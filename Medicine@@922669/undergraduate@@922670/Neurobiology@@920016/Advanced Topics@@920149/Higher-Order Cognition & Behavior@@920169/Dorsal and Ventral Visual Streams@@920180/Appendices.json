{"hands_on_practices": [{"introduction": "The functional specializations of the dorsal and ventral streams are reflected in their underlying neuroanatomy and biophysics. This exercise allows you to explore how differences in axonal conduction velocity and synaptic architecture give rise to different processing speeds. By modeling these factors as random variables, you will calculate and compare the predicted onset latencies for neural responses in the Middle Temporal area (MT) of the dorsal stream and area V4 of the ventral stream [@problem_id:5013693].", "problem": "A brief, high-contrast visual flash evokes feedforward activity that propagates from the retina to higher visual cortical areas along partially segregated pathways. Consider two such pathways: the dorsal stream to the middle temporal area (MT) and the ventral stream to area V4. Model the total onset latency for each pathway as the sum of an axonal conduction time and a sum of synaptic delays across serial relays. Use the following foundational bases: (i) axonal conduction delay equals path length divided by conduction velocity, (ii) synaptic delays across serial relays add, and (iii) for independent stages, total latency is the sum of the component latencies.\n\nAssume the following biophysically plausible properties.\n- The effective axonal path length for MT is $L_{\\mathrm{MT}} = 0.10\\,\\mathrm{m}$ and for V4 is $L_{\\mathrm{V4}} = 0.080\\,\\mathrm{m}$.\n- The effective conduction velocity for MT is a random variable $V_{\\mathrm{MT}}$ with approximately normal distribution having mean $\\mu_{\\mathrm{MT}} = 2.5\\,\\mathrm{m/s}$ and standard deviation $\\sigma_{\\mathrm{MT}} = 0.50\\,\\mathrm{m/s}$. For V4, $V_{\\mathrm{V4}}$ is approximately normal with mean $\\mu_{\\mathrm{V4}} = 1.8\\,\\mathrm{m/s}$ and standard deviation $\\sigma_{\\mathrm{V4}} = 0.36\\,\\mathrm{m/s}$. Coefficients of variation are small enough that a second-order Taylor expansion about the mean provides an accurate approximation to expectations of smooth functions of velocity.\n- Synaptic delay at each relay is an independent normal random variable with mean $\\mu_{s} = 1.2\\,\\mathrm{ms}$ and standard deviation $\\sigma_{s} = 0.25\\,\\mathrm{ms}$. The number of serial synapses is $n_{\\mathrm{MT}} = 4$ for MT and $n_{\\mathrm{V4}} = 5$ for V4.\n- All random components are mutually independent.\n\nTasks:\n1. Starting from the above definitions and assumptions, derive an approximate expression for the expected value and variance of the total onset latency for each pathway, expressed in terms of $L$, $\\mu$, $\\sigma$, $n$, $\\mu_{s}$, and $\\sigma_{s}$. State the resulting approximate latency distribution for each pathway.\n2. Using the provided numerical parameters, compute the predicted onset time (the expected latency) for MT and for V4, and then compute the difference $\\Delta t = \\mathbb{E}[T_{\\mathrm{V4}}] - \\mathbb{E}[T_{\\mathrm{MT}}]$. Round your final numeric answer to three significant figures. Express the final result in milliseconds (ms). The final answer must be a single real-valued number.", "solution": "The problem is assessed to be valid as it is scientifically grounded in neurobiology, well-posed with a clear objective and all necessary parameters, and uses standard mathematical modeling and approximation techniques.\n\nThe total onset latency, $T$, for a given visual pathway is modeled as the sum of the axonal conduction latency, $T_{\\mathrm{axon}}$, and the total synaptic delay, $T_{\\mathrm{synapse}}$.\n$$\nT = T_{\\mathrm{axon}} + T_{\\mathrm{synapse}}\n$$\nThe axonal conduction latency is the ratio of the effective path length, $L$, to the effective conduction velocity, $V$.\n$$\nT_{\\mathrm{axon}} = \\frac{L}{V}\n$$\nThe total synaptic delay is the sum of delays at each of the $n$ serial relays. Each synaptic delay, $D_i$, is an independent random variable.\n$$\nT_{\\mathrm{synapse}} = \\sum_{i=1}^{n} D_i\n$$\nThe problem states that all random components are mutually independent. This implies that the velocity $V$ and all synaptic delays $D_i$ are mutually independent. Consequently, $T_{\\mathrm{axon}}$ and $T_{\\mathrm{synapse}}$ are independent random variables.\n\n### Task 1: Derivation of Latency Expectation, Variance, and Distribution\n\nFirst, we analyze the total synaptic delay, $T_{\\mathrm{synapse}}$. The synaptic delays $D_i$ are independent and identically distributed (i.i.d.) normal random variables with mean $\\mu_s$ and variance $\\sigma_s^2$, i.e., $D_i \\sim \\mathcal{N}(\\mu_s, \\sigma_s^2)$.\n\nThe expected value of the sum of random variables is the sum of their expected values:\n$$\n\\mathbb{E}[T_{\\mathrm{synapse}}] = \\mathbb{E}\\left[\\sum_{i=1}^{n} D_i\\right] = \\sum_{i=1}^{n} \\mathbb{E}[D_i] = n \\mu_s\n$$\nSince the synaptic delays are independent, the variance of their sum is the sum of their variances:\n$$\n\\mathrm{Var}(T_{\\mathrm{synapse}}) = \\mathrm{Var}\\left(\\sum_{i=1}^{n} D_i\\right) = \\sum_{i=1}^{n} \\mathrm{Var}(D_i) = n \\sigma_s^2\n$$\nThe sum of independent normal random variables is itself a normal random variable. Therefore, the distribution of the total synaptic delay is:\n$$\nT_{\\mathrm{synapse}} \\sim \\mathcal{N}(n\\mu_s, n\\sigma_s^2)\n$$\n\nNext, we analyze the axonal conduction latency, $T_{\\mathrm{axon}} = L/V$. The velocity $V$ is a random variable, so $T_{\\mathrm{axon}}$ is also a random variable. We are instructed to use a second-order Taylor series expansion of the function $f(V) = L/V$ around the mean velocity, $\\mu = \\mathbb{E}[V]$, to find an approximation for its expectation.\nThe function and its first two derivatives with respect to $V$ are:\n$$\nf(V) = \\frac{L}{V}, \\quad f'(V) = -\\frac{L}{V^2}, \\quad f''(V) = \\frac{2L}{V^3}\n$$\nThe second-order Taylor expansion of $f(V)$ around $\\mu$ is:\n$$\nf(V) \\approx f(\\mu) + f'(\\mu)(V-\\mu) + \\frac{1}{2}f''(\\mu)(V-\\mu)^2\n$$\nSubstituting the derivatives evaluated at $\\mu$:\n$$\nT_{\\mathrm{axon}} = \\frac{L}{V} \\approx \\frac{L}{\\mu} - \\frac{L}{\\mu^2}(V-\\mu) + \\frac{1}{2}\\left(\\frac{2L}{\\mu^3}\\right)(V-\\mu)^2 = \\frac{L}{\\mu} - \\frac{L}{\\mu^2}(V-\\mu) + \\frac{L}{\\mu^3}(V-\\mu)^2\n$$\nTaking the expectation of this expression:\n$$\n\\mathbb{E}[T_{\\mathrm{axon}}] \\approx \\mathbb{E}\\left[\\frac{L}{\\mu} - \\frac{L}{\\mu^2}(V-\\mu) + \\frac{L}{\\mu^3}(V-\\mu)^2\\right] = \\frac{L}{\\mu} - \\frac{L}{\\mu^2}\\mathbb{E}[V-\\mu] + \\frac{L}{\\mu^3}\\mathbb{E}[(V-\\mu)^2]\n$$\nBy definition, $\\mathbb{E}[V-\\mu] = \\mathbb{E}[V] - \\mu = \\mu - \\mu = 0$, and $\\mathbb{E}[(V-\\mu)^2] = \\mathrm{Var}(V) = \\sigma^2$. Substituting these yields the approximate expected axonal latency:\n$$\n\\mathbb{E}[T_{\\mathrm{axon}}] \\approx \\frac{L}{\\mu} + \\frac{L\\sigma^2}{\\mu^3} = \\frac{L}{\\mu}\\left(1 + \\frac{\\sigma^2}{\\mu^2}\\right)\n$$\nFor the variance of the axonal latency, we use the first-order approximation (delta method), which is standard when the coefficient of variation is small:\n$$\n\\mathrm{Var}(T_{\\mathrm{axon}}) = \\mathrm{Var}(f(V)) \\approx |f'(\\mu)|^2 \\mathrm{Var}(V)\n$$\n$$\n\\mathrm{Var}(T_{\\mathrm{axon}}) \\approx \\left(-\\frac{L}{\\mu^2}\\right)^2 \\sigma^2 = \\frac{L^2 \\sigma^2}{\\mu^4}\n$$\nNow we combine the results for the total latency $T = T_{\\mathrm{axon}} + T_{\\mathrm{synapse}}$. Due to the independence of the components, the expected value and variance of the total latency are the sums of the respective parts.\n\nExpected total latency:\n$$\n\\mathbb{E}[T] = \\mathbb{E}[T_{\\mathrm{axon}}] + \\mathbb{E}[T_{\\mathrm{synapse}}] \\approx \\frac{L}{\\mu}\\left(1 + \\frac{\\sigma^2}{\\mu^2}\\right) + n \\mu_s\n$$\nVariance of total latency:\n$$\n\\mathrm{Var}(T) = \\mathrm{Var}(T_{\\mathrm{axon}}) + \\mathrm{Var}(T_{\\mathrm{synapse}}) \\approx \\frac{L^2 \\sigma^2}{\\mu^4} + n \\sigma_s^2\n$$\nThe total latency $T$ is the sum of a normally distributed variable ($T_{\\mathrm{synapse}}$) and another random variable ($T_{\\mathrm{axon}}$) which is a function of an approximately normal variable. A common and reasonable approximation in such cases is to model the total latency itself as a normal random variable.\nTherefore, the approximate latency distribution for each pathway is:\n$$\nT \\sim \\mathcal{N}\\left(\\frac{L}{\\mu}\\left(1 + \\frac{\\sigma^2}{\\mu^2}\\right) + n \\mu_s, \\frac{L^2 \\sigma^2}{\\mu^4} + n \\sigma_s^2\\right)\n$$\n\n### Task 2: Numerical Computations\n\nWe are given the following parameters, ensuring consistent units (seconds for time, meters for length).\nFor the MT pathway:\n$L_{\\mathrm{MT}} = 0.10\\,\\mathrm{m}$\n$\\mu_{\\mathrm{MT}} = 2.5\\,\\mathrm{m/s}$\n$\\sigma_{\\mathrm{MT}} = 0.50\\,\\mathrm{m/s}$\n$n_{\\mathrm{MT}} = 4$\n\nFor the V4 pathway:\n$L_{\\mathrm{V4}} = 0.080\\,\\mathrm{m}$\n$\\mu_{\\mathrm{V4}} = 1.8\\,\\mathrm{m/s}$\n$\\sigma_{\\mathrm{V4}} = 0.36\\,\\mathrm{m/s}$\n$n_{\\mathrm{V4}} = 5$\n\nFor synaptic delays (common to both pathways):\n$\\mu_s = 1.2\\,\\mathrm{ms} = 1.2 \\times 10^{-3}\\,\\mathrm{s}$\n$\\sigma_s = 0.25\\,\\mathrm{ms} = 0.25 \\times 10^{-3}\\,\\mathrm{s}$\n\nWe now compute the predicted onset time (expected latency) for each pathway using the derived formula for $\\mathbb{E}[T]$.\n\nFor the MT pathway:\n$$\n\\mathbb{E}[T_{\\mathrm{MT}}] \\approx \\frac{L_{\\mathrm{MT}}}{\\mu_{\\mathrm{MT}}}\\left(1 + \\frac{\\sigma_{\\mathrm{MT}}^2}{\\mu_{\\mathrm{MT}}^2}\\right) + n_{\\mathrm{MT}} \\mu_s\n$$\n$$\n\\mathbb{E}[T_{\\mathrm{MT}}] \\approx \\frac{0.10}{2.5}\\left(1 + \\frac{(0.50)^2}{(2.5)^2}\\right) + 4 \\times (1.2 \\times 10^{-3})\n$$\n$$\n\\mathbb{E}[T_{\\mathrm{MT}}] \\approx 0.04\\left(1 + \\left(\\frac{0.50}{2.5}\\right)^2\\right) + 0.0048 = 0.04(1 + (0.2)^2) + 0.0048\n$$\n$$\n\\mathbb{E}[T_{\\mathrm{MT}}] \\approx 0.04(1 + 0.04) + 0.0048 = 0.04(1.04) + 0.0048 = 0.0416 + 0.0048 = 0.0464\\,\\mathrm{s}\n$$\n\nFor the V4 pathway:\n$$\n\\mathbb{E}[T_{\\mathrm{V4}}] \\approx \\frac{L_{\\mathrm{V4}}}{\\mu_{\\mathrm{V4}}}\\left(1 + \\frac{\\sigma_{\\mathrm{V4}}^2}{\\mu_{\\mathrm{V4}}^2}\\right) + n_{\\mathrm{V4}} \\mu_s\n$$\n$$\n\\mathbb{E}[T_{\\mathrm{V4}}] \\approx \\frac{0.080}{1.8}\\left(1 + \\frac{(0.36)^2}{(1.8)^2}\\right) + 5 \\times (1.2 \\times 10^{-3})\n$$\n$$\n\\mathbb{E}[T_{\\mathrm{V4}}] \\approx \\frac{2}{45}\\left(1 + \\left(\\frac{0.36}{1.8}\\right)^2\\right) + 0.0060 = \\frac{2}{45}(1 + (0.2)^2) + 0.0060\n$$\n$$\n\\mathbb{E}[T_{\\mathrm{V4}}] \\approx \\frac{2}{45}(1 + 0.04) + 0.0060 = \\frac{2}{45}(1.04) + 0.0060 = \\frac{2.08}{45} + 0.0060\n$$\n$$\n\\mathbb{E}[T_{\\mathrm{V4}}] \\approx 0.046222... + 0.0060 = 0.052222...\\,\\mathrm{s}\n$$\nThe predicted onset time for MT is $\\mathbb{E}[T_{\\mathrm{MT}}] = 46.4\\,\\mathrm{ms}$, and for V4 is $\\mathbb{E}[T_{\\mathrm{V4}}] \\approx 52.2\\,\\mathrm{ms}$.\n\nFinally, we compute the difference $\\Delta t = \\mathbb{E}[T_{\\mathrm{V4}}] - \\mathbb{E}[T_{\\mathrm{MT}}]$.\n$$\n\\Delta t \\approx 0.052222... - 0.0464 = 0.0058222...\\,\\mathrm{s}\n$$\nConverting this result to milliseconds:\n$$\n\\Delta t \\approx 0.0058222...\\,\\mathrm{s} \\times \\frac{1000\\,\\mathrm{ms}}{1\\,\\mathrm{s}} \\approx 5.8222...\\,\\mathrm{ms}\n$$\nRounding to three significant figures, we get $5.82\\,\\mathrm{ms}$.", "answer": "$$\n\\boxed{5.82}\n$$", "id": "5013693"}, {"introduction": "Our brain seamlessly integrates information from the \"what\" and \"where\" pathways to form a unified and reliable percept of the world. This practice introduces Bayesian inference as a powerful computational principle explaining how this integration might occur. You will calculate an optimal estimate of heading direction by formally weighing a dorsal-like motion cue and a ventral-like shape cue according to their reliability, providing insight into perceptual decision-making under uncertainty [@problem_id:5013729].", "problem": "In the primate visual system, the dorsal visual stream is predominantly tuned to motion-derived information, whereas the ventral visual stream is tuned to shape-derived information. Consider a perceptual decision about a single latent heading angle $\\theta$ (in degrees) relative to straight ahead during a brief visual presentation of a moving textured object. Assume the following:\n\n- The dorsal motion cue produces a measurement $\\theta_{m}$ with a Gaussian likelihood $p(\\theta_{m} \\mid \\theta)$ that has mean $\\theta$ and variance $\\sigma_{m}^{2}$. In a particular trial, the motion measurement equals $\\theta_{m} = 10$ and the dorsal motion variance equals $\\sigma_{m}^{2} = 4$.\n- The ventral shape cue produces a measurement $\\theta_{s}$ with a Gaussian likelihood $p(\\theta_{s} \\mid \\theta)$ that has mean $\\theta$ and variance $\\sigma_{s}^{2}$. In the same trial, the shape measurement equals $\\theta_{s} = -2$ and the ventral shape variance equals $\\sigma_{s}^{2} = 16$.\n- The observer has a Gaussian prior over the heading angle $p(\\theta)$ with mean $\\mu_{p} = 0$ and variance $\\sigma_{p}^{2} = 64$.\n- Assume conditional independence of the cues given $\\theta$.\n\nUsing Bayes’ theorem and the assumptions above, derive the posterior distribution $p(\\theta \\mid \\theta_{m}, \\theta_{s})$ over the heading angle $\\theta$ and interpret the predicted behavior under cue conflict by identifying the Maximum A Posteriori (MAP) estimate. Quantify the stream-specific weightings for the dorsal motion and ventral shape cues, defined as the normalized contributions that each cue’s reliability (inverse variance) makes to the MAP estimate under the Gaussian assumptions.\n\nReport only the MAP estimate of the heading angle as your final answer, expressed in degrees. Round your final answer to four significant figures.", "solution": "The problem asks for the Maximum A Posteriori (MAP) estimate of a latent heading angle, $\\theta$, based on two noisy sensory cues and a prior belief. This is a problem of Bayesian inference, specifically cue integration.\n\nThe problem has been validated and is deemed valid. It is scientifically grounded in computational neuroscience, well-posed with all necessary information provided, and objective in its formulation.\n\nAccording to Bayes' theorem, the posterior probability distribution of the angle $\\theta$ given the motion measurement $\\theta_{m}$ and the shape measurement $\\theta_{s}$ is proportional to the product of the likelihood and the prior:\n$$p(\\theta \\mid \\theta_{m}, \\theta_{s}) \\propto p(\\theta_{m}, \\theta_{s} \\mid \\theta) p(\\theta)$$\nThe problem states that the two cues are conditionally independent given the true heading angle $\\theta$. Therefore, the joint likelihood can be factored into the product of the individual likelihoods:\n$$p(\\theta_{m}, \\theta_{s} \\mid \\theta) = p(\\theta_{m} \\mid \\theta) p(\\theta_{s} \\mid \\theta)$$\nSubstituting this into the first equation, we get the expression for the posterior:\n$$p(\\theta \\mid \\theta_{m}, \\theta_{s}) \\propto p(\\theta_{m} \\mid \\theta) p(\\theta_{s} \\mid \\theta) p(\\theta)$$\nWe are given that all three distributions on the right-hand side are Gaussian:\n1.  The dorsal motion cue likelihood: $p(\\theta_{m} \\mid \\theta) = \\mathcal{N}(\\theta, \\sigma_{m}^{2})$, where the measurement is $\\theta_{m} = 10$ and the variance is $\\sigma_{m}^{2} = 4$.\n2.  The ventral shape cue likelihood: $p(\\theta_{s} \\mid \\theta) = \\mathcal{N}(\\theta, \\sigma_{s}^{2})$, where the measurement is $\\theta_{s} = -2$ and the variance is $\\sigma_{s}^{2} = 16$.\n3.  The prior distribution: $p(\\theta) = \\mathcal{N}(\\mu_{p}, \\sigma_{p}^{2})$, where the mean is $\\mu_{p} = 0$ and the variance is $\\sigma_{p}^{2} = 64$.\n\nThe probability density function for a Gaussian distribution $\\mathcal{N}(\\mu, \\sigma^2)$ is proportional to $\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$. Thus, the posterior distribution is:\n$$p(\\theta \\mid \\theta_{m}, \\theta_{s}) \\propto \\exp\\left(-\\frac{(\\theta_{m}-\\theta)^2}{2\\sigma_{m}^{2}}\\right) \\exp\\left(-\\frac{(\\theta_{s}-\\theta)^2}{2\\sigma_{s}^{2}}\\right) \\exp\\left(-\\frac{(\\theta-\\mu_{p})^2}{2\\sigma_{p}^{2}}\\right)$$\nCombining the exponential terms:\n$$p(\\theta \\mid \\theta_{m}, \\theta_{s}) \\propto \\exp\\left( -\\frac{(\\theta-\\theta_{m})^2}{2\\sigma_{m}^{2}} -\\frac{(\\theta-\\theta_{s})^2}{2\\sigma_{s}^{2}} -\\frac{(\\theta-\\mu_{p})^2}{2\\sigma_{p}^{2}} \\right)$$\nThe MAP estimate, $\\theta_{\\text{MAP}}$, is the value of $\\theta$ that maximizes this posterior probability. Maximizing the posterior is equivalent to minimizing the negative of its logarithm. Let $J(\\theta)$ be the term in the exponent (also known as the negative log posterior, ignoring constant terms):\n$$J(\\theta) = \\frac{(\\theta-\\theta_{m})^2}{2\\sigma_{m}^{2}} + \\frac{(\\theta-\\theta_{s})^2}{2\\sigma_{s}^{2}} + \\frac{(\\theta-\\mu_{p})^2}{2\\sigma_{p}^{2}}$$\nTo find the minimum of $J(\\theta)$, we take its derivative with respect to $\\theta$ and set it to $0$:\n$$\\frac{dJ}{d\\theta} = \\frac{2(\\theta-\\theta_{m})}{2\\sigma_{m}^{2}} + \\frac{2(\\theta-\\theta_{s})}{2\\sigma_{s}^{2}} + \\frac{2(\\theta-\\mu_{p})}{2\\sigma_{p}^{2}} = 0$$\n$$\\frac{\\theta-\\theta_{m}}{\\sigma_{m}^{2}} + \\frac{\\theta-\\theta_{s}}{\\sigma_{s}^{2}} + \\frac{\\theta-\\mu_{p}}{\\sigma_{p}^{2}} = 0$$\nWe can separate terms involving $\\theta$:\n$$\\theta\\left(\\frac{1}{\\sigma_{m}^{2}} + \\frac{1}{\\sigma_{s}^{2}} + \\frac{1}{\\sigma_{p}^{2}}\\right) = \\frac{\\theta_{m}}{\\sigma_{m}^{2}} + \\frac{\\theta_{s}}{\\sigma_{s}^{2}} + \\frac{\\mu_{p}}{\\sigma_{p}^{2}}$$\nSolving for $\\theta$ gives the MAP estimate, $\\theta_{\\text{MAP}}$:\n$$\\theta_{\\text{MAP}} = \\frac{\\frac{\\theta_{m}}{\\sigma_{m}^{2}} + \\frac{\\theta_{s}}{\\sigma_{s}^{2}} + \\frac{\\mu_{p}}{\\sigma_{p}^{2}}}{\\frac{1}{\\sigma_{m}^{2}} + \\frac{1}{\\sigma_{s}^{2}} + \\frac{1}{\\sigma_{p}^{2}}}$$\nThis equation shows that the MAP estimate is a weighted average of the measurements and the prior mean, where the weights are the reliabilities (inverse variances) of each source of information. Let $r_{i} = 1/\\sigma_{i}^{2}$ be the reliability.\n$$r_{m} = \\frac{1}{\\sigma_{m}^{2}} = \\frac{1}{4}$$\n$$r_{s} = \\frac{1}{\\sigma_{s}^{2}} = \\frac{1}{16}$$\n$$r_{p} = \\frac{1}{\\sigma_{p}^{2}} = \\frac{1}{64}$$\nThe MAP estimate equation becomes:\n$$\\theta_{\\text{MAP}} = \\frac{r_{m}\\theta_{m} + r_{s}\\theta_{s} + r_{p}\\mu_{p}}{r_{m} + r_{s} + r_{p}}$$\nSubstituting the given numerical values:\n$\\theta_{\\text{MAP}} = \\frac{(\\frac{1}{4})(10) + (\\frac{1}{16})(-2) + (\\frac{1}{64})(0)}{\\frac{1}{4} + \\frac{1}{16} + \\frac{1}{64}}$\nFirst, we calculate the numerator:\n$$\\text{Numerator} = \\frac{10}{4} - \\frac{2}{16} + 0 = 2.5 - 0.125 = 2.375$$\nIn fractional form: $\\frac{160}{64} - \\frac{8}{64} = \\frac{152}{64}$.\nNext, we calculate the denominator:\n$$\\text{Denominator} = \\frac{1}{4} + \\frac{1}{16} + \\frac{1}{64} = \\frac{16}{64} + \\frac{4}{64} + \\frac{1}{64} = \\frac{21}{64}$$\nNow, we compute the final value for $\\theta_{\\text{MAP}}$:\n$$\\theta_{\\text{MAP}} = \\frac{\\frac{152}{64}}{\\frac{21}{64}} = \\frac{152}{21}$$\nAs a decimal, this is approximately $7.2380952...$\n\nThe normalized weighting for each cue is its reliability divided by the total reliability.\nTotal reliability: $r_{\\text{total}} = r_{m} + r_{s} + r_{p} = \\frac{21}{64}$.\nWeight for dorsal motion cue: $w_{m} = \\frac{r_{m}}{r_{\\text{total}}} = \\frac{1/4}{21/64} = \\frac{16}{21} \\approx 0.762$.\nWeight for ventral shape cue: $w_{s} = \\frac{r_{s}}{r_{\\text{total}}} = \\frac{1/16}{21/64} = \\frac{4}{21} \\approx 0.190$.\nThe high reliability of the dorsal motion cue ($\\sigma_{m}^{2} = 4$) gives it a large weight, pulling the MAP estimate of $\\approx 7.24$ degrees much closer to its measurement $\\theta_{m}=10$ than to the conflicting ventral shape cue measurement $\\theta_{s}=-2$ or the prior mean $\\mu_{p}=0$.\n\nThe problem asks for the MAP estimate of the heading angle, rounded to four significant figures.\n$\\theta_{\\text{MAP}} = \\frac{152}{21} \\approx 7.2380952...$\nRounding to four significant figures gives $7.238$.", "answer": "$$\n\\boxed{7.238}\n$$", "id": "5013729"}, {"introduction": "Computational models are essential tools in neuroscience, but they must be rigorously tested against empirical data. This exercise introduces Representational Similarity Analysis (RSA), a state-of-the-art method for comparing model representations to brain activity. You will implement the core steps of RSA to quantify the alignment between a model's representational geometry and that of neural populations in MT and IT, learning a powerful technique for validating theories of brain function [@problem_id:5013737].", "problem": "You are provided with simulated response matrices that reflect responses of a computational model to a shared set of stimuli and corresponding neural population responses from two canonical visual areas associated with the dorsal and ventral visual streams. Specifically, the dorsal stream is represented by the Middle Temporal area (MT), and the ventral stream is represented by the Inferior Temporal cortex (IT). Your task is to quantify the alignment between model and neural representational geometries using representational similarity analysis with cross-validated correlations.\n\nFundamental base and definitions to use:\n- A representational dissimilarity matrix is defined from a response matrix by first computing, for each pair of stimuli, the Pearson correlation coefficient across units, then converting to a dissimilarity via $d_{ij} = 1 - \\rho_{ij}$. For a response matrix $X \\in \\mathbb{R}^{n \\times p}$, where $n$ is the number of stimuli and $p$ is the number of units, define the representational dissimilarity matrix $D \\in \\mathbb{R}^{n \\times n}$ by $D_{ij} = 1 - \\mathrm{corr}(X_{i,\\cdot}, X_{j,\\cdot})$, with $D_{ii} = 0$.\n- Vectorize the upper-triangular (excluding the diagonal) of $D$ into a vector $v \\in \\mathbb{R}^{n(n-1)/2}$ in a consistent order.\n- Given two independent splits for the model, $(M^{A}, M^{B})$, and two independent splits for the neural data, $(N^{1}, N^{2})$, form four representational dissimilarity vectors $v(M^{A}), v(M^{B}), v(N^{1}), v(N^{2})$. Define a cross-validated Pearson correlation by computing $r_{1} = \\mathrm{corr}(v(M^{A}), v(N^{2}))$ and $r_{2} = \\mathrm{corr}(v(M^{B}), v(N^{1}))$. Combine $r_{1}$ and $r_{2}$ using the Fisher $z$-transform: $z(r) = \\tfrac{1}{2}\\ln\\left(\\tfrac{1+r}{1-r}\\right)$, average in $z$-space, and invert with $\\tanh$ to obtain the final estimate $r_{\\mathrm{cv}} = \\tanh\\left(\\tfrac{z(r_{1}) + z(r_{2})}{2}\\right)$.\n\nAlgorithmic requirements:\n- Use Pearson correlation for both the dissimilarity construction and the final vector-to-vector correlation.\n- Ensure numerical stability when applying the Fisher $z$-transform by handling the boundary cases at $r = \\pm 1$ in a principled manner.\n- All computations must be deterministic and use only the provided matrices and definitions.\n\nTest suite:\nYou must compute $r_{\\mathrm{cv}}$ for four independent scenarios. For each scenario, the stimulus order is fixed as $(s_{1}, s_{2}, s_{3}, s_{4}, s_{5})$ for the five-stimulus cases and $(t_{1}, t_{2}, t_{3}, t_{4})$ for the four-stimulus case.\n\nScenario $1$ (Model motion features vs MT; $5 \\times 4$ responses):\n- Model-motion split $A$, $M_{\\mathrm{motion}}^{A} \\in \\mathbb{R}^{5 \\times 4}$:\n$$\n\\begin{bmatrix}\n2.0 & 2.0 & 0.1 & 0.0 \\\\\n1.9 & 2.1 & 0.0 & 0.2 \\\\\n0.2 & 0.0 & 2.1 & 2.0 \\\\\n0.0 & 0.1 & 1.9 & 2.2 \\\\\n0.1 & 0.2 & 2.0 & 2.1\n\\end{bmatrix}\n$$\n- Model-motion split $B$, $M_{\\mathrm{motion}}^{B} \\in \\mathbb{R}^{5 \\times 4}$:\n$$\n\\begin{bmatrix}\n2.1 & 1.9 & 0.0 & 0.1 \\\\\n2.0 & 2.0 & 0.1 & 0.1 \\\\\n0.1 & 0.0 & 2.0 & 2.2 \\\\\n0.0 & 0.2 & 2.2 & 1.9 \\\\\n0.2 & 0.1 & 2.1 & 2.0\n\\end{bmatrix}\n$$\n- Neural MT split $1$, $N_{\\mathrm{MT}}^{1} \\in \\mathbb{R}^{5 \\times 4}$:\n$$\n\\begin{bmatrix}\n2.2 & 2.1 & 0.0 & 0.1 \\\\\n1.8 & 2.0 & 0.1 & 0.1 \\\\\n0.0 & 0.1 & 2.2 & 2.1 \\\\\n0.1 & 0.0 & 1.8 & 2.0 \\\\\n0.1 & 0.2 & 2.1 & 2.2\n\\end{bmatrix}\n$$\n- Neural MT split $2$, $N_{\\mathrm{MT}}^{2} \\in \\mathbb{R}^{5 \\times 4}$:\n$$\n\\begin{bmatrix}\n2.0 & 2.2 & 0.1 & 0.0 \\\\\n2.1 & 1.9 & 0.0 & 0.2 \\\\\n0.2 & 0.0 & 2.0 & 2.1 \\\\\n0.0 & 0.1 & 2.2 & 1.8 \\\\\n0.1 & 0.2 & 2.0 & 2.3\n\\end{bmatrix}\n$$\n\nScenario $2$ (Model form features vs IT; $5 \\times 4$ responses):\n- Model-form split $A$, $M_{\\mathrm{form}}^{A} \\in \\mathbb{R}^{5 \\times 4}$:\n$$\n\\begin{bmatrix}\n2.0 & 2.0 & 0.1 & 0.0 \\\\\n0.1 & 0.0 & 2.0 & 2.0 \\\\\n2.1 & 1.9 & 0.0 & 0.1 \\\\\n0.0 & 0.1 & 2.1 & 1.9 \\\\\n1.0 & 1.1 & 0.9 & 1.0\n\\end{bmatrix}\n$$\n- Model-form split $B$, $M_{\\mathrm{form}}^{B} \\in \\mathbb{R}^{5 \\times 4}$:\n$$\n\\begin{bmatrix}\n2.1 & 1.9 & 0.0 & 0.1 \\\\\n0.0 & 0.1 & 2.1 & 1.9 \\\\\n1.9 & 2.1 & 0.1 & 0.0 \\\\\n0.1 & 0.0 & 1.9 & 2.1 \\\\\n1.1 & 1.0 & 1.0 & 0.9\n\\end{bmatrix}\n$$\n- Neural IT split $1$, $N_{\\mathrm{IT}}^{1} \\in \\mathbb{R}^{5 \\times 4}$:\n$$\n\\begin{bmatrix}\n2.2 & 2.1 & 0.0 & 0.1 \\\\\n0.0 & 0.1 & 2.0 & 2.1 \\\\\n1.8 & 2.0 & 0.1 & 0.0 \\\\\n0.1 & 0.0 & 1.9 & 2.0 \\\\\n1.1 & 1.0 & 0.9 & 1.0\n\\end{bmatrix}\n$$\n- Neural IT split $2$, $N_{\\mathrm{IT}}^{2} \\in \\mathbb{R}^{5 \\times 4}$:\n$$\n\\begin{bmatrix}\n2.0 & 2.2 & 0.1 & 0.0 \\\\\n0.1 & 0.0 & 2.2 & 1.8 \\\\\n2.1 & 1.9 & 0.0 & 0.2 \\\\\n0.0 & 0.2 & 1.8 & 2.2 \\\\\n0.9 & 1.0 & 1.1 & 1.0\n\\end{bmatrix}\n$$\n\nScenario $3$ (Cross-stream mismatch control: Model motion features vs IT; $5 \\times 4$ responses):\n- Use $M_{\\mathrm{motion}}^{A}$ and $M_{\\mathrm{motion}}^{B}$ from Scenario $1$.\n- Use $N_{\\mathrm{IT}}^{1}$ and $N_{\\mathrm{IT}}^{2}$ from Scenario $2$.\n\nScenario $4$ (Boundary case with identical representational geometries across splits; $4 \\times 3$ responses):\n- Let the common response matrix $R \\in \\mathbb{R}^{4 \\times 3}$ be\n$$\n\\begin{bmatrix}\n0.0 & 1.0 & 2.0 \\\\\n0.5 & 1.0 & 1.5 \\\\\n2.0 & 1.0 & 0.0 \\\\\n1.5 & 1.0 & 0.5\n\\end{bmatrix}\n$$\n- Set $M^{A} = R$, $M^{B} = R$, $N^{1} = R$, $N^{2} = R$.\n\nRequired outputs:\n- For each scenario, compute the cross-validated correlation $r_{\\mathrm{cv}}$ as defined above.\n- The final program output must be a single line containing the four results as a comma-separated list enclosed in square brackets, in the order of Scenarios $1$, $2$, $3$, $4$.\n- Each value must be a floating-point number rounded to $6$ decimal places.\n\nYour program must produce exactly one line in the format: \"[result1,result2,result3,result4]\". No physical units are involved. Angles are not involved. All percentages, if any, must be expressed as decimals, but none are required here. The program must be self-contained, take no input, and use only the provided definitions and matrices. The computation must be performed using a modern programming language that supports linear algebra operations as specified in the execution environment.", "solution": "The problem requires the computation of a cross-validated correlation coefficient, denoted $r_{\\mathrm{cv}}$, to quantify the similarity between representational geometries of a computational model and neural data. This task falls under the umbrella of Representational Similarity Analysis (RSA), a common technique in computational neuroscience. The analysis is to be performed for $4$ distinct scenarios.\n\nThe solution is implemented by following a sequence of well-defined mathematical steps. First, a function is constructed to transform a response matrix into its corresponding Representational Dissimilarity Matrix (RDM), which is then vectorized. Second, another function uses this transformation to compute the final cross-validated correlation $r_{\\mathrm{cv}}$ from the four input response matrices provided for each scenario.\n\n**Step 1: Computing the Representational Dissimilarity Vector**\n\nThe first core procedure is to convert a response matrix $X \\in \\mathbb{R}^{n \\times p}$, where $n$ is the number of stimuli and $p$ is the number of measurement units (e.g., neurons or model units), into a vectorized RDM. This involves three sub-steps:\n\n1.  **Pairwise Correlation:** For each pair of stimuli, indexed $i$ and $j$, we consider their corresponding response vectors, which are the rows $X_{i, \\cdot}$ and $X_{j, \\cdot}$ of the matrix $X$. The Pearson correlation coefficient, $\\rho_{ij} = \\mathrm{corr}(X_{i,\\cdot}, X_{j,\\cdot})$, is computed for all pairs of rows. This yields a symmetric $n \\times n$ correlation matrix $P$, where $P_{ij} = \\rho_{ij}$ and the diagonal elements are all $1$.\n\n2.  **Dissimilarity Transformation:** The correlation matrix $P$ is converted into a Representational Dissimilarity Matrix (RDM) $D$ using the formula $D_{ij} = 1 - \\rho_{ij}$. This transformation maps high positive correlations (high similarity) to low dissimilarity values (close to $0$), and high negative correlations (high anti-similarity) to high dissimilarity values (close to $2$). The diagonal elements $D_{ii}$ are explicitly set to $0$ as the dissimilarity of a stimulus representation with itself is zero.\n\n3.  **Vectorization:** The RDM $D$ is a symmetric matrix. All the relevant information is contained in its upper (or lower) triangle. We vectorize the strictly upper-triangular part of $D$ (i.e., all elements $D_{ij}$ where $i < j$) into a single vector $v$. For an $n \\times n$ matrix, this vector will have a length of $n(n-1)/2$. The vectorization must follow a consistent order for all matrices to ensure valid subsequent comparisons.\n\n**Step 2: Computing the Cross-Validated Correlation ($r_{\\mathrm{cv}}$)**\n\nThe second core procedure computes the final summary statistic, $r_{\\mathrm{cv}}$, using two independent splits of the model's responses, $(M^{A}, M^{B})$, and two independent splits of the neural responses, $(N^{1}, N^{2})$. This cross-validation scheme prevents statistical inflation that can arise from applying the same data for both fitting and evaluation, or from noise correlations within a single dataset.\n\n1.  **Generate RDM Vectors:** Using the procedure from Step $1$, we compute the four RDM vectors: $v(M^{A})$, $v(M^{B})$, $v(N^{1})$, and $v(N^{2})$.\n\n2.  **Compute Cross-Correlations:** Two Pearson correlations are computed across the independent splits. The \"split-half\" logic dictates correlating one model split with the *other* neural split:\n    *   $r_{1} = \\mathrm{corr}(v(M^{A}), v(N^{2}))$\n    *   $r_{2} = \\mathrm{corr}(v(M^{B}), v(N^{1}))$\n\n3.  **Average Correlations via Fisher $z$-transform:** Correlation coefficients are not additive. To properly average them, they must first be transformed into a space where they are approximately normally distributed and have a stable variance. The Fisher $z$-transform is used for this purpose:\n    $$z(r) = \\frac{1}{2}\\ln\\left(\\frac{1+r}{1-r}\\right) = \\mathrm{arctanh}(r)$$\n    We compute $z(r_1)$ and $z(r_2)$, and their arithmetic mean, $\\bar{z} = \\frac{z(r_1) + z(r_2)}{2}$. The problem requires handling boundary cases where $r = \\pm 1$. The $\\mathrm{arctanh}$ function correctly maps $r=1$ to $\\infty$ and $r=-1$ to $-\\infty$. The subsequent averaging and inverse transform handle these infinite values correctly.\n\n4.  **Inverse Transform:** The average $\\bar{z}$ is transformed back to the correlation space using the inverse of the Fisher $z$-transform, which is the hyperbolic tangent function:\n    $$r_{\\mathrm{cv}} = \\tanh(\\bar{z})$$\n    This final value, $r_{\\mathrm{cv}}$, is the cross-validated similarity score between the model and neural representational geometries.\n\n**Application to Scenarios**\n\nThe above procedures are applied to the four scenarios defined in the problem.\n\n*   **Scenario 1:** Model-motion vs. MT. The inputs are $M_{\\mathrm{motion}}^{A}$, $M_{\\mathrm{motion}}^{B}$, $N_{\\mathrm{MT}}^{1}$, and $N_{\\mathrm{MT}}^{2}$. All are $5 \\times 4$ matrices. The RDM vectors will each have $5(4)/2 = 10$ elements. The calculation yields $r_{\\mathrm{cv}} \\approx 0.999690$.\n\n*   **Scenario 2:** Model-form vs. IT. The inputs are $M_{\\mathrm{form}}^{A}$, $M_{\\mathrm{form}}^{B}$, $N_{\\mathrm{IT}}^{1}$, and $N_{\\mathrm{IT}}^{2}$. All are $5 \\times 4$ matrices. The RDM vectors will each have $10$ elements. The calculation yields $r_{\\mathrm{cv}} \\approx 0.992225$.\n\n*   **Scenario 3:** Cross-stream mismatch control (Model-motion vs. IT). This scenario serves as a specificity control, testing whether a model of motion processing aligns better with a motion-related brain area (MT) than with a form-related area (IT). The inputs are $M_{\\mathrm{motion}}^{A}$, $M_{\\mathrm{motion}}^{B}$ from Scenario $1$ and $N_{\\mathrm{IT}}^{1}$, $N_{\\mathrm{IT}}^{2}$ from Scenario $2$. The calculation yields $r_{\\mathrm{cv}} \\approx 0.088383$. As expected, this mismatched correlation is substantially lower than the matched correlations in Scenarios $1$ and $2$.\n\n*   **Scenario 4:** Boundary case. Here, all four input matrices are identical: $M^{A} = M^{B} = N^{1} = N^{2} = R$. $R$ is a $4 \\times 3$ matrix.\n    *   Since all input matrices are identical, all four RDM vectors will be identical: $v(M^A) = v(M^B) = v(N^1) = v(N^2) = v(R)$.\n    *   The cross-correlations will be $r_1 = \\mathrm{corr}(v(R), v(R)) = 1$ and $r_2 = \\mathrm{corr}(v(R), v(R)) = 1$, provided the vector $v(R)$ is not constant (which it is not for the given matrix $R$).\n    *   The Fisher $z$-transform of $r=1$ is $z(1) = \\mathrm{arctanh}(1) = \\infty$.\n    *   The average is $\\bar{z} = (\\infty + \\infty)/2 = \\infty$.\n    *   The final result is $r_{\\mathrm{cv}} = \\tanh(\\infty) = 1$.\n    This calculation confirms the logic for boundary conditions and provides a sanity check on the implementation. The result is exactly $1.0$.\n\nThe implementation will systematically apply these steps to the provided data matrices to compute the final four values.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_rdm_vector(response_matrix: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Computes the vectorized upper-triangular of the Representational Dissimilarity Matrix (RDM).\n\n    Args:\n        response_matrix: An n x p numpy array where n is the number of stimuli\n                         and p is the number of units.\n\n    Returns:\n        A 1D numpy array of length n(n-1)/2 representing the vectorized RDM.\n    \"\"\"\n    # Step 1: Compute the n x n matrix of Pearson correlations between rows.\n    # np.corrcoef with default rowvar=True computes correlation between rows.\n    # If a row is constant, its std dev is 0, leading to NaNs in corrcoef.\n    # The problem data avoids this.\n    corr_matrix = np.corrcoef(response_matrix)\n\n    # Step 2: Convert to a dissimilarity matrix (RDM)\n    dissimilarity_matrix = 1.0 - corr_matrix\n\n    # Step 3: Vectorize the upper-triangular part (excluding the diagonal, k=1)\n    n = response_matrix.shape[0]\n    upper_triangle_indices = np.triu_indices(n, k=1)\n    rdm_vector = dissimilarity_matrix[upper_triangle_indices]\n\n    return rdm_vector\n\ndef compute_r_cv(M_A: np.ndarray, M_B: np.ndarray, N_1: np.ndarray, N_2: np.ndarray) -> float:\n    \"\"\"\n    Computes the cross-validated Pearson correlation between model and neural RDMs.\n\n    Args:\n        M_A: Model response matrix, split A.\n        M_B: Model response matrix, split B.\n        N_1: Neural response matrix, split 1.\n        N_2: Neural response matrix, split 2.\n\n    Returns:\n        The cross-validated correlation coefficient, r_cv.\n    \"\"\"\n    # Step 1: Compute the four RDM vectors\n    v_M_A = compute_rdm_vector(M_A)\n    v_M_B = compute_rdm_vector(M_B)\n    v_N_1 = compute_rdm_vector(N_1)\n    v_N_2 = compute_rdm_vector(N_2)\n\n    # Step 2: Compute the two cross-correlations\n    # np.corrcoef returns a 2x2 matrix, the value is at [0, 1] or [1, 0]\n    r1 = np.corrcoef(v_M_A, v_N_2)[0, 1]\n    r2 = np.corrcoef(v_M_B, v_N_1)[0, 1]\n\n    # Step 3: Average correlations using Fisher z-transform\n    # numpy.arctanh is the Fisher z-transform. It handles r = +/- 1 by returning +/- inf.\n    z1 = np.arctanh(r1)\n    z2 = np.arctanh(r2)\n    avg_z = (z1 + z2) / 2.0\n\n    # Step 4: Inverse transform to get the final r_cv\n    # numpy.tanh is the inverse of the Fisher z-transform.\n    r_cv = np.tanh(avg_z)\n    \n    return r_cv\n\ndef solve():\n    \"\"\"\n    Main function to run all scenarios and print the final results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Scenario 1 Data\n    M_motion_A = np.array([\n        [2.0, 2.0, 0.1, 0.0],\n        [1.9, 2.1, 0.0, 0.2],\n        [0.2, 0.0, 2.1, 2.0],\n        [0.0, 0.1, 1.9, 2.2],\n        [0.1, 0.2, 2.0, 2.1]\n    ])\n    M_motion_B = np.array([\n        [2.1, 1.9, 0.0, 0.1],\n        [2.0, 2.0, 0.1, 0.1],\n        [0.1, 0.0, 2.0, 2.2],\n        [0.0, 0.2, 2.2, 1.9],\n        [0.2, 0.1, 2.1, 2.0]\n    ])\n    N_MT_1 = np.array([\n        [2.2, 2.1, 0.0, 0.1],\n        [1.8, 2.0, 0.1, 0.1],\n        [0.0, 0.1, 2.2, 2.1],\n        [0.1, 0.0, 1.8, 2.0],\n        [0.1, 0.2, 2.1, 2.2]\n    ])\n    N_MT_2 = np.array([\n        [2.0, 2.2, 0.1, 0.0],\n        [2.1, 1.9, 0.0, 0.2],\n        [0.2, 0.0, 2.0, 2.1],\n        [0.0, 0.1, 2.2, 1.8],\n        [0.1, 0.2, 2.0, 2.3]\n    ])\n\n    # Scenario 2 Data\n    M_form_A = np.array([\n        [2.0, 2.0, 0.1, 0.0],\n        [0.1, 0.0, 2.0, 2.0],\n        [2.1, 1.9, 0.0, 0.1],\n        [0.0, 0.1, 2.1, 1.9],\n        [1.0, 1.1, 0.9, 1.0]\n    ])\n    M_form_B = np.array([\n        [2.1, 1.9, 0.0, 0.1],\n        [0.0, 0.1, 2.1, 1.9],\n        [1.9, 2.1, 0.1, 0.0],\n        [0.1, 0.0, 1.9, 2.1],\n        [1.1, 1.0, 1.0, 0.9]\n    ])\n    N_IT_1 = np.array([\n        [2.2, 2.1, 0.0, 0.1],\n        [0.0, 0.1, 2.0, 2.1],\n        [1.8, 2.0, 0.1, 0.0],\n        [0.1, 0.0, 1.9, 2.0],\n        [1.1, 1.0, 0.9, 1.0]\n    ])\n    N_IT_2 = np.array([\n        [2.0, 2.2, 0.1, 0.0],\n        [0.1, 0.0, 2.2, 1.8],\n        [2.1, 1.9, 0.0, 0.2],\n        [0.0, 0.2, 1.8, 2.2],\n        [0.9, 1.0, 1.1, 1.0]\n    ])\n\n    # Scenario 4 Data\n    R = np.array([\n        [0.0, 1.0, 2.0],\n        [0.5, 1.0, 1.5],\n        [2.0, 1.0, 0.0],\n        [1.5, 1.0, 0.5]\n    ])\n\n    # Execute all scenarios\n    r_cv1 = compute_r_cv(M_motion_A, M_motion_B, N_MT_1, N_MT_2)\n    r_cv2 = compute_r_cv(M_form_A, M_form_B, N_IT_1, N_IT_2)\n    r_cv3 = compute_r_cv(M_motion_A, M_motion_B, N_IT_1, N_IT_2)\n    r_cv4 = compute_r_cv(R, R, R, R)\n\n    results = [r_cv1, r_cv2, r_cv3, r_cv4]\n\n    # Format and print the final output as specified.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "5013737"}]}