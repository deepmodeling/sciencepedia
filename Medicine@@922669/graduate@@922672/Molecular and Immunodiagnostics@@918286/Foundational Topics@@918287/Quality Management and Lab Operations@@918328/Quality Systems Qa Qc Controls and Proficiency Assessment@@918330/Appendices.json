{"hands_on_practices": [{"introduction": "A robust quality system moves beyond implementing arbitrary control rules to designing a QC strategy that is quantitatively matched to an assay's performance. This practice introduces the concept of the sigma metric, $\\sigma = (\\mathrm{TEa} - |\\mathrm{bias}|)/\\mathrm{SD}$, as a powerful indicator of assay capability. You will use this metric to model and compare the performance of different QC rules, calculating their respective probabilities of error detection ($P_{ed}$) and false rejection ($P_{fr}$), and ultimately determine a rational, evidence-based QC frequency that appropriately balances risk and operational efficiency [@problem_id:5153046].", "problem": "A clinical molecular assay performing real-time polymerase chain reaction (PCR) for viral load quantification is operated under a Quality Systems framework encompassing Quality Assurance (QA) and Quality Control (QC). The laboratory seeks to determine the QC frequency and evaluate the operating characteristics of candidate QC rules using the assay’s sigma metric. The sigma metric is defined by Total Allowable Error (TEa), bias, and imprecision as $\\sigma = \\frac{\\mathrm{TEa} - |\\mathrm{bias}|}{\\mathrm{SD}}$. For the purpose of assessing QC rule performance, assume a “critical systematic shift” in the measurement process equal to $\\delta = \\sigma$ standard deviations, where $\\sigma$ is the assay sigma metric.\n\nThe laboratory runs $N = 240$ patient samples per day. Consider two single-rule QC procedures applied to standardized control measurements:\n\n- The $1_{3s}$ rule: One control measurement per QC event; the rule signals when a single standardized control value exceeds the interval $[-3, 3]$.\n- The $2_{2s}$ rule: Two independent control measurements per QC event (e.g., one at low level and one at high level); the rule signals when both controls exceed $+2$ or both are below $-2$ in the same direction.\n\nModel each standardized control measurement $X$ as Gaussian $X \\sim \\mathcal{N}(\\delta, 1)$ after appropriate normalization. Let $\\Phi(\\cdot)$ denote the standard normal cumulative distribution function. Define the probability of false rejection (no underlying shift), $P_{fr}$, for each rule as the probability that the rule signals when $\\delta = 0$. Define the probability of error detection (under the critical systematic shift), $P_{ed}$, for each rule as the probability that the rule signals when $\\delta = \\sigma$. The assay sigma metric for this evaluation is $\\sigma = 4.0$.\n\nUnder the assumption that QC events are independent across the run, the probability of detecting the critical systematic shift at least once in a run with $k$ QC events is $1 - (1 - P_{ed})^{k}$. The laboratory requires a minimum detection probability of $0.95$ over the run. The recommended QC frequency for a rule is the minimal integer $k$ satisfying $1 - (1 - P_{ed})^{k} \\geq 0.95$, together with a corresponding sample spacing of $\\frac{N}{k}$ patient samples per QC event.\n\nUsing only the above definitions and assumptions, compute for each rule ($1_{3s}$ and $2_{2s}$):\n1. The minimal integer $k$ meeting the detection probability requirement $1 - (1 - P_{ed})^{k} \\geq 0.95$.\n2. The sample spacing $\\frac{N}{k}$.\n3. $P_{fr}$ with $\\delta = 0$.\n4. $P_{ed}$ with $\\delta = \\sigma = 4.0$.\n\nExpress $P_{fr}$ and $P_{ed}$ as decimals, rounded to five significant figures. The values of $k$ and $\\frac{N}{k}$ must be integers. Report your final results in the following order as an eight-entry row matrix:\n$$\\big(k_{1_{3s}}, \\tfrac{N}{k_{1_{3s}}}, P_{fr,1_{3s}}, P_{ed,1_{3s}}, k_{2_{2s}}, \\tfrac{N}{k_{2_{2s}}}, P_{fr,2_{2s}}, P_{ed,2_{2s}}\\big).$$\nAll probabilities must be expressed as pure decimals (no percentage sign). The integers have implicit units of “events” and “samples per event,” respectively.", "solution": "The problem requires the calculation of key performance characteristics for two different Quality Control (QC) rules, denoted $1_{3s}$ and $2_{2s}$, applied to a real-time PCR assay. The required outputs are the minimal QC frequency ($k$), the corresponding sample spacing ($\\frac{N}{k}$), the probability of false rejection ($P_{fr}$), and the probability of error detection ($P_{ed}$). All calculations are based on the provided assay sigma metric of $\\sigma = 4.0$.\n\nA standardized control measurement $X$ is modeled as a Gaussian random variable $X \\sim \\mathcal{N}(\\delta, 1)$, where $\\delta$ represents a systematic shift in standard deviation units.\nThe probability of false rejection, $P_{fr}$, is the probability that a rule signals an error when no shift is present, i.e., when $\\delta = 0$. In this case, $X \\sim \\mathcal{N}(0, 1)$.\nThe probability of error detection, $P_{ed}$, is the probability that a rule signals an error in the presence of a critical systematic shift, defined as $\\delta = \\sigma = 4.0$. In this case, $X \\sim \\mathcal{N}(4, 1)$.\n\nThe standard normal cumulative distribution function (CDF) is denoted by $\\Phi(z) = P(Z \\le z)$ for $Z \\sim \\mathcal{N}(0, 1)$.\n\nThe minimal QC frequency, $k$, is the smallest integer that satisfies the detection probability requirement $1 - (1 - P_{ed})^{k} \\ge 0.95$ and is also a divisor of the total number of patient samples, $N = 240$, ensuring the sample spacing $\\frac{N}{k}$ is an integer. The inequality can be rearranged to solve for $k$:\n$$ (1 - P_{ed})^{k} \\le 0.05 $$\n$$ k \\ln(1 - P_{ed}) \\le \\ln(0.05) $$\nSince $1 - P_{ed}  1$, its logarithm is negative. Dividing by a negative number reverses the inequality:\n$$ k \\ge \\frac{\\ln(0.05)}{\\ln(1 - P_{ed})} $$\nLet $k_{\\mathrm{min}} = \\frac{\\ln(0.05)}{\\ln(1 - P_{ed})}$. We must find the smallest integer $k$ such that $k \\ge k_{\\mathrm{min}}$ and $240 \\pmod k = 0$.\n\nWe will now perform these calculations for each rule.\n\n### Analysis of the $1_{3s}$ Rule\n\nThis rule uses one control measurement, $X$, and signals if the value falls outside the interval $[-3, 3]$, i.e., $|X|  3$.\n\n**1. Probability of False Rejection ($P_{fr, 1_{3s}}$)**\nFor $P_{fr}$, we set $\\delta = 0$, so $X \\sim \\mathcal{N}(0, 1)$.\n$$ P_{fr, 1_{3s}} = P(|X|  3) = P(X  -3) + P(X  3) $$\nBy the symmetry of the standard normal distribution, $P(X  -3) = P(X  3) = 1 - \\Phi(3)$.\n$$ P_{fr, 1_{3s}} = 2(1 - \\Phi(3)) $$\nUsing the standard value $\\Phi(3) \\approx 0.9986501$:\n$$ P_{fr, 1_{3s}} = 2(1 - 0.9986501) = 2(0.0013499) = 0.0026998 $$\nRounded to five significant figures, $P_{fr, 1_{3s}} = 0.0026998$.\n\n**2. Probability of Error Detection ($P_{ed, 1_{3s}}$)**\nFor $P_{ed}$, we set $\\delta = \\sigma = 4.0$, so $X \\sim \\mathcal{N}(4, 1)$. We standardize the variable by letting $Z = X - 4$, where $Z \\sim \\mathcal{N}(0, 1)$.\n$$ P_{ed, 1_{3s}} = P(|X|  3) = P(X  -3) + P(X  3) $$\nThe event $X  -3$ corresponds to $Z  -3 - 4 = -7$.\nThe event $X  3$ corresponds to $Z  3 - 4 = -1$.\n$$ P_{ed, 1_{3s}} = P(Z  -7) + P(Z  -1) = \\Phi(-7) + (1 - \\Phi(-1)) $$\nUsing the property $\\Phi(-z) = 1 - \\Phi(z)$, this becomes:\n$$ P_{ed, 1_{3s}} = \\Phi(-7) + \\Phi(1) $$\nUsing standard values $\\Phi(1) \\approx 0.8413447$ and $\\Phi(-7) \\approx 1.28 \\times 10^{-12}$.\n$$ P_{ed, 1_{3s}} \\approx 1.28 \\times 10^{-12} + 0.8413447 \\approx 0.8413447 $$\nRounded to five significant figures, $P_{ed, 1_{3s}} = 0.84134$.\n\n**3. Minimal QC Frequency ($k_{1_{3s}}$) and Sample Spacing**\nWe calculate the minimum required $k$:\n$$ k_{\\mathrm{min}} = \\frac{\\ln(0.05)}{\\ln(1 - 0.84134)} = \\frac{\\ln(0.05)}{\\ln(0.15866)} \\approx \\frac{-2.99573}{-1.84096} \\approx 1.627 $$\nWe need the smallest integer $k \\ge 1.627$ that is a divisor of $N=240$. The divisors of $240$ include $1, 2, 3, 4, \\dots$. The smallest divisor greater than or equal to $1.627$ is $2$.\nTherefore, $k_{1_{3s}} = 2$.\nThe sample spacing is $\\frac{N}{k_{1_{3s}}} = \\frac{240}{2} = 120$.\n\n### Analysis of the $2_{2s}$ Rule\n\nThis rule uses two independent control measurements, $X_1$ and $X_2$, and signals if both are above $+2$ or both are below $-2$.\n\n**1. Probability of False Rejection ($P_{fr, 2_{2s}}$)**\nFor $P_{fr}$, we set $\\delta = 0$, so $X_1, X_2 \\sim \\mathcal{N}(0, 1)$ are independent and identically distributed.\n$$ P_{fr, 2_{2s}} = P((X_1  2 \\text{ and } X_2  2) \\text{ or } (X_1  -2 \\text{ and } X_2  -2)) $$\nSince the two events are disjoint and the measurements are independent:\n$$ P_{fr, 2_{2s}} = P(X_1  2)P(X_2  2) + P(X_1  -2)P(X_2  -2) $$\n$$ P_{fr, 2_{2s}} = (P(X  2))^2 + (P(X  -2))^2 $$\nFor $X \\sim \\mathcal{N}(0, 1)$, $P(X  2) = 1 - \\Phi(2)$ and $P(X  -2) = \\Phi(-2) = 1 - \\Phi(2)$.\n$$ P_{fr, 2_{2s}} = (1 - \\Phi(2))^2 + (1 - \\Phi(2))^2 = 2(1 - \\Phi(2))^2 $$\nUsing $\\Phi(2) \\approx 0.977250$:\n$$ P_{fr, 2_{2s}} = 2(1 - 0.977250)^2 = 2(0.022750)^2 \\approx 2(0.00051756) \\approx 0.00103512 $$\nRounded to five significant figures, $P_{fr, 2_{2s}} = 0.0010351$.\n\n**2. Probability of Error Detection ($P_{ed, 2_{2s}}$)**\nFor $P_{ed}$, we set $\\delta = \\sigma = 4.0$, so $X_1, X_2 \\sim \\mathcal{N}(4, 1)$ are i.i.d.\n$$ P_{ed, 2_{2s}} = (P(X  2))^2 + (P(X  -2))^2 \\quad \\text{where } X \\sim \\mathcal{N}(4, 1) $$\nWe standardize the variable by letting $Z = X - 4$, where $Z \\sim \\mathcal{N}(0, 1)$.\n$P(X  2) = P(Z  2 - 4) = P(Z  -2) = 1 - \\Phi(-2) = \\Phi(2)$.\n$P(X  -2) = P(Z  -2 - 4) = P(Z  -6) = \\Phi(-6)$.\n$$ P_{ed, 2_{2s}} = (\\Phi(2))^2 + (\\Phi(-6))^2 $$\nUsing standard values $\\Phi(2) \\approx 0.977250$ and $\\Phi(-6) \\approx 9.87 \\times 10^{-10}$.\n$$ P_{ed, 2_{2s}} \\approx (0.977250)^2 + (9.87 \\times 10^{-10})^2 \\approx 0.955017 + 9.74 \\times 10^{-19} \\approx 0.955017 $$\nRounded to five significant figures, $P_{ed, 2_{2s}} = 0.95502$.\n\n**3. Minimal QC Frequency ($k_{2_{2s}}$) and Sample Spacing**\nWe calculate the minimum required $k$:\n$$ k_{\\mathrm{min}} = \\frac{\\ln(0.05)}{\\ln(1 - 0.95502)} = \\frac{\\ln(0.05)}{\\ln(0.04498)} \\approx \\frac{-2.99573}{-3.10153} \\approx 0.9659 $$\nWe need the smallest integer $k \\ge 0.9659$ that is a divisor of $N=240$. The smallest such integer is $1$.\nTherefore, $k_{2_{2s}} = 1$.\nThe sample spacing is $\\frac{N}{k_{2_{2s}}} = \\frac{240}{1} = 240$.\n\n### Summary of Results\nThe computed values for each rule are:\nFor the $1_{3s}$ rule: $k_{1_{3s}} = 2$, sample spacing = $120$, $P_{fr, 1_{3s}} = 0.0026998$, $P_{ed, 1_{3s}} = 0.84134$.\nFor the $2_{2s}$ rule: $k_{2_{2s}} = 1$, sample spacing = $240$, $P_{fr, 2_{2s}} = 0.0010351$, $P_{ed, 2_{2s}} = 0.95502$.\n\nThese results are combined into the specified eight-entry row matrix for the final answer.\n$$ \\begin{pmatrix} k_{1_{3s}}  \\frac{N}{k_{1_{3s}}}  P_{fr, 1_{3s}}  P_{ed, 1_{3s}}  k_{2_{2s}}  \\frac{N}{k_{2_{2s}}}  P_{fr, 2_{2s}}  P_{ed, 2_{2s}} \\end{pmatrix} $$\n$$ \\begin{pmatrix} 2  120  0.0026998  0.84134  1  240  0.0010351  0.95502 \\end{pmatrix} $$", "answer": "$$ \\boxed{\\begin{pmatrix} 2  120  0.0026998  0.84134  1  240  0.0010351  0.95502 \\end{pmatrix}} $$", "id": "5153046"}, {"introduction": "Interpreting a Quality Control signal requires careful judgment, as a rule violation is evidence, not definitive proof, of an out-of-control state. This exercise introduces a sophisticated, probabilistic approach to QC troubleshooting using Bayes' theorem. You will learn to formally update your assessment of an assay's status by combining prior knowledge of its reliability with the specific evidence from observed QC data, calculating a posterior probability of a true system shift, $\\Pr(S=1 | \\text{data})$, to guide decisions on corrective action [@problem_id:5153011].", "problem": "A clinical laboratory operates an automated immunoassay analyzer performing a high-sensitivity Thyroid Stimulating Hormone (TSH) assay. The laboratory’s Quality Assurance (QA) program uses a Westgard multi-rule scheme to interpret daily Quality Control (QC) data, and its proficiency assessment program has characterized the analyzer’s reliability over time. Consider a binary latent state $S \\in \\{0,1\\}$, where $S=1$ denotes that a sustained positive bias of $+2$ standard deviations has been present throughout a two-run period (a clinically significant assay shift), and $S=0$ denotes no such sustained shift.\n\nFrom longitudinal Internal Quality Control (IQC) characterization and External Quality Assessment (EQA) outcomes, the laboratory has established the following:\n\n- Prior probability of a sustained $+2$ standard deviation shift over the two-run period: $\\Pr(S=1) = 0.001$ and $\\Pr(S=0) = 1 - 0.001$.\n- Per-run probabilities for three Westgard rule violations under $S=0$ (in-control):\n  - One $1_{3s}$ violation indicator $A$: $\\Pr(A=1 \\mid S=0) = 0.0027$.\n  - One $2_{2s}$ violation indicator $B$: $\\Pr(B=1 \\mid S=0) = 0.00104$.\n  - One $R_{4s}$ violation indicator $C$: $\\Pr(C=1 \\mid S=0) = 0.00104$.\n- Per-run probabilities for the same rule violations under $S=1$ (sustained $+2$ standard deviation shift):\n  - $\\Pr(A=1 \\mid S=1) = 0.1587$.\n  - $\\Pr(B=1 \\mid S=1) = 0.25$.\n  - $\\Pr(C=1 \\mid S=1) = 0.00104$.\n\nAssume the following measurement model consistent with quality system practice:\n- The shift state $S$ persists (if present) over both consecutive daily runs.\n- Conditional on $S$, violation indicators for different rules within the same run and across runs are independent and identically distributed according to the probabilities specified above.\n\nOver two consecutive daily runs, the laboratory observed this pattern of rule outcomes:\n- Run $1$: $A=1$, $B=0$, $C=0$.\n- Run $2$: $A=0$, $B=1$, $C=1$.\n\nUsing Bayes’ theorem and the independence model stated, compute the posterior probability $\\Pr(S=1 \\mid \\text{data})$ that a sustained assay shift is present given the observed QC rule violations. Express your answer as a decimal. Round your answer to four significant figures. Based on the quality plan, immediate escalation (holding all patient testing and initiating full recalibration) is required when $\\Pr(S=1 \\mid \\text{data}) \\ge \\tau$ with $\\tau = 0.25$; you may comment on this decision in your reasoning, but the numerical answer requested is only $\\Pr(S=1 \\mid \\text{data})$.", "solution": "The objective is to compute the posterior probability of a sustained assay shift, $\\Pr(S=1 \\mid \\text{data})$, given the observed Quality Control (QC) data from two consecutive runs. This is a direct application of Bayes' theorem.\n\nLet $S$ be the latent state variable, where $S=1$ indicates a sustained shift and $S=0$ indicates an in-control state.\nThe observed data, $D$, consists of the outcomes from two runs.\nLet $D_1$ represent the data from run 1: one $1_{3s}$ violation ($A_1=1$), no $2_{2s}$ violation ($B_1=0$), and no $R_{4s}$ violation ($C_1=0$).\nLet $D_2$ represent the data from run 2: no $1_{3s}$ violation ($A_2=0$), one $2_{2s}$ violation ($B_2=1$), and one $R_{4s}$ violation ($C_2=1$).\nThus, the total data is $D = \\{D_1, D_2\\} = \\{A_1=1, B_1=0, C_1=0, A_2=0, B_2=1, C_2=1\\}$.\n\nBayes' theorem states:\n$$ \\Pr(S=1 \\mid D) = \\frac{\\Pr(D \\mid S=1) \\Pr(S=1)}{\\Pr(D)} $$\nThe denominator, $\\Pr(D)$, is the total probability of observing the data, which can be expanded using the law of total probability:\n$$ \\Pr(D) = \\Pr(D \\mid S=1) \\Pr(S=1) + \\Pr(D \\mid S=0) \\Pr(S=0) $$\nSubstituting this into Bayes' theorem gives:\n$$ \\Pr(S=1 \\mid D) = \\frac{\\Pr(D \\mid S=1) \\Pr(S=1)}{\\Pr(D \\mid S=1) \\Pr(S=1) + \\Pr(D \\mid S=0) \\Pr(S=0)} $$\n\nThe problem states that, conditional on the state $S$, the QC rule violations are independent across runs and within runs. This allows us to calculate the likelihoods $\\Pr(D \\mid S=1)$ and $\\Pr(D \\mid S=0)$.\n\nFirst, we calculate the likelihood of the data given a sustained shift, $\\Pr(D \\mid S=1)$, which we denote $L_1$:\n$$ L_1 = \\Pr(D \\mid S=1) = \\Pr(D_1 \\mid S=1) \\times \\Pr(D_2 \\mid S=1) $$\n$$ L_1 = \\left[ \\Pr(A_1=1 \\mid S=1) \\Pr(B_1=0 \\mid S=1) \\Pr(C_1=0 \\mid S=1) \\right] \\times \\left[ \\Pr(A_2=0 \\mid S=1) \\Pr(B_2=1 \\mid S=1) \\Pr(C_2=1 \\mid S=1) \\right] $$\nWe use the provided probabilities and note that $\\Pr(\\text{event}=0 \\mid S) = 1 - \\Pr(\\text{event}=1 \\mid S)$.\nThe probabilities for $S=1$ are:\n- $\\Pr(A=1 \\mid S=1) = 0.1587 \\implies \\Pr(A=0 \\mid S=1) = 1 - 0.1587 = 0.8413$\n- $\\Pr(B=1 \\mid S=1) = 0.25 \\implies \\Pr(B=0 \\mid S=1) = 1 - 0.25 = 0.75$\n- $\\Pr(C=1 \\mid S=1) = 0.00104 \\implies \\Pr(C=0 \\mid S=1) = 1 - 0.00104 = 0.99896$\n\nSubstituting these values into the expression for $L_1$:\n$$ L_1 = (0.1587 \\times 0.75 \\times 0.99896) \\times (0.8413 \\times 0.25 \\times 0.00104) $$\n$$ L_1 \\approx (0.11889813) \\times (0.000218738) \\approx 2.600904 \\times 10^{-5} $$\n\nNext, we calculate the likelihood of the data given the in-control state, $\\Pr(D \\mid S=0)$, which we denote $L_0$:\n$$ L_0 = \\Pr(D \\mid S=0) = \\Pr(D_1 \\mid S=0) \\times \\Pr(D_2 \\mid S=0) $$\n$$ L_0 = \\left[ \\Pr(A_1=1 \\mid S=0) \\Pr(B_1=0 \\mid S=0) \\Pr(C_1=0 \\mid S=0) \\right] \\times \\left[ \\Pr(A_2=0 \\mid S=0) \\Pr(B_2=1 \\mid S=0) \\Pr(C_2=1 \\mid S=0) \\right] $$\nThe probabilities for $S=0$ are:\n- $\\Pr(A=1 \\mid S=0) = 0.0027 \\implies \\Pr(A=0 \\mid S=0) = 1 - 0.0027 = 0.9973$\n- $\\Pr(B=1 \\mid S=0) = 0.00104 \\implies \\Pr(B=0 \\mid S=0) = 1 - 0.00104 = 0.99896$\n- $\\Pr(C=1 \\mid S=0) = 0.00104 \\implies \\Pr(C=0 \\mid S=0) = 1 - 0.00104 = 0.99896$\n\nSubstituting these values into the expression for $L_0$:\n$$ L_0 = (0.0027 \\times 0.99896 \\times 0.99896) \\times (0.9973 \\times 0.00104 \\times 0.00104) $$\n$$ L_0 \\approx (0.002694406) \\times (1.07910184 \\times 10^{-6}) \\approx 2.90760 \\times 10^{-9} $$\n\nWe are given the prior probabilities:\n- $\\Pr(S=1) = 0.001$\n- $\\Pr(S=0) = 1 - 0.001 = 0.999$\n\nNow we can compute the terms for Bayes' theorem:\nThe numerator is $\\Pr(D \\mid S=1) \\Pr(S=1) = L_1 \\times \\Pr(S=1)$:\n$$ L_1 \\Pr(S=1) = (2.600904 \\times 10^{-5}) \\times 0.001 = 2.600904 \\times 10^{-8} $$\nThe second term in the denominator is $\\Pr(D \\mid S=0) \\Pr(S=0) = L_0 \\times \\Pr(S=0)$:\n$$ L_0 \\Pr(S=0) = (2.90760 \\times 10^{-9}) \\times 0.999 = 2.9046924 \\times 10^{-9} $$\nThe total denominator is the sum of these two terms:\n$$ \\Pr(D) = (2.600904 \\times 10^{-8}) + (2.9046924 \\times 10^{-9}) = 2.89137324 \\times 10^{-8} $$\nFinally, we compute the posterior probability:\n$$ \\Pr(S=1 \\mid D) = \\frac{2.600904 \\times 10^{-8}}{2.89137324 \\times 10^{-8}} \\approx 0.8995537 $$\n\nThe problem asks to round the answer to four significant figures.\n$$ \\Pr(S=1 \\mid D) \\approx 0.8996 $$\nThis posterior probability of approximately $90\\%$ is significantly higher than the initial prior probability of $0.1\\%$. The observed QC violations provide strong evidence in favor of the hypothesis that a sustained shift has occurred.\nThe quality plan requires escalation if this probability is greater than or equal to a threshold $\\tau = 0.25$. Since $0.8996  0.25$, the observed data strongly justifies holding patient results and initiating a full recalibration of the analyzer, as per the laboratory's protocol.", "answer": "$$\n\\boxed{0.8996}\n$$", "id": "5153011"}, {"introduction": "The ultimate output of a quality system is a patient result accompanied by a statement of its reliability. This practice explores the formal process of estimating measurement uncertainty, a cornerstone of laboratory accreditation standards like ISO 15189. You will construct a comprehensive uncertainty budget, systematically identifying, quantifying, and propagating all significant sources of variation—from calibration and reagent preparation to instrumental imprecision—to compute a combined and expanded uncertainty ($U$) for a final result, providing a scientifically rigorous expression of its quality [@problem_id:5153028].", "problem": "A clinical laboratory accredited under International Organization for Standardization 15189 (ISO 15189) is implementing a measurement uncertainty estimate for a cytokine concentration determined by Enzyme-Linked Immunosorbent Assay (ELISA). To satisfy Quality Assurance (QA), Quality Control (QC), and proficiency assessment requirements, you will construct an uncertainty budget and compute the expanded uncertainty for a single patient sample measurement.\n\nThe reporting model for the ELISA is a linear calibration of absorbance on concentration. The measurand (reported concentration) is defined by the functional relationship\n$$\nC = \\frac{D\\,(A - b)}{m},\n$$\nwhere $C$ is the concentration in $\\mathrm{ng\\,mL^{-1}}$, $A$ is the mean sample absorbance, $m$ is the calibration slope (absorbance per $\\mathrm{ng\\,mL^{-1}}$), $b$ is the calibration intercept (absorbance), and $D$ is the dilution factor of the prepared specimen. The following empirically established inputs and their associated uncertainties are available from the laboratory’s method validation and instrument specifications. Use only these inputs and no others.\n\n- Sample mean absorbance: $A = 1.250$ from $n = 6$ wells with within-plate standard deviation $s_{A} = 0.010$. Treat this as a Type A evaluation with degrees of freedom $\\nu_{A} = n - 1$.\n- Calibration slope: $m = 0.0300\\ \\mathrm{A}\\,(\\mathrm{ng\\,mL^{-1}})^{-1}$ with standard uncertainty $u(m) = 0.0007\\ \\mathrm{A}\\,(\\mathrm{ng\\,mL^{-1}})^{-1}$ obtained from a linear regression; degrees of freedom $\\nu_{m} = 4$.\n- Calibration intercept: $b = 0.0500\\ \\mathrm{A}$ with standard uncertainty $u(b) = 0.0080\\ \\mathrm{A}$ obtained from the same regression; degrees of freedom $\\nu_{b} = 4$.\n- Dilution factor: The specimen was prepared by mixing $V_{s} = 100\\ \\mu\\mathrm{L}$ of sample with $V_{b} = 900\\ \\mu\\mathrm{L}$ of diluent to achieve a target $D = \\frac{V_{s} + V_{b}}{V_{s}}$. The pipettes used have manufacturer-stated expanded uncertainties (coverage factor $k = 2$): for $V_{s}$, $\\pm 1.0\\ \\mu\\mathrm{L}$; for $V_{b}$, $\\pm 3.0\\ \\mu\\mathrm{L}$. Treat these as Type B normal-distribution specifications with standard uncertainties $u(V_{s})$ and $u(V_{b})$ equal to the expanded uncertainties divided by $2$, and with effectively infinite degrees of freedom.\n\nTasks:\n1. Construct an uncertainty budget by identifying each input quantity $x_{i} \\in \\{A, m, b, D\\}$, its estimate, its standard uncertainty $u(x_{i})$, the corresponding sensitivity coefficient $c_{i} = \\frac{\\partial C}{\\partial x_{i}}$ evaluated at the estimates, and its variance contribution $w_{i} = \\left(c_{i}\\,u(x_{i})\\right)^{2}$.\n2. Combine the contributions according to the Guide to the Expression of Uncertainty in Measurement (GUM) to obtain the combined standard uncertainty $u_{c}(C)$.\n3. Compute the effective degrees of freedom $\\nu_{\\mathrm{eff}}$ using the Welch–Satterthwaite formula based on the $w_{i}$ and their associated degrees of freedom.\n4. Using a two-sided $95\\%$ coverage, select the coverage factor $k$ as the Student’s $t$ quantile at probability $0.975$ with $\\nu_{\\mathrm{eff}}$ degrees of freedom, and calculate the expanded uncertainty $U = k\\,u_{c}(C)$.\n\nAssume that all input quantities are uncorrelated. Express the final expanded uncertainty $U$ in $\\mathrm{ng\\,mL^{-1}}$ and round your answer to four significant figures. The final answer must be a single real number as specified.", "solution": "The objective is to compute the expanded uncertainty, $U$, for a cytokine concentration, $C$, determined by an Enzyme-Linked Immunosorbent Assay (ELISA). The process follows the principles outlined in the Guide to the Expression of Uncertainty in Measurement (GUM).\n\nThe measurand, $C$, is defined by the functional relationship:\n$$\nC = \\frac{D\\,(A - b)}{m}\n$$\nwhere $A$ is the mean sample absorbance, $m$ is the calibration slope, $b$ is the calibration intercept, and $D$ is the dilution factor.\n\nFirst, the nominal value of the concentration $C$ is calculated using the provided estimates for the input quantities. The dilution factor $D$ is determined by the sample volume $V_s = 100\\ \\mu\\mathrm{L}$ and diluent volume $V_b = 900\\ \\mu\\mathrm{L}$:\n$$\nD = \\frac{V_s + V_b}{V_s} = \\frac{100\\ \\mu\\mathrm{L} + 900\\ \\mu\\mathrm{L}}{100\\ \\mu\\mathrm{L}} = \\frac{1000}{100} = 10\n$$\nWith $A = 1.250$, $b = 0.0500$, $m = 0.0300$, and $D=10$, the concentration is:\n$$\nC = \\frac{10 \\times (1.250 - 0.0500)}{0.0300} = \\frac{10 \\times 1.200}{0.0300} = \\frac{12}{0.0300} = 400\\ \\mathrm{ng\\,mL^{-1}}\n$$\n\nNext, we evaluate the standard uncertainty $u(x_i)$ and degrees of freedom $\\nu_i$ for each input quantity $x_i \\in \\{A, m, b, D\\}$.\n\n1.  **Mean Absorbance, $A$**:\n    -   Value: $A = 1.250$.\n    -   The standard uncertainty is the standard error of the mean of $n=6$ measurements with standard deviation $s_A = 0.010$.\n    $$\n    u(A) = \\frac{s_A}{\\sqrt{n}} = \\frac{0.010}{\\sqrt{6}}\n    $$\n    -   The degrees of freedom for this Type A evaluation are $\\nu_A = n - 1 = 5$.\n\n2.  **Calibration Slope, $m$**:\n    -   Value: $m = 0.0300$.\n    -   Standard uncertainty: $u(m) = 0.0007$.\n    -   Degrees of freedom: $\\nu_m = 4$.\n\n3.  **Calibration Intercept, $b$**:\n    -   Value: $b = 0.0500$.\n    -   Standard uncertainty: $u(b) = 0.0080$.\n    -   Degrees of freedom: $\\nu_b = 4$.\n\n4.  **Dilution Factor, $D$**:\n    -   Value: $D = 10$.\n    -   The uncertainty of $D$ is propagated from the uncertainties of the pipetted volumes, $V_s$ and $V_b$. The functional relationship is $D = 1 + V_b/V_s$.\n    -   The standard uncertainties for the volumes are derived from the expanded uncertainties ($U(V_s) = 1.0\\ \\mu\\mathrm{L}$, $U(V_b) = 3.0\\ \\mu\\mathrm{L}$) and coverage factor $k=2$:\n        $$\n        u(V_s) = \\frac{U(V_s)}{k} = \\frac{1.0\\ \\mu\\mathrm{L}}{2} = 0.5\\ \\mu\\mathrm{L}\n        $$\n        $$\n        u(V_b) = \\frac{U(V_b)}{k} = \\frac{3.0\\ \\mu\\mathrm{L}}{2} = 1.5\\ \\mu\\mathrm{L}\n        $$\n    -   The combined variance for $D$ is $u^2(D) = \\left(\\frac{\\partial D}{\\partial V_s}\\right)^2 u^2(V_s) + \\left(\\frac{\\partial D}{\\partial V_b}\\right)^2 u^2(V_b)$, assuming $V_s$ and $V_b$ are uncorrelated.\n    -   The sensitivity coefficients are:\n        $$\n        \\frac{\\partial D}{\\partial V_s} = -\\frac{V_b}{V_s^2} = -\\frac{900}{(100)^2} = -0.09\n        $$\n        $$\n        \\frac{\\partial D}{\\partial V_b} = \\frac{1}{V_s} = \\frac{1}{100} = 0.01\n        $$\n    -   The combined variance is:\n        $$\n        u^2(D) = (-0.09)^2 (0.5)^2 + (0.01)^2 (1.5)^2 = 0.0081 \\times 0.25 + 0.0001 \\times 2.25 = 0.002025 + 0.000225 = 0.00225\n        $$\n    -   The standard uncertainty is $u(D) = \\sqrt{0.00225}$.\n    -   Since the uncertainties for $V_s$ and $V_b$ are Type B with effectively infinite degrees of freedom, the resulting degrees of freedom for $D$ are also infinite, $\\nu_D = \\infty$.\n\nNow, we construct the uncertainty budget for $C$. This requires the sensitivity coefficients $c_i = \\frac{\\partial C}{\\partial x_i}$ evaluated at the nominal values of the inputs.\n$$\nc_A = \\frac{\\partial C}{\\partial A} = \\frac{D}{m} = \\frac{10}{0.0300} = \\frac{1000}{3}\n$$\n$$\nc_m = \\frac{\\partial C}{\\partial m} = -\\frac{D(A-b)}{m^2} = -\\frac{C}{m} = -\\frac{400}{0.0300} = -\\frac{40000}{3}\n$$\n$$\nc_b = \\frac{\\partial C}{\\partial b} = -\\frac{D}{m} = -\\frac{10}{0.0300} = -\\frac{1000}{3}\n$$\n$$\nc_D = \\frac{\\partial C}{\\partial D} = \\frac{A-b}{m} = \\frac{C}{D} = \\frac{400}{10} = 40\n$$\nThe variance contribution of each input is $w_i = (c_i u(x_i))^2$.\n$$\nw_A = \\left(\\frac{1000}{3} \\times \\frac{0.010}{\\sqrt{6}}\\right)^2 = \\left(\\frac{10}{3\\sqrt{6}}\\right)^2 = \\frac{100}{54} = \\frac{50}{27} \\approx 1.8519\n$$\n$$\nw_m = \\left(-\\frac{40000}{3} \\times 0.0007\\right)^2 = \\left(-\\frac{28}{3}\\right)^2 = \\frac{784}{9} \\approx 87.1111\n$$\n$$\nw_b = \\left(-\\frac{1000}{3} \\times 0.0080\\right)^2 = \\left(-\\frac{8}{3}\\right)^2 = \\frac{64}{9} \\approx 7.1111\n$$\n$$\nw_D = (40 \\times \\sqrt{0.00225})^2 = 1600 \\times 0.00225 = 3.6\n$$\nThe combined variance $u_c^2(C)$ is the sum of these contributions, as all inputs are assumed to be uncorrelated:\n$$\nu_c^2(C) = \\sum w_i = \\frac{50}{27} + \\frac{784}{9} + \\frac{64}{9} + 3.6 \\approx 1.8519 + 87.1111 + 7.1111 + 3.6 = 99.6741\n$$\nThe combined standard uncertainty is:\n$$\nu_c(C) = \\sqrt{u_c^2(C)} \\approx \\sqrt{99.6741} \\approx 9.9837\\ \\mathrm{ng\\,mL^{-1}}\n$$\nThe effective degrees of freedom, $\\nu_{\\mathrm{eff}}$, are calculated using the Welch-Satterthwaite formula:\n$$\n\\nu_{\\mathrm{eff}} = \\frac{u_c^4(C)}{\\sum_{i=1}^{N} \\frac{w_i^2}{\\nu_i}} = \\frac{(99.6741)^2}{\\frac{(1.8519)^2}{5} + \\frac{(87.1111)^2}{4} + \\frac{(7.1111)^2}{4} + \\frac{(3.6)^2}{\\infty}}\n$$\n$$\n\\nu_{\\mathrm{eff}} \\approx \\frac{9934.92}{ \\frac{3.4295}{5} + \\frac{7588.34}{4} + \\frac{50.5678}{4} + 0} \\approx \\frac{9934.92}{0.6859 + 1897.085 + 12.64195} \\approx \\frac{9934.92}{1910.41285} \\approx 5.2003\n$$\nFor a $95\\%$ confidence interval, the coverage factor $k$ is the Student's $t$-quantile for a probability of $0.975$ with $\\nu_{\\mathrm{eff}} \\approx 5.2003$ degrees of freedom. Interpolating standard tables or using statistical software yields:\n$$\nk = t_{0.975}(5.2003) \\approx 2.5463\n$$\nFinally, the expanded uncertainty $U$ is:\n$$\nU = k \\cdot u_c(C) \\approx 2.5463 \\times 9.9837 \\approx 25.4216\\ \\mathrm{ng\\,mL^{-1}}\n$$\nRounding to four significant figures as requested, the expanded uncertainty is $25.42\\ \\mathrm{ng\\,mL^{-1}}$.", "answer": "$$\n\\boxed{25.42}\n$$", "id": "5153028"}]}