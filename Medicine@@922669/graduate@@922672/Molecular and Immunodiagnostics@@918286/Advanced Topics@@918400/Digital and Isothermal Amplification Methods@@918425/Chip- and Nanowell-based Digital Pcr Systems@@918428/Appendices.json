{"hands_on_practices": [{"introduction": "The core utility of digital PCR lies in its ability to provide absolute quantification of nucleic acids. This first exercise walks you through the fundamental process of converting raw observational data—the number of positive partitions—into an estimate of target concentration. By deriving the maximum likelihood estimator from the underlying Poisson statistics of molecule partitioning, you will build a foundational understanding of how every dPCR instrument arithmetically arrives at its final reported value [@problem_id:5098729].", "problem": "A chip-based Digital Polymerase Chain Reaction (dPCR) assay is used to quantify a single gene target from a clinical specimen relevant to molecular and immunodiagnostics. The microfluidic chip partitions the reaction into $N=20{,}000$ nanowells, each of volume $v=1.2\\,\\mathrm{nL}$. After end-point amplification and fluorescence imaging, $k=3{,}000$ nanowells are classified as positive. Assume that target molecules are randomly and independently distributed among partitions, that the number of molecules entering each nanowell is a Poisson random variable with mean $\\lambda$, and that a nanowell is called positive if it contains at least one target molecule.\n\nStarting from the Poisson law for molecular partitioning and the definition of positivity as the complement of the zero-count event, derive the maximum likelihood estimator for $\\lambda$ in terms of $N$ and $k$. Then, using the relationship between mean occupancy and bulk concentration, compute the estimated target concentration $c$ in copies per $\\mu\\mathrm{L}$. Carefully account for unit conversion between $\\mathrm{nL}$ and $\\mu\\mathrm{L}$. Round your final numerical answer for $c$ to four significant figures and express it in copies per $\\mu\\mathrm{L}$.", "solution": "The problem requires the derivation of the maximum likelihood estimator for the mean number of target molecules per nanowell, $\\lambda$, and subsequently the calculation of the target concentration, $c$, in copies per microliter.\n\nLet $X_i$ be the number of target molecules in the $i$-th nanowell, for $i = 1, 2, \\dots, N$. The problem states that $X_i$ follows a Poisson distribution with mean $\\lambda$. The probability mass function is given by:\n$$P(X_i = m) = \\frac{\\lambda^m \\exp(-\\lambda)}{m!}$$\nwhere $m$ is a non-negative integer representing the number of molecules.\n\nA nanowell is defined as positive if it contains at least one target molecule, i.e., $X_i \\ge 1$. The complementary event is a negative nanowell, which contains zero molecules, $X_i = 0$. The probability of a nanowell being negative is:\n$$P(X_i = 0) = \\frac{\\lambda^0 \\exp(-\\lambda)}{0!} = \\exp(-\\lambda)$$\nThe probability, $p$, of a nanowell being positive is therefore:\n$$p = P(X_i \\ge 1) = 1 - P(X_i = 0) = 1 - \\exp(-\\lambda)$$\n\nThe experiment consists of observing $N$ independent nanowells. This can be modeled as a series of $N$ Bernoulli trials, where success is a positive nanowell. The total number of positive nanowells, $k$, follows a binomial distribution with parameters $N$ and $p$:\n$$P(k | N, p) = \\binom{N}{k} p^k (1-p)^{N-k}$$\nTo find the maximum likelihood estimator (MLE) for $\\lambda$, we first write the likelihood function, $L$, in terms of $\\lambda$ by substituting $p = 1 - \\exp(-\\lambda)$ and $(1-p) = \\exp(-\\lambda)$:\n$$L(\\lambda | k, N) = \\binom{N}{k} (1 - \\exp(-\\lambda))^k (\\exp(-\\lambda))^{N-k}$$\nIt is analytically more convenient to maximize the log-likelihood function, $\\ln L$:\n$$\\ln L(\\lambda | k, N) = \\ln\\left[\\binom{N}{k}\\right] + k \\ln(1 - \\exp(-\\lambda)) + (N-k) \\ln(\\exp(-\\lambda))$$\n$$\\ln L(\\lambda | k, N) = \\ln\\left[\\binom{N}{k}\\right] + k \\ln(1 - \\exp(-\\lambda)) - \\lambda(N-k)$$\nTo find the value of $\\lambda$ that maximizes this function, we take the first derivative with respect to $\\lambda$ and set it to zero. The term $\\ln\\left[\\binom{N}{k}\\right]$ is a constant with respect to $\\lambda$.\n$$\\frac{d}{d\\lambda} \\ln L(\\lambda | k, N) = k \\cdot \\frac{1}{1 - \\exp(-\\lambda)} \\cdot (-\\exp(-\\lambda)) \\cdot (-1) - (N-k)$$\n$$\\frac{d}{d\\lambda} \\ln L(\\lambda | k, N) = \\frac{k \\exp(-\\lambda)}{1 - \\exp(-\\lambda)} - (N-k)$$\nSetting the derivative to zero to find the MLE, denoted $\\hat{\\lambda}$:\n$$\\frac{k \\exp(-\\hat{\\lambda})}{1 - \\exp(-\\hat{\\lambda})} = N-k$$\n$$k \\exp(-\\hat{\\lambda}) = (N-k)(1 - \\exp(-\\hat{\\lambda}))$$\n$$k \\exp(-\\hat{\\lambda}) = (N-k) - (N-k)\\exp(-\\hat{\\lambda})$$\n$$k \\exp(-\\hat{\\lambda}) + (N-k)\\exp(-\\hat{\\lambda}) = N-k$$\n$$N \\exp(-\\hat{\\lambda}) = N-k$$\n$$\\exp(-\\hat{\\lambda}) = \\frac{N-k}{N} = 1 - \\frac{k}{N}$$\nSolving for $\\hat{\\lambda}$ by taking the natural logarithm of both sides:\n$$-\\hat{\\lambda} = \\ln\\left(1 - \\frac{k}{N}\\right)$$\n$$\\hat{\\lambda} = -\\ln\\left(1 - \\frac{k}{N}\\right)$$\nThis is the maximum likelihood estimator for $\\lambda$ in terms of $N$ and $k$.\n\nNow, we use the given numerical values to compute $\\hat{\\lambda}$.\nGiven:\nTotal number of nanowells, $N = 20000$.\nNumber of positive nanowells, $k = 3000$.\n$$\\hat{\\lambda} = -\\ln\\left(1 - \\frac{3000}{20000}\\right) = -\\ln\\left(1 - 0.15\\right) = -\\ln(0.85)$$\n$$\\hat{\\lambda} \\approx 0.1625189$$\n\nThe concentration $c$ is the average number of molecules per unit volume. The mean number of molecules in a single nanowell is $\\lambda$, and the volume of a single nanowell is $v$. Therefore, the estimated concentration $\\hat{c}$ is:\n$$\\hat{c} = \\frac{\\hat{\\lambda}}{v}$$\nGiven:\nVolume of each nanowell, $v = 1.2\\,\\mathrm{nL}$.\nThe problem requires the concentration in units of copies per $\\mu\\mathrm{L}$. We must perform a unit conversion.\n$1\\,\\mu\\mathrm{L} = 1000\\,\\mathrm{nL}$, so $1\\,\\mathrm{nL} = 10^{-3}\\,\\mu\\mathrm{L}$.\n$$v = 1.2 \\times 10^{-3}\\,\\mu\\mathrm{L}$$\nNow we can compute the estimated concentration $\\hat{c}$:\n$$\\hat{c} = \\frac{-\\ln(0.85)}{1.2 \\times 10^{-3}\\,\\mu\\mathrm{L}} \\approx \\frac{0.1625189}{1.2 \\times 10^{-3}} \\frac{\\text{copies}}{\\mu\\mathrm{L}}$$\n$$\\hat{c} \\approx 135.43244\\,\\frac{\\text{copies}}{\\mu\\mathrm{L}}$$\nRounding the final answer to four significant figures, we get:\n$$\\hat{c} \\approx 135.4\\,\\frac{\\text{copies}}{\\mu\\mathrm{L}}$$", "answer": "$$\\boxed{1.354 \\times 10^{2}}$$", "id": "5098729"}, {"introduction": "Building on simple quantification, a major application of dPCR in diagnostics is the precise measurement of copy number variation (CNV), which requires comparing the concentration of a target gene to a stable reference gene. This practice extends the principles of Poisson analysis to a ratiometric measurement and introduces the essential statistical tool of confidence intervals [@problem_id:5098724]. Mastering this allows you to not only calculate the copy number but also to report the statistical confidence in your measurement, a critical aspect of clinical diagnostics.", "problem": "In a chip-based digital polymerase chain reaction (dPCR) assay designed for molecular and immunodiagnostics copy number variation quantification, a sample is partitioned into nanowells of equal volume. Let the occupancy of target molecules per nanowell for a biomarker gene (target, denoted by $T$) and a single-copy reference gene (reference, denoted by $R$) be modeled by independent Poisson random variables with means $\\lambda_T$ and $\\lambda_R$, respectively, per nanowell. A nanowell is called \"positive\" when it contains at least one amplifiable template molecule. Under the Poisson model, the probability that a nanowell is positive is the complement of the probability of zero occupancy. The observed number of positive nanowells, $k$, out of $N$ nanowells, therefore follows a Binomial law with success probability determined by the underlying Poisson mean. Starting from these foundations, derive the maximum likelihood estimators $\\hat{\\lambda}_T$ and $\\hat{\\lambda}_R$ from the observed positive fractions for $T$ and $R$, respectively. Then derive the estimator of the relative copy number, $\\widehat{\\mathrm{CN}}$, defined as the ratio of the per-nanowell Poisson means, $\\widehat{\\mathrm{CN}} = \\hat{\\lambda}_T / \\hat{\\lambda}_R$, which equals the concentration ratio when partition volumes are equal. Using a first-order delta method approximation and assuming the $T$ and $R$ counts are independent, derive an approximate two-sided $95\\%$ confidence interval for $\\widehat{\\mathrm{CN}}$.\n\nGiven $N_T = N_R = 20{,}000$ nanowells, $k_T = 8{,}000$ positives for $T$, and $k_R = 10{,}000$ positives for $R$, compute the numerical values of $\\hat{\\lambda}_T$, $\\hat{\\lambda}_R$, $\\widehat{\\mathrm{CN}}$, and the lower and upper endpoints of the $95\\%$ confidence interval for $\\widehat{\\mathrm{CN}}$. Express all answers as dimensionless numbers and round your numerical answers to four significant figures.", "solution": "The solution is developed in three parts: first, the derivation of the maximum likelihood estimator (MLE) for the Poisson mean $\\lambda$; second, the derivation of the approximate confidence interval for the ratio of two such estimators using the delta method; and third, the computation of the numerical values.\n\nLet $X$ be the random variable representing the number of molecules in a single nanowell. According to the problem statement, $X$ follows a Poisson distribution with mean $\\lambda$, i.e., $X \\sim \\mathrm{Poisson}(\\lambda)$. The probability mass function is $P(X=x) = \\frac{e^{-\\lambda}\\lambda^x}{x!}$ for $x = 0, 1, 2, \\dots$. A nanowell is positive if it contains at least one molecule, i.e., $X \\ge 1$. The probability of a single nanowell being positive, denoted by $p$, is the complement of it being empty ($X=0$):\n$$p = P(X \\ge 1) = 1 - P(X=0) = 1 - \\frac{e^{-\\lambda}\\lambda^0}{0!} = 1 - e^{-\\lambda}$$\nThe number of observed positive nanowells, $k$, out of a total of $N$ nanowells, is the sum of $N$ independent Bernoulli trials, each with success probability $p$. Therefore, $k$ follows a binomial distribution, $k \\sim \\mathrm{Binomial}(N, p)$. The likelihood function for $p$ given the observation $k$ is:\n$$L(p; k, N) = \\binom{N}{k} p^k (1-p)^{N-k}$$\nTo find the MLE of $p$, we maximize this function or, more conveniently, its logarithm (the log-likelihood):\n$$\\ln L(p) = \\ln\\binom{N}{k} + k \\ln p + (N-k) \\ln(1-p)$$\nTaking the derivative with respect to $p$ and setting it to zero yields the MLE $\\hat{p}$:\n$$\\frac{d(\\ln L)}{dp} = \\frac{k}{p} - \\frac{N-k}{1-p} = 0$$\n$$\\frac{k}{\\hat{p}} = \\frac{N-k}{1-\\hat{p}} \\implies k(1-\\hat{p}) = (N-k)\\hat{p} \\implies k - k\\hat{p} = N\\hat{p} - k\\hat{p} \\implies k = N\\hat{p}$$\n$$\\hat{p} = \\frac{k}{N}$$\nBy the invariance property of maximum likelihood estimators, the MLE for $\\lambda$, denoted $\\hat{\\lambda}$, can be found by substituting $\\hat{p}$ into the equation relating $p$ and $\\lambda$:\n$$\\hat{p} = 1 - e^{-\\hat{\\lambda}} \\implies \\frac{k}{N} = 1 - e^{-\\hat{\\lambda}}$$\n$$e^{-\\hat{\\lambda}} = 1 - \\frac{k}{N} = \\frac{N-k}{N}$$\n$$-\\hat{\\lambda} = \\ln\\left(\\frac{N-k}{N}\\right)$$\n$$\\hat{\\lambda} = -\\ln\\left(\\frac{N-k}{N}\\right) = \\ln\\left(\\left(\\frac{N-k}{N}\\right)^{-1}\\right) = \\ln\\left(\\frac{N}{N-k}\\right)$$\nApplying this general formula to the target ($T$) and reference ($R$) genes, we obtain their respective MLEs:\n$$\\hat{\\lambda}_T = \\ln\\left(\\frac{N_T}{N_T-k_T}\\right) \\quad \\text{and} \\quad \\hat{\\lambda}_R = \\ln\\left(\\frac{N_R}{N_R-k_R}\\right)$$\n\nNext, we derive the approximate $95\\%$ confidence interval for the relative copy number, $\\widehat{\\mathrm{CN}} = \\hat{\\lambda}_T / \\hat{\\lambda}_R$, using the first-order delta method. The variance of a function $g(\\hat{\\theta}_1, \\hat{\\theta}_2)$ of two uncorrelated estimators is approximated by:\n$$\\mathrm{Var}(g(\\hat{\\theta}_1, \\hat{\\theta}_2)) \\approx \\left(\\frac{\\partial g}{\\partial \\theta_1}\\right)^2 \\mathrm{Var}(\\hat{\\theta}_1) + \\left(\\frac{\\partial g}{\\partial \\theta_2}\\right)^2 \\mathrm{Var}(\\hat{\\theta}_2)$$\nIn our case, $g(\\hat{\\lambda}_T, \\hat{\\lambda}_R) = \\hat{\\lambda}_T / \\hat{\\lambda}_R$. The partial derivatives are:\n$$\\frac{\\partial g}{\\partial \\lambda_T} = \\frac{1}{\\lambda_R} \\quad \\text{and} \\quad \\frac{\\partial g}{\\partial \\lambda_R} = -\\frac{\\lambda_T}{\\lambda_R^2}$$\nThe variance of $\\widehat{\\mathrm{CN}}$ is thus approximated as:\n$$\\mathrm{Var}(\\widehat{\\mathrm{CN}}) \\approx \\left(\\frac{1}{\\hat{\\lambda}_R}\\right)^2 \\mathrm{Var}(\\hat{\\lambda}_T) + \\left(-\\frac{\\hat{\\lambda}_T}{\\hat{\\lambda}_R^2}\\right)^2 \\mathrm{Var}(\\hat{\\lambda}_R) = \\frac{\\mathrm{Var}(\\hat{\\lambda}_T)}{\\hat{\\lambda}_R^2} + \\frac{\\hat{\\lambda}_T^2 \\mathrm{Var}(\\hat{\\lambda}_R)}{\\hat{\\lambda}_R^4}$$\n$$\\mathrm{Var}(\\widehat{\\mathrm{CN}}) \\approx \\left(\\frac{\\hat{\\lambda}_T}{\\hat{\\lambda}_R}\\right)^2 \\left( \\frac{\\mathrm{Var}(\\hat{\\lambda}_T)}{\\hat{\\lambda}_T^2} + \\frac{\\mathrm{Var}(\\hat{\\lambda}_R)}{\\hat{\\lambda}_R^2} \\right) = (\\widehat{\\mathrm{CN}})^2 \\left( \\mathrm{RelVar}(\\hat{\\lambda}_T) + \\mathrm{RelVar}(\\hat{\\lambda}_R) \\right)$$\nTo find $\\mathrm{Var}(\\hat{\\lambda})$, we again use the delta method for $\\hat{\\lambda} = h(\\hat{p}) = -\\ln(1-\\hat{p})$.\n$$\\mathrm{Var}(\\hat{\\lambda}) \\approx \\left(h'(\\hat{p})\\right)^2 \\mathrm{Var}(\\hat{p})$$\nThe derivative is $h'(\\hat{p}) = \\frac{1}{1-\\hat{p}}$. The variance of the binomial proportion estimator $\\hat{p}=k/N$ is $\\mathrm{Var}(\\hat{p}) = \\frac{p(1-p)}{N}$. We estimate this by plugging in $\\hat{p}$, so $\\widehat{\\mathrm{Var}}(\\hat{p}) = \\frac{\\hat{p}(1-\\hat{p})}{N}$.\n$$\\widehat{\\mathrm{Var}}(\\hat{\\lambda}) \\approx \\left(\\frac{1}{1-\\hat{p}}\\right)^2 \\frac{\\hat{p}(1-\\hat{p})}{N} = \\frac{\\hat{p}}{N(1-\\hat{p})}$$\nSubstituting $\\hat{p} = k/N$:\n$$\\widehat{\\mathrm{Var}}(\\hat{\\lambda}) = \\frac{k/N}{N(1-k/N)} = \\frac{k/N}{N((N-k)/N)} = \\frac{k}{N(N-k)}$$\nApplying this to $T$ and $R$:\n$$\\widehat{\\mathrm{Var}}(\\hat{\\lambda}_T) = \\frac{k_T}{N_T(N_T-k_T)} \\quad \\text{and} \\quad \\widehat{\\mathrm{Var}}(\\hat{\\lambda}_R) = \\frac{k_R}{N_R(N_R-k_R)}$$\nAn approximate two-sided $95\\%$ confidence interval for $\\widehat{\\mathrm{CN}}$ is given by $\\widehat{\\mathrm{CN}} \\pm z_{1-0.05/2} \\sqrt{\\widehat{\\mathrm{Var}}(\\widehat{\\mathrm{CN}})}$, where $z_{0.975} \\approx 1.96$.\n\nFinally, we compute the numerical values using the provided data: $N_T = 20,000$, $k_T = 8,000$, $N_R = 20,000$, $k_R = 10,000$.\nFirst, we compute the MLEs for $\\lambda_T$ and $\\lambda_R$:\n$$\\hat{\\lambda}_T = \\ln\\left(\\frac{20000}{20000-8000}\\right) = \\ln\\left(\\frac{20000}{12000}\\right) = \\ln\\left(\\frac{5}{3}\\right) = -\\ln(0.6) \\approx 0.5108256$$\n$$\\hat{\\lambda}_R = \\ln\\left(\\frac{20000}{20000-10000}\\right) = \\ln\\left(\\frac{20000}{10000}\\right) = \\ln(2) \\approx 0.6931472$$\nRounding to four significant figures, $\\hat{\\lambda}_T \\approx 0.5108$ and $\\hat{\\lambda}_R \\approx 0.6931$.\n\nNext, we compute the estimator for the copy number:\n$$\\widehat{\\mathrm{CN}} = \\frac{\\hat{\\lambda}_T}{\\hat{\\lambda}_R} = \\frac{0.5108256}{0.6931472} \\approx 0.7369656$$\nRounding to four significant figures, $\\widehat{\\mathrm{CN}} \\approx 0.7370$.\n\nNow, we compute the estimated variances of $\\hat{\\lambda}_T$ and $\\hat{\\lambda}_R$:\n$$\\widehat{\\mathrm{Var}}(\\hat{\\lambda}_T) = \\frac{8000}{20000(20000-8000)} = \\frac{8000}{20000 \\times 12000} = \\frac{1}{30000}$$\n$$\\widehat{\\mathrm{Var}}(\\hat{\\lambda}_R) = \\frac{10000}{20000(20000-10000)} = \\frac{10000}{20000 \\times 10000} = \\frac{1}{20000}$$\nThe estimated variance of $\\widehat{\\mathrm{CN}}$ is:\n$$\\widehat{\\mathrm{Var}}(\\widehat{\\mathrm{CN}}) \\approx (\\widehat{\\mathrm{CN}})^2 \\left( \\frac{\\widehat{\\mathrm{Var}}(\\hat{\\lambda}_T)}{\\hat{\\lambda}_T^2} + \\frac{\\widehat{\\mathrm{Var}}(\\hat{\\lambda}_R)}{\\hat{\\lambda}_R^2} \\right)$$\n$$\\widehat{\\mathrm{Var}}(\\widehat{\\mathrm{CN}}) \\approx (0.7369656)^2 \\left( \\frac{1/30000}{(0.5108256)^2} + \\frac{1/20000}{(0.6931472)^2} \\right)$$\n$$\\widehat{\\mathrm{Var}}(\\widehat{\\mathrm{CN}}) \\approx (0.543118) \\left( \\frac{3.333... \\times 10^{-5}}{0.260943} + \\frac{5 \\times 10^{-5}}{0.480453} \\right) \\approx (0.543118)(1.2774 \\times 10^{-4} + 1.0407 \\times 10^{-4})$$\n$$\\widehat{\\mathrm{Var}}(\\widehat{\\mathrm{CN}}) \\approx (0.543118)(2.3181 \\times 10^{-4}) \\approx 1.2588 \\times 10^{-4}$$\nThe standard error of $\\widehat{\\mathrm{CN}}$ is $SE(\\widehat{\\mathrm{CN}}) = \\sqrt{1.2588 \\times 10^{-4}} \\approx 0.0112198$.\nThe margin of error for the $95\\%$ confidence interval is $ME = z_{0.975} \\times SE(\\widehat{\\mathrm{CN}}) \\approx 1.96 \\times 0.0112198 \\approx 0.0219908$.\n\nThe $95\\%$ confidence interval is $\\widehat{\\mathrm{CN}} \\pm ME$:\nLower Endpoint: $0.7369656 - 0.0219908 = 0.7149748$\nUpper Endpoint: $0.7369656 + 0.0219908 = 0.7589564$\n\nRounding to four significant figures:\nLower Endpoint $\\approx 0.7150$\nUpper Endpoint $\\approx 0.7590$\nThe five requested numerical values are $\\hat{\\lambda}_T = 0.5108$, $\\hat{\\lambda}_R = 0.6931$, $\\widehat{\\mathrm{CN}} = 0.7370$, CI lower = $0.7150$, CI upper = $0.7590$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.5108  0.6931  0.7370  0.7150  0.7590\n\\end{pmatrix}\n}\n$$", "id": "5098724"}, {"introduction": "While the Poisson model provides a powerful ideal framework, real-world microfluidic systems have physical imperfections that can introduce systematic errors. This exercise delves into the practical consequences of well-to-well volume variation, a common artifact of chip manufacturing, on the accuracy of concentration estimates [@problem_id:5098714]. By analyzing this source of bias, you will develop a more critical perspective on dPCR data and appreciate the importance of instrument characterization and error modeling in high-precision measurements.", "problem": "A chip-based digital Polymerase Chain Reaction (PCR) assay partitions a sample into $N$ nanowells, each containing volume $v_{i}$. In ideal digital PCR (dPCR), the number of target molecules per well is commonly modeled as a Poisson random variable with mean $c\\,v_{i}$, where $c$ is the true target concentration. The probability that a well is called positive is then a function of $c$ and $v_{i}$. In practice, engineered chips exhibit well-to-well volume dispersion. Consider a chip whose well volumes $v_{i}$ are independent and identically distributed with mean $\\bar{v} = 1.0\\,\\mathrm{nL}$ and coefficient of variation $\\mathrm{CV} = 5\\%$. An experiment on this chip yields $k$ positive wells out of $N$ total, with the observed fraction $k/N = 0.3$.\n\nStarting from the Poisson occupancy model and the definition of the coefficient of variation, derive an asymptotic expression (to second order in the volume dispersion) for the fractional bias in the concentration estimate when volumes are incorrectly treated as uniform. Let the naive estimator be obtained by treating all wells as having volume $\\bar{v}$ and by inverting the observed positive fraction under that assumption. Define the fractional bias as $(\\hat{c} - c)/c$, where $\\hat{c}$ is the naive estimate and $c$ is the true concentration consistent with the observed fraction under the actual volume dispersion. Use a second-order Taylor expansion in the well-volume variability to quantify the bias, and then evaluate this estimate numerically for $\\bar{v} = 1.0\\,\\mathrm{nL}$, $\\mathrm{CV} = 0.05$, and $k/N = 0.3$.\n\nExpress the final fractional bias as a dimensionless decimal number and round your answer to four significant figures.", "solution": "Let $M_i$ be the number of target molecules in the $i$-th well of volume $v_i$. According to the problem statement, $M_i$ follows a Poisson distribution with mean $\\lambda_i = c\\,v_i$, where $c$ is the true concentration.\n$$ P(M_i = m) = \\frac{(c\\,v_i)^m \\exp(-c\\,v_i)}{m!} $$\nA well is considered \"positive\" if it contains one or more molecules ($M_i \\ge 1$). The probability of a well with volume $v_i$ being positive, denoted $p(v_i)$, is:\n$$ p(v_i) = 1 - P(M_i = 0) = 1 - \\exp(-c\\,v_i) $$\nIn reality, the well volumes $v_i$ are not uniform but are i.i.d. random variables drawn from a distribution. Let $V$ represent this random volume variable. The probability of any randomly selected well being positive, $P_{true}$, is the expectation of $p(V)$ over the distribution of $V$.\n$$ P_{true} = \\mathbb{E}[p(V)] = \\mathbb{E}[1 - \\exp(-c\\,V)] = 1 - \\mathbb{E}[\\exp(-c\\,V)] $$\nTo evaluate $\\mathbb{E}[\\exp(-c\\,V)]$, we perform a second-order Taylor expansion of the function $f(V) = \\exp(-c\\,V)$ around the mean volume $\\bar{v} = \\mathbb{E}[V]$.\n$$ f(V) \\approx f(\\bar{v}) + f'(\\bar{v})(V - \\bar{v}) + \\frac{f''(\\bar{v})}{2}(V - \\bar{v})^2 $$\nThe derivatives of $f(V)$ are:\n$$ f'(V) = -c \\exp(-c\\,V) \\quad \\implies \\quad f'(\\bar{v}) = -c \\exp(-c\\,\\bar{v}) $$\n$$ f''(V) = c^2 \\exp(-c\\,V) \\quad \\implies \\quad f''(\\bar{v}) = c^2 \\exp(-c\\,\\bar{v}) $$\nTaking the expectation of the Taylor series:\n$$ \\mathbb{E}[f(V)] \\approx \\mathbb{E}\\left[ f(\\bar{v}) + f'(\\bar{v})(V - \\bar{v}) + \\frac{f''(\\bar{v})}{2}(V - \\bar{v})^2 \\right] $$\nUsing the linearity of expectation:\n$$ \\mathbb{E}[f(V)] \\approx f(\\bar{v}) + f'(\\bar{v})\\mathbb{E}[V - \\bar{v}] + \\frac{f''(\\bar{v})}{2}\\mathbb{E}[(V - \\bar{v})^2] $$\nWe know that $\\mathbb{E}[V - \\bar{v}] = \\mathbb{E}[V] - \\bar{v} = 0$, and by definition, $\\mathbb{E}[(V - \\bar{v})^2] = \\mathrm{Var}(V)$.\n$$ \\mathbb{E}[\\exp(-c\\,V)] \\approx \\exp(-c\\,\\bar{v}) + \\frac{c^2 \\exp(-c\\,\\bar{v})}{2} \\mathrm{Var}(V) $$\nThe variance is related to the coefficient of variation $(\\mathrm{CV})$ by $\\mathrm{Var}(V) = (\\mathrm{CV} \\cdot \\bar{v})^2 = \\mathrm{CV}^2 \\bar{v}^2$. Substituting this in:\n$$ \\mathbb{E}[\\exp(-c\\,V)] \\approx \\exp(-c\\,\\bar{v}) \\left( 1 + \\frac{1}{2} c^2 \\bar{v}^2 \\mathrm{CV}^2 \\right) $$\nThe true probability of a positive well is therefore:\n$$ P_{true} \\approx 1 - \\exp(-c\\,\\bar{v}) \\left( 1 + \\frac{1}{2} (c\\,\\bar{v})^2 \\mathrm{CV}^2 \\right) $$\nThe observed fraction of positive wells, $k/N$, is our experimental measurement of $P_{true}$.\n$$ \\frac{k}{N} \\approx 1 - \\exp(-c\\,\\bar{v}) \\left( 1 + \\frac{1}{2} (c\\,\\bar{v})^2 \\mathrm{CV}^2 \\right) $$\nNow, consider the naive estimator $\\hat{c}$. It is obtained by incorrectly assuming all volumes are uniform at $\\bar{v}$, which implies the probability of a positive well is $1 - \\exp(-\\hat{c}\\,\\bar{v})$. This probability is equated to the observed fraction:\n$$ \\frac{k}{N} = 1 - \\exp(-\\hat{c}\\,\\bar{v}) $$\nWe can now relate the naive estimate $\\hat{c}$ to the true concentration $c$ by equating the two expressions for $k/N$.\n$$ 1 - \\exp(-\\hat{c}\\,\\bar{v}) \\approx 1 - \\exp(-c\\,\\bar{v}) \\left( 1 + \\frac{1}{2} (c\\,\\bar{v})^2 \\mathrm{CV}^2 \\right) $$\n$$ \\exp(-\\hat{c}\\,\\bar{v}) \\approx \\exp(-c\\,\\bar{v}) \\left( 1 + \\frac{1}{2} (c\\,\\bar{v})^2 \\mathrm{CV}^2 \\right) $$\nTaking the natural logarithm of both sides:\n$$ -\\hat{c}\\,\\bar{v} \\approx \\ln\\left[ \\exp(-c\\,\\bar{v}) \\left( 1 + \\frac{1}{2} (c\\,\\bar{v})^2 \\mathrm{CV}^2 \\right) \\right] $$\n$$ -\\hat{c}\\,\\bar{v} \\approx -c\\,\\bar{v} + \\ln\\left( 1 + \\frac{1}{2} (c\\,\\bar{v})^2 \\mathrm{CV}^2 \\right) $$\nSince $\\mathrm{CV}$ is small ($0.05$), the term $\\frac{1}{2} (c\\,\\bar{v})^2 \\mathrm{CV}^2$ is also small. We use the first-order Taylor approximation $\\ln(1+x) \\approx x$ for small $x$:\n$$ -\\hat{c}\\,\\bar{v} \\approx -c\\,\\bar{v} + \\frac{1}{2} (c\\,\\bar{v})^2 \\mathrm{CV}^2 $$\nDividing by $-\\bar{v}$:\n$$ \\hat{c} \\approx c - \\frac{1}{2} c^2 \\bar{v} \\mathrm{CV}^2 $$\nThe fractional bias is defined as $(\\hat{c} - c)/c$.\n$$ \\frac{\\hat{c} - c}{c} \\approx \\frac{(c - \\frac{1}{2} c^2 \\bar{v} \\mathrm{CV}^2) - c}{c} = \\frac{-\\frac{1}{2} c^2 \\bar{v} \\mathrm{CV}^2}{c} = -\\frac{1}{2} c\\,\\bar{v}\\,\\mathrm{CV}^2 $$\nThis expression depends on the true concentration $c$, which is unknown. To obtain a practical formula, we express the bias in terms of the measurable quantities. The term itself is of order $\\mathrm{CV}^2$, which is a small correction. Thus, we can approximate $c$ with the naive estimate $\\hat{c}$ within this term without affecting the overall second-order accuracy of the expression.\n$$ \\frac{\\hat{c} - c}{c} \\approx -\\frac{1}{2} \\hat{c}\\,\\bar{v}\\,\\mathrm{CV}^2 $$\nFrom the naive model, we have an expression for $\\hat{c}\\,\\bar{v}$:\n$$ \\exp(-\\hat{c}\\,\\bar{v}) = 1 - \\frac{k}{N} \\implies \\hat{c}\\,\\bar{v} = -\\ln\\left(1 - \\frac{k}{N}\\right) $$\nSubstituting this into our expression for the fractional bias:\n$$ \\frac{\\hat{c} - c}{c} \\approx -\\frac{1}{2} \\left[ -\\ln\\left(1 - \\frac{k}{N}\\right) \\right] \\mathrm{CV}^2 = \\frac{1}{2} \\ln\\left(1 - \\frac{k}{N}\\right) \\mathrm{CV}^2 $$\nThis is the desired asymptotic expression for the fractional bias. Since $k/N  1$, $\\ln(1-k/N)$ is negative, correctly predicting that the naive concentration $\\hat{c}$ is an underestimate of the true concentration $c$.\n\nWe are given $k/N = 0.3$ and $\\mathrm{CV} = 0.05$. Substituting these values into the derived formula:\n$$ \\frac{\\hat{c} - c}{c} \\approx \\frac{1}{2} \\ln(1 - 0.3) (0.05)^2 $$\n$$ \\frac{\\hat{c} - c}{c} \\approx \\frac{1}{2} \\ln(0.7) (0.0025) $$\nUsing a calculator for the natural logarithm:\n$$ \\ln(0.7) \\approx -0.3566749 $$\n$$ \\frac{\\hat{c} - c}{c} \\approx \\frac{1}{2} (-0.3566749) (0.0025) $$\n$$ \\frac{\\hat{c} - c}{c} \\approx (-0.17833745) (0.0025) $$\n$$ \\frac{\\hat{c} - c}{c} \\approx -0.0004458436 $$\nRounding the result to four significant figures, we get:\n$$ \\frac{\\hat{c} - c}{c} \\approx -0.0004458 $$\nThis is the estimated fractional bias in the concentration measurement due to a $5\\%$ coefficient of variation in well volume.", "answer": "$$\\boxed{-0.0004458}$$", "id": "5098714"}]}