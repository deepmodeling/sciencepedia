{"hands_on_practices": [{"introduction": "The foundation of DNA methylation analysis, particularly from bisulfite sequencing data, rests on the accurate quantification of methylation levels at individual CpG sites. This first practice exercise guides you through this fundamental step. You will learn to translate raw sequencing read counts into a methylation proportion and, more importantly, to calculate a confidence interval for this estimate, which is a critical measure of its precision [@problem_id:5109692]. Mastering this basic skill is essential before moving on to more complex modeling.", "problem": "A targeted bisulfite sequencing assay is performed to quantify cytosine methylation at a single cytosine–phosphate–guanine (CpG) site in a colorectal tumor biopsy. In sodium bisulfite conversion, unmethylated cytosines are deaminated to uracil (read as thymine after Polymerase Chain Reaction (PCR) and sequencing), whereas methylated cytosines resist conversion and are read as cytosines. After stringent quality control (duplicate removal and base quality filtering), the site has sequencing coverage $n = 120$ reads, with $k = 54$ reads called as methylated cytosine. Assume each read is an independent Bernoulli trial with true methylation probability $p$ at this CpG in the sampled cell population, and that non-conversion and base-calling errors are negligible relative to sampling variability.\n\nUsing the binomial sampling model as the fundamental base, and a two-sided confidence level of $0.95$ based on the standard normal reference distribution, compute:\n1. The methylation proportion $\\hat{p}$.\n2. The Wilson score confidence interval for $p$ at level $0.95$ obtained by inverting the score test for the binomial proportion.\n\nReport your three final numbers in the order $(\\hat{p}, L, U)$, where $L$ and $U$ are the lower and upper confidence limits, respectively. Express all three as decimals (not as percentages), and round your answers to four significant figures.", "solution": "The measurement process maps to a binomial model by construction: each read overlapping the CpG can be viewed as an independent Bernoulli trial with probability $p$ of observing a methylated cytosine, assuming negligible systematic error after quality control. Thus, the count of methylated reads $k$ follows $k \\sim \\mathrm{Binomial}(n, p)$, and the canonical estimator of $p$ is the sample proportion\n$$\n\\hat{p} \\equiv \\frac{k}{n}.\n$$\nFor interval estimation with target coverage $0.95$, a widely used approach that controls coverage better than the naive Wald interval is the Wilson score interval, derived by inverting the score test for the null hypothesis $H_{0}: p = p_{0}$.\n\nStarting from the binomial likelihood with parameter $p$, the score test statistic (normalized by the Fisher information under $H_{0}$) is\n$$\nS(p_{0}) \\equiv \\frac{\\hat{p} - p_{0}}{\\sqrt{\\frac{p_{0}(1 - p_{0})}{n}}}.\n$$\nA two-sided score test at level $\\alpha$ rejects $H_{0}$ when $|S(p_{0})|  z$, where $z$ is the upper $(1-\\alpha/2)$ quantile of the standard normal distribution. The $(1-\\alpha)$ Wilson score confidence set is the collection of $p_{0}$ not rejected:\n$$\n\\left| \\frac{\\hat{p} - p_{0}}{\\sqrt{\\frac{p_{0}(1 - p_{0})}{n}}} \\right| \\leq z.\n$$\nSquaring both sides and rearranging yields a quadratic inequality in $p_{0}$:\n$$\n\\frac{(\\hat{p} - p_{0})^{2}}{\\frac{p_{0}(1 - p_{0})}{n}} \\leq z^{2}\n\\;\\;\\Longleftrightarrow\\;\\;\nn(\\hat{p} - p_{0})^{2} \\leq z^{2} p_{0}(1 - p_{0}).\n$$\nExpanding and collecting terms on the left-hand side:\n$$\nn\\hat{p}^{2} - 2n\\hat{p}p_{0} + np_{0}^{2} - z^{2}p_{0} + z^{2}p_{0}^{2} \\leq 0,\n$$\nwhich we write as\n$$\n(n + z^{2})p_{0}^{2} - (2n\\hat{p} + z^{2})p_{0} + n\\hat{p}^{2} \\leq 0.\n$$\nThe set of $p_{0}$ satisfying this inequality is the interval between the two roots of the quadratic equation $(n + z^{2})p_{0}^{2} - (2n\\hat{p} + z^{2})p_{0} + n\\hat{p}^{2} = 0$. Using the quadratic formula, the roots are\n$$\np_{0} \\;=\\; \\frac{(2n\\hat{p} + z^{2}) \\pm \\sqrt{(2n\\hat{p} + z^{2})^{2} - 4(n + z^{2})n\\hat{p}^{2}}}{2(n + z^{2})}.\n$$\nThe discriminant simplifies as follows:\n$$\n\\begin{aligned}\n(2n\\hat{p} + z^{2})^{2} - 4(n + z^{2})n\\hat{p}^{2}\n= 4n^{2}\\hat{p}^{2} + 4n\\hat{p}z^{2} + z^{4} - 4n^{2}\\hat{p}^{2} - 4n z^{2}\\hat{p}^{2} \\\\\n= z^{2}\\!\\left(z^{2} + 4n\\hat{p}(1 - \\hat{p})\\right).\n\\end{aligned}\n$$\nHence, the Wilson score interval can be written in the algebraically equivalent and commonly used form\n$$\n\\left[\\,L, U\\,\\right] \\;=\\; \\frac{\\hat{p} + \\frac{z^{2}}{2n} \\;\\pm\\; z\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n} + \\frac{z^{2}}{4n^{2}}}}{1 + \\frac{z^{2}}{n}}.\n$$\n\nWe now substitute the observed values. The point estimate is\n$$\n\\hat{p} \\;=\\; \\frac{k}{n} \\;=\\; \\frac{54}{120} \\;=\\; 0.45.\n$$\nFor a two-sided confidence level of $0.95$, we take $z \\approx 1.96$ and compute the components:\n$$\n\\frac{z^{2}}{n} \\;=\\; \\frac{3.8416}{120} \\;=\\; 0.032013333\\ldots,\\quad\n1 + \\frac{z^{2}}{n} \\;=\\; 1.032013333\\ldots,\n$$\n$$\n\\hat{p} + \\frac{z^{2}}{2n} \\;=\\; 0.45 + \\frac{3.8416}{240} \\;=\\; 0.466006666\\ldots,\n$$\n$$\n\\frac{\\hat{p}(1 - \\hat{p})}{n} + \\frac{z^{2}}{4n^{2}}\n\\;=\\; \\frac{0.45 \\times 0.55}{120} + \\frac{3.8416}{4 \\times 120^{2}}\n\\;=\\; 0.0020625 + 0.000066694444\\ldots\n\\;=\\; 0.002129194444\\ldots,\n$$\n$$\nz\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n} + \\frac{z^{2}}{4n^{2}}}\n\\;=\\; 1.96 \\times \\sqrt{0.002129194444\\ldots}\n\\;=\\; 1.96 \\times 0.046143192\\ldots\n\\;=\\; 0.09043786\\ldots.\n$$\nTherefore,\n$$\nL \\;=\\; \\frac{0.466006666\\ldots - 0.09043786\\ldots}{1.032013333\\ldots}\n\\;=\\; \\frac{0.375568806\\ldots}{1.032013333\\ldots}\n\\;=\\; 0.363919\\ldots,\n$$\n$$\nU \\;=\\; \\frac{0.466006666\\ldots + 0.09043786\\ldots}{1.032013333\\ldots}\n\\;=\\; \\frac{0.556444526\\ldots}{1.032013333\\ldots}\n\\;=\\; 0.539184\\ldots.\n$$\n\nRounded to four significant figures and expressed as decimals (not percentages), the requested triplet $(\\hat{p}, L, U)$ is\n$$\n\\hat{p} = 0.4500,\\quad L = 0.3639,\\quad U = 0.5392.\n$$\nThese results are scientifically appropriate in this molecular and immunodiagnostics context because the binomial model captures read-level methylation calls under independence, and the Wilson interval provides improved coverage properties over the Wald interval at moderate coverage $n$ frequently encountered in targeted assays.", "answer": "$$\\boxed{\\begin{pmatrix}0.4500  0.3639  0.5392\\end{pmatrix}}$$", "id": "5109692"}, {"introduction": "Moving beyond simple estimation, a core task in disease research is to formally test whether methylation levels are associated with a clinical outcome while adjusting for other influencing factors. This practice demonstrates the use of a generalized linear model (GLM) with a binomial family and logit link, which is the gold standard for analyzing bisulfite sequencing count data. By fitting this model, you will learn to derive key metrics like odds ratios and p-values to make statistically sound inferences about disease effects, accounting for covariates like age and experimental batch effects [@problem_id:5109769].", "problem": "You are given aggregated bisulfite sequencing data measuring cytosine–phosphate–guanine (CpG) site DNA methylation in independent individuals. For each individual $i$, you observe methylated read counts $m_i$ and total read counts $n_i$, along with covariates disease status $D_i$ (control $0$, disease $1$), age $A_i$ (in years), and batch $B_i$ (categorical: A, B, or C). Assume the following fundamental base in molecular and immunodiagnostics for methylation proportion modeling: each $m_i$ is distributed as a binomial random variable given $n_i$ and a methylation probability $p_i$, written as $m_i \\sim \\mathrm{Binomial}(n_i,p_i)$, where the methylation proportion is $p_i \\in (0,1)$ expressed as a decimal. Let the covariate effects on the methylation probability be linked through a generalized linear model with a logit link, defined by $\\mathrm{logit}(p_i)=\\log\\left(\\frac{p_i}{1-p_i}\\right)=\\mathbf{x}_i^\\top\\boldsymbol{\\beta}$, where the design vector $\\mathbf{x}_i$ includes an intercept, $D_i$, $A_i$, and batch indicators for $B_i$ with batch B as the reference category. Use dummy variables such that $\\mathbf{x}_i=[1,D_i,A_i,\\mathbb{I}(B_i=\\mathrm{A}),\\mathbb{I}(B_i=\\mathrm{C})]$.\n\nYour task is to fit the generalized linear model by maximum likelihood estimation for the three test cases below, and for each case compute the following quantities that allow interpretation of the disease coefficient:\n- The estimated disease-status coefficient $\\hat{\\beta}_{\\mathrm{disease}}$ (a float).\n- The disease-status odds ratio $\\exp(\\hat{\\beta}_{\\mathrm{disease}})$ (a float).\n- The two-sided Wald test $p$-value for $\\hat{\\beta}_{\\mathrm{disease}}$ under a standard normal approximation (a float), reported as a decimal.\n- A boolean indicating whether disease increases methylation probability, defined as $\\exp(\\hat{\\beta}_{\\mathrm{disease}})1$.\n- The difference in predicted methylation probability at a fixed reference covariate configuration with age $A^\\ast$ and batch B, equal to $\\Delta p = \\sigma(\\hat{\\beta}_0+\\hat{\\beta}_A A^\\ast+\\hat{\\beta}_{\\mathrm{disease}})-\\sigma(\\hat{\\beta}_0+\\hat{\\beta}_A A^\\ast)$, where $\\sigma(z)=\\frac{1}{1+\\exp(-z)}$, $A^\\ast$ is fixed at $60$, and the batch indicators for A and C are set to $0$ to represent the batch B reference. Report $\\Delta p$ as a decimal.\n\nFollow these universal modeling instructions:\n- Use the binomial model $m_i \\sim \\mathrm{Binomial}(n_i,p_i)$ with the canonical logit link $\\mathrm{logit}(p_i)=\\mathbf{x}_i^\\top\\boldsymbol{\\beta}$.\n- Construct the design matrix with an intercept and the specified covariates, treating batch B as the reference so that its dummy variables are $0$.\n- Fit the model by maximum likelihood and obtain the asymptotic variance of $\\hat{\\boldsymbol{\\beta}}$ from the observed Fisher information at the solution.\n- Compute the Wald statistic for the disease coefficient as $z=\\hat{\\beta}_{\\mathrm{disease}}/\\mathrm{SE}(\\hat{\\beta}_{\\mathrm{disease}})$ and the two-sided $p$-value using the standard normal distribution.\n\nAll methylation proportions must be handled as decimals (not in percent form). There are no angle quantities in this task. The final program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets. Each test case’s result should itself be a list in the order $[\\hat{\\beta}_{\\mathrm{disease}},\\exp(\\hat{\\beta}_{\\mathrm{disease}}),p\\text{-value},\\text{boolean},\\Delta p]$.\n\nTest suite:\n\nTest case $1$ (moderate coverage, balanced groups):\n- $m=\\{\\,38,55,39,54,41,88,38,60,45,66,24,56\\,\\}$\n- $n=\\{\\,100,95,110,100,90,120,80,100,85,100,75,95\\,\\}$\n- $D=\\{\\,0,1,0,1,0,1,0,1,0,1,0,1\\,\\}$\n- $A=\\{\\,50,52,60,58,45,65,70,55,62,48,52,68\\,\\}$\n- $B=\\{\\,\\mathrm{B},\\mathrm{B},\\mathrm{A},\\mathrm{A},\\mathrm{C},\\mathrm{C},\\mathrm{B},\\mathrm{B},\\mathrm{C},\\mathrm{C},\\mathrm{A},\\mathrm{A}\\,\\}$\n\nTest case $2$ (small counts, boundary behavior including zero successes):\n- $m=\\{\\,6,4,1,0,36,30,2,1\\,\\}$\n- $n=\\{\\,20,20,5,2,50,50,10,10\\,\\}$\n- $D=\\{\\,0,1,0,1,0,1,0,1\\,\\}$\n- $A=\\{\\,40,40,30,30,70,70,25,25\\,\\}$\n- $B=\\{\\,\\mathrm{B},\\mathrm{B},\\mathrm{A},\\mathrm{A},\\mathrm{C},\\mathrm{C},\\mathrm{B},\\mathrm{B}\\,\\}$\n\nTest case $3$ (strong disease effect, high coverage, non-reference batch variation):\n- $m=\\{\\,31,67,18,46,44,86,31,63,25,46\\,\\}$\n- $n=\\{\\,100,100,80,80,120,120,90,90,60,60\\,\\}$\n- $D=\\{\\,0,1,0,1,0,1,0,1,0,1\\,\\}$\n- $A=\\{\\,60,60,50,50,55,55,45,45,35,35\\,\\}$\n- $B=\\{\\,\\mathrm{B},\\mathrm{B},\\mathrm{A},\\mathrm{A},\\mathrm{C},\\mathrm{C},\\mathrm{B},\\mathrm{B},\\mathrm{C},\\mathrm{C}\\,\\}$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[\\,[r_{11},r_{12},r_{13},r_{14},r_{15}],\\,[r_{21},r_{22},r_{23},r_{24},r_{25}],\\,[r_{31},r_{32},r_{33},r_{34},r_{35}]\\,]$), where each $r_{jk}$ is a float or boolean in the order specified above for test case $j$ and metric $k$.", "solution": "The problem has been validated and is deemed sound. It is a well-posed, scientifically grounded, and computationally feasible task rooted in the standard biostatistical analysis of sequencing data. All necessary data and definitions are provided, and there are no internal contradictions.\n\nThe problem requires fitting a Generalized Linear Model (GLM) to bisulfite sequencing data to analyze the association between DNA methylation and disease status while adjusting for covariates. The core of the model is the assumption that the number of methylated reads $m_i$ for an individual $i$ follows a binomial distribution, $m_i \\sim \\mathrm{Binomial}(n_i, p_i)$, where $n_i$ is the total number of reads and $p_i$ is the unknown probability of methylation at a specific CpG site.\n\n**Model Specification**\nThe relationship between the methylation probability $p_i$ and a set of covariates is modeled via a link function. The specified model is a binomial GLM with a logit link function, which is the canonical link for the binomial family and ensures that the predicted probabilities $p_i$ are constrained to the interval $(0, 1)$. The model is defined as:\n$$\n\\mathrm{logit}(p_i) = \\log\\left(\\frac{p_i}{1-p_i}\\right) = \\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}\n$$\nHere, $\\eta_i$ is the linear predictor for the $i$-th observation. The vector of covariates $\\mathbf{x}_i$ is given by $\\mathbf{x}_i = [1, D_i, A_i, \\mathbb{I}(B_i=\\mathrm{A}), \\mathbb{I}(B_i=\\mathrm{C})]^\\top$, where $1$ is for the intercept, $D_i$ is the disease status ($0$ or $1$), $A_i$ is the age, and $\\mathbb{I}(\\cdot)$ are indicator functions for batch effects, with batch B serving as the reference category. The corresponding vector of coefficients to be estimated is $\\boldsymbol{\\beta} = [\\beta_0, \\beta_{\\mathrm{disease}}, \\beta_A, \\beta_{B=\\mathrm{A}}, \\beta_{B=\\mathrm{C}}]^\\top$.\n\nThe inverse of the logit link function is the logistic sigmoid function, $\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$, which maps the linear predictor back to the probability scale: $p_i = \\sigma(\\eta_i)$.\n\n**Maximum Likelihood Estimation (MLE)**\nThe coefficients $\\boldsymbol{\\beta}$ are estimated by maximizing the log-likelihood function. The log-likelihood for $N$ independent observations is:\n$$\n\\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^N \\left( \\log\\binom{n_i}{m_i} + m_i \\log(p_i) + (n_i - m_i) \\log(1-p_i) \\right)\n$$\nSubstituting $p_i = \\sigma(\\mathbf{x}_i^\\top \\boldsymbol{\\beta})$, and after some algebraic simplification, the log-likelihood function in terms of $\\boldsymbol{\\beta}$ becomes:\n$$\n\\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{i=1}^N \\left( \\log\\binom{n_i}{m_i} + m_i(\\mathbf{x}_i^\\top \\boldsymbol{\\beta}) - n_i \\log(1 + \\exp(\\mathbf{x}_i^\\top \\boldsymbol{\\beta})) \\right)\n$$\nThe maximum likelihood estimate $\\hat{\\boldsymbol{\\beta}}$ is the value of $\\boldsymbol{\\beta}$ that maximizes this function. As the log-likelihood for a GLM with a canonical link is concave, a unique maximum exists. This maximization is performed numerically, typically using an iterative algorithm like Newton-Raphson or Iteratively Reweighted Least Squares (IRLS). These methods require the gradient (score vector) and the Hessian matrix of the log-likelihood function.\n\nThe gradient is given by:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\beta}} = \\sum_{i=1}^N (m_i - n_i p_i) \\mathbf{x}_i = \\mathbf{X}^\\top (\\mathbf{m} - n\\mathbf{p})\n$$\nThe Hessian matrix is:\n$$\n\\mathbf{H}(\\boldsymbol{\\beta}) = \\frac{\\partial^2 \\mathcal{L}}{\\partial \\boldsymbol{\\beta} \\partial \\boldsymbol{\\beta}^\\top} = -\\sum_{i=1}^N n_i p_i (1 - p_i) \\mathbf{x}_i \\mathbf{x}_i^\\top = -\\mathbf{X}^\\top \\mathbf{W} \\mathbf{X}\n$$\nwhere $\\mathbf{X}$ is the design matrix with rows $\\mathbf{x}_i^\\top$, and $\\mathbf{W}$ is a diagonal matrix with diagonal elements $W_{ii} = n_i p_i (1-p_i)$.\n\n**Inference and Calculation of Required Quantities**\nOnce the MLE $\\hat{\\boldsymbol{\\beta}}$ is obtained, we can perform statistical inference. The asymptotic variance-covariance matrix of the estimator is the inverse of the observed Fisher information matrix, $\\mathcal{I}(\\hat{\\boldsymbol{\\beta}})$, evaluated at the solution:\n$$\n\\mathrm{Var}(\\hat{\\boldsymbol{\\beta}}) \\approx \\mathcal{I}(\\hat{\\boldsymbol{\\beta}})^{-1} = (-\\mathbf{H}(\\hat{\\boldsymbol{\\beta}}))^{-1} = (\\mathbf{X}^\\top \\mathbf{W}(\\hat{\\boldsymbol{\\beta}}) \\mathbf{X})^{-1}\n$$\nThe standard error of an individual coefficient estimate, $\\mathrm{SE}(\\hat{\\beta}_j)$, is the square root of the corresponding diagonal element of this variance-covariance matrix.\n\nThe required quantities are then computed as follows:\n1.  **Estimated disease coefficient ($\\hat{\\beta}_{\\mathrm{disease}}$)**: This is the second element of the estimated vector $\\hat{\\boldsymbol{\\beta}}$.\n2.  **Odds ratio ($\\exp(\\hat{\\beta}_{\\mathrm{disease}})$)**: This represents the factor by which the odds of methylation change for a subject with the disease ($D=1$) compared to a control subject ($D=0$), holding all other covariates constant.\n3.  **Wald test $p$-value**: The two-sided Wald test statistic for the null hypothesis $H_0: \\beta_{\\mathrm{disease}}=0$ is $z = \\hat{\\beta}_{\\mathrm{disease}} / \\mathrm{SE}(\\hat{\\beta}_{\\mathrm{disease}})$. Under the null hypothesis, this statistic follows a standard normal distribution. The $p$-value is calculated as $p = 2 \\cdot (1 - \\Phi(|z|))$, where $\\Phi$ is the cumulative distribution function of the standard normal distribution.\n4.  **Boolean for effect direction**: This is simply $\\exp(\\hat{\\beta}_{\\mathrm{disease}})  1$. If true, the disease is associated with an increase in the odds of methylation.\n5.  **Difference in predicted methylation probability ($\\Delta p$)**: This is calculated at a fixed reference profile: age $A^\\ast=60$ and batch B. For this profile, the linear predictors for a diseased and a control individual are $\\eta_{1} = \\hat{\\beta}_0 + \\hat{\\beta}_{\\mathrm{disease}} + 60\\hat{\\beta}_A$ and $\\eta_{0} = \\hat{\\beta}_0 + 60\\hat{\\beta}_A$, respectively. The difference in predicted probabilities is then $\\Delta p = \\sigma(\\eta_{1}) - \\sigma(\\eta_{0})$.\n\nThe following computational procedure will be applied to each test case to derive the final results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the DNA methylation GLM problem for three test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (moderate coverage, balanced groups):\n        {\n            \"m\": [38, 55, 39, 54, 41, 88, 38, 60, 45, 66, 24, 56],\n            \"n\": [100, 95, 110, 100, 90, 120, 80, 100, 85, 100, 75, 95],\n            \"D\": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n            \"A\": [50, 52, 60, 58, 45, 65, 70, 55, 62, 48, 52, 68],\n            \"B\": ['B', 'B', 'A', 'A', 'C', 'C', 'B', 'B', 'C', 'C', 'A', 'A']\n        },\n        # Test case 2 (small counts, boundary behavior including zero successes):\n        {\n            \"m\": [6, 4, 1, 0, 36, 30, 2, 1],\n            \"n\": [20, 20, 5, 2, 50, 50, 10, 10],\n            \"D\": [0, 1, 0, 1, 0, 1, 0, 1],\n            \"A\": [40, 40, 30, 30, 70, 70, 25, 25],\n            \"B\": ['B', 'B', 'A', 'A', 'C', 'C', 'B', 'B']\n        },\n        # Test case 3 (strong disease effect, high coverage, non-reference batch variation):\n        {\n            \"m\": [31, 67, 18, 46, 44, 86, 31, 63, 25, 46],\n            \"n\": [100, 100, 80, 80, 120, 120, 90, 90, 60, 60],\n            \"D\": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n            \"A\": [60, 60, 50, 50, 55, 55, 45, 45, 35, 35],\n            \"B\": ['B', 'B', 'A', 'A', 'C', 'C', 'B', 'B', 'C', 'C']\n        }\n    ]\n\n    results = []\n    for case_data in test_cases:\n        m_vec = np.array(case_data[\"m\"])\n        n_vec = np.array(case_data[\"n\"])\n        D_vec = np.array(case_data[\"D\"])\n        A_vec = np.array(case_data[\"A\"])\n        B_cat = case_data[\"B\"]\n\n        # 1. Construct the design matrix X\n        num_obs = len(m_vec)\n        X = np.zeros((num_obs, 5))\n        X[:, 0] = 1  # Intercept\n        X[:, 1] = D_vec  # Disease status\n        X[:, 2] = A_vec  # Age\n        X[:, 3] = np.array([1 if b == 'A' else 0 for b in B_cat])  # Batch A\n        X[:, 4] = np.array([1 if b == 'C' else 0 for b in B_cat])  # Batch C\n\n        # 2. Define objective function (negative log-likelihood), gradient, and Hessian\n        def neg_log_likelihood(beta, X, m, n):\n            eta = X @ beta\n            # Use logaddexp for numerical stability: log(1 + exp(eta))\n            log_p_denom = np.logaddexp(0, eta)\n            log_lik = m * eta - n * log_p_denom\n            return -np.sum(log_lik)\n\n        def gradient(beta, X, m, n):\n            eta = X @ beta\n            p = 1 / (1 + np.exp(-eta))\n            # grad is sum over i of (n_i * p_i - m_i) * x_i\n            grad = (n * p - m) @ X\n            return grad\n\n        def hessian(beta, X, m, n):\n            eta = X @ beta\n            p = 1 / (1 + np.exp(-eta))\n            w = n * p * (1 - p)\n            W = np.diag(w)\n            hess = X.T @ W @ X\n            return hess\n\n        # 3. Perform optimization to find MLE for beta\n        initial_beta = np.zeros(X.shape[1])\n        opt_res = minimize(\n            fun=neg_log_likelihood,\n            x0=initial_beta,\n            args=(X, m_vec, n_vec),\n            method='Newton-CG',\n            jac=gradient,\n            hess=hessian,\n            options={'xtol': 1e-8, 'disp': False}\n        )\n        beta_hat = opt_res.x\n\n        # 4. Calculate the required quantities\n        # Estimated disease coefficient\n        beta_disease = beta_hat[1]\n\n        # Asymptotic covariance matrix\n        fisher_info_matrix = hessian(beta_hat, X, m_vec, n_vec)\n        cov_matrix = np.linalg.inv(fisher_info_matrix)\n        \n        # Standard error for the disease coefficient\n        se_beta_disease = np.sqrt(cov_matrix[1, 1])\n        \n        # Two-sided Wald test\n        wald_z_statistic = beta_disease / se_beta_disease\n        p_value = 2 * norm.sf(np.abs(wald_z_statistic))\n        \n        # Odds ratio\n        odds_ratio = np.exp(beta_disease)\n        \n        # Boolean indicating if methylation increases with disease\n        increases_methylation = odds_ratio > 1\n\n        # Difference in predicted methylation probability\n        def sigmoid(z):\n            return 1 / (1 + np.exp(-z))\n        \n        age_star = 60.0\n        # Linear predictors for a reference individual (Batch B, Age=60)\n        # beta_hat[0] is intercept, [1] is disease, [2] is age\n        eta_control = beta_hat[0] + beta_hat[2] * age_star\n        eta_disease = beta_hat[0] + beta_hat[1] + beta_hat[2] * age_star\n        \n        p_control = sigmoid(eta_control)\n        p_disease = sigmoid(eta_disease)\n        delta_p = p_disease - p_control\n        \n        case_result = [\n            float(beta_disease),\n            float(odds_ratio),\n            float(p_value),\n            bool(increases_methylation),\n            float(delta_p)\n        ]\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "5109769"}, {"introduction": "When scaling up from single CpG sites to an epigenome-wide association study (EWAS), the primary analytical challenge becomes navigating confounding. Variables like age, sex, and especially the mixture of different cell types in a tissue sample can be associated with both disease and methylation, creating spurious results if not properly handled. This final practice challenges you to think like an epidemiologist, evaluating various statistical and study design strategies to disentangle true disease signals from the noise of confounding, a crucial step for ensuring the validity of your findings [@problem_id:5109766].", "problem": "A research group is conducting a cross-sectional case-control study of DNA methylation in a systemic autoimmune disease using whole blood Illumina arrays, measuring fractional methylation at cytosine–phosphate–guanine (CpG) dinucleotides as $\\beta$-values. The sample consists of $ n = 300 $ adults, with $ n_D = 150 $ cases and $ 150 $ controls. The disease indicator is $ D_i \\in \\{0,1\\} $, chronological age is $ A_i $ in years, sex is $ S_i \\in \\{0,1\\} $ for female/male, and cell composition is represented by $ C_{ik} $ for $ k = 1,\\dots,K $ leukocyte subtypes (e.g., CD4 T cells, CD8 T cells, B cells, monocytes, neutrophils), with $ \\sum_{k=1}^{K} C_{ik} = 1 $ per individual. The group aims to identify disease-associated, cell-intrinsic differential methylation on autosomes, independent of age, sex, and cellular heterogeneity.\n\nExploratory analysis reveals the following characteristics: cases are older on average ($ \\overline{A}_{\\text{cases}} - \\overline{A}_{\\text{controls}} \\approx 8 $ years), the proportion of females is higher among cases ($ P(S=1 \\mid D=1) \\approx 0.70 $ versus $ P(S=1 \\mid D=0) \\approx 0.50 $), and cell-type proportions differ (e.g., higher neutrophil fraction in cases, lower CD4 T cell fraction). A naive per-CpG two-sample comparison of $\\beta$-values between cases and controls (ignoring $ A_i $, $ S_i $, and $ C_{ik} $) yields widespread differences enriched near loci previously reported to have strong age associations.\n\nThe study’s inferential target is the average difference in methylation attributable to $ D_i $ at each autosomal CpG, for individuals with matched age, sex, and comparable cell-type composition. Based on fundamental definitions, a variable is a confounder if it is associated with both the exposure of interest and the outcome, and omission of confounders in regression induces bias in the estimate of the exposure effect. To design and analyze the study in a scientifically sound way, the team must identify biological confounders and propose strategies that control their effects while preserving the disease signal that reflects cell-intrinsic changes.\n\nWhich of the following strategies are appropriate to control biological confounding by age, sex, and cell composition under the stated target and data structure?\n\nA. Fit per-CpG linear regression models with methylation $ Y_{ij} $ as outcome and include chronological age $ A_i $, sex $ S_i $, and cell-type proportions $ C_{ik} $ (estimated by a reference-based deconvolution method using leukocyte reference methylomes) as covariates, with $ D_i $ as the variable of interest.\n\nB. Remove all CpG probes on sex chromosomes from the analysis to eliminate sex-related effects, and do not include sex in the model to avoid over-adjustment for autosomal sex differences.\n\nC. At the design stage, match cases and controls on chronological age $ A_i $ and sex $ S_i $ (pairwise or frequency matching). In analysis, include residual imbalances in $ A_i $ and $ S_i $ as covariates, and adjust for cell-type composition via deconvolution-derived $ C_{ik} $.\n\nD. Apply Surrogate Variable Analysis (SVA), specifying $ D_i $ as the variable of interest to be preserved, estimate $ K' $ surrogate variables that capture unmeasured heterogeneity (e.g., cell composition and other unwanted variation), and include them as covariates alongside $ D_i $ in per-CpG models.\n\nE. Exclude CpGs reported in prior literature as age-associated and proceed with unadjusted case-control comparisons of $\\beta$-values, arguing this removes age confounding without further adjustment for $ A_i $.\n\nF. Estimate inverse probability weights $ w_i \\propto 1 / P(A_i, S_i, C_{i\\cdot} \\mid D_i) $ from a multinomial or factorized model of $ (A_i, S_i, C_{i\\cdot}) $ given $ D_i $, and fit weighted per-CpG regression of methylation on $ D_i $ to balance the distributions of $ A_i $, $ S_i $, and $ C_{ik} $ across disease groups.\n\nSelect all that apply.", "solution": "The problem statement has been validated and found to be scientifically sound, well-posed, and objective. It describes a canonical scenario in epigenome-wide association studies (EWAS) and asks for appropriate statistical strategies to address known sources of confounding.\n\n### Step 1: Extract Givens\n- **Study Design:** Cross-sectional case-control study.\n- **Population:** $n = 300$ adults, with $n_D = 150$ cases and $n_{controls} = 150$ controls.\n- **Outcome:** Fractional DNA methylation ($\\beta$-values) at CpG sites from whole blood Illumina arrays. Let's denote this as $Y_{ij}$ for individual $i$ and CpG $j$.\n- **Exposure:** Disease indicator $D_i \\in \\{0, 1\\}$.\n- **Potential Confounders:**\n    - Chronological age $A_i$ in years.\n    - Sex $S_i \\in \\{0, 1\\}$ (female/male).\n    - Cell composition $C_{ik}$ for $k=1, \\dots, K$ leukocyte subtypes, where $\\sum_{k=1}^{K} C_{ik} = 1$.\n- **Observed Imbalances:**\n    - Age: $\\overline{A}_{\\text{cases}} - \\overline{A}_{\\text{controls}} \\approx 8$ years.\n    - Sex: $P(S=1 \\mid D=1) \\approx 0.70$ versus $P(S=1 \\mid D=0) \\approx 0.50$.\n    - Cell Composition: Proportions differ between cases and controls.\n- **Inferential Target:** To identify disease-associated, cell-intrinsic differential methylation on autosomes, independent of age, sex, and cellular heterogeneity. This means estimating the effect of $D_i$ on $Y_{ij}$ while holding $A_i$, $S_i$, and $C_{ik}$ constant.\n- **Confounder Definition:** A variable is a confounder if it is associated with both the exposure ($D_i$) and the outcome ($Y_{ij}$) and its omission leads to bias.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is valid.\n- **Scientifically Grounded:** The setup is a standard representation of an EWAS. Confounding by age, sex, and cell-type composition are the most critical and widely recognized challenges in blood-based DNA methylation studies. The described methods and concepts are central to modern molecular epidemiology and biostatistics.\n- **Well-Posed:** The objective is clearly defined: estimate the effect of disease on methylation, adjusted for specified confounders. This is a well-defined statistical estimation problem.\n- **Objective:** The problem is described using precise, objective, and standard scientific terminology. There are no subjective or ambiguous statements.\n\nThe problem requires evaluating different statistical strategies for controlling confounding, a core task in observational research.\n\n### Solution Derivation\n\nThe primary goal is to obtain an unbiased estimate of the association between disease status $D_i$ and methylation $Y_{ij}$ at autosomal CpGs. The problem explicitly states that age ($A_i$), sex ($S_i$), and cell composition ($C_{ik}$) are associated with both the disease status and methylation. Therefore, they are confounders. A valid analytical strategy must account for the confounding effects of $A_i$, $S_i$, and $C_{ik}$ to isolate the \"cell-intrinsic\" effect of $D_i$.\n\nLet's evaluate each proposed strategy against this principle.\n\n**A. Fit per-CpG linear regression models with methylation $Y_{ij}$ as outcome and include chronological age $A_i$, sex $S_i$, and cell-type proportions $C_{ik}$ (estimated by a reference-based deconvolution method using leukocyte reference methylomes) as covariates, with $D_i$ as the variable of interest.**\n\nThis strategy proposes a multivariable linear regression model of the form:\n$$ Y_{ij} = \\beta_{0j} + \\beta_{Dj} D_i + \\beta_{Aj} A_i + \\beta_{Sj} S_i + \\sum_{k=1}^{K-1} \\gamma_{kj} C_{ik} + \\epsilon_{ij} $$\n(Note: we only include $K-1$ cell types to avoid perfect multicollinearity, as $\\sum_{k=1}^{K} C_{ik} = 1$).\nIn this model, the coefficient $\\beta_{Dj}$ represents the expected change in methylation $Y_{ij}$ for a unit change in $D_i$ (i.e., comparing cases to controls), while holding $A_i$, $S_i$, and $C_{ik}$ statistically constant. This directly estimates the disease association adjusted for the known confounders. The use of reference-based deconvolution to estimate cell-type proportions is the standard method for this purpose. This is the most common and accepted approach for EWAS analysis.\n\n**Verdict: Correct.** This is a standard, robust, and appropriate method for confounding adjustment in this context.\n\n**B. Remove all CpG probes on sex chromosomes from the analysis to eliminate sex-related effects, and do not include sex in the model to avoid over-adjustment for autosomal sex differences.**\n\nRemoving probes on sex chromosomes is a standard pre-processing step when the analysis focus is on autosomes, as stated in the problem's objective. However, the second part of the statement is fundamentally incorrect. Sex is a confounder in this study: it is associated with disease status ($P(S=1|D=1) \\neq P(S=1|D=0)$) and is known to influence methylation patterns on autosomes (e.g., via hormonal environments, differential expression of autosomal genes). Failing to include sex ($S_i$) as a covariate in the model for autosomal CpGs would result in omitted-variable bias. The estimate for the disease effect would be contaminated by the effect of the sex imbalance between cases and controls. The concern about \"over-adjustment\" is misplaced; sex is a common cause of both disease risk and autosomal methylation patterns, not a mediator on the causal pathway from disease to methylation.\n\n**Verdict: Incorrect.** This strategy fails to properly control for confounding by sex.\n\n**C. At the design stage, match cases and controls on chronological age $A_i$ and sex $S_i$ (pairwise or frequency matching). In analysis, include residual imbalances in $A_i$ and $S_i$ as covariates, and adjust for cell-type composition via deconvolution-derived $C_{ik}$.**\n\nThis describes a powerful two-part strategy.\n1.  **Design:** Matching on strong, known confounders like age and sex is an excellent design choice. It breaks the association between these confounders and the exposure (disease status) in the sample, reducing the potential for bias and increasing statistical efficiency.\n2.  **Analysis:** Since matching is rarely perfect, it is best practice to additionally adjust for any residual differences in the matched variables ($A_i$ and $S_i$) in the final regression model. Additionally, cell-type composition ($C_{ik}$), which was not matched, must be included as a covariate to meet the inferential goal of identifying cell-intrinsic effects. This combined approach is considered a gold standard in epidemiology.\n\n**Verdict: Correct.** This is a highly appropriate and robust strategy for controlling confounding.\n\n**D. Apply Surrogate Variable Analysis (SVA), specifying $D_i$ as the variable of interest to be preserved, estimate $K'$ surrogate variables that capture unmeasured heterogeneity (e.g., cell composition and other unwanted variation), and include them as covariates alongside $D_i$ in per-CpG models.**\n\nSurrogate Variable Analysis (SVA) is a method specifically designed for high-dimensional data like EWAS to identify and adjust for sources of \"unwanted variation.\" This variation can include known but unmeasured confounders (like cell composition if no reference is used), unknown confounders (e.g., genetic ancestry, diet), and technical artifacts (e.g., batch effects). SVA estimates surrogate variables (SVs) that capture these major sources of variation in the data, orthogonal to the primary variable of interest ($D_i$). Including these SVs as covariates in the regression model, $Y_{ij} = \\beta_{0j} + \\beta_{Dj} D_i + \\sum_{l=1}^{K'} \\delta_{lj} SV_{il} + \\epsilon_{ij}$, effectively adjusts for these latent confounding factors. In the context of this problem, the SVs would likely capture the strong signals from cell composition heterogeneity, as well as potential age and sex effects and other batch effects, thereby \"cleaning\" the estimate of the disease effect $\\beta_{Dj}$.\n\n**Verdict: Correct.** SVA is a widely used and appropriate data-driven method for controlling complex confounding in EWAS.\n\n**E. Exclude CpGs reported in prior literature as age-associated and proceed with unadjusted case-control comparisons of $\\beta$-values, arguing this removes age confounding without further adjustment for $A_i$.**\n\nThis strategy is fundamentally flawed and misunderstands the nature of confounding. Confounding arises from an association between a confounder (age) and the exposure (disease) within the study sample. This association will bias the estimated effect of the exposure on *any* outcome, regardless of whether that outcome has a known prior association with the confounder. Filtering out a subset of outcomes (CpGs) does not remove the confounding relationship present in the data. An unadjusted comparison for the remaining CpGs will still be biased by the age difference between cases and controls. Furthermore, this approach may discard CpGs where methylation is genuinely affected by both age and the disease, leading to a loss of true findings. This strategy also completely ignores confounding by sex and cell composition.\n\n**Verdict: Incorrect.** This is a statistically invalid approach to handling confounding.\n\n**F. Estimate inverse probability weights $w_i \\propto 1 / P(A_i, S_i, C_{i\\cdot} \\mid D_i)$ from a multinomial or factorized model of $(A_i, S_i, C_{i\\cdot})$ given $D_i$, and fit weighted per-CpG regression of methylation on $D_i$ to balance the distributions of $A_i$, $S_i$, and $C_{ik}$ across disease groups.**\n\nThis describes a causal inference technique using inverse probability weighting (IPW). The goal of weighting is to create a pseudo-population where the distributions of the confounders ($A_i$, $S_i$, $C_{ik}$) are independent of the exposure ($D_i$). The proposed weight, $w_i \\propto 1 / P(\\text{Confounders}_i \\mid D_i)$, is a valid type of \"balancing weight\". By weighting each observation $i$ by the inverse of the probability of observing its confounder profile within its own disease group, the weighted distributions of the confounders are made to be the same (e.g., uniform over their support) across the case and control groups. Running a weighted regression of the outcome on the exposure using these weights yields an estimate of the exposure effect that is adjusted for the confounding variables used to construct the weights. This is an advanced but valid alternative to direct covariate adjustment in a regression model.\n\n**Verdict: Correct.** This is a statistically valid strategy for controlling for confounding by age, sex, and cell composition.", "answer": "$$\\boxed{ACDF}$$", "id": "5109766"}]}