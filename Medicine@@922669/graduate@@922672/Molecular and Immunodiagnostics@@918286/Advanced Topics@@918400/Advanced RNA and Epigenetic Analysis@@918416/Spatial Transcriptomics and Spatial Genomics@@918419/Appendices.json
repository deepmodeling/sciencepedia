{"hands_on_practices": [{"introduction": "This first practice grounds us in the experimental reality of high-resolution spatial genomics. We will explore the trade-offs between desired feature resolution, sample area, and total imaging time by calculating the key parameters for a tiled microscopy experiment [@problem_id:5164024]. This exercise highlights how fundamental principles like the Nyquist sampling theorem directly impact experimental design and resource planning.", "problem": "A spatially resolved transcriptomic (SRT) assay is performed on a square tissue section of area $A$ to localize messenger ribonucleic acid (mRNA) transcripts with subcellular precision using widefield fluorescence imaging. To ensure reliable detection of the smallest target features (for example, hybridization spots), the sampling must obey the Nyquist sampling theorem: a feature of minimal characteristic size $f$ is detectable only if the specimen-plane pixel size $p$ satisfies $p \\leq f/2$. The imaging system consists of a scientific complementary metal-oxide-semiconductor (sCMOS) camera with $N_x \\times N_y$ pixels and an objective such that the specimen-plane pixel size is $p$. The field of view (FOV) is a rectangle of width $W = N_x p$ and height $H = N_y p$. A fractional overlap $\\beta$ of adjacent tiles along both axes is required to ensure robust mosaic registration and illumination flat-fielding, so the mosaic pitch is $p_x = (1 - \\beta) W$ horizontally and $p_y = (1 - \\beta) H$ vertically. The stage executes a serpentine scan: in each row of $n_x$ tiles, the stage traverses $(n_x - 1)$ horizontal pitch steps; between rows, it performs one vertical pitch step. The total stage-travel length is the sum of all horizontal and vertical pitch traversals. The stage moves at speed $v$. Each tile acquisition consists of $c$ sequential fluorescent channels, each with exposure time $t_{\\exp}$ and per-channel readout time $t_{\\mathrm{read}}$, plus a single per-tile focus-lock update time $t_{\\mathrm{focus}}$ and a per-tile stabilization time $t_{\\mathrm{stab}}$. At each row reversal, an additional reversal overhead $t_{\\mathrm{rev}}$ is incurred. The total imaging time is the sum of capture time over all tiles and the stage travel time, plus row-reversal overheads.\n\nUsing the following parameters, compute the total number of tiles and the total imaging time:\n- Desired minimal detectable feature size $f = 2\\,\\mu\\mathrm{m}$.\n- Tissue area $A = 100\\,\\mathrm{mm}^2$ and the tissue is square with side length $\\sqrt{A}$.\n- Camera pixel count $N_x = N_y = 2048$.\n- Specimen-plane pixel size $p = 0.325\\,\\mu\\mathrm{m}$.\n- Tile overlap $\\beta = 0.10$ along both axes.\n- Stage speed $v = 40\\,\\mathrm{mm}\\,\\mathrm{s}^{-1}$.\n- Number of fluorescence channels per tile $c = 4$.\n- Per-channel exposure time $t_{\\exp} = 0.200\\,\\mathrm{s}$ and per-channel readout time $t_{\\mathrm{read}} = 0.020\\,\\mathrm{s}$.\n- Per-tile focus-lock update $t_{\\mathrm{focus}} = 0.015\\,\\mathrm{s}$ and per-tile stabilization $t_{\\mathrm{stab}} = 0.005\\,\\mathrm{s}$.\n- Per row reversal overhead $t_{\\mathrm{rev}} = 0.010\\,\\mathrm{s}$.\n\nBegin from the sampling requirement above to verify that the provided $p$ is sufficient for $f$, then derive the number of tiles per row $n_x$ and per column $n_y$, the total number of tiles $N$, the total travel length of the serpentine path, and the total imaging time in hours. For the imaging time, express the final answer in hours and round to four significant figures. Report the number of tiles as an exact integer. The final answer must contain only two values: the total number of tiles and the total imaging time in hours.", "solution": "The problem statement is evaluated and found to be valid. It is scientifically grounded in the principles of fluorescence microscopy and automated imaging, well-posed with a complete and consistent set of parameters, and presented in an objective, formal manner. A unique solution can be derived through a systematic application of the provided definitions and formulas.\n\nThe solution proceeds in several steps: verification of the sampling criterion, calculation of the imaging field of view (FOV) and mosaic parameters, determination of the number of tiles required to cover the tissue area, and finally, calculation of the total imaging time by summing the acquisition, travel, and overhead time components.\n\nFirst, we verify that the Nyquist sampling criterion is met. The minimal detectable feature size is given as $f = 2\\,\\mu\\mathrm{m}$. The theorem requires that the specimen-plane pixel size, $p$, satisfies the condition $p \\leq f/2$.\nGiven $p = 0.325\\,\\mu\\mathrm{m}$, we compute the required maximum pixel size:\n$$ \\frac{f}{2} = \\frac{2\\,\\mu\\mathrm{m}}{2} = 1\\,\\mu\\mathrm{m} $$\nThe condition is $0.325\\,\\mu\\mathrm{m} \\leq 1\\,\\mu\\mathrm{m}$, which is satisfied. Thus, the specified pixel size is adequate for the desired feature resolution.\n\nNext, we calculate the dimensions of the FOV. The camera sensor has $N_x = 2048$ pixels and $N_y = 2048$ pixels.\nThe FOV width is $W = N_x p$ and the height is $H = N_y p$.\n$$ W = H = 2048 \\times 0.325\\,\\mu\\mathrm{m} = 665.6\\,\\mu\\mathrm{m} $$\nFor consistency with other parameters given in millimeters, we convert this to $W = H = 0.6656\\,\\mathrm{mm}$.\nThe mosaic is constructed with a fractional overlap $\\beta = 0.10$. The distance between the centers of adjacent tiles, or the mosaic pitch, is:\n$$ p_x = (1 - \\beta) W = (1 - 0.10) \\times 0.6656\\,\\mathrm{mm} = 0.59904\\,\\mathrm{mm} $$\n$$ p_y = (1 - \\beta) H = (1 - 0.10) \\times 0.6656\\,\\mathrm{mm} = 0.59904\\,\\mathrm{mm} $$\n\nWe then determine the number of tiles needed to cover the square tissue section of area $A = 100\\,\\mathrm{mm}^2$. The side length of the tissue is $L_{\\text{tissue}} = \\sqrt{A} = \\sqrt{100\\,\\mathrm{mm}^2} = 10\\,\\mathrm{mm}$.\nThe total extent covered by $n_x$ tiles in the horizontal direction is $W + (n_x - 1)p_x$. This must be greater than or equal to $L_{\\text{tissue}}$.\n$$ W + (n_x - 1)p_x \\geq L_{\\text{tissue}} $$\nSolving for $n_x$:\n$$ n_x \\geq 1 + \\frac{L_{\\text{tissue}} - W}{p_x} $$\nSince $n_x$ must be an integer, we take the ceiling of the expression:\n$$ n_x = \\left\\lceil 1 + \\frac{10\\,\\mathrm{mm} - 0.6656\\,\\mathrm{mm}}{0.59904\\,\\mathrm{mm}} \\right\\rceil = \\left\\lceil 1 + \\frac{9.3344}{0.59904} \\right\\rceil = \\lceil 1 + 15.5823... \\rceil = \\lceil 16.5823... \\rceil = 17 $$\nSince the tissue, FOV, and overlap are symmetric, the number of tiles in the vertical direction is $n_y = 17$. The total number of tiles is $N$:\n$$ N = n_x \\times n_y = 17 \\times 17 = 289 $$\n\nFinally, we calculate the total imaging time, $T_{\\text{total}}$, which is the sum of the total capture time ($T_{\\text{capture}}$), total stage travel time ($T_{\\text{travel}}$), and total row-reversal overhead ($T_{\\text{rev}}$).\n$$ T_{\\text{total}} = T_{\\text{capture}} + T_{\\text{travel}} + T_{\\text{rev}} $$\n\nThe time to acquire a single tile, $t_{\\text{tile}}$, is:\n$$ t_{\\text{tile}} = c(t_{\\exp} + t_{\\mathrm{read}}) + t_{\\mathrm{focus}} + t_{\\mathrm{stab}} $$\n$$ t_{\\text{tile}} = 4(0.200\\,\\mathrm{s} + 0.020\\,\\mathrm{s}) + 0.015\\,\\mathrm{s} + 0.005\\,\\mathrm{s} = 4(0.220\\,\\mathrm{s}) + 0.020\\,\\mathrm{s} = 0.880\\,\\mathrm{s} + 0.020\\,\\mathrm{s} = 0.900\\,\\mathrm{s} $$\nThe total capture time for all $N$ tiles is:\n$$ T_{\\text{capture}} = N \\times t_{\\text{tile}} = 289 \\times 0.900\\,\\mathrm{s} = 260.1\\,\\mathrm{s} $$\n\nThe total stage travel length, $L_{\\text{travel}}$, for a serpentine scan path is the sum of all horizontal and vertical movements:\n$$ L_{\\text{travel}} = n_y(n_x - 1)p_x + (n_y - 1)p_y $$\n$$ L_{\\text{travel}} = 17(17 - 1)(0.59904\\,\\mathrm{mm}) + (17-1)(0.59904\\,\\mathrm{mm}) = (17 \\times 16 + 16) \\times 0.59904\\,\\mathrm{mm} $$\n$$ L_{\\text{travel}} = 288 \\times 0.59904\\,\\mathrm{mm} = 172.52352\\,\\mathrm{mm} $$\nWith a stage speed $v = 40\\,\\mathrm{mm}\\,\\mathrm{s}^{-1}$, the total travel time is:\n$$ T_{\\text{travel}} = \\frac{L_{\\text{travel}}}{v} = \\frac{172.52352\\,\\mathrm{mm}}{40\\,\\mathrm{mm}\\,\\mathrm{s}^{-1}} = 4.313088\\,\\mathrm{s} $$\n\nThe total row-reversal overhead involves $(n_y - 1)$ reversals, each incurring a time penalty $t_{\\mathrm{rev}} = 0.010\\,\\mathrm{s}$:\n$$ T_{\\text{rev}} = (n_y - 1)t_{\\mathrm{rev}} = (17 - 1) \\times 0.010\\,\\mathrm{s} = 16 \\times 0.010\\,\\mathrm{s} = 0.16\\,\\mathrm{s} $$\n\nThe total imaging time in seconds is:\n$$ T_{\\text{total}} = 260.1\\,\\mathrm{s} + 4.313088\\,\\mathrm{s} + 0.16\\,\\mathrm{s} = 264.573088\\,\\mathrm{s} $$\n\nThe problem requires the final answer in hours, rounded to four significant figures.\n$$ T_{\\text{total, hours}} = \\frac{264.573088\\,\\mathrm{s}}{3600\\,\\mathrm{s}/\\text{hour}} \\approx 0.07349252...\\,\\text{hours} $$\nRounding to four significant figures gives $0.07349$ hours.\n\nThe final two quantities are the total number of tiles, $N=289$, and the total imaging time in hours, $0.07349$.", "answer": "$$ \\boxed{\\begin{pmatrix} 289 & 0.07349 \\end{pmatrix}} $$", "id": "5164024"}, {"introduction": "Moving from data acquisition to data properties, this exercise tackles a core challenge in array-based spatial transcriptomics: signal mixing from multiple cells. Using principles from stochastic geometry, we will derive a model for the expected number of cells contributing to a single capture spot [@problem_id:5163993]. This theoretical practice is essential for building an intuition for data complexity and appreciating the need for downstream computational deconvolution.", "problem": "In a spatially resolved gene expression assay such as Spatial Transcriptomics (ST), a tissue section is placed on an array of circular capture spots of diameter $d_{s}$ that collect messenger ribonucleic acid (mRNA) from any cell body that geometrically intersects a spot. Consider a two-dimensional tissue layer where cells are modeled as non-overlapping circular disks with random diameters $D$. Assume:\n- Cell centers follow a homogeneous Poisson point process (PPP) in two dimensions with intensity $n$ (cells per unit area).\n- The cell body diameter $D$ is an independent random variable with probability distribution having finite first and second moments.\n- The cellular area fraction (areal packing fraction) of the tissue is $\\phi \\in (0,1)$, defined as the fraction of area occupied by cells.\n- A cell contributes to a spot’s multiplicity if and only if its disk intersects the spot’s disk.\n\nUsing only foundational definitions for homogeneous PPPs, linearity of expectation, and standard results on the area of Minkowski dilations (Steiner’s formula for convex sets), perform the following:\n\n1. Derive an analytic expression for the expected cell multiplicity per spot, $\\mathbb{E}[M]$, as a function of $d_{s}$, $\\phi$, and the first two moments of $D$. Your derivation should start from:\n   - The PPP definition that the expected count in a region equals intensity times area.\n   - The relationship between intensity $n$ and the packing fraction $\\phi$ under a non-overlap approximation.\n   - The area of the dilation of a disk by another disk, extended by linearity to a random cell radius.\n   Express your final symbolic result in terms of $d_{s}$, $\\phi$, $\\mathbb{E}[D]$, and $\\mathbb{E}[D^{2}]$.\n\n2. Specialize your expression to the case where $D$ follows a Gamma distribution with mean $\\bar{d}$ and coefficient of variation $c_{v}$. Express $\\mathbb{E}[M]$ purely in terms of $d_{s}$, $\\phi$, $\\bar{d}$, and $c_{v}$.\n\n3. Evaluate the expected multiplicity numerically for a tissue with packing fraction $\\phi = $ $0.7$, spot diameter $d_{s} = $ $55$ micrometers, and a Gamma diameter distribution with mean $\\bar{d} = $ $12$ micrometers and coefficient of variation $c_{v} = $ $0.25$. Express the final result as a dimensionless expected count (cells per spot) and round your answer to four significant figures.", "solution": "The problem is assessed to be valid as it is scientifically grounded in the principles of stochastic geometry and probability theory, well-posed with a clear objective, and provides a complete and consistent set of parameters typical for the field of spatial transcriptomics.\n\nThe solution is derived in three parts as requested.\n\nPart 1: Derivation of the expected cell multiplicity per spot, $\\mathbb{E}[M]$.\n\nLet $M$ be the random variable representing the multiplicity, which is the number of cells captured by a single spot. The problem models cell centers as a homogeneous Poisson Point Process (PPP) in $\\mathbb{R}^2$ with intensity $n$. The cells themselves are circular disks with a random diameter $D$, and the capture spots are circular disks of fixed diameter $d_s$.\n\nA cell with center $\\mathbf{x}_c \\in \\mathbb{R}^2$ and radius $R = D/2$ intersects a spot centered at the origin with radius $r_s = d_s/2$ if and only if the distance between their centers is less than or equal to the sum of their radii. This condition is expressed as $\\|\\mathbf{x}_c\\| \\le R + r_s$.\n\nFor a specific cell with a given radius $R$, its center $\\mathbf{x}_c$ must fall within a disk of radius $R + r_s$ centered at the origin for it to be counted. The area of this \"capture region\" is the area of the Minkowski sum of the spot disk and the cell disk, given by $A(D) = \\pi (r_s + R)^2 = \\pi (d_s/2 + D/2)^2$.\n\nAccording to the properties of a homogeneous PPP, the expected number of points that fall into a given region is the intensity $n$ multiplied by the area of that region. Since the area of our capture region depends on the random variable $D$, we must take the expectation over the distribution of $D$. Using the law of total expectation (or Campbell's Theorem for marked point processes), the expected multiplicity $\\mathbb{E}[M]$ is the product of the intensity $n$ and the expected area of the capture region:\n$$\n\\mathbb{E}[M] = n \\cdot \\mathbb{E}[A(D)]\n$$\nWe first compute the expected area $\\mathbb{E}[A(D)]$ using the linearity of expectation:\n$$\n\\mathbb{E}[A(D)] = \\mathbb{E}\\left[\\pi \\left(\\frac{d_s}{2} + \\frac{D}{2}\\right)^2\\right] = \\frac{\\pi}{4} \\mathbb{E}[(d_s + D)^2] = \\frac{\\pi}{4} \\mathbb{E}[d_s^2 + 2d_s D + D^2]\n$$\n$$\n\\mathbb{E}[A(D)] = \\frac{\\pi}{4} (d_s^2 + 2d_s \\mathbb{E}[D] + \\mathbb{E}[D^2])\n$$\nNext, we relate the intensity $n$ to the cellular area fraction $\\phi$. The area fraction $\\phi$ is defined as the total area occupied by cells per unit area. For a PPP, this is the product of the expected number of cells per unit area, $n$, and the expected area of a single cell. The area of a cell with diameter $D$ is $\\pi (D/2)^2 = \\frac{\\pi}{4}D^2$. Its expected area is $\\mathbb{E}[\\frac{\\pi}{4}D^2] = \\frac{\\pi}{4}\\mathbb{E}[D^2]$.\nTherefore, the area fraction is:\n$$\n\\phi = n \\cdot \\frac{\\pi}{4}\\mathbb{E}[D^2]\n$$\nThis allows us to express the intensity $n$ in terms of $\\phi$ and the second moment of the cell diameter:\n$$\nn = \\frac{4\\phi}{\\pi \\mathbb{E}[D^2]}\n$$\nNow, we substitute this expression for $n$ into the equation for $\\mathbb{E}[M]$:\n$$\n\\mathbb{E}[M] = \\left(\\frac{4\\phi}{\\pi \\mathbb{E}[D^2]}\\right) \\cdot \\left(\\frac{\\pi}{4} (d_s^2 + 2d_s \\mathbb{E}[D] + \\mathbb{E}[D^2])\\right)\n$$\nThe factors of $\\pi/4$ cancel, yielding:\n$$\n\\mathbb{E}[M] = \\phi \\cdot \\frac{d_s^2 + 2d_s \\mathbb{E}[D] + \\mathbb{E}[D^2]}{\\mathbb{E}[D^2]}\n$$\nThis expression can be written as:\n$$\n\\mathbb{E}[M] = \\phi \\left(1 + \\frac{2d_s \\mathbb{E}[D]}{\\mathbb{E}[D^2]} + \\frac{d_s^2}{\\mathbb{E}[D^2]}\\right)\n$$\nThis is the required analytic expression for the expected multiplicity as a function of $d_s$, $\\phi$, and the first two moments of $D$, $\\mathbb{E}[D]$ and $\\mathbb{E}[D^2]$.\n\nPart 2: Specialization for a Gamma-distributed diameter.\n\nThe problem specifies that the cell diameter $D$ follows a Gamma distribution with mean $\\mathbb{E}[D] = \\bar{d}$ and coefficient of variation $c_v$. The coefficient of variation is defined as $c_v = \\frac{\\sqrt{\\text{Var}(D)}}{\\mathbb{E}[D]}$.\n\nWe need to express the first and second moments of $D$ in terms of $\\bar{d}$ and $c_v$.\nThe first moment is given directly:\n$$\n\\mathbb{E}[D] = \\bar{d}\n$$\nThe second moment $\\mathbb{E}[D^2]$ is related to the variance and the mean by the identity $\\text{Var}(D) = \\mathbb{E}[D^2] - (\\mathbb{E}[D])^2$.\nFrom the definition of $c_v$, the variance is $\\text{Var}(D) = (c_v \\cdot \\mathbb{E}[D])^2 = c_v^2 \\bar{d}^2$.\nTherefore, we can solve for the second moment:\n$$\n\\mathbb{E}[D^2] = \\text{Var}(D) + (\\mathbb{E}[D])^2 = c_v^2 \\bar{d}^2 + \\bar{d}^2 = \\bar{d}^2(1 + c_v^2)\n$$\nSubstituting these expressions for $\\mathbb{E}[D]$ and $\\mathbb{E}[D^2]$ into the result from Part 1:\n$$\n\\mathbb{E}[M] = \\phi \\left(1 + \\frac{2d_s \\bar{d}}{\\bar{d}^2(1 + c_v^2)} + \\frac{d_s^2}{\\bar{d}^2(1 + c_v^2)}\\right)\n$$\nSimplifying this expression yields:\n$$\n\\mathbb{E}[M] = \\phi \\left(1 + \\frac{2d_s/\\bar{d} + (d_s/\\bar{d})^2}{1 + c_v^2}\\right)\n$$\nThis is the specialized expression for $\\mathbb{E}[M]$ in terms of $d_s$, $\\phi$, $\\bar{d}$, and $c_v$.\n\nPart 3: Numerical evaluation.\n\nWe are given the following parameter values:\n- Packing fraction: $\\phi = 0.7$\n- Spot diameter: $d_s = 55$ micrometers\n- Mean cell diameter: $\\bar{d} = 12$ micrometers\n- Coefficient of variation of cell diameter: $c_v = 0.25$\n\nFirst, we calculate the values of the moments:\n$$\n\\mathbb{E}[D] = \\bar{d} = 12\n$$\n$$\n\\mathbb{E}[D^2] = \\bar{d}^2(1 + c_v^2) = 12^2(1 + 0.25^2) = 144(1 + 0.0625) = 144(1.0625) = 153\n$$\nNow, we substitute these moments and the given parameters into the general expression from Part 1:\n$$\n\\mathbb{E}[M] = \\phi \\left(1 + \\frac{2d_s \\mathbb{E}[D]}{\\mathbb{E}[D^2]} + \\frac{d_s^2}{\\mathbb{E}[D^2]}\\right)\n$$\n$$\n\\mathbb{E}[M] = 0.7 \\left(1 + \\frac{2(55)(12)}{153} + \\frac{55^2}{153}\\right)\n$$\n$$\n\\mathbb{E}[M] = 0.7 \\left(1 + \\frac{1320}{153} + \\frac{3025}{153}\\right)\n$$\nCombining the terms inside the parentheses over the common denominator $153$:\n$$\n\\mathbb{E}[M] = 0.7 \\left(\\frac{153 + 1320 + 3025}{153}\\right) = 0.7 \\left(\\frac{4498}{153}\\right)\n$$\nPerforming the division and multiplication:\n$$\n\\mathbb{E}[M] \\approx 0.7 \\times 29.39869...\n$$\n$$\n\\mathbb{E}[M] \\approx 20.57908...\n$$\nThe problem requires rounding the result to four significant figures.\n$$\n\\mathbb{E}[M] \\approx 20.58\n$$\nThe expected multiplicity is approximately $20.58$ cells per spot.", "answer": "$$\\boxed{20.58}$$", "id": "5163993"}, {"introduction": "Building directly on the issue of signal mixing explored previously, our final practice delves into a powerful computational solution. We will formulate the mathematical basis for cell type deconvolution, a method to estimate cell type proportions, $p_s$, from the mixed expression profiles of individual spots [@problem_id:5163986]. This advanced exercise introduces non-negative least squares and spatial regularization, demonstrating how optimization theory is leveraged to extract refined biological insights from spatially resolved data.", "problem": "In a spatial transcriptomics deconvolution setting, a spot-level observed gene expression vector $y_{s} \\in \\mathbb{R}^{m}$ is modeled as a linear combination of $k$ reference expression signatures collected in a matrix $G \\in \\mathbb{R}^{m \\times k}$ with non-negative cell type proportions $p_{s} \\in \\mathbb{R}^{k}$, so that $y_{s} \\approx G p_{s}$. Ignoring measurement noise correlations and assuming least squares fidelity, a standard estimator per spot solves a non-negative least squares problem. Spatial context suggests that neighboring spots should have similar cell type compositions; this can be captured by a quadratic penalty induced by the unnormalized graph Laplacian of the spot adjacency graph.\n\nStarting from the foundational facts that least squares objectives are convex quadratics in their arguments and that the Karush–Kuhn–Tucker (KKT) conditions characterize optimality for convex problems with inequality constraints, proceed as follows.\n\n- First, for a single spot $s$, formulate the Lagrangian for the non-negative least squares problem\n$$\n\\min_{p_{s} \\in \\mathbb{R}^{k}} \\ \\frac{1}{2} \\| y_{s} - G p_{s} \\|_{2}^{2} \\quad \\text{subject to} \\quad p_{s} \\succeq 0,\n$$\nand derive the KKT conditions in terms of the primal variable $p_{s}$ and the dual variable $\\mu_{s} \\in \\mathbb{R}^{k}$ associated with the non-negativity constraints.\n\n- Next, consider $n$ spots indexed by $s \\in \\{1,\\dots,n\\}$ with an undirected weighted adjacency graph having weights $w_{st}=w_{ts} \\ge 0$ and unnormalized graph Laplacian $L \\in \\mathbb{R}^{n \\times n}$ defined by $L_{ss} = \\sum_{t \\ne s} w_{st}$ and $L_{st} = -w_{st}$ for $s \\ne t$. Argue how the stationarity condition is modified when augmenting the objective with the spatial smoothness regularizer\n$$\n\\frac{\\lambda}{2} \\sum_{(s,t)} w_{st} \\| p_{s} - p_{t} \\|_{2}^{2},\n$$\nwith $\\lambda \\ge 0$. You may express the coupled stationarity conditions using the graph Laplacian.\n\n- Finally, specialize to a two-spot, two-cell-type toy model that captures spatial smoothing while remaining analytically tractable. Let $k=2$, $n=2$, let $G = I_{2}$ (the $2 \\times 2$ identity), let the only nonzero edge weight be $w_{AB}=1$ between spots $A$ and $B$, and impose per-spot simplex constraints $1^{\\top} p_{s} = 1$ and $p_{s} \\succeq 0$ so that $p_{s}$ is a vector of cell type fractions. Take $y_{A} = \\begin{pmatrix} a \\\\ 1-a \\end{pmatrix}$ and $y_{B} = \\begin{pmatrix} b \\\\ 1-b \\end{pmatrix}$ with $a \\in (0,1)$ and $b \\in (0,1)$. Under the assumption that the non-negativity constraints are inactive at the optimum for all $\\lambda \\ge 0$ (which is satisfied when $a \\in (0,1)$ and $b \\in (0,1)$), reduce the problem to two scalar variables $x = p_{A,1}$ and $z = p_{B,1}$ and minimize the resulting quadratic objective. Derive the exact closed-form analytic expression for the optimal $x^{\\star}$ as a function of $a$, $b$, and $\\lambda$. Report this expression as your final answer. Do not round; provide a closed-form expression.", "solution": "The problem is valid as it is scientifically grounded in computational biology and optimization theory, mathematically well-posed, objective, and self-contained. The provided data and assumptions are consistent and sufficient for deriving a unique, meaningful solution.\n\nThe solution is developed in three parts as requested by the problem statement.\n\n**Part 1: KKT Conditions for Single-Spot Non-Negative Least Squares**\n\nThe problem for a single spot $s$ is a non-negative least squares (NNLS) problem, which is a convex optimization problem. The objective function is $\\mathcal{J}(p_s) = \\frac{1}{2} \\| y_s - G p_s \\|_2^2$, and the constraints are $p_s \\succeq 0$. This corresponds to $k$ individual constraints $p_{s,j} \\ge 0$ for $j=1, \\dots, k$. We can write these constraints in the standard form $g_j(p_s) \\le 0$ as $-p_{s,j} \\le 0$.\n\nThe Lagrangian function $\\mathcal{L}$ is formed by adding the constraints to the objective function, weighted by Lagrange multipliers (also known as dual variables). Let $\\mu_s \\in \\mathbb{R}^k$ be the vector of Lagrange multipliers for the non-negativity constraints on $p_s$. The Lagrangian is:\n$$\n\\mathcal{L}(p_s, \\mu_s) = \\mathcal{J}(p_s) + \\sum_{j=1}^{k} \\mu_{s,j} (-p_{s,j}) = \\frac{1}{2} \\| y_s - G p_s \\|_2^2 - \\mu_s^\\top p_s\n$$\nThe Karush-Kuhn-Tucker (KKT) conditions provide necessary and sufficient conditions for optimality for a convex problem with inequality constraints. They are:\n\n1.  **Stationarity**: The gradient of the Lagrangian with respect to the primal variables $p_s$ must be zero.\n    First, we compute the gradient of the objective function $\\mathcal{J}(p_s)$:\n    $$\n    \\mathcal{J}(p_s) = \\frac{1}{2} (y_s - G p_s)^\\top (y_s - G p_s) = \\frac{1}{2} (y_s^\\top y_s - 2 y_s^\\top G p_s + p_s^\\top G^\\top G p_s)\n    $$\n    The gradient with respect to $p_s$ is:\n    $$\n    \\nabla_{p_s} \\mathcal{J}(p_s) = \\frac{1}{2} (-2 G^\\top y_s + 2 G^\\top G p_s) = G^\\top G p_s - G^\\top y_s\n    $$\n    The gradient of the full Lagrangian is:\n    $$\n    \\nabla_{p_s} \\mathcal{L}(p_s, \\mu_s) = (G^\\top G p_s - G^\\top y_s) - \\mu_s\n    $$\n    Setting this to zero gives the stationarity condition:\n    $$\n    G^\\top G p_s - G^\\top y_s - \\mu_s = 0\n    $$\n\n2.  **Primal Feasibility**: The primal variables must satisfy the original constraints.\n    $$\n    p_s \\succeq 0\n    $$\n\n3.  **Dual Feasibility**: The Lagrange multipliers for inequality constraints of the form $g(x) \\le 0$ must be non-negative.\n    $$\n    \\mu_s \\succeq 0\n    $$\n\n4.  **Complementary Slackness**: The product of each Lagrange multiplier and its corresponding constraint must be zero.\n    $$\n    \\mu_{s,j} p_{s,j} = 0 \\quad \\text{for all} \\quad j = 1, \\dots, k\n    $$\n    In vector form, this is written using the element-wise (Hadamard) product as $\\mu_s \\odot p_s = 0$.\n\nIn summary, the KKT conditions for the single-spot NNLS problem are:\n-   $G^\\top G p_s - G^\\top y_s - \\mu_s = 0$\n-   $p_s \\succeq 0$\n-   $\\mu_s \\succeq 0$\n-   $\\mu_s \\odot p_s = 0$\n\n**Part 2: Modified Stationarity with Spatial Regularization**\n\nThe objective function is augmented with a spatial regularization term for a system of $n$ spots. The total objective function is:\n$$\nJ(p_1, \\dots, p_n) = \\sum_{s=1}^n \\frac{1}{2} \\| y_s - G p_s \\|_2^2 + \\frac{\\lambda}{2} \\sum_{(s,t)} w_{st} \\| p_s - p_t \\|_2^2\n$$\nThe first part is the sum of the individual least squares errors. The second part is the spatial regularizer, which penalizes differences in cell type proportions $p_s$ and $p_t$ between adjacent spots $s$ and $t$, weighted by $w_{st}$.\n\nTo find the modified stationarity condition, we need to find the gradient of the total objective with respect to a single proportion vector $p_s$. The Lagrangian for the full problem is $\\mathcal{L} = J(p_1, \\dots, p_n) - \\sum_{s=1}^n \\mu_s^\\top p_s$. The stationarity condition for each spot $s$ is $\\nabla_{p_s} \\mathcal{L} = 0$.\n\nThe gradient of the data-fitting term $\\sum_{i=1}^n \\frac{1}{2} \\| y_i - G p_i \\|_2^2$ with respect to $p_s$ is simply $G^\\top G p_s - G^\\top y_s$, as derived in Part 1.\n\nNow, consider the regularization term $R = \\frac{\\lambda}{2} \\sum_{(u,v)} w_{uv} \\| p_u - p_v \\|_2^2$. The sum is over unique undirected edges $(u,v)$. This can be rewritten as a sum over all pairs $(u,v)$ with a factor of $1/2$: $R = \\frac{\\lambda}{4} \\sum_{u=1}^n \\sum_{v=1}^n w_{uv} \\| p_u - p_v \\|_2^2$, where we define $w_{uu}=0$. The gradient with respect to $p_s$ is:\n$$\n\\nabla_{p_s} R = \\frac{\\lambda}{4} \\sum_{u=1}^n \\sum_{v=1}^n w_{uv} \\nabla_{p_s} \\| p_u - p_v \\|_2^2\n$$\nThe gradient $\\nabla_{p_s} \\| p_u - p_v \\|_2^2$ is non-zero only if $u=s$ or $v=s$.\n$$\n\\nabla_{p_s} R = \\frac{\\lambda}{4} \\left( \\sum_{v \\ne s} w_{sv} \\nabla_{p_s} \\| p_s - p_v \\|_2^2 + \\sum_{u \\ne s} w_{us} \\nabla_{p_s} \\| p_u - p_s \\|_2^2 \\right)\n$$\nUsing $\\nabla_x \\|x-c\\|_2^2 = 2(x-c)$ and the symmetry $w_{us}=w_{su}$, we get:\n$$\n\\nabla_{p_s} R = \\frac{\\lambda}{4} \\left( \\sum_{t \\ne s} w_{st} 2(p_s - p_t) + \\sum_{t \\ne s} w_{st} 2(p_s - p_t) \\right) = \\lambda \\sum_{t \\ne s} w_{st} (p_s - p_t)\n$$\nThis expression can be related to the graph Laplacian $L$.\n$$\n\\nabla_{p_s} R = \\lambda \\left( \\left(\\sum_{t \\ne s} w_{st}\\right) p_s - \\sum_{t \\ne s} w_{st} p_t \\right)\n$$\nUsing the definition of the unnormalized graph Laplacian, $L_{ss} = \\sum_{t \\ne s} w_{st}$ and $L_{st} = -w_{st}$ for $s \\ne t$:\n$$\n\\nabla_{p_s} R = \\lambda \\left( L_{ss} p_s + \\sum_{t \\ne s} L_{st} p_t \\right) = \\lambda \\sum_{t=1}^n L_{st} p_t\n$$\nThis is the $s$-th block row of the product of a block matrix involving $L$ and the stacked vector of all $p_t$.\n\nThe stationarity condition for each spot $s$ is obtained by setting $\\nabla_{p_s} \\mathcal{L} = 0$:\n$$\nG^\\top G p_s - G^\\top y_s + \\lambda \\sum_{t=1}^n L_{st} p_t - \\mu_s = 0\n$$\nCompared to the single-spot case, the stationarity condition for spot $s$ is modified by the addition of the term $\\lambda \\sum_{t=1}^n L_{st} p_t$. This term couples the solution for $p_s$ with the solutions for its neighbors in the graph, enforcing spatial smoothness. The full system consists of $n$ such vector equations, which must be solved simultaneously.\n\n**Part 3: Two-Spot, Two-Cell-Type Toy Model**\n\nWe are given a simplified model with $n=2$ spots ($A, B$) and $k=2$ cell types.\n-   $G = I_2$, the $2 \\times 2$ identity matrix.\n-   $y_A = \\begin{pmatrix} a \\\\ 1-a \\end{pmatrix}$, $y_B = \\begin{pmatrix} b \\\\ 1-b \\end{pmatrix}$ with $a,b \\in (0,1)$.\n-   $w_{AB}=1$, so the graph Laplacian is $L = \\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix}$.\n-   Constraints: $p_s \\succeq 0$ and $1^\\top p_s = 1$ for $s \\in \\{A, B\\}$.\n-   Assumption: The non-negativity constraints $p_s \\succeq 0$ are inactive.\n\nThe sum-to-one constraint means we can parameterize the proportion vectors. Let $x = p_{A,1}$ and $z = p_{B,1}$. Then $p_{A,2} = 1-x$ and $p_{B,2} = 1-z$. So, $p_A = \\begin{pmatrix} x \\\\ 1-x \\end{pmatrix}$ and $p_B = \\begin{pmatrix} z \\\\ 1-z \\end{pmatrix}$. The assumption that non-negativity is inactive means we can ignore these constraints in the optimization (and verify post-hoc that the solution satisfies them). The simplex constraints become box constraints $x \\in [0,1]$ and $z \\in [0,1]$.\n\nThe total objective function is $J(p_A, p_B) = \\frac{1}{2} \\| y_A - p_A \\|_2^2 + \\frac{1}{2} \\| y_B - p_B \\|_2^2 + \\frac{\\lambda}{2} \\| p_A - p_B \\|_2^2$, since $G=I_2$ and $w_{AB}=1$.\n\nLet's express the terms in $J$ using $x$ and $z$:\n-   $\\| y_A - p_A \\|_2^2 = \\left\\| \\begin{pmatrix} a-x \\\\ (1-a)-(1-x) \\end{pmatrix} \\right\\|_2^2 = (a-x)^2 + (x-a)^2 = 2(a-x)^2$.\n-   $\\| y_B - p_B \\|_2^2 = \\left\\| \\begin{pmatrix} b-z \\\\ (1-b)-(1-z) \\end{pmatrix} \\right\\|_2^2 = (b-z)^2 + (z-b)^2 = 2(b-z)^2$.\n-   $\\| p_A - p_B \\|_2^2 = \\left\\| \\begin{pmatrix} x-z \\\\ (1-x)-(1-z) \\end{pmatrix} \\right\\|_2^2 = (x-z)^2 + (z-x)^2 = 2(x-z)^2$.\n\nSubstituting these into the objective function:\n$$\nJ(x, z) = \\frac{1}{2} \\left[ 2(a-x)^2 + 2(b-z)^2 + \\lambda \\cdot 2(x-z)^2 \\right] = (a-x)^2 + (b-z)^2 + \\lambda(x-z)^2\n$$\nTo find the optimal $(x^\\star, z^\\star)$, we minimize this unconstrained quadratic function by setting its partial derivatives with respect to $x$ and $z$ to zero.\n$$\n\\frac{\\partial J}{\\partial x} = -2(a-x) + 2\\lambda(x-z) = 0 \\implies -a+x+\\lambda x - \\lambda z = 0 \\implies (1+\\lambda)x - \\lambda z = a\n$$\n$$\n\\frac{\\partial J}{\\partial z} = -2(b-z) - 2\\lambda(x-z) = 0 \\implies -b+z-\\lambda x + \\lambda z = 0 \\implies -\\lambda x + (1+\\lambda)z = b\n$$\nThis gives a system of two linear equations in $x$ and $z$:\n$$\n\\begin{pmatrix} 1+\\lambda & -\\lambda \\\\ -\\lambda & 1+\\lambda \\end{pmatrix} \\begin{pmatrix} x \\\\ z \\end{pmatrix} = \\begin{pmatrix} a \\\\ b \\end{pmatrix}\n$$\nWe need to solve for $x$. We can use Cramer's rule. The determinant of the coefficient matrix is:\n$$\n\\Delta = (1+\\lambda)^2 - (-\\lambda)^2 = 1 + 2\\lambda + \\lambda^2 - \\lambda^2 = 1+2\\lambda\n$$\nThe determinant for the numerator of $x$ is:\n$$\n\\Delta_x = \\det \\begin{pmatrix} a & -\\lambda \\\\ b & 1+\\lambda \\end{pmatrix} = a(1+\\lambda) - b(-\\lambda) = a + a\\lambda + b\\lambda = a + (a+b)\\lambda\n$$\nThe solution for $x^{\\star}$ is:\n$$\nx^{\\star} = \\frac{\\Delta_x}{\\Delta} = \\frac{a + (a+b)\\lambda}{1+2\\lambda}\n$$\nAs a check, since $a,b \\in (0,1)$ and $\\lambda \\ge 0$, we have $x^\\star > 0$. Also, $x^\\star < 1$ because $a + (a+b)\\lambda < 1+2\\lambda \\iff a-1 + (a+b-2)\\lambda < 0$, which is true since $a-1 < 0$ and $a+b-2 < 0$. Thus the solution lies in $(0,1)$ and the non-negativity constraints are indeed inactive.", "answer": "$$\\boxed{\\frac{a + (a+b)\\lambda}{1+2\\lambda}}$$", "id": "5163986"}]}