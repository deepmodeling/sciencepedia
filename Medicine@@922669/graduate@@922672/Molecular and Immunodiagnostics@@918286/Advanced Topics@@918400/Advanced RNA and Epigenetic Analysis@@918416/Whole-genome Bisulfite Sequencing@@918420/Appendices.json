{"hands_on_practices": [{"introduction": "The first and most critical step in any genomics analysis pipeline is rigorous quality control (QC). Before drawing biological conclusions, we must ensure the underlying Whole-Genome Bisulfite Sequencing (WGBS) data is technically sound. This exercise walks you through the calculation of three essential QC metrics—bisulfite conversion efficiency, duplication rate, and coverage uniformity—which together provide a comprehensive assessment of data quality and the success of the sequencing experiment [@problem_id:5172321].", "problem": "Whole-Genome Bisulfite Sequencing (WGBS) infers cytosine methylation state by sodium bisulfite conversion of unmethylated cytosines to uracils, which are read as thymine after polymerase chain reaction (PCR). In a high-quality WGBS dataset used for molecular and immunodiagnostics, three core quality metrics are assessed: bisulfite conversion efficiency, duplication rate, and coverage uniformity. Starting from first principles—namely, that unmethylated cytosines are expected to convert to thymine with high probability, PCR introduces duplicate molecules that bias depth, and uniform coverage ensures stable statistical power across loci—derive each metric and then compute them from the following dataset. Use these results, together with scientifically motivated quality thresholds, to form a dimensionless composite quality index.\n\nYou sequence a human sample with a spike-in of a known unmethylated control genome (for example, bacteriophage lambda). For conversion efficiency, you aggregate observations at non-cytosine–phosphate–guanine (non-CpG) cytosines in the spike-in, where methylation is negligibly rare and any observed cytosines after treatment are due to incomplete conversion. The observed counts in the spike-in are:\n- total eligible cytosine observations: $N_{\\text{eligible}} = 3{,}200{,}000$,\n- calls observed as thymine: $N_{T} = 3{,}190{,}400$,\n- calls observed as cytosine: $N_{C} = 9{,}600$.\n\nFor duplication rate, you align $R_{\\text{total}} = 75{,}000{,}000$ read pairs to the human reference genome and mark $R_{\\text{dup}} = 9{,}000{,}000$ read pairs as PCR duplicates based on identical start and end coordinates (assume no Unique Molecular Identifiers (UMIs) were used).\n\nFor coverage uniformity, you partition the mappable autosomal genome into $N = 1000$ non-overlapping bins of equal size and compute per-bin coverage depths $\\{d_{i}\\}_{i=1}^{N}$ (in units of $X$, the fold coverage). The sample mean is $\\bar{d} = 25$, and the sum of squared deviations from the mean is\n$$\n\\text{SSE} = \\sum_{i=1}^{N} (d_{i} - \\bar{d})^{2} = 15{,}984.\n$$\n\nFirst, derive from first principles the expressions you will use to compute:\n- the bisulfite conversion efficiency $E$,\n- the duplication rate $D$,\n- the coverage uniformity quantified by the coefficient of variation $\\mathrm{CV}$.\n\nThen, compute their values for the dataset above. Using the following scientifically motivated thresholds for a high-quality WGBS dataset,\n- bisulfite conversion efficiency threshold $T_{E} = 0.995$,\n- duplication rate threshold $T_{D} = 0.20$,\n- coverage uniformity threshold $T_{U} = 0.30$,\nbriefly explain why each threshold is reasonable in the context of molecular and immunodiagnostics. Finally, define the composite, dimensionless quality index\n$$\nQ \\equiv \\left( \\min\\!\\left(1, \\frac{E}{T_{E}}\\right) \\cdot \\max\\!\\left(0, 1 - \\frac{D}{T_{D}}\\right) \\cdot \\max\\!\\left(0, 1 - \\frac{\\mathrm{CV}}{T_{U}}\\right) \\right)^{\\frac{1}{3}},\n$$\nand compute $Q$ for this dataset. Round your final $Q$ to four significant figures. Express the final answer as a dimensionless number with no units.", "solution": "The problem statement has been validated and is deemed scientifically sound, well-posed, and objective. It presents a standard bioinformatics quality control task based on realistic data from a Whole-Genome Bisulfite Sequencing (WGBS) experiment. We will proceed with a full solution.\n\nThe solution is structured into four parts as requested:\n1.  Derivation of the quality metrics from first principles.\n2.  Computation of these metrics using the provided dataset.\n3.  Justification for the specified quality thresholds.\n4.  Calculation of the composite quality index $Q$.\n\n**1. Derivation of Quality Metrics from First Principles**\n\n**Bisulfite Conversion Efficiency ($E$)**\nThe fundamental principle of bisulfite sequencing is the chemical conversion of unmethylated cytosine ($C$) to uracil ($U$), while methylated cytosine ($5\\text{mC}$) remains unchanged. Following PCR amplification, uracil is read as thymine ($T$). The efficiency of this conversion is a critical parameter, as incomplete conversion of unmethylated cytosines leads to them being erroneously identified as methylated.\n\nTo measure this efficiency, an unmethylated control genome (e.g., lambda phage) is \"spiked-in\" before bisulfite treatment. In this control, all cytosines are unmethylated and should, in principle, convert to uracil and subsequently be read as thymine. The conversion efficiency, $E$, is therefore the fraction of all eligible cytosines in the control that are successfully read as thymine.\n\nLet $N_{\\text{eligible}}$ be the total number of cytosine positions observed in the unmethylated control. Let $N_{T}$ be the number of times these positions are read as thymine (successful conversion) and $N_{C}$ be the number of times they are read as cytosine (failed conversion). By definition, $N_{\\text{eligible}} = N_{T} + N_{C}$. The conversion efficiency $E$ is derived as the ratio of successful outcomes to the total number of trials:\n$$\nE = \\frac{\\text{Number of successfully converted cytosines}}{\\text{Total number of eligible cytosines}} = \\frac{N_{T}}{N_{\\text{eligible}}}\n$$\n\n**Duplication Rate ($D$)**\nDuring the preparation of a sequencing library, the initial DNA fragments are amplified using Polymerase Chain Reaction (PCR) to generate sufficient material for the sequencer. This process can introduce bias, where certain fragments are amplified preferentially, resulting in multiple identical copies derived from a single original molecule. These are termed PCR duplicates. A high rate of duplication reduces the molecular complexity of the library, leading to wasted sequencing capacity and lower effective coverage.\n\nThe duplication rate, $D$, is the fraction of the total sequenced reads that are identified as duplicates. Let $R_{\\text{total}}$ be the total number of read pairs aligned to the reference genome and $R_{\\text{dup}}$ be the subset of these reads marked as duplicates (typically based on having identical mapping coordinates). The duplication rate is then:\n$$\nD = \\frac{\\text{Number of duplicate read pairs}}{\\text{Total number of aligned read pairs}} = \\frac{R_{\\text{dup}}}{R_{\\text{total}}}\n$$\n\n**Coverage Uniformity (Coefficient of Variation, $\\mathrm{CV}$)**\nIdeal sequencing provides uniform depth of coverage across the entire genome, ensuring that all regions have sufficient data for robust statistical analysis. In practice, coverage is never perfectly uniform due to biases in library preparation (e.g., GC-content bias) and sequencing. The coefficient of variation ($\\mathrm{CV}$) is a standardized measure of the dispersion of a probability distribution or frequency distribution, and it is used here to quantify the non-uniformity of coverage. It is defined as the ratio of the standard deviation to the mean.\n\nLet the genome be partitioned into $N$ bins, and let $\\{d_{i}\\}_{i=1}^{N}$ be the average coverage depth in each bin. The sample mean coverage is $\\bar{d} = \\frac{1}{N} \\sum_{i=1}^{N} d_{i}$. The sample variance, $s^2$, which provides an unbiased estimate of the population variance, is calculated from the sum of squared deviations from the mean ($\\text{SSE} = \\sum_{i=1}^{N} (d_{i} - \\bar{d})^{2}$):\n$$\ns^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} (d_{i} - \\bar{d})^{2} = \\frac{\\text{SSE}}{N-1}\n$$\nThe sample standard deviation is $s = \\sqrt{s^2}$. The coefficient of variation is then the ratio of the sample standard deviation to the sample mean:\n$$\n\\mathrm{CV} = \\frac{s}{\\bar{d}} = \\frac{\\sqrt{\\frac{\\text{SSE}}{N-1}}}{\\bar{d}}\n$$\nA lower $\\mathrm{CV}$ indicates higher uniformity of coverage.\n\n**2. Computation of Metric Values**\n\nUsing the provided dataset, we now compute the values for $E$, $D$, and $\\mathrm{CV}$.\n\nFor bisulfite conversion efficiency $E$:\n$N_{\\text{eligible}} = 3{,}200{,}000$ and $N_{T} = 3{,}190{,}400$.\n$$\nE = \\frac{N_{T}}{N_{\\text{eligible}}} = \\frac{3{,}190{,}400}{3{,}200{,}000} = 0.997\n$$\n\nFor duplication rate $D$:\n$R_{\\text{total}} = 75{,}000{,}000$ and $R_{\\text{dup}} = 9{,}000{,}000$.\n$$\nD = \\frac{R_{\\text{dup}}}{R_{\\text{total}}} = \\frac{9{,}000{,}000}{75{,}000{,}000} = \\frac{9}{75} = \\frac{3}{25} = 0.12\n$$\n\nFor coverage uniformity $\\mathrm{CV}$:\n$N = 1000$, $\\bar{d} = 25$, and $\\text{SSE} = 15{,}984$.\nFirst, we compute the sample standard deviation $s$:\n$$\ns = \\sqrt{\\frac{\\text{SSE}}{N-1}} = \\sqrt{\\frac{15{,}984}{1000-1}} = \\sqrt{\\frac{15{,}984}{999}} = \\sqrt{16} = 4\n$$\nNow, we compute the coefficient of variation $\\mathrm{CV}$:\n$$\n\\mathrm{CV} = \\frac{s}{\\bar{d}} = \\frac{4}{25} = 0.16\n$$\n\n**3. Justification of Quality Thresholds**\n\nThe problem provides scientifically motivated thresholds for a high-quality WGBS dataset.\n\n- **Bisulfite conversion efficiency threshold $T_{E} = 0.995$**: A high conversion rate is paramount for accuracy. Any unmethylated cytosine that fails to convert is incorrectly read as a cytosine, creating a false-positive signal for methylation. In diagnostics, where detecting small changes in methylation or identifying lowly methylated regions is crucial, the background noise must be minimized. A threshold of $E \\ge 0.995$ ensures that the false methylation signal from non-conversion is below $0.5\\%$, providing the high signal-to-noise ratio required for reliable diagnostic calls.\n\n- **Duplication rate threshold $T_{D} = 0.20$**: A low duplication rate reflects a high-complexity library. High duplication ($D > 0.20$) suggests insufficient starting material or excessive PCR amplification, both of which can introduce significant bias. This leads to a lower number of unique molecules being sequenced, reducing the effective coverage and compromising the quantitative accuracy of methylation level estimates. For diagnostic applications, maintaining library complexity by keeping $D$ below $20\\%$ is essential for unbiased and reproducible results.\n\n- **Coverage uniformity threshold $T_{U} = 0.30$**: This threshold pertains to the coefficient of variation ($\\mathrm{CV}$). A low $\\mathrm{CV}$ indicates uniform coverage across the genome. High non-uniformity (e.g., $\\mathrm{CV} > 0.30$) implies that some genomic regions are significantly under-sequenced, leading to low statistical power for methylation calling in those areas. For a comprehensive diagnostic assay, it is critical to have reliable data across all relevant genomic loci. A uniformity threshold for the $\\mathrm{CV}$ ensures that such \"blind spots\" are minimized.\n\n**4. Calculation of the Composite Quality Index $Q$**\n\nThe composite quality index $Q$ is defined as:\n$$\nQ \\equiv \\left( \\min\\!\\left(1, \\frac{E}{T_{E}}\\right) \\cdot \\max\\!\\left(0, 1 - \\frac{D}{T_{D}}\\right) \\cdot \\max\\!\\left(0, 1 - \\frac{\\mathrm{CV}}{T_{U}}\\right) \\right)^{\\frac{1}{3}}\n$$\nWe substitute the computed metric values and the given thresholds:\n$E = 0.997$, $T_{E} = 0.995$\n$D = 0.12$, $T_{D} = 0.20$\n$\\mathrm{CV} = 0.16$, $T_{U} = 0.30$\n\nWe evaluate each term of the product separately:\n- **Term 1**: $\\min\\left(1, \\frac{E}{T_{E}}\\right) = \\min\\left(1, \\frac{0.997}{0.995}\\right)$. Since $0.997 > 0.995$, the ratio is greater than $1$, so the term evaluates to $1$.\n- **Term 2**: $\\max\\left(0, 1 - \\frac{D}{T_{D}}\\right) = \\max\\left(0, 1 - \\frac{0.12}{0.20}\\right) = \\max(0, 1 - 0.6) = \\max(0, 0.4) = 0.4 = \\frac{2}{5}$.\n- **Term 3**: $\\max\\left(0, 1 - \\frac{\\mathrm{CV}}{T_{U}}\\right) = \\max\\left(0, 1 - \\frac{0.16}{0.30}\\right) = \\max\\left(0, 1 - \\frac{16}{30}\\right) = \\max\\left(0, 1 - \\frac{8}{15}\\right) = \\max\\left(0, \\frac{7}{15}\\right) = \\frac{7}{15}$.\n\nNow, we combine these terms to compute $Q$:\n$$\nQ = \\left( 1 \\cdot \\frac{2}{5} \\cdot \\frac{7}{15} \\right)^{\\frac{1}{3}} = \\left( \\frac{14}{75} \\right)^{\\frac{1}{3}}\n$$\nWe calculate the numerical value and round to four significant figures:\n$$\nQ \\approx (0.186666...)^{\\frac{1}{3}} \\approx 0.571533...\n$$\nRounding to four significant figures, we get $Q \\approx 0.5715$.\nThis value represents a composite score of the sequencing experiment's quality, normalized by pre-defined standards and combined using a geometric mean.", "answer": "$$\n\\boxed{0.5715}\n$$", "id": "5172321"}, {"introduction": "WGBS data does not provide a direct readout of the true methylation state; it is an observation filtered through a series of biochemical and computational processes, each with potential for bias. A primary artifact is the incomplete conversion of unmethylated cytosines, which can systematically inflate apparent methylation levels. This practice challenges you to derive a mathematical correction from first principles, providing a tool to adjust the observed data and obtain a more accurate estimate of the true biological methylation fraction [@problem_id:5172342].", "problem": "Whole-Genome Bisulfite Sequencing (WGBS) uses sodium bisulfite chemistry to deaminate unmethylated cytosines, converting them to uracil, which are read as thymine after polymerase chain reaction (PCR), while methylated cytosines are protected and remain as cytosine. Consider a single cytosine locus with a true methylation fraction denoted by $p \\in [0,1]$. Let the incomplete conversion rate of unmethylated cytosines be $q \\in [0,1)$, defined as the probability that an unmethylated cytosine fails to deaminate and remains as cytosine through the process. Assume no over-conversion of methylated cytosines, no sequencing miscalls, and no mapping bias. You sequence $n$ independent reads covering this locus and compute the observed methylation proportion $\\hat{p} = k/n$, where $k$ is the number of reads calling cytosine at this position after alignment.\n\nStarting from the chemical specificity of bisulfite conversion and a Bernoulli model for read outcomes, derive the expected observed methylation proportion as a function of $p$ and $q$, interpret how $q$ inflates the apparent methylation relative to $p$, and, by inverting this relationship, construct a consistent estimator $\\tilde{p}$ of $p$ expressed solely in terms of $\\hat{p}$ and $q$. Your derivation should clearly justify each probabilistic step from first principles.\n\nReport only your final estimator $\\tilde{p}$ in closed form as a function of $\\hat{p}$ and $q$. No numerical evaluation is required. Do not include units. The final answer must be a single analytic expression.", "solution": "The problem requires the derivation of a consistent estimator for the true methylation fraction, $p$, at a single cytosine locus, based on observed data from Whole-Genome Bisulfite Sequencing (WGBS). The estimator must account for the incomplete conversion of unmethylated cytosines, quantified by the rate $q$.\n\nLet us begin by formalizing the process from first principles. We are interested in the event of observing a cytosine ('C') in a single sequencing read covering the locus. Let $C_{obs}$ denote this event. The true state of the cytosine on the DNA molecule can either be methylated, an event we denote as $M$, or unmethylated, denoted as $U$.\n\nAccording to the problem statement, the true methylation fraction is $p$. This is the prior probability that a cytosine at the locus is methylated. Therefore, we have:\n$$P(M) = p$$\n$$P(U) = 1 - P(M) = 1 - p$$\n\nThe problem provides the conditional probabilities of observing a 'C' based on the true underlying state, incorporating the artifacts of the bisulfite sequencing chemistry.\n1.  Methylated cytosines are protected from deamination and are always read as 'C'. The problem specifies no over-conversion and no sequencing errors. Thus, the probability of observing a 'C' given that the true state is methylated is $1$:\n    $$P(C_{obs} | M) = 1$$\n2.  Unmethylated cytosines are supposed to be converted to uracil (and read as thymine). However, the conversion is incomplete with a probability $q$. An incomplete conversion means the unmethylated cytosine is not deaminated and remains a cytosine, which is subsequently read as 'C'. Therefore, the probability of observing a 'C' given that the true state is unmethylated is equal to the incomplete conversion rate $q$:\n    $$P(C_{obs} | U) = q$$\n\nUsing the law of total probability, we can calculate the marginal probability of observing a 'C' in any single read, which we shall denote as $\\theta$. This probability is the sum of probabilities of observing a 'C' over all possible true states, weighted by the probabilities of those states:\n$$\\theta = P(C_{obs}) = P(C_{obs} | M) P(M) + P(C_{obs} | U) P(U)$$\nSubstituting the values defined above:\n$$\\theta = (1)(p) + (q)(1-p)$$\n$$\\theta = p + q - qp = p(1-q) + q$$\n\nThis expression for $\\theta$ represents the true probability of success (observing a 'C') in a single Bernoulli trial corresponding to one read. The problem states that we have $n$ independent reads. The number of 'C' reads, $k$, is therefore a random variable following a binomial distribution, $k \\sim \\text{Binomial}(n, \\theta)$.\n\nThe observed methylation proportion, $\\hat{p}$, is defined as $\\hat{p} = k/n$. We are asked to derive its expected value. Using the properties of expectation and the fact that the expected value of a binomial random variable is $E[k] = n\\theta$:\n$$E[\\hat{p}] = E\\left[\\frac{k}{n}\\right] = \\frac{1}{n} E[k] = \\frac{1}{n} (n\\theta) = \\theta$$\nThus, the expected value of the observed methylation proportion is:\n$$E[\\hat{p}] = p(1-q) + q$$\n\nWe can interpret this result to understand how the incomplete conversion rate $q$ inflates the apparent methylation level. The expected observed value $E[\\hat{p}]$ can be rewritten as $p + q(1-p)$. The true methylation level is $p$. The term $q(1-p)$ represents a positive bias, or an inflation, added to the true value. This bias arises from the fraction of cytosines that are truly unmethylated, ($1-p$), but are erroneously read as 'C' due to failed conversion, which occurs with probability $q$. The inflation is zero only if $q=0$ (perfect conversion) or $p=1$ (the site is fully methylated, so there are no unmethylated cytosines to be misread).\n\nTo construct a consistent estimator for $p$, we can employ the method of moments. This method consists of equating the sample moment to the corresponding population moment and solving for the parameter of interest. Here, the first sample moment is the observed proportion $\\hat{p}$, which is an unbiased estimator for the population mean $E[\\hat{p}]$. By the law of large numbers, $\\hat{p}$ is a consistent estimator of $E[\\hat{p}]$. We set the observed statistic $\\hat{p}$ equal to its expected value:\n$$\\hat{p} = E[\\hat{p}] = p(1-q) + q$$\n\nWe now solve this equation algebraically for $p$ to obtain our estimator, which we will denote as $\\tilde{p}$.\n$$\\hat{p} - q = \\tilde{p}(1-q)$$\nGiven that $q \\in [0, 1)$, the term ($1-q$) is non-zero, so we can divide by it:\n$$\\tilde{p} = \\frac{\\hat{p} - q}{1-q}$$\n\nThis expression defines a consistent estimator $\\tilde{p}$ for the true methylation fraction $p$. It corrects the raw observed proportion $\\hat{p}$ by accounting for the inflation caused by the incomplete conversion rate $q$. Its consistency follows from the consistency of $\\hat{p}$ and the continuous mapping theorem, as $\\tilde{p}$ is a continuous function of $\\hat{p}$ (for a fixed $q \\neq 1$). As $n \\to \\infty$, $\\hat{p} \\to E[\\hat{p}]$, and thus $\\tilde{p} \\to \\frac{E[\\hat{p}] - q}{1-q} = \\frac{(p(1-q)+q)-q}{1-q} = \\frac{p(1-q)}{1-q} = p$.\nThe resulting estimator $\\tilde{p}$ is expressed solely in terms of the observable quantity $\\hat{p}$ and the known parameter $q$.", "answer": "$$\n\\boxed{\\frac{\\hat{p} - q}{1-q}}\n$$", "id": "5172342"}, {"introduction": "The ultimate goal of many WGBS studies in immunodiagnostics is to identify statistically significant differences in methylation between experimental groups. This requires a statistical model that not only captures the count-based nature of the data but also accounts for biological variability between replicates. This advanced practice guides you through the derivation of a likelihood ratio test based on the Beta-Binomial model, a powerful framework for detecting differential methylation while properly handling the overdispersion commonly seen in biological data [@problem_id:5172323].", "problem": "A research team is analyzing Whole-Genome Bisulfite Sequencing (WGBS) data for a single cytosine-phosphate-guanine (CpG) locus to detect differential methylation between two immunological cohorts: a disease group and a healthy control group. For each biological replicate $i$ in group $g \\in \\{A,B\\}$, the team measures the number of methylated reads $k_{g i}$ and the total coverage $n_{g i}$ at the locus. The underlying per-read methylation probability $p_{g i}$ is modeled to account for biological overdispersion across replicates by assuming that $p_{g i}$ is random, with $p_{g i} \\sim \\mathrm{Beta}(\\alpha_{g}, \\beta_{g})$, where $\\alpha_{g} = \\phi \\pi_{g}$ and $\\beta_{g} = \\phi (1 - \\pi_{g})$, and $\\phi > 0$ is a known dispersion parameter shared across groups. Conditional on $p_{g i}$, the observed count $k_{g i}$ follows a binomial distribution $k_{g i} \\mid p_{g i} \\sim \\mathrm{Binomial}(n_{g i}, p_{g i})$. The parameters $\\pi_{g} \\in (0,1)$ represent the group-level methylation proportions, and the independence of replicates across and within groups is assumed.\n\nStarting from the above hierarchical model and the definition of the Beta function $B(a,b) = \\int_{0}^{1} t^{a-1} (1-t)^{b-1} \\, dt$ (with the identity $B(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}$ relating it to the Gamma function $\\Gamma(\\cdot)$), derive the marginal likelihood for the observed counts under both the null hypothesis $H_{0} : \\pi_{A} = \\pi_{B} = \\pi$ and the alternative hypothesis $H_{1} : \\pi_{A} \\neq \\pi_{B}$. Then, construct the likelihood ratio test statistic $T$ by comparing the maximized null and alternative log-likelihoods. Provide the closed-form analytic expression of $T$ in terms of the observed counts $\\{(k_{g i}, n_{g i})\\}$, the known dispersion $\\phi$, and the maximum likelihood estimates $\\hat{\\pi}$ under $H_{0}$ and $(\\hat{\\pi}_{A}, \\hat{\\pi}_{B})$ under $H_{1}$. Finally, specify the asymptotic null distribution of $T$ under standard regularity conditions appropriate for this model.\n\nYour final answer must be a single closed-form analytic expression for the test statistic and the symbol for its asymptotic null distribution, presented together as a single row matrix using the $\\mathrm{pmatrix}$ environment. No numerical evaluation is required, and no units apply.", "solution": "The user wants to derive the likelihood ratio test statistic for differential methylation analysis using a Beta-Binomial model.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **Groups:** Two cohorts, disease group $A$ and healthy control group $B$, denoted by index $g \\in \\{A, B\\}$.\n-   **Data:** For each biological replicate $i$ in group $g$, the data consist of a pair $(k_{gi}, n_{gi})$, where $k_{gi}$ is the number of methylated reads and $n_{gi}$ is the total coverage. Let $N_A$ and $N_B$ be the number of replicates in group $A$ and $B$, respectively.\n-   **Hierarchical Model:**\n    1.  The conditional distribution of the count $k_{gi}$ given the per-read methylation probability $p_{gi}$ is Binomial: $k_{gi} \\mid p_{gi} \\sim \\mathrm{Binomial}(n_{gi}, p_{gi})$.\n    2.  The per-read methylation probability $p_{gi}$ for replicates in group $g$ is a random variable drawn from a Beta distribution to model biological overdispersion: $p_{gi} \\sim \\mathrm{Beta}(\\alpha_g, \\beta_g)$.\n-   **Parameterization:** The parameters of the Beta distribution are given by $\\alpha_g = \\phi \\pi_g$ and $\\beta_g = \\phi(1-\\pi_g)$, where:\n    -   $\\pi_g \\in (0,1)$ is the group-level mean methylation proportion for group $g$.\n    -   $\\phi > 0$ is a known dispersion parameter, shared between groups.\n-   **Hypotheses:**\n    -   Null Hypothesis ($H_0$): The group-level methylation proportions are equal, i.e., $\\pi_A = \\pi_B = \\pi$.\n    -   Alternative Hypothesis ($H_1$): The group-level methylation proportions are different, i.e., $\\pi_A \\neq \\pi_B$.\n-   **Identities Provided:**\n    -   Beta function: $B(a,b) = \\int_{0}^{1} t^{a-1} (1-t)^{b-1} \\, dt$.\n    -   Relation to Gamma function: $B(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}$.\n-   **Assumptions:** Independence of replicates across and within groups.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem describes a Beta-Binomial model, which is a standard and highly appropriate statistical framework for analyzing count data with overdispersion, such as read counts from whole-genome bisulfite sequencing (WGBS). The model is scientifically sound and widely used in bioinformatics.\n-   **Well-Posed:** The problem is well-posed. It requests the derivation of a likelihood ratio test (LRT) statistic, a standard procedure in statistical inference. The model is fully specified, and the question is structured to lead to a unique analytical result for the test statistic's form.\n-   **Objective:** The problem is stated in precise, formal, and objective mathematical and statistical terms.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. It is a standard, albeit detailed, exercise in statistical modeling and hypothesis testing, directly relevant to the specified field. I will proceed with the derivation.\n\n### Derivation\n\n**1. Marginal Likelihood of a Single Observation**\n\nFirst, we derive the marginal probability of observing $k_{gi}$ counts out of $n_{gi}$ total reads for a single replicate $i$ in group $g$. This is obtained by integrating the product of the conditional Binomial probability and the prior Beta probability over all possible values of $p_{gi}$. This is the probability mass function (PMF) of the Beta-Binomial distribution.\n\nThe conditional probability is:\n$$ P(k_{gi} | p_{gi}) = \\binom{n_{gi}}{k_{gi}} p_{gi}^{k_{gi}} (1-p_{gi})^{n_{gi}-k_{gi}} $$\nThe prior probability density for $p_{gi}$ is:\n$$ f(p_{gi} | \\alpha_g, \\beta_g) = \\frac{p_{gi}^{\\alpha_g-1} (1-p_{gi})^{\\beta_g-1}}{B(\\alpha_g, \\beta_g)} $$\nThe marginal probability $P(k_{gi})$ is the integral of their product:\n$$ P(k_{gi}) = \\int_0^1 P(k_{gi} | p_{gi}) f(p_{gi} | \\alpha_g, \\beta_g) \\, dp_{gi} $$\n$$ P(k_{gi}) = \\int_0^1 \\binom{n_{gi}}{k_{gi}} p_{gi}^{k_{gi}} (1-p_{gi})^{n_{gi}-k_{gi}} \\frac{p_{gi}^{\\alpha_g-1} (1-p_{gi})^{\\beta_g-1}}{B(\\alpha_g, \\beta_g)} \\, dp_{gi} $$\n$$ P(k_{gi}) = \\frac{\\binom{n_{gi}}{k_{gi}}}{B(\\alpha_g, \\beta_g)} \\int_0^1 p_{gi}^{k_{gi}+\\alpha_g-1} (1-p_{gi})^{n_{gi}-k_{gi}+\\beta_g-1} \\, dp_{gi} $$\nThe integral is, by definition, the Beta function $B(k_{gi}+\\alpha_g, n_{gi}-k_{gi}+\\beta_g)$.\n$$ P(k_{gi}) = \\binom{n_{gi}}{k_{gi}} \\frac{B(k_{gi}+\\alpha_g, n_{gi}-k_{gi}+\\beta_g)}{B(\\alpha_g, \\beta_g)} $$\nSubstituting $\\alpha_g = \\phi\\pi_g$ and $\\beta_g = \\phi(1-\\pi_g)$:\n$$ P(k_{gi}; \\pi_g, \\phi) = \\binom{n_{gi}}{k_{gi}} \\frac{B(k_{gi}+\\phi\\pi_g, n_{gi}-k_{gi}+\\phi(1-\\pi_g))}{B(\\phi\\pi_g, \\phi(1-\\pi_g))} $$\n\n**2. Log-Likelihood under the Alternative Hypothesis ($H_1$)**\n\nUnder $H_1: \\pi_A \\neq \\pi_B$, the parameters are $(\\pi_A, \\pi_B)$. The total likelihood $L_1$ is the product of the marginal probabilities for all independent observations.\n$$ L_1(\\pi_A, \\pi_B) = \\left( \\prod_{i=1}^{N_A} P(k_{Ai}; \\pi_A, \\phi) \\right) \\left( \\prod_{j=1}^{N_B} P(k_{Bj}; \\pi_B, \\phi) \\right) $$\nThe log-likelihood $\\ell_1 = \\ln L_1$ is:\n$$ \\ell_1(\\pi_A, \\pi_B) = \\sum_{i=1}^{N_A} \\ln P(k_{Ai}; \\pi_A, \\phi) + \\sum_{j=1}^{N_B} \\ln P(k_{Bj}; \\pi_B, \\phi) $$\n$$ \\ell_1(\\pi_A, \\pi_B) = \\sum_{g \\in \\{A,B\\}} \\sum_{i} \\left[ \\ln\\binom{n_{gi}}{k_{gi}} + \\ln B(k_{gi}+\\phi\\pi_g, n_{gi}-k_{gi}+\\phi(1-\\pi_g)) - \\ln B(\\phi\\pi_g, \\phi(1-\\pi_g)) \\right] $$\nThe term $\\ln\\binom{n_{gi}}{k_{gi}}$ does not depend on the parameters $\\pi_A, \\pi_B$ and will cancel in the likelihood ratio. Let $\\ell'_1$ be the part of the log-likelihood that depends on the parameters:\n$$ \\ell'_1(\\pi_A, \\pi_B) = \\sum_{g \\in \\{A,B\\}} \\sum_{i} \\left[ \\ln B(k_{gi}+\\phi\\pi_g, n_{gi}-k_{gi}+\\phi(1-\\pi_g)) - \\ln B(\\phi\\pi_g, \\phi(1-\\pi_g)) \\right] $$\nThe maximized log-likelihood under $H_1$ is $\\ell'_1(\\hat{\\pi}_A, \\hat{\\pi}_B)$, where $(\\hat{\\pi}_A, \\hat{\\pi}_B)$ are the Maximum Likelihood Estimates (MLEs).\n\n**3. Log-Likelihood under the Null Hypothesis ($H_0$)**\n\nUnder $H_0: \\pi_A = \\pi_B = \\pi$, there is a single parameter $\\pi$. The log-likelihood $\\ell_0(\\pi)$ is:\n$$ \\ell_0(\\pi) = \\sum_{g \\in \\{A,B\\}} \\sum_{i} \\ln P(k_{gi}; \\pi, \\phi) $$\n$$ \\ell_0(\\pi) = \\sum_{g,i} \\left[ \\ln\\binom{n_{gi}}{k_{gi}} + \\ln B(k_{gi}+\\phi\\pi, n_{gi}-k_{gi}+\\phi(1-\\pi)) - \\ln B(\\phi\\pi, \\phi(1-\\pi)) \\right] $$\nLet $\\ell'_0$ be the parameter-dependent part:\n$$ \\ell'_0(\\pi) = \\sum_{g,i} \\left[ \\ln B(k_{gi}+\\phi\\pi, n_{gi}-k_{gi}+\\phi(1-\\pi)) - \\ln B(\\phi\\pi, \\phi(1-\\pi)) \\right] $$\nThe maximized log-likelihood under $H_0$ is $\\ell'_0(\\hat{\\pi})$, where $\\hat{\\pi}$ is the MLE for the common proportion.\n\n**4. The Likelihood Ratio Test Statistic ($T$)**\n\nThe likelihood ratio test statistic $T$ is given by:\n$$ T = 2 \\left( \\sup_{\\pi_A, \\pi_B} \\ell_1(\\pi_A, \\pi_B) - \\sup_{\\pi} \\ell_0(\\pi) \\right) = 2 (\\ell_1(\\hat{\\pi}_A, \\hat{\\pi}_B) - \\ell_0(\\hat{\\pi})) $$\nThe constant terms cancel out, so we have:\n$$ T = 2 (\\ell'_1(\\hat{\\pi}_A, \\hat{\\pi}_B) - \\ell'_0(\\hat{\\pi})) $$\nLet's write this out explicitly. We use the identity $B(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}$, so $\\ln B(a,b) = \\ln\\Gamma(a) + \\ln\\Gamma(b) - \\ln\\Gamma(a+b)$.\n\nThe maximized alternative log-likelihood (parameter-dependent part) is:\n$$ \\ell'_1(\\hat{\\pi}_A, \\hat{\\pi}_B) = \\sum_{g \\in \\{A,B\\}} \\sum_{i=1}^{N_g} \\left[ \\ln\\Gamma(k_{gi}+\\phi\\hat{\\pi}_g) + \\ln\\Gamma(n_{gi}-k_{gi}+\\phi(1-\\hat{\\pi}_g)) - \\ln\\Gamma(n_{gi}+\\phi) \\right] \\\\ - \\sum_{g \\in \\{A,B\\}} N_g \\left[ \\ln\\Gamma(\\phi\\hat{\\pi}_g) + \\ln\\Gamma(\\phi(1-\\hat{\\pi}_g)) - \\ln\\Gamma(\\phi) \\right] $$\nThe maximized null log-likelihood (parameter-dependent part) is:\n$$ \\ell'_0(\\hat{\\pi}) = \\sum_{g \\in \\{A,B\\}} \\sum_{i=1}^{N_g} \\left[ \\ln\\Gamma(k_{gi}+\\phi\\hat{\\pi}) + \\ln\\Gamma(n_{gi}-k_{gi}+\\phi(1-\\hat{\\pi})) - \\ln\\Gamma(n_{gi}+\\phi) \\right] \\\\ - (N_A+N_B) \\left[ \\ln\\Gamma(\\phi\\hat{\\pi}) + \\ln\\Gamma(\\phi(1-\\hat{\\pi})) - \\ln\\Gamma(\\phi) \\right] $$\nWhen calculating $T=2(\\ell'_1(\\hat{\\pi}_A, \\hat{\\pi}_B) - \\ell'_0(\\hat{\\pi}))$, the terms $-\\ln\\Gamma(n_{gi}+\\phi)$ and $+\\ln\\Gamma(\\phi)$ cancel out. The resulting expression for $T$ is:\n$$ T = 2 \\Biggl( \\sum_{g \\in \\{A,B\\}} \\sum_{i=1}^{N_g} \\left[ \\ln\\Gamma(k_{gi}+\\phi\\hat{\\pi}_g) + \\ln\\Gamma(n_{gi}-k_{gi}+\\phi(1-\\hat{\\pi}_g)) \\right] - \\sum_{g \\in \\{A,B\\}} N_g \\left[ \\ln\\Gamma(\\phi\\hat{\\pi}_g) + \\ln\\Gamma(\\phi(1-\\hat{\\pi}_g)) \\right] \\\\ - \\left( \\sum_{g \\in \\{A,B\\}} \\sum_{i=1}^{N_g} \\left[ \\ln\\Gamma(k_{gi}+\\phi\\hat{\\pi}) + \\ln\\Gamma(n_{gi}-k_{gi}+\\phi(1-\\hat{\\pi})) \\right] - (N_A+N_B) \\left[ \\ln\\Gamma(\\phi\\hat{\\pi}) + \\ln\\Gamma(\\phi(1-\\hat{\\pi})) \\right] \\right) \\Biggr) $$\nThe expression can be rearranged by grouping terms for each dataset, which is notationally cleaner. For group $A$ with $N_A$ replicates indexed by $i$, and group $B$ with $N_B$ replicates indexed by $j$:\n$$ T = 2 \\Biggl( \\left( \\sum_{i=1}^{N_A} \\ln \\frac{\\Gamma(k_{Ai}+\\phi\\hat{\\pi}_A)}{\\Gamma(k_{Ai}+\\phi\\hat{\\pi})} + \\sum_{i=1}^{N_A} \\ln \\frac{\\Gamma(n_{Ai}-k_{Ai}+\\phi(1-\\hat{\\pi}_A))}{\\Gamma(n_{Ai}-k_{Ai}+\\phi(1-\\hat{\\pi}))} + N_A \\ln \\frac{\\Gamma(\\phi\\hat{\\pi})\\Gamma(\\phi(1-\\hat{\\pi}))}{\\Gamma(\\phi\\hat{\\pi}_A)\\Gamma(\\phi(1-\\hat{\\pi}_A))} \\right) \\\\ + \\left( \\sum_{j=1}^{N_B} \\ln \\frac{\\Gamma(k_{Bj}+\\phi\\hat{\\pi}_B)}{\\Gamma(k_{Bj}+\\phi\\hat{\\pi})} + \\sum_{j=1}^{N_B} \\ln \\frac{\\Gamma(n_{Bj}-k_{Bj}+\\phi(1-\\hat{\\pi}_B))}{\\Gamma(n_{Bj}-k_{Bj}+\\phi(1-\\hat{\\pi}))} + N_B \\ln \\frac{\\Gamma(\\phi\\hat{\\pi})\\Gamma(\\phi(1-\\hat{\\pi}))}{\\Gamma(\\phi\\hat{\\pi}_B)\\Gamma(\\phi(1-\\hat{\\pi}_B))} \\right) \\Biggl) $$\nFor the final answer, we present the first, more explicit, form.\n\n**5. Asymptotic Null Distribution of $T$**\n\nAccording to Wilks' theorem, for large sample sizes ($N_A, N_B \\to \\infty$), the likelihood ratio test statistic $T$ asymptotically follows a chi-squared ($\\chi^2$) distribution under the null hypothesis, provided certain regularity conditions are met. These conditions are satisfied by the Beta-Binomial model. The degrees of freedom for the $\\chi^2$ distribution is the difference in the number of free parameters between the alternative and null models.\n-   Dimension of parameter space under $H_1$: The parameters are $(\\pi_A, \\pi_B)$, so the dimension is $2$.\n-   Dimension of parameter space under $H_0$: The constraint $\\pi_A = \\pi_B = \\pi$ leaves one free parameter, $\\pi$, so the dimension is $1$.\n-   Difference in dimensions (degrees of freedom): $2 - 1 = 1$.\n\nTherefore, the asymptotic distribution of $T$ under $H_0$ is a chi-squared distribution with $1$ degree of freedom.\n$$ T \\xrightarrow{d} \\chi^2_1 \\quad \\text{under } H_0 $$\n\nFinal Answer Composition: The question requires the closed-form expression for $T$ and its asymptotic null distribution. This composite answer will be presented as a row matrix. The expression for $T$ below is expanded for full clarity, where summations over $i$ for group $g$ span all replicates in that group, with $N_g$ being the number of replicates.\n\n$$ T = 2 \\Biggl( \\sum_{g \\in \\{A,B\\}} \\sum_{i=1}^{N_g} \\left[ \\ln\\Gamma(k_{gi}+\\phi\\hat{\\pi}_g) + \\ln\\Gamma(n_{gi}-k_{gi}+\\phi(1-\\hat{\\pi}_g)) \\right] - \\sum_{g \\in \\{A,B\\}} N_g \\left[ \\ln\\Gamma(\\phi\\hat{\\pi}_g) + \\ln\\Gamma(\\phi(1-\\hat{\\pi}_g)) \\right] \\\\ - \\sum_{g \\in \\{A,B\\}} \\sum_{i=1}^{N_g} \\left[ \\ln\\Gamma(k_{gi}+\\phi\\hat{\\pi}) + \\ln\\Gamma(n_{gi}-k_{gi}+\\phi(1-\\hat{\\pi})) \\right] + (N_A+N_B) \\left[ \\ln\\Gamma(\\phi\\hat{\\pi}) + \\ln\\Gamma(\\phi(1-\\hat{\\pi})) \\right] \\Biggr) $$\nHere, $\\hat{\\pi}_g$ represents the MLE for group $g$ under $H_1$ (i.e., $\\hat{\\pi}_A$ for group $A$ and $\\hat{\\pi}_B$ for group $B$).", "answer": "$$ \\boxed{ \\begin{pmatrix} 2 \\Biggl( \\displaystyle\\sum_{g \\in \\{A,B\\}} \\sum_{i=1}^{N_g} \\left[ \\ln\\Gamma(k_{gi}+\\phi\\hat{\\pi}_g) + \\ln\\Gamma(n_{gi}-k_{gi}+\\phi(1-\\hat{\\pi}_g)) \\right] - \\sum_{g \\in \\{A,B\\}} N_g \\left[ \\ln\\Gamma(\\phi\\hat{\\pi}_g) + \\ln\\Gamma(\\phi(1-\\hat{\\pi}_g)) \\right] - \\sum_{g \\in \\{A,B\\}} \\sum_{i=1}^{N_g} \\left[ \\ln\\Gamma(k_{gi}+\\phi\\hat{\\pi}) + \\ln\\Gamma(n_{gi}-k_{gi}+\\phi(1-\\hat{\\pi})) \\right] + (N_A+N_B) \\left[ \\ln\\Gamma(\\phi\\hat{\\pi}) + \\ln\\Gamma(\\phi(1-\\hat{\\pi})) \\right] \\Biggr) & \\chi^2_1 \\end{pmatrix} } $$", "id": "5172323"}]}