{"hands_on_practices": [{"introduction": "A foundational step in any experiment using Unique Molecular Identifiers (UMIs) is determining the required diversity of the UMI library. If the UMI pool is too small relative to the number of molecules being tagged, different molecules may be assigned the same UMI by chance—an event known as a \"collision.\" This exercise [@problem_id:5169920] guides you through the process of modeling this phenomenon, which is analogous to the classic \"birthday problem,\" to calculate the minimum UMI length needed to keep these collisions below a desired threshold, ensuring the integrity of molecular counting.", "problem": "In a high-throughput immunodiagnostic assay based on Next-Generation Sequencing (NGS), Unique Molecular Identifiers (UMIs) are used to tag and deduplicate original molecules to accurately estimate abundance. A Unique Molecular Identifier (UMI) is a random deoxyribonucleic acid (DNA) oligonucleotide of length $L$, synthesized so that each position is independently and uniformly chosen from the four nucleotides. Thus, the total UMI design space is $M = 4^{L}$ distinct barcodes. Consider a library with $n = 10^{6}$ distinct molecules, each independently and uniformly assigned a UMI from the $M$ possibilities.\n\nDefine the expected collision rate $\\rho(M,n)$ as the expected fraction (expressed as a decimal) of molecules whose assigned UMI is not unique within the library, meaning that there exists at least one other molecule sharing the same UMI. Starting only from fundamental probability definitions for independent sampling with replacement and the uniform distribution over $M$ labels, derive a closed-form expression for $\\rho(M,n)$ and then determine the minimum integer UMI length $L$ such that $\\rho(4^{L}, 10^{6}) < 0.01$. Report the minimal integer $L$ as your final answer. No rounding is required beyond choosing the minimal integer.", "solution": "The problem asks for two results: first, a closed-form expression for the expected collision rate $\\rho(M, n)$, and second, the minimum integer UMI length $L$ that satisfies a given condition on this rate. The problem statement is scientifically sound, well-posed, and objective. We can proceed with a formal derivation.\n\nLet $n$ be the number of distinct molecules, and let $M$ be the size of the UMI design space. Each of the $n$ molecules is assigned a UMI by independently sampling with replacement from the $M$ available UMIs, with each UMI having a uniform probability of $1/M$ of being chosen.\n\nWe are asked to find the expected collision rate, $\\rho(M, n)$, defined as the expected fraction of molecules whose assigned UMI is not unique. Let $C$ be the random variable representing the total number of molecules that have a non-unique UMI (i.e., at least one other molecule shares their UMI). The fraction of such molecules is $C/n$. The expected collision rate is therefore $\\rho(M, n) = E\\left[\\frac{C}{n}\\right]$. By the linearity of expectation, this is equal to $\\frac{1}{n}E[C]$.\n\nTo find the expected value of $C$, we can use the method of indicator variables. For each molecule $i \\in \\{1, 2, \\ldots, n\\}$, let $I_i$ be an indicator random variable defined as:\n$$\nI_i =\n\\begin{cases}\n1 & \\text{if molecule } i \\text{ has a non-unique UMI} \\\\\n0 & \\text{if molecule } i \\text{ has a unique UMI}\n\\end{cases}\n$$\nThe total number of molecules with a non-unique UMI is the sum of these indicators: $C = \\sum_{i=1}^{n} I_i$.\nUsing the linearity of expectation, the expected value of $C$ is:\n$$E[C] = E\\left[\\sum_{i=1}^{n} I_i\\right] = \\sum_{i=1}^{n} E[I_i]$$\nFor an indicator variable, its expectation is equal to the probability of the event it indicates: $E[I_i] = P(I_i = 1)$.\nThe event $I_i = 1$ occurs if the UMI assigned to molecule $i$ is not unique. It is simpler to calculate the probability of the complementary event, $I_i = 0$, which is that the UMI of molecule $i$ is unique.\n$$P(I_i = 1) = 1 - P(I_i = 0)$$\nThe UMI assigned to molecule $i$ is unique if and only if none of the other $n-1$ molecules are assigned the same UMI. Let $U_i$ be the UMI assigned to molecule $i$. For any other molecule $j \\neq i$, the probability that its UMI, $U_j$, is different from $U_i$ is $P(U_j \\neq U_i) = \\frac{M-1}{M}$. This is because there are $M-1$ \"successful\" outcomes out of $M$ total possibilities for $U_j$.\n\nSince the UMI for each of the $n-1$ other molecules is chosen independently, the probability that all of them are different from $U_i$ is the product of their individual probabilities:\n$$P(I_i = 0) = \\left(\\frac{M-1}{M}\\right)^{n-1} = \\left(1 - \\frac{1}{M}\\right)^{n-1}$$\nTherefore, the probability that molecule $i$ has a non-unique UMI is:\n$$P(I_i = 1) = 1 - \\left(1 - \\frac{1}{M}\\right)^{n-1}$$\nBy symmetry, this probability is the same for all molecules $i=1, \\ldots, n$. So, $E[I_i] = 1 - \\left(1 - \\frac{1}{M}\\right)^{n-1}$ for all $i$.\nNow we can compute $E[C]$:\n$$E[C] = \\sum_{i=1}^{n} \\left[1 - \\left(1 - \\frac{1}{M}\\right)^{n-1}\\right] = n \\left[1 - \\left(1 - \\frac{1}{M}\\right)^{n-1}\\right]$$\nFinally, we can write the expression for the expected collision rate $\\rho(M, n)$:\n$$\\rho(M, n) = \\frac{E[C]}{n} = \\frac{n \\left[1 - \\left(1 - \\frac{1}{M}\\right)^{n-1}\\right]}{n} = 1 - \\left(1 - \\frac{1}{M}\\right)^{n-1}$$\nThis is the required closed-form expression.\n\nNow, we must find the minimum integer UMI length $L$ such that $\\rho(4^L, 10^6) < 0.01$. We are given $n = 10^6$ and the UMI design space is $M = 4^L$.\nThe inequality to solve is:\n$$1 - \\left(1 - \\frac{1}{4^L}\\right)^{10^6 - 1} < 0.01$$\nLet's substitute $M = 4^L$ and $n = 10^6$:\n$$1 - \\left(1 - \\frac{1}{M}\\right)^{n-1} < 0.01$$\n$$0.99 < \\left(1 - \\frac{1}{M}\\right)^{n-1}$$\nTo solve for $M$, we take the natural logarithm of both sides. Since $\\ln(x)$ is a monotonically increasing function, the direction of the inequality is preserved:\n$$\\ln(0.99) < (n-1) \\ln\\left(1 - \\frac{1}{M}\\right)$$\nFor the expected collision rate to be small, $M$ must be much larger than $n$. Thus, $1/M$ is very small. We can use the Taylor series approximation for the natural logarithm, $\\ln(1+x) \\approx x$ for small $|x|$. Let $x = -1/M$. The approximation is $\\ln(1 - 1/M) \\approx -1/M$. This approximation is highly accurate in this regime.\nSubstituting this into the inequality:\n$$\\ln(0.99) < (n-1) \\left(-\\frac{1}{M}\\right) = -\\frac{n-1}{M}$$\nTo isolate $M$, we can multiply both sides by $-M$. Since $M > 0$ and $\\ln(0.99) < 0$, the term $-\\ln(0.99)$ is positive. This operation reverses the inequality sign:\n$$-M \\ln(0.99) > n-1$$\n$$M > \\frac{n-1}{-\\ln(0.99)}$$\nNow, we substitute the numerical values $n = 10^6$:\n$$M > \\frac{10^6 - 1}{-\\ln(0.99)} = \\frac{999999}{-\\ln(0.99)}$$\nUsing a calculator, $\\ln(0.99) \\approx -0.01005033585$.\n$$M > \\frac{999999}{0.01005033585} \\approx 99499119.4$$\nWe have the relationship $M = 4^L$. So we must find the smallest integer $L$ such that:\n$$4^L > 99499119.4$$\nTaking the base-$4$ logarithm of both sides:\n$$L > \\log_4(99499119.4)$$\nThis can be calculated as:\n$$L > \\frac{\\ln(99499119.4)}{\\ln(4)}$$\nUsing a calculator for the logarithms: $\\ln(99499119.4) \\approx 18.415509$ and $\\ln(4) \\approx 1.386294$.\n$$L > \\frac{18.415509}{1.386294} \\approx 13.2839$$\nSince the UMI length $L$ must be an integer, the minimum integer value for $L$ that satisfies this condition is $14$.\nTo verify, let's check the values of $4^L$ around this threshold:\nFor $L=13$, $M = 4^{13} = 67,108,864$, which is less than the required $99,499,119.4$.\nFor $L=14$, $M = 4^{14} = 268,435,456$, which is greater than the required $99,499,119.4$.\nThus, the minimal integer UMI length is $14$.", "answer": "$$\\boxed{14}$$", "id": "5169920"}, {"introduction": "While a sufficiently large UMI library can minimize random collisions, it does not eliminate errors introduced during sequencing. A single base-calling error in a UMI sequence can create a \"new\" UMI that is not present in the original library, leading to an artificial inflation of molecule counts. This practice [@problem_id:5169904] delves into this critical issue by asking you to derive the expected analytical bias caused by such errors and to formulate a correction factor, providing a powerful tool to improve the accuracy of UMI-based quantification.", "problem": "In molecular and immunodiagnostics workflows that use Unique Molecular Identifiers (UMIs), deduplication often assumes UMI sequences are error-free and collapses reads only when their UMIs are exactly identical. Consider a library where each original molecule is tagged by a UMI of length $L$ bases chosen uniformly from a four-nucleotide alphabet (so there are $4^{L}$ possible UMIs), and each molecule yields exactly $r$ independent sequencing reads. Assume a per-base sequencing error rate $e$ that is independent across bases and reads; when any base in a UMI is erroneously sequenced, the resulting UMI sequence differs from the true UMI. Assume the UMI space is sufficiently large (that is, $4^{L}$ is much larger than the number of reads per molecule) so that collisions between distinct erroneous UMIs, or between an erroneous UMI and a true UMI from another molecule, are negligible.\n\nStarting from first principles of independent sequencing errors and basic probability, derive the expected multiplicative bias introduced by treating UMIs as error-free in deduplication. Define the bias $b(e,L,r)$ as the expected ratio of the observed unique-UMI count to the true molecule count minus $1$, that is, $b(e,L,r) = \\frac{\\mathbb{E}[M_{\\text{obs}}]}{N} - 1$, where $M_{\\text{obs}}$ is the observed number of unique UMIs after exact-match deduplication and $N$ is the true number of molecules. Next, propose a correction factor $c(e,L,r)$ to multiply the observed unique-UMI count so that the resulting estimator is unbiased for $N$ under the stated assumptions.\n\nExpress your final bias and correction factor as closed-form analytic expressions that depend on $e$, $L$, and $r$. No numerical approximation or rounding is required. Your answers must be unitless analytic expressions.", "solution": "The problem requires the derivation of the multiplicative bias in molecule counting when sequencing errors in Unique Molecular Identifiers (UMIs) are ignored, and a corresponding correction factor. The solution will be derived from first principles of probability theory, based on the model and assumptions provided.\n\nFirst, let's establish the basic probabilities related to sequencing a single UMI.\nA UMI has a length of $L$ bases.\nThe per-base sequencing error rate is $e$.\nThe probability that a single base is sequenced correctly is $1-e$.\nSince sequencing errors are independent across bases, the probability that an entire UMI of length $L$ is sequenced correctly is the product of the probabilities of each of its $L$ bases being sequenced correctly. Let this probability be $p_c$.\n$$p_c = (1-e)^L$$\nThe probability that a UMI is sequenced erroneously (i.e., at least one base has an error) is $p_e$.\n$$p_e = 1 - p_c = 1 - (1-e)^L$$\n\nThe problem is simplified by the crucial assumption that the UMI space is large enough to make collisions negligible. This implies that:\n1.  Any two distinct erroneous UMI sequences generated are unique.\n2.  Any erroneous UMI sequence is not identical to any true UMI sequence present in the original sample.\nEffectively, every sequencing event that produces an erroneous UMI creates a new, unique identifier that has not been seen before. The only way multiple reads are collapsed into a single count is if they are error-free and thus identical to the true UMI of the parent molecule.\n\nLet us consider a single original molecule. It is tagged with one true UMI and gives rise to exactly $r$ independent sequencing reads. Let $M_{\\text{obs},1}$ be the number of unique UMIs observed for this single molecule. The total expected number of observed unique UMIs, $\\mathbb{E}[M_{\\text{obs}}]$, for $N$ molecules can be found by leveraging the linearity of expectation and the non-collision assumption. The non-collision assumption ensures that the sets of UMIs generated from different original molecules are disjoint. Therefore, $\\mathbb{E}[M_{\\text{obs}}] = N \\cdot \\mathbb{E}[M_{\\text{obs},1}]$. We need to find $\\mathbb{E}[M_{\\text{obs},1}]$.\n\nLet $K$ be the number of erroneous reads among the $r$ reads from our single molecule. Each read is an independent Bernoulli trial with a probability of error $p_e$. Thus, $K$ follows a binomial distribution, $K \\sim \\text{Binomial}(r, p_e)$.\n\nWe can determine the number of unique UMIs observed, $M_{\\text{obs},1}$, by conditioning on the value of $K$.\nIf $K=k$ for $k \\in \\{0, 1, \\dots, r-1\\}$, there are $k$ erroneous reads and $r-k > 0$ correct reads.\n-   The $k$ erroneous reads, by the non-collision assumption, produce $k$ distinct UMIs.\n-   The $r-k$ correct reads all produce the same true UMI.\n-   The total number of unique UMIs observed is $k$ (from errors) $+ 1$ (the true UMI) = $k+1$.\nIf $K=r$, all $r$ reads are erroneous.\n-   The $r$ erroneous reads produce $r$ distinct UMIs.\n-   The true UMI is not observed since there are no correct reads.\n-   The total number of unique UMIs observed is $r$.\n\nWe can express the random variable $M_{\\text{obs},1}$ in terms of $K$:\n$M_{\\text{obs},1} = K+1$ if $K < r$, and $M_{\\text{obs},1} = r$ if $K=r$. This can be written compactly using an indicator function $I(K=r)$:\n$$M_{\\text{obs},1} = K + 1 - I(K=r)$$\nwhere $I(K=r)$ is $1$ if $K=r$ and $0$ otherwise.\n\nWe can now find the expected value of $M_{\\text{obs},1}$ using the linearity of expectation:\n$$\\mathbb{E}[M_{\\text{obs},1}] = \\mathbb{E}[K + 1 - I(K=r)] = \\mathbb{E}[K] + 1 - \\mathbb{E}[I(K=r)]$$\nFor a binomial random variable $K \\sim \\text{Binomial}(r, p_e)$, the expectation is $\\mathbb{E}[K] = r \\cdot p_e$.\nThe expectation of the indicator function is the probability of the event: $\\mathbb{E}[I(K=r)] = P(K=r)$.\nFor a binomial distribution, $P(K=r) = \\binom{r}{r} p_e^r (1-p_e)^{r-r} = p_e^r$.\nSubstituting these results gives:\n$$\\mathbb{E}[M_{\\text{obs},1}] = r \\cdot p_e + 1 - p_e^r$$\nSubstituting the expression for $p_e$:\n$$\\mathbb{E}[M_{\\text{obs},1}] = 1 + r(1 - (1-e)^L) - (1 - (1-e)^L)^r$$\nThis is the expected number of unique UMIs generated from a single true molecule.\n\nNow we can derive the bias $b(e,L,r)$, defined as $\\frac{\\mathbb{E}[M_{\\text{obs}}]}{N} - 1$.\n$$b(e,L,r) = \\frac{N \\cdot \\mathbb{E}[M_{\\text{obs},1}]}{N} - 1 = \\mathbb{E}[M_{\\text{obs},1}] - 1$$\n$$b(e,L,r) = \\left( 1 + r(1 - (1-e)^L) - (1 - (1-e)^L)^r \\right) - 1$$\n$$b(e,L,r) = r(1 - (1-e)^L) - (1 - (1-e)^L)^r$$\nThis expression represents the expected fractional overestimation of the true molecule count.\n\nNext, we propose a correction factor $c(e,L,r)$ for an unbiased estimator of $N$. The estimator is $\\hat{N} = c(e,L,r) \\cdot M_{\\text{obs}}$. For this estimator to be unbiased, its expectation must equal the true value $N$:\n$$\\mathbb{E}[\\hat{N}] = N$$\n$$\\mathbb{E}[c(e,L,r) \\cdot M_{\\text{obs}}] = N$$\nSince $c(e,L,r)$ is a deterministic factor, we have:\n$$c(e,L,r) \\cdot \\mathbb{E}[M_{\\text{obs}}] = N$$\n$$c(e,L,r) \\cdot (N \\cdot \\mathbb{E}[M_{\\text{obs},1}]) = N$$\nSolving for $c(e,L,r)$ for $N>0$:\n$$c(e,L,r) = \\frac{1}{\\mathbb{E}[M_{\\text{obs},1}]}$$\nSubstituting the expression for $\\mathbb{E}[M_{\\text{obs},1}]$:\n$$c(e,L,r) = \\frac{1}{1 + r(1 - (1-e)^L) - (1 - (1-e)^L)^r}$$\nMultiplying the observed unique UMI count $M_{\\text{obs}}$ by this factor provides an unbiased estimate of the true number of molecules $N$ under the stated assumptions.", "answer": "$$\\boxed{\\begin{aligned} \\text{Bias } b(e,L,r) = r(1 - (1-e)^L) - (1 - (1-e)^L)^r \\\\ \\text{Correction factor } c(e,L,r) = \\frac{1}{1 + r(1 - (1-e)^L) - (1 - (1-e)^L)^r} \\end{aligned}}$$", "id": "5169904"}, {"introduction": "The ultimate goal of using UMIs is to generate a high-confidence consensus from multiple reads originating from a single molecule, thereby filtering out sequencing and amplification artifacts. This final exercise [@problem_id:5169827] challenges you to build a sophisticated Bayesian model that accomplishes this. By integrating various sources of information—including per-base quality scores, prior probabilities of variants, and models for different types of experimental errors—you will learn to calculate the posterior probability of a genetic variant, representing the pinnacle of quantitative analysis in UMI-based diagnostics.", "problem": "A targeted immunodiagnostics assay employs Unique Molecular Identifier (UMI) families to suppress sequencing errors through consensus. Consider a single genomic locus whose reference base is \"G.\" A UMI family of size $n=8$ provides base calls at this locus: seven reads call \"A\" with Phred quality scores $Q = 35, 30, 33, 25, 38, 32, 34$ respectively, and one read calls \"G\" with Phred quality score $Q=40$. The Phred quality score $Q$ and the probability of a per-read base-calling error $p$ are related by the standard definition $Q = -10 \\log_{10}(p)$, so $p = 10^{-Q/10}$. Assume that, conditional on the underlying template base for the UMI family, sequencing errors across reads are independent and that a substitution error produces each of the three non-true bases with equal probability. \n\nModel two mutually exclusive hypotheses for the underlying template base of this UMI family at the locus:\n- $H_{V}$: the original molecule is truly variant with base \"A\" at this locus.\n- $H_{R}$: the original molecule is truly reference with base \"G\" at this locus.\n\nIn UMI-aware Bayesian modeling, incorporate two error channels:\n1. Per-read sequencing error characterized by the per-read $p_i = 10^{-Q_i/10}$.\n2. A family-level pre-amplification polymerase error that converts the underlying template base from \"G\" to \"A\" with probability $\\epsilon_{\\mathrm{pcr}}$, after which all reads derive from the incorrect template. If no family-level error occurs, the template remains \"G\" and reads follow the per-read error model.\n\nLet the prior probability that the original molecule is truly variant at this locus be $\\pi_{V}$, and the prior probability that it is truly reference be $1 - \\pi_{V}$. Use the following parameters: $\\pi_{V} = 1.0 \\times 10^{-5}$ and $\\epsilon_{\\mathrm{pcr}} = 1.0 \\times 10^{-6}$. Using Bayes' theorem and the assumptions above, construct the Bayesian consensus model for this UMI family and derive the posterior probability $P(H_{V} \\mid \\text{data})$ that the underlying template base for the UMI family is the variant \"A.\" \n\nExpress the final probability as a decimal and round your answer to four significant figures.", "solution": "We begin by invoking Bayes' theorem. With data $\\mathcal{D}$ given by the observed base calls and their Phred quality scores, the posterior probability for the variant hypothesis $H_{V}$ is\n$$\nP(H_{V} \\mid \\mathcal{D}) = \\frac{P(\\mathcal{D} \\mid H_{V}) P(H_{V})}{P(\\mathcal{D} \\mid H_{V}) P(H_{V}) + P(\\mathcal{D} \\mid H_{R}) P(H_{R})},\n$$\nwhere $P(H_{V}) = \\pi_{V}$ and $P(H_{R}) = 1 - \\pi_{V}$.\n\nWe must compute the likelihoods $P(\\mathcal{D} \\mid H_{V})$ and $P(\\mathcal{D} \\mid H_{R})$ under the stated error model.\n\nUnder $H_{V}$, the underlying template base is \"A.\" Each read that reports \"A\" is correct with probability $1 - p_i$, and each read that reports one of the other bases is erroneous. For the single read that reports \"G,\" the probability of specifically observing \"G\" given the true base \"A\" and a sequencing error is $p_8/3$ by the uniform substitution assumption. Therefore,\n$$\nL_{V} \\equiv P(\\mathcal{D} \\mid H_{V}) = \\left(\\prod_{i=1}^{7} (1 - p_i)\\right) \\cdot \\frac{p_8}{3}.\n$$\n\nUnder $H_{R}$, the underlying true template base is \"G,\" but there is a mixture due to the family-level error channel. With probability $\\epsilon_{\\mathrm{pcr}}$, an early polymerase error converts the template to \"A\" for the entire family, after which the read-generation process and likelihood match the $H_{V}$ case. With probability $1 - \\epsilon_{\\mathrm{pcr}}$, no family-level error occurs and the template remains \"G.\" In this no-family-error case, a read reporting \"G\" is correct with probability $1 - p_i$ and a read reporting \"A\" is a specific substitution error with probability $p_i/3$. Thus,\n$$\nL_{R} \\equiv P(\\mathcal{D} \\mid H_{R}) = \\epsilon_{\\mathrm{pcr}} \\, L_{V} \\;+\\; (1 - \\epsilon_{\\mathrm{pcr}}) \\left[ \\left(\\prod_{i=1}^{7} \\frac{p_i}{3}\\right) \\cdot (1 - p_8) \\right].\n$$\n\nNext, we compute the per-read error probabilities from the Phred scores $p_i = 10^{-Q_i/10}$:\n- For the seven reads calling \"A\":\n\n$$\n\\begin{aligned}\np_1 = 10^{-35/10} = 10^{-3.5} \\approx 3.162 \\times 10^{-4}, \\\\\np_2 = 10^{-30/10} = 10^{-3} = 1.000 \\times 10^{-3}, \\\\\np_3 = 10^{-33/10} = 10^{-3.3} \\approx 5.012 \\times 10^{-4}, \\\\\np_4 = 10^{-25/10} = 10^{-2.5} \\approx 3.162 \\times 10^{-3}, \\\\\np_5 = 10^{-38/10} = 10^{-3.8} \\approx 1.585 \\times 10^{-4}, \\\\\np_6 = 10^{-32/10} = 10^{-3.2} \\approx 6.310 \\times 10^{-4}, \\\\\np_7 = 10^{-34/10} = 10^{-3.4} \\approx 3.981 \\times 10^{-4},\n\\end{aligned}\n$$\n\nand for the single read calling \"G\":\n\n$$\np_8 = 10^{-40/10} = 10^{-4} = 1.000 \\times 10^{-4}.\n$$\n\n\nWe now compute $L_{V}$:\n\n$$\n\\prod_{i=1}^{7} (1 - p_i) \\approx (0.9996838)(0.9990000)(0.9994988)(0.9968377)(0.9998415)(0.9993690)(0.9996019) \\approx 0.9938458.\n$$\n\nTherefore,\n\n$$\nL_{V} = 0.9938458 \\times \\frac{p_8}{3} = 0.9938458 \\times \\frac{1.000 \\times 10^{-4}}{3} \\approx 3.3128 \\times 10^{-5}.\n$$\n\n\nNext compute the no-family-error component under $H_{R}$:\n\n$$\n\\left(\\prod_{i=1}^{7} \\frac{p_i}{3}\\right) \\cdot (1 - p_8) = \\left(\\frac{1}{3}\\right)^{7} \\left(\\prod_{i=1}^{7} p_i\\right) \\cdot (1 - p_8).\n$$\n\nWe approximate\n\n$$\n\\prod_{i=1}^{7} p_i \\approx (3.162 \\times 10^{-4})(1.000 \\times 10^{-3})(5.012 \\times 10^{-4})(3.162 \\times 10^{-3})(1.585 \\times 10^{-4})(6.310 \\times 10^{-4})(3.981 \\times 10^{-4}) \\approx 1.9953 \\times 10^{-23}.\n$$\n\nSince $\\left(\\frac{1}{3}\\right)^{7} = \\frac{1}{3^{7}} = \\frac{1}{2187} \\approx 4.572 \\times 10^{-4}$ and $(1 - p_8) = 0.9999$, we have\n\n$$\n\\left(\\prod_{i=1}^{7} \\frac{p_i}{3}\\right) \\cdot (1 - p_8) \\approx (4.572 \\times 10^{-4})(1.9953 \\times 10^{-23})(0.9999) \\approx 9.116 \\times 10^{-27}.\n$$\n\nThus,\n\n$$\nL_{R} = \\epsilon_{\\mathrm{pcr}} \\, L_{V} + (1 - \\epsilon_{\\mathrm{pcr}}) \\times 9.116 \\times 10^{-27} \\approx (1.0 \\times 10^{-6})(3.3128 \\times 10^{-5}) + 9.116 \\times 10^{-27} \\approx 3.3128 \\times 10^{-11}.\n$$\n\n\nFinally, apply Bayes' theorem with $\\pi_{V} = 1.0 \\times 10^{-5}$:\n\n$$\nP(H_{V} \\mid \\mathcal{D}) = \\frac{\\pi_{V} L_{V}}{\\pi_{V} L_{V} + (1 - \\pi_{V}) L_{R}}.\n$$\n\nCompute the numerator:\n\n$$\n\\pi_{V} L_{V} = (1.0 \\times 10^{-5})(3.3128 \\times 10^{-5}) = 3.3128 \\times 10^{-10}.\n$$\n\nCompute the denominator:\n\n$$\n\\pi_{V} L_{V} + (1 - \\pi_{V}) L_{R} \\approx 3.3128 \\times 10^{-10} + (0.99999)(3.3128 \\times 10^{-11}) \\approx 3.3128 \\times 10^{-10} + 3.3128 \\times 10^{-11} = 3.6441 \\times 10^{-10}.\n$$\n\nTherefore,\n\n$$\nP(H_{V} \\mid \\mathcal{D}) \\approx \\frac{3.3128 \\times 10^{-10}}{3.6441 \\times 10^{-10}} \\approx 0.9091.\n$$\n\nExpressed as a decimal and rounded to four significant figures, the posterior probability is $0.9091$.", "answer": "$$\\boxed{0.9091}$$", "id": "5169827"}]}