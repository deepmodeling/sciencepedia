{"hands_on_practices": [{"introduction": "A fundamental skill in operating any sequencing platform is the ability to predict and evaluate its performance. This practice connects the key operational parameters of a nanopore sequencing run—such as the number of active pores ($N$), their occupancy ($p$), and the translocation speed ($v$)—to the total data yield ($Y$). By deriving the expected yield from first principles, you will gain a quantitative understanding of sequencing throughput and learn how to assess the efficiency of a real-world experiment by comparing theoretical predictions with observed data, as demonstrated in this exercise [@problem_id:5138882].", "problem": "A clinical laboratory uses an Oxford Nanopore Technologies (ONT) flow cell during a targeted immunodiagnostics assay. The sequencing conditions are held constant, and the following summary statistics are recorded during the steady-state window of the run:\n\n- Number of active nanopores at steady state: $N = 1450$.\n- Time-averaged occupancy (fraction of time each pore is translocating DNA under motor control): $p = 0.82$.\n- Average read length: $\\bar{L} = 18000$ bases.\n- Motor stepping rate under the applied bias and chemistry: $v = 450$ bases per second.\n- Duration of steady-state data collection: $T = 18$ hours.\n- Basecaller-reported observed production over the same interval: $Y_{\\text{obs}} = 33.90$ gigabases.\n\nStarting from first principles of renewal processes and rate definitions relevant to nanopore strand sequencing, derive an expression for the expected total yield in bases as a function of $N$, $p$, $\\bar{L}$, $v$, and $T$ under steady-state conditions. Use physically justified assumptions about how occupancy and motor stepping rate determine per-pore base emission. Then evaluate the expected yield numerically and compute the fractional deviation between the observed and expected yields, defined as\n$$\\delta \\equiv \\frac{Y_{\\text{obs}} - Y_{\\text{exp}}}{Y_{\\text{exp}}}.$$\nExpress the intermediate expected yield in gigabases for clarity, but report only the final value of $\\delta$ as a unitless decimal. Round your final answer for $\\delta$ to four significant figures.", "solution": "The problem statement is first validated for scientific soundness, completeness, and objectivity.\n\n### Step 1: Extract Givens\nThe following data are provided in the problem statement:\n- Number of active nanopores at steady state: $N = 1450$.\n- Time-averaged occupancy: $p = 0.82$.\n- Average read length: $\\bar{L} = 18000$ bases.\n- Motor stepping rate: $v = 450$ bases per second.\n- Duration of steady-state data collection: $T = 18$ hours.\n- Observed production (yield): $Y_{\\text{obs}} = 33.90$ gigabases.\n- Definition of fractional deviation: $\\delta \\equiv \\frac{Y_{\\text{obs}} - Y_{\\text{exp}}}{Y_{\\text{exp}}}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, describing a standard nanopore sequencing experiment. The parameters given ($N$, $p$, $\\bar{L}$, $v$, $T$, $Y_{\\text{obs}}$) are within realistic ranges for current Oxford Nanopore Technologies platforms. The concepts used are central to the field of molecular diagnostics using strand sequencing. The problem is well-posed, providing all necessary information to derive the expected yield, $Y_{\\text{exp}}$, based on a physical model, and then to compute the requested fractional deviation, $\\delta$. The problem is expressed in objective, quantitative terms, with unambiguous definitions. The inclusion of $\\bar{L}$, which will be shown to cancel out of the final rate expression, is not a contradiction but a feature of the physical model that demonstrates a deeper understanding of the process; it is required for the conceptual derivation from renewal process principles. Therefore, the problem is not underspecified, overconstrained, or ill-posed.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\n### Derivation of Expected Yield ($Y_{\\text{exp}}$)\nThe expected total yield, $Y_{\\text{exp}}$, is the total number of bases sequenced over the duration $T$. This can be calculated by determining the time-averaged rate of base production for the entire system and multiplying by the duration.\n\nWe start from the first principles of the sequencing process for a single pore. The motor stepping rate, $v$, represents the instantaneous speed of base translocation, in units of bases per second, *during the time a DNA strand is actively being read*. The time-averaged occupancy, $p$, is the dimensionless fraction of total time that a pore is in this active, translocating state.\n\nThe time-averaged rate of base production for a single pore, $R_{\\text{pore}}$, is therefore the product of the rate during translocation and the probability of being in that state:\n$$R_{\\text{pore}} = p \\cdot v$$\n\nAssuming the $N$ active pores operate independently, the total time-averaged rate of base production for the entire flow cell, $R_{\\text{total}}$, is the sum of the individual pore rates:\n$$R_{\\text{total}} = \\sum_{i=1}^{N} R_{\\text{pore}, i} = N \\cdot R_{\\text{pore}} = Npv$$\n\nThe total expected yield, $Y_{\\text{exp}}$, over a duration $T$ is the total rate multiplied by the time interval:\n$$Y_{\\text{exp}} = R_{\\text{total}} \\cdot T = NpvT$$\n\nThis derivation provides the yield as a function of $N$, $p$, $v$, and $T$. We can further justify this result using the principles of renewal processes as requested, which also clarifies the role of the average read length, $\\bar{L}$.\n\nLet $\\tau_{\\text{read}}$ be the average time required to translocate a single DNA molecule. This is given by the average read length divided by the translocation speed:\n$$\\tau_{\\text{read}} = \\frac{\\bar{L}}{v}$$\nLet $\\tau_{\\text{idle}}$ be the average time a pore is idle between successive reads (i.e., the capture time for the next molecule).\nThe total average time for one complete cycle (read + idle) is $\\tau_{\\text{cycle}} = \\tau_{\\text{read}} + \\tau_{\\text{idle}}$.\nThe occupancy, $p$, is defined as the fraction of time the pore is busy, so:\n$$p = \\frac{\\tau_{\\text{read}}}{\\tau_{\\text{cycle}}}$$\nFrom this, we can express the cycle time as $\\tau_{\\text{cycle}} = \\frac{\\tau_{\\text{read}}}{p} = \\frac{\\bar{L}}{pv}$.\n\nThe number of reads produced by a single pore in time $T$ is $n_{\\text{reads}} = \\frac{T}{\\tau_{\\text{cycle}}}$.\nThe total number of bases produced by a single pore in time $T$ is the number of reads multiplied by the average bases per read:\n$$Y_{\\text{pore}} = n_{\\text{reads}} \\cdot \\bar{L} = \\left(\\frac{T}{\\tau_{\\text{cycle}}}\\right) \\bar{L}$$\nSubstituting our expression for $\\tau_{\\text{cycle}}$:\n$$Y_{\\text{pore}} = \\left(\\frac{T}{\\bar{L}/(pv)}\\right) \\bar{L} = \\frac{Tpv}{\\bar{L}} \\bar{L} = Tpv$$\nThis confirms that the per-pore yield is indeed $Tpv$ and is independent of the average read length $\\bar{L}$ once the occupancy $p$ is known. The total expected yield for $N$ pores is again:\n$$Y_{\\text{exp}} = N \\cdot Y_{\\text{pore}} = NpvT$$\n\n### Numerical Evaluation\nWe now substitute the given values into this expression. First, we must ensure consistent units. The rate $v$ is in bases per second, so the time $T$ must be converted from hours to seconds.\n$$T = 18 \\text{ hours} \\times \\frac{3600 \\text{ seconds}}{1 \\text{ hour}} = 64800 \\text{ s}$$\n\nNow we calculate the expected yield, $Y_{\\text{exp}}$:\n$$Y_{\\text{exp}} = (1450) \\cdot (0.82) \\cdot (450 \\frac{\\text{bases}}{\\text{s}}) \\cdot (64800 \\text{ s})$$\n$$Y_{\\text{exp}} = 34,671,240,000 \\text{ bases}$$\n\nFor clarity, as requested by the problem, we express this in gigabases (Gb), where $1 \\text{ Gb} = 10^9$ bases:\n$$Y_{\\text{exp}} = 34.67124 \\text{ Gb}$$\n\n### Calculation of Fractional Deviation ($\\delta$)\nThe final step is to compute the fractional deviation, $\\delta$, between the observed yield, $Y_{\\text{obs}}$, and the expected yield, $Y_{\\text{exp}}$.\nThe given observed yield is $Y_{\\text{obs}} = 33.90 \\text{ Gb}$.\n$$\\delta = \\frac{Y_{\\text{obs}} - Y_{\\text{exp}}}{Y_{\\text{exp}}} = \\frac{33.90 \\text{ Gb} - 34.67124 \\text{ Gb}}{34.67124 \\text{ Gb}}$$\n$$\\delta = \\frac{33.90 \\times 10^9 - 34.67124 \\times 10^9}{34.67124 \\times 10^9} = \\frac{-0.77124}{34.67124}$$\n$$\\delta \\approx -0.02224534$$\nRounding to four significant figures, we get:\n$$\\delta \\approx -0.02225$$\nThis value indicates that the observed yield was approximately $2.225\\%$ lower than the yield predicted by the idealized steady-state model.", "answer": "$$\n\\boxed{-0.02225}\n$$", "id": "5138882"}, {"introduction": "At the heart of nanopore sequencing lies a sophisticated signal processing challenge: converting a noisy, continuous stream of ionic current measurements into a discrete sequence of nucleotides. This exercise [@problem_id:5138906] invites you to model this process using a Hidden Markov Model (HMM), where distinct current levels correspond to different nucleotide contexts. By implementing the Viterbi algorithm, you will perform the essential task of 'basecalling' by decoding the most probable sequence of hidden states, gaining first-hand experience with the core computational engine of nanopore technology.", "problem": "You are given a simplified model of a nanopore strand sequencing readout in which the ionic current is modeled as a Hidden Markov Model (HMM) where hidden states represent discrete step states of the strand (for example, short nucleotide contexts) and emissions are noisy averaged ionic current measurements per step. The physical context is a nanopore system in molecular and immunodiagnostics, where ionic current levels, measured in picoamperes (pA), are characteristic of local strand configurations, and the strand advances in discrete steps controlled by a motor protein. You must construct likelihoods for step states based on a Gaussian emission model and implement a Viterbi decoder to infer the most probable sequence of step states from the noisy averaged current traces.\n\nFundamental base and definitions to use:\n- Hidden Markov Model (HMM): a stochastic model with hidden states and observed emissions. Let the hidden state at time index $t$ be $s_t \\in \\{0,1,\\dots,M-1\\}$ with state transition probabilities $A_{ij} = \\mathbb{P}(s_t = j \\mid s_{t-1} = i)$ and an initial distribution $\\pi_j = \\mathbb{P}(s_0 = j)$.\n- Emission model: for each state $j$, the averaged ionic current per step $\\bar{I}_t$ is modeled as a Gaussian (Normal) random variable with mean $\\mu_j$ and variance $\\sigma^2/K$, i.e., $\\bar{I}_t \\sim \\mathcal{N}(\\mu_j, \\sigma^2/K)$, where $\\sigma$ is the per-sample standard deviation and $K$ is the number of samples averaged per step. The likelihood is \n$$\np(\\bar{I}_t \\mid s_t=j) = \\frac{1}{\\sqrt{2\\pi \\sigma^2/K}}\\exp\\left(-\\frac{(\\bar{I}_t - \\mu_j)^2}{2\\sigma^2/K}\\right).\n$$\n- Maximum a posteriori decoding via the Viterbi algorithm: compute the most probable state path $s_0,s_1,\\dots,s_{T-1}$ given observations $\\bar{I}_0,\\bar{I}_1,\\dots,\\bar{I}_{T-1}$ by dynamic programming in the log domain using natural logarithms.\n\nYour task:\n1. For each test case, construct emission log-likelihoods $\\log p(\\bar{I}_t \\mid s_t=j)$ using the Gaussian model above, with variance $\\sigma^2/K$. Then implement the Viterbi dynamic programming recurrences:\n$$\n\\delta_t(j) = \\max_i \\left[\\delta_{t-1}(i) + \\log A_{ij}\\right] + \\log p(\\bar{I}_t \\mid s_t=j),\n$$\nwith initialization\n$$\n\\delta_0(j) = \\log \\pi_j + \\log p(\\bar{I}_0 \\mid s_0=j),\n$$\nand maintain backpointers to reconstruct the maximizing path. Use natural logarithms for all log operations.\n2. Decode the most probable state sequence for each test case independently.\n3. Express the final decoded sequences as lists of integers (state indices), with no physical units in the output. All physical units mentioned below are for the model specification only; the output is unitless.\n4. Your program should produce a single line of output containing the decoded sequences for all test cases as a comma-separated list enclosed in square brackets, where each decoded sequence is represented as a list of integers, e.g., $[[0,1,2],[1,1,0]]$.\n\nTest suite:\n- Test Case 1 (general \"happy path\"):\n  - Number of states: $M = 4$.\n  - State means (picoamperes): $\\mu = [64.8, 67.6, 62.9, 70.5]$.\n  - Per-sample standard deviation (picoamperes): $\\sigma = 2.0$.\n  - Samples per step: $K = 5$.\n  - Transition matrix:\n    $$\n    A = \\begin{bmatrix}\n    0.70 & 0.25 & 0.03 & 0.02 \\\\\n    0.15 & 0.70 & 0.13 & 0.02 \\\\\n    0.02 & 0.15 & 0.70 & 0.13 \\\\\n    0.02 & 0.03 & 0.25 & 0.70\n    \\end{bmatrix}\n    $$\n  - Initial distribution: $\\pi = [0.25, 0.25, 0.25, 0.25]$.\n  - Number of steps: $T = 8$.\n  - Averaged observations (picoamperes): $\\bar{I} = [65.1, 67.3, 67.8, 62.2, 70.3, 69.8, 63.1, 66.9]$.\n\n- Test Case 2 (overlapping state means, challenging emissions):\n  - Number of states: $M = 3$.\n  - State means (picoamperes): $\\mu = [66.0, 66.6, 66.9]$.\n  - Per-sample standard deviation (picoamperes): $\\sigma = 1.2$.\n  - Samples per step: $K = 10$.\n  - Transition matrix:\n    $$\n    A = \\begin{bmatrix}\n    0.60 & 0.35 & 0.05 \\\\\n    0.20 & 0.60 & 0.20 \\\\\n    0.05 & 0.35 & 0.60\n    \\end{bmatrix}\n    $$\n  - Initial distribution: $\\pi = [\\tfrac{1}{3}, \\tfrac{1}{3}, \\tfrac{1}{3}]$.\n  - Number of steps: $T = 6$.\n  - Averaged observations (picoamperes): $\\bar{I} = [65.8, 66.9, 66.6, 66.5, 66.7, 66.1]$.\n\n- Test Case 3 (boundary and short sequence):\n  - Number of states: $M = 2$.\n  - State means (picoamperes): $\\mu = [63.0, 69.0]$.\n  - Per-sample standard deviation (picoamperes): $\\sigma = 3.0$.\n  - Samples per step: $K = 2$.\n  - Transition matrix:\n    $$\n    A = \\begin{bmatrix}\n    0.80 & 0.20 \\\\\n    0.20 & 0.80\n    \\end{bmatrix}\n    $$\n  - Initial distribution: $\\pi = [0.5, 0.5]$.\n  - Number of steps: $T = 1$.\n  - Averaged observations (picoamperes): $\\bar{I} = [68.2]$.\n\nAngle units are not applicable. Percentages do not appear in the output. The ionic current values used in the model are given in picoamperes (pA), but your program’s output must be the decoded state index sequences without units. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[[0,1,2],[2,1,0],[1]]$.", "solution": "The posed problem requires the decoding of the most probable sequence of hidden states from a series of noisy observations, a canonical task in the analysis of sequential data. The system is modeled as a Hidden Markov Model (HMM), a framework well-suited for describing the stochastic process underlying nanopore sequencing where a biopolymer, such as DNA, translocates through a nanopore, giving rise to a sequence of characteristic ionic current levels. The Viterbi algorithm provides an exact and computationally efficient solution to this decoding problem via dynamic programming.\n\nThe solution proceeds by first formalizing the HMM components and then implementing the Viterbi algorithm in the numerically stable logarithmic domain.\n\nA Hidden Markov Model is defined by a set of parameters $(\\mathcal{S}, \\mathcal{V}, A, B, \\pi)$, where:\n- $\\mathcal{S} = \\{0, 1, \\dots, M-1\\}$ is the finite set of $M$ hidden states, representing local strand configurations.\n- $\\mathcal{V}$ is the set of possible observations. In this problem, observations are continuous, representing the averaged ionic current $\\bar{I}_t \\in \\mathbb{R}$.\n- $A$ is the state transition probability matrix, where $A_{ij} = \\mathbb{P}(s_t = j \\mid s_{t-1} = i)$ is the probability of transitioning from state $i$ to state $j$.\n- $B$ represents the emission probabilities, $p(\\bar{I}_t \\mid s_t=j)$, which is the probability of observing current $\\bar{I}_t$ given the system is in state $j$.\n- $\\pi$ is the initial state distribution, where $\\pi_j = \\mathbb{P}(s_0 = j)$.\n\nThe problem specifies a Gaussian emission model for the averaged ionic current $\\bar{I}_t$ at time step $t$. Given the hidden state is $s_t=j$, the observation $\\bar{I}_t$ is drawn from a Normal distribution $\\mathcal{N}(\\mu_j, \\sigma_{avg}^2)$, where $\\mu_j$ is the mean current for state $j$ and $\\sigma_{avg}^2 = \\sigma^2/K$ is the variance of the averaged measurement. Here, $\\sigma$ is the per-sample standard deviation and $K$ is the number of samples averaged per step.\n\nThe probability density function for an observation $\\bar{I}_t$ given state $j$ is:\n$$\np(\\bar{I}_t \\mid s_t=j) = \\frac{1}{\\sqrt{2\\pi \\sigma^2/K}}\\exp\\left(-\\frac{(\\bar{I}_t - \\mu_j)^2}{2\\sigma^2/K}\\right)\n$$\nDirectly multiplying these probabilities for a long sequence can lead to numerical underflow. Therefore, all computations are performed using natural logarithms. The log-likelihood of an emission is:\n$$\n\\log p(\\bar{I}_t \\mid s_t=j) = -\\frac{1}{2}\\log(2\\pi \\sigma^2/K) - \\frac{(\\bar{I}_t - \\mu_j)^2}{2\\sigma^2/K}\n$$\nThese log-likelihoods are computed for each time step $t \\in \\{0, \\dots, T-1\\}$ and each state $j \\in \\{0, \\dots, M-1\\}$.\n\nThe Viterbi algorithm finds the optimal state sequence $S^* = (s_0^*, s_1^*, \\dots, s_{T-1}^*)$ by maximizing the joint log-probability of the state sequence and the observations. This is achieved through dynamic programming. We define two tables:\n$1$. $\\delta_t(j)$: The maximum log-probability of any path of length $t+1$ that ends in state $j$ and generates observations $\\bar{I}_0, \\dots, \\bar{I}_t$.\n$2$. $\\psi_t(j)$: A backpointer table to store the state at time $t-1$ that maximizes the probability of reaching state $j$ at time $t$.\n\nThe algorithm proceeds in three stages:\n\n**$1$. Initialization ($t=0$):**\nFor each state $j \\in \\{0, \\dots, M-1\\}$, the initial log-probability is the sum of the log initial probability and the log-emission probability for the first observation $\\bar{I}_0$.\n$$\n\\delta_0(j) = \\log \\pi_j + \\log p(\\bar{I}_0 \\mid s_0=j)\n$$\n\n**$2$. Recursion ($t=1, \\dots, T-1$):**\nFor each subsequent time step $t$, we extend the optimal paths from time $t-1$. For each state $j$, we find the previous state $i$ that maximizes the probability of transitioning to $j$ and generating observation $\\bar{I}_t$.\n$$\n\\delta_t(j) = \\max_{i \\in \\{0, \\dots, M-1\\}} \\left[ \\delta_{t-1}(i) + \\log A_{ij} \\right] + \\log p(\\bar{I}_t \\mid s_t=j)\n$$\nThe backpointer for state $j$ at time $t$ stores the index of this maximizing previous state $i$:\n$$\n\\psi_t(j) = \\arg\\max_{i \\in \\{0, \\dots, M-1\\}} \\left[ \\delta_{t-1}(i) + \\log A_{ij} \\right]\n$$\n\n**$3$. Termination and Path Reconstruction:**\nAfter computing $\\delta_{T-1}(j)$ for all states $j$, the most probable final state is the one with the highest log-probability:\n$$\ns^*_{T-1} = \\arg\\max_{j \\in \\{0, \\dots, M-1\\}} \\delta_{T-1}(j)\n$$\nThe remainder of the most probable path is found by backtracking from this final state using the stored backpointers:\n$$\ns^*_{t-1} = \\psi_t(s^*_t) \\quad \\text{for } t = T-1, \\dots, 1\n$$\nThis procedure yields the complete optimal state sequence $S^*=(s_0^*, s_1^*, \\dots, s_{T-1}^*)$, which is the solution for a given test case. The implementation will process each test case provided in the problem statement independently using this algorithm.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef viterbi_decode(M, mu, sigma, K, A, pi, T, I_bar):\n    \"\"\"\n    Decodes the most probable sequence of hidden states in an HMM using the Viterbi algorithm.\n    All calculations are performed in the log domain for numerical stability.\n\n    Args:\n        M (int): Number of hidden states.\n        mu (list or np.ndarray): Mean ionic current for each state.\n        sigma (float): Per-sample standard deviation of the ionic current.\n        K (int): Number of samples averaged per step.\n        A (list of lists or np.ndarray): State transition probability matrix.\n        pi (list or np.ndarray): Initial state probability distribution.\n        T (int): Number of observations (time steps).\n        I_bar (list or np.ndarray): Sequence of averaged ionic current observations.\n\n    Returns:\n        list: The most probable sequence of state indices.\n    \"\"\"\n    num_states = M\n    num_observations = T\n\n    # Convert inputs to numpy arrays for vectorized operations\n    mu = np.array(mu)\n    # Ensure A and pi are numpy arrays for log operations\n    A = np.array(A)\n    pi = np.array(pi)\n    I_bar = np.array(I_bar)\n\n    # 1. Preparation: Compute log probabilities\n    # Use np.errstate to suppress warnings for log(0), which is correctly handled as -np.inf\n    with np.errstate(divide='ignore'):\n        log_A = np.log(A)\n        log_pi = np.log(pi)\n\n    # Compute emission log-likelihoods for all observations and states.\n    # The matrix emission_log_lik will have shape (T, M), where B[t, j] = log p(I_bar[t] | s_t = j).\n    var_avg = (sigma**2) / K\n    std_avg = np.sqrt(var_avg)\n    \n    emission_log_lik = np.zeros((num_observations, num_states))\n    for t in range(num_observations):\n        # norm.logpdf calculates the log probability density for I_bar[t] under\n        # a normal distribution for each state's mean mu[j] and the common scale std_avg.\n        emission_log_lik[t, :] = norm.logpdf(I_bar[t], loc=mu, scale=std_avg)\n\n    # 2. Dynamic Programming tables\n    # delta[t, j]: max log-prob of a path ending in state j at time t\n    delta = np.zeros((num_observations, num_states))\n    # psi[t, j]: backpointer to the previous state on the optimal path to j at t\n    psi = np.zeros((num_observations, num_states), dtype=int)\n\n    # 3. Initialization step (t=0)\n    delta[0, :] = log_pi + emission_log_lik[0, :]\n\n    # 4. Recursion step (t=1 to T-1)\n    if num_observations > 1:\n        for t in range(1, num_observations):\n            for j in range(num_states):\n                # For each current state j, find the best previous state i.\n                # The term inside the max is delta[t-1, i] + log_A[i, j].\n                temp_log_prob = delta[t-1, :] + log_A[:, j]\n                \n                # Find the maximum log probability and the corresponding state index\n                max_log_prob = np.max(temp_log_prob)\n                argmax_index = np.argmax(temp_log_prob)\n                \n                # Update the DP tables\n                delta[t, j] = max_log_prob + emission_log_lik[t, j]\n                psi[t, j] = argmax_index\n\n    # 5. Termination and Path Reconstruction (Backtracking)\n    path = np.zeros(num_observations, dtype=int)\n    \n    # Find the most probable final state\n    path[num_observations - 1] = np.argmax(delta[num_observations - 1, :])\n    \n    # Backtrack to find the rest of the optimal path\n    for t in range(num_observations - 2, -1, -1):\n        path[t] = psi[t + 1, path[t + 1]]\n\n    return path.tolist()\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        (\n            4, # M\n            [64.8, 67.6, 62.9, 70.5], # mu\n            2.0, # sigma\n            5, # K\n            [[0.70, 0.25, 0.03, 0.02],\n             [0.15, 0.70, 0.13, 0.02],\n             [0.02, 0.15, 0.70, 0.13],\n             [0.02, 0.03, 0.25, 0.70]], # A\n            [0.25, 0.25, 0.25, 0.25], # pi\n            8, # T\n            [65.1, 67.3, 67.8, 62.2, 70.3, 69.8, 63.1, 66.9] # I_bar\n        ),\n        # Test Case 2\n        (\n            3, # M\n            [66.0, 66.6, 66.9], # mu\n            1.2, # sigma\n            10, # K\n            [[0.60, 0.35, 0.05],\n             [0.20, 0.60, 0.20],\n             [0.05, 0.35, 0.60]], # A\n            [1/3, 1/3, 1/3], # pi\n            6, # T\n            [65.8, 66.9, 66.6, 66.5, 66.7, 66.1] # I_bar\n        ),\n        # Test Case 3\n        (\n            2, # M\n            [63.0, 69.0], # mu\n            3.0, # sigma\n            2, # K\n            [[0.80, 0.20],\n             [0.20, 0.80]], # A\n            [0.5, 0.5], # pi\n            1, # T\n            [68.2] # I_bar\n        )\n    ]\n\n    results = []\n    for case in test_cases:\n        M, mu, sigma, K, A, pi, T, I_bar = case\n        decoded_path = viterbi_decode(M, mu, sigma, K, A, pi, T, I_bar)\n        results.append(decoded_path)\n\n    # Final print statement in the exact required format.\n    # The str() representation of a list of lists contains spaces.\n    # The required format is compact, without spaces.\n    print(str(results).replace(' ', ''))\n\nsolve()\n\n```", "id": "5138906"}, {"introduction": "While individual nanopore reads provide valuable long-range information, their inherent error rates necessitate a strategy for achieving high-fidelity results. This practice focuses on the crucial downstream step of generating a reliable consensus sequence by combining information from multiple independent reads covering the same genomic locus [@problem_id:5138841]. You will apply principles of binomial probability to model how consensus accuracy improves with increasing coverage, and determine the depth required to meet a specific quality threshold, such as a Phred score of $Q=30$.", "problem": "A molecular and immunodiagnostics laboratory uses nanopore strand sequencing to assemble a per-base consensus across independent single-strand reads to detect single-nucleotide variants in a clinically relevant locus. Assume that each independent read covering a given base has identical and independent base-call performance: with probability $a$ it reports the true base, and with probability $1-a$ it reports some incorrect base. To suppress bias from error mode heterogeneity, assume errors are symmetric among the three incorrect bases. The laboratory constructs a consensus base at coverage depth $N$ (an odd integer to avoid ties) by majority vote over the $N$ base calls. The Phred quality score (PQS) for a consensus call is defined such that if the probability of a consensus error is $e$, then the consensus quality is $Q=-10\\log_{10}(e)$.\n\nStarting from the definitions of independence, the binomial distribution, and the Phred quality score, derive an analytic expression for the consensus accuracy $A(N)$ as a function of coverage depth $N$ and per-read correctness $a$. Then, specializing to $a=0.95$, determine the minimal odd coverage depth $N$ required so that the consensus Phred quality is at least $Q=30$ (that is, the consensus error probability $e$ is no greater than $10^{-3}$). Report the minimal odd $N$ as your final answer. No rounding is required.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard application of binomial probability to a simplified model of genetic sequencing consensus, a core concept in bioinformatics and diagnostics. All provided information is self-contained and sufficient for a unique solution.\n\nLet $a$ be the probability that a single, independent read correctly identifies a base. The probability of an incorrect base call is then $1-a$. The coverage depth, $N$, is the number of independent reads covering the base, and it is given to be an odd integer.\n\nA consensus call is formed by a majority vote. Let $k$ be the number of reads that correctly identify the true base out of $N$ total reads. These $N$ reads are independent Bernoulli trials, so the number of correct reads $k$ follows a binomial distribution:\n$$P(k; N, a) = \\binom{N}{k} a^k (1-a)^{N-k}$$\nFor the consensus call to be correct, the true base must be called more frequently than any other base. The problem states that errors are symmetric, meaning the $1-a$ probability of an error is distributed equally among the three other possible bases. If the number of correct reads $k$ is greater than half the total reads, $N/2$, then the number of incorrect reads, $N-k$, must be less than $N/2$. Since these $N-k$ reads are distributed among three incorrect bases, no single incorrect base can possibly receive more votes than $k$. Therefore, the condition for a correct consensus call is that the number of correct reads, $k$, constitutes a majority.\n\nSince $N$ is an odd integer, a majority is achieved if $k > N/2$. The smallest integer $k$ satisfying this is $k = (N+1)/2$. The consensus is correct if $k$ is any integer from $(N+1)/2$ to $N$.\n\nThe consensus accuracy, $A(N)$, is the probability that the consensus call is correct. This is the sum of probabilities for all values of $k$ that result in a correct consensus:\n$$A(N) = P\\left(k \\ge \\frac{N+1}{2}\\right) = \\sum_{k=(N+1)/2}^{N} P(k; N, a)$$\nSubstituting the binomial probability mass function, we arrive at the analytic expression for the consensus accuracy as a function of $N$ and $a$:\n$$A(N) = \\sum_{k=(N+1)/2}^{N} \\binom{N}{k} a^k (1-a)^{N-k}$$\nThis is the first part of the required derivation.\n\nThe probability of a consensus error, $e$, is the complement of the accuracy: $e(N) = 1 - A(N)$. This corresponds to the case where the number of correct reads is in the minority, i.e., $k < (N+1)/2$. Since $k$ is an integer, this is equivalent to $k \\le (N-1)/2$.\n$$e(N) = P\\left(k \\le \\frac{N-1}{2}\\right) = \\sum_{k=0}^{(N-1)/2} \\binom{N}{k} a^k (1-a)^{N-k}$$\nThe Phred quality score, $Q$, is defined as $Q = -10\\log_{10}(e)$. The problem requires finding the minimal odd $N$ such that $Q \\ge 30$ for a per-read accuracy of $a=0.95$.\nThe condition $Q \\ge 30$ translates to:\n$$-10\\log_{10}(e) \\ge 30$$\n$$\\log_{10}(e) \\le -3$$\n$$e \\le 10^{-3}$$\nWe need to find the smallest odd integer $N$ for which $e(N) \\le 0.001$, given $a=0.95$ and $1-a=0.05$. We will test successive odd values of $N$.\n\nFor $N=1$:\nThe error condition is $k \\le (1-1)/2 = 0$, so $k=0$.\n$e(1) = \\binom{1}{0} a^0 (1-a)^1 = 1-a = 0.05$.\n$0.05 > 0.001$, so $N=1$ is insufficient.\n\nFor $N=3$:\nThe error condition is $k \\le (3-1)/2 = 1$, so $k=0$ or $k=1$.\n$e(3) = \\sum_{k=0}^{1} \\binom{3}{k} a^k (1-a)^{3-k} = \\binom{3}{0}a^0(1-a)^3 + \\binom{3}{1}a^1(1-a)^2$\n$e(3) = (1-a)^3 + 3a(1-a)^2 = (0.05)^3 + 3(0.95)(0.05)^2$\n$e(3) = 0.000125 + 3(0.95)(0.0025) = 0.000125 + 0.007125 = 0.00725$.\n$0.00725 > 0.001$, so $N=3$ is insufficient.\n\nFor $N=5$:\nThe error condition is $k \\le (5-1)/2 = 2$, so $k=0, 1, 2$.\n$e(5) = \\sum_{k=0}^{2} \\binom{5}{k} a^k (1-a)^{5-k} = \\binom{5}{0}(1-a)^5 + \\binom{5}{1}a(1-a)^4 + \\binom{5}{2}a^2(1-a)^3$\n$e(5) = (0.05)^5 + 5(0.95)(0.05)^4 + 10(0.95)^2(0.05)^3$\n$e(5) = 3.125 \\times 10^{-7} + 5(0.95)(6.25 \\times 10^{-6}) + 10(0.9025)(1.25 \\times 10^{-4})$\n$e(5) = 0.0000003125 + 0.0000296875 + 0.001128125 = 0.001158125$.\n$0.001158125 > 0.001$, so $N=5$ is insufficient.\n\nFor $N=7$:\nThe error condition is $k \\le (7-1)/2 = 3$, so $k=0, 1, 2, 3$.\n$e(7) = \\sum_{k=0}^{3} \\binom{7}{k} a^k (1-a)^{7-k}$\n$e(7) = \\binom{7}{0}(1-a)^7 + \\binom{7}{1}a(1-a)^6 + \\binom{7}{2}a^2(1-a)^5 + \\binom{7}{3}a^3(1-a)^4$\n$e(7) = (0.05)^7 + 7(0.95)(0.05)^6 + 21(0.95)^2(0.05)^5 + 35(0.95)^3(0.05)^4$\n$e(7) = (7.8125 \\times 10^{-10}) + 7(0.95)(1.5625 \\times 10^{-8}) + 21(0.9025)(3.125 \\times 10^{-7}) + 35(0.857375)(6.25 \\times 10^{-6})$\n$e(7) = 7.8125 \\times 10^{-10} + 1.0390625 \\times 10^{-7} + 5.9228515625 \\times 10^{-6} + 1.8754296875 \\times 10^{-4}$\n$e(7) = 0.00000000078125 + 0.00000010390625 + 0.0000059228515625 + 0.00018754296875$\n$e(7) \\approx 1.9357 \\times 10^{-4}$.\n$1.9357 \\times 10^{-4} = 0.00019357$, which is less than $0.001$.\nThus, $N=7$ is sufficient to achieve the desired quality score.\n\nSince coverage depth $N=5$ is insufficient and $N=7$ is sufficient, the minimal odd coverage depth required is $N=7$.", "answer": "$$\\boxed{7}$$", "id": "5138841"}]}