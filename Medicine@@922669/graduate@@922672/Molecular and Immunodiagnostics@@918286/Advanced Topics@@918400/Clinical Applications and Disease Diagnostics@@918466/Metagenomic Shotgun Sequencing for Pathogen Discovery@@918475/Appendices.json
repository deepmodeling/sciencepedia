{"hands_on_practices": [{"introduction": "Metagenomic sequencing is fundamentally a sampling process. The presence of a pathogen's nucleic acid in a specimen does not guarantee its detection, as a finite number of sequencing reads might fail to capture it by chance. This exercise [@problem_id:5131994] delves into this core challenge by asking you to derive the probability of such a detection failure from first principles. Understanding the relationship between pathogen abundance ($f$), sequencing depth ($D$), and sampling variance is critical for interpreting negative results and appreciating the inherent statistical limits of detection.", "problem": "In metagenomic shotgun sequencing for pathogen discovery, assume that sequencing reads are independent and uniformly sampled from the pool of sequencing-accessible nucleic acid molecules. Let the true relative abundance of a target pathogen in the specimen be $f$, defined as the probability that any one read derives from the pathogen, and let the sequencing depth be $D$, defined as the total number of reads produced. Under these conditions, define the random variable $X$ to be the number of pathogen-derived reads observed.\n\nStarting from first principles of Bernoulli sampling and independence, derive the probability of observing zero pathogen-derived reads. Then, using the given values $f = 10^{-6}$ and $D = 10^{8}$, compute this probability. You may use an appropriate asymptotic approximation if justified, but you must clearly articulate the reasoning. Round your final numerical probability to $3$ significant figures and express it as a decimal.\n\nFinally, briefly discuss the implications of your result for clinical reporting thresholds in metagenomic next-generation sequencing (NGS), for example when a laboratory requires at least $k$ reads for a positive report. Your discussion should be framed in terms of sampling variance and its contribution to false negatives under the stated assumptions, without invoking any unprovided shortcut formulas or empirical rules.", "solution": "The problem statement has been validated and is determined to be sound, well-posed, and scientifically grounded.\n\nThe problem asks for the derivation and calculation of the probability of observing zero pathogen-derived reads in a metagenomic shotgun sequencing experiment, and a discussion of the result's implications.\n\nThe core assumptions are that the sequencing reads are independent and uniformly sampled from the pool of nucleic acid molecules. This process can be modeled as a series of Bernoulli trials.\n\nLet $D$ be the total number of sequencing reads (the sequencing depth), which corresponds to the number of trials. Let $f$ be the true relative abundance of the pathogen, which is the probability that any single read originates from the pathogen. This corresponds to the probability of \"success\" in a single Bernoulli trial.\n\nThe random variable $X$ represents the total number of pathogen-derived reads observed in $D$ trials. Since the trials are independent and the probability of success $f$ is constant for each trial, $X$ follows a Binomial distribution, denoted as $X \\sim B(D, f)$.\n\nThe probability mass function (PMF) for a Binomial distribution gives the probability of observing exactly $k$ successes in $n$ trials:\n$$P(X=k) = \\binom{n}{k} p^k (1-p)^{n-k}$$\nIn our context, $n=D$, $p=f$, and we are interested in the case where $k=0$. Substituting these values into the PMF, we derive the probability of observing zero pathogen-derived reads:\n$$P(X=0) = \\binom{D}{0} f^0 (1-f)^{D-0}$$\nBy definition, $\\binom{D}{0} = 1$ and $f^0 = 1$. Therefore, the exact probability is:\n$$P(X=0) = (1-f)^D$$\n\nNow, we are asked to compute this probability for the given values $f = 10^{-6}$ and $D = 10^{8}$.\nThe direct calculation of $(1 - 10^{-6})^{10^{8}}$ is computationally cumbersome. The problem allows for an asymptotic approximation if justified. The conditions for the Poisson approximation to the Binomial distribution are that the number of trials $D$ is very large and the probability of success $f$ is very small. In our case, $D = 10^8$ is indeed very large, and $f = 10^{-6}$ is very small. Thus, the use of a Poisson approximation is well-justified.\n\nThe Binomial distribution $B(D, f)$ can be approximated by a Poisson distribution with parameter $\\lambda$, where $\\lambda$ is the expected number of successes.\n$$\\lambda = E[X] = Df$$\nLet's calculate $\\lambda$ for the given values:\n$$\\lambda = (10^8) \\times (10^{-6}) = 10^{2} = 100$$\nThe PMF of the Poisson distribution is:\n$$P(X=k) \\approx \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$$\nWe want to find the probability of observing zero reads, i.e., $k=0$.\n$$P(X=0) \\approx \\frac{\\lambda^0 \\exp(-\\lambda)}{0!}$$\nSince $\\lambda^0 = 1$ and $0! = 1$, this simplifies to:\n$$P(X=0) \\approx \\exp(-\\lambda) = \\exp(-Df)$$\nThis approximation arises from the well-known limit definition of the exponential function:\n$$P(X=0) = (1-f)^D = \\left(1 - \\frac{Df}{D}\\right)^D = \\left(1 - \\frac{\\lambda}{D}\\right)^D$$\nFor large $D$, this expression converges to $\\exp(-\\lambda)$.\n\nNow, we compute the numerical value:\n$$P(X=0) \\approx \\exp(-100)$$\nCalculating this value and rounding to $3$ significant figures:\n$$\\exp(-100) \\approx 3.7200759... \\times 10^{-44}$$\nRounded to $3$ significant figures, the probability is $3.72 \\times 10^{-44}$.\n\nFinally, for the discussion on implications, the result $P(X=0) \\approx 3.72 \\times 10^{-44}$ is the probability of a false negative (failing to detect the pathogen at all) when the pathogen is present at a relative abundance of $f = 10^{-6}$ and the sequencing depth is $D = 10^8$. The expected number of pathogen reads is $\\lambda = Df = 100$.\n\nThe fact that $P(X=0)$ is non-zero, even if infinitesimally small in this case, illustrates a fundamental principle: the stochastic nature of sequencing introduces sampling variance. Even when a pathogen is present and the expected number of reads is high ($100$), there is a finite probability of observing zero reads by chance.\n\nIf a clinical laboratory sets a reporting threshold of requiring at least $k$ reads for a positive report (e.g., $k=3$), a false negative occurs if the observed number of reads $X$ is less than $k$. The probability of this event, $P(X < k)$, is the sum of probabilities $P(X=0), P(X=1), \\dots, P(X=k-1)$. The value $P(X=0)$ we calculated represents the absolute minimum false-negative rate for any threshold $k \\ge 1$.\n\nWhile the false-negative rate is exceedingly low for the given parameters, this scenario changes dramatically if the product $\\lambda=Df$ is small. For example, if a lower sequencing depth were used (e.g., $D=10^6$) for the same pathogen abundance ($f=10^{-6}$), the expected number of reads would be $\\lambda = 1$. The probability of observing zero reads would then be $P(X=0) \\approx \\exp(-1) \\approx 0.368$. In this situation, there would be a $36.8\\%$ chance of missing the pathogen entirely, a clinically unacceptable false-negative rate.\n\nThis demonstrates that sampling variance is a critical contributor to false negatives in metagenomic diagnostics. The ability to reliably detect a pathogen is not guaranteed simply by its presence; it is governed by the probability distribution of observed reads, which in turn depends fundamentally on the interplay between pathogen abundance ($f$) and sequencing depth ($D$). Setting a reporting threshold $k$ must be balanced against the risk of false negatives, a risk that is mathematically determined by the parameter $\\lambda=Df$.", "answer": "$$\\boxed{3.72 \\times 10^{-44}}$$", "id": "5131994"}, {"introduction": "While detecting a pathogen is the first step, clinical management often requires knowing *how much* of it is present. Metagenomic data primarily provides relative abundances, but absolute quantification (e.g., genome copies per milliliter) is far more actionable. This practice [@problem_id:5132005] guides you through the logic of internal standard calibration, a powerful technique that uses a known quantity of a synthetic 'spike-in' control to convert relative read counts into an absolute measure of pathogen load. Deriving the relationship from scratch reveals the critical assumptions that underpin this essential quantitative method.", "problem": "A cerebrospinal fluid specimen is analyzed by metagenomic shotgun sequencing for pathogen discovery. A synthetic double-stranded DNA spike-in control is added immediately prior to lysis to enable absolute quantification. You may assume the following foundations: during shotgun library preparation and sequencing, fragments are sampled without replacement from the pool of input nucleic acid molecules; under uniform and unbiased sampling, the expected number of sequencing reads assigned to any source is proportional to the total number of input nucleotides contributed by that source; and, for a haploid organism, the total nucleotides contributed by that source equal the number of genome copies times the haploid genome length. Internally controlled absolute quantification uses the spike-in to calibrate unknowns.\n\nThe experiment yields the following measured and known quantities:\n- Input sample volume processed: $V_{\\text{in}} = 1.00 \\ \\mathrm{mL}$.\n- Spike-in molecules added at lysis: $N_{\\text{spike}} = 5.00 \\times 10^{7}$ genome copies of a linearized plasmid of length $L_{\\text{spike}} = 3.000 \\times 10^{3} \\ \\mathrm{bp}$.\n- Sequencing configuration: paired-end reads of equal length across the run; duplicate and low-quality reads are removed prior to taxonomic assignment.\n- Post-processing read counts assigned by competitive mapping:\n  - Human: $2.70 \\times 10^{7}$ read pairs.\n  - Spike-in: $6.00 \\times 10^{4}$ read pairs.\n  - A single bacterial pathogen of interest (haploid): $4.00 \\times 10^{2}$ read pairs.\n  - All other taxa combined: negligible for this calculation.\n- The haploid genome length of the detected bacterial pathogen is $L_{\\text{path}} = 2.000 \\times 10^{6} \\ \\mathrm{bp}$.\n\nUsing first principles and only the foundations stated above, derive from scratch an expression to estimate the bacterial pathogen genome copies per milliliter in the original sample and compute its value. You must explicitly justify each modeling step you introduce in the derivation. Round your final numerical answer to three significant figures. Express the final concentration in copies $\\mathrm{mL}^{-1}$.\n\nIn addition to the computation, briefly identify the core assumptions required for the internal standard calibration to be valid in this context and explain, at a conceptual level, why they are necessary. Do not use any pre-memorized shortcut formulas; instead, build your reasoning from the stated foundations and definitions only. Your final reported answer must be a single real number.", "solution": "The problem statement has been critically validated and is deemed to be self-contained, scientifically grounded, and well-posed. All necessary data and foundational principles for a unique and meaningful solution are provided. We may therefore proceed with the derivation and computation.\n\nThe central foundation provided for this analysis is that the expected number of sequencing reads assigned to any source is proportional to the total number of input nucleotides from that source. Let $C_i$ represent the number of sequencing read pairs assigned to source $i$, and let $T_i$ be the total number of nucleotides contributed by source $i$ to the initial nucleic acid pool prior to sequencing. The proportionality can be expressed as:\n$$E[C_i] = k \\cdot T_i$$\nwhere $E[C_i]$ is the expected value of the read count for source $i$, and $k$ is a constant of proportionality that depends on the total sequencing depth and other systemic factors, but is assumed to be identical for all sources of DNA in the sample.\n\nThis principle is applied to the two non-host sources of interest: the bacterial pathogen (denoted 'path') and the internal spike-in control (denoted 'spike').\nFor the pathogen:\n$$E[C_{\\text{path}}] = k \\cdot T_{\\text{path}}$$\nFor the spike-in:\n$$E[C_{\\text{spike}}] = k \\cdot T_{\\text{spike}}$$\nBy taking the ratio of these two equations, the unknown constant of proportionality $k$ is eliminated. This is the fundamental basis of internal calibration, as it normalizes the measurement of the unknown analyte (pathogen) against a known internal reference (spike-in).\n$$\\frac{E[C_{\\text{path}}]}{E[C_{\\text{spike}}]} = \\frac{k \\cdot T_{\\text{path}}}{k \\cdot T_{\\text{spike}}} = \\frac{T_{\\text{path}}}{T_{\\text{spike}}}$$\nIn a real experiment, we use the observed read counts as estimates for their expected values, $C_i \\approx E[C_i]$. This approximation is reasonable for sufficiently large read counts.\n$$\\frac{C_{\\text{path}}}{C_{\\text{spike}}} = \\frac{T_{\\text{path}}}{T_{\\text{spike}}}$$\nThe second foundational principle states that for a haploid organism, the total number of nucleotides is the product of the number of genome copies and the haploid genome length. Let $N_i$ be the number of genome copies and $L_i$ be the genome length in base pairs (bp) for source $i$.\nThe total nucleotides for the pathogen are:\n$$T_{\\text{path}} = N_{\\text{path}} \\cdot L_{\\text{path}}$$\nThe total nucleotides for the spike-in are:\n$$T_{\\text{spike}} = N_{\\text{spike}} \\cdot L_{\\text{spike}}$$\nHere, $N_{\\text{path}}$ represents the total number of pathogen genome copies present in the initial sample volume, $V_{\\text{in}}$.\n\nSubstituting these expressions back into the ratio equation yields:\n$$\\frac{C_{\\text{path}}}{C_{\\text{spike}}} = \\frac{N_{\\text{path}} \\cdot L_{\\text{path}}}{N_{\\text{spike}} \\cdot L_{\\text{spike}}}$$\nOur objective is to determine the concentration of the pathogen, which first requires solving for the absolute number of pathogen genome copies, $N_{\\text{path}}$. Rearranging the equation:\n$$N_{\\text{path}} = N_{\\text{spike}} \\cdot \\frac{C_{\\text{path}}}{C_{\\text{spike}}} \\cdot \\frac{L_{\\text{spike}}}{L_{\\text{path}}}$$\nThis derived expression allows us to calculate the number of pathogen genomes in the processed sample volume by relating the ratio of observed read counts to the ratio of known genome lengths, scaled by the known quantity of the spike-in control.\n\nThe problem requires the final answer as a concentration in copies per milliliter. Let this concentration be $\\rho_{\\text{path}}$. It is defined as the total number of pathogen copies, $N_{\\text{path}}$, divided by the input sample volume, $V_{\\text{in}}$.\n$$\\rho_{\\text{path}} = \\frac{N_{\\text{path}}}{V_{\\text{in}}}$$\nSubstituting the expression for $N_{\\text{path}}$:\n$$\\rho_{\\text{path}} = \\frac{1}{V_{\\text{in}}} \\left( N_{\\text{spike}} \\cdot \\frac{C_{\\text{path}}}{C_{\\text{spike}}} \\cdot \\frac{L_{\\text{spike}}}{L_{\\text{path}}} \\right)$$\nNow we substitute the given numerical values into this expression.\nGiven:\n- Input volume: $V_{\\text{in}} = 1.00 \\ \\mathrm{mL}$\n- Spike-in copies: $N_{\\text{spike}} = 5.00 \\times 10^{7}$ copies\n- Spike-in read pairs: $C_{\\text{spike}} = 6.00 \\times 10^{4}$\n- Pathogen read pairs: $C_{\\text{path}} = 4.00 \\times 10^{2}$\n- Spike-in length: $L_{\\text{spike}} = 3.000 \\times 10^{3} \\ \\mathrm{bp}$\n- Pathogen length: $L_{\\text{path}} = 2.000 \\times 10^{6} \\ \\mathrm{bp}$\n\nCalculation:\n$$\\rho_{\\text{path}} = \\frac{1}{1.00 \\ \\mathrm{mL}} \\left( (5.00 \\times 10^{7}) \\cdot \\frac{4.00 \\times 10^{2}}{6.00 \\times 10^{4}} \\cdot \\frac{3.000 \\times 10^{3}}{2.000 \\times 10^{6}} \\right)$$\n$$\\rho_{\\text{path}} = \\left( 5.00 \\times 10^{7} \\right) \\cdot \\left( \\frac{4.00}{6.00} \\times 10^{2-4} \\right) \\cdot \\left( \\frac{3.000}{2.000} \\times 10^{3-6} \\right) \\ \\mathrm{copies} \\cdot \\mathrm{mL}^{-1}$$\n$$\\rho_{\\text{path}} = \\left( 5.00 \\times \\frac{2}{3} \\times 1.5 \\right) \\cdot \\left( 10^{7} \\times 10^{-2} \\times 10^{-3} \\right) \\ \\mathrm{copies} \\cdot \\mathrm{mL}^{-1}$$\n$$\\rho_{\\text{path}} = \\left( 5.00 \\times \\frac{2}{3} \\times \\frac{3}{2} \\right) \\cdot 10^{7-2-3} \\ \\mathrm{copies} \\cdot \\mathrm{mL}^{-1}$$\n$$\\rho_{\\text{path}} = 5.00 \\cdot 10^{2} \\ \\mathrm{copies} \\cdot \\mathrm{mL}^{-1}$$\n$$\\rho_{\\text{path}} = 500 \\ \\mathrm{copies} \\cdot \\mathrm{mL}^{-1}$$\nRounding to three significant figures as requested, the value is $5.00 \\times 10^2$.\n\nIn addition to the computation, we identify the core assumptions required for this internal standard calibration to be valid.\n\n1.  **Equivalent Processing Efficiency from Lysis Onward**: The spike-in control, a synthetic naked DNA molecule, is added prior to sample lysis. The fundamental assumption is that the pathogen's genomic DNA, once released from the cell, and the spike-in DNA behave identically throughout all subsequent workflow steps. This includes DNA extraction/purification, fragmentation, library construction (end-repair, A-tailing, adapter ligation), and PCR amplification. Crucially, this requires that the lysis step itself is non-biasing and effectively releases the nucleic acid from the pathogen. If the pathogen has a robust cell wall that is resistant to the lysis method, its DNA will be under-represented in the initial pool, leading to a significant underestimation of its concentration. The calibration model implicitly assumes $100\\%$ lysis efficiency or that the efficiency is identical for all organisms, which is a strong assumption.\n\n2.  **Unbiased Sequencing and Mapping**: The model is based on \"uniform and unbiased sampling\". This assumes that DNA fragments from the pathogen and the spike-in have an equal probability of being sequenced, regardless of their primary sequence. Factors such as extreme GC content ($(\\text{G}+\\text{C})/(\\text{A}+\\text{T}+\\mathrm{G}+\\text{C})$) can introduce known biases during PCR amplification and sequencing. Furthermore, the bioinformatics analysis must be unbiased. The algorithm used for competitive mapping must assign reads to their correct origin with equal accuracy and precision for both pathogen and spike-in sequences. If pathogen sequences are more likely to be discarded as ambiguous or mis-mapped (e.g., due to homology with the human genome), the count $C_{\\text{path}}$ will be artificially low, again leading to an underestimate of the pathogen load.\n\n3.  **Accurate Knowledge of Genome Lengths**: The calculation explicitly depends on the genome lengths $L_{\\text{path}}$ and $L_{\\text{spike}}$. The method assumes that the values used are accurate. While the spike-in length is precisely known by design, the pathogen genome length is an estimate based on a reference. Significant variation in genome size between the detected strain and the reference genome could introduce a systematic error in the quantification. The assumption is that the reference genome length is a sufficiently accurate representation of the actual genome length of the pathogen in the sample.", "answer": "$$\\boxed{5.00 \\times 10^{2}}$$", "id": "5132005"}, {"introduction": "After generating read counts, a crucial decision must be made: is the pathogen truly present? Setting a simple read count threshold is a common but often arbitrary practice. This hands-on exercise [@problem_id:5132078] introduces a rigorous, decision-theoretic framework for optimizing a diagnostic threshold. By modeling read counts as a Poisson process and incorporating the prevalence of the disease along with the clinical costs of false positives and false negatives, you will develop a data-driven rule that balances the trade-off between sensitivity and specificity in a rational and justifiable manner.", "problem": "You are tasked with writing a complete, runnable program that models a binary detection decision for pathogen presence in metagenomic shotgun sequencing within the field of molecular and immunodiagnostics. The setting is as follows: a sequencing assay yields a count of pathogen-specific reads per sample, and this count is modeled as arising from a Poisson process under two conditions. Under background (no pathogen), the count is modeled as a Poisson random variable with rate $\\lambda_0$. Under pathogen presence, the count is modeled as a Poisson random variable with rate $\\lambda_1$. The rates $\\lambda_0$ and $\\lambda_1$ represent expected counts measured in Reads Per Million (RPM), while the observed count is an integer number of reads. The decision rule is parameterized by an integer threshold $\\tau$: predict pathogen presence if and only if the observed count $k$ satisfies $k \\ge \\tau$.\n\nYour program must, for each test case, compute the Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC), and then optimize the threshold under a specified loss function. The ROC curve is the parametric plot of the False Positive Rate (FPR) and the True Positive Rate (TPR) as $\\tau$ varies over the nonnegative integers. The AUC is the integral of the ROC curve from FPR $1$ down to FPR $0$, computed numerically from the discrete ROC points. The optimization of the threshold requires minimizing the expected loss\n$$\nL(\\tau) = c_{\\mathrm{FP}} \\cdot (1 - \\pi) \\cdot \\mathrm{FPR}(\\tau) + c_{\\mathrm{FN}} \\cdot \\pi \\cdot \\big(1 - \\mathrm{TPR}(\\tau)\\big),\n$$\nwhere $\\pi$ is the prevalence (the prior probability that a sample contains the pathogen), $c_{\\mathrm{FP}}$ is the cost of a False Positive (FP), and $c_{\\mathrm{FN}}$ is the cost of a False Negative (FN). The optimized threshold $\\tau^*$ is defined as any integer threshold that achieves the minimal expected loss. In case of ties, choose the smallest $\\tau$ that attains the minimal expected loss.\n\nBase your derivation on the following foundational definitions and widely accepted facts, which serve as the starting point:\n- In metagenomic shotgun sequencing, read counts mapping uniquely to a pathogen genome can be modeled as outcomes of a counting process. Under fixed assay conditions, independent read generation with a constant rate yields a Poisson model for counts, with probability mass function $P(K = k \\mid \\lambda) = e^{-\\lambda} \\lambda^k / k!$ for integer $k \\ge 0$ and rate $\\lambda > 0$.\n- The Receiver Operating Characteristic (ROC) curve relates $\\mathrm{TPR}$ and $\\mathrm{FPR}$ across decision thresholds for a binary classifier. The Area Under the Curve (AUC) is a scalar performance summary that equals $1$ for perfect separation and $\\tfrac{1}{2}$ for indistinguishable classes under symmetric ranking.\n- Decision-theoretic risk minimization combines prior probabilities and misclassification costs to select thresholds that minimize expected loss.\n\nYour program must implement the following steps for each test case:\n1. Construct the discrete ROC curve by evaluating $\\mathrm{TPR}(\\tau)$ and $\\mathrm{FPR}(\\tau)$ over integer thresholds $\\tau \\in \\{0,1,2,\\dots, T_{\\max}\\}$, where $T_{\\max}$ is a sufficiently large integer such that both tails are numerically negligible at and beyond $T_{\\max}$. Use a principled choice of $T_{\\max}$ based on the upper quantiles of the Poisson distributions parameterized by $\\lambda_0$ and $\\lambda_1$.\n2. Compute the numerical AUC from the discrete ROC points using a consistent numerical integration method over FPR, ensuring that $\\mathrm{AUC} \\in [0,1]$.\n3. For a given prevalence $\\pi$ and loss weights $c_{\\mathrm{FP}}$ and $c_{\\mathrm{FN}}$, compute the expected loss $L(\\tau)$ for each threshold, and select the optimal threshold $\\tau^*$ with the tie-breaking rule specified above.\n4. Report, for each test case, the tuple $[\\tau^*, \\mathrm{AUC}, \\mathrm{FPR}(\\tau^*), \\mathrm{TPR}(\\tau^*), L(\\tau^*)]$ with floating-point entries rounded to $6$ decimal places and $\\tau^*$ as an integer.\n\nDefinitions, units, and clarifications:\n- The rates $\\lambda_0$ and $\\lambda_1$ are expected read counts per million total reads and are expressed in Reads Per Million (RPM), but the threshold $\\tau$ and observed counts are in raw reads (integer counts).\n- The False Positive Rate (FPR) is $P(\\text{declare pathogen} \\mid \\text{background})$, and the True Positive Rate (TPR) is $P(\\text{declare pathogen} \\mid \\text{pathogen present})$.\n- All probabilities must be expressed as decimals, not with a percentage sign.\n\nTest suite to implement:\n- Case $1$: $\\lambda_0 = 0.5$, $\\lambda_1 = 5.0$, $\\pi = 0.05$, $c_{\\mathrm{FP}} = 1.0$, $c_{\\mathrm{FN}} = 10.0$.\n- Case $2$ (boundary condition): $\\lambda_0 = 2.0$, $\\lambda_1 = 2.0$, $\\pi = 0.5$, $c_{\\mathrm{FP}} = 1.0$, $c_{\\mathrm{FN}} = 1.0$.\n- Case $3$ (subtle signal): $\\lambda_0 = 0.8$, $\\lambda_1 = 1.2$, $\\pi = 0.1$, $c_{\\mathrm{FP}} = 1.0$, $c_{\\mathrm{FN}} = 3.0$.\n- Case $4$ (high background, moderate separation): $\\lambda_0 = 10.0$, $\\lambda_1 = 20.0$, $\\pi = 0.2$, $c_{\\mathrm{FP}} = 2.0$, $c_{\\mathrm{FN}} = 1.0$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case, and each element itself is a list of the form $[\\tau^*, \\mathrm{AUC}, \\mathrm{FPR}(\\tau^*), \\mathrm{TPR}(\\tau^*), L(\\tau^*)]$. For example: $[[1,0.900000,0.100000,0.950000,0.600000],[\\dots]]$.", "solution": "The user-provided problem has been assessed and is determined to be valid. It is scientifically grounded, well-posed, objective, and internally consistent. We may therefore proceed with a full solution.\n\n### 1. Mathematical Formulation of the Detection Problem\n\nThe problem is structured around two competing hypotheses:\n-   $H_0$: The sample is from a background condition (no pathogen). The observed read count $K$ is a random variable following a Poisson distribution with rate $\\lambda_0$.\n-   $H_1$: The sample contains the pathogen. The observed read count $K$ is a random variable following a Poisson distribution with rate $\\lambda_1$.\n\nThe probability mass function (PMF) for a Poisson-distributed random variable $K$ with rate parameter $\\lambda$ is given by:\n$$\nP(K=k \\mid \\lambda) = \\frac{e^{-\\lambda} \\lambda^k}{k!} \\quad \\text{for } k \\in \\{0, 1, 2, \\dots\\}\n$$\nA decision rule is established based on an integer threshold $\\tau \\ge 0$. The pathogen is declared present if the observed count $k$ is greater than or equal to $\\tau$.\n$$\n\\text{Decision} = \\begin{cases} \\text{Pathogen present (Positive)} & \\text{if } k \\ge \\tau \\\\ \\text{Background (Negative)} & \\text{if } k < \\tau \\end{cases}\n$$\n\n### 2. True Positive Rate and False Positive Rate\n\nThe performance of this decision rule is characterized by the True Positive Rate (TPR) and the False Positive Rate (FPR), which are conditional probabilities defined as follows:\n\n-   **True Positive Rate (TPR)**, or sensitivity, is the probability of correctly identifying a sample with the pathogen. It is the probability of observing $K \\ge \\tau$ given that the state is $H_1$.\n    $$\n    \\mathrm{TPR}(\\tau) = P(K \\ge \\tau \\mid H_1) = P(K \\ge \\tau \\mid \\lambda_1) = \\sum_{k=\\tau}^{\\infty} \\frac{e^{-\\lambda_1} \\lambda_1^k}{k!}\n    $$\n    This is the survival function (or complementary cumulative distribution function, CCDF) of the Poisson distribution with rate $\\lambda_1$. It can be computed as $\\mathrm{TPR}(\\tau) = 1 - P(K < \\tau \\mid \\lambda_1) = 1 - P(K \\le \\tau - 1 \\mid \\lambda_1) = 1 - F_{\\text{Poisson}(\\lambda_1)}(\\tau-1)$, where $F$ is the cumulative distribution function (CDF).\n\n-   **False Positive Rate (FPR)**, or $1 - \\text{specificity}$, is the probability of incorrectly identifying a background sample as containing the pathogen. It is the probability of observing $K \\ge \\tau$ given that the state is $H_0$.\n    $$\n    \\mathrm{FPR}(\\tau) = P(K \\ge \\tau \\mid H_0) = P(K \\ge \\tau \\mid \\lambda_0) = \\sum_{k=\\tau}^{\\infty} \\frac{e^{-\\lambda_0} \\lambda_0^k}{k!}\n    $$\n    Similarly, this is the survival function of the Poisson distribution with rate $\\lambda_0$, computed as $\\mathrm{FPR}(\\tau) = 1 - F_{\\text{Poisson}(\\lambda_0)}(\\tau-1)$.\n\nAs the threshold $\\tau$ increases from $0$ to $\\infty$, both $\\mathrm{TPR}(\\tau)$ and $\\mathrm{FPR}(\\tau)$ are non-increasing, ranging from $1$ (for $\\tau=0$) to $0$ (as $\\tau \\to \\infty$).\n\n### 3. ROC Curve and Area Under the Curve (AUC)\n\nThe ROC curve is a parametric plot of $(\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau))$ in a 2D plane, for all possible values of the threshold $\\tau$. For our discrete set of integer thresholds $\\tau \\in \\{0, 1, 2, \\dots, T_{\\max}\\}$, this generates a set of discrete points. The curve conventionally includes the points $(0,0)$ (for $\\tau \\to \\infty$) and $(1,1)$ (for $\\tau=0$).\n\nTo compute the ROC curve and AUC:\n1.  A sufficiently large upper threshold, $T_{\\max}$, is chosen such that the Poisson probabilities $P(K > T_{\\max})$ are negligible for both $\\lambda_0$ and $\\lambda_1$. This can be determined by finding a high quantile of the Poisson distribution with rate $\\max(\\lambda_0, \\lambda_1)$.\n2.  The ROC points $(\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau))$ are calculated for a sequence of thresholds, typically from $T_{\\max}+1$ down to $0$. This generates a set of $(x,y)$ coordinates that are sorted by the x-coordinate (FPR).\n3.  The Area Under the Curve (AUC) is a scalar metric summarizing the classifier's performance, representing its ability to distinguish between the two classes. It is the integral of the ROC curve from $\\mathrm{FPR}=0$ to $\\mathrm{FPR}=1$. For a discrete set of ROC points $(x_i, y_i)$ sorted by $x_i$, the AUC can be numerically computed using the trapezoidal rule:\n    $$\n    \\mathrm{AUC} = \\sum_{i=1}^{N} \\frac{y_i + y_{i-1}}{2} (x_i - x_{i-1})\n    $$\n    where the points are $(x_0, y_0), (x_1, y_1), \\dots, (x_N, y_N)$. An AUC of $1.0$ signifies a perfect classifier, while an AUC of $0.5$ indicates performance no better than random chance.\n\n### 4. Optimal Threshold Selection via Loss Minimization\n\nThe optimal threshold, $\\tau^*$, is chosen to minimize the expected loss, or risk, associated with misclassification. The loss function $L(\\tau)$ is given as:\n$$\nL(\\tau) = c_{\\mathrm{FP}} \\cdot (1 - \\pi) \\cdot \\mathrm{FPR}(\\tau) + c_{\\mathrm{FN}} \\cdot \\pi \\cdot \\mathrm{FNR}(\\tau)\n$$\nwhere $\\pi$ is the prior probability (prevalence) of pathogen presence, $c_{\\mathrm{FP}}$ is the cost of a false positive, $c_{\\mathrm{FN}}$ is the cost of a false negative, and $\\mathrm{FNR}(\\tau)$ is the False Negative Rate.\n\nThe False Negative Rate is the probability of failing to detect the pathogen when it is present:\n$$\n\\mathrm{FNR}(\\tau) = P(K < \\tau \\mid H_1) = 1 - P(K \\ge \\tau \\mid H_1) = 1 - \\mathrm{TPR}(\\tau)\n$$\nSubstituting this into the loss function yields:\n$$\nL(\\tau) = c_{\\mathrm{FP}} \\cdot (1 - \\pi) \\cdot \\mathrm{FPR}(\\tau) + c_{\\mathrm{FN}} \\cdot \\pi \\cdot \\big(1 - \\mathrm{TPR}(\\tau)\\big)\n$$\nTo find the optimal threshold $\\tau^*$, we will-\n1.  Calculate $L(\\tau)$ for each integer threshold $\\tau$ in the range $[0, T_{\\max}]$.\n2.  Identify the minimum value of this loss function, $L_{\\min} = \\min_{\\tau} L(\\tau)$.\n3.  The optimal threshold $\\tau^*$ is the smallest integer $\\tau$ for which $L(\\tau) = L_{\\min}$.\n\nThe algorithm proceeds by first calculating the vectors of $\\mathrm{FPR}(\\tau)$ and $\\mathrm{TPR}(\\tau)$ for $\\tau \\in [0, T_{\\max}]$, then using these vectors to compute the AUC and the vector of losses $L(\\tau)$, from which the optimal threshold and associated performance metrics are determined. This procedure is applied to each test case provided.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import poisson\n\ndef solve():\n    \"\"\"\n    Solves the pathogen detection problem for a suite of test cases.\n    For each case, it calculates the optimal detection threshold, AUC,\n    and associated performance metrics by modeling read counts with\n    Poisson distributions and minimizing an expected loss function.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (lambda_0, lambda_1, pi, c_fp, c_fn)\n        (0.5, 5.0, 0.05, 1.0, 10.0), # Case 1\n        (2.0, 2.0, 0.5, 1.0, 1.0),   # Case 2 (boundary condition)\n        (0.8, 1.2, 0.1, 1.0, 3.0),   # Case 3 (subtle signal)\n        (10.0, 20.0, 0.2, 2.0, 1.0)  # Case 4 (high background)\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        lambda0, lambda1, pi, c_fp, c_fn = case\n        \n        # 1. Construct the discrete ROC curve\n        # Choose T_max to ensure tails are negligible.\n        # We use the 1 - 1e-12 quantile of the larger Poisson lambda,\n        # plus a small buffer. We use max(..., 1) to handle small lambdas.\n        t_max = int(poisson.ppf(1 - 1e-12, max(lambda0, lambda1, 1))) + 10\n        \n        # Thresholds to evaluate for optimization\n        taus_opt = np.arange(0, t_max + 1)\n        \n        # Calculate FPR and TPR for each threshold.\n        # P(K >= tau) = 1 - P(K = tau - 1) = 1 - CDF(tau - 1)\n        fprs = 1 - poisson.cdf(taus_opt - 1, lambda0)\n        tprs = 1 - poisson.cdf(taus_opt - 1, lambda1)\n        \n        # 2. Compute the numerical AUC\n        # For AUC calculation, we need ROC points sorted by ascending FPR.\n        # This is achieved by evaluating thresholds from high to low.\n        taus_roc = np.arange(t_max + 1, -1, -1)\n        roc_fpr = 1 - poisson.cdf(taus_roc - 1, lambda0)\n        roc_tpr = 1 - poisson.cdf(taus_roc - 1, lambda1)\n        \n        # Use a consistent numerical integration method (trapezoidal rule).\n        auc = np.trapz(roc_tpr, roc_fpr)\n        \n        # 3. Optimize the threshold under the loss function\n        # L(tau) = c_FP * (1 - pi) * FPR(tau) + c_FN * pi * (1 - TPR(tau))\n        losses = c_fp * (1 - pi) * fprs + c_fn * pi * (1 - tprs)\n        \n        # Find the index of the minimum loss. np.argmin() breaks ties\n        # by choosing the smallest index, which corresponds to the smallest tau.\n        opt_idx = np.argmin(losses)\n        \n        tau_star = taus_opt[opt_idx]\n        min_loss = losses[opt_idx]\n        fpr_at_tau_star = fprs[opt_idx]\n        tpr_at_tau_star = tprs[opt_idx]\n        \n        # 4. Report the tuple of results\n        result_tuple = [\n            int(tau_star),           # tau* as integer\n            auc,                     # AUC\n            fpr_at_tau_star,         # FPR(tau*)\n            tpr_at_tau_star,         # TPR(tau*)\n            min_loss                 # L(tau*)\n        ]\n        results.append(result_tuple)\n\n    # Final print statement in the exact required format.\n    # Floating-point entries are rounded to 6 decimal places.\n    output_parts = []\n    for r in results:\n        formatted_r = (\n            f\"[{r[0]},\"\n            f\"{r[1]:.6f},\"\n            f\"{r[2]:.6f},\"\n            f\"{r[3]:.6f},\"\n            f\"{r[4]:.6f}]\"\n        )\n        output_parts.append(formatted_r)\n    \n    print(f\"[{','.join(output_parts)}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "5132078"}]}