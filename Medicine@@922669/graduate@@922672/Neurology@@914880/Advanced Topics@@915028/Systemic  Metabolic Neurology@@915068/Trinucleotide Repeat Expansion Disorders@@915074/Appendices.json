{"hands_on_practices": [{"introduction": "Understanding trinucleotide repeat expansion disorders begins at the molecular level with the process of repeat instability. This practice invites you to build a quantitative model from first principles, capturing the interplay between deoxyribonucleic acid (DNA) replication slippage and mismatch repair (MMR) that drives changes in repeat length. By deriving the expected change in repeat count per cell cycle, you will gain hands-on experience in translating complex biological phenomena into a predictive mathematical framework. [@problem_id:4533469]", "problem": "A tract of unstable trinucleotide repeats in a neuronal progenitor is replicated once per cell cycle. In trinucleotide repeat expansion disorders, replication slippage during deoxyribonucleic acid (DNA) synthesis produces looped mispairs whose fate depends on mismatch repair (MMR). Use the following experimentally grounded model, consistent with polymerase slippage and repair in repetitive DNA:\n\n- The tract contains an initial repeat number $n_0 \\in \\mathbb{N}$ at the start of the cell cycle.\n- Each repeat unit independently generates a slippage intermediate during replication with probability $p$, where $0 < p \\ll 1$ and $p n_0 \\ll 1$. Under this rare-event regime, assume at most one slippage intermediate forms per cell cycle, with probability approximately $p n_0$.\n- Conditional on a slippage intermediate forming, MMR corrects the mispair to the original sequence with probability $q$, where $0 \\le q \\le 1$. If corrected, the repeat number does not change during that cycle.\n- If not corrected (which occurs with probability $1 - q$), the mispair is fixed into the genome during ligation as either an expansion by $+1$ repeat or a contraction by $-1$ repeat. Motivated by the increased thermodynamic stability and formation propensity of longer hairpins, suppose the conditional odds of expansion relative to contraction scale with tract length as $n_0 : 1$. Equivalently, the conditional probability of expansion given an uncorrected slippage intermediate is $\\frac{n_0}{n_0 + 1}$ and the conditional probability of contraction is $\\frac{1}{n_0 + 1}$.\n\nStarting from the law of total expectation and these assumptions, derive the expected change in repeat length per cell cycle, $\\mathbb{E}[\\Delta n \\mid n_0, p, q]$, as a closed-form expression in $p$, $q$, and $n_0$. Express your final result in repeats per cell cycle. No numerical evaluation is required; provide an exact analytic expression as your answer. Do not round.", "solution": "We begin from basic probability and the law of total expectation. Let $\\Delta n$ denote the net change in repeat count across one cell cycle. We decompose by the events that lead to change:\n\n- Event $S$: at least one slippage intermediate forms during replication. Under the rare-event assumption with $p n_0 \\ll 1$ and independent per-unit slippage probability $p$, the probability of at least one slippage intermediate in the tract is approximated by\n$$\n\\mathbb{P}(S) \\approx p n_0.\n$$\n- Conditional on $S$, the mispair is corrected by mismatch repair (MMR) with probability $q$, yielding $\\Delta n = 0$.\n- If not corrected, with probability $(1 - q)$, the mispair is fixed as either an expansion by $+1$ repeat with probability $\\frac{n_0}{n_0 + 1}$ or a contraction by $-1$ repeat with probability $\\frac{1}{n_0 + 1}$, reflecting the $n_0 : 1$ expansion-to-contraction odds.\n\nDefine the conditional mean step size given an uncorrected slippage event:\n$$\n\\mu_{\\text{step}}(n_0) \\equiv \\mathbb{E}\\big[\\Delta n \\,\\big|\\, S, \\text{uncorrected}\\big]\n= (+1)\\cdot \\frac{n_0}{n_0 + 1} + (-1)\\cdot \\frac{1}{n_0 + 1}\n= \\frac{n_0 - 1}{n_0 + 1}.\n$$\nNow apply the law of total expectation, conditioning on $S$ and on correction:\n$$\n\\mathbb{E}[\\Delta n \\mid n_0, p, q]\n= \\mathbb{E}\\big[\\Delta n \\,\\big|\\, S\\big]\\cdot \\mathbb{P}(S) + \\mathbb{E}\\big[\\Delta n \\,\\big|\\, \\neg S\\big]\\cdot \\mathbb{P}(\\neg S).\n$$\nIf $\\neg S$ occurs, then no slippage intermediate forms and $\\Delta n = 0$, so $\\mathbb{E}[\\Delta n \\mid \\neg S] = 0$. Furthermore,\n$$\n\\mathbb{E}\\big[\\Delta n \\,\\big|\\, S\\big]\n= \\mathbb{E}\\big[\\Delta n \\,\\big|\\, S, \\text{corrected}\\big]\\cdot q\n+ \\mathbb{E}\\big[\\Delta n \\,\\big|\\, S, \\text{uncorrected}\\big]\\cdot (1 - q)\n= 0 \\cdot q + \\mu_{\\text{step}}(n_0)\\cdot (1 - q).\n$$\nCombining these pieces,\n$$\n\\mathbb{E}[\\Delta n \\mid n_0, p, q]\n\\approx \\big[(1 - q)\\,\\mu_{\\text{step}}(n_0)\\big]\\cdot \\big(p n_0\\big)\n= (1 - q)\\, p\\, n_0 \\cdot \\frac{n_0 - 1}{n_0 + 1}.\n$$\nTherefore, the expected change in repeat length per cell cycle, in repeats per cell cycle, is\n$$\n\\mathbb{E}[\\Delta n \\mid n_0, p, q] \\approx (1 - q)\\, p\\, n_0 \\,\\frac{n_0 - 1}{n_0 + 1}.\n$$\nThis expression increases with $n_0$ and is positive for $n_0 > 1$, capturing the empirically observed expansion bias at longer repeat tracts under the stated model assumptions.", "answer": "$$\\boxed{(1 - q)\\,p\\,n_0\\,\\frac{n_0 - 1}{n_0 + 1}}$$", "id": "4533469"}, {"introduction": "Translating genotype to phenotype is a central challenge in neurology, with the goal of predicting clinical outcomes such as age at onset. This exercise puts you in the role of a quantitative researcher, tasked with building and testing statistical models that link genetic data—specifically, repeat length ($R_i$) and a polygenic modifier score ($M_i$)—to the age at which a patient develops symptoms ($A_i$). Through this hands-on coding practice, you will implement Ordinary Least Squares (OLS) regression to estimate the impact of these genetic factors, developing essential skills in computational modeling and data analysis. [@problem_id:4533421]", "problem": "You are to construct and estimate a multivariate model for the age at onset of a trinucleotide repeat expansion disorder, grounded in mechanistic reasoning and quantitative principles. Let $R_i$ denote the trinucleotide repeat length (in number of repeats) for individual $i$, $M_i$ denote a polygenic modifier burden score (dimensionless and allowed to be any real value), and $A_i$ denote the age at onset (in years) for individual $i$. Use the following foundational base to derive an estimable model:\n\n1. The Central Dogma of Molecular Biology (DNA $\\rightarrow$ RNA $\\rightarrow$ protein) and the well-tested observation that longer pathogenic trinucleotide repeats increase somatic expansion and lead to earlier clinical onset, with modifier genes (for example, DNA repair pathway genes) altering this trajectory.\n2. A threshold mechanism of disease initiation where cumulative damage or dysfunction increases over time, modulated by the somatic expansion rate, and onset occurs when a threshold is crossed.\n\nAssume Gaussian observational error at the level of the chosen transformed dependent variable. Consider two transform-based linear modeling strategies that can be justified from this mechanistic base:\n\n- Log-linear damage-to-onset time scaling: assume that the multiplicative contributors to age at onset $A_i$ from $R_i$ and $M_i$ lead to an approximately additive structure in $\\ln A_i$, so that\n$$\n\\ln A_i = \\beta_0 + \\beta_R R_i + \\beta_M M_i + \\beta_{RM} R_i M_i + \\varepsilon_i,\n$$\nwhere $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$.\n- Reciprocal damage rate threshold crossing: assume onset time is inversely proportional to a linearized somatic expansion rate, yielding\n$$\n\\frac{1}{A_i} = \\gamma_0 + \\gamma_R R_i + \\gamma_M M_i + \\varepsilon_i,\n$$\nwhere $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$.\n\nYour task is to:\n- Implement Ordinary Least Squares (OLS) to estimate effect sizes for each specified test case by fitting the appropriate transformed dependent variable $y_i$ to the specified predictors. For the log-linear model, fit $y_i = \\ln A_i$; for the reciprocal model, fit $y_i = 1/A_i$.\n- Construct the design matrix with an intercept term and the predictors $R_i$, $M_i$, and optionally the interaction term $R_i M_i$ when specified.\n- For each test case, compute the estimated coefficients in the order $[\\hat{\\theta}_0,\\hat{\\theta}_R,\\hat{\\theta}_M]$ and append $[\\hat{\\theta}_{RM}]$ as a fourth element only when the interaction is specified, where $\\hat{\\theta}$ denotes $\\hat{\\beta}$ or $\\hat{\\gamma}$ depending on the model.\n\nAll ages $A_i$ are measured in years. In the log-linear model, effect sizes are expressed in natural log-years per unit predictor; in the reciprocal model, effect sizes are expressed in $1/\\text{years}$ per unit predictor.\n\nUse the following test suite. For each case, generate the observed ages $A_i$ deterministically using the stated generative parameters and the given $R_i$, $M_i$, and $\\varepsilon_i$ arrays. For the log-linear model, construct $A_i$ via $A_i = \\exp(\\beta_0 + \\beta_R R_i + \\beta_M M_i + \\beta_{RM} R_i M_i + \\varepsilon_i)$ with $\\beta_{RM}$ omitted when the interaction is not specified. For the reciprocal model, construct $A_i$ via $A_i = \\left(\\gamma_0 + \\gamma_R R_i + \\gamma_M M_i + \\varepsilon_i\\right)^{-1}$.\n\nTest Case $1$ (log-linear with interaction, moderate sample, small noise):\n- Parameters: $\\beta_0 = 4.5$, $\\beta_R = -0.015$, $\\beta_M = -0.06$, $\\beta_{RM} = -0.0015$.\n- Repeat lengths $R$: $[41,45,50,55,60,42,47,53,58,44,49,52,57,61]$.\n- Modifier scores $M$: $[-1.2,0.5,-0.7,1.8,2.1,-0.5,1.1,-1.5,0.3,0.8,-2.0,1.5,-0.3,2.2]$.\n- Errors $\\varepsilon$: $[0.03,-0.02,0.01,-0.04,0.05,0.00,0.02,-0.03,0.01,-0.01,0.04,-0.02,0.00,0.03]$.\n\nTest Case $2$ (log-linear without interaction, near-threshold repeats, no noise):\n- Parameters: $\\beta_0 = 4.6$, $\\beta_R = -0.01$, $\\beta_M = -0.04$.\n- Repeat lengths $R$: $[36,37,38,39,40,36,38,40,37,39]$.\n- Modifier scores $M$: $[-0.4,-0.2,0.0,0.2,0.4,-1.0,1.0,-1.5,1.5,0.0]$.\n- Errors $\\varepsilon$: $[0,0,0,0,0,0,0,0,0,0]$.\n\nTest Case $3$ (reciprocal without interaction, moderate sample, small noise):\n- Parameters: $\\gamma_0 = 0.015$, $\\gamma_R = 0.0002$, $\\gamma_M = 0.002$.\n- Repeat lengths $R$: $[38,42,46,50,54,40,45,49,53,55]$.\n- Modifier scores $M$: $[-1.0,-0.5,0.0,0.5,1.0,-1.5,1.5,-0.8,0.8,0.2]$.\n- Errors $\\varepsilon$: $[0.0005,-0.0003,0.0,0.0004,-0.0006,0.0000,0.0002,-0.0002,0.0001,-0.0001]$.\n\nTest Case $4$ (log-linear with interaction, minimal sample, no noise):\n- Parameters: $\\beta_0 = 4.55$, $\\beta_R = -0.016$, $\\beta_M = -0.05$, $\\beta_{RM} = -0.002$.\n- Repeat lengths $R$: $[43,48,52,57]$.\n- Modifier scores $M$: $[-0.8,0.0,0.9,1.7]$.\n- Errors $\\varepsilon$: $[0,0,0,0]$.\n\nAlgorithmic requirements:\n- Use Ordinary Least Squares, computing $\\hat{\\theta} = (X^\\top X)^{-1}X^\\top y$ or an equivalent numerically stable solver.\n- No regularization, no external data, and no randomness beyond the provided fixed errors.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s result should itself be a bracketed comma-separated list of its estimated coefficients in the order specified above. For example: $[[\\hat{\\theta}_0,\\hat{\\theta}_R,\\hat{\\theta}_M,\\hat{\\theta}_{RM}],[\\hat{\\theta}_0,\\hat{\\theta}_R,\\hat{\\theta}_M],\\dots]$. All ages are in years, and for the reciprocal model the transformed dependent variable is in $1/\\text{years}$. The printed coefficients should be floats.", "solution": "The problem requires implementing Ordinary Least Squares (OLS) regression to estimate parameters for two different models of disease age at onset. The solution involves writing a program that iterates through four test cases.\n\nFor each test case, the program first constructs the dependent variable vector, `y`. Based on the model type (log-linear or reciprocal), `y` is either `ln(A)` or `1/A`. The problem simplifies this by providing the exact linear predictor plus error term for `y`, so `y` is calculated directly as `y = (linear_predictor) + ε`.\n\nNext, the program constructs the design matrix, `X`. This matrix always includes a column of ones for the intercept. It then includes columns for the repeat length `R` and the modifier score `M`. If the model specifies an interaction, an additional column for the element-wise product `R * M` is added.\n\nFinally, the program calculates the estimated coefficients, `θ_hat`, using a numerically stable OLS solver, which is equivalent to the formula `θ_hat = (X^T X)^-1 X^T y`. The estimated coefficients for each test case are collected and formatted into the required output string. For test cases with zero error, the estimated coefficients will exactly match the true parameters, verifying the correctness of the implementation.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and estimates multivariate models for the age at onset of a \n    trinucleotide repeat expansion disorder using Ordinary Least Squares (OLS).\n    \"\"\"\n\n    test_cases = [\n        {\n            \"id\": \"Test Case 1\",\n            \"model_type\": \"log-linear\",\n            \"interaction\": True,\n            \"params\": {\"beta_0\": 4.5, \"beta_R\": -0.015, \"beta_M\": -0.06, \"beta_RM\": -0.0015},\n            \"R\": np.array([41, 45, 50, 55, 60, 42, 47, 53, 58, 44, 49, 52, 57, 61], dtype=float),\n            \"M\": np.array([-1.2, 0.5, -0.7, 1.8, 2.1, -0.5, 1.1, -1.5, 0.3, 0.8, -2.0, 1.5, -0.3, 2.2], dtype=float),\n            \"eps\": np.array([0.03, -0.02, 0.01, -0.04, 0.05, 0.00, 0.02, -0.03, 0.01, -0.01, 0.04, -0.02, 0.00, 0.03], dtype=float)\n        },\n        {\n            \"id\": \"Test Case 2\",\n            \"model_type\": \"log-linear\",\n            \"interaction\": False,\n            \"params\": {\"beta_0\": 4.6, \"beta_R\": -0.01, \"beta_M\": -0.04},\n            \"R\": np.array([36, 37, 38, 39, 40, 36, 38, 40, 37, 39], dtype=float),\n            \"M\": np.array([-0.4, -0.2, 0.0, 0.2, 0.4, -1.0, 1.0, -1.5, 1.5, 0.0], dtype=float),\n            \"eps\": np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=float)\n        },\n        {\n            \"id\": \"Test Case 3\",\n            \"model_type\": \"reciprocal\",\n            \"interaction\": False,\n            \"params\": {\"gamma_0\": 0.015, \"gamma_R\": 0.0002, \"gamma_M\": 0.002},\n            \"R\": np.array([38, 42, 46, 50, 54, 40, 45, 49, 53, 55], dtype=float),\n            \"M\": np.array([-1.0, -0.5, 0.0, 0.5, 1.0, -1.5, 1.5, -0.8, 0.8, 0.2], dtype=float),\n            \"eps\": np.array([0.0005, -0.0003, 0.0, 0.0004, -0.0006, 0.0000, 0.0002, -0.0002, 0.0001, -0.0001], dtype=float)\n        },\n        {\n            \"id\": \"Test Case 4\",\n            \"model_type\": \"log-linear\",\n            \"interaction\": True,\n            \"params\": {\"beta_0\": 4.55, \"beta_R\": -0.016, \"beta_M\": -0.05, \"beta_RM\": -0.002},\n            \"R\": np.array([43, 48, 52, 57], dtype=float),\n            \"M\": np.array([-0.8, 0.0, 0.9, 1.7], dtype=float),\n            \"eps\": np.array([0, 0, 0, 0], dtype=float)\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        R, M, eps = case[\"R\"], case[\"M\"], case[\"eps\"]\n        params = case[\"params\"]\n        n_obs = len(R)\n\n        # 1. Construct the transformed dependent variable vector 'y'\n        # For both log-linear and reciprocal models, y = linear_predictor + error\n        \n        # Get true parameters based on model type (beta or gamma)\n        p_0 = params.get(\"beta_0\", params.get(\"gamma_0\"))\n        p_R = params.get(\"beta_R\", params.get(\"gamma_R\"))\n        p_M = params.get(\"beta_M\", params.get(\"gamma_M\"))\n        \n        y = p_0 + p_R * R + p_M * M\n        if case[\"interaction\"]:\n            p_RM = params.get(\"beta_RM\", params.get(\"gamma_RM\"))\n            y += p_RM * R * M\n        y += eps\n\n        # 2. Construct the design matrix 'X'\n        # Column order: intercept, R, M, R*M (if applicable)\n        intercept = np.ones(n_obs)\n        X = np.c_[intercept, R, M]\n        if case[\"interaction\"]:\n            interaction_term = R * M\n            X = np.c_[X, interaction_term]\n            \n        # 3. Compute OLS coefficients using a numerically stable solver\n        # theta_hat = (X.T @ X)^-1 @ X.T @ y\n        # np.linalg.lstsq is a more stable way to compute this.\n        # It returns a tuple; the coefficients are the first element.\n        coeffs, _, _, _ = np.linalg.lstsq(X, y.T, rcond=None)\n        \n        results.append(list(coeffs))\n\n    # Format the output as a string: [[...],[...],...]\n    result_strings = [f\"[{','.join(map(str, res))}]\" for res in results]\n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "4533421"}, {"introduction": "The ability to accurately detect pathogenic repeat expansions is fundamental to both clinical diagnostics and research. However, the molecular techniques used, such as the Polymerase Chain Reaction (PCR), are susceptible to artifacts that can mimic true expansions. This practice presents a detailed diagnostic scenario where you must act as a clinical laboratory scientist, applying rigorous quality control criteria to differentiate a genuine genetic finding from technical noise. By working through this case study, you will develop a deep, practical understanding of the principles behind robust genetic testing and interpretation. [@problem_id:4533391]", "problem": "A clinical neurology laboratory is validating a workflow for detecting pathogenic trinucleotide repeat expansions associated with neurodegenerative and neurodevelopmental disorders (for example, Huntington disease in the Huntingtin gene and Fragile X syndrome in the Fragile X Messenger Ribonucleoprotein $1$ gene). The laboratory uses fluorescence-labeled Polymerase Chain Reaction (PCR) with Capillary Electrophoresis (CE) for sizing normal alleles, and Triplet-Primed Polymerase Chain Reaction (TP-PCR) for screening expansions. Independently, large expansions are confirmed by Southern blot when indicated.\n\nConsider the following scenario. A patient suspected of Huntington disease is tested at the Huntingtin gene CAG locus. Sizing PCR amplifies a single allele of approximately $20$ repeats with a peak height of approximately $5{,}000$ relative fluorescence units, and shows minor stutter peaks at $\\pm 3$ base pairs below the main peak whose heights are approximately $5\\%$ of the main peak. TP-PCR yields a broad ladder of peaks spaced by $3$ base pairs extending from approximately $60$ to at least $110$ repeats, with peak intensities within $80\\%$ to $100\\%$ of each other across the ladder. The replicate TP-PCR runs ($2$ independent extractions and $2$ independent PCRs) show a Pearson correlation coefficient of the peak-intensity profiles of approximately $0.98$. The No-Template Control (NTC) shows no peaks above baseline (approximately $0$). A known positive control with a characterized expanded allele shows the expected ladder. When the TP-PCR is repeated using a high-fidelity polymerase and a different annealing temperature (changed by $+$3$^{\\circ}$C), the ladder persists with similar spacing and intensity distribution. The family study, when available, reveals that one parent shows a similar ladder and the other shows two normal alleles; the child shows transmission consistent with Mendelian inheritance. Southern blot confirms a high molecular weight band consistent with a long allele when the laboratory’s reflex threshold for confirmation (set at estimated $ > 60$ repeats) is met.\n\nUsing fundamental bases appropriate to this context—the Central Dogma of Molecular Biology (DNA replication fidelity and the basis of genetic inheritance), the kinetics of Polymerase Chain Reaction (doubling behavior across cycles, primer-template specificity), and well-characterized behaviors of PCR in repetitive DNA (polymerase slippage causing stutter artifacts that decay geometrically, and triplet-primed amplification producing a ladder on expanded alleles)—determine which quality control criteria most robustly differentiate true expansions from PCR artifacts in this diagnostic setting.\n\nWhich option(s) identify a scientifically sound and sufficient set of criteria to call a true expansion and exclude PCR artifacts?\n\nA. Verify that peak spacing equals the repeat unit ($3$ base pairs) on TP-PCR, require replicate concordance with correlation $r \\geq 0.95$, ensure a clean No-Template Control with baseline approximately $0$, and use an orthogonal method (Southern blot) to confirm long alleles that exceed the laboratory’s confirmation threshold; then interpret the ladder as a true expansion.\n\nB. Call a true expansion whenever a single TP-PCR run shows a ladder in which at least one peak exceeds a predefined intensity threshold, without replicate analysis, negative controls, or orthogonal confirmation.\n\nC. Use stutter ratio thresholds in sizing PCR (for example, calling any pattern where stutter exceeds $10\\%$ of the main peak a true expansion) without TP-PCR or Southern blot, because stutter accounts for all ladder-like patterns.\n\nD. Rely on the internal size standard and a positive control alone to call expansions; do not perform replicates, vary polymerases or temperatures, or confirm by Southern blot.\n\nE. Require consistency of the TP-PCR ladder across different polymerases and annealing temperatures, evaluate allele peak height ratios in sizing PCR to exclude allelic dropout of the long allele, and incorporate family segregation analysis when available; if these are satisfied and the NTC is clean, call a true expansion, with Southern blot confirmation for very large alleles per laboratory policy.", "solution": "**Option A** is correct because it outlines a standard, robust quality control workflow for a clinical diagnostic laboratory. It includes verifying the specific signal (3 bp spacing), ensuring reproducibility (high replicate correlation), running essential controls (clean NTC), and using an independent, orthogonal method (Southern blot) for confirmation. These steps are collectively sufficient to confidently distinguish a true expansion from common artifacts.\n\n**Option E** is also correct as it describes an even more comprehensive and exceptionally rigorous approach. It adds robustness checks (consistency across different PCR conditions), sophisticated data integration (interpreting sizing PCR peak heights to infer allelic dropout), and the use of genetic evidence (family segregation analysis). This multi-layered validation provides the highest possible degree of confidence in the result.\n\n**Options B, C, and D** are incorrect because they are critically flawed. Option B lacks essential controls and replication. Option C is based on a fundamental misinterpretation of stutter artifacts versus TP-PCR signals. Option D omits crucial controls (NTC), replication, and confirmation.", "answer": "$$\\boxed{AE}$$", "id": "4533391"}]}