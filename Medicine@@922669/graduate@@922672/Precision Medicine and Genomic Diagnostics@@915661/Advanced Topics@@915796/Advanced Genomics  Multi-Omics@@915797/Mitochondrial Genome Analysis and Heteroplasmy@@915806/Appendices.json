{"hands_on_practices": [{"introduction": "Quantifying mitochondrial heteroplasmy with next-generation sequencing is fundamentally a sampling process, which introduces statistical uncertainty. This foundational exercise guides you to model this process using a binomial distribution and derive, from first principles, the variance of the observed heteroplasmy fraction [@problem_id:4360571]. Mastering this derivation is key to understanding the direct relationship between sequencing depth and the precision of any heteroplasmy measurement.", "problem": "A mitochondrial variant is being quantified in a single patient sample using Next-Generation Sequencing (NGS). Assume that each sequenced mitochondrial deoxyribonucleic acid (DNA) molecule independently either carries the variant ($1$) or does not ($0$), and that the true heteroplasmy fraction in the sampled cell population is $p \\in (0,1)$. Let $n$ be the total number of sequenced molecules, and let $k$ be the count of variant-bearing molecules among these $n$ independent reads. Define the observed heteroplasmy as $\\hat{p} = k/n$. \n\nStarting from the definition of independent Bernoulli trials and the Binomial sampling model, treat $k$ as a realization from a $\\mathrm{Binomial}(n,p)$ likelihood and derive the sampling distribution of $\\hat{p}$, including its support and probability mass function. Then, starting from first principles (without invoking any pre-stated variance formulas), derive the exact variance of $\\hat{p}$ under this model. Your final answer should be a single closed-form analytic expression in terms of $n$ and $p$. No numerical rounding is required, and no units apply.", "solution": "The problem statement is assessed to be valid as it is scientifically grounded, well-posed, objective, and internally consistent. It presents a standard problem in statistical genomics that can be formally solved using established principles.\n\nThe core of this problem lies in the statistical properties of a Binomial distribution and a linear transformation of a Binomial random variable. We are given that the count of variant-bearing molecules, $k$, is a realization from a Binomial distribution with parameters $n$ (number of trials) and $p$ (probability of success). This is denoted as $k \\sim \\mathrm{Binomial}(n, p)$. The probability mass function (PMF) for $k$ is:\n$$P(k=j) = \\binom{n}{j} p^j (1-p)^{n-j}, \\quad \\text{for } j \\in \\{0, 1, 2, \\dots, n\\}$$\nThe observed heteroplasmy, $\\hat{p}$, is defined as the random variable $\\hat{p} = \\frac{k}{n}$.\n\nFirst, we derive the sampling distribution of $\\hat{p}$.\nThe set of possible values that $k$ can assume is its support, which is the set of integers $\\{0, 1, 2, \\dots, n\\}$. Since $\\hat{p}$ is a direct scaling of $k$ by a factor of $\\frac{1}{n}$, the support of $\\hat{p}$ is the set of values $\\left\\{\\frac{0}{n}, \\frac{1}{n}, \\frac{2}{n}, \\dots, \\frac{n}{n}\\right\\}$.\nTo find the PMF of $\\hat{p}$, let $x$ be a value in its support. The event $\\hat{p}=x$ is equivalent to the event $\\frac{k}{n}=x$, which in turn is equivalent to $k=nx$. Thus, the probability of $\\hat{p}$ taking on a specific value $x$ is the same as the probability of $k$ taking on the value $nx$:\n$$P(\\hat{p}=x) = P(k=nx)$$\nSubstituting $j=nx$ into the PMF of the Binomial distribution, we obtain the PMF for $\\hat{p}$:\n$$P(\\hat{p}=x) = \\binom{n}{nx} p^{nx} (1-p)^{n-nx}, \\quad \\text{for } x \\in \\left\\{0, \\frac{1}{n}, \\frac{2}{n}, \\dots, 1\\right\\}$$\nThis fully specifies the sampling distribution of the observed heteroplasmy, $\\hat{p}$.\n\nNext, we derive the exact variance of $\\hat{p}$, denoted $\\mathrm{Var}(\\hat{p})$, from first principles. The variance is defined as:\n$$\\mathrm{Var}(\\hat{p}) = E[\\hat{p}^2] - (E[\\hat{p}])^2$$\nWe begin by finding the expected value of $\\hat{p}$, $E[\\hat{p}]$. Using the linearity of expectation:\n$$E[\\hat{p}] = E\\left[\\frac{k}{n}\\right] = \\frac{1}{n}E[k]$$\nThe expected value of a Binomial random variable $k$, $E[k]$, is derived from its definition:\n$$E[k] = \\sum_{j=0}^{n} j \\cdot P(k=j) = \\sum_{j=0}^{n} j \\binom{n}{j} p^j (1-p)^{n-j}$$\nThe term for $j=0$ is $0$, so the summation starts at $j=1$. We use the identity $j\\binom{n}{j} = j \\frac{n!}{j!(n-j)!} = \\frac{n!}{(j-1)!(n-j)!} = n \\frac{(n-1)!}{(j-1)!(n-j)!} = n\\binom{n-1}{j-1}$.\n$$E[k] = \\sum_{j=1}^{n} n\\binom{n-1}{j-1} p^j (1-p)^{n-j}$$\nFactoring out $n$ and $p$:\n$$E[k] = np \\sum_{j=1}^{n} \\binom{n-1}{j-1} p^{j-1} (1-p)^{n-j}$$\nLet $i=j-1$ and $m=n-1$. The limits of summation change from $j=1 \\dots n$ to $i=0 \\dots m$. The exponent $n-j$ becomes $(m+1)-(i+1) = m-i$.\n$$E[k] = np \\sum_{i=0}^{m} \\binom{m}{i} p^i (1-p)^{m-i}$$\nThe summation term is the binomial expansion of $(p + (1-p))^m = 1^m = 1$.\nTherefore, $E[k] = np$.\nSubstituting this back, we find the expected value of $\\hat{p}$:\n$$E[\\hat{p}] = \\frac{1}{n}(np) = p$$\nThis confirms that $\\hat{p}$ is an unbiased estimator for $p$.\n\nNow, we compute the second moment, $E[\\hat{p}^2]$.\n$$E[\\hat{p}^2] = E\\left[\\left(\\frac{k}{n}\\right)^2\\right] = \\frac{1}{n^2}E[k^2]$$\nTo find $E[k^2]$, it is convenient to first calculate the second factorial moment, $E[k(k-1)]$:\n$$E[k(k-1)] = \\sum_{j=0}^{n} j(j-1) \\binom{n}{j} p^j (1-p)^{n-j}$$\nThe terms for $j=0$ and $j=1$ are $0$, so the summation starts at $j=2$. We use the identity $j(j-1)\\binom{n}{j} = j(j-1)\\frac{n!}{j!(n-j)!} = \\frac{n!}{(j-2)!(n-j)!} = n(n-1)\\frac{(n-2)!}{(j-2)!(n-j)!} = n(n-1)\\binom{n-2}{j-2}$.\n$$E[k(k-1)] = \\sum_{j=2}^{n} n(n-1)\\binom{n-2}{j-2} p^j (1-p)^{n-j}$$\nFactoring out $n(n-1)$ and $p^2$:\n$$E[k(k-1)] = n(n-1)p^2 \\sum_{j=2}^{n} \\binom{n-2}{j-2} p^{j-2} (1-p)^{n-j}$$\nLet $i=j-2$ and $m=n-2$. The limits of summation change from $j=2 \\dots n$ to $i=0 \\dots m$. The exponent $n-j$ becomes $(m+2)-(i+2) = m-i$.\n$$E[k(k-1)] = n(n-1)p^2 \\sum_{i=0}^{m} \\binom{m}{i} p^i (1-p)^{m-i}$$\nAgain, the sum is the binomial expansion of $(p + (1-p))^m = 1$.\nThus, $E[k(k-1)] = n(n-1)p^2$.\nWe can express $E[k^2]$ using the relation $E[k(k-1)] = E[k^2-k] = E[k^2] - E[k]$.\n$$E[k^2] = E[k(k-1)] + E[k] = n(n-1)p^2 + np = n^2p^2 - np^2 + np$$\nNow we can find $E[\\hat{p}^2]$:\n$$E[\\hat{p}^2] = \\frac{1}{n^2} (n^2p^2 - np^2 + np) = p^2 - \\frac{p^2}{n} + \\frac{p}{n}$$\nFinally, we substitute $E[\\hat{p}]$ and $E[\\hat{p}^2]$ into the variance formula:\n$$\\mathrm{Var}(\\hat{p}) = E[\\hat{p}^2] - (E[\\hat{p}])^2 = \\left(p^2 - \\frac{p^2}{n} + \\frac{p}{n}\\right) - p^2$$\n$$\\mathrm{Var}(\\hat{p}) = \\frac{p}{n} - \\frac{p^2}{n}$$\nFactoring this expression yields the final result:\n$$\\mathrm{Var}(\\hat{p}) = \\frac{p(1-p)}{n}$$\nThis is the exact variance of the observed heteroplasmy fraction $\\hat{p}$ under the Binomial sampling model.", "answer": "$$\\boxed{\\frac{p(1-p)}{n}}$$", "id": "4360571"}, {"introduction": "Beyond random sampling error, systematic biases can severely compromise the accuracy of heteroplasmy quantification, with allele-specific PCR amplification being a primary culprit. This practice challenges you to mathematically model how differential amplification efficiencies skew the observed allele fraction and to critically evaluate modern solutions like Unique Molecular Identifiers (UMIs) [@problem_id:4360603]. Understanding these dynamics is essential for designing and interpreting high-fidelity quantitative assays.", "problem": "A clinical mitochondrial genome assay aims to quantify heteroplasmy at a single nucleotide variant in mitochondrial DNA. Let the true per-molecule variant allele fraction be $p \\in (0,1)$ among $N$ original double-stranded mitochondrial genomes extracted from a single sample. Library preparation uses polymerase chain reaction (PCR) with $c$ cycles. Due to sequence-context effects, the per-cycle amplification efficiencies differ between the variant allele and the reference allele; let these per-cycle efficiencies be $e_{V}$ and $e_{R}$, respectively, and assume they are constant across cycles. Sequencing samples amplicons uniformly at random from the post-PCR pool to produce reads. The observed variant read fraction is $\\hat{p} = R_{V}/(R_{V}+R_{R})$, where $R_{V}$ and $R_{R}$ are variant and reference read counts.\n\nStarting from the following fundamentals:\n- PCR is a branching process where, in each cycle, the expected copy number of a template is multiplied by its per-cycle efficiency.\n- Random sampling of molecules without allelic bias implies that the expected read fraction equals the fraction of molecules in the library prior to sampling.\n- A Unique Molecular Identifier (UMI) is a random barcode ligated to each original molecule before amplification; deduplicating reads by UMI collapses all reads from the same original molecule to a single consensus, so counts reflect the number of distinct captured templates rather than the number of PCR products.\n\nDerive, from these principles and without invoking any unproven shortcut formulas, how allele-specific PCR efficiency skews $\\hat{p}$ away from $p$ as a function of $c$, $e_{V}$, and $e_{R}$. Then consider the use of Unique Molecular Identifiers (UMIs) to correct PCR-induced bias by collapsing duplicates. Assume negligible UMI collisions and no allelic mapping bias.\n\nWhich of the following statements are correct? Select all that apply.\n\nA. If $\\rho = e_{V}/e_{R}$ is the per-cycle relative efficiency, then under large post-PCR molecule counts and unbiased read sampling,\n$$\n\\mathbb{E}[\\hat{p}] \\;=\\; \\frac{p\\,\\rho^{c}}{(1-p) + p\\,\\rho^{c}}.\n$$\n\nB. Under allele-specific efficiency, the expected read fraction is linear in the relative amplification, so\n$$\n\\mathbb{E}[\\hat{p}] \\;=\\; p\\,\\rho^{c},\n$$\nand no normalization by the reference allele is required.\n\nC. Increasing the total read depth to infinity eliminates PCR amplification bias, so $\\lim_{D\\to\\infty}\\mathbb{E}[\\hat{p}\\,|\\,\\text{depth}=D]=p$ even if $\\rho \\neq 1$.\n\nD. Deduplicating with UMIs can correct PCR bias only if UMIs are attached after PCR, because the bias must be observed before it can be removed.\n\nE. If the numbers of captured original variant and reference molecules are independent Poisson random variables with means $\\lambda p$ and $\\lambda(1-p)$, respectively, then deduplication by UMIs yields the estimator $\\tilde{p}=U_{V}/(U_{V}+U_{R})$, which is unbiased for $p$ conditional on $U_{V}+U_{R}0$ when $\\rho \\neq 1$, but has larger variance than $\\hat{p}$ because $U_{V}+U_{R}$ is typically much smaller than $R_{V}+R_{R}$.\n\nF. If $\\rho$ is known, a debiased estimator of $p$ based on the observed read fraction is\n$$\n\\tilde{p} \\;=\\; \\frac{\\hat{p}}{\\rho^{c}(1-\\hat{p}) + \\hat{p}},\n$$\nwhich is consistent for $p$ as the number of unique molecules grows, assuming equal pre-PCR capture probabilities for the two alleles and no allelic mapping bias.", "solution": "The problem statement will first be validated for scientific and logical soundness.\n\n### Step 1: Extract Givens\nThe givens from the problem statement are:\n- True per-molecule variant allele fraction: $p \\in (0,1)$.\n- Number of original double-stranded mitochondrial genomes: $N$.\n- Number of PCR cycles: $c$.\n- Per-cycle amplification efficiency for the variant allele: $e_V$.\n- Per-cycle amplification efficiency for the reference allele: $e_R$.\n- The efficiencies $e_V$ and $e_R$ are constant across cycles.\n- Observed variant read fraction: $\\hat{p} = R_{V}/(R_{V}+R_{R})$, where $R_V$ and $R_R$ are variant and reference read counts, respectively.\n- Fundamental Principle 1: PCR is a branching process where, in each cycle, the expected copy number of a template is multiplied by its per-cycle efficiency.\n- Fundamental Principle 2: Random sampling of molecules without allelic bias implies that the expected read fraction equals the fraction of molecules in the library prior to sampling.\n- Fundamental Principle 3: A Unique Molecular Identifier (UMI) is a random barcode ligated to each original molecule before amplification. Deduplicating reads by UMI collapses all reads from the same original molecule to a single consensus, so counts reflect the number of distinct captured templates.\n- Assumptions for the UMI part: Negligible UMI collisions and no allelic mapping bias.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes a standard, albeit simplified, model of quantitative next-generation sequencing (NGS), specifically addressing the issue of PCR amplification bias and its correction using either computational methods or UMIs.\n\n- **Scientifically Grounded:** The model is firmly based on established principles of molecular biology (PCR) and biostatistics (sampling theory). The concept of allele-specific PCR efficiency is a well-documented phenomenon in real-world assays. The use of UMIs to mitigate this bias is a cornerstone of modern quantitative sequencing. The model is a valid and widely used simplification of a real-world process.\n- **Well-Posed:** The problem is clearly stated. It asks for a derivation based on provided first principles and then an evaluation of specific statements based on that derivation. It provides all necessary variables and definitions to proceed. A unique mathematical relationship between the quantities can be derived.\n- **Objective:** The language is formal, technical, and devoid of subjectivity or bias. All terms are either standard in the field or explicitly defined.\n\nThe problem statement is free from the flaws listed in the instructions. It is scientifically sound, well-posed, and objective.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\n### Derivation from First Principles\n\nLet's derive the relationship between the true allele fraction $p$ and the expected observed read fraction $\\mathbb{E}[\\hat{p}]$ without UMIs.\n\n$1$. **Initial state:** We start with $N$ total molecules from a single sample. The number of variant molecules is $N_V = pN$ and the number of reference molecules is $N_R = (1-p)N$.\n\n$2$. **PCR Amplification:** According to Fundamental Principle 1, PCR acts as a branching process. After one cycle, the expected number of variant molecules is $(pN) \\cdot e_V$ and reference molecules is $((1-p)N) \\cdot e_R$. After $c$ cycles, assuming constant efficiency, the expected number of molecules for each allele is:\n$$ \\mathbb{E}[\\text{Number of variant molecules post-PCR}] = N_{V, post} = (pN) \\cdot (e_V)^c $$\n$$ \\mathbb{E}[\\text{Number of reference molecules post-PCR}] = N_{R, post} = ((1-p)N) \\cdot (e_R)^c $$\n\n$3$. **Post-PCR Molecular Fraction:** The fraction of variant molecules in the post-PCR library, let's call it $p'$, is the ratio of the expected number of variant molecules to the total expected number of molecules.\n$$ p' = \\frac{N_{V, post}}{N_{V, post} + N_{R, post}} = \\frac{(pN)(e_V)^c}{(pN)(e_V)^c + ((1-p)N)(e_R)^c} $$\nThe initial number of molecules, $N$, cancels out:\n$$ p' = \\frac{p(e_V)^c}{p(e_V)^c + (1-p)(e_R)^c} $$\n\n$4$. **Sequencing and Read Fraction:** According to Fundamental Principle 2, uniform random sampling of amplicons means the expected value of the observed read fraction $\\hat{p}$ is equal to the molecular fraction $p'$ in the library being sequenced.\n$$ \\mathbb{E}[\\hat{p}] = p' = \\frac{p(e_V)^c}{p(e_V)^c + (1-p)(e_R)^c} $$\n\n$5$. **Using Relative Efficiency:** Let the per-cycle relative efficiency be $\\rho = e_V/e_R$. We can divide the numerator and denominator of the expression for $\\mathbb{E}[\\hat{p}]$ by $(e_R)^c$:\n$$ \\mathbb{E}[\\hat{p}] = \\frac{p \\frac{(e_V)^c}{(e_R)^c}}{p \\frac{(e_V)^c}{(e_R)^c} + (1-p) \\frac{(e_R)^c}{(e_R)^c}} = \\frac{p \\left(\\frac{e_V}{e_R}\\right)^c}{p \\left(\\frac{e_V}{e_R}\\right)^c + (1-p)} = \\frac{p\\rho^c}{(1-p) + p\\rho^c} $$\nThis completes the required derivation. Now, we evaluate the options.\n\n### Option-by-Option Analysis\n\n**A. If $\\rho = e_{V}/e_{R}$ is the per-cycle relative efficiency, then under large post-PCR molecule counts and unbiased read sampling,  $\\mathbb{E}[\\hat{p}] \\;=\\; \\frac{p\\,\\rho^{c}}{(1-p) + p\\,\\rho^{c}}$.**\n\nThis statement presents the exact formula derived from first principles. The condition of \"large post-PCR molecule counts and unbiased read sampling\" formally justifies equating the expected read fraction with the fraction of molecules in the amplified library, consistent with Fundamental Principle 2 and the law of large numbers.\n\nVerdict: **Correct**.\n\n**B. Under allele-specific efficiency, the expected read fraction is linear in the relative amplification, so $\\mathbb{E}[\\hat{p}] \\;=\\; p\\,\\rho^{c},$ and no normalization by the reference allele is required.**\n\nThis statement claims $\\mathbb{E}[\\hat{p}] = p\\rho^c$. As shown in the derivation, the correct expression is $\\mathbb{E}[\\hat{p}] = \\frac{p\\rho^c}{(1-p) + p\\rho^c}$. The denominator, $(1-p) + p\\rho^c$, is a crucial normalization term that ensures the result is a fraction between $0$ and $1$. The expression $p\\rho^c$ can exceed $1$ (for instance, if $p=0.5$ and $\\rho=1.2$, $c=10$, then $\\rho^c \\approx 6.19$ and $p\\rho^c  3$), which is nonsensical for a fraction. The claim is therefore mathematically incorrect.\n\nVerdict: **Incorrect**.\n\n**C. Increasing the total read depth to infinity eliminates PCR amplification bias, so $\\lim_{D\\to\\infty}\\mathbb{E}[\\hat{p}\\,|\\,\\text{depth}=D]=p$ even if $\\rho \\neq 1$.**\n\nIncreasing the total read depth, $D = R_V + R_R$, reduces the random sampling error associated with sequencing the post-PCR library. As $D \\to \\infty$, the observed read fraction $\\hat{p}$ converges to its expected value, $\\mathbb{E}[\\hat{p}]$.\n$$ \\lim_{D\\to\\infty} \\hat{p} = \\mathbb{E}[\\hat{p}] = \\frac{p\\rho^c}{(1-p) + p\\rho^c} $$\nThe question asks if this limit equals the true fraction $p$. The expression equals $p$ if and only if $\\rho^c=1$ (which implies $\\rho=1$, since $c \\ge 1$), or for the trivial cases of $p=0$ or $p=1$, which are excluded by $p \\in (0,1)$. The problem specifies the case where $\\rho \\neq 1$. Therefore, increasing read depth does not correct the *systematic bias* introduced by PCR; it merely ensures the observed fraction accurately reflects the *biased* composition of the amplified library.\n\nVerdict: **Incorrect**.\n\n**D. Deduplicating with UMIs can correct PCR bias only if UMIs are attached after PCR, because the bias must be observed before it can be removed.**\n\nThis statement misrepresents the correctional mechanism of UMIs. According to Fundamental Principle 3, UMIs are ligated to each *original* molecule *before* amplification. This ensures that every molecule produced from a single original template carries the same unique barcode. When reads are deduplicated by UMI, all reads originating from one initial molecule are collapsed into a single count. This means the final count reflects the number of *original molecules captured*, not the number of PCR products. This process *prevents* the amplification bias from affecting the final quantification. If UMIs were attached *after* PCR, they would tag molecules from the already-biased pool, rendering them useless for bias correction. The reasoning \"bias must be observed before it can be removed\" is fallacious; UMIs work by preventing the measurement of the bias in the first place.\n\nVerdict: **Incorrect**.\n\n**E. If the numbers of captured original variant and reference molecules are independent Poisson random variables with means $\\lambda p$ and $\\lambda(1-p)$, respectively, then deduplication by UMIs yields the estimator $\\tilde{p}=U_{V}/(U_{V}+U_{R})$, which is unbiased for $p$ conditional on $U_{V}+U_{R}0$ when $\\rho \\neq 1$, but has larger variance than $\\hat{p}$ because $U_{V}+U_{R}$ is typically much smaller than $R_{V}+R_{R}$.**\n\nThis statement correctly describes both the benefit and the drawback of using UMIs.\n- **Unbiasedness:** After UMI deduplication, the counts $U_V$ and $U_R$ represent the number of *original* variant and reference molecules that were captured and sequenced. The differential amplification characterized by $\\rho \\neq 1$ has no effect on these counts. Modeling the capture process with independent Poisson variables $U_V \\sim \\text{Pois}(\\lambda p)$ and $U_R \\sim \\text{Pois}(\\lambda(1-p))$ is a standard approach. Given a total number of unique molecules $U_V + U_R = k$, the conditional distribution of $U_V$ is Binomial, $U_V | (U_V+U_R=k) \\sim \\text{Bin}(k, \\frac{\\lambda p}{\\lambda p + \\lambda(1-p)} = p)$. The conditional expectation is $\\mathbb{E}[\\tilde{p} | U_V+U_R=k] = \\mathbb{E}[U_V/k | U_V+U_R=k] = (1/k) \\cdot (kp) = p$. By the law of total expectation, the estimator $\\tilde{p}$ is unbiased for $p$.\n- **Variance:** The estimator $\\hat{p}$ without UMIs is based on the total number of reads, $R_V + R_R$, which is typically very large. The estimator $\\tilde{p}$ is based on the total number of unique molecules, $U_V + U_R$. In most NGS experiments, there is significant amplification, so $R_V+R_R \\gg U_V+U_R$. The variance of a proportion estimator is inversely proportional to the sample size. Therefore, $\\tilde{p}$, while unbiased, has higher sampling variance than the biased estimator $\\hat{p}$ because it is based on a much smaller effective sample size. This trade-off (removing bias at the cost of increasing variance) is a fundamental concept in this field.\n\nVerdict: **Correct**.\n\n**F. If $\\rho$ is known, a debiased estimator of $p$ based on the observed read fraction is $\\tilde{p} \\;=\\; \\frac{\\hat{p}}{\\rho^{c}(1-\\hat{p}) + \\hat{p}},$ which is consistent for $p$ as the number of unique molecules grows, assuming equal pre-PCR capture probabilities for the two alleles and no allelic mapping bias.**\n\nThis statement proposes a computational method to correct for PCR bias. We can check the formula by algebraically inverting the relationship between $p$ and $\\mathbb{E}[\\hat{p}]$. Let $P = \\mathbb{E}[\\hat{p}]$. We have:\n$$ P = \\frac{p\\rho^c}{1-p+p\\rho^c} $$\n$$ P(1-p+p\\rho^c) = p\\rho^c $$\n$$ P - Pp + Pp\\rho^c = p\\rho^c $$\n$$ P = p\\rho^c - Pp\\rho^c + Pp = p(\\rho^c(1-P) + P) $$\n$$ p = \\frac{P}{\\rho^c(1-P) + P} $$\nIf we have a consistent estimator for $P$ (the biased proportion), such as the observed read fraction $\\hat{p}$ from a very large number of reads, we can plug it into this formula to estimate $p$. The formula provided for $\\tilde{p}$ is a direct application of this algebraic inversion, with $\\hat{p}$ substituted for $P$. An estimator is consistent if it converges in probability to the true parameter value as the sample size increases. As the amount of data (molecules and reads) grows, $\\hat{p}$ converges to $P = \\mathbb{E}[\\hat{p}]$. Since the formula is a continuous function of $P$ (for $P \\in [0,1], \\rho^c  0$), the estimator $\\tilde{p}$ will converge to the true value $p$. Thus, it is a consistent estimator.\n\nVerdict: **Correct**.", "answer": "$$\\boxed{AEF}$$", "id": "4360603"}, {"introduction": "Contamination from Nuclear Mitochondrial DNA Segments (NUMTs) presents a major challenge in mitochondrial genomics, as they can be misidentified as true mitochondrial variants and confound heteroplasmy estimates. This problem places you in the role of a clinical scientist tasked with evaluating two different mtDNA enrichment strategies based on their ability to suppress NUMT-derived signals [@problem_id:4360549]. You will use data from synthetic spike-in controls to quantify and compare the risk of artifacts, a core skill in assay validation and quality control.", "problem": "A clinical genomics laboratory is comparing two mitochondrial DNA (mtDNA) enrichment strategies for heteroplasmy assessment: hybridization capture with tiling baits and long-range polymerase chain reaction (lrPCR). The central concern is contamination by nuclear mitochondrial DNA segments (NUMTs), which can distort low-frequency variant estimates. The lab will use synthetic spike-ins to calibrate method-specific efficiencies and quantify residual NUMT risk. The following well-tested facts and definitions are used as the fundamental base for the derivation:\n\n- Nuclear mitochondrial DNA segments (NUMTs) are fragments of mtDNA integrated into the nuclear genome; they can hybridize to mtDNA baits and, in some cases, be amplified if primer sites are present.\n- In hybridization capture, the expected yield of a target class is proportional to its target abundance and capture efficiency. Let $T$ denote the effective target abundance (e.g., base pairs homologous to the baits multiplied by copy number) and $e$ denote the method-specific efficiency; the expected captured signal from a class is proportional to $e \\cdot T$.\n- In long-range polymerase chain reaction (lrPCR), successful amplification requires primers to anneal at both ends of a long segment and that the intervening sequence be present contiguously. NUMTs are typically fragmented and incomplete; their probability of amplifying a full-length mtDNA product is therefore very low.\n- For rare-event counts, sequencing read counts are well modeled by a Poisson process. If $k=0$ events are observed, the $95\\%$ upper bound on the mean $\\lambda$ satisfies $e^{-\\lambda} = 0.05$, giving $\\lambda_{95\\%} \\approx 3$.\n\nAssume a human sample where the diploid nuclear genome has length $L_{\\mathrm{nuc}} = 6.4 \\times 10^{9}$ base pairs and the mtDNA length is $L_{\\mathrm{mt}} = 1.66 \\times 10^{4}$ base pairs. The tissue has an average mtDNA copy number per cell $c_{\\mathrm{mt}} = 2000$. The total nuclear content includes NUMT fragments homologous to the mtDNA baits with aggregate length fraction $p_{\\mathrm{NUMT}} = 5 \\times 10^{-4}$ of $L_{\\mathrm{nuc}}$.\n\nDefine the effective target abundances per cell:\n$$\nT_{\\mathrm{mt}} = c_{\\mathrm{mt}} \\cdot L_{\\mathrm{mt}}, \\quad T_{\\mathrm{NUMT}} = p_{\\mathrm{NUMT}} \\cdot L_{\\mathrm{nuc}}.\n$$\n\nThe lab adds two synthetic spike-ins before enrichment: an mtDNA-like control $S_{\\mathrm{M}}$ and a NUMT-like control $S_{\\mathrm{N}}$, each at equal molecule count. After library preparation and sequencing:\n\n- In the capture library, the total aligned reads to targets is $R_{\\mathrm{cap}} = 2{,}000{,}000$, with reads mapping to $S_{\\mathrm{M}}$ equal to $r_{M,\\mathrm{cap}} = 30{,}000$ and to $S_{\\mathrm{N}}$ equal to $r_{N,\\mathrm{cap}} = 15{,}000$.\n- In the lrPCR library, the total aligned reads to targets is $R_{\\mathrm{lr}} = 2{,}000{,}000$, with reads mapping to $S_{\\mathrm{M}}$ equal to $r_{M,\\mathrm{lr}} = 60{,}000$ and to $S_{\\mathrm{N}}$ equal to $r_{N,\\mathrm{lr}} = 0$.\n\nAssume read yield from a spike-in is proportional to its molecule count times a method-specific efficiency for its class; because $S_{\\mathrm{M}}$ and $S_{\\mathrm{N}}$ are added at equal molecule counts, the ratio of their observed reads estimates the efficiency ratio for the two classes within a method. Use these data and facts to:\n\n1. Derive from first principles the expected NUMT contamination fraction in the capture library,\n$$\nf_{\\mathrm{NUMT,cap}} = \\frac{e_{\\mathrm{NUMT,cap}} \\cdot T_{\\mathrm{NUMT}}}{e_{\\mathrm{NUMT,cap}} \\cdot T_{\\mathrm{NUMT}} + e_{\\mathrm{mt,cap}} \\cdot T_{\\mathrm{mt}}},\n$$\nand compute its numerical value.\n\n2. Using the Poisson $95\\%$ upper bound for zero observed NUMT-like spike-in reads in the lrPCR library, derive an upper bound on the efficiency ratio $\\rho_{\\mathrm{lr}} = \\frac{e_{\\mathrm{NUMT,lr}}}{e_{\\mathrm{mt,lr}}}$ and then the corresponding $95\\%$ upper bound on the NUMT contamination fraction in the lrPCR library,\n$$\nf_{\\mathrm{NUMT,lr}} \\le \\frac{\\rho_{\\mathrm{lr}} \\cdot T_{\\mathrm{NUMT}}}{\\rho_{\\mathrm{lr}} \\cdot T_{\\mathrm{NUMT}} + T_{\\mathrm{mt}}}.\n$$\n\n3. Briefly interpret the implications for false heteroplasmy calls at a $1\\%$ detection threshold.\n\nWhich option gives the correct quantitative analysis and interpretation?\n\nA. $f_{\\mathrm{NUMT,cap}} \\approx 4.6\\%$ and $f_{\\mathrm{NUMT,lr}} \\lesssim 4.8 \\times 10^{-6}$, implying roughly a $10^{4}$-fold reduction in NUMT contamination with lrPCR; residual NUMT-induced heteroplasmy above $1\\%$ is negligible.\n\nB. $f_{\\mathrm{NUMT,cap}} \\approx 0.5\\%$ because $e_{\\mathrm{NUMT,cap}}/e_{\\mathrm{mt,cap}} = 0.5$, and $f_{\\mathrm{NUMT,lr}} \\lesssim 5 \\times 10^{-3}$; lrPCR yields only an approximately $10$-fold improvement, so false heteroplasmy near $1\\%$ remains likely.\n\nC. $f_{\\mathrm{NUMT,cap}} \\approx 9.6\\%$ by taking $T_{\\mathrm{NUMT}}/T_{\\mathrm{mt}}$ alone, and $f_{\\mathrm{NUMT,lr}} = 0$ because $r_{N,\\mathrm{lr}} = 0$; lrPCR completely eliminates NUMT risk.\n\nD. $f_{\\mathrm{NUMT,cap}} \\approx 4.6\\%$, but $f_{\\mathrm{NUMT,lr}} \\lesssim \\frac{3}{2{,}000{,}000} \\approx 1.5 \\times 10^{-6}$ using the Poisson bound over total reads; lrPCR reduces NUMT contamination by about $3 \\times 10^{4}$-fold and residual risk at $1\\%$ is negligible.", "solution": "The user has provided a problem requiring a quantitative comparison of two mtDNA enrichment methods, hybridization capture and long-range PCR (lrPCR), with respect to contamination by nuclear mitochondrial DNA segments (NUMTs).\n\n### Problem Validation\n\nFirst, the validity of the problem statement must be established.\n\n#### Step 1: Extract Givens\n\n- **Constants and Data**:\n  - Diploid nuclear genome length: $L_{\\mathrm{nuc}} = 6.4 \\times 10^{9}$ base pairs\n  - mtDNA length: $L_{\\mathrm{mt}} = 1.66 \\times 10^{4}$ base pairs\n  - Average mtDNA copy number per cell: $c_{\\mathrm{mt}} = 2000$\n  - Aggregate length fraction of NUMTs in nuclear genome: $p_{\\mathrm{NUMT}} = 5 \\times 10^{-4}$\n\n- **Definitions**:\n  - Effective target abundance of mtDNA per cell: $T_{\\mathrm{mt}} = c_{\\mathrm{mt}} \\cdot L_{\\mathrm{mt}}$\n  - Effective target abundance of NUMTs per cell: $T_{\\mathrm{NUMT}} = p_{\\mathrm{NUMT}} \\cdot L_{\\mathrm{nuc}}$\n\n- **Principles and Models**:\n  - The expected captured signal from a target class is proportional to $e \\cdot T$, where $e$ is capture efficiency and $T$ is effective target abundance.\n  - For zero observed events ($k=0$) in a Poisson process, the $95\\%$ upper bound on the mean $\\lambda$ is given by $e^{-\\lambda} = 0.05$, which yields $\\lambda_{95\\%} \\approx 3$.\n  - Spike-ins $S_{\\mathrm{M}}$ (mtDNA-like) and $S_{\\mathrm{N}}$ (NUMT-like) are added at equal molecule counts. The ratio of their observed reads estimates the ratio of efficiencies for their respective classes.\n\n- **Experimental Data**:\n  - **Hybridization Capture Library**:\n    - Total reads: $R_{\\mathrm{cap}} = 2{,}000{,}000$\n    - Reads for $S_{\\mathrm{M}}$: $r_{M,\\mathrm{cap}} = 30{,}000$\n    - Reads for $S_{\\mathrm{N}}$: $r_{N,\\mathrm{cap}} = 15{,}000$\n  - **lrPCR Library**:\n    - Total reads: $R_{\\mathrm{lr}} = 2{,}000{,}000$\n    - Reads for $S_{\\mathrm{M}}$: $r_{M,\\mathrm{lr}} = 60{,}000$\n    - Reads for $S_{\\mathrm{N}}$: $r_{N,\\mathrm{lr}} = 0$\n\n- **Tasks**:\n  1. Derive and compute the NUMT contamination fraction for capture, $f_{\\mathrm{NUMT,cap}}$.\n  2. Derive an upper bound on the NUMT contamination fraction for lrPCR, $f_{\\mathrm{NUMT,lr}}$.\n  3. Interpret the implications for false heteroplasmy calls at a $1\\%$ detection threshold.\n\n#### Step 2: Validate Using Extracted Givens\n\nThe problem is scientifically grounded in the fields of genomics and bioinformatics. The concepts of mtDNA, NUMTs, hybridization capture, lrPCR, and the use of spike-ins for quantitative normalization are standard and accurately described. The physical constants (genome sizes, copy numbers) are realistic. The statistical model (Poisson for rare counts) is appropriate for sequencing data analysis. The problem is well-posed, providing all necessary definitions, data, and models to arrive at a unique, meaningful solution. The language is objective and precise. No flaws from the validation checklist are present.\n\n#### Step 3: Verdict and Action\n\nThe problem statement is **valid**. A full solution will be derived.\n\n### Solution Derivation\n\nThe solution requires a three-part analysis as specified in the problem statement.\n\n#### 1. Analysis of Hybridization Capture\n\nFirst, we calculate the effective target abundances for mitochondrial DNA ($T_{\\mathrm{mt}}$) and NUMTs ($T_{\\mathrm{NUMT}}$) per cell.\n$$T_{\\mathrm{mt}} = c_{\\mathrm{mt}} \\cdot L_{\\mathrm{mt}} = 2000 \\cdot (1.66 \\times 10^{4} \\text{ bp}) = 3.32 \\times 10^{7} \\text{ bp}$$\n$$T_{\\mathrm{NUMT}} = p_{\\mathrm{NUMT}} \\cdot L_{\\mathrm{nuc}} = (5 \\times 10^{-4}) \\cdot (6.4 \\times 10^{9} \\text{ bp}) = 3.2 \\times 10^{6} \\text{ bp}$$\n\nNext, we estimate the ratio of efficiencies for capturing NUMT-like sequences versus mtDNA-like sequences. Since the spike-ins $S_{\\mathrm{M}}$ and $S_{\\mathrm{N}}$ were added in equal molar amounts, the ratio of their read counts directly reflects the ratio of their capture efficiencies.\n$$\n\\frac{e_{\\mathrm{NUMT,cap}}}{e_{\\mathrm{mt,cap}}} = \\frac{r_{N,\\mathrm{cap}}}{r_{M,\\mathrm{cap}}} = \\frac{15{,}000}{30{,}000} = 0.5\n$$\nLet this efficiency ratio be $\\rho_{\\mathrm{cap}} = 0.5$.\n\nThe expected NUMT contamination fraction, $f_{\\mathrm{NUMT,cap}}$, is the fraction of signal from NUMTs relative to the total signal from both NUMTs and mtDNA.\n$$\nf_{\\mathrm{NUMT,cap}} = \\frac{e_{\\mathrm{NUMT,cap}} \\cdot T_{\\mathrm{NUMT}}}{e_{\\mathrm{NUMT,cap}} \\cdot T_{\\mathrm{NUMT}} + e_{\\mathrm{mt,cap}} \\cdot T_{\\mathrm{mt}}}\n$$\nWe can divide the numerator and denominator by $e_{\\mathrm{mt,cap}}$ to express this in terms of the efficiency ratio $\\rho_{\\mathrm{cap}}$:\n$$\nf_{\\mathrm{NUMT,cap}} = \\frac{\\rho_{\\mathrm{cap}} \\cdot T_{\\mathrm{NUMT}}}{\\rho_{\\mathrm{cap}} \\cdot T_{\\mathrm{NUMT}} + T_{\\mathrm{mt}}}\n$$\nSubstituting the calculated values:\n$$\nf_{\\mathrm{NUMT,cap}} = \\frac{0.5 \\cdot (3.2 \\times 10^{6})}{0.5 \\cdot (3.2 \\times 10^{6}) + 3.32 \\times 10^{7}} = \\frac{1.6 \\times 10^{6}}{1.6 \\times 10^{6} + 3.32 \\times 10^{7}} = \\frac{1.6 \\times 10^{6}}{3.48 \\times 10^{7}} \\approx 0.045977\n$$\nThus, the NUMT contamination fraction in the capture library is approximately $4.6\\%$.\n$$f_{\\mathrm{NUMT,cap}} \\approx 4.6\\%$$\n\n#### 2. Analysis of Long-Range PCR\n\nFor the lrPCR method, we again use the spike-in controls to estimate the efficiency ratio $\\rho_{\\mathrm{lr}} = e_{\\mathrm{NUMT,lr}}/e_{\\mathrm{mt,lr}}$.\n$$\n\\rho_{\\mathrm{lr}} \\approx \\frac{r_{N,\\mathrm{lr}}}{r_{M,\\mathrm{lr}}} = \\frac{0}{60{,}000} = 0\n$$\nHowever, observing zero reads ($r_{N,\\mathrm{lr}}=0$) does not prove the true rate is zero. Following the problem's directive, we use the Poisson model to find a $95\\%$ upper bound on the expected number of reads for the NUMT-like spike-in, $\\lambda_{N}$. For an observation of $k=0$, the $95\\%$ upper bound is $\\lambda_{N,95\\%} \\approx 3$. The observed reads for the mtDNA-like spike-in, $r_{M,\\mathrm{lr}} = 60{,}000$, is a large number, so we can approximate its mean $\\lambda_M$ by this value.\n\nThe upper bound on the efficiency ratio, $\\rho_{\\mathrm{lr}, \\text{up}}$, is therefore:\n$$\n\\rho_{\\mathrm{lr}, \\text{up}} = \\frac{\\lambda_{N,95\\%}}{\\lambda_M} \\approx \\frac{3}{60{,}000} = \\frac{1}{20{,}000} = 5 \\times 10^{-5}\n$$\n\nNow we can calculate the $95\\%$ upper bound on the NUMT contamination fraction, $f_{\\mathrm{NUMT,lr}, \\text{up}}$. This is an increasing function of $\\rho_{\\mathrm{lr}}$, so we use $\\rho_{\\mathrm{lr}, \\text{up}}$.\n$$\nf_{\\mathrm{NUMT,lr}} \\le f_{\\mathrm{NUMT,lr}, \\text{up}} = \\frac{\\rho_{\\mathrm{lr}, \\text{up}} \\cdot T_{\\mathrm{NUMT}}}{\\rho_{\\mathrm{lr}, \\text{up}} \\cdot T_{\\mathrm{NUMT}} + T_{\\mathrm{mt}}}\n$$\nThe numerator is $\\rho_{\\mathrm{lr}, \\text{up}} \\cdot T_{\\mathrm{NUMT}} = (5 \\times 10^{-5}) \\cdot (3.2 \\times 10^{6}) = 160$.\nThe denominator is $\\rho_{\\mathrm{lr}, \\text{up}} \\cdot T_{\\mathrm{NUMT}} + T_{\\mathrm{mt}} = 160 + 3.32 \\times 10^{7} = 33{,}200{,}160$.\n$$\nf_{\\mathrm{NUMT,lr}, \\text{up}} = \\frac{160}{33{,}200{,}160} \\approx 4.819 \\times 10^{-6}\n$$\nThe upper bound on the NUMT contamination fraction in the lrPCR library is approximately $4.8 \\times 10^{-6}$, or $0.00048\\%$.\n\n#### 3. Interpretation\n\n- **Hybridization Capture**: The estimated NUMT contamination is $f_{\\mathrm{NUMT,cap}} \\approx 4.6\\%$. This is a substantial level of background noise. If a NUMT carries a sequence variant relative to the true mtDNA, this variant will appear in the sequencing data at a frequency of approximately $4.6\\%$. This makes it impossible to confidently call a true heteroplasmy at a $1\\%$ level, as the signal from the NUMT would completely obscure or mimic such a low-frequency variant.\n\n- **Long-Range PCR**: The NUMT contamination is bounded at $f_{\\mathrm{NUMT,lr}} \\lesssim 4.8 \\times 10^{-6}$ (or $0.00048\\%$). This level is orders of magnitude below the $1\\%$ detection threshold for heteroplasmy. Therefore, with lrPCR, the risk of a false heteroplasmy call at the $1\\%$ level due to NUMT contamination is negligible.\n\n- **Comparison**: The reduction in contamination is $f_{\\mathrm{NUMT,cap}} / f_{\\mathrm{NUMT,lr}, \\text{up}} \\approx 0.046 / (4.8 \\times 10^{-6}) \\approx 9580$, which is on the order of $10^4$. lrPCR provides approximately a $10,000$-fold improvement over this particular hybridization capture protocol in terms of rejecting NUMT artifacts.\n\n### Option-by-Option Analysis\n\n**A. $f_{\\mathrm{NUMT,cap}} \\approx 4.6\\%$ and $f_{\\mathrm{NUMT,lr}} \\lesssim 4.8 \\times 10^{-6}$, implying roughly a $10^{4}$-fold reduction in NUMT contamination with lrPCR; residual NUMT-induced heteroplasmy above $1\\%$ is negligible.**\n- The calculated value for $f_{\\mathrm{NUMT,cap}}$ is $\\approx 4.6\\%$. **Correct**.\n- The calculated upper bound for $f_{\\mathrm{NUMT,lr}}$ is $\\lesssim 4.8 \\times 10^{-6}$. **Correct**.\n- The reduction factor is on the order of $10^4$. **Correct**.\n- The interpretation that risk to a $1\\%$ call is negligible for lrPCR is correct, as $4.8 \\times 10^{-6} \\ll 0.01$. The wording \"heteroplasmy above 1% is negligible\" is slightly awkward but conveys the correct conclusion. **Correct**.\nThis option aligns perfectly with our derivation.\n\n**B. $f_{\\mathrm{NUMT,cap}} \\approx 0.5\\%$ because $e_{\\mathrm{NUMT,cap}}/e_{\\mathrm{mt,cap}} = 0.5$, and $f_{\\mathrm{NUMT,lr}} \\lesssim 5 \\times 10^{-3}$; lrPCR yields only an approximately $10$-fold improvement, so false heteroplasmy near $1\\%$ remains likely.**\n- The claim $f_{\\mathrm{NUMT,cap}} \\approx 0.5\\%$ is incorrect. It appears to mistakenly equate the final contamination fraction with the efficiency ratio. Our calculation yielded $4.6\\%$. **Incorrect**.\n- The claimed bound $f_{\\mathrm{NUMT,lr}} \\lesssim 5 \\times 10^{-3}$ is incorrect. Our calculation yielded $\\approx 4.8 \\times 10^{-6}$, which is three orders of magnitude smaller. **Incorrect**.\n- The claimed $10$-fold improvement is derived from their faulty numbers and is also incorrect. **Incorrect**.\n\n**C. $f_{\\mathrm{NUMT,cap}} \\approx 9.6\\%$ by taking $T_{\\mathrm{NUMT}}/T_{\\mathrm{mt}}$ alone, and $f_{\\mathrm{NUMT,lr}} = 0$ because $r_{N,\\mathrm{lr}} = 0$; lrPCR completely eliminates NUMT risk.**\n- The value $f_{\\mathrm{NUMT,cap}} \\approx 9.6\\%$ is incorrect. This value corresponds to $T_{\\mathrm{NUMT}}/T_{\\mathrm{mt}} \\approx 0.096$ but fails to account for the capture efficiency difference ($\\rho_{\\mathrm{cap}}=0.5$), which is a critical part of the model. **Incorrect**.\n- The claim $f_{\\mathrm{NUMT,lr}} = 0$ is statistically naive. Observing zero events in a finite sample does not prove the true rate is zero. The problem explicitly provides a method (Poisson bound) to handle this, which this option ignores. **Incorrect**.\n\n**D. $f_{\\mathrm{NUMT,cap}} \\approx 4.6\\%$, but $f_{\\mathrm{NUMT,lr}} \\lesssim \\frac{3}{2{,}000{,}000} \\approx 1.5 \\times 10^{-6}$ using the Poisson bound over total reads; lrPCR reduces NUMT contamination by about $3 \\times 10^{4}$-fold and residual risk at $1\\%$ is negligible.**\n- The value $f_{\\mathrm{NUMT,cap}} \\approx 4.6\\%$ is correct. **Correct**.\n- The calculation for the upper bound of $f_{\\mathrm{NUMT,lr}}$ is flawed. It uses the total read count $R_{\\mathrm{lr}}$ as the denominator for the Poisson bound on the NUMT-like spike-in fraction. The correct reference is the read count of the corresponding mtDNA-like spike-in ($r_{M,\\mathrm{lr}} = 60{,}000$), not the total reads. This is because the efficiency ratio must be estimated by comparing like with like (spike-in to spike-in). Using the total reads as a reference is not what was specified or implied by the model. This leads to an incorrect upper bound for the efficiency ratio and thus an incorrect upper bound for the final contamination fraction. **Incorrect**.\n\nBased on the analysis, only option A presents a fully correct derivation and interpretation.", "answer": "$$\\boxed{A}$$", "id": "4360549"}]}