{"hands_on_practices": [{"introduction": "This problem addresses the most fundamental challenge in resolving complex genomic rearrangements: the physical requirement of spanning the entire altered structure with a single, contiguous sequencing read. This exercise asks you to derive the minimum read length needed to not only cover a series of rearranged segments but also to anchor the read confidently to the reference genome [@problem_id:4377786]. By working through this calculation, you will gain a concrete understanding of why long-read sequencing is not just an incremental improvement but a technological necessity for studying complex structural variants.", "problem": "A complex structural variant affecting a cancer driver gene is represented as an alternating sequence of junctions (breakpoints) and inter-junction intervals along the rearranged haplotype. Let there be $k$ junctions crossed by a single contiguous path, and let the $k$ inter-junction intervals along this path have lengths $d_1, d_2, \\dots, d_k$ in base pairs. A single long read from Single Molecule Real-Time sequencing (SMRT) or Oxford Nanopore Technologies must span this entire path to enable resolution of the rearrangement in a clinical genomic diagnostics setting.\n\nFoundational base:\n- A breakpoint is a junction between two genomic loci; its geometric extent is negligible compared to interval lengths and is treated as a point.\n- A long read of length $L$ covers a contiguous sequence and, to be confidently aligned, must contain at least $u$ bases of uniquely mappable flanking sequence at its left end and at its right end, where $u$ is the minimal unique-seed length required by the alignment process (for example, the minimal $k$-mer seeding length that achieves reliable uniqueness under the aligner’s error tolerance).\n- Within the read, each internal breakpoint must be embedded between sufficient sequence on its left and right to be observed, but those bases come from the inter-junction intervals that the read already spans.\n\nStarting only from these base facts and definitions, derive an analytic expression for the minimum read length $L_{\\min}$ that is necessary and sufficient to span the entire rearrangement path and enable confident alignment of the read’s ends. Then, using your derived expression, compute $L_{\\min}$ for the case\n$$\nk = 5, \\quad (d_1, d_2, d_3, d_4, d_5) = (2400,\\ 13150,\\ 820,\\ 29900,\\ 412)\\ \\text{bp}, \\quad u = 150\\ \\text{bp}.\n$$\nAssume the interval lengths are large enough that each internal breakpoint is flanked by at least $u$ bases on both sides within the read. Express the final length in base pairs (bp). Provide the exact integer number of base pairs; do not round.", "solution": "The user wants me to solve the following problem.\n\nThe problem asks for the derivation of an analytic expression for the minimum read length, $L_{\\min}$, necessary to fully resolve a complex genomic rearrangement and to apply this expression to a specific case.\n\nFirst, a validation of the problem statement is performed.\n\n### Step 1: Extract Givens\n- Number of junctions crossed: $k$.\n- Number of inter-junction intervals: $k$, with lengths $d_1, d_2, \\dots, d_k$.\n- Minimal unique-seed length for alignment: $u$.\n- A read must contain at least $u$ bases of flanking sequence at its left and right ends.\n- Assumption: Interval lengths are large enough that each internal breakpoint is flanked by at least $u$ bases on both sides within the read.\n- Specific values for computation: $k = 5$, $(d_1, d_2, d_3, d_4, d_5) = (2400, 13150, 820, 29900, 412)$ base pairs (bp), and $u = 150$ bp.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the principles of long-read sequencing and structural variant analysis. The terminology and concepts are standard in the field of genomics. The problem is objective and formalizable.\n\nA minor ambiguity exists in the problem statement. It specifies \"$k$ junctions crossed\" and \"$k$ inter-junction intervals\". A contiguous path formed by joining $k$ intervals end-to-end contains $k-1$ internal junctions (breakpoints). This suggests a slight linguistic imprecision. However, the problem consistently uses $k$ as the number of intervals, providing $k=5$ and a corresponding list of 5 interval lengths $(d_1, \\dots, d_5)$. The core of the problem depends on the total length of these intervals, not the number of junctions. Therefore, this ambiguity is deemed a non-fatal imprecision that does not prevent a unique and logical solution. The most reasonable interpretation is that the path is composed of $k$ distinct segments. The problem is otherwise self-contained, well-posed, and free of contradictions or scientifically unsound premises.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A solution will be derived.\n\n### Derivation of the Minimum Read Length, $L_{\\min}$\n\nThe problem requires determining the minimum length of a sequencing read, $L$, that can both span a complex structural variant and be aligned confidently to a reference genome.\n\nLet the rearranged genomic path be defined as a contiguous sequence formed by the concatenation of $k$ intervals of lengths $d_1, d_2, \\dots, d_k$. The junctions are treated as points of zero length. The total length of the sequence constituting the rearrangement, denoted by $D$, is the sum of the lengths of these intervals:\n$$D = \\sum_{i=1}^{k} d_i$$\n\nFor a read to resolve this structure, two conditions must be met:\n1.  The read must completely span the entire rearranged path of length $D$.\n2.  The read must be alignable. The problem states this requires the read to contain at least $u$ bases of uniquely mappable flanking sequence at its left end and at its right end. These flanking sequences are contiguous with the rearranged path but are not part of it.\n\nLet us model the rearranged path on a one-dimensional coordinate system. We can define the start of the path to be at coordinate $0$ and the end at coordinate $D$. The path thus occupies the interval $[0, D]$.\n- The left flanking region is the sequence at coordinates $x < 0$.\n- The right flanking region is the sequence at coordinates $x > D$.\n\nA sequencing read of length $L$ covers a contiguous interval of the genome. Let this interval be $[x_0, x_0 + L]$.\n\nTo satisfy the alignment condition, the read must capture at least $u$ bases from the left flanking region and $u$ bases from the right flanking region.\n- To capture $u$ bases from the left flank (region $x < 0$), the read must start at or before coordinate $-u$. This imposes the constraint $x_0 \\le -u$.\n- To capture $u$ bases from the right flank (region $x > D$), the read must end at or after coordinate $D + u$. This imposes the constraint $x_0 + L \\ge D + u$.\n\nThe read must also span the entire rearrangement path from coordinate $0$ to $D$. The two conditions above are stricter and automatically ensure the path is spanned. If $x_0 \\le -u$ and $x_0 + L \\ge D+u$, then the read interval $[x_0, x_0+L]$ necessarily contains $[0, D]$ since $u > 0$ and $D > 0$.\n\nWe seek the minimum read length, $L_{\\min}$. From the second constraint, we have:\n$$L \\ge D + u - x_0$$\nTo minimize $L$, we must maximize the value of $x_0$. From the first constraint, the maximum permissible value for $x_0$ is $-u$.\n\nSubstituting $x_0 = -u$ into the inequality for $L$:\n$$L \\ge D + u - (-u)$$\n$$L \\ge D + 2u$$\n\nThus, the minimum possible read length, $L_{\\min}$, that satisfies all conditions is:\n$$L_{\\min} = D + 2u$$\nSubstituting the expression for $D$:\n$$L_{\\min} = \\left(\\sum_{i=1}^{k} d_i\\right) + 2u$$\nThis expression represents the length of the rearranged sequence itself, plus the length of two minimal unique anchor sequences on both ends.\n\nThe problem includes the assumption that \"interval lengths are large enough that each internal breakpoint is flanked by at least $u$ bases on both sides within the read.\" Our derived minimum-length read, which covers the entirety of all intervals $d_1, \\dots, d_k$, will contain the full sequence of each interval. Thus, for a junction between intervals $d_i$ and $d_{i+1}$, the read will contain all of $d_i$ to the left of the junction and all of $d_{i+1}$ to the right. The assumption therefore simplifies to the condition that $d_i \\ge u$ for all $i$ corresponding to an interval that flanks an internal junction. This assumption ensures that the problem is well-defined and does not require a more complex model for breakpoint detection, but it does not alter the derivation of $L_{\\min}$ which is dictated by the requirements at the external ends of the entire rearranged path.\n\n### Calculation for the Specific Case\n\nWe are given the following values:\n- $k = 5$\n- $(d_1, d_2, d_3, d_4, d_5) = (2400, 13150, 820, 29900, 412)$ bp\n- $u = 150$ bp\n\nFirst, we calculate the total length of the rearranged path, $D$:\n$$D = \\sum_{i=1}^{5} d_i = d_1 + d_2 + d_3 + d_4 + d_5$$\n$$D = 2400 + 13150 + 820 + 29900 + 412$$\n$$D = 46682\\ \\text{bp}$$\n\nNext, we use the derived formula for $L_{\\min}$:\n$$L_{\\min} = D + 2u$$\n$$L_{\\min} = 46682 + 2 \\times 150$$\n$$L_{\\min} = 46682 + 300$$\n$$L_{\\min} = 46982\\ \\text{bp}$$\n\nThe minimum read length required is $46982$ base pairs.", "answer": "$$\\boxed{46982}$$", "id": "4377786"}, {"introduction": "Once a structural variant (SV) calling algorithm has been run, the critical next step is to evaluate its performance. This practice introduces the standard metrics used for benchmarking in genomics: precision, recall, and the $F_1$ score [@problem_id:4377762]. You will learn how to apply these concepts in a realistic setting where breakpoint coordinates from long reads have a margin of error, requiring a \"tolerant\" matching approach to assess accuracy against a truth set.", "problem": "A clinical genomics study aims to benchmark Structural Variant (SV) calling performance for resolving complex genomic rearrangements using long reads. A high-confidence truth set of $120$ SVs is curated from orthogonal assays and integrative curation. A long-read SV caller reports $110$ variant calls. Because long-read breakpoint estimates can vary slightly, a predicted call is considered a match to a truth SV if and only if the SV type is the same and each relevant breakpoint is within $\\pm 50$ base pairs (bp) of the truth breakpoint. For two-breakpoint SVs (for example, deletions and inversions), both breakpoints must satisfy the tolerance; for one-breakpoint SVs (for example, insertions), the single breakpoint must satisfy the same tolerance. A one-to-one bipartite matching between truth SVs and predicted SVs is constructed that maximizes the total number of matches under these rules.\n\nAfter matching, the aggregated confusion matrix counts are: true positives $TP = 84$, false positives $FP = 26$, and false negatives $FN = 36$.\n\nStarting from core definitions in binary classification, define precision, recall, and the $F_1$ score for SV benchmarking under the above tolerant matching paradigm in terms of $TP$, $FP$, and $FN$. Then compute the $F_1$ score for the given counts. Round your final numerical value to four significant figures. Express the final answer as a pure number without units.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n-   Number of Structural Variants (SVs) in the truth set: $120$.\n-   Number of SV calls from the long-read caller: $110$.\n-   Matching tolerance for breakpoints: $\\pm 50$ bp.\n-   True Positives ($TP$): $84$.\n-   False Positives ($FP$): $26$.\n-   False Negatives ($FN$): $36$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It describes a standard procedure for benchmarking genomic variant callers. The provided data is complete and internally consistent.\n\n-   The total number of actual positive cases (SVs in the truth set) is given as $120$. This must be equal to the sum of true positives (correctly identified true SVs) and false negatives (missed true SVs). Checking the data: $TP + FN = 84 + 36 = 120$. This is consistent.\n-   The total number of predicted positive cases (SVs called by the algorithm) is given as $110$. This must be equal to the sum of true positives (correctly made calls) and false positives (incorrectly made calls). Checking the data: $TP + FP = 84 + 26 = 110$. This is also consistent.\n\nThe problem is valid as it is free of scientific unsoundness, contradictions, ambiguity, or any other listed flaws. A complete solution can be derived from the provided information.\n\n**Solution Derivation**\nThe task is to define precision, recall, and the $F_1$ score in the context of binary classification, and then compute the $F_1$ score for the given data. These metrics are fundamental for evaluating the performance of a classification model, which in this case is the SV caller.\n\nA **True Positive ($TP$)** is an outcome where the model correctly predicts the positive class. Here, it is a called SV that matches a true SV. We are given $TP = 84$.\n\nA **False Positive ($FP$)** is an outcome where the model incorrectly predicts the positive class. Here, it is a called SV that does not match any true SV. We are given $FP = 26$. This corresponds to over-calling or spurious calls.\n\nA **False Negative ($FN$)** is an outcome where the model incorrectly predicts the negative class. Here, it is a true SV that was not detected by the caller. We are given $FN = 36$. This corresponds to lack of sensitivity.\n\n**1. Definition of Metrics**\n\n**Precision**: Precision, also known as the Positive Predictive Value (PPV), measures the fraction of positive predictions that are actually correct. It answers the question: \"Of all the SVs called by the algorithm, what proportion were real?\" It is defined as:\n$$ \\text{Precision} = \\frac{TP}{TP + FP} $$\n\n**Recall**: Recall, also known as Sensitivity or the True Positive Rate (TPR), measures the fraction of actual positives that were correctly identified. It answers the question: \"Of all the real SVs present in the sample, what proportion did the algorithm find?\" It is defined as:\n$$ \\text{Recall} = \\frac{TP}{TP + FN} $$\n\n**$F_1$ Score**: The $F_1$ score is the harmonic mean of precision and recall. It provides a single metric that balances both, which is particularly useful when the class distribution is uneven. The general formula for the harmonic mean of two numbers $a$ and $b$ is $2 / (\\frac{1}{a} + \\frac{1}{b})$. Therefore, the $F_1$ score is:\n$$ F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\nTo express the $F_1$ score directly in terms of $TP$, $FP$, and $FN$, we substitute the definitions of precision and recall:\n$$ F_1 = 2 \\cdot \\frac{\\left(\\frac{TP}{TP + FP}\\right) \\cdot \\left(\\frac{TP}{TP + FN}\\right)}{\\left(\\frac{TP}{TP + FP}\\right) + \\left(\\frac{TP}{TP + FN}\\right)} $$\nTo simplify, we find a common denominator for the sum in the denominator of the main fraction:\n$$ F_1 = 2 \\cdot \\frac{\\frac{TP^2}{(TP + FP)(TP + FN)}}{\\frac{TP(TP + FN) + TP(TP + FP)}{(TP + FP)(TP + FN)}} $$\nCanceling the common term $(TP + FP)(TP + FN)$ from the numerator and denominator:\n$$ F_1 = \\frac{2 \\cdot TP^2}{TP(TP + FN) + TP(TP + FP)} $$\nFactoring out $TP$ from the denominator:\n$$ F_1 = \\frac{2 \\cdot TP^2}{TP((TP + FN) + (TP + FP))} = \\frac{2 \\cdot TP}{TP + FN + TP + FP} $$\nThis simplifies to the canonical formula:\n$$ F_1 = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN} $$\n\n**2. Calculation of the $F_1$ Score**\n\nUsing the provided counts: $TP = 84$, $FP = 26$, and $FN = 36$. We substitute these values into the derived formula for the $F_1$ score.\n\n$$ F_1 = \\frac{2 \\cdot 84}{2 \\cdot 84 + 26 + 36} $$\n$$ F_1 = \\frac{168}{168 + 26 + 36} $$\n$$ F_1 = \\frac{168}{168 + 62} $$\n$$ F_1 = \\frac{168}{230} $$\nNow, we compute the numerical value:\n$$ F_1 = \\frac{168}{230} \\approx 0.73043478... $$\nThe problem requires rounding the final answer to four significant figures. The first four significant figures are $7$, $3$, $0$, and $4$. The fifth significant figure is $3$, which is less than $5$, so we round down.\n$$ F_1 \\approx 0.7304 $$", "answer": "$$\\boxed{0.7304}$$", "id": "4377762"}, {"introduction": "Beyond simply detecting the presence of a rearrangement, quantitative analysis—such as determining the precise copy number of a duplicated gene—requires rigorous statistical modeling. This exercise guides you through the process of deriving confidence intervals for copy number changes from overdispersed long-read count data [@problem_id:4377748]. You will apply the Negative Binomial distribution, a standard model for sequencing data, and use the Delta method to estimate the uncertainty of your findings, reflecting the sophisticated statistical reasoning used in clinical-grade genomic diagnostics.", "problem": "In a clinically validated long-read genomic sequencing pipeline for detecting copy-number changes associated with structural rearrangements, the genome is partitioned into equal-width windows, and the number of mapped long-read starts per window is counted. Motivated by the counting nature of sequencing and by empirically observed overdispersion in long-read coverage, consider the following generative model: for a given sample and a fixed genomic window, the observed count $X$ of mapped read starts is conditionally Poisson with a random rate $\\Lambda$, and the latent rate $\\Lambda$ varies across windows due to sequence-context and mapping heterogeneity. Specifically, let $X \\mid \\Lambda \\sim \\mathrm{Poisson}(\\Lambda)$ and $\\Lambda \\sim \\mathrm{Gamma}(r, b)$, where $r>0$ is the shape and $b>0$ is the scale. This Gamma–Poisson mixture leads to a marginal Negative Binomial (NB) distribution for $X$, and is widely used to model windowed read-depth in sequencing.\n\nA suspected duplication in a tumor sample is evaluated against its matched normal by aggregating counts over $k$ independent windows spanning the aberrant region. Let $S_{\\mathrm{T}}$ and $S_{\\mathrm{N}}$ denote the aggregated counts over the tumor and normal, respectively. Assume the tumor windows are identically distributed with mean per-window count $\\mu_{\\mathrm{T}}$ and dispersion parameter $\\alpha_{\\mathrm{T}}$, and the normal windows are identically distributed with mean per-window count $\\mu_{\\mathrm{N}}$ and dispersion parameter $\\alpha_{\\mathrm{N}}$. The dispersion parameter $\\alpha$ is defined such that the per-window marginal variance of the NB is larger than its mean in a way you will derive. Assume $S_{\\mathrm{T}}$ and $S_{\\mathrm{N}}$ are independent.\n\nYou are given the following empirically estimated quantities for a candidate duplication region: $k=50$ windows, $S_{\\mathrm{T}}=3750$, $S_{\\mathrm{N}}=2500$, $\\alpha_{\\mathrm{T}}=0.08$, and $\\alpha_{\\mathrm{N}}=0.05$.\n\nTasks:\n- Starting from the Poisson–Gamma mixture definition above and using the laws of total expectation and total variance, derive the marginal variance of a single-window NB read-count in terms of its mean $\\mu$ and dispersion $\\alpha$. Clearly state any parameter relationships you impose between $(r,b)$ and $(\\mu,\\alpha)$.\n- Using independence across windows, derive the mean and variance of the aggregated count $S$ over $k$ windows for a given sample. Then, using the Delta method for smooth transformations of approximately normal aggregates, obtain an analytic expression for the approximate variance of the log copy-number ratio estimator $\\ln(\\hat{r})$, where the estimator is defined as $\\hat{r} = S_{\\mathrm{T}} / S_{\\mathrm{N}}$.\n- Using plug-in estimates $\\hat{\\mu}_{\\mathrm{T}} = S_{\\mathrm{T}}/k$ and $\\hat{\\mu}_{\\mathrm{N}} = S_{\\mathrm{N}}/k$, compute the two-sided $95\\%$ confidence interval for $r$ by first constructing the interval on $\\ln(r)$ and then exponentiating the endpoints. Report the lower endpoint of this confidence interval, expressed as a decimal. Round your final answer to four significant figures.\n\nThe final answer must be a single real number.", "solution": "The problem is subjected to validation prior to any attempt at a solution.\n\n### Step 1: Extracted Givens\n-   **Model:** The observed count $X$ in a genomic window is modeled as a Gamma-Poisson mixture: $X \\mid \\Lambda \\sim \\mathrm{Poisson}(\\Lambda)$ and $\\Lambda \\sim \\mathrm{Gamma}(r, b)$, where $r>0$ is shape and $b>0$ is scale. This implies $X$ has a marginal Negative Binomial (NB) distribution.\n-   **Sample Aggregates:** $S_{\\mathrm{T}}$ and $S_{\\mathrm{N}}$ are aggregated counts over $k$ independent and identically distributed (i.i.d.) windows for tumor and normal samples, respectively.\n-   **Distributional Parameters:**\n    -   Tumor per-window mean: $\\mu_{\\mathrm{T}}$\n    -   Tumor per-window dispersion: $\\alpha_{\\mathrm{T}}$\n    -   Normal per-window mean: $\\mu_{\\mathrm{N}}$\n    -   Normal per-window dispersion: $\\alpha_{\\mathrm{N}}$\n-   **Independence:** $S_{\\mathrm{T}}$ and $S_{\\mathrm{N}}$ are independent.\n-   **Data:** $k=50$, $S_{\\mathrm{T}}=3750$, $S_{\\mathrm{N}}=2500$, $\\alpha_{\\mathrm{T}}=0.08$, $\\alpha_{\\mathrm{N}}=0.05$.\n-   **Estimators:** Copy-number ratio estimator $\\hat{r} = S_{\\mathrm{T}} / S_{\\mathrm{N}}$. Plug-in estimators for mean counts are $\\hat{\\mu}_{\\mathrm{T}} = S_{\\mathrm{T}}/k$ and $\\hat{\\mu}_{\\mathrm{N}} = S_{\\mathrm{N}}/k$.\n-   **Tasks:**\n    1.  Derive the marginal variance of a single-window NB count, $\\mathrm{Var}(X)$, in terms of its mean $\\mu$ and dispersion $\\alpha$. State the relationship between the Gamma parameters $(r, b)$ and the NB parameters $(\\mu, \\alpha)$.\n    2.  Derive the mean and variance of the aggregated count $S$. Use the Delta method to find an expression for the approximate variance of the log copy-number ratio estimator, $\\mathrm{Var}(\\ln(\\hat{r}))$.\n    3.  Compute the lower endpoint of the two-sided $95\\%$ confidence interval for the true copy-number ratio, rounded to four significant figures.\n\n### Step 2: Validation\n-   **Scientifically Grounded:** The problem is based on established statistical models (Poisson-Gamma mixture, Negative Binomial distribution) that are standard for analyzing overdispersed count data in genomics. The application to copy-number variation detection is a realistic and important problem in precision medicine.\n-   **Well-Posed:** All necessary information, data, and statistical methods (Delta method) are specified. The tasks are clearly defined and lead to a unique, meaningful solution.\n-   **Objective:** The problem is stated in precise, quantitative terms, free of subjectivity or ambiguity.\n-   **Consistency and Completeness:** The problem is self-contained. There are no contradictions. Note: The problem uses the symbol $r$ for both the Gamma shape parameter and the copy number ratio. This is a minor notational infelicity, but the context makes the meaning clear in each instance. We will proceed by interpreting the symbol based on its context.\n\n### Step 3: Verdict\nThe problem is valid. We proceed with the solution.\n\n### Solution Derivation\n\n**Task 1: Marginal Variance of a Single-Window Count**\n\nLet $X$ be the read count in a single window. We are given the hierarchical model $X \\mid \\Lambda \\sim \\mathrm{Poisson}(\\Lambda)$ and $\\Lambda \\sim \\mathrm{Gamma}(r, b)$. The properties of these distributions are:\n-   $\\mathrm{E}[X \\mid \\Lambda] = \\Lambda$ and $\\mathrm{Var}(X \\mid \\Lambda) = \\Lambda$.\n-   $\\mathrm{E}[\\Lambda] = rb$ and $\\mathrm{Var}(\\Lambda) = rb^2$, where $r$ is the shape and $b$ is the scale parameter of the Gamma distribution.\n\nWe use the law of total expectation to find the marginal mean, $\\mu$, of $X$:\n$$ \\mu = \\mathrm{E}[X] = \\mathrm{E}[\\mathrm{E}[X \\mid \\Lambda]] = \\mathrm{E}[\\Lambda] = rb $$\n\nWe use the law of total variance to find the marginal variance of $X$:\n$$ \\mathrm{Var}(X) = \\mathrm{E}[\\mathrm{Var}(X \\mid \\Lambda)] + \\mathrm{Var}(\\mathrm{E}[X \\mid \\Lambda]) $$\n$$ \\mathrm{Var}(X) = \\mathrm{E}[\\Lambda] + \\mathrm{Var}(\\Lambda) $$\nSubstituting the mean and variance of $\\Lambda$:\n$$ \\mathrm{Var}(X) = rb + rb^2 $$\nWe can rewrite this by substituting $\\mu = rb$:\n$$ \\mathrm{Var}(X) = \\mu + \\mu b $$\nThe problem defines the dispersion parameter $\\alpha$ through the variance parameterization $\\mathrm{Var}(X) = \\mu + \\alpha \\mu^2$. Equating our derived variance with this definition gives:\n$$ \\mu + \\mu b = \\mu + \\alpha \\mu^2 $$\nAssuming $\\mu > 0$, we can simplify to find the scale parameter $b$:\n$$ \\mu b = \\alpha \\mu^2 \\implies b = \\alpha \\mu $$\nNow we find the shape parameter $r$ by substituting this result back into the expression for the mean, $\\mu = rb$:\n$$ \\mu = r(\\alpha \\mu) $$\nAssuming $\\mu > 0$, we get $1 = r\\alpha$, which implies:\n$$ r = \\frac{1}{\\alpha} $$\nThus, the relationship between the Gamma parameters $(r,b)$ and the NB mean-dispersion parameters $(\\mu,\\alpha)$ is $r=1/\\alpha$ and $b=\\alpha\\mu$. The marginal variance of the single-window NB count is, by definition, $\\mathrm{Var}(X) = \\mu + \\alpha \\mu^2$.\n\n**Task 2: Mean/Variance of Aggregated Count and Variance of Log-Ratio**\n\nLet $S$ be the aggregated count over $k$ i.i.d. windows, $S = \\sum_{i=1}^k X_i$. The mean of $S$ is:\n$$ \\mathrm{E}[S] = \\mathrm{E}\\left[\\sum_{i=1}^k X_i\\right] = \\sum_{i=1}^k \\mathrm{E}[X_i] = \\sum_{i=1}^k \\mu = k\\mu $$\nDue to independence, the variance of $S$ is the sum of the variances:\n$$ \\mathrm{Var}(S) = \\mathrm{Var}\\left[\\sum_{i=1}^k X_i\\right] = \\sum_{i=1}^k \\mathrm{Var}(X_i) = \\sum_{i=1}^k (\\mu + \\alpha\\mu^2) = k(\\mu + \\alpha\\mu^2) $$\nThese results apply to both tumor (T) and normal (N) samples with their respective parameters:\n$$ \\mathrm{E}[S_{\\mathrm{T}}] = k\\mu_{\\mathrm{T}}, \\quad \\mathrm{Var}(S_{\\mathrm{T}}) = k(\\mu_{\\mathrm{T}} + \\alpha_{\\mathrm{T}}\\mu_{\\mathrm{T}}^2) $$\n$$ \\mathrm{E}[S_{\\mathrm{N}}] = k\\mu_{\\mathrm{N}}, \\quad \\mathrm{Var}(S_{\\mathrm{N}}) = k(\\mu_{\\mathrm{N}} + \\alpha_{\\mathrm{N}}\\mu_{\\mathrm{N}}^2) $$\n\nNext, we find the approximate variance of the log copy-number ratio estimator $\\ln(\\hat{r}_{CN}) = \\ln(S_{\\mathrm{T}}/S_{\\mathrm{N}})$. We define the function $g(S_{\\mathrm{T}}, S_{\\mathrm{N}}) = \\ln(S_{\\mathrm{T}}) - \\ln(S_{\\mathrm{N}})$. The Delta method approximation for the variance of $g(S_{\\mathrm{T}}, S_{\\mathrm{N}})$ is:\n$$ \\mathrm{Var}(g(S_{\\mathrm{T}}, S_{\\mathrm{N}})) \\approx \\left(\\frac{\\partial g}{\\partial S_{\\mathrm{T}}}\\right)^2 \\mathrm{Var}(S_{\\mathrm{T}}) + \\left(\\frac{\\partial g}{\\partial S_{\\mathrm{N}}}\\right)^2 \\mathrm{Var}(S_{\\mathrm{N}}) + 2 \\left(\\frac{\\partial g}{\\partial S_{\\mathrm{T}}}\\right)\\left(\\frac{\\partial g}{\\partial S_{\\mathrm{N}}}\\right)\\mathrm{Cov}(S_{\\mathrm{T}}, S_{\\mathrm{N}}) $$\nThe partial derivatives are $\\frac{\\partial g}{\\partial S_{\\mathrm{T}}} = \\frac{1}{S_{\\mathrm{T}}}$ and $\\frac{\\partial g}{\\partial S_{\\mathrm{N}}} = -\\frac{1}{S_{\\mathrm{N}}}$. These are evaluated at the expectations, $\\mathrm{E}[S_{\\mathrm{T}}]=k\\mu_{\\mathrm{T}}$ and $\\mathrm{E}[S_{\\mathrm{N}}]=k\\mu_{\\mathrm{N}}$. Since $S_{\\mathrm{T}}$ and $S_{\\mathrm{N}}$ are independent, $\\mathrm{Cov}(S_{\\mathrm{T}}, S_{\\mathrm{N}})=0$.\n$$ \\mathrm{Var}(\\ln(\\hat{r}_{CN})) \\approx \\left(\\frac{1}{k\\mu_{\\mathrm{T}}}\\right)^2 \\mathrm{Var}(S_{\\mathrm{T}}) + \\left(\\frac{-1}{k\\mu_{\\mathrm{N}}}\\right)^2 \\mathrm{Var}(S_{\\mathrm{N}}) $$\n$$ \\mathrm{Var}(\\ln(\\hat{r}_{CN})) \\approx \\frac{k(\\mu_{\\mathrm{T}} + \\alpha_{\\mathrm{T}}\\mu_{\\mathrm{T}}^2)}{(k\\mu_{\\mathrm{T}})^2} + \\frac{k(\\mu_{\\mathrm{N}} + \\alpha_{\\mathrm{N}}\\mu_{\\mathrm{N}}^2)}{(k\\mu_{\\mathrm{N}})^2} $$\nSimplifying the terms:\n$$ \\mathrm{Var}(\\ln(\\hat{r}_{CN})) \\approx \\frac{k\\mu_{\\mathrm{T}}(1 + \\alpha_{\\mathrm{T}}\\mu_{\\mathrm{T}})}{k^2\\mu_{\\mathrm{T}}^2} + \\frac{k\\mu_{\\mathrm{N}}(1 + \\alpha_{\\mathrm{N}}\\mu_{\\mathrm{N}})}{k^2\\mu_{\\mathrm{N}}^2} $$\n$$ \\mathrm{Var}(\\ln(\\hat{r}_{CN})) \\approx \\frac{1 + \\alpha_{\\mathrm{T}}\\mu_{\\mathrm{T}}}{k\\mu_{\\mathrm{T}}} + \\frac{1 + \\alpha_{\\mathrm{N}}\\mu_{\\mathrm{N}}}{k\\mu_{\\mathrm{N}}} $$\n$$ \\mathrm{Var}(\\ln(\\hat{r}_{CN})) \\approx \\left(\\frac{1}{k\\mu_{\\mathrm{T}}} + \\frac{\\alpha_{\\mathrm{T}}}{k}\\right) + \\left(\\frac{1}{k\\mu_{\\mathrm{N}}} + \\frac{\\alpha_{\\mathrm{N}}}{k}\\right) = \\frac{1}{k}\\left(\\frac{1}{\\mu_{\\mathrm{T}}} + \\frac{1}{\\mu_{\\mathrm{N}}} + \\alpha_{\\mathrm{T}} + \\alpha_{\\mathrm{N}}\\right) $$\nThis is the required analytic expression.\n\n**Task 3: Confidence Interval Calculation**\n\nFor large $k$, $\\ln(\\hat{r}_{CN})$ is approximately normally distributed. A two-sided $95\\%$ confidence interval for the true log-ratio, $\\ln(r_{CN})$, is given by:\n$$ \\ln(\\hat{r}_{CN}) \\pm z_{0.975} \\cdot \\mathrm{SE}(\\ln(\\hat{r}_{CN})) $$\nwhere $\\mathrm{SE}(\\ln(\\hat{r}_{CN}))$ is the standard error, i.e., the square root of the estimated variance, and $z_{0.975} \\approx 1.96$ is the critical value from the standard normal distribution.\n\nFirst, we compute the plug-in estimates for the mean counts:\n$$ \\hat{\\mu}_{\\mathrm{T}} = \\frac{S_{\\mathrm{T}}}{k} = \\frac{3750}{50} = 75 $$\n$$ \\hat{\\mu}_{\\mathrm{N}} = \\frac{S_{\\mathrm{N}}}{k} = \\frac{2500}{50} = 50 $$\nNext, we compute the point estimate of the log-ratio:\n$$ \\ln(\\hat{r}_{CN}) = \\ln\\left(\\frac{S_{\\mathrm{T}}}{S_{\\mathrm{N}}}\\right) = \\ln\\left(\\frac{3750}{2500}\\right) = \\ln(1.5) \\approx 0.405465 $$\nNow, we estimate the variance using our derived formula and the plug-in estimates:\n$$ \\widehat{\\mathrm{Var}}(\\ln(\\hat{r}_{CN})) = \\frac{1}{k}\\left(\\frac{1}{\\hat{\\mu}_{\\mathrm{T}}} + \\frac{1}{\\hat{\\mu}_{\\mathrm{N}}} + \\alpha_{\\mathrm{T}} + \\alpha_{\\mathrm{N}}\\right) $$\n$$ \\widehat{\\mathrm{Var}}(\\ln(\\hat{r}_{CN})) = \\frac{1}{50}\\left(\\frac{1}{75} + \\frac{1}{50} + 0.08 + 0.05\\right) $$\n$$ \\widehat{\\mathrm{Var}}(\\ln(\\hat{r}_{CN})) = \\frac{1}{50}(0.013333... + 0.02 + 0.13) = \\frac{1}{50}(0.163333...) $$\nIn exact fractions, this is $\\frac{1}{50}(\\frac{1}{75} + \\frac{1}{50} + \\frac{13}{100}) = \\frac{1}{50}(\\frac{4+6+39}{300}) = \\frac{1}{50}(\\frac{49}{300}) = \\frac{49}{15000}$.\nSo, $\\widehat{\\mathrm{Var}}(\\ln(\\hat{r}_{CN})) = \\frac{49}{15000} \\approx 0.0032667$.\n\nThe standard error is the square root of the variance:\n$$ \\mathrm{SE}(\\ln(\\hat{r}_{CN})) = \\sqrt{\\frac{49}{15000}} = \\frac{7}{\\sqrt{15000}} \\approx 0.057155 $$\nThe margin of error (ME) for the $95\\%$ CI is:\n$$ \\mathrm{ME} = z_{0.975} \\cdot \\mathrm{SE}(\\ln(\\hat{r}_{CN})) \\approx 1.96 \\times 0.057155 \\approx 0.112023 $$\nThe lower bound of the confidence interval for $\\ln(r_{CN})$ is:\n$$ \\ln(r_{CN})_{\\text{lower}} = \\ln(\\hat{r}_{CN}) - \\mathrm{ME} \\approx 0.405465 - 0.112023 = 0.293442 $$\nTo find the lower bound of the confidence interval for the ratio $r_{CN}$ itself, we exponentiate this value:\n$$ (r_{CN})_{\\text{lower}} = \\exp(\\ln(r_{CN})_{\\text{lower}}) \\approx \\exp(0.293442) \\approx 1.34105 $$\nRounding to four significant figures, the lower endpoint is $1.341$.", "answer": "$$\\boxed{1.341}$$", "id": "4377748"}]}