{"hands_on_practices": [{"introduction": "This first practice returns to the foundations of quantitative genetics, exploring how narrow-sense heritability ($h^2$) can be estimated from the resemblance between relatives. You will derive the classic result that links the slope of an offspring-parent regression to $h^2$ and, critically, investigate how real-world measurement error can systematically bias this estimate [@problem_id:4328507]. Mastering this correction is essential for accurately interpreting heritability estimates from family studies.", "problem": "In a population-based biobank study targeting precision medicine and genomic diagnostics, consider a complex quantitative trait such as adult systolic blood pressure. Assume an additive polygenic architecture with random mating and no assortative mating, and ignore dominance, epistasis, shared environmental covariance between generations, and gene–environment correlation. Let the narrow-sense heritability be defined as $h^{2} = V_{A} / V_{P}$, where $V_{A}$ is the additive genetic variance and $V_{P}$ is the total phenotypic variance.\n\nA mid-parent–offspring regression is performed using the observed mid-parent phenotype as predictor and the offspring phenotype as response. Let $Y_{f}^{\\mathrm{true}}$ and $Y_{m}^{\\mathrm{true}}$ denote the true parental phenotypes, and $Y_{f}^{\\mathrm{obs}} = Y_{f}^{\\mathrm{true}} + e_{f}$, $Y_{m}^{\\mathrm{obs}} = Y_{m}^{\\mathrm{true}} + e_{m}$ their observed values, where $e_{f}$ and $e_{m}$ are independent classical measurement errors with zero mean and variance $\\sigma_{e}^{2}$, independent of all true phenotypes. The true mid-parent is $M^{\\mathrm{true}} = \\frac{Y_{f}^{\\mathrm{true}} + Y_{m}^{\\mathrm{true}}}{2}$ and the observed mid-parent is $M^{\\mathrm{obs}} = \\frac{Y_{f}^{\\mathrm{obs}} + Y_{m}^{\\mathrm{obs}}}{2} = M^{\\mathrm{true}} + \\varepsilon_{M}$ with $\\varepsilon_{M} = \\frac{e_{f} + e_{m}}{2}$. The offspring phenotype $Y_{o}$ is measured with negligible error. In the dataset, the ordinary least squares slope of the offspring on the observed mid-parent is $b = 0.45$. Independent test–retest studies establish that the per-parent test–retest reliability (defined as $\\mathrm{Var}(Y^{\\mathrm{true}})/\\mathrm{Var}(Y^{\\mathrm{obs}})$) is $r_{p} = 0.80$.\n\nStarting from core quantitative genetics definitions and properties of covariance in pedigrees, derive the relationship between the regression slope of offspring on the true mid-parent and $h^{2}$, and then derive how classical measurement error in the parents attenuates the observed slope. Using these derivations, compute the measurement-error-corrected narrow-sense heritability $h^{2}$ for this dataset, reporting a single number. No rounding is required.", "solution": "The problem requires the calculation of the narrow-sense heritability, $h^2$, corrected for measurement error in the parental phenotypes. The solution will proceed in three stages as requested by the prompt: first, deriving the relationship between the true mid-parent–offspring regression slope and $h^2$; second, deriving the attenuation of this slope by measurement error; and third, applying these derivations to compute $h^2$ from the provided data.\n\nThe fundamental model for a quantitative trait phenotype, ignoring dominance and epistasis as specified, is $Y^{\\mathrm{true}} = A + E_{u}$, where $A$ is the additive genetic value and $E_{u}$ is the unique environmental contribution. The total phenotypic variance is $V_P = \\mathrm{Var}(Y^{\\mathrm{true}}) = \\mathrm{Var}(A) + \\mathrm{Var}(E_{u}) = V_A + V_E$. The narrow-sense heritability is defined as $h^2 = V_A / V_P$.\n\n**1. Regression of Offspring Phenotype on True Mid-Parent Phenotype**\n\nThe slope of a simple linear regression of a response variable $Y$ on a predictor variable $X$ is given by $\\beta_{Y|X} = \\frac{\\mathrm{Cov}(X, Y)}{\\mathrm{Var}(X)}$. Here, the response is the offspring phenotype, $Y_o$, and the predictor is the true mid-parent phenotype, $M^{\\mathrm{true}} = \\frac{Y_{f}^{\\mathrm{true}} + Y_{m}^{\\mathrm{true}}}{2}$. The offspring's phenotype is measured with negligible error, so we can denote it as $Y_o$. The slope, which we shall call $\\beta^{\\mathrm{true}}$, is:\n$$\n\\beta^{\\mathrm{true}} = \\frac{\\mathrm{Cov}(Y_o, M^{\\mathrm{true}})}{\\mathrm{Var}(M^{\\mathrm{true}})}\n$$\nWe must compute the covariance in the numerator and the variance in the denominator.\n\nNumerator: $\\mathrm{Cov}(Y_o, M^{\\mathrm{true}})$\nUsing the definition of $M^{\\mathrm{true}}$ and properties of covariance:\n$$\n\\mathrm{Cov}(Y_o, M^{\\mathrm{true}}) = \\mathrm{Cov}\\left(Y_o, \\frac{Y_{f}^{\\mathrm{true}} + Y_{m}^{\\mathrm{true}}}{2}\\right) = \\frac{1}{2} \\left[ \\mathrm{Cov}(Y_o, Y_{f}^{\\mathrm{true}}) + \\mathrm{Cov}(Y_o, Y_{m}^{\\mathrm{true}}) \\right]\n$$\nThe covariance between an offspring and one parent (e.g., the father) is $\\mathrm{Cov}(Y_o, Y_{f}^{\\mathrm{true}})$. Under the problem's assumptions (no shared environment between generations, purely additive genetics), this covariance is equal to the covariance of their additive genetic values: $\\mathrm{Cov}(Y_o, Y_{f}^{\\mathrm{true}}) = \\mathrm{Cov}(A_o, A_f)$. A child receives a random half of its alleles from each parent, so the covariance of additive genetic values between a parent and offspring is $\\frac{1}{2}V_A$. Thus:\n$$\n\\mathrm{Cov}(Y_o, Y_{f}^{\\mathrm{true}}) = \\mathrm{Cov}(Y_o, Y_{m}^{\\mathrm{true}}) = \\frac{1}{2}V_A\n$$\nSubstituting this into the expression for the covariance with the mid-parent:\n$$\n\\mathrm{Cov}(Y_o, M^{\\mathrm{true}}) = \\frac{1}{2} \\left( \\frac{1}{2}V_A + \\frac{1}{2}V_A \\right) = \\frac{1}{2}V_A\n$$\n\nDenominator: $\\mathrm{Var}(M^{\\mathrm{true}})$\nUsing the definition of $M^{\\mathrm{true}}$ and properties of variance:\n$$\n\\mathrm{Var}(M^{\\mathrm{true}}) = \\mathrm{Var}\\left(\\frac{Y_{f}^{\\mathrm{true}} + Y_{m}^{\\mathrm{true}}}{2}\\right) = \\frac{1}{4} \\mathrm{Var}(Y_{f}^{\\mathrm{true}} + Y_{m}^{\\mathrm{true}}) = \\frac{1}{4} \\left[ \\mathrm{Var}(Y_{f}^{\\mathrm{true}}) + \\mathrm{Var}(Y_{m}^{\\mathrm{true}}) + 2\\mathrm{Cov}(Y_{f}^{\\mathrm{true}}, Y_{m}^{\\mathrm{true}}) \\right]\n$$\nThe parents are drawn from the same population, so $\\mathrm{Var}(Y_{f}^{\\mathrm{true}}) = \\mathrm{Var}(Y_{m}^{\\mathrm{true}}) = V_P$. The problem specifies random mating and no assortative mating, which implies that the phenotypes of the parents are uncorrelated: $\\mathrm{Cov}(Y_{f}^{\\mathrm{true}}, Y_{m}^{\\mathrm{true}}) = 0$. Therefore:\n$$\n\\mathrm{Var}(M^{\\mathrm{true}}) = \\frac{1}{4} (V_P + V_P + 0) = \\frac{2V_P}{4} = \\frac{1}{2}V_P\n$$\n\nCombining the numerator and denominator, the true regression slope is:\n$$\n\\beta^{\\mathrm{true}} = \\frac{\\frac{1}{2}V_A}{\\frac{1}{2}V_P} = \\frac{V_A}{V_P} = h^2\n$$\nThis establishes the classic quantitative genetics result that the regression slope of offspring phenotype on the true mid-parent phenotype is equal to the narrow-sense heritability.\n\n**2. Attenuation of the Slope by Measurement Error**\n\nThe observed regression is of $Y_o$ on the observed mid-parent phenotype, $M^{\\mathrm{obs}} = \\frac{Y_{f}^{\\mathrm{obs}} + Y_{m}^{\\mathrm{obs}}}{2}$. The observed slope, given as $b=0.45$, is:\n$$\nb = \\frac{\\mathrm{Cov}(Y_o, M^{\\mathrm{obs}})}{\\mathrm{Var}(M^{\\mathrm{obs}})}\n$$\nWe analyze the effect of measurement error on the numerator and denominator separately. The observed phenotypes are $Y_{f}^{\\mathrm{obs}} = Y_{f}^{\\mathrm{true}} + e_{f}$ and $Y_{m}^{\\mathrm{obs}} = Y_{m}^{\\mathrm{true}} + e_{m}$. The observed mid-parent is $M^{\\mathrm{obs}} = M^{\\mathrm{true}} + \\varepsilon_M$, where $\\varepsilon_M = \\frac{e_f + e_m}{2}$.\n\nNumerator: $\\mathrm{Cov}(Y_o, M^{\\mathrm{obs}})$\n$$\n\\mathrm{Cov}(Y_o, M^{\\mathrm{obs}}) = \\mathrm{Cov}(Y_o, M^{\\mathrm{true}} + \\varepsilon_M) = \\mathrm{Cov}(Y_o, M^{\\mathrm{true}}) + \\mathrm{Cov}(Y_o, \\varepsilon_M)\n$$\nThe measurement errors $e_f$ and $e_m$ are independent of all true phenotypes, including $Y_o$. Therefore, their average, $\\varepsilon_M$, is also independent of $Y_o$, which means $\\mathrm{Cov}(Y_o, \\varepsilon_M) = 0$. The numerator is unaffected by the measurement error:\n$$\n\\mathrm{Cov}(Y_o, M^{\\mathrm{obs}}) = \\mathrm{Cov}(Y_o, M^{\\mathrm{true}}) = \\frac{1}{2}V_A\n$$\n\nDenominator: $\\mathrm{Var}(M^{\\mathrm{obs}})$\n$$\n\\mathrm{Var}(M^{\\mathrm{obs}}) = \\mathrm{Var}(M^{\\mathrm{true}} + \\varepsilon_M) = \\mathrm{Var}(M^{\\mathrm{true}}) + \\mathrm{Var}(\\varepsilon_M) + 2\\mathrm{Cov}(M^{\\mathrm{true}}, \\varepsilon_M)\n$$\nSince the errors are independent of true phenotypes, $\\mathrm{Cov}(M^{\\mathrm{true}}, \\varepsilon_M) = 0$. The variance of the error term $\\varepsilon_M$ is:\n$$\n\\mathrm{Var}(\\varepsilon_M) = \\mathrm{Var}\\left(\\frac{e_f + e_m}{2}\\right) = \\frac{1}{4}\\mathrm{Var}(e_f + e_m)\n$$\nAs $e_f$ and $e_m$ are independent with variance $\\sigma_e^2$, $\\mathrm{Var}(e_f + e_m) = \\mathrm{Var}(e_f) + \\mathrm{Var}(e_m) = \\sigma_e^2 + \\sigma_e^2 = 2\\sigma_e^2$.\n$$\n\\mathrm{Var}(\\varepsilon_M) = \\frac{1}{4}(2\\sigma_e^2) = \\frac{1}{2}\\sigma_e^2\n$$\nThe total variance of the observed mid-parent is:\n$$\n\\mathrm{Var}(M^{\\mathrm{obs}}) = \\mathrm{Var}(M^{\\mathrm{true}}) + \\mathrm{Var}(\\varepsilon_M) = \\frac{1}{2}V_P + \\frac{1}{2}\\sigma_e^2 = \\frac{1}{2}(V_P + \\sigma_e^2)\n$$\nThe observed regression slope $b$ is therefore:\n$$\nb = \\frac{\\frac{1}{2}V_A}{\\frac{1}{2}(V_P + \\sigma_e^2)} = \\frac{V_A}{V_P + \\sigma_e^2}\n$$\nThis can be rewritten in terms of $h^2$:\n$$\nb = \\frac{V_A/V_P}{(V_P + \\sigma_e^2)/V_P} = \\frac{h^2}{1 + \\sigma_e^2/V_P}\n$$\nThis expression shows the attenuation of the true slope $h^2$ by a factor related to the measurement error variance.\n\n**3. Computation of the Corrected Heritability**\n\nTo solve for $h^2$, we must find the value of the attenuation factor. The problem provides the per-parent test-retest reliability, $r_p = 0.80$, defined as:\n$$\nr_p = \\frac{\\mathrm{Var}(Y^{\\mathrm{true}})}{\\mathrm{Var}(Y^{\\mathrm{obs}})}\n$$\nFor a single parent, $\\mathrm{Var}(Y^{\\mathrm{true}}) = V_P$. The observed variance is $\\mathrm{Var}(Y^{\\mathrm{obs}}) = \\mathrm{Var}(Y^{\\mathrm{true}} + e) = \\mathrm{Var}(Y^{\\mathrm{true}}) + \\mathrm{Var}(e) = V_P + \\sigma_e^2$. Thus,\n$$\nr_p = \\frac{V_P}{V_P + \\sigma_e^2}\n$$\nNow, let us examine the attenuation factor in our expression for the observed slope $b$:\n$$\nb = \\frac{V_A}{V_P + \\sigma_e^2} = \\left(\\frac{V_A}{V_P}\\right) \\left(\\frac{V_P}{V_P + \\sigma_e^2}\\right) = h^2 \\cdot r_p\n$$\nThe relationship is remarkably simple: the observed slope is the product of the narrow-sense heritability and the reliability of a single parent's measurement. This arises because the process of creating the mid-parent value scales both the signal variance ($\\mathrm{Var}(M^{\\mathrm{true}}) = V_P/2$) and the noise variance ($\\mathrm{Var}(\\varepsilon_M) = \\sigma_e^2/2$) by the same factor of $1/2$, leaving their ratio, and thus the reliability, unchanged. The reliability of the mid-parent predictor is $r_M = \\frac{\\mathrm{Var}(M^{\\mathrm{true}})}{\\mathrm{Var}(M^{\\mathrm{obs}})} = \\frac{V_P/2}{(V_P + \\sigma_e^2)/2} = \\frac{V_P}{V_P + \\sigma_e^2} = r_p$.\n\nWe are given $b = 0.45$ and $r_p = 0.80$. We can now solve for $h^2$:\n$$\nh^2 = \\frac{b}{r_p} = \\frac{0.45}{0.80}\n$$\n$$\nh^2 = \\frac{45/100}{80/100} = \\frac{45}{80} = \\frac{9}{16}\n$$\nConverting this fraction to a decimal gives the final numerical answer.\n$$\nh^2 = 0.5625\n$$", "answer": "$$\\boxed{0.5625}$$", "id": "4328507"}, {"introduction": "We now transition from family designs to the era of large-scale genomic data, introducing Linkage Disequilibrium (LD) Score regression, a powerful method for estimating SNP-based heritability ($h^2_{\\text{SNP}}$) using only Genome-Wide Association Study (GWAS) summary statistics [@problem_id:4328524]. By engaging with its first principles, you will see how the confounding effect of LD on association statistics can be ingeniously repurposed to separate true polygenic signal from background noise and population structure.", "problem": "A research team conducts a large-scale Genome-Wide Association Study (GWAS) of a continuous trait with unit variance under the additive polygenic model. Genotypes are standardized so that each Single-Nucleotide Polymorphism (SNP) genotype has mean zero and variance one, and the phenotype is standardized to have mean zero and variance one. The team plans to estimate Single-Nucleotide Polymorphism heritability, denoted $h^{2}_{\\text{SNP}}$, using Linkage Disequilibrium (LD) Score regression (LDSC), where Linkage Disequilibrium (LD) Score $\\ell_{j}$ for SNP $j$ is defined as the sum of squared correlations with all other genotyped SNPs. Assume the following standard conditions for LD Score regression: additive genetic effects, small and approximately independent SNP effect sizes across the genome, effect sizes independent of local LD, negligible confounding such that the regression intercept equals the null expectation, and homogeneous sampling such that the sampling variance contributes its canonical null term.\n\nStarting from the additive model and the definition of $h^{2}_{\\text{SNP}}$ as the proportion of phenotypic variance explained by all genotyped SNPs, derive the expression linking the expected mean of the association $\\chi^{2}$ statistics across SNPs to $h^{2}_{\\text{SNP}}$, the sample size $N$, the number of SNPs $M$, and the average LD score $\\bar{\\ell}$. Then, using the provided summary statistics from the GWAS meta-analysis—mean $\\chi^{2}$ statistic $\\overline{\\chi^{2}} = 1.30$, sample size $N = 200{,}000$, average LD score $\\bar{\\ell} = 100$, and number of SNPs $M = 1{,}000{,}000$—compute $h^{2}_{\\text{SNP}}$ under the stated assumptions.\n\nExpress your final answer as a decimal fraction. No rounding is required beyond exact arithmetic.", "solution": "The task is twofold: first, to derive the theoretical relationship between the mean chi-squared ($\\chi^2$) statistic, SNP heritability ($h^{2}_{\\text{SNP}}$), sample size ($N$), number of SNPs ($M$), and the average LD score ($\\bar{\\ell}$); second, to compute $h^{2}_{\\text{SNP}}$ using the provided data.\n\n**Part 1: Derivation of the LD Score Regression Equation**\n\nWe begin with the standard additive linear model for a phenotype $y$ in a sample of $N$ individuals. The phenotype for individual $i$ is given by:\n$$\ny_i = \\sum_{j=1}^{M} X_{ij} \\beta_j + \\epsilon_i\n$$\nwhere $M$ is the number of genotyped SNPs, $X_{ij}$ is the standardized genotype of individual $i$ at SNP $j$, $\\beta_j$ is the true additive genetic effect of SNP $j$, and $\\epsilon_i$ is the non-genetic component (environmental effects and noise) for individual $i$.\n\nThe problem states that both the phenotype and genotypes are standardized. This implies:\n- Phenotype: $\\mathbb{E}[y_i] = 0$ and $\\text{Var}(y) = 1$.\n- Genotype: For each SNP $j$, $\\mathbb{E}[X_{ij}] = 0$ and $\\text{Var}(X_j) = 1$ over the $N$ individuals.\n\nThe SNP heritability, $h^{2}_{\\text{SNP}}$, is defined as the proportion of phenotypic variance explained by all genotyped SNPs. Since $\\text{Var}(y)=1$, we have:\n$$\nh^{2}_{\\text{SNP}} = \\text{Var}\\left(\\sum_{j=1}^{M} X_{ij} \\beta_j\\right)\n$$\nThe core assumption of the polygenic model used in LDSC is that the effect sizes $\\beta_j$ are random variables drawn independently from a distribution with mean $0$ and variance $\\mathbb{E}[\\beta_j^2] = \\frac{h^{2}_{\\text{SNP}}}{M}$. This ensures that, if all SNPs were in linkage equilibrium (uncorrelated), the total genetic variance would be $\\sum_{j=1}^{M} \\text{Var}(\\beta_j) \\text{Var}(X_j) = M \\times \\frac{h^{2}_{\\text{SNP}}}{M} \\times 1 = h^{2}_{\\text{SNP}}$.\n\nIn a GWAS, we estimate the marginal effect of each SNP $j$ using simple linear regression. For standardized variables, the estimated effect size, $\\hat{\\beta}_j$, is the sample correlation between the genotype $X_j$ and the phenotype $y$:\n$$\n\\hat{\\beta}_j = \\frac{1}{N} \\sum_{i=1}^{N} X_{ij} y_i\n$$\nSubstituting the true model for $y_i$:\n$$\n\\hat{\\beta}_j = \\frac{1}{N} \\sum_{i=1}^{N} X_{ij} \\left( \\sum_{k=1}^{M} X_{ik} \\beta_k + \\epsilon_i \\right) = \\sum_{k=1}^{M} \\left( \\frac{1}{N} \\sum_{i=1}^{N} X_{ij} X_{ik} \\right) \\beta_k + \\frac{1}{N} \\sum_{i=1}^{N} X_{ij} \\epsilon_i\n$$\nThe term $\\frac{1}{N} \\sum_{i=1}^{N} X_{ij} X_{ik}$ is the sample correlation between SNP $j$ and SNP $k$, denoted by $r_{jk}$. The second term represents sampling noise. So, we can write:\n$$\n\\hat{\\beta}_j = \\sum_{k=1}^{M} r_{jk} \\beta_k + e_j\n$$\nwhere $e_j = \\frac{1}{N} \\sum_{i=1}^{N} X_{ij} \\epsilon_i$.\n\nThe association test statistic for SNP $j$ is typically a z-score, $Z_j = \\frac{\\hat{\\beta}_j}{\\text{SE}(\\hat{\\beta}_j)}$. For a large sample size $N$ and standardized variables, the standard error of the effect estimate is approximately $\\text{SE}(\\hat{\\beta}_j) \\approx \\frac{1}{\\sqrt{N}}$.\nThe $\\chi^2$ statistic is the square of the z-score: $\\chi^2_j = Z_j^2 \\approx N \\hat{\\beta}_j^2$.\n$$\n\\chi^2_j \\approx N \\left( \\sum_{k=1}^{M} r_{jk} \\beta_k + e_j \\right)^2 = N \\left( \\sum_{k=1}^{M} r_{jk} \\beta_k \\right)^2 + 2N e_j \\left( \\sum_{k=1}^{M} r_{jk} \\beta_k \\right) + N e_j^2\n$$\nWe are interested in the expected value of this statistic, $\\mathbb{E}[\\chi^2_j]$, where the expectation is taken over the distribution of true effects $\\beta_k$ and the sampling of individuals (which determines $e_j$).\n$$\n\\mathbb{E}[\\chi^2_j] = \\mathbb{E}\\left[N \\left( \\sum_{k=1}^{M} r_{jk} \\beta_k \\right)^2\\right] + 2N \\mathbb{E}\\left[e_j \\left( \\sum_{k=1}^{M} r_{jk} \\beta_k \\right)\\right] + \\mathbb{E}[N e_j^2]\n$$\nThe genetic effects $\\beta_k$ are assumed to be independent of the non-genetic component $\\epsilon_i$, and thus independent of the sampling noise $e_j$. Therefore, the cross-term is zero: $\\mathbb{E}[e_j (\\dots)] = \\mathbb{E}[e_j]\\mathbb{E}[(\\dots)] = 0$.\n\nLet's evaluate the remaining two terms.\nThe first term is the contribution from genetics and LD:\n$$\n\\mathbb{E}\\left[N \\left( \\sum_{k=1}^{M} r_{jk} \\beta_k \\right)^2\\right] = N \\mathbb{E}\\left[ \\left(\\sum_k r_{jk} \\beta_k\\right) \\left(\\sum_m r_{jm} \\beta_m\\right) \\right] = N \\sum_{k,m} r_{jk} r_{jm} \\mathbb{E}[\\beta_k \\beta_m]\n$$\nSince effect sizes of different SNPs are independent, $\\mathbb{E}[\\beta_k \\beta_m] = 0$ for $k \\neq m$. Thus, we only consider terms where $k = m$. Using $\\mathbb{E}[\\beta_k^2] = \\frac{h^{2}_{\\text{SNP}}}{M}$:\n$$\nN \\sum_{k=1}^{M} r_{jk}^2 \\mathbb{E}[\\beta_k^2] = N \\sum_{k=1}^{M} r_{jk}^2 \\left(\\frac{h^{2}_{\\text{SNP}}}{M}\\right) = N \\frac{h^{2}_{\\text{SNP}}}{M} \\sum_{k=1}^{M} r_{jk}^2\n$$\nThe LD score for SNP $j$ is defined as $\\ell_j = \\sum_{k=1}^{M} r_{jk}^2$. So the term becomes $N \\frac{h^{2}_{\\text{SNP}}}{M} \\ell_j$.\n\nThe second term is the contribution from sampling variance, $\\mathbb{E}[N e_j^2]$. The problem specifies \"homogeneous sampling such that the sampling variance contributes its canonical null term.\" Under the null hypothesis of no genetic effects ($\\beta_j = 0$ for all $j$), the $\\chi^2$ statistic for a single test follows a $\\chi^2$ distribution with one degree of freedom, which has an expected value of $1$. This contribution to the expected $\\chi^2$ statistic from sampling noise is therefore $1$.\n\nCombining the terms, the expected $\\chi^2$ statistic for a single SNP $j$ is:\n$$\n\\mathbb{E}[\\chi^2_j] = N \\frac{h^{2}_{\\text{SNP}}}{M} \\ell_j + 1\n$$\nThis equation forms the basis of LD Score regression, where one regresses the observed $\\chi^2_j$ statistics against their pre-computed LD scores $\\ell_j$. The problem asks for the relationship involving the *mean* $\\chi^2$ statistic, $\\overline{\\chi^2}$. We find this by averaging the above expression over all $M$ SNPs:\n$$\n\\mathbb{E}[\\overline{\\chi^2}] = \\mathbb{E}\\left[\\frac{1}{M}\\sum_{j=1}^{M} \\chi^2_j\\right] = \\frac{1}{M}\\sum_{j=1}^{M} \\mathbb{E}[\\chi^2_j] = \\frac{1}{M}\\sum_{j=1}^{M} \\left(N \\frac{h^{2}_{\\text{SNP}}}{M} \\ell_j + 1\\right)\n$$\n$$\n\\mathbb{E}[\\overline{\\chi^2}] = \\frac{N h^{2}_{\\text{SNP}}}{M^2} \\sum_{j=1}^{M} \\ell_j + \\frac{1}{M}\\sum_{j=1}^{M} 1 = \\frac{N h^{2}_{\\text{SNP}}}{M} \\left(\\frac{1}{M}\\sum_{j=1}^{M} \\ell_j\\right) + 1\n$$\nRecognizing that $\\bar{\\ell} = \\frac{1}{M}\\sum_{j=1}^{M} \\ell_j$ is the average LD score, we arrive at the final derived expression:\n$$\n\\mathbb{E}[\\overline{\\chi^2}] = \\frac{N h^{2}_{\\text{SNP}}}{M} \\bar{\\ell} + 1\n$$\n\n**Part 2: Calculation of $h^{2}_{\\text{SNP}}$**\n\nWe use the observed mean $\\chi^2$ statistic, $\\overline{\\chi^2} = 1.30$, as our estimate for its expectation, $\\mathbb{E}[\\overline{\\chi^2}]$. We can now solve for $h^{2}_{\\text{SNP}}$:\n$$\n\\overline{\\chi^2} = \\frac{N \\bar{\\ell}}{M} h^{2}_{\\text{SNP}} + 1\n$$\n$$\n\\overline{\\chi^2} - 1 = \\frac{N \\bar{\\ell}}{M} h^{2}_{\\text{SNP}}\n$$\n$$\nh^{2}_{\\text{SNP}} = \\frac{M (\\overline{\\chi^2} - 1)}{N \\bar{\\ell}}\n$$\nThe provided summary statistics are:\n- $\\overline{\\chi^2} = 1.30$\n- $N = 200{,}000 = 2 \\times 10^5$\n- $\\bar{\\ell} = 100 = 10^2$\n- $M = 1{,}000{,}000 = 10^6$\n\nSubstituting these values into the expression for $h^{2}_{\\text{SNP}}$:\n$$\nh^{2}_{\\text{SNP}} = \\frac{1{,}000{,}000 \\times (1.30 - 1)}{200{,}000 \\times 100}\n$$\n$$\nh^{2}_{\\text{SNP}} = \\frac{10^6 \\times 0.30}{(2 \\times 10^5) \\times 10^2}\n$$\n$$\nh^{2}_{\\text{SNP}} = \\frac{0.30 \\times 10^6}{2 \\times 10^7}\n$$\n$$\nh^{2}_{\\text{SNP}} = \\frac{0.30}{2 \\times 10^{7-6}} = \\frac{0.30}{2 \\times 10^1} = \\frac{0.30}{20}\n$$\n$$\nh^{2}_{\\text{SNP}} = 0.015\n$$\nThe estimated SNP heritability is $0.015$, or $1.5\\%$.", "answer": "$$\n\\boxed{0.015}\n$$", "id": "4328524"}, {"introduction": "Building upon the LD Score regression framework, this final practice extends the analysis to two traits to quantify their shared genetic architecture. You will use bivariate LD Score regression to estimate the genetic correlation ($\\rho_g$), a measure of pleiotropy, and explore the crucial distinction between genetic and phenotypic correlations [@problem_id:4328573]. This practice demonstrates how to dissect the observed relationship between traits into its underlying genetic and environmental components, a key task in modern complex trait genetics.", "problem": "A biobank cohort conducted two independent Genome-Wide Association Studies (GWAS) of two standardized complex traits, denoted trait $A$ and trait $B$, in unrelated individuals of the same ancestry. Summary statistics were computed for $M$ common Single Nucleotide Polymorphisms (SNPs) that passed quality control, and Linkage Disequilibrium (LD) scores $\\ell_j$ were estimated in a matched LD reference panel. Let $z_{1j}$ and $z_{2j}$ be the marginal $z$-scores for SNP $j$ in traits $A$ and $B$, respectively. Define the cross-trait moment $\\chi^{(12)}_j = z_{1j} z_{2j}$ and the per-trait moments $\\chi^{(1)}_j = z_{1j}^2$ and $\\chi^{(2)}_j = z_{2j}^2$. Assume an additive polygenic architecture, homoscedastic SNP effects, and that confounding bias and sample overlap are negligible.\n\nYou are given the following aggregated quantities over the $M$ SNPs:\n- Number of SNPs: $M = 10^6$.\n- GWAS sample sizes: $N_1 = 3 \\times 10^5$ for trait $A$ and $N_2 = 2 \\times 10^5$ for trait $B$.\n- LD score sums: $S_{\\ell} = \\sum_{j=1}^{M} \\ell_j = 10^8$ and $S_{\\ell^2} = \\sum_{j=1}^{M} \\ell_j^2 = 1.5 \\times 10^{10}$.\n- Cross-trait aggregated moments: $S_{x} = \\sum_{j=1}^{M} \\chi^{(12)}_j = 1.0383 \\times 10^6$ and $S_{\\ell x} = \\sum_{j=1}^{M} \\ell_j \\chi^{(12)}_j = 1.55745 \\times 10^8$.\n- Trait $A$ aggregated moments: $S_{y1} = \\sum_{j=1}^{M} \\chi^{(1)}_j = 7 \\times 10^6$ and $S_{\\ell y1} = \\sum_{j=1}^{M} \\ell_j \\chi^{(1)}_j = 10^9$.\n- Trait $B$ aggregated moments: $S_{y2} = \\sum_{j=1}^{M} \\chi^{(2)}_j = 3 \\times 10^6$ and $S_{\\ell y2} = \\sum_{j=1}^{M} \\ell_j \\chi^{(2)}_j = 4 \\times 10^8$.\n\nStarting from fundamental definitions of LD score and the additive random-effects model for SNP effects, use bivariate LD score regression to:\n1. Estimate the genetic correlation $\\rho_g$ between traits $A$ and $B$ from these aggregates. Your computation should proceed by first estimating the regression slopes that link the moments to LD scores, then mapping the slopes to SNP-heritabilities on the observed scale for traits $A$ and $B$, and finally converting the cross-trait slope to a genetic covariance and hence to $\\rho_g$.\n2. Briefly interpret how a positive $\\rho_g$ could arise even when the phenotypic correlation between $A$ and $B$, measured in an external cohort, is negative, with $r_p = -0.12$.\n\nExpress the final numerical value of $\\rho_g$ and round your answer to four significant figures. No units are required in the final answer.", "solution": "The problem requires the estimation of the genetic correlation, $\\rho_g$, between two traits, A and B, using summary statistics from Genome-Wide Association Studies (GWAS) via bivariate LD Score (LDSC) regression. Additionally, it asks for an interpretation of a potential discrepancy between the signs of the genetic and phenotypic correlations.\n\n### Part 1: Estimation of Genetic Correlation ($\\rho_g$)\n\n**Theoretical Framework**\n\nThe LDSC method is based on a linear relationship between the expected chi-square statistic of a Single Nucleotide Polymorphism (SNP), denoted $\\chi_j^2 = z_j^2$, and its LD score, $\\ell_j$. The LD score $\\ell_j = \\sum_{k} r_{jk}^2$ quantifies the extent to which SNP $j$ is in linkage disequilibrium (LD) with other SNPs.\n\nUnder an additive polygenic model with homoscedastic SNP effects, and assuming negligible confounding bias (e.g., from population stratification) and no sample overlap between studies, the expected values of the per-trait and cross-trait moments are given by:\n\n1.  For trait A (denoted by subscript $1$):\n    $$E[\\chi^{(1)}_j] = E[z_{1j}^2] = \\frac{N_1 h_1^2}{M} \\ell_j + 1$$\n2.  For trait B (denoted by subscript $2$):\n    $$E[\\chi^{(2)}_j] = E[z_{2j}^2] = \\frac{N_2 h_2^2}{M} \\ell_j + 1$$\n3.  For the cross-trait product:\n    $$E[\\chi^{(12)}_j] = E[z_{1j} z_{2j}] = \\frac{\\sqrt{N_1 N_2} \\rho_{g12}}{M} \\ell_j$$\n\nIn these equations:\n- $N_k$ is the sample size for trait $k$.\n- $M$ is the number of SNPs used in the analysis.\n- $h_k^2$ is the SNP-heritability of trait $k$.\n- $\\rho_{g12}$ is the genetic covariance between traits A and B.\n- The intercept of $1$ in the per-trait equations arises from sampling noise in the estimation of SNP effect sizes.\n- The intercept for the cross-trait equation is $0$ because the studies are independent (no sample overlap), so the estimation errors for $z_{1j}$ and $z_{2j}$ are uncorrelated.\n\nThese equations represent simple linear models. We can estimate the slopes via ordinary least squares (OLS) regression of the moments ($\\chi_j$) on the LD scores ($\\ell_j$) across all $M$ SNPs.\n\n**Estimation of Regression Slopes**\n\nThe slope $b$ of a simple linear regression of $y$ on $x$ is given by:\n$$b = \\frac{M \\sum_{j=1}^{M} x_j y_j - (\\sum_{j=1}^{M} x_j)(\\sum_{j=1}^{M} y_j)}{M \\sum_{j=1}^{M} x_j^2 - (\\sum_{j=1}^{M} x_j)^2}$$\nThe denominator, $D$, is common to all three regressions. Using the provided aggregate sums:\n$S_{\\ell} = \\sum_{j=1}^{M} \\ell_j = 10^8$\n$S_{\\ell^2} = \\sum_{j=1}^{M} \\ell_j^2 = 1.5 \\times 10^{10}$\n$M = 10^6$\n\n$$D = M S_{\\ell^2} - (S_{\\ell})^2 = (10^6)(1.5 \\times 10^{10}) - (10^8)^2 = 1.5 \\times 10^{16} - 1 \\times 10^{16} = 5 \\times 10^{15}$$\n\nNow, we calculate the slope for each case.\n\n1.  **Slope for Trait A ($b_1$)**: Regression of $\\chi^{(1)}_j$ on $\\ell_j$.\n    The numerator is $N_1^{num} = M S_{\\ell y1} - S_{\\ell} S_{y1}$.\n    Using $S_{y1} = \\sum \\chi^{(1)}_j = 7 \\times 10^6$ and $S_{\\ell y1} = \\sum \\ell_j \\chi^{(1)}_j = 10^9$:\n    $$N_1^{num} = (10^6)(10^9) - (10^8)(7 \\times 10^6) = 10^{15} - 7 \\times 10^{14} = 3 \\times 10^{14}$$\n    $$b_1 = \\frac{N_1^{num}}{D} = \\frac{3 \\times 10^{14}}{5 \\times 10^{15}} = 0.06$$\n\n2.  **Slope for Trait B ($b_2$)**: Regression of $\\chi^{(2)}_j$ on $\\ell_j$.\n    The numerator is $N_2^{num} = M S_{\\ell y2} - S_{\\ell} S_{y2}$.\n    Using $S_{y2} = \\sum \\chi^{(2)}_j = 3 \\times 10^6$ and $S_{\\ell y2} = \\sum \\ell_j \\chi^{(2)}_j = 4 \\times 10^8$:\n    $$N_2^{num} = (10^6)(4 \\times 10^8) - (10^8)(3 \\times 10^6) = 4 \\times 10^{14} - 3 \\times 10^{14} = 10^{14}$$\n    $$b_2 = \\frac{N_2^{num}}{D} = \\frac{10^{14}}{5 \\times 10^{15}} = 0.02$$\n\n3.  **Slope for Cross-Trait ($b_{12}$)**: Regression of $\\chi^{(12)}_j$ on $\\ell_j$.\n    The numerator is $N_{12}^{num} = M S_{\\ell x} - S_{\\ell} S_{x}$.\n    Using $S_{x} = \\sum \\chi^{(12)}_j = 1.0383 \\times 10^6$ and $S_{\\ell x} = \\sum \\ell_j \\chi^{(12)}_j = 1.55745 \\times 10^8$:\n    $$N_{12}^{num} = (10^6)(1.55745 \\times 10^8) - (10^8)(1.0383 \\times 10^6) = 1.55745 \\times 10^{14} - 1.0383 \\times 10^{14} = 5.1915 \\times 10^{13}$$\n    $$b_{12} = \\frac{N_{12}^{num}}{D} = \\frac{5.1915 \\times 10^{13}}{5 \\times 10^{15}} = 0.010383$$\n\n**Calculation of Genetic Parameters**\n\nFrom the theoretical models, we have the following relations for the slopes:\n$$b_1 = \\frac{N_1 h_1^2}{M} \\quad \\implies \\quad h_1^2 = \\frac{b_1 M}{N_1}$$\n$$b_2 = \\frac{N_2 h_2^2}{M} \\quad \\implies \\quad h_2^2 = \\frac{b_2 M}{N_2}$$\n$$b_{12} = \\frac{\\sqrt{N_1 N_2} \\rho_{g12}}{M} \\quad \\implies \\quad \\rho_{g12} = \\frac{b_{12} M}{\\sqrt{N_1 N_2}}$$\n\nThe genetic correlation $\\rho_g$ is defined as the standardized genetic covariance:\n$$\\rho_g = \\frac{\\rho_{g12}}{\\sqrt{h_1^2 h_2^2}}$$\n\nSubstituting the expressions for $h_1^2$, $h_2^2$, and $\\rho_{g12}$:\n$$\\rho_g = \\frac{\\frac{b_{12} M}{\\sqrt{N_1 N_2}}}{\\sqrt{\\left(\\frac{b_1 M}{N_1}\\right) \\left(\\frac{b_2 M}{N_2}\\right)}} = \\frac{\\frac{b_{12} M}{\\sqrt{N_1 N_2}}}{\\frac{M}{\\sqrt{N_1 N_2}} \\sqrt{b_1 b_2}} = \\frac{b_{12}}{\\sqrt{b_1 b_2}}$$\n\nThis shows that the genetic correlation can be calculated directly from the regression slopes.\n\nPlugging in the estimated slope values:\n$$b_1 = 0.06$$\n$$b_2 = 0.02$$\n$$b_{12} = 0.010383$$\n$$\\rho_g = \\frac{0.010383}{\\sqrt{0.06 \\times 0.02}} = \\frac{0.010383}{\\sqrt{0.0012}} \\approx \\frac{0.010383}{0.034641016} \\approx 0.299732$$\nRounding to four significant figures, the estimated genetic correlation is $\\rho_g = 0.2997$.\n\n### Part 2: Interpretation of $\\rho_g > 0$ with $r_p < 0$\n\nThe phenotypic correlation ($r_p$) between two traits is a function of both shared genetic influences (pleiotropy) and shared environmental influences. The relationship can be expressed by the quantitative genetic model:\n$$r_p = \\rho_g \\sqrt{h_1^2 h_2^2} + \\rho_e \\sqrt{e_1^2 e_2^2}$$\nwhere $\\rho_e$ is the environmental correlation, and $e_k^2 = 1 - h_k^2$ is the proportion of variance attributable to environmental factors (environmentability).\n\nWe are given $r_p = -0.12$ and have estimated $\\rho_g \\approx 0.2997$. The positive genetic correlation indicates that, on average, genetic variants that increase trait A also tend to increase trait B.\n\nFor the observed phenotypic correlation $r_p$ to be negative despite a positive genetic correlation $\\rho_g$, the environmental correlation $\\rho_e$ must be negative and its contribution must be larger in magnitude and opposite in sign to the genetic contribution.\n\nThis situation arises when environmental factors that tend to increase trait A are associated with environmental factors that decrease trait B (and vice versa), and this antagonistic environmental effect on the phenotypes outweighs the synergistic effect of the shared genetics. For example, a medication (an environmental factor) taken for a condition genetically correlated with high values of trait A might have a side effect that lowers trait B, inducing a negative environmental correlation. If this effect is strong enough, it can make the overall phenotypic correlation negative.", "answer": "$$\\boxed{0.2997}$$", "id": "4328573"}]}