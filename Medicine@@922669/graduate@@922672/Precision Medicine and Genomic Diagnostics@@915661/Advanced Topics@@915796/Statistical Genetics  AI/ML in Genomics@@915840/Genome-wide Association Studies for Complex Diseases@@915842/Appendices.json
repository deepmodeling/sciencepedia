{"hands_on_practices": [{"introduction": "A primary goal of a Genome-Wide Association Study (GWAS) is to identify genetic variants associated with a trait. However, a statistically significant association begs the question: how much does this variant actually contribute to the trait's variation in the population? This exercise walks you through the derivation of the proportion of variance explained ($R^2$) by a single SNP, a fundamental metric for quantifying the impact of a GWAS finding. Mastering this helps you connect a variant's per-allele effect size and its frequency to its overall importance in shaping the phenotype. [@problem_id:4346456]", "problem": "Consider a single-variant additive model in a Genome-Wide Association Study (GWAS) of a standardized quantitative trait. Let the trait for individual $i$ be $Y_i$, standardized so that $\\operatorname{E}[Y_i]=0$ and $\\operatorname{Var}(Y_i)=1$. Let the genotype be coded additively as $G_i\\in\\{0,1,2\\}$ counting minor alleles at a single biallelic locus with minor allele frequency $p$ in Hardy–Weinberg equilibrium. Assume the linear regression model $Y_i=\\mu+\\beta G_i+\\varepsilon_i$ with $\\operatorname{E}[\\varepsilon_i\\mid G_i]=0$, and let $\\hat{\\beta}$ denote the ordinary least squares estimator obtained from regressing $Y$ on $G$.\n\nStarting from the core definitions of ordinary least squares, variance, and covariance, and using Hardy–Weinberg equilibrium to express the distributional properties of $G$, derive a closed-form expression for the per-allele proportion of variance in $Y$ explained by this single variant, expressed as the coefficient of determination $R^2$ in terms of $p$ and $\\hat{\\beta}$. Then, based on your derivation, explain how $R^2$ translates to phenotypic impact in a population when the trait is standardized. Provide your final result as a single analytic expression in terms of $p$ and $\\hat{\\beta}$. No numerical evaluation is required.", "solution": "The problem requires the derivation of a closed-form expression for the proportion of variance in a standardized quantitative trait $Y$ explained by a single genetic variant $G$, denoted by the coefficient of determination $R^2$. The expression is to be in terms of the minor allele frequency, $p$, and the ordinary least squares (OLS) estimator of the effect size, $\\hat{\\beta}$.\n\nFirst, we establish the fundamental definitions. The coefficient of determination, $R^2$, in a simple linear regression model is the fraction of total variance in the dependent variable $Y$ that is explained by the independent variable $G$. It is formally defined as:\n$$R^2 = \\frac{\\operatorname{Var}(\\hat{Y})}{\\operatorname{Var}(Y)}$$\nwhere $\\hat{Y}$ represents the predicted values of $Y$ from the regression model. In this problem, the linear model is given by $Y_i = \\mu + \\beta G_i + \\varepsilon_i$. The corresponding fitted OLS model is $\\hat{Y}_i = \\hat{\\mu} + \\hat{\\beta} G_i$, where $\\hat{\\mu}$ and $\\hat{\\beta}$ are the OLS estimators for the intercept and slope, respectively.\n\nThe variance of the predicted values, $\\operatorname{Var}(\\hat{Y})$, can be expressed in terms of the variance of the predictor variable $G$:\n$$\\operatorname{Var}(\\hat{Y}) = \\operatorname{Var}(\\hat{\\mu} + \\hat{\\beta} G) = \\operatorname{Var}(\\hat{\\beta} G) = \\hat{\\beta}^2 \\operatorname{Var}(G)$$\nHere, we treat the OLS estimator $\\hat{\\beta}$ as a fixed quantity derived from a given sample, and calculate the variance over the distribution of $G$.\n\nSubstituting this into the definition of $R^2$, we get:\n$$R^2 = \\frac{\\hat{\\beta}^2 \\operatorname{Var}(G)}{\\operatorname{Var}(Y)}$$\nThe problem states that the trait $Y_i$ is standardized, which means its variance is unity: $\\operatorname{Var}(Y_i) = 1$. Therefore, the expression for $R^2$ simplifies to:\n$$R^2 = \\hat{\\beta}^2 \\operatorname{Var}(G)$$\nTo proceed, we must derive the variance of the genotype variable, $\\operatorname{Var}(G)$. The problem specifies that the genotype $G_i$ is coded additively as $0$, $1$, or $2$, counting the number of minor alleles at a single biallelic locus. The population is assumed to be in Hardy–Weinberg equilibrium (HWE) with a minor allele frequency of $p$.\n\nUnder HWE, the probabilities of the three possible genotypes are:\n\\begin{itemize}\n    \\item $P(G=0) = (1-p)^2$ (homozygous for the major allele)\n    \\item $P(G=1) = 2p(1-p)$ (heterozygous)\n    \\item $P(G=2) = p^2$ (homozygous for the minor allele)\n\\end{itemize}\n\nWe can now calculate the expected value of $G$, $\\operatorname{E}[G]$:\n$$\\operatorname{E}[G] = \\sum_{g \\in \\{0, 1, 2\\}} g \\cdot P(G=g)$$\n$$\\operatorname{E}[G] = (0) \\cdot (1-p)^2 + (1) \\cdot 2p(1-p) + (2) \\cdot p^2$$\n$$\\operatorname{E}[G] = 2p - 2p^2 + 2p^2 = 2p$$\n\nNext, we calculate the expected value of $G^2$, $\\operatorname{E}[G^2]$:\n$$\\operatorname{E}[G^2] = \\sum_{g \\in \\{0, 1, 2\\}} g^2 \\cdot P(G=g)$$\n$$\\operatorname{E}[G^2] = (0)^2 \\cdot (1-p)^2 + (1)^2 \\cdot 2p(1-p) + (2)^2 \\cdot p^2$$\n$$\\operatorname{E}[G^2] = 2p(1-p) + 4p^2 = 2p - 2p^2 + 4p^2 = 2p + 2p^2$$\n\nThe variance of $G$ is given by the formula $\\operatorname{Var}(G) = \\operatorname{E}[G^2] - (\\operatorname{E}[G])^2$. Substituting the derived quantities:\n$$\\operatorname{Var}(G) = (2p + 2p^2) - (2p)^2$$\n$$\\operatorname{Var}(G) = 2p + 2p^2 - 4p^2 = 2p - 2p^2$$\n$$\\operatorname{Var}(G) = 2p(1-p)$$\nThis is a standard result for the variance of an additively coded genotype under HWE.\n\nNow, we substitute this expression for $\\operatorname{Var}(G)$ back into our simplified equation for $R^2$:\n$$R^2 = \\hat{\\beta}^2 \\cdot [2p(1-p)]$$\n$$R^2 = 2p(1-p)\\hat{\\beta}^2$$\nThis is the closed-form expression for the proportion of variance explained by the single variant in terms of the minor allele frequency $p$ and the OLS estimated effect size $\\hat{\\beta}$.\n\nRegarding the interpretation of this result, $R^2$ represents the variant's contribution to the population's phenotypic variance. Since the trait is standardized ($\\operatorname{Var}(Y)=1$), the aforementioned $R^2$ is not just a proportion but also the absolute amount of variance explained by the genetic locus. The formula $R^2 = 2p(1-p)\\hat{\\beta}^2$ shows that this phenotypic impact is a product of two factors:\n$1$. $\\hat{\\beta}^2$: The squared per-allele effect size. Since $Y$ is standardized to have a standard deviation of $1$, $\\hat{\\beta}$ quantifies the change in the trait in standard deviation units for each additional minor allele. This term reflects the intrinsic biological or functional impact of the allele substitution.\n$2$. $2p(1-p)$: The variance of the genotype count $G$. This term is a function of the minor allele frequency $p$ and is maximized when $p=0.5$. It acts as a population-level scalar for the biological effect.\n\nThis relationship demonstrates that the overall contribution of a genetic variant to the heritable variance of a trait in a population depends critically on both its per-allele effect size ($\\beta$) and its frequency ($p$). A variant with a large biological effect (large $\\beta$) may explain very little population variance if it is very rare ($p \\to 0$). Conversely, a common variant ($p$ near $0.5$) can explain a substantial amount of variance even with a modest per-allele effect size. This is a fundamental principle in the interpretation of genome-wide association studies, highlighting why GWAS is well-powered to detect common variants of modest effect but struggles to find rare variants unless their effects are very large.", "answer": "$$\\boxed{2p(1-p)\\hat{\\beta}^2}$$", "id": "4346456"}, {"introduction": "Designing a successful GWAS requires careful planning, and a critical first step is determining the necessary sample size. A study that is too small will be underpowered and fail to detect true associations, while one that is unnecessarily large wastes resources. This practice challenges you to perform a power calculation from first principles, linking the desired statistical power, significance threshold, allele frequency, and expected effect size to the number of participants needed. This skill is indispensable for writing research grants and planning robust genetic studies. [@problem_id:4346478]", "problem": "In a case-control Genome-Wide Association Study (GWAS) targeting a complex disease, consider testing a Single Nucleotide Polymorphism (SNP) under an additive logistic regression model where genotype is coded as $G \\in \\{0,1,2\\}$. Assume Hardy–Weinberg equilibrium, minor allele frequency $p=0.2$, balanced sampling with case fraction $\\phi=1/2$, and no population stratification. The effect size is summarized by the odds ratio $\\text{OR}=1.1$, corresponding to a log-odds coefficient $\\beta$ in the logistic model. Use a two-sided genome-wide significance threshold $\\alpha=5 \\times 10^{-8}$ and require statistical power $0.8$ to reject the null.\n\nStarting from the definition of the odds ratio in logistic regression, the variance of the genotype under Hardy–Weinberg equilibrium, and the large-sample behavior of the Wald test for a single-parameter hypothesis in logistic regression, derive the expression for the noncentrality parameter of the test statistic as a function of the total sample size $n$ under balanced case-control sampling. Then compute the expected number of cases required to achieve the specified power at genome-wide significance for this SNP, using the two-sided test. Express your final answer as a real number. Round your answer to three significant figures.", "solution": "To find the required number of cases, we must first derive the total sample size $n$ needed to achieve the specified statistical power. This requires calculating the noncentrality parameter (NCP) of the association test statistic.\n\n**1. Model Parameters and Test Statistic**\nThe logistic regression model relates the disease odds to the genotype $G$. The per-allele odds ratio ($\\text{OR}$) is related to the log-odds coefficient $\\beta$ by $\\beta = \\ln(\\text{OR})$. For $\\text{OR}=1.1$, we have:\n$$ \\beta = \\ln(1.1) \\approx 0.09531 $$\nThe association test for $H_0: \\beta=0$ is based on the Wald statistic $W = \\hat{\\beta} / \\mathrm{SE}(\\hat{\\beta})$, which is approximately standard normal under the null. Under the alternative hypothesis ($\\beta \\neq 0$), $W^2$ follows a non-central chi-squared distribution, $\\chi^2_1(\\lambda)$, where $\\lambda$ is the NCP.\n\n**2. Noncentrality Parameter (NCP)**\nThe NCP $\\lambda$ is given by $\\lambda = \\beta^2 / \\mathrm{Var}(\\hat{\\beta})$. For a case-control study, the variance of the coefficient estimate $\\hat{\\beta}$ is approximated by:\n$$ \\mathrm{Var}(\\hat{\\beta}) \\approx \\frac{1}{n \\phi (1-\\phi) \\mathrm{Var}_{pop}(G)} $$\nwhere $n$ is the total sample size, $\\phi$ is the case fraction, and $\\mathrm{Var}_{pop}(G)$ is the genotype variance in the general population.\nUnder Hardy–Weinberg equilibrium, the variance of the additively coded genotype $G$ with minor allele frequency $p$ is $\\mathrm{Var}_{pop}(G) = 2p(1-p)$. With $p=0.2$:\n$$ \\mathrm{Var}_{pop}(G) = 2(0.2)(1-0.2) = 0.32 $$\nSubstituting this into the NCP formula gives the NCP as a function of $n$:\n$$ \\lambda = n \\phi (1-\\phi) \\mathrm{Var}_{pop}(G) \\beta^2 $$\n\n**3. Sample Size Calculation**\nTo achieve statistical power $1-\\beta_{err}$ for a two-sided test at significance level $\\alpha$, the NCP must satisfy:\n$$ \\sqrt{\\lambda} \\approx z_{1-\\alpha/2} + z_{1-\\beta_{err}} $$\nwhere $z_q$ is the upper $(1-q)$-quantile of the standard normal distribution.\nThe problem specifies:\n- Significance level $\\alpha = 5 \\times 10^{-8}$, so we need the quantile for $1 - \\alpha/2 = 1 - 2.5 \\times 10^{-8}$. The value is $z_{1-\\alpha/2} \\approx 5.4513$.\n- Power $1-\\beta_{err} = 0.8$, so we need the quantile for $0.8$. The value is $z_{0.8} \\approx 0.8416$.\n\nThe required NCP is therefore:\n$$ \\lambda \\approx (z_{1-\\alpha/2} + z_{0.8})^2 \\approx (5.4513 + 0.8416)^2 = (6.2929)^2 \\approx 39.6006 $$\nWe can now solve for the total sample size $n$ by rearranging the NCP expression. Given balanced sampling ($\\phi=0.5$):\n$$ n = \\frac{\\lambda}{\\phi(1-\\phi) \\mathrm{Var}_{pop}(G) \\beta^2} = \\frac{\\lambda}{0.25 \\cdot \\mathrm{Var}_{pop}(G) \\cdot \\beta^2} $$\nSubstituting the numerical values:\n$$ n \\approx \\frac{39.6006}{0.25 \\times 0.32 \\times (\\ln(1.1))^2} $$\n$$ n \\approx \\frac{39.6006}{0.08 \\times (0.09531)^2} \\approx \\frac{39.6006}{0.00072672} \\approx 54493 $$\nThe problem asks for the expected number of cases. With balanced sampling, the number of cases is half the total sample size:\n$$ n_{cases} = n \\times \\phi = \\frac{n}{2} \\approx \\frac{54493}{2} \\approx 27246.5 $$\nRounding this result to three significant figures gives $27200$, or $2.72 \\times 10^4$.", "answer": "$$ \\boxed{2.72 \\times 10^{4}} $$", "id": "4346478"}, {"introduction": "A significant challenge in interpreting GWAS results is linkage disequilibrium (LD), where a block of correlated variants can make it difficult to identify the true causal SNP. Conditional analysis is a powerful technique used to dissect these association signals by statistically adjusting for the effects of lead SNPs. This exercise guides you in deriving and applying the formula for summary-based conditional analysis using an external LD reference panel, providing a hands-on understanding of how researchers fine-map causal variants from GWAS summary statistics. [@problem_id:4346493]", "problem": "A Genome-Wide Association Study (GWAS) is conducted for a complex disease with small per-allele effects, and summary statistics are available from a single-variant analysis. You are asked to perform a summary-based conditional analysis using an external Linkage Disequilibrium (LD) reference panel to estimate the adjusted effect of a target single nucleotide polymorphism (SNP) after conditioning on a lead SNP at the same locus. Work from first principles of multiple linear regression and covariance, without assuming any pre-derived summary-based conditional formula.\n\nAssume the following scientifically standard approximations and conditions:\n- The phenotype and the genotypes of the two SNPs are approximately standardized to zero mean and unit variance, and effect sizes are small, so that the single-SNP test statistic for SNP $i$ satisfies $z_i \\approx \\sqrt{n} \\, \\mathrm{corr}(X_i, Y)$, where $n$ is the sample size, $X_i$ is the standardized genotype dosage for SNP $i$, and $Y$ is the standardized phenotype.\n- Under multiple linear regression with standardized predictors, the population covariance of predictors is the LD correlation matrix.\n- The external LD reference panel provides the $2 \\times 2$ correlation matrix for the lead SNP $L$ and the target SNP $T$, with off-diagonal correlation $\\rho$.\n\nData:\n- Sample size: $n = 80{,}000$.\n- Single-variant summary statistics: $z_L = 8.5$, $z_T = 4.0$.\n- External LD correlation between the two SNPs: $\\rho = 0.65$.\n\nTasks:\n1. Starting from the normal equations for ordinary least squares with standardized predictors, derive an expression for the adjusted effect estimate $\\hat{\\beta}_T$ of the target SNP $T$ after conditioning on the lead SNP $L$, expressed in terms of $n$, $z_L$, $z_T$, and $\\rho$ only.\n2. Using the provided numerical values and the external LD correlation matrix, compute the adjusted effect estimate $\\hat{\\beta}_T$.\n\nState any additional assumptions you make and justify them. Briefly discuss, in words, how a mismatch between the external LD correlation $\\rho$ and the true study LD correlation would influence the adjusted estimate, focusing on the direction and magnitude of potential bias. Your final reported answer must be the single numerical value for $\\hat{\\beta}_T$, expressed without units, and rounded to three significant figures.", "solution": "This solution derives the adjusted effect size of a target SNP ($T$) conditional on a lead SNP ($L$) using summary-level GWAS data and an external Linkage Disequilibrium (LD) reference panel, starting from the principles of multiple linear regression.\n\n**1. Derivation of the Adjusted Effect Estimate**\n\nLet $Y$ be the standardized phenotype, and $X_L$ and $X_T$ be the standardized genotypes for the lead and target SNPs. The multiple linear regression model is:\n$$ Y = X_L \\beta_L + X_T \\beta_T + \\epsilon $$\nwhere $\\beta_L$ and $\\beta_T$ are the joint (adjusted) effect sizes. The ordinary least squares (OLS) estimates $\\hat{\\beta} = (\\hat{\\beta}_L, \\hat{\\beta}_T)'$ are found by solving the normal equations: $(X'X)\\hat{\\beta} = X'Y$.\n\nFor a large sample size $n$ and standardized variables, we can make the following approximations:\n- $\\frac{1}{n}X'X \\approx R$, where $R$ is the LD correlation matrix of the predictors: $R = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}$.\n- $\\frac{1}{n}X'Y \\approx \\begin{pmatrix} \\mathrm{corr}(X_L, Y) \\\\ \\mathrm{corr}(X_T, Y) \\end{pmatrix}$.\n\nThe single-variant z-scores relate to these correlations by $z_i \\approx \\sqrt{n} \\, \\mathrm{corr}(X_i, Y)$, which implies $\\mathrm{corr}(X_i, Y) \\approx z_i/\\sqrt{n}$.\n\nSubstituting these into the normal equations (after dividing by $n$) gives:\n$$ R \\hat{\\beta} \\approx \\frac{1}{\\sqrt{n}} \\begin{pmatrix} z_L \\\\ z_T \\end{pmatrix} $$\nTo solve for $\\hat{\\beta}$, we multiply by the inverse of the correlation matrix, $R^{-1}$:\n$$ \\hat{\\beta} \\approx R^{-1} \\frac{1}{\\sqrt{n}} \\begin{pmatrix} z_L \\\\ z_T \\end{pmatrix} $$\nThe inverse of the $2 \\times 2$ matrix $R$ is $R^{-1} = \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix}$.\nPerforming the matrix multiplication gives the adjusted effects:\n$$ \\begin{pmatrix} \\hat{\\beta}_L \\\\ \\hat{\\beta}_T \\end{pmatrix} \\approx \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix} \\frac{1}{\\sqrt{n}} \\begin{pmatrix} z_L \\\\ z_T \\end{pmatrix} = \\frac{1}{\\sqrt{n}(1-\\rho^2)} \\begin{pmatrix} z_L - \\rho z_T \\\\ z_T - \\rho z_L \\end{pmatrix} $$\nFrom this, we extract the expression for the adjusted effect of the target SNP $T$:\n$$ \\hat{\\beta}_T \\approx \\frac{z_T - \\rho z_L}{\\sqrt{n}(1-\\rho^2)} $$\n\n**2. Numerical Calculation**\nUsing the provided data: $n = 80{,}000$, $z_L = 8.5$, $z_T = 4.0$, and $\\rho = 0.65$.\n$$ \\hat{\\beta}_T \\approx \\frac{4.0 - (0.65)(8.5)}{\\sqrt{80000}(1 - 0.65^2)} $$\n$$ \\hat{\\beta}_T \\approx \\frac{4.0 - 5.525}{282.8427 \\times (1 - 0.4225)} $$\n$$ \\hat{\\beta}_T \\approx \\frac{-1.525}{282.8427 \\times 0.5775} \\approx \\frac{-1.525}{163.3417} \\approx -0.0093362 $$\nRounding to three significant figures, the adjusted effect estimate is $\\hat{\\beta}_T \\approx -0.00934$.\n\n**3. Discussion of LD Mismatch**\nThe accuracy of this summary-based conditional analysis depends critically on the assumption that the external LD correlation ($\\rho_{ext}$) is a good proxy for the true in-sample LD ($\\rho_{true}$). If $\\rho_{ext} \\neq \\rho_{true}$, bias is introduced.\n- **Direction of Bias**: The formula for $\\hat{\\beta}_T$ is driven by the term $z_T - \\rho z_L$, which aims to remove the part of SNP $T$'s signal that is due to LD with SNP $L$. If the external LD is an overestimate ($\\rho_{ext} > \\rho_{true}$), the analysis over-corrects, biasing the estimate $\\hat{\\beta}_T$ downwards (more negative or less positive). Conversely, if the external LD is an underestimate ($\\rho_{ext}  \\rho_{true}$), the analysis under-corrects, biasing $\\hat{\\beta}_T$ upwards.\n- **Magnitude of Bias**: The bias is proportional to the difference $|\\rho_{ext} - \\rho_{true}|$ and is amplified by the magnitude of the lead SNP's z-score ($z_L$). This highlights the importance of using a well-matched LD reference panel, particularly when analyzing strong signals in populations with distinct genetic ancestries and LD patterns.", "answer": "$$\\boxed{-0.00934}$$", "id": "4346493"}]}