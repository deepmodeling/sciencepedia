{"hands_on_practices": [{"introduction": "This first practice provides a foundational, hands-on experience in building a splice site predictor from the ground up based on a log-likelihood scoring function, a cornerstone of bioinformatics. By systematically introducing single-nucleotide variants in a process known as *in silico* saturation mutagenesis, you will quantify the sensitivity of each position within the splice donor motif. This exercise is key to understanding which parts of a sequence signal are most critical for the model's prediction [@problem_id:4385861].", "problem": "You are tasked with designing and implementing a complete simulation and analysis pipeline, grounded in first principles of molecular genetics and probabilistic modeling, to quantify position-wise functional sensitivity of the $5'$ splice donor motif to single-nucleotide changes. The computational objective is to identify, from a provided set of sequences, the motif positions at which single-nucleotide variants (SNVs) induce the largest expected perturbation in a log-likelihood ratio score defined under a position-specific multinomial model with independent columns and a fixed genomic background.\n\nStart from the following foundational bases: the Central Dogma of Molecular Biology (deoxyribonucleic acid to ribonucleic acid to protein), the existence of conserved splice site motifs around exon-intron junctions, and the widely used sequence motif scoring paradigm based on log-likelihood ratios under independent-position multinomial models with a fixed background nucleotide distribution. You may use these to construct a fully specified definition of the scoring function and the induced change in score caused by a single-nucleotide substitution. Do not assume any other specialized results.\n\nYour program must implement the following, adhering to scientific realism and internal consistency:\n- Model the $5'$ donor motif as a length-$L$ position-specific multinomial model with independent columns. Use $L=9$ and the alphabet $\\{A,C,G,T\\}$.\n- For any sequence $x$ of length $L$, define a log-likelihood ratio score $S(x)$ that sums contributions across positions by comparing the position-specific probabilities to the fixed background. You must derive this score from the above modeling assumptions without importing any unproven shortcut formulae.\n- For a single-nucleotide variant at position $i$ that changes the reference base $b$ to an alternate base $a \\neq b$, define the score change $\\Delta S = S(x^{(i \\rightarrow a)}) - S(x)$, where $x^{(i \\rightarrow a)}$ is the sequence with the base at position $i$ replaced by $a$. Derive from first principles how to compute $\\Delta S$ in this model.\n- For each position $i \\in \\{0,1,\\ldots,L-1\\}$ in a given reference sequence $x$, enumerate all three possible alternate nucleotides to generate the $\\Delta S$ values at that position. Use these to define a per-position sensitivity metric $E_i$ as the expected absolute score change at position $i$ under a uniform distribution over the three alternate bases, i.e., the mean of the three absolute values of $\\Delta S$ at that position.\n- Let $\\tau$ be the empirical $q$-quantile of the set $\\{E_0,\\ldots,E_{L-1}\\}$ with $q=0.75$. A position $i$ is labeled \"high-sensitivity\" if $E_i \\ge \\tau$.\n- Your implementation must use natural logarithms for all computations of log-likelihood ratios and must assume that all provided probabilities are strictly positive, ensuring numerical well-posedness.\n\nUse the following fixed parameters for all computations:\n- Length $L=9$ with positions indexed $0$ through $8$.\n- Background nucleotide distribution $q$ given by $q(A)=0.3$, $q(C)=0.2$, $q(G)=0.2$, $q(T)=0.3$.\n- Position-specific motif probabilities $P_i(b)$ for each position $i \\in \\{0,\\ldots,8\\}$ and base $b \\in \\{A,C,G,T\\}$:\n    - Position $0$: $P_0(A)=0.4$, $P_0(C)=0.4$, $P_0(G)=0.1$, $P_0(T)=0.1$.\n    - Position $1$: $P_1(A)=0.8$, $P_1(C)=0.0666666667$, $P_1(G)=0.0666666667$, $P_1(T)=0.0666666667$.\n    - Position $2$: $P_2(A)=0.0666666667$, $P_2(C)=0.0666666667$, $P_2(G)=0.8$, $P_2(T)=0.0666666667$.\n    - Position $3$: $P_3(A)=0.0166666667$, $P_3(C)=0.0166666667$, $P_3(G)=0.95$, $P_3(T)=0.0166666667$.\n    - Position $4$: $P_4(A)=0.0166666667$, $P_4(C)=0.0166666667$, $P_4(G)=0.0166666667$, $P_4(T)=0.95$.\n    - Position $5$: $P_5(A)=0.45$, $P_5(C)=0.05$, $P_5(G)=0.45$, $P_5(T)=0.05$.\n    - Position $6$: $P_6(A)=0.6$, $P_6(C)=0.1$, $P_6(G)=0.2$, $P_6(T)=0.1$.\n    - Position $7$: $P_7(A)=0.2$, $P_7(C)=0.1$, $P_7(G)=0.6$, $P_7(T)=0.1$.\n    - Position $8$: $P_8(A)=0.1$, $P_8(C)=0.1$, $P_8(G)=0.2$, $P_8(T)=0.6$.\n\nTest suite. Your program must compute the sets of high-sensitivity positions for each of the following reference sequences (each of length $9$ over $\\{A,C,G,T\\}$), using the above $P_i(b)$ and $q$:\n- Case $1$: $x^{(1)} = \\text{\"CAGGTAAGT\"}$.\n- Case $2$: $x^{(2)} = \\text{\"CAGGTCAGT\"}$.\n- Case $3$: $x^{(3)} = \\text{\"TTAGGTCGT\"}$.\n\nFor each case, output the list of $0$-indexed positions labeled as high-sensitivity.\n\nFinal output format. Your program should produce a single line of output containing a comma-separated list enclosed in square brackets, without spaces, where each element is itself a list of integer positions for one test case, in order of the cases. The lists for individual cases should have their elements in strictly increasing order. For example, a valid shape is a list-of-lists with no spaces. The output must aggregate the results for the three cases in order into a single bracketed list. No units are involved, and angles are not used. All returned values are integers as specified.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in established principles of molecular genetics and probabilistic modeling, internally consistent, and well-posed, providing all necessary information for a unique solution.\n\nThe task is to identify positions in a deoxyribonucleic acid (DNA) sequence that are highly sensitive to single-nucleotide variants (SNVs) with respect to a splice site scoring model. The analysis is based on a log-likelihood ratio score derived from a position-specific multinomial model.\n\nWe begin by formally deriving the required mathematical quantities from first principles.\n\n**1. Log-Likelihood Ratio Score $S(x)$**\n\nThe problem specifies a scoring paradigm based on the log-likelihood ratio between a motif model ($H_M$) and a background model ($H_B$). Let $x = x_0x_1...x_{L-1}$ be a DNA sequence of length $L=9$ over the alphabet $\\mathcal{A} = \\{A, C, G, T\\}$.\n\nUnder the motif model, the probability of observing sequence $x$ is given by the product of position-specific probabilities, due to the assumption of independent columns:\n$$P(x | H_M) = \\prod_{i=0}^{L-1} P_i(x_i)$$\nwhere $P_i(b)$ is the given probability of observing base $b \\in \\mathcal{A}$ at position $i$.\n\nUnder the background model, the probability of observing sequence $x$ is given by the product of fixed background probabilities:\n$$P(x | H_B) = \\prod_{i=0}^{L-1} q(x_i)$$\nwhere $q(b)$ is the given background probability of base $b$.\n\nThe likelihood ratio ($LR$) is the ratio of these two probabilities:\n$$LR(x) = \\frac{P(x | H_M)}{P(x | H_B)} = \\frac{\\prod_{i=0}^{L-1} P_i(x_i)}{\\prod_{i=0}^{L-1} q(x_i)} = \\prod_{i=0}^{L-1} \\frac{P_i(x_i)}{q(x_i)}$$\n\nThe log-likelihood ratio score, $S(x)$, is defined as the natural logarithm of the likelihood ratio. Using the property $\\ln(ab) = \\ln(a) + \\ln(b)$, the product becomes a sum:\n$$S(x) = \\ln(LR(x)) = \\ln\\left(\\prod_{i=0}^{L-1} \\frac{P_i(x_i)}{q(x_i)}\\right) = \\sum_{i=0}^{L-1} \\ln\\left(\\frac{P_i(x_i)}{q(x_i)}\\right)$$\nThis decomposes the total score into a sum of position-wise scores, $S_i(b) = \\ln(P_i(b)/q(b))$, such that $S(x) = \\sum_{i=0}^{L-1} S_i(x_i)$.\n\n**2. Score Change $\\Delta S$ due to a Single-Nucleotide Variant (SNV)**\n\nConsider a reference sequence $x$ and a variant sequence $x^{(i \\rightarrow a)}$ that is identical to $x$ except at position $i$, where the original base $b = x_i$ is replaced by an alternate base $a \\neq b$.\n\nThe score of the reference sequence is $S(x) = \\sum_{j=0}^{L-1} S_j(x_j)$.\nThe score of the variant sequence is $S(x^{(i \\rightarrow a)}) = \\sum_{j=0}^{L-1} S_j(x^{(i \\rightarrow a)}_j)$.\n\nSince $x_j = x^{(i \\rightarrow a)}_j$ for all $j \\neq i$, the terms in the sum are identical for all positions except $i$. The score change, $\\Delta S$, is defined as the difference between the variant and reference scores:\n$$\\Delta S = S(x^{(i \\rightarrow a)}) - S(x)$$\n$$\\Delta S = \\left(S_i(a) + \\sum_{j \\neq i} S_j(x_j)\\right) - \\left(S_i(b) + \\sum_{j \\neq i} S_j(x_j)\\right)$$\nThe summation terms cancel, yielding a simple expression that depends only on the scores at the mutated position $i$:\n$$\\Delta S = S_i(a) - S_i(b) = \\ln\\left(\\frac{P_i(a)}{q(a)}\\right) - \\ln\\left(\\frac{P_i(b)}{q(b)}\\right)$$\n\n**3. Position-Wise Sensitivity Metric $E_i$**\n\nFor each position $i \\in \\{0, 1, \\ldots, L-1\\}$ in a given reference sequence $x$, the sensitivity $E_i$ is defined as the expected absolute score change, assuming a uniform probability distribution over the three possible alternate bases. Let $b = x_i$ be the reference base at position $i$.\n$$E_i = \\mathbb{E}[|\\Delta S|] = \\frac{1}{3} \\sum_{a \\in \\mathcal{A}, a \\neq b} |\\Delta S_{i, a}|$$\nwhere $\\Delta S_{i, a}$ is the score change at position $i$ when base $b$ is changed to base $a$. Substituting the expression for $\\Delta S$:\n$$E_i = \\frac{1}{3} \\sum_{a \\in \\mathcal{A}, a \\neq b} \\left| \\ln\\left(\\frac{P_i(a)}{q(a)}\\right) - \\ln\\left(\\frac{P_i(b)}{q(b)}\\right) \\right|$$\nThis metric quantifies the average magnitude of perturbation to the splice site score caused by a random SNV at position $i$.\n\n**4. High-Sensitivity Position Identification**\n\nTo identify which positions are most sensitive, we first compute the set of sensitivity scores $\\{E_0, E_1, \\ldots, E_{L-1}\\}$ for a given reference sequence. A threshold $\\tau$ is then established as the empirical $q$-quantile of this set, with $q=0.75$. For a set of $n=9$ values, the $0.75$-quantile corresponds to the value at index $(n-1)q = (9-1)(0.75) = 6$ in the sorted list of $E_i$ values (using $0$-based indexing).\n\nA position $i$ is classified as \"high-sensitivity\" if its sensitivity score $E_i$ meets or exceeds this threshold: $E_i \\ge \\tau$.\n\n**Computational Procedure**\n\nThe overall algorithm for each test case is as follows:\n1.  For the given reference sequence $x$ of length $L=9$.\n2.  For each position $i$ from $0$ to $8$:\n    a. Identify the reference base $b = x_i$.\n    b. Calculate the three $\\Delta S$ values for mutating $b$ to each of the three alternate bases $a$.\n    c. Compute $E_i$ by taking the arithmetic mean of the absolute values of the three $\\Delta S$ values.\n3.  Collect the nine sensitivity scores $\\{E_0, E_1, \\ldots, E_8\\}$.\n4.  Sort these scores to find the threshold $\\tau$, which is the 7th value in the sorted list (index $6$).\n5.  Identify all positions $i$ for which $E_i \\ge \\tau$.\n6.  Return the list of these positions, sorted in increasing order.\n\nThis procedure will be applied to each of the three provided reference sequences using the specified model parameters.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the splice site sensitivity problem by implementing the derived model.\n    \"\"\"\n    # Define problem parameters\n    L = 9\n    ALPHABET = ['A', 'C', 'G', 'T']\n    BASE_TO_IDX = {base: i for i, base in enumerate(ALPHABET)}\n\n    # Background probabilities q(b)\n    q_dist = np.array([0.3, 0.2, 0.2, 0.3])\n\n    # Position-specific probabilities P_i(b)\n    p_matrix = np.array([\n        # A, C, G, T\n        [0.4, 0.4, 0.1, 0.1],                       # Pos 0\n        [0.8, 1/15, 1/15, 1/15],                     # Pos 1\n        [1/15, 1/15, 0.8, 1/15],                     # Pos 2\n        [1/60, 1/60, 0.95, 1/60],                    # Pos 3\n        [1/60, 1/60, 1/60, 0.95],                    # Pos 4\n        [0.45, 0.05, 0.45, 0.05],                    # Pos 5\n        [0.6, 0.1, 0.2, 0.1],                        # Pos 6\n        [0.2, 0.1, 0.6, 0.1],                        # Pos 7\n        [0.1, 0.1, 0.2, 0.6]                         # Pos 8\n    ])\n\n    test_cases = [\n        \"CAGGTAAGT\",\n        \"CAGGTCAGT\",\n        \"TTAGGTCGT\",\n    ]\n\n    # Pre-compute the log-likelihood ratio matrix S_i(b) = ln(P_i(b)/q(b))\n    # Using broadcasting for element-wise division.\n    log_ratio_matrix = np.log(p_matrix / q_dist)\n\n    def calculate_high_sensitivity_positions(ref_seq, l, alphabet, base_to_idx, log_ratios):\n        \"\"\"\n        Calculates high-sensitivity positions for a single reference sequence.\n        \"\"\"\n        e_scores = np.zeros(l)\n\n        for i in range(l):\n            ref_base = ref_seq[i]\n            ref_base_idx = base_to_idx[ref_base]\n            ref_score = log_ratios[i, ref_base_idx]\n            \n            abs_delta_s_sum = 0.0\n            num_alternates = 0\n\n            for alt_base in alphabet:\n                if alt_base != ref_base:\n                    alt_base_idx = base_to_idx[alt_base]\n                    alt_score = log_ratios[i, alt_base_idx]\n                    delta_s = alt_score - ref_score\n                    abs_delta_s_sum += abs(delta_s)\n                    num_alternates += 1\n            \n            e_scores[i] = abs_delta_s_sum / num_alternates\n\n        # Calculate the threshold tau (0.75-quantile)\n        tau = np.quantile(e_scores, 0.75, method='linear')\n        \n        # Find positions where E_i >= tau\n        # Use a small tolerance for floating point comparisons to be robust\n        high_sensitivity_indices = np.where(e_scores >= tau - 1e-9)[0]\n        \n        return sorted(list(high_sensitivity_indices))\n\n    # Process each test case\n    all_results = []\n    for seq in test_cases:\n        result = calculate_high_sensitivity_positions(seq, L, ALPHABET, BASE_TO_IDX, log_ratio_matrix)\n        all_results.append(result)\n\n    # Format the final output string as specified: [[pos1,pos2],[pos3],...]\n    result_strings = []\n    for res_list in all_results:\n        inner_str = \",\".join(map(str, res_list))\n        result_strings.append(f\"[{inner_str}]\")\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "4385861"}, {"introduction": "Moving from model construction to evaluation, this exercise tackles one of the most significant challenges in genomic diagnostics: extreme class imbalance. You will derive the relationship between a classifier's performance metrics (True Positive Rate, $TPR$, and False Positive Rate, $FPR$) and its practical utility (precision) to see firsthand why metrics like the Receiver Operating Characteristic Area Under the Curve (ROC-AUC) can be misleading. This practice demonstrates why the Precision-Recall curve is an indispensable tool for comparing models intended for genome-wide scanning [@problem_id:4385852].", "problem": "In a whole-genome clinical pipeline for variant interpretation, a splice site predictor ranks candidate donor sites genome-wide. Let the prevalence of true donor sites among all candidate loci be $\\pi$, with $\\pi = 10^{-4}$, reflecting extreme class imbalance. Two models, $M_1$ and $M_2$, output continuous scores that are thresholded to call positives. At a clinically considered operating threshold $\\tau_1$, $M_1$ achieves $\\mathrm{TPR} = 0.95$ and $\\mathrm{FPR} = 10^{-3}$. At another clinically considered threshold $\\tau_2$, $M_2$ achieves $\\mathrm{TPR} = 0.85$ and $\\mathrm{FPR} = 10^{-5}$. Both models have similarly high Receiver Operating Characteristic area under the curve (ROC-AUC) near $0.99$ when evaluated on held-out data. Using only first principles—namely, the definitions of True Positive Rate ($\\mathrm{TPR}$), False Positive Rate ($\\mathrm{FPR}$), precision (positive predictive value; $\\mathrm{PPV}$), recall (sensitivity), and Bayes’ theorem for conditional probabilities—derive how class imbalance (i.e., small $\\pi$) governs precision as a function of $\\mathrm{TPR}$, $\\mathrm{FPR}$, and $\\pi$. Then, use your derivation to compute the expected precision at $(\\mathrm{TPR}=0.95, \\mathrm{FPR}=10^{-3}, \\pi=10^{-4})$ and at $(\\mathrm{TPR}=0.85, \\mathrm{FPR}=10^{-5}, \\pi=10^{-4})$. Finally, based on your derivation and computations, identify all correct statements about why Precision-Recall area under the curve (PR-AUC) is preferable to ROC-AUC for comparing splice site predictors under extreme imbalance.\n\nSelect ALL that apply.\n\nA. With $\\pi = 10^{-4}$, the expected precision at $(\\mathrm{TPR}=0.95, \\mathrm{FPR}=10^{-3})$ is approximately $0.087$, whereas at $(\\mathrm{TPR}=0.85, \\mathrm{FPR}=10^{-5})$ it is approximately $0.895$; therefore, under extreme imbalance, reducing $\\mathrm{FPR}$ has a dominant effect on precision.\n\nB. ROC-AUC is invariant to $\\pi$ and can rate both models similarly even when one yields many more false positives in absolute terms; PR-AUC has a chance baseline equal to $\\pi$ and thus better contextualizes performance when $\\pi \\ll 1$.\n\nC. When $\\pi$ is extremely small, precision is well approximated by $\\mathrm{TPR}/\\mathrm{FPR}$ and therefore does not depend on $\\pi$.\n\nD. The baseline PR-AUC of a non-informative classifier equals $1/2$, just like ROC-AUC, so PR-AUC offers no advantage for imbalanced data.\n\nE. In genome-wide splice site scanning, clinically useful thresholds often require $\\mathrm{FPR}$ in $[0, 10^{-5}]$; two models with similar ROC-AUC can have markedly different PR-AUC if one concentrates gains in this ultra–low $\\mathrm{FPR}$ regime, making PR-AUC more discriminative for model selection.", "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in the principles of machine learning model evaluation and biostatistics, specifically within the context of genomic diagnostics. The problem is well-posed, providing all necessary data ($\\pi$, $\\mathrm{TPR}$, $\\mathrm{FPR}$) for the required derivations and calculations. The language used is objective and precise. Therefore, a full solution will be derived.\n\nThe core of the problem is to relate precision, or positive predictive value ($\\mathrm{PPV}$), to the true positive rate ($\\mathrm{TPR}$), false positive rate ($\\mathrm{FPR}$), and the class prevalence ($\\pi$).\n\nLet $D$ be the event that a candidate locus is a true donor site (the positive class), and let $N$ be the event that it is not (the negative class). Let $+$ denote a positive prediction from a model. We are given the following definitions and values:\n-   Prevalence: $\\pi = P(D) = 10^{-4}$. Consequently, $P(N) = 1 - \\pi = 1 - 10^{-4} = 0.9999$.\n-   True Positive Rate (Recall, Sensitivity): $\\mathrm{TPR} = P(+|D)$.\n-   False Positive Rate: $\\mathrm{FPR} = P(+|N)$.\n-   Precision (Positive Predictive Value): $\\mathrm{PPV} = P(D|+)$.\n\nUsing Bayes' theorem for conditional probabilities, we can express the precision as:\n$$ \\mathrm{PPV} = P(D|+) = \\frac{P(+|D) P(D)}{P(+)} $$\nThe denominator, $P(+)$, is the overall probability of a positive prediction, which can be found using the law of total probability:\n$$ P(+) = P(+|D)P(D) + P(+|N)P(N) $$\nSubstituting the standard terminology and given variables:\n$$ P(+) = (\\mathrm{TPR})(\\pi) + (\\mathrm{FPR})(1-\\pi) $$\nSubstituting this back into the expression for $\\mathrm{PPV}$, we derive the governing relationship:\n$$ \\mathrm{PPV} = \\frac{(\\mathrm{TPR})(\\pi)}{(\\mathrm{TPR})(\\pi) + (\\mathrm{FPR})(1-\\pi)} $$\nThis formula demonstrates how precision is governed by $\\mathrm{TPR}$, $\\mathrm{FPR}$, and the prevalence $\\pi$.\n\nNext, we compute the expected precision for the two models at their respective operating thresholds.\n\nFor model $M_1$ at threshold $\\tau_1$:\n$\\mathrm{TPR}_1 = 0.95$, $\\mathrm{FPR}_1 = 10^{-3}$, and $\\pi = 10^{-4}$.\n$$ \\mathrm{PPV}_1 = \\frac{(0.95)(10^{-4})}{(0.95)(10^{-4}) + (10^{-3})(1 - 10^{-4})} $$\n$$ \\mathrm{PPV}_1 = \\frac{9.5 \\times 10^{-5}}{9.5 \\times 10^{-5} + (10^{-3})(0.9999)} $$\n$$ \\mathrm{PPV}_1 = \\frac{9.5 \\times 10^{-5}}{9.5 \\times 10^{-5} + 9.999 \\times 10^{-4}} = \\frac{9.5 \\times 10^{-5}}{0.95 \\times 10^{-4} + 9.999 \\times 10^{-4}} = \\frac{0.95}{0.95 + 9.999} = \\frac{0.95}{10.949} \\approx 0.08676... $$\nSo, the precision for $M_1$ is approximately $0.087$.\n\nFor model $M_2$ at threshold $\\tau_2$:\n$\\mathrm{TPR}_2 = 0.85$, $\\mathrm{FPR}_2 = 10^{-5}$, and $\\pi = 10^{-4}$.\n$$ \\mathrm{PPV}_2 = \\frac{(0.85)(10^{-4})}{(0.85)(10^{-4}) + (10^{-5})(1 - 10^{-4})} $$\n$$ \\mathrm{PPV}_2 = \\frac{8.5 \\times 10^{-5}}{8.5 \\times 10^{-5} + (10^{-5})(0.9999)} $$\n$$ \\mathrm{PPV}_2 = \\frac{8.5 \\times 10^{-5}}{8.5 \\times 10^{-5} + 0.9999 \\times 10^{-5}} = \\frac{8.5}{8.5 + 0.9999} = \\frac{8.5}{9.4999} \\approx 0.8947... $$\nSo, the precision for $M_2$ is approximately $0.895$.\n\nNow, we evaluate each statement.\n\nA. With $\\pi = 10^{-4}$, the expected precision at $(\\mathrm{TPR}=0.95, \\mathrm{FPR}=10^{-3})$ is approximately $0.087$, whereas at $(\\mathrm{TPR}=0.85, \\mathrm{FPR}=10^{-5})$ it is approximately $0.895$; therefore, under extreme imbalance, reducing $\\mathrm{FPR}$ has a dominant effect on precision.\nOur calculations confirm the precision values of $\\approx 0.087$ for $M_1$ and $\\approx 0.895$ for $M_2$. Model $M_2$ achieves a vastly superior precision (by a factor of more than $10$) compared to $M_1$. This dramatic improvement is achieved despite a modest decrease in $\\mathrm{TPR}$ (from $0.95$ to $0.85$) because its $\\mathrm{FPR}$ is $100$ times lower (from $10^{-3}$ to $10^{-5}$). This demonstrates that, under extreme imbalance where $\\pi$ is very small, the $\\mathrm{FPR}$ term in the denominator of the precision formula, $(\\mathrm{FPR})(1-\\pi)$, can dominate the $(\\mathrm{TPR})(\\pi)$ term. To achieve high precision, $\\mathrm{FPR}$ must be reduced to a level comparable to or smaller than $\\mathrm{TPR} \\cdot \\pi$. Thus, the conclusion that reducing $\\mathrm{FPR}$ has a dominant effect is strongly supported by the calculation.\nVerdict: **Correct**.\n\nB. ROC-AUC is invariant to $\\pi$ and can rate both models similarly even when one yields many more false positives in absolute terms; PR-AUC has a chance baseline equal to $\\pi$ and thus better contextualizes performance when $\\pi \\ll 1$.\nThe $ROC$ curve plots $\\mathrm{TPR} = P(+|D)$ against $\\mathrm{FPR} = P(+|N)$. Neither of these quantities depends on the class prevalence $\\pi = P(D)$. Thus, the $ROC$ curve and its area (ROC-AUC) are invariant to class imbalance. The problem states both models have high ROC-AUC near $0.99$, rating them similarly. The ratio of absolute numbers of false positives to true positives is $\\frac{N_{FP}}{N_{TP}} = \\frac{P(+|N)P(N)}{P(+|D)P(D)} = \\frac{\\mathrm{FPR}}{\\mathrm{TPR}}\\frac{1-\\pi}{\\pi}$. Given $\\pi=10^{-4}$, this ratio is $\\approx \\frac{\\mathrm{FPR}}{\\mathrm{TPR}} \\times 10^4$. For $M_1$, this is $\\approx \\frac{10^{-3}}{0.95} \\times 10^4 \\approx 10.5$. For $M_2$, this is $\\approx \\frac{10^{-5}}{0.85} \\times 10^4 \\approx 0.12$. So $M_1$ produces far more false positives per true positive. A random classifier has a constant expected precision equal to the prevalence $\\pi$. The corresponding Precision-Recall curve is a horizontal line at precision $=\\pi$, so the baseline PR-AUC is $\\pi$. When $\\pi=10^{-4}$, the baseline is extremely low. PR-AUC measures performance relative to this low baseline, making it much more sensitive to differences in precision, which is the key challenge in imbalanced problems. All parts of this statement are correct.\nVerdict: **Correct**.\n\nC. When $\\pi$ is extremely small, precision is well approximated by $\\mathrm{TPR}/\\mathrm{FPR}$ and therefore does not depend on $\\pi$.\nThe derived formula is $\\mathrm{PPV} = \\frac{(\\mathrm{TPR})(\\pi)}{(\\mathrm{TPR})(\\pi) + (\\mathrm{FPR})(1-\\pi)}$. When $\\pi \\ll 1$, this can be approximated as $\\mathrm{PPV} \\approx \\frac{\\mathrm{TPR} \\cdot \\pi}{\\mathrm{TPR} \\cdot \\pi + \\mathrm{FPR}}$. For this to be further approximated by $\\mathrm{TPR}/\\mathrm{FPR}$, it would require $\\pi \\cdot (\\mathrm{TPR} \\cdot \\pi + \\mathrm{FPR}) \\approx (\\mathrm{TPR})^2$, which is nonsensical. A more common approximation, valid when false positives vastly outnumber true positives (i.e., $\\mathrm{FPR} \\gg \\mathrm{TPR} \\cdot \\pi$, as for $M_1$), is $\\mathrm{PPV} \\approx \\frac{\\mathrm{TPR} \\cdot \\pi}{\\mathrm{FPR}} = \\pi \\left(\\frac{\\mathrm{TPR}}{\\mathrm{FPR}}\\right)$. This approximation explicitly shows that precision is proportional to $\\pi$. A small prevalence $\\pi$ directly suppresses precision, contradicting the claim that precision does not depend on $\\pi$. Using our computed values, for $M_1$, $\\mathrm{TPR}/\\mathrm{FPR} = 950$ while $\\mathrm{PPV}_1 \\approx 0.087$. These are not approximately equal. The statement is fundamentally incorrect.\nVerdict: **Incorrect**.\n\nD. The baseline PR-AUC of a non-informative classifier equals $1/2$, just like ROC-AUC, so PR-AUC offers no advantage for imbalanced data.\nThe baseline ROC-AUC for a non-informative classifier (which performs at random) is indeed $1/2$, corresponding to the area under the diagonal line $\\mathrm{TPR}=\\mathrm{FPR}$. However, as established in the analysis of option B, the baseline for a Precision-Recall curve is the prevalence of the positive class, $\\pi$. A non-informative classifier achieves an average precision of $\\pi$ across all recall levels, yielding a PR-AUC of $\\pi$. The statement that the baseline PR-AUC is $1/2$ is false. The fact that its baseline is $\\pi$ is precisely why PR-AUC is advantageous for imbalanced data, as it correctly frames the performance in the context of a low prior probability of the positive class.\nVerdict: **Incorrect**.\n\nE. In genome-wide splice site scanning, clinically useful thresholds often require $\\mathrm{FPR}$ in $[0, 10^{-5}]$; two models with similar ROC-AUC can have markedly different PR-AUC if one concentrates gains in this ultra–low $\\mathrm{FPR}$ regime, making PR-AUC more discriminative for model selection.\nThe premise is sound: in a genome-wide scan with billions of loci, only a very low $\\mathrm{FPR}$ is tolerable to avoid a deluge of false positives. As shown by our calculations for $M_1$ and $M_2$, performance in the ultra-low $\\mathrm{FPR}$ regime has a dramatic impact on precision ($\\mathrm{PPV}$). The $PR$ curve directly plots $\\mathrm{PPV}$ against recall ($\\mathrm{TPR}$). A model like $M_2$ that achieves useful $\\mathrm{TPR}$ at a much smaller $\\mathrm{FPR}$ than $M_1$ will have a substantially higher $PR$ curve. The ROC-AUC integrates over the entire $[0, 1]$ range of $\\mathrm{FPR}$, and performance in the high-FPR region (e.g., $\\mathrm{FPR} > 0.01$) can contribute significantly to the area, obscuring critical differences at the clinically relevant low-FPR end. Because the $PR$ curve is sensitive to performance in this critical low-FPR, high-precision region, the resulting PR-AUC will be a much more discriminative metric for comparing models like $M_1$ and $M_2$, even if their ROC-AUCs are nearly identical.\nVerdict: **Correct**.", "answer": "$$\\boxed{ABE}$$", "id": "4385852"}, {"introduction": "Modern splice predictors often use complex, non-linear models like deep neural networks, which can be challenging to interpret. This final practice explores how we can \"look inside\" these models using attribution methods to understand their decision-making process. You will analyze the principles behind techniques like Integrated Gradients and learn about the rigorous statistical and biological validation strategies required to confirm that a model's learned features correspond to real molecular mechanisms [@problem_id:4385868].", "problem": "A laboratory studying inherited disease-causing splice variants trains a differentiable sequence-to-function model that maps a single-stranded deoxyribonucleic acid (DNA) or ribonucleic acid (RNA) sequence to a scalar prediction of splice acceptor or donor usage probability. Let the model be a function $f(\\mathbf{x})$ where the input $\\mathbf{x}\\in\\{0,1\\}^{L\\times 4}$ is a one-hot encoding over $L$ positions and four nucleotides. The central dogma of molecular biology (deoxyribonucleic acid to ribonucleic acid to protein) and the canonical spliceosome recognition principles imply that splice acceptors and donors are sequence-dependent signals mediated by specific RNA-binding proteins and small nuclear ribonucleoproteins. For interpretability, the group considers attribution methods that map the prediction $f(\\mathbf{x})$ back to nucleotides to identify motif occurrences that drive predictions.\n\nThey consider two approaches: gradient-based saliency, which uses local sensitivity of $f$ to $\\mathbf{x}$, and integrated gradients, which accumulates gradients along a path from a baseline $\\mathbf{x}_0$ (representing absence of signal) to the input $\\mathbf{x}$. For evaluation against biology, they plan to validate whether high-attribution positions coincide with known splicing factor binding sites, using motif databases such as the Catalog of Inferred Sequence Binding Preferences for RNA (CISBP-RNA) and ATtRACT, and external assays such as Crosslinking Immunoprecipitation sequencing (CLIP-seq).\n\nAssume $f$ is continuously differentiable with respect to its inputs and the baseline $\\mathbf{x}_0$ is chosen to reflect an absence-of-signal representation (e.g., all zeros). Based on first principles of differential calculus (chain rule, line integrals) and statistical validation under appropriate controls, which of the following statements are correct?\n\nA. For any continuously differentiable $f$, integrated gradients computed along the straight-line path from $\\mathbf{x}_0$ to $\\mathbf{x}$ satisfy a completeness property that the sum of per-feature attributions equals $f(\\mathbf{x})-f(\\mathbf{x}_0)$, which follows from the fundamental theorem of calculus applied to a line integral.\n\nB. In a linear-logistic model $f(\\mathbf{x})=\\sigma(\\mathbf{w}^{\\top}\\mathbf{x}+b)$, where $\\sigma$ is the logistic function and $\\mathbf{w}$ and $b$ are parameters, integrated gradients with baseline $\\mathbf{x}_0=\\mathbf{0}$ exactly reduce to $\\mathbf{x}\\odot\\mathbf{w}$ and therefore do not depend on $\\sigma$.\n\nC. When inputs are one-hot and motif validation uses a Position Weight Matrix (PWM), a principled approach is to aggregate attributions across the four nucleotide channels at each position, align per-position attribution scores to PWM hits for a candidate splicing factor, and estimate enrichment using a permutation test that shuffles attribution values within matched genomic contexts to control for base composition and local sequence structure.\n\nD. Comparing attribution peaks to CLIP-seq peaks for RNA-binding proteins within a fixed genomic window provides reliable mechanistic validation even if the CLIP-seq data are from a different cell type or condition than the model’s training context, because binding motifs are universal.\n\nE. Gradient-based saliency is invariant to rescaling of the one-hot encoding (e.g., replacing $0/1$ with $0/2$) when $f$ is differentiable, whereas integrated gradients are affected by such rescaling and thus do not satisfy implementation invariance.\n\nF. A practical internal validation is in silico mutagenesis: systematically substituting nucleotides at positions with high attribution and measuring the change $\\Delta f=f(\\mathbf{x}^{\\prime})-f(\\mathbf{x})$. A strong positive correlation between attributions and $\\Delta f$ across mutations supports a causal influence on the prediction, but should be complemented with external evidence such as motif enrichment or CLIP-seq to validate biological mechanism.\n\nSelect all correct options.", "solution": "The user wants a critical validation of the problem statement, followed by a detailed solution and evaluation of the provided options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Model**: A continuously differentiable function $f(\\mathbf{x})$ mapping a sequence to a scalar probability.\n- **Input**: $\\mathbf{x} \\in \\{0, 1\\}^{L \\times 4}$, a one-hot encoding for a sequence of length $L$ over $4$ nucleotides.\n- **Task Context**: Splice site prediction in inherited diseases, linking sequence to splice acceptor/donor usage.\n- **Interpretability Methods**:\n  1.  **Gradient-based saliency**: Uses local sensitivity of $f$ to $\\mathbf{x}$.\n  2.  **Integrated gradients (IG)**: Accumulates gradients along a straight-line path from a baseline $\\mathbf{x}_0$ to the input $\\mathbf{x}$.\n- **Baseline**: $\\mathbf{x}_0$ is an absence-of-signal representation, specifically an all-zeros tensor.\n- **Validation Context**: Comparing high-attribution positions to known splicing factor binding sites from databases (CISBP-RNA, ATtRACT) and experimental assays (CLIP-seq).\n- **Core Question**: Evaluate the correctness of statements A-F based on first principles of differential calculus and statistical validation.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded (Critical)**: The problem statement is firmly grounded in computational biology, machine learning, and molecular biology. Splice site prediction, one-hot encoding, gradient-based attribution methods (saliency, Integrated Gradients), and validation against biological data (motif databases, CLIP-seq) are all standard and well-established components in the field of genomic diagnostics and precision medicine. The premises are scientifically sound.\n- **Well-Posed**: The problem is well-posed. It presents a clear context and a set of distinct, falsifiable statements (A-F) to be evaluated for their correctness based on the given information and established principles.\n- **Objective (Critical)**: The language is technical, precise, and devoid of subjective or ambiguous terminology.\n\n**Flaw Checklist Assessment**:\n1.  **Scientific/Factual Unsoundness**: None. The problem accurately describes a common research scenario in bioinformatics.\n2.  **Non-Formalizable/Irrelevant**: None. The problem is highly formalizable using concepts from calculus and statistics, and is directly relevant to the stated topic.\n3.  **Incomplete/Contradictory Setup**: None. The problem provides sufficient information to assess each statement. The assumption that $f$ is continuously differentiable is standard for these methods.\n4.  **Unrealistic/Infeasible**: None. The setup is a realistic representation of a computational genomics project.\n5.  **Ill-Posed/Poorly Structured**: None. A unique verdict (correct/incorrect) can be reached for each statement.\n6.  **Pseudo-Profound, Trivial, or Tautological**: None. The statements require non-trivial knowledge of attribution methods, calculus, statistics, and molecular biology.\n7.  **Outside Scientific Verifiability**: None. All claims are verifiable.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It is scientifically sound, well-posed, and objective. I will now proceed with the solution by analyzing each option.\n\n### Solution\n\n**Option A: Analysis**\n\nThis statement claims that Integrated Gradients (IG) satisfies a \"completeness\" property, where the sum of attributions equals the change in the function's output, $f(\\mathbf{x}) - f(\\mathbf{x}_0)$. This property is a direct consequence of the Path Integral formulation of IG.\n\nLet the straight-line path from baseline $\\mathbf{x}_0$ to input $\\mathbf{x}$ be parameterized by $\\gamma(\\alpha) = \\mathbf{x}_0 + \\alpha(\\mathbf{x} - \\mathbf{x}_0)$ for $\\alpha \\in [0, 1]$.\nThe IG attribution for the $i$-th feature, $x_i$, is defined as:\n$$IG_i(\\mathbf{x}) = (x_i - x_{0,i}) \\int_{0}^{1} \\frac{\\partial f(\\gamma(\\alpha))}{\\partial x_i} d\\alpha$$\nThe sum of all attributions is:\n$$\\sum_{i} IG_i(\\mathbf{x}) = \\sum_{i} (x_i - x_{0,i}) \\int_{0}^{1} \\frac{\\partial f(\\gamma(\\alpha))}{\\partial x_i} d\\alpha$$\nWe can bring the constant term $(x_i - x_{0,i})$ inside the integral and then swap the summation and integration:\n$$\\sum_{i} IG_i(\\mathbf{x}) = \\int_{0}^{1} \\sum_{i} \\frac{\\partial f(\\gamma(\\alpha))}{\\partial x_i} (x_i - x_{0,i}) d\\alpha$$\nThe term inside the summation is the dot product of the gradient of $f$ at $\\gamma(\\alpha)$ and the vector $(\\mathbf{x} - \\mathbf{x}_0)$, which is the derivative of the path, $\\gamma'(\\alpha)$. By the multivariable chain rule, this is the derivative of the composite function $f(\\gamma(\\alpha))$ with respect to $\\alpha$:\n$$\\frac{d}{d\\alpha} f(\\gamma(\\alpha)) = \\nabla f(\\gamma(\\alpha)) \\cdot \\gamma'(\\alpha) = \\sum_{i} \\frac{\\partial f(\\gamma(\\alpha))}{\\partial x_i} (x_i - x_{0,i})$$\nSubstituting this back into the integral, we get:\n$$\\sum_{i} IG_i(\\mathbf{x}) = \\int_{0}^{1} \\frac{d}{d\\alpha} f(\\gamma(\\alpha)) d\\alpha$$\nBy the fundamental theorem of calculus for line integrals (or the simple single-variable fundamental theorem of calculus), this integral evaluates to:\n$$\\int_{0}^{1} \\frac{d}{d\\alpha} f(\\gamma(\\alpha)) d\\alpha = f(\\gamma(1)) - f(\\gamma(0)) = f(\\mathbf{x}) - f(\\mathbf{x}_0)$$\nThus, $\\sum_{i} IG_i(\\mathbf{x}) = f(\\mathbf{x}) - f(\\mathbf{x}_0)$. The statement is a precise description of the \"completeness\" axiom, a defining property of Integrated Gradients.\n\nVerdict: **Correct**.\n\n**Option B: Analysis**\n\nThis statement claims that for a linear-logistic model $f(\\mathbf{x}) = \\sigma(\\mathbf{w}^{\\top}\\mathbf{x} + b)$ with a zero baseline $\\mathbf{x}_0 = \\mathbf{0}$, IG reduces to $\\mathbf{x} \\odot \\mathbf{w}$ and is independent of $\\sigma$.\n\nThe gradient of $f$ is $\\nabla f(\\mathbf{x}) = \\sigma'(\\mathbf{w}^{\\top}\\mathbf{x} + b)\\mathbf{w}$.\nThe IG attribution vector is $\\mathbf{IG}(\\mathbf{x}) = (\\mathbf{x} - \\mathbf{0}) \\odot \\int_0^1 \\nabla f(\\mathbf{0} + \\alpha(\\mathbf{x} - \\mathbf{0})) d\\alpha$.\n$$\\mathbf{IG}(\\mathbf{x}) = \\mathbf{x} \\odot \\int_0^1 \\nabla f(\\alpha\\mathbf{x}) d\\alpha = \\mathbf{x} \\odot \\int_0^1 \\sigma'(\\mathbf{w}^{\\top}(\\alpha\\mathbf{x}) + b) \\mathbf{w} d\\alpha$$\n$$\\mathbf{IG}(\\mathbf{x}) = (\\mathbf{x} \\odot \\mathbf{w}) \\int_0^1 \\sigma'(\\alpha(\\mathbf{w}^{\\top}\\mathbf{x}) + b) d\\alpha$$\nFor the attribution to be $\\mathbf{x} \\odot \\mathbf{w}$, the integral must evaluate to $1$. Let's evaluate the integral. Let $u = \\alpha(\\mathbf{w}^{\\top}\\mathbf{x}) + b$, so $du = (\\mathbf{w}^{\\top}\\mathbf{x}) d\\alpha$.\n$$\\int_0^1 \\sigma'(\\alpha(\\mathbf{w}^{\\top}\\mathbf{x}) + b) d\\alpha = \\frac{1}{\\mathbf{w}^{\\top}\\mathbf{x}} \\int_{b}^{\\mathbf{w}^{\\top}\\mathbf{x}+b} \\sigma'(u) du = \\frac{1}{\\mathbf{w}^{\\top}\\mathbf{x}} [\\sigma(u)]_{b}^{\\mathbf{w}^{\\top}\\mathbf{x}+b} = \\frac{\\sigma(\\mathbf{w}^{\\top}\\mathbf{x}+b) - \\sigma(b)}{\\mathbf{w}^{\\top}\\mathbf{x}}$$\nThe full attribution is:\n$$\\mathbf{IG}(\\mathbf{x}) = (\\mathbf{x} \\odot \\mathbf{w}) \\frac{\\sigma(\\mathbf{w}^{\\top}\\mathbf{x}+b) - \\sigma(b)}{\\mathbf{w}^{\\top}\\mathbf{x}}$$\nThis expression is clearly dependent on the function $\\sigma$ and is not simply $\\mathbf{x} \\odot \\mathbf{w}$ in general. The statement is only true for a purely linear function $f(\\mathbf{x}) = \\mathbf{w}^{\\top}\\mathbf{x} + b$, where $\\sigma$ is the identity function and $\\sigma'$ is $1$, making the integral equal to $1$. The presence of the non-linear logistic function $\\sigma$ makes the statement false.\n\nVerdict: **Incorrect**.\n\n**Option C: Analysis**\n\nThis statement describes a statistical validation procedure for attribution maps. Let's evaluate each part:\n1.  **Aggregate attributions**: The input is one-hot, $\\mathbf{x} \\in \\{0,1\\}^{L \\times 4}$, so attributions are also on an $L \\times 4$ grid. To compare with a per-position motif score (like from a PWM), it's necessary to get a single score per position. Aggregating (e.g., summing) attributions across the four nucleotide channels at each position is a principled way to do this. For one-hot inputs, only one nucleotide channel per position has a non-zero input value, and its attribution is often the quantity of interest, which is equivalent to summing if attributions on zero-valued inputs are zero (as is the case for methods like Gradient*Input or for IG with a zero baseline).\n2.  **Align with PWM hits**: A PWM identifies sequence motifs. Locating high-scoring PWM sites and checking if they correspond to regions of high attribution is a standard way to assess if the model has learned biologically relevant features.\n3.  **Permutation test for enrichment**: To claim that the alignment is statistically significant (i.e., an enrichment), one must compare the observed overlap to a null distribution. A simple permutation test would shuffle scores randomly, but this ignores local genomic context. The proposed method, \"shuffles attribution values within matched genomic contexts to control for base composition and local sequence structure,\" is a sophisticated and highly principled approach. It creates a robust null model by preserving potential confounding factors, ensuring that any observed enrichment is more likely due to the specific sequence motif rather than general properties of the genomic region.\n\nThis entire procedure is statistically sound and represents best practices in the field.\n\nVerdict: **Correct**.\n\n**Option D: Analysis**\n\nThis statement claims that validating a model's attributions against CLIP-seq data from a different cell type or condition is reliable because binding motifs are universal.\nWhile it is true that the primary sequence motif recognized by an RNA-binding protein (RBP) is generally constant, the actual *in vivo* binding event, which CLIP-seq measures, is highly context-dependent. RBP binding is regulated by numerous factors, including:\n- The expression level of the RBP in the specific cell type.\n- The presence of co-factors or competing proteins.\n- RNA accessibility, which is affected by local secondary and tertiary structure.\n- Post-translational modifications of the RBP.\nThese factors vary significantly across different cell types and conditions. Therefore, a set of CLIP-seq peaks from cell type B may not represent the functional RBP binding events that influence splicing in cell type A (the context on which the model was trained). A direct comparison can be misleading and is not considered \"reliable mechanistic validation\". The strongest validation comes from using experimental data from a context that is as closely matched to the model's training data as possible.\n\nVerdict: **Incorrect**.\n\n**Option E: Analysis**\n\nThis statement concerns the \"implementation invariance\" property of attribution methods with respect to input rescaling. Let the original input be $\\mathbf{x}$ (with $0/1$ values) and a rescaled version be $\\mathbf{x}'=c\\mathbf{x}$ (with $0/c$ values, e.g., $c=2$). We must analyze how gradient saliency and IG respond. We assume the function $f$ is unchanged, and we are just feeding it a numerically different input.\n\n- **Gradient-based Saliency**: The saliency map is the gradient, $\\nabla f$. We compare $\\nabla_{\\mathbf{x}} f(\\mathbf{x})$ with $\\nabla_{\\mathbf{x}'} f(\\mathbf{x}')$. Using the chain rule, $\\frac{\\partial}{\\partial x'_i} = \\frac{\\partial x_i}{\\partial x'_i} \\frac{\\partial}{\\partial x_i} = \\frac{1}{c} \\frac{\\partial}{\\partial x_i}$. Therefore, $\\nabla_{\\mathbf{x}'} f(\\mathbf{x}') = \\frac{1}{c} \\nabla_{\\mathbf{x}} f(\\mathbf{x})$. The gradient is not invariant; it is scaled by $1/c$. The statement claims it is invariant.\n\n- **Integrated Gradients**: Let the baseline be $\\mathbf{x}_0 = \\mathbf{0}$, which also implies $\\mathbf{x}'_0 = c \\mathbf{x}_0 = \\mathbf{0}$.\nThe IG attribution for the original input is $\\mathbf{IG}(\\mathbf{x}) = \\mathbf{x} \\odot \\int_0^1 \\nabla_{\\mathbf{x}} f(\\alpha\\mathbf{x}) d\\alpha$.\nThe IG attribution for the rescaled input is $\\mathbf{IG}(\\mathbf{x}') = \\mathbf{x}' \\odot \\int_0^1 \\nabla_{\\mathbf{x}'} f(\\alpha\\mathbf{x}') d\\alpha$.\nSubstitute $\\mathbf{x}' = c\\mathbf{x}$ and $\\nabla_{\\mathbf{x}'} = \\frac{1}{c} \\nabla_{\\mathbf{x}}$:\n$$\\mathbf{IG}(\\mathbf{x}') = (c\\mathbf{x}) \\odot \\int_0^1 \\frac{1}{c} \\nabla_{\\mathbf{x}} f(\\alpha(c\\mathbf{x})) d\\alpha$$\nThe problem here is that the function is now evaluated along a different path in its domain. To properly test implementation invariance, we must consider two functionally equivalent models, as described in the original IG paper. Let model 1 be $h_1(\\mathbf{z}) = f(\\mathbf{z})$ operating on $0/1$ inputs, and model 2 be $h_2(\\mathbf{w}) = f(\\mathbf{w}/c)$ operating on $0/c$ inputs. For an input sequence, model 1 gets $\\mathbf{x}$ and model 2 gets $\\mathbf{x}' = c\\mathbf{x}$. The outputs are identical: $h_1(\\mathbf{x})=f(\\mathbf{x})$ and $h_2(\\mathbf{x}') = f(c\\mathbf{x}/c) = f(\\mathbf{x})$.\n- Attribution for $h_1$ at $\\mathbf{x}$: $\\mathbf{IG}_{h_1}(\\mathbf{x}) = \\mathbf{x} \\odot \\int_0^1 \\nabla h_1(\\alpha\\mathbf{x})d\\alpha$.\n- Attribution for $h_2$ at $\\mathbf{x}'$: $\\mathbf{IG}_{h_2}(\\mathbf{x}') = \\mathbf{x}' \\odot \\int_0^1 \\nabla_{\\mathbf{x}'} h_2(\\alpha\\mathbf{x}')d\\alpha$.\nThe gradient $\\nabla_{\\mathbf{x}'} h_2(\\mathbf{w}) = \\nabla_{\\mathbf{w}} f(\\mathbf{w}/c)$ evaluates using the chain rule to $\\frac{1}{c}\\nabla f(\\mathbf{w}/c)$. So $\\nabla_{\\mathbf{x}'} h_2(\\alpha\\mathbf{x}') = \\frac{1}{c}\\nabla f(\\alpha\\mathbf{x}'/c) = \\frac{1}{c}\\nabla f(\\alpha\\mathbf{x}) = \\frac{1}{c}\\nabla h_1(\\alpha\\mathbf{x})$.\nPlugging this in:\n$$\\mathbf{IG}_{h_2}(\\mathbf{x}') = (c\\mathbf{x}) \\odot \\int_0^1 \\frac{1}{c} \\nabla h_1(\\alpha\\mathbf{x})d\\alpha = \\mathbf{x} \\odot \\int_0^1 \\nabla h_1(\\alpha\\mathbf{x})d\\alpha = \\mathbf{IG}_{h_1}(\\mathbf{x})$$\nThe attributions are identical. Thus, IG **satisfies** implementation invariance. Gradient saliency does not, as the gradients of $h_1$ and $h_2$ would be $\\nabla f(\\mathbf{x})$ and $\\frac{1}{c}\\nabla f(\\mathbf{x})$, which are different.\nThe statement says \"Gradient-based saliency is invariant... whereas integrated gradients are affected\". This is the exact opposite of what is correct.\n\nVerdict: **Incorrect**.\n\n**Option F: Analysis**\n\nThis statement proposes a two-part validation strategy.\n1.  **Internal Validation (Faithfulness)**: This part describes *in silico* mutagenesis, where input positions are changed and the effect on the output, $\\Delta f$, is measured. Correlating the predicted attribution scores with the measured $\\Delta f$ values is a primary method for assessing the \"faithfulness\" or \"fidelity\" of an attribution method. A strong correlation means the attribution method is a good local or global proxy for feature importance *with respect to the model's computations*. The claim that this supports a \"causal influence on the prediction\" is correct in the context of the model's internal logic.\n2.  **External Validation (Plausibility)**: The statement correctly points out that faithfulness to the model is not sufficient to prove biological relevance. The model itself could have learned non-biological artifacts. Therefore, it is crucial to complement internal validation with external evidence, such as showing that high-attribution regions are enriched for known biological signals (e.g., RBP binding motifs from databases or CLIP-seq peaks from matched experiments). This duality of checking for both model faithfulness and biological plausibility is the gold standard for validating interpretability methods in scientific applications.\n\nThe statement provides a complete and accurate description of a robust validation workflow.\n\nVerdict: **Correct**.\n\n### Summary of Correct Options\n\n- **A** is correct.\n- **B** is incorrect.\n- **C** is correct.\n- **D** is incorrect.\n- **E** is incorrect.\n- **F** is correct.\n\nThe correct options are A, C, and F.", "answer": "$$\\boxed{ACF}$$", "id": "4385868"}]}