{"hands_on_practices": [{"introduction": "The first step in planning any saturation genome editing (SGE) experiment is to grasp its scale. Before synthesizing DNA or culturing cells, a researcher must determine the total number of unique genetic variants to be tested and the overall size of the editing library. This foundational exercise guides you through the simple but essential combinatorial calculation needed to determine the library size for an SGE screen, providing a concrete understanding of the experimental scope from the outset [@problem_id:4329417].", "problem": "A research team is designing a saturation genome editing (SGE) library using Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) to map variant effects across a single coding exon. The exon has length $L$ measured in base pairs, and the design objective is to include every possible single-nucleotide substitution at every position in the exon. In this context, a single-nucleotide substitution is defined as changing exactly one base at one genomic position to any other base in the canonical deoxyribonucleic acid (DNA) alphabet $\\{ \\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T} \\}$, excluding the original base at that position. The team also requires redundancy, meaning each distinct variant must be represented by $r$ independently synthesized donor constructs (for example, unique molecularly barcoded oligonucleotides), so that experimental stochasticity does not underpower detection of variant effects.\n\nUsing only the following fundamental bases and definitions:\n- The Central Dogma of Molecular Biology establishes that coding exons are stretches of DNA that encode messenger ribonucleic acid (mRNA) and ultimately protein, with sequence measured in base pairs.\n- The DNA alphabet has cardinality $4$, and a single-nucleotide substitution at a position replaces the current base with any other base, yielding $4 - 1$ possible substitutions per position.\n- The rule of product from combinatorics states that if one process can occur in $a$ ways and independently another in $b$ ways, the combined process can occur in $a \\times b$ ways.\n\nAssume there are no insertions, deletions, or multi-nucleotide changes, and do not include any wild-type controls or additional design elements beyond the variants and their redundancy. Derive a symbolic expression, in simplest closed form, for the total number of distinct constructs required in the library as a function of $L$ and $r$. Express your final answer as a single analytic expression. No rounding is required, and no physical units should be included in the final expression.", "solution": "The user-provided problem has been analyzed and validated against the specified criteria.\n\n### Step 1: Extract Givens\n- Exon length: $L$ base pairs.\n- Library design objective: Include every possible single-nucleotide substitution at every position in the exon.\n- Definition of a single-nucleotide substitution: Changing one base at one position to any of the other $3$ canonical DNA bases. The DNA alphabet is $\\{ \\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T} \\}$.\n- Redundancy: Each distinct variant is represented by $r$ independently synthesized donor constructs.\n- Fundamental principles provided: The Central Dogma of Molecular Biology regarding coding exons; the DNA alphabet cardinality is $4$, leading to $4-1$ substitutions per position; the rule of product from combinatorics.\n- Exclusions: No insertions, deletions, multi-nucleotide changes, wild-type controls, or other design elements.\n- Goal: Derive a symbolic expression for the total number of distinct constructs required, as a function of $L$ and $r$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated as follows:\n- **Scientifically Grounded**: The problem is based on established principles of molecular biology, genetics, and CRISPR technology (specifically, saturation genome editing). The definitions provided for a coding exon, single-nucleotide substitution, and the DNA alphabet are factually correct and standard in the field.\n- **Well-Posed**: The problem is clearly defined. It provides all necessary parameters ($L$ and $r$) and constraints to derive a unique mathematical expression for the total number of library constructs.\n- **Objective**: The language is precise, technical, and free of subjective or ambiguous terminology.\n\nBased on this evaluation, the problem is deemed valid and solvable.\n\n### Step 3: Derivation of the Solution\nThe objective is to calculate the total number of constructs, $N$, required for a saturation genome editing library targeting an exon of length $L$ with a redundancy of $r$.\n\n1.  **Determine the number of possible unique variants.**\n    A unique variant is defined by a single-nucleotide substitution. To specify such a variant, we must make two independent choices:\n    a.  **The position of the substitution:** The exon has a length of $L$ base pairs. Therefore, there are $L$ distinct positions where a substitution can occur.\n    b.  **The identity of the substituted nucleotide:** At any given position, the DNA alphabet consists of $4$ bases. A substitution requires changing the original base to one of the other bases. This leaves $4 - 1 = 3$ possible choices for the new nucleotide at that specific position.\n\n2.  **Apply the rule of product.**\n    The problem provides the rule of product: if one process can occur in $a$ ways and an independent process can occur in $b$ ways, the combined process can occur in $a \\times b$ ways.\n    In this context, the process of creating a unique variant involves choosing a position ($L$ ways) and choosing a substitution ($3$ ways).\n    Let $V$ be the total number of distinct single-nucleotide variants possible for the exon. Applying the rule of product:\n    $$V = (\\text{Number of positions}) \\times (\\text{Number of substitutions per position})$$\n    $$V = L \\times 3 = 3L$$\n    So, there are $3L$ unique variants that must be included in the library.\n\n3.  **Incorporate the redundancy factor.**\n    The problem states that each distinct variant must be represented by $r$ independently synthesized constructs. This redundancy is designed to ensure robust detection of variant effects by overcoming experimental noise and stochasticity.\n    Let $N$ be the total number of constructs in the library. To calculate $N$, we multiply the total number of distinct variants, $V$, by the redundancy factor, $r$.\n    $$N = V \\times r$$\n    Substituting the expression for $V$:\n    $$N = (3L) \\times r = 3Lr$$\n\nThis expression represents the total number of constructs required for the library as a function of the exon length $L$ and the redundancy factor $r$. It is in its simplest closed form.", "answer": "$$\\boxed{3Lr}$$", "id": "4329417"}, {"introduction": "Once the scope of the library is defined, the next challenge is to ensure the variants are efficiently introduced into the target cells. In CRISPR-based SGE, this is typically achieved through homology-directed repair (HDR), a process whose efficiency depends on the design of the DNA donor template. This problem explores the quantitative relationship between a key design parameter—the length of the homology arms on the donor template—and the resulting HDR probability, allowing you to use a mathematical model to optimize your experimental design for success [@problem_id:4329407].", "problem": "A laboratory is designing a clustered regularly interspaced short palindromic repeats (CRISPR)-based saturation genome editing library to systematically map the effects of single-nucleotide variants on gene function for clinical variant interpretation in precision medicine. In such designs, double-strand break repair proceeds via homology-directed repair (HDR) using a donor template with symmetric homology arms of length $h$ on each side of the edit site. Empirically, the probability of homology-directed repair, denoted $p_{\\mathrm{HDR}}$, increases with $h$ and is well described by an exponential saturation model consistent with a constant hazard per base of productive strand invasion and annealing. Assume the following relationship holds across the relevant design space: $p_{\\mathrm{HDR}}=1-\\exp(-\\alpha h)$, where $\\alpha>0$ is a fit parameter capturing the per-base effective rate of productive alignment of the donor arms to the genomic locus, and $h \\ge 0$ is measured in base pairs.\n\nYou are tasked with determining the minimal homology arm length $h_{\\min}$ required to achieve an HDR efficiency at or above a specified threshold $p_{\\mathrm{min}}$ for accurate variant incorporation in a pooled assay, under the constraints $0<p_{\\mathrm{min}}<1$ and $\\alpha>0$. Starting from fundamental probability principles (the complement rule) and the given empirical model, derive an analytic expression for $h_{\\min}$ in terms of $\\alpha$ and $p_{\\mathrm{min}}$. Express your final answer in base pairs (bp). No numerical substitution is required, and no rounding is needed. Provide the final expression simplified.", "solution": "The problem has been validated and is deemed scientifically grounded, well-posed, and objective. It is based on a standard exponential saturation model used in molecular biology and presents a solvable mathematical challenge derived from clear premises. All necessary parameters are provided in symbolic form with appropriate constraints. Therefore, I will proceed with a full solution.\n\nThe problem asks for the minimal homology arm length, denoted $h_{\\min}$, required to ensure that the probability of homology-directed repair, $p_{\\mathrm{HDR}}$, is at or above a specified threshold, $p_{\\mathrm{min}}$. This can be stated as the inequality:\n$$\np_{\\mathrm{HDR}} \\ge p_{\\mathrm{min}}\n$$\nThe problem provides an empirical model for $p_{\\mathrm{HDR}}$ as a function of the homology arm length $h$:\n$$\np_{\\mathrm{HDR}} = 1 - \\exp(-\\alpha h)\n$$\nwhere $h$ is the length in base pairs, and $\\alpha$ is a positive constant ($\\alpha > 0$). The constraints on the minimum desired probability are $0 < p_{\\mathrm{min}} < 1$.\n\nThe provided model is consistent with the complement rule of probability. If we define the event of successful HDR as $E$, then $p_{\\mathrm{HDR}} = P(E)$. The complement event, $E^c$, is the failure to achieve HDR. The complement rule states $P(E) = 1 - P(E^c)$. Comparing this to the given model, the probability of *failure* to achieve HDR is identified as:\n$$\nP(E^c) = \\exp(-\\alpha h)\n$$\nThis exponential decay form is characteristic of a process with a constant hazard rate, as mentioned in the problem description, where $\\alpha$ represents the effective per-base rate of successful engagement that leads to HDR.\n\nTo find the minimal length $h_{\\min}$, we substitute the model for $p_{\\mathrm{HDR}}$ into the required inequality:\n$$\n1 - \\exp(-\\alpha h) \\ge p_{\\mathrm{min}}\n$$\nOur goal is to solve this inequality for $h$. First, we rearrange the terms to isolate the exponential function:\n$$\n1 - p_{\\mathrm{min}} \\ge \\exp(-\\alpha h)\n$$\nThis inequality can be rephrased using the complement event: the probability of HDR failure, $\\exp(-\\alpha h)$, must be less than or equal to $1 - p_{\\mathrm{min}}$.\n\nTo solve for $h$, we take the natural logarithm of both sides. The natural logarithm function, $\\ln(x)$, is a strictly increasing function for $x > 0$. Thus, applying it to both sides of an inequality preserves the direction of the inequality. We must first ensure that the arguments of the logarithm are positive. The term $\\exp(-\\alpha h)$ is always positive. For the left-hand side, the problem states $0 < p_{\\mathrm{min}} < 1$, which implies that $0 < 1 - p_{\\mathrm{min}} < 1$. Therefore, the argument $1 - p_{\\mathrm{min}}$ is positive, and taking the natural logarithm is a valid operation.\n$$\n\\ln(1 - p_{\\mathrm{min}}) \\ge \\ln(\\exp(-\\alpha h))\n$$\nUsing the property that $\\ln(\\exp(x)) = x$, we simplify the right-hand side:\n$$\n\\ln(1 - p_{\\mathrm{min}}) \\ge -\\alpha h\n$$\nTo isolate $h$, we divide both sides by $-\\alpha$. Since it is given that $\\alpha > 0$, the term $-\\alpha$ is negative. Dividing an inequality by a negative number reverses the direction of the inequality sign:\n$$\n\\frac{\\ln(1 - p_{\\mathrm{min}})}{-\\alpha} \\le h\n$$\nThis can be rewritten as:\n$$\nh \\ge -\\frac{\\ln(1 - p_{\\mathrm{min}})}{\\alpha}\n$$\nUsing the logarithmic identity $-\\ln(x) = \\ln(x^{-1}) = \\ln(1/x)$, we can simplify the expression:\n$$\nh \\ge \\frac{1}{\\alpha} \\ln\\left(\\frac{1}{1 - p_{\\mathrm{min}}}\\right)\n$$\nThis inequality specifies the condition that any valid homology arm length $h$ must satisfy to achieve the desired efficiency. The problem asks for the *minimal* length, $h_{\\min}$. The minimal value of $h$ that satisfies this condition is the lower bound of the interval. Therefore, we set $h_{\\min}$ equal to this lower bound:\n$$\nh_{\\min} = \\frac{1}{\\alpha} \\ln\\left(\\frac{1}{1 - p_{\\mathrm{min}}}\\right)\n$$\nThis expression provides the minimal homology arm length $h_{\\min}$ in base pairs as a function of the effective rate parameter $\\alpha$ and the minimum desired HDR probability $p_{\\mathrm{min}}$.\nThe function $f(h) = 1-\\exp(-\\alpha h)$ is a monotonically increasing function of $h$ for $\\alpha > 0$. Therefore, for any $h > h_{\\min}$, the HDR probability will be greater than $p_{\\mathrm{min}}$, and for any $h < h_{\\min}$, the probability will be less than $p_{\\mathrm{min}}$. Thus, $h_{\\min}$ is indeed the unique minimal length required.\nThe problem requires the final answer to be a simplified analytical expression. The derived expression is fully simplified.", "answer": "$$\\boxed{\\frac{1}{\\alpha} \\ln\\left(\\frac{1}{1 - p_{\\mathrm{min}}}\\right)}$$", "id": "4329407"}, {"introduction": "After executing an SGE experiment and collecting sequencing data, the final and most critical step is to accurately interpret the results. Raw data from pooled screens are often confounded by experimental artifacts, such as toxicity from the CRISPR-induced DNA cut itself, which can obscure the true fitness effect of a variant. This advanced problem demonstrates how to use a sophisticated statistical model and a well-designed experiment with matched controls to deconvolve the true biological signal from various sources of noise, enabling a precise and unbiased estimate of a variant's functional impact [@problem_id:4329401].", "problem": "A pool-based variant effect mapping experiment using Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) and Homology-Directed Repair (HDR) is performed to quantify the fitness impact of all single-nucleotide variants in a clinically actionable gene. The design tiles $K$ distinct CRISPR guide ribonucleoproteins across a locus $L$, and for each guide $k \\in \\{1,\\dots,K\\}$ and each biological replicate $r \\in \\{1,\\dots,R\\}$, two HDR templates are delivered: one template installs a specific variant $v$; the other template restores the exact wild-type sequence (the matched cut-and-repair control). After a competition of duration $T$, deep sequencing yields frequencies at time $0$ and time $T$ for each edited allele. For each $(k,r)$, define the measured log fold change for variant $v$ as\n$$\ny_{v,k,r} \\equiv \\ln\\!\\left(\\frac{f_{v,k,r}(T)}{f_{v,k,r}(0)}\\right),\n$$\nand for the matched wild-type HDR control as\n$$\ny_{w,k,r} \\equiv \\ln\\!\\left(\\frac{f_{w,k,r}(T)}{f_{w,k,r}(0)}\\right).\n$$\nAssume a pooled competition regime in which the expected change in log frequency over time for any allele is the sum of a variant-specific Malthusian fitness effect and shared components that arise from double-strand break (DSB) cutting at locus $L$ and replicate-level drift. Concretely, suppose that for each $(k,r)$,\n$$\ny_{v,k,r} \\;=\\; s_v\\,T \\;+\\; c_L\\,T \\;+\\; d_k\\,T \\;+\\; m_r\\,T \\;+\\; \\varepsilon_{v,k,r},\n$$\nand\n$$\ny_{w,k,r} \\;=\\; 0\\cdot T \\;+\\; c_L\\,T \\;+\\; d_k\\,T \\;+\\; m_r\\,T \\;+\\; \\varepsilon_{w,k,r},\n$$\nwhere $s_v$ is the true variant-specific fitness effect per unit time, $c_L$ is the locus-specific cutting toxicity per unit time (shared across all guides at locus $L$), $d_k$ is the guide-specific additive cutting toxicity per unit time, $m_r$ is the replicate-level drift per unit time, and $\\varepsilon_{v,k,r}$ and $\\varepsilon_{w,k,r}$ are independent, zero-mean noise terms. For each $(k,r)$, define a known inverse-variance weight\n$$\nw_{k,r} \\equiv \\frac{1}{\\operatorname{Var}\\!\\left(y_{v,k,r} - y_{w,k,r}\\right)},\n$$\nreflecting heteroscedastic measurement uncertainty across guides and replicates, and assume $\\varepsilon_{v,k,r}$ and $\\varepsilon_{w,k,r}$ are Gaussian with finite variances.\n\nStarting from the definition of Malthusian fitness in pooled competitions and the additive decomposition above, derive a single closed-form analytic expression for a minimum-variance unbiased linear estimator of the true variant-specific fitness $s_v$ that separates the variant effect from locus-specific and guide-specific cutting toxicities by leveraging the matched HDR wild-type controls and modeling shared components. Your final expression should be written entirely in terms of $T$, the weights $w_{k,r}$, and the measured quantities $y_{v,k,r}$ and $y_{w,k,r}$. The answer should be an analytical expression; do not provide any numerical evaluation. If you introduce any additional symbols, define them precisely. Express the final fitness effect per unit time (no unit needs to be printed in the final expression). No rounding is required.", "solution": "The problem requires the derivation of a minimum-variance unbiased linear estimator for the true variant-specific fitness effect, $s_v$. This is also known as the Best Linear Unbiased Estimator (BLUE). The derivation proceeds by first simplifying the given statistical model to isolate the parameter of interest, $s_v$, and then applying the principles of optimal estimation for linear models with heteroscedastic noise.\n\nLet us begin by analyzing the provided models for the log fold changes:\n$$\ny_{v,k,r} \\;=\\; s_v\\,T \\;+\\; c_L\\,T \\;+\\; d_k\\,T \\;+\\; m_r\\,T \\;+\\; \\varepsilon_{v,k,r}\n$$\n$$\ny_{w,k,r} \\;=\\; 0\\cdot T \\;+\\; c_L\\,T \\;+\\; d_k\\,T \\;+\\; m_r\\,T \\;+\\; \\varepsilon_{w,k,r}\n$$\nThe experimental design, which includes a matched wild-type control for each variant measurement, is crucial. By taking the difference between the log fold change for the variant and its corresponding wild-type control for each guide $k$ and replicate $r$, we can eliminate the shared nuisance parameters. Let us define this difference as $\\Delta y_{k,r}$:\n$$\n\\Delta y_{k,r} \\equiv y_{v,k,r} - y_{w,k,r}\n$$\nSubstituting the given model equations into this definition yields:\n$$\n\\Delta y_{k,r} = (s_v\\,T \\;+\\; c_L\\,T \\;+\\; d_k\\,T \\;+\\; m_r\\,T \\;+\\; \\varepsilon_{v,k,r}) - (c_L\\,T \\;+\\; d_k\\,T \\;+\\; m_r\\,T \\;+\\; \\varepsilon_{w,k,r})\n$$\nThe terms corresponding to locus-specific toxicity ($c_L$), guide-specific toxicity ($d_k$), and replicate-level drift ($m_r$) cancel out perfectly:\n$$\n\\Delta y_{k,r} = s_v\\,T + (\\varepsilon_{v,k,r} - \\varepsilon_{w,k,r})\n$$\nLet us define a new composite noise term $\\eta_{k,r} \\equiv \\varepsilon_{v,k,r} - \\varepsilon_{w,k,r}$. Since $\\varepsilon_{v,k,r}$ and $\\varepsilon_{w,k,r}$ are independent and have zero mean, the new noise term $\\eta_{k,r}$ also has zero mean:\n$$\n\\mathbb{E}[\\eta_{k,r}] = \\mathbb{E}[\\varepsilon_{v,k,r}] - \\mathbb{E}[\\varepsilon_{w,k,r}] = 0 - 0 = 0\n$$\nThe simplified model for each measurement pair is now:\n$$\n\\Delta y_{k,r} = s_v\\,T + \\eta_{k,r}\n$$\nAn issue of heteroscedasticity remains, as the variance of $\\eta_{k,r}$ may differ for each $(k,r)$. The variance of $\\eta_{k,r}$ is given by $\\operatorname{Var}(\\eta_{k,r}) = \\operatorname{Var}(\\varepsilon_{v,k,r} - \\varepsilon_{w,k,r})$. Due to the independence of the epsilon terms, this is $\\operatorname{Var}(\\eta_{k,r}) = \\operatorname{Var}(\\varepsilon_{v,k,r}) + \\operatorname{Var}(\\varepsilon_{w,k,r})$.\nThe problem provides the inverse-variance weight $w_{k,r}$ as:\n$$\nw_{k,r} \\equiv \\frac{1}{\\operatorname{Var}\\!\\left(y_{v,k,r} - y_{w,k,r}\\right)} = \\frac{1}{\\operatorname{Var}\\!\\left(\\Delta y_{k,r}\\right)}\n$$\nSince $s_v T$ is a constant for a given variant, $\\operatorname{Var}(\\Delta y_{k,r}) = \\operatorname{Var}(s_v T + \\eta_{k,r}) = \\operatorname{Var}(\\eta_{k,r})$. Therefore, we have $\\operatorname{Var}(\\eta_{k,r}) = 1/w_{k,r}$.\n\nTo estimate $s_v$, we can rearrange the simplified model. For each of the $K \\times R$ independent measurements, we can form an individual estimate of $s_v$:\n$$\n\\frac{\\Delta y_{k,r}}{T} = s_v + \\frac{\\eta_{k,r}}{T}\n$$\nLet $Z_{k,r} \\equiv \\frac{\\Delta y_{k,r}}{T}$. Then we have $Z_{k,r} = s_v + \\epsilon'_{k,r}$, where $\\epsilon'_{k,r} = \\eta_{k,r}/T$. Each $Z_{k,r}$ is an unbiased estimator of $s_v$ since $\\mathbb{E}[Z_{k,r}] = s_v + \\mathbb{E}[\\eta_{k,r}]/T = s_v$. However, these estimators have different variances:\n$$\n\\operatorname{Var}(Z_{k,r}) = \\operatorname{Var}\\left(\\frac{\\eta_{k,r}}{T}\\right) = \\frac{1}{T^2}\\operatorname{Var}(\\eta_{k,r}) = \\frac{1}{T^2 w_{k,r}}\n$$\nThe BLUE for $s_v$ is the inverse-variance weighted average of the individual estimators $Z_{k,r}$. The optimal weights for this average, let's call them $\\alpha_{k,r}$, are proportional to the inverse of the variance of each $Z_{k,r}$:\n$$\n\\alpha_{k,r} \\propto \\frac{1}{\\operatorname{Var}(Z_{k,r})} = T^2 w_{k,r}\n$$\nTo ensure the final estimator is unbiased, these weights must sum to $1$. We normalize them accordingly:\n$$\n\\alpha_{k,r} = \\frac{T^2 w_{k,r}}{\\sum_{i=1}^K \\sum_{j=1}^R T^2 w_{i,j}} = \\frac{w_{k,r}}{\\sum_{i=1}^K \\sum_{j=1}^R w_{i,j}}\n$$\nThe BLUE for $s_v$, denoted $\\hat{s}_v$, is the linear combination of the $Z_{k,r}$ with these optimal weights:\n$$\n\\hat{s}_v = \\sum_{k=1}^K \\sum_{r=1}^R \\alpha_{k,r} Z_{k,r}\n$$\nSubstituting the expressions for $\\alpha_{k,r}$ and $Z_{k,r}$ gives:\n$$\n\\hat{s}_v = \\sum_{k=1}^K \\sum_{r=1}^R \\left( \\frac{w_{k,r}}{\\sum_{i=1}^K \\sum_{j=1}^R w_{i,j}} \\right) \\left( \\frac{y_{v,k,r} - y_{w,k,r}}{T} \\right)\n$$\nThis expression can be rearranged into a more compact form by factoring out terms that do not depend on the summation indices $k$ and $r$:\n$$\n\\hat{s}_v = \\frac{1}{T \\left(\\sum_{k=1}^K \\sum_{r=1}^R w_{k,r}\\right)} \\sum_{k=1}^K \\sum_{r=1}^R w_{k,r} (y_{v,k,r} - y_{w,k,r})\n$$\nThis is the final closed-form analytic expression for the minimum-variance unbiased linear estimator of $s_v$. It correctly combines all available measurements, weighted by their known inverse variances, to produce a single, optimal estimate of the variant's fitness effect, while being robust to the specified confounding factors.", "answer": "$$\n\\boxed{\\frac{\\sum_{k=1}^{K} \\sum_{r=1}^{R} w_{k,r} (y_{v,k,r} - y_{w,k,r})}{T \\sum_{k=1}^{K} \\sum_{r=1}^{R} w_{k,r}}}\n$$", "id": "4329401"}]}