{"hands_on_practices": [{"introduction": "Precision medicine trials rely on accurate biomarker tests to assign patients to the correct treatment arms, but no diagnostic test is perfect. This exercise demonstrates how to quantify the real-world performance of a biomarker assay using fundamental concepts like sensitivity, specificity, and Bayes' theorem. By calculating the Positive and Negative Predictive Values (PPV and NPV), you will understand the probability of correct patient assignment and the expected number of misclassifications, which are critical operational metrics for an umbrella trial [@problem_id:4326317].", "problem": "An umbrella clinical trial in precision oncology uses a centralized genomic diagnostic to assign patients to biomarker-directed treatment arms within a single histologic cancer type. The biomarker $B$ identifies an actionable variant. The incoming screened population has biomarker prevalence $p = 0.05$. The assay’s sensitivity (true positive rate) is $0.92$ and its specificity (true negative rate) is $0.99$. Let $n = 200$ denote the number of consecutively screened patients considered for arm assignment.\n\nUsing only the definitions of sensitivity, specificity, and Bayes theorem, and assuming independent Bernoulli outcomes across patients, derive expressions for the Positive Predictive Value (PPV) and Negative Predictive Value (NPV) of the assay for $B$ in terms of $p$, sensitivity, and specificity, then evaluate them at the given parameter values. Define a “misassigned patient” as a screened patient who is routed to a biomarker-positive arm despite truly lacking $B$ (a false positive) or is denied routing to a biomarker-positive arm despite truly harboring $B$ (a false negative). Under the independence assumption, compute the expected number of misassigned patients in the cohort of $n = 200$.\n\nRound all numerical answers to four significant figures. Express PPV and NPV as unitless decimals. Express the expected misassigned count in patients.", "solution": "The problem is valid as it is scientifically grounded in standard biostatistical principles, is well-posed with sufficient information for a unique solution, and is stated objectively.\n\nFirst, we define the relevant events and translate the given parameters into probabilistic notation.\nLet $D^+$ be the event that a patient truly has the biomarker $B$.\nLet $D^-$ be the event that a patient truly lacks the biomarker $B$.\nLet $T^+$ be the event that the assay test result is positive.\nLet $T^-$ be the event that the assay test result is negative.\n\nFrom the problem statement, we are given:\nThe prevalence of the biomarker, $p = P(D^+) = 0.05$.\nThe probability of a patient not having the biomarker is $P(D^-) = 1 - P(D^+) = 1 - p = 1 - 0.05 = 0.95$.\nThe assay's sensitivity, $\\text{sens} = P(T^+ | D^+) = 0.92$. This is the true positive rate.\nThe assay's specificity, $\\text{spec} = P(T^- | D^-) = 0.99$. This is the true negative rate.\nThe total number of screened patients is $n = 200$.\n\nFrom these definitions, we can derive the rates of incorrect test results:\nThe false positive rate (FPR) is $P(T^+ | D^-) = 1 - P(T^- | D^-) = 1 - \\text{spec} = 1 - 0.99 = 0.01$.\nThe false negative rate (FNR) is $P(T^- | D^+) = 1 - P(T^+ | D^+) = 1 - \\text{sens} = 1 - 0.92 = 0.08$.\n\n### Derivation of PPV and NPV\nThe Positive Predictive Value (PPV) is the probability that a patient with a positive test result a has the biomarker, $P(D^+ | T^+)$. Using Bayes' theorem:\n$$ \\text{PPV} = P(D^+ | T^+) = \\frac{P(T^+ | D^+) P(D^+)}{P(T^+)} $$\nThe denominator, $P(T^+)$, is the total probability of a positive test, which can be found using the law of total probability:\n$$ P(T^+) = P(T^+ | D^+) P(D^+) + P(T^+ | D^-) P(D^-) $$\nSubstituting the symbolic definitions:\n$$ P(T^+) = (\\text{sens}) \\cdot p + (1 - \\text{spec}) \\cdot (1 - p) $$\nTherefore, the expression for PPV is:\n$$ \\text{PPV} = \\frac{(\\text{sens}) \\cdot p}{(\\text{sens}) \\cdot p + (1 - \\text{spec}) \\cdot (1 - p)} $$\n\nThe Negative Predictive Value (NPV) is the probability that a patient with a negative test result does not have the biomarker, $P(D^- | T^-)$. Using Bayes' theorem:\n$$ \\text{NPV} = P(D^- | T^-) = \\frac{P(T^- | D^-) P(D^-)}{P(T^-)} $$\nThe denominator, $P(T^-)$, is the total probability of a negative test:\n$$ P(T^-) = P(T^- | D^-) P(D^-) + P(T^- | D^+) P(D^+) $$\nSubstituting the symbolic definitions:\n$$ P(T^-) = (\\text{spec}) \\cdot (1 - p) + (1 - \\text{sens}) \\cdot p $$\nTherefore, the expression for NPV is:\n$$ \\text{NPV} = \\frac{(\\text{spec}) \\cdot (1 - p)}{(\\text{spec}) \\cdot (1 - p) + (1 - \\text{sens}) \\cdot p} $$\n\n### Evaluation of PPV and NPV\nWe now substitute the given numerical values into the derived expressions.\nFor PPV:\n$$ \\text{PPV} = \\frac{0.92 \\cdot 0.05}{0.92 \\cdot 0.05 + (1 - 0.99) \\cdot (1 - 0.05)} = \\frac{0.046}{0.046 + 0.01 \\cdot 0.95} = \\frac{0.046}{0.046 + 0.0095} = \\frac{0.046}{0.0555} \\approx 0.8288288... $$\nRounding to four significant figures, $\\text{PPV} = 0.8288$.\n\nFor NPV:\n$$ \\text{NPV} = \\frac{0.99 \\cdot (1 - 0.05)}{0.99 \\cdot (1 - 0.05) + (1 - 0.92) \\cdot 0.05} = \\frac{0.99 \\cdot 0.95}{0.99 \\cdot 0.95 + 0.08 \\cdot 0.05} = \\frac{0.9405}{0.9405 + 0.004} = \\frac{0.9405}{0.9445} \\approx 0.9957649... $$\nRounding to four significant figures, $\\text{NPV} = 0.9958$.\n\n### Expected Number of Misassigned Patients\nA misassigned patient is defined as a false positive (FP) or a false negative (FN). The probability that a randomly selected patient from the screened population is misassigned, $P(\\text{misassigned})$, is the sum of the probabilities of these two mutually exclusive events.\n\nThe probability of a false positive is the joint probability of not having the biomarker and testing positive, $P(D^- \\cap T^+)$.\n$$ P(\\text{FP}) = P(T^+ | D^-) P(D^-) = (1 - \\text{spec})(1 - p) $$\nThe probability of a false negative is the joint probability of having the biomarker and testing negative, $P(D^+ \\cap T^-)$.\n$$ P(\\text{FN}) = P(T^- | D^+) P(D^+) = (1 - \\text{sens}) p $$\n\nThe total probability of a single patient being misassigned is:\n$$ P(\\text{misassigned}) = P(\\text{FP}) + P(\\text{FN}) = (1 - \\text{spec})(1 - p) + (1 - \\text{sens}) p $$\nLet $M$ be the random variable representing the number of misassigned patients in a cohort of $n$. Since the screening outcomes for each patient are assumed to be independent Bernoulli trials, the expected number of misassigned patients, $E[M]$, is the total number of patients $n$ multiplied by the probability of a single patient being misassigned.\n$$ E[M] = n \\cdot P(\\text{misassigned}) = n \\cdot \\left[ (1 - \\text{spec})(1 - p) + (1 - \\text{sens}) p \\right] $$\n\nSubstituting the given numerical values:\n$$ E[M] = 200 \\cdot \\left[ (1 - 0.99)(1 - 0.05) + (1 - 0.92)(0.05) \\right] $$\n$$ E[M] = 200 \\cdot \\left[ (0.01)(0.95) + (0.08)(0.05) \\right] $$\n$$ E[M] = 200 \\cdot \\left[ 0.0095 + 0.0040 \\right] $$\n$$ E[M] = 200 \\cdot 0.0135 = 2.7 $$\nRounding to four significant figures, the expected number of misassigned patients is $2.700$.", "answer": "$$\\boxed{\\begin{pmatrix} 0.8288 & 0.9958 & 2.700 \\end{pmatrix}}$$", "id": "4326317"}, {"introduction": "A key innovation in platform trials is the ability to adapt based on accumulating data, for instance by allocating more patients to more promising therapies. This \"response-adaptive randomization\" aims to improve trial efficiency and patient outcomes. This practice immerses you in the core mechanics of a Bayesian adaptive design by having you use the Beta-Binomial model to update beliefs about treatment efficacy and dynamically adjust patient allocation probabilities, gaining insight into how these trials learn and evolve [@problem_id:4326226].", "problem": "Consider a response-adaptive randomization policy within a multi-arm platform trial in precision oncology, where three targeted therapies are being evaluated in parallel for a biomarker-defined population. Let each arm have binary outcomes (success versus failure) and assume independent Beta-Binomial models for arm-level response probabilities. Specifically, assume a Beta prior $\\operatorname{Beta}(1,1)$ for each arm’s response probability. You observe cumulative data consisting of successes $(s_1,s_2,s_3)=(12,8,4)$ and failures $(f_1,f_2,f_3)=(18,22,26)$. The next cohort to be randomized has size $N=270$ patients. The decision policy is to allocate patients with probabilities proportional to the posterior expected response probabilities for each arm under the Beta-Binomial model with the specified prior and observed data.\n\nStarting from the fundamental definition of Bayes’ theorem and the conjugacy of the Beta prior to the Binomial likelihood, derive updated posterior distributions and posterior expectations for the response probabilities of the three arms. Then, derive the normalized allocation probabilities implied by the stated policy, and compute the expected sample sizes per arm for the next cohort of $N=270$ patients.\n\nReport the three allocation probabilities followed by the three expected sample sizes as a single row matrix. Express expected sample sizes as counts of patients. Do not round any quantities; provide exact values.", "solution": "The problem is valid as it is scientifically grounded in Bayesian statistics and clinical trial design, well-posed with all necessary information, and stated objectively. We can therefore proceed with a solution.\n\nLet $\\theta_k$ be the unknown true response probability for arm $k$, where $k \\in \\{1, 2, 3\\}$. The outcomes for each arm are binary (success or failure), so the number of successes $s_k$ in $n_k$ trials follows a Binomial distribution, $s_k \\sim \\operatorname{Binomial}(n_k, \\theta_k)$.\n\nThe problem specifies a Beta-Binomial model. For each arm $k$, we are given a prior distribution for the response probability $\\theta_k$. The prior is a Beta distribution, $\\theta_k \\sim \\operatorname{Beta}(\\alpha_0, \\beta_0)$. The problem states this is a $\\operatorname{Beta}(1, 1)$ prior, which is a uniform distribution on the interval $[0, 1]$. Thus, the initial parameters are $\\alpha_0 = 1$ and $\\beta_0 = 1$. The probability density function of the prior is $p(\\theta_k) = \\frac{\\Gamma(\\alpha_0+\\beta_0)}{\\Gamma(\\alpha_0)\\Gamma(\\beta_0)} \\theta_k^{\\alpha_0-1} (1-\\theta_k)^{\\beta_0-1}$ for $\\theta_k \\in [0, 1]$.\n\nThe likelihood of observing $s_k$ successes and $f_k$ failures in $n_k = s_k + f_k$ trials is given by the Binomial probability mass function, which is proportional to $\\theta_k^{s_k} (1-\\theta_k)^{f_k}$.\n\nAccording to Bayes' theorem, the posterior distribution of $\\theta_k$ is proportional to the product of the prior distribution and the likelihood function:\n$$p(\\theta_k | s_k, f_k) \\propto p(\\theta_k) \\times L(\\theta_k | s_k, f_k)$$\n$$p(\\theta_k | s_k, f_k) \\propto \\left[ \\theta_k^{\\alpha_0-1} (1-\\theta_k)^{\\beta_0-1} \\right] \\times \\left[ \\theta_k^{s_k} (1-\\theta_k)^{f_k} \\right]$$\n$$p(\\theta_k | s_k, f_k) \\propto \\theta_k^{\\alpha_0+s_k-1} (1-\\theta_k)^{\\beta_0+f_k-1}$$\nThis is the kernel of a Beta distribution. This demonstrates the conjugacy of the Beta prior for the Binomial likelihood. The updated posterior distribution for $\\theta_k$ is a Beta distribution with parameters $\\alpha_k = \\alpha_0 + s_k$ and $\\beta_k = \\beta_0 + f_k$.\nSo, $\\theta_k | s_k, f_k \\sim \\operatorname{Beta}(\\alpha_0 + s_k, \\beta_0 + f_k)$.\n\nWe are given the cumulative data for the three arms:\n- Arm 1: $s_1 = 12$, $f_1 = 18$\n- Arm 2: $s_2 = 8$, $f_2 = 22$\n- Arm 3: $s_3 = 4$, $f_3 = 26$\n\nAnd a prior of $\\operatorname{Beta}(1, 1)$ for all arms. We can now compute the posterior parameters for each arm.\n- For Arm 1:\n  $\\alpha_1 = \\alpha_0 + s_1 = 1 + 12 = 13$\n  $\\beta_1 = \\beta_0 + f_1 = 1 + 18 = 19$\n  The posterior distribution for $\\theta_1$ is $\\operatorname{Beta}(13, 19)$.\n- For Arm 2:\n  $\\alpha_2 = \\alpha_0 + s_2 = 1 + 8 = 9$\n  $\\beta_2 = \\beta_0 + f_2 = 1 + 22 = 23$\n  The posterior distribution for $\\theta_2$ is $\\operatorname{Beta}(9, 23)$.\n- For Arm 3:\n  $\\alpha_3 = \\alpha_0 + s_3 = 1 + 4 = 5$\n  $\\beta_3 = \\beta_0 + f_3 = 1 + 26 = 27$\n  The posterior distribution for $\\theta_3$ is $\\operatorname{Beta}(5, 27)$.\n\nThe randomization policy states that the allocation probabilities for the next cohort are proportional to the posterior expected response probabilities. The expected value of a random variable $X \\sim \\operatorname{Beta}(\\alpha, \\beta)$ is $E[X] = \\frac{\\alpha}{\\alpha + \\beta}$. Let $\\hat{\\theta}_k = E[\\theta_k | s_k, f_k]$ be the posterior expectation for arm $k$.\n- For Arm 1:\n  $\\hat{\\theta}_1 = \\frac{\\alpha_1}{\\alpha_1 + \\beta_1} = \\frac{13}{13 + 19} = \\frac{13}{32}$\n- For Arm 2:\n  $\\hat{\\theta}_2 = \\frac{\\alpha_2}{\\alpha_2 + \\beta_2} = \\frac{9}{9 + 23} = \\frac{9}{32}$\n- For Arm 3:\n  $\\hat{\\theta}_3 = \\frac{\\alpha_3}{\\alpha_3 + \\beta_3} = \\frac{5}{5 + 27} = \\frac{5}{32}$\n\nThe allocation probability for arm $k$, denoted $\\pi_k$, is proportional to $\\hat{\\theta}_k$. We must normalize these values so they sum to $1$. The normalization constant is the sum of the posterior expectations:\n$$ \\sum_{j=1}^3 \\hat{\\theta}_j = \\frac{13}{32} + \\frac{9}{32} + \\frac{5}{32} = \\frac{13 + 9 + 5}{32} = \\frac{27}{32} $$\nThe allocation probability for arm $k$ is $\\pi_k = \\frac{\\hat{\\theta}_k}{\\sum_{j=1}^3 \\hat{\\theta}_j}$.\n- For Arm 1:\n  $\\pi_1 = \\frac{13/32}{27/32} = \\frac{13}{27}$\n- For Arm 2:\n  $\\pi_2 = \\frac{9/32}{27/32} = \\frac{9}{27} = \\frac{1}{3}$\n- For Arm 3:\n  $\\pi_3 = \\frac{5/32}{27/32} = \\frac{5}{27}$\n\nThe next cohort has a size of $N=270$ patients. The expected number of patients allocated to arm $k$, $E[N_k]$, is given by $N \\times \\pi_k$.\n- Expected sample size for Arm 1:\n  $E[N_1] = 270 \\times \\pi_1 = 270 \\times \\frac{13}{27} = 10 \\times 13 = 130$\n- Expected sample size for Arm 2:\n  $E[N_2] = 270 \\times \\pi_2 = 270 \\times \\frac{1}{3} = 90$\n- Expected sample size for Arm 3:\n  $E[N_3] = 270 \\times \\pi_3 = 270 \\times \\frac{5}{27} = 10 \\times 5 = 50$\n\nThe results are the three allocation probabilities $(\\pi_1, \\pi_2, \\pi_3)$ and the three expected sample sizes $(E[N_1], E[N_2], E[N_3])$.", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{13}{27} & \\frac{1}{3} & \\frac{5}{27} & 130 & 90 & 50 \\end{pmatrix} } $$", "id": "4326226"}, {"introduction": "Basket and umbrella trials test therapies across multiple patient cohorts simultaneously, which introduces the challenge of multiple hypothesis testing. Making many comparisons inflates the risk of claiming a treatment is effective when it is not (a Type I error). This problem addresses this critical issue by having you apply and compare two common methods for controlling the Family-Wise Error Rate (FWER): the Bonferroni and Holm procedures, learning how to make statistically rigorous conclusions from multi-cohort data [@problem_id:4326251].", "problem": "A precision oncology basket trial evaluates a targeted therapy across $K=6$ histology-defined cohorts that share a predictive genomic biomarker. Each cohort implements a one-sided hypothesis test on a binary clinical endpoint against a common null, producing raw $p$-values $\\{0.002,\\,0.017,\\,0.04,\\,0.06,\\,0.21,\\,0.33\\}$. In multi-cohort designs such as basket, umbrella, and platform trials, controlling the Family-Wise Error Rate (FWER) is essential for scientific validity. Starting from the definition of FWER and the union bound (Bonferroni inequality), and from the general step-down principle underlying sequential rejective procedures, derive the adjusted $p$-values for both the Bonferroni and Holm procedures for $K$ hypotheses.\n\nThen, apply these derivations to the six cohorts to compute:\n1. The Bonferroni adjusted $p$-values for each cohort.\n2. The Holm adjusted $p$-values for each cohort (ordered results must be mapped back to the original cohort indexing, which here follows the ascending order of the given $p$-values).\n\nInterpret the decisions at significance level $\\alpha=0.05$ by comparing adjusted $p$-values to $\\alpha$. Encode each decision numerically as $1$ for “reject the null hypothesis for that cohort” and $0$ for “do not reject.” Round all adjusted $p$-values to four significant figures. Report the final answer as a single row matrix, in the following concatenated order:\n- Bonferroni adjusted $p$-values for cohorts $1$ through $6$,\n- Holm adjusted $p$-values for cohorts $1$ through $6$,\n- Bonferroni decisions (in cohort order),\n- Holm decisions (in cohort order).", "solution": "The problem is valid as it is scientifically grounded in established statistical theory for clinical trials, is well-posed with all necessary information provided, and is stated objectively.\n\nLet there be $K$ null hypotheses, $H_1, H_2, \\dots, H_K$, and their corresponding raw $p$-values, $p_1, p_2, \\dots, p_K$. The goal of a multiple testing procedure is to control the Family-Wise Error Rate (FWER), which is the probability of making at least one Type I error (incorrectly rejecting a true null hypothesis) among the family of $K$ tests. A procedure controls the FWER at level $\\alpha$ if $FWER \\le \\alpha$.\n\nLet $I_0$ be the set of indices corresponding to true null hypotheses. Then,\n$$FWER = P\\left(\\bigcup_{i \\in I_0} \\{\\text{reject } H_i\\}\\right)$$\n\n**Derivation of the Bonferroni Procedure**\nThe Bonferroni procedure is based on the Boole's or union bound inequality, which states that for any collection of events $A_1, \\dots, A_K$:\n$$P\\left(\\bigcup_{i=1}^K A_i\\right) \\le \\sum_{i=1}^K P(A_i)$$\nApplying this to the FWER definition:\n$$FWER = P\\left(\\bigcup_{i \\in I_0} \\{\\text{reject } H_i\\}\\right) \\le \\sum_{i \\in I_0} P(\\text{reject } H_i)$$\nThe simple Bonferroni method rejects hypothesis $H_i$ if its raw $p$-value $p_i$ is less than or equal to $\\alpha/K$. Under a true null hypothesis $H_i$, the $p$-value $p_i$ follows a Uniform($0,1$) distribution, so $P(p_i \\le c) = c$. Therefore, $P(\\text{reject } H_i) = P(p_i \\le \\alpha/K) = \\alpha/K$.\nSubstituting this into the inequality:\n$$FWER \\le \\sum_{i \\in I_0} \\frac{\\alpha}{K} = |I_0| \\frac{\\alpha}{K} \\le K \\frac{\\alpha}{K} = \\alpha$$\nThis demonstrates that the procedure controls the FWER at level $\\alpha$.\n\nThe Bonferroni adjusted $p$-value, $\\tilde{p}_i^{\\text{Bonf}}$, is the smallest overall significance level $\\alpha$ at which the hypothesis $H_i$ would be rejected. Rejection occurs when $p_i \\le \\alpha/K$, which is equivalent to $K p_i \\le \\alpha$. Thus, the adjusted $p$-value is defined as:\n$$\\tilde{p}_i^{\\text{Bonf}} = \\min(K p_i, 1)$$\nThe value is capped at $1$ because a probability cannot exceed $1$.\n\n**Derivation of the Holm Procedure**\nThe Holm procedure is a sequential step-down method that is uniformly more powerful than the Bonferroni procedure. It follows these steps:\n1. Order the raw $p$-values from smallest to largest: $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(K)}$. Let the corresponding hypotheses be $H_{(1)}, H_{(2)}, \\dots, H_{(K)}$.\n2. For $j = 1, 2, \\dots, K$, compare the $j$-th ordered $p$-value $p_{(j)}$ with a sequentially adjusted significance level $\\alpha / (K - j + 1)$.\n3. If $p_{(1)} \\le \\alpha/K$, reject $H_{(1)}$ and proceed to step $j=2$. If not, fail to reject all hypotheses and stop.\n4. In general, if $H_{(1)}, \\dots, H_{(j-1)}$ have been rejected, compare $p_{(j)}$ to $\\alpha/(K - j + 1)$. If $p_{(j)} \\le \\alpha/(K - j + 1)$, reject $H_{(j)}$ and continue. Otherwise, fail to reject $H_{(j)}$ and all remaining hypotheses $H_{(j+1)}, \\dots, H_{(K)}$, and stop.\n\nThe Holm adjusted $p$-value, $\\tilde{p}_{(j)}^{\\text{Holm}}$, for the $j$-th ordered hypothesis $H_{(j)}$ is derived from this sequential process. To reject $H_{(j)}$, we must have rejected all preceding hypotheses $H_{(i)}$ for $i < j$. This requires $p_{(i)} \\le \\alpha/(K - i + 1)$ for all $i = 1, \\dots, j$. This is equivalent to requiring $\\alpha \\ge (K - i + 1)p_{(i)}$ for all $i = 1, \\dots, j$. The smallest $\\alpha$ that satisfies this for $H_{(j)}$ is therefore the maximum of these required values. To ensure the adjusted $p$-values are monotonically non-decreasing, we define the adjusted $p$-value for the $j$-th ordered hypothesis as:\n$$\\tilde{p}_{(j)}^{\\text{Holm}} = \\min\\left(1, \\max_{i=1, \\dots, j} \\{(K-i+1)p_{(i)}\\}\\right)$$\nThis can be computed recursively:\n$\\tilde{p}_{(1)}^{\\text{Holm}} = \\min(1, K p_{(1)})$\n$\\tilde{p}_{(j)}^{\\text{Holm}} = \\min(1, \\max(\\tilde{p}_{(j-1)}^{\\text{Holm}}, (K-j+1)p_{(j)}))$ for $j > 1$.\n\n**Application to the Given Data**\nThe number of cohorts (hypotheses) is $K=6$. The raw $p$-values are already provided in ascending order:\n$p_{(1)} = 0.002$\n$p_{(2)} = 0.017$\n$p_{(3)} = 0.04$\n$p_{(4)} = 0.06$\n$p_{(5)} = 0.21$\n$p_{(6)} = 0.33$\n\nThe significance level is $\\alpha = 0.05$.\n\n**1. Bonferroni Adjusted $p$-values and Decisions**\nWe use the formula $\\tilde{p}_j^{\\text{Bonf}} = \\min(6 p_j, 1)$.\n$\\tilde{p}_1^{\\text{Bonf}} = \\min(6 \\times 0.002, 1) = \\min(0.012, 1) = 0.01200$\n$\\tilde{p}_2^{\\text{Bonf}} = \\min(6 \\times 0.017, 1) = \\min(0.102, 1) = 0.1020$\n$\\tilde{p}_3^{\\text{Bonf}} = \\min(6 \\times 0.04, 1) = \\min(0.24, 1) = 0.2400$\n$\\tilde{p}_4^{\\text{Bonf}} = \\min(6 \\times 0.06, 1) = \\min(0.36, 1) = 0.3600$\n$\\tilde{p}_5^{\\text{Bonf}} = \\min(6 \\times 0.21, 1) = \\min(1.26, 1) = 1.000$\n$\\tilde{p}_6^{\\text{Bonf}} = \\min(6 \\times 0.33, 1) = \\min(1.98, 1) = 1.000$\n\nDecisions: Reject $H_j$ if $\\tilde{p}_j^{\\text{Bonf}} \\le 0.05$.\n- Cohort 1: $0.01200 \\le 0.05 \\implies$ Reject (1)\n- Cohort 2: $0.1020 > 0.05 \\implies$ Fail to reject (0)\n- Cohort 3: $0.2400 > 0.05 \\implies$ Fail to reject (0)\n- Cohort 4: $0.3600 > 0.05 \\implies$ Fail to reject (0)\n- Cohort 5: $1.000 > 0.05 \\implies$ Fail to reject (0)\n- Cohort 6: $1.000 > 0.05 \\implies$ Fail to reject (0)\n\n**2. Holm Adjusted $p$-values and Decisions**\nWe use the recursive formula $\\tilde{p}_{(j)}^{\\text{Holm}} = \\min(1, \\max(\\tilde{p}_{(j-1)}^{\\text{Holm}}, (K-j+1)p_{(j)}))$.\n- For $j=1$: $\\tilde{p}_{(1)}^{\\text{Holm}} = \\min(1, (6-1+1)p_{(1)}) = \\min(1, 6 \\times 0.002) = 0.01200$.\n- For $j=2$: $\\tilde{p}_{(2)}^{\\text{Holm}} = \\min(1, \\max(\\tilde{p}_{(1)}^{\\text{Holm}}, (6-2+1)p_{(2)})) = \\min(1, \\max(0.012, 5 \\times 0.017)) = \\min(1, \\max(0.012, 0.085)) = 0.08500$.\n- For $j=3$: $\\tilde{p}_{(3)}^{\\text{Holm}} = \\min(1, \\max(\\tilde{p}_{(2)}^{\\text{Holm}}, (6-3+1)p_{(3)})) = \\min(1, \\max(0.085, 4 \\times 0.04)) = \\min(1, \\max(0.085, 0.16)) = 0.1600$.\n- For $j=4$: $\\tilde{p}_{(4)}^{\\text{Holm}} = \\min(1, \\max(\\tilde{p}_{(3)}^{\\text{Holm}}, (6-4+1)p_{(4)})) = \\min(1, \\max(0.16, 3 \\times 0.06)) = \\min(1, \\max(0.16, 0.18)) = 0.1800$.\n- For $j=5$: $\\tilde{p}_{(5)}^{\\text{Holm}} = \\min(1, \\max(\\tilde{p}_{(4)}^{\\text{Holm}}, (6-5+1)p_{(5)})) = \\min(1, \\max(0.18, 2 \\times 0.21)) = \\min(1, \\max(0.18, 0.42)) = 0.4200$.\n- For $j=6$: $\\tilde{p}_{(6)}^{\\text{Holm}} = \\min(1, \\max(\\tilde{p}_{(5)}^{\\text{Holm}}, (6-6+1)p_{(6)})) = \\min(1, \\max(0.42, 1 \\times 0.33)) = \\min(1, 0.42) = 0.4200$.\n\nThe set of Holm adjusted $p$-values (rounded to four significant figures) is: $\\{0.01200, 0.08500, 0.1600, 0.1800, 0.4200, 0.4200\\}$.\n\nDecisions: Reject $H_j$ if $\\tilde{p}_j^{\\text{Holm}} \\le 0.05$.\n- Cohort 1: $0.01200 \\le 0.05 \\implies$ Reject (1)\n- Cohort 2: $0.08500 > 0.05 \\implies$ Fail to reject (0)\n- Cohort 3: $0.1600 > 0.05 \\implies$ Fail to reject (0)\n- Cohort 4: $0.1800 > 0.05 \\implies$ Fail to reject (0)\n- Cohort 5: $0.4200 > 0.05 \\implies$ Fail to reject (0)\n- Cohort 6: $0.4200 > 0.05 \\implies$ Fail to reject (0)\n\nIn this case, both methods lead to the same conclusion: only the null hypothesis for the first cohort is rejected.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.01200 & 0.1020 & 0.2400 & 0.3600 & 1.000 & 1.000 & 0.01200 & 0.08500 & 0.1600 & 0.1800 & 0.4200 & 0.4200 & 1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\n\\end{pmatrix}\n}\n$$", "id": "4326251"}]}