{"hands_on_practices": [{"introduction": "A primary task in genomic surveillance is to identify putative transmission clusters from sequence data. This is often achieved by calculating pairwise genetic distances, such as Single Nucleotide Polymorphism (SNP) counts, and grouping genetically similar isolates. This exercise [@problem_id:4347474] provides hands-on practice with single-linkage clustering, a fundamental graph-based method. More importantly, it challenges you to confront a common real-world complication: how ascertainment bias, where only a fraction of true genetic variants are observed, can distort our view of transmission networks and lead to incorrect epidemiological inferences.", "problem": "Consider a pathogen genomic dataset of six isolates $S_1, S_2, S_3, S_4, S_5, S_6$ collected during an outbreak investigation. The pairwise Single Nucleotide Polymorphism (SNP) distances $D_{ij}$ between isolates $S_i$ and $S_j$ are measured across the whole genome (excluding repetitive and unreliable regions) and are given by the following values for $i<j$:\n$D_{12}=2$, $D_{13}=4$, $D_{14}=7$, $D_{15}=8$, $D_{16}=6$, $D_{23}=3$, $D_{24}=6$, $D_{25}=7$, $D_{26}=5$, $D_{34}=8$, $D_{35}=9$, $D_{36}=7$, $D_{45}=3$, $D_{46}=7$, $D_{56}=8$.\n\nA single-linkage clustering rule is applied with threshold $\\tau=5$: isolates $S_i$ and $S_j$ are connected by an edge if $D_{ij} \\leq \\tau$, and clusters are the connected components of the resulting undirected graph.\n\nPart (a): Using the above rule, determine the connected components (cluster membership) implied by the true whole-genome distances.\n\nPart (b): In many precision medicine and genomic diagnostics settings, ascertainment bias arises when targeted genotyping panels or minor-allele-frequency filters observe only a fraction $q$ of true variants. Model this ascertainment by assuming that, conditional on a true distance $D_{ij}=k$, the observed count of differences $X_{ij}$ follows a Binomial thinning model $X_{ij} \\sim \\mathrm{Binomial}(k,q)$, independently across pairs, with $q=0.6$. Under the same single-linkage threshold $\\tau=5$, an edge is present if the observed distance $X_{ij} \\leq \\tau$.\n\nDefine the misclassification count $M$ as the number of pairwise relationships whose edge status under the observed distances disagrees with the edge status under the true distances (i.e., false merges where $D_{ij}>\\tau$ but $X_{ij}\\leq\\tau$, plus false splits where $D_{ij}\\leq\\tau$ but $X_{ij}>\\tau$). Derive an expression for the expected value $\\mathbb{E}[M]$ under the Binomial thinning model and evaluate it numerically for the given distances and $q=0.6$.\n\nRound your final numerical answer for $\\mathbb{E}[M]$ to four significant figures. Express the final value as a dimensionless quantity.", "solution": "The user has provided a problem in two parts. First, I will validate the problem statement.\n\n### Problem Validation\n\n#### Step 1: Extract Givens\n- **Isolates**: A set of six isolates $\\{S_1, S_2, S_3, S_4, S_5, S_6\\}$.\n- **True Pairwise SNP Distances ($D_{ij}$)**:\n  - $D_{12}=2$, $D_{13}=4$, $D_{14}=7$, $D_{15}=8$, $D_{16}=6$\n  - $D_{23}=3$, $D_{24}=6$, $D_{25}=7$, $D_{26}=5$\n  - $D_{34}=8$, $D_{35}=9$, $D_{36}=7$\n  - $D_{45}=3$, $D_{46}=7$\n  - $D_{56}=8$\n- **Clustering Rule (True Distances)**: An edge connects isolates $S_i$ and $S_j$ if $D_{ij} \\leq \\tau$, where the threshold is $\\tau=5$. Clusters are the connected components of the resulting graph.\n- **Model for Observed Distances ($X_{ij}$)**: For a true distance $D_{ij}=k$, the observed distance $X_{ij}$ is a random variable following a Binomial distribution: $X_{ij} \\sim \\mathrm{Binomial}(k, q)$, with $q=0.6$. This is applied independently for each pair $(i, j)$.\n- **Clustering Rule (Observed Distances)**: An edge connects isolates $S_i$ and $S_j$ if $X_{ij} \\leq \\tau=5$.\n- **Misclassification Count ($M$)**: Defined as the number of pairwise relationships whose edge status under observed distances disagrees with the edge status under true distances. This includes false merges ($D_{ij} > \\tau$ but $X_{ij} \\leq \\tau$) and false splits ($D_{ij} \\leq \\tau$ but $X_{ij} > \\tau$).\n- **Tasks**:\n  1.  **(Part a)** Determine the clusters (connected components) based on the true distances $D_{ij}$.\n  2.  **(Part b)** Derive an expression for the expected misclassification count, $\\mathbb{E}[M]$, and evaluate it numerically for $q=0.6$, rounded to four significant figures.\n\n#### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is well-grounded in genomic epidemiology and biostatistics. It uses standard concepts like SNP distances, single-linkage clustering, and Binomial models for sampling/ascertainment processes. The setup is a valid, though simplified, representation of real-world challenges in infectious disease surveillance.\n2.  **Well-Posed**: The problem is clearly defined. Part (a) is a direct application of graph theory. Part (b) is a well-defined expectation calculation based on a probabilistic model. All parameters and definitions are provided, leading to a unique solution.\n3.  **Objective**: The problem is stated using precise, objective, and formal language.\n4.  **Completeness and Consistency**: The set of $15$ pairwise distances for $6$ isolates is complete. All necessary parameters ($\\tau=5$, $q=0.6$) are given. There are no contradictions.\n\n#### Step 3: Verdict and Action\nThe problem is valid. I will proceed with a full solution.\n\n### Solution\n\n#### Part (a): Cluster Membership from True Distances\n\nThe clustering rule states that an edge exists between isolates $S_i$ and $S_j$ if their true SNP distance $D_{ij}$ is less than or equal to the threshold $\\tau=5$. We must identify the pairs $(i, j)$ that satisfy $D_{ij} \\leq 5$.\n\nThe given distances are:\n- $D_{12}=2 \\leq 5$ (Edge)\n- $D_{13}=4 \\leq 5$ (Edge)\n- $D_{14}=7 > 5$\n- $D_{15}=8 > 5$\n- $D_{16}=6 > 5$\n- $D_{23}=3 \\leq 5$ (Edge)\n- $D_{24}=6 > 5$\n- $D_{25}=7 > 5$\n- $D_{26}=5 \\leq 5$ (Edge)\n- $D_{34}=8 > 5$\n- $D_{35}=9 > 5$\n- $D_{36}=7 > 5$\n- $D_{45}=3 \\leq 5$ (Edge)\n- $D_{46}=7 > 5$\n- $D_{56}=8 > 5$\n\nThe set of edges in the graph is $\\{(S_1, S_2), (S_1, S_3), (S_2, S_3), (S_2, S_6), (S_4, S_5)\\}$. We now find the connected components of this graph.\n- $S_1$ is connected to $S_2$ and $S_3$.\n- $S_2$ is connected to $S_1$, $S_3$, and $S_6$.\n- $S_3$ is connected to $S_1$ and $S_2$.\n- $S_6$ is connected to $S_2$.\n- From these connections, we can see that a path exists between any two nodes in the set $\\{S_1, S_2, S_3, S_6\\}$. For example, $S_1$ is connected to $S_6$ via the path $S_1 \\to S_2 \\to S_6$. Therefore, $\\{S_1, S_2, S_3, S_6\\}$ forms a single connected component.\n- The remaining isolates are $S_4$ and $S_5$. They are connected to each other by the edge $(S_4, S_5)$. There are no edges connecting $\\{S_4, S_5\\}$ to the first component.\n- Thus, $\\{S_4, S_5\\}$ forms a second connected component.\n\nThe clusters are the connected components.\nCluster 1: $\\{S_1, S_2, S_3, S_6\\}$\nCluster 2: $\\{S_4, S_5\\}$\n\n#### Part (b): Expected Misclassification Count\n\nThe misclassification count $M$ is the total number of pairs $(i, j)$ for $i<j$ where the edge status is incorrect under the observed distances $X_{ij}$. Let $M_{ij}$ be an indicator variable for a misclassification for the pair $(i, j)$:\n$$ M_{ij} = \\mathbb{I}((D_{ij} \\leq \\tau \\text{ and } X_{ij} > \\tau) \\lor (D_{ij} > \\tau \\text{ and } X_{ij} \\leq \\tau)) $$\nThe total misclassification count is $M = \\sum_{i<j} M_{ij}$. By the linearity of expectation:\n$$ \\mathbb{E}[M] = \\sum_{i<j} \\mathbb{E}[M_{ij}] $$\nThe expectation of an indicator variable is the probability of the event it indicates. The two events in the definition of $M_{ij}$ are mutually exclusive. Therefore:\n$$ \\mathbb{E}[M_{ij}] = P(D_{ij} \\leq \\tau \\text{ and } X_{ij} > \\tau) + P(D_{ij} > \\tau \\text{ and } X_{ij} \\leq \\tau) $$\nSince $D_{ij}$ is a fixed, given constant for each pair, we can analyze two distinct cases:\n\nCase 1: The true distance is at or below the threshold ($D_{ij} \\leq \\tau$).\nThese are the pairs that form an edge in the true-distance graph. A misclassification occurs if $X_{ij} > \\tau$ (a \"false split\"). The probability of this is $P(X_{ij} > \\tau)$. Here, $\\tau=5$. For all pairs with $D_{ij} \\leq 5$, the values are $D_{12}=2, D_{13}=4, D_{23}=3, D_{26}=5, D_{45}=3$.\nThe observed count $X_{ij}$ follows a $\\mathrm{Binomial}(D_{ij}, q)$ distribution. A property of the binomial distribution is that the random variable can take values only up to the number of trials, i.e., $0 \\leq X_{ij} \\leq D_{ij}$.\nSince for all these pairs $D_{ij} \\leq 5$, it is impossible for $X_{ij}$ to be greater than $5$. Thus, for every pair where $D_{ij} \\leq 5$, $P(X_{ij} > 5) = 0$. The contribution to $\\mathbb{E}[M]$ from these pairs is $0$.\n\nCase 2: The true distance is above the threshold ($D_{ij} > \\tau$).\nThese are the pairs that do not form an edge in the true-distance graph. A misclassification occurs if $X_{ij} \\leq \\tau$ (a \"false merge\"). The probability of this is $P(X_{ij} \\leq \\tau)$. Here, $\\tau=5$.\nThe total expected misclassification count is the sum of these probabilities over all pairs with $D_{ij} > 5$:\n$$ \\mathbb{E}[M] = \\sum_{i<j : D_{ij} > 5} P(X_{ij} \\leq 5) $$\nwhere $X_{ij} \\sim \\mathrm{Binomial}(D_{ij}, q=0.6)$. The probability term is the cumulative distribution function (CDF) of the Binomial distribution, $F(5; D_{ij}, 0.6)$.\n\nWe now list the pairs with $D_{ij} > 5$ and group them by distance value:\n- $D_{ij} = 6$: $D_{16}, D_{24}$ ($2$ pairs)\n- $D_{ij} = 7$: $D_{14}, D_{25}, D_{36}, D_{46}$ ($4$ pairs)\n- $D_{ij} = 8$: $D_{15}, D_{34}, D_{56}$ ($3$ pairs)\n- $D_{ij} = 9$: $D_{35}$ ($1$ pair)\n\nThe expression for $\\mathbb{E}[M]$ is:\n$$ \\mathbb{E}[M] = 2 \\cdot P(X \\leq 5 | k=6) + 4 \\cdot P(X \\leq 5 | k=7) + 3 \\cdot P(X \\leq 5 | k=8) + 1 \\cdot P(X \\leq 5 | k=9) $$\nwhere $X \\sim \\mathrm{Binomial}(k, 0.6)$. We calculate each probability term. Let $p=0.6$ and $1-p=0.4$.\n$P(X \\leq 5) = 1 - P(X > 5)$.\n\n1.  For $k=6$: $X \\sim \\mathrm{Binomial}(6, 0.6)$.\n    $P(X \\leq 5) = 1 - P(X=6) = 1 - \\binom{6}{6}p^6(1-p)^0 = 1 - (0.6)^6 = 1 - 0.046656 = 0.953344$.\n\n2.  For $k=7$: $X \\sim \\mathrm{Binomial}(7, 0.6)$.\n    $P(X \\leq 5) = 1 - P(X=6) - P(X=7)$.\n    $P(X=6) = \\binom{7}{6}p^6(1-p)^1 = 7 \\cdot (0.6)^6 \\cdot (0.4)^1 = 7 \\cdot 0.046656 \\cdot 0.4 = 0.1306368$.\n    $P(X=7) = \\binom{7}{7}p^7(1-p)^0 = (0.6)^7 = 0.0279936$.\n    $P(X \\leq 5) = 1 - (0.1306368 + 0.0279936) = 1 - 0.1586304 = 0.8413696$.\n\n3.  For $k=8$: $X \\sim \\mathrm{Binomial}(8, 0.6)$.\n    $P(X \\leq 5) = 1 - P(X=6) - P(X=7) - P(X=8)$.\n    $P(X=6) = \\binom{8}{6}p^6(1-p)^2 = 28 \\cdot (0.6)^6 \\cdot (0.4)^2 = 28 \\cdot 0.046656 \\cdot 0.16 = 0.20901888$.\n    $P(X=7) = \\binom{8}{7}p^7(1-p)^1 = 8 \\cdot (0.6)^7 \\cdot (0.4)^1 = 8 \\cdot 0.0279936 \\cdot 0.4 = 0.08957952$.\n    $P(X=8) = \\binom{8}{8}p^8(1-p)^0 = (0.6)^8 = 0.01679616$.\n    $P(X \\leq 5) = 1 - (0.20901888 + 0.08957952 + 0.01679616) = 1 - 0.31539456 = 0.68460544$.\n\n4.  For $k=9$: $X \\sim \\mathrm{Binomial}(9, 0.6)$.\n    $P(X \\leq 5) = 1 - P(X=6) - P(X=7) - P(X=8) - P(X=9)$.\n    $P(X=6) = \\binom{9}{6}p^6(1-p)^3 = 84 \\cdot (0.6)^6 \\cdot (0.4)^3 = 84 \\cdot 0.046656 \\cdot 0.064 = 0.250822656$.\n    $P(X=7) = \\binom{9}{7}p^7(1-p)^2 = 36 \\cdot (0.6)^7 \\cdot (0.4)^2 = 36 \\cdot 0.0279936 \\cdot 0.16 = 0.161243136$.\n    $P(X=8) = \\binom{9}{8}p^8(1-p)^1 = 9 \\cdot (0.6)^8 \\cdot (0.4)^1 = 9 \\cdot 0.01679616 \\cdot 0.4 = 0.060466176$.\n    $P(X=9) = \\binom{9}{9}p^9(1-p)^0 = (0.6)^9 = 0.010077696$.\n    $P(X \\leq 5) = 1 - (0.250822656 + 0.161243136 + 0.060466176 + 0.010077696) = 1 - 0.482609664 = 0.517390336$.\n\nNow, we can compute $\\mathbb{E}[M]$:\n$$ \\mathbb{E}[M] = 2 \\cdot (0.953344) + 4 \\cdot (0.8413696) + 3 \\cdot (0.68460544) + 1 \\cdot (0.517390336) $$\n$$ \\mathbb{E}[M] = 1.906688 + 3.3654784 + 2.05381632 + 0.517390336 $$\n$$ \\mathbb{E}[M] = 7.843373056 $$\n\nThe problem asks to round the final numerical answer to four significant figures.\nThe value is $7.843373056$. The first four significant figures are $7, 8, 4, 3$. The fifth significant figure is $3$, which is less than $5$, so we round down.\nThe final numerical answer is $7.843$. This is a dimensionless quantity as it is a count.", "answer": "$$\n\\boxed{7.843}\n$$", "id": "4347474"}, {"introduction": "Beyond identifying static clusters, genomic epidemiology aims to understand the tempo of pathogen evolution. A key concept is the 'molecular clock', the idea that mutations accumulate at a relatively steady rate over time. This exercise [@problem_id:4347450] guides you through a cornerstone technique for quantifying this rate: root-to-tip regression. By performing a linear regression of genetic divergence against sampling time, you will estimate the substitution rate ($\\mu$) and learn how to assess the statistical significance of this 'temporal signal', a critical step in any time-resolved phylogenetic analysis.", "problem": "A central task in genomic epidemiology is to test for and quantify a molecular clock signal. Under a strict molecular clock, the expected root-to-tip genetic divergence (measured in substitutions per site) increases linearly with sampling time because nucleotide substitutions accumulate approximately as a Poisson process with rate parameter equal to the substitution rate per site per unit time. Consider a set of viruses sampled over multiple years for which a time-resolved phylogeny has been inferred. For each tip sequence, you are given its sampling time (in years since a common reference year) and its root-to-tip distance (in substitutions per site) along the inferred time-scaled tree. Assume that ordinary least squares regression of root-to-tip distance on sampling time is an appropriate estimator under homoscedastic, approximately normally distributed residuals around the linear expectation implied by the molecular clock.\n\nData: There are $5$ isolates with $(x_i,y_i)$ pairs, where $x_i$ is time in years since the reference year $2014.0$ and $y_i$ is the root-to-tip distance in substitutions per site:\n- $(x_1,y_1)=(0,\\,0.00148)$\n- $(x_2,y_2)=(1,\\,0.00231)$\n- $(x_3,y_3)=(2,\\,0.00309)$\n- $(x_4,y_4)=(3,\\,0.00392)$\n- $(x_5,y_5)=(4,\\,0.00469)$\n\nTasks:\n1. Using ordinary least squares, compute the slope and intercept of the regression of $y$ on $x$.\n2. Interpret the slope as the estimated substitution rate per site per year, denoted $\\mu$, under the strict molecular clock.\n3. Assess the statistical significance of temporal signal by testing the null hypothesis that the slope is zero using a two-sided $t$-test at significance level $\\alpha=0.05$, and briefly justify your conclusion based on the computed test statistic.\n\nReport your final numerical answer as the estimate of $\\mu$ rounded to three significant figures. Express $\\mu$ in substitutions per site per year. Do not include any other quantities in your final answer.", "solution": "The problem is well-defined and scientifically valid. It describes a standard application of linear regression in molecular phylogenetics, known as root-to-tip regression, used to estimate evolutionary rates and test for a temporal signal (molecular clock). All necessary data and statistical assumptions are provided, making the problem self-contained and solvable.\n\nThe problem asks for three tasks to be completed:\n1. Computation of the slope and intercept for an ordinary least squares (OLS) regression.\n2. Interpretation of the slope as an evolutionary rate.\n3. Assessment of the statistical significance of the slope via a $t$-test.\n\nThe linear model for the regression of root-to-tip distance ($y$) on sampling time ($x$) is given by:\n$$y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$$\nwhere $y_i$ is the root-to-tip distance for the $i$-th isolate, $x_i$ is its sampling time, $\\beta_0$ is the intercept, $\\beta_1$ is the slope, and $\\epsilon_i$ represents the residual error. The model assumes the errors are independent and identically distributed with a mean of $0$ and a constant variance $\\sigma^2$.\n\nThe data provided are $n=5$ pairs of $(x_i, y_i)$:\n$(0, 0.00148)$, $(1, 0.00231)$, $(2, 0.00309)$, $(3, 0.00392)$, $(4, 0.00469)$.\n\nFirst, we calculate the summary statistics needed for OLS regression.\nThe sample size is $n=5$.\nThe sum of the $x_i$ values is:\n$$\\sum_{i=1}^{5} x_i = 0 + 1 + 2 + 3 + 4 = 10$$\nThe sample mean of $x$ is:\n$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i = \\frac{10}{5} = 2$$\nThe sum of the $y_i$ values is:\n$$\\sum_{i=1}^{5} y_i = 0.00148 + 0.00231 + 0.00309 + 0.00392 + 0.00469 = 0.01549$$\nThe sample mean of $y$ is:\n$$\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i = \\frac{0.01549}{5} = 0.003098$$\n\nNext, we compute the sum of squares $S_{xx}$ and the sum of cross-products $S_{xy}$.\n$$S_{xx} = \\sum_{i=1}^{n} (x_i - \\bar{x})^2 = (0-2)^2 + (1-2)^2 + (2-2)^2 + (3-2)^2 + (4-2)^2 = 4 + 1 + 0 + 1 + 4 = 10$$\n$$S_{xy} = \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$$\n$$S_{xy} = (0-2)(0.00148 - 0.003098) + (1-2)(0.00231 - 0.003098) + (2-2)(0.00309 - 0.003098) + (3-2)(0.00392 - 0.003098) + (4-2)(0.00469 - 0.003098)$$\n$$S_{xy} = (-2)(-0.001618) + (-1)(-0.000788) + (0)(-0.000008) + (1)(0.000822) + (2)(0.001592)$$\n$$S_{xy} = 0.003236 + 0.000788 + 0 + 0.000822 + 0.003184 = 0.00803$$\n\nTask 1: Compute the slope and intercept.\nThe OLS estimator for the slope $\\beta_1$ is:\n$$\\hat{\\beta}_1 = \\frac{S_{xy}}{S_{xx}} = \\frac{0.00803}{10} = 0.000803$$\nThe OLS estimator for the intercept $\\beta_0$ is:\n$$\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} = 0.003098 - (0.000803)(2) = 0.003098 - 0.001606 = 0.001492$$\nThe estimated regression line is $\\hat{y} = 0.001492 + 0.000803x$.\n\nTask 2: Interpret the slope.\nThe slope, $\\hat{\\beta}_1$, represents the estimated increase in root-to-tip genetic distance for each additional year of sampling time. This corresponds directly to the definition of the substitution rate per site per year, denoted by $\\mu$.\n$$\\mu = \\hat{\\beta}_1 = 0.000803 \\text{ substitutions per site per year}$$\n\nTask 3: Assess the statistical significance of the temporal signal.\nWe test the null hypothesis $H_0: \\beta_1 = 0$ against the two-sided alternative $H_1: \\beta_1 \\neq 0$ at a significance level of $\\alpha=0.05$.\nThe test statistic is $t = \\frac{\\hat{\\beta}_1}{\\text{SE}(\\hat{\\beta}_1)}$, which follows a $t$-distribution with $n-2$ degrees of freedom under the null hypothesis. Here, the degrees of freedom are $df = 5-2 = 3$.\n\nTo compute the standard error of the slope, $\\text{SE}(\\hat{\\beta}_1)$, we first need the sum of squared errors (SSE) and the residual standard error ($s$).\nWe first need the total sum of squares for $y$, $S_{yy}$:\n$$S_{yy} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2 = (-0.001618)^2 + (-0.000788)^2 + (-0.000008)^2 + (0.000822)^2 + (0.001592)^2$$\n$$S_{yy} \\approx 2.617924 \\times 10^{-6} + 0.620944 \\times 10^{-6} + 0.000064 \\times 10^{-6} + 0.675684 \\times 10^{-6} + 2.534464 \\times 10^{-6} \\approx 6.44908 \\times 10^{-6}$$\nThe sum of squared errors is calculated as:\n$$\\text{SSE} = S_{yy} - \\frac{(S_{xy})^2}{S_{xx}} = 6.44908 \\times 10^{-6} - \\frac{(0.00803)^2}{10} = 6.44908 \\times 10^{-6} - \\frac{0.0000644809}{10}$$\n$$\\text{SSE} = 6.44908 \\times 10^{-6} - 6.44809 \\times 10^{-6} = 9.9 \\times 10^{-10}$$\nThe unbiased estimator of the variance of the residuals, $s^2$, is:\n$$s^2 = \\frac{\\text{SSE}}{n-2} = \\frac{9.9 \\times 10^{-10}}{3} = 3.3 \\times 10^{-10}$$\nThe standard error of the slope estimate is:\n$$\\text{SE}(\\hat{\\beta}_1) = \\sqrt{\\frac{s^2}{S_{xx}}} = \\sqrt{\\frac{3.3 \\times 10^{-10}}{10}} = \\sqrt{3.3 \\times 10^{-11}} \\approx 5.74456 \\times 10^{-6}$$\nNow we can compute the $t$-statistic:\n$$t = \\frac{\\hat{\\beta}_1 - 0}{\\text{SE}(\\hat{\\beta}_1)} = \\frac{0.000803}{5.74456 \\times 10^{-6}} \\approx 139.78$$\nFor a two-sided test with $\\alpha = 0.05$ and $df = 3$, the critical $t$-value is $t_{\\alpha/2, df} = t_{0.025, 3}$. From standard statistical tables, $t_{0.025, 3} = 3.182$.\nSince the absolute value of our test statistic, $|t| \\approx 139.78$, is substantially larger than the critical value of $3.182$, we reject the null hypothesis $H_0: \\beta_1 = 0$. The $p$-value associated with this $t$-statistic is extremely small ($p \\ll 0.05$). This provides very strong evidence that the slope is not zero, and thus there is a significant temporal signal in the data. The observed linear relationship between genetic distance and sampling time is statistically significant.\n\nThe final answer requires the estimate of $\\mu$ rounded to three significant figures.\n$$\\mu = 0.000803$$\nThis value is already expressed to three significant figures ($8$, $0$, and $3$). In standard scientific notation, this is $8.03 \\times 10^{-4}$.", "answer": "$$\\boxed{8.03 \\times 10^{-4}}$$", "id": "4347450"}, {"introduction": "The ultimate synthesis in genomic epidemiology involves using phylogenetic trees to reconstruct the historical dynamics of an epidemic. The branching patterns within a dated tree are a direct echo of the population-level processes of transmission and recovery. In this advanced practice [@problem_id:4347420], you will implement and compare two powerful phylodynamic models: the Bayesian Skyline Plot (BSP) for estimating effective population size ($N_e(t)$) and a Yule birth-process model for estimating the effective reproductive number ($R_t$). This exercise will solidify your understanding of the deep theoretical link between coalescent theory and epidemic dynamics.", "problem": "You are given a dated binary phylogenetic tree representing an infectious disease outbreak, with all tips sampled at the present and internal nodes dated by their ages measured backward from the present. The goal is to compute a piecewise-constant Bayesian Skyline Plot (BSP) estimate of the effective coalescent population size as a function of time, denoted by $N_e(t)$, and to compare it to a matched birth-only (Yule) effective reproductive number trajectory $R_t$ computed under the same grouping of intervals. All times are specified in years, and $R_t$ is dimensionless. You must implement the following steps and produce the requested comparison metric for each test case.\n\nDefinitions and fundamental base:\n- Kingmanâ€™s coalescent posits that, with $k$ extant lineages at time $t$, the instantaneous coalescent hazard is $\\lambda(t) = \\binom{k}{2} / N_e(t)$. Over an interval of duration $\\Delta t$ in which $k$ is constant, the waiting time to the next coalescent event is exponentially distributed with rate $\\binom{k}{2} / N_e(t)$.\n- The Bayesian Skyline Plot (BSP) models $N_e(t)$ as piecewise-constant over contiguous groups of coalescent intervals. Within each group $i$, define the coalescent rate parameter $r_i = 1 / N_{e,i}$, and place a Gamma prior $r_i \\sim \\text{Gamma}(a, b)$ with shape $a$ and rate $b$, both strictly positive.\n- The Yule (pure birth) process assumes that each existing lineage gives birth at rate $\\beta(t)$, producing an exponentially distributed waiting time to the next branching event with rate $k \\beta(t)$ when there are $k$ lineages. Within each group $i$, assume piecewise-constant $\\beta_i$ with prior $\\beta_i \\sim \\text{Gamma}(a, b)$ (same hyperparameters as for the coalescent rate), and adopt a fixed generation time $T_g$ (in years). Under a fixed generation time model, an effective reproductive number can be defined by $R_{t,i} = \\exp(\\beta_i T_g)$.\n\nRequired computations per test case:\n1. Tree representation and intervals:\n   - You are given the number of tips $n$ and an ordered list of internal node ages $\\{t_j\\}_{j=1}^{n-1}$ with $0 = t_0 < t_1 < t_2 < \\dots < t_{n-1}$ measured in years backward from the present. The interval durations are $\\Delta t_j = t_j - t_{j-1}$.\n   - At the start of interval $j$ (counting from $j = 1$), the number of lineages is $k_j = n - (j - 1)$.\n2. Grouping (matched sampling):\n   - You are given an integer group size $g$ specifying that the skyline is formed by grouping $g$ consecutive coalescent intervals into one piecewise-constant segment. The final group may contain fewer than $g$ intervals if $(n-1)$ is not a multiple of $g$. Use the same grouping to estimate both $N_{e,i}$ (BSP) and $\\beta_i$ (Yule), thereby ensuring matched sampling across the two trajectories.\n3. BSP posterior and estimator:\n   - For group $i$, let $n_i$ be its number of intervals, and define the coalescent exposure\n     $$S^{\\text{coal}}_i = \\sum_{j \\in \\text{group } i} \\binom{k_j}{2} \\, \\Delta t_j.$$\n   - The likelihood contribution for $r_i$ over the group is proportional to $r_i^{n_i} \\exp(-r_i S^{\\text{coal}}_i)$, and with prior $r_i \\sim \\text{Gamma}(a,b)$ (shape-rate parameterization), the posterior is $\\text{Gamma}(a+n_i, b+S^{\\text{coal}}_i)$.\n   - The BSP estimator for the effective population size in group $i$ is the posterior mean of $N_{e,i} = 1/r_i$, which under $r_i \\sim \\text{Gamma}(\\alpha,\\beta)$ equals\n     $$\\mathbb{E}[N_{e,i}] = \\mathbb{E}\\left[\\frac{1}{r_i}\\right] = \\frac{\\beta}{\\alpha - 1}, \\quad \\text{valid for } \\alpha > 1.$$\n     Applying this to the posterior parameters yields\n     $$\\widehat{N}_{e,i} = \\frac{b + S^{\\text{coal}}_i}{(a + n_i) - 1}.$$\n4. Yule posterior and $R_t$ estimator:\n   - For group $i$, define the Yule exposure\n     $$S^{\\text{yule}}_i = \\sum_{j \\in \\text{group } i} k_j \\, \\Delta t_j.$$\n   - The likelihood contribution for $\\beta_i$ is proportional to $\\beta_i^{n_i} \\exp(-\\beta_i S^{\\text{yule}}_i)$, and with prior $\\beta_i \\sim \\text{Gamma}(a,b)$, the posterior is $\\text{Gamma}(a+n_i, b+S^{\\text{yule}}_i)$.\n   - The posterior mean is $\\mathbb{E}[\\beta_i] = \\dfrac{a + n_i}{b + S^{\\text{yule}}_i}$, and with fixed generation time $T_g$ (in years), define\n     $$\\widehat{R}_{t,i} = \\exp\\!\\big(\\mathbb{E}[\\beta_i] \\, T_g\\big).$$\n5. Comparison metric:\n   - To compare the BSP $\\{\\widehat{N}_{e,i}\\}$ and the Yule-based $\\{\\widehat{R}_{t,i}\\}$ trajectories under matched sampling, compute the Spearman rank correlation between $\\{\\widehat{N}_{e,i}\\}$ and $\\{1/\\widehat{R}_{t,i}\\}$. This assesses whether larger effective population sizes correspond to smaller reproductive numbers across segments, as expected under the inverse relationship between coalescent rate and branching rate.\n   - If either sequence is constant (zero variance in ranks), define the correlation as $0.0$ for that test case.\n\nImplementation details:\n- You must implement all computations exactly as specified above. Do not use any external input.\n- Your program must produce a single line of output containing the Spearman rank correlations (floats) for all test cases as a comma-separated list enclosed in square brackets.\n\nTest suite:\nProvide the following test cases, each defined by $(n, \\{t_j\\}, g, a, b, T_g)$:\n- Case $1$: $n = 6$, $\\{t_j\\} = [0.15, 0.29, 0.45, 0.80, 1.30]$ (years), $g = 2$, $a = 2.0$, $b = 0.001$, $T_g = 0.10$ (years).\n- Case $2$: $n = 10$, $\\{t_j\\} = [0.02, 0.035, 0.050, 0.062, 0.072, 0.078, 0.082, 0.085, 0.087]$ (years), $g = 3$, $a = 2.0$, $b = 0.001$, $T_g = 0.05$ (years).\n- Case $3$: $n = 4$, $\\{t_j\\} = [0.30, 0.70, 1.50]$ (years), $g = 1$, $a = 2.0$, $b = 0.001$, $T_g = 0.20$ (years).\n\nAnswer specification:\n- Your program should produce a single line of output containing the Spearman rank correlations for the three cases as a comma-separated list enclosed in square brackets (e.g., $[x_1,x_2,x_3]$), where each $x_i$ is a float.", "solution": "The problem requires the computation and comparison of two different measures of historical population dynamics derived from a dated phylogenetic tree: the effective population size, $N_e(t)$, estimated using a Bayesian Skyline Plot (BSP), and the effective reproductive number, $R_t$, estimated using a pure-birth (Yule) process model. The comparison is performed by calculating the Spearman rank correlation between the estimated trajectories of $\\widehat{N}_{e,i}$ and $1/\\widehat{R}_{t,i}$ over a set of pre-defined time intervals.\n\nThe solution proceeds systematically through the following steps for each test case.\n\n**1. Derivation of Coalescent Intervals and Lineage Counts**\nGiven the number of tips $n$ and an ordered list of $n-1$ internal node ages $\\{t_j\\}_{j=1}^{n-1}$, we first establish the fundamental data for the analysis. The times are measured backward from the present (time $0$), so we define $t_0 = 0$. The phylogenetic history is partitioned into $n-1$ coalescent intervals. The $j$-th interval, for $j \\in \\{1, 2, \\dots, n-1\\}$, spans the time from $t_{j-1}$ to $t_j$. Its duration is $\\Delta t_j = t_j - t_{j-1}$.\n\nThe number of extant lineages, $k$, decreases by one at each coalescent event (internal node). Since all tips are at the present, we start with $n$ lineages at time $0$. The number of lineages remains constant throughout each interval. For the $j$-th interval, which begins just after the $(j-1)$-th coalescent event, the number of lineages is $k_j = n - (j-1)$. This count ranges from $k_1 = n$ down to $k_{n-1} = 2$.\n\n**2. Grouping of Coalescent Intervals**\nThe piecewise-constant nature of the estimates is determined by grouping consecutive coalescent intervals. A given integer group size, $g$, specifies that each estimation segment (indexed by $i$) is composed of $g$ adjacent intervals. The total of $n-1$ intervals are thus partitioned into $\\lceil(n-1)/g\\rceil$ groups. The final group may contain fewer than $g$ intervals if $n-1$ is not an even multiple of $g$. Let $n_i$ be the number of intervals in group $i$. This matched grouping ensures that both the BSP and Yule estimates are computed over the same time segments, enabling a direct comparison.\n\n**3. Bayesian Skyline Plot (BSP) Estimation of $\\widehat{N}_{e,i}$**\nThe BSP model assumes a piecewise-constant effective population size, $N_{e,i}$, for each group $i$. This is equivalent to assuming a piecewise-constant coalescent rate, $r_i = 1/N_{e,i}$. The likelihood of observing $n_i$ coalescent events within the intervals of group $i$ is derived from the exponential waiting time distribution of the Kingman coalescent. For a given rate $r_i$, the likelihood is proportional to $r_i^{n_i} \\exp(-r_i S^{\\text{coal}}_i)$, where $S^{\\text{coal}}_i$ is the total coalescent exposure for the group:\n$$S^{\\text{coal}}_i = \\sum_{j \\in \\text{group } i} \\binom{k_j}{2} \\Delta t_j$$\nWe are given a Gamma prior for the rate parameter, $r_i \\sim \\text{Gamma}(a, b)$, with shape $a$ and rate $b$. Due to the conjugacy of the Gamma distribution with the Poisson process likelihood (which this resembles), the posterior distribution for $r_i$ is also a Gamma distribution:\n$$r_i | \\text{data} \\sim \\text{Gamma}(a + n_i, b + S^{\\text{coal}}_i)$$\nThe problem requires an estimator for the effective population size $N_{e,i}$, which is the reciprocal of the rate $r_i$. We use the posterior mean of $N_{e,i}$. If a random variable $X \\sim \\text{Gamma}(\\alpha, \\beta)$, then the expectation of its reciprocal is $\\mathbb{E}[1/X] = \\beta/(\\alpha-1)$, provided $\\alpha > 1$. Applying this to our posterior distribution, we obtain the estimator for the effective population size in group $i$:\n$$\\widehat{N}_{e,i} = \\frac{b + S^{\\text{coal}}_i}{(a + n_i) - 1}$$\nThe condition $(a+n_i) > 1$ is satisfied for all test cases, as $a=2.0$ and $n_i \\ge 1$.\n\n**4. Yule Process Estimation of $\\widehat{R}_{t,i}$**\nIn parallel, we model the branching process using a pure-birth (Yule) model with a piecewise-constant birth rate, $\\beta_i$, for each group $i$. The likelihood of observing $n_i$ branching events within group $i$ is proportional to $\\beta_i^{n_i} \\exp(-\\beta_i S^{\\text{yule}}_i)$, where $S^{\\text{yule}}_i$ is the total Yule exposure:\n$$S^{\\text{yule}}_i = \\sum_{j \\in \\text{group } i} k_j \\Delta t_j$$\nUsing the same $\\text{Gamma}(a, b)$ prior for $\\beta_i$, the posterior distribution is:\n$$\\beta_i | \\text{data} \\sim \\text{Gamma}(a + n_i, b + S^{\\text{yule}}_i)$$\nThe problem defines the estimator for the effective reproductive number, $\\widehat{R}_{t,i}$, based on the posterior mean of the birth rate, $\\mathbb{E}[\\beta_i]$. The mean of a $\\text{Gamma}(\\alpha, \\beta)$ distribution is $\\alpha/\\beta$. Thus, the posterior mean birth rate is:\n$$\\mathbb{E}[\\beta_i] = \\frac{a + n_i}{b + S^{\\text{yule}}_i}$$\nUsing the provided fixed generation time $T_g$, the estimator for the effective reproductive number is:\n$$\\widehat{R}_{t,i} = \\exp\\left(\\mathbb{E}[\\beta_i] \\cdot T_g\\right)$$\n\n**5. Comparison via Spearman Rank Correlation**\nAfter computing the sequences $\\{\\widehat{N}_{e,i}\\}$ and $\\{\\widehat{R}_{t,i}\\}$ for all groups $i$ in a given tree, we compare them. Population genetics theory suggests an inverse relationship between effective population size and reproductive number ($N_e$ is large when $R_t$ is small, and vice-versa). To test this, we compute the Spearman rank correlation coefficient, $\\rho$, between the sequence $\\{\\widehat{N}_{e,i}\\}$ and the sequence of reciprocal reproductive numbers, $\\{1/\\widehat{R}_{t,i}\\}$.\n\nThe Spearman correlation measures the strength and direction of the monotonic relationship between the ranks of the two sequences. A value of $\\rho$ near $+1$ indicates a strong positive monotonic relationship, supporting the theoretical expectation. A value near $-1$ indicates a strong negative monotonic relationship, and a value near $0$ indicates little to no monotonic relationship. As per the problem specification, if either sequence of estimates is constant (i.e., has zero variance in its ranks), the correlation is defined to be $0.0$.\n\nThis entire procedure is applied to each test case to generate the final vector of correlation coefficients.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import spearmanr\nfrom math import ceil, exp\n\ndef calculate_correlation(n, t_j_list, g, a, b, T_g):\n    \"\"\"\n    Computes the Spearman correlation between BSP and Yule trajectories.\n\n    Args:\n        n (int): Number of tips in the tree.\n        t_j_list (list): Ordered list of internal node ages.\n        g (int): Group size for intervals.\n        a (float): Shape parameter for Gamma priors.\n        b (float): Rate parameter for Gamma priors.\n        T_g (float): Generation time in years.\n\n    Returns:\n        float: The Spearman rank correlation coefficient.\n    \"\"\"\n    # Step 1: Preprocessing to get interval durations and lineage counts\n    num_intervals = n - 1\n    if num_intervals == 0:\n        return 0.0\n\n    t_nodes = [0.0] + t_j_list\n    delta_t = [t_nodes[i] - t_nodes[i - 1] for i in range(1, len(t_nodes))]\n    \n    # k_j for j = 1, ..., n-1\n    k_lineages = [n - (j - 1) for j in range(1, num_intervals + 1)]\n\n    # Step 2: Grouping\n    num_groups = ceil(num_intervals / g)\n    if num_groups == 0:\n        return 0.0\n\n    N_e_hats = []\n    inv_R_t_hats = []\n\n    # Step 3  4: Calculate estimators for each group\n    for i in range(num_groups):\n        start_interval_idx = i * g\n        end_interval_idx = min((i + 1) * g, num_intervals)\n        \n        S_coal_i = 0.0\n        S_yule_i = 0.0\n        n_i = end_interval_idx - start_interval_idx\n\n        for j_idx in range(start_interval_idx, end_interval_idx):\n            kj = k_lineages[j_idx]\n            dtj = delta_t[j_idx]\n            \n            # Coalescent exposure contribution\n            binom_k = kj * (kj - 1) / 2.0\n            S_coal_i += binom_k * dtj\n            \n            # Yule exposure contribution\n            S_yule_i += kj * dtj\n\n        # Posterior parameters\n        alpha_post = a + n_i\n        beta_coal_post = b + S_coal_i\n        beta_yule_post = b + S_yule_i\n\n        # BSP Estimator calculation\n        # The condition (a + n_i) > 1 is met by problem constraints\n        N_e_hat_i = beta_coal_post / (alpha_post - 1)\n        N_e_hats.append(N_e_hat_i)\n\n        # Yule Estimator calculation\n        E_beta_i = alpha_post / beta_yule_post\n        R_t_hat_i = exp(E_beta_i * T_g)\n        inv_R_t_hats.append(1.0 / R_t_hat_i)\n\n    # Step 5: Spearman Correlation\n    # Handle constant sequences as per problem statement\n    is_N_const = len(set(N_e_hats)) = 1\n    is_R_const = len(set(inv_R_t_hats)) = 1\n    if is_N_const or is_R_const:\n        return 0.0\n\n    # scipy.stats.spearmanr is used for the standard statistical calculation\n    correlation, _ = spearmanr(N_e_hats, inv_R_t_hats)\n    \n    # spearmanr can return nan if variance is zero, which we already checked.\n    # This is a fallback to ensure compliance.\n    if np.isnan(correlation):\n       return 0.0\n       \n    return correlation\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: (n, {t_j}, g, a, b, T_g)\n        (6, [0.15, 0.29, 0.45, 0.80, 1.30], 2, 2.0, 0.001, 0.10),\n        # Case 2\n        (10, [0.02, 0.035, 0.050, 0.062, 0.072, 0.078, 0.082, 0.085, 0.087], 3, 2.0, 0.001, 0.05),\n        # Case 3\n        (4, [0.30, 0.70, 1.50], 1, 2.0, 0.001, 0.20),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, t_j_list, g, a, b, T_g = case\n        result = calculate_correlation(n, t_j_list, g, a, b, T_g)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4347420"}]}