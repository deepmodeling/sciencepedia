{"hands_on_practices": [{"introduction": "Before we can deconvolve bulk tissue data, we need a reliable reference: the signature matrix, $S$. This practice walks you through the essential bioinformatic pipeline for constructing this matrix from raw single-cell RNA sequencing (scRNA-seq) data [@problem_id:4321251]. You will implement key preprocessing steps, including library size normalization and variance stabilization, to understand how a high-quality signature matrix, the foundation of accurate deconvolution, is built from scratch.", "problem": "You are provided with single-cell RNA sequencing (scRNA-seq) count data and integer cell-type labels for $K$ types. Your task is to construct a reference signature matrix $S \\in \\mathbb{R}^{G \\times K}$ whose entries $S_{g,t}$ represent the per-cell-type average expression of gene $g$ on a linear scale after appropriate preprocessing. The construction must be based on scientifically justified steps grounded in the mixture model for bulk-tissue expression, where bulk expression for gene $g$ is modeled as a linear combination of cell-type-specific expression: $$Y_g \\approx \\sum_{t=1}^{K} S_{g,t} \\, p_t,$$ where $Y_g$ is bulk expression in linear units and $p_t$ are nonnegative mixture weights that sum to one. To ensure comparability across cells with different capture efficiencies and sequencing depths, you must normalize scRNA-seq counts by library size and stabilize variance, and then return to a linear scale consistent with the mixture model.\n\nStart from the following core facts and definitions:\n- Single-cell RNA sequencing (scRNA-seq) count data are nonnegative integers subject to variable library sizes per cell due to technical factors (capture efficiency, sequencing depth).\n- The library size for cell $i$ is defined as $$L_i = \\sum_{g=1}^{G} C_{g,i},$$ where $C_{g,i}$ is the raw count for gene $g$ in cell $i$.\n- Counts can be scaled to counts per million (CPM), a linear unit, by $$X_{g,i} = \\begin{cases} \\dfrac{C_{g,i}}{L_i} \\times M, & L_i > 0, \\\\ 0, & L_i = 0, \\end{cases}$$ with $M = 10^6$ (one million) representing the target library size.\n- Logarithmic transformation is commonly used to stabilize variance in count-derived measures; however, the mixture model requires a linear scale for $S$.\n\nYou must implement the following steps:\n1. Compute library sizes $L_i$ for all cells.\n2. Normalize counts to CPM using the rule above with $M = 10^6$.\n3. Apply variance stabilization by computing $$Z_{g,i} = \\log\\!\\big(1 + X_{g,i}\\big),$$ using the natural logarithm.\n4. For each cell type $t \\in \\{1, \\dots, K\\}$, compute the mean of $Z_{g,i}$ over cells of type $t$: $$\\mu_{g,t} = \\frac{1}{n_t} \\sum_{i \\in I_t} Z_{g,i},$$ where $I_t$ is the set of indices of cells with label $t$ and $n_t = |I_t|$.\n5. Back-transform to the linear CPM scale: $$S_{g,t} = \\exp(\\mu_{g,t}) - 1.$$\n\nHandle edge cases as follows:\n- If $L_i = 0$ for a cell, define $X_{g,i} = 0$ for all $g$ to avoid division by zero and because no counts imply no evidence of expression for that cell.\n- If a cell type $t$ has no cells (i.e., $n_t = 0$), define $S_{g,t} = 0$ for all $g$.\n\nUnits: All outputs for $S$ must be expressed in counts per million (CPM), as real-valued floats. The logarithm is unitless. Angles are not involved. Percentages, if any arise conceptually, must be represented as decimals, but your program should not compute mixture weights.\n\nYour program must implement the above pipeline and compute $S$ for each of the test cases below. For each case, return a row-major flattened list of $G \\times K$ floats rounded to six decimal places.\n\nTest Suite:\n- Case A (general case, $G = 4$, $N = 6$, $K = 3$):\n  $$C = \\begin{bmatrix}\n  100 & 200 & 0 & 50 & 400 & 300 \\\\\n  0 & 100 & 50 & 0 & 200 & 100 \\\\\n  500 & 0 & 0 & 300 & 100 & 0 \\\\\n  0 & 0 & 100 & 200 & 0 & 0\n  \\end{bmatrix}, \\quad \\text{labels} = [1, 1, 2, 2, 3, 3], \\quad M = 10^6.$$\n- Case B (edge: zero-library-size cell, gene entirely zero, $G = 3$, $N = 4$, $K = 2$):\n  $$C = \\begin{bmatrix}\n  0 & 0 & 100 & 0 \\\\\n  0 & 0 & 0 & 0 \\\\\n  0 & 50 & 0 & 50\n  \\end{bmatrix}, \\quad \\text{labels} = [1, 1, 2, 2], \\quad M = 10^6.$$\n- Case C (edge: single-cell type, skewed counts, $G = 2$, $N = 3$, $K = 2$):\n  $$C = \\begin{bmatrix}\n  1000 & 2000 & 3000 \\\\\n  5000 & 0 & 0\n  \\end{bmatrix}, \\quad \\text{labels} = [1, 2, 2], \\quad M = 10^6.$$\n\nFinal Output Format:\nYour program should produce a single line of output containing a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a bracketed, comma-separated list of the flattened $S$ values in row-major order, rounded to six decimal places. For example:\n$$[ [s^{(A)}_1,\\dots,s^{(A)}_{G\\cdot K}], [s^{(B)}_1,\\dots,s^{(B)}_{G\\cdot K}], [s^{(C)}_1,\\dots,s^{(C)}_{G\\cdot K}] ].$$", "solution": "The user has provided a well-defined computational biology problem to construct a cell-type signature matrix $S$ from single-cell RNA sequencing (scRNA-seq) count data. The problem is scientifically sound, mathematically precise, and algorithmically specified. It is validated as a legitimate problem.\n\nThe objective is to compute a signature matrix $S \\in \\mathbb{R}^{G \\times K}$, where $S_{g,t}$ represents the average expression of gene $g$ for cell type $t$. This matrix is crucial for cellular deconvolution, which aims to estimate cell-type proportions from bulk-tissue expression data using the linear mixture model $Y_g \\approx \\sum_{t=1}^{K} S_{g,t} \\, p_t$. The provided methodology is a standard and robust pipeline in bioinformatics. The solution proceeds by implementing the specified steps, with each step grounded in established scientific principles.\n\n**Step 1: Normalization by Library Size**\n\nThe raw data consists of a count matrix $C \\in \\mathbb{Z}_{\\ge 0}^{G \\times N}$, where $C_{g,i}$ is the number of RNA transcripts for gene $g$ detected in cell $i$. A primary source of technical variation in scRNA-seq is the difference in sequencing depth and capture efficiency across cells. The library size for cell $i$, defined as the total count of transcripts $L_i = \\sum_{g=1}^{G} C_{g,i}$, serves as a proxy for these technical factors. To make expression levels comparable across cells, the raw counts must be normalized.\n\nThe problem specifies normalization to counts per million (CPM), a widely used method. The CPM value for gene $g$ in cell $i$, denoted $X_{g,i}$, is calculated as:\n$$\nX_{g,i} = \\begin{cases} \\dfrac{C_{g,i}}{L_i} \\times M, & L_i > 0, \\\\ 0, & L_i = 0. \\end{cases}\n$$\nHere, $M = 10^6$ is a scaling factor that sets a common library size for all cells (one million). This transformation puts the expression data on a linear, comparable scale while correctly handling the edge case of cells with zero total counts ($L_i = 0$), for which expression is logically zero.\n\n**Step 2: Variance Stabilization**\n\nGene expression count data, even after normalization, often exhibit heteroscedasticity, where the variance of expression increases with the mean. This property can give disproportionate weight to highly expressed genes in downstream analyses. A logarithmic transformation is a standard statistical technique to stabilize the variance, making it more uniform across the range of expression values.\n\nThe specified transformation is:\n$$\nZ_{g,i} = \\log\\!\\big(1 + X_{g,i}\\big)\n$$\nwhere $\\log$ denotes the natural logarithm. The addition of a pseudocount of $1$ serves two purposes: it prevents the logarithm of zero (since $X_{g,i} \\ge 0$), and it dampens the effect of the logarithm on small count values, preventing the undue inflation of ratios between lowly expressed genes.\n\n**Step 3: Aggregation by Cell Type**\n\nTo create a canonical expression signature for each cell type, we must aggregate the expression profiles of all cells belonging to that type. The problem specifies that the cell-type labels are integers from $1$ to $K$. For each gene $g$ and cell type $t$, the signature is derived from the average of the log-transformed values.\n\nLet $I_t$ be the set of cell indices corresponding to type $t$, and $n_t = |I_t|$ be the number of such cells. The mean log-expression, $\\mu_{g,t}$, is computed as:\n$$\n\\mu_{g,t} = \\frac{1}{n_t} \\sum_{i \\in I_t} Z_{g,i}\n$$\nAveraging in the logarithmic space is more robust to outliers than averaging on the linear CPM scale. Extreme expression values in a single cell will have a less dramatic impact on the mean. If a cell type $t$ is not represented in the dataset ($n_t = 0$), its signature profile $S_{g,t}$ is defined as $0$ for all genes $g$, which is a logical default.\n\n**Step 4: Back-transformation to a Linear Scale**\n\nThe final signature matrix $S$ is intended for use in a linear mixture model.\nTherefore, the aggregated expression values must be on a linear scale, not a logarithmic one. The mean log-expression values $\\mu_{g,t}$ must be transformed back to the original CPM scale.\n\nThe inverse of the transformation $z = \\log(1+x)$ is $x = \\exp(z) - 1$. Applying this to $\\mu_{g,t}$ yields the final signature matrix entries:\n$$\nS_{g,t} = \\exp(\\mu_{g,t}) - 1\n$$\nThis value, $S_{g,t}$, can be interpreted as a robust measure of the central tendency of expression for gene $g$ in cell type $t$. It is equivalent to the geometric mean of the $(1+X_{g,i})$ values for all cells of type $t$, minus $1$. This provides a representative expression value on the linear CPM scale, suitable for deconvolution algorithms.\n\nThe complete pipeline constitutes a principled and scientifically justified method for constructing a high-quality signature matrix from scRNA-seq data.", "answer": "```python\nimport numpy as np\n\ndef build_signature_matrix(C, labels, M=1e6):\n    \"\"\"\n    Constructs a reference signature matrix S from scRNA-seq count data.\n\n    Args:\n        C (np.ndarray): A GxN matrix of raw counts (G genes, N cells).\n        labels (np.ndarray): A 1D array of N integer cell-type labels (1-based).\n        M (float): The scaling factor for CPM normalization (e.g., 10^6).\n\n    Returns:\n        np.ndarray: The GxK signature matrix S.\n    \"\"\"\n    # Defensive copy to avoid modifying original inputs\n    C = C.astype(np.float64)\n    labels = np.array(labels, dtype=int)\n\n    G, N = C.shape\n    if N == 0:\n        # Handle case with no cells\n        K = np.max(labels) if labels.size > 0 else 0\n        return np.zeros((G, K))\n    \n    # Step 1: Compute library sizes\n    L = C.sum(axis=0)\n\n    # Step 2: Normalize to counts per million (CPM)\n    X = np.zeros_like(C, dtype=np.float64)\n    valid_cells_mask = L > 0\n    # Use np.divide with a 'where' clause for safe division\n    X[:, valid_cells_mask] = np.divide(C[:, valid_cells_mask], L[valid_cells_mask], where=L[valid_cells_mask] > 0) * M\n    \n    # Step 3: Apply variance stabilization\n    Z = np.log(1.0 + X)\n\n    # Determine K, the number of cell types\n    # The problem implies labels are 1...K, so max(labels) defines K.\n    K = np.max(labels) if labels.size > 0 else 0\n    S = np.zeros((G, K), dtype=np.float64)\n    \n    # Iterate through cell types 1 to K\n    for t in range(1, K + 1):\n        # Find indices for cells of the current type t\n        cell_indices = np.where(labels == t)[0]\n        n_t = len(cell_indices)\n\n        # Step 4 & 5: Aggregate and Back-transform\n        if n_t > 0:\n            # Select columns from Z for the current cell type\n            Z_t = Z[:, cell_indices]\n            \n            # Compute the mean of log-transformed values\n            mu_gt = np.mean(Z_t, axis=1)\n            \n            # Back-transform to the linear scale and assign to S\n            # S columns are 0-indexed, so we use t-1\n            S[:, t - 1] = np.exp(mu_gt) - 1.0\n        else:\n            # Per the problem, if a cell type has no cells, its signature is all zeros.\n            # S is initialized to zeros, so no action is needed.\n            pass\n            \n    return S\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        (\n            np.array([\n                [100, 200, 0, 50, 400, 300],\n                [0, 100, 50, 0, 200, 100],\n                [500, 0, 0, 300, 100, 0],\n                [0, 0, 100, 200, 0, 0]\n            ]),\n            np.array([1, 1, 2, 2, 3, 3])\n        ),\n        (\n            np.array([\n                [0, 0, 100, 0],\n                [0, 0, 0, 0],\n                [0, 50, 0, 50]\n            ]),\n            np.array([1, 1, 2, 2])\n        ),\n        (\n            np.array([\n                [1000, 2000, 3000],\n                [5000, 0, 0]\n            ]),\n            np.array([1, 2, 2])\n        )\n    ]\n\n    all_results_str = []\n    for C, labels in test_cases:\n        S = build_signature_matrix(C, labels)\n        \n        # Flatten the matrix in row-major ('C') order\n        flat_S = S.flatten(order='C')\n        \n        # Format each number to six decimal places\n        formatted_S = [f\"{val:.6f}\" for val in flat_S]\n        \n        # Create the string for the current case's result list\n        case_result_str = f\"[{','.join(formatted_S)}]\"\n        all_results_str.append(case_result_str)\n\n    # Final print statement in the exact required format\n    final_output = f\"[{','.join(all_results_str)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "4321251"}, {"introduction": "With a signature matrix $S$ and a bulk expression vector $y$ available, the core deconvolution task is to solve for the unknown cell-type proportions $p$. This exercise provides a concrete, hands-on calculation using the non-negative least squares (NNLS) framework, which is fundamental to many deconvolution algorithms [@problem_id:4321276]. By working through this small-scale example, you will solidify your understanding of the constrained optimization problem at the heart of the linear mixture model.", "problem": "In the linear mixture model for bulk-tissue gene expression used in cellular deconvolution for precision medicine and genomic diagnostics, the observed bulk expression vector $\\mathbf{y} \\in \\mathbb{R}^{5}$ is modeled as a convex combination of cell-type-specific expression signatures, $\\mathbf{y} \\approx \\mathbf{S}\\mathbf{p}$, where $\\mathbf{S} \\in \\mathbb{R}^{5 \\times 3}$ is the signature matrix (columns are cell-type profiles across $5$ genes), and $\\mathbf{p} \\in \\mathbb{R}^{3}$ is the nonnegative cell-type proportion vector satisfying $\\mathbf{1}^{\\top}\\mathbf{p} = 1$. Consider a scenario with $5$ genes and $3$ cell types, with the signature matrix and bulk vector given by\n$$\n\\mathbf{S} = \n\\begin{bmatrix}\n8 & 2 & 0 \\\\\n1 & 4 & 3 \\\\\n0 & 5 & 2 \\\\\n3 & 1 & 0 \\\\\n2 & 0 & 6\n\\end{bmatrix},\n\\quad\n\\mathbf{y} =\n\\begin{bmatrix}\n3.2 \\\\\n2.8 \\\\\n2.6 \\\\\n1.3 \\\\\n2.4\n\\end{bmatrix},\n$$\nwhere all entries are in units of transcripts per million (TPM). Using the nonnegative least squares formulation with the equality constraint $\\mathbf{1}^{\\top}\\mathbf{p} = 1$, compute the optimal cell-type proportion vector $\\hat{\\mathbf{p}}$ and then compute the residual Euclidean norm $\\|\\mathbf{S}\\hat{\\mathbf{p}} - \\mathbf{y}\\|_{2}$ in TPM. Express the final residual norm in TPM and round your answer to four significant figures if rounding is required. The answer must be a single real-valued number.", "solution": "The user has provided a problem from the field of genomic diagnostics, specifically concerning the cellular deconvolution of bulk-tissue expression data. The task is to compute the optimal cell-type proportion vector $\\hat{\\mathbf{p}}$ and the corresponding residual norm $\\|\\mathbf{S}\\hat{\\mathbf{p}} - \\mathbf{y}\\|_{2}$.\n\nFirst, a validation of the problem statement is required.\n\n### Step 1: Extract Givens\n-   The model for bulk expression is $\\mathbf{y} \\approx \\mathbf{S}\\mathbf{p}$.\n-   The bulk expression vector is $\\mathbf{y} = \\begin{bmatrix} 3.2 \\\\ 2.8 \\\\ 2.6 \\\\ 1.3 \\\\ 2.4 \\end{bmatrix}$.\n-   The signature matrix is $\\mathbf{S} = \\begin{bmatrix} 8 & 2 & 0 \\\\ 1 & 4 & 3 \\\\ 0 & 5 & 2 \\\\ 3 & 1 & 0 \\\\ 2 & 0 & 6 \\end{bmatrix}$.\n-   The cell-type proportion vector $\\mathbf{p} \\in \\mathbb{R}^{3}$ must satisfy the constraints:\n    1.  Nonnegativity: $p_i \\ge 0$ for $i=1, 2, 3$. This can be written as $\\mathbf{p} \\ge \\mathbf{0}$.\n    2.  Sum-to-one: $\\sum_{i=1}^{3} p_i = 1$. This can be written as $\\mathbf{1}^{\\top}\\mathbf{p} = 1$.\n-   The optimization problem is a constrained nonnegative least squares problem: find $\\hat{\\mathbf{p}}$ that minimizes $\\|\\mathbf{S}\\mathbf{p} - \\mathbf{y}\\|_{2}$. This is equivalent to minimizing $\\|\\mathbf{S}\\mathbf{p} - \\mathbf{y}\\|_{2}^2$.\n-   The final quantity to compute is the residual Euclidean norm, $\\|\\mathbf{S}\\hat{\\mathbf{p}} - \\mathbf{y}\\|_{2}$.\n-   The final answer must be rounded to four significant figures if rounding is required.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded. The linear mixture model $\\mathbf{y} = \\mathbf{S}\\mathbf{p}$ is a standard and widely used formulation for computational deconvolution of bulk transcriptomic data. The optimization framework, nonnegative least squares with a sum-to-one constraint, is a common approach to solve for the cell-type proportions $\\mathbf{p}$. The data types (real-valued expression levels) and dimensions are realistic.\n\nThe problem is mathematically well-posed. The objective function $f(\\mathbf{p}) = \\|\\mathbf{S}\\mathbf{p} - \\mathbf{y}\\|_{2}^2$ is convex. The constraint set, defined by $\\mathbf{p} \\ge \\mathbf{0}$ and $\\mathbf{1}^{\\top}\\mathbf{p} = 1$, is a simplex, which is a convex and compact set. The minimization of a convex function over a convex set has a unique global minimum. Therefore, a unique solution $\\hat{\\mathbf{p}}$ exists.\n\nThe problem statement is complete, objective, and contains no contradictions or ambiguities.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. A solution will be derived.\n\n### Solution Derivation\nThe optimization problem is to find $\\hat{\\mathbf{p}}$ that solves:\n$$ \\underset{\\mathbf{p}}{\\text{minimize}} \\quad \\frac{1}{2}\\|\\mathbf{S}\\mathbf{p} - \\mathbf{y}\\|_{2}^2 $$\n$$ \\text{subject to} \\quad \\mathbf{p} \\ge \\mathbf{0} \\quad \\text{and} \\quad \\mathbf{1}^{\\top}\\mathbf{p} = 1 $$\nLet $\\mathbf{p} = [p_1, p_2, p_3]^{\\top}$. The equality constraint $\\mathbf{1}^{\\top}\\mathbf{p} = 1$ can be used to eliminate one of the variables. Let $p_3 = 1 - p_1 - p_2$. The problem can be reformulated in terms of $p_1$ and $p_2$.\nThe constraints become $p_1 \\ge 0$, $p_2 \\ge 0$, and $1 - p_1 - p_2 \\ge 0$, which simplifies to $p_1 + p_2 \\le 1$.\n\nLet the columns of $\\mathbf{S}$ be $\\mathbf{c}_1, \\mathbf{c}_2, \\mathbf{c}_3$. The term $\\mathbf{S}\\mathbf{p}$ can be rewritten as:\n$$ \\mathbf{S}\\mathbf{p} = p_1\\mathbf{c}_1 + p_2\\mathbf{c}_2 + p_3\\mathbf{c}_3 = p_1\\mathbf{c}_1 + p_2\\mathbf{c}_2 + (1-p_1-p_2)\\mathbf{c}_3 = p_1(\\mathbf{c}_1 - \\mathbf{c}_3) + p_2(\\mathbf{c}_2 - \\mathbf{c}_3) + \\mathbf{c}_3 $$\nLet $\\mathbf{p}' = \\begin{bmatrix} p_1 \\\\ p_2 \\end{bmatrix}$, $\\mathbf{S}' = \\begin{bmatrix} \\mathbf{c}_1 - \\mathbf{c}_3 & \\mathbf{c}_2 - \\mathbf{c}_3 \\end{bmatrix}$, and $\\mathbf{y}' = \\mathbf{y} - \\mathbf{c}_3$. The objective function becomes minimizing $\\|\\mathbf{S}'\\mathbf{p}' - \\mathbf{y}'\\|_{2}^2$ subject to $p_1 \\ge 0, p_2 \\ge 0, p_1+p_2 \\le 1$.\n\nFirst, we compute $\\mathbf{S}'$ and $\\mathbf{y}'$:\n$$\n\\mathbf{c}_1 - \\mathbf{c}_3 = \\begin{bmatrix} 8-0 \\\\ 1-3 \\\\ 0-2 \\\\ 3-0 \\\\ 2-6 \\end{bmatrix} = \\begin{bmatrix} 8 \\\\ -2 \\\\ -2 \\\\ 3 \\\\ -4 \\end{bmatrix}, \\quad\n\\mathbf{c}_2 - \\mathbf{c}_3 = \\begin{bmatrix} 2-0 \\\\ 4-3 \\\\ 5-2 \\\\ 1-0 \\\\ 0-6 \\end{bmatrix} = \\begin{bmatrix} 2 \\\\ 1 \\\\ 3 \\\\ 1 \\\\ -6 \\end{bmatrix}\n$$\nSo, $\\mathbf{S}' = \\begin{bmatrix} 8 & 2 \\\\ -2 & 1 \\\\ -2 & 3 \\\\ 3 & 1 \\\\ -4 & -6 \\end{bmatrix}$.\n$$\n\\mathbf{y}' = \\mathbf{y} - \\mathbf{c}_3 = \\begin{bmatrix} 3.2 \\\\ 2.8 \\\\ 2.6 \\\\ 1.3 \\\\ 2.4 \\end{bmatrix} - \\begin{bmatrix} 0 \\\\ 3 \\\\ 2 \\\\ 0 \\\\ 6 \\end{bmatrix} = \\begin{bmatrix} 3.2 \\\\ -0.2 \\\\ 0.6 \\\\ 1.3 \\\\ -3.6 \\end{bmatrix}\n$$\nWe first solve the unconstrained least squares problem by solving the normal equations: $(\\mathbf{S}')^{\\top}\\mathbf{S}'\\mathbf{p}' = (\\mathbf{S}')^{\\top}\\mathbf{y}'$.\n\nLet's compute the matrices $(\\mathbf{S}')^{\\top}\\mathbf{S}'$ and $(\\mathbf{S}')^{\\top}\\mathbf{y}'$:\n$$\n(\\mathbf{S}')^{\\top}\\mathbf{S}' = \n\\begin{bmatrix}\n8 & -2 & -2 & 3 & -4 \\\\\n2 & 1 & 3 & 1 & -6\n\\end{bmatrix}\n\\begin{bmatrix} 8 & 2 \\\\ -2 & 1 \\\\ -2 & 3 \\\\ 3 & 1 \\\\ -4 & -6 \\end{bmatrix}\n=\n\\begin{bmatrix}\n64+4+4+9+16 & 16-2-6+3+24 \\\\\n16-2-6+3+24 & 4+1+9+1+36\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n97 & 35 \\\\\n35 & 51\n\\end{bmatrix}\n$$\n$$\n(\\mathbf{S}')^{\\top}\\mathbf{y}' = \n\\begin{bmatrix}\n8 & -2 & -2 & 3 & -4 \\\\\n2 & 1 & 3 & 1 & -6\n\\end{bmatrix}\n\\begin{bmatrix} 3.2 \\\\ -0.2 \\\\ 0.6 \\\\ 1.3 \\\\ -3.6 \\end{bmatrix}\n=\n\\begin{bmatrix}\n8(3.2) - 2(-0.2) - 2(0.6) + 3(1.3) - 4(-3.6) \\\\\n2(3.2) + 1(-0.2) + 3(0.6) + 1(1.3) - 6(-3.6)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n25.6 + 0.4 - 1.2 + 3.9 + 14.4 \\\\\n6.4 - 0.2 + 1.8 + 1.3 + 21.6\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n43.1 \\\\\n30.9\n\\end{bmatrix}\n$$\nThe system to solve is $\\begin{bmatrix} 97 & 35 \\\\ 35 & 51 \\end{bmatrix} \\begin{bmatrix} p_1 \\\\ p_2 \\end{bmatrix} = \\begin{bmatrix} 43.1 \\\\ 30.9 \\end{bmatrix}$.\nThe determinant of the matrix is $97 \\times 51 - 35^2 = 4947 - 1225 = 3722$.\nThe solution $\\mathbf{p}'$ is given by:\n$$\n\\begin{bmatrix} p_1 \\\\ p_2 \\end{bmatrix} = \\frac{1}{3722} \\begin{bmatrix} 51 & -35 \\\\ -35 & 97 \\end{bmatrix} \\begin{bmatrix} 43.1 \\\\ 30.9 \\end{bmatrix}\n= \\frac{1}{3722} \\begin{bmatrix} 51(43.1) - 35(30.9) \\\\ -35(43.1) + 97(30.9) \\end{bmatrix}\n= \\frac{1}{3722} \\begin{bmatrix} 2198.1 - 1081.5 \\\\ -1508.5 + 2997.3 \\end{bmatrix}\n= \\frac{1}{3722} \\begin{bmatrix} 1116.6 \\\\ 1488.8 \\end{bmatrix}\n= \\begin{bmatrix} 0.3 \\\\ 0.4 \\end{bmatrix}\n$$\nSo the unconstrained solution is $p_1 = 0.3$ and $p_2 = 0.4$. We must check if this solution satisfies the constraints of the reduced problem:\n1. $p_1 = 0.3 \\ge 0$ (satisfied)\n2. $p_2 = 0.4 \\ge 0$ (satisfied)\n3. $p_1 + p_2 = 0.3 + 0.4 = 0.7 \\le 1$ (satisfied)\n\nSince the unconstrained solution lies within the feasible region, it is also the solution to the constrained problem.\nNow we find $p_3$:\n$$ p_3 = 1 - p_1 - p_2 = 1 - 0.3 - 0.4 = 0.3 $$\nThis satisfies the constraint $p_3 \\ge 0$.\nTherefore, the optimal cell-type proportion vector is $\\hat{\\mathbf{p}} = \\begin{bmatrix} 0.3 \\\\ 0.4 \\\\ 0.3 \\end{bmatrix}$.\n\nThe final step is to compute the residual Euclidean norm, $\\|\\mathbf{S}\\hat{\\mathbf{p}} - \\mathbf{y}\\|_{2}$. First, we compute the fitted bulk expression vector $\\hat{\\mathbf{y}} = \\mathbf{S}\\hat{\\mathbf{p}}$:\n$$\n\\hat{\\mathbf{y}} = \\mathbf{S}\\hat{\\mathbf{p}} = \n\\begin{bmatrix}\n8 & 2 & 0 \\\\\n1 & 4 & 3 \\\\\n0 & 5 & 2 \\\\\n3 & 1 & 0 \\\\\n2 & 0 & 6\n\\end{bmatrix}\n\\begin{bmatrix}\n0.3 \\\\\n0.4 \\\\\n0.3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n8(0.3) + 2(0.4) + 0(0.3) \\\\\n1(0.3) + 4(0.4) + 3(0.3) \\\\\n0(0.3) + 5(0.4) + 2(0.3) \\\\\n3(0.3) + 1(0.4) + 0(0.3) \\\\\n2(0.3) + 0(0.4) + 6(0.3)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n2.4 + 0.8 \\\\\n0.3 + 1.6 + 0.9 \\\\\n2.0 + 0.6 \\\\\n0.9 + 0.4 \\\\\n0.6 + 1.8\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n3.2 \\\\\n2.8 \\\\\n2.6 \\\\\n1.3 \\\\\n2.4\n\\end{bmatrix}\n$$\nWe observe that the fitted vector $\\hat{\\mathbf{y}}$ is exactly equal to the observed vector $\\mathbf{y}$.\nThe residual vector is:\n$$ \\mathbf{S}\\hat{\\mathbf{p}} - \\mathbf{y} = \\begin{bmatrix} 3.2 \\\\ 2.8 \\\\ 2.6 \\\\ 1.3 \\\\ 2.4 \\end{bmatrix} - \\begin{bmatrix} 3.2 \\\\ 2.8 \\\\ 2.6 \\\\ 1.3 \\\\ 2.4 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\mathbf{0} $$\nThe residual Euclidean norm is therefore:\n$$ \\|\\mathbf{S}\\hat{\\mathbf{p}} - \\mathbf{y}\\|_{2} = \\|\\mathbf{0}\\|_{2} = \\sqrt{0^2+0^2+0^2+0^2+0^2} = 0 $$\nThe result is an exact value of $0$, so no rounding is necessary. This indicates that the observed data can be perfectly explained by the linear mixture model, meaning the vector $\\mathbf{y}$ lies within the convex hull of the columns of the signature matrix $\\mathbf{S}$.", "answer": "$$\\boxed{0}$$", "id": "4321276"}, {"introduction": "While least-squares methods provide a point estimate, Bayesian inference offers a powerful way to incorporate prior knowledge and quantify uncertainty. This practice delves into the conjugate Dirichlet-Multinomial model, demonstrating how to encode beliefs about cell-type prevalence—such as the known rarity of a specific cell type—into your analysis [@problem_id:4321280]. You will explore how changing prior parameters affects the posterior estimates of cell proportions, gaining insight into the interplay between data and prior knowledge in a probabilistic setting.", "problem": "You are modeling cellular composition proportions in bulk-tissue expression data for precision medicine and genomic diagnostics. Suppose the underlying cell-type proportion vector is $p = (p_1, \\dots, p_K)$ with $p_j \\ge 0$ and $\\sum_{j=1}^K p_j = 1$. You place an asymmetric Dirichlet prior on $p$ to encode prior knowledge about rare cell types: $p \\sim \\text{Dirichlet}(\\alpha_1, \\dots, \\alpha_K)$, where a rare cell type has a small concentration parameter $\\alpha_j$. You then observe aggregated cell-type-specific counts $x = (x_1, \\dots, x_K)$ from a total of $N = \\sum_{j=1}^K x_j$ assignments, modeled by a Multinomial likelihood with parameter $p$.\n\nStarting from fundamental definitions of the Multinomial likelihood and Dirichlet prior, and their Bayesian conjugacy, derive the posterior distribution of $p$ given $x$. From that posterior, derive general expressions for the posterior mean $\\mathbb{E}[p_j \\mid x]$ and posterior variance $\\mathrm{Var}(p_j \\mid x)$ in terms of the posterior concentration parameters. Use these expressions to encode prior knowledge about a rare cell type by changing a single concentration parameter $\\alpha_j$ while keeping all other concentration parameters fixed. Simulate how changing that single parameter affects the posterior mean and variance of the corresponding $p_j$ across several scenarios by computing the exact values (do not use percentage signs; express all proportions as decimals).\n\nImplement a program that, for each test case below, takes:\n- an asymmetric prior concentration vector $(\\alpha_1, \\dots, \\alpha_K)$,\n- an index $j$ designating the rare cell type whose single concentration parameter is to be changed,\n- a list of replacement values for $\\alpha_j$,\n- an observed count vector $(x_1, \\dots, x_K)$,\n\nand outputs, for each replacement value of $\\alpha_j$, the posterior mean and variance of $p_j$ under the corresponding posterior. The output for one test case should be a list of floats in the order $[\\text{mean}_1,\\text{var}_1,\\text{mean}_2,\\text{var}_2,\\dots]$, where each pair corresponds to one replacement value for $\\alpha_j$.\n\nUse the following test suite, designed to probe different regimes:\n\n- Test Case 1 (general case, rare cell has few counts):\n  - $K = 5$\n  - Prior concentrations: $(\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4, \\alpha_5) = (0.5, 2.0, 2.0, 1.0, 0.1)$\n  - Rare cell-type index: $j = 5$\n  - Replacement values for $\\alpha_5$: $[0.05, 0.1, 1.0]$\n  - Observed counts: $(x_1, x_2, x_3, x_4, x_5) = (60, 180, 140, 15, 5)$\n\n- Test Case 2 (boundary case, zero observed counts for the rare cell):\n  - $K = 4$\n  - Prior concentrations: $(\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4) = (1.5, 1.5, 1.5, 0.05)$\n  - Rare cell-type index: $j = 4$\n  - Replacement values for $\\alpha_4$: $[0.01, 0.05, 5.0]$\n  - Observed counts: $(x_1, x_2, x_3, x_4) = (120, 80, 50, 0)$\n\n- Test Case 3 (large prior for the rare cell relative to data):\n  - $K = 3$\n  - Prior concentrations: $(\\alpha_1, \\alpha_2, \\alpha_3) = (0.5, 0.5, 100.0)$\n  - Rare cell-type index: $j = 3$\n  - Replacement values for $\\alpha_3$: $[10.0, 100.0, 1000.0]$\n  - Observed counts: $(x_1, x_2, x_3) = (30, 20, 10)$\n\n- Test Case 4 (small sample size, multiple rare types, sensitivity to prior):\n  - $K = 6$\n  - Prior concentrations: $(\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4, \\alpha_5, \\alpha_6) = (0.2, 0.2, 0.2, 0.2, 0.2, 0.2)$\n  - Rare cell-type index: $j = 3$\n  - Replacement values for $\\alpha_3$: $[0.01, 0.2, 2.0]$\n  - Observed counts: $(x_1, x_2, x_3, x_4, x_5, x_6) = (2, 1, 0, 0, 1, 0)$\n\nYour program should produce a single line of output containing the aggregated results across all four test cases as a comma-separated list enclosed in square brackets, where each test case contributes one inner list in the format described above. All numeric outputs should be decimals rounded to six digits after the decimal point. The final output must be of the form\n$[[\\text{mean}_1,\\text{var}_1,\\text{mean}_2,\\text{var}_2,\\dots],[\\dots],[\\dots],[\\dots]]$,\nprinted exactly as a single line with no additional text.", "solution": "We begin by formalizing the probabilistic model for cellular deconvolution of bulk-tissue expression data. Let $p = (p_1, \\dots, p_K)$ denote the vector of cell-type proportions, where $p_j \\ge 0$ and $\\sum_{j=1}^K p_j = 1$. To encode prior knowledge, we place an asymmetric Dirichlet prior on $p$,\n$$\np \\sim \\text{Dirichlet}(\\alpha_1, \\dots, \\alpha_K),\n$$\nwhere the concentration parameters $\\alpha_j > 0$ control the prior mass over compositions. Small $\\alpha_j$ for a rare cell type indexes a prior belief that $p_j$ is typically small.\n\nSuppose we observe counts $x = (x_1, \\dots, x_K)$, with total $N = \\sum_{j=1}^K x_j$, generated by a Multinomial distribution conditioned on $p$:\n$$\nx \\mid p \\sim \\text{Multinomial}(N, p).\n$$\nThe likelihood under the Multinomial is, up to a multinomial coefficient constant, \n$$\nL(p; x) \\propto \\prod_{j=1}^K p_j^{x_j}.\n$$\nThe Dirichlet prior has density\n$$\n\\pi(p; \\alpha) = \\frac{1}{B(\\alpha)} \\prod_{j=1}^K p_j^{\\alpha_j - 1},\n$$\nwhere $B(\\alpha)$ is the multivariate Beta function $B(\\alpha) = \\frac{\\prod_{j=1}^K \\Gamma(\\alpha_j)}{\\Gamma(\\alpha_0)}$ and $\\alpha_0 = \\sum_{j=1}^K \\alpha_j$.\n\nBy Bayes' theorem, the posterior is proportional to the product of likelihood and prior:\n$$\n\\pi(p \\mid x) \\propto L(p; x) \\cdot \\pi(p; \\alpha) \\propto \\prod_{j=1}^K p_j^{x_j} \\cdot \\prod_{j=1}^K p_j^{\\alpha_j - 1} = \\prod_{j=1}^K p_j^{(\\alpha_j + x_j) - 1}.\n$$\nRecognizing the Dirichlet kernel, we conclude the posterior distribution is also Dirichlet with updated concentration parameters\n$$\n\\alpha'_j = \\alpha_j + x_j, \\quad \\text{for } j = 1, \\dots, K,\n$$\nand total concentration\n$$\n\\alpha'_0 = \\sum_{j=1}^K \\alpha'_j = \\sum_{j=1}^K \\alpha_j + \\sum_{j=1}^K x_j = \\alpha_0 + N.\n$$\n\nWe now derive the posterior mean and variance of $p_j$ under the Dirichlet distribution. For $p \\sim \\text{Dirichlet}(\\alpha')$, standard moment results can be derived using properties of the Gamma function and the representation of the Dirichlet as normalized Gamma random variables. Specifically, let $Y_j \\sim \\text{Gamma}(\\alpha'_j, 1)$ independently and define $S = \\sum_{k=1}^K Y_k$. Then $p_j = Y_j / S$. Using this representation, one obtains\n$$\n\\mathbb{E}[p_j] = \\frac{\\alpha'_j}{\\alpha'_0},\n$$\nand the second moment\n$$\n\\mathbb{E}[p_j^2] = \\frac{\\alpha'_j(\\alpha'_j + 1)}{\\alpha'_0(\\alpha'_0 + 1)}.\n$$\nTherefore, the variance is\n$$\n\\mathrm{Var}(p_j) = \\mathbb{E}[p_j^2] - (\\mathbb{E}[p_j])^2 = \\frac{\\alpha'_j(\\alpha'_0 - \\alpha'_j)}{\\alpha'^2_0(\\alpha'_0 + 1)}.\n$$\nThese expressions follow from the known Dirichlet moments or can be derived via integration using the Dirichlet density and Beta/Gamma identities.\n\nTo encode prior knowledge about a rare cell type in a Bayesian deconvolution setting, we consider changing a single prior concentration parameter $\\alpha_j$ while keeping all other $\\alpha_k$ for $k \\ne j$ fixed. Given observed counts $x$, this change yields a posterior with updated parameters $\\alpha'_j = \\alpha_j^{(\\text{new})} + x_j$ and $\\alpha'_0 = (\\alpha_0^{(\\text{new})}) + N$, where $\\alpha_0^{(\\text{new})}$ reflects the modified single component. The posterior mean and variance of $p_j$ respond to this change through the above formulas.\n\nAlgorithmic steps to compute the requested outputs for each test case:\n1. Parse $K$, the prior concentration vector $(\\alpha_1, \\dots, \\alpha_K)$, the rare cell-type index $j$, the list of replacement values for $\\alpha_j$, and the observed counts $(x_1, \\dots, x_K)$.\n2. For each replacement value $v$ in the list:\n   - Form a new prior vector $\\tilde{\\alpha}$ identical to the given prior except $\\tilde{\\alpha}_j = v$.\n   - Compute the posterior parameters $\\alpha'_k = \\tilde{\\alpha}_k + x_k$ for all $k$, and $\\alpha'_0 = \\sum_{k=1}^K \\alpha'_k$.\n   - Compute the posterior mean $\\mu_j = \\alpha'_j / \\alpha'_0$ and variance $\\sigma_j^2 = \\alpha'_j(\\alpha'_0 - \\alpha'_j)/(\\alpha'^2_0(\\alpha'_0 + 1))$.\n   - Append $\\mu_j$ and $\\sigma_j^2$ to the test case’s result list.\n3. Round all numeric outputs to six digits after the decimal point.\n4. Aggregate the results from all test cases into a single outer list and print on one line in the format specified.\n\nThis procedure deterministically quantifies how changing a single Dirichlet concentration parameter for a rare cell type affects the posterior mean and variance of its proportion estimate under a conjugate Dirichlet-Multinomial model. The test suite covers a general case, a boundary condition with zero observed counts, a dominating prior, and a small-sample scenario to probe sensitivity to prior specification.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef posterior_mean_variance(alpha_vec, counts_vec, j_index):\n    \"\"\"\n    Compute posterior mean and variance for p_j under a Dirichlet posterior\n    given prior alpha_vec and observed counts counts_vec, for index j_index.\n    \"\"\"\n    alpha_vec = np.asarray(alpha_vec, dtype=float)\n    counts_vec = np.asarray(counts_vec, dtype=float)\n    alpha_post = alpha_vec + counts_vec\n    alpha0_post = float(np.sum(alpha_post))\n    aj_post = float(alpha_post[j_index])\n    mean_j = aj_post / alpha0_post\n    var_j = aj_post * (alpha0_post - aj_post) / (alpha0_post**2 * (alpha0_post + 1.0))\n    return mean_j, var_j\n\ndef format_results_nested(nested_lists):\n    \"\"\"\n    Format nested list of floats into a single-line string with required structure,\n    rounding to six decimals.\n    \"\"\"\n    def fmt_float(x):\n        # Round to six decimal places\n        return f\"{x:.6f}\"\n    inner_strs = []\n    for inner in nested_lists:\n        inner_fmt = \",\".join(fmt_float(val) for val in inner)\n        inner_strs.append(f\"[{inner_fmt}]\")\n    return f\"[{','.join(inner_strs)}]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (K, prior_alpha, j_index, alpha_j_variants, counts)\n    test_cases = [\n        # Test Case 1\n        (5, [0.5, 2.0, 2.0, 1.0, 0.1], 4, [0.05, 0.1, 1.0], [60, 180, 140, 15, 5]),\n        # Test Case 2\n        (4, [1.5, 1.5, 1.5, 0.05], 3, [0.01, 0.05, 5.0], [120, 80, 50, 0]),\n        # Test Case 3\n        (3, [0.5, 0.5, 100.0], 2, [10.0, 100.0, 1000.0], [30, 20, 10]),\n        # Test Case 4\n        (6, [0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 2, [0.01, 0.2, 2.0], [2, 1, 0, 0, 1, 0]),\n    ]\n\n    results = []\n    for K, prior_alpha, j_index, variants, counts in test_cases:\n        # Sanity checks\n        assert len(prior_alpha) == K\n        assert len(counts) == K\n        assert j_index >= 0 and j_index < K\n        inner_results = []\n        for v in variants:\n            # Replace only the single concentration parameter for the rare cell type.\n            alpha_new = list(prior_alpha)\n            # Ensure positivity of Dirichlet parameters\n            if v <= 0:\n                raise ValueError(\"Dirichlet concentration parameters must be strictly positive.\")\n            alpha_new[j_index] = v\n            mean_j, var_j = posterior_mean_variance(alpha_new, counts, j_index)\n            inner_results.extend([mean_j, var_j])\n        results.append(inner_results)\n\n    # Final print statement in the exact required format.\n    print(format_results_nested(results))\n\nsolve()\n```", "id": "4321280"}]}