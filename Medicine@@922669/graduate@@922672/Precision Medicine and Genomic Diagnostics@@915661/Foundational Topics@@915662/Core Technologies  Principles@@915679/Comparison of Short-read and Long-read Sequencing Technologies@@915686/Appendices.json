{"hands_on_practices": [{"introduction": "To effectively design and budget for a genomic study, it is essential to understand the practical throughput of different sequencing platforms. This exercise provides a foundational comparison of leading short-read and long-read technologies by calculating the number of human genomes that can be sequenced in a single instrument run [@problem_id:4328179]. By incorporating realistic data yields and platform-specific usable data fractions, you will gain a quantitative understanding of how these factors determine the scalability of each technology for large-scale clinical whole-genome sequencing projects.", "problem": "In clinical whole-genome sequencing for precision medicine, platform throughput and usable data fraction determine how many human genomes can be completed at a target coverage depth. Consider one instrument run each of three platforms: Illumina NovaSeq, Pacific Biosciences (PacBio) Sequel IIe, and Oxford Nanopore Technologies (ONT) PromethION. The total per-run raw yields are approximately $3.0\\times 10^{12}$ base pairs for Illumina NovaSeq, an upper-end $3.0\\times 10^{10}$ base pairs of High-Fidelity (HiFi) reads for PacBio Sequel IIe, and an upper-end $2.0\\times 10^{11}$ base pairs for ONT PromethION. Assume a human haploid genome size of $G=3.0\\times 10^{9}$ base pairs and a clinical coverage requirement of $30$-fold coverage per genome. To account for quality control and alignment, use the following platform-specific usable data fractions: $f_{\\text{NovaSeq}}=0.85$ (to reflect duplicate removal and quality trimming), $f_{\\text{SequelIIe}}=0.95$ (HiFi pass reads), and $f_{\\text{PromethION}}=0.75$ (fraction of reads meeting the accuracy threshold and aligning).\n\nStarting from the fundamental definition of coverage depth as total usable sequenced bases divided by reference genome size, and treating the number of completed genomes as an integer constrained by the available usable data, determine the maximum integer number of complete human genomes at $30\\times$ coverage that each platform can produce per run. Provide your final answer as an ordered triple $\\left(N_{\\text{NovaSeq}}, N_{\\text{SequelIIe}}, N_{\\text{PromethION}}\\right)$, where each $N$ is the greatest integer less than or equal to the achievable count. Do not include any units in your final answer.", "solution": "The problem is subjected to a rigorous validation process before any attempt at a solution.\n\n### Step 1: Extract Givens\nThe data, variables, and conditions provided in the problem statement are as follows:\n-   **Platform 1: Illumina NovaSeq**\n    -   Total raw yield: $D_{\\text{raw,NovaSeq}} = 3.0 \\times 10^{12}$ base pairs\n    -   Usable data fraction: $f_{\\text{NovaSeq}} = 0.85$\n-   **Platform 2: PacBio Sequel IIe**\n    -   Total raw yield (HiFi): $D_{\\text{raw,SequelIIe}} = 3.0 \\times 10^{10}$ base pairs\n    -   Usable data fraction: $f_{\\text{SequelIIe}} = 0.95$\n-   **Platform 3: ONT PromethION**\n    -   Total raw yield: $D_{\\text{raw,PromethION}} = 2.0 \\times 10^{11}$ base pairs\n    -   Usable data fraction: $f_{\\text{PromethION}} = 0.75$\n-   **Universal Parameters**\n    -   Human haploid genome size: $G = 3.0 \\times 10^{9}$ base pairs\n    -   Required coverage depth: $C = 30$-fold\n-   **Constraint**\n    -   The number of completed genomes, $N$, must be the greatest integer less than or equal to the calculated value.\n    -   The final answer is to be an ordered triple $\\left(N_{\\text{NovaSeq}}, N_{\\text{SequelIIe}}, N_{\\text{PromethION}}\\right)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity against the established criteria.\n-   **Scientifically Grounded:** The problem is based on fundamental concepts in genomics, specifically whole-genome sequencing. The specified platforms (Illumina NovaSeq, PacBio Sequel IIe, ONT PromethION) are real, widely used instruments. The given yield values, genome size, coverage requirement, and usable data fractions are realistic and representative of current high-throughput sequencing practices in a clinical context. The problem is free of scientific error or pseudoscience.\n-   **Well-Posed:** All necessary quantitative data ($D_{\\text{raw}}$, $f$, $G$, $C$) are provided. The objective is clearly stated: to calculate the maximum integer number of genomes. The constraint to use the greatest integer less than or equal to the calculated value (i.e., the floor function) ensures a unique and stable solution.\n-   **Objective:** The problem is formulated with precise, unbiased, and quantitative language. It is devoid of subjective or opinion-based claims.\n\nThe problem statement is found to be scientifically grounded, well-posed, objective, and self-contained. No flaws outlined in the validation checklist are present.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\n### Solution Derivation\nThe solution proceeds by first determining the amount of usable sequencing data required to sequence a single human genome to the specified coverage depth. Then, for each platform, the total available usable data per run is calculated. Finally, the number of genomes is determined by dividing the total available usable data by the data required per genome, subject to the integer constraint.\n\nLet $B_{\\text{req}}$ be the total usable sequenced bases required to cover one genome to a depth of $C$. Based on the provided definition, this is calculated as the product of the coverage depth and the genome size:\n$$\nB_{\\text{req}} = C \\times G\n$$\nSubstituting the given values, $C=30$ and $G=3.0 \\times 10^{9}$ base pairs:\n$$\nB_{\\text{req}} = 30 \\times (3.0 \\times 10^{9} \\text{ bp}) = 90 \\times 10^{9} \\text{ bp} = 9.0 \\times 10^{10} \\text{ bp}\n$$\nThis is the amount of usable sequence data required per genome.\n\nNext, we calculate the total usable data, $D_{\\text{usable}}$, produced by each platform in a single run. This is the product of the total raw yield, $D_{\\text{raw}}$, and the platform-specific usable data fraction, $f$.\n$$\nD_{\\text{usable}} = D_{\\text{raw}} \\times f\n$$\nWe compute this for each of the three platforms:\n\n**1. Illumina NovaSeq:**\n$$\nD_{\\text{usable, NovaSeq}} = D_{\\text{raw, NovaSeq}} \\times f_{\\text{NovaSeq}} = (3.0 \\times 10^{12}) \\times 0.85 = 2.55 \\times 10^{12} \\text{ bp}\n$$\n\n**2. PacBio Sequel IIe:**\n$$\nD_{\\text{usable, SequelIIe}} = D_{\\text{raw, SequelIIe}} \\times f_{\\text{SequelIIe}} = (3.0 \\times 10^{10}) \\times 0.95 = 2.85 \\times 10^{10} \\text{ bp}\n$$\n\n**3. ONT PromethION:**\n$$\nD_{\\text{usable, PromethION}} = D_{\\text{raw, PromethION}} \\times f_{\\text{PromethION}} = (2.0 \\times 10^{11}) \\times 0.75 = 1.5 \\times 10^{11} \\text{ bp}\n$$\n\nThe number of genomes, $N$, that can be completed is the total usable data from the run divided by the usable data required per genome. As the problem requires the maximum *integer* number, we apply the floor function, $\\lfloor \\cdot \\rfloor$.\n$$\nN = \\left\\lfloor \\frac{D_{\\text{usable}}}{B_{\\text{req}}} \\right\\rfloor\n$$\nWe now calculate $N$ for each platform using $B_{\\text{req}} = 9.0 \\times 10^{10}$ bp.\n\n**1. Illumina NovaSeq:**\n$$\nN_{\\text{NovaSeq}} = \\left\\lfloor \\frac{2.55 \\times 10^{12}}{9.0 \\times 10^{10}} \\right\\rfloor = \\left\\lfloor \\frac{2.55}{9.0} \\times 10^{2} \\right\\rfloor = \\lfloor 0.2833... \\times 100 \\rfloor = \\lfloor 28.33... \\rfloor = 28\n$$\n\n**2. PacBio Sequel IIe:**\n$$\nN_{\\text{SequelIIe}} = \\left\\lfloor \\frac{2.85 \\times 10^{10}}{9.0 \\times 10^{10}} \\right\\rfloor = \\lfloor 0.3166... \\rfloor = 0\n$$\n\n**3. ONT PromethION:**\n$$\nN_{\\text{PromethION}} = \\left\\lfloor \\frac{1.5 \\times 10^{11}}{9.0 \\times 10^{10}} \\right\\rfloor = \\left\\lfloor \\frac{1.5}{9.0} \\times 10^{1} \\right\\rfloor = \\lfloor 0.1666... \\times 10 \\rfloor = \\lfloor 1.666... \\rfloor = 1\n$$\n\nThe maximum integer number of complete human genomes at $30\\times$ coverage for each platform per run are $28$ for NovaSeq, $0$ for Sequel IIe, and $1$ for PromethION. The final answer is the ordered triple $(28, 0, 1)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 28 & 0 & 1 \\end{pmatrix}}\n$$", "id": "4328179"}, {"introduction": "A key challenge in precision medicine is the reliable detection of low-frequency mosaic variants, which requires distinguishing a faint biological signal from background sequencing noise. This problem delves into the statistical principles governing this challenge by asking you to derive the minimum sequencing depth required to achieve a specified sensitivity and specificity [@problem_id:4328142]. By applying the Central Limit Theorem to a binomial error model, you will directly connect a platform's intrinsic error rate ($p$) to the experimental design ($n$) needed to confidently call a variant of a given allele fraction ($f$), highlighting the trade-offs between sequencing depth and detection power.", "problem": "A clinical laboratory implementing Oxford Nanopore Technologies (ONT) long-read sequencing for a targeted panel aims to prospectively set a read depth policy for detecting low-level mosaic single-nucleotide variants relevant to precision oncology. Assume the following foundational modeling assumptions, which reflect well-tested facts in sequencing error modeling and inferential testing:\n\n- Each read covering a locus is an independent Bernoulli trial for whether it reports an alternate base call.\n- Under the null hypothesis of no true variant at the locus, the per-read probability of an alternate call equals the ONT per-read base miscall rate $p$, here $p=0.03$.\n- Under the alternative hypothesis that a mosaic variant is truly present at variant allele fraction $f$, here $f=0.05$, reads originate from molecules carrying the alternate base with probability $f$ and from molecules carrying the reference base with probability $1-f$. Assume symmetry of basecalling errors at this locus so that a true alternate base is miscalled as reference with probability $p$, and a true reference base is miscalled as alternate with probability $p$.\n- A one-sided binomial test at significance level $\\alpha=0.01$ is used to call a variant if the observed count of alternate-supporting reads exceeds a data-dependent critical value that controls the type I error at $\\alpha$.\n- For clinical sensitivity, require that the test has power at least $1-\\beta$ with $\\beta=0.10$ to detect a true mosaic fraction $f$ at coverage $n$.\n\nStarting from the Central Limit Theorem (CLT) for the binomial distribution and the definition of statistical power for a one-sided test, derive an analytic expression for the minimal read depth $n$ (as a function of $p$, $f$, $\\alpha$, and $\\beta$) needed to achieve the above decision criteria under the stated model. Then evaluate this expression numerically for ONT with $p=0.03$, $f=0.05$, $\\alpha=0.01$, and $\\beta=0.10$, and report the smallest integer $n$ that satisfies the criteria.\n\nFinally, briefly justify, in the context of comparing short-read and long-read sequencing technologies for precision medicine, how such a coverage requirement would interact with practical clinical reporting thresholds (for example, minimal alternate read counts and minimal reportable variant allele fractions) and how these thresholds might differ between ONT long reads and short-read platforms with substantially lower per-read error rates.\n\nYour final numeric answer must be the minimal integer $n$. Do not include any units. Do not round to a fixed number of decimal places; instead, report the exact minimal integer that satisfies the criteria.", "solution": "The problem has been validated and is determined to be a scientifically grounded, well-posed, and objective problem in statistical bioinformatics. We may proceed with a formal solution.\n\nThe task is to derive the minimum required read depth, $n$, for detecting a mosaic single-nucleotide variant. We will use a normal approximation to the binomial distribution, as specified by the use of the Central Limit Theorem (CLT).\n\nLet $X$ be the random variable representing the number of reads supporting the alternate allele out of a total of $n$ reads.\n\n**1. Model under the Null Hypothesis ($H_0$)**\nUnder the null hypothesis, no true variant is present. An observed alternate allele is always a sequencing error. The probability of observing an alternate allele on any given read is the per-read base miscall rate, $p$.\nLet $p_0$ be this probability.\n$$p_0 = p$$\nThus, under $H_0$, the number of alternate reads $X$ follows a binomial distribution:\n$$X | H_0 \\sim \\text{Binomial}(n, p_0)$$\nThe mean and variance are:\n$$\\mu_0 = E[X|H_0] = n p_0 = np$$\n$$\\sigma_0^2 = \\text{Var}(X|H_0) = n p_0 (1-p_0) = np(1-p)$$\n\n**2. Model under the Alternative Hypothesis ($H_1$)**\nUnder the alternative hypothesis, a true mosaic variant is present at a variant allele fraction (VAF) of $f$. A read can originate from a molecule carrying the alternate allele (with probability $f$) or the reference allele (with probability $1-f$). The error model is symmetric.\nLet $p_1$ be the probability of observing an alternate allele on any given read. We calculate this using the law of total probability:\n$$p_1 = P(\\text{call alt}) = P(\\text{call alt} | \\text{true alt})P(\\text{true alt}) + P(\\text{call alt} | \\text{true ref})P(\\text{true ref})$$\nFrom the problem statement:\n- $P(\\text{true alt}) = f$\n- $P(\\text{true ref}) = 1-f$\n- $P(\\text{call alt} | \\text{true ref}) = p$ (a reference base is miscalled as alternate)\n- A true alternate base is miscalled as reference with probability $p$, so it is correctly called as alternate with probability $1-p$. Thus, $P(\\text{call alt} | \\text{true alt}) = 1-p$.\n\nSubstituting these into the equation for $p_1$:\n$$p_1 = (1-p)f + p(1-f) = f - pf + p - pf = f + p - 2pf$$\nUnder $H_1$, the number of alternate reads $X$ follows a binomial distribution with this new probability:\n$$X | H_1 \\sim \\text{Binomial}(n, p_1)$$\nThe mean and variance are:\n$$\\mu_1 = E[X|H_1] = n p_1$$\n$$\\sigma_1^2 = \\text{Var}(X|H_1) = n p_1 (1-p_1)$$\n\n**3. Test Statistics and CLT Approximation**\nFor a sufficiently large $n$, the CLT allows us to approximate these binomial distributions with normal distributions:\n$$X | H_0 \\approx N(\\mu_0, \\sigma_0^2) = N(np, np(1-p))$$\n$$X | H_1 \\approx N(\\mu_1, \\sigma_1^2) = N(np_1, np_1(1-p_1))$$\nWe use a one-sided test, rejecting $H_0$ for a large number of alternate reads. Let $k$ be the critical value for the count of alternate reads. We reject $H_0$ if $X > k$.\n\n**4. Derivation of the Analytical Expression for $n$**\nThe test must satisfy two conditions: a significance level $\\alpha$ and a power of $1-\\beta$.\n\nFirst, the Type I error rate (significance) is constrained by $\\alpha$:\n$$P(X > k | H_0) = \\alpha$$\nStandardizing the variable under $H_0$:\n$$P\\left(\\frac{X - \\mu_0}{\\sigma_0} > \\frac{k - \\mu_0}{\\sigma_0} \\right) = \\alpha$$\nLet $z_{\\alpha}$ be the upper $\\alpha$-quantile of the standard normal distribution, where $P(Z > z_{\\alpha}) = \\alpha$ for $Z \\sim N(0,1)$. Then:\n$$\\frac{k - \\mu_0}{\\sigma_0} = z_{\\alpha}$$\n$$k = \\mu_0 + z_{\\alpha}\\sigma_0 = np + z_{\\alpha}\\sqrt{np(1-p)}$$\n\nSecond, the Type II error rate is $\\beta$, which means the power is $1-\\beta$:\n$$P(X > k | H_1) = 1-\\beta$$\nThis is equivalent to:\n$$P(X \\le k | H_1) = \\beta$$\nStandardizing the variable under $H_1$:\n$$P\\left(\\frac{X - \\mu_1}{\\sigma_1} \\le \\frac{k - \\mu_1}{\\sigma_1} \\right) = \\beta$$\nLet $z_{\\beta}$ be the upper $\\beta$-quantile of the standard normal distribution. Then the corresponding lower-tail quantile is $-z_{\\beta}$, so:\n$$\\frac{k - \\mu_1}{\\sigma_1} = -z_{\\beta}$$\n$$k = \\mu_1 - z_{\\beta}\\sigma_1 = np_1 - z_{\\beta}\\sqrt{np_1(1-p_1)}$$\n\nNow we have two expressions for the critical value $k$. By equating them, we can solve for $n$:\n$$np + z_{\\alpha}\\sqrt{np(1-p)} = np_1 - z_{\\beta}\\sqrt{np_1(1-p_1)}$$\nRearranging the terms to group $n$ and $\\sqrt{n}$:\n$$np_1 - np = z_{\\alpha}\\sqrt{np(1-p)} + z_{\\beta}\\sqrt{np_1(1-p_1)}$$\n$$n(p_1 - p) = \\sqrt{n} \\left( z_{\\alpha}\\sqrt{p(1-p)} + z_{\\beta}\\sqrt{p_1(1-p_1)} \\right)$$\nSolving for $\\sqrt{n}$:\n$$\\sqrt{n} = \\frac{z_{\\alpha}\\sqrt{p(1-p)} + z_{\\beta}\\sqrt{p_1(1-p_1)}}{p_1 - p}$$\nSquaring both sides gives the desired analytical expression for the minimal read depth $n$:\n$$n = \\left( \\frac{z_{\\alpha}\\sqrt{p(1-p)} + z_{\\beta}\\sqrt{p_1(1-p_1)}}{p_1 - p} \\right)^2$$\nSubstituting $p_1 = f+p-2pf$, the denominator becomes $p_1 - p = f(1-2p)$.\n$$n = \\left( \\frac{z_{\\alpha}\\sqrt{p(1-p)} + z_{\\beta}\\sqrt{(f+p-2pf)(1 - (f+p-2pf))}}{f(1-2p)} \\right)^2$$\nThis is the general analytic expression for $n$ as a function of $p$, $f$, $\\alpha$, and $\\beta$.\n\n**5. Numerical Evaluation**\nWe are given the following values:\n- $p = 0.03$ (ONT error rate)\n- $f = 0.05$ (mosaic VAF)\n- $\\alpha = 0.01$ (significance level)\n- $\\beta = 0.10$ (Type II error rate)\n\nFirst, we find the critical values from the standard normal distribution:\n- $z_{\\alpha} = z_{0.01} \\approx 2.3263$\n- $z_{\\beta} = z_{0.10} \\approx 1.2816$\n\nNext, we calculate the probabilities $p_0$ and $p_1$:\n- $p_0 = p = 0.03$\n- $p_1 = f + p - 2pf = 0.05 + 0.03 - 2(0.05)(0.03) = 0.08 - 0.003 = 0.077$\n\nNow we compute the terms in the formula for $n$:\n- Denominator: $p_1 - p_0 = 0.077 - 0.03 = 0.047$\n- Numerator term 1: $z_{\\alpha}\\sqrt{p_0(1-p_0)} = 2.3263 \\times \\sqrt{0.03(1-0.03)} = 2.3263 \\times \\sqrt{0.0291} \\approx 2.3263 \\times 0.170587 \\approx 0.39684$\n- Numerator term 2: $z_{\\beta}\\sqrt{p_1(1-p_1)} = 1.2816 \\times \\sqrt{0.077(1-0.077)} = 1.2816 \\times \\sqrt{0.071071} \\approx 1.2816 \\times 0.266591 \\approx 0.34166$\n\nCombining these to find $n$:\n$$n = \\left( \\frac{0.39684 + 0.34166}{0.047} \\right)^2 = \\left( \\frac{0.73850}{0.047} \\right)^2 \\approx (15.7128)^2 \\approx 246.88$$\nSince the read depth $n$ must be an integer, and the coverage must be at least this value to meet the power requirement, we must take the ceiling of this result.\n$$n = \\lceil 246.88 \\rceil = 247$$\n\n**6. Justification and Comparison of Sequencing Technologies**\nThe derived coverage requirement of $n=247$ for ONT long-read sequencing highlights a critical challenge for this technology in precision oncology: its high intrinsic base error rate.\n\nThe high noise floor, where the expected number of alternate reads under the null hypothesis is $np_0 = 247 \\times 0.03 \\approx 7.4$, necessitates a high threshold for calling a variant. Specifically, the critical count $k$ is approximately $k = np_0 + z_{\\alpha}\\sqrt{np_0(1-p_0)} \\approx 7.41 + 2.3263\\sqrt{247(0.0291)} \\approx 7.41 + 6.24 \\approx 13.65$. This means at least $14$ alternate reads are required to call a variant with $99\\%$ confidence. Such high thresholds for minimal alternate read counts are necessary to control false positives but can limit sensitivity for very low-level variants.\n\nIn contrast, short-read sequencing platforms (e.g., Illumina) have a much lower per-read error rate, typically $p' \\approx 0.001$. Repeating the calculation with this error rate yields a dramatically lower coverage requirement of $n' \\approx 51$. For short-read data, the background noise is minuscule ($n'p' = 51 \\times 0.001 = 0.051$ reads expected by chance). Consequently, observing even a few alternate reads (e.g., $3$ or $4$) can be highly significant. This allows clinical labs using short-read data to set much lower minimal alternate read count thresholds and confidently report variants at low allele fractions with more modest coverage depths.\n\nIn summary, while long-read sequencing is advantageous for resolving complex structural variants and phasing haplotypes, its higher error rate imposes a substantial coverage burden for the detection of low-frequency single-nucleotide variants. This necessitates either very deep (and costly) sequencing or the acceptance of higher reporting thresholds (both in terms of alternate read counts and minimum VAF) compared to what is achievable with lower-error short-read technologies.", "answer": "$$\n\\boxed{247}\n$$", "id": "4328142"}, {"introduction": "While long-read sequencing excels at identifying large structural variants, it also generates unique artifacts like chimeric reads that can mimic true genomic rearrangements. This practice shifts the focus from base-level errors to read-level artifacts, tasking you with designing a rule-based classifier to distinguish genuine structural variants from chimeras [@problem_id:4328159]. By integrating multiple lines of evidence—such as coverage continuity, breakpoint consistency, and read orientation—you will engage in a practical bioinformatics challenge of optimizing sensitivity and specificity to ensure the accuracy of structural variant calls.", "problem": "You are given a set of candidate breakpoint observations from long-read sequencing in the context of precision medicine and genomic diagnostics. The task is to design and implement a classification method that distinguishes genuine structural variants from chimeric long reads by integrating coverage continuity, breakpoint consistency across molecules, and orientation constraints. The classification must be controlled by thresholds that are selected to balance sensitivity and specificity.\n\nFundamental base and core definitions to use:\n- A read is a contiguous sequence reported by a sequencing instrument. In long-read technologies, individual molecules can span large genomic distances.\n- Coverage is the number of molecules that map to a genomic locus. Coverage continuity near a breakpoint is a proxy for whether the observation is supported along the molecule.\n- A structural variant is a genomic rearrangement such as a deletion, insertion, inversion, or translocation that is present in the sample. A chimeric read is a laboratory or instrument artifact that erroneously concatenates fragments from different molecules or unrelated genomic locations.\n- Define sensitivity as $ \\mathrm{TP} / (\\mathrm{TP} + \\mathrm{FN}) $ and specificity as $ \\mathrm{TN} / (\\mathrm{TN} + \\mathrm{FP}) $, where $ \\mathrm{TP} $ is the number of true positives, $ \\mathrm{FN} $ is the number of false negatives, $ \\mathrm{TN} $ is the number of true negatives, and $ \\mathrm{FP} $ is the number of false positives.\n- Define Youden’s $ J $ statistic as $ J = \\text{sensitivity} + \\text{specificity} - 1 $. Maximizing $ J $ yields a threshold set that jointly optimizes sensitivity and specificity.\n\nFeature definitions for each candidate breakpoint:\n- Coverage continuity score $ s_c \\in [0,1] $ is the ratio of the minimum mean coverage in windows on either side of the breakpoint to the genome-wide mean coverage for molecules in the region. A value near $ 1 $ indicates continuity; lower values indicate potential discontinuity.\n- Support fraction $ f_s = n_s / n_t $, where $ n_s $ is the number of molecules that support the breakpoint, and $ n_t $ is the number of molecules spanning the region. Express $ f_s $ as a decimal (not a percentage).\n- Breakpoint positional variance $ \\sigma_b $ measured in base pairs (bp) across supporting molecules. Express $ \\sigma_b $ in base pairs.\n- Orientation consistency score $ s_o = n_{\\text{match}} / n_s $, where $ n_{\\text{match}} $ is the number of supporting molecules whose orientation matches a mechanistically plausible orientation for a single structural variant class under a linear reference. If $ n_s = 0 $, define $ s_o = 0 $.\n\nClassification rule parameterized by thresholds:\n- Classify a candidate as a genuine structural variant if and only if all of the following hold simultaneously:\n  - $ s_c \\ge T_c $\n  - $ f_s \\ge T_s $\n  - $ \\sigma_b \\le T_b $ (expressed in bp)\n  - $ s_o \\ge T_o $\n- Otherwise, classify the candidate as a chimeric long read.\n\nThreshold selection protocol:\n- Consider the candidate threshold grids:\n  - $ T_c \\in \\{ 0.70, 0.80, 0.90 \\} $\n  - $ T_s \\in \\{ 0.20, 0.30, 0.40 \\} $\n  - $ T_b \\in \\{ 10, 20, 50, 60 \\} $ (bp)\n  - $ T_o \\in \\{ 0.60, 0.70, 0.80 \\} $\n- For each combination $ (T_c, T_s, T_b, T_o) $, classify each training case, compute sensitivity and specificity, then compute $ J $.\n- Select the threshold combination that maximizes $ J $. In case of ties in $ J $, prefer the combination with larger specificity. If still tied, prefer larger $ T_c $, larger $ T_s $, larger $ T_o $, and smaller $ T_b $.\n\nTest suite:\n- Training cases (each case is a tuple $ (s_c, n_s, n_t, \\sigma_b, n_{\\text{match}}, n_{\\text{mismatch}}, \\text{label}) $, where label is $ 1 $ for a genuine structural variant and $ 0 $ for a chimera):\n  1. $ (0.95, 6, 10, 12, 6, 0, 1) $\n  2. $ (0.90, 4, 12, 18, 4, 0, 1) $\n  3. $ (0.65, 1, 15, 100, 0, 1, 0) $\n  4. $ (0.75, 2, 20, 80, 1, 1, 0) $\n  5. $ (0.82, 3, 8, 25, 3, 0, 1) $\n  6. $ (0.88, 9, 30, 55, 9, 0, 1) $\n- Evaluation cases (each case is an unlabeled tuple $ (s_c, n_s, n_t, \\sigma_b, n_{\\text{match}}, n_{\\text{mismatch}}) $):\n  1. $ (0.80, 3, 10, 20, 3, 0) $\n  2. $ (0.92, 5, 25, 15, 4, 1) $\n  3. $ (0.93, 6, 18, 12, 3, 3) $\n  4. $ (0.87, 5, 14, 60, 5, 0) $\n  5. $ (0.85, 0, 22, 200, 0, 0) $\n  6. $ (0.90, 3, 10, 50, 2, 1) $\n\nRequired outputs and format:\n- Your program must compute the optimal thresholds $ (T_c, T_s, T_b, T_o) $ using the training cases and the tie-breaking rules above.\n- Then, using the optimal thresholds, classify each evaluation case as genuine structural variant ($ \\text{True} $) or chimeric long read ($ \\text{False} $).\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n  - $ T_c $, $ T_s $, $ T_b $, $ T_o $ (floats for $ T_c $, $ T_s $, $ T_o $, and integer for $ T_b $),\n  - followed by six booleans for the six evaluation cases in the order listed above.\nFor example, the output should look like $ [T_c,T_s,T_b,T_o,\\text{eval}_1,\\text{eval}_2,\\text{eval}_3,\\text{eval}_4,\\text{eval}_5,\\text{eval}_6] $.\n\nNo external input is allowed. All computations must be performed within the program using the specified test suite.", "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of genomic structural variant detection, well-posed with a clear objective and a deterministic procedure for achieving it, and presented in an objective, formal manner. All data and rules required for a unique solution are provided, and there are no internal contradictions or factual inaccuracies.\n\nThe solution proceeds in three principal stages: first, the extraction and calculation of defined features for each candidate breakpoint; second, a systematic grid search to determine the optimal set of classification thresholds; and third, the application of these thresholds to classify the evaluation cases.\n\n**1. Feature Extraction from Observational Data**\n\nFor each candidate breakpoint, characterized by the tuple $(s_c, n_s, n_t, \\sigma_b, n_{\\text{match}}, n_{\\text{mismatch}})$, we must compute a vector of four features: coverage continuity score ($s_c$), support fraction ($f_s$), breakpoint positional variance ($\\sigma_b$), and orientation consistency score ($s_o$). The problem statement provides $s_c$ and $\\sigma_b$ directly. The remaining two features are calculated as follows:\n\n- The support fraction, $f_s$, is the ratio of the number of molecules supporting the breakpoint, $n_s$, to the total number of molecules spanning the region, $n_t$.\n$$f_s = \\frac{n_s}{n_t}$$\n\n- The orientation consistency score, $s_o$, is the ratio of supporting molecules with a concordant orientation, $n_{\\text{match}}$, to the total number of supporting molecules, $n_s$. By definition, if $n_s = 0$, then $s_o = 0$.\n$$s_o = \\begin{cases} \\frac{n_{\\text{match}}}{n_s} & \\text{if } n_s > 0 \\\\ 0 & \\text{if } n_s = 0 \\end{cases}$$\n\nThis calculation is applied to all $6$ training cases and $6$ evaluation cases to produce a standardized feature set for analysis. For the training data, we have $4$ positive instances (genuine structural variants, label $1$) and $2$ negative instances (chimeras, label $0$).\n\n**2. Optimal Threshold Selection**\n\nThe core of the task is to identify a set of thresholds $(T_c, T_s, T_b, T_o)$ that optimally separates genuine structural variants from artifacts. A candidate is classified as a genuine variant if and only if all four of the following conditions are met simultaneously:\n- $s_c \\ge T_c$\n- $f_s \\ge T_s$\n- $\\sigma_b \\le T_b$\n- $s_o \\ge T_o$\n\nThe optimization criterion is the maximization of Youden's $J$ statistic, defined as:\n$$J = \\text{sensitivity} + \\text{specificity} - 1$$\nwhere sensitivity is $\\mathrm{TP} / (\\mathrm{TP} + \\mathrm{FN})$ and specificity is $\\mathrm{TN} / (\\mathrm{TN} + \\mathrm{FP})$. Here, $\\mathrm{TP}$, $\\mathrm{FN}$, $\\mathrm{TN}$, and $\\mathrm{FP}$ represent true positives, false negatives, true negatives, and false positives, respectively.\n\nA grid search is performed over all possible combinations of thresholds from the provided sets:\n- $T_c \\in \\{ 0.70, 0.80, 0.90 \\}$\n- $T_s \\in \\{ 0.20, 0.30, 0.40 \\}$\n- $T_b \\in \\{ 10, 20, 50, 60 \\}$ bp\n- $T_o \\in \\{ 0.60, 0.70, 0.80 \\}$\n\nFor each of the $3 \\times 3 \\times 4 \\times 3 = 108$ threshold combinations, the training data is classified, and the resulting values of $J$ and specificity are computed. The optimal threshold set is selected based on a strict, hierarchical tie-breaking rule:\n1. Maximize Youden's $J$ statistic.\n2. In case of a tie in $J$, maximize specificity.\n3. If a tie persists, select the combination with the largest $T_c$.\n4. If still tied, select the combination with the largest $T_s$.\n5. If still tied, select the combination with the largest $T_o$.\n6. Finally, if a tie remains, select the combination with the smallest $T_b$.\n\nThis deterministic procedure guarantees a single, unique optimal threshold combination. Our analysis reveals that multiple threshold combinations achieve a perfect score of $J=1.0$ (sensitivity=$1.0$, specificity=$1.0$). Applying the tie-breaking rules to this set of optimal candidates yields the unique threshold set $(T_c, T_s, T_b, T_o) = (0.80, 0.30, 60, 0.80)$.\n\n**3. Classification of Evaluation Cases**\n\nWith the optimal thresholds $(T_c^* = 0.80, T_s^* = 0.30, T_b^* = 60, T_o^* = 0.80)$ determined, we proceed to classify the $6$ evaluation cases. For each case, we first compute its feature vector $(s_c, f_s, \\sigma_b, s_o)$ and then apply the classification rule: the case is classified as a genuine structural variant (True) if $s_c \\ge 0.80$, $f_s \\ge 0.30$, $\\sigma_b \\le 60$, and $s_o \\ge 0.80$. Otherwise, it is classified as a chimeric read (False). This yields a definitive classification for each of the unlabeled evaluation cases. The final output aggregates the optimal thresholds and the classification results for the evaluation set into a single formatted list.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    This function implements the entire workflow:\n    1. Processes training data to find optimal classification thresholds.\n    2. Processes evaluation data using these thresholds.\n    3. Prints the results in the specified format.\n    \"\"\"\n    \n    # Step 1: Define the Givens from the problem statement.\n    \n    # Training cases: (sc, ns, nt, sigma_b, n_match, n_mismatch, label)\n    training_cases_raw = [\n        (0.95, 6, 10, 12, 6, 0, 1),\n        (0.90, 4, 12, 18, 4, 0, 1),\n        (0.65, 1, 15, 100, 0, 1, 0),\n        (0.75, 2, 20, 80, 1, 1, 0),\n        (0.82, 3, 8, 25, 3, 0, 1),\n        (0.88, 9, 30, 55, 9, 0, 1),\n    ]\n\n    # Evaluation cases: (sc, ns, nt, sigma_b, n_match, n_mismatch)\n    evaluation_cases_raw = [\n        (0.80, 3, 10, 20, 3, 0),\n        (0.92, 5, 25, 15, 4, 1),\n        (0.93, 6, 18, 12, 3, 3),\n        (0.87, 5, 14, 60, 5, 0),\n        (0.85, 0, 22, 200, 0, 0),\n        (0.90, 3, 10, 50, 2, 1),\n    ]\n\n    # Threshold grids\n    T_c_grid = [0.70, 0.80, 0.90]\n    T_s_grid = [0.20, 0.30, 0.40]\n    T_b_grid = [10, 20, 50, 60]\n    T_o_grid = [0.60, 0.70, 0.80]\n\n    # Step 2: Feature Extraction\n    \n    def calculate_features(raw_case):\n        \"\"\"Calculates the four features for a given raw data case.\"\"\"\n        s_c, n_s, n_t, sigma_b, n_match, _ = raw_case[:6]\n        \n        # Support fraction f_s\n        f_s = n_s / n_t if n_t > 0 else 0.0\n        \n        # Orientation consistency score s_o\n        s_o = n_match / n_s if n_s > 0 else 0.0\n        \n        return (s_c, f_s, sigma_b, s_o)\n\n    training_data = []\n    for case in training_cases_raw:\n        features = calculate_features(case)\n        label = case[6]\n        training_data.append({'features': features, 'label': label})\n\n    # Count total positive and negative cases in training set\n    P = sum(1 for item in training_data if item['label'] == 1)\n    N = sum(1 for item in training_data if item['label'] == 0)\n\n    # Step 3: Threshold Optimization via Grid Search\n    \n    best_thresholds = None\n    # Initialize best_score_tuple for lexicographical comparison based on tie-breaking rules\n    # (J, specificity, T_c, T_s, T_o, -T_b)\n    best_score_tuple = (-np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf)\n\n    for T_c in T_c_grid:\n        for T_s in T_s_grid:\n            for T_b in T_b_grid:\n                for T_o in T_o_grid:\n                    \n                    TP, FP, TN, FN = 0, 0, 0, 0\n                    \n                    for item in training_data:\n                        s_c, f_s, sigma_b, s_o = item['features']\n                        label = item['label']\n                        \n                        # Apply classification rule\n                        prediction = (\n                            s_c >= T_c and\n                            f_s >= T_s and\n                            sigma_b = T_b and\n                            s_o >= T_o\n                        )\n                        \n                        # Update confusion matrix\n                        if prediction and label == 1:\n                            TP += 1\n                        elif not prediction and label == 1:\n                            FN += 1\n                        elif prediction and label == 0:\n                            FP += 1\n                        elif not prediction and label == 0:\n                            TN += 1\n                    \n                    # Calculate performance metrics\n                    sensitivity = TP / P if P > 0 else 0.0\n                    specificity = TN / N if N > 0 else 0.0\n                    j_statistic = sensitivity + specificity - 1.0\n                    \n                    # Apply tie-breaking rules using lexicographical comparison\n                    current_thresholds = (T_c, T_s, T_b, T_o)\n                    current_score_tuple = (j_statistic, specificity, T_c, T_s, T_o, -T_b)\n                    \n                    if current_score_tuple > best_score_tuple:\n                        best_score_tuple = current_score_tuple\n                        best_thresholds = current_thresholds\n\n    # Step 4: Classification of Evaluation Cases\n    \n    optimal_Tc, optimal_Ts, optimal_Tb, optimal_To = best_thresholds\n    \n    evaluation_results = []\n    for case in evaluation_cases_raw:\n        s_c, f_s, sigma_b, s_o = calculate_features(case)\n        \n        # Apply classification rule with optimal thresholds\n        is_sv = (\n            s_c >= optimal_Tc and\n            f_s >= optimal_Ts and\n            sigma_b = optimal_Tb and\n            s_o >= optimal_To\n        )\n        evaluation_results.append(is_sv)\n\n    # Step 5: Format and Print the Final Output\n    \n    final_output_list = [\n        optimal_Tc,\n        optimal_Ts,\n        optimal_Tb,\n        optimal_To\n    ] + evaluation_results\n    \n    # Format the list into the required string format\n    output_str = f\"[{','.join(map(str, final_output_list))}]\"\n    \n    print(output_str)\n\nsolve()\n```", "id": "4328159"}]}