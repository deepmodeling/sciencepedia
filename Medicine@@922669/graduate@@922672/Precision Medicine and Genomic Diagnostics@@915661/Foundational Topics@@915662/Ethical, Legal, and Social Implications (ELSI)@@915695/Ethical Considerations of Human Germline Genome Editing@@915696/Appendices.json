{"hands_on_practices": [{"introduction": "Before any new medical technology, especially one as profound as germline editing, is used in humans, we must establish a high degree of confidence in its safety. This practice [@problem_id:4337748] translates the precautionary principle into a quantitative framework using Bayesian statistics. You will determine the minimum number of successful preclinical experiments required to be confident that the risk of severe errors is acceptably low, providing a concrete example of how evidence standards can be rigorously defined before first-in-human trials.", "problem": "A research consortium planning first-in-human germline genome editing seeks to set a preclinical evidence threshold grounded in Bayesian decision-making to honor the biomedical ethics principles of nonmaleficence and the precautionary principle. Define the probability of a severe off-target genomic alteration per standardized edit as $p \\in [0,1]$. Ethical safety for first-in-human trials is operationalized as $p \\leq \\theta$, with $\\theta = 0.01$. Prior to any human use, the consortium mandates that the Bayesian posterior probability of safety, $\\Pr(p \\leq \\theta \\mid \\text{data})$, must exceed $0.95$.\n\nAssume preclinical edits are conducted in a validated high-fidelity in vitro model and that:\n- Each edit is an independent Bernoulli trial with probability $p$ of a severe off-target event that would be clinically significant if it occurred in humans.\n- Severe off-target events are detected without error under the protocol.\n- The prior on $p$ is $\\text{Beta}(\\alpha_{0}, \\beta_{0})$ with $\\alpha_{0} = 1$ and $\\beta_{0} = 1$ to reflect prior ignorance over $[0,1]$.\n\nLet $n$ denote the number of independent preclinical edits conducted and $k$ the number of observed severe off-target events. Under the ethical policy, progression to first-in-human trials requires that $\\Pr(p \\leq \\theta \\mid k, n) > 0.95$. Suppose the preclinical program proceeds until no severe off-target events have been observed, i.e., $k = 0$. Derive, from first principles, the minimal integer $n$ such that the policy criterion is satisfied for $\\theta = 0.01$ and report that minimal $n$ as a single number. No rounding is required beyond choosing the minimal integer that achieves the criterion. The answer is unitless.", "solution": "The problem requires the determination of the minimum number of independent preclinical edits, $n$, that must be conducted without any observed severe off-target events ($k=0$) to satisfy a specific ethical safety criterion. This criterion is formulated within a Bayesian statistical framework.\n\n### Step 1: Problem Formulation and Model Specification\nThe problem defines the unknown probability of a severe off-target event as $p$. The data-generating process is a series of $n$ independent Bernoulli trials, where each trial results in an off-target event with probability $p$. The number of observed events, $k$, in $n$ trials follows a Binomial distribution, with the likelihood function given by:\n$$ L(p \\mid k, n) = \\binom{n}{k} p^k (1-p)^{n-k} $$\nThe prior belief about the parameter $p$ is modeled by a Beta distribution, $p \\sim \\text{Beta}(\\alpha_0, \\beta_0)$. The probability density function (PDF) of the prior is:\n$$ f(p; \\alpha_0, \\beta_0) = \\frac{p^{\\alpha_0-1}(1-p)^{\\beta_0-1}}{B(\\alpha_0, \\beta_0)} $$\nwhere $B(\\alpha_0, \\beta_0)$ is the Beta function. We are given the prior parameters $\\alpha_0=1$ and $\\beta_0=1$, which corresponds to a uniform distribution on the interval $[0,1]$, expressing maximal prior uncertainty about $p$.\n\n### Step 2: Derivation of the Posterior Distribution\nThe Beta distribution is a conjugate prior for the Bernoulli/Binomial likelihood. This means that the posterior distribution of $p$, given the data $(k, n)$, is also a Beta distribution. The posterior PDF is proportional to the product of the prior PDF and the likelihood function:\n$$ f(p \\mid k, n) \\propto L(p \\mid k, n) \\times f(p; \\alpha_0, \\beta_0) $$\n$$ f(p \\mid k, n) \\propto p^k (1-p)^{n-k} \\times p^{\\alpha_0-1}(1-p)^{\\beta_0-1} $$\n$$ f(p \\mid k, n) \\propto p^{\\alpha_0+k-1} (1-p)^{\\beta_0+n-k-1} $$\nThis is the kernel of a Beta distribution with updated parameters $\\alpha_{\\text{post}} = \\alpha_0 + k$ and $\\beta_{\\text{post}} = \\beta_0 + n - k$. Thus, the posterior distribution is:\n$$ p \\mid k,n \\sim \\text{Beta}(\\alpha_0 + k, \\beta_0 + n - k) $$\nThe problem specifies that no severe off-target events are observed, so $k=0$. Substituting the given values $\\alpha_0=1$, $\\beta_0=1$, and $k=0$, the posterior parameters become:\n$$ \\alpha_{\\text{post}} = 1 + 0 = 1 $$\n$$ \\beta_{\\text{post}} = 1 + n - 0 = n + 1 $$\nTherefore, the posterior distribution of $p$ is $p \\mid k=0, n \\sim \\text{Beta}(1, n+1)$.\n\n### Step 3: Application of the Ethical Policy Criterion\nThe ethical policy requires that the posterior probability of safety, defined as $p \\leq \\theta$, must be greater than $0.95$. The safety threshold is given as $\\theta = 0.01$. Mathematically, this condition is:\n$$ \\Pr(p \\leq \\theta \\mid k=0, n) > 0.95 $$\nThis probability is the cumulative distribution function (CDF) of the posterior distribution, $\\text{Beta}(1, n+1)$, evaluated at $p=\\theta$. The CDF of a Beta distribution $\\text{Beta}(\\alpha, \\beta)$ is given by the integral:\n$$ F(x; \\alpha, \\beta) = \\int_0^x \\frac{t^{\\alpha-1}(1-t)^{\\beta-1}}{B(\\alpha, \\beta)} dt $$\nFor our posterior distribution $\\text{Beta}(1, n+1)$ and threshold $\\theta=0.01$, this becomes:\n$$ \\Pr(p \\leq 0.01 \\mid k=0, n) = \\int_0^{0.01} \\frac{t^{1-1}(1-t)^{(n+1)-1}}{B(1, n+1)} dt = \\frac{1}{B(1, n+1)} \\int_0^{0.01} (1-t)^n dt $$\nFirst, we evaluate the Beta function $B(1, n+1) = \\frac{\\Gamma(1)\\Gamma(n+1)}{\\Gamma(1+n+1)} = \\frac{0! \\cdot n!}{(n+1)!} = \\frac{1}{n+1}$, where $\\Gamma$ is the Gamma function.\nNext, we evaluate the integral:\n$$ \\int_0^{0.01} (1-t)^n dt = \\left[ -\\frac{(1-t)^{n+1}}{n+1} \\right]_0^{0.01} = \\left(-\\frac{(1-0.01)^{n+1}}{n+1}\\right) - \\left(-\\frac{(1-0)^{n+1}}{n+1}\\right) = \\frac{1 - (0.99)^{n+1}}{n+1} $$\nCombining these results, the posterior probability is:\n$$ \\Pr(p \\leq 0.01 \\mid k=0, n) = (n+1) \\times \\left( \\frac{1 - (0.99)^{n+1}}{n+1} \\right) = 1 - (0.99)^{n+1} $$\n\n### Step 4: Solving for the Minimal Number of Edits, n\nWe must find the minimal integer $n$ that satisfies the inequality derived from the policy criterion:\n$$ 1 - (0.99)^{n+1} > 0.95 $$\nRearranging the inequality:\n$$ 0.05 > (0.99)^{n+1} $$\nTo solve for $n$, we take the natural logarithm of both sides. Since the natural logarithm is a strictly increasing function, the direction of the inequality is preserved.\n$$ \\ln(0.05) > \\ln\\left((0.99)^{n+1}\\right) $$\n$$ \\ln(0.05) > (n+1) \\ln(0.99) $$\nThe value of $\\ln(0.99)$ is negative because its argument is less than $1$. Therefore, dividing by $\\ln(0.99)$ reverses the direction of the inequality:\n$$ \\frac{\\ln(0.05)}{\\ln(0.99)} < n+1 $$\nSolving for $n$:\n$$ n > \\frac{\\ln(0.05)}{\\ln(0.99)} - 1 $$\nNow, we compute the numerical value of the right-hand side:\n$$ \\frac{\\ln(0.05)}{\\ln(0.99)} \\approx \\frac{-2.99573}{-0.01005} \\approx 298.08 $$\nSo the inequality becomes:\n$$ n > 298.08 - 1 $$\n$$ n > 297.08 $$\nSince $n$ must be an integer representing the number of edits, the minimal integer $n$ that satisfies this condition is $298$.\nThis means that a minimum of $298$ preclinical edits must be performed with zero observed severe off-target events to meet the consortium's ethical standard for proceeding to first-in-human trials.", "answer": "$$\\boxed{298}$$", "id": "4337748"}, {"introduction": "Once a technology is deemed ready for clinical consideration, each proposed intervention must be weighed on its own merits. This exercise [@problem_id:4337772] places you in the role of an ethics committee member applying a quantitative proportionality test to a specific germline editing proposal. By calculating and comparing the expected harm from potential off-target effects to the expected therapeutic benefit, you will practice a core skill in biomedical ethics: operationalizing principles like nonmaleficence into a structured, evidence-based decision.", "problem": "A clinical ethics committee is evaluating the permissibility of a proposed human germline genome editing protocol intended to avert a high-penetrance, early-onset monogenic disease. In the committeeâ€™s decision framework for precision medicine and genomic diagnostics, the weak precautionary principle is operationalized via a proportionality test grounded in expected value reasoning: the expected disvalue of reasonably foreseeable severe harms must be proportionate to the expected therapeutic benefit. Concretely, the committee construes proportionality to require that the expected disvalue of severe off-target effects does not exceed a fraction $\\lambda$ of the expected benefit, where $\\lambda \\in (0,1]$ is a policy parameter reflecting the strictness of weak precaution.\n\nAssume the following ethically quantified parameters, in commensurable ethical utility units: the estimated probability of a severe off-target event per embryo is $p=0.01$, the disvalue magnitude of such a severe harm is $M=100$, and the expected therapeutic benefit of preventing the target disease for the edited embryo is $B=4$. A draft policy proposes a weak-precaution proportionality threshold of $\\lambda_{w}=0.20$.\n\nUsing only the core definitions of expected value and proportionality as described, derive the minimal proportionality coefficient $\\lambda_{\\min}$ that would render the intervention proportionate under the weak precaution test for the given $p$, $M$, and $B$. Report the numerical value of $\\lambda_{\\min}$, rounded to four significant figures, as a unitless ratio. Do not include any units in your final boxed answer.", "solution": "The core of the problem lies in translating the committee's proportionality test into a mathematical expression and solving for the required parameter. The given parameters are:\n- Probability of a severe off-target event, $p = 0.01$.\n- Disvalue magnitude of a severe harm, $M = 100$.\n- Expected therapeutic benefit, $B = 4$.\n\nFirst, we must calculate the expected disvalue of severe off-target effects. The expected value of an event is its probability multiplied by its value or disvalue. Let $D$ represent the expected disvalue.\n$$D = p \\times M$$\n\nThe proportionality test, as stated, requires that the expected disvalue $D$ does not exceed a fraction $\\lambda$ of the expected benefit $B$. This is formulated as the following inequality:\n$$D \\le \\lambda B$$\n\nSubstituting the expression for $D$, we have:\n$$pM \\le \\lambda B$$\n\nThe problem asks for the minimal proportionality coefficient, $\\lambda_{\\min}$, that would render the intervention proportionate. This means we are looking for the smallest value of $\\lambda$ for which the inequality is satisfied. The set of all values of $\\lambda$ for which the intervention is proportionate is given by rearranging the inequality:\n$$\\lambda \\ge \\frac{pM}{B}$$\n\nThe minimal value, $\\lambda_{\\min}$, in this set is the value at the boundary of the inequality, where equality holds:\n$$\\lambda_{\\min} = \\frac{pM}{B}$$\n\nNow, we substitute the given numerical values into this expression:\n$$\\lambda_{\\min} = \\frac{0.01 \\times 100}{4}$$\n$$\\lambda_{\\min} = \\frac{1}{4}$$\n$$\\lambda_{\\min} = 0.25$$\n\nThe problem requires the numerical value to be reported rounded to four significant figures. The exact value is $0.25$. To express this with a precision of four significant figures, we append trailing zeros.\n$$\\lambda_{\\min} = 0.2500$$\n\nThis value, $\\lambda_{\\min}=0.2500$, is the minimum threshold for the proportionality parameter $\\lambda$ for the intervention to be considered proportionate under the specified framework. The contextual information that a draft policy proposes $\\lambda_{w}=0.20$ is notable because our calculated minimum required value is greater than the proposed value ($0.2500 > 0.20$). This implies that under the proposed policy, this specific intervention would be deemed disproportionate and impermissible. This confirms the consistency of the conceptual framework.", "answer": "$$\\boxed{0.2500}$$", "id": "4337772"}, {"introduction": "The ethical analysis of germline editing must extend beyond the individual to encompass its heritable nature and potential long-term effects on the human gene pool. In this final practice [@problem_id:4337737], you will use the principles of population genetics to model the multi-generational impact of a large-scale editing program. This exercise will allow you to explore how interventions can alter allele frequencies over time and calculate the effort required to achieve specific public health goals, highlighting the profound societal responsibilities associated with this technology.", "problem": "A health authority is considering a heritable intervention program in which embryos at risk for a single, autosomal, deleterious allele are screened using genomic diagnostics and a constant fraction $\\,\\alpha\\,$ of the embryos that carry the allele receive germline genome editing that perfectly converts the deleterious allele to the wild-type allele without mosaicism. Assume a very large, randomly mating population with no migration, no selection after birth, and negligible linkage. Let $\\,q_t\\,$ denote the population allele frequency of the deleterious allele immediately prior to embryo screening in generation $\\,t\\,$. Let $\\,\\mu\\,$ denote the per-generation de novo mutation rate from wild-type to the deleterious allele, acting between generations $\\,t\\,$ and $\\,t+1\\,$ on wild-type alleles. Assume perfect detection of carrier embryos before editing and that editing, when applied, fully corrects the deleterious allele in those embryos.\n\nStarting only from population genetic fundamentals (random mating implies alleles are randomly sampled and, absent forces, allele frequencies remain constant across generations; de novo mutation converts a fraction $\\,\\mu\\,$ of wild-type alleles to the deleterious allele each generation; and editing reduces the frequency of the deleterious allele among embryos actually edited), first derive the first-order linear recurrence for $\\,q_{t+1}\\,$ as a function of $\\,q_t\\,$, $\\,\\alpha\\,$, and $\\,\\mu\\,$.\n\nIn light of ethical commitments to minimize intervention intensity while still achieving public health goals, suppose the mutation rate is negligible on the implementation timescale, so set $\\,\\mu=0\\,$ for planning. The authority sets a measurable target to reduce the deleterious allele frequency from an initial $\\,q_0\\,$ to at most $\\,q_f\\,$ within exactly $\\,T\\,$ nonoverlapping generations, where $\\,0<q_f<q_0\\leq 1\\,$ and $\\,T\\in\\mathbb{N}\\,$. Under the above assumptions and with constant $\\,\\alpha\\,$ across generations, determine the exact analytic expression for the smallest constant fraction $\\,\\alpha\\,$ of carrier embryos that must be edited each generation to meet the target. Express your final answer as a closed-form expression in terms of $\\,q_0\\,$, $\\,q_f\\,$, and $\\,T\\,$. Do not round.", "solution": "The problem asks for two results: first, a general recurrence relation for the deleterious allele frequency, and second, the minimum intervention level $\\alpha$ required to meet a specific target under simplified conditions.\n\n### Part 1: Derivation of the Recurrence Relation for $q_{t+1}$\n\nLet $q_t$ be the frequency of the deleterious allele (let's call it $A$) in the population at generation $t$, just before embryo screening. The frequency of the wild-type allele ($a$) is $p_t = 1 - q_t$. Assuming the population is in Hardy-Weinberg equilibrium due to random mating, the genotype frequencies at fertilization are:\n- Homozygous deleterious ($AA$): $f(AA) = q_t^2$\n- Heterozygous ($Aa$): $f(Aa) = 2p_t q_t$\n- Homozygous wild-type ($aa$): $f(aa) = p_t^2$\n\nThe intervention consists of editing a constant fraction $\\alpha$ of \"embryos that carry the allele\". These are the $AA$ and $Aa$ genotypes. We interpret this to mean that any specific carrier embryo has a probability $\\alpha$ of being selected for editing, and if selected, the editing process perfectly converts all its $A$ alleles to $a$ alleles.\n\nLet's calculate the genotype frequencies after this editing step.\nA fraction $\\alpha$ of $AA$ embryos are edited, becoming $aa$. The remaining fraction, $1-\\alpha$, stays as $AA$. The new frequency of $AA$, denoted $f'(AA)$, is:\n$$f'(AA) = (1-\\alpha) f(AA) = (1-\\alpha)q_t^2$$\nSimilarly, a fraction $\\alpha$ of $Aa$ embryos are edited. Since editing is perfect, they also become $aa$. The remaining fraction, $1-\\alpha$, stays as $Aa$. The new frequency of $Aa$, denoted $f'(Aa)$, is:\n$$f'(Aa) = (1-\\alpha) f(Aa) = (1-\\alpha)2p_t q_t$$\nThe original $aa$ embryos are untouched. The embryos converted from $AA$ and $Aa$ are added to this pool. The new frequency of $aa$, $f'(aa)$, is:\n$$f'(aa) = f(aa) + \\alpha f(AA) + \\alpha f(Aa) = p_t^2 + \\alpha q_t^2 + \\alpha 2p_t q_t$$\nThe sum of new frequencies is $f'(AA) + f'(Aa) + f'(aa) = (1-\\alpha)q_t^2 + (1-\\alpha)2p_t q_t + p_t^2 + \\alpha q_t^2 + \\alpha 2p_t q_t = q_t^2 + 2p_t q_t + p_t^2 = (q_t+p_t)^2 = 1^2 = 1$, which confirms the calculation is consistent.\n\nNow, we find the frequency of the deleterious allele $A$ immediately after editing, let's call it $q_t'$. This is calculated from the new genotype frequencies:\n$$q_t' = f'(AA) + \\frac{1}{2}f'(Aa)$$\n$$q_t' = (1-\\alpha)q_t^2 + \\frac{1}{2}(1-\\alpha)2p_t q_t$$\n$$q_t' = (1-\\alpha)q_t^2 + (1-\\alpha)p_t q_t$$\nFactoring out $(1-\\alpha)$ and $q_t$:\n$$q_t' = (1-\\alpha)q_t (q_t + p_t)$$\nSince $q_t + p_t = 1$, this simplifies to:\n$$q_t' = (1-\\alpha)q_t$$\nThis is a linear relationship, as suggested by the problem statement. The frequency of the wild-type allele after editing is $p_t' = 1 - q_t' = 1 - (1-\\alpha)q_t$.\n\nThe second process is de novo mutation, which occurs at a rate $\\mu$ from the wild-type allele $a$ to the deleterious allele $A$. This happens to the post-editing allele pool before the next generation's allele frequency is established. The frequency of allele $A$ in generation $t+1$, denoted $q_{t+1}$, is the sum of the deleterious alleles that survived editing plus the new deleterious alleles created by mutation from wild-type alleles.\n$$q_{t+1} = q_t' + \\mu p_t'$$\nSubstituting the expressions for $q_t'$ and $p_t'$:\n$$q_{t+1} = (1-\\alpha)q_t + \\mu (1 - (1-\\alpha)q_t)$$\n$$q_{t+1} = (1-\\alpha)q_t + \\mu - \\mu(1-\\alpha)q_t$$\nGrouping terms with $q_t$:\n$$q_{t+1} = [(1-\\alpha) - \\mu(1-\\alpha)]q_t + \\mu$$\n$$q_{t+1} = (1-\\alpha)(1-\\mu)q_t + \\mu$$\nThis is the required first-order linear recurrence relation for $q_{t+1}$.\n\n### Part 2: Determination of the Smallest Intervention Fraction $\\alpha$\n\nFor the second part of the problem, we are instructed to set the mutation rate to zero, i.e., $\\mu=0$. The recurrence relation simplifies considerably:\n$$q_{t+1} = (1-\\alpha)(1-0)q_t + 0$$\n$$q_{t+1} = (1-\\alpha)q_t$$\nThis is a standard geometric decay model. We can express the allele frequency at any generation $t$ in terms of the initial frequency $q_0$ by applying the recurrence iteratively:\n$$q_1 = (1-\\alpha)q_0$$\n$$q_2 = (1-\\alpha)q_1 = (1-\\alpha)^2 q_0$$\nBy induction, the frequency at generation $T$ is:\n$$q_T = (1-\\alpha)^T q_0$$\nThe public health target is to reduce the allele frequency from $q_0$ to at most $q_f$ within exactly $T$ generations. This translates to the mathematical condition:\n$$q_T \\leq q_f$$\nSubstituting our expression for $q_T$:\n$$(1-\\alpha)^T q_0 \\leq q_f$$\nWe must solve for $\\alpha$. Since $q_0 > 0$, we can divide by $q_0$:\n$$(1-\\alpha)^T \\leq \\frac{q_f}{q_0}$$\nGiven that $T \\in \\mathbb{N}$ ($T \\geq 1$), and that $0 \\leq \\alpha \\leq 1$ and $0 < q_f < q_0$, both sides of the inequality are positive. We can take the $T$-th root of both sides without changing the direction of the inequality:\n$$1-\\alpha \\leq \\left(\\frac{q_f}{q_0}\\right)^{\\frac{1}{T}}$$\nNow, we isolate $\\alpha$:\n$$-\\alpha \\leq \\left(\\frac{q_f}{q_0}\\right)^{\\frac{1}{T}} - 1$$\nMultiplying by $-1$ reverses the inequality:\n$$\\alpha \\geq 1 - \\left(\\frac{q_f}{q_0}\\right)^{\\frac{1}{T}}$$\nThe problem asks for the smallest constant fraction $\\alpha$ that will meet the target. This minimum value is achieved when the equality holds. Any smaller value of $\\alpha$ would result in $q_T > q_f$, failing to meet the goal. Therefore, the exact smallest value for $\\alpha$ is:\n$$\\alpha = 1 - \\left(\\frac{q_f}{q_0}\\right)^{\\frac{1}{T}}$$\nThis expression is in terms of the given parameters $q_0$, $q_f$, and $T$.", "answer": "$$\n\\boxed{1 - \\left(\\frac{q_f}{q_0}\\right)^{\\frac{1}{T}}}\n$$", "id": "4337737"}]}