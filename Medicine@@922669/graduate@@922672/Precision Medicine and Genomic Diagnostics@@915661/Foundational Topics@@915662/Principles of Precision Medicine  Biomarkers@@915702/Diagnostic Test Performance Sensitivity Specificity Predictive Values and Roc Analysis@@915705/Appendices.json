{"hands_on_practices": [{"introduction": "Mastering the evaluation of diagnostic tests begins with a firm grasp of the fundamental metrics. This first exercise grounds you in the core concepts of sensitivity and specificity by having you calculate them directly from a standard confusion matrix. More importantly, it challenges you to think critically about the context of the evaluation, specifically how a case-control study design allows for the direct estimation of these metrics independent of the disease's prevalence in the general population [@problem_id:4332588].", "problem": "A targeted next-generation sequencing assay is evaluated for detecting a pathogenic variant in a precision oncology setting. In a multi-center case-control evaluation, samples are classified by the assay as positive or negative, and a gold-standard orthogonal method determines the true variant status. Let the true positive count be $TP = 48$, false negative count be $FN = 12$, false positive count be $FP = 18$, and true negative count be $TN = 122$. Using only the foundational definitions of conditional probability and error rates in binary classification, compute the following four performance characteristics: sensitivity, specificity, false positive rate, and false negative rate. Then, using a first-principles argument about conditional probabilities under retrospective (case-control) sampling, determine which of these four quantities are invariant to disease prevalence under case-control sampling.\n\nReport the final answer as a single row matrix in the order $\\bigl(\\text{sensitivity},\\ \\text{specificity},\\ \\text{false positive rate},\\ \\text{false negative rate},\\ I_{\\text{sensitivity}},\\ I_{\\text{specificity}},\\ I_{\\text{false positive rate}},\\ I_{\\text{false negative rate}}\\bigr)$, where $I_{\\cdot}$ is $1$ if the quantity is prevalence-invariant under case-control sampling and $0$ otherwise. Express the four rates as exact reduced fractions. No rounding is permitted. The invariance indicators must be reported as exact integers $0$ or $1$.", "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and self-contained. All data required for the calculations are provided, and the concepts are fundamental to statistics and clinical diagnostics. The problem is therefore valid.\n\nLet $D^+$ be the event that an individual has the pathogenic variant (is a case), and $D^-$ be the event that an individual does not have the variant (is a control). Let $T^+$ be the event that the assay result is positive, and $T^-$ be the event that the assay result is negative.\n\nThe provided data are the counts for the four possible outcomes in a binary classification confusion matrix:\n- True Positives ($TP$): The number of individuals with the variant who test positive. $TP = 48$.\n- False Negatives ($FN$): The number of individuals with the variant who test negative. $FN = 12$.\n- False Positives ($FP$): The number of individuals without the variant who test positive. $FP = 18$.\n- True Negatives ($TN$): The number of individuals without the variant who test negative. $TN = 122$.\n\nFrom these counts, we can determine the total number of cases and controls in the study:\n- Total number of cases (individuals with the variant): $P = TP + FN = 48 + 12 = 60$.\n- Total number of controls (individuals without the variant): $N = FP + TN = 18 + 122 = 140$.\n\nThe four performance characteristics are computed based on their definitions as conditional probabilities.\n\n1.  **Sensitivity (True Positive Rate, $TPR$)**\n    Sensitivity is the probability of a positive test result given that the individual truly has the variant. It is a measure of how well the test identifies true cases.\n    $$ \\text{Sensitivity} = P(T^+ | D^+) = \\frac{\\text{Number of individuals with } T^+ \\text{ and } D^+}{\\text{Total number of individuals with } D^+} = \\frac{TP}{TP + FN} $$\n    Substituting the given values:\n    $$ \\text{Sensitivity} = \\frac{48}{48 + 12} = \\frac{48}{60} = \\frac{4 \\times 12}{5 \\times 12} = \\frac{4}{5} $$\n\n2.  **Specificity (True Negative Rate, $TNR$)**\n    Specificity is the probability of a negative test result given that the individual truly does not have the variant. It is a measure of how well the test identifies true non-cases.\n    $$ \\text{Specificity} = P(T^- | D^-) = \\frac{\\text{Number of individuals with } T^- \\text{ and } D^-}{\\text{Total number of individuals with } D^-} = \\frac{TN}{TN + FP} $$\n    Substituting the given values:\n    $$ \\text{Specificity} = \\frac{122}{122 + 18} = \\frac{122}{140} = \\frac{61 \\times 2}{70 \\times 2} = \\frac{61}{70} $$\n\n3.  **False Positive Rate ($FPR$)**\n    The false positive rate is the probability of a positive test result given that the individual truly does not have the variant. This is a Type I error rate.\n    $$ FPR = P(T^+ | D^-) = \\frac{\\text{Number of individuals with } T^+ \\text{ and } D^-}{\\text{Total number of individuals with } D^-} = \\frac{FP}{FP + TN} $$\n    It is also definitionally related to specificity: $FPR = 1 - \\text{Specificity}$.\n    Substituting the given values:\n    $$ FPR = \\frac{18}{18 + 122} = \\frac{18}{140} = \\frac{9 \\times 2}{70 \\times 2} = \\frac{9}{70} $$\n\n4.  **False Negative Rate ($FNR$)**\n    The false negative rate is the probability of a negative test result given that the individual truly has the variant. This is a Type II error rate.\n    $$ FNR = P(T^- | D^+) = \\frac{\\text{Number of individuals with } T^- \\text{ and } D^+}{\\text{Total number of individuals with } D^+} = \\frac{FN}{TP + FN} $$\n    It is also definitionally related to sensitivity: $FNR = 1 - \\text{Sensitivity}$.\n    Substituting the given values:\n    $$ FNR = \\frac{12}{48 + 12} = \\frac{12}{60} = \\frac{1 \\times 12}{5 \\times 12} = \\frac{1}{5} $$\n\nNext, we must determine which of these quantities are invariant to disease prevalence under case-control sampling.\n\nA case-control study is a retrospective study design where subjects are selected based on their known outcome status. Here, a group of \"cases\" (individuals with the variant, $D^+$) and a group of \"controls\" (individuals without the variant, $D^-$) are assembled. The proportion of cases to controls in the study sample is determined by the study design, not by the natural prevalence of the disease in the population. Prevalence, $\\pi = P(D^+)$, is the a priori probability of having the disease in the general population, from which a study sample might be drawn. In a case-control design, the sample prevalence is artificially fixed and is not an estimate of $\\pi$.\n\nWe analyze the definitions of the four metrics in light of this sampling scheme:\n\n-   **Sensitivity, $P(T^+|D^+)$**: This probability is conditioned on the event $D^+$. The calculation $\\frac{TP}{TP+FN}$ is performed entirely within the group of cases. Since the estimation of sensitivity only depends on the subjects who are known to have the disease, it is independent of how many subjects without the disease were included in the study. Therefore, sensitivity is an intrinsic characteristic of the test's performance on the diseased population and is **invariant** to the disease prevalence in the general population. The indicator $I_{\\text{sensitivity}}$ is $1$.\n\n-   **Specificity, $P(T^-|D^-)$**: This probability is conditioned on the event $D^-$. The calculation $\\frac{TN}{TN+FP}$ is performed entirely within the group of controls. Similar to sensitivity, the estimation of specificity only depends on the subjects known to be disease-free. It is therefore an intrinsic characteristic of the test's performance on the non-diseased population and is **invariant** to disease prevalence. The indicator $I_{\\text{specificity}}$ is $1$.\n\n-   **False Positive Rate, $P(T^+|D^-)$**: This probability is also conditioned on the event $D^-$. Its calculation, $\\frac{FP}{FP+TN}$, is performed entirely within the control group. As it is simply $1 - \\text{Specificity}$, it shares the same properties. The FPR is **invariant** to disease prevalence. The indicator $I_{\\text{false positive rate}}$ is $1$.\n\n-   **False Negative Rate, $P(T^-|D^+)$**: This probability is also conditioned on the event $D^+$. Its calculation, $\\frac{FN}{TP+FN}$, is performed entirely within the case group. As it is simply $1 - \\text{Sensitivity}$, it also shares the same properties. The FNR is **invariant** to disease prevalence. The indicator $I_{\\text{false negative rate}}$ is $1$.\n\nIn summary, all four metrics—sensitivity, specificity, false positive rate, and false negative rate—are defined by probabilities conditional on the true disease status. A case-control study design allows for the direct estimation of these quantities precisely because it samples from the distinct strata of diseased and non-diseased individuals. These metrics are properties of the test itself, not the population in which it is used. In contrast, metrics like Positive Predictive Value ($PPV = P(D^+|T^+)$) and Negative Predictive Value ($NPV = P(D^-|T^-)$) are critically dependent on prevalence $\\pi = P(D^+)$ via Bayes' theorem and cannot be directly estimated from a case-control study without external knowledge of $\\pi$.\n\nThe calculated values and their invariance indicators are:\n- Sensitivity: $\\frac{4}{5}$, Invariant ($I=1$)\n- Specificity: $\\frac{61}{70}$, Invariant ($I=1$)\n- False Positive Rate: $\\frac{9}{70}$, Invariant ($I=1$)\n- False Negative Rate: $\\frac{1}{5}$, Invariant ($I=1$)\n\nThe final answer is presented as a single row matrix in the specified order.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{4}{5} & \\frac{61}{70} & \\frac{9}{70} & \\frac{1}{5} & 1 & 1 & 1 & 1\n\\end{pmatrix}\n}\n$$", "id": "4332588"}, {"introduction": "While binary classifications are a useful starting point, most modern genomic classifiers output a continuous score rather than a simple positive or negative result. This practice moves from the 2x2 table to the richer landscape of Receiver Operating Characteristic (ROC) analysis, guiding you through the step-by-step construction of an empirical ROC curve from a small dataset of scores. By completing this exercise, you will gain a concrete understanding of how the Area Under the Curve (AUC) is derived and what it represents: the overall discriminative power of a test across all possible decision thresholds [@problem_id:4332613].", "problem": "A genomic classifier used in precision oncology outputs a continuous diagnostic score for each individual. Consider an evaluation cohort with $n_{D} = 4$ disease cases and $n_{N} = 4$ non-diseased controls. The classifier scores are observed as follows: disease cases have scores $[0.95, 0.81, 0.77, 0.62]$ and non-diseased controls have scores $[0.83, 0.79, 0.70, 0.40]$. Use the decision rule \"predict disease if the score is greater than or equal to threshold $\\tau$\" and vary $\\tau$ across the observed scores to construct the empirical Receiver Operating Characteristic (ROC) curve, where the ROC plots the True Positive Rate (TPR) against the False Positive Rate (FPR) as $\\tau$ is varied.\n\nStarting from first principles, use the canonical definitions of sensitivity and specificity as conditional probabilities to derive the empirical ROC points produced by thresholding the finite sample. Explicitly identify any ties among scores across disease status and explain how such ties must be handled to produce a well-defined empirical ROC and area under the curve in finite samples. Then, compute the empirical Area Under the Curve (AUC) of the ROC using a threshold-sweep consistent with the stepwise changes induced by the decision rule and a geometrically justified integration along the FPR axis.\n\nRound your final AUC to $4$ significant figures and express it as a decimal fraction without any percent sign.", "solution": "The problem asks for the construction of a Receiver Operating Characteristic (ROC) curve and the calculation of the Area Under the Curve (AUC) for a given set of diagnostic scores from a cohort of diseased and non-diseased individuals.\n\n### Step 1: Problem Validation\n\nThe problem provides the following givens:\n-   Number of disease cases: $n_{D} = 4$.\n-   Scores for disease cases: $[0.95, 0.81, 0.77, 0.62]$.\n-   Number of non-diseased controls: $n_{N} = 4$.\n-   Scores for non-diseased controls: $[0.83, 0.79, 0.70, 0.40]$.\n-   Decision rule: Predict disease if score $\\ge \\tau$.\n\nThe problem asks to:\n1.  Construct the empirical ROC curve by varying the threshold $\\tau$.\n2.  Explain the handling of tied scores.\n3.  Compute the empirical AUC using geometric integration along the False Positive Rate (FPR) axis.\n4.  Round the final AUC to $4$ significant figures.\n\nThe problem is scientifically grounded in the well-established statistical methodology of ROC analysis for diagnostic test evaluation. It is well-posed, with all necessary data provided and no contradictions. The task is objective and requires a standard, verifiable calculation. The problem is therefore deemed **valid**.\n\n### Step 2: Theoretical Framework\n\nLet $S$ be the diagnostic score. Let $D$ denote the state of having the disease and $N$ denote the state of not having the disease. The decision rule classifies an individual as positive ($T+$) if their score $S$ is greater than or equal to a threshold $\\tau$, and negative ($T-$) otherwise.\n\nThe two key performance metrics for an ROC curve are the True Positive Rate (TPR) and the False Positive Rate (FPR).\n\n-   **True Positive Rate (TPR)**, or sensitivity, is the probability of a correct positive prediction among the diseased population: $TPR(\\tau) = P(S \\ge \\tau | D)$.\n-   **False Positive Rate (FPR)** is the probability of an incorrect positive prediction among the non-diseased population: $FPR(\\tau) = P(S \\ge \\tau | N)$. Note that Specificity is $1 - FPR(\\tau)$.\n\nFor a finite sample, these probabilities are estimated by proportions:\n$$TPR(\\tau) = \\frac{\\text{Number of diseased individuals with score} \\ge \\tau}{n_{D}} = \\frac{TP(\\tau)}{n_{D}}$$\n$$FPR(\\tau) = \\frac{\\text{Number of non-diseased individuals with score} \\ge \\tau}{n_{N}} = \\frac{FP(\\tau)}{n_{N}}$$\nwhere $TP(\\tau)$ and $FP(\\tau)$ are the counts of true positives and false positives at threshold $\\tau$, respectively.\n\n### Step 3: Empirical ROC Curve Construction\n\nThe empirical ROC curve is constructed by calculating the $(FPR, TPR)$ pair for every possible threshold. In a finite sample, the set of relevant thresholds consists of the unique score values present in the data. To construct the curve, we can sweep the threshold $\\tau$ from a value above the maximum score down to a value below the minimum score.\n\nThe given scores are:\n-   Diseased ($S_D$): $\\{0.95, 0.81, 0.77, 0.62\\}$\n-   Non-diseased ($S_N$): $\\{0.83, 0.79, 0.70, 0.40\\}$\n\nWe combine and sort all scores in descending order, noting the class of each score:\n$0.95 (D), 0.83 (N), 0.81 (D), 0.79 (N), 0.77 (D), 0.70 (N), 0.62 (D), 0.40 (N)$.\n\nNow, we vary the threshold $\\tau$ and compute the cumulative counts of $TP$ and $FP$, and the corresponding rates $TPR$ and $FPR$. The ROC curve starts at $(0,0)$ (for $\\tau > \\max(S)$) and ends at $(1,1)$ (for $\\tau \\le \\min(S)$).\n\n1.  **Initial point:** For any $\\tau > 0.95$, no score is $\\ge \\tau$. So, $TP=0, FP=0$. This gives the point $(FPR, TPR) = (0/4, 0/4) = (0, 0)$.\n\n2.  **Threshold $\\tau$ crosses $0.95$ (D):** For $0.83 < \\tau \\le 0.95$, one diseased case score is $\\ge \\tau$. $TP=1, FP=0$. This gives the point $(0/4, 1/4) = (0, 0.25)$. The curve moves from $(0,0)$ up to $(0,0.25)$.\n\n3.  **Threshold $\\tau$ crosses $0.83$ (N):** For $0.81 < \\tau \\le 0.83$, one diseased and one non-diseased score are $\\ge \\tau$. $TP=1, FP=1$. This gives the point $(1/4, 1/4) = (0.25, 0.25)$. The curve moves from $(0,0.25)$ right to $(0.25,0.25)$.\n\n4.  **Threshold $\\tau$ crosses $0.81$ (D):** For $0.79 < \\tau \\le 0.81$, $TP=2, FP=1$. Point: $(1/4, 2/4) = (0.25, 0.5)$.\n\n5.  **Threshold $\\tau$ crosses $0.79$ (N):** For $0.77 < \\tau \\le 0.79$, $TP=2, FP=2$. Point: $(2/4, 2/4) = (0.5, 0.5)$.\n\n6.  **Threshold $\\tau$ crosses $0.77$ (D):** For $0.70 < \\tau \\le 0.77$, $TP=3, FP=2$. Point: $(2/4, 3/4) = (0.5, 0.75)$.\n\n7.  **Threshold $\\tau$ crosses $0.70$ (N):** For $0.62 < \\tau \\le 0.70$, $TP=3, FP=3$. Point: $(3/4, 3/4) = (0.75, 0.75)$.\n\n8.  **Threshold $\\tau$ crosses $0.62$ (D):** For $0.40 < \\tau \\le 0.62$, $TP=4, FP=3$. Point: $(3/4, 4/4) = (0.75, 1.0)$.\n\n9.  **Threshold $\\tau$ crosses $0.40$ (N):** For $\\tau \\le 0.40$, all scores are $\\ge \\tau$. $TP=4, FP=4$. Point: $(4/4, 4/4) = (1.0, 1.0)$.\n\nThe vertices of the empirical ROC curve are the sequence of points:\n$P_0=(0, 0)$, $P_1=(0, 0.25)$, $P_2=(0.25, 0.25)$, $P_3=(0.25, 0.5)$, $P_4=(0.5, 0.5)$, $P_5=(0.5, 0.75)$, $P_6=(0.75, 0.75)$, $P_7=(0.75, 1.0)$, $P_8=(1.0, 1.0)$.\n\n### Step 4: Handling of Tied Scores\n\nThe problem requires an explanation of how tied scores are handled. First, we note that in the given dataset, there are no identical scores between a diseased and a non-diseased individual, nor within either group. All $n_{D} + n_{N} = 8$ scores are unique.\n\nIn the general case where ties exist, suppose a score value $s^*$ is shared by $k_{D}$ diseased individuals and $k_{N}$ non-diseased individuals. When the decision threshold $\\tau$ is lowered past $s^*$, all these individuals are simultaneously reclassified as positive. This causes the count of true positives to increase by $k_{D}$ and the count of false positives to increase by $k_{N}$ in a single step.\n\nIf the ROC curve point just before this threshold is $(FPR_{i-1}, TPR_{i-1})$, the new point becomes:\n$$FPR_i = FPR_{i-1} + \\frac{k_{N}}{n_{N}}$$\n$$TPR_i = TPR_{i-1} + \\frac{k_{D}}{n_{D}}$$\nThis results in a single diagonal segment on the ROC plot, connecting $(FPR_{i-1}, TPR_{i-1})$ to $(FPR_i, TPR_i)$. This procedure ensures the ROC curve and its area are well-defined.\n\n### Step 5: AUC Calculation\n\nThe Area Under the Curve (AUC) is the integral of the ROC function $TPR(FPR)$ from $FPR=0$ to $FPR=1$. For an empirical ROC curve defined by a set of vertices $(x_i, y_i) = (FPR_i, TPR_i)$, the AUC can be computed by summing the areas of the trapezoids formed by each consecutive pair of vertices and the FPR axis. The area of a trapezoid with vertices $(x_{i-1}, y_{i-1})$ and $(x_i, y_i)$ is given by:\n$$Area_i = \\frac{y_{i-1} + y_i}{2} (x_i - x_{i-1})$$\nThe total AUC is the sum of these areas over all segments of the curve. Using the vertices $P_0, \\dots, P_8$ derived above:\n\n-   Segment $P_0 \\to P_1$: $x_0=0, y_0=0$; $x_1=0, y_1=0.25$. Area = $\\frac{0+0.25}{2}(0-0) = 0$.\n-   Segment $P_1 \\to P_2$: $x_1=0, y_1=0.25$; $x_2=0.25, y_2=0.25$. Area = $\\frac{0.25+0.25}{2}(0.25-0) = 0.25 \\times 0.25 = 0.0625$.\n-   Segment $P_2 \\to P_3$: $x_2=0.25, y_2=0.25$; $x_3=0.25, y_3=0.5$. Area = $\\frac{0.25+0.5}{2}(0.25-0.25) = 0$.\n-   Segment $P_3 \\to P_4$: $x_3=0.25, y_3=0.5$; $x_4=0.5, y_4=0.5$. Area = $\\frac{0.5+0.5}{2}(0.5-0.25) = 0.5 \\times 0.25 = 0.125$.\n-   Segment $P_4 \\to P_5$: $x_4=0.5, y_4=0.5$; $x_5=0.5, y_5=0.75$. Area = $\\frac{0.5+0.75}{2}(0.5-0.5) = 0$.\n-   Segment $P_5 \\to P_6$: $x_5=0.5, y_5=0.75$; $x_6=0.75, y_6=0.75$. Area = $\\frac{0.75+0.75}{2}(0.75-0.5) = 0.75 \\times 0.25 = 0.1875$.\n-   Segment $P_6 \\to P_7$: $x_6=0.75, y_6=0.75$; $x_7=0.75, y_7=1.0$. Area = $\\frac{0.75+1.0}{2}(0.75-0.75) = 0$.\n-   Segment $P_7 \\to P_8$: $x_7=0.75, y_7=1.0$; $x_8=1.0, y_8=1.0$. Area = $\\frac{1.0+1.0}{2}(1.0-0.75) = 1.0 \\times 0.25 = 0.25$.\n\nThe total AUC is the sum of the non-zero area components:\n$$AUC = 0.0625 + 0.125 + 0.1875 + 0.25 = 0.625$$\nThe problem requires the answer to be rounded to $4$ significant figures.\n$$AUC = 0.6250$$", "answer": "$$\\boxed{0.6250}$$", "id": "4332613"}, {"introduction": "A key challenge in applying diagnostic test evidence to clinical practice is generalizability—will a test perform as well in your patient population as it did in the validation study? This exercise introduces the critical concept of spectrum bias, a phenomenon where a test's observed sensitivity can change depending on the mix of disease severity in the population, even if the test's underlying mechanics are identical. By working through this hypothetical scenario, you will quantify how case-mix can alter performance metrics, providing a crucial lesson in the cautious interpretation of diagnostic accuracy studies [@problem_id:4332601].", "problem": "In a targeted sequencing assay used in precision oncology, the variant-calling algorithm computes a continuous log-likelihood ratio score $X$ for the presence of a driver mutation. A positive call is issued when $X \\geq c$. Suppose that, conditional on true mutation status and severity of disease biology (reflecting variant allele fraction and tumor purity), the score $X$ has the following distributions, which are identical across all cohorts:\n\n- For truly mutated cases with mild biology, $X \\mid (D, S=\\text{mild}) \\sim \\mathcal{N}(\\mu_{\\text{mild}}, \\sigma^{2})$ with $\\mu_{\\text{mild}}=2$ and $\\sigma=1$.\n- For truly mutated cases with severe biology, $X \\mid (D, S=\\text{severe}) \\sim \\mathcal{N}(\\mu_{\\text{severe}}, \\sigma^{2})$ with $\\mu_{\\text{severe}}=5$ and $\\sigma=1$.\n- For truly non-mutated cases, $X \\mid \\bar{D} \\sim \\mathcal{N}(0,1)$.\n\nThe decision threshold is fixed at $c=3$, and the algorithm, its threshold, and all conditional distributions above are identical across cohorts.\n\nTwo study cohorts differ only in the composition of disease severity among truly mutated cases:\n- Cohort A has $\\mathbb{P}(S=\\text{severe} \\mid D)=0.3$ and $\\mathbb{P}(S=\\text{mild} \\mid D)=0.7$.\n- Cohort B has $\\mathbb{P}(S=\\text{severe} \\mid D)=0.7$ and $\\mathbb{P}(S=\\text{mild} \\mid D)=0.3$.\n\nNo other aspect of the test, the measurement process, or the conditional distributions depends on the cohort.\n\nUsing only core definitions of diagnostic test performance, do the following:\n\n- Provide a precise definition of spectrum bias in the evaluation of diagnostic tests in terms of how case-mix alters observed performance without any change in the underlying test mechanics.\n- Using the definition of sensitivity as $\\mathbb{P}(T^{+} \\mid D)$, and the fixed threshold rule $T^{+}\\iff X \\geq c$, derive expressions for the observed sensitivity in Cohort A and Cohort B, and compute the difference $\\Delta=\\text{sensitivity}_{B}-\\text{sensitivity}_{A}$.\n\nExpress your final numeric answer for $\\Delta$ as a decimal and round to four significant figures. Do not include any units in your final answer.", "solution": "The problem statement has been evaluated and is determined to be valid. It is scientifically grounded in the principles of biostatistics and diagnostic test evaluation, is well-posed with a complete and consistent set of givens, and is expressed in objective, formal language. It represents a non-trivial application of probability theory to a realistic scenario in precision medicine, specifically demonstrating the concept of spectrum bias.\n\nThe first task is to provide a precise definition of spectrum bias. Spectrum bias, also known as case-mix bias, is a phenomenon in which the observed performance of a diagnostic test, particularly its sensitivity and specificity, varies across different populations or studies. This variation does not arise from any change in the intrinsic properties of the test itself (e.g., the analytical method, the decision threshold) but is instead a consequence of differences in the composition of the populations being tested. Specifically, sensitivity can be affected by the \"spectrum\" of disease severity, stage, or other patient characteristics within the diseased group, while specificity can be affected by the spectrum of alternative conditions in the non-diseased group. If a test's ability to detect the disease is correlated with disease severity, then a study population with a higher proportion of severe cases will exhibit a higher apparent sensitivity than a population with a higher proportion of mild or early-stage cases, even when the test's conditional performance at any given level of severity is identical for both populations.\n\nThe second task is to derive the observed sensitivity for Cohort A and Cohort B and compute their difference. Sensitivity is defined as the probability of a positive test result ($T^{+}$) given that the individual truly has the disease ($D$), i.e., $\\mathbb{P}(T^{+} \\mid D)$. A positive test result is issued when the log-likelihood score $X$ is greater than or equal to the threshold $c$. Thus, sensitivity is $\\mathbb{P}(X \\geq c \\mid D)$.\n\nThe population of diseased individuals ($D$) is a heterogeneous mixture of cases with mild biology ($S=\\text{mild}$) and severe biology ($S=\\text{severe}$). We can apply the law of total probability to express the overall sensitivity as a weighted average of the sensitivities within these two strata:\n$$\n\\text{Sensitivity} = \\mathbb{P}(X \\geq c \\mid D) = \\mathbb{P}(X \\geq c \\mid D, S=\\text{mild})\\mathbb{P}(S=\\text{mild} \\mid D) + \\mathbb{P}(X \\geq c \\mid D, S=\\text{severe})\\mathbb{P}(S=\\text{severe} \\mid D)\n$$\nLet us denote the stratum-specific sensitivities as:\n$\\text{Sens}_{\\text{mild}} = \\mathbb{P}(X \\geq c \\mid D, S=\\text{mild})$\n$\\text{Sens}_{\\text{severe}} = \\mathbb{P}(X \\geq c \\mid D, S=\\text{severe})$\n\nThese stratum-specific sensitivities are determined by the underlying conditional distributions of the score $X$ and the fixed threshold $c$. They are constant across the cohorts because the problem states these distributions are identical. We are given:\n- For mild cases: $X \\mid (D, S=\\text{mild}) \\sim \\mathcal{N}(\\mu_{\\text{mild}}, \\sigma^{2})$ with $\\mu_{\\text{mild}}=2$ and $\\sigma=1$.\n- For severe cases: $X \\mid (D, S=\\text{severe}) \\sim \\mathcal{N}(\\mu_{\\text{severe}}, \\sigma^{2})$ with $\\mu_{\\text{severe}}=5$ and $\\sigma=1$.\n- The threshold is $c=3$.\n\nWe calculate the stratum-specific sensitivities by standardizing the normal distributions. Let $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$, and let $\\Phi(\\cdot)$ be its cumulative distribution function (CDF).\n\nFor the mild stratum:\n$$\n\\text{Sens}_{\\text{mild}} = \\mathbb{P}(X \\geq 3) = \\mathbb{P}\\left(\\frac{X - \\mu_{\\text{mild}}}{\\sigma} \\geq \\frac{3 - 2}{1}\\right) = \\mathbb{P}(Z \\geq 1) = 1 - \\Phi(1)\n$$\nFor the severe stratum:\n$$\n\\text{Sens}_{\\text{severe}} = \\mathbb{P}(X \\geq 3) = \\mathbb{P}\\left(\\frac{X - \\mu_{\\text{severe}}}{\\sigma} \\geq \\frac{3 - 5}{1}\\right) = \\mathbb{P}(Z \\geq -2) = 1 - \\Phi(-2)\n$$\nUsing the symmetry property of the standard normal distribution, $\\Phi(-z) = 1 - \\Phi(z)$, we have:\n$$\n\\text{Sens}_{\\text{severe}} = 1 - (1 - \\Phi(2)) = \\Phi(2)\n$$\nNow we can compute the overall sensitivity for each cohort using their specific case-mix probabilities.\n\nFor Cohort A:\n$\\mathbb{P}_A(S=\\text{mild} \\mid D) = 0.7$\n$\\mathbb{P}_A(S=\\text{severe} \\mid D) = 0.3$\n$$\n\\text{sensitivity}_{A} = \\text{Sens}_{\\text{mild}} \\cdot \\mathbb{P}_A(S=\\text{mild} \\mid D) + \\text{Sens}_{\\text{severe}} \\cdot \\mathbb{P}_A(S=\\text{severe} \\mid D)\n$$\n$$\n\\text{sensitivity}_{A} = (1 - \\Phi(1)) \\cdot 0.7 + \\Phi(2) \\cdot 0.3\n$$\n\nFor Cohort B:\n$\\mathbb{P}_B(S=\\text{mild} \\mid D) = 0.3$\n$\\mathbb{P}_B(S=\\text{severe} \\mid D) = 0.7$\n$$\n\\text{sensitivity}_{B} = \\text{Sens}_{\\text{mild}} \\cdot \\mathbb{P}_B(S=\\text{mild} \\mid D) + \\text{Sens}_{\\text{severe}} \\cdot \\mathbb{P}_B(S=\\text{severe} \\mid D)\n$$\n$$\n\\text{sensitivity}_{B} = (1 - \\Phi(1)) \\cdot 0.3 + \\Phi(2) \\cdot 0.7\n$$\n\nThe problem asks for the difference $\\Delta = \\text{sensitivity}_{B} - \\text{sensitivity}_{A}$.\n$$\n\\Delta = [0.3(1 - \\Phi(1)) + 0.7\\Phi(2)] - [0.7(1 - \\Phi(1)) + 0.3\\Phi(2)]\n$$\nGrouping terms by $\\text{Sens}_{\\text{mild}}=(1 - \\Phi(1))$ and $\\text{Sens}_{\\text{severe}}=\\Phi(2)$:\n$$\n\\Delta = (0.3 - 0.7)(1 - \\Phi(1)) + (0.7 - 0.3)\\Phi(2)\n$$\n$$\n\\Delta = -0.4(1 - \\Phi(1)) + 0.4\\Phi(2)\n$$\n$$\n\\Delta = 0.4[\\Phi(2) - (1 - \\Phi(1))]\n$$\n$$\n\\Delta = 0.4[\\Phi(2) + \\Phi(1) - 1]\n$$\nTo obtain the numerical value, we use standard values for the normal CDF:\n$\\Phi(1) \\approx 0.84134$\n$\\Phi(2) \\approx 0.97725$\nSubstituting these values into the expression for $\\Delta$:\n$$\n\\Delta \\approx 0.4[0.97725 + 0.84134 - 1]\n$$\n$$\n\\Delta \\approx 0.4[1.81859 - 1]\n$$\n$$\n\\Delta \\approx 0.4[0.81859]\n$$\n$$\n\\Delta \\approx 0.327436\n$$\nRounding to four significant figures, as required, we obtain $\\Delta = 0.3274$.\nThis positive difference confirms that Cohort B, which is enriched for cases with severe biology, exhibits a higher observed sensitivity than Cohort A, which is predominantly composed of cases with mild biology. This is a direct quantitative demonstration of spectrum bias.", "answer": "$$\\boxed{0.3274}$$", "id": "4332601"}]}