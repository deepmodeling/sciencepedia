{"hands_on_practices": [{"introduction": "The cornerstone of evaluating performance in any proficiency testing (PT) or external quality assessment (EQA) scheme is the ability to quantify a laboratory's result against a common standard. This exercise introduces the fundamental tool for this task: the standardized performance score, or z-score. By calculating a z-score, we can transform a raw measurement into a universal, dimensionless metric that objectively shows how a participant's result compares to the consensus value established by the peer group [@problem_id:4373437].", "problem": "An oncology next-generation sequencing (NGS) laboratory participates in External Quality Assessment (EQA) via Proficiency Testing (PT) for quantitative variant allele fraction (VAF) measurement on a synthetic reference specimen. In PT/EQA, performance is judged relative to an assigned value determined from a consensus of competent laboratories and a target dispersion derived from robust statistical estimators, consistent with International Organization for Standardization (ISO) 13528 guidance. Let the participant’s reported VAF be $x = 0.12$ (expressed as a decimal fraction), the assigned value be $X = 0.10$, and the robust target standard deviation be $\\sigma = 0.03$. Using the foundational definition that standardization maps a measurement $y$ with location $m$ and scale $s$ to a dimensionless score with zero mean and unit variance, compute the standardized performance score for this PT item and interpret it against the commonly used qualitative thresholds of $|z|  2$ for acceptable performance and $|z| \\geq 3$ for unacceptable performance. Report the numerical value of the standardized performance score rounded to four significant figures. No units are required for the score.", "solution": "The problem statement is subjected to validation before proceeding with a solution.\n\n### Step 1: Extract Givens\n-   Participant's reported Variant Allele Fraction (VAF): $x = 0.12$\n-   Assigned value (consensus VAF): $X = 0.10$\n-   Robust target standard deviation for the PT item: $\\sigma = 0.03$\n-   Definition of standardization: \"standardization maps a measurement $y$ with location $m$ and scale $s$ to a dimensionless score with zero mean and unit variance\"\n-   Qualitative performance thresholds:\n    -   Acceptable performance: $|z|  2$\n    -   Unacceptable performance: $|z| \\geq 3$\n-   Required output: The numerical value of the standardized performance score rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective.\n-   **Scientific Grounding**: The problem is based on established principles of statistical quality control used in External Quality Assessment (EQA) and Proficiency Testing (PT), as codified in standards like ISO 13528. The use of a standardized score (z-score) to evaluate laboratory performance against a consensus value and a target dispersion is standard practice in clinical and diagnostic laboratory medicine, including genomic testing. The numerical values provided for VAF and its standard deviation are realistic for next-generation sequencing (NGS) applications in oncology.\n-   **Well-Posedness**: The problem provides all necessary data ($x$, $X$, $\\sigma$) and a clear definition to compute a unique standardized score. The objective is unambiguous.\n-   **Objectivity**: The problem is stated using precise, quantitative, and unbiased terminology common to the fields of statistics and laboratory quality assurance.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A solution will be derived.\n\nThe core task is to compute a standardized performance score. The problem defines standardization as a process that \"maps a measurement $y$ with location $m$ and scale $s$ to a dimensionless score with zero mean and unit variance.\" This is the formal definition of a standard score, or z-score. The general formula for a z-score is:\n$$\nz = \\frac{y - m}{s}\n$$\nIn the context of this proficiency testing problem, we map the given variables to the terms in the general formula:\n-   The participant's measurement is the reported VAF, so $y = x$.\n-   The location parameter is the assigned value, which represents the consensus mean, so $m = X$.\n-   The scale parameter is the robust target standard deviation, so $s = \\sigma$.\n\nSubstituting these into the general formula gives the specific equation for the standardized performance score in this PT/EQA context:\n$$\nz = \\frac{x - X}{\\sigma}\n$$\nWe are given the following numerical values:\n-   $x = 0.12$\n-   $X = 0.10$\n-   $\\sigma = 0.03$\n\nSubstituting these values into the equation yields:\n$$\nz = \\frac{0.12 - 0.10}{0.03}\n$$\nFirst, we compute the difference in the numerator:\n$$\nz = \\frac{0.02}{0.03}\n$$\nThis simplifies to the exact fraction:\n$$\nz = \\frac{2}{3}\n$$\nTo provide the numerical value as requested, we convert the fraction to a decimal.\n$$\nz = 0.666666...\n$$\nThe problem requires this value to be rounded to four significant figures.\n$$\nz \\approx 0.6667\n$$\nThe problem also requests an interpretation of this score. We must compare the absolute value of the score, $|z|$, to the provided thresholds.\n$$\n|z| = |0.6667| = 0.6667\n$$\nThe condition for acceptable performance is $|z|  2$. Since $0.6667  2$, the laboratory's performance on this PT item is classified as acceptable. It is not between $2$ and $3$ (a range often deemed questionable or requiring investigation) and is well below the threshold for unacceptable performance, which is $|z| \\geq 3$.\nThe final numerical answer required is the score itself, rounded as specified.", "answer": "$$ \\boxed{0.6667} $$", "id": "4373437"}, {"introduction": "While the z-score provides a clear performance metric, it relies on having a trustworthy \"assigned value\" or consensus target. In reality, this target must be derived from the results of all participating laboratories, which may include significant errors or outliers. This practice delves into the critical process of establishing a reliable consensus value using robust statistical methods that are resistant to distortion by errant data points, ensuring the benchmark for evaluation is both fair and accurate [@problem_id:4373412].", "problem": "An External Quality Assessment (EQA) provider in precision oncology distributes a contrived sample for measuring Variant Allele Fraction (VAF) of a single nucleotide variant (SNV). Seven laboratories report VAF estimates forming the dataset $x = \\{0.094, 0.101, 0.097, 0.500, 0.102, 0.098, 0.099\\}$ for a target value $X \\approx 0.100$. In designing a consensus assigned value resistant to a single gross error, the provider uses a robust location and scale approach grounded in the sample median and the median absolute deviation.\n\nStarting from the definitions of the sample median $\\tilde{x}$ and the median absolute deviation $\\operatorname{MAD} = \\operatorname{median}(|x_i - \\tilde{x}|)$, and using the Gaussian consistency constant $c = 1.4826$ to form the robust scale estimate $s_{r} = c \\cdot \\operatorname{MAD}$, apply a decision rule analogous to the three-sigma rule: flag any observation whose robust standardized distance $\\frac{|x_i - \\tilde{x}|}{s_r}$ exceeds $3.5$ as an outlier. After removing any flagged outlier(s), compute the one-point trimmed mean $\\bar{x}_{\\text{trim}}$ of the remaining values as the EQA consensus assigned value for VAF.\n\nReport the final $\\bar{x}_{\\text{trim}}$ as a unitless decimal fraction (do not use a percent sign), and round your answer to four significant figures.", "solution": "The problem requires the calculation of a consensus assigned value for a Variant Allele Fraction (VAF) from a set of laboratory measurements, using a robust statistical approach to identify and remove an outlier.\n\nThe problem is determined to be valid as it is scientifically grounded, objective, and contains sufficient information for a unique solution. A minor ambiguity in the term \"one-point trimmed mean\" is resolved by interpreting it as the arithmetic mean of the data remaining after outlier removal, a standard procedure in such consensus value-setting, rather than a subsequent symmetric trim.\n\nThe step-by-step calculation is as follows:\n\nThe given dataset of VAF estimates is $x = \\{0.094, 0.101, 0.097, 0.500, 0.102, 0.098, 0.099\\}$. The number of observations is $n=7$.\n\n1.  **Calculate the sample median ($\\tilde{x}$):**\n    First, the data is sorted in ascending order:\n    $$x_{\\text{sorted}} = \\{0.094, 0.097, 0.098, 0.099, 0.101, 0.102, 0.500\\}$$\n    The median of $n=7$ data points is the middle value, located at position $\\frac{n+1}{2} = \\frac{7+1}{2} = 4$. The fourth value in the sorted list is $0.099$.\n    $$\\tilde{x} = 0.099$$\n\n2.  **Calculate the Median Absolute Deviation ($\\operatorname{MAD}$):**\n    The absolute deviations from the median, $|x_i - \\tilde{x}|$, for each data point are calculated:\n    \\begin{itemize}\n        \\item $|0.094 - 0.099| = 0.005$\n        \\item $|0.101 - 0.099| = 0.002$\n        \\item $|0.097 - 0.099| = 0.002$\n        \\item $|0.500 - 0.099| = 0.401$\n        \\item $|0.102 - 0.099| = 0.003$\n        \\item $|0.098 - 0.099| = 0.001$\n        \\item $|0.099 - 0.099| = 0.000$\n    \\end{itemize}\n    The set of absolute deviations is $\\{0.005, 0.002, 0.002, 0.401, 0.003, 0.001, 0.000\\}$. Sorting these deviations gives:\n    $$\\text{Sorted Deviations} = \\{0.000, 0.001, 0.002, 0.002, 0.003, 0.005, 0.401\\}$$\n    The median of these $7$ deviations is the fourth value, which is $0.002$.\n    $$\\operatorname{MAD} = \\operatorname{median}(|x_i - \\tilde{x}|) = 0.002$$\n\n3.  **Compute the robust scale estimate ($s_r$):**\n    Using the given Gaussian consistency constant $c = 1.4826$, the robust scale estimate $s_r$ is:\n    $$s_{r} = c \\cdot \\operatorname{MAD} = 1.4826 \\times 0.002 = 0.0029652$$\n\n4.  **Identify and remove outliers:**\n    The outlier detection rule flags any observation $x_i$ where the robust standardized distance exceeds $3.5$:\n    $$\\frac{|x_i - \\tilde{x}|}{s_r} > 3.5$$\n    This is equivalent to checking if an absolute deviation $|x_i - \\tilde{x}|$ exceeds the threshold $3.5 \\cdot s_r$:\n    $$\\text{Threshold} = 3.5 \\times 0.0029652 = 0.0103782$$\n    Comparing the calculated absolute deviations to this threshold, only one value is larger:\n    $$0.401 > 0.0103782$$\n    This deviation corresponds to the data point $x_i = 0.500$, which is therefore identified as an outlier and removed from the dataset.\n\n5.  **Compute the consensus assigned value ($\\bar{x}_{\\text{trim}}$):**\n    After removing the outlier, the remaining dataset is $x_{\\text{remaining}} = \\{0.094, 0.101, 0.097, 0.102, 0.098, 0.099\\}$.\n    The consensus assigned value, denoted $\\bar{x}_{\\text{trim}}$, is the arithmetic mean of these $n_{\\text{remaining}} = 6$ values:\n    $$\\bar{x}_{\\text{trim}} = \\frac{0.094 + 0.101 + 0.097 + 0.102 + 0.098 + 0.099}{6}$$\n    $$\\bar{x}_{\\text{trim}} = \\frac{0.591}{6} = 0.0985$$\n\n6.  **Round to four significant figures:**\n    The exact result of the calculation is $0.0985$. The significant figures are $9$, $8$, and $5$, for a total of three. To report this value rounded to four significant figures, a trailing zero is added.\n    $$\\bar{x}_{\\text{trim}} \\approx 0.09850$$", "answer": "$$\n\\boxed{0.09850}\n$$", "id": "4373412"}, {"introduction": "Moving beyond the standard z-score, advanced EQA for quantitative assays requires a more nuanced approach that respects the principles of metrology, or the science of measurement. This exercise explores a participant-specific performance score that incorporates the measurement uncertainty reported by the laboratory and the uncertainty of the assigned value itself. Understanding the distinction between a traditional z-score and this metrologically-based discrepancy is crucial for fairly assessing high-precision methods and for interpreting results near the limits of detection [@problem_id:4373472].", "problem": "An External Quality Assessment (EQA) provider for quantitative genomic biomarkers (for example, variant allele fraction in circulating tumor DNA) considers two standardization approaches for participant results. Let a laboratory report a measurement result $x$ together with its evaluated standard uncertainty $u_x$ derived from a validated measurement uncertainty budget, and let the EQA assigned value be $X$ with standard uncertainty $u_X$ obtained from a traceable assignment process using commutable materials. The provider also defines a fit-for-purpose standard deviation for proficiency assessment $\\sigma_{\\mathrm{pt}}$ intended to represent allowable between-laboratory dispersion for grading.\n\nStarting from the measurement error model with unbiased, independent, approximately Gaussian errors for the participant result and the assigned value, and from the rule for propagation of uncertainty for sums and differences of independent quantities, determine the standard uncertainty of the difference $d = x - X$ and explain how this motivates a participant-specific standardized discrepancy distinct from a traditional proficiency $z$-score. Then, consider the following realistic EQA case: a laboratory reports $x = 2.8\\,\\%$ with $u_x = 0.3\\,\\%$, the assigned value is $X = 3.0\\,\\%$ with $u_X = 0.4\\,\\%$, and the provider’s $\\sigma_{\\mathrm{pt}} = 0.6\\,\\%$. Based on first principles, compare the magnitudes of standardized discrepancies under the two approaches and justify, in the context of quantitative genomic biomarkers, when the participant-specific approach is preferable for grading.\n\nWhich option best captures the correct derivation, numerical comparison for the case, and justification for when the participant-specific approach is preferable?\n\nA. Under independence, the standard uncertainty of $d$ is the root-sum-of-squares of the two standard uncertainties, motivating a participant-specific standardized discrepancy that uses the combined uncertainty of the participant result and the assigned value; with the given data, the traditional proficiency $z$-score magnitude is approximately $0.33$ while the participant-specific standardized discrepancy magnitude is approximately $0.40$. Such participant-specific scores are preferable when the assigned value uncertainty and the participant’s method-specific uncertainty are explicitly available and non-negligible, such as for low-abundance variant allele fractions near the limit of detection or across methods with heterogeneous precision, because they provide metrologically traceable, fair grading tied to stated uncertainties.\n\nB. The participant-specific standardized discrepancy should use only the participant’s $u_x$ in the denominator and ignore $u_X$; with the given data this yields a magnitude of approximately $0.67$, and it is preferable precisely when the assigned value uncertainty is negligible so that grading relies solely on the participant’s own precision.\n\nC. Because the provider supplies a fit-for-purpose $\\sigma_{\\mathrm{pt}}$, the traditional proficiency $z$-score and the participant-specific standardized discrepancy are approximately equal both in derivation and numerically in this case, each giving a magnitude close to $0.33$; therefore the participant-specific approach offers no particular advantage for genomic biomarkers.\n\nD. The participant-specific approach is preferable only when the assigned value $X$ is produced by a reference method with effectively zero uncertainty and when $\\sigma_{\\mathrm{pt}}$ is unknown; in such cases with the given data, both standardized discrepancies would be identical in magnitude and near $0.33$.\n\nE. For low-level genomic measurands near the limit of detection, the traditional proficiency $z$-score is preferable because it down-weights assigned value uncertainty by using $\\sigma_{\\mathrm{pt}}$, thereby avoiding inflated scores; the participant-specific approach would over-penalize laboratories as the assigned value uncertainty increases.", "solution": "The user has provided a problem from the field of proficiency testing and external quality assessment, specifically applied to quantitative genomic biomarkers. The task is to validate the problem statement, derive a solution from first principles, and evaluate the given options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   Participant's reported measurement result: $x$\n-   Participant's evaluated standard uncertainty: $u_x$\n-   EQA assigned value: $X$\n-   Standard uncertainty of the assigned value: $u_X$\n-   Fit-for-purpose standard deviation for proficiency assessment: $\\sigma_{\\mathrm{pt}}$\n-   Definition of the difference: $d = x - X$\n-   Model assumptions: Unbiased, independent, approximately Gaussian errors for the participant result and the assigned value.\n-   Governing rule: Propagation of uncertainty for sums and differences of independent quantities.\n-   Numerical values for a specific case:\n    -   $x = 2.8\\,\\%$\n    -   $u_x = 0.3\\,\\%$\n    -   $X = 3.0\\,\\%$\n    -   $u_X = 0.4\\,\\%$\n    -   $\\sigma_{\\mathrm{pt}} = 0.6\\,\\%$\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-defined and scientifically grounded in the principles of metrology and statistics as applied to laboratory medicine. The concepts presented—measurement uncertainty, assigned value, uncertainty propagation, and proficiency testing scores ($z$-scores)—are standard (e.g., ISO/IEC Guide 98-3 \"GUM\", ISO 13528, ISO 17043). The distinction between a population-based standard deviation for proficiency ($\\sigma_{\\mathrm{pt}}$) and a measurement-specific combined uncertainty is a critical topic in modern EQA. The application to quantitative genomic diagnostics (circulating tumor DNA variant allele fraction) is highly relevant and realistic. All data required for the derivation and numerical calculation are provided, and there are no internal contradictions. The problem does not violate any of the invalidity criteria.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. The solution will proceed by deriving the required quantities and relationships from first principles, followed by a detailed evaluation of each option.\n\n### Derivation and Solution\n\nThe problem asks for three things: first, the derivation of the standard uncertainty of the difference $d = x - X$; second, an explanation of how this leads to a participant-specific standardized discrepancy; and third, a numerical comparison and justification for the preference of this approach in the context of genomic biomarkers.\n\n**1. Standard Uncertainty of the Difference, $u_d$**\n\nThe problem states that we should start from the rule for propagation of uncertainty for sums and differences of independent quantities. The difference is given by $d = x - X$. According to the Guide to the Expression of Uncertainty in Measurement (GUM), for a function $y = f(q_1, q_2, ..., q_n)$ where the input quantities $q_i$ are independent (uncorrelated), the combined variance $u_c^2(y)$ is given by:\n$$\nu_c^2(y) = \\sum_{i=1}^{n} \\left( \\frac{\\partial f}{\\partial q_i} \\right)^2 u^2(q_i)\n$$\nIn our case, the function is $d(x,X) = x - X$. The input quantities are $x$ and $X$, with standard uncertainties $u_x$ and $u_X$ respectively. The problem states that the errors are independent. The partial derivatives are:\n$$\n\\frac{\\partial d}{\\partial x} = 1\n$$\n$$\n\\frac{\\partial d}{\\partial X} = -1\n$$\nApplying the propagation of uncertainty formula, the variance of the difference, $u_d^2$, is:\n$$\nu_d^2 = \\left( \\frac{\\partial d}{\\partial x} \\right)^2 u_x^2 + \\left( \\frac{\\partial d}{\\partial X} \\right)^2 u_X^2 = (1)^2 u_x^2 + (-1)^2 u_X^2 = u_x^2 + u_X^2\n$$\nTherefore, the standard uncertainty of the difference $d$ is the square root of the variance:\n$$\nu_d = \\sqrt{u_x^2 + u_X^2}\n$$\nThis is the root-sum-of-squares of the individual standard uncertainties.\n\n**2. Motivation for a Participant-Specific Standardized Discrepancy**\n\nA standardized discrepancy is a dimensionless quantity that compares a measurement difference to its expected statistical dispersion (i.e., its standard uncertainty). The goal is to assess if the observed difference is statistically significant.\n- The observed difference is $d = x - X$.\n- The best estimate for the standard uncertainty of this specific difference, derived above, is $u_d = \\sqrt{u_x^2 + u_X^2}$.\n\nA logical and metrologically sound standardized discrepancy is the ratio of the difference to its standard uncertainty. Let us denote this standardized discrepancy as $E_n$ (a notation commonly used for such performance statistics in interlaboratory comparisons):\n$$\nE_n = \\frac{d}{u_d} = \\frac{x - X}{\\sqrt{u_x^2 + u_X^2}}\n$$\nThis discrepancy is \"participant-specific\" because its denominator explicitly incorporates the participant's own reported standard uncertainty, $u_x$. It evaluates the consistency of the participant's result $x \\pm u_x$ with the assigned value $X \\pm u_X$.\n\nIn contrast, a traditional proficiency testing $z$-score is defined as:\n$$\nz = \\frac{x - X}{\\sigma_{\\mathrm{pt}}}\n$$\nThe denominator $\\sigma_{\\mathrm{pt}}$ is a fixed, externally defined performance criterion and is the same for all participants. It does not account for the participant's specific uncertainty claim ($u_x$) nor the uncertainty of the assigned value ($u_X$), but rather represents a target for between-laboratory precision deemed \"fit-for-purpose\" by the EQA provider.\n\n**3. Numerical Comparison and Justification**\n\nUsing the given data: $x = 2.8\\,\\%$, $u_x = 0.3\\,\\%$, $X = 3.0\\,\\%$, $u_X = 0.4\\,\\%$, and $\\sigma_{\\mathrm{pt}} = 0.6\\,\\%$.\n\n- **Difference**: $d = x - X = 2.8\\,\\% - 3.0\\,\\% = -0.2\\,\\%$.\n\n- **Traditional Proficiency $z$-score**:\n$$\nz = \\frac{-0.2\\,\\%}{0.6\\,\\%} = -\\frac{1}{3} \\approx -0.333\n$$\nThe magnitude is $|z| \\approx 0.33$.\n\n- **Participant-Specific Standardized Discrepancy ($E_n$)**:\nFirst, calculate the combined uncertainty in the denominator:\n$$\nu_d = \\sqrt{u_x^2 + u_X^2} = \\sqrt{(0.3\\,\\%)^2 + (0.4\\,\\%)^2} = \\sqrt{0.09\\,\\%^2 + 0.16\\,\\%^2} = \\sqrt{0.25\\,\\%^2} = 0.5\\,\\%\n$$\nNow, calculate the discrepancy:\n$$\nE_n = \\frac{-0.2\\,\\%}{0.5\\,\\%} = -0.4\n$$\nThe magnitude is $|E_n| = 0.40$.\n\n- **Justification for Preference**:\nThe participant-specific approach ($E_n$ score) is preferable in contexts where a metrologically rigorous assessment is required. This is particularly true for quantitative genomic biomarkers for several reasons:\n1.  **Fairness and Individualized Assessment**: Methods for measuring genomic biomarkers (e.g., NGS, dPCR) have widely varying precision capabilities. A laboratory using a high-precision method (low $u_x$) should be evaluated against a tighter tolerance than a lab using a lower-precision screening method (higher $u_x$). The $E_n$ score achieves this by incorporating $u_x$ into the grading, providing a fair assessment of performance relative to capability. The $z$-score applies a single blunt standard ($\\sigma_{\\mathrm{pt}}$) to all.\n2.  **Metrological Traceability**: The $E_n$ score is built upon the GUM framework, which is the foundation of modern metrology. It tests the statistical consistency of two measurement results, each with a stated uncertainty. This is a more fundamental and informative assessment than comparing to a policy-driven performance limit.\n3.  **Significance of Uncertainties**: In quantitative genomics, especially for low-abundance targets like variant allele fractions near the limit of detection, the measurement uncertainties ($u_x$ and $u_X$) are often large relative to the measurand value and cannot be considered negligible. Ignoring them, as the $z$-score effectively does by substituting $\\sigma_{\\mathrm{pt}}$, discards crucial information and can lead to misinterpretation of performance. For instance, if the assigned value has a large uncertainty ($u_X$), it is not reasonable to expect a participant's result to agree with it very closely. The $E_n$ score correctly accounts for this by widening the acceptance interval (increasing the denominator), whereas the $z$-score does not.\n\n### Option-by-Option Analysis\n\n**A. Under independence, the standard uncertainty of $d$ is the root-sum-of-squares of the two standard uncertainties, motivating a participant-specific standardized discrepancy that uses the combined uncertainty of the participant result and the assigned value; with the given data, the traditional proficiency $z$-score magnitude is approximately $0.33$ while the participant-specific standardized discrepancy magnitude is approximately $0.40$. Such participant-specific scores are preferable when the assigned value uncertainty and the participant’s method-specific uncertainty are explicitly available and non-negligible, such as for low-abundance variant allele fractions near the limit of detection or across methods with heterogeneous precision, because they provide metrologically traceable, fair grading tied to stated uncertainties.**\n-   **Evaluation**: This option correctly states the rule for uncertainty propagation (root-sum-of-squares). It correctly identifies that this motivates a discrepancy using the combined uncertainty. The numerical calculations for both the $z$-score magnitude ($\\approx$$0.33$) and the participant-specific score magnitude ($0.40$) are correct. The justification for preference is comprehensive and accurate, citing the importance of non-negligible uncertainties, method heterogeneity, and the desire for metrologically traceable and fair grading.\n-   **Verdict**: **Correct**.\n\n**B. The participant-specific standardized discrepancy should use only the participant’s $u_x$ in the denominator and ignore $u_X$; with the given data this yields a magnitude of approximately $0.67$, and it is preferable precisely when the assigned value uncertainty is negligible so that grading relies solely on the participant’s own precision.**\n-   **Evaluation**: This is incorrect. The uncertainty of the difference $d=x-X$ must include the uncertainty of $X$. Ignoring $u_X$ violates the rules of error propagation unless $u_X \\ll u_x$. In this case, $u_X=0.4\\,\\%$ is even larger than $u_x=0.3\\,\\%$, making its omission a serious error. The calculation based on this flawed premise, $|-0.2/0.3| \\approx 0.67$, is arithmetically correct but conceptually wrong.\n-   **Verdict**: **Incorrect**.\n\n**C. Because the provider supplies a fit-for-purpose $\\sigma_{\\mathrm{pt}}$, the traditional proficiency $z$-score and the participant-specific standardized discrepancy are approximately equal both in derivation and numerically in this case, each giving a magnitude close to $0.33$; therefore the participant-specific approach offers no particular advantage for genomic biomarkers.**\n-   **Evaluation**: This is incorrect on multiple counts. The derivations are fundamentally different: one uses $\\sigma_{\\mathrm{pt}}$, the other uses $\\sqrt{u_x^2 + u_X^2}$. The numerical results were calculated as $\\approx$$0.33$ and $0.40$, which are not approximately equal. The denominator for the $z$-score is $0.6\\,\\%$, while for the $E_n$ score it is $0.5\\,\\%$. The conclusion that there is no advantage is contrary to the principles of metrology.\n-   **Verdict**: **Incorrect**.\n\n**D. The participant-specific approach is preferable only when the assigned value $X$ is produced by a reference method with effectively zero uncertainty and when $\\sigma_{\\mathrm{pt}}$ is unknown; in such cases with the given data, both standardized discrepancies would be identical in magnitude and near $0.33$.**\n-   **Evaluation**: The conditions for preference are overly restrictive and incorrect. The participant-specific approach is valuable even when $u_X$ is not zero. Furthermore, if $u_X$ were zero, the denominator for the participant-specific score would be $u_x = 0.3\\,\\%$, while the $z$-score denominator is $\\sigma_{\\mathrm{pt}} = 0.6\\,\\%$. The scores would *not* be identical; they would be $|-0.2/0.3| \\approx 0.67$ and $|-0.2/0.6| \\approx 0.33$.\n-   **Verdict**: **Incorrect**.\n\n**E. For low-level genomic measurands near the limit of detection, the traditional proficiency $z$-score is preferable because it down-weights assigned value uncertainty by using $\\sigma_{\\mathrm{pt}}$, thereby avoiding inflated scores; the participant-specific approach would over-penalize laboratories as the assigned value uncertainty increases.**\n-   **Evaluation**: This reasoning is inverted. The participant-specific score's denominator is $E_n = \\frac{x-X}{\\sqrt{u_x^2 + u_X^2}}$. As the assigned value uncertainty $u_X$ increases, the denominator *increases*, which *decreases* the magnitude of the score. This is a more forgiving evaluation, which is appropriate when the target is itself uncertain. The option incorrectly claims this approach \"over-penalizes\" labs. The $z$-score does not \"down-weight\" $u_X$; it *ignores* it completely.\n-   **Verdict**: **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "4373472"}]}