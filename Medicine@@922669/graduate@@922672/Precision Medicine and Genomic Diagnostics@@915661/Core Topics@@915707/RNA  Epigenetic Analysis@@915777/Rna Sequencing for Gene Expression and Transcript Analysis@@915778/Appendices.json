{"hands_on_practices": [{"introduction": "The foundation of a successful ribonucleic acid sequencing (RNA-seq) experiment lies in selecting a library preparation strategy that matches the quality of the biological sample. This is especially true for challenging clinical specimens like Formalin-Fixed Paraffin-Embedded (FFPE) tissues, which often yield degraded RNA. This practice problem [@problem_id:4378663] guides you through the critical decision between polyadenylated (poly(A)) transcript selection and ribosomal RNA (rRNA) depletion, demonstrating how initial sample quality dictates the optimal approach to ensure representative and uniform gene coverage.", "problem": "A molecular diagnostics laboratory is preparing ribonucleic acid sequencing (RNA-seq) libraries from a Formalin-Fixed Paraffin-Embedded (FFPE) tumor specimen for use in precision oncology. The Bioanalyzer trace indicates severely degraded total ribonucleic acid (RNA) with a modal fragment size of approximately $150$ nucleotides (nt). Two library preparation strategies are under consideration: polyadenylated transcript enrichment using oligodeoxythymidine (oligo(dT)) capture (polyA selection) versus ribosomal ribonucleic acid (rRNA) depletion followed by random priming.\n\nStarting from the Central Dogma of molecular biology (deoxyribonucleic acid (DNA) $\\rightarrow$ RNA $\\rightarrow$ protein) and the well-established facts that (i) polyadenylated tails reside at the $3^{\\prime}$ ends of most human messenger RNA (mRNA), (ii) rRNA comprises approximately $80$-$90\\%$ of total RNA in human cells, and (iii) FFPE processing causes fragmentation and crosslinking that shortens and chemically modifies RNA, answer the following:\n\n- Which library preparation approach is more appropriate for obtaining representative gene expression and transcript coverage from this FFPE RNA?\n- Under a simplified model in which fragmentation breakpoints are uniformly distributed along transcripts, estimate the fraction of fragments from a typical mRNA of length $L = 2{,}000$ nt that would contain the $3^{\\prime}$ polyadenylated region when the fragment length is $\\ell = 150$ nt. Use this to justify the choice regarding expected capture efficiency and coverage bias.\n- Based on the chosen approach and the stated degradation, predict the qualitative uniformity of coverage across transcript bodies (exonic regions), specifically whether $3^{\\prime}$ bias is expected to be increased, decreased, or minimized, and note any residual biases that may persist.\n\nChoose the single best option that integrates a scientifically justified choice and a correct coverage prediction.\n\nA. Select rRNA depletion with random priming; only about $7.5\\%$ of fragments from $L = 2{,}000$ nt transcripts will include the $3^{\\prime}$ polyA region when $\\ell = 150$ nt, making polyA selection inefficient in FFPE. Random priming yields approximately uniform coverage across transcript bodies with reduced $3^{\\prime}$ bias, albeit with residual sequence-context and fragment-size biases.\n\nB. Select polyA enrichment with oligo(dT); because polyA tails can be up to $200$ nt, most $\\ell = 150$ nt fragments will contain the tail, ensuring efficient capture and perfectly uniform coverage across transcripts without bias.\n\nC. Select rRNA depletion with random priming; coverage will be strongly biased to $3^{\\prime}$ ends because random primers preferentially bind near polyA tails in degraded RNA.\n\nD. Select polyA enrichment with oligo(dT); coverage will be concentrated at $5^{\\prime}$ ends due to capture of capped transcripts, which improves $5^{\\prime}$ representation in fragmented FFPE RNA.", "solution": "The user wants me to act as a meticulous STEM professor to solve a problem about RNA sequencing library preparation.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **Sample Type:** Formalin-Fixed Paraffin-Embedded (FFPE) tumor specimen.\n*   **Sample Quality:** Severely degraded total ribonucleic acid (`RNA`).\n*   **Fragment Size:** Modal fragment size is approximately $150$ nucleotides (nt).\n*   **Methods for Comparison:**\n    1.  Polyadenylated (`polyA`) transcript enrichment using oligodeoxythymidine (`oligo(dT)`) capture.\n    2.  Ribosomal ribonucleic acid (`rRNA`) depletion followed by random priming.\n*   **Provided Principles and Facts:**\n    *   The Central Dogma of molecular biology: $$DNA \\rightarrow RNA \\rightarrow protein$$\n    *   Fact (i): `polyA` tails are at the $3^{\\prime}$ ends of most human messenger `RNA` (`mRNA`).\n    *   Fact (ii): `rRNA` constitutes approximately $80$-$90\\%$ of total `RNA` in human cells.\n    *   Fact (iii): FFPE processing leads to `RNA` fragmentation, crosslinking, and chemical modification.\n*   **Tasks:**\n    1.  Choose the more appropriate library preparation approach for representative gene expression and transcript coverage.\n    2.  Estimate the fraction of fragments from a typical `mRNA` of length $L = 2{,}000$ nt that would contain the $3^{\\prime}$ `polyA` region, for a fragment length of $\\ell = 150$ nt, assuming uniform fragmentation breakpoints.\n    3.  Predict the qualitative uniformity of coverage and expected biases (`$3^{\\prime}$` bias).\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientifically Grounded:** The problem is firmly rooted in established principles of molecular biology and genomics. The scenario of working with degraded `RNA` from FFPE samples is a common, critical challenge in clinical diagnostics. The techniques described (`polyA` selection, `rRNA` depletion, random priming) are standard laboratory methods. The provided facts are correct.\n*   **Well-Posed:** The problem provides sufficient information to make a reasoned choice between the two methods and to perform the requested estimation. The question is clearly structured, leading from a choice of method to its quantitative and qualitative justification.\n*   **Objective:** The problem is framed in precise, technical language, free from subjectivity or bias.\n*   **Other Flaws:** The problem is complete, realistic, and its structure allows for a unique, logical solution. The simplified model for fragmentation (`uniform breakpoints`) is an acceptable and common simplification for estimation purposes in this context.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It is a well-posed, scientifically sound question typical of graduate-level molecular biology or bioinformatics. I will now proceed with the solution.\n\n### Solution Derivation\n\nThe problem requires a three-part answer: the selection of the appropriate method, a quantitative justification, and a qualitative prediction of sequencing coverage.\n\n**1. Selection of Library Preparation Approach**\n\nThe defining characteristic of the starting material is that it is severely degraded, with `RNA` molecules fragmented into small pieces of approximately $150$ nt. We must evaluate the two proposed methods in this context.\n\n*   **`polyA` Selection via `oligo(dT)` Capture:** This method specifically targets the `polyA` tail found at the extreme $3^{\\prime}$ end of mature `mRNA` molecules. When an `mRNA` transcript is intact, this is an effective way to enrich for `mRNA` and initiate reverse transcription from a defined point. However, with severely fragmented `RNA`, the vast majority of the fragments originating from a single `mRNA` molecule will not contain the $3^{\\prime}$ end and, consequently, will lack the `polyA` tail. Only the fragment(s) derived from the very end of the original transcript will be captured. This leads to two major problems:\n    1.  **Inefficiency:** A large proportion of `mRNA` material is lost because most fragments are not captured.\n    2.  **Severe Bias:** The resulting sequence data will be heavily skewed towards the $3^{\\prime}$ end of transcripts, providing a poor and non-representative view of the gene's overall expression and structure (e.g., splice variants).\n\n*   **`rRNA` Depletion with Random Priming:** This method first addresses the issue of abundance by removing the non-coding `rRNA`, which makes up $80$-$90\\%$ of total cellular `RNA`. This step enriches for all other `RNA` types, including fragmented `mRNA`. Subsequently, random primers (short oligonucleotides of random sequence, e.g., hexamers) are used to initiate reverse transcription. These primers can anneal at any complementary location along the length of any `RNA` fragment. This has significant advantages for degraded samples:\n    1.  **Efficiency:** It allows for the conversion of all `RNA` fragments into complementary `DNA` (cDNA), regardless of their original position in the full-length transcript. This captures information from the entire length of the genes.\n    2.  **Uniformity:** By priming randomly across all fragments, this approach theoretically samples the entire transcript body, leading to more uniform sequencing coverage and minimizing the $3^{\\prime}$ bias inherent in `polyA` selection methods.\n\n**Conclusion:** For severely degraded FFPE `RNA`, `rRNA` depletion followed by random priming is the vastly superior method for obtaining representative gene expression data.\n\n**2. Estimation of Capture Efficiency for `polyA` Selection**\n\nWe are asked to estimate the fraction of fragments from an `mRNA` of length $L = 2{,}000$ nt that would contain the $3^{\\prime}$ `polyA` region, given a fragment length of $\\ell = 150$ nt.\n\nThe model states that fragmentation breakpoints are uniformly distributed. This implies that any nucleotide position along the transcript is equally likely to be included in a resulting fragment. A fragment can be captured by `oligo(dT)` only if it is derived from the region of the original transcript that includes the $3^{\\prime}$ `polyA` tail. The fragments that contain this tail must originate from the $3^{\\prime}$-most portion of the transcript. The length of this source region is approximately the length of the fragments themselves, $\\ell$.\n\nTherefore, the fraction of fragments that will contain the `polyA` region can be estimated as the ratio of the length of the $3^{\\prime}$-end source region to the total length of the transcript:\n\n$$ \\text{Fraction} \\approx \\frac{\\ell}{L} $$\n\nSubstituting the given values:\n\n$$ \\text{Fraction} \\approx \\frac{150 \\text{ nt}}{2{,}000 \\text{ nt}} = \\frac{15}{200} = \\frac{3}{40} = 0.075 $$\n\nThis corresponds to $7.5\\%$. This calculation demonstrates the low efficiency of `polyA` selection: over $90\\%$ of the `mRNA` fragments would be discarded, leading to a significant loss of information. This quantitative estimate strongly supports the choice of the `rRNA` depletion method.\n\n**3. Prediction of Coverage Uniformity**\n\nBased on the chosen approach (`rRNA` depletion with random priming) and the severe `RNA` degradation:\n\n*   **Coverage Uniformity:** The use of random primers is specifically designed to overcome the limitations of `oligo(dT)` priming on degraded `RNA`. By initiating cDNA synthesis from locations throughout each fragment, information from all parts of the original transcripts can be recovered. This leads to **approximately uniform coverage** across the transcript bodies (exons).\n*   **`$3^{\\prime}$ Bias:** Compared to the extreme `$3^{\\prime}$` skewing that would result from `polyA` selection, the random priming approach leads to a significant **reduction or minimization of `$3^{\\prime}$` bias**.\n*   **Residual Biases:** No `RNA-seq` protocol is perfect. The random priming approach is still subject to certain biases. \"Random\" primers do not anneal with perfect uniformity; they exhibit sequence-specific affinities (e.g., related to `$GC$` content), leading to **sequence-context bias**. Furthermore, the enzymes used for reverse transcription and amplification can have their own biases. The fragmentation process itself may not be perfectly random. Therefore, some level of **residual bias** is expected to persist in the final data.\n\n### Option-by-Option Analysis\n\n**A. Select rRNA depletion with random priming; only about $7.5\\%$ of fragments from $L = 2{,}000$ nt transcripts will include the $3^{\\prime}$ polyA region when $\\ell = 150$ nt, making polyA selection inefficient in FFPE. Random priming yields approximately uniform coverage across transcript bodies with reduced $3^{\\prime}$ bias, albeit with residual sequence-context and fragment-size biases.**\nThis option correctly identifies `rRNA` depletion with random priming as the best method. The calculation of `polyA` capture inefficiency as $\\approx 7.5\\%$ is correct based on a reasonable estimation model. The description of the resulting coverage—approximately uniform, with reduced `$3^{\\prime}$` bias and the presence of residual biases—is accurate.\n**Verdict: Correct.**\n\n**B. Select polyA enrichment with oligo(dT); because polyA tails can be up to $200$ nt, most $\\ell = 150$ nt fragments will contain the tail, ensuring efficient capture and perfectly uniform coverage across transcripts without bias.**\nThis option selects the inappropriate method for degraded `RNA`. The reasoning is flawed; the length of the `polyA` tail is irrelevant to the probability that a random fragment from a long transcript will contain it. The claim of \"efficient capture\" is wrong, as shown by the $7.5\\%$ estimate. The claim of \"perfectly uniform coverage\" is also incorrect; this method would produce extreme `$3^{\\prime}$` bias.\n**Verdict: Incorrect.**\n\n**C. Select rRNA depletion with random priming; coverage will be strongly biased to $3^{\\prime}$ ends because random primers preferentially bind near polyA tails in degraded RNA.**\nThis option correctly selects the method but provides a completely incorrect justification for the coverage profile. The defining characteristic of random primers is that they bind *randomly*, not preferentially near `polyA` tails. This statement describes the outcome of `oligo(dT)` priming, not random priming. The method is chosen to *avoid* a strong `$3^{\\prime}$` bias.\n**Verdict: Incorrect.**\n\n**D. Select polyA enrichment with oligo(dT); coverage will be concentrated at $5^{\\prime}$ ends due to capture of capped transcripts, which improves $5^{\\prime}$ representation in fragmented FFPE RNA.**\nThis option selects the incorrect method. The mechanism described is also incorrect. `polyA` selection targets the `$3^{\\prime}$` polyadenylated tail, not the `$5^{\\prime}$` cap. Therefore, any resulting bias would be towards the `$3^{\\prime}$` end, not the `$5^{\\prime}$` end.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "4378663"}, {"introduction": "Following library preparation and sequencing, rigorous quality control (QC) is essential to determine if the generated data is suitable for downstream analysis. This exercise [@problem_id:4378616] presents a common real-world scenario where an initial sequencing run yields suboptimal results due to factors like high rRNA contamination. You will learn to quantitatively assess the 'usable' sequencing depth and perform a cost-benefit analysis to choose the most effective and economical path forward, highlighting the iterative nature of experimental genomics.", "problem": "A clinical transcriptome profiling project in precision oncology uses ribonucleic acid sequencing (RNA-seq, RNA sequencing) to quantify messenger ribonucleic acid (mRNA) gene expression from tumor tissue. The existing library was sequenced to a total of $N_{0} = 80 \\times 10^{6}$ paired-end fragments. Quality control removed a fraction $0.04$ of raw fragments. Post hoc alignment revealed that a fraction $0.30$ of reads maps to ribosomal ribonucleic acid (rRNA), which cannot be used for mRNA quantification. Of the non-rRNA reads, a fraction $0.96$ aligns to the genome, and among aligned reads, a fraction $0.72$ overlaps annotated exons of protein-coding genes. Of the exonic alignments, a fraction $0.12$ is multi-mapping and excluded from quantification, and the deduplication step removes a fraction $0.18$ as polymerase chain reaction (PCR) duplicates. Assume these filters act independently on a per-fragment basis.\n\nPrecision medicine analytics for isoform-level differential expression requires at least $T = 45 \\times 10^{6}$ usable, unique, exonic fragments across all libraries combined. You may either resequence the existing library or remake the library with improved rRNA depletion. Assume the following:\n\n- Resequencing the existing library preserves all fractions given above, costs $c = 38$ United States Dollars (USD) per $10^{6}$ raw paired-end fragments, and has no additional fixed cost.\n- Remaking the library improves the rRNA mapping fraction from $0.30$ to $0.05$ and the duplicate fraction from $0.18$ to $0.10$, while all other fractions remain the same as above. This option costs the same $c = 38$ USD per $10^{6}$ raw paired-end fragments plus a fixed library preparation cost of $C_{\\text{lib}} = 500$ USD.\n- The budget cap is $B = 2000$ USD. You may combine reads from the existing library and the new sequencing performed under either strategy, but you must choose only one strategy.\n\nStarting from first principles in RNA-seq quantification and probability, compute the effective usable depth (in $10^{6}$ usable fragments) in the existing dataset, then determine the minimal total cost in USD to reach the target $T$ by choosing the cost-feasible strategy that meets or exceeds $T$. Round your final cost to four significant figures. Express the final cost in USD. Do not use the percentage sign anywhere; express all fractions as decimals or ratios. Assume paired-end fragments are counted as units throughout.", "solution": "The problem requires a quantitative analysis of an RNA sequencing experiment to determine the most cost-effective strategy to achieve a target number of usable sequencing fragments. The solution involves three main steps: first, calculating the current number of usable fragments from the initial dataset; second, modeling the two proposed strategies to determine the cost of reaching the target; and third, selecting the minimal cost strategy that is within the specified budget.\n\nLet $N_{\\text{raw}}$ be the number of raw paired-end fragments. The number of usable fragments, $N_{\\text{usable}}$, is obtained after a series of filtering steps. As these filters are assumed to act independently, the final number of usable fragments can be calculated by multiplying the initial number of fragments by a series of retention fractions. The overall yield, $\\eta$, is the product of these fractions.\n\nThe filtering steps and their corresponding retention fractions are:\n1. Quality Control (QC): A fraction $f_{\\text{qc}} = 0.04$ is removed, so the retention fraction is $(1 - f_{\\text{qc}})$.\n2. Ribosomal RNA (rRNA) mapping: A fraction $f_{\\text{rRNA}}$ maps to rRNA and is discarded. The retention fraction is $(1 - f_{\\text{rRNA}})$.\n3. Genome alignment: A fraction $f_{\\text{align}}$ of non-rRNA reads aligns to the genome. This is a success fraction, not a removal fraction.\n4. Exonic overlap: A fraction $f_{\\text{exon}}$ of aligned reads overlaps exons. This is also a success fraction.\n5. Multi-mapping removal: A fraction $f_{\\text{multi}}$ of exonic reads is multi-mapping and is removed. The retention fraction is $(1 - f_{\\text{multi}})$.\n6. PCR duplicate removal: A fraction $f_{\\text{pcr}}$ is removed. The retention fraction is $(1 - f_{\\text{pcr}})$.\n\nThe formula for the overall yield fraction $\\eta$ is:\n$$ \\eta = (1 - f_{\\text{qc}}) \\times (1 - f_{\\text{rRNA}}) \\times f_{\\text{align}} \\times f_{\\text{exon}} \\times (1 - f_{\\text{multi}}) \\times (1 - f_{\\text{pcr}}) $$\n\nFirst, we calculate the effective usable depth from the existing library.\nThe given parameters for the initial library are:\n$N_0 = 80 \\times 10^6$\n$f_{\\text{qc}} = 0.04$\n$f_{\\text{rRNA}} = 0.30$\n$f_{\\text{align}} = 0.96$\n$f_{\\text{exon}} = 0.72$\n$f_{\\text{multi}} = 0.12$\n$f_{\\text{pcr}} = 0.18$\n\nThe yield fraction for the existing library, $\\eta_0$, is:\n$$ \\eta_0 = (1 - 0.04) \\times (1 - 0.30) \\times 0.96 \\times 0.72 \\times (1 - 0.12) \\times (1 - 0.18) $$\n$$ \\eta_0 = 0.96 \\times 0.70 \\times 0.96 \\times 0.72 \\times 0.88 \\times 0.82 $$\n$$ \\eta_0 \\approx 0.335173386 $$\n\nThe number of usable fragments in the existing dataset, $N_{\\text{usable,0}}$, is:\n$$ N_{\\text{usable,0}} = N_0 \\times \\eta_0 = (80 \\times 10^6) \\times 0.335173386 \\approx 26,813,871 \\text{ fragments} $$\nThe effective usable depth in the existing dataset is approximately $26.81 \\times 10^6$ fragments.\n\nThe target is $T = 45 \\times 10^6$ usable fragments. The number of additional usable fragments required is:\n$$ \\Delta N_{\\text{usable}} = T - N_{\\text{usable,0}} = 45 \\times 10^6 - 26,813,871 = 18,186,129 \\text{ fragments} $$\n\nNow, we evaluate the two strategies to obtain these additional fragments.\n\nStrategy 1: Resequence the existing library.\nThis strategy uses the same library, so the yield fraction remains $\\eta_0 \\approx 0.335173$. Let $N_{\\text{reseq}}$ be the number of additional raw fragments needed.\n$$ N_{\\text{reseq}} = \\frac{\\Delta N_{\\text{usable}}}{\\eta_0} = \\frac{18,186,129}{0.335173} \\approx 54,258,515 \\text{ raw fragments} $$\nThe cost is $c = 38$ USD per $10^6$ raw fragments. There is no fixed cost.\n$$ C_1 = \\left( \\frac{N_{\\text{reseq}}}{10^6} \\right) \\times c = \\left( \\frac{54,258,515}{10^6} \\right) \\times 38 \\approx 54.2585 \\times 38 \\approx 2061.82 \\text{ USD} $$\nThe budget is $B = 2000$ USD. Since $C_1 > B$, this strategy is not feasible.\n\nStrategy 2: Remake the library and sequence.\nThis strategy has improved rRNA depletion and PCR duplicate rates. The new parameters are:\n$f'_{\\text{rRNA}} = 0.05$\n$f'_{\\text{pcr}} = 0.10$\nAll other fractions remain the same. The new yield fraction, $\\eta_1$, is:\n$$ \\eta_1 = (1 - 0.04) \\times (1 - 0.05) \\times 0.96 \\times 0.72 \\times (1 - 0.12) \\times (1 - 0.10) $$\n$$ \\eta_1 = 0.96 \\times 0.95 \\times 0.96 \\times 0.72 \\times 0.88 \\times 0.90 $$\n$$ \\eta_1 \\approx 0.499256525 $$\nThe number of new raw fragments needed, $N_{\\text{newlib}}$, is:\n$$ N_{\\text{newlib}} = \\frac{\\Delta N_{\\text{usable}}}{\\eta_1} = \\frac{18,186,129}{0.499256525} \\approx 36,426,463 \\text{ raw fragments} $$\nThe cost for this strategy includes a fixed library preparation cost of $C_{\\text{lib}} = 500$ USD and a variable sequencing cost.\n$$ C_{2,\\text{variable}} = \\left( \\frac{N_{\\text{newlib}}}{10^6} \\right) \\times c = \\left( \\frac{36,426,463}{10^6} \\right) \\times 38 \\approx 36.4265 \\times 38 \\approx 1384.21 \\text{ USD} $$\nThe total cost for Strategy 2 is:\n$$ C_2 = C_{\\text{lib}} + C_{2,\\text{variable}} = 500 + 1384.21 = 1884.21 \\text{ USD} $$\nSince $C_2 < B$, this strategy is financially feasible.\n\nComparing the two strategies, only Strategy 2 is feasible within the budget. Therefore, the minimal cost to reach the target is the cost of Strategy 2.\nMinimal cost $\\approx 1884.21$ USD.\nThe problem asks for this value to be rounded to four significant figures.\n$1884.21$ rounded to four significant figures is $1884$.", "answer": "$$\\boxed{1884}$$", "id": "4378616"}, {"introduction": "Once high-quality data is secured, raw read counts must be transformed into normalized expression values for accurate biological interpretation. This exercise [@problem_id:4378618] focuses on a fundamental step in this process: correcting for gene length bias. By calculating Transcripts Per Million (TPM), you will see firsthand how this method accounts for the fact that longer genes naturally produce more reads, a crucial correction for comparing the expression levels of different genes within the same sample.", "problem": "In short-read RNA sequencing (RNA-seq) for precision oncology, raw read counts depend on both transcript abundance and the probability of sampling fragments from longer molecules. This induces a length bias that must be removed to compare gene expression levels within a sample. Consider a single tumor RNA-seq sample in which three genes, $G_1$, $G_2$, and $G_3$, have been quantified by a standard pipeline that reports raw fragment counts and per-gene effective lengths (in kilobases) that already account for fragment length distribution and mappability. The observed raw counts and effective lengths are:\n- $G_1$: count $= 1250$, effective length $= 1.9$ kilobases,\n- $G_2$: count $= 2100$, effective length $= 10.7$ kilobases,\n- $G_3$: count $= 480$, effective length $= 0.9$ kilobases.\n\nUsing only the formal definition that Transcripts Per Million (TPM) is obtained by normalizing counts by effective length and scaling so that the values for all features under consideration sum to one million within the sample, do the following:\n1) Compute the TPM values for $G_1$, $G_2$, and $G_3$ for this sample.\n2) Let the naive relative expression be the ratio of raw counts $G_2/G_1$, and the length-corrected relative expression be the ratio of TPM values $G_2/G_1$. Define the multiplicative distortion factor $D$ as the naive ratio divided by the length-corrected ratio.\n\nReport as your final answer the value of $D$, rounded to four significant figures. Express the final answer as a unitless decimal (no units).", "solution": "The problem statement has been validated and found to be scientifically grounded, well-posed, objective, and internally consistent. It describes a standard normalization procedure in bioinformatics, specifically RNA sequencing data analysis, and all provided data and definitions are appropriate for the context. We may therefore proceed with the solution.\n\nLet $C_i$ denote the raw fragment count and $L_i$ denote the effective length in kilobases for each gene $G_i$, where $i \\in \\{1, 2, 3\\}$. The given values are:\n-   For gene $G_1$: $C_1 = 1250$, $L_1 = 1.9$ kb.\n-   For gene $G_2$: $C_2 = 2100$, $L_2 = 10.7$ kb.\n-   For gene $G_3$: $C_3 = 480$, $L_3 = 0.9$ kb.\n\nThe problem requires the calculation of a multiplicative distortion factor, $D$. This factor is defined as the ratio of the naive relative expression to the length-corrected relative expression.\n\nFirst, let us define the terms as per the problem statement.\nThe naive relative expression of $G_2$ to $G_1$ is the ratio of their raw counts:\n$$\nR_{\\text{naive}} = \\frac{C_2}{C_1}\n$$\n\nThe length-corrected relative expression is the ratio of their Transcripts Per Million (TPM) values. The definition of TPM for a gene $i$ within a set of considered genes is a two-step process:\n1.  Normalize the raw count $C_i$ by the effective length $L_i$. This gives a rate of fragments per kilobase, let's call it $r_i$:\n    $$\n    r_i = \\frac{C_i}{L_i}\n    $$\n2.  Scale these rates such that their sum across all considered genes ($G_1, G_2, G_3$) equals one million ($10^6$). The TPM for gene $i$ is thus:\n    $$\n    \\text{TPM}_i = \\frac{r_i}{\\sum_{j=1}^{3} r_j} \\times 10^6\n    $$\n    Substituting the expression for $r_i$, we get:\n    $$\n    \\text{TPM}_i = \\frac{C_i/L_i}{\\sum_{j=1}^{3} (C_j/L_j)} \\times 10^6\n    $$\n\nThe length-corrected relative expression of $G_2$ to $G_1$ is the ratio of their TPM values:\n$$\nR_{\\text{corrected}} = \\frac{\\text{TPM}_2}{\\text{TPM}_1}\n$$\nWe can substitute the formal definition of TPM into this ratio:\n$$\nR_{\\text{corrected}} = \\frac{\\frac{C_2/L_2}{\\sum_{j=1}^{3} (C_j/L_j)} \\times 10^6}{\\frac{C_1/L_1}{\\sum_{j=1}^{3} (C_j/L_j)} \\times 10^6}\n$$\nThe scaling factor ($10^6$) and the sum of rates in the denominator ($\\sum_{j=1}^{3} (C_j/L_j)$) are common to both the numerator and the denominator of this fraction, so they cancel out. This simplifies the expression for the corrected ratio significantly:\n$$\nR_{\\text{corrected}} = \\frac{C_2/L_2}{C_1/L_1} = \\frac{C_2 L_1}{C_1 L_2}\n$$\n\nNow we can define the multiplicative distortion factor $D$ as specified:\n$$\nD = \\frac{R_{\\text{naive}}}{R_{\\text{corrected}}}\n$$\nSubstituting our derived expressions for $R_{\\text{naive}}$ and $R_{\\text{corrected}}$:\n$$\nD = \\frac{C_2/C_1}{(C_2 L_1)/(C_1 L_2)}\n$$\nThis expression can be simplified by multiplying the numerator by the reciprocal of the denominator:\n$$\nD = \\frac{C_2}{C_1} \\cdot \\frac{C_1 L_2}{C_2 L_1}\n$$\nThe count terms $C_1$ and $C_2$ cancel out, leaving a remarkably simple result:\n$$\nD = \\frac{L_2}{L_1}\n$$\nThis result demonstrates that the distortion introduced by ignoring gene length is precisely the ratio of the effective lengths of the genes being compared. It is not necessary to calculate the individual TPM values for any of the genes to find $D$.\n\nWe can now substitute the given values for the effective lengths of $G_1$ and $G_2$ to find the numerical value of $D$:\n-   $L_1 = 1.9$ kb\n-   $L_2 = 10.7$ kb\n\n$$\nD = \\frac{10.7}{1.9}\n$$\nPerforming the division:\n$$\nD \\approx 5.6315789...\n$$\nThe problem requires the final answer to be rounded to four significant figures.\n$$\nD \\approx 5.632\n$$\nThe distortion factor is a unitless quantity, as the units of length (kilobases) cancel in the ratio. This indicates that the naive count-based ratio overestimates the relative expression of $G_1$ compared to $G_2$ by a factor of approximately $5.632$, or conversely, it underestimates the relative expression of $G_2$ to $G_1$ by the same factor, due to the much larger effective length of $G_2$.", "answer": "$$\\boxed{5.632}$$", "id": "4378618"}]}