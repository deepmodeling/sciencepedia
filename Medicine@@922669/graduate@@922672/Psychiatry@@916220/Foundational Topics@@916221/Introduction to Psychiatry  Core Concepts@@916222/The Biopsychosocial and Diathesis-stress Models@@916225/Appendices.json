{"hands_on_practices": [{"introduction": "To truly master the diathesis-stress framework, one must first grasp its mathematical formalization. This exercise guides you through the derivation of a logistic risk function that includes an interaction term, demonstrating how the synergistic effect of diathesis ($D$) and stress ($S$) is captured. By exploring the meaning of the interaction coefficient $\\beta_{DS}$ on the odds ratio scale, you will build a foundational intuition for how these models operate [@problem_id:4765951].", "problem": "A central claim of the diathesis-stress framework in psychiatry is that the probability of onset of a disorder depends on both an individual’s diathesis (trait-like vulnerability) and environmental stress, and that their joint effect may not be purely additive. Consider a binary onset indicator $Y \\in \\{0,1\\}$ for a disorder within a fixed observation window, with $Y=1$ indicating onset. Let $D \\in \\mathbb{R}$ denote a continuous diathesis score and $S \\in \\mathbb{R}$ denote a continuous stress exposure score.\n\nUse the following foundational modeling assumptions:\n- The onset indicator $Y$ is modeled as a Bernoulli random variable with success probability $p(D,S)$.\n- The odds of onset are defined as $\\frac{p(D,S)}{1 - p(D,S)}$.\n- The log-odds (logit) link used in a generalized linear model (GLM) with a Bernoulli outcome relates the expected value to a linear predictor via the transformation $\\ln\\!\\left(\\frac{p(D,S)}{1 - p(D,S)}\\right)$.\n- In the spirit of the diathesis-stress model, suppose the linear predictor is additive in the main effects of $D$ and $S$ and includes their product to allow for interaction.\n\nTasks:\n1) Starting solely from the definitions above and the additivity of the linear predictor on the log-odds scale, derive the closed-form expression for the risk function $p(D,S)$ that includes an intercept and linear main effects of $D$ and $S$ plus their interaction. Express the result in terms of coefficients $\\beta_{0}$, $\\beta_{D}$, $\\beta_{S}$, and $\\beta_{DS}$.\n\n2) Define the stress odds ratio at a fixed diathesis level $D$ for a one-unit increase in stress as\n$$\\mathrm{OR}_{S}(D) \\equiv \\frac{\\text{odds of onset at }(D,S+1)}{\\text{odds of onset at }(D,S)}.$$\nDerive $\\mathrm{OR}_{S}(D)$ in terms of the coefficients.\n\n3) Define the moderation strength of diathesis on the effect of stress as the ratio of stress odds ratios when diathesis increases by one unit:\n$$M \\equiv \\frac{\\mathrm{OR}_{S}(D+1)}{\\mathrm{OR}_{S}(D)}.$$\nProvide a simplified, closed-form analytic expression for $M$ in terms of the model coefficients. Report only this final expression as your answer. Do not include units. If you arrive at a numerical value during intermediate steps, do not round; the final deliverable is a symbolic expression.", "solution": "The problem asks for a derivation of three quantities related to a logistic regression model formalizing the diathesis-stress framework. The model predicts the probability of disorder onset, $p(D,S)$, based on a continuous diathesis score, $D$, and a continuous stress score, $S$.\n\nThe foundational assumptions are:\n1.  The onset $Y$ is a Bernoulli trial with probability of success $p(D,S)$.\n2.  The model uses a logit link function, meaning the log-odds of onset is a linear function of the predictors.\n3.  The linear predictor, $\\eta(D,S)$, includes an intercept, main effects for $D$ and $S$, and their interaction term.\n\nFirst, we write the expression for the linear predictor $\\eta(D,S)$ using the given coefficients $\\beta_{0}$, $\\beta_{D}$, $\\beta_{S}$, and $\\beta_{DS}$:\n$$ \\eta(D,S) = \\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS $$\n\nThe logit link function states that the log-odds are equal to this linear predictor:\n$$ \\ln\\left(\\frac{p(D,S)}{1 - p(D,S)}\\right) = \\eta(D,S) = \\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS $$\n\nTask 1: Derive the closed-form expression for the risk function $p(D,S)$.\nTo find $p(D,S)$, we must invert the logit transformation. First, we exponentiate both sides of the equation to solve for the odds, $\\frac{p(D,S)}{1 - p(D,S)}$:\n$$ \\frac{p(D,S)}{1 - p(D,S)} = \\exp(\\eta(D,S)) = \\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS) $$\nFor algebraic convenience, let $p = p(D,S)$ and $E = \\exp(\\eta(D,S))$. The equation becomes:\n$$ \\frac{p}{1-p} = E $$\nSolving for $p$:\n$$ p = E(1-p) \\implies p = E - Ep \\implies p + Ep = E \\implies p(1+E) = E \\implies p = \\frac{E}{1+E} $$\nSubstituting the expression for $E$ back, we obtain the risk function:\n$$ p(D,S) = \\frac{\\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS)}{1 + \\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS)} $$\nThis is the required expression for Task 1.\n\nTask 2: Derive the stress odds ratio $\\mathrm{OR}_{S}(D)$.\nThe stress odds ratio is defined for a one-unit increase in stress $S$ at a fixed level of diathesis $D$:\n$$ \\mathrm{OR}_{S}(D) \\equiv \\frac{\\text{odds of onset at }(D,S+1)}{\\text{odds of onset at }(D,S)} $$\nFrom our previous step, the odds are given by $\\exp(\\eta(D,S))$.\nThe odds at $(D, S+1)$ are:\n$$ \\text{odds}(D,S+1) = \\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}(S+1) + \\beta_{DS}D(S+1)) $$\n$$ = \\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{S} + \\beta_{DS}DS + \\beta_{DS}D) $$\nThe odds at $(D, S)$ are:\n$$ \\text{odds}(D,S) = \\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS) $$\nWe form the ratio:\n$$ \\mathrm{OR}_{S}(D) = \\frac{\\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{S} + \\beta_{DS}DS + \\beta_{DS}D)}{\\exp(\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS)} $$\nUsing the exponential property $\\frac{\\exp(a)}{\\exp(b)} = \\exp(a-b)$, the exponent of the resulting expression is the difference between the numerator's exponent and the denominator's exponent:\n$$ (\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{S} + \\beta_{DS}DS + \\beta_{DS}D) - (\\beta_{0} + \\beta_{D}D + \\beta_{S}S + \\beta_{DS}DS) = \\beta_{S} + \\beta_{DS}D $$\nThus, the stress odds ratio is:\n$$ \\mathrm{OR}_{S}(D) = \\exp(\\beta_{S} + \\beta_{DS}D) $$\n\nTask 3: Derive the moderation strength $M$.\nThe final task is to find a simplified expression for the moderation strength $M$, defined as:\n$$ M \\equiv \\frac{\\mathrm{OR}_{S}(D+1)}{\\mathrm{OR}_{S}(D)} $$\nWe use the result from Task 2. The numerator is found by substituting $D+1$ into the expression for $\\mathrm{OR}_{S}(D)$:\n$$ \\mathrm{OR}_{S}(D+1) = \\exp(\\beta_{S} + \\beta_{DS}(D+1)) = \\exp(\\beta_{S} + \\beta_{DS}D + \\beta_{DS}) $$\nThe denominator is the expression for $\\mathrm{OR}_{S}(D)$ itself:\n$$ \\mathrm{OR}_{S}(D) = \\exp(\\beta_{S} + \\beta_{DS}D) $$\nForming the ratio for $M$:\n$$ M = \\frac{\\exp(\\beta_{S} + \\beta_{DS}D + \\beta_{DS})}{\\exp(\\beta_{S} + \\beta_{DS}D)} $$\nAgain, we subtract the exponents:\n$$ (\\beta_{S} + \\beta_{DS}D + \\beta_{DS}) - (\\beta_{S} + \\beta_{DS}D) = \\beta_{DS} $$\nTherefore, the simplified, closed-form expression for the moderation strength $M$ is:\n$$ M = \\exp(\\beta_{DS}) $$\nThis result shows that in this specific log-linear model of interaction, the moderation strength $M$ is constant and depends only on the interaction coefficient $\\beta_{DS}$. This is the final expression required by the problem.", "answer": "$$\n\\boxed{\\exp(\\beta_{DS})}\n$$", "id": "4765951"}, {"introduction": "With a theoretical understanding of the model's structure, the next logical step is to apply it to a practical scenario. This problem provides coefficients from a hypothetical psychiatric cohort study and asks you to calculate an individual's specific risk of developing a major depressive episode given their polygenic risk score ($PRS$) and stress level ($S$). This practice translates abstract statistical parameters into a concrete, clinically relevant probability, highlighting the model's utility in personalized risk assessment [@problem_id:4765949].", "problem": "A prospective cohort study of first-onset major depressive episode over a $12$-month period is modeled under the diathesis-stress framework, which posits that the probability of onset depends on an individual's vulnerability (diathesis) and exposure to stress. In this cohort, diathesis is operationalized as a standardized Polygenic Risk Score (PRS) in standard deviation units, and stress exposure is summarized as a continuous stress index $S$ on a validated $0$ to $3$ scale. To link predictors to onset probability, the study uses a logistic regression consistent with the diathesis-stress model and a Gene-by-Environment (G$\\times$E) interaction:\n$$\n\\mathrm{logit}(p) \\equiv \\ln\\!\\left(\\frac{p}{1-p}\\right) = \\beta_{0} + \\beta_{G}\\,PRS + \\beta_{S}\\,S + \\beta_{G\\times E}\\,PRS\\cdot S,\n$$\nwhere $p$ is the probability of episode onset within $12$ months.\n\nSuppose the population-representative training data for this cohort yielded the following coefficients: $\\beta_{0} = -3.2$, $\\beta_{G} = 0.45$, $\\beta_{S} = 0.55$, and $\\beta_{G\\times E} = 0.20$. For an individual with $PRS = 1.2$ and $S = 2.0$:\n\n1. Starting from the core definitions of the diathesis-stress framework and the properties of the logistic link, derive the analytic expression for the predicted onset probability $p$ in terms of the linear predictor and the inverse-logit transformation, then compute its numerical value for the given $PRS$ and $S$.\n2. Briefly interpret the clinical relevance of the resulting probability with respect to the baseline risk implied by $\\beta_{0}$ and the sign of $\\beta_{G\\times E}$.\n\nExpress the predicted probability $p$ as a unitless scalar in $[0,1]$ and round your final numerical answer to four significant figures.", "solution": "This problem requires us to calculate the probability of a major depressive episode for a specific individual using a given logistic regression model that formalizes the diathesis-stress hypothesis. The solution involves two main parts: first, computing the numerical probability, and second, interpreting its clinical relevance.\n\n**Part 1: Calculation of the Onset Probability**\n\nThe model links the predictors to the probability of onset, $p$, through the logit function:\n$$ \\ln\\left(\\frac{p}{1-p}\\right) = \\beta_{0} + \\beta_{G}\\,PRS + \\beta_{S}\\,S + \\beta_{G\\times E}\\,PRS \\cdot S $$\nTo find the probability $p$, we first calculate the linear predictor, $\\eta$, for the given individual ($PRS = 1.2$, $S = 2.0$) using the provided coefficients:\n$$ \\eta = \\beta_{0} + \\beta_{G}\\,PRS + \\beta_{S}\\,S + \\beta_{G\\times E}\\,PRS \\cdot S $$\n$$ \\eta = -3.2 + (0.45)(1.2) + (0.55)(2.0) + (0.20)(1.2)(2.0) $$\n$$ \\eta = -3.2 + 0.54 + 1.10 + 0.48 = -1.08 $$\nNext, we apply the inverse-logit (logistic sigmoid) transformation to find $p$:\n$$ p = \\frac{1}{1 + \\exp(-\\eta)} $$\nSubstituting the value of $\\eta$:\n$$ p = \\frac{1}{1 + \\exp(-(-1.08))} = \\frac{1}{1 + \\exp(1.08)} \\approx \\frac{1}{1 + 2.94468} = \\frac{1}{3.94468} \\approx 0.253496 $$\nRounding to four significant figures, the predicted probability of onset is $0.2535$.\n\n**Part 2: Interpretation of Clinical Relevance**\n\n1.  **Comparison to Baseline Risk:** The intercept, $\\beta_0 = -3.2$, gives the log-odds of onset for an individual with $PRS=0$ and $S=0$. The corresponding baseline probability is $p_{baseline} = (1 + \\exp(3.2))^{-1} \\approx 0.039$, or a $3.9\\%$ risk. The individual's calculated risk of $25.35\\%$ is substantially higher (over 6.5 times the baseline), highlighting the combined impact of their genetic predisposition and stress exposure.\n\n2.  **Role of the Interaction Term:** The coefficient for the interaction, $\\beta_{G\\times E} = 0.20$, is positive. This mathematically confirms the diathesis-stress hypothesis: stress has a stronger adverse effect on individuals with higher genetic vulnerability. For this person, the interaction term contributes $0.20 \\times 1.2 \\times 2.0 = 0.48$ to the log-odds, significantly increasing their risk beyond what would be predicted by the main effects of genes and stress alone. This synergistic effect demonstrates that the combination of diathesis and stress is more pathogenic than the sum of its parts.", "answer": "$$\n\\boxed{0.2535}\n$$", "id": "4765949"}, {"introduction": "The Biopsychosocial and Diathesis-Stress models represent competing views on how risk factors combine—additively versus interactively. In clinical research, how do we decide which model provides a better explanation or more accurate predictions? This final, advanced practice introduces cross-validation, a cornerstone of modern data science, to empirically evaluate and select the superior model based on its out-of-sample predictive performance [@problem_id:4766024]. This exercise equips you with a crucial skill for critically appraising and developing evidence-based predictive tools in psychiatry.", "problem": "You are given two competing probabilistic models for predicting binary clinical outcomes that are grounded in psychiatric theory. The first is the Biopsychosocial Model, which posits that biological, psychological, and social variables each contribute additively to the risk of disorder. The second is the Diathesis-Stress Model, which posits that vulnerability (diathesis) and environmental stress interact multiplicatively to shape risk. Your task is to implement $k$-fold cross-validation of logistic regression for each model, compute out-of-sample predictive performance via average per-sample negative log-likelihood, and decide which model should guide clinical decision-making for each provided test case.\n\nFundamental definitions and assumptions:\n- Let $y_i \\in \\{0,1\\}$ denote the binary outcome for individual $i$, where $y_i = 1$ represents the occurrence of a depressive episode and $y_i = 0$ represents its absence.\n- Let $\\sigma(z)$ be the logistic (sigmoid) function defined by $\\sigma(z) = \\dfrac{1}{1 + e^{-z}}$.\n- For a given design matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ and parameter vector $\\mathbf{w} \\in \\mathbb{R}^{p}$, the logistic regression model specifies $p_i = \\mathbb{P}(y_i=1 \\mid \\mathbf{x}_i) = \\sigma(\\mathbf{x}_i^\\top \\mathbf{w})$.\n- The negative log-likelihood (cross-entropy loss) for logistic regression on a dataset $\\{(\\mathbf{x}_i,y_i)\\}_{i=1}^n$ is given by\n$$\n\\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^n \\left[\\ln\\left(1 + e^{\\mathbf{x}_i^\\top \\mathbf{w}}\\right) - y_i \\cdot \\mathbf{x}_i^\\top \\mathbf{w}\\right].\n$$\n- In $k$-fold cross-validation, the dataset indices are partitioned into $k$ disjoint folds of (approximately) equal size; for each fold $j$, parameters $\\mathbf{w}^{(j)}$ are fit on the complement folds, and the loss $\\mathcal{L}^{(j)}$ is evaluated on fold $j$. The out-of-sample performance is the average per-sample loss across all held-out folds,\n$$\n\\overline{\\mathcal{L}} = \\frac{1}{n} \\sum_{j=1}^k \\sum_{i \\in \\text{fold } j} \\left[\\ln\\left(1 + e^{\\mathbf{x}_i^\\top \\mathbf{w}^{(j)}}\\right) - y_i \\cdot \\mathbf{x}_i^\\top \\mathbf{w}^{(j)}\\right].\n$$\n\nCompeting models:\n- Biopsychosocial Model (additive): Biological ($B$), Psychological ($P$), and Social ($S$) variables contribute additively via\n$$\n\\mathbb{P}(y=1 \\mid B,P,S) = \\sigma\\left(\\beta_0 + \\beta_B \\cdot B + \\beta_P \\cdot P + \\beta_S \\cdot S\\right).\n$$\n- Diathesis-Stress Model (interaction): Diathesis $D$ is a linear combination of biological and psychological factors ($D = w_B \\cdot B + w_P \\cdot P$), stress $T$ is the social factor ($T=S$), and risk depends on their additive and multiplicative interaction via\n$$\n\\mathbb{P}(y=1 \\mid D,T) = \\sigma\\left(\\alpha_0 + \\alpha_D \\cdot D + \\alpha_T \\cdot T + \\alpha_{DT} \\cdot D \\cdot T\\right).\n$$\n\nData generation:\n- For each test case, synthetic data are generated as follows. Draw $B$ and $P$ jointly from a bivariate normal distribution with correlation $\\rho$ via $B = \\mu_B + \\sigma_B \\cdot Z_1$, $P = \\mu_P + \\sigma_P \\cdot (\\rho \\cdot Z_1 + \\sqrt{1-\\rho^2} \\cdot Z_2)$, where $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$ are independent. Draw $S$ independently as $S = \\mu_S + \\sigma_S \\cdot Z_3$ with $Z_3 \\sim \\mathcal{N}(0,1)$ independent of $Z_1$ and $Z_2$.\n- Compute $D = w_B \\cdot B + w_P \\cdot P$ and $T = S$. For the specified ground-truth model in each test case, compute the linear predictor $z$ (either additive in $B,P,S$ or interaction in $D,T,D \\cdot T$), then draw $y \\sim \\text{Bernoulli}(\\sigma(z))$ independently across individuals.\n\nCross-validation and decision rule:\n- For each model, perform $k$-fold cross-validation logistic regression using only training folds to compute any data standardization. The evaluation metric is average per-sample negative log-likelihood $\\overline{\\mathcal{L}}$ on held-out folds. Prefer the model with smaller $\\overline{\\mathcal{L}}$.\n- To decide which model guides clinical decision-making, output an integer for each test case: output $1$ if the Biopsychosocial Model has the lower out-of-sample loss, and output $2$ if the Diathesis-Stress Model has the lower out-of-sample loss. In case the difference in losses is less than a small tolerance $\\epsilon$ (use $\\epsilon = 10^{-6}$), choose the Biopsychosocial Model (output $1$) to favor the simpler additive structure.\n\nTest suite:\nImplement the above for the following test cases, each specified by sample size $n$, folds $k$, correlation $\\rho$, diathesis weights $(w_B,w_P)$, and ground-truth coefficients. Use the provided random seeds for reproducibility of index shuffling and data generation.\n\n- Case $1$ (additive ground truth):\n  - $n = 800$, $k = 5$, $\\rho = 0.2$, $(w_B,w_P) = (0.7,0.3)$, seed $= 17$.\n  - Feature scales: $(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$.\n  - Ground-truth additive coefficients: $(\\beta_0,\\beta_B,\\beta_P,\\beta_S) = (-1.0, 0.8, 0.6, 0.5)$.\n\n- Case $2$ (interaction ground truth):\n  - $n = 1200$, $k = 5$, $\\rho = 0.1$, $(w_B,w_P) = (0.6,0.4)$, seed $= 23$.\n  - Feature scales: $(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$.\n  - Ground-truth interaction coefficients: $(\\alpha_0,\\alpha_D,\\alpha_T,\\alpha_{DT}) = (-2.0, 1.0, 0.3, 1.2)$.\n\n- Case $3$ (small sample additive ground truth):\n  - $n = 60$, $k = 3$, $\\rho = 0.0$, $(w_B,w_P) = (0.5,0.5)$, seed $= 99$.\n  - Feature scales: $(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$.\n  - Ground-truth additive coefficients: $(\\beta_0,\\beta_B,\\beta_P,\\beta_S) = (-0.5, 0.5, 0.4, 0.4)$.\n\n- Case $4$ (high correlation interaction ground truth):\n  - $n = 1000$, $k = 5$, $\\rho = 0.9$, $(w_B,w_P) = (0.5,0.5)$, seed $= 202$.\n  - Feature scales: $(\\mu_B,\\mu_P,\\mu_S) = (0,0,0)$, $(\\sigma_B,\\sigma_P,\\sigma_S) = (1,1,1)$.\n  - Ground-truth interaction coefficients: $(\\alpha_0,\\alpha_D,\\alpha_T,\\alpha_{DT}) = (-1.5, 0.9, 0.3, 0.8)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$). Each element must be an integer $1$ or $2$ as defined by the decision rule above, ordered by the cases listed ($1$ through $4$). No other text should be printed.", "solution": "The problem requires a comparison of two psychiatric models, the Biopsychosocial (BPS) and Diathesis-Stress (DS) models, using a $k$-fold cross-validation framework. The decision of which model is superior for a given dataset hinges on the out-of-sample predictive performance, measured by the average per-sample negative log-likelihood. The overall process for each test case involves data generation, followed by model fitting and evaluation via cross-validation, and concluding with a model selection decision.\n\nFirst, for each test case, synthetic data is generated according to the provided specifications. A random number generator is initialized with the given seed to ensure reproducibility of both the data and the subsequent partitioning for cross-validation. The biological ($B$), psychological ($P$), and social ($S$) variables are drawn from Gaussian distributions. Specifically, $B$ and $P$ are drawn from a bivariate normal distribution with means $(\\mu_B, \\mu_P)$, standard deviations $(\\sigma_B, \\sigma_P)$, and correlation $\\rho$. This is achieved by generating independent standard normal variables $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$ and setting $B = \\mu_B + \\sigma_B Z_1$ and $P = \\mu_P + \\sigma_P (\\rho Z_1 + \\sqrt{1-\\rho^2} Z_2)$. The social variable $S = \\mu_S + \\sigma_S Z_3$ is drawn from a normal distribution with $Z_3 \\sim \\mathcal{N}(0,1)$ being independent of $Z_1$ and $Z_2$. The binary outcome $y_i \\in \\{0, 1\\}$ for each of the $n$ individuals is then generated from a Bernoulli distribution, $y_i \\sim \\text{Bernoulli}(p_i)$, where the probability $p_i$ is determined by the logistic function $p_i = \\sigma(z_i) = (1 + e^{-z_i})^{-1}$. The linear predictor $z_i$ is computed based on the specified ground-truth model for the case, which can be either the additive BPS model or the interaction-based DS model.\n\nThe two competing models are both special cases of logistic regression.\n1.  **Biopsychosocial (BPS) Model**: This is an additive model where the linear predictor $z$ is a function of $B$, $P$, and $S$. The probability of a positive outcome is $\\mathbb{P}(y=1) = \\sigma(\\beta_0 + \\beta_B B + \\beta_P P + \\beta_S S)$. The features for this model are simply $(B, P, S)$, and we fit the coefficients $(\\beta_0, \\beta_B, \\beta_P, \\beta_S)$.\n2.  **Diathesis-Stress (DS) Model**: This model includes a multiplicative interaction term. First, a 'diathesis' variable $D$ is constructed as a specified linear combination of the biological and psychological factors, $D = w_B B + w_P P$, and a 'stress' variable $T$ is equated to the social factor, $T = S$. The probability of a positive outcome is then given by $\\mathbb{P}(y=1) = \\sigma(\\alpha_0 + \\alpha_D D + \\alpha_T T + \\alpha_{DT} D \\cdot T)$. The features for this model are $(D, T, D \\cdot T)$, and we fit the coefficients $(\\alpha_0, \\alpha_D, \\alpha_T, \\alpha_{DT})$.\n\nThe core of the task is to perform $k$-fold cross-validation for each model. The dataset of $n$ samples is randomly partitioned into $k$ disjoint folds of approximately equal size. For each fold $j \\in \\{1, \\dots, k\\}$, that fold is held out as the validation set, while the remaining $k-1$ folds constitute the training set.\n\nFor each model, and for each of the $k$ splits:\n- The features of the model are constructed.\n- A critical step is feature standardization. The means and standard deviations of the features are computed *only from the training set*. These statistics are then used to standardize both the training and the validation set features (by subtracting the mean and dividing by the standard deviation). This procedure correctly prevents information leakage from the validation set into the training process. A constant feature (standard deviation of $0$) is handled by not scaling it.\n- An intercept term (a column of ones) is added to the standardized feature matrix of the training set.\n- The logistic regression parameters $\\mathbf{w}$ are estimated by minimizing the negative log-likelihood (NLL), or cross-entropy loss, on the training data. The NLL for parameters $\\mathbf{w}$ on a dataset $\\{(\\mathbf{x}_i,y_i)\\}_{i=1}^m$ is\n$$ \\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^m \\left[\\ln\\left(1 + e^{\\mathbf{x}_i^\\top \\mathbf{w}}\\right) - y_i (\\mathbf{x}_i^\\top \\mathbf{w})\\right]. $$\nThis is a convex optimization problem, which is solved efficiently using the BFGS algorithm. The algorithm's performance is enhanced by providing the analytical gradient of the NLL function:\n$$ \\nabla_{\\mathbf{w}} \\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^m \\left(\\sigma(\\mathbf{x}_i^\\top \\mathbf{w}) - y_i\\right) \\mathbf{x}_i = \\mathbf{X}^\\top (\\sigma(\\mathbf{X}\\mathbf{w}) - \\mathbf{y}). $$\n- Once the parameters $\\mathbf{w}^{(j)}$ are fitted on the training data of fold $j$, the NLL is calculated on the corresponding held-out validation set using these parameters.\n\nAfter iterating through all $k$ folds, the total NLL for each model is the sum of the NLLs from each of the $k$ validation sets. This total loss is then divided by the total number of samples, $n$, to obtain the average per-sample out-of-sample NLL, $\\overline{\\mathcal{L}}$.\n\nFinally, a decision is made by comparing $\\overline{\\mathcal{L}}_{\\text{BPS}}$ and $\\overline{\\mathcal{L}}_{\\text{DS}}$. The DS model is chosen (output $2$) only if its loss is strictly lower than the BPS model's loss by a margin greater than a tolerance $\\epsilon = 10^{-6}$. That is, if $\\overline{\\mathcal{L}}_{\\text{BPS}} > \\overline{\\mathcal{L}}_{\\text{DS}} + \\epsilon$. Otherwise, the simpler BPS model is chosen (output $1$), favoring parsimony in cases of near-equal performance. This procedure is repeated for all specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef _nll(w, X, y):\n    \"\"\"\n    Calculates the negative log-likelihood for logistic regression.\n    The formula is sum(log(1 + exp(z)) - y*z), which is numerically\n    stabilized using logaddexp(0, z) for log(1 + exp(z)).\n    \"\"\"\n    z = X @ w\n    loss = np.sum(np.logaddexp(0, z) - y * z)\n    return loss\n\ndef _grad_nll(w, X, y):\n    \"\"\"\n    Calculates the gradient of the negative log-likelihood.\n    The formula is X.T @ (p - y), where p is the predicted probability.\n    \"\"\"\n    z = X @ w\n    # Sigmoid function, numerically stable for large negative z\n    p = 1 / (1 + np.exp(-z))\n    grad = X.T @ (p - y)\n    return grad\n\ndef fit_logistic_regression(X, y):\n    \"\"\"\n    Fits a logistic regression model.\n    Assumes X already includes an intercept column.\n    \"\"\"\n    num_features = X.shape[1]\n    w0 = np.zeros(num_features)\n    \n    res = minimize(\n        _nll,\n        w0,\n        args=(X, y),\n        jac=_grad_nll,\n        method='BFGS'\n    )\n    \n    return res.x\n\ndef run_single_case(n, k, rho, w_diathesis, feature_scales, ground_truth, seed):\n    \"\"\"\n    Runs a single test case for model comparison.\n    \"\"\"\n    # 1. Setup Random Number Generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # 2. Generate Synthetic Data\n    mus = feature_scales['mus']\n    sigmas = feature_scales['sigmas']\n    \n    z1 = rng.normal(0, 1, size=n)\n    z2 = rng.normal(0, 1, size=n)\n    z3 = rng.normal(0, 1, size=n)\n    \n    B = mus[0] + sigmas[0] * z1\n    P = mus[1] + sigmas[1] * (rho * z1 + np.sqrt(1 - rho**2) * z2)\n    S = mus[2] + sigmas[2] * z3\n    \n    if ground_truth['type'] == 'additive':\n        beta0, betaB, betaP, betaS = ground_truth['coefs']\n        z_true = beta0 + betaB * B + betaP * P + betaS * S\n    else:  # 'interaction'\n        w_b, w_p = w_diathesis\n        D = w_b * B + w_p * P\n        T = S\n        alpha0, alphaD, alphaT, alphaDT = ground_truth['coefs']\n        z_true = alpha0 + alphaD * D + alphaT * T + alphaDT * D * T\n\n    p_true = 1 / (1 + np.exp(-z_true))\n    y = rng.binomial(1, p_true, size=n)\n    \n    # 3. K-Fold Cross-Validation\n    indices = np.arange(n)\n    rng.shuffle(indices)\n    folds = np.array_split(indices, k)\n    \n    total_loss_bps = 0.0\n    total_loss_ds = 0.0\n    \n    w_b, w_p = w_diathesis\n\n    for i in range(k):\n        val_indices = folds[i]\n        train_indices = np.concatenate([folds[j] for j in range(k) if i != j])\n        y_train, y_val = y[train_indices], y[val_indices]\n\n        # --- Biopsychosocial Model ---\n        X_train_feats_bps = np.column_stack((B[train_indices], P[train_indices], S[train_indices]))\n        \n        mean_bps = np.mean(X_train_feats_bps, axis=0)\n        std_bps = np.std(X_train_feats_bps, axis=0)\n        std_bps[std_bps == 0] = 1.0 # Prevent division by zero\n        \n        X_train_std_bps = (X_train_feats_bps - mean_bps) / std_bps\n        X_train_int_bps = np.insert(X_train_std_bps, 0, 1, axis=1)\n        w_bps = fit_logistic_regression(X_train_int_bps, y_train)\n\n        X_val_feats_bps = np.column_stack((B[val_indices], P[val_indices], S[val_indices]))\n        X_val_std_bps = (X_val_feats_bps - mean_bps) / std_bps\n        X_val_int_bps = np.insert(X_val_std_bps, 0, 1, axis=1)\n        total_loss_bps += _nll(w_bps, X_val_int_bps, y_val)\n\n        # --- Diathesis-Stress Model ---\n        D_train = w_b * B[train_indices] + w_p * P[train_indices]\n        T_train = S[train_indices]\n        DT_train = D_train * T_train\n        X_train_feats_ds = np.column_stack((D_train, T_train, DT_train))\n        \n        mean_ds = np.mean(X_train_feats_ds, axis=0)\n        std_ds = np.std(X_train_feats_ds, axis=0)\n        std_ds[std_ds == 0] = 1.0\n        \n        X_train_std_ds = (X_train_feats_ds - mean_ds) / std_ds\n        X_train_int_ds = np.insert(X_train_std_ds, 0, 1, axis=1)\n        w_ds = fit_logistic_regression(X_train_int_ds, y_train)\n        \n        D_val = w_b * B[val_indices] + w_p * P[val_indices]\n        T_val = S[val_indices]\n        DT_val = D_val * T_val\n        X_val_feats_ds = np.column_stack((D_val, T_val, DT_val))\n        \n        X_val_std_ds = (X_val_feats_ds - mean_ds) / std_ds\n        X_val_int_ds = np.insert(X_val_std_ds, 0, 1, axis=1)\n        total_loss_ds += _nll(w_ds, X_val_int_ds, y_val)\n        \n    # 4. Final Comparison\n    avg_loss_bps = total_loss_bps / n\n    avg_loss_ds = total_loss_ds / n\n    epsilon = 1e-6\n\n    if avg_loss_bps > avg_loss_ds + epsilon:\n        return 2\n    else:\n        return 1\n\ndef solve():\n    test_cases = [\n        {\n            'n': 800, 'k': 5, 'rho': 0.2, 'w_diathesis': (0.7, 0.3), 'seed': 17,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'additive', 'coefs': (-1.0, 0.8, 0.6, 0.5)}\n        },\n        {\n            'n': 1200, 'k': 5, 'rho': 0.1, 'w_diathesis': (0.6, 0.4), 'seed': 23,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'interaction', 'coefs': (-2.0, 1.0, 0.3, 1.2)}\n        },\n        {\n            'n': 60, 'k': 3, 'rho': 0.0, 'w_diathesis': (0.5, 0.5), 'seed': 99,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'additive', 'coefs': (-0.5, 0.5, 0.4, 0.4)}\n        },\n        {\n            'n': 1000, 'k': 5, 'rho': 0.9, 'w_diathesis': (0.5, 0.5), 'seed': 202,\n            'feature_scales': {'mus': (0, 0, 0), 'sigmas': (1, 1, 1)},\n            'ground_truth': {'type': 'interaction', 'coefs': (-1.5, 0.9, 0.3, 0.8)}\n        }\n    ]\n    \n    results = []\n    for case in test_cases:\n        result = run_single_case(**case)\n        results.append(result)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4766024"}]}