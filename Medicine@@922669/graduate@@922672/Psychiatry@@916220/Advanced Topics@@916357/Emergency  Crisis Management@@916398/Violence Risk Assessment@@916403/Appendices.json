{"hands_on_practices": [{"introduction": "A risk assessment tool is only as good as our ability to interpret its results. This first exercise focuses on the core metrics of predictive value, which are essential for translating a tool's score into a meaningful probability for a specific patient. By working through the calculation of Positive Predictive Value ($PPV$) and Negative Predictive Value ($NPV$), you will gain a hands-on understanding of how a tool's intrinsic properties—sensitivity and specificity—interact with the population's base rate of violence to determine its real-world predictive power [@problem_id:4771699].", "problem": "A community forensic psychiatry service implements a structured violence risk assessment tool to forecast whether an outpatient will perpetrate at least one violent act within the next $12$ months. Over a $12$-month horizon in this population, the base rate (prevalence) of at least one violent incident is $0.05$. The tool’s operating characteristics, established in prior validation, are sensitivity $0.80$ and specificity $0.85$. Using only the core definitions of sensitivity, specificity, and the laws of conditional probability (including Bayes’ theorem), derive the expressions for the positive predictive value and negative predictive value in terms of prevalence, sensitivity, and specificity. Then evaluate these expressions at the given parameters.\n\nExpress the positive predictive value and the negative predictive value as unitless decimals (not percentages). Round each to four significant figures. Provide your final answers in the order $\\mathrm{PPV}$, $\\mathrm{NPV}$.", "solution": "The problem is assessed as valid. It is scientifically grounded in the principles of probability theory and its application to diagnostic/prognostic testing, which are standard in medical statistics and epidemiology. The problem is well-posed, providing all necessary information (prevalence, sensitivity, specificity) to derive and calculate the requested metrics (positive and negative predictive values). The language is objective and the scenario is realistic.\n\nLet us define the following events:\n- $V$: The event that an outpatient perpetrates at least one violent act within $12$ months. This is a \"positive\" state of reality.\n- $V^c$: The event that an outpatient does not perpetrate any violent acts within $12$ months. This is a \"negative\" state of reality.\n- $T^+$: The event that the risk assessment tool returns a positive result (i.e., predicts the individual will be violent).\n- $T^-$: The event that the risk assessment tool returns a negative result (i.e., predicts the individual will not be violent).\n\nThe problem provides the following parameters, which can be expressed as probabilities:\n- The base rate or prevalence of violence is $p = P(V) = 0.05$.\n- The probability of not being violent is therefore $P(V^c) = 1 - P(V) = 1 - 0.05 = 0.95$.\n- The sensitivity of the tool is the probability of a positive test given that the individual is actually violent: $Se = P(T^+ | V) = 0.80$.\n- The specificity of the tool is the probability of a negative test given that the individual is not violent: $Sp = P(T^- | V^c) = 0.85$.\n\nWe are tasked with deriving expressions for the positive predictive value ($\\mathrm{PPV}$) and negative predictive value ($\\mathrm{NPV}$).\n\nThe positive predictive value is the probability that an individual is truly violent given a positive test result, i.e., $\\mathrm{PPV} = P(V | T^+)$.\nThe negative predictive value is the probability that an individual is truly not violent given a negative test result, i.e., $\\mathrm{NPV} = P(V^c | T^-)$.\n\nWe will use Bayes' theorem, which states $P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$, and the law of total probability.\n\n**Derivation of Positive Predictive Value ($\\mathrm{PPV}$)**\nUsing Bayes' theorem, we can write the $\\mathrm{PPV}$ as:\n$$\n\\mathrm{PPV} = P(V | T^+) = \\frac{P(T^+ | V) P(V)}{P(T^+)}\n$$\nThe numerator contains the sensitivity ($Se = P(T^+ | V)$) and the prevalence ($p = P(V)$). The denominator, $P(T^+)$, is the total probability of a positive test result. We can expand it using the law of total probability:\n$$\nP(T^+) = P(T^+ | V) P(V) + P(T^+ | V^c) P(V^c)\n$$\nWe need to find $P(T^+ | V^c)$, which is the false positive rate. It is the complement of the specificity, since for a non-violent individual ($V^c$), the test can be either positive ($T^+$) or negative ($T^-$).\n$$\nP(T^+ | V^c) = 1 - P(T^- | V^c) = 1 - Sp\n$$\nSubstituting this into the expression for $P(T^+)$:\n$$\nP(T^+) = (Se)(p) + (1 - Sp)(1 - p)\n$$\nNow, substituting this denominator back into the Bayes' theorem expression for $\\mathrm{PPV}$:\n$$\n\\mathrm{PPV} = \\frac{P(T^+ | V) P(V)}{P(T^+ | V) P(V) + P(T^+ | V^c) P(V^c)} = \\frac{(Se)(p)}{(Se)(p) + (1 - Sp)(1 - p)}\n$$\nThis is the general expression for the positive predictive value.\n\n**Derivation of Negative Predictive Value ($\\mathrm{NPV}$)**\nUsing Bayes' theorem, we can write the $\\mathrm{NPV}$ as:\n$$\n\\mathrm{NPV} = P(V^c | T^-) = \\frac{P(T^- | V^c) P(V^c)}{P(T^-)}\n$$\nThe numerator contains the specificity ($Sp = P(T^- | V^c)$) and the probability of not being violent ($1 - p = P(V^c)$). The denominator, $P(T^-)$, is the total probability of a negative test result. We expand it using the law of total probability:\n$$\nP(T^-) = P(T^- | V) P(V) + P(T^- | V^c) P(V^c)\n$$\nWe need to find $P(T^- | V)$, which is the false negative rate. It is the complement of the sensitivity, since for a violent individual ($V$), the test can be either positive ($T^+$) or negative ($T^-$).\n$$\nP(T^- | V) = 1 - P(T^+ | V) = 1 - Se\n$$\nSubstituting this into the expression for $P(T^-)$:\n$$\nP(T^-) = (1 - Se)(p) + (Sp)(1 - p)\n$$\nNow, substituting this denominator back into the Bayes' theorem expression for $\\mathrm{NPV}$:\n$$\n\\mathrm{NPV} = \\frac{P(T^- | V^c) P(V^c)}{P(T^- | V) P(V) + P(T^- | V^c) P(V^c)} = \\frac{(Sp)(1 - p)}{(1 - Se)(p) + (Sp)(1 - p)}\n$$\nThis is the general expression for the negative predictive value.\n\n**Evaluation of Expressions**\nNow we substitute the given values: $p = 0.05$, $Se = 0.80$, and $Sp = 0.85$.\n\nFor $\\mathrm{PPV}$:\n$$\n\\mathrm{PPV} = \\frac{(0.80)(0.05)}{(0.80)(0.05) + (1 - 0.85)(1 - 0.05)} = \\frac{0.04}{0.04 + (0.15)(0.95)}\n$$\n$$\n\\mathrm{PPV} = \\frac{0.04}{0.04 + 0.1425} = \\frac{0.04}{0.1825} \\approx 0.219178\n$$\nRounding to four significant figures, we get $\\mathrm{PPV} = 0.2192$.\n\nFor $\\mathrm{NPV}$:\n$$\n\\mathrm{NPV} = \\frac{(0.85)(1 - 0.05)}{(1 - 0.80)(0.05) + (0.85)(1 - 0.05)} = \\frac{(0.85)(0.95)}{(0.20)(0.05) + (0.85)(0.95)}\n$$\n$$\n\\mathrm{NPV} = \\frac{0.8075}{0.01 + 0.8075} = \\frac{0.8075}{0.8175} \\approx 0.987767\n$$\nRounding to four significant figures, we get $\\mathrm{NPV} = 0.9878$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.2192 & 0.9878 \\end{pmatrix}}\n$$", "id": "4771699"}, {"introduction": "Violence risk is dynamic, changing with a patient's clinical state. This practice moves beyond static assessment to demonstrate how to update a baseline risk probability in light of new, evolving clinical information. You will apply the odds-based formulation of Bayes' theorem to integrate the impact of several dynamic risk factors, each quantified by a positive likelihood ratio ($LR^{+}$), to arrive at a revised post-test probability of violence [@problem_id:4771720]. This exercise is fundamental to the practice of structured professional judgment, where clinicians must synthesize multiple pieces of evidence.", "problem": "A psychiatric emergency service is implementing structured clinical judgment for imminent violence risk within the next $24$ hours among adult patients presenting with acute agitation. For the current patient, the baseline pre-test probability of a violent incident in the next $24$ hours, based on cohort data from similar presentations, is $p_0 = 0.10$. Three observed clinical markers are present: acute intoxicant use at presentation, medication nonadherence over the past week, and heightened autonomic arousal manifested by tachycardia and motor restlessness. Based on prior meta-analytic synthesis, suppose the following positive likelihood ratios (LRs) for these markers, when present, are assumed to be stable and transportable to this setting: acute intoxication $\\mathrm{LR}^{+} = 2.8$, medication nonadherence $\\mathrm{LR}^{+} = 3.5$, and heightened arousal $\\mathrm{LR}^{+} = 2.2$. Assume conditional independence of these markers given the outcome status (violent versus nonviolent during the next $24$ hours).\n\nUsing only fundamental definitions—Bayes’ theorem, odds, and the definition of a likelihood ratio—derive from first principles the patient’s post-test probability of a violent incident in the next $24$ hours after observing these three markers, and compute its numerical value. Express the final probability as a decimal between $0$ and $1$, and round your answer to four significant figures.", "solution": "The problem requires the derivation and calculation of the post-test probability of a violent incident, given a baseline pre-test probability and the presence of three clinical markers with known positive likelihood ratios. The derivation must proceed from first principles, utilizing Bayes' theorem, the definition of odds, and the definition of a likelihood ratio.\n\nLet $D$ denote the event that a patient will have a violent incident in the next $24$ hours. Let $\\bar{D}$ denote the complementary event that the patient will not have a violent incident.\nThe problem provides the baseline pre-test probability of a violent incident as $p_0$.\n$$ P(D) = p_0 = 0.10 $$\nThe probability of no incident is therefore:\n$$ P(\\bar{D}) = 1 - P(D) = 1 - 0.10 = 0.90 $$\n\nThe concept of odds is defined as the ratio of the probability of an event occurring to the probability of it not occurring. The pre-test odds of a violent incident, denoted $\\text{Odds}_{\\text{pre}}$, are:\n$$ \\text{Odds}_{\\text{pre}} = \\frac{P(D)}{P(\\bar{D})} = \\frac{0.10}{0.90} = \\frac{1}{9} $$\n\nLet $E_1$, $E_2$, and $E_3$ be the events corresponding to the observation of the three clinical markers:\n$E_1$: acute intoxicant use\n$E_2$: medication nonadherence\n$E_3$: heightened autonomic arousal\n\nWe are given the positive likelihood ratios ($\\mathrm{LR}^{+}$) for each of these markers. The positive likelihood ratio for a marker $E_i$ is defined as the ratio of the probability of observing the marker in a patient who will become violent to the probability of observing the same marker in a patient who will not.\n$$ \\mathrm{LR}_i^{+} = \\frac{P(E_i | D)}{P(E_i | \\bar{D})} $$\nThe given values are:\n$$ \\mathrm{LR}_1^{+} = 2.8 $$\n$$ \\mathrm{LR}_2^{+} = 3.5 $$\n$$ \\mathrm{LR}_3^{+} = 2.2 $$\n\nWe need to find the a posteriori probability, or post-test probability, of a violent incident given that all three markers are observed. Let $E$ be the composite event $E = E_1 \\cap E_2 \\cap E_3$. We want to calculate $P(D|E)$.\n\nBayes' theorem in its odds form relates post-test odds to pre-test odds and the likelihood ratio of the evidence. The post-test odds are defined as:\n$$ \\text{Odds}_{\\text{post}} = \\frac{P(D|E)}{P(\\bar{D}|E)} $$\nUsing the definition of conditional probability, $P(A|B) = P(A \\cap B) / P(B)$, we can write:\n$$ \\text{Odds}_{\\text{post}} = \\frac{P(D \\cap E) / P(E)}{P(\\bar{D} \\cap E) / P(E)} = \\frac{P(D \\cap E)}{P(\\bar{D} \\cap E)} $$\nUsing the multiplicative rule of probability, $P(A \\cap B) = P(B|A)P(A)$:\n$$ \\text{Odds}_{\\text{post}} = \\frac{P(E|D)P(D)}{P(E|\\bar{D})P(\\bar{D})} $$\nThis can be rearranged to show the core relationship:\n$$ \\text{Odds}_{\\text{post}} = \\left(\\frac{P(E|D)}{P(E|\\bar{D})}\\right) \\left(\\frac{P(D)}{P(\\bar{D})}\\right) $$\nThe first term is the likelihood ratio for the composite evidence $E$, which we denote $\\mathrm{LR}_{\\text{total}}$. The second term is the pre-test odds, $\\text{Odds}_{\\text{pre}}$.\n$$ \\text{Odds}_{\\text{post}} = \\mathrm{LR}_{\\text{total}} \\times \\text{Odds}_{\\text{pre}} $$\n\nThe problem states that we can assume conditional independence of the markers given the outcome status. This means:\n$$ P(E|D) = P(E_1 \\cap E_2 \\cap E_3 | D) = P(E_1|D) P(E_2|D) P(E_3|D) $$\n$$ P(E|\\bar{D}) = P(E_1 \\cap E_2 \\cap E_3 | \\bar{D}) = P(E_1|\\bar{D}) P(E_2|\\bar{D}) P(E_3|\\bar{D}) $$\n\nUsing this assumption, we can calculate the total likelihood ratio, $\\mathrm{LR}_{\\text{total}}$, for the combined presence of all three markers:\n$$ \\mathrm{LR}_{\\text{total}} = \\frac{P(E|D)}{P(E|\\bar{D})} = \\frac{P(E_1|D) P(E_2|D) P(E_3|D)}{P(E_1|\\bar{D}) P(E_2|\\bar{D}) P(E_3|\\bar{D})} $$\n$$ \\mathrm{LR}_{\\text{total}} = \\left(\\frac{P(E_1|D)}{P(E_1|\\bar{D})}\\right) \\left(\\frac{P(E_2|D)}{P(E_2|\\bar{D})}\\right) \\left(\\frac{P(E_3|D)}{P(E_3|\\bar{D})}\\right) = \\mathrm{LR}_1^{+} \\times \\mathrm{LR}_2^{+} \\times \\mathrm{LR}_3^{+} $$\nSubstituting the given values:\n$$ \\mathrm{LR}_{\\text{total}} = 2.8 \\times 3.5 \\times 2.2 = 9.8 \\times 2.2 = 21.56 $$\n\nNow we can calculate the post-test odds:\n$$ \\text{Odds}_{\\text{post}} = \\mathrm{LR}_{\\text{total}} \\times \\text{Odds}_{\\text{pre}} = 21.56 \\times \\frac{1}{9} = \\frac{21.56}{9} $$\n\nFinally, we convert the post-test odds back into a probability. If the post-test probability is $p_{\\text{post}} = P(D|E)$, then the post-test odds are $\\frac{p_{\\text{post}}}{1-p_{\\text{post}}}$. We can solve for $p_{\\text{post}}$:\n$$ \\text{Odds} = \\frac{p}{1-p} \\implies \\text{Odds}(1-p) = p \\implies \\text{Odds} - \\text{Odds} \\cdot p = p \\implies \\text{Odds} = p(1+\\text{Odds}) \\implies p = \\frac{\\text{Odds}}{1+\\text{Odds}} $$\nApplying this formula to our post-test odds:\n$$ p_{\\text{post}} = \\frac{\\text{Odds}_{\\text{post}}}{1+\\text{Odds}_{\\text{post}}} = \\frac{21.56/9}{1 + 21.56/9} = \\frac{21.56}{9 + 21.56} = \\frac{21.56}{30.56} $$\nNow, we compute the numerical value:\n$$ p_{\\text{post}} = \\frac{21.56}{30.56} \\approx 0.7054973822... $$\nThe problem requires the answer to be rounded to four significant figures. The first four significant digits are $7$, $0$, $5$, and $4$. The fifth digit is $9$, which is $5$ or greater, so we round up the fourth digit.\n$$ p_{\\text{post}} \\approx 0.7055 $$\nThis is the patient's post-test probability of a violent incident in the next $24$ hours.", "answer": "$$ \\boxed{0.7055} $$", "id": "4771720"}, {"introduction": "In a world of multiple competing risk models, how do we choose the best one for our clinical setting? This final exercise challenges you to think like a clinical administrator and decision analyst, moving beyond standard discrimination metrics like the area under the curve ($AUC$). You will compare two models by evaluating their Net Benefit at a clinically relevant decision threshold, highlighting why a well-calibrated model with slightly lower discrimination can be superior in practice for maximizing clinical utility and ensuring accurate risk communication [@problem_id:4771743].", "problem": "In an acute psychiatric inpatient unit, administrators are evaluating two multivariable violence risk prediction models to guide whether to initiate intensive observation and preventive measures during the first $24$ hours after admission. The clinical decision rule is to initiate the intervention if the predicted probability of imminent violence exceeds the threshold probability $p_t = 0.20$, chosen by the clinical leadership to reflect the relative harm of a false positive (unnecessary intensive observation) compared to a false negative (missed violence). Both models were externally validated on the same cohort of $N = 500$ consecutively admitted patients, with $E = 100$ observed violent incidents within $24$ hours (prevalence $E/N = 0.20$). The two models have similar discrimination, with areas under the receiver operating characteristic curve (AUC) of $0.78$ for Model A and $0.79$ for Model B, where the area under the receiver operating characteristic curve (AUC) is defined as the probability that a randomly selected patient who will become violent is assigned a higher predicted risk than a randomly selected patient who will not.\n\nCalibration assessment at validation showed the following: Model A had calibration-in-the-large (intercept) of approximately $-0.01$ and calibration slope approximately $0.98$; Model B had calibration-in-the-large of approximately $0.06$ and calibration slope approximately $0.75$. Decision-making at the clinically relevant threshold $p_t = 0.20$ yields the following classification summaries from the validation cohort:\n\n- For Model A at $p_t = 0.20$: true positives (TP) $= 64$, false positives (FP) $= 56$.\n- For Model B at $p_t = 0.20$: true positives (TP) $= 70$, false positives (FP) $= 90$.\n\nAssume that “treat-all” (initiating intensive observation for all $N$ patients) is possible and has a net benefit determined by the same threshold $p_t$, and that “treat-none” (initiating intensive observation for no patient) has a net benefit of $0$ by convention. The goal is to select the model that maximizes clinical utility at $p_t = 0.20$ while supporting accurate communication of individualized risk to patients and staff.\n\nWhich choice best aligns with decision-analytic principles and the evidence provided?\n\nA. Deploy Model A, because at $p_t = 0.20$ it achieves higher net benefit and is well calibrated, despite slightly lower AUC.\n\nB. Deploy Model B, because its slightly higher AUC indicates better discrimination, and therefore calibration and threshold-specific net benefit can be disregarded.\n\nC. Deploy neither model and rely exclusively on unstructured clinical judgment, because the AUCs are similar and thus both models’ utilities are indistinguishable.\n\nD. Deploy Model B at a lower threshold than $p_t = 0.20$ to increase sensitivity, accepting more false positives to avoid missed violent incidents.\n\nE. Prefer Model B after logistic recalibration, because fixing miscalibration will necessarily improve its net benefit at $p_t = 0.20$ relative to Model A.", "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n\nThe problem provides the following information:\n-   **Context**: Evaluation of two multivariable violence risk prediction models (Model A, Model B) in an acute psychiatric inpatient unit.\n-   **Decision Threshold**: An intervention is initiated if the predicted probability of violence exceeds the threshold $p_t = 0.20$.\n-   **Validation Cohort**: Total number of patients, $N = 500$.\n-   **Events**: Number of observed violent incidents, $E = 100$.\n-   **Prevalence**: The prevalence of violence is $E/N = 100/500 = 0.20$.\n-   **Discrimination**:\n    -   Model A: Area under the receiver operating characteristic curve (AUC) is $0.78$.\n    -   Model B: Area under the receiver operating characteristic curve (AUC) is $0.79$.\n    -   Definition of AUC: \"the probability that a randomly selected patient who will become violent is assigned a higher predicted risk than a randomly selected patient who will not.\"\n-   **Calibration**:\n    -   Model A: Calibration-in-the-large (intercept) $\\approx -0.01$; calibration slope $\\approx 0.98$.\n    -   Model B: Calibration-in-the-large (intercept) $\\approx 0.06$; calibration slope $\\approx 0.75$.\n-   **Classification Performance at $p_t = 0.20$**:\n    -   Model A: true positives ($TP_A$) $= 64$, false positives ($FP_A$) $= 56$.\n    -   Model B: true positives ($TP_B$) $= 70$, false positives ($FP_B$) $= 90$.\n-   **Assumptions**:\n    -   \"Treat-all\" strategy is possible.\n    -   \"Treat-none\" strategy has a net benefit of $0$.\n-   **Objective**: \"select the model that maximizes clinical utility at $p_t = 0.20$ while supporting accurate communication of individualized risk to patients and staff.\"\n\n### Step 2: Validate Using Extracted Givens\n\n-   **Scientifically Grounded**: The problem is based on established principles of clinical prediction modeling, biostatistics, and decision analysis. The metrics used (AUC, calibration intercept/slope, TP, FP, Net Benefit) are standard tools for evaluating and comparing such models. The scenario is a realistic application in clinical psychiatry.\n-   **Well-Posed**: The problem provides all necessary quantitative data to perform a decision-analytic comparison. The objective is clearly stated. A unique, rational conclusion can be derived from the provided information.\n-   **Objective**: The problem presents data and asks for a conclusion based on established principles. The language is technical and unbiased.\n\nThe problem does not violate any of the invalidity criteria. It is scientifically sound, well-posed, and objective.\n\n### Step 3: Verdict and Action\n\nThe problem statement is valid. I will proceed with the solution.\n\n## Solution Derivation\n\nThe primary goal is to select the model that maximizes clinical utility at the specified threshold $p_t = 0.20$. The standard metric for this is the **Net Benefit (NB)**. The NB of a model at a given threshold probability $p_t$ is defined as:\n\n$$\nNB(p_t) = \\frac{TP}{N} - \\frac{FP}{N} \\left( \\frac{p_t}{1 - p_t} \\right)\n$$\n\nThis formula quantifies the value of a model by rewarding true positives and penalizing false positives, with the penalty weighted by the odds of the threshold probability, $\\frac{p_t}{1 - p_t}$. The model with the higher Net Benefit at the clinical decision threshold is considered more useful.\n\nThe problem also states a secondary goal: \"supporting accurate communication of individualized risk\". This directly relates to the model's **calibration**. A well-calibrated model produces predicted probabilities that accurately reflect the true underlying risk. Perfect calibration is indicated by a calibration-in-the-large (intercept) of $0$ and a calibration slope of $1$.\n\nFirst, let's calculate the weighting factor for the false positives at the given threshold $p_t = 0.20$:\n$$\n\\frac{p_t}{1 - p_t} = \\frac{0.20}{1 - 0.20} = \\frac{0.20}{0.80} = 0.25\n$$\n\nNow, we can calculate the Net Benefit for each model using the provided data: $N=500$, $TP_A=64$, $FP_A=56$, $TP_B=70$, $FP_B=90$.\n\n**Net Benefit for Model A:**\n$$\nNB_A(0.20) = \\frac{64}{500} - \\frac{56}{500} \\left( 0.25 \\right)\n$$\n$$\nNB_A(0.20) = \\frac{64 - (56 \\times 0.25)}{500} = \\frac{64 - 14}{500} = \\frac{50}{500} = 0.100\n$$\n\n**Net Benefit for Model B:**\n$$\nNB_B(0.20) = \\frac{70}{500} - \\frac{90}{500} \\left( 0.25 \\right)\n$$\n$$\nNB_B(0.20) = \\frac{70 - (90 \\times 0.25)}{500} = \\frac{70 - 22.5}{500} = \\frac{47.5}{500} = 0.095\n$$\n\nComparing the Net Benefits, we find that $NB_A(0.20) > NB_B(0.20)$. This indicates that at the clinically chosen threshold of $p_t = 0.20$, Model A provides greater clinical utility.\n\nNext, we evaluate the secondary goal of supporting accurate risk communication by examining the calibration metrics:\n-   **Model A**: Calibration intercept $\\approx -0.01$ and slope $\\approx 0.98$. These values are very close to the ideal values of $0$ and $1$, respectively, indicating that Model A is **well-calibrated**. Its predicted probabilities are reliable estimates of the true risk.\n-   **Model B**: Calibration intercept $\\approx 0.06$ and slope $\\approx 0.75$. A slope of $0.75$ deviates significantly from the ideal of $1$, indicating **poor calibration**. The model's predicted probabilities are \"shrunken\" or compressed, leading to an overestimation of risk for low-risk patients and an underestimation of risk for high-risk patients. This makes it unsuitable for accurately communicating individualized risk.\n\nFinally, we consider discrimination (AUC). Model B has a slightly higher AUC ($0.79$ vs. $0.78$). However, AUC is a global measure of a model's ability to rank patients, averaged over all possible thresholds. A small difference in AUC is far less important for a specific clinical decision than the Net Benefit at the chosen threshold and the model's calibration.\n\nIn summary, Model A demonstrates superior clinical utility (higher Net Benefit) at the specified decision threshold and is well-calibrated, making it suitable for communicating risk. Model B, despite a marginally higher AUC, has lower utility at the threshold and is poorly calibrated.\n\n## Option-by-Option Analysis\n\n**A. Deploy Model A, because at $p_t = 0.20$ it achieves higher net benefit and is well calibrated, despite slightly lower AUC.**\n-   Our calculations show $NB_A(0.20) = 0.100$ and $NB_B(0.20) = 0.095$. Thus, Model A has a higher net benefit.\n-   The provided calibration metrics (intercept $\\approx -0.01$, slope $\\approx 0.98$) confirm that Model A is well-calibrated.\n-   The AUC for Model A ($0.78$) is indeed slightly lower than for Model B ($0.79$).\n-   This statement correctly prioritizes net benefit at the decision threshold and good calibration over a marginal difference in a global discrimination metric (AUC). This aligns perfectly with modern decision-analytic principles.\n-   Verdict: **Correct**.\n\n**B. Deploy Model B, because its slightly higher AUC indicates better discrimination, and therefore calibration and threshold-specific net benefit can be disregarded.**\n-   This is flawed reasoning. A slightly higher global discrimination (AUC) does not guarantee better performance at a specific clinical threshold. The Net Benefit calculation, which is the direct measure of utility at that threshold, showed Model A to be superior. Disregarding calibration and threshold-specific net benefit is contrary to the principles of evidence-based decision making.\n-   Verdict: **Incorrect**.\n\n**C. Deploy neither model and rely exclusively on unstructured clinical judgment, because the AUCs are similar and thus both models’ utilities are indistinguishable.**\n-   The premise that similar AUCs imply indistinguishable utilities is false. Our Net Benefit calculation shows a clear, albeit small, difference in utility at $p_t = 0.20$.\n-   Furthermore, we must compare the models' utility to the default strategies of \"treat-all\" or \"treat-none\". The net benefit of \"treat-none\" is given as $0$. The net benefit of \"treat-all\" is $NB_{all} = \\frac{E}{N} - \\frac{N-E}{N}(\\frac{p_t}{1-p_t}) = \\frac{100}{500} - \\frac{400}{500}(\\frac{0.2}{0.8}) = 0.2 - 0.8(0.25) = 0.2 - 0.2 = 0$. Since both $NB_A(0.20)=0.100$ and $NB_B(0.20)=0.095$ are greater than $0$, both models are superior to treating everyone or treating no one. Abandoning them would result in a loss of clinical utility.\n-   Verdict: **Incorrect**.\n\n**D. Deploy Model B at a lower threshold than $p_t = 0.20$ to increase sensitivity, accepting more false positives to avoid missed violent incidents.**\n-   The problem explicitly states that the threshold $p_t = 0.20$ was chosen by clinical leadership to balance the harms of false positives and false negatives. Arbitrarily changing the threshold for one model invalidates the basis of the decision-making framework. The task is to compare the models at the given, fixed threshold.\n-   Verdict: **Incorrect**.\n\n**E. Prefer Model B after logistic recalibration, because fixing miscalibration will necessarily improve its net benefit at $p_t = 0.20$ relative to Model A.**\n-   Model B is miscalibrated and would benefit from recalibration. Recalibration adjusts predicted probabilities to better match observed outcomes, which typically improves a model's performance. However, there is no guarantee (\"necessarily\") that the recalibrated Net Benefit of Model B would exceed that of Model A. Model A is already well-calibrated and has superior net benefit. While Model B has a higher AUC, suggesting a higher \"potential\" utility, it is not certain that recalibration would allow it to surpass Model A's current, validated performance. Making a decision on the hypothetical outcome of a future procedure is speculative. The decision must be based on the evidence provided.\n-   Verdict: **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "4771743"}]}