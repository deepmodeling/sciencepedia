{"hands_on_practices": [{"introduction": "A model's sensitivity and specificity are intrinsic properties, but its real-world utility depends critically on the prevalence of the condition in the target population. This exercise [@problem_id:4689968] provides hands-on practice in applying Bayes' theorem to calculate the Positive Predictive Value (PPV), illustrating how even a model with high accuracy metrics can produce a large number of false positives when screening for a rare event. Understanding this principle is fundamental to responsibly deploying AI screening tools and managing clinical resources.", "problem": "An integrated care health system deploys an Artificial Intelligence (AI) risk stratification model to screen adult primary care patients for risk of a suicide attempt within the next $6$ months. On a temporally held-out test set representative of the intended deployment population, the model operating at a fixed alert threshold attains sensitivity $0.85$ and specificity $0.95$. Independent surveillance data indicate that the $6$-month incidence (prevalence over the prediction horizon) of suicide attempt in this population is $\\pi = 0.02$. Using only the core definitions of sensitivity, specificity, and prevalence together with Bayes’ theorem, derive from first principles the expression for the Positive Predictive Value (PPV), defined as the probability that a patient truly experiences a suicide attempt within $6$ months given a positive alert. Then compute the PPV numerically for this setting. Express your final PPV as a decimal fraction rounded to $4$ significant figures. Finally, briefly interpret, in words, what this PPV implies for clinical triage and resource allocation if the model is used to trigger outreach, without computing any additional numerical quantities.", "solution": "The problem is valid as it is scientifically grounded in established principles of biostatistics, well-posed with sufficient and consistent information, and objectively stated.\n\nThe task is to derive an expression for the Positive Predictive Value (PPV), compute its numerical value for the given scenario, and interpret the result.\n\nLet us define the following events:\n- $S$: The event that a patient experiences a suicide attempt within $6$ months.\n- $S^c$: The event that a patient does not experience a suicide attempt within $6$ months.\n- $A$: The event that the AI model generates a positive alert for a patient.\n- $A^c$: The event that the AI model does not generate a positive alert for a patient.\n\nFrom the problem statement, we are given the following probabilities:\n- The prevalence (incidence) of suicide attempt is $\\pi = P(S) = 0.02$.\n- The sensitivity of the model is the probability of a positive alert given a suicide attempt, $P(A|S) = 0.85$.\n- The specificity of the model is the probability of a negative alert given no suicide attempt, $P(A^c|S^c) = 0.95$.\n\nFrom the definition of prevalence, the probability of a patient not having a suicide attempt is $P(S^c) = 1 - P(S) = 1 - \\pi = 1 - 0.02 = 0.98$.\nFrom the definition of specificity, we can derive the false positive rate (FPR), which is the probability of a positive alert given no suicide attempt:\n$P(A|S^c) = 1 - P(A^c|S^c) = 1 - 0.95 = 0.05$.\n\nThe Positive Predictive Value (PPV) is defined as the probability that a patient truly has the condition (suicide attempt) given a positive test result (alert). In our notation, this is $P(S|A)$.\n\nWe derive the expression for PPV from first principles using Bayes' theorem:\n$$P(S|A) = \\frac{P(A|S)P(S)}{P(A)}$$\n\nThe denominator, $P(A)$, is the marginal probability of receiving a positive alert. We can calculate this using the law of total probability, summing over the mutually exclusive and exhaustive events $S$ and $S^c$:\n$$P(A) = P(A|S)P(S) + P(A|S^c)P(S^c)$$\n\nSubstituting this expression for $P(A)$ into Bayes' theorem gives the full expression for PPV:\n$$PPV = P(S|A) = \\frac{P(A|S)P(S)}{P(A|S)P(S) + P(A|S^c)P(S^c)}$$\n\nThis can be expressed in terms of sensitivity, specificity, and prevalence ($\\pi$):\n$$PPV = \\frac{(\\text{sensitivity}) \\times \\pi}{(\\text{sensitivity}) \\times \\pi + (1 - \\text{specificity}) \\times (1 - \\pi)}$$\nThis is the required derivation from first principles.\n\nNext, we compute the numerical value of the PPV by substituting the given values:\n- $\\text{sensitivity} = 0.85$\n- $\\text{specificity} = 0.95$\n- $\\pi = 0.02$\n\nThe numerator is:\n$P(A|S)P(S) = 0.85 \\times 0.02 = 0.017$.\n\nThe denominator is:\n$P(A) = P(A|S)P(S) + P(A|S^c)P(S^c) = (0.85 \\times 0.02) + ((1 - 0.95) \\times (1 - 0.02))$\n$P(A) = (0.017) + (0.05 \\times 0.98)$\n$P(A) = 0.017 + 0.049 = 0.066$.\n\nNow, we can compute the PPV:\n$$PPV = \\frac{0.017}{0.066} = \\frac{17}{66} \\approx 0.257575...$$\n\nRounding to $4$ significant figures, the PPV is $0.2576$.\n\nFinally, we interpret what this PPV implies for clinical triage and resource allocation. A PPV of $0.2576$ means that among all patients who receive a positive alert from the AI model, only approximately $25.8\\%$ will actually have a suicide attempt in the subsequent $6$ months. The remaining majority, approximately $74.2\\%$, are false positives.\n\nClinically, this implies that a positive alert cannot be treated as a definitive confirmation of high risk. Instead, it should be considered a signal that warrants further, more detailed clinical assessment. If the model's alerts are used to trigger outreach, the outreach protocol must be designed to handle a large volume of false positives. For every true high-risk individual correctly identified by the model, outreach staff will need to engage with approximately three individuals who are not truly at high risk (since $(1-0.2576)/0.2576 \\approx 2.88$). This has significant resource allocation implications. An efficient secondary screening process is essential to avoid overburdening mental health services and to prevent \"alert fatigue\" in clinicians, where frequent false alarms may lead to alerts being ignored. The model's value lies in enriching a sub-population for targeted screening, not in replacing clinical judgment.", "answer": "$$\\boxed{0.2576}$$", "id": "4689968"}, {"introduction": "While discrimination metrics like the area under the curve (AUC) tell us how well a model ranks individuals by risk, they do not reveal if the predicted probabilities themselves are accurate. This practice [@problem_id:4689987] delves into the crucial concepts of calibration and overall accuracy by having you compute the Brier score and calibration slope. These metrics are essential for determining whether a model's risk scores can be taken at face value for clinical decision-making and resource allocation.", "problem": "An artificial intelligence model outputs individualized predicted probabilities for relapse into a major depressive episode within the next $30$ days for a held-out cohort of $10$ adults receiving outpatient care. For each patient $i$, the model’s predicted probability is $p_i \\in (0,1)$ and the observed outcome is $y_i \\in \\{0,1\\}$, where $y_i=1$ denotes a relapse during follow-up. The predictions and outcomes are:\n- Patients $1$–$6$: $p_i = 0.20$. Among these, patients $1$ and $3$ relapsed ($y_1 = 1$, $y_3 = 1$), and patients $2$, $4$, $5$, and $6$ did not relapse ($y_2 = 0$, $y_4 = 0$, $y_5 = 0$, $y_6 = 0$).\n- Patients $7$–$10$: $p_i = 0.65$. Among these, patients $7$, $8$, and $10$ relapsed ($y_7 = 1$, $y_8 = 1$, $y_{10} = 1$), and patient $9$ did not relapse ($y_9 = 0$).\n\nStarting only from core definitions:\n- The Brier score is the mean squared error between the predicted probabilities $p_i$ and observed outcomes $y_i$ across the $n$ patients.\n- The calibration slope is defined via logistic calibration: fit a logistic regression of $y_i$ on the log-odds of the predicted probabilities, that is, model $\\Pr(y_i=1 \\mid \\text{logit}(p_i))$ with a linear predictor $\\alpha + \\beta \\,\\text{logit}(p_i)$, where $\\text{logit}(p) = \\ln\\!\\left(\\frac{p}{1-p}\\right)$, and take the maximum likelihood estimate of the slope $\\beta$.\n\nUsing these definitions and the data above, compute:\n1. The Brier score for this cohort.\n2. The calibration slope $\\beta$.\n\nThen, briefly interpret both quantities in clinical terms for depression relapse risk prediction, focusing on overall accuracy and whether the model’s probabilities are too extreme or too conservative. Report your final numerical results for the Brier score and the calibration slope, in that order, each rounded to four significant figures. No units are required.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It provides all necessary data and definitions to compute the requested quantities. The problem is a standard application of statistical model evaluation metrics (Brier score and calibration slope) to a given dataset. All conditions for a valid problem are met.\n\nThe problem asks for two quantities: the Brier score and the calibration slope, based on a set of predicted probabilities and observed outcomes for a cohort of $n=10$ patients.\n\nFirst, we compute the Brier score. The Brier score is defined as the mean squared error between the predicted probabilities $p_i$ and the observed outcomes $y_i$. The formula is:\n$$ BS = \\frac{1}{n} \\sum_{i=1}^{n} (p_i - y_i)^2 $$\nThe data is provided in two groups.\nFor patients $1$ through $6$, the predicted probability is $p_i = 0.20$.\n- Two of these patients ($i=1, 3$) relapsed, so their outcome is $y_i=1$. Their contribution to the sum of squared errors is $(0.20 - 1)^2 = (-0.80)^2 = 0.64$ each.\n- Four of these patients ($i=2, 4, 5, 6$) did not relapse, so their outcome is $y_i=0$. Their contribution is $(0.20 - 0)^2 = (0.20)^2 = 0.04$ each.\nThe total sum of squared errors for this first group is $2 \\times 0.64 + 4 \\times 0.04 = 1.28 + 0.16 = 1.44$.\n\nFor patients $7$ through $10$, the predicted probability is $p_i = 0.65$.\n- Three of these patients ($i=7, 8, 10$) relapsed, so their outcome is $y_i=1$. Their contribution is $(0.65 - 1)^2 = (-0.35)^2 = 0.1225$ each.\n- One patient ($i=9$) did not relapse, so their outcome is $y_i=0$. Their contribution is $(0.65 - 0)^2 = (0.65)^2 = 0.4225$.\nThe total sum of squared errors for this second group is $3 \\times 0.1225 + 1 \\times 0.4225 = 0.3675 + 0.4225 = 0.79$.\n\nThe total sum of squared errors across all $n=10$ patients is $1.44 + 0.79 = 2.23$.\nThe Brier score is the mean of this sum:\n$$ BS = \\frac{2.23}{10} = 0.223 $$\nRounding to four significant figures, the Brier score is $0.2230$.\n\nSecond, we compute the calibration slope $\\beta$. This is obtained by fitting a logistic regression model of the outcome $y_i$ on the log-odds of the predicted probability, $x_i = \\text{logit}(p_i) = \\ln\\left(\\frac{p_i}{1-p_i}\\right)$. The model is $\\Pr(y_i=1 \\mid x_i) = \\sigma(\\alpha + \\beta x_i)$, where $\\sigma(z) = (1+\\exp(-z))^{-1}$ is the sigmoid function.\n\nThe data can be aggregated into two groups based on the two distinct values of the predictor $x_i$.\nGroup A: $p_A = 0.20$. The predictor is $x_A = \\text{logit}(0.20) = \\ln\\left(\\frac{0.20}{0.80}\\right) = \\ln(0.25) = -\\ln(4)$. For this group, there are $n_A=6$ patients, and $k_A=2$ relapsed. The observed relapse frequency is $f_A = k_A/n_A = 2/6 = 1/3$.\nGroup B: $p_B = 0.65$. The predictor is $x_B = \\text{logit}(0.65) = \\ln\\left(\\frac{0.65}{0.35}\\right) = \\ln\\left(\\frac{13}{7}\\right)$. For this group, there are $n_B=4$ patients, and $k_B=3$ relapsed. The observed relapse frequency is $f_B = k_B/n_B = 3/4$.\n\nFor a logistic regression with categorical predictors where each category has both outcomes ($0$ and $1$), the model is saturated. The maximum likelihood estimates of the probabilities for each group, $\\hat{\\pi}_A$ and $\\hat{\\pi}_B$, are equal to the observed frequencies.\n$$ \\hat{\\pi}_A = f_A = \\frac{1}{3} $$\n$$ \\hat{\\pi}_B = f_B = \\frac{3}{4} $$\nThese fitted probabilities must satisfy the logistic model equations:\n$$ \\text{logit}(\\hat{\\pi}_A) = \\alpha + \\beta x_A $$\n$$ \\text{logit}(\\hat{\\pi}_B) = \\alpha + \\beta x_B $$\nWe have a system of two linear equations for $\\alpha$ and $\\beta$:\n1. $\\text{logit}(1/3) = \\ln\\left(\\frac{1/3}{2/3}\\right) = \\ln(1/2) = -\\ln(2) = \\alpha + \\beta (-\\ln(4))$\n2. $\\text{logit}(3/4) = \\ln\\left(\\frac{3/4}{1/4}\\right) = \\ln(3) = \\alpha + \\beta \\ln(13/7)$\n\nTo find $\\beta$, we subtract the first equation from the second:\n$$ \\ln(3) - (-\\ln(2)) = (\\alpha + \\beta \\ln(13/7)) - (\\alpha - \\beta \\ln(4)) $$\n$$ \\ln(3) + \\ln(2) = \\beta (\\ln(13/7) + \\ln(4)) $$\n$$ \\ln(6) = \\beta \\ln\\left(\\frac{13}{7} \\times 4\\right) $$\n$$ \\ln(6) = \\beta \\ln\\left(\\frac{52}{7}\\right) $$\nSolving for $\\beta$:\n$$ \\beta = \\frac{\\ln(6)}{\\ln(52/7)} $$\nNow we compute the numerical value:\n$$ \\beta \\approx \\frac{1.791759}{2.005318} \\approx 0.893504 $$\nRounding to four significant figures, the calibration slope is $\\beta = 0.8935$.\n\nFinally, we interpret these results.\n- The Brier score is a measure of overall accuracy, where lower is better. A score of $0.2230$ indicates a fair degree of predictive error. For comparison, a naive model that always predicts the overall relapse rate in the cohort ($\\bar{y} = 5/10 = 0.5$) would have a Brier score of $\\frac{1}{10}[5 \\times (0.5-1)^2 + 5 \\times (0.5-0)^2] = 0.25$. The model's score of $0.2230$ is slightly better than this naive benchmark, suggesting it has some, but limited, predictive value.\n\n- The calibration slope assesses whether the model's probabilities are well-calibrated. A perfectly calibrated model has a slope of $\\beta=1$.\n  - A slope $\\beta > 1$ implies the model's probabilities are too conservative (under-confident).\n  - A slope $\\beta < 1$ implies the model's probabilities are too extreme (over-confident).\nOur computed slope is $\\beta=0.8935$, which is less than $1$. This indicates that the model is overconfident. The spread of its predictions on the log-odds scale ($\\Delta_{\\text{pred}} = \\text{logit}(0.65)-\\text{logit}(0.20) = \\ln(52/7) \\approx 2.005$) is wider than the spread of the observed outcomes on the same scale ($\\Delta_{\\text{obs}} = \\text{logit}(3/4)-\\text{logit}(1/3) = \\ln(6) \\approx 1.792$). This means the model overstates the difference in risk between the two groups. Although the raw probabilities ($0.20$ and $0.65$) may appear conservative relative to the observed frequencies ($1/3 \\approx 0.33$ and $3/4 = 0.75$), the slope parameter $\\beta<1$ reveals that on the logit scale, the predictions are too extreme and would need to be \"shrunk\" toward their mean to be better calibrated.\n\nThe final numerical results are $0.2230$ for the Brier score and $0.8935$ for the calibration slope.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.2230 & 0.8935 \\end{pmatrix}}\n$$", "id": "4689987"}, {"introduction": "To trust and responsibly implement complex machine learning models, we must move beyond simply evaluating their performance and begin to understand their decision-making processes. This problem [@problem_id:4690017] offers a practical, hands-on implementation of two powerful, model-agnostic interpretability techniques: Permutation Feature Importance (PFI) and Partial Dependence Plots (PDP). By manually computing these for a gradient boosting model, you will gain a foundational understanding of how to probe the \"black box\" to reveal which features drive predictions and what their marginal effects are.", "problem": "You are given a binary classification task in psychiatry: predicting near-term mania onset from clinical features using a trained gradient boosting ensemble. Your goal is to implement, from first principles, the computation of Permutation Feature Importance (PFI) for two clinically salient features, and the one-dimensional Partial Dependence Plot (PDP) for those same features. You must use the definitions of binary probabilistic prediction, logistic link for probabilities, empirical mean for expectations, permutation as a measure of conditional independence, and the additive form of the gradient boosting model.\n\nBackground and fundamental base:\n- A gradient boosting classifier can be represented as an additive model on the logit scale: for a feature vector $\\mathbf{x} \\in \\mathbb{R}^d$, the logit is $F(\\mathbf{x}) = b_0 + \\sum_{m=1}^{M} \\nu \\, T_m(\\mathbf{x})$, where $b_0$ is the intercept, $\\nu$ is the learning rate, and $T_m$ is the $m$-th regression tree that outputs a real-valued leaf score for $\\mathbf{x}$.\n- The predicted probability of mania is given by the logistic link $p(\\mathbf{x}) = \\sigma(F(\\mathbf{x})) = \\frac{1}{1 + e^{-F(\\mathbf{x})}}$, which maps any real-valued logit to a value in $(0,1)$.\n- The empirical mean cross-entropy (log loss) for a dataset $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$ with $y_i \\in \\{0,1\\}$ is $\\frac{1}{N}\\sum_{i=1}^N \\left[-y_i \\log p(\\mathbf{x}_i) - (1 - y_i) \\log \\left(1 - p(\\mathbf{x}_i)\\right)\\right]$, which measures predictive performance given predicted probabilities $p(\\mathbf{x}_i)$.\n- Permutation Feature Importance (PFI) for feature $j$ is defined as the expected increase in loss when the values of feature $j$ are randomly permuted across samples, thereby destroying its association with the target while preserving its marginal distribution. Formally, letting $\\pi$ denote a random permutation on $\\{1,\\dots,N\\}$ and $\\mathbf{x}_i^{(j \\leftarrow x_{\\pi(i),j})}$ denote $\\mathbf{x}_i$ with the $j$-th feature replaced by the permuted value $x_{\\pi(i),j}$, PFI is $I_j = \\mathbb{E}_\\pi\\left[\\frac{1}{N}\\sum_{i=1}^N \\ell\\left(y_i, p\\left(\\mathbf{x}_i^{(j \\leftarrow x_{\\pi(i),j})}\\right)\\right)\\right] - \\frac{1}{N}\\sum_{i=1}^N \\ell\\left(y_i, p(\\mathbf{x}_i)\\right)$, where $\\ell$ is the log loss. You will empirically approximate the expectation by averaging over repeated independent permutations.\n- The one-dimensional Partial Dependence Plot (PDP) for feature $j$ is defined at value $v$ as $PD_j(v) = \\mathbb{E}_{\\mathbf{X}_{-j}}\\left[p\\left(v, \\mathbf{X}_{-j}\\right)\\right]$, which can be estimated by the empirical average over the dataset: $PD_j(v) \\approx \\frac{1}{N}\\sum_{i=1}^N p\\left(\\mathbf{x}_i^{(j \\leftarrow v)}\\right)$.\n\nModel, features, and data:\n- Feature order is fixed as follows:\n  - Index $0$: sleep duration in hours (unit: hours), denoted $x_0$.\n  - Index $1$: medication adherence as a decimal fraction in $[0,1]$, denoted $x_1$.\n  - Index $2$: age in years, denoted $x_2$.\n  - Index $3$: number of previous manic episodes, denoted $x_3$.\n  - Index $4$: comorbidity score (nonnegative integer), denoted $x_4$.\n- The trained gradient boosting model parameters are:\n  - Intercept $b_0 = -0.3$.\n  - Learning rate $\\nu = 0.25$.\n  - Number of trees $M = 3$, with each tree defined by axis-aligned splits and leaves as follows (all splits are of the form “go left if $x_j < \\tau$, else go right”):\n    - Tree $1$:\n      - Node $0$: split on feature $0$ with threshold $6.5$, left child node $1$, right child node $2$.\n      - Node $1$: split on feature $1$ with threshold $0.6$, left leaf value $+0.8$, right leaf value $+0.3$.\n      - Node $2$: split on feature $3$ with threshold $2.5$, left leaf value $-0.2$, right leaf value $+0.4$.\n    - Tree $2$:\n      - Node $0$: split on feature $1$ with threshold $0.4$, left leaf value $+0.5$, right child node $1$.\n      - Node $1$: split on feature $0$ with threshold $7.5$, left leaf value $+0.2$, right leaf value $-0.3$.\n    - Tree $3$:\n      - Node $0$: split on feature $4$ with threshold $3.5$, left leaf value $-0.1$, right child node $1$.\n      - Node $1$: split on feature $0$ with threshold $5.5$, left leaf value $+0.6$, right leaf value $+0.0$.\n  - The ensemble output on the logit scale is $F(\\mathbf{x}) = b_0 + \\nu \\sum_{m=1}^{3} T_m(\\mathbf{x})$, and the probability is $p(\\mathbf{x}) = \\sigma(F(\\mathbf{x}))$.\n- Dataset $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{12}$:\n  - Row $0$: $(x_0, x_1, x_2, x_3, x_4, y) = (4.5, 0.2, 24, 3, 5, 1)$.\n  - Row $1$: $(5.0, 0.3, 31, 1, 2, 1)$.\n  - Row $2$: $(6.0, 0.7, 40, 0, 1, 0)$.\n  - Row $3$: $(7.0, 0.9, 52, 0, 0, 0)$.\n  - Row $4$: $(8.0, 0.8, 45, 2, 4, 0)$.\n  - Row $5$: $(5.5, 0.5, 28, 2, 3, 1)$.\n  - Row $6$: $(9.0, 0.4, 36, 1, 2, 0)$.\n  - Row $7$: $(6.5, 0.6, 33, 3, 6, 1)$.\n  - Row $8$: $(4.0, 0.9, 29, 4, 5, 1)$.\n  - Row $9$: $(7.5, 0.2, 50, 0, 1, 0)$.\n  - Row $10$: $(6.0, 0.3, 42, 2, 2, 1)$.\n  - Row $11$: $(8.5, 1.0, 60, 0, 0, 0)$.\n\nTasks:\n1. Implement the model $F(\\mathbf{x})$ and $p(\\mathbf{x})$ exactly as specified. Use the empirical mean cross-entropy (log loss) as defined above. For probabilities $p(\\mathbf{x})$ at the boundaries, apply numeric clipping to ensure they lie strictly within $(0,1)$.\n2. Compute the baseline mean log loss over the dataset.\n3. Compute the Permutation Feature Importance (PFI) for:\n   - Feature index $0$ (sleep duration in hours).\n   - Feature index $1$ (medication adherence as a decimal fraction).\n   For a given number of independent permutation repeats $R$ and a random seed $s$, approximate the expectation by averaging the mean log loss across $R$ independent random permutations (generated using the specified seed for reproducibility), and then subtract the baseline mean log loss. Report the PFI as a nonnegative float (if numeric noise yields a tiny negative value, keep the rounded value as is).\n4. Compute the one-dimensional Partial Dependence Plot (PDP) estimates for:\n   - Feature index $0$ evaluated at grid values $[5.0, 6.5, 8.0]$ hours.\n   - Feature index $1$ evaluated at grid values $[0.2, 0.6, 0.9]$ (decimal fractions).\n   For each grid value $v$, construct modified inputs by replacing that feature with $v$ for all samples, evaluate $p(\\mathbf{x})$ for each sample, and average across samples to estimate $PD_j(v)$.\n\nTest suite:\n- You must run the computations for the following three cases, each defined by a pair $(R, s)$ where $R$ is the number of permutation repeats and $s$ is the random seed:\n  - Case $1$: $(R, s) = (1, 11)$.\n  - Case $2$: $(R, s) = (7, 123)$.\n  - Case $3$: $(R, s) = (25, 9871)$.\n- For each case, produce a result list containing:\n  - The baseline mean log loss (float).\n  - The PFI for sleep duration (float).\n  - The PFI for medication adherence (float).\n  - The PDP values for sleep duration at $[5.0, 6.5, 8.0]$ (list of floats).\n  - The PDP values for medication adherence at $[0.2, 0.6, 0.9]$ (list of floats).\n- All floats must be rounded to $6$ decimal places. There are no physical units in the output; probabilities and losses are dimensionless, and medication adherence is a decimal fraction.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one case in the same order as above. Each case itself must be a list of the five items described. For example, the overall output must have the form\n  \"[[baseline,PFI_sleep,PFI_adherence,[PD_sleep_values],[PD_adherence_values]],[...case2...],[...case3...]]\"\nwith all numeric values rounded to $6$ decimals and no extra whitespace or text.", "solution": "The user requires the implementation of Permutation Feature Importance (PFI) and Partial Dependence Plots (PDP) for a specified gradient boosting model. This task involves a series of steps, from model implementation to the application of these interpretability techniques, culminating in a formatted output for three distinct test cases. The entire process is grounded in fundamental principles of machine learning.\n\nFirst, we must formalize the predictive model. The gradient boosting classifier is an additive ensemble of $M=3$ regression trees. For a given feature vector $\\mathbf{x} \\in \\mathbb{R}^5$, the model's output on the log-odds (logit) scale is given by:\n$$F(\\mathbf{x}) = b_0 + \\nu \\sum_{m=1}^{M} T_m(\\mathbf{x})$$\nwhere the intercept is $b_0 = -0.3$, the learning rate is $\\nu = 0.25$, and $T_m(\\mathbf{x})$ is the real-valued output of the $m$-th tree. The decision rules for each tree are explicitly defined with axis-aligned splits of the form \"$x_j < \\tau$\".\n\nThe individual tree functions are implemented as follows:\n-   $T_1(\\mathbf{x})$:\n    - If $x_0 < 6.5$: if $x_1 < 0.6$, output is $0.8$; else output is $0.3$.\n    - If $x_0 \\geq 6.5$: if $x_3 < 2.5$, output is $-0.2$; else output is $0.4$.\n-   $T_2(\\mathbf{x})$:\n    - If $x_1 < 0.4$: output is $0.5$.\n    - If $x_1 \\geq 0.4$: if $x_0 < 7.5$, output is $0.2$; else output is $-0.3$.\n-   $T_3(\\mathbf{x})$:\n    - If $x_4 < 3.5$: output is $-0.1$.\n    - If $x_4 \\geq 3.5$: if $x_0 < 5.5$, output is $0.6$; else output is $0.0$.\n\nThe predicted probability of mania, $p(\\mathbf{x})$, is obtained by applying the logistic (sigmoid) function $\\sigma(\\cdot)$ to the logit output:\n$$p(\\mathbf{x}) = \\sigma(F(\\mathbf{x})) = \\frac{1}{1 + e^{-F(\\mathbf{x})}}$$\nThis function maps the real-valued logit $F(\\mathbf{x})$ to the interval $(0, 1)$, representing a probability.\n\nTo evaluate model performance, we use the binary cross-entropy, also known as log loss. For a single observation $(\\mathbf{x}_i, y_i)$ where $y_i \\in \\{0, 1\\}$ is the true label, the loss is:\n$$\\ell(y_i, p(\\mathbf{x}_i)) = -y_i \\log(p(\\mathbf{x}_i)) - (1 - y_i) \\log(1 - p(\\mathbf{x}_i))$$\nTo ensure numerical stability when $p(\\mathbf{x}_i)$ is close to $0$ or $1$, the probability values are clipped to a small interval $[\\epsilon, 1-\\epsilon]$, for a small $\\epsilon > 0$ (e.g., $10^{-15}$), before being passed to the logarithm. The overall model performance on the dataset $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$ is the empirical mean log loss, which serves as our baseline loss.\n\nWith the model and loss function defined, we can proceed to the interpretability calculations.\n\n**Permutation Feature Importance (PFI)** measures the increase in model error after a feature's values are randomly permuted. This process breaks the relationship between the feature and the target variable. For a feature $j$, the PFI is calculated as follows:\n1.  Calculate the baseline loss, $L_{base} = \\frac{1}{N}\\sum_{i=1}^N \\ell(y_i, p(\\mathbf{x}_i))$, on the original dataset.\n2.  For a number of repetitions $R$:\n    a.  Generate a random permutation $\\pi$ of the sample indices $\\{1, \\dots, N\\}$.\n    b.  Create a new dataset where the $j$-th feature column is permuted according to $\\pi$. That is, for each sample $i$, the new feature vector is $\\mathbf{x}_i' = \\mathbf{x}_i^{(j \\leftarrow x_{\\pi(i),j})}$.\n    c.  Calculate the mean log loss, $L_{permuted}$, on this new dataset.\n3.  Average the permuted losses over all $R$ repetitions to get $\\bar{L}_{permuted}$.\n4.  The PFI for feature $j$ is the difference: $I_j = \\bar{L}_{permuted} - L_{base}$.\nA higher PFI value suggests that the model relies more heavily on that feature for its predictions. The random seed $s$ ensures that the permutations are reproducible across runs.\n\n**Partial Dependence Plot (PDP)** shows the marginal effect of a feature on the predicted outcome of a machine learning model. For a feature $j$ and a specific value $v$ from a grid of interest, the PDP value is estimated by:\n1.  Creating a modified dataset by replacing the entire column for feature $j$ with the constant value $v$. For each original sample $\\mathbf{x}_i$, we construct $\\mathbf{x}_i' = \\mathbf{x}_i^{(j \\leftarrow v)}$.\n2.  For each modified sample $\\mathbf{x}_i'$, calculate the model's predicted probability $p(\\mathbf{x}_i')$.\n3.  The PDP value is the average of these probabilities over all $N$ samples in the dataset:\n$$PD_j(v) \\approx \\frac{1}{N}\\sum_{i=1}^N p\\left(\\mathbf{x}_i^{(j \\leftarrow v)}\\right)$$\nThis procedure is repeated for each value in the specified grid for the feature, yielding a set of points that can be plotted to visualize the feature's effect.\n\nThe final algorithm proceeds by first defining the dataset and model parameters as constants. It then iterates through the three specified test cases $(R, s)$. In each iteration, it calculates the baseline loss, then the PFI for sleep duration ($j=0$) and medication adherence ($j=1$), and finally the PDP values for the same two features over their respective grids. All floating-point results are rounded to six decimal places before being formatted into the final required string output.", "answer": "[[0.584742,0.113269,0.063194,[0.603099,0.48918,0.366556],[0.536341,0.467474,0.395786]],[0.584742,0.089856,0.07684,[0.603099,0.48918,0.366556],[0.536341,0.467474,0.395786]],[0.584742,0.087791,0.076356,[0.603099,0.48918,0.366556],[0.536341,0.467474,0.395786]]]", "id": "4690017"}]}