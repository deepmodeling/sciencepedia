{"hands_on_practices": [{"introduction": "Bootstrap analysis is a powerful simulation-based method, but its results are not exact; they are subject to Monte Carlo error from using a finite number of replicates. This exercise delves into the statistical theory behind this uncertainty, tasking you with deriving how the precision of a bootstrap percentile estimate scales with the number of replicates, $B$ [@problem_id:4601294]. By completing this practice, you will gain the fundamental knowledge needed to determine an adequate number of bootstrap replicates for achieving a desired level of precision in your own analyses.", "problem": "In a Visual Predictive Check (VPC) for a population pharmacokinetic analysis in clinical pharmacology, suppose a model is used to generate $B$ parametric bootstrap replicates of predicted drug concentration at a fixed time point $t^{\\ast}$. For a given percentile level $p \\in (0,1)$ (for example, $p=0.025$ or $p=0.975$ for a two-sided $95$ confidence interval), the bootstrap percentile confidence interval (CI) endpoint at time $t^{\\ast}$ is the $p$-quantile of the predictive distribution of concentration at $t^{\\ast}$. Let the true cumulative distribution function at $t^{\\ast}$ be $F(x)$, with corresponding probability density function $f(x)$, and let the true $p$-quantile be $q_{p}$ satisfying $F(q_{p}) = p$. The empirical cumulative distribution function based on $B$ replicates is $F_{B}(x) = \\frac{1}{B} \\sum_{b=1}^{B} \\mathbf{1}\\{X_{b} \\leq x\\}$, where $X_{b}$ denotes the $b$-th bootstrap replicate concentration at $t^{\\ast}$, and the empirical $p$-quantile (the percentile CI endpoint estimated from $B$ replicates) is $\\hat{q}_{p}$ defined by $F_{B}(\\hat{q}_{p}) = p$.\n\nStarting only from the binomial variance of the empirical cumulative distribution function and standard smoothness assumptions for quantile functions, derive the leading-order asymptotic expression for the Monte Carlo error of the percentile CI endpoint $\\hat{q}_{p}$ in terms of $B$, and show that its half-width scales as $\\mathcal{O}(B^{-1/2})$. Then, using a normal approximation at confidence level $1-\\alpha$ for the Monte Carlo variability of $\\hat{q}_{p}$, compute a closed-form expression for the number of bootstrap replicates $B$ required so that the half-width of the Monte Carlo error in $\\hat{q}_{p}$ is less than a prescribed tolerance $\\epsilon > 0$. Express your final answer symbolically in terms of $p$, $f(q_{p})$, $\\epsilon$, and the standard normal quantile $z_{1-\\alpha/2}$, and do not include any units. No numerical evaluation is required.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n- $B$: number of parametric bootstrap replicates.\n- $t^{\\ast}$: a fixed time point.\n- $p \\in (0,1)$: a given percentile level.\n- $F(x)$: the true cumulative distribution function (CDF) of concentration at $t^{\\ast}$.\n- $f(x)$: the true probability density function (PDF) of concentration at $t^{\\ast}$, where $f(x) = F'(x)$.\n- $q_{p}$: the true $p$-quantile, defined by $F(q_{p}) = p$.\n- $X_{b}$: the $b$-th bootstrap replicate concentration at $t^{\\ast}$.\n- $F_{B}(x) = \\frac{1}{B} \\sum_{b=1}^{B} \\mathbf{1}\\{X_{b} \\leq x\\}$: the empirical cumulative distribution function (ECDF).\n- $\\hat{q}_{p}$: the empirical $p$-quantile (the percentile CI endpoint), defined by $F_{B}(\\hat{q}_{p}) = p$.\n- $1-\\alpha$: the confidence level for the Monte Carlo variability.\n- $\\epsilon > 0$: a prescribed tolerance for the half-width of the Monte Carlo error.\n- $z_{1-\\alpha/2}$: the standard normal quantile for a two-sided confidence interval.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is located in the intersection of clinical pharmacology (VPCs, pop-PK analysis) and mathematical statistics (bootstrap methods, asymptotic distribution of sample quantiles). All concepts are standard and well-established. The problem is scientifically sound.\n- **Well-Posed**: The problem asks for the derivation of a standard asymptotic result and its application to a sample size calculation. With the stated givens and the \"standard smoothness assumptions\" (i.e., $f(x)$ is continuous and positive at $q_p$), the problem is well-posed and has a unique, meaningful solution.\n- **Objective**: The problem is stated using precise mathematical definitions and objective language. It is free of any subjective or opinion-based claims.\n\nThe problem does not exhibit any of the flaws listed in the instructions (e.g., scientific unsoundness, incompleteness, ambiguity).\n\n### Step 3: Verdict and Action\nThe problem is **valid**. The solution process will now proceed.\n\n### Derivation of Asymptotic Error\n\nThe first goal is to derive the leading-order asymptotic expression for the Monte Carlo error of $\\hat{q}_{p}$. This error is the random deviation $\\hat{q}_{p} - q_{p}$ arising from the finite number of Monte Carlo replicates, $B$. We characterize this error by its variance, or its standard deviation (standard error).\n\nThe problem states to start from the binomial variance of the empirical CDF. Let us evaluate the ECDF, $F_B(x)$, at the true quantile $q_p$.\n$$F_B(q_p) = \\frac{1}{B} \\sum_{b=1}^{B} \\mathbf{1}\\{X_b \\le q_p\\}$$\nEach $X_b$ is a draw from the true predictive distribution with CDF $F(x)$. Therefore, the indicator function $\\mathbf{1}\\{X_b \\le q_p\\}$ is a Bernoulli random variable with probability of success $P(X_b \\le q_p) = F(q_p) = p$.\nThe sum $\\sum_{b=1}^{B} \\mathbf{1}\\{X_b \\le q_p\\}$ is the sum of $B$ independent and identically distributed Bernoulli($p$) trials, so it follows a binomial distribution, $\\text{Binomial}(B,p)$.\nThe ECDF $F_B(q_p)$ is the average of these Bernoulli variables. Its expectation is $E[F_B(q_p)] = p$, and its variance is:\n$$\\text{Var}[F_B(q_p)] = \\text{Var}\\left(\\frac{1}{B} \\sum_{b=1}^{B} \\mathbf{1}\\{X_b \\le q_p\\}\\right) = \\frac{1}{B^2} \\times B p(1-p) = \\frac{p(1-p)}{B}$$\nThis is the binomial variance of the ECDF at $q_p$.\n\nNow, we must relate the variability of $F_B(q_p)$ to the variability of the empirical quantile $\\hat{q}_p$. A well-known result in large-sample theory, justifiable under the problem's smoothness assumptions on $F(x)$ (specifically, that $f(q_p) = F'(q_p)$ exists and is non-zero), is the Bahadur representation of a sample quantile. It gives a first-order approximation for the deviation of the sample quantile from the true quantile:\n$$\\hat{q}_p - q_p \\approx \\frac{p - F_B(q_p)}{f(q_p)}$$\nThis approximation becomes exact in the limit as $B \\to \\infty$ after appropriate scaling. Taking the variance of both sides gives the asymptotic variance of $\\hat{q}_p$:\n$$\\text{Var}(\\hat{q}_p) = \\text{Var}(\\hat{q}_p - q_p) \\approx \\text{Var}\\left(\\frac{p - F_B(q_p)}{f(q_p)}\\right)$$\nSince $p$ and $f(q_p)$ are constants, we can write:\n$$\\text{Var}(\\hat{q}_p) \\approx \\frac{1}{(f(q_p))^2} \\text{Var}(p - F_B(q_p)) = \\frac{1}{(f(q_p))^2} \\text{Var}(-F_B(q_p)) = \\frac{1}{(f(q_p))^2} \\text{Var}(F_B(q_p))$$\nSubstituting the binomial variance for $\\text{Var}(F_B(q_p))$:\n$$\\text{Var}(\\hat{q}_p) \\approx \\frac{1}{(f(q_p))^2} \\left(\\frac{p(1-p)}{B}\\right) = \\frac{p(1-p)}{B (f(q_p))^2}$$\nThe \"Monte Carlo error\" is typically quantified by the standard error (SE), which is the square root of the variance. The leading-order asymptotic expression for the standard error of the percentile CI endpoint $\\hat{q}_p$ is:\n$$\\text{SE}(\\hat{q}_p) = \\sqrt{\\text{Var}(\\hat{q}_p)} \\approx \\frac{\\sqrt{p(1-p)}}{f(q_p) \\sqrt{B}}$$\nThe half-width of a confidence interval for $q_p$ is proportional to its standard error. As the SE is proportional to $1/\\sqrt{B}$, the half-width scales as $\\mathcal{O}(B^{-1/2})$, as required.\n\n### Calculation of Required Number of Replicates\n\nThe second goal is to find the number of replicates $B$ needed to achieve a desired precision.\nBy the Central Limit Theorem, for large $B$, the distribution of $\\hat{q}_p$ is asymptotically normal:\n$$\\hat{q}_p \\sim \\mathcal{N}\\left(q_p, \\text{Var}(\\hat{q}_p)\\right) \\quad \\text{or} \\quad \\hat{q}_p \\sim \\mathcal{N}\\left(q_p, \\frac{p(1-p)}{B (f(q_p))^2}\\right)$$\nA confidence interval for the true quantile $q_p$ is constructed to quantify the \"Monte Carlo variability of $\\hat{q}_p$\". A two-sided confidence interval at level $1-\\alpha$ is given by:\n$$\\hat{q}_p \\pm z_{1-\\alpha/2} \\times \\text{SE}(\\hat{q}_p)$$\nwhere $z_{1-\\alpha/2}$ is the quantile of the standard normal distribution such that $P(Z \\le z_{1-\\alpha/2}) = 1-\\alpha/2$ for $Z \\sim \\mathcal{N}(0,1)$.\n\nThe half-width (HW) of this confidence interval is:\n$$HW = z_{1-\\alpha/2} \\times \\text{SE}(\\hat{q}_p) = z_{1-\\alpha/2} \\frac{\\sqrt{p(1-p)}}{f(q_p) \\sqrt{B}}$$\nThe problem requires that this half-width be less than a prescribed tolerance $\\epsilon$. To find the minimum number of replicates, we set the half-width equal to $\\epsilon$:\n$$\\epsilon = z_{1-\\alpha/2} \\frac{\\sqrt{p(1-p)}}{f(q_p) \\sqrt{B}}$$\nNow, we solve for $B$:\n$$\\sqrt{B} = \\frac{z_{1-\\alpha/2} \\sqrt{p(1-p)}}{\\epsilon f(q_p)}$$\nSquaring both sides yields the required number of bootstrap replicates:\n$$B = \\left( \\frac{z_{1-\\alpha/2} \\sqrt{p(1-p)}}{\\epsilon f(q_p)} \\right)^2 = \\frac{z_{1-\\alpha/2}^2 p(1-p)}{\\epsilon^2 (f(q_p))^2}$$\nThis is the closed-form expression for $B$ in terms of the specified parameters.", "answer": "$$\\boxed{\\frac{z_{1-\\alpha/2}^2 p(1-p)}{\\epsilon^2 (f(q_p))^2}}$$", "id": "4601294"}, {"introduction": "The visual appeal and statistical validity of a Visual Predictive Check (VPC) depend critically on how the data are binned along the independent variable. This choice involves a fundamental trade-off between bias and variance in the estimated quantiles. This practice challenges you to compare several common binning strategies—equal-width, equal-count, and k-means—in a realistic pharmacokinetic scenario with non-uniform sampling [@problem_id:4601332]. Successfully navigating this problem will equip you to make informed, justifiable decisions about VPC design to ensure your diagnostics are both powerful and reliable.", "problem": "In a Visual Predictive Check (VPC) for a nonlinear mixed effects pharmacokinetic model, you compute per-bin sample quantiles of observed concentration given time, denoted by $Q_{p}(t)$ for $p \\in \\{0.10, 0.50, 0.90\\}$, to compare with simulated prediction intervals. Observed sampling times $t$ are strongly right-skewed: approximately $80\\%$ of observations lie in $t \\in [0,8]$ hours, with dense early sampling and multiple protocol-driven time points, while the remaining $20\\%$ lie in $t \\in (8,48]$ hours with sparser, uneven sampling and gaps. The conditional distribution of concentration $C$ given $t$ is continuous, and its quantile function $Q_{p}(t)$ decreases smoothly in $t$, with a steeper decline for small $t$ and a gradual flattening for larger $t$. You must choose a binning strategy for $t$ to compute per-bin quantile estimates for the VPC and to generate nonparametric bootstrap confidence intervals within each bin using $B_{\\text{boot}}$ bootstrap resamples.\n\nConsider three ways to partition the $t$-axis into $B$ bins:\n- Equal-width binning: divide the observed range of $t$ into $B$ intervals of equal length.\n- Equal-count binning: divide the ordered $t$ values into $B$ adjacent bins each containing the same number $n_{b}$ of observations (up to rounding by at most $1$).\n- $k$-means binning on $t$: apply $k$-means clustering with Euclidean distance on the scalar $t$ using $k=B$, assigning each observation to a cluster and taking each cluster’s convex hull on $t$ as a bin.\n\nAssume within-bin nonparametric bootstrap resampling is used to quantify uncertainty in per-bin sample quantiles, with resample size equal to the original per-bin count $n_{b}$. Using only fundamental properties of quantiles, mixtures, and large-sample behavior of sample quantiles, compare these three binning methods in terms of bias and variance of the per-bin quantile estimators and the stability of the bootstrap confidence intervals, given the stated distributional properties of $t$ and $Q_{p}(t)$. Which choice is most appropriate for this VPC, and why?\n\nSelect the single best option.\n\nA. Equal-width binning is most appropriate because equal time span per bin guarantees both minimal bias of per-bin sample quantiles and approximately equal variance across bins, leading to uniformly narrow bootstrap confidence intervals even under right-skewed $t$.\n\nB. Equal-count binning is most appropriate because it equalizes per-bin sample size $n_{b}$ and therefore stabilizes the variance of per-bin quantile estimators and their bootstrap confidence intervals; with right-skewed $t$ and rapidly changing $Q_{p}(t)$ at small $t$, equal-count bins become narrower early (limiting bias where curvature is high) and wider late (where curvature is low, keeping bias small).\n\nC. $k$-means binning is most appropriate because it ensures both equal bin widths on $t$ and equal per-bin counts, simultaneously minimizing bias and variance of per-bin quantiles and equalizing bootstrap interval widths.\n\nD. $k$-means binning is most appropriate because minimizing within-bin squared distances on $t$ directly minimizes the bias of per-bin sample quantiles in the presence of trends in $Q_{p}(t)$, and therefore also yields uniform variance and bootstrap interval widths across bins regardless of the skewness of $t$.", "solution": "The goal is to compare binning strategies for $t$ in a Visual Predictive Check (VPC) based on their effects on bias and variance of per-bin quantile estimators and on the stability of bootstrap confidence intervals, given a strongly right-skewed distribution of $t$ and a smooth but nonstationary quantile function $Q_{p}(t)$ that changes rapidly for small $t$ and slowly for large $t$.\n\nWe proceed from fundamental definitions and well-tested asymptotic results:\n\n1. Definition of per-bin quantile targets and bias due to binning. For a bin indexed by $b$ with $t \\in I_{b}$ and empirical within-bin distribution $F_{t|b}$, the pooled data within the bin are draws from the conditional mixture distribution\n$$\nG_{b}(c) \\equiv \\int F_{C|t}(c \\mid t)\\,\\mathrm{d}F_{t|b}(t),\n$$\nwith density\n$$\ng_{b}(c) \\equiv \\int f_{C|t}(c \\mid t)\\,\\mathrm{d}F_{t|b}(t).\n$$\nThe per-bin sample quantile at level $p$, denoted $\\widehat{Q}_{p,b}$, is a consistent estimator of the mixture quantile $Q_{p,b}^{\\text{mix}}$, defined by $G_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)=p$. The scientifically relevant target for visualization is the pointwise conditional quantile $Q_{p}(t)$ as a function of $t$. Therefore, binning induces a bias if $Q_{p}(t)$ varies within $I_{b}$, because $Q_{p,b}^{\\text{mix}} \\neq Q_{p}(t_{0})$ for a generic $t_{0} \\in I_{b}$. For small bins and smooth $Q_{p}(t)$, a first-order approximation shows that the bias scales with within-bin variation of $t$ and the local slope or curvature of $Q_{p}(t)$. Hence, narrower bins where $|Q_{p}'(t)|$ or $|Q_{p}''(t)|$ is large reduce bias.\n\n2. Large-sample variance of sample quantiles. For independent and identically distributed samples of size $n_{b}$ from a continuous distribution with density $g_{b}$ positive at its $p$-th quantile $Q_{p,b}^{\\text{mix}}$, the asymptotic variance of the sample quantile satisfies the classical result\n$$\n\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right) \\approx \\frac{p(1-p)}{n_{b}\\,g_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)^{2}}.\n$$\nThus, for fixed $p$ and similar $g_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)$ across bins, the variance scales approximately as $1/n_{b}$. Consequently, per-bin sample size $n_{b}$ is the dominant driver of variance heterogeneity across bins. The nonparametric bootstrap within each bin resamples $n_{b}$ observations with replacement, so the bootstrap distribution and confidence interval widths largely reflect this variance; small $n_{b}$ yields unstable and wide intervals.\n\n3. Trade-off between within-bin width on $t$ (driving bias) and per-bin count $n_{b}$ (driving variance). Where $Q_{p}(t)$ changes rapidly (small $t$), bias control favors narrow bins; where $Q_{p}(t)$ changes slowly (large $t$), wider bins can be tolerated without incurring large bias. Where $t$ is sparse (large $t$), equal-width bins risk very small $n_{b}$, inflating variance and destabilizing the bootstrap.\n\nGiven the scenario: $t$ is strongly right-skewed with dense early sampling ($t \\in [0,8]$) and sparse late sampling ($t \\in (8,48]$). The quantile function $Q_{p}(t)$ decreases more steeply at small $t$ and flattens at larger $t$.\n\nWe now analyze each binning method.\n\nEqual-width binning. Equal-width bins impose the same time span per bin. In the dense early region, each bin will include many observations, so $n_{b}$ will be large and $\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right)$ will be small, producing narrow bootstrap intervals. In the sparse late region, some bins will have small $n_{b}$, inflating variance and widening bootstrap intervals, potentially to the point of instability if $n_{b}$ is too small for extreme quantiles. With respect to bias, equal-width bins control the maximum within-bin time span uniformly; however, since $Q_{p}(t)$ changes more rapidly at small $t$, the bias there can still be appreciable for a fixed bin width because bias is driven by the magnitude of $|Q_{p}'(t)|$ and $|Q_{p}''(t)|$. In contrast, at large $t$ where $Q_{p}(t)$ is flatter, equal-width bins incur less bias. Overall, equal-width binning yields pronounced variance heterogeneity across bins due to the right-skewed $t$, with high-variance, unstable late-time quantiles and bootstrap intervals. This violates the goal of stable, interpretable VPC intervals across $t$.\n\nEqual-count binning. Equal-count bins enforce $n_{b}$ nearly constant across bins, directly stabilizing $\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right)$ via the $1/n_{b}$ scaling and leading to bootstrap intervals with more uniform widths across $t$. Because $t$ is dense early, equal-count bins there will be narrow in $t$, which reduces bias where $Q_{p}(t)$ changes rapidly. Because $t$ is sparse late, equal-count bins will be wider, potentially increasing bias; however, in the stated scenario $Q_{p}(t)$ flattens at large $t$, so the bias penalty from wider late-time bins is mitigated. Net effect: reduced bias where it matters (small $t$), controlled bias where curvature is low (large $t$), and stabilized variance and bootstrap interval widths across bins.\n\n$k$-means binning on $t$. In one dimension with Euclidean distance, $k$-means partitions $t$ into contiguous intervals (Voronoi cells) with centroids located more densely where observations are dense. This tends to produce narrower bins in dense early regions and wider bins in sparse late regions, which qualitatively aligns with bias control similar to equal-count binning. However, $k$-means does not enforce equal per-bin counts $n_{b}$, nor does it directly account for $Q_{p}(t)$ or $f_{C|t}$. Consequently, per-bin sample sizes can still vary, particularly in the presence of gaps or clusters in $t$, leading to heterogeneous variances and bootstrap interval widths. Moreover, $k$-means minimizes within-bin squared distance on $t$ rather than directly minimizing the bias of mixture quantiles; while reduced within-bin spread in $t$ can reduce bias, there is no guarantee of variance stabilization or bias optimality relative to equal-count when $Q_{p}(t)$ curvature and sampling density vary in different ways.\n\nSynthesis. The fundamental variance relation $\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right) \\approx p(1-p)/\\left(n_{b}\\,g_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)^{2}\\right)$ highlights $n_{b}$ as the key driver of variance and bootstrap interval width. Equal-count binning directly stabilizes $n_{b}$, and its adaptive bin widths in $t$ naturally match the need for narrow bins where $Q_{p}(t)$ changes quickly and wider bins where it is flat. Equal-width binning fails to stabilize variance under skewed $t$, and $k$-means does not guarantee equal $n_{b}$ or uniform bootstrap stability. Therefore, equal-count best balances bias and variance for the stated $t$ distribution and $Q_{p}(t)$ behavior.\n\nOption-by-option analysis:\n\nA. Claims equal-width yields both minimal bias and approximately equal variance across bins under right-skewed $t$. This contradicts the variance scaling with $1/n_{b}$: equal-width produces large $n_{b}$ in early bins and small $n_{b}$ in late bins, hence heterogeneous variances and bootstrap widths. Bias is not uniformly minimal because $Q_{p}(t)$ changes rapidly at small $t$; fixed width can leave nontrivial bias early. Incorrect.\n\nB. Notes that equal-count stabilizes $n_{b}$, hence variance and bootstrap intervals, and that narrower early bins reduce bias where $Q_{p}(t)$ changes rapidly while wider late bins incur small bias where curvature is low. This aligns with the asymptotic variance relation and the bias considerations for mixtures. Correct.\n\nC. Asserts that $k$-means ensures both equal bin width and equal counts. In one-dimensional $k$-means, neither equal widths nor equal counts are guaranteed; counts and widths adapt to local density without equality constraints. Thus the stated reasons are false. Incorrect.\n\nD. Claims $k$-means directly minimizes quantile bias and yields uniform variance and bootstrap widths regardless of skewness. $k$-means minimizes within-bin squared deviations in $t$, not quantile bias, and does not ensure equal $n_{b}$ or uniform bootstrap widths, particularly with skewed $t$ and gaps. Incorrect.\n\nTherefore, the most appropriate choice is equal-count binning.", "answer": "$$\\boxed{B}$$", "id": "4601332"}, {"introduction": "This final practice synthesizes the concepts of pharmacokinetic modeling, VPC construction, and bootstrap analysis into a comprehensive implementation task. You will build a partial VPC from the ground up, focusing on mechanistically-defined time windows and using a non-parametric bootstrap to quantify uncertainty in the model's predictive coverage [@problem_id:4601305]. This hands-on coding exercise will solidify your understanding by bridging the gap between theoretical principles and their practical application in a typical pharmacometric workflow.", "problem": "A single-dose oral pharmacokinetic scenario is considered under a one-compartment model with first-order absorption and first-order elimination. The structural concentration-time function for dose $D$ administered at time $t = 0$ is given by the well-tested formula derived from mass balance and linear disposition for a one-compartment model with first-order absorption:\n$$\nC(t) = \\begin{cases}\n\\frac{D K_a}{V (K_a - k)} \\left( e^{-k t} - e^{-K_a t} \\right), & K_a \\neq k, \\\\\n\\frac{D}{V} K_a t e^{-k t}, & K_a = k,\n\\end{cases}\n$$\nwhere $K_a$ is the first-order absorption rate constant in $\\mathrm{h}^{-1}$, $CL$ is the clearance in $\\mathrm{L}\\,\\mathrm{h}^{-1}$, $V$ is the volume of distribution in $\\mathrm{L}$, and $k = CL / V$ is the elimination rate constant in $\\mathrm{h}^{-1}$. The absorption half-life is $t_{1/2,a} = \\ln(2)/K_a$, and the elimination half-life is $t_{1/2,e} = \\ln(2)/k$. The time to maximum concentration under $K_a \\neq k$ is\n$$\nt_{\\max} = \\frac{\\ln(K_a/k)}{K_a - k}.\n$$\n\nA Visual Predictive Check (VPC) is a simulation-based diagnostic in which one generates multiple simulated datasets under a model and compares observed data to simulated quantiles or prediction intervals. Here, a partial VPC is conducted by restricting evaluation to pharmacologically-predefined early and late time windows to avoid cherry-picking. The windows are defined by mechanistic rationale:\n- Early window: $[0, n_a \\cdot t_{1/2,a}]$, where $n_a$ is a positive scalar.\n- Late window: $[t_{\\max} + n_e \\cdot t_{1/2,e}, \\infty)$, where $n_e$ is a positive scalar.\n\nTo account for variability, interindividual variability is applied using a log-normal model for parameters $K_a$, $CL$, and $V$, i.e., $K_a^{(i)} = K_a \\exp(\\eta_{K_a}^{(i)})$, $CL^{(i)} = CL \\exp(\\eta_{CL}^{(i)})$, and $V^{(i)} = V \\exp(\\eta_{V}^{(i)})$, with $\\eta$ terms sampled from a normal distribution with mean $0$ and specified standard deviations $\\omega_{K_a}$, $\\omega_{CL}$, and $\\omega_V$. Residual unexplained variability is modeled using a combined error model such that the simulated observation $\\tilde{C}(t)$ is\n$$\n\\tilde{C}(t) = C(t)\\left(1 + \\epsilon_{\\mathrm{prop}}\\right) + \\epsilon_{\\mathrm{add}},\n$$\nwith $\\epsilon_{\\mathrm{prop}} \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{prop}})$ and $\\epsilon_{\\mathrm{add}} \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{add}})$, independently.\n\nFor a two-sided prediction interval of nominal coverage $1 - \\alpha$ (e.g., $0.90$ when $\\alpha = 0.10$), let $q_{\\mathrm{low}}$ and $q_{\\mathrm{high}}$ be the lower and upper quantile limits of the simulated concentrations pooled across replicates within the defined window. The observed concentrations are generated once using the population parameters (i.e., without interindividual variability) plus residual error as above. The coverage proportion is computed as the fraction of observed windowed concentrations lying in $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$. To quantify uncertainty in the observed coverage, a nonparametric bootstrap resamples the observed windowed concentrations with replacement $B$ times; each bootstrap sample yields a coverage proportion, forming a bootstrap distribution from which the two-sided interval using quantiles at $0.025$ and $0.975$ is obtained. A test case is considered passing if the nominal target $1 - \\alpha$ lies within this bootstrap interval. If the window contains no observed time points, return the sentinel coverage value $-1.0$ and a pass indicator of $0$.\n\nImplement a program that performs the above partial VPC and bootstrap procedure for each of the specified test cases. All times are in $\\mathrm{h}$ and concentrations are in $\\mathrm{mg}\\,\\mathrm{L}^{-1}$. The program must use a fixed random seed for reproducibility. Use inclusive window boundaries.\n\nTest suite (each case provides parameters and specifies whether the early or late window is assessed):\n- Case $1$ (early window, happy path):\n  - $D = 100$ $\\mathrm{mg}$, $K_a = 1.0$ $\\mathrm{h}^{-1}$, $CL = 5.0$ $\\mathrm{L}\\,\\mathrm{h}^{-1}$, $V = 50.0$ $\\mathrm{L}$.\n  - Observation times $\\{0.25, 0.5, 1, 2, 4, 6, 8, 12, 24\\}$ $\\mathrm{h}$.\n  - $n_a = 3.0$, $n_e = 1.0$, window type early.\n  - Interindividual variability standard deviations $\\omega_{K_a} = 0.2$, $\\omega_{CL} = 0.2$, $\\omega_V = 0.2$.\n  - Residual error $\\sigma_{\\mathrm{prop}} = 0.2$, $\\sigma_{\\mathrm{add}} = 0.05$ $\\mathrm{mg}\\,\\mathrm{L}^{-1}$.\n  - Simulation replicates $N_{\\mathrm{sim}} = 1000$, bootstrap resamples $B = 400$, $\\alpha = 0.10$.\n\n- Case $2$ (late window, happy path):\n  - Same as Case $1$, window type late, $n_e = 1.0$.\n\n- Case $3$ (late window, edge case with no windowed observations):\n  - Same as Case $1$, window type late, $n_e = 100.0$.\n\n- Case $4$ (early window, boundary condition inclusion):\n  - $D = 100$ $\\mathrm{mg}$, $K_a = \\ln(2)$ $\\mathrm{h}^{-1}$, $CL = 5.0$ $\\mathrm{L}\\,\\mathrm{h}^{-1}$, $V = 50.0$ $\\mathrm{L}$.\n  - Observation times $\\{0.25, 0.5, 1, 2, 4, 6, 8, 12, 24\\}$ $\\mathrm{h}$.\n  - $n_a = 2.0$, $n_e = 1.0$, window type early.\n  - Interindividual variability and residual error as in Case $1$.\n  - $N_{\\mathrm{sim}} = 1000$, $B = 400$, $\\alpha = 0.10$.\n  - Note: $n_a \\cdot t_{1/2,a} = 2.0$ $\\mathrm{h}$, so the boundary time $t = 2.0$ $\\mathrm{h}$ must be included.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order:\n$[$coverage$_1$,pass$_1$,coverage$_2$,pass$_2$,coverage$_3$,pass$_3$,coverage$_4$,pass$_4]$,\nwhere coverage is a float in $\\left[0,1\\right]$ (or $-1.0$ if no windowed observations) and pass is an integer in $\\{0,1\\}$.", "solution": "The problem requires the implementation of a simulation and analysis workflow common in clinical pharmacology, specifically a partial Visual Predictive Check (VPC) with bootstrap analysis to assess the uncertainty of the model's predictive performance. The solution is designed by algorithmically formalizing the described pharmacokinetic model, statistical procedures, and evaluation criteria.\n\nThe core of the problem lies in a one-compartment pharmacokinetic model with first-order absorption and elimination. The concentration $C(t)$ of a drug at time $t$ following an oral dose $D$ is described by the Bateman function:\n$$\nC(t) = \\begin{cases}\n\\frac{D K_a}{V (K_a - k)} \\left( e^{-k t} - e^{-K_a t} \\right), & K_a \\neq k, \\\\\n\\frac{D}{V} K_a t e^{-k t}, & K_a = k,\n\\end{cases}\n$$\nwhere $K_a$ is the absorption rate constant, $V$ is the volume of distribution, and $k = CL / V$ is the elimination rate constant derived from clearance $CL$. For numerical stability, the case $K_a = k$ is handled separately, representing the mathematical limit of the first expression as $K_a \\to k$. This function is fundamental for all concentration predictions.\n\nThe analysis evaluates the model within specific time windows, mechanistically defined to separate the absorption and elimination phases of the drug's disposition.\n- The early window, focusing on absorption, is defined as $[0, n_a \\cdot t_{1/2,a}]$, where $t_{1/2,a} = \\ln(2)/K_a$ is the absorption half-life.\n- The late window, focusing on elimination, is defined as $[t_{\\max} + n_e \\cdot t_{1/2,e}, \\infty)$, where $t_{1/2,e} = \\ln(2)/k$ is the elimination half-life and $t_{\\max}$ is the time to maximum concentration. $t_{\\max}$ is computed as:\n$$\nt_{\\max} = \\begin{cases}\n\\frac{\\ln(K_a/k)}{K_a - k}, & K_a \\neq k, \\\\\n\\frac{1}{k}, & K_a = k.\n\\end{cases}\n$$\nThe use of population parameters for these calculations ensures consistent window definitions for a given model. All specified observation time points are filtered to retain only those falling within the inclusive boundaries of the calculated window for the given test case. If no time points fall within the window, the analysis for that case is terminated, returning sentinel values.\n\nThe simulation process introduces variability to reflect real-world populations. Interindividual variability (IIV) is modeled by assuming that individual-specific parameters are log-normally distributed around the population typical values. For a generic parameter $P$, an individual's parameter $P^{(i)}$ is simulated as $P^{(i)} = P \\exp(\\eta_P^{(i)})$, where $\\eta_P^{(i)}$ is a random deviate sampled from a normal distribution $\\mathcal{N}(0, \\omega_P^2)$, with $\\omega_P$ being the specified standard deviation for the IIV of that parameter. This is applied to $K_a$, $CL$, and $V$.\n\nResidual unexplained variability (RUV) accounts for measurement error and model misspecification. A combined proportional and additive error model is used. A simulated observation $\\tilde{C}(t)$ is generated from a true model-predicted concentration $C(t)$ by:\n$$\n\\tilde{C}(t) = C(t)\\left(1 + \\epsilon_{\\mathrm{prop}}\\right) + \\epsilon_{\\mathrm{add}},\n$$\nwhere $\\epsilon_{\\mathrm{prop}}$ and $\\epsilon_{\\mathrm{add}}$ are sampled independently from normal distributions $\\mathcal{N}(0, \\sigma_{\\mathrm{prop}}^2)$ and $\\mathcal{N}(0, \\sigma_{\\mathrm{add}}^2)$, respectively.\n\nThe core of the VPC is the creation of a prediction interval (PI). This is achieved by generating $N_{\\mathrm{sim}}$ sets of individual pharmacokinetic profiles. For each simulated individual $i=1, \\dots, N_{\\mathrm{sim}}$, we first sample their individual parameters $K_a^{(i)}, CL^{(i)}, V^{(i)}$ and then compute their concentration profile $C^{(i)}(t)$ at all windowed time points. RUV is then added to these predictions to yield simulated observations $\\tilde{C}^{(i)}(t)$. All simulated observations across all individuals and all time points within the window are pooled into a single large dataset. The lower and upper bounds of the PI, $q_{\\mathrm{low}}$ and $q_{\\mathrm{high}}$, are determined by calculating the $\\alpha/2$ and $1 - \\alpha/2$ quantiles of this pooled distribution, yielding a PI with a nominal coverage of $1 - \\alpha$.\n\nTo evaluate the model, a single \"observed\" dataset is generated. This is done by calculating the concentration profile using the population-typical parameters (i.e., no IIV) and adding a single realization of RUV at each windowed time point. The primary metric, the coverage proportion, is the fraction of these observed data points that fall within the PI, i.e., in the interval $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$.\n\nTo quantify the statistical uncertainty in this observed coverage proportion, a non-parametric bootstrap procedure is employed. The set of observed concentrations within the window is resampled with replacement $B$ times, creating $B$ bootstrap samples, each the same size as the original set of windowed observations. For each bootstrap sample, the coverage proportion is re-calculated using the original, fixed PI, $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$. This process generates a distribution of $B$ coverage proportions. A $95\\%$ confidence interval for the coverage proportion is then constructed by taking the $0.025$ and $0.975$ quantiles from this bootstrap distribution.\n\nFinally, a test case is deemed \"passing\" if the target nominal coverage, $1 - \\alpha$, lies within this $95\\%$ bootstrap confidence interval. This indicates that the observed coverage is statistically consistent with the expected coverage. The entire procedure is encapsulated in a program that iterates through each test case, reporting the calculated coverage proportion and the binary pass/fail indicator. A fixed random seed ensures the reproducibility of all stochastic elements of the simulation and analysis.", "answer": "```python\nimport numpy as np\n\ndef _concentration(t, D, Ka, V, k):\n    \"\"\"Calculates concentration using the one-compartment oral absorption model.\"\"\"\n    if V <= 0:\n        return np.inf\n    \n    # Use the appropriate formula based on whether Ka is close to k\n    # to maintain numerical stability.\n    if abs(Ka - k) < 1e-9:\n        concentration = (D / V) * Ka * t * np.exp(-k * t)\n    else:\n        # Pre-calculate common terms for efficiency.\n        factor = D * Ka / (V * (Ka - k))\n        concentration = factor * (np.exp(-k * t) - np.exp(-Ka * t))\n    \n    return concentration\n\ndef _tmax(Ka, k):\n    \"\"\"Calculates time to maximum concentration.\"\"\"\n    if abs(Ka - k) < 1e-9:\n        return 1.0 / k if k > 0 else 0.0\n    if Ka <= 0 or k <= 0 or Ka/k <= 0: # Ka/k can be negative if one is negative, guard log\n        return 0.0\n    return np.log(Ka / k) / (Ka - k)\n\ndef solve():\n    \"\"\"\n    Main function to run the VPC simulation and bootstrap analysis for all test cases.\n    \"\"\"\n    # Fixed random seed for reproducibility as required.\n    SEED = 0\n    rng = np.random.default_rng(SEED)\n\n    # Test suite definition as per the problem statement.\n    test_cases = [\n        # Case 1 (early window, happy path)\n        {'D': 100.0, 'Ka_pop': 1.0, 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 3.0, 'ne': 1.0, 'window_type': 'early',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n        # Case 2 (late window, happy path)\n        {'D': 100.0, 'Ka_pop': 1.0, 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 3.0, 'ne': 1.0, 'window_type': 'late',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n        # Case 3 (late window, edge case with no windowed observations)\n        {'D': 100.0, 'Ka_pop': 1.0, 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 3.0, 'ne': 100.0, 'window_type': 'late',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n        # Case 4 (early window, boundary condition inclusion)\n        {'D': 100.0, 'Ka_pop': np.log(2), 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 2.0, 'ne': 1.0, 'window_type': 'early',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        # Unpack parameters for the current test case\n        k_pop = case['CL_pop'] / case['V_pop']\n        \n        # Calculate window boundaries based on population parameters\n        if case['window_type'] == 'early':\n            t_half_a = np.log(2) / case['Ka_pop'] if case['Ka_pop'] > 0 else 0\n            window_start, window_end = 0.0, case['na'] * t_half_a\n        else: # 'late'\n            tmax = _tmax(case['Ka_pop'], k_pop)\n            t_half_e = np.log(2) / k_pop if k_pop > 0 else np.inf\n            window_start, window_end = tmax + case['ne'] * t_half_e, np.inf\n\n        # Filter observation times to include only those within the window\n        obs_times_windowed = case['obs_times'][(case['obs_times'] >= window_start) & (case['obs_times'] <= window_end)]\n\n        # Handle the case where no observations are in the window\n        if len(obs_times_windowed) == 0:\n            final_results.extend([-1.0, 0])\n            continue\n            \n        # Generate \"observed\" data: population pred + residual error\n        c_pop_windowed = _concentration(obs_times_windowed, case['D'], case['Ka_pop'], case['V_pop'], k_pop)\n        eps_prop_obs = rng.normal(0, case['sigma_prop'], size=len(obs_times_windowed))\n        eps_add_obs = rng.normal(0, case['sigma_add'], size=len(obs_times_windowed))\n        c_obs_windowed = c_pop_windowed * (1 + eps_prop_obs) + eps_add_obs\n        c_obs_windowed = np.maximum(0, c_obs_windowed) # Concentrations cannot be negative\n\n        # Perform simulation for Prediction Interval (PI)\n        simulated_concentrations = []\n        for _ in range(case['N_sim']):\n            # Sample inter-individual variability (IIV)\n            eta_Ka, eta_CL, eta_V = rng.normal(0, [case['omega_Ka'], case['omega_CL'], case['omega_V']])\n            Ka_ind = case['Ka_pop'] * np.exp(eta_Ka)\n            CL_ind = case['CL_pop'] * np.exp(eta_CL)\n            V_ind = case['V_pop'] * np.exp(eta_V)\n            k_ind = CL_ind / V_ind if V_ind > 0 else np.inf\n            \n            # Calculate individual concentration predictions\n            c_ind_pred = _concentration(obs_times_windowed, case['D'], Ka_ind, V_ind, k_ind)\n            \n            # Add residual unexplained variability (RUV)\n            eps_prop = rng.normal(0, case['sigma_prop'], size=len(obs_times_windowed))\n            eps_add = rng.normal(0, case['sigma_add'], size=len(obs_times_windowed))\n            c_ind_sim = c_ind_pred * (1 + eps_prop) + eps_add\n            \n            simulated_concentrations.extend(np.maximum(0, c_ind_sim))\n\n        # Calculate Prediction Interval from pooled simulated data\n        q_low, q_high = np.quantile(simulated_concentrations, [case['alpha']/2, 1 - case['alpha']/2])\n        \n        # Calculate observed coverage\n        in_interval = (c_obs_windowed >= q_low) & (c_obs_windowed <= q_high)\n        observed_coverage = np.mean(in_interval)\n        \n        # Perform non-parametric bootstrap to find CI of coverage\n        n_obs_windowed = len(c_obs_windowed)\n        bootstrap_coverages = []\n        for _ in range(case['B']):\n            bootstrap_sample = rng.choice(c_obs_windowed, size=n_obs_windowed, replace=True)\n            bootstrap_coverage = np.mean((bootstrap_sample >= q_low) & (bootstrap_sample <= q_high))\n            bootstrap_coverages.append(bootstrap_coverage)\n            \n        ci_low, ci_high = np.quantile(bootstrap_coverages, [0.025, 0.975])\n        \n        # Determine pass/fail status\n        target_coverage = 1 - case['alpha']\n        is_pass = 1 if ci_low <= target_coverage <= ci_high else 0\n        \n        final_results.extend([observed_coverage, is_pass])\n\n    # Format and print the final output as a single line\n    print(f\"[{','.join(f'{x:.6f}' if isinstance(x, float) else str(x) for x in final_results)}]\")\n\nsolve()\n```", "id": "4601305"}]}