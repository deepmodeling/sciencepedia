{"hands_on_practices": [{"introduction": "Before a trial begins, assessing its feasibility is paramount, especially in rare diseases where patient recruitment is a primary obstacle. This exercise guides you through modeling patient accrual using foundational principles of stochastic processes, specifically the Poisson process [@problem_id:4541025]. By mastering this calculation, you can quantitatively estimate recruitment timelines, identify potential bottlenecks, and make informed decisions about trial planning and resource allocation.", "problem": "A multicenter rare disease Phase II trial aims to randomize $N=120$ participants globally. A disease registry maintains $2{,}000$ patients who meet eligibility criteria. Across the participating network of $50$ active sites, each site identifies eligible candidates at a constant expected pre-consent screening yield of $0.02$ candidates per site per month. Historical data indicate that each identified eligible candidate independently provides informed consent with probability $0.30$. Assume the following foundational modeling assumptions appropriate for rare-event accrual in clinical pharmacology: (i) candidate identification at each site is well-approximated by a homogeneous Poisson process with rate $\\lambda_{s}$ per site per month, (ii) independence across sites, (iii) Bernoulli thinning applies at consent with probability $p$, and (iv) the finite registry size constrains the total expected number of consenting candidates to $2,000 \\times 0.30$ but does not otherwise alter per-month rates while the pool is not exhausted. Under these assumptions, use first principles to determine the expected total monthly accrual rate of randomized participants and the expected duration, in months, needed to enroll $N=120$. Express the expected monthly accrual rate in patients per month and the expected duration in months. Provide a single final answer containing both values as a row matrix. No rounding is required unless you choose to represent values in scientific notation, in which case present them to four significant figures.", "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. It constitutes a formalizable exercise in stochastic process modeling as applied to clinical trial accrual.\n\nThe problem asks for two quantities: the expected total monthly accrual rate of randomized participants and the expected duration to enroll a target number of participants, based on a set of clearly defined assumptions and parameters.\n\nFirst, let us define the symbolic representation for the given parameters:\n-   The total number of participants to be enrolled is $N = 120$.\n-   The number of active clinical trial sites is $K = 50$.\n-   The rate of identifying eligible candidates at a single site is given as a constant expected pre-consent screening yield, which we interpret as the rate parameter of a Poisson process. Let this rate be $\\lambda_s = 0.02$ candidates per site per month.\n-   The probability that an identified eligible candidate provides informed consent is $p = 0.30$.\n\nThe problem states that candidate identification at each site follows a homogeneous Poisson process. Let $C_i(t)$ be the number of eligible candidates identified at site $i$ in a time interval of duration $t$ months. According to the problem statement, $C_i(t)$ is a random variable following a Poisson distribution with parameter $\\lambda_s t$.\n$$P(C_i(t)=k) = \\frac{\\exp(-\\lambda_s t)(\\lambda_s t)^k}{k!}$$\nThe rate of this process for a single site is $\\lambda_s = 0.02$ per month.\n\nEach identified candidate subsequently provides consent with a probability $p = 0.30$. This is a Bernoulli trial, independent for each candidate. This process is known as thinning a Poisson process. A fundamental property of Poisson processes is that if events from a Poisson process with rate $\\lambda$ are independently selected with probability $p$, the resulting process of selected events is also a Poisson process with a new rate $\\lambda' = \\lambda \\times p$.\n\nLet us denote the rate of enrollment (i.e., consented participants) at a single site $i$ as $\\lambda_{enroll, i}$. Applying the thinning principle, we have:\n$$ \\lambda_{enroll, i} = \\lambda_s \\times p $$\nSubstituting the given values:\n$$ \\lambda_{enroll, i} = 0.02 \\times 0.30 = 0.006 \\text{ participants per site per month} $$\nThis means the enrollment process at each site is a Poisson process with a rate of $0.006$ participants per month.\n\nThe trial involves $K=50$ sites, and the enrollment processes at these sites are assumed to be independent. The total enrollment process for the entire trial is the superposition (sum) of the $K$ individual site processes. Another fundamental property of Poisson processes states that the sum of $K$ independent Poisson processes with rates $\\lambda_1, \\lambda_2, \\dots, \\lambda_K$ is also a Poisson process with a rate $\\Lambda = \\sum_{i=1}^{K} \\lambda_i$. In this case, all sites are identical, so $\\lambda_{enroll, i}$ is the same for all $i=1, \\dots, K$.\nTherefore, the total enrollment rate for the trial, $\\Lambda$, is:\n$$ \\Lambda = \\sum_{i=1}^{K} \\lambda_{enroll, i} = K \\times \\lambda_{enroll, i} = K \\times \\lambda_s \\times p $$\n\nWe can now calculate the first required quantity: the expected total monthly accrual rate. For a Poisson process with rate $\\Lambda$, the expected number of events in a unit time interval (one month) is equal to $\\Lambda$.\n$$ \\text{Expected monthly accrual rate} = \\Lambda = 50 \\times 0.02 \\times 0.30 $$\n$$ \\Lambda = 1.0 \\times 0.30 = 0.3 \\text{ participants per month} $$\n\nThe second quantity to be determined is the expected duration, in months, to enroll $N=120$ participants.\nFor a Poisson process with rate $\\Lambda$, the time between consecutive events (inter-arrival time) is an exponential random variable with rate parameter $\\Lambda$. Let $T_{arrival}$ be the inter-arrival time. The probability density function of $T_{arrival}$ is $f(t) = \\Lambda \\exp(-\\Lambda t)$ for $t \\ge 0$. The expected value of this inter-arrival time is:\n$$ E[T_{arrival}] = \\frac{1}{\\Lambda} $$\nThe total time to enroll $N$ participants, let's call it $T_N$, is the sum of $N$ such independent and identically distributed inter-arrival times.\n$$ T_N = T_{arrival,1} + T_{arrival,2} + \\dots + T_{arrival,N} $$\nBy the linearity of expectation, the expected total time is the sum of the individual expected times:\n$$ E[T_N] = E[\\sum_{j=1}^{N} T_{arrival,j}] = \\sum_{j=1}^{N} E[T_{arrival,j}] = N \\times E[T_{arrival}] $$\n$$ E[T_N] = N \\times \\frac{1}{\\Lambda} = \\frac{N}{\\Lambda} $$\n\nUsing the values $N=120$ and the previously calculated $\\Lambda=0.3$:\n$$ E[T_{120}] = \\frac{120}{0.3} = \\frac{1200}{3} = 400 \\text{ months} $$\n\nThe problem mentions a finite registry of $2,000$ patients, which implies a total available pool of $2,000 \\times 0.30 = 600$ potentially consenting participants. Since the target enrollment is $N=120$, which is less than $600$, the assumption that the enrollment rate remains constant because the pool is not exhausted is consistent and valid for the duration of the trial.\n\nThe two required values are the expected total monthly accrual rate, $\\Lambda = 0.3$ participants per month, and the expected duration to enroll $N=120$ participants, $E[T_N] = 400$ months. The final answer should present these two values.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.3 & 400\n\\end{pmatrix}\n}\n$$", "id": "4541025"}, {"introduction": "A successful trial depends on a clear and precise definition of the scientific question being answered, a concept formalized by the estimand framework from the International Council for Harmonisation (ICH). This practice challenges you to apply the ICH E9(R1) addendum to a realistic crossover trial scenario, identifying misalignments between the stated estimand, the endpoint definition, and the analysis plan [@problem_id:4541039]. This skill is critical for designing robust trials where the statistical analysis directly addresses the scientific objective, even in the face of real-world events like rescue medication use and patient discontinuation.", "problem": "A sponsor designs a randomized, double-blind, $2$-period, $2$-sequence crossover trial in a rare disease to compare an investigational therapy $A$ versus control $B$. Sequences are $AB$ and $BA$ with a planned washout judged pharmacologically adequate based on the drug’s elimination half-life. Let $i \\in \\{1,\\dots,N\\}$ index participants and $j \\in \\{1,2\\}$ index periods. Let $T_{ij} \\in \\{A,B\\}$ denote the randomized treatment received by participant $i$ in period $j$, and let $Y_{ij}$ denote the continuous primary endpoint measured at the end of period $j$ on a fixed schedule. Rescue medication is permitted for symptom worsening at any time during a period; let $R_{ij} \\in \\{0,1\\}$ indicate whether participant $i$ used rescue during period $j$. Participants may also discontinue early; let $M_{ij} \\in \\{0,1\\}$ indicate whether $Y_{ij}$ is missing at the scheduled time ($M_{ij}=1$ if missing).\n\nThe estimand statement in the protocol is: target population is all randomized participants meeting eligibility criteria; treatment condition of interest is the randomized treatment $A$ versus $B$; variable is the end-of-period endpoint $Y_{ij}$; intercurrent events, including rescue medication and discontinuation, are handled by the treatment policy strategy (that is, the scientific question is the average difference in $Y_{ij}$ comparing $A$ versus $B$ regardless of rescue or discontinuation); the summary measure is the within-participant mean difference at the scheduled end of period, aggregated over sequences and periods, corresponding to a marginal treatment effect.\n\nHowever, the endpoint section defines the primary endpoint for analysis as “the last observed measurement before rescue carried forward to the scheduled end of period,” and the analysis set excludes any participant-periods with rescue use or early discontinuation. The primary analysis is a paired within-participant comparison of treatment periods without explicit adjustment for period or sequence. Intermittent missing data are imputed using last observation carried forward, and $Y_{ij}$ values obtained after rescue are not used.\n\nUsing the International Council for Harmonisation (ICH) E9(R1) addendum on estimands and sensitivity analysis as the fundamental framework, and basic properties of crossover designs (fixed period and sequence effects, random subject effects, and the potential for carryover), evaluate the alignment between the stated estimand, the endpoint definition, and the analysis. Assume randomization is valid and washout is pharmacologically plausible but not infinite. Identify any principal inconsistency and select the remedy that best preserves the originally stated estimand while maintaining scientific and statistical validity in a small-sample rare disease setting. Which option is most appropriate?\n\nA. There is a fundamental misalignment: a treatment policy estimand requires using $Y_{ij}$ at the scheduled time regardless of rescue, but the endpoint definition censors at rescue and the analysis excludes rescue users and discontinuations. Remedy: redefine the endpoint as the scheduled $Y_{ij}$ irrespective of $R_{ij}$, analyze with a linear mixed-effects model for crossover including fixed effects for treatment, period, and sequence and a random subject effect, use a Missing At Random (MAR)-consistent approach such as a Mixed Model for Repeated Measures (MMRM) or inverse probability weighting (IPW) to handle $M_{ij}=1$, and conduct prespecified Missing Not At Random (MNAR) sensitivity analyses (for example, delta-adjusted or reference-based imputation); retain the treatment policy estimand.\n\nB. There is no misalignment: carrying forward the last pre-rescue value and excluding rescue users removes confounding by rescue and targets the desired effect. Remedy: retain the per-protocol analysis and add a test for carryover at conventional significance to ensure validity.\n\nC. The only issue is efficiency loss from excluding rescue users; the estimand and endpoint are aligned. Remedy: keep excluding rescue and discontinuations but increase sample size or borrow external controls to compensate.\n\nD. There is misalignment because the analysis effectively targets a hypothetical scenario without rescue. Remedy: change the estimand to a hypothetical strategy that censors at $R_{ij}=1$, impute missing post-rescue values under a no-rescue model using a tipping-point sensitivity analysis, and keep the paired within-participant comparison without period or sequence effects.\n\nE. The misalignment arises because rescue is a mediator of treatment effect. Remedy: include only post-rescue data and adjust for $R_{ij}$ as a covariate to estimate a direct effect, while continuing to exclude discontinuations and using last observation carried forward for intermittent missingness.", "solution": "The problem statement is critically evaluated for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n- **Trial Design**: Randomized, double-blind, $2$-period, $2$-sequence crossover trial.\n- **Treatments**: Investigational therapy $A$ versus control $B$.\n- **Sequences**: $AB$ and $BA$.\n- **Washout**: Judged pharmacologically adequate.\n- **Population**: Rare disease, $N$ participants indexed by $i \\in \\{1,\\dots,N\\}$.\n- **Periods**: $2$ periods indexed by $j \\in \\{1,2\\}$.\n- **Randomized Treatment**: $T_{ij} \\in \\{A,B\\}$ is the treatment for participant $i$ in period $j$.\n- **Primary Endpoint**: $Y_{ij}$ is a continuous variable measured at the end of period $j$.\n- **Intercurrent Events (ICEs)**:\n    - **Rescue Medication**: $R_{ij} \\in \\{0,1\\}$, where $R_{ij}=1$ indicates use of rescue medication by participant $i$ in period $j$.\n    - **Early Discontinuation**: $M_{ij} \\in \\{0,1\\}$, where $M_{ij}=1$ indicates that $Y_{ij}$ is missing at the scheduled time.\n- **Stated Estimand**:\n    - **Population**: All randomized participants.\n    - **Treatments**: Randomized treatment $A$ versus $B$.\n    - **Variable**: End-of-period endpoint $Y_{ij}$.\n    - **ICE Handling**: Treatment policy strategy (effect is evaluated regardless of rescue use or discontinuation).\n    - **Summary Measure**: Within-participant mean difference at the scheduled end of period, aggregated over sequences and periods (marginal treatment effect).\n- **Endpoint Definition for Analysis**: \"the last observed measurement before rescue carried forward to the scheduled end of period.\"\n- **Analysis Plan**:\n    - **Analysis Set**: Excludes any participant-periods with rescue use ($R_{ij}=1$) or early discontinuation ($M_{ij}=1$).\n    - **Primary Analysis Method**: A paired within-participant comparison of treatment periods.\n    - **Model Adjustments**: No explicit adjustment for period or sequence.\n    - **Missing Data Handling**: Intermittent missing data are imputed using last observation carried forward (LOCF). Values of $Y_{ij}$ obtained after rescue use are not used.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement describes a clinical trial protocol with several components: the design, the scientific question (estimand), the endpoint definition, and the analysis plan. The task is to evaluate the alignment between these components. The problem is scientifically grounded in clinical trial methodology and biostatistics, specifically referencing the ICH E9(R1) framework. It is well-posed, as it asks to identify inconsistencies and propose a valid remedy. The language is objective and precise.\n\nThe core of the validation is to check for internal consistency. A critical examination reveals several major contradictions:\n\n1.  **Contradiction between Estimand and Analysis Set**: The estimand specifies a \"treatment policy\" strategy and a target population of \"all randomized participants.\" This corresponds to an intent-to-treat (ITT) principle, where the effect of treatment is assessed in the full randomized population, irrespective of adherence or other post-randomization events. However, the analysis plan states that the \"analysis set excludes any participant-periods with rescue use or early discontinuation.\" This defines a per-protocol or completer analysis, which estimates the treatment effect only in the subpopulation of participants who adhered to the protocol and did not experience these intercurrent events. Analyzing a subgroup defined by post-randomization events introduces a high risk of selection bias and does not address the scientific question posed by the treatment policy estimand.\n\n2.  **Contradiction between Estimand and Endpoint Definition**: The estimand's variable is the endpoint $Y_{ij}$ measured at the scheduled end of the period. The treatment policy strategy implies that this measurement should be taken as planned, regardless of whether rescue medication was used. The protocol's endpoint definition, however, is \"the last observed measurement before rescue carried forward.\" This fundamentally alters the endpoint variable. Instead of measuring a treatment's effect on the outcome at the end of the period, it measures the outcome at an earlier, variable time point (just before rescue) or uses an imputed value. This does not align with the estimand's specified variable.\n\n3.  **Contradiction in Handling of Rescue**: The \"Endpoint Definition\" suggests using a LOCF-like approach for rescue users (\"carried forward\"), which implies these participants' data are modified and included. The \"Analysis Plan\" states that participant-periods with rescue use are excluded entirely. These are mutually exclusive actions.\n\n4.  **Flawed Statistical Method**: The specified analysis is a \"paired within-participant comparison... without explicit adjustment for period or sequence.\" A crossover design is susceptible to period effects (systematic changes over time, independent of treatment) and sequence (or carryover) effects (the effect of the period $1$ treatment lingering into period $2$). Failing to model these effects can lead to biased estimates of the treatment effect and incorrect standard errors. The standard and appropriate analysis for a $2 \\times 2$ crossover trial is a mixed-effects model that includes fixed effects for treatment, period, and sequence, and a random effect for the participant.\n\nThe problem itself is not invalid; rather, it describes a scientifically and statistically flawed trial protocol. The task of identifying and remedying these flaws is a valid and well-posed problem in biostatistics.\n\n### Step 3: Verdict and Action\nThe problem is valid. The protocol it describes is internally inconsistent and scientifically flawed. The task is to identify the best remedy. I will proceed with the option-by-option analysis.\n\n### Derivation and Option Analysis\n\nThe principal inconsistency is the disconnect between the scientific question (the **estimand**) and the planned analysis. The estimand asks for the marginal treatment effect under a **treatment policy** strategy, which evaluates the effect of being assigned to treatment $A$ versus $B$ in all randomized patients, regardless of whether they subsequently use rescue medication or discontinue. This is a pragmatic question about the overall effectiveness of a treatment strategy. The planned analysis, by excluding participants who use rescue or discontinue, attempts to estimate a different quantity: the treatment effect in a selected subgroup of \"good compliers.\" This is a form of per-protocol analysis and is subject to selection bias, as the need for rescue medication is often correlated with treatment efficacy.\n\nFurthermore, the specified statistical method (a simple paired comparison) is inadequate for a crossover design, as it ignores potential period and sequence effects, which are known sources of bias. The handling of missing data via LOCF is also an outdated and disfavored method, known to produce biased results, especially when discontinuation is related to treatment outcome.\n\nA valid remedy must align the analysis with the stated estimand and employ statistically sound methods.\n\n**Option A Evaluation**:\n- **Diagnosis**: This option correctly identifies the \"fundamental misalignment,\" stating that \"a treatment policy estimand requires using $Y_{ij}$ at the scheduled time regardless of rescue, but the endpoint definition censors at rescue and the analysis excludes rescue users and discontinuations.\" This is a precise and accurate diagnosis of the core problem.\n- **Remedy**:\n    1.  It proposes redefining the endpoint to be \"the scheduled $Y_{ij}$ irrespective of $R_{ij}$.\" This correctly aligns the measurement with the estimand's variable.\n    2.  It proposes \"a linear mixed-effects model for crossover including fixed effects for treatment, period, and sequence and a random subject effect.\" This is the gold-standard statistical model for analyzing data from a crossover trial, correctly accounting for the data structure and potential confounding factors.\n    3.  It proposes using a \"Missing At Random (MAR)-consistent approach such as a Mixed Model for Repeated Measures (MMRM) or inverse probability weighting (IPW) to handle $M_{ij}=1$.\" This is the modern, principled approach to handling missing data, vastly superior to LOCF or complete-case analysis (exclusion). MMRM is particularly well-suited as it is a natural extension of the mixed-effects model.\n    4.  It recommends conducting \"prespecified Missing Not At Random (MNAR) sensitivity analyses.\" This is a critical step required by modern regulatory guidelines (ICH E9(R1)) to assess the robustness of the conclusions to the untestable MAR assumption.\n    5.  It concludes by suggesting to \"retain the treatment policy estimand.\" This fulfills the problem's constraint to find a remedy that preserves the original scientific question.\n- **Verdict**: **Correct**. This option provides a comprehensive and methodologically rigorous solution that corrects all identified flaws and aligns the analysis with the stated scientific objective and modern statistical practice.\n\n**Option B Evaluation**:\n- **Diagnosis**: This option claims \"There is no misalignment.\" This is factually incorrect, as demonstrated by the multiple contradictions between the estimand and the analysis plan.\n- **Remedy**: It suggests retaining the flawed per-protocol analysis. This analysis does not estimate the target estimand and is subject to bias. Adding a test for carryover, while good practice in general, does not remedy the fundamental selection bias from excluding rescue users.\n- **Verdict**: **Incorrect**. The diagnosis is wrong, and the remedy is inadequate.\n\n**Option C Evaluation**:\n- **Diagnosis**: This option claims the only issue is \"efficiency loss.\" This fundamentally mischaracterizes the problem. Excluding participants based on a post-randomization outcome ($R_{ij}=1$) introduces systematic bias, which is a problem of validity, not just efficiency (statistical power). A larger sample size cannot correct for bias.\n- **Remedy**: Increasing sample size or borrowing external controls does not solve the problem of bias. A larger sample size would only provide a more precise, but still wrong, answer.\n- **Verdict**: **Incorrect**. It misdiagnoses bias as a mere loss of efficiency.\n\n**Option D Evaluation**:\n- **Diagnosis**: It correctly notes that the analysis \"effectively targets a hypothetical scenario without rescue.\" This type of estimand is known as a \"hypothetical estimand\" in the ICH E9(R1) framework.\n- **Remedy**: It proposes changing the estimand to match the analysis. While this is a possible choice in a real-world scenario, the problem asks to \"preserve the originally stated estimand.\" This remedy violates that constraint. Furthermore, it proposes to \"keep the paired within-participant comparison without period or sequence effects,\" which is a statistically flawed model.\n- **Verdict**: **Incorrect**. The remedy violates a key constraint of the question and retains a flawed statistical model.\n\n**Option E Evaluation**:\n- **Diagnosis**: It identifies rescue as a mediator, which is a correct observation in the causal pathway. However, the misalignment is not because it *is* a mediator, but because the estimand and analysis treat its role inconsistently.\n- **Remedy**: The proposed remedy is to \"include only post-rescue data\" and \"adjust for $R_{ij}$ as a covariate.\" This is nonsensical. It would discard all data from participants who did not require rescue, who may be the majority and represent treatment success. Adjusting for a post-randomization mediator/collider like $R_{ij}$ as a standard covariate in a regression model is known to induce bias and does not estimate a meaningful causal effect (like a direct effect) without specialized causal mediation techniques, which are not what is described. The stated goal is a total effect (treatment policy), not a direct effect.\n- **Verdict**: **Incorrect**. The remedy is statistically and logically flawed and would estimate a quantity that is neither the target of the estimand nor a valid causal effect.\n\nBased on this comprehensive analysis, Option A is the only one that correctly identifies all aspects of the misalignment and proposes a complete, modern, and statistically valid remedy that aligns the analysis with the original scientific question.", "answer": "$$\\boxed{A}$$", "id": "4541039"}, {"introduction": "Rare disease trials often measure multiple endpoints to maximize the information gained from a small and precious sample of participants, but this creates a multiple testing problem. This practice provides hands-on experience with the Holm–Bonferroni method, a powerful procedure for controlling the Family-Wise Error Rate ($FWER$) when performing multiple hypothesis tests [@problem_id:4541012]. Understanding how to correctly adjust for multiplicity is essential for maintaining statistical rigor and ensuring that any claims of efficacy are credible and not due to chance.", "problem": "A Phase II clinical investigation in a rare monogenic disease evaluates the pharmacodynamic impact of a novel small-molecule therapy using four pre-specified, clinically meaningful co-primary endpoints. Because small sample sizes and multiple endpoints are characteristic of trials in rare diseases, the design controls the Family-Wise Error Rate (FWER) at level $\\alpha = 0.05$ across the four endpoint hypotheses using the Holm–Bonferroni step-down procedure, which strongly controls FWER under arbitrary dependence among endpoints. Suppose the independent analyses of the four endpoints yield observed $p$-values $(0.01, 0.03, 0.04, 0.20)$ in the original endpoint order $1$ through $4$. Starting from the foundational definition of FWER control and the interpretation of $p$-values as tail probabilities under their respective null hypotheses, derive the Holm–Bonferroni adjusted $p$-values for the four endpoints and determine how many endpoints remain significant when the adjusted $p$-values are assessed at $\\alpha = 0.05$. Round each adjusted $p$-value to four significant figures. Present your final answer as a single row matrix with five entries: the first four entries are the Holm–Bonferroni adjusted $p$-values in the original endpoint order $(1,2,3,4)$, and the fifth entry is the number of endpoints that remain significant at level $\\alpha = 0.05$. No units are required.", "solution": "The user has provided a problem statement that requires validation and, if valid, a complete solution.\n\n### Step 1: Extract Givens\n- Number of co-primary endpoints, $m$: $4$.\n- Significance level (Family-Wise Error Rate, FWER), $\\alpha$: $0.05$.\n- Multiple testing correction procedure: Holm–Bonferroni step-down procedure.\n- Observed unadjusted $p$-values for endpoints $1, 2, 3, 4$: $(p_1, p_2, p_3, p_4) = (0.01, 0.03, 0.04, 0.20)$.\n- Required rounding for adjusted $p$-values: four significant figures.\n- Required output: A row matrix containing the four adjusted $p$-values in their original order, and the number of endpoints that remain significant at $\\alpha = 0.05$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria.\n- **Scientifically Grounded**: The problem is grounded in the established statistical discipline of multiple hypothesis testing, a core component of clinical trial design and analysis. The Family-Wise Error Rate (FWER), $p$-values, and the Holm–Bonferroni procedure are standard, well-defined concepts. The scenario described is a realistic application in clinical pharmacology for rare diseases.\n- **Well-Posed**: The problem is well-posed. It provides all necessary data (the set of $p$-values, the number of tests, the significance level $\\alpha$) and specifies a deterministic algorithm (Holm–Bonferroni) to arrive at a unique solution.\n- **Objective**: The problem is stated using precise, objective, and quantitative language. It is free of ambiguity, subjectivity, or opinion.\n- **Completeness and Consistency**: The problem is self-contained and internally consistent. The number of endpoints matches the number of provided $p$-values. The task is clearly defined and follows logically from the premises.\n- **No Other Flaws**: The problem does not violate any other validation criteria. It is not unrealistic, ill-posed, trivial, or unverifiable.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A solution will be derived.\n\n### Solution Derivation\nThe problem requires the calculation of Holm–Bonferroni adjusted $p$-values and a subsequent determination of statistical significance for four co-primary endpoints.\n\nThe Family-Wise Error Rate (FWER) is the probability of committing at least one Type I error (i.e., falsely rejecting a true null hypothesis) across a family of hypothesis tests. The Holm–Bonferroni method provides strong control of the FWER at a pre-specified level $\\alpha$. An adjusted $p$-value, $\\tilde{p}_i$, for a given hypothesis $H_i$ is defined as the smallest FWER level $\\alpha$ at which the hypothesis $H_i$ would be rejected by the procedure. An endpoint is considered statistically significant if its adjusted $p$-value is less than or equal to the desired FWER level, $\\alpha$.\n\nThe Holm–Bonferroni procedure is executed as follows:\n1.  Let there be $m$ null hypotheses, $H_1, \\dots, H_m$, with corresponding unadjusted $p$-values, $p_1, \\dots, p_m$. In this problem, $m=4$.\n2.  Order the $p$-values from smallest to largest: $p_{(1)} \\leq p_{(2)} \\leq \\dots \\leq p_{(m)}$. Let the corresponding hypotheses be $H_{(1)}, \\dots, H_{(m)}$.\n3.  The Holm–Bonferroni adjusted $p$-value for the $k$-th ordered hypothesis, $\\tilde{p}_{(k)}$, is calculated recursively to ensure monotonicity. The formula is:\n    $$ \\tilde{p}_{(k)} = \\max \\left\\{ \\tilde{p}_{(k-1)}, (m-k+1)p_{(k)} \\right\\} \\quad \\text{for } k > 1 $$\n    with the base case:\n    $$ \\tilde{p}_{(1)} = (m-1+1)p_{(1)} = m \\cdot p_{(1)} $$\n    This is equivalent to the compact definition:\n    $$ \\tilde{p}_{(k)} = \\max_{j=1, \\dots, k} \\left\\{ (m-j+1) p_{(j)} \\right\\} $$\n\nLet us apply this procedure to the given data.\nThe number of hypotheses is $m=4$.\nThe unadjusted $p$-values are given in their original order as $(p_1, p_2, p_3, p_4) = (0.01, 0.03, 0.04, 0.20)$.\n\nFirst, we order the $p$-values. In this case, the provided $p$-values are already sorted in non-decreasing order:\n$$ p_{(1)} = 0.01, \\quad p_{(2)} = 0.03, \\quad p_{(3)} = 0.04, \\quad p_{(4)} = 0.20 $$\nThe ordered hypotheses $H_{(k)}$ correspond directly to the original hypotheses $H_k$, i.e., $H_{(1)}=H_1, H_{(2)}=H_2$, and so on.\n\nNow, we compute the adjusted $p$-values, $\\tilde{p}_{(k)}$, for each ordered hypothesis. We will cap the adjusted $p$-values at $1.0$ if any calculation exceeds it, as a $p$-value cannot be greater than $1$.\n\nFor $k=1$:\n$$ \\tilde{p}_{(1)} = m \\cdot p_{(1)} = 4 \\times 0.01 = 0.04 $$\n\nFor $k=2$:\nThe intermediate value is $(m-2+1)p_{(2)} = 3 \\times 0.03 = 0.09$.\n$$ \\tilde{p}_{(2)} = \\max(\\tilde{p}_{(1)}, 0.09) = \\max(0.04, 0.09) = 0.09 $$\n\nFor $k=3$:\nThe intermediate value is $(m-3+1)p_{(3)} = 2 \\times 0.04 = 0.08$.\n$$ \\tilde{p}_{(3)} = \\max(\\tilde{p}_{(2)}, 0.08) = \\max(0.09, 0.08) = 0.09 $$\n\nFor $k=4$:\nThe intermediate value is $(m-4+1)p_{(4)} = 1 \\times 0.20 = 0.20$.\n$$ \\tilde{p}_{(4)} = \\max(\\tilde{p}_{(3)}, 0.20) = \\max(0.09, 0.20) = 0.20 $$\n\nThe calculated adjusted $p$-values for the ordered hypotheses are $(0.04, 0.09, 0.09, 0.20)$. Since the original order was the same as the sorted order, these are the adjusted $p$-values for endpoints $1, 2, 3,$ and $4$ respectively:\n$$ (\\tilde{p}_1, \\tilde{p}_2, \\tilde{p}_3, \\tilde{p}_4) = (0.04, 0.09, 0.09, 0.20) $$\n\nThe problem requires rounding each value to four significant figures:\n- $\\tilde{p}_1 = 0.04 \\rightarrow 0.04000$\n- $\\tilde{p}_2 = 0.09 \\rightarrow 0.09000$\n- $\\tilde{p}_3 = 0.09 \\rightarrow 0.09000$\n- $\\tilde{p}_4 = 0.20 \\rightarrow 0.2000$\n\nNext, we determine how many endpoints remain significant at the FWER level $\\alpha = 0.05$. An endpoint is significant if its adjusted $p$-value is less than or equal to $\\alpha$.\n- Endpoint 1: $\\tilde{p}_1 = 0.04000 \\leq 0.05$. This endpoint is significant.\n- Endpoint 2: $\\tilde{p}_2 = 0.09000 > 0.05$. This endpoint is not significant.\n- Endpoint 3: $\\tilde{p}_3 = 0.09000 > 0.05$. This endpoint is not significant.\n- Endpoint 4: $\\tilde{p}_4 = 0.2000 > 0.05$. This endpoint is not significant.\n\nTherefore, only one endpoint remains statistically significant after controlling the FWER using the Holm–Bonferroni procedure. The number of significant endpoints is $1$.\n\nThe final answer requires a single row matrix containing the four adjusted $p$-values (rounded to four significant figures) in their original order, and the number of significant endpoints. This matrix will be $(0.04000, 0.09000, 0.09000, 0.2000, 1)$.", "answer": "$$ \\boxed{ \\begin{pmatrix} 0.04000 & 0.09000 & 0.09000 & 0.2000 & 1 \\end{pmatrix} } $$", "id": "4541012"}]}