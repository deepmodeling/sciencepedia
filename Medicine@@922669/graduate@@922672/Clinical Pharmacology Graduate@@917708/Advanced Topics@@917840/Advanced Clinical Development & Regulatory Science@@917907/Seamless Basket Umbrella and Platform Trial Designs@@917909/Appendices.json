{"hands_on_practices": [{"introduction": "A primary motivation for adopting platform trial designs is their remarkable efficiency, particularly in reducing the total number of patients required. This first practice invites you to quantify this advantage by deriving the change in total sample size when shifting from multiple independent trials to a single platform study with a shared control arm [@problem_id:4589373]. By working through this calculation, you will gain a concrete understanding of the resource savings that make these designs so attractive.", "problem": "A multi-arm platform trial in clinical pharmacology evaluates $m=5$ experimental treatments against a common control, with the intent to preserve the same marginal power for each experimental-versus-control hypothesis test as would be achieved in separate, independently controlled trials. Assume the following foundational conditions: (i) the treatment effect and outcome variance are identical across arms; (ii) drop-out is negligible; (iii) hypothesis testing uses large-sample normal approximations so that the required per-arm sample size depends only on the allocation ratio, the type I error rate $ \\alpha $, the desired power $ 1-\\beta $, the common variance, and the effect size; and (iv) the allocation ratio for each experimental-versus-control comparison is fixed at $1:1$.\n\nUnder independent controls, each experimental treatment would be studied in its own two-arm trial with allocation ratio $1:1$. Under a shared control, all $m$ experimental arms are studied concurrently with a single control arm, with equal per-arm allocation so that each experimental arm-to-control comparison maintains the $1:1$ allocation ratio at the per-arm level.\n\nDefine the inflation factor for total sample size when moving from independent controls to a shared control as the multiplicative change \n$$F=\\frac{N_{\\text{shared}}}{N_{\\text{independent}}},$$\nwhere $N_{\\text{independent}}$ is the total sample size across all $m$ independent two-arm trials that achieves the desired power for each comparison, and $N_{\\text{shared}}$ is the total sample size in the shared-control platform design that achieves the same per-comparison power under the same $1:1$ per-arm allocation.\n\nDerive $F$ from first principles starting at the level of per-comparison required sample sizes implied by the large-sample normal theory and the fixed $1:1$ allocation. Then calculate $F$ for $m=5$. Express your final answer as a decimal rounded to four significant figures.", "solution": "The user wants me to solve a problem.\n\n**1. Problem Validation**\n\n**Step 1: Extract Givens**\n- Number of experimental treatments: $m=5$.\n- Control scheme: common control.\n- Design goal: Preserve the same marginal power for each of the $m$ experimental-versus-control hypothesis tests as would be achieved in $m$ separate, independently controlled trials.\n- Assumption (i): Treatment effect and outcome variance are identical across all arms.\n- Assumption (ii): Drop-out is negligible.\n- Assumption (iii): Hypothesis testing uses large-sample normal approximations.\n- Assumption (iv): The allocation ratio for each experimental-versus-control comparison is fixed at $1:1$.\n- Independent controls scenario: $m$ separate two-arm trials, each with a $1:1$ allocation ratio.\n- Shared control scenario: $m$ experimental arms and one common control arm. Equal per-arm allocation for experimental arms, and each experimental arm-to-control comparison maintains the $1:1$ allocation ratio.\n- Inflation factor definition: $F=\\frac{N_{\\text{shared}}}{N_{\\text{independent}}}$.\n- $N_{\\text{independent}}$: total sample size across all $m$ independent trials.\n- $N_{\\text{shared}}$: total sample size in the shared-control platform trial.\n- Task: Derive $F$ and calculate its value for $m=5$, rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is a standard exercise in the statistical design of clinical trials, specifically comparing platform trial efficiency to parallel independent trials. The assumptions, such as large-sample normal theory and fixed allocation ratios, are common in introductory sample size calculations. This is a well-established topic in biostatistics and clinical pharmacology. The problem is scientifically sound.\n- **Well-Posed**: The problem is clearly defined. It provides a set of consistent assumptions and constraints and asks for the derivation and calculation of a specific ratio, $F$. The constraints are sufficient to determine a unique solution.\n- **Objective**: The problem is stated in precise, objective language without subjective or opinion-based elements.\n- **Completeness and Consistency**: The problem is self-contained. The provided information (number of arms, allocation rules, power-equivalence constraint) is sufficient to derive the sample size ratio. The constraints are consistent with each other.\n- **Realism**: The scenario is a simplified but realistic representation of a common problem in clinical trial design. Platform trials are used precisely for the efficiency gains explored in this problem.\n- **Structure**: The problem is well-structured and free from ambiguity. The term \"maintains the $1:1$ allocation ratio at the per-arm level\" is a prescriptive constraint that dictates the structure of the shared-control arm's sample size relative to the experimental arms.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is scientifically grounded, well-posed, and all necessary information is provided. The derivation can proceed.\n\n**2. Solution Derivation**\n\nLet us begin from first principles. According to assumption (iii), we are in the large-sample normal approximation setting. The sample size required to achieve a power of $1-\\beta$ for a two-sided type I error rate of $\\alpha$ in a two-sample z-test comparing two means with a common variance $\\sigma^2$ and effect size $\\delta$ is determined by the standard formula.\n\nFor a two-arm trial with sample sizes $n_1$ and $n_2$, the variance of the estimated difference in means is $\\sigma^2 (\\frac{1}{n_1} + \\frac{1}{n_2})$. The power is a function of this variance. To maintain constant power, the quantity $\\frac{1}{n_1} + \\frac{1}{n_2}$ must be held constant.\n\nLet $n_0$ represent the sample size required for each arm in a standard, independent, two-arm clinical trial with a $1:1$ allocation ratio to achieve the desired power. In such a trial, we have one experimental arm and one control arm, with $n_0$ subjects each. The total sample size for one such trial is $2n_0$. The power-determining quantity for this benchmark comparison is $\\frac{1}{n_0} + \\frac{1}{n_0} = \\frac{2}{n_0}$.\n\n**Scenario 1: Independent Controls**\nIn this scenario, we conduct $m$ separate two-arm trials. Each trial compares one of the $m$ experimental treatments to its own dedicated control group.\n- Each of the $m$ trials has a $1:1$ allocation, so each comprises one experimental arm with $n_0$ subjects and one control arm with $n_0$ subjects.\n- The total sample size for a single trial is $n_0 + n_0 = 2n_0$.\n- Since there are $m$ such independent trials, the total sample size across all trials is:\n$$N_{\\text{independent}} = m \\times (2n_0) = 2mn_0$$\n\n**Scenario 2: Shared Control**\nIn this scenario, we have a single platform trial with $m$ experimental arms and one shared control arm. Let $n_{E,i}$ be the sample size for the $i$-th experimental arm and $n_C$ be the sample size for the shared control arm.\nThe problem states \"equal per-arm allocation\" for the experimental arms, which implies $n_{E,1} = n_{E,2} = \\dots = n_{E,m}$. Let us denote this common sample size as $n_E$.\n\nThe problem requires that the shared-control design \"preserve the same marginal power\" for each of the $m$ pairwise comparisons between an experimental arm and the shared control. This means that for each comparison (e.g., arm $E_i$ vs. arm $C$), the power must be the same as in the benchmark independent trial. This imposes a condition on their sample sizes, $n_E$ and $n_C$:\n$$\\frac{1}{n_E} + \\frac{1}{n_C} = \\frac{2}{n_0}$$\n\nFurthermore, the problem specifies a crucial constraint: \"each experimental arm-to-control comparison maintains the $1:1$ allocation ratio at the per-arm level.\" This is a prescriptive statement about the sample sizes themselves, meaning the number of subjects in an experimental arm must be equal to the number of subjects in the control arm it is being compared to. This translates to the constraint:\n$$n_E = n_C$$\n\nWe now have a system of two equations to solve for $n_E$ and $n_C$ in terms of $n_0$:\n1. $\\frac{1}{n_E} + \\frac{1}{n_C} = \\frac{2}{n_0}$\n2. $n_E = n_C$\n\nSubstituting the second equation into the first gives:\n$$\\frac{1}{n_E} + \\frac{1}{n_E} = \\frac{2}{n_E} = \\frac{2}{n_0}$$\nThis immediately implies $n_E = n_0$.\nFrom $n_E = n_C$, we also have $n_C = n_0$.\n\nSo, in the shared-control design, each of the $m$ experimental arms must have $n_0$ subjects, and the single shared control arm must also have $n_0$ subjects.\n\nThe total sample size for the shared-control platform trial, $N_{\\textsharing}$, is the sum of the sample sizes of all arms:\n$$N_{\\text{shared}} = (\\sum_{i=1}^{m} n_{E,i}) + n_C = (m \\times n_E) + n_C = mn_0 + n_0 = (m+1)n_0$$\n\n**Derivation of the Inflation Factor F**\nThe inflation factor $F$ is defined as the ratio of the total sample size in the shared design to the total sample size in the independent-controls design.\n$$F = \\frac{N_{\\text{shared}}}{N_{\\text{independent}}} = \\frac{(m+1)n_0}{2mn_0}$$\nThe term $n_0$, which encapsulates the specifics of the power, effect size, and variance, cancels out, leaving a general formula dependent only on the number of experimental arms, $m$:\n$$F = \\frac{m+1}{2m}$$\n\n**Calculation for m=5**\nThe problem asks for the value of $F$ for a trial with $m=5$ experimental treatments. Substituting $m=5$ into the derived formula:\n$$F = \\frac{5+1}{2 \\times 5} = \\frac{6}{10} = 0.6$$\nThe problem requires the answer to be expressed as a decimal rounded to four significant figures.\n$$F = 0.6000$$\nThis result indicates that the shared-control platform design, under the given constraints, requires only $60\\%$ of the total subjects that would be needed to run five separate, independent trials, representing a $40\\%$ savings in total sample size.", "answer": "$$\\boxed{0.6000}$$", "id": "4589373"}, {"introduction": "Beyond efficiency, the power of umbrella and basket trials lies in their ability to systematically investigate how a treatment's effectiveness varies across different biomarker-defined subgroups. This exercise delves into the statistical modeling at the heart of this analysis, asking you to derive the expression for an interaction odds ratio within a logistic regression framework [@problem_id:4589337]. Completing this derivation will clarify how model coefficients directly quantify whether a treatment effect is enhanced or diminished in the presence of a specific biomarker.", "problem": "An umbrella trial in clinical pharmacology evaluates a single disease with multiple biomarker-defined subgroups. Let there be $J$ binary biomarkers indexed by $j \\in \\{1,\\dots,J\\}$, where each $B_j \\in \\{0,1\\}$ indicates the presence $(1)$ or absence $(0)$ of biomarker $j$. Subjects may have none, one, or several biomarkers present. Let $T \\in \\{0,1\\}$ indicate assignment to investigational treatment $(1)$ versus control $(0)$. The primary endpoint is a binary clinical response $Y \\in \\{0,1\\}$ measured at a fixed time. Assume the probability of response $p(T,\\mathbf{B}) = \\Pr(Y=1 \\mid T,\\mathbf{B})$ is modeled via a logistic regression:\n$$\n\\operatorname{logit}\\!\\big(p(T,\\mathbf{B})\\big) \\equiv \\ln\\!\\left(\\frac{p(T,\\mathbf{B})}{1 - p(T,\\mathbf{B})}\\right) = \\beta_0 + \\beta_T T + \\sum_{j=1}^{J} \\beta_j B_j + \\sum_{j=1}^{J} \\gamma_j \\, T \\, B_j,\n$$\nwhere $\\beta_0$ is the intercept, $\\beta_T$ is the main treatment effect, $\\beta_j$ are main effects for biomarkers, and $\\gamma_j$ are biomarker-treatment interaction parameters.\n\nStarting only from the definitions of odds $o = \\frac{p}{1-p}$, the logit link $\\operatorname{logit}(p) = \\ln(o)$, and the odds ratio (OR) defined as the ratio of odds between two conditions on the same covariate set, derive the closed-form analytic expression for the biomarker-specific interaction odds ratio $IOR_j$ defined as the ratio of the treatment odds ratio when biomarker $j$ is present versus when biomarker $j$ is absent, holding all other biomarkers at $0$. Concretely, define\n$$\n\\mathrm{OR}_{T \\mid B_j=1} \\equiv \\frac{o\\big(T=1, B_j=1, B_k=0 \\ \\forall k \\neq j\\big)}{o\\big(T=0, B_j=1, B_k=0 \\ \\forall k \\neq j\\big)},\n$$\n$$\n\\mathrm{OR}_{T \\mid B_j=0} \\equiv \\frac{o\\big(T=1, B_j=0, B_k=0 \\ \\forall k \\neq j\\big)}{o\\big(T=0, B_j=0, B_k=0 \\ \\forall k \\neq j\\big)},\n$$\nand\n$$\nIOR_j \\equiv \\frac{\\mathrm{OR}_{T \\mid B_j=1}}{\\mathrm{OR}_{T \\mid B_j=0}}.\n$$\nExpress $IOR_j$ purely in terms of the model coefficients, as a single closed-form expression. No numerical evaluation is required and no rounding is needed. Provide your final answer as a closed-form expression only.", "solution": "The user wants me to derive a closed-form expression for the biomarker-specific interaction odds ratio, $IOR_j$, based on the provided logistic regression model.\n\nThe problem statement defines a logistic regression model for the probability of response $p(T, \\mathbf{B})$ as:\n$$\n\\operatorname{logit}\\!\\big(p(T,\\mathbf{B})\\big) = \\beta_0 + \\beta_T T + \\sum_{i=1}^{J} \\beta_i B_i + \\sum_{i=1}^{J} \\gamma_i \\, T \\, B_i\n$$\nThe logit function is defined as $\\operatorname{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right)$, which is equivalent to the natural logarithm of the odds, $\\ln(o)$. Therefore, the log-odds for a given set of covariates $(T, \\mathbf{B})$ is given directly by the linear predictor:\n$$\n\\ln\\big(o(T, \\mathbf{B})\\big) = \\beta_0 + \\beta_T T + \\sum_{i=1}^{J} \\beta_i B_i + \\sum_{i=1}^{J} \\gamma_i \\, T \\, B_i\n$$\nThe goal is to compute $IOR_j = \\frac{\\mathrm{OR}_{T \\mid B_j=1}}{\\mathrm{OR}_{T \\mid B_j=0}}$. We will compute the numerator and denominator separately.\n\nFirst, let's compute $\\mathrm{OR}_{T \\mid B_j=1}$. This is the odds ratio for treatment ($T=1$ vs $T=0$) for the subpopulation where biomarker $j$ is present ($B_j=1$) and all other biomarkers are absent ($B_k=0$ for all $k \\neq j$).\nThe log-odds for a treated subject ($T=1$) in this subpopulation is:\n$$\n\\ln\\big(o(T=1, B_j=1, B_k=0 \\ \\forall k \\neq j)\\big) = \\beta_0 + \\beta_T(1) + \\beta_j(1) + \\sum_{k \\neq j} \\beta_k(0) + \\gamma_j(1)(1) + \\sum_{k \\neq j} \\gamma_k(1)(0)\n$$\n$$\n= \\beta_0 + \\beta_T + \\beta_j + \\gamma_j\n$$\nThe log-odds for a control subject ($T=0$) in the same subpopulation is:\n$$\n\\ln\\big(o(T=0, B_j=1, B_k=0 \\ \\forall k \\neq j)\\big) = \\beta_0 + \\beta_T(0) + \\beta_j(1) + \\sum_{k \\neq j} \\beta_k(0) + \\gamma_j(0)(1) + \\sum_{k \\neq j} \\gamma_k(0)(0)\n$$\n$$\n= \\beta_0 + \\beta_j\n$$\nThe logarithm of the odds ratio $\\mathrm{OR}_{T \\mid B_j=1}$ is the difference between these two log-odds:\n$$\n\\ln(\\mathrm{OR}_{T \\mid B_j=1}) = (\\beta_0 + \\beta_T + \\beta_j + \\gamma_j) - (\\beta_0 + \\beta_j) = \\beta_T + \\gamma_j\n$$\nExponentiating both sides yields the odds ratio:\n$$\n\\mathrm{OR}_{T \\mid B_j=1} = \\exp(\\beta_T + \\gamma_j)\n$$\n\nNext, let's compute $\\mathrm{OR}_{T \\mid B_j=0}$. This is the odds ratio for treatment for the subpopulation where biomarker $j$ is absent ($B_j=0$) and all other biomarkers are also absent ($B_k=0$ for all $k \\neq j$). This corresponds to the case where all biomarkers are absent ($B_k=0$ for all $k$).\nThe log-odds for a treated subject ($T=1$) in this all-biomarker-negative subpopulation is:\n$$\n\\ln\\big(o(T=1, B_k=0 \\ \\forall k)\\big) = \\beta_0 + \\beta_T(1) + \\sum_{k=1}^{J} \\beta_k(0) + \\sum_{k=1}^{J} \\gamma_k(1)(0) = \\beta_0 + \\beta_T\n$$\nThe log-odds for a control subject ($T=0$) in the same subpopulation is:\n$$\n\\ln\\big(o(T=0, B_k=0 \\ \\forall k)\\big) = \\beta_0 + \\beta_T(0) + \\sum_{k=1}^{J} \\beta_k(0) + \\sum_{k=1}^{J} \\gamma_k(0)(0) = \\beta_0\n$$\nThe logarithm of the odds ratio $\\mathrm{OR}_{T \\mid B_j=0}$ is the difference between these two log-odds:\n$$\n\\ln(\\mathrm{OR}_{T \\mid B_j=0}) = (\\beta_0 + \\beta_T) - \\beta_0 = \\beta_T\n$$\nExponentiating both sides yields the odds ratio:\n$$\n\\mathrm{OR}_{T \\mid B_j=0} = \\exp(\\beta_T)\n$$\n\nFinally, we compute the interaction odds ratio $IOR_j$ by taking the ratio of the two odds ratios derived above:\n$$\nIOR_j = \\frac{\\mathrm{OR}_{T \\mid B_j=1}}{\\mathrm{OR}_{T \\mid B_j=0}} = \\frac{\\exp(\\beta_T + \\gamma_j)}{\\exp(\\beta_T)}\n$$\nUsing the property of exponential functions $\\frac{\\exp(a)}{\\exp(b)} = \\exp(a-b)$, we find:\n$$\nIOR_j = \\exp\\big((\\beta_T + \\gamma_j) - \\beta_T\\big) = \\exp(\\gamma_j)\n$$\nThis result demonstrates that in a logistic regression model that includes a product term for interaction (like $T \\cdot B_j$), the exponentiated interaction coefficient ($\\exp(\\gamma_j)$) is precisely the ratio of the odds ratios, which quantifies the interaction effect.", "answer": "$$\\boxed{\\exp(\\gamma_j)}$$", "id": "4589337"}, {"introduction": "Testing multiple hypotheses, as is common in basket, umbrella, and platform trials, introduces the risk of making at least one false positive finding. This final practice addresses the critical challenge of multiple comparisons by asking you to apply two common methods for controlling the family-wise error rate [@problem_id:4589358]. By calculating and comparing the significance thresholds for the Bonferroni correction and the more powerful Holm step-down procedure, you will develop a practical skill essential for maintaining statistical rigor in complex trials.", "problem": "A seamless platform trial in clinical pharmacology is planned to evaluate efficacy signals across six concurrently active cohorts that are biomarker-defined subgroups, consistent with basket and umbrella trial structures. The trial adopts a family-wise error rate (FWER) control across all six primary efficacy hypotheses, which are tested simultaneously at the end of a combined phase that seamlessly bridges exploratory and confirmatory analyses. Let the number of simultaneous hypotheses be $m=6$ and the target overall Type I error rate be $\\alpha=0.05$. Using the definition of family-wise error rate as the probability of at least one false rejection among the $m$ simultaneous null hypotheses under the global null, and starting from the union bound (Bonferroni inequality) on the probability of a union of events, derive the per-comparison significance threshold (Bonferroni adjustment) that guarantees control of FWER at level $\\alpha$ when all six hypotheses are tested in parallel.\n\nNext, consider applying the Holm sequentially rejective step-down procedure, which orders the observed $p$-values as $p_{(1)}\\le p_{(2)}\\le \\cdots \\le p_{(6)}$ and tests them sequentially against adjusted critical values to achieve strong control of FWER under arbitrary dependence. From first principles of the Holm procedure, derive the sequence of adjusted critical values for $i=1,2,\\ldots,6$ in terms of $m$ and $\\alpha$, and then specialize them to the case $m=6$ and $\\alpha=0.05$.\n\nExpress all numerical thresholds as exact fractions; no rounding is required. Report your final result as a single row matrix whose first entry is the Bonferroni per-comparison threshold and whose next six entries are the Holm step-down critical values for $i=1,2,\\ldots,6$, in order corresponding to $p_{(1)},\\ldots,p_{(6)}$.", "solution": "The problem requires the derivation and calculation of significance thresholds for multiple hypothesis testing under two different procedures: the single-step Bonferroni correction and the sequential Holm-Bonferroni method. The context is a clinical trial with $m=6$ hypotheses to be tested simultaneously, with the family-wise error rate (FWER) to be controlled at a level of $\\alpha=0.05$.\n\nFirst, we derive the Bonferroni per-comparison significance threshold.\nThe family-wise error rate (FWER) is defined as the probability of committing at least one Type I error among the $m$ hypothesis tests. A Type I error is the rejection of a true null hypothesis. Let $H_1, H_2, \\ldots, H_m$ be the $m$ null hypotheses. Let $I_0$ be the set of indices corresponding to the true null hypotheses. The FWER is the probability of rejecting at least one $H_i$ for $i \\in I_0$.\n$$\n\\text{FWER} = P\\left(\\bigcup_{i \\in I_0} \\{\\text{reject } H_i\\}\\right)\n$$\nTo control FWER, we must ensure this probability is no greater than a specified level $\\alpha$. The Bonferroni method provides this control under the worst-case scenario, which is the global null hypothesis, where all $m$ null hypotheses are true, i.e., $I_0 = \\{1, 2, \\ldots, m\\}$. In this case, any rejection is a Type I error.\n\nLet $R_i$ be the event that hypothesis $H_i$ is rejected. The FWER is then $P(\\cup_{i=1}^{m} R_i)$. Each hypothesis $H_i$ is tested at a per-comparison significance level $\\alpha'$. This means we reject $H_i$ if its associated p-value $p_i$ is less than or equal to $\\alpha'$. Under the null hypothesis $H_i$, the probability of this event is $P(R_i) = P(p_i \\le \\alpha') = \\alpha'$, assuming the p-value distribution is uniform on $[0,1]$ for a continuous test statistic.\n\nThe derivation starts from the union bound, also known as Boole's inequality or the Bonferroni inequality, which states that for any collection of events $R_1, \\ldots, R_m$:\n$$\nP\\left(\\bigcup_{i=1}^{m} R_i\\right) \\le \\sum_{i=1}^{m} P(R_i)\n$$\nApplying this to the FWER, we have:\n$$\n\\text{FWER} = P\\left(\\bigcup_{i=1}^{m} R_i\\right) \\le \\sum_{i=1}^{m} P(R_i) = \\sum_{i=1}^{m} \\alpha' = m \\alpha'\n$$\nTo guarantee that the FWER is controlled at level $\\alpha$, we require the upper bound to be no more than $\\alpha$:\n$$\nm \\alpha' \\le \\alpha\n$$\nBy choosing the per-comparison threshold $\\alpha'$ to be $\\alpha' = \\frac{\\alpha}{m}$, we ensure FWER control:\n$$\n\\text{FWER} \\le m \\left(\\frac{\\alpha}{m}\\right) = \\alpha\n$$\nThis is the Bonferroni correction. For the given problem, $m=6$ and $\\alpha=0.05$. The per-comparison significance threshold is:\n$$\n\\alpha' = \\frac{0.05}{6} = \\frac{\\frac{5}{100}}{6} = \\frac{5}{600} = \\frac{1}{120}\n$$\n\nNext, we analyze the Holm sequentially rejective step-down procedure. This procedure provides strong control of FWER (i.e., control under any configuration of true and false nulls) and is uniformly more powerful than the Bonferroni correction.\n\nThe procedure is as follows:\n$1$. Order the $m$ p-values from smallest to largest: $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$. Let the corresponding null hypotheses be $H_{(1)}, H_{(2)}, \\ldots, H_{(m)}$.\n$2$. For $i = 1, 2, \\ldots, m$, the procedure tests the $i$-th ordered p-value, $p_{(i)}$, against an adjusted critical value. The critical value for step $i$ is $\\frac{\\alpha}{m-i+1}$.\n$3$. The sequential testing logic is:\n   - Step $1$: If $p_{(1)} \\le \\frac{\\alpha}{m-1+1} = \\frac{\\alpha}{m}$, reject $H_{(1)}$ and proceed to step $2$. Otherwise, stop and fail to reject any hypotheses.\n   - Step $i$: If all hypotheses $H_{(1)}, \\ldots, H_{(i-1)}$ were rejected in the previous steps, compare $p_{(i)}$ with $\\frac{\\alpha}{m-i+1}$. If $p_{(i)} \\le \\frac{\\alpha}{m-i+1}$, reject $H_{(i)}$ and proceed to step $i+1$. Otherwise, stop and fail to reject $H_{(i)}$ and all subsequent hypotheses $H_{(i+1)}, \\ldots, H_{(m)}$.\n\nThe sequence of adjusted critical values against which $p_{(i)}$ is compared is $c_i = \\frac{\\alpha}{m-i+1}$ for $i=1, \\ldots, m$. We derive this from the first principles of the procedure's proof of FWER control.\n\nLet $I_0$ be the set of indices of the $m_0 > 0$ true null hypotheses. A Type I error occurs if any hypothesis $H_i$ with $i \\in I_0$ is rejected. Let $k^*$ be the smallest index in the ordered list $\\{1, \\ldots, m\\}$ such that $H_{(k^*)}$ is a true null hypothesis. This means $H_{(1)}, \\ldots, H_{(k^*-1)}$ are all associated with false nulls.\nIf a Type I error occurs, there must be a smallest index $j_0$ such that $H_{(j_0)}$ is a rejected true null. By definition of $k^*$, we must have $j_0 \\ge k^*$.\nFor $H_{(j_0)}$ to be rejected, the Holm procedure requires $p_{(i)} \\le \\frac{\\alpha}{m-i+1}$ for all $i=1, \\ldots, j_0$.\nIn particular, this must hold for $i=k^*$. So, a Type I error implies that $p_{(k^*)} \\le \\frac{\\alpha}{m-k^*+1}$.\nTherefore, the FWER is bounded by the probability of this event:\n$$\n\\text{FWER} = P(\\text{Type I error}) \\le P\\left(p_{(k^*)} \\le \\frac{\\alpha}{m-k^*+1}\\right)\n$$\nThe set of hypotheses $\\{H_{(k^*)}, H_{(k^*+1)}, \\ldots, H_{(m)}\\}$ contains all $m_0$ true null hypotheses. The size of this set is $m-k^*+1$, so we must have $m_0 \\le m-k^*+1$. This implies $\\frac{1}{m-k^*+1} \\le \\frac{1}{m_0}$.\nThe p-value $p_{(k^*)}$ is the smallest p-value among the hypotheses $\\{H_{(k^*)}, \\ldots, H_{(m)}\\}$. This set includes all true nulls, so $p_{(k^*)}$ must be less than or equal to the smallest p-value among all true nulls. Let this be $p_{\\min, I_0} = \\min_{i \\in I_0} p_i$.\n$$\np_{(k^*)} = \\min(\\{p_{(k^*)}, \\ldots, p_{(m)}\\}) \\le \\min_{i \\in I_0} p_i = p_{\\min, I_0}\n$$\nCombining these inequalities, we have:\n$$\n\\text{FWER} \\le P\\left(p_{(k^*)} \\le \\frac{\\alpha}{m-k^*+1}\\right) \\le P\\left(p_{\\min, I_0} \\le \\frac{\\alpha}{m-k^*+1}\\right) \\le P\\left(p_{\\min, I_0} \\le \\frac{\\alpha}{m_0}\\right)\n$$\nThe last step used $m_0 \\le m-k^*+1$. The p-values for the $m_0$ true null hypotheses are, under their respective nulls, stochastically greater than or equal to independent Uniform$(0,1)$ random variables. For an upper bound on the probability, we can use the union bound on the $m_0$ p-values from $I_0$:\n$$\nP\\left(p_{\\min, I_0} \\le \\frac{\\alpha}{m_0}\\right) = P\\left(\\bigcup_{i \\in I_0} \\left\\{p_i \\le \\frac{\\alpha}{m_0}\\right\\}\\right) \\le \\sum_{i \\in I_0} P\\left(p_i \\le \\frac{\\alpha}{m_0}\\right) = \\sum_{i \\in I_0} \\frac{\\alpha}{m_0} = m_0 \\cdot \\frac{\\alpha}{m_0} = \\alpha\n$$\nThis confirms that the Holm procedure controls the FWER at level $\\alpha$. The critical values used in this procedure, $c_i = \\frac{\\alpha}{m-i+1}$, are thus established from first principles.\n\nFor the given problem, $m=6$ and $\\alpha=0.05$, the sequence of Holm critical values is:\nFor $i=1$: $c_1 = \\frac{\\alpha}{m-1+1} = \\frac{0.05}{6} = \\frac{1}{120}$\nFor $i=2$: $c_2 = \\frac{\\alpha}{m-2+1} = \\frac{0.05}{5} = \\frac{1}{100}$\nFor $i=3$: $c_3 = \\frac{\\alpha}{m-3+1} = \\frac{0.05}{4} = \\frac{1}{80}$\nFor $i=4$: $c_4 = \\frac{\\alpha}{m-4+1} = \\frac{0.05}{3} = \\frac{1}{60}$\nFor $i=5$: $c_5 = \\frac{\\alpha}{m-5+1} = \\frac{0.05}{2} = \\frac{1}{40}$\nFor $i=6$: $c_6 = \\frac{\\alpha}{m-6+1} = \\frac{0.05}{1} = \\frac{1}{20}$\n\nThe final result is a row matrix containing the Bonferroni threshold followed by the six Holm step-down critical values.\n\nBonferroni threshold: $\\frac{1}{120}$.\nHolm critical values: $\\frac{1}{120}, \\frac{1}{100}, \\frac{1}{80}, \\frac{1}{60}, \\frac{1}{40}, \\frac{1}{20}$.\nThe first Holm critical value is identical to the Bonferroni threshold, which is always the case.\nThe final matrix is constructed with these seven values.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{120} & \\frac{1}{120} & \\frac{1}{100} & \\frac{1}{80} & \\frac{1}{60} & \\frac{1}{40} & \\frac{1}{20}\n\\end{pmatrix}\n}\n$$", "id": "4589358"}]}