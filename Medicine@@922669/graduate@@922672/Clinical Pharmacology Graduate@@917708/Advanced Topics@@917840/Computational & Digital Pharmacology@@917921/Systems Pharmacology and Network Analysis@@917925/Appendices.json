{"hands_on_practices": [{"introduction": "A fundamental first step in systems pharmacology is to translate our knowledge of biological pathways into a formal mathematical structure, which allows us to use the powerful tools of linear algebra and graph theory. This exercise demonstrates how to construct two key representations—the adjacency matrix of a substrate-product graph and the stoichiometric matrix of a reaction network—from a set of biochemical reactions describing drug metabolism. Mastering this translation is essential for modeling and simulating the behavior of complex biological systems [@problem_id:4594957].", "problem": "A hypothetical xenobiotic drug $X$ undergoes biotransformation in a hepatocyte under the influence of endogenous cofactors commonly encountered in clinical pharmacology. Consider the species set $\\{D, M_{1}, M_{2}, \\mathrm{NADPH}, \\mathrm{NADP}^{+}, \\mathrm{GSH}\\}$, where $D$ denotes the parent drug, $M_{1}$ a primary metabolite, $M_{2}$ a conjugate metabolite, Nicotinamide Adenine Dinucleotide Phosphate (reduced) ($\\mathrm{NADPH}$), Nicotinamide Adenine Dinucleotide Phosphate (oxidized) ($\\mathrm{NADP}^{+}$), and glutathione ($\\mathrm{GSH}$). The pathway is given by the following reaction stoichiometries:\n$$\nR_{1}:\\quad D + \\mathrm{NADPH} \\longrightarrow M_{1} + \\mathrm{NADP}^{+},\n$$\n$$\nR_{2}:\\quad M_{1} + \\mathrm{GSH} \\longrightarrow M_{2},\n$$\n$$\nR_{3}:\\quad M_{2} \\longrightarrow M_{1},\n$$\n$$\nR_{4}:\\quad M_{1} \\longrightarrow D.\n$$\nModel the pathway as:\n- A directed graph on the species, with a directed edge from a reactant species to a product species whenever a reaction uses the reactant to produce the product.\n- A reaction hypergraph whose incidence is given by the stoichiometric mapping from species to reactions, with negative entries for reactants and positive entries for products, and zeros otherwise.\n\nTasks:\n- Derive the directed graph adjacency matrix $A \\in \\mathbb{R}^{6 \\times 6}$ with the species ordered as $(D, M_{1}, M_{2}, \\mathrm{NADPH}, \\mathrm{NADP}^{+}, \\mathrm{GSH})$.\n- Derive the stoichiometric incidence matrix $S \\in \\mathbb{R}^{6 \\times 4}$ with reactions ordered as $(R_{1}, R_{2}, R_{3}, R_{4})$ and the same species row order as above.\n- Compute the rank of the stoichiometric incidence matrix $S$.\n\nExpress your final answer as a single integer. No rounding is required, and no units are needed.", "solution": "We begin from foundational network definitions and stoichiometric bookkeeping used in systems pharmacology. A biochemical reaction is represented by stoichiometric coefficients that count how many molecules of each species are consumed or produced per reaction event. For each reaction, we assign a negative coefficient to each reactant and a positive coefficient to each product. The stoichiometric incidence matrix $S$ has rows indexed by species and columns indexed by reactions, with entries equal to these signed stoichiometric coefficients.\n\nSeparately, the directed graph on species has an adjacency matrix $A$ whose entry $A_{ij}$ is $1$ if there exists at least one reaction in which species $i$ is a reactant and species $j$ is a product, and $0$ otherwise. This constructs the substrate–product graph, often used to analyze reachability and connectivity among molecular entities.\n\nStep 1: Construct the directed graph adjacency matrix $A$.\n\nWe list the ordered species: $(D, M_{1}, M_{2}, \\mathrm{NADPH}, \\mathrm{NADP}^{+}, \\mathrm{GSH})$ and examine each reaction to identify directed edges from reactants to products.\n\n- Reaction $R_{1}: D + \\mathrm{NADPH} \\longrightarrow M_{1} + \\mathrm{NADP}^{+}$ yields the edges:\n  - $D \\rightarrow M_{1}$,\n  - $D \\rightarrow \\mathrm{NADP}^{+}$,\n  - $\\mathrm{NADPH} \\rightarrow M_{1}$,\n  - $\\mathrm{NADPH} \\rightarrow \\mathrm{NADP}^{+}$.\n- Reaction $R_{2}: M_{1} + \\mathrm{GSH} \\longrightarrow M_{2}$ yields the edges:\n  - $M_{1} \\rightarrow M_{2}$,\n  - $\\mathrm{GSH} \\rightarrow M_{2}$.\n- Reaction $R_{3}: M_{2} \\longrightarrow M_{1}$ yields the edge:\n  - $M_{2} \\rightarrow M_{1}$.\n- Reaction $R_{4}: M_{1} \\longrightarrow D$ yields the edge:\n  - $M_{1} \\rightarrow D$.\n\nNo other edges exist. Therefore, row by row (source to targets) in the order $(D, M_{1}, M_{2}, \\mathrm{NADPH}, \\mathrm{NADP}^{+}, \\mathrm{GSH})$, we fill $A$:\n\n- Row $D$: edges to $M_{1}$ and $\\mathrm{NADP}^{+}$, so\n  $$\n  [0,\\,1,\\,0,\\,0,\\,1,\\,0].\n  $$\n- Row $M_{1}$: edges to $M_{2}$ and $D$, so\n  $$\n  [1,\\,0,\\,1,\\,0,\\,0,\\,0].\n  $$\n- Row $M_{2}$: edge to $M_{1}$, so\n  $$\n  [0,\\,1,\\,0,\\,0,\\,0,\\,0].\n  $$\n- Row $\\mathrm{NADPH}$: edges to $M_{1}$ and $\\mathrm{NADP}^{+}$, so\n  $$\n  [0,\\,1,\\,0,\\,0,\\,1,\\,0].\n  $$\n- Row $\\mathrm{NADP}^{+}$: no outgoing edges, so\n  $$\n  [0,\\,0,\\,0,\\,0,\\,0,\\,0].\n  $$\n- Row $\\mathrm{GSH}$: edge to $M_{2}$, so\n  $$\n  [0,\\,0,\\,1,\\,0,\\,0,\\,0].\n  $$\n\nThus,\n$$\nA = \\begin{pmatrix}\n0 & 1 & 0 & 0 & 1 & 0 \\\\\n1 & 0 & 1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 0\n\\end{pmatrix}.\n$$\n\nStep 2: Construct the stoichiometric incidence matrix $S$.\n\nWe assign rows in the order $(D, M_{1}, M_{2}, \\mathrm{NADPH}, \\mathrm{NADP}^{+}, \\mathrm{GSH})$ and columns $(R_{1}, R_{2}, R_{3}, R_{4})$.\n\n- For $R_{1}: D + \\mathrm{NADPH} \\longrightarrow M_{1} + \\mathrm{NADP}^{+}$:\n  - $D$: $-1$,\n  - $M_{1}$: $+1$,\n  - $M_{2}$: $0$,\n  - $\\mathrm{NADPH}$: $-1$,\n  - $\\mathrm{NADP}^{+}$: $+1$,\n  - $\\mathrm{GSH}$: $0$.\n\nSo the first column is\n$$\n\\begin{pmatrix}\n-1 \\\\ 1 \\\\ 0 \\\\ -1 \\\\ 1 \\\\ 0\n\\end{pmatrix}.\n$$\n\n- For $R_{2}: M_{1} + \\mathrm{GSH} \\longrightarrow M_{2}$:\n  - $D$: $0$,\n  - $M_{1}$: $-1$,\n  - $M_{2}$: $+1$,\n  - $\\mathrm{NADPH}$: $0$,\n  - $\\mathrm{NADP}^{+}$: $0$,\n  - $\\mathrm{GSH}$: $-1$.\n\nSo the second column is\n$$\n\\begin{pmatrix}\n0 \\\\ -1 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ -1\n\\end{pmatrix}.\n$$\n\n- For $R_{3}: M_{2} \\longrightarrow M_{1}$:\n  - $D$: $0$,\n  - $M_{1}$: $+1$,\n  - $M_{2}$: $-1$,\n  - $\\mathrm{NADPH}$: $0$,\n  - $\\mathrm{NADP}^{+}$: $0$,\n  - $\\mathrm{GSH}$: $0$.\n\nSo the third column is\n$$\n\\begin{pmatrix}\n0 \\\\ 1 \\\\ -1 \\\\ 0 \\\\ 0 \\\\ 0\n\\end{pmatrix}.\n$$\n\n- For $R_{4}: M_{1} \\longrightarrow D$:\n  - $D$: $+1$,\n  - $M_{1}$: $-1$,\n  - $M_{2}$: $0$,\n  - $\\mathrm{NADPH}$: $0$,\n  - $\\mathrm{NADP}^{+}$: $0$,\n  - $\\mathrm{GSH}$: $0$.\n\nSo the fourth column is\n$$\n\\begin{pmatrix}\n1 \\\\ -1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\n\\end{pmatrix}.\n$$\n\nCollecting columns, we have\n$$\nS = \\begin{pmatrix}\n-1 & 0 & 0 & 1 \\\\\n1 & -1 & 1 & -1 \\\\\n0 & 1 & -1 & 0 \\\\\n-1 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 0 \\\\\n0 & -1 & 0 & 0\n\\end{pmatrix}.\n$$\n\nStep 3: Compute the rank of $S$.\n\nSince $S \\in \\mathbb{R}^{6 \\times 4}$, the rank is at most $4$. To decide whether all $4$ columns are linearly independent, we test whether a linear combination $\\alpha \\mathbf{c}_{1} + \\beta \\mathbf{c}_{2} + \\gamma \\mathbf{c}_{3} + \\delta \\mathbf{c}_{4} = \\mathbf{0}$ forces $\\alpha = \\beta = \\gamma = \\delta = 0$, where $\\mathbf{c}_{k}$ denotes the $k$-th column of $S$.\n\nWrite the columns explicitly:\n$$\n\\mathbf{c}_{1} = \\begin{pmatrix} -1 \\\\ 1 \\\\ 0 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix},\\quad\n\\mathbf{c}_{2} = \\begin{pmatrix} 0 \\\\ -1 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ -1 \\end{pmatrix},\\quad\n\\mathbf{c}_{3} = \\begin{pmatrix} 0 \\\\ 1 \\\\ -1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix},\\quad\n\\mathbf{c}_{4} = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n\nSet $\\alpha \\mathbf{c}_{1} + \\beta \\mathbf{c}_{2} + \\gamma \\mathbf{c}_{3} + \\delta \\mathbf{c}_{4} = \\mathbf{0}$ and equate rows:\n\n- Row $D$: $- \\alpha + 0 + 0 + \\delta = 0 \\implies \\delta = \\alpha$.\n- Row $M_{1}$: $\\alpha - \\beta + \\gamma - \\delta = 0$. Using $\\delta = \\alpha$, we get $- \\beta + \\gamma = 0 \\implies \\gamma = \\beta$.\n- Row $M_{2}$: $0 + \\beta - \\gamma + 0 = 0 \\implies \\beta - \\gamma = 0$, consistent with $\\gamma = \\beta$.\n- Row $\\mathrm{NADPH}$: $- \\alpha + 0 + 0 + 0 = 0 \\implies \\alpha = 0$. Hence $\\delta = 0$.\n- Row $\\mathrm{NADP}^{+}$: $\\alpha + 0 + 0 + 0 = 0 \\implies \\alpha = 0$, already enforced.\n- Row $\\mathrm{GSH}$: $0 - \\beta + 0 + 0 = 0 \\implies \\beta = 0$. Hence $\\gamma = 0$.\n\nTherefore, the only solution is $\\alpha = \\beta = \\gamma = \\delta = 0$, implying that the columns are linearly independent. Consequently, the rank of $S$ is\n$$\n\\mathrm{rank}(S) = 4.\n$$\n\nThis completes the derivation of $A$, $S$, and the computation of the requested scalar network property (the rank of the stoichiometric incidence matrix).", "answer": "$$\\boxed{4}$$", "id": "4594957"}, {"introduction": "Beyond static representation, systems pharmacology is concerned with the dynamics of biological networks, especially how they maintain stability and how drugs can perturb it. This practice delves into the stability analysis of a signaling cascade with negative feedback, a common motif in cellular regulation. By applying the Routh-Hurwitz criterion, you will determine the conditions under which a drug's inhibitory action can stabilize an otherwise unstable system, a crucial concept for therapeutic design and understanding homeostasis [@problem_id:4594941].", "problem": "A three-tier signaling cascade in a clinical pharmacology context is modeled by three sequential, linearized first-order modules with strictly positive time constants $\\tau_1$, $\\tau_2$, and $\\tau_3$ (units: minutes), and static gains $K_1$, $K_2$, and $K_3$ (dimensionless). The cascade is closed by a negative feedback from the output back to the input with feedback strength $F$ (dimensionless), representing homeostatic regulation. A drug acting on the second tier reduces its gain by a fraction $\\alpha \\in [0,1]$, so that $K_2$ is replaced by $K_2(1-\\alpha)$.\n\nUnder standard linear time-invariant (LTI) assumptions, the closed-loop characteristic equation for the cascade can be written as a cubic in the complex frequency $s$ whose coefficients depend on $\\tau_1$, $\\tau_2$, $\\tau_3$, $F$, $K_1$, $K_2$, $K_3$, and $\\alpha$. Starting from the definition of LTI stability as all characteristic roots having strictly negative real parts, and using only the construction of the Routh array and its sign-change criterion, derive the necessary and sufficient inequalities on the cubic’s coefficients (the Routh–Hurwitz criteria for order $3$). Then, by expressing the cubic’s coefficients in terms of $\\tau_1$, $\\tau_2$, $\\tau_3$, $F$, $K_1$, $K_2$, $K_3$, and $\\alpha$, determine the minimum inhibition fraction $\\alpha_{\\min}$ required to ensure closed-loop stability for the following physiologically plausible parameter set:\n- $\\tau_1 = 20\\ \\mathrm{min}$, $\\tau_2 = 5\\ \\mathrm{min}$, $\\tau_3 = 2\\ \\mathrm{min}$,\n- $K_1 = 3$, $K_2 = 2$, $K_3 = 5$,\n- $F = 1$.\n\nExpress your final answer for $\\alpha_{\\min}$ as a dimensionless decimal rounded to four significant figures.", "solution": "The problem requires an analysis of the stability of a closed-loop signaling cascade, which is modeled as a linear time-invariant (LTI) system. The stability of an LTI system is determined by the locations of the roots of its characteristic equation in the complex frequency plane. For a system to be stable, all roots (poles of the closed-loop transfer function) must lie in the left half of the complex plane, meaning they must all have strictly negative real parts. The Routh-Hurwitz criterion provides a method to determine whether this condition is met without explicitly calculating the roots.\n\nFirst, we establish the characteristic equation for the given system. The system consists of a forward path with three sequential first-order modules and a negative feedback loop. The transfer function of a first-order module with gain $K$ and time constant $\\tau$ is $G(s) = \\frac{K}{1+\\tau s}$.\n\nThe forward path is the product of the transfer functions of the three tiers. The gain of the second tier is modified by the drug, becoming $K_2(1-\\alpha)$. The forward path transfer function, $G_F(s)$, is therefore:\n$$G_F(s) = \\left(\\frac{K_1}{1+\\tau_1 s}\\right) \\left(\\frac{K_2(1-\\alpha)}{1+\\tau_2 s}\\right) \\left(\\frac{K_3}{1+\\tau_3 s}\\right) = \\frac{K_1 K_2 K_3 (1-\\alpha)}{(1+\\tau_1 s)(1+\\tau_2 s)(1+\\tau_3 s)}$$\nThe feedback path has a transfer function $H(s) = F$. For a negative feedback system, the closed-loop transfer function is $G_{CL}(s) = \\frac{G_F(s)}{1+G_F(s)H(s)}$. The characteristic equation is the denominator of $G_{CL}(s)$ set to zero:\n$$1 + G_F(s)H(s) = 0$$\nSubstituting the expressions for $G_F(s)$ and $H(s)$:\n$$1 + \\frac{K_1 K_2 K_3 F (1-\\alpha)}{(1+\\tau_1 s)(1+\\tau_2 s)(1+\\tau_3 s)} = 0$$\nTo obtain the polynomial form, we multiply by the denominator:\n$$(1+\\tau_1 s)(1+\\tau_2 s)(1+\\tau_3 s) + K_1 K_2 K_3 F (1-\\alpha) = 0$$\nExpanding the product of the first-order terms:\n$$(\\tau_1\\tau_2\\tau_3)s^3 + (\\tau_1\\tau_2 + \\tau_1\\tau_3 + \\tau_2\\tau_3)s^2 + (\\tau_1+\\tau_2+\\tau_3)s + 1 + K_1 K_2 K_3 F (1-\\alpha) = 0$$\nThis is a third-order polynomial in $s$ of the general form $a_3 s^3 + a_2 s^2 + a_1 s + a_0 = 0$, where:\n$a_3 = \\tau_1\\tau_2\\tau_3$\n$a_2 = \\tau_1\\tau_2 + \\tau_1\\tau_3 + \\tau_2\\tau_3$\n$a_1 = \\tau_1+\\tau_2+\\tau_3$\n$a_0 = 1 + K_1 K_2 K_3 F (1-\\alpha)$\n\nNext, as per the problem's instructions, we derive the Routh-Hurwitz stability conditions for this cubic polynomial using the Routh array. The array is constructed as follows:\n$$\n\\begin{array}{c|cc}\ns^3 & a_3 & a_1 \\\\\ns^2 & a_2 & a_0 \\\\\ns^1 & b_1 & 0 \\\\\ns^0 & c_1 & 0\n\\end{array}\n$$\nThe elements $b_1$ and $c_1$ are calculated as:\n$b_1 = \\frac{a_2 a_1 - a_3 a_0}{a_2}$\n$c_1 = \\frac{b_1 a_0 - a_2(0)}{b_1} = a_0$\n\nFor the system to be stable, all roots must have negative real parts. The Routh-Hurwitz criterion states that this is true if and only if all elements in the first column of the Routh array ($a_3, a_2, b_1, c_1$) have the same sign. Since the time constants $\\tau_i$ are strictly positive, $a_3 = \\tau_1\\tau_2\\tau_3 > 0$. Thus, all first-column elements must be positive for stability.\nThe conditions are:\n1. $a_2 > 0$\n2. $b_1 > 0$\n3. $c_1 > 0$\n\nLet's analyze these conditions.\n1. $a_2 = \\tau_1\\tau_2 + \\tau_1\\tau_3 + \\tau_2\\tau_3$. Since all $\\tau_i > 0$, $a_2$ is guaranteed to be positive.\n2. $c_1 = a_0$. Thus, we must have $a_0 > 0$.\n3. $b_1 > 0 \\implies \\frac{a_2 a_1 - a_3 a_0}{a_2} > 0$. Since $a_2 > 0$, this simplifies to the critical condition: $a_2 a_1 - a_3 a_0 > 0$, or $a_2 a_1 > a_3 a_0$.\n(Note: The condition $a_1 > 0$ is also necessary, which is true as $a_1=\\tau_1+\\tau_2+\\tau_3 > 0$).\nSo, the necessary and sufficient conditions for stability of the cubic system are $a_0 > 0$ and $a_2 a_1 > a_3 a_0$.\n\nNow, we apply these conditions to the specific system using the given parameters:\n$\\tau_1 = 20\\ \\mathrm{min}$, $\\tau_2 = 5\\ \\mathrm{min}$, $\\tau_3 = 2\\ \\mathrm{min}$\n$K_1 = 3$, $K_2 = 2$, $K_3 = 5$, $F = 1$\n$\\alpha \\in [0,1]$\n\nFirst, we calculate the numerical values of the coefficients:\n$a_3 = 20 \\times 5 \\times 2 = 200$\n$a_2 = (20 \\times 5) + (20 \\times 2) + (5 \\times 2) = 100 + 40 + 10 = 150$\n$a_1 = 20 + 5 + 2 = 27$\n$a_0 = 1 + (3 \\times 2 \\times 5 \\times 1)(1-\\alpha) = 1 + 30(1-\\alpha) = 1 + 30 - 30\\alpha = 31 - 30\\alpha$\n\nLet's check the stability conditions.\nFirst condition: $a_0 > 0$.\n$31 - 30\\alpha > 0 \\implies 31 > 30\\alpha \\implies \\alpha < \\frac{31}{30} \\approx 1.033$.\nSince the problem states $\\alpha \\in [0,1]$, this condition is always satisfied.\n\nSecond, and more restrictive, condition: $a_2 a_1 > a_3 a_0$.\n$150 \\times 27 > 200 \\times (31 - 30\\alpha)$\n$4050 > 200 \\times (31 - 30\\alpha)$\nDividing by $50$:\n$81 > 4 \\times (31 - 30\\alpha)$\n$81 > 124 - 120\\alpha$\n$120\\alpha > 124 - 81$\n$120\\alpha > 43$\n$\\alpha > \\frac{43}{120}$\n\nThe system is stable if and only if $\\alpha > \\frac{43}{120}$. The problem asks for the minimum inhibition fraction, $\\alpha_{\\min}$, required to ensure stability. This corresponds to the boundary of the stability region. At this boundary value, the system is marginally stable. Therefore, the minimum value that defines the threshold for stability is:\n$\\alpha_{\\min} = \\frac{43}{120}$\n\nFinally, we convert this fraction to a decimal rounded to four significant figures:\n$\\alpha_{\\min} = \\frac{43}{120} \\approx 0.358333...$\nRounding to four significant figures gives:\n$\\alpha_{\\min} \\approx 0.3583$\nThis is the minimum inhibition fraction required to bring the system from an unstable or marginally stable state (when $\\alpha$ is small) into a stable state.", "answer": "$$\\boxed{0.3583}$$", "id": "4594941"}, {"introduction": "While some pathways are well-characterized, a major challenge in systems pharmacology is to infer network connectivity from high-throughput experimental data. This practice introduces a modern, data-driven approach using Least Absolute Shrinkage and Selection Operator (LASSO) regression to reconstruct a sparse network from perturbation-response measurements. You will work through a computational problem to identify the most influential connections in a pathway, providing a powerful example of how statistical learning can uncover pathway specificity and guide drug discovery [@problem_id:4595013].", "problem": "You are given a linearized systems pharmacology setup in which small experimental perturbations produce proportional changes in measured node activities. Under the linear-response approximation, the relationship between perturbations and responses is modeled as $$\\mathbf{R} = \\mathbf{W}\\mathbf{P},$$ where $\\mathbf{R}\\in\\mathbb{R}^{m\\times n}$ is the matrix of measured responses of $m$ nodes across $n$ experiments, $\\mathbf{P}\\in\\mathbb{R}^{m\\times n}$ is the matrix of perturbation intensities applied to $m$ pathway-aligned inputs across the same $n$ experiments, and $\\mathbf{W}\\in\\mathbb{R}^{m\\times m}$ encodes the edge weights from perturbation channels to measured nodes. For a single node $i$ (a row of $\\mathbf{R}$), the vector of responses across experiments, denoted $\\mathbf{y}\\in\\mathbb{R}^{n}$, is related to the perturbation design matrix (transposed) $\\mathbf{X}=\\mathbf{P}^\\top\\in\\mathbb{R}^{n\\times m}$ and the unknown edge weight vector $\\mathbf{w}\\in\\mathbb{R}^{m}$ via $$\\mathbf{y}=\\mathbf{X}\\mathbf{w}.$$ To enforce biologically plausible sparsity and pathway specificity, estimate $\\mathbf{w}$ by solving the Least Absolute Shrinkage and Selection Operator (LASSO) optimization problem, which seeks $$\\underset{\\mathbf{w}\\in\\mathbb{R}^{m}}{\\min}\\;\\frac{1}{2n}\\left\\lVert\\mathbf{y}-\\mathbf{X}\\mathbf{w}\\right\\rVert_2^2+\\lambda\\left\\lVert\\mathbf{w}\\right\\rVert_1,$$ where $\\lambda>0$ is the regularization parameter controlling sparsity.\n\nAfter estimating $\\mathbf{w}$, interpret sparsity in terms of pathway specificity. Each perturbation feature (column of $\\mathbf{P}$) belongs to a pathway group label from the set $\\{\\text{A},\\text{B}\\}$. Define the number of non-zero edges as $$N_{\\text{nz}}=\\left|\\left\\{j\\in\\{1,\\dots,m\\}\\;:\\;\\left|w_j\\right|>\\tau\\right\\}\\right|,$$ where $\\tau$ is a numerical threshold for practical zero and must be set to $\\tau=10^{-6}$. Define the pathway specificity index (PSI) as a decimal fraction $$\\text{PSI}=\\begin{cases}\\displaystyle\\frac{\\max\\left\\{c_{\\text{A}},c_{\\text{B}}\\right\\}}{N_{\\text{nz}}},&\\text{if }N_{\\text{nz}}>0,\\\\\\\\[6pt] 0,&\\text{if }N_{\\text{nz}}=0,\\end{cases}$$ where $c_{\\text{A}}$ (respectively $c_{\\text{B}}$) counts the number of non-zero edges pointing to features in pathway $\\text{A}$ (respectively $\\text{B}$). A larger $\\text{PSI}$ indicates that the non-zero edges are concentrated within a single pathway group, consistent with pathway-specific targeting.\n\nImplement a program that, for each provided test case, performs LASSO regression to estimate $\\mathbf{w}$ from $\\mathbf{y}$ and $\\mathbf{X}$ using coordinate descent with soft-thresholding and then computes $N_{\\text{nz}}$ and $\\text{PSI}$. For numerical stability, use the features as given, do not rescale them, and use the exact threshold $\\tau=10^{-6}$ for counting non-zero coefficients. Express $\\text{PSI}$ as a decimal (not a percentage), rounded to three decimal places.\n\nTest suite and data:\n- Case $1$ (happy path, mixed specificity):\n  - $m=3$, $n=6$\n  - $$\\mathbf{P}_1=\\begin{bmatrix}\n  1.0 & 0.0 & 2.0 & 0.0 & 1.0 & 0.0\\\\\n  0.0 & 1.0 & 0.0 & 2.0 & 0.5 & 1.5\\\\\n  1.0 & 1.0 & 1.0 & 1.0 & -1.0 & -1.0\n  \\end{bmatrix}$$\n  - True weights for the target node: $$\\mathbf{w}^{\\star}_1=\\begin{bmatrix}1.5&0.0&-0.5\\end{bmatrix}$$\n  - Pathway groups: $[\\text{A},\\text{A},\\text{B}]$\n  - Regularization parameter: $\\lambda=0.3$\n  - Responses: $$\\mathbf{y}_1=\\mathbf{P}_1^\\top\\mathbf{w}^{\\star}_1$$\n- Case $2$ (low regularization, same-path concentration):\n  - $m=3$, $n=5$\n  - $$\\mathbf{P}_2=\\begin{bmatrix}\n  1 & 2 & 1 & 0 & 0\\\\\n  0 & 1 & 2 & 1 & 0\\\\\n  0 & 0 & 0 & 1 & 1\n  \\end{bmatrix}$$\n  - True weights: $$\\mathbf{w}^{\\star}_2=\\begin{bmatrix}0.8&0.6&0.0\\end{bmatrix}$$\n  - Pathway groups: $[\\text{A},\\text{A},\\text{B}]$\n  - Regularization parameter: $\\lambda=0.05$\n  - Responses: $$\\mathbf{y}_2=\\mathbf{P}_2^\\top\\mathbf{w}^{\\star}_2$$\n- Case $3$ (boundary case, zero response):\n  - $m=3$, $n=4$\n  - $$\\mathbf{P}_3=\\begin{bmatrix}\n  1 & 0 & 1 & 0\\\\\n  0 & 1 & 0 & 1\\\\\n  1 & 1 & 0 & 0\n  \\end{bmatrix}$$\n  - True weights: $$\\mathbf{w}^{\\star}_3=\\begin{bmatrix}0&0&0\\end{bmatrix}$$\n  - Pathway groups: $[\\text{A},\\text{B},\\text{B}]$\n  - Regularization parameter: $\\lambda=0.1$\n  - Responses: $$\\mathbf{y}_3=\\begin{bmatrix}0&0&0&0\\end{bmatrix}$$\n- Case $4$ (collinearity challenge):\n  - $m=3$, $n=6$\n  - $$\\mathbf{P}_4=\\begin{bmatrix}\n  1 & 2 & 1 & 2 & 1 & 2\\\\\n  1 & 2 & 1 & 2 & 1 & 2\\\\\n  0 & 0 & 1 & 1 & 0 & 0\n  \\end{bmatrix}$$\n  - True weights: $$\\mathbf{w}^{\\star}_4=\\begin{bmatrix}1.0&0.0&0.5\\end{bmatrix}$$\n  - Pathway groups: $[\\text{A},\\text{B},\\text{B}]$\n  - Regularization parameter: $\\lambda=0.3$\n  - Responses: $$\\mathbf{y}_4=\\mathbf{P}_4^\\top\\mathbf{w}^{\\star}_4$$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[\\text{result}_1,\\text{result}_2,\\dots]$). Specifically, output $$[N_{\\text{nz},1},\\text{PSI}_1,N_{\\text{nz},2},\\text{PSI}_2,N_{\\text{nz},3},\\text{PSI}_3,N_{\\text{nz},4},\\text{PSI}_4],$$ where $N_{\\text{nz},k}$ is the integer number of non-zero coefficients for case $k$ and $\\text{PSI}_k$ is the pathway specificity index for case $k$ rounded to three decimal places (as a decimal fraction).", "solution": "The problem requires the estimation of a sparse weight vector $\\mathbf{w}$ in a linear model $\\mathbf{y} = \\mathbf{X}\\mathbf{w}$ using the Least Absolute Shrinkage and Selection Operator (LASSO) method. Subsequently, the estimated vector $\\mathbf{w}$ is analyzed for sparsity and pathway specificity.\n\nThe LASSO optimization problem is formulated as finding the vector $\\mathbf{w} \\in \\mathbb{R}^{m}$ that minimizes the following objective function:\n$$\nL(\\mathbf{w}) = \\frac{1}{2n} \\left\\lVert \\mathbf{y} - \\mathbf{X}\\mathbf{w} \\right\\rVert_2^2 + \\lambda \\left\\lVert \\mathbf{w} \\right\\rVert_1\n$$\nwhere $\\mathbf{y} \\in \\mathbb{R}^n$ is the vector of responses, $\\mathbf{X} \\in \\mathbb{R}^{n \\times m}$ is the design matrix, $n$ is the number of experiments, $m$ is the number of features (perturbation inputs), and $\\lambda > 0$ is the regularization parameter. The term $\\frac{1}{2n}\\left\\lVert \\mathbf{y} - \\mathbf{X}\\mathbf{w} \\right\\rVert_2^2$ is the mean squared error, which measures the model's fit to the data. The term $\\lambda \\left\\lVert \\mathbf{w} \\right\\rVert_1$ is the $L_1$-norm penalty, which encourages sparsity by driving some components of $\\mathbf{w}$ to exactly zero.\n\nTo solve this optimization problem, we employ the method of cyclic coordinate descent. This iterative algorithm optimizes the objective function with respect to a single coefficient $w_j$ at a time, holding all other coefficients $w_k$ (for $k \\neq j$) constant. The update for each coefficient is performed in a cycle through all coefficients $j=1, \\dots, m$.\n\nFor a single coefficient $w_j$, the objective function can be written as a function of $w_j$ alone:\n$$\nL(w_j) = \\frac{1}{2n} \\sum_{i=1}^{n} \\left( y_i - \\sum_{k \\neq j} X_{ik}w_k - X_{ij}w_j \\right)^2 + \\lambda \\sum_{k \\neq j} |w_k| + \\lambda |w_j|\n$$\nThis is a one-dimensional LASSO problem. To find the optimal $w_j$, we can find the value that sets the subgradient of the objective with respect to $w_j$ to zero. The solution is given by the soft-thresholding operator. Let $\\rho_j = \\sum_{i=1}^n X_{ij} (y_i - \\sum_{k \\neq j} X_{ik}w_k)$ be the dot product of the $j$-th feature with the partial residuals, and let $a_j = \\sum_{i=1}^n X_{ij}^2$ be the sum of squares of the $j$-th feature. The update rule for $w_j$ is:\n$$\nw_j \\leftarrow \\frac{S(\\rho_j, n\\lambda)}{a_j}\n$$\nwhere $S(\\alpha, \\gamma)$ is the soft-thresholding function, defined as:\n$$\nS(\\alpha, \\gamma) = \\operatorname{sign}(\\alpha) \\max(0, |\\alpha| - \\gamma) = \\begin{cases} \\alpha - \\gamma & \\text{if } \\alpha > \\gamma \\\\ \\alpha + \\gamma & \\text{if } \\alpha < -\\gamma \\\\ 0 & \\text{if } |\\alpha| \\le \\gamma \\end{cases}\n$$\nThe coordinate descent algorithm proceeds as follows:\n1. Initialize the weight vector $\\mathbf{w} = \\mathbf{0}$.\n2. Precompute $a_j = \\mathbf{X}_{:,j}^\\top\\mathbf{X}_{:,j}$ for each feature $j=1, \\dots, m$.\n3. Repeat for a fixed number of iterations or until the change in $\\mathbf{w}$ is below a tolerance:\n   For $j = 1, \\dots, m$:\n     a. Calculate $\\rho_j = \\mathbf{X}_{:,j}^\\top (\\mathbf{y} - \\sum_{k \\neq j} \\mathbf{X}_{:,k}w_k)$, where the most recently updated values of $w_k$ are used.\n     b. Update $w_j$ using the soft-thresholding rule: $w_j \\leftarrow S(\\rho_j, n\\lambda) / a_j$.\n\nAfter the algorithm converges to an estimated vector $\\mathbf{\\hat{w}}$, we analyze its structure. The number of non-zero edges, $N_{\\text{nz}}$, is calculated by counting the coefficients whose absolute value exceeds a small threshold $\\tau = 10^{-6}$:\n$$\nN_{\\text{nz}} = \\left| \\left\\{ j \\in \\{1, \\dots, m\\} \\,:\\, |\\hat{w}_j| > \\tau \\right\\} \\right|\n$$\nThe Pathway Specificity Index (PSI) measures the concentration of these non-zero edges within the predefined pathway groups $\\{\\text{A}, \\text{B}\\}$. Let $c_{\\text{A}}$ and $c_{\\text{B}}$ be the counts of non-zero edges corresponding to features in pathways A and B, respectively. The PSI is defined as:\n$$\n\\text{PSI} = \\begin{cases} \\displaystyle\\frac{\\max\\{c_{\\text{A}}, c_{\\text{B}}\\}}{N_{\\text{nz}}}, & \\text{if } N_{\\text{nz}} > 0, \\\\ 0, & \\text{if } N_{\\text{nz}} = 0. \\end{cases}\n$$\nThis procedure is applied to each of the four test cases provided. For each case, the design matrix $\\mathbf{X}$ is constructed as the transpose of the given perturbation matrix $\\mathbf{P}$, and the response vector $\\mathbf{y}$ is generated from the true weights $\\mathbf{w}^{\\star}$ via $\\mathbf{y} = \\mathbf{X}\\mathbf{w}^{\\star}$. The LASSO estimation is performed, and the resulting $N_{\\text{nz}}$ and PSI, rounded to three decimal places, are reported.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the LASSO problem using coordinate descent for multiple test cases\n    and computes pathway specificity metrics.\n    \"\"\"\n\n    def solve_lasso(X, y, lambda_val, max_iter=10000, tol=1e-9):\n        \"\"\"\n        Solves the LASSO optimization problem using cyclic coordinate descent.\n\n        Args:\n            X (np.ndarray): The design matrix (n x m).\n            y (np.ndarray): The response vector (n,).\n            lambda_val (float): The regularization parameter.\n            max_iter (int): Maximum number of iterations.\n            tol (float): Convergence tolerance.\n\n        Returns:\n            np.ndarray: The estimated weight vector w (m,).\n        \"\"\"\n        n, m = X.shape\n        w = np.zeros(m)\n        \n        # Precompute sum of squares of columns of X\n        a = np.einsum('ij,ij->j', X, X)\n        \n        # Soft-thresholding helper function\n        def soft_threshold(rho, gamma):\n            if rho > gamma:\n                return rho - gamma\n            elif rho < -gamma:\n                return rho + gamma\n            else:\n                return 0\n        \n        term_to_threshold = n * lambda_val\n\n        for _ in range(max_iter):\n            w_old = w.copy()\n            for j in range(m):\n                if a[j] == 0:\n                    continue\n                \n                # Calculate rho_j = X_j^T * (y - sum_{k!=j} X_k * w_k)\n                # This formulation is for cyclic coordinate descent, using the most\n                # recent values of w.\n                current_prediction_without_j = np.dot(X, w) - X[:, j] * w[j]\n                residual_without_j = y - current_prediction_without_j\n                rho_j = np.dot(X[:, j], residual_without_j)\n                \n                w[j] = soft_threshold(rho_j, term_to_threshold) / a[j]\n\n            if np.linalg.norm(w - w_old, ord=np.inf) < tol:\n                break\n                \n        return w\n\n    def calculate_metrics(w, pathways, threshold):\n        \"\"\"\n        Calculates the number of non-zero weights (N_nz) and the\n        Pathway Specificity Index (PSI).\n\n        Args:\n            w (np.ndarray): The estimated weight vector.\n            pathways (list): List of pathway labels for each feature.\n            threshold (float): Numerical threshold for practical zero.\n\n        Returns:\n            tuple: A tuple containing (N_nz, PSI).\n        \"\"\"\n        non_zero_indices = np.where(np.abs(w) > threshold)[0]\n        N_nz = len(non_zero_indices)\n        \n        if N_nz == 0:\n            return N_nz, 0.0\n\n        counts = {'A': 0, 'B': 0}\n        for idx in non_zero_indices:\n            pathway = pathways[idx]\n            counts[pathway] += 1\n            \n        c_A = counts['A']\n        c_B = counts['B']\n\n        psi = max(c_A, c_B) / N_nz\n        \n        return N_nz, psi\n        \n    # --- Define Test Cases from Problem Statement ---\n    \n    # Case 1\n    P1 = np.array([[1.0, 0.0, 2.0, 0.0, 1.0, 0.0],\n                   [0.0, 1.0, 0.0, 2.0, 0.5, 1.5],\n                   [1.0, 1.0, 1.0, 1.0, -1.0, -1.0]])\n    w_star1 = np.array([1.5, 0.0, -0.5])\n    pathways1 = ['A', 'A', 'B']\n    lambda1 = 0.3\n\n    # Case 2\n    P2 = np.array([[1, 2, 1, 0, 0],\n                   [0, 1, 2, 1, 0],\n                   [0, 0, 0, 1, 1]], dtype=float)\n    w_star2 = np.array([0.8, 0.6, 0.0])\n    pathways2 = ['A', 'A', 'B']\n    lambda2 = 0.05\n    \n    # Case 3\n    P3 = np.array([[1, 0, 1, 0],\n                   [0, 1, 0, 1],\n                   [1, 1, 0, 0]], dtype=float)\n    w_star3 = np.array([0, 0, 0], dtype=float)\n    pathways3 = ['A', 'B', 'B']\n    lambda3 = 0.1\n\n    # Case 4\n    P4 = np.array([[1, 2, 1, 2, 1, 2],\n                   [1, 2, 1, 2, 1, 2],\n                   [0, 0, 1, 1, 0, 0]], dtype=float)\n    w_star4 = np.array([1.0, 0.0, 0.5])\n    pathways4 = ['A', 'B', 'B']\n    lambda4 = 0.3\n\n    test_cases = [\n        (P1, w_star1, pathways1, lambda1),\n        (P2, w_star2, pathways2, lambda2),\n        (P3, w_star3, pathways3, lambda3),\n        (P4, w_star4, pathways4, lambda4)\n    ]\n\n    results = []\n    tau = 1e-6\n\n    for P, w_star, pathways, lambda_val in test_cases:\n        X = P.T\n        y = X @ w_star\n            \n        w_hat = solve_lasso(X, y, lambda_val)\n        \n        N_nz, psi = calculate_metrics(w_hat, pathways, tau)\n        \n        results.append(str(N_nz))\n        results.append(f\"{psi:.3f}\")\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "4595013"}]}