{"hands_on_practices": [{"introduction": "The initial step of many viral infections is the binding of a pathogen to specific receptors on the host cell surface. This practice explores how the principles of receptor kinetics can be used to build quantitative models of this critical process. By deriving and applying the Hill-Langmuir equation, you will learn to predict pathogen entry rates and compare them across different experimental systems, such as a controlled organoid culture and a more complex human challenge model [@problem_id:4676509]. This exercise highlights how fundamental biophysical models help bridge the gap between simplified *in vitro* systems and *in vivo* reality.", "problem": "A human airway organoid culture is used to study apical entry of a respiratory pathogen that binds a cell-surface receptor. Single-cell quantification indicates that each epithelial cell has $N_{R}$ apical receptors. The ligand-receptor interaction at the apical membrane is modeled as a reversible binding reaction $L + R \\rightleftharpoons LR$ governed by the law of mass action, with forward rate constant $k_{\\mathrm{on}}$ and reverse rate constant $k_{\\mathrm{off}}$. The dissociation constant is defined as $K_{d} = \\frac{k_{\\mathrm{off}}}{k_{\\mathrm{on}}}$. Assume that binding equilibrates rapidly relative to downstream internalization such that the system reaches a quasi-steady state for binding at the apical surface. The entry flux per cell is modeled by $J = k_{\\mathrm{entry}} N_{R} \\theta$, where $k_{\\mathrm{entry}}$ is the per-occupied-receptor entry rate constant and $\\theta$ is the fraction of receptors occupied.\n\nPart 1: Starting from the law of mass action and the definition of $K_{d}$, derive the expression for the steady-state receptor occupancy $\\theta$ in terms of the free ligand concentration $[L]$ and $K_{d}$.\n\nPart 2: In the organoid experiment, the apical free ligand concentration is $[L]_{\\mathrm{org}} = 5~\\mathrm{nM}$, $K_{d,\\mathrm{org}} = 15~\\mathrm{nM}$, $N_{R} = 2.0 \\times 10^{5}$ receptors per cell, and $k_{\\mathrm{entry}} = 2.0 \\times 10^{-5}~\\mathrm{s}^{-1}$. In a Human Challenge Model (HCM) of nasal inoculation, mucosal protease processing increases affinity by a factor $\\alpha = 0.40$ (so $K_{d,\\mathrm{HCM}} = \\alpha K_{d,\\mathrm{org}}$), while decoy binding reduces the free apical ligand concentration by a factor $\\beta = 0.60$ (so $[L]_{\\mathrm{HCM}} = \\beta [L]_{\\mathrm{org}}$). Under the same $N_{R}$ and $k_{\\mathrm{entry}}$, compute the fold-change in entry flux per cell $F = \\frac{J_{\\mathrm{HCM}}}{J_{\\mathrm{org}}}$.\n\nReport $F$ as a dimensionless number, rounded to four significant figures. Do not include units in your final reported value.", "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of chemical kinetics and receptor pharmacology, well-posed with sufficient information for a unique solution, and stated objectively. I will proceed with a full solution.\n\nThe problem is divided into two parts. First, the derivation of the steady-state receptor occupancy fraction, $\\theta$. Second, the calculation of the fold-change in pathogen entry flux, $F$, between two conditions.\n\nPart 1: Derivation of Receptor Occupancy $\\theta$\n\nThe ligand-receptor binding is described by the reversible reaction:\n$$L + R \\underset{k_{\\mathrm{off}}}{\\stackrel{k_{\\mathrm{on}}}{\\rightleftharpoons}} LR$$\nHere, $L$ represents the free ligand, $R$ the free receptor, and $LR$ the ligand-receptor complex. The forward and reverse rate constants are $k_{\\mathrm{on}}$ and $k_{\\mathrm{off}}$, respectively.\n\nAccording to the law of mass action, the rate of formation of the complex is proportional to the concentrations of the free reactants, $[L]$ and $[R]$:\n$$\\text{Rate}_{\\mathrm{forward}} = k_{\\mathrm{on}} [L] [R]$$\nThe rate of dissociation of the complex is proportional to the concentration of the complex, $[LR]$:\n$$\\text{Rate}_{\\mathrm{reverse}} = k_{\\mathrm{off}} [LR]$$\nThe problem states that binding equilibrates rapidly, implying the system reaches a quasi-steady state where the rate of formation equals the rate of dissociation:\n$$k_{\\mathrm{on}} [L] [R] = k_{\\mathrm{off}} [LR]$$\nRearranging this equation, we can group the rate constants:\n$$\\frac{[L] [R]}{[LR]} = \\frac{k_{\\mathrm{off}}}{k_{\\mathrm{on}}}$$\nThe problem defines the dissociation constant, $K_{d}$, as $K_{d} = \\frac{k_{\\mathrm{off}}}{k_{\\mathrm{on}}}$. Substituting this definition gives the equilibrium relationship:\n$$K_{d} = \\frac{[L] [R]}{[LR]}$$\nThe receptor occupancy, $\\theta$, is defined as the fraction of total receptors that are occupied by a ligand. Let $[R]_{\\mathrm{total}}$ be the total concentration of receptors. The total concentration is the sum of free receptors, $[R]$, and occupied receptors, $[LR]$:\n$$[R]_{\\mathrm{total}} = [R] + [LR]$$\nThe occupancy fraction is therefore:\n$$\\theta = \\frac{[LR]}{[R]_{\\mathrm{total}}} = \\frac{[LR]}{[R] + [LR]}$$\nTo express $\\theta$ in terms of $[L]$ and $K_{d}$, we first rearrange the equilibrium equation to solve for $[R]$:\n$$[R] = K_{d} \\frac{[LR]}{[L]}$$\nNow, we substitute this expression for $[R]$ into the denominator of the equation for $\\theta$:\n$$\\theta = \\frac{[LR]}{\\left(K_{d} \\frac{[LR]}{[L]}\\right) + [LR]}$$\nThe term $[LR]$ is common to all terms in the numerator and denominator and can be cancelled:\n$$\\theta = \\frac{1}{\\frac{K_{d}}{[L]} + 1}$$\nMultiplying the numerator and denominator by $[L]$ yields the final expression, commonly known as the Hill-Langmuir equation for non-cooperative binding:\n$$\\theta = \\frac{[L]}{K_{d} + [L]}$$\nThis completes the derivation for Part 1.\n\nPart 2: Calculation of the Fold-Change in Entry Flux\n\nThe entry flux per cell, $J$, is given by the model $J = k_{\\mathrm{entry}} N_{R} \\theta$. We need to compute the fold-change $F = \\frac{J_{\\mathrm{HCM}}}{J_{\\mathrm{org}}}$, where the subscripts `org` and `HCM` denote the organoid and Human Challenge Model conditions, respectively.\n\nThe flux for the organoid model is:\n$$J_{\\mathrm{org}} = k_{\\mathrm{entry}} N_{R} \\theta_{\\mathrm{org}}$$\nThe flux for the Human Challenge Model is:\n$$J_{\\mathrm{HCM}} = k_{\\mathrm{entry}} N_{R} \\theta_{\\mathrm{HCM}}$$\nThe problem states that $k_{\\mathrm{entry}}$ and $N_{R}$ are the same in both conditions. Therefore, the fold-change $F$ simplifies to the ratio of the occupancies:\n$$F = \\frac{J_{\\mathrm{HCM}}}{J_{\\mathrm{org}}} = \\frac{k_{\\mathrm{entry}} N_{R} \\theta_{\\mathrm{HCM}}}{k_{\\mathrm{entry}} N_{R} \\theta_{\\mathrm{org}}} = \\frac{\\theta_{\\mathrm{HCM}}}{\\theta_{\\mathrm{org}}}$$\nUsing the result from Part 1, we can write the expressions for $\\theta_{\\mathrm{org}}$ and $\\theta_{\\mathrm{HCM}}$:\n$$\\theta_{\\mathrm{org}} = \\frac{[L]_{\\mathrm{org}}}{K_{d,\\mathrm{org}} + [L]_{\\mathrm{org}}}$$\n$$\\theta_{\\mathrm{HCM}} = \\frac{[L]_{\\mathrm{HCM}}}{K_{d,\\mathrm{HCM}} + [L]_{\\mathrm{HCM}}}$$\nThe problem provides the relationships between the parameters in the two models:\n$$[L]_{\\mathrm{HCM}} = \\beta [L]_{\\mathrm{org}}$$\n$$K_{d,\\mathrm{HCM}} = \\alpha K_{d,\\mathrm{org}}$$\nwhere $\\alpha = 0.40$ and $\\beta = 0.60$.\nSubstituting these into the expression for $\\theta_{\\mathrm{HCM}}$:\n$$\\theta_{\\mathrm{HCM}} = \\frac{\\beta [L]_{\\mathrm{org}}}{\\alpha K_{d,\\mathrm{org}} + \\beta [L]_{\\mathrm{org}}}$$\nNow we can write the full expression for $F$:\n$$F = \\frac{\\theta_{\\mathrm{HCM}}}{\\theta_{\\mathrm{org}}} = \\frac{\\frac{\\beta [L]_{\\mathrm{org}}}{\\alpha K_{d,\\mathrm{org}} + \\beta [L]_{\\mathrm{org}}}}{\\frac{[L]_{\\mathrm{org}}}{K_{d,\\mathrm{org}} + [L]_{\\mathrm{org}}}}$$\nWe can simplify this complex fraction:\n$$F = \\frac{\\beta [L]_{\\mathrm{org}}}{\\alpha K_{d,\\mathrm{org}} + \\beta [L]_{\\mathrm{org}}} \\times \\frac{K_{d,\\mathrm{org}} + [L]_{\\mathrm{org}}}{[L]_{\\mathrm{org}}}$$\nThe term $[L]_{\\mathrm{org}}$ cancels, yielding a general expression for the fold-change:\n$$F = \\beta \\left( \\frac{K_{d,\\mathrm{org}} + [L]_{\\mathrm{org}}}{\\alpha K_{d,\\mathrm{org}} + \\beta [L]_{\\mathrm{org}}} \\right)$$\nNow we substitute the given numerical values: $[L]_{\\mathrm{org}} = 5~\\mathrm{nM}$, $K_{d,\\mathrm{org}} = 15~\\mathrm{nM}$, $\\alpha = 0.40$, and $\\beta = 0.60$. Note that the units of concentration (nM) are consistent and will cancel, so we may proceed with the numerical values.\n$$F = 0.60 \\left( \\frac{15 + 5}{(0.40)(15) + (0.60)(5)} \\right)$$\n$$F = 0.60 \\left( \\frac{20}{6 + 3} \\right)$$\n$$F = 0.60 \\left( \\frac{20}{9} \\right)$$\n$$F = \\frac{12}{9} = \\frac{4}{3}$$\nThe numerical value is $F = 1.3333...$. The problem requires the answer to be rounded to four significant figures.\n$$F \\approx 1.333$$\nThis is the dimensionless fold-change in entry flux.", "answer": "$$\\boxed{1.333}$$", "id": "4676509"}, {"introduction": "Moving from the molecular level to the whole-organism response, a key objective in infectious disease research is to measure the effect of therapeutic interventions on viral replication and shedding. Human challenge trials provide a controlled setting to collect such data, often in the form of longitudinal viral load measurements. This practice [@problem_id:4676472] introduces a core data analysis workflow in clinical virology: converting raw quantitative PCR ($C_t$) values into absolute viral loads and using numerical integration to calculate the area under the curve (AUC), a standard metric for quantifying total viral shedding and assessing antiviral efficacy.", "problem": "A randomized human challenge study of an antiviral agent measures upper respiratory viral shedding by quantitative Polymerase Chain Reaction (qPCR). In qPCR, the cycle threshold $C_{t}$ is inversely related to the logarithm (base ten) of the initial template quantity, and for an established assay the relationship can be represented by a standard curve. Assume the following assay standard curve, validated on organoid-derived viral calibrators, holds over the dynamic range for clinical swabs: \n$$C_{t}=\\alpha-\\beta \\log_{10}\\left(N\\right),$$ \nwhere $N$ is the viral load in copies per milliliter, $\\alpha=40.0$, and $\\beta=3.3$. Any $C_{t}$ strictly greater than $38$ is treated as non-detect and set to $N=0$.\n\nParticipants were sampled once daily from day $0$ (inoculation) to day $10$ (inclusive). The mean $C_{t}$ values over time in the placebo arm (control) were: day $0$: $40$, day $1$: $34$, day $2$: $28$, day $3$: $22$, day $4$: $20$, day $5$: $24$, day $6$: $30$, day $7$: $34$, day $8$: $37$, day $9$: $40$, day $10$: $40$. The mean $C_{t}$ values in the antiviral arm (treatment) were: day $0$: $40$, day $1$: $36$, day $2$: $32$, day $3$: $26$, day $4$: $24$, day $5$: $28$, day $6$: $34$, day $7$: $38$, day $8$: $40$, day $9$: $40$, day $10$: $40$.\n\nUsing only first principles that justify the standard curve and the definition of the definite integral, convert each $C_{t}$ value to $N$ and approximate the area under the viral load curve (AUC) from day $0$ to day $10$ for each arm by applying the trapezoidal rule to the daily measurements. Then, compute the difference in AUC between arms as control minus treatment. Express the final difference in copies-day per milliliter and round your answer to three significant figures. The final answer must be a single real number.", "solution": "The problem statement has been critically evaluated and is deemed valid. It is scientifically grounded in the principles of quantitative polymerase chain reaction (qPCR) and viral kinetics, is well-posed with sufficient and consistent data, and is expressed in objective, formal language. The problem is directly relevant to quantitative analysis in infectious disease research. We may therefore proceed with the solution.\n\nThe problem requires the calculation of the difference in viral load area under the curve (AUC) between a control arm and a treatment arm in a human challenge study. The steps are: first, to convert the given cycle threshold ($C_t$) values to viral load ($N$) in copies/mL for each arm; second, to approximate the AUC for each arm using the trapezoidal rule; and third, to compute the difference between these AUCs.\n\nFirst, we must establish the relationship to convert $C_t$ to $N$. The problem provides the standard curve equation:\n$$C_{t}=\\alpha-\\beta \\log_{10}(N)$$\nwith parameters $\\alpha=40.0$ and $\\beta=3.3$. To find $N$ as a function of $C_t$, we rearrange this equation:\n$$ \\log_{10}(N) = \\frac{\\alpha - C_t}{\\beta} $$\n$$ N(C_t) = 10^{\\frac{\\alpha - C_t}{\\beta}} $$\nSubstituting the given values for $\\alpha$ and $\\beta$:\n$$ N(C_t) = 10^{\\frac{40.0 - C_t}{3.3}} $$\nA crucial condition is that any $C_t$ value strictly greater than $38$ is considered non-detect, and the corresponding viral load $N$ is set to $0$. This condition overrides the formula for $C_t > 38$. This establishes a piecewise function for $N$:\n$$ N(C_t) = \\begin{cases} 10^{\\frac{40.0 - C_t}{3.3}} & \\text{if } C_t \\le 38 \\\\ 0 & \\text{if } C_t > 38 \\end{cases} $$\n\nNext, we calculate the daily viral loads, $N_c(t)$, for the control arm at each time point $t$ from day $0$ to day $10$. The given $C_t$ values for the control arm are $[40, 34, 28, 22, 20, 24, 30, 34, 37, 40, 40]$.\n- $t=0, C_t=40 > 38 \\implies N_c(0) = 0$\n- $t=1, C_t=34 \\le 38 \\implies N_c(1) = 10^{\\frac{40-34}{3.3}} = 10^{\\frac{6}{3.3}}$\n- $t=2, C_t=28 \\le 38 \\implies N_c(2) = 10^{\\frac{40-28}{3.3}} = 10^{\\frac{12}{3.3}}$\n- $t=3, C_t=22 \\le 38 \\implies N_c(3) = 10^{\\frac{40-22}{3.3}} = 10^{\\frac{18}{3.3}}$\n- $t=4, C_t=20 \\le 38 \\implies N_c(4) = 10^{\\frac{40-20}{3.3}} = 10^{\\frac{20}{3.3}}$\n- $t=5, C_t=24 \\le 38 \\implies N_c(5) = 10^{\\frac{40-24}{3.3}} = 10^{\\frac{16}{3.3}}$\n- $t=6, C_t=30 \\le 38 \\implies N_c(6) = 10^{\\frac{40-30}{3.3}} = 10^{\\frac{10}{3.3}}$\n- $t=7, C_t=34 \\le 38 \\implies N_c(7) = 10^{\\frac{40-34}{3.3}} = 10^{\\frac{6}{3.3}}$\n- $t=8, C_t=37 \\le 38 \\implies N_c(8) = 10^{\\frac{40-37}{3.3}} = 10^{\\frac{3}{3.3}}$\n- $t=9, C_t=40 > 38 \\implies N_c(9) = 0$\n- $t=10, C_t=40 > 38 \\implies N_c(10) = 0$\n\nWe approximate the area under the viral load curve, $AUC_c = \\int_0^{10} N_c(t) dt$, using the trapezoidal rule with daily measurements from $t_0=0$ to $t_{10}=10$. The time step is constant at $\\Delta t = 1$ day. The formula for the trapezoidal rule is:\n$$ AUC = \\Delta t \\left( \\frac{N(t_0) + N(t_{10})}{2} + \\sum_{i=1}^{9} N(t_i) \\right) $$\nFor the control arm, with $\\Delta t=1$, $N_c(0)=0$, and $N_c(10)=0$:\n$$ AUC_c = 1 \\cdot \\left( \\frac{0 + 0}{2} + \\sum_{i=1}^{9} N_c(i) \\right) = \\sum_{i=1}^{9} N_c(i) $$\n$$ AUC_c = N_c(1)+N_c(2)+N_c(3)+N_c(4)+N_c(5)+N_c(6)+N_c(7)+N_c(8)+N_c(9) $$\n$$ AUC_c = 10^{\\frac{6}{3.3}} + 10^{\\frac{12}{3.3}} + 10^{\\frac{18}{3.3}} + 10^{\\frac{20}{3.3}} + 10^{\\frac{16}{3.3}} + 10^{\\frac{10}{3.3}} + 10^{\\frac{6}{3.3}} + 10^{\\frac{3}{3.3}} + 0 $$\nNumerically, this is:\n$AUC_c \\approx 65.793 + 4328.741 + 284803.589 + 1149799.305 + 70543.604 + 1072.304 + 65.793 + 8.113 \\approx 1510687.24$ copies-day/mL.\n\nNext, we repeat the process for the treatment arm. The given $C_t$ values are $[40, 36, 32, 26, 24, 28, 34, 38, 40, 40, 40]$. The daily viral loads, $N_t(t)$, are:\n- $t=0, C_t=40 > 38 \\implies N_t(0) = 0$\n- $t=1, C_t=36 \\le 38 \\implies N_t(1) = 10^{\\frac{40-36}{3.3}} = 10^{\\frac{4}{3.3}}$\n- $t=2, C_t=32 \\le 38 \\implies N_t(2) = 10^{\\frac{40-32}{3.3}} = 10^{\\frac{8}{3.3}}$\n- $t=3, C_t=26 \\le 38 \\implies N_t(3) = 10^{\\frac{40-26}{3.3}} = 10^{\\frac{14}{3.3}}$\n- $t=4, C_t=24 \\le 38 \\implies N_t(4) = 10^{\\frac{40-24}{3.3}} = 10^{\\frac{16}{3.3}}$\n- $t=5, C_t=28 \\le 38 \\implies N_t(5) = 10^{\\frac{40-28}{3.3}} = 10^{\\frac{12}{3.3}}$\n- $t=6, C_t=34 \\le 38 \\implies N_t(6) = 10^{\\frac{40-34}{3.3}} = 10^{\\frac{6}{3.3}}$\n- $t=7, C_t=38 \\le 38 \\implies N_t(7) = 10^{\\frac{40-38}{3.3}} = 10^{\\frac{2}{3.3}}$\n- $t=8, C_t=40 > 38 \\implies N_t(8) = 0$\n- $t=9, C_t=40 > 38 \\implies N_t(9) = 0$\n- $t=10, C_t=40 > 38 \\implies N_t(10) = 0$\n\nWe apply the trapezoidal rule for the treatment arm, $AUC_t$. Here, $\\Delta t=1$, $N_t(0)=0$, and $N_t(10)=0$:\n$$ AUC_t = 1 \\cdot \\left( \\frac{0 + 0}{2} + \\sum_{i=1}^{9} N_t(i) \\right) = \\sum_{i=1}^{9} N_t(i) $$\n$$ AUC_t = N_t(1)+N_t(2)+N_t(3)+N_t(4)+N_t(5)+N_t(6)+N_t(7)+N_t(8)+N_t(9) $$\n$$ AUC_t = 10^{\\frac{4}{3.3}} + 10^{\\frac{8}{3.3}} + 10^{\\frac{14}{3.3}} + 10^{\\frac{16}{3.3}} + 10^{\\frac{12}{3.3}} + 10^{\\frac{6}{3.3}} + 10^{\\frac{2}{3.3}} + 0 + 0 $$\nNumerically, this is:\n$AUC_t \\approx 16.295 + 265.772 + 17475.228 + 70543.604 + 4328.741 + 65.793 + 4.037 \\approx 92699.470$ copies-day/mL.\n\nFinally, we compute the difference in AUC between the control and treatment arms, $\\Delta AUC = AUC_c - AUC_t$.\n$$ \\Delta AUC \\approx 1510687.24 - 92699.470 = 1417987.77 \\text{ copies-day/mL} $$\nThe problem requires this result to be rounded to three significant figures. The first three significant digits are $1$, $4$, and $1$. The fourth digit is $7$, which is greater than or equal to $5$, so we round up the third digit.\n$$ \\Delta AUC \\approx 1420000 $$\nThis can be expressed in scientific notation as $1.42 \\times 10^6$.", "answer": "$$\\boxed{1.42 \\times 10^6}$$", "id": "4676472"}, {"introduction": "While bulk measurements provide population-level averages, single-cell technologies reveal the profound heterogeneity of infection within a cell population. Single-cell RNA sequencing (scRNA-seq) can quantify pathogen transcripts in individual cells, but interpreting this sparse data requires sophisticated statistical methods. This advanced practice [@problem_id:4676539] demonstrates how to apply a Zero-Inflated Poisson (ZIP) model to infer a latent biological variable—the per-cell Multiplicity of Infection (MOI)—from pathogen transcript counts, a crucial step in understanding the diverse outcomes of cell-pathogen encounters.", "problem": "You are given single-cell RNA sequencing (scRNA-seq) pathogen transcript counts per cell from organoid or human challenge model experiments. The scientific question is to infer per-cell Multiplicity of Infection (MOI) from these counts using a Zero-Inflated Poisson (ZIP) model and to validate those MOI estimates against independent virion entry assay measurements for the same cells. Assume a measurement timepoint at which pathogen transcript counts are proportional to the number of entering virions per cell. The core modeling assumptions are as follows: single-cell pathogen transcript counts are modeled by a zero-inflated Poisson with parameters $\\,\\mu\\,$ (Poisson mean) and $\\,\\psi\\,$ (zero-inflation probability); per-virion transcript production at the measurement timepoint is a known proportionality constant $\\,\\alpha\\,$ such that the Poisson mean is $\\,\\mu = \\alpha \\lambda\\,$, where $\\,\\lambda\\,$ is the latent MOI of the susceptible-cell branch.\n\nStarting from the axioms of probability and classical definitions:\n- The Poisson distribution for a non-negative integer $\\,y\\,$ with rate $\\,\\mu > 0\\,$ has probability mass function $\\,\\mathbb{P}(Y=y) = e^{-\\mu} \\mu^{y} / y!\\,$.\n- A zero-inflated Poisson is a mixture of a point mass at zero and a Poisson component: with probability $\\,\\psi\\,$ the observation is exactly zero, and with probability $\\,1-\\psi\\,$ the observation $\\,Y\\,$ is drawn from a Poisson with mean $\\,\\mu\\,$.\n- Maximum Likelihood Estimation (MLE) chooses parameters that maximize the likelihood (or equivalently minimize the negative log-likelihood) given independent and identically distributed observations.\n- Bayesian posterior expectations use Bayes' theorem to compute $\\,\\mathbb{E}[K \\mid Y=y]\\,$ from a prior $\\,K \\sim \\text{Poisson}(\\lambda)\\,$ and an emission model $\\,Y \\mid K \\sim \\text{Poisson}(\\alpha K)\\,$ for $\\,y > 0\\,$, and a mixture for $\\,y=0\\,$ that accounts for structural zeros $\\,(\\psi)\\,$ versus Poisson zeros $\\,((1-\\psi) e^{-\\mu})\\,$.\n\nTask:\n1. For each provided test case, estimate $\\,\\mu\\,$ and $\\,\\psi\\,$ by maximum likelihood under the zero-inflated Poisson model:\n   - For each observation $\\,y_i = 0\\,$, the contribution to the likelihood is $\\psi + (1-\\psi)e^{-\\mu}$.\n   - For each observation $\\,y_i > 0\\,$, the contribution to the likelihood is $(1-\\psi) e^{-\\mu} \\mu^{y_i} / y_i!$.\n   - Optimize $\\mu > 0$ and $0 \\le \\psi  1$ to minimize the total negative log-likelihood. Use numerically stable computations throughout.\n2. Set $\\,\\lambda = \\mu / \\alpha\\,$ to map the fitted Poisson mean to MOI using the known proportionality $\\,\\alpha\\,$.\n3. For each cell, compute the posterior per-cell MOI $\\,\\widehat{K}_i = \\mathbb{E}[K \\mid Y=y_i]\\,$ under a mechanistic prior $\\,K \\sim \\text{Poisson}(\\lambda)\\,$ and emission $\\,Y \\mid K \\sim \\text{Poisson}(\\alpha K)\\,$:\n   - For $\\,y_i  0\\,$, use Bayes' theorem with unnormalized weights $w_k \\propto \\mathbb{P}(K=k) \\mathbb{P}(Y=y_i \\mid K=k) \\propto \\frac{\\lambda^k}{k!} e^{-\\alpha k} (\\alpha k)^{y_i}$ over $\\,k \\in \\{1,2,\\dots\\}\\,$. Compute $\\widehat{K}_i = \\sum_k k w_k / \\sum_k w_k$ using a numerically stable log-sum-exp evaluation and a sensible truncation of the sum that captures the tail mass.\n   - For $\\,y_i = 0\\,$, use the ZIP mixture posterior weight $w_0 = \\frac{(1-\\psi) e^{-\\mu}}{\\psi + (1-\\psi) e^{-\\mu}}$ for belonging to the Poisson branch versus being a structural zero. In the Poisson branch, compute $\\mathbb{E}[K \\mid Y=0]$ using weights $w_k \\propto \\frac{\\lambda^k}{k!} e^{-\\alpha k}$ for $\\,k \\in \\{0,1,2,\\dots\\}\\,$, and set $\\widehat{K}_i = w_0 \\times \\mathbb{E}[K \\mid Y=0]$.\n4. Validate against independent entry assays by computing the Root Mean Square Error (RMSE) across cells: $\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (\\widehat{K}_i - K^{\\text{assay}}_i)^2}$.\n\nTest Suite:\nImplement the above for the following three test cases, each consisting of a list of scRNA-seq pathogen transcript counts per cell $\\,\\{y_i\\}\\,$, an $\\,\\alpha\\,$ value, and independent entry assay virion counts per cell $\\,\\{K^{\\text{assay}}_i\\}\\,$. All numbers are given explicitly.\n\n- Test case $\\,1\\,$ (happy path, moderate zero inflation):\n  - Counts $\\,\\{y_i\\}\\,$: $[0,0,3,8,0,5,0,2,10,0,1,0,7,0,4,0,0,6,0,9]$.\n  - $\\,\\alpha = 5.0\\,$.\n  - Entry assay $\\,\\{K^{\\text{assay}}_i\\}\\,$: $[0,0,1,2,0,1,0,1,2,0,1,0,2,0,1,0,0,1,0,2]$.\n- Test case $\\,2\\,$ (boundary condition, no zero inflation):\n  - Counts $\\,\\{y_i\\}\\,$: $[0,4,5,2,7,9,1,0,3,8]$.\n  - $\\,\\alpha = 4.0\\,$.\n  - Entry assay $\\,\\{K^{\\text{assay}}_i\\}\\,$: $[0,1,1,1,1,2,1,0,1,2]$.\n- Test case $\\,3\\,$ (edge case, high zero inflation):\n  - Counts $\\,\\{y_i\\}\\,$: $[0,0,0,3,0,0,6,0,0,0,0,9]$.\n  - $\\,\\alpha = 3.0\\,$.\n  - Entry assay $\\,\\{K^{\\text{assay}}_i\\}\\,$: $[0,0,0,1,0,0,2,0,0,0,0,3]$.\n\nAnswer specification:\n- For each test case, compute the single validation metric $\\,\\text{RMSE}\\,$ as a float.\n- Your program should produce a single line of output containing the three $\\,\\text{RMSE}\\,$ values for the test cases in order, rounded to six decimal places, as a comma-separated list enclosed in square brackets (for example, $\\,\\texttt{[0.123456,0.234567,0.345678]}\\,$). No other text should be printed.\n- No physical units are involved, and all values must be printed as decimal floats with six decimal places, not as percentages.\n\nScientific realism note:\nThis task operationalizes widely used zero-inflated Poisson modeling for scRNA-seq pathogen transcript counts and ties the inferred Poisson mean to MOI via a known per-virion transcript proportionality. The posterior per-cell MOI calculation uses a mechanistic prior over virion entries per cell and a Poisson emission conditional on MOI to capture biological variability at the single-cell level. This workflow is applicable across organoid and human challenge model data where independent entry assay measurements can be used for validation.", "solution": "The problem statement has been validated and is determined to be a well-posed, scientifically grounded, and computationally tractable problem in statistical bioinformatics. It describes a standard workflow for analyzing single-cell pathogen count data, involving parameter estimation for a zero-inflated model and subsequent Bayesian inference for a latent variable (Multiplicity of Infection). All necessary data, definitions, and constraints are provided. The problem is free of scientific inaccuracies, contradictions, or ambiguities.\n\nThe solution proceeds by implementing the four specified tasks for each test case.\n\n### 1. Maximum Likelihood Estimation (MLE) of ZIP Parameters\n\nThe pathogen transcript counts $\\{y_i\\}$ are modeled as independent and identically distributed draws from a Zero-Inflated Poisson (ZIP) distribution with parameters $\\mu$ (Poisson mean) and $\\psi$ (zero-inflation probability). The probability mass function (PMF) is given by:\n$$\n\\mathbb{P}(Y=y) = \n\\begin{cases} \n\\psi + (1-\\psi)e^{-\\mu}  \\text{if } y = 0 \\\\\n(1-\\psi)\\frac{e^{-\\mu}\\mu^y}{y!}  \\text{if } y  0 \n\\end{cases}\n$$\nTo estimate $\\mu$ and $\\psi$, we maximize the log-likelihood of the observed data. Let $n_0$ be the number of zero counts and $n_{0}$ be the number of non-zero counts. The total log-likelihood function $\\mathcal{L}(\\mu, \\psi)$ is:\n$$\n\\mathcal{L}(\\mu, \\psi) = n_0 \\log(\\psi + (1-\\psi)e^{-\\mu}) + \\sum_{i: y_i0} \\log\\left((1-\\psi)\\frac{e^{-\\mu}\\mu^{y_i}}{y_i!}\\right)\n$$\nExpanding the second term, we get:\n$$\n\\mathcal{L}(\\mu, \\psi) = n_0 \\log(\\psi + (1-\\psi)e^{-\\mu}) + n_{0}(\\log(1-\\psi) - \\mu) + \\left(\\sum_{i: y_i0} y_i\\right)\\log\\mu - \\sum_{i: y_i0} \\log(y_i!)\n$$\nWe minimize the negative log-likelihood (NLL), $-\\mathcal{L}(\\mu, \\psi)$, subject to the constraints $\\mu  0$ and $0 \\le \\psi  1$. The constant term involving $\\log(y_i!)$ can be ignored during optimization. This is a numerical optimization problem, which we solve using the L-BFGS-B algorithm, a quasi-Newton method that supports box constraints. Initial parameter guesses are derived from the method of moments.\n\n### 2. Inference of MOI Rate $\\lambda$\n\nThe estimated Poisson mean $\\hat{\\mu}$ from the MLE procedure represents the average transcript count for the susceptible portion of the cell population. This is related to the latent mean Multiplicity of Infection (MOI), $\\lambda$, by the given proportionality constant $\\alpha$, representing per-virion transcript production. We compute the estimate for $\\lambda$ as:\n$$\n\\hat{\\lambda} = \\frac{\\hat{\\mu}}{\\alpha}\n$$\n\n### 3. Posterior Per-Cell MOI Estimation\n\nFor each cell $i$, we compute the posterior expectation of its MOI, $\\widehat{K}_i = \\mathbb{E}[K \\mid Y=y_i]$, using the estimated population parameter $\\hat{\\lambda}$. This combines a prior belief about MOI with the observed transcript count data for each cell. The models used are:\n- Prior: $K \\sim \\text{Poisson}(\\hat{\\lambda})$\n- Emission Likelihood: $Y \\mid K \\sim \\text{Poisson}(\\alpha K)$\n\nThe computation differs for zero and non-zero counts.\n\n#### Case 1: Non-Zero Counts ($y_i  0$)\nFor a cell with transcript count $y_i  0$, the posterior probability of its MOI being $k$ is given by Bayes' theorem:\n$$\n\\mathbb{P}(K=k \\mid Y=y_i) \\propto \\mathbb{P}(Y=y_i \\mid K=k) \\mathbb{P}(K=k)\n$$\nSince $y_i  0$, we must have $k \\ge 1$. The unnormalized posterior weights $w_k$ for $k \\in \\{1, 2, ...\\}$ are:\n$$\nw_k \\propto \\left( \\frac{e^{-\\alpha k}(\\alpha k)^{y_i}}{y_i!} \\right) \\left( \\frac{e^{-\\hat{\\lambda}}\\hat{\\lambda}^k}{k!} \\right) \\propto \\frac{(\\alpha k)^{y_i} \\hat{\\lambda}^k e^{-\\alpha k}}{k!}\n$$\nThe posterior expectation $\\widehat{K}_i$ is the weighted average:\n$$\n\\widehat{K}_i = \\frac{\\sum_{k=1}^{\\infty} k \\cdot w_k}{\\sum_{k=1}^{\\infty} w_k}\n$$\nTo compute this numerically, we work with log-weights to prevent underflow/overflow and truncate the infinite sum at a sufficiently large $k_{max}$. The sums are computed stably using the log-sum-exp trick.\n\n#### Case 2: Zero Counts ($y_i = 0$)\nAn observation of $y_i=0$ arises from a mixture: either the cell is a \"structural zero\" (truly uninfected, with probability $\\psi$), or it belongs to the susceptible group but stochastically produced zero transcripts (a \"Poisson zero\", with probability $1-\\psi$). The posterior expectation accounts for this mixture.\n$\\widehat{K}_i = \\mathbb{E}[K \\mid Y_i=0] = \\mathbb{P}(\\text{Poisson branch} \\mid Y_i=0) \\cdot \\mathbb{E}[K \\mid Y_i=0, \\text{Poisson branch}]$\nThe posterior probability of being in the Poisson branch, given $y_i=0$, is:\n$$\nw_0 = \\mathbb{P}(\\text{Poisson branch} \\mid Y_i=0) = \\frac{(1-\\hat{\\psi})e^{-\\hat{\\mu}}}{\\hat{\\psi} + (1-\\hat{\\psi})e^{-\\hat{\\mu}}}\n$$\nConditional on being in the Poisson branch, the posterior for $K$ given $Y=0$ is derived from the prior $K \\sim \\text{Poisson}(\\hat{\\lambda})$ and likelihood $\\mathbb{P}(Y=0 \\mid K=k) = e^{-\\alpha k}$. The resulting posterior distribution for $K$ is $\\text{Poisson}(\\hat{\\lambda}e^{-\\alpha})$, whose expectation is simply its mean.\n$$\n\\mathbb{E}[K \\mid Y_i=0, \\text{Poisson branch}] = \\hat{\\lambda}e^{-\\alpha}\n$$\nThus, the estimated MOI for a cell with zero counts is:\n$$\n\\widehat{K}_i = w_0 \\cdot (\\hat{\\lambda}e^{-\\alpha})\n$$\n\n### 4. Validation via RMSE\n\nFinally, the estimated per-cell MOI values $\\{\\widehat{K}_i\\}$ are validated against the ground truth measurements from the independent entry assay $\\{K^{\\text{assay}}_i\\}$. The validation metric is the Root Mean Square Error (RMSE):\n$$\n\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (\\widehat{K}_i - K^{\\text{assay}}_i)^2}\n$$\nThis entire procedure is applied to each of the three provided test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import gammaln\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the results.\n    \"\"\"\n\n    def solve_case(counts, alpha, k_assay):\n        \"\"\"\n        Solves one test case: estimates ZIP parameters, infers per-cell MOI,\n        and returns the RMSE against assay data.\n        \"\"\"\n        counts_arr = np.array(counts, dtype=np.float64)\n        n = len(counts_arr)\n        n0 = np.sum(counts_arr == 0)\n        n_pos = n - n0\n\n        # === 1. Maximum Likelihood Estimation for mu and psi ===\n\n        def neg_log_likelihood(params, counts_arr, n0, n_pos):\n            \"\"\"Computes the negative log-likelihood for the ZIP model.\"\"\"\n            mu, psi = params\n            \n            # This function is called by a bounded optimizer, so params are valid.\n            \n            # Log-likelihood for zero counts: log(psi + (1-psi)*exp(-mu))\n            # This expression is numerically stable for valid parameters.\n            log_prob_zero = np.log(psi + (1.0 - psi) * np.exp(-mu))\n            ll_zeros = n0 * log_prob_zero\n            \n            # Log-likelihood for positive counts\n            if n_pos  0:\n                pos_counts = counts_arr[counts_arr  0]\n                sum_pos_counts = np.sum(pos_counts)\n                \n                # log(1-psi) is valid as psi  1 from bounds\n                # log(mu) is valid as mu  0 from bounds\n                ll_pos = n_pos * (np.log(1.0 - psi) - mu) + sum_pos_counts * np.log(mu)\n            else:\n                ll_pos = 0.0\n            \n            # The total log-likelihood is ll_zeros + ll_pos. We return its negative.\n            return -(ll_zeros + ll_pos)\n\n        # Initial guesses using method of moments (for the non-zero part)\n        if n_pos  0:\n            mu_init = np.mean(counts_arr[counts_arr  0])\n        else: # All zeros case\n            mu_init = 1e-6 # A small, positive value\n            \n        p0_obs = n0 / n\n        denominator = 1.0 - np.exp(-mu_init)\n        if abs(denominator)  1e-9:\n          psi_init = 0.0\n        else:\n          psi_init = (p0_obs - np.exp(-mu_init)) / denominator\n        \n        psi_init = np.clip(psi_init, 0.0, 1.0 - 1e-9)\n\n        # Numerical optimization to find MLE parameters\n        opt_result = minimize(\n            neg_log_likelihood,\n            x0=[mu_init, psi_init],\n            args=(counts_arr, n0, n_pos),\n            method='L-BFGS-B',\n            bounds=[(1e-9, None), (0.0, 1.0 - 1e-9)]\n        )\n        mu, psi = opt_result.x\n        \n        # === 2. Infer MOI rate lambda ===\n        lambda_ = mu / alpha\n        \n        # === 3. Compute posterior per-cell MOI k_hat ===\n        k_hats = np.zeros(n)\n        k_max = 50  # Truncation limit for infinite sums should be sufficient\n        \n        # --- For cells with y_i = 0 ---\n        # Posterior probability of being a Poisson zero (not a structural zero)\n        # w0 = (1-psi)exp(-mu) / (psi + (1-psi)exp(-mu))\n        prob_poisson_branch_given_zero = ((1.0 - psi) * np.exp(-mu)) / (psi + (1.0 - psi) * np.exp(-mu))\n        \n        # Expected K for a Poisson branch cell that gives Y=0.\n        # Posterior P(K|Y=0, susceptible) is Poisson(lambda * exp(-alpha)).\n        # Expectation is its mean.\n        expected_k_poisson_zero = lambda_ * np.exp(-alpha)\n        \n        # Full posterior expectation for a Y=0 cell\n        k_hat_zero = prob_poisson_branch_given_zero * expected_k_poisson_zero\n        \n        # --- For cells with y_i  0 ---\n        k_range = np.arange(1, k_max + 1, dtype=np.float64)\n        log_gammaln_k_plus_1 = gammaln(k_range + 1)\n        \n        for i in range(n):\n            y = counts_arr[i]\n            if y == 0:\n                k_hats[i] = k_hat_zero\n            else:\n                # Calculate posterior expectation E[K | Y=y] using log-sum-exp\n                # log(w_k) is proportional to y*log(alpha*k) + k*log(lambda) - alpha*k - log(k!)\n                log_wk = (y * (np.log(alpha) + np.log(k_range)) + \n                          k_range * np.log(lambda_) - \n                          alpha * k_range - \n                          log_gammaln_k_plus_1)\n                \n                # Rescale by max log-weight for numerical stability (log-sum-exp trick)\n                log_wk_max = np.max(log_wk)\n                exp_terms = np.exp(log_wk - log_wk_max)\n                \n                sum_exp_terms = np.sum(exp_terms)\n                sum_k_exp_terms = np.sum(k_range * exp_terms)\n                \n                # E[K | Y=y] = sum(k * w_k) / sum(w_k)\n                k_hats[i] = sum_k_exp_terms / sum_exp_terms\n                \n        # === 4. Compute RMSE against assay data ===\n        assay_counts_arr = np.array(k_assay, dtype=np.float64)\n        rmse = np.sqrt(np.mean((k_hats - assay_counts_arr)**2))\n        \n        return rmse\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"counts\": [0,0,3,8,0,5,0,2,10,0,1,0,7,0,4,0,0,6,0,9],\n            \"alpha\": 5.0,\n            \"k_assay\": [0,0,1,2,0,1,0,1,2,0,1,0,2,0,1,0,0,1,0,2]\n        },\n        {\n            \"counts\": [0,4,5,2,7,9,1,0,3,8],\n            \"alpha\": 4.0,\n            \"k_assay\": [0,1,1,1,1,2,1,0,1,2]\n        },\n        {\n            \"counts\": [0,0,0,3,0,0,6,0,0,0,0,9],\n            \"alpha\": 3.0,\n            \"k_assay\": [0,0,0,1,0,0,2,0,0,0,0,3]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        rmse = solve_case(case[\"counts\"], case[\"alpha\"], case[\"k_assay\"])\n        results.append(rmse)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "4676539"}]}