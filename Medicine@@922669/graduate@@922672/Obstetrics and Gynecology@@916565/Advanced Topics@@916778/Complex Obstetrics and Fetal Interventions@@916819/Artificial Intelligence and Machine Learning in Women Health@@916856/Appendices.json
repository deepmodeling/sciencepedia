{"hands_on_practices": [{"introduction": "Real-world clinical data from electronic health records is often messy and incomplete. This exercise tackles a critical and common problem: when data is \"Missing Not At Random\" (MNAR), it can introduce significant bias into our models, leading to flawed conclusions. This is particularly relevant in obstetrics, where factors like late initiation of prenatal care can systematically affect data availability.\n\nThis practice [@problem_id:4404536] will guide you through a hypothetical but realistic scenario to understand this bias analytically. You will explore how an apparently intractable MNAR problem can become statistically manageable when we condition on the right auxiliary information. By deriving the bias and then applying Inverse Probability Weighting (IPW)—a powerful statistical technique—you will learn how to obtain a corrected, unbiased estimate of population-level risk. This provides a foundational understanding of data-driven bias, equipping you to critically assess the validity of AI models trained on imperfect clinical data.", "problem": "An academic medical center is building an artificial intelligence (AI) risk stratification tool for preeclampsia that uses gestational age as a key predictor. Let $S$ denote the model’s predicted individual risk (a probability) and $G$ denote the gestational age category at the time of intake, with $G \\in \\{g_{E}, g_{L}\\}$, where $g_{E}$ represents early intake (approximately first trimester) and $g_{L}$ represents late intake (approximately second trimester). Due to late prenatal care, gestational age $G$ is frequently unrecorded in the electronic health record. Let $R$ be the missingness indicator for $G$, with $R=1$ if $G$ is recorded and $R=0$ otherwise. The late prenatal care indicator $L \\in \\{0,1\\}$ is fully observed for all patients, with $L=1$ indicating late prenatal care.\n\nAssume the following scientifically realistic data-generating structure, reflecting the common situation that missingness depends on the unobserved $G$ (thereby being Missing Not At Random (MNAR) in the dataset that does not condition on $G$), but becomes Missing At Random (MAR) after conditioning on $L$ because $L$ fully determines $G$ in this stylized setup:\n\n1. Prevalence of late prenatal care: $\\mathbb{P}(L=1)=0.35$ and $\\mathbb{P}(L=0)=0.65$.\n2. Deterministic link between $L$ and gestational age category: $G=g_{E}$ if $L=0$ and $G=g_{L}$ if $L=1$.\n3. Missingness of $G$ depends on $G$ (hence MNAR without $L$): $\\mathbb{P}(R=1 \\mid G=g_{E})=0.95$ and $\\mathbb{P}(R=1 \\mid G=g_{L})=0.40$.\n4. The AI model’s predicted risk depends only on $G$ (other covariates are integrated out for this exercise): $S=s_{E}$ if $G=g_{E}$ and $S=s_{L}$ if $G=g_{L}$, with $s_{E}=0.06$ and $s_{L}=0.12$.\n\nWork in the large-sample (population) limit so that sample averages converge to expectations. Use only core definitions from the missing data literature (e.g., Missing Not At Random (MNAR), Missing At Random (MAR)), the law of total probability, and the law of iterated expectations.\n\nTasks:\n1. Starting from first principles, derive an analytical expression for the bias of the complete-case (i.e., $R=1$) mean risk estimator relative to the true mean risk, and then compute its exact numerical value under the specified structure.\n2. Derive from first principles an inverse probability weighting (IPW) estimator for the marginal mean risk that uses weights based on $\\pi(L)=\\mathbb{P}(R=1 \\mid L)$, and show analytically that, under the given structure, the IPW estimator recovers the true mean risk in the population.\n3. Compute the numerical value of the IPW-corrected mean risk.\n\nProvide the final answer as the bias of the complete-case mean risk estimator (task 1), expressed as a decimal and rounded to four significant figures. No units are required. Do not report a percentage sign; express any proportion as a pure decimal.", "solution": "We formalize the problem using the following notation. Let $S$ be the predicted risk, $G \\in \\{g_{E}, g_{L}\\}$ the gestational age category, $L \\in \\{0,1\\}$ the late-care indicator with $\\mathbb{P}(L=1)=0.35$ and $\\mathbb{P}(L=0)=0.65$, and $R \\in \\{0,1\\}$ the indicator that $G$ is recorded. The structure imposes $G=g_{E}$ if $L=0$ and $G=g_{L}$ if $L=1$. Missingness depends on $G$: $\\mathbb{P}(R=1 \\mid G=g_{E})=0.95$ and $\\mathbb{P}(R=1 \\mid G=g_{L})=0.40$. Predicted risk is $S=s_{E}$ when $G=g_{E}$ and $S=s_{L}$ when $G=g_{L}$ with $s_{E}=0.06$ and $s_{L}=0.12$.\n\nWe first identify the true marginal mean risk and the naive complete-case mean, then compute the bias, and finally derive inverse probability weighting (IPW) and show it corrects the mean.\n\nStep 1: True marginal mean risk. By the law of total probability applied to $L$ and the deterministic relationship between $L$ and $G$, the true mean is\n$$\n\\mathbb{E}[S]\n= \\mathbb{P}(L=0)\\, s_{E} + \\mathbb{P}(L=1)\\, s_{L}\n= 0.65 \\times 0.06 + 0.35 \\times 0.12.\n$$\nCompute:\n$$\n0.65 \\times 0.06 = 0.039,\\quad 0.35 \\times 0.12 = 0.042,\\quad \\Rightarrow \\mathbb{E}[S] = 0.081.\n$$\nIn exact fractional form, $\\mathbb{E}[S] = \\frac{81}{1000}$.\n\nStep 2: Naive complete-case mean risk and its bias. The complete-case mean uses only $R=1$ cases and estimates $\\mathbb{E}[S \\mid R=1]$. By definition,\n$$\n\\mathbb{E}[S \\mid R=1]\n= \\sum_{g \\in \\{g_{E}, g_{L}\\}} \\mathbb{P}(G=g \\mid R=1)\\, s(g).\n$$\nCompute $\\mathbb{P}(G=g \\mid R=1)$ via Bayes’ rule and the law of total probability. Because $G=g_{E}$ iff $L=0$ and $G=g_{L}$ iff $L=1$,\n$$\n\\mathbb{P}(R=1) = \\mathbb{P}(R=1 \\mid G=g_{E})\\mathbb{P}(G=g_{E}) + \\mathbb{P}(R=1 \\mid G=g_{L})\\mathbb{P}(G=g_{L})\n= 0.95 \\times 0.65 + 0.40 \\times 0.35 = 0.6175 + 0.14 = 0.7575.\n$$\nThen\n$$\n\\mathbb{P}(G=g_{E} \\mid R=1) = \\frac{0.95 \\times 0.65}{0.7575} = \\frac{0.6175}{0.7575} = \\frac{247}{303},\n$$\n$$\n\\mathbb{P}(G=g_{L} \\mid R=1) = \\frac{0.40 \\times 0.35}{0.7575} = \\frac{0.14}{0.7575} = \\frac{56}{303}.\n$$\nTherefore,\n$$\n\\mathbb{E}[S \\mid R=1] = \\frac{247}{303}\\times 0.06 + \\frac{56}{303}\\times 0.12.\n$$\nUse exact fractions $0.06=\\frac{3}{50}$ and $0.12=\\frac{3}{25}$:\n$$\n\\mathbb{E}[S \\mid R=1] = \\frac{247}{303}\\cdot \\frac{3}{50} + \\frac{56}{303}\\cdot \\frac{3}{25}\n= \\frac{3}{303}\\left(\\frac{247}{50} + \\frac{56}{25}\\right)\n= \\frac{3}{303}\\left(\\frac{247}{50} + \\frac{112}{50}\\right)\n= \\frac{3}{303}\\cdot \\frac{359}{50}\n= \\frac{1077}{15150} = \\frac{359}{5050}.\n$$\nAs a decimal, $\\mathbb{E}[S \\mid R=1] \\approx 0.0710891089$.\n\nBy definition, the bias of the complete-case estimator relative to the true mean is\n$$\n\\text{Bias} = \\mathbb{E}[S \\mid R=1] - \\mathbb{E}[S].\n$$\nUsing the exact forms,\n$$\n\\text{Bias} = \\frac{359}{5050} - \\frac{81}{1000}.\n$$\nPut over a common denominator $101000$:\n$$\n\\frac{359}{5050} = \\frac{7180}{101000},\\quad \\frac{81}{1000} = \\frac{8181}{101000},\n$$\nhence\n$$\n\\text{Bias} = \\frac{7180 - 8181}{101000} = -\\frac{1001}{101000} \\approx -0.0099108911.\n$$\nThe negative sign reveals downward bias: late-intake pregnancies with higher $s_{L}$ are underrepresented among $R=1$.\n\nInterpretation of missing data mechanism. Because $R$ depends on $G$ directly, which is unobserved when $R=0$, the missingness is Missing Not At Random (MNAR) when not conditioning on a sufficient set. However, in this stylized structure $L$ fully determines $G$, and $L$ is fully observed, so the mechanism is Missing At Random (MAR) conditional on $L$; that is, $\\mathbb{P}(R=1 \\mid S,G,L)=\\mathbb{P}(R=1 \\mid L)$.\n\nStep 3: Inverse probability weighting (IPW) correction. Define the selection probability $\\pi(L)=\\mathbb{P}(R=1 \\mid L)$. Given the deterministic mapping $L \\mapsto G$,\n$$\n\\pi(0) = \\mathbb{P}(R=1 \\mid L=0) = \\mathbb{P}(R=1 \\mid G=g_{E}) = 0.95,\\quad\n\\pi(1) = \\mathbb{P}(R=1 \\mid L=1) = \\mathbb{P}(R=1 \\mid G=g_{L}) = 0.40.\n$$\nThe (normalized) IPW estimator of the marginal mean uses weights $w(L)=1/\\pi(L)$:\n$$\n\\hat{\\mu}_{\\text{IPW}} = \\frac{\\mathbb{E}\\!\\left[ \\frac{R}{\\pi(L)} S \\right]}{\\mathbb{E}\\!\\left[ \\frac{R}{\\pi(L)} \\right]}.\n$$\nBy the law of iterated expectations and the MAR property given $L$,\n$$\n\\mathbb{E}\\!\\left[ \\frac{R}{\\pi(L)} S \\right]\n= \\mathbb{E}\\!\\left[ \\mathbb{E}\\!\\left[ \\left. \\frac{R}{\\pi(L)} S \\right| L \\right] \\right]\n= \\mathbb{E}\\!\\left[ \\frac{1}{\\pi(L)} \\mathbb{E}[ R \\mid L ]\\, \\mathbb{E}[ S \\mid L ] \\right]\n= \\mathbb{E}\\!\\left[ \\frac{1}{\\pi(L)} \\pi(L) \\, \\mathbb{E}[ S \\mid L ] \\right]\n= \\mathbb{E}[ \\mathbb{E}[ S \\mid L ] ] = \\mathbb{E}[S].\n$$\nSimilarly,\n$$\n\\mathbb{E}\\!\\left[ \\frac{R}{\\pi(L)} \\right]\n= \\mathbb{E}\\!\\left[ \\mathbb{E}\\!\\left[ \\left. \\frac{R}{\\pi(L)} \\right| L \\right] \\right]\n= \\mathbb{E}\\!\\left[ \\frac{1}{\\pi(L)} \\mathbb{E}[ R \\mid L ] \\right]\n= \\mathbb{E}\\!\\left[ \\frac{1}{\\pi(L)} \\pi(L) \\right] = \\mathbb{E}[1]=1.\n$$\nTherefore,\n$$\n\\hat{\\mu}_{\\text{IPW}} = \\mathbb{E}[S],\n$$\nshowing that IPW recovers the true marginal mean under correct specification of $\\pi(L)$.\n\nNumerical value of the IPW-corrected mean. From Step 1,\n$$\n\\hat{\\mu}_{\\text{IPW}} = \\mathbb{E}[S] = 0.081 = \\frac{81}{1000}.\n$$\n\nSummary. The complete-case estimator has bias\n$$\n\\text{Bias} = -\\frac{1001}{101000} \\approx -0.0099108911,\n$$\nand the inverse probability weighted estimator recovers the true mean risk $0.081$ in this structure. Per the problem’s instruction, we report the bias rounded to four significant figures.", "answer": "$$\\boxed{-0.009911}$$", "id": "4404536"}, {"introduction": "Moving beyond static predictions, many modern clinical AI tools function as sophisticated monitoring systems that process continuous streams of data. This practice simulates the design of such a system for detecting hypertensive episodes in pregnancy using time-series data from home blood pressure cuffs and wearable activity sensors. This task is crucial for the timely management of hypertensive disorders of pregnancy.\n\nIn this exercise [@problem_id:4404625], you will construct a multi-layered algorithm that translates clinical expertise into a formal set of rules. This involves integrating trimester-specific statistical norms, absolute clinical thresholds for hypertension, and context-aware adjustments that account for physical activity and filter out motion artifacts. This hands-on task demonstrates how to codify complex clinical logic to build a reliable and robust decision support tool for remote patient monitoring.", "problem": "You are tasked with constructing and implementing an algorithm to detect hypertensive episodes in pregnancy from home Blood Pressure (BP) and wearable activity sensor time-series. The algorithm must use trimester-specific normative distributions to set detection thresholds with a controlled false positive rate, incorporate adjustments for activity-induced transient elevations, apply robust outlier suppression for motion artifacts, and respect minimum clinical threshold floors. The final output must classify each provided test case as an integer code: $0$ for no episode detected, $1$ for a primary hypertensive episode detected, or $2$ for a severe hypertensive episode detected. All blood pressure values are in millimeters of mercury (mmHg). Sampling is at $1$ minute intervals. Activity is a dimensionless value normalized to the interval $\\left[0,1\\right]$.\n\nFundamental base and constraints:\n\n- Blood Pressure (BP) readings consist of systolic values $S_t$ and diastolic values $D_t$ measured at discrete times $t = 1,2,\\dots,T$.\n- The trimester-specific normative distributions are modeled as independent Gaussian distributions $S \\sim \\mathcal{N}\\left(\\mu_s,\\sigma_s^2\\right)$ and $D \\sim \\mathcal{N}\\left(\\mu_d,\\sigma_d^2\\right)$ for resting measurements.\n- A false positive rate $\\alpha$ is enforced via the Neyman-Pearson tail-quantile construction. Define the upper-tail quantile $q_\\alpha = \\Phi^{-1}\\left(1-\\alpha\\right)$, where $\\Phi^{-1}$ is the inverse cumulative distribution function of the standard normal distribution. The trimester-specific normative thresholds are:\n  $$T_{s,\\mathrm{norm}} = \\mu_s + \\sigma_s q_\\alpha,\\quad T_{d,\\mathrm{norm}} = \\mu_d + \\sigma_d q_\\alpha.$$\n- Clinical minimum threshold floors for pregnancy hypertension must apply: the systolic threshold $T_{s,\\mathrm{floor}} = 140$ and the diastolic threshold $T_{d,\\mathrm{floor}} = 90$. The operative primary detection thresholds are:\n  $$T_s = \\max\\left(T_{s,\\mathrm{norm}},\\,T_{s,\\mathrm{floor}}\\right),\\quad T_d = \\max\\left(T_{d,\\mathrm{norm}},\\,T_{d,\\mathrm{floor}}\\right).$$\n- Severe thresholds for pregnancy hypertension with severe features are absolute: $T_{s,\\mathrm{severe}} = 160$ and $T_{d,\\mathrm{severe}} = 110$.\n- To account for activity-induced transient elevations, apply a linear adjustment to readings before comparing to $T_s$ and $T_d$:\n  $$S_{t,\\mathrm{adj}} = S_t - \\beta_s a_t,\\quad D_{t,\\mathrm{adj}} = D_t - \\beta_d a_t,$$\n  where $a_t \\in [0,1]$ is the activity level at time $t$, $\\beta_s = 8$ and $\\beta_d = 5$ in mmHg per unit activity.\n- Robust suppression of motion artifacts uses the Median Absolute Deviation (MAD). For a sequence $x_t$, compute\n  $$m_x = \\mathrm{median}(x_t),\\quad \\mathrm{MAD}_x = \\mathrm{median}\\left(\\left|x_t - m_x\\right|\\right).$$\n  A sample at time $t$ is marked invalid if \n  $$\\left|S_t - m_S\\right| > k \\cdot \\mathrm{MAD}_S\\ \\text{ or }\\ \\left|D_t - m_D\\right| > k \\cdot \\mathrm{MAD}_D,$$\n  and simultaneously $a_t > a_{\\mathrm{artifact}}$. Use $k=3$ and $a_{\\mathrm{artifact}} = 0.5$.\n- Rest gating: an episode can only be declared when the activity is low, with $a_t \\le a_{\\mathrm{rest}}$, where $a_{\\mathrm{rest}} = 0.3$.\n- Primary episode detection requires at least $r$ consecutive valid, rest-gated samples that exceed the operative thresholds:\n  $$\\text{primary if there exists } t \\text{ such that for } r \\text{ consecutive indices } i\\in\\{t,\\dots,t+r-1\\},\\ a_i \\le a_{\\mathrm{rest}},\\ \\text{valid}_i = \\text{true},\\ \\text{and } \\left( S_{i,\\mathrm{adj}} \\ge T_s\\ \\text{ or }\\ D_{i,\\mathrm{adj}} \\ge T_d \\right).$$\n  Use $r=3$.\n- Severe episode detection requires at least $p$ consecutive valid, rest-gated samples that exceed the severe thresholds using unadjusted measurements:\n  $$\\text{severe if there exists } t \\text{ such that for } p \\text{ consecutive indices } i\\in\\{t,\\dots,t+p-1\\},\\ a_i \\le a_{\\mathrm{rest}},\\ \\text{valid}_i = \\text{true},\\ \\text{and } \\left( S_{i} \\ge T_{s,\\mathrm{severe}}\\ \\text{ or }\\ D_{i} \\ge T_{d,\\mathrm{severe}} \\right).$$\n  Use $p=2$.\n- Classification rule: return $2$ if severe criteria are met; else return $1$ if primary criteria are met; else return $0$.\n\nTrimester-specific normative parameters:\n\n- First trimester ($\\text{trimester}=1$): $\\mu_s = 118$, $\\sigma_s = 10$; $\\mu_d = 76$, $\\sigma_d = 8$.\n- Second trimester ($\\text{trimester}=2$): $\\mu_s = 112$, $\\sigma_s = 9$; $\\mu_d = 72$, $\\sigma_d = 7$.\n- Third trimester ($\\text{trimester}=3$): $\\mu_s = 116$, $\\sigma_s = 10$; $\\mu_d = 74$, $\\sigma_d = 8$.\n- Use $\\alpha = 0.01$.\n\nYour program must implement the above algorithm and produce the specified classifications for the following test suite. Each test case is a tuple containing $(\\text{trimester}, S, D, A)$, where $S$ is the systolic sequence, $D$ is the diastolic sequence, and $A$ is the activity sequence. All BP values are in mmHg, and activity values are dimensionless in $\\left[0,1\\right]$.\n\nTest suite:\n\n- Case $1$ (first trimester, high activity spikes, no episode expected):\n  - $\\text{trimester} = 1$\n  - $S = [126,130,142,139,145,135,128,140]$\n  - $D = [80,82,84,83,86,79,81,85]$\n  - $A = [0.6,0.7,0.8,0.7,0.9,0.65,0.7,0.8]$\n- Case $2$ (second trimester, sustained diastolic elevation at rest, primary episode expected):\n  - $\\text{trimester} = 2$\n  - $S = [118,120,122,119,117,115,121,120]$\n  - $D = [92,94,95,91,89,88,87,90]$\n  - $A = [0.1,0.1,0.1,0.1,0.1,0.1,0.2,0.1]$\n- Case $3$ (third trimester, severe systolic elevations at rest, severe episode expected):\n  - $\\text{trimester} = 3$\n  - $S = [165,166,164,150,148,152]$\n  - $D = [90,92,88,85,84,86]$\n  - $A = [0.05,0.05,0.05,0.1,0.1,0.1]$\n- Case $4$ (second trimester, systolic near normative threshold but below clinical floor, no episode expected):\n  - $\\text{trimester} = 2$\n  - $S = [136,136,137,132,133,135]$\n  - $D = [80,82,81,79,80,82]$\n  - $A = [0.1,0.1,0.1,0.1,0.1,0.1]$\n- Case $5$ (first trimester, motion artifact outlier with high activity, no episode expected after robust filtering):\n  - $\\text{trimester} = 1$\n  - $S = [120,122,200,121,119,118,117,116]$\n  - $D = [75,76,90,74,73,72,71,70]$\n  - $A = [0.1,0.1,0.8,0.1,0.1,0.1,0.1,0.1]$\n\nFinal output format:\n\n- Your program should produce a single line of output containing the classification results for the five test cases as a comma-separated list enclosed in square brackets, for example: $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5\\right]$.\n- Each $\\text{result}_i$ must be an integer in $\\{0,1,2\\}$ as defined above.", "solution": "The problem statement has been critically examined and is determined to be valid. It is scientifically grounded in established principles of obstetrics and ambulatory blood pressure monitoring, well-posed with a clear and complete set of definitions and constraints, and objective in its formulation. The task is to construct a rule-based algorithm for classifying hypertensive episodes from time-series data, a problem that is both formalizable and relevant to the application of artificial intelligence in women's health. We may therefore proceed with a principled solution.\n\nThe algorithm systematically processes time-series data of systolic blood pressure ($S_t$), diastolic blood pressure ($D_t$), and physical activity ($a_t$) for a given pregnancy trimester. The classification logic entails several stages: parameter initialization, outlier suppression, and sequential-episode detection.\n\nFirst, we establish the constants and parameters governing the algorithm.\nThe false positive rate for normative thresholding is set to $\\alpha = 0.01$. The quantile for a one-tailed test is $q_\\alpha = \\Phi^{-1}(1-\\alpha)$, where $\\Phi^{-1}$ is the inverse of the standard normal cumulative distribution function. For $\\alpha = 0.01$, $q_{0.01} = \\Phi^{-1}(0.99) \\approx 2.3263$.\n\nThe clinical threshold floors are $T_{s,\\mathrm{floor}} = 140$ mmHg and $T_{d,\\mathrm{floor}} = 90$ mmHg for primary hypertension, and the absolute severe thresholds are $T_{s,\\mathrm{severe}} = 160$ mmHg and $T_{d,\\mathrm{severe}} = 110$ mmHg.\n\nActivity-related parameters include the adjustment coefficients $\\beta_s = 8$ mmHg/unit activity and $\\beta_d = 5$ mmHg/unit activity, the artifact activity threshold $a_{\\mathrm{artifact}} = 0.5$, and the resting state threshold $a_{\\mathrm{rest}} = 0.3$.\n\nOutlier detection is governed by a multiplier $k=3$. Episode detection requires a minimum of $r=3$ consecutive readings for a primary episode and $p=2$ for a severe episode.\n\nThe analysis for each test case begins by selecting the trimester-specific normative parameters $(\\mu_s, \\sigma_s, \\mu_d, \\sigma_d)$ from the provided table:\n- Trimester $1$: $\\mu_s = 118$, $\\sigma_s = 10$; $\\mu_d = 76$, $\\sigma_d = 8$.\n- Trimester $2$: $\\mu_s = 112$, $\\sigma_s = 9$; $\\mu_d = 72$, $\\sigma_d = 7$.\n- Trimester $3$: $\\mu_s = 116$, $\\sigma_s = 10$; $\\mu_d = 74$, $\\sigma_d = 8$.\n\nFrom these, the normative blood pressure thresholds are calculated:\n$$T_{s,\\mathrm{norm}} = \\mu_s + \\sigma_s q_\\alpha$$\n$$T_{d,\\mathrm{norm}} = \\mu_d + \\sigma_d q_\\alpha$$\n\nThe operative primary thresholds, $T_s$ and $T_d$, are then determined by taking the maximum of the normative and clinical floor thresholds, ensuring that clinical standards are respected:\n$$T_s = \\max\\left(T_{s,\\mathrm{norm}},\\,T_{s,\\mathrm{floor}}\\right)$$\n$$T_d = \\max\\left(T_{d,\\mathrm{norm}},\\,T_{d,\\mathrm{floor}}\\right)$$\n\nThe next stage is robust outlier suppression. This step identifies and flags data points likely corrupted by motion artifacts. For the full sequences of systolic ($S$) and diastolic ($D$) pressures, we compute their medians ($m_S, m_D$) and Median Absolute Deviations ($\\mathrm{MAD}_S, \\mathrm{MAD}_D$). A sample at time $t$ is marked as invalid if it is a statistical outlier in either blood pressure channel while activity is high. Formally, a sample is invalid if:\n$$\\left(\\left|S_t - m_S\\right| > k \\cdot \\mathrm{MAD}_S\\ \\text{ or }\\ \\left|D_t - m_D\\right| > k \\cdot \\mathrm{MAD}_D\\right) \\land (a_t > a_{\\mathrm{artifact}})$$\nAll other samples are considered valid.\n\nEpisode detection follows a specific hierarchy: we first check for a severe episode, and only if none is found do we proceed to check for a primary episode.\n\nTo detect a severe episode, we search for a sequence of $p=2$ consecutive time points $i \\in \\{t, \\dots, t+p-1\\}$ that simultaneously satisfy three conditions:\n$1$. The sample is valid (i.e., not a motion artifact).\n$2$. The patient is at rest: $a_i \\le a_{\\mathrm{rest}}$.\n$3$. The unadjusted blood pressure meets or exceeds the severe criteria: $S_i \\ge T_{s,\\mathrm{severe}}$ or $D_i \\ge T_{d,\\mathrm{severe}}$.\nIf such a sequence is found, the case is classified as a severe episode (code $2$) and the analysis for this case concludes.\n\nIf no severe episode is detected, we then search for a primary episode. This requires finding a sequence of $r=3$ consecutive time points $i \\in \\{t, \\dots, t+r-1\\}$ that satisfy three analogous conditions:\n$1$. The sample is valid.\n$2$. The patient is at rest: $a_i \\le a_{\\mathrm{rest}}$.\n$3$. The activity-adjusted blood pressure meets or exceeds the operative primary thresholds. The adjusted pressures are calculated as:\n$$S_{i,\\mathrm{adj}} = S_i - \\beta_s a_i$$\n$$D_{i,\\mathrm{adj}} = D_i - \\beta_d a_i$$\nThe condition is then $S_{i,\\mathrm{adj}} \\ge T_s$ or $D_{i,\\mathrm{adj}} \\ge T_d$.\nIf such a sequence is found, the case is classified as a primary episode (code $1$).\n\nIf neither a severe nor a primary episode is detected after checking all possible subsequences, the case is classified as normal (code $0$).\n\nThis comprehensive algorithm will be implemented to classify the provided test suite.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Implements the algorithm for detecting hypertensive episodes in pregnancy.\n    \"\"\"\n\n    # --- Algorithm Constants and Parameters ---\n    ALPHA = 0.01\n    T_S_FLOOR = 140\n    T_D_FLOOR = 90\n    T_S_SEVERE = 160\n    T_D_SEVERE = 110\n    BETA_S = 8\n    BETA_D = 5\n    K_MAD = 3\n    A_ARTIFACT = 0.5\n    A_REST = 0.3\n    R_PRIMARY = 3\n    P_SEVERE = 2\n\n    q_alpha = norm.ppf(1 - ALPHA)\n\n    # Trimester-specific normative parameters (mu_s, sigma_s, mu_d, sigma_d)\n    trimester_params = {\n        1: (118, 10, 76, 8),\n        2: (112, 9, 72, 7),\n        3: (116, 10, 74, 8),\n    }\n\n    # --- Test Suite ---\n    test_cases = [\n        # Case 1 (first trimester, high activity spikes, no episode expected)\n        (1,\n         np.array([126, 130, 142, 139, 145, 135, 128, 140]),\n         np.array([80, 82, 84, 83, 86, 79, 81, 85]),\n         np.array([0.6, 0.7, 0.8, 0.7, 0.9, 0.65, 0.7, 0.8])),\n\n        # Case 2 (second trimester, sustained diastolic elevation at rest, primary episode expected)\n        (2,\n         np.array([118, 120, 122, 119, 117, 115, 121, 120]),\n         np.array([92, 94, 95, 91, 89, 88, 87, 90]),\n         np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.1])),\n\n        # Case 3 (third trimester, severe systolic elevations at rest, severe episode expected)\n        (3,\n         np.array([165, 166, 164, 150, 148, 152]),\n         np.array([90, 92, 88, 85, 84, 86]),\n         np.array([0.05, 0.05, 0.05, 0.1, 0.1, 0.1])),\n\n        # Case 4 (second trimester, systolic near normative threshold but below clinical floor, no episode expected)\n        (2,\n         np.array([136, 136, 137, 132, 133, 135]),\n         np.array([80, 82, 81, 79, 80, 82]),\n         np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1])),\n\n        # Case 5 (first trimester, motion artifact outlier with high activity, no episode expected)\n        (1,\n         np.array([120, 122, 200, 121, 119, 118, 117, 116]),\n         np.array([75, 76, 90, 74, 73, 72, 71, 70]),\n         np.array([0.1, 0.1, 0.8, 0.1, 0.1, 0.1, 0.1, 0.1])),\n    ]\n\n    results = []\n\n    for case in test_cases:\n        trimester, s_data, d_data, a_data = case\n        num_samples = len(s_data)\n\n        # --- Step 1: Calculate Trimester-Specific Thresholds ---\n        mu_s, sigma_s, mu_d, sigma_d = trimester_params[trimester]\n        \n        t_s_norm = mu_s + sigma_s * q_alpha\n        t_d_norm = mu_d + sigma_d * q_alpha\n\n        t_s_primary = max(t_s_norm, T_S_FLOOR)\n        t_d_primary = max(t_d_norm, T_D_FLOOR)\n\n        # --- Step 2: Outlier Suppression (Validity Check) ---\n        m_s = np.median(s_data)\n        m_d = np.median(d_data)\n        \n        mad_s = np.median(np.abs(s_data - m_s))\n        mad_d = np.median(np.abs(d_data - m_d))\n        \n        is_valid = np.full(num_samples, True, dtype=bool)\n        for t in range(num_samples):\n            s_dev_check = mad_s > 0 and np.abs(s_data[t] - m_s) > K_MAD * mad_s\n            if mad_s == 0 and s_data[t] != m_s: s_dev_check = True\n\n            d_dev_check = mad_d > 0 and np.abs(d_data[t] - m_d) > K_MAD * mad_d\n            if mad_d == 0 and d_data[t] != m_d: d_dev_check = True\n\n            if (s_dev_check or d_dev_check) and a_data[t] > A_ARTIFACT:\n                is_valid[t] = False\n\n        # --- Step 3: Episode Detection ---\n        severe_detected = False\n        primary_detected = False\n\n        # Check for Severe Episode (Priority 1)\n        if num_samples >= P_SEVERE:\n            for t in range(num_samples - P_SEVERE + 1):\n                is_consecutive_match = True\n                for i in range(t, t + P_SEVERE):\n                    is_rest_gated = a_data[i] = A_REST\n                    bp_exceeded = s_data[i] >= T_S_SEVERE or d_data[i] >= T_D_SEVERE\n                    if not (is_valid[i] and is_rest_gated and bp_exceeded):\n                        is_consecutive_match = False\n                        break\n                if is_consecutive_match:\n                    severe_detected = True\n                    break\n        \n        # Check for Primary Episode (Priority 2)\n        if not severe_detected and num_samples >= R_PRIMARY:\n            for t in range(num_samples - R_PRIMARY + 1):\n                is_consecutive_match = True\n                for i in range(t, t + R_PRIMARY):\n                    s_adj = s_data[i] - BETA_S * a_data[i]\n                    d_adj = d_data[i] - BETA_D * a_data[i]\n                    is_rest_gated = a_data[i] = A_REST\n                    bp_exceeded = s_adj >= t_s_primary or d_adj >= t_d_primary\n                    if not (is_valid[i] and is_rest_gated and bp_exceeded):\n                        is_consecutive_match = False\n                        break\n                if is_consecutive_match:\n                    primary_detected = True\n                    break\n        \n        # --- Step 4: Classification ---\n        if severe_detected:\n            results.append(2)\n        elif primary_detected:\n            results.append(1)\n        else:\n            results.append(0)\n\n    # --- Final Output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4404625"}, {"introduction": "A model with high statistical accuracy, such as a high Area Under the Curve (AUC), is not always clinically useful. Its application in practice might lead to more harm than good through unnecessary interventions (overtreatment) or missed diagnoses (undertreatment). Decision Curve Analysis (DCA) and its core metric, Net Benefit, were developed to bridge this crucial gap between abstract statistical performance and concrete clinical utility.\n\nThis practice [@problem_id:4404542] challenges you to think like a decision analyst. You will derive the Net Benefit formula from the first principles of expected utility, directly linking it to the clinical trade-off between the benefit of a true positive and the harm of a false positive. You will then apply this formula to evaluate a hypothetical preeclampsia prediction model, quantifying its value across a range of clinical risk thresholds. This skill is essential for determining whether implementing a predictive model is likely to lead to better patient outcomes.", "problem": "A tertiary perinatal center is evaluating a probabilistic binary classifier that outputs an individualized predicted probability $\\hat{p}_i$ of developing preeclampsia for each pregnant patient $i$. A clinical decision rule is to initiate a preventive intervention if $\\hat{p}_i \\ge t$, where $t$ is a risk threshold chosen by the clinician based on the relative tolerance for overtreatment versus undertreatment. Using fundamental decision-analytic principles and empirical frequencies, you will derive the clinical net benefit as a function of $t$ and then compute its mean value across a clinically relevant range.\n\nFoundational base:\n- Expected utility under uncertainty, where the threshold probability $t$ encodes the trade-off between the benefit of treating a true case versus the harm of treating a non-case.\n- Empirical counts of true positives and false positives from observed outcomes under a threshold rule, and the interpretation of net benefit as net true positives per patient when the benefit is normalized to $1$.\n\nDerive, from first principles of expected utility and the definition of threshold probability, a formula for the clinical net benefit $NB(t)$ of the classifier when using the threshold rule $\\hat{p}_i \\ge t$ in terms of the empirical counts of true positives $TP(t)$ and false positives $FP(t)$ among $N$ patients.\n\nThen, using the following observed dataset of $N = 12$ singleton pregnancies with model-predicted risks and observed preeclampsia outcomes $y_i \\in \\{0,1\\}$, compute the mean clinical net benefit over the threshold interval $t \\in [0.05, 0.30]$:\n- Patient $1$: $\\hat{p}_1 = 0.04$, $y_1 = 0$\n- Patient $2$: $\\hat{p}_2 = 0.06$, $y_2 = 0$\n- Patient $3$: $\\hat{p}_3 = 0.08$, $y_3 = 1$\n- Patient $4$: $\\hat{p}_4 = 0.10$, $y_4 = 0$\n- Patient $5$: $\\hat{p}_5 = 0.12$, $y_5 = 0$\n- Patient $6$: $\\hat{p}_6 = 0.15$, $y_6 = 1$\n- Patient $7$: $\\hat{p}_7 = 0.18$, $y_7 = 0$\n- Patient $8$: $\\hat{p}_8 = 0.22$, $y_8 = 1$\n- Patient $9$: $\\hat{p}_9 = 0.25$, $y_9 = 0$\n- Patient $10$: $\\hat{p}_{10} = 0.27$, $y_{10} = 1$\n- Patient $11$: $\\hat{p}_{11} = 0.30$, $y_{11} = 0$\n- Patient $12$: $\\hat{p}_{12} = 0.40$, $y_{12} = 1$\n\nUse the convention that a patient is classified as positive if $\\hat{p}_i \\ge t$. Let $TP(t)$ and $FP(t)$ denote the number of true positives and false positives, respectively, at threshold $t$. Define the clinical net benefit $NB(t)$ as the expected net true positives per patient (benefit of a true positive set to $1$ and the harm of a false positive encoded by $t$).\n\nCompute the mean clinical net benefit over the interval,\n$$\n\\overline{NB} \\;=\\; \\frac{1}{0.30 - 0.05}\\int_{0.05}^{0.30} NB(t)\\, dt,\n$$\nusing the observed outcomes above. Round your final answer for $\\overline{NB}$ to $4$ significant figures. Express the final result in units of net true positives per patient.", "solution": "The problem asks for two components: first, a derivation of the clinical net benefit formula, $NB(t)$, from first principles; and second, the calculation of the mean net benefit, $\\overline{NB}$, over a specified interval of risk thresholds $t$ using a given dataset.\n\n**Part 1: Derivation of the Net Benefit Formula**\n\nThe derivation begins with the decision-analytic principle of maximizing expected utility. For an individual patient, a preventive intervention is recommended if the expected utility of intervening is greater than the expected utility of not intervening. Let $\\hat{p}$ be the model-predicted probability that the patient will develop preeclampsia (i.e., is a \"case\").\n\nLet $b$ be the net benefit of treating a patient who is truly a case (a true positive, TP). Let $c$ be the net harm (or cost) of treating a patient who is not a case (a false positive, FP). We can set the utility of not intervening to zero for both cases and non-cases, as this represents the baseline or default strategy.\n\nThe expected utility of intervention, $E[U(\\text{Intervene})]$, for a patient with risk $\\hat{p}$ is the probability of being a case multiplied by the benefit of a TP, minus the probability of not being a case multiplied by the harm of an FP:\n$$\nE[U(\\text{Intervene})] = \\hat{p} \\cdot b - (1-\\hat{p}) \\cdot c\n$$\nThe expected utility of not intervening is defined as the baseline, which is zero:\n$$\nE[U(\\text{No Intervene})] = 0\n$$\nA rational decision-maker would choose to intervene if $E[U(\\text{Intervene})]  E[U(\\text{No Intervene})]$, which implies:\n$$\n\\hat{p} \\cdot b - (1-\\hat{p}) \\cdot c  0\n$$\nThe risk threshold, $t$, is defined as the probability at which the decision-maker is indifferent between intervening and not intervening. This occurs when the expected utilities are equal:\n$$\nt \\cdot b - (1-t) \\cdot c = 0\n$$\nThis equation establishes the relationship between the benefit-harm trade-off and the threshold probability $t$:\n$$\nt \\cdot b = (1-t) \\cdot c \\implies \\frac{c}{b} = \\frac{t}{1-t}\n$$\nThe problem states that the benefit of a true positive is normalized to $1$, so we set $b=1$. Consequently, the harm of a false positive, in units of true positive benefit, is $c = \\frac{t}{1-t}$.\n\nThe total net benefit for a population of $N$ patients is the sum of benefits for all true positives minus the sum of harms for all false positives. Using a decision threshold $t$, the number of true positives is $TP(t)$ and the number of false positives is $FP(t)$. The total net benefit is:\n$$\n\\text{Total Net Benefit} = TP(t) \\cdot b - FP(t) \\cdot c\n$$\nThe clinical net benefit per patient, $NB(t)$, is the total net benefit divided by the total number of patients, $N$:\n$$\nNB(t) = \\frac{TP(t) \\cdot b - FP(t) \\cdot c}{N}\n$$\nSubstituting $b=1$ and $c = \\frac{t}{1-t}$, we arrive at the desired formula for clinical net benefit:\n$$\nNB(t) = \\frac{TP(t)}{N} - \\frac{FP(t)}{N} \\frac{t}{1-t}\n$$\nThis formula represents the net gain in true positives per patient, after accounting for the harm of false positives, when using the decision threshold $t$.\n\n**Part 2: Calculation of the Mean Net Benefit**\n\nWe are tasked with computing the mean clinical net benefit $\\overline{NB}$ over the interval $t \\in [0.05, 0.30]$, given by:\n$$\n\\overline{NB} = \\frac{1}{0.30 - 0.05} \\int_{0.05}^{0.30} NB(t) \\, dt = \\frac{1}{0.25} \\int_{0.05}^{0.30} \\left( \\frac{TP(t)}{12} - \\frac{FP(t)}{12} \\frac{t}{1-t} \\right) dt\n$$\nThe dataset consists of $N=12$ patients. The functions $TP(t)$ and $FP(t)$ are step functions that change values only at the predicted probabilities $\\hat{p}_i$. The relevant $\\hat{p}_i$ values in the integration interval $[0.05, 0.30]$ are $\\{0.06, 0.08, 0.10, 0.12, 0.15, 0.18, 0.22, 0.25, 0.27, 0.30\\}$. These values partition the integration interval into subintervals where $TP(t)$ and $FP(t)$ are constant.\n\nThe patient data is:\n$\\hat{p} = \\{0.04, 0.06, 0.08, 0.10, 0.12, 0.15, 0.18, 0.22, 0.25, 0.27, 0.30, 0.40\\}$\n$y = \\{0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1\\}$\n\nWe compute the values of $TP(t)$ and $FP(t)$ for each subinterval. A patient $i$ is classified as positive if $\\hat{p}_i \\ge t$.\n1.  For $t \\in (0.27, 0.30]$: Patients with $\\hat{p}_i \\in \\{0.30, 0.40\\}$ are positive. These are patients 11 ($y=0$) and 12 ($y=1$). Thus, $TP(t)=1$, $FP(t)=1$.\n2.  For $t \\in (0.25, 0.27]$: Patients with $\\hat{p}_i \\in \\{0.27, 0.30, 0.40\\}$ are positive. Patient 10 ($y=1$) is added. Thus, $TP(t)=2$, $FP(t)=1$.\n3.  For $t \\in (0.22, 0.25]$: Patient 9 ($y=0$) is added. $TP(t)=2$, $FP(t)=2$.\n4.  For $t \\in (0.18, 0.22]$: Patient 8 ($y=1$) is added. $TP(t)=3$, $FP(t)=2$.\n5.  For $t \\in (0.15, 0.18]$: Patient 7 ($y=0$) is added. $TP(t)=3$, $FP(t)=3$.\n6.  For $t \\in (0.12, 0.15]$: Patient 6 ($y=1$) is added. $TP(t)=4$, $FP(t)=3$.\n7.  For $t \\in (0.10, 0.12]$: Patient 5 ($y=0$) is added. $TP(t)=4$, $FP(t)=4$.\n8.  For $t \\in (0.08, 0.10]$: Patient 4 ($y=0$) is added. $TP(t)=4$, $FP(t)=5$.\n9.  For $t \\in (0.06, 0.08]$: Patient 3 ($y=1$) is added. $TP(t)=5$, $FP(t)=5$.\n10. For $t \\in [0.05, 0.06]$: Patient 2 ($y=0$) is added. $TP(t)=5$, $FP(t)=6$.\n\nThe total integral is the sum of integrals over these subintervals:\n$$\n\\int_{0.05}^{0.30} NB(t) \\, dt = \\frac{1}{12} \\sum_{k=1}^{10} \\int_{t_k}^{t_{k+1}} \\left( TP_k - FP_k \\frac{t}{1-t} \\right) dt\n$$\nThe antiderivative of the integrand is $\\int (A - B\\frac{t}{1-t}) dt = \\int (A + B - \\frac{B}{1-t}) dt = (A+B)t + B\\ln(1-t)$.\n\nLet's compute the value of the integral $\\int_{0.05}^{0.30} (TP(t) - FP(t) \\frac{t}{1-t}) dt$:\n1.  $\\int_{0.27}^{0.30} (1 - 1 \\frac{t}{1-t}) dt = [2t + \\ln(1-t)]_{0.27}^{0.30} = (0.60+\\ln(0.70))-(0.54+\\ln(0.73)) \\approx 0.01804$\n2.  $\\int_{0.25}^{0.27} (2 - 1 \\frac{t}{1-t}) dt = [3t + \\ln(1-t)]_{0.25}^{0.27} = (0.81+\\ln(0.73))-(0.75+\\ln(0.75)) \\approx 0.03297$\n3.  $\\int_{0.22}^{0.25} (2 - 2 \\frac{t}{1-t}) dt = [4t + 2\\ln(1-t)]_{0.22}^{0.25} = (1.00+2\\ln(0.75))-(0.88+2\\ln(0.78)) \\approx 0.04156$\n4.  $\\int_{0.18}^{0.22} (3 - 2 \\frac{t}{1-t}) dt = [5t + 2\\ln(1-t)]_{0.18}^{0.22} = (1.10+2\\ln(0.78))-(0.90+2\\ln(0.82)) \\approx 0.09998$\n5.  $\\int_{0.15}^{0.18} (3 - 3 \\frac{t}{1-t}) dt = [6t + 3\\ln(1-t)]_{0.15}^{0.18} = (1.08+3\\ln(0.82))-(0.90+3\\ln(0.85)) \\approx 0.07221$\n6.  $\\int_{0.12}^{0.15} (4 - 3 \\frac{t}{1-t}) dt = [7t + 3\\ln(1-t)]_{0.12}^{0.15} = (1.05+3\\ln(0.85))-(0.84+3\\ln(0.88)) \\approx 0.10593$\n7.  $\\int_{0.10}^{0.12} (4 - 4 \\frac{t}{1-t}) dt = [8t + 4\\ln(1-t)]_{0.10}^{0.12} = (0.96+4\\ln(0.88))-(0.80+4\\ln(0.90)) \\approx 0.07011$\n8.  $\\int_{0.08}^{0.10} (4 - 5 \\frac{t}{1-t}) dt = [9t + 5\\ln(1-t)]_{0.08}^{0.10} = (0.90+5\\ln(0.90))-(0.72+5\\ln(0.92)) \\approx 0.07010$\n9.  $\\int_{0.06}^{0.08} (5 - 5 \\frac{t}{1-t}) dt = [10t + 5\\ln(1-t)]_{0.06}^{0.08} = (0.80+5\\ln(0.92))-(0.60+5\\ln(0.94)) \\approx 0.09250$\n10. $\\int_{0.05}^{0.06} (5 - 6 \\frac{t}{1-t}) dt = [11t+6\\ln(1-t)]_{0.05}^{0.06} = (0.66+6\\ln(0.94))-(0.55+6\\ln(0.95)) \\approx 0.04646$\n\nSumming these values gives the total value of the numerator integral:\n$$\n\\text{Sum} \\approx 0.01804 + 0.03297 + 0.04156 + 0.09998 + 0.07221 + 0.10593 + 0.07011 + 0.07010 + 0.09250 + 0.04646 = 0.64986\n$$\nNow, we compute the integral of $NB(t)$:\n$$\n\\int_{0.05}^{0.30} NB(t) \\, dt = \\frac{1}{12} \\times 0.64986 \\approx 0.054155\n$$\nFinally, we compute the mean net benefit $\\overline{NB}$:\n$$\n\\overline{NB} = \\frac{1}{0.25} \\times 0.054155 \\approx 0.21662\n$$\nRounding to $4$ significant figures, the result is $0.2166$. This value represents the average net benefit, in units of true positives gained per patient, when the clinical decision threshold is varied across the clinically relevant range of $5\\%$ to $30\\%$ risk.", "answer": "$$\n\\boxed{0.2166}\n$$", "id": "4404542"}]}