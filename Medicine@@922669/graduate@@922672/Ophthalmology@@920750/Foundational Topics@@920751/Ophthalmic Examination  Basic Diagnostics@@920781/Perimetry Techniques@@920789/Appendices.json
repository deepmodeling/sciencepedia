{"hands_on_practices": [{"introduction": "The decibel ($dB$) is the fundamental unit of sensitivity in automated perimetry, yet its physical meaning can be opaque. This foundational exercise bridges the gap between the clinical measurement and the underlying physics of the stimulus [@problem_id:4710838]. By converting the instrument's reported decibel attenuation into physical luminance and calculating the corresponding Weber contrast, you will gain a first-principles understanding of what the perimeter is actually measuring.", "problem": "A Humphrey Field Analyzer (HFA) presents Goldmann size III stimuli for automated static perimetry on a uniform photopic background. Let the instrument’s maximum stimulus luminance be $L_{\\max}$ (in $\\mathrm{cd}\\,\\mathrm{m}^{-2}$), and let the background luminance be $B$ (in $\\mathrm{cd}\\,\\mathrm{m}^{-2}$). A patient’s threshold reading at a tested location is reported by the HFA as an attenuation of $x$ decibels ($\\mathrm{dB}$).\n\nStarting from first principles appropriate to photopic perimetry, use the following foundational definitions:\n- The base-$10$ decibel attenuation for luminance is defined by $x = 10 \\log_{10}\\!\\left(\\frac{L_{\\max}}{L_{\\mathrm{stim}}}\\right)$, where $L_{\\mathrm{stim}}$ is the physical stimulus luminance actually delivered at threshold.\n- Weber contrast is defined by $C = \\frac{L_{\\mathrm{stim}} - B}{B}$.\n\nAssume the Goldmann size III stimulus at the stated background operates in the Weber regime (i.e., outside complete spatial summation so that threshold is governed by a luminance increment rather than total energy). Derive a closed-form analytic expression for:\n1) The threshold stimulus luminance $L_{\\mathrm{stim}}$ in $\\mathrm{cd}\\,\\mathrm{m}^{-2}$ as a function of $x$ and $L_{\\max}$.\n2) The Weber contrast $C$ (dimensionless) required to reach threshold at background $B$.\n\nProvide your final answer as a single row matrix whose first entry is $L_{\\mathrm{stim}}$ (expressed in $\\mathrm{cd}\\,\\mathrm{m}^{-2}$) and whose second entry is $C$ (expressed as a decimal fraction). No numerical evaluation is required; give the expressions in closed form. No rounding is needed.", "solution": "The problem statement is deemed valid as it is scientifically grounded, well-posed, and objective. It is based on established principles and definitions from vision science and clinical ophthalmology, specifically concerning automated static perimetry. All necessary information for a derivation is provided, and the problem is free of contradictions, ambiguities, or factual errors.\n\nThe task is to derive expressions for the threshold stimulus luminance, $L_{\\mathrm{stim}}$, and the corresponding Weber contrast, $C$, based on the provided definitions.\n\n**Part 1: Derivation of Threshold Stimulus Luminance ($L_{\\mathrm{stim}}$)**\n\nWe begin with the definition of decibel ($dB$) attenuation provided for the Humphrey Field Analyzer (HFA):\n$$x = 10 \\log_{10}\\!\\left(\\frac{L_{\\max}}{L_{\\mathrm{stim}}}\\right)$$\nHere, $x$ is the attenuation in decibels, $L_{\\max}$ is the maximum stimulus luminance of the instrument, and $L_{\\mathrm{stim}}$ is the stimulus luminance presented at the patient's detection threshold. Our goal is to solve this equation for $L_{\\mathrm{stim}}$ as a function of $x$ and $L_{\\max}$.\n\nFirst, we isolate the logarithmic term by dividing both sides of the equation by $10$:\n$$\\frac{x}{10} = \\log_{10}\\!\\left(\\frac{L_{\\max}}{L_{\\mathrm{stim}}}\\right)$$\nTo eliminate the base-$10$ logarithm, we apply the inverse operation, which is exponentiation with a base of $10$. We raise $10$ to the power of each side of the equation:\n$$10^{\\frac{x}{10}} = 10^{\\log_{10}\\!\\left(\\frac{L_{\\max}}{L_{\\mathrm{stim}}}\\right)}$$\nBy the definition of a logarithm, $10^{\\log_{10}(y)} = y$. Applying this property to the right side of the equation yields:\n$$10^{\\frac{x}{10}} = \\frac{L_{\\max}}{L_{\\mathrm{stim}}}$$\nFinally, we solve for $L_{\\mathrm{stim}}$ by algebraic rearrangement:\n$$L_{\\mathrm{stim}} \\cdot 10^{\\frac{x}{10}} = L_{\\max}$$\n$$L_{\\mathrm{stim}} = \\frac{L_{\\max}}{10^{\\frac{x}{10}}}$$\nThis expression can be written using a negative exponent:\n$$L_{\\mathrm{stim}} = L_{\\max} 10^{-\\frac{x}{10}}$$\nThis is the closed-form analytic expression for the threshold stimulus luminance in $\\mathrm{cd}\\,\\mathrm{m}^{-2}$ as a function of the measured decibel attenuation $x$ and the instrument's maximum luminance $L_{\\max}$.\n\n**Part 2: Derivation of Weber Contrast ($C$)**\n\nNext, we derive the expression for the Weber contrast, $C$. The problem provides the definition of Weber contrast for a light-on-light increment threshold:\n$$C = \\frac{L_{\\mathrm{stim}} - B}{B}$$\nwhere $L_{\\mathrm{stim}}$ is the luminance of the stimulus at threshold and $B$ is the uniform background luminance. The problem states this is an appropriate model for the Goldmann III stimulus under photopic conditions (the Weber regime).\n\nTo express $C$ in terms of the initial given variables ($x$, $L_{\\max}$, and $B$), we substitute the expression for $L_{\\mathrm{stim}}$ derived in Part 1 into the equation for $C$:\n$$C = \\frac{(L_{\\max} 10^{-\\frac{x}{10}}) - B}{B}$$\nThis is the closed-form analytic expression for the dimensionless Weber contrast required to reach threshold. This expression can also be written as:\n$$C = \\frac{L_{\\max} 10^{-\\frac{x}{10}}}{B} - 1$$\nHowever, the single-fraction form is more compact.\n\nThe two requested expressions are:\n1) $L_{\\mathrm{stim}} = L_{\\max} 10^{-\\frac{x}{10}}$\n2) $C = \\frac{L_{\\max} 10^{-\\frac{x}{10}} - B}{B}$\n\nThe final answer should be presented as a single row matrix containing these two expressions.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nL_{\\max} 10^{-\\frac{x}{10}} & \\frac{L_{\\max} 10^{-\\frac{x}{10}} - B}{B}\n\\end{pmatrix}\n}\n$$", "id": "4710838"}, {"introduction": "A visual field test yields dozens of individual threshold estimates, but clinicians often rely on global indices like the Mean Deviation ($MD$) to summarize the overall field status. This practice demonstrates the statistically robust method for calculating the $MD$ from individual measurements that have varying precision [@problem_id:4710800]. By applying the principle of inverse-variance weighting, you will learn how to derive the most accurate estimate of overall visual field depression and, crucially, how to quantify the confidence in that estimate.", "problem": "A patient undergoes threshold automated perimetry on a $24$-$2$ grid using the Swedish Interactive Thresholding Algorithm. For each of $12$ non–blind spot test locations deemed reliable (fixation losses and false responses within acceptable limits), the instrument reports the age-corrected total deviation values in decibels (dB) and the corresponding standard errors in decibels. Assume the following physically and clinically realistic conditions: (i) total deviation at location $i$ is modeled as an observation of a single underlying mean deviation (MD) $\\mu$ plus zero-mean random error, (ii) errors are independent across locations, (iii) for each location $i$, the measurement error is approximately Gaussian with variance equal to the square of the reported standard error. The observed data are:\n- Location $1$: total deviation $-3.1$ dB, standard error $1.1$ dB.\n- Location $2$: total deviation $-2.7$ dB, standard error $0.9$ dB.\n- Location $3$: total deviation $-5.4$ dB, standard error $1.3$ dB.\n- Location $4$: total deviation $-1.8$ dB, standard error $1.0$ dB.\n- Location $5$: total deviation $-4.0$ dB, standard error $1.2$ dB.\n- Location $6$: total deviation $-3.6$ dB, standard error $1.1$ dB.\n- Location $7$: total deviation $-2.1$ dB, standard error $0.8$ dB.\n- Location $8$: total deviation $-6.3$ dB, standard error $1.5$ dB.\n- Location $9$: total deviation $-3.8$ dB, standard error $1.0$ dB.\n- Location $10$: total deviation $-4.5$ dB, standard error $1.3$ dB.\n- Location $11$: total deviation $-2.9$ dB, standard error $0.9$ dB.\n- Location $12$: total deviation $-3.2$ dB, standard error $1.1$ dB.\n\nStarting from appropriate statistical principles for combining independent Gaussian observations with unequal variances, determine the mean deviation (MD) using weights that reflect the reported standard errors, and derive a $95\\%$ confidence interval for the MD under the model assumptions. Use a normal critical value for the confidence interval construction. Round your final numerical results to three significant figures. Express the MD and the confidence interval bounds in decibels (dB).", "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. It presents a standard problem in statistical estimation applied to a realistic scenario in ophthalmic perimetry.\n\nThe task is to determine the best estimate for a single underlying mean deviation (MD), denoted by the parameter $\\mu$, from a series of $N=12$ independent measurements, and to construct a $95\\%$ confidence interval for this estimate. Each measurement $i$ consists of an observed total deviation, $y_i$, and a corresponding standard error, $\\sigma_i$.\n\nAccording to the problem's assumptions, each observation $y_i$ is drawn from a Gaussian distribution with mean $\\mu$ and a variance $\\sigma_i^2$ specific to that location:\n$$y_i \\sim \\mathcal{N}(\\mu, \\sigma_i^2)$$\nThe observations are independent. The goal is to find the optimal estimate of $\\mu$ and its confidence interval.\n\nFirst, we determine the point estimate for the mean deviation, $\\hat{\\mu}$. The most appropriate method for combining independent measurements with unequal but known variances is to use a weighted average, where each measurement is weighted by the inverse of its variance. This method can be derived from the principle of maximum likelihood estimation (MLE) or, equivalently, the method of weighted least squares. It yields the best linear unbiased estimator (BLUE).\n\nThe weight for each observation $y_i$ is defined as $w_i = 1/\\sigma_i^2$. The estimator $\\hat{\\mu}$ for the mean deviation is then given by the formula:\n$$\\hat{\\mu} = \\frac{\\sum_{i=1}^{N} w_i y_i}{\\sum_{i=1}^{N} w_i}$$\n\nThe provided data are:\n1. $y_1 = -3.1$, $\\sigma_1 = 1.1 \\implies w_1 = 1/1.1^2 = 1/1.21 \\approx 0.8264$\n2. $y_2 = -2.7$, $\\sigma_2 = 0.9 \\implies w_2 = 1/0.9^2 = 1/0.81 \\approx 1.2346$\n3. $y_3 = -5.4$, $\\sigma_3 = 1.3 \\implies w_3 = 1/1.3^2 = 1/1.69 \\approx 0.5917$\n4. $y_4 = -1.8$, $\\sigma_4 = 1.0 \\implies w_4 = 1/1.0^2 = 1/1.00 = 1.0000$\n5. $y_5 = -4.0$, $\\sigma_5 = 1.2 \\implies w_5 = 1/1.2^2 = 1/1.44 \\approx 0.6944$\n6. $y_6 = -3.6$, $\\sigma_6 = 1.1 \\implies w_6 = 1/1.1^2 = 1/1.21 \\approx 0.8264$\n7. $y_7 = -2.1$, $\\sigma_7 = 0.8 \\implies w_7 = 1/0.8^2 = 1/0.64 = 1.5625$\n8. $y_8 = -6.3$, $\\sigma_8 = 1.5 \\implies w_8 = 1/1.5^2 = 1/2.25 \\approx 0.4444$\n9. $y_9 = -3.8$, $\\sigma_9 = 1.0 \\implies w_9 = 1/1.0^2 = 1/1.00 = 1.0000$\n10. $y_{10} = -4.5$, $\\sigma_{10} = 1.3 \\implies w_{10} = 1/1.3^2 = 1/1.69 \\approx 0.5917$\n11. $y_{11} = -2.9$, $\\sigma_{11} = 0.9 \\implies w_{11} = 1/0.9^2 = 1/0.81 \\approx 1.2346$\n12. $y_{12} = -3.2$, $\\sigma_{12} = 1.1 \\implies w_{12} = 1/1.1^2 = 1/1.21 \\approx 0.8264$\n\nWe compute the sum of the weights, $\\sum_{i=1}^{12} w_i$:\n$$\\sum_{i=1}^{12} w_i = \\frac{1}{1.21} + \\frac{1}{0.81} + \\frac{1}{1.69} + \\frac{1}{1.00} + \\frac{1}{1.44} + \\frac{1}{1.21} + \\frac{1}{0.64} + \\frac{1}{2.25} + \\frac{1}{1.00} + \\frac{1}{1.69} + \\frac{1}{0.81} + \\frac{1}{1.21}$$\n$$\\sum_{i=1}^{12} w_i \\approx 0.82645 + 1.23457 + 0.59172 + 1.00000 + 0.69444 + 0.82645 + 1.56250 + 0.44444 + 1.00000 + 0.59172 + 1.23457 + 0.82645 \\approx 10.8333$$\nNext, we compute the sum of the weighted observations, $\\sum_{i=1}^{12} w_i y_i$:\n$$\\sum_{i=1}^{12} w_i y_i = \\frac{-3.1}{1.21} + \\frac{-2.7}{0.81} + \\frac{-5.4}{1.69} + \\frac{-1.8}{1.00} + \\frac{-4.0}{1.44} + \\frac{-3.6}{1.21} + \\frac{-2.1}{0.64} + \\frac{-6.3}{2.25} + \\frac{-3.8}{1.00} + \\frac{-4.5}{1.69} + \\frac{-2.9}{0.81} + \\frac{-3.2}{1.21}$$\n$$\\sum_{i=1}^{12} w_i y_i \\approx -2.56198 - 3.33333 - 3.19527 - 1.80000 - 2.77778 - 2.97521 - 3.28125 - 2.80000 - 3.80000 - 2.66272 - 3.58025 - 2.64463 \\approx -35.4124$$\nThe estimate for the MD is:\n$$\\hat{\\mu} = \\frac{-35.4124}{10.8333} \\approx -3.2689 \\text{ dB}$$\n\nNext, we derive the $95\\%$ confidence interval for $\\mu$. Since $\\hat{\\mu}$ is a linear combination of independent Gaussian variables, it is also a Gaussian-distributed random variable. The variance of $\\hat{\\mu}$ is:\n$$\\text{Var}(\\hat{\\mu}) = \\text{Var}\\left(\\frac{\\sum w_i y_i}{\\sum w_i}\\right) = \\frac{1}{(\\sum w_i)^2} \\sum \\text{Var}(w_i y_i) = \\frac{1}{(\\sum w_i)^2} \\sum w_i^2 \\text{Var}(y_i)$$\nSince $\\text{Var}(y_i) = \\sigma_i^2 = 1/w_i$:\n$$\\text{Var}(\\hat{\\mu}) = \\frac{1}{(\\sum w_i)^2} \\sum w_i^2 \\left(\\frac{1}{w_i}\\right) = \\frac{\\sum w_i}{(\\sum w_i)^2} = \\frac{1}{\\sum w_i}$$\nThe standard error of the estimate $\\hat{\\mu}$ is therefore:\n$$\\text{SE}(\\hat{\\mu}) = \\sigma_{\\hat{\\mu}} = \\sqrt{\\frac{1}{\\sum w_i}}$$\nUsing our calculated sum of weights:\n$$\\sigma_{\\hat{\\mu}} = \\sqrt{\\frac{1}{10.8333}} \\approx \\sqrt{0.092308} \\approx 0.30382 \\text{ dB}$$\nA $95\\%$ confidence interval for $\\mu$ is constructed as $\\hat{\\mu} \\pm z_{\\alpha/2} \\sigma_{\\hat{\\mu}}$, where $\\alpha = 0.05$. The critical value from the standard normal distribution is $z_{0.025} = 1.96$.\nThe margin of error (ME) is:\n$$\\text{ME} = 1.96 \\times 0.30382 \\approx 0.59549$$\nThe confidence interval bounds are:\nLower Bound = $\\hat{\\mu} - \\text{ME} = -3.2689 - 0.59549 = -3.86439 \\text{ dB}$\nUpper Bound = $\\hat{\\mu} + \\text{ME} = -3.2689 + 0.59549 = -2.67341 \\text{ dB}$\n\nThe problem requires the final numerical results to be rounded to three significant figures.\nThe estimated Mean Deviation (MD), $\\hat{\\mu}$, is $-3.27$ dB.\nThe lower bound of the $95\\%$ confidence interval is $-3.86$ dB.\nThe upper bound of the $95\\%$ confidence interval is $-2.67$ dB.\n\nThe final answer consists of the estimated MD, the lower confidence bound, and the upper confidence bound.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-3.27 & -3.86 & -2.67\n\\end{pmatrix}\n}\n$$", "id": "4710800"}, {"introduction": "A key clinical observation in perimetry is that test-retest variability is not constant; it increases significantly in areas of glaucomatous damage. This advanced exercise explores the theoretical basis for this phenomenon by modeling the underlying frequency-of-seeing curve [@problem_id:4710790]. Using core concepts from psychophysics and estimation theory, you will derive how the steepness of the psychometric function dictates measurement precision, providing a rigorous explanation for why sensitivity and variability are intrinsically linked.", "problem": "In standard automated perimetry, a visual field location with baseline sensitivity $S$ (in dB) is probed by a yes-no detection task using brief light stimuli whose presentation level $d$ (in dB) is adaptively centered near the location’s threshold. Let the frequency-of-seeing function (psychometric function) be modeled as a logistic with a sensitivity-dependent slope:\n$$\np(\\text{detect}\\mid d,S) \\;=\\; \\gamma \\;+\\; \\frac{1-\\gamma-\\lambda}{1+\\exp\\!\\big(-k(S)\\,[\\,d - t(S)\\,]\\big)} \\, ,\n$$\nwhere $\\gamma$ is the guess rate, $\\lambda$ is the lapse rate, $t(S)$ is the threshold (equal to baseline sensitivity in dB, so $t(S)=S$), and $k(S)$ is the local slope (in per-decibel units) at threshold. In a yes-no paradigm, assume $\\gamma=0$ and a small lapse rate $\\lambda>0$. Consider $n$ independent presentations delivered sufficiently close to $d=t(S)$ so that the Maximum Likelihood Estimator (MLE) of $t(S)$ is asymptotically efficient with variance governed by the per-trial Fisher information at $d=t(S)$.\n\nAssume an empirically motivated, first-order linear model of slope versus baseline sensitivity over the range of interest:\n$$\nk(S) \\;=\\; k_{0} \\;+\\; \\alpha\\,S \\, ,\n$$\nwith $k_{0}=0.06 \\text{ dB}^{-1}$ and $\\alpha=0.02 \\text{ dB}^{-2}$. Take $\\lambda=0.03$ and $n=6$ as representative of a short near-threshold sampling phase; all other aspects are as stated above.\n\nUsing only fundamental definitions of the logistic psychometric function, Bernoulli likelihood for yes-no responses, and the Fisher information with the Cramér–Rao Lower Bound, derive an expression for the expected standard deviation of the threshold estimate $\\sigma(S)$ in terms of $k(S)$ and the task parameters. Then, compute the ratio\n$$\nR \\;=\\; \\frac{\\sigma(S=10\\ \\text{dB})}{\\sigma(S=28\\ \\text{dB})} \\, .\n$$\nProvide your final result for $R$ as a dimensionless decimal, rounded to four significant figures.", "solution": "The problem requires the derivation of an expression for the standard deviation of a threshold estimate, $\\sigma(S)$, and the computation of a ratio of this standard deviation at two different baseline sensitivities, $S$.\n\nFirst, a validation of the problem statement is performed.\nThe givens are:\n1.  The frequency-of-seeing (psychometric) function:\n    $$p(\\text{detect}\\mid d,S) = \\gamma + \\frac{1-\\gamma-\\lambda}{1+\\exp(-k(S)[d - t(S)])}$$\n2.  The threshold function: $t(S) = S$.\n3.  The guess rate: $\\gamma = 0$.\n4.  The lapse rate: $\\lambda = 0.03$.\n5.  Number of independent trials: $n=6$.\n6.  The slope function: $k(S) = k_{0} + \\alpha S$.\n7.  Slope parameters: $k_0 = 0.06 \\text{ dB}^{-1}$, $\\alpha = 0.02 \\text{ dB}^{-2}$.\n8.  Stimulus presentation level: $d$ is near $t(S)$. We are to evaluate quantities at $d=t(S)=S$.\n9.  The Maximum Likelihood Estimator (MLE) of $t(S)$ is asymptotically efficient.\n\nThe problem is scientifically grounded in the theory of psychophysics and statistical estimation, using standard models (logistic function) and principles (Fisher information, Cramér–Rao Lower Bound). It is well-posed, with all necessary information provided for a unique solution. The language is objective and precise. Therefore, the problem is deemed valid.\n\nThe solution proceeds as follows. The response to each stimulus presentation is a Bernoulli random variable $Y$, where $Y=1$ for detection and $Y=0$ for non-detection. The probability of detection, $P$, is given by the psychometric function. Substituting $\\gamma=0$ and $t(S)=S$ into the given function, we have:\n$$P(d, S) = \\frac{1-\\lambda}{1+\\exp(-k(S)[d-S])}$$\nThe problem states that the MLE for the threshold $S$ is asymptotically efficient. This implies that the variance of the estimate $\\hat{S}$ achieves the Cramér–Rao Lower Bound (CRLB). The CRLB is the reciprocal of the Fisher information, $I(S)$. The standard deviation of the estimate, $\\sigma(S)$, is the square root of the variance:\n$$\\sigma(S) = \\sqrt{\\text{Var}(\\hat{S})} = \\sqrt{\\frac{1}{I(S)}} = \\frac{1}{\\sqrt{I(S)}}$$\nFor $n$ independent trials, the total Fisher information $I(S)$ is $n$ times the Fisher information for a single trial, $I_1(S)$:\n$$I(S) = n \\cdot I_1(S)$$\nThe per-trial Fisher information for a Bernoulli process with parameter $S$ is given by:\n$$I_1(S) = \\frac{1}{P(1-P)} \\left( \\frac{\\partial P}{\\partial S} \\right)^2$$\nWe must evaluate this expression at the presentation level specified, $d=S$.\n\nFirst, we evaluate $P(d,S)$ at $d=S$:\n$$P\\vert_{d=S} = \\frac{1-\\lambda}{1+\\exp(-k(S)[S-S])} = \\frac{1-\\lambda}{1+\\exp(0)} = \\frac{1-\\lambda}{2}$$\nFrom this, we find the product $P(1-P)$ at $d=S$:\n$$P(1-P)\\vert_{d=S} = \\left(\\frac{1-\\lambda}{2}\\right) \\left(1 - \\frac{1-\\lambda}{2}\\right) = \\left(\\frac{1-\\lambda}{2}\\right) \\left(\\frac{1+\\lambda}{2}\\right) = \\frac{1-\\lambda^2}{4}$$\nNext, we calculate the partial derivative of $P(d,S)$ with respect to $S$. Let $u(S) = -k(S)[d-S] = k(S)[S-d]$.\n$$P(d,S) = (1-\\lambda)(1+\\exp(u(S)))^{-1}$$\nUsing the chain rule:\n$$\\frac{\\partial P}{\\partial S} = -(1-\\lambda)(1+\\exp(u))^{-2} \\exp(u) \\frac{\\partial u}{\\partial S}$$\nThe derivative of $u(S)$ with respect to $S$ is:\n$$\\frac{\\partial u}{\\partial S} = \\frac{\\partial}{\\partial S}(k(S)[S-d]) = \\frac{dk}{dS}(S-d) + k(S)(1) = k'(S)(S-d) + k(S)$$\nWe evaluate this derivative at $d=S$:\n$$\\left.\\frac{\\partial u}{\\partial S}\\right|_{d=S} = k'(S)(S-S) + k(S) = k(S)$$\nAt $d=S$, we also have $u=0$, so $\\exp(u)=1$. Substituting these into the expression for $\\frac{\\partial P}{\\partial S}$:\n$$\\left.\\frac{\\partial P}{\\partial S}\\right|_{d=S} = -(1-\\lambda)(1+\\exp(0))^{-2} \\exp(0) \\cdot k(S) = -(1-\\lambda)(1+1)^{-2}(1) \\cdot k(S) = -\\frac{(1-\\lambda)k(S)}{4}$$\nNow we can compute the per-trial Fisher information $I_1(S)$ at $d=S$:\n$$I_1(S) = \\frac{\\left( -\\frac{(1-\\lambda)k(S)}{4} \\right)^2}{\\frac{1-\\lambda^2}{4}} = \\frac{\\frac{(1-\\lambda)^2 k(S)^2}{16}}{\\frac{(1-\\lambda)(1+\\lambda)}{4}} = \\frac{4(1-\\lambda)^2 k(S)^2}{16(1-\\lambda)(1+\\lambda)} = \\frac{(1-\\lambda)k(S)^2}{4(1+\\lambda)}$$\nThe total Fisher information for $n$ trials is:\n$$I(S) = n I_1(S) = \\frac{n(1-\\lambda)k(S)^2}{4(1+\\lambda)}$$\nThe standard deviation of the threshold estimate, $\\sigma(S)$, is then:\n$$\\sigma(S) = \\frac{1}{\\sqrt{I(S)}} = \\sqrt{\\frac{4(1+\\lambda)}{n(1-\\lambda)k(S)^2}} = \\frac{2}{k(S)} \\sqrt{\\frac{1+\\lambda}{n(1-\\lambda)}}$$\nThis is the derived expression for the expected standard deviation of the threshold estimate.\n\nThe problem asks for the ratio $R = \\sigma(S=10\\ \\text{dB}) / \\sigma(S=28\\ \\text{dB})$.\n$$R = \\frac{\\sigma(10)}{\\sigma(28)} = \\frac{\\frac{2}{k(10)} \\sqrt{\\frac{1+\\lambda}{n(1-\\lambda)}}}{\\frac{2}{k(28)} \\sqrt{\\frac{1+\\lambda}{n(1-\\lambda)}}} = \\frac{k(28)}{k(10)}$$\nThe ratio depends only on the slope values $k(S)$ at the two sensitivities. The values of $n$ and $\\lambda$ are not needed for the final ratio.\n\nWe use the given linear model for the slope $k(S) = k_0 + \\alpha S$, with $k_0=0.06 \\text{ dB}^{-1}$ and $\\alpha=0.02 \\text{ dB}^{-2}$.\nFor $S=10\\ \\text{dB}$:\n$$k(10) = 0.06 + 0.02 \\times 10 = 0.06 + 0.20 = 0.26$$\nFor $S=28\\ \\text{dB}$:\n$$k(28) = 0.06 + 0.02 \\times 28 = 0.06 + 0.56 = 0.62$$\nNow, we compute the ratio $R$:\n$$R = \\frac{k(28)}{k(10)} = \\frac{0.62}{0.26} = \\frac{62}{26} = \\frac{31}{13} \\approx 2.38461538...$$\nRounding the result to four significant figures, we get $R = 2.385$.", "answer": "$$\\boxed{2.385}$$", "id": "4710790"}]}