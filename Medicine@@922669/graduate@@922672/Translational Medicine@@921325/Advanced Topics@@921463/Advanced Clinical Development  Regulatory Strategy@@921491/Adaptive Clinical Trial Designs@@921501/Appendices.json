{"hands_on_practices": [{"introduction": "Group sequential designs represent a foundational type of adaptive trial, where data are analyzed at pre-planned intervals. This structure allows a trial to be stopped early if the accumulating evidence demonstrates overwhelming efficacy or futility, saving time and resources. This exercise [@problem_id:4519357] provides direct practice in the fundamental mechanics of such an interim analysis, challenging you to calculate a test statistic from interim data and apply a pre-specified stopping rule. Mastering this process is a crucial first step in understanding how evidence is formally assessed and acted upon during a clinical trial.", "problem": "A parallel two-arm superiority trial in clinical pharmacology evaluates the mean change in systolic blood pressure reduction from baseline at week $8$ for a new antihypertensive versus matched placebo. Let the arm-specific outcomes be modeled as independent and identically distributed normal random variables with common known variance $\\sigma^{2}$, and let the treatment effect be the difference in population means $\\delta = \\mu_{\\mathrm{T}} - \\mu_{\\mathrm{C}}$, where larger positive values of $\\delta$ indicate greater mean reduction in systolic blood pressure for the antihypertensive relative to placebo. The null hypothesis is $H_{0}: \\delta \\leq 0$ versus the one-sided alternative $H_{1}: \\delta > 0$.\n\nThe trial uses a pre-specified group sequential design with an efficacy boundary governed by a one-sided Type I error rate $\\alpha = 0.025$ controlled via a Lan-DeMets O’Brien-Fleming spending function, with two looks: an interim analysis and the final analysis. The planned sample sizes are $N_{\\mathrm{T}} = 400$ and $N_{\\mathrm{C}} = 400$. The common variance is $\\sigma^{2} = 36$ $\\mathrm{mmHg}^{2}$, based on prior phase II data.\n\nAt the interim analysis, the sample sizes are $n_{\\mathrm{T}} = 120$ and $n_{\\mathrm{C}} = 120$, and the observed sample mean reductions are $\\bar{Y}_{\\mathrm{T}} = 11.8$ $\\mathrm{mmHg}$ and $\\bar{Y}_{\\mathrm{C}} = 9.4$ $\\mathrm{mmHg}$. The pre-specified interim efficacy boundary (on the standardized $Z$-scale) is $c_{1} = 2.963$, corresponding to an information fraction $t_{1}$ derived from the design.\n\nUsing only first principles and standard large-sample normal theory for the difference of means with known variance, derive the appropriate $Z$-statistic for testing $H_{0}$ at the interim look, compute its observed value $Z_{1}$ from the given data, and decide whether to stop for efficacy or continue to the next look by comparing $Z_{1}$ to $c_{1}$. Report the computed value of $Z_{1}$ as your final answer. Round your final numeric answer to four significant figures. Express the final answer as a dimensionless number. No textual decision statement is required in the final numeric answer, but your reasoning must include the decision.", "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- **Trial Design**: Parallel two-arm superiority clinical trial.\n- **Endpoint**: Mean change in systolic blood pressure reduction from baseline at week $8$.\n- **Arms**: Treatment (T) and Placebo/Control (C).\n- **Outcome Model**: Arm-specific outcomes are independent and identically distributed normal random variables.\n- **Population Variance**: Common known variance, $\\sigma^{2} = 36$ $\\mathrm{mmHg}^{2}$.\n- **Treatment Effect**: Difference in population means, $\\delta = \\mu_{\\mathrm{T}} - \\mu_{\\mathrm{C}}$.\n- **Hypotheses**: Null hypothesis $H_{0}: \\delta \\leq 0$; Alternative hypothesis $H_{1}: \\delta > 0$.\n- **Design Type**: Pre-specified group sequential design with two looks.\n- **Error Control**: One-sided Type I error rate $\\alpha = 0.025$, controlled by a Lan-DeMets O’Brien-Fleming spending function.\n- **Planned Total Sample Sizes**: $N_{\\mathrm{T}} = 400$, $N_{\\mathrm{C}} = 400$.\n- **Interim Analysis Data (Look 1)**:\n  - Sample sizes: $n_{\\mathrm{T}} = 120$, $n_{\\mathrm{C}} = 120$.\n  - Observed sample mean reductions: $\\bar{Y}_{\\mathrm{T}} = 11.8$ $\\mathrm{mmHg}$, $\\bar{Y}_{\\mathrm{C}} = 9.4$ $\\mathrm{mmHg}$.\n- **Efficacy Boundary**: Pre-specified interim efficacy boundary on the standardized $Z$-scale is $c_{1} = 2.963$.\n- **Task**: Derive and compute the $Z$-statistic at the interim look, $Z_{1}$, and compare it to $c_{1}$ to make a decision. Report the numerical value of $Z_{1}$ rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is located squarely within the established field of biostatistics, specifically the design and analysis of clinical trials. The use of a normal distribution for a physiological endpoint, a Z-test for the difference of means with known variance, and a group sequential design with an O'Brien-Fleming boundary are all standard, scientifically sound methodologies.\n- **Well-Posed**: The problem is well-posed. It asks for a specific calculation ($Z_{1}$) for which all necessary data ($\\bar{Y}_{\\mathrm{T}}$, $\\bar{Y}_{\\mathrm{C}}$, $n_{\\mathrm{T}}$, $n_{\\mathrm{C}}$, $\\sigma^{2}$) are provided. A unique, meaningful solution exists.\n- **Objective**: The problem is stated in precise, objective, and quantitative language, free of any subjective or ambiguous terms.\n- **Completeness and Consistency**: The problem is self-contained and internally consistent. The information provided is sufficient to calculate the requested statistic. Contextual information like the total planned sample size ($N_{\\mathrm{T}}$, $N_{\\mathrm{C}}$) and the spending function type are relevant for understanding the design but are not required for the specific calculation of $Z_{1}$, as the critical value $c_1$ is given directly. This does not constitute a flaw.\n- **Realism**: The values for sample size, variance ($\\sigma = \\sqrt{36} = 6$ $\\mathrm{mmHg}$), and observed effects are realistic for an antihypertensive drug trial.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. All criteria for a sound scientific problem are met. A solution will be derived.\n\nThe task is to compute the standardized test statistic, $Z_{1}$, at the first interim analysis and compare it to the critical value $c_{1}$. The hypotheses to be tested are $H_{0}: \\delta \\leq 0$ versus $H_{1}: \\delta > 0$, where $\\delta = \\mu_{\\mathrm{T}} - \\mu_{\\mathrm{C}}$. The test is performed at the boundary of the null space, i.e., assuming $\\delta = 0$.\n\nThe general form of the $Z$-statistic for a two-sample test of means with known variance is:\n$$ Z = \\frac{(\\text{Point Estimate of } \\delta) - (\\text{Hypothesized value of } \\delta)}{\\text{Standard Error of the Point Estimate}} $$\n\nAt the interim analysis (look $1$), the point estimate for the treatment effect $\\delta$ is the difference in the observed sample means:\n$$ \\hat{\\delta}_{1} = \\bar{Y}_{\\mathrm{T}} - \\bar{Y}_{\\mathrm{C}} $$\nThe hypothesized value of $\\delta$ under the null hypothesis is $\\delta_{0} = 0$.\n\nThe standard error of the point estimate, $\\mathrm{SE}(\\hat{\\delta}_{1})$, is based on the variances of the sample means. The variance of a sample mean $\\bar{Y}$ from a population with known variance $\\sigma^{2}$ and sample size $n$ is $\\mathrm{Var}(\\bar{Y}) = \\frac{\\sigma^{2}}{n}$. Since the two arms are independent, the variance of the difference of their sample means is the sum of their individual variances:\n$$ \\mathrm{Var}(\\hat{\\delta}_{1}) = \\mathrm{Var}(\\bar{Y}_{\\mathrm{T}} - \\bar{Y}_{\\mathrm{C}}) = \\mathrm{Var}(\\bar{Y}_{\\mathrm{T}}) + \\mathrm{Var}(\\bar{Y}_{\\mathrm{C}}) $$\nAt the interim analysis, with sample sizes $n_{\\mathrm{T}}$ and $n_{\\mathrm{C}}$, this becomes:\n$$ \\mathrm{Var}(\\hat{\\delta}_{1}) = \\frac{\\sigma^{2}}{n_{\\mathrm{T}}} + \\frac{\\sigma^{2}}{n_{\\mathrm{C}}} $$\nThe standard error is the square root of the variance:\n$$ \\mathrm{SE}(\\hat{\\delta}_{1}) = \\sqrt{\\frac{\\sigma^{2}}{n_{\\mathrm{T}}} + \\frac{\\sigma^{2}}{n_{\\mathrm{C}}}} $$\nThe test statistic at the interim look, $Z_{1}$, is therefore:\n$$ Z_{1} = \\frac{(\\bar{Y}_{\\mathrm{T}} - \\bar{Y}_{\\mathrm{C}}) - 0}{\\sqrt{\\frac{\\sigma^{2}}{n_{\\mathrm{T}}} + \\frac{\\sigma^{2}}{n_{\\mathrm{C}}}}} = \\frac{\\bar{Y}_{\\mathrm{T}} - \\bar{Y}_{\\mathrm{C}}}{\\sigma \\sqrt{\\frac{1}{n_{\\mathrm{T}}} + \\frac{1}{n_{\\mathrm{C}}}}} $$\nNow, we substitute the provided numerical values into this formula.\nGiven:\n- $\\bar{Y}_{\\mathrm{T}} = 11.8$\n- $\\bar{Y}_{\\mathrm{C}} = 9.4$\n- $\\sigma^{2} = 36$, which implies $\\sigma = \\sqrt{36} = 6$.\n- $n_{\\mathrm{T}} = 120$\n- $n_{\\mathrm{C}} = 120$\n\nFirst, compute the numerator (the observed effect size):\n$$ \\hat{\\delta}_{1} = \\bar{Y}_{\\mathrm{T}} - \\bar{Y}_{\\mathrm{C}} = 11.8 - 9.4 = 2.4 $$\nNext, compute the standard error of the estimate:\n$$ \\mathrm{SE}(\\hat{\\delta}_{1}) = \\sqrt{\\frac{36}{120} + \\frac{36}{120}} = \\sqrt{\\frac{72}{120}} = \\sqrt{\\frac{6 \\times 12}{10 \\times 12}} = \\sqrt{\\frac{6}{10}} = \\sqrt{0.6} $$\nNow, compute the $Z_{1}$ statistic:\n$$ Z_{1} = \\frac{2.4}{\\sqrt{0.6}} $$\nCalculating the numerical value:\n$$ Z_{1} \\approx \\frac{2.4}{0.774596669...} \\approx 3.09838667... $$\nThe problem requires rounding to four significant figures. The fifth significant figure is $3$, so we round down.\n$$ Z_{1} \\approx 3.098 $$\nThe final step is to apply the decision rule. The trial stops for efficacy if the observed statistic $Z_{1}$ exceeds the pre-specified boundary $c_{1}$.\nThe observed statistic is $Z_{1} \\approx 3.098$.\nThe efficacy boundary is $c_{1} = 2.963$.\nComparing the two values:\n$$ 3.098 > 2.963 $$\nSince $Z_{1} > c_{1}$, the null hypothesis $H_{0}$ is rejected at the interim analysis. The conclusion is to stop the trial for demonstrated efficacy of the new antihypertensive treatment. The question asks for the computed value of $Z_{1}$.", "answer": "$$\\boxed{3.098}$$", "id": "4519357"}, {"introduction": "While group sequential designs are powerful, some scenarios call for more flexible adaptations, such as modifying the trial's sample size based on unblinded interim results. However, making such changes naively can introduce statistical bias and inflate the Type I error rate, potentially leading to false claims of efficacy. This conceptual exercise [@problem_id:4987211] challenges you to reason from first principles about *why* this bias occurs and to explore the sophisticated statistical tools, like combination tests and the conditional error principle, that are required to maintain a trial's integrity.", "problem": "A translational medicine team is planning a two-stage adaptive superiority trial comparing a new therapy to control on a continuous endpoint with known variance $\\sigma^2 = 1$. Let $\\theta$ denote the mean difference (new therapy minus control), and consider testing $H_0: \\theta = 0$ versus $H_1: \\theta > 0$ at a one-sided significance level $\\alpha \\in (0,1)$. Stage $1$ enrolls $n_1$ patients per arm and yields an unblinded interim statistic $Z_1$ from the usual $Z$-test. The originally planned total sample size corresponds to an additional stage $2$ enrollment of $n_{2,0}$ patients per arm, with an originally planned fixed-design final analysis using the conventional pooled $Z$-statistic and critical value $\\Phi^{-1}(1-\\alpha)$, where $\\Phi$ is the standard normal cumulative distribution function. There is no early efficacy stopping, and all patients proceed to final analysis.\n\nAt the interim, the sponsor implements an unblinded, data-driven sample size inflation rule: if $Z_1$ falls in a pre-specified “promising zone” of positive values (for concreteness, a Borel set $S \\subset (0,\\infty)$ with nonzero Lebesgue measure), the stage $2$ sample size is increased to $n_{2,+} > n_{2,0}$; otherwise stage $2$ remains at $n_{2,0}$. No multiplicity adjustment is pre-specified, and at the end the investigator computes the usual pooled $Z$-statistic using all stage $1$ and stage $2$ observations and compares it to the standard normal critical value $\\Phi^{-1}(1-\\alpha)$, effectively analyzing “as if” the design had been fixed.\n\nWork from first principles appropriate to adaptive clinical trials, specifically: (i) independent stage-wise increments and central limit behavior under $H_0$ that imply stage-wise standardized $Z$-statistics are independent and standard normal when sample sizes are fixed, and (ii) the law of total probability and conditioning on the interim statistic $Z_1$. Based on these principles, analyze the distribution of the final pooled $Z$-statistic under $H_0$ when stage $2$ sample size depends on $Z_1$ as above, and reason how adaptive combination testing or the conditional error approach restores a known null distribution and strong Type I error control.\n\nSelect all statements that are correct.\n\nA. Under $H_0$, the naive final pooled $Z$-statistic (computed with the usual fixed-design formula and the standard normal critical value) remains exactly $N(0,1)$ because stage-wise independence ensures validity even if $n_2$ is a function of $Z_1$.\n\nB. Under $H_0$, when the inflation rule decreases the final weight on stage $1$ for $Z_1 \\in S \\subset (0,\\infty)$, the naive final pooled $Z$-statistic is a mixture of normals with conditional mean $E\\!\\left[Z_{\\text{final}} \\mid Z_1 = z\\right] = \\sqrt{w(z)}\\, z$ and conditional variance $1 - w(z)$, where $w(z)$ is the stage $1$ information fraction after adaptation. For $z \\in S$ that are not extreme, reducing $w(z)$ increases the one-sided rejection probability at the fixed cut-off $\\Phi^{-1}(1-\\alpha)$, yielding inflated Type I error.\n\nC. A pre-specified inverse-normal combination test that combines the stage-wise $p$-values with fixed, pre-specified weights yields a normally distributed combination statistic under $H_0$ that is valid regardless of how $n_2$ is chosen as a function of $Z_1$.\n\nD. The conditional error principle attains strong control of the unconditional Type I error by requiring that, for each realized interim value $Z_1 = z$, the conditional probability of final rejection under $H_0$ induced by the adapted second-stage analysis does not exceed the original design’s conditional error given $Z_1 = z$.\n\nE. If instead the team performed a blinded sample size re-estimation at interim based solely on a variance estimate that is independent of $Z_1$ and does not use any unblinded estimate of $\\theta$, then the final pooled $Z$-statistic under $H_0$ retains the standard normal null distribution and the nominal one-sided Type I error without additional adjustment.", "solution": "The user wants me to act as a meticulous STEM professor and solve a problem related to adaptive clinical trial designs.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n\n*   **Trial design**: A two-stage adaptive superiority trial.\n*   **Hypotheses**: $H_0: \\theta = 0$ versus $H_1: \\theta > 0$, where $\\theta$ is the mean difference (new therapy minus control).\n*   **Endpoint**: Continuous, with known variance $\\sigma^2 = 1$.\n*   **Significance level**: One-sided $\\alpha \\in (0,1)$.\n*   **Stage 1**: $n_1$ patients per arm, yielding an interim $Z$-statistic $Z_1$.\n*   **Original Stage 2 plan**: $n_{2,0}$ patients per arm.\n*   **Original Final analysis plan**: Pooled $Z$-statistic with critical value $\\Phi^{-1}(1-\\alpha)$.\n*   **Stopping rules**: No early efficacy stopping.\n*   **Adaptation rule**: Unblinded sample size re-estimation (SSR).\n    *   If $Z_1 \\in S \\subset (0,\\infty)$ (a pre-specified \"promising zone\"), the stage $2$ sample size is increased to $n_{2,+}$ where $n_{2,+} > n_{2,0}$.\n    *   Otherwise, the stage $2$ sample size remains $n_{2,0}$.\n*   **Actual Final analysis**: A naive approach is used. The usual pooled $Z$-statistic is computed with the adapted sample size and compared to the fixed-design critical value $\\Phi^{-1}(1-\\alpha)$.\n*   **Required Principles**: (i) Independent, standard normal stage-wise $Z$-statistics under $H_0$ for fixed sample sizes. (ii) Law of total probability and conditioning on $Z_1$.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientific Grounding**: The problem is grounded in the established statistical theory of adaptive clinical trials. The scenario described—unblinded sample size re-estimation based on interim effect size—is a common and well-studied topic. The concepts of Type I error inflation, combination tests, and the conditional error principle are central to this field. The problem is scientifically sound.\n*   **Well-Posed**: The problem is well-posed. It presents a clear scenario and asks for an analysis of the statistical consequences and the principles of valid solutions. The information provided is sufficient to reason about the distributions of the test statistics and evaluate the given statements based on first principles of probability and statistics.\n*   **Objective**: The language is formal, precise, and objective. It uses standard terminology from biostatistics without ambiguity or subjective framing.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It is a well-defined problem in statistical methodology for clinical trials. I will now proceed with the derivation and option-by-option analysis.\n\n**Derivation and Analysis**\n\nUnder the null hypothesis $H_0: \\theta = 0$, and with known variance $\\sigma^2 = 1$, the stage-wise test statistics can be defined.\n\nThe stage $1$ statistic is $Z_1 = \\frac{\\hat{\\theta}_1}{\\sqrt{2/n_1}}$, where $\\hat{\\theta}_1$ is the observed mean difference in stage $1$. Under $H_0$, $Z_1 \\sim N(0,1)$.\n\nThe stage $2$ statistic, based on an additional $n_2$ patients per arm, is $Z_2 = \\frac{\\hat{\\theta}_2}{\\sqrt{2/n_2}}$. Under $H_0$, $Z_2 \\sim N(0,1)$. Crucially, because the stage $2$ patients are a new, independent cohort, $Z_2$ is statistically independent of $Z_1$. This holds regardless of the value of $n_2$.\n\nThe \"naive\" final pooled $Z$-statistic is constructed as if the design were fixed with sample sizes $n_1$ and $n_2$. Its formula is:\n$$ Z_{\\text{final}} = \\frac{\\text{overall weighted mean difference}}{\\text{standard error}} = \\frac{n_1 \\hat{\\theta}_1 + n_2 \\hat{\\theta}_2}{n_1 + n_2} \\bigg/ \\sqrt{\\frac{2\\sigma^2}{n_1+n_2}} $$\nSubstituting $\\hat{\\theta}_1 = Z_1 \\sqrt{2/n_1}$, $\\hat{\\theta}_2 = Z_2 \\sqrt{2/n_2}$, and $\\sigma^2=1$:\n$$ Z_{\\text{final}} = \\frac{n_1 (Z_1 \\sqrt{2/n_1}) + n_2 (Z_2 \\sqrt{2/n_2})}{\\sqrt{2(n_1+n_2)}} = \\frac{\\sqrt{2n_1} Z_1 + \\sqrt{2n_2} Z_2}{\\sqrt{2(n_1+n_2)}} = \\sqrt{\\frac{n_1}{n_1+n_2}} Z_1 + \\sqrt{\\frac{n_2}{n_1+n_2}} Z_2 $$\nIn this adaptive design, the stage $2$ sample size $n_2$ is a function of the stage $1$ outcome, $n_2(Z_1)$. Consequently, the weights are also functions of $Z_1$. Let the stage $1$ information fraction be $w(Z_1) = \\frac{n_1}{n_1+n_2(Z_1)}$. The naive statistic is:\n$$ Z_{\\text{naive}}(Z_1, Z_2) = \\sqrt{w(Z_1)} Z_1 + \\sqrt{1-w(Z_1)} Z_2 $$\nThe core issue is that the random weight $\\sqrt{w(Z_1)}$ is correlated with the random variable $Z_1$. This violates the conditions under which a simple weighted sum of standard normal variables is itself standard normal.\n\n**Option-by-Option Analysis**\n\n**A. Under $H_0$, the naive final pooled $Z$-statistic (computed with the usual fixed-design formula and the standard normal critical value) remains exactly $N(0,1)$ because stage-wise independence ensures validity even if $n_2$ is a function of $Z_1$.**\n\nWhile it is true that the stage-wise statistics $Z_1$ and $Z_2$ are independent, this is not sufficient to ensure the naive pooled statistic $Z_{\\text{naive}}$ is standard normal. The statistic $Z_{\\text{naive}} = \\sqrt{w(Z_1)} Z_1 + \\sqrt{1-w(Z_1)} Z_2$ involves a product of two correlated random variables, $f(Z_1) = \\sqrt{w(Z_1)}$ and $Z_1$. The distribution of such a combination is not standard normal. The rule \"increase sample size for promising results\" introduces a selection bias for which the naive statistic does not adjust, leading to a distortion of its null distribution. In general, this distortion leads to an inflation of the Type I error rate.\n**Verdict: Incorrect.**\n\n**B. Under $H_0$, when the inflation rule decreases the final weight on stage $1$ for $Z_1 \\in S \\subset (0,\\infty)$, the naive final pooled $Z$-statistic is a mixture of normals with conditional mean $E\\!\\left[Z_{\\text{final}} \\mid Z_1 = z\\right] = \\sqrt{w(z)}\\, z$ and conditional variance $1 - w(z)$, where $w(z)$ is the stage $1$ information fraction after adaptation. For $z \\in S$ that are not extreme, reducing $w(z)$ increases the one-sided rejection probability at the fixed cut-off $\\Phi^{-1}(1-\\alpha)$, yielding inflated Type I error.**\n\nFirst part: Conditional distribution. Given $Z_1=z$, $n_2(z)$ is fixed, so the weight $w(z) = \\frac{n_1}{n_1+n_2(z)}$ is also fixed. The statistic becomes $Z_{\\text{naive}}|_{Z_1=z} = \\sqrt{w(z)} z + \\sqrt{1-w(z)} Z_2$. Since $Z_2 \\sim N(0,1)$ and is independent of $Z_1$, this conditional distribution is normal. Its mean is $E[\\sqrt{w(z)} z + \\sqrt{1-w(z)} Z_2] = \\sqrt{w(z)} z$. Its variance is $Var(\\sqrt{w(z)} z + \\sqrt{1-w(z)} Z_2) = (1-w(z))Var(Z_2) = 1-w(z)$. The unconditional distribution of $Z_{\\text{naive}}$ is the mixture of these conditional normal distributions over the $N(0,1)$ distribution of $Z_1$. This part of the statement is correct.\n\nSecond part: Impact on rejection probability. The conditional rejection probability is $P(Z_{\\text{naive}} > c_\\alpha | Z_1=z) = P(Z_2 > \\frac{c_\\alpha - \\sqrt{w(z)} z}{\\sqrt{1-w(z)}}) = 1 - \\Phi\\left(\\frac{c_\\alpha - \\sqrt{w(z)} z}{\\sqrt{1-w(z)}}\\right)$, where $c_\\alpha = \\Phi^{-1}(1-\\alpha)$. For $z \\in S$, the rule increases $n_2$, which decreases $w(z)$. We analyze how the argument of $\\Phi(\\cdot)$, let's call it $u(w, z) = \\frac{c_\\alpha - \\sqrt{w} z}{\\sqrt{1-w}}$, changes as $w$ decreases. The derivative is $\\frac{\\partial u}{\\partial w} = \\frac{c_\\alpha\\sqrt{w} - z}{2w^{1/2}(1-w)^{3/2}}$. When $z  c_\\alpha\\sqrt{w}$, $\\frac{\\partial u}{\\partial w} > 0$, so decreasing $w$ decreases $u$, which increases the rejection probability $1-\\Phi(u)$. The \"promising zone\" $S$ for interim results typically includes values of $z$ that are positive but not large enough to be definitively significant (i.e., \"not extreme\"). For such values, it is plausible that $z  c_\\alpha\\sqrt{w}$ (e.g., if $\\alpha=0.025$, $c_\\alpha \\approx 1.96$, and for $w=0.5$, $\\sqrt{w} \\approx 0.707$, so $c_\\alpha\\sqrt{w} \\approx 1.39$). In this region, increasing the sample size (reducing $w$) boosts the conditional probability of rejection. This boost, integrated over the distribution of $Z_1$, is the source of overall Type I error inflation. The statement accurately describes this mechanism.\n**Verdict: Correct.**\n\n**C. A pre-specified inverse-normal combination test that combines the stage-wise $p$-values with fixed, pre-specified weights yields a normally distributed combination statistic under $H_0$ that is valid regardless of how $n_2$ is chosen as a function of $Z_1$.**\n\nThe inverse-normal combination method uses a test statistic of the form $Z_C = \\sqrt{w_1} \\Phi^{-1}(1-p_1) + \\sqrt{w_2} \\Phi^{-1}(1-p_2)$, where $p_1$ and $p_2$ are the stage-wise p-values, and $w_1, w_2$ are pre-specified fixed weights with $w_1+w_2=1$. For one-sided tests, $p_1 = 1-\\Phi(Z_1)$ and $p_2 = 1-\\Phi(Z_2)$. This simplifies the statistic to $Z_C = \\sqrt{w_1} Z_1 + \\sqrt{w_2} Z_2$. Under $H_0$, $Z_1$ and $Z_2$ are independent $N(0,1)$ random variables. Because $w_1$ and $w_2$ are fixed constants, $Z_C$ is a linear combination of independent normal variables and is therefore also normally distributed with mean $0$ and variance $(\\sqrt{w_1})^2 + (\\sqrt{w_2})^2 = w_1+w_2=1$. The key is that the validity of this null distribution depends only on $Z_1, Z_2$ being i.i.d. $N(0,1)$ and the weights being fixed. The sample size $n_2$ can be changed based on $Z_1$, and this will affect the power of the stage $2$ test, but it does not change the fact that under $H_0$, the resulting statistic $Z_2$ is standard normal and independent of $Z_1$. Thus, the null distribution of $Z_C$ is preserved, and the Type I error is controlled.\n**Verdict: Correct.**\n\n**D. The conditional error principle attains strong control of the unconditional Type I error by requiring that, for each realized interim value $Z_1 = z$, the conditional probability of final rejection under $H_0$ induced by the adapted second-stage analysis does not exceed the original design’s conditional error given $Z_1 = z$.**\n\nThis statement is a precise definition of the conditional error principle (due to Proschan and Hunsberger). Let $A(z)$ be the conditional probability of rejecting $H_0$ given $Z_1=z$ in the originally planned fixed design. Let $A^*(z)$ be the conditional rejection probability for the adapted design. The principle requires that any adaptation must satisfy $A^*(z) \\le A(z)$ for all possible outcomes $z$. The unconditional Type I error of the original design is $\\alpha = \\int A(z)\\phi(z)dz$. The unconditional Type I error of the adapted design is $\\alpha^* = \\int A^*(z)\\phi(z)dz$. By requiring $A^*(z) \\le A(z)$ for all $z$, it directly follows that $\\alpha^* \\le \\alpha$. This guarantees that the Type I error rate of the adaptive trial does not exceed the nominal level $\\alpha$. The statement correctly describes this logic.\n**Verdict: Correct.**\n\n**E. If instead the team performed a blinded sample size re-estimation at interim based solely on a variance estimate that is independent of $Z_1$ and does not use any unblinded estimate of $\\theta$, then the final pooled $Z$-statistic under $H_0$ retains the standard normal null distribution and the nominal one-sided Type I error without additional adjustment.**\n\nThis describes blinded sample size re-estimation (BSSR). The sample size $n_2$ is modified based on information that is \"blinded\" to the treatment effect. In the context of a trial with normal data, this typically means using a pooled estimate of the variance $\\sigma^2$ from stage $1$ data, without reference to the treatment group assignments. A key result from mathematical statistics (for normally distributed data) is that the sample mean and the sample variance are independent statistics. Under $H_0: \\theta=0$, the unblinded interim statistic $Z_1$ is a function of the mean difference, while a blinded variance estimate is not. Therefore, the variance estimate used for adaptation is independent of $Z_1$. If the rule $n_2(\\cdot)$ depends only on this variance estimate, then the resulting sample size $n_2$ and the corresponding weights $w$ in the final statistic are random, but they are independent of $Z_1$. The test statistic is $Z_{\\text{final}} = \\sqrt{w} Z_1 + \\sqrt{1-w} Z_2$. Conditionally on the realized variance estimate (which fixes $w$), the statistic has an $N(0,1)$ distribution because $Z_1, Z_2$ are i.i.d. $N(0,1)$ and the weights are constant. Since the conditional distribution is $N(0,1)$ for every possible outcome of the variance estimate, the unconditional distribution is also exactly $N(0,1)$. Thus, the naive analysis remains valid.\n**Verdict: Correct.**", "answer": "$$\\boxed{BCDE}$$", "id": "4987211"}, {"introduction": "The Bayesian paradigm offers an intuitive and powerful framework for adaptive trials, formally incorporating prior knowledge and updating it as new data becomes available. A critical part of designing any trial, Bayesian or frequentist, is to evaluate its long-run performance, or \"operating characteristics,\" before it begins. This computational exercise [@problem_id:4519388] requires you to translate statistical theory into practice by deriving and implementing formulas to calculate a design's probability of success and expected sample size. This provides a deep, hands-on understanding of how different design parameters influence a trial's behavior and ultimate success.", "problem": "Consider a single-arm, two-stage Bayesian adaptive design for a binary response in clinical pharmacology. Let the unknown response probability be denoted by $\\theta \\in [0,1]$. Prior knowledge about $\\theta$ is modeled as a Beta distribution $\\mathrm{Beta}(a,b)$, where $a0$ and $b0$. Patients are enrolled in two stages: an interim analysis occurs after $n_1$ observations, and a final analysis occurs at a maximum of $N$ observations, with $N \\ge n_1$. Let $x_1$ denote the number of responses observed at the interim stage and $x$ the total number of responses at the end of the trial. Assume that conditional on $\\theta$, the data are independent and identically distributed Bernoulli trials, so that $x_1 \\sim \\mathrm{Binomial}(n_1,\\theta)$ and $x \\sim \\mathrm{Binomial}(N,\\theta)$.\n\nAt each analysis, decisions are made by thresholding posterior tail probabilities relative to a clinically meaningful response threshold $\\theta_0 \\in (0,1)$. Specifically, at sample size $n$ with $x$ observed responses, the posterior distribution is $\\theta \\mid x \\sim \\mathrm{Beta}(a+x,b+n-x)$ by conjugacy. Define the posterior tail probability $T(x,n) = \\mathbb{P}(\\theta \\ge \\theta_0 \\mid x,n) = 1 - I_{\\theta_0}(a+x,b+n-x)$, where $I_{z}(\\alpha,\\beta)$ is the regularized incomplete beta function.\n\nThe decision rule is:\n- Early success at the interim if $T(x_1,n_1) \\ge t_s$, stop and declare success.\n- Early futility at the interim if $T(x_1,n_1) \\le t_f$, stop and declare futility.\n- Otherwise, continue to the final analysis at $N$ observations, and declare final success if $T(x,N) \\ge t_F$; otherwise declare futility.\n\nFor a fixed true response probability $p \\in [0,1]$, define the operating characteristics as follows:\n- The probability of success at $p$, denoted $\\pi_{\\mathrm{succ}}(p)$, equals the probability (over the sampling distribution under $p$) that the design declares success at either interim or final analysis.\n- The expected sample size at $p$, denoted $E_{\\!N}(p)$, equals the expectation of the total number of patients accrued before stopping, under the sampling distribution with true response probability $p$.\n- The Type I error is defined at the null boundary $p=\\theta_0$ as $\\alpha = \\pi_{\\mathrm{succ}}(\\theta_0)$.\n\nUsing only the following fundamental base:\n- The binomial sampling model $X \\sim \\mathrm{Binomial}(n,p)$ with probability mass function $\\mathbb{P}(X=x) = \\binom{n}{x} p^x (1-p)^{n-x}$ for $x \\in \\{0,1,\\dots,n\\}$ and $p \\in [0,1]$.\n- Conjugacy of the Beta prior with the Binomial likelihood: $\\theta \\mid x \\sim \\mathrm{Beta}(a+x,b+n-x)$ when $\\theta \\sim \\mathrm{Beta}(a,b)$ and $X \\sim \\mathrm{Binomial}(n,\\theta)$.\n- The identity $\\mathbb{P}(\\theta \\ge \\theta_0 \\mid x,n) = 1 - I_{\\theta_0}(a+x,b+n-x)$ where $I_z(\\alpha,\\beta)$ is the regularized incomplete beta function.\n\nDerive from first principles expressions for $\\pi_{\\mathrm{succ}}(p)$, $\\alpha$, and $E_{\\!N}(p)$ in terms of $a$, $b$, $n_1$, $N$, $\\theta_0$, $t_s$, $t_f$, $t_F$, and $p$. Your program must implement these expressions exactly via summation over the relevant binomial distributions for interim and final stages, without simulation.\n\nYour program should compute these operating characteristics for each of the following test cases. For each test case, compute for each specified true response probability value $p$ the triple $[\\pi_{\\mathrm{succ}}(p), \\alpha, E_{\\!N}(p)]$ with all three quantities expressed as decimals rounded to six digits after the decimal point.\n\nTest suite:\n- Case $1$: $a=1$, $b=1$, $n_1=20$, $N=40$, $\\theta_0=0.2$, $t_s=0.99$, $t_f=0.05$, $t_F=0.95$, and evaluate at $p \\in \\{0.2, 0.35\\}$.\n- Case $2$ (boundary where there is effectively one stage): $a=1$, $b=1$, $n_1=10$, $N=10$, $\\theta_0=0.3$, $t_s=0.9$, $t_f=0.1$, $t_F=0.9$, and evaluate at $p \\in \\{0.3, 0.5\\}$. This probes the boundary condition $N=n_1$ where only a single analysis is performed.\n- Case $3$ (informative prior): $a=2$, $b=8$, $n_1=15$, $N=30$, $\\theta_0=0.2$, $t_s=0.975$, $t_f=0.05$, $t_F=0.95$, and evaluate at $p \\in \\{0.1, 0.2, 0.4\\}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list of triples $[\\pi_{\\mathrm{succ}}(p), \\alpha, E_{\\!N}(p)]$ for the specified $p$ values in the given order. For example, the overall structure should be of the form $[[\\cdot,\\cdot,\\dots],[\\cdot,\\cdot,\\dots],[\\cdot,\\cdot,\\dots]]$, where each $\\cdot$ is a triple. All probabilities must be expressed as decimals, not as percentages. No physical units are involved.", "solution": "The problem is assessed as valid. It is a well-defined task in biostatistics, specifically in the design of adaptive clinical trials. The problem is scientifically grounded in Bayesian inference and probability theory, self-contained with all necessary parameters provided, and articulated using objective, formal mathematical language. There are no contradictions, ambiguities, or violations of scientific principles. We may, therefore, proceed with the derivation of the required operating characteristics from first principles.\n\nLet the true response probability be $p \\in [0,1]$. The number of responses in the first stage, $X_1$, is a random variable following a binomial distribution, $X_1 \\sim \\mathrm{Binomial}(n_1, p)$. The sample space for $X_1$ is $\\{0, 1, \\dots, n_1\\}$.\n\nAt the interim analysis after $n_1$ patients, for each possible outcome $x_1 \\in \\{0, 1, \\dots, n_1\\}$, the posterior tail probability $T(x_1, n_1) = \\mathbb{P}(\\theta \\ge \\theta_0 \\mid x_1, n_1)$ is computed as $1 - I_{\\theta_0}(a+x_1, b+n_1-x_1)$, where $I_z(\\alpha, \\beta)$ is the regularized incomplete beta function. Based on this value, the set of all possible interim outcomes is partitioned into three disjoint sets:\n- The set of outcomes leading to early success: $S_1 = \\{x_1 \\in \\{0, \\dots, n_1\\} \\mid T(x_1, n_1) \\ge t_s \\}$.\n- The set of outcomes leading to early futility: $F_1 = \\{x_1 \\in \\{0, \\dots, n_1\\} \\mid T(x_1, n_1) \\le t_f \\}$.\n- The set of outcomes leading to continuation: $C_1 = \\{x_1 \\in \\{0, \\dots, n_1\\} \\mid t_f  T(x_1, n_1)  t_s \\}$.\n\nThe probability of observing $x_1$ responses in the first stage, given the true probability $p$, is determined by the binomial probability mass function (PMF):\n$$ \\mathbb{P}(X_1 = x_1 \\mid p) = \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} $$\n\n**Derivation of the Probability of Success, $\\pi_{\\mathrm{succ}}(p)$**\nA trial is declared successful via one of two mutually exclusive paths: success at the interim stage, or continuation at interim followed by success at the final stage. The total probability of success is the sum of the probabilities of these two paths.\n\n1.  **Path 1: Early Success.** This occurs if the observed number of responses $X_1$ is a member of the set $S_1$. The probability of this event is the sum of the probabilities of all outcomes in $S_1$:\n    $$ \\mathbb{P}(\\text{Early Success}) = \\mathbb{P}(X_1 \\in S_1) = \\sum_{x_1 \\in S_1} \\mathbb{P}(X_1 = x_1 \\mid p) = \\sum_{x_1 \\in S_1} \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} $$\n\n2.  **Path 2: Continuation and Final Success.** This path requires the interim outcome $X_1$ to be in the continuation set $C_1$. If $x_1 \\in C_1$, an additional $n_2 = N - n_1$ patients are enrolled. Let $X_2$ be the number of responses in this second cohort. Given the true rate $p$, $X_2 \\sim \\mathrm{Binomial}(n_2, p)$ and is independent of $X_1$. The total number of responses at the final analysis is $X = x_1+X_2$. Final success is declared if $T(x_1+X_2, N) \\ge t_F$.\n    For a fixed interim outcome $x_1 \\in C_1$, we define $S_2(x_1)$ as the set of second-stage outcomes that result in final success:\n    $$ S_2(x_1) = \\{x_2 \\in \\{0, \\dots, n_2\\} \\mid T(x_1+x_2, N) \\ge t_F \\} $$\n    The probability of achieving final success, conditional on the interim outcome being $x_1$, is the probability that $X_2$ falls into $S_2(x_1)$:\n    $$ \\mathbb{P}(\\text{Final Success} \\mid X_1 = x_1) = \\mathbb{P}(X_2 \\in S_2(x_1)) = \\sum_{x_2 \\in S_2(x_1)} \\mathbb{P}(X_2=x_2 \\mid p) = \\sum_{x_2 \\in S_2(x_1)} \\binom{n_2}{x_2} p^{x_2} (1-p)^{n_2-x_2} $$\n    The total probability for Path 2 is found by summing over all possible continuation outcomes $x_1 \\in C_1$, weighted by their respective probabilities, by the law of total probability:\n    $$ \\mathbb{P}(\\text{Continuation and Final Success}) = \\sum_{x_1 \\in C_1} \\mathbb{P}(\\text{Final Success} \\mid X_1 = x_1) \\mathbb{P}(X_1=x_1 \\mid p) $$\n    $$ = \\sum_{x_1 \\in C_1} \\left[ \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} \\left( \\sum_{x_2 \\in S_2(x_1)} \\binom{N-n_1}{x_2} p^{x_2} (1-p)^{N-n_1-x_2} \\right) \\right] $$\n\nThe total probability of success, $\\pi_{\\mathrm{succ}}(p)$, is the sum of the probabilities of these two disjoint paths:\n$$ \\pi_{\\mathrm{succ}}(p) = \\mathbb{P}(\\text{Early Success}) + \\mathbb{P}(\\text{Continuation and Final Success}) $$\n$$ \\pi_{\\mathrm{succ}}(p) = \\sum_{x_1 \\in S_1} \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} + \\sum_{x_1 \\in C_1} \\left[ \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} \\left( \\sum_{x_2 \\in S_2(x_1)} \\binom{N-n_1}{x_2} p^{x_2} (1-p)^{N-n_1-x_2} \\right) \\right] $$\n\n**Derivation of Type I Error, $\\alpha$**\nThe Type I error rate, $\\alpha$, is defined as the probability of declaring success when the true response rate is $p=\\theta_0$. It is therefore calculated by evaluating the expression for $\\pi_{\\mathrm{succ}}(p)$ at $p=\\theta_0$:\n$$ \\alpha = \\pi_{\\mathrm{succ}}(\\theta_0) $$\n\n**Derivation of Expected Sample Size, $E_{\\!N}(p)$**\nThe sample size is a random variable taking the value $n_1$ if the trial stops at the interim analysis (due to success or futility) or $N$ if it continues. The trial continues if and only if the interim outcome $X_1$ falls into the set $C_1$.\nThe probability of continuation is the probability that $X_1 \\in C_1$:\n$$ \\mathbb{P}(\\text{Continue}) = \\mathbb{P}(X_1 \\in C_1) = \\sum_{x_1 \\in C_1} \\mathbb{P}(X_1=x_1 \\mid p) = \\sum_{x_1 \\in C_1} \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} $$\nThe expected sample size, $E_{\\!N}(p)$, is the weighted average of the two possible sample sizes:\n$$ E_{\\!N}(p) = n_1 \\cdot \\mathbb{P}(\\text{Stop at Interim}) + N \\cdot \\mathbb{P}(\\text{Continue}) $$\nSince $\\mathbb{P}(\\text{Stop at Interim}) = 1 - \\mathbb{P}(\\text{Continue})$, we can write:\n$$ E_{\\!N}(p) = n_1 \\cdot (1 - \\mathbb{P}(\\text{Continue})) + N \\cdot \\mathbb{P}(\\text{Continue}) = n_1 - n_1 \\cdot \\mathbb{P}(\\text{Continue}) + N \\cdot \\mathbb{P}(\\text{Continue}) $$\nThis simplifies to:\n$$ E_{\\!N}(p) = n_1 + (N - n_1) \\cdot \\mathbb{P}(\\text{Continue}) $$\nSubstituting the expression for the probability of continuation yields the final formula:\n$$ E_{\\!N}(p) = n_1 + (N-n_1) \\left( \\sum_{x_1 \\in C_1} \\binom{n_1}{x_1} p^{x_1} (1-p)^{n_1-x_1} \\right) $$\nThese derived expressions are implemented in the following program by first determining the decision sets $S_1$, $C_1$, and $S_2(x_1)$, and then performing the specified summations over the relevant binomial PMFs.", "answer": "```python\nimport numpy as np\nfrom scipy.special import comb, betainc\n\ndef _calculate_op_chars_for_p(a, b, n1, N, theta0, ts, tf, tF, p):\n    \"\"\"\n    Calculates the probability of success and expected sample size for a given true response rate p.\n    \"\"\"\n    # 1. Determine decision boundaries for the interim analysis\n    x1_values = np.arange(n1 + 1)\n    \n    # Calculate posterior tail probability T(x1, n1) for all possible x1\n    post_a_interim = a + x1_values\n    post_b_interim = b + n1 - x1_values\n    T_interim = 1 - betainc(post_a_interim, post_b_interim, theta0)\n    \n    # Identify outcomes for early success, futility, and continuation\n    s1_mask = T_interim = ts\n    c1_mask = (T_interim  tf)  (T_interim  ts)\n\n    # 2. Calculate probabilities of interim outcomes under the true rate p\n    pmf_x1 = comb(n1, x1_values) * (p**x1_values) * ((1-p)**(n1-x1_values))\n\n    # 3. Calculate Expected Sample Size E_N(p)\n    prob_continue = np.sum(pmf_x1[c1_mask])\n    expected_n = n1 + (N - n1) * prob_continue\n\n    # 4. Calculate Probability of Success pi_succ(p)\n    # Path 1: Early success\n    prob_early_succ = np.sum(pmf_x1[s1_mask])\n    \n    # Path 2: Continuation followed by final success\n    prob_cont_succ = 0.0\n    c1_outcomes = x1_values[c1_mask]\n    n2 = N - n1\n    \n    # If there is a second stage and continuation is possible\n    if n2  0 and len(c1_outcomes)  0:\n        x2_values = np.arange(n2 + 1)\n        pmf_x2 = comb(n2, x2_values) * (p**x2_values) * ((1-p)**(n2-x2_values))\n        \n        for x1_c in c1_outcomes:\n            # For this specific interim outcome x1_c, find which stage 2 outcomes lead to success\n            post_a_final = a + x1_c + x2_values\n            post_b_final = b + N - (x1_c + x2_values)\n            T_final = 1 - betainc(post_a_final, post_b_final, theta0)\n            \n            s2_mask = T_final = tF\n            \n            # Probability of final success, conditional on interim outcome x1_c\n            prob_final_succ_given_x1c = np.sum(pmf_x2[s2_mask])\n            \n            # Add this path's probability to the total\n            prob_cont_succ += pmf_x1[x1_c] * prob_final_succ_given_x1c\n            \n    # Handle the boundary case where N=n1 (single stage)\n    elif n2 == 0 and len(c1_outcomes)  0:\n        for x1_c in c1_outcomes:\n            # \"Continue\" means re-evaluating against the final threshold tF\n            if T_interim[x1_c] = tF:\n                prob_cont_succ += pmf_x1[x1_c]\n                \n    pi_succ = prob_early_succ + prob_cont_succ\n    \n    return pi_succ, expected_n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the formatted results.\n    \"\"\"\n    test_cases = [\n        {'params': (1, 1, 20, 40, 0.2, 0.99, 0.05, 0.95), 'p_values': [0.2, 0.35]},\n        {'params': (1, 1, 10, 10, 0.3, 0.9, 0.1, 0.9), 'p_values': [0.3, 0.5]},\n        {'params': (2, 8, 15, 30, 0.2, 0.975, 0.05, 0.95), 'p_values': [0.1, 0.2, 0.4]}\n    ]\n\n    all_results_list = []\n    for case in test_cases:\n        params = case['params']\n        p_values = case['p_values']\n        theta0 = params[4]\n\n        # Calculate Type I error (alpha) once per case\n        alpha, _ = _calculate_op_chars_for_p(*params, p=theta0)\n\n        case_results = []\n        for p in p_values:\n            pi_succ_p, en_p = _calculate_op_chars_for_p(*params, p=p)\n            case_results.append(f\"[{pi_succ_p:.6f},{alpha:.6f},{en_p:.6f}]\")\n        \n        all_results_list.append(f\"[{','.join(case_results)}]\")\n\n    # Print the final result in the exact required format.\n    print(f\"[[{','.join(all_results_list)}]]\")\n\nsolve()\n```", "id": "4519388"}]}