{"hands_on_practices": [{"introduction": "Understanding how a drug accumulates in the body with repeated dosing is a cornerstone of pharmacology, essential for preventing toxicity and ensuring efficacy. This exercise reinforces first principles by asking you to derive the accumulation ratio, $R_{\\mathrm{acc}}$, from the ground up using the concept of superposition in a linear system. Mastering this derivation provides a clear link between a drug's half-life ($t_{1/2}$) and the dosing interval ($\\tau$), which is fundamental to rational dose regimen design [@problem_id:5046120].", "problem": "A one-compartment, linear, time-invariant population pharmacokinetic (PopPK) model is used to describe a small-molecule drug administered by rapid intravenous bolus at fixed dosing interval $\\,\\tau\\,$. Let the typical population clearance be $\\,\\mathrm{CL}_{\\mathrm{typ}}\\,$ and the typical population volume of distribution be $\\,V_{\\mathrm{typ}}\\,$. Assume first-order elimination with rate constant $\\,k = \\mathrm{CL}_{\\mathrm{typ}}/V_{\\mathrm{typ}}\\,$ and define the elimination half-life $\\,t_{1/2}\\,$ by $\\,t_{1/2} = \\ln(2)/k\\,$. Under multiple dosing at steady state, the peak concentration immediately post-dose is elevated relative to the peak after the first dose due to superposition of residual concentrations from prior doses.\n\nStarting from the fundamental assumptions of linearity, time invariance, and first-order elimination, use the exponential decay of concentration between doses and the principle of superposition to derive the closed-form expression for the accumulation ratio $\\,R_{\\mathrm{acc}}\\,$, defined as the ratio of the steady-state peak concentration immediately after a dose to the peak concentration immediately after the first dose, as a function of $\\,k\\,$ and $\\,\\tau\\,$. Then evaluate $\\,R_{\\mathrm{acc}}\\,$ for $\\,\\mathrm{CL}_{\\mathrm{typ}} = 5.0\\,\\mathrm{L}\\,\\mathrm{h}^{-1}\\,$, $\\,V_{\\mathrm{typ}} = 50.0\\,\\mathrm{L}\\,$, and $\\,\\tau = 8.0\\,\\mathrm{h}\\,$. Briefly interpret, in words, how the ratio of $\\,t_{1/2}\\,$ to $\\,\\tau\\,$ governs the magnitude of accumulation at steady state.\n\nProvide your final numerical answer as a dimensionless number rounded to four significant figures. Do not include units in your final answer.", "solution": "The problem is well-posed, scientifically grounded, and self-contained. It is a standard derivation in classical pharmacokinetics. We may proceed with the solution.\n\nThe problem describes a one-compartment model for a drug administered via intravenous (IV) bolus. In this model, the concentration of the drug in the body, $C(t)$, at time $t$ after a single IV bolus dose $D$ is given by the exponential decay function:\n$$C(t) = C_0 \\exp(-kt)$$\nwhere $k$ is the first-order elimination rate constant and $C_0$ is the initial concentration at $t=0$. For a rapid IV bolus, the dose $D$ is assumed to instantly distribute throughout the volume of distribution, $V_{\\mathrm{typ}}$. Therefore, the initial concentration is $C_0 = D/V_{\\mathrm{typ}}$. This initial concentration is also the peak concentration after the first dose, denoted as $C_{\\mathrm{max, 1}}$.\n$$C_{\\mathrm{max, 1}} = \\frac{D}{V_{\\mathrm{typ}}}$$\nThe concentration at any time $t$ after the first dose is thus $C_1(t) = (D/V_{\\mathrm{typ}}) \\exp(-kt)$.\n\nThe drug is administered at a fixed dosing interval $\\tau$. According to the principle of superposition for a linear, time-invariant (LTI) system, the total concentration at any time is the sum of the concentrations resulting from each individual dose.\n\nThe peak concentration immediately after the first dose (at $t=0^+$) is $C_{\\mathrm{max, 1}}$.\nThe peak concentration immediately after the second dose (at $t=\\tau^+$) is the sum of the concentration from the new dose ($D/V_{\\mathrm{typ}}$) and the residual concentration remaining from the first dose at time $\\tau$.\n$$C_{\\mathrm{max, 2}} = \\frac{D}{V_{\\mathrm{typ}}} + C_1(\\tau) = \\frac{D}{V_{\\mathrm{typ}}} + \\frac{D}{V_{\\mathrm{typ}}}\\exp(-k\\tau) = \\frac{D}{V_{\\mathrm{typ}}} (1 + \\exp(-k\\tau))$$\nSimilarly, the peak concentration immediately after the third dose (at $t=2\\tau^+$) is the concentration from the new dose plus the residual concentrations from the first two doses. The first dose was given at $t=0$, so $2\\tau$ has elapsed. The second dose was given at $t=\\tau$, so $\\tau$ has elapsed.\n$$C_{\\mathrm{max, 3}} = \\frac{D}{V_{\\mathrm{typ}}} + \\frac{D}{V_{\\mathrm{typ}}}\\exp(-k(2\\tau)) + \\frac{D}{V_{\\mathrm{typ}}}\\exp(-k\\tau) = \\frac{D}{V_{\\mathrm{typ}}} (1 + \\exp(-k\\tau) + \\exp(-2k\\tau))$$\n\nBy extension, the peak concentration immediately after the $n$-th dose, administered at time $t=(n-1)\\tau$, is the sum of contributions from all $n$ doses:\n$$C_{\\mathrm{max, n}} = \\sum_{i=0}^{n-1} \\left( \\frac{D}{V_{\\mathrm{typ}}} \\exp(-ik\\tau) \\right) = \\frac{D}{V_{\\mathrm{typ}}} \\sum_{i=0}^{n-1} (\\exp(-k\\tau))^i$$\nThis is a finite geometric series with first term $a=1$, common ratio $r = \\exp(-k\\tau)$, and $n$ terms. The sum of this series is $\\frac{a(1-r^n)}{1-r}$.\n$$C_{\\mathrm{max, n}} = \\frac{D}{V_{\\mathrm{typ}}} \\left( \\frac{1 - (\\exp(-k\\tau))^n}{1 - \\exp(-k\\tau)} \\right) = \\frac{D}{V_{\\mathrm{typ}}} \\left( \\frac{1 - \\exp(-nk\\tau)}{1 - \\exp(-k\\tau)} \\right)$$\nSteady state is the condition reached after a sufficiently large number of doses, i.e., as $n \\to \\infty$. The steady-state peak concentration, $C_{\\mathrm{max, ss}}$, is the limit of $C_{\\mathrm{max, n}}$ as $n \\to \\infty$.\n$$C_{\\mathrm{max, ss}} = \\lim_{n \\to \\infty} C_{\\mathrm{max, n}} = \\lim_{n \\to \\infty} \\left[ \\frac{D}{V_{\\mathrm{typ}}} \\left( \\frac{1 - \\exp(-nk\\tau)}{1 - \\exp(-k\\tau)} \\right) \\right]$$\nSince $k>0$ and $\\tau>0$, the term $\\exp(-k\\tau)$ is a positive number less than $1$. Therefore, as $n \\to \\infty$, the term $\\exp(-nk\\tau) \\to 0$.\n$$C_{\\mathrm{max, ss}} = \\frac{D}{V_{\\mathrm{typ}}} \\left( \\frac{1 - 0}{1 - \\exp(-k\\tau)} \\right) = \\frac{D}{V_{\\mathrm{typ}}} \\left( \\frac{1}{1 - \\exp(-k\\tau)} \\right)$$\nThe accumulation ratio, $R_{\\mathrm{acc}}$, is defined as the ratio of the steady-state peak concentration to the peak concentration after the first dose.\n$$R_{\\mathrm{acc}} = \\frac{C_{\\mathrm{max, ss}}}{C_{\\mathrm{max, 1}}} = \\frac{\\frac{D}{V_{\\mathrm{typ}}} \\frac{1}{1 - \\exp(-k\\tau)}}{\\frac{D}{V_{\\mathrm{typ}}}}$$\nThis simplifies to the closed-form expression for the accumulation ratio as a function of $k$ and $\\tau$:\n$$R_{\\mathrm{acc}} = \\frac{1}{1 - \\exp(-k\\tau)}$$\n\nNext, we evaluate $R_{\\mathrm{acc}}$ for the given parameters: $\\mathrm{CL}_{\\mathrm{typ}} = 5.0\\,\\mathrm{L}\\,\\mathrm{h}^{-1}$, $V_{\\mathrm{typ}} = 50.0\\,\\mathrm{L}$, and $\\tau = 8.0\\,\\mathrm{h}$.\nFirst, we calculate the elimination rate constant $k$:\n$$k = \\frac{\\mathrm{CL}_{\\mathrm{typ}}}{V_{\\mathrm{typ}}} = \\frac{5.0\\,\\mathrm{L}\\,\\mathrm{h}^{-1}}{50.0\\,\\mathrm{L}} = 0.1\\,\\mathrm{h}^{-1}$$\nNow, we substitute the values of $k$ and $\\tau$ into the expression for $R_{\\mathrm{acc}}$:\n$$R_{\\mathrm{acc}} = \\frac{1}{1 - \\exp(-k\\tau)} = \\frac{1}{1 - \\exp(-(0.1\\,\\mathrm{h}^{-1})(8.0\\,\\mathrm{h}))} = \\frac{1}{1 - \\exp(-0.8)}$$\nNumerically, $\\exp(-0.8) \\approx 0.44932896$.\n$$R_{\\mathrm{acc}} = \\frac{1}{1 - 0.44932896} = \\frac{1}{0.55067104} \\approx 1.815933$$\nRounding to four significant figures, we get $R_{\\mathrm{acc}} \\approx 1.816$.\n\nFinally, we interpret the relationship between the elimination half-life, $t_{1/2}$, the dosing interval, $\\tau$, and the magnitude of accumulation.\nThe half-life is defined by $t_{1/2} = \\ln(2)/k$, which gives $k = \\ln(2)/t_{1/2}$. Substituting this into the expression for $R_{\\mathrm{acc}}$:\n$$R_{\\mathrm{acc}} = \\frac{1}{1 - \\exp(-\\frac{\\ln(2)}{t_{1/2}}\\tau)} = \\frac{1}{1 - \\exp(\\ln(2^{-\\tau/t_{1/2}}))} = \\frac{1}{1 - 2^{-\\tau/t_{1/2}}}$$\nThis expression shows that $R_{\\mathrm{acc}}$ is determined by the ratio of the dosing interval to the half-life, $\\tau/t_{1/2}$. Alternatively, one can consider the ratio of the half-life to the dosing interval, $t_{1/2}/\\tau$.\nIf the half-life is much longer than the dosing interval ($t_{1/2} \\gg \\tau$), then a very small fraction of the drug is eliminated between doses. This means the ratio $\\tau/t_{1/2}$ is small, making $2^{-\\tau/t_{1/2}}$ close to $1$, the denominator $1 - 2^{-\\tau/t_{1/2}}$ close to $0$, and thus $R_{\\mathrm{acc}}$ becomes very large. Substantial accumulation occurs.\nConversely, if the half-life is much shorter than the dosing interval ($t_{1/2} \\ll \\tau$), then most of the drug is eliminated before the next dose is administered. The ratio $\\tau/t_{1/2}$ is large, making $2^{-\\tau/t_{1/2}}$ close to $0$, the denominator close to $1$, and thus $R_{\\mathrm{acc}}$ approaches $1$. Minimal accumulation occurs.\nIn summary, the ratio of the drug's elimination half-life to the dosing interval governs the degree of accumulation at steady state. A large ratio ($t_{1/2}/\\tau \\gg 1$) implies significant accumulation, while a small ratio ($t_{1/2}/\\tau \\ll 1$) implies negligible accumulation.\nFor our specific case, $k=0.1\\,\\mathrm{h}^{-1}$, so $t_{1/2} = \\ln(2)/0.1 \\approx 6.93\\,\\mathrm{h}$. With $\\tau = 8.0\\,\\mathrm{h}$, the ratio $t_{1/2}/\\tau \\approx 6.93/8.0 \\approx 0.87$, which is close to $1$. A value of $R_{\\mathrm{acc}} \\approx 1.816$ indicates moderate accumulation, consistent with a dosing interval that is slightly longer than the half-life. If dosing had occurred exactly every half-life, $R_{\\mathrm{acc}}$ would be exactly $2$.", "answer": "$$\\boxed{1.816}$$", "id": "5046120"}, {"introduction": "A central task in PopPK modeling is to explain inter-individual variability by identifying patient-specific covariates that influence drug pharmacokinetics. The Likelihood Ratio Test (LRT) is a cornerstone statistical method for formally comparing a simpler 'base' model to a more complex one that includes a covariate. This practice provides a hands-on application of the LRT, demonstrating how to use the change in the objective function value to make a statistically-principled decision about including a covariate in your model [@problem_id:5046115].", "problem": "In a translational medicine study, a population pharmacokinetic (PopPK) analysis of a small-molecule therapeutic was conducted in $n=120$ adults using a one-compartment model with first-order elimination. Two nested nonlinear mixed-effects models were fit by maximum likelihood. The reduced model specifies a typical clearance $CL$ without any covariate effect, while the full model adds a single linear covariate effect (slope parameter) of standardized estimated glomerular filtration rate on the typical $CL$. The structural and random-effects specifications are otherwise identical, and regularity conditions for asymptotic likelihood-based inference are assumed to hold so that Wilks’s theorem applies and no boundary constraints are implicated. The maximum likelihood fits yielded objective function values equal to minus two times the maximized log-likelihood: $-2\\ln(\\mathcal{L}_{\\text{reduced}})=1523.6$ and $-2\\ln(\\mathcal{L}_{\\text{full}})=1516.9$. Using only fundamental likelihood principles and asymptotic theory appropriate for nested model comparison, assess whether adding the covariate is statistically justified at significance level $\\alpha=0.05$ and then determine the critical value of the chi-squared distribution with one degree of freedom corresponding to $\\alpha=0.05$. Report only this critical value as your final answer. Round your answer to four significant figures. Express the final answer as a unitless number.", "solution": "The problem requires an assessment of statistical significance for including a covariate in a population pharmacokinetic (PopPK) model, based on the change in the objective function value, and then to provide the corresponding critical value used for this assessment. The appropriate statistical method for comparing two nested models fit by maximum likelihood is the Likelihood Ratio Test (LRT).\n\nThe problem states that two nested models were fit: a reduced model without the covariate and a full model including the covariate. The objective function value (OFV) is given as minus two times the maximized log-likelihood, $OFV = -2\\ln(\\mathcal{L})$. The values provided are:\n- $OFV_{\\text{reduced}} = -2\\ln(\\mathcal{L}_{\\text{reduced}}) = 1523.6$\n- $OFV_{\\text{full}} = -2\\ln(\\mathcal{L}_{\\text{full}}) = 1516.9$\n\nThe Likelihood Ratio Test statistic, let's call it $\\Lambda$, is calculated as the difference between the OFV of the reduced model and the OFV of the full model. It is critical that the OFV of the full model, which has more parameters and thus fits the data at least as well, is less than or equal to the OFV of the reduced model. The given values $1516.9 < 1523.6$ are consistent with this principle.\n\nThe test statistic $\\Lambda$ is calculated as:\n$$\n\\Lambda = OFV_{\\text{reduced}} - OFV_{\\text{full}}\n$$\nSubstituting the given values:\n$$\n\\Lambda = 1523.6 - 1516.9 = 6.7\n$$\n\nThe problem states that regularity conditions hold and Wilks's theorem applies. According to Wilks's theorem, under the null hypothesis ($H_0$) that the simpler (reduced) model is the true model (i.e., the covariate effect is zero), the test statistic $\\Lambda$ asymptotically follows a chi-squared ($\\chi^2$) distribution. The degrees of freedom ($df$) of this $\\chi^2$ distribution are equal to the difference in the number of estimated parameters between the full and reduced models.\n\nThe full model adds a \"single linear covariate effect (slope parameter)\" to the reduced model. Therefore, the full model has one more parameter than the reduced model.\n$$\ndf = (\\text{number of parameters in full model}) - (\\text{number of parameters in reduced model}) = 1\n$$\nSo, under $H_0$, the test statistic $\\Lambda$ follows a $\\chi^2$ distribution with $1$ degree of freedom, denoted $\\chi^2_1$.\n\nTo assess whether adding the covariate is statistically justified at a significance level $\\alpha = 0.05$, we compare the calculated test statistic $\\Lambda$ to the critical value from the $\\chi^2_1$ distribution. The critical value, which we can denote $c$, is the value that is exceeded with probability $\\alpha$. It is the $(1-\\alpha)$ quantile of the distribution. For $\\alpha = 0.05$, we need the $0.95$ quantile of the $\\chi^2_1$ distribution.\n$$\nP(\\chi^2_1 > c) = 0.05\n$$\nThe decision rule is to reject $H_0$ if $\\Lambda > c$. Since our calculated test statistic is $\\Lambda = 6.7$, we would compare this value to $c$.\n\nThe problem asks specifically for the value of this critical value, $c$. The $\\chi^2$ distribution with one degree of freedom is equivalent to the square of a standard normal distribution, $Z^2$, where $Z \\sim N(0, 1)$. The critical value $c$ for a one-tailed test on $\\chi^2_1$ at level $\\alpha$ corresponds to the square of the critical value $z$ from a two-tailed test on the standard normal distribution at the same level $\\alpha$. Specifically, $P(\\chi^2_1 > c) = P(Z^2 > c) = P(|Z| > \\sqrt{c}) = \\alpha$. The standard normal critical value for $\\alpha = 0.05$ is $z_{\\alpha/2} = z_{0.025} \\approx 1.95996$.\nThe critical value $c$ is therefore:\n$$\nc = (z_{0.025})^2 \\approx (1.95996)^2 \\approx 3.8414588...\n$$\nThis is a standard value found in statistical tables for the $\\chi^2$ distribution.\n\nBased on this, the assessment would be that since $\\Lambda = 6.7 > 3.841...$, the null hypothesis is rejected, and the inclusion of the estimated glomerular filtration rate as a covariate on clearance is statistically justified at the $\\alpha=0.05$ level.\n\nThe problem asks for the critical value itself, rounded to four significant figures.\n$$\nc \\approx 3.8414588...\n$$\nRounding to four significant figures gives $3.841$.\n\nThis is the critical value of the chi-squared distribution with one degree of freedom corresponding to a significance level of $\\alpha = 0.05$.", "answer": "$$\\boxed{3.841}$$", "id": "5046115"}, {"introduction": "A successful PopPK model must not only describe the data used to build it, but also accurately predict outcomes in new populations. This exercise simulates the critical process of external model validation, a capstone activity in the modeling workflow. You will use the model to generate simulation-based prediction intervals for key pharmacokinetic metrics and assess whether observed data from a new cohort fall within these expected ranges, providing a robust test of the model's predictive power [@problem_id:5046163].", "problem": "A translational medicine scientist is externally validating a population pharmacokinetic (PopPK) model by comparing observed cohort-level distributions of peak concentration and exposure to model-based simulated prediction intervals. The model is a one-compartment oral absorption model with first-order absorption and first-order elimination. Let $A_{g}(t)$ denote the drug amount in the gastrointestinal tract at time $t$ and $A_{c}(t)$ denote the drug amount in the central compartment at time $t$. The structural model is given by the mass balance ordinary differential equations\n$$\n\\frac{dA_{g}(t)}{dt} = -k_{a}A_{g}(t), \\quad \\frac{dA_{c}(t)}{dt} = k_{a}A_{g}(t) - k_{e}A_{c}(t),\n$$\nwith initial conditions $A_{g}(0)=F\\cdot D$ and $A_{c}(0)=0$, where $F$ is bioavailability and $D$ is dose. The elimination rate constant is $k_{e} = \\frac{CL}{V}$, where $CL$ is clearance and $V$ is volume of distribution. The concentration is $C(t) = \\frac{A_{c}(t)}{V}$. The two scalar metrics of interest are the maximum concentration $C_{\\max} = \\max_{t \\ge 0} C(t)$ and the exposure quantified by the area under the concentration–time curve from time $0$ to infinity $AUC = \\int_{0}^{\\infty} C(t)\\,dt$. Inter-individual variability is modeled on the log scale. For subject $i$ with body weight $WT_{i}$ (in $\\mathrm{kg}$), the individual parameters follow allometric scaling with lognormal inter-individual variability,\n$$\nCL_{i} = \\theta_{CL}\\left(\\frac{WT_{i}}{70}\\right)^{0.75} \\exp(\\eta_{CL,i}), \\quad\nV_{i} = \\theta_{V}\\left(\\frac{WT_{i}}{70}\\right)^{1} \\exp(\\eta_{V,i}), \\quad\nk_{a,i} = \\theta_{k_{a}} \\exp(\\eta_{k_{a},i}),\n$$\nwhere $\\eta_{CL,i} \\sim \\mathcal{N}(0,\\omega_{CL}^{2})$, $\\eta_{V,i} \\sim \\mathcal{N}(0,\\omega_{V}^{2})$, and $\\eta_{k_{a},i} \\sim \\mathcal{N}(0,\\omega_{k_{a}}^{2})$, independent across parameters and subjects. Bioavailability $F$ is assumed known and constant.\n\nYou must implement an external validation procedure by forward-simulating virtual subjects from the fitted PopPK model and comparing the observed cohort-level distributions of $C_{\\max}$ and $AUC$ to simulated prediction intervals for the corresponding cohort quantiles. The prediction intervals are constructed by repeatedly drawing simulated cohorts with the same covariate set (the same body weights) under the model, computing the cohort quantiles, and then taking the central interval defined by the lower and upper $\\alpha/2$ and $1-\\alpha/2$ quantiles of these cohort-quantile distributions.\n\nThe program must implement the following, starting only from the model definitions above and standard calculus and probability:\n\n- Derive and compute $C(t)$ from the mass balance model and use it to compute $C_{\\max}$ for each subject. If the analytical maximizer exists under the model assumptions, you may use it; otherwise, compute the maximum concentration numerically over a sufficiently dense, fixed time grid on $[0,T_{\\max}]$ with $T_{\\max}$ chosen large enough to approximate the global maximum reliably. \n- Derive and compute $AUC$ from first principles using the definition as a time integral and the structural model. You may use an analytical result if derived from the model.\n- Use the specified inter-individual variability to simulate many virtual subjects for a given cohort covariate set (body weights), matching the external validation covariate distribution by exact replication of the observed weights across a large pool of simulated subjects. Then form many replicate virtual cohorts by sampling with replacement from this pool, each replicate cohort having the same number of subjects as observed. For each replicate cohort, compute the cohort quantiles at probabilities $p \\in \\{0.1, 0.5, 0.9\\}$ for both $C_{\\max}$ and $AUC$. Finally, define the central $90\\%$ prediction interval for each cohort quantile as the $0.05$ and $0.95$ quantiles across replicate cohorts.\n- For each observed cohort, compute the empirical quantiles of the observed subject-level $C_{\\max}$ and $AUC$ at probabilities $p \\in \\{0.1, 0.5, 0.9\\}$.\n- For each metric ($C_{\\max}$ and $AUC$) and each probability $p \\in \\{0.1,0.5,0.9\\}$, return a boolean indicating whether the observed cohort quantile lies within the corresponding simulated $90\\%$ prediction interval (inclusive of endpoints).\n\nPhysical and numerical specifications:\n\n- Use dose $D$ in $\\mathrm{mg}$ and report concentration in $\\mathrm{mg/L}$ and exposure in $\\mathrm{mg\\cdot h/L}$. Use time in $\\mathrm{h}$ and rate constants in $\\mathrm{h^{-1}}$. Express the final boolean outputs as dimensionless values without units.\n- The model parameters are fixed at $F = 1$, $\\theta_{CL} = 5\\,\\mathrm{L/h}$, $\\theta_{V} = 50\\,\\mathrm{L}$, $\\theta_{k_{a}} = 1.2\\,\\mathrm{h^{-1}}$, $\\omega_{CL} = 0.25$, $\\omega_{V} = 0.25$, and $\\omega_{k_{a}} = 0.35$. Use dose $D = 100\\,\\mathrm{mg}$ for all subjects.\n- For numerical maximization of $C(t)$ when needed, use a fixed time grid on $[0,48]\\,\\mathrm{h}$ with a resolution no coarser than $\\Delta t = 0.024\\,\\mathrm{h}$.\n- For the quantile calculations, use the standard definition where the $p$-quantile is the smallest value $q$ such that at least a proportion $p$ of the data is less than or equal to $q$, implemented with linear interpolation as needed.\n\nTest suite and required output format:\n\n- There are three test cohorts. For each cohort, the observed data include the body weights in $\\mathrm{kg}$, the observed $C_{\\max}$ values in $\\mathrm{mg/L}$, and the observed $AUC$ values in $\\mathrm{mg\\cdot h/L}$.\n\nCohort A:\n- Weights (kg): $[60, 65, 70, 75, 80, 55, 90, 72, 68, 85, 77, 62]$.\n- Observed $C_{\\max}$ (mg/L): $[1.70, 1.62, 1.55, 1.48, 1.42, 1.78, 1.30, 1.52, 1.58, 1.36, 1.46, 1.66]$.\n- Observed $AUC$ (mg·h/L): $[22.44, 21.14, 20.00, 18.99, 18.10, 23.96, 16.57, 19.58, 20.44, 17.29, 18.62, 21.91]$.\n\nCohort B:\n- Weights (kg): $[60, 65, 70, 75, 80, 55, 90, 72, 68, 85, 77, 62]$.\n- Observed $C_{\\max}$ (mg/L): $[2.38, 2.27, 2.17, 2.07, 1.99, 2.49, 1.82, 2.13, 2.21, 1.90, 2.04, 2.32]$.\n- Observed $AUC$ (mg·h/L): $[31.42, 29.60, 28.00, 26.59, 25.34, 33.54, 23.20, 27.41, 28.62, 24.20, 26.07, 30.67]$.\n\nCohort C:\n- Weights (kg): $[50, 100, 70, 55, 95, 80]$.\n- Observed $C_{\\max}$ (mg/L): $[1.90, 1.25, 1.55, 1.77, 1.30, 1.41]$.\n- Observed $AUC$ (mg·h/L): $[25.90, 15.10, 20.20, 24.30, 15.70, 18.20]$.\n\n- Your program must:\n    - Simulate a large pool of virtual subjects by exact replication of the observed weights per cohort, with independent draws of $\\eta$ for each replication, to approximate the PopPK-predicted subject-level distributions of $C_{\\max}$ and $AUC$.\n    - Generate many replicate virtual cohorts by sampling with replacement from this pool, each with the same number of subjects as the observed cohort, to approximate the sampling distribution of the cohort quantiles at probabilities $p \\in \\{0.1,0.5,0.9\\}$.\n    - Construct the central $90\\%$ prediction interval for each cohort quantile using the $0.05$ and $0.95$ quantiles across replicate cohorts.\n    - Compute, for each cohort and for each metric ($C_{\\max}$ and $AUC$), a boolean indicator for each $p \\in \\{0.1,0.5,0.9\\}$ that evaluates to true if the observed cohort quantile lies within the simulated $90\\%$ prediction interval (inclusive), and false otherwise.\n\n- Final output format: Your program should produce a single line of output containing a list of three elements, one per cohort (A, B, C), where each element is a list of six boolean values in the order $[C_{\\max}@0.1, C_{\\max}@0.5, C_{\\max}@0.9, AUC@0.1, AUC@0.5, AUC@0.9]$. The output must be printed as a single Python-style list literal, for example, $[[\\text{True},\\text{False},\\dots],[\\dots],[\\dots]]$ on a single line with no additional text.", "solution": "The problem requires the implementation of an external validation procedure for a given population pharmacokinetic (PopPK) model. This process involves comparing observed clinical trial data to predictions generated by the model through stochastic simulation. The core of the task is to determine if the observed distributions of key pharmacokinetic (PK) metrics, specifically maximum concentration ($C_{\\max}$) and total exposure ($AUC$), are consistent with the model's predictions.\n\nFirst, we must establish a firm theoretical foundation by deriving the analytical solutions for the concentration-time profile $C(t)$ and the metrics of interest, $C_{\\max}$ and $AUC$. The structural model is a one-compartment model with first-order oral absorption, described by the following system of linear ordinary differential equations:\n$$\n\\frac{dA_{g}(t)}{dt} = -k_{a}A_{g}(t)\n$$\n$$\n\\frac{dA_{c}(t)}{dt} = k_{a}A_{g}(t) - k_{e}A_{c}(t)\n$$\nwith initial conditions $A_{g}(0)=F \\cdot D$ and $A_{c}(0)=0$. Here, $A_{g}(t)$ is the amount of drug in the gastrointestinal tract, $A_{c}(t)$ is the amount in the central compartment, $D$ is the dose, $F$ is the bioavailability, $k_{a}$ is the absorption rate constant, and $k_{e}$ is the elimination rate constant.\n\nThe solution to the first equation for $A_g(t)$ is $A_{g}(t) = F D e^{-k_{a}t}$. Substituting this into the second equation yields a first-order linear ODE for $A_c(t)$, which can be solved using an integrating factor. Assuming $k_{a} \\neq k_{e}$, the solution for the amount of drug in the central compartment is the well-known Bateman function:\n$$\nA_{c}(t) = \\frac{k_{a}F D}{k_{a} - k_{e}}(e^{-k_{e}t} - e^{-k_{a}t})\n$$\nThe plasma concentration is $C(t) = A_{c}(t)/V$, where $V$ is the volume of distribution:\n$$\nC(t) = \\frac{F D}{V} \\frac{k_{a}}{k_{a} - k_{e}}(e^{-k_{e}t} - e^{-k_{a}t})\n$$\n\nNext, we derive the analytical expressions for $AUC$ and $C_{\\max}$. The area under the concentration-time curve, $AUC$, is the integral of $C(t)$ from $t=0$ to $t=\\infty$:\n$$\nAUC = \\int_{0}^{\\infty} C(t)\\,dt = \\frac{F D k_{a}}{V(k_{a} - k_{e})} \\int_{0}^{\\infty} (e^{-k_{e}t} - e^{-k_{a}t})\\,dt\n$$\n$$\nAUC = \\frac{F D k_{a}}{V(k_{a} - k_{e})} \\left[ -\\frac{1}{k_{e}}e^{-k_{e}t} + \\frac{1}{k_{a}}e^{-k_{a}t} \\right]_{0}^{\\infty} = \\frac{F D k_{a}}{V(k_{a} - k_{e})} \\left( 0 - \\left(-\\frac{1}{k_{e}} + \\frac{1}{k_{a}}\\right) \\right) = \\frac{F D k_{a}}{V(k_{a} - k_{e})} \\left( \\frac{k_{a}-k_{e}}{k_{a}k_{e}} \\right)\n$$\nThis simplifies to a fundamental relationship in pharmacokinetics, $AUC = \\frac{F D}{V k_{e}}$. Since the elimination rate constant $k_e$ is defined as the ratio of clearance ($CL$) to volume of distribution ($V$), i.e., $k_e = CL/V$, the expression for $AUC$ further simplifies to:\n$$\nAUC = \\frac{F D}{CL}\n$$\nThis result is robust and holds even for the special case where $k_a = k_e$.\n\nThe maximum concentration, $C_{\\max}$, occurs at time $t_{\\max}$ where the derivative $\\frac{dC(t)}{dt}$ is zero. Solving $\\frac{dC(t)}{dt}=0$ for $t$ gives:\n$$\nt_{\\max} = \\frac{\\ln(k_{a}/k_{e})}{k_{a} - k_{e}}\n$$\nSubstituting $t_{\\max}$ back into the equation for $C(t)$ gives $C_{\\max} = C(t_{\\max})$. This can be shown to simplify to the compact form:\n$$\nC_{\\max} = \\frac{F D}{V} \\left( \\frac{k_{a}}{k_{e}} \\right)^{\\frac{k_{e}}{k_{e}-k_{a}}}\n$$\nIn the specific case where $k_{a} = k_{e}$, the concentration equation is $C(t) = \\frac{F D k_{a}}{V} t e^{-k_{a}t}$. For this case, $t_{\\max} = 1/k_a$ and $C_{\\max} = \\frac{F D}{V} e^{-1}$. The general formula for $C_{\\max}$ correctly converges to this limit as $k_e \\to k_a$. Using these analytical formulas for $AUC$ and $C_{\\max}$ is more accurate and computationally efficient than numerical integration or optimization.\n\nThe validation procedure is executed as follows:\n1.  **Simulate a Virtual Population**: For each observed cohort, we create a large virtual population. This is done by replicating the vector of observed subject body weights ($WT$) many times. For each virtual subject entry, we generate individual PK parameters ($CL_i, V_i, k_{a,i}$) using the specified PopPK model structure. This involves applying allometric scaling based on weight and incorporating inter-individual variability by drawing random effects ($\\eta_{CL,i}, \\eta_{V,i}, \\eta_{k_{a},i}$) from their specified normal distributions, $\\mathcal{N}(0, \\omega^2)$. Specifically, for subject $i$ with weight $WT_i$:\n    $$\n    CL_{i} = \\theta_{CL}\\left(\\frac{WT_{i}}{70}\\right)^{0.75} \\exp(\\eta_{CL,i}), \\quad V_{i} = \\theta_{V}\\left(\\frac{WT_{i}}{70}\\right)^{1} \\exp(\\eta_{V,i}), \\quad k_{a,i} = \\theta_{k_{a}} \\exp(\\eta_{k_{a},i})\n    $$\n    Using these individual parameters, we calculate the corresponding $C_{\\max,i}$ and $AUC_i$ for each virtual subject, thereby forming a large pool of model-predicted outcomes.\n\n2.  **Simulate Replicate Cohorts**: We generate a large number of replicate virtual cohorts. Each replicate is formed by sampling with replacement from the large virtual population created in the previous step. The size of each replicate cohort is identical to the number of subjects in the original observed cohort. This process mimics the statistical variability inherent in conducting the clinical study multiple times.\n\n3.  **Compute Distribution of Cohort Quantiles**: For each simulated replicate cohort, we calculate the cohort-level quantiles for both $C_{\\max}$ and $AUC$ at the specified probabilities $p \\in \\{0.1, 0.5, 0.9\\}$. This yields, for each metric and probability level, a distribution of simulated cohort quantiles.\n\n4.  **Construct Prediction Intervals (PIs)**: The central $90\\%$ prediction interval for each cohort quantile is constructed by finding the $5^{th}$ and $95^{th}$ percentiles of its distribution across the replicate cohorts. This interval represents the range within which the model predicts the observed cohort quantile should lie with $90\\%$ probability.\n\n5.  **Perform Validation Check**: We compute the empirical quantiles from the observed $C_{\\max}$ and $AUC$ data for each cohort. Finally, for each of the six metrics (three quantiles for $C_{\\max}$, three for $AUC$), we check if the observed quantile falls within the corresponding $90\\%$ prediction interval (inclusive of the endpoints). The result is a boolean value (True/False) for each check.\n\nThis entire procedure is systematically applied to each of the three test cohorts provided, and the boolean results are collected and formatted as specified. The use of vectorized operations in `numpy` allows for efficient computation over the large number of simulated subjects and replicates.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the PopPK model validation for all cohorts.\n    \"\"\"\n    \n    # Use a fixed seed for reproducibility of the stochastic simulation.\n    np.random.seed(0)\n\n    # --- Model and Simulation Parameters ---\n    # Populational typical values (thetas)\n    THETA_CL = 5.0   # Clearance (L/h)\n    THETA_V = 50.0    # Volume of distribution (L)\n    THETA_KA = 1.2    # Absorption rate constant (h^-1)\n\n    # Inter-individual variability (omegas, as standard deviations)\n    OMEGA_CL = 0.25\n    OMEGA_V = 0.25\n    OMEGA_KA = 0.35\n\n    # Dosing and bioavailability\n    F = 1.0         # Bioavailability (unitless)\n    D = 100.0       # Dose (mg)\n\n    # Simulation settings\n    N_POOL_MULT = 1000   # Multiplier for the size of the virtual subject pool\n    N_REPLICATES = 1000  # Number of replicate cohorts to simulate\n\n    # Quantiles for analysis\n    QUANTILE_PROBS = [0.1, 0.5, 0.9]\n    PI_PROBS = [0.05, 0.95]\n    \n    # --- Test Cohort Data ---\n    COHORTS = {\n        \"A\": {\n            \"weights\": np.array([60, 65, 70, 75, 80, 55, 90, 72, 68, 85, 77, 62]),\n            \"obs_cmax\": np.array([1.70, 1.62, 1.55, 1.48, 1.42, 1.78, 1.30, 1.52, 1.58, 1.36, 1.46, 1.66]),\n            \"obs_auc\": np.array([22.44, 21.14, 20.00, 18.99, 18.10, 23.96, 16.57, 19.58, 20.44, 17.29, 18.62, 21.91]),\n        },\n        \"B\": {\n            \"weights\": np.array([60, 65, 70, 75, 80, 55, 90, 72, 68, 85, 77, 62]),\n            \"obs_cmax\": np.array([2.38, 2.27, 2.17, 2.07, 1.99, 2.49, 1.82, 2.13, 2.21, 1.90, 2.04, 2.32]),\n            \"obs_auc\": np.array([31.42, 29.60, 28.00, 26.59, 25.34, 33.54, 23.20, 27.41, 28.62, 24.20, 26.07, 30.67]),\n        },\n        \"C\": {\n            \"weights\": np.array([50, 100, 70, 55, 95, 80]),\n            \"obs_cmax\": np.array([1.90, 1.25, 1.55, 1.77, 1.30, 1.41]),\n            \"obs_auc\": np.array([25.90, 15.10, 20.20, 24.30, 15.70, 18.20]),\n        }\n    }\n    \n    def calculate_pk_metrics(cl, v, ka):\n        \"\"\"\n        Calculates Cmax and AUC for sets of individual PK parameters using analytical formulas.\n        This function is vectorized to efficiently handle large arrays of parameters.\n        \"\"\"\n        ke = cl / v\n        \n        # AUC calculation: AUC = F * D / CL\n        auc = (F * D) / cl\n        \n        # Cmax calculation\n        cmax = np.zeros_like(ka)\n        \n        # Handle the case where ka is numerically equal to ke to avoid division by zero.\n        mask_neq = np.abs(ka - ke) > 1e-9\n        \n        # Case 1: ka != ke\n        if np.any(mask_neq):\n            v_neq = v[mask_neq]\n            ka_neq = ka[mask_neq]\n            ke_neq = ke[mask_neq]\n            # Use the formula: Cmax = (F*D/V) * (ka/ke)^(ke/(ke-ka))\n            exponent = ke_neq / (ke_neq - ka_neq)\n            cmax[mask_neq] = (F * D / v_neq) * np.power(ka_neq / ke_neq, exponent)\n\n        # Case 2: ka == ke\n        if np.any(~mask_neq):\n            v_eq = v[~mask_neq]\n            # Use the formula: Cmax = (F*D/V) * exp(-1)\n            cmax[~mask_neq] = (F * D / v_eq) * np.exp(-1.0)\n            \n        return cmax, auc\n    \n\n    def run_validation_for_cohort(cohort_data):\n        \"\"\"\n        Performs the full validation procedure for a single cohort.\n        \"\"\"\n        weights = cohort_data[\"weights\"]\n        obs_cmax = cohort_data[\"obs_cmax\"]\n        obs_auc = cohort_data[\"obs_auc\"]\n        n_subjects_cohort = len(weights)\n        \n        # 1. Create a large virtual subject pool based on the cohort's weight distribution.\n        pool_weights = np.tile(weights, N_POOL_MULT)\n        total_pool_size = len(pool_weights)\n        \n        # Generate random effects for the entire pool.\n        eta_cl = np.random.normal(0, OMEGA_CL, total_pool_size)\n        eta_v = np.random.normal(0, OMEGA_V, total_pool_size)\n        eta_ka = np.random.normal(0, OMEGA_KA, total_pool_size)\n        \n        # Calculate individual parameters for the pool using allometric scaling and random effects.\n        cl_pool = THETA_CL * np.power(pool_weights / 70.0, 0.75) * np.exp(eta_cl)\n        v_pool = THETA_V * np.power(pool_weights / 70.0, 1.0) * np.exp(eta_v)\n        ka_pool = THETA_KA * np.exp(eta_ka)\n        \n        # Calculate Cmax and AUC for the entire pool.\n        pool_cmax, pool_auc = calculate_pk_metrics(cl_pool, v_pool, ka_pool)\n        \n        # 2. Generate replicate cohorts by sampling from the pool.\n        replicate_indices = np.random.choice(total_pool_size, size=(N_REPLICATES, n_subjects_cohort), replace=True)\n        replicate_cmax_cohorts = pool_cmax[replicate_indices]\n        replicate_auc_cohorts = pool_auc[replicate_indices]\n        \n        # 3. Compute the distribution of cohort quantiles.\n        rep_cmax_quantiles = np.quantile(replicate_cmax_cohorts, q=QUANTILE_PROBS, axis=1).T\n        rep_auc_quantiles = np.quantile(replicate_auc_cohorts, q=QUANTILE_PROBS, axis=1).T\n        \n        # 4. Construct the 90% prediction intervals for the cohort quantiles.\n        pi_cmax = np.quantile(rep_cmax_quantiles, q=PI_PROBS, axis=0)\n        pi_auc = np.quantile(rep_auc_quantiles, q=PI_PROBS, axis=0)\n        \n        # 5. Calculate observed cohort quantiles and perform the validation check.\n        obs_cmax_quantiles = np.quantile(obs_cmax, q=QUANTILE_PROBS)\n        obs_auc_quantiles = np.quantile(obs_auc, q=QUANTILE_PROBS)\n        \n        results = []\n        # Check Cmax quantiles against their PIs.\n        for i in range(len(QUANTILE_PROBS)):\n            is_in_interval = (pi_cmax[0, i] <= obs_cmax_quantiles[i] <= pi_cmax[1, i])\n            results.append(bool(is_in_interval))\n            \n        # Check AUC quantiles against their PIs.\n        for i in range(len(QUANTILE_PROBS)):\n            is_in_interval = (pi_auc[0, i] <= obs_auc_quantiles[i] <= pi_auc[1, i])\n            results.append(bool(is_in_interval))\n            \n        return results\n\n    all_cohort_results = []\n    for cohort_name in [\"A\", \"B\", \"C\"]:\n        cohort_results = run_validation_for_cohort(COHORTS[cohort_name])\n        all_cohort_results.append(cohort_results)\n\n    # Format the final output string to match the required Python list literal format without spaces.\n    inner_strs = [f\"[{','.join(map(str, res))}]\" for res in all_cohort_results]\n    final_output = f\"[{','.join(inner_strs)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "5046163"}]}