{"hands_on_practices": [{"introduction": "This exercise tackles a fundamental question of experimental feasibility in proteomics. Before committing resources to a large-scale study, it is critical to estimate whether the available starting material is sufficient to achieve the desired analytical depth. This calculation connects instrument performance metrics, such as the limit of detection ($LOD$), with expected biological sample yields to determine the minimum number of cells required for a successful immunopeptidomics experiment [@problem_id:5022969].", "problem": "In an immunopeptidomics workflow aimed at translational target discovery, Human Leukocyte Antigen (HLA) class I peptides are isolated from a tumor cell population and analyzed by mass spectrometry. Empirical yields for total HLA peptide amount obtained from an input of $10^{7}$ cells are commonly reported in the range $1$ to $5$ femtomole (fmol). The instrument’s limit of detection per peptide is $50$ attomole (amol). Sampling efficiency, defined as the fraction of peptides above threshold that are stochastically selected and successfully identified in a single run, is $0.5$. Assume the following: (i) the total isolated HLA peptide amount is distributed uniformly across the unique peptides present, (ii) a peptide is considered detected only if its amount is at least the instrument limit of detection, and (iii) the sampling efficiency applies as a multiplicative factor to the number of above-threshold peptides that will be identified. To minimize the required input, use the most favorable yield within the stated range.\n\nCompute the minimum number of cells required so that $2{,}000$ unique peptides are detected under these conditions. Express your final answer as the number of cells.", "solution": "The problem is determined to be valid as it is scientifically grounded in the principles of proteomics and mass spectrometry, is well-posed with a unique solution derivable from the provided data, and is expressed in objective, formal language. We proceed with the solution.\n\nLet $N_{identified}$ be the target number of identified unique peptides, which is given as $N_{identified} = 2000$.\nLet $\\eta$ be the sampling efficiency, given as $\\eta = 0.5$.\nLet $LOD$ be the instrument's limit of detection per peptide, given as $LOD = 50$ attomoles (amol).\nLet $N_{above\\_LOD}$ be the number of unique peptides with an amount greater than or equal to the $LOD$. The number of peptides that are successfully identified is described by the relationship:\n$$N_{identified} = \\eta \\times N_{above\\_LOD}$$\nTo identify $2000$ peptides, the number of peptides above the detection limit must be:\n$$N_{above\\_LOD} = \\frac{N_{identified}}{\\eta} = \\frac{2000}{0.5} = 4000$$\n\nThe problem states an assumption that the total isolated HLA peptide amount, $A_{total}$, is distributed uniformly across all unique peptides present, a number we denote as $N_{unique}$. This implies that the amount per peptide, $A_{peptide}$, is the same for all species: $A_{peptide} = \\frac{A_{total}}{N_{unique}}$. For any peptides to be detected, their amount must be at least the $LOD$. Because of the uniform distribution, if one peptide species is above the $LOD$, all peptide species are. Therefore, to have any peptides detected, we require all $N_{unique}$ species to have an amount of at least $LOD$. This leads to the conclusion that the number of unique peptide species required in the sample must be equal to the required number of species above the detection limit:\n$$N_{unique} = N_{above\\_LOD} = 4000$$\n\nThe minimum total peptide amount required, $A_{total, min}$, is achieved when the amount of each unique peptide is exactly at the limit of detection, i.e., $A_{peptide} = LOD$.\n$$A_{total, min} = N_{unique} \\times LOD$$\nSubstituting the numerical values:\n$$A_{total, min} = 4000 \\times 50 \\, \\text{amol} = 200000 \\, \\text{amol}$$\nTo be consistent with the units of the yield provided in the problem, we convert this amount from attomoles to femtomoles (fmol), using the conversion factor $1 \\, \\text{fmol} = 1000 \\, \\text{amol}$.\n$$A_{total, min} = 200000 \\, \\text{amol} \\times \\frac{1 \\, \\text{fmol}}{1000 \\, \\text{amol}} = 200 \\, \\text{fmol}$$\n\nThe yield of peptides is given in a range of $1$ to $5$ fmol per a reference number of cells, $N_{cells, ref} = 10^7$. Let $Y$ represent the yield in units of fmol per $10^7$ cells. The total amount of peptide, $A_{total}$, obtained from a number of cells $N_{cells}$ is given by the proportional relationship:\n$$A_{total} = \\left(\\frac{Y}{N_{cells, ref}}\\right) \\times N_{cells}$$\nWe can rearrange this equation to solve for the required number of cells, $N_{cells}$:\n$$N_{cells} = \\frac{A_{total} \\times N_{cells, ref}}{Y}$$\nThe problem asks for the minimum number of cells required. To minimize $N_{cells}$ for a fixed required peptide amount ($A_{total, min}$), we must maximize the yield, $Y$. From the given range, $[1, 5]$ fmol, the maximum yield is $Y_{max} = 5$ fmol per $10^7$ cells.\n\nFinally, we substitute the values for $A_{total, min}$, $N_{cells, ref}$, and $Y_{max}$ into the equation for $N_{cells}$:\n$$N_{cells} = \\frac{A_{total, min} \\times N_{cells, ref}}{Y_{max}} = \\frac{200 \\, \\text{fmol} \\times 10^7 \\, \\text{cells}}{5 \\, \\text{fmol}}$$\nThe units of fmol cancel, yielding the number of cells.\n$$N_{cells} = \\frac{200}{5} \\times 10^7 = 40 \\times 10^7 = 4 \\times 10^8$$\nThus, the minimum number of cells required to detect $2000$ unique peptides is $4 \\times 10^8$.", "answer": "$$\\boxed{4 \\times 10^{8}}$$", "id": "5022969"}, {"introduction": "Moving from the technical feasibility of a single measurement to the statistical validity of a whole study, this practice addresses the crucial step of power analysis. A study that is underpowered is wasteful and potentially unethical, as it is unlikely to detect a true biological effect. This exercise requires you to derive the sample size formula from first principles, reinforcing the statistical theory behind study design and applying it to a common phosphoproteomics scenario to determine the number of subjects needed per cohort [@problem_id:5022986].", "problem": "A translational phosphoproteomics study is being planned to discover actionable targets by contrasting phosphosite abundance between a disease cohort and a matched control cohort. Quantitative measurements (for example, from tandem mass spectrometry) are log-transformed base 2 to stabilize variance, so that a log base 2 fold-change of $1$ corresponds to a doubling in abundance. A pilot study performed under the same sample preparation and acquisition conditions provides a pooled within-group variance estimate on the log base 2 scale of $s_{p}^{2} = 0.50$ for a candidate phosphosite.\n\nYou will design a two-arm study with equal per-group sample sizes, using a two-sample $t$-test framework to detect a true difference in group means of $\\delta = 1$ on the log base 2 scale. Assume independent samples, equal variances across groups, and that the sampling distribution of the difference of sample means is well approximated by a Gaussian distribution due to the Central Limit Theorem. The significance level is two-sided $\\alpha = 0.05$, and the target statistical power is $0.80$.\n\nStarting from the definitions of Type I and Type II error and the sampling distribution of the difference of means under the null and alternative, derive the Gaussian-approximate per-group sample size $n$ needed to achieve the specified power at the specified $\\alpha$ without invoking any pre-memorized sample size formulas. Then, using the pilot variance estimate $s_{p}^{2}$ as the common variance in the approximation, compute the numerical value of $n$.\n\nUse the following rounding requirements: round any standard normal quantiles to four significant figures, and report the final per-group sample size $n$ to four significant figures. Do not round $n$ to an integer; report it as a real number.", "solution": "The user has provided a problem that requires the derivation of a sample size formula and its subsequent numerical evaluation.\n\n### Step 1: Extract Givens\n-   **Study Design**: Two-arm study, disease vs. control.\n-   **Data Transformation**: Log-transformed base $2$.\n-   **Statistical Test**: Two-sample $t$-test framework, with a Gaussian (normal) approximation.\n-   **Sample Sizes**: Equal per-group sample sizes, $n_1 = n_2 = n$.\n-   **Assumptions**: Independent samples, equal variances.\n-   **Variance Estimate**: Pooled within-group variance on log base $2$ scale, $s_{p}^{2} = 0.50$. This will be used as the common variance $\\sigma^2$.\n-   **Effect Size**: True difference in group means to detect, $\\delta = 1$.\n-   **Significance Level**: Two-sided $\\alpha = 0.05$.\n-   **Statistical Power**: Target power is $1-\\beta = 0.80$.\n-   **Rounding**: Standard normal quantiles to four significant figures; final sample size $n$ to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is well-grounded in biostatistics and experimental design. Power analysis for a two-sample test is a standard procedure. The context of phosphoproteomics is realistic, as is the use of log-transformation for mass-spectrometry data. The specified parameters ($\\alpha$, power, $\\delta$, $\\sigma^2$) are typical for such studies.\n-   **Well-Posed**: The problem is well-posed. It clearly defines the objective: derive the sample size formula from first principles and then calculate its value. All necessary parameters and assumptions are provided. A unique, meaningful solution exists.\n-   **Objective**: The problem is stated in precise, objective language, free of bias or subjective claims.\n\nThe problem does not violate any of the specified invalidity criteria. It is scientifically sound, formalizable, complete, realistic, well-posed, and non-trivial.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n### Derivation of the Sample Size Formula\nLet $\\mu_1$ and $\\mu_2$ be the true population means of the log-transformed phosphosite abundance for the disease and control groups, respectively. Let $\\bar{X}_1$ and $\\bar{X}_2$ be the corresponding sample means from samples of size $n$. The common population variance is $\\sigma^2$, which we will estimate with $s_p^2$. The difference to detect is $\\delta = \\mu_1 - \\mu_2$.\n\nThe null and alternative hypotheses for the two-sided test are:\n$$H_0: \\mu_1 - \\mu_2 = 0$$\n$$H_A: \\mu_1 - \\mu_2 \\neq 0$$\n\nThe test statistic is based on the difference of the sample means, $\\bar{X}_1 - \\bar{X}_2$. Due to the independence of the samples and the assumption of equal variance $\\sigma^2$, the variance of this difference is:\n$$\\text{Var}(\\bar{X}_1 - \\bar{X}_2) = \\text{Var}(\\bar{X}_1) + \\text{Var}(\\bar{X}_2) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n} = \\frac{2\\sigma^2}{n}$$\nThe standard error of the difference is $SE = \\sqrt{\\frac{2\\sigma^2}{n}}$.\n\nThe problem specifies using a Gaussian approximation. Therefore, the sampling distribution of the difference in means is approximated as:\n$$\\bar{X}_1 - \\bar{X}_2 \\sim N\\left(\\mu_1 - \\mu_2, \\frac{2\\sigma^2}{n}\\right)$$\n\n**Condition for Type I Error ($\\alpha$)**\nUnder the null hypothesis ($H_0$), $\\mu_1 - \\mu_2 = 0$. The sampling distribution is $\\bar{X}_1 - \\bar{X}_2 \\sim N(0, \\frac{2\\sigma^2}{n})$. A Type I error occurs if we reject $H_0$ when it is true. For a two-sided test with significance level $\\alpha$, we reject $H_0$ if the observed difference is sufficiently far from $0$. The rejection region is defined by critical values that cut off $\\alpha/2$ in each tail of the standard normal distribution. Let $z_{\\alpha/2}$ be the standard normal quantile such that $P(Z > z_{\\alpha/2}) = \\alpha/2$, where $Z$ is a standard normal random variable.\n\nWe reject $H_0$ if $|\\bar{X}_1 - \\bar{X}_2| > C$, where $C$ is the critical value of the difference. To find $C$, we standardize:\n$$\\frac{C - 0}{\\sqrt{2\\sigma^2/n}} = z_{\\alpha/2}$$\n$$C = z_{\\alpha/2} \\sqrt{\\frac{2\\sigma^2}{n}}$$\nSo, we reject $H_0$ if $\\bar{X}_1 - \\bar{X}_2 > z_{\\alpha/2} \\sqrt{\\frac{2\\sigma^2}{n}}$ or if $\\bar{X}_1 - \\bar{X}_2 < -z_{\\alpha/2} \\sqrt{\\frac{2\\sigma^2}{n}}$.\n\n**Condition for Statistical Power ($1-\\beta$)**\nStatistical power is the probability of correctly rejecting $H_0$ when the alternative hypothesis ($H_A$) is true. We evaluate power for a specific alternative, $\\mu_1 - \\mu_2 = \\delta$. Under this alternative, the sampling distribution is $\\bar{X}_1 - \\bar{X}_2 \\sim N(\\delta, \\frac{2\\sigma^2}{n})$.\n\nFor $\\delta > 0$, the probability of falling into the lower rejection region ($\\bar{X}_1 - \\bar{X}_2 < -C$) is negligible. Thus, the power can be approximated by considering only the upper rejection region:\n$$\\text{Power} = 1 - \\beta \\approx P\\left(\\bar{X}_1 - \\bar{X}_2 > C \\mid \\mu_1 - \\mu_2 = \\delta\\right)$$\nTo calculate this probability, we standardize the critical value $C$ with respect to the distribution under $H_A$:\n$$1 - \\beta = P\\left( \\frac{(\\bar{X}_1 - \\bar{X}_2) - \\delta}{\\sqrt{2\\sigma^2/n}} > \\frac{C - \\delta}{\\sqrt{2\\sigma^2/n}} \\right)$$\nThe term on the left inside the probability is a standard normal variable $Z$. Let $z_\\beta$ be the standard normal quantile such that $P(Z > z_\\beta) = \\beta$. Then $P(Z > -z_\\beta) = 1-\\beta$. Thus, we must have:\n$$-z_\\beta = \\frac{C - \\delta}{\\sqrt{2\\sigma^2/n}}$$\n\nNow, we substitute the expression for $C$ from the Type I error condition:\n$$-z_\\beta = \\frac{z_{\\alpha/2} \\sqrt{\\frac{2\\sigma^2}{n}} - \\delta}{\\sqrt{2\\sigma^2/n}} = z_{\\alpha/2} - \\frac{\\delta}{\\sqrt{\\frac{2\\sigma^2}{n}}}$$\nRearranging to solve for the term containing $n$:\n$$\\frac{\\delta}{\\sqrt{\\frac{2\\sigma^2}{n}}} = z_{\\alpha/2} + z_\\beta$$\nSquaring both sides:\n$$\\frac{\\delta^2}{\\frac{2\\sigma^2}{n}} = (z_{\\alpha/2} + z_\\beta)^2$$\n$$\\frac{n\\delta^2}{2\\sigma^2} = (z_{\\alpha/2} + z_\\beta)^2$$\nFinally, solving for the per-group sample size $n$:\n$$n = \\frac{2\\sigma^2(z_{\\alpha/2} + z_\\beta)^2}{\\delta^2}$$\nThis is the general formula for the per-group sample size in a two-sample test under the Gaussian approximation, derived from first principles.\n\n### Numerical Calculation\nWe now substitute the given values into the derived formula.\n-   $\\sigma^2 \\approx s_{p}^{2} = 0.50$\n-   $\\delta = 1$\n-   $\\alpha = 0.05 \\implies \\alpha/2 = 0.025$\n-   $1-\\beta = 0.80 \\implies \\beta = 0.20$\n\nWe need to find the standard normal quantiles $z_{0.025}$ and $z_{0.20}$. The problem requires rounding these to four significant figures.\n-   $z_{\\alpha/2} = z_{0.025}$ is the value for which the cumulative probability is $1-0.025 = 0.975$. From a standard normal table or calculator, this value is approximately $1.95996$. Rounded to four significant figures, $z_{0.025} = 1.960$.\n-   $z_\\beta = z_{0.20}$ is the value for which the cumulative probability is $1-0.20 = 0.80$. From a standard normal table or calculator, this value is approximately $0.84162$. Rounded to four significant figures, $z_{0.20} = 0.8416$.\n\nSubstituting these values into the sample size formula:\n$$n = \\frac{2(0.50)(1.960 + 0.8416)^2}{(1)^2}$$\n$$n = \\frac{1 \\times (2.8016)^2}{1}$$\n$$n = (2.8016)^2$$\n$$n = 7.84896256$$\n\nThe problem requires reporting the final value for $n$ to four significant figures.\n$$n \\approx 7.849$$\nThis represents the non-integer per-group sample size required to achieve the specified power. In a practical setting, one would round this up to the next integer (i.e., $8$ participants per group). However, the problem explicitly requests the real number result.", "answer": "$$\n\\boxed{7.849}\n$$", "id": "5022986"}, {"introduction": "Once data is acquired, the focus shifts to robust analysis, where one of the most common and complex challenges is handling missing values. In mass spectrometry-based proteomics, values can be missing for different reasons: some are \"Missing Not At Random\" ($MNAR$) because a peptide's abundance is below the detection limit, while others are \"Missing At Random\" ($MAR$) due to stochastic sampling. This problem challenges you to select the most appropriate imputation strategy that acknowledges this mixed mechanism, a critical step to avoid introducing significant bias into your downstream discovery of differentially regulated phosphosites [@problem_id:5022971].", "problem": "An immunoaffinity phosphotyrosine enrichment followed by liquid chromatography–tandem mass spectrometry (LC–MS/MS) is performed on peripheral blood mononuclear cells from two cohorts in a translational medicine study to discover phosphosite targets predictive of response to immunotherapy. Label-free quantification is used, and log-intensities are analyzed at the phosphosite level. The acquisition is data-dependent, and missing values are present. The team observes the following empirically supported facts that are standard in phosphoproteomics: (i) data-dependent acquisition introduces stochastic precursor selection that leads to missing values even for peptides above the limit of detection, and this mechanism is commonly modeled as Missing At Random (MAR); (ii) low-abundance phosphopeptides fall below the sample- and run-specific limit of detection, introducing left-censoring of the intensity distribution, which is Missing Not At Random (MNAR); (iii) after log-transformation, within-condition intensity distributions of non-missing values are approximately Gaussian for many phosphosites.\n\nYou are asked to design an imputation approach that minimizes bias in downstream differential phosphorylation testing between the responder group and the non-responder group. Your design should start from the foundational definitions that (a) under MAR, the probability of missingness does not depend on the unobserved value conditional on observed data, whereas (b) under MNAR due to left-censoring, the probability of missingness increases as the true intensity decreases relative to a run-specific censoring threshold. Consider that a given phosphosite may exhibit both mechanisms across runs.\n\nWhich of the following strategies is most appropriate to minimize bias in downstream group comparisons while respecting the coexistence of MAR and MNAR mechanisms in phosphoproteomics?\n\nA. Discard all samples with any missing phosphosite measurements (complete-case analysis), then apply a two-sample $t$-test on the remaining data.\n\nB. After log-transformation and normalization, impute all missing values with the within-group mean for that phosphosite, then apply a two-sample $t$-test.\n\nC. For each phosphosite, use a mechanism-aware, two-part imputation: first, fit a logistic regression of the missingness indicator $m_{ij}\\in\\{0,1\\}$ on observed intensity proxies and group to classify missingness as MAR or MNAR for each run; for MAR-designated entries, impute using $k$-nearest neighbors within batch; for MNAR-designated entries, estimate a run-specific censoring threshold $c_j$ (for sample $j$) from the lower tail of observed intensities and impute by sampling from a left-truncated normal distribution $\\mathcal{N}(\\mu_{gj},\\sigma_{g}^2)$ truncated below $c_j$, where $g$ indexes group, with $\\mu_{gj}$ and $\\sigma_{g}^2$ estimated from the low-intensity tail within group; then perform variance-moderated tests across groups.\n\nD. Impute every missing value with a small constant equal to one half of the global minimum observed log-intensity to reflect below–limit of detection behavior, then use a Wilcoxon rank-sum test between groups.\n\nE. Apply low-rank singular value decomposition (SVD) matrix completion assuming Missing Completely At Random (MCAR) across the entire matrix, followed by moderated $t$-tests between groups.\n\nSelect the single best option.", "solution": "The problem requires the selection of the most appropriate statistical strategy for handling missing data in a quantitative phosphoproteomics dataset to minimize bias in downstream differential analysis. The problem statement provides critical information about the data generation process, which must guide the choice of methodology.\n\n### Problem Validation\nThe problem statement is valid.\n1.  **Givens Extracted:**\n    *   **Experiment:** Immunoaffinity phosphotyrosine enrichment with LC-MS/MS.\n    *   **Data:** Label-free quantification (LFQ) of phosphosites from two cohorts (responders, non-responders). Data are log-transformed intensities.\n    *   **Acquisition:** Data-dependent acquisition (DDA).\n    *   **Missing Data Mechanisms:** The problem explicitly states the coexistence of two mechanisms:\n        *   (i) **Missing At Random (MAR):** Due to stochastic precursor selection in DDA.\n        *   (ii) **Missing Not At Random (MNAR):** Due to low-abundance phosphopeptides falling below a run-specific limit of detection (left-censoring).\n    *   **Distributional Assumption:** (iii) Log-transformed intensities of non-missing values are approximately Gaussian.\n    *   **Objective:** Minimize bias in downstream differential phosphorylation testing.\n    *   **Definitions:** Standard statistical definitions of MAR and MNAR are provided.\n\n2.  **Validation Verdict:** The problem is scientifically grounded, well-posed, and objective. The scenario described is a standard and non-trivial challenge in bioinformatics and computational proteomics. The provided facts about DDA-based proteomics, including the mixed MAR/MNAR missing data paradigm and the approximate log-normality of intensities, are accurate representations of real-world data characteristics. The problem is internally consistent and provides sufficient information to evaluate the proposed strategies.\n\n### Derivation of the Correct Approach\nThe fundamental challenge is the presence of a mixed missing data mechanism. A statistically sound approach must not treat all missing values uniformly. Instead, it must differentiate between MAR and MNAR values and apply an appropriate imputation strategy for each.\n\n*   **MAR values:** For a value missing at random, its missingness is not informative about its true value (conditional on observed data). Imputation should therefore be based on the information present in the observed data, for instance, by leveraging correlations with other phosphosites or other samples.\n*   **MNAR values:** For a value missing not at random due to left-censoring, its missingness is highly informative: its true value is below some detection threshold. Imputation must respect this fact. Simply replacing these values with a measure of central tendency (like the mean) would introduce a severe positive bias, while ignoring them would also bias the results.\n\nLet $Y_{ij}$ be the log-intensity of phosphosite $i$ in sample $j$. Let $M_{ij}$ be an indicator variable, where $M_{ij}=1$ if $Y_{ij}$ is missing and $M_{ij}=0$ otherwise. The problem states that the probability of missingness $P(M_{ij}=1 | Y_{ij}, \\mathbf{Y}_{obs})$ depends on different factors for MAR and MNAR. A robust strategy must therefore:\n1.  Acknowledge the mixed mechanism.\n2.  Ideally, attempt to classify each missing value ($M_{ij}=1$) as either MAR or MNAR.\n3.  Apply a method suitable for MAR data to the MAR-classified values.\n4.  Apply a method suitable for MNAR (left-censored) data to the MNAR-classified values.\n5.  Perform a downstream statistical test that is compatible with the properties of the imputed dataset. Moderated $t$-tests are appropriate given the approximate normality and high-dimensional nature of the data.\n\nWith this framework, we can evaluate the options.\n\n### Option-by-Option Analysis\n\n**A. Discard all samples with any missing phosphosite measurements (complete-case analysis), then apply a two-sample $t$-test on the remaining data.**\nThis is a complete-case analysis. In high-throughput proteomics, missing values are pervasive. This strategy would almost certainly result in discarding most, if not all, of the samples, rendering analysis impossible. More critically, it is statistically invalid when data are not Missing Completely At Random (MCAR). Since the missingness is partly MNAR—correlated with low peptide abundance—this approach would selectively remove samples that provide evidence for low expression, leading to severe bias in estimating group means and differences.\n**Verdict: Incorrect**\n\n**B. After log-transformation and normalization, impute all missing values with the within-group mean for that phosphosite, then apply a two-sample $t$-test.**\nThis strategy treats all missing values as if they were MAR and should be estimated by the central tendency. This is fundamentally flawed for the MNAR component. For a phosphosite with low abundance in one group, many of its values will be missing due to being below the detection limit. Imputing these with the mean of the observed (higher) values will artificially inflate the mean of that group, masking the true biological difference. This leads to a loss of statistical power (false negatives). Additionally, mean imputation artificially reduces the variance, which can lead to an inflated $t$-statistic and an increased rate of false positives.\n**Verdict: Incorrect**\n\n**C. For each phosphosite, use a mechanism-aware, two-part imputation: first, fit a logistic regression of the missingness indicator $m_{ij}\\in\\{0,1\\}$ on observed intensity proxies and group to classify missingness as MAR or MNAR for each run; for MAR-designated entries, impute using $k$-nearest neighbors within batch; for MNAR-designated entries, estimate a run-specific censoring threshold $c_j$ (for sample $j$) from the lower tail of observed intensities and impute by sampling from a left-truncated normal distribution $\\mathcal{N}(\\mu_{gj},\\sigma_{g}^2)$ truncated below $c_j$, where $g$ indexes group, with $\\mu_{gj}$ and $\\sigma_{g}^2$ estimated from the low-intensity tail within group; then perform variance-moderated tests across groups.**\nThis strategy directly and correctly addresses the problem's core complexity. It proposes a principled, multi-step pipeline:\n1.  **Classification:** It first attempts to separate MAR from MNAR missingness, which is the crucial first step.\n2.  **Tailored Imputation:** It then applies distinct, appropriate imputation strategies for each class. For MAR, $k$-nearest neighbors ($k$-NN) is a well-established method that uses local similarity in the data structure. For MNAR, it correctly treats the data as left-censored and imputes values by sampling from a truncated normal distribution. This is a stochastic imputation method that preserves the distributional shape and uncertainty, which is superior to deterministic imputation with a single constant. The use of a run-specific censoring threshold ($c_j$) and group-specific parameters for the truncated distribution demonstrates a high level of statistical rigor.\n3.  **Appropriate Testing:** Finally, it uses variance-moderated tests (e.g., from the `limma` package), which are the standard of care for differential expression analysis in high-dimensional genomics/proteomics data to improve statistical power and stability.\nThis option represents a state-of-the-art approach that respects the data-generating process.\n**Verdict: Correct**\n\n**D. Impute every missing value with a small constant equal to one half of the global minimum observed log-intensity to reflect below–limit of detection behavior, then use a Wilcoxon rank-sum test between groups.**\nThis strategy has two major flaws. First, it assumes all missing values are MNAR, which contradicts the problem statement that MAR values are also present. Imputing a MAR value with a small constant introduces a strong negative bias. Second, using a single, deterministic constant for imputation creates a large number of artificial ties in the data, which severely degrades the performance and validity of a rank-based method like the Wilcoxon test. It also wrongly uses a *global* minimum, ignoring that detection limits are run-specific.\n**Verdict: Incorrect**\n\n**E. Apply low-rank singular value decomposition (SVD) matrix completion assuming Missing Completely At Random (MCAR) across the entire matrix, followed by moderated $t$-tests between groups.**\nThis strategy is based on an incorrect assumption. SVD-based matrix completion methods are designed for data that are MAR or, as explicitly stated here, MCAR. They are not robust to the presence of MNAR data. The MNAR mechanism violates the core assumption of SVD imputation, as the missingness pattern contains information about the magnitude of the missing values. Applying SVD in this context will cause the low-abundance, censored values to be imputed with values that are biased towards the global mean or major axes of variation, thus masking true biological differences, similar to the bias of mean imputation.\n**Verdict: Incorrect**", "answer": "$$\\boxed{C}$$", "id": "5022971"}]}