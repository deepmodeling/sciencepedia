{"hands_on_practices": [{"introduction": "To begin our practical exploration, we will analyze a foundational non-linear model of disease progression. Unlike simple linear models, many biological systems exhibit saturation and self-limiting behavior, which are captured elegantly by models like the logistic equation. This exercise [@problem_id:5066095] will guide you through finding the equilibrium points of a system representing disease burden and, critically, determining their stability. Mastering this stability analysis is essential for predicting whether a disease will resolve on its own or persist at a chronic level, and for understanding how treatments might shift the system towards a healthy state.", "problem": "In a translational medicine setting, consider a coarse-grained systems biology model for a chronic disease burden represented by a scalar state variable $x(t)$ that aggregates a measurable disease proxy (for example, a composite inflammatory biomarker) under competing processes: proliferation due to pathogenic drivers and removal due to treatment and immune clearance. Assume well-mixed dynamics and that proliferation saturates as burden increases due to limited resources or host constraints. The disease burden evolves according to the ordinary differential equation (ODE) $dx/dt = f(x)$ with\n$$\nf(x) \\equiv \\alpha\\, x\\left(1-\\frac{x}{K}\\right) - \\beta\\, x,\n$$\nwhere $x(t) \\ge 0$, $\\alpha$ is the intrinsic per-capita proliferation rate, $K$ is a carrying capacity parameter, and $\\beta$ is the per-capita net removal rate. The parameters are given by $\\alpha = 0.5\\,\\text{day}^{-1}$, $K = 100\\,\\text{a.u.}$, and $\\beta = 0.2\\,\\text{day}^{-1}$, where a.u. denotes arbitrary units.\n\nUsing only first principles of fixed point analysis for autonomous one-dimensional ODEs (fixed points occur where $f(x)=0$; local stability of a fixed point $x^{*}$ is determined by the sign of $f'(x^{*})$), carry out the following:\n\n1. Derive all fixed points of the system and identify the biologically relevant positive equilibrium $x^{*}$ for the given parameters.\n2. Determine the local stability of $x^{*}$ by evaluating $f'(x^{*})$.\n\nReport your final numerical result as a row matrix $\\big(x^{*}, f'(x^{*})\\big)$ without units. Do not round; provide exact values. For interpretation, $x^{*}$ should be understood in arbitrary units (a.u.) and $f'(x^{*})$ in $\\text{day}^{-1}$, but do not include units in your final answer.", "solution": "The problem statement is critically validated and found to be valid. It is scientifically grounded, employing a standard logistic growth model with a linear clearance term, a common construct in population dynamics and systems biology. The problem is well-posed, providing a specific ordinary differential equation (ODE), all necessary parameter values, and a clear, formalizable task based on first principles of dynamical systems analysis. There are no internal contradictions, missing data, or unrealistic assumptions.\n\nThe task is to find the fixed points of the system described by the ODE $\\frac{dx}{dt} = f(x)$ and determine the stability of the biologically relevant positive fixed point, $x^{*}$. The governing function is given by:\n$$\nf(x) = \\alpha\\, x\\left(1-\\frac{x}{K}\\right) - \\beta\\, x\n$$\nwhere the parameters are $\\alpha = 0.5\\,\\text{day}^{-1}$, $K = 100\\,\\text{a.u.}$, and $\\beta = 0.2\\,\\text{day}^{-1}$.\n\nFirst, we find the fixed points (equilibria) of the system by setting $f(x) = 0$:\n$$\n\\alpha\\, x\\left(1-\\frac{x}{K}\\right) - \\beta\\, x = 0\n$$\nWe can factor out the variable $x$:\n$$\nx \\left[ \\alpha\\left(1-\\frac{x}{K}\\right) - \\beta \\right] = 0\n$$\nThis equation yields two solutions for the fixed points.\n\nThe first fixed point is the trivial equilibrium:\n$$\nx_1^{*} = 0\n$$\nThis represents a state of complete disease clearance.\n\nThe second fixed point is found by setting the expression in the brackets to zero:\n$$\n\\alpha\\left(1-\\frac{x}{K}\\right) - \\beta = 0\n$$\nSolving for $x$:\n$$\n\\alpha - \\frac{\\alpha x}{K} = \\beta\n$$\n$$\n\\alpha - \\beta = \\frac{\\alpha x}{K}\n$$\n$$\nx = \\frac{K(\\alpha - \\beta)}{\\alpha} = K \\left(1 - \\frac{\\beta}{\\alpha}\\right)\n$$\nLet's denote this second fixed point as $x_2^{*}$. The problem asks for the \"biologically relevant positive equilibrium\". For $x_2^{*}$ to be positive, we must have $1 - \\frac{\\beta}{\\alpha} > 0$, which implies $\\alpha > \\beta$.\n\nUsing the given parameter values, $\\alpha = 0.5$ and $\\beta = 0.2$, we find that $\\alpha > \\beta$ is indeed true. Therefore, a positive, non-trivial equilibrium exists. This is the fixed point of interest, $x^{*}$.\nWe calculate its value:\n$$\nx^{*} = 100 \\left(1 - \\frac{0.2}{0.5}\\right) = 100 \\left(1 - 0.4\\right) = 100(0.6) = 60\n$$\n\nNext, we determine the local stability of this fixed point $x^{*} = 60$. The stability is determined by the sign of the derivative of $f(x)$, denoted $f'(x)$, evaluated at $x^{*}$. A negative sign ($f'(x^{*}) < 0$) indicates a stable fixed point, while a positive sign ($f'(x^{*}) > 0$) indicates an unstable one.\n\nFirst, we compute the derivative $f'(x)$. It is more convenient to first expand the expression for $f(x)$:\n$$\nf(x) = \\alpha x - \\frac{\\alpha}{K}x^2 - \\beta x = (\\alpha - \\beta)x - \\frac{\\alpha}{K}x^2\n$$\nNow, we differentiate with respect to $x$:\n$$\nf'(x) = \\frac{d}{dx}\\left( (\\alpha-\\beta)x - \\frac{\\alpha}{K}x^2 \\right) = \\alpha - \\beta - \\frac{2\\alpha}{K}x\n$$\nWe evaluate this derivative at the positive fixed point $x^{*} = K(1 - \\frac{\\beta}{\\alpha})$:\n$$\nf'(x^{*}) = (\\alpha - \\beta) - \\frac{2\\alpha}{K} \\left[ K \\left(1 - \\frac{\\beta}{\\alpha}\\right) \\right]\n$$\n$$\nf'(x^{*}) = (\\alpha - \\beta) - 2\\alpha \\left(1 - \\frac{\\beta}{\\alpha}\\right)\n$$\n$$\nf'(x^{*}) = (\\alpha - \\beta) - (2\\alpha - 2\\beta)\n$$\n$$\nf'(x^{*}) = \\alpha - \\beta - 2\\alpha + 2\\beta = -\\alpha + \\beta = -(\\alpha - \\beta)\n$$\nSince $\\alpha > \\beta$, the term $(\\alpha - \\beta)$ is positive. Therefore, $f'(x^{*})$ is negative, which confirms that the fixed point $x^{*}$ is locally stable.\n\nFinally, we calculate the numerical value of $f'(x^{*})$ using the given parameters:\n$$\nf'(x^{*}) = -(\\alpha - \\beta) = -(0.5 - 0.2) = -0.3\n$$\nThe results to be reported are the positive fixed point $x^{*} = 60$ and the value of the derivative at this point, $f'(x^{*}) = -0.3$.\nThe final result is the row matrix $(x^{*}, f'(x^{*}))$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 60 & -0.3 \\end{pmatrix}}\n$$", "id": "5066095"}, {"introduction": "While deterministic models describe the average behavior of a large population, they miss a crucial element of biology: randomness. Stochastic fluctuations are particularly important at low population numbers, where the chance survival of a single pathogenic cell can lead to disease relapse. This practice [@problem_id:5066008] provides a hands-on introduction to the Gillespie Stochastic Simulation Algorithm (SSA), a cornerstone of computational systems biology. By calculating the reaction propensities and sampling the waiting time to the next event, you will simulate the element of chance and gain insight into how individual random events shape the system's trajectory.", "problem": "A translational medicine team is building a minimal stochastic disease model to interpret early treatment response in a patient whose pathogenic clonal cell population is driven by proliferation and cytotoxic clearance. In a systems biology representation, let $X$ denote the number of clonal cells. Consider the reaction network with two unimolecular reactions: $R_1: X \\to 2X$ (proliferation) and $R_2: X \\to \\emptyset$ (clearance). Assume well-mixed conditions and the law of mass action. The per-molecule rates are $k_1 = 2.0 \\times 10^{-2} \\ \\text{h}^{-1}$ for $R_1$ and $k_2 = 1.5 \\times 10^{-2} \\ \\text{h}^{-1}$ for $R_2$. At the present time, the measured state is $X = 50$. You will perform one direct-step of the Gillespie stochastic simulation algorithm (SSA) to propagate this state.\n\nStarting from first principles appropriate to systems biology and stochastic chemical kinetics, including the law of mass action and the memoryless property of Poisson processes, derive the propensity functions $a_1(X)$ and $a_2(X)$ and the total propensity $a_0(X)$ for the reaction network at state $X$. Then, using the direct SSA step and a given independent random draw $u_1 = 0.367879$ from the continuous uniform distribution on the unit interval, compute the sampled waiting time $\\tau$ until the next reaction. Express the final $\\tau$ in hours and round your answer to four significant figures.\n\nFor completeness of the step, you may assume another independent uniform draw $u_2 = 0.600000$ would be used to select which reaction fires based on $a_1(X)$ and $a_2(X)$; however, do not report the identity of the reaction in the final numeric answer. Report only the waiting time $\\tau$ in hours, rounded to four significant figures.", "solution": "The problem requires the calculation of the waiting time, $\\tau$, for the next reaction in a stochastic chemical system using one step of the Gillespie Stochastic Simulation Algorithm (SSA). The system describes the dynamics of a pathogenic clonal cell population, $X$, governed by two elementary, unimolecular reactions: proliferation, $R_1: X \\to 2X$, and clearance, $R_2: X \\to \\emptyset$. The analysis will be based on the fundamental principles of stochastic chemical kinetics.\n\nFirst, we derive the propensity functions for the two reactions. The propensity function, $a_j(X)$, for a reaction $R_j$ gives the probability per unit time that reaction $R_j$ will occur in the system, given the state is $X$. For elementary reactions under well-mixed conditions, the law of mass action dictates the form of the propensity.\n\nFor a unimolecular reaction of the form $S \\to \\text{products}$ with a stochastic rate constant $k$, the propensity function is given by $a(X) = k \\cdot X$, where $X$ is the number of molecules of species $S$. This arises because each of the $X$ molecules has a constant probability $k$ per unit time of undergoing the reaction, and these events are independent.\n\nThe proliferation reaction, $R_1: X \\to 2X$, is a unimolecular process where a single cell of type $X$ divides. The per-molecule rate constant is given as $k_1 = 2.0 \\times 10^{-2} \\ \\text{h}^{-1}$. Therefore, the propensity function for reaction $R_1$ is:\n$$a_1(X) = k_1 X$$\n\nThe clearance reaction, $R_2: X \\to \\emptyset$, is also a unimolecular process where a single cell of type $X$ is removed. The per-molecule rate constant is given as $k_2 = 1.5 \\times 10^{-2} \\ \\text{h}^{-1}$. The propensity function for reaction $R_2$ is:\n$$a_2(X) = k_2 X$$\n\nThe problem specifies that the current state of the system is $X = 50$ cells. We can calculate the numerical values of the propensities at this state:\n$$a_1(50) = (2.0 \\times 10^{-2} \\ \\text{h}^{-1}) \\times 50 = 1.0 \\ \\text{h}^{-1}$$\n$$a_2(50) = (1.5 \\times 10^{-2} \\ \\text{h}^{-1}) \\times 50 = 0.75 \\ \\text{h}^{-1}$$\n\nThe Gillespie SSA relies on the total propensity, $a_0(X)$, which is the sum of all individual propensity functions. This quantity represents the total rate at which *any* reaction will occur in the system.\n$$a_0(X) = \\sum_{j} a_j(X) = a_1(X) + a_2(X)$$\nSubstituting the calculated values for the state $X = 50$:\n$$a_0(50) = 1.0 \\ \\text{h}^{-1} + 0.75 \\ \\text{h}^{-1} = 1.75 \\ \\text{h}^{-1}$$\n\nThe core principle of the SSA is that the waiting time $\\tau$ until the next reaction event is a random variable. The assumption that each reaction channel behaves as an independent Poisson process, a consequence of the memoryless property of the underlying microscopic events, implies that the time to the next event (the minimum of the waiting times for each channel) follows an exponential distribution with a rate parameter equal to the total propensity, $a_0(X)$.\n\nThe probability density function for $\\tau$ is $p(\\tau | X) = a_0(X) \\exp(-a_0(X)\\tau)$. To generate a random variate $\\tau$ from this distribution, we use the inverse transform sampling method. Let $u_1$ be a random number drawn from a uniform distribution on the unit interval, $U(0, 1)$. We set $u_1$ equal to the cumulative distribution function $F(\\tau) = \\int_0^\\tau p(s|X) ds = 1 - \\exp(-a_0(X)\\tau)$ and solve for $\\tau$:\n$$u_1 = 1 - \\exp(-a_0(X)\\tau)$$\n$$\\exp(-a_0(X)\\tau) = 1 - u_1$$\n$$-a_0(X)\\tau = \\ln(1 - u_1)$$\nSince $u_1$ is a uniform random number in $(0, 1)$, $1-u_1$ is also a uniform random number in $(0, 1)$. Thus, the formula is commonly written as:\n$$\\tau = \\frac{1}{a_0(X)} \\ln\\left(\\frac{1}{u_1}\\right) = -\\frac{\\ln(u_1)}{a_0(X)}$$\n\nUsing the given random number $u_1 = 0.367879$ and the calculated total propensity $a_0(50) = 1.75 \\ \\text{h}^{-1}$, we can compute the waiting time $\\tau$:\n$$\\tau = -\\frac{\\ln(0.367879)}{1.75 \\ \\text{h}^{-1}}$$\nFirst, we evaluate the natural logarithm:\n$$\\ln(0.367879) \\approx -1.000000605$$\nNow, we compute $\\tau$:\n$$\\tau \\approx -\\frac{-1.000000605}{1.75} \\ \\text{h} \\approx 0.571428917 \\ \\text{h}$$\n\nThe problem requires the answer to be rounded to four significant figures.\n$$\\tau \\approx 0.5714 \\ \\text{h}$$\nThis value represents the stochastically sampled time that will elapse before either a proliferation or a clearance event occurs, starting from the state $X=50$.", "answer": "$$\\boxed{0.5714}$$", "id": "5066008"}, {"introduction": "A mathematical model's predictive power is only as good as the parameters we feed into it, which must be learned from experimental data. However, not all parameters are created equal; some are \"sloppy,\" meaning different parameter combinations produce nearly indistinguishable model outputs, making them difficult to estimate reliably. This exercise [@problem_id:5066099] delves into the advanced but critical topic of parameter identifiability. You will explore how model structure and experimental design can lead to collinearity between parameters and learn how a strategic reparameterization can help decouple these effects, making the model more robust and trustworthy for translational applications.", "problem": "In translational medicine, a common systems biology representation of resource-limited clonal expansion is the nonlinear ordinary differential equation $x'(t) = k_1 x(t) - k_2 x(t)^2$, where $x(t)$ denotes a measurable disease burden proxy at time $t$, $k_1$ is a net proliferation rate, and $k_2$ encodes second-order competitive limitation. Suppose $x(t)$ is observed at times $t_i$ with additive Gaussian noise $y_i = x(t_i; k_1, k_2, x_0) + \\varepsilon_i$, where $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ and $x_0$ is a known initial condition. Use the following foundational bases: (i) mass-action kinetics implies that first-order and second-order terms arise from encounters proportional to $x$ and $x^2$, respectively; (ii) local practical identifiability is assessed by the Fisher Information Matrix (FIM) for Gaussian noise, which is constructed from parameter sensitivities of model predictions; and (iii) equilibria satisfy $x'(t)=0$.\n\nAssume the sampling strategy is dominated by late-time observations such that $x(t)$ is close to its nonzero equilibrium for most $t_i$. Reason from these bases to determine how parameter collinearity arises in the sensitivity structure and identify the corresponding non-identifiable direction in the original parameter space $(k_1,k_2)$. Then, propose a reparameterization that reduces sloppiness by decoupling the dominant amplitude and time-scale effects, and explain why this transformation improves identifiability when the experimental design includes both early and late phases.\n\nWhich option most correctly characterizes the non-identifiable direction and provides a scientifically justified reparameterization that reduces sloppiness?\n\nA. Near equilibrium, the dominant sensitivity is to the carrying capacity combination, making the columns of the FIM associated with $k_1$ and $k_2$ nearly proportional. The non-identifiable direction is along variations that keep $k_1/k_2$ constant, i.e., $k_2 \\,\\mathrm{d}k_1 - k_1 \\,\\mathrm{d}k_2 = 0$. Reparameterize to $r = k_1$ and $K = k_1/k_2$, and non-dimensionalize via $u = x/K$ and $\\tau = r t$, so the dominant amplitude ($K$) and time-scale ($r$) effects are orthogonalized; this reduces sloppiness provided data include both approach-to-equilibrium and transient growth.\n\nB. Collinearity arises solely from measurement noise at large $t$, so increasing the number of samples eliminates non-identifiability without changing parameters. The best reparameterization is $\\lambda = k_1 + k_2$ and $\\mu = k_1 k_2$ because sums and products are more stable numerically, which removes sloppiness regardless of sampling regime.\n\nC. The parameters $k_1$ and $k_2$ appear only as their sum in the dynamics near equilibrium, implying the non-identifiable direction is along $k_1 - k_2 = \\text{constant}$. Therefore, reparameterize to $\\alpha = k_1 + k_2$ and $\\beta = k_1 - k_2$, which diagonalizes the FIM.\n\nD. The late-time collinearity is due to the initial condition $x_0$, so rescaling the state $x$ by $k_1$ as $v = x/k_1$ and keeping time unscaled makes the sensitivities of $k_1$ and $k_2$ orthogonal, eliminating sloppiness even if all data are near equilibrium.", "solution": "We begin from mass-action kinetics and the definition of local practical identifiability through the Fisher Information Matrix (FIM). The model is $x'(t) = k_1 x(t) - k_2 x(t)^2$ under Gaussian noise observations. For the equilibrium analysis, set $x'(t)=0$ to obtain equilibria $x^* = 0$ and $x^* = k_1/k_2$. The nonzero equilibrium is $x^* = K$ with $K = k_1/k_2$, reflecting the carrying capacity implied by resource limitation in mass-action terms.\n\nFor late-time sampling, the system is near $x^* = K$, and dynamics are dominated by the approach to equilibrium rather than transient exponential growth. To formalize the sensitivity structure, it is convenient to use a reparameterization $(r,K)$ with $r = k_1$ and $K = k_1/k_2$. The analytic solution of the logistic equation is\n$$\nx(t) = \\frac{K}{1 + \\left(\\frac{K - x_0}{x_0}\\right) e^{- r t}},\n$$\nwhich follows from separation of variables and partial fractions. This representation shows that $r$ controls the time scale of approach to equilibrium and $K$ controls the equilibrium amplitude.\n\nThe FIM for Gaussian noise is\n$$\n\\mathrm{FIM}( \\theta ) = \\frac{1}{\\sigma^2} \\sum_i \\left( \\nabla_\\theta x(t_i; \\theta) \\right) \\left( \\nabla_\\theta x(t_i; \\theta) \\right)^\\top,\n$$\nwhere $\\theta$ is the parameter vector. In the original parameterization, $\\theta = (k_1,k_2)$, and in the reparameterization, $\\theta = (r,K)$. The sensitivity relations via the chain rule are\n$$\n\\frac{\\partial x}{\\partial k_1} = \\frac{\\partial x}{\\partial r} \\frac{\\partial r}{\\partial k_1} + \\frac{\\partial x}{\\partial K} \\frac{\\partial K}{\\partial k_1} = \\frac{\\partial x}{\\partial r} + \\frac{1}{k_2}\\frac{\\partial x}{\\partial K},\n$$\nand\n$$\n\\frac{\\partial x}{\\partial k_2} = \\frac{\\partial x}{\\partial K} \\frac{\\partial K}{\\partial k_2} = -\\frac{k_1}{k_2^2} \\frac{\\partial x}{\\partial K} = -\\frac{K}{k_2} \\frac{\\partial x}{\\partial K}.\n$$\nNear equilibrium, $x(t)$ is close to $K$, so the system has largely relaxed; thus the sensitivity to the time-scale parameter $\\partial x / \\partial r$ becomes small in magnitude relative to $\\partial x / \\partial K$ because changing $r$ modifies predominantly how fast equilibrium is approached, a feature weakly reflected when all data lie near the plateau. Therefore, for late-time $t_i$,\n$$\n\\frac{\\partial x}{\\partial k_1} \\approx \\frac{1}{k_2} \\frac{\\partial x}{\\partial K}, \\quad \\frac{\\partial x}{\\partial k_2} \\approx -\\frac{K}{k_2} \\frac{\\partial x}{\\partial K},\n$$\nwhich implies\n$$\n\\frac{\\partial x}{\\partial k_1} \\approx -\\frac{1}{K} \\frac{\\partial x}{\\partial k_2}.\n$$\nHence, the sensitivity columns associated with $k_1$ and $k_2$ in the FIM are nearly proportional, i.e., collinear, yielding an ill-conditioned matrix and a sloppy parameter direction. In this regime, the model predictions are primarily sensitive to the combination $K = k_1/k_2$; variations in $(k_1,k_2)$ that preserve $K$ produce nearly indistinguishable outputs.\n\nThe corresponding non-identifiable direction is found by setting the differential of $K$ to zero:\n$$\n\\mathrm{d}K = \\mathrm{d}\\left(\\frac{k_1}{k_2}\\right) = \\frac{1}{k_2}\\mathrm{d}k_1 - \\frac{k_1}{k_2^2}\\mathrm{d}k_2 = 0 \\quad \\Longrightarrow \\quad k_2 \\,\\mathrm{d}k_1 - k_1 \\,\\mathrm{d}k_2 = 0,\n$$\nequivalently $ \\mathrm{d}k_1/k_1 = \\mathrm{d}k_2/k_2$. Movements along this direction change $(k_1,k_2)$ proportionally, keeping $K$ fixed and leaving near-equilibrium outputs unchanged.\n\nA reparameterization that reduces sloppiness is to use $(r,K)$ directly and non-dimensionalize the model to decouple amplitude and time scale:\n$$\nu = \\frac{x}{K}, \\quad \\tau = r t.\n$$\nThen\n$$\n\\frac{\\mathrm{d}u}{\\mathrm{d}\\tau} = u(1-u),\n$$\nwith solution independent of $(r,K)$ once scaled, and the parameters re-enter only through the mappings back to physical units: $x = K u$ sets amplitude, and $t = \\tau / r$ sets time scale. When the experimental design includes both early-time data (where $u$ departs significantly from $0$ and the dynamics reveal $r$ through the transient growth) and late-time data near the plateau (where $u$ approaches $1$ and the amplitude reveals $K$), the sensitivities to $r$ and $K$ affect orthogonal aspects of the curve, improving the conditioning of the FIM and reducing sloppiness. In contrast, late-time-only data provide information primarily on $K$; $r$ remains poorly identifiable regardless of parameterization.\n\nWe now analyze each option:\n\nA. This option correctly states that near equilibrium, sensitivities to $k_1$ and $k_2$ become nearly proportional because the output depends mainly on $K = k_1/k_2$. It identifies the non-identifiable direction $k_2 \\,\\mathrm{d}k_1 - k_1 \\,\\mathrm{d}k_2 = 0$, which is equivalent to preserving $K$. The proposed reparameterization $(r,K)$ and non-dimensionalization $u = x/K$, $\\tau = r t$ correctly separate amplitude and time-scale effects, improving identifiability when both transient and plateau data are available. Verdict — Correct.\n\nB. This option incorrectly attributes collinearity solely to measurement noise and claims that increasing sample size alone fixes non-identifiability. Collinearity here is structural, driven by the model’s sensitivity pattern near equilibrium, and cannot be resolved by sampling more of the same late-time regime. The proposed $(\\lambda,\\mu) = (k_1 + k_2, k_1 k_2)$ reparameterization does not align with the model’s identifiable combinations and does not decouple amplitude and time-scale, so it does not reduce sloppiness in the described regime. Verdict — Incorrect.\n\nC. This option incorrectly claims that $k_1$ and $k_2$ appear only as their sum near equilibrium and posits a non-identifiable direction along $k_1 - k_2 = \\text{constant}$. The equilibrium is $K = k_1/k_2$, not a function of the sum or difference, and the sensitivity collinearity is proportional to $\\partial x/\\partial K$, not to $\\partial x/\\partial (k_1 \\pm k_2)$. The suggested reparameterization $(\\alpha,\\beta) = (k_1 + k_2, k_1 - k_2)$ does not diagonalize the FIM in the logistic model context. Verdict — Incorrect.\n\nD. This option incorrectly attributes late-time collinearity to the initial condition $x_0$ and suggests scaling $x$ by $k_1$ alone, $v = x/k_1$, without adjusting the time variable. The late-time collinearity arises from the structure near equilibrium where the amplitude $K$ dominates; scaling by $k_1$ does not separate amplitude and time-scale and fails to produce orthogonal sensitivities. Moreover, leaving time unscaled retains coupling of $k_1$ to both amplitude and time-scale, so sloppiness persists. Verdict — Incorrect.\n\nTherefore, option A is the only correct and scientifically justified choice.", "answer": "$$\\boxed{A}$$", "id": "5066099"}]}