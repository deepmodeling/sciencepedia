{"hands_on_practices": [{"introduction": "A cornerstone of population genetics is the Hardy-Weinberg Equilibrium (HWE) principle, which provides a mathematical baseline for allele and genotype frequencies in an idealized population. This exercise grounds this fundamental theory in a practical public health context, using pharmacogenomics as an example. By calculating allele frequencies and using the chi-square test to check for deviations from HWE, you will engage in a critical first step of any population genomics study: data quality control and assessment of underlying population structure. [@problem_id:5047855]", "problem": "A county-wide pharmacogenomic screening initiative is conducted under a precision public health program in translational medicine to assess population-level genotypic distributions for a Single-Nucleotide Polymorphism (SNP) in the vitamin K epoxide reductase complex subunit $1$ ($\\text{VKORC1}$) gene, relevant to warfarin dosing. In a random sample of $N=1000$ unrelated adults from a genetically diverse urban population, high-quality genotyping yields the following observed genotype counts for alleles $A$ and $a$: $AA=400$, $Aa=400$, and $aa=200$. Assume all individuals are unrelated and that genotyping error is negligible. Using population genetics fundamentals—allele frequency definitions in a diploid population and the Hardy-Weinberg Equilibrium (HWE) principle derived from random mating and Mendelian inheritance—compute the allele frequencies $p$ for allele $A$ and $q$ for allele $a$, the expected genotype counts under HWE, and the Pearson chi-square goodness-of-fit statistic for deviation from HWE. Treat the allele frequency as estimated from the sample, and therefore use the appropriate degrees of freedom for the test. Report the chi-square test statistic as your final numeric answer, rounded to four significant figures. No units are required.", "solution": "The problem statement has been analyzed and is deemed valid. It is scientifically grounded in the principles of population genetics, well-posed with sufficient and consistent data, and objectively stated. The context of pharmacogenomics and the `VKORC1` gene is a standard and appropriate example in translational medicine. We may therefore proceed with the solution.\n\nThe problem requires the calculation of the Pearson chi-square ($\\chi^2$) goodness-of-fit statistic to test whether the observed genotype counts for a specific SNP conform to the expectations of Hardy-Weinberg Equilibrium (HWE). The solution involves three primary steps:\n1.  Calculate the allele frequencies from the observed genotype counts.\n2.  Use these allele frequencies to calculate the expected genotype counts under HWE.\n3.  Compute the $\\chi^2$ statistic using the observed and expected counts.\n\nThe given observed genotype counts from a sample of $N=1000$ individuals are:\n-   Number of individuals with genotype $AA$: $N_{AA} = 400$\n-   Number of individuals with genotype $Aa$: $N_{Aa} = 400$\n-   Number of individuals with genotype $aa$: $N_{aa} = 200$\n\nThe total number of individuals in the sample is $N = N_{AA} + N_{Aa} + N_{aa} = 400 + 400 + 200 = 1000$, which is consistent with the problem statement.\n\n**Step 1: Calculate allele frequencies**\nThe frequencies of the alleles $A$ and $a$, denoted by $p$ and $q$ respectively, are calculated from the observed counts. In a diploid population of size $N$, there are $2N$ total alleles.\nThe total number of $A$ alleles is twice the number of $AA$ homozygotes plus the number of $Aa$ heterozygotes.\n$$ \\text{Count}(A) = (2 \\times N_{AA}) + N_{Aa} = (2 \\times 400) + 400 = 800 + 400 = 1200 $$\nThe total number of $a$ alleles is twice the number of $aa$ homozygotes plus the number of $Aa$ heterozygotes.\n$$ \\text{Count}(a) = (2 \\times N_{aa}) + N_{Aa} = (2 \\times 200) + 400 = 400 + 400 = 800 $$\nThe total number of alleles in the sample is $2N = 2 \\times 1000 = 2000$. As a check, $\\text{Count}(A) + \\text{Count}(a) = 1200 + 800 = 2000$, which is correct.\n\nThe frequency $p$ of allele $A$ is:\n$$ p = \\frac{\\text{Count}(A)}{2N} = \\frac{1200}{2000} = 0.6 $$\nThe frequency $q$ of allele $a$ is:\n$$ q = \\frac{\\text{Count}(a)}{2N} = \\frac{800}{2000} = 0.4 $$\nAs required, the sum of allele frequencies is $p + q = 0.6 + 0.4 = 1.0$.\n\n**Step 2: Calculate expected genotype counts under HWE**\nThe Hardy-Weinberg principle states that for a population in equilibrium, the expected genotype frequencies are given by $p^2$ for $AA$, $2pq$ for $Aa$, and $q^2$ for $aa$.\nThe expected frequencies are:\n-   Expected frequency of $AA$: $f_{exp}(AA) = p^2 = (0.6)^2 = 0.36$\n-   Expected frequency of $Aa$: $f_{exp}(Aa) = 2pq = 2(0.6)(0.4) = 0.48$\n-   Expected frequency of $aa$: $f_{exp}(aa) = q^2 = (0.4)^2 = 0.16$\nThe sum of expected frequencies is $0.36 + 0.48 + 0.16 = 1.0$.\n\nTo find the expected counts, we multiply these frequencies by the total sample size, $N=1000$:\n-   Expected count of $AA$: $E_{AA} = p^2 N = 0.36 \\times 1000 = 360$\n-   Expected count of $Aa$: $E_{Aa} = 2pq N = 0.48 \\times 1000 = 480$\n-   Expected count of $aa$: $E_{aa} = q^2 N = 0.16 \\times 1000 = 160$\nThe sum of expected counts is $360 + 480 + 160 = 1000$, which matches the sample size.\n\n**Step 3: Compute the Pearson chi-square statistic**\nThe $\\chi^2$ statistic is calculated using the formula:\n$$ \\chi^2 = \\sum_{i} \\frac{(O_i - E_i)^2}{E_i} $$\nwhere $O_i$ are the observed counts and $E_i$ are the expected counts for each genotype category $i$.\n\nWe have the following observed ($O$) and expected ($E$) counts:\n-   Genotype $AA$: $O_{AA} = 400$, $E_{AA} = 360$\n-   Genotype $Aa$: $O_{Aa} = 400$, $E_{Aa} = 480$\n-   Genotype $aa$: $O_{aa} = 200$, $E_{aa} = 160$\n\nNow, we compute the $\\chi^2$ value:\n$$ \\chi^2 = \\frac{(O_{AA} - E_{AA})^2}{E_{AA}} + \\frac{(O_{Aa} - E_{Aa})^2}{E_{Aa}} + \\frac{(O_{aa} - E_{aa})^2}{E_{aa}} $$\n$$ \\chi^2 = \\frac{(400 - 360)^2}{360} + \\frac{(400 - 480)^2}{480} + \\frac{(200 - 160)^2}{160} $$\n$$ \\chi^2 = \\frac{(40)^2}{360} + \\frac{(-80)^2}{480} + \\frac{(40)^2}{160} $$\n$$ \\chi^2 = \\frac{1600}{360} + \\frac{6400}{480} + \\frac{1600}{160} $$\nLet's simplify the fractions:\n$$ \\chi^2 = \\frac{160}{36} + \\frac{640}{48} + 10 $$\n$$ \\chi^2 = \\frac{40}{9} + \\frac{40}{3} + 10 $$\nTo sum these values, we find a common denominator, which is $9$:\n$$ \\chi^2 = \\frac{40}{9} + \\frac{120}{9} + \\frac{90}{9} = \\frac{40 + 120 + 90}{9} = \\frac{250}{9} $$\nConverting the fraction to a decimal:\n$$ \\chi^2 = 27.777... $$\nThe problem asks for the result rounded to four significant figures.\n$$ \\chi^2 \\approx 27.78 $$\nThe degrees of freedom ($df$) for this test are given by the number of categories minus $1$, minus the number of independent parameters estimated from the data. We have $3$ genotype categories ($AA$, $Aa$, $aa$). We estimated one parameter, the allele frequency $p$ (since $q=1-p$). Therefore, the degrees of freedom are $df = 3 - 1 - 1 = 1$. The calculated $\\chi^2$ value of approximately $27.78$ with $1$ degree of freedom indicates a highly significant deviation from Hardy-Weinberg equilibrium.", "answer": "$$\\boxed{27.78}$$", "id": "5047855"}, {"introduction": "While a genetic test may exhibit high analytical accuracy in the lab, its true utility in a public health setting depends critically on the population's characteristics, especially disease prevalence. This practice moves from theoretical principles to the practical evaluation of a population-wide screening program. By applying Bayes' theorem to calculate the Positive Predictive Value (PPV), you will uncover the often surprising relationship between test accuracy and predictive power, a vital consideration for designing effective and ethical precision health interventions. [@problem_id:5047891]", "problem": "A national precision public health program in translational medicine is considering implementation of a population genomics screen for a rare monogenic disorder defined by a pathogenic variant. The test has sensitivity $0.95$ and specificity $0.99$. The population prevalence (prior probability) of being affected is $K = 0.001$. Assume the test performance is stable across subgroups and that each screened individual’s outcome is independent.\n\nStarting from the definition of sensitivity and specificity and Bayes’ theorem for conditional probabilities, derive the positive predictive value (PPV) $P(\\text{Disease} \\mid +)$ of this screen in this population. Then, using first principles of probability and expectation for independent Bernoulli trials, derive the expected number of true positives among $100{,}000$ screened individuals.\n\nExpress the positive predictive value as a decimal fraction (not a percentage), rounded to four significant figures, and provide the expected number of true positives as an exact integer count per $100{,}000$ screened. Report your final answer as two values in the order: PPV, expected true positives.", "solution": "The problem asks for the derivation of the positive predictive value (PPV) and the expected number of true positives for a population-wide genetic screen. The problem is well-posed and scientifically grounded, providing all necessary parameters for a complete solution.\n\nLet $D$ be the event that an individual has the monogenic disorder, and let $D^c$ be the event that the individual does not have the disorder.\nLet $+$ be the event of a positive test result, and let $-$ be the event of a negative test result.\n\nThe givens from the problem statement are translated into probabilistic terms:\n1.  The population prevalence of the disorder, $K$, is the prior probability of having the disease: $P(D) = K = 0.001$.\n2.  The sensitivity of the test is the probability of a positive test result given that the individual has the disease: $P(+ \\mid D) = 0.95$.\n3.  The specificity of the test is the probability of a negative test result given that the individual does not have the disease: $P(- \\mid D^c) = 0.99$.\n4.  The total number of screened individuals is $N = 100000$.\n\nFirst, we derive the positive predictive value (PPV), which is defined as the conditional probability of having the disease given a positive test result, $P(D \\mid +)$.\nAccording to Bayes' theorem:\n$$P(D \\mid +) = \\frac{P(+ \\mid D) P(D)}{P(+)}$$\nTo use this formula, we must first calculate the total probability of a positive test, $P(+)$, using the law of total probability. The event of a positive test can be partitioned into two mutually exclusive events: a true positive (testing positive and having the disease) and a false positive (testing positive but not having the disease).\n$$P(+) = P(+ \\cap D) + P(+ \\cap D^c)$$\nUsing the definition of conditional probability, $P(A \\cap B) = P(A \\mid B)P(B)$, this expands to:\n$$P(+) = P(+ \\mid D) P(D) + P(+ \\mid D^c) P(D^c)$$\nWe are given $P(+ \\mid D)$ and $P(D)$. We need to determine $P(D^c)$ and $P(+ \\mid D^c)$.\nThe probability of not having the disease, $P(D^c)$, is the complement of the prevalence:\n$$P(D^c) = 1 - P(D) = 1 - 0.001 = 0.999$$\nThe probability of a positive test in a disease-free individual, $P(+ \\mid D^c)$, is the complement of the specificity, $P(- \\mid D^c)$. This is because for a disease-free individual, the test can only be positive or negative.\n$$P(+ \\mid D^c) = 1 - P(- \\mid D^c) = 1 - 0.99 = 0.01$$\nThis quantity, $P(+ \\mid D^c)$, is also known as the false positive rate.\n\nNow we can calculate the total probability of a positive test, $P(+)$:\n$$P(+) = (0.95)(0.001) + (0.01)(0.999) = 0.00095 + 0.00999 = 0.01094$$\nWith $P(+)$ calculated, we can determine the PPV:\n$$P(D \\mid +) = \\frac{P(+ \\mid D) P(D)}{P(+)} = \\frac{(0.95)(0.001)}{0.01094} = \\frac{0.00095}{0.01094}$$\n$$P(D \\mid +) \\approx 0.086837294332724...$$\nThe problem requires this value to be rounded to four significant figures.\n$$PPV = P(D \\mid +) \\approx 0.08684$$\n\nNext, we derive the expected number of true positives among $N=100000$ screened individuals.\nA true positive (TP) is an event where an individual both has the disease ($D$) and tests positive ($+$). The probability of a randomly selected individual being a true positive is $P(TP) = P(D \\cap +)$.\nUsing the definition of conditional probability:\n$$P(TP) = P(D \\cap +) = P(+ \\mid D) P(D)$$\nSubstituting the given values:\n$$P(TP) = (0.95)(0.001) = 0.00095$$\nThe screening of each of the $N$ individuals is an independent Bernoulli trial, where \"success\" is defined as the individual being a true positive. Let $X$ be the random variable representing the total number of true positives in the sample of $N$ individuals. $X$ follows a binomial distribution, $X \\sim B(N, p)$, where $N=100000$ is the number of trials and $p = P(TP) = 0.00095$ is the probability of success in each trial.\n\nThe expected value (or mean) of a binomially distributed random variable is given by the formula $E[X] = Np$.\nTherefore, the expected number of true positives, $E[X]$, is:\n$$E[X] = N \\times p = 100000 \\times 0.00095$$\n$$E[X] = 95$$\nThis is an exact integer count, as required.\n\nThe final answer consists of two values in order: the PPV rounded to four significant figures and the exact integer count of the expected number of true positives.", "answer": "$$\\boxed{\\begin{pmatrix} 0.08684 & 95 \\end{pmatrix}}$$", "id": "5047891"}, {"introduction": "The promise of precision public health hinges on the equitable performance of predictive models across diverse populations. This advanced exercise tackles the critical challenge of algorithmic fairness, where you will quantify performance disparities between groups using standard metrics. By applying an optimization-based approach to determine a threshold adjustment, you will gain hands-on experience with methods used to ensure genomic innovations reduce, rather than exacerbate, health inequities. [@problem_id:5047738]", "problem": "A national precision public health program deploys a genomic-clinical risk model to prioritize ten-year coronary artery disease screening. The risk score combines a Polygenic Risk Score (PRS) with clinical covariates and outputs an estimated risk $p \\in [0,1]$. Individuals are flagged for intensive screening if their predicted risk exceeds a decision threshold.\n\nTwo ancestry-stratified populations are evaluated: Group $A$ (reference) and Group $B$ (target for threshold adjustment). At the current common threshold $t=0.20$, the following operating characteristics are observed, estimated under independent validation:\n\n- Group $A$: True Positive Rate (TPR) $=0.82$, False Positive Rate (FPR) $=0.12$, calibration slope $s_A=0.97$, disease prevalence $\\pi_A=0.15$.\n- Group $B$: True Positive Rate (TPR) $=0.70$, False Positive Rate (FPR) $=0.08$, calibration slope $s_B=0.85$, disease prevalence $\\pi_B=0.10$.\n\nYou are asked to quantify group fairness and determine a small threshold adjustment for Group $B$ that reduces disparities while accounting for calibration. Use only the following fundamental bases and definitions:\n\n- True Positive Rate (TPR) is $TPR=P(\\hat{Y}=1 \\mid Y=1)$ and False Positive Rate (FPR) is $FPR=P(\\hat{Y}=1 \\mid Y=0)$.\n- Positive Predictive Value (PPV) is $PPV=P(Y=1 \\mid \\hat{Y}=1)$, derivable from Bayes’ rule as $PPV=\\dfrac{\\pi \\cdot TPR}{\\pi \\cdot TPR + (1-\\pi)\\cdot FPR}$ for prevalence $\\pi$.\n- Equalized odds disparity between two groups is measured by the Euclidean distance in $\\{TPR,FPR\\}$ space, $D_{EO}=\\sqrt{(TPR_A-TPR_B)^2+(FPR_A-FPR_B)^2}$.\n- Calibration slope $s$ is the slope from regressing observed outcomes on the logit of predicted risk; ideal calibration corresponds to $s=1$.\n\nAssume that near $t=0.20$, the Group $B$ operating characteristics vary smoothly with threshold. Let the first-order threshold sensitivities at this operating point be:\n$$\\alpha=\\frac{d\\,TPR_B}{dt}=-3.00 \\quad\\text{and}\\quad \\beta=\\frac{d\\,FPR_B}{dt}=-1.00.$$\nYou will adjust only Group $B$’s threshold by a small increment $\\Delta t$ (with Group $A$ fixed), so that $TPR_B$ and $FPR_B$ change approximately as\n$$TPR_B(t+\\Delta t)\\approx TPR_B(t)+\\alpha\\,\\Delta t,\\qquad FPR_B(t+\\Delta t)\\approx FPR_B(t)+\\beta\\,\\Delta t.$$\n\nDefine the fairness objective to be the regularized squared equalized-odds discrepancy,\n$$E(\\Delta t)=\\big(TPR_A-\\big[TPR_B+\\alpha\\,\\Delta t\\big]\\big)^2+\\big(FPR_A-\\big[FPR_B+\\beta\\,\\Delta t\\big]\\big)^2+\\lambda\\,(\\Delta t)^2,$$\nwith a calibration-aware regularization weight\n$$\\lambda=(1-s_B)^2.$$\n\nTasks:\n1. Using the stated definitions, compute the following at $t=0.20$:\n   - The equalized odds distance $D_{EO}$ between Group $A$ and Group $B$.\n   - The Positive Predictive Value disparity $\\Delta_{PPV}=PPV_A-PPV_B$.\n   - The calibration slope disparity $\\Delta_s=s_A-s_B$.\n2. Derive, from first principles and the given approximations, the closed-form minimizer $\\Delta t^\\star$ of $E(\\Delta t)$ and evaluate it numerically using the provided data. Express the final answer as the single numerical value of $\\Delta t^\\star$ (unitless threshold change, interpreted as a proportion of risk), and round your final answer to four significant figures.", "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\nThe data, definitions, and conditions provided in the problem statement are as follows:\n- Risk score $p \\in [0,1]$.\n- Common threshold $t=0.20$.\n- Group $A$ (reference) characteristics at $t=0.20$:\n  - True Positive Rate $TPR_A=0.82$\n  - False Positive Rate $FPR_A=0.12$\n  - Calibration slope $s_A=0.97$\n  - Disease prevalence $\\pi_A=0.15$\n- Group $B$ (target) characteristics at $t=0.20$:\n  - True Positive Rate $TPR_B=0.70$\n  - False Positive Rate $FPR_B=0.08$\n  - Calibration slope $s_B=0.85$\n  - Disease prevalence $\\pi_B=0.10$\n- Definitions:\n  - $TPR=P(\\hat{Y}=1 \\mid Y=1)$\n  - $FPR=P(\\hat{Y}=1 \\mid Y=0)$\n  - $PPV=\\dfrac{\\pi \\cdot TPR}{\\pi \\cdot TPR + (1-\\pi)\\cdot FPR}$\n  - Equalized odds distance $D_{EO}=\\sqrt{(TPR_A-TPR_B)^2+(FPR_A-FPR_B)^2}$\n  - Calibration slope $s$ is from regressing outcomes on the logit of predicted risk.\n- Threshold sensitivities for Group $B$ at $t=0.20$:\n  - $\\alpha=\\frac{d\\,TPR_B}{dt}=-3.00$\n  - $\\beta=\\frac{d\\,FPR_B}{dt}=-1.00$\n- First-order approximations for Group $B$'s operating characteristics with a threshold change $\\Delta t$:\n  - $TPR_B(t+\\Delta t)\\approx TPR_B(t)+\\alpha\\,\\Delta t$\n  - $FPR_B(t+\\Delta t)\\approx FPR_B(t)+\\beta\\,\\Delta t$\n- Fairness objective function to be minimized:\n  - $E(\\Delta t)=\\big(TPR_A-\\big[TPR_B+\\alpha\\,\\Delta t\\big]\\big)^2+\\big(FPR_A-\\big[FPR_B+\\beta\\,\\Delta t\\big]\\big)^2+\\lambda\\,(\\Delta t)^2$\n- Calibration-aware regularization weight:\n  - $\\lambda=(1-s_B)^2$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity against the established criteria.\n- **Scientifically Grounded**: The problem is situated squarely within the field of translational medicine, specifically addressing the critical issue of fairness in algorithmic medicine and precision public health. All concepts used, such as $TPR$, $FPR$, $PPV$, calibration slope, and equalized odds, are standard, well-defined metrics in machine learning fairness and clinical model evaluation. The use of a first-order Taylor expansion to model the effect of a small threshold change is a standard and appropriate mathematical approximation. The regularization of an objective function to balance competing goals (fairness vs. calibration) is a common technique in optimization. The problem is scientifically sound.\n- **Well-Posed**: The problem is well-posed. It provides all necessary data and definitions to perform the required calculations. The objective function $E(\\Delta t)$ is a quadratic function of $\\Delta t$ with a positive coefficient for the $(\\Delta t)^2$ term (since $\\alpha^2+\\beta^2+\\lambda > 0$), ensuring a unique global minimum exists.\n- **Objective**: The problem is stated using precise, quantitative, and unbiased language. All terms are formally defined. There are no subjective or opinion-based statements.\n\nThe problem does not exhibit any of the flaws listed in the validation criteria (e.g., factual unsoundness, incompleteness, ambiguity).\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\nThe solution proceeds in two parts as requested. First, we compute the baseline disparity metrics. Second, we derive and evaluate the optimal threshold adjustment $\\Delta t^\\star$.\n\n**Part 1: Baseline Disparity Calculations**\n\nWe are asked to compute three metrics at the common threshold $t=0.20$.\n\n1.  **Equalized Odds Distance ($D_{EO}$)**\n    This metric measures the Euclidean distance between the two groups in the $\\{TPR, FPR\\}$ plane.\n    $$D_{EO} = \\sqrt{(TPR_A-TPR_B)^2+(FPR_A-FPR_B)^2}$$\n    Substituting the given values:\n    $$D_{EO} = \\sqrt{(0.82-0.70)^2+(0.12-0.08)^2} = \\sqrt{(0.12)^2+(0.04)^2} = \\sqrt{0.0144+0.0016} = \\sqrt{0.016}$$\n    Numerically, $D_{EO} \\approx 0.1265$.\n\n2.  **Positive Predictive Value Disparity ($\\Delta_{PPV}$)**\n    First, we calculate the $PPV$ for each group using the formula $PPV=\\dfrac{\\pi \\cdot TPR}{\\pi \\cdot TPR + (1-\\pi)\\cdot FPR}$.\n    For Group $A$:\n    $$PPV_A = \\frac{\\pi_A \\cdot TPR_A}{\\pi_A \\cdot TPR_A + (1-\\pi_A) \\cdot FPR_A} = \\frac{0.15 \\cdot 0.82}{0.15 \\cdot 0.82 + (1-0.15) \\cdot 0.12} = \\frac{0.123}{0.123 + 0.85 \\cdot 0.12} = \\frac{0.123}{0.123 + 0.102} = \\frac{0.123}{0.225} \\approx 0.5467$$\n    For Group $B$:\n    $$PPV_B = \\frac{\\pi_B \\cdot TPR_B}{\\pi_B \\cdot TPR_B + (1-\\pi_B) \\cdot FPR_B} = \\frac{0.10 \\cdot 0.70}{0.10 \\cdot 0.70 + (1-0.10) \\cdot 0.08} = \\frac{0.07}{0.07 + 0.90 \\cdot 0.08} = \\frac{0.07}{0.07 + 0.072} = \\frac{0.07}{0.142} \\approx 0.4930$$\n    The disparity is the difference:\n    $$\\Delta_{PPV} = PPV_A-PPV_B \\approx 0.5467 - 0.4930 = 0.0537$$\n\n3.  **Calibration Slope Disparity ($\\Delta_s$)**\n    This is a direct subtraction of the given calibration slopes:\n    $$\\Delta_s = s_A-s_B = 0.97 - 0.85 = 0.12$$\n\n**Part 2: Derivation and Evaluation of Optimal Threshold Adjustment ($\\Delta t^\\star$)**\n\nThe objective is to find the value of $\\Delta t$ that minimizes the function:\n$$E(\\Delta t)=\\big(TPR_A-\\big[TPR_B+\\alpha\\,\\Delta t\\big]\\big)^2+\\big(FPR_A-\\big[FPR_B+\\beta\\,\\Delta t\\big]\\big)^2+\\lambda\\,(\\Delta t)^2$$\nLet's define the initial disparities as $\\Delta_{TPR} = TPR_A - TPR_B$ and $\\Delta_{FPR} = FPR_A - FPR_B$. The function can be rewritten as:\n$$E(\\Delta t) = (\\Delta_{TPR} - \\alpha \\Delta t)^2 + (\\Delta_{FPR} - \\beta \\Delta t)^2 + \\lambda (\\Delta t)^2$$\nTo find the minimum, we differentiate $E(\\Delta t)$ with respect to $\\Delta t$ and set the derivative to zero.\n$$\\frac{dE}{d(\\Delta t)} = \\frac{d}{d(\\Delta t)} \\left[ (\\Delta_{TPR} - \\alpha \\Delta t)^2 + (\\Delta_{FPR} - \\beta \\Delta t)^2 + \\lambda (\\Delta t)^2 \\right]$$\nUsing the chain rule:\n$$\\frac{dE}{d(\\Delta t)} = 2(\\Delta_{TPR} - \\alpha \\Delta t)(-\\alpha) + 2(\\Delta_{FPR} - \\beta \\Delta t)(-\\beta) + 2\\lambda \\Delta t$$\nSetting the derivative to zero and dividing by $2$:\n$$-\\alpha(\\Delta_{TPR} - \\alpha \\Delta t) - \\beta(\\Delta_{FPR} - \\beta \\Delta t) + \\lambda \\Delta t = 0$$\nDistributing the terms:\n$$-\\alpha\\Delta_{TPR} + \\alpha^2 \\Delta t - \\beta\\Delta_{FPR} + \\beta^2 \\Delta t + \\lambda \\Delta t = 0$$\nWe now isolate the terms containing $\\Delta t$:\n$$\\Delta t (\\alpha^2 + \\beta^2 + \\lambda) = \\alpha\\Delta_{TPR} + \\beta\\Delta_{FPR}$$\nSolving for $\\Delta t$, we obtain the optimal adjustment, $\\Delta t^\\star$:\n$$\\Delta t^\\star = \\frac{\\alpha\\Delta_{TPR} + \\beta\\Delta_{FPR}}{\\alpha^2 + \\beta^2 + \\lambda}$$\nSubstituting the original definitions for $\\Delta_{TPR}$ and $\\Delta_{FPR}$:\n$$\\Delta t^\\star = \\frac{\\alpha(TPR_A - TPR_B) + \\beta(FPR_A - FPR_B)}{\\alpha^2 + \\beta^2 + \\lambda}$$\nNow, we substitute the numerical values provided.\nFirst, calculate the regularization weight $\\lambda$:\n$$\\lambda = (1 - s_B)^2 = (1 - 0.85)^2 = (0.15)^2 = 0.0225$$\nNext, calculate the numerator of the expression for $\\Delta t^\\star$:\n$$\\text{Numerator} = (-3.00)(0.82 - 0.70) + (-1.00)(0.12 - 0.08)$$\n$$\\text{Numerator} = (-3.00)(0.12) + (-1.00)(0.04) = -0.36 - 0.04 = -0.40$$\nThen, calculate the denominator:\n$$\\text{Denominator} = \\alpha^2 + \\beta^2 + \\lambda = (-3.00)^2 + (-1.00)^2 + 0.0225$$\n$$\\text{Denominator} = 9.00 + 1.00 + 0.0225 = 10.0225$$\nFinally, we compute $\\Delta t^\\star$:\n$$\\Delta t^\\star = \\frac{-0.40}{10.0225} \\approx -0.03990773...$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\\Delta t^\\star \\approx -0.03991$$\nThis result indicates that for Group $B$, the decision threshold should be lowered from $0.20$ to approximately $0.20 - 0.03991 = 0.16009$ to minimize the regularized fairness-calibration objective. This adjustment aims to increase both $TPR_B$ and $FPR_B$ (since $\\alpha$ and $\\beta$ are negative), moving them closer to the values for Group $A$ and thus reducing the equalized odds disparity. The regularization term penalizes large adjustments, with the penalty being larger due to Group $B$'s poorer initial calibration ($s_B=0.85$).", "answer": "$$\\boxed{-0.03991}$$", "id": "5047738"}]}