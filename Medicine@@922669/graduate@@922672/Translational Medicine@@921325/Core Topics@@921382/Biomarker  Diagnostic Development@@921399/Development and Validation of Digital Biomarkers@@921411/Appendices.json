{"hands_on_practices": [{"introduction": "This exercise establishes the theoretical bedrock for any digital biomarker: faithful signal acquisition. Before we can analyze a signal, we must first convert it from a continuous, real-world phenomenon into a discrete series of numbers. This practice [@problem_id:5007582] guides you through deriving the Nyquist criterion, $f_s \\ge 2 f_{\\max}$, from first principles, demonstrating the critical relationship between a signal's maximum frequency content ($f_{\\max}$) and the required sampling rate ($f_s$) to prevent irreversible information loss through aliasing.", "problem": "In the development and validation of digital biomarkers in translational medicine, Heart Rate Variability (HRV) serves as a sensitive marker of autonomic function and cardiorespiratory coupling. Consider a continuous-time HRV signal $x(t)$ that is known, by physiological measurement and preprocessing, to be band-limited to a maximum frequency $f_{\\max}$, meaning its Continuous-Time Fourier Transform (CTFT) $X(f)$ satisfies $X(f) = 0$ for $|f| > f_{\\max}$. The signal is sampled uniformly at sampling frequency $f_{s}$ with sampling period $T_{s} = \\frac{1}{f_{s}}$ using an impulse train sampler to produce a discrete-time sequence for downstream spectral analysis and digital biomarker extraction.\n\nStarting from first principles of uniform sampling and the CTFT properties of impulse trains, derive the minimum sampling frequency constraint in terms of $f_{\\max}$ that guarantees perfect, alias-free reconstruction of $x(t)$ from its samples by ideal low-pass filtering of the sampled spectrum. Then, apply your derived constraint to an HRV signal whose clinically relevant spectral content extends up to $0.4\\,\\text{Hz}$ (the upper bound of the high-frequency band used in HRV analysis) to determine the minimum sampling rate sufficient to resolve frequency components up to $0.4\\,\\text{Hz}$ without aliasing.\n\nProvide the final numerical sampling rate in Hertz. If no rounding is required, report the exact value. Do not include units in the boxed final answer; state units only in your reasoning.", "solution": "We begin with the standard model of uniform sampling. Let $x(t)$ be a continuous-time, band-limited signal with CTFT $X(f)$ supported on $|f| \\le f_{\\max}$. Uniform sampling at period $T_{s} = \\frac{1}{f_{s}}$ can be modeled by multiplying $x(t)$ with a Dirac impulse train\n$$\np(t) = \\sum_{n=-\\infty}^{\\infty} \\delta(t - n T_{s}),\n$$\nproducing the sampled signal\n$$\ns(t) = x(t)\\,p(t) = x(t) \\sum_{n=-\\infty}^{\\infty} \\delta(t - n T_{s}).\n$$\nThe CTFT of $p(t)$ is a frequency-domain impulse train,\n$$\nP(f) = \\frac{1}{T_{s}} \\sum_{k=-\\infty}^{\\infty} \\delta(f - k f_{s}),\n$$\nwhere $f_{s} = \\frac{1}{T_{s}}$ is the sampling frequency. Using the modulation-convolution duality for the CTFT, the CTFT of $s(t)$ is the convolution of $X(f)$ with $P(f)$:\n$$\nS(f) = X(f) * P(f) = \\int_{-\\infty}^{\\infty} X(\\nu)\\,P(f - \\nu)\\,d\\nu.\n$$\nSubstituting $P(f)$ yields\n$$\nS(f) = \\frac{1}{T_{s}} \\sum_{k=-\\infty}^{\\infty} X(f - k f_{s}).\n$$\nThus the spectrum of the sampled signal consists of replicas of $X(f)$ shifted by integer multiples of $f_{s}$ and scaled by $\\frac{1}{T_{s}}$:\n$$\nS(f) = \\frac{1}{T_{s}} \\left( \\cdots + X(f + 2 f_{s}) + X(f + f_{s}) + X(f) + X(f - f_{s}) + X(f - 2 f_{s}) + \\cdots \\right).\n$$\nPerfect reconstruction by ideal low-pass filtering requires that these shifted replicas do not overlap. Since $X(f)$ is supported on $[-f_{\\max}, f_{\\max}]$, the baseband copy occupies $[-f_{\\max}, f_{\\max}]$. The nearest shifted copies are centered at $f = \\pm f_{s}$ and occupy $[f_{s} - f_{\\max}, f_{s} + f_{\\max}]$ and $[-f_{s} - f_{\\max}, -f_{s} + f_{\\max}]$, respectively. To prevent overlap of the baseband $[-f_{\\max}, f_{\\max}]$ with the nearest shifted copies, we require the lower edge of the first upper replica to be at or beyond the upper edge of the baseband, i.e.,\n$$\nf_{s} - f_{\\max} \\ge f_{\\max}.\n$$\nThis inequality simplifies to\n$$\nf_{s} \\ge 2 f_{\\max}.\n$$\nThis is the Nyquist sampling criterion for band-limited signals: the sampling frequency must be at least twice the maximum frequency present to avoid aliasing. The equality case $f_{s} = 2 f_{\\max}$ produces replicas that meet at $f = \\pm f_{\\max}$ but do not overlap, allowing exact recovery with an ideal brick-wall low-pass filter.\n\nWe now apply this to Heart Rate Variability (HRV), which is a digital biomarker of autonomic function. Suppose the HRV spectrum of interest is band-limited to $f_{\\max} = 0.4\\,\\text{Hz}$. The Nyquist criterion then imposes\n$$\nf_{s} \\ge 2 \\times 0.4\\,\\text{Hz} = 0.8\\,\\text{Hz}.\n$$\nTherefore, the minimum sampling rate sufficient to resolve HRV components up to $0.4\\,\\text{Hz}$ without aliasing is $0.8\\,\\text{Hz}$. No rounding is required; this is an exact value. Expressed in Hertz, the answer is $0.8\\,\\text{Hz}$, and per the instruction, we will report the numeric value alone in the boxed final answer.", "answer": "$$\\boxed{0.8}$$", "id": "5007582"}, {"introduction": "After developing a continuous digital biomarker, we must quantify its consistency and precision. This practice [@problem_id:5007617] introduces test-retest reliability, a cornerstone of measurement validation, using the Intraclass Correlation Coefficient (ICC). By partitioning the total measurement variance into components representing true between-subject differences and measurement error, you will learn to compute and interpret the ICC, a crucial metric for determining if a biomarker is stable enough for longitudinal monitoring or clinical trials.", "problem": "A translational medicine study evaluates a continuous smartphone-derived digital biomarker of resting tremor amplitude under repeated measurements to establish test-retest reliability. The biomarker is collected for $n=48$ individuals across $k=4$ sessions conducted under unchanged clinical conditions. The data are modeled using a two-way random-effects linear mixed-effects model,\n$$Y_{ij}=\\mu+S_{i}+D_{j}+\\varepsilon_{ij},$$\nwhere $Y_{ij}$ is the measured biomarker for individual $i$ at session $j$, $\\mu$ is the grand mean, $S_{i}$ is the random subject effect with $S_{i}\\sim \\mathcal{N}(0,\\sigma_{S}^{2})$, $D_{j}$ is the random session effect with $D_{j}\\sim \\mathcal{N}(0,\\sigma_{D}^{2})$, and $\\varepsilon_{ij}$ is the residual error with $\\varepsilon_{ij}\\sim \\mathcal{N}(0,\\sigma_{\\varepsilon}^{2})$. All random components are independent.\n\nFirst, provide a concise definition of test-retest reliability in the context of continuous digital biomarkers and the above hierarchical measurement model. Next, using the model and the foundational definition of reliability as the proportion of total variance attributable to stable between-subject differences for a single-session measurement, derive an expression for the Intraclass Correlation Coefficient (ICC; Intraclass Correlation Coefficient) under this two-way random-effects setting for a single session. Finally, compute the ICC using the following Restricted Maximum Likelihood (REML; Restricted Maximum Likelihood) estimates of the variance components:\n$$\\hat{\\sigma}_{S}^{2}=0.95,\\quad \\hat{\\sigma}_{D}^{2}=0.12,\\quad \\hat{\\sigma_{\\varepsilon}}^{2}=0.31.$$\nExpress the final ICC as a real number. Round your answer to four significant figures. The ICC is unitless; do not include any units in your final numerical value.", "solution": "The problem asks for three items: a definition of test-retest reliability, the derivation of the ICC formula for the specified model, and the computation of the ICC value.\n\nFirst, a concise definition of test-retest reliability is required. In the context of continuous measurements such as digital biomarkers, test-retest reliability quantifies the consistency and stability of measurements obtained from the same subjects under similar conditions but at different times. From a statistical modeling perspective, it is the proportion of total variance in the measurements that is attributable to \"true\" or stable differences between subjects, as opposed to variance arising from measurement error or systematic variations across measurement occasions. A high reliability indicates that the biomarker can consistently distinguish between individuals.\n\nThe problem specifies a two-way random-effects linear mixed-effects model:\n$$Y_{ij}=\\mu+S_{i}+D_{j}+\\varepsilon_{ij}$$\nwhere $Y_{ij}$ is the measured biomarker for individual/subject $i$ at session $j$. The components are:\n- $\\mu$: the grand mean, a fixed effect.\n- $S_{i}$: the random effect for subject $i$, with $S_{i}\\sim \\mathcal{N}(0,\\sigma_{S}^{2})$. The term $\\sigma_{S}^{2}$ represents the between-subject variance.\n- $D_{j}$: the random effect for session $j$, with $D_{j}\\sim \\mathcal{N}(0,\\sigma_{D}^{2})$. The term $\\sigma_{D}^{2}$ represents the between-session variance, which might reflect systematic changes in measurement conditions across sessions.\n- $\\varepsilon_{ij}$: the residual error term for subject $i$ at session $j$, with $\\varepsilon_{ij}\\sim \\mathcal{N}(0,\\sigma_{\\varepsilon}^{2})$. The term $\\sigma_{\\varepsilon}^{2}$ represents the random measurement error variance.\n\nAll random components ($S_i$, $D_j$, $\\varepsilon_{ij}$) are assumed to be independent.\n\nTo derive the expression for the ICC, we must first determine the total variance of a single observation, $Y_{ij}$. Since the random effects are independent, the total variance is the sum of their individual variances. The mean $\\mu$ is a constant, so its variance is $0$.\n$$ \\text{Var}(Y_{ij}) = \\text{Var}(\\mu + S_{i} + D_{j} + \\varepsilon_{ij}) $$\n$$ \\text{Var}(Y_{ij}) = \\text{Var}(S_{i}) + \\text{Var}(D_{j}) + \\text{Var}(\\varepsilon_{ij}) $$\nSubstituting the definitions of the variances:\n$$ \\text{Var}(Y_{ij}) = \\sigma_{S}^{2} + \\sigma_{D}^{2} + \\sigma_{\\varepsilon}^{2} $$\nThis expression represents the total variance in the measurements.\n\nThe problem defines reliability as the proportion of total variance attributable to stable between-subject differences for a single-session measurement. The variance component that represents stable, true differences between subjects is the between-subject variance, $\\sigma_{S}^{2}$.\n\nThe ICC is the ratio of this between-subject variance to the total variance. Therefore, the formula for the ICC in this context is:\n$$ \\text{ICC} = \\frac{\\text{Between-subject variance}}{\\text{Total variance}} = \\frac{\\sigma_{S}^{2}}{\\sigma_{S}^{2} + \\sigma_{D}^{2} + \\sigma_{\\varepsilon}^{2}} $$\nThis specific form of ICC is often referred to as ICC for absolute agreement, corresponding to McGraw and Wong's ICC(A,1) or Shrout and Fleiss's ICC(2,1), which is appropriate for a two-way random-effects model where both subjects and sessions are considered random samples from larger populations. The variance due to sessions, $\\sigma_D^2$, is included in the denominator as it contributes to the measurement error when assessing absolute agreement.\n\nFinally, we compute the numerical value of the ICC using the provided Restricted Maximum Likelihood (REML) estimates for the variance components:\n$$ \\hat{\\sigma}_{S}^{2} = 0.95 $$\n$$ \\hat{\\sigma}_{D}^{2} = 0.12 $$\n$$ \\hat{\\sigma_{\\varepsilon}}^{2} = 0.31 $$\nSubstituting these estimates into the ICC formula:\n$$ \\text{ICC} = \\frac{\\hat{\\sigma}_{S}^{2}}{\\hat{\\sigma}_{S}^{2} + \\hat{\\sigma}_{D}^{2} + \\hat{\\sigma}_{\\varepsilon}^{2}} = \\frac{0.95}{0.95 + 0.12 + 0.31} $$\nFirst, we calculate the sum in the denominator, which is the total variance:\n$$ 0.95 + 0.12 + 0.31 = 1.38 $$\nNow, we compute the ratio:\n$$ \\text{ICC} = \\frac{0.95}{1.38} \\approx 0.688405797... $$\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $6, 8, 8, 4$. The fifth digit is $0$, so we round down (i.e., we do not change the fourth digit).\n$$ \\text{ICC} \\approx 0.6884 $$\nThis value indicates that approximately $68.84\\%$ of the total variance in the biomarker measurements is due to stable differences between subjects.", "answer": "$$\\boxed{0.6884}$$", "id": "5007617"}, {"introduction": "Many digital biomarkers function as classifiers, making binary decisions such as detecting a fall or identifying a disease flare-up. This exercise [@problem_id:5007644] provides hands-on experience with the fundamental tools of classifier validation derived from a confusion matrix: sensitivity and specificity. More importantly, it highlights a critical translational concept—how a biomarker's predictive value in a real-world setting is profoundly influenced by the prevalence of the event, illustrating the essential difference between a test's intrinsic properties and its applied clinical utility.", "problem": "A wrist-worn inertial measurement unit-based digital biomarker for fall detection is being validated in a prospective cohort study of community-dwelling older adults as part of a translational medicine pipeline. Over a monitoring period, ground-truth events are adjudicated by clinical staff using synchronized video and patient interviews. The algorithm emits a binary classification at the granularity of a detected episode: $\\,\\text{fall}$ or $\\,\\text{non-fall}$. The adjudicated confusion matrix over $\\,N=1000\\,$ episodes is:\n- True positives ($\\mathrm{TP}$): $96$ episodes adjudicated as fall and classified as fall.\n- False negatives ($\\mathrm{FN}$): $24$ episodes adjudicated as fall but classified as non-fall.\n- False positives ($\\mathrm{FP}$): $44$ episodes adjudicated as non-fall but classified as fall.\n- True negatives ($\\mathrm{TN}$): $836$ episodes adjudicated as non-fall and classified as non-fall.\n\nWithin this validation dataset, compute the following operating characteristics grounded in core definitions used in clinical test evaluation:\n- Sensitivity (true positive rate).\n- Specificity (true negative rate).\n- Positive Predictive Value (PPV; the probability an algorithm-positive episode is truly a fall).\n- Negative Predictive Value (NPV; the probability an algorithm-negative episode is truly a non-fall).\n\nThen, treating sensitivity and specificity as properties of the algorithm that are stable across populations, derive general expressions for PPV and NPV as functions of the population fall prevalence $p \\in (0,1)$ and analyze how these functions change when moving from the validation cohort’s prevalence to alternative deployment prevalences. Evaluate these functions at $p=0.02$ and $p=0.30$ to illustrate the direction and magnitude of change.\n\nFinally, report only the value of the Positive Predictive Value at $p=0.02$ as the final numeric answer. Round your final numeric answer to four significant figures and express it in decimal form (no percent sign).", "solution": "The problem requires the calculation of several operating characteristics for a digital biomarker from a confusion matrix, the derivation of general forms for predictive values, and the evaluation of these functions at different population prevalences. The solution proceeds by first defining and calculating the metrics for the given validation data, then deriving the general formulas, and finally applying them to the specified scenarios.\n\nThe provided data from the confusion matrix for a total of $N=1000$ episodes are:\n- True Positives ($\\mathrm{TP}$): $96$\n- False Negatives ($\\mathrm{FN}$): $24$\n- False Positives ($\\mathrm{FP}$): $44$\n- True Negatives ($\\mathrm{TN}$): $836$\n\nFirst, we compute the operating characteristics for the validation cohort. The total number of adjudicated falls is $\\mathrm{TP} + \\mathrm{FN} = 96 + 24 = 120$. The total number of adjudicated non-falls is $\\mathrm{FP} + \\mathrm{TN} = 44 + 836 = 880$. The total number of episodes is $120 + 880 = 1000$.\n\nSensitivity ($\\mathrm{Se}$), or the true positive rate, is the proportion of actual positives that are correctly identified as such.\n$$ \\mathrm{Se} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}} = \\frac{96}{96 + 24} = \\frac{96}{120} = 0.8 $$\n\nSpecificity ($\\mathrm{Sp}$), or the true negative rate, is the proportion of actual negatives that are correctly identified as such.\n$$ \\mathrm{Sp} = \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FP}} = \\frac{836}{836 + 44} = \\frac{836}{880} = 0.95 $$\n\nPositive Predictive Value ($\\mathrm{PPV}$) is the probability that an episode classified as a fall is truly a fall.\n$$ \\mathrm{PPV} = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}} = \\frac{96}{96 + 44} = \\frac{96}{140} = \\frac{24}{35} \\approx 0.6857 $$\n\nNegative Predictive Value ($\\mathrm{NPV}$) is the probability that an episode classified as a non-fall is truly a non-fall.\n$$ \\mathrm{NPV} = \\frac{\\mathrm{TN}}{\\mathrm{TN} + \\mathrm{FN}} = \\frac{836}{836 + 24} = \\frac{836}{860} = \\frac{209}{215} \\approx 0.9721 $$\n\nNext, we derive general expressions for $\\mathrm{PPV}$ and $\\mathrm{NPV}$ as functions of the population fall prevalence, denoted by $p \\in (0,1)$. We assume that sensitivity ($\\mathrm{Se}$) and specificity ($\\mathrm{Sp}$) are intrinsic properties of the algorithm and remain constant across different populations.\n\nUsing Bayes' theorem, the $\\mathrm{PPV}$ is the conditional probability of a true fall given a positive algorithm classification, $P(\\text{Fall} | \\text{Alg-Pos})$.\n$$ \\mathrm{PPV}(p) = \\frac{P(\\text{Alg-Pos} | \\text{Fall}) P(\\text{Fall})}{P(\\text{Alg-Pos})} $$\nThe denominator, $P(\\text{Alg-Pos})$, is found using the law of total probability:\n$$ P(\\text{Alg-Pos}) = P(\\text{Alg-Pos} | \\text{Fall}) P(\\text{Fall}) + P(\\text{Alg-Pos} | \\text{Non-fall}) P(\\text{Non-fall}) $$\nSubstituting the definitions $P(\\text{Fall})=p$, $P(\\text{Non-fall})=1-p$, $P(\\text{Alg-Pos} | \\text{Fall})=\\mathrm{Se}$, and $P(\\text{Alg-Pos} | \\text{Non-fall})=1-\\mathrm{Sp}$, we get:\n$$ \\mathrm{PPV}(p) = \\frac{(\\mathrm{Se}) \\cdot p}{(\\mathrm{Se}) \\cdot p + (1-\\mathrm{Sp})(1-p)} $$\nSimilarly, the $\\mathrm{NPV}$ is the conditional probability of a true non-fall given a negative algorithm classification, $P(\\text{Non-fall} | \\text{Alg-Neg})$.\n$$ \\mathrm{NPV}(p) = \\frac{P(\\text{Alg-Neg} | \\text{Non-fall}) P(\\text{Non-fall})}{P(\\text{Alg-Neg})} $$\nThe denominator, $P(\\text{Alg-Neg})$, is:\n$$ P(\\text{Alg-Neg}) = P(\\text{Alg-Neg} | \\text{Non-fall}) P(\\text{Non-fall}) + P(\\text{Alg-Neg} | \\text{Fall}) P(\\text{Fall}) $$\nSubstituting the definitions $P(\\text{Alg-Neg} | \\text{Non-fall})=\\mathrm{Sp}$ and $P(\\text{Alg-Neg} | \\text{Fall})=1-\\mathrm{Se}$, we get:\n$$ \\mathrm{NPV}(p) = \\frac{(\\mathrm{Sp}) \\cdot (1-p)}{(\\mathrm{Sp}) \\cdot (1-p) + (1-\\mathrm{Se}) \\cdot p} $$\nNow, we use the calculated values $\\mathrm{Se} = 0.8$ and $\\mathrm{Sp} = 0.95$. The functions become:\n$$ \\mathrm{PPV}(p) = \\frac{0.8p}{0.8p + (1-0.95)(1-p)} = \\frac{0.8p}{0.8p + 0.05(1-p)} = \\frac{0.8p}{0.75p + 0.05} = \\frac{16p}{15p+1} $$\n$$ \\mathrm{NPV}(p) = \\frac{0.95(1-p)}{0.95(1-p) + (1-0.8)p} = \\frac{0.95(1-p)}{0.95(1-p) + 0.2p} = \\frac{0.95 - 0.95p}{0.95 - 0.75p} = \\frac{19(1-p)}{19 - 15p} $$\nThe prevalence in the validation cohort was $p_{cohort} = \\frac{120}{1000} = 0.12$. As prevalence changes, $\\mathrm{PPV}$ and $\\mathrm{NPV}$ will change. An increase in prevalence $p$ will increase $\\mathrm{PPV}(p)$ and decrease $\\mathrm{NPV}(p)$.\n\nWe evaluate these functions at the specified alternative prevalences.\nAt $p=0.02$:\n$$ \\mathrm{PPV}(0.02) = \\frac{16(0.02)}{15(0.02)+1} = \\frac{0.32}{0.3+1} = \\frac{0.32}{1.3} = \\frac{16}{65} \\approx 0.2461538... $$\n$$ \\mathrm{NPV}(0.02) = \\frac{19(1-0.02)}{19 - 15(0.02)} = \\frac{19(0.98)}{19 - 0.3} = \\frac{18.62}{18.7} \\approx 0.9957219... $$\nAt $p=0.30$:\n$$ \\mathrm{PPV}(0.30) = \\frac{16(0.30)}{15(0.30)+1} = \\frac{4.8}{4.5+1} = \\frac{4.8}{5.5} = \\frac{48}{55} \\approx 0.872727... $$\n$$ \\mathrm{NPV}(0.30) = \\frac{19(1-0.30)}{19 - 15(0.30)} = \\frac{19(0.7)}{19 - 4.5} = \\frac{13.3}{14.5} \\approx 0.917241... $$\nThe dramatic dependence of predictive values on prevalence is evident. When deployed in a population with a low fall prevalence of $p=0.02$, the $\\mathrm{PPV}$ drops to approximately $0.2462$, meaning a large majority of alerts would be false alarms. The $\\mathrm{NPV}$, however, becomes very high ($0.9957$), providing strong confidence that an episode not flagged by the algorithm is indeed a non-fall.\n\nThe question asks for the value of the Positive Predictive Value at $p=0.02$, rounded to four significant figures.\n$$ \\mathrm{PPV}(0.02) \\approx 0.2461538...$$\nRounding to four significant figures gives $0.2462$.", "answer": "$$\\boxed{0.2462}$$", "id": "5007644"}]}