{"hands_on_practices": [{"introduction": "In high-throughput proteomics, search engines generate thousands of peptide-spectrum matches (PSMs), each with a raw score that is not directly interpretable as a measure of confidence. To ensure the reliability of these identifications, a rigorous statistical validation is essential. This exercise guides you through the implementation of the target-decoy approach, the gold standard for estimating and controlling the False Discovery Rate (FDR) in proteomics, allowing you to transform raw scores into meaningful, calibrated significance values ($q$-values) [@problem_id:4994733]. Mastering this practice is fundamental to establishing the statistical foundation upon which all subsequent biomarker analyses are built.", "problem": "You are given arrays of raw peptide-spectrum match (PSM) scores produced by a tandem mass spectrometry search engine for two classes: targets (putative real peptide identifications) and decoys (synthetic or shuffled sequences designed to emulate incorrect matches). The goal is to design a principled calibration procedure that transforms raw scores into significance values using the decoy null distribution, and then to compute minimal false discovery rates (q-values) to determine identification thresholds.\n\nUse the following fundamental base in your derivation and algorithm:\n\n- In the target-decoy framework, incorrect matches are assumed to be distributed like decoys under the null. Let the decoy scores be sampled from a null distribution. For any raw score $s$, define the calibrated $p$-value via the empirical decoy tail probability:\n$$\np(s) = \\frac{\\#\\{\\text{decoy scores } \\ge s\\}}{n_D}\n$$\nwhere $n_D$ is the total number of decoy observations. This is an empirical, distribution-free calibration that maps heterogeneous raw scores onto a common significance scale.\n\n- For a significance threshold $t$ applied to calibrated $p$-values, define $D(t)$ as the number of decoys with $p$-value less than or equal to $t$ and $T(t)$ as the number of targets with $p$-value less than or equal to $t$. The estimated false discovery rate at threshold $t$ is\n$$\n\\widehat{\\mathrm{FDR}}(t) = \\frac{D(t)}{T(t)} \\, .\n$$\n\n- For a given target PSM with calibrated $p$-value $p_i$, its $q$-value is the minimal false discovery rate at which it would be accepted. If $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$ denote the sorted target $p$-values, then for the target at rank $k$:\n$$\nq_{(k)} = \\min_{j \\ge k} \\widehat{\\mathrm{FDR}}(p_{(j)}) \\, .\n$$\nThis enforces monotonicity of the $q$-values with respect to acceptance thresholds. All proportions and thresholds must be expressed as decimals (for example, use $0.05$ and not a percentage sign).\n\nYour task is to implement this calibration and $q$-value computation in a single program. The program must:\n\n1. Accept no input; instead, use the embedded test suite provided below.\n2. For each test case, compute calibrated $p$-values for targets and decoys using the empirical decoy tail probability $p(s)$ as defined above.\n3. Compute target $q$-values using the definition above, with $\\widehat{\\mathrm{FDR}}(t) = D(t)/T(t)$ and no additional continuity correction.\n4. For each specified identification threshold $\\alpha$ (expressed as a decimal), count the number of target PSMs whose $q$-value is less than or equal to $\\alpha$.\n5. Aggregate these counts across all test cases and thresholds into a single flat list in a predefined order and print it exactly once.\n\nTest suite parameter values:\n\n- Test Case $1$ (general case):\n    - Target scores: $[2.1, 3.0, 1.5, 2.7, 3.5, 0.9, 1.2]$\n    - Decoy scores: $[0.5, 1.0, 1.4, 2.0, 2.3, 2.6, 2.9, 3.2]$\n    - Thresholds $\\alpha$: $[0.05, 0.10]$\n\n- Test Case $2$ (boundary case with very strong targets):\n    - Target scores: $[4.0, 3.8, 3.6, 3.5]$\n    - Decoy scores: $[0.2, 0.3, 0.4, 0.1, 0.25]$\n    - Thresholds $\\alpha$: $[0.01, 0.05, 0.10]$\n\n- Test Case $3$ (edge case with ties between target and decoy scores):\n    - Target scores: $[1.0, 1.0, 0.5]$\n    - Decoy scores: $[1.0, 0.5, 0.5]$\n    - Thresholds $\\alpha$: $[0.20]$\n\nOutput specification:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must be a flat sequence of integers giving, in order, the counts of accepted targets at each threshold for Test Case $1$ (in the order given), followed by Test Case $2$ (in the order given), followed by Test Case $3$ (in the order given). For example, the output must have the form $[\\text{tc1\\_a1},\\text{tc1\\_a2},\\text{tc2\\_a1},\\text{tc2\\_a2},\\text{tc2\\_a3},\\text{tc3\\_a1}]$.", "solution": "The objective is to transform raw peptide-spectrum match (PSM) scores into calibrated significance values and then determine minimal false discovery rates ($q$-values) for setting identification thresholds. The scientific foundation rests on the target-decoy strategy, which treats decoy matches as a faithful empirical surrogate for the null distribution of incorrect matches. This permits nonparametric calibration and control of discoveries.\n\nPrinciple $1$: Calibration via the empirical null distribution. Let the decoy scores be independent draws from the null distribution of incorrect matches. For any raw score $s$, the empirical tail probability under the decoy distribution gives a calibrated $p$-value:\n$$\np(s) = \\frac{\\#\\{\\text{decoy scores } \\ge s\\}}{n_D} \\, .\n$$\nThis mapping is monotone decreasing in $s$ and converts arbitrary raw scores into a common significance scale. Under the null, $p(s)$ is approximately uniform on $[0,1]$ because it is an empirical cumulative distribution function (by the probability integral transform), and under the alternative (true targets), $p(s)$ concentrates near $0$.\n\nPrinciple $2$: Estimating the false discovery rate (FDR). For a threshold $t$ on calibrated $p$-values, define\n$$\nD(t) = \\#\\{\\text{decoy } p \\le t\\}, \\quad T(t) = \\#\\{\\text{target } p \\le t\\} \\, .\n$$\nAssuming a balanced search and that the decoy $p$-values represent the null, the proportion of false discoveries among accepted targets at threshold $t$ is estimated by\n$$\n\\widehat{\\mathrm{FDR}}(t) = \\frac{D(t)}{T(t)} \\, .\n$$\nThis estimator is an empirical ratio of accepted nulls to accepted targets. We do not introduce a continuity correction here; thus $\\widehat{\\mathrm{FDR}}(t)$ can be $0$ if no decoys are accepted.\n\nPrinciple $3$: $q$-values as minimal FDR. The $q$-value for a given target PSM is defined as the minimal false discovery rate at which it would be accepted. Let the sorted target $p$-values be $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$. At each rank $k$, consider the acceptance threshold $t = p_{(k)}$ and compute\n$$\n\\widehat{\\mathrm{FDR}}(p_{(k)}) = \\frac{D(p_{(k)})}{T(p_{(k)})} = \\frac{D(p_{(k)})}{k} \\, .\n$$\nTo enforce monotonicity (that is, $q$-values should be non-decreasing with decreasing stringency), define\n$$\nq_{(k)} = \\min_{j \\ge k} \\widehat{\\mathrm{FDR}}(p_{(j)}) \\, .\n$$\nThis is the empirical analogue of the minimal FDR at or above the PSM’s own acceptance threshold.\n\nAlgorithmic design:\n\n- Compute calibrated $p$-values for both targets and decoys using the empirical decoy tail probability $p(s)$. This step performs score calibration, transforming heterogeneous raw scores onto a unified significance scale, justified by the empirical null modeled by decoys.\n\n- Sort target $p$-values in ascending order to form ranks. For each sorted target threshold $p_{(k)}$, compute $D(p_{(k)})$ using the decoy $p$-values and set $T(p_{(k)}) = k$. The estimated false discovery rates at these thresholds are $\\widehat{\\mathrm{FDR}}(p_{(k)}) = D(p_{(k)})/k$.\n\n- Compute the suffix minimum over the sequence $\\{\\widehat{\\mathrm{FDR}}(p_{(k)})\\}_{k=1}^m$ to obtain monotone $q$-values: $q_{(k)} = \\min_{j \\ge k} \\widehat{\\mathrm{FDR}}(p_{(j)})$. Map these back to the original target ordering.\n\n- For each identification threshold $\\alpha$ (expressed in decimals), count the number of target $q$-values satisfying $q_i \\le \\alpha$.\n\nTest suite coverage rationale:\n\n- Test Case $1$ exercises typical overlap between target and decoy scores, producing a mix of small and large $p$-values and ensuring nontrivial $D(t)$ and $T(t)$ ratios.\n\n- Test Case $2$ represents a boundary scenario in which targets are far stronger than decoys; here the empirical decoy tail probabilities for targets are $0$, and $\\widehat{\\mathrm{FDR}}(t)$ can be $0$, validating that the algorithm accepts many targets at stringent $\\alpha$.\n\n- Test Case $3$ introduces ties between target and decoy scores to test robustness in computing tail probabilities and cumulative counts, ensuring consistent handling of equality through the $\\ge$ and $\\le$ definitions.\n\nFinal output format:\n\n- Produce a single line with a flat list of integers giving, in order, the counts of accepted targets for Test Case $1$ thresholds, then Test Case $2$ thresholds, then Test Case $3$ thresholds, exactly as $[\\text{tc1\\_a1},\\text{tc1\\_a2},\\text{tc2\\_a1},\\text{tc2\\_a2},\\text{tc2\\_a3},\\text{tc3\\_a1}]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef empirical_p_values(scores, decoy_scores):\n    \"\"\"\n    Compute calibrated p-values for given raw scores using the empirical decoy tail.\n    p(s) = #{decoy >= s} / n_decoy\n    \"\"\"\n    decoy_scores = np.asarray(decoy_scores, dtype=float)\n    n_decoy = decoy_scores.size\n    # Sort decoys for efficient tail counting using binary search\n    decoy_sorted = np.sort(decoy_scores)\n    # For each s, count how many decoys are >= s using searchsorted on ascending array\n    # Number >= s = n_decoy - index of first element > (s - epsilon)\n    # We use 'left' on s to get index of first >= s, then tail count is n_decoy - idx.\n    def tail_count(s):\n        idx = np.searchsorted(decoy_sorted, s, side='left')\n        return n_decoy - idx\n    # Vectorize tail_count over scores\n    scores = np.asarray(scores, dtype=float)\n    tail_counts = np.array([tail_count(s) for s in scores], dtype=float)\n    pvals = tail_counts / float(n_decoy)\n    return pvals\n\ndef target_decoy_q_values(target_pvals, decoy_pvals):\n    \"\"\"\n    Compute q-values for targets using the target-decoy FDR estimator:\n    FDR(p_(k)) = D(p_(k)) / k where D counts decoy p-values <= threshold.\n    q_(k) = min_{j>=k} FDR(p_(j)) to enforce monotonicity.\n    \"\"\"\n    target_pvals = np.asarray(target_pvals, dtype=float)\n    decoy_pvals = np.asarray(decoy_pvals, dtype=float)\n\n    # Sort target p-values ascending and keep indices to map back\n    sort_idx = np.argsort(target_pvals)\n    sorted_target_p = target_pvals[sort_idx]\n\n    # Pre-sort decoy p-values ascending for cumulative counting\n    decoy_sorted_p = np.sort(decoy_pvals)\n\n    # For each sorted target threshold t, compute D(t) = # decoy p <= t using searchsorted with 'right'\n    D = np.searchsorted(decoy_sorted_p, sorted_target_p, side='right').astype(float)\n    # T(k) = k for ranks 1..m\n    m = sorted_target_p.size\n    T = np.arange(1, m + 1, dtype=float)\n\n    # Estimated FDR at each threshold\n    fdr = D / T\n\n    # Compute suffix minimum to get monotone q-values in sorted order\n    # q_sorted[k] = min_{j>=k} fdr[j]\n    # Use cumulative minimum on reversed array, then reverse back\n    rev_cummin = np.minimum.accumulate(fdr[::-1])\n    q_sorted = rev_cummin[::-1]\n\n    # Map back to original order\n    q_vals = np.empty_like(q_sorted)\n    q_vals[sort_idx] = q_sorted\n\n    return q_vals\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {\n            \"target_scores\": [2.1, 3.0, 1.5, 2.7, 3.5, 0.9, 1.2],\n            \"decoy_scores\":  [0.5, 1.0, 1.4, 2.0, 2.3, 2.6, 2.9, 3.2],\n            \"alphas\":        [0.05, 0.10],\n        },\n        # Test Case 2\n        {\n            \"target_scores\": [4.0, 3.8, 3.6, 3.5],\n            \"decoy_scores\":  [0.2, 0.3, 0.4, 0.1, 0.25],\n            \"alphas\":        [0.01, 0.05, 0.10],\n        },\n        # Test Case 3\n        {\n            \"target_scores\": [1.0, 1.0, 0.5],\n            \"decoy_scores\":  [1.0, 0.5, 0.5],\n            \"alphas\":        [0.20],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        target_scores = case[\"target_scores\"]\n        decoy_scores = case[\"decoy_scores\"]\n        alphas = case[\"alphas\"]\n\n        # Step 1: Calibrate scores to p-values using empirical decoy tail\n        target_p = empirical_p_values(target_scores, decoy_scores)\n        decoy_p = empirical_p_values(decoy_scores, decoy_scores)\n\n        # Step 2: Compute q-values for targets using target-decoy FDR estimator\n        q_vals = target_decoy_q_values(target_p, decoy_p)\n\n        # Step 3: For each alpha threshold, count accepted targets (q <= alpha)\n        for alpha in alphas:\n            count = int(np.sum(q_vals <= float(alpha)))\n            results.append(count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4994733"}, {"introduction": "Once a set of candidate protein biomarkers has been confidently identified and quantified, the next crucial step is to assess their collective ability to distinguish between different clinical states, such as disease versus control. The Receiver Operating Characteristic (ROC) curve is a powerful, threshold-independent tool for visualizing and measuring the discriminatory performance of such a classifier. This practice will allow you to derive an ROC curve from a set of model predictions and compute the Area Under the Curve (AUC), a summary metric that quantifies the biomarker panel's intrinsic ability to separate two groups [@problem_id:4994751].", "problem": "A translational proteomics team is validating a candidate biomarker panel measured by Liquid Chromatography–Tandem Mass Spectrometry (LC-MS/MS) to discriminate a clinically defined disease state from controls. A probabilistic classifier trained on peptide intensity features outputs ranked predicted probabilities for blinded validation samples. For the validation set, the known clinical status and model output probabilities are:\n\n- Disease present (positives): $\\{0.93,\\,0.85,\\,0.77,\\,0.52,\\,0.40,\\,0.30\\}$.\n- Disease absent (negatives): $\\{0.88,\\,0.68,\\,0.35,\\,0.25,\\,0.15,\\,0.05\\}$.\n\nUsing the foundational definitions that the True Positive Rate (TPR, sensitivity) is $\\mathrm{TPR} = \\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$ and the False Positive Rate (FPR, $1-\\text{specificity}$) is $\\mathrm{FPR} = \\frac{\\mathrm{FP}}{\\mathrm{FP}+\\mathrm{TN}}$, and that the Receiver Operating Characteristic (ROC) curve is the parametric plot of $\\left(\\mathrm{FPR}(\\tau),\\,\\mathrm{TPR}(\\tau)\\right)$ as the decision threshold $\\tau$ on the predicted probability is swept from high to low, perform the following:\n\n- Derive the ROC curve from first principles by sweeping $\\tau$ across the set of unique model outputs, and explicitly enumerate the sequence of $\\left(\\mathrm{FPR},\\,\\mathrm{TPR}\\right)$ points.\n- Compute the Area Under the Curve (AUC) as the integral of $\\mathrm{TPR}$ with respect to $\\mathrm{FPR}$ over $\\mathrm{FPR}\\in[0,1]$, evaluating it exactly for the given data.\n\nAdditionally, for clinical decision-making, briefly interpret discrimination versus calibration in this context. Assume a hypothetical recalibration of predicted probabilities via the monotonic mapping $p' = \\sigma\\!\\left(a + b\\,\\sigma^{-1}(p)\\right)$ with $\\sigma(x) = \\frac{1}{1+\\exp(-x)}$, $a = 0$, and $b = 2$. Discuss, without performing any new numerical computation, whether this recalibration would change the ROC curve or the AUC, and explain the implications for threshold selection under unequal misclassification costs.\n\nExpress the final AUC as an exact fraction or a decimal number. Do not include any units and do not use a percentage sign. If you choose a decimal, you may report it exactly without rounding requirements.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It provides sufficient data and clear definitions to derive a unique solution for the requested calculations and a well-reasoned discussion for the conceptual parts. The problem is a standard exercise in the evaluation of binary classifiers, a core task in translational medicine and biomarker discovery.\n\n### Part 1: Derivation of the ROC Curve\n\nThe Receiver Operating Characteristic (ROC) curve is a plot of the True Positive Rate (TPR) against the False Positive Rate (FPR) at various decision threshold settings.\n\nThe given data are:\n-   Probabilities for the disease-present (positive) class, $P$: $\\{0.93, 0.85, 0.77, 0.52, 0.40, 0.30\\}$. The total number of positives is $N_P = 6$.\n-   Probabilities for the disease-absent (negative) class, $N$: $\\{0.88, 0.68, 0.35, 0.25, 0.15, 0.05\\}$. The total number of negatives is $N_N = 6$.\n\nThe TPR and FPR are defined as:\n$$ \\mathrm{TPR} = \\frac{\\mathrm{TP}}{N_P} \\quad \\text{and} \\quad \\mathrm{FPR} = \\frac{\\mathrm{FP}}{N_N} $$\nwhere TP (True Positives) is the number of positive samples with a score greater than or equal to the threshold $\\tau$, and FP (False Positives) is the number of negative samples with a score $\\ge \\tau$.\n\nTo construct the ROC curve, we consider each unique score value as a potential threshold. We sort all unique scores in descending order:\n$S = \\{0.93, 0.88, 0.85, 0.77, 0.68, 0.52, 0.40, 0.35, 0.30, 0.25, 0.15, 0.05\\}$.\n\nWe sweep the threshold $\\tau$ from a value greater than the maximum score (e.g., $\\tau=1$) down to a value less than or equal to the minimum score.\n\n1.  For $\\tau > 0.93$: No sample is classified as positive. $\\mathrm{TP}=0$, $\\mathrm{FP}=0$. Thus, $(\\mathrm{FPR}, \\mathrm{TPR}) = (0, 0)$. This is the starting point of the ROC curve.\n\n2.  As we lower the threshold past each score, we update TP or FP. Each time the threshold crosses a positive sample's score, TP increases by $1$, and TPR increases by $1/N_P = 1/6$. Each time it crosses a negative sample's score, FP increases by $1$, and FPR increases by $1/N_N = 1/6$.\n\nThe sequence of points $(\\mathrm{FPR}, \\mathrm{TPR})$ is generated as the threshold is lowered:\n-   $\\tau = 0.93$: A positive score is crossed. TP becomes $1$. Point: $(\\frac{0}{6}, \\frac{1}{6}) = (0, \\frac{1}{6})$.\n-   $\\tau = 0.88$: A negative score is crossed. FP becomes $1$. Point: $(\\frac{1}{6}, \\frac{1}{6})$.\n-   $\\tau = 0.85$: A positive score is crossed. TP becomes $2$. Point: $(\\frac{1}{6}, \\frac{2}{6}) = (\\frac{1}{6}, \\frac{1}{3})$.\n-   $\\tau = 0.77$: A positive score is crossed. TP becomes $3$. Point: $(\\frac{1}{6}, \\frac{3}{6}) = (\\frac{1}{6}, \\frac{1}{2})$.\n-   $\\tau = 0.68$: A negative score is crossed. FP becomes $2$. Point: $(\\frac{2}{6}, \\frac{3}{6}) = (\\frac{1}{3}, \\frac{1}{2})$.\n-   $\\tau = 0.52$: A positive score is crossed. TP becomes $4$. Point: $(\\frac{2}{6}, \\frac{4}{6}) = (\\frac{1}{3}, \\frac{2}{3})$.\n-   $\\tau = 0.40$: A positive score is crossed. TP becomes $5$. Point: $(\\frac{2}{6}, \\frac{5}{6}) = (\\frac{1}{3}, \\frac{5}{6})$.\n-   $\\tau = 0.35$: A negative score is crossed. FP becomes $3$. Point: $(\\frac{3}{6}, \\frac{5}{6}) = (\\frac{1}{2}, \\frac{5}{6})$.\n-   $\\tau = 0.30$: A positive score is crossed. TP becomes $6$. Point: $(\\frac{3}{6}, \\frac{6}{6}) = (\\frac{1}{2}, 1)$.\n-   $\\tau = 0.25$: A negative score is crossed. FP becomes $4$. Point: $(\\frac{4}{6}, \\frac{6}{6}) = (\\frac{2}{3}, 1)$.\n-   $\\tau = 0.15$: A negative score is crossed. FP becomes $5$. Point: $(\\frac{5}{6}, \\frac{6}{6}) = (\\frac{5}{6}, 1)$.\n-   $\\tau = 0.05$: A negative score is crossed. FP becomes $6$. Point: $(\\frac{6}{6}, \\frac{6}{6}) = (1, 1)$. This is the final point.\n\nThe explicit sequence of $(\\mathrm{FPR}, \\mathrm{TPR})$ vertices for the ROC curve, starting from $(0,0)$ and ending at $(1,1)$, is: $(0,0) \\to (0, \\frac{1}{6}) \\to (\\frac{1}{6}, \\frac{1}{6}) \\to (\\frac{1}{6}, \\frac{1}{3}) \\to (\\frac{1}{6}, \\frac{1}{2}) \\to (\\frac{1}{3}, \\frac{1}{2}) \\to (\\frac{1}{3}, \\frac{2}{3}) \\to (\\frac{1}{3}, \\frac{5}{6}) \\to (\\frac{1}{2}, \\frac{5}{6}) \\to (\\frac{1}{2}, 1) \\to (\\frac{2}{3}, 1) \\to (\\frac{5}{6}, 1) \\to (1,1)$.\n\n### Part 2: Computation of the Area Under the Curve (AUC)\n\nThe AUC is the integral of the ROC curve, $\\int_0^1 \\mathrm{TPR}(\\mathrm{FPR}) \\, d\\mathrm{FPR}$. For an empirical ROC curve constructed from discrete data, this integral is calculated by summing the areas of the trapezoids formed by the vertices. The area of a trapezoid defined by points $(x_{i-1}, y_{i-1})$ and $(x_i, y_i)$ is $\\frac{1}{2}(y_{i-1} + y_i)(x_i - x_{i-1})$.\n\nThe ROC curve consists of horizontal and vertical segments. The area is accumulated only by the horizontal segments where $\\mathrm{FPR}$ changes.\n-   From $\\mathrm{FPR}=0$ to $\\mathrm{FPR}=1/6$, $\\mathrm{TPR}$ is constant at $1/6$. Area = $(\\frac{1}{6} - 0) \\times \\frac{1}{6} = \\frac{1}{36}$. (This assumes step-like behavior, an alternative is the trapezoidal rule which we will use).\n\nUsing the trapezoidal rule on the vertices:\n-   Points $(\\frac{1}{6}, \\frac{1}{6})$ to $(\\frac{1}{6}, \\frac{1}{2})$: These are vertical segments where $\\Delta\\mathrm{FPR}=0$, contributing no area.\n-   Points $(\\frac{1}{6}, \\frac{1}{2})$ to $(\\frac{1}{3}, \\frac{1}{2})$: horizontal segment. Area = $\\frac{1}{2}(\\frac{1}{2}+\\frac{1}{2})(\\frac{1}{3}-\\frac{1}{6}) = \\frac{1}{2}(1)(\\frac{1}{6}) = \\frac{1}{12}$.\n-   Points $(\\frac{1}{3}, \\frac{1}{2})$ to $(\\frac{1}{3}, \\frac{5}{6})$: vertical segment, zero area.\n-   And so on.\n\nA more direct method is to sum the areas of rectangles under the curve.\n-   Area$_1$: width $\\frac{1}{6}$, height $\\frac{1}{6}$. Area = $\\frac{1}{36}$.\n-   Area$_2$: width $\\frac{1}{6}$, height $\\frac{3}{6}$. Area = $(\\frac{2}{6}-\\frac{1}{6}) \\times \\frac{3}{6} = \\frac{1}{6} \\times \\frac{3}{6} = \\frac{3}{36}$.\n-   Area$_3$: width $\\frac{1}{6}$, height $\\frac{5}{6}$. Area = $(\\frac{3}{6}-\\frac{2}{6}) \\times \\frac{5}{6} = \\frac{1}{6} \\times \\frac{5}{6} = \\frac{5}{36}$.\n-   Area$_4$: width $\\frac{3}{6}$, height $1$. Area = $(1-\\frac{3}{6}) \\times 1 = \\frac{3}{6} = \\frac{18}{36}$.\nTotal Area = $\\frac{1}{36} + \\frac{3}{36} + \\frac{5}{36} + \\frac{18}{36} = \\frac{27}{36}$.\n\nAn equivalent and robust method is using the Wilcoxon-Mann-Whitney U statistic formulation, where the AUC is the probability that a randomly chosen positive sample has a higher score than a randomly chosen negative sample, $P(S_P > S_N)$. There are $N_P \\times N_N = 6 \\times 6 = 36$ possible pairs of (positive, negative) samples.\nWe count the number of pairs $(p, n)$ where $p \\in P$, $n \\in N$, and $p > n$.\n-   For $p=0.93$: $6$ pairs ($0.93 >$ all $6$ negative scores).\n-   For $p=0.85$: $5$ pairs ($0.85 >$ all negative scores except $0.88$).\n-   For $p=0.77$: $5$ pairs ($0.77 >$ all negative scores except $0.88$).\n-   For $p=0.52$: $4$ pairs ($0.52 > \\{0.35, 0.25, 0.15, 0.05\\}$).\n-   For $p=0.40$: $4$ pairs ($0.40 > \\{0.35, 0.25, 0.15, 0.05\\}$).\n-   For $p=0.30$: $3$ pairs ($0.30 > \\{0.25, 0.15, 0.05\\}$).\nThe total number of concordant pairs is $6 + 5 + 5 + 4 + 4 + 3 = 27$.\nThere are no ties between positive and negative scores.\nThe AUC is therefore:\n$$ \\mathrm{AUC} = \\frac{27}{36} = \\frac{3}{4} = 0.75 $$\n\n### Part 3: Interpretation of Discrimination and Calibration\n\n-   **Discrimination** refers to a model's ability to distinguish between classes. A model with good discrimination assigns higher scores to positive instances than to negative instances. The ROC curve and its associated AUC are pure measures of discrimination. They are constructed based on the rank ordering of scores. An AUC of $1.0$ represents perfect discrimination, while an AUC of $0.5$ represents a model with no better-than-random discrimination.\n\n-   **Calibration** refers to the degree to which a model's predicted probabilities reflect the true likelihood of an event. A model is perfectly calibrated if, among all instances where it predicts a probability of $p$, the true fraction of positive instances is also $p$. Calibration is about the absolute meaning of the predicted values, not just their rank. A model can have excellent discrimination (high AUC) but be poorly calibrated (e.g., systematically over- or under-confident).\n\nIn summary, discrimination is about separating classes, while calibration is about the trustworthiness of the probability scores themselves.\n\n### Part 4: Effect of Recalibration\n\nThe proposed recalibration is a monotonic mapping $p' = \\sigma(a + b\\,\\sigma^{-1}(p))$. With $a=0$ and $b=2$, the mapping is $p' = \\sigma(2\\,\\sigma^{-1}(p))$. The sigmoid function $\\sigma(x) = (1+\\exp(-x))^{-1}$ and its inverse, the logit function $\\sigma^{-1}(p) = \\ln(p/(1-p))$, are both strictly monotonically increasing. Since $b = 2 > 0$, the transformation $x \\mapsto 2x$ is also strictly increasing. The composition of strictly monotonically increasing functions is itself strictly monotonically increasing.\n\n-   **Effect on ROC Curve and AUC**: The ROC curve and AUC are measures of discrimination and depend only on the rank ordering of the scores. Since the recalibration function $p \\mapsto p'$ is strictly monotonic, it preserves the rank order of the predicted probabilities. If $p_1 > p_2$, then $p'_1 > p'_2$. Consequently, the ROC curve will be **identical** to the original one, and the AUC will be **unchanged**. The recalibration improves calibration without affecting discrimination.\n\n-   **Implications for Threshold Selection**: Clinical decisions often involve unequal costs for different types of misclassification (False Positives vs. False Negatives). The optimal decision threshold $\\tau^*$ depends on these costs. For example, to minimize expected cost, one might classify as positive if the predicted probability $p$ exceeds a threshold related to the cost ratio, e.g., $\\tau^* = \\frac{C_{FP}}{C_{FP} + C_{FN}}$, where $C_{FP}$ and $C_{FN}$ are the costs of a false positive and false negative, respectively. This formula assumes the probabilities are well-calibrated. If the original probabilities $p$ are not calibrated, applying a theoretically derived threshold is incorrect. Recalibration aims to make the probabilities $p'$ reliable. By using the recalibrated probabilities $p'$, a decision-maker can apply a threshold derived from cost-benefit analysis with greater confidence that it will lead to optimal outcomes. Thus, while recalibration does not change the overall discriminatory power (AUC), it is crucial for making well-informed, cost-sensitive decisions at the individual level by ensuring the probabilities used for thresholding are meaningful.", "answer": "$$\\boxed{0.75}$$", "id": "4994751"}, {"introduction": "A biomarker with excellent discriminatory power, indicated by a high AUC, is not guaranteed to be clinically useful. Its practical value depends on the context of its application, particularly the prevalence of the disease in the target population. This exercise demonstrates how to translate a test's sensitivity and specificity into Positive and Negative Predictive Values (PPV and NPV) using Bayes' theorem, answering the critical clinical questions about the probability of disease given a specific test result [@problem_id:4994694]. This final step is essential for bridging the gap between statistical performance and real-world clinical decision-making in translational medicine.", "problem": "A translational proteomics assay based on Parallel Reaction Monitoring (PRM) Mass Spectrometry (MS) has been developed to classify patients for a clinically actionable phenotype (disease present versus disease absent) using a validated set of peptide biomarkers. In an independent clinical validation cohort intended to match the assay’s real-world deployment, the assay’s performance was characterized by sensitivity $\\mathrm{sens}$ and specificity $\\mathrm{spec}$, and the target population’s disease prevalence was estimated as $P$. Sensitivity is defined as the conditional probability $P(T^{+} | D^{+})$, where $T^{+}$ denotes a positive test result and $D^{+}$ denotes disease present. Specificity is defined as $P(T^{-} | D^{-})$, where $T^{-}$ denotes a negative test result and $D^{-}$ denotes disease absent. The disease prevalence is $P(D^{+}) = P$ and $P(D^{-}) = 1-P$.\n\nStarting from the definitions above, the Law of Total Probability, and Bayes’ theorem for conditional probability, derive expressions for the Positive Predictive Value (PPV), $P(D^{+} | T^{+})$, and the Negative Predictive Value (NPV), $P(D^{-} | T^{-})$, in terms of $\\mathrm{sens}$, $\\mathrm{spec}$, and $P$. Then, evaluate both quantities numerically for an assay with $\\mathrm{sens}=0.92$, $\\mathrm{spec}=0.85$, and $P=0.12$, appropriate for a high-risk clinic population.\n\nExpress both PPV and NPV as decimal fractions between $0$ and $1$, and round each value to four significant figures. Report your final numerical results together as an ordered pair $(\\mathrm{PPV},\\ \\mathrm{NPV})$.", "solution": "The problem asks for $P(D^{+}\\mid T^{+})$ and $P(D^{-}\\mid T^{-})$ using the fundamental definitions of sensitivity, specificity, prevalence, the Law of Total Probability, and Bayes’ theorem.\n\nDefine the events:\n- $D^{+}$: disease present,\n- $D^{-}$: disease absent,\n- $T^{+}$: positive test,\n- $T^{-}$: negative test.\n\nBy definition,\n- Sensitivity is $\\mathrm{sens}=P(T^{+}\\mid D^{+})$.\n- Specificity is $\\mathrm{spec}=P(T^{-}\\mid D^{-})$.\n- Prevalence is $P(D^{+})=P$, hence $P(D^{-})=1-P$.\n\nFrom these definitions, we also have\n$$\nP(T^{+}\\mid D^{-}) = 1 - \\mathrm{spec}, \\quad P(T^{-}\\mid D^{+}) = 1 - \\mathrm{sens}.\n$$\n\nBy the Law of Total Probability, the marginal probability of a positive test is\n$$\nP(T^{+}) = P(T^{+}\\mid D^{+})P(D^{+}) + P(T^{+}\\mid D^{-})P(D^{-}) = \\mathrm{sens}\\cdot P + (1-\\mathrm{spec})\\cdot (1-P).\n$$\nSimilarly, the marginal probability of a negative test is\n$$\nP(T^{-}) = P(T^{-}\\mid D^{+})P(D^{+}) + P(T^{-}\\mid D^{-})P(D^{-}) = (1-\\mathrm{sens})\\cdot P + \\mathrm{spec}\\cdot (1-P).\n$$\n\nBayes’ theorem gives the Positive Predictive Value (PPV) as\n$$\n\\mathrm{PPV} = P(D^{+}\\mid T^{+}) = \\frac{P(T^{+}\\mid D^{+})P(D^{+})}{P(T^{+})} = \\frac{\\mathrm{sens}\\cdot P}{\\mathrm{sens}\\cdot P + (1-\\mathrm{spec})\\cdot (1-P)}.\n$$\nBayes’ theorem similarly gives the Negative Predictive Value (NPV) as\n$$\n\\mathrm{NPV} = P(D^{-}\\mid T^{-}) = \\frac{P(T^{-}\\mid D^{-})P(D^{-})}{P(T^{-})} = \\frac{\\mathrm{spec}\\cdot (1-P)}{(1-\\mathrm{sens})\\cdot P + \\mathrm{spec}\\cdot (1-P)}.\n$$\n\nNow substitute the numerical values $\\mathrm{sens}=0.92$, $\\mathrm{spec}=0.85$, and $P=0.12$.\n\nCompute the components for $\\mathrm{PPV}$:\n$$\n\\mathrm{sens}\\cdot P = 0.92 \\times 0.12 = 0.1104,\n$$\n$$\n(1-\\mathrm{spec})\\cdot (1-P) = (1-0.85)\\times (1-0.12) = 0.15 \\times 0.88 = 0.132.\n$$\nTherefore,\n$$\n\\mathrm{PPV} = \\frac{0.1104}{0.1104 + 0.132} = \\frac{0.1104}{0.2424}.\n$$\nThis fraction simplifies exactly to\n$$\n\\mathrm{PPV} = \\frac{1104}{2424} = \\frac{46}{101} \\approx 0.455445544\\ldots\n$$\nRounded to four significant figures, $\\mathrm{PPV} = 0.4554$.\n\nCompute the components for $\\mathrm{NPV}$:\n$$\n(1-\\mathrm{sens})\\cdot P = (1-0.92)\\times 0.12 = 0.08 \\times 0.12 = 0.0096,\n$$\n$$\n\\mathrm{spec}\\cdot (1-P) = 0.85 \\times 0.88 = 0.748.\n$$\nTherefore,\n$$\n\\mathrm{NPV} = \\frac{0.748}{0.0096 + 0.748} = \\frac{0.748}{0.7576}.\n$$\nThis fraction simplifies exactly to\n$$\n\\mathrm{NPV} = \\frac{748}{757.6} = \\frac{7480}{7576} = \\frac{935}{947} \\approx 0.987332262\\ldots\n$$\nRounded to four significant figures, $\\mathrm{NPV} = 0.9873$.\n\nAs requested, report both as decimal fractions rounded to four significant figures and present together.", "answer": "$$\\boxed{\\begin{pmatrix}0.4554 & 0.9873\\end{pmatrix}}$$", "id": "4994694"}]}