{"hands_on_practices": [{"introduction": "Permuted-block randomization is a cornerstone of clinical trials, designed to maintain balance between treatment arms throughout enrollment. However, its integrity hinges on effective allocation concealment. This first practice problem challenges you to quantify the degree to which predictability can undermine the randomization process when concealment is breached, providing a concrete measure of the risk of selection bias. [@problem_id:5053984]", "problem": "Consider a two-arm Phase II trial in translational medicine using permuted blocks of fixed size $m=6$ with equal allocation ($3$ allocations to arm $A$ and $3$ allocations to arm $B$ per block). Allocation concealment is compromised because recruiters use open envelopes that reveal the block size and allow inference from previously assigned allocations within the current block. Assume the following scientifically plausible framework: blocks are generated uniformly at random from all balanced permutations, the recruiter knows the block size $m$, the fixed per-block quotas, and observes the allocations already assigned in the current block, but cannot see into future envelopes. At each enrollment within a block, indexed by position $k \\in \\{1,2,3,4,5,6\\}$, the recruiter attempts to predict the next allocation once. The recruiter uses an optimal strategy: choose the arm with the larger remaining per-block quota; if the remaining quotas are equal, the recruiter guesses randomly between arms $A$ and $B$. Assume the position $k$ at which the recruiter makes the prediction is uniformly distributed over $\\{1,\\ldots,6\\}$.\n\nStarting only from the definition of permuted-block randomization, the concept of sampling without replacement, and basic combinatorics, derive the expected probability that the recruiter correctly predicts the next allocation, averaged over the random position $k$ and the random balanced block sequence. Express the final probability as a single exact fraction. No units are required, and rounding is not permitted.\n\nThen, briefly justify two scientifically grounded mitigation strategies within translational medicine practice that would reduce this predictability: one addressing allocation concealment (for example, sealed sequentially numbered opaque envelopes) and one addressing the randomization structure (for example, randomly varying block sizes unknown to recruiters). Do not change your numerical result when discussing mitigations; focus on qualitative impact supported by first principles.", "solution": "The problem requires the calculation of the expected probability that a recruiter correctly predicts the next allocation in a two-arm trial using permuted-block randomization. The validation of the problem statement confirms its scientific soundness and well-posed nature. We can proceed with a formal derivation.\n\nThe randomization scheme consists of permuted blocks of a fixed size $m=6$. Within each block, there are $3$ allocations to arm $A$ and $3$ to arm $B$. The total number of unique, balanced block sequences is given by the binomial coefficient $\\binom{6}{3}$:\n$$ N = \\binom{6}{3} = \\frac{6!}{3!(6-3)!} = \\frac{6 \\times 5 \\times 4}{3 \\times 2 \\times 1} = 20 $$\nThese $20$ sequences are assumed to be selected with uniform probability.\n\nThe recruiter makes a single prediction at position $k$, where $k$ is drawn uniformly from $\\{1, 2, 3, 4, 5, 6\\}$. The recruiter's prediction is made before the $k$-th subject is allocated. At this point, $k-1$ allocations have been observed. Let $n_A(k-1)$ and $n_B(k-1)$ be the number of allocations to arms $A$ and $B$ respectively, among the first $k-1$ subjects. The number of remaining allocations for each arm are $r_A = 3 - n_A(k-1)$ and $r_B = 3 - n_B(k-1)$.\n\nThe recruiter's optimal strategy is:\n1. If $r_A > r_B$, predict arm $A$. The probability of being correct is the probability that the next allocation is indeed $A$, which is $P(\\text{next=A}) = \\frac{r_A}{r_A+r_B}$.\n2. If $r_B > r_A$, predict arm $B$. The probability of being correct is $P(\\text{next=B}) = \\frac{r_B}{r_A+r_B}$.\n3. If $r_A = r_B$, guess randomly. The probability of being correct is $\\frac{1}{2}$.\n\nLet $P_c(k)$ be the probability of a correct prediction, given the prediction is made at position $k$. This probability is an average over all $20$ possible block sequences. We calculate $P_c(k)$ for each $k \\in \\{1, \\ldots, 6\\}$.\n\nFor $k=1$:\nNo allocations have been made, so $n_A(0)=0$ and $n_B(0)=0$. The remaining quotas are $r_A=3$ and $r_B=3$. Since $r_A = r_B$, the recruiter guesses randomly. The probability of a correct guess is $\\frac{1}{2}$.\n$$ P_c(1) = \\frac{1}{2} $$\n\nFor $k=2$:\nOne allocation has been made ($k-1=1$). Either $(n_A(1), n_B(1))=(1,0)$ or $(0,1)$. By symmetry, these states are equally likely (each occurs for $\\binom{5}{2}=10$ out of $20$ sequences).\n- If $(n_A, n_B)=(1,0)$, then $r_A=2, r_B=3$. The recruiter predicts $B$. The probability of being correct is $P(\\text{next=B}) = \\frac{r_B}{r_A+r_B} = \\frac{3}{5}$.\n- If $(n_A, n_B)=(0,1)$, then $r_A=3, r_B=2$. The recruiter predicts $A$. The probability of being correct is $P(\\text{next=A}) = \\frac{r_A}{r_A+r_B} = \\frac{3}{5}$.\nIn either case, the probability of being correct is $\\frac{3}{5}$.\n$$ P_c(2) = \\frac{3}{5} $$\n\nFor $k=3$:\nTwo allocations have been made ($k-1=2$). The possible states $(n_A, n_B)$ are $(2,0)$, $(1,1)$, and $(0,2)$. The number of sequences corresponding to each prefix are:\n- Prefix with $(2,0)$: $\\binom{2}{2}\\binom{4}{1}=4$ sequences.\n- Prefix with $(1,1)$: $\\binom{2}{1}\\binom{4}{2}=12$ sequences.\n- Prefix with $(0,2)$: $\\binom{2}{0}\\binom{4}{3}=4$ sequences.\nTotal sequences: $4+12+4=20$.\n- For state $(2,0)$ (probability $\\frac{4}{20}$), $r_A=1, r_B=3$. Predict $B$. Correctness probability: $\\frac{3}{1+3}=\\frac{3}{4}$.\n- For state $(0,2)$ (probability $\\frac{4}{20}$), $r_A=3, r_B=1$. Predict $A$. Correctness probability: $\\frac{3}{3+1}=\\frac{3}{4}$.\n- For state $(1,1)$ (probability $\\frac{12}{20}$), $r_A=2, r_B=2$. Guess randomly. Correctness probability: $\\frac{1}{2}$.\n$$ P_c(3) = \\left(\\frac{4}{20}\\right)\\left(\\frac{3}{4}\\right) + \\left(\\frac{4}{20}\\right)\\left(\\frac{3}{4}\\right) + \\left(\\frac{12}{20}\\right)\\left(\\frac{1}{2}\\right) = \\frac{3}{20} + \\frac{3}{20} + \\frac{6}{20} = \\frac{12}{20} = \\frac{3}{5} $$\n\nFor $k=4$:\nThree allocations have been made ($k-1=3$). Possible states $(n_A, n_B)$ and corresponding sequence counts:\n- $(3,0)$: $\\binom{3}{3}\\binom{3}{0}=1$ sequence.\n- $(2,1)$: $\\binom{3}{2}\\binom{3}{1}=9$ sequences.\n- $(1,2)$: $\\binom{3}{1}\\binom{3}{2}=9$ sequences.\n- $(0,3)$: $\\binom{3}{0}\\binom{3}{3}=1$ sequence.\nTotal sequences: $1+9+9+1=20$.\n- For state $(3,0)$ (probability $\\frac{1}{20}$), $r_A=0, r_B=3$. Predict $B$. Correctness probability: $\\frac{3}{0+3}=1$.\n- For state $(0,3)$ (probability $\\frac{1}{20}$), $r_A=3, r_B=0$. Predict $A$. Correctness probability: $\\frac{3}{3+0}=1$.\n- For state $(2,1)$ (probability $\\frac{9}{20}$), $r_A=1, r_B=2$. Predict $B$. Correctness probability: $\\frac{2}{1+2}=\\frac{2}{3}$.\n- For state $(1,2)$ (probability $\\frac{9}{20}$), $r_A=2, r_B=1$. Predict $A$. Correctness probability: $\\frac{2}{2+1}=\\frac{2}{3}$.\n$$ P_c(4) = \\left(\\frac{1}{20}\\right)(1) + \\left(\\frac{1}{20}\\right)(1) + \\left(\\frac{9}{20}\\right)\\left(\\frac{2}{3}\\right) + \\left(\\frac{9}{20}\\right)\\left(\\frac{2}{3}\\right) = \\frac{1+1+6+6}{20} = \\frac{14}{20} = \\frac{7}{10} $$\n\nFor $k=5$:\nFour allocations have been made ($k-1=4$). Possible states $(n_A, n_B)$ and corresponding sequence counts:\n- $(3,1)$: $\\binom{4}{3}\\binom{2}{0}=4$ sequences.\n- $(2,2)$: $\\binom{4}{2}\\binom{2}{1}=12$ sequences.\n- $(1,3)$: $\\binom{4}{1}\\binom{2}{2}=4$ sequences.\nTotal sequences: $4+12+4=20$.\n- For state $(3,1)$ (probability $\\frac{4}{20}$), $r_A=0, r_B=2$. Predict $B$. Correctness probability: $\\frac{2}{0+2}=1$.\n- For state $(1,3)$ (probability $\\frac{4}{20}$), $r_A=2, r_B=0$. Predict $A$. Correctness probability: $\\frac{2}{2+0}=1$.\n- For state $(2,2)$ (probability $\\frac{12}{20}$), $r_A=1, r_B=1$. Guess randomly. Correctness probability: $\\frac{1}{2}$.\n$$ P_c(5) = \\left(\\frac{4}{20}\\right)(1) + \\left(\\frac{4}{20}\\right)(1) + \\left(\\frac{12}{20}\\right)\\left(\\frac{1}{2}\\right) = \\frac{4+4+6}{20} = \\frac{14}{20} = \\frac{7}{10} $$\n\nFor $k=6$:\nFive allocations have been made ($k-1=5$). Possible states are $(3,2)$ and $(2,3)$.\n- For state $(3,2)$ (probability $\\frac{\\binom{5}{3}}{20}=\\frac{10}{20}$), $r_A=0, r_B=1$. Predict $B$. Correctness probability: $\\frac{1}{0+1}=1$.\n- For state $(2,3)$ (probability $\\frac{\\binom{5}{2}}{20}=\\frac{10}{20}$), $r_A=1, r_B=0$. Predict $A$. Correctness probability: $\\frac{1}{1+0}=1$.\n$$ P_c(6) = \\left(\\frac{10}{20}\\right)(1) + \\left(\\frac{10}{20}\\right)(1) = 1 $$\n\nThe position $k$ is uniformly distributed, so the expected probability is the average of the $P_c(k)$ values:\n$$ E[P_c] = \\frac{1}{6} \\sum_{k=1}^{6} P_c(k) = \\frac{1}{6} \\left( \\frac{1}{2} + \\frac{3}{5} + \\frac{3}{5} + \\frac{7}{10} + \\frac{7}{10} + 1 \\right) $$\nTo sum the fractions, we use a common denominator of $10$:\n$$ E[P_c] = \\frac{1}{6} \\left( \\frac{5}{10} + \\frac{6}{10} + \\frac{6}{10} + \\frac{7}{10} + \\frac{7}{10} + \\frac{10}{10} \\right) = \\frac{1}{6} \\left( \\frac{5+6+6+7+7+10}{10} \\right) = \\frac{1}{6} \\left( \\frac{41}{10} \\right) $$\n$$ E[P_c] = \\frac{41}{60} $$\nThis value, which is approximately $0.683$, is significantly higher than the baseline chance of $\\frac{1}{2}$, indicating a substantial risk of selection bias due to the compromised allocation concealment.\n\nNext, two scientifically grounded mitigation strategies are justified.\n\nFirst, to address the compromised allocation concealment, a robust procedural safeguard is the implementation of sequentially numbered, opaque, sealed envelopes (SNOSE) or, more effectively, a centralized randomization system (e.g., telephone- or web-based). The flaw in the problem is that the recruiter can observe past allocations within the block. A proper concealment mechanism ensures that the recruiter is blind to all previous assignments. By opening envelopes in strict sequence (enforced by numbering) or by receiving the allocation from a remote system, the recruiter gains no information about the block's composition or their position within it. This intervention directly breaks the feedback loop that enables prediction. The recruiter's forecast for any given subject would revert to a random guess between arm $A$ and arm $B$, reducing the probability of a correct prediction to the ideal value of $\\frac{1}{2}$, assuming no other biases are present.\n\nSecond, to address the predictability inherent in the randomization structure itself, one can use randomly varying block sizes. The recruiter's ability to predict future allocations, especially towards the end of a block, relies on knowing the fixed block size ($m=6$) and the fixed allocation ratio ($3$:$3$). By using a mix of different block sizes (e.g., blocks of size $2$, $4$, and $6$) chosen randomly for each successive block, the recruiter can no longer be certain when a block is nearing its end. For example, after observing allocations $A, A, B$, the recruiter does not know if the next allocation must be $B$ (to complete a block of size $4$ with a $2$:$2$ ratio) or if they are in the middle of a larger block where the next allocation is not as constrained. This uncertainty about the block's boundary obfuscates the \"card-counting\" process, reducing the forcing of allocations and thus decreasing the predictability below the calculated $\\frac{41}{60}$. The block sizes must remain unknown to the site personnel for this method to be effective.", "answer": "$$\n\\boxed{\\frac{41}{60}}\n$$", "id": "5053984"}, {"introduction": "After randomizing a participant, maintaining the blind is paramount to prevent bias in outcome reporting and assessment. Distinctive side effects of an investigational drug can provide a powerful clue, potentially allowing participants to unblind themselves. This exercise provides a formal model of this risk, using Bayesian principles to calculate the probability of a correct guess and to quantify the precise benefit of using an active placebo to preserve blinding integrity. [@problem_id:5053999]", "problem": "A randomized, double-blind, two-arm clinical trial in translational medicine evaluates an investigational drug against a control. Randomization is balanced at 1:1 within two prospectively defined strata reflecting metabolizer phenotype: stratum $\\mathcal{H}$ (high metabolizers) with prevalence $w_{\\mathcal{H}} = 0.6$ and stratum $\\mathcal{L}$ (low metabolizers) with prevalence $w_{\\mathcal{L}} = 0.4$. Blinding integrity is potentially compromised by a binary side-effect signal $S \\in \\{0,1\\}$ that is more common under the active drug. Each participant observes their own $S$ and knows their stratum label but not their assignment. Assume all participants adopt the Bayes-optimal decision rule under 0-1 loss to guess their assignment (active versus control), given the known stratum-specific signal probabilities and the 1:1 prior.\n\nConsider two designs for the control arm:\n- Inert placebo: the side-effect probabilities in stratum $\\mathcal{H}$ are $p_{T,\\mathcal{H}} = 0.40$ under the active drug and $p_{C,\\mathcal{H}} = 0.02$ under control; in stratum $\\mathcal{L}$ they are $p_{T,\\mathcal{L}} = 0.20$ under the active drug and $p_{C,\\mathcal{L}} = 0.03$ under control.\n- Active placebo: the side-effect probabilities in stratum $\\mathcal{H}$ are $p_{T,\\mathcal{H}} = 0.40$ under the active drug and $p_{A,\\mathcal{H}} = 0.28$ under the active placebo; in stratum $\\mathcal{L}$ they are $p_{T,\\mathcal{L}} = 0.20$ under the active drug and $p_{A,\\mathcal{L}} = 0.16$ under the active placebo.\n\nStarting from the definitions of randomization and conditional probability, and using only Bayesâ€™ theorem and the optimality of likelihood-ratio decision rules under 0-1 loss, derive the expression for the maximum achievable probability of a correct arm guess given observation $S$ and stratum label, then aggregate over strata. Under these assumptions, compute the fold-change in the overall probability of a correct guess when moving from the inert placebo design to the active placebo design, defined as\n$$\nR \\equiv \\frac{\\text{overall probability of correct guess with active placebo}}{\\text{overall probability of correct guess with inert placebo}}.\n$$\nProvide $R$ as a decimal, rounded to four significant figures. No percent sign is permitted, and no units are required.", "solution": "The problem requires the calculation of the fold-change in the overall probability of a participant correctly guessing their treatment assignment when moving from an inert placebo to an active placebo design. We begin by establishing the theoretical framework for this calculation, grounded in Bayesian decision theory.\n\nLet $A \\in \\{T, C\\}$ represent the treatment arm assignment, where $T$ is the active drug and $C$ is the control. Let $X \\in \\{\\mathcal{H}, \\mathcal{L}\\}$ denote the stratum, with prevalences $w_{\\mathcal{H}} = P(X=\\mathcal{H}) = 0.6$ and $w_{\\mathcal{L}} = P(X=\\mathcal{L}) = 0.4$. The side-effect signal is a binary random variable $S \\in \\{0, 1\\}$.\n\nThe problem states that randomization is balanced $1:1$ within each stratum. This establishes the prior probabilities for a participant in any stratum $X$:\n$$P(A=T | X) = P(A=C | X) = \\frac{1}{2}$$\nA participant knows their stratum $X$ and observes their signal $S$. To guess their assignment, they use the Bayes-optimal decision rule under $0-1$ loss, which is to choose the assignment with the higher posterior probability. The posterior probabilities are given by Bayes' theorem:\n$$P(A=T | S, X) = \\frac{P(S | A=T, X) P(A=T | X)}{P(S|X)}$$\n$$P(A=C | S, X) = \\frac{P(S | A=C, X) P(A=C | X)}{P(S|X)}$$\nThe term $P(S|X)$ in the denominator is the marginal probability of observing $S$ in stratum $X$, given by the law of total probability:\n$$P(S|X) = P(S|A=T, X)P(A=T|X) + P(S|A=C, X)P(A=C|X)$$\nSubstituting the prior probabilities $P(A=T|X) = P(A=C|X) = 1/2$:\n$$P(S|X) = \\frac{1}{2} [P(S|A=T, X) + P(S|A=C, X)]$$\nLet us denote the likelihoods as $p_{T,X}(S) \\equiv P(S|A=T, X)$ and $p_{C,X}(S) \\equiv P(S|A=C, X)$. The posteriors are:\n$$P(T|S,X) = \\frac{p_{T,X}(S) \\cdot \\frac{1}{2}}{\\frac{1}{2}[p_{T,X}(S) + p_{C,X}(S)]} = \\frac{p_{T,X}(S)}{p_{T,X}(S) + p_{C,X}(S)}$$\n$$P(C|S,X) = \\frac{p_{C,X}(S)}{p_{T,X}(S) + p_{C,X}(S)}$$\nThe Bayes-optimal decision rule is to guess the arm corresponding to the larger posterior. The probability of this guess being correct is the value of the larger posterior probability itself.\n$$P(\\text{correct guess} | S, X) = \\max\\{P(T|S,X), P(C|S,X)\\} = \\frac{\\max\\{p_{T,X}(S), p_{C,X}(S)\\}}{p_{T,X}(S) + p_{C,X}(S)}$$\nTo find the probability of a correct guess within a stratum $X$, we must average over the possible outcomes of $S$:\n$$P(\\text{correct guess} | X) = \\sum_{S \\in \\{0,1\\}} P(\\text{correct guess} | S, X) P(S | X)$$\nSubstituting the expressions derived above:\n$$P(\\text{correct guess} | X) = \\sum_{S \\in \\{0,1\\}} \\frac{\\max\\{p_{T,X}(S), p_{C,X}(S)\\}}{p_{T,X}(S) + p_{C,X}(S)} \\cdot \\frac{1}{2}[p_{T,X}(S) + p_{C,X}(S)]$$\n$$P(\\text{correct guess} | X) = \\frac{1}{2} \\sum_{S \\in \\{0,1\\}} \\max\\{p_{T,X}(S), p_{C,X}(S)\\}$$\nLet $p_{A,X} \\equiv P(S=1 | A, X)$. Then $P(S=0 | A, X) = 1 - p_{A,X}$. The expression becomes:\n$$P(\\text{correct guess} | X) = \\frac{1}{2} \\left( \\max\\{p_{T,X}(1), p_{C,X}(1)\\} + \\max\\{p_{T,X}(0), p_{C,X}(0)\\} \\right)$$\n$$P(\\text{correct guess} | X) = \\frac{1}{2} \\left[ \\max\\{p_{T,X}, p_{C,X}\\} + \\max\\{1-p_{T,X}, 1-p_{C,X}\\} \\right]$$\nFor all conditions specified in the problem, $p_{T,X} > p_{C,X}$. This implies $1-p_{T,X}  1-p_{C,X}$. Thus, the maximums are resolved as:\n$\\max\\{p_{T,X}, p_{C,X}\\} = p_{T,X}$\n$\\max\\{1-p_{T,X}, 1-p_{C,X}\\} = 1-p_{C,X}$\nThis simplifies the stratum-specific probability of a correct guess to:\n$$P(\\text{correct guess} | X) = \\frac{1}{2} (p_{T,X} + 1 - p_{C,X})$$\nThe overall probability of a correct guess, $P_{\\text{overall}}$, is the weighted average of the stratum-specific probabilities:\n$$P_{\\text{overall}} = \\sum_{X \\in \\{\\mathcal{H},\\mathcal{L}\\}} P(\\text{correct guess} | X) w_X = P(\\text{correct guess} | \\mathcal{H})w_{\\mathcal{H}} + P(\\text{correct guess} | \\mathcal{L})w_{\\mathcal{L}}$$\n\nNow we apply this framework to the two specified designs.\n\n**1. Inert Placebo Design**\nThe given probabilities are:\nIn stratum $\\mathcal{H}$: $p_{T,\\mathcal{H}} = 0.40$ and $p_{C,\\mathcal{H}} = 0.02$.\nIn stratum $\\mathcal{L}$: $p_{T,\\mathcal{L}} = 0.20$ and $p_{C,\\mathcal{L}} = 0.03$.\nThe stratum prevalences are $w_{\\mathcal{H}} = 0.6$ and $w_{\\mathcal{L}} = 0.4$.\n\nThe probability of a correct guess in stratum $\\mathcal{H}$ is:\n$$P(\\text{correct guess} | \\mathcal{H})_{\\text{inert}} = \\frac{1}{2} (0.40 + 1 - 0.02) = \\frac{1}{2} (1.38) = 0.69$$\nThe probability of a correct guess in stratum $\\mathcal{L}$ is:\n$$P(\\text{correct guess} | \\mathcal{L})_{\\text{inert}} = \\frac{1}{2} (0.20 + 1 - 0.03) = \\frac{1}{2} (1.17) = 0.585$$\nThe overall probability of a correct guess for the inert placebo design, $P_I$, is:\n$$P_I = (0.69)(0.6) + (0.585)(0.4) = 0.414 + 0.234 = 0.648$$\n\n**2. Active Placebo Design**\nThe given probabilities are:\nIn stratum $\\mathcal{H}$: $p_{T,\\mathcal{H}} = 0.40$ and the control probability is $p_{A,\\mathcal{H}} = 0.28$.\nIn stratum $\\mathcal{L}$: $p_{T,\\mathcal{L}} = 0.20$ and the control probability is $p_{A,\\mathcal{L}} = 0.16$.\n\nThe probability of a correct guess in stratum $\\mathcal{H}$ is:\n$$P(\\text{correct guess} | \\mathcal{H})_{\\text{active}} = \\frac{1}{2} (0.40 + 1 - 0.28) = \\frac{1}{2} (1.12) = 0.56$$\nThe probability of a correct guess in stratum $\\mathcal{L}$ is:\n$$P(\\text{correct guess} | \\mathcal{L})_{\\text{active}} = \\frac{1}{2} (0.20 + 1 - 0.16) = \\frac{1}{2} (1.04) = 0.52$$\nThe overall probability of a correct guess for the active placebo design, $P_A$, is:\n$$P_A = (0.56)(0.6) + (0.52)(0.4) = 0.336 + 0.208 = 0.544$$\n\n**3. Fold-Change Calculation**\nThe fold-change $R$ is the ratio of the overall probability of a correct guess with the active placebo to that with the inert placebo:\n$$R = \\frac{P_A}{P_I} = \\frac{0.544}{0.648}$$\nPerforming the division and rounding to four significant figures:\n$$R \\approx 0.83949074 \\ldots$$\n$$R \\approx 0.8395$$\nThe result indicates that moving to an active placebo design reduces the probability of a correct guess by about $16\\%$, thereby improving the integrity of the blinding.", "answer": "$$\\boxed{0.8395}$$", "id": "5053999"}, {"introduction": "We conclude by shifting our focus from trial design and conduct to the analysis phase. While randomization ensures long-run balance of all covariates, chance imbalances in powerful prognostic factors can still occur in any single trial, inflating the variance of the treatment effect estimate. This practice problem provides a rigorous analytical demonstration of how post-stratification on a prognostic biomarker recovers statistical precision, offering a clear quantitative justification for covariate adjustment in trial analysis. [@problem_id:5054035]", "problem": "A randomized controlled trial (RCT) in oncology compares an investigational targeted therapy to control in a population with a binary predictive biomarker $Z \\in \\{0,1\\}$ that is also prognostic for a continuous outcome $Y$ (for example, log tumor burden). The biomarker prevalence in the trial-eligible source population is $p = \\Pr(Z=1) \\in (0,1)$. A total of $n$ participants are enrolled under complete randomization with equal allocation, so that $n_T = n_C = n/2$ are assigned to treatment and control, respectively. The structural outcome model is\n$$\nY_i \\;=\\; \\tau A_i \\;+\\; \\beta Z_i \\;+\\; \\varepsilon_i,\n$$\nwhere $A_i \\in \\{0,1\\}$ is treatment assignment, $\\tau$ is the average treatment effect, $\\beta$ is the prognostic effect of the biomarker on the outcome, and $\\varepsilon_i$ are independent and identically distributed with $\\mathbb{E}[\\varepsilon_i]=0$ and $\\operatorname{Var}(\\varepsilon_i)=\\sigma^2$, independent of $(A_i,Z_i)$. Assume that $Z_i$ are independent and identically distributed as $\\operatorname{Bernoulli}(p)$, independent of $A_i$ by randomization.\n\nDefine the overall standardized difference in the biomarker between treatment groups as\n$$\nD_Z \\;=\\; \\frac{\\bar{Z}_T - \\bar{Z}_C}{\\sqrt{p(1-p)}},\n$$\nwhere $\\bar{Z}_T$ and $\\bar{Z}_C$ are the sample means of $Z$ in treatment and control, respectively. For each stratum $z \\in \\{0,1\\}$, consider the within-stratum standardized difference in $Z$ between arms, defined analogously as\n$$\nD_Z^{(z)} \\;=\\; \\frac{\\bar{Z}_{T \\mid Z=z} - \\bar{Z}_{C \\mid Z=z}}{\\sqrt{p(1-p)}},\n$$\nwhere $\\bar{Z}_{T \\mid Z=z}$ and $\\bar{Z}_{C \\mid Z=z}$ denote arm-specific means of $Z$ among participants with $Z=z$.\n\nLet the unadjusted estimator of $\\tau$ be the simple difference in mean outcomes,\n$$\n\\hat{\\tau}_{\\mathrm{unadj}} \\;=\\; \\bar{Y}_T - \\bar{Y}_C,\n$$\nand let the post-stratified estimator reweight the arm differences within each biomarker stratum to the target population mixture,\n$$\n\\hat{\\tau}_{\\mathrm{post}} \\;=\\; p \\left(\\bar{Y}_{T \\mid Z=1} - \\bar{Y}_{C \\mid Z=1}\\right) \\;+\\; (1-p)\\left(\\bar{Y}_{T \\mid Z=0} - \\bar{Y}_{C \\mid Z=0}\\right).\n$$\n\nStarting from the basic properties of the Bernoulli distribution and independence induced by randomization, and using only standard facts about the variance of sample means of independent and identically distributed variables, do the following:\n\n$1.$ Compute $\\mathbb{E}[D_Z]$ and $\\mathbb{E}[D_Z^2]$ to the first order in $1/n$ under complete randomization with equal allocation, and compute $D_Z^{(z)}$ for each stratum $z \\in \\{0,1\\}$.\n\n$2.$ Derive $\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{unadj}})$ and $\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{post}})$ to the first order in $1/n$ under the given model and assumptions, making explicit how the imbalance in $Z$ contributes an extra variance term to $\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{unadj}})$ and why this term vanishes for $\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{post}})$.\n\n$3.$ Express the variance ratio\n$$\nR(p,\\beta,\\sigma^2) \\;=\\; \\frac{\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{unadj}})}{\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{post}})}\n$$\nas a closed-form analytic expression in terms of $p$, $\\beta$, and $\\sigma^2$ only, under equal allocation $n_T=n_C=n/2$ and to the first order in $1/n$.\n\nProvide your final answer as the single closed-form analytic expression for $R(p,\\beta,\\sigma^2)$. No numerical rounding is required and no units are needed.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and internally consistent. It presents a standard biostatistical problem concerning the impact of covariate adjustment on the precision of treatment effect estimation in a randomized controlled trial. All necessary parameters, models, and definitions are provided to derive a unique and meaningful solution. The problem is valid.\n\nWe will address the three parts of the problem in sequence.\n\nPart 1: Analysis of biomarker differences $D_Z$ and $D_Z^{(z)}$.\n\nFirst, we compute the expectation of the overall standardized difference in the biomarker, $D_Z = \\frac{\\bar{Z}_T - \\bar{Z}_C}{\\sqrt{p(1-p)}}$. The sample means $\\bar{Z}_T$ and $\\bar{Z}_C$ are the averages of the biomarker $Z_i$ over the $n_T = n/2$ subjects in the treatment arm and $n_C = n/2$ subjects in the control arm, respectively.\nBy the assumption of complete randomization, treatment assignment $A_i$ is independent of the biomarker status $Z_i$. The variables $Z_i$ are independent and identically distributed (i.i.d.) as $\\operatorname{Bernoulli}(p)$. Therefore, the expected value of $Z_i$ for any subject, regardless of treatment assignment, is $\\mathbb{E}[Z_i] = p$.\nUsing the linearity of expectation:\n$$\n\\mathbb{E}[\\bar{Z}_T] = \\mathbb{E}\\left[\\frac{1}{n_T} \\sum_{i: A_i=1} Z_i\\right] = \\frac{1}{n_T} \\sum_{i: A_i=1} \\mathbb{E}[Z_i] = \\frac{1}{n_T} (n_T p) = p.\n$$\nSimilarly, $\\mathbb{E}[\\bar{Z}_C] = p$.\nThe expectation of $D_Z$ is therefore:\n$$\n\\mathbb{E}[D_Z] = \\frac{\\mathbb{E}[\\bar{Z}_T] - \\mathbb{E}[\\bar{Z}_C]}{\\sqrt{p(1-p)}} = \\frac{p-p}{\\sqrt{p(1-p)}} = 0.\n$$\n\nNext, we compute $\\mathbb{E}[D_Z^2]$. Since $\\mathbb{E}[D_Z] = 0$, we have $\\mathbb{E}[D_Z^2] = \\operatorname{Var}(D_Z)$.\n$$\n\\operatorname{Var}(D_Z) = \\operatorname{Var}\\left(\\frac{\\bar{Z}_T - \\bar{Z}_C}{\\sqrt{p(1-p)}}\\right) = \\frac{1}{p(1-p)} \\operatorname{Var}(\\bar{Z}_T - \\bar{Z}_C).\n$$\nThe subjects in the treatment and control arms are distinct, and the $Z_i$ values are i.i.d. Therefore, $\\bar{Z}_T$ and $\\bar{Z}_C$ are independent, and $\\operatorname{Cov}(\\bar{Z}_T, \\bar{Z}_C) = 0$.\n$$\n\\operatorname{Var}(\\bar{Z}_T - \\bar{Z}_C) = \\operatorname{Var}(\\bar{Z}_T) + \\operatorname{Var}(\\bar{Z}_C).\n$$\nThe variance of a single $Z_i \\sim \\operatorname{Bernoulli}(p)$ is $\\operatorname{Var}(Z_i) = p(1-p)$. The variance of the sample mean of $n_T$ such i.i.d. variables is:\n$$\n\\operatorname{Var}(\\bar{Z}_T) = \\frac{\\operatorname{Var}(Z_i)}{n_T} = \\frac{p(1-p)}{n_T}.\n$$\nSimilarly, $\\operatorname{Var}(\\bar{Z}_C) = \\frac{p(1-p)}{n_C}$.\nWith equal allocation $n_T = n_C = n/2$:\n$$\n\\operatorname{Var}(\\bar{Z}_T - \\bar{Z}_C) = \\frac{p(1-p)}{n/2} + \\frac{p(1-p)}{n/2} = \\frac{2p(1-p)}{n} + \\frac{2p(1-p)}{n} = \\frac{4p(1-p)}{n}.\n$$\nSubstituting this back into the expression for $\\mathbb{E}[D_Z^2]$:\n$$\n\\mathbb{E}[D_Z^2] = \\frac{1}{p(1-p)} \\left(\\frac{4p(1-p)}{n}\\right) = \\frac{4}{n}.\n$$\nThis is the first-order result in $1/n$.\n\nFinally, we compute the within-stratum standardized difference $D_Z^{(z)}$ for $z \\in \\{0, 1\\}$.\nThe term $\\bar{Z}_{T \\mid Z=z}$ is the sample mean of the biomarker $Z$ among participants in the treatment group who have $Z=z$. By definition, for every such participant $i$, $Z_i=z$. Therefore, the sample mean must be $z$:\n$$\n\\bar{Z}_{T \\mid Z=z} = z.\n$$\nThis holds as long as the stratum is not empty in the treatment arm. Similarly, for the control arm:\n$$\n\\bar{Z}_{C \\mid Z=z} = z.\n$$\nThus, for both strata:\n$$\nD_Z^{(z)} = \\frac{z - z}{\\sqrt{p(1-p)}} = 0.\n$$\nSo, $D_Z^{(0)} = 0$ and $D_Z^{(1)} = 0$.\n\nPart 2: Derivation of estimator variances.\n\nFirst, we derive $\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{unadj}})$, where $\\hat{\\tau}_{\\mathrm{unadj}} = \\bar{Y}_T - \\bar{Y}_C$. The sample means of the outcome are:\n$$\n\\bar{Y}_T = \\frac{1}{n_T}\\sum_{i: A_i=1} Y_i = \\frac{1}{n_T}\\sum_{i: A_i=1} (\\tau \\cdot 1 + \\beta Z_i + \\varepsilon_i) = \\tau + \\beta \\bar{Z}_T + \\bar{\\varepsilon}_T.\n$$\n$$\n\\bar{Y}_C = \\frac{1}{n_C}\\sum_{i: A_i=0} Y_i = \\frac{1}{n_C}\\sum_{i: A_i=0} (\\tau \\cdot 0 + \\beta Z_i + \\varepsilon_i) = \\beta \\bar{Z}_C + \\bar{\\varepsilon}_C.\n$$\nThe unadjusted estimator can be written as:\n$$\n\\hat{\\tau}_{\\mathrm{unadj}} = (\\tau + \\beta \\bar{Z}_T + \\bar{\\varepsilon}_T) - (\\beta \\bar{Z}_C + \\bar{\\varepsilon}_C) = \\tau + \\beta(\\bar{Z}_T - \\bar{Z}_C) + (\\bar{\\varepsilon}_T - \\bar{\\varepsilon}_C).\n$$\nSince $\\mathbb{E}[\\bar{Z}_T - \\bar{Z}_C]=0$ and $\\mathbb{E}[\\bar{\\varepsilon}_T - \\bar{\\varepsilon}_C]=0$, the estimator is unbiased, $\\mathbb{E}[\\hat{\\tau}_{\\mathrm{unadj}}] = \\tau$. Its variance is:\n$$\n\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{unadj}}) = \\operatorname{Var}(\\beta(\\bar{Z}_T - \\bar{Z}_C) + (\\bar{\\varepsilon}_T - \\bar{\\varepsilon}_C)).\n$$\nThe variables $Z_i$ and $\\varepsilon_j$ are independent for all $i, j$. Therefore, the term $(\\bar{Z}_T - \\bar{Z}_C)$ is independent of $(\\bar{\\varepsilon}_T - \\bar{\\varepsilon}_C)$, and their variances add:\n$$\n\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{unadj}}) = \\beta^2 \\operatorname{Var}(\\bar{Z}_T - \\bar{Z}_C) + \\operatorname{Var}(\\bar{\\varepsilon}_T - \\bar{\\varepsilon}_C).\n$$\nWe already found $\\operatorname{Var}(\\bar{Z}_T - \\bar{Z}_C) = \\frac{4p(1-p)}{n}$.\nThe variance of the error term difference is $\\operatorname{Var}(\\bar{\\varepsilon}_T - \\bar{\\varepsilon}_C) = \\operatorname{Var}(\\bar{\\varepsilon}_T) + \\operatorname{Var}(\\bar{\\varepsilon}_C)$. Since $\\varepsilon_i$ are i.i.d. with variance $\\sigma^2$:\n$$\n\\operatorname{Var}(\\bar{\\varepsilon}_T) = \\frac{\\sigma^2}{n_T} = \\frac{\\sigma^2}{n/2} = \\frac{2\\sigma^2}{n}.\n$$\n$$\n\\operatorname{Var}(\\bar{\\varepsilon}_C) = \\frac{\\sigma^2}{n_C} = \\frac{\\sigma^2}{n/2} = \\frac{2\\sigma^2}{n}.\n$$\nSo, $\\operatorname{Var}(\\bar{\\varepsilon}_T - \\bar{\\varepsilon}_C) = \\frac{2\\sigma^2}{n} + \\frac{2\\sigma^2}{n} = \\frac{4\\sigma^2}{n}$.\nCombining the terms, the variance of the unadjusted estimator is:\n$$\n\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{unadj}}) = \\beta^2 \\left(\\frac{4p(1-p)}{n}\\right) + \\frac{4\\sigma^2}{n} = \\frac{4\\sigma^2 + 4\\beta^2 p(1-p)}{n}.\n$$\nThe term $\\frac{4\\beta^2 p(1-p)}{n}$ is the contribution from the chance imbalance in the prognostic biomarker $Z$ between the treatment and control arms.\n\nNext, we derive $\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{post}})$. The estimator is $\\hat{\\tau}_{\\mathrm{post}} = p \\hat{\\tau}_1 + (1-p) \\hat{\\tau}_0$, where $\\hat{\\tau}_z = \\bar{Y}_{T \\mid Z=z} - \\bar{Y}_{C \\mid Z=z}$.\nWithin stratum $Z=z$, the outcome model for a subject $i$ is $Y_i = \\tau A_i + \\beta z + \\varepsilon_i$.\n$$\n\\bar{Y}_{T \\mid Z=z} = \\frac{1}{n_{T,z}}\\sum_{i:A_i=1,Z_i=z}(\\tau + \\beta z + \\varepsilon_i) = \\tau + \\beta z + \\bar{\\varepsilon}_{T,z}.\n$$\n$$\n\\bar{Y}_{C \\mid Z=z} = \\frac{1}{n_{C,z}}\\sum_{i:A_i=0,Z_i=z}(\\beta z + \\varepsilon_i) = \\beta z + \\bar{\\varepsilon}_{C,z}.\n$$\nThe within-stratum difference is:\n$$\n\\hat{\\tau}_z = (\\tau + \\beta z + \\bar{\\varepsilon}_{T,z}) - (\\beta z + \\bar{\\varepsilon}_{C,z}) = \\tau + (\\bar{\\varepsilon}_{T,z} - \\bar{\\varepsilon}_{C,z}).\n$$\nThe post-stratified estimator becomes:\n$$\n\\hat{\\tau}_{\\mathrm{post}} = p(\\tau + \\bar{\\varepsilon}_{T,1} - \\bar{\\varepsilon}_{C,1}) + (1-p)(\\tau + \\bar{\\varepsilon}_{T,0} - \\bar{\\varepsilon}_{C,0}) = \\tau + p(\\bar{\\varepsilon}_{T,1} - \\bar{\\varepsilon}_{C,1}) + (1-p)(\\bar{\\varepsilon}_{T,0} - \\bar{\\varepsilon}_{C,0}).\n$$\nThe terms involving $\\beta$ and $Z$ have been removed by the stratification process. This explains why the extra variance term due to $Z$ imbalance vanishes for $\\hat{\\tau}_{\\mathrm{post}}$.\nThe estimators $\\hat{\\tau}_1$ and $\\hat{\\tau}_0$ are computed on disjoint subsets of the data (subjects with $Z=1$ vs $Z=0$) and are therefore independent.\n$$\n\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{post}}) = p^2 \\operatorname{Var}(\\hat{\\tau}_1) + (1-p)^2 \\operatorname{Var}(\\hat{\\tau}_0).\n$$\nWe need $\\operatorname{Var}(\\hat{\\tau}_z) = \\operatorname{Var}(\\bar{\\varepsilon}_{T,z} - \\bar{\\varepsilon}_{C,z})$. The stratum sample sizes $n_{T,z}$ and $n_{C,z}$ are random. We use the law of total variance, conditioning on these sizes.\n$$\n\\operatorname{Var}(\\hat{\\tau}_z) = \\mathbb{E}[\\operatorname{Var}(\\hat{\\tau}_z | n_{T,z}, n_{C,z})] + \\operatorname{Var}(\\mathbb{E}[\\hat{\\tau}_z | n_{T,z}, n_{C,z}]).\n$$\nSince $\\mathbb{E}[\\hat{\\tau}_z | n_{T,z}, n_{C,z}] = \\tau$, the second term is $\\operatorname{Var}(\\tau)=0$.\n$$\n\\operatorname{Var}(\\hat{\\tau}_z) = \\mathbb{E}\\left[\\sigma^2\\left(\\frac{1}{n_{T,z}} + \\frac{1}{n_{C,z}}\\right)\\right] = \\sigma^2 \\left(\\mathbb{E}\\left[\\frac{1}{n_{T,z}}\\right] + \\mathbb{E}\\left[\\frac{1}{n_{C,z}}\\right]\\right).\n$$\nTo first order in $1/n$, we use the approximation $\\mathbb{E}[1/X] \\approx 1/\\mathbb{E}[X]$.\nThe expected sample sizes are $\\mathbb{E}[n_{T,1}] = n_T \\Pr(Z=1) = (n/2)p$, and $\\mathbb{E}[n_{C,1}] = n_C \\Pr(Z=1) = (n/2)p$.\nThus, for stratum $z=1$:\n$$\n\\mathbb{E}\\left[\\frac{1}{n_{T,1}}\\right] \\approx \\frac{1}{np/2} = \\frac{2}{np}, \\quad \\mathbb{E}\\left[\\frac{1}{n_{C,1}}\\right] \\approx \\frac{1}{np/2} = \\frac{2}{np}.\n$$\nSo, $\\operatorname{Var}(\\hat{\\tau}_1) \\approx \\sigma^2(\\frac{2}{np} + \\frac{2}{np}) = \\frac{4\\sigma^2}{np}$.\nSimilarly, for stratum $z=0$, we replace $p$ with $(1-p)$: $\\mathbb{E}[n_{T,0}] = n(1-p)/2$ and $\\mathbb{E}[n_{C,0}] = n(1-p)/2$.\nSo, $\\operatorname{Var}(\\hat{\\tau}_0) \\approx \\sigma^2(\\frac{2}{n(1-p)} + \\frac{2}{n(1-p)}) = \\frac{4\\sigma^2}{n(1-p)}$.\nSubstituting these into the variance expression for $\\hat{\\tau}_{\\mathrm{post}}$:\n$$\n\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{post}}) \\approx p^2\\left(\\frac{4\\sigma^2}{np}\\right) + (1-p)^2\\left(\\frac{4\\sigma^2}{n(1-p)}\\right) = \\frac{4p\\sigma^2}{n} + \\frac{4(1-p)\\sigma^2}{n} = \\frac{4\\sigma^2}{n}(p + 1 - p) = \\frac{4\\sigma^2}{n}.\n$$\nAs derived, the component of variance related to $\\beta$ is absent in $\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{post}})$.\n\nPart 3: Variance ratio $R(p,\\beta,\\sigma^2)$.\n\nWe compute the ratio of the two variances to the first order in $1/n$:\n$$\nR(p,\\beta,\\sigma^2) = \\frac{\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{unadj}})}{\\operatorname{Var}(\\hat{\\tau}_{\\mathrm{post}})} = \\frac{\\frac{4\\sigma^2 + 4\\beta^2 p(1-p)}{n}}{\\frac{4\\sigma^2}{n}}.\n$$\n$$\nR(p,\\beta,\\sigma^2) = \\frac{4\\sigma^2 + 4\\beta^2 p(1-p)}{4\\sigma^2} = 1 + \\frac{4\\beta^2 p(1-p)}{4\\sigma^2}.\n$$\n$$\nR(p,\\beta,\\sigma^2) = 1 + \\frac{\\beta^2 p(1-p)}{\\sigma^2}.\n$$\nThis is the closed-form analytic expression for the variance ratio.", "answer": "$$\n\\boxed{1 + \\frac{\\beta^2 p(1-p)}{\\sigma^2}}\n$$", "id": "5054035"}]}