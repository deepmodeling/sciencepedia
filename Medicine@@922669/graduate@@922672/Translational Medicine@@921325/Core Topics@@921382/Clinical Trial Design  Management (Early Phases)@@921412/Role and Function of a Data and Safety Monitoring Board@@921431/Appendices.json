{"hands_on_practices": [{"introduction": "A primary responsibility of a Data and Safety Monitoring Board is to protect trial participants from undue harm. This often requires statistically comparing the incidence of adverse events between the experimental and control arms at planned interim points. This exercise provides hands-on practice with a foundational tool for this task, the Wald test for a difference in proportions. By working through this hypothetical scenario, you will apply the test to determine if an observed imbalance in adverse events is statistically significant enough to cross a pre-specified safety boundary, a critical skill for making evidence-based recommendations. [@problem_id:5058119]", "problem": "A translational Phase II randomized clinical trial is being monitored by a Data and Safety Monitoring Board (DSMB). The DSMB evaluates potential harm by prospectively applying a one-sided standardized Wald test for the difference in Adverse Event (AE) incidence between the experimental arm and the control arm at prespecified interim analyses. Assume the AE process in each arm follows a Binomial model with independent participants. At the current interim, the observed AE incidence proportions are $p_1 = 0.15$ in the experimental arm and $p_0 = 0.08$ in the control arm, with equal and fixed sample sizes $n_1 = n_0 = 250$. The DSMB’s monitoring plan, based on a spending-function approach, specifies a one-sided harm boundary corresponding to a standardized test statistic threshold of $z_h = 2.4$ at this interim.\n\nStarting from the Binomial model and the Central Limit Theorem, derive the Wald statistic for testing the null hypothesis $H_0: p_1 = p_0$ using the pooled estimator for the common event probability under the null, and compute the resulting standardized $z$-statistic. Then, interpret whether this $z$ would lead the DSMB to conclude that the harm boundary is crossed at this interim. Round your computed $z$ to four significant figures. Express the final answer as a dimensionless number without units.", "solution": "The problem requires the calculation of a standardized Wald test statistic to compare two independent binomial proportions and the interpretation of this statistic in the context of a clinical trial's Data and Safety Monitoring Board (DSMB) harm boundary.\n\nFirst, we establish the theoretical framework. The problem states that the number of Adverse Events (AEs) in each arm follows a Binomial model. Let $X_1$ and $X_0$ be the random variables representing the number of participants experiencing an AE in the experimental arm (arm 1) and the control arm (arm 0), respectively. Their distributions are given by:\n$$X_1 \\sim \\text{Binomial}(n_1, p_1)$$\n$$X_0 \\sim \\text{Binomial}(n_0, p_0)$$\nwhere $n_1$ and $n_0$ are the sample sizes, and $p_1$ and $p_0$ are the true, unknown AE incidence probabilities in the respective populations.\n\nThe point estimators for these probabilities are the sample proportions, denoted by $\\hat{p}_1$ and $\\hat{p}_0$. The problem provides the observed values for these estimators:\n$$\\hat{p}_1 = \\frac{x_1}{n_1} = 0.15$$\n$$\\hat{p}_0 = \\frac{x_0}{n_0} = 0.08$$\nwith sample sizes $n_1 = 250$ and $n_0 = 250$.\n\nAccording to the Central Limit Theorem, for sufficiently large sample sizes (which is the case here, as $n_1=250$ and $n_0=250$), the sampling distributions of these proportions can be approximated by Normal distributions:\n$$\\hat{p}_1 \\approx N\\left(p_1, \\frac{p_1(1-p_1)}{n_1}\\right)$$\n$$\\hat{p}_0 \\approx N\\left(p_0, \\frac{p_0(1-p_0)}{n_0}\\right)$$\nSince the two arms of the trial consist of independent participants, the sampling distribution of the difference in proportions, $\\hat{p}_1 - \\hat{p}_0$, is also approximately Normal:\n$$\\hat{p}_1 - \\hat{p}_0 \\approx N\\left(p_1 - p_0, \\frac{p_1(1-p_1)}{n_1} + \\frac{p_0(1-p_0)}{n_0}\\right)$$\n\nThe DSMB is testing the null hypothesis $H_0$ of no difference in AE incidence, against a one-sided alternative hypothesis $H_1$ that the experimental arm has a higher incidence (potential for harm):\n$$H_0: p_1 = p_0 \\quad (\\text{or } p_1 - p_0 = 0)$$\n$$H_1: p_1 > p_0$$\n\nThe Wald test statistic, in its general form, is given by:\n$$z = \\frac{(\\text{estimator}) - (\\text{hypothesized value})}{\\text{standard error of the estimator}}$$\nFor this problem, the estimator is $\\hat{p}_1 - \\hat{p}_0$ and the hypothesized value under $H_0$ is $0$. Thus,\n$$z = \\frac{\\hat{p}_1 - \\hat{p}_0}{\\text{SE}(\\hat{p}_1 - \\hat{p}_0)}$$\n\nThe problem specifies using the pooled estimator for the common event probability to calculate the standard error. Under the null hypothesis $H_0$, we assume $p_1 = p_0 = p$, where $p$ is the common unknown proportion. The variance of the difference simplifies to:\n$$\\text{Var}(\\hat{p}_1 - \\hat{p}_0) = \\frac{p(1-p)}{n_1} + \\frac{p(1-p)}{n_0} = p(1-p)\\left(\\frac{1}{n_1} + \\frac{1}{n_0}\\right)$$\nThe best estimate for this common proportion $p$ is the pooled sample proportion, $\\hat{p}_{\\text{pool}}$, which combines the data from both arms:\n$$\\hat{p}_{\\text{pool}} = \\frac{x_1 + x_0}{n_1 + n_0} = \\frac{n_1 \\hat{p}_1 + n_0 \\hat{p}_0}{n_1 + n_0}$$\nThe standard error is then estimated by substituting $\\hat{p}_{\\text{pool}}$ for $p$:\n$$\\text{SE}_{\\text{pool}}(\\hat{p}_1 - \\hat{p}_0) = \\sqrt{\\hat{p}_{\\text{pool}}(1-\\hat{p}_{\\text{pool}})\\left(\\frac{1}{n_1} + \\frac{1}{n_0}\\right)}$$\n\nThe final formula for the standardized $z$-statistic is:\n$$z = \\frac{\\hat{p}_1 - \\hat{p}_0}{\\sqrt{\\hat{p}_{\\text{pool}}(1-\\hat{p}_{\\text{pool}})\\left(\\frac{1}{n_1} + \\frac{1}{n_0}\\right)}}$$\n\nNow, we substitute the given numerical values: $\\hat{p}_1 = 0.15$, $\\hat{p}_0 = 0.08$, $n_1 = 250$, and $n_0 = 250$.\n\nFirst, we compute the pooled proportion $\\hat{p}_{\\text{pool}}$:\n$$\\hat{p}_{\\text{pool}} = \\frac{(250)(0.15) + (250)(0.08)}{250 + 250} = \\frac{37.5 + 20}{500} = \\frac{57.5}{500} = 0.115$$\n\nNext, we calculate the terms for the standard error:\n$$1 - \\hat{p}_{\\text{pool}} = 1 - 0.115 = 0.885$$\n$$\\frac{1}{n_1} + \\frac{1}{n_0} = \\frac{1}{250} + \\frac{1}{250} = \\frac{2}{250} = 0.008$$\n\nNow, we compute the pooled standard error:\n$$\\text{SE}_{\\text{pool}} = \\sqrt{0.115 \\times 0.885 \\times 0.008} = \\sqrt{0.0008142} \\approx 0.0285341896$$\n\nThe difference in observed proportions is:\n$$\\hat{p}_1 - \\hat{p}_0 = 0.15 - 0.08 = 0.07$$\n\nFinally, we compute the $z$-statistic:\n$$z = \\frac{0.07}{0.0285341896} \\approx 2.453180$$\nRounding to four significant figures, we get $z = 2.453$.\n\nThe final step is to interpret this result. The DSMB's monitoring plan specifies a one-sided harm boundary at a standardized test statistic threshold of $z_h = 2.4$. The calculated statistic is $z = 2.453$. We compare the computed value to the boundary:\n$$z = 2.453 > z_h = 2.4$$\nSince the calculated $z$-statistic exceeds the prespecified harm boundary, this result would lead the DSMB to conclude that the harm boundary has been crossed at this interim analysis. This represents a statistically significant signal of potential excess harm in the experimental arm compared to the control arm, warranting a formal review by the board which could lead to a recommendation to modify or halt the trial.", "answer": "$$\\boxed{2.453}$$", "id": "5058119"}, {"introduction": "Beyond ensuring safety, a DSMB also plays a crucial role in maintaining trial efficiency and ethics by assessing futility—the likelihood that a trial will fail to show a benefit even if completed. This exercise delves into the sophisticated world of group-sequential trial design to calculate conditional power, a key metric for this assessment. You will work within the canonical statistical framework for interim analyses to predict the probability of a successful trial outcome given the data observed so far, providing a quantitative basis for a potential recommendation to halt a trial for futility. [@problem_id:5058159]", "problem": "A randomized, double-blind Phase III trial in translational medicine is monitored by an independent Data and Safety Monitoring Board (DSMB) with a prespecified one-sided group-sequential design for efficacy. The primary analysis is based on a standardized $Z$-statistic that, under the canonical joint normal formulation of information-based monitoring, has the following properties: for information fraction $t \\in (0,1]$, the standardized statistic $Z(t)$ satisfies that $(Z(t), Z(1))$ is bivariate normal with means $\\theta \\sqrt{t}$ and $\\theta$, variances $1$ and $1$, and correlation $\\sqrt{t}$, where $\\theta$ denotes the design-standardized effect under a fixed alternative. The DSMB uses a nonbinding futility rule based on conditional power: if the conditional power at the interim is less than or equal to a threshold $c_f$, the futility boundary is considered crossed, though the DSMB retains discretion regarding stopping.\n\nAt the interim analysis with information fraction $t_i = 0.5$, the observed interim standardized statistic is $z_i = 0.8$. The trial is designed for a planned standardized alternative effect $\\mu = 0.5$, and the final one-sided critical value is $z_{1-\\alpha} = 1.645$. The DSMB has set the nonbinding futility threshold at $c_f = 0.2$. Using only the fundamental properties stated above, derive the conditional distribution of $Z(1)$ given the interim observation, obtain the resulting conditional power as a function of the given quantities, evaluate it at the provided numerical values, and determine whether the nonbinding futility boundary would be crossed.\n\nProvide your final answer as a row matrix containing two entries: the conditional power (rounded to four significant figures, expressed as a decimal) and a crossing indicator (use $1$ if the futility boundary is crossed and $0$ otherwise). No units should be included in the final answer.", "solution": "The problem requires the calculation of conditional power (CP) for a group-sequential trial and its comparison to a futility threshold. This involves deriving the conditional distribution of the final test statistic given the interim result.\n\nAccording to the problem statement, the pair of random variables for the interim and final standardized statistics, $(Z(t_i), Z(1))$, follows a bivariate normal distribution. The parameters of this distribution are given as:\n- Mean vector: $E\\left[\\begin{pmatrix} Z(t_i) \\\\ Z(1) \\end{pmatrix}\\right] = \\begin{pmatrix} \\theta\\sqrt{t_i} \\\\ \\theta \\end{pmatrix}$\n- Covariance matrix: $\\Sigma = \\begin{pmatrix} 1 & \\sqrt{t_i} \\\\ \\sqrt{t_i} & 1 \\end{pmatrix}$\n\nFrom the properties of the bivariate normal distribution, the conditional distribution of $Z(1)$ given the observation $Z(t_i)=z_i$ is also normal. Its parameters are:\n- Conditional Mean: $E[Z(1)|Z(t_i)=z_i] = E[Z(1)] + \\text{Corr}(Z(1),Z(t_i))\\frac{\\text{SD}(Z(1))}{\\text{SD}(Z(t_i))}(z_i - E[Z(t_i)])$\n$$ E[Z(1)|Z(t_i)=z_i] = \\theta + \\sqrt{t_i}\\frac{1}{1}(z_i - \\theta\\sqrt{t_i}) = \\theta(1-t_i) + z_i\\sqrt{t_i} $$\n- Conditional Variance: $\\text{Var}[Z(1)|Z(t_i)=z_i] = \\text{Var}(Z(1))(1 - \\text{Corr}(Z(1),Z(t_i))^2)$\n$$ \\text{Var}[Z(1)|Z(t_i)=z_i] = 1 \\cdot (1 - (\\sqrt{t_i})^2) = 1 - t_i $$\nThus, the conditional distribution is:\n$$ Z(1) | Z(t_i)=z_i \\sim \\mathcal{N}(\\theta(1-t_i) + z_i\\sqrt{t_i}, 1-t_i) $$\n\nConditional power (CP) is the probability of rejecting the null hypothesis at the final analysis (i.e., $Z(1) > z_{1-\\alpha}$), given the interim data and assuming a specific alternative effect $\\theta=\\mu$.\n$$ \\text{CP} = P(Z(1) > z_{1-\\alpha} | Z(t_i)=z_i; \\theta=\\mu) $$\nTo compute this, we standardize $Z(1)$ using its conditional distribution parameters:\n$$ \\text{CP} = P\\left( \\frac{Z(1) - (\\mu(1-t_i) + z_i\\sqrt{t_i})}{\\sqrt{1-t_i}} > \\frac{z_{1-\\alpha} - (\\mu(1-t_i) + z_i\\sqrt{t_i})}{\\sqrt{1-t_i}} \\right) $$\nLet $W$ be a standard normal variable and $\\Phi(\\cdot)$ be its cumulative distribution function (CDF).\n$$ \\text{CP} = P\\left(W > \\frac{z_{1-\\alpha} - \\mu(1-t_i) - z_i\\sqrt{t_i}}{\\sqrt{1-t_i}}\\right) = 1 - \\Phi\\left(\\frac{z_{1-\\alpha} - \\mu(1-t_i) - z_i\\sqrt{t_i}}{\\sqrt{1-t_i}}\\right) $$\nUsing the property $1 - \\Phi(x) = \\Phi(-x)$, we simplify this to:\n$$ \\text{CP} = \\Phi\\left(\\frac{\\mu(1-t_i) + z_i\\sqrt{t_i} - z_{1-\\alpha}}{\\sqrt{1-t_i}}\\right) $$\n\nNow, we substitute the provided numerical values:\n- Interim information fraction: $t_i = 0.5$\n- Observed interim statistic: $z_i = 0.8$\n- Planned alternative effect: $\\mu = 0.5$\n- Final critical value: $z_{1-\\alpha} = 1.645$\n\nThe argument of the CDF is:\n$$ \\frac{\\mu(1-t_i) + z_i\\sqrt{t_i} - z_{1-\\alpha}}{\\sqrt{1-t_i}} = \\frac{0.5(1-0.5) + 0.8\\sqrt{0.5} - 1.645}{\\sqrt{1-0.5}} $$\n$$ = \\frac{0.25 + 0.8(0.707106...) - 1.645}{0.707106...} $$\n$$ = \\frac{0.25 + 0.565685... - 1.645}{0.707106...} = \\frac{-0.829314...}{0.707106...} \\approx -1.17282 $$\nSo, the conditional power is:\n$$ \\text{CP} = \\Phi(-1.17282) \\approx 0.1204358 $$\nRounding to four significant figures, the conditional power is $0.1204$.\n\nThe final step is to determine if the futility boundary is crossed. The condition for crossing is $\\text{CP} \\le c_f$, where the futility threshold is given as $c_f = 0.2$.\nWe compare our result to this threshold:\n$$ 0.1204 \\le 0.2 $$\nThis inequality is true, which means the nonbinding futility boundary is crossed. The crossing indicator is therefore $1$.\n\nThe final answer consists of two parts: the conditional power ($0.1204$) and the crossing indicator ($1$).", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.1204 & 1\n\\end{pmatrix}\n}\n$$", "id": "5058159"}, {"introduction": "Real-world clinical trial data is rarely as clean as textbook examples, and a DSMB's most challenging tasks often involve grappling with data imperfections. This practice moves beyond pure calculation to the critical reasoning required to handle informative missing data, a common and serious issue where the reasons for data being missing can bias the results. By analyzing a scenario with significant and differential missingness, you will learn to think strategically about how to assess the robustness of interim efficacy and safety signals and identify appropriate sensitivity analyses to request, ensuring the board's conclusions are built on a sound evidentiary foundation. [@problem_id:5058103]", "problem": "A randomized, double-blind, Phase II clinical trial in translational oncology is reviewed at interim by the Data and Safety Monitoring Board (DSMB). The trial compares a novel immunotherapy to standard of care, with $1{:}1$ randomization and planned sample size of $n_1 = 200$ in the treatment arm and $n_0 = 200$ in the control arm. The primary efficacy endpoint is a binary response at week $12$, $Y \\in \\{0,1\\}$, and a key safety endpoint is the occurrence of Grade $\\ge 3$ immune-related adverse events by week $12$, $A \\in \\{0,1\\}$. Let $T \\in \\{0,1\\}$ denote treatment ($T=1$) versus control ($T=0$), and let $R_Y \\in \\{0,1\\}$ indicate whether the week $12$ efficacy outcome is observed ($R_Y=1$) or missing ($R_Y=0$). Similarly, let $R_A \\in \\{0,1\\}$ indicate observation of the safety endpoint through week $12$. At interim, the DSMB observes: treatment arm has $n_1 = 200$ randomized, with $R_Y=1$ observed for $130$ participants and $R_Y=0$ for $70$ participants ($35\\%$ missing); control arm has $n_0 = 200$ randomized, with $R_Y=1$ observed for $170$ participants and $R_Y=0$ for $30$ participants ($15\\%$ missing). Among those with observed efficacy outcomes, the treatment arm has $70$ responders ($Y=1$) and the control arm has $80$ responders. For safety among those with observed data, the treatment arm has $30$ participants with $A=1$ and the control arm has $20$ participants with $A=1$. Investigators report a complete-case efficacy risk difference $\\hat{\\Delta}_{\\text{CC}} = \\bar{Y}_{\\text{obs},1} - \\bar{Y}_{\\text{obs},0}$ favoring treatment, and a lower observed rate of adverse events in treatment than control.\n\nThe DSMB is concerned about informative missingness. Use the following fundamental base:\n\n- Rubin’s taxonomy of missing data mechanisms: Missing Completely At Random (MCAR) where $P(R=1 \\mid Y, T, X) = P(R=1)$; Missing At Random (MAR) where $P(R=1 \\mid Y, T, X) = P(R=1 \\mid T, X)$; and Missing Not At Random (MNAR) where $P(R=1 \\mid Y, T, X)$ depends on unobserved $Y$ even after conditioning on $T$ and baseline covariates $X$.\n\n- The law of total expectation: for any arm $t \\in \\{0,1\\}$, $E[Y \\mid T=t] = E[Y \\mid T=t, R_Y=1] P(R_Y=1 \\mid T=t) + E[Y \\mid T=t, R_Y=0] P(R_Y=0 \\mid T=t)$, and analogously for $A$.\n\n- The causal estimands of interest at interim are the arm-specific means $E[Y \\mid T=t]$ and $E[A \\mid T=t]$ and their differences $E[Y \\mid T=1] - E[Y \\mid T=0]$ and $E[A \\mid T=1] - E[A \\mid T=0]$.\n\nAssume baseline covariates $X$ are available and well-measured. The DSMB’s qualitative context is that adverse events may prompt discontinuation or missed week $12$ visits, and early robust responders may skip visits due to early discharge, suggesting potential $P(R_Y=1 \\mid Y, T)$ and $P(R_A=1 \\mid A, T)$ dependence on the unobserved outcomes.\n\nWhich of the following actions and interpretations are appropriate for the DSMB to assess how informative missingness can bias safety and efficacy signals and to evaluate robustness? Select all that apply.\n\nA. Recognize that if $P(R_Y=1 \\mid Y, T)$ depends on $Y$ (MNAR), then the complete-case efficacy estimate $\\hat{\\Delta}_{\\text{CC}}$ can be biased. Request sensitivity analyses using pattern-mixture or selection models that introduce arm-specific sensitivity parameters (e.g., $\\Delta$-adjustments for $E[Y \\mid T=t, R_Y=0]$) to examine how conclusions change under plausible MNAR deviations.\n\nB. Rely on inverse probability weighting using models for $P(R_Y=1 \\mid T, X)$ alone to fully correct bias in both efficacy and safety, because weighting by the observation probability identifies $E[Y \\mid T]$ and $E[A \\mid T]$ even when missingness is MNAR, making further sensitivity analyses unnecessary.\n\nC. Request a tipping-point analysis for efficacy and safety that systematically varies assumptions about $E[Y \\mid T=t, R_Y=0]$ and $E[A \\mid T=t, R_A=0]$ in each arm until the interim conclusion reverses, coupled with conservative worst-case bounds (e.g., impute all missing $Y$ in $T=1$ as failures and all missing $Y$ in $T=0$ as successes; for safety, impute all missing $A$ in $T=1$ as events and all missing $A$ in $T=0$ as non-events) to bracket the possible bias.\n\nD. If missingness is monotone and plausibly driven by latent disease trajectory, request joint modeling of longitudinal markers and time-to-dropout with shared random effects to probe MNAR mechanisms, and compare these results to analyses under Missing At Random (e.g., multiple imputation using $T$ and $X$) to assess sensitivity of the interim signals.\n\nE. Prefer complete-case analysis augmented by a per-protocol subset restricted to adherent participants, because conditioning on adherence removes confounding and yields unbiased interim efficacy and safety estimates irrespective of the missingness mechanism, allowing the DSMB to rely on these results without sensitivity analyses.", "solution": "The problem asks for an evaluation of appropriate actions for a Data and Safety Monitoring Board (DSMB) reviewing a clinical trial with significant and differential missing data. The core of the problem lies in the potential for this missingness to be *informative* or *Missing Not At Random* (MNAR), which could substantially bias the trial's interim results.\n\nFirst, let's establish the quantitative context from the provided information.\nThe trial has randomized $n_1 = 200$ participants to the treatment arm ($T=1$) and $n_0 = 200$ to the control arm ($T=0$).\nThe primary efficacy endpoint $Y$ is binary.\nIn the treatment arm, the outcome is missing for $70$ of $200$ participants, a missingness rate of $P(R_Y=0 \\mid T=1) = 70/200 = 0.35$.\nIn the control arm, the outcome is missing for $30$ of $200$ participants, a missingness rate of $P(R_Y=0 \\mid T=0) = 30/200 = 0.15$.\nThis large and differential rate of missing data between the arms is a severe warning sign that the Missing Completely At Random (MCAR) assumption, $P(R_Y=1 \\mid Y, T, X) = P(R_Y=1)$, is violated.\n\nThe investigators report a complete-case (CC) efficacy risk difference, $\\hat{\\Delta}_{\\text{CC}}$, favoring treatment. This estimate is based only on participants with observed outcomes.\nFor the treatment arm, there are $70$ responders among $130$ observed participants, yielding an observed response rate of $\\bar{Y}_{\\text{obs},1} = 70/130 \\approx 0.538$.\nFor the control arm, there are $80$ responders among $170$ observed participants, yielding an observed response rate of $\\bar{Y}_{\\text{obs},0} = 80/170 \\approx 0.471$.\nThe complete-case risk difference is $\\hat{\\Delta}_{\\text{CC}} = \\bar{Y}_{\\text{obs},1} - \\bar{Y}_{\\text{obs},0} \\approx 0.067$.\n\nThe causal estimand of interest is the true risk difference, $\\Delta = E[Y \\mid T=1] - E[Y \\mid T=0]$. The law of total expectation, as provided, shows the relationship between the true mean in an arm ($E[Y \\mid T=t]$) and the means in the observed and missing subsets:\n$$E[Y \\mid T=t] = E[Y \\mid T=t, R_Y=1] P(R_Y=1 \\mid T=t) + E[Y \\mid T=t, R_Y=0] P(R_Y=0 \\mid T=t)$$\nA complete-case analysis implicitly assumes that the mean response among those with missing data is the same as among those with observed data, i.e., $E[Y \\mid T=t, R_Y=0] = E[Y \\mid T=t, R_Y=1]$. Under the MNAR mechanism suggested by the problem's context—where $P(R_Y=1 \\mid Y, T)$ depends on the unobserved outcome $Y$—this assumption is indefensible. For example, if patients who are not responding well ($Y=0$) are more likely to drop out, then $E[Y \\mid T=t, R_Y=0]$ would be lower than $E[Y \\mid T=t, R_Y=1]$, and the complete-case estimate $\\bar{Y}_{\\text{obs},t}$ would be biased upwards. Given this context, we evaluate the proposed actions.\n\n**Option A Evaluation**\nThis option states that if missingness is MNAR ($P(R_Y=1 \\mid Y, T)$ depends on $Y$), the complete-case estimate $\\hat{\\Delta}_{\\text{CC}}$ can be biased. It then proposes requesting sensitivity analyses using pattern-mixture models (PMM) or selection models, which introduce sensitivity parameters to explore plausible MNAR scenarios.\nThis reasoning is entirely correct. The potential for bias in $\\hat{\\Delta}_{\\text{CC}}$ under MNAR is the central issue. PMMs and selection models are the two primary frameworks for conducting sensitivity analyses under MNAR. PMMs model the distribution of the outcome conditional on the missingness pattern, $f(Y \\mid R_Y=r, T=t)$, and require untestable assumptions about the outcomes for the missing subjects (e.g., specifying $E[Y \\mid T=t, R_Y=0]$ relative to $E[Y \\mid T=t, R_Y=1]$ via a parameter $\\delta_t$). Selection models jointly model the outcome and the missingness process, $f(Y, R_Y \\mid T=t)$. Both approaches allow the DSMB to formally assess the robustness of the trial's conclusions to a range of plausible deviations from the simpler MAR assumption. This is a critical and standard procedure when faced with substantial missing data.\nVerdict: **Correct**.\n\n**Option B Evaluation**\nThis option suggests relying on inverse probability weighting (IPW) using models for the observation probability, $P(R_Y=1 \\mid T, X)$, to fully correct bias even under MNAR, obviating the need for further sensitivity analysis.\nThis is fundamentally incorrect. Standard IPW is a valid method for correcting bias under the Missing At Random (MAR) assumption, where $P(R_Y=1 \\mid Y, T, X) = P(R_Y=1 \\mid T, X)$. That is, missingness can depend on *observed* data ($T, X$), but not on the *unobserved* outcome $Y$ itself. Under MAR, weighting each observed subject $i$ by $w_i = 1 / \\hat{P}(R_{Y,i}=1 \\mid T_i, X_i)$ produces a consistent estimate of the population mean $E[Y \\mid T=t]$. However, the problem explicitly raises the concern of MNAR, where the missingness probability *does* depend on the unobserved $Y$. In this scenario, standard IPW based on a model for $P(R_Y=1 \\mid T, X)$ is no longer guaranteed to be unbiased and can perform as poorly as complete-case analysis. Claiming it \"fully corrects bias\" under MNAR and makes sensitivity analyses \"unnecessary\" is a dangerous misconception.\nVerdict: **Incorrect**.\n\n**Option C Evaluation**\nThis option advocates for a tipping-point analysis and the use of conservative worst-case bounds. A tipping-point analysis is a specific form of sensitivity analysis where one systematically varies the assumptions about the missing data (e.g., the value of $E[Y \\mid T=t, R_Y=0]$) to find the point at which the qualitative conclusion of the study (e.g., treatment is superior to control) would be reversed. This provides a clear measure of the robustness of the interim finding. The worst-case bounding analysis complements this by establishing the absolute range of possible treatment effects. The example given (imputing all missing $Y$ in the treatment arm as failures, $Y=0$, and all missing $Y$ in the control arm as successes, $Y=1$) represents a plausible \"worst-case\" scenario for the treatment effect. This type of bracketing, along with a tipping-point analysis, provides the DSMB with a comprehensive view of the uncertainty created by the missing data. This is an exemplary approach to handling potential MNAR.\nVerdict: **Correct**.\n\n**Option D Evaluation**\nThis option suggests joint modeling of longitudinal markers and time-to-dropout if missingness is monotone (i.e., due to dropout) and driven by a latent disease process. It also suggests comparing these results to standard MAR-based analyses like multiple imputation (MI).\nThis describes a sophisticated and appropriate methodology. Joint models (a class of selection models) can effectively account for MNAR mechanisms where dropout is driven by the underlying trajectory of the disease, which is proxied by longitudinal markers. The models use the information in the observed marker history to inform the dropout process and, in turn, provide a less biased estimate of the treatment effect on the endpoint. Comparing the results from such an MNAR model to those from a standard MAR-based analysis (like MI using baseline covariates $X$ and treatment arm $T$) is a crucial form of sensitivity analysis. If the results are consistent across models, confidence in the findings increases. If they diverge, it highlights that the conclusions are sensitive to the untestable missing data assumptions. This is exactly the kind of rigorous investigation a DSMB should request.\nVerdict: **Correct**.\n\n**Option E Evaluation**\nThis option recommends preferring a complete-case (CC) analysis augmented by a per-protocol (PP) analysis, claiming this combination yields unbiased estimates regardless of the missingness mechanism.\nThis recommendation is deeply flawed and contrary to fundamental principles of clinical trial analysis. A PP analysis, which restricts the sample to participants who fully adhere to the protocol, destroys the integrity of randomization. Adherence is a post-randomization variable that can be influenced by treatment efficacy and tolerability. Comparing self-selected groups of \"adherers\" introduces selection bias and invalidates causal inference. The primary principle for unbiased estimation of a pragmatic treatment effect is Intention-To-Treat (ITT), which analyzes participants as randomized, regardless of adherence. Neither CC nor PP analysis is robust to MNAR, and in fact, PP analysis often exacerbates bias. Relying on these biased methods \"without sensitivity analyses\" would be a dereliction of the DSMB's duty to ensure trial integrity.\nVerdict: **Incorrect**.", "answer": "$$\\boxed{ACD}$$", "id": "5058103"}]}