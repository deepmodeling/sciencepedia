{"hands_on_practices": [{"introduction": "A cornerstone of functional genomics is the pooled CRISPR screen, a powerful technique for identifying genes that are essential for cell viability or other phenotypes. The success of such a screen hinges on careful experimental design. This exercise [@problem_id:5066651] challenges you to apply the statistical principles, specifically the Poisson model of viral infection, that govern the trade-offs between statistical power and experimental bias, ensuring you can correctly determine key parameters like Multiplicity of Infection (MOI) and library coverage.", "problem": "A pooled Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) loss-of-function screen is designed to identify essential genes in a tumor cell line. A lentiviral single-guide RNA (sgRNA) library contains $L = 10^5$ distinct sgRNAs targeting putative essential and nonessential genes. Cells are infected and then subjected to antibiotic selection, passaging, and a viability readout. Assume the following fundamental basis: (i) viral entry events into cells occur independently and can be modeled as a Poisson process, (ii) antibiotic selection removes cells that receive zero functional integrations, and (iii) the narrowest population bottleneck during the screen determines how many unique sgRNAs effectively contribute signal to downstream next-generation sequencing (NGS) counts. Define Multiplicity of Infection (MOI) as a property of the infection process and define library coverage as a property of representation of the library in the cell population.\n\nThe design goal is to maximize power to detect depletion of sgRNAs targeting essential genes while minimizing bias from multi-guide cells and from loss of representation. A team considers infecting at MOI $m = 0.3$ and estimates that the combined effect of post-selection bottlenecks (e.g., drug selection, passaging, sampling) reduces the number of surviving, analyzable cells to a fraction $f = 0.5$ of the initially plated population. They require a final minimal coverage of $C_{\\min} = 500$ cells per sgRNA at the narrowest bottleneck.\n\nWhich single option correctly defines MOI and library coverage in pooled CRISPR screens, correctly infers the impact of MOI and coverage on statistical power and bias for identifying essential targets, and correctly computes the key quantities implied by the above assumptions?\n\nA. MOI is the mean number of viral integrations per cell under Poisson infection, and library coverage is the average number of cells per sgRNA at the narrowest bottleneck that still contribute to the phenotype. At MOI $m = 0.3$, the fraction of all cells with exactly one integration is approximately $m e^{-m} \\approx 0.22$, while among infected cells the fraction with multiple integrations is approximately $\\dfrac{1 - e^{-m}(1+m)}{1 - e^{-m}} \\approx 0.14$. Lowering MOI reduces multi-sgRNA bias but increases the fraction of uninfected cells, which must be offset by higher starting cell numbers to maintain coverage. To ensure $C_{\\min} = 500$ with $L = 10^5$ and $f = 0.5$, the minimal starting population is $N_0 \\ge \\dfrac{L \\, C_{\\min}}{(1 - e^{-m}) \\, f} \\approx 3.9 \\times 10^8$ cells. Higher coverage reduces sampling variance and increases power to detect depleting sgRNAs.\n\nB. MOI is the fraction of cells that become infected, and library coverage is the number of NGS reads per sgRNA. At MOI $m = 0.3$, exactly $30\\%$ of cells are infected, so multi-infection is negligible. Higher MOI always increases power without introducing bias because more cells carry sgRNAs. The minimal starting cells to reach $C_{\\min} = 500$ are $N_0 \\ge L \\, C_{\\min} \\, f \\approx 2.5 \\times 10^7$ cells.\n\nC. MOI is the mean number of viral integrations per cell, and coverage is the number of infected cells per sgRNA after selection. At MOI $m = 0.3$, the fraction of infected cells with multiple integrations is approximately $1 - e^{-m}(1+m) \\approx 0.037$, which is small enough to ignore. To achieve $C_{\\min} = 500$, we need $N_0 \\ge \\dfrac{L \\, C_{\\min}}{f} \\approx 1.0 \\times 10^8$ cells because only the post-selection bottleneck matters for coverage. Increasing coverage reduces power to detect strong effects because more cells dilute phenotypes.\n\nD. MOI is the number of virus particles added per cell, and coverage is the number of plasmid colonies per sgRNA during library cloning. An MOI $m = 2$ ensures nearly every cell gets at least one sgRNA, minimizing bias. Multi-infection can be modeled as a binomial process with probability $p = m/(1+m)$, so the multi-infection rate is $p^2$. For $L = 10^5$ and $C_{\\min} = 500$, the needed starting cells are $N_0 \\ge L \\, C_{\\min} = 5 \\times 10^7$, independent of selection losses because selection only removes uninfected cells.", "solution": "The user wants me to validate and solve a problem concerning the experimental design of a pooled CRISPR screen.\n\n### Step 1: Extract Givens\n- Type of experiment: Pooled Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR) loss-of-function screen.\n- Goal: Identify essential genes in a tumor cell line.\n- Library size: $L = 10^5$ distinct single-guide RNAs (sgRNAs).\n- Process model:\n    - (i) Viral entry is a Poisson process.\n    - (ii) Antibiotic selection removes cells with zero functional integrations.\n    - (iii) The narrowest population bottleneck determines effective sgRNA representation.\n- Terms to define: Multiplicity of Infection (MOI) and library coverage.\n- Design parameters:\n    - Proposed MOI: $m = 0.3$.\n    - Post-selection survival fraction: $f = 0.5$ of the initially plated population.\n    - Required final minimal coverage: $C_{\\min} = 500$ cells per sgRNA.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement describes a standard scenario in functional genomics.\n- **Scientifically Grounded:** The entire premise is based on established, standard procedures for performing and analyzing pooled CRISPR screens. The use of a lentiviral library, the concept of MOI, the Poisson model for infection, antibiotic selection, population bottlenecks, and the trade-off between multi-infection bias and screen coverage are all fundamental and correct principles in this field. The numerical values ($L = 10^5$, $m = 0.3$, $C_{\\min} = 500$) are highly realistic for a modern screen. The problem belongs to the specified topic of *target identification using genetic and functional genomics approaches* within *translational medicine*.\n- **Well-Posed:** The problem provides all necessary data and assumptions to define the terms, perform the calculations, and evaluate the logical statements presented in the options. The question is unambiguous.\n- **Objective:** The language is technical and devoid of subjective or opinion-based claims.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is scientifically sound, well-posed, and objective. I will proceed to derive the solution and evaluate the options.\n\n### Derivation of Principles and Calculations\n\n**1. Definitions and Poisson Model**\n- **Multiplicity of Infection (MOI):** In the context of a pooled viral library infection modeled as a Poisson process, the MOI (denoted by $m$) is the mean of the distribution. It represents the average number of functional viral integrations per cell. It is a key parameter controlling the distribution of sgRNAs among cells.\n- **Library Coverage:** In this context, library coverage refers to the average number of cells that contain a specific sgRNA and survive to the narrowest population bottleneck of the experiment. This bottleneck determines the statistical power of the screen, as it sets the sampling depth for each sgRNA.\n- **Poisson Distribution:** The probability $P(k)$ that a given cell receives exactly $k$ functional viral integrations is given by the Poisson formula:\n$$P(k) = \\frac{e^{-m} m^k}{k!}$$\nGiven $m = 0.3$:\n- Fraction of uninfected cells ($k=0$): $P(0) = \\frac{e^{-0.3} (0.3)^0}{0!} = e^{-0.3} \\approx 0.7408$. These cells are eliminated by antibiotic selection.\n- Fraction of cells with a single integration ($k=1$): $P(1) = \\frac{e^{-0.3} (0.3)^1}{1!} = 0.3 e^{-0.3} \\approx 0.3 \\times 0.7408 \\approx 0.2222$. This is the desired population for an unambiguous phenotype-to-genotype link.\n- Fraction of cells with multiple integrations ($k \\ge 2$): $P(k \\ge 2) = 1 - P(0) - P(1) = 1 - e^{-0.3} - 0.3 e^{-0.3} = 1 - e^{-0.3}(1+0.3) \\approx 1 - 0.7408 \\times 1.3 \\approx 1 - 0.96304 = 0.03696$.\n\n**2. Bias, Power, and MOI Trade-off**\n- **Bias:** Multi-guide cells (those with $k \\ge 2$ integrations) are a source of bias. If a cell with two sgRNAs dies, it is impossible to know which sgRNA caused the lethal phenotype. A low MOI is chosen to minimize the fraction of such cells.\n- **Rate of multi-infection among infected cells:** The fraction of *all* cells that are infected is $P(k \\ge 1) = 1 - P(0) = 1 - e^{-m}$. The fraction of *infected* cells that have multiple guides is a conditional probability:\n$$P(k \\ge 2 | k \\ge 1) = \\frac{P(k \\ge 2 \\cap k \\ge 1)}{P(k \\ge 1)} = \\frac{P(k \\ge 2)}{P(k \\ge 1)} = \\frac{1 - e^{-m}(1+m)}{1 - e^{-m}}$$\nFor $m=0.3$:\n$$P(k \\ge 2 | k \\ge 1) \\approx \\frac{0.03696}{1 - 0.7408} = \\frac{0.03696}{0.2592} \\approx 0.1426$$\nSo, approximately $14.3\\%$ of the cells that survive antibiotic selection will contain multiple sgRNAs.\n- **Power:** Statistical power to detect gene essentiality (depletion of a corresponding sgRNA) is determined by the ability to distinguish a true signal from sampling noise. Higher library coverage ($C$) reduces the variance of sgRNA counts, thereby increasing power. Lowering MOI necessitates starting with more cells to achieve the same number of *infected* cells, thus maintaining coverage.\n\n**3. Calculation of Initial Cell Number ($N_0$)**\n- The total number of unique sgRNAs is $L = 10^5$.\n- The required minimal coverage at the bottleneck is $C_{\\min} = 500$ cells/sgRNA.\n- The total number of cells required at the narrowest bottleneck is $N_{\\text{bottleneck}} = L \\times C_{\\min} = 10^5 \\times 500 = 5 \\times 10^7$ cells.\n- This bottleneck population is the result of a sequence of loss events starting from the initial population $N_0$.\n- First, a fraction $(1 - e^{-m})$ of cells are successfully infected and survive antibiotic selection. The population becomes $N_0 (1 - e^{-m})$.\n- Second, other processes (passaging, etc.) lead to further cell loss, represented by a survival fraction $f = 0.5$. The problem statement for Option A suggests a sequential loss model, which is the most rigorous interpretation: the population at the bottleneck is $N_0 \\times (1-e^{-m}) \\times f$.\n- We must satisfy the condition: $N_{\\text{bottleneck}} \\le N_0 (1-e^{-m}) f$.\n- To find the minimal starting population, we set this as an equality and solve for $N_0$:\n$$N_0 = \\frac{N_{\\text{bottleneck}}}{(1-e^{-m})f} = \\frac{L C_{\\min}}{(1-e^{-m})f}$$\n- Plugging in the values:\n$$N_0 = \\frac{5 \\times 10^7}{(1 - e^{-0.3}) \\times 0.5} \\approx \\frac{5 \\times 10^7}{0.2592 \\times 0.5} = \\frac{5 \\times 10^7}{0.1296} \\approx 3.858 \\times 10^8$$\nThis is approximately $3.9 \\times 10^8$ cells.\n\n### Option-by-Option Analysis\n\n**A. MOI is the mean number of viral integrations per cell under Poisson infection, and library coverage is the average number of cells per sgRNA at the narrowest bottleneck that still contribute to the phenotype. At MOI $m = 0.3$, the fraction of all cells with exactly one integration is approximately $m e^{-m} \\approx 0.22$, while among infected cells the fraction with multiple integrations is approximately $\\dfrac{1 - e^{-m}(1+m)}{1 - e^{-m}} \\approx 0.14$. Lowering MOI reduces multi-sgRNA bias but increases the fraction of uninfected cells, which must be offset by higher starting cell numbers to maintain coverage. To ensure $C_{\\min} = 500$ with $L = 10^5$ and $f = 0.5$, the minimal starting population is $N_0 \\ge \\dfrac{L \\, C_{\\min}}{(1 - e^{-m}) \\, f} \\approx 3.9 \\times 10^8$ cells. Higher coverage reduces sampling variance and increases power to detect depleting sgRNAs.**\n- Definitions of MOI and coverage are correct and precise.\n- The calculation for the fraction of cells with one integration ($P(1) = 0.3e^{-0.3} \\approx 0.22$) is correct.\n- The calculation for the fraction of *infected* cells with multiple integrations ($P(k \\ge 2 | k \\ge 1) \\approx 0.14$) is correct.\n- The reasoning about the MOI trade-off (bias vs. cell numbers) is correct.\n- The formula for the starting cell number $N_0$ is correct based on a sound sequential loss model, and the calculation yields the correct value ($\\approx 3.9 \\times 10^8$).\n- The final statement about coverage, sampling variance, and power is correct.\n- **Verdict:** Correct.\n\n**B. MOI is the fraction of cells that become infected, and library coverage is the number of NGS reads per sgRNA. At MOI $m = 0.3$, exactly $30\\%$ of cells are infected, so multi-infection is negligible. Higher MOI always increases power without introducing bias because more cells carry sgRNAs. The minimal starting cells to reach $C_{\\min} = 500$ are $N_0 \\ge L \\, C_{\\min} \\, f \\approx 2.5 \\times 10^7$ cells.**\n- The definition of MOI is incorrect. The fraction of infected cells is $1 - e^{-m}$.\n- The definition of coverage is imprecise; coverage refers to cells, not reads, although they are related.\n- The claim that at $m=0.3$, $30\\%$ of cells are infected is incorrect. The actual fraction is $1 - e^{-0.3} \\approx 26\\%$.\n- The statement that higher MOI does not introduce bias is fundamentally wrong; it is a primary source of bias.\n- The calculation for $N_0$ is based on an incorrect formula that ignores the fraction of uninfected cells.\n- **Verdict:** Incorrect.\n\n**C. MOI is the mean number of viral integrations per cell, and coverage is the number of infected cells per sgRNA after selection. At MOI $m = 0.3$, the fraction of infected cells with multiple integrations is approximately $1 - e^{-m}(1+m) \\approx 0.037$, which is small enough to ignore. To achieve $C_{\\min} = 500$, we need $N_0 \\ge \\dfrac{L \\, C_{\\min}}{f} \\approx 1.0 \\times 10^8$ cells because only the post-selection bottleneck matters for coverage. Increasing coverage reduces power to detect strong effects because more cells dilute phenotypes.**\n- The definition of MOI is correct. The definition of coverage is acceptable, though less precise than in option A.\n- The description of the multi-integration fraction is incorrect. The formula $1 - e^{-m}(1+m)$ gives the fraction relative to *all* cells, not *infected* cells. The value $0.037$ is the fraction of all cells, while the fraction among infected cells is much higher ($\\approx 0.14$).\n- The statement that increasing coverage *reduces* power is fundamentally incorrect. The opposite is true.\n- The formula for $N_0$ is incorrect as it fails to account for the loss of cells due to non-infection ($1 - e^{-m}$ factor).\n- **Verdict:** Incorrect.\n\n**D. MOI is the number of virus particles added per cell, and coverage is the number of plasmid colonies per sgRNA during library cloning. An MOI $m = 2$ ensures nearly every cell gets at least one sgRNA, minimizing bias. Multi-infection can be modeled as a binomial process with probability $p = m/(1+m)$, so the multi-infection rate is $p^2$. For $L = 10^5$ and $C_{\\min} = 500$, the needed starting cells are $N_0 \\ge L \\, C_{\\min} = 5 \\times 10^7$, independent of selection losses because selection only removes uninfected cells.**\n- The definition of MOI is imprecise (added particles vs. functional integrations).\n- The definition of coverage is completely wrong, confusing screen coverage with cloning quality control.\n- The claim that a high MOI like $m=2$ *minimizes bias* is the opposite of the truth; it maximizes multi-infection bias.\n- The suggestion to model the process as binomial is incorrect; the problem specifies a Poisson process.\n- The calculation for $N_0$ is wrong; it computes the number of cells at the bottleneck ($N_{\\text{bottleneck}}$), not the required starting number, and ignores all loss factors.\n- **Verdict:** Incorrect.", "answer": "$$\\boxed{A}$$", "id": "5066651"}, {"introduction": "Genome-Wide Association Studies (GWAS) have identified thousands of genetic variants associated with human diseases, yet the vast majority lie in non-coding regions of the genome. A critical step in translating these findings is to link a non-coding variant to its putative target gene. This problem [@problem_id:5066767] provides hands-on practice in building a quantitative model that integrates multiple genomic data types—including 3D chromatin contacts from Hi-C and regulatory element activity from ATAC-seq—to generate an evidence-based score for a variant-gene connection.", "problem": "In translational medicine, assigning a noncoding genetic variant to a putative target gene relies on integrating three-dimensional genome organization and chromatin state. The Central Dogma of Molecular Biology states that deoxyribonucleic acid (DNA) sequence variation can modulate ribonucleic acid (RNA) transcription through cis-regulatory elements that contact gene promoters. High-throughput chromosome conformation capture (Hi-C) provides contact frequencies between genomic loci, and Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) reports chromatin accessibility, a proxy for regulatory element activity.\n\nConsider a single noncoding variant $v$ and a candidate gene promoter $p$ located within the same topologically associating domain (TAD). Assume the following well-tested modeling bases:\n- Within a TAD, the probability of regulatory contact between two loci decreases with genomic separation, and empirical decay can be approximated by an exponential penalty with rate parameter $\\lambda$, so greater distance reduces the chance of functional contact.\n- Hi-C observed-over-expected ($\\mathrm{O}/\\mathrm{E}$) contact enrichments scale the baseline contact propensity at fixed genomic separation.\n- ATAC-seq signal is monotonic in occupancy but saturates; a simple saturating transform $A(x)$ can be used to map normalized counts $x$ to a quantity proportional to the probability of accessibility.\n- Replicate ATAC-seq signals for a locus are approximately log-normally distributed; thus, the maximum likelihood estimator of central tendency is the geometric mean.\n\nYou are provided matched-cell-type data:\n- Genomic separation between $v$ and $p$ is $d = 0.240$ megabases.\n- Hi-C observed-over-expected enrichment for the $10$ kilobase bins containing $v$ and $p$ is $C_{\\mathrm{OE}} = 1.35$.\n- The exponential decay rate is $\\lambda = 2.0$ megabase$^{-1}$.\n- Library-size normalized ATAC-seq intensities (reads per million) for $v$ across two replicates are $x_{v,1} = 35$ and $x_{v,2} = 50$; for $p$, $x_{p,1} = 20$ and $x_{p,2} = 26$.\n- Use the saturating transform $A(x) = \\frac{x}{K + x}$ with $K = 40$ (reads per million).\n\nStarting from the bases above and treating contact propensity and accessibility as conditionally independent contributors to a joint assignment propensity, derive a dimensionless distance- and contact-weighted score $S$ for assigning $v$ to $p$ that combines the distance-penalized Hi-C term with accessibility at both loci. Compute $S$ using the provided values and report the result as a single real number. Round your answer to four significant figures. The score is dimensionless; do not include any units in your final numerical answer.", "solution": "The user-provided problem will first be subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- **Noncoding variant:** $v$\n- **Candidate gene promoter:** $p$\n- **Genomic separation:** $d = 0.240$ megabases.\n- **Hi-C observed-over-expected enrichment:** $C_{\\mathrm{OE}} = 1.35$.\n- **Exponential decay rate:** $\\lambda = 2.0$ megabase$^{-1}$.\n- **ATAC-seq intensities for $v$ (replicate 1):** $x_{v,1} = 35$ reads per million.\n- **ATAC-seq intensities for $v$ (replicate 2):** $x_{v,2} = 50$ reads per million.\n- **ATAC-seq intensities for $p$ (replicate 1):** $x_{p,1} = 20$ reads per million.\n- **ATAC-seq intensities for $p$ (replicate 2):** $x_{p,2} = 26$ reads per million.\n- **Saturating transform for accessibility:** $A(x) = \\frac{x}{K + x}$.\n- **Saturation constant:** $K = 40$ reads per million.\n- **Modeling Assumption 1:** Contact probability decays with genomic distance $d$ as an exponential penalty $\\exp(-\\lambda d)$.\n- **Modeling Assumption 2:** Hi-C $\\mathrm{O}/\\mathrm{E}$ contact enrichment $C_{\\mathrm{OE}}$ scales the baseline contact propensity.\n- **Modeling Assumption 3:** ATAC-seq signal is transformed by the saturating function $A(x)$ to represent accessibility.\n- **Modeling Assumption 4:** The maximum likelihood estimator for replicate ATAC-seq signals is the geometric mean.\n- **Modeling Assumption 5:** Contact propensity and accessibility are conditionally independent contributors to a joint assignment propensity.\n- **Objective:** Derive a dimensionless score $S$ and compute its value, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria.\n- **Scientifically Grounded:** The problem is firmly rooted in computational biology and translational medicine. It uses standard high-throughput sequencing data types (Hi-C, ATAC-seq) and established quantitative models for interpreting them (exponential decay of contact probability, saturating kinetics for signal response, log-normal distribution of sequencing counts). The Central Dogma is correctly cited as the underlying biological principle. The scenario described—linking a noncoding variant to a target gene—is a central and authentic challenge in the field.\n- **Well-Posed:** The problem is fully specified. All necessary data ($d$, $C_{\\mathrm{OE}}$, $\\lambda$, $x$ values, $K$), models (exponential decay, geometric mean, saturating transform), and the principle for combining evidence (multiplication of conditionally independent terms) are provided. This allows for the derivation and computation of a unique, stable, and meaningful score.\n- **Objective:** The problem is stated in precise, quantitative, and unbiased language. It is free of subjective claims or opinions.\n- **No Flaws Detected:** The problem does not violate any of the specified invalidity criteria. The units are consistent: $\\lambda$ is in units of megabase$^{-1}$ and $d$ is in megabases, making the product $\\lambda d$ in the exponent dimensionless. The ATAC-seq intensities $x$ and the constant $K$ are in the same units (reads per million), making the accessibility term $A(x)$ dimensionless. The Hi-C $\\mathrm{O}/\\mathrm{E}$ value $C_{\\mathrm{OE}}$ is inherently a dimensionless ratio. Consequently, the final score $S$ is correctly identified as dimensionless.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, and objective. It is deemed **valid**. A full solution will be provided.\n\nThe objective is to derive a dimensionless score $S$ that quantifies the evidence for a functional link between a noncoding variant $v$ and a gene promoter $p$. The problem states that the score should combine a distance-penalized Hi-C term with the accessibility at both loci, treating these as conditionally independent contributors. This principle of conditional independence implies that the total score is the product of the individual contributing factors.\n\nThe score $S$ can be expressed as:\n$$S = (\\text{Contact Propensity}) \\times (\\text{Accessibility at } v) \\times (\\text{Accessibility at } p)$$\n\nLet us derive each term based on the provided modeling bases.\n\n1.  **Contact Propensity:** This term combines the baseline decay of contact probability with genomic distance and the specific measured Hi-C contact enrichment. The exponential penalty for distance $d$ is given by $\\exp(-\\lambda d)$. The Hi-C observed-over-expected enrichment $C_{\\mathrm{OE}}$ scales this baseline. Thus, the contact propensity term is $C_{\\mathrm{OE}} \\exp(-\\lambda d)$.\n\n2.  **Accessibility at Locus $v$:** The ATAC-seq signal is a proxy for chromatin accessibility. For a locus with replicate measurements, the central tendency is estimated by the geometric mean, as per the log-normal distribution assumption. For variant $v$ with replicate intensities $x_{v,1}$ and $x_{v,2}$, the representative signal is $x_v = \\sqrt{x_{v,1} x_{v,2}}$. This signal is then converted to an accessibility probability-like quantity using the given saturating transform $A(x) = \\frac{x}{K+x}$. Therefore, the accessibility term for $v$ is $A(x_v) = \\frac{\\sqrt{x_{v,1} x_{v,2}}}{K + \\sqrt{x_{v,1} x_{v,2}}}$.\n\n3.  **Accessibility at Locus $p$:** Similarly, for promoter $p$ with replicate intensities $x_{p,1}$ and $x_{p,2}$, the representative signal is $x_p = \\sqrt{x_{p,1} x_{p,2}}$. The corresponding accessibility term is $A(x_p) = \\frac{\\sqrt{x_{p,1} x_{p,2}}}{K + \\sqrt{x_{p,1} x_{p,2}}}$.\n\nCombining these three components, the full expression for the score $S$ is:\n$$S = C_{\\mathrm{OE}} \\exp(-\\lambda d) \\left( \\frac{\\sqrt{x_{v,1} x_{v,2}}}{K + \\sqrt{x_{v,1} x_{v,2}}} \\right) \\left( \\frac{\\sqrt{x_{p,1} x_{p,2}}}{K + \\sqrt{x_{p,1} x_{p,2}}} \\right)$$\n\nNow, we substitute the provided numerical values into this expression.\nGiven:\n- $d = 0.240$\n- $C_{\\mathrm{OE}} = 1.35$\n- $\\lambda = 2.0$\n- $x_{v,1} = 35$, $x_{v,2} = 50$\n- $x_{p,1} = 20$, $x_{p,2} = 26$\n- $K = 40$\n\nFirst, calculate the representative ATAC-seq signals:\nFor variant $v$:\n$$x_v = \\sqrt{x_{v,1} x_{v,2}} = \\sqrt{35 \\times 50} = \\sqrt{1750} \\approx 41.833001...$$\nFor promoter $p$:\n$$x_p = \\sqrt{x_{p,1} x_{p,2}} = \\sqrt{20 \\times 26} = \\sqrt{520} \\approx 22.803508...$$\n\nNext, calculate the accessibility terms using the saturating transform:\n$$A(x_v) = \\frac{\\sqrt{1750}}{40 + \\sqrt{1750}} \\approx \\frac{41.833001}{40 + 41.833001} = \\frac{41.833001}{81.833001} \\approx 0.511213...$$\n$$A(x_p) = \\frac{\\sqrt{520}}{40 + \\sqrt{520}} \\approx \\frac{22.803508}{40 + 22.803508} = \\frac{22.803508}{62.803508} \\approx 0.363095...$$\n\nThen, calculate the distance-penalized Hi-C term. The exponent is $\\lambda d = 2.0 \\times 0.240 = 0.48$.\n$$C_{\\mathrm{OE}} \\exp(-\\lambda d) = 1.35 \\times \\exp(-0.48) \\approx 1.35 \\times 0.618783... \\approx 0.835357...$$\n\nFinally, multiply the three terms to find the score $S$:\n$$S \\approx (0.835357) \\times (0.511213) \\times (0.363095)$$\n$$S \\approx 0.155132...$$\n\nThe problem requires the answer to be rounded to four significant figures.\n$$S \\approx 0.1551$$", "answer": "$$\\boxed{0.1551}$$", "id": "5066767"}, {"introduction": "Biological processes and diseases are rarely the result of a single protein's action but rather emerge from complex interaction networks. Network-based approaches allow us to leverage this connectivity to expand a small set of known disease-associated genes into a prioritized list of new candidate targets. This computational exercise [@problem_id:5066670] guides you through the implementation of a Random Walk with Restart algorithm, a widely used method to quantify a protein's proximity to known disease seeds within a protein-protein interaction network, effectively 'diffusing' information from known hits to new, high-confidence candidates.", "problem": "You are given a weighted, undirected protein–protein interaction network represented as a graph $G = (V, E)$ with $|V| = n$ proteins (nodes). Let the weighted adjacency matrix be $A \\in \\mathbb{R}^{n \\times n}$ where $A_{ij} \\ge 0$ encodes the interaction strength between protein $i$ and protein $j$, and $A_{ij} = A_{ji}$ for all $i, j$. Define the diagonal degree matrix $D \\in \\mathbb{R}^{n \\times n}$ with entries $D_{ii} = \\sum_{j=1}^{n} A_{ij}$. Define the row-normalized transition matrix $W \\in \\mathbb{R}^{n \\times n}$ by\n$$\nW = D^{-1} A,\n$$\nwith the convention that if $D_{ii} = 0$, the $i$-th row of $W$ is the zero row.\n\nSuppose you have a nonnegative seed vector $s \\in \\mathbb{R}^n$ representing Genome-Wide Association Study (GWAS) evidence for disease-relevant proteins, where $s_i  0$ for proteins implicated by GWAS and $s_i = 0$ otherwise. Consider diffusion by random walk with restart parameter $\\lambda \\in (0, 1]$ defined by the fixed-point equation\n$$\nf = \\lambda s + (1 - \\lambda) W f,\n$$\nwhere $f \\in \\mathbb{R}^n$ is the diffusion score vector. This equation is guaranteed to have a unique solution for $\\lambda \\in (0,1]$ under the given construction of $W$.\n\nYour task is to write a program that, for each test case:\n1. Computes $W$ from $A$ and $D$.\n2. Solves for the diffusion score vector $f$ using the fixed-point equation above.\n3. Identifies candidate targets as those nodes $i$ such that $s_i = 0$ and $f_i  \\epsilon$, where $\\epsilon$ is a small numerical tolerance set to $10^{-12}$.\n4. Ranks candidate targets in descending order of $f_i$, breaking ties by ascending node index.\n5. Returns the top-$k$ candidate targets (node indices). If fewer than $k$ candidates have strictly positive diffusion scores, return all such candidates. If the seed vector $s$ is identically zero, return the empty list.\n\nAssume all quantities are dimensionless and no physical units apply.\n\nAcronym definitions: Genome-Wide Association Study (GWAS), Protein–Protein Interaction (PPI).\n\nUse the following test suite, each defined by its adjacency matrix $A$, seed vector $s$, restart parameter $\\lambda$, and integer $k$.\n\nTest case 1 (happy path, moderately connected network):\n$$\nA^{(1)} =\n\\begin{bmatrix}\n0  0.5  0  0  0  0  0.1 \\\\\n0.5  0  0.4  0  0.1  0  0 \\\\\n0  0.4  0  0.3  0  0.2  0 \\\\\n0  0  0.3  0  0.7  0  0 \\\\\n0  0.1  0  0.7  0  0.2  0 \\\\\n0  0  0.2  0  0.2  0  0.6 \\\\\n0.1  0  0  0  0  0.6  0 \\\\\n\\end{bmatrix}, \\quad\ns^{(1)} =\n\\begin{bmatrix}\n0 \\\\\n1.2 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n0.8 \\\\\n0 \\\\\n\\end{bmatrix}, \\quad\n\\lambda^{(1)} = 0.65, \\quad k^{(1)} = 3.\n$$\n\nTest case 2 (boundary case with an isolated seeded node):\n$$\nA^{(2)} =\n\\begin{bmatrix}\n0  1.0  0.3  0  0 \\\\\n1.0  0  0.5  0  0.2 \\\\\n0.3  0.5  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  0.2  0  0  0 \\\\\n\\end{bmatrix}, \\quad\ns^{(2)} =\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n0 \\\\\n1.0 \\\\\n0 \\\\\n\\end{bmatrix}, \\quad\n\\lambda^{(2)} = 0.85, \\quad k^{(2)} = 2.\n$$\n\nTest case 3 (disconnected components, seeds in different components):\n$$\nA^{(3)} =\n\\begin{bmatrix}\n0  0.9  0.4  0  0  0  0  0 \\\\\n0.9  0  0.9  0  0  0  0  0 \\\\\n0.4  0.9  0  0.9  0  0  0  0 \\\\\n0  0  0.9  0  0  0  0  0 \\\\\n0  0  0  0  0  0.8  0.3  0 \\\\\n0  0  0  0  0.8  0  0.8  0 \\\\\n0  0  0  0  0.3  0.8  0  0.8 \\\\\n0  0  0  0  0  0  0.8  0 \\\\\n\\end{bmatrix}, \\quad\ns^{(3)} =\n\\begin{bmatrix}\n0 \\\\\n1.0 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n1.1 \\\\\n0 \\\\\n\\end{bmatrix}, \\quad\n\\lambda^{(3)} = 0.7, \\quad k^{(3)} = 3.\n$$\n\nTest case 4 (edge case with no seeds):\n$$\nA^{(4)} =\n\\begin{bmatrix}\n0  0.5  0  0.5 \\\\\n0.5  0  0.5  0 \\\\\n0  0.5  0  0.5 \\\\\n0.5  0  0.5  0 \\\\\n\\end{bmatrix}, \\quad\ns^{(4)} =\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n0 \\\\\n0 \\\\\n\\end{bmatrix}, \\quad\n\\lambda^{(4)} = 0.9, \\quad k^{(4)} = 2.\n$$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the list of selected node indices for that test case, for example, using the exact format: `[list_case1,list_case2,list_case3,list_case4]`.", "solution": "The user-provided problem statement has been meticulously validated and is determined to be valid. It is scientifically grounded in the established principles of network-based gene prioritization, mathematically well-posed, and all its terms and objectives are defined with sufficient precision. The problem asks for the implementation of the Random Walk with Restart (RWR) algorithm to identify and rank new protein targets based on their network proximity to a set of known disease-associated proteins (seeds).\n\nThe solution proceeds in two stages: first, a principled exposition of the underlying mathematical framework, and second, the design of a computational algorithm to solve the problem for the given test cases.\n\n### Principles of Network Diffusion and Random Walk with Restart\n\nThe core of this problem lies in modeling the \"influence\" of a set of seed proteins across a Protein-Protein Interaction (PPI) network. This is achieved through a network diffusion process, specifically the Random Walk with Restart (RWR) algorithm. Conceptually, RWR simulates a random walker that traverses the graph. From any given node, the walker can either move to an adjacent node, with probabilities determined by interaction strengths, or \"restart\" by teleporting back to one of the initial seed nodes.\n\nThe final score for each protein, represented by the vector $f$, corresponds to the steady-state probability of finding the walker at that protein's corresponding node. A high score $f_i$ for a non-seed protein $i$ implies that it is well-connected to the seed proteins through various paths in the network, making it a strong candidate for being functionally related to the disease or biological process defined by the seeds.\n\n### Mathematical Formulation and Solution\n\nThe problem is defined on a weighted, undirected graph $G = (V, E)$, where $V$ is the set of $n$ proteins and $E$ is the set of interactions. The interaction strengths are given by the weighted adjacency matrix $A$.\n\n1.  **Transition Matrix Construction**: The first step is to define the probabilities of moving between nodes. The degree of a node $i$, $D_{ii} = \\sum_{j=1}^{n} A_{ij}$, represents the total interaction strength of protein $i$. The row-normalized transition matrix $W = D^{-1} A$ is constructed, where $W_{ij} = A_{ij} / D_{ii}$ is the probability of transitioning from node $i$ to node $j$, conditioned on not restarting. For an isolated node $i$ with $D_{ii}=0$, its corresponding row in $W$ is defined as a zero vector, signifying that the walker cannot leave this node.\n\n2.  **The Fixed-Point Equation**: The steady-state diffusion scores are captured by the vector $f \\in \\mathbb{R}^n$ which satisfies the fixed-point equation:\n    $$\n    f = \\lambda s + (1 - \\lambda) W f\n    $$\n    Here, $s$ is the normalized seed vector, and $\\lambda \\in (0, 1]$ is the restart parameter. The term $\\lambda s$ represents the probability of restarting to a seed node, while $(1 - \\lambda) W f$ represents the probability flow from neighboring nodes.\n\n3.  **Solving the Linear System**: To find the unique solution for $f$, we rearrange the equation into a standard system of linear equations.\n    $$\n    f - (1 - \\lambda) W f = \\lambda s\n    $$\n    Factoring out $f$ gives:\n    $$\n    (I - (1 - \\lambda) W) f = \\lambda s\n    $$\n    where $I$ is the $n \\times n$ identity matrix. This is a linear system of the form $M x = b$, where the matrix $M = I - (1 - \\lambda) W$, the unknown vector is $x = f$, and the right-hand side vector is $b = \\lambda s$.\n    For $\\lambda \\in (0, 1]$, the spectral radius of $(1-\\lambda)W$ is strictly less than $1$, which guarantees that the matrix $M$ is invertible. Therefore, a unique solution for $f$ exists and can be found by solving this linear system. Computationally, this is efficiently and stably achieved using a numerical linear algebra solver, rather than by explicitly computing the matrix inverse $M^{-1}$.\n\n### Algorithmic Procedure\n\nThe following step-by-step algorithm is implemented to solve the problem for each test case.\n\n1.  **Input**: Receive the adjacency matrix $A$, seed vector $s$, restart parameter $\\lambda$, and the integer $k$.\n\n2.  **Handle the Zero Seed Case**: If the seed vector $s$ contains only zeros, the system becomes $(I - (1 - \\lambda) W) f = 0$. Since the matrix is invertible, the unique solution is the trivial one, $f=0$. In this case, no candidates will have a score above the threshold $\\epsilon$, so we return an empty list as per the problem specification.\n\n3.  **Compute Degree and Transition Matrices**:\n    a. Calculate the degree of each node by summing the rows of $A$: $D_{ii} = \\sum_{j} A_{ij}$.\n    b. Construct the transition matrix $W = D^{-1} A$. Care must be taken for nodes with degree $0$. For any row $i$ where $D_{ii} = 0$, the corresponding row $W_{i, \\cdot}$ is set to all zeros.\n\n4.  **Solve the Linear System**:\n    a. Construct the identity matrix $I$ of size $n \\times n$.\n    b. Form the matrix $M = I - (1 - \\lambda) W$.\n    c. Form the vector $b = \\lambda s$.\n    d. Solve the system $M f = b$ for the diffusion score vector $f$.\n\n5.  **Identify and Rank Candidates**:\n    a. Define the set of candidate nodes as those with an initial seed score of zero: $\\{i \\mid s_i = 0\\}$.\n    b. Filter these candidates to retain only those whose final diffusion score is strictly positive, i.e., $f_i  \\epsilon$ where $\\epsilon = 10^{-12}$.\n    c. Create a list of pairs $(f_i, i)$ for each valid candidate node $i$.\n    d. Sort this list of candidates. The primary sorting criterion is the diffusion score $f_i$ in descending order. The secondary criterion for tie-breaking is the node index $i$ in ascending order.\n\n6.  **Output Generation**:\n    a. Extract the node indices from the sorted list.\n    b. Return the top $k$ indices from this list. If the number of candidates is less than $k$, return all candidate indices.\n\nThis procedure is applied to each of the four test cases provided. The results are then formatted into the specified single-line string output.", "answer": "```python\nimport numpy as np\n\ndef solve_diffusion(A, s, lam, k, epsilon=1e-12):\n    \"\"\"\n    Computes and ranks candidate targets using Random Walk with Restart.\n\n    Args:\n        A (np.ndarray): The weighted adjacency matrix of the network.\n        s (np.ndarray): The seed vector.\n        lam (float): The restart parameter lambda.\n        k (int): The number of top candidates to return.\n        epsilon (float): A small numerical tolerance for score comparison.\n\n    Returns:\n        list: A list of the top-k ranked candidate node indices.\n    \"\"\"\n    n = A.shape[0]\n\n    # Handle the special case where the seed vector is all zeros.\n    if np.all(s == 0):\n        return []\n\n    # 1. Compute the degree matrix D and the transition matrix W.\n    degrees = np.sum(A, axis=1)\n    \n    # Create an inverse degree vector, handling zero-degree nodes.\n    inv_degrees = np.zeros_like(degrees)\n    non_zero_mask = degrees != 0\n    inv_degrees[non_zero_mask] = 1.0 / degrees[non_zero_mask]\n    \n    # Construct W by element-wise multiplication with the inverse degrees.\n    # This is equivalent to D_inv @ A but safer for zero-degree nodes.\n    W = inv_degrees[:, np.newaxis] * A\n    \n    # 2. Solve the fixed-point equation (I - (1-lam)W)f = lam*s\n    I = np.identity(n)\n    M = I - (1 - lam) * W\n    b = lam * s\n    \n    try:\n        f = np.linalg.solve(M, b)\n    except np.linalg.LinAlgError:\n        # This case should not be reached given the problem's guarantee\n        # of a unique solution, but is included for robustness.\n        return []\n\n    # 3. Identify candidate targets.\n    # Candidates are non-seed nodes (s_i = 0) with a score  epsilon.\n    non_seed_indices = np.where(s == 0)[0]\n    \n    candidates = []\n    for i in non_seed_indices:\n        if f[i]  epsilon:\n            candidates.append({'score': f[i], 'index': i})\n            \n    # 4. Rank candidates: descending score, ascending index for ties.\n    # The sort key (-score, index) achieves this.\n    candidates.sort(key=lambda c: (-c['score'], c['index']))\n    \n    # 5. Return the top-k candidate indices.\n    ranked_indices = [c['index'] for c in candidates]\n    \n    return ranked_indices[:k]\n\ndef solve():\n    \"\"\"\n    Defines and runs the test suite for the network diffusion problem.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"A\": np.array([\n                [0, 0.5, 0, 0, 0, 0, 0.1],\n                [0.5, 0, 0.4, 0, 0.1, 0, 0],\n                [0, 0.4, 0, 0.3, 0, 0.2, 0],\n                [0, 0, 0.3, 0, 0.7, 0, 0],\n                [0, 0.1, 0, 0.7, 0, 0.2, 0],\n                [0, 0, 0.2, 0, 0.2, 0, 0.6],\n                [0.1, 0, 0, 0, 0, 0.6, 0]\n            ]),\n            \"s\": np.array([0, 1.2, 0, 0, 0, 0.8, 0]),\n            \"lam\": 0.65,\n            \"k\": 3\n        },\n        {\n            \"A\": np.array([\n                [0, 1.0, 0.3, 0, 0],\n                [1.0, 0, 0.5, 0, 0.2],\n                [0.3, 0.5, 0, 0, 0],\n                [0, 0, 0, 0, 0],\n                [0, 0.2, 0, 0, 0]\n            ]),\n            \"s\": np.array([0, 0, 0, 1.0, 0]),\n            \"lam\": 0.85,\n            \"k\": 2\n        },\n        {\n            \"A\": np.array([\n                [0, 0.9, 0.4, 0, 0, 0, 0, 0],\n                [0.9, 0, 0.9, 0, 0, 0, 0, 0],\n                [0.4, 0.9, 0, 0.9, 0, 0, 0, 0],\n                [0, 0, 0.9, 0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 0.8, 0.3, 0],\n                [0, 0, 0, 0, 0.8, 0, 0.8, 0],\n                [0, 0, 0, 0, 0.3, 0.8, 0, 0.8],\n                [0, 0, 0, 0, 0, 0, 0.8, 0]\n            ]),\n            \"s\": np.array([0, 1.0, 0, 0, 0, 0, 1.1, 0]),\n            \"lam\": 0.7,\n            \"k\": 3\n        },\n        {\n            \"A\": np.array([\n                [0, 0.5, 0, 0.5],\n                [0.5, 0, 0.5, 0],\n                [0, 0.5, 0, 0.5],\n                [0.5, 0, 0.5, 0]\n            ]),\n            \"s\": np.array([0, 0, 0, 0]),\n            \"lam\": 0.9,\n            \"k\": 2\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_diffusion(case[\"A\"], case[\"s\"], case[\"lam\"], case[\"k\"])\n        results.append(result)\n\n    # Format the output string precisely as required: \"[list1,list2,...]\"\n    # str() adds spaces, so they must be removed.\n    formatted_results = [str(r).replace(' ', '') for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "5066670"}]}