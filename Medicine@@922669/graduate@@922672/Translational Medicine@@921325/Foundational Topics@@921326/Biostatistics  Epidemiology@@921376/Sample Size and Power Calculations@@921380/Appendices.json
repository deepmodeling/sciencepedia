{"hands_on_practices": [{"introduction": "This first exercise establishes the fundamental principles of sample size calculation. You will determine the minimum number of participants needed to detect a specific change in a continuous outcome—in this case, systolic blood pressure—based on predefined levels of statistical power $1 - \\beta$, significance $\\alpha$, and population variability $\\sigma$. Mastering this core calculation [@problem_id:4579227] is the essential first step for designing statistically sound studies.", "problem": "A city health department plans a pre–post evaluation of a sodium-reduction campaign intended to reduce mean systolic blood pressure in adults. Let the individual-level change be defined as post-intervention systolic blood pressure minus pre-intervention systolic blood pressure, so that a successful reduction is reflected by a negative change. Past surveillance suggests that, for individuals in this population, the distribution of change is approximately normal with a known standard deviation (SD) of $\\sigma = 5$ mmHg. Investigators wish to test the null hypothesis that the mean change is zero against a two-sided alternative, while designing the study to have a statistical power of $1-\\beta = 0.90$ to detect a true mean reduction of magnitude $\\delta = 2$ mmHg at a Type I error probability $\\alpha = 0.05$ (two-sided).\n\nAssume independent participants and that the sampling distribution of the mean change is normal with variance $\\sigma^{2}/n$ for sample size $n$. Using these foundations, determine the minimal whole-number sample size $n$ required to achieve the stated power to detect a true mean reduction of $\\delta = 2$ mmHg under a two-sided test with $\\alpha = 0.05$. Report the minimal whole-number sample size required; if your computation yields a non-integer, take the next largest integer. Finally, round your answer to $4$ significant figures.", "solution": "The problem requires the determination of the minimal sample size, $n$, for a pre–post study designed to evaluate the effectiveness of a sodium-reduction campaign on systolic blood pressure. The validation of the problem statement confirms that it is scientifically grounded, well-posed, and contains all necessary information to proceed with a formal statistical calculation.\n\nWe are testing a hypothesis about the mean change in systolic blood pressure, $\\mu$, where the change is defined as post-intervention minus pre-intervention. A reduction is indicated by a negative value of $\\mu$. The null hypothesis, $H_0$, is that there is no mean change, while the alternative hypothesis, $H_A$, is that there is a mean change. This constitutes a two-sided test.\n$$H_0: \\mu = 0$$\n$$H_A: \\mu \\neq 0$$\n\nThe study is being designed to meet specific statistical criteria. The provided parameters are:\n- The standard deviation of the individual-level change, $\\sigma = 5$ mmHg.\n- The magnitude of the true mean reduction to be detected, $\\delta = |\\mu_{A}| = 2$ mmHg. Since we are interested in a reduction, the specific alternative mean is $\\mu_A = -2$ mmHg.\n- The Type I error probability, $\\alpha = 0.05$ for a two-sided test.\n- The desired statistical power, $1-\\beta = 0.90$, which implies a Type II error probability of $\\beta = 0.10$.\n\nThe test statistic for the sample mean change, $\\bar{X}$, under the null hypothesis is given by $Z = \\frac{\\bar{X} - 0}{\\sigma/\\sqrt{n}}$. For a two-sided test at significance level $\\alpha$, we reject $H_0$ if the observed $|Z|$ is greater than the critical value $z_{1-\\alpha/2}$. The critical value $z_{1-\\alpha/2}$ is the quantile of the standard normal distribution exceeded with probability $\\alpha/2$.\n\nPower is the probability of correctly rejecting a false null hypothesis. We want to ensure that if the true mean change is $\\mu_A = -\\delta = -2$ mmHg, the probability of rejecting $H_0$ is at least $1-\\beta$. The power is the probability that our test statistic falls into the rejection region, given that the true mean is $\\mu_A$.\n$$\\text{Power} = P\\left(\\left|\\frac{\\bar{X}}{\\sigma/\\sqrt{n}}\\right|  z_{1-\\alpha/2} \\bigg| \\mu=\\mu_A\\right) = 1-\\beta$$\nWhen $\\mu = \\mu_A$, the quantity $\\frac{\\bar{X}-\\mu_A}{\\sigma/\\sqrt{n}}$ follows a standard normal distribution. We can express the rejection condition in terms of $\\bar{X}$: reject $H_0$ if $\\bar{X}  -z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}$ or $\\bar{X}  z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}$.\nThe power is the sum of the probabilities of these two disjoint events, conditioned on $\\mu = \\mu_A$:\n$$\\text{Power} = P\\left(\\bar{X}  -z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\bigg| \\mu=\\mu_A\\right) + P\\left(\\bar{X}  z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\bigg| \\mu=\\mu_A\\right)$$\nStandardizing these expressions by subtracting $\\mu_A$ and dividing by $\\sigma/\\sqrt{n}$, we get:\n$$\\text{Power} = P\\left(Z'  \\frac{-z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} - \\mu_A}{\\sigma/\\sqrt{n}}\\right) + P\\left(Z'  \\frac{z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} - \\mu_A}{\\sigma/\\sqrt{n}}\\right)$$\nwhere $Z'$ is a standard normal random variable. Substituting $\\mu_A = -\\delta$:\n$$\\text{Power} = P\\left(Z'  -z_{1-\\alpha/2} + \\frac{\\delta\\sqrt{n}}{\\sigma}\\right) + P\\left(Z'  z_{1-\\alpha/2} + \\frac{\\delta\\sqrt{n}}{\\sigma}\\right)$$\nFor a meaningful study design, the alternative mean is sufficiently far from the null mean. As we are detecting a negative change ($\\mu_A  0$), the primary contribution to power comes from the left tail of the rejection region. The second term, corresponding to rejecting in the upper tail when the true mean is negative, is typically negligible. Thus, we can approximate the power by the first term:\n$$1-\\beta \\approx P\\left(Z'  -z_{1-\\alpha/2} + \\frac{\\delta\\sqrt{n}}{\\sigma}\\right)$$\nFor this probability to equal $1-\\beta$, the argument of the cumulative distribution function must be equal to the corresponding quantile, $z_{1-\\beta}$.\n$$-z_{1-\\alpha/2} + \\frac{\\delta\\sqrt{n}}{\\sigma} \\approx z_{1-\\beta}$$\nSolving for $\\sqrt{n}$:\n$$\\frac{\\delta\\sqrt{n}}{\\sigma} \\approx z_{1-\\alpha/2} + z_{1-\\beta}$$\n$$\\sqrt{n} \\approx \\frac{\\sigma(z_{1-\\alpha/2} + z_{1-\\beta})}{\\delta}$$\nSquaring both sides gives the formula for the required sample size:\n$$n = \\frac{\\sigma^2 (z_{1-\\alpha/2} + z_{1-\\beta})^2}{\\delta^2}$$\nNow, we substitute the given values.\nFirst, we find the required quantiles (Z-scores) from the standard normal distribution:\n- For a two-sided $\\alpha = 0.05$, we need $z_{1-\\alpha/2} = z_{1-0.025} = z_{0.975}$. The value is approximately $1.95996$.\n- For a power of $1-\\beta = 0.90$, we need $z_{1-\\beta} = z_{0.90}$. The value is approximately $1.28155$.\n\nNow, we substitute these values along with $\\sigma=5$ and $\\delta=2$ into the sample size formula:\n$$n = \\frac{5^2 (1.95996 + 1.28155)^2}{2^2}$$\n$$n = \\frac{25 \\times (3.24151)^2}{4}$$\n$$n = \\frac{25 \\times 10.507398}{4}$$\n$$n = \\frac{262.68495}{4}$$\n$$n \\approx 65.6712$$\nSince the sample size $n$ must be a whole number of participants, we must take the next largest integer to ensure the power is at least $0.90$.\n$$n_{min} = \\lceil 65.6712 \\rceil = 66$$\nThe minimal whole-number sample size required is $66$. The problem finally instructs to round this answer to $4$ significant figures. A whole number such as $66$ has two significant figures. To express it with four significant figures, we add trailing zeros after the decimal point.\nFinal answer formatted to 4 significant figures: $66.00$.", "answer": "$$\\boxed{66.00}$$", "id": "4579227"}, {"introduction": "A calculated sample size represents the number of participants needed for the final analysis, not the number to enroll at the start. This practical exercise [@problem_id:4579232] addresses the real-world challenge of participant attrition, or loss to follow-up. You will learn how to adjust an initial sample size estimate to account for expected drop-outs, ensuring your study remains adequately powered through to its conclusion.", "problem": "A preventive medicine team is designing a two-arm community-based randomized controlled trial (RCT) to evaluate the effect of a mailed colorectal cancer screening kit on screening completion within six months. The primary outcome is binary (completion vs. non-completion), and the unadjusted sample size calculation—based on standard large-sample approximations for comparing proportions—indicates that $300$ participants per arm are required to achieve the desired statistical power at a fixed Type I error rate. However, due to anticipated loss to follow-up and withdrawal, the team expects an attrition proportion of $0.15$ in each arm.\n\nAssume that statistical power depends on the number of analyzable participants and that attrition is independent of treatment assignment and outcome. The team wishes to plan the initial enrollment per arm so that the expected number of analyzable participants per arm equals the unadjusted requirement.\n\nUsing only these assumptions and the definition that the expected retained proportion is $1 - a$ for attrition proportion $a$, compute the final planned number of participants per arm to enroll. Because participant counts are discrete, report the final planned count as the smallest integer not less than the computed value (the ceiling). Provide your answer as a single integer count of participants per arm. No additional rounding beyond this integer constraint is required.", "solution": "The problem statement is evaluated as valid. It is scientifically grounded in the principles of biostatistics and clinical trial design, specifically concerning sample size adjustments for participant attrition. The problem is well-posed, providing all necessary data and a clear objective. The language is precise and objective, and the assumptions are explicitly stated.\n\nLet $N_{unadj}$ represent the unadjusted sample size required per arm to achieve the desired statistical power. This is the target number of participants who must complete the study and be included in the final analysis. From the problem statement, we are given:\n$$ N_{unadj} = 300 $$\n\nLet $a$ be the proportion of participants expected to be lost to follow-up or withdrawal (attrition). The problem provides this value as:\n$$ a = 0.15 $$\n\nThe proportion of participants who are expected to be retained and provide analyzable data is therefore $1 - a$.\n\nLet $N_{initial}$ be the initial number of participants to be enrolled in each arm of the trial. The expected number of analyzable participants per arm, which we can denote as $E[N_{final}]$, is the initial number of enrolled participants multiplied by the expected retention proportion. This relationship is expressed as:\n$$ E[N_{final}] = N_{initial} \\times (1 - a) $$\n\nThe core requirement of the problem is to determine the initial enrollment, $N_{initial}$, such that the expected number of analyzable participants equals the unadjusted sample size requirement, $N_{unadj}$. We can set up the following equality:\n$$ E[N_{final}] = N_{unadj} $$\n\nSubstituting the expression for $E[N_{final}]$, we get:\n$$ N_{initial} \\times (1 - a) = N_{unadj} $$\n\nTo find the required initial number of participants, we can solve this equation for $N_{initial}$:\n$$ N_{initial} = \\frac{N_{unadj}}{1 - a} $$\n\nNow, we substitute the given numerical values into this formula:\n$$ N_{initial} = \\frac{300}{1 - 0.15} $$\n$$ N_{initial} = \\frac{300}{0.85} $$\n\nPerforming the division:\n$$ N_{initial} \\approx 352.941176... $$\n\nThe number of participants must be a whole number, as it represents a count of individuals. The problem specifies that the final planned count should be reported as the smallest integer not less than the computed value. This mathematical operation is the ceiling function, denoted by $\\lceil \\cdot \\rceil$. Therefore, the final planned number of participants per arm, $N_{planned}$, is:\n$$ N_{planned} = \\lceil N_{initial} \\rceil = \\lceil 352.941176... \\rceil $$\n$$ N_{planned} = 353 $$\n\nTo ensure that the expected number of analyzable participants is at least $300$, the team must enroll $353$ individuals in each arm of the trial.", "answer": "$$\\boxed{353}$$", "id": "4579232"}, {"introduction": "Translational research often involves complex endpoints, such as event counts, that do not follow a simple normal distribution. This advanced practice [@problem_id:5059803] moves beyond closed-form equations to a computational approach for designing a study with an over-dispersed count outcome, a common scenario in fields like immunology or oncology. You will develop a method to ensure robust power even when key model parameters, like the degree of over-dispersion, are not known with certainty.", "problem": "A two-arm randomized translational medicine study will compare event count endpoints between a control arm and an intervention arm. Event counts per participant are known to be over-dispersed relative to the Poisson model. Assume that each participant’s count is modeled with a Negative Binomial distribution (NB) characterized by a mean $\\,\\mu\\,$ and an over-dispersion parameter $\\,k\\,$, such that the variance satisfies $\\,\\mathrm{Var}(Y)=\\mu+\\mu^2/k\\,$. Let the control arm mean be $\\,\\mu_c\\,$ and the intervention arm mean be $\\,\\mu_t=r\\mu_c\\,$ for a specified rate ratio $\\,r\\,$, with equal allocation of $\\,n\\,$ participants per arm.\n\nYou must design a program to calibrate the per-arm sample size $\\,n\\,$ such that, for a two-sided test of the equality of arm means at significance level $\\,\\alpha\\,$, the minimum statistical power (expressed as a decimal, not with a percentage sign) across a plausible range of the over-dispersion parameter $\\,k\\,$ meets or exceeds a specified target. The plausible range of $\\,k\\,$ is defined by a log-normal distribution for $\\,k\\,$, where $\\,\\log k\\,$ is normally distributed with mean $\\,\\mu_{\\log k}\\,$ and standard deviation $\\,\\sigma_{\\log k}\\,$. Instead of sampling $\\,k\\,$ randomly, you must evaluate power over a grid of $\\,k\\,$ values spanning the interval between two quantiles $\\,q_{\\mathrm{low}}\\,$ and $\\,q_{\\mathrm{high}}\\,$ of the log-normal distribution for $\\,k\\,$, using a specified number of grid points. Across that grid, compute the minimum power; the calibrated sample size $\\,n\\,$ is the smallest integer within a provided search interval that achieves at least the target minimum power.\n\nBase your test construction on fundamental large-sample principles: use the Central Limit Theorem (CLT) and the NB variance property to justify a two-sample Wald-type test for the difference of arm means without relying on software-specific NB regression fits. Do not use shortcut sample size formulas; demonstrate the computation of power from first principles and numerical evaluation.\n\nYour program must implement the following logic for each test case:\n- Construct an evenly spaced grid of quantile levels between $\\,q_{\\mathrm{low}}\\,$ and $\\,q_{\\mathrm{high}}\\,$. Map each quantile level to a $\\,k\\,$ value using the log-normal distribution specified by $\\,\\mu_{\\log k}\\,$ and $\\,\\sigma_{\\log k}\\,$.\n- For a candidate per-arm sample size $\\,n\\,$, compute the power at each $\\,k\\,$ grid value using a two-sided Wald-type test for $\\,H_0:\\mu_t=\\mu_c\\,$ vs. $\\,H_1:\\mu_t\\neq\\mu_c\\,$, with significance level $\\,\\alpha\\,$. Use the CLT with the NB variance to justify the distribution of the test statistic under the alternative $\\,\\mu_t=r\\mu_c\\,$. Aggregate the powers across the $\\,k\\,$ grid by taking the minimum.\n- Increase $\\,n\\,$ within a specified integer search interval until the minimum power across the $\\,k\\,$ grid meets or exceeds the target. Report the smallest such $\\,n\\,$. If no $\\,n\\,$ in the interval meets the target, report the upper bound of the interval.\n\nAll outputs must be unitless numbers. Express powers as decimals, not percentages.\n\nTest suite:\nProvide solutions for the following four test cases. In each case, the output must be the calibrated integer per-arm sample size $\\,n\\,$.\n1. Case A (general case): $\\,\\mu_c=1.5\\,$, $\\,r=0.7\\,$, $\\,\\alpha=0.05\\,$, target minimum power $\\,=0.8\\,$, log-normal parameters $\\,\\mu_{\\log k}=\\log(2.0)\\,$ and $\\,\\sigma_{\\log k}=0.5\\,$, quantile interval $\\,q_{\\mathrm{low}}=0.1\\,$ and $\\,q_{\\mathrm{high}}=0.9\\,$, grid points $\\,=7\\,$, search interval $\\,n\\in\\{20,21,\\dots,150\\}\\,$.\n2. Case B (high over-dispersion stress): $\\,\\mu_c=1.5\\,$, $\\,r=0.7\\,$, $\\,\\alpha=0.05\\,$, target minimum power $\\,=0.8\\,$, log-normal parameters $\\,\\mu_{\\log k}=\\log(0.6)\\,$ and $\\,\\sigma_{\\log k}=0.6\\,$, quantile interval $\\,q_{\\mathrm{low}}=0.1\\,$ and $\\,q_{\\mathrm{high}}=0.9\\,$, grid points $\\,=7\\,$, search interval $\\,n\\in\\{20,21,\\dots,150\\}\\,$.\n3. Case C (low over-dispersion stress): $\\,\\mu_c=1.5\\,$, $\\,r=0.7\\,$, $\\,\\alpha=0.05\\,$, target minimum power $\\,=0.8\\,$, log-normal parameters $\\,\\mu_{\\log k}=\\log(8.0)\\,$ and $\\,\\sigma_{\\log k}=0.4\\,$, quantile interval $\\,q_{\\mathrm{low}}=0.1\\,$ and $\\,q_{\\mathrm{high}}=0.9\\,$, grid points $\\,=7\\,$, search interval $\\,n\\in\\{20,21,\\dots,150\\}\\,$.\n4. Case D (smaller effect size): $\\,\\mu_c=1.0\\,$, $\\,r=0.8\\,$, $\\,\\alpha=0.05\\,$, target minimum power $\\,=0.75\\,$, log-normal parameters $\\,\\mu_{\\log k}=\\log(1.5)\\,$ and $\\,\\sigma_{\\log k}=0.5\\,$, quantile interval $\\,q_{\\mathrm{low}}=0.1\\,$ and $\\,q_{\\mathrm{high}}=0.9\\,$, grid points $\\,=7\\,$, search interval $\\,n\\in\\{20,21,\\dots,150\\}\\,$.\n\nFinal output format:\nYour program should produce a single line of output containing the calibrated per-arm sample sizes for the four cases as a comma-separated list enclosed in square brackets, for example \"[$a_1$,$a_2$,$a_3$,$a_4$]\". The actual outputs must be integers corresponding to the calibrated $\\,n\\,$ values for the four cases in the order listed above.", "solution": "The problem statement has been rigorously validated and is determined to be valid. It is scientifically grounded, well-posed, objective, and internally consistent, presenting a formal biostatistical sample size calculation problem. All necessary parameters are provided for each test case.\n\nThe solution will be developed by adhering to the specified first-principles approach. The process involves deriving the power of a two-sample Wald-type test for the difference of Negative Binomial means, handling the uncertainty in the over-dispersion parameter $\\,k\\,$ by ensuring a minimum power across a plausible range of its values, and implementing a numerical search to find the required sample size $\\,n\\,$.\n\n### 1. Statistical Model and Hypotheses\n\nLet $\\,Y_{ci} \\sim \\mathrm{NB}(\\mu_c, k)\\,$ for $\\,i=1, \\dots, n\\,$ be the event counts for $\\,n\\,$ participants in the control arm, and $\\,Y_{ti} \\sim \\mathrm{NB}(\\mu_t, k)\\,$ for $\\,i=1, \\dots, n\\,$ be the counts for $\\,n\\,$ participants in the treatment arm. The Negative Binomial (NB) distribution is parameterized by its mean $\\,\\mu\\,$ and a common over-dispersion parameter $\\,k\\,$. The means for the two arms are $\\,E[Y_{ci}] = \\mu_c\\,$ and $\\,E[Y_{ti}] = \\mu_t = r\\mu_c\\,$. The variance is given by $\\,\\mathrm{Var}(Y) = \\mu + \\mu^2/k\\,$.\n\nThe variances for an individual observation in each arm are:\n$$ \\sigma_c^2 = \\mathrm{Var}(Y_{ci}) = \\mu_c + \\frac{\\mu_c^2}{k} $$\n$$ \\sigma_t^2 = \\mathrm{Var}(Y_{ti}) = \\mu_t + \\frac{\\mu_t^2}{k} $$\n\nThe null and alternative hypotheses for the two-sided test of mean equality are:\n$$ H_0: \\mu_t = \\mu_c \\quad (\\text{or } \\mu_t - \\mu_c = 0) $$\n$$ H_1: \\mu_t \\neq \\mu_c \\quad (\\text{or } \\mu_t - \\mu_c \\neq 0) $$\n\n### 2. Large-Sample Test Statistic and Power Calculation\n\nLet $\\,\\bar{Y}_c = \\frac{1}{n}\\sum_{i=1}^n Y_{ci}\\,$ and $\\,\\bar{Y}_t = \\frac{1}{n}\\sum_{i=1}^n Y_{ti}\\,$ be the sample means for the control and treatment arms, respectively. By the Central Limit Theorem (CLT), for a sufficiently large sample size $\\,n\\,$, the distributions of the sample means are approximately normal:\n$$ \\bar{Y}_c \\dot\\sim N\\left(\\mu_c, \\frac{\\sigma_c^2}{n}\\right) $$\n$$ \\bar{Y}_t \\dot\\sim N\\left(\\mu_t, \\frac{\\sigma_t^2}{n}\\right) $$\n\nThe test is based on the difference in sample means, $\\,D = \\bar{Y}_t - \\bar{Y}_c\\,$. Its distribution is also approximately normal:\n$$ D \\dot\\sim N\\left(\\mu_t - \\mu_c, \\frac{\\sigma_t^2 + \\sigma_c^2}{n}\\right) $$\nLet $\\,\\mu_d = \\mu_t - \\mu_c\\,$ be the true difference in means and $\\,\\sigma_D^2 = \\frac{\\sigma_t^2 + \\sigma_c^2}{n}\\,$ be the variance of the difference.\n\nA Wald-type test statistic is given by $\\,Z = \\frac{\\bar{Y}_t - \\bar{Y}_c}{\\widehat{SE}_D}\\,$, where $\\,\\widehat{SE}_D\\,$ is the estimated standard error of the difference. For large samples, we can approximate the distribution of this statistic for power calculation purposes by replacing the estimated standard error with the true standard error under the alternative hypothesis, $\\,\\sigma_D = \\sqrt{\\sigma_D^2}\\,$.\n\nAt a significance level $\\,\\alpha\\,$, we reject $\\,H_0\\,$ if $\\,|\\frac{D}{\\sigma_D}|  z_{1-\\alpha/2}\\,$, where $\\,z_{q}\\,$ is the $\\,q\\,$-quantile of the standard normal distribution. Note that this is a slight simplification; the test statistic would use an estimated variance, but for large-sample power analysis, using the true variance under $\\,H_1\\,$ is standard practice.\n\nThe statistical power is the probability of rejecting $\\,H_0\\,$ given that $\\,H_1\\,$ is true.\n$$ \\text{Power} = P\\left(\\frac{D}{\\sigma_D}  -z_{1-\\alpha/2} \\mid H_1\\right) + P\\left(\\frac{D}{\\sigma_D}  z_{1-\\alpha/2} \\mid H_1\\right) $$\nTo evaluate these probabilities, we standardize $\\,D\\,$ under $\\,H_1\\,$:\n$$ \\frac{D - \\mu_d}{\\sigma_D} \\sim N(0, 1) $$\nSubstituting $\\,D = Z_{std}\\sigma_D + \\mu_d\\,$ where $\\,Z_{std} \\sim N(0, 1)\\,$:\n$$ \\text{Power} = P\\left(\\frac{Z_{std}\\sigma_D + \\mu_d}{\\sigma_D}  -z_{1-\\alpha/2}\\right) + P\\left(\\frac{Z_{std}\\sigma_D + \\mu_d}{\\sigma_D}  z_{1-\\alpha/2}\\right) $$\n$$ \\text{Power} = P\\left(Z_{std}  -z_{1-\\alpha/2} - \\frac{\\mu_d}{\\sigma_D}\\right) + P\\left(Z_{std}  z_{1-\\alpha/2} - \\frac{\\mu_d}{\\sigma_D}\\right) $$\nUsing the cumulative distribution function (CDF) of the standard normal distribution, $\\,\\Phi(z) = P(Z_{std} \\le z)\\,$:\n$$ \\text{Power} = \\Phi\\left(-z_{1-\\alpha/2} - \\frac{\\mu_d}{\\sigma_D}\\right) + \\left[1 - \\Phi\\left(z_{1-\\alpha/2} - \\frac{\\mu_d}{\\sigma_D}\\right)\\right] $$\nThis is the core formula for calculating power for a given set of parameters $\\,(\\mu_c, r, k, n, \\alpha)\\,$.\n\n### 3. Nuisance Parameter Grid Construction\n\nThe over-dispersion parameter $\\,k\\,$ is a nuisance parameter whose exact value is unknown. The problem specifies modeling this uncertainty by assuming $\\,\\log k\\,$ follows a normal distribution, $\\,\\log k \\sim N(\\mu_{\\log k}, \\sigma_{\\log k}^2)\\,$. Power must be guaranteed over a plausible range of $\\,k\\,$ values derived from this distribution.\n\nThe algorithm to construct the grid of $\\,k\\,$ values is:\n1.  Define an evenly spaced grid of $\\,m\\,$ quantile levels $\\,q_j\\,$ from $\\,q_{\\mathrm{low}}\\,$ to $\\,q_{\\mathrm{high}}$.\n2.  For each $\\,q_j\\,$, compute the corresponding quantile of the standard normal distribution, $\\,z_{q_j} = \\Phi^{-1}(q_j)\\,$.\n3.  Transform these $\\,z\\,$-scores to quantiles of the $\\,\\log k\\,$ distribution: $\\,(\\log k)_j = \\mu_{\\log k} + z_{q_j}\\sigma_{\\log k}\\,$.\n4.  Exponentiate to obtain the grid of $\\,k\\,$ values: $\\,k_j = \\exp((\\log k)_j) = \\exp(\\mu_{\\log k} + z_{q_j}\\sigma_{\\log k})\\,$.\n\nAs variance is inversely related to $\\,k\\,$, statistical power will be lowest at the smallest value of $\\,k\\,$ in the grid. The problem requires computing the power at each $\\,k_j\\,$ and taking the minimum to ensure robustness.\n\n### 4. Sample Size Calibration Algorithm\n\nThe final step is to find the smallest integer sample size $\\,n\\,$ per arm within a specified search interval $\\,[n_{\\min}, n_{\\max}]\\,$ that achieves the target minimum power.\n\nThe complete computational procedure is as follows:\n1.  For a given test case, establish all parameters: $\\,\\mu_c, r, \\alpha\\,$, target power, $\\,\\mu_{\\log k}, \\sigma_{\\log k}, q_{\\mathrm{low}}, q_{\\mathrm{high}}\\,$, number of grid points, and the search interval for $\\,n\\,$.\n2.  Construct the grid of $\\,k\\,$ values as described in Section 3.\n3.  Determine the critical value $\\,z_{1-\\alpha/2}\\,$ from the standard normal distribution.\n4.  Iterate through candidate sample sizes $\\,n=n_{\\min}, n_{\\min}+1, \\dots, n_{\\max}\\,$.\n5.  For each $\\,n\\,$:\n    a. Initialize an empty list to store power values.\n    b. For each value $\\,k_j\\,$ in the grid:\n        i.  Calculate arm means $\\,\\mu_c\\,$ and $\\,\\mu_t = r\\mu_c\\,$.\n        ii. Calculate arm variances $\\,\\sigma_c^2 = \\mu_c + \\mu_c^2/k_j\\,$ and $\\,\\sigma_t^2 = \\mu_t + \\mu_t^2/k_j\\,$.\n        iii. Calculate the difference in means $\\,\\mu_d = \\mu_t - \\mu_c\\,$.\n        iv. Calculate the standard error of the difference $\\,\\sigma_D = \\sqrt{(\\sigma_c^2 + \\sigma_t^2)/n}\\,$.\n        v.  Compute the power using the formula from Section 2.\n        vi. Append the computed power to the list.\n    c. Find the minimum power, $\\,\\text{power}_{\\min}\\,$ in the list.\n    d. If $\\,\\text{power}_{\\min} \\ge \\text{target power}\\,$, then the current $\\,n\\,$ is the required sample size. Return $\\,n\\,$ and terminate the search for this test case.\n6.  If the loop completes without meeting the power target, return $\\,n_{\\max}\\,$ as per the problem specification.\nThis procedure will be implemented for each of the four test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef calculate_sample_size(\n    mu_c, r, alpha, target_power, mu_log_k, sigma_log_k, \n    q_low, q_high, grid_points, n_search_interval\n):\n    \"\"\"\n    Calculates the per-arm sample size n for a two-arm study with NB-distributed counts.\n\n    The function determines the smallest integer n in a search interval that achieves a target\n    minimum power across a grid of plausible over-dispersion parameter (k) values.\n    \"\"\"\n    # Step 1: Construct the grid of k values from its log-normal distribution.\n    # The grid spans from the q_low to q_high quantiles.\n    quantile_levels = np.linspace(q_low, q_high, grid_points)\n    z_quantiles = norm.ppf(quantile_levels)\n    log_k_values = mu_log_k + z_quantiles * sigma_log_k\n    k_grid = np.exp(log_k_values)\n    \n    # Step 2: Set up constants for the power calculation.\n    n_min, n_max = n_search_interval\n    # Two-sided test critical value from the standard normal distribution.\n    z_critical = norm.ppf(1 - alpha / 2.0)\n    mu_t = r * mu_c\n    mu_diff = mu_t - mu_c\n\n    # Step 3: Iterate through the sample size search interval.\n    for n in range(n_min, n_max + 1):\n        powers_at_n = []\n        # Step 4: For each candidate n, calculate power for each k in the grid.\n        for k in k_grid:\n            if k = 0: # Over-dispersion k must be positive.\n                continue\n            \n            # Variance for each arm, based on the NB model Var(Y) = mu + mu^2/k\n            var_c = mu_c + mu_c**2 / k\n            var_t = mu_t + mu_t**2 / k\n            \n            # Standard error of the difference in sample means\n            se_diff = np.sqrt((var_c + var_t) / n)\n            \n            # If standard error is zero (no variance), power is 1 if means differ.\n            if se_diff == 0:\n                power = 1.0 if mu_diff != 0 else 0.0\n                powers_at_n.append(power)\n                continue\n\n            # Core power formula for a two-sample Z-test\n            # Power = P(Z  -z_crit - mu_d/se_d) + P(Z  z_crit - mu_d/se_d)\n            # where Z ~ N(0,1)\n            arg1 = z_critical - mu_diff / se_diff\n            arg2 = -z_critical - mu_diff / se_diff\n            \n            power = norm.cdf(arg2) + (1.0 - norm.cdf(arg1))\n            powers_at_n.append(power)\n            \n        # Step 5: Check if the minimum power across the k-grid meets the target.\n        if powers_at_n:\n            min_power = min(powers_at_n)\n            if min_power = target_power:\n                return n\n    \n    # Step 6: If no n in the interval meets the target, return the upper bound.\n    return n_max\n\ndef solve():\n    \"\"\"\n    Defines and runs the test cases specified in the problem statement.\n    \"\"\"\n    test_cases = [\n        # Case A: General case\n        {'mu_c': 1.5, 'r': 0.7, 'alpha': 0.05, 'target_power': 0.8,\n         'mu_log_k': np.log(2.0), 'sigma_log_k': 0.5, 'q_low': 0.1, 'q_high': 0.9,\n         'grid_points': 7, 'n_search_interval': (20, 150)},\n        \n        # Case B: High over-dispersion stress (low k)\n        {'mu_c': 1.5, 'r': 0.7, 'alpha': 0.05, 'target_power': 0.8,\n         'mu_log_k': np.log(0.6), 'sigma_log_k': 0.6, 'q_low': 0.1, 'q_high': 0.9,\n         'grid_points': 7, 'n_search_interval': (20, 150)},\n\n        # Case C: Low over-dispersion stress (high k)\n        {'mu_c': 1.5, 'r': 0.7, 'alpha': 0.05, 'target_power': 0.8,\n         'mu_log_k': np.log(8.0), 'sigma_log_k': 0.4, 'q_low': 0.1, 'q_high': 0.9,\n         'grid_points': 7, 'n_search_interval': (20, 150)},\n\n        # Case D: Smaller effect size\n        {'mu_c': 1.0, 'r': 0.8, 'alpha': 0.05, 'target_power': 0.75,\n         'mu_log_k': np.log(1.5), 'sigma_log_k': 0.5, 'q_low': 0.1, 'q_high': 0.9,\n         'grid_points': 7, 'n_search_interval': (20, 150)},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_sample_size(**case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "5059803"}]}