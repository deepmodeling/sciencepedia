{"hands_on_practices": [{"introduction": "Agent-based models are powerful tools for understanding how individual cell behaviors give rise to tissue-level properties. A fundamental aspect of this behavior is phenotypic plasticity, where cells stochastically switch between different functional states. This practice explores the simplest model of such dynamics: a two-state Continuous-Time Markov Chain, which serves as a foundational building block for more complex models of cell differentiation and heterogeneity. By deriving the stationary distribution, you will see how microscopic transition rates ($k_{12}$, $k_{21}$) directly determine the macroscopic equilibrium composition of a cell population. [@problem_id:4314010]", "problem": "Consider an agent-based model for a well-mixed population of cells in a homogeneous tissue microenvironment in which each cell independently switches between two phenotypic states, denoted by $S_{1}$ and $S_{2}$. The switching dynamics are continuous in time and memoryless, and the transitions are characterized by constant rates: a cell in state $S_{1}$ switches to state $S_{2}$ with rate $k_{12}  0$, and a cell in state $S_{2}$ switches to state $S_{1}$ with rate $k_{21}  0$. Assume that, on the timescale of interest, birth and death are negligible and the microenvironmental signals are stationary, so that the rates $k_{12}$ and $k_{21}$ do not depend on time or the number of cells.\n\nModel each cell’s phenotypic trajectory as a Continuous-Time Markov Chain (CTMC) with state space $\\{S_{1}, S_{2}\\}$ and the above transition rates. Let $p_{1}(t)$ and $p_{2}(t)$ denote the probabilities that a randomly chosen cell is in state $S_{1}$ or $S_{2}$ at time $t$, respectively, with $p_{1}(t) + p_{2}(t) = 1$ for all $t \\geq 0$. Define the stationary distribution $(\\pi_{1}, \\pi_{2})$ as the time-independent limit of $(p_{1}(t), p_{2}(t))$ as $t \\to \\infty$, assuming the chain is ergodic.\n\nStarting from the fundamental definitions of CTMC dynamics and conservation of probability, derive the stationary distribution $(\\pi_{1}, \\pi_{2})$ in closed form in terms of $k_{12}$ and $k_{21}$. Then, using your result, reason about how the ratio $r = k_{12}/k_{21}$ biologically controls the long-term fraction of cells in $S_{2}$ relative to $S_{1}$ under this agent-based model. Express your final answer as the ordered pair $(\\pi_{1}, \\pi_{2})$ in closed form. No numerical values are required, and no rounding is necessary. The final quantities are dimensionless probabilities, so no units should be reported.", "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- **Model:** An agent-based model for a well-mixed cell population in a homogeneous tissue microenvironment.\n- **States:** Two phenotypic states, $S_{1}$ and $S_{2}$.\n- **Dynamics:** Continuous-Time Markov Chain (CTMC) for each cell, continuous in time and memoryless.\n- **Transition Rates:** Constant rates.\n  - From $S_{1}$ to $S_{2}$: rate $k_{12}  0$.\n  - From $S_{2}$ to $S_{1}$: rate $k_{21}  0$.\n- **Assumptions:** Birth and death are negligible on the timescale of interest; microenvironmental signals are stationary.\n- **Probabilities:** $p_{1}(t)$ and $p_{2}(t)$ are the probabilities of a cell being in state $S_{1}$ or $S_{2}$ at time $t$.\n- **Constraint:** Conservation of probability, $p_{1}(t) + p_{2}(t) = 1$ for all $t \\geq 0$.\n- **Stationary Distribution:** $(\\pi_{1}, \\pi_{2})$ is the limit of $(p_{1}(t), p_{2}(t))$ as $t \\to \\infty$.\n- **Ergodicity:** The chain is assumed to be ergodic.\n- **Objective 1:** Derive the stationary distribution $(\\pi_{1}, \\pi_{2})$ in closed form in terms of $k_{12}$ and $k_{21}$.\n- **Objective 2:** Interpret how the ratio $r = k_{12}/k_{21}$ controls the long-term fraction of cells in $S_{2}$ relative to $S_{1}$.\n- **Final Answer Format:** The ordered pair $(\\pi_{1}, \\pi_{2})$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes a classic two-state Continuous-Time Markov Chain. This is a fundamental and widely used model in systems biology, physics, and chemistry to describe stochastic transitions between discrete states.\n\n1.  **Scientifically Grounded:** The problem is firmly grounded in the established mathematical theory of stochastic processes (specifically, CTMCs) and its application to biological systems (cell phenotype switching). This is a standard approach in systems biomedicine.\n2.  **Well-Posed:** The problem is well-posed. The a priori conditions $k_{12}  0$ and $k_{21}  0$ ensure that the CTMC is irreducible (all states are reachable from all other states). For a finite-state, irreducible CTMC, a unique stationary distribution is guaranteed to exist.\n3.  **Objective:** The language is formal, precise, and objective, using well-defined mathematical terms.\n4.  **Completeness:** The problem provides all necessary information (the two transition rates) and constraints (conservation of probability, definition of stationarity) to uniquely determine the solution.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a standard, self-contained, and well-posed problem in mathematical biology. Proceeding with the solution.\n\nThe dynamics of the probabilities $p_{1}(t)$ and $p_{2}(t)$ for a cell to be in state $S_{1}$ or $S_{2}$ are described by the forward Kolmogorov equations, also known as the master equation for the system. The rate of change of probability for a given state is determined by the flux of probability into that state minus the flux of probability out of it.\n\nFor state $S_{1}$, the probability $p_{1}(t)$ increases due to cells switching from $S_{2}$ to $S_{1}$ (flux in) and decreases due to cells switching from $S_{1}$ to $S_{2}$ (flux out). The corresponding differential equation is:\n$$\n\\frac{dp_{1}(t)}{dt} = k_{21} p_{2}(t) - k_{12} p_{1}(t)\n$$\nSimilarly, for state $S_{2}$, the probability $p_{2}(t)$ increases due to cells switching from $S_{1}$ to $S_{2}$ and decreases due to cells switching from $S_{2}$ to $S_{1}$. The differential equation is:\n$$\n\\frac{dp_{2}(t)}{dt} = k_{12} p_{1}(t) - k_{21} p_{2}(t)\n$$\nThe stationary distribution $(\\pi_{1}, \\pi_{2})$ is defined as the time-independent solution to this system, where the probabilities no longer change with time. This occurs when the time derivatives are zero: $\\frac{dp_{1}(t)}{dt} = 0$ and $\\frac{dp_{2}(t)}{dt} = 0$. Replacing $p_{1}(t)$ with $\\pi_{1}$ and $p_{2}(t)$ with $\\pi_{2}$, we get the steady-state equations:\n$$\n0 = k_{21} \\pi_{2} - k_{12} \\pi_{1}\n$$\n$$\n0 = k_{12} \\pi_{1} - k_{21} \\pi_{2}\n$$\nBoth equations are linearly dependent and simplify to the same relationship, known as the detailed balance condition:\n$$\nk_{12} \\pi_{1} = k_{21} \\pi_{2}\n$$\nThis equation signifies that at equilibrium, the total probabilistic flux from state $S_{1}$ to $S_{2}$ is exactly equal to the total probabilistic flux from $S_{2}$ to $S_{1}$.\n\nTo find a unique solution for $\\pi_{1}$ and $\\pi_{2}$, we must use a second, independent equation. This is provided by the axiom of conservation of probability, which states that a cell must be in one of the possible states. At steady state, this becomes:\n$$\n\\pi_{1} + \\pi_{2} = 1\n$$\nWe now have a system of two linear equations with two unknowns:\n1.  $k_{12} \\pi_{1} = k_{21} \\pi_{2}$\n2.  $\\pi_{1} + \\pi_{2} = 1$\n\nFrom equation (1), we can express $\\pi_{1}$ in terms of $\\pi_{2}$:\n$$\n\\pi_{1} = \\frac{k_{21}}{k_{12}} \\pi_{2}\n$$\nSubstitute this expression for $\\pi_{1}$ into equation (2):\n$$\n\\left(\\frac{k_{21}}{k_{12}}\\right) \\pi_{2} + \\pi_{2} = 1\n$$\nFactor out $\\pi_{2}$:\n$$\n\\pi_{2} \\left(\\frac{k_{21}}{k_{12}} + 1\\right) = 1\n$$\n$$\n\\pi_{2} \\left(\\frac{k_{21} + k_{12}}{k_{12}}\\right) = 1\n$$\nSolving for $\\pi_{2}$ yields:\n$$\n\\pi_{2} = \\frac{k_{12}}{k_{12} + k_{21}}\n$$\nNow, we can find $\\pi_{1}$ using the conservation of probability, $\\pi_{1} = 1 - \\pi_{2}$:\n$$\n\\pi_{1} = 1 - \\frac{k_{12}}{k_{12} + k_{21}} = \\frac{(k_{12} + k_{21}) - k_{12}}{k_{12} + k_{21}} = \\frac{k_{21}}{k_{12} + k_{21}}\n$$\nThus, the stationary distribution is $(\\pi_{1}, \\pi_{2}) = \\left(\\frac{k_{21}}{k_{12} + k_{21}}, \\frac{k_{12}}{k_{12} + k_{21}}\\right)$.\n\nNext, we analyze how the ratio $r = k_{12}/k_{21}$ controls the long-term fraction of cells in $S_{2}$ relative to $S_{1}$. The long-term fraction of cells in each state corresponds to the stationary probabilities $\\pi_{1}$ and $\\pi_{2}$. Let's examine the ratio of these probabilities:\n$$\n\\frac{\\pi_{2}}{\\pi_{1}} = \\frac{\\frac{k_{12}}{k_{12} + k_{21}}}{\\frac{k_{21}}{k_{12} + k_{21}}} = \\frac{k_{12}}{k_{21}}\n$$\nSince the problem defines $r = k_{12}/k_{21}$, we have the direct relationship:\n$$\n\\frac{\\pi_{2}}{\\pi_{1}} = r\n$$\nThis result provides a clear biological interpretation. The ratio $r$ represents the relative propensity for a cell to switch into state $S_{2}$ compared to switching out of it.\n- If $r  1$, then $k_{12}  k_{21}$. The rate of transition towards $S_{2}$ is greater than the rate of transition back to $S_{1}$. This implies that $\\pi_{2}  \\pi_{1}$, and the population at equilibrium will be dominated by cells in the $S_{2}$ phenotype.\n- If $r  1$, then $k_{12}  k_{21}$. The rate of transition away from $S_{2}$ is greater than the rate towards it. This implies that $\\pi_{2}  \\pi_{1}$, and the population at equilibrium will be dominated by cells in the $S_{1}$ phenotype.\n- If $r = 1$, then $k_{12} = k_{21}$. The transition rates are equal in both directions. This implies that $\\pi_{2} = \\pi_{1}$, and since they must sum to $1$, $\\pi_1 = \\pi_2 = 0.5$. The cell population will be equally distributed between the two states in the long term.\n\nIn summary, the ratio of the transition rates, $r$, acts as a control parameter that directly sets the equilibrium ratio of the two phenotypic subpopulations.", "answer": "$$\n\\boxed{\\left( \\frac{k_{21}}{k_{12} + k_{21}}, \\frac{k_{12}}{k_{12} + k_{21}} \\right)}\n$$", "id": "4314010"}, {"introduction": "Beyond internal states, cells are physical entities that occupy space and exert forces on one another. This exercise challenges you to build a 2D off-lattice model, a common approach for simulating dense tissues where cell shape and packing are important. You will implement pairwise repulsive forces, handle periodic boundary conditions to simulate a bulk material, and use the virial theorem to connect microscopic interactions to the macroscopic concept of mechanical pressure. This hands-on coding task will equip you with the fundamental skills to simulate collective cell mechanics and quantify emergent properties of crowded cellular environments. [@problem_id:4313977]", "problem": "You are asked to implement a two-dimensional agent-based model of disk-like cells under Periodic Boundary Conditions (PBC) with central pairwise repulsion. Each cell is represented by a disk of radius $R$ and interacts with other cells via a repulsive, linear, distance-limited force specified by the positive-part operator. The interaction between two cells at separation distance $r$ is given by a central force of magnitude $F(r) = k \\left(1 - \\frac{r}{r_0}\\right)_+$, where $(x)_+ = \\max(x, 0)$ and $r_0 = 2R$ is the contact cutoff for identical disks. The vector force direction is along the line connecting the two cell centers. The system is athermal (no kinetic contributions).\n\nStarting from the fundamental definition of packing fraction as total nominal occupied area divided by system area, and from the two-dimensional Irving–Kirkwood virial route to mechanical pressure in the athermal limit for central pairwise forces, design and implement a program that:\n- Computes the packing fraction $\\phi$.\n- Computes the two-dimensional mechanical pressure $P$ using the virial expression specialized to pairwise central forces in two dimensions and evaluated under PBC with the minimum-image convention.\n- Computes crowding metrics that quantify local mechanical crowding:\n    1. The mean positive overlap fraction $\\overline{o}$ across unordered interacting pairs, defined by $o_{ij} = \\left(1 - \\frac{r_{ij}}{r_0}\\right)_+$ for $i  j$ and averaged only over pairs with $o_{ij}  0$. If there are no overlapping pairs, define $\\overline{o} = 0$.\n    2. The mean contact number per cell $\\overline{z}$, where a contact between cells $i$ and $j$ is counted if $r_{ij}  r_0$ using the minimum-image separation. The mean is taken over all cells.\n\nAll distances must be computed under Periodic Boundary Conditions using the minimum-image convention. The mechanical pressure $P$ must be reported in nanoNewton per micrometer, i.e., $\\mathrm{nN}/\\mu\\mathrm{m}$, the packing fraction $\\phi$ and the mean positive overlap fraction $\\overline{o}$ are dimensionless, and the mean contact number $\\overline{z}$ is a float representing the average number of contacts per cell. For clarity and standardization, report all floating-point outputs rounded to six decimal places.\n\nUse the following fixed test suite of four cases. In each case, the box is rectangular with side lengths $L_x$ and $L_y$ in micrometers $\\mu\\mathrm{m}$, the radius is $R$ in micrometers, and the force scale is $k$ in nanoNewtons $\\mathrm{nN}$. The cell centers are specified by coordinates $(x, y)$ in micrometers.\n\n- Case $1$ (low crowding; a few overlaps):\n    - $L_x = 50$, $L_y = 50$, $R = 2$, $k = 0.5$.\n    - Positions (in $\\mu\\mathrm{m}$): $(5, 5)$, $(8.6, 5)$, $(23, 5)$, $(32, 5)$, $(41, 5)$, $(5, 20)$, $(8.6, 20)$, $(23, 20)$, $(32, 20)$, $(41, 20)$.\n\n- Case $2$ (high crowding; dense grid):\n    - $L_x = 20$, $L_y = 20$, $R = 3$, $k = 1.0$.\n    - Positions (in $\\mu\\mathrm{m}$): $(2, 2)$, $(6, 2)$, $(10, 2)$, $(14, 2)$, $(2, 6)$, $(6, 6)$, $(10, 6)$, $(14, 6)$, $(2, 10)$, $(6, 10)$, $(10, 10)$, $(14, 10)$, $(2, 14)$, $(6, 14)$, $(10, 14)$, $(14, 14)$.\n\n- Case $3$ (boundary at cutoff; no force):\n    - $L_x = 30$, $L_y = 30$, $R = 5$, $k = 0.8$.\n    - Positions (in $\\mu\\mathrm{m}$): $(5, 5)$, $(15, 5)$, $(5, 15)$, $(15, 15)$.\n\n- Case $4$ (single cell; trivial crowding):\n    - $L_x = 40$, $L_y = 40$, $R = 7$, $k = 1.2$.\n    - Positions (in $\\mu\\mathrm{m}$): $(10, 10)$.\n\nYour program must:\n- Implement the minimum-image convention for PBC: for each pair of cells $i$ and $j$, compute $\\Delta x = x_j - x_i$ and $\\Delta y = y_j - y_i$, then map each component into the interval $[-\\frac{L}{2}, \\frac{L}{2})$ by subtracting $L$ times the nearest integer, where $L$ is $L_x$ for $\\Delta x$ and $L_y$ for $\\Delta y$.\n- From these minimum-image separations, compute the pair distance $r_{ij}$.\n- Use $r_0 = 2R$ uniformly for identical disks.\n\nFor each test case, return a list of four values $[\\phi, P, \\overline{o}, \\overline{z}]$, with $P$ in $\\mathrm{nN}/\\mu\\mathrm{m}$. The final program output must be a single line with a comma-separated list of these four-element lists enclosed in square brackets, for example, $[[\\phi_1, P_1, \\overline{o}_1, \\overline{z}_1],[\\phi_2, P_2, \\overline{o}_2, \\overline{z}_2],\\ldots]$, and each floating-point number must be rounded to six decimal places.", "solution": "The problem statement has been analyzed and is deemed valid. It is scientifically grounded in the principles of statistical mechanics and computational soft matter physics, well-posed with all necessary information provided, and objective in its formulation. We can therefore proceed with a solution.\n\nThe task is to compute four key metrics for a two-dimensional system of disk-like cells interacting via a repulsive force under periodic boundary conditions (PBC). The metrics are the packing fraction $\\phi$, the mechanical pressure $P$, the mean positive overlap fraction $\\overline{o}$, and the mean contact number per cell $\\overline{z}$.\n\n### 1. Fundamental Principles and Definitions\n\nThe model describes a system of $N$ identical disk-like cells, each with radius $R$, in a rectangular domain of size $L_x \\times L_y$. The total area of the system is $A = L_x L_y$. The cells interact through a central pairwise repulsive force given by:\n$$ F(r) = k \\left(1 - \\frac{r}{r_0}\\right)_+ $$\nwhere $r$ is the center-to-center separation distance, $k$ is the force spring constant, $r_0 = 2R$ is the contact cutoff distance, and $(x)_+ = \\max(x, 0)$ is the positive-part operator. This force is non-zero only when cells overlap, i.e., when $r  r_0$. The system is athermal, meaning there are no kinetic energy contributions to its properties.\n\nAll intercellular distances $r_{ij}$ between cells $i$ and $j$ must be calculated using the minimum-image convention (MIC) to correctly handle the periodic boundary conditions. For a displacement vector $\\Delta\\mathbf{r} = (\\Delta x, \\Delta y)$, the minimum image displacement $\\Delta\\mathbf{r}' = (\\Delta x', \\Delta y')$ is found by:\n$$ \\Delta x' = \\Delta x - L_x \\cdot \\text{round}\\left(\\frac{\\Delta x}{L_x}\\right) $$\n$$ \\Delta y' = \\Delta y - L_y \\cdot \\text{round}\\left(\\frac{\\Delta y}{L_y}\\right) $$\nThe distance is then $r_{ij} = \\sqrt{(\\Delta x')^2 + (\\Delta y')^2}$.\n\nBased on these principles, we define the required metrics:\n\n#### Packing Fraction ($\\phi$)\nThe packing fraction is the ratio of the total nominal area occupied by the cells to the total system area. The area of a single cell is $A_{cell} = \\pi R^2$. For $N$ cells, the total occupied area is $N A_{cell}$.\n$$ \\phi = \\frac{N \\pi R^2}{A} = \\frac{N \\pi R^2}{L_x L_y} $$\n\n#### Mechanical Pressure ($P$)\nThe mechanical pressure in a two-dimensional athermal system with central pairwise forces is derived from the virial theorem. The pressure tensor component from inter-particle forces is given by $\\frac{1}{A} \\sum_{ij} \\mathbf{r}_{ij} \\otimes \\mathbf{F}_{ij}$, where $\\mathbf{r}_{ij}$ is the minimum-image vector from cell $i$ to $j$ and $\\mathbf{F}_{ij}$ is the force exerted by $j$ on $i$. For a central force $\\mathbf{F}_{ij} = F(r_{ij}) \\frac{\\mathbf{r}_{ij}}{r_{ij}}$, the scalar pressure $P$ is half the trace of this tensor:\n$$ P = \\frac{1}{2A} \\sum_{ij} r_{ij} F(r_{ij}) $$\nSubstituting the given force law and summing only over interacting pairs (where $r_{ij}  r_0$), the expression becomes:\n$$ P = \\frac{1}{2 L_x L_y} \\sum_{ij, r_{ij}  r_0} k r_{ij} \\left(1 - \\frac{r_{ij}}{r_0}\\right) $$\n\n#### Mean Positive Overlap Fraction ($\\overline{o}$)\nThe overlap fraction for a pair of cells $(i, j)$ is defined as $o_{ij} = \\left(1 - \\frac{r_{ij}}{r_0}\\right)_+$. This quantity is positive only for interacting pairs ($r_{ij}  r_0$). The mean positive overlap fraction, $\\overline{o}$, is the average of these positive values over all such interacting pairs.\nLet $N_{overlap}$ be the number of unique pairs $(i,j)$ with $ij$ for which $r_{ij}  r_0$.\n$$ \\overline{o} = \\begin{cases} \\frac{1}{N_{overlap}} \\sum_{ij, r_{ij}  r_0} \\left(1 - \\frac{r_{ij}}{r_0}\\right)  \\text{if } N_{overlap}  0 \\\\ 0  \\text{if } N_{overlap} = 0 \\end{cases} $$\n\n#### Mean Contact Number ($\\overline{z}$)\nA contact between cells $i$ and $j$ exists if their separation $r_{ij}$ is less than the cutoff $r_0$. The contact number for a single cell $i$, denoted $z_i$, is the count of other cells $j$ for which this condition holds. The mean contact number $\\overline{z}$ is the average of $z_i$ over all $N$ cells.\n$$ z_i = \\sum_{j \\neq i, r_{ij}  r_0} 1 $$\n$$ \\overline{z} = \\frac{1}{N} \\sum_{i=1}^N z_i $$\nIf $N=0$, $\\overline{z}=0$. The sum $\\sum_{i=1}^N z_i$ is equal to twice the total number of interacting pairs.\n\n### 2. Algorithmic Implementation\n\nThe computation proceeds by systematically calculating these four metrics for each given test case.\n\n1.  **Initialization**: For each case, retrieve the parameters $L_x, L_y, R, k$ and the list of $N$ cell positions $\\mathbf{r}_i = (x_i, y_i)$. Initialize accumulators for the virial sum, the overlap sum, the count of overlapping pairs, and an array to store contact numbers for each cell.\n2.  **Packing Fraction**: Compute $\\phi$ directly from its definition. This is independent of pairwise interactions.\n3.  **Pairwise Interaction Loop**: Iterate through all unique pairs of cells $(i, j)$ with $i  j$. For each pair:\n    a.  Calculate the displacement vector $\\Delta\\mathbf{r} = \\mathbf{r}_j - \\mathbf{r}_i$.\n    b.  Apply the minimum-image convention to obtain the shortest separation vector $\\Delta\\mathbf{r}'$ and its magnitude, the distance $r_{ij}$.\n    c.  Check for interaction: if $r_{ij}  r_0 = 2R$.\n    d.  If an interaction exists:\n        i.  Calculate the force magnitude $F_{ij} = k(1 - r_{ij}/r_0)$ and its contribution to the virial, $r_{ij} F_{ij}$. Add this to the total virial sum.\n        ii. Calculate the overlap fraction $o_{ij} = 1 - r_{ij}/r_0$. Add this to the total overlap sum and increment the count of overlapping pairs.\n        iii. Increment the contact counters for both cell $i$ and cell $j$.\n4.  **Final Metric Calculation**: After iterating through all pairs:\n    a.  Calculate the pressure $P$ from the total virial sum and the system area $A$.\n    b.  Calculate the mean positive overlap $\\overline{o}$ by dividing the overlap sum by the overlap count. If the count is zero, $\\overline{o}$ is zero.\n    c.  Calculate the mean contact number $\\overline{z}$ by taking the average of the per-cell contact counters.\n5.  **Output Formatting**: Round each of the four computed floating-point values ($\\phi, P, \\overline{o}, \\overline{z}$) to six decimal places as required. Assemble the results into the specified list format.\n\nThis algorithm correctly implements the physical and mathematical definitions provided in the problem statement, ensuring a robust and accurate solution. Special cases, such as a single cell or no interacting pairs, are handled naturally by the logic. For a single cell ($N=1$), the pairwise loops are not entered, correctly resulting in $P=0, \\overline{o}=0, \\overline{z}=0$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes packing fraction, pressure, mean overlap, and mean contact number\n    for a 2D agent-based model of cells under periodic boundary conditions.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"Lx\": 50.0, \"Ly\": 50.0, \"R\": 2.0, \"k\": 0.5,\n            \"positions\": [\n                (5.0, 5.0), (8.6, 5.0), (23.0, 5.0), (32.0, 5.0), (41.0, 5.0),\n                (5.0, 20.0), (8.6, 20.0), (23.0, 20.0), (32.0, 20.0), (41.0, 20.0)\n            ]\n        },\n        {\n            \"Lx\": 20.0, \"Ly\": 20.0, \"R\": 3.0, \"k\": 1.0,\n            \"positions\": [\n                (2.0, 2.0), (6.0, 2.0), (10.0, 2.0), (14.0, 2.0),\n                (2.0, 6.0), (6.0, 6.0), (10.0, 6.0), (14.0, 6.0),\n                (2.0, 10.0), (6.0, 10.0), (10.0, 10.0), (14.0, 10.0),\n                (2.0, 14.0), (6.0, 14.0), (10.0, 14.0), (14.0, 14.0)\n            ]\n        },\n        {\n            \"Lx\": 30.0, \"Ly\": 30.0, \"R\": 5.0, \"k\": 0.8,\n            \"positions\": [\n                (5.0, 5.0), (15.0, 5.0), (5.0, 15.0), (15.0, 15.0)\n            ]\n        },\n        {\n            \"Lx\": 40.0, \"Ly\": 40.0, \"R\": 7.0, \"k\": 1.2,\n            \"positions\": [(10.0, 10.0)]\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        Lx, Ly, R, k = case[\"Lx\"], case[\"Ly\"], case[\"R\"], case[\"k\"]\n        positions = np.array(case[\"positions\"], dtype=np.float64)\n        \n        N = positions.shape[0]\n        A = Lx * Ly\n        r0 = 2.0 * R\n\n        # Handle trivial cases (N  2)\n        if N  2:\n            phi = (N * np.pi * R**2) / A if A  0 else 0.0\n            results = [phi, 0.0, 0.0, 0.0]\n            # Round and append\n            all_results.append([round(val, 6) for val in results])\n            continue\n            \n        # 1. Compute packing fraction (phi)\n        phi = (N * np.pi * R**2) / A\n\n        # Initialize accumulators\n        virial_sum = 0.0\n        overlap_sum = 0.0\n        overlap_count = 0\n        contacts = np.zeros(N, dtype=int)\n\n        # Loop over all unique pairs of cells\n        for i in range(N):\n            for j in range(i + 1, N):\n                # Compute displacement vector\n                delta = positions[j] - positions[i]\n                \n                # Apply minimum-image convention for PBC\n                delta[0] -= Lx * np.rint(delta[0] / Lx)\n                delta[1] -= Ly * np.rint(delta[1] / Ly)\n                \n                r_ij = np.linalg.norm(delta)\n\n                # Check for interaction (overlap)\n                if r_ij  r0:\n                    # Contribution to pressure (Virial)\n                    force_mag = k * (1.0 - r_ij / r0)\n                    virial_sum += r_ij * force_mag\n                    \n                    # Contribution to mean positive overlap\n                    overlap = 1.0 - r_ij / r0\n                    overlap_sum += overlap\n                    overlap_count += 1\n                    \n                    # Increment contact numbers\n                    contacts[i] += 1\n                    contacts[j] += 1\n        \n        # 2. Compute mechanical pressure (P)\n        pressure = virial_sum / (2.0 * A) if A  0 else 0.0\n        \n        # 3. Compute mean positive overlap fraction (o_bar)\n        mean_overlap = overlap_sum / overlap_count if overlap_count  0 else 0.0\n\n        # 4. Compute mean contact number (z_bar)\n        mean_contacts = np.mean(contacts)\n\n        # Store rounded results for the current case\n        case_results = [\n            round(phi, 6),\n            round(pressure, 6),\n            round(mean_overlap, 6),\n            round(mean_contacts, 6)\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as specified\n    formatted_results = [\n        f\"[{','.join(f'{v:.6f}' for v in res)}]\" for res in all_results\n    ]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4313977"}, {"introduction": "Cell motility is a key driver of many biological processes, and agent-based models often simplify space onto a discrete lattice to study movement. This practice explores how to model directed cell movement (chemotaxis) on such a lattice, using the principle of maximum entropy to govern probabilistic choices based on an external gradient. This exercise reveals a critical aspect of computational modeling: the choice of representation (e.g., the lattice neighborhood) can create non-obvious artifacts, such as directional bias. By comparing different neighborhood schemes, you will gain a deeper appreciation for the trade-offs involved in designing a scientifically robust agent-based model. [@problem_id:4313996]", "problem": "Consider a square-lattice Agent-Based Model (ABM) of cell motility in the plane, in which each agent executes a time-discrete random walk with one move per time step to a neighboring lattice site. Two neighborhood schemes are considered: the Moore neighborhood (comprising $8$ neighbors with displacements $\\{(\\pm 1,0),(0,\\pm 1),(\\pm 1,\\pm 1)\\}$) and the von Neumann neighborhood (comprising $4$ neighbors with displacements $\\{(\\pm 1,0),(0,\\pm 1)\\}$). The chemotactic gradient is represented by a unit vector $\\hat{\\mathbf{g}}$ orientated at angle $\\theta$ (in radians) relative to the positive $x$-axis, that is $\\hat{\\mathbf{g}} = (\\cos\\theta,\\sin\\theta)$. Assume no resting state.\n\nDefine two step-length conventions for the displacement applied when a move is executed:\n- \"physical\": the displacement vector is the raw lattice vector $\\mathbf{d}_i \\in \\mathbb{Z}^2$, yielding cardinal steps of length $1$ and diagonal steps of length $\\sqrt{2}$.\n- \"normalized\": the displacement vector is the unit vector in the lattice direction $\\hat{\\mathbf{d}}_i = \\mathbf{d}_i/\\|\\mathbf{d}_i\\|$, so all performed steps have unit length.\n\nAssume the agent senses the directional alignment of candidate moves with the gradient (but not their length), and model the choice probabilities by the following principle: among the available neighbor directions $\\{\\mathbf{d}_i\\}$ in the chosen neighborhood, the probability of selecting a direction is governed by maximum entropy under a constraint on the expected alignment with $\\hat{\\mathbf{g}}$, controlled by a sensitivity parameter $\\beta \\ge 0$ (dimensionless). The chosen move is then executed according to the specified step-length convention. The directional bias, $b$, is defined as the expected projection of the step displacement onto $\\hat{\\mathbf{g}}$ per time step (in lattice cell-lengths per step). Formally, let the displacement actually applied be $\\mathbf{s}_i$, and the selection probability be $p_i$, then\n$$\nb = \\sum_i p_i \\, (\\mathbf{s}_i \\cdot \\hat{\\mathbf{g}}).\n$$\n\nYour task is to derive, from first principles and the stated assumptions, a mathematically explicit expression for the choice probabilities $p_i$ and the resulting directional bias $b$ for a given neighborhood, sensitivity $\\beta$, step-length convention, and gradient angle $\\theta$. Then implement a program that computes $b$ for each of the test cases below.\n\nPhysical unit specification: report $b$ in lattice cell-lengths per step, rounded to six decimal places.\n\nAngle unit specification: input angles are specified in radians.\n\nTest suite and parameter coverage:\n- Case $1$: neighborhood \"Moore\", step-length convention \"physical\", sensitivity $\\beta = 1$, gradient angle $\\theta = \\pi/4$.\n- Case $2$: neighborhood \"vonNeumann\", step-length convention \"normalized\", sensitivity $\\beta = 10$, gradient angle $\\theta = \\pi/4$.\n- Case $3$: neighborhood \"Moore\", step-length convention \"normalized\", sensitivity $\\beta = 0$, gradient angle $\\theta = \\pi/3$.\n- Case $4$: neighborhood \"vonNeumann\", step-length convention \"physical\", sensitivity $\\beta = 1/2$, gradient angle $\\theta = 0$.\n- Case $5$: neighborhood \"Moore\", step-length convention \"physical\", sensitivity $\\beta = 100$, gradient angle $\\theta = \\arctan(2)$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[$result_1,result_2,\\dots$]\"), where each $result_i$ is the directional bias $b$ for the corresponding test case, rounded to six decimal places, in the order of the cases listed above.", "solution": "The problem asks for the derivation of an expression for the directional bias, $b$, of a chemotactic agent on a square lattice and its computation for several test cases. The solution proceeds by first deriving the choice probabilities from the principle of maximum entropy and then using these probabilities to compute the expected displacement, i.e., the directional bias.\n\n**1. Derivation of Choice Probabilities from Maximum Entropy**\n\nThe problem states that the probability $p_i$ of selecting a move in direction $i$ is governed by the principle of maximum entropy (MaxEnt). We seek to find the probability distribution $\\{p_i\\}$ over the $N$ available moves that maximizes the Shannon entropy, $S = -\\sum_{i=1}^{N} p_i \\ln p_i$, subject to certain constraints.\n\nThe constraints are:\n1.  **Normalization**: The probabilities must sum to $1$.\n    $$ \\sum_{i=1}^{N} p_i = 1 $$\n2.  **Expected Alignment**: The agent's choice is biased by the alignment of the possible move *directions* with the gradient vector $\\hat{\\mathbf{g}}$. Let the unit vector for the $i$-th move direction be $\\hat{\\mathbf{d}}_i$. The alignment is the scalar product $c_i = \\hat{\\mathbf{d}}_i \\cdot \\hat{\\mathbf{g}}$. The constraint is on the expected value of this alignment.\n    $$ \\sum_{i=1}^{N} p_i c_i = \\langle c \\rangle $$\n    where $\\langle c \\rangle$ is a specified mean alignment, whose value is implicitly controlled by the sensitivity parameter $\\beta$.\n\nWe use the method of Lagrange multipliers to maximize $S$ under these constraints. The Lagrangian $\\mathcal{L}$ is:\n$$ \\mathcal{L}(\\{p_i\\}, \\lambda_0, \\beta) = -\\sum_{i=1}^{N} p_i \\ln p_i - \\lambda_0 \\left(\\sum_{i=1}^{N} p_i - 1\\right) - \\beta \\left(\\sum_{i=1}^{N} p_i c_i - \\langle c \\rangle\\right) $$\nHere, $\\lambda_0$ and $\\beta$ are the Lagrange multipliers. The problem identifies $\\beta$ as the \"sensitivity parameter\". For a parameter to represent sensitivity to an attractive gradient, a larger positive $\\beta$ must correspond to a stronger preference for directions aligned with the gradient (larger $\\langle c \\rangle$). We will confirm this interpretation.\n\nDifferentiating $\\mathcal{L}$ with respect to $p_j$ and setting the result to zero gives:\n$$ \\frac{\\partial \\mathcal{L}}{\\partial p_j} = -\\ln p_j - 1 - \\lambda_0 - \\beta c_j = 0 $$\n$$ \\ln p_j = -1 - \\lambda_0 - \\beta c_j \\implies p_j = e^{-1-\\lambda_0} e^{-\\beta c_j} $$\n\nTo find the term $e^{-1-\\lambda_0}$, we apply the normalization constraint:\n$$ \\sum_{j=1}^{N} p_j = e^{-1-\\lambda_0} \\sum_{j=1}^{N} e^{-\\beta c_j} = 1 \\implies e^{-1-\\lambda_0} = \\frac{1}{\\sum_{j=1}^{N} e^{-\\beta c_j}} $$\nThe denominator is the partition function, $Z = \\sum_{j=1}^{N} e^{-\\beta c_j}$. The probability of choosing move $j$ is thus:\n$$ p_j = \\frac{e^{-\\beta c_j}}{Z} $$\nThis is a standard Boltzmann-Gibbs distribution. The expected alignment is $\\langle c \\rangle = \\frac{\\partial \\ln Z}{\\partial(-\\beta)}$. To ensure that $\\langle c \\rangle$ increases with sensitivity, we expect $\\frac{\\partial \\langle c \\rangle}{\\partial \\beta}  0$. The derivative is $\\frac{\\partial \\langle c \\rangle}{\\partial \\beta} = \\langle c^2 \\rangle - \\langle c \\rangle^2 = \\text{Var}(c) \\ge 0$. If we use the multiplier $-\\beta$, then $\\frac{\\partial \\langle c \\rangle}{\\partial(-\\beta)} = -\\text{Var}(c) \\le 0$. This would imply chemo-repulsion. Therefore, to model attraction as implied by \"sensitivity\", the Lagrange multiplier should be positive, leading to a distribution of the form $p_j \\propto e^{+\\beta c_j}$. The correct formulation is:\n$$ p_i = \\frac{e^{\\beta c_i}}{Z}, \\quad \\text{where} \\quad Z = \\sum_{j=1}^{N} e^{\\beta c_j} $$\nand $c_i = \\hat{\\mathbf{d}}_i \\cdot \\hat{\\mathbf{g}}$. This is the probability distribution we will use.\n\n**2. Defining Model Components**\n\nThe calculation of the directional bias $b$ requires defining the specific vectors for each component of the model.\n*   **Gradient Vector**: $\\hat{\\mathbf{g}} = (\\cos\\theta, \\sin\\theta)$, where $\\theta$ is the angle with the positive $x$-axis.\n*   **Neighborhoods and Displacements**: Let $N$ be the number of neighbors.\n    *   **Moore Neighborhood ($N=8$)**: The set of raw lattice displacements is $\\{\\mathbf{d}_i^{\\text{Moore}}\\} = \\{(\\pm 1, 0), (0, \\pm 1), (\\pm 1, \\pm 1)\\}$.\n    *   **von Neumann Neighborhood ($N=4$)**: The set of raw lattice displacements is $\\{\\mathbf{d}_i^{\\text{vN}}\\} = \\{(\\pm 1, 0), (0, \\pm 1)\\}$.\n*   **Direction Vectors**: The unit direction vectors, $\\hat{\\mathbf{d}}_i$, are obtained by normalizing the raw vectors: $\\hat{\\mathbf{d}}_i = \\mathbf{d}_i / \\|\\mathbf{d}_i\\|$. For von Neumann moves, $\\|\\mathbf{d}_i\\|=1$, so $\\hat{\\mathbf{d}}_i=\\mathbf{d}_i$. For Moore, the diagonal moves like $(1,1)$ have length $\\|\\mathbf{d}_i\\|=\\sqrt{2}$, so the corresponding direction vector is $\\hat{\\mathbf{d}}_i=(1/\\sqrt{2}, 1/\\sqrt{2})$.\n*   **Step-Length Conventions**: The actual displacement vector applied, $\\mathbf{s}_i$, depends on the convention.\n    *   **\"physical\"**: The step vector is the raw lattice vector, $\\mathbf{s}_i = \\mathbf{d}_i$.\n    *   **\"normalized\"**: The step vector is the unit direction vector, $\\mathbf{s}_i = \\hat{\\mathbf{d}}_i$.\n\n**3. Formulation of Directional Bias, $b$**\n\nThe directional bias, $b$, is defined as the expected projection of the step displacement vector $\\mathbf{s}_i$ onto the gradient vector $\\hat{\\mathbf{g}}$, averaged over all possible moves.\n$$ b = \\sum_{i=1}^{N} p_i \\, (\\mathbf{s}_i \\cdot \\hat{\\mathbf{g}}) $$\nUsing the derived probability $p_i$, the full expression for $b$ is:\n$$ b = \\sum_{i=1}^{N} \\left( \\frac{e^{\\beta (\\hat{\\mathbf{d}}_i \\cdot \\hat{\\mathbf{g}})}}{\\sum_{j=1}^{N} e^{\\beta (\\hat{\\mathbf{d}}_j \\cdot \\hat{\\mathbf{g}})}} \\right) (\\mathbf{s}_i \\cdot \\hat{\\mathbf{g}}) $$\n\n**4. Computational Algorithm**\n\nFor any given test case (neighborhood, step-length convention, $\\beta$, $\\theta$), the computation of $b$ proceeds as follows:\n\n1.  Identify the set of raw displacement vectors $\\{\\mathbf{d}_i\\}$ for the specified neighborhood.\n2.  Calculate the corresponding set of unit direction vectors $\\{\\hat{\\mathbf{d}}_i\\}$.\n3.  Determine the set of applied step vectors $\\{\\mathbf{s}_i\\}$ based on the step-length convention.\n4.  Construct the gradient vector $\\hat{\\mathbf{g}} = (\\cos\\theta, \\sin\\theta)$.\n5.  Calculate the directional alignments $c_i = \\hat{\\mathbf{d}}_i \\cdot \\hat{\\mathbf{g}}$ for each move $i$.\n6.  Calculate the weights $w_i = e^{\\beta c_i}$.\n7.  Compute the partition function $Z = \\sum_{i=1}^{N} w_i$.\n8.  Determine the choice probabilities $p_i = w_i / Z$.\n9.  Calculate the projected displacement for each move, $b_i = \\mathbf{s}_i \\cdot \\hat{\\mathbf{g}}$.\n10. Compute the final directional bias as the weighted sum $b = \\sum_{i=1}^{N} p_i b_i$.\n\nA special case is $\\beta=0$. Here, $w_i=e^0=1$ for all $i$, so $p_i=1/N$. The bias becomes $b = \\frac{1}{N} \\sum_i (\\mathbf{s}_i \\cdot \\hat{\\mathbf{g}})$. Since both the Moore and von Neumann neighborhoods are symmetric with respect to the origin (i.e., $\\sum_i \\mathbf{d}_i = \\mathbf{0}$ and $\\sum_i \\hat{\\mathbf{d}}_i = \\mathbf{0}$), the bias for $\\beta=0$ is always $0$, as seen in Test Case $3$. For $\\beta  0$, the bias will be positive, indicating a net drift in the direction of the gradient. For very large $\\beta$, the probability will be concentrated on the move with the highest alignment $c_i$, and $b$ will approach the maximum possible value of $(\\mathbf{s}_{\\text{best}} \\cdot \\hat{\\mathbf{g}})$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the cell motility problem for the given test suite.\n    \"\"\"\n\n    # Define neighborhood raw displacement vectors\n    neighborhoods_raw = {\n        \"Moore\": np.array([\n            [1.0, 0.0], [-1.0, 0.0], [0.0, 1.0], [0.0, -1.0],\n            [1.0, 1.0], [-1.0, -1.0], [1.0, -1.0], [-1.0, 1.0]\n        ]),\n        \"vonNeumann\": np.array([\n            [1.0, 0.0], [-1.0, 0.0], [0.0, 1.0], [0.0, -1.0]\n        ])\n    }\n\n    # Define the test cases from the problem statement.\n    # The format is (neighborhood, step-length convention, sensitivity beta, gradient angle theta).\n    test_cases = [\n        (\"Moore\", \"physical\", 1.0, np.pi / 4),\n        (\"vonNeumann\", \"normalized\", 10.0, np.pi / 4),\n        (\"Moore\", \"normalized\", 0.0, np.pi / 3),\n        (\"vonNeumann\", \"physical\", 0.5, 0.0),\n        (\"Moore\", \"physical\", 100.0, np.arctan(2.0)),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        neighborhood_name, convention, beta, theta = case\n\n        # 1. Get raw displacement vectors for the neighborhood\n        d_raw = neighborhoods_raw[neighborhood_name]\n\n        # 2. Calculate unit direction vectors\n        norms = np.linalg.norm(d_raw, axis=1)\n        # Reshape for broadcasting to prevent division errors in logic, although not strictly needed here\n        # as norms are always non-zero.\n        d_unit = d_raw / norms[:, np.newaxis]\n\n        # 3. Determine applied step vectors based on convention\n        if convention == \"physical\":\n            s_vectors = d_raw\n        elif convention == \"normalized\":\n            s_vectors = d_unit\n        else:\n            raise ValueError(f\"Unknown step-length convention: {convention}\")\n\n        # 4. Construct gradient vector\n        g_vector = np.array([np.cos(theta), np.sin(theta)])\n\n        # 5. Calculate directional alignments (c_i = d_hat_i . g_hat)\n        # This is a matrix-vector product where each row of d_unit is a vector\n        alignments = d_unit @ g_vector\n\n        # 6. Calculate choice probabilities (p_i propto exp(beta * c_i))\n        # Handle the beta=0 case explicitly to avoid potential floating point issues,\n        # although np.exp(0) is exactly 1.\n        if beta == 0.0:\n            num_moves = d_raw.shape[0]\n            probabilities = np.full(num_moves, 1.0 / num_moves)\n        else:\n            weights = np.exp(beta * alignments)\n            partition_function = np.sum(weights)\n            probabilities = weights / partition_function\n\n        # 7. Calculate projected displacement for each move (b_i = s_i . g_hat)\n        projected_displacements = s_vectors @ g_vector\n        \n        # 8. Compute final directional bias (b = sum(p_i * b_i))\n        directional_bias = np.sum(probabilities * projected_displacements)\n        \n        results.append(directional_bias)\n\n    # Final print statement in the exact required format.\n    # The results are formatted to six decimal places.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "4313996"}]}