{"hands_on_practices": [{"introduction": "Real-world protein-protein interaction (PPI) networks are often fragmented into multiple disconnected components, posing a challenge for proximity metrics based on shortest-path distances. This exercise [@problem_id:4366923] confronts this foundational issue by asking you to compare a proximity calculation restricted to the Largest Connected Component (LCC) with one that uses a penalty for disconnected nodes. By quantifying the bias between these two common approaches, you will develop a critical understanding of how data preprocessing choices can influence network-based conclusions.", "problem": "A protein–protein interaction (PPI) network is represented as an undirected, unweighted graph $G=(V,E)$ that may be disconnected. The network comprises multiple components; the Largest Connected Component (LCC) contains $15{,}000$ nodes out of a total of $18{,}000$ nodes. Consider a drug target set $S$ and a disease protein set $T$ embedded in $G$, where $|S|=10$ and $|T|=12$. Of the drug targets, $7$ are in the LCC and $3$ are outside. Of the disease proteins, $9$ are in the LCC and $3$ are outside. \n\nDefine the network proximity between $S$ and $T$ as the mean nearest-neighbor shortest-path distance from $S$ to $T$:\n$$\n\\delta(S,T)=\\frac{1}{|S|}\\sum_{s\\in S}\\min_{t\\in T} d_G(s,t),\n$$\nwhere $d_G(s,t)$ denotes the shortest-path length in hop counts in $G$. For pairs in different components, adopt a finite penalty distance $D_{\\infty}=7$ so that if $s$ and all $t\\in T$ lie in components disconnected from $s$, then $\\min_{t\\in T} d_G(s,t)$ is taken to be $D_{\\infty}$. \n\nTo emulate the common restriction to the Largest Connected Component (LCC) in systems biomedicine, define the LCC-restricted proximity\n$$\n\\delta_{\\mathrm{LCC}}(S,T)=\\frac{1}{|S\\cap \\mathrm{LCC}|}\\sum_{s\\in S\\cap \\mathrm{LCC}} \\min_{t\\in T\\cap \\mathrm{LCC}} d_G(s,t),\n$$\ncomputed by removing all nodes not in the LCC before measuring distances.\n\nEmpirical observations on $G$ show:\n- For the $7$ drug targets in $S\\cap \\mathrm{LCC}$, the nearest-neighbor distances to $T\\cap \\mathrm{LCC}$ are $\\{1,2,2,3,3,4,5\\}$ hops.\n- Of the $3$ drug targets outside the LCC, exactly one shares a small component with a single disease protein in $T$ at a distance of $2$ hops; the remaining two drug targets lie in components with no disease proteins.\n\nStarting from the foundational definitions of connected components, shortest-path distance, and the above proximity definitions, justify the rationale for restricting computations to the LCC when using shortest-path-based proximity in disconnected PPI networks. Then, compute the signed bias defined as\n$$\nb=\\delta_{\\mathrm{LCC}}(S,T)-\\delta(S,T),\n$$\ngiven the data above. Round your final numeric answer to four significant figures. No units are required.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, objective, and self-contained. It presents a standard task in network-based systems biomedicine, providing all necessary definitions, data, and constraints to arrive at a unique, verifiable solution. The premises are consistent and the terminology is precise. Therefore, the problem is valid.\n\nThe solution is divided into two parts, as requested by the problem statement: first, a justification for restricting network proximity computations to the Largest Connected Component (LCC), and second, the calculation of the signed bias $b$.\n\n**Part 1: Rationale for LCC Restriction in Proximity Calculations**\n\nThe use of shortest-path distance, $d_G(s,t)$, is fundamental to many network proximity measures. In a graph $G$ that is not connected, the graph is partitioned into two or more connected components. By definition, no path exists between nodes residing in different components. Consequently, the shortest-path distance between such nodes is infinite, i.e., $d_G(s,t) = \\infty$.\n\nThis poses a significant challenge for proximity metrics that average these distances. An average involving even one infinite value is itself infinite, rendering the metric non-informative. For instance, the definition $\\delta(S,T)=\\frac{1}{|S|}\\sum_{s\\in S}\\min_{t\\in T} d_G(s,t)$ becomes problematic if any drug target $s \\in S$ is in a component devoid of any disease proteins from $T$. In this case, $\\min_{t\\in T} d_G(s,t) = \\infty$, causing $\\delta(S,T)$ to diverge.\n\nTwo primary strategies exist to address this issue:\n1.  **Assigning a Finite Penalty:** This approach, explicitly mentioned in the problem, replaces infinite distances with a large, finite penalty value, $D_{\\infty}$. Here, if a source node $s$ is disconnected from all target nodes $t \\in T$, its contribution to the sum is set to $D_{\\infty}=7$. While this makes the computation tractable, it introduces a critical dependency on an arbitrary parameter. The choice of $D_{\\infty}$ can substantially alter the final proximity score and any subsequent statistical assessment (e.g., a Z-score). A higher $D_{\\infty}$ penalizes disconnectedness more severely. The lack of a theoretically justified value for $D_{\\infty}$ makes this method subjective and potentially brittle.\n\n2.  **Restricting to the LCC:** Protein-protein interaction (PPI) networks derived from high-throughput experiments typically feature a \"giant\" or Largest Connected Component (LCC) that contains a large majority of the nodes (in this case, $15,000$ out of $18,000$ nodes, or about $83.3\\%$). The remaining nodes are scattered across numerous small, isolated components. The scientific rationale for restricting analysis to the LCC is that this component represents the core, interconnected functional machinery of the cell. The smaller components are often interpreted as containing less functionally central proteins, or may represent experimental artifacts or incomplete data. By focusing on the LCC, all nodes within the scope of analysis are, by definition, mutually reachable, ensuring all shortest-path distances $d_G(s,t)$ are finite and well-defined. This approach eliminates the need for an arbitrary penalty like $D_{\\infty}$, leading to a more robust and parameter-free distance calculation. The primary drawback is the loss of information from nodes outside the LCC, which may harbor relevant biological signal. The problem's calculation of bias is designed to quantify the effect of this information loss.\n\nIn summary, restricting computations to the LCC is a pragmatic and common approach in systems biomedicine to ensure that shortest-path-based metrics are well-defined and not skewed by arbitrary penalty parameters, under the assumption that the most significant biological processes are captured within the network's largest interconnected region.\n\n**Part 2: Calculation of the Signed Bias $b$**\n\nThe signed bias is defined as $b=\\delta_{\\mathrm{LCC}}(S,T)-\\delta(S,T)$. We will compute each term separately.\n\n**Calculating $\\delta_{\\mathrm{LCC}}(S,T)$:**\nThe LCC-restricted proximity is defined as:\n$$\n\\delta_{\\mathrm{LCC}}(S,T)=\\frac{1}{|S\\cap \\mathrm{LCC}|}\\sum_{s\\in S\\cap \\mathrm{LCC}} \\min_{t\\in T\\cap \\mathrm{LCC}} d_G(s,t)\n$$\nFrom the problem statement, the number of drug targets in the LCC is $|S\\cap \\mathrm{LCC}| = 7$. The set of nearest-neighbor distances for these $7$ targets to the disease proteins within the LCC ($T\\cap \\mathrm{LCC}$) is given as $\\{1,2,2,3,3,4,5\\}$.\nThe sum of these distances is:\n$$\n\\sum_{s\\in S\\cap \\mathrm{LCC}} \\min_{t\\in T\\cap \\mathrm{LCC}} d_G(s,t) = 1+2+2+3+3+4+5 = 20\n$$\nTherefore, the LCC-restricted proximity is:\n$$\n\\delta_{\\mathrm{LCC}}(S,T) = \\frac{20}{7}\n$$\n\n**Calculating $\\delta(S,T)$:**\nThe global proximity is defined as:\n$$\n\\delta(S,T)=\\frac{1}{|S|}\\sum_{s\\in S}\\min_{t\\in T} d_G(s,t)\n$$\nWe are given $|S|=10$. The sum can be partitioned into a sum over targets in the LCC and a sum over targets outside the LCC:\n$$\n\\sum_{s\\in S}\\min_{t\\in T} d_G(s,t) = \\sum_{s\\in S\\cap \\mathrm{LCC}}\\min_{t\\in T} d_G(s,t) + \\sum_{s\\in S\\setminus \\mathrm{LCC}}\\min_{t\\in T} d_G(s,t)\n$$\nFor the first term, consider a target $s \\in S\\cap \\mathrm{LCC}$. It is connected to all $t \\in T\\cap \\mathrm{LCC}$ but disconnected from all $t \\in T\\setminus \\mathrm{LCC}$. Thus, the minimum distance will be to a node within its own component (the LCC):\n$$\n\\min_{t\\in T} d_G(s,t) = \\min(\\min_{t\\in T\\cap \\mathrm{LCC}} d_G(s,t), \\min_{t\\in T\\setminus \\mathrm{LCC}} d_G(s,t)) = \\min(\\min_{t\\in T\\cap \\mathrm{LCC}} d_G(s,t), \\infty) = \\min_{t\\in T\\cap \\mathrm{LCC}} d_G(s,t)\n$$\nThe sum for these $7$ targets is the same as calculated before:\n$$\n\\sum_{s\\in S\\cap \\mathrm{LCC}}\\min_{t\\in T} d_G(s,t) = 20\n$$\nFor the second term, we consider the $|S\\setminus \\mathrm{LCC}| = 3$ targets outside the LCC.\n- One target lies in a small component with a single disease protein from $T$ at a distance of $2$ hops. For this target, its minimum distance to any protein in $T$ is this value, since all other proteins in $T$ are in different components (the LCC or others) and thus infinitely far. So, its contribution is $2$.\n- The remaining two targets lie in components with no disease proteins from $T$. According to the problem's rule, for these targets, the minimum distance is assigned the penalty value $D_{\\infty}=7$. The contribution from each of these two targets is $7$.\nThe sum for the targets outside the LCC is:\n$$\n\\sum_{s\\in S\\setminus \\mathrm{LCC}}\\min_{t\\in T} d_G(s,t) = 2 + 7 + 7 = 16\n$$\nThe total sum for all targets in $S$ is $20 + 16 = 36$.\nTherefore, the global proximity is:\n$$\n\\delta(S,T) = \\frac{36}{10} = 3.6\n$$\n\n**Calculating the Bias $b$:**\nNow we compute the signed bias:\n$$\nb = \\delta_{\\mathrm{LCC}}(S,T) - \\delta(S,T) = \\frac{20}{7} - 3.6 = \\frac{20}{7} - \\frac{36}{10} = \\frac{20}{7} - \\frac{18}{5}\n$$\nTo subtract the fractions, we find a common denominator, which is $35$:\n$$\nb = \\frac{20 \\times 5}{35} - \\frac{18 \\times 7}{35} = \\frac{100 - 126}{35} = -\\frac{26}{35}\n$$\nFinally, we convert this fraction to a decimal and round to four significant figures:\n$$\nb = -\\frac{26}{35} \\approx -0.742857...\n$$\nRounding to four significant figures gives:\n$$\nb \\approx -0.7429\n$$\nThe negative bias indicates that restricting the analysis to the LCC resulted in a lower (i.e., closer) proximity value compared to the global calculation that includes a penalty for disconnected nodes. This is because the global calculation was inflated by the high penalty cost ($D_\\infty=7$) assigned to the two completely isolated drug targets.", "answer": "$$\\boxed{-0.7429}$$", "id": "4366923"}, {"introduction": "While informative, a global PPI network represents a static map of all possible interactions; true biological function is highly context-dependent. This comprehensive coding practice [@problem_id:4366944] guides you through an essential workflow in modern systems biomedicine: building a tissue-specific network by integrating proteome expression data. You will implement a full analysis pipeline to calculate how network proximity changes in specific cellular contexts and learn to validate these computational predictions against experimental target engagement data, bridging the gap between in silico modeling and biological reality.", "problem": "You are given a formal setting for network proximity in the context of drug-disease relationships under tissue-specific proteome constraints. The computational task is to start from core graph-theoretic definitions, derive an aggregate proximity measure between a set of drug targets and a disease module, incorporate tissue-specific proteome constraints by excluding nodes below an expression threshold, and then validate the change in proximity against a proteomics-derived target engagement metric across tissues. All computations must be performed on small, explicitly specified graphs to ensure reproducibility.\n\nBegin from the following fundamental bases, which you should use to derive a rigorous algorithm:\n- A protein-protein interaction network is represented as an undirected, simple graph with node set $V$ of size $|V| = n$ and edge set $E \\subseteq V \\times V$. Shortest-path distance $d(u,v)$ between nodes $u \\in V$ and $v \\in V$ is defined as the minimum number of edges in any path connecting $u$ to $v$ in the graph. If no path exists, the distance is undefined under the pure definition; to enable robust aggregation, you must define an effective finite distance by capping at a maximum value $d_{\\max}$, chosen as $d_{\\max} = n$, and use this cap wherever disconnections occur.\n- A disease module is a subset $D \\subseteq V$ and a drug’s target set is a subset $T \\subseteq V$. Tissues will be modeled as constraints over $V$ by providing an expression level $x_i \\in \\mathbb{R}_{\\ge 0}$ for each node $i \\in V$ in a given tissue and an expression threshold $\\tau \\in \\mathbb{R}_{\\ge 0}$. The tissue-specific network is formed by excluding nodes whose expression is strictly below the threshold (i.e., retain node $i$ if $x_i \\ge \\tau$), along with all incident edges.\n- Proteomics-derived target engagement (first appearance) metrics (Protein Target Engagement, PTE) will be provided as a vector of continuous values $y_t \\in \\mathbb{R}$, one value per tissue. Validation will be performed by computing a correlation between proximity changes and the engagement values across tissues. Use rank-based correlation that is robust to monotonic but nonlinear relationships.\n\nYour derivation must proceed from these bases without assuming any shortcut formulas. Specifically:\n1. Starting solely from the shortest-path definition $d(u,v)$, derive a principled aggregate quantity that captures how close the drug’s target set $T$ is to the disease module $D$ within a graph. Your aggregate must be set-wise, depend on $d(u,v)$, and be well-defined even when some nodes are disconnected, by employing the cap $d_{\\max} = n$.\n2. Define how tissue-specific proteome constraints alter the graph and consequently the aggregate proximity by removing nodes with expression $x_i  \\tau$. If any target in $T$ is removed by the constraint, your aggregate must still be computable by explicitly handling missing targets; similarly, if all disease nodes in $D$ are removed, your aggregate must remain defined via $d_{\\max}$.\n3. Define the baseline (unconstrained) proximity on the full graph, the tissue-specific proximity on the constrained graph, and the change in proximity $\\Delta$ as the tissue-specific proximity minus the baseline proximity. To validate against PTE, compute a rank-based correlation between $-\\Delta$ and the PTE values across tissues, with the interpretation that smaller tissue-specific proximity relative to baseline (i.e., negative $\\Delta$) should concord with stronger engagement.\n4. Implement your derivation as a complete program that, for each test case defined below, computes the correlation across tissues and returns the correlation coefficient as a float.\n\nImportant implementation details:\n- Use unweighted, undirected shortest-path distances.\n- Use the cap $d_{\\max} = n$ for any unreachable source-target or if the disease set becomes empty in a tissue.\n- If a target $t \\in T$ is absent in a tissue (due to $x_t  \\tau$), you must treat its contribution to the aggregate as $d_{\\max}$.\n- Perform validation using Spearman’s rank correlation, which is a widely accepted nonparametric measure.\n\nTest suite specification:\nYou must implement and evaluate the following four test cases. Each case uses a small graph, specified target and disease sets, three tissues with per-node expressions and a common threshold per case, and a PTE vector of three real values. All indices and numeric values are provided explicitly and must be used exactly as given.\n\n- Test Case $1$ (happy path with selective node removal):\n  - Nodes: $n = 8$, labeled $0,1,2,3,4,5,6,7$.\n  - Edges $E$: $(0,1),(1,2),(2,3),(3,4),(4,5),(5,6),(6,7),(0,7),(1,5),(2,6)$.\n  - Targets $T = \\{0,5\\}$, Disease $D = \\{3,7\\}$.\n  - Tissues and expressions with threshold $\\tau = 0.5$:\n    - Tissue $A$: $[1.0,0.8,0.7,0.9,0.4,1.0,0.6,1.0]$.\n    - Tissue $B$: $[0.9,0.7,0.8,0.6,0.9,1.0,0.8,0.3]$.\n    - Tissue $C$: $[0.4,0.6,0.9,1.0,0.7,1.0,0.9,0.9]$.\n  - PTE vector across tissues: $[0.6,0.2,0.1]$.\n\n- Test Case $2$ (disease nodes removed and potential empty disease set):\n  - Nodes: $n = 6$, labeled $0,1,2,3,4,5$.\n  - Edges $E$: $(0,1),(1,2),(2,3),(3,4),(4,5),(1,4)$.\n  - Targets $T = \\{1,4\\}$, Disease $D = \\{0,5\\}$.\n  - Tissues and expressions with threshold $\\tau = 0.5$:\n    - Tissue $A$: $[0.2,1.0,0.9,0.9,1.0,0.8]$.\n    - Tissue $B$: $[0.9,1.0,0.8,0.7,0.9,0.4]$.\n    - Tissue $C$: $[0.2,1.0,0.7,0.7,1.0,0.4]$.\n  - PTE vector across tissues: $[0.5,0.4,0.0]$.\n\n- Test Case $3$ (empty target set in a tissue and path disruption):\n  - Nodes: $n = 5$, labeled $0,1,2,3,4$.\n  - Edges $E$: $(0,1),(1,2),(2,3),(3,4)$.\n  - Targets $T = \\{0,2\\}$, Disease $D = \\{3\\}$.\n  - Tissues and expressions with threshold $\\tau = 0.5$:\n    - Tissue $A$: $[0.4,0.4,0.3,0.9,0.9]$.\n    - Tissue $B$: $[1.0,0.4,1.0,1.0,1.0]$.\n    - Tissue $C$: $[1.0,1.0,1.0,1.0,1.0]$.\n  - PTE vector across tissues: $[0.05,0.4,0.7]$.\n\n- Test Case $4$ (overlap between targets and disease and removal of overlapping nodes):\n  - Nodes: $n = 6$, labeled $0,1,2,3,4,5$.\n  - Edges $E$: $(0,1),(1,2),(2,3),(3,4),(4,5)$.\n  - Targets $T = \\{2,5\\}$, Disease $D = \\{2,4\\}$.\n  - Tissues and expressions with threshold $\\tau = 0.5$:\n    - Tissue $A$: $[1.0,1.0,0.4,1.0,1.0,1.0]$.\n    - Tissue $B$: $[1.0,1.0,1.0,1.0,0.4,1.0]$.\n    - Tissue $C$: $[1.0,1.0,1.0,1.0,1.0,1.0]$.\n  - PTE vector across tissues: $[0.1,0.4,0.9]$.\n\nProgram output specification:\n- For each test case, compute the baseline proximity on the full graph, the tissue-specific proximities for the three tissues, the proximity changes $\\Delta$ per tissue, then the Spearman correlation coefficient between the vector $-\\Delta$ and the given PTE vector for the three tissues. Aggregate the four correlation coefficients into a single Python list in the order of the test cases and print this list.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result1,result2,result3,result4]$).", "solution": "The problem asks for the derivation and implementation of a computational pipeline to assess drug-disease relationships using network proximity, modulated by tissue-specific proteome data. The validation of this model is performed by correlating the calculated proximity changes with an experimental metric, Protein Target Engagement (PTE), across different tissues. The entire process must be grounded in fundamental graph-theoretic definitions.\n\n### Principle-Based Derivation and Algorithmic Design\n\n**1. Aggregate Proximity Measure $P(T, D)$**\n\nThe problem requires a principled aggregate quantity to measure the closeness of a drug's target set, $T \\subseteq V$, to a disease module, $D \\subseteq V$, within a protein-protein interaction network represented as a graph $G=(V, E)$. The measure must be based on the shortest-path distance, $d(u,v)$.\n\nA natural starting point is to define the distance from a single target node $t \\in T$ to the entire disease set $D$. This is logically defined as the shortest distance from $t$ to any node in $D$:\n$$d(t, D) = \\min_{d \\in D} d(t, d)$$\nThis quantity, $d(t, D)$, represents the proximity of an individual target to the disease module.\n\nTo aggregate these individual proximities into a single set-wise measure for the entire target set $T$, a simple and principled approach is to compute the arithmetic mean of the individual proximities over all targets in $T$. This yields the average proximity of the target set to the disease module. We define this aggregate proximity, $P(T, D)$, as:\n$$P(T, D) = \\frac{1}{|T|} \\sum_{t \\in T} d(t, D)$$\nwhere $|T|$ is the number of targets. This definition is set-wise and directly derived from the shortest-path distance $d(u,v)$ as required.\n\nThe problem specifies handling for disconnected nodes and empty sets using a cap $d_{\\max} = n$, where $n = |V|$ is the total number of nodes in the original graph.\n- If a target $t$ is disconnected from all nodes in $D$, then $d(t,d)$ is infinite for all $d \\in D$. In this case, we set $d(t, D) = d_{\\max}$.\n- If the disease set $D$ is empty, the minimum is undefined. We adhere to the problem's rule and set $d(t, D) = d_{\\max}$ for any target $t$.\n\n**2. Incorporating Tissue-Specific Constraints**\n\nTissue specificity is introduced by filtering the network based on node expression levels. For a given tissue with expression values $x_i$ for each node $i \\in V$ and a threshold $\\tau$, the tissue-specific graph $G_{\\text{tissue}}$ is constructed.\nThe set of nodes present in the tissue is $V_{\\text{tissue}} = \\{i \\in V \\mid x_i \\ge \\tau\\}$. The graph $G_{\\text{tissue}}$ is the subgraph of $G$ induced by $V_{\\text{tissue}}$.\n\nThe calculation of tissue-specific proximity, $P_{\\text{tissue}}(T, D)$, must account for nodes from $T$ or $D$ being removed. The problem states that the aggregation must still be based on the original target set $T$.\nThe contribution of each original target $t \\in T$ to the tissue-specific proximity is defined as follows:\n- If target $t$ is removed from the network (i.e., $t \\notin V_{\\text{tissue}}$), its contribution to the total distance is explicitly defined as $d_{\\max}$.\n- If target $t$ is present in the network (i.e., $t \\in V_{\\text{tissue}}$), its proximity is calculated with respect to the disease nodes that are also present, $D_{\\text{tissue}} = D \\cap V_{\\text{tissue}}$. The distance, $d_{G_{\\text{tissue}}}(t, d)$, is calculated within the context of the subgraph $G_{\\text{tissue}}$.\n  - If $D_{\\text{tissue}}$ is empty, the contribution of target $t$ is $d_{\\max}$.\n  - If $D_{\\text{tissue}}$ is not empty, the contribution is $\\min_{d \\in D_{\\text{tissue}}} d_{G_{\\text{tissue}}}(t, d)$. This value is capped at $d_{\\max}$ if $t$ is disconnected from all nodes in $D_{\\text{tissue}}$ within $G_{\\text{tissue}}$.\n\nCombining these rules, the tissue-specific proximity is:\n$$P_{\\text{tissue}}(T, D) = \\frac{1}{|T|} \\sum_{t \\in T} d_{\\text{tissue}}(t, D; V_{\\text{tissue}})$$\nwhere $d_{\\text{tissue}}(t, D; V_{\\text{tissue}})$ is the contribution of target $t$ as defined above.\n\n**3. Validation via Proximity Change and Correlation**\n\nThe validation step compares the change in proximity to the PTE metric.\n- **Baseline Proximity, $P_{\\text{baseline}}$**: This is the proximity $P(T, D)$ calculated on the full, unconstrained graph $G$.\n- **Tissue-Specific Proximity, $P_k$**: This is the proximity calculated for each tissue $k$, using the corresponding tissue-specific graph $G_k$.\n- **Proximity Change, $\\Delta_k$**: For each tissue $k$, the change is $\\Delta_k = P_k - P_{\\text{baseline}}$. A positive $\\Delta_k$ indicates that the targets have become \"more distant\" from the disease module in that tissue's context.\n\nThe hypothesis is that stronger target engagement (higher PTE) in a tissue should correspond to a greater reduction in proximity (more negative $\\Delta$). Therefore, we expect a positive correlation between the PTE values, $y_k$, and the negative proximity change, $-\\Delta_k$.\nThe problem specifies using Spearman's rank correlation coefficient, $\\rho$, a non-parametric measure robust to non-linear relationships. It is calculated as the Pearson a correlation coefficient of the rank-transformed variables. For a set of $m$ tissues, we compute:\n$$\\rho = \\text{SpearmanCorr}(\\{-\\Delta_k\\}_{k=1}^m, \\{y_k\\}_{k=1}^m)$$\n\n### Algorithmic Implementation\n\nA step-by-step algorithm to solve a single test case is as follows:\n\n1.  **Initialization**: Given graph data ($n$, $E$), sets ($T$, $D$), and tissue data (expressions, $\\tau$, PTE vector). Set $d_{\\max} = n$.\n2.  **Shortest-Path Calculation**: The distance $d(u,v)$ on an unweighted graph is the number of edges in a shortest path. For a given graph context (full or tissue-specific), we can compute these distances. A Breadth-First Search (BFS) starting from each required source node is efficient.\n3.  **Proximity Calculation Function**: A function, `calculate_proximity(n, edges, T, D, nodes_present)`, will implement the logic derived above.\n    a. It receives the master node count $n$, all original edges $E$, the original sets $T$ and $D$, and the set of nodes `nodes_present` for the current context.\n    b. It constructs an adjacency list for the subgraph induced by `nodes_present`.\n    c. It determines the current disease set $D_{\\text{context}} = D \\cap \\text{nodes\\_present}$.\n    d. It initializes a total distance sum to $0$.\n    e. It iterates through each target $t \\in T$:\n        i. If $t \\notin \\text{nodes\\_present}$ or if $D_{\\text{context}}$ is empty, add $d_{\\max}$ to the sum.\n        ii. Otherwise, run a BFS on the subgraph starting from $t$ to find its distances to all reachable nodes.\n        iii. Find the minimum distance from $t$ to any node in $D_{\\text{context}}$. If no node in $D_{\\text{context}}$ is reachable, this distance is $d_{\\max}$. Add this minimum distance to the sum.\n    f. Return the total sum divided by $|T|$.\n4.  **Main Execution Flow**:\n    a. Calculate $P_{\\text{baseline}}$ by calling the proximity function with all nodes present.\n    b. Create an empty list for tissue-specific proximities, `tissue_proximities`.\n    c. For each tissue's expression data:\n        i. Determine the set of `nodes_present` where $x_i \\ge \\tau$.\n        ii. Call the proximity function with this set to get $P_k$.\n        iii. Append $P_k$ to `tissue_proximities`.\n    d. Calculate the vector $\\mathbf{\\Delta} = [P_k - P_{\\text{baseline}} \\text{ for } P_k \\text{ in } \\text{tissue\\_proximities}]$.\n    e. Calculate the vector $-\\mathbf{\\Delta}$.\n    f. Use `scipy.stats.spearmanr` to compute the correlation between $-\\mathbf{\\Delta}$ and the given PTE vector. Handle the case where the correlation is `nan` (due to zero variance in an input vector) by returning $0.0$.\n    g. The resulting coefficient is the answer for the test case.\n\nThis complete, step-by-step procedure rigorously follows the derivations and adheres to all constraints specified in the problem statement.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import spearmanr\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases.\n    \"\"\"\n\n    def _calculate_proximity(n_total, all_edges, T, D, nodes_present):\n        \"\"\"\n        Calculates the aggregate proximity of target set T to disease set D\n        in the context of a graph defined by nodes_present.\n        \"\"\"\n        d_max = float(n_total)\n        \n        if not T:\n            return 0.0\n\n        # Build tissue-specific graph using an adjacency list\n        adj_list = {node: [] for node in nodes_present}\n        for u, v in all_edges:\n            if u in nodes_present and v in nodes_present:\n                adj_list[u].append(v)\n                adj_list[v].append(u)\n\n        D_context = D.intersection(nodes_present)\n        total_dist_sum = 0.0\n\n        for t in T:\n            # Case 1: Target is not present in the tissue\n            if t not in nodes_present:\n                total_dist_sum += d_max\n                continue\n\n            # Case 2: Target is present, but disease module is empty in the tissue\n            if not D_context:\n                total_dist_sum += d_max\n                continue\n            \n            # Case 3: Target and disease nodes are present. Use BFS to find shortest paths.\n            q = deque([(t, 0)])\n            # distances from target t to other nodes in the context\n            distances = {node: float('inf') for node in nodes_present}\n            if t in distances:\n                distances[t] = 0\n\n            visited = {t}\n\n            while q:\n                u, dist = q.popleft()\n                for v in adj_list.get(u, []):\n                    if v not in visited:\n                        visited.add(v)\n                        distances[v] = dist + 1\n                        q.append((v, dist + 1))\n            \n            # Find min distance from t to D_context\n            min_dist_for_t = d_max\n            for d in D_context:\n                dist_td = distances.get(d, float('inf'))\n                if dist_td  min_dist_for_t:\n                    min_dist_for_t = dist_td\n            \n            total_dist_sum += min_dist_for_t\n\n        return total_dist_sum / len(T)\n\n    def process_case(case_data):\n        \"\"\"\n        Processes a single test case to compute the correlation.\n        \"\"\"\n        n, edges, T, D, tissues, tau, pte_vector = case_data\n        \n        # Calculate baseline proximity\n        all_nodes = set(range(n))\n        baseline_proximity = _calculate_proximity(n, edges, T, D, all_nodes)\n        \n        tissue_proximities = []\n        for tissue_expr in tissues:\n            nodes_present = {i for i, expr in enumerate(tissue_expr) if expr = tau}\n            tissue_prox = _calculate_proximity(n, edges, T, D, nodes_present)\n            tissue_proximities.append(tissue_prox)\n            \n        deltas = np.array(tissue_proximities) - baseline_proximity\n        neg_deltas = -deltas\n        \n        # Spearman correlation between -Delta and PTE\n        corr, _ = spearmanr(neg_deltas, pte_vector)\n        \n        # Handle case where correlation is undefined (NaN) due to no variance\n        if np.isnan(corr):\n            return 0.0\n        \n        return corr\n\n    # Test cases defined in the problem\n    test_cases = [\n        (\n            8,  # n\n            {(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (0, 7), (1, 5), (2, 6)},  # E\n            {0, 5},  # T\n            {3, 7},  # D\n            [  # tissues expressions\n                [1.0, 0.8, 0.7, 0.9, 0.4, 1.0, 0.6, 1.0],\n                [0.9, 0.7, 0.8, 0.6, 0.9, 1.0, 0.8, 0.3],\n                [0.4, 0.6, 0.9, 1.0, 0.7, 1.0, 0.9, 0.9],\n            ],\n            0.5,  # tau\n            [0.6, 0.2, 0.1]  # PTE vector\n        ),\n        (\n            6,  # n\n            {(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (1, 4)},  # E\n            {1, 4},  # T\n            {0, 5},  # D\n            [  # tissues expressions\n                [0.2, 1.0, 0.9, 0.9, 1.0, 0.8],\n                [0.9, 1.0, 0.8, 0.7, 0.9, 0.4],\n                [0.2, 1.0, 0.7, 0.7, 1.0, 0.4],\n            ],\n            0.5,  # tau\n            [0.5, 0.4, 0.0]  # PTE vector\n        ),\n        (\n            5,  # n\n            {(0, 1), (1, 2), (2, 3), (3, 4)},  # E\n            {0, 2},  # T\n            {3},  # D\n            [  # tissues expressions\n                [0.4, 0.4, 0.3, 0.9, 0.9],\n                [1.0, 0.4, 1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0, 1.0, 1.0],\n            ],\n            0.5,  # tau\n            [0.05, 0.4, 0.7]  # PTE vector\n        ),\n        (\n            6,  # n\n            {(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)},  # E\n            {2, 5},  # T\n            {2, 4},  # D\n            [  # tissues expressions\n                [1.0, 1.0, 0.4, 1.0, 1.0, 1.0],\n                [1.0, 1.0, 1.0, 1.0, 0.4, 1.0],\n                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n            ],\n            0.5,  # tau\n            [0.1, 0.4, 0.9]  # PTE vector\n        ),\n    ]\n\n    results = [process_case(case) for case in test_cases]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "4366944"}, {"introduction": "Calculating a proximity score is only the first step; to claim a meaningful relationship, we must demonstrate that the observed proximity is statistically significant. This requires comparing our result against a well-defined null model that represents what we would expect to see by chance. This exercise [@problem_id:4366983] explores the crucial conceptual distinction between two common null models—label permutation and edge rewiring—forcing you to analyze how each one controls for different aspects of network topology and why this choice is fundamental to the scientific validity of your conclusions.", "problem": "A human protein-protein interaction network (Protein-Protein Interaction (PPI) network) is modeled as a simple, connected graph $G = (V,E)$, where $V$ is the set of proteins and $E$ is the set of physical interactions. Let $|V| = N$, and let $d(u,v)$ denote the unweighted shortest path distance between nodes $u \\in V$ and $v \\in V$. Consider a drug characterized by a set of targets $T \\subset V$ with $|T| = m$, and a disease characterized by a set of associated genes $S \\subset V$ with $|S| = n$. A widely used drug-disease network proximity is defined as the average cross shortest path distance\n$$\n\\Delta(T,S) = \\frac{1}{mn}\\sum_{t \\in T}\\sum_{s \\in S} d(t,s).\n$$\nYou aim to test whether the observed $\\Delta(T,S)$ is significantly smaller than expected by chance, indicating proximity between the drug targets and disease genes. Two null models are under consideration:\n\nNull Model 1 (Label-Permutation Null): On the fixed network $G$, randomize the labels by sampling $T' \\subset V$ with $|T'| = m$ and $S' \\subset V$ with $|S'| = n$ under a degree-matching constraint such that the empirical degree distributions of $T'$ and $S'$ match those of $T$ and $S$ (within allowable tolerance), and compute $\\Delta(T',S')$ over many realizations to obtain an empirical expectation.\n\nNull Model 2 (Edge-Rewiring Null): Generate surrogates $G'$ by degree-preserving edge rewiring (configuration-like rewiring that preserves the degree sequence exactly), compute $\\Delta(T,S)$ on each $G'$, and aggregate to obtain an empirical expectation.\n\nStarting from the definitions of shortest path distance on graphs, the meaning of degree sequence preservation, and the role of higher-order topology (e.g., clustering, assortativity, and modularity) in determining path length distributions, analyze which null better controls for network topology when testing drug-disease proximity. Your analysis must begin from these core definitions and proceed by deriving expressions for the expected proximity under each null and by explaining how network features beyond the degree sequence influence $\\Delta(T,S)$.\n\nTo ground the analysis, consider the following scientifically plausible scenario: A human PPI network has $N = 5000$, an average degree $\\langle k \\rangle \\approx 8$, an empirical average pairwise shortest path distance across all node pairs of $\\bar{d}_G \\approx 3.2$, high clustering coefficient, and modular community structure. Under degree-preserving rewiring, the surrogate networks $G'$ reduce clustering and partially disrupt modularity, yielding an empirical average pairwise shortest path distance $\\bar{d}_{G'} \\approx 2.7$ with similar diameter quantiles. For a particular drug and disease, the observed proximity is $\\Delta(T,S) = 2.9$ with $m = 20$ and $n = 30$.\n\nWhich statement is most accurate for controlling network topology in the statistical test of drug-disease proximity?\n\nA. Label-permutation with degree matching better controls for network topology because it holds $G$ fixed, preserving all path distances $d(u,v)$ induced by clustering and modularity, while adjusting for degree-driven selection bias in $T$ and $S$, thus estimating the expected $\\Delta$ against the actual topology of $G$.\n\nB. Edge-rewiring with degree preservation better controls for network topology because it removes biases from clustering and community structure, leaving only degree effects; therefore it provides the most neutral baseline for $\\Delta$ on any network.\n\nC. If the degree sequence is preserved, both nulls are equivalent with respect to controlling topology, since shortest path distances depend only on the degree sequence.\n\nD. Label-permutation without degree matching is preferable for topology control because $T'$ and $S'$ are sampled uniformly, thereby canceling degree effects and community structure simultaneously on $G$.\n\nE. Combining both nulls by requiring significance under label-permutation on $G$ and edge-rewiring on $G'$ provides strictly better topology control than either alone because any discrepancy across nulls reflects true biological signal rather than structural artifacts.\n\nSelect the single best option that correctly characterizes the null model that better controls for network topology in this context and justify your choice using the provided scenario and first-principles reasoning on graphs and shortest paths.", "solution": "The problem asks for an analysis of two null models for assessing the statistical significance of drug-disease proximity in a protein-protein interaction (PPI) network. The core of the task is to determine which null model better controls for network topology.\n\n### Step 1: Problem Validation\n\nI will first extract the given information and validate the problem statement.\n\n**Givens:**\n1.  **Network Model:** A simple, connected graph $G = (V,E)$, where $V$ is the set of proteins and $E$ is the set of physical interactions.\n2.  **Network Size:** $|V| = N$.\n3.  **Distance Metric:** $d(u,v)$ is the unweighted shortest path distance between nodes $u, v \\in V$.\n4.  **Drug/Disease Sets:** A drug is represented by its target set $T \\subset V$ with size $|T| = m$. A disease is represented by its associated gene set $S \\subset V$ with size $|S| = n$.\n5.  **Proximity Measure:** The average cross shortest path distance is defined as $\\Delta(T,S) = \\frac{1}{mn}\\sum_{t \\in T}\\sum_{s \\in S} d(t,s)$.\n6.  **Hypothesis Test:** The goal is to test if the observed $\\Delta(T,S)$ is significantly smaller than expected by chance.\n7.  **Null Model 1 (Label-Permutation):** On the fixed graph $G$, random sets $T'$ and $S'$ are sampled with $|T'| = m$ and $|S'| = n$ under a degree-matching constraint. The null distribution is formed from $\\Delta(T',S')$.\n8.  **Null Model 2 (Edge-Rewiring):** The sets $T$ and $S$ are fixed, but the graph $G$ is randomized into surrogate graphs $G'$ via degree-preserving edge rewiring. The null distribution is formed from $\\Delta(T,S)$ computed on each $G'$.\n9.  **Scenario Data:**\n    *   $N = 5000$.\n    *   Average degree $\\langle k \\rangle \\approx 8$.\n    *   Average pairwise shortest path distance on $G$: $\\bar{d}_G \\approx 3.2$.\n    *   $G$ has high clustering and modular community structure.\n    *   Surrogate graphs $G'$ from rewiring have reduced clustering and modularity.\n    *   Average pairwise shortest path distance on $G'$: $\\bar{d}_{G'} \\approx 2.7$.\n    *   Observed proximity for a specific case: $\\Delta(T,S) = 2.9$.\n    *   Set sizes: $m = 20$, $n = 30$.\n\n**Validation:**\n1.  **Scientific Groundedness:** The problem is firmly rooted in network science and systems biomedicine. The modeling of PPI networks as graphs, the use of shortest path distance for proximity, and the application of null models for statistical testing are standard and well-established methodologies. The two null models described—label permutation with degree matching and degree-preserving edge rewiring—are canonical approaches in network analysis.\n2.  **Well-Posedness:** The question is precise: \"analyze which null better controls for network topology\". The definitions are clear and the provided scenario data are consistent and serve to illustrate the core concepts. A unique, reasoned answer can be derived.\n3.  **Objectivity:** The problem is stated in objective, formal language without subjective or biased phrasing.\n\n**Verdict:** The problem statement is valid. It is scientifically sound, well-posed, objective, and complete. It presents a non-trivial conceptual challenge regarding the choice of statistical null models in network analysis. I will now proceed with the solution derivation.\n\n### Step 2: Derivation and Analysis\n\nThe central question is what it means to \"control for network topology\" in the context of this hypothesis test. The topology of the network $G$ encompasses all its structural features, from the local (degree sequence) to the meso-scale (clustering, motifs, community structure) and global (path length distribution, diameter). These features collectively determine the set of all pairwise shortest path distances $\\{d(u,v)\\}_{u,v \\in V}$. The proximity measure $\\Delta(T,S)$ is an average over a subset of these distances.\n\nThe purpose of a null model is to generate an ensemble of \"random\" configurations that share certain properties with the observed data, against which the observed statistic can be compared. An effective null model for this problem should preserve the structural context (the network topology) in which the biological hypothesis is being tested, while randomizing the specific element under investigation (the choice of genes/targets).\n\n**Analysis of Null Model 1 (Label-Permutation with Degree Matching)**\n\nThis model operates on the fixed, real network $G$. This means that the entire topological structure of the network—including its high clustering and modularity, as mentioned in the scenario—is preserved. The set of all possible shortest path distances $\\{d(u,v)\\}$ is invariant. The null hypothesis tests whether the specific sets of nodes $T$ and $S$ are significantly closer to each other than would be expected for randomly chosen sets $T'$ and $S'$ that have similar degree characteristics, *on this very same network*.\n\nThe expected value of the proximity under this null model, $E_{1}[\\Delta(T',S')]$, represents the average distance between two sets of nodes of size $m$ and $n$ with specified degree distributions on the graph $G$. This value will be influenced by the global path length properties of $G$. Given the scenario's $\\bar{d}_G \\approx 3.2$, we can anticipate $E_{1}[\\Delta(T',S')]$ to be near this value, modulated slightly by the degree-matching constraint (e.g., if $T$ and $S$ consist of high-degree hubs, the expected distance will be smaller than the global average).\n\nBy comparing the observed $\\Delta(T,S)$ to the distribution of $\\Delta(T',S')$, we are isolating the effect of the specific choice of nodes in $T$ and $S$ from the background structure of the network and from any potential sampling bias related to node degrees. This is the correct way to test for a specific, localized relationship within the fixed context of the biological network. Therefore, this model properly controls for the full network topology.\n\n**Analysis of Null Model 2 (Edge-Rewiring)**\n\nThis model fixes the node sets $T$ and $S$ but randomizes the network's edge structure, creating an ensemble of surrogate graphs $\\{G'\\}$. The only topological property that is strictly preserved is the degree sequence. As stated in the problem, higher-order structures like clustering and modularity, which are characteristic of real biological networks, are destroyed.\n\nThis destruction of topology has a direct and significant impact on shortest path distances. The process of rewiring transforms a structured, \"lumpy\" network into a more homogeneous, random one. In such random graphs, shortcuts are more plentiful, leading to a general decrease in path lengths. The scenario quantifies this effect: the average path length drops from $\\bar{d}_G \\approx 3.2$ to $\\bar{d}_{G'} \\approx 2.7$.\n\nThe expected value of the proximity under this null, $E_{2}[\\Delta(T,S)_{\\text{on } G'}]$, will therefore be centered around $\\bar{d}_{G'} \\approx 2.7$. The null hypothesis here asks: \"Is the distance between the fixed sets $T$ and $S$ on the real network $G$ different from their expected distance on a random graph that only shares the same degree sequence?\"\n\nIn our scenario, the observed proximity is $\\Delta(T,S) = 2.9$. Comparing this to the null expectation of $\\approx 2.7$, we find that the observed value is *larger* than the expectation. This test would fail to find significant proximity; it might even conclude that the nodes are significantly *separated*. This counter-intuitive result arises because the null model has created a baseline where everything is artificially close. The test is no longer about the relationship between $T$ and $S$. Instead, it is implicitly testing whether the real network's modularity and clustering (which are absent in $G'$) serve to increase path lengths relative to a random graph. This is a different scientific question and is not what is meant by testing for drug-disease proximity. This model fails to control for the relevant topological context; in fact, it actively obliterates it.\n\n**Conclusion of Analysis**\nNull Model 1 (Label-Permutation) is superior for controlling for network topology because it preserves the entire topological structure of the network $G$ as the context for the test. Null Model 2 (Edge-Rewiring) discards crucial higher-order topology, fundamentally altering the path length distribution and thus providing an inappropriate baseline for comparison.\n\n### Step 3: Evaluation of Options\n\n**A. Label-permutation with degree matching better controls for network topology because it holds $G$ fixed, preserving all path distances $d(u,v)$ induced by clustering and modularity, while adjusting for degree-driven selection bias in $T$ and $S$, thus estimating the expected $\\Delta$ against the actual topology of $G$.**\nThis statement is a precise and correct summary of the analysis. It correctly identifies that holding $G$ fixed preserves the complete topology. It accurately describes the role of degree-matching in correcting for selection bias. It rightly concludes that this procedure establishes a null hypothesis benchmarked against the actual network structure. This option is **Correct**.\n\n**B. Edge-rewiring with degree preservation better controls for network topology because it removes biases from clustering and community structure, leaving only degree effects; therefore it provides the most neutral baseline for $\\Delta$ on any network.**\nThis statement mischaracterizes clustering and community structure as \"biases\" to be removed. In the context of a biological network, these features are fundamental aspects of its organization and function, not artifacts. Destroying them does not create a \"neutral baseline\" for the original network; it creates a baseline for a different, random network. The reasoning is flawed. This option is **Incorrect**.\n\n**C. If the degree sequence is preserved, both nulls are equivalent with respect to controlling topology, since shortest path distances depend only on the degree sequence.**\nThe premise of this statement is factually wrong. Shortest path distances do not depend only on the degree sequence. Two graphs with identical degree sequences can have vastly different structures (e.g., clustering, diameter, path length distributions). The provided scenario proves this with $\\bar{d}_G \\approx 3.2$ and $\\bar{d}_{G'} \\approx 2.7$ for graphs with the same degree sequence. Therefore, the conclusion that the nulls are equivalent is also false. This option is **Incorrect**.\n\n**D. Label-permutation without degree matching is preferable for topology control because $T'$ and $S'$ are sampled uniformly, thereby canceling degree effects and community structure simultaneously on $G$.**\nWhile label-permutation on a fixed $G$ correctly preserves the topology, omitting degree matching is a serious flaw. If the true sets $T$ and $S$ are biased towards high-degree nodes (a common scenario), comparing their proximity to that of uniformly random sets will likely produce a spurious significant result. The test would simply be detecting that hubs are close to each other, not a specific functional link. The claim that this \"cancel[s] ... community structure\" is also nonsensical; sampling does not alter the structure of $G$. This option proposes a weaker null model than the one described in the problem. This option is **Incorrect**.\n\n**E. Combining both nulls by requiring significance under label-permutation on $G$ and edge-rewiring on $G'$ provides strictly better topology control than either alone because any discrepancy across nulls reflects true biological signal rather than structural artifacts.**\nThis approach confounds two distinct statistical questions. As analyzed, the two nulls test different hypotheses. A discrepancy between their outcomes is not necessarily \"true biological signal\" but rather a reflection of the different properties being controlled for. In the provided scenario, a drug-disease pair could be significantly proximal under Null Model 1 but significantly separated (or not proximal) under Null Model 2. Requiring significance under both is an overly conservative and conceptually muddled strategy, not a \"strictly better\" one. This option is **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "4366983"}]}