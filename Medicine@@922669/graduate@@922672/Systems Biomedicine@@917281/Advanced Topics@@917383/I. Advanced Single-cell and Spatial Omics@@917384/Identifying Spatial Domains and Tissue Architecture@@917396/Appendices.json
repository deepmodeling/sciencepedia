{"hands_on_practices": [{"introduction": "The ability to identify distinct spatial domains in a tissue is fundamentally constrained by the resolution of our measurement technologies. Before we can analyze biological patterns, we must first understand the physical and information-theoretic limits of the instruments we use. This practice challenges you to think like an instrument designer by deriving the performance requirements for a spatial transcriptomics platform from first principles [@problem_id:4354059]. By synthesizing concepts from signal processing and sampling theory, you will determine the maximum spot size capable of resolving adjacent domains, gaining a concrete appreciation for how technology design directly impacts biological discovery.", "problem": "A spatial transcriptomics platform uses a regular array of circular capture spots of diameter $S$ laid out with pitch $p$ equal to the spot diameter (i.e., $p = S$ so spots do not overlap). In a tissue section, consider two adjacent spatial domains whose centroids along a one-dimensional transect are separated by a center-to-center distance $d$ (expressed in micrometers). Molecular assignment and diffusion during capture introduce a blur that can be approximated by a Gaussian point spread function (PSF) with standard deviation $\\sigma_{b}$ (in micrometers). Each spot integrates RNA counts over its area; along the transect, model this integration as a one-dimensional rectangular averaging kernel of width $S$.\n\nStarting from first principles of linear systems and sampling:\n\n- Convolution of independent kernels adds variances, so the effective PSF standard deviation $\\sigma_{\\mathrm{eff}}$ along the transect is given by the square root of the sum of the Gaussian blur variance and the variance of the rectangular kernel.\n- A widely used resolution criterion in imaging states that two identical peaks convolved with a Gaussian of standard deviation $\\sigma_{\\mathrm{eff}}$ are just resolvable when their separation equals $2 \\sigma_{\\mathrm{eff}}$.\n- The Shannon–Nyquist sampling theorem requires that to resolve features of scale $d$, the sampling pitch $p$ must satisfy $p \\leq d/2$.\n\nAssume $d  2 \\sigma_{b}$ so that resolution is physically possible after blurring. Using only the above principles and facts, derive a closed-form analytic expression for the largest permissible spot diameter $S_{\\max}$ (in micrometers) that still guarantees resolvability of the two adjacent domains given the separation $d$ and blur $\\sigma_{b}$. This $S_{\\max}$ is the strict upper bound on $S$ imposed by resolution constraints, and thus characterizes the minimal spot-diameter requirement of the platform in the sense that $S$ must not exceed $S_{\\max}$ to resolve the domains.\n\nExpress your final answer as a single analytic expression in terms of $d$ and $\\sigma_{b}$. No numerical evaluation is required.", "solution": "We model the measured signal along a one-dimensional transect crossing the boundary between two adjacent domains as the true underlying spatial signal convolved with two kernels: a Gaussian blur representing molecular diffusion and misassignment, and a rectangular averaging kernel representing spot integration. The convolution of two independent kernels with variances $\\sigma_{1}^{2}$ and $\\sigma_{2}^{2}$ has an effective variance equal to the sum $\\sigma_{1}^{2} + \\sigma_{2}^{2}$, because convolution corresponds to the sum of independent random variables in the probabilistic interpretation.\n\nFirst, we determine the variance contributed by the rectangular averaging kernel. A one-dimensional rectangular (uniform) kernel of width $S$ and unit area has a probability density function\n$$\nu(x) = \\begin{cases}\n\\frac{1}{S},  |x| \\leq \\frac{S}{2}, \\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nThe variance of a uniform distribution on the interval $\\left[-\\frac{S}{2}, \\frac{S}{2}\\right]$ is\n$$\n\\sigma_{\\mathrm{rect}}^{2} = \\frac{S^{2}}{12}.\n$$\nThe Gaussian blur is modeled as a zero-mean Gaussian kernel with variance $\\sigma_{b}^{2}$ (and standard deviation $\\sigma_{b}$). Therefore, the effective PSF standard deviation along the transect after convolving the Gaussian blur with the rectangular averaging kernel is\n$$\n\\sigma_{\\mathrm{eff}} = \\sqrt{\\sigma_{b}^{2} + \\sigma_{\\mathrm{rect}}^{2}} = \\sqrt{\\sigma_{b}^{2} + \\frac{S^{2}}{12}}.\n$$\n\nNext, we invoke a well-tested resolvability criterion for Gaussian-limited systems: two identical peaks are just resolvable when their center-to-center separation equals twice the standard deviation of the Gaussian PSF. This Rayleigh-like criterion for Gaussian responses is\n$$\nd_{\\mathrm{R}} = 2 \\sigma_{\\mathrm{eff}}.\n$$\nTo ensure resolvability of the two adjacent domains separated by $d$, we require\n$$\nd \\geq 2 \\sigma_{\\mathrm{eff}} = 2 \\sqrt{\\sigma_{b}^{2} + \\frac{S^{2}}{12}}.\n$$\nSolving this inequality for $S$ provides an upper bound on the spot diameter. Square both sides:\n$$\nd^{2} \\geq 4 \\left( \\sigma_{b}^{2} + \\frac{S^{2}}{12} \\right) = 4 \\sigma_{b}^{2} + \\frac{S^{2}}{3}.\n$$\nRearrange to isolate $S^{2}$:\n$$\n\\frac{S^{2}}{3} \\leq d^{2} - 4 \\sigma_{b}^{2} \\quad \\Longrightarrow \\quad S^{2} \\leq 3 \\left( d^{2} - 4 \\sigma_{b}^{2} \\right).\n$$\nHence, the Gaussian-resolvability constraint yields\n$$\nS \\leq \\sqrt{3 \\left( d^{2} - 4 \\sigma_{b}^{2} \\right)}.\n$$\nThis constraint is meaningful only if $d^{2} - 4 \\sigma_{b}^{2}  0$, i.e., $d  2 \\sigma_{b}$, which is assumed.\n\nIn addition to the blur-based resolvability, we must ensure that sampling by the spot lattice does not alias features at scale $d$. The Shannon–Nyquist sampling theorem stipulates that to resolve a feature of scale $d$, the sampling pitch $p$ must satisfy\n$$\np \\leq \\frac{d}{2}.\n$$\nSince the platform uses pitch equal to the spot diameter ($p = S$), this translates to\n$$\nS \\leq \\frac{d}{2}.\n$$\n\nFor the system to resolve the adjacent domains, both independent constraints must be satisfied simultaneously. Therefore, the largest permissible spot diameter $S_{\\max}$ is the minimum of the two upper bounds:\n$$\nS_{\\max}(d, \\sigma_{b}) = \\min \\left( \\frac{d}{2}, \\, \\sqrt{3 \\left( d^{2} - 4 \\sigma_{b}^{2} \\right)} \\right).\n$$\nThis expression gives the strict upper bound on the spot diameter imposed by resolution constraints (Gaussian-limited resolvability and Nyquist sampling). To guarantee resolvability, the platform must choose $S$ such that $S \\leq S_{\\max}(d, \\sigma_{b})$. Since the question asks for the largest permissible spot diameter that still guarantees resolution, the desired analytic expression is precisely $S_{\\max}(d, \\sigma_{b})$.", "answer": "$$\\boxed{\\min\\!\\left(\\frac{d}{2},\\,\\sqrt{3\\left(d^{2}-4\\sigma_{b}^{2}\\right)}\\right)}$$", "id": "4354059"}, {"introduction": "Once spatial data has been acquired, a crucial next step is to construct a model that captures the observed patterns and dependencies. This exercise delves into Gaussian Markov Random Fields (GMRFs), a powerful and widely-used framework in spatial statistics for applications like denoising and identifying domains. You will bridge theory and practice by first deriving the precision matrix of a Conditional Autoregressive (CAR) model, a popular GMRF specification, and then implementing code to analyze its properties [@problem_id:4354044]. This will build a deep understanding of how the model's mathematical structure encodes conditional independence and reflects the tissue's physical adjacency graph.", "problem": "Consider a spatial model for tissue architecture in systems biomedicine where tissue locations (e.g., spots or cells) are represented as nodes on a graph capturing physical adjacency. Let the adjacency be encoded by a symmetric, nonnegative, weighted matrix $W \\in \\mathbb{R}^{n \\times n}$ with $w_{ii} = 0$ and $w_{ij} = w_{ji} \\ge 0$. Define the degree of node $i$ as $d_i = \\sum_{j=1}^{n} w_{ij}$ and the degree matrix $D = \\operatorname{diag}(d_1,\\dots,d_n)$. Consider a Gaussian Markov Random Field (GMRF) prior specified via a Conditional Autoregressive (CAR) model: for each node $i$, the full conditional distribution is\n$$\nx_i \\mid x_{-i} \\sim \\mathcal{N}\\left(\\mu_i, \\sigma_i^2\\right),\n\\quad \\text{with} \\quad\n\\mu_i = \\frac{\\rho}{d_i} \\sum_{j \\neq i} w_{ij} x_j,\n\\quad\n\\sigma_i^2 = \\frac{1}{\\tau d_i},\n$$\nwhere $\\tau  0$ is a scalar precision parameter and $\\rho \\in [0,1]$ is a spatial smoothing parameter (with $\\rho = 1$ corresponding to the intrinsic CAR and $\\rho  1$ corresponding to a proper CAR under appropriate spectral bounds). Starting from the fundamental definition of the multivariate normal in canonical precision form and the structure of Gaussian conditional distributions, derive the joint precision matrix $Q \\in \\mathbb{R}^{n \\times n}$ for the GMRF implied by the above CAR conditionals. Using this derivation, implement an algorithm that, given $(W, \\tau, \\rho)$, constructs $Q$, and then evaluates how the sparsity pattern of $Q$ relates to the tissue adjacency graph defined by $W$.\n\nYour program must perform the following tasks for each test case $(W, \\tau, \\rho)$:\n1. Compute the precision matrix $Q$ implied by the CAR specification.\n2. Verify whether the off-diagonal sparsity pattern of $Q$ matches the adjacency pattern of $W$, i.e., check if for all $i \\neq j$, $Q_{ij} \\neq 0$ if and only if $w_{ij} \\neq 0$. Return a boolean.\n3. Count the total number of numerically nonzero entries of $Q$ (including diagonal), using a numerical tolerance of $10^{-12}$ on absolute values. Return an integer.\n4. Determine whether $Q$ is positive definite by verifying that all eigenvalues are strictly greater than $10^{-12}$. Return a boolean.\n5. Compute the nullity (dimension of the null space) of $Q$ by counting the number of eigenvalues less than or equal to $10^{-10}$. Return an integer.\n\nFundamental base to use in your derivation:\n- The canonical (precision) form of a multivariate normal distribution: a GMRF with precision matrix $Q$ has density $p(x) \\propto \\exp\\left(-\\frac{1}{2} x^\\top Q x\\right)$ with $Q$ symmetric and positive semidefinite for a valid distribution.\n- The structure of Gaussian conditional distributions in terms of the precision matrix: for a joint normal with precision $Q$, the conditional distribution of $x_i$ given $x_{-i}$ is Gaussian with variance $1/Q_{ii}$ and mean equal to a linear combination of $x_{-i}$ with coefficients determined by the off-diagonal entries of $Q$ and $Q_{ii}$.\n- The relation between conditional independence and zeros in the precision matrix: $Q_{ij} = 0$ implies that nodes $i$ and $j$ are conditionally independent given all other nodes.\n\nTest suite:\n- Case A (connected, proper CAR): $W$ is the unweighted $3 \\times 3$ grid with $4$-neighborhood adjacency, $\\tau = 2.0$, $\\rho = 0.4$.\n- Case B (connected, intrinsic CAR): $W$ is the same $3 \\times 3$ grid, $\\tau = 1.0$, $\\rho = 1.0$.\n- Case C (disconnected, intrinsic CAR): $W$ is the block-diagonal adjacency formed by two disjoint unweighted $2 \\times 2$ grids (each with $4$-neighborhood adjacency), $\\tau = 1.0$, $\\rho = 1.0$.\n- Case D (weighted chain, proper CAR): $W$ is a $1$-dimensional chain of length $5$ with edges $(1,2)$, $(2,3)$, $(3,4)$, $(4,5)$, unit weights except a weak boundary $w_{2,3} = 0.2$, $\\tau = 1.5$, $\\rho = 0.9$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list of the form $[\\text{boolean}, \\text{integer}, \\text{boolean}, \\text{integer}]$. The overall output is thus a list of lists in the form\n$$\n[\\,[b_1,i_1,b_2,i_2],\\,[b_1',i_1',b_2',i_2'],\\,\\ldots\\,].\n$$", "solution": "The objective is to derive the joint precision matrix $Q$ for a Gaussian Markov Random Field (GMRF) specified by a Conditional Autoregressive (CAR) model, and subsequently analyze the properties of $Q$ based on the tissue adjacency graph structure.\n\n### 1. Derivation of the Precision Matrix $Q$\n\nThe derivation begins with the fundamental definition of a multivariate normal distribution in its canonical form. For a random vector $x \\in \\mathbb{R}^n$, the probability density function (PDF) of a zero-mean GMRF is given by:\n$$\np(x) \\propto \\exp\\left(-\\frac{1}{2} x^\\top Q x\\right)\n$$\nwhere $Q \\in \\mathbb{R}^{n \\times n}$ is the symmetric, positive semidefinite precision matrix. The structure of this matrix encodes the conditional independence relationships between the variables.\n\nTo find the full conditional distribution of a single variable $x_i$ given all others $x_{-i} = (x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_n)^\\top$, we examine the terms in the quadratic form $x^\\top Q x$ that involve $x_i$.\n$$\nx^\\top Q x = \\sum_{k=1}^n \\sum_{l=1}^n Q_{kl} x_k x_l = Q_{ii} x_i^2 + 2x_i \\sum_{j \\neq i} Q_{ij} x_j + \\sum_{k \\neq i, l \\neq i} Q_{kl} x_k x_l\n$$\nThe terms involving $x_i$ are $Q_{ii} x_i^2 + 2x_i \\sum_{j \\neq i} Q_{ij} x_j$. The conditional PDF $p(x_i | x_{-i})$ is proportional to $\\exp(-\\frac{1}{2} (Q_{ii} x_i^2 + 2x_i \\sum_{j \\neq i} Q_{ij} x_j))$. We can complete the square with respect to $x_i$:\n$$\nQ_{ii} x_i^2 + 2x_i \\sum_{j \\neq i} Q_{ij} x_j = Q_{ii} \\left( x_i^2 + 2x_i \\frac{\\sum_{j \\neq i} Q_{ij} x_j}{Q_{ii}} \\right) = Q_{ii} \\left( x_i + \\frac{\\sum_{j \\neq i} Q_{ij} x_j}{Q_{ii}} \\right)^2 - \\text{terms not involving } x_i\n$$\nThe conditional distribution $p(x_i|x_{-i})$ is therefore a Gaussian distribution with parameters:\n- Conditional Mean: $E[x_i | x_{-i}] = -\\frac{1}{Q_{ii}} \\sum_{j \\neq i} Q_{ij} x_j$\n- Conditional Variance: $\\operatorname{Var}(x_i | x_{-i}) = \\frac{1}{Q_{ii}}$\n\nNext, we equate these general forms with the specific conditional distributions provided by the CAR model:\n$$\nx_i \\mid x_{-i} \\sim \\mathcal{N}\\left(\\mu_i, \\sigma_i^2\\right)\n\\quad \\text{with} \\quad\n\\mu_i = \\frac{\\rho}{d_i} \\sum_{j \\neq i} w_{ij} x_j\n\\quad \\text{and} \\quad\n\\sigma_i^2 = \\frac{1}{\\tau d_i}\n$$\nwhere $d_i = \\sum_{j=1}^n w_{ij}$.\n\nBy comparing the conditional variances, we find the diagonal elements of $Q$:\n$$\n\\frac{1}{Q_{ii}} = \\sigma_i^2 = \\frac{1}{\\tau d_i} \\implies Q_{ii} = \\tau d_i\n$$\n\nBy comparing the conditional means, we find the off-diagonal elements of $Q$:\n$$\n-\\frac{1}{Q_{ii}} \\sum_{j \\neq i} Q_{ij} x_j = \\mu_i = \\frac{\\rho}{d_i} \\sum_{j \\neq i} w_{ij} x_j\n$$\nSubstituting $Q_{ii} = \\tau d_i$:\n$$\n-\\frac{1}{\\tau d_i} \\sum_{j \\neq i} Q_{ij} x_j = \\frac{\\rho}{d_i} \\sum_{j \\neq i} w_{ij} x_j\n$$\nMultiplying by $-\\tau d_i$ gives:\n$$\n\\sum_{j \\neq i} Q_{ij} x_j = -\\tau \\rho \\sum_{j \\neq i} w_{ij} x_j\n$$\nSince this must hold for any vector $x_{-i}$, the coefficients of each $x_j$ (for $j \\neq i$) on both sides must be equal:\n$$\nQ_{ij} = -\\tau \\rho w_{ij} \\quad \\text{for } i \\neq j\n$$\n\nCombining the results for diagonal and off-diagonal entries, we can express the precision matrix $Q$ in matrix form. Let $D = \\operatorname{diag}(d_1, \\dots, d_n)$ be the diagonal degree matrix and $W$ be the adjacency matrix. The precision matrix is:\n$$\nQ = \\tau (D - \\rho W)\n$$\nThis derivation provides a direct formula to construct $Q$ from the given model parameters $W$, $\\tau$, and $\\rho$.\n\n### 2. Algorithmic Procedure and Property Analysis\n\nBased on the derived formula for $Q$, we can systematically address the problem's tasks.\n\n**Task 1: Compute the precision matrix $Q$.**\nThe algorithm is straightforward: given the matrix $W$ and scalars $\\tau$ and $\\rho$, first compute the degree of each node $d_i = \\sum_{j} w_{ij}$ to form the diagonal matrix $D$. Then, compute $Q$ using the formula $Q = \\tau (D - \\rho W)$.\n\n**Task 2: Verify the sparsity pattern.**\nThe off-diagonal entries of $Q$ are given by $Q_{ij} = -\\tau \\rho w_{ij}$ for $i \\neq j$. The problem states $\\tau  0$ and $\\rho \\in [0, 1]$. For the test cases, $\\rho  0$. Therefore, an off-diagonal entry $Q_{ij}$ is non-zero if and only if $w_{ij}$ is also non-zero. This confirms that the off-diagonal sparsity pattern of the precision matrix $Q$ is identical to that of the adjacency matrix $W$. This is a hallmark property of GMRFs, where zero entries in the precision matrix correspond to conditional independencies.\n\n**Task 3: Count numerically nonzero entries of $Q$.**\nSince $Q_{ii} = \\tau d_i$ and for any connected node, $d_i  0$ and $\\tau  0$, all diagonal entries of $Q$ will be non-zero. The non-zero off-diagonal entries directly correspond to the non-zero entries in $W$. The total count is thus $n$ (for the diagonal) plus the number of non-zero off-diagonal entries in $W$, which is twice the number of edges in the graph. The implementation will count all entries of $Q$ with an absolute value greater than a tolerance of $10^{-12}$.\n\n**Task 4  5: Determine positive definiteness and nullity.**\nThese properties are determined by analyzing the eigenvalues of $Q$. Since $Q$ is symmetric ($D$ is diagonal, and $W$ is symmetric), all its eigenvalues are real.\n- **Positive Definiteness**: $Q$ is positive definite if all its eigenvalues are strictly positive. The algorithm checks if all eigenvalues are greater than a tolerance of $10^{-12}$.\n- **Nullity**: The nullity of $Q$ is the dimension of its null space, which equals the number of eigenvalues that are zero. Numerically, this is counted as the number of eigenvalues less than or equal to a tolerance of $10^{-10}$.\n\nThe properties of $Q$ are critically dependent on the parameter $\\rho$:\n- If $\\rho = 1$ (intrinsic CAR), $Q = \\tau(D-W) = \\tau L$, where $L$ is the graph Laplacian. $L$ is known to be positive semidefinite. The nullity of $L$ is equal to the number of connected components in the graph defined by $W$. For a connected graph, the nullity is $1$, and $Q$ is not positive definite.\n- If $\\rho  1$ (proper CAR) and the graph is connected, $Q$ is generally positive definite, provided $\\rho$ satisfies certain spectral bounds related to $W$ and $D$. For the given test cases with $\\rho  1$, these conditions are met, leading to a positive definite $Q$ and zero nullity.\n\nThis framework allows us to translate the abstract CAR model specification into a concrete matrix $Q$ and analyze its structural and mathematical properties in relation to the underlying adjacency graph.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_grid_adjacency(height, width):\n    \"\"\"\n    Constructs an unweighted adjacency matrix for a grid graph with 4-neighborhood.\n    \"\"\"\n    n = height * width\n    W = np.zeros((n, n))\n    for r in range(height):\n        for c in range(width):\n            i = r * width + c\n            # Horizontal connection to the right\n            if c  width - 1:\n                j = i + 1\n                W[i, j] = W[j, i] = 1\n            # Vertical connection downwards\n            if r  height - 1:\n                j = i + width\n                W[i, j] = W[j, i] = 1\n    return W\n\ndef process_case(W, tau, rho):\n    \"\"\"\n    Performs all required computations for a single test case.\n    \"\"\"\n    n = W.shape[0]\n\n    # Task 1: Compute the precision matrix Q\n    d = W.sum(axis=1)\n    D = np.diag(d)\n    Q = tau * (D - rho * W)\n\n    # Task 2: Verify the off-diagonal sparsity pattern\n    # The derivation Q_ij = -tau * rho * w_ij shows that for tau, rho  0,\n    # the off-diagonal sparsity patterns must match. We verify this numerically.\n    q_is_nonzero_offdiag = np.abs(Q)  1e-12\n    np.fill_diagonal(q_is_nonzero_offdiag, False)\n    w_is_nonzero = np.abs(W)  1e-12\n    # w_ii is given as 0, so no need to touch the diagonal for W\n    sparsity_match = np.all(q_is_nonzero_offdiag == w_is_nonzero)\n\n    # Task 3: Count the total number of numerically nonzero entries of Q\n    nonzero_count = int(np.sum(np.abs(Q)  1e-12))\n\n    # For tasks 4 and 5, compute the eigenvalues of Q.\n    # Q is real and symmetric, so its eigenvalues are real. np.linalg.eigvalsh is efficient and stable.\n    eigenvalues = np.linalg.eigvalsh(Q)\n    \n    # Task 4: Determine whether Q is positive definite\n    is_pd = np.all(eigenvalues  1e-12)\n\n    # Task 5: Compute the nullity (dimension of the null space) of Q\n    nullity = int(np.sum(eigenvalues = 1e-10))\n\n    return [sparsity_match, nonzero_count, is_pd, nullity]\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run them, and print the results.\n    \"\"\"\n    # Case A: 3x3 grid, proper CAR\n    W_A = build_grid_adjacency(3, 3)\n    case_A = (W_A, 2.0, 0.4)\n\n    # Case B: 3x3 grid, intrinsic CAR\n    W_B = build_grid_adjacency(3, 3)\n    case_B = (W_B, 1.0, 1.0)\n\n    # Case C: Two disjoint 2x2 grids, intrinsic CAR\n    W_2x2 = build_grid_adjacency(2, 2)\n    W_C = np.block([\n        [W_2x2, np.zeros((4, 4))],\n        [np.zeros((4, 4)), W_2x2]\n    ])\n    case_C = (W_C, 1.0, 1.0)\n    \n    # Case D: Weighted chain, proper CAR.\n    # Nodes are 0-indexed: 0, 1, 2, 3, 4.\n    # The problem statement says w_{2,3}=0.2, which in 1-based indexing is the\n    # edge between node 2 and 3. This corresponds to the edge (1,2) in 0-based indexing.\n    W_D = np.zeros((5, 5))\n    edges = [(0, 1, 1.0), (1, 2, 0.2), (2, 3, 1.0), (3, 4, 1.0)]\n    for i, j, w in edges:\n        W_D[i, j] = W_D[j, i] = w\n    case_D = (W_D, 1.5, 0.9)\n\n    test_cases = [case_A, case_B, case_C, case_D]\n\n    results = []\n    for W_case, tau_case, rho_case in test_cases:\n        result = process_case(W_case, tau_case, rho_case)\n        results.append(result)\n\n    # Format the final output string to match the problem specification\n    # e.g., [[true,33,true,0],[true,33,false,1],...]\n    formatted_results = []\n    for res in results:\n        # Convert python boolean True/False to lowercase true/false\n        b1_str = str(res[0]).lower()\n        i1 = res[1]\n        b2_str = str(res[2]).lower()\n        i2 = res[3]\n        formatted_results.append(f\"[{b1_str},{i1},{b2_str},{i2}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4354044"}, {"introduction": "Beyond modeling observed patterns, a deeper understanding of tissue architecture comes from simulating the underlying biophysical processes that create it. This advanced practice explores the field of morphoelasticity, where spatially varying tissue growth generates mechanical stresses that can autonomously pattern a developing organ. You will implement a simple finite element model to simulate this process, predicting the emergence of domain boundaries from sharp gradients in elastic energy [@problem_id:4354088]. This exercise provides a powerful look at how systems-level properties and tissue architecture can arise from local cellular-level rules, connecting biological principles to continuum mechanics.", "problem": "Consider a thin, homogeneous elastic sheet occupying the unit square domain $\\Omega = [0,1] \\times [0,1]$ in dimensionless units. The sheet undergoes spatially varying growth that is modeled as an eigenstrain (growth strain) field $\\boldsymbol{\\varepsilon}^{g}(\\mathbf{x})$ superposed on small elastic deformations. The goal is to identify predicted spatial domain boundaries in the sheet that arise from gradients in elastic energy density induced by the growth field, using a simple finite element (FE) discretization.\n\nFundamental base and core definitions:\n- Assume small-strain, linear isotropic elasticity in plane stress for a thin sheet. The strain-displacement relation is $\\boldsymbol{\\varepsilon}(\\mathbf{u}) = \\mathbf{B}\\,\\mathbf{u}_{e}$ within each linear triangular element, where $\\mathbf{B}$ is the standard strain-displacement matrix constructed from shape function gradients and $\\mathbf{u}_{e}$ is the vector of nodal displacements for the element.\n- The elastic constitutive relation in Voigt notation for plane stress is $\\boldsymbol{\\sigma} = \\mathbf{D}\\,\\boldsymbol{\\varepsilon}^{e}$, where $\\boldsymbol{\\varepsilon}^{e} = \\boldsymbol{\\varepsilon}(\\mathbf{u}) - \\boldsymbol{\\varepsilon}^{g}$ is the elastic strain and\n$$\n\\mathbf{D} = \\frac{E}{1-\\nu^2}\n\\begin{bmatrix}\n1  \\nu  0 \\\\\n\\nu  1  0 \\\\\n0  0  \\frac{1-\\nu}{2}\n\\end{bmatrix},\n$$\nwith $E$ the Young’s modulus and $\\nu$ the Poisson’s ratio.\n- The total elastic energy density in an element is\n$$\nw = \\frac{1}{2}\\,\\boldsymbol{\\varepsilon}^{e\\,\\top} \\mathbf{D}\\, \\boldsymbol{\\varepsilon}^{e}.\n$$\n- The finite element equilibrium equations are obtained by minimizing the elastic energy functional $\\Pi(\\mathbf{u}) = \\frac{1}{2}\\int_{\\Omega} \\boldsymbol{\\varepsilon}^{e\\,\\top} \\mathbf{D}\\, \\boldsymbol{\\varepsilon}^{e}\\, \\mathrm{d}\\Omega$ subject to Dirichlet boundary conditions. In the discrete setting, this yields a linear system $\\mathbf{K}\\,\\mathbf{u} = \\mathbf{f}$, where $\\mathbf{K}$ is the global stiffness matrix assembled from element contributions and the equivalent nodal load vector due to growth is\n$$\n\\mathbf{f} = \\sum_{e} t\\,A_{e}\\,\\mathbf{B}^{\\top}\\mathbf{D}\\,\\boldsymbol{\\varepsilon}^{g}_{e},\n$$\nwith $t$ the sheet thickness and $A_{e}$ the element area. The sheet is anchored by imposing zero displacement on all nodes along the left boundary $x=0$ to remove rigid-body modes.\n\nDomain boundary identification principle:\n- Spatial domain boundaries are operationally defined as interior mesh edges across which the elastic energy density $w$ exhibits a large jump. Let $\\Delta w_{ij} = \\left| w_{i} - w_{j} \\right|$ denote the absolute difference in $w$ between two adjacent triangles sharing an interior edge. For a given threshold factor $\\tau  0$, classify an interior edge as a predicted domain boundary if $\\Delta w_{ij}  \\tau \\cdot \\mathrm{median}\\left(\\{ \\Delta w_{kl} \\}_{\\text{all interior edges}}\\right)$. This median-based criterion is robust to scale variations in $w$.\n\nNumerical discretization requirements:\n- Discretize $\\Omega$ with a uniform structured grid of $N_x \\times N_y$ nodes, subdividing each rectangular cell into two linear triangles using standard connectivity. Use element-wise constant $\\boldsymbol{\\varepsilon}^{g}_{e}$ evaluated at the element centroid. Take sheet thickness $t=1$ (dimensionless).\n- Use material parameters $E=1$ and $\\nu=0.3$ (dimensionless), and enforce Dirichlet boundary conditions $\\mathbf{u}=(0,0)$ for all nodes with $x=0$.\n- Compute the displacement field $\\mathbf{u}$ by assembling $\\mathbf{K}$ and $\\mathbf{f}$ and solving the linear system. Compute $w$ per element, determine the set of predicted domain boundary edges using the threshold rule above, and report the number of boundary edges and the $x$-coordinate of their centroid (mean of midpoints of flagged edges). If no edge is flagged, report the centroid $x$-coordinate as $-1.0$.\n\nTest suite:\n- Case $1$ (uniform isotropic growth): $N_x = 20$, $N_y = 20$, $\\tau = 3.0$, $\\boldsymbol{\\varepsilon}^{g}(x,y) = [0.01,\\,0.01,\\,0.0]$.\n- Case $2$ (piecewise growth with interior interface): $N_x = 20$, $N_y = 20$, $\\tau = 3.0$, $\\boldsymbol{\\varepsilon}^{g}(x,y) = [0.008,\\,0.008,\\,0.0]$ for $x  0.5$ and $\\boldsymbol{\\varepsilon}^{g}(x,y) = [0.02,\\,0.0,\\,0.0]$ for $x \\ge 0.5$.\n- Case $3$ (linearly varying growth): $N_x = 20$, $N_y = 20$, $\\tau = 3.0$, $\\boldsymbol{\\varepsilon}^{g}(x,y) = [0.03\\,x,\\,0.005,\\,0.0]$.\n\nAnswer specification:\n- For each case, compute the integer number of predicted domain boundary edges and the centroid $x$-coordinate of these edges as a float rounded to six decimal places (dimensionless). The final output must be a single line containing a comma-separated list of three sublists, each sublist formatted as $[N_{\\text{boundary}}, x_{\\text{centroid}}]$, enclosed in square brackets, for example: $[[12,0.503000],[5,0.250000],[8,0.742000]]$. No units should be included in the output.", "solution": "We begin from the small-strain, linear elastic setting for a thin sheet in plane stress. The core definitions establish the relation between displacement, strain, and stress, and the role of growth as an eigenstrain. In Voigt notation, the elastic constitutive matrix for plane stress is\n$$\n\\mathbf{D} = \\frac{E}{1-\\nu^2}\n\\begin{bmatrix}\n1  \\nu  0 \\\\\n\\nu  1  0 \\\\\n0  0  \\frac{1-\\nu}{2}\n\\end{bmatrix},\n$$\nwith $E$ the Young’s modulus and $\\nu$ the Poisson’s ratio. The elastic strain is defined by subtracting the growth strain from the kinematic strain, $\\boldsymbol{\\varepsilon}^{e} = \\boldsymbol{\\varepsilon}(\\mathbf{u}) - \\boldsymbol{\\varepsilon}^{g}$.\n\nPrinciple-based derivation of the discrete system:\n- The total elastic energy is\n$$\n\\Pi(\\mathbf{u}) = \\frac{1}{2}\\int_{\\Omega} \\boldsymbol{\\varepsilon}^{e\\,\\top} \\mathbf{D}\\, \\boldsymbol{\\varepsilon}^{e}\\, \\mathrm{d}\\Omega\n= \\frac{1}{2}\\int_{\\Omega} (\\boldsymbol{\\varepsilon}(\\mathbf{u}) - \\boldsymbol{\\varepsilon}^{g})^{\\top} \\mathbf{D}\\, (\\boldsymbol{\\varepsilon}(\\mathbf{u}) - \\boldsymbol{\\varepsilon}^{g})\\, \\mathrm{d}\\Omega.\n$$\nApplying the principle of stationary potential energy, we take the first variation $\\delta \\Pi = 0$ for admissible virtual displacements $\\delta \\mathbf{u}$, which yields after standard steps the weak form and, under a finite element discretization with linear triangular elements, the linear system\n$$\n\\mathbf{K}\\,\\mathbf{u} = \\mathbf{f},\n$$\nwhere the global stiffness matrix $\\mathbf{K}$ is assembled from element contributions\n$$\n\\mathbf{K}_{e} = t\\,A_{e}\\,\\mathbf{B}^{\\top}\\mathbf{D}\\,\\mathbf{B},\n$$\nwith $t$ the thickness and $A_{e}$ the element area, and the equivalent nodal load due to growth strain is\n$$\n\\mathbf{f}_{e} = t\\,A_{e}\\,\\mathbf{B}^{\\top}\\mathbf{D}\\,\\boldsymbol{\\varepsilon}^{g}_{e}.\n$$\nThese expressions follow directly by substituting $\\boldsymbol{\\varepsilon}(\\mathbf{u}) = \\mathbf{B}\\,\\mathbf{u}_{e}$ and noting that linear shape functions produce a constant strain per element. The sign convention arises from minimizing $\\Pi(\\mathbf{u})$; the cross term integrates to $-\\int \\boldsymbol{\\varepsilon}^{g\\,\\top}\\mathbf{D}\\,\\boldsymbol{\\varepsilon}(\\mathbf{u})\\,\\mathrm{d}\\Omega$, whose variation yields a positive contribution to the right-hand side.\n\nMesh and element operators:\n- We construct a uniform $N_x \\times N_y$ structured grid over $\\Omega$ with nodes at $(x_{i}, y_{j})$, and split each rectangular cell into two triangles. For each triangular element with nodes at $(x_{1},y_{1})$, $(x_{2},y_{2})$, $(x_{3},y_{3})$, the area is $A_{e} = \\frac{1}{2}\\left| x_{1}(y_{2}-y_{3}) + x_{2}(y_{3}-y_{1}) + x_{3}(y_{1}-y_{2}) \\right|$. The derivatives of the linear shape functions are constants:\n$$\n\\frac{\\partial N_{i}}{\\partial x} = \\frac{\\beta_{i}}{2A_{e}}, \\quad \\frac{\\partial N_{i}}{\\partial y} = \\frac{\\gamma_{i}}{2A_{e}},\n$$\nwith $\\beta_{1} = y_{2} - y_{3}$, $\\beta_{2} = y_{3} - y_{1}$, $\\beta_{3} = y_{1} - y_{2}$ and $\\gamma_{1} = x_{3} - x_{2}$, $\\gamma_{2} = x_{1} - x_{3}$, $\\gamma_{3} = x_{2} - x_{1}$. The strain-displacement matrix $\\mathbf{B}$ for plane stress in Voigt form is\n$$\n\\mathbf{B} =\n\\begin{bmatrix}\n\\frac{\\partial N_{1}}{\\partial x}  0  \\frac{\\partial N_{2}}{\\partial x}  0  \\frac{\\partial N_{3}}{\\partial x}  0 \\\\\n0  \\frac{\\partial N_{1}}{\\partial y}  0  \\frac{\\partial N_{2}}{\\partial y}  0  \\frac{\\partial N_{3}}{\\partial y} \\\\\n\\frac{\\partial N_{1}}{\\partial y}  \\frac{\\partial N_{1}}{\\partial x}  \\frac{\\partial N_{2}}{\\partial y}  \\frac{\\partial N_{2}}{\\partial x}  \\frac{\\partial N_{3}}{\\partial y}  \\frac{\\partial N_{3}}{\\partial x}\n\\end{bmatrix}.\n$$\n\nBoundary conditions and solution:\n- To eliminate rigid-body modes, impose Dirichlet boundary conditions $\\mathbf{u}=(0,0)$ for all nodes with $x=0$. In the discrete system, this is enforced by modifying rows and columns corresponding to fixed degrees of freedom and setting the diagonal to one with a zero right-hand side for those degrees of freedom. The equilibrium displacement vector $\\mathbf{u}$ is then obtained by solving $\\mathbf{K}\\mathbf{u}=\\mathbf{f}$.\n\nEnergy density computation:\n- For each element, compute the elastic strain as\n$$\n\\boldsymbol{\\varepsilon}^{e}_{e} = \\mathbf{B}\\,\\mathbf{u}_{e} - \\boldsymbol{\\varepsilon}^{g}_{e},\n$$\nand the corresponding elastic energy density\n$$\nw_{e} = \\frac{1}{2}\\,\\boldsymbol{\\varepsilon}^{e\\,\\top}_{e}\\,\\mathbf{D}\\,\\boldsymbol{\\varepsilon}^{e}_{e}.\n$$\n\nPredicted domain boundaries:\n- Construct the set of interior edges using triangle connectivity. For any interior edge shared by triangles $i$ and $j$, compute $\\Delta w_{ij} = |w_{i} - w_{j}|$. Let $m$ be the median of all $\\Delta w_{ij}$ values (considering only interior edges). An interior edge is flagged as a predicted domain boundary if $\\Delta w_{ij}  \\tau \\cdot m$. The domain boundary centroid in the $x$-direction is computed as the mean of the $x$-coordinates of the midpoints of all flagged edges. If no edges are flagged, report $x_{\\text{centroid}} = -1.0$.\n\nTest suite implementation details:\n- Use $E=1$, $\\nu=0.3$, and $t=1$ (all dimensionless). Use $N_x=20$, $N_y=20$, and $\\tau=3.0$ for all cases.\n- Growth strain fields:\n  - Case $1$: $\\boldsymbol{\\varepsilon}^{g}(x,y) = [0.01,\\,0.01,\\,0.0]$ (uniform isotropic).\n  - Case $2$: $\\boldsymbol{\\varepsilon}^{g}(x,y) = [0.008,\\,0.008,\\,0.0]$ for $x0.5$ and $\\boldsymbol{\\varepsilon}^{g}(x,y) = [0.02,\\,0.0,\\,0.0]$ for $x\\ge 0.5$ (piecewise with interior interface).\n  - Case $3$: $\\boldsymbol{\\varepsilon}^{g}(x,y) = [0.03\\,x,\\,0.005,\\,0.0]$ (linearly varying).\n\nAlgorithmic steps summary:\n- Generate the mesh and triangle connectivity.\n- Assemble $\\mathbf{K}$ and $\\mathbf{f}$ using $\\mathbf{B}$ and $\\boldsymbol{\\varepsilon}^{g}_{e}$ at centroids.\n- Apply Dirichlet constraints along $x=0$ and solve for $\\mathbf{u}$.\n- Compute $w_{e}$ for all elements.\n- Build interior edge adjacency and compute $\\Delta w_{ij}$ for all interior edges.\n- Flag domain boundary edges using the median threshold criterion and compute the centroid $x$-coordinate.\n- Output for each case the pair $[N_{\\text{boundary}}, x_{\\text{centroid}}]$ with $x_{\\text{centroid}}$ rounded to six decimal places, aggregated on one line as specified.\n\nThis design integrates fundamental elasticity and growth principles into a reproducible computational procedure for identifying domain boundaries implied by tissue growth-induced stresses and energy gradients, consistent with systems biomedicine analysis of spatial domains and tissue architecture under morphoelastic effects.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import coo_matrix, lil_matrix, csc_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef generate_mesh(nx, ny):\n    \"\"\"\n    Generate a structured grid on [0,1]x[0,1] with nx x ny nodes,\n    and triangulate each cell into two triangles.\n    Returns:\n        nodes: (N,2) array of coordinates\n        elems: list of triangles, each as a tuple of 3 node indices\n    \"\"\"\n    xs = np.linspace(0.0, 1.0, nx)\n    ys = np.linspace(0.0, 1.0, ny)\n    xv, yv = np.meshgrid(xs, ys, indexing='xy')\n    nodes = np.column_stack([xv.ravel(), yv.ravel()])\n    elems = []\n    def idx(i, j):\n        return j * nx + i\n    for j in range(ny - 1):\n        for i in range(nx - 1):\n            n00 = idx(i, j)\n            n10 = idx(i + 1, j)\n            n01 = idx(i, j + 1)\n            n11 = idx(i + 1, j + 1)\n            # Split into two triangles: (n00, n10, n11) and (n00, n11, n01)\n            elems.append((n00, n10, n11))\n            elems.append((n00, n11, n01))\n    return nodes, elems\n\ndef compute_B_and_area(tri_coords):\n    \"\"\"\n    Compute the B matrix and area for a linear triangular element.\n    tri_coords: (3,2) array with coordinates of the triangle nodes (x,y).\n    Returns:\n        B: (3,6) strain-displacement matrix\n        area: scalar area\n    \"\"\"\n    x1, y1 = tri_coords[0]\n    x2, y2 = tri_coords[1]\n    x3, y3 = tri_coords[2]\n    # Area (signed) and then absolute value\n    det = x1*(y2 - y3) + x2*(y3 - y1) + x3*(y1 - y2)\n    area = 0.5 * abs(det)\n    if area = 1e-14:\n        # Degenerate triangle; return zeros\n        return np.zeros((3,6)), 0.0\n\n    beta1 = y2 - y3\n    beta2 = y3 - y1\n    beta3 = y1 - y2\n    gamma1 = x3 - x2\n    gamma2 = x1 - x3\n    gamma3 = x2 - x1\n\n    dN1_dx = beta1 / (2.0 * area)\n    dN2_dx = beta2 / (2.0 * area)\n    dN3_dx = beta3 / (2.0 * area)\n    dN1_dy = gamma1 / (2.0 * area)\n    dN2_dy = gamma2 / (2.0 * area)\n    dN3_dy = gamma3 / (2.0 * area)\n\n    B = np.array([\n        [dN1_dx, 0.0,      dN2_dx, 0.0,      dN3_dx, 0.0     ],\n        [0.0,     dN1_dy,  0.0,     dN2_dy,  0.0,     dN3_dy ],\n        [dN1_dy,  dN1_dx,  dN2_dy,  dN2_dx,  dN3_dy,  dN3_dx ]\n    ])\n    return B, area\n\ndef plane_stress_D(E, nu):\n    \"\"\"\n    Constitutive matrix for plane stress in Voigt form.\n    \"\"\"\n    coef = E / (1.0 - nu**2)\n    D = coef * np.array([\n        [1.0, nu,  0.0],\n        [nu,  1.0, 0.0],\n        [0.0, 0.0, (1.0 - nu) / 2.0]\n    ])\n    return D\n\ndef assemble_system(nodes, elems, growth_func, D, thickness=1.0):\n    \"\"\"\n    Assemble global stiffness matrix K and growth-induced load vector f.\n    Returns:\n        K: sparse (2N x 2N) CSC matrix\n        f: (2N,) vector\n        B_list: list of B matrices per element\n        area_list: list of areas per element\n        elem_nodes: list of node index tuples per element\n        eps_g_list: (n_elems,3) array of eigenstrain per element\n    \"\"\"\n    n_nodes = nodes.shape[0]\n    n_dofs = 2 * n_nodes\n    data = []\n    rows = []\n    cols = []\n    f = np.zeros(n_dofs)\n    B_list = []\n    area_list = []\n    eps_g_list = []\n\n    for e_idx, tri in enumerate(elems):\n        tri_coords = nodes[np.array(tri)]\n        B, area = compute_B_and_area(tri_coords)\n        B_list.append(B)\n        area_list.append(area)\n        if area == 0.0:\n            eps_g = np.zeros(3)\n            eps_g_list.append(eps_g)\n            continue\n        # Element centroid\n        cx = np.mean(tri_coords[:, 0])\n        cy = np.mean(tri_coords[:, 1])\n        eps_g = np.array(growth_func(cx, cy), dtype=float)\n        eps_g_list.append(eps_g)\n\n        # Element stiffness and equivalent nodal load due to growth\n        Ke = thickness * area * (B.T @ D @ B)\n        fe = thickness * area * (B.T @ D @ eps_g)\n\n        # Assemble into global K and f\n        elem_dofs = []\n        for n in tri:\n            elem_dofs.extend([2 * n, 2 * n + 1])  # u_x, u_y\n        # Add Ke contributions\n        for i_local, i_global in enumerate(elem_dofs):\n            for j_local, j_global in enumerate(elem_dofs):\n                rows.append(i_global)\n                cols.append(j_global)\n                data.append(Ke[i_local, j_local])\n        # Add fe contributions\n        for i_local, i_global in enumerate(elem_dofs):\n            f[i_global] += fe[i_local]\n\n    K = coo_matrix((data, (rows, cols)), shape=(n_dofs, n_dofs)).tocsc()\n    return K, f, B_list, area_list, elems, np.array(eps_g_list)\n\ndef apply_dirichlet_left_boundary(K, f, nodes, tol=1e-12):\n    \"\"\"\n    Apply u=0, v=0 on all nodes with x=0 (within tolerance).\n    Modify K and f in place.\n    \"\"\"\n    n_nodes = nodes.shape[0]\n    fixed_dofs = []\n    for idx in range(n_nodes):\n        x = nodes[idx, 0]\n        if abs(x - 0.0) = tol:\n            fixed_dofs.append(2 * idx)     # u_x\n            fixed_dofs.append(2 * idx + 1) # u_y\n\n    K_lil = K.tolil()\n    for dof in fixed_dofs:\n        # Zero row and column, set diagonal to 1, RHS to 0\n        K_lil.rows[dof] = [dof]\n        K_lil.data[dof] = [1.0]\n        f[dof] = 0.0\n        # Zero column entries\n        # Iterate over all rows to set K[i, dof] = 0\n        for i in range(K_lil.shape[0]):\n            if i != dof:\n                K_lil[i, dof] = 0.0\n    return K_lil.tocsc(), f\n\ndef solve_system(K, f):\n    \"\"\"\n    Solve K u = f for u.\n    \"\"\"\n    u = spsolve(K, f)\n    return u\n\ndef compute_element_energy(B_list, area_list, elems, nodes, D, u, eps_g_list, thickness=1.0):\n    \"\"\"\n    Compute elastic energy density per element.\n    Returns:\n        w_list: list of energy densities per element\n    \"\"\"\n    w_list = []\n    for e_idx, tri in enumerate(elems):\n        area = area_list[e_idx]\n        if area == 0.0:\n            w_list.append(0.0)\n            continue\n        B = B_list[e_idx]\n        eps_g = eps_g_list[e_idx]\n        # Gather element DOFs\n        elem_dofs = []\n        for n in tri:\n            elem_dofs.extend([2 * n, 2 * n + 1])\n        u_e = u[np.array(elem_dofs)]\n        eps_e = B @ u_e - eps_g\n        w = 0.5 * (eps_e.T @ D @ eps_e)  # energy density\n        w_list.append(float(w))\n    return np.array(w_list)\n\ndef build_edge_adjacency(elems):\n    \"\"\"\n    Build mapping from edges (sorted node index pair) to list of adjacent triangle indices.\n    Returns:\n        edge_to_tris: dict { (n1,n2): [t_idx_1, t_idx_2?] }\n    \"\"\"\n    edge_to_tris = {}\n    for t_idx, tri in enumerate(elems):\n        i, j, k = tri\n        edges = [(min(i, j), max(i, j)), (min(j, k), max(j, k)), (min(k, i), max(k, i))]\n        for e in edges:\n            if e not in edge_to_tris:\n                edge_to_tris[e] = [t_idx]\n            else:\n                edge_to_tris[e].append(t_idx)\n    return edge_to_tris\n\ndef detect_domain_boundaries(nodes, w_list, edge_to_tris, tau):\n    \"\"\"\n    Detect boundary edges based on median threshold of energy differences.\n    Returns:\n        boundary_edges: list of edges ((n1,n2))\n        x_centroid: mean x of midpoints of boundary edges; -1.0 if none\n    \"\"\"\n    diffs = []\n    interior_edges = []\n    for edge, tris in edge_to_tris.items():\n        if len(tris) == 2:\n            t1, t2 = tris\n            dw = abs(w_list[t1] - w_list[t2])\n            diffs.append(dw)\n            interior_edges.append((edge, dw))\n    if len(diffs) == 0:\n        return [], -1.0\n    diffs_arr = np.array(diffs)\n    # Median of positive differences to avoid zero-only cases\n    positive_diffs = diffs_arr[diffs_arr  0.0]\n    if positive_diffs.size  0:\n        m = float(np.median(positive_diffs))\n    else:\n        m = 0.0\n    threshold = tau * m\n    boundary_edges = [edge for edge, dw in interior_edges if dw  threshold]\n    if len(boundary_edges) == 0:\n        return [], -1.0\n    # Compute centroid in x of midpoints\n    x_mids = []\n    for n1, n2 in boundary_edges:\n        xmid = 0.5 * (nodes[n1, 0] + nodes[n2, 0])\n        x_mids.append(xmid)\n    x_centroid = float(np.mean(x_mids))\n    return boundary_edges, x_centroid\n\ndef case_growth_functions():\n    \"\"\"\n    Define growth strain functions for the three test cases.\n    Returns a list of callables growth_func(x, y) - [exx, eyy, exy]\n    \"\"\"\n    def g1(x, y):\n        return [0.01, 0.01, 0.0]\n\n    def g2(x, y):\n        if x  0.5:\n            return [0.008, 0.008, 0.0]\n        else:\n            return [0.02, 0.0, 0.0]\n\n    def g3(x, y):\n        return [0.03 * x, 0.005, 0.0]\n\n    return [g1, g2, g3]\n\ndef run_case(nx, ny, tau, growth_func, E=1.0, nu=0.3, thickness=1.0):\n    nodes, elems = generate_mesh(nx, ny)\n    D = plane_stress_D(E, nu)\n    K, f, B_list, area_list, elem_nodes, eps_g_list = assemble_system(nodes, elems, growth_func, D, thickness=thickness)\n    K_bc, f_bc = apply_dirichlet_left_boundary(K, f, nodes, tol=1e-12)\n    u = solve_system(K_bc, f_bc)\n    w_list = compute_element_energy(B_list, area_list, elem_nodes, nodes, D, u, eps_g_list, thickness=thickness)\n    edge_to_tris = build_edge_adjacency(elem_nodes)\n    boundary_edges, x_centroid = detect_domain_boundaries(nodes, w_list, edge_to_tris, tau)\n    N_boundary = len(boundary_edges)\n    return N_boundary, x_centroid\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (nx, ny, tau, growth_func)\n        (20, 20, 3.0, case_growth_functions()[0]),  # Case 1\n        (20, 20, 3.0, case_growth_functions()[1]),  # Case 2\n        (20, 20, 3.0, case_growth_functions()[2]),  # Case 3\n    ]\n\n    results = []\n    for nx, ny, tau, gfunc in test_cases:\n        N_boundary, x_centroid = run_case(nx, ny, tau, gfunc, E=1.0, nu=0.3, thickness=1.0)\n        results.append((N_boundary, x_centroid))\n\n    # Build the exact required format: a single line with nested lists and x rounded to six decimals.\n    formatted = \"[\" + \",\".join([f\"[{n},{x:.6f}]\" if np.isfinite(x) else f\"[{n},-1.000000]\" for n, x in results]) + \"]\"\n    print(formatted)\n\nsolve()\n```", "id": "4354088"}]}