{"hands_on_practices": [{"introduction": "Before committing significant resources to a single-cell experiment, it is crucial to ensure the experimental design has sufficient statistical power to achieve its goals. A primary concern is determining the required sample size, or number of cells to sequence, especially when the target is a rare cell population. This practice grounds this practical design question in fundamental probability theory, modeling cell capture as a series of independent Bernoulli trials to derive the relationship between sampling depth ($N$), population frequency ($f$), and the probability of detection. This exercise builds the essential skill of performing *a priori* power calculations to design cost-effective and successful experiments [@problem_id:4377566].", "problem": "A single-cell RNA sequencing (scRNA-seq) experiment aims to detect a rare cell type present at population frequency $f$ in a large, well-mixed tissue. Assume the following conditions hold: each captured cell is an independent and identically distributed Bernoulli trial for being of the rare type with success probability $f$, the sampling is unbiased with respect to cell type, and classification of a captured rare cell is perfect. Starting only from these assumptions and core principles of probability for independent Bernoulli trials, derive the probability that sampling $N$ cells yields detection of at least one rare cell as a function of $f$ and $N$. Then, by inverting your expression, derive an analytic expression for the smallest integer $N$ such that the detection probability is at least a user-specified target $P^{\\star}$ with $0  P^{\\star}  1$. Finally, evaluate your expression for $f = 7 \\times 10^{-5}$ and $P^{\\star} = 0.975$, and report the smallest integer $N$ that satisfies the criterion. Provide the final $N$ as an integer with no units. No rounding by significant figures is required because the requested $N$ is an integer.", "solution": "The problem statement will first be validated against the required criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   Population frequency of a rare cell type: $f$\n-   Each captured cell is an independent and identically distributed (i.i.d.) Bernoulli trial for being of the rare type with success probability $f$.\n-   Sampling is unbiased with respect to cell type.\n-   Classification of a captured rare cell is perfect.\n-   Total number of cells sampled: $N$\n-   Target detection probability: $P^{\\star}$\n-   Constraint on target probability: $0  P^{\\star}  1$\n-   Numerical value for frequency: $f = 7 \\times 10^{-5}$\n-   Numerical value for target probability: $P^{\\star} = 0.975$\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is firmly grounded in probability theory, specifically the binomial distribution derived from i.i.d. Bernoulli trials. This is a standard and fundamental model used in designing single-cell sequencing experiments to estimate the required sample size for detecting rare populations. The assumptions (unbiased sampling, perfect classification) are idealizations but are standard for formulating a baseline model.\n-   **Well-Posed:** The problem is well-posed. It asks for the derivation of a probability, the inversion of that formula to find a minimal sample size, and a specific numerical calculation. All necessary parameters ($f$, $P^{\\star}$) are provided, and the objective is clear, leading to a unique, stable, and meaningful solution.\n-   **Objective:** The language is formal, precise, and devoid of subjective or opinion-based statements.\n-   **Other Flaws:** The problem does not exhibit any other flaws such as being incomplete, contradictory, unrealistic, ill-posed, or trivial. The values provided are within a realistic range for biological experiments of this nature.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\n\nLet the event of capturing a rare cell be a \"success\" and the event of capturing a common cell be a \"failure.\" According to the problem statement, each of the $N$ cell captures is an independent Bernoulli trial with a probability of success $f$.\n\nLet $X$ be the random variable representing the number of rare cells detected in a sample of $N$ cells. Under the given assumptions, $X$ follows a binomial distribution with parameters $N$ (number of trials) and $f$ (probability of success). The probability mass function is given by:\n$$P(X=k) = \\binom{N}{k} f^k (1-f)^{N-k}$$\nfor $k \\in \\{0, 1, 2, ..., N\\}$.\n\nThe problem asks for the probability of detecting *at least one* rare cell. This is the event $\\{X \\ge 1\\}$. It is more straightforward to calculate the probability of the complementary event, which is detecting *zero* rare cells, i.e., $\\{X=0\\}$, and subtract this from $1$.\n\nThe probability of detecting zero rare cells is:\n$$P(X=0) = \\binom{N}{0} f^0 (1-f)^{N-0}$$\nSince $\\binom{N}{0} = 1$ and $f^0 = 1$, this simplifies to:\n$$P(X=0) = (1-f)^N$$\nThe probability of detecting at least one rare cell, which we denote as $P_{\\text{detect}}(N, f)$, is therefore:\n$$P_{\\text{detect}}(N, f) = P(X \\ge 1) = 1 - P(X=0) = 1 - (1-f)^N$$\nThis is the expression for the detection probability as a function of $f$ and $N$.\n\nNext, we must find the smallest integer $N$ such that the detection probability is at least a user-specified target $P^{\\star}$. We set up the inequality:\n$$P_{\\text{detect}}(N, f) \\ge P^{\\star}$$\n$$1 - (1-f)^N \\ge P^{\\star}$$\nRearranging the inequality to solve for $N$:\n$$1 - P^{\\star} \\ge (1-f)^N$$\nThe problem states $0  P^{\\star}  1$, which implies $0  1 - P^{\\star}  1$. Also, as $f$ is a population frequency, we assume $0  f  1$, which means $0  1-f  1$. Since both sides of the inequality are positive, we can take the natural logarithm of both sides. The natural logarithm is a strictly increasing function, so the direction of the inequality is preserved:\n$$\\ln(1 - P^{\\star}) \\ge \\ln((1-f)^N)$$\nUsing the logarithm power rule $\\ln(a^b) = b\\ln(a)$:\n$$\\ln(1 - P^{\\star}) \\ge N \\ln(1-f)$$\nTo isolate $N$, we must divide by $\\ln(1-f)$. Since $0  1-f  1$, its logarithm, $\\ln(1-f)$, is a negative number. Dividing an inequality by a negative number reverses the direction of the inequality sign:\n$$\\frac{\\ln(1 - P^{\\star})}{\\ln(1-f)} \\le N$$\nThis can be written as:\n$$N \\ge \\frac{\\ln(1 - P^{\\star})}{\\ln(1-f)}$$\nThe problem requires the smallest *integer* $N$ that satisfies this condition. The expression on the right-hand side is the minimum required sample size, which may not be an integer. Therefore, the smallest integer $N$ must be the ceiling of this value.\nThe analytic expression for the smallest integer $N$ is:\n$$N = \\left\\lceil \\frac{\\ln(1 - P^{\\star})}{\\ln(1-f)} \\right\\rceil$$\n\nFinally, we evaluate this expression for the given numerical values: $f = 7 \\times 10^{-5}$ and $P^{\\star} = 0.975$.\n\nFirst, we calculate the terms inside the logarithms:\n$$1 - P^{\\star} = 1 - 0.975 = 0.025$$\n$$1 - f = 1 - 7 \\times 10^{-5} = 1 - 0.00007 = 0.99993$$\n\nNow, we substitute these into the inequality for $N$:\n$$N \\ge \\frac{\\ln(0.025)}{\\ln(0.99993)}$$\nUsing a calculator for the values of the logarithms:\n$$\\ln(0.025) \\approx -3.68887945411$$\n$$\\ln(0.99993) \\approx -0.0000700024501$$\nNow we compute the ratio:\n$$N \\ge \\frac{-3.68887945411}{-0.0000700024501} \\approx 52696.0906$$\nThe smallest integer $N$ that satisfies this condition is the ceiling of this value:\n$$N = \\lceil 52696.0906 \\rceil = 52697$$\nTherefore, a minimum of $52697$ cells must be sampled to ensure the probability of detecting at least one rare cell is at least $0.975$.", "answer": "$$\\boxed{52697}$$", "id": "4377566"}, {"introduction": "Droplet-based single-cell technologies are powerful but are susceptible to technical artifacts, most notably the formation of \"doublets\" where two cells are captured in the same droplet. These artifacts can systematically bias downstream analyses, such as the estimation of cell-type proportions. This two-part exercise challenges you to first model and quantify the bias introduced by doublets, and then to design an optimal classification strategy to identify them based on the F1-score. Mastering this problem will provide a deep, quantitative understanding of a critical quality control challenge in single-cell analysis and the trade-offs involved in mitigating it [@problem_id:4377572].", "problem": "A droplet-based single-cell RNA sequencing (scRNA-seq) experiment samples a heterogeneous population consisting of two cell types, denoted $A$ and $B$, with true proportions $p_A$ and $p_B = 1 - p_A$. A fraction $\\delta$ of captured barcodes arises from doublets, formed by pairing two independently sampled cells. The doublet type frequencies are thus $A+A$ with probability $p_A^2$, $A+B$ with probability $2 p_A p_B$, and $B+B$ with probability $p_B^2$. A naive cell-type assignment classifier labels a barcode as type $A$ if an internal marker score exceeds its counterpart; for doublets, the rule is as follows: $A+A$ is always labeled $A$, $B+B$ is always labeled $B$, and $A+B$ is labeled $A$ with probability $q$ and $B$ with probability $1 - q$. Assume the classifier is otherwise perfect on singlets.\n\nPart 1 (Proportion impact): Derive from first principles an analytic expression for the expected observed proportion of type $A$, denoted $\\hat{p}_A^{\\mathrm{obs}}$, under the above generative model and assignment rule. Then derive the bias $\\Delta_A = \\hat{p}_A^{\\mathrm{obs}} - p_A$ in terms of $p_A$, $\\delta$, and $q$. Evaluate $\\Delta_A$ for $p_A = 0.65$, $\\delta = 0.12$, and $q = 0.75$. Express $\\Delta_A$ as a decimal fraction and round your numerical answer to four significant figures.\n\nPart 2 (Doublet detection threshold optimizing precisionâ€“recall): A doublet detection score $s$ is computed for each barcode from aggregate features such as library size and co-expression. Model the score conditional on the barcode type as exponential tails: $s \\mid \\mathrm{doublet} \\sim \\mathrm{Exp}(\\lambda_D)$ and $s \\mid \\mathrm{singlet} \\sim \\mathrm{Exp}(\\lambda_S)$ on $[0,\\infty)$, with $\\lambda_S  \\lambda_D$. Let the prior doublet prevalence be $\\pi_D \\in (0,1)$. Consider a threshold rule that predicts a doublet if and only if $s  t$. Using the standard definitions of precision and recall and the harmonic mean known as the $F_1$-score, derive a closed-form expression for the threshold $t^{\\star}$ that maximizes the $F_1$-score in terms of $\\pi_D$, $\\lambda_D$, and $\\lambda_S$. Then evaluate $t^{\\star}$ numerically for $\\lambda_D = 0.5$, $\\lambda_S = 1.5$, and $\\pi_D = 0.10$, and round your numerical answer to four significant figures.\n\nReport your final answers as a single row matrix containing the two quantities in the order $\\Delta_A$ and $t^{\\star}$. No physical units are required for these answers.", "solution": "The problem is evaluated as valid because it is scientifically grounded in the principles of single-cell genomics and statistical classification, is mathematically well-posed with sufficient information for a unique solution, and is stated objectively. We proceed with solving both parts.\n\nPart 1: Derivation of the bias $\\Delta_A$\n\nLet $\\hat{p}_A^{\\mathrm{obs}}$ be the observed proportion of cells classified as type $A$. This is the probability that a randomly selected barcode is classified as type $A$. We can express this using the law of total probability, conditioning on whether the barcode corresponds to a singlet or a doublet.\n\nThe fraction of barcodes from singlets is $1-\\delta$, and the fraction from doublets is $\\delta$. Thus,\n$$\n\\hat{p}_A^{\\mathrm{obs}} = P(\\text{classified as } A) = P(\\text{classified as } A \\mid \\text{singlet}) P(\\text{singlet}) + P(\\text{classified as } A \\mid \\text{doublet}) P(\\text{doublet})\n$$\n$$\n\\hat{p}_A^{\\mathrm{obs}} = P(A_{\\mathrm{obs}} \\mid S)(1-\\delta) + P(A_{\\mathrm{obs}} \\mid D)\\delta\n$$\nFirst, consider the singlets. A singlet is drawn from the population with true proportions $p_A$ and $p_B$. The classifier is perfect for singlets.\n$$\nP(A_{\\mathrm{obs}} \\mid S) = P(A_{\\mathrm{obs}} \\mid \\text{true cell is } A) P(\\text{true cell is } A) + P(A_{\\mathrm{obs}} \\mid \\text{true cell is } B) P(\\text{true cell is } B)\n$$\nHere, $P(\\text{true cell is } A) = p_A$ and $P(\\text{true cell is } B) = p_B$. Since the classifier is perfect for singlets, $P(A_{\\mathrm{obs}} \\mid \\text{true cell is } A) = 1$ and $P(A_{\\mathrm{obs}} \\mid \\text{true cell is } B) = 0$.\n$$\nP(A_{\\mathrm{obs}} \\mid S) = (1)(p_A) + (0)(p_B) = p_A\n$$\nNext, consider the doublets. The problem states the probabilities of doublet types are $P(A+A) = p_A^2$, $P(A+B) = 2p_A p_B$, and $P(B+B) = p_B^2$. The classification rules for doublets are given.\n$$\nP(A_{\\mathrm{obs}} \\mid D) = P(A_{\\mathrm{obs}} \\mid A+A)P(A+A) + P(A_{\\mathrm{obs}} \\mid A+B)P(A+B) + P(A_{\\mathrm{obs}} \\mid B+B)P(B+B)\n$$\nSubstituting the given probabilities: $P(A_{\\mathrm{obs}} \\mid A+A)=1$, $P(A_{\\mathrm{obs}} \\mid A+B)=q$, and $P(A_{\\mathrm{obs}} \\mid B+B)=0$.\n$$\nP(A_{\\mathrm{obs}} \\mid D) = (1)(p_A^2) + (q)(2p_A p_B) + (0)(p_B^2) = p_A^2 + 2q p_A p_B\n$$\nNow, we substitute these back into the expression for $\\hat{p}_A^{\\mathrm{obs}}$.\n$$\n\\hat{p}_A^{\\mathrm{obs}} = p_A(1-\\delta) + (p_A^2 + 2q p_A p_B)\\delta\n$$\nThe bias is defined as $\\Delta_A = \\hat{p}_A^{\\mathrm{obs}} - p_A$.\n$$\n\\Delta_A = [p_A(1-\\delta) + (p_A^2 + 2q p_A p_B)\\delta] - p_A\n$$\n$$\n\\Delta_A = p_A - p_A\\delta + p_A^2\\delta + 2q p_A p_B \\delta - p_A\n$$\n$$\n\\Delta_A = - p_A\\delta + p_A^2\\delta + 2q p_A p_B \\delta\n$$\nWe can factor out $\\delta p_A$:\n$$\n\\Delta_A = \\delta p_A (-1 + p_A + 2q p_B)\n$$\nSubstituting $p_B = 1-p_A$:\n$$\n\\Delta_A = \\delta p_A (-1 + p_A + 2q(1-p_A))\n$$\n$$\n\\Delta_A = \\delta p_A (-1 + p_A + 2q - 2q p_A)\n$$\n$$\n\\Delta_A = \\delta p_A ((p_A - 2q p_A) + (2q - 1))\n$$\n$$\n\\Delta_A = \\delta p_A (p_A(1 - 2q) - (1 - 2q))\n$$\n$$\n\\Delta_A = \\delta p_A (1-p_A)(-(1-2q)) = \\delta p_A (1-p_A)(2q-1) = \\delta p_A p_B (2q-1)\n$$\nFor the numerical evaluation, we are given $p_A = 0.65$, $\\delta = 0.12$, and $q = 0.75$.\nFirst, $p_B = 1 - p_A = 1 - 0.65 = 0.35$.\nThen, $2q-1 = 2(0.75) - 1 = 1.5 - 1 = 0.5$.\nSubstituting these values into the expression for $\\Delta_A$:\n$$\n\\Delta_A = (0.12)(0.65)(0.35)(0.5) = 0.01365\n$$\nThis value has four significant figures, so no rounding is needed.\n\nPart 2: Derivation of the optimal threshold $t^{\\star}$\n\nWe want to find the threshold $t$ that maximizes the $F_1$-score. The $F_1$-score is the harmonic mean of precision $P$ and recall $R$: $F_1 = 2 \\frac{PR}{P+R}$.\n\nFirst, we define precision and recall as functions of the threshold $t$. The positive class is \"doublet\".\nThe score distributions are $s \\mid \\mathrm{doublet} \\sim \\mathrm{Exp}(\\lambda_D)$ and $s \\mid \\mathrm{singlet} \\sim \\mathrm{Exp}(\\lambda_S)$. The survival function for an exponential distribution $\\mathrm{Exp}(\\lambda)$ is $S(t) = P(s  t) = \\exp(-\\lambda t)$.\n\nLet $\\pi_D$ be the prior probability of a barcode being a doublet. The number of true positives ($TP$), false positives ($FP$), and false negatives ($FN$) for a threshold $t$ are proportional to:\n$$\nP(\\text{TP}; t) = P(st \\mid \\text{doublet})P(\\text{doublet}) = \\pi_D \\exp(-\\lambda_D t)\n$$\n$$\nP(\\text{FP}; t) = P(st \\mid \\text{singlet})P(\\text{singlet}) = (1-\\pi_D) \\exp(-\\lambda_S t)\n$$\n$$\nP(\\text{FN}; t) = P(s \\le t \\mid \\text{doublet})P(\\text{doublet}) = \\pi_D (1 - \\exp(-\\lambda_D t))\n$$\nRecall, $R(t)$, is the true positive rate:\n$$\nR(t) = \\frac{P(\\text{TP}; t)}{P(\\text{TP}; t) + P(\\text{FN}; t)} = \\frac{\\pi_D \\exp(-\\lambda_D t)}{\\pi_D \\exp(-\\lambda_D t) + \\pi_D (1 - \\exp(-\\lambda_D t))} = \\exp(-\\lambda_D t)\n$$\nPrecision, $P(t)$, is the positive predictive value:\n$$\nP(t) = \\frac{P(\\text{TP}; t)}{P(\\text{TP}; t) + P(\\text{FP}; t)} = \\frac{\\pi_D \\exp(-\\lambda_D t)}{\\pi_D \\exp(-\\lambda_D t) + (1-\\pi_D) \\exp(-\\lambda_S t)}\n$$\nThe $F_1$-score can be written as:\n$$\nF_1(t) = \\frac{2 P(\\text{TP}; t)}{2 P(\\text{TP}; t) + P(\\text{FP}; t) + P(\\text{FN}; t)} = \\frac{2 \\pi_D \\exp(-\\lambda_D t)}{2\\pi_D \\exp(-\\lambda_D t) + (1-\\pi_D) \\exp(-\\lambda_S t) + \\pi_D(1-\\exp(-\\lambda_D t))}\n$$\n$$\nF_1(t) = \\frac{2 \\pi_D \\exp(-\\lambda_D t)}{\\pi_D + \\pi_D \\exp(-\\lambda_D t) + (1-\\pi_D) \\exp(-\\lambda_S t)}\n$$\nTo maximize $F_1(t)$, we can differentiate with respect to $t$ and set the derivative to $0$. Let's ignore the constant factor $2\\pi_D$ in the numerator and maximize $G(t) = \\frac{\\exp(-\\lambda_D t)}{\\pi_D + \\pi_D \\exp(-\\lambda_D t) + (1-\\pi_D) \\exp(-\\lambda_S t)}$.\nUsing the quotient rule, $(u/v)' = (u'v - uv')/v^2=0$, which implies $u'v - uv' = 0$.\nLet $u(t) = \\exp(-\\lambda_D t)$ and $v(t) = \\pi_D + \\pi_D \\exp(-\\lambda_D t) + (1-\\pi_D) \\exp(-\\lambda_S t)$.\nThe derivatives are $u'(t) = -\\lambda_D \\exp(-\\lambda_D t)$ and $v'(t) = -\\pi_D \\lambda_D \\exp(-\\lambda_D t) - (1-\\pi_D)\\lambda_S \\exp(-\\lambda_S t)$.\nSetting $u'v - uv' = 0$:\n$$\n(-\\lambda_D e^{-\\lambda_D t})(\\pi_D + \\pi_D e^{-\\lambda_D t} + (1-\\pi_D)e^{-\\lambda_S t}) - (e^{-\\lambda_D t})(-\\pi_D\\lambda_D e^{-\\lambda_D t} - (1-\\pi_D)\\lambda_S e^{-\\lambda_S t}) = 0\n$$\nDividing by the non-zero term $e^{-\\lambda_D t}$:\n$$\n-\\lambda_D(\\pi_D + \\pi_D e^{-\\lambda_D t} + (1-\\pi_D)e^{-\\lambda_S t}) - (-\\pi_D\\lambda_D e^{-\\lambda_D t} - (1-\\pi_D)\\lambda_S e^{-\\lambda_S t}) = 0\n$$\n$$\n-\\lambda_D\\pi_D - \\lambda_D\\pi_D e^{-\\lambda_D t} - \\lambda_D(1-\\pi_D)e^{-\\lambda_S t} + \\pi_D\\lambda_D e^{-\\lambda_D t} + (1-\\pi_D)\\lambda_S e^{-\\lambda_S t} = 0\n$$\nThe terms $-\\lambda_D\\pi_D e^{-\\lambda_D t}$ and $+\\pi_D\\lambda_D e^{-\\lambda_D t}$ cancel out.\n$$\n-\\lambda_D\\pi_D + (1-\\pi_D)(\\lambda_S - \\lambda_D)e^{-\\lambda_S t} = 0\n$$\nSolving for $e^{-\\lambda_S t}$:\n$$\ne^{-\\lambda_S t} = \\frac{\\lambda_D \\pi_D}{(1-\\pi_D)(\\lambda_S - \\lambda_D)}\n$$\nTaking the natural logarithm of both sides:\n$$\n-\\lambda_S t = \\ln\\left(\\frac{\\lambda_D \\pi_D}{(1-\\pi_D)(\\lambda_S - \\lambda_D)}\\right)\n$$\nThe optimal threshold $t^{\\star}$ is:\n$$\nt^{\\star} = -\\frac{1}{\\lambda_S}\\ln\\left(\\frac{\\lambda_D \\pi_D}{(1-\\pi_D)(\\lambda_S - \\lambda_D)}\\right) = \\frac{1}{\\lambda_S}\\ln\\left(\\frac{(1-\\pi_D)(\\lambda_S - \\lambda_D)}{\\lambda_D \\pi_D}\\right)\n$$\nFor the numerical evaluation, we use $\\lambda_D = 0.5$, $\\lambda_S = 1.5$, and $\\pi_D = 0.10$.\n$1-\\pi_D = 0.90$.\n$\\lambda_S - \\lambda_D = 1.5 - 0.5 = 1.0$.\nThe argument of the logarithm is:\n$$\n\\frac{(1-\\pi_D)(\\lambda_S - \\lambda_D)}{\\lambda_D \\pi_D} = \\frac{(0.90)(1.0)}{(0.5)(0.10)} = \\frac{0.9}{0.05} = 18\n$$\nSo, the optimal threshold is:\n$$\nt^{\\star} = \\frac{1}{1.5} \\ln(18)\n$$\nCalculating the numerical value:\n$$\nt^{\\star} \\approx \\frac{2.8903717}{1.5} \\approx 1.9269145\n$$\nRounding to four significant figures gives $t^{\\star} = 1.927$.\n\nThe final answer requires both quantities, $\\Delta_A$ and $t^{\\star}$, in a single row matrix.\n$$\n\\Delta_A = 0.01365\n$$\n$$\nt^{\\star} = 1.927\n$$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.01365  1.927\n\\end{pmatrix}\n}\n$$", "id": "4377572"}, {"introduction": "A central goal in scRNA-seq analysis is to distinguish meaningful biological variation from the substantial technical noise inherent in the data. A foundational step in many workflows is to identify Highly Variable Genes (HVGs), as these are most likely to drive the biological processes that define cellular identity and state. This computational practice guides you through implementing a modern, model-based approach to HVG selection, using a Negative Binomial model to describe technical noise and identifying genes with residual variance that significantly exceeds model expectations. By translating statistical theory into a working pipeline, this exercise provides hands-on experience with the core logic of normalization and feature selection that underpins many advanced single-cell analysis tools [@problem_id:4377587].", "problem": "You are given a computational task grounded in the principles of single-cell systems biology within systems biomedicine: implement a method to normalize Unique Molecular Identifier (UMI) count data by known sampling depths, perform variance stabilization grounded in a generative model, and select Highly Variable Genes (HVG) based on residual variance across cells.\n\nFundamental base and core definitions to use:\n- Let $x_{g i}$ denote the observed UMI count for gene $g$ in cell $i$. Assume a generative model in which $x_{g i}$ is a random variable with mean $s_i \\mu_g$, where $s_i$ is a size factor representing sampling depth for cell $i$, and $\\mu_g$ is the expected expression level for gene $g$. The Negative Binomial (NB) model with a fixed dispersion parameter $\\phi \\ge 0$ has variance\n$$\n\\operatorname{Var}[x_{g i}] = s_i \\mu_g + \\phi (s_i \\mu_g)^2,\n$$\nand reduces to the Poisson model when $\\phi = 0$.\n- Known library sizes $L_i$ are proportional to the true sampling depths; use them to compute the size factors $s_i$ by rescaling $L_i$ to a common reference depth. The reference depth must be a robust statistic of the $L_i$.\n- Use the NB mean-variance relationship above as the basis for variance stabilization and residual analysis.\n\nTask requirements:\n1. Compute size factors $s_i$ from the provided library sizes $L_i$ using a robust reference.\n2. Estimate $\\mu_g$ for each gene $g$ directly from the joint model $E[x_{g i}] = s_i \\mu_g$ using principled estimation.\n3. Construct a variance-stabilized residual representation of the data in a way that is consistent with the NB mean-variance relationship. The residuals must be centered per gene and must be scaled to account for the mean-dependent variance under the model.\n4. For each gene, compute the residual variance across cells, and select the top $k$ genes with the largest residual variance. In case of ties in residual variance, break ties by the smaller gene index. Use zero-based indexing for genes.\n\nYour program must implement the above pipeline and apply it to the following test suite. For each test case, return the list of selected gene indices (zero-based), ordered from highest to lowest residual variance after tie-breaking, with length equal to $k$.\n\nTest suite:\n- Case A (general case):\n  - Counts matrix $X$ (genes $\\times$ cells):\n    $$\n    X = \\begin{bmatrix}\n    10  15  8  12  11  9 \\\\\n    5  20  6  25  5  23 \\\\\n    50  75  40  60  55  45 \\\\\n    0  1  0  2  0  1 \\\\\n    30  70  24  72  33  63\n    \\end{bmatrix}\n    $$\n  - Library sizes $L = [1000, 1500, 800, 1200, 1100, 900]$.\n  - Dispersion $\\phi = 0.1$.\n  - Number of HVGs $k = 2$.\n- Case B (boundary condition, Poisson limit and equal depths):\n  - Counts matrix $X$:\n    $$\n    X = \\begin{bmatrix}\n    10  10  10  10 \\\\\n    2  20  1  18 \\\\\n    0  0  0  0 \\\\\n    5  7  6  4\n    \\end{bmatrix}\n    $$\n  - Library sizes $L = [1000, 1000, 1000, 1000]$.\n  - Dispersion $\\phi = 0$.\n  - Number of HVGs $k = 1$.\n- Case C (edge case with heterogeneous depths and near-zero genes):\n  - Counts matrix $X$:\n    $$\n    X = \\begin{bmatrix}\n    1  5  0  4  6 \\\\\n    50  210  30  160  260 \\\\\n    8  60  3  40  90 \\\\\n    0  0  0  0  0 \\\\\n    15  30  9  40  35 \\\\\n    0  100  0  150  300\n    \\end{bmatrix}\n    $$\n  - Library sizes $L = [500, 2000, 300, 1500, 2500]$.\n  - Dispersion $\\phi = 1.0$.\n  - Number of HVGs $k = 2$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For example, the output format must be a single line string like `[[i1,i2],[j1],[k1,k2]]` with no spaces.", "solution": "The problem presents a valid and well-posed computational task grounded in the established principles of single-cell systems biology. It requires the implementation of a standard workflow for identifying highly variable genes (HVGs) from Unique Molecular Identifier (UMI) count data. The model, methodology, and data are scientifically sound and internally consistent. We proceed with a principled solution.\n\nThe objective is to identify genes that exhibit greater variability across cells than expected under a specified technical noise model. The model assumes that the UMI count $x_{gi}$ for gene $g$ in cell $i$ follows a distribution with a mean proportional to the cell's sampling depth and the gene's intrinsic expression level, $E[x_{gi}] = s_i \\mu_g$. The variance is given by the Negative Binomial (NB) relationship: $\\operatorname{Var}[x_{gi}] = s_i \\mu_g + \\phi (s_i \\mu_g)^2$. The parameter $\\phi$ controls the dispersion, capturing extra-Poisson variation. When $\\phi=0$, the model simplifies to the Poisson distribution.\n\nThe solution is constructed by following the four required tasks.\n\n### Step 1: Size Factor Calculation\nThe \"size factors\" $s_i$ are normalization constants that account for differences in library size or sampling depth across cells. They are computed by scaling the given raw library sizes $L_i$ to a common reference scale.\n\nThe problem specifies using a \"robust statistic\" for the reference depth. The median is the standard choice for this purpose as it is insensitive to outlier cells with extremely high or low library sizes. The reference depth $L_{ref}$ is thus defined as:\n$$\nL_{ref} = \\operatorname{median}(\\{L_1, L_2, \\ldots, L_{N_c}\\})\n$$\nwhere $N_c$ is the number of cells.\n\nThe size factor for each cell $i$ is then calculated as the ratio of its library size to the reference depth:\n$$\ns_i = \\frac{L_i}{L_{ref}}\n$$\nThis ensures that a cell with a median library size will have a size factor of $1$, and other cells will have their counts effectively scaled to this reference level.\n\n### Step 2: Gene Expression Mean Estimation\nThe parameter $\\mu_g$ represents the normalized, intrinsic mean expression level of gene $g$. The model equation is $E[x_{gi}] = s_i \\mu_g$. To estimate $\\mu_g$ from the observed data $x_{gi}$ and the calculated size factors $s_i$, we can use the method of moments. Summing the expectations across all cells for a given gene $g$ yields:\n$$\n\\sum_{i=1}^{N_c} E[x_{gi}] = \\sum_{i=1}^{N_c} s_i \\mu_g = \\mu_g \\sum_{i=1}^{N_c} s_i\n$$\nBy the law of large numbers, we can approximate the sum of expectations with the sum of observations, $E[\\sum_i x_{gi}] \\approx \\sum_i x_{gi}$. This leads to a principled estimator for $\\mu_g$:\n$$\n\\hat{\\mu}_g = \\frac{\\sum_{i=1}^{N_c} x_{gi}}{\\sum_{i=1}^{N_c} s_i}\n$$\nThis estimator represents the total counts for a gene, scaled by the total effective library size. If a gene has zero total counts across all cells, its estimated mean expression $\\hat{\\mu}_g$ will be $0$.\n\n### Step 3: Variance-Stabilized Residual Calculation\nThe core of HVG detection is to distinguish biological variability from technical noise. We achieve this by calculating residuals that are stabilized with respect to the mean expression level. The Pearson residual is a suitable metric for this purpose. It is defined as the difference between the observed count and the expected count, standardized by the expected standard deviation from the model.\n\nFirst, we calculate the estimated expected count $\\hat{E}[x_{gi}]$ for each gene-cell pair using our estimates $\\hat{\\mu}_g$ and known size factors $s_i$:\n$$\n\\hat{E}[x_{gi}] = s_i \\hat{\\mu}_g\n$$\nNext, we calculate the expected variance $\\widehat{\\operatorname{Var}}[x_{gi}]$ under the NB model, plugging in our estimated mean:\n$$\n\\widehat{\\operatorname{Var}}[x_{gi}] = s_i \\hat{\\mu}_g + \\phi (s_i \\hat{\\mu}_g)^2 = \\hat{E}[x_{gi}] + \\phi (\\hat{E}[x_{gi}])^2\n$$\nThe Pearson residual $r_{gi}$ is then:\n$$\nr_{gi} = \\frac{x_{gi} - \\hat{E}[x_{gi}]}{\\sqrt{\\widehat{\\operatorname{Var}}[x_{gi}]}} = \\frac{x_{gi} - s_i \\hat{\\mu}_g}{\\sqrt{s_i \\hat{\\mu}_g + \\phi (s_i \\hat{\\mu}_g)^2}}\n$$\nThese residuals are centered around an expectation of $0$ and, if the data perfectly follow the noise model, will have a theoretical variance of $1$.\n\nA critical edge case occurs when $\\hat{\\mu}_g = 0$. This happens for genes with zero counts in all cells. In this scenario, both the expected count $\\hat{E}[x_{gi}]$ and the expected variance $\\widehat{\\operatorname{Var}}[x_{gi}]$ are $0$. The residual formula becomes $\\frac{0-0}{0}$, which is indeterminate. However, the correct physical and statistical interpretation is that if a gene is not expressed and not expected to be expressed, there is no deviation from the model. Therefore, the residuals $r_{gi}$ for such a gene must be defined as $0$.\n\n### Step 4: Highly Variable Gene Selection\nGenes whose expression levels are driven by biological processes, rather than just technical noise, will exhibit larger variance in their residuals than the model predicts. We can quantify this by computing the sample variance of the residuals for each gene across all cells.\n\nFor each gene $g$, the residual variance $\\operatorname{Var}_{res}(g)$ is calculated as the unbiased sample variance of its residuals $\\{r_{g1}, r_{g2}, \\ldots, r_{g,N_c}\\}$:\n$$\n\\operatorname{Var}_{res}(g) = \\frac{1}{N_c - 1} \\sum_{i=1}^{N_c} (r_{gi} - \\bar{r}_g)^2\n$$\nwhere $\\bar{r}_g = \\frac{1}{N_c} \\sum_{i=1}^{N_c} r_{gi}$ is the sample mean of the residuals for gene $g$.\n\nFinally, to select the top $k$ HVGs, we perform the following steps:\n1.  Create a list of tuples, one for each gene, containing its residual variance and its original index: $(\\operatorname{Var}_{res}(g), g)$.\n2.  Sort this list. The primary sorting criterion is the residual variance, in descending order. The secondary criterion, to break ties, is the gene index, in ascending order.\n3.  The indices of the top $k$ genes from this sorted list are the result.\nThis procedure ensures a unique and deterministic ranking of genes based on their excess-of-model variance, fulfilling all requirements of the problem statement.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the highly variable gene detection problem for the provided test suite.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"X\": np.array([\n                [10, 15, 8, 12, 11, 9],\n                [5, 20, 6, 25, 5, 23],\n                [50, 75, 40, 60, 55, 45],\n                [0, 1, 0, 2, 0, 1],\n                [30, 70, 24, 72, 33, 63]\n            ]),\n            \"L\": np.array([1000, 1500, 800, 1200, 1100, 900]),\n            \"phi\": 0.1,\n            \"k\": 2\n        },\n        {\n            \"X\": np.array([\n                [10, 10, 10, 10],\n                [2, 20, 1, 18],\n                [0, 0, 0, 0],\n                [5, 7, 6, 4]\n            ]),\n            \"L\": np.array([1000, 1000, 1000, 1000]),\n            \"phi\": 0.0,\n            \"k\": 1\n        },\n        {\n            \"X\": np.array([\n                [1, 5, 0, 4, 6],\n                [50, 210, 30, 160, 260],\n                [8, 60, 3, 40, 90],\n                [0, 0, 0, 0, 0],\n                [15, 30, 9, 40, 35],\n                [0, 100, 0, 150, 300]\n            ]),\n            \"L\": np.array([500, 2000, 300, 1500, 2500]),\n            \"phi\": 1.0,\n            \"k\": 2\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        X = case[\"X\"]\n        L = case[\"L\"]\n        phi = case[\"phi\"]\n        k = case[\"k\"]\n        \n        num_genes, num_cells = X.shape\n\n        # Step 1: Compute size factors s_i\n        L_ref = np.median(L)\n        s = L / L_ref\n\n        # Step 2: Estimate gene expression mean mu_g\n        # mu_hat has shape (num_genes,)\n        sum_s = np.sum(s)\n        total_counts_per_gene = np.sum(X, axis=1)\n        mu_hat = np.divide(total_counts_per_gene, sum_s, \n                           out=np.zeros_like(total_counts_per_gene, dtype=float), \n                           where=sum_s!=0)\n\n        # Step 3: Construct variance-stabilized residuals\n        # Reshape for broadcasting: mu_hat (G,1), s (1,C) - expected_counts (G,C)\n        mu_hat_col = mu_hat[:, np.newaxis]\n        s_row = s[np.newaxis, :]\n        \n        expected_counts = mu_hat_col * s_row\n        \n        expected_variance = expected_counts + phi * (expected_counts**2)\n        \n        # Calculate Pearson residuals: (observed - expected) / sqrt(expected_variance)\n        numerator = X - expected_counts\n        denominator = np.sqrt(expected_variance)\n        \n        # Handle division by zero for genes with mu_hat = 0\n        residuals = np.divide(numerator, denominator, \n                              out=np.zeros_like(numerator, dtype=float), \n                              where=denominator!=0)\n        \n        # Step 4: Compute residual variance and select top k genes\n        # ddof=1 for unbiased sample variance.\n        # This will be an array of shape (num_genes,)\n        # If a row in residuals is constant (e.g., all 0s), variance is 0.\n        # np.var handles this correctly, no NaNs are produced for constant inputs.\n        residual_variances = np.var(residuals, axis=1, ddof=1)\n        \n        # Create a list of (variance, gene_index) tuples.\n        gene_variances = list(enumerate(residual_variances))\n        \n        # Sort by variance (desc) and then by gene index (asc) for tie-breaking.\n        # Python's sort is stable, but a lambda key is more explicit.\n        # key = (variance, index) - sort by (-variance, index)\n        sorted_genes = sorted(gene_variances, key=lambda item: (-item[1], item[0]))\n        \n        # Select the top k gene indices.\n        top_k_indices = [index for index, var in sorted_genes[:k]]\n        \n        all_results.append(f\"[{','.join(map(str, top_k_indices))}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[[{','.join(all_results)}]]\")\n\nsolve()\n```", "id": "4377587"}]}