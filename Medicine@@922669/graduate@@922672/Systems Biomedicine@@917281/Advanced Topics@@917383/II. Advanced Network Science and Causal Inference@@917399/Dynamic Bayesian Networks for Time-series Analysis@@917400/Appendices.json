{"hands_on_practices": [{"introduction": "To begin our hands-on exploration of Dynamic Bayesian Networks, we start with the most fundamental inferential task: filtering. This practice problem tasks you with manually tracking the hidden states of a hypothetical gene regulatory network over time, given a sequence of observations [@problem_id:4336551]. By applying the core predict-update cycle of Bayesian filtering, you will gain a concrete understanding of how a DBN recursively refines its beliefs about a system's state as new evidence becomes available.", "problem": "Consider a gene-regulatory time-series modeled by a Dynamic Bayesian Network (DBN), where the hidden variables are a transcription factor activity $T_t \\in \\{0,1\\}$ and a gene activation state $G_t \\in \\{0,1\\}$, and the observed variable is a discretized expression measurement $Y_t \\in \\{0,1\\}$ at time $t$. The DBN is defined by the following structure: an initial prior $p(T_1)$ and $p(G_1 \\mid T_1)$; Markovian transitions $p(T_t \\mid T_{t-1})$ and $p(G_t \\mid G_{t-1}, T_t)$; and an emission model $p(Y_t \\mid G_t)$. The Conditional Probability Tables (CPTs) are given below (all numbers are probabilities):\n\n- Initial prior for the transcription factor: $p(T_1=1) = 0.6$, $p(T_1=0) = 0.4$.\n- Initial gene state given the transcription factor: $p(G_1=1 \\mid T_1=1) = 0.7$, $p(G_1=0 \\mid T_1=1) = 0.3$; $p(G_1=1 \\mid T_1=0) = 0.2$, $p(G_1=0 \\mid T_1=0) = 0.8$.\n- Transcription factor dynamics: $p(T_t=1 \\mid T_{t-1}=1) = 0.8$, $p(T_t=0 \\mid T_{t-1}=1) = 0.2$; $p(T_t=1 \\mid T_{t-1}=0) = 0.3$, $p(T_t=0 \\mid T_{t-1}=0) = 0.7$.\n- Gene dynamics conditioned on previous gene state and current transcription factor: $p(G_t=1 \\mid G_{t-1}=1, T_t=1) = 0.9$, $p(G_t=0 \\mid G_{t-1}=1, T_t=1) = 0.1$; $p(G_t=1 \\mid G_{t-1}=0, T_t=1) = 0.5$, $p(G_t=0 \\mid G_{t-1}=0, T_t=1) = 0.5$; $p(G_t=1 \\mid G_{t-1}=1, T_t=0) = 0.6$, $p(G_t=0 \\mid G_{t-1}=1, T_t=0) = 0.4$; $p(G_t=1 \\mid G_{t-1}=0, T_t=0) = 0.1$, $p(G_t=0 \\mid G_{t-1}=0, T_t=0) = 0.9$.\n- Emission model: $p(Y_t=1 \\mid G_t=1) = 0.85$, $p(Y_t=0 \\mid G_t=1) = 0.15$; $p(Y_t=1 \\mid G_t=0) = 0.2$, $p(Y_t=0 \\mid G_t=0) = 0.8$.\n\nYou observe the sequence $y_{1:3} = (y_1, y_2, y_3) = (1, 0, 1)$. Using the fundamental base of Bayes’ theorem, the law of total probability, and the Markov property encoded by the DBN conditional independencies, perform exact filtering to compute the normalized joint beliefs $p(T_t, G_t \\mid y_{1:t})$ for $t \\in \\{1,2,3\\}$ for the ordered state pairs $(T_t,G_t) \\in \\{(1,1),(1,0),(0,1),(0,0)\\}$.\n\nFinally, compute the posterior probability $p(G_3 = 1 \\mid y_{1:3})$ and report this as your final answer. Round your final answer to four significant figures. Express the final answer as a pure number (no units and no percentage sign).", "solution": "The problem requires performing exact filtering on a Dynamic Bayesian Network (DBN) to compute the posterior probability of hidden states given a sequence of observations. The hidden state at time $t$ is a composite variable $X_t = (T_t, G_t)$, where $T_t$ is the transcription factor activity and $G_t$ is the gene activation state. The state space for $X_t$ consists of $4$ possible states, which we will consistently order as $\\{(1,1), (1,0), (0,1), (0,0)\\}$. The observation at time $t$ is $Y_t$. We are given the observation sequence $y_{1:3}=(1,0,1)$.\n\nThe filtering task is to compute the posterior distribution $p(X_t \\mid y_{1:t})$ for $t=1, 2, 3$. This is achieved via a recursive process involving a prediction step and an update step. Let $\\pi_t(X_t) \\equiv p(X_t \\mid y_{1:t})$ be the filtered belief at time $t$.\n\nThe recursion is as follows:\n1.  **Prediction**: The one-step-ahead prediction of the state is given by the Chapman-Kolmogorov equation:\n    $$p(X_t \\mid y_{1:t-1}) = \\sum_{X_{t-1}} p(X_t \\mid X_{t-1}) p(X_{t-1} \\mid y_{1:t-1})$$\n    The transition probability $p(X_t \\mid X_{t-1})$ is determined by the DBN structure: $p(X_t \\mid X_{t-1}) = p(T_t, G_t \\mid T_{t-1}, G_{t-1}) = p(T_t \\mid T_{t-1}) p(G_t \\mid G_{t-1}, T_t)$.\n\n2.  **Update**: The predicted distribution is updated using the observation $y_t$ via Bayes' rule:\n    $$p(X_t \\mid y_{1:t}) = \\frac{p(y_t \\mid X_t, y_{1:t-1}) p(X_t \\mid y_{1:t-1})}{p(y_t \\mid y_{1:t-1})}$$\n    Given the DBN structure, the emission $Y_t$ is conditionally independent of past states and observations given the current state $X_t$. Specifically, $p(y_t \\mid X_t, y_{1:t-1}) = p(y_t \\mid X_t) = p(y_t \\mid G_t)$. The denominator is a normalization constant. Thus, the update can be written as:\n    $$\\pi_t(X_t) \\propto p(y_t \\mid G_t) p(X_t \\mid y_{1:t-1})$$\n\nWe will now apply this process for $t=1, 2, 3$.\n\n**Time Step $t=1$**\n\nFor $t=1$, the \"prediction\" is simply the prior distribution over the initial state $X_1$. The prior joint probability is $p(X_1) = p(T_1, G_1) = p(T_1) p(G_1 \\mid T_1)$.\n$p(T_1=1, G_1=1) = 0.6 \\times 0.7 = 0.42$.\n$p(T_1=1, G_1=0) = 0.6 \\times 0.3 = 0.18$.\n$p(T_1=0, G_1=1) = 0.4 \\times 0.2 = 0.08$.\n$p(T_1=0, G_1=0) = 0.4 \\times 0.8 = 0.32$.\n\nNext, we update this prior with the observation $y_1=1$. The unnormalized posterior (forward message) $\\alpha_1(X_1)$ is $\\alpha_1(X_1) = p(y_1 \\mid G_1) p(X_1)$.\n$\\alpha_1(1,1) = 0.85 \\times 0.42 = 0.357$.\n$\\alpha_1(1,0) = 0.20 \\times 0.18 = 0.036$.\n$\\alpha_1(0,1) = 0.85 \\times 0.08 = 0.068$.\n$\\alpha_1(0,0) = 0.20 \\times 0.32 = 0.064$.\n\nThe normalization constant is $Z_1 = \\sum_{X_1} \\alpha_1(X_1) = 0.357 + 0.036 + 0.068 + 0.064 = 0.525$.\nThe filtered belief $\\pi_1(X_1)=p(X_1 \\mid y_1)$ is found by dividing each $\\alpha_1$ component by $Z_1$:\n$\\pi_1(1,1) = 0.68$.\n$\\pi_1(1,0) \\approx 0.06857$.\n$\\pi_1(0,1) \\approx 0.12952$.\n$\\pi_1(0,0) \\approx 0.12190$.\n\n**Time Step $t=2$**\n\nFirst, the prediction step. We compute $p(X_2 \\mid y_1) = \\sum_{X_1} p(X_2 \\mid X_1) \\pi_1(X_1)$. This is done by summing over the four possible states of $X_1$, using the transition probabilities and the filtered belief $\\pi_1(X_1)$ from the previous step. The resulting predicted probability vector for the states of $X_2$ is approximately:\n$p(X_2 \\mid y_1) \\approx (0.57029, 0.10400, 0.14590, 0.17981)$.\n\nNext, we update with the observation $y_2=0$. Emission probabilities are $p(Y_2=0 \\mid G_2=1) = 0.15$ and $p(Y_2=0 \\mid G_2=0) = 0.8$. The unnormalized posterior is $\\alpha_2(X_2) \\propto p(y_2 \\mid G_2) p(X_2 \\mid y_1)$.\n$\\alpha_2(1,1) \\propto 0.15 \\times 0.57029 \\approx 0.08554$.\n$\\alpha_2(1,0) \\propto 0.80 \\times 0.10400 \\approx 0.08320$.\n$\\alpha_2(0,1) \\propto 0.15 \\times 0.14590 \\approx 0.02189$.\n$\\alpha_2(0,0) \\propto 0.80 \\times 0.17981 \\approx 0.14385$.\n\nThe normalization constant is the sum of these unnormalized values, $Z_2 \\approx 0.33448$.\nThe filtered belief $\\pi_2(X_2)=p(X_2 \\mid y_{1:2})$ is:\n$\\pi_2(1,1) \\approx 0.08554 / 0.33448 \\approx 0.25575$.\n$\\pi_2(1,0) \\approx 0.08320 / 0.33448 \\approx 0.24875$.\n$\\pi_2(0,1) \\approx 0.02189 / 0.33448 \\approx 0.06543$.\n$\\pi_2(0,0) \\approx 0.14385 / 0.33448 \\approx 0.43007$.\n\n**Time Step $t=3$**\n\nPrediction step: $p(X_3 \\mid y_{1:2}) = \\sum_{X_2} p(X_3 \\mid X_2) \\pi_2(X_2)$.\nThe predicted probability vector for $X_3$ is approximately:\n$p(X_3 \\mid y_{1:2}) \\approx (0.36582, 0.18643, 0.09325, 0.35450)$.\n\nUpdate with the observation $y_3=1$. Emission probabilities are $p(Y_3=1 \\mid G_3=1) = 0.85$ and $p(Y_3=1 \\mid G_3=0) = 0.2$.\nThe unnormalized posterior is $\\alpha_3(X_3) \\propto p(y_3 \\mid G_3) p(X_3 \\mid y_{1:2})$.\n$\\alpha_3(1,1) \\propto 0.85 \\times 0.36582 \\approx 0.31095$.\n$\\alpha_3(1,0) \\propto 0.20 \\times 0.18643 \\approx 0.03729$.\n$\\alpha_3(0,1) \\propto 0.85 \\times 0.09325 \\approx 0.07926$.\n$\\alpha_3(0,0) \\propto 0.20 \\times 0.35450 \\approx 0.07090$.\n\nThe normalization constant is the sum of these unnormalized values, $Z_3 \\approx 0.49840$.\nThe filtered belief $\\pi_3(X_3)=p(X_3 \\mid y_{1:3})$ is:\n$\\pi_3(1,1) \\approx 0.31095 / 0.49840 \\approx 0.62388$.\n$\\pi_3(1,0) \\approx 0.03729 / 0.49840 \\approx 0.07481$.\n$\\pi_3(0,1) \\approx 0.07926 / 0.49840 \\approx 0.15904$.\n$\\pi_3(0,0) \\approx 0.07090 / 0.49840 \\approx 0.14225$.\n\n**Final Answer Calculation**\n\nThe problem asks for the posterior probability $p(G_3=1 \\mid y_{1:3})$. This is obtained by marginalizing the joint posterior distribution $p(T_3, G_3 \\mid y_{1:3})$ over the variable $T_3$.\n$$p(G_3=1 \\mid y_{1:3}) = \\sum_{T_3 \\in \\{0,1\\}} p(T_3, G_3=1 \\mid y_{1:3})$$\n$$p(G_3=1 \\mid y_{1:3}) = p(T_3=1, G_3=1 \\mid y_{1:3}) + p(T_3=0, G_3=1 \\mid y_{1:3})$$\n$$p(G_3=1 \\mid y_{1:3}) = \\pi_3(1,1) + \\pi_3(0,1)$$\n$$p(G_3=1 \\mid y_{1:3}) \\approx 0.62388 + 0.15904 \\approx 0.78292$$\nUsing higher precision values from the calculation gives $0.78293605$.\nRounding the result to four significant figures gives $0.7829$.", "answer": "$$\\boxed{0.7829}$$", "id": "4336551"}, {"introduction": "Having mastered state estimation with a given model, the next logical step is to learn the model's parameters directly from data. This exercise guides you through a key part of the Baum-Welch algorithm, a cornerstone of learning in Hidden Markov Models [@problem_id:4336550]. You will use the forward-backward algorithm to compute the expected number of transitions between latent states, providing the essential ingredients for updating the model's transition matrix and revealing the underlying system dynamics from time-series observations.", "problem": "Consider a Dynamic Bayesian Network (DBN) representation of a two-state Hidden Markov Model (HMM) for a single gene’s regulatory activity in systems biomedicine. The latent regulatory state is denoted by $Z_t \\in \\{1,2\\}$, where $Z_t=1$ denotes an inactive state and $Z_t=2$ denotes an active state. The observed expression measurement at time $t$ is a continuous variable $Y_t \\in \\mathbb{R}$. The model obeys the first-order Markov property and conditional independence between observations given the latent state, with the following components as the fundamental base:\n- The initial distribution $p(Z_1=i)=\\pi_i$.\n- The transition distribution $p(Z_t=j \\mid Z_{t-1}=i)=a_{ij}$, where for each $i$, $\\sum_{j} a_{ij}=1$ and $a_{ij} \\ge 0$.\n- The emission distribution $p(Y_t \\mid Z_t=i)$.\n\nAssume the emission model is Gaussian: $Y_t \\mid Z_t=i \\sim \\mathcal{N}(\\mu_i,\\sigma^2)$ with $\\mu_1=0$, $\\mu_2=2$, and $\\sigma^2=1$. The HMM parameters for the latent dynamics are:\n- Initial distribution $\\pi_1=0.6$, $\\pi_2=0.4$.\n- Transition matrix entries $a_{11}=0.85$, $a_{12}=0.15$, $a_{21}=0.30$, $a_{22}=0.70$.\n\nYou observe the time series $Y_1=0.3$, $Y_2=1.9$, $Y_3=2.1$ (i.e., $T=3$). Using the forward-backward algorithm derived from the joint factorization $p(Z_{1:T},Y_{1:T}) = p(Z_1)\\prod_{t=2}^{T}p(Z_t\\mid Z_{t-1})\\prod_{t=1}^{T}p(Y_t\\mid Z_t)$ and the definition of conditional expectations, compute the expected transition counts $\\mathbb{E}\\left[\\mathbb{I}\\{Z_{t-1}=1,Z_t=2\\}\\mid Y_{1:3}\\right]$ for $t=2$ and $t=3$, and use them to perform the maximum-likelihood update of the transition probability $p(Z_t=2\\mid Z_{t-1}=1)$ under the normalization constraint $\\sum_{j} a_{1j}=1$.\n\nProvide the final updated value of $p(Z_t=2\\mid Z_{t-1}=1)$ as a single real number. Round your answer to four significant figures. Express the probability as a decimal (no percentage sign).", "solution": "To find the maximum-likelihood update for the transition probability $a_{12} = p(Z_t=2 \\mid Z_{t-1}=1)$, we use the Baum-Welch algorithm, a specific instance of the Expectation-Maximization (EM) algorithm for Hidden Markov Models (HMMs). The M-step update rule for $a_{ij}$ is the ratio of the expected number of transitions from state $i$ to state $j$ to the expected number of total transitions originating from state $i$.\n\nThe general formula for the re-estimation of $a_{ij}$ is:\n$$\n\\hat{a}_{ij} = \\frac{\\sum_{t=2}^{T} p(Z_{t-1}=i, Z_t=j \\mid Y_{1:T})}{\\sum_{t=1}^{T-1} p(Z_t=i \\mid Y_{1:T})}\n$$\nThe terms in the numerator and denominator are smoothed posterior probabilities, which are computed using the forward-backward algorithm. Let $\\alpha_t(i) = p(Y_{1:t}, Z_t=i)$ be the forward variable and $\\beta_t(i) = p(Y_{t+1:T} \\mid Z_t=i)$ be the backward variable. The required probabilities are:\n-   Smoothed pairwise posterior: $\\xi_t(i,j) = p(Z_{t-1}=i, Z_t=j \\mid Y_{1:T}) = \\frac{\\alpha_{t-1}(i) a_{ij} p(Y_t \\mid Z_t=j) \\beta_t(j)}{p(Y_{1:T})}$\n-   Smoothed marginal posterior: $\\gamma_t(i) = p(Z_t=i \\mid Y_{1:T}) = \\frac{\\alpha_t(i)\\beta_t(i)}{p(Y_{1:T})}$\n-   Data likelihood: $p(Y_{1:T}) = \\sum_{i=1}^2 \\alpha_T(i)$\n\nWith a time horizon of $T=3$, the update formula for $a_{12}$ is:\n$$\n\\hat{a}_{12} = \\frac{\\xi_2(1,2) + \\xi_3(1,2)}{\\gamma_1(1) + \\gamma_2(1)}\n$$\n\n**Step I: Emission Probabilities**\nFirst, we compute the emission probabilities $b_i(Y_t) = p(Y_t \\mid Z_t=i)$ using the Gaussian PDF, $\\mathcal{N}(Y_t; \\mu_i, \\sigma^2=1)$.\n-   $Y_1=0.3$: $b_1(Y_1) \\approx 0.381384$, $b_2(Y_1) \\approx 0.094045$\n-   $Y_2=1.9$: $b_1(Y_2) \\approx 0.065616$, $b_2(Y_2) \\approx 0.396953$\n-   $Y_3=2.1$: $b_1(Y_3) \\approx 0.043984$, $b_2(Y_3) \\approx 0.396953$\n\n**Step II: Forward Pass ($\\alpha_t(i)$)**\nWe recursively compute the forward variables.\n-   $t=1$:\n    $\\alpha_1(1) = \\pi_1 b_1(Y_1) = 0.6 \\times 0.381384 = 0.228830$\n    $\\alpha_1(2) = \\pi_2 b_2(Y_1) = 0.4 \\times 0.094045 = 0.037618$\n-   $t=2$:\n    $\\alpha_2(1) = [\\alpha_1(1)a_{11} + \\alpha_1(2)a_{21}] b_1(Y_2) \\approx 0.013504$\n    $\\alpha_2(2) = [\\alpha_1(1)a_{12} + \\alpha_1(2)a_{22}] b_2(Y_2) \\approx 0.024078$\n-   $t=3$:\n    $\\alpha_3(1) = [\\alpha_2(1)a_{11} + \\alpha_2(2)a_{21}] b_1(Y_3) \\approx 0.00082256$\n    $\\alpha_3(2) = [\\alpha_2(1)a_{12} + \\alpha_2(2)a_{22}] b_2(Y_3) \\approx 0.00749448$\n-   Data likelihood: $p(Y_{1:3}) = \\alpha_3(1) + \\alpha_3(2) \\approx 0.00831704$\n\n**Step III: Backward Pass ($\\beta_t(i)$)**\nWe recursively compute the backward variables, starting with $\\beta_3(i)=1$.\n-   $t=2$:\n    $\\beta_2(1) = a_{11}b_1(Y_3)\\beta_3(1) + a_{12}b_2(Y_3)\\beta_3(2) \\approx 0.096929$\n    $\\beta_2(2) = a_{21}b_1(Y_3)\\beta_3(1) + a_{22}b_2(Y_3)\\beta_3(2) \\approx 0.291062$\n-   $t=1$:\n    $\\beta_1(1) = a_{11}b_1(Y_2)\\beta_2(1) + a_{12}b_2(Y_2)\\beta_2(2) \\approx 0.022734$\n    $\\beta_1(2) = a_{21}b_1(Y_2)\\beta_2(1) + a_{22}b_2(Y_2)\\beta_2(2) \\approx 0.082778$\n\n**Step IV: Smoothed Probabilities**\nNow we compute the terms needed for the update formula.\n-   Denominator terms ($\\gamma_t(1)$):\n    $\\gamma_1(1) = \\frac{\\alpha_1(1)\\beta_1(1)}{p(Y_{1:3})} = \\frac{0.228830 \\times 0.022734}{0.00831704} \\approx 0.62557$\n    $\\gamma_2(1) = \\frac{\\alpha_2(1)\\beta_2(1)}{p(Y_{1:3})} = \\frac{0.013504 \\times 0.096929}{0.00831704} \\approx 0.15738$\n    Denominator sum: $\\gamma_1(1) + \\gamma_2(1) \\approx 0.78295$.\n\n-   Numerator terms ($\\xi_t(1,2)$):\n    $\\xi_2(1,2) = \\frac{\\alpha_1(1) a_{12} b_2(Y_2) \\beta_2(2)}{p(Y_{1:3})} = \\frac{0.228830 \\times 0.15 \\times 0.396953 \\times 0.291062}{0.00831704} \\approx 0.47691$\n    $\\xi_3(1,2) = \\frac{\\alpha_2(1) a_{12} b_2(Y_3) \\beta_3(2)}{p(Y_{1:3})} = \\frac{0.013504 \\times 0.15 \\times 0.396953 \\times 1}{0.00831704} \\approx 0.096726$\n    Numerator sum: $\\xi_2(1,2) + \\xi_3(1,2) \\approx 0.573636$.\n\n**Step V: Parameter Update**\nFinally, we compute the updated transition probability $\\hat{a}_{12}$:\n$$\n\\hat{a}_{12} = \\frac{\\xi_2(1,2) + \\xi_3(1,2)}{\\gamma_1(1) + \\gamma_2(1)} \\approx \\frac{0.573636}{0.78295} \\approx 0.73266\n$$\nRounding to four significant figures, the result is $0.7327$.", "answer": "$$\\boxed{0.7327}$$", "id": "4336550"}, {"introduction": "Our final practice moves from passive observation to active intervention, a crucial step towards causal modeling in systems biology. This problem challenges you to formally incorporate an external perturbation into a DBN's structure, modifying the network's factorization to reflect an action that forces a variable to a specific state [@problem_id:4336566]. Deriving the resulting interventional distribution provides fundamental insight into how DBNs can be used to predict the consequences of experimental actions, moving beyond mere correlation to the domain of causal inference.", "problem": "In a systems biomedicine setting, consider a regulatory module modeled as a Dynamic Bayesian Network (DBN), represented with a Two-slice Temporal Bayesian Network (2TBN). The module contains three discrete-valued biological state variables at each time index $t \\in \\{0,1,\\dots,T\\}$: a transcription factor $X_t$, a downstream gene product $Y_t$, and a post-translational modification state $Z_t$. Assume a first-order Markov property across time slices and no intra-slice edges, with inter-slice parent sets given by $\\mathrm{Pa}(X_t)=\\{X_{t-1},Z_{t-1}\\}$, $\\mathrm{Pa}(Y_t)=\\{X_{t-1},Y_{t-1}\\}$, and $\\mathrm{Pa}(Z_t)=\\{Y_{t-1},Z_{t-1}\\}$. Let $p(X_0,Y_0,Z_0)$ denote the initial-joint distribution at time $t=0$, and for $t \\ge 1$ let $p(X_t \\mid X_{t-1},Z_{t-1})$, $p(Y_t \\mid X_{t-1},Y_{t-1})$, and $p(Z_t \\mid Y_{t-1},Z_{t-1})$ denote the observational conditional probability distributions (CPDs).\n\nYou are asked to incorporate explicit intervention nodes to represent time-localized experimental perturbations. Introduce a binary intervention node $I_t \\in \\{0,1\\}$ for each time $t \\in \\{1,\\dots,T\\}$, with a directed edge $I_t \\to X_t$, whose semantics are: when $I_t=0$ the observational dynamics for $X_t$ apply, and when $I_t=1$ the variable $X_t$ is exogenously set to a fixed value $x^{\\star}$ independent of its parents. Consider a single hard intervention applied at a particular time $t_{\\mathrm{int}} \\in \\{1,\\dots,T\\}$, where $I_{t_{\\mathrm{int}}}=1$ and $X_{t_{\\mathrm{int}}}$ is thereby forced to $x^{\\star}$, while for all $t \\ne t_{\\mathrm{int}}$ we have $I_t=0$. Let $\\delta_{a,b}$ denote the Kronecker delta, equal to $1$ if $a=b$ and $0$ otherwise.\n\nStarting only from the chain rule for joint distributions, the Bayesian network factorization rule, and the first-order Markov property defined by the two-slice template above, derive the modified factorization for the interventional joint distribution over the full trajectory $(X_0,\\dots,X_T,Y_0,\\dots,Y_T,Z_0,\\dots,Z_T)$ induced by the described intervention. Your final expression should factorize over time and clearly reflect that $X_{t_{\\mathrm{int}}}$ is set to $x^{\\star}$, while all other CPDs remain observational. Express your final answer as a single closed-form analytic expression in terms of $p(X_0,Y_0,Z_0)$, the observational CPDs, and the Kronecker delta $\\delta_{\\,\\cdot,\\cdot}$. Do not include an equality sign in your final answer. No numerical approximation or rounding is required, and no physical units apply.", "solution": "We begin with the standard principles that define a Two-slice Temporal Bayesian Network (2TBN) for a Dynamic Bayesian Network (DBN). The two key foundational elements are: the chain rule for joint distributions and the Bayesian network factorization property. Together with the first-order Markov property, these imply that, over a finite horizon $t \\in \\{0,1,\\dots,T\\}$, the joint observational distribution factorizes as\n$$\np(X_0,Y_0,Z_0) \\prod_{t=1}^{T} p(X_t \\mid X_{t-1},Z_{t-1}) \\, p(Y_t \\mid X_{t-1},Y_{t-1}) \\, p(Z_t \\mid Y_{t-1},Z_{t-1}) .\n$$\nThis arises because the first-order Markov property and the specified parent sets $\\mathrm{Pa}(X_t)=\\{X_{t-1},Z_{t-1}\\}$, $\\mathrm{Pa}(Y_t)=\\{X_{t-1},Y_{t-1}\\}$, and $\\mathrm{Pa}(Z_t)=\\{Y_{t-1},Z_{t-1}\\}$ determine the conditional independences that the 2TBN encodes, and the Bayesian network factorization writes the joint as the product of each node’s conditional probability given its parents.\n\nWe now incorporate explicit intervention nodes. For each time $t \\in \\{1,\\dots,T\\}$, we add a binary intervention variable $I_t \\in \\{0,1\\}$ with a directed edge $I_t \\to X_t$. The semantics are as follows: when $I_t=0$, $X_t$ follows its observational CPD $p(X_t \\mid X_{t-1},Z_{t-1})$; when $I_t=1$, the incoming edges into $X_t$ from its observational parents are effectively cut and $X_t$ is deterministically set to a fixed value $x^{\\star}$, independent of $(X_{t-1},Z_{t-1})$. A convenient and standard way to encode this in a single conditional probability table for $X_t$ is to define\n$$\np(X_t \\mid X_{t-1},Z_{t-1},I_t) = (1-I_t)\\, p(X_t \\mid X_{t-1},Z_{t-1}) + I_t \\, \\delta_{X_t,\\,x^{\\star}} ,\n$$\nwhere $\\delta_{a,b}$ is the Kronecker delta, equal to $1$ when $a=b$ and $0$ otherwise. This defines a valid conditional distribution for $X_t$ because it is a convex combination of two valid conditionals for all $I_t \\in \\{0,1\\}$ and sums to $1$ over the support of $X_t$.\n\nWith these intervention nodes added, the augmented Bayesian network over $(X_{0:T},Y_{0:T},Z_{0:T},I_{1:T})$ factorizes as\n$$\np(X_0,Y_0,Z_0)\\,\\prod_{t=1}^{T} p(I_t)\\, p(X_t \\mid X_{t-1},Z_{t-1},I_t)\\, p(Y_t \\mid X_{t-1},Y_{t-1})\\, p(Z_t \\mid Y_{t-1},Z_{t-1}) .\n$$\nHere $p(I_t)$ are arbitrary exogenous priors for the intervention nodes. Under a hard, time-localized intervention at $t_{\\mathrm{int}} \\in \\{1,\\dots,T\\}$ that sets $I_{t_{\\mathrm{int}}}=1$ and $I_t=0$ for all $t \\ne t_{\\mathrm{int}}$, we appeal to the intervention semantics that fix those variables and remove the need to include their probabilities in the interventional distribution over the biological state variables $(X_{0:T},Y_{0:T},Z_{0:T})$. Concretely, the interventional joint distribution $p_{\\mathrm{do}}(X_{0:T},Y_{0:T},Z_{0:T})$ is obtained by replacing the observational factor $p(X_{t_{\\mathrm{int}}} \\mid X_{t_{\\mathrm{int}}-1},Z_{t_{\\mathrm{int}}-1})$ with the degenerate factor $\\delta_{X_{t_{\\mathrm{int}}},\\,x^{\\star}}$, while leaving all other factors unchanged. This is a direct consequence of the Bayesian network factorization with the modified conditional for $X_{t_{\\mathrm{int}}}$ induced by $I_{t_{\\mathrm{int}}}=1$, together with $I_t=0$ for all $t \\ne t_{\\mathrm{int}}$ which restores the observational conditional for $X_t$ at those times.\n\nTherefore, the modified factorization for the interventional joint over the full trajectory of biological states is\n$$\np(X_0,Y_0,Z_0)\\;\n\\left[\\prod_{\\substack{t=1\\\\ t \\ne t_{\\mathrm{int}}}}^{T} p(X_t \\mid X_{t-1},Z_{t-1})\\right]\\;\n\\delta_{X_{t_{\\mathrm{int}}},\\,x^{\\star}}\\;\n\\left[\\prod_{t=1}^{T} p(Y_t \\mid X_{t-1},Y_{t-1})\\; p(Z_t \\mid Y_{t-1},Z_{t-1})\\right] .\n$$\nThis expression reflects exactly the intervention’s effect: the factor for $X_{t_{\\mathrm{int}}}$ is replaced by $\\delta_{X_{t_{\\mathrm{int}}},\\,x^{\\star}}$, encoding that $X_{t_{\\mathrm{int}}}$ is fixed to $x^{\\star}$, while all other factors remain observational and preserve the original time-factorized structure implied by the 2TBN. The downstream impact of the intervention propagates forward in time through the unchanged observational CPDs that depend on $X_{t}$ for $t \\ge t_{\\mathrm{int}}+1$.", "answer": "$$\\boxed{p(X_0,Y_0,Z_0)\\,\\left[\\prod_{\\substack{t=1\\\\ t \\ne t_{\\mathrm{int}}}}^{T} p(X_t \\mid X_{t-1},Z_{t-1})\\right]\\,\\delta_{X_{t_{\\mathrm{int}}},\\,x^{\\star}}\\,\\left[\\prod_{t=1}^{T} p(Y_t \\mid X_{t-1},Y_{t-1})\\,p(Z_t \\mid Y_{t-1},Z_{t-1})\\right]}$$", "id": "4336566"}]}