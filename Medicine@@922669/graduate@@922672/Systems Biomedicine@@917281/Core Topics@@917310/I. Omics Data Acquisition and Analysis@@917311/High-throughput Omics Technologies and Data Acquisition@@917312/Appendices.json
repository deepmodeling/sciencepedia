{"hands_on_practices": [{"introduction": "A successful high-throughput experiment begins not in the lab, but with careful statistical planning. This exercise focuses on power analysis, a critical step in experimental design that ensures your study is capable of detecting meaningful biological effects. By working through this problem, you will apply the Negative Binomial distribution—the standard statistical model for RNA-seq count data—to calculate the minimum number of biological replicates needed to achieve a desired statistical power, connecting theoretical models to practical, resource-defining decisions [@problem_id:4350600].", "problem": "Design a balanced two-condition Ribonucleic Acid sequencing (RNA-Seq) experiment to detect a true log base $2$ fold change of $1$ in gene expression between condition $A$ and condition $B$ with statistical power $0.8$. Assume the following scientifically realistic and standard modeling and experimental conditions: biological counts for a given gene in each condition are independently and identically distributed according to a Negative Binomial distribution with mean $\\mu$ and overdispersion parameter $\\phi$, all libraries are of comparable size so that mean expression reflects relative abundance, the two conditions have equal numbers of biological replicates, the dispersion is gene-specific but known and equal to $\\phi=0.1$ for the gene of interest, and the hypothesis test is conducted at a two-sided significance level $\\alpha=0.05$ using a log-link generalized linear model and large-sample Wald approximation on the log fold change. Let the baseline mean for the gene in condition $A$ be $\\mu_{1}=20$ normalized counts and the true fold change be $2$ so that the mean in condition $B$ is $\\mu_{2}=40$ normalized counts. Ignore any multiple testing adjustments. Compute the minimum number of biological replicates per condition required to achieve the specified power under these assumptions. Report the final answer as the smallest integer satisfying the power requirement. No rounding by significant figures is needed.", "solution": "The user wants me to solve a sample size calculation problem for an RNA-Seq experiment.\n\nHere's my plan:\n1.  **Validate the problem statement.** I need to carefully check if the problem is well-posed, scientifically grounded, and contains all necessary information.\n    *   **Step 1: Extract Givens.** I will list all the parameters, distributions, and conditions provided.\n    *   **Step 2: Validate.** I'll check for any inconsistencies, scientific flaws, or missing information. The problem describes a standard scenario in bioinformatics for power analysis of RNA-Seq data. It seems well-grounded in statistical theory for count data (Negative Binomial distribution, GLMs) and common practices in genomics.\n    *   **Step 3: Verdict.** Assuming the validation is successful, I'll proceed to solve it. If not, I'll state the reasons for invalidity.\n\n2.  **Solve the problem (if valid).**\n    *   The core of the problem is to find the minimum number of replicates, let's call it $n$, for each of two conditions.\n    *   The problem specifies the statistical test: a Wald test for the coefficient corresponding to the log fold change in a Generalized Linear Model (GLM) with a log link.\n    *   The data for each gene is assumed to follow a Negative Binomial (NB) distribution.\n    *   The key is to relate the sample size $n$ to the statistical power of the test.\n    *   The power of a test is $1 - \\beta$, where $\\beta$ is the probability of a Type II error. We are given the desired power is $0.8$.\n    *   The significance level is $\\alpha = 0.05$ (two-sided).\n\nLet's break down the statistical model:\n*   Let $Y_{ij}$ be the count for gene $i$ in replicate $j$. The problem focuses on a single gene, so we can drop the index $i$.\n*   Let $Y_{kj}$ be the count for condition $k$ ($k=1$ for condition A, $k=2$ for condition B) in replicate $j$ ($j=1, \\dots, n$).\n*   The problem states $Y_{kj} \\sim \\text{NB}(\\mu_k, \\phi)$, where $\\mu_k$ is the mean and $\\phi$ is the dispersion parameter. The variance of the NB distribution is given by $V = \\mu + \\phi\\mu^2$.\n*   We have a GLM with a log link: $\\ln(\\mu_k) = \\beta_0 + \\beta_1 x_k$.\n*   We can set up the design matrix. Let $x_k = 0$ for condition A ($k=1$) and $x_k = 1$ for condition B ($k=2$).\n    *   For condition A: $\\ln(\\mu_1) = \\beta_0$. So, $\\beta_0 = \\ln(\\mu_1)$.\n    *   For condition B: $\\ln(\\mu_2) = \\beta_0 + \\beta_1$. So, $\\beta_1 = \\ln(\\mu_2) - \\ln(\\mu_1) = \\ln(\\mu_2/\\mu_1)$.\n*   The parameter $\\beta_1$ is the true log base $e$ fold change. The problem statement specifies a log base $2$ fold change. Let's call the log base 2 fold change $LFC_2$.\n    *   $LFC_2 = \\log_2(\\mu_2/\\mu_1)$.\n    *   $\\beta_1 = \\ln(\\mu_2/\\mu_1) = \\ln(2^{LFC_2}) = LFC_2 \\cdot \\ln(2)$.\n*   The hypothesis test is on the coefficient $\\beta_1$.\n    *   Null hypothesis $H_0: \\beta_1 = 0$ (no fold change).\n    *   Alternative hypothesis $H_A: \\beta_1 \\neq 0$.\n*   The test uses a large-sample Wald approximation. The Wald statistic is $W = \\frac{\\hat{\\beta}_1}{\\text{SE}(\\hat{\\beta}_1)}$, which under $H_0$ is approximately distributed as a standard normal distribution, $N(0,1)$.\n*   We reject $H_0$ if $|W| > z_{1-\\alpha/2}$, where $z_{1-\\alpha/2}$ is the $(1-\\alpha/2)$-quantile of the standard normal distribution.\n\nNow, let's consider the power. The power is the probability of rejecting $H_0$ when $H_A$ is true.\n*   Under $H_A$, $\\beta_1$ is not zero. The test statistic $W$ is approximately normally distributed, but not with mean 0. The distribution of the estimator $\\hat{\\beta}_1$ is approximately $N(\\beta_1, \\text{Var}(\\hat{\\beta}_1))$.\n*   The Wald statistic $W = \\frac{\\hat{\\beta}_1}{\\text{SE}(\\hat{\\beta}_1)}$ is approximately $N(\\frac{\\beta_1}{\\text{SE}(\\hat{\\beta}_1)}, 1)$.\n*   Power = $P(|W| > z_{1-\\alpha/2} | H_A \\text{ is true})$.\n*   Power = $P(W > z_{1-\\alpha/2} | H_A) + P(W < -z_{1-\\alpha/2} | H_A)$.\n*   Let's assume $\\beta_1 > 0$. The term $P(W < -z_{1-\\alpha/2})$ will be very small. A common approximation is to consider only the upper tail: Power $\\approx P(W > z_{1-\\alpha/2} | H_A)$.\n*   Let $Z$ be a standard normal variable.\n    *   $W = \\frac{\\hat{\\beta}_1}{\\text{SE}(\\hat{\\beta}_1)} = \\frac{\\hat{\\beta}_1 - \\beta_1}{\\text{SE}(\\hat{\\beta}_1)} + \\frac{\\beta_1}{\\text{SE}(\\hat{\\beta}_1)}$.\n    *   The first term is approximately $N(0,1)$. Let's call it $Z$.\n    *   So, $W \\approx Z + \\frac{\\beta_1}{\\text{SE}(\\hat{\\beta}_1)}$.\n*   Power $\\approx P(Z + \\frac{\\beta_1}{\\text{SE}(\\hat{\\beta}_1)} > z_{1-\\alpha/2}) = P(Z > z_{1-\\alpha/2} - \\frac{\\beta_1}{\\text{SE}(\\hat{\\beta}_1)})$.\n*   For a desired power of $1-\\beta_{power}$, we need the argument of the tail probability to be $z_{1-(1-\\beta_{power})} = z_{\\beta_{power}} = -z_{1-\\beta_{power}}$.\n*   So, we need $z_{1-\\alpha/2} - \\frac{\\beta_1}{\\text{SE}(\\hat{\\beta}_1)} \\le z_{\\beta_{power}} = -z_{1-\\beta_{power}}$.\n*   This gives the standard formula: $\\frac{|\\beta_1|}{\\text{SE}(\\hat{\\beta}_1)} \\ge z_{1-\\alpha/2} + z_{1-\\beta_{power}}$. Note that for a two-sided test, we have power to detect a positive or negative effect. Since the formula is symmetric with $|\\beta_1|$, this covers both cases.\n*   Here, $\\beta_{power}$ is the Type II error rate. So if power is $0.8$, $\\beta_{power}=0.2$.\n\nNow, I need to find the expression for the standard error of $\\hat{\\beta}_1$, $\\text{SE}(\\hat{\\beta}_1) = \\sqrt{\\text{Var}(\\hat{\\beta}_1)}$.\n*   The variance of the coefficients in a GLM is related to the Fisher information matrix. For a two-sample comparison with $n$ replicates per group, the variance of the log fold change coefficient $\\hat{\\beta}_1$ is approximately:\n    $\\text{Var}(\\hat{\\beta}_1) \\approx \\frac{1}{n} \\left( \\frac{1}{\\mu_1} + \\phi \\right) + \\frac{1}{n} \\left( \\frac{1}{\\mu_2} + \\phi \\right)$.\n    Let me double-check this formula. This formula is from several sources, including classic papers on RNA-seq power analysis (e.g., in the `edgeR` or `DESeq2` vignettes).\n    The variance of a single observation $Y_{kj}$ is $V_k = \\mu_k + \\phi \\mu_k^2$.\n    The \"information\" from a single observation for estimating the mean $\\mu_k$ is related to $1/V_k$.\n    In GLMs with a log link, the variance of the log-mean is given by $\\text{Var}(\\ln(\\hat{\\mu}_k)) \\approx \\frac{\\text{Var}(Y_k)}{n (\\mu_k g'(\\mu_k))^2} = \\frac{\\mu_k + \\phi\\mu_k^2}{n (\\mu_k \\cdot 1/\\mu_k)^2} = \\frac{\\mu_k + \\phi\\mu_k^2}{n} = \\frac{1}{n}(\\mu_k(1+\\phi\\mu_k))$.\n    This doesn't look right.\n    \n    Let's re-derive it. The variance of the estimated coefficient is the diagonal element of the inverse of the Fisher information matrix.\n    For a NB-GLM, the weight for an observation $i$ is $w_i = 1/\\text{Var}(\\ln(\\hat{\\mu}_i))$. Wait, no, that's not it. The weight is $1/\\text{Var}(\\hat{\\eta_i})$ where $\\eta_i$ is the linear predictor.\n    The variance for a GLM coefficient is given by $(X^T W X)^{-1}_{jj}$ where $W$ is a diagonal matrix of weights. For NB with log link, the weights are $w_i = \\frac{1}{1/\\mu_i + \\phi}$.\n    Our design matrix $X$ for $n$ replicates per group (total $2n$ samples) is:\n    $X = \\begin{pmatrix} 1 & 0 \\\\ \\vdots & \\vdots \\\\ 1 & 0 \\\\ 1 & 1 \\\\ \\vdots & \\vdots \\\\ 1 & 1 \\end{pmatrix}$, where there are $n$ rows of $(1, 0)$ and $n$ rows of $(1, 1)$.\n    The weight matrix $W$ is diagonal with $n$ entries of $w_1 = \\frac{1}{1/\\mu_1 + \\phi}$ and $n$ entries of $w_2 = \\frac{1}{1/\\mu_2 + \\phi}$.\n    $X^T W X = \\begin{pmatrix} 1 & \\dots & 1 & 1 & \\dots & 1 \\\\ 0 & \\dots & 0 & 1 & \\dots & 1 \\end{pmatrix} \\begin{pmatrix} w_1 & & & & \\\\ & \\ddots & & & \\\\ & & w_1 & & \\\\ & & & w_2 & & \\\\ & & & & \\ddots & \\\\ & & & & & w_2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ \\vdots & \\vdots \\\\ 1 & 0 \\\\ 1 & 1 \\\\ \\vdots & \\vdots \\\\ 1 & 1 \\end{pmatrix}$\n    \n    $X^T W = \\begin{pmatrix} n w_1 & n w_2 \\\\ 0 & n w_2 \\end{pmatrix}$\n    $X^T W X = \\begin{pmatrix} w_1 & \\dots & w_1 & w_2 & \\dots & w_2 \\\\ 0 & \\dots & 0 & w_2 & \\dots & w_2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ \\vdots & \\vdots \\\\ 1 & 0 \\\\ 1 & 1 \\\\ \\vdots & \\vdots \\\\ 1 & 1 \\end{pmatrix}$\n    $X^T W X = \\begin{pmatrix} n w_1 + n w_2 & n w_2 \\\\ n w_2 & n w_2 \\end{pmatrix}$\n    \n    Now I need to invert this matrix. The determinant is $(n w_1 + n w_2)(n w_2) - (n w_2)^2 = n^2 w_1 w_2 + n^2 w_2^2 - n^2 w_2^2 = n^2 w_1 w_2$.\n    The inverse is:\n    $(X^T W X)^{-1} = \\frac{1}{n^2 w_1 w_2} \\begin{pmatrix} n w_2 & -n w_2 \\\\ -n w_2 & n w_1 + n w_2 \\end{pmatrix} = \\frac{1}{n w_1 w_2} \\begin{pmatrix} w_2 & -w_2 \\\\ -w_2 & w_1 + w_2 \\end{pmatrix}$.\n    \n    The variance of $\\hat{\\beta}_1$ is the $(2,2)$ element of this inverse matrix.\n    $\\text{Var}(\\hat{\\beta}_1) = \\frac{w_1 + w_2}{n w_1 w_2} = \\frac{1}{n} \\left(\\frac{1}{w_2} + \\frac{1}{w_1}\\right)$.\n    Substituting back $w_k = \\frac{1}{1/\\mu_k + \\phi}$:\n    $\\text{Var}(\\hat{\\beta}_1) = \\frac{1}{n} \\left( (1/\\mu_2 + \\phi) + (1/\\mu_1 + \\phi) \\right) = \\frac{1}{n} \\left( \\frac{1}{\\mu_1} + \\frac{1}{\\mu_2} + 2\\phi \\right)$.\n    \n    It seems I have derived the same formula twice. So it must be correct. Let me check some literature to be certain.\n    Looking at a source like \"RNA-seq differential expression analysis: an extended review and meta-analysis\" by Soneson and Delorenzi (2013), in their supplement, they have a formula for power.\n    Their formula for variance of log-fold-change is $\\sigma^2_{LFC} = (\\frac{1}{\\mu_1} + \\phi) / n_1 + (\\frac{1}{\\mu_2} + \\phi) / n_2$.\n    This is exactly what I derived with the delta method.\n    What is the difference? My GLM derivation gives $2\\phi$, their formula has $\\phi$ in each term.\n    Wait... $(\\frac{1}{\\mu_1}+\\phi) + (\\frac{1}{\\mu_2}+\\phi)$ is indeed $\\frac{1}{\\mu_1} + \\frac{1}{\\mu_2} + 2\\phi$.\n    Is it possible the dispersion $\\phi$ is not treated as a constant in the GLM weighting?\n    In a standard NB GLM, the variance is $\\mu + \\alpha\\mu^2$, where $\\alpha$ is the dispersion parameter. The iterative re-weighted least squares (IRWLS) algorithm uses weights $w_i = \\mu_i^2 / \\text{Var}(Y_i) = \\mu_i^2 / (\\mu_i + \\alpha\\mu_i^2) = \\mu_i / (1+\\alpha\\mu_i)$.\n    The link function is log, so $g'(\\mu) = 1/\\mu$. The weights for the Fisher scoring are $w_i = 1 / (\\text{Var}(Y_i) (g'(\\mu_i))^2) = 1 / ((\\mu_i + \\alpha\\mu_i^2)(1/\\mu_i)^2) = 1 / (1/\\mu_i + \\alpha)$.\n    This is exactly what I used, with $\\phi$ instead of $\\alpha$.\n    \n    So $\\text{Var}(\\hat{\\beta}_1) = \\frac{1}{n} \\left( \\frac{1}{\\mu_1} + \\frac{1}{\\mu_2} + 2\\phi \\right)$ seems to be the correct result from first principles of GLM theory.\n    Let's check another source. The `power.t.test` function in R for a two-sample t-test uses sample sizes $n1, n2$ and the pooled standard deviation $s$. The standard error of the difference in means is $s \\sqrt{1/n1 + 1/n2}$.\n    Here we are on a log scale. The \"observations\" are the $\\ln(\\text{counts})$, but this is not how it is modeled. The model is on the counts directly.\n    \n    Let's trust the Soneson and Delorenzi formula, which is widely cited and implemented.\n    $\\text{Var}(\\hat{\\beta}_1) = \\frac{1}{n}(\\frac{1}{\\mu_1} + \\phi) + \\frac{1}{n}(\\frac{1}{\\mu_2} + \\phi)$.\n    Is the dispersion $\\phi$ here defined differently?\n    In DESeq2, Var = $\\mu + \\alpha \\mu^2$. Here, the problem says Var = $\\mu + \\phi \\mu^2$. So $\\phi$ is the dispersion parameter, often denoted $\\alpha$.\n    The variance of log-transformed data is often approximated as $\\text{Var}(\\log(Y)) \\approx \\text{Var}(Y) / E[Y]^2 = (\\mu+\\phi\\mu^2)/\\mu^2 = 1/\\mu + \\phi$.\n    If we consider the sample mean of log-transformed counts (a bad idea, but for intuition), the variance of the mean log would be $(1/\\mu + \\phi)/n$.\n    The difference of two such means would have variance $(\\frac{1}{n_1}(\\frac{1}{\\mu_1}+\\phi)) + (\\frac{1}{n_2}(\\frac{1}{\\mu_2}+\\phi))$.\n    For $n_1=n_2=n$, this is $\\frac{1}{n} \\left( \\frac{1}{\\mu_1} + \\frac{1}{\\mu_2} + 2\\phi \\right)$.\n    I have re-derived the same thing again. Why do I doubt it?\n    \n    Let's check the `RNASeqPower` R package. The vignette has a formula.\n    `n = ((z_{1-alpha/2} + z_{1-beta})^2 / (log(rho))^2) * (1/lambda_1 + 1/lambda_2 + phi(lambda_1+lambda_2))` where $\\rho$ is fold change, $\\lambda$ are means, and `phi` is dispersion. This is a different model (Poisson-Gamma).\n    \n    Let's check the `RnaSeqSampleSize` R package. Their documentation cites a paper by Li et al. (2013).\n    Formula (1) in that paper is: $n = \\frac{(z_{\\alpha/2}+z_{\\beta})^2}{(\\log_2 FC)^2} \\left[ \\frac{(\\mu_1+\\mu_2)}{(\\mu_1\\mu_2\\ln2)^2} + \\frac{(\\phi_1+\\phi_2)}{(\\ln2)^2} \\right]$.\n    This looks complicated. Let's try to simplify.\n    $n (\\ln2 \\cdot \\log_2 FC)^2 = (z_{\\alpha/2}+z_{\\beta})^2 \\left[ \\frac{1}{\\mu_1\\mu_2} \\frac{\\mu_1+\\mu_2}{(\\ln2)^2} + \\phi_1+\\phi_2 \\right]$.\n    $n (\\ln FC)^2 = (z_{\\alpha/2}+z_{\\beta})^2 \\left[ \\frac{1}{(\\ln2)^2} (\\frac{1}{\\mu_1}+\\frac{1}{\\mu_2}) + \\phi_1+\\phi_2 \\right]$.\n    This seems to be mixing up log bases. Let's assume $\\phi_1=\\phi_2=\\phi$.\n    $n (\\ln FC)^2 / (z_{\\alpha/2}+z_{\\beta})^2 = \\frac{1}{(\\ln2)^2} (\\frac{1}{\\mu_1}+\\frac{1}{\\mu_2}) + 2\\phi$.\n    The variance of the LFC estimator would be $\\text{Var}(\\hat{\\ln FC}) = \\frac{(\\ln FC)^2 n}{(z_{\\alpha/2}+z_{\\beta})^2}$. No, this is not right.\n    From the power formula, $\\frac{|\\beta_1|}{\\text{SE}(\\hat{\\beta}_1)} = z_{1-\\alpha/2} + z_{1-\\beta_{power}}$.\n    So $(\\text{SE}(\\hat{\\beta}_1))^2 = \\text{Var}(\\hat{\\beta}_1) = \\frac{\\beta_1^2}{(z_{1-\\alpha/2} + z_{1-\\beta_{power}})^2}$.\n    The sample size 'n' is inside the variance term.\n    \n    Let's stick with my derived variance: $\\text{Var}(\\hat{\\beta}_1) = \\frac{1}{n} \\left( \\frac{1}{\\mu_1} + \\frac{1}{\\mu_2} + 2\\phi \\right)$. It came from two separate derivations (GLM Fisher Info and Delta Method on sample means) that agreed. It seems robust. Perhaps some sources write it as $(\\frac{1}{\\mu_1}+\\phi)/n_1 + (\\frac{1}{\\mu_2}+\\phi)/n_2$ and it is just a matter of interpretation of what $\\phi$ represents. In the framework $V = \\mu + \\phi \\mu^2$, my derivation seems correct. This is the parameterization used in edgeR. The one in DESeq2 is subtly different during normalization, but let's stick to the problem statement.\n    \n    So, the formula to solve is:\n    $\\frac{|\\beta_1|}{\\sqrt{\\frac{1}{n} \\left( \\frac{1}{\\mu_1} + \\frac{1}{\\mu_2} + 2\\phi \\right)}} \\ge z_{1-\\alpha/2} + z_{1-\\beta_{power}}$\n    \n    Let's plug in the given values.\n    *   Significance level $\\alpha = 0.05$. This is a two-sided test.\n        $z_{1-\\alpha/2} = z_{1-0.025} = z_{0.975}$. Using a standard normal table or calculator, this is approximately $1.96$.\n    *   Power $1 - \\beta_{power} = 0.8$. So the Type II error rate is $\\beta_{power} = 0.2$.\n        $z_{1-\\beta_{power}} = z_{0.8}$. This is a one-sided quantile. Its value is approximately $0.8416$.\n    *   Log base 2 fold change is $1$. Let's call it $LFC_2 = 1$.\n        The true fold change is $\\mu_2 / \\mu_1 = 2^{LFC_2} = 2^1 = 2$.\n    *   The baseline mean is $\\mu_1 = 20$.\n    *   The mean in condition B is $\\mu_2 = \\mu_1 \\times (\\text{fold change}) = 20 \\times 2 = 40$. This matches the problem statement.\n    *   The coefficient in the GLM is the log base $e$ fold change.\n        $\\beta_1 = \\ln(\\mu_2 / \\mu_1) = \\ln(2)$. The value is approximately $0.693$.\n    *   The dispersion parameter is $\\phi = 0.1$.\n    \n    Now, let's set up the inequality for $n$:\n    $\\frac{\\ln(2)}{\\sqrt{\\frac{1}{n} \\left( \\frac{1}{20} + \\frac{1}{40} + 2(0.1) \\right)}} \\ge z_{0.975} + z_{0.8}$\n    \n    Let's calculate the terms.\n    *   $z_{0.975} \\approx 1.959964$\n    *   $z_{0.8} \\approx 0.841621$\n    *   $z_{0.975} + z_{0.8} \\approx 1.959964 + 0.841621 = 2.801585$\n    *   $\\ln(2) \\approx 0.693147$\n    *   $\\frac{1}{20} = 0.05$\n    *   $\\frac{1}{40} = 0.025$\n    *   $2\\phi = 2(0.1) = 0.2$\n    *   The term in the parenthesis is $0.05 + 0.025 + 0.2 = 0.275$.\n    \n    The inequality becomes:\n    $\\frac{\\ln(2)}{\\sqrt{\\frac{0.275}{n}}} \\ge 2.801585$\n    \n    Square both sides:\n    $\\frac{(\\ln(2))^2}{\\frac{0.275}{n}} \\ge (2.801585)^2$\n    \n    $\\frac{n (\\ln(2))^2}{0.275} \\ge (2.801585)^2$\n    \n    Solve for $n$:\n    $n \\ge \\frac{0.275 \\times (2.801585)^2}{(\\ln(2))^2}$\n    \n    Let's compute the values:\n    *   $(2.801585)^2 \\approx 7.848879$\n    *   $(\\ln(2))^2 \\approx (0.693147)^2 \\approx 0.480453$\n    \n    $n \\ge \\frac{0.275 \\times 7.848879}{0.480453}$\n    $n \\ge \\frac{2.15844}{0.480453}$\n    $n \\ge 4.4925$\n    \n    The problem asks for the minimum number of biological replicates per condition, which must be an integer. Since $n$ must be at least $4.4925$, the smallest integer satisfying this is $n=5$.\n    \n    So, 5 replicates per condition are needed.\n    \n    Let's double-check the validation steps.\n    **Step 1: Extract Givens**\n    - Experiment type: balanced two-condition Ribonucleic Acid sequencing (RNA-Seq)\n    - Target effect size: true log base 2 fold change of $1$.\n    - Statistical power: $0.8$.\n    - Distribution model: Negative Binomial distribution for biological counts, independent and identically distributed within a condition.\n    - Mean and overdispersion: $\\mu$ and $\\phi$.\n    - Library size assumption: Comparable, mean expression reflects relative abundance.\n    - Design: Equal numbers of biological replicates per condition.\n    - Dispersion parameter: $\\phi=0.1$ (known and constant for the gene).\n    - Hypothesis test: Two-sided significance level $\\alpha=0.05$, using a log-link GLM and large-sample Wald approximation.\n    - Baseline mean (condition A): $\\mu_1 = 20$.\n    - True fold change: $2$.\n    - Mean (condition B): $\\mu_2 = 40$.\n    - Adjustments: Ignore multiple testing.\n    - Required output: Minimum integer number of biological replicates per condition.\n    \n    **Step 2: Validate Using Extracted Givens**\n    - **Scientifically Grounded**: Yes. The problem uses the Negative Binomial distribution, which is the standard model for RNA-seq count data, accounting for overdispersion. The use of GLMs, Wald tests, and the concepts of power, significance, and fold change are all central to bioinformatics and differential expression analysis. The parameter values ($\\mu=20$, $\\phi=0.1$, fold change=2) are realistic for a moderately expressed gene.\n    - **Well-Posed**: Yes. The problem is well-defined. It asks for a single quantity (minimum integer $n$) and provides all the necessary parameters and model assumptions to calculate it. A unique solution exists.\n    - **Objective**: Yes. The language is precise and quantitative. No subjective claims.\n    - **Factual Unsoundness**: None.\n    - **Incomplete or Contradictory Setup**: The problem is self-contained. It states the fold change is 2, and that $\\mu_1=20$ and $\\mu_2=40$, which is consistent. All necessary statistical parameters ($\\alpha$, power, $\\phi$) are provided. The model (NB-GLM, Wald test) is specified.\n    - **Unrealistic or Infeasible**: The conditions are realistic for an RNA-Seq experiment.\n    - **Ill-Posed or Poorly Structured**: No ambiguity. The question is clear.\n    - **Pseudo-Profound, Trivial, or Tautological**: No. This is a standard and non-trivial power calculation that requires understanding of the underlying statistical model of RNA-seq data.\n    - **Outside Scientific Verifiability**: The calculation is verifiable through standard statistical theory.\n    \n    **Step 3: Verdict and Action**\n    The problem is valid. I will proceed with providing the full solution.\n    \n    The solution narrative should walk through the steps I just took.\n    1.  Identify the goal: find the smallest integer $n$ (replicates per condition).\n    2.  State the statistical framework: Wald test for a coefficient in a NB-GLM.\n    3.  Write down the power equation: $\\frac{|\\beta_1|}{\\text{SE}(\\hat{\\beta_1})} \\ge z_{1-\\alpha/2} + z_{1-\\beta_{power}}$.\n    4.  Define the parameters in the equation.\n        - $\\beta_1$ is the natural log fold change, $\\ln(\\mu_2/\\mu_1)$.\n        - $\\text{SE}(\\hat{\\beta}_1)$ is the standard error of the estimator for $\\beta_1$.\n        - $z$-scores are quantiles of the standard normal distribution.\n    5.  Derive or state the formula for the variance of $\\hat{\\beta}_1$ in the context of a Negative Binomial GLM with $n$ replicates per group.\n    6.  Substitute the specific values from the problem into the derived inequality for $n$.\n    7.  Solve the inequality for $n$.\n    8.  Conclude with the smallest integer value for $n$.\n    \n    This seems like a solid plan. All numbers, variables, and symbols will be enclosed in LaTeX `$...$` or `$$...$$` tags.\n    For example, \"The power is $0.8$\". \"The mean is $\\mu_1=20$\". This is a high-priority rule.\n    I will use symbolic forms as long as possible before substituting numbers.\n    The final expression for $n$ will be:\n    $n \\ge \\frac{(z_{1-\\alpha/2} + z_{1-\\beta_{power}})^2}{(\\ln(\\mu_2/\\mu_1))^2} \\left( \\frac{1}{\\mu_1} + \\frac{1}{\\mu_2} + 2\\phi \\right)$.\n    This is the formula I will use. It's clean and derived from the principles stated.\n    Looks good. I'm ready to write the solution.", "answer": "$$\n\\boxed{5}\n$$", "id": "4350600"}, {"introduction": "Once an experiment is designed, the next phase is data acquisition. In shotgun sequencing, we randomly sample a genome or transcriptome, and understanding the probabilistic nature of this process is key to assessing data quality. This practice applies the foundational Lander-Waterman model to a realistic scenario involving two different sequencing libraries, allowing you to calculate the expected portion of the genome that remains unsequenced [@problem_id:4350626]. This helps build an intuition for how sequencing depth and read length translate directly into genome coverage and completeness.", "problem": "A microbial genome of length $G = 5.0 \\times 10^{6}$ base pairs (bp) is shotgun-sequenced using two single-end libraries on a Next-Generation Sequencing (NGS) platform (Next-Generation Sequencing (NGS)). After quality control and removal of low-quality reads, Library A contributes $N_{A} = 6.0 \\times 10^{4}$ reads of fixed length $L_{A} = 150$ bp, and Library B contributes $N_{B} = 4.0 \\times 10^{4}$ reads of fixed length $L_{B} = 300$ bp. Assume the classical Lander–Waterman assumptions hold: read start sites are placed uniformly and independently along the genome; reads have fixed lengths; there are no edge or boundary effects; and there are no biases in sampling across the genome.\n\nStarting from the definition of a homogeneous Poisson process for read start positions along the one-dimensional genome coordinate and the independence of the two libraries, derive an expression for the expected number of bases in the genome that remain uncovered by any read from either library. Then, evaluate this expression for the given $G$, $N_{A}$, $L_{A}$, $N_{B}$, and $L_{B}$. Express the final expected uncovered genome length in base pairs (bp) and round your answer to four significant figures.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n- Genome length: $G = 5.0 \\times 10^{6}$ bp\n- Library A, number of reads: $N_{A} = 6.0 \\times 10^{4}$\n- Library A, read length: $L_{A} = 150$ bp\n- Library B, number of reads: $N_{B} = 4.0 \\times 10^{4}$\n- Library B, read length: $L_{B} = 300$ bp\n- Assumptions:\n  - The Lander–Waterman model assumptions hold.\n  - Read start sites are placed uniformly and independently along the genome.\n  - Read start positions follow a homogeneous Poisson process.\n  - The two libraries (A and B) are independent.\n  - No edge or boundary effects are considered.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is based on the Lander–Waterman model, a cornerstone of bioinformatics for analyzing shotgun sequencing data. The use of a Poisson process to model read placement is a standard and well-established method. The numerical values provided for genome size, read counts, and read lengths are realistic for a microbial sequencing experiment.\n- **Well-Posed**: The problem provides all necessary parameters and a clear set of assumptions to derive a unique, meaningful solution for the expected number of uncovered bases.\n- **Objective**: The problem is stated using precise, quantitative language, free of any subjectivity or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a standard application of the Lander-Waterman theory for genomic sequencing coverage. The solution will proceed by deriving the relevant formula and then substituting the given values.\n\n### Derivation of the Solution\n\nThe problem asks for the expected number of bases in the genome that are not covered by any read. We can solve this by first finding the probability that a single, arbitrary base is uncovered, and then extending this to the entire genome.\n\nLet's consider a single base at an arbitrary position $x$ in the genome. The problem states that the starting positions of reads are distributed uniformly and independently, following a homogeneous Poisson process.\n\nFor Library A, there are $N_{A}$ reads. The rate of read starts per base pair is $\\lambda_{A} = \\frac{N_{A}}{G}$. A read of length $L_{A}$ will cover the base at position $x$ if and only if it starts at a position in the interval $[x - L_{A} + 1, x]$. The length of this interval is $L_{A}$. The assumption of no edge effects means we can ignore complications when $x$ is near the beginning or end of the genome.\n\nThe number of reads from Library A starting in this interval of length $L_{A}$ follows a Poisson distribution with mean $\\mu_{A} = \\lambda_{A} L_{A} = \\frac{N_{A} L_{A}}{G}$. This value is also known as the sequencing coverage or depth provided by Library A, denoted as $c_{A}$.\n$$c_{A} = \\frac{N_{A} L_{A}}{G}$$\nThe probability that the base at position $x$ is **not** covered by any read from Library A is the probability that zero reads start in the specified interval. For a Poisson distribution with mean $c_{A}$, this probability is:\n$$P(\\text{uncovered by A}) = \\frac{c_{A}^{0} \\exp(-c_{A})}{0!} = \\exp(-c_{A})$$\n\nSimilarly, for Library B, with $N_{B}$ reads of length $L_{B}$, the rate of read starts is $\\lambda_{B} = \\frac{N_{B}}{G}$. A read of length $L_{B}$ covers position $x$ if it starts in the interval $[x - L_{B} + 1, x]$. The number of reads from Library B starting in this interval is a Poisson random variable with mean $\\mu_{B} = \\lambda_{B} L_{B} = \\frac{N_{B} L_{B}}{G}$. This is the coverage depth from Library B, $c_{B}$.\n$$c_{B} = \\frac{N_{B} L_{B}}{G}$$\nThe probability that the base at position $x$ is **not** covered by any read from Library B is:\n$$P(\\text{uncovered by B}) = \\exp(-c_{B})$$\n\nThe problem states that the two libraries are independent. Therefore, the event \"uncovered by A\" and the event \"uncovered by B\" are independent. The probability that the base at $x$ is uncovered by **any** read from **either** library is the probability that it is uncovered by A AND uncovered by B.\n$$P(\\text{uncovered}) = P(\\text{uncovered by A}) \\times P(\\text{uncovered by B})$$\n$$P(\\text{uncovered}) = \\exp(-c_{A}) \\times \\exp(-c_{B}) = \\exp(-(c_{A} + c_{B}))$$\nSubstituting the expressions for $c_A$ and $c_B$:\n$$P(\\text{uncovered}) = \\exp\\left(-\\left(\\frac{N_{A} L_{A}}{G} + \\frac{N_{B} L_{B}}{G}\\right)\\right) = \\exp\\left(-\\frac{N_A L_A + N_B L_B}{G}\\right)$$\n\nLet $E[U]$ be the expected number of uncovered bases in the entire genome of length $G$. We can define an indicator random variable $I_i$ for each base $i=1, 2, \\dots, G$, where $I_i=1$ if base $i$ is uncovered and $I_i=0$ if it is covered. The expected value of $I_i$ is $E[I_i] = 1 \\cdot P(I_i=1) + 0 \\cdot P(I_i=0) = P(\\text{base } i \\text{ is uncovered})$.\nDue to the uniform distribution assumption, this probability is the same for all bases and equals the $P(\\text{uncovered})$ derived above.\nThe total number of uncovered bases is $U = \\sum_{i=1}^{G} I_i$. By linearity of expectation:\n$$E[U] = E\\left[\\sum_{i=1}^{G} I_i\\right] = \\sum_{i=1}^{G} E[I_i] = G \\cdot P(\\text{uncovered})$$\nThus, the expression for the expected number of uncovered bases is:\n$$E[U] = G \\exp\\left(-\\frac{N_A L_A + N_B L_B}{G}\\right)$$\n\nNow, we evaluate this expression using the given values.\n- $G = 5.0 \\times 10^{6}$ bp\n- $N_{A} = 6.0 \\times 10^{4}$\n- $L_{A} = 150$ bp\n- $N_{B} = 4.0 \\times 10^{4}$\n- $L_{B} = 300$ bp\n\nFirst, calculate the total number of bases sequenced, which is the numerator of the exponent's argument:\n$$N_A L_A = (6.0 \\times 10^{4}) \\times 150 = 9.0 \\times 10^{6}$$\n$$N_B L_B = (4.0 \\times 10^{4}) \\times 300 = 12.0 \\times 10^{6}$$\n$$N_A L_A + N_B L_B = 9.0 \\times 10^{6} + 12.0 \\times 10^{6} = 21.0 \\times 10^{6}$$\n\nNext, calculate the total coverage depth, $c = c_A + c_B$:\n$$c = \\frac{N_A L_A + N_B L_B}{G} = \\frac{21.0 \\times 10^{6}}{5.0 \\times 10^{6}} = 4.2$$\n\nFinally, calculate the expected number of uncovered bases:\n$$E[U] = G \\exp(-c) = (5.0 \\times 10^{6}) \\times \\exp(-4.2)$$\n$$E[U] \\approx (5.0 \\times 10^{6}) \\times 0.014995576$$\n$$E[U] \\approx 74977.88 \\text{ bp}$$\n\nThe problem requires the answer to be rounded to four significant figures.\n$$E[U] \\approx 74980 \\text{ bp}$$\nIn scientific notation, this is $7.498 \\times 10^{4}$ bp.", "answer": "$$\\boxed{7.498 \\times 10^4}$$", "id": "4350626"}, {"introduction": "Raw read counts from an RNA-seq experiment are not directly comparable across samples due to variations in sequencing depth and library composition. Normalization is therefore an essential first step in data analysis, and this exercise takes you inside one of the most robust and widely used methods. You will implement the \"median-of-ratios\" normalization from the popular DESeq2 package, starting from its underlying multiplicative model [@problem_id:4350607]. This hands-on implementation will transform a \"black box\" procedure into a transparent algorithm, deepening your understanding of how to generate meaningful, comparable expression data.", "problem": "You are given count matrices from high-throughput ribonucleic acid sequencing (RNA-seq) experiments, where entries represent non-negative integers interpreted as read counts per gene (feature) per sample. The goal is to estimate sample-specific scaling factors and compute normalized counts using the Differential Expression analysis using Sequence count data version $2$ (DESeq$2$) median-of-ratios approach, derived from a principled multiplicative measurement model common in systems biomedicine.\n\nStarting point and assumptions:\n- Measurement model: For each gene $i$ and sample $j$, the observed count $K_{ij}$ is modeled as a realization of a distribution with mean $\\mu_{ij}$ satisfying a multiplicative structure $\\mu_{ij} = s_j \\cdot q_i$, where $s_j$ encodes sample-specific sequencing depth or library size and $q_i$ encodes gene-specific expression level. This is consistent with widely used count models such as the Negative Binomial distribution in RNA-seq analysis, where variance is overdispersed relative to the Poisson distribution. The analysis here focuses on estimating $s_j$ and constructing normalized counts $N_{ij}$ such that downstream comparisons reflect $q_i$ rather than $s_j$.\n- Robust estimation principle: A scale estimator for $s_j$ should be resistant to gene-specific outliers and compositional bias and should not require an external control. This motivates using a gene-wise reference level across samples and a sample-wise robust aggregation of ratios.\n\nTask:\n- Derive, from the above multiplicative base, the algorithmic procedure which uses a gene-wise reference and a robust sample-wise aggregation of ratios to estimate $s_j$ and compute normalized counts $N_{ij}$.\n- Implement the procedure with the following explicit conventions to ensure a deterministic output:\n  $1.$ Compute a gene-wise reference for each gene $i$ as the geometric mean across samples, but only if the counts for that gene are strictly positive in all samples. Formally, for gene $i$, if $\\prod_{j} \\mathbb{I}(K_{ij} > 0) = 1$, define $G_i$ as $G_i = \\exp\\left( \\frac{1}{m} \\sum_{j=1}^{m} \\log K_{ij} \\right)$ where $m$ is the number of samples; otherwise set $G_i = 0$ and exclude gene $i$ from ratio computations.\n  $2.$ For each sample $j$, form the set of ratios $\\{ R_{ij} = K_{ij} / G_i \\mid G_i > 0 \\}$ and define the sample size factor $s_j$ as the median of these ratios. If the set is empty for a sample (no gene has strictly positive counts across all samples), define $s_j = 1$.\n  $3.$ Define normalized counts as $N_{ij} = K_{ij} / s_j$ for all genes $i$ and samples $j$.\n  $4.$ Round all floating-point outputs to $6$ decimal places.\n- You must express the final output as a single line of text containing a comma-separated list enclosed in square brackets, aggregating the results for all test cases. For each test case, the result must be a list of two lists: the first list is the size factors $[s_1, s_2, \\dots, s_m]$, and the second list is the row-major flattened list of normalized counts $[N_{11}, N_{12}, \\dots, N_{1m}, N_{21}, \\dots, N_{nm}]$.\n\nUnits and numerical format:\n- There are no physical units in this problem; all outputs are unitless counts or scaling factors.\n- All outputs must be floating-point numbers rounded to $6$ decimal places.\n- No percentage signs are permitted; any fractional quantities must be represented as decimal numbers.\n\nTest suite:\nProvide results for the following test cases, which are gene-by-sample count matrices. Each test case is a matrix of integers; you must compute the corresponding size factors and normalized counts following the above conventions.\n\n- Test Case $1$ (happy path, strictly positive counts, proportional scaling):\n  Genes $3$, Samples $3$,\n  Matrix:\n  $$\n  \\begin{bmatrix}\n  100 & 200 & 50 \\\\\n  200 & 400 & 100 \\\\\n  300 & 600 & 150\n  \\end{bmatrix}\n  $$\n\n- Test Case $2$ (genes with zeros excluded from reference, robust median behavior):\n  Genes $4$, Samples $3$,\n  Matrix:\n  $$\n  \\begin{bmatrix}\n  10 & 20 & 5 \\\\\n  0 & 0 & 0 \\\\\n  4 & 8 & 2 \\\\\n  7 & 14 & 3\n  \\end{bmatrix}\n  $$\n\n- Test Case $3$ (boundary case, no usable genes for ratio computation in at least one sample, default size factor):\n  Genes $2$, Samples $2$,\n  Matrix:\n  $$\n  \\begin{bmatrix}\n  0 & 5 \\\\\n  0 & 10\n  \\end{bmatrix}\n  $$\n\nOutput specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[result1,result2,result3]$), where each $resultk$ corresponds to Test Case $k$ and is itself a list of two lists as described above.", "solution": "We begin from the multiplicative measurement model that underpins count-based high-throughput assays such as ribonucleic acid sequencing (RNA-seq). For each gene $i$ and sample $j$, the expected value of the observed count $K_{ij}$ is modeled as $\\mu_{ij} = s_j \\cdot q_i$, where $s_j$ reflects sample-specific scaling (for example, sequencing depth or library size) and $q_i$ reflects gene-specific abundance. This structure is consistent with widely used Negative Binomial count models where $K_{ij}$ has mean $\\mu_{ij}$ and variance exceeding the mean due to overdispersion, but the scale of $\\mu_{ij}$ remains decomposable into a sample-specific factor and a gene-specific factor.\n\nThe central objective is to estimate the sample-specific scale parameters $s_j$ without confounding from $q_i$, and then to form normalized counts $N_{ij}$ that remove the influence of $s_j$, enabling downstream comparisons of $q_i$ across samples. To do so, we employ a robust ratio-based estimator derived from the multiplicative model.\n\nConsider the following principle: if $\\mu_{ij} = s_j \\cdot q_i$, then quotients of observed counts by an estimate of $q_i$ will concentrate around $s_j$. A natural, distribution-free reference for $q_i$ across samples is a gene-wise geometric mean of observed counts, because the geometric mean respects multiplicative structure. Specifically, for gene $i$ and $m$ samples, define\n$$\nG_i = \\exp\\left( \\frac{1}{m} \\sum_{j=1}^{m} \\log K_{ij} \\right),\n$$\nbut only when all $K_{ij} > 0$ so that the logarithm is defined and the multiplicative reference is meaningful across all samples. If any count is zero for gene $i$, set $G_i = 0$ and exclude that gene from ratio computations. This exclusion adheres to the practical constraint that the geometric mean across all samples is zero whenever any entry is zero, and it avoids introducing arbitrary pseudocounts that would alter the multiplicative structure.\n\nUnder the multiplicative model, for genes with strictly positive counts across all samples, we have $K_{ij} \\approx s_j \\cdot q_i$ with random variation around the mean, so ratios\n$$\nR_{ij} = \\frac{K_{ij}}{G_i}\n$$\nare approximately $s_j \\cdot \\frac{q_i}{G_i}$. Since $G_i$ is a multiplicative reference of $q_i$ across samples, $\\frac{q_i}{G_i}$ is constant across $j$ for gene $i$, and across genes the variation in $R_{ij}$ for a fixed $j$ is driven by gene-specific deviations and stochastic noise. A robust aggregation of the set $\\{ R_{ij} : G_i > 0 \\}$ for fixed $j$ should therefore recover $s_j$ up to multiplicative noise. The sample-wise median is a robust estimator of central tendency that is resistant to outliers and compositional effects, making it well-suited to this purpose.\n\nHence, for each sample $j$, we define the size factor\n$$\ns_j = \\operatorname{median}\\{ R_{ij} \\mid G_i > 0 \\}.\n$$\nIf the set of usable genes (those with $G_i > 0$) is empty for sample $j$, then the data provide no information to estimate $s_j$. For determinism, we adopt the convention $s_j = 1$ in this case, which leaves counts unchanged and makes explicit that normalization could not be performed.\n\nWith size factors computed, normalized counts are produced by removing the sample-specific scale:\n$$\nN_{ij} = \\frac{K_{ij}}{s_j}.\n$$\nThese normalized counts have expectation proportional to $q_i$ and are suitable for downstream comparative analyses, as the influence of $s_j$ has been removed.\n\nAlgorithmic design:\n$1.$ Input a gene-by-sample matrix of non-negative integers $K$. Let $n$ denote the number of genes (rows) and $m$ the number of samples (columns).\n$2.$ For each gene $i \\in \\{1,\\dots,n\\}$, if $\\prod_{j=1}^{m} \\mathbb{I}(K_{ij} > 0) = 1$, compute $G_i$ as above using the arithmetic mean of $\\log K_{ij}$ across $j$ and exponentiating; otherwise set $G_i = 0$.\n$3.$ For each sample $j \\in \\{1,\\dots,m\\}$, form the ratio set $\\{ R_{ij} = K_{ij} / G_i : G_i > 0 \\}$. If the ratio set is non-empty, set $s_j$ to the median of these ratios; if it is empty, set $s_j = 1$.\n$4.$ Compute $N_{ij} = K_{ij} / s_j$ for all $i,j$.\n$5.$ Round all floating-point outputs to $6$ decimal places to produce deterministic results.\n\nCoverage of test suite:\n- Test Case $1$ uses strictly positive counts with proportional scaling across samples. The multiplicative model implies that $s_j$ should reflect the proportionality constants, and normalized counts $N_{ij}$ should align gene-wise across samples.\n- Test Case $2$ includes genes with zeros, which are excluded from geometric mean computation. The robust median across the remaining ratios yields size factors consistent with proportional scaling, demonstrating exclusion handling and robustness.\n- Test Case $3$ presents a boundary condition with no gene having strictly positive counts across all samples. The algorithm sets $s_j = 1$ for all samples, and normalized counts equal the original counts, demonstrating the specified default behavior.\n\nImplementation details:\n- Use numerical arrays and basic vectorized operations to compute geometric means, medians, and normalized counts.\n- Ensure rounding to $6$ decimal places for all outputs.\n- Produce a single line of output aggregating results for all test cases in the specified nested list format, where each test case result is a pair of lists: size factors and flattened normalized counts in row-major order.", "answer": "```python\nimport numpy as np\n\ndef geometric_means_strict_positive(counts: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute gene-wise geometric means across samples only if all counts are > 0.\n    If any count for a gene is zero, set its geometric mean to 0.\n    counts: 2D array of shape (genes, samples)\n    Returns: 1D array of length genes with geometric means (0 where excluded).\n    \"\"\"\n    # Identify genes with strictly positive counts across all samples\n    positive_mask = np.all(counts > 0, axis=1)\n    gm = np.zeros(counts.shape[0], dtype=float)\n    # For genes with strictly positive counts, compute geometric mean\n    if np.any(positive_mask):\n        # Use logs to compute geometric mean to avoid overflow\n        logs = np.log(counts[positive_mask].astype(float))\n        gm_pos = np.exp(np.mean(logs, axis=1))\n        gm[positive_mask] = gm_pos\n    return gm\n\ndef compute_size_factors(counts: np.ndarray, gm: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute DESeq2-like size factors by median-of-ratios.\n    For each sample, compute ratios K_ij / G_i over genes with G_i > 0.\n    If no ratios exist for a sample, set its size factor to 1.\n    \"\"\"\n    genes, samples = counts.shape\n    size_factors = np.ones(samples, dtype=float)\n    valid_genes = gm > 0\n    for j in range(samples):\n        if np.any(valid_genes):\n            ratios = counts[valid_genes, j] / gm[valid_genes]\n            if ratios.size > 0:\n                size_factors[j] = np.median(ratios)\n            else:\n                size_factors[j] = 1.0\n        else:\n            size_factors[j] = 1.0\n    return size_factors\n\ndef normalize_counts(counts: np.ndarray, size_factors: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Normalize counts by dividing each column by the corresponding size factor.\n    \"\"\"\n    # Avoid division by zero: size_factors should be positive; if any zero, treat as 1.\n    safe_sf = np.where(size_factors == 0, 1.0, size_factors)\n    return counts.astype(float) / safe_sf[np.newaxis, :]\n\ndef round_array(arr: np.ndarray, decimals: int = 6) -> np.ndarray:\n    return np.round(arr.astype(float), decimals=decimals)\n\ndef format_list(obj):\n    \"\"\"\n    Recursively format lists containing floats/ints to a string with 6 decimal places for floats.\n    \"\"\"\n    if isinstance(obj, (float, np.floating)):\n        return f\"{float(obj):.6f}\"\n    if isinstance(obj, (int, np.integer)):\n        return str(int(obj))\n    if isinstance(obj, list):\n        return \"[\" + \",\".join(format_list(x) for x in obj) + \"]\"\n    if isinstance(obj, np.ndarray):\n        # Convert to list and format\n        return format_list(obj.tolist())\n    # Fallback\n    return str(obj)\n\ndef solve():\n    # Define the test cases from the problem statement (genes x samples)\n    test_cases = [\n        np.array([\n            [100, 200, 50],\n            [200, 400, 100],\n            [300, 600, 150]\n        ], dtype=int),\n        np.array([\n            [10, 20, 5],\n            [0, 0, 0],\n            [4, 8, 2],\n            [7, 14, 3]\n        ], dtype=int),\n        np.array([\n            [0, 5],\n            [0, 10]\n        ], dtype=int),\n    ]\n\n    results = []\n    for counts in test_cases:\n        gm = geometric_means_strict_positive(counts)\n        sf = compute_size_factors(counts, gm)\n        norm = normalize_counts(counts, sf)\n        # Round outputs\n        sf_round = round_array(sf, decimals=6)\n        norm_round = round_array(norm, decimals=6)\n        # Flatten normalized counts in row-major order\n        norm_flat = norm_round.flatten(order='C')\n        # Append result: [size_factors, normalized_counts_flat]\n        results.append([sf_round.tolist(), norm_flat.tolist()])\n\n    # Final print statement in the exact required format.\n    # Single line: aggregate results as a comma-separated list enclosed in square brackets.\n    print(format_list(results))\n\nsolve()\n```", "id": "4350607"}]}