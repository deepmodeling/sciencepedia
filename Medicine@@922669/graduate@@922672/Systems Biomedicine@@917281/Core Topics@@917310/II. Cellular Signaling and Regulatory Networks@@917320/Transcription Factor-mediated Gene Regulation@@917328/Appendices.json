{"hands_on_practices": [{"introduction": "Understanding gene regulation quantitatively requires connecting the biophysical properties of transcription factor (TF) binding to the resulting gene expression level. This exercise guides you through the application of statistical thermodynamics, a cornerstone of quantitative biology, to model how a cis-regulatory element works. By deriving the impact of a mutation that alters TF binding free energy by $\\Delta \\Delta G$, you will build a first-principles understanding of how changes in DNA sequence translate into predictable changes in transcription [@problem_id:4395664].", "problem": "In the statistical thermodynamic model of transcriptional regulation, a promoter-enhancer system is described by a set of binding microstates corresponding to the occupancy of regulatory proteins at their sites. Under the Central Dogma of molecular biology, transcription is initiated when RNA polymerase (RNAP) is recruited to the promoter, and in the equilibrium thermodynamic framework the probability of RNAP occupancy is given by a ratio of Boltzmann-weighted microstates over the partition function. Consider an enhancer with two transcription factors (TFs), denoted as A and B, each binding independently to a unique site, and a promoter-bound RNAP. Assume the following context and definitions:\n\n- Each binding microstate is characterized by an energy that is additive across bound species and includes interaction energies only when RNAP and a TF are simultaneously bound. Specifically, if TF A is bound concurrently with RNAP, the energy is lowered by an interaction energy $\\epsilon_{A} > 0$, and analogously for TF B with interaction energy $\\epsilon_{B} > 0$. There is no direct interaction between TF A and TF B beyond their additive contributions to the energy, and no three-body interaction beyond the product of pairwise interactions.\n- For each species $i \\in \\{A, B, P\\}$ (where $P$ denotes RNAP), the effective binding weight is $w_{i} = \\frac{[i]}{C_{0}} \\exp\\!\\left(-\\frac{\\Delta G_{i}}{R T}\\right)$, where $[i]$ is the free concentration, $C_{0}$ is a reference concentration, $\\Delta G_{i}$ is the standard binding free energy for species $i$ at its site, $R$ is the gas constant, and $T$ is the absolute temperature.\n- When RNAP and TF $i$ are co-bound, the microstate weight is multiplied by $r_{i} = \\exp\\!\\left(\\frac{\\epsilon_{i}}{R T}\\right)$, reflecting the favorable interaction energy $\\epsilon_{i}$.\n- The predicted expression level is proportional to the equilibrium probability that RNAP is bound to the promoter, and proportionality constants cancel when taking ratios of expression between conditions.\n\nA point mutation in the enhancer changes the motif affinity of TF A by an amount $\\Delta \\Delta G$, so that TF A’s binding free energy becomes $\\Delta G_{A}^{\\text{mut}} = \\Delta G_{A} + \\Delta \\Delta G$. All other parameters remain unchanged.\n\nStarting from the principle that microstate probabilities are given by Boltzmann weights and that the partition function is the sum over all microstates, derive the exact closed-form expression for the ratio of predicted expression in the mutant relative to the wild type, $\\frac{E_{\\text{mut}}}{E_{\\text{wt}}}$, in terms of $\\Delta \\Delta G$, $R$, $T$, $w_{A}$, $w_{B}$, $w_{P}$, $r_{A}$, and $r_{B}$. Do not assume any limiting regime (such as weak binding or saturation), and do not introduce any heuristic approximations. Express your final answer as a single analytic expression. No numerical substitution is required.", "solution": "The problem requires the derivation of the ratio of gene expression levels for a mutant versus a wild-type transcriptional system, based on a statistical thermodynamic model. The system consists of a promoter that binds RNA polymerase (RNAP, denoted P) and an enhancer with two independent sites for transcription factors (TFs) A and B.\n\nFirst, I shall validate the problem statement.\n\n### Step 1: Extract Givens\n-   System components: Transcription factors A and B, RNA Polymerase P.\n-   Binding model: Independent binding to unique sites.\n-   Energy model: Additive energies for bound species. An interaction energy $\\epsilon_{A} > 0$ exists for co-binding of A and P, and $\\epsilon_{B} > 0$ for B and P. No direct A-B interaction.\n-   Binding weights: $w_{i} = \\frac{[i]}{C_{0}} \\exp(-\\frac{\\Delta G_{i}}{R T})$ for $i \\in \\{A, B, P\\}$.\n-   Interaction factors: $r_{i} = \\exp(\\frac{\\epsilon_{i}}{R T})$ for $i \\in \\{A, B\\}$. The weight of a state with P and TF $i$ co-bound is multiplied by $r_{i}$.\n-   Gene Expression: $E \\propto P(\\text{RNAP bound})$, where $P(\\text{RNAP bound})$ is the equilibrium probability of RNAP occupying the promoter.\n-   Mutation: A mutation changes the binding free energy of TF A from $\\Delta G_{A}$ to $\\Delta G_{A}^{\\text{mut}} = \\Delta G_{A} + \\Delta \\Delta G$. All other parameters are constant.\n-   Objective: Derive the closed-form expression for the ratio $\\frac{E_{\\text{mut}}}{E_{\\text{wt}}}$ in terms of $\\Delta \\Delta G$, $R$, $T$, $w_{A}$, $w_{B}$, $w_{P}$, $r_{A}$, and $r_{B}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the Shea-Ackers model of transcriptional regulation, a cornerstone of quantitative systems biology. It is well-posed, with all necessary parameters and relationships defined to derive a unique solution. The language is objective and precise. The problem is self-contained, consistent, and does not violate any scientific principles. It is a formalizable and relevant problem in its specified field.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with a full derivation.\n\nThe core of the statistical thermodynamic model is the partition function, $Z$, which is the sum of the statistical weights of all possible microstates of the system. The probability of any particular configuration is the ratio of its weight to the partition function.\n\nThe system has $3$ species (A, B, P) that can be either bound or unbound, leading to $2^{3} = 8$ possible microstates. Let us enumerate the microstates and their corresponding statistical weights for the wild-type (wt) system. The weight of the empty state (no proteins bound) is defined as $1$.\n\nThe microstates and their weights are:\n1.  Empty state: weight = $1$\n2.  Only A bound: weight = $w_{A}$\n3.  Only B bound: weight = $w_{B}$\n4.  Only P bound: weight = $w_{P}$\n5.  A and B bound: weight = $w_{A} w_{B}$ (independent binding)\n6.  A and P bound: weight = $w_{A} w_{P} r_{A}$ (with interaction)\n7.  B and P bound: weight = $w_{B} w_{P} r_{B}$ (with interaction)\n8.  A, B, and P bound: weight = $w_{A} w_{B} w_{P} r_{A} r_{B}$ (pairwise interactions are multiplicative)\n\nThe wild-type partition function, $Z_{\\text{wt}}$, is the sum of these weights:\n$$Z_{\\text{wt}} = 1 + w_{A} + w_{B} + w_{P} + w_{A} w_{B} + w_{A} w_{P} r_{A} + w_{B} w_{P} r_{B} + w_{A} w_{B} w_{P} r_{A} r_{B}$$\nThis expression can be factored by grouping terms based on the occupancy of P:\n$$Z_{\\text{wt}} = (1 + w_{A} + w_{B} + w_{A} w_{B}) + w_{P}(1 + w_{A} r_{A} + w_{B} r_{B} + w_{A} w_{B} r_{A} r_{B})$$\nFactoring further yields a more compact form:\n$$Z_{\\text{wt}} = (1+w_{A})(1+w_{B}) + w_{P}(1+w_{A} r_{A})(1+w_{B} r_{B})$$\n\nThe predicted expression level, $E_{\\text{wt}}$, is proportional to the probability of RNAP being bound. This probability, $P_{\\text{wt}}(\\text{P bound})$, is the sum of weights of all microstates containing P, divided by the partition function $Z_{\\text{wt}}$.\nThe sum of weights for states with P bound is the second term in the grouped expression for $Z_{\\text{wt}}$:\n$$\\sum W(\\text{P bound}) = w_{P}(1+w_{A} r_{A})(1+w_{B} r_{B})$$\nTherefore, the probability is:\n$$P_{\\text{wt}}(\\text{P bound}) = \\frac{w_{P}(1+w_{A} r_{A})(1+w_{B} r_{B})}{Z_{\\text{wt}}} = \\frac{w_{P}(1+w_{A} r_{A})(1+w_{B} r_{B})}{(1+w_{A})(1+w_{B}) + w_{P}(1+w_{A} r_{A})(1+w_{B} r_{B})}$$\n\nNow, we consider the effect of the mutation. The mutation changes the binding free energy of TF A by $\\Delta \\Delta G$, such that $\\Delta G_{A}^{\\text{mut}} = \\Delta G_{A} + \\Delta \\Delta G$. This affects the binding weight $w_{A}$. The new weight, $w_{A}^{\\text{mut}}$, is:\n$$w_{A}^{\\text{mut}} = \\frac{[A]}{C_{0}} \\exp\\left(-\\frac{\\Delta G_{A}^{\\text{mut}}}{RT}\\right) = \\frac{[A]}{C_{0}} \\exp\\left(-\\frac{\\Delta G_{A} + \\Delta \\Delta G}{RT}\\right)$$\n$$w_{A}^{\\text{mut}} = \\left(\\frac{[A]}{C_{0}} \\exp\\left(-\\frac{\\Delta G_{A}}{RT}\\right)\\right) \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right) = w_{A} \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right)$$\n\nTo find the expression probability for the mutant, $P_{\\text{mut}}(\\text{P bound})$, we replace $w_{A}$ with $w_{A}^{\\text{mut}}$ in the wild-type probability expression. All other parameters remain unchanged.\nThe mutant partition function, $Z_{\\text{mut}}$, is:\n$$Z_{\\text{mut}} = (1+w_{A}^{\\text{mut}})(1+w_{B}) + w_{P}(1+w_{A}^{\\text{mut}} r_{A})(1+w_{B} r_{B})$$\nThe probability of RNAP binding for the mutant is:\n$$P_{\\text{mut}}(\\text{P bound}) = \\frac{w_{P}(1+w_{A}^{\\text{mut}} r_{A})(1+w_{B} r_{B})}{Z_{\\text{mut}}}$$\n\nThe problem asks for the ratio of expression levels, $\\frac{E_{\\text{mut}}}{E_{\\text{wt}}}$. Since expression is proportional to the RNAP binding probability, the proportionality constant cancels out:\n$$\\frac{E_{\\text{mut}}}{E_{\\text{wt}}} = \\frac{P_{\\text{mut}}(\\text{P bound})}{P_{\\text{wt}}(\\text{P bound})}$$\nSubstituting the expressions for the probabilities:\n$$\\frac{E_{\\text{mut}}}{E_{\\text{wt}}} = \\frac{\\frac{w_{P}(1+w_{A}^{\\text{mut}} r_{A})(1+w_{B} r_{B})}{Z_{\\text{mut}}}}{\\frac{w_{P}(1+w_{A} r_{A})(1+w_{B} r_{B})}{Z_{\\text{wt}}}}$$\nThe terms $w_{P}$ and $(1+w_{B} r_{B})$ cancel, simplifying the ratio to:\n$$\\frac{E_{\\text{mut}}}{E_{\\text{wt}}} = \\frac{1+w_{A}^{\\text{mut}} r_{A}}{1+w_{A} r_{A}} \\cdot \\frac{Z_{\\text{wt}}}{Z_{\\text{mut}}}$$\nNow, we substitute the expressions for $Z_{\\text{wt}}$, $Z_{\\text{mut}}$, and $w_{A}^{\\text{mut}}$:\n$$\\frac{E_{\\text{mut}}}{E_{\\text{wt}}} = \\frac{1+w_{A} r_{A} \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right)}{1+w_{A} r_{A}} \\times \\frac{(1+w_{A})(1+w_{B}) + w_{P}(1+w_{A} r_{A})(1+w_{B} r_{B})}{(1+w_{A} \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right))(1+w_{B}) + w_{P}(1+w_{A} r_{A} \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right))(1+w_{B} r_{B})}$$\nThis can be written as a single fraction:\n$$\\frac{E_{\\text{mut}}}{E_{\\text{wt}}} = \\frac{\\left(1+w_{A} r_{A} \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right)\\right) \\left[ (1+w_{A})(1+w_{B}) + w_{P}(1+w_{A} r_{A})(1+w_{B} r_{B}) \\right]}{\\left(1+w_{A} r_{A}\\right) \\left[ (1+w_{A} \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right))(1+w_{B}) + w_{P}(1+w_{A} r_{A} \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right))(1+w_{B} r_{B}) \\right]}$$\nThis is the final, exact closed-form expression for the ratio of mutant to wild-type expression levels.", "answer": "$$\\boxed{\\frac{\\left(1+w_{A} r_{A} \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right)\\right) \\left( (1+w_{A})(1+w_{B}) + w_{P}(1+w_{A} r_{A})(1+w_{B} r_{B}) \\right)}{\\left(1+w_{A} r_{A}\\right) \\left( (1+w_{A} \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right))(1+w_{B}) + w_{P}(1+w_{A} r_{A} \\exp\\left(-\\frac{\\Delta \\Delta G}{RT}\\right))(1+w_{B} r_{B}) \\right)}}$$", "id": "4395664"}, {"introduction": "While thermodynamic models provide a powerful picture of steady-state regulation, cellular processes are inherently stochastic due to the low copy number of molecules. This practice moves beyond deterministic descriptions to explore how noise propagates through a simple gene cascade [@problem_id:4395606]. Using the Linear Noise Approximation (LNA), you will derive how fluctuations in a transcription factor's concentration contribute to the variance in its target's expression, providing insight into the dynamic and noisy nature of gene regulation.", "problem": "Consider a minimal transcription factor-target cascade in a systems biomedicine context, where a transcription factor $X(t)$ is synthesized and degraded by a birth-death process, and a downstream target $Y(t)$ is synthesized at a rate that depends on $X(t)$ via a Hill-type regulatory function. Specifically, the reaction scheme is:\n- Transcription factor $X$: synthesis at rate $\\alpha_{x}$ and degradation at rate $\\gamma_{x} X$.\n- Target $Y$: synthesis at rate $\\alpha_{y} h(X)$ and degradation at rate $\\gamma_{y} Y$.\n\nAssume a Hill function $h(X)$ with Hill coefficient $n$ and dissociation constant $K$,\n$$\nh(X) = \\frac{X^{n}}{K^{n} + X^{n}}.\n$$\nWork under the following scientifically standard assumptions and definitions:\n- The Central Dogma of Molecular Biology (DNA $\\rightarrow$ RNA $\\rightarrow$ Protein) provides the biophysical basis for transcription factor-mediated regulation of gene expression.\n- The deterministic mean-field steady state of the transcription factor is $\\bar{X} = \\alpha_{x} / \\gamma_{x}$, and the deterministic steady state of the target is $\\bar{Y} = \\alpha_{y} h(\\bar{X}) / \\gamma_{y}$.\n- Stochastic fluctuations arise from molecular birth-death events described at mesoscopic scale by the Chemical Master Equation. Use the Linear Noise Approximation (LNA) to analyze fluctuations by expanding around the deterministic steady state.\n- Focus exclusively on the propagation of upstream fluctuations (in $X$) into downstream variance of $Y$; neglect intrinsic birth-death noise of $Y$ itself so that the only noise source is in the $X$ dynamics. This isolates the contribution of $X$ fluctuations to $\\mathrm{Var}(Y)$.\n\nStarting from these bases, derive, using first principles of the Linear Noise Approximation, a closed-form analytic expression for the steady-state variance contribution in $Y$ that is caused by upstream fluctuations in $X$, denoted $\\mathrm{Var}_{\\mathrm{ext}}(Y)$. Your final expression must be in terms of $\\alpha_{x}$, $\\gamma_{x}$, $\\alpha_{y}$, $\\gamma_{y}$, $K$, $n$, and $\\bar{X}$, and must explicitly incorporate the local sensitivity of the regulatory function $h(X)$ at $X = \\bar{X}$.\n\nAnswer form requirement:\n- Provide a single closed-form analytic expression. Do not provide numerical approximations.\n- Do not include any units in the final expression.", "solution": "The user-provided problem has been rigorously validated and is determined to be a well-posed, scientifically grounded problem in the field of systems biomedicine. It requests the derivation of the extrinsic variance of a target gene's product, a standard calculation within the framework of stochastic gene expression. We will proceed with a first-principles derivation using the Linear Noise Approximation (LNA).\n\nOur system consists of two molecular species, a transcription factor $X$ and a target protein $Y$. Their dynamics are described by a set of coupled stochastic processes.\n\nFirst, we establish the deterministic, mean-field description of the system. The rate of change of the mean concentration (or number of molecules) of $X$ and $Y$ is given by the following ordinary differential equations (ODEs):\n$$\n\\frac{d[X]}{dt} = \\alpha_x - \\gamma_x [X]\n$$\n$$\n\\frac{d[Y]}{dt} = \\alpha_y h([X]) - \\gamma_y [Y]\n$$\nwhere $h([X]) = \\frac{[X]^n}{K^n + [X]^n}$. At steady state, the time derivatives are zero, which yields the mean steady-state concentrations provided in the problem statement:\n$$\n\\bar{X} = \\frac{\\alpha_x}{\\gamma_x}\n$$\n$$\n\\bar{Y} = \\frac{\\alpha_y}{\\gamma_y} h(\\bar{X})\n$$\n\nWe now analyze the fluctuations around this steady state using the Linear Noise Approximation (LNA). We express the instantaneous state of the system as the sum of the deterministic steady state and a stochastic fluctuation term:\n$$\nX(t) = \\bar{X} + \\xi_x(t)\n$$\n$$\nY(t) = \\bar{Y} + \\xi_y(t)\n$$\n\nThe dynamics of the transcription factor $X$ are described by a simple birth-death process. For such a process, the fluctuation dynamics can be described by an Ornstein-Uhlenbeck process governed by the Langevin equation:\n$$\n\\frac{d\\xi_x}{dt} = -\\gamma_x \\xi_x + \\eta_x(t)\n$$\nThe term $\\eta_x(t)$ represents Gaussian white noise, whose strength is determined by the sum of the underlying reaction propensities at steady state. The birth rate is $\\alpha_x$ and the death rate is $\\gamma_x X$. At steady state, the total rate is $\\alpha_x + \\gamma_x \\bar{X}$. Since $\\alpha_x = \\gamma_x \\bar{X}$, the noise strength (the variance of the noise increments) is $\\langle \\eta_x(t) \\eta_x(t') \\rangle = (\\alpha_x + \\gamma_x \\bar{X}) \\delta(t - t') = 2 \\gamma_x \\bar{X} \\delta(t-t')$. The steady-state variance of an Ornstein-Uhlenbeck process $\\frac{dz}{dt} = -az + \\eta(t)$ with $\\langle \\eta(t) \\eta(t') \\rangle = \\Sigma \\delta(t-t')$ is given by $\\frac{\\Sigma}{2a}$. For $X$, this yields:\n$$\n\\mathrm{Var}(X) = \\langle \\xi_x^2 \\rangle = \\frac{2 \\gamma_x \\bar{X}}{2 \\gamma_x} = \\bar{X}\n$$\nThis is a canonical result for a simple birth-death process.\n\nNext, we derive the linearized equation for the fluctuations in $Y$, $\\xi_y$. The problem states that we must neglect the intrinsic noise of $Y$ (i.e., the noise from its own birth and death) and only consider the extrinsic noise propagated from $X$. The dynamics of the fluctuation $\\xi_y$ are found by linearizing the production term for $Y$ around the steady state $\\bar{X}$:\n$$\n\\frac{d(\\bar{Y} + \\xi_y)}{dt} = \\alpha_y h(\\bar{X} + \\xi_x) - \\gamma_y (\\bar{Y} + \\xi_y)\n$$\nUsing a first-order Taylor expansion for $h(X)$ around $\\bar{X}$:\n$$\nh(\\bar{X} + \\xi_x) \\approx h(\\bar{X}) + \\frac{dh}{dX}\\bigg|_{X=\\bar{X}} \\xi_x = h(\\bar{X}) + h'(\\bar{X}) \\xi_x(t)\n$$\nSubstituting this into the dynamic equation for $Y$ and canceling the steady-state terms ($0 = \\alpha_y h(\\bar{X}) - \\gamma_y \\bar{Y}$), we obtain the linearized Langevin equation for $\\xi_y$, driven by the fluctuations $\\xi_x$:\n$$\n\\frac{d\\xi_y}{dt} = -\\gamma_y \\xi_y + \\alpha_y h'(\\bar{X}) \\xi_x(t)\n$$\nTo find the variance of $Y$, we analyze this system in the frequency domain. Let $\\tilde{\\xi}_x(\\omega)$ and $\\tilde{\\xi}_y(\\omega)$ be the Fourier transforms of $\\xi_x(t)$ and $\\xi_y(t)$, respectively. The Fourier transform of the ODE for $\\xi_y$ is:\n$$\ni \\omega \\tilde{\\xi}_y(\\omega) = -\\gamma_y \\tilde{\\xi}_y(\\omega) + \\alpha_y h'(\\bar{X}) \\tilde{\\xi}_x(\\omega)\n$$\nSolving for $\\tilde{\\xi}_y(\\omega)$ gives the relationship between the output and input fluctuations:\n$$\n\\tilde{\\xi}_y(\\omega) = \\frac{\\alpha_y h'(\\bar{X})}{i\\omega + \\gamma_y} \\tilde{\\xi}_x(\\omega)\n$$\nThe Power Spectral Density (PSD) of the output, $S_y(\\omega)$, is related to the PSD of the input, $S_x(\\omega)$, by the squared magnitude of the transfer function:\n$$\nS_y(\\omega) = \\left| \\frac{\\alpha_y h'(\\bar{X})}{i\\omega + \\gamma_y} \\right|^2 S_x(\\omega) = \\frac{(\\alpha_y h'(\\bar{X}))^2}{\\omega^2 + \\gamma_y^2} S_x(\\omega)\n$$\nThe PSD of the input fluctuation $\\xi_x$ (an Ornstein-Uhlenbeck process) is:\n$$\nS_x(\\omega) = \\frac{2 \\gamma_x \\bar{X}}{\\omega^2 + \\gamma_x^2}\n$$\nSubstituting $S_x(\\omega)$ into the expression for $S_y(\\omega)$:\n$$\nS_y(\\omega) = \\frac{(\\alpha_y h'(\\bar{X}))^2}{\\omega^2 + \\gamma_y^2} \\frac{2 \\gamma_x \\bar{X}}{\\omega^2 + \\gamma_x^2}\n$$\nThe steady-state variance is the integral of the PSD over all frequencies, divided by $2\\pi$:\n$$\n\\mathrm{Var}_{\\mathrm{ext}}(Y) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} S_y(\\omega) d\\omega = \\frac{(\\alpha_y h'(\\bar{X}))^2 (2 \\gamma_x \\bar{X})}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{1}{(\\omega^2 + \\gamma_y^2)(\\omega^2 + \\gamma_x^2)} d\\omega\n$$\nThe integral can be solved using partial fraction decomposition and standard integral tables, yielding $\\int_{-\\infty}^{\\infty} \\frac{1}{(\\omega^2+a^2)(\\omega^2+b^2)}d\\omega = \\frac{\\pi}{ab(a+b)}$. With $a=\\gamma_y$ and $b=\\gamma_x$:\n$$\n\\int_{-\\infty}^{\\infty} \\frac{1}{(\\omega^2 + \\gamma_y^2)(\\omega^2 + \\gamma_x^2)} d\\omega = \\frac{\\pi}{\\gamma_y \\gamma_x (\\gamma_y + \\gamma_x)}\n$$\nSubstituting this result back into the expression for the variance:\n$$\n\\mathrm{Var}_{\\mathrm{ext}}(Y) = \\frac{(\\alpha_y h'(\\bar{X}))^2 \\gamma_x \\bar{X}}{\\pi} \\left( \\frac{\\pi}{\\gamma_y \\gamma_x (\\gamma_y + \\gamma_x)} \\right) = \\frac{(\\alpha_y h'(\\bar{X}))^2 \\bar{X}}{\\gamma_y (\\gamma_x + \\gamma_y)}\n$$\nThe final step is to insert the explicit expression for the local sensitivity, $h'(\\bar{X})$. The derivative of the Hill function $h(X) = \\frac{X^n}{K^n + X^n}$ is:\n$$\nh'(X) = \\frac{n X^{n-1}(K^n + X^n) - X^n(n X^{n-1})}{(K^n + X^n)^2} = \\frac{n K^n X^{n-1}}{(K^n + X^n)^2}\n$$\nEvaluating at the steady state $X=\\bar{X}$:\n$$\nh'(\\bar{X}) = \\frac{n K^n \\bar{X}^{n-1}}{(K^n + \\bar{X}^n)^2}\n$$\nSubstituting this into our variance expression gives the final answer:\n$$\n\\mathrm{Var}_{\\mathrm{ext}}(Y) = \\frac{\\left( \\alpha_y \\frac{n K^n \\bar{X}^{n-1}}{(K^n + \\bar{X}^n)^2} \\right)^2 \\bar{X}}{\\gamma_y (\\gamma_x + \\gamma_y)}\n$$\nSimplifying this expression, we arrive at the closed-form solution:\n$$\n\\mathrm{Var}_{\\mathrm{ext}}(Y) = \\frac{\\alpha_y^2 n^2 K^{2n} \\bar{X}^{2(n-1)} \\bar{X}}{\\gamma_y (\\gamma_x + \\gamma_y) (K^n + \\bar{X}^n)^4} = \\frac{\\alpha_y^2 n^2 K^{2n} \\bar{X}^{2n-1}}{\\gamma_y (\\gamma_x + \\gamma_y) (K^n + \\bar{X}^n)^4}\n$$\nThis expression represents the contribution to the variance of the target protein $Y$ that arises solely from the upstream fluctuations of its transcription factor $X$, as required.", "answer": "$$\n\\boxed{\\frac{\\alpha_{y}^{2} n^{2} K^{2n} \\bar{X}^{2n-1}}{\\gamma_{y} (\\gamma_{x} + \\gamma_{y}) (K^{n} + \\bar{X}^{n})^{4}}}\n$$", "id": "4395606"}, {"introduction": "A central goal in systems biology is to map the regulatory networks that control cellular function, a task that requires integrating diverse high-throughput datasets. This exercise introduces a Bayesian framework for this challenge, a powerful approach for making robust inferences from noisy and incomplete data. You will design and implement a model that formally combines evidence of physical binding (from ChIP-seq) and functional consequence (from expression perturbation) to infer causal transcription factor-target relationships and quantify the uncertainty of your predictions [@problem_id:4395615].", "problem": "You are asked to design and implement a principled Bayesian integrative model to infer causal transcription factor–target relationships from two data modalities: Chromatin Immunoprecipitation followed by sequencing (ChIP-seq) and expression perturbation. The setting is as follows. For a single transcription factor and a collection of genes, you observe, for each gene indexed by $g$, a ChIP-seq derived binding score $b_g$ (treated as a dimensionless normalized continuous score) and a log$_2$ fold-change in expression $e_g$ (dimensionless) obtained under a transcription factor perturbation experiment. The modeling task is to combine these two orthogonal signals to infer, for each gene, whether the transcription factor causally regulates it.\n\nFundamental base to use:\n- The Central Dogma of molecular biology implies that transcription factors modulate transcription, which can be assayed by perturbation experiments; binding evidence from ChIP-seq indicates physical occupancy near regulatory regions.\n- Bayes’ theorem for inverse probability: for a latent discrete variable $z_g \\in \\{0,1\\}$ indicating whether the transcription factor causally regulates gene $g$ ($z_g=1$) or not ($z_g=0$), with prior probability $p(z_g=1)=\\pi$, and observed data $x_g=(b_g,e_g)$, the posterior is obtained by $p(z_g=1 \\mid x_g) \\propto p(z_g=1) \\, p(x_g \\mid z_g=1)$.\n- A well-tested measurement model assumption: conditional independence of measurements given the latent regulatory state, that is, $p(b_g,e_g \\mid z_g) = p(b_g \\mid z_g) \\, p(e_g \\mid z_g)$.\n- A well-tested distributional model for measurement variability: Gaussian noise around different mean levels for the two groups $z_g \\in \\{0,1\\}$.\n\nModel specification to implement:\n- Latent causal indicator $z_g \\in \\{0,1\\}$ with prior $p(z_g=1)=\\pi$ and $p(z_g=0)=1-\\pi$.\n- Conditional on $z_g$, assume Gaussian observation models with different parameters across the two classes and conditional independence across modalities:\n  - $b_g \\mid z_g=1 \\sim \\mathcal{N}(\\mu_{b,1}, \\sigma_{b,1}^2)$ and $b_g \\mid z_g=0 \\sim \\mathcal{N}(\\mu_{b,0}, \\sigma_{b,0}^2)$,\n  - $e_g \\mid z_g=1 \\sim \\mathcal{N}(\\mu_{e,1}, \\sigma_{e,1}^2)$ and $e_g \\mid z_g=0 \\sim \\mathcal{N}(\\mu_{e,0}, \\sigma_{e,0}^2)$.\n- For each gene, you must compute:\n  1. The posterior probability $p(z_g=1 \\mid b_g, e_g)$.\n  2. The base-$10$ logarithm of the Bayes factor $\\log_{10}\\mathrm{BF}_g$, where $\\mathrm{BF}_g$ is the likelihood ratio $\\mathrm{BF}_g = \\dfrac{p(b_g \\mid z_g=1)p(e_g \\mid z_g=1)}{p(b_g \\mid z_g=0)p(e_g \\mid z_g=0)}$.\n  3. A posterior uncertainty measure defined as the Shannon entropy of the Bernoulli posterior, $H_g = -\\left[p(z_g=1 \\mid b_g,e_g)\\log p(z_g=1 \\mid b_g,e_g) + (1-p(z_g=1 \\mid b_g,e_g))\\log(1-p(z_g=1 \\mid b_g,e_g))\\right]$ in natural units (nats).\n- For each test case, apply a decision rule: classify a gene as causally regulated if and only if $p(z_g=1 \\mid b_g, e_g) \\ge \\tau$, where $\\tau$ is a specified threshold.\n\nYour program must implement numerically stable computations using logarithms to avoid underflow when evaluating Gaussian likelihoods and Bayes factors.\n\nTest suite:\nImplement your solution for the following three test cases. Each case specifies $(\\pi, \\mu_{b,1}, \\sigma_{b,1}, \\mu_{b,0}, \\sigma_{b,0}, \\mu_{e,1}, \\sigma_{e,1}, \\mu_{e,0}, \\sigma_{e,0})$, the list of observed $(b_g,e_g)$ pairs, and the decision threshold $\\tau$.\n\n- Case $1$ (general integration, moderate prior):\n  - Parameters: $\\pi = 0.3$, $\\mu_{b,1} = 2.0$, $\\sigma_{b,1} = 1.0$, $\\mu_{b,0} = 0.0$, $\\sigma_{b,0} = 1.5$, $\\mu_{e,1} = 1.0$, $\\sigma_{e,1} = 0.7$, $\\mu_{e,0} = 0.0$, $\\sigma_{e,0} = 0.7$.\n  - Genes: $(b_g,e_g)$ in the order $[(3.0, 1.5), (2.5, -0.2), (-0.5, 1.2), (0.1, 0.0), (1.2, 0.6)]$.\n  - Threshold: $\\tau = 0.5$.\n\n- Case $2$ (stringent prior and decision threshold):\n  - Parameters: $\\pi = 0.1$, $\\mu_{b,1} = 2.0$, $\\sigma_{b,1} = 1.0$, $\\mu_{b,0} = 0.0$, $\\sigma_{b,0} = 1.5$, $\\mu_{e,1} = 1.0$, $\\sigma_{e,1} = 0.7$, $\\mu_{e,0} = 0.0$, $\\sigma_{e,0} = 0.7$.\n  - Genes: $(b_g,e_g)$ in the order $[(0.0, 0.0), (4.5, 2.0), (-1.0, -0.8), (2.0, 0.9), (1.0, 0.2)]$.\n  - Threshold: $\\tau = 0.8$.\n\n- Case $3$ (binding non-informative, expression informative):\n  - Parameters: $\\pi = 0.5$, $\\mu_{b,1} = 0.0$, $\\sigma_{b,1} = 2.0$, $\\mu_{b,0} = 0.0$, $\\sigma_{b,0} = 2.0$, $\\mu_{e,1} = 1.2$, $\\sigma_{e,1} = 0.5$, $\\mu_{e,0} = 0.0$, $\\sigma_{e,0} = 1.0$.\n  - Genes: $(b_g,e_g)$ in the order $[(3.0, 1.1), (-2.0, 0.9), (0.0, -0.1), (1.0, 2.0)]$.\n  - Threshold: $\\tau = 0.5$.\n\nOutput specification:\n- For each test case, produce a list with four elements in the following order:\n  $[ \\text{posteriors}, \\text{count}, \\text{log10BFs}, \\text{entropies} ]$, where:\n  - $\\text{posteriors}$ is the list of $p(z_g=1 \\mid b_g,e_g)$ for all genes in the case, each rounded to $3$ decimal places,\n  - $\\text{count}$ is the integer number of genes with $p(z_g=1 \\mid b_g,e_g) \\ge \\tau$ in the case,\n  - $\\text{log10BFs}$ is the list of $\\log_{10}\\mathrm{BF}_g$ for all genes in the case, each rounded to $3$ decimal places,\n  - $\\text{entropies}$ is the list of $H_g$ in nats for all genes in the case, each rounded to $3$ decimal places.\n- Your program should produce a single line of output containing the results for all three test cases as a comma-separated list enclosed in square brackets with no spaces. For example, a syntactically valid shape is $[[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot]]$. No additional text should be printed.", "solution": "The problem statement has been critically examined and is determined to be **valid**. It is scientifically grounded in established principles of molecular biology and Bayesian statistics, is well-posed with a complete and consistent set of definitions and parameters, and is expressed in objective, formal language. There are no identifiable flaws.\n\nThe task is to implement a Bayesian integrative model to infer transcription factor-target gene relationships from two data types: ChIP-seq binding scores ($b_g$) and expression log-fold changes ($e_g$). For each gene $g$, we will compute the posterior probability of it being a causal target, the Bayes factor for the causal model, and the entropy of the posterior distribution.\n\nThe solution is constructed upon the following principles:\n\n**1. Bayesian Inference Framework**\n\nThe core of the model is Bayes' theorem, which allows us to update our prior belief about the regulatory status of a gene in light of observed data. For each gene $g$, we have a latent binary variable $z_g \\in \\{0, 1\\}$, where $z_g=1$ indicates that the gene is causally regulated by the transcription factor, and $z_g=0$ indicates it is not. The prior probability of regulation is given as $p(z_g=1) = \\pi$.\n\nThe posterior probability of regulation, given the observed data $x_g = (b_g, e_g)$, is given by:\n$$\np(z_g=1 \\mid b_g, e_g) = \\frac{p(b_g, e_g \\mid z_g=1) p(z_g=1)}{p(b_g, e_g)}\n$$\nThe denominator, $p(b_g, e_g)$, is the marginal likelihood or evidence, obtained by the law of total probability:\n$$\np(b_g, e_g) = p(b_g, e_g \\mid z_g=1) p(z_g=1) + p(b_g, e_g \\mid z_g=0) p(z_g=0)\n$$\nwhere $p(z_g=0) = 1 - \\pi$.\n\n**2. Conditional Independence and Likelihood Models**\n\nA key modeling assumption is the conditional independence of the two data modalities given the latent regulatory state $z_g$. This is a standard and practical assumption in data integration, reflecting that the physical binding event (ChIP-seq) and its functional consequence (expression change) are distinct measurements whose noise processes are independent, conditional on the true underlying state. This allows us to write the joint likelihood as a product of individual likelihoods:\n$$\np(b_g, e_g \\mid z_g) = p(b_g \\mid z_g) \\, p(e_g \\mid z_g)\n$$\nThe problem specifies that each of these conditional likelihoods follows a Gaussian distribution:\n- For binding scores: $b_g \\mid z_g=k \\sim \\mathcal{N}(\\mu_{b,k}, \\sigma_{b,k}^2)$ for $k \\in \\{0,1\\}$.\n- For expression data: $e_g \\mid z_g=k \\sim \\mathcal{N}(\\mu_{e,k}, \\sigma_{e,k}^2)$ for $k \\in \\{0,1\\}$.\n\n**3. Numerically Stable Computation using Log-Probabilities**\n\nDirect evaluation of Gaussian probability densities can result in numerical underflow, as these values can be extremely small. All computations should therefore be performed in logarithmic space. The log-probability density function of a Gaussian distribution $\\mathcal{N}(x; \\mu, \\sigma^2)$ is:\n$$\n\\log p(x; \\mu, \\sigma^2) = -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(x-\\mu)^2}{2\\sigma^2}\n$$\nWe define the log-likelihood of the data for gene $g$ under each hypothesis:\n- Log-likelihood for the `regulated` state ($z_g=1$):\n  $$\n  \\ell_1(g) = \\log p(b_g, e_g \\mid z_g=1) = \\log p(b_g \\mid z_g=1) + \\log p(e_g \\mid z_g=1)\n  $$\n- Log-likelihood for the `unregulated` state ($z_g=0$):\n  $$\n  \\ell_0(g) = \\log p(b_g, e_g \\mid z_g=0) = \\log p(b_g \\mid z_g=0) + \\log p(e_g \\mid z_g=0)\n  $$\n\n**4. Derivation of Required Quantities**\n\nWith these principles, we can derive the expressions for the three required outputs for each gene.\n\n**4.1. Bayes Factor ($\\mathrm{BF}_g$)**\n\nThe Bayes factor is the ratio of the likelihoods of the two competing hypotheses. It quantifies the evidence provided by the data in favor of the regulated model ($z_g=1$) over the unregulated model ($z_g=0$).\n$$\n\\mathrm{BF}_g = \\frac{p(b_g, e_g \\mid z_g=1)}{p(b_g, e_g \\mid z_g=0)}\n$$\nIn log space, this becomes a simple subtraction:\n$$\n\\log \\mathrm{BF}_g = \\ell_1(g) - \\ell_0(g)\n$$\nThe problem requires the base-$10$ logarithm, which is obtained by a change of base:\n$$\n\\log_{10} \\mathrm{BF}_g = \\frac{\\log \\mathrm{BF}_g}{\\log 10}\n$$\n\n**4.2. Posterior Probability ($p(z_g=1 \\mid b_g, e_g)$)**\n\nThe posterior probability can be expressed in terms of the Bayes factor and the prior odds, $\\frac{\\pi}{1-\\pi}$. This formulation is numerically superior.\n$$\np(z_g=1 \\mid b_g, e_g) = \\frac{p(b_g, e_g \\mid z_g=1) \\pi}{p(b_g, e_g \\mid z_g=1) \\pi + p(b_g, e_g \\mid z_g=0) (1-\\pi)}\n$$\nDividing the numerator and denominator by $p(b_g, e_g \\mid z_g=0) (1-\\pi)$ gives:\n$$\np(z_g=1 \\mid b_g, e_g) = \\frac{\\frac{p(b_g, e_g \\mid z_g=1)}{p(b_g, e_g \\mid z_g=0)} \\frac{\\pi}{1-\\pi}}{\\frac{p(b_g, e_g \\mid z_g=1)}{p(b_g, e_g \\mid z_g=0)} \\frac{\\pi}{1-\\pi} + 1} = \\frac{\\mathrm{BF}_g \\cdot \\frac{\\pi}{1-\\pi}}{1 + \\mathrm{BF}_g \\cdot \\frac{\\pi}{1-\\pi}}\n$$\nThis expression is a logistic sigmoid function. Let an intermediate variable $\\alpha_g$ be the log-posterior odds:\n$$\n\\alpha_g = \\log\\left(\\mathrm{BF}_g \\cdot \\frac{\\pi}{1-\\pi}\\right) = (\\ell_1(g) - \\ell_0(g)) + (\\log(\\pi) - \\log(1-\\pi)) = \\log \\mathrm{BF}_g + \\mathrm{logit}(\\pi)\n$$\nThen the posterior probability is:\n$$\np(z_g=1 \\mid b_g, e_g) = \\frac{e^{\\alpha_g}}{1+e^{\\alpha_g}} = \\frac{1}{1+e^{-\\alpha_g}} = \\mathrm{sigmoid}(\\alpha_g)\n$$\nThis form is numerically stable and straightforward to implement.\n\n**4.3. Posterior Entropy ($H_g$)**\n\nThe posterior distribution for $z_g$ is a Bernoulli distribution with parameter $p_g = p(z_g=1 \\mid b_g, e_g)$. The Shannon entropy of this distribution, measured in natural units (nats), quantifies the uncertainty remaining after observing the data.\n$$\nH_g = - \\sum_{k \\in \\{0,1\\}} p(z_g=k \\mid b_g, e_g) \\log p(z_g=k \\mid b_g, e_g)\n$$\n$$\nH_g = - \\left[ p_g \\log p_g + (1-p_g) \\log(1-p_g) \\right]\n$$\nSpecial care is taken for the cases where $p_g=0$ or $p_g=1$, where the entropy is $0$, as $\\lim_{x\\to 0} x\\log x = 0$.\n\n**5. Algorithmic Implementation**\n\nThe overall algorithm proceeds as follows for each test case:\n1. Initialize empty lists for `posteriors`, `log10BFs`, `entropies`, and an integer `count` to $0$.\n2. For each gene $g$ with observations $(b_g, e_g)$:\n   a. Calculate the four component log-likelihoods using the Gaussian `logpdf`: $\\log p(b_g \\mid z_g=1)$, $\\log p(b_g \\mid z_g=0)$, $\\log p(e_g \\mid z_g=1)$, $\\log p(e_g \\mid z_g=0)$.\n   b. Sum these to get the total log-likelihoods $\\ell_1(g)$ and $\\ell_0(g)$.\n   c. Compute $\\log \\mathrm{BF}_g = \\ell_1(g) - \\ell_0(g)$ and convert to base-$10$: $\\log_{10} \\mathrm{BF}_g = \\log \\mathrm{BF}_g / \\log(10)$.\n   d. Compute the log-prior odds, $\\mathrm{logit}(\\pi) = \\log(\\pi) - \\log(1-\\pi)$.\n   e. Compute the posterior probability $p_g = \\mathrm{sigmoid}(\\log \\mathrm{BF}_g + \\mathrm{logit}(\\pi))$.\n   f. Compute the posterior entropy $H_g$ from $p_g$.\n   g. Append the rounded values of $p_g$, $\\log_{10} \\mathrm{BF}_g$, and $H_g$ to their respective lists.\n   h. If $p_g \\ge \\tau$, increment `count`.\n3. Assemble the final list for the test case: `[posteriors, count, log10BFs, entropies]`.\n4. Repeat for all test cases and format the final output as a list of lists.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.special import expit\n\ndef solve():\n    \"\"\"\n    Implements a Bayesian integrative model to infer transcription factor-target relationships.\n    \"\"\"\n    test_cases = [\n        {\n            \"params\": {\n                \"pi\": 0.3, \"mu_b1\": 2.0, \"sigma_b1\": 1.0, \"mu_b0\": 0.0, \"sigma_b0\": 1.5,\n                \"mu_e1\": 1.0, \"sigma_e1\": 0.7, \"mu_e0\": 0.0, \"sigma_e0\": 0.7\n            },\n            \"genes\": [(3.0, 1.5), (2.5, -0.2), (-0.5, 1.2), (0.1, 0.0), (1.2, 0.6)],\n            \"threshold\": 0.5\n        },\n        {\n            \"params\": {\n                \"pi\": 0.1, \"mu_b1\": 2.0, \"sigma_b1\": 1.0, \"mu_b0\": 0.0, \"sigma_b0\": 1.5,\n                \"mu_e1\": 1.0, \"sigma_e1\": 0.7, \"mu_e0\": 0.0, \"sigma_e0\": 0.7\n            },\n            \"genes\": [(0.0, 0.0), (4.5, 2.0), (-1.0, -0.8), (2.0, 0.9), (1.0, 0.2)],\n            \"threshold\": 0.8\n        },\n        {\n            \"params\": {\n                \"pi\": 0.5, \"mu_b1\": 0.0, \"sigma_b1\": 2.0, \"mu_b0\": 0.0, \"sigma_b0\": 2.0,\n                \"mu_e1\": 1.2, \"sigma_e1\": 0.5, \"mu_e0\": 0.0, \"sigma_e0\": 1.0\n            },\n            \"genes\": [(3.0, 1.1), (-2.0, 0.9), (0.0, -0.1), (1.0, 2.0)],\n            \"threshold\": 0.5\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        params = case[\"params\"]\n        genes = case[\"genes\"]\n        tau = case[\"threshold\"]\n\n        pi = params[\"pi\"]\n        mu_b1, sigma_b1 = params[\"mu_b1\"], params[\"sigma_b1\"]\n        mu_b0, sigma_b0 = params[\"mu_b0\"], params[\"sigma_b0\"]\n        mu_e1, sigma_e1 = params[\"mu_e1\"], params[\"sigma_e1\"]\n        mu_e0, sigma_e0 = params[\"mu_e0\"], params[\"sigma_e0\"]\n\n        posteriors = []\n        log10BFs = []\n        entropies = []\n        regulated_count = 0\n\n        # Precompute logit of prior\n        # logit(pi) = log(pi / (1-pi)) = log(pi) - log(1-pi)\n        logit_pi = np.log(pi) - np.log(1 - pi)\n\n        for b_g, e_g in genes:\n            # Calculate log-likelihoods for each modality and state\n            log_p_b_1 = norm.logpdf(b_g, loc=mu_b1, scale=sigma_b1)\n            log_p_b_0 = norm.logpdf(b_g, loc=mu_b0, scale=sigma_b0)\n            log_p_e_1 = norm.logpdf(e_g, loc=mu_e1, scale=sigma_e1)\n            log_p_e_0 = norm.logpdf(e_g, loc=mu_e0, scale=sigma_e0)\n\n            # Sum log-likelihoods for each class (due to conditional independence)\n            ell_1 = log_p_b_1 + log_p_e_1\n            ell_0 = log_p_b_0 + log_p_e_0\n\n            # 1. Bayes Factor\n            # log BF (natural log) = ell_1 - ell_0\n            log_bf = ell_1 - ell_0\n            log10_bf = log_bf / np.log(10)\n            log10BFs.append(round(log10_bf, 3))\n\n            # 2. Posterior probability\n            # p = sigmoid(log_BF + logit(pi))\n            log_posterior_odds = log_bf + logit_pi\n            posterior_prob = expit(log_posterior_odds)\n            posteriors.append(round(posterior_prob, 3))\n\n            # 3. Posterior entropy\n            # H = -[p*log(p) + (1-p)*log(1-p)]\n            p = posterior_prob\n            if p == 0 or p == 1:\n                entropy = 0.0\n            else:\n                entropy = -(p * np.log(p) + (1 - p) * np.log(1 - p))\n            entropies.append(round(entropy, 3))\n\n            # 4. Apply decision rule\n            if posterior_prob >= tau:\n                regulated_count += 1\n\n        case_result = [\n            posteriors,\n            regulated_count,\n            log10BFs,\n            entropies\n        ]\n        all_results.append(case_result)\n\n    # Format the output string precisely as required, with no spaces in lists.\n    result_strings = []\n    for res in all_results:\n        # res[0] is posteriors (list)\n        # res[1] is count (int)\n        # res[2] is log10BFs (list)\n        # res[3] is entropies (list)\n        posteriors_str = f\"[{','.join(map(str, res[0]))}]\"\n        log10bfs_str = f\"[{','.join(map(str, res[2]))}]\"\n        entropies_str = f\"[{','.join(map(str, res[3]))}]\"\n        \n        result_strings.append(f\"[{posteriors_str},{res[1]},{log10bfs_str},{entropies_str}]\")\n\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "4395615"}]}