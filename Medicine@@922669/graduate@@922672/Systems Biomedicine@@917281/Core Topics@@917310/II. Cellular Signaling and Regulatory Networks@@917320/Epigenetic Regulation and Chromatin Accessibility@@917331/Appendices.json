{"hands_on_practices": [{"introduction": "This practice delves into the dynamic nature of chromatin accessibility at the single-molecule level. By modeling the binding of a transcription factor to a site that stochastically switches between open and closed states, you will apply principles of chemical kinetics to quantify how chromatin remodeling impacts gene regulation. This exercise [@problem_id:4338614] provides a quantitative foundation for understanding how the cellular machinery controls access to the genetic code.", "problem": "A single Transcription Factor (TF) binds specifically to a genomic site with bimolecular association rate constant $k_{\\text{on}}$ and unimolecular dissociation rate constant $k_{\\text{off}}$. The TF concentration is $C$. When the site is on naked DNA, it is continuously accessible. When the site is on nucleosomal DNA, it stochastically switches between an inaccessible closed state and an accessible open state due to Chromatin Remodeler (CR) activity, with opening rate $k_{r}$ (remodeling) and closing rate $k_{c}$ (re-nucleation). Assume that TF binding is possible only in the open state and that re-nucleation does not occur while the TF is bound at the site.\n\nStarting from the core definitions of chemical kinetics and steady-state probability flow in continuous-time Markov chains, derive the steady-state expected rate (events per second) of TF binding initiation to the site in each of the following contexts:\n1. Naked DNA (always accessible).\n2. Nucleosomal DNA with stochastic opening and closing.\n\nThen, using your derived expressions, compute how much chromatin remodeling increases the binding initiation frequency for the nucleosomal site by comparing a baseline “low remodeling” condition to a “high remodeling” condition. Use the parameter values:\n- $k_{\\text{on}} = 1.0 \\times 10^{6}\\ \\text{M}^{-1}\\ \\text{s}^{-1}$,\n- $k_{\\text{off}} = 1.0 \\times 10^{-1}\\ \\text{s}^{-1}$,\n- $C = 1.0 \\times 10^{-8}\\ \\text{M}$,\n- $k_{c} = 2.0 \\times 10^{-1}\\ \\text{s}^{-1}$,\n- baseline opening $k_{r}^{(0)} = 1.0 \\times 10^{-3}\\ \\text{s}^{-1}$,\n- remodeled opening $k_{r}^{(1)} = 5.0 \\times 10^{-2}\\ \\text{s}^{-1}$.\n\nDefine the fold-increase due to remodeling as the ratio of the nucleosomal binding initiation rate under $k_{r}^{(1)}$ to that under $k_{r}^{(0)}$. Round your final fold-increase to four significant figures. The final answer must be a single number without units. If you perform any intermediate numerical calculations of rates, express them in $\\text{s}^{-1}$.", "solution": "The problem asks for the derivation of the steady-state TF binding initiation rate for two scenarios: a continuously accessible site on naked DNA and a stochastically accessible site on nucleosomal DNA. We will model both scenarios as continuous-time Markov chains and solve for the steady-state probabilities to find the binding flux.\n\nFirst, let us define the effective first-order rate constant for TF binding as $k'_{\\text{on}} = k_{\\text{on}}C$, where $k_{\\text{on}}$ is the bimolecular association rate constant and $C$ is the TF concentration.\n\n**1. Naked DNA (Always Accessible)**\n\nFor naked DNA, the binding site is always accessible. The system can be described by two states:\n- State U: The site is Unbound.\n- State B: The site is Bound by the TF.\n\nThe kinetic scheme is a simple reversible reaction:\n$$\n\\text{U} \\underset{k_{\\text{off}}}{\\stackrel{k'_{\\text{on}}}{\\rightleftharpoons}} \\text{B}\n$$\nwhere $k'_{\\text{on}} = k_{\\text{on}}C$.\n\nAt steady state, the rate of flow from U to B must equal the rate of flow from B to U. Let $P(\\text{U})$ and $P(\\text{B})$ be the steady-state probabilities of being in the unbound and bound states, respectively.\nThe balance equation is:\n$$\nk'_{\\text{on}} P(\\text{U}) = k_{\\text{off}} P(\\text{B})\n$$\nAdditionally, the probabilities must sum to unity:\n$$\nP(\\text{U}) + P(\\text{B}) = 1\n$$\nFrom the balance equation, we express $P(\\text{B})$ in terms of $P(\\text{U})$:\n$$\nP(\\text{B}) = \\frac{k'_{\\text{on}}}{k_{\\text{off}}} P(\\text{U})\n$$\nSubstituting this into the normalization condition:\n$$\nP(\\text{U}) + \\frac{k'_{\\text{on}}}{k_{\\text{off}}} P(\\text{U}) = 1 \\implies P(\\text{U}) \\left(1 + \\frac{k'_{\\text{on}}}{k_{\\text{off}}}\\right) = 1\n$$\nSolving for $P(\\text{U})$:\n$$\nP(\\text{U}) = \\frac{1}{1 + \\frac{k'_{\\text{on}}}{k_{\\text{off}}}} = \\frac{k_{\\text{off}}}{k_{\\text{off}} + k'_{\\text{on}}}\n$$\nThe rate of binding initiation, $R_{\\text{naked}}$, is the unidirectional flux from state U to state B, which is given by the product of the rate constant for this transition and the probability of being in the initial state U.\n$$\nR_{\\text{naked}} = k'_{\\text{on}} P(\\text{U}) = k_{\\text{on}}C \\cdot \\frac{k_{\\text{off}}}{k_{\\text{off}} + k_{\\text{on}}C}\n$$\n\n**2. Nucleosomal DNA (Stochastic Accessibility)**\n\nFor nucleosomal DNA, the binding site accessibility is regulated. The system is described by three states:\n- State C: The site is on a Closed, inaccessible nucleosome (and is unbound).\n- State O: The site is on an Open, accessible nucleosome (and is unbound).\n- State B: The site is on an open nucleosome and is Bound by the TF.\n\nThe kinetic scheme, based on the problem description, is:\n$$\n\\text{C} \\underset{k_c}{\\stackrel{k_r}{\\rightleftharpoons}} \\text{O} \\underset{k_{\\text{off}}}{\\stackrel{k'_{\\text{on}}}{\\rightleftharpoons}} \\text{B}\n$$\nwhere $k_r$ is the chromatin opening rate, $k_c$ is the closing rate, and $k'_{\\text{on}} = k_{\\text{on}}C$. The key constraints are that TF can only bind to the open state (O), and the nucleosome cannot close when the TF is bound (no transition from B to C).\n\nLet $P(\\text{C})$, $P(\\text{O})$, and $P(\\text{B})$ be the steady-state probabilities. The detailed balance equations for the flows between states are:\n1.  Flows involving state C: $k_r P(\\text{C}) = k_c P(\\text{O})$\n2.  Flows involving state B: $k'_{\\text{on}} P(\\text{O}) = k_{\\text{off}} P(\\text{B})$\n3.  The normalization condition: $P(\\text{C}) + P(\\text{O}) + P(\\text{B}) = 1$\n\nWe can express $P(\\text{C})$ and $P(\\text{B})$ in terms of $P(\\text{O})$:\nFrom equation (1):\n$$\nP(\\text{C}) = \\frac{k_c}{k_r} P(\\text{O})\n$$\nFrom equation (2):\n$$\nP(\\text{B}) = \\frac{k'_{\\text{on}}}{k_{\\text{off}}} P(\\text{O})\n$$\nSubstitute these into the normalization equation (3):\n$$\n\\frac{k_c}{k_r} P(\\text{O}) + P(\\text{O}) + \\frac{k'_{\\text{on}}}{k_{\\text{off}}} P(\\text{O}) = 1\n$$\nFactor out $P(\\text{O})$:\n$$\nP(\\text{O}) \\left( \\frac{k_c}{k_r} + 1 + \\frac{k'_{\\text{on}}}{k_{\\text{off}}} \\right) = 1\n$$\nSolving for $P(\\text{O})$:\n$$\nP(\\text{O}) = \\frac{1}{1 + \\frac{k'_{\\text{on}}}{k_{\\text{off}}} + \\frac{k_c}{k_r}}\n$$\nThe rate of binding initiation, $R_{\\text{nuc}}$, is the unidirectional flux from the open, unbound state (O) to the bound state (B). This is the only pathway for binding initiation.\n$$\nR_{\\text{nuc}} = k'_{\\text{on}} P(\\text{O}) = \\frac{k'_{\\text{on}}}{1 + \\frac{k'_{\\text{on}}}{k_{\\text{off}}} + \\frac{k_c}{k_r}} = \\frac{k_{\\text{on}}C}{1 + \\frac{k_{\\text{on}}C}{k_{\\text{off}}} + \\frac{k_c}{k_r}}\n$$\n\n**3. Fold-Increase Calculation**\n\nWe are asked to compute the fold-increase in binding initiation frequency due to an increase in the chromatin remodeling rate from a baseline $k_{r}^{(0)}$ to a higher rate $k_{r}^{(1)}$. The fold-increase is defined as the ratio of the corresponding rates, $R_{\\text{nuc}}^{(1)} / R_{\\text{nuc}}^{(0)}$.\n\nLet $R_{\\text{nuc}}^{(0)}$ be the rate with $k_r = k_{r}^{(0)}$ and $R_{\\text{nuc}}^{(1)}$ be the rate with $k_r = k_{r}^{(1)}$.\n$$\nR_{\\text{nuc}}^{(0)} = \\frac{k_{\\text{on}}C}{1 + \\frac{k_{\\text{on}}C}{k_{\\text{off}}} + \\frac{k_c}{k_{r}^{(0)}}}\n$$\n$$\nR_{\\text{nuc}}^{(1)} = \\frac{k_{\\text{on}}C}{1 + \\frac{k_{\\text{on}}C}{k_{\\text{off}}} + \\frac{k_c}{k_{r}^{(1)}}}\n$$\nThe fold-increase is their ratio:\n$$\n\\text{Fold-Increase} = \\frac{R_{\\text{nuc}}^{(1)}}{R_{\\text{nuc}}^{(0)}} = \\frac{\\frac{k_{\\text{on}}C}{1 + \\frac{k_{\\text{on}}C}{k_{\\text{off}}} + \\frac{k_c}{k_{r}^{(1)}}}}{\\frac{k_{\\text{on}}C}{1 + \\frac{k_{\\text{on}}C}{k_{\\text{off}}} + \\frac{k_c}{k_{r}^{(0)}}}} = \\frac{1 + \\frac{k_{\\text{on}}C}{k_{\\text{off}}} + \\frac{k_c}{k_{r}^{(0)}}}{1 + \\frac{k_{\\text{on}}C}{k_{\\text{off}}} + \\frac{k_c}{k_{r}^{(1)}}}\n$$\nNow, we substitute the given numerical values:\n- $k_{\\text{on}} = 1.0 \\times 10^{6}\\ \\text{M}^{-1}\\ \\text{s}^{-1}$\n- $k_{\\text{off}} = 1.0 \\times 10^{-1}\\ \\text{s}^{-1}$\n- $C = 1.0 \\times 10^{-8}\\ \\text{M}$\n- $k_{c} = 2.0 \\times 10^{-1}\\ \\text{s}^{-1}$\n- $k_{r}^{(0)} = 1.0 \\times 10^{-3}\\ \\text{s}^{-1}$\n- $k_{r}^{(1)} = 5.0 \\times 10^{-2}\\ \\text{s}^{-1}$\n\nFirst, we calculate the dimensionless ratios:\n$$\n\\frac{k_{\\text{on}}C}{k_{\\text{off}}} = \\frac{(1.0 \\times 10^{6}\\ \\text{M}^{-1}\\ \\text{s}^{-1})(1.0 \\times 10^{-8}\\ \\text{M})}{1.0 \\times 10^{-1}\\ \\text{s}^{-1}} = \\frac{1.0 \\times 10^{-2}\\ \\text{s}^{-1}}{1.0 \\times 10^{-1}\\ \\text{s}^{-1}} = 0.1\n$$\n$$\n\\frac{k_c}{k_{r}^{(0)}} = \\frac{2.0 \\times 10^{-1}\\ \\text{s}^{-1}}{1.0 \\times 10^{-3}\\ \\text{s}^{-1}} = 200\n$$\n$$\n\\frac{k_c}{k_{r}^{(1)}} = \\frac{2.0 \\times 10^{-1}\\ \\text{s}^{-1}}{5.0 \\times 10^{-2}\\ \\text{s}^{-1}} = 4\n$$\nNow, we use these values in the fold-increase expression:\n$$\n\\text{Fold-Increase} = \\frac{1 + 0.1 + 200}{1 + 0.1 + 4} = \\frac{201.1}{5.1}\n$$\nPerforming the final division:\n$$\n\\text{Fold-Increase} \\approx 39.4313725...\n$$\nAs intermediate results, the binding rates are:\n- $R_{\\text{nuc}}^{(0)} = \\frac{1.0 \\times 10^{-2}}{201.1}\\ \\text{s}^{-1} \\approx 4.973 \\times 10^{-5}\\ \\text{s}^{-1}$\n- $R_{\\text{nuc}}^{(1)} = \\frac{1.0 \\times 10^{-2}}{5.1}\\ \\text{s}^{-1} \\approx 1.961 \\times 10^{-3}\\ \\text{s}^{-1}$\n\nRounding the final fold-increase to four significant figures gives $39.43$.", "answer": "$$\n\\boxed{39.43}\n$$", "id": "4338614"}, {"introduction": "From modeling biological processes, we now turn to modeling the process of measurement itself. Accurate quantification is the bedrock of systems biology, yet experimental techniques have inherent biases. This exercise [@problem_id:4338644] explores the widely used method of bisulfite sequencing, where you will use first-order reaction kinetics to derive a formula that corrects for incomplete chemical conversion, a major source of error in DNA methylation studies.", "problem": "Bisulfite sequencing (BS-seq) infers cytosine methylation by chemically converting unmethylated cytosines to uracil, which are read as thymine after polymerase chain reaction and sequencing, while methylated cytosines are more resistant to conversion and are read as cytosine. Consider a single genomic cytosine in a large mixture of cells with a true methylation fraction $m \\in [0,1]$. Assume the following foundational and well-tested biophysical and statistical principles: (i) sodium bisulfite conversion of cytosines proceeds as a first-order reaction with respect to time, so that for a cytosine species with deamination rate constant $k$ under treatment time $t$, the probability of conversion by time $t$ is $1-\\exp(-k t)$; (ii) methylated and unmethylated cytosines have distinct effective rate constants $k_{m}$ and $k_{u}$, respectively, with $k_{m} \\ll k_{u}$; (iii) molecules are independent and identically distributed draws from the mixture, so that population-level readouts are expectations over a Bernoulli mixture with mixing weight $m$.\n\nDefine the observed methylation fraction $\\hat{m}$ at this locus as the fraction of reads reporting cytosine after bisulfite treatment and sequencing, under negligible sequencing error. Starting from the principles above and without invoking any pre-derived BS-seq correction formulas, do the following:\n\n- Derive the expected conversion probability for unmethylated and methylated cytosines as functions of $k_{u}$, $k_{m}$, and $t$.\n- Using a probabilistic mixture model, derive the expectation of the observed cytosine-calling fraction $\\hat{m}$ as a function of the true methylation fraction $m$, the unmethylated conversion probability, and the methylated non-conversion probability.\n- Algebraically solve this relationship to obtain a closed-form expression for $m$ in terms of the observable $\\hat{m}$ and the kinetic parameters $k_{u}$, $k_{m}$, and $t$.\n\nProvide your final answer as a single closed-form analytic expression for $m$ as a function of $\\hat{m}$, $k_{u}$, $k_{m}$, and $t$. No numerical evaluation is required. If any constraints on parameters are necessary for identifiability, state them in your derivation. The final answer must be a single expression with no units.", "solution": "We model sodium bisulfite conversion as a first-order reaction with respect to time, which is a standard kinetic model for unimolecular transformations. For a cytosine species with rate constant $k$ under treatment duration $t$, the probability that conversion has occurred by time $t$ is given by $1-\\exp(-k t)$, and the probability that no conversion has occurred by time $t$ is $\\exp(-k t)$. We distinguish two species: unmethylated cytosine, with rate constant $k_{u}$, and methylated cytosine, with rate constant $k_{m}$, typically satisfying $k_{m} \\ll k_{u}$ due to the protective effect of the methyl group.\n\nStep $1$: Derive conversion probabilities for each species.\n- For an unmethylated cytosine, the probability of conversion by time $t$ is\n$$\n\\alpha \\equiv 1 - \\exp(-k_{u} t),\n$$\nand the probability of non-conversion is\n$$\n1 - \\alpha = \\exp(-k_{u} t).\n$$\n- For a methylated cytosine, the probability of conversion by time $t$ is\n$$\n\\gamma \\equiv 1 - \\exp(-k_{m} t),\n$$\nand the probability of non-conversion (resistance) is\n$$\n\\beta \\equiv 1 - \\gamma = \\exp(-k_{m} t).\n$$\n\nStep $2$: Express the expected observed cytosine-calling fraction in terms of $m$, $\\alpha$, and $\\beta$.\nUnder bisulfite sequencing readout, a base is called as cytosine if it is not converted during treatment, and as thymine if it is converted. Ignoring sequencing error, the probability that a read reports cytosine is the mixture of non-conversion probabilities from methylated and unmethylated molecules, weighted by their prevalence:\n$$\n\\mathbb{E}[\\hat{m}] = m \\cdot \\Pr(\\text{C call} \\mid \\text{methylated}) + (1 - m) \\cdot \\Pr(\\text{C call} \\mid \\text{unmethylated}).\n$$\nSubstituting the non-conversion probabilities yields\n$$\n\\mathbb{E}[\\hat{m}] = m \\cdot \\beta + (1 - m) \\cdot (1 - \\alpha).\n$$\nUsing the kinetic definitions above, this becomes\n$$\n\\mathbb{E}[\\hat{m}] = m \\cdot \\exp(-k_{m} t) + (1 - m) \\cdot \\exp(-k_{u} t).\n$$\n\nStep $3$: Solve for $m$ in terms of $\\hat{m}$, $k_{u}$, $k_{m}$, and $t$.\nAssuming sufficient sequencing depth so that $\\hat{m}$ concentrates around its expectation, we set $\\hat{m} \\approx \\mathbb{E}[\\hat{m}]$ for the purpose of deriving the correction. Then\n$$\n\\hat{m} = m \\cdot \\exp(-k_{m} t) + (1 - m) \\cdot \\exp(-k_{u} t).\n$$\nRearranging,\n$$\n\\hat{m} = m \\cdot \\exp(-k_{m} t) + \\exp(-k_{u} t) - m \\cdot \\exp(-k_{u} t)\n= \\exp(-k_{u} t) + m \\left[\\exp(-k_{m} t) - \\exp(-k_{u} t)\\right].\n$$\nTherefore,\n$$\nm = \\frac{\\hat{m} - \\exp(-k_{u} t)}{\\exp(-k_{m} t) - \\exp(-k_{u} t)}.\n$$\n\nIdentifiability and constraints: The denominator $\\exp(-k_{m} t) - \\exp(-k_{u} t)$ must be nonzero. Under the realistic condition $k_{m} \\neq k_{u}$ and $t > 0$, we have $\\exp(-k_{m} t) \\neq \\exp(-k_{u} t)$. In typical practice $k_{m} < k_{u}$, so $\\exp(-k_{m} t) > \\exp(-k_{u} t)$, ensuring a positive denominator. Additionally, $k_{u} \\geq 0$, $k_{m} \\geq 0$, and $t \\geq 0$.\n\nThis expression explicitly corrects the observed cytosine fraction $\\hat{m}$ for incomplete conversion of unmethylated cytosines and potential over-conversion of methylated cytosines under first-order kinetics, thereby quantifying and removing the bias introduced by incomplete conversion.", "answer": "$$\\boxed{\\frac{\\hat{m}-\\exp(-k_{u} t)}{\\exp(-k_{m} t)-\\exp(-k_{u} t)}}$$", "id": "4338644"}, {"introduction": "This final practice moves from analytical modeling to computational data analysis, a cornerstone of modern systems biomedicine. You will step into the role of a bioinformatician analyzing a multi-omics dataset, integrating hypothetical protein occupancy (CUT&RUN) and chromatin accessibility (ATAC-seq) profiles. This exercise [@problem_id:4338626] will guide you through the essential steps of data normalization and correlation analysis to test a hypothesis about the function of a long non-coding RNA in epigenetic regulation.", "problem": "You are given paired profiles representing Cleavage Under Targets and Release Using Nuclease (CUT&RUN) for the Polycomb Repressive Complex 2 (PRC2) and Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) based chromatin accessibility, each measured in a control and a long non-coding RNA (lncRNA) depletion condition across a shared set of genomic windows with known lengths. From first principles of sequencing-based occupancy profiling in systems biomedicine, assume that the expected occupancy or accessibility signal in a genomic window is proportional to the number of aligned reads mapping to that window, inversely proportional to the library size (total aligned reads), and inversely proportional to the genomic span of that window. Under this model, define the normalized per-base signal for PRC2 in condition $X \\in \\{C, K\\}$ as\n$$\ns_{R}^{(X)}(i) \\equiv \\frac{x_{i}^{(X)}}{L_{R}^{(X)} \\cdot \\ell_i},\n$$\nand the normalized per-base signal for accessibility as\n$$\ns_{A}^{(X)}(i) \\equiv \\frac{a_{i}^{(X)}}{L_{A}^{(X)} \\cdot \\ell_i},\n$$\nwhere $x_{i}^{(X)}$ and $a_{i}^{(X)}$ are raw read counts for PRC2 and accessibility respectively, $L_{R}^{(X)}$ and $L_{A}^{(X)}$ are the corresponding library sizes (total aligned reads), and $\\ell_i$ is the length (in base pairs) of window $i$. Use a small pseudocount $\\varepsilon = 10^{-12}$ to avoid division by zero or taking logarithms of zero.\n\nYour task is to implement a program that, for each provided test case, computes:\n- the global change in PRC2 occupancy under lncRNA depletion,\n$$\n\\Delta_R \\equiv \\log_2\\left(\\frac{\\sum_{i} s_{R}^{(K)}(i) + \\varepsilon}{\\sum_{i} s_{R}^{(C)}(i) + \\varepsilon}\\right),\n$$\n- the global change in chromatin accessibility,\n$$\n\\Delta_A \\equiv \\log_2\\left(\\frac{\\sum_{i} s_{A}^{(K)}(i) + \\varepsilon}{\\sum_{i} s_{A}^{(C)}(i) + \\varepsilon}\\right),\n$$\n- and the Pearson correlation coefficient between per-window log fold changes of PRC2 and accessibility,\n$$\nd_R(i) \\equiv \\log_2\\left(\\frac{s_{R}^{(K)}(i) + \\varepsilon}{s_{R}^{(C)}(i) + \\varepsilon}\\right), \\quad\nd_A(i) \\equiv \\log_2\\left(\\frac{s_{A}^{(K)}(i) + \\varepsilon}{s_{A}^{(C)}(i) + \\varepsilon}\\right),\n$$\n$$\nr \\equiv \\frac{\\sum_i \\left(d_R(i) - \\overline{d_R}\\right)\\left(d_A(i) - \\overline{d_A}\\right)}{\\sqrt{\\sum_i \\left(d_R(i) - \\overline{d_R}\\right)^2} \\cdot \\sqrt{\\sum_i \\left(d_A(i) - \\overline{d_A}\\right)^2}},\n$$\nwith the convention that if the variance of $d_R$ or $d_A$ is zero (making $r$ undefined), then $r$ is defined to be $0$.\n\nScientific realism constraints: Assume the windows are non-overlapping and cover regions relevant to Polycomb targeting, that the observed counts arise from independent sampling proportional to underlying occupancy or accessibility, and that library size and window length are the dominant normalization factors.\n\nImplement your program to evaluate the following test suite. Each test case specifies the window lengths $\\{\\ell_i\\}$, PRC2 counts in control $\\{x_i^{(C)}\\}$ and knockdown $\\{x_i^{(K)}\\}$ with library sizes $L_R^{(C)}$ and $L_R^{(K)}$, and ATAC counts in control $\\{a_i^{(C)}\\}$ and knockdown $\\{a_i^{(K)}\\}$ with library sizes $L_A^{(C)}$ and $L_A^{(K)}$:\n\n- Test case $1$ (typical shift: decreased PRC2, increased accessibility):\n  - Window lengths $\\{\\ell_i\\} = \\{1000, 800, 1200, 600, 1000\\}$\n  - PRC2 control counts $\\{x_i^{(C)}\\} = \\{500, 400, 600, 200, 300\\}$, PRC2 knockdown counts $\\{x_i^{(K)}\\} = \\{300, 250, 350, 120, 150\\}$\n  - PRC2 library sizes $L_R^{(C)} = 20000000$, $L_R^{(K)} = 22000000$\n  - Accessibility control counts $\\{a_i^{(C)}\\} = \\{200, 220, 180, 150, 190\\}$, Accessibility knockdown counts $\\{a_i^{(K)}\\} = \\{260, 300, 240, 200, 230\\}$\n  - Accessibility library sizes $L_A^{(C)} = 25000000$, $L_A^{(K)} = 23000000$\n\n- Test case $2$ (no change; boundary condition):\n  - Window lengths $\\{\\ell_i\\} = \\{1000, 1000, 1000, 1000\\}$\n  - PRC2 control counts $\\{x_i^{(C)}\\} = \\{100, 100, 100, 100\\}$, PRC2 knockdown counts $\\{x_i^{(K)}\\} = \\{100, 100, 100, 100\\}$\n  - PRC2 library sizes $L_R^{(C)} = 10000000$, $L_R^{(K)} = 10000000$\n  - Accessibility control counts $\\{a_i^{(C)}\\} = \\{80, 120, 90, 110\\}$, Accessibility knockdown counts $\\{a_i^{(K)}\\} = \\{80, 120, 90, 110\\}$\n  - Accessibility library sizes $L_A^{(C)} = 10000000$, $L_A^{(K)} = 10000000$\n\n- Test case $3$ (low counts with zeros; tests pseudocount handling):\n  - Window lengths $\\{\\ell_i\\} = \\{500, 1500, 800, 1200\\}$\n  - PRC2 control counts $\\{x_i^{(C)}\\} = \\{0, 10, 0, 5\\}$, PRC2 knockdown counts $\\{x_i^{(K)}\\} = \\{0, 5, 0, 2\\}$\n  - PRC2 library sizes $L_R^{(C)} = 5000000$, $L_R^{(K)} = 6000000$\n  - Accessibility control counts $\\{a_i^{(C)}\\} = \\{50, 0, 40, 0\\}$, Accessibility knockdown counts $\\{a_i^{(K)}\\} = \\{25, 0, 80, 0\\}$\n  - Accessibility library sizes $L_A^{(C)} = 8000000$, $L_A^{(K)} = 7000000$\n\n- Test case $4$ (increased PRC2 with decreased accessibility; zero-variance correlation edge):\n  - Window lengths $\\{\\ell_i\\} = \\{500, 500, 500\\}$\n  - PRC2 control counts $\\{x_i^{(C)}\\} = \\{120, 80, 60\\}$, PRC2 knockdown counts $\\{x_i^{(K)}\\} = \\{240, 160, 120\\}$\n  - PRC2 library sizes $L_R^{(C)} = 15000000$, $L_R^{(K)} = 15000000$\n  - Accessibility control counts $\\{a_i^{(C)}\\} = \\{300, 200, 100\\}$, Accessibility knockdown counts $\\{a_i^{(K)}\\} = \\{150, 100, 50\\}$\n  - Accessibility library sizes $L_A^{(C)} = 12000000$, $L_A^{(K)} = 10000000$\n\nFor each test case, your program must return a list of three real numbers $[\\Delta_R, \\Delta_A, r]$. Aggregate the outputs across all test cases into a single line as a list of lists. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result1,result2,result3]$ where each $resultj$ is itself a list $[\\Delta_R, \\Delta_A, r]$).", "solution": "The problem requires the implementation of a computational analysis pipeline to quantify and compare changes in Polycomb Repressive Complex 2 (PRC2) occupancy and chromatin accessibility from next-generation sequencing data. The analysis is based on a defined biophysical and statistical model. The solution is structured into three principal components: data normalization, quantification of signal changes, and correlation analysis.\n\n**1. Normalization of Sequencing Data**\n\nThe fundamental principle underlying the analysis of sequencing-based assays like CUT&RUN and ATAC-seq is that the number of reads mapping to a specific genomic region is proportional to the biological signal of interest (e.g., protein occupancy or DNA accessibility) in that region. However, raw read counts, denoted as $x_{i}^{(X)}$ for PRC2 and $a_{i}^{(X)}$ for accessibility in a given genomic window $i$ and experimental condition $X$, are not directly comparable. They are confounded by at least two major technical factors:\n- **Sequencing Depth (Library Size):** An experiment with a larger total number of aligned reads (library size, $L$) will systematically produce higher counts across all windows, irrespective of biological changes.\n- **Genomic Window Length:** A longer genomic window ($\\ell_i$) has a greater chance of accumulating reads by chance, even if the per-base-pair signal density is uniform.\n\nTo account for these factors and derive a comparable measure of signal density, the problem defines a normalized per-base signal. For PRC2 in condition $X \\in \\{C, K\\}$ (Control, Knockdown), the normalized signal for window $i$ is:\n$$\ns_{R}^{(X)}(i) \\equiv \\frac{x_{i}^{(X)}}{L_{R}^{(X)} \\cdot \\ell_i}\n$$\nSimilarly, for accessibility, the normalized signal is:\n$$\ns_{A}^{(X)}(i) \\equiv \\frac{a_{i}^{(X)}}{L_{A}^{(X)} \\cdot \\ell_i}\n$$\nThese formulas effectively compute a signal density, representing the fraction of the total library reads that map to a given window, normalized by the window's length in base pairs. This normalization is a simplified but standard and principled approach, analogous to metrics like Reads Per Kilobase per Million mapped reads (RPKM).\n\n**2. Quantification of Global and Local Signal Changes**\n\nWith normalized signals, we can quantify the effect of the lncRNA depletion. The problem specifies two levels of analysis: global and local.\n\n- **Global Change:** To assess the overall shift in signal across the entire set of analyzed windows, the global change metrics $\\Delta_R$ and $\\Delta_A$ are defined. These are calculated by first summing the normalized per-base signals across all windows for each condition and then computing the log-base-$2$ ratio of the sums.\n$$\n\\Delta_R \\equiv \\log_2\\left(\\frac{\\sum_{i} s_{R}^{(K)}(i) + \\varepsilon}{\\sum_{i} s_{R}^{(C)}(i) + \\varepsilon}\\right), \\quad \\Delta_A \\equiv \\log_2\\left(\\frac{\\sum_{i} s_{A}^{(K)}(i) + \\varepsilon}{\\sum_{i} s_{A}^{(C)}(i) + \\varepsilon}\\right)\n$$\nA value of $\\Delta_R = -1$, for instance, indicates a $2$-fold decrease in the total PRC2 signal across the interrogated loci upon knockdown. The small pseudocount, $\\varepsilon = 10^{-12}$, is added to ensure numerical stability, preventing division by zero or taking the logarithm of zero if a condition has zero total signal.\n\n- **Local Change:** To understand how individual windows behave, per-window log-fold changes are computed. These are defined as:\n$$\nd_R(i) \\equiv \\log_2\\left(\\frac{s_{R}^{(K)}(i) + \\varepsilon}{s_{R}^{(C)}(i) + \\varepsilon}\\right), \\quad d_A(i) \\equiv \\log_2\\left(\\frac{s_{A}^{(K)}(i) + \\varepsilon}{s_{A}^{(C)}(i) + \\varepsilon}\\right)\n$$\nThese values, $d_R(i)$ and $d_A(i)$, form vectors of local responses to the perturbation, allowing for a more granular view of the biological effects.\n\n**3. Correlation of Local Changes**\n\nThe final task is to determine if there is a relationship between the local changes in PRC2 occupancy and chromatin accessibility. The canonical antagonism between PRC2 (a repressive complex) and open chromatin suggests that where PRC2 is lost, accessibility should increase, and vice versa. This inverse relationship can be quantified using the Pearson correlation coefficient, $r$, between the vectors of local log-fold changes, $d_R$ and $d_A$.\nThe formula for the Pearson correlation coefficient is:\n$$\nr \\equiv \\frac{\\operatorname{cov}(d_R, d_A)}{\\sigma_{d_R} \\sigma_{d_A}} = \\frac{\\sum_i \\left(d_R(i) - \\overline{d_R}\\right)\\left(d_A(i) - \\overline{d_A}\\right)}{\\sqrt{\\sum_i \\left(d_R(i) - \\overline{d_R}\\right)^2} \\cdot \\sqrt{\\sum_i \\left(d_A(i) - \\overline{d_A}\\right)^2}}\n$$\nwhere $\\overline{d_R}$ and $\\overline{d_A}$ are the means of the respective log-fold change vectors. The coefficient $r$ ranges from $-1$ (perfect anti-correlation) to $+1$ (perfect positive correlation), with $0$ indicating no linear correlation. The problem correctly specifies a convention to handle the case where the correlation is mathematically undefined because one of the signals does not change across windows (i.e., its variance, $\\sigma^2$, is zero). In such a case, $r$ is defined to be $0$.\n\n**Computational Algorithm**\n\nThe implementation will proceed as follows for each test case:\n1.  Represent all input data—window lengths, read counts, and library sizes— as numerical arrays and scalar variables.\n2.  Compute the four vectors of normalized signals: $s_{R}^{(C)}$, $s_{R}^{(K)}$, $s_{A}^{(C)}$, and $s_{A}^{(K)}$, using the element-wise formula defined above.\n3.  Calculate the global change metrics, $\\Delta_R$ and $\\Delta_A$, by summing the appropriate signal vectors, adding the pseudocount $\\varepsilon$, and then taking the log-base-$2$ of the ratio.\n4.  Calculate the two vectors of per-window log-fold changes, $d_R$ and $d_A$.\n5.  Compute the variance of the $d_R$ and $d_A$ vectors. If either variance is zero, set the Pearson correlation $r$ to $0$. Otherwise, compute $r$ using the standard formula.\n6.  Collect the three resulting values, $[\\Delta_R, \\Delta_A, r]$, for the test case.\n7.  Aggregate the results from all test cases into a final list of lists for output.\nThis procedure systematically translates the provided biostatistical model into a concrete set of computations.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes global signal changes and local correlation for paired\n    genomic sequencing data based on a provided normalization model.\n    \"\"\"\n    \n    # Pseudocount to avoid numerical instability\n    epsilon = 1e-12\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"l\": [1000, 800, 1200, 600, 1000],\n            \"x_c\": [500, 400, 600, 200, 300],\n            \"x_k\": [300, 250, 350, 120, 150],\n            \"L_R_C\": 20000000,\n            \"L_R_K\": 22000000,\n            \"a_c\": [200, 220, 180, 150, 190],\n            \"a_k\": [260, 300, 240, 200, 230],\n            \"L_A_C\": 25000000,\n            \"L_A_K\": 23000000,\n        },\n        {\n            \"l\": [1000, 1000, 1000, 1000],\n            \"x_c\": [100, 100, 100, 100],\n            \"x_k\": [100, 100, 100, 100],\n            \"L_R_C\": 10000000,\n            \"L_R_K\": 10000000,\n            \"a_c\": [80, 120, 90, 110],\n            \"a_k\": [80, 120, 90, 110],\n            \"L_A_C\": 10000000,\n            \"L_A_K\": 10000000,\n        },\n        {\n            \"l\": [500, 1500, 800, 1200],\n            \"x_c\": [0, 10, 0, 5],\n            \"x_k\": [0, 5, 0, 2],\n            \"L_R_C\": 5000000,\n            \"L_R_K\": 6000000,\n            \"a_c\": [50, 0, 40, 0],\n            \"a_k\": [25, 0, 80, 0],\n            \"L_A_C\": 8000000,\n            \"L_A_K\": 7000000,\n        },\n        {\n            \"l\": [500, 500, 500],\n            \"x_c\": [120, 80, 60],\n            \"x_k\": [240, 160, 120],\n            \"L_R_C\": 15000000,\n            \"L_R_K\": 15000000,\n            \"a_c\": [300, 200, 100],\n            \"a_k\": [150, 100, 50],\n            \"L_A_C\": 12000000,\n            \"L_A_K\": 10000000,\n        },\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        # Convert inputs to numpy arrays for vectorized operations\n        l_arr = np.array(case[\"l\"], dtype=np.float64)\n        x_c_arr = np.array(case[\"x_c\"], dtype=np.float64)\n        x_k_arr = np.array(case[\"x_k\"], dtype=np.float64)\n        a_c_arr = np.array(case[\"a_c\"], dtype=np.float64)\n        a_k_arr = np.array(case[\"a_k\"], dtype=np.float64)\n\n        # 1. Calculate normalized per-base signals\n        s_r_c = x_c_arr / (case[\"L_R_C\"] * l_arr)\n        s_r_k = x_k_arr / (case[\"L_R_K\"] * l_arr)\n        s_a_c = a_c_arr / (case[\"L_A_C\"] * l_arr)\n        s_a_k = a_k_arr / (case[\"L_A_K\"] * l_arr)\n\n        # 2. Calculate global changes (Delta_R, Delta_A)\n        sum_s_r_c = np.sum(s_r_c)\n        sum_s_r_k = np.sum(s_r_k)\n        delta_r = np.log2((sum_s_r_k + epsilon) / (sum_s_r_c + epsilon))\n\n        sum_s_a_c = np.sum(s_a_c)\n        sum_s_a_k = np.sum(s_a_k)\n        delta_a = np.log2((sum_s_a_k + epsilon) / (sum_s_a_c + epsilon))\n\n        # 3. Calculate per-window log-fold changes (d_R, d_A)\n        d_r = np.log2((s_r_k + epsilon) / (s_r_c + epsilon))\n        d_a = np.log2((s_a_k + epsilon) / (s_a_c + epsilon))\n        \n        # 4. Calculate Pearson correlation coefficient (r)\n        # Handle the special case where variance is zero.\n        if np.var(d_r) == 0.0 or np.var(d_a) == 0.0:\n            r = 0.0\n        else:\n            # Use numpy's built-in correlation coefficient function\n            corr_matrix = np.corrcoef(d_r, d_a)\n            r = corr_matrix[0, 1]\n            # Ensure stability for near-zero variance due to float precision\n            if np.isnan(r):\n                r = 0.0\n\n        all_results.append([delta_r, delta_a, r])\n\n    # Final print statement in the exact required format.\n    # The default str() representation of a list is \"[item1, item2, ...]\"\n    # so joining these string representations with a comma produces the desired output.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "4338626"}]}