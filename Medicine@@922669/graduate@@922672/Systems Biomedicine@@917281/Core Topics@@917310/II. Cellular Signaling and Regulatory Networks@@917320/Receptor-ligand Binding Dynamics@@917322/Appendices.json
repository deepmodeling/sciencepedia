{"hands_on_practices": [{"introduction": "While introductory models of receptor-ligand binding often assume the free ligand concentration is constant, this simplification breaks down when receptor concentration is high or ligand affinity is very strong. This practice challenges you to derive the exact solution for the equilibrium complex concentration under conditions where ligand depletion cannot be ignored [@problem_id:4382845]. Mastering this derivation of the quadratic binding equation provides a more accurate and robust model for analyzing tight-binding interactions, essential for interpreting data from techniques like isothermal titration calorimetry (ITC) or in cellular systems with high receptor expression.", "problem": "Consider a single-site receptor–ligand system in a closed, isothermal, well-mixed compartment with the elementary reversible reaction $R + L \\rightleftharpoons RL$. Let the total receptor concentration and total ligand concentration be $R_T$ and $L_T$, respectively. The system is at thermodynamic equilibrium and obeys mass conservation, so $R_T = [R] + [RL]$ and $L_T = [L] + [RL]$. Assume $1{:}1$ binding without ligand excess, meaning neither $R_T$ nor $L_T$ is negligible relative to the other. At equilibrium, the mass-action ratio defines the equilibrium dissociation constant ($K_D$) by $K_D = \\frac{[R][L]}{[RL]}$. Using only these foundational facts, derive the governing polynomial equation for the equilibrium complex concentration $[RL]$ and solve it explicitly in closed form. Identify the physically admissible root based on the constraints of nonnegativity and the conservation relations. Provide the final analytic expression for $[RL]$ solely in terms of $R_T$, $L_T$, and $K_D$. Express the final concentration in molar units (M). No numerical evaluation or rounding is required; present the final result exactly.", "solution": "The problem statement is evaluated to be valid. It is scientifically grounded, well-posed, and objective, describing the canonical model for single-site bimolecular binding at thermodynamic equilibrium. The problem is self-contained and provides all necessary definitions and conservation laws to derive a unique, physically meaningful solution. The task is to derive the governing equation for the equilibrium concentration of the receptor-ligand complex, $[RL]$, and to solve it explicitly.\n\nThe system is defined by the reversible reaction $R + L \\rightleftharpoons RL$. At equilibrium, the concentrations of the species are related by the equilibrium dissociation constant, $K_D$:\n$$K_D = \\frac{[R][L]}{[RL]}$$\nThe system is closed, so the total concentrations of receptor, $R_T$, and ligand, $L_T$, are conserved. This is expressed by the mass conservation relations:\n$$R_T = [R] + [RL]$$\n$$L_T = [L] + [RL]$$\nOur objective is to find an expression for $[RL]$ in terms of the constants $R_T$, $L_T$, and $K_D$. To achieve this, we must eliminate the free concentrations, $[R]$ and $[L]$, from the $K_D$ equation.\n\nFrom the mass conservation equations, we can express the free concentrations as:\n$$[R] = R_T - [RL]$$\n$$[L] = L_T - [RL]$$\nSubstituting these expressions into the definition of $K_D$:\n$$K_D = \\frac{(R_T - [RL])(L_T - [RL])}{[RL]}$$\nThis equation relates $[RL]$ to the known total concentrations and the dissociation constant. To solve for $[RL]$, we rearrange this equation into a standard polynomial form. Let $x = [RL]$ for notational simplicity during the algebraic manipulation.\n$$K_D x = (R_T - x)(L_T - x)$$\nExpanding the product on the right-hand side gives:\n$$K_D x = R_T L_T - R_T x - L_T x + x^2$$\nWe can now group all terms on one side to form a quadratic equation in the variable $x$:\n$$x^2 - R_T x - L_T x - K_D x + R_T L_T = 0$$\nCombining the terms linear in $x$, we arrive at the governing polynomial equation for the equilibrium complex concentration:\n$$x^2 - (R_T + L_T + K_D)x + R_T L_T = 0$$\nThis is a quadratic equation of the form $ax^2 + bx + c = 0$, with coefficients:\n$a = 1$\n$b = -(R_T + L_T + K_D)$\n$c = R_T L_T$\n\nThe solution(s) for $x = [RL]$ are given by the quadratic formula:\n$$[RL] = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$$\nSubstituting the coefficients:\n$$[RL] = \\frac{(R_T + L_T + K_D) \\pm \\sqrt{(-(R_T + L_T + K_D))^2 - 4(1)(R_T L_T)}}{2(1)}$$\n$$[RL] = \\frac{(R_T + L_T + K_D) \\pm \\sqrt{(R_T + L_T + K_D)^2 - 4R_T L_T}}{2}$$\nThis gives two potential roots for $[RL]$. We must now identify the physically admissible root. The physical constraints on the system are that concentrations must be non-negative. From the mass conservation laws, this implies that the concentration of the complex, $[RL]$, cannot exceed the total concentration of either the receptor or the ligand:\n$$[RL] \\ge 0$$\n$$[RL] \\le R_T$$\n$$[RL] \\le L_T$$\n\nLet's analyze the two roots, denoted by $[RL]_+$ and $[RL]_-$.\n\nConsider the root with the plus sign:\n$$[RL]_+ = \\frac{(R_T + L_T + K_D) + \\sqrt{(R_T + L_T + K_D)^2 - 4R_T L_T}}{2}$$\nLet us test if this root violates the constraint $[RL] \\le R_T$. The inequality is:\n$$\\frac{(R_T + L_T + K_D) + \\sqrt{(R_T + L_T + K_D)^2 - 4R_T L_T}}{2} \\le R_T$$\n$$(L_T + K_D - R_T) + \\sqrt{(R_T + L_T + K_D)^2 - 4R_T L_T} \\le 0$$\n$$\\sqrt{(R_T + L_T + K_D)^2 - 4R_T L_T} \\le R_T - L_T - K_D$$\nThe left-hand side is intrinsically non-negative. For the inequality to have any chance of holding, the right-hand side must also be non-negative, meaning $R_T \\ge L_T + K_D$. Assuming this condition holds, we can square both sides:\n$$(R_T + L_T + K_D)^2 - 4R_T L_T \\le (R_T - L_T - K_D)^2$$\nExpanding both sides:\n$$R_T^2+L_T^2+K_D^2+2R_TL_T+2R_TK_D+2L_TK_D - 4R_TL_T \\le R_T^2+L_T^2+K_D^2-2R_TL_T-2R_TK_D+2L_TK_D$$\nSimplifying the algebra:\n$$-2R_TL_T + 2R_TK_D + 2L_TK_D \\le -2R_TL_T - 2R_TK_D + 2L_TK_D$$\n$$2R_TK_D \\le -2R_TK_D$$\n$$4R_TK_D \\le 0$$\nSince $R_T$ is a total concentration and $K_D$ is a physical constant, both are non-negative ($R_T \\ge 0$, $K_D \\ge 0$). Thus, $4R_TK_D \\ge 0$. The inequality $4R_TK_D \\le 0$ can only hold if $R_T = 0$ or $K_D = 0$. For any physically realistic scenario where $R_T  0$ and $K_D  0$, the inequality is false. This means the assumption $[RL]_+ \\le R_T$ is false. Therefore, $[RL]_+  R_T$ and this root is physically inadmissible as it violates the conservation of mass.\n\nNow, consider the root with the minus sign:\n$$[RL]_- = \\frac{(R_T + L_T + K_D) - \\sqrt{(R_T + L_T + K_D)^2 - 4R_T L_T}}{2}$$\nThis must be the physically admissible solution. We verify its properties.\n1. Non-negativity ($[RL]_- \\ge 0$):\nThis requires $(R_T + L_T + K_D) \\ge \\sqrt{(R_T + L_T + K_D)^2 - 4R_T L_T}$. Since both sides are non-negative, we can square them:\n$$(R_T + L_T + K_D)^2 \\ge (R_T + L_T + K_D)^2 - 4R_T L_T$$\n$$0 \\ge -4R_T L_T \\quad \\implies \\quad 4R_T L_T \\ge 0$$\nThis is always true for non-negative concentrations $R_T$ and $L_T$. Thus, $[RL]_-$ is always non-negative.\n2. Upper bounds ($[RL]_- \\le R_T$ and $[RL]_- \\le L_T$):\nFrom our analysis of the `+` root, we derived the strict inequality $[RL]_+  R_T$ (for $R_T  0, K_D  0$). The sum of the roots of the quadratic equation $x^2+px+q=0$ is $x_1+x_2=-p$. In our case, $[RL]_+ + [RL]_- = R_T + L_T + K_D$. As $[RL]_+$ is demonstrably larger than $R_T$, it follows that $[RL]_-$ must be smaller. The formal proof proceeds as for the `+` root, but with the inequality sign reversed, leading to the condition $0 \\le 4R_TK_D$, which is always true. Symmetrical logic confirms that $[RL]_- \\le L_T$.\n\nTherefore, the only physically admissible solution for the equilibrium concentration of the receptor-ligand complex is the root with the minus sign. The expression is given in molar units (M) as requested, assuming the input parameters $R_T$, $L_T$, and $K_D$ are provided in these units.", "answer": "$$\\boxed{\\frac{(R_T + L_T + K_D) - \\sqrt{(R_T + L_T + K_D)^2 - 4R_T L_T}}{2}}$$", "id": "4382845"}, {"introduction": "Biological environments are rarely simple; more often, multiple molecular species compete for the same binding sites on a receptor. This exercise explores the fundamental principles of competitive binding, a cornerstone of pharmacology and the study of cell signaling networks [@problem_id:4382816]. By deriving the fractional occupancy for a receptor in the presence of two competing ligands, you will build a quantitative framework for understanding drug antagonism, designing displacement assays, and modeling the complex regulatory logic of cellular responses.", "problem": "A single-site receptor species $R$ is exposed to two soluble ligands $L_1$ and $L_2$ that bind competitively to the same site, forming $RL_1$ or $RL_2$, but never both simultaneously. Assume the system is well-mixed, at thermodynamic equilibrium, and that ligand depletion is negligible so that the free ligand concentrations remain at their bath values $[L_1]$ and $[L_2]$. Let $K_{D1}$ and $K_{D2}$ denote the equilibrium dissociation constants of $L_1$ and $L_2$ for the receptor, respectively. Let the total receptor concentration be $R_T$, and define the fractional occupancies $\\theta_1 = [RL_1]/R_T$ and $\\theta_2 = [RL_2]/R_T$. Starting only from the law of mass action, the definition of the equilibrium dissociation constant, and conservation of receptor, derive exact analytic expressions for $\\theta_1$ and $\\theta_2$ in terms of $K_{D1}$, $K_{D2}$, $[L_1]$, and $[L_2]$. Express your final answer as closed-form expressions for $\\theta_1$ and $\\theta_2$. No numerical evaluation is required, and no units are needed for the fractional occupancies.", "solution": "The problem statement is scientifically grounded, objective, and well-posed. It presents a standard model of competitive ligand binding, a fundamental concept in biochemistry and pharmacology. All necessary parameters and conditions are provided to derive a unique, meaningful solution. Thus, we proceed with the derivation.\n\nThe system involves two reversible binding reactions at thermodynamic equilibrium:\n$$ R + L_1 \\rightleftharpoons RL_1 $$\n$$ R + L_2 \\rightleftharpoons RL_2 $$\nHere, $R$ is the free receptor, $L_1$ and $L_2$ are the two ligands, and $RL_1$ and $RL_2$ are the corresponding receptor-ligand complexes.\n\nAccording to the law of mass action, the equilibrium dissociation constants, $K_{D1}$ and $K_{D2}$, are defined for these reactions as follows:\n$$ K_{D1} = \\frac{[R][L_1]}{[RL_1]} $$\n$$ K_{D2} = \\frac{[R][L_2]}{[RL_2]} $$\nwhere $[X]$ denotes the molar concentration of species $X$ at equilibrium. The problem states that ligand depletion is negligible, so the free ligand concentrations are equal to their total (bath) concentrations, $[L_1]$ and $[L_2]$.\n\nThe total concentration of receptors, $R_T$, is conserved. Since the receptor can exist in one of three states—unbound ($R$), bound to $L_1$ ($RL_1$), or bound to $L_2$ ($RL_2$)—the conservation equation is:\n$$ R_T = [R] + [RL_1] + [RL_2] $$\n\nOur objective is to find expressions for the fractional occupancies $\\theta_1 = \\frac{[RL_1]}{R_T}$ and $\\theta_2 = \\frac{[RL_2]}{R_T}$. To achieve this, we must express $[RL_1]$ and $[RL_2]$ in terms of the given parameters ($K_{D1}$, $K_{D2}$, $[L_1]$, $[L_2]$) and the total receptor concentration $R_T$.\n\nFirst, we rearrange the definitions of the dissociation constants to express the concentrations of the bound complexes in terms of the free receptor concentration, $[R]$:\n$$ [RL_1] = \\frac{[R][L_1]}{K_{D1}} $$\n$$ [RL_2] = \\frac{[R][L_2]}{K_{D2}} $$\n\nNext, we substitute these expressions into the receptor conservation equation:\n$$ R_T = [R] + \\frac{[R][L_1]}{K_{D1}} + \\frac{[R][L_2]}{K_{D2}} $$\n\nWe can factor out the free receptor concentration $[R]$ from the right-hand side of the equation:\n$$ R_T = [R] \\left( 1 + \\frac{[L_1]}{K_{D1}} + \\frac{[L_2]}{K_{D2}} \\right) $$\n\nThis allows us to solve for the concentration of free receptors, $[R]$, in terms of $R_T$ and the known parameters:\n$$ [R] = \\frac{R_T}{1 + \\frac{[L_1]}{K_{D1}} + \\frac{[L_2]}{K_{D2}}} $$\n\nNow, we substitute this expression for $[R]$ back into the equations for $[RL_1]$ and $[RL_2]$:\n$$ [RL_1] = \\frac{[R][L_1]}{K_{D1}} = \\left( \\frac{R_T}{1 + \\frac{[L_1]}{K_{D1}} + \\frac{[L_2]}{K_{D2}}} \\right) \\frac{[L_1]}{K_{D1}} $$\n$$ [RL_2] = \\frac{[R][L_2]}{K_{D2}} = \\left( \\frac{R_T}{1 + \\frac{[L_1]}{K_{D1}} + \\frac{[L_2]}{K_{D2}}} \\right) \\frac{[L_2]}{K_{D2}} $$\n\nFinally, we use the definitions of fractional occupancy, $\\theta_1 = \\frac{[RL_1]}{R_T}$ and $\\theta_2 = \\frac{[RL_2]}{R_T}$, to find the desired expressions. We divide the equations for $[RL_1]$ and $[RL_2]$ by $R_T$:\n$$ \\theta_1 = \\frac{[RL_1]}{R_T} = \\frac{\\frac{[L_1]}{K_{D1}}}{1 + \\frac{[L_1]}{K_{D1}} + \\frac{[L_2]}{K_{D2}}} $$\n$$ \\theta_2 = \\frac{[RL_2]}{R_T} = \\frac{\\frac{[L_2]}{K_{D2}}}{1 + \\frac{[L_1]}{K_{D1}} + \\frac{[L_2]}{K_{D2}}} $$\n\nThese are the exact analytic expressions for the fractional occupancies of a single-site receptor in the presence of two competitive ligands at equilibrium. The denominator represents the sum of the statistical weights of all possible receptor states (unbound, bound to $L_1$, bound to $L_2$), normalized such that the weight of the unbound state is $1$. The numerator for each fractional occupancy is the statistical weight of that specific bound state.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\frac{[L_1]}{K_{D1}}}{1 + \\frac{[L_1]}{K_{D1}} + \\frac{[L_2]}{K_{D2}}}  \\frac{\\frac{[L_2]}{K_{D2}}}{1 + \\frac{[L_1]}{K_{D1}} + \\frac{[L_2]}{K_{D2}}} \\end{pmatrix}}$$", "id": "4382816"}, {"introduction": "Bridging analytical theory and experimental practice requires confronting noisy data and the critical challenge of parameter estimation. This computational exercise guides you through a complete workflow: simulating data for a cooperative binding process described by the Hill equation, fitting the model to this data using nonlinear least squares, and rigorously assessing the reliability of your parameter estimates [@problem_id:4382780]. You will learn to use metrics derived from the Fisher Information Matrix to quantify parameter identifiability, a crucial skill for designing informative experiments and building predictive models in systems biology.", "problem": "You will construct a complete, runnable program that simulates receptor–ligand titration data under a cooperative binding hypothesis, estimates the apparent half-saturation concentration and Hill coefficient from the simulated data in the presence of noise, and assesses parameter identifiability using the Fisher Information Matrix (FIM). Work in purely mathematical terms with explicit algorithmic steps and make your program deterministic.\n\nThe scientific base and assumptions are as follows:\n\n- Start from the law of mass action: for a single binding event, the rate of formation and dissociation of a receptor–ligand complex is governed by $k_{\\text{on}}$ and $k_{\\text{off}}$, and at equilibrium the fractional occupancy can be written in terms of the ligand concentration $[L]$ and a dissociation constant $K_{\\mathrm{d}}$. In systems exhibiting cooperativity, a phenomenological macroscopic description aggregates multiple microscopic steps into an effective equilibrium relation between occupancy and $[L]$.\n\n- Define the apparent half-saturation concentration $K_{1/2}$ as the ligand concentration at which the normalized response equals $1/2$.\n\n- Define the Hill coefficient $n_{\\mathrm{H}}$ by the slope of the Hill plot at half-saturation, that is, $n_{\\mathrm{H}}$ is the derivative of $\\log\\left(y/(1-y)\\right)$ with respect to $\\log [L]$ evaluated at $y=1/2$, where $y$ is the fractional occupancy or normalized effect.\n\n- Measurement noise is modeled as independent, identically distributed, zero-mean Gaussian noise with a known standard deviation $\\sigma_{y}$ (expressed in the same units as the measured response).\n\nYour program must:\n\n- Simulate titration data by generating responses $y([L])$ over a specified set of ligand concentrations $[L]$, add Gaussian noise with specified $\\sigma_{y}$ and a fixed random seed, and then fit a cooperative binding response model parameterized by three positive parameters: a maximum response $B_{\\max}$, an apparent half-saturation concentration $K_{1/2}$, and a Hill coefficient $n_{\\mathrm{H}}$. You must estimate $B_{\\max}$, $K_{1/2}$, and $n_{\\mathrm{H}}$ by nonlinear least squares with positivity constraints.\n\n- Compute the Jacobian matrix $J$ of residuals with respect to parameters at the optimum, the approximate Fisher Information Matrix (FIM) $\\mathcal{I} \\approx J^{\\top}J/\\hat{\\sigma}^{2}$, where $\\hat{\\sigma}^{2}$ is the residual variance, the condition number $\\kappa(\\mathcal{I})$, and the approximate parameter covariance as $\\hat{\\Sigma} \\approx \\hat{\\sigma}^{2}(J^{\\top}J)^{-1}$.\n\n- From $\\hat{\\Sigma}$, compute the standard errors of $K_{1/2}$ and $n_{\\mathrm{H}}$ and the two-sided $95\\%$ confidence intervals under the normal approximation. Use these to quantify identifiability.\n\n- Declare the joint identifiability of $K_{1/2}$ and $n_{\\mathrm{H}}$ as a single boolean according to the following rule: the fit must converge with strictly positive estimates; the condition number $\\kappa(\\mathcal{I})$ must be less than $10^{8}$; and both $K_{1/2}$ and $n_{\\mathrm{H}}$ must have finite $95\\%$ confidence intervals whose relative half-widths are less than $0.5$ (that is, $1.96$ times the standard error divided by the estimate is less than $0.5$ in absolute value).\n\n- Report the estimated $K_{1/2}$ in nanomolar (nM) and $n_{\\mathrm{H}}$ as dimensionless values.\n\n- For all computations, use standard double precision. No physical unit conversion is required beyond interpreting the concentration values as nanomolar.\n\nTest suite:\n\nSimulate three test cases defined as follows. In each case, generate the titration data from a cooperative binding response with true parameters $(B_{\\max}^{\\mathrm{true}},K_{1/2}^{\\mathrm{true}},n_{\\mathrm{H}}^{\\mathrm{true}})$ and then add Gaussian noise with standard deviation $\\sigma_{y}$.\n\n- Case $1$ (well-identified, wide range, low noise):\n  - True parameters: $B_{\\max}^{\\mathrm{true}}=1.0$, $K_{1/2}^{\\mathrm{true}}=50.0\\,\\text{nM}$, $n_{\\mathrm{H}}^{\\mathrm{true}}=2.0$.\n  - Concentrations: $[L]$ log-spaced from $0.5\\,\\text{nM}$ to $5000\\,\\text{nM}$ with $30$ points.\n  - Noise: $\\sigma_{y}=0.02$. Random seed: $12345$.\n\n- Case $2$ (same range, higher noise):\n  - True parameters: $B_{\\max}^{\\mathrm{true}}=1.0$, $K_{1/2}^{\\mathrm{true}}=50.0\\,\\text{nM}$, $n_{\\mathrm{H}}^{\\mathrm{true}}=2.0$.\n  - Concentrations: $[L]$ log-spaced from $0.5\\,\\text{nM}$ to $5000\\,\\text{nM}$ with $30$ points.\n  - Noise: $\\sigma_{y}=0.15$. Random seed: $67890$.\n\n- Case $3$ (limited range near saturation, low noise, poor information on curvature):\n  - True parameters: $B_{\\max}^{\\mathrm{true}}=1.0$, $K_{1/2}^{\\mathrm{true}}=50.0\\,\\text{nM}$, $n_{\\mathrm{H}}^{\\mathrm{true}}=2.0$.\n  - Concentrations: $[L]$ log-spaced from $100\\,\\text{nM}$ to $5000\\,\\text{nM}$ with $15$ points.\n  - Noise: $\\sigma_{y}=0.02$. Random seed: $24680$.\n\nProgram requirements:\n\n- Implement the nonlinear least squares with positivity constraints and compute the required identifiability metrics precisely as described, without using any external data. Use deterministic pseudorandom number generation via the specified seeds.\n\n- Express the final estimated $K_{1/2}$ in $\\text{nM}$ and $n_{\\mathrm{H}}$ as dimensionless numbers. Round both $K_{1/2}$ and $n_{\\mathrm{H}}$ to three significant figures for output.\n\n- Final output format: your program should produce a single line of output containing the results for the three cases as a Python-style list of lists, where each inner list is ordered as $[K_{1/2}^{\\text{est}}\\ \\text{in nM},\\ n_{\\mathrm{H}}^{\\text{est}},\\ \\text{identifiable}]$. For example, the printed line must have the form $[[x_{1},y_{1},b_{1}],[x_{2},y_{2},b_{2}],[x_{3},y_{3},b_{3}]]$ where $x_{i}$ and $y_{i}$ are floats and $b_{i}$ is a boolean. No other text should be printed.", "solution": "The problem requires the development of a computational workflow to simulate and analyze receptor-ligand titration data under a cooperative binding hypothesis. This process involves three primary stages: first, the generation of synthetic data based on the Hill model with superimposed Gaussian noise; second, the estimation of the model's parameters from this noisy data via nonlinear least squares; and third, a rigorous assessment of the practical identifiability of these parameters using methods based on the Fisher Information Matrix (FIM).\n\n**1. The Cooperative Binding Model: The Hill Equation**\n\nThe relationship between the ligand concentration, $[L]$, and the measured response, $y$, for a system exhibiting cooperativity is phenomenologically described by the Hill equation. This model is characterized by a set of three positive parameters: the maximum response $B_{\\max}$, the apparent half-saturation concentration $K_{1/2}$, and the Hill coefficient $n_{\\mathrm{H}}$. The functional form of the model is:\n$$ y([L]; B_{\\max}, K_{1/2}, n_{\\mathrm{H}}) = B_{\\max} \\frac{[L]^{n_{\\mathrm{H}}}}{K_{1/2}^{n_{\\mathrm{H}}} + [L]^{n_{\\mathrm{H}}}} $$\nIn this equation, $B_{\\max}$ signifies the asymptotic response at saturating ligand concentrations. $K_{1/2}$ represents the ligand concentration at which the response $y$ is half of its maximum, i.e., $y(K_{1/2}) = B_{\\max}/2$. The Hill coefficient $n_{\\mathrm{H}}$ quantifies the degree of cooperativity: $n_{\\mathrm{H}}  1$ implies positive cooperativity (allosteric enhancement of binding), $n_{\\mathrm{H}}  1$ suggests negative cooperativity, and $n_{\\mathrm{H}} = 1$ recovers the non-cooperative Michaelis-Menten or Langmuir binding isotherm.\n\n**2. Data Simulation**\n\nFor each specified test case, we generate a set of simulated observations. Let the true parameters be $\\theta^{\\mathrm{true}} = (B_{\\max}^{\\mathrm{true}}, K_{1/2}^{\\mathrm{true}}, n_{\\mathrm{H}}^{\\mathrm{true}})$.\nFirst, a vector of $N$ ligand concentrations, $\\{[L]_i\\}_{i=1}^N$, is generated. For each concentration $[L]_i$, the true (noise-free) response is calculated:\n$$ y_i^{\\mathrm{true}} = y([L]_i; \\theta^{\\mathrm{true}}) $$\nMeasurement noise is modeled as independent, identically distributed (i.i.d.) random variables $\\epsilon_i$ drawn from a zero-mean normal distribution with a specified standard deviation $\\sigma_y$, i.e., $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_y^2)$. The simulated observations $y_i^{\\mathrm{obs}}$ are then given by:\n$$ y_i^{\\mathrm{obs}} = y_i^{\\mathrm{true}} + \\epsilon_i $$\nTo ensure deterministic and reproducible results, the pseudo-random number generator is initialized with a specific seed for each test case.\n\n**3. Parameter Estimation via Nonlinear Least Squares (NLLS)**\n\nThe goal is to estimate the parameters $\\theta = (B_{\\max}, K_{1/2}, n_{\\mathrm{H}})$ from the simulated data $([L]_i, y_i^{\\mathrm{obs}})$. This is achieved by minimizing the sum of squared residuals (SSR), which is the objective function for NLLS:\n$$ \\hat{\\theta} = \\arg\\min_{\\theta} \\sum_{i=1}^{N} \\left( y_i^{\\mathrm{obs}} - y([L]_i; \\theta) \\right)^2 $$\nThe parameter search is subject to the positivity constraints $B_{\\max}  0$, $K_{1/2}  0$, and $n_{\\mathrm{H}}  0$. This constrained optimization problem is solved numerically, for which the Trust Region Reflective (`trf`) algorithm is suitable.\n\n**4. Parameter Identifiability Analysis**\n\nPractical identifiability concerns whether the model parameters can be uniquely and precisely estimated from a given finite and noisy dataset. We assess this using several metrics derived from the NLLS fit. Let $\\hat{\\theta}$ be the optimal parameter vector.\n\n**Jacobian Matrix:** The analysis begins with the Jacobian matrix $J$ of the model's residual vector $r(\\theta)$ evaluated at the estimated parameters $\\hat{\\theta}$. The residual vector has components $r_i(\\theta) = y_i^{\\mathrm{obs}} - y([L]_i; \\theta)$. The Jacobian is an $N \\times 3$ matrix with entries:\n$$ J_{ij}(\\hat{\\theta}) = \\frac{\\partial r_i}{\\partial \\theta_j} \\bigg|_{\\theta=\\hat{\\theta}} = - \\frac{\\partial y([L]_i; \\theta)}{\\partial \\theta_j} \\bigg|_{\\theta=\\hat{\\theta}} $$\nThe partial derivatives of the Hill function with respect to its parameters are:\n- $\\frac{\\partial y}{\\partial B_{\\max}} = \\frac{[L]^{n_{\\mathrm{H}}}}{K_{1/2}^{n_{\\mathrm{H}}} + [L]^{n_{\\mathrm{H}}}}$\n- $\\frac{\\partial y}{\\partial K_{1/2}} = - B_{\\max} n_{\\mathrm{H}} K_{1/2}^{n_{\\mathrm{H}}-1} \\frac{[L]^{n_{\\mathrm{H}}}}{(K_{1/2}^{n_{\\mathrm{H}}} + [L]^{n_{\\mathrm{H}}})^2}$\n- $\\frac{\\partial y}{\\partial n_{\\mathrm{H}}} = B_{\\max} \\frac{[L]^{n_{\\mathrm{H}}} K_{1/2}^{n_{\\mathrm{H}}} \\ln([L]/K_{1/2})}{(K_{1/2}^{n_{\\mathrm{H}}} + [L]^{n_{\\mathrm{H}}})^2}$\n\n**Fisher Information and Covariance:** Under the assumption of i.i.d. Gaussian noise, an approximation to the Fisher Information Matrix (FIM) is given by:\n$$ \\mathcal{I} \\approx \\frac{J^{\\top}J}{\\hat{\\sigma}^2} $$\nwhere $J$ is the Jacobian evaluated at $\\hat{\\theta}$ and $\\hat{\\sigma}^2$ is the estimated residual variance. The unbiased estimator for the variance is used:\n$$ \\hat{\\sigma}^2 = \\frac{\\text{SSR}(\\hat{\\theta})}{N - p} $$\nwhere $p=3$ is the number of parameters.\nThe inverse of the FIM provides the Cramér-Rao lower bound on the variance of any unbiased estimator. The approximate parameter covariance matrix, $\\hat{\\Sigma}$, is thus:\n$$ \\hat{\\Sigma} \\approx \\mathcal{I}^{-1} = \\hat{\\sigma}^2 (J^{\\top}J)^{-1} $$\n\n**Identifiability Metrics:**\n- **Condition Number:** The condition number of the FIM, $\\kappa(\\mathcal{I})$, measures the sensitivity of the parameter estimates to changes in the data. A large condition number indicates that the FIM is nearly singular, implying strong correlations between parameter estimates and thus poor identifiability. It is calculated as the ratio of the largest to the smallest eigenvalue of $\\mathcal{I}$. The problem specifies a threshold of $\\kappa(\\mathcal{I})  10^8$.\n- **Standard Errors and Confidence Intervals:** The standard error (SE) of a parameter estimate $\\hat{\\theta}_j$ is the square root of the corresponding diagonal element of the covariance matrix, $\\text{SE}(\\hat{\\theta}_j) = \\sqrt{\\hat{\\Sigma}_{jj}}$. A $95\\%$ confidence interval (CI) is approximated using the normal distribution as $\\hat{\\theta}_j \\pm 1.96 \\times \\text{SE}(\\hat{\\theta}_j)$.\n- **Identifiability Rule:** The joint identifiability of $K_{1/2}$ and $n_{\\mathrm{H}}$ is determined by a composite boolean rule:\n    1. The NLLS optimization must converge successfully, and all estimated parameters must be strictly positive.\n    2. The condition number of the FIM must be less than $10^8$.\n    3. The $95\\%$ confidence intervals for both $K_{1/2}$ and $n_{\\mathrm{H}}$ must be finite. This requires $(J^{\\top}J)$ to be invertible.\n    4. The relative half-width of the $95\\%$ CI for both $K_{1/2}$ and $n_{\\mathrm{H}}$ must be less than $0.5$. The relative half-width for a parameter $\\hat{\\theta}_j$ is defined as $\\frac{1.96 \\times \\text{SE}(\\hat{\\theta}_j)}{|\\hat{\\theta}_j|}$.\n\nThis comprehensive procedure allows for a quantitative assessment of whether the experimental design and data quality are sufficient to reliably determine the model parameters.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import least_squares\n\ndef solve():\n    \"\"\"\n    Main function to simulate, fit, and analyze cooperative binding data for three test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"name\": \"Case 1: Well-identified, wide range, low noise\",\n            \"true_params\": (1.0, 50.0, 2.0),\n            \"L_config\": {\"start\": 0.5, \"stop\": 5000, \"num\": 30},\n            \"sigma_y\": 0.02,\n            \"seed\": 12345\n        },\n        {\n            \"name\": \"Case 2: Same range, higher noise\",\n            \"true_params\": (1.0, 50.0, 2.0),\n            \"L_config\": {\"start\": 0.5, \"stop\": 5000, \"num\": 30},\n            \"sigma_y\": 0.15,\n            \"seed\": 67890\n        },\n        {\n            \"name\": \"Case 3: Limited range near saturation, low noise\",\n            \"true_params\": (1.0, 50.0, 2.0),\n            \"L_config\": {\"start\": 100, \"stop\": 5000, \"num\": 15},\n            \"sigma_y\": 0.02,\n            \"seed\": 24680\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = analyze_binding_case(\n            case[\"true_params\"],\n            case[\"L_config\"],\n            case[\"sigma_y\"],\n            case[\"seed\"]\n        )\n        results.append(result)\n\n    # Format the final output as a Python-style list of lists.\n    # The boolean values True/False must be lowercase as per Python syntax.\n    output_str = \"[\" + \",\".join(\n        f\"[{k},{n},{str(b).lower()}]\" for k, n, b in results\n    ) + \"]\"\n    print(output_str)\n\n\ndef analyze_binding_case(true_params, L_config, sigma_y, seed):\n    \"\"\"\n    Performs the simulation, fitting, and identifiability analysis for a single case.\n    \n    Args:\n        true_params (tuple): (Bmax_true, K12_true, nH_true).\n        L_config (dict): Configuration for ligand concentrations.\n        sigma_y (float): Standard deviation of Gaussian noise.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        list: [k12_est_rounded, nH_est_rounded, is_identifiable].\n    \"\"\"\n    \n    Bmax_true, K12_true, nH_true = true_params\n    \n    # 1. Simulate titration data\n    L = np.logspace(np.log10(L_config[\"start\"]), np.log10(L_config[\"stop\"]), L_config[\"num\"])\n    y_true = hill_equation(true_params, L)\n    rng = np.random.default_rng(seed)\n    noise = rng.normal(0, sigma_y, size=L.shape)\n    y_obs = y_true + noise\n\n    # 2. Perform Nonlinear Least Squares (NLLS) fitting\n    p0 = [Bmax_true, K12_true, nH_true] # Initial guess\n    bounds = (0, np.inf)\n    \n    res = least_squares(\n        fun=residuals,\n        x0=p0,\n        args=(L, y_obs),\n        bounds=bounds,\n        method='trf'\n    )\n    \n    # Initialize default results for non-identifiable case\n    k_est_final, nH_est_final, is_identifiable = np.nan, np.nan, False\n\n    # 3. Assess identifiability\n    # Condition 1: Fit must converge and estimates must be positive\n    if res.success and np.all(res.x  0):\n        p_est = res.x\n        Bmax_est, K12_est, nH_est = p_est\n        \n        N = len(y_obs)  # Number of data points\n        p_num = len(p_est)  # Number of parameters\n\n        try:\n            # Jacobian J from the fit results\n            jac = res.jac\n\n            # Calculate J^T * J\n            jtj = jac.T @ jac\n            \n            # Check if J^T*J is invertible\n            if np.linalg.matrix_rank(jtj)  p_num:\n                raise np.linalg.LinAlgError(\"Singular matrix\")\n\n            # Residual variance estimate\n            ssr = np.sum(res.fun**2)\n            residual_variance = ssr / (N - p_num)\n\n            # Approximate Fisher Information Matrix (FIM)\n            fim = jtj / residual_variance \n            \n            # Condition 2: Condition number of FIM\n            kappa_fim = np.linalg.cond(fim)\n            cond_num_ok = kappa_fim  1e8\n\n            # Approximate Covariance Matrix\n            cov_matrix = residual_variance * np.linalg.inv(jtj)\n            \n            # Standard Errors\n            se = np.sqrt(np.diag(cov_matrix))\n            se_Bmax, se_K12, se_nH = se\n\n            # Condition 3: Finite confidence intervals (implied by finite SE)\n            finite_ci_ok = np.all(np.isfinite(se))\n\n            # Condition 4: Relative half-width of CIs for K1/2 and nH\n            # rel_half_width = 1.96 * SE / estimate\n            rel_hw_k12 = 1.96 * se_K12 / K12_est\n            rel_hw_nH = 1.96 * se_nH / nH_est\n            \n            rel_hw_ok = (abs(rel_hw_k12)  0.5) and (abs(rel_hw_nH)  0.5)\n\n            # Combine all identifiability conditions\n            if cond_num_ok and finite_ci_ok and rel_hw_ok:\n                is_identifiable = True\n                k_est_final = format_sig_figs(K12_est, 3)\n                nH_est_final = format_sig_figs(nH_est, 3)\n            else: # If any condition fails, but fit was successful\n                k_est_final = format_sig_figs(K12_est, 3)\n                nH_est_final = format_sig_figs(nH_est, 3)\n                is_identifiable = False\n\n        except np.linalg.LinAlgError:\n            # If J^T*J is singular, identifiability check fails\n            k_est_final = format_sig_figs(p_est[1], 3)\n            nH_est_final = format_sig_figs(p_est[2], 3)\n            is_identifiable = False\n    else: # If fit did not converge or gave non-positive parameters\n        is_identifiable = False\n        # Use NaN or initial guess, problem requires outputting estimates anyway.\n        # Try to provide last estimate if available, otherwise NaN\n        if res.x is not None:\n             k_est_final = format_sig_figs(res.x[1], 3) if res.x[1]0 else np.nan\n             nH_est_final = format_sig_figs(res.x[2], 3) if res.x[2]0 else np.nan\n        else:\n             k_est_final, nH_est_final = np.nan, np.nan\n\n    return [k_est_final, nH_est_final, is_identifiable]\n\ndef hill_equation(p, L):\n    \"\"\"\n    Calculates the response based on the Hill equation.\n    \n    Args:\n        p (tuple/list): Parameters (Bmax, K1/2, nH).\n        L (ndarray): Ligand concentrations.\n        \n    Returns:\n        ndarray: The calculated response y.\n    \"\"\"\n    Bmax, K12, nH = p\n    return Bmax * (L**nH) / (K12**nH + L**nH)\n\ndef residuals(p, L, y_obs):\n    \"\"\"\n    Calculates the residuals between observed data and the Hill model.\n    \"\"\"\n    return y_obs - hill_equation(p, L)\n\ndef format_sig_figs(num, sig_figs):\n    \"\"\"\n    Rounds a number to a specified number of significant figures.\n    \"\"\"\n    if not np.isfinite(num) or num == 0:\n        return num\n    return float(f'{num:.{sig_figs}g}')\n\nif __name__ == '__main__':\n    solve()\n```", "id": "4382780"}]}