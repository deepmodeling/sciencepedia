{"hands_on_practices": [{"introduction": "A foundational skill in genomics is the ability to predict regulatory regions directly from DNA sequence. CpG islands, which are central to understanding DNA methylation patterns, are defined by specific sequence characteristics. This practice [@problem_id:4335581] will guide you through the derivation of a probabilistic classifier from first principles. By applying Bayes' theorem, you will build a model that links simple sequence statistics—GC content and CpG frequency—to the likelihood of a region being a CpG island, thereby providing a quantitative estimate of its susceptibility to methylation.", "problem": "A central phenomenon in systems biomedicine is that Deoxyribonucleic Acid (DNA) cytosine methylation is depleted within Cytosine-phosphate-Guanine (CpG) islands, which are short genomic regions characterized by high Guanine + Cytosine (GC) content and elevated CpG observed/expected values relative to the genomic background. Let a genomic window of length $L$ be summarized by two sequence features: GC content $g$ defined as $g = (n_{G} + n_{C})/L$, and the CpG observed/expected ratio $r$ defined as $r = \\dfrac{n_{\\mathrm{CpG}} \\cdot L}{n_{C} \\cdot n_{G}}$, where $n_{G}$, $n_{C}$, and $n_{\\mathrm{CpG}}$ are the counts of guanine, cytosine, and CpG dinucleotides within the window, respectively. We consider a probabilistic, sequence-only classifier that predicts CpG island presence and, by complement, methylation susceptibility.\n\nAssume there are two latent classes: island ($I$) and non-island ($N$). Conditional on the class, the features are independent and Gaussian: $g \\mid I \\sim \\mathcal{N}(\\mu_{g,I}, \\sigma_{g,I}^{2})$, $r \\mid I \\sim \\mathcal{N}(\\mu_{r,I}, \\sigma_{r,I}^{2})$, $g \\mid N \\sim \\mathcal{N}(\\mu_{g,N}, \\sigma_{g,N}^{2})$, and $r \\mid N \\sim \\mathcal{N}(\\mu_{r,N}, \\sigma_{r,N}^{2})$. Let the prior probability of the island class be $\\pi = \\mathbb{P}(I)$, so that $\\mathbb{P}(N) = 1 - \\pi$. Here $\\mu_{g,I}$, $\\sigma_{g,I}$, $\\mu_{r,I}$, $\\sigma_{r,I}$, $\\mu_{g,N}$, $\\sigma_{g,N}$, $\\mu_{r,N}$, $\\sigma_{r,N}$, and $\\pi$ are fixed parameters representing a genomic context and species.\n\nStarting only from the definitions of $g$ and $r$, the independence assumption, the Gaussian likelihood, and Bayes’ theorem, derive the analytic expression for the methylation susceptibility $S(g,r)$ of the window, defined as $S(g,r) = 1 - \\mathbb{P}(I \\mid g, r)$, under this model. Express your final answer as a single closed-form function of $g$, $r$, $\\mu_{g,I}$, $\\sigma_{g,I}$, $\\mu_{r,I}$, $\\sigma_{r,I}$, $\\mu_{g,N}$, $\\sigma_{g,N}$, $\\mu_{r,N}$, $\\sigma_{r,N}$, and $\\pi$. No numerical evaluation is required. Give your final expression in simplest form with standard elementary functions. State your final answer as one analytic expression; no inequalities or equations are permitted within the final answer.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It provides a complete and consistent set of definitions and conditions for a standard problem in probabilistic classification. The model, while an abstraction, is based on established principles in computational biology and statistical modeling. Therefore, the problem is valid, and a solution can be derived.\n\nThe methylation susceptibility, $S(g,r)$, is defined as $S(g,r) = 1 - \\mathbb{P}(I \\mid g, r)$, where $I$ denotes the CpG island class and $(g, r)$ are the observed features (GC content and CpG ratio). Since the latent classes are island ($I$) and non-island ($N$), the law of total probability for conditional probabilities states that $\\mathbb{P}(I \\mid g, r) + \\mathbb{P}(N \\mid g, r) = 1$. Thus, the susceptibility is precisely the posterior probability of the non-island class given the data:\n$$\nS(g,r) = \\mathbb{P}(N \\mid g, r)\n$$\nTo find this posterior probability, we apply Bayes' theorem. Let $p(\\cdot)$ denote a probability density function.\n$$\n\\mathbb{P}(N \\mid g, r) = \\frac{p(g, r \\mid N) \\mathbb{P}(N)}{p(g, r)}\n$$\nThe denominator, $p(g,r)$, is the marginal probability of the data, which can be expanded using the law of total probability over the two latent classes:\n$$\np(g, r) = p(g, r \\mid I) \\mathbb{P}(I) + p(g, r \\mid N) \\mathbb{P}(N)\n$$\nSubstituting this into the expression for the posterior gives:\n$$\n\\mathbb{P}(N \\mid g, r) = \\frac{p(g, r \\mid N) \\mathbb{P}(N)}{p(g, r \\mid I) \\mathbb{P}(I) + p(g, r \\mid N) \\mathbb{P}(N)}\n$$\nTo simplify this expression, we can divide the numerator and the denominator by the term $p(g, r \\mid N) \\mathbb{P}(N)$:\n$$\nS(g, r) = \\frac{1}{\\frac{p(g, r \\mid I) \\mathbb{P}(I)}{p(g, r \\mid N) \\mathbb{P}(N)} + 1}\n$$\nThe problem states that, conditional on the class, the features $g$ and $r$ are independent. This allows us to write the joint conditional likelihoods as the product of the individual conditional likelihoods:\n$$\np(g, r \\mid I) = p(g \\mid I) p(r \\mid I)\n$$\n$$\np(g, r \\mid N) = p(g \\mid N) p(r \\mid N)\n$$\nThe prior probabilities are given as $\\mathbb{P}(I) = \\pi$ and $\\mathbb{P}(N) = 1 - \\pi$. The ratio in the denominator becomes:\n$$\n\\frac{p(g \\mid I) p(r \\mid I) \\pi}{p(g \\mid N) p(r \\mid N) (1 - \\pi)}\n$$\nThe conditional distributions are given as Gaussian. The probability density function for a normal distribution $\\mathcal{N}(\\mu, \\sigma^2)$ is $p(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)$. We substitute the corresponding PDFs for each term:\n\\begin{itemize}\n    \\item $p(g \\mid I) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{g,I}} \\exp\\left(-\\frac{(g - \\mu_{g,I})^2}{2\\sigma_{g,I}^2}\\right)$\n    \\item $p(r \\mid I) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{r,I}} \\exp\\left(-\\frac{(r - \\mu_{r,I})^2}{2\\sigma_{r,I}^2}\\right)$\n    \\item $p(g \\mid N) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{g,N}} \\exp\\left(-\\frac{(g - \\mu_{g,N})^2}{2\\sigma_{g,N}^2}\\right)$\n    \\item $p(r \\mid N) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{r,N}} \\exp\\left(-\\frac{(r - \\mu_{r,N})^2}{2\\sigma_{r,N}^2}\\right)$\n\\end{itemize}\nLet's compute the likelihood ratio $p(g, r \\mid I) / p(g, r \\mid N)$:\n$$\n\\frac{p(g, r \\mid I)}{p(g, r \\mid N)} = \\frac{\\frac{1}{2\\pi\\sigma_{g,I}\\sigma_{r,I}} \\exp\\left(-\\frac{(g - \\mu_{g,I})^2}{2\\sigma_{g,I}^2} - \\frac{(r - \\mu_{r,I})^2}{2\\sigma_{r,I}^2}\\right)}{\\frac{1}{2\\pi\\sigma_{g,N}\\sigma_{r,N}} \\exp\\left(-\\frac{(g - \\mu_{g,N})^2}{2\\sigma_{g,N}^2} - \\frac{(r - \\mu_{r,N})^2}{2\\sigma_{r,N}^2}\\right)}\n$$\nThe $1/(2\\pi)$ terms cancel. We can combine the constant prefactors and the exponential terms:\n$$\n\\frac{p(g, r \\mid I)}{p(g, r \\mid N)} = \\frac{\\sigma_{g,N}\\sigma_{r,N}}{\\sigma_{g,I}\\sigma_{r,I}} \\exp\\left[ \\left(-\\frac{(g - \\mu_{g,I})^2}{2\\sigma_{g,I}^2} - \\frac{(r - \\mu_{r,I})^2}{2\\sigma_{r,I}^2}\\right) - \\left(-\\frac{(g - \\mu_{g,N})^2}{2\\sigma_{g,N}^2} - \\frac{(r - \\mu_{r,N})^2}{2\\sigma_{r,N}^2}\\right) \\right]\n$$\nRearranging the terms inside the exponent for clarity:\n$$\n\\text{Exponent} = \\frac{(g - \\mu_{g,N})^2}{2\\sigma_{g,N}^2} - \\frac{(g - \\mu_{g,I})^2}{2\\sigma_{g,I}^2} + \\frac{(r - \\mu_{r,N})^2}{2\\sigma_{r,N}^2} - \\frac{(r - \\mu_{r,I})^2}{2\\sigma_{r,I}^2}\n$$\nNow, we assemble the full expression for $S(g,r)$:\n$$\nS(g,r) = \\left(1 + \\frac{\\pi}{1-\\pi} \\frac{p(g, r \\mid I)}{p(g, r \\mid N)}\\right)^{-1}\n$$\nSubstituting the likelihood ratio expression derived above yields the final analytical form for the methylation susceptibility:\n$$\nS(g,r) = \\left(1 + \\frac{\\pi}{1-\\pi} \\frac{\\sigma_{g,N}\\sigma_{r,N}}{\\sigma_{g,I}\\sigma_{r,I}} \\exp\\left( \\frac{(g - \\mu_{g,N})^2}{2\\sigma_{g,N}^2} - \\frac{(g - \\mu_{g,I})^2}{2\\sigma_{g,I}^2} + \\frac{(r - \\mu_{r,N})^2}{2\\sigma_{r,N}^2} - \\frac{(r - \\mu_{r,I})^2}{2\\sigma_{r,I}^2} \\right)\\right)^{-1}\n$$\nThis expression is a single closed-form function of the given features ($g, r$) and model parameters ($\\pi$, $\\mu_{g,I}$, $\\sigma_{g,I}$, $\\mu_{r,I}$, $\\sigma_{r,I}$, $\\mu_{g,N}$, $\\sigma_{g,N}$, $\\mu_{r,N}$, $\\sigma_{r,N}$), as required.", "answer": "$$\\boxed{\\left(1 + \\frac{\\pi}{1-\\pi} \\frac{\\sigma_{g,N}\\sigma_{r,N}}{\\sigma_{g,I}\\sigma_{r,I}} \\exp\\left( \\frac{(g - \\mu_{g,N})^2}{2\\sigma_{g,N}^2} - \\frac{(g - \\mu_{g,I})^2}{2\\sigma_{g,I}^2} + \\frac{(r - \\mu_{r,N})^2}{2\\sigma_{r,N}^2} - \\frac{(r - \\mu_{r,I})^2}{2\\sigma_{r,I}^2} \\right)\\right)^{-1}}$$", "id": "4335581"}, {"introduction": "Epigenetic states are not static; they are the result of dynamic processes involving 'reader' and 'writer' enzymes that establish, maintain, and erase marks. This exercise [@problem_id:4335592] offers a hands-on experience in modeling these dynamics through code. You will implement a 'reader-writer' feedback model for the spreading of the repressive H3K27me3 mark, exploring how local interactions and enzymatic activities can lead to emergent system properties like bistability and the formation of stable epigenetic domains, which are thought to be a basis for cellular memory.", "problem": "You are to implement and analyze a mechanistic network model of histone H3 lysine 27 trimethylation spreading mediated by Polycomb Repressive Complex 2 (PRC2), capturing reader–writer feedback and demethylation, within a one-dimensional array of nucleosomes. Polycomb Repressive Complex 2 (PRC2) is a histone methyltransferase that deposits trimethylation of lysine 27 on histone H3 (H3K27me3); PRC2 is recruited more strongly to nucleosomes already marked with H3K27me3, yielding positive feedback that can drive bistability and spatial domain formation. Your program must be a complete, runnable program that computes bistability and domain formation metrics for a specified test suite of parameters and produces results in a single-line format described below.\n\nModel definition:\n- Consider a linear chain of $L$ nucleosome positions indexed by $i \\in \\{0,1,\\dots,L-1\\}$.\n- Let $x_i(t) \\in [0,1]$ denote the fraction of histone H3 at position $i$ that is in the H3K27me3 state at time $t$.\n- Let $w_{ij}$ be an interaction kernel describing reader–writer recruitment influence from position $j$ to position $i$, constrained so that $\\sum_{j=0}^{L-1} w_{ij} = 1$ for each $i$. Assume the kernel decays exponentially with genomic distance: $w_{ij} \\propto \\exp(-|i-j|/\\lambda)$, with row-wise normalization to satisfy the sum constraint.\n- Define the local reader signal at position $i$ as $M_i(t) = \\sum_{j=0}^{L-1} w_{ij} x_j(t)$.\n- Let the methylation propensity be the sum of a basal writer term and a reader–writer feedback term, modeled by a Hill function: $k_b + \\alpha h(M_i)$, where $h(z) = \\dfrac{z^n}{K^n + z^n}$ with Hill coefficient $n \\geq 1$ and half-saturation constant $K  0$. Here $k_b \\geq 0$ is the basal methylation rate and $\\alpha \\geq 0$ is the maximal reader–writer amplification strength.\n- Let $k_d \\geq 0$ be the demethylation rate (e.g., representing the activity of lysine demethylases such as KDM6).\n\nUnder mass-action style kinetics and exclusivity between methylated and unmethylated states, the dynamics at each position are:\n$$\n\\frac{dx_i}{dt} = \\left(k_b + \\alpha h(M_i)\\right)\\left(1 - x_i\\right) - k_d x_i.\n$$\n\nUniform-state reduction for bistability analysis:\n- To assess bistability in a spatially homogeneous approximation, assume $x_i(t) = x(t)$ for all $i$. With the normalized kernel, $M_i(t) = x(t)$ for all $i$ and the dynamics reduce to a single-variable ordinary differential equation:\n$$\n\\frac{dx}{dt} = f(x) = \\left(k_b + \\alpha h(x)\\right)\\left(1 - x\\right) - k_d x, \\quad x \\in [0,1].\n$$\n- Steady states $x^\\ast$ satisfy $f(x^\\ast)=0$. A steady state is (linearly) stable if $f'(x^\\ast)  0$ and unstable if $f'(x^\\ast)  0$. The presence of at least two distinct stable steady states in $[0,1]$ defines bistability for this reduced model.\n\nSpatial domain formation:\n- To assess domain formation, integrate the full $L$-dimensional system from an initial condition with a single seed of high H3K27me3 at a specified position $s$ (e.g., $x_s(0)=x_{\\text{seed}}$), with all other positions initialized to a low baseline (e.g., $x_i(0)=x_{\\text{bg}}$ for $i\\neq s$).\n- Evolve the system deterministically until it reaches a numerical steady state. Define the domain size at steady state as the count of positions $i$ with $x_i$ greater than or equal to a specified threshold $\\theta \\in (0,1)$.\n\nScientific basis:\n- Start from core definitions of reader–writer feedback in epigenetics and mass-action kinetics, acknowledging that PRC2 recruitment depends on existing H3K27me3 marks and that demethylases reduce mark levels. Use the Hill function to represent cooperative recruitment, a well-tested phenomenological model in biochemical systems for cooperative binding and reaction rate amplification.\n\nMathematical tasks your program must perform:\n1. Given parameters $(k_b,\\alpha,k_d,K,n)$, compute whether the reduced one-variable system is bistable on $x \\in [0,1]$. This requires finding all roots of $f(x)$ in $[0,1]$ and classifying their stability via the sign of $f'(x)$ computed analytically. Output a boolean indicating whether there are at least two stable steady states.\n2. Given full network parameters $(L,\\lambda,k_b,\\alpha,k_d,K,n,s,x_{\\text{seed}},x_{\\text{bg}},\\theta)$, construct $w_{ij}$ with exponential decay and row normalization, integrate the full network ordinary differential equation to steady state from the seeded initial condition, and compute the integer domain size as $\\#\\{i : x_i \\geq \\theta\\}$.\n\nNumerical details:\n- Use a deterministic integration scheme suitable for smooth ordinary differential equations; ensure $x_i(t)$ remains within $[0,1]$ (e.g., by clamping or appropriate step size). No physical units are required; all rates are dimensionless for this exercise.\n- For bistability analysis, scan the interval $[0,1]$ finely to bracket roots of $f(x)$ and refine them with robust root-finding. Use the analytical derivative $f'(x)$ to classify stability:\n$$\nh(x) = \\frac{x^n}{K^n + x^n}, \\quad h'(x) = \\frac{n K^n x^{n-1}}{\\left(K^n + x^n\\right)^2},\n$$\n$$\nf'(x) = \\alpha h'(x)\\left(1 - x\\right) - \\left(k_b + \\alpha h(x)\\right) - k_d.\n$$\n\nTest suite:\nYour program must evaluate the following four parameter sets, each yielding two outputs: bistability (boolean) and domain size (integer). Use the same threshold $\\theta$ provided per case. Seed index $s$ is the midpoint $s=\\lfloor L/2 \\rfloor$.\n\n- Case 1 (general reader–writer feedback, moderate demethylation; expected to allow bistability and domain formation if feedback is sufficiently strong):\n    - $L=50$, $\\lambda=5$, $k_b=0.01$, $\\alpha=0.60$, $k_d=0.05$, $K=0.20$, $n=4$, $s=25$, $x_{\\text{seed}}=0.80$, $x_{\\text{bg}}=0.00$, $\\theta=0.60$.\n- Case 2 (weak feedback; expected to be monostable with minimal or no domain formation):\n    - $L=50$, $\\lambda=3$, $k_b=0.01$, $\\alpha=0.10$, $k_d=0.05$, $K=0.30$, $n=2$, $s=25$, $x_{\\text{seed}}=0.80$, $x_{\\text{bg}}=0.00$, $\\theta=0.60$.\n- Case 3 (strong feedback, higher demethylation; expected to challenge bistability and limit domain size):\n    - $L=50$, $\\lambda=7$, $k_b=0.02$, $\\alpha=0.80$, $k_d=0.20$, $K=0.25$, $n=3$, $s=25$, $x_{\\text{seed}}=0.80$, $x_{\\text{bg}}=0.00$, $\\theta=0.60$.\n- Case 4 (very strong feedback and long-range spreading; expected to favor bistability and large domains):\n    - $L=50$, $\\lambda=10$, $k_b=0.03$, $\\alpha=0.90$, $k_d=0.05$, $K=0.15$, $n=5$, $s=25$, $x_{\\text{seed}}=0.80$, $x_{\\text{bg}}=0.00$, $\\theta=0.60$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with entries ordered per case as $[\\text{bistability}_1,\\text{domain}_1,\\text{bistability}_2,\\text{domain}_2,\\text{bistability}_3,\\text{domain}_3,\\text{bistability}_4,\\text{domain}_4]$. Booleans must be printed in their programming-language canonical form, and domain sizes must be integers.\n\nImplementation constraints:\n- Language: Python\n- Version: 3.12\n- Libraries: numpy (1.23.5), scipy (1.11.4) only\n- Self-contained: no user input, no external files, no network access\n- Ensure code readability and produce exactly the specified single-line output.", "solution": "The user has provided a problem that requires the implementation and analysis of a mechanistic model for epigenetic spreading. The problem is well-defined, scientifically grounded in the principles of systems biology, and computationally tractable. The validation process confirms that all necessary components are specified and consistent. I will therefore proceed with a complete solution.\n\nThe solution is divided into two main computational tasks as specified:\n1.  **Bistability Analysis**: Determining if the spatially uniform (zero-dimensional) simplification of the model exhibits at least two stable steady states.\n2.  **Spatial Domain Simulation**: Simulating the full one-dimensional model to determine the size of the H3K27me3 domain that forms from a seeded initial condition.\n\n### Part 1: Bistability Analysis of the Uniform-State Reduction\n\nThe problem establishes a model for the dynamics of the H3K27me3 methylation fraction, $x_i(t)$, at each nucleosome position $i$. In a spatially homogeneous system, we assume $x_i(t) = x(t)$ for all $i$. Due to the row-wise normalization of the interaction kernel $w_{ij}$ such that $\\sum_j w_{ij} = 1$, the local reader signal simplifies to $M_i(t) = \\sum_j w_{ij} x_j(t) = x(t) \\sum_j w_{ij} = x(t)$. The full system of $L$ differential equations thus reduces to a single ordinary differential equation (ODE) for the uniform methylation fraction $x(t) \\in [0,1]$:\n$$\n\\frac{dx}{dt} = f(x) = \\left(k_b + \\alpha h(x)\\right)\\left(1 - x\\right) - k_d x\n$$\nwhere $h(x) = \\frac{x^n}{K^n + x^n}$ is the Hill function representing cooperative reader-writer feedback. The parameters $k_b, \\alpha, k_d, K, n$ are the basal methylation rate, maximal feedback strength, demethylation rate, half-saturation constant, and Hill coefficient, respectively.\n\nSteady states, denoted $x^\\ast$, are the roots of the equation $f(x^\\ast) = 0$. The stability of a steady state is determined by the sign of the derivative of $f(x)$ evaluated at that state, $f'(x^\\ast)$. A steady state is linearly stable if $f'(x^\\ast)  0$ and unstable if $f'(x^\\ast)  0$. The system is defined as bistable if there exist at least two distinct stable steady states in the interval $[0,1]$.\n\nThe analytical derivative, $f'(x)$, is given by:\n$$\nf'(x) = \\alpha h'(x)\\left(1 - x\\right) - \\left(k_b + \\alpha h(x)\\right) - k_d\n$$\nwith the derivative of the Hill function being:\n$$\nh'(x) = \\frac{n K^n x^{n-1}}{\\left(K^n + x^n\\right)^2}\n$$\n\nTo implement the bistability analysis, we follow a numerical procedure:\n1.  **Root Finding**: We must find all roots of $f(x)=0$ in the interval $x \\in [0,1]$. A robust method is to first scan the interval with a fine grid (e.g., $1001$ points from $0$ to $1$) to identify subintervals where the sign of $f(x)$ changes. By the Intermediate Value Theorem, a sign change between two points guarantees at least one root lies between them. We then use a numerical root-finding algorithm, such as the Brent-Dekker method (`scipy.optimize.brentq`), on each such subinterval to find the root with high precision.\n2.  **Stability Classification**: For each root $x^\\ast$ found, we compute the value of the analytical derivative $f'(x^\\ast)$.\n3.  **Bistability Verdict**: We count the number of stable steady states (those where $f'(x^\\ast)  0$). If this count is two or greater, the system is declared bistable.\n\n### Part 2: Spatial Domain Formation\n\nThis task involves simulating the full one-dimensional system of $L$ coupled ODEs:\n$$\n\\frac{dx_i}{dt} = \\left(k_b + \\alpha h(M_i)\\right)\\left(1 - x_i\\right) - k_d x_i, \\quad \\text{for } i = 0, 1, \\dots, L-1\n$$\nwhere $M_i = \\sum_{j=0}^{L-1} w_{ij} x_j$.\n\nThe implementation requires several steps:\n1.  **Constructing the Interaction Kernel ($w_{ij}$)**: The kernel $w_{ij}$ describes the influence of nucleosome $j$ on nucleosome $i$. It is defined by an exponential decay with genomic distance, $w_{ij}' = \\exp(-|i-j|/\\lambda)$, where $\\lambda$ is the characteristic spreading length. This unnormalized kernel is then normalized row-wise to satisfy the constraint $\\sum_{j=0}^{L-1} w_{ij} = 1$ for all $i$. In matrix form, we construct a matrix of unnormalized weights and then divide each row by its sum.\n2.  **Setting up the ODE System**: We define a function that computes the vector of derivatives, $\\frac{d\\vec{x}}{dt}$, given the current state vector $\\vec{x}(t)$ and time $t$. This function first computes the reader signal vector $\\vec{M} = W \\vec{x}$ using matrix-vector multiplication, then evaluates the Hill function element-wise for each component of $\\vec{M}$, and finally computes the derivatives for all $x_i$ according to the governing equation. The state variables $x_i$ are constrained to $[0,1]$. The structure of the ODEs ensures that if the system starts in the hypercube $[0,1]^L$, it remains there for all time, as the vector field on the boundary points inwards.\n3.  **Numerical Integration**: We use a robust ODE solver, such as `scipy.integrate.solve_ivp`, to integrate the system over time. The integration starts from a specified initial condition: a single \"seed\" of high methylation, $x_s(0) = x_{\\text{seed}}$, at a central position $s=\\lfloor L/2 \\rfloor$, with all other positions at a low background level, $x_i(0)=x_{\\text{bg}}$ for $i \\neq s$. We integrate for a sufficiently long duration to allow the system to converge to a numerical steady state.\n4.  **Measuring Domain Size**: Once the steady state vector $\\vec{x}_{\\text{ss}}$ is obtained (i.e., the solution at the final integration time), we determine the domain size. This is defined as the number of nucleosome positions $i$ where the methylation level $x_{i, \\text{ss}}$ exceeds a given threshold $\\theta$. This is computed by counting the elements of $\\vec{x}_{\\text{ss}}$ that satisfy $x_{i, \\text{ss}} \\ge \\theta$.\n\nBy implementing these two components, we can process the given test cases and generate the required outputs.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\nfrom scipy.integrate import solve_ivp\n\ndef check_bistability(kb, alpha, kd, K, n):\n    \"\"\"\n    Computes whether the reduced one-variable system is bistable.\n\n    Args:\n        kb (float): Basal methylation rate.\n        alpha (float): Maximal reader-writer amplification strength.\n        kd (float): Demethylation rate.\n        K (float): Half-saturation constant for Hill function.\n        n (float): Hill coefficient.\n\n    Returns:\n        bool: True if the system is bistable, False otherwise.\n    \"\"\"\n    # Define the function f(x) for which roots are the steady states.\n    def f(x):\n        # The Hill function h(x)\n        try:\n            h_x = (x**n) / (K**n + x**n)\n        except (ValueError, ZeroDivisionError):\n            # Handle potential numerical issues at x=0 for n1, although n=1 is a constraint.\n            if x == 0:\n                h_x = 0\n            else:\n                # This case should not be reached with valid inputs\n                h_x = 1.0 if x  K else 0.0\n        return (kb + alpha * h_x) * (1 - x) - kd * x\n\n    # Define the derivative f'(x) to classify stability.\n    def f_prime(x):\n        # The Hill function h(x) and its derivative h'(x)\n        x_n = x**n\n        K_n = K**n\n        denom = K_n + x_n\n        h_x = x_n / denom\n        # Handle x=0 case for n=1 in derivative\n        if x == 0 and n == 1:\n            h_prime_x = n * K_n / (denom**2)\n        elif x == 0 and n  1:\n            h_prime_x = 0\n        else:\n             h_prime_x = (n * K_n * x**(n - 1)) / (denom**2)\n        \n        return alpha * h_prime_x * (1 - x) - (kb + alpha * h_x) - kd\n\n    # Find roots of f(x) in [0, 1] by bracketing and then refining.\n    roots = []\n    grid = np.linspace(0, 1, 1001)\n    y_grid = np.array([f(p) for p in grid])\n\n    for i in range(len(grid) - 1):\n        if np.sign(y_grid[i]) != np.sign(y_grid[i+1]):\n            try:\n                root = brentq(f, grid[i], grid[i+1])\n                # Add root if it's not a duplicate\n                if not any(np.isclose(root, r) for r in roots):\n                    roots.append(root)\n            except ValueError:\n                # brentq raises ValueError if signs are not opposite, but we checked.\n                # This is a safeguard.\n                pass\n\n    # Count number of stable steady states.\n    stable_states_count = 0\n    for r in roots:\n        if f_prime(r)  0:\n            stable_states_count += 1\n\n    return stable_states_count = 2\n\ndef compute_domain_size(L, lam, kb, alpha, kd, K, n, s, x_seed, x_bg, theta):\n    \"\"\"\n    Computes the steady-state domain size for the full spatial model.\n\n    Args:\n        L (int): Number of nucleosomes.\n        lam (float): Spreading length for the interaction kernel.\n        kb, alpha, kd, K, n: Model parameters.\n        s (int): Seed position index.\n        x_seed (float): Methylation fraction at the seed.\n        x_bg (float): Background methylation fraction.\n        theta (float): Threshold for counting a position in the domain.\n\n    Returns:\n        int: The number of positions with methylation = theta at steady state.\n    \"\"\"\n    # 1. Construct the interaction kernel W\n    indices = np.arange(L)\n    dist_matrix = np.abs(indices[:, np.newaxis] - indices)\n    W_unnormalized = np.exp(-dist_matrix / lam)\n    row_sums = W_unnormalized.sum(axis=1)\n    W = W_unnormalized / row_sums[:, np.newaxis]\n\n    # 2. Define the system of ODEs\n    def dxdt(t, y, W_mat, kb_p, alpha_p, kd_p, K_p, n_p):\n        M = W_mat @ y\n        # Clipping M to [0, 1] is a safeguard against numerical integration errors.\n        M_safe = np.clip(M, 0.0, 1.0)\n        K_n = K_p**n_p\n        M_safe_n = M_safe**n_p\n        h_M = M_safe_n / (K_n + M_safe_n)\n        return (kb_p + alpha_p * h_M) * (1 - y) - kd_p * y\n\n    # 3. Set up initial conditions\n    x0 = np.full(L, x_bg, dtype=float)\n    x0[s] = x_seed\n\n    # 4. Integrate the ODEs to steady state\n    t_final = 5000.0\n    t_span = (0, t_final)\n    \n    sol = solve_ivp(\n        fun=dxdt,\n        t_span=t_span,\n        y0=x0,\n        method='RK45',\n        args=(W, kb, alpha, kd, K, n)\n    )\n\n    # 5. Compute domain size from the final state\n    x_ss = sol.y[:, -1]\n    domain_size = int(np.sum(x_ss = theta))\n    \n    return domain_size\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        {'L': 50, 'lambda': 5, 'kb': 0.01, 'alpha': 0.60, 'kd': 0.05, 'K': 0.20, 'n': 4, 's': 25, 'x_seed': 0.80, 'x_bg': 0.00, 'theta': 0.60},\n        # Case 2\n        {'L': 50, 'lambda': 3, 'kb': 0.01, 'alpha': 0.10, 'kd': 0.05, 'K': 0.30, 'n': 2, 's': 25, 'x_seed': 0.80, 'x_bg': 0.00, 'theta': 0.60},\n        # Case 3\n        {'L': 50, 'lambda': 7, 'kb': 0.02, 'alpha': 0.80, 'kd': 0.20, 'K': 0.25, 'n': 3, 's': 25, 'x_seed': 0.80, 'x_bg': 0.00, 'theta': 0.60},\n        # Case 4\n        {'L': 50, 'lambda': 10, 'kb': 0.03, 'alpha': 0.90, 'kd': 0.05, 'K': 0.15, 'n': 5, 's': 25, 'x_seed': 0.80, 'x_bg': 0.00, 'theta': 0.60},\n    ]\n\n    results = []\n    for case in test_cases:\n        bistable = check_bistability(case['kb'], case['alpha'], case['kd'], case['K'], case['n'])\n        domain = compute_domain_size(\n            case['L'], case['lambda'], case['kb'], case['alpha'], case['kd'], \n            case['K'], case['n'], case['s'], case['x_seed'], case['x_bg'], case['theta']\n        )\n        results.extend([bistable, domain])\n\n    # Format output as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "4335592"}, {"introduction": "In systems biomedicine, a critical goal is to move from observing correlations to identifying causal relationships. An observed association between an epigenetic mark and a disease phenotype could arise from a true causal effect, or it could be due to confounding by unmeasured lifestyle or genetic factors. This advanced practice [@problem_id:4335638] challenges you to think like a statistical geneticist, evaluating strategies that use natural genetic variation as an 'instrument' to probe causality. By engaging with the principles of Mendelian Randomization, you will learn to critically assess the evidence needed to claim that an epigenetic modification is a true causal driver of a biological outcome.", "problem": "A research team in systems biomedicine aims to determine whether epigenetic marks causally influence a complex inflammatory phenotype. Let $M$ denote DNA methylation at a promoter CpG site near a cytokine gene, let $H$ denote histone H$3$ lysine $27$ acetylation (H$3$K$27$ac) at the same promoter, and let $Y$ denote a continuous inflammatory biomarker measured in plasma. Observational analyses in a cohort of size $n$ show that $M$ and $H$ are each correlated with $Y$. Let $U$ denote unmeasured factors such as smoking intensity, latent infection burden, and circulating immune cell-type composition. The team considers the following linear structural model as a starting point: \n- $M = \\alpha_{G_M} G_M + \\alpha_{U \\to M} U + \\varepsilon_M$,\n- $H = \\alpha_{G_H} G_H + \\alpha_{U \\to H} U + \\varepsilon_H$,\n- $Y = \\beta_M M + \\beta_H H + \\beta_U U + \\varepsilon_Y$,\nwhere $G_M$ is a cis-methylation quantitative trait locus (cis-meQTL) for $M$ and $G_H$ is a cis-histone quantitative trait locus (cis-hQTL) for $H$, $\\varepsilon_M$, $\\varepsilon_H$, and $\\varepsilon_Y$ are mean-zero errors, and all coefficients are finite constants. Assume that germline genotypes are assigned at conception according to Mendel’s laws and are fixed across the life course, and that the Central Dogma (DNA to RNA to protein) holds as a well-tested organizing principle for molecular flow. The team recognizes that correlation between $M$ or $H$ and $Y$ is not, in general, causation.\n\nFrom first principles of causal inference and genetics, explain why naive regression of $Y$ on $M$ (or $H$) may be biased, and evaluate instrumental-variable strategies that use genetic variants to identify a causal effect of $M$ and $H$ on $Y$. Consider the core instrumental variable assumptions of relevance, independence, and exclusion restriction, and the possibility of horizontal pleiotropy and linkage disequilibrium.\n\nWhich of the following strategies and claims are valid for identifying and diagnosing a causal effect of $M$ and/or $H$ on $Y$ in this setting? Select all that apply.\n\nA. Use a single cis-meQTL $G_M$ as an instrument for $M$ and estimate the causal effect of $M$ on $Y$ using a ratio estimator in a one-sample analysis, after verifying that $G_M$ is strongly associated with $M$ (e.g., $F$-statistic $ 10$), that $G_M$ is not associated with measured proxies for $U$, and that fine-mapping and colocalization indicate the same causal variant drives the $G_M$–$M$ and $G_M$–$Y$ associations; complement with sensitivity analyses for horizontal pleiotropy.\n\nB. Use a trans-expression quantitative trait locus (trans-eQTL) that broadly influences multiple genes as an instrument for $H$, because its widespread regulatory influence both strengthens the instrument and minimizes violation of the exclusion restriction by averaging effects across pathways.\n\nC. Adjust for measured confounders in a multiple regression of $Y$ on $M$ and $H$; with a sufficiently large $n$, any residual unmeasured confounding by $U$ is expected to be negligible, so the coefficient on $M$ can be interpreted as causal without instrumental variables.\n\nD. Implement two-sample Mendelian randomization combining summary statistics: obtain $\\widehat{\\beta}_{YG}$ from a genome-wide association study of $Y$ and $\\widehat{\\beta}_{MG}$ from an epigenome-wide association study of $M$ for the same cis-meQTL $G_M$, require high posterior probability of colocalization between $M$ and $Y$ at the locus, apply Steiger directionality to test $G_M \\to M \\to Y$, and restrict to ancestrally matched samples to mitigate population stratification.\n\nE. Construct a polygenic risk score for $Y$ and use it as an instrument for $M$ to maximize instrument strength; since germline variants are fixed, this will satisfy the independence assumption and thereby identify the causal effect of $M$ on $Y$.\n\nF. Fit a multivariable Mendelian randomization using $G_M$ as an instrument for $M$ and $G_H$ as an instrument for $H$ to estimate the direct effects $\\beta_M$ and $\\beta_H$ simultaneously; diagnose weak instruments with conditional $F$-statistics and assess directional pleiotropy using methods such as multivariable MR-Egger, while verifying that $G_M$ and $G_H$ do not have direct pathways to $Y$ other than through $M$ and $H$, respectively.\n\nAnswer choices are independent; select all that are correct. Do not assume availability of interventional data. Base your reasoning on the structural equations, Mendelian assortment, and the definitions of instrumental variable assumptions, without appealing to any unmentioned shortcut formulas.", "solution": "The problem statement is a valid representation of a causal inference challenge in systems biomedicine. It is scientifically grounded, well-posed, objective, and internally consistent. It poses a non-trivial question regarding the estimation of causal effects from observational data in the presence of unmeasured confounding, a central problem in epidemiology and statistical genetics.\n\n### Analysis of Naive Regression Bias\n\nThe goal is to estimate the causal parameters $\\beta_M$ and $\\beta_H$ from the structural equation for the outcome $Y$:\n$$Y = \\beta_M M + \\beta_H H + \\beta_U U + \\varepsilon_Y$$\nA naive regression of $Y$ on $M$ alone, i.e., fitting $Y \\sim M$, would yield an estimated coefficient that converges to $\\frac{\\text{Cov}(Y, M)}{\\text{Var}(M)}$. Let's analyze this term. Assuming all variables are mean-centered for simplicity:\n$$ \\text{Cov}(Y, M) = \\text{Cov}(\\beta_M M + \\beta_H H + \\beta_U U + \\varepsilon_Y, M) $$\n$$ = \\beta_M \\text{Cov}(M, M) + \\beta_H \\text{Cov}(H, M) + \\beta_U \\text{Cov}(U, M) + \\text{Cov}(\\varepsilon_Y, M) $$\nGiven the structural models for $M$ and $H$:\n$$ M = \\alpha_{G_M} G_M + \\alpha_{U \\to M} U + \\varepsilon_M $$\n$$ H = \\alpha_{G_H} G_H + \\alpha_{U \\to H} U + \\varepsilon_H $$\nThe unmeasured factor $U$ is a common cause of $M$, $H$, and $Y$. From the equations, we can see that $U$ is correlated with $M$ (if $\\alpha_{U \\to M} \\neq 0$) and $H$ (if $\\alpha_{U \\to H} \\neq 0$). Thus, $\\text{Cov}(U, M)$ and $\\text{Cov}(H, M)$ (via the shared dependence on $U$) are generally non-zero.\nSpecifically, $\\text{Cov}(U, M) = \\alpha_{U \\to M} \\text{Var}(U)$ (assuming $U$ is uncorrelated with $G_M$ and $\\varepsilon_M$).\nThe regression coefficient from the naive model is:\n$$ \\frac{\\text{Cov}(Y, M)}{\\text{Var}(M)} = \\beta_M + \\beta_H \\frac{\\text{Cov}(H, M)}{\\text{Var}(M)} + \\beta_U \\frac{\\text{Cov}(U, M)}{\\text{Var}(M)} $$\nThis expression is biased for the true causal effect $\\beta_M$. The bias consists of two terms: one due to confounding from the parallel exposure $H$ which is itself affected by $U$ (path $M \\leftarrow U \\to H \\to Y$), and another due to direct confounding by $U$ (path $M \\leftarrow U \\to Y$). Because $U$ is unmeasured, this bias cannot be removed by simply including $U$ in a regression model. This is a classic example of omitted-variable bias.\n\n### Instrumental Variable (IV) Strategies\n\nTo overcome this bias, we can use genetic variants as instrumental variables. A valid instrument $G$ for an exposure $M$ must satisfy three core assumptions:\n1.  **Relevance (IV1):** $G$ must be associated with $M$. For $G_M$, this means $\\alpha_{G_M} \\neq 0$.\n2.  **Independence (IV2):** $G$ must be independent of all unmeasured confounders $U$ of the $M-Y$ relationship. Due to Mendelian assortment, this is plausible for germline variants with respect to environmental or behavioral confounders, i.e., $\\text{Cov}(G_M, U) = 0$.\n3.  **Exclusion Restriction (IV3):** $G$ affects $Y$ only through $M$. Any path from $G$ to $Y$ must pass through $M$.\n\nA crucial challenge, highlighted by the model, is that the instrument for one exposure might be correlated with the other exposure, violating the exclusion restriction. This is known as horizontal pleiotropy. For example, if we use $G_M$ as an instrument for $M$, the IV estimator for $\\beta_M$ is $\\frac{\\text{Cov}(G_M, Y)}{\\text{Cov}(G_M, M)}$.\n$$ \\text{Cov}(G_M, Y) = \\text{Cov}(G_M, \\beta_M M + \\beta_H H + \\beta_U U) = \\beta_M \\text{Cov}(G_M, M) + \\beta_H \\text{Cov}(G_M, H) $$\nThe IV estimator is $\\beta_M + \\beta_H \\frac{\\text{Cov}(G_M, H)}{\\text{Cov}(G_M, M)}$. It is biased unless $\\beta_H=0$ or $\\text{Cov}(G_M, H)=0$. The term $\\text{Cov}(G_M, H)$ will be non-zero if $G_M$ pleiotropically affects $H$ or is in linkage disequilibrium (LD) with $G_H$.\n\n### Evaluation of Options\n\n**A. Use a single cis-meQTL $G_M$ as an instrument for $M$ ...**\nThis option presents a rigorous workflow for single-instrument Mendelian Randomization (MR). Checking for a strong instrument ($F$-statistic $ 10$) validates the Relevance assumption (IV1) and mitigates weak instrument bias. Checking for association with proxies for $U$ is a necessary (though incomplete) test of the Independence assumption (IV2). Crucially, using fine-mapping and colocalization to confirm a shared causal variant for the $G_M-M$ and $G_M-Y$ associations is a state-of-the-art method to strengthen the evidence for the Exclusion Restriction (IV3) and rule out confounding by LD. Finally, acknowledging the need for sensitivity analyses for residual horizontal pleiotropy demonstrates a methodologically sound and cautious approach.\nVerdict: **Correct**.\n\n**B. Use a trans-expression quantitative trait locus (trans-eQTL) ...**\nThis proposal is fundamentally flawed. A `trans-eQTL` that broadly influences multiple genes is, by definition, highly pleiotropic. The exclusion restriction (IV3) requires the instrument to affect the outcome *solely* through the specified exposure ($H$). An instrument with widespread effects violates this assumption maximally, as it creates numerous pathways to the outcome ($Y$) that do not pass through $H$. The claim that this \"minimizes violation of the exclusion restriction by averaging effects\" is baseless; widespread pleiotropy is the primary threat to the validity of an MR study, not a feature to be desired. Furthermore, `trans` effects are typically much weaker than `cis` effects, so such a variant would likely be a weak instrument, leading to substantial bias.\nVerdict: **Incorrect**.\n\n**C. Adjust for measured confounders in a multiple regression...**\nThis statement demonstrates a fundamental misunderstanding of confounding bias. Confounding by unmeasured variables ($U$) is a source of systematic error (bias), not random error (variance). Increasing the sample size $n$ reduces variance and increases the precision of an estimate, but it does not reduce bias. An estimator subject to confounding is inconsistent; as $n \\to \\infty$, it converges to a wrong value, not the true causal effect. Given that $U$ is defined to include potent factors like smoking and immune cell composition, the residual unmeasured confounding is expected to be substantial, not negligible, regardless of sample size.\nVerdict: **Incorrect**.\n\n**D. Implement two-sample Mendelian randomization combining summary statistics ...**\nThis option describes a sophisticated and valid two-sample MR study design. Using summary statistics ($\\widehat{\\beta}_{YG}$ and $\\widehat{\\beta}_{MG}$) from large-scale GWAS and EWAS is a powerful and efficient approach. The proposed validation steps are critical and appropriate: colocalization addresses confounding by LD at the instrument locus; the Steiger directionality test helps confirm the assumed causal direction ($G_M \\to M \\to Y$) and guards against reverse causation ($G_M \\to Y \\to M$); and restricting to ancestrally matched samples to a limited degree mitigates bias from population stratification. This constitutes a robust, state-of-the-art MR pipeline.\nVerdict: **Correct**.\n\n**E. Construct a polygenic risk score for $Y$ and use it as an instrument for $M$ ...**\nThis strategy is invalid. A polygenic risk score (PRS) for the outcome $Y$ is constructed from a multitude of genetic variants known to be associated with $Y$. To serve as a valid instrument for $M$, this PRS would need to satisfy the exclusion restriction: it must influence $Y$ *only* through $M$. By its very construction, a PRS for $Y$ includes variants that influence $Y$ through myriad biological pathways, most of which will not involve the specific epigenetic mark $M$. This represents a massive violation of the exclusion restriction due to pervasive horizontal pleiotropy. While the variants are germline, satisfying independence from environmental confounders (IV2), the violation of the exclusion restriction (IV3) makes the instrument utterly unsuitable for estimating the causal effect of $M$.\nVerdict: **Incorrect**.\n\n**F. Fit a multivariable Mendelian randomization using $G_M$ as an instrument for $M$ and $G_H$ as an instrument for $H$ ...**\nThis is an advanced and highly appropriate strategy for the given problem. The structural model explicitly includes two exposures, $M$ and $H$, which are likely to be correlated and whose genetic influences may be linked. Multivariable MR (MVMR) is specifically designed to address this scenario. By using instruments for both exposures ($G_M$ and $G_H$), MVMR can simultaneously estimate the direct causal effects of $M$ on $Y$ ($\\beta_M$) and $H$ on $Y$ ($\\beta_H$), while accounting for the correlation between the instruments (e.g., LD) and the correlation between the exposures. The described diagnostics—conditional $F$-statistics for instrument strength and multivariable MR-Egger for pleiotropy—are the correct, state-of-the-art tools for validating an MVMR analysis. This approach correctly addresses the pleiotropic confounding path ($G_M \\to H \\to Y$ or $G_M \\leftrightarrow G_H \\to H \\to Y$) that would bias a standard single-exposure MR.\nVerdict: **Correct**.", "answer": "$$\\boxed{ADF}$$", "id": "4335638"}]}