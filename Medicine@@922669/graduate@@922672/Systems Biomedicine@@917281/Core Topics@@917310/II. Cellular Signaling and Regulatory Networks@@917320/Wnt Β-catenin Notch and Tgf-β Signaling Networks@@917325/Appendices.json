{"hands_on_practices": [{"introduction": "A cornerstone of systems biology is the ability to translate conceptual biological mechanisms into quantitative mathematical models. This practice provides foundational training in this skill by asking you to derive a model of signaling crosstalk from first principles. Specifically, you will formalize the interaction between the Wnt and TGF-$\\beta$ pathways, where nuclear $\\beta$-catenin and Smad proteins form a functional complex, using mass-action kinetics and conservation laws to predict the steady-state outcome [@problem_id:4399624]. This exercise sharpens your ability to construct and analyze equilibrium models, which are essential for understanding how interacting pathways achieve a stable functional state.", "problem": "In epithelial cells, Wingless/Integrated (Wnt) and Transforming Growth Factor beta (TGF-$\\beta$) signals crosstalk via a nuclear transcriptional complex formed by $\\beta$-catenin and Smad proteins. Consider the following coarse-grained, well-mixed nuclear model constructed from first principles: mass-action kinetics, conservation laws, and ordinary differential equation (ODE) balance for production and degradation.\n\nAssume that the pool of nuclear-available $\\beta$-catenin, denoted $X_{\\mathrm{tot}}(t)$, turns over on the timescale of interest according to an ODE with a Wnt-dependent effective production and a first-order loss,\n$$\n\\frac{d X_{\\mathrm{tot}}}{d t} \\;=\\; p_{W}(L_{W}) \\;-\\; \\delta \\, X_{\\mathrm{tot}} ,\n$$\nwhere $L_{W}$ is the Wnt ligand level, $\\delta$ is the effective first-order turnover rate for $\\beta$-catenin moieties (free or complexed), and the Wnt-dependent production is modeled by a saturable increase over a basal rate,\n$$\np_{W}(L_{W}) \\;=\\; s_{B} \\left( 1 \\;+\\; \\lambda_{W} \\,\\frac{L_{W}}{K_{W} + L_{W}} \\right) .\n$$\nAssume that TGF-$\\beta$ ligand $L_{T}$ determines the nuclear Smad availability $S_{\\mathrm{tot}}$ through a saturating activation,\n$$\nS_{\\mathrm{tot}}(L_{T}) \\;=\\; S_{0} \\,\\frac{L_{T}}{K_{T} + L_{T}} .\n$$\nInside the nucleus, $\\beta$-catenin and Smad reversibly bind to form the transcriptional complex $C$ via the reaction $X_{\\mathrm{free}} + S_{\\mathrm{free}} \\rightleftharpoons C$ under rapid equilibrium with dissociation constant $K_{d}$, obeying the mass-action relation\n$$\nK_{d} \\;=\\; \\frac{X_{\\mathrm{free}} \\, S_{\\mathrm{free}}}{C} .\n$$\nConservation gives $X_{\\mathrm{tot}} = X_{\\mathrm{free}} + C$ and $S_{\\mathrm{tot}} = S_{\\mathrm{free}} + C$.\n\nStarting from these definitions and laws, and assuming a steady state for $X_{\\mathrm{tot}}$ on the timescale of binding, derive a closed-form analytic expression for the steady-state nuclear complex concentration $C^{\\ast}$ as a function of $L_{W}$, $L_{T}$, and the model parameters $s_{B}$, $\\lambda_{W}$, $K_{W}$, $\\delta$, $S_{0}$, $K_{T}$, and $K_{d}$. Express your final answer as a single simplified symbolic expression. No numerical evaluation or rounding is required.", "solution": "The user wants to find the steady-state concentration of a nuclear transcriptional complex, $C^{\\ast}$, as a function of the external ligand concentrations $L_W$ and $L_T$. The derivation will proceed in two main stages. First, we will determine the steady-state total concentrations of the constituent proteins, $\\beta$-catenin ($X_{\\mathrm{tot}}$) and Smad ($S_{\\mathrm{tot}}$), as functions of their respective ligand signals. Second, we will solve the reversible binding equilibrium problem to find the concentration of the complex $C$ given these total protein amounts.\n\nStep 1: Determine the steady-state total protein concentrations.\n\nThe total nuclear $\\beta$-catenin concentration, $X_{\\mathrm{tot}}$, is governed by the ordinary differential equation (ODE):\n$$ \\frac{d X_{\\mathrm{tot}}}{d t} = p_{W}(L_{W}) - \\delta \\, X_{\\mathrm{tot}} $$\nThe problem asks for the steady state, which is found by setting the time derivative to zero, $\\frac{d X_{\\mathrm{tot}}}{d t} = 0$. Let $X_{\\mathrm{tot}}^{\\ast}$ denote this steady-state concentration.\n$$ 0 = p_{W}(L_{W}) - \\delta \\, X_{\\mathrm{tot}}^{\\ast} $$\n$$ X_{\\mathrm{tot}}^{\\ast} = \\frac{p_{W}(L_{W})}{\\delta} $$\nThe production rate $p_{W}(L_{W})$ is given by:\n$$ p_{W}(L_{W}) = s_{B} \\left( 1 + \\lambda_{W} \\frac{L_{W}}{K_{W} + L_{W}} \\right) $$\nSubstituting this into the expression for $X_{\\mathrm{tot}}^{\\ast}$:\n$$ X_{\\mathrm{tot}}^{\\ast}(L_W) = \\frac{s_{B}}{\\delta} \\left( 1 + \\lambda_{W} \\frac{L_{W}}{K_{W} + L_{W}} \\right) $$\nThis expression can be written as a single fraction for algebraic convenience:\n$$ X_{\\mathrm{tot}}^{\\ast}(L_W) = \\frac{s_{B}}{\\delta} \\left( \\frac{K_{W} + L_{W} + \\lambda_{W}L_{W}}{K_{W} + L_{W}} \\right) = \\frac{s_{B} \\left( K_{W} + (1+\\lambda_{W})L_{W} \\right)}{\\delta (K_{W} + L_{W})} $$\nThe total nuclear Smad availability, $S_{\\mathrm{tot}}$, is given directly as a function of the ligand $L_T$:\n$$ S_{\\mathrm{tot}}(L_{T}) = S_{0} \\frac{L_{T}}{K_{T} + L_{T}} $$\nSince this expression does not involve a differential equation, it represents the quasi-steady-state availability of Smad as determined by $L_T$.\n\nStep 2: Solve the binding equilibrium problem.\n\nThe formation of the complex $C$ from free $\\beta$-catenin ($X_{\\mathrm{free}}$) and free Smad ($S_{\\mathrm{free}}$) is described by the reversible reaction $X_{\\mathrm{free}} + S_{\\mathrm{free}} \\rightleftharpoons C$. The problem states that this reaction is under rapid equilibrium, meaning the binding and unbinding events are much faster than the changes in the total protein concentrations. The equilibrium is characterized by the dissociation constant $K_d$:\n$$ K_{d} = \\frac{X_{\\mathrm{free}} \\, S_{\\mathrm{free}}}{C} $$\nThe total concentrations are conserved in the binding reaction, leading to the conservation laws:\n$$ X_{\\mathrm{tot}}^{\\ast} = X_{\\mathrm{free}} + C $$\n$$ S_{\\mathrm{tot}} = S_{\\mathrm{free}} + C $$\nFrom these conservation laws, we can express the free concentrations in terms of the total concentrations and the complex concentration $C$:\n$$ X_{\\mathrm{free}} = X_{\\mathrm{tot}}^{\\ast} - C $$\n$$ S_{\\mathrm{free}} = S_{\\mathrm{tot}} - C $$\nSubstituting these into the expression for $K_d$:\n$$ K_{d} = \\frac{(X_{\\mathrm{tot}}^{\\ast} - C)(S_{\\mathrm{tot}} - C)}{C} $$\nThis equation must be solved for $C$. Let $C^{\\ast}$ be the steady-state complex concentration that solves this equation. To simplify notation, we will temporarily drop the superscript star on $X_{\\mathrm{tot}}^{\\ast}$ and $C^{\\ast}$.\n$$ K_{d} C = (X_{\\mathrm{tot}} - C)(S_{\\mathrm{tot}} - C) $$\n$$ K_{d} C = X_{\\mathrm{tot}}S_{\\mathrm{tot}} - X_{\\mathrm{tot}}C - S_{\\mathrm{tot}}C + C^2 $$\nRearranging into a standard quadratic form, $aC^2 + bC + c = 0$:\n$$ C^2 - (X_{\\mathrm{tot}} + S_{\\mathrm{tot}} + K_{d})C + X_{\\mathrm{tot}}S_{\\mathrm{tot}} = 0 $$\nThe solutions for $C$ are given by the quadratic formula:\n$$ C = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$\nSubstituting $a=1$, $b = -(X_{\\mathrm{tot}} + S_{\\mathrm{tot}} + K_{d})$, and $c = X_{\\mathrm{tot}}S_{\\mathrm{tot}}$:\n$$ C = \\frac{(X_{\\mathrm{tot}} + S_{\\mathrm{tot}} + K_{d}) \\pm \\sqrt{(X_{\\mathrm{tot}} + S_{\\mathrm{tot}} + K_{d})^2 - 4 X_{\\mathrm{tot}}S_{\\mathrm{tot}}}}{2} $$\nWe must select the physically meaningful root. The concentration of the complex, $C$, cannot exceed the total concentration of either of its components, i.e., $C \\le X_{\\mathrm{tot}}$ and $C \\le S_{\\mathrm{tot}}$.\n\nLet's examine the solution with the plus sign.\nThe term under the square root is $\\sqrt{(X_{\\mathrm{tot}} + S_{\\mathrm{tot}} + K_{d})^2 - 4 X_{\\mathrm{tot}}S_{\\mathrm{tot}}} = \\sqrt{(X_{\\mathrm{tot}}-S_{\\mathrm{tot}})^2 + 2K_d(X_{\\mathrm{tot}}+S_{\\mathrm{tot}}) + K_d^2}$. This term is always greater than or equal to $|X_{\\mathrm{tot}}-S_{\\mathrm{tot}}|$.\nTherefore, the `plus` solution gives $C \\ge \\frac{1}{2}(X_{\\mathrm{tot}} + S_{\\mathrm{tot}} + K_{d} + |X_{\\mathrm{tot}}-S_{\\mathrm{tot}}|)$.\nIf $X_{\\mathrm{tot}} \\ge S_{\\mathrm{tot}}$, this becomes $C \\ge \\frac{1}{2}(X_{\\mathrm{tot}} + S_{\\mathrm{tot}} + K_{d} + X_{\\mathrm{tot}}-S_{\\mathrm{tot}}) = X_{\\mathrm{tot}} + \\frac{K_d}{2}$. This violates the condition $C \\le X_{\\mathrm{tot}}$.\nIf $S_{\\mathrm{tot}} \\ge X_{\\mathrm{tot}}$, this becomes $C \\ge \\frac{1}{2}(X_{\\mathrm{tot}} + S_{\\mathrm{tot}} + K_{d} + S_{\\mathrm{tot}}-X_{\\mathrm{tot}}) = S_{\\mathrm{tot}} + \\frac{K_d}{2}$. This violates the condition $C \\le S_{\\mathrm{tot}}$.\nThus, the solution with the plus sign is unphysical. We must choose the minus sign.\n\nThe physically correct solution for the steady-state complex concentration $C^{\\ast}$ is:\n$$ C^{\\ast} = \\frac{1}{2} \\left[ (X_{\\mathrm{tot}}^{\\ast} + S_{\\mathrm{tot}} + K_{d}) - \\sqrt{(X_{\\mathrm{tot}}^{\\ast} + S_{\\mathrm{tot}} + K_{d})^2 - 4 X_{\\mathrm{tot}}^{\\ast}S_{\\mathrm{tot}}} \\right] $$\nFinally, we substitute the full expressions for $X_{\\mathrm{tot}}^{\\ast}(L_W)$ and $S_{\\mathrm{tot}}(L_T)$ to obtain the final answer as a single symbolic expression.\nLet $X_{\\mathrm{tot}}^{\\ast} = \\frac{s_{B}}{\\delta} \\left( 1 + \\lambda_{W} \\frac{L_{W}}{K_{W} + L_{W}} \\right)$ and $S_{\\mathrm{tot}} = S_{0} \\frac{L_{T}}{K_{T} + L_{T}}$. The final expression for $C^{\\ast}$ is thus the substitution of these terms into the quadratic solution.", "answer": "$$ \\boxed{ \\frac{1}{2} \\left( \\left[ \\frac{s_{B}}{\\delta} \\left( 1 + \\lambda_{W} \\frac{L_{W}}{K_{W} + L_{W}} \\right) + S_{0} \\frac{L_{T}}{K_{T} + L_{T}} + K_{d} \\right] - \\sqrt{\\left[ \\frac{s_{B}}{\\delta} \\left( 1 + \\lambda_{W} \\frac{L_{W}}{K_{W} + L_{W}} \\right) + S_{0} \\frac{L_{T}}{K_{T} + L_{T}} + K_{d} \\right]^2 - 4 \\left( \\frac{s_{B}}{\\delta} \\left( 1 + \\lambda_{W} \\frac{L_{W}}{K_{W} + L_{W}} \\right) \\right) \\left( S_{0} \\frac{L_{T}}{K_{T} + L_{T}} \\right)} \\right) } $$", "id": "4399624"}, {"introduction": "Signaling pathways do not merely exist in static states; their dynamics are often critical to their function. This exercise shifts our focus from steady-state analysis to the temporal behavior of a signaling network, exploring how feedback architecture gives rise to dynamic patterns like oscillations. You will implement and simulate a classic Goodwin-type oscillator model adapted for the Notch signaling pathway's auto-regulation of the Hes1 gene [@problem_id:4399622]. By numerically integrating the system of ordinary differential equations and analyzing the resulting time series, you will gain hands-on experience with the principles of negative feedback and the computational tools used to predict and classify the dynamic fate of a biological system.", "problem": "Consider a minimal dynamical systems model of Notch pathway transcriptional feedback that captures oscillations in Hairy and Enhancer of Split 1 (Hes1) under Notch signaling. The model balances transcriptional activation by the Notch Intracellular Domain (NICD) and Transforming Growth Factor beta (TGF-β), with auto-repression by Hes1. Assume the Central Dogma of Molecular Biology (DNA to messenger ribonucleic acid (mRNA) to protein) and mass-action kinetics for production and degradation. Let $M(t)$ denote Hes1 mRNA, $P(t)$ denote Hes1 protein, and $R(t)$ denote an effective repressor complex (for example, protein-mediated occupancy of the promoter that reduces transcription), all in arbitrary concentration units. Time $t$ is measured in minutes.\n\nUse the following well-tested modeling choices:\n- Transcription is activated multiplicatively by NICD and TGF-β and repressed by the repressor $R(t)$ via a Hill function derived from equilibrium binding: the transcription rate is proportional to $\\nu \\big/ \\left(1 + R(t)^h\\right)$, where $\\nu = \\alpha_0 \\left(1 + \\sigma_N A_N\\right)\\left(1 + \\sigma_T A_T\\right)$, $\\alpha_0$ is the basal transcription rate, $A_N$ is the dimensionless Notch activation level, $A_T$ is the dimensionless TGF-β activation level, $\\sigma_N$ and $\\sigma_T$ are scaling coefficients, and $h$ is the Hill coefficient representing the cooperativity of repression. All rate constants are nonnegative.\n- Translation and repressor formation are linear, and degradation is first-order for each species.\n\nThe resulting Goodwin-type system is\n$$\n\\frac{dM}{dt} = \\frac{\\nu}{1 + R^h} - k_1 M,\\quad\n\\frac{dP}{dt} = k_s M - k_2 P,\\quad\n\\frac{dR}{dt} = k_p P - k_3 R,\n$$\nwhere $k_1$, $k_2$, $k_3$ are degradation rates in $\\text{min}^{-1}$, $k_s$ and $k_p$ are production rate constants in $\\text{min}^{-1}$, and all variables and parameters are nonnegative.\n\nYour task is to write a complete program that, for each parameter set in the test suite below, integrates the system from small positive initial conditions and determines whether the system exhibits sustained oscillations in $P(t)$ in the long-time regime. An oscillation should be classified as sustained if, after discarding an initial transient, the last portion of the trajectory for $P(t)$ contains at least $3$ distinct local maxima and its amplitude (maximum minus minimum over that portion) exceeds a small threshold. If these two criteria are both met, return the boolean value True for that test case; otherwise return False.\n\nUse the following constants across all simulations unless otherwise specified: initial conditions $M(0) = 0.1$, $P(0) = 0.1$, $R(0) = 0.1$, integration horizon $T_{\\text{end}} = 1000$ minutes, and discard the initial transient of $500$ minutes when assessing oscillations. Use absolute tolerances and relative tolerances sufficiently small to resolve dynamics. Rates must be treated in $\\text{min}^{-1}$.\n\nTest suite parameter sets, each specified as a tuple $\\left(A_N, A_T, h, k_1, k_2, k_3, k_s, k_p, \\alpha_0, \\sigma_N, \\sigma_T\\right)$:\n- Case $1$ (happy path oscillatory): $\\left(1.0,\\, 0.5,\\, 8.0,\\, 0.02,\\, 0.02,\\, 0.02,\\, 0.4,\\, 0.4,\\, 1.0,\\, 1.0,\\, 0.5\\right)$.\n- Case $2$ (boundary, low cooperativity): $\\left(1.0,\\, 0.5,\\, 3.0,\\, 0.02,\\, 0.02,\\, 0.02,\\, 0.4,\\, 0.4,\\, 1.0,\\, 1.0,\\, 0.5\\right)$.\n- Case $3$ (edge case, fast degradation): $\\left(1.0,\\, 0.5,\\, 8.0,\\, 0.08,\\, 0.08,\\, 0.08,\\, 0.4,\\, 0.4,\\, 1.0,\\, 1.0,\\, 0.5\\right)$.\n- Case $4$ (strong activation): $\\left(2.0,\\, 1.0,\\, 8.0,\\, 0.02,\\, 0.02,\\, 0.02,\\, 0.4,\\, 0.4,\\, 1.0,\\, 1.0,\\, 0.5\\right)$.\n\nYour program should produce a single line of output containing the results for the four cases as a comma-separated list enclosed in square brackets (for example, $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4\\right]$), where each $\\text{result}_i$ is a boolean indicating whether sustained oscillations are present according to the criteria above. No additional output should be produced.", "solution": "The user-provided problem statement has been analyzed and is deemed valid. It is scientifically grounded in the principles of biochemical kinetics and systems biology, well-posed as a numerical integration and analysis task, and sufficiently complete and objective to permit a unique solution. The model is a standard Goodwin-type oscillator, which is a canonical representation of genetic negative feedback loops. The parameters and initial conditions are clearly specified. The only minor ambiguity is the definition of a \"small threshold\" for oscillation amplitude. For this analysis, a physically reasonable threshold of $0.1$ concentration units is chosen to distinguish sustained oscillations from numerical noise or rapid decay to a fixed point.\n\nThe problem requires the numerical integration of a system of three coupled nonlinear ordinary differential equations (ODEs) that model the dynamics of Hes1 mRNA, $M(t)$, Hes1 protein, $P(t)$, and an effective repressor complex, $R(t)$. The system is given by:\n$$\n\\frac{dM}{dt} = \\frac{\\nu}{1 + R^h} - k_1 M\n$$\n$$\n\\frac{dP}{dt} = k_s M - k_2 P\n$$\n$$\n\\frac{dR}{dt} = k_p P - k_3 R\n$$\nThe state variables $M$, $P$, and $R$ represent concentrations and are functions of time $t$. The parameters are as follows: $k_1$, $k_2$, $k_3$ are first-order degradation rate constants; $k_s$ and $k_p$ are production rate constants; and $h$ is the Hill coefficient for repression. The term $\\nu$ represents the maximal transcription rate, modulated by external signals, and is defined as:\n$$\n\\nu = \\alpha_0 (1 + \\sigma_N A_N)(1 + \\sigma_T A_T)\n$$\nwhere $\\alpha_0$ is the basal transcription rate, $A_N$ and $A_T$ are dimensionless activation levels for Notch and TGF-$\\beta$ signaling, respectively, and $\\sigma_N$ and $\\sigma_T$ are corresponding scaling coefficients.\n\nThe solution methodology involves the following steps for each provided parameter set:\n1.  **Parameter Setup**: The parameters from the test case tuple $\\left(A_N, A_T, h, k_1, k_2, k_3, k_s, k_p, \\alpha_0, \\sigma_N, \\sigma_T\\right)$ are assigned, and the composite parameter $\\nu$ is calculated.\n\n2.  **Numerical Integration**: The system of ODEs is integrated numerically over the time interval $t \\in [0, 1000]$ minutes, starting from the initial conditions $M(0) = 0.1$, $P(0) = 0.1$, and $R(0) = 0.1$. A high-quality adaptive step-size solver, specifically `scipy.integrate.solve_ivp` from the SciPy library, is employed. A dense output is requested to obtain a finely resolved time series for the state variables, which is essential for accurately identifying local extrema. High-precision relative and absolute tolerances (e.g., $10^{-9}$) are used to ensure the accuracy of the numerical solution.\n\n3.  **Transient Discard**: As per the problem specification, the initial transient phase of the simulation is discarded. The analysis is performed only on the time series data for $t \\in [500, 1000]$ minutes. This ensures that the classification of behavior as oscillatory or stable is based on the long-term, asymptotic dynamics of the system, not on its initial response.\n\n4.  **Oscillation Detection**: The trajectory of the Hes1 protein, $P(t)$, in the post-transient window ($t \\ge 500$) is analyzed against two specific criteria to determine if sustained oscillations are present.\n    *   **Amplitude Criterion**: The amplitude of the oscillation is calculated as the difference between the maximum and minimum values of $P(t)$ within the analysis window. This amplitude must exceed a predefined threshold, which is set to $0.1$ concentration units. This criterion ensures that the observed fluctuations are significant and not artifacts of numerical error around a stable steady state. If $\\left( \\max_{t \\ge 500} P(t) - \\min_{t \\ge 500} P(t) \\right) > 0.1$, this condition is met.\n    *   **Peak Count Criterion**: The number of local maxima (peaks) in the $P(t)$ trajectory within the analysis window is counted. A point $P(t_i)$ is considered a local maximum if it is strictly greater than its immediate neighbors, i.e., $P(t_{i-1}) < P(t_i) > P(t_{i+1})$. The problem requires at least $3$ distinct local maxima to classify the behavior as a sustained oscillation. This ensures the system is undergoing multiple cycles and has not just exhibited a single overshoot before settling.\n\n5.  **Classification**: For each parameter set, the final output is a boolean value. It is `True` if and only if both the amplitude criterion and the peak count criterion are satisfied. Otherwise, it is `False`. The results for all four test cases are compiled into a single list.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Integrates the Hes1 oscillator model and detects sustained oscillations\n    for a suite of test case parameters.\n    \"\"\"\n    \n    # Define common constants for the simulation\n    y0 = np.array([0.1, 0.1, 0.1])  # Initial conditions [M(0), P(0), R(0)]\n    t_span = [0, 1000]             # Integration time horizon in minutes\n    transient_time = 500           # Time to discard for transient behavior\n    amp_threshold = 0.1            # Amplitude threshold for oscillation\n    min_peaks = 3                  # Minimum number of peaks for sustained oscillation\n\n    # Test suite parameter sets:\n    # (A_N, A_T, h, k_1, k_2, k_3, k_s, k_p, alpha_0, sigma_N, sigma_T)\n    test_cases = [\n        # Case 1: happy path oscillatory\n        (1.0, 0.5, 8.0, 0.02, 0.02, 0.02, 0.4, 0.4, 1.0, 1.0, 0.5),\n        # Case 2: boundary, low cooperativity\n        (1.0, 0.5, 3.0, 0.02, 0.02, 0.02, 0.4, 0.4, 1.0, 1.0, 0.5),\n        # Case 3: edge case, fast degradation\n        (1.0, 0.5, 8.0, 0.08, 0.08, 0.08, 0.4, 0.4, 1.0, 1.0, 0.5),\n        # Case 4: strong activation\n        (2.0, 1.0, 8.0, 0.02, 0.02, 0.02, 0.4, 0.4, 1.0, 1.0, 0.5),\n    ]\n\n    def hes1_model(t, y, nu, h, k1, k2, k3, ks, kp):\n        \"\"\"\n        Defines the ODE system for the Hes1 oscillator.\n        y = [M, P, R]\n        \"\"\"\n        M, P, R = y\n        dM_dt = nu / (1 + R**h) - k1 * M\n        dP_dt = ks * M - k2 * P\n        dR_dt = kp * P - k3 * R\n        return [dM_dt, dP_dt, dR_dt]\n\n    results = []\n    \n    # Generate time points for evaluation to ensure dense output\n    t_eval = np.linspace(t_span[0], t_span[1], 2000)\n\n    for case in test_cases:\n        A_N, A_T, h, k1, k2, k3, ks, kp, alpha_0, sigma_N, sigma_T = case\n        \n        # Calculate the composite transcription rate nu\n        nu = alpha_0 * (1 + sigma_N * A_N) * (1 + sigma_T * A_T)\n        \n        # Package arguments for the ODE solver\n        args = (nu, h, k1, k2, k3, ks, kp)\n        \n        # Integrate the ODE system\n        sol = solve_ivp(\n            hes1_model, \n            t_span, \n            y0, \n            method='RK45', \n            t_eval=t_eval, \n            args=args,\n            rtol=1e-9, \n            atol=1e-9\n        )\n        \n        # Extract time and P(t) solution\n        t_sol = sol.t\n        P_sol = sol.y[1]\n        \n        # Find the index where the analysis window starts\n        transient_idx = np.searchsorted(t_sol, transient_time, side='left')\n        \n        # Get the post-transient part of the P trajectory\n        P_analysis = P_sol[transient_idx:]\n        \n        is_oscillatory = False\n        if P_analysis.size > 2: # Need at least 3 points to find a peak\n            # 1. Amplitude criterion\n            amplitude = np.max(P_analysis) - np.min(P_analysis)\n            amplitude_criterion_met = amplitude > amp_threshold\n            \n            # 2. Peak count criterion\n            peak_count = 0\n            for i in range(1, len(P_analysis) - 1):\n                if P_analysis[i] > P_analysis[i-1] and P_analysis[i] > P_analysis[i+1]:\n                    peak_count += 1\n            peaks_criterion_met = peak_count >= min_peaks\n            \n            # Both criteria must be met\n            if amplitude_criterion_met and peaks_criterion_met:\n                is_oscillatory = True\n        \n        results.append(is_oscillatory)\n\n    # Format and print the final output exactly as required\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4399622"}, {"introduction": "While forward modeling predicts system outputs from known parameters, a central challenge in systems biomedicine is the 'inverse problem': inferring the hidden internal states of a cell from measurable experimental data. This final practice bridges the gap between theoretical models and data-driven discovery. You will apply a Bayesian statistical framework to infer the unobserved activities of the Wnt, Notch, and TGF-$\\beta$ pathways based on a simulated gene expression dataset [@problem_id:4399635]. This exercise introduces the powerful technique of Maximum A Posteriori (MAP) estimation, which manifests here as regularized regression, providing a robust method for analyzing noisy and complex biological measurements.", "problem": "You are asked to perform data-driven inference of pathway activity for three signaling pathways: Wnt/β-catenin signaling, Notch signaling, and Transforming Growth Factor beta (TGF-β) signaling. In systems biomedicine, under a small-signal approximation and steady-state assumption, the transcriptional response of downstream target genes is often modeled as a linear superposition of pathway activities. Formally, assume that the measured expression vector of $n$ target genes, denoted by $\\mathbf{y} \\in \\mathbb{R}^n$, is generated by\n$$\n\\mathbf{y} = \\mathbf{b} + \\mathbf{S}\\mathbf{a} + \\boldsymbol{\\varepsilon},\n$$\nwhere $\\mathbf{b} \\in \\mathbb{R}^n$ is a baseline expression vector, $\\mathbf{S} \\in \\mathbb{R}^{n \\times p}$ is a known signature (sensitivity) matrix encoding the effect of each pathway on each gene, $\\mathbf{a} \\in \\mathbb{R}^p$ is the unknown pathway activity vector for $p$ pathways, and $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I}_n)$ represents independent Gaussian measurement noise with variance $\\sigma^2$. Suppose a prior belief that activities are concentrated near $0$ is modeled by a zero-mean Gaussian prior $\\mathbf{a} \\sim \\mathcal{N}(\\mathbf{0}, \\tau^2 \\mathbf{I}_p)$ with variance $\\tau^2$.\n\nStarting from the Central Dogma of Molecular Biology and the linearization of gene regulatory responses near steady state, use Bayesian inference with the Gaussian likelihood and Gaussian prior to derive the Maximum A Posteriori (MAP) estimator for $\\mathbf{a}$ and implement it algorithmically without relying on any pre-derived shortcut formulas. The derivation must proceed from first principles of probability and optimization. Then, for each test case below, compute the MAP estimate of the pathway activities. All activities are dimensionless and must be reported as floats rounded to $6$ decimals.\n\nTest suite of parameter values:\n\n- Case $1$ (well-conditioned, additive activation):\n  - $n = 6$, $p = 3$\n  - $\\mathbf{S} = \\begin{bmatrix}\n  0.8 & 0.1 & 0.2 \\\\\n  0.6 & 0.2 & 0.1 \\\\\n  0.1 & 0.7 & 0.3 \\\\\n  0.2 & 0.6 & 0.4 \\\\\n  0.0 & 0.1 & 0.9 \\\\\n  0.3 & 0.2 & 0.8\n  \\end{bmatrix}$\n  - $\\mathbf{b} = \\begin{bmatrix}0.0\\\\0.0\\\\0.0\\\\0.0\\\\0.0\\\\0.0\\end{bmatrix}$\n  - $\\mathbf{y} = \\begin{bmatrix}0.99\\\\0.77\\\\0.66\\\\0.78\\\\0.68\\\\0.96\\end{bmatrix}$\n  - $\\sigma^2 = 0.01$, $\\tau^2 = 10.0$\n\n- Case $2$ (strong collinearity between Wnt/β-catenin and Notch signatures):\n  - $n = 4$, $p = 3$\n  - $\\mathbf{S} = \\begin{bmatrix}\n  0.5 & 0.49 & 0.1 \\\\\n  0.4 & 0.41 & 0.2 \\\\\n  0.6 & 0.6 & 0.3 \\\\\n  0.55 & 0.54 & 0.2\n  \\end{bmatrix}$\n  - $\\mathbf{b} = \\begin{bmatrix}0.0\\\\0.0\\\\0.0\\\\0.0\\end{bmatrix}$\n  - $\\mathbf{y} = \\begin{bmatrix}0.812\\\\0.688\\\\1.02\\\\0.912\\end{bmatrix}$\n  - $\\sigma^2 = 0.1$, $\\tau^2 = 1.0$\n\n- Case $3$ (mixed activation and repression in signatures):\n  - $n = 5$, $p = 3$\n  - $\\mathbf{S} = \\begin{bmatrix}\n  0.7 & -0.2 & 0.1 \\\\\n  0.2 & 0.5 & -0.3 \\\\\n  -0.1 & 0.6 & 0.4 \\\\\n  0.3 & -0.4 & 0.7 \\\\\n  -0.2 & 0.3 & 0.8\n  \\end{bmatrix}$\n  - $\\mathbf{b} = \\begin{bmatrix}0.0\\\\0.0\\\\0.0\\\\0.0\\\\0.0\\end{bmatrix}$\n  - $\\mathbf{y} = \\begin{bmatrix}0.43\\\\0.05\\\\0.54\\\\0.65\\\\0.72\\end{bmatrix}$\n  - $\\sigma^2 = 0.02$, $\\tau^2 = 2.0$\n\n- Case $4$ (underdetermined system with $n < p$):\n  - $n = 2$, $p = 3$\n  - $\\mathbf{S} = \\begin{bmatrix}\n  0.5 & 0.2 & 0.3 \\\\\n  0.1 & 0.3 & 0.6\n  \\end{bmatrix}$\n  - $\\mathbf{b} = \\begin{bmatrix}0.0\\\\0.0\\end{bmatrix}$\n  - $\\mathbf{y} = \\begin{bmatrix}0.49\\\\0.55\\end{bmatrix}$\n  - $\\sigma^2 = 0.05$, $\\tau^2 = 0.5$\n\nYour program must compute the MAP estimate $\\widehat{\\mathbf{a}}$ for each case and return the results as a single line of output containing a list of lists, where each inner list corresponds to one case and contains the three pathway activities in the fixed order $\\left[\\text{Wnt/}\\beta\\text{-catenin}, \\text{Notch}, \\text{TGF-}\\beta\\right]$, each rounded to $6$ decimals. For example, the output format should be like $\\left[[a_{11},a_{12},a_{13}],[a_{21},a_{22},a_{23}],\\ldots\\right]$ with every $a_{ij}$ printed as a float rounded to $6$ decimals.", "solution": "The problem is valid. It is scientifically grounded in the principles of systems biomedicine, specifically the modeling of gene expression as a linear response to signaling pathway activities. The problem is well-posed, objective, and provides all necessary information to derive and compute the Maximum A Posteriori (MAP) estimate for the pathway activities.\n\nThe solution proceeds by deriving the MAP estimator from first principles of Bayesian inference. The model for the observed gene expression vector $\\mathbf{y} \\in \\mathbb{R}^n$ is given by\n$$\n\\mathbf{y} = \\mathbf{b} + \\mathbf{S}\\mathbf{a} + \\boldsymbol{\\varepsilon}\n$$\nwhere $\\mathbf{b} \\in \\mathbb{R}^n$ is the baseline expression, $\\mathbf{S} \\in \\mathbb{R}^{n \\times p}$ is the signature matrix, $\\mathbf{a} \\in \\mathbb{R}^p$ is the unknown pathway activity vector, and $\\boldsymbol{\\varepsilon} \\in \\mathbb{R}^n$ is the measurement noise. We are given the probabilistic models for the noise and the pathway activities:\n$1$. The measurement noise follows an independent Gaussian distribution: $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I}_n)$.\n$2$. The prior belief on pathway activities is a zero-mean Gaussian: $\\mathbf{a} \\sim \\mathcal{N}(\\mathbf{0}, \\tau^2 \\mathbf{I}_p)$.\n\nOur goal is to find the MAP estimate of $\\mathbf{a}$, denoted $\\widehat{\\mathbf{a}}_{\\text{MAP}}$, which is the value of $\\mathbf{a}$ that maximizes the posterior probability density $p(\\mathbf{a} | \\mathbf{y})$. According to Bayes' theorem, the posterior is proportional to the product of the likelihood and the prior:\n$$\np(\\mathbf{a} | \\mathbf{y}) \\propto p(\\mathbf{y} | \\mathbf{a}) p(\\mathbf{a})\n$$\nMaximizing the posterior is equivalent to maximizing its logarithm, as the logarithm is a monotonically increasing function. The log-posterior is:\n$$\n\\ln p(\\mathbf{a} | \\mathbf{y}) = \\ln p(\\mathbf{y} | \\mathbf{a}) + \\ln p(\\mathbf{a}) + \\text{constant}\n$$\nWe derive the expressions for the log-likelihood and log-prior.\n\nFirst, we define the likelihood $p(\\mathbf{y} | \\mathbf{a})$. From the model equation, for a given $\\mathbf{a}$, the observation vector $\\mathbf{y}$ is a sum of a constant vector $\\mathbf{b} + \\mathbf{S}\\mathbf{a}$ and a random noise vector $\\boldsymbol{\\varepsilon}$. Thus, $\\mathbf{y}$ is also a Gaussian random vector.\nThe mean of $\\mathbf{y}$ given $\\mathbf{a}$ is $E[\\mathbf{y} | \\mathbf{a}] = E[\\mathbf{b} + \\mathbf{S}\\mathbf{a} + \\boldsymbol{\\varepsilon}] = \\mathbf{b} + \\mathbf{S}\\mathbf{a}$.\nThe covariance of $\\mathbf{y}$ given $\\mathbf{a}$ is $\\text{Cov}(\\mathbf{y} | \\mathbf{a}) = \\text{Cov}(\\mathbf{b} + \\mathbf{S}\\mathbf{a} + \\boldsymbol{\\varepsilon}) = \\text{Cov}(\\boldsymbol{\\varepsilon}) = \\sigma^2 \\mathbf{I}_n$.\nSo, the likelihood is given by the multivariate Gaussian PDF:\n$$\np(\\mathbf{y} | \\mathbf{a}) = \\mathcal{N}(\\mathbf{y}; \\mathbf{b} + \\mathbf{S}\\mathbf{a}, \\sigma^2\\mathbf{I}_n) = \\frac{1}{(2\\pi\\sigma^2)^{n/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} (\\mathbf{y} - (\\mathbf{b} + \\mathbf{S}\\mathbf{a}))^T (\\mathbf{y} - (\\mathbf{b} + \\mathbf{S}\\mathbf{a}))\\right)\n$$\nThe log-likelihood, ignoring terms not dependent on $\\mathbf{a}$, is:\n$$\n\\ln p(\\mathbf{y} | \\mathbf{a}) = -\\frac{1}{2\\sigma^2} \\|\\mathbf{y} - \\mathbf{b} - \\mathbf{S}\\mathbf{a}\\|_2^2 + \\text{constant}\n$$\n\nNext, we define the prior $p(\\mathbf{a})$. We are given that $\\mathbf{a} \\sim \\mathcal{N}(\\mathbf{0}, \\tau^2 \\mathbf{I}_p)$. The PDF is:\n$$\np(\\mathbf{a}) = \\mathcal{N}(\\mathbf{a}; \\mathbf{0}, \\tau^2\\mathbf{I}_p) = \\frac{1}{(2\\pi\\tau^2)^{p/2}} \\exp\\left(-\\frac{1}{2\\tau^2} \\mathbf{a}^T \\mathbf{a}\\right)\n$$\nThe log-prior, again ignoring constant terms, is:\n$$\n\\ln p(\\mathbf{a}) = -\\frac{1}{2\\tau^2} \\|\\mathbf{a}\\|_2^2 + \\text{constant}\n$$\n\nCombining the log-likelihood and log-prior, the log-posterior to be maximized is:\n$$\n\\widehat{\\mathbf{a}}_{\\text{MAP}} = \\arg\\max_{\\mathbf{a}} \\left( -\\frac{1}{2\\sigma^2} \\|\\mathbf{y} - \\mathbf{b} - \\mathbf{S}\\mathbf{a}\\|_2^2 - \\frac{1}{2\\tau^2} \\|\\mathbf{a}\\|_2^2 \\right)\n$$\nMaximizing this expression is equivalent to minimizing its negative:\n$$\n\\widehat{\\mathbf{a}}_{\\text{MAP}} = \\arg\\min_{\\mathbf{a}} J(\\mathbf{a}) = \\arg\\min_{\\mathbf{a}} \\left( \\frac{1}{2\\sigma^2} \\|\\mathbf{y} - \\mathbf{b} - \\mathbf{S}\\mathbf{a}\\|_2^2 + \\frac{1}{2\\tau^2} \\|\\mathbf{a}\\|_2^2 \\right)\n$$\nLet's define a modified observation vector $\\mathbf{y}' = \\mathbf{y} - \\mathbf{b}$. The objective function is:\n$$\nJ(\\mathbf{a}) = \\frac{1}{2\\sigma^2} \\|\\mathbf{y}' - \\mathbf{S}\\mathbf{a}\\|_2^2 + \\frac{1}{2\\tau^2} \\|\\mathbf{a}\\|_2^2\n$$\nTo find the minimum, we compute the gradient of $J(\\mathbf{a})$ with respect to $\\mathbf{a}$ and set it to the zero vector.\n$$\n\\nabla_{\\mathbf{a}} J(\\mathbfa) = \\nabla_{\\mathbf{a}} \\left[ \\frac{1}{2\\sigma^2} (\\mathbf{y}' - \\mathbf{S}\\mathbf{a})^T (\\mathbf{y}' - \\mathbf{S}\\mathbf{a}) + \\frac{1}{2\\tau^2} \\mathbf{a}^T \\mathbf{a} \\right]\n$$\nUsing the matrix calculus identities $\\nabla_{\\mathbf{x}} (\\mathbf{c} - \\mathbf{A}\\mathbf{x})^T(\\mathbf{c} - \\mathbf{A}\\mathbf{x}) = -2\\mathbf{A}^T(\\mathbf{c} - \\mathbf{A}\\mathbf{x})$ and $\\nabla_{\\mathbf{x}} (\\mathbf{x}^T\\mathbf{B}\\mathbf{x}) = 2\\mathbf{B}\\mathbf{x}$ for symmetric $\\mathbf{B}$:\n$$\n\\nabla_{\\mathbf{a}} J(\\mathbf{a}) = \\frac{1}{2\\sigma^2} (-2\\mathbf{S}^T(\\mathbf{y}' - \\mathbf{S}\\mathbf{a})) + \\frac{1}{2\\tau^2} (2\\mathbf{a}) = -\\frac{1}{\\sigma^2} \\mathbf{S}^T\\mathbf{y}' + \\frac{1}{\\sigma^2} \\mathbf{S}^T\\mathbf{S}\\mathbf{a} + \\frac{1}{\\tau^2} \\mathbf{a}\n$$\nSetting the gradient to $\\mathbf{0}$:\n$$\n\\left(\\frac{1}{\\sigma^2} \\mathbf{S}^T\\mathbf{S} + \\frac{1}{\\tau^2} \\mathbf{I}_p\\right) \\mathbf{a} = \\frac{1}{\\sigma^2} \\mathbf{S}^T\\mathbf{y}'\n$$\nMultiplying by $\\sigma^2$ yields:\n$$\n\\left(\\mathbf{S}^T\\mathbf{S} + \\frac{\\sigma^2}{\\tau^2} \\mathbf{I}_p\\right) \\mathbf{a} = \\mathbf{S}^T\\mathbf{y}'\n$$\nThe matrix $\\mathbf{S}^T\\mathbf{S}$ is positive semi-definite. Since $\\sigma^2 > 0$ and $\\tau^2 > 0$, the ratio $\\lambda = \\sigma^2/\\tau^2 > 0$. Therefore, the matrix $\\mathbf{S}^T\\mathbf{S} + \\lambda\\mathbf{I}_p$ is positive definite and thus invertible. This guarantees a unique solution for $\\mathbf{a}$. We solve for $\\mathbf{a}$ to get the MAP estimator:\n$$\n\\widehat{\\mathbf{a}}_{\\text{MAP}} = \\left(\\mathbf{S}^T\\mathbf{S} + \\frac{\\sigma^2}{\\tau^2} \\mathbf{I}_p\\right)^{-1} \\mathbf{S}^T (\\mathbf{y} - \\mathbf{b})\n$$\nThis result is also known as Tikhonov-regularized least squares or Ridge Regression, where the regularization parameter is determined by the ratio of noise variance to prior variance. This framework correctly handles all provided test cases, including the ill-conditioned (Case $2$) and underdetermined (Case $4$) scenarios, by ensuring the problem remains well-posed.\n\nThe algorithm is implemented by constructing the matrices and vectors from the given parameters for each case and solving the resulting system of linear equations. Specifically, we solve the system $A\\mathbf{x}=\\mathbf{v}$ where $A = \\mathbf{S}^T\\mathbf{S} + (\\sigma^2/\\tau^2)\\mathbf{I}_p$, $\\mathbf{x} = \\mathbf{a}$, and $\\mathbf{v} = \\mathbf{S}^T(\\mathbf{y} - \\mathbf{b})$. Using a linear solver is more numerically stable than computing the matrix inverse directly.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"S\": np.array([\n                [0.8, 0.1, 0.2],\n                [0.6, 0.2, 0.1],\n                [0.1, 0.7, 0.3],\n                [0.2, 0.6, 0.4],\n                [0.0, 0.1, 0.9],\n                [0.3, 0.2, 0.8]\n            ]),\n            \"b\": np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n            \"y\": np.array([0.99, 0.77, 0.66, 0.78, 0.68, 0.96]),\n            \"sigma_sq\": 0.01,\n            \"tau_sq\": 10.0\n        },\n        {\n            \"S\": np.array([\n                [0.5, 0.49, 0.1],\n                [0.4, 0.41, 0.2],\n                [0.6, 0.6, 0.3],\n                [0.55, 0.54, 0.2]\n            ]),\n            \"b\": np.array([0.0, 0.0, 0.0, 0.0]),\n            \"y\": np.array([0.812, 0.688, 1.02, 0.912]),\n            \"sigma_sq\": 0.1,\n            \"tau_sq\": 1.0\n        },\n        {\n            \"S\": np.array([\n                [0.7, -0.2, 0.1],\n                [0.2, 0.5, -0.3],\n                [-0.1, 0.6, 0.4],\n                [0.3, -0.4, 0.7],\n                [-0.2, 0.3, 0.8]\n            ]),\n            \"b\": np.array([0.0, 0.0, 0.0, 0.0, 0.0]),\n            \"y\": np.array([0.43, 0.05, 0.54, 0.65, 0.72]),\n            \"sigma_sq\": 0.02,\n            \"tau_sq\": 2.0\n        },\n        {\n            \"S\": np.array([\n                [0.5, 0.2, 0.3],\n                [0.1, 0.3, 0.6]\n            ]),\n            \"b\": np.array([0.0, 0.0]),\n            \"y\": np.array([0.49, 0.55]),\n            \"sigma_sq\": 0.05,\n            \"tau_sq\": 0.5\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        # Extract parameters for the current case\n        S = case[\"S\"]\n        b = case[\"b\"]\n        y = case[\"y\"]\n        sigma_sq = case[\"sigma_sq\"]\n        tau_sq = case[\"tau_sq\"]\n\n        # Number of pathways (columns of S)\n        p = S.shape[1]\n\n        # Shift the observation vector by the baseline\n        y_prime = y - b\n        \n        # Calculate the regularization parameter lambda\n        lambda_reg = sigma_sq / tau_sq\n        \n        # Construct the matrix A = (S^T S + lambda * I)\n        A = S.T @ S + lambda_reg * np.identity(p)\n        \n        # Construct the vector v = S^T (y - b)\n        v = S.T @ y_prime\n        \n        # Solve the linear system A * a = v for a.\n        # This is more numerically stable than computing the inverse of A.\n        a_map = np.linalg.solve(A, v)\n        all_results.append(a_map)\n\n    # Format the final output string according to the problem specification.\n    # The result is a list of lists, with each number as a float rounded to 6 decimals.\n    result_str_parts = []\n    for a_map in all_results:\n        # Format each list of results to \"[val1,val2,...]\" with 6 decimal places\n        inner_list_str = f\"[{','.join([f'{x:.6f}' for x in a_map])}]\"\n        result_str_parts.append(inner_list_str)\n\n    final_output = f\"[{','.join(result_str_parts)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "4399635"}]}