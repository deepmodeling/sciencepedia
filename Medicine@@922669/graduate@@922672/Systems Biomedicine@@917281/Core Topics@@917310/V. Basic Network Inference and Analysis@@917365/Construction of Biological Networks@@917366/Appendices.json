{"hands_on_practices": [{"introduction": "A biological network is not a single entity but a consensus model synthesized from numerous, often noisy, experimental sources. This exercise provides hands-on practice in one of the most fundamental tasks in systems biology: integrating heterogeneous evidence into a unified, probabilistic network. You will apply basic probability theory to combine confidence scores from different experimental techniques and learn how to represent both directed and undirected interactions within a single, computationally tractable adjacency matrix [@problem_id:4330440].", "problem": "You are constructing a probabilistic, directed protein interaction network for four proteins $P_1$, $P_2$, $P_3$, and $P_4$ using multiple heterogeneous evidence sources. In systems biomedicine, an edge confidence is interpreted as the probability that the reported interaction is true, and directionality is encoded when the biological mechanism implies causality (for example, kinase to substrate or transcription factor to target gene). The following evidence codes and their base reliabilities are provided, each interpreted as an independent probability of truth when considered alone: Yeast Two-Hybrid (Y2H): $0.35$, Co-Immunoprecipitation (Co-IP): $0.65$, Affinity Purification Mass Spectrometry (AP-MS): $0.55$, Chromatin Immunoprecipitation sequencing (ChIP-seq): $0.75$, Curated literature (CUR): $0.90$, Phosphorylation motif (PM): $0.30$. The observed interactions are:\n- $P_1$ and $P_2$ are reported by Y2H and AP-MS, with no asserted directionality.\n- $P_1$ regulates $P_3$ with CUR support, with direction $P_1 \\rightarrow P_3$.\n- $P_2$ and $P_3$ are reported by Co-IP, with no asserted directionality.\n- $P_3$ regulates $P_4$ supported by ChIP-seq, with direction $P_3 \\rightarrow P_4$.\n- $P_4$ and $P_1$ are reported by AP-MS and Co-IP, with no asserted directionality.\n- $P_2$ phosphorylates $P_4$ supported by PM, with direction $P_2 \\rightarrow P_4$.\nDesign a representation that encodes edge confidence and directionality where available using a principled approach grounded in fundamental probability and graph-theoretic definitions appropriate for network construction in systems biomedicine. Then construct the directed, edge-weighted adjacency matrix $A \\in \\mathbb{R}^{4 \\times 4}$ for the node order $(P_1, P_2, P_3, P_4)$, clearly specifying how undirected edges are represented. Finally, compute the scalar\n$$S = \\sum_{i=1}^{4}\\sum_{j=1}^{4} A_{ij}$$\nand provide its numerical value as a pure number with no units. No rounding is required.", "solution": "The problem is valid as it is scientifically grounded in the principles of probabilistic network construction, well-posed with sufficient information for a unique solution, and objectively stated.\n\nThe task is to construct a directed, edge-weighted adjacency matrix $A$ for a network of $4$ proteins, $P_1, P_2, P_3, P_4$, and then to compute the sum of its elements. The construction requires a principled approach to combine evidence from multiple independent sources and to represent both directed and undirected interactions.\n\nFirst, we define the principles for network construction.\n$1$. **Combining Independent Probabilistic Evidence**: The problem states that each evidence source provides an independent probability of a true interaction. Let an interaction be supported by $n$ independent evidence sources with respective probabilities (reliabilities) $p_1, p_2, \\dots, p_n$. The probability that at least one of these evidence sources is correct is given by $1$ minus the probability that all of them are incorrect. The probability of source $i$ being incorrect is $(1-p_i)$. Since the sources are independent, the probability of them all being incorrect is the product of their individual probabilities of being incorrect. Thus, the combined confidence score $c$ for the interaction is:\n$$c = 1 - \\prod_{i=1}^{n} (1 - p_i)$$\nThe problem gives the following base probabilities for each evidence code: $p_{Y2H} = 0.35$, $p_{CoIP} = 0.65$, $p_{APMS} = 0.55$, $p_{ChIP} = 0.75$, $p_{CUR} = 0.90$, and $p_{PM} = 0.30$.\n\n$2$. **Representing Edges in the Adjacency Matrix**: The problem requires a directed adjacency matrix $A \\in \\mathbb{R}^{4 \\times 4}$ for the ordered nodes $(P_1, P_2, P_3, P_4)$. An entry $A_{ij}$ will represent the confidence score of the directed interaction $P_i \\rightarrow P_j$.\n- For a **directed interaction** $P_i \\rightarrow P_j$ supported by evidence with a combined confidence $c$, we set $A_{ij} = c$. In the absence of evidence for the reverse interaction $P_j \\rightarrow P_i$, we set $A_{ji} = 0$.\n- For an **undirected interaction** between $P_i$ and $P_j$ with a combined confidence $c$, the evidence confirms a physical association but not causality. A standard and principled graph-theoretic representation in a directed matrix is to assign the confidence score to both directed edges, signifying that the link exists symmetrically. Therefore, we set $A_{ij} = A_{ji} = c$.\n- If there is no evidence for an interaction between $P_i$ and $P_j$, then $A_{ij} = A_{ji} = 0$.\n- Self-loops are not mentioned, so we assume $A_{ii} = 0$ for all $i$.\n\nWe now compute the confidence scores for each reported interaction and populate the matrix $A$.\n\n- **Interaction between $P_1$ and $P_2$**: Supported by Y2H ($p=0.35$) and AP-MS ($p=0.55$). No directionality is asserted.\nThe combined confidence is $c_{12} = 1 - (1 - 0.35)(1 - 0.55) = 1 - (0.65)(0.45) = 1 - 0.2925 = 0.7075$.\nSince the interaction is undirected, we set $A_{12} = 0.7075$ and $A_{21} = 0.7075$.\n\n- **Interaction between $P_1$ and $P_3$**: Supported by CUR ($p=0.90$) with direction $P_1 \\rightarrow P_3$.\nThe confidence is $c_{13} = 0.90$.\nSince the interaction is directed, we set $A_{13} = 0.90$. There is no evidence for the reverse interaction, so $A_{31} = 0$.\n\n- **Interaction between $P_2$ and $P_3$**: Supported by Co-IP ($p=0.65$). No directionality is asserted.\nThe confidence is $c_{23} = 0.65$.\nSince the interaction is undirected, we set $A_{23} = 0.65$ and $A_{32} = 0.65$.\n\n- **Interaction between $P_3$ and $P_4$**: Supported by ChIP-seq ($p=0.75$) with direction $P_3 \\rightarrow P_4$.\nThe confidence is $c_{34} = 0.75$.\nSince the interaction is directed, we set $A_{34} = 0.75$. There is no evidence for the reverse interaction, so $A_{43} = 0$.\n\n- **Interaction between $P_4$ and $P_1$**: Supported by AP-MS ($p=0.55$) and Co-IP ($p=0.65$). No directionality is asserted.\nThe combined confidence is $c_{41} = 1 - (1 - 0.55)(1 - 0.65) = 1 - (0.45)(0.35) = 1 - 0.1575 = 0.8425$.\nSince the interaction is undirected, we set $A_{41} = 0.8425$ and $A_{14} = 0.8425$.\n\n- **Interaction between $P_2$ and $P_4$**: Supported by PM ($p=0.30$) with direction $P_2 \\rightarrow P_4$.\nThe confidence is $c_{24} = 0.30$.\nSince the interaction is directed, we set $A_{24} = 0.30$. There is no evidence for the reverse interaction, so $A_{42} = 0$.\n\nCombining these results, the directed adjacency matrix $A$ is:\n$$A = \\begin{pmatrix} A_{11}  A_{12}  A_{13}  A_{14} \\\\ A_{21}  A_{22}  A_{23}  A_{24} \\\\ A_{31}  A_{32}  A_{33}  A_{34} \\\\ A_{41}  A_{42}  A_{43}  A_{44} \\end{pmatrix} = \\begin{pmatrix} 0  0.7075  0.90  0.8425 \\\\ 0.7075  0  0.65  0.30 \\\\ 0  0.65  0  0.75 \\\\ 0.8425  0  0  0 \\end{pmatrix}$$\n\nFinally, we compute the scalar $S$, which is the sum of all elements in $A$.\n$$S = \\sum_{i=1}^{4}\\sum_{j=1}^{4} A_{ij}$$\nWe sum all the non-zero entries calculated above:\n$S = A_{12} + A_{13} + A_{14} + A_{21} + A_{23} + A_{24} + A_{32} + A_{34} + A_{41}$\n$S = 0.7075 + 0.90 + 0.8425 + 0.7075 + 0.65 + 0.30 + 0.65 + 0.75 + 0.8425$\nGrouping terms:\n$S = (0.7075 + 0.7075) + (0.8425 + 0.8425) + (0.65 + 0.65) + 0.90 + 0.30 + 0.75$\n$S = (2 \\times 0.7075) + (2 \\times 0.8425) + (2 \\times 0.65) + 0.90 + 0.30 + 0.75$\n$S = 1.415 + 1.685 + 1.30 + 0.90 + 0.30 + 0.75$\n$S = 3.100 + 1.30 + 0.90 + 0.30 + 0.75$\n$S = 4.40 + 0.90 + 0.30 + 0.75$\n$S = 5.30 + 0.30 + 0.75$\n$S = 5.60 + 0.75$\n$S = 6.35$\n\nThe numerical value of the scalar $S$ is $6.35$.", "answer": "$$\\boxed{6.35}$$", "id": "4330440"}, {"introduction": "Once a network is constructed, a primary goal is to identify its most critical components. This practice introduces you to centrality analysis, a powerful set of graph-theoretic tools for quantifying the importance of each node within the network's structure. By calculating degree, betweenness, and eigenvector centralities, you will learn to pinpoint nodes that function as major hubs or crucial bottlenecks, providing key insights into the functional architecture of biological signaling pathways [@problem_id:4330471].", "problem": "You are given the task of constructing and analyzing directed biological signaling networks using graph-theoretic centrality measures. Consider a directed, unweighted graph represented by an adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$ over a node set $V=\\{0,1,\\ldots,n-1\\}$, where $A_{ij}=1$ indicates a directed interaction from node $i$ to node $j$. In systems biomedicine, such graphs are commonly constructed by integrating curated protein-protein interaction (PPI) data and kinase-substrate relationships into a consolidated signaling network. A set $H \\subseteq V$ of nodes with literature support as “known hubs” is provided for each network instance. Your task is to compute centrality measures and quantify how well central nodes (as ranked by each measure) correspond to the known hubs. All computations must be performed in purely mathematical terms as defined below.\n\nFundamental base, definitions, and requirements:\n- A directed graph $G=(V,E)$ is defined by $V=\\{0,\\ldots,n-1\\}$ and $E=\\{(i,j)\\mid A_{ij}=1\\}$. A directed path is a sequence of nodes with edges following edge directionality. The graph-theoretic distance $d(s,t)$ is the length (number of edges) of a shortest directed path from node $s$ to node $t$, if one exists, otherwise it is considered infinite.\n- Degree centrality: For each node $v \\in V$, define its degree as the sum of its in-degree and out-degree, that is, the number of incident edges considering direction. You must compute this degree for ranking. No normalization is required for ranking.\n- Betweenness centrality: For each node $v \\in V$, define its score based on the fraction of shortest directed paths between all ordered pairs $(s,t)$ with $s \\neq v$, $t \\neq v$, and $s \\neq t$, that pass through $v$. Use shortest directed paths under the unweighted metric. Use the standard normalization for directed graphs by dividing by $(n-1)(n-2)$.\n- Eigenvector centrality: Define a nonnegative vector $x \\in \\mathbb{R}_{\\ge 0}^n$ whose entries quantify the influence of nodes such that the centrality of node $i$ is proportional to the sum of the centralities of nodes that point to it. Concretely, $x$ is the principal eigenvector (corresponding to the largest eigenvalue) of $A^{\\top}$, computed by power iteration starting from a strictly positive vector and normalizing at each iteration. Terminate when the $\\ell_2$-norm of the difference between successive iterates is below a tolerance or after a maximum number of iterations. If $A^{\\top}x$ becomes the zero vector at any iteration, return the zero vector for $x$.\n- Ranking and tie-breaking: For each centrality measure $C \\in \\{\\text{degree}, \\text{betweenness}, \\text{eigenvector}\\}$, produce a ranking of nodes by descending centrality score. If two nodes have exactly equal scores, break ties by choosing the smaller node index first.\n- Hub overlap quantification: Given a set $H$ of known hubs with $|H|=k$, define the top-$k$ set $T_C$ as the $k$ nodes with highest centrality by measure $C$ under the above ranking rule. Quantify correspondence using the Jaccard index $J(T_C,H) = \\frac{|T_C \\cap H|}{|T_C \\cup H|}$. This quantity is a real number in $[0,1]$ and must be reported as a floating-point value.\n- Final outputs must be floats rounded to three decimal places.\n\nTest suite:\nCompute the three Jaccard indices $[J_{\\text{deg}}, J_{\\text{bet}}, J_{\\text{eig}}]$ for each of the following three directed networks. For every network, use the given adjacency matrix $A$ and the known hub set $H$. All entries shown are in $\\{0,1\\}$, and node indices are $0$-based.\n\n- Test case $1$:\n    - Size $n=7$.\n    - Adjacency matrix $A_1$ (row $i$, column $j$ gives $A_{ij}$):\n      $\n      \\begin{bmatrix}\n      0  1  1  0  0  0  0 \\\\\n      1  0  1  1  1  0  0 \\\\\n      0  0  0  1  1  1  0 \\\\\n      0  0  0  0  1  1  0 \\\\\n      0  0  0  0  0  1  1 \\\\\n      0  0  0  0  0  0  1 \\\\\n      0  0  0  0  0  0  0\n      \\end{bmatrix}\n      $\n    - Known hubs $H_1=\\{1,4\\}$.\n\n- Test case $2$:\n    - Size $n=8$.\n    - Adjacency matrix $A_2$:\n      $\n      \\begin{bmatrix}\n      0  1  1  0  0  0  0  0 \\\\\n      0  0  1  0  0  0  0  0 \\\\\n      0  1  0  1  0  0  0  0 \\\\\n      0  0  0  0  0  0  0  0 \\\\\n      0  0  0  0  0  1  0  1 \\\\\n      0  0  0  0  0  0  1  1 \\\\\n      0  0  0  0  1  0  0  0 \\\\\n      0  0  0  0  0  0  0  0\n      \\end{bmatrix}\n      $\n    - Known hubs $H_2=\\{2,5\\}$.\n\n- Test case $3$:\n    - Size $n=9$.\n    - Adjacency matrix $A_3$:\n      $\n      \\begin{bmatrix}\n      0  1  1  0  0  0  0  0  0 \\\\\n      0  0  0  1  0  0  0  0  0 \\\\\n      0  0  0  1  0  0  0  0  0 \\\\\n      0  0  0  0  1  1  0  0  0 \\\\\n      0  0  0  0  0  0  1  0  0 \\\\\n      0  0  0  0  0  0  1  0  0 \\\\\n      0  0  0  0  0  0  0  1  1 \\\\\n      0  0  0  0  0  0  0  0  0 \\\\\n      0  0  0  0  0  0  0  0  0\n      \\end{bmatrix}\n      $\n    - Known hubs $H_3=\\{3,6\\}$.\n\nProgramming requirements:\n- Implement computation of the three centrality measures from the above definitions, using standard shortest path concepts for directed graphs and principal eigenvector computation via power iteration on $A^{\\top}$.\n- For each test case, let $k=|H|$ and compute $T_{\\text{deg}}$, $T_{\\text{bet}}$, $T_{\\text{eig}}$ as the top-$k$ nodes under each centrality with the specified tie-breaking rule. Compute the three Jaccard indices between $T_C$ and $H$.\n- Your program must produce a single line of output containing the results as a comma-separated list of three lists (one per test case), each inner list containing the three floating-point Jaccard indices rounded to three decimal places, enclosed in square brackets. For example, an output would look like $[[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3]]$ where each $a_i,b_i,c_i$ is a float rounded to three decimals.", "solution": "The problem statement has been critically examined and is determined to be valid. It is scientifically grounded in network theory and its application to systems biology, is mathematically well-posed with clearly defined terms and objectives, and provides a complete and consistent set of data for the required computations. The problem constitutes a rigorous exercise in implementing and interpreting standard graph centrality measures. We may therefore proceed with a full solution.\n\nThe solution involves the computation of three distinct centrality measures for each given network, followed by a quantitative comparison against a provided set of known hub nodes. Each step is detailed below, grounded in established principles of graph theory and numerical linear algebra.\n\nThe core of the problem is a directed graph $G=(V,E)$ on $n$ nodes, represented by an adjacency matrix $A$. An entry $A_{ij}=1$ denotes a directed edge from node $i$ to node $j$. For each analysis, we are given a set $H$ of $k = |H|$ known hub nodes. Our goal is to compute, for each centrality measure $C$, the top-$k$ nodes $T_C$ and then the Jaccard index $J(T_C, H)$.\n\n### 1. Degree Centrality\n\n**Principle**: Degree centrality is a local measure of a node's importance, quantified by its number of connections. For a directed graph, this is the sum of its in-degree and out-degree. The in-degree of a node $v$ is the number of edges pointing to it, and the out-degree is the number of edges originating from it.\n\n**Computation**: Given the adjacency matrix $A$, the in-degree of node $j$ is the sum of the $j$-th column, $\\sum_{i=0}^{n-1} A_{ij}$. The out-degree of node $i$ is the sum of the $i$-th row, $\\sum_{j=0}^{n-1} A_{ij}$. The total degree for node $v$ is therefore given by:\n$$\n\\text{deg}(v) = \\sum_{i=0}^{n-1} A_{iv} + \\sum_{j=0}^{n-1} A_{vj}\n$$\nThese values are computed for every node in the graph.\n\n### 2. Betweenness Centrality\n\n**Principle**: Betweenness centrality is a global measure that quantifies the extent to which a node lies on shortest paths between other nodes. A node with high betweenness centrality acts as a crucial \"bridge\" or \"bottleneck\" for communication or flow within the network. For a node $v$, its betweenness centrality, $C_B(v)$, is defined as the sum of the fractions of shortest paths between all other node pairs $(s, t)$ that pass through $v$.\n\n**Computation**: The formula for a directed graph is:\n$$\nC_B(v) = \\sum_{s,t \\in V, s \\neq v \\neq t, s \\neq t} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}\n$$\nwhere $\\sigma_{st}$ is the total number of shortest directed paths from $s$ to $t$, and $\\sigma_{st}(v)$ is the number of those paths that include $v$ as an intermediate node. The computation is performed efficiently using Brandes' algorithm. This algorithm proceeds in two main stages for each node $s \\in V$ as a source:\n1.  **Shortest Path Counting**: A Breadth-First Search (BFS) starting from $s$ is used to compute the shortest path distances $d(s, \\cdot)$ and the number of shortest paths $\\sigma_{s\\cdot}$ to all other nodes.\n2.  **Dependency Accumulation**: Nodes are processed in decreasing order of their distance from $s$. For each node $w$, a dependency score $\\delta_s(w)$ is computed, representing the sum of dependencies of nodes further from $s$ on paths through $w$. The dependency of a node $v$ on its successor $w$ is the fraction of shortest paths from $s$ to $w$ that pass through $v$. The centrality score of each node $v$ is incremented by its total dependency from the source $s$.\n\nAfter iterating through all possible source nodes $s$, the resulting scores are normalized by dividing by $(n-1)(n-2)$, the total number of ordered pairs of distinct nodes excluding the endpoints.\n\n### 3. Eigenvector Centrality\n\n**Principle**: Eigenvector centrality is a recursive measure of influence. A node's centrality is not just determined by its number of connections (like degree), but by the centrality of the nodes that connect to it. A node is important if it is pointed to by other important nodes.\n\n**Computation**: This principle is mathematically formalized as an eigenvector problem. Let $x_i$ be the centrality of node $i$. The definition states that $x_i$ is proportional to the sum of centralities of nodes $j$ that have an edge to $i$. This can be written as:\n$$\nx_i = \\frac{1}{\\lambda} \\sum_{j: (j,i) \\in E} x_j = \\frac{1}{\\lambda} \\sum_{j=0}^{n-1} A_{ji} x_j\n$$\nIn matrix form, this is $\\lambda x = A^\\top x$. The vector of centralities, $x$, is thus an eigenvector of the transpose of the adjacency matrix, $A^\\top$. By the Perron-Frobenius theorem and its extensions for non-negative matrices, there is a largest non-negative eigenvalue $\\lambda_{\\text{max}}$ with a corresponding non-negative eigenvector. This is the principal eigenvector, which we seek.\n\nIt is computed numerically using the power iteration method. Starting with a strictly positive vector $x^{(0)}$ (e.g., a vector of all ones), we iteratively compute:\n$$\nx^{(k+1)} = \\frac{A^\\top x^{(k)}}{\\|A^\\top x^{(k)}\\|_2}\n$$\nThe process is repeated until the change between successive vectors, $\\|x^{(k+1)} - x^{(k)}\\|_2$, falls below a specified tolerance, or a maximum number of iterations is reached. The resulting vector $x$ contains the eigenvector centrality scores. For directed acyclic graphs (DAGs), as seen in the test cases, the largest eigenvalue of $A^\\top$ is $0$, and power iteration correctly converges to the corresponding eigenvector. In this context, centrality \"flows\" through the network, accumulating at nodes that are further downstream.\n\n### 4. Ranking and Hub Overlap Quantification\n\n**Ranking**: For each of the three centrality measures, all $n$ nodes are ranked in descending order of their centrality scores. According to the problem specification, any ties in scores are resolved by giving precedence to the node with the smaller index.\n\n**Jaccard Index**: To quantify the overlap between the set of top-ranked nodes and the set of known hubs, the Jaccard index is used. Given a set $H$ of $k$ known hubs, we identify the set $T_C$ of the top $k$ nodes according to a centrality C. The Jaccard index is then:\n$$\nJ(T_C, H) = \\frac{|T_C \\cap H|}{|T_C \\cup H|} = \\frac{|T_C \\cap H|}{|T_C| + |H| - |T_C \\cap H|}\n$$\nThis value ranges from $0$ (no overlap) to $1$ (perfect overlap), providing a standardized measure of correspondence. The final results are presented rounded to three decimal places.", "answer": "```python\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis on all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        (\n            [\n                [0, 1, 1, 0, 0, 0, 0],\n                [1, 0, 1, 1, 1, 0, 0],\n                [0, 0, 0, 1, 1, 1, 0],\n                [0, 0, 0, 0, 1, 1, 0],\n                [0, 0, 0, 0, 0, 1, 1],\n                [0, 0, 0, 0, 0, 0, 1],\n                [0, 0, 0, 0, 0, 0, 0]\n            ],\n            {1, 4}\n        ),\n        (\n            [\n                [0, 1, 1, 0, 0, 0, 0, 0],\n                [0, 0, 1, 0, 0, 0, 0, 0],\n                [0, 1, 0, 1, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 1, 0, 1],\n                [0, 0, 0, 0, 0, 0, 1, 1],\n                [0, 0, 0, 0, 1, 0, 0, 0],\n                [0, 0, 0, 0, 0, 0, 0, 0]\n            ],\n            {2, 5}\n        ),\n        (\n            [\n                [0, 1, 1, 0, 0, 0, 0, 0, 0],\n                [0, 0, 0, 1, 0, 0, 0, 0, 0],\n                [0, 0, 0, 1, 0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 1, 1, 0, 0, 0],\n                [0, 0, 0, 0, 0, 0, 1, 0, 0],\n                [0, 0, 0, 0, 0, 0, 1, 0, 0],\n                [0, 0, 0, 0, 0, 0, 0, 1, 1],\n                [0, 0, 0, 0, 0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 0, 0, 0, 0]\n            ],\n            {3, 6}\n        )\n    ]\n\n    final_results = []\n    for A_list, H_set in test_cases:\n        A = np.array(A_list, dtype=np.int32)\n        n = A.shape[0]\n        k = len(H_set)\n\n        # Calculate centralities\n        deg_cen = calculate_degree_centrality(A, n)\n        bet_cen = calculate_betweenness_centrality(A, n)\n        eig_cen = calculate_eigenvector_centrality(A, n)\n\n        # Get rankings\n        deg_rank = rank_nodes(deg_cen)\n        bet_rank = rank_nodes(bet_cen)\n        eig_rank = rank_nodes(eig_cen)\n\n        # Get top-k sets\n        T_deg = set(deg_rank[:k])\n        T_bet = set(bet_rank[:k])\n        T_eig = set(eig_rank[:k])\n\n        # Calculate Jaccard indices\n        j_deg = jaccard_index(T_deg, H_set)\n        j_bet = jaccard_index(T_bet, H_set)\n        j_eig = jaccard_index(T_eig, H_set)\n\n        final_results.append([j_deg, j_bet, j_eig])\n\n    # Format output as specified\n    outer_list_str = []\n    for res_list in final_results:\n        inner_list_str = \",\".join([f\"{x:.3f}\" for x in res_list])\n        outer_list_str.append(f\"[{inner_list_str}]\")\n    print(f\"[{','.join(outer_list_str)}]\")\n\ndef calculate_degree_centrality(A, n):\n    \"\"\"Computes degree centrality (in-degree + out-degree) for each node.\"\"\"\n    in_degree = np.sum(A, axis=0)\n    out_degree = np.sum(A, axis=1)\n    return in_degree + out_degree\n\ndef calculate_betweenness_centrality(A, n):\n    \"\"\"Computes betweenness centrality using Brandes' algorithm for directed graphs.\"\"\"\n    betweenness = np.zeros(n, dtype=np.float64)\n    nodes = list(range(n))\n    \n    for s in nodes:\n        # Single-source shortest path using BFS\n        S = []  # Stack of nodes in order of non-increasing distance from s\n        P = [[] for _ in range(n)]  # List of predecessors on shortest paths from s\n        sigma = np.zeros(n, dtype=np.float64)\n        sigma[s] = 1.0\n        d = np.full(n, -1, dtype=np.int32)\n        d[s] = 0\n        \n        Q = deque([s])\n        \n        while Q:\n            v = Q.popleft()\n            S.append(v)\n            \n            # Find neighbors of v\n            neighbors = np.where(A[v, :] == 1)[0]\n            for w in neighbors:\n                # Path discovery\n                if d[w]  0:\n                    Q.append(w)\n                    d[w] = d[v] + 1\n                \n                # Path counting\n                if d[w] == d[v] + 1:\n                    sigma[w] += sigma[v]\n                    P[w].append(v)\n                    \n        # Dependency accumulation\n        delta = np.zeros(n, dtype=np.float64)\n        while S:\n            w = S.pop()\n            for v in P[w]:\n                if sigma[w] != 0:\n                    delta[v] += (sigma[v] / sigma[w]) * (1.0 + delta[w])\n            if w != s:\n                betweenness[w] += delta[w]\n\n    # Normalization\n    if n > 2:\n        norm = (n - 1) * (n - 2)\n        betweenness /= norm\n    \n    return betweenness\n\ndef calculate_eigenvector_centrality(A, n, tol=1e-9, max_iters=1000):\n    \"\"\"Computes eigenvector centrality using power iteration on A.T.\"\"\"\n    At = A.T.astype(np.float64)\n    x = np.ones(n, dtype=np.float64)\n    \n    for _ in range(max_iters):\n        x_prev = x\n        x = At @ x\n        \n        norm_x = np.linalg.norm(x)\n        if norm_x == 0:\n            return np.zeros(n, dtype=np.float64)\n            \n        x = x / norm_x\n        \n        if np.linalg.norm(x - x_prev)  tol:\n            break\n            \n    return x\n\ndef rank_nodes(centrality_scores):\n    \"\"\"Ranks nodes by centrality, breaking ties with smaller node index.\"\"\"\n    nodes = list(range(len(centrality_scores)))\n    # Pair scores with node indices\n    scored_nodes = list(zip(centrality_scores, nodes))\n    \n    # Sort by score descending (-score), then by node index ascending\n    scored_nodes.sort(key=lambda item: (-item[0], item[1]))\n    \n    # Return just the ranked node indices\n    return [node for score, node in scored_nodes]\n\ndef jaccard_index(set1, set2):\n    \"\"\"Computes the Jaccard index between two sets.\"\"\"\n    intersection_size = float(len(set1.intersection(set2)))\n    union_size = float(len(set1.union(set2)))\n    \n    if union_size == 0:\n        # This case is not expected in this problem as k > 0\n        return 1.0\n    \n    return intersection_size / union_size\n\nif __name__ == '__main__':\n    solve()\n\n```", "id": "4330471"}, {"introduction": "Biological networks are dynamic entities that govern cellular decision-making processes over time. This practice advances from static structural analysis to dynamic simulation by guiding you through the construction and analysis of a Boolean network model. You will implement the logical rules of a signaling pathway to simulate its behavior, discovering how the network's topology and logic give rise to stable states, or attractors, which represent distinct cellular fates like proliferation or apoptosis [@problem_id:5002323].", "problem": "You are tasked with constructing and analyzing a synchronous Boolean network model that represents a simplified survival-versus-apoptosis signaling pathway in a translational medicine context. The pathway includes receptor activation, downstream kinase signaling, transcriptional regulation, and a feedback regulator that can toggle in response to transcription factor activity. The model integrates drug inhibition, bypass activation, and stress signaling as clamped inputs. Your program must enumerate all attractors of the network under specified input conditions and summarize attractor properties.\n\nFundamental base definitions to use:\n- A Boolean network is a discrete-time dynamical system with state vector $x(t) \\in \\{0,1\\}^n$ that updates synchronously according to $x(t+1) = f(x(t), u)$, where $u$ denotes clamped input variables held constant for all $t$.\n- An attractor is a recurrent set reached by the dynamics that is either a fixed point or a limit cycle. In a finite, deterministic, synchronous Boolean network, every trajectory eventually enters an attractor due to the finiteness of the state space.\n\nNetwork specification:\n- Clamped inputs: $L_1$ (ligand $1$), $L_2$ (ligand $2$), $D$ (receptor-blocking drug), $S$ (stress signal), $ALT$ (alternative bypass pathway activation), $I$ (kinase inhibitor drug). Each input takes value in $\\{0,1\\}$ and is constant over time.\n- Dynamic nodes to be updated synchronously:\n  - $R$: receptor activation.\n  - $A$: adaptor protein.\n  - $K$: kinase activity.\n  - $TF$: Transcription Factor (TF).\n  - $F$: feedback regulator.\n  - $Apop$: apoptosis effector.\n  - $Prolif$: proliferation effector.\n- Logical update rules for synchronous updates ($t \\mapsto t+1$):\n  - $R(t+1) = (L_1 \\lor L_2) \\land \\neg D$\n  - $A(t+1) = R(t)$\n  - $K(t+1) = (A(t) \\lor ALT) \\land \\neg I \\land \\neg F(t)$\n  - $TF(t+1) = K(t) \\lor \\left(ALT \\land \\neg S\\right)$\n  - $F(t+1) = TF(t) \\oplus F(t)$ where $\\oplus$ denotes exclusive OR defined as $a \\oplus b = 1$ if $a \\neq b$ and $0$ otherwise\n  - $Apop(t+1) = S \\land \\neg TF(t)$\n  - $Prolif(t+1) = TF(t) \\land \\neg S$\n- All logical operations are pointwise over $\\{0,1\\}$, where $\\lor$ is logical OR, $\\land$ is logical AND, $\\neg$ is logical NOT, and $\\oplus$ is exclusive OR. The inputs $L_1, L_2, D, S, ALT, I$ remain fixed for all $t$ in each simulation.\n\nState representation:\n- Represent the dynamic state vector as the ordered tuple $(R, A, K, TF, F, Apop, Prolif) \\in \\{0,1\\}^7$.\n\nAttractor analysis requirements:\n- For a given set of clamped inputs, enumerate trajectories starting from all $2^7$ possible initial dynamic states. For each trajectory, iteratively apply the synchronous update until a previously visited state is encountered, at which point the recurrent set of states constitutes an attractor (fixed point if the set size is $1$, limit cycle otherwise).\n- Deduplicate attractors across different initial conditions by comparing the sets of states comprising each attractor. Two attractors are considered the same if they consist of the same set of dynamic states, regardless of phase or traversal order.\n\nTest suite:\n- Use the following input parameter sets to exercise the model:\n  1. $(L_1,L_2,D,S,ALT,I) = (1,0,0,0,0,0)$\n  2. $(L_1,L_2,D,S,ALT,I) = (1,1,1,1,0,1)$\n  3. $(L_1,L_2,D,S,ALT,I) = (0,0,1,0,1,1)$\n  4. $(L_1,L_2,D,S,ALT,I) = (0,0,0,0,0,0)$\n- These cases include a general case with active ligand and no inhibition, a high-inhibition and stress case, a bypass-activated case expected to produce oscillatory feedback, and the boundary case with all inputs off.\n\nRequired outputs per test case:\n- For each input parameter set, compute and output the following three quantities:\n  1. The integer number $n$ of distinct attractors.\n  2. The integer $\\ell$ equal to the sum of the lengths of all distinct attractors (each fixed point contributes $1$, each limit cycle contributes its cycle length).\n  3. The boolean $b$ indicating whether any attractor contains at least one state in which apoptosis is active, that is, whether there exists an attractor with some state having $Apop = 1$.\n\nFinal output format:\n- Your program should produce a single line of output containing the aggregated results for the test suite as a comma-separated list enclosed in square brackets. The list must be ordered as $[n_1,\\ell_1,b_1,n_2,\\ell_2,b_2,n_3,\\ell_3,b_3,n_4,\\ell_4,b_4]$, where the subscript indexes the test case in the order given above. No additional text should be printed.", "solution": "The problem presents a well-defined task in computational systems biology: to analyze the attractors of a synchronous Boolean network model. The model represents a simplified signal transduction pathway, a common paradigm in biology for studying cellular decision-making processes like survival versus apoptosis. The problem is scientifically grounded, mathematically precise, and algorithmically tractable.\n\nThe core of the system is a discrete-time dynamical system defined over a finite state space. The state of the network at any time `$t$` is given by a `$7$-dimensional binary vector `$x(t) \\in \\{0,1\\}^7$`, where each component corresponds to the activity level (ON/OFF, `$1$/$0$`) of a specific biological entity. The state vector is specified as the ordered tuple `$x(t) = (R(t), A(t), K(t), TF(t), F(t), Apop(t), Prolif(t))$`. The total number of possible states is `$2^7 = 128$`.\n\nThe system's evolution is governed by a set of deterministic, synchronous update rules, which can be expressed as a function `$f$` that maps the current state `$x(t)$` and a set of clamped inputs `$u$` to the next state `$x(t+1)$`. The inputs `$u = (L_1, L_2, D, S, ALT, I)$` represent external conditions or drug interventions and are held constant throughout a given simulation.\n\nThe logical update functions for each node `$x_i$` (where, for example, `$x_1=R$`, `$x_2=A$`, etc.) are as follows:\n- `$x_1(t+1) = (L_1 \\lor L_2) \\land \\neg D$`. The Receptor `$R$` is activated by ligands `$L_1$` or `$L_2$` unless blocked by drug `$D$`. Note that its state at `$t+1$` is entirely determined by the static inputs, not by the dynamic state at time `$t$`.\n- `$x_2(t+1) = x_1(t)$`. The Adaptor protein `$A$` simply follows the state of the receptor from the previous time step.\n- `$x_3(t+1) = (x_2(t) \\lor ALT) \\land \\neg I \\land \\neg x_5(t)$`. The Kinase `$K$` is activated by the adaptor `$A$` or by a bypass pathway `$ALT$`, but its activity can be suppressed by an inhibitor `$I$` or by the feedback regulator `$F$`.\n- `$x_4(t+1) = x_3(t) \\lor (ALT \\land \\neg S)$`. The Transcription Factor `$TF$` is activated by the kinase `$K$`, or by the bypass pathway `$ALT$` in the absence of a stress signal `$S$`.\n- `$x_5(t+1) = x_4(t) \\oplus x_5(t)$`. The feedback regulator `$F$` acts as a toggle switch. It flips its state if the transcription factor `$TF$` was active in the previous step (`$x_4(t)=1$`) and maintains its state otherwise (`$x_4(t)=0$`). This introduces memory and the potential for oscillatory dynamics.\n- `$x_6(t+1) = S \\land \\neg x_4(t)$`. The Apoptosis effector `$Apop$` is activated only when a stress signal `$S$` is present AND the pro-survival transcription factor `$TF$` is inactive.\n- `$x_7(t+1) = x_4(t) \\land \\neg S$`. The Proliferation effector `$Prolif$` is activated by the transcription factor `$TF$` in the absence of a stress signal `$S$`.\n\nSince the state space is finite and the dynamics are deterministic, any trajectory starting from an initial state `$x(0)$` must eventually repeat a state, at which point it has entered an attractor. An attractor is a subset of the state space that is closed under the dynamics; it can be a fixed point (a cycle of length `$1$`) or a limit cycle (a cycle of length `$k  1$`). The set of all states that lead to a particular attractor is called its basin of attraction.\n\nThe algorithmic procedure to identify and characterize all attractors for a given input configuration `$u$` is as follows:\n1.  **State Space Enumeration**: We must explore the dynamics starting from every possible initial condition to guarantee that all attractors are found. We will iterate through all `$128$` states of the system, represented numerically by integers from `$0$` to `$127$`.\n2.  **Trajectory Simulation**: For each initial state `$x_{init}$` that has not yet been part of a previously explored trajectory, we simulate the network's evolution step-by-step: `$x_0 = x_{init}$, $x_1 = f(x_0, u)$, $x_2 = f(x_1, u)$, ... . We maintain a history of visited states in the current trajectory.\n3.  **Attractor Identification**: The simulation for a given trajectory terminates when a state is generated that has already appeared in its history. This repeated state marks the entry into an attractor. The attractor itself consists of all states from the first occurrence of the repeated state to the end of the calculated trajectory.\n4.  **Deduplication and Storage**: To count only unique attractors, we store the identified attractors' state sets. A canonical representation, such as a `frozenset` of state tuples, is used. This allows for efficient storage in a master `set` that automatically handles deduplication. All states within any found trajectory are marked as \"visited\" to avoid redundant simulations.\n5.  **Metric Calculation**: Once all `$128$` initial states have been accounted for (i.e., assigned to an attractor's basin), we can compute the required metrics from the set of unique attractors:\n    -   `$n$`: The number of distinct attractors, which is the size of the set of unique attractors.\n    -   `$\\ell$`: The sum of the lengths of all distinct attractors. This is calculated by summing the number of states in each unique attractor.\n    -   `$b$`: A boolean indicating if any state within any attractor has the `$Apop$` node active (`$x_6=1$`). This is determined by iterating through all states of all found attractors.\n\nThis comprehensive analysis is performed for each of the four specified input parameter sets. The results are then aggregated and formatted into the required single-line output.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and analyzes a synchronous Boolean network model of a signaling pathway.\n    For given input conditions, it finds all attractors (fixed points and limit cycles)\n    and computes statistics about them.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # (L1, L2, D, S, ALT, I)\n    test_cases = [\n        (1, 0, 0, 0, 0, 0),  # Case 1: Ligand-activated, no inhibition\n        (1, 1, 1, 1, 0, 1),  # Case 2: High-inhibition and stress\n        (0, 0, 1, 0, 1, 1),  # Case 3: Bypass-activated\n        (0, 0, 0, 0, 0, 0),  # Case 4: All inputs off\n    ]\n\n    final_results = []\n\n    for inputs in test_cases:\n        L1, L2, D, S, ALT, I = inputs\n\n        memoized_updates = {}\n\n        def update_function(state_tuple):\n            \"\"\"\n            Computes the next state of the Boolean network given the current state.\n            The state is a tuple (R, A, K, TF, F, Apop, Prolif).\n            \"\"\"\n            if state_tuple in memoized_updates:\n                return memoized_updates[state_tuple]\n\n            R_curr, A_curr, K_curr, TF_curr, F_curr, _, _ = state_tuple\n\n            # Logical update rules\n            R_next = (L1 or L2) and not D\n            A_next = R_curr\n            K_next = (A_curr or ALT) and not I and not F_curr\n            TF_next = K_curr or (ALT and not S)\n            # XOR logic: a != b is equivalent to a ^ b for 0/1 integers\n            F_next = TF_curr != F_curr\n            Apop_next = S and not TF_curr\n            Prolif_next = TF_curr and not S\n            \n            # Convert booleans to integers (0 or 1) and form the next state tuple\n            next_state = (\n                int(R_next), int(A_next), int(K_next), int(TF_next),\n                int(F_next), int(Apop_next), int(Prolif_next)\n            )\n            \n            memoized_updates[state_tuple] = next_state\n            return next_state\n\n        num_nodes = 7\n        num_states = 2**num_nodes\n        \n        # A set to keep track of states that are already part of a found trajectory\n        processed_states = set()\n        # A set to store unique attractors (as frozensets of state tuples)\n        unique_attractors = set()\n\n        # Iterate through all possible 2^7 = 128 initial states\n        for i in range(num_states):\n            # Generate the state tuple from its integer representation\n            initial_state = tuple((i >> (num_nodes - 1 - j))  1 for j in range(num_nodes))\n\n            if initial_state in processed_states:\n                continue\n\n            # Simulate trajectory starting from this un-processed state\n            trajectory = []\n            state_to_index_map = {}\n            current_state = initial_state\n\n            while current_state not in state_to_index_map:\n                state_to_index_map[current_state] = len(trajectory)\n                trajectory.append(current_state)\n                current_state = update_function(current_state)\n\n            # An attractor is found when a state is repeated\n            cycle_start_index = state_to_index_map[current_state]\n            attractor_states = trajectory[cycle_start_index:]\n            \n            # Add the canonical form of the attractor (a frozenset) to the set of unique attractors\n            unique_attractors.add(frozenset(attractor_states))\n            \n            # Mark all states in the found trajectory (transient path + attractor) as processed\n            processed_states.update(trajectory)\n\n        # Analyze the collected unique attractors for the current test case\n        # 1. Number of distinct attractors\n        n = len(unique_attractors)\n        \n        # 2. Sum of the lengths of all distinct attractors\n        ell = sum(len(att) for att in unique_attractors)\n        \n        # 3. Boolean indicating if apoptosis is ever active in any attractor\n        apoptosis_is_active = False\n        APOP_NODE_INDEX = 5  # (R, A, K, TF, F, Apop, Prolif) -> index 5\n        for attractor in unique_attractors:\n            if any(state[APOP_NODE_INDEX] == 1 for state in attractor):\n                apoptosis_is_active = True\n                break\n        \n        # Convert the boolean to an integer (0 or 1) for the final output\n        b = int(apoptosis_is_active)\n        \n        final_results.extend([n, ell, b])\n\n    # Print the final result in the exact required format\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "5002323"}]}