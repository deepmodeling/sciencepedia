{"hands_on_practices": [{"introduction": "This first exercise solidifies the theoretical underpinnings of the Area Under the ROC Curve (AUC). By working through a hypothetical scenario where classifier scores from a cross-validation experiment follow Gaussian distributions, you will derive the AUC analytically. This practice directly connects the probabilistic definition of AUC—the probability that a positive case outscores a negative case—to the statistical parameters of the score distributions, providing a deep, first-principles understanding of this core metric [@problem_id:4360914].", "problem": "A systems biomedicine group evaluates a binary classifier that predicts activation of a host-response endotype in sepsis from transcriptomic features. The classifier outputs a continuous score per patient, and evaluation follows stratified $k$-fold cross-validation (with $k=5$), where in each fold the model is trained on $4$ folds and used to score the held-out fold. The model assessment comprises Receiver Operating Characteristic (ROC) analysis, where the ROC curve is defined as the graph of the true positive rate versus the false positive rate as the discrimination threshold varies across all real values. The area under the ROC curve (AUC) equals the probability that a randomly selected positive-class score exceeds a randomly selected negative-class score.\n\nAssume that, within each held-out fold $i \\in \\{1,2,3,4,5\\}$, the distribution of scores for the positive class is approximately Gaussian with mean $\\mu_{1,i}$ and population variance $\\sigma_{1,i}^{2}$, and the distribution of scores for the negative class is approximately Gaussian with mean $\\mu_{0,i}$ and population variance $\\sigma_{0,i}^{2}$. Assume independence of scores across patients and folds. The cross-validated AUC is to be estimated by pooling all held-out scores across folds into a single positive-class distribution with pooled mean $\\mu_{1}$ and pooled population variance $\\sigma_{1}^{2}$, and a single negative-class distribution with pooled mean $\\mu_{0}$ and pooled population variance $\\sigma_{0}^{2}$. The pooled means are defined by the weighted averages of fold-specific means using the held-out sample sizes, and the pooled population variances are defined by the total-law-of-variance decomposition across folds.\n\nThe held-out fold summaries are:\n\n- Fold $1$: $n_{1,1}=32$, $\\mu_{1,1}=1.35$, $\\sigma_{1,1}^{2}=0.36$; $n_{0,1}=40$, $\\mu_{0,1}=0.55$, $\\sigma_{0,1}^{2}=0.49$.\n- Fold $2$: $n_{1,2}=28$, $\\mu_{1,2}=1.20$, $\\sigma_{1,2}^{2}=0.25$; $n_{0,2}=45$, $\\mu_{0,2}=0.50$, $\\sigma_{0,2}^{2}=0.36$.\n- Fold $3$: $n_{1,3}=30$, $\\mu_{1,3}=1.10$, $\\sigma_{1,3}^{2}=0.30$; $n_{0,3}=42$, $\\mu_{0,3}=0.40$, $\\sigma_{0,3}^{2}=0.30$.\n- Fold $4$: $n_{1,4}=35$, $\\mu_{1,4}=1.40$, $\\sigma_{1,4}^{2}=0.28$; $n_{0,4}=38$, $\\mu_{0,4}=0.60$, $\\sigma_{0,4}^{2}=0.42$.\n- Fold $5$: $n_{1,5}=25$, $\\mu_{1,5}=1.25$, $\\sigma_{1,5}^{2}=0.32$; $n_{0,5}=50$, $\\mu_{0,5}=0.45$, $\\sigma_{0,5}^{2}=0.35$.\n\nUsing only the definitions of ROC, AUC, and Gaussian distribution properties, derive an analytic expression for the cross-validated AUC in terms of the pooled parameters $\\mu_{1}$, $\\mu_{0}$, $\\sigma_{1}^{2}$, and $\\sigma_{0}^{2}$, and then compute its numerical value based on the provided fold summaries. Round your final numerical answer to four significant figures. Express the final value as a pure number without any unit.", "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded, well-posed, objective, and internally consistent, providing all necessary information for a unique solution. We may therefore proceed with the derivation and computation.\n\nThe task is to first derive an analytic expression for the cross-validated Area Under the ROC Curve (AUC) in terms of pooled statistical parameters, and then to compute its numerical value.\n\n**Part 1: Analytic Expression for AUC**\n\nThe problem defines the AUC as the probability that a randomly selected positive-class score exceeds a randomly selected negative-class score. Let $S_1$ be the random variable representing a score from the pooled positive-class distribution, and $S_0$ be the random variable for a score from the pooled negative-class distribution.\n\nAccording to the problem statement, these pooled scores are modeled by Gaussian distributions:\n$$S_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2)$$\n$$S_0 \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$$\nThe individuals from whom scores are taken are independent, thus $S_1$ and $S_0$ are independent random variables.\n\nThe AUC is therefore the probability $P(S_1 > S_0)$, which can be rewritten as $P(S_1 - S_0 > 0)$.\nLet us define a new random variable $D = S_1 - S_0$. Since $S_1$ and $S_0$ are independent Gaussian variables, their difference $D$ is also a Gaussian variable. The parameters of the distribution of $D$ are:\nThe mean (expected value) of $D$:\n$$E[D] = E[S_1 - S_0] = E[S_1] - E[S_0] = \\mu_1 - \\mu_0$$\nThe variance of $D$:\n$$\\text{Var}(D) = \\text{Var}(S_1 - S_0) = \\text{Var}(S_1) + \\text{Var}(-S_0) = \\text{Var}(S_1) + (-1)^2 \\text{Var}(S_0) = \\sigma_1^2 + \\sigma_0^2$$\nThe independence of $S_1$ and $S_0$ is critical for this step, as it ensures the covariance term is zero.\nSo, the distribution of the difference is $D \\sim \\mathcal{N}(\\mu_1 - \\mu_0, \\sigma_1^2 + \\sigma_0^2)$.\n\nThe AUC is the probability $P(D > 0)$. To calculate this, we standardize the variable $D$ to a standard normal variable $Z \\sim \\mathcal{N}(0,1)$:\n$$P(D > 0) = P\\left(\\frac{D - (\\mu_1 - \\mu_0)}{\\sqrt{\\sigma_1^2 + \\sigma_0^2}} > \\frac{0 - (\\mu_1 - \\mu_0)}{\\sqrt{\\sigma_1^2 + \\sigma_0^2}}\\right)$$\n$$P(D > 0) = P\\left(Z > -\\frac{\\mu_1 - \\mu_0}{\\sqrt{\\sigma_1^2 + \\sigma_0^2}}\\right)$$\nDue to the symmetry of the standard normal distribution, $P(Z > -z) = P(Z < z)$. Let $\\Phi(z)$ be the cumulative distribution function (CDF) of the standard normal distribution, which is defined as $\\Phi(z) = P(Z \\le z)$.\nTherefore, the analytic expression for the AUC is:\n$$\\text{AUC} = \\Phi\\left(\\frac{\\mu_1 - \\mu_0}{\\sqrt{\\sigma_1^2 + \\sigma_0^2}}\\right)$$\n\n**Part 2: Calculation of Pooled Parameters**\n\nNext, we calculate the pooled parameters $\\mu_1, \\sigma_1^2, \\mu_0, \\sigma_0^2$ from the data provided for the $k=5$ folds.\n\nFor the positive class (class $1$):\nTotal sample size: $N_1 = \\sum_{i=1}^{5} n_{1,i} = 32 + 28 + 30 + 35 + 25 = 150$.\nThe pooled mean $\\mu_1$ is the weighted average of the fold-specific means:\n$$\\mu_1 = \\frac{1}{N_1} \\sum_{i=1}^{5} n_{1,i}\\mu_{1,i} = \\frac{32(1.35) + 28(1.20) + 30(1.10) + 35(1.40) + 25(1.25)}{150}$$\n$$\\mu_1 = \\frac{43.2 + 33.6 + 33.0 + 49.0 + 31.25}{150} = \\frac{190.05}{150} = 1.267$$\nThe pooled variance $\\sigma_1^2$ is given by the law of total variance: $\\sigma_1^2 = E[\\sigma_{1,i}^2] + \\text{Var}(\\mu_{1,i})$.\n$$\\sigma_1^2 = \\frac{1}{N_1}\\sum_{i=1}^{5} n_{1,i}\\sigma_{1,i}^2 + \\frac{1}{N_1}\\sum_{i=1}^{5} n_{1,i}(\\mu_{1,i} - \\mu_1)^2$$\nThe first term (mean of variances):\n$$\\frac{1}{150}[32(0.36)+28(0.25)+30(0.30)+35(0.28)+25(0.32)] = \\frac{11.52+7.0+9.0+9.8+8.0}{150} = \\frac{45.32}{150}$$\nThe second term (variance of means): $\\frac{1}{N_1} \\left( \\sum n_{1,i}\\mu_{1,i}^2 - N_1\\mu_1^2 \\right)$\n$$\\sum n_{1,i}\\mu_{1,i}^2 = 32(1.35^2)+28(1.20^2)+30(1.10^2)+35(1.40^2)+25(1.25^2) = 58.32+40.32+36.3+68.6+39.0625 = 242.6025$$\n$$N_1\\mu_1^2 = 150(1.267^2) = 150(1.605289) = 240.79335$$\n$$\\sum n_{1,i}(\\mu_{1,i} - \\mu_1)^2 = 242.6025 - 240.79335 = 1.80915$$\nSo, $\\sigma_1^2 = \\frac{45.32 + 1.80915}{150} = \\frac{47.12915}{150} \\approx 0.31419433$$\n\nFor the negative class (class $0$):\nTotal sample size: $N_0 = \\sum_{i=1}^{5} n_{0,i} = 40 + 45 + 42 + 38 + 50 = 215$.\nThe pooled mean $\\mu_0$:\n$$\\mu_0 = \\frac{1}{N_0} \\sum_{i=1}^{5} n_{0,i}\\mu_{0,i} = \\frac{40(0.55) + 45(0.50) + 42(0.40) + 38(0.60) + 50(0.45)}{215}$$\n$$\\mu_0 = \\frac{22.0 + 22.5 + 16.8 + 22.8 + 22.5}{215} = \\frac{106.6}{215} \\approx 0.49581395$$\nThe pooled variance $\\sigma_0^2$:\n$$\\sigma_0^2 = \\frac{1}{N_0}\\sum n_{0,i}\\sigma_{0,i}^2 + \\frac{1}{N_0}\\sum n_{0,i}(\\mu_{0,i} - \\mu_0)^2$$\nThe first term:\n$$\\frac{1}{215}[40(0.49)+45(0.36)+42(0.30)+38(0.42)+50(0.35)] = \\frac{19.6+16.2+12.6+15.96+17.5}{215} = \\frac{81.86}{215}$$\nThe second term:\n$$\\sum n_{0,i}\\mu_{0,i}^2 = 40(0.55^2)+45(0.50^2)+42(0.40^2)+38(0.60^2)+50(0.45^2) = 12.1+11.25+6.72+13.68+10.125 = 53.875$$\n$$N_0\\mu_0^2 = 215\\left(\\frac{106.6}{215}\\right)^2 = \\frac{106.6^2}{215} = \\frac{11363.56}{215} \\approx 52.853767$$\n$$\\sum n_{0,i}(\\mu_{0,i} - \\mu_0)^2 = 53.875 - 52.853767 = 1.021233$$\nSo, $\\sigma_0^2 = \\frac{81.86 + 1.021233}{215} = \\frac{82.881233}{215} \\approx 0.38549411$$\n\n**Part 3: Final AUC Calculation**\n\nNow we substitute the computed pooled parameters into the analytic AUC expression.\nDifference in means:\n$$\\mu_1 - \\mu_0 = 1.267 - \\frac{106.6}{215} = \\frac{272.405 - 106.6}{215} = \\frac{165.805}{215} \\approx 0.771186$$\nSum of variances:\n$$\\sigma_1^2 + \\sigma_0^2 \\approx 0.31419433 + 0.38549411 = 0.69968844$$\nStandard deviation of the difference:\n$$\\sqrt{\\sigma_1^2 + \\sigma_0^2} \\approx \\sqrt{0.69968844} \\approx 0.8364738$$\nThe argument of the CDF $\\Phi$ is:\n$$z = \\frac{\\mu_1 - \\mu_0}{\\sqrt{\\sigma_1^2 + \\sigma_0^2}} \\approx \\frac{0.771186}{0.8364738} \\approx 0.921949$$\nFinally, we compute the AUC:\n$$\\text{AUC} = \\Phi(0.921949) \\approx 0.8217346$$\nRounding the final numerical answer to four significant figures gives $0.8217$.", "answer": "$$\\boxed{0.8217}$$", "id": "4360914"}, {"introduction": "While the AUC measures a model's overall discriminative ability, translating a classifier into a practical decision-support tool requires selecting a specific operating threshold. This exercise moves from assessment to application, challenging you to derive optimal thresholds for a sepsis risk model under two distinct frameworks. You will explore how to find the threshold that maximizes Youden’s $J$ index, a common metric of diagnostic performance, and contrast it with a utility-based threshold that minimizes expected loss by incorporating clinical costs and disease prevalence [@problem_id:4360915].", "problem": "A sepsis risk model in systems biomedicine is assessed using stratified nested Cross-Validation (CV). The model outputs a linear risk score $s \\in \\mathbb{R}$ from which binary decisions are made by thresholding $s \\ge t$. Out-of-fold predictions aggregated across CV folds yield class-conditional score distributions that are empirically well-approximated by Gaussian densities with a common variance: for non-septic patients ($Y=0$), $s \\sim \\mathcal{N}(\\mu_{0},\\sigma^{2})$; for septic patients ($Y=1$), $s \\sim \\mathcal{N}(\\mu_{1},\\sigma^{2})$. The CV estimates for these parameters are $\\mu_{0}=-0.9$, $\\mu_{1}=0.7$, and $\\sigma=0.8$. The Receiver Operating Characteristic (ROC) analysis is to be used to select a decision threshold in two ways: maximizing Youden’s $J$ and maximizing a cost-sensitive expected utility.\n\nAssume a target deployment population with disease prevalence $\\pi=0.2$. A false negative (missing a septic patient) incurs a misclassification harm $C_{\\mathrm{FN}}=10$, and a false positive (unnecessary treatment for a non-septic patient) incurs a misclassification harm $C_{\\mathrm{FP}}=1$. Correct classifications are taken as the baseline with zero additional harm. Under these assumptions, the expected per-patient loss at threshold $t$ is\n$$\n\\mathcal{L}(t)=\\pi\\,C_{\\mathrm{FN}}\\,\\Pr(s<t \\mid Y=1)+(1-\\pi)\\,C_{\\mathrm{FP}}\\,\\Pr(s\\ge t \\mid Y=0).\n$$\nStarting only from the fundamental definitions of Bayes risk minimization and the Gaussian likelihood model stated above, and without invoking any pre-stated threshold formulas, do the following:\n1. Derive an analytical expression for the threshold $t_{U}$ that minimizes $\\mathcal{L}(t)$.\n2. Derive an analytical expression for the threshold $t_{J}$ that maximizes Youden’s $J$, defined as $J(t)=\\mathrm{TPR}(t)+\\mathrm{TNR}(t)-1$, where $\\mathrm{TPR}(t)=\\Pr(s\\ge t\\mid Y=1)$ and $\\mathrm{TNR}(t)=\\Pr(s<t\\mid Y=0)$.\n3. Evaluate both expressions using the CV-estimated parameters $\\mu_{0}$, $\\mu_{1}$, $\\sigma$, and the deployment parameters $\\pi$, $C_{\\mathrm{FN}}$, $C_{\\mathrm{FP}}$ given above.\n\nRound your final numerical answer to four significant figures. Express the final numerical answer as the cost-sensitive utility-optimal threshold $t_{U}$ on the model’s linear score scale (unitless). The final answer must be a single real number.", "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n-   Model output: A linear risk score $s \\in \\mathbb{R}$.\n-   Decision rule: Thresholding $s \\ge t$.\n-   Class-conditional score distributions for non-septic ($Y=0$) and septic ($Y=1$) patients:\n    -   $s \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0},\\sigma^{2})$\n    -   $s \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1},\\sigma^{2})$\n-   CV-estimated parameters:\n    -   $\\mu_{0} = -0.9$\n    -   $\\mu_{1} = 0.7$\n    -   $\\sigma = 0.8$\n-   Deployment population parameters:\n    -   Prevalence: $\\pi = \\Pr(Y=1) = 0.2$\n    -   Misclassification harms: $C_{\\mathrm{FN}} = 10$, $C_{\\mathrm{FP}} = 1$. Correct classification harm is $0$.\n-   Expected per-patient loss function:\n    $$\n    \\mathcal{L}(t)=\\pi\\,C_{\\mathrm{FN}}\\,\\Pr(s<t \\mid Y=1)+(1-\\pi)\\,C_{\\mathrm{FP}}\\,\\Pr(s\\ge t \\mid Y=0)\n    $$\n-   Youden's J index definition: $J(t)=\\mathrm{TPR}(t)+\\mathrm{TNR}(t)-1$.\n-   TPR and TNR definitions:\n    -   $\\mathrm{TPR}(t) = \\Pr(s\\ge t\\mid Y=1)$\n    -   $\\mathrm{TNR}(t) = \\Pr(s<t\\mid Y=0)$\n-   Objectives:\n    1.  Derive the analytical expression for the threshold $t_{U}$ that minimizes $\\mathcal{L}(t)$.\n    2.  Derive the analytical expression for the threshold $t_{J}$ that maximizes $J(t)$.\n    3.  Evaluate both expressions and provide a final numerical answer for $t_{U}$ rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, employing standard concepts from statistical decision theory, signal detection theory, and machine learning model evaluation (ROC analysis, cost-sensitive learning). The use of Gaussian distributions for modeling classifier scores is a common and valid assumption (e.g., in Linear Discriminant Analysis). The problem is well-posed, as it provides all necessary parameters and clearly defined objective functions ($\\mathcal{L}(t)$ to be minimized, $J(t)$ to be maximized) which are differentiable and allow for a unique solution via calculus. The problem statement is objective, complete, and internally consistent, with no factual or logical flaws. The parameters are physically and numerically plausible.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. A full, reasoned solution will be provided.\n\n### Solution Derivation\n\nLet the probability density function (PDF) of the score $s$ for class $k \\in \\{0,1\\}$ be denoted by $p(s \\mid Y=k)$. Given the problem statement, these are Gaussian densities:\n$$\np(s \\mid Y=k) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(s-\\mu_k)^2}{2\\sigma^2}\\right)\n$$\n\n**1. Derivation of the Cost-Sensitive Utility-Optimal Threshold $t_U$**\n\nThe objective is to find the threshold $t$ that minimizes the expected loss $\\mathcal{L}(t)$. The loss function is given as:\n$$\n\\mathcal{L}(t)=\\pi\\,C_{\\mathrm{FN}}\\,\\Pr(s<t \\mid Y=1)+(1-\\pi)\\,C_{\\mathrm{FP}}\\,\\Pr(s\\ge t \\mid Y=0)\n$$\nWe can express the probabilities as integrals of the class-conditional PDFs:\n$$\n\\mathcal{L}(t)=\\pi\\,C_{\\mathrm{FN}}\\int_{-\\infty}^{t} p(s' \\mid Y=1) ds' + (1-\\pi)\\,C_{\\mathrm{FP}}\\int_{t}^{\\infty} p(s' \\mid Y=0) ds'\n$$\nTo find the minimum, we differentiate $\\mathcal{L}(t)$ with respect to $t$ and set the derivative to zero. Using the Fundamental Theorem of Calculus (specifically, the Leibniz integral rule):\n$$\n\\frac{d}{dt}\\int_{a}^{t} f(x) dx = f(t) \\quad \\text{and} \\quad \\frac{d}{dt}\\int_{t}^{b} f(x) dx = -f(t)\n$$\nApplying this to $\\mathcal{L}(t)$:\n$$\n\\frac{d\\mathcal{L}(t)}{dt} = \\pi\\,C_{\\mathrm{FN}}\\,p(t \\mid Y=1) - (1-\\pi)\\,C_{\\mathrm{FP}}\\,p(t \\mid Y=0)\n$$\nSetting the derivative to zero to find the optimal threshold $t_{U}$:\n$$\n\\pi\\,C_{\\mathrm{FN}}\\,p(t_U \\mid Y=1) = (1-\\pi)\\,C_{\\mathrm{FP}}\\,p(t_U \\mid Y=0)\n$$\nThis can be rearranged into a likelihood ratio form:\n$$\n\\frac{p(t_U \\mid Y=1)}{p(t_U \\mid Y=0)} = \\frac{(1-\\pi)C_{\\mathrm{FP}}}{\\pi C_{\\mathrm{FN}}}\n$$\nNow, substitute the Gaussian PDF expressions. The normalization constant $\\frac{1}{\\sqrt{2\\pi\\sigma^2}}$ cancels out:\n$$\n\\frac{\\exp\\left(-\\frac{(t_U-\\mu_1)^2}{2\\sigma^2}\\right)}{\\exp\\left(-\\frac{(t_U-\\mu_0)^2}{2\\sigma^2}\\right)} = \\frac{(1-\\pi)C_{\\mathrm{FP}}}{\\pi C_{\\mathrm{FN}}}\n$$\n$$\n\\exp\\left( \\frac{(t_U-\\mu_0)^2 - (t_U-\\mu_1)^2}{2\\sigma^2} \\right) = \\frac{(1-\\pi)C_{\\mathrm{FP}}}{\\pi C_{\\mathrm{FN}}}\n$$\nTaking the natural logarithm of both sides:\n$$\n\\frac{(t_U^2 - 2t_U\\mu_0 + \\mu_0^2) - (t_U^2 - 2t_U\\mu_1 + \\mu_1^2)}{2\\sigma^2} = \\ln\\left(\\frac{(1-\\pi)C_{\\mathrm{FP}}}{\\pi C_{\\mathrm{FN}}}\\right)\n$$\nThe $t_U^2$ terms cancel:\n$$\n\\frac{2t_U(\\mu_1 - \\mu_0) + (\\mu_0^2 - \\mu_1^2)}{2\\sigma^2} = \\ln\\left(\\frac{(1-\\pi)C_{\\mathrm{FP}}}{\\pi C_{\\mathrm{FN}}}\\right)\n$$\nFactoring $\\mu_0^2 - \\mu_1^2 = -(\\mu_1 - \\mu_0)(\\mu_1 + \\mu_0)$:\n$$\n\\frac{2t_U(\\mu_1 - \\mu_0) - (\\mu_1 - \\mu_0)(\\mu_0 + \\mu_1)}{2\\sigma^2} = \\ln\\left(\\frac{(1-\\pi)C_{\\mathrm{FP}}}{\\pi C_{\\mathrm{FN}}}\\right)\n$$\nMultiplying by $2\\sigma^2$ and dividing by $(\\mu_1 - \\mu_0)$ (assuming $\\mu_1 \\neq \\mu_0$):\n$$\n2t_U - (\\mu_0 + \\mu_1) = \\frac{2\\sigma^2}{\\mu_1 - \\mu_0}\\ln\\left(\\frac{(1-\\pi)C_{\\mathrm{FP}}}{\\pi C_{\\mathrm{FN}}}\\right)\n$$\nSolving for $t_U$:\n$$\nt_U = \\frac{\\mu_0 + \\mu_1}{2} + \\frac{\\sigma^2}{\\mu_1 - \\mu_0}\\ln\\left(\\frac{(1-\\pi)C_{\\mathrm{FP}}}{\\pi C_{\\mathrm{FN}}}\\right)\n$$\n\n**2. Derivation of the Youden's J-Optimal Threshold $t_J$**\n\nThe objective is to find the threshold $t$ that maximizes Youden's J index, $J(t) = \\mathrm{TPR}(t) + \\mathrm{TNR}(t) - 1$.\nUsing the definitions provided:\n$$\nJ(t) = \\Pr(s\\ge t\\mid Y=1) + \\Pr(s<t\\mid Y=0) - 1\n$$\nIn integral form:\n$$\nJ(t) = \\int_{t}^{\\infty} p(s' \\mid Y=1) ds' + \\int_{-\\infty}^{t} p(s' \\mid Y=0) ds' - 1\n$$\nDifferentiating $J(t)$ with respect to $t$ and setting to zero:\n$$\n\\frac{dJ(t)}{dt} = -p(t \\mid Y=1) + p(t \\mid Y=0)\n$$\nSetting the derivative to zero to find the optimal threshold $t_J$:\n$$\np(t_J \\mid Y=1) = p(t_J \\mid Y=0)\n$$\nThis condition states that the optimal threshold is the point where the two class-conditional PDFs intersect. Substituting the Gaussian PDF expressions:\n$$\n\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(t_J-\\mu_1)^2}{2\\sigma^2}\\right) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(t_J-\\mu_0)^2}{2\\sigma^2}\\right)\n$$\nThe normalization factors cancel. Taking the natural logarithm of both sides:\n$$\n-\\frac{(t_J-\\mu_1)^2}{2\\sigma^2} = -\\frac{(t_J-\\mu_0)^2}{2\\sigma^2}\n$$\n$$\n(t_J-\\mu_1)^2 = (t_J-\\mu_0)^2\n$$\nTaking the square root gives two possibilities. The non-trivial one (where $\\mu_1 \\neq \\mu_0$) is:\n$$\nt_J - \\mu_1 = -(t_J - \\mu_0) = -t_J + \\mu_0\n$$\n$$\n2t_J = \\mu_0 + \\mu_1\n$$\nSolving for $t_J$:\n$$\nt_J = \\frac{\\mu_0 + \\mu_1}{2}\n$$\n\n**3. Numerical Evaluation**\n\nThe given parameters are: $\\mu_{0}=-0.9$, $\\mu_{1}=0.7$, $\\sigma=0.8$, $\\pi=0.2$, $C_{\\mathrm{FN}}=10$, $C_{\\mathrm{FP}}=1$.\n\nFirst, we evaluate $t_J$:\n$$\nt_J = \\frac{-0.9 + 0.7}{2} = \\frac{-0.2}{2} = -0.1\n$$\n\nNext, we evaluate $t_U$. We need the following terms:\n-   The midpoint: $\\frac{\\mu_0 + \\mu_1}{2} = -0.1$\n-   The variance: $\\sigma^2 = (0.8)^2 = 0.64$\n-   The difference in means: $\\mu_1 - \\mu_0 = 0.7 - (-0.9) = 1.6$\n-   The cost-prevalence ratio term:\n$$\n\\frac{(1-\\pi)C_{\\mathrm{FP}}}{\\pi C_{\\mathrm{FN}}} = \\frac{(1-0.2) \\times 1}{0.2 \\times 10} = \\frac{0.8 \\times 1}{2.0} = 0.4\n$$\nNow, substitute these into the expression for $t_U$:\n$$\nt_U = -0.1 + \\frac{0.64}{1.6} \\ln(0.4)\n$$\n$$\nt_U = -0.1 + 0.4 \\ln(0.4)\n$$\nNumerically evaluating this expression:\n$$\n\\ln(0.4) \\approx -0.91629073\n$$\n$$\nt_U \\approx -0.1 + 0.4 \\times (-0.91629073)\n$$\n$$\nt_U \\approx -0.1 - 0.36651629\n$$\n$$\nt_U \\approx -0.46651629\n$$\nRounding to four significant figures, we get $t_U = -0.4665$.", "answer": "$$\\boxed{-0.4665}$$", "id": "4360915"}, {"introduction": "A rigorous scientific assessment requires not only a point estimate of performance but also a quantification of its uncertainty. This final practice introduces a powerful computational method for this purpose: the nonparametric stratified bootstrap. You will implement this resampling technique to construct a confidence interval for the AUC, providing a plausible range for the model's true performance and reflecting the statistical variability inherent in finite datasets. This skill is essential for robustly reporting and interpreting model evaluation results in any research context [@problem_id:4360926].", "problem": "A translational systems biomedicine study evaluates a gene-expression based binary classifier for predicting inflammatory disease status using cross-validation and receiver operating characteristic analysis. The classifier produces probabilistic risk scores for each held-out subject in each fold of cross-validation, and the objective is to assess the model with an area under the receiver operating characteristic curve and to quantify uncertainty using confidence intervals derived from principled resampling. Build a program that, for each specified test case, pools the held-out predictions across folds to approximate out-of-sample performance, computes the area under the receiver operating characteristic curve, and constructs a two-sided confidence interval using a nonparametric stratified bootstrap that preserves the positive-to-negative case ratio.\n\nBegin from the following foundational definitions and facts. The receiver operating characteristic (ROC) curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR) as the decision threshold varies over the real line. For a binary outcome $Y \\in \\{0,1\\}$ with $Y=1$ indicating disease and $Y=0$ indicating no disease, and a real-valued score $S \\in \\mathbb{R}$ where larger values indicate greater evidence for $Y=1$, the True Positive Rate at threshold $t$ is $ \\mathrm{TPR}(t) = \\mathbb{P}(S \\ge t \\mid Y=1)$ and the False Positive Rate is $ \\mathrm{FPR}(t) = \\mathbb{P}(S \\ge t \\mid Y=0)$. The area under the ROC curve (AUC) is the integral $ \\mathrm{AUC} = \\int_{0}^{1} \\mathrm{TPR}(\\mathrm{FPR}^{-1}(u)) \\, du $, and a well-tested probabilistic identity equates the area under the curve with the probability that a randomly chosen positive case has a higher score than a randomly chosen negative case, with ties contributing half-credit, i.e. $ \\mathrm{AUC} = \\mathbb{P}( S^{+} > S^{-} ) + \\tfrac{1}{2} \\mathbb{P}( S^{+} = S^{-} )$. Equivalently, for a finite sample with $m$ positive cases and $n$ negative cases, if ranks are assigned to scores in ascending order with tied scores receiving the average of their ranks, then $ \\mathrm{AUC} = \\dfrac{\\sum_{i: Y_i = 1} R_i - \\frac{m(m+1)}{2}}{m n} $, where $R_i$ is the rank of the score $S_i$. Confidence intervals can be estimated via nonparametric bootstrap resampling: repeatedly resample with replacement the positive cases and the negative cases separately to maintain class imbalance, recompute the statistic on each bootstrap sample, and take appropriate percentiles of the bootstrap distribution to form a percentile-based confidence interval, for instance a two-sided $1-\\alpha$ interval given by the $\\alpha/2$ and $1-\\alpha/2$ quantiles.\n\nImplement the following algorithmic tasks with mathematical and logical precision:\n- Pool held-out predictions across the provided cross-validation folds by concatenating all scores and labels to form a single out-of-sample assessment set.\n- Compute the area under the receiver operating characteristic curve using the rank-based identity above, with ties handled by average ranks.\n- Construct a two-sided percentile confidence interval for the area under the curve using a stratified bootstrap with $B$ resamples and confidence level $1-\\alpha$. In each bootstrap replicate, sample $m$ positive cases with replacement from the pooled positives and $n$ negative cases with replacement from the pooled negatives, combine into a bootstrap sample, and compute the area under the curve. The interval endpoints are the $\\alpha/2$ and $1-\\alpha/2$ empirical quantiles of the bootstrap AUC values.\n\nYour program must implement the above and produce outputs for the following test suite, which is designed to test general performance, handling of near-perfect separation with ties, and handling of class imbalance in small samples. For each test case $j$, the inputs are the number of folds $K_j$, per-fold label arrays $L^{(j)}_k$ and score arrays $S^{(j)}_k$ for $k=1,\\dots,K_j$, the number of bootstrap resamples $B_j$, the confidence parameter $\\alpha_j$, and the bootstrap random seed $r_j$. In each case, labels are $0$ for negative (no disease) and $1$ for positive (disease), and scores are real-valued in $[0,1]$.\n\nTest Case 1 (balanced, moderate effect, $K_1=3$):\n- Fold $1$: $L^{(1)}_1 = [1,1,0,0,1,0,1,0]$, $S^{(1)}_1 = [0.82,0.77,0.40,0.35,0.90,0.55,0.65,0.20]$.\n- Fold $2$: $L^{(1)}_2 = [0,1,0,1,0,1,0,1]$, $S^{(1)}_2 = [0.30,0.88,0.45,0.72,0.25,0.60,0.50,0.78]$.\n- Fold $3$: $L^{(1)}_3 = [1,0,1,0,0,1,0,1]$, $S^{(1)}_3 = [0.70,0.40,0.95,0.35,0.60,0.85,0.55,0.80]$.\n- Bootstrap: $B_1 = 500$, $\\alpha_1 = 0.05$, $r_1 = 42$.\n\nTest Case 2 (near-perfect separation with ties, $K_2=3$):\n- Fold $1$: $L^{(2)}_1 = [1,1,1,0,0,0]$, $S^{(2)}_1 = [0.99,0.97,0.95,0.60,0.60,0.59]$.\n- Fold $2$: $L^{(2)}_2 = [1,0,1,0,1,0]$, $S^{(2)}_2 = [0.90,0.10,0.92,0.12,0.91,0.11]$.\n- Fold $3$: $L^{(2)}_3 = [0,0,1,1,1,0]$, $S^{(2)}_3 = [0.20,0.30,0.85,0.86,0.87,0.30]$.\n- Bootstrap: $B_2 = 300$, $\\alpha_2 = 0.05$, $r_2 = 123$.\n\nTest Case 3 (imbalanced, small sample, $K_3=4$):\n- Fold $1$: $L^{(3)}_1 = [0,0,0,1,0,0]$, $S^{(3)}_1 = [0.10,0.15,0.05,0.65,0.20,0.18]$.\n- Fold $2$: $L^{(3)}_2 = [0,1,0,0,0,1]$, $S^{(3)}_2 = [0.22,0.70,0.30,0.25,0.35,0.68]$.\n- Fold $3$: $L^{(3)}_3 = [0,0,0,0,1,0]$, $S^{(3)}_3 = [0.12,0.27,0.20,0.18,0.75,0.16]$.\n- Fold $4$: $L^{(3)}_4 = [0,0,1,0,0,0]$, $S^{(3)}_4 = [0.33,0.28,0.72,0.25,0.24,0.29]$.\n- Bootstrap: $B_3 = 800$, $\\alpha_3 = 0.05$, $r_3 = 2023$.\n\nRequirements and output specification:\n- For each test case $j$, pool all $L^{(j)}_k$ and $S^{(j)}_k$ over $k=1,\\dots,K_j$, compute the pooled area under the curve $\\mathrm{AUC}_j$, and its two-sided percentile confidence interval endpoints $(\\mathrm{CI}^{\\mathrm{low}}_j, \\mathrm{CI}^{\\mathrm{high}}_j)$ at confidence level $1-\\alpha_j$ using $B_j$ bootstrap replicates with random seed $r_j$.\n- Your program should produce a single line of output containing the nine results as a comma-separated list enclosed in square brackets in the order $[\\mathrm{AUC}_1,\\mathrm{CI}^{\\mathrm{low}}_1,\\mathrm{CI}^{\\mathrm{high}}_1,\\mathrm{AUC}_2,\\mathrm{CI}^{\\mathrm{low}}_2,\\mathrm{CI}^{\\mathrm{high}}_2,\\mathrm{AUC}_3,\\mathrm{CI}^{\\mathrm{low}}_3,\\mathrm{CI}^{\\mathrm{high}}_3]$.\n- Express each numeric output as a decimal float rounded to six places (no percentage signs).", "solution": "The problem statement poses a well-defined and scientifically grounded task in the field of biostatistics and machine learning. It requires the implementation of a standard procedure for evaluating a binary classifier: computing the Area Under the Receiver Operating Characteristic curve (AUC) from pooled cross-validation predictions and constructing a confidence interval using a stratified nonparametric bootstrap. The problem is valid as it is self-contained, logically consistent, and based on established statistical principles.\n\nThe solution will be developed by first establishing the theoretical and algorithmic framework, then implementing this framework to process the specified test cases.\n\n### Principles of the Method\n\n1.  **Pooling Cross-Validation Folds**: In $k$-fold cross-validation, a dataset is partitioned into $k$ subsets. The model is trained $k$ times, each time holding out one subset for testing and training on the remaining $k-1$ subsets. This yields $k$ sets of predictions on unseen data. Pooling these predictions—concatenating the scores and corresponding true labels from all held-out folds—creates a single, larger set of out-of-sample predictions. This approach provides a more stable and robust estimate of the model's generalization performance compared to averaging performance metrics computed on each small fold individually.\n\n2.  **Area Under the ROC Curve (AUC)**: The AUC is a scalar measure of a classifier's ability to distinguish between two classes. A value of $1.0$ represents a perfect classifier, while a value of $0.5$ indicates performance no better than random chance. The problem provides the rank-based formula for computing the AUC for a finite sample of $m$ positive cases and $n$ negative cases:\n    $$ \\mathrm{AUC} = \\frac{\\sum_{i: Y_i = 1} R_i - \\frac{m(m+1)}{2}}{m n} $$\n    Here, $Y_i \\in \\{0, 1\\}$ are the true labels ($1$ for positive, $0$ for negative), and $R_i$ is the rank of the classifier's score $S_i$ for the $i$-th positive case, when all scores from both classes are ranked together. Ranks are assigned in ascending order of scores (lower scores get lower ranks). Critically, when scores are tied, they are assigned the average of the ranks they would otherwise occupy. This formulation is equivalent to the Wilcoxon-Mann-Whitney U statistic and directly computes the AUC without constructing the ROC curve explicitly, making it computationally efficient.\n\n3.  **Stratified Bootstrap for Confidence Intervals**: To quantify the uncertainty in our AUC estimate, we employ a nonparametric bootstrap procedure. A confidence interval provides a range of plausible values for the true, underlying AUC. The procedure is as follows:\n    - **Stratification**: The set of pooled predictions is separated into positive ($m$ cases) and negative ($n$ cases) subsets. Stratification ensures that the class ratio ($m:n$) of the original sample is preserved in each bootstrap resample. This is crucial for the stability of the AUC estimate, especially in imbalanced datasets.\n    - **Resampling**: For a specified number of bootstrap replicates $B$, we generate $B$ new datasets. Each bootstrap dataset is formed by sampling $m$ scores *with replacement* from the set of positive scores and $n$ scores *with replacement* from the set of negative scores.\n    - **Re-computation**: The AUC is calculated for each of the $B$ bootstrap datasets. This generates a distribution of $B$ bootstrap AUC values.\n    - **Percentile Interval**: A two-sided $1-\\alpha$ confidence interval is constructed by taking the empirical quantiles of the bootstrap distribution. The lower bound is the $(\\alpha/2)$-th quantile, and the upper bound is the $(1-\\alpha/2)$-th quantile. For example, for a $95\\%$ confidence interval ($\\alpha=0.05$), we use the $2.5$-th and $97.5$-th percentiles of the bootstrap AUCs. This method relies on the provided random seed for reproducibility.\n\n### Algorithmic Implementation Steps\n\nFor each test case, the following sequence of operations will be performed:\n\n1.  **Data Aggregation**: The label arrays $L_{k}$ and score arrays $S_{k}$ from all $K$ folds are concatenated to form a single pooled label array, $L_{\\text{pooled}}$, and a single pooled score array, $S_{\\text{pool}}$.\n\n2.  **Point Estimate of AUC**: The `calculate_auc` function is applied to $L_{\\text{pool}}$ and $S_{\\text{pool}}$.\n    a.  The function first obtains the counts of positive cases, $m$, and negative cases, $n$.\n    b.  It then computes the ranks of all scores in $S_{\\text{pool}}$. This is done by first sorting pairs of (score, original index) and then iterating through the sorted list to identify groups of tied scores. Each score in a tied group is assigned the average of the 1-based ranks that the group occupies.\n    c.  The ranks corresponding to the positive cases (where $L_{\\text{pool}} = 1$) are summed.\n    d.  The final AUC is calculated using the rank-based formula.\n\n3.  **Confidence Interval Estimation**: A function `bootstrap_ci` is used to generate the confidence interval.\n    a.  The random number generator is seeded with the specified value $r_j$ to ensure reproducibility.\n    b.  The pooled scores are separated into a positive-case array ($S_{\\text{pos}}$) and a negative-case array ($S_{\\text{neg}}$).\n    c.  A loop runs $B_j$ times. In each iteration:\n        i. A bootstrap sample of $m$ scores is drawn with replacement from $S_{\\text{pos}}$.\n        ii. A bootstrap sample of $n$ scores is drawn with replacement from $S_{\\text{neg}}$.\n        iii. These two samples are combined. The `calculate_auc` function is called on this new bootstrap dataset.\n        iv. The resulting AUC value is stored.\n    d. After the loop, the lower and upper bounds of the confidence interval, $\\mathrm{CI}^{\\mathrm{low}}$ and $\\mathrm{CI}^{\\mathrm{high}}$, are calculated as the $(\\alpha_j/2)$ and $(1-\\alpha_j/2)$ quantiles of the collected bootstrap AUCs.\n\n4.  **Output Formatting**: The computed point estimate $\\mathrm{AUC}_j$ and the confidence interval bounds $(\\mathrm{CI}^{\\mathrm{low}}_j, \\mathrm{CI}^{\\mathrm{high}}_j)$ are formatted to six decimal places. This process is repeated for all test cases, and the nine resulting values are aggregated into a single comma-separated string enclosed in brackets.", "answer": "```python\nimport numpy as np\n\ndef calculate_auc(labels, scores):\n    \"\"\"\n    Computes the Area Under the ROC Curve (AUC) using the rank-based formula.\n    Handles ties by assigning average ranks.\n    \"\"\"\n    labels = np.asarray(labels)\n    scores = np.asarray(scores)\n\n    pos_indices = np.where(labels == 1)[0]\n    neg_indices = np.where(labels == 0)[0]\n    \n    m = len(pos_indices)\n    n = len(neg_indices)\n\n    if m == 0 or n == 0:\n        return 0.5\n\n    # Manual implementation of ranking with tie handling ('average' method)\n    # This avoids dependency on scipy.stats.rankdata and demonstrates the principle.\n    scores_with_indices = sorted(zip(scores, range(len(scores))))\n    ranks = np.zeros(len(scores))\n    \n    i = 0\n    while i < len(scores):\n        j = i\n        # Find end of tie group\n        while j < len(scores) - 1 and scores_with_indices[j+1][0] == scores_with_indices[i][0]:\n            j += 1\n        \n        # Ranks are 1-based, so add 1 to indices\n        rank_sum = sum(range(i + 1, j + 2))\n        avg_rank = rank_sum / (j - i + 1)\n        \n        # Assign average rank to all tied elements\n        for k in range(i, j + 1):\n            original_index = scores_with_indices[k][1]\n            ranks[original_index] = avg_rank\n        \n        i = j + 1\n\n    sum_of_pos_ranks = np.sum(ranks[pos_indices])\n    \n    auc = (sum_of_pos_ranks - m * (m + 1) / 2.0) / (m * n)\n    return auc\n\n\ndef bootstrap_ci(labels, scores, B, alpha, seed):\n    \"\"\"\n    Constructs a two-sided percentile confidence interval for the AUC\n    using a stratified bootstrap.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    labels = np.asarray(labels)\n    scores = np.asarray(scores)\n\n    pos_scores = scores[labels == 1]\n    neg_scores = scores[labels == 0]\n    \n    m = len(pos_scores)\n    n = len(neg_scores)\n\n    if m == 0 or n == 0:\n        return 0.5, 0.5\n        \n    bootstrap_aucs = np.zeros(B)\n    for i in range(B):\n        pos_sample = rng.choice(pos_scores, size=m, replace=True)\n        neg_sample = rng.choice(neg_scores, size=n, replace=True)\n        \n        boot_scores = np.concatenate([pos_sample, neg_sample])\n        boot_labels = np.concatenate([np.ones(m), np.zeros(n)])\n        \n        bootstrap_aucs[i] = calculate_auc(boot_labels, boot_scores)\n\n    ci_low = np.quantile(bootstrap_aucs, alpha / 2.0)\n    ci_high = np.quantile(bootstrap_aucs, 1.0 - alpha / 2.0)\n    \n    return ci_low, ci_high\n\n\ndef solve():\n    test_cases = [\n        # Test Case 1\n        {\n            \"folds\": [\n                (np.array([1,1,0,0,1,0,1,0]), np.array([0.82,0.77,0.40,0.35,0.90,0.55,0.65,0.20])),\n                (np.array([0,1,0,1,0,1,0,1]), np.array([0.30,0.88,0.45,0.72,0.25,0.60,0.50,0.78])),\n                (np.array([1,0,1,0,0,1,0,1]), np.array([0.70,0.40,0.95,0.35,0.60,0.85,0.55,0.80]))\n            ],\n            \"B\": 500, \"alpha\": 0.05, \"r\": 42\n        },\n        # Test Case 2\n        {\n            \"folds\": [\n                (np.array([1,1,1,0,0,0]), np.array([0.99,0.97,0.95,0.60,0.60,0.59])),\n                (np.array([1,0,1,0,1,0]), np.array([0.90,0.10,0.92,0.12,0.91,0.11])),\n                (np.array([0,0,1,1,1,0]), np.array([0.20,0.30,0.85,0.86,0.87,0.30]))\n            ],\n            \"B\": 300, \"alpha\": 0.05, \"r\": 123\n        },\n        # Test Case 3\n        {\n            \"folds\": [\n                (np.array([0,0,0,1,0,0]), np.array([0.10,0.15,0.05,0.65,0.20,0.18])),\n                (np.array([0,1,0,0,0,1]), np.array([0.22,0.70,0.30,0.25,0.35,0.68])),\n                (np.array([0,0,0,0,1,0]), np.array([0.12,0.27,0.20,0.18,0.75,0.16])),\n                (np.array([0,0,1,0,0,0]), np.array([0.33,0.28,0.72,0.25,0.24,0.29]))\n            ],\n            \"B\": 800, \"alpha\": 0.05, \"r\": 2023\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        # Pool held-out predictions across folds\n        pooled_labels = np.concatenate([data[0] for data in case[\"folds\"]])\n        pooled_scores = np.concatenate([data[1] for data in case[\"folds\"]])\n        \n        # Compute pooled AUC\n        pooled_auc = calculate_auc(pooled_labels, pooled_scores)\n        \n        # Construct bootstrap confidence interval\n        ci_low, ci_high = bootstrap_ci(pooled_labels, pooled_scores, case[\"B\"], case[\"alpha\"], case[\"r\"])\n        \n        all_results.extend([pooled_auc, ci_low, ci_high])\n\n    # Format output to six decimal places as specified\n    formatted_results = [f\"{res:.6f}\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4360926"}]}