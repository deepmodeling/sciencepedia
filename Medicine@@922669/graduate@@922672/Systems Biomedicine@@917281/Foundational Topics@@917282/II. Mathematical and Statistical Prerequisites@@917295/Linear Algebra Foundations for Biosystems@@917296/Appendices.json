{"hands_on_practices": [{"introduction": "Experimental data in systems biology often comes in the form of time-series vectors. A fundamental question is whether different measurements, such as the responses of several proteins, represent truly distinct dynamical signatures or are simply variations of one another. This exercise [@problem_id:4358122] will guide you through using the concept of linear independence to answer this question, helping you to distinguish unique biological behaviors from correlated ones within a dataset.", "problem": "A signaling pathway experiment in systems biomedicine measures the concentrations of three phosphorylated proteins at $4$ equally spaced time points after stimulation, producing three time series vectors in the sample space $\\mathbb{R}^{4}$: \n$$\nx_{1} = \\begin{pmatrix}1\\\\3\\\\5\\\\7\\end{pmatrix},\\quad\nx_{2} = \\begin{pmatrix}2\\\\1\\\\0\\\\-1\\end{pmatrix},\\quad\nx_{3} = \\begin{pmatrix}3\\\\4\\\\5\\\\6\\end{pmatrix}.\n$$\nTo focus on dynamical signatures rather than static offsets, the dynamical component of each time series is defined as its mean-centered form, obtained by applying the centering operator $H$ on $\\mathbb{R}^{4}$, where $H$ is given by $H = I - \\frac{1}{4}\\mathbf{1}\\mathbf{1}^{\\top}$, $I$ is the identity matrix, and $\\mathbf{1}$ is the length-$4$ vector of ones. Measurement reliability is captured by a positive definite diagonal weighting matrix \n$$\nW = \\mathrm{diag}(1,\\,2,\\,1,\\,3),\n$$ \nwhich induces a weighted inner product $\\langle u, v \\rangle_{W} = u^{\\top} W v$ on $\\mathbb{R}^{4}$. Using fundamental definitions from linear algebra, determine the number of distinct dynamical signatures present in the experiment, defined as the dimension of the span of the mean-centered vectors under this positive definite weighting. Express your final answer as a single real-valued number (unitless). No rounding is required.", "solution": "The problem requires us to determine the number of distinct dynamical signatures, which is defined as the dimension of the subspace spanned by a set of mean-centered time series vectors.\n\nFirst, we must establish the quantities provided. We are given three vectors in $\\mathbb{R}^{4}$:\n$$\nx_{1} = \\begin{pmatrix}1\\\\3\\\\5\\\\7\\end{pmatrix}, \\quad\nx_{2} = \\begin{pmatrix}2\\\\1\\\\0\\\\-1\\end{pmatrix}, \\quad\nx_{3} = \\begin{pmatrix}3\\\\4\\\\5\\\\6\\end{pmatrix}\n$$\nThe dynamical component of a vector $x \\in \\mathbb{R}^{4}$ is its mean-centered form, obtained by applying the centering operator $H = I - \\frac{1}{4}\\mathbf{1}\\mathbf{1}^{\\top}$, where $I$ is the $4 \\times 4$ identity matrix and $\\mathbf{1}$ is the $4 \\times 1$ vector of ones. The problem also specifies a weighting matrix $W = \\mathrm{diag}(1, 2, 1, 3)$ and an associated weighted inner product $\\langle u, v \\rangle_{W} = u^{\\top} W v$.\n\nThe objective is to find the dimension of the subspace spanned by the mean-centered vectors, $\\dim(\\mathrm{span}\\{Hx_1, Hx_2, Hx_3\\})$. It is a fundamental principle of linear algebra that the dimension of a vector subspace is an intrinsic property, defined by the maximum number of linearly independent vectors in any basis for that subspace. The definition of linear independence of a set of vectors $\\{v_1, \\dots, v_k\\}$ is that the equation $\\sum_{i=1}^k c_i v_i = 0$ holds if and only if all scalar coefficients $c_i$ are zero. This definition does not depend on any inner product. Consequently, the dimension of the span is invariant with respect to the choice of inner product on the space $\\mathbb{R}^{4}$. The provided weighting matrix $W$ and the inner product $\\langle u, v \\rangle_{W}$ are therefore irrelevant to the calculation of the dimension. This information would be pertinent for questions concerning vector norms, angles, or orthogonality within the weighted space, but not for dimension.\n\nWe proceed by computing the mean-centered vectors. For any vector $x \\in \\mathbb{R}^{4}$, the vector $Hx$ is obtained by subtracting the mean of the components of $x$ from each component. Let $\\bar{x} = \\frac{1}{4}\\mathbf{1}^{\\top}x$ be the mean of the components of $x$. Then, $Hx = x - (\\frac{1}{4}\\mathbf{1}\\mathbf{1}^{\\top})x = x - \\mathbf{1}(\\frac{1}{4}\\mathbf{1}^{\\top}x) = x - \\bar{x}\\mathbf{1}$.\n\nLet us denote the mean-centered vectors as $y_i = Hx_i$ for $i \\in \\{1, 2, 3\\}$.\n\nFor $x_1$:\nThe mean is $\\bar{x}_1 = \\frac{1+3+5+7}{4} = \\frac{16}{4} = 4$.\nThe mean-centered vector is:\n$$\ny_1 = x_1 - \\bar{x}_1\\mathbf{1} = \\begin{pmatrix}1\\\\3\\\\5\\\\7\\end{pmatrix} - 4\\begin{pmatrix}1\\\\1\\\\1\\\\1\\end{pmatrix} = \\begin{pmatrix}1-4\\\\3-4\\\\5-4\\\\7-4\\end{pmatrix} = \\begin{pmatrix}-3\\\\-1\\\\1\\\\3\\end{pmatrix}\n$$\n\nFor $x_2$:\nThe mean is $\\bar{x}_2 = \\frac{2+1+0-1}{4} = \\frac{2}{4} = \\frac{1}{2}$.\nThe mean-centered vector is:\n$$\ny_2 = x_2 - \\bar{x}_2\\mathbf{1} = \\begin{pmatrix}2\\\\1\\\\0\\\\-1\\end{pmatrix} - \\frac{1}{2}\\begin{pmatrix}1\\\\1\\\\1\\\\1\\end{pmatrix} = \\begin{pmatrix}2-\\frac{1}{2}\\\\1-\\frac{1}{2}\\\\0-\\frac{1}{2}\\\\-1-\\frac{1}{2}\\end{pmatrix} = \\begin{pmatrix}3/2\\\\1/2\\\\-1/2\\\\-3/2\\end{pmatrix}\n$$\n\nFor $x_3$:\nThe mean is $\\bar{x}_3 = \\frac{3+4+5+6}{4} = \\frac{18}{4} = \\frac{9}{2}$.\nThe mean-centered vector is:\n$$\ny_3 = x_3 - \\bar{x}_3\\mathbf{1} = \\begin{pmatrix}3\\\\4\\\\5\\\\6\\end{pmatrix} - \\frac{9}{2}\\begin{pmatrix}1\\\\1\\\\1\\\\1\\end{pmatrix} = \\begin{pmatrix}3-\\frac{9}{2}\\\\4-\\frac{9}{2}\\\\5-\\frac{9}{2}\\\\6-\\frac{9}{2}\\end{pmatrix} = \\begin{pmatrix}-3/2\\\\-1/2\\\\1/2\\\\3/2\\end{pmatrix}\n$$\n\nNow, we must find the dimension of the span of the set of vectors $\\{y_1, y_2, y_3\\}$. This is equivalent to finding the rank of the matrix whose columns are these vectors. We can determine this by checking for linear dependence among the vectors.\nLet's inspect the relationships between $y_1$, $y_2$, and $y_3$.\nComparing $y_1$ and $y_3$:\n$$\ny_1 = \\begin{pmatrix}-3\\\\-1\\\\1\\\\3\\end{pmatrix}, \\quad y_3 = \\begin{pmatrix}-3/2\\\\-1/2\\\\1/2\\\\3/2\\end{pmatrix}\n$$\nBy inspection, we see that each component of $y_3$ is exactly one-half of the corresponding component of $y_1$. Thus, $y_3 = \\frac{1}{2}y_1$.\n\nComparing $y_1$ and $y_2$:\n$$\ny_1 = \\begin{pmatrix}-3\\\\-1\\\\1\\\\3\\end{pmatrix}, \\quad y_2 = \\begin{pmatrix}3/2\\\\1/2\\\\-1/2\\\\-3/2\\end{pmatrix}\n$$\nFactoring out a scalar from $y_2$, we can write $y_2 = \\frac{1}{2}\\begin{pmatrix}3\\\\1\\\\-1\\\\-3\\end{pmatrix} = -\\frac{1}{2}\\begin{pmatrix}-3\\\\-1\\\\1\\\\3\\end{pmatrix}$. This shows that $y_2 = -\\frac{1}{2}y_1$.\n\nSince both $y_2$ and $y_3$ are scalar multiples of $y_1$, the set $\\{y_1, y_2, y_3\\}$ is linearly dependent. The span of this set is equivalent to the span of $y_1$ alone, because any linear combination of $y_1, y_2, y_3$ can be expressed as a scalar multiple of $y_1$:\n$$\nc_1 y_1 + c_2 y_2 + c_3 y_3 = c_1 y_1 + c_2 \\left(-\\frac{1}{2}y_1\\right) + c_3 \\left(\\frac{1}{2}y_1\\right) = \\left(c_1 - \\frac{1}{2}c_2 + \\frac{1}{2}c_3\\right)y_1\n$$\nThe span is therefore $\\mathrm{span}\\{y_1, y_2, y_3\\} = \\mathrm{span}\\{y_1\\}$.\n\nThe vector $y_1 = \\begin{pmatrix}-3\\\\-1\\\\1\\\\3\\end{pmatrix}$ is a non-zero vector. The dimension of the subspace spanned by a single non-zero vector is $1$.\n\nTherefore, the number of distinct dynamical signatures, defined as the dimension of the span of the mean-centered vectors, is $1$.", "answer": "$$\\boxed{1}$$", "id": "4358122"}, {"introduction": "The states of a biological system are not arbitrary; they are governed by fundamental physical constraints such as the conservation of mass. This practice [@problem_id:4358130] explores how these constraints confine the system's reachable states to an affine subspace. You will demonstrate the crucial distinction between this affine space and the true vector subspace inhabited by perturbations around a steady state, clarifying the geometric foundation for analyzing system dynamics.", "problem": "Consider a single-cell biosystem in which the adenine nucleotide pool and the nicotinamide nucleotide pool are conserved over the experimental timescale due to negligible de novo synthesis, degradation, and external exchange. Let the concentrations of Adenosine Triphosphate (ATP), Adenosine Diphosphate (ADP), Adenosine Monophosphate (AMP), Nicotinamide Adenine Dinucleotide (oxidized form, NAD), and Nicotinamide Adenine Dinucleotide (reduced form, NADH) be denoted by the state vector $x \\in \\mathbb{R}^{5}$ with $x = \\big(x_{1}, x_{2}, x_{3}, x_{4}, x_{5}\\big)$ corresponding to $(\\mathrm{ATP}, \\mathrm{ADP}, \\mathrm{AMP}, \\mathrm{NAD}, \\mathrm{NADH})$, respectively. Empirically, total adenine nucleotides and total nicotinamide nucleotides are conserved, i.e., there exist fixed totals $A_{T}$ and $N_{T}$ such that $x_{1} + x_{2} + x_{3} = A_{T}$ and $x_{4} + x_{5} = N_{T}$. These conservation constraints can be written compactly as $C x = c$ with\n$$\nC = \\begin{pmatrix}\n1 & 1 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1 & 1\n\\end{pmatrix}, \\quad\nc = \\begin{pmatrix}\nA_{T} \\\\\nN_{T}\n\\end{pmatrix}.\n$$\nSuppose the biosystem attains a steady state $x^{\\ast} \\in \\mathbb{R}^{5}$ satisfying $C x^{\\ast} = c$ with the biologically plausible totals $A_{T} = 3.0 \\times 10^{-3}$ and $N_{T} = 1.0 \\times 10^{-3}$ (expressed in molar units), and a steady-state concentration vector\n$$\nx^{\\ast} = \\begin{pmatrix}\n1.2 \\times 10^{-3} \\\\\n1.5 \\times 10^{-3} \\\\\n0.3 \\times 10^{-3} \\\\\n0.7 \\times 10^{-3} \\\\\n0.3 \\times 10^{-3}\n\\end{pmatrix}.\n$$\nStarting from fundamental mass conservation and the linear algebra definition of an affine subspace as the solution set of a system of linear equations with constant terms, do the following:\n1. Justify why the reachable state space $\\mathcal{A} = \\{ x \\in \\mathbb{R}^{5} \\mid C x = c \\}$ is an affine subspace constrained by conservation laws, and verify that $x^{\\ast} \\in \\mathcal{A}$ using the given $A_{T}$ and $N_{T}$.\n2. Show that the perturbations $y = x - x^{\\ast}$ about the steady state are confined to the set $\\mathcal{S} = \\{ y \\in \\mathbb{R}^{5} \\mid C y = 0 \\}$, and explain why $\\mathcal{S}$ is a true vector subspace.\n3. Compute the exact dimension of the perturbation subspace $\\mathcal{S}$ as a single real-valued number. No rounding is required, and no units are to be reported for the final dimension.", "solution": "**Part 1: The Reachable State Space $\\mathcal{A}$**\n\nThe reachable state space is defined by the set $\\mathcal{A} = \\{ x \\in \\mathbb{R}^{5} \\mid C x = c \\}$. By definition, the solution set to a consistent system of linear equations $Ax=b$ is an affine subspace. Here, the existence of a steady state $x^*$ satisfying the condition confirms the system is consistent. An affine subspace can be expressed as a particular solution translated by the null space of the matrix, i.e., $\\mathcal{A} = x^* + \\mathrm{Null}(C)$.\n\nTo verify that the given steady state $x^*$ is in $\\mathcal{A}$, we compute $C x^*$:\n$$\nC x^{\\ast} = \\begin{pmatrix} 1 & 1 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1.2 \\times 10^{-3} \\\\ 1.5 \\times 10^{-3} \\\\ 0.3 \\times 10^{-3} \\\\ 0.7 \\times 10^{-3} \\\\ 0.3 \\times 10^{-3} \\end{pmatrix} = \\begin{pmatrix} (1.2 + 1.5 + 0.3) \\times 10^{-3} \\\\ (0.7 + 0.3) \\times 10^{-3} \\end{pmatrix} = \\begin{pmatrix} 3.0 \\times 10^{-3} \\\\ 1.0 \\times 10^{-3} \\end{pmatrix}\n$$\nThis result matches the vector of totals $c = (A_T, N_T)^T$. Thus, $x^{\\ast} \\in \\mathcal{A}$.\n\n**Part 2: The Perturbation Subspace $\\mathcal{S}$**\n\nA perturbation about the steady state is defined as $y = x - x^{\\ast}$, where $x$ is any reachable state in $\\mathcal{A}$. Since both $x$ and $x^*$ are in $\\mathcal{A}$, they both satisfy the conservation law: $Cx = c$ and $Cx^* = c$.\nApplying the matrix $C$ to the perturbation vector $y$:\n$$ C y = C (x - x^{\\ast}) = C x - C x^{\\ast} = c - c = 0 $$\nThis shows that any perturbation vector $y$ must satisfy $C y = 0$, meaning all perturbations lie in the set $\\mathcal{S} = \\{ y \\in \\mathbb{R}^{5} \\mid C y = 0 \\}$.\n\nThe set $\\mathcal{S}$ is a true vector subspace because it is the null space of the matrix $C$. A set is a vector subspace if it contains the zero vector, is closed under vector addition, and is closed under scalar multiplication.\n1.  **Zero vector**: $C(0) = 0$, so $0 \\in \\mathcal{S}$.\n2.  **Closure under addition**: If $y_1, y_2 \\in \\mathcal{S}$, then $C y_1 = 0$ and $C y_2 = 0$. It follows that $C(y_1 + y_2) = C y_1 + C y_2 = 0 + 0 = 0$, so $y_1+y_2 \\in \\mathcal{S}$.\n3.  **Closure under scalar multiplication**: If $y \\in \\mathcal{S}$ and $k$ is a scalar, then $C y = 0$. It follows that $C(k y) = k(C y) = k(0) = 0$, so $ky \\in \\mathcal{S}$.\nSince all three axioms hold, $\\mathcal{S}$ is a vector subspace.\n\n**Part 3: Dimension of the Perturbation Subspace $\\mathcal{S}$**\n\nThe dimension of the perturbation subspace $\\mathcal{S}$ is the dimension of the null space of $C$, also known as the nullity of $C$. According to the Rank-Nullity Theorem, for a matrix with $n$ columns, $\\mathrm{rank}(C) + \\mathrm{nullity}(C) = n$.\n\nThe matrix $C$ is a $2 \\times 5$ matrix, so $n=5$. Its rows are $(1, 1, 1, 0, 0)$ and $(0, 0, 0, 1, 1)$. These two rows are linearly independent because neither is a scalar multiple of the other. Therefore, the rank of $C$ is 2.\n\nUsing the Rank-Nullity Theorem:\n$$ \\mathrm{dim}(\\mathcal{S}) = \\mathrm{nullity}(C) = n - \\mathrm{rank}(C) = 5 - 2 = 3 $$\nAlternatively, the dimension of the null space is the number of free variables in the homogeneous system $Cy=0$. The system is $y_1+y_2+y_3=0$ and $y_4+y_5=0$. In row-echelon form, $y_1$ and $y_4$ are pivot variables, while $y_2$, $y_3$, and $y_5$ are free variables. The number of free variables is 3, which confirms that the dimension of the null space is 3.\n\nThe dimension of the perturbation subspace $\\mathcal{S}$ is 3.", "answer": "$$\\boxed{3}$$", "id": "4358130"}, {"introduction": "Understanding how a biological system responds to small disturbances is central to predicting its behavior. This practice [@problem_id:4358165] introduces one of the most powerful tools for this purpose: local stability analysis via the Jacobian matrix. By linearizing a nonlinear system at its steady state, you will learn to use the eigenvalues of the Jacobian to determine whether the system is stable and to characterize the timescales of its return to equilibrium.", "problem": "Consider a well-mixed single-cell metabolic module modeled by ordinary differential equations (ODEs) for two intracellular metabolites, with inflow, enzymatic conversion, and dilution. Metabolite $x$ is supplied at a constant rate $a$ and converted into metabolite $y$ by an enzyme following Michaelis–Menten kinetics. Metabolite $y$ is further removed by another enzyme that also follows Michaelis–Menten kinetics. Both metabolites are diluted with a first-order rate constant $d$ due to cell growth. Let $v_{1}(x)$ denote the Michaelis–Menten rate for $x \\to y$, and $v_{2}(y)$ for the removal of $y$. The mass balances are\n$$\n\\frac{dx}{dt} \\;=\\; a \\;-\\; v_{1}(x) \\;-\\; d\\,x, \n\\qquad\n\\frac{dy}{dt} \\;=\\; v_{1}(x) \\;-\\; v_{2}(y) \\;-\\; d\\,y,\n$$\nwith Michaelis–Menten forms\n$$\nv_{1}(x) \\;=\\; \\frac{V_{1}\\,x}{K_{1}+x},\n\\qquad\nv_{2}(y) \\;=\\; \\frac{V_{2}\\,y}{K_{2}+y}.\n$$\nUse as given parameters $K_{1}=1$, $K_{2}=2$, $d=0.1$, $V_{1}=2.0$, $V_{2}=1.6$, and $a=1.1$. \n\nTasks:\n- Starting from the definitions of the vector field and the Jacobian matrix (the matrix of first partial derivatives of the right-hand side with respect to the state variables), construct the Jacobian matrix $J(x,y)$ symbolically for this system.\n- Verify from the steady-state conditions that $(x^{\\ast},y^{\\ast})=(1,2)$ is a steady state for the given parameters.\n- Evaluate the Jacobian matrix at $(x^{\\ast},y^{\\ast})$ and determine the eigenvalue with the largest real part (the dominant eigenvalue), which governs the leading-order local stability and timescale of return to the steady state.\n\nProvide your final answer as a single exact real number representing the dominant eigenvalue. Do not include units. No rounding is required.", "solution": "The solution proceeds according to the three tasks outlined in the problem.\n\n**1. Construct the Jacobian Matrix**\n\nThe system is described by the vector field $\\mathbf{F}(x,y) = (f(x,y), g(x,y))^T$, where:\n$$ f(x,y) = a - \\frac{V_{1}\\,x}{K_{1}+x} - d\\,x $$\n$$ g(x,y) = \\frac{V_{1}\\,x}{K_{1}+x} - \\frac{V_{2}\\,y}{K_{2}+y} - d\\,y $$\nThe Jacobian matrix $J(x,y)$ is the matrix of first partial derivatives:\n$$ J(x,y) = \\begin{pmatrix} \\frac{\\partial f}{\\partial x} & \\frac{\\partial f}{\\partial y} \\\\ \\frac{\\partial g}{\\partial x} & \\frac{\\partial g}{\\partial y} \\end{pmatrix} $$\nWe compute each element using the quotient rule for the Michaelis-Menten terms:\n*   $\\frac{\\partial f}{\\partial x} = -\\frac{\\partial}{\\partial x}\\left(\\frac{V_{1}\\,x}{K_{1}+x}\\right) - d = -V_{1}\\frac{K_{1}}{(K_{1}+x)^2} - d$\n*   $\\frac{\\partial f}{\\partial y} = 0$\n*   $\\frac{\\partial g}{\\partial x} = \\frac{\\partial}{\\partial x}\\left(\\frac{V_{1}\\,x}{K_{1}+x}\\right) = V_{1}\\frac{K_{1}}{(K_{1}+x)^2}$\n*   $\\frac{\\partial g}{\\partial y} = -\\frac{\\partial}{\\partial y}\\left(\\frac{V_{2}\\,y}{K_{2}+y}\\right) - d = -V_{2}\\frac{K_{2}}{(K_{2}+y)^2} - d$\n\nThe symbolic Jacobian matrix is:\n$$ J(x,y) = \\begin{pmatrix} -\\frac{V_{1}K_{1}}{(K_{1}+x)^2} - d & 0 \\\\ \\frac{V_{1}K_{1}}{(K_{1}+x)^2} & -\\frac{V_{2}K_{2}}{(K_{2}+y)^2} - d \\end{pmatrix} $$\n\n**2. Verify the Steady State**\n\nWe must verify that $\\mathbf{F}(x^*, y^*) = (0,0)^T$ for $(x^{\\ast},y^{\\ast})=(1,2)$ with parameters $a=1.1, K_{1}=1, V_{1}=2.0, d=0.1, K_{2}=2, V_{2}=1.6$.\n\nFor the first component:\n$$ \\frac{dx}{dt} \\bigg|_{(1,2)} = 1.1 - \\frac{2.0 \\cdot 1}{1+1} - 0.1 \\cdot 1 = 1.1 - 1.0 - 0.1 = 0 $$\nFor the second component:\n$$ \\frac{dy}{dt} \\bigg|_{(1,2)} = \\frac{2.0 \\cdot 1}{1+1} - \\frac{1.6 \\cdot 2}{2+2} - 0.1 \\cdot 2 = 1.0 - \\frac{3.2}{4} - 0.2 = 1.0 - 0.8 - 0.2 = 0 $$\nBoth rates are zero, so $(1,2)$ is a steady state.\n\n**3. Evaluate the Jacobian and Find the Dominant Eigenvalue**\n\nWe evaluate the Jacobian matrix at the steady state $(x^{\\ast}, y^{\\ast}) = (1, 2)$:\n*   $J_{11} = -\\frac{2.0 \\cdot 1}{(1+1)^2} - 0.1 = -\\frac{2.0}{4} - 0.1 = -0.5 - 0.1 = -0.6$\n*   $J_{12} = 0$\n*   $J_{21} = \\frac{2.0 \\cdot 1}{(1+1)^2} = \\frac{2.0}{4} = 0.5$\n*   $J_{22} = -\\frac{1.6 \\cdot 2}{(2+2)^2} - 0.1 = -\\frac{3.2}{16} - 0.1 = -0.2 - 0.1 = -0.3$\n\nThe evaluated Jacobian matrix $J^*$ is:\n$$ J^{\\ast} = \\begin{pmatrix} -0.6 & 0 \\\\ 0.5 & -0.3 \\end{pmatrix} $$\nSince this is a lower triangular matrix, its eigenvalues are its diagonal entries. The eigenvalues are $\\lambda_1 = -0.6$ and $\\lambda_2 = -0.3$.\n\nThe dominant eigenvalue is the one with the largest (least negative) real part:\n$$ \\max(\\text{Re}(\\lambda_1), \\text{Re}(\\lambda_2)) = \\max(-0.6, -0.3) = -0.3 $$\nThe dominant eigenvalue is $-0.3$.", "answer": "$$\\boxed{-0.3}$$", "id": "4358165"}]}