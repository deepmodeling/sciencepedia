{"hands_on_practices": [{"introduction": "To begin, we will walk through the core mechanics of the Benjamini–Hochberg (BH) procedure. This foundational exercise requires you to apply the step-up algorithm from first principles to a small set of $p$-values, ensuring you can correctly rank the values, apply the critical value test at each rank, and identify the final set of rejected hypotheses. Mastering this fundamental calculation is the first step toward confidently applying and interpreting multiple testing corrections in your own research [@problem_id:4363527].", "problem": "In a systems biomedicine investigation of a perturbation to an intracellular signaling network, you measure changes in messenger ribonucleic acid (mRNA) abundance for $m=10$ candidate genes thought to function as hubs that integrate stress signals. For each gene, you perform a null-hypothesis test of no change under perturbation relative to control, obtaining the following vector of $p$-values (ordered by the gene indexing used in the assay design, not by magnitude):\n$$\n\\mathbf{p} = \\left(0.0009,\\ 0.003,\\ 0.021,\\ 0.055,\\ 0.13,\\ 0.24,\\ 0.0004,\\ 0.0085,\\ 0.041,\\ 0.72\\right).\n$$\nYou aim to control the False Discovery Rate (FDR) at target level $q=0.1$ using the Benjamini–Hochberg procedure. Starting from fundamental definitions of FDR and the canonical steps underlying Benjamini–Hochberg, compute the Benjamini–Hochberg rejection set at level $q=0.1$ for the given $p$-values. Your derivation must explicitly show:\n- the ranking of the $p$-values in ascending order with their original gene indices,\n- the sequence of threshold comparisons at each rank,\n- the identification of the largest rank $k$ that determines the step-up cutoff,\n- the mapping back to the original indices to state the final rejection set.\n\nExpress the final rejection set as the list of original gene indices written in increasing numerical order. The final answer must be a calculation and should be given as a single row matrix using the LaTeX $\\mathrm{pmatrix}$ environment inside the answer box. No rounding is required.", "solution": "The problem requires the application of the Benjamini–Hochberg (BH) procedure to a given set of $p$-values from a systems biomedicine experiment to control the False Discovery Rate (FDR).\n\nFirst, let us establish the fundamental definitions. We are given $m$ null hypothesis tests, $H_1, H_2, \\ldots, H_m$, and their corresponding $p$-values, $p_1, p_2, \\ldots, p_m$. We summarize the outcomes of the $m$ tests in a contingency table:\n\n|                  | Null Hypothesis is True | Alternative is True | Total     |\n|------------------|-------------------------|---------------------|-----------|\n| **Not Rejected** | $U$ (True Negatives)    | $T$ (False Negatives) | $m-R$     |\n| **Rejected**     | $V$ (False Positives)   | $S$ (True Positives)  | $R$       |\n| **Total**        | $m_0$                   | $m - m_0$           | $m$       |\n\nHere, $R$ is the total number of rejected hypotheses, and $V$ is the number of true null hypotheses that are incorrectly rejected (Type I errors, or false discoveries). The False Discovery Rate is defined as the expected value of the proportion of false discoveries among all discoveries:\n$$\n\\text{FDR} = E\\left[ \\frac{V}{\\max(R, 1)} \\right]\n$$\nThe Benjamini–Hochberg procedure provides a way to control the FDR such that $\\text{FDR} \\le q$ for a specified target level $q$.\n\nThe givens in this problem are:\n- The total number of hypothesis tests (genes): $m = 10$.\n- The vector of $p$-values, with indices from $1$ to $10$:\n$$\n\\mathbf{p} = \\left(0.0009,\\ 0.003,\\ 0.021,\\ 0.055,\\ 0.13,\\ 0.24,\\ 0.0004,\\ 0.0085,\\ 0.041,\\ 0.72\\right)\n$$\n- The target FDR level: $q = 0.1$.\n\nThe Benjamini–Hochberg procedure consists of the following steps:\n\n1.  **Rank the $p$-values**: Let $p_{(1)} \\le p_{(2)} \\le \\ldots \\le p_{(m)}$ be the $p$-values sorted in ascending order. We must keep track of their original indices.\n\nThe original $p$-values and their indices are:\n- $p_1 = 0.0009$\n- $p_2 = 0.003$\n- $p_3 = 0.021$\n- $p_4 = 0.055$\n- $p_5 = 0.13$\n- $p_6 = 0.24$\n- $p_7 = 0.0004$\n- $p_8 = 0.0085$\n- $p_9 = 0.041$\n- $p_{10} = 0.72$\n\nSorting these $p$-values in ascending order, we obtain the ranked list along with their original gene indices:\n\n| Rank ($i$) | Original Index | Sorted $p$-value ($p_{(i)}$) |\n|------------|----------------|------------------------------|\n| $1$        | $7$            | $0.0004$                     |\n| $2$        | $1$            | $0.0009$                     |\n| $3$        | $2$            | $0.003$                      |\n| $4$        | $8$            | $0.0085$                     |\n| $5$        | $3$            | $0.021$                      |\n| $6$        | $9$            | $0.041$                      |\n| $7$        | $4$            | $0.055$                      |\n| $8$        | $5$            | $0.13$                       |\n| $9$        | $6$            | $0.24$                       |\n| $10$       | $10$           | $0.72$                       |\n\n2.  **Find the rejection cutoff**: We find the largest rank $k$ such that the corresponding $p$-value $p_{(k)}$ satisfies the condition:\n$$\np_{(k)} \\le \\frac{k}{m}q\n$$\nFor our problem, with $m=10$ and $q=0.1$, the threshold for each rank $i$ is $\\frac{i}{10}(0.1) = 0.01 \\times i$. We now perform the sequence of comparisons for each rank $i=1, \\ldots, 10$:\n\n- For $i=1$: $p_{(1)} = 0.0004$. Threshold: $\\frac{1}{10}(0.1) = 0.01$. Comparison: $0.0004 \\le 0.01$ (True).\n- For $i=2$: $p_{(2)} = 0.0009$. Threshold: $\\frac{2}{10}(0.1) = 0.02$. Comparison: $0.0009 \\le 0.02$ (True).\n- For $i=3$: $p_{(3)} = 0.003$. Threshold: $\\frac{3}{10}(0.1) = 0.03$. Comparison: $0.003 \\le 0.03$ (True).\n- For $i=4$: $p_{(4)} = 0.0085$. Threshold: $\\frac{4}{10}(0.1) = 0.04$. Comparison: $0.0085 \\le 0.04$ (True).\n- For $i=5$: $p_{(5)} = 0.021$. Threshold: $\\frac{5}{10}(0.1) = 0.05$. Comparison: $0.021 \\le 0.05$ (True).\n- For $i=6$: $p_{(6)} = 0.041$. Threshold: $\\frac{6}{10}(0.1) = 0.06$. Comparison: $0.041 \\le 0.06$ (True).\n- For $i=7$: $p_{(7)} = 0.055$. Threshold: $\\frac{7}{10}(0.1) = 0.07$. Comparison: $0.055 \\le 0.07$ (True).\n- For $i=8$: $p_{(8)} = 0.13$. Threshold: $\\frac{8}{10}(0.1) = 0.08$. Comparison: $0.13 \\le 0.08$ (False).\n- For $i=9$: $p_{(9)} = 0.24$. Threshold: $\\frac{9}{10}(0.1) = 0.09$. Comparison: $0.24 \\le 0.09$ (False).\n- For $i=10$: $p_{(10)} = 0.72$. Threshold: $\\frac{10}{10}(0.1) = 0.1$. Comparison: $0.72 \\le 0.1$ (False).\n\nThe largest rank $k$ for which the condition $p_{(k)} \\le \\frac{k}{m}q$ is satisfied is $k=7$.\n\n3.  **Determine the rejection set**: The BH procedure rejects all null hypotheses $H_{(i)}$ for $i=1, \\ldots, k$. This means we reject the null hypotheses corresponding to the $k=7$ smallest $p$-values. The $p$-values to be declared significant are $p_{(1)}, p_{(2)}, p_{(3)}, p_{(4)}, p_{(5)}, p_{(6)},$ and $p_{(7)}$.\n\n4.  **Map back to original indices**: We now identify the original gene indices corresponding to these $7$ significant $p$-values from the table in step 1.\n- $p_{(1)}$ corresponds to original index $7$.\n- $p_{(2)}$ corresponds to original index $1$.\n- $p_{(3)}$ corresponds to original index $2$.\n- $p_{(4)}$ corresponds to original index $8$.\n- $p_{(5)}$ corresponds to original index $3$.\n- $p_{(6)}$ corresponds to original index $9$.\n- $p_{(7)}$ corresponds to original index $4$.\n\nThe rejection set, in terms of original gene indices, is $\\{1, 2, 3, 4, 7, 8, 9\\}$. The problem asks for this set to be expressed as a list of indices in increasing numerical order. Sorting these indices gives the final result.", "answer": "$$\\boxed{\\begin{pmatrix} 1  2  3  4  7  8  9 \\end{pmatrix}}$$", "id": "4363527"}, {"introduction": "The standard Benjamini–Hochberg procedure provides guarantees under the assumption that statistical tests are independent or exhibit positive dependence. This practice explores what happens when this assumption may not hold by introducing the more conservative Benjamini–Yekutieli (BY) procedure, which controls the False Discovery Rate under arbitrary dependence. By applying both methods to the same dataset, you will directly observe the trade-off between statistical power and robustness to dependence, a critical consideration in many systems biomedicine applications where measurements are often correlated [@problem_id:4363605].", "problem": "A systems biomedicine study evaluates differential abundance for $m=20$ plasma proteins measured across two patient cohorts. For each protein, a single hypothesis test is performed and a $p$-value is obtained. The investigator seeks to control the false discovery rate (FDR) at level $q=0.05$ using both the Benjamini–Hochberg (BH) and Benjamini–Yekutieli (BY) procedures, where BY is intended to be valid under arbitrary dependence among the test statistics, and BH is valid under independence or certain positive dependence structures.\n\nYou are given the unsorted $p$-value vector (one per protein):\n$$\n\\{\\,0.04000,\\;0.01410,\\;0.00030,\\;0.05500,\\;0.01270,\\;0.00150,\\;0.04900,\\;0.00012,\\;0.01900,\\;0.03200,\\;0.00620,\\;0.08000,\\;0.00210,\\;0.01050,\\;0.00410,\\;0.00090,\\;0.02500,\\;0.00840,\\;0.00320,\\;0.04400\\,\\}.\n$$\n\nStarting from the core definition of false discovery rate and the principle that step-up procedures operate on the ascendingly ordered $p$-values, determine the rejection sets produced by the Benjamini–Hochberg (BH) procedure at $q=0.05$ and the Benjamini–Yekutieli (BY) procedure at $q=0.05$ for $m=20$ tests. Then contrast these sets by computing the difference in the number of rejections, defined as\n$$\nR_{\\mathrm{BH}} - R_{\\mathrm{BY}},\n$$\nwhere $R_{\\mathrm{BH}}$ is the number of hypotheses rejected by BH and $R_{\\mathrm{BY}}$ is the number rejected by BY.\n\nReport this difference as a single integer. No rounding is required.", "solution": "The user has provided a valid problem statement. The task is to apply two different multiple testing correction procedures, the Benjamini–Hochberg (BH) and Benjamini–Yekutieli (BY) procedures, to a given set of $p$-values and to determine the difference in the number of rejected hypotheses.\n\nThe problem involves $m=20$ hypothesis tests, and the goal is to control the false discovery rate (FDR) at a level $q=0.05$. The provided unsorted $p$-values are:\n$$\nP = \\{\\,0.04000,\\;0.01410,\\;0.00030,\\;0.05500,\\;0.01270,\\;0.00150,\\;0.04900,\\;0.00012,\\;0.01900,\\;0.03200,\\;0.00620,\\;0.08000,\\;0.00210,\\;0.01050,\\;0.00410,\\;0.00090,\\;0.02500,\\;0.00840,\\;0.00320,\\;0.04400\\,\\}.\n$$\n\nBoth the BH and BY procedures are step-up procedures, which means they operate on the $p$-values sorted in ascending order. Let the sorted $p$-values be denoted by $p_{(1)}, p_{(2)}, \\dots, p_{(m)}$.\n\nFirst, we sort the provided $p$-values:\n$p_{(1)} = 0.00012$\n$p_{(2)} = 0.00030$\n$p_{(3)} = 0.00090$\n$p_{(4)} = 0.00150$\n$p_{(5)} = 0.00210$\n$p_{(6)} = 0.00320$\n$p_{(7)} = 0.00410$\n$p_{(8)} = 0.00620$\n$p_{(9)} = 0.00840$\n$p_{(10)} = 0.01050$\n$p_{(11)} = 0.01270$\n$p_{(12)} = 0.01410$\n$p_{(13)} = 0.01900$\n$p_{(14)} = 0.02500$\n$p_{(15)} = 0.03200$\n$p_{(16)} = 0.04000$\n$p_{(17)} = 0.04400$\n$p_{(18)} = 0.04900$\n$p_{(19)} = 0.05500$\n$p_{(20)} = 0.08000$\n\nNow, we will apply each procedure.\n\n**Benjamini–Hochberg (BH) Procedure**\nThe BH procedure finds the largest integer $k$ such that the corresponding sorted $p$-value $p_{(k)}$ satisfies the condition:\n$$\np_{(k)} \\le \\frac{k}{m}q\n$$\nIf such a $k$ exists, all null hypotheses corresponding to $p_{(1)}, \\dots, p_{(k)}$ are rejected. The number of rejected hypotheses is $R_{\\mathrm{BH}} = k$.\n\nGiven $m=20$ and $q=0.05$, the BH threshold for the $i$-th sorted $p$-value is:\n$$\n\\frac{i}{20} \\times 0.05 = i \\times 0.0025\n$$\nWe must find the largest index $k$ for which $p_{(k)} \\le k \\times 0.0025$. We inspect the sorted $p$-values starting from the largest index and going down, or check each one systematically. Let's check the boundary cases identified during analysis.\n\nFor $i=16$:\n$p_{(16)} = 0.04000$.\nThe BH threshold is $\\frac{16}{20} \\times 0.05 = 0.8 \\times 0.05 = 0.04$.\nThe condition is $0.04000 \\le 0.04$, which is true.\n\nFor $i=17$:\n$p_{(17)} = 0.04400$.\nThe BH threshold is $\\frac{17}{20} \\times 0.05 = 0.85 \\times 0.05 = 0.0425$.\nThe condition is $0.04400 \\le 0.0425$, which is false.\n\nSince the condition holds for $k=16$ but fails for $k=17$, the largest index for which the inequality is satisfied is $k=16$. Therefore, the BH procedure rejects $16$ hypotheses.\n$$\nR_{\\mathrm{BH}} = 16\n$$\n\n**Benjamini–Yekutieli (BY) Procedure**\nThe BY procedure is a more conservative method that controls the FDR under arbitrary dependence assumptions. It finds the largest integer $k$ such that:\n$$\np_{(k)} \\le \\frac{k}{m \\cdot C(m)}q\n$$\nwhere $C(m)$ is the sum of the reciprocals of the integers from $1$ to $m$, also known as the $m$-th Harmonic number, $H_m$.\n$$\nC(m) = \\sum_{i=1}^{m} \\frac{1}{i}\n$$\nFor $m=20$, we must first calculate $C(20)$:\n$$\nC(20) = H_{20} = \\sum_{i=1}^{20} \\frac{1}{i} = 1 + \\frac{1}{2} + \\frac{1}{3} + \\dots + \\frac{1}{20}\n$$\nNumerically evaluating this sum gives:\n$$\nC(20) \\approx 3.597739657\n$$\nThe BY threshold for the $i$-th sorted $p$-value is:\n$$\n\\frac{i}{20 \\cdot C(20)} \\times 0.05 \\approx \\frac{i \\times 0.0025}{3.59774}\n$$\nWe must find the largest index $k$ for which $p_{(k)} \\le \\frac{k \\times 0.0025}{C(20)}$. Let's examine the p-values around the expected cutoff.\n\nFor $i=7$:\n$p_{(7)} = 0.00410$.\nThe BY threshold is $\\frac{7}{20 \\cdot C(20)} \\times 0.05 \\approx \\frac{7 \\times 0.05}{20 \\times 3.59774} \\approx \\frac{0.35}{71.9548} \\approx 0.004864$.\nThe condition is $0.00410 \\le 0.004864$, which is true.\n\nFor $i=8$:\n$p_{(8)} = 0.00620$.\nThe BY threshold is $\\frac{8}{20 \\cdot C(20)} \\times 0.05 \\approx \\frac{8 \\times 0.05}{20 \\times 3.59774} \\approx \\frac{0.40}{71.9548} \\approx 0.005559$.\nThe condition is $0.00620 \\le 0.005559$, which is false.\n\nThe largest index for which the BY condition holds is $k=7$. Thus, the BY procedure rejects $7$ hypotheses.\n$$\nR_{\\mathrm{BY}} = 7\n$$\n\n**Difference in the Number of Rejections**\nThe problem asks for the difference $R_{\\mathrm{BH}} - R_{\\mathrm{BY}}$.\n$$\nR_{\\mathrm{BH}} - R_{\\mathrm{BY}} = 16 - 7 = 9\n$$\nThe difference in the number of rejections between the Benjamini–Hochberg and Benjamini–Yekutieli procedures is $9$.", "answer": "$$\\boxed{9}$$", "id": "4363605"}, {"introduction": "Before applying any multiple testing correction, it is crucial to perform diagnostic checks on the distribution of your $p$-values. This practice shifts our focus from calculation to interpretation, challenging you to analyze a $p$-value histogram to assess the validity of the underlying null model and estimate the proportion of true null hypotheses, $\\pi_0$. Recognizing features that suggest model misspecification or even $p$-hacking is a vital skill for any researcher working with high-dimensional data [@problem_id:4363560].", "problem": "A systems biomedicine laboratory conducts differential expression analyses across $m$ gene-level hypotheses in a large single-cell RNA sequencing study. The statistical workflow will apply the Benjamini-Hochberg (BH) procedure to control the false discovery rate (FDR), but the team first wants to diagnose calibration and estimate the null proportion $\\pi_{0}$ from the empirical distribution of $p$-values. The following context is available and scientifically well-established: under a true null hypothesis, a $p$-value is uniformly distributed on $(0,1)$ and, across $m$ tests, the $p$-value distribution can be approximated as a mixture of a uniform component (from true nulls) and a component stochastically concentrated near $0$ (from true alternatives). The team constructs an equal-width histogram with bin width $0.05$ and also computes several summaries:\n- The fraction of $p$-values greater than $0.8$ is $0.19$.\n- The counts in the narrow windows $(0.045,0.05]$ and $(0.05,0.055]$ are $600$ and $250$, respectively.\n- The fraction of $p$-values less than $0.001$ is $0.03$.\nAssume $m = 20{,}000$ and that the tests are designed so that, under true nulls, $p$-values are independent and identically distributed and continuous.\n\nWhich option best describes a statistically sound $p$-value histogram diagnostic that both provides a defensible estimate of $\\pi_{0}$ and can flag $p$-hacking or model misspecification prior to applying BH?\n\nA. Construct equal-width bins over $(0,1]$ with sufficient expected uniform counts per bin, visually and formally assess whether the high-$p$ region (for example $p \\in (0.5,1]$) is approximately flat, and estimate $\\pi_{0}$ by comparing the observed upper-tail fraction to the uniform expectation across several thresholds (for example $\\lambda \\in \\{0.5,0.6,0.7,0.8,0.9\\}$) and checking stability. Using the given summary for $\\lambda = 0.8$, report $\\hat{\\pi}_{0} \\approx 0.95$; interpret the pronounced asymmetry between $(0.045,0.05]$ and $(0.05,0.055]$ as evidence consistent with researcher degrees of freedom or discretization, prompting targeted quality control and model checks. Proceed with BH once the upper-tail uniformity and $\\hat{\\pi}_{0}$ stability are verified.\n\nB. Test the entire histogram against a uniform distribution on $(0,1]$ with a goodness-of-fit test; if uniformity is rejected due to many small $p$-values or a spike near $p \\approx 0.05$, conclude BH is invalid in this setting and switch to Bonferroni. For $\\pi_{0}$, use the location of the histogram’s mode (near $p = 1$ here) to set $\\hat{\\pi}_{0} = 1$ and proceed.\n\nC. Focus on the left tail because it is “most informative”: estimate $\\pi_{0}$ from the proportion of $p$-values less than $0.2$, then treat the spike just below $0.05$ as expected under multiple testing. Proceed with BH without additional checks provided the fraction of $p$-values below $0.001$ exceeds $0.02$.\n\nD. Estimate $\\pi_{0}$ directly as the observed fraction of $p$-values exceeding $0.8$ (namely $0.19$), because true nulls produce many large $p$-values. Ignore local features around $p = 0.05$ because BH will correct them, and apply BH immediately at the desired FDR level.", "solution": "The problem statement poses a valid and highly relevant question in the field of high-throughput biological data analysis, specifically concerning the diagnostic checks required before applying multiple testing correction procedures. The provided data and context are scientifically sound and internally consistent.\n\n**Step 1: Extract Givens**\n- Total number of hypotheses (genes): $m = 20,000$.\n- The analysis involves applying the Benjamini-Hochberg (BH) procedure to control the False Discovery Rate (FDR).\n- The goal is to perform a diagnostic check on the $p$-value distribution, estimate the null proportion $\\pi_0$, and identify potential issues like $p$-hacking or model misspecification.\n- Theoretical context: For true null hypotheses, $p$-values are i.i.d. from a $Uniform(0,1)$ distribution. The overall distribution of $p$-values is a mixture: $f(p) = \\pi_0 \\cdot 1 + (1-\\pi_0)f_1(p)$, where $f_1(p)$ is the density for true alternatives, concentrated near $p=0$.\n- Empirical data summaries:\n    - The fraction of $p$-values greater than $0.8$ is $0.19$.\n    - The number of $p$-values in the interval $(0.045, 0.05]$ is $600$.\n    - The number of $p$-values in the interval $(0.05, 0.055]$ is $250$.\n    - The fraction of $p$-values less than $0.001$ is $0.03$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It describes a standard scenario in genomics and asks for the correct application of established statistical principles for quality control of $p$-value distributions. All provided data are plausible and serve to test the understanding of these principles. There are no contradictions, ambiguities, or factual errors in the setup. The problem is therefore valid.\n\n**Step 3: Derivation and Evaluation of Options**\n\nThe primary diagnostic tool for a large set of $p$-values is their empirical distribution, often visualized as a histogram. The underlying statistical model posits that this distribution is a mixture of a uniform component from true null hypotheses and another component, enriched near zero, from true alternative hypotheses. A sound diagnostic procedure leverages this model to both check the validity of the underlying statistical tests and to estimate key parameters like the null proportion, $\\pi_0$.\n\nA key assumption for many statistical tests is that the resulting $p$-values under the null hypothesis are uniformly distributed on $(0,1)$. A histogram of $p$-values should therefore exhibit a flat region for larger $p$-values (e.g., $p0.5$), as these are expected to arise overwhelmingly from true nulls. The height of this flat region is proportional to $\\pi_0$. Deviations from flatness in the right tail can indicate problems with the statistical model (e.g., conservativeness or anti-conservativeness). Sharp, localized features, especially near conventional significance thresholds like $p=0.05$, are highly suspicious and often point to \"p-hacking\" or artifacts from data processing.\n\nThe proportion of true nulls, $\\pi_0$, can be estimated by assuming that for some large threshold $\\lambda$, all $p$-values greater than $\\lambda$ originate from null hypotheses. Under this assumption, the number of $p$-values exceeding $\\lambda$, denoted $\\#\\{p_i  \\lambda\\}$, should be approximately $m \\cdot \\pi_0 \\cdot (1-\\lambda)$. This leads to the estimator:\n$$ \\hat{\\pi}_0(\\lambda) = \\frac{\\#\\{p_i  \\lambda\\}}{m(1-\\lambda)} $$\nA robust estimation involves checking the stability of $\\hat{\\pi}_0(\\lambda)$ across a range of $\\lambda$ values.\n\nLet's apply these principles to the given data and evaluate each option.\n\n**Analysis of Option A:**\nThis option proposes a multi-step diagnostic procedure.\n1.  **Assess Uniformity of the Upper Tail:** It suggests constructing a histogram and assessing if the region for large $p$-values (e.g., $p \\in (0.5, 1]$) is approximately flat. This is the cornerstone of a valid $p$-value diagnostic, as this region's behavior reflects the validity of the null distribution.\n2.  **Estimate $\\pi_0$ Stably:** It recommends estimating $\\pi_0$ by applying the standard formula for several thresholds $\\lambda$ (e.g., $\\lambda \\in \\{0.5, 0.6, 0.7, 0.8, 0.9\\}$) and checking for stability. This is the state-of-the-art method, proposed by Storey and others, to obtain a reliable estimate.\n3.  **Calculate $\\hat{\\pi}_0$ with given data:** For $\\lambda = 0.8$, the fraction of $p$-values greater than $0.8$ is $0.19$. The number of such $p$-values is $0.19 \\times m$. The estimator gives:\n    $$ \\hat{\\pi}_0(0.8) = \\frac{0.19 \\cdot m}{m(1-0.8)} = \\frac{0.19}{0.2} = 0.95 $$\n    The option's claim that $\\hat{\\pi}_0 \\approx 0.95$ is arithmetically correct.\n4.  **Interpret the Anomaly at $p=0.05$:** The counts in the two adjacent intervals of equal width ($0.005$) are $600$ for $(0.045, 0.05]$ and $250$ for $(0.05, 0.055]$. A smooth, non-increasing density is expected. The sharp drop by more than a factor of $2$ right at the $p=0.05$ boundary is a major red flag. Option A correctly interprets this as potential \"researcher degrees of freedom\" (p-hacking) or a \"discretization\" artifact, warranting further quality control. This is the correct, cautious interpretation.\n5.  **Course of Action:** It recommends proceeding with the BH procedure only after these diagnostic checks are satisfactory. This is a responsible and statistically sound workflow.\n\nConclusion for A: This option perfectly describes a meticulous, modern, and statistically rigorous diagnostic workflow. Every statement is correct and reflects best practices. **Correct**.\n\n**Analysis of Option B:**\nThis option proposes testing the entire histogram for uniformity. This is fundamentally incorrect. We *expect* the distribution to be non-uniform due to the presence of true alternatives, which cause an enrichment of $p$-values near $0$. A global goodness-of-fit test for uniformity would almost always be rejected in a successful experiment, but this rejection is uninformative about the validity of the null distribution. Concluding from this rejection that BH is invalid is a non-sequitur. Switching to the Bonferroni correction is also illogical; it is a more conservative method that doesn't address the potential underlying issues with $p$-value validity. Furthermore, it suggests setting $\\hat{\\pi}_0 = 1$ based on a supposed mode near $p=1$, which is not supported by the data (the mode is certainly near $p=0$, given the enrichment of small $p$-values) and ignores a powerful way to increase the power of the BH procedure. Conclusion for B: This option is based on a cascade of misunderstandings of multiple testing theory. **Incorrect**.\n\n**Analysis of Option C:**\nThis option suggests focusing only on the left tail of the distribution. While the left tail contains the \"signal\" (true alternative hypotheses), the right tail is what validates the \"background\" (true null hypotheses). Estimating $\\pi_0$, a property of the nulls, from the left tail is incorrect. Specifically, using the proportion of $p$-values less than $0.2$ to estimate $\\pi_0$ is conceptually wrong and would lead to a nonsensical result. The option also dismisses the sharp spike below $p=0.05$ as \"expected,\" which is a dangerous misinterpretation. A smooth rise towards $p=0$ is expected, but a sharp cliff at $p=0.05$ is an artifact that must be investigated. The final criterion about the fraction of $p$-values below $0.001$ is an arbitrary and insufficient quality check. Conclusion for C: This option demonstrates a flawed understanding of how to interpret $p$-value distributions. **Incorrect**.\n\n**Analysis of Option D:**\nThis option makes two critical errors. First, it incorrectly estimates $\\pi_0$ as the raw fraction of $p$-values above a threshold ($0.19$), rather than the correctly scaled value. The correct formula is $\\hat{\\pi}_0(\\lambda) = (\\text{fraction }  \\lambda)/(1-\\lambda)$. Using $\\hat{\\pi}_0 = 0.19$ would be a massive underestimate, leading to an unnecessarily conservative analysis. Second, it suggests ignoring the local feature around $p=0.05$ with the false belief that \"BH will correct them.\" The BH procedure is a mathematical algorithm that operates on a list of $p$-values; it cannot fix or diagnose underlying problems in how those $p$-values were generated. Applying BH to invalid or manipulated $p$-values will produce invalid results. \"Garbage in, garbage out\" is a fundamental principle here. Conclusion for D: This option advocates for an incorrect calculation and an irresponsible neglect of clear warning signs in the data. **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "4363560"}]}