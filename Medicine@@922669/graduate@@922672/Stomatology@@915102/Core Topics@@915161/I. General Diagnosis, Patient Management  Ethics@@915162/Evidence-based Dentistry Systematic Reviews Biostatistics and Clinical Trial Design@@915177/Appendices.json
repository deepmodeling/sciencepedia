{"hands_on_practices": [{"introduction": "Before we can trust the conclusions of a clinical study, we must first trust its data. In studies involving diagnostic judgments, ensuring that different examiners make consistent assessments—a concept known as inter-rater reliability—is paramount for the study's validity. This exercise [@problem_id:4717621] introduces Cohen’s kappa ($\\kappa$), a fundamental statistic that measures agreement between two raters while correcting for the agreement that could occur purely by chance. Mastering this concept allows you to critically appraise the quality of data in primary studies, a crucial skill for conducting systematic reviews.", "problem": "A reliability calibration exercise was conducted within a randomized controlled trial in stomatology to evaluate examiner consistency in diagnosing caries presence on bitewing radiographs. Two trained examiners independently rated a set of $N$ patients for caries presence versus absence on a single index tooth, yielding a $2 \\times 2$ contingency table of joint ratings. The cell counts are: $(\\text{yes, yes}) = 20$, $(\\text{yes, no}) = 5$, $(\\text{no, yes}) = 10$, and $(\\text{no, no}) = 65$, where the first coordinate denotes Rater A and the second denotes Rater B. Using the foundational definitions of joint and marginal probabilities, and the notion of chance agreement implied by independence of raters, derive from first principles the inter-rater reliability coefficient known as Cohen’s $\\kappa$ and compute its value from the given data. Then, interpret the magnitude of reliability in the context of evidence-based dentistry and systematic review grading, explicitly noting the impact of marginal distributions on chance agreement. Provide the final value of $\\kappa$ as an exact simplified fraction. Do not round.", "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n- A reliability calibration exercise in a randomized controlled trial in stomatology.\n- Two examiners, Rater A and Rater B, rated $N$ patients for caries presence.\n- The joint ratings are provided in a $2 \\times 2$ contingency table format.\n- Cell counts:\n  - Rater A 'yes', Rater B 'yes': $n_{11} = 20$\n  - Rater A 'yes', Rater B 'no': $n_{12} = 5$\n  - Rater A 'no', Rater B 'yes': $n_{21} = 10$\n  - Rater A 'no', Rater B 'no': $n_{22} = 65$\n- The task is to derive Cohen’s $\\kappa$ from first principles, compute its value as an exact simplified fraction, and interpret its magnitude, including the effect of marginal distributions.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, as it deals with a standard biostatistical method (Cohen's $\\kappa$) applied in a conventional context (inter-rater reliability in a clinical trial). The problem is well-posed; the provided data are complete and sufficient for the calculation of $\\kappa$. The terminology is precise and objective. There are no contradictions, factual errors, or reliance on pseudoscience. The problem is a standard application of statistical theory and is verifiable.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n### Solution Derivation\n\nThe Cohen's $\\kappa$ coefficient is a statistical measure of inter-rater agreement for categorical items. It is designed to account for the possibility of agreement occurring by chance. The formula for $\\kappa$ is defined as:\n$$ \\kappa = \\frac{p_o - p_e}{1 - p_e} $$\nwhere $p_o$ is the relative observed agreement among raters, and $p_e$ is the hypothetical probability of chance agreement. We will derive and compute these quantities from first principles using the provided data.\n\nFirst, let's structure the data into a contingency table. Let the rows represent Rater A's judgments and columns represent Rater B's judgments.\n\n|             | Rater B: Yes | Rater B: No | Row Total |\n|-------------|--------------|-------------|-----------|\n| Rater A: Yes| $n_{11}=20$  | $n_{12}=5$  | $25$      |\n| Rater A: No | $n_{21}=10$  | $n_{22}=65$  | $75$      |\n| Col Total   | $30$         | $70$        | $N=100$   |\n\nThe total number of patients, $N$, is the sum of all cell counts:\n$$ N = n_{11} + n_{12} + n_{21} + n_{22} = 20 + 5 + 10 + 65 = 100 $$\n\n**1. Observed Agreement ($p_o$)**\n\nThe observed agreement is the proportion of cases where both raters gave the same rating. This occurs in the diagonal cells of the contingency table (both said 'yes' or both said 'no').\nThe number of agreements is the sum of the diagonal elements:\n$$ \\text{Agreements} = n_{11} + n_{22} = 20 + 65 = 85 $$\nThe proportion of observed agreement, $p_o$, is this number divided by the total number of patients, $N$:\n$$ p_o = \\frac{n_{11} + n_{22}}{N} = \\frac{85}{100} = \\frac{17}{20} $$\n\n**2. Chance Agreement ($p_e$)**\n\nThe chance agreement, $p_e$, is the probability that the raters would agree if their ratings were statistically independent. To calculate this, we first need the marginal probabilities for each rater giving each rating. These are estimated from the row and column totals.\n\nThe marginal proportion for Rater A saying 'yes' is the total number of 'yes' ratings from Rater A divided by $N$:\n$$ p_{A,yes} = \\frac{n_{11} + n_{12}}{N} = \\frac{20 + 5}{100} = \\frac{25}{100} = \\frac{1}{4} $$\nThe marginal proportion for Rater A saying 'no' is:\n$$ p_{A,no} = \\frac{n_{21} + n_{22}}{N} = \\frac{10 + 65}{100} = \\frac{75}{100} = \\frac{3}{4} $$\n\nSimilarly, for Rater B:\nThe marginal proportion for Rater B saying 'yes' is:\n$$ p_{B,yes} = \\frac{n_{11} + n_{21}}{N} = \\frac{20 + 10}{100} = \\frac{30}{100} = \\frac{3}{10} $$\nThe marginal proportion for Rater B saying 'no' is:\n$$ p_{B,no} = \\frac{n_{12} + n_{22}}{N} = \\frac{5 + 65}{100} = \\frac{70}{100} = \\frac{7}{10} $$\n\nUnder the assumption of independence, the probability of both raters saying 'yes' by chance is the product of their individual probabilities of saying 'yes':\n$$ P(\\text{chance agreement on 'yes'}) = p_{A,yes} \\times p_{B,yes} = \\frac{1}{4} \\times \\frac{3}{10} = \\frac{3}{40} $$\nThe probability of both raters saying 'no' by chance is the product of their individual probabilities of saying 'no':\n$$ P(\\text{chance agreement on 'no'}) = p_{A,no} \\times p_{B,no} = \\frac{3}{4} \\times \\frac{7}{10} = \\frac{21}{40} $$\n\nThe total probability of chance agreement, $p_e$, is the sum of these two probabilities:\n$$ p_e = P(\\text{chance agreement on 'yes'}) + P(\\text{chance agreement on 'no'}) $$\n$$ p_e = \\frac{3}{40} + \\frac{21}{40} = \\frac{24}{40} = \\frac{3}{5} $$\n\n**3. Calculation of Cohen's $\\kappa$**\n\nNow we substitute the values of $p_o$ and $p_e$ into the formula for $\\kappa$:\n$$ \\kappa = \\frac{p_o - p_e}{1 - p_e} = \\frac{\\frac{17}{20} - \\frac{3}{5}}{1 - \\frac{3}{5}} $$\nTo subtract the fractions in the numerator, we find a common denominator, which is $20$:\n$$ \\frac{17}{20} - \\frac{3}{5} = \\frac{17}{20} - \\frac{12}{20} = \\frac{5}{20} = \\frac{1}{4} $$\nThe denominator is:\n$$ 1 - \\frac{3}{5} = \\frac{5}{5} - \\frac{3}{5} = \\frac{2}{5} $$\nNow, we compute the final value of $\\kappa$:\n$$ \\kappa = \\frac{\\frac{1}{4}}{\\frac{2}{5}} = \\frac{1}{4} \\times \\frac{5}{2} = \\frac{5}{8} $$\n\n**4. Interpretation and Impact of Marginal Distributions**\n\nThe calculated value of Cohen's $\\kappa$ is $\\frac{5}{8}$, or $0.625$. According to widely used benchmarks (e.g., Landis and Koch, 1977), a $\\kappa$ value in the range of $0.61 - 0.80$ is considered to represent \"substantial\" agreement. This indicates a good level of inter-rater reliability for caries diagnosis in this exercise. In the context of evidence-based dentistry, such a level of agreement is crucial. Systematic reviews and meta-analyses depend on the quality and reliability of data from primary studies. If the diagnostic judgments within a clinical trial have low reliability (low $\\kappa$), the trial's internal validity is weakened, which in turn compromises the evidence base for clinical decision-making.\n\nThe problem specifically asks to address the impact of marginal distributions on chance agreement. The value of $p_e = \\frac{3}{5} = 0.60$ is calculated directly from the marginal proportions of 'yes'/'no' ratings for each examiner ($25\\%$/$75\\%$ for Rater A and $30\\%$/$70\\%$ for Rater B). These marginals reflect the individual prevalence of a 'yes' diagnosis for each rater. The prevalence of a 'no' diagnosis is high for both raters ($75\\%$ and $70\\%$). This imbalance leads to a high probability of chance agreement ($p_e = 0.60$). A significant portion of the observed agreement ($p_o = 0.85$) is thus expected to occur simply by chance. The $\\kappa$ coefficient corrects for this by focusing on the agreement beyond chance, which is $p_o - p_e = 0.85 - 0.60 = 0.25$. This quantity is then normalized by the maximum possible agreement beyond chance, $1 - p_e = 1 - 0.60 = 0.40$, yielding $\\kappa = 0.25/0.40 = 0.625$.\n\nThis demonstrates the \"paradox of kappa\": when the prevalence of one category is very high (or very low), the marginals become highly skewed. This inflates $p_e$, which can suppress the value of $\\kappa$ even when observed agreement ($p_o$) is high. In this case, the raters agree $85\\%$ of the time, but the substantial agreement that would be expected by chance alone ($60\\%$) tempers the final reliability score. This highlights that $\\kappa$ is a more stringent measure of agreement than the simple percentage agreement ($p_o$).", "answer": "$$\\boxed{\\frac{5}{8}}$$", "id": "4717621"}, {"introduction": "Evidence-based practice requires us to understand not just whether a diagnostic test works, but precisely how it informs our clinical judgment. This practice [@problem_id:4717609] moves from the intrinsic properties of a test—its sensitivity and specificity—to its real-world application using likelihood ratios and Bayesian reasoning. You will learn how to calculate the post-test probability of disease, transforming a piece of diagnostic data into a powerful tool for clinical decision-making.", "problem": "A prospective diagnostic accuracy study in a tertiary stomatology clinic evaluates Cone Beam Computed Tomography (CBCT) for detecting periapical lesions in mandibular molars prior to non-surgical root canal retreatment. A reference standard based on histopathologic confirmation and expert clinical consensus classifies each case as disease present or disease absent. The CBCT classification yields the following $2 \\times 2$ table counts: true positives $TP=45$, false positives $FP=5$, false negatives $FN=15$, and true negatives $TN=35$. Based on historical referral patterns and prevalence data for this clinic, the pretest probability of disease for patients undergoing CBCT in this context is $0.40$. Using only core definitions from diagnostic test evaluation and Bayesian updating in odds form, compute the sensitivity, specificity, the positive likelihood ratio $LR^{+}$, the negative likelihood ratio $LR^{-}$, and the post-test probability of disease after a positive CBCT test. Round each computed quantity to four significant figures. Express probabilities as decimals (not with a percentage sign).", "solution": "The problem statement is evaluated for validity.\n\n### Step 1: Extract Givens\n- True Positives: $TP = 45$\n- False Positives: $FP = 5$\n- False Negatives: $FN = 15$\n- True Negatives: $TN = 35$\n- Pre-test probability of disease: $P(\\text{D+}) = 0.40$\n- Task: Compute sensitivity, specificity, positive likelihood ratio ($LR^{+}$), negative likelihood ratio ($LR^{-}$), and post-test probability of disease after a positive CBCT test.\n- Constraint: Use core definitions and Bayesian updating in odds form.\n- Constraint: Round each computed quantity to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific Groundedness**: The problem utilizes fundamental and standard concepts of diagnostic test evaluation in biostatistics (sensitivity, specificity, likelihood ratios) and Bayesian inference. The clinical context (CBCT for periapical lesions) is a realistic application in stomatology. The concepts are scientifically sound.\n2.  **Well-Posedness**: The problem provides all necessary numerical data ($TP, FP, FN, TN$) to calculate the test's intrinsic accuracy metrics. It also provides the pre-test probability required for calculating the post-test probability. The instructions are unambiguous, leading to a unique set of solutions.\n3.  **Objectivity**: The problem is stated in precise, objective language, free of subjective or opinion-based assertions.\n\nThe prevalence of disease in the study sample is calculated as $\\frac{TP+FN}{TP+FN+FP+TN} = \\frac{45+15}{45+15+5+35} = \\frac{60}{100} = 0.60$. This value is distinct from the given pre-test probability of $0.40$, which represents the probability for a patient in the target clinical population. This distinction is appropriate; test characteristics (sensitivity, specificity, likelihood ratios) are derived from a study sample and then applied to a patient population with a known (and often different) pre-test probability. This does not represent a contradiction but a standard application of diagnostic reasoning.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is scientifically grounded, well-posed, and objective. A complete solution will be provided.\n\n### Solution\nThe solution proceeds by calculating the five requested quantities based on their core definitions.\n\n1.  **Sensitivity (Sens)**\n    Sensitivity is the probability of a positive test result given that the disease is present. It is the proportion of true positives among all individuals with the disease.\n    $$ \\text{Sens} = \\frac{TP}{TP + FN} $$\n    Substituting the given values:\n    $$ \\text{Sens} = \\frac{45}{45 + 15} = \\frac{45}{60} = 0.75 $$\n    Rounded to four significant figures, this is $0.7500$.\n\n2.  **Specificity (Spec)**\n    Specificity is the probability of a negative test result given that the disease is absent. It is the proportion of true negatives among all individuals without the disease.\n    $$ \\text{Spec} = \\frac{TN}{TN + FP} $$\n    Substituting the given values:\n    $$ \\text{Spec} = \\frac{35}{35 + 5} = \\frac{35}{40} = 0.875 $$\n    Rounded to four significant figures, this is $0.8750$.\n\n3.  **Positive Likelihood Ratio ($LR^{+}$)**\n    The positive likelihood ratio is the ratio of the probability of a positive test in a diseased individual (sensitivity) to the probability of a positive test in a non-diseased individual ($1 - \\text{specificity}$).\n    $$ LR^{+} = \\frac{\\text{Sens}}{1 - \\text{Spec}} $$\n    Using the calculated values for sensitivity and specificity:\n    $$ LR^{+} = \\frac{0.75}{1 - 0.875} = \\frac{0.75}{0.125} = 6 $$\n    Rounded to four significant figures, this is $6.000$.\n\n4.  **Negative Likelihood Ratio ($LR^{-}$)**\n    The negative likelihood ratio is the ratio of the probability of a negative test in a diseased individual ($1 - \\text{sensitivity}$) to the probability of a negative test in a non-diseased individual (specificity).\n    $$ LR^{-} = \\frac{1 - \\text{Sens}}{\\text{Spec}} $$\n    Using the calculated values for sensitivity and specificity:\n    $$ LR^{-} = \\frac{1 - 0.75}{0.875} = \\frac{0.25}{0.875} \\approx 0.285714... $$\n    Rounded to four significant figures, this is $0.2857$.\n\n5.  **Post-Test Probability of Disease after a Positive Test ($P(\\text{D+}|\\text{T+})$)**\n    This will be calculated using Bayesian updating in odds form as requested.\n    First, convert the pre-test probability to pre-test odds.\n    $$ \\text{Odds}_{\\text{pre}} = \\frac{P(\\text{D+})}{1 - P(\\text{D+})} $$\n    Given $P(\\text{D+}) = 0.40$:\n    $$ \\text{Odds}_{\\text{pre}} = \\frac{0.40}{1 - 0.40} = \\frac{0.40}{0.60} = \\frac{2}{3} $$\n    Next, calculate the post-test odds by multiplying the pre-test odds by the positive likelihood ratio ($LR^{+}$).\n    $$ \\text{Odds}_{\\text{post}} = \\text{Odds}_{\\text{pre}} \\times LR^{+} $$\n    $$ \\text{Odds}_{\\text{post}} = \\frac{2}{3} \\times 6 = 4 $$\n    Finally, convert the post-test odds back to a probability.\n    $$ P(\\text{D+}|\\text{T+}) = \\frac{\\text{Odds}_{\\text{post}}}{1 + \\text{Odds}_{\\text{post}}} $$\n    $$ P(\\text{D+}|\\text{T+}) = \\frac{4}{1 + 4} = \\frac{4}{5} = 0.8 $$\n    Rounded to four significant figures, this is $0.8000$.\n\nThe five computed quantities, rounded to four significant figures, are:\n- Sensitivity: $0.7500$\n- Specificity: $0.8750$\n- Positive Likelihood Ratio: $6.000$\n- Negative Likelihood Ratio: $0.2857$\n- Post-test probability after a positive test: $0.8000$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.7500 & 0.8750 & 6.000 & 0.2857 & 0.8000\n\\end{pmatrix}\n}\n$$", "id": "4717609"}, {"introduction": "At the top of the evidence pyramid lies the systematic review with meta-analysis, where results from multiple independent trials are synthesized to produce a single, more precise estimate of an intervention's effect. However, pooling results is only meaningful if the studies are sufficiently similar. This capstone exercise [@problem_id:4717605] delves into the critical methods for assessing between-study heterogeneity, using foundational statistics like Cochran’s $Q$, the between-study variance $\\tau^2$, and the $I^2$ statistic to determine if a group of studies can be meaningfully combined.", "problem": "A research team in stomatology is conducting a quantitative synthesis of three randomized controlled trials (RCTs) assessing a preventive intervention for postoperative infection following third molar surgery. Each trial reports the log relative risk (log $RR$) of infection and its estimated sampling variance computed from individual patient data. Let $y_i$ denote the observed log $RR$ from study $i$ and $v_i$ its estimated variance. The three trials report $y_1=0.10$, $y_2=0.30$, $y_3=-0.05$, with corresponding variances $v_1=0.04$, $v_2=0.09$, $v_3=0.02$.\n\nStarting from the foundational definitions used in inverse-variance meta-analysis and the method-of-moments approach to random-effects modeling, do the following:\n\n1. Derive and compute the fixed-effect heterogeneity statistic $Q$ from the inverse-variance weighted mean of the study effects.\n2. Using the method-of-moments logic underlying the DerSimonian–Laird random-effects model, derive and compute the between-study variance estimator $\\tau^{2}$.\n3. From first principles, derive and compute the inconsistency metric $I^{2}$.\n\nAssume there are $k=3$ studies. Round each final quantity to four significant figures. Express $I^{2}$ as a decimal (do not use a percentage sign).", "solution": "The problem will be validated before a solution is attempted.\n\n### Step 1: Extract Givens\nThe problem provides the following information for a meta-analysis of $k=3$ randomized controlled trials:\n- Study 1: log relative risk $y_1=0.10$, variance $v_1=0.04$.\n- Study 2: log relative risk $y_2=0.30$, variance $v_2=0.09$.\n- Study 3: log relative risk $y_3=-0.05$, variance $v_3=0.02$.\n- Number of studies: $k=3$.\n- The task is to derive and compute three quantities based on inverse-variance weighting and the method-of-moments:\n  1. The fixed-effect heterogeneity statistic $Q$.\n  2. The between-study variance estimator $\\tau^2$ (DerSimonian-Laird).\n  3. The inconsistency metric $I^2$.\n- Final numerical results are to be rounded to four significant figures, with $I^2$ expressed as a decimal.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is set in the context of evidence-based medicine (stomatology) and uses standard, well-established biostatistical methods for meta-analysis (inverse-variance weighting, Cochran's $Q$, DerSimonian-Laird estimator, $I^2$ statistic). The premises are factually and methodologically sound.\n2.  **Well-Posed**: The problem provides all necessary data ($y_i$, $v_i$, $k$) and specifies the exact methods to be used. The definitions of $Q$, $\\tau^2$, and $I^2$ are standard and lead to a unique, stable solution.\n3.  **Objective**: The problem is stated using precise, quantitative language and established terminology from biostatistics. It is free of subjectivity or ambiguity.\n4.  **Complete and Consistent**: The data and constraints are self-contained and consistent. There is no missing or contradictory information.\n5.  **Realistic**: The log relative risks and their variances are of a plausible magnitude for clinical trial data.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is scientifically sound, well-posed, objective, and complete. A full solution will be provided.\n\n***\n\n### Solution\nThe solution requires the derivation and computation of three key statistics in meta-analysis: Cochran's $Q$, the DerSimonian-Laird estimator for between-study variance $\\tau^2$, and the $I^2$ statistic.\n\nLet $y_i$ be the observed effect size (log relative risk) for study $i$, and let $v_i$ be its associated sampling variance, for $i=1, 2, ..., k$. The givens are $k=3$, with:\n$y_1=0.10$, $v_1=0.04$\n$y_2=0.30$, $v_2=0.09$\n$y_3=-0.05$, $v_3=0.02$\n\n#### 1. The Heterogeneity Statistic, $Q$\n\nThe fixed-effect model assumes that all studies share a common true effect size, $\\theta$. The observed effect $y_i$ is an estimate of $\\theta$, with $y_i \\sim N(\\theta, v_i)$. The optimal way to combine these estimates is by inverse-variance weighting. The weight for each study is the reciprocal of its variance:\n$$w_i = \\frac{1}{v_i}$$\nThe pooled estimate of the common effect size, $\\hat{\\theta}_{FE}$, is the inverse-variance weighted average:\n$$\\hat{\\theta}_{FE} = \\frac{\\sum_{i=1}^{k} w_i y_i}{\\sum_{i=1}^{k} w_i}$$\nCochran's $Q$ statistic measures the weighted sum of squared deviations of each study's effect estimate from this pooled estimate. It quantifies the total variation in the effect sizes. It is defined as:\n$$Q = \\sum_{i=1}^{k} w_i (y_i - \\hat{\\theta}_{FE})^2$$\nA computationally more direct formula, which avoids pre-calculating $\\hat{\\theta}_{FE}$, is derived by expanding the square:\n$$Q = \\sum w_i \\left(y_i^2 - 2y_i\\hat{\\theta}_{FE} + \\hat{\\theta}_{FE}^2\\right) = \\sum w_i y_i^2 - 2\\hat{\\theta}_{FE}\\sum w_i y_i + \\hat{\\theta}_{FE}^2\\sum w_i$$\nSubstituting the expression for $\\hat{\\theta}_{FE}$:\n$$Q = \\sum w_i y_i^2 - 2\\frac{\\sum w_i y_i}{\\sum w_i}\\sum w_i y_i + \\left(\\frac{\\sum w_i y_i}{\\sum w_i}\\right)^2\\sum w_i$$\n$$Q = \\sum_{i=1}^{k} w_i y_i^2 - \\frac{\\left(\\sum_{i=1}^{k} w_i y_i\\right)^2}{\\sum_{i=1}^{k} w_i}$$\nWe now compute the necessary terms.\nThe weights are:\n$w_1 = \\frac{1}{0.04} = 25$\n$w_2 = \\frac{1}{0.09} = \\frac{100}{9}$\n$w_3 = \\frac{1}{0.02} = 50$\n\nThe sum of the weights is:\n$$\\sum_{i=1}^{3} w_i = 25 + \\frac{100}{9} + 50 = 75 + \\frac{100}{9} = \\frac{675+100}{9} = \\frac{775}{9}$$\nThe sum of weighted effects is:\n$$\\sum_{i=1}^{3} w_i y_i = 25(0.10) + \\frac{100}{9}(0.30) + 50(-0.05) = 2.5 + \\frac{30}{9} - 2.5 = \\frac{10}{3}$$\nThe sum of weighted squared effects is:\n$$\\sum_{i=1}^{3} w_i y_i^2 = 25(0.10)^2 + \\frac{100}{9}(0.30)^2 + 50(-0.05)^2$$\n$$= 25(0.01) + \\frac{100}{9}(0.09) + 50(0.0025) = 0.25 + 1 + 0.125 = 1.375 = \\frac{11}{8}$$\nNow, we compute $Q$:\n$$Q = \\frac{11}{8} - \\frac{\\left(\\frac{10}{3}\\right)^2}{\\frac{775}{9}} = \\frac{11}{8} - \\frac{\\frac{100}{9}}{\\frac{775}{9}} = \\frac{11}{8} - \\frac{100}{775}$$\nSimplifying the fraction $\\frac{100}{775} = \\frac{4 \\times 25}{31 \\times 25} = \\frac{4}{31}$.\n$$Q = \\frac{11}{8} - \\frac{4}{31} = \\frac{11 \\times 31 - 4 \\times 8}{8 \\times 31} = \\frac{341 - 32}{248} = \\frac{309}{248}$$\nNumerically, $Q \\approx 1.2459677...$. Rounding to four significant figures, we get:\n$$Q \\approx 1.246$$\n\n#### 2. The Between-Study Variance, $\\tau^2$\n\nThe DerSimonian-Laird estimator for the between-study variance, $\\tau^2$, is based on the method of moments. The random-effects model assumes that each study's true effect, $\\theta_i$, is drawn from a common distribution, typically $N(\\mu, \\tau^2)$. The observed effect $y_i$ is then sampled from $N(\\theta_i, v_i)$.\nThe $Q$ statistic, under this more general model, has an expected value of:\n$$E[Q] = (k-1) + C\\tau^2$$\nwhere $C$ is a weighting constant defined as:\n$$C = \\sum_{i=1}^{k} w_i - \\frac{\\sum_{i=1}^{k} w_i^2}{\\sum_{i=1}^{k} w_i}$$\nThe method of moments equates the observed value of $Q$ with its expected value and solves for $\\tau^2$:\n$$Q_{obs} = (k-1) + C\\hat{\\tau}^2 \\implies \\hat{\\tau}^2 = \\frac{Q_{obs} - (k-1)}{C}$$\nBecause variance cannot be negative, the estimator is truncated at zero:\n$$\\hat{\\tau}^2 = \\max\\left(0, \\frac{Q - (k-1)}{C}\\right)$$\nWe have $k=3$, so the degrees of freedom are $k-1=2$.\nWe calculated $Q = \\frac{309}{248} \\approx 1.246$.\nWe observe that $Q < k-1$, since $1.246 < 2$.\nTherefore, the numerator of the expression for $\\hat{\\tau}^2$ is negative:\n$$Q - (k-1) = \\frac{309}{248} - 2 = \\frac{309 - 496}{248} = -\\frac{187}{248} < 0$$\nAs a result, the estimate for the between-study variance is truncated to zero:\n$$\\hat{\\tau}^2 = \\max\\left(0, \\frac{-187/248}{C}\\right) = 0$$\nThe exact value is $0$. To report this to four significant figures as requested, we write it as $0.0000$.\n\n#### 3. The Inconsistency Metric, $I^2$\n\nThe $I^2$ statistic describes the proportion of the total variation in effect size estimates that is due to heterogeneity between studies rather than sampling error (chance). It is derived from the $Q$ statistic.\nThe total variation is captured by $Q$. The variation expected due to chance alone is given by the degrees of freedom, $df = k-1$. The \"excess\" variation, attributable to heterogeneity, is thus $Q - (k-1)$.\n$I^2$ is the ratio of the heterogeneity variation to the total variation:\n$$I^2 = \\frac{\\text{Heterogeneity Variation}}{\\text{Total Variation}} = \\frac{Q - (k-1)}{Q}$$\nLike $\\tau^2$, $I^2$ is constrained to be non-negative, so its formula is:\n$$I^2 = \\max\\left(0, \\frac{Q - (k-1)}{Q}\\right)$$\nUsing our values for $Q$ and $k$:\n$$I^2 = \\max\\left(0, \\frac{1.246 - 2}{1.246}\\right) = \\max\\left(0, \\frac{-0.754}{1.246}\\right) = 0$$\nThe value of $I^2$ is exactly $0$, indicating that there is no observable heterogeneity in this set of studies beyond what would be expected by chance. Expressed as a decimal to four significant figures, this is $0.0000$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1.246 & 0.0000 & 0.0000 \\end{pmatrix}}\n$$", "id": "4717605"}]}