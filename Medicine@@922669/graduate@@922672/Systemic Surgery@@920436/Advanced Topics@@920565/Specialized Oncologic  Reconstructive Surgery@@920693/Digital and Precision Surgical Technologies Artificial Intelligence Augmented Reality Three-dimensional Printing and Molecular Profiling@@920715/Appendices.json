{"hands_on_practices": [{"introduction": "Reinforcement Learning allows surgical robots and other autonomous systems to learn optimal behaviors through trial and error, guided by a system of rewards. The core of this process is the iterative refinement of an action-value function, which estimates the long-term benefit of taking an action in a certain state. This exercise provides a hands-on look at a single Q-learning update, the fundamental calculation that drives an AI agent's learning and decision-making process. [@problem_id:5110348]", "problem": "In a robotic systemic surgery workflow that integrates Augmented Reality (AR) overlays, Three-Dimensional (3D) printed anatomical guides, and molecular profiling-informed patient stratification, an autonomous camera controller uses Reinforcement Learning (RL) to stabilize AR registration during instrument manipulation. The task is modeled as a Markov Decision Process, where the action-value function quantifies the expected discounted return for taking an action in a given state. Starting from the Bellman optimality principle for the action-value function and using a constant step-size stochastic approximation, derive the single-step update rule for the action-value estimate and apply it to the following scenario. At time step $t$, the controller is in state $s$ and executes action $a$. The immediate reward observed is $r=1.0$. The current estimate is $Q_t(s,a)=2.0$. The discount factor is $\\gamma=0.95$. The constant learning rate is $\\alpha=0.1$. The maximum predicted action-value in the successor state $s'$ under the current estimator is $\\max_{a'}Q_t(s',a')=3.0$. Compute the updated estimate $Q_{t+1}(s,a)$ as a real number. No rounding is required.", "solution": "The problem will first be validated for scientific soundness, self-consistency, and clarity.\n\n### Step 1: Extract Givens\nThe problem provides the following information:\n- **Model**: A Markov Decision Process for an autonomous camera controller.\n- **Function**: The action-value function, denoted as $Q(s,a)$.\n- **Learning Principle**: The Bellman optimality principle.\n- **Update Method**: Single-step, constant step-size stochastic approximation (specifically, Q-learning).\n- **Time step**: $t$.\n- **State at time $t$**: $s$.\n- **Action at time $t$**: $a$.\n- **Observed immediate reward**: $r = 1.0$.\n- **Current action-value estimate**: $Q_t(s,a) = 2.0$.\n- **Discount factor**: $\\gamma = 0.95$.\n- **Constant learning rate (step-size)**: $\\alpha = 0.1$.\n- **Maximum predicted action-value in the successor state $s'$**: $\\max_{a'}Q_t(s',a') = 3.0$.\n- **Objective**: Compute the updated action-value estimate, $Q_{t+1}(s,a)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria.\n\n- **Scientifically Grounded**: The problem is based on the standard and well-established theory of Reinforcement Learning (RL). The use of a Markov Decision Process (MDP), the Bellman optimality principle, the action-value function ($Q$-function), and the Q-learning update rule are all fundamental concepts in this field. The application to robotic surgery control is a realistic and active area of research. The problem is scientifically and mathematically sound.\n- **Well-Posed**: All necessary parameters ($\\alpha$, $\\gamma$, $r$, $Q_t(s,a)$, and $\\max_{a'}Q_t(s',a')$) required for a single-step temporal-difference update are provided. The question asks for a specific, uniquely determinable numerical value.\n- **Objective**: The problem is stated in precise, technical language with no subjective or ambiguous terms. All numerical values are given explicitly.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or ambiguity. The framing, while specific to a surgical technology context, poses a standard, formalizable problem in computational science.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\n### Derivation and Solution\nThe task is to compute the updated action-value estimate, $Q_{t+1}(s,a)$, using the principles of temporal-difference learning, specifically the Q-learning algorithm.\n\nThe Bellman optimality equation for the action-value function $Q^*(s,a)$ states that the optimal value of taking action $a$ in state $s$ is the expected immediate reward plus the discounted maximum expected future reward from the next state $s'$:\n$$Q^*(s,a) = \\mathbb{E}[R_{t+1} + \\gamma \\max_{a'} Q^*(S_{t+1}, a') | S_t=s, A_t=a]$$\nIn Reinforcement Learning, the true environmental dynamics and reward function are unknown. Therefore, $Q^*(s,a)$ is approximated iteratively from experience. After taking action $a$ in state $s$, we observe a reward $r$ and a new state $s'$. This single sample of experience, $(s, a, r, s')$, is used to update our current estimate, $Q_t(s,a)$.\n\nThe Q-learning algorithm uses the observed reward $r$ and the current estimate of the maximum value obtainable from the next state, $\\max_{a'}Q_t(s',a')$, to form a target value for the update. This is the temporal-difference (TD) target:\n$$ \\text{TD Target} = r + \\gamma \\max_{a'}Q_t(s',a') $$\nThe update rule for $Q_t(s,a)$ is derived from stochastic approximation, which moves the current estimate a small step, determined by the learning rate $\\alpha$, toward the TD target. The update rule is:\n$$ Q_{t+1}(s,a) = Q_t(s,a) + \\alpha \\left[ \\left( r + \\gamma \\max_{a'}Q_t(s',a') \\right) - Q_t(s,a) \\right] $$\nThe term inside the square brackets, $\\left( r + \\gamma \\max_{a'}Q_t(s',a') \\right) - Q_t(s,a)$, is known as the TD error.\n\nWe are given the following values:\n- Current estimate: $Q_t(s,a) = 2.0$\n- Reward: $r = 1.0$\n- Discount factor: $\\gamma = 0.95$\n- Learning rate: $\\alpha = 0.1$\n- Maximum value in the successor state: $\\max_{a'}Q_t(s',a') = 3.0$\n\nSubstituting these values into the Q-learning update equation:\n$$ Q_{t+1}(s,a) = 2.0 + 0.1 \\left[ \\left( 1.0 + 0.95 \\times 3.0 \\right) - 2.0 \\right] $$\nFirst, we compute the term inside the parentheses, which is the sampled estimate of the optimal future value (the TD target):\n$$ 1.0 + 0.95 \\times 3.0 = 1.0 + 2.85 = 3.85 $$\nNext, we compute the TD error by subtracting the old estimate from this target:\n$$ \\text{TD Error} = 3.85 - 2.0 = 1.85 $$\nFinally, we update the estimate by adding the product of the learning rate and the TD error to the old estimate:\n$$ Q_{t+1}(s,a) = 2.0 + 0.1 \\times 1.85 $$\n$$ Q_{t+1}(s,a) = 2.0 + 0.185 $$\n$$ Q_{t+1}(s,a) = 2.185 $$\nThus, the updated estimate for the action-value function for the state-action pair $(s,a)$ is $2.185$.", "answer": "$$\\boxed{2.185}$$", "id": "5110348"}, {"introduction": "Once an AI model is trained, we must rigorously evaluate its performance before it can be trusted in a clinical setting like surgical planning. This practice moves from the mechanism of learning to the science of evaluation, focusing on the common task of segmenting anatomical structures from medical images. You will calculate standard metrics like the Dice Similarity Coefficient and explore the nuances of boundary-based errors, gaining insight into how to quantitatively assess the reliability of AI-generated models. [@problem_id:5110408]", "problem": "An Artificial Intelligence (AI)-assisted organ segmentation pipeline for Computed Tomography (CT) in systemic surgery planning produces a predicted binary mask $A$ for the liver, and an expert-annotated ground truth binary mask $B$. The masks are subsets of a discrete voxel lattice and are treated as finite sets with cardinalities equal to the voxel counts. The following quantities are measured: $|A|=8000$, $|B|=10000$, and $|A\\cap B|=7000$. Assume the boundaries $\\partial A$ and $\\partial B$ are compact in the Euclidean metric induced by the voxel grid spacing, and that boundary-to-boundary discrepancies are measured as minimal Euclidean distances between boundary points. The Dice Similarity Coefficient (DSC) is defined for two finite sets $A$ and $B$ as the overlap-based similarity measure. The Hausdorff distance $H(A,B)$ between two compact sets is defined using the supremum of the minimal distances between points on the boundaries in both directions.\n\nIn addition, suppose that the average boundary deviation, defined as the expected value of the minimal boundary-to-boundary distance when sampling points uniformly on $\\partial A\\cup\\partial B$, is $2$ millimeters. Treat this average as the expectation of a nonnegative random variable $D$ representing the boundary discrepancy.\n\nUsing only fundamental definitions of overlap measures and metric distances, along with well-tested probabilistic inequalities for nonnegative random variables, do the following:\n- Compute the Dice Similarity Coefficient for the given $A$ and $B$.\n- Provide a rigorous lower bound on the Hausdorff distance in millimeters and a nonparametric upper bound on the $95$th-percentile robust Hausdorff distance (the smallest $t$ such that at least a fraction $0.95$ of boundary discrepancies are at most $t$) in millimeters, expressed in terms of the given average boundary deviation.\n\nExpress the Hausdorff bounds in millimeters (mm). No rounding is required; provide exact values.", "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded, well-posed, and objective. All provided data are consistent and sufficient for deriving the requested quantities. The problem is a straightforward application of standard definitions and principles from medical image analysis and probability theory.\n\nThe solution is divided into three parts as requested by the problem statement.\n\n**Part 1: Computation of the Dice Similarity Coefficient (DSC)**\n\nThe Dice Similarity Coefficient (DSC) is a statistical measure of the similarity between two finite sets. For a predicted segmentation mask $A$ and a ground truth mask $B$, the DSC is defined as:\n$$\n\\text{DSC}(A, B) = \\frac{2 |A \\cap B|}{|A| + |B|}\n$$\nwhere $|S|$ denotes the cardinality (i.e., the number of elements or voxels) of a set $S$.\n\nThe problem provides the following values:\n- Cardinality of the predicted mask, $|A| = 8000$.\n- Cardinality of the ground truth mask, $|B| = 10000$.\n- Cardinality of the intersection of the masks, $|A \\cap B| = 7000$.\n\nSubstituting these values into the DSC formula:\n$$\n\\text{DSC} = \\frac{2 \\times 7000}{8000 + 10000} = \\frac{14000}{18000}\n$$\nSimplifying the fraction:\n$$\n\\text{DSC} = \\frac{14}{18} = \\frac{7}{9}\n$$\n\n**Part 2: Lower Bound on the Hausdorff Distance**\n\nLet $D$ be the random variable representing the minimal boundary-to-boundary distance when sampling a point uniformly from the union of the boundaries, $\\partial A \\cup \\partial B$. The problem states that the average boundary deviation, which is the expectation of $D$, is $E[D] = 2$ millimeters.\n\nThe Hausdorff distance between the boundaries, $H(\\partial A, \\partial B)$, is defined as the supremum (the least upper bound) of all minimal distances from a point on one boundary to the set of points on the other boundary.\n$$\nH(\\partial A, \\partial B) = \\max \\left( \\sup_{x \\in \\partial A} \\inf_{y \\in \\partial B} d(x, y), \\sup_{y \\in \\partial B} \\inf_{x \\in \\partial A} d(y, x) \\right)\n$$\nThis value, $H(\\partial A, \\partial B)$, represents the maximum possible value that the random variable $D$ can attain. Let $d_{\\max} = H(\\partial A, \\partial B)$ be the supremum of the support of the distribution of $D$.\n\nFor any non-negative random variable $D$, its expected value $E[D]$ cannot exceed its maximum possible value $d_{\\max}$. This can be shown formally:\n$$\nE[D] = \\int_0^{d_{\\max}} x f(x) \\,dx \\le \\int_0^{d_{\\max}} d_{\\max} f(x) \\,dx = d_{\\max} \\int_0^{d_{\\max}} f(x) \\,dx = d_{\\max} \\times 1 = d_{\\max}\n$$\nwhere $f(x)$ is the probability density function of $D$.\n\nTherefore, we have the inequality:\n$$\nH(\\partial A, \\partial B) \\ge E[D]\n$$\nGiven $E[D] = 2$ mm, the rigorous lower bound on the Hausdorff distance is $2$ mm.\n\n**Part 3: Upper Bound on the $95$th-Percentile Robust Hausdorff Distance**\n\nThe $95$th-percentile robust Hausdorff distance is defined as the smallest value $t$ such that the probability of a randomly sampled boundary discrepancy $D$ being less than or equal to $t$ is at least $0.95$. This is formally written as finding the smallest $t$ such that:\n$$\nP(D \\le t) \\ge 0.95\n$$\nThis is equivalent to finding an upper bound on $t_{0.95}$, the $95$th percentile of the distribution of $D$.\n\nThe problem specifies the use of a nonparametric inequality for a non-negative random variable, for which we only know the expectation $E[D] = 2$. The appropriate tool is Markov's inequality, which states that for any non-negative random variable $X$ and any constant $a > 0$:\n$$\nP(X \\ge a) \\le \\frac{E[X]}{a}\n$$\nThe condition $P(D \\le t) \\ge 0.95$ is complementary to $P(D > t) \\le 0.05$. Assuming $D$ is a continuous variable, such that $P(D=t)=0$, this is equivalent to $P(D \\ge t) \\le 0.05$.\n\nApplying Markov's inequality to the random variable $D$:\n$$\nP(D \\ge t) \\le \\frac{E[D]}{t} = \\frac{2}{t}\n$$\nTo guarantee that $P(D \\ge t) \\le 0.05$, we must find the smallest $t$ that satisfies this condition. We can enforce this by setting the upper bound provided by the inequality to be equal to our desired probability threshold:\n$$\n\\frac{2}{t} = 0.05\n$$\nSolving for $t$:\n$$\nt = \\frac{2}{0.05} = \\frac{2}{\\frac{1}{20}} = 2 \\times 20 = 40\n$$\nFor $t = 40$ mm, Markov's inequality guarantees that $P(D \\ge 40) \\le \\frac{2}{40} = 0.05$. This ensures that $P(D \\le 40) \\ge 1 - 0.05 = 0.95$. Therefore, $40$ mm is a valid nonparametric upper bound for the $95$th-percentile robust Hausdorff distance.\n\nThe three requested values are:\n1.  Dice Similarity Coefficient: $\\frac{7}{9}$\n2.  Lower Bound on Hausdorff Distance: $2$ mm\n3.  Upper Bound on $95$th-Percentile Robust Hausdorff Distance: $40$ mm", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{7}{9} & 2 & 40 \\end{pmatrix}}\n$$", "id": "5110408"}, {"introduction": "Advanced surgical technologies are integrated into complex real-time systems where overall performance is critical. This exercise examines a crucial system-level parameter in surgical Augmented Reality: motion-to-photon latency. By calculating the total delay from motion capture to visual feedback, you will connect hardware and software specifications directly to a clinical precision requirement and quantify the system's responsiveness. [@problem_id:5110434]", "problem": "A head-tracked optical see-through Augmented Reality (AR) surgical navigation system overlays anatomical guidance onto the surgeonâ€™s field of view. To ensure accurate registration between the virtual overlay and the moving instrument tip, the motion-to-photon latency must be controlled. The pipeline consists of: camera sensing with exposure integration, computational pose estimation and rendering, vertical synchronization gating due to display refresh, and raster scanout until the region of interest is illuminated.\n\nAssume the following hardware characteristics and operating conditions:\n- Display refresh frequency is $f = 60\\,\\mathrm{Hz}$ (sample-and-hold), so frames are presented only at refresh boundaries.\n- Camera exposure duration is $T_{\\text{exp}} = 10\\,\\mathrm{ms}$, and the sample is available to processing at the end of exposure.\n- Pose estimation and rendering require $T_{\\text{proc}} = 20\\,\\mathrm{ms}$.\n- From the start of the frame update to the region-of-interest pixel illumination, the scanout time is $T_{\\text{scan}} = 8\\,\\mathrm{ms}$.\n- The expected vertical synchronization (vsync) wait is uniformly distributed over one refresh period, so take its expected value as one-half of the refresh period.\n\nIntraoperative precision requirements specify that the overlay misregistration should not exceed $d = 0.5\\,\\mathrm{mm}$ relative to the instrument tip. During fine manipulation, the tip speed can reach $v = 30\\,\\mathrm{mm/s}$. Use the kinematic relationship between displacement and latency $d = v \\, t$ to determine the maximum allowable latency $L_{\\max}$ for the overlay alignment.\n\nStarting from first principles and core definitions, derive:\n1. The expected motion-to-photon latency $L$ of this AR pipeline as the sum of exposure completion, processing, expected vsync wait, and scanout.\n2. The maximum allowable latency $L_{\\max}$ from the displacement constraint $d = v \\, t$.\n\nDefine the required latency reduction due to reprojection (asynchronous time-warp) as $R = \\max\\!\\big(0,\\, L - L_{\\max}\\big)$.\n\nCompute $R$ and express your final numerical answer in milliseconds. Round your answer to four significant figures. Do not include units in your final boxed answer.", "solution": "The problem requires the calculation of the required latency reduction, $R$, for an Augmented Reality (AR) surgical navigation system. This quantity is defined as $R = \\max\\!\\big(0,\\, L - L_{\\max}\\big)$, where $L$ is the expected motion-to-photon latency of the system and $L_{\\max}$ is the maximum allowable latency to meet a specified precision requirement. The solution will proceed by first deriving expressions for $L$ and $L_{\\max}$ and then computing the final value for $R$.\n\nFirst, we determine the expected motion-to-photon latency, $L$. The problem states that this latency is the sum of several sequential delays in the processing pipeline. The components are: camera exposure, processing, vertical synchronization (vsync) wait, and display scanout. The model for the total latency $L$ is given by:\n$$L = T_{\\text{exp}} + T_{\\text{proc}} + T_{\\text{vsync\\_wait}} + T_{\\text{scan}}$$\nThe given values for the fixed delays are:\n- Camera exposure duration, $T_{\\text{exp}} = 10\\,\\mathrm{ms}$. The problem specifies using this value directly for the \"exposure completion\" component of a simple summation model for latency.\n- Pose estimation and rendering time, $T_{\\text{proc}} = 20\\,\\mathrm{ms}$.\n- Raster scanout time, $T_{\\text{scan}} = 8\\,\\mathrm{ms}$.\n\nThe vsync wait time, $T_{\\text{vsync\\_wait}}$, is a variable delay that depends on when the rendered frame is ready relative to the display's refresh cycle. The display refresh frequency is given as $f = 60\\,\\mathrm{Hz}$. The duration of a single refresh period, $T_{\\text{period}}$, is the reciprocal of the frequency:\n$$T_{\\text{period}} = \\frac{1}{f} = \\frac{1}{60}\\,\\mathrm{s}$$\nTo maintain consistency of units, we convert this period to milliseconds:\n$$T_{\\text{period}} = \\frac{1}{60}\\,\\mathrm{s} \\times \\frac{1000\\,\\mathrm{ms}}{1\\,\\mathrm{s}} = \\frac{100}{6}\\,\\mathrm{ms} = \\frac{50}{3}\\,\\mathrm{ms}$$\nThe problem states that the vsync wait is uniformly distributed over one refresh period. The expected value of a uniform random variable over an interval $[0, T_{\\text{period}}]$ is half the interval's length. Therefore, the expected vsync wait is:\n$$T_{\\text{vsync\\_wait}} = \\frac{1}{2} T_{\\text{period}} = \\frac{1}{2} \\times \\frac{50}{3}\\,\\mathrm{ms} = \\frac{25}{3}\\,\\mathrm{ms}$$\nNow, we can compute the total expected latency $L$ by summing the components:\n$$L = 10\\,\\mathrm{ms} + 20\\,\\mathrm{ms} + \\frac{25}{3}\\,\\mathrm{ms} + 8\\,\\mathrm{ms}$$\n$$L = (10 + 20 + 8)\\,\\mathrm{ms} + \\frac{25}{3}\\,\\mathrm{ms} = 38\\,\\mathrm{ms} + \\frac{25}{3}\\,\\mathrm{ms}$$\n$$L = \\frac{3 \\times 38}{3}\\,\\mathrm{ms} + \\frac{25}{3}\\,\\mathrm{ms} = \\frac{114 + 25}{3}\\,\\mathrm{ms} = \\frac{139}{3}\\,\\mathrm{ms}$$\n\nNext, we determine the maximum allowable latency, $L_{\\max}$. This is derived from the intraoperative precision requirement, which states that the dynamic misregistration (displacement), $d$, should not exceed $0.5\\,\\mathrm{mm}$ when the instrument tip is moving at a speed $v$ of up to $30\\,\\mathrm{mm/s}$. The kinematic relationship between displacement, speed, and time (latency) is $d = v \\, t$. Solving for the time, which is our maximum allowable latency $L_{\\max}$, we get:\n$$L_{\\max} = \\frac{d}{v}$$\nSubstituting the given values:\n- $d = 0.5\\,\\mathrm{mm}$\n- $v = 30\\,\\mathrm{mm/s}$\n$$L_{\\max} = \\frac{0.5\\,\\mathrm{mm}}{30\\,\\mathrm{mm/s}} = \\frac{0.5}{30}\\,\\mathrm{s}$$\nConverting this duration to milliseconds:\n$$L_{\\max} = \\frac{0.5}{30}\\,\\mathrm{s} \\times \\frac{1000\\,\\mathrm{ms}}{1\\,\\mathrm{s}} = \\frac{500}{30}\\,\\mathrm{ms} = \\frac{50}{3}\\,\\mathrm{ms}$$\n\nFinally, we compute the required latency reduction, $R$, using the provided definition $R = \\max\\!\\big(0,\\, L - L_{\\max}\\big)$.\nWe compare the calculated system latency $L$ with the maximum allowable latency $L_{\\max}$:\n$$L = \\frac{139}{3}\\,\\mathrm{ms} \\approx 46.33\\,\\mathrm{ms}$$\n$$L_{\\max} = \\frac{50}{3}\\,\\mathrm{ms} \\approx 16.67\\,\\mathrm{ms}$$\nSince $L > L_{\\max}$, the system's inherent latency exceeds the acceptable threshold, and a reduction is necessary. The required reduction is the difference between the two values:\n$$R = L - L_{\\max} = \\frac{139}{3}\\,\\mathrm{ms} - \\frac{50}{3}\\,\\mathrm{ms} = \\frac{139 - 50}{3}\\,\\mathrm{ms} = \\frac{89}{3}\\,\\mathrm{ms}$$\nTo provide the final numerical answer, we compute the decimal value and round to four significant figures as requested:\n$$R = \\frac{89}{3}\\,\\mathrm{ms} \\approx 29.6666...\\,\\mathrm{ms}$$\nRounding to four significant figures gives:\n$$R \\approx 29.67\\,\\mathrm{ms}$$\nThis is the amount of latency that must be compensated for, for example by using predictive tracking or reprojection techniques like asynchronous time-warp, to meet the surgical precision requirements.", "answer": "$$\\boxed{29.67}$$", "id": "5110434"}]}