{"hands_on_practices": [{"introduction": "Ergonomics is fundamental to surgeon well-being and performance, as awkward postures during long procedures can lead to musculoskeletal injuries. We can objectively quantify this risk by analyzing the geometry of a surgeon's posture using established frameworks like the Rapid Upper Limb Assessment (RULA). This practice bridges the gap between abstract kinematics and practical risk assessment, allowing you to translate raw motion capture data into actionable ergonomic insightsâ€”a foundational skill for designing safer surgical techniques and environments [@problem_id:5183990].", "problem": "You are given three-dimensional motion capture positions for key anatomical landmarks recorded during standardized laparoscopic tasks, and your goal is to compute a simplified Rapid Upper Limb Assessment (RULA)-inspired ergonomic risk score based solely on kinematic geometry. Use vector calculus to quantify joint angles from the marker positions and then apply explicit threshold-based scoring rules. The final risk level must be produced for each task. This problem focuses on first-principles derivations from geometric definitions, without using proprietary tables, and is thus universally implementable.\n\nAssume a right-handed coordinate system where the global upward vertical axis is the unit vector $\\hat{\\mathbf{z}}_{+} = (0,0,1)$, the global downward vertical axis is $\\hat{\\mathbf{z}}_{-} = (0,0,-1)$, the forward direction is the $\\hat{\\mathbf{x}}$ axis, and the left-right direction is the $\\hat{\\mathbf{y}}$ axis (positive toward the subject's left). All positions are given in meters. Angles must be computed and expressed in degrees and all angle computations must use radians internally, with the conversion factor $180/\\pi$ applied at the end.\n\nFundamental base for derivation:\n- Vector difference: for points $\\mathbf{A}$ and $\\mathbf{B}$, the directed segment vector from $\\mathbf{A}$ to $\\mathbf{B}$ is $\\mathbf{v} = \\mathbf{B} - \\mathbf{A}$.\n- Dot product and angle: for nonzero vectors $\\mathbf{a}$ and $\\mathbf{b}$, the angle $\\theta$ between them is\n$$\n\\theta = \\arccos\\!\\left(\\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{a}\\|\\,\\|\\mathbf{b}\\|}\\right),\n$$\nwhere $\\|\\cdot\\|$ denotes the Euclidean norm. The angle returned by $\\arccos(\\cdot)$ is in radians and must be converted to degrees as $\\theta_{\\text{deg}} = \\theta \\cdot \\left(\\frac{180}{\\pi}\\right)$.\n\nCompute the following segment vectors and angles:\n- Upper arm vector $\\mathbf{u} = \\mathbf{E} - \\mathbf{S}$, where $\\mathbf{S}$ is shoulder, $\\mathbf{E}$ is elbow. Shoulder elevation angle $\\theta_{UA} = \\angle(\\mathbf{u}, \\hat{\\mathbf{z}}_{-})$.\n- Forearm vector $\\mathbf{f} = \\mathbf{W} - \\mathbf{E}$, where $\\mathbf{W}$ is wrist. Elbow angle $\\theta_{EL} = \\angle(-\\mathbf{u}, \\mathbf{f})$.\n- Hand vector $\\mathbf{h} = \\mathbf{H}_{hand} - \\mathbf{W}$, where $\\mathbf{H}_{hand}$ is hand tip. Wrist extension angle $\\theta_{WE} = \\angle(\\mathbf{f}, \\mathbf{h})$. Wrist radial/ulnar deviation is defined via horizontal-plane projections: $\\mathbf{f}_{xy} = (f_x, f_y, 0)$ and $\\mathbf{h}_{xy} = (h_x, h_y, 0)$, with deviation angle $\\theta_{WD} = \\angle(\\mathbf{f}_{xy}, \\mathbf{h}_{xy})$.\n- Torso axis vector $\\mathbf{t} = \\mathbf{T} - \\mathbf{P}$, where $\\mathbf{P}$ is pelvis base and $\\mathbf{T}$ is torso top. Trunk flexion angle $\\theta_{TR} = \\angle(\\mathbf{t}, \\hat{\\mathbf{z}}_{+})$. Trunk lateral bend angle is computed by frontal-plane projection $\\mathbf{t}_{yz} = (0, t_y, t_z)$ and $\\theta_{LB} = \\angle(\\mathbf{t}_{yz}, \\hat{\\mathbf{z}}_{+})$.\n- Neck flexion vector $\\mathbf{n} = \\mathbf{H}_{head} - \\mathbf{T}$, where $\\mathbf{H}_{head}$ is head center. Neck flexion angle $\\theta_{N} = \\angle(\\mathbf{n}, \\mathbf{t})$.\n- Knee flexion: define thigh vector $\\mathbf{q} = \\mathbf{H}_{hip} - \\mathbf{K}$ and shank vector $\\mathbf{r} = \\mathbf{A} - \\mathbf{K}$, where $\\mathbf{H}_{hip}$ is hip, $\\mathbf{K}$ is knee, and $\\mathbf{A}$ is ankle. Compute the inter-segment angle $\\theta_{\\text{knee-seg}} = \\angle(\\mathbf{q}, \\mathbf{r})$, and define knee flexion as $\\theta_{KF} = 180^\\circ - \\theta_{\\text{knee-seg}}$.\n\nApply the following threshold-based scoring rules. All inequalities are exact and inclusive as written:\n\nUpper limb group $A$:\n- Shoulder elevation score $S_{UA}$ from $\\theta_{UA}$:\n  - If $0^\\circ \\le \\theta_{UA} \\le 20^\\circ$: $S_{UA} = 1$.\n  - If $20^\\circ < \\theta_{UA} \\le 45^\\circ$: $S_{UA} = 2$.\n  - If $45^\\circ < \\theta_{UA} \\le 90^\\circ$: $S_{UA} = 3$.\n  - If $\\theta_{UA} > 90^\\circ$: $S_{UA} = 4$.\n- Elbow score $S_{EL}$ from $\\theta_{EL}$:\n  - If $60^\\circ \\le \\theta_{EL} \\le 100^\\circ$: $S_{EL} = 1$.\n  - If $\\theta_{EL} < 60^\\circ$ or $100^\\circ < \\theta_{EL} \\le 120^\\circ$: $S_{EL} = 2$.\n  - If $\\theta_{EL} > 120^\\circ$: $S_{EL} = 3$.\n- Wrist extension score $S_{WE}$ from $\\theta_{WE}$:\n  - If $0^\\circ \\le \\theta_{WE} \\le 15^\\circ$: $S_{WE} = 1$.\n  - If $15^\\circ < \\theta_{WE} \\le 30^\\circ$: $S_{WE} = 2$.\n  - If $\\theta_{WE} > 30^\\circ$: $S_{WE} = 3$.\n- Wrist radial/ulnar deviation increment $\\Delta_{WD}$ from $\\theta_{WD}$:\n  - If $0^\\circ \\le \\theta_{WD} \\le 10^\\circ$: $\\Delta_{WD} = 0$.\n  - If $10^\\circ < \\theta_{WD} \\le 20^\\circ$: $\\Delta_{WD} = 1$.\n  - If $\\theta_{WD} > 20^\\circ$: $\\Delta_{WD} = 2$.\n- External load/repetition increment $L_a$ from tool mass $m$ in kilograms:\n  - If $m \\ge 2$: $L_a = 1$.\n  - If $m < 2$: $L_a = 0$.\n- Upper limb group score: $A = S_{UA} + S_{EL} + S_{WE} + \\Delta_{WD} + L_a$.\n\nNeck-trunk-legs group $C$:\n- Neck flexion score $S_{N}$ from $\\theta_{N}$:\n  - If $0^\\circ \\le \\theta_{N} \\le 10^\\circ$: $S_{N} = 1$.\n  - If $10^\\circ < \\theta_{N} \\le 20^\\circ$: $S_{N} = 2$.\n  - If $20^\\circ < \\theta_{N} \\le 45^\\circ$: $S_{N} = 3$.\n  - If $\\theta_{N} > 45^\\circ$: $S_{N} = 4$.\n- Trunk flexion score $S_{TR}$ from $\\theta_{TR}$ and lateral bend increment $\\Delta_{LB}$ from $\\theta_{LB}$:\n  - Flexion $S_{TR}$:\n    - If $0^\\circ \\le \\theta_{TR} \\le 5^\\circ$: $S_{TR} = 1$.\n    - If $5^\\circ < \\theta_{TR} \\le 20^\\circ$: $S_{TR} = 2$.\n    - If $20^\\circ < \\theta_{TR} \\le 60^\\circ$: $S_{TR} = 3$.\n    - If $\\theta_{TR} > 60^\\circ$: $S_{TR} = 4$.\n  - Lateral bend $\\Delta_{LB}$:\n    - If $0^\\circ \\le \\theta_{LB} \\le 10^\\circ$: $\\Delta_{LB} = 0$.\n    - If $\\theta_{LB} > 10^\\circ$: $\\Delta_{LB} = 1$.\n- Legs score $S_{LG}$ from knee flexion $\\theta_{KF}$:\n  - If $0^\\circ \\le \\theta_{KF} \\le 30^\\circ$: $S_{LG} = 1$.\n  - If $\\theta_{KF} > 30^\\circ$: $S_{LG} = 2$.\n- Neck-trunk-legs group score: $C = S_{N} + (S_{TR} + \\Delta_{LB}) + S_{LG}$.\n\nFinal composite score and risk level:\n- Composite score $S = \\max(A, C)$.\n- Risk level $R$ is mapped from $S$ as:\n  - If $1 \\le S \\le 2$: $R = 1$.\n  - If $3 \\le S \\le 4$: $R = 2$.\n  - If $5 \\le S \\le 6$: $R = 3$.\n  - If $S \\ge 7$: $R = 4$.\nReport only the final risk level $R$ for each task.\n\nAngle unit: degrees. Mass unit: kilograms. Positions unit: meters.\n\nTest suite: For each task $i \\in \\{1,2,3,4\\}$, you are provided $12$ three-dimensional points and one scalar mass:\n- Pelvis base $\\mathbf{P}$, Torso top $\\mathbf{T}$, Head center $\\mathbf{H}_{head}$, Right shoulder $\\mathbf{S}$, Right elbow $\\mathbf{E}$, Right wrist $\\mathbf{W}$, Right hand tip $\\mathbf{H}_{hand}$, Right hip $\\mathbf{H}_{hip}$, Right knee $\\mathbf{K}$, Right ankle $\\mathbf{A}$, and tool mass $m$.\n\nUse the following parameter values:\n- Task $1$ (camera navigation, near neutral):\n  - $\\mathbf{P} = (0,\\,0,\\,1.0)$, $\\mathbf{T} = (0,\\,0,\\,1.5)$, $\\mathbf{H}_{head} = (0.05,\\,0,\\,1.7)$,\n  - $\\mathbf{S} = (0,\\,-0.2,\\,1.5)$, $\\mathbf{E} = (0,\\,-0.2,\\,1.2)$, $\\mathbf{W} = (0.2,\\,-0.2,\\,1.2)$, $\\mathbf{H}_{hand} = (0.35,\\,-0.2,\\,1.2)$,\n  - $\\mathbf{H}_{hip} = (0,\\,-0.1,\\,1.0)$, $\\mathbf{K} = (0,\\,-0.1,\\,0.55)$, $\\mathbf{A} = (0,\\,-0.1,\\,0.1)$, $m = 0.5$.\n- Task $2$ (suturing, elevated arm and wrist extension):\n  - $\\mathbf{P} = (0,\\,0,\\,1.0)$, $\\mathbf{T} = (0,\\,0,\\,1.5)$, $\\mathbf{H}_{head} = (0.04,\\,0,\\,1.7)$,\n  - $\\mathbf{S} = (0,\\,-0.2,\\,1.5)$, $\\mathbf{E} = (0.144,\\,-0.2,\\,1.25)$, $\\mathbf{W} = (0.344,\\,-0.2,\\,1.25)$, $\\mathbf{H}_{hand} = (0.444,\\,-0.2,\\,1.30)$,\n  - $\\mathbf{H}_{hip} = (0,\\,-0.1,\\,1.0), \\mathbf{K} = (0,\\,-0.1,\\,0.55), \\mathbf{A} = (0,\\,-0.1,\\,0.1)$, $m = 0.5$.\n- Task $3$ (knot tying, neck flexion and trunk flexion with radial deviation):\n  - $\\mathbf{P} = (0,\\,0,\\,1.0)$, $\\mathbf{T} = (0.234,\\,0,\\,1.454)$, $\\mathbf{H}_{head} = (0.534,\\,0,\\,1.504)$,\n  - $\\mathbf{S} = (0.234,\\,-0.2,\\,1.404)$, $\\mathbf{E} = (0.378,\\,-0.2,\\,1.154)$, $\\mathbf{W} = (0.578,\\,-0.2,\\,1.154)$, $\\mathbf{H}_{hand} = (0.578,\\,-0.1,\\,1.154)$,\n  - $\\mathbf{H}_{hip} = (0,\\,-0.1,\\,1.0)$, $\\mathbf{K} = (0.2,\\,-0.1,\\,0.8)$, $\\mathbf{A} = (0,\\,-0.1,\\,0.4)$, $m = 0.5$.\n- Task $4$ (stapling, high shoulder elevation with heavy tool):\n  - $\\mathbf{P} = (0,\\,0,\\,1.0)$, $\\mathbf{T} = (0,\\,0,\\,1.5)$, $\\mathbf{H}_{head} = (0.02,\\,0,\\,1.65)$,\n  - $\\mathbf{S} = (0,\\,-0.2,\\,1.5)$, $\\mathbf{E} = (0.25,\\,-0.2,\\,1.543)$, $\\mathbf{W} = (0.25,\\,-0.02,\\,1.543)$, $\\mathbf{H}_{hand} = (0.25,\\,0.08,\\,1.543)$,\n  - $\\mathbf{H}_{hip} = (0,\\,-0.1,\\,1.0)$, $\\mathbf{K} = (0,\\,-0.1,\\,0.55)$, $\\mathbf{A} = (0,\\,-0.1,\\,0.1)$, $m = 2.5$.\n\nYour program must compute the risk level $R$ for each of the four tasks and produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4]$), where each $r_i$ is an integer in $\\{1,2,3,4\\}$.", "solution": "The problem is evaluated as valid. It is scientifically grounded in vector kinematics and biomechanics, well-posed with a clear, deterministic path from inputs to a unique output, and objective in its definitions and rules. All necessary data and formulas are provided, and the setup is internally consistent and free of contradictions, with one minor exception.\n\nThe scoring rules dictate that the minimum possible value for the intermediate scores $A$ and $C$ is $3$ (since $A = S_{UA} + S_{EL} + S_{WE} + \\Delta_{WD} + L_a \\ge 1+1+1+0+0 = 3$ and $C = S_{N} + (S_{TR} + \\Delta_{LB}) + S_{LG} \\ge 1+1+0+1 = 3$). Consequently, the final composite score $S = \\max(A, C)$ must be at least $3$. The rule for determining the risk level $R$, `If $1 \\le S \\le 2$: R = 1`, defines a condition on $S$ that can never be met. This is a minor inconsistency but does not invalidate the problem, as all achievable scores $S$ fall into the other well-defined categories, allowing for a unique and correct solution to be computed for the given test cases.\n\nThe solution proceeds by implementing the specified calculations in a step-by-step manner.\n\n**1. Vector and Angle Calculation**\nThe core of the kinematic analysis is the calculation of angles between specified body segment vectors. For any two non-zero vectors $\\mathbf{a}$ and $\\mathbf{b}$, the angle $\\theta$ between them is computed using the dot product formula:\n$$\n\\theta = \\arccos\\left(\\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{a}\\| \\|\\mathbf{b}\\|}\\right)\n$$\nThe result of the $\\arccos$ function is in radians and must be converted to degrees via multiplication by $\\frac{180}{\\pi}$. To ensure numerical stability, the argument to $\\arccos$ is clipped to the range $[-1, 1]$. In cases where a projected vector (e.g., $\\mathbf{f}_{xy}$) becomes a zero vector, the resulting angle is defined as $0^\\circ$.\n\nThe specific vectors and angles are calculated as follows for each task dataset, which provides the 3D coordinates of points $\\mathbf{P}$ (pelvis), $\\mathbf{T}$ (torso top), $\\mathbf{H}_{head}$ (head center), $\\mathbf{S}$ (shoulder), $\\mathbf{E}$ (elbow), $\\mathbf{W}$ (wrist), $\\mathbf{H}_{hand}$ (hand tip), $\\mathbf{H}_{hip}$ (hip), $\\mathbf{K}$ (knee), $\\mathbf{A}$ (ankle), and the tool mass $m$. The global vertical up and down vectors are $\\hat{\\mathbf{z}}_{+} = (0,0,1)$ and $\\hat{\\mathbf{z}}_{-} = (0,0,-1)$, respectively.\n\n- **Upper Arm:** $\\mathbf{u} = \\mathbf{E} - \\mathbf{S}$. Shoulder elevation angle $\\theta_{UA} = \\angle(\\mathbf{u}, \\hat{\\mathbf{z}}_{-})$.\n- **Forearm:** $\\mathbf{f} = \\mathbf{W} - \\mathbf{E}$. Elbow angle $\\theta_{EL} = \\angle(-\\mathbf{u}, \\mathbf{f})$.\n- **Hand:** $\\mathbf{h} = \\mathbf{H}_{hand} - \\mathbf{W}$. Wrist extension angle $\\theta_{WE} = \\angle(\\mathbf{f}, \\mathbf{h})$. For wrist deviation, vectors are projected onto the horizontal plane: $\\mathbf{f}_{xy} = (f_x, f_y, 0)$ and $\\mathbf{h}_{xy} = (h_x, h_y, 0)$. The angle is $\\theta_{WD} = \\angle(\\mathbf{f}_{xy}, \\mathbf{h}_{xy})$.\n- **Trunk:** $\\mathbf{t} = \\mathbf{T} - \\mathbf{P}$. Trunk flexion angle $\\theta_{TR} = \\angle(\\mathbf{t}, \\hat{\\mathbf{z}}_{+})$. For lateral bend, the vector is projected to the frontal plane: $\\mathbf{t}_{yz} = (0, t_y, t_z)$. The angle is $\\theta_{LB} = \\angle(\\mathbf{t}_{yz}, \\hat{\\mathbf{z}}_{+})$.\n- **Neck:** $\\mathbf{n} = \\mathbf{H}_{head} - \\mathbf{T}$. Neck flexion angle $\\theta_{N} = \\angle(\\mathbf{n}, \\mathbf{t})$.\n- **Legs:** Thigh vector $\\mathbf{q} = \\mathbf{H}_{hip} - \\mathbf{K}$ and shank vector $\\mathbf{r} = \\mathbf{A} - \\mathbf{K}$. The inter-segment angle is $\\theta_{\\text{knee-seg}} = \\angle(\\mathbf{q}, \\mathbf{r})$. Knee flexion is then $\\theta_{KF} = 180^\\circ - \\theta_{\\text{knee-seg}}$.\n\n**2. Ergonomic Score Calculation**\nOnce all angles are computed in degrees, the specified threshold-based rules are applied to determine component scores, which are then summed to find the group scores $A$ and $C$.\n\n**Upper Limb Group Score ($A$)**\n- Shoulder elevation score $S_{UA}$ is determined from $\\theta_{UA}$.\n- Elbow score $S_{EL}$ is determined from $\\theta_{EL}$.\n- Wrist extension score $S_{WE}$ is determined from $\\theta_{WE}$.\n- Wrist deviation increment $\\Delta_{WD}$ is determined from $\\theta_{WD}$.\n- Load increment $L_a$ is $1$ if $m \\ge 2$, and $0$ otherwise.\n- The group score is the sum: $A = S_{UA} + S_{EL} + S_{WE} + \\Delta_{WD} + L_a$.\n\n**Neck-Trunk-Legs Group Score ($C$)**\n- Neck flexion score $S_{N}$ is determined from $\\theta_{N}$.\n- Trunk flexion score $S_{TR}$ is determined from $\\theta_{TR}$.\n- Trunk lateral bend increment $\\Delta_{LB}$ is determined from $\\theta_{LB}$.\n- Legs score $S_{LG}$ is determined from $\\theta_{KF}$.\n- The group score is the sum: $C = S_{N} + (S_{TR} + \\Delta_{LB}) + S_{LG}$.\n\n**3. Final Risk Level Determination**\nThe final composite score $S$ is the maximum of the two group scores: $S = \\max(A, C)$. This score is then mapped to a final risk level $R \\in \\{1, 2, 3, 4\\}$ according to the provided thresholds:\n- If $1 \\le S \\le 2$: $R = 1$ (unreachable as noted).\n- If $3 \\le S \\le 4$: $R = 2$.\n- If $5 \\le S \\le 6$: $R = 3$.\n- If $S \\ge 7$: $R = 4$.\n\nThis entire procedure is applied to each of the four test cases to generate the final list of risk levels.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final results.\n    \"\"\"\n    \n    # Define global coordinate system vectors\n    Z_PLUS = np.array([0.0, 0.0, 1.0])\n    Z_MINUS = np.array([0.0, 0.0, -1.0])\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        { # Task 1\n            \"P\": np.array([0.0, 0.0, 1.0]), \"T\": np.array([0.0, 0.0, 1.5]), \"H_head\": np.array([0.05, 0.0, 1.7]),\n            \"S\": np.array([0.0, -0.2, 1.5]), \"E\": np.array([0.0, -0.2, 1.2]), \"W\": np.array([0.2, -0.2, 1.2]),\n            \"H_hand\": np.array([0.35, -0.2, 1.2]), \"H_hip\": np.array([0.0, -0.1, 1.0]), \"K\": np.array([0.0, -0.1, 0.55]),\n            \"A\": np.array([0.0, -0.1, 0.1]), \"m\": 0.5\n        },\n        { # Task 2\n            \"P\": np.array([0.0, 0.0, 1.0]), \"T\": np.array([0.0, 0.0, 1.5]), \"H_head\": np.array([0.04, 0.0, 1.7]),\n            \"S\": np.array([0.0, -0.2, 1.5]), \"E\": np.array([0.144, -0.2, 1.25]), \"W\": np.array([0.344, -0.2, 1.25]),\n            \"H_hand\": np.array([0.444, -0.2, 1.30]), \"H_hip\": np.array([0.0, -0.1, 1.0]), \"K\": np.array([0.0, -0.1, 0.55]),\n            \"A\": np.array([0.0, -0.1, 0.1]), \"m\": 0.5\n        },\n        { # Task 3\n            \"P\": np.array([0.0, 0.0, 1.0]), \"T\": np.array([0.234, 0.0, 1.454]), \"H_head\": np.array([0.534, 0.0, 1.504]),\n            \"S\": np.array([0.234, -0.2, 1.404]), \"E\": np.array([0.378, -0.2, 1.154]), \"W\": np.array([0.578, -0.2, 1.154]),\n            \"H_hand\": np.array([0.578, -0.1, 1.154]), \"H_hip\": np.array([0.0, -0.1, 1.0]), \"K\": np.array([0.2, -0.1, 0.8]),\n            \"A\": np.array([0.0, -0.1, 0.4]), \"m\": 0.5\n        },\n        { # Task 4\n            \"P\": np.array([0.0, 0.0, 1.0]), \"T\": np.array([0.0, 0.0, 1.5]), \"H_head\": np.array([0.02, 0.0, 1.65]),\n            \"S\": np.array([0.0, -0.2, 1.5]), \"E\": np.array([0.25, -0.2, 1.543]), \"W\": np.array([0.25, -0.02, 1.543]),\n            \"H_hand\": np.array([0.25, 0.08, 1.543]), \"H_hip\": np.array([0.0, -0.1, 1.0]), \"K\": np.array([0.0, -0.1, 0.55]),\n            \"A\": np.array([0.0, -0.1, 0.1]), \"m\": 2.5\n        }\n    ]\n\n    def angle_between_vectors(v1, v2):\n        \"\"\"Computes the angle between two vectors in degrees.\"\"\"\n        norm_v1 = np.linalg.norm(v1)\n        norm_v2 = np.linalg.norm(v2)\n        if norm_v1 == 0 or norm_v2 == 0:\n            return 0.0\n        \n        dot_product = np.dot(v1, v2)\n        cos_theta = dot_product / (norm_v1 * norm_v2)\n        # Clip to handle potential floating-point inaccuracies\n        cos_theta = np.clip(cos_theta, -1.0, 1.0)\n        \n        theta_rad = np.arccos(cos_theta)\n        return np.rad2deg(theta_rad)\n\n    def calculate_risk(case):\n        \"\"\"Calculates the ergonomic risk level for a single task.\"\"\"\n        # 1. Compute segment vectors\n        u = case[\"E\"] - case[\"S\"]     # Upper arm\n        f = case[\"W\"] - case[\"E\"]     # Forearm\n        h = case[\"H_hand\"] - case[\"W\"] # Hand\n        t = case[\"T\"] - case[\"P\"]       # Torso\n        n = case[\"H_head\"] - case[\"T\"] # Neck\n        q = case[\"H_hip\"] - case[\"K\"] # Thigh\n        r = case[\"A\"] - case[\"K\"]       # Shank\n\n        # 2. Compute angles\n        theta_UA = angle_between_vectors(u, Z_MINUS)\n        theta_EL = angle_between_vectors(-u, f)\n        theta_WE = angle_between_vectors(f, h)\n        \n        f_xy = np.array([f[0], f[1], 0.0])\n        h_xy = np.array([h[0], h[1], 0.0])\n        theta_WD = angle_between_vectors(f_xy, h_xy)\n\n        theta_TR = angle_between_vectors(t, Z_PLUS)\n        t_yz = np.array([0.0, t[1], t[2]])\n        theta_LB = angle_between_vectors(t_yz, Z_PLUS)\n        \n        theta_N = angle_between_vectors(n, t)\n        \n        theta_knee_seg = angle_between_vectors(q, r)\n        theta_KF = 180.0 - theta_knee_seg\n\n        # 3. Compute Group A score\n        if 0 <= theta_UA <= 20: S_UA = 1\n        elif 20 < theta_UA <= 45: S_UA = 2\n        elif 45 < theta_UA <= 90: S_UA = 3\n        else: S_UA = 4\n\n        if 60 <= theta_EL <= 100: S_EL = 1\n        elif theta_EL < 60 or 100 < theta_EL <= 120: S_EL = 2\n        else: S_EL = 3\n        \n        if 0 <= theta_WE <= 15: S_WE = 1\n        elif 15 < theta_WE <= 30: S_WE = 2\n        else: S_WE = 3\n\n        if 0 <= theta_WD <= 10: Delta_WD = 0\n        elif 10 < theta_WD <= 20: Delta_WD = 1\n        else: Delta_WD = 2\n\n        L_a = 1 if case[\"m\"] >= 2 else 0\n        \n        A = S_UA + S_EL + S_WE + Delta_WD + L_a\n\n        # 4. Compute Group C score\n        if 0 <= theta_N <= 10: S_N = 1\n        elif 10 < theta_N <= 20: S_N = 2\n        elif 20 < theta_N <= 45: S_N = 3\n        else: S_N = 4\n\n        if 0 <= theta_TR <= 5: S_TR = 1\n        elif 5 < theta_TR <= 20: S_TR = 2\n        elif 20 < theta_TR <= 60: S_TR = 3\n        else: S_TR = 4\n        \n        Delta_LB = 1 if theta_LB > 10 else 0\n        \n        S_LG = 2 if theta_KF > 30 else 1\n\n        C = S_N + (S_TR + Delta_LB) + S_LG\n\n        # 5. Final composite score and risk level\n        S_final = max(A, C)\n\n        if 3 <= S_final <= 4: R = 2\n        elif 5 <= S_final <= 6: R = 3\n        elif S_final >= 7: R = 4\n        else: # Covers the unreachable 1 <= S <= 2 case\n            R = 1 \n        \n        return R\n\n    results = [calculate_risk(case) for case in test_cases]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "5183990"}, {"introduction": "Beyond individual physical strain, surgical safety hinges on the reliability of the entire operating room system, where process failures can have severe consequences. Failure Modes and Effects Analysis (FMEA) is a proactive method to identify potential failures, with the Risk Priority Number ($RPN$) serving as a core metric to prioritize mitigation efforts. This exercise elevates your perspective from ergonomics to systems-level thinking, teaching you how to apply a structured risk management framework to enhance patient safety under practical constraints [@problem_id:5184059].", "problem": "A high-fidelity simulation-based process analysis of Operating Room (OR) instrument setup is conducted to study human factors and ergonomics influences on reliability. The study aims to construct a Failure Modes and Effects Analysis (FMEA) to prioritize mitigations under a fixed resource budget. The FMEA uses an ordinal scale for severity, occurrence, and detectability difficulty, each rated from $1$ (best) to $10$ (worst). For each failure mode, the severity score $S$ estimates the harm magnitude to the patient if the failure occurs, the occurrence score $O$ approximates the likelihood of the failure during setup based on observed frequency in the simulation and ergonomic stressors, and the detectability score $D$ represents the difficulty of detecting the failure prior to patient impact. Derive, from first principles and core definitions of risk as expected loss under uncertainty and detectability as preemptive risk control, the FMEA risk scoring metric appropriate for ordinal scales, and then apply it to the following failure modes and candidate mitigations.\n\nBaseline failure modes (with scores derived from simulation logs and human factors assessment):\n\n- Failure Mode $1$ (FM$1$): powered driver torque miscalibration. Baseline scores: $S_{1}=8$, $O_{1}=4$, $D_{1}=7$.\n- Failure Mode $2$ (FM$2$): missing laparoscopic clip applier in tray. Baseline scores: $S_{2}=6$, $O_{2}=5$, $D_{2}=5$.\n- Failure Mode $3$ (FM$3$): sterility breach due to pack damage. Baseline scores: $S_{3}=9$, $O_{3}=3$, $D_{3}=6$.\n\nCandidate mitigations (resource costs and their effects on the ordinal scores are estimated from simulation interventions and ergonomic redesign prototyping):\n\n- Mitigation $M_{1}$ (preoperative calibration double-check), resource cost $c_{1}=3$: for FM$1$, reduces $O_{1}$ by $2$ points and reduces $D_{1}$ by $2$ points.\n- Mitigation $M_{2}$ (tray kitting with barcode verification), resource cost $c_{2}=4$: for FM$2$, reduces $O_{2}$ by $3$ points and reduces $D_{2}$ by $2$ points.\n- Mitigation $M_{3}$ (sterility integrity pressure-decay test), resource cost $c_{3}=5$: for FM$3$, reduces $O_{3}$ by $2$ points and reduces $D_{3}$ by $3$ points.\n\nAssume that mitigations only affect the specified failure modes and are additive in the sense that applying a mitigation changes the corresponding $O$ and $D$ by the stated amounts relative to baseline, with scores bounded below by $1$. You have a resource budget of $B=7$ units, and you may select any subset of the mitigations whose total cost does not exceed $B$.\n\nUsing the derived FMEA risk scoring metric, compute the aggregate baseline risk across the three failure modes and, for each feasible mitigation portfolio under the budget constraint, compute the aggregate risk after mitigation. Then determine the maximum achievable reduction in aggregate risk across all feasible portfolios.\n\nProvide the final answer as a single exact integer equal to the maximum achievable reduction in the aggregate risk metric across the three failure modes under the budget constraint. No rounding is required and no units are to be reported.", "solution": "The problem requires finding the optimal set of mitigations to maximize risk reduction under a budget. This involves three main steps: 1) deriving the appropriate risk metric, 2) calculating the baseline risk for the system, and 3) evaluating all feasible mitigation strategies to find the one that yields the maximum risk reduction.\n\n### 1. Derivation of the Risk Metric\nThe problem asks for a risk metric derived from first principles. Risk is fundamentally the expectation of loss, which can be expressed as the product of the probability of harm and the magnitude (consequence) of that harm. The FMEA scores serve as ordinal proxies for these quantities:\n- **Severity ($S$)** is a proxy for the magnitude of harm.\n- **Occurrence ($O$)** is a proxy for the probability of the failure mode occurring.\n- **Detectability ($D$)** represents the difficulty of detecting a failure. A higher $D$ score implies a higher probability that a failure will go undetected and lead to harm.\n\nTherefore, the probability of harm is proportional to the probability of occurrence multiplied by the probability of non-detection. The overall risk for a single failure mode can thus be modeled as the product of the three scores. This metric is commonly known as the Risk Priority Number (RPN).\n$$ \\text{Risk} = \\text{RPN} = S \\times O \\times D $$\nFor a system with multiple independent failure modes, the aggregate risk is the sum of the individual RPNs.\n$$ \\text{Aggregate Risk} = \\sum_{i} \\text{RPN}_i = \\sum_{i} S_i \\times O_i \\times D_i $$\nThis is the metric we will use to evaluate the system.\n\n### 2. Baseline Risk Calculation\nWe first calculate the baseline RPN for each failure mode (FM) and then sum them to get the aggregate baseline risk.\n- FM1: RPN$_1 = S_1 \\times O_1 \\times D_1 = 8 \\times 4 \\times 7 = 224$\n- FM2: RPN$_2 = S_2 \\times O_2 \\times D_2 = 6 \\times 5 \\times 5 = 150$\n- FM3: RPN$_3 = S_3 \\times O_3 \\times D_3 = 9 \\times 3 \\times 6 = 162$\n\nAggregate Baseline Risk = $224 + 150 + 162 = 536$.\n\n### 3. Evaluating Mitigation Portfolios\nThe total budget is $B=7$. The costs of the mitigations are $c_1=3$, $c_2=4$, and $c_3=5$. We identify all feasible portfolios (subsets of mitigations) whose total cost does not exceed 7:\n- $\\{M_1\\}$: cost = 3 (Feasible)\n- $\\{M_2\\}$: cost = 4 (Feasible)\n- $\\{M_3\\}$: cost = 5 (Feasible)\n- $\\{M_1, M_2\\}$: cost = 3 + 4 = 7 (Feasible)\n- Other combinations like $\\{M_1, M_3\\}$ (cost 8) and $\\{M_2, M_3\\}$ (cost 9) exceed the budget.\n\nNow, we calculate the risk reduction for each feasible portfolio. The risk reduction is the baseline aggregate risk minus the new aggregate risk.\n\n**Portfolio $\\{M_1\\}$**:\n- Affects FM1: New $O_1 = 4-2=2$, New $D_1 = 7-2=5$.\n- New RPN$_1 = 8 \\times 2 \\times 5 = 80$.\n- New Aggregate Risk = $80 + 150 + 162 = 392$.\n- Risk Reduction = $536 - 392 = 144$.\n\n**Portfolio $\\{M_2\\}$**:\n- Affects FM2: New $O_2 = 5-3=2$, New $D_2 = 5-2=3$.\n- New RPN$_2 = 6 \\times 2 \\times 3 = 36$.\n- New Aggregate Risk = $224 + 36 + 162 = 422$.\n- Risk Reduction = $536 - 422 = 114$.\n\n**Portfolio $\\{M_3\\}$**:\n- Affects FM3: New $O_3 = 3-2=1$, New $D_3 = 6-3=3$.\n- New RPN$_3 = 9 \\times 1 \\times 3 = 27$.\n- New Aggregate Risk = $224 + 150 + 27 = 401$.\n- Risk Reduction = $536 - 401 = 135$.\n\n**Portfolio $\\{M_1, M_2\\}$**:\n- Affects FM1 and FM2. The new RPNs are 80 (for FM1) and 36 (for FM2).\n- New Aggregate Risk = $80 + 36 + 162 = 278$.\n- Risk Reduction = $536 - 278 = 258$.\n\n### 4. Conclusion\nComparing the risk reductions from all feasible portfolios:\n- $\\{M_1\\}$: 144\n- $\\{M_2\\}$: 114\n- $\\{M_3\\}$: 135\n- $\\{M_1, M_2\\}$: 258\n\nThe maximum achievable reduction in aggregate risk is 258.", "answer": "$$\\boxed{258}$$", "id": "5184059"}, {"introduction": "Effective training is key to enhancing performance and mitigating risk, but a surgeon's training time is a finite resource that must be allocated efficiently. The \"law of practice\" can be modeled mathematically to predict competence gain, often as an exponential curve exhibiting diminishing returns. This advanced practice challenges you to use constrained optimization to solve a real-world training problem, mastering a quantitative approach to designing maximally efficient surgical curricula based on learning models and physical limitations [@problem_id:5184102].", "problem": "A resident surgeon trains multiple microskills using a simulation platform under fixed time availability. In human factors and ergonomics, a well-tested empirical regularity is the law of practice, which states that performance improves with repeated practice according to a diminishing-returns curve. One widely used representation for competence acquisition at the subskill level is an exponential saturation law rooted in motor learning principles: competence gain increases monotonically with practice time but with decreasing marginal returns as time increases. Consider $n$ subskills, indexed by $i \\in \\{1,\\dots,n\\}$. Let $t_i \\ge 0$ denote the practice time allocated to subskill $i$ (in minutes), let $w_i > 0$ denote the importance weight of subskill $i$ in overall competence, and let $\\alpha_i > 0$ denote the learning-rate parameter (per minute) for subskill $i$. The competence gain contributed by subskill $i$ is modeled as\n$$\ng_i(t_i) = w_i \\left(1 - e^{-\\alpha_i t_i}\\right).\n$$\nThe overall competence gain is the sum $\\sum_{i=1}^n g_i(t_i)$. The allocation must satisfy a total time budget $\\sum_{i=1}^n t_i \\le T$ (in minutes), and each subskill may optionally have a per-session fatigue cap $0 \\le t_i \\le m_i$ (in minutes), where $m_i$ can be set to $+\\infty$ to indicate no cap. This formulation assumes independent subskill gains that aggregate linearly, monotone concavity of $g_i(\\cdot)$ consistent with diminishing returns, and nonnegativity of decision variables and parameters.\n\nTask: Derive, from first principles, the optimal allocation rule that maximizes $\\sum_{i=1}^n g_i(t_i)$ subject to $\\sum_{i=1}^n t_i \\le T$ and $0 \\le t_i \\le m_i$, and implement a program that computes the optimal $t_i$ for several test cases. The derivation must start from fundamental convexity properties of $g_i(\\cdot)$ and constrained optimization stationarity conditions without using shortcut formulas. Your program must output the allocation vectors as lists of floats (minutes), rounded to three decimal places.\n\nPhysical and numerical units: All time quantities must be expressed in minutes, and all outputs must be rounded to three decimal places and presented in minutes.\n\nAngle units: No angles are involved.\n\nPercentages: No percentages are involved.\n\nTest suite and parameters:\n- Case $1$ (happy path, no per-subskill cap): $n=3$, $w=[\\,0.4,\\,0.35,\\,0.25\\,]$, $\\alpha=[\\,0.06,\\,0.03,\\,0.09\\,]$ per minute, $T=180$, $m=[\\,+\\infty,\\,+\\infty,\\,+\\infty\\,]$.\n- Case $2$ (boundary condition $T=0$): $n=3$, $w=[\\,0.4,\\,0.35,\\,0.25\\,]$, $\\alpha=[\\,0.06,\\,0.03,\\,0.09\\,]$ per minute, $T=0$, $m=[\\,+\\infty,\\,+\\infty,\\,+\\infty\\,]$.\n- Case $3$ (slow learning in the most important subskill): $n=3$, $w=[\\,0.6,\\,0.2,\\,0.2\\,]$, $\\alpha=[\\,0.01,\\,0.05,\\,0.07\\,]$ per minute, $T=120$, $m=[\\,+\\infty,\\,+\\infty,\\,+\\infty\\,]$.\n- Case $4$ (fatigue caps active): $n=4$, $w=[\\,0.3,\\,0.3,\\,0.2,\\,0.2\\,]$, $\\alpha=[\\,0.04,\\,0.02,\\,0.08,\\,0.03\\,]$ per minute, $T=150$, $m=[\\,50,\\,30,\\,20,\\,80\\,]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a list of the optimal allocations $[t_1,\\dots,t_n]$ for the corresponding case, e.g., $[[t^{(1)}_1,\\dots],[t^{(2)}_1,\\dots],\\dots]$, with each $t_i$ expressed in minutes and rounded to three decimal places.", "solution": "The task is to determine the optimal allocation of a fixed total time budget $T$ among $n$ subskills to maximize the total competence gain. This is a classic resource allocation problem that can be solved using the methods of constrained nonlinear optimization.\n\n### 1. Problem Formulation\n\nThe problem is to find the vector of practice times $\\mathbf{t} = [t_1, t_2, \\dots, t_n]$ that solves the following optimization problem:\n\n- **Maximize:**\n  $$G(\\mathbf{t}) = \\sum_{i=1}^n g_i(t_i) = \\sum_{i=1}^n w_i \\left(1 - e^{-\\alpha_i t_i}\\right)$$\n\n- **Subject to the constraints:**\n  1. Total time budget: $\\sum_{i=1}^n t_i \\le T$\n  2. Per-session fatigue caps: $0 \\le t_i \\le m_i$ for $i=1, \\dots, n$\n\nHere, $w_i > 0$ is the importance weight, $\\alpha_i > 0$ is the learning rate, $T \\ge 0$ is the total time, and $m_i \\ge 0$ is the time cap for subskill $i$. We note that maximizing $G(\\mathbf{t})$ is equivalent to minimizing its negative, $-G(\\mathbf{t}) = \\sum_{i=1}^n -w_i(1 - e^{-\\alpha_i t_i}) = \\sum_{i=1}^n w_i e^{-\\alpha_i t_i} - \\sum_{i=1}^n w_i$. Since $\\sum w_i$ is a constant with respect to $\\mathbf{t}$, this is equivalent to minimizing the function $F(\\mathbf{t}) = \\sum_{i=1}^n w_i e^{-\\alpha_i t_i}$.\n\n### 2. Convexity Analysis\n\nTo ensure that a solution found via stationarity conditions is a global optimum, we analyze the convexity of the problem.\n\nThe individual gain function for subskill $i$ is $g_i(t_i) = w_i(1 - e^{-\\alpha_i t_i})$. We compute its first and second derivatives with respect to $t_i$:\n- First derivative (marginal gain):\n  $$\\frac{d g_i}{d t_i} = \\frac{d}{d t_i} \\left[ w_i - w_i e^{-\\alpha_i t_i} \\right] = w_i \\alpha_i e^{-\\alpha_i t_i}$$\n  Since $w_i > 0$ and $\\alpha_i > 0$, the first derivative is always positive, confirming that competence gain is a monotonically increasing function of practice time.\n\n- Second derivative:\n  $$\\frac{d^2 g_i}{d t_i^2} = \\frac{d}{d t_i} \\left[ w_i \\alpha_i e^{-\\alpha_i t_i} \\right] = -w_i \\alpha_i^2 e^{-\\alpha_i t_i}$$\n  Since $w_i > 0$ and $\\alpha_i^2 > 0$, the second derivative is strictly negative for all $t_i \\ge 0$. This proves that each function $g_i(t_i)$ is strictly concave.\n\nThe objective function $G(\\mathbf{t})$ is a sum of concave functions, which makes it a concave function. The feasible region, defined by the linear inequality $\\sum t_i \\le T$ and the box constraints $0 \\le t_i \\le m_i$, is a convex set (specifically, a convex polytope). Maximizing a concave function over a convex set is a convex optimization problem. For such problems, the Karush-Kuhn-Tucker (KKT) conditions are sufficient for a point to be a global maximum.\n\n### 3. Lagrangian and KKT Conditions\n\nWe formulate the Lagrangian function $\\mathcal{L}$ for the maximization problem, incorporating the constraints with Lagrange multipliers $\\lambda \\ge 0$ (for the total time budget), $\\mu_i \\ge 0$ (for the upper bounds $t_i \\le m_i$), and $\\nu_i \\ge 0$ (for the non-negativity constraints $t_i \\ge 0$, written as $-t_i \\le 0$).\n\n$$\n\\mathcal{L}(\\mathbf{t}, \\lambda, \\boldsymbol{\\mu}, \\boldsymbol{\\nu}) = \\sum_{i=1}^n w_i (1 - e^{-\\alpha_i t_i}) - \\lambda \\left(\\sum_{i=1}^n t_i - T\\right) - \\sum_{i=1}^n \\mu_i (t_i - m_i) + \\sum_{i=1}^n \\nu_i t_i\n$$\n\nThe KKT conditions for an optimal solution $\\mathbf{t}^*$ are:\n1.  **Stationarity:** $\\frac{\\partial \\mathcal{L}}{\\partial t_i} = 0$ for all $i=1, \\dots, n$.\n2.  **Primal Feasibility:** $\\sum_{i=1}^n t_i^* \\le T$ and $0 \\le t_i^* \\le m_i$ for all $i$.\n3.  **Dual Feasibility:** $\\lambda \\ge 0$, $\\mu_i \\ge 0$, $\\nu_i \\ge 0$ for all $i$.\n4.  **Complementary Slackness:**\n    - $\\lambda(\\sum_{i=1}^n t_i^* - T) = 0$\n    - $\\mu_i(t_i^* - m_i) = 0$ for all $i$.\n    - $\\nu_i t_i^* = 0$ for all $i$.\n\n### 4. Derivation of the Optimal Allocation Rule\n\nFrom the stationarity condition, we have:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial t_i} = \\frac{d g_i}{d t_i} - \\lambda - \\mu_i + \\nu_i = w_i \\alpha_i e^{-\\alpha_i t_i^*} - \\lambda - \\mu_i + \\nu_i = 0\n$$\nThis gives the key relationship for the marginal gain at the optimum:\n$$\nw_i \\alpha_i e^{-\\alpha_i t_i^*} = \\lambda + \\mu_i - \\nu_i\n$$\nThe Lagrange multiplier $\\lambda$ represents the marginal value of an additional minute of total practice time, i.e., the shadow price of the time budget. We analyze the optimal time $t_i^*$ by considering the complementary slackness conditions:\n\n- **Case 1: $0 < t_i^* < m_i$ (Interior solution)**\n  The non-negativity and upper-bound constraints are not active. Complementary slackness implies $\\nu_i = 0$ and $\\mu_i = 0$. The stationarity condition simplifies to:\n  $$w_i \\alpha_i e^{-\\alpha_i t_i^*} = \\lambda$$\n  This signifies that for any subskill practiced for a non-zero time that does not hit its cap, the marginal gain at the optimal time must be equal to the common shadow price $\\lambda$. Solving for $t_i^*$:\n  $$e^{-\\alpha_i t_i^*} = \\frac{\\lambda}{w_i \\alpha_i} \\implies t_i^* = -\\frac{1}{\\alpha_i} \\ln\\left(\\frac{\\lambda}{w_i \\alpha_i}\\right) = \\frac{1}{\\alpha_i} \\ln\\left(\\frac{w_i \\alpha_i}{\\lambda}\\right)$$\n  This is valid only if $w_i \\alpha_i > \\lambda$, ensuring $t_i^* > 0$.\n\n- **Case 2: $t_i^* = 0$**\n  The non-negativity constraint is active, so $\\nu_i \\ge 0$. Since $m_i > 0$ (for non-trivial caps), the upper bound is not active, so $\\mu_i=0$. The stationarity condition is $w_i \\alpha_i e^0 = \\lambda + 0 - \\nu_i$, which implies $w_i \\alpha_i = \\lambda - \\nu_i$. Since $\\nu_i \\ge 0$, this leads to $w_i \\alpha_i \\le \\lambda$. This means if the initial marginal gain for a subskill is less than or equal to the shadow price $\\lambda$, no time should be allocated to it.\n\n- **Case 3: $t_i^* = m_i$**\n  The upper-bound constraint is active, so $\\mu_i \\ge 0$. The non-negativity constraint is not active (as $m_i > 0$), so $\\nu_i=0$. The stationarity condition is $w_i \\alpha_i e^{-\\alpha_i m_i} = \\lambda + \\mu_i - 0$. Since $\\mu_i \\ge 0$, this leads to $w_i \\alpha_i e^{-\\alpha_i m_i} \\ge \\lambda$. If the marginal gain after practicing for the maximum allowed time $m_i$ is still greater than or equal to the shadow price $\\lambda$, then the allocation for that subskill should be capped at $m_i$.\n\nCombining these three cases yields a single rule for the optimal allocation $t_i^*$ as a function of the unknown shadow price $\\lambda$:\n$$\nt_i^*(\\lambda) = \\min\\left(m_i, \\max\\left(0, \\frac{1}{\\alpha_i} \\ln\\left(\\frac{w_i \\alpha_i}{\\lambda}\\right)\\right)\\right)\n$$\nThis can be expressed compactly using the median function: $t_i^*(\\lambda) = \\text{median}\\left(0, m_i, \\frac{1}{\\alpha_i} \\ln(\\frac{w_i \\alpha_i}{\\lambda})\\right)$.\n\n### 5. Algorithmic Solution to Find $\\lambda$\n\nThe final step is to determine the value of $\\lambda$.\nFirst consider a special case: if $\\sum_{i=1}^n m_i \\le T$, there is enough total time to practice each subskill up to its individual cap. Since the marginal gains are always non-negative, the optimal solution is to set $t_i^* = m_i$ for all $i$.\n\nIf $\\sum_{i=1}^n m_i > T$, the total time budget is a binding constraint. From complementary slackness, we must have $\\sum_{i=1}^n t_i^* - T = 0$. This implies we must find $\\lambda > 0$ that solves the equation:\n$$\n\\sum_{i=1}^n t_i^*(\\lambda) = T\n$$\nLet's define the function $f(\\lambda) = \\sum_{i=1}^n t_i^*(\\lambda)$. Each term $t_i^*(\\lambda)$ is a non-increasing function of $\\lambda$, and is strictly decreasing for $\\lambda$ values that yield an interior solution for $t_i^*$. Thus, $f(\\lambda)$ is a monotonically decreasing function of $\\lambda$. This property allows us to find the unique root $\\lambda$ that satisfies $f(\\lambda)=T$ efficiently using a numerical method like binary search (bisection).\n\nThe algorithm is as follows:\n1.  If $\\sum m_i \\le T$, the solution is $t_i = m_i$ for all $i$.\n2.  Otherwise, the time constraint is active, and we search for $\\lambda > 0$.\n3.  Establish a search interval for $\\lambda$. The lower bound can be $0$. An upper bound is $\\max_i(w_i \\alpha_i)$, because if $\\lambda$ exceeds this value, all $t_i^*$ would be $0$, and the total time sum would be $0$, which is less than $T$ (assuming $T>0$).\n4.  Use binary search on $\\lambda$ within this interval:\n    a. Pick a midpoint $\\lambda_{\\text{mid}}$.\n    b. Calculate the total time demand $T_{\\text{calc}} = \\sum_i t_i^*(\\lambda_{\\text{mid}})$.\n    c. If $T_{\\text{calc}} > T$, the trial $\\lambda_{\\text{mid}}$ is too low, so we need to increase it. Set the new lower bound of the search to $\\lambda_{\\text{mid}}$.\n    d. If $T_{\\text{calc}} < T$, the trial $\\lambda_{\\text{mid}}$ is too high. Set the new upper bound to $\\lambda_{\\text{mid}}$.\n5.  Repeat for a sufficient number of iterations to converge to the $\\lambda$ that results in $\\sum t_i^* \\approx T$.\n6.  Use the final converged value of $\\lambda$ to compute the optimal allocation vector $\\mathbf{t}^* = [t_1^*(\\lambda), \\dots, t_n^*(\\lambda)]$.\n\nThis procedure provides a complete, principled, and computationally efficient method for solving the given optimization problem.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: happy path, no per-subskill cap\n        {'n': 3, 'w': np.array([0.4, 0.35, 0.25]), 'alpha': np.array([0.06, 0.03, 0.09]), 'T': 180.0, 'm': np.array([np.inf, np.inf, np.inf])},\n        # Case 2: boundary condition T=0\n        {'n': 3, 'w': np.array([0.4, 0.35, 0.25]), 'alpha': np.array([0.06, 0.03, 0.09]), 'T': 0.0, 'm': np.array([np.inf, np.inf, np.inf])},\n        # Case 3: slow learning in the most important subskill\n        {'n': 3, 'w': np.array([0.6, 0.2, 0.2]), 'alpha': np.array([0.01, 0.05, 0.07]), 'T': 120.0, 'm': np.array([np.inf, np.inf, np.inf])},\n        # Case 4: fatigue caps active\n        {'n': 4, 'w': np.array([0.3, 0.3, 0.2, 0.2]), 'alpha': np.array([0.04, 0.02, 0.08, 0.03]), 'T': 150.0, 'm': np.array([50.0, 30.0, 20.0, 80.0])}\n    ]\n\n    results = []\n    for case in test_cases:\n        optimal_t = solve_case(case['w'], case['alpha'], case['T'], case['m'])\n        results.append(optimal_t)\n\n    # Format the final output string exactly as required.\n    # [list_of_floats_1,list_of_floats_2,...]\n    # No spaces within each list, e.g., '[1.0,2.0]'\n    formatted_results = [str(res).replace(\" \", \"\") for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef get_t(lmbda, w, alpha, m):\n    \"\"\"\n    Calculates t_i for a given lambda (lmbda) based on the derived formula.\n    t_i(lambda) = min(m_i, max(0, (1/alpha_i) * log((w_i * alpha_i) / lambda)))\n    \"\"\"\n    if lmbda <= 0:\n        return m\n\n    initial_marginal_gains = w * alpha\n    \n    # To avoid log(<=0), we only calculate for items where gain > lambda\n    # For a vectorized implementation, we can use np.where, or rely on np.log\n    # producing -inf and then use np.maximum(0, ...)\n    # However, to be safe against warnings/errors:\n    ratio = np.divide(initial_marginal_gains, lmbda, \n                      out=np.zeros_like(initial_marginal_gains, dtype=float), \n                      where=initial_marginal_gains > lmbda)\n    \n    # Calculate unconstrained times for valid ratios\n    unconstrained_t = np.zeros_like(w, dtype=float)\n    valid_indices = ratio > 1  # log(x) > 0 for x > 1\n    if np.any(valid_indices):\n        unconstrained_t[valid_indices] = (1 / alpha[valid_indices]) * np.log(ratio[valid_indices])\n\n    # Apply non-negativity (already handled by logic) and fatigue caps\n    t = np.minimum(m, unconstrained_t)\n    return t\n\ndef solve_case(w, alpha, T, m):\n    \"\"\"\n    Solves the allocation problem for a single case.\n    \"\"\"\n    n = len(w)\n\n    # Handle boundary case T=0\n    if T == 0:\n        return [0.0] * n\n\n    # Handle case where total time budget exceeds sum of all caps\n    sum_m = np.sum(m)\n    if sum_m <= T:\n        # If any m_i is inf, sum_m will be inf, and this path won't be taken unless T is also inf.\n        # We replace inf with T to handle this edge case, as it's not possible to spend infinite time.\n        # However, the optimal solution is simply to allocate m_i.\n        final_t = np.minimum(m, T) # In case one m_i is inf, just cap it at T\n        # More accurately, if sum m_i is finite and <= T, t_i = m_i.\n        # This implementation will return m_i. If a m_i is inf, the problem is under-constrained\n        # without additional information. Here, np.sum handles inf correctly.\n        final_t = np.round(m, 3).tolist()\n        # Correctly handle infinite caps\n        finite_m_indices = np.isfinite(m)\n        if np.all(finite_m_indices):\n            return np.round(m, 3).tolist()\n        else:\n            # This case means sum of finite caps is less than T, and other caps are infinite.\n            # This requires running the optimizer on the unconstrained subskills with remaining time.\n            # The general binary search handles this naturally.\n            pass\n\n\n    # Binary search for the optimal lambda\n    # Range for lambda: [0, max(w*alpha)]\n    initial_marginal_gains = w * alpha\n    lambda_low = 0.0\n    # A safe upper bound for lambda. If lambda is higher, all t_i will be 0.\n    lambda_high = np.max(initial_marginal_gains) \n    \n    # Iteratively find lambda\n    for _ in range(100): # 100 iterations are sufficient for high precision\n        lambda_mid = (lambda_low + lambda_high) / 2.0\n        if lambda_mid == lambda_low or lambda_mid == lambda_high: # Reached precision limit\n            break\n        \n        t_current = get_t(lambda_mid, w, alpha, m)\n        total_t = np.sum(t_current)\n        \n        if total_t > T:\n            # Allocated too much time, lambda is too small. Increase lambda.\n            lambda_low = lambda_mid\n        else:\n            # Allocated too little time, lambda is too large. Decrease lambda.\n            lambda_high = lambda_mid\n            \n    # Final optimal lambda is lambda_high (or low), as they converge. lambda_high ensures total_t <= T\n    optimal_lambda = lambda_high\n    final_t = get_t(optimal_lambda, w, alpha, m)\n\n    # Due to float precision, sum(final_t) might be slightly less than T.\n    # The problem doesn't specify if the sum must be exactly T.\n    # The KKT conditions only require sum(t_i) <= T, and sum(t_i) < T implies lambda=0,\n    # which is handled. A small deviation from T is acceptable.\n    \n    # Round to three decimal places and convert to list\n    return np.round(final_t, 3).tolist()\n\nsolve()\n```", "id": "5184102"}]}