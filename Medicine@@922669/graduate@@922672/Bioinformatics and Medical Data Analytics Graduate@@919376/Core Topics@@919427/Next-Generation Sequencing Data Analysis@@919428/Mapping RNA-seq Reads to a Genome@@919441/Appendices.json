{"hands_on_practices": [{"introduction": "The accuracy of RNA-seq analysis begins with rigorous data preprocessing. This exercise challenges you to implement a complete FASTQ quality control pipeline, a critical first step for any mapping workflow. By algorithmically defining rules for adapter trimming, quality filtering, and length control, you will gain a concrete understanding of how raw sequencing reads are prepared for downstream alignment [@problem_id:4580665].", "problem": "You are given a set of synthetic deoxyribonucleic acid (DNA) sequencing reads in FASTQ form and are asked to implement a rigorous preprocessing and quality filtering pipeline that is directly relevant to downstream mapping of ribonucleic acid sequencing (RNA-seq) reads to a genome. The pipeline must be implemented exactly as specified and must be applied to the provided test suite. The objective is to formalize the preprocessing logic in purely mathematical and algorithmic terms grounded in well-tested bioinformatics principles.\n\nFundamental base and definitions:\n- Phred quality score definition: for each base call, the Phred score $Q$ is defined by $Q = -10 \\log_{10}(p_{\\mathrm{error}})$, where $p_{\\mathrm{error}}$ is the probability that the base call is incorrect. The Sanger FASTQ encoding (Phred$+33$) maps a quality character $q$ to $Q = \\mathrm{ord}(q) - 33$, where $\\mathrm{ord}(\\cdot)$ is the integer code point function.\n- Independence assumption: under the standard approximation used in many preprocessing tools, expected errors over a read segment can be computed as the sum of base-wise error probabilities $p_i = 10^{-Q_i/10}$ across retained bases.\n\nTarget preprocessing pipeline to implement:\n1. Adapter trimming at the $3'$ end:\n   - Let the adapter sequence be a fixed string $A$ and the read sequence be a string $S$ of length $n$ with quality characters $q_1,\\dots,q_n$.\n   - For overlap lengths $L$ iterating from $|A|$ down to $k_{\\min}$, compute the mismatch count between the suffix $S[n-L+1,\\dots,n]$ and the prefix $A[1,\\dots,L]$ under position-wise comparison. If the count is less than or equal to $m_{\\max}$ for the first such $L$ encountered, trim exactly the last $L$ bases from the read and the corresponding last $L$ quality characters. If no such $L$ is found, do not trim.\n2. Sliding-window quality trimming from both ends:\n   - Map each quality character to its Phred score $Q_i = \\mathrm{ord}(q_i)-33$.\n   - Left-trim rule: for window size $w$ and minimum average quality threshold $Q_{\\min}$, scan windows $[i,i+w-1]$ for $i=0,\\dots,n-w$. Identify the smallest index $s$ such that the arithmetic mean $\\frac{1}{w}\\sum_{j=i}^{i+w-1} Q_j \\ge Q_{\\min}$ holds at $i=s$. Set the retained start to $s$. If no window satisfies the threshold, the read is discarded with zero output.\n   - Right-trim rule: scan windows $[e-w,e-1]$ for $e=w,\\dots,n$ from right to left. Identify the largest index $e$ such that $\\frac{1}{w}\\sum_{j=e-w}^{e-1} Q_j \\ge Q_{\\min}$ holds. Set the retained end to $e$. If no window satisfies the threshold, the read is discarded with zero output.\n   - The retained segment is $S[s,\\dots,e-1]$ with quality scores $Q_s,\\dots,Q_{e-1}$. If $s \\ge e$, the read is discarded with zero output.\n3. Ambiguity and length filters:\n   - Let the fraction of ambiguous bases be $f_N = \\frac{\\text{count of 'N' in }S[s,\\dots,e-1]}{e-s}$. If $f_N > f_{N,\\max}$, discard the read.\n   - If the retained length $\\ell = e-s$ is strictly less than the minimum length $L_{\\min}$, discard the read.\n4. Metrics to report for retained reads:\n   - Retained length $\\ell$ as an integer.\n   - Mean base quality $\\bar{Q} = \\frac{1}{\\ell}\\sum_{i=s}^{e-1} Q_i$, rounded to three decimal places.\n   - Expected number of base call errors $E = \\sum_{i=s}^{e-1} 10^{-Q_i/10}$, rounded to three decimal places.\n   - Pass indicator as a boolean that is true if the read was retained and false if discarded by any filter.\n5. Output for discarded reads:\n   - If the read fails any filter, output the quadruple $[\\ell,\\bar{Q},E,\\mathrm{pass}]$ as $[0,0.0,0.0,\\mathrm{false}]$.\n\nYour program must implement the above logic and process the following test suite. Each test case provides $(S, q\\_str, A, w, Q_{\\min}, L_{\\min}, f_{N,\\max}, k_{\\min}, m_{\\max})$:\n- Test case $1$ (happy path with adapter trimming):\n  - $S$: the string \"ACGT\" repeated $15$ times, followed by \"AGATCGGAAG\". That is $S = \\text{\"ACGT\"} \\times 15 \\, \\Vert \\, \\text{\"AGATCGGAAG\"}$.\n  - $q\\_str$: the character \"I\" repeated $60$ times, followed by \"!\" repeated $10$ times. That is $q\\_str = \\text{\"I\"} \\times 60 \\, \\Vert \\, \\text{\"!\"} \\times 10$.\n  - $A$: \"AGATCGGAAGAGC\".\n  - $w = 5$, $Q_{\\min} = 20$, $L_{\\min} = 30$, $f_{N,\\max} = 0.1$, $k_{\\min} = 8$, $m_{\\max} = 1$.\n- Test case $2$ (high quality but excessive ambiguity):\n  - $S$: \"N\" repeated $15$ times, followed by \"A\" repeated $35$ times. That is $S = \\text{\"N\"} \\times 15 \\, \\Vert \\, \\text{\"A\"} \\times 35$.\n  - $q\\_str$: \"I\" repeated $50$ times. That is $q\\_str = \\text{\"I\"} \\times 50$.\n  - $A$: \"AGATCGGAAGAGC\".\n  - $w = 5$, $Q_{\\min} = 20$, $L_{\\min} = 30$, $f_{N,\\max} = 0.2$, $k_{\\min} = 8$, $m_{\\max} = 1$.\n- Test case $3$ (insufficient length after trimming):\n  - $S$: the string \"ACGT\" repeated $10$ times. That is $S = \\text{\"ACGT\"} \\times 10$.\n  - $q\\_str$: \"!\" repeated $20$ times, followed by \"I\" repeated $20$ times. That is $q\\_str = \\text{\"!\"} \\times 20 \\, \\Vert \\, \\text{\"I\"} \\times 20$.\n  - $A$: \"AGATCGGAAGAGC\".\n  - $w = 5$, $Q_{\\min} = 25$, $L_{\\min} = 30$, $f_{N,\\max} = 0.1$, $k_{\\min} = 8$, $m_{\\max} = 0$.\n- Test case $4$ (adapter absent, mixed ends, moderate ambiguity):\n  - $S$: the string \"ACGT\" repeated $10$ times, followed by \"NNNNN\", followed by \"TGCA\" repeated $5$ times, followed by \"ACGTA\". That is $S = \\text{\"ACGT\"} \\times 10 \\, \\Vert \\, \\text{\"NNNNN\"} \\, \\Vert \\, \\text{\"TGCA\"} \\times 5 \\, \\Vert \\, \\text{\"ACGTA\"}$.\n  - $q\\_str$: \"!\" repeated $3$ times, followed by \"I\" repeated $64$ times, followed by \"!\" repeated $3$ times. That is $q\\_str = \\text{\"!\"} \\times 3 \\, \\Vert \\, \\text{\"I\"} \\times 64 \\, \\Vert \\, \\text{\"!\"} \\times 3$.\n  - $A$: \"AGATCGGAAGAGC\".\n  - $w = 4$, $Q_{\\min} = 30$, $L_{\\min} = 50$, $f_{N,\\max} = 0.1$, $k_{\\min} = 8$, $m_{\\max} = 1$.\n- Test case $5$ (boundary case with $w=1$ for base-wise thresholding):\n  - $S$: \"ACGTACGTACGT\".\n  - $q\\_str$: \"A5?@B?A=A>5?\" where each character maps via Phred$+$33 encoding.\n  - $A$: \"AGATCGGAAGAGC\".\n  - $w = 1$, $Q_{\\min} = 30$, $L_{\\min} = 5$, $f_{N,\\max} = 0.0$, $k_{\\min} = 6$, $m_{\\max} = 0$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all five test cases as a comma-separated list enclosed in square brackets. Each test case’s result must be a list of the form $[\\ell,\\bar{Q},E,\\mathrm{pass}]$, where $\\ell$ is an integer, $\\bar{Q}$ and $E$ are floats rounded to three decimal places, and $\\mathrm{pass}$ is a boolean. For discarded reads, output $[0,0.0,0.0,\\mathrm{false}]$.\n- Example format (not the actual answers): $[[12,35.200,0.015,\\mathrm{true}],[0,0.0,0.0,\\mathrm{false}],\\dots]$.", "solution": "The problem statement presents a well-defined and scientifically grounded task from the field of bioinformatics: to implement a specific sequence preprocessing pipeline for DNA sequencing reads. The pipeline's components—adapter trimming, sliding-window quality filtering, and filtering based on length and ambiguous base content—are standard procedures in preparing raw sequencing data for downstream analysis, such as mapping reads to a reference genome. All parameters, definitions, and algorithmic steps are specified with sufficient precision to permit a unique and deterministic implementation. The problem is therefore deemed valid.\n\nThe solution will be presented as a step-by-step algorithmic procedure, formalizing the logic described in the problem statement. All mathematical entities are rendered in LaTeX as required.\n\n### I. Formalization of the Preprocessing Algorithm\n\nLet a single read be represented by a sequence of bases $S$ and a corresponding string of quality characters $q_{str}$. Let the pipeline parameters be an adapter sequence $A$, a window size $w$, a minimum average quality threshold $Q_{\\min}$, a minimum retained length $L_{\\min}$, a maximum ambiguous base fraction $f_{N,\\max}$, a minimum adapter overlap $k_{\\min}$, and a maximum mismatch count $m_{\\max}$.\n\nA discard action results in the output $[0, 0.0, 0.0, \\mathrm{false}]$.\n\n**Step 0: Initial Transformation**\nThe input quality string $q_{str}$ is first converted into an array of Phred quality scores, $Q_{arr}$, using the Sanger (Phred$+33$) encoding:\n$$\n(Q_{arr})_i = \\mathrm{ord}((q_{str})_i) - 33\n$$\nwhere $\\mathrm{ord}(\\cdot)$ is the ASCII code point function. Let the initial read length be $n_0 = |S|$.\n\n**Step 1: 3' Adapter Trimming**\nThis step removes adapter sequences from the $3'$ end of the read.\n1.  Let the current read be $S'$ and quality string be $q'_{str}$. Initially, $S' \\leftarrow S$ and $q'_{str} \\leftarrow q_{str}$.\n2.  Iterate the overlap length $L$ from $L_{start} = \\min(|A|, |S'|)$ down to $k_{\\min}$.\n3.  For each $L$, compare the suffix of the read of length $L$, $S'[\\text{end}-L+1 : \\text{end}]$, with the prefix of the adapter of length $L$, $A[1:L]$.\n4.  Let the number of mismatches be $m$. If $m \\le m_{\\max}$, this is considered a match. Since we iterate from the longest possible overlap downwards, the first match found is the one we accept.\n5.  Upon finding such a match for length $L$, the read and its quality string are trimmed by removing the last $L$ characters.\n    -   $S_{new} \\leftarrow S'[1 : \\text{end}-L]$\n    -   $q_{new\\_str} \\leftarrow q'_{str}[1 : \\text{end}-L]$\n    The process then terminates for this read and proceeds to the next step with the trimmed sequences.\n6.  If the loop completes with no match found, the read is not trimmed.\n\nLet the read sequence and quality array after this step be $S_1$ and $Q_1$, with length $n_1 = |S_1|$. If $n_1 < w$, the read cannot be processed by the sliding window filter and is discarded.\n\n**Step 2: Sliding-Window Quality Trimming**\nThis step trims low-quality regions from both ends of the read.\n1.  **Left trim (finding start position $s$):**\n    We scan windows of size $w$ from left to right. The first window whose average quality meets the threshold $Q_{\\min}$ defines the start of the high-quality region.\n    -   We seek the smallest index $s \\in [0, n_1-w]$ such that:\n        $$\n        \\frac{1}{w} \\sum_{j=s}^{s+w-1} (Q_1)_j \\ge Q_{\\min}\n        $$\n    -   If no such index $s$ exists, the read is discarded.\n2.  **Right trim (finding end position $e$):**\n    We scan windows of size $w$ from right to left. The last window whose average quality meets the threshold $Q_{\\min}$ defines the end of the high-quality region.\n    -   We seek the largest index $e \\in [w, n_1]$ such that the window ending at $e-1$ qualifies:\n        $$\n        \\frac{1}{w} \\sum_{j=e-w}^{e-1} (Q_1)_j \\ge Q_{\\min}\n        $$\n    -   If no such index $e$ exists, the read is discarded.\n3.  **Final Segment:** The retained segment is defined by the interval $[s, e)$. The new read is $S_2 = S_1[s:e]$ and its quality scores are $Q_2 = Q_1[s:e]$. If $s \\ge e$, the resulting segment is empty or invalid, and the read is discarded.\n\n**Step 3: Ambiguity and Length Filtering**\nThe retained read $S_2$ is subjected to final checks.\n1.  **Length Filter:**\n    The length of the retained read is $\\ell = |S_2| = e-s$. If $\\ell < L_{\\min}$, the read is too short and is discarded.\n2.  **Ambiguity Filter:**\n    The fraction of ambiguous bases ('N') in the retained read, $f_N$, is calculated:\n    $$\n    f_N = \\frac{\\text{count of 'N' in } S_2}{\\ell}\n    $$\n    If $f_N > f_{N,\\max}$, the read has too many ambiguous bases and is discarded. This check is only performed if $\\ell>0$.\n\n**Step 4: Metric Calculation for Retained Reads**\nIf a read passes all filters, we compute the following metrics on the final sequence $S_2$ and its qualities $Q_2$ of length $\\ell$:\n1.  **Retained Length:** $\\ell$.\n2.  **Mean Base Quality:** The arithmetic mean of the Phred scores of the retained bases.\n    $$\n    \\bar{Q} = \\frac{1}{\\ell} \\sum_{i=0}^{\\ell-1} (Q_2)_i\n    $$\n3.  **Expected Errors:** The sum of error probabilities for each retained base. The error probability $p_i$ for a base with quality score $(Q_2)_i$ is $p_i = 10^{-(Q_2)_i/10}$.\n    $$\n    E = \\sum_{i=0}^{\\ell-1} 10^{-(Q_2)_i/10}\n    $$\n4.  **Pass Indicator:** A boolean value, `true`.\n\nThe final output for a passing read is $[\\ell, \\mathrm{round}(\\bar{Q}, 3), \\mathrm{round}(E, 3), \\mathrm{true}]$.\n\nThis rigorous, multi-stage pipeline ensures that only high-quality, biologically informative sequences are passed on to subsequent, more computationally intensive analyses. The implementation below will precisely follow this described logic.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef process_read(S, q_str, A, w, Q_min, L_min, f_N_max, k_min, m_max):\n    \"\"\"\n    Implements the full preprocessing pipeline for a single DNA sequencing read.\n    \"\"\"\n    \n    # --- Step 1: Adapter Trimming ---\n    s_current, q_current = S, q_str\n    \n    # Iterate from longest possible overlap down to the minimum\n    adapter_len = len(A)\n    read_len_initial = len(s_current)\n    \n    trimmed = False\n    for L in range(min(adapter_len, read_len_initial), k_min - 1, -1):\n        if L == 0: continue\n        read_suffix = s_current[read_len_initial - L:]\n        adapter_prefix = A[:L]\n        \n        mismatches = sum(1 for i in range(L) if read_suffix[i] != adapter_prefix[i])\n        \n        if mismatches <= m_max:\n            s_current = s_current[:read_len_initial - L]\n            q_current = q_current[:read_len_initial - L]\n            trimmed = True\n            break\n            \n    # --- Step 2: Quality Trimming ---\n    read_len_after_adapter = len(s_current)\n    \n    if read_len_after_adapter < w:\n        return [0, 0.0, 0.0, False]\n        \n    q_scores = np.array([ord(c) - 33 for c in q_current], dtype=float)\n    \n    if read_len_after_adapter == w:\n        window_avgs = np.array([np.mean(q_scores)])\n    else:\n        window_avgs = np.convolve(q_scores, np.ones(w, dtype=float), 'valid') / w\n\n    qualifying_indices = np.where(window_avgs >= Q_min)[0]\n    \n    if qualifying_indices.size == 0:\n        return [0, 0.0, 0.0, False]\n        \n    s = qualifying_indices[0]\n    # The end of the retained segment is the end of the last qualifying window.\n    # The last qualifying window starts at index `qualifying_indices[-1]`.\n    # A window starting at index `i` ends at index `i+w-1`. The slice is `[i:i+w]`.\n    e = qualifying_indices[-1] + w\n    \n    if s >= e:\n        return [0, 0.0, 0.0, False]\n\n    # Apply the trim\n    s_trimmed = s_current[s:e]\n    q_trimmed_scores = q_scores[s:e]\n    \n    # --- Step 3: Ambiguity and Length Filters ---\n    retained_len = len(s_trimmed)\n    \n    if retained_len < L_min:\n        return [0, 0.0, 0.0, False]\n        \n    n_count = s_trimmed.count('N')\n    if retained_len > 0:\n      f_N = n_count / retained_len\n      if f_N > f_N_max:\n          return [0, 0.0, 0.0, False]\n\n    # --- Step 4: Metric Calculation ---\n    ell = retained_len\n    if ell == 0: # Should be caught by s>=e, but as a safeguard\n        return [0, 0.0, 0.0, False]\n\n    q_bar = np.mean(q_trimmed_scores)\n    expected_errors = np.sum(10**(-q_trimmed_scores / 10.0))\n    passed = True\n    \n    return [ell, round(q_bar, 3), round(expected_errors, 3), passed]\n    \n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the pipeline, and print results.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (happy path with adapter trimming)\n        (\"ACGT\" * 15 + \"AGATCGGAAG\", \"I\" * 60 + \"!\" * 10, \"AGATCGGAAGAGC\", 5, 20, 30, 0.1, 8, 1),\n        # Test case 2 (high quality but excessive ambiguity)\n        (\"N\" * 15 + \"A\" * 35, \"I\" * 50, \"AGATCGGAAGAGC\", 5, 20, 30, 0.2, 8, 1),\n        # Test case 3 (insufficient length after trimming)\n        (\"ACGT\" * 10, \"!\" * 20 + \"I\" * 20, \"AGATCGGAAGAGC\", 5, 25, 30, 0.1, 8, 0),\n        # Test case 4 (adapter absent, mixed ends, moderate ambiguity)\n        (\"ACGT\" * 10 + \"NNNNN\" + \"TGCA\" * 5 + \"ACGTA\", \"!\" * 3 + \"I\" * 64 + \"!\" * 3, \"AGATCGGAAGAGC\", 4, 30, 50, 0.1, 8, 1),\n        # Test case 5 (boundary case with w=1 for base-wise thresholding)\n        (\"ACGTACGTACGT\", \"A5?@B?A=A>5?\", \"AGATCGGAAGAGC\", 1, 30, 5, 0.0, 6, 0)\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_read(*case)\n        results.append(result)\n\n    # Format the final output string as specified.\n    result_strings = []\n    for res in results:\n        l, q, E, p = res\n        if not p:\n            result_strings.append(\"[0,0.0,0.0,false]\")\n        else:\n            result_strings.append(f\"[{l},{q:.3f},{E:.3f},{str(p).lower()}]\")\n            \n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n\n```", "id": "4580665"}, {"introduction": "Effective read mapping often requires more than simple sequence matching; it involves making statistically sound decisions about which parts of a read contain a true biological signal. This practice asks you to develop a model-based trimming algorithm from first principles. You will use a log-likelihood ratio framework to determine the optimal read boundaries, providing a quantitative basis for distinguishing genomic sequence from adapter contamination or low-quality overhangs [@problem_id:4580721].", "problem": "You are tasked with implementing a principled algorithm that models how adapter contamination and end overhangs affect mapping of ribonucleic acid sequencing (RNA-seq) reads to a genome. The objective is to formalize trimming decisions at both ends of a read as model selection under a log-likelihood ratio framework and compute the quantitative benefit of optimal trimming compared to no trimming. The scenario is grounded in the Central Dogma of Molecular Biology and a standard error model for sequencing data.\n\nUse the following foundational base:\n- The Central Dogma of Molecular Biology states that deoxyribonucleic acid (DNA) encodes ribonucleic acid (RNA), which is sequenced to yield short reads that originate from messenger RNA (mRNA). A sequencing read ideally corresponds to a contiguous genomic segment (after splicing back to the reference genome in an exon-exon aware mapper), but in practice may contain non-genomic bases at its ends due to library preparation artifacts (adapters, primer-derived overhangs) and may contain substitution errors from the sequencer.\n- A standard independent base-calling error model yields a per-base error rate $\\epsilon$, with correct base calls occurring with probability $1-\\epsilon$ and erroneous calls distributed uniformly among the three incorrect nucleotides with probability $\\epsilon/3$ per incorrect nucleotide.\n- Under a null model of random background, assume uniform nucleotide composition, with background probability $b_x = 1/4$ for each base $x \\in \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$.\n\nProblem setup to be implemented:\n- Given a genome string $G$, an adapter string $A$, and read strings $R$, we consider trimming the read at both ends. Let the read be indexed from $0$ to $|R|-1$. A trim configuration consists of a prefix trim of $p$ bases and a suffix trim of $s$ bases, producing a retained subsequence $R' = R[p : |R|-s]$ with length $L = |R|-p-s$.\n- Retained length must satisfy $L \\ge L_{\\min}$, where $L_{\\min}$ is a fixed minimal retained length. Trimming incurs a penalty of $\\sigma$ per removed base, so the total trimming penalty is $\\sigma (p+s)$.\n- For any retained read $R'$ and genome position $i$, the correct-mapping hypothesis posits that $R'$ aligns to $G[i : i+L]$, generating each observed base according to the sequencing error model. The random-background hypothesis posits that observed bases are generated independently from the uniform background distribution.\n- The alignment objective is defined via a log-likelihood ratio: for a candidate alignment of $R'$ to $G[i : i+L]$, define the per-base log-likelihood ratio using the two hypotheses based on whether bases match or mismatch. The total alignment score is the sum of these per-base log-likelihood ratios over the retained length $L$. The mapping score for $R'$ is the maximum total alignment score over all valid positions $i$ with $0 \\le i \\le |G|-L$.\n- The trimming objective is to choose $p$ and $s$ (subject to $L \\ge L_{\\min}$) that maximize the mapping score for $R'$ minus the trimming penalty $\\sigma (p+s)$.\n\nYour program must:\n1. Derive from first principles the per-base log-likelihood ratio using the above error and background models, and then the total alignment score as a sum over the retained length $L$. You must then implement the search over genome positions and trimming configurations to find the optimal trimmed mapping score and compare it against the untrimmed best mapping score.\n2. For each test case, report the improvement defined as the optimal-trimmed best mapping score minus the untrimmed best mapping score. Positive improvement indicates that trimming increases the mapping score relative to no trimming.\n\nParameters and test suite (ensure you use exactly these values):\n- Error rate $\\epsilon = 0.01$.\n- Background probability $b_x = 1/4$ for each nucleotide $x$.\n- Trimming penalty $\\sigma = \\log(4)$ using the natural logarithm.\n- Minimum retained length $L_{\\min} = 5$.\n- Genome $G$:\n  \"TTTACGGTACGTTAGGACCATGACCGTACCTGACTGACCTGACGTTACCGTTAAGGCTAGCTAGCTAGGGTACCGTTA\".\n- Adapter $A$: \"AGATCGGAAGAGC\".\n- Test reads $R$:\n  - Case $1$ (adapter suffix and $5'$ overhang with one sequencing error within the insert):\n    Construct $R_1$ by concatenating \"GG\" (a $5'$ overhang), the substring $G[20:50]$ (zero-indexed, end exclusive), with a single internal base substitution at position $10$ within that substring (substitute any base with a different valid nucleotide), and then the adapter $A$ appended at the $3'$ end.\n  - Case $2$ (no adapter, clean insert):\n    $R_2 = G[30:60]$ (exact substring, no overhang and no internal mutation).\n  - Case $3$ (adapter-only):\n    $R_3 = A + A$ (adapter repeated twice, with no genomic insert).\n\nComputational requirements:\n- Implement the per-base log-likelihood ratio using the sequencing-error hypothesis versus the random-background hypothesis.\n- Compute, for each read, the best untrimmed mapping score and the best trimmed mapping score under the trimming search with the stated penalty and minimal retained length.\n- For each case, compute the improvement equal to the difference between the best trimmed mapping score and the best untrimmed mapping score.\n\nFinal output format:\n- Your program should produce a single line of output containing the improvements for the three test cases as a comma-separated list enclosed in square brackets, for example, \"[x1,x2,x3]\".\n- Each number must be rounded to $6$ decimal places.\n- The output must be produced with no other text.\n\nDesign for coverage:\n- The test suite covers a general case where trimming both ends yields a benefit (Case $1$), a case where trimming should not help (Case $2$), and an edge case where the read is only adapter and trimming is constrained by $L_{\\min}$ (Case $3$).\n- Quantifiable answers: each test case yields a single real number (float) equal to the improvement as defined above.", "solution": "The problem requires the development and implementation of an algorithm for optimally trimming RNA-seq reads to improve their mapping score to a reference genome. This is framed as a model selection problem, where we compare a correct-mapping hypothesis against a random-background hypothesis using a log-likelihood ratio score.\n\nFirst, we derive the per-base log-likelihood ratio (LLR) score. Let $R'$ be a retained read segment of length $L$, and $G'$ be a genomic segment of the same length to which $R'$ is being aligned. For each position $j$ in the read ($0 \\le j  L$), let $r_j = R'[j]$ be the observed read base and $g_j = G'[j]$ be the corresponding genome base.\n\nWe consider two competing hypotheses for the origin of the observed base $r_j$:\n\\begin{itemize}\n    \\item $H_1$: The correct-mapping hypothesis. The read base $r_j$ is generated from the genomic base $g_j$ subject to sequencing errors.\n    \\item $H_0$: The random-background hypothesis. The read base $r_j$ is generated from a random background distribution.\n\\end{itemize}\n\nAccording to the problem's sequencing error model, the probability of a correct base call is $1-\\epsilon$, and the probability of any specific substitution is $\\epsilon/3$. The probability of observing $r_j$ given the genomic base $g_j$ under $H_1$ is:\n$$ P(r_j | g_j, H_1) = \\begin{cases} 1-\\epsilon  \\text{if } r_j = g_j \\text{ (match)} \\\\ \\epsilon/3  \\text{if } r_j \\neq g_j \\text{ (mismatch)} \\end{cases} $$\n\nUnder the random-background hypothesis $H_0$, each nucleotide is assumed to occur with a uniform probability $b_x = 1/4$. Thus, the probability of observing any base $r_j$ is:\n$$ P(r_j | H_0) = 1/4 $$\n\nThe per-base log-likelihood ratio, $\\text{LLR}(r_j, g_j)$, is the natural logarithm of the ratio of these probabilities:\n$$ \\text{LLR}(r_j, g_j) = \\log\\left(\\frac{P(r_j | g_j, H_1)}{P(r_j | H_0)}\\right) $$\n\nWe can now define the score for a match and a mismatch:\nFor a match ($r_j = g_j$):\n$$ \\text{score}_{\\text{match}} = \\log\\left(\\frac{1-\\epsilon}{1/4}\\right) = \\log(4(1-\\epsilon)) $$\nFor a mismatch ($r_j \\neq g_j$):\n$$ \\text{score}_{\\text{mismatch}} = \\log\\left(\\frac{\\epsilon/3}{1/4}\\right) = \\log\\left(\\frac{4\\epsilon}{3}\\right) $$\n\nUsing the given parameter $\\epsilon = 0.01$:\n$$ \\text{score}_{\\text{match}} = \\log(4(1-0.01)) = \\log(3.96) \\approx 1.376227 $$\n$$ \\text{score}_{\\text{mismatch}} = \\log\\left(\\frac{4 \\times 0.01}{3}\\right) = \\log\\left(\\frac{0.04}{3}\\right) \\approx -4.317488 $$\n\nThe total alignment score, $S(R', G')$, for a read segment $R'$ aligned to a genomic segment $G'$ is the sum of the per-base LLRs over the length $L$:\n$$ S(R', G') = N_{\\text{match}} \\cdot \\text{score}_{\\text{match}} + N_{\\text{mismatch}} \\cdot \\text{score}_{\\text{mismatch}} $$\nwhere $N_{\\text{match}}$ and $N_{\\text{mismatch}}$ are the number of matches and mismatches in the alignment, respectively.\n\nThe mapping score for a given read segment $R'$, denoted $\\text{MapScore}(R', G)$, is the maximum alignment score over all possible starting positions $i$ in the genome $G$, where $0 \\le i \\le |G| - L$:\n$$ \\text{MapScore}(R', G) = \\max_{0 \\le i \\le |G|-L} S(R', G[i:i+L]) $$\n\nThe final objective is to find the optimal prefix trim $p$ and suffix trim $s$ that maximize the mapping score minus a penalty for trimming. The trimmed read is $R'[p,s] = R[p:|R|-s]$, and its length is $L = |R|-p-s$. The trimming is subject to the constraint $L \\ge L_{\\min}$. The objective function to maximize is:\n$$ \\text{Obj}(p, s) = \\text{MapScore}(R'[p,s], G) - \\sigma(p+s) $$\nwhere $\\sigma = \\log(4)$ is the per-base trimming penalty.\n\nThe algorithm proceeds as follows for each read $R$:\n1.  Calculate the untrimmed mapping score. This corresponds to the case $p=0, s=0$. The objective value is simply $\\text{MapScore}(R, G)$.\n2.  Perform a search over all valid trimming configurations $(p, s)$. The valid range for $p$ is from $0$ to $|R|-L_{\\min}$. For each $p$, the valid range for $s$ is from $0$ to $|R|-p-L_{\\min}$. This ensures the retained length $|R|-p-s \\ge L_{\\min}$.\n3.  For each pair $(p,s)$, form the retained read $R' = R[p:|R|-s]$. Calculate its mapping score $\\text{MapScore}(R', G)$ by finding the best alignment against the genome. Then, compute the objective function value $\\text{Obj}(p,s)$.\n4.  The optimal-trimmed best mapping score is the maximum objective value found across all $(p,s)$ pairs:\n    $$ S_{\\text{trimmed\\_optimal}} = \\max_{p,s} \\text{Obj}(p,s) $$\n5.  The improvement is the difference between this optimal score and the untrimmed score:\n    $$ \\text{Improvement} = S_{\\text{trimmed\\_optimal}} - \\text{MapScore}(R, G) $$\n\nThis procedure is applied to each of the three test cases specified in the problem statement. The core of the implementation involves a nested loop structure: the outer loops iterate through trim parameters $(p,s)$, and the inner loop iterates through genome positions $i$ to compute the mapping score for the trimmed read.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the improvement in mapping score from optimal trimming for three RNA-seq read test cases.\n    \"\"\"\n    # Define parameters from the problem statement.\n    EPSILON = 0.01\n    SIGMA = np.log(4)\n    L_MIN = 5\n    GENOME = \"TTTACGGTACGTTAGGACCATGACCGTACCTGACTGACCTGACGTTACCGTTAAGGCTAGCTAGCTAGGGTACCGTTA\"\n    ADAPTER = \"AGATCGGAAGAGC\"\n\n    # Pre-calculate log-likelihood ratio scores based on the derived formulas.\n    SCORE_MATCH = np.log(4 * (1 - EPSILON))\n    SCORE_MISMATCH = np.log(4 * EPSILON / 3)\n\n    # Construct the test case reads.\n    # Case 1: 5' overhang, genomic insert with one error, 3' adapter.\n    g_sub = GENOME[20:50]\n    # Substitute base at index 10 of the substring (G[30]) from 'C' to 'A'\n    g_sub_mutated = g_sub[:10] + 'A' + g_sub[11:]\n    r1 = \"GG\" + g_sub_mutated + ADAPTER\n\n    # Case 2: Clean genomic insert.\n    r2 = GENOME[30:60]\n\n    # Case 3: Adapter dimer.\n    r3 = ADAPTER + ADAPTER\n    \n    test_cases = [r1, r2, r3]\n    \n    results = []\n\n    def get_mapping_score(read_segment, genome, score_match, score_mismatch):\n        \"\"\"\n        Calculates the maximum alignment score of a read segment against a genome.\n        \"\"\"\n        read_len = len(read_segment)\n        genome_len = len(genome)\n\n        if read_len == 0:\n            return 0.0\n        if read_len  genome_len:\n            return -np.inf\n\n        max_score = -np.inf\n        \n        # Use numpy for efficient comparison, but converting to list/array each time.\n        read_arr = np.array(list(read_segment))\n\n        for i in range(genome_len - read_len + 1):\n            genome_segment = genome[i : i + read_len]\n            genome_arr = np.array(list(genome_segment))\n            \n            matches = np.sum(read_arr == genome_arr)\n            mismatches = read_len - matches\n            \n            score = matches * score_match + mismatches * score_mismatch\n            if score  max_score:\n                max_score = score\n        \n        return max_score\n\n    for read in test_cases:\n        read_len = len(read)\n        \n        # 1. Calculate the score for the untrimmed read.\n        untrimmed_score = get_mapping_score(read, GENOME, SCORE_MATCH, SCORE_MISMATCH)\n\n        # 2. Search for the optimal trimming configuration.\n        max_trimmed_objective = -np.inf\n\n        # Iterate over all possible prefix trims (p)\n        for p in range(read_len - L_MIN + 1):\n            # Iterate over all possible suffix trims (s)\n            for s in range(read_len - p - L_MIN + 1):\n                retained_len = read_len - p - s\n                \n                # This check is guaranteed by loop bounds but good for clarity\n                if retained_len  L_MIN:\n                    continue\n                \n                retained_read = read[p : read_len - s]\n                \n                # Calculate mapping score for the trimmed read\n                mapping_score = get_mapping_score(retained_read, GENOME, SCORE_MATCH, SCORE_MISMATCH)\n                \n                # Calculate the final objective score including the trimming penalty\n                objective_score = mapping_score - SIGMA * (p + s)\n                \n                if objective_score  max_trimmed_objective:\n                    max_trimmed_objective = objective_score\n\n        # 3. Compute the improvement\n        improvement = max_trimmed_objective - untrimmed_score\n        results.append(improvement)\n\n    # Format the output as specified.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4580721"}, {"introduction": "A significant challenge in read mapping arises when a read aligns equally well to multiple locations in the genome, a common occurrence due to repetitive sequences or gene families. This exercise guides you in developing a principled method to resolve such ambiguities. You will apply Bayes' theorem to combine evidence from alignment quality with prior biological information, such as gene expression levels, to probabilistically assign multi-mapping reads and improve quantification accuracy [@problem_id:4580744].", "problem": "You are given a scenario in Ribonucleic Acid sequencing (RNA-seq) read mapping where multiple candidate alignments for a single read achieve the same maximum alignment score to a Deoxyribonucleic Acid (DNA) reference. The task is to resolve the ambiguity among these equal-score candidates using a principled probabilistic rule derived from first principles, rather than arbitrary tie-breakers. The fundamental base you must use consists of the following well-tested facts and definitions: (i) Bayes theorem for posterior probabilities, (ii) the commonly accepted RNA-seq sampling model that the probability of sampling a fragment from a transcript is proportional to expression times effective length, and (iii) an independent error model in which mismatches and insertion-deletion events (indels) occur with fixed probabilities at the per-event level.\n\nSpecifically, assume a read has $n$ candidate genomic loci or splice-junction alignments, indexed by $i \\in \\{1,\\dots,n\\}$. Each candidate alignment is characterized by counts $m_i$ (the number of mismatches) and $d_i$ (the number of indel events) in the alignment, and there exist strictly positive error probabilities $e$ for a mismatch event and $g$ for an indel event, with $0  e  1$ and $0  g  1$. For each locus $i$, you are given a nonnegative expression level $E_i$ and an effective length $L_i  0$. The equal-score condition means that all candidate alignments considered attain the same maximum value of an alignment scoring function; you should not use the score itself further, but only the provided error counts and the priors derived from expression and effective length.\n\nFrom these bases alone, derive an ambiguity resolution rule that computes, for each read, the posterior probability vector over candidates and outputs these posterior probabilities as fractional assignments that sum to $1$ across candidates. Your program should implement this rule exactly for each test case described below.\n\nYou must not invent any additional assumptions beyond what is stated. You must start from Bayes theorem and the sampling model proportional to expression times effective length, together with the independent error model, and derive an implementable computation that yields a normalized posterior over the candidate alignments.\n\nImplement the computation for the following test suite of parameter sets. In each test case, you are given the tuple $(e, g, \\mathbf{E}, \\mathbf{L}, \\mathbf{m}, \\mathbf{d})$, where $\\mathbf{E}$, $\\mathbf{L}$, $\\mathbf{m}$, and $\\mathbf{d}$ are arrays aligned by candidate index.\n\n- Test case $1$ (happy path; differing priors, identical error counts):\n  - $e = 0.01$, $g = 0.001$\n  - $\\mathbf{E} = [50, 25]$\n  - $\\mathbf{L} = [1500, 1500]$\n  - $\\mathbf{m} = [1, 1]$\n  - $\\mathbf{d} = [0, 0]$\n- Test case $2$ (equal priors; different error profiles across three candidates):\n  - $e = 0.02$, $g = 0.001$\n  - $\\mathbf{E} = [10, 10, 10]$\n  - $\\mathbf{L} = [1000, 1000, 1000]$\n  - $\\mathbf{m} = [2, 1, 1]$\n  - $\\mathbf{d} = [0, 0, 1]$\n- Test case $3$ (priors and errors exactly counterbalanced to yield equal posterior mass over two candidates):\n  - $e = 0.05$, $g = 0.001$\n  - $\\mathbf{E} = [50, 100]$\n  - $\\mathbf{L} = [100, 1000]$\n  - $\\mathbf{m} = [0, 1]$\n  - $\\mathbf{d} = [0, 0]$\n- Test case $4$ (boundary case with a zero prior for one candidate):\n  - $e = 0.01$, $g = 0.001$\n  - $\\mathbf{E} = [0, 20]$\n  - $\\mathbf{L} = [1000, 1000]$\n  - $\\mathbf{m} = [0, 0]$\n  - $\\mathbf{d} = [0, 0]$\n- Test case $5$ (four-way ambiguity with both mismatch and indel events present):\n  - $e = 0.02$, $g = 0.02$\n  - $\\mathbf{E} = [100, 98, 102, 100]$\n  - $\\mathbf{L} = [100, 100, 100, 100]$\n  - $\\mathbf{m} = [1, 1, 1, 0]$\n  - $\\mathbf{d} = [0, 1, 0, 0]$\n\nYour program must, for each test case, compute the normalized posterior probability vector over candidates in the given order, rounded to $6$ decimal places. The rounding should be applied to each component of the posterior vector independently. Your program should produce a single line of output containing the results for all test cases as a comma-separated list of the rounded posterior vectors, enclosed in square brackets, with no spaces. For example, the format must look like \"[[a11,a12,...],[a21,a22,...],...]\" where each $a_{ij}$ is a decimal number rounded to $6$ places.\n\nNo physical units or angles are involved in this task. All numeric outputs must be decimals as specified; do not use the percentage sign anywhere in the output. Ensure scientific realism by strictly adhering to the base facts and assumptions above, and do not add any untested heuristics or arbitrary tie-breaking rules.", "solution": "The objective is to compute the posterior probability distribution over a set of $n$ candidate alignments for a single RNA-sequencing read, given that all candidates share the same maximum alignment score. Let $R$ denote the event of observing the read, and let $C_i$ for $i \\in \\{1, \\dots, n\\}$ be the event that the read originated from the $i$-th candidate locus. The problem is to calculate the posterior probability $P(C_i | R)$ for each candidate $i$.\n\nThe solution is derived from first principles, beginning with Bayes' theorem, which provides the formal relationship between the desired posterior probability, the prior probability of each candidate, and the likelihood of observing the read given each candidate:\n$$\nP(C_i | R) = \\frac{P(R | C_i) P(C_i)}{\\sum_{j=1}^{n} P(R | C_j) P(C_j)}\n$$\nThe denominator is a normalization constant, ensuring that the posterior probabilities sum to $1$. To solve the problem, we must define the expressions for the prior, $P(C_i)$, and the likelihood, $P(R | C_i)$, based on the provided information.\n\nThe prior probability, $P(C_i)$, represents the probability of a read originating from locus $i$ before considering the alignment evidence from the read itself. The problem states that the probability of sampling a fragment from a transcript is proportional to its expression level $E_i$ and its effective length $L_i$. This directly translates into a model for the prior probability:\n$$\nP(C_i) \\propto E_i L_i\n$$\nWe can define an unnormalized prior weight for each candidate $i$ as $\\pi_i = E_i L_i$. Since any constant of proportionality will be the same for all candidates, it will cancel out during the final normalization step. Therefore, we can proceed using these unnormalized prior weights.\n\nThe likelihood, $P(R | C_i)$, is the probability of observing the specific read sequence $R$ given that it originated from locus $i$. The problem specifies an independent error model where mismatches and indels are independent events occurring with fixed probabilities $e$ and $g$ per event, respectively. The alignment for candidate $i$ is characterized by $m_i$ mismatches and $d_i$ indel events. The most direct interpretation of the \"per-event\" model is that the likelihood of a read arising from a template is proportional to the joint probability of the observed error events. Under the assumption of independence, this is the product of the individual event probabilities.\n$$\nP(R | C_i) \\propto e^{m_i} g^{d_i}\n$$\nThis likelihood model focuses on the occurrences of errors. Other factors, such as the probability of matches, are implicitly assumed to be constant across all high-scoring alignments or absorbed into a normalization constant that cancels out. The problem framing, which sets aside the alignment score itself, supports this focused error-based likelihood.\n\nCombining the prior and the likelihood, we can compute an unnormalized posterior weight, $W_i$, for each candidate $i$. This weight is proportional to the true posterior probability $P(C_i|R)$.\n$$\nW_i \\propto P(R | C_i) P(C_i)\n$$\nSubstituting our derived expressions, we get:\n$$\nW_i = (E_i L_i) \\cdot (e^{m_i} g^{d_i})\n$$\nHere, we have used equality by defining $W_i$ as the product of the unnormalized prior and the proportional likelihood term.\n\nFinally, to obtain the posterior probability vector, we normalize these weights so that they sum to $1$. The posterior probability for candidate $i$ is its weight divided by the sum of all weights:\n$$\nP(C_i | R) = \\frac{W_i}{\\sum_{j=1}^{n} W_j} = \\frac{E_i L_i e^{m_i} g^{d_i}}{\\sum_{j=1}^{n} E_j L_j e^{m_j} g^{d_j}}\n$$\nThis formula provides a complete, principled rule for resolving ambiguity.\n\nThe algorithm to implement this rule is as follows:\nFor each test case, specified by the parameters $(e, g, \\mathbf{E}, \\mathbf{L}, \\mathbf{m}, \\mathbf{d})$:\n1. For each candidate $i$ from $1$ to $n$, compute the unnormalized posterior weight $W_i = E_i L_i e^{m_i} g^{d_i}$.\n2. Compute the total weight $W_{\\text{total}} = \\sum_{j=1}^{n} W_j$.\n3. If $W_{\\text{total}}$ is $0$ (which occurs if all prior expression levels $E_j$ are $0$), the posterior is undefined. A reasonable convention is to assign a uniform probability, $1/n$, to each candidate.\n4. If $W_{\\text{total}} > 0$, compute the posterior probability for each candidate as $P(C_i|R) = W_i / W_{\\text{total}}$.\n5. Round each component of the resulting posterior probability vector to $6$ decimal places.\n\nThis procedure strictly adheres to the principles and data provided in the problem statement.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the RNA-seq read mapping ambiguity problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {'e': 0.01, 'g': 0.001, 'E': np.array([50, 25]), 'L': np.array([1500, 1500]), 'm': np.array([1, 1]), 'd': np.array([0, 0])},\n        # Test case 2\n        {'e': 0.02, 'g': 0.001, 'E': np.array([10, 10, 10]), 'L': np.array([1000, 1000, 1000]), 'm': np.array([2, 1, 1]), 'd': np.array([0, 0, 1])},\n        # Test case 3\n        {'e': 0.05, 'g': 0.001, 'E': np.array([50, 100]), 'L': np.array([100, 1000]), 'm': np.array([0, 1]), 'd': np.array([0, 0])},\n        # Test case 4\n        {'e': 0.01, 'g': 0.001, 'E': np.array([0, 20]), 'L': np.array([1000, 1000]), 'm': np.array([0, 0]), 'd': np.array([0, 0])},\n        # Test case 5\n        {'e': 0.02, 'g': 0.02, 'E': np.array([100, 98, 102, 100]), 'L': np.array([100, 100, 100, 100]), 'm': np.array([1, 1, 1, 0]), 'd': np.array([0, 1, 0, 0])},\n    ]\n\n    results = []\n    for case in test_cases:\n        e, g, E, L, m, d = case['e'], case['g'], case['E'], case['L'], case['m'], case['d']\n\n        # Calculate unnormalized prior weights: proportional to Expression * Length\n        prior_weights = E * L\n\n        # Calculate likelihoods: proportional to e^m * g^d\n        likelihoods = (e ** m) * (g ** d)\n\n        # Calculate unnormalized posterior weights\n        unnormalized_posteriors = prior_weights * likelihoods\n\n        # Normalize to get posterior probabilities\n        total_weight = np.sum(unnormalized_posteriors)\n\n        if total_weight == 0:\n            # This case occurs if all prior probabilities are zero (e.g., all E_i are 0).\n            # The posterior is ill-defined. A uniform distribution is a reasonable default.\n            num_candidates = len(E)\n            if num_candidates  0:\n                posterior_probs = np.full(num_candidates, 1.0 / num_candidates)\n            else:\n                posterior_probs = np.array([])\n        else:\n            posterior_probs = unnormalized_posteriors / total_weight\n        \n        # Round each probability to 6 decimal places\n        rounded_probs = np.round(posterior_probs, 6).tolist()\n        results.append(rounded_probs)\n\n    # Format the final output string as specified\n    case_strs = []\n    for res_list in results:\n        num_strs = [str(num) for num in res_list]\n        case_str = f\"[{','.join(num_strs)}]\"\n        case_strs.append(case_str)\n    \n    final_output = f\"[{','.join(case_strs)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "4580744"}]}