{"hands_on_practices": [{"introduction": "At the heart of most k-mer based analyses lies the fundamental task of counting. However, since DNA is double-stranded, simply counting substrings is insufficient; we must account for the fact that a k-mer on one strand corresponds to its reverse complement on the other. This practice guides you through implementing a canonical k-mer counting algorithm, a cornerstone procedure that prevents double-counting by normalizing each k-mer and its reverse complement to a single representative form [@problem_id:4576288]. Mastering this is the first step toward building robust and accurate bioinformatic tools.", "problem": "You are given a set of Deoxyribonucleic Acid (DNA) reads over the alphabet $\\{A,C,G,T\\}$ and an integer $k$. From first principles based on Watson–Crick base pairing (adenine with thymine and cytosine with guanine), the reverse complement of a DNA sequence is obtained by reversing the sequence and complementing each base via the bijection $A \\leftrightarrow T$ and $C \\leftrightarrow G$. A $k$-mer is any contiguous substring of length $k$ within a read. Counting $k$-mers across a dataset of reads is foundational in high-throughput sequencing analytics. However, if both a $k$-mer and its reverse complement are counted as distinct entities, the contribution of non-palindromic loci is effectively double-counted compared to that of palindromic loci, creating a statistical bias. A canonicalization procedure is used to normalize these counts. Define a canonicalization function $c(s)$ that maps a $k$-mer $s$ to the lexicographically smallest sequence between $s$ and its reverse complement $rc(s)$, using the lexicographic order $ACGT$. A $k$-mer $p$ is called palindromic if $p = rc(p)$.\n\nStarting from these foundational definitions, design and implement an algorithm that:\n- extracts all valid $k$-mers (windows of size $k$) from each read, skipping any window containing a character outside $\\{A,C,G,T\\}$,\n- computes the reverse complement $rc(s)$ for each valid $k$-mer $s$,\n- maps each $k$-mer $s$ to its canonical representative $c(s) = \\min(s,rc(s))$ under the given lexicographic order,\n- counts canonical $k$-mer occurrences across the reads,\n- and verifies, via a quantifiable metric, that palindromic $k$-mers are not double-counted.\n\nFor each test case, your program must produce the following outputs:\n- $U$: the number of unique canonical $k$-mers,\n- $T$: the total number of canonical $k$-mer occurrences across all reads (the sum of counts),\n- $M$: the maximum count among canonical $k$-mers (define $M=0$ if no valid $k$-mers exist),\n- $B$: a boolean that is $\\text{True}$ if palindromic $k$-mers are not double-counted, and $\\text{False}$ otherwise. For test cases that specify a palindromic target $p$, let $B$ be $\\text{True}$ if and only if the canonical count of $p$ equals the raw number of windows exactly equal to $p$; for test cases without a specified palindromic target, let $B$ be $\\text{True}$ if there are no pairs of distinct canonical keys that are reverse complements of each other.\n\nUse only the DNA alphabet $\\{A,C,G,T\\}$ for counting; any window containing characters outside this set must be excluded. Treat input reads case-insensitively by converting to uppercase before processing. The reverse complement function must implement $A \\leftrightarrow T$ and $C \\leftrightarrow G$ exactly. The canonicalization must use the lexicographic order $ACGT$.\n\nTest Suite (each test case is a tuple of reads, $k$, and an optional palindromic target to check):\n1. Reads: [\"ACGTACGT\"], $k=4$, palindromic target \"ACGT\".\n2. Reads: [\"A\",\"ACG\"], $k=4$, no palindromic target.\n3. Reads: [\"ANNNT\",\"NTGC\"], $k=3$, no palindromic target.\n4. Reads: [\"ATTA\",\"TAAT\"], $k=2$, palindromic target \"AT\".\n\nScientific realism and coverage:\n- Case $1$ is a general case with a palindromic $k$-mer present and non-palindromic pairs across orientations.\n- Case $2$ is a boundary condition with reads shorter than $k$ producing no valid $k$-mers.\n- Case $3$ tests exclusion of windows containing invalid characters outside $\\{A,C,G,T\\}$.\n- Case $4$ includes multiple palindromic $k$-mers of even length and non-palindromic ones, testing canonical grouping and palindromic handling.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case result represented as a list $[U,T,M,B]$. For example, the output should look like: \"[[U1,T1,M1,B1],[U2,T2,M2,B2],[U3,T3,M3,B3],[U4,T4,M4,B4]]\". No physical units or angle units are involved. All counts must be integers; booleans must be printed in their native boolean representation.", "solution": "The problem requires an algorithm to process a set of DNA reads, count the canonical $k$-mers, and verify the integrity of the counting process. The solution is structured as follows:\n\n1.  **Initialization**: For each test case, a dictionary, `canonical_counts`, is initialized to store the frequency of each canonical $k$-mer. A complement mapping for base pairing is also defined.\n\n2.  **K-mer Extraction and Validation**: The algorithm iterates through each provided read, converting it to uppercase to ensure case-insensitivity. A sliding window of length $k$ moves across the read. Any window containing a character outside the valid DNA alphabet ($\\{A, C, G, T\\}$) is discarded.\n\n3.  **Canonicalization**: For each valid $k$-mer, $s$, its canonical representative is determined. This involves two sub-steps:\n    a.  **Reverse Complement**: A function, $rc(s)$, reverses the string $s$ and substitutes each base with its complement ($A \\leftrightarrow T$, $C \\leftrightarrow G$).\n    b.  **Lexicographical Comparison**: The canonical form, $c(s)$, is determined by the lexicographical minimum of the $k$-mer and its reverse complement: $c(s) = \\min(s, rc(s))$ based on the order $A  C  G  T$.\n\n4.  **Counting**: The computed canonical $k$-mer, $c(s)$, is used as a key in the `canonical_counts` dictionary. Its corresponding value (count) is incremented. This process ensures that a $k$-mer and its reverse complement are aggregated under a single canonical key.\n\n5.  **Output Calculation**: After processing all reads for a test case, the required metrics ($U, T, M, B$) are calculated from the `canonical_counts` dictionary:\n    -   $U$ (unique count), $T$ (total count), and $M$ (max count) are derived directly from the dictionary's keys and values.\n    -   $B$ (boolean verification) is calculated based on the test case. If a palindromic target $p$ is provided, the algorithm verifies that the final canonical count for $p$ matches the raw number of times the substring $p$ was observed in valid windows. This confirms that palindromes are handled correctly. If no target is given, the algorithm verifies the internal consistency of the canonicalization by checking that no two distinct keys in the final count dictionary are reverse complements of each other.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        {\"reads\": [\"ACGTACGT\"], \"k\": 4, \"palindromic_target\": \"ACGT\"},\n        {\"reads\": [\"A\", \"ACG\"], \"k\": 4, \"palindromic_target\": None},\n        {\"reads\": [\"ANNNT\", \"NTGC\"], \"k\": 3, \"palindromic_target\": None},\n        {\"reads\": [\"ATTA\", \"TAAT\"], \"k\": 2, \"palindromic_target\": \"AT\"},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = process_case(case[\"reads\"], case[\"k\"], case[\"palindromic_target\"])\n        all_results.append(result)\n\n    # Format the final output string to remove spaces for a compact representation\n    # e.g., '[3,5,2,True]' instead of '[3, 5, 2, True]'\n    formatted_strings = [str(res).replace(\" \", \"\") for res in all_results]\n    print(f\"[{','.join(formatted_strings)}]\")\n\ndef process_case(reads, k, palindromic_target):\n    \"\"\"\n    Processes a single test case according to the problem specification.\n    \"\"\"\n    complement_map = str.maketrans('ACGT', 'TGCA')\n    valid_bases = {'A', 'C', 'G', 'T'}\n\n    def reverse_complement(s):\n        return s.translate(complement_map)[::-1]\n\n    canonical_counts = {}\n    raw_target_count = 0\n\n    for read in reads:\n        read_upper = read.upper()\n        if len(read_upper)  k:\n            continue\n        for i in range(len(read_upper) - k + 1):\n            kmer = read_upper[i:i+k]\n            \n            # Skip any k-mer containing invalid characters\n            if not set(kmer).issubset(valid_bases):\n                continue\n\n            # For verification metric B with a target\n            if palindromic_target and kmer == palindromic_target:\n                raw_target_count += 1\n            \n            # Canonicalization\n            rc_kmer = reverse_complement(kmer)\n            canonical_kmer = min(kmer, rc_kmer)\n            \n            # Counting\n            canonical_counts[canonical_kmer] = canonical_counts.get(canonical_kmer, 0) + 1\n\n    # Calculate U, T, M\n    if not canonical_counts:\n        U, T, M = 0, 0, 0\n    else:\n        U = len(canonical_counts)\n        T = sum(canonical_counts.values())\n        M = max(canonical_counts.values())\n\n    # Calculate B\n    B = True\n    if palindromic_target:\n        # Check if the target is indeed palindromic.\n        is_palindrome = (palindromic_target == reverse_complement(palindromic_target))\n        if not is_palindrome:\n            # This case shouldn't happen with the given test data,\n            # but is a robust check. The canonical form would be different.\n            # The logic stands for any target p. We need its canonical form.\n            canonical_target = min(palindromic_target, reverse_complement(palindromic_target))\n            canonical_count_p = canonical_counts.get(canonical_target, 0)\n        else:\n             # For a palindrome, its canonical form is itself.\n            canonical_count_p = canonical_counts.get(palindromic_target, 0)\n        \n        B = (canonical_count_p == raw_target_count)\n\n    else:\n        # Verify that no two distinct canonical keys are reverse complements.\n        # This confirms the correctness of the canonicalization logic.\n        keys = list(canonical_counts.keys())\n        key_set = set(keys)\n        for key in keys:\n            rc_key = reverse_complement(key)\n            if key != rc_key and rc_key in key_set:\n                B = False\n                break\n    \n    return [U, T, M, B]\n\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "4576288"}, {"introduction": "While idealized DNA sequences provide a clean starting point, real-world sequencing data is fraught with noise, including ambiguous base calls (denoted 'N') and varying levels of base quality. This exercise moves from theory to practice by having you implement a rigorous, multi-stage filtering protocol for k-mer extraction based on Phred quality scores and other statistical criteria [@problem_id:4576335]. By applying rules based on the error probability model $p_{\\mathrm{err}} = 10^{-Q/10}$, you will learn how to make principled decisions about which k-mers are reliable enough for downstream analysis, a critical skill for any work involving raw sequencing reads.", "problem": "You are given a formalization of sliding-window $k$-mer validation over a single-read sequence that follows the structure of a FASTQ record. The record consists of a nucleotide sequence string and a corresponding integer-valued quality score vector in Phred scale. A Phred quality score $Q$ is related to the probability of an incorrect base call $p_{\\mathrm{err}}$ by the widely accepted relation $p_{\\mathrm{err}} = 10^{-Q/10}$. In sequencing data, the character $N$ denotes an ambiguous nucleotide. The task is to formalize and implement a principled rule-set that excludes or transforms ambiguous positions to form valid $k$-mers, and then to quantify the proportion of discarded windows under that rule-set.\n\nStarting from core definitions:\n- A $k$-mer is a contiguous substring of length $k$ from the read sequence.\n- Define a sliding window index $i$ that ranges from $0$ to $L-k$, where $L$ is the read length. The window at index $i$ spans positions $i, i+1, \\ldots, i+k-1$.\n- Let the read sequence be $S = (S_0, S_1, \\ldots, S_{L-1})$ with $S_i \\in \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}, \\mathrm{N}\\}$ and the corresponding Phred quality scores be $Q = (Q_0, Q_1, \\ldots, Q_{L-1})$ with $Q_i \\in \\mathbb{Z}$.\n- Let $\\pi = (\\pi_{\\mathrm{A}}, \\pi_{\\mathrm{C}}, \\pi_{\\mathrm{G}}, \\pi_{\\mathrm{T}})$ be a base-composition prior over $\\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$, with $\\sum_b \\pi_b = 1$ and $\\pi_b \\ge 0$ for each base $b$.\n- Let $\\rho$ be an imputation certainty threshold with $0 \\le \\rho \\le 1$.\n- Let $Q_{\\min}$ be the minimum acceptable per-position Phred quality score, and let $\\tau$ be an upper bound on the expected number of errors per window.\n\nRule-set for window validity:\n1. Ambiguity resolution: For each position $i$ with $S_i = \\mathrm{N}$, if $\\max_{b \\in \\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}} \\pi_b \\ge \\rho$, then deterministically impute $S_i \\leftarrow b^\\*$ where $b^\\* = \\arg\\max_b \\pi_b$. Otherwise leave $S_i = \\mathrm{N}$ (unresolved).\n2. Quality filter: A window $(i,\\ldots,i+k-1)$ is immediately invalid if $\\min_{j \\in [i,i+k-1]} Q_j  Q_{\\min}$.\n3. Post-imputation ambiguity filter: A window $(i,\\ldots,i+k-1)$ is invalid if any $S_j = \\mathrm{N}$ remains within the window after the ambiguity resolution step.\n4. Expected error bound: For a window $(i,\\ldots,i+k-1)$, compute $E_i = \\sum_{j=i}^{i+k-1} 10^{-Q_j/10}$ using the Phred relation. The window is invalid if $E_i  \\tau$.\n5. A window is valid if and only if it passes all of the above filters.\n\nDefine the proportion of discarded windows as the fraction $\\frac{D}{W}$, where $W = L-k+1$ is the total number of windows and $D$ is the number of invalid windows under the rule-set.\n\nImplement a program that:\n- Applies the above rule-set to each specified test case.\n- Computes and reports the proportion $\\frac{D}{W}$ for each test case as a float rounded to six decimal places.\n\nTest suite:\n- Test case $1$ (happy path with unresolved ambiguities and low-quality bases):\n  - $k = 7$, $Q_{\\min} = 20$, $\\tau = 0.7$, $\\rho = 0.3$, $\\pi = (0.25, 0.25, 0.25, 0.25)$.\n  - Sequence $S$ of length $L = 30$: $S = \\mathrm{ACNTACGTACNTACGNNCGTACGTANGTAA}$.\n  - Quality scores $Q_i$: $Q_i = 30$ for all $i$ except $Q_5 = 15$, $Q_6 = 15$, $Q_{21} = 10$.\n  - This read contains exactly $5$ ambiguous positions $\\mathrm{N}$.\n- Test case $2$ (imputation enabled, high confidence prior, all high quality):\n  - $k = 7$, $Q_{\\min} = 25$, $\\tau = 0.1$, $\\rho = 0.45$, $\\pi = (0.5, 0.2, 0.2, 0.1)$.\n  - Sequence $S$ of length $L = 30$: $S = \\mathrm{NGCATGCATNCANGCATGCANGCATGCATN}$.\n  - Quality scores $Q_i$: $Q_i = 35$ for all $i$.\n  - This read contains exactly $5$ ambiguous positions $\\mathrm{N}$.\n- Test case $3$ (boundary condition $k=1$):\n  - $k = 1$, $Q_{\\min} = 20$, $\\tau = 0.6$, $\\rho = 0.26$, $\\pi = (0.25, 0.25, 0.25, 0.25)$.\n  - Sequence $S$ of length $L = 10$: $S = \\mathrm{NNNNNAAAAA}$.\n  - Quality scores $Q_i$: $Q_i = 40$ for all $i$.\n  - This read contains exactly $5$ ambiguous positions $\\mathrm{N}$.\n- Test case $4$ (large windows, imputation enabled, but expected error bound and quality threshold cause discards):\n  - $k = 10$, $Q_{\\min} = 10$, $\\tau = 0.2$, $\\rho = 0.5$, $\\pi = (0.6, 0.2, 0.1, 0.1)$.\n  - Sequence $S$ of length $L = 12$: $S = \\mathrm{ANNTANGTNCGN}$.\n  - Quality scores $Q_i$: $Q_i = 5$ at indices $1, 2, 5, 8, 11$, and $Q_i = 30$ for all other indices.\n  - This read contains exactly $5$ ambiguous positions $\\mathrm{N}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each float rounded to six decimal places. For example, the output should look like $[\\mathrm{r}_1,\\mathrm{r}_2,\\mathrm{r}_3,\\mathrm{r}_4]$, where each $\\mathrm{r}_i$ is the proportion of discarded windows for the corresponding test case expressed as a decimal number.", "solution": "The problem requires the validation of sliding-window $k$-mers extracted from a sequencing read, which is defined by a nucleotide sequence $S$ and a corresponding vector of Phred quality scores $Q$. The validity of each window is determined by a precise, multi-stage rule-set. Our objective is to implement this rule-set and compute the proportion of discarded windows for several test cases.\n\nThe core of the solution lies in a systematic, window-by-window application of the specified filters. For a given read of length $L$ and a $k$-mer length $k$, there are $W = L-k+1$ possible sliding windows. We must evaluate each of these windows against the rule-set. The process can be broken down into two main phases: a one-time pre-processing step on the entire sequence, and a per-window validation loop.\n\n**1. Pre-Processing: Ambiguity Resolution**\n\nThe first rule addresses ambiguous bases, denoted by '$\\mathrm{N}$'.\n- Rule $1$: For each position $i$ where the sequence has $S_i = \\mathrm{N}$, we consult a base-composition prior $\\pi = (\\pi_{\\mathrm{A}}, \\pi_{\\mathrm{C}}, \\pi_{\\mathrm{G}}, \\pi_{\\mathrm{T}})$ and an imputation certainty threshold $\\rho$. If the probability of the most likely base, $\\max_{b} \\pi_b$, is greater than or equal to the threshold $\\rho$, we deterministically impute the ambiguous base to this most likely base: $S_i \\leftarrow b^\\*$ where $b^\\* = \\arg\\max_b \\pi_b$. If $\\max_{b} \\pi_b  \\rho$, the base remains unresolved ($S_i = \\mathrm{N}$). This step transforms the original sequence $S$ into a new sequence, let's call it $S'$.\n\n**2. Per-Window Validation**\n\nAfter pre-processing, we iterate through each window, indexed by its starting position $i$ from $0$ to $L-k$. A window is considered valid if and only if it satisfies all of the following conditions. If any condition is not met, the window is marked as invalid.\n\n- Rule $3$ (Post-imputation ambiguity filter): The window must not contain any unresolved '$\\mathrm{N}$' characters. That is, for the window sub-sequence $S'_{i..i+k-1}$, every character must be in $\\{\\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T}\\}$.\n- Rule $2$ (Quality filter): The Phred quality score of every base within the window must meet a minimum threshold $Q_{\\min}$. That is, $\\min_{j=i}^{i+k-1} Q_j \\ge Q_{\\min}$.\n- Rule $4$ (Expected error bound): The sum of error probabilities for all bases in the window must not exceed a specified tolerance $\\tau$. The error probability $p_{\\mathrm{err}}$ for a base with Phred score $Q_j$ is given by $p_{\\mathrm{err},j} = 10^{-Q_j/10}$. The condition is $\\sum_{j=i}^{i+k-1} 10^{-Q_j/10} \\le \\tau$.\n\nA window starting at index $i$ is counted as discarded if it fails one or more of these three filters. After evaluating all $W$ windows, we count the total number of discarded windows, $D$. The final result is the proportion $\\frac{D}{W}$.\n\nWe now apply this procedure to each test case.\n\n**Test Case 1**\n- Parameters: $k=7$, $Q_{\\min}=20$, $\\tau=0.7$, $\\rho=0.3$, $\\pi=(0.25, 0.25, 0.25, 0.25)$.\n- Sequence: $S = \\mathrm{ACNTACGTACNTACGNNCGTACGTANGTAA}$ ($L=30$).\n- Quality Scores: $Q_i = 30$ for all $i$ except $Q_5 = 15$, $Q_6 = 15$, $Q_{21} = 10$.\n- Total windows: $W = 30 - 7 + 1 = 24$.\n1.  Ambiguity Resolution: $\\max(\\pi) = 0.25$. Since $0.25  \\rho=0.3$, no imputation occurs. The sequence $S'$ is identical to $S$. The '$\\mathrm{N}$' bases remain at indices $2, 10, 14, 15, 25$.\n2.  Window Validation:\n    -   Ambiguity Filter (Rule 3): A window is invalid if it contains an '$\\mathrm{N}$'. Any window starting at $i$ such that its interval $[i, i+6]$ overlaps with $\\{2, 10, 14, 15, 25\\}$ is invalid. This invalidates windows with indices $i \\in \\{0,1,2\\} \\cup \\{4,...,10\\} \\cup \\{8,...,14\\} \\cup \\{9,...,15\\} \\cup \\{19,...,23\\}$. The union of these sets is $\\{0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23\\}$.\n    -   Quality Filter (Rule 2): Low-quality bases are at indices $5, 6, 21$. A window is invalid if its interval $[i, i+6]$ overlaps with these indices. This invalidates windows with indices $i \\in \\{0,...,5\\} \\cup \\{0,...,6\\} \\cup \\{15,...,21\\}$. The union is $\\{0, 1, 2, 3, 4, 5, 6\\} \\cup \\{15, 16, 17, 18, 19, 20, 21\\}$.\n    -   Combined Invalidity: The set of all discarded windows is the union of the sets from both filters. This union is $\\{0, 1, ..., 23\\}$, which covers all possible window indices.\n-   Conclusion: All $24$ windows are invalid. $D=24$. The proportion of discarded windows is $24/24 = 1.0$.\n\n**Test Case 2**\n- Parameters: $k=7$, $Q_{\\min}=25$, $\\tau=0.1$, $\\rho=0.45$, $\\pi=(0.5, 0.2, 0.2, 0.1)$.\n- Sequence: $S = \\mathrm{NGCATGCATNCANGCATGCANGCATGCATN}$ ($L=30$).\n- Quality Scores: $Q_i = 35$ for all $i$.\n- Total windows: $W = 30 - 7 + 1 = 24$.\n1.  Ambiguity Resolution: $\\max(\\pi) = 0.5$. Since $0.5 \\ge \\rho=0.45$, imputation is performed. The base with the maximum prior is '$\\mathrm{A}$'. All '$\\mathrm{N}$'s are replaced with '$\\mathrm{A}$'.\n2.  Window Validation:\n    -   Ambiguity Filter (Rule 3): After imputation, no '$\\mathrm{N}$'s remain. This filter is passed by all windows.\n    -   Quality Filter (Rule 2): All quality scores are $35$, which is $\\ge Q_{\\min}=25$. This filter is passed by all windows.\n    -   Expected Error Filter (Rule 4): The error probability for any base is $10^{-35/10} = 10^{-3.5}$. The expected error per window is $E_i = 7 \\times 10^{-3.5} \\approx 0.0022$. Since $0.0022 \\le \\tau=0.1$, this filter is passed by all windows.\n-   Conclusion: All $24$ windows are valid. $D=0$. The proportion of discarded windows is $0/24 = 0.0$.\n\n**Test Case 3**\n- Parameters: $k=1$, $Q_{\\min}=20$, $\\tau=0.6$, $\\rho=0.26$, $\\pi=(0.25, 0.25, 0.25, 0.25)$.\n- Sequence: $S = \\mathrm{NNNNNAAAAA}$ ($L=10$).\n- Quality Scores: $Q_i = 40$ for all $i$.\n- Total windows: $W = 10 - 1 + 1 = 10$.\n1.  Ambiguity Resolution: $\\max(\\pi) = 0.25$. Since $0.25  \\rho=0.26$, no imputation occurs.\n2.  Window Validation: Each window is a single base.\n    -   Ambiguity Filter (Rule 3): Windows at indices $0, 1, 2, 3, 4$ contain '$\\mathrm{N}$' and are invalid. Windows at $5, 6, 7, 8, 9$ are valid under this rule.\n    -   Quality Filter (Rule 2): All scores are $40 \\ge Q_{\\min}=20$. All windows pass.\n    -   Expected Error Filter (Rule 4): For each window, the expected error is $10^{-40/10} = 0.0001$. Since $0.0001 \\le \\tau=0.6$, all windows pass.\n-   Conclusion: The first $5$ windows are discarded due to ambiguity. $D=5$. The proportion is $5/10 = 0.5$.\n\n**Test Case 4**\n- Parameters: $k=10$, $Q_{\\min}=10$, $\\tau=0.2$, $\\rho=0.5$, $\\pi=(0.6, 0.2, 0.1, 0.1)$.\n- Sequence: $S = \\mathrm{ANNTANGTNCGN}$ ($L=12$).\n- Quality Scores: $Q_i=5$ at indices $1, 2, 5, 8, 11$; $Q_i = 30$ otherwise.\n- Total windows: $W = 12 - 10 + 1 = 3$. Windows start at $i=0, 1, 2$.\n1.  Ambiguity Resolution: $\\max(\\pi)=0.6$. Since $0.6 \\ge \\rho=0.5$, imputation occurs, replacing all '$\\mathrm{N}$'s with '$\\mathrm{A}$'.\n2.  Window Validation:\n    -   Ambiguity Filter (Rule 3): After imputation, no '$\\mathrm{N}$'s remain. All windows pass this filter.\n    -   Quality Filter (Rule 2): $Q_{\\min}=10$.\n        -   Window $0$ (indices $[0, 9]$) contains bases with $Q=5$ at indices $1, 2, 5, 8$. Since $5  10$, this window is invalid.\n        -   Window $1$ (indices $[1, 10]$) contains bases with $Q=5$ at indices $1, 2, 5, 8$. Since $5  10$, this window is invalid.\n        -   Window $2$ (indices $[2, 11]$) contains bases with $Q=5$ at indices $2, 5, 8, 11$. Since $5  10$, this window is invalid.\n-   Conclusion: All $3$ windows are invalid due to the quality filter. We do not need to check the expected error filter. $D=3$. The proportion is $3/3 = 1.0$.\n\nFinal proportions: $[1.0, 0.0, 0.5, 1.0]$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for k-mer window validation.\n    \"\"\"\n\n    def calculate_discard_proportion(k, Q_min, tau, rho, pi, S, Q):\n        \"\"\"\n        Calculates the proportion of discarded windows for a single test case.\n        \"\"\"\n        L = len(S)\n        if L  k:\n            return 1.0  # Or 0.0 if no windows exist, but problem implies L >= k\n\n        W = L - k + 1\n        S_list = list(S)\n        \n        # Rule 1: Ambiguity resolution\n        pi_max = np.max(pi)\n        if pi_max >= rho:\n            bases = ['A', 'C', 'G', 'T']\n            b_star_index = np.argmax(pi)\n            b_star = bases[b_star_index]\n            for i in range(L):\n                if S_list[i] == 'N':\n                    S_list[i] = b_star\n        \n        S_prime = \"\".join(S_list)\n\n        num_valid_windows = 0\n        p_err = 10**(-np.array(Q, dtype=float) / 10.0)\n\n        for i in range(W):\n            window_S = S_prime[i : i + k]\n            window_Q = Q[i : i + k]\n            window_p_err = p_err[i : i + k]\n            \n            # Rule 3: Post-imputation ambiguity filter\n            passes_ambiguity = 'N' not in window_S\n            \n            # Rule 2: Quality filter\n            passes_quality = np.min(window_Q) >= Q_min\n            \n            # Rule 4: Expected error bound\n            passes_error = np.sum(window_p_err) = tau\n\n            if passes_ambiguity and passes_quality and passes_error:\n                num_valid_windows += 1\n        \n        num_discarded = W - num_valid_windows\n        return num_discarded / W\n\n    # Test Case 1\n    Q1 = np.full(30, 30)\n    Q1[[5, 6, 21]] = [15, 15, 10]\n    case1 = {\n        \"k\": 7, \"Q_min\": 20, \"tau\": 0.7, \"rho\": 0.3, \"pi\": (0.25, 0.25, 0.25, 0.25),\n        \"S\": \"ACNTACGTACNTACGNNCGTACGTANGTAA\", \"Q\": Q1\n    }\n\n    # Test Case 2\n    Q2 = np.full(30, 35)\n    case2 = {\n        \"k\": 7, \"Q_min\": 25, \"tau\": 0.1, \"rho\": 0.45, \"pi\": (0.5, 0.2, 0.2, 0.1),\n        \"S\": \"NGCATGCATNCANGCATGCANGCATGCATN\", \"Q\": Q2\n    }\n\n    # Test Case 3\n    Q3 = np.full(10, 40)\n    case3 = {\n        \"k\": 1, \"Q_min\": 20, \"tau\": 0.6, \"rho\": 0.26, \"pi\": (0.25, 0.25, 0.25, 0.25),\n        \"S\": \"NNNNNAAAAA\", \"Q\": Q3\n    }\n    \n    # Test Case 4\n    Q4 = np.full(12, 30)\n    Q4[[1, 2, 5, 8, 11]] = 5\n    case4 = {\n        \"k\": 10, \"Q_min\": 10, \"tau\": 0.2, \"rho\": 0.5, \"pi\": (0.6, 0.2, 0.1, 0.1),\n        \"S\": \"ANNTANGTNCGN\", \"Q\": Q4\n    }\n\n    test_cases = [case1, case2, case3, case4]\n    \n    results = []\n    for case in test_cases:\n        result = calculate_discard_proportion(**case)\n        results.append(f\"{result:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "4576335"}, {"introduction": "As genomic datasets grow exponentially, the ability to rapidly search for specific sequences becomes paramount. This practice challenges you to design and implement a scalable k-mer query system with sublinear time complexity, a significant leap from simple batch counting [@problem_id:4576326]. You will explore the power of an inverted index built upon a hash table, coupled with efficient 2-bit encoding of nucleotides, to create a system that can instantaneously report which genomes in a large collection contain a query k-mer. This exercise bridges the gap between basic sequence manipulation and the high-performance computational techniques required for modern large-scale genomics.", "problem": "You are given a finite set of Deoxyribonucleic Acid (DNA) genomes, each represented as a string over the alphabet $\\{ \\text{A}, \\text{C}, \\text{G}, \\text{T}, \\text{N} \\}$, where $\\text{N}$ denotes an ambiguous nucleotide. A $k$-mer is any contiguous substring of length $k$ over $\\{ \\text{A}, \\text{C}, \\text{G}, \\text{T} \\}$. The reverse complement (RC) of a DNA string is obtained by reversing the string and replacing each nucleotide by its complement, where $\\text{A}$ complements $\\text{T}$ and $\\text{C}$ complements $\\text{G}$. Your task is to design and implement a query algorithm and data structure that, for a given $k$ and a query $k$-mer $q$ (possibly with reverse complement equivalence), returns the list of genome identifiers containing at least one occurrence of $q$ in either orientation (forward or reverse complement). The query time must be sublinear in $n$, where $n$ is the total number of nucleotides across all genomes. You must justify the data structure choice from first principles.\n\nStart from fundamental definitions and well-tested observations, not from any shortcut formulas, and use the following base:\n- A $k$-mer is a length-$k$ contiguous substring over $\\{ \\text{A}, \\text{C}, \\text{G}, \\text{T} \\}$.\n- Reverse complement invariance captures matches on either DNA strand.\n- Hash tables (under uniform hashing assumptions) provide expected constant-time lookup.\n- Two-bit encoding maps $\\{ \\text{A}, \\text{C}, \\text{G}, \\text{T} \\}$ to integers, enabling compact keys for $k$-mers.\n\nRequirements for the algorithm:\n- Preprocess the genomes to build an index on $k$-mers using only $\\{ \\text{A}, \\text{C}, \\text{G}, \\text{T} \\}$ (skip any window containing $\\text{N}$). Treat forward and reverse complement $k$-mers as equivalent by canonicalizing each observed $k$-mer to the minimum of its integer-encoded value and the integer-encoded value of its reverse complement.\n- Return, for a given query $k$-mer $q$, the sorted list of genome identifiers that contain $q$ (considering reverse complement equivalence).\n- If $q$ contains any character outside $\\{ \\text{A}, \\text{C}, \\text{G}, \\text{T} \\}$ or has length not equal to $k$, return the empty list.\n\nYou must provide a correct program that constructs the index and answers a fixed test suite without reading input, files, or using network access. Your justification and design should demonstrate that the query time is sublinear in $n$ (for example, expected constant time under uniform hashing), and reason explicitly about the time to compute the canonical form of $q$ and the impact of the number of genomes that actually contain $q$.\n\nUse the following genomes (each assigned an identifier equal to its position in the list starting at $0$):\n- $0$: $\\text{ACGTACGTACGT}$\n- $1$: $\\text{GTACGTAAGACT}$\n- $2$: $\\text{TTTTACGTGGGG}$\n- $3$: $\\text{CCCCGACTAAAA}$\n- $4$: $\\text{ACGNNNACGTAC}$\n- $5$: $\\text{TGCATGCAAGTC}$\n\nImplement your algorithm and produce answers for the following test suite. Each test case is a pair $(k, q)$:\n- Test case $1$: $(k = 4, q = \\text{AGTC})$\n- Test case $2$: $(k = 4, q = \\text{ACGT})$\n- Test case $3$: $(k = 1, q = \\text{A})$\n- Test case $4$: $(k = 6, q = \\text{ACGTAC})$\n- Test case $5$: $(k = 5, q = \\text{AAAAA})$\n- Test case $6$: $(k = 4, q = \\text{ACGN})$\n\nExpress each test case’s answer as a list of integers (genome identifiers). The final output must aggregate all test case results into a single line as a comma-separated list enclosed in square brackets, where each element is the list for that test case. For example, the output format must be exactly of the form $[\\,[\\ldots],\\,[\\ldots],\\ldots\\,]$ with no spaces.\n\nNo physical units, angle units, or percentages are involved in this problem. Your program should be self-contained and produce the single line of output with the aggregated results. Ensure scientific realism by treating only exact matches over $\\{ \\text{A}, \\text{C}, \\text{G}, \\text{T} \\}$ and ignoring windows containing $\\text{N}$ when building the index.", "solution": "The problem requires the design and implementation of a data structure and algorithm to efficiently query a set of genomes for the presence of a given $k$-mer or its reverse complement. The primary constraint is that the query time must be sublinear in $n$, the total number of nucleotides across all genomes.\n\nOur approach is founded on the principle of trading preprocessing time for fast query time. A naive search for a query $k$-mer $q$ would involve scanning each genome, resulting in a time complexity of $O(n)$ per query, which is unacceptable. To achieve sublinear query performance, we must build an index.\n\n**1. Core Strategy: An Inverted Index using a Hash Table**\n\nThe most suitable data structure for this task is a hash table (in Python, a `dict`), which we will use to build an inverted index. An inverted index maps content (in this case, $k$-mers) to its locations (in this case, the identifiers of the genomes containing it).\n\nThe fundamental advantage of a hash table is its average time complexity for lookups, insertions, and deletions, which is $O(1)$ under the reasonable assumption of a uniform hashing function. By mapping each unique $k$-mer to a list of genome identifiers, a query for a $k$-mer reduces to a single hash table lookup. This operation's time is independent of the total genome size $n$, thus satisfying the sublinear query time requirement.\n\n**2. Key Representation: Two-Bit Encoding of $k$-mers**\n\nUsing raw strings as keys in a hash table is feasible but inefficient in terms of memory and computational cost for hashing and comparison. A more compact and performant representation is possible by exploiting the small size of the DNA alphabet, $\\{\\text{A}, \\text{C}, \\text{G}, \\text{T}\\}$. These $4$ characters can be uniquely mapped to $2$-bit integers:\n$$\n\\text{A} \\rightarrow 00_2 (0) \\\\\n\\text{C} \\rightarrow 01_2 (1) \\\\\n\\text{G} \\rightarrow 10_2 (2) \\\\\n\\text{T} \\rightarrow 11_2 (3)\n$$\nA $k$-mer, being a sequence of $k$ nucleotides, can therefore be represented as a single $2k$-bit integer. For $k \\le 32$, this fits within a standard $64$-bit integer type. For example, the $4$-mer `ACGT` is encoded as the concatenation of the $2$-bit codes for `A`, `C`, `G`, and `T`, yielding `00011011` in binary, which is the integer $27$. This integer representation serves as a highly efficient key for our hash table.\n\n**3. Handling Reverse Complement Equivalence: Canonical Representation**\n\nThe problem demands that a query for a $k$-mer $q$ also match its reverse complement, $q^{RC}$. To handle this, we must ensure that $q$ and $q^{RC}$ map to the same entry in our index. This is achieved by defining a canonical representation for every $\\{q, q^{RC}\\}$ pair. The problem specifies this canonical form: the key for any $k$-mer $s$ is $\\min(v(s), v(s^{RC}))$, where $v(s)$ is the integer representation of $s$.\n\nTo compute the integer representation of the reverse complement, $v(s^{RC})$, from the integer representation of the $k$-mer, $v(s)$, we can use bitwise operations. Let $s$ be a $k$-mer with integer value $I$ and $2k$-bit representation $b_1b_2...b_k$, where each $b_i$ is a $2$-bit block.\nThe complement of a nucleotide corresponds to the bitwise NOT of its $2$-bit code (e.g., $v(\\text{A})=00_2$, $v(\\text{T})=11_2$, and $\\sim 00_2 = 11_2$).\nThe reverse complement string is the reversed sequence of complemented bases. Its integer representation, $I_{RC}$, can be computed from $I$ in two steps:\n1.  Compute the bitwise NOT of $I$: $I_{comp} = \\sim I$. This results in an integer whose bit representation is $(\\sim b_1)(\\sim b_2)...(\\sim b_k)$.\n2.  Reverse the order of the $2$-bit blocks in $I_{comp}$. This can be done by iteratively stripping the lowest $2$-bit block from $I_{comp}$ and prepending it to a new integer.\n\nThis bitwise manipulation is significantly faster than string-based reversal and complementation.\n\n**4. Algorithmic Design**\n\nThe process is divided into two phases: preprocessing and querying.\n\n**Preprocessing Phase (Index Construction):**\nThe goal is to populate a hash table, `index`, mapping canonical $k$-mer integer keys to sets of genome identifiers.\n1.  Initialize an empty hash table, `index`.\n2.  Iterate through each genome $g$ with its identifier $ gid \\in \\{0, 1, ..., G-1\\}$.\n3.  For each substring $s$ of length $k$ in $g$:\n    a. Check if $s$ contains any ambiguous nucleotides (`N`). If it does, this window is invalid and is skipped, as per the problem statement.\n    b. If $s$ is valid, compute its $2k$-bit integer representation, $v(s)$.\n    c. Compute the integer representation of its reverse complement, $v(s^{RC})$.\n    d. Determine the canonical key: $k_{canonical} = \\min(v(s), v(s^{RC}))$.\n    e. Add the genome identifier $gid$ to the set of identifiers associated with $k_{canonical}$ in the `index`. Using a `set` automatically handles the case where a $k$-mer appears multiple times in the same genome.\n\nTo optimize step $3b$, a rolling computation can be used. Instead of re-encoding each $k$-mer from scratch (an $O(k)$ operation), we can compute the integer for the next $k$-mer from the previous one in $O(1)$ time by bit-shifting the old value to discard the exiting nucleotide and ORing in the new nucleotide. This reduces the total preprocessing time from $O(nk)$ to $O(n)$.\n\n**Query Phase:**\n1.  Given a query $k$-mer $q$ and a length $k$, first validate the query. If `len(q)` is not equal to $k$ or if $q$ contains characters outside $\\{\\text{A}, \\text{C}, \\text{G}, \\text{T}\\}$, return an empty list.\n2.  Compute the integer representation of $q$, $v(q)$.\n3.  Compute the integer representation of its reverse complement, $v(q^{RC})$.\n4.  Determine the canonical query key: $k_{query} = \\min(v(q), v(q^{RC}))$.\n5.  Perform a lookup for $k_{query}$ in the `index`.\n6.  If the key is found, retrieve the associated set of genome identifiers. Convert this set to a list and sort it in ascending order as required.\n7.  If the key is not found, the $k$-mer is not in any genome, and an empty list is returned.\n\n**5. Complexity Analysis**\n\n*   **Preprocessing Time**: Using the rolling computation, iterating through all genomes of total length $n$ takes $O(n)$ time. For each valid $k$-mer, computing the canonical key and updating the hash table takes, on average, $O(1)$ time. Thus, the total preprocessing time is $O(n)$.\n*   **Preprocessing Space**: The index stores an entry for each unique canonical $k$-mer. The number of such $k$-mers is at most $n$. Each entry stores a key and a set of genome IDs. The total space complexity is proportional to the number of distinct canonical $k$-mers and the total number of occurrences, which is $O(\\sum_{kmer} |docs(kmer)|)$. In the worst case, this is $O(n)$.\n*   **Query Time**:\n    1.  Validating and encoding the query $q$ takes $O(k)$ time.\n    2.  Computing its canonical key is $O(k)$.\n    3.  The hash table lookup is expected $O(1)$.\n    4.  If the $k$-mer is found in $m$ genomes, converting the set of IDs to a sorted list takes $O(m \\log m)$.\n    The total query time is therefore $O(k + m \\log m)$. Since $k$ is a small constant and $m$ (the number of genomes containing the $k$-mer) is much smaller than $n$, the query time is sublinear in $n$, fully satisfying the problem's core requirement.", "answer": "```python\nimport numpy as np\n\nclass KmerIndex:\n    \"\"\"\n    A data structure to index k-mers from a set of genomes for fast querying.\n    It handles reverse-complement equivalence by canonicalizing k-mers.\n    \"\"\"\n    def __init__(self, genomes, k):\n        \"\"\"\n        Initializes and builds the k-mer index.\n\n        Args:\n            genomes (list of str): A list of DNA sequences.\n            k (int): The k-mer length.\n        \"\"\"\n        if not isinstance(k, int) or k = 0:\n            raise ValueError(\"k must be a positive integer.\")\n        \n        self.k = k\n        self.genomes = genomes\n        self.index = {}\n        self.encoding = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n        self.valid_chars = set(self.encoding.keys())\n\n        # Guard for k values that would exceed a 64-bit integer representation\n        if self.k > 32:\n            raise ValueError(\"k > 32 is not supported by this implementation.\")\n\n        # Bitmask to keep k-mer integers within 2*k bits\n        self.kmer_mask = (1  (2 * self.k)) - 1 if self.k > 0 else 0\n        \n        self._build_index()\n\n    def _to_int(self, kmer_str):\n        \"\"\"Converts a k-mer string to its integer representation.\"\"\"\n        val = 0\n        for char in kmer_str:\n            val = (val  2) | self.encoding[char]\n        return val\n\n    def _rc_int(self, kmer_int):\n        \"\"\"Computes the integer representation of a k-mer's reverse complement.\"\"\"\n        # 1. Bitwise complement the 2k-bit integer.\n        #    A(00)->T(11), C(01)->G(10), which is a bitwise NOT.\n        comp_int = ~kmer_int  self.kmer_mask\n        \n        # 2. Reverse the order of the 2-bit blocks.\n        rc = 0\n        for _ in range(self.k):\n            block = comp_int  3  # Get the lowest 2 bits\n            rc = (rc  2) | block\n            comp_int >>= 2\n        return rc\n\n    def _canonical_key(self, kmer_int):\n        \"\"\"Computes the canonical key for a k-mer (min of itself and its RC).\"\"\"\n        rc = self._rc_int(kmer_int)\n        return min(kmer_int, rc)\n\n    def _build_index(self):\n        \"\"\"\n        Scans all genomes and populates the index.\n        It skips any k-mer window containing 'N'.\n        \"\"\"\n        for gid, genome in enumerate(self.genomes):\n            if len(genome)  self.k:\n                continue\n            \n            # Using a simple sliding window. For very large genomes, a rolling\n            # hash update would be more performant (O(n) vs O(n*k)).\n            for i in range(len(genome) - self.k + 1):\n                kmer_str = genome[i : i + self.k]\n                \n                # Validate k-mer characters, skipping if 'N' is present.\n                if not all(c in self.valid_chars for c in kmer_str):\n                    continue\n                \n                # Process the valid k-mer\n                kmer_int = self._to_int(kmer_str)\n                key = self._canonical_key(kmer_int)\n                \n                if key not in self.index:\n                    self.index[key] = set()\n                self.index[key].add(gid)\n\n    def query(self, q_str):\n        \"\"\"\n        Queries the index for a given k-mer string.\n\n        Args:\n            q_str (str): The query k-mer.\n\n        Returns:\n            list: A sorted list of genome identifiers containing the k-mer\n                  or its reverse complement. Returns an empty list for invalid\n                  queries or if the k-mer is not found.\n        \"\"\"\n        # Validate query string\n        if len(q_str) != self.k or not set(q_str).issubset(self.valid_chars):\n            return []\n        \n        q_int = self._to_int(q_str)\n        key = self._canonical_key(q_int)\n        \n        if key in self.index:\n            return sorted(list(self.index[key]))\n        else:\n            return []\n\ndef solve():\n    \"\"\"\n    Main function to run the predefined test suite and print results.\n    \"\"\"\n    genomes = [\n        \"ACGTACGTACGT\",   # 0\n        \"GTACGTAAGACT\",   # 1\n        \"TTTTACGTGGGG\",   # 2\n        \"CCCCGACTAAAA\",   # 3\n        \"ACGNNNACGTAC\",   # 4\n        \"TGCATGCAAGTC\"    # 5\n    ]\n    test_cases = [\n        (4, \"AGTC\"),\n        (4, \"ACGT\"),\n        (1, \"A\"),\n        (6, \"ACGTAC\"),\n        (5, \"AAAAA\"),\n        (4, \"ACGN\")\n    ]\n\n    # Cache indices by k-value to avoid rebuilding for same-k queries\n    indices = {}\n    results = []\n    \n    for k, q in test_cases:\n        if k not in indices:\n            indices[k] = KmerIndex(genomes, k)\n        \n        index = indices[k]\n        result = index.query(q)\n        results.append(result)\n\n    # Format the final output string to be exactly [[...],[...],...]\n    # with no spaces, as per the strict output requirement.\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4576326"}]}