{"hands_on_practices": [{"introduction": "The theoretical foundation of modern genome assembly rests on graph theory, but choosing the right type of graph traversal is critical. A naive approach might model assembly as finding a Hamiltonian path, which visits each unique sequence fragment once. This practice explores a counterexample [@problem_id:4552719] to demonstrate why this model fails in the presence of genomic repeats, and why the Eulerian path formulation, which traverses every connection based on its frequency, provides a more robust framework for reconstruction.", "problem": "Consider de novo genome assembly under two classical graph-based formulations, motivated by the overlap–layout–consensus (OLC) and de Bruijn graph paradigms. In a de Bruijn graph, the vertices are $(k-1)$-mers and directed edges are $k$-mers connecting a vertex equal to the $k-1$ prefix to a vertex equal to the $k-1$ suffix; edges can occur with multiplicities when the same $k$-mer appears multiple times in the genome. A Hamiltonian path is defined as a path visiting each vertex exactly once; an Eulerian traversal is defined as a walk that traverses each edge exactly as many times as it occurs (including multiplicity). It is a well-tested fact that a linear genome of length $n$ generates a de Bruijn graph that admits an Eulerian trail when built from all its $k$-mers (because, aside from the start and end vertices, the in-degree equals the out-degree). Many naive formulations of assembly as a Hamiltonian path on the vertex set fail to account for edge multiplicities arising from repeats, whereas Eulerian traversals natively incorporate them.\n\nStarting from these core definitions and facts, choose the single configuration below that constitutes a valid counterexample demonstrating that a Hamiltonian path approach on the vertex set can fail to reconstruct the genome in the presence of repeats that are shorter than the read length, while an Eulerian traversal succeeds by using edge multiplicities. Your choice must satisfy realistic assumptions: error-free reads of length $L$ with complete coverage and a de Bruijn graph parameter $k$ with $k \\leq L$.\n\nA. Genome $G = \\text{ATATATC}$, read length $L = 5$, $k = 3$. The de Bruijn graph has vertices $\\text{AT}$, $\\text{TA}$, $\\text{TC}$ and edges $\\text{ATA}$ with multiplicity $2$, $\\text{TAT}$ with multiplicity $2$, and $\\text{ATC}$ with multiplicity $1$. The repeat $\\text{AT}$ of length $2$ is shorter than $L$.\n\nB. Genome $G = \\text{ACGTTGCA}$, read length $L = 7$, $k = 4$. The de Bruijn graph has no repeated $k$-mers; all edges are unique.\n\nC. Genome $G = \\text{ACGTGCTA}$, read length $L = 7$, $k = 3$. The de Bruijn graph has no repeated $(k-1)$-mers; all vertices have degree constraints consistent with a simple path.\n\nD. Genome $G = \\text{ATATATC}$, read length $L = 2$, $k = 3$. The repeat $\\text{AT}$ has length $2$ that is not shorter than $L$, and the read length violates the stated condition on repeats being shorter than the read length.\n\nSelect the correct option.", "solution": "The problem statement is a valid exercise in bioinformatics graph theory. It is scientifically grounded, well-posed, and objective. It presents standard definitions for de Bruijn graphs, Hamiltonian paths, and Eulerian traversals in the context of de novo genome assembly. The core task is to identify a specific instance from the options that serves as a counterexample to the viability of a simple Hamiltonian path model for assembly in the presence of repeats, a well-established challenge in the field. All necessary conditions and definitions are provided.\n\nThe fundamental principle at issue is the distinction between paths defined on vertices versus paths defined on edges. A Hamiltonian path visits each vertex exactly once. An Eulerian traversal (path or trail) traverses each edge exactly once, respecting multiplicity.\nIn de Bruijn graphs used for genome assembly:\n-   Vertices represent $(k-1)$-mers.\n-   Edges represent $k$-mers.\nIf the genome sequence contains a repeat that is longer than or equal to the vertex length, $(k-1)$, the correct path for reconstructing the genome will necessarily revisit the vertex or vertices corresponding to that repeat.\nFor example, a sequence `...XYZ...XYZ...` where `XYZ` is a $(k-1)$-mer will require any valid reconstruction path to pass through the vertex `XYZ` twice. A Hamiltonian path, by definition, cannot do this.\nAn Eulerian traversal, however, operates on edges. A repeated $k$-mer in the genome simply becomes a multi-edge in the graph. The Eulerian traversal is defined to traverse every edge according to its multiplicity, so it naturally handles such repeats and can revisit vertices as required.\n\nThe task is to find an option that demonstrates this failure of the Hamiltonian approach and success of the Eulerian approach. The counterexample must satisfy the constraints: error-free reads of length $L$, complete coverage, and $k \\leq L$.\n\n### Analysis of Options\n\n**A. Genome $G = \\text{ATATATC}$, read length $L = 5$, $k = 3$. The de Bruijn graph has vertices $\\text{AT}$, $\\text{TA}$, $\\text{TC}$ and edges $\\text{ATA}$ with multiplicity $2$, $\\text{TAT}$ with multiplicity $2$, and $\\text{ATC}$ with multiplicity $1$. The repeat $\\text{AT}$ of length $2$ is shorter than $L$.**\n\nFirst, let's validate the setup. The condition $k \\leq L$ is satisfied, as $3 \\leq 5$. The repeat unit `AT` has length $2$, which is shorter than the read length $L=5$. A repeat of a 2-mer leads to a repeat of longer k-mers.\n\nLet's construct the de Bruijn graph with $k=3$. The vertices are $(k-1)$-mers (2-mers) and edges are $k$-mers (3-mers).\nThe genome is $G = \\text{ATATATC}$ (length $n=7$).\nThe set of $k$-mers of length $3$ is:\n1.  From $G[1..3]$: $\\text{ATA}$\n2.  From $G[2..4]$: $\\text{TAT}$\n3.  From $G[3..5]$: $\\text{ATA}$\n4.  From $G[4..6]$: $\\text{TAT}$\n5.  From $G[5..7]$: $\\text{ATC}$\n\nThe vertices (2-mers) are the prefixes and suffixes of these 3-mers: $\\{\\text{AT}, \\text{TA}, \\text{TC}\\}$.\nThe edges are:\n-   $\\text{ATA}$: connects vertex $\\text{AT}$ to vertex $\\text{TA}$. This $k$-mer appears twice.\n-   $\\text{TAT}$: connects vertex $\\text{TA}$ to vertex $\\text{AT}$. This $k$-mer appears twice.\n-   $\\text{ATC}$: connects vertex $\\text{AT}$ to vertex $\\text{TC}$. This $k$-mer appears once.\n\nThe graph description in the option is correct:\n-   Vertices: $\\{\\text{AT}, \\text{TA}, \\text{TC}\\}$\n-   Edges: $\\text{ATA}$ (multiplicity $2$), $\\text{TAT}$ (multiplicity $2$), $\\text{ATC}$ (multiplicity $1$).\n\n**Eulerian Traversal:**\nLet's check the degrees of the vertices (in-degree, out-degree):\n-   Vertex $\\text{AT}$: in-degree = $2$ (from the two $\\text{TAT}$ edges), out-degree = $3$ (from the two $\\text{ATA}$ edges and one $\\text{ATC}$ edge). $\\text{out} - \\text{in} = 1$. This must be the start vertex of an Eulerian trail.\n-   Vertex $\\text{TA}$: in-degree = $2$ (from the two $\\text{ATA}$ edges), out-degree = $2$ (from the two $\\text{TAT}$ edges). $\\text{out} - \\text{in} = 0$.\n-   Vertex $\\text{TC}$: in-degree = $1$ (from the $\\text{ATC}$ edge), out-degree = $0$. $\\text{in} - \\text{out} = 1$. This must be the end vertex.\nSince there is exactly one start vertex and one end vertex, an Eulerian trail exists. The trail traversing all edges is: $\\text{AT} \\xrightarrow{\\text{ATA}} \\text{TA} \\xrightarrow{\\text{TAT}} \\text{AT} \\xrightarrow{\\text{ATA}} \\text{TA} \\xrightarrow{\\text{TAT}} \\text{AT} \\xrightarrow{\\text{ATC}} \\text{TC}$.\nSpelling out this path gives the sequence: $\\text{AT}$ (start vertex) + A (from ATA) + T (from TAT) + A (from ATA) + T (from TAT) + C (from ATC) = $\\text{ATATATC}$. The Eulerian traversal successfully reconstructs the genome. This works because it revisits vertices $\\text{AT}$ and $\\text{TA}$.\n\n**Hamiltonian Path:**\nA Hamiltonian path must visit each vertex exactly once. The vertices are $\\{\\text{AT}, \\text{TA}, \\text{TC}\\}$. There are a few possible Hamiltonian paths, for example, $\\text{TA} \\to \\text{AT} \\to \\text{TC}$. This path uses one $\\text{TAT}$ edge and one $\\text{ATC}$ edge. The reconstructed sequence would be $\\text{TA}$ + T + C = $\\text{TATC}$. This is incorrect and does not use all the specified $k$-mers. The fundamental flaw is that the correct genomic path requires visiting vertices $\\text{AT}$ and $\\text{TA}$ multiple times. A Hamiltonian path is structurally incapable of representing this path.\n\nTherefore, this option is a valid counterexample.\n\n**Verdict:** **Correct**.\n\n**B. Genome $G = \\text{ACGTTGCA}$, read length $L = 7$, $k = 4$. The de Bruijn graph has no repeated $k$-mers; all edges are unique.**\n\nThe condition $k \\leq L$ is satisfied, as $4 \\leq 7$.\nLet's list the $k$-mers ($4$-mers) from the genome $G = \\text{ACGTTGCA}$:\n$\\text{ACGT}$, $\\text{CGTT}$, $\\text{GTTG}$, $\\text{TTGC}$, $\\text{TGCA}$.\nAs claimed, all $k$-mers are unique. This means all edges in the de Bruijn graph have multiplicity $1$.\nThe vertices ($(k-1)$-mers or $3$-mers) are:\n$\\text{ACG}$, $\\text{CGT}$, $\\text{GTT}$, $\\text{TTG}$, $\\text{TGC}$, $\\text{GCA}$.\nAll vertices are also unique. The graph structure is a simple path:\n$\\text{ACG} \\to \\text{CGT} \\to \\text{GTT} \\to \\text{TTG} \\to \\text{TGC} \\to \\text{GCA}$.\nIn such a simple graph, a path that visits every vertex once (Hamiltonian) is the same as a path that traverses every edge once (Eulerian). Both will succeed and correctly reconstruct the genome. This example does not demonstrate a failure of the Hamiltonian path approach due to repeats, because there are no repeats at the $k$-mer level.\n\n**Verdict:** **Incorrect**.\n\n**C. Genome $G = \\text{ACGTGCTA}$, read length $L = 7$, $k = 3$. The de Bruijn graph has no repeated $(k-1)$-mers; all vertices have degree constraints consistent with a simple path.**\n\nThe condition $k \\leq L$ is satisfied, as $3 \\leq 7$.\nThe option claims there are no repeated $(k-1)$-mers, which are $2$-mers.\nLet's list the 2-mers from the genome's $k$-mers:\nThe $k$-mers ($3$-mers) are: $\\text{ACG}, \\text{CGT}, \\text{GTG}, \\text{TGC}, \\text{GCT}, \\text{CTA}$.\nThe vertices ($2$-mers) are: $\\text{AC}, \\text{CG}, \\text{GT}, \\text{TG}, \\text{GC}, \\text{CT}, \\text{TA}$.\nAll these vertices are unique. The claim is correct.\nThe graph is: $\\text{AC} \\to \\text{CG} \\to \\text{GT} \\to \\text{TG} \\to \\text{GC} \\to \\text{CT} \\to \\text{TA}$.\nThis is a simple path graph. As with option B, both Hamiltonian and Eulerian path approaches will succeed. This cannot serve as a counterexample.\n\n**Verdict:** **Incorrect**.\n\n**D. Genome $G = \\text{ATATATC}$, read length $L = 2$, $k = 3$. The repeat $\\text{AT}$ has length $2$ that is not shorter than $L$, and the read length violates the stated condition on repeats being shorter than the read length.**\n\nThis option describes a configuration that violates the problem's own explicit constraints. The problem requires that the chosen counterexample must satisfy realistic assumptions, including `$k \\leq L$`. Here, we have $k=3$ and $L=2$, so $k > L$. It is not possible to construct a de Bruijn graph with parameter $k=3$ from reads of length $L=2$, because you cannot extract $3$-mers from $2$-mers. The entire setup is invalid based on the problem's own rules. Therefore, it cannot be a *valid* counterexample.\n\n**Verdict:** **Incorrect**.\n\n### Conclusion\n\nOnly option A provides a configuration that satisfies all the stated constraints and correctly demonstrates a scenario where a Hamiltonian path formulation fails to reconstruct a genome due to repeats, while an Eulerian traversal succeeds. The repeats in the genome lead to repeated edges and vertex reuse in the de Bruijn graph, a structure that an Eulerian traversal can handle but a Hamiltonian path cannot.", "answer": "$$\\boxed{A}$$", "id": "4552719"}, {"introduction": "While the Eulerian path framework provides a strong theoretical basis, real sequencing data introduces complexities like errors and heterozygosity, which appear as 'bubbles' in the de Bruijn graph. Deciding whether to collapse these bubbles (as errors) or preserve them (as true variants) is a critical step in producing an accurate assembly. This exercise [@problem_id:4552729] delves into the statistical heart of this problem, asking you to derive and apply a Likelihood Ratio Test to distinguish a spurious error from a genuine heterozygous site.", "problem": "A bubble in a de Bruijn graph (DBG) during de novo assembly arises when two alternative directed paths diverge from a node and reconverge, typically reflecting either true diploid heterozygosity or sequencing errors. In a diploid genome, a heterozygous Single Nucleotide Polymorphism (SNP) induces two allelic paths whose coverage is proportional to allelic fractions, whereas a sequencing error tends to produce a low-coverage spurious path. Assume Next-Generation Sequencing (NGS) read coverage across $k$-mers is well modeled by independent Poisson variables whose means are proportional to path-specific exposure weights that aggregate per-$k$-mer contributions along the path (for example, lengths or quality-weighted multiplicities). Consider a single bubble with two branch paths $A$ and $B$, with observed aggregate $k$-mer counts $S_{A}$ and $S_{B}$ over exposure weights $E_{A}$ and $E_{B}$, respectively. Let the base-calling error rate be $\\epsilon$, and assume a simple substitution-error model where, conditional on an error occurring at the distinguishing site, the erroneous base is uniformly one of the three possible alternative nucleotides, so the probability of the specific erroneous allele is $\\epsilon/3$.\n\nFormulate a Likelihood Ratio Test (LRT) to decide between the hypotheses:\n- $\\mathcal{H}_{0}$ (error bubble): branch $A$ is the true allele with per-unit exposure rate proportional to $(1-\\epsilon)$ and branch $B$ is the spurious error allele with per-unit exposure rate proportional to $\\epsilon/3$, with an unknown shared scaling factor $\\lambda$.\n- $\\mathcal{H}_{1}$ (heterozygous bubble): both branches are true alleles with per-unit exposure rates proportional to $\\lambda q$ for branch $A$ and $\\lambda(1-q)$ for branch $B$, where $\\lambda>0$ and $q\\in(0,1)$ are unknown.\n\nStarting from the Poisson likelihood and without invoking any shortcut formulas, derive the coverage-weighted LRT statistic $-2\\ln\\Lambda$ in closed form in terms of $S_{A}$, $S_{B}$, $E_{A}$, $E_{B}$, and $\\epsilon$. Then, using the derived expression, compute the numerical value of $-2\\ln\\Lambda$ for the following bubble:\n- $S_{A} = 240$, $S_{B} = 230$,\n- $E_{A} = 12$, $E_{B} = 12$,\n- $\\epsilon = 0.01$.\n\nRound your final numerical value to four significant figures. Express the final statistic as a dimensionless number. Finally, explain, in words, how this decision rule justifies preserving bubbles that reflect true heterozygosity rather than collapsing bubbles attributable to sequencing errors, but only report the numerical value for the final answer.", "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded in the principles of statistical genomics, is well-posed, objective, and contains all necessary information to derive a solution.\n\nThe task is to formulate a Likelihood Ratio Test (LRT) to distinguish between an error-induced bubble and a heterozygous bubble in a de Bruijn graph. We are given the observed aggregate $k$-mer counts $S_A$ and $S_B$ for two alternative paths, A and B, with corresponding exposure weights $E_A$ and $E_B$. The counts are assumed to follow independent Poisson distributions.\n\nThe likelihood function for two independent Poisson-distributed random variables $S_A$ and $S_B$ with means $\\mu_A$ and $\\mu_B$ is given by:\n$$L(\\mu_A, \\mu_B; S_A, S_B) = \\frac{\\mu_A^{S_A} \\exp(-\\mu_A)}{S_A!} \\cdot \\frac{\\mu_B^{S_B} \\exp(-\\mu_B)}{S_B!}$$\nThe log-likelihood, ignoring constant terms in $S_A!$ and $S_B!$ which will cancel in the LRT, is:\n$$\\ln L(\\mu_A, \\mu_B) = S_A \\ln(\\mu_A) - \\mu_A + S_B \\ln(\\mu_B) - \\mu_B$$\n\nWe will find the maximized log-likelihood under each hypothesis.\n\n**Null Hypothesis $\\mathcal{H}_0$: Error Bubble**\nUnder $\\mathcal{H}_0$, the means are parameterized by a single unknown scaling factor $\\lambda > 0$:\n$$\\mu_A = \\lambda (1-\\epsilon) E_A$$\n$$\\mu_B = \\lambda \\frac{\\epsilon}{3} E_B$$\nThe log-likelihood under $\\mathcal{H}_0$ is a function of $\\lambda$:\n$$\\ln L_0(\\lambda) = S_A \\ln(\\lambda (1-\\epsilon) E_A) - \\lambda (1-\\epsilon) E_A + S_B \\ln(\\lambda \\frac{\\epsilon}{3} E_B) - \\lambda \\frac{\\epsilon}{3} E_B$$\n$$\\ln L_0(\\lambda) = (S_A + S_B) \\ln(\\lambda) - \\lambda \\left((1-\\epsilon)E_A + \\frac{\\epsilon}{3}E_B\\right) + \\text{constant terms}$$\nTo find the Maximum Likelihood Estimate (MLE) for $\\lambda$, we differentiate with respect to $\\lambda$ and set the result to zero:\n$$\\frac{\\partial \\ln L_0}{\\partial \\lambda} = \\frac{S_A + S_B}{\\lambda} - \\left((1-\\epsilon)E_A + \\frac{\\epsilon}{3}E_B\\right) = 0$$\nSolving for $\\lambda$ gives the MLE $\\hat{\\lambda}_0$:\n$$\\hat{\\lambda}_0 = \\frac{S_A + S_B}{(1-\\epsilon)E_A + \\frac{\\epsilon}{3}E_B}$$\nThe MLEs for the means under $\\mathcal{H}_0$ are:\n$$\\hat{\\mu}_{A,0} = \\hat{\\lambda}_0 (1-\\epsilon) E_A = (S_A + S_B) \\frac{(1-\\epsilon)E_A}{(1-\\epsilon)E_A + \\frac{\\epsilon}{3}E_B}$$\n$$\\hat{\\mu}_{B,0} = \\hat{\\lambda}_0 \\frac{\\epsilon}{3} E_B = (S_A + S_B) \\frac{\\frac{\\epsilon}{3}E_B}{(1-\\epsilon)E_A + \\frac{\\epsilon}{3}E_B}$$\nNote that $\\hat{\\mu}_{A,0} + \\hat{\\mu}_{B,0} = S_A + S_B$.\nThe maximized log-likelihood under $\\mathcal{H}_0$ is $\\ln L_0(\\hat{\\lambda}_0) = S_A \\ln(\\hat{\\mu}_{A,0}) - \\hat{\\mu}_{A,0} + S_B \\ln(\\hat{\\mu}_{B,0}) - \\hat{\\mu}_{B,0}$.\n\n**Alternative Hypothesis $\\mathcal{H}_1$: Heterozygous Bubble**\nUnder $\\mathcal{H}_1$, the means are parameterized by two unknown parameters, $\\lambda > 0$ and $q \\in (0,1)$:\n$$\\mu_A = \\lambda q E_A$$\n$$\\mu_B = \\lambda (1-q) E_B$$\nThis model has two free parameters. For any pair of observed positive counts $(S_A, S_B)$, we can find a unique pair $(\\lambda, q)$ within the specified ranges such that the model means equal the observations. Solving $\\hat{\\mu}_{A,1} = S_A$ and $\\hat{\\mu}_{B,1} = S_B$ for $\\lambda$ and $q$ gives:\n$$\\hat{q}_1 = \\frac{S_A/E_A}{S_A/E_A + S_B/E_B} = \\frac{S_A E_B}{S_A E_B + S_B E_A}$$\n$$\\hat{\\lambda}_1 = \\frac{S_A}{E_A} + \\frac{S_B}{E_B}$$\nSince the given counts $S_A, S_B$ are positive, $\\hat{q}_1 \\in (0,1)$ and $\\hat{\\lambda}_1 > 0$. Therefore, the parameter space under $\\mathcal{H}_1$ is rich enough to perfectly fit any positive data. This means $\\mathcal{H}_1$ is a reparameterization of the saturated model. The MLEs for the means under this hypothesis are simply the observed counts:\n$$\\hat{\\mu}_{A,1} = S_A$$\n$$\\hat{\\mu}_{B,1} = S_B$$\nThe maximized log-likelihood under $\\mathcal{H}_1$ is $\\ln L_1 = S_A \\ln(S_A) - S_A + S_B \\ln(S_B) - S_B$.\n\n**Likelihood Ratio Test Statistic**\nThe LRT statistic is given by $-2\\ln\\Lambda$, where $\\Lambda = \\frac{L_0(\\hat{\\lambda}_0)}{L_1(\\hat{\\lambda}_1, \\hat{q}_1)}$.\n$$-2\\ln\\Lambda = -2 (\\ln L_0 - \\ln L_1)$$\n$$-2\\ln\\Lambda = -2 \\left[ (S_A \\ln(\\hat{\\mu}_{A,0}) - \\hat{\\mu}_{A,0} + S_B \\ln(\\hat{\\mu}_{B,0}) - \\hat{\\mu}_{B,0}) - (S_A \\ln(S_A) - S_A + S_B \\ln(S_B) - S_B) \\right]$$\nUsing the fact that $\\hat{\\mu}_{A,0} + \\hat{\\mu}_{B,0} = S_A+S_B$, the terms $-\\hat{\\mu}_{A,0} - \\hat{\\mu}_{B,0}$ and $-S_A - S_B$ cancel.\n$$-2\\ln\\Lambda = -2 \\left[ S_A \\ln(\\hat{\\mu}_{A,0}) + S_B \\ln(\\hat{\\mu}_{B,0}) - S_A \\ln(S_A) - S_B \\ln(S_B) \\right]$$\n$$-2\\ln\\Lambda = 2 \\left[ S_A (\\ln(S_A) - \\ln(\\hat{\\mu}_{A,0})) + S_B (\\ln(S_B) - \\ln(\\hat{\\mu}_{B,0})) \\right]$$\n$$-2\\ln\\Lambda = 2 \\left[ S_A \\ln\\left(\\frac{S_A}{\\hat{\\mu}_{A,0}}\\right) + S_B \\ln\\left(\\frac{S_B}{\\hat{\\mu}_{B,0}}\\right) \\right]$$\nSubstituting the expressions for $\\hat{\\mu}_{A,0}$ and $\\hat{\\mu}_{B,0}$, we obtain the closed-form expression:\n$$ -2\\ln\\Lambda = 2 \\left[ S_A \\ln\\left(\\frac{S_A \\left((1-\\epsilon)E_A + \\frac{\\epsilon}{3}E_B\\right)}{(S_A+S_B)(1-\\epsilon)E_A}\\right) + S_B \\ln\\left(\\frac{S_B \\left((1-\\epsilon)E_A + \\frac{\\epsilon}{3}E_B\\right)}{(S_A+S_B)\\frac{\\epsilon}{3}E_B}\\right) \\right] $$\n\n**Numerical Calculation**\nWe are given the values: $S_A = 240$, $S_B = 230$, $E_A = 12$, $E_B = 12$, and $\\epsilon=0.01$.\nFirst, calculate the expected counts under $\\mathcal{H}_0$:\n$$S_A + S_B = 240 + 230 = 470$$\nSince $E_A=E_B=12$, the expressions for the means simplify:\n$$\\hat{\\mu}_{A,0} = (470) \\frac{(1-0.01) \\cdot 12}{(1-0.01) \\cdot 12 + \\frac{0.01}{3} \\cdot 12} = 470 \\frac{0.99}{0.99 + 0.01/3} = 470 \\frac{0.99}{2.98/3} = 470 \\frac{2.97}{2.98} \\approx 468.4228$$\n$$\\hat{\\mu}_{B,0} = 470 - \\hat{\\mu}_{A,0} = 470 - 470 \\frac{2.97}{2.98} = 470 \\left(1 - \\frac{2.97}{2.98}\\right) = 470 \\frac{0.01}{2.98} \\approx 1.5772$$\nNow we compute the statistic:\n$$-2\\ln\\Lambda = 2 \\left[ 240 \\ln\\left(\\frac{240}{468.4228}\\right) + 230 \\ln\\left(\\frac{230}{1.5772}\\right) \\right]$$\n$$-2\\ln\\Lambda = 2 \\left[ 240 \\ln(0.512358) + 230 \\ln(145.8298) \\right]$$\n$$-2\\ln\\Lambda = 2 \\left[ 240(-0.668735) + 230(4.982410) \\right]$$\n$$-2\\ln\\Lambda = 2 \\left[ -160.4964 + 1145.9543 \\right]$$\n$$-2\\ln\\Lambda = 2 [985.4579] = 1970.9158$$\nRounding to four significant figures, the value is $1971$.\n\n**Explanation of the Decision Rule**\nThe LRT statistic $-2\\ln\\Lambda$ quantifies how much better the alternative hypothesis $\\mathcal{H}_1$ (heterozygous alleles) explains the observed data compared to the null hypothesis $\\mathcal{H}_0$ (sequencing error). A larger value of this statistic indicates stronger evidence against the null hypothesis.\nUnder Wilks' theorem, for nested or correctly specified models, this statistic asymptotically follows a chi-squared distribution with degrees of freedom equal to the difference in the number of free parameters between the two hypotheses ($df = 2-1=1$ in this case). A researcher would compare the calculated value of $-2\\ln\\Lambda$ to a critical value from the $\\chi^2_1$ distribution (e.g., $3.84$ for a significance level of $\\alpha=0.05$).\nIn our case, the observed counts $S_A=240$ and $S_B=230$ are very similar. The heterozygous model ($\\mathcal{H}_1$) can readily account for these similar counts with an estimated allele fraction $\\hat{q}_1 = 240/470 \\approx 0.51$. In contrast, the error model ($\\mathcal{H}_0$) assumes one path is a rare artifact, so it predicts count proportions close to $(1-\\epsilon) : \\epsilon/3$, which is approximately $0.99 : 0.0033$. The expected counts under this model ($\\hat{\\mu}_{A,0} \\approx 468, \\hat{\\mu}_{B,0} \\approx 2$) are drastically different from the observed counts. This poor fit of the error model results in a very small likelihood $L_0$ compared to $L_1$, leading to a very large positive value for $-2\\ln\\Lambda$.\nThe extremely large statistic ($1971$) provides overwhelming evidence to reject the error hypothesis in favor of the heterozygous hypothesis. Therefore, the decision rule justifies preserving the bubble as it almost certainly represents true biological variation (heterozygosity) rather than a technical artifact.", "answer": "$$\\boxed{1971}$$", "id": "4552729"}, {"introduction": "Once an assembly algorithm has produced a set of contiguous sequences, or 'contigs,' a crucial question remains: how good is the assembly? The $N50$ statistic is the most widely used metric for quantifying assembly continuity, indicating the length of the contigs that make up the bulk of the assembly. This final practice [@problem_id:4552686] will guide you through deriving the algorithm for calculating $N50$ from first principles and applying it to a set of contigs, a fundamental skill for evaluating and comparing genome assemblies.", "problem": "A de novo genome assembly was generated using a de Bruijn graph method with $k$-mer size $k=55$ from a diploid sample, and contigs were computed after resolving bubbles and removing low-coverage tips. Consider the assembled contig lengths (in base pairs) collected from the final contig set: $830{,}124$, $710{,}552$, $690{,}121$, $540{,}600$, $439{,}820$, $415{,}000$, $398{,}657$, $372{,}000$, $250{,}300$, $240{,}000$, $120{,}000$, $95{,}000$. In de novo genome assembly (overlap–layout–consensus and de Bruijn graphs), the $N50$ statistic is defined as the contig length $L$ such that at least one half of the total assembly size is contained in contigs of length greater than or equal to $L$. Using only standard, widely accepted definitions of contigs and the $N50$ statistic, derive the algorithmic procedure from first principles to compute $N50$ for a multiset of contig lengths, and then apply it to the given lengths. Explicitly describe the sorting and accumulation steps, define the threshold mathematically, and identify the smallest contig length crossing the threshold. Report the final $N50$ length as an integer number of base pairs. Do not round; provide the exact integer. Express the final result in base pairs.", "solution": "The problem requires the computation of the N50 statistic for a given set of contig lengths from a de novo genome assembly. First, we must formalize the definition of the N50 statistic and derive the algorithm for its calculation from first principles, as requested.\n\nThe N50 statistic is a measure of assembly continuity. It is defined as the length $L_{50}$ such that at least $50\\%$ of the total assembly size is contained within contigs of length greater than or equal to $L_{50}$. By convention in bioinformatics, $L_{50}$ is one of the contig lengths from the assembly itself. Specifically, it is the smallest contig length in the minimal set of the largest contigs whose combined length meets or exceeds $50\\%$ of the total assembly size.\n\nFrom this definition, we can derive a precise, step-by-step algorithm:\n\n1.  **Calculate the Total Assembly Size**: Let the given multiset of contig lengths be $\\mathcal{L} = \\{l_1, l_2, \\dots, l_n\\}$, where $n$ is the total number of contigs. The total assembly size, $S_{\\text{total}}$, is the sum of the lengths of all contigs.\n    $$S_{\\text{total}} = \\sum_{i=1}^{n} l_i$$\n\n2.  **Define the N50 Threshold**: The threshold is defined as one half of the total assembly size.\n    $$T_{50} = \\frac{S_{\\text{total}}}{2}$$\n\n3.  **Sort the Contig Lengths**: The contig lengths must be sorted in descending order, from longest to shortest. Let the sorted list of lengths be $\\mathcal{L}' = (l'_1, l'_2, \\dots, l'_n)$, where $l'_1 \\ge l'_2 \\ge \\dots \\ge l'_n$.\n\n4.  **Find the N50 Value**: Iterate through the sorted list $\\mathcal{L}'$, calculating the cumulative sum of the contig lengths. The N50 value is the length $l'_j$ of the first contig in the sequence that causes the cumulative sum to meet or exceed the threshold $T_{50}$. Mathematically, we find the smallest index $j$ such that:\n    $$\\sum_{i=1}^{j} l'_i \\ge T_{50}$$\n    The N50 value is then the contig length at this index, $L_{50} = l'_j$. The previous cumulative sum must be less than the threshold: $\\sum_{i=1}^{j-1} l'_i < T_{50}$ (with the sum being $0$ for $j=1$).\n\nNow, we apply this algorithm to the provided data.\n\nThe given contig lengths, in base pairs, are:\n$\\mathcal{L} = \\{830{,}124, 710{,}552, 690{,}121, 540{,}600, 439{,}820, 415{,}000, 398{,}657, 372{,}000, 250{,}300, 240{,}000, 120{,}000, 95{,}000\\}$.\nThere are $n=12$ contigs.\n\n**Step 1: Calculate the Total Assembly Size**\nWe sum all the lengths in the set $\\mathcal{L}$:\n$$S_{\\text{total}} = 830{,}124 + 710{,}552 + 690{,}121 + 540{,}600 + 439{,}820 + 415{,}000 + 398{,}657 + 372{,}000 + 250{,}300 + 240{,}000 + 120{,}000 + 95{,}000$$\n$$S_{\\text{total}} = 5{,}092{,}174 \\text{ base pairs}$$\n\n**Step 2: Define the N50 Threshold**\nThe threshold is half of the total assembly size:\n$$T_{50} = \\frac{5{,}092{,}174}{2} = 2{,}546{,}087$$\n\n**Step 3: Sort the Contig Lengths**\nThe provided list of contig lengths is already sorted in descending order. Let's denote this sorted list as $\\mathcal{L}'$:\n$\\mathcal{L}' = (l'_1, l'_2, \\dots, l'_{12}) = (830{,}124, 710{,}552, 690{,}121, 540{,}600, 439{,}820, 415{,}000, 398{,}657, 372{,}000, 250{,}300, 240{,}000, 120{,}000, 95{,}000)$.\n\n**Step 4: Find the N50 Value by Accumulation**\nWe compute the cumulative sum of contig lengths from the sorted list $\\mathcal{L}'$ and compare it to the threshold $T_{50} = 2{,}546{,}087$.\n\n-   Add $l'_1 = 830{,}124$:\n    Cumulative sum = $830{,}124$. This is less than $2{,}546{,}087$.\n\n-   Add $l'_2 = 710{,}552$:\n    Cumulative sum = $830{,}124 + 710{,}552 = 1{,}540{,}676$. This is less than $2{,}546{,}087$.\n\n-   Add $l'_3 = 690{,}121$:\n    Cumulative sum = $1{,}540{,}676 + 690{,}121 = 2{,}230{,}797$. This is less than $2{,}546{,}087$.\n\n-   Add $l'_4 = 540{,}600$:\n    Cumulative sum = $2{,}230{,}797 + 540{,}600 = 2{,}771{,}397$. This value is greater than or equal to the threshold $T_{50} = 2{,}546{,}087$.\n\nThis is the first point at which the cumulative sum crosses the threshold. The index is $j=4$. The contig length that caused this crossing is $l'_4$. Therefore, the N50 value is the length of this contig.\n\n$L_{50} = l'_4 = 540{,}600$.\n\nThe set of contigs with length greater than or equal to $540{,}600$ is $\\{830{,}124, 710{,}552, 690{,}121, 540{,}600\\}$. The sum of their lengths is $2{,}771{,}397$, which constitutes $\\frac{2{,}771{,}397}{5{,}092{,}174} \\approx 54.4\\%$ of the total assembly, thus satisfying the N50 definition. The next largest contig length in the sorted list is $l'_3 = 690{,}121$. The sum of lengths of contigs $\\ge 690{,}121$ is $2{,}230{,}797$, which is less than the threshold. Thus, $l'_4 = 540{,}600$ is indeed the correct N50 value according to the standard definition.", "answer": "$$\\boxed{540600}$$", "id": "4552686"}]}