{"hands_on_practices": [{"introduction": "The first gate in any quality control pipeline is ensuring the integrity and correct interpretation of the input data. In NGS, Phred quality scores are encoded as ASCII characters, but different standards use different numerical offsets. This practice [@problem_id:4590262] guides you to build a principled statistical test to distinguish between the two dominant encodings, Phred+33 and Phred+64, based on the empirically observed range of quality characters. Successfully completing this task is fundamental, as misinterpreting the encoding renders all subsequent quality-based analyses invalid.", "problem": "You will design and implement a program that, given the empirical distribution of quality characters from files in the FASTQ format (FASTQ), performs a hypothesis test to infer whether the encoding offset used is Phred plus $33$ or Phred plus $64$. The context is Next Generation Sequencing (NGS) data preprocessing in bioinformatics and medical data analytics, where quality control of base-calling accuracy is critical.\n\nAssume the following foundational definitions and facts:\n- Phred quality score (Phred) is defined by the relationship $$Q=-10\\log_{10}(p),$$ where $Q$ is an integer-valued quality score and $p$ is the probability of error for a base call.\n- In FASTQ, quality scores are represented as American Standard Code for Information Interchange (ASCII) characters using an offset $o$ such that each character $c$ encodes an integer $$q(c,o)=\\mathrm{ord}(c)-o.$$ Widely used encodings are $o=33$ (Phred plus $33$) and $o=64$ (Phred plus $64$).\n- Empirically and by platform specification, observed Phred scores are constrained to the integer range $$q\\in\\{0,1,2,\\dots,41\\}.$$\n- Under the encoding offset $o$, the valid ASCII support for quality characters is $$\\mathcal{S}_o=\\{c\\in\\text{ASCII}:\\mathrm{ord}(c)\\in[o,o+41]\\}.$$\n\nYour task is to construct a statistical test, based only on the empirical distribution of observed quality characters, to decide between the two composite hypotheses\n- $H_{33}: o=33$,\n- $H_{64}: o=64$,\nsubject to the constraint that the mapped scores $q(c,o)$ must lie in the set $\\{0,\\dots,41\\}$ for all observed characters $c$. The test must be principled, derive its decision rule from the above definitions and facts, and return a numerical decision for each test case. If the observed empirical distribution does not allow a definitive choice between $H_{33}$ and $H_{64}$ under these constraints, the test must output an undetermined code according to a clearly justified rule.\n\nInput format and data model:\n- There is no external input; your program will internally use four test cases, each provided as a list of strings. Each string represents one FASTQ quality line. The program should treat the multiset of all characters across lines in a case as the empirical sample $\\{c_1,\\dots,c_n\\}$.\n- The four test cases are:\n    1. Case A (typical Phred plus $33$ scenario): $$[\"!!IIJJ\", \"!IJIJ\"]$$\n    2. Case B (typical Phred plus $64$ scenario): $$[\"@@hhi\", \"hhi@@\"]$$\n    3. Case C (ambiguous scenario entirely within the overlap region): $$[\"@ABCDEFGHIJ\"]$$\n    4. Case D (boundary ambiguous scenario): $$[\"@@@III\", \"@I@I@I\"]$$\n\nOutput specification:\n- For each case, output a single integer decision:\n    - Output $33$ if your test infers Phred plus $33$,\n    - Output $64$ if your test infers Phred plus $64$,\n    - Output $0$ if your test is undetermined under the derived decision rule.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the four cases, for example `[33,64,0,0]`.\n\nDesign constraints:\n- The derivation must begin from the above core definitions and widely accepted facts and proceed to a logically sound decision rule. Do not assume any additional platform-specific heuristics or external hints beyond the stated constraints.\n- The statistical test must be defined in purely mathematical terms, relying only on the empirical distribution of observed ASCII characters (through their integer codes) and the known support constraints implied by the two encodings.\n- Ensure completeness, scientific realism, and self-consistency: The decision rule must be justifiable and robust for the provided test suite, including normal operation, boundary conditions, and edge cases.", "solution": "The problem requires the design of a statistical test to determine the encoding offset of Phred quality scores in FASTQ-formatted data. The decision is to be made between two competing hypotheses: $H_{33}$, which posits an offset of $o=33$ (Phred+33), and $H_{64}$, which posits an offset of $o=64$ (Phred+64). The decision must be based solely on the empirical distribution of observed quality characters, subject to established constraints of the FASTQ format and Phred scores.\n\nOur derivation begins with the fundamental principles provided. The Phred quality score, $Q$, is an integer. The problem states that empirically, these scores are confined to the set $Q \\in \\{0, 1, 2, \\dots, 41\\}$. In a FASTQ file, each quality score is encoded as an American Standard Code for Information Interchange (ASCII) character, $c$, using an integer offset, $o$. The decoding rule is given by:\n$$q(c, o) = \\mathrm{ord}(c) - o$$\nwhere $\\mathrm{ord}(c)$ is the ASCII ordinal value of the character $c$.\n\nFor any given character $c$ present in a quality string to be considered valid under a specific encoding hypothesis $H_o$, its decoded quality score $q(c, o)$ must fall within the permissible range of Phred scores. That is, for a given offset $o$, a character $c$ is valid if and only if:\n$$0 \\le q(c, o) \\le 41$$\nSubstituting the definition of $q(c, o)$, we obtain a constraint on the ordinal value of the character:\n$$0 \\le \\mathrm{ord}(c) - o \\le 41$$\nThis inequality can be rewritten to define a closed interval of valid ASCII ordinal values for a given offset $o$:\n$$o \\le \\mathrm{ord}(c) \\le o + 41$$\n\nWe can now define the valid ASCII ordinal ranges for our two specific hypotheses.\n\nFor hypothesis $H_{33}$ (Phred+33), where the offset is $o=33$:\nThe range of valid ordinal values is $[33, 33+41]$, which is $[33, 74]$. Let us denote this set of ordinal values as $\\mathcal{R}_{33}$. The corresponding ASCII characters range from `!` (ordinal $33$) to `J` (ordinal $74$).\n\nFor hypothesis $H_{64}$ (Phred+64), where the offset is $o=64$:\nThe range of valid ordinal values is $[64, 64+41]$, which is $[64, 105]$. Let us denote this set of ordinal values as $\\mathcal{R}_{64}$. The corresponding ASCII characters range from `@` (ordinal $64$) to `i` (ordinal $105$).\n\nThe core of our statistical test is a rule of consistency. A given hypothesis $H_o$ is considered viable if, and only if, *all* characters in the observed empirical sample are valid under that hypothesis. Let the multiset of observed characters from a given test case be $C_{obs} = \\{c_1, c_2, \\dots, c_n\\}$, and let $O_{obs} = \\{\\mathrm{ord}(c_1), \\mathrm{ord}(c_2), \\dots, \\mathrm{ord}(c_n)\\}$ be the corresponding set of ordinal values.\n\nHypothesis $H_{33}$ is viable if and only if every observed ordinal value falls within the range $\\mathcal{R}_{33}$. Mathematically, $O_{obs} \\subseteq \\mathcal{R}_{33}$.\nHypothesis $H_{64}$ is viable if and only if every observed ordinal value falls within the range $\\mathcal{R}_{64}$. Mathematically, $O_{obs} \\subseteq \\mathcal{R}_{64}$.\n\nThese set inclusion conditions can be checked efficiently by examining the minimum and maximum values of the observed ordinals. Let $o_{min} = \\min(O_{obs})$ and $o_{max} = \\max(O_{obs})$.\nThe viability condition for $H_{33}$, which we denote as the boolean predicate $V_{33}$, is:\n$$V_{33} \\equiv (o_{min} \\ge 33) \\land (o_{max} \\le 74)$$\nThe viability condition for $H_{64}$, denoted as $V_{64}$, is:\n$$V_{64} \\equiv (o_{min} \\ge 64) \\land (o_{max} \\le 105)$$\n\nIf the set of observations $C_{obs}$ is empty, $o_{min}$ and $o_{max}$ are undefined. In this special case, the conditions $O_{obs} \\subseteq \\mathcal{R}_{33}$ and $O_{obs} \\subseteq \\mathcal{R}_{64}$ are vacuously true, making both hypotheses viable.\n\nWith these predicates, we can construct a deterministic decision rule:\n1.  If $V_{33}$ is true and $V_{64}$ is false: The data are uniquely consistent with the Phred+33 encoding. This implies that there is at least one character $c$ with $\\mathrm{ord}(c)  64$. The decision is $33$.\n2.  If $V_{33}$ is false and $V_{64}$ is true: The data are uniquely consistent with the Phred+64 encoding. This implies that there is at least one character $c$ with $\\mathrm{ord}(c)  74$. The decision is $64$.\n3.  If $V_{33}$ is true and $V_{64}$ is true: The data are consistent with both encoding schemes. This occurs if and only if all observed characters have ordinal values within the intersection of the two valid ranges: $\\mathcal{R}_{33} \\cap \\mathcal{R}_{64} = [33, 74] \\cap [64, 105] = [64, 74]$. In this scenario, the encoding is ambiguous based on the given constraints. The decision is $0$ (undetermined). This logic also covers the edge case of an empty set of observations.\n4.  If $V_{33}$ is false and $V_{64}$ is false: The data are inconsistent with both hypotheses. This would occur if the sample contained, for example, a character with an ordinal value less than $33$ or a combination of characters that spans outside both individual ranges (e.g., a character with ordinal $ 64$ and another with ordinal $ 74$). Such data would violate the problem's premise that a valid encoding exists. As no definitive choice can be made, this case is also classified as undetermined, and the decision is $0$.\n\nThis set of rules provides a complete, robust, and logically derived algorithm for deciding between $H_{33}$ and $H_{64}$, or declaring ambiguity, for any given sample of quality characters.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Designs and implements a program to infer FASTQ quality encoding format.\n    The program performs a hypothesis test to decide between Phred+33 and Phred+64.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Typical Phred+33 scenario\n        [\"!!IIJJ\", \"!IJIJ\"],\n        # Case B: Typical Phred+64 scenario\n        [\"@@hhi\", \"hhi@@\"],\n        # Case C: Ambiguous scenario\n        [\"@ABCDEFGHIJ\"],\n        # Case D: Boundary ambiguous scenario\n        [\"@@@III\", \"@I@I@I\"],\n    ]\n\n    results = []\n    \n    # Define constants for the ordinal ranges based on the problem statement.\n    # For Phred+33 (o=33), valid quality scores q in [0, 41] map to ordinals in [33, 74].\n    PHRED33_ORD_MIN = 33\n    PHRED33_ORD_MAX = 74\n    \n    # For Phred+64 (o=64), valid quality scores q in [0, 41] map to ordinals in [64, 105].\n    PHRED64_ORD_MIN = 64\n    PHRED64_ORD_MAX = 105\n\n    for case in test_cases:\n        # Concatenate all quality strings in the case to get the full sample of characters.\n        all_chars = \"\".join(case)\n\n        # Handle the edge case of no character observations.\n        # If there are no characters, the data is consistent with both hypotheses (vacuously true),\n        # so the result is undetermined.\n        if not all_chars:\n            results.append(0)\n            continue\n            \n        # Convert all characters to their ASCII ordinal values.\n        ord_values = np.array([ord(c) for c in all_chars])\n        \n        # Find the minimum and maximum ordinal values in the sample.\n        o_min = ord_values.min()\n        o_max = ord_values.max()\n\n        # Determine if the observed range of ordinals is consistent with Phred+33.\n        # The entire sample must fall within the valid range for Phred+33.\n        is_valid_33 = (o_min = PHRED33_ORD_MIN) and (o_max = PHRED33_ORD_MAX)\n        \n        # Determine if the observed range of ordinals is consistent with Phred+64.\n        # The entire sample must fall within the valid range for Phred+64.\n        is_valid_64 = (o_min = PHRED64_ORD_MIN) and (o_max = PHRED64_ORD_MAX)\n\n        # Apply the decision rule derived from the consistency checks.\n        if is_valid_33 and not is_valid_64:\n            # The data is only consistent with Phred+33.\n            decision = 33\n        elif not is_valid_33 and is_valid_64:\n            # The data is only consistent with Phred+64.\n            decision = 64\n        elif is_valid_33 and is_valid_64:\n            # The data is consistent with both. All characters fall in the\n            # overlapping ordinal range [64, 74]. The encoding is ambiguous.\n            decision = 0\n        else: # not is_valid_33 and not is_valid_64\n            # The data is inconsistent with both schemas. This case is also ambiguous\n            # or indicates invalid data; it cannot be determined.\n            decision = 0\n            \n        results.append(decision)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4590262"}, {"introduction": "A common artifact in many sequencing technologies is a drop in base-calling accuracy towards the end of reads. These low-quality tails can increase mapping errors and generate false positive variants. This exercise [@problem_id:4590261] puts you in control of a core QC task: implementing a sliding-window trimming algorithm. You will apply a defined quality threshold to windows of bases to decide where to trim reads, providing direct, practical experience in using Phred scores to improve dataset reliability.", "problem": "A sequencing center generates five reads from Next-Generation Sequencing (NGS), each accompanied by basewise Phred quality scores. The Phred quality score (Phred) is defined by $Q = -10 \\log_{10}(p)$, where $p$ is the probability that a base is called incorrectly. A widely used and well-tested heuristic in NGS data quality control is sliding-window trimming: scan the read from the $5'$ end with a fixed window of size $w$, compute the arithmetic mean of the Phred scores in the window, and if the windowâ€™s mean drops below a specified threshold, trim the read at the start of that window (discarding that window and all downstream bases). This approach improves downstream alignment and variant calling robustness by removing low-confidence regions.\n\nConsider a window size $w = 4$ and a threshold of mean quality $Q \\ge 20$. For each read, let the quality sequence be $Q_{1}, Q_{2}, \\dots, Q_{n}$ with $1$-based indexing. Define window means $M_{i} = \\frac{1}{4}\\left(Q_{i} + Q_{i+1} + Q_{i+2} + Q_{i+3}\\right)$ for $i = 1, 2, \\dots, n-3$. The trimming rule is:\n- Find the smallest index $k$ such that $M_{k}  20$. If such $k$ exists, trim the read starting at base $k$ (retain bases $1$ through $k-1$); if no such $k$ exists, retain the entire read of length $n$.\n\nGiven the following five quality strings (already in numeric Phred $Q$ units), apply the above trimming rule and report, for each read, the number of bases retained after trimming. Express the final results as a single row matrix of five numbers (no units), corresponding to reads $1$ through $5$ in order.\n\nRead $1$: $31, 30, 29, 30, 28, 27, 26, 25, 24, 23, 22, 21, 18, 17, 16, 15$\n\nRead $2$: $25, 24, 23, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29$\n\nRead $3$: $28, 29, 30, 31, 27, 26, 25, 24, 23, 22, 21, 20, 20, 21, 22, 23$\n\nRead $4$: $35, 34, 10, 10, 10, 10, 10, 10, 30, 30, 30, 30, 30, 30, 30, 30$\n\nRead $5$: $20, 20, 20, 20, 20, 19, 19, 19, 19, 18, 18, 18, 21, 22, 23, 24$\n\nNo rounding is needed; report exact integer retained lengths in bases.", "solution": "The problem is well-defined, scientifically grounded in the field of bioinformatics, and provides all necessary information to proceed. We are tasked with applying a sliding-window trimming algorithm to five sequences of Phred quality scores. The window size is $w=4$ and the mean quality threshold is $20$. For each read, described by its quality sequence $Q_1, Q_2, \\dots, Q_n$, we calculate the window means $M_i = \\frac{1}{4}(Q_i + Q_{i+1} + Q_{i+2} + Q_{i+3})$. We must find the smallest index $k$ for which $M_k  20$. If such a $k$ is found, the read is trimmed, and the number of retained bases is $k-1$. If no such $k$ exists, the entire read of length $n$ is retained. All reads have length $n=16$.\n\nRead $1$: $Q^{(1)} = (31, 30, 29, 30, 28, 27, 26, 25, 24, 23, 22, 21, 18, 17, 16, 15)$.\nWe calculate the window means sequentially:\n$M_1 = \\frac{1}{4}(31+30+29+30) = \\frac{120}{4} = 30.0 \\ge 20$.\n$M_2 = \\frac{1}{4}(30+29+30+28) = \\frac{117}{4} = 29.25 \\ge 20$.\n$M_3 = \\frac{1}{4}(29+30+28+27) = \\frac{114}{4} = 28.5 \\ge 20$.\n$M_4 = \\frac{1}{4}(30+28+27+26) = \\frac{111}{4} = 27.75 \\ge 20$.\n$M_5 = \\frac{1}{4}(28+27+26+25) = \\frac{106}{4} = 26.5 \\ge 20$.\n$M_6 = \\frac{1}{4}(27+26+25+24) = \\frac{102}{4} = 25.5 \\ge 20$.\n$M_7 = \\frac{1}{4}(26+25+24+23) = \\frac{98}{4} = 24.5 \\ge 20$.\n$M_8 = \\frac{1}{4}(25+24+23+22) = \\frac{94}{4} = 23.5 \\ge 20$.\n$M_9 = \\frac{1}{4}(24+23+22+21) = \\frac{90}{4} = 22.5 \\ge 20$.\n$M_{10} = \\frac{1}{4}(23+22+21+18) = \\frac{84}{4} = 21.0 \\ge 20$.\n$M_{11} = \\frac{1}{4}(22+21+18+17) = \\frac{78}{4} = 19.5  20$.\nThe smallest index for which the mean is less than $20$ is $k=11$. The read is trimmed by retaining bases $1$ through $k-1 = 10$. The number of retained bases is $10$.\n\nRead $2$: $Q^{(2)} = (25, 24, 23, 15, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29)$.\n$M_1 = \\frac{1}{4}(25+24+23+15) = \\frac{87}{4} = 21.75 \\ge 20$.\n$M_2 = \\frac{1}{4}(24+23+15+16) = \\frac{78}{4} = 19.5  20$.\nThe smallest index is $k=2$. The read is trimmed by retaining bases $1$ through $k-1=1$. The number of retained bases is $1$.\n\nRead $3$: $Q^{(3)} = (28, 29, 30, 31, 27, 26, 25, 24, 23, 22, 21, 20, 20, 21, 22, 23)$.\n$M_1 = \\frac{1}{4}(28+29+30+31) = \\frac{118}{4} = 29.5 \\ge 20$.\n$M_2 = \\frac{1}{4}(29+30+31+27) = \\frac{117}{4} = 29.25 \\ge 20$.\n$M_3 = \\frac{1}{4}(30+31+27+26) = \\frac{114}{4} = 28.5 \\ge 20$.\n... (continuing this process) ...\n$M_9 = \\frac{1}{4}(23+22+21+20) = \\frac{86}{4} = 21.5 \\ge 20$.\n$M_{10} = \\frac{1}{4}(22+21+20+20) = \\frac{83}{4} = 20.75 \\ge 20$.\n$M_{11} = \\frac{1}{4}(21+20+20+21) = \\frac{82}{4} = 20.5 \\ge 20$.\n$M_{12} = \\frac{1}{4}(20+20+21+22) = \\frac{83}{4} = 20.75 \\ge 20$.\n$M_{13} = \\frac{1}{4}(20+21+22+23) = \\frac{86}{4} = 21.5 \\ge 20$.\nAll possible window means are greater than or equal to $20$. No trimming occurs. The entire read is retained. The number of retained bases is $n=16$.\n\nRead $4$: $Q^{(4)} = (35, 34, 10, 10, 10, 10, 10, 10, 30, 30, 30, 30, 30, 30, 30, 30)$.\n$M_1 = \\frac{1}{4}(35+34+10+10) = \\frac{89}{4} = 22.25 \\ge 20$.\n$M_2 = \\frac{1}{4}(34+10+10+10) = \\frac{64}{4} = 16  20$.\nThe smallest index is $k=2$. The read is trimmed by retaining bases $1$ through $k-1=1$. The number of retained bases is $1$.\n\nRead $5$: $Q^{(5)} = (20, 20, 20, 20, 20, 19, 19, 19, 19, 18, 18, 18, 21, 22, 23, 24)$.\n$M_1 = \\frac{1}{4}(20+20+20+20) = \\frac{80}{4} = 20.0 \\ge 20$.\n$M_2 = \\frac{1}{4}(20+20+20+20) = \\frac{80}{4} = 20.0 \\ge 20$.\n$M_3 = \\frac{1}{4}(20+20+20+19) = \\frac{79}{4} = 19.75  20$.\nThe smallest index is $k=3$. The read is trimmed by retaining bases $1$ through $k-1=2$. The number of retained bases is $2$.\n\nThe number of bases retained for each of the five reads are $10, 1, 16, 1, 2$. This is collated into a single row matrix.", "answer": "$$ \\boxed{ \\begin{pmatrix} 10  1  16  1  2 \\end{pmatrix} } $$", "id": "4590261"}, {"introduction": "Modern quantitative sequencing experiments require distinguishing true biological signals from artifacts of library amplification. This advanced practice [@problem_id:4590260] tackles this challenge by using Unique Molecular Identifiers (UMIs), which tag individual molecules before amplification. You will first implement an error-aware deduplication algorithm to merge UMIs that are likely variants due to sequencing errors, and then apply a statistical occupancy model to correct for random UMI collisions. This exercise integrates algorithmic and statistical skills to perform a sophisticated quantification essential for applications like digital gene expression analysis.", "problem": "You are given multiple sets of Next-Generation Sequencing (NGS) alignments annotated with Unique Molecular Identifiers (UMIs). The objective is two-fold: first, perform error-aware UMI deduplication using a Hamming-distance threshold of $1$ to estimate the number of unique molecules per locus; second, adjust these counts to estimate and correct for UMI collisions based on an occupancy model derived from first principles. All UMIs are of equal length and consist of characters from the Deoxyribonucleic Acid (DNA) alphabet $\\{A, C, G, T\\}$.\n\nDefinitions and assumptions to use:\n- The Hamming distance $d(u, v)$ between two UMIs $u$ and $v$ of equal length is the number of positions at which the corresponding symbols differ.\n- Error correction is performed within each locus by merging lower-abundance UMIs into higher-abundance UMIs if $d(u, v) \\leq 1$. Specifically, construct a directed graph where each UMI $u$ has a directed edge to UMI $v$ if $d(u, v) \\leq 1$ and the count $c(v)  c(u)$. Iteratively merge each UMI $u$ into its neighbor $v$ with the maximal count among neighbors satisfying those conditions (breaking ties lexicographically), updating counts and continuing until no merges are possible. The final number of nodes remaining is the deduplicated unique molecule count $K$ for that locus.\n- The UMI design space size $M$ for UMIs of length $L$ over the DNA alphabet size $A = 4$ is $M = A^{L} = 4^{L}$.\n- To adjust for UMI collisions, assume that each of the $N$ underlying molecules independently and uniformly selects a UMI from the $M$-sized design space. Under this assumption, derive $N$ from the observed $K$ using the occupancy model. Express the adjusted molecule estimate $\\hat{N}$ as a float rounded to $3$ decimal places. If $K = 0$, define $\\hat{N} = 0$.\n\nYour task is to implement a program that, given the following test suite, performs the above steps for each case and outputs the results in the specified format.\n\nTest suite parameterization:\nFor each test case, you are given the UMI length $L$, the edit-distance threshold $t$ (always $1$), and a list of UMI strings with integer counts. All UMIs listed belong to a single locus for that case.\n\n- Case $1$:\n  - $L = 8$, $t = 1$\n  - UMIs and counts:\n    - $\\texttt{ACGTACGT}$ with count $12$\n    - $\\texttt{ACGTACGA}$ with count $2$\n    - $\\texttt{ACGTTCGT}$ with count $1$\n    - $\\texttt{ACGTACGG}$ with count $1$\n    - $\\texttt{TCGTACGT}$ with count $1$\n\n- Case $2$:\n  - $L = 10$, $t = 1$\n  - UMIs and counts:\n    - $\\texttt{AAAAAGGGGG}$ with count $5$\n    - $\\texttt{TTTTTCCCCC}$ with count $4$\n    - $\\texttt{GGGGGAAAAA}$ with count $3$\n\n- Case $3$:\n  - $L = 2$, $t = 1$\n  - UMIs and counts ($15$ distinct UMIs, each with count $1$):\n    - $\\texttt{AA}$, $\\texttt{AC}$, $\\texttt{AG}$, $\\texttt{AT}$, $\\texttt{CA}$, $\\texttt{CC}$, $\\texttt{CG}$, $\\texttt{CT}$, $\\texttt{GA}$, $\\texttt{GC}$, $\\texttt{GG}$, $\\texttt{GT}$, $\\texttt{TA}$, $\\texttt{TC}$, $\\texttt{TG}$\n\n- Case $4$:\n  - $L = 6$, $t = 1$\n  - UMIs and counts:\n    - $\\texttt{AAAAAA}$ with count $20$\n    - $\\texttt{AAAATA}$ with count $1$\n    - $\\texttt{AAAAAG}$ with count $1$\n    - $\\texttt{CCCCCC}$ with count $18$\n    - $\\texttt{CCCACC}$ with count $2$\n    - $\\texttt{CCCCCG}$ with count $1$\n\n- Case $5$:\n  - $L = 8$, $t = 1$\n  - UMIs and counts:\n    - $\\texttt{GATTACAA}$ with count $3$\n    - $\\texttt{GATTACAT}$ with count $3$\n    - $\\texttt{CTTTACAA}$ with count $1$\n    - $\\texttt{TGCCGGTT}$ with count $10$\n    - $\\texttt{TGCCGGTA}$ with count $1$\n    - $\\texttt{AAAAAAAT}$ with count $1$\n    - $\\texttt{TTTTTTTT}$ with count $1$\n\nProgram requirements:\n- For each case, compute the deduplicated unique molecule count $K$ using the specified directional adjacency merging rule with $t = 1$.\n- Compute the UMI space size $M = 4^{L}$.\n- Derive the collision-adjusted molecule estimate $\\hat{N}$ from first principles of the occupancy model and report it rounded to $3$ decimal places. Use the unitless count domain; no physical units are involved.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each result is a two-element list $[K, \\hat{N}]$. For example, the output format must be exactly like $[[K_1,\\hat{N}_1],[K_2,\\hat{N}_2],\\dots]$ with no additional text.", "solution": "The problem statement has been analyzed and is determined to be valid. It is scientifically sound, well-posed, objective, and contains all necessary information to derive a unique, verifiable solution. The problem involves two standard procedures in bioinformatics: error-aware UMI deduplication and statistical correction for UMI collisions, both of which are grounded in established algorithmic and statistical principles.\n\nThe solution is partitioned into two principal stages for each test case:\n1.  Error-aware UMI deduplication to determine the observed number of unique molecules, $K$.\n2.  Statistical estimation of the true number of unique molecules, $\\hat{N}$, to correct for UMI collisions.\n\n### Part 1: UMI Deduplication via Directional Merging\n\nThe goal of this stage is to consolidate UMIs that are likely variants of a parent UMI due to sequencing errors. The problem defines a specific, deterministic algorithm for this process, which can be conceptualized as a directed graph problem.\n\nLet the set of unique UMIs at a given locus be $U = \\{u_1, u_2, \\dots, u_p\\}$, with associated counts $\\{c(u_1), c(u_2), \\dots, c(p)\\}$. The deduplication procedure is as follows:\n\n1.  **Graph Representation**: We can imagine a directed graph where each UMI is a node. A directed edge exists from node $u$ to node $v$ if and only if two conditions are met:\n    - The Hamming distance is minimal: $d(u, v) \\leq 1$. Given that $u \\neq v$, this is equivalent to $d(u, v) = 1$.\n    - The read count of the target UMI is strictly greater than the source UMI: $c(v)  c(u)$.\n\n2.  **Iterative Merging**: The process is iterative. In each pass, we identify UMIs that can be merged. A UMI $u$ is merged into a UMI $v$ if an edge exists from $u$ to $v$. The problem specifies a resolution strategy for cases where a UMI $u$ could be merged into multiple other UMIs:\n    - The target UMI $v$ must have the maximal count among all possible targets for $u$.\n    - If a tie in maximal counts occurs (i.e., multiple potential targets have the same highest count), the tie is broken by choosing the target UMI that is lexicographically smallest.\n\n3.  **Algorithmic Implementation**: To implement this deterministically, a systematic approach is required. The process continues until no more merges are possible in a full pass over the remaining UMIs.\n    - We maintain a dictionary of UMI strings to their integer counts.\n    - We loop until a pass completes with no merges. In each pass:\n        a. We create a sorted list of the current UMIs, ordered first by count (ascending) and second by the UMI string itself (lexicographically ascending). This ensures we always attempt to merge lower-abundance UMIs into higher-abundance ones in a consistent order.\n        b. For each UMI $u$ with count $c(u)$ in this sorted list, we identify a set of valid merge targets $\\{v_1, v_2, \\dots\\}$. A UMI $v_j$ is a valid target if $d(u, v_j) = 1$ and $c(v_j)  c(u)$.\n        c. If the set of targets is non-empty, we select the single best target $v_{best}$. This is done by finding the maximum count among all targets, and then selecting the lexicographically smallest UMI among those with the maximum count.\n        d. If a $v_{best}$ is found, we perform the merge: the count of $u$ is added to the count of $v_{best}$, and $u$ is removed from our set of UMIs. The pass is then immediately restarted (by breaking the inner loop and continuing the outer loop) because the change in counts can affect subsequent potential merges.\n        e. If a full pass over all UMIs results in no merges, the process terminates.\n\n4.  **Final Count**: The number of UMIs remaining at the end of this iterative process is the deduplicated unique molecule count, $K$.\n\n### Part 2: Collision Correction using an Occupancy Model\n\nThe second stage corrects for the possibility that two or more distinct initial molecules were, by chance, labeled with the same UMI. This is a classic statistical problem known as the occupancy problem or \"balls-into-bins\".\n\n1.  **Model Formulation**:\n    - Let $N$ be the true, unknown number of unique molecules (the \"balls\").\n    - Let $M$ be the total size of the UMI design space (the \"bins\"). For a UMI of length $L$ and an alphabet of size $A=4$ (for DNA), $M = A^L = 4^L$.\n    - We assume each of the $N$ molecules independently and uniformly selects one of the $M$ possible UMIs.\n    - We observe $K$ distinct UMIs after error correction (the number of \"occupied bins\").\n\n2.  **Derivation of the Estimator**: We can estimate $N$ by relating it to the expected value of $K$.\n    - The probability that a specific UMI (bin) is *not* chosen by a single molecule is $(1 - 1/M)$.\n    - The probability that this specific UMI is not chosen by any of the $N$ molecules is $(1 - 1/M)^N$.\n    - This is the probability that the bin is empty. By linearity of expectation, the expected number of empty bins is $E[\\text{empty bins}] = M \\cdot (1 - 1/M)^N$.\n    - The expected number of occupied bins, $E[K]$, is the total number of bins minus the expected number of empty bins:\n    $$E[K] = M - M \\left(1 - \\frac{1}{M}\\right)^N = M \\left[1 - \\left(1 - \\frac{1}{M}\\right)^N\\right]$$\n    - To find our estimator $\\hat{N}$, we apply the method of moments by setting the observed value $K$ equal to its expectation and solving for $N$:\n    $$K = M \\left[1 - \\left(1 - \\frac{1}{M}\\right)^{\\hat{N}}\\right]$$\n    - Rearranging the terms to solve for $\\hat{N}$:\n    $$\\frac{K}{M} = 1 - \\left(1 - \\frac{1}{M}\\right)^{\\hat{N}}$$\n    $$\\left(1 - \\frac{1}{M}\\right)^{\\hat{N}} = 1 - \\frac{K}{M}$$\n    - Taking the natural logarithm of both sides:\n    $$\\hat{N} \\ln\\left(1 - \\frac{1}{M}\\right) = \\ln\\left(1 - \\frac{K}{M}\\right)$$\n    - Finally, we arrive at the estimator for $N$:\n    $$\\hat{N} = \\frac{\\ln\\left(1 - \\frac{K}{M}\\right)}{\\ln\\left(1 - \\frac{1}{M}\\right)}$$\n\n3.  **Special Cases**:\n    - If $K=0$, the problem defines $\\hat{N}=0$, which is consistent with the formula as $\\ln(1)=0$.\n    - If $K \\geq M$, the argument to the numerator's logarithm, $(1-K/M)$, becomes non-positive, and the formula is undefined or yields a non-real result in this domain. This scenario, where more unique UMIs are observed than are possible, should not occur in a valid application of this model but would imply an extremely large or infinite number of original molecules. The provided test cases do not exhibit this property.\n\nThe final estimate $\\hat{N}$ is calculated using this formula and rounded to $3$ decimal places as required. The overall procedure combines these two parts to produce a pair $[K, \\hat{N}]$ for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the UMI deduplication and collision correction for all test cases.\n    \"\"\"\n    \n    def hamming_distance(s1, s2):\n        \"\"\"Calculates the Hamming distance between two strings of equal length.\"\"\"\n        # The problem context implies strings are of equal length.\n        # No explicit check is added here for performance, relying on correct input.\n        return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n\n    def solve_deduplication(umi_counts):\n        \"\"\"\n        Performs iterative, directional UMI merging based on count and Hamming distance.\n\n        Args:\n            umi_counts (dict): A dictionary mapping UMI strings to their counts.\n\n        Returns:\n            int: The number of unique UMIs (K) after deduplication.\n        \"\"\"\n        current_umis = umi_counts.copy()\n\n        while True:\n            merged_in_pass = False\n            # Sort UMIs to process: by count ascending, then UMI string ascending.\n            # This ensures we always try to merge smaller groups into larger ones\n            # in a deterministic order.\n            sorted_umis_to_process = sorted(current_umis.items(), key=lambda item: (item[1], item[0]))\n\n            for umi_u, count_u in sorted_umis_to_process:\n                # If umi_u was already merged in this pass, its key will be gone.\n                if umi_u not in current_umis:\n                    continue\n\n                potential_targets = []\n                for umi_v, count_v in current_umis.items():\n                    if umi_u == umi_v:\n                        continue\n                    \n                    # Conditions for merging: d=1 and target count is strictly greater.\n                    if count_v  count_u and hamming_distance(umi_u, umi_v) == 1:\n                        potential_targets.append((umi_v, count_v))\n\n                if not potential_targets:\n                    continue\n                \n                # Find the best target: max count, then lexicographically smallest UMI.\n                # Sorting by count descending (-item[1]) and UMI string ascending (item[0]).\n                potential_targets.sort(key=lambda item: (-item[1], item[0]))\n                best_target_umi, _ = potential_targets[0]\n\n                # Perform the merge.\n                current_umis[best_target_umi] += current_umis[umi_u]\n                del current_umis[umi_u]\n                \n                merged_in_pass = True\n                # Restart the pass because counts have changed, which can affect\n                # subsequent merge decisions.\n                break\n            \n            if not merged_in_pass:\n                break\n        \n        return len(current_umis)\n\n    def solve_collision_correction(K, M):\n        \"\"\"\n        Estimates the true number of molecules (N_hat) from the observed\n        number (K) and the UMI space size (M).\n\n        Args:\n            K (int): The observed number of unique UMIs.\n            M (int): The total size of the UMI design space.\n\n        Returns:\n            float: The estimated true number of molecules, N_hat, rounded to 3 decimal places.\n        \"\"\"\n        if K == 0:\n            return 0.0\n        \n        # The formula is undefined if K = M. This case is not expected in the\n        # provided test suite. For K=M, N would be infinite.\n        if K = M:\n             return float('inf')\n\n        # Formula: N_hat = ln(1 - K/M) / ln(1 - 1/M)\n        n_hat = np.log(1 - K / M) / np.log(1 - 1 / M)\n        return round(n_hat, 3)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (8, {\n            'ACGTACGT': 12, 'ACGTACGA': 2, 'ACGTTCGT': 1, 'ACGTACGG': 1, 'TCGTACGT': 1\n        }),\n        (10, {\n            'AAAAAGGGGG': 5, 'TTTTTCCCCC': 4, 'GGGGGAAAAA': 3\n        }),\n        (2, dict.fromkeys([\n            'AA', 'AC', 'AG', 'AT', 'CA', 'CC', 'CG', 'CT',\n            'GA', 'GC', 'GG', 'GT', 'TA', 'TC', 'TG'\n        ], 1)),\n        (6, {\n            'AAAAAA': 20, 'AAAATA': 1, 'AAAAAG': 1, 'CCCCCC': 18, 'CCCACC': 2, 'CCCCCG': 1\n        }),\n        (8, {\n            'GATTACAA': 3, 'GATTACAT': 3, 'CTTTACAA': 1, 'TGCCGGTT': 10, 'TGCCGGTA': 1,\n            'AAAAAAAT': 1, 'TTTTTTTT': 1\n        })\n    ]\n\n    final_results = []\n    for L, umi_counts in test_cases:\n        K = solve_deduplication(umi_counts)\n        M = 4**L\n        N_hat = solve_collision_correction(K, M)\n        # Format N_hat to ensure three decimal places in the output string.\n        final_results.append(f\"[{K},{N_hat:.3f}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(final_results)}]\")\n\nsolve()\n```", "id": "4590260"}]}