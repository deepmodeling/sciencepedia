{"hands_on_practices": [{"introduction": "Raw biological data is rarely pristine, and protein interaction datasets are no exception. This first practice simulates the crucial initial step in any network analysis pipeline: data curation. You will implement a workflow to standardize protein identifiers and convert a raw edge list into a simple, undirected graph, which is the foundational representation for most downstream analyses [@problem_id:4602326].", "problem": "You are given the task of implementing a deterministic post-processing workflow for a protein–protein interaction (PPI) network that enforces the semantics of a simple undirected graph consistent with standard curation practice in bioinformatics and medical data analytics. Nodes represent proteins by identifiers (strings), and edges represent physical interactions. The workflow must perform identifier normalization on all edge endpoints, then remove self-loops and deduplicate symmetric edges, and finally quantify the changes in counts induced by these operations.\n\nFoundational base and definitions to use:\n- A PPI network is modeled as a simple undirected graph with vertex set $V$ and edge set $E \\subseteq \\{\\{u,v\\} \\mid u,v \\in V, u \\neq v\\}$; therefore, self-loops are excluded and symmetric duplicates represent the same interaction.\n- Identifier normalization is required because multiple strings may denote the same protein. Normalization maps raw endpoint strings to canonical identifiers in a reproducible manner.\n- The edge list supplied to the workflow may contain directed duplicates, symmetric duplicates, and self-loops prior to post-processing. The initial list of edges is a multiset of ordered pairs of strings.\n\nSpecification of the normalization function:\n- For any raw node label $x$ (a string), define a canonicalization function $C(x)$ as $C(x) = A(U(T(x)))$ where:\n  - $T$ removes leading and trailing whitespace from $x$.\n  - $U$ converts the result of $T(x)$ to uppercase using a deterministic locale-independent rule.\n  - $A$ is a provided alias map (a dictionary) that maps certain uppercase strings to canonical uppercase identifiers; if an uppercase string is not a key in the alias map, it maps to itself.\n- The alias map is total via the identity rule described above. It is provided per test case.\n\nProcessing pipeline to implement:\n- Step $1$ (Normalization): Map every input edge $(u,v)$ to $(C(u), C(v))$. Let the multiset of normalized edges be $E_{\\mathrm{norm}}$ and its size be $|E_{\\mathrm{norm}}|$. Let the set of unique node identifiers observed in $E_{\\mathrm{norm}}$ be $V_{\\mathrm{norm}}$ with size $|V_{\\mathrm{norm}}|$.\n- Step $2$ (Simple graph reduction): From $E_{\\mathrm{norm}}$, remove all edges $(w,w)$ with $w \\in V_{\\mathrm{norm}}$ (self-loops). For each remaining $(a,b)$ with $a \\neq b$, treat $(a,b)$ and $(b,a)$ as the same undirected interaction and deduplicate them by representing each as the unordered pair $\\{a,b\\}$. Let the resulting undirected edge set be $E_{\\mathrm{after}}$ with size $|E_{\\mathrm{after}}|$. Let the set of nodes incident to at least one edge in $E_{\\mathrm{after}}$ be $V_{\\mathrm{after}}$ with size $|V_{\\mathrm{after}}|$.\n- Report the pair of integer changes $(\\Delta E, \\Delta V)$ defined by $\\Delta E = |E_{\\mathrm{after}}| - |E_{\\mathrm{norm}}|$ and $\\Delta V = |V_{\\mathrm{after}}| - |V_{\\mathrm{norm}}|$.\n\nYour program must implement this pipeline and apply it to the following test suite. Each test case provides an edge list and an alias map. Each edge is an ordered pair of strings, and each alias map is a dictionary from uppercase strings to uppercase canonical strings.\n\nTest suite:\n- Test case $1$:\n  - Edges: [(\"TP53\",\"MDM2\"), (\"mdm2\",\" tp53 \"), (\"TP53\",\"TP53\"), (\"EGFR\",\"GRB2\"), (\"grb2\",\"egfr\")]\n  - Alias map: {}\n- Test case $2$:\n  - Edges: [(\"IL6\",\"gp130\"), (\"IL-6\",\"IL6R\"), (\"il6\",\"IL6\"), (\"GP130\",\"IL6R\")]\n  - Alias map: {\"GP130\":\"IL6ST\", \"IL-6\":\"IL6\"}\n- Test case $3$:\n  - Edges: [(\"p53\",\"tp53\"), (\"TP53\",\" P53 \"), (\"tumor protein p53\",\"TP53\")]\n  - Alias map: {\"P53\":\"TP53\", \"TUMOR PROTEIN P53\":\"TP53\"}\n- Test case $4$:\n  - Edges: []\n  - Alias map: {}\n- Test case $5$:\n  - Edges: [(\"AKT1\",\"MTOR\"), (\"akt1\",\"mtor\"), (\"MTOR\",\"AKT1\"), (\"AKT1\",\"AKT1\")]\n  - Alias map: {}\n- Test case $6$:\n  - Edges: [(\"Mapk1\",\"ERK2\"), (\"ERK1\",\"MAPK3\"), (\"MAPK1\",\"ERK1\"), (\"ERK2\",\" MAPK3 \")]\n  - Alias map: {\"ERK2\":\"MAPK1\", \"ERK1\":\"MAPK3\"}\n\nRequirements:\n- Treat all edges as described, starting from the multiset of provided ordered pairs.\n- Apply $C(\\cdot)$ exactly as specified.\n- Compute $(\\Delta E, \\Delta V)$ for each test case, where all counts are integers.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a two-element list representing $[\\Delta E,\\Delta V]$ for the corresponding test case, in order. For example, a valid output for three cases would look like \"[[a,b],[c,d],[e,f]]\" with integers and no spaces. There are no physical units or angles involved; all outputs are pure integers.", "solution": "The problem statement has been rigorously validated and is deemed to be scientifically grounded, well-posed, and objective. It describes a standard data processing workflow in bioinformatics for curating protein-protein interaction (PPI) networks. The specifications are complete, consistent, and formalizable into an algorithm. Therefore, a complete solution is presented.\n\nThe core task is to implement a deterministic pipeline to transform a raw list of protein-protein interactions into a simple, undirected graph. This process, common in bioinformatics data curation, involves standardizing identifiers and removing redundancies. The effect of this curation is then quantified by comparing the initial and final counts of nodes (proteins) and edges (interactions).\n\nThe solution is structured according to the specified pipeline.\n\n**$1$. Identifier Normalization**\n\nIn biological databases, the same protein can be referred to by multiple identifiers (e.g., gene names, UniProt accessions, common aliases). To ensure data integrity and enable correct network analysis, these raw identifiers must be mapped to a single canonical form. The problem defines a three-step canonicalization function, $C(x) = A(U(T(x)))$, for any given raw identifier string $x$.\n\n-   **$T(x)$**: This function removes any leading or trailing whitespace from the string $x$. This step handles common formatting inconsistencies.\n-   **$U(T(x))$**: This function converts the resulting string to uppercase using a deterministic, locale-independent rule. This neutralizes case-sensitivity, another source of spurious variation.\n-   **$A(U(T(x)))$**: This function applies a provided alias map, $A$. The map is a dictionary that resolves known aliases to their canonical identifiers. If an identifier is not a key in the map, it is considered canonical and maps to itself (the identity rule).\n\nThis function $C(x)$ is applied to both endpoints of every edge $(u,v)$ in the initial list, producing a multiset of normalized edges, denoted $E_{\\mathrm{norm}}$.\n\n**$2$. Baseline Network Metrics**\n\nBefore cleaning the network structure, we establish baseline counts.\n\n-   **Edge Count $|E_{\\mathrm{norm}}|$**: The problem specifies that the initial edge count, $|E_{\\mathrm{norm}}|$, is the size of the multiset of edges provided as input. This corresponds to the total number of interaction records before any processing.\n-   **Node Count $|V_{\\mathrm{norm}}|$**: After normalizing all identifiers, the set of unique canonical protein identifiers, $V_{\\mathrm{norm}}$, is extracted from the normalized edge list $E_{\\mathrm{norm}}$. Its cardinality, $|V_{\\mathrm{norm}}|$, represents the total number of distinct proteins in the dataset before graph-based cleaning.\n\n**$3$. Simple Graph Reduction**\n\nThe standard model for a PPI network is a simple undirected graph, $G=(V, E)$, where $E$ is a set of unordered pairs of distinct vertices, i.e., $E \\subseteq \\{\\{u,v\\} \\mid u,v \\in V, u \\neq v\\}$. The normalized edge list $E_{\\mathrm{norm}}$ may violate this structure by containing self-loops and duplicate edges. The reduction process enforces these constraints.\n\n-   **Removal of Self-Loops**: Interactions of a protein with itself, represented as edges $(w,w)$, are known as self-loops. While biologically meaningful in some contexts (e.g., homodimerization), they are excluded from the definition of a simple graph. Thus, all edges where the two endpoints are identical are removed from $E_{\\mathrm{norm}}$.\n-   **Deduplication of Symmetric Edges**: A physical interaction between protein $a$ and protein $b$ is an undirected relationship. Therefore, the ordered pairs $(a,b)$ and $(b,a)$ represent the same edge. To count each unique interaction only once, we convert each remaining edge $\\{a,b\\}$ with $a \\neq b$ into a canonical form (e.g., a lexicographically sorted tuple) and store them in a set data structure. This automatically handles both directed duplicates like $(a,b), (a,b)$ and symmetric duplicates like $(a,b), (b,a)$.\n\nThe resulting set of unique, undirected edges is denoted $E_{\\mathrm{after}}$, and its size is $|E_{\\mathrm{after}}|$. The set of nodes that are endpoints in these final edges is $V_{\\mathrm{after}}$, with size $|V_{\\mathrm{after}}|$.\n\n**$4$. Quantification of Change**\n\nThe final step is to quantify the changes in network size. Two metrics are calculated:\n\n-   **Change in Edge Count ($\\Delta E$)**: $\\Delta E = |E_{\\mathrm{after}}| - |E_{\\mathrm{norm}}|$. This value is typically negative, reflecting the removal of self-loops and redundant edges.\n-   **Change in Node Count ($\\Delta V$)**: $\\Delta V = |V_{\\mathrm{after}}| - |V_{\\mathrm{norm}}|$. This value can be negative if some proteins were only involved in self-loops, which are subsequently removed. If a protein only appeared in self-loops and nowhere else, it will be in $V_{\\mathrm{norm}}$ but not in $V_{\\mathrm{after}}$.\n\nThese quantities, $(\\Delta E, \\Delta V)$, summarize the impact of the curation workflow on the network's topology.\n\n**Algorithmic Implementation**\n\nThe pipeline is implemented using standard data structures. The input edge list is processed to produce the multiset $E_{\\mathrm{norm}}$. The set $V_{\\mathrm{norm}}$ is generated by iterating through $E_{\\mathrm{norm}}$ and adding nodes to a Python `set`. For the reduction, a new `set` is used to store canonical representations of the undirected edges (e.g., sorted tuples), which efficiently filters out self-loops and all types of duplicates. The final node set $V_{\\mathrm{after}}$ is constructed from this final edge set. The counts are obtained using `len()` on the lists and sets, and the deltas are computed via subtraction.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Implements the full PPI network processing pipeline and prints the results\n    for the entire test suite.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1\n        {\n            \"edges\": [(\"TP53\",\"MDM2\"), (\"mdm2\",\" tp53 \"), (\"TP53\",\"TP53\"), (\"EGFR\",\"GRB2\"), (\"grb2\",\"egfr\")],\n            \"alias_map\": {}\n        },\n        # Test case 2\n        {\n            \"edges\": [(\"IL6\",\"gp130\"), (\"IL-6\",\"IL6R\"), (\"il6\",\"IL6\"), (\"GP130\",\"IL6R\")],\n            \"alias_map\": {\"GP130\":\"IL6ST\", \"IL-6\":\"IL6\"}\n        },\n        # Test case 3\n        {\n            \"edges\": [(\"p53\",\"tp53\"), (\"TP53\",\" P53 \"), (\"tumor protein p53\",\"TP53\")],\n            \"alias_map\": {\"P53\":\"TP53\", \"TUMOR PROTEIN P53\":\"TP53\"}\n        },\n        # Test case 4\n        {\n            \"edges\": [],\n            \"alias_map\": {}\n        },\n        # Test case 5\n        {\n            \"edges\": [(\"AKT1\",\"MTOR\"), (\"akt1\",\"mtor\"), (\"MTOR\",\"AKT1\"), (\"AKT1\",\"AKT1\")],\n            \"alias_map\": {}\n        },\n        # Test case 6\n        {\n            \"edges\": [(\"Mapk1\",\"ERK2\"), (\"ERK1\",\"MAPK3\"), (\"MAPK1\",\"ERK1\"), (\"ERK2\",\" MAPK3 \")],\n            \"alias_map\": {\"ERK2\":\"MAPK1\", \"ERK1\":\"MAPK3\"}\n        }\n    ]\n\n    def process_network(edges, alias_map):\n        \"\"\"\n        Processes a single PPI network case according to the specified pipeline.\n\n        Args:\n            edges (list): A list of tuples, representing the raw edge list.\n            alias_map (dict): A dictionary for normalizing protein identifiers.\n\n        Returns:\n            list: A two-element list containing [delta_e, delta_v].\n        \"\"\"\n        # |E_norm| is the size of the initial multiset of edges.\n        count_e_norm = len(edges)\n\n        def canonical_id(raw_id, aliases):\n            # C(x) = A(U(T(x)))\n            stripped_id = raw_id.strip()\n            upper_id = stripped_id.upper()\n            return aliases.get(upper_id, upper_id)\n\n        # Step 1: Normalization and baseline counts\n        E_norm = []\n        V_norm_set = set()\n        for u, v in edges:\n            norm_u = canonical_id(u, alias_map)\n            norm_v = canonical_id(v, alias_map)\n            E_norm.append((norm_u, norm_v))\n            V_norm_set.add(norm_u)\n            V_norm_set.add(norm_v)\n        \n        count_v_norm = len(V_norm_set)\n\n        # Step 2: Simple graph reduction\n        E_after_set = set()\n        for u, v in E_norm:\n            # Exclude self-loops\n            if u != v:\n                # Create a canonical representation for the undirected edge\n                # by sorting the identifiers lexicographically.\n                canonical_edge = tuple(sorted((u, v)))\n                E_after_set.add(canonical_edge)\n        \n        count_e_after = len(E_after_set)\n\n        # V_after is the set of nodes incident to edges in E_after.\n        V_after_set = set()\n        for u, v in E_after_set:\n            V_after_set.add(u)\n            V_after_set.add(v)\n        \n        count_v_after = len(V_after_set)\n\n        # Step 3: Quantification\n        delta_e = count_e_after - count_e_norm\n        delta_v = count_v_after - count_v_norm\n\n        return [delta_e, delta_v]\n\n    results = []\n    for case in test_cases:\n        result = process_network(case[\"edges\"], case[\"alias_map\"])\n        results.append(result)\n\n    # Final print statement in the exact required format: [[a,b],[c,d]]\n    # str() produces spaces (e.g., '[-3, 0]'), which must be removed.\n    output_str = str(results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```", "id": "4602326"}, {"introduction": "With a clean network, we can begin to uncover its biological meaning by analyzing its structure. This exercise focuses on calculating the local clustering coefficient, a key metric that quantifies how tightly connected a protein's neighbors are. Applying this measure helps in identifying dense subgraphs, which often correspond to functional modules or stable protein complexes in a cell [@problem_id:4602288].", "problem": "A Protein–Protein Interaction (PPI) network models physical binding relationships among proteins as an undirected, simple graph, where vertices represent proteins and edges represent interactions. Let the network be represented by the adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$ with $n=7$, where $A_{ij}=1$ denotes a putative direct interaction between proteins $i$ and $j$, and $A_{ii}=0$. The adjacency matrix is\n$$\nA=\\begin{pmatrix}\n0 & 1 & 1 & 1 & 0 & 0 & 0 \\\\\n1 & 0 & 1 & 1 & 0 & 0 & 0 \\\\\n1 & 1 & 0 & 1 & 1 & 0 & 0 \\\\\n1 & 1 & 1 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 1 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 1 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0\n\\end{pmatrix}.\n$$\nIn network transitivity analysis, a three-protein complex is operationally captured by a triangle, namely a set of three vertices with all three pairwise edges present. The local transitivity (also called the local clustering coefficient) at a vertex $i$, denoted $C_i$, is defined as the fraction of unordered pairs among the neighbors of $i$ that are themselves joined by an edge. For vertices with fewer than two neighbors, set $C_i=0$ by convention.\n\nTasks:\n1. Using only the operational definitions above and the provided matrix $A$, compute $C_i$ for each vertex $i \\in \\{1,2,\\dots,7\\}$.\n2. For the threshold $\\tau=\\frac{2}{3}$, form the induced subgraph on the vertex set $\\{\\,i : C_i \\ge \\tau\\,\\}$ and determine its connected components. Identify the largest connected component by vertex count.\n3. Report as your final answer the arithmetic mean of $C_i$ over the vertices in that largest high-transitivity component. Provide the final answer as an exact rational number without rounding or units.", "solution": "The problem is valid as it is scientifically grounded in standard graph theory and its application in bioinformatics, is well-posed with all necessary information provided, and is formulated objectively. We proceed with the solution.\n\nThe problem asks for a three-part analysis of a Protein–Protein Interaction (PPI) network represented by a given adjacency matrix $A$. The network has $n=7$ vertices (proteins). The adjacency matrix is given by:\n$$\nA=\\begin{pmatrix}\n0 & 1 & 1 & 1 & 0 & 0 & 0 \\\\\n1 & 0 & 1 & 1 & 0 & 0 & 0 \\\\\n1 & 1 & 0 & 1 & 1 & 0 & 0 \\\\\n1 & 1 & 1 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 1 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 1 & 0 & 1 \\\\\n0 & 0 & 0 & 0 & 0 & 1 & 0\n\\end{pmatrix}\n$$\nwhere $A_{ij}=1$ if there is an interaction between protein $i$ and protein $j$.\n\n**Task 1: Compute the local clustering coefficient $C_i$ for each vertex $i$.**\n\nThe local clustering coefficient $C_i$ for a vertex $i$ is defined as the fraction of possible edges between the neighbors of $i$ that actually exist. If $k_i$ is the degree of vertex $i$ (i.e., its number of neighbors), and $E_i$ is the number of edges between the neighbors of $i$, then $C_i$ is given by:\n$$\nC_i = \\frac{E_i}{\\binom{k_i}{2}} = \\frac{2E_i}{k_i(k_i - 1)}\n$$\nBy convention, if $k_i < 2$, $C_i=0$. Let $N(i)$ be the set of neighbors of vertex $i$. $k_i = |N(i)|$ is the sum of the entries in row $i$ of $A$. $E_i$ is the number of pairs of vertices $\\{j, k\\}$ such that $j, k \\in N(i)$ and $A_{jk}=1$.\n\nLet's compute $C_i$ for each vertex $i \\in \\{1, 2, \\dots, 7\\}$.\n\n- **Vertex 1:** From row $1$ of $A$, $N(1) = \\{2, 3, 4\\}$. The degree is $k_1 = 3$. The possible pairs of neighbors are $\\{2,3\\}, \\{2,4\\}, \\{3,4\\}$. We check the adjacency matrix for edges between these neighbors: $A_{23}=1$, $A_{24}=1$, and $A_{34}=1$. Thus, there are $E_1=3$ edges between the neighbors of vertex $1$.\n$$ C_1 = \\frac{3}{\\binom{3}{2}} = \\frac{3}{3} = 1 $$\n\n- **Vertex 2:** From row $2$ of $A$, $N(2) = \\{1, 3, 4\\}$. The degree is $k_2 = 3$. The pairs of neighbors are $\\{1,3\\}, \\{1,4\\}, \\{3,4\\}$. We check for edges: $A_{13}=1$, $A_{14}=1$, and $A_{34}=1$. There are $E_2=3$ edges.\n$$ C_2 = \\frac{3}{\\binom{3}{2}} = \\frac{3}{3} = 1 $$\n\n- **Vertex 3:** From row $3$ of $A$, $N(3) = \\{1, 2, 4, 5\\}$. The degree is $k_3 = 4$. There are $\\binom{4}{2}=6$ possible pairs of neighbors: $\\{1,2\\}, \\{1,4\\}, \\{1,5\\}, \\{2,4\\}, \\{2,5\\}, \\{4,5\\}$. We check for edges: $A_{12}=1$, $A_{14}=1$, $A_{15}=0$, $A_{24}=1$, $A_{25}=0$, $A_{45}=1$. The number of existing edges is $E_3 = 1+1+0+1+0+1 = 4$.\n$$ C_3 = \\frac{4}{\\binom{4}{2}} = \\frac{4}{6} = \\frac{2}{3} $$\n\n- **Vertex 4:** From row $4$ of $A$, $N(4) = \\{1, 2, 3, 5\\}$. The degree is $k_4 = 4$. The pairs of neighbors are $\\{1,2\\}, \\{1,3\\}, \\{1,5\\}, \\{2,3\\}, \\{2,5\\}, \\{3,5\\}$. We check for edges: $A_{12}=1$, $A_{13}=1$, $A_{15}=0$, $A_{23}=1$, $A_{25}=0$, $A_{35}=1$. The number of existing edges is $E_4 = 1+1+0+1+0+1=4$.\n$$ C_4 = \\frac{4}{\\binom{4}{2}} = \\frac{4}{6} = \\frac{2}{3} $$\n\n- **Vertex 5:** From row $5$ of $A$, $N(5) = \\{3, 4, 6\\}$. The degree is $k_5 = 3$. The pairs of neighbors are $\\{3,4\\}, \\{3,6\\}, \\{4,6\\}$. We check for edges: $A_{34}=1$, $A_{36}=0$, $A_{46}=0$. The number of existing edges is $E_5=1$.\n$$ C_5 = \\frac{1}{\\binom{3}{2}} = \\frac{1}{3} $$\n\n- **Vertex 6:** From row $6$ of $A$, $N(6) = \\{5, 7\\}$. The degree is $k_6 = 2$. There is one pair of neighbors, $\\{5,7\\}$. We check for an edge: $A_{57}=0$. The number of existing edges is $E_6=0$.\n$$ C_6 = \\frac{0}{\\binom{2}{2}} = \\frac{0}{1} = 0 $$\n\n- **Vertex 7:** From row $7$ of $A$, $N(7) = \\{6\\}$. The degree is $k_7 = 1$. Since $k_7 < 2$, by convention, $C_7=0$.\n\nThe computed local clustering coefficients are:\n$C_1=1$, $C_2=1$, $C_3=\\frac{2}{3}$, $C_4=\\frac{2}{3}$, $C_5=\\frac{1}{3}$, $C_6=0$, $C_7=0$.\n\n**Task 2: Find the largest connected component of the high-transitivity induced subgraph.**\n\nThe threshold is given as $\\tau = \\frac{2}{3}$. We need to form the induced subgraph on the set of vertices $V' = \\{i : C_i \\ge \\tau\\}$.\nUsing the values from Task 1:\n- $C_1 = 1 \\ge \\frac{2}{3}$\n- $C_2 = 1 \\ge \\frac{2}{3}$\n- $C_3 = \\frac{2}{3} \\ge \\frac{2}{3}$\n- $C_4 = \\frac{2}{3} \\ge \\frac{2}{3}$\n- $C_5 = \\frac{1}{3} < \\frac{2}{3}$\n- $C_6 = 0 < \\frac{2}{3}$\n- $C_7 = 0 < \\frac{2}{3}$\n\nThe vertex set for the induced subgraph is $V' = \\{1, 2, 3, 4\\}$.\nThe induced subgraph contains these four vertices and all edges from the original graph connecting any pair of them. We examine the submatrix of $A$ corresponding to rows and columns $1, 2, 3, 4$:\n$$\nA' = \\begin{pmatrix}\n0 & 1 & 1 & 1 \\\\\n1 & 0 & 1 & 1 \\\\\n1 & 1 & 0 & 1 \\\\\n1 & 1 & 1 & 0\n\\end{pmatrix}\n$$\nThis is the adjacency matrix of a complete graph on $4$ vertices, denoted $K_4$. In a complete graph, every vertex is connected to every other vertex. Therefore, the graph is connected. This induced subgraph consists of a single connected component. As there is only one component, it is trivially the largest one. The vertex set of this largest component is $\\{1, 2, 3, 4\\}$.\n\n**Task 3: Compute the arithmetic mean of $C_i$ for the vertices in the largest component.**\n\nThe vertices in the largest high-transitivity component are $\\{1, 2, 3, 4\\}$. We need to find the arithmetic mean of their corresponding $C_i$ values.\nThe values are $C_1=1$, $C_2=1$, $C_3=\\frac{2}{3}$, and $C_4=\\frac{2}{3}$.\nThe arithmetic mean, $\\bar{C}$, is calculated as:\n$$\n\\bar{C} = \\frac{1}{4} \\sum_{i \\in \\{1,2,3,4\\}} C_i = \\frac{1}{4} \\left(C_1 + C_2 + C_3 + C_4\\right)\n$$\n$$\n\\bar{C} = \\frac{1}{4} \\left(1 + 1 + \\frac{2}{3} + \\frac{2}{3}\\right)\n$$\n$$\n\\bar{C} = \\frac{1}{4} \\left(2 + \\frac{4}{3}\\right)\n$$\n$$\n\\bar{C} = \\frac{1}{4} \\left(\\frac{6}{3} + \\frac{4}{3}\\right)\n$$\n$$\n\\bar{C} = \\frac{1}{4} \\left(\\frac{10}{3}\\right)\n$$\n$$\n\\bar{C} = \\frac{10}{12} = \\frac{5}{6}\n$$\nThe arithmetic mean of the clustering coefficients for the vertices in the largest high-transitivity component is $\\frac{5}{6}$.", "answer": "$$\n\\boxed{\\frac{5}{6}}\n$$", "id": "4602288"}, {"introduction": "Beyond describing static structure, PPI networks are powerful tools for functional prediction and hypothesis generation. This advanced practice introduces the Random Walk with Restart (RWR) algorithm, a powerful method for prioritizing candidate genes based on their connectivity to known disease-associated proteins. By simulating a walker's journey through the network, you will quantify these complex relationships to identify promising new candidates for further study [@problem_id:4602350].", "problem": "Consider an undirected, weighted protein–protein interaction (PPI) network with four proteins labeled $A$, $B$, $C$, and $D$. The nonzero symmetric edge weights (interaction confidences) are: $w_{AB} = 3$, $w_{AC} = 1$, $w_{BC} = 1$, $w_{BD} = 2$, and $w_{CD} = 2$. Let the Random Walk with Restart (RWR) process be defined as follows: at each discrete time step, with probability $\\alpha = \\frac{1}{2}$ the walker restarts by sampling a seed protein according to the seed distribution $s$, and with probability $1 - \\alpha$ the walker moves to a neighboring protein according to a column-stochastic transition matrix $P$. Construct $P$ by normalizing the edge weights column-wise so that for any source node $j$, $P_{ij} = \\frac{w_{ij}}{\\sum_{k} w_{kj}}$ with $w_{jj} = 0$ and $w_{ij} = w_{ji}$. The disease seed set is $\\{A, B\\}$ with a uniform prior, so $s_A = \\frac{1}{2}$, $s_B = \\frac{1}{2}$, $s_C = 0$, and $s_D = 0$.\n\nUsing foundational principles of time-homogeneous Markov chains and the formal definition of Random Walk with Restart, derive the steady-state RWR score $r_D$ (the long-run probability of finding the walker at protein $D$) and report it as a decimal. Round your answer to five significant figures.", "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. It provides a complete and consistent set of givens to solve for the steady-state Random Walk with Restart (RWR) scores.\n\nThe RWR process is a time-homogeneous Markov chain. The probability distribution vector over the nodes at time step $t+1$, denoted by $r^{(t+1)}$, is given by the iterative equation:\n$$r^{(t+1)} = (1 - \\alpha) P r^{(t)} + \\alpha s$$\nwhere $\\alpha$ is the restart probability, $P$ is the column-stochastic transition matrix of the network, and $s$ is the seed probability distribution vector.\n\nIn the steady state, the probability distribution is constant, i.e., $r^{(t+1)} = r^{(t)} = r$. The steady-state vector $r$ therefore satisfies the equation:\n$$r = (1 - \\alpha) P r + \\alpha s$$\nThis equation can be rearranged to solve for $r$:\n$$I r - (1 - \\alpha) P r = \\alpha s$$\n$$(I - (1 - \\alpha) P) r = \\alpha s$$\nwhere $I$ is the identity matrix.\n\nThe problem provides the following parameters: a four-protein network $\\{A, B, C, D\\}$, a set of edge weights $w_{ij}$, a restart probability $\\alpha = \\frac{1}{2}$, and a seed vector $s$. Our objective is to find $r_D$, the component of $r$ corresponding to protein $D$.\n\nFirst, we construct the weighted adjacency matrix $W$, with the order of proteins being $(A, B, C, D)$. The given weights are $w_{AB} = 3$, $w_{AC} = 1$, $w_{BC} = 1$, $w_{BD} = 2$, and $w_{CD} = 2$. Since the network is undirected, $w_{ij} = w_{ji}$. Other weights, including diagonal elements, are $0$.\n$$W = \\begin{pmatrix} 0 & 3 & 1 & 0 \\\\ 3 & 0 & 1 & 2 \\\\ 1 & 1 & 0 & 2 \\\\ 0 & 2 & 2 & 0 \\end{pmatrix}$$\n\nNext, we construct the column-stochastic transition matrix $P$ where $P_{ij} = \\frac{w_{ij}}{\\sum_{k} w_{kj}}$. This requires calculating the sum of weights for each column of $W$. Let $d_j = \\sum_{k} w_{kj}$ be the weighted degree of node $j$.\n$d_A = w_{BA} + w_{CA} = 3 + 1 = 4$\n$d_B = w_{AB} + w_{CB} + w_{DB} = 3 + 1 + 2 = 6$\n$d_C = w_{AC} + w_{BC} + w_{DC} = 1 + 1 + 2 = 4$\n$d_D = w_{BD} + w_{CD} = 2 + 2 = 4$\n\nNow, we normalize each column of $W$ by its corresponding sum:\n$$P = \\begin{pmatrix}\n0/4 & 3/6 & 1/4 & 0/4 \\\\\n3/4 & 0/6 & 1/4 & 2/4 \\\\\n1/4 & 1/6 & 0/4 & 2/4 \\\\\n0/4 & 2/6 & 2/4 & 0/4\n\\end{pmatrix} = \\begin{pmatrix}\n0 & \\frac{1}{2} & \\frac{1}{4} & 0 \\\\\n\\frac{3}{4} & 0 & \\frac{1}{4} & \\frac{1}{2} \\\\\n\\frac{1}{4} & \\frac{1}{6} & 0 & \\frac{1}{2} \\\\\n0 & \\frac{1}{3} & \\frac{1}{2} & 0\n\\end{pmatrix}$$\n\nWith $\\alpha = \\frac{1}{2}$, the term $1 - \\alpha$ is also $\\frac{1}{2}$. The steady-state equation becomes:\n$$(I - \\frac{1}{2} P) r = \\frac{1}{2} s$$\nMultiplying by $2$ simplifies the equation to:\n$$(2I - P) r = s$$\nLet $r = (r_A, r_B, r_C, r_D)^T$. The seed vector is $s = (\\frac{1}{2}, \\frac{1}{2}, 0, 0)^T$. The matrix $(2I - P)$ is:\n$$2I - P = \\begin{pmatrix} 2 & 0 & 0 & 0 \\\\ 0 & 2 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\\\ 0 & 0 & 0 & 2 \\end{pmatrix} - \\begin{pmatrix}\n0 & \\frac{1}{2} & \\frac{1}{4} & 0 \\\\\n\\frac{3}{4} & 0 & \\frac{1}{4} & \\frac{1}{2} \\\\\n\\frac{1}{4} & -\\frac{1}{6} & 0 & \\frac{1}{2} \\\\\n0 & -\\frac{1}{3} & -\\frac{1}{2} & 2\n\\end{pmatrix} = \\begin{pmatrix}\n2 & -\\frac{1}{2} & -\\frac{1}{4} & 0 \\\\\n-\\frac{3}{4} & 2 & -\\frac{1}{4} & -\\frac{1}{2} \\\\\n-\\frac{1}{4} & -\\frac{1}{6} & 2 & -\\frac{1}{2} \\\\\n0 & -\\frac{1}{3} & -\\frac{1}{2} & 2\n\\end{pmatrix}$$\nThis yields the following system of linear equations:\n1. $2r_A - \\frac{1}{2}r_B - \\frac{1}{4}r_C = \\frac{1}{2}$\n2. $-\\frac{3}{4}r_A + 2r_B - \\frac{1}{4}r_C - \\frac{1}{2}r_D = \\frac{1}{2}$\n3. $-\\frac{1}{4}r_A - \\frac{1}{6}r_B + 2r_C - \\frac{1}{2}r_D = 0$\n4. $-\\frac{1}{3}r_B - \\frac{1}{2}r_C + 2r_D = 0$\n\nFrom equation (4), we can express $r_D$ in terms of $r_B$ and $r_C$:\n$$2r_D = \\frac{1}{3}r_B + \\frac{1}{2}r_C \\implies r_D = \\frac{1}{6}r_B + \\frac{1}{4}r_C$$\nFrom equation (3), multiplied by $12$ for clarity: $-3r_A - 2r_B + 24r_C - 6r_D = 0$.\nSubstituting $6r_D = r_B + \\frac{3}{2}r_C$:\n$$-3r_A - 2r_B + 24r_C - (r_B + \\frac{3}{2}r_C) = 0$$\n$$-3r_A - 3r_B + \\frac{45}{2}r_C = 0 \\implies r_A = \\frac{15}{2}r_C - r_B$$\nNow we substitute these expressions for $r_A$ and $r_D$ into equations (1) and (2).\nFrom equation (1), multiplied by $4$: $8r_A - 2r_B - r_C = 2$.\n$$8(\\frac{15}{2}r_C - r_B) - 2r_B - r_C = 2$$\n$$60r_C - 8r_B - 2r_B - r_C = 2 \\implies -10r_B + 59r_C = 2$$\nFrom equation (2), multiplied by $4$: $-3r_A + 8r_B - r_C - 2r_D = 2$.\n$$-3(\\frac{15}{2}r_C - r_B) + 8r_B - r_C - 2(\\frac{1}{6}r_B + \\frac{1}{4}r_C) = 2$$\n$$-\\frac{45}{2}r_C + 3r_B + 8r_B - r_C - \\frac{1}{3}r_B - \\frac{1}{2}r_C = 2$$\n$$(3+8-\\frac{1}{3})r_B + (-\\frac{45}{2}-1-\\frac{1}{2})r_C = 2$$\n$$\\frac{32}{3}r_B - 24r_C = 2 \\implies 32r_B - 72r_C = 6 \\implies 16r_B - 36r_C = 3$$\nWe now have a system of two equations for $r_B$ and $r_C$:\n(I) $16r_B - 36r_C = 3$\n(II) $-10r_B + 59r_C = 2$\nMultiplying (I) by $10$ and (II) by $16$:\n$$160r_B - 360r_C = 30$$\n$$-160r_B + 944r_C = 32$$\nAdding these two equations gives:\n$$584r_C = 62 \\implies r_C = \\frac{62}{584} = \\frac{31}{292}$$\nSubstituting $r_C$ into (I):\n$$16r_B - 36(\\frac{31}{292}) = 3 \\implies 16r_B - \\frac{9 \\cdot 4 \\cdot 31}{4 \\cdot 73} = 3 \\implies 16r_B - \\frac{279}{73} = 3$$\n$$16r_B = 3 + \\frac{279}{73} = \\frac{219 + 279}{73} = \\frac{498}{73} \\implies r_B = \\frac{498}{16 \\cdot 73} = \\frac{249}{8 \\cdot 73} = \\frac{249}{584}$$\nFinally, we calculate $r_D$ using the relation derived earlier:\n$$r_D = \\frac{1}{6}r_B + \\frac{1}{4}r_C = \\frac{1}{6}\\left(\\frac{249}{584}\\right) + \\frac{1}{4}\\left(\\frac{31}{292}\\right)$$\n$$r_D = \\frac{83}{2 \\cdot 584} + \\frac{31}{4 \\cdot 292} = \\frac{83}{1168} + \\frac{31}{1168} = \\frac{114}{1168} = \\frac{57}{584}$$\nTo provide the answer as a decimal rounded to five significant figures, we compute the value:\n$$r_D = \\frac{57}{584} \\approx 0.0976027397...$$\nThe first five significant figures are $9, 7, 6, 0, 2$. The next digit is $7$, so we round up the fifth significant digit.\n$$r_D \\approx 0.097603$$\nThis is the steady-state probability of finding the walker at protein $D$.", "answer": "$$\\boxed{0.097603}$$", "id": "4602350"}]}