{"hands_on_practices": [{"introduction": "The simplest way to describe texture is by summarizing the distribution of pixel intensities within a region, ignoring their spatial arrangement. These \"first-order\" statistics are derived from the intensity histogram. This exercise explores the fundamental properties and limitations of this approach using Shannon entropy as a representative feature [@problem_id:4613027]. By working through this problem, you will demonstrate why first-order features are blind to spatial patterns and how they are affected by preprocessing choices like intensity quantization, motivating the need for more sophisticated texture analysis methods.", "problem": "An investigator is analyzing texture in a grayscale Magnetic Resonance Imaging (MRI) Region of Interest (ROI) using first-order statistics derived from the intensity histogram. Consider a $2$-dimensional ROI comprising $N=1000$ voxels. The gray levels have been quantized into $L=6$ adjacent bins labeled $1$ through $6$, with histogram counts $(n_1,n_2,n_3,n_4,n_5,n_6)=(150,250,300,100,120,80)$. Define the first-order (Shannon) entropy in natural units (nats) as $H=-\\sum_{k=1}^{L} p_k \\ln(p_k)$, where $p_k=n_k/N$ are the empirical probabilities and $\\ln$ denotes the natural logarithm. \n\nTasks:\n- Starting from the definition of the empirical histogram and probability mass function, demonstrate that $H$ is invariant under any permutation of the spatial voxel positions (i.e., any bijective reindexing of the ROI that preserves the multiset of observed gray levels).\n- Now consider a re-quantization operation that merges adjacent bins $1$ and $2$, and merges adjacent bins $3$ and $4$, producing a new set of $L'=4$ bins with probabilities $(p_{1'}=p_1+p_2,\\; p_{2'}=p_3+p_4,\\; p_{3'}=p_5,\\; p_{4'}=p_6)$. Using first principles, derive the general form of the entropy change due to merging two bins, and state whether this change increases or decreases the entropy. Then, for the provided histogram, compute the numerical value of the change in entropy $\\Delta H = H' - H$ in nats.\n\nRound your final numerical result for $\\Delta H$ to four significant figures and express it in nats.", "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of information theory as applied to medical image analysis, is well-posed with consistent and complete data, and is expressed in objective, formal language. We may therefore proceed with a solution.\n\nThe problem is divided into two tasks. We address each in sequence.\n\n## Task 1: Invariance of Entropy under Spatial Permutation\n\nThe first-order Shannon entropy is defined as $H = -\\sum_{k=1}^{L} p_k \\ln(p_k)$. The core of this task is to demonstrate that the probabilities $p_k$ are invariant to the spatial arrangement of voxels within the Region of Interest (ROI).\n\nThe empirical histogram is constructed by counting the number of voxels, $n_k$, that have a gray level value falling into bin $k$. Let the set of all voxel indices in the ROI be $\\mathcal{V} = \\{v_1, v_2, \\ldots, v_N\\}$, where $N = 1000$ is the total number of voxels. Let $I(v)$ be the gray level value of the voxel at spatial position $v \\in \\mathcal{V}$. The gray levels are quantized into $L=6$ bins. The count for each bin $k$ is given by:\n$$\nn_k = |\\{v \\in \\mathcal{V} \\mid I(v) \\text{ is in bin } k\\}|\n$$\nThe problem states we consider a \"bijective reindexing of the ROI that preserves the multiset of observed gray levels.\" Let $\\sigma: \\mathcal{V} \\rightarrow \\mathcal{V}$ be such a permutation of the spatial voxel positions. After this reindexing, the voxel at position $v$ now has the gray level $I'(v) = I(\\sigma(v))$.\n\nThe multiset of gray levels before the permutation is $\\{I(v_1), I(v_2), \\ldots, I(v_N)\\}$. The multiset of gray levels after the permutation is $\\{I'(v_1), I'(v_2), \\ldots, I'(v_N)\\} = \\{I(\\sigma(v_1)), I(\\sigma(v_2)), \\ldots, I(\\sigma(v_N))\\}$. Since $\\sigma$ is a bijection on the set of voxel indices, the second multiset is merely a reordering of the first, and thus the two multisets are identical.\n\nThe new histogram counts, $n'_k$, are calculated from the permuted intensity map $I'$:\n$$\nn'_k = |\\{v \\in \\mathcal{V} \\mid I'(v) \\text{ is in bin } k\\}| = |\\{v \\in \\mathcal{V} \\mid I(\\sigma(v)) \\text{ is in bin } k\\}|\n$$\nBecause $\\sigma$ is a bijection, as $v$ ranges over all elements in $\\mathcal{V}$, $\\sigma(v)$ also ranges over all elements in $\\mathcal{V}$ exactly once. Therefore, the set of voxels being evaluated, $\\{I(\\sigma(v_1)), \\ldots, I(\\sigma(v_N))\\}$, is identical to the original set $\\{I(v_1), \\ldots, I(v_N)\\}$. Consequently, the number of voxels whose intensity falls into bin $k$ remains the same.\n$$\nn'_k = n_k \\quad \\text{for all } k \\in \\{1, \\ldots, L\\}\n$$\nThe empirical probabilities are defined as $p_k = n_k / N$. Since both $n_k$ and $N$ are invariant under the spatial permutation, the probabilities $p_k$ are also invariant:\n$$\np'_k = \\frac{n'_k}{N} = \\frac{n_k}{N} = p_k\n$$\nThe Shannon entropy $H$ is a function solely of the set of probabilities $\\{p_1, p_2, \\ldots, p_L\\}$. Since these probabilities are unchanged by the spatial permutation of voxels, the entropy $H$ must also be invariant. This demonstrates that first-order statistics, like entropy derived from the histogram, are insensitive to the spatial configuration of gray levels.\n\n## Task 2: Entropy Change due to Bin Merging\n\n### General Derivation and Direction of Change\n\nConsider two distinct bins, labeled $a$ and $b$, with probabilities $p_a$ and $p_b$ respectively. All other bins $k \\notin \\{a,b\\}$ have probabilities $p_k$. The initial entropy is:\n$$\nH = - \\sum_{k=1}^{L} p_k \\ln(p_k) = -(p_a \\ln(p_a) + p_b \\ln(p_b)) - \\sum_{k \\neq a, b} p_k \\ln(p_k)\n$$\nThe re-quantization operation merges bins $a$ and $b$ into a new single bin, let's call it $a'$, with a new probability $p_{a'} = p_a + p_b$. The other bins remain unchanged. The new entropy, $H'$, is calculated over the new set of bins:\n$$\nH' = -p_{a'} \\ln(p_{a'}) - \\sum_{k \\neq a, b} p_k \\ln(p_k) = -(p_a+p_b)\\ln(p_a+p_b) - \\sum_{k \\neq a, b} p_k \\ln(p_k)\n$$\nThe change in entropy, $\\Delta H_{\\text{merge}}$, due to this single merge operation is the difference $H' - H$:\n$$\n\\Delta H_{\\text{merge}} = H' - H = \\left[ -(p_a+p_b)\\ln(p_a+p_b) - \\sum_{k \\neq a, b} p_k \\ln(p_k) \\right] - \\left[ -(p_a \\ln(p_a) + p_b \\ln(p_b)) - \\sum_{k \\neq a, b} p_k \\ln(p_k) \\right]\n$$\nThe terms for the unmerged bins cancel, leaving the general form of the entropy change for merging two bins:\n$$\n\\Delta H_{\\text{merge}} = p_a \\ln(p_a) + p_b \\ln(p_b) - (p_a+p_b)\\ln(p_a+p_b)\n$$\nTo determine the sign of this change, we can rewrite the expression:\n$$\n\\Delta H_{\\text{merge}} = p_a \\ln(p_a) - p_a \\ln(p_a+p_b) + p_b \\ln(p_b) - p_b \\ln(p_a+p_b)\n$$\n$$\n\\Delta H_{\\text{merge}} = p_a \\ln\\left(\\frac{p_a}{p_a+p_b}\\right) + p_b \\ln\\left(\\frac{p_b}{p_a+p_b}\\right)\n$$\nAssuming the bins are non-empty, we have $p_a > 0$ and $p_b > 0$. This implies $p_a+p_b > p_a$ and $p_a+p_b > p_b$. Therefore, the arguments of the logarithms, $\\frac{p_a}{p_a+p_b}$ and $\\frac{p_b}{p_a+p_b}$, are both strictly between $0$ and $1$. The natural logarithm of any number in this interval is negative. Since $p_a$ and $p_b$ are positive, both terms in the sum are negative. Thus, their sum is also negative.\n$$\n\\Delta H_{\\text{merge}} < 0\n$$\nThis proves that merging bins always decreases the entropy (or leaves it unchanged if one of the initial probabilities is zero). This is an expected result, as merging bins is equivalent to a loss of information about the distribution, making the system appear less disordered.\n\n### Numerical Computation for the Given Problem\n\nThe given histogram counts are $(n_1, n_2, n_3, n_4, n_5, n_6) = (150, 250, 300, 100, 120, 80)$ with $N=1000$. The corresponding probabilities are:\n$p_1 = 150/1000 = 0.15$\n$p_2 = 250/1000 = 0.25$\n$p_3 = 300/1000 = 0.30$\n$p_4 = 100/1000 = 0.10$\n$p_5 = 120/1000 = 0.12$\n$p_6 = 80/1000 = 0.08$\n\nThe operation involves two separate merges: bins $1$ and $2$ are merged, and bins $3$ and $4$ are merged. The total change in entropy $\\Delta H$ is the sum of the changes from each individual merge operation. Let $\\Delta H_{1,2}$ be the change from merging bins $1$ and $2$, and $\\Delta H_{3,4}$ be the change from merging bins $3$ and $4$.\n$$\n\\Delta H = \\Delta H_{1,2} + \\Delta H_{3,4}\n$$\nUsing the general form derived above:\n$$\n\\Delta H_{1,2} = p_1 \\ln(p_1) + p_2 \\ln(p_2) - (p_1+p_2)\\ln(p_1+p_2)\n$$\n$$\n\\Delta H_{3,4} = p_3 \\ln(p_3) + p_4 \\ln(p_4) - (p_3+p_4)\\ln(p_3+p_4)\n$$\nThe new merged probabilities are $p_{1'} = p_1+p_2 = 0.15+0.25 = 0.40$ and $p_{2'} = p_3+p_4 = 0.30+0.10 = 0.40$.\n\nNow we compute the numerical values in nats:\n$$\n\\Delta H_{1,2} = 0.15 \\ln(0.15) + 0.25 \\ln(0.25) - 0.40 \\ln(0.40)\n$$\n$$\n\\Delta H_{1,2} \\approx 0.15(-1.89712) + 0.25(-1.38629) - 0.40(-0.91629)\n$$\n$$\n\\Delta H_{1,2} \\approx -0.284568 - 0.346573 + 0.366516 = -0.264625\n$$\n$$\n\\Delta H_{3,4} = 0.30 \\ln(0.30) + 0.10 \\ln(0.10) - 0.40 \\ln(0.40)\n$$\n$$\n\\Delta H_{3,4} \\approx 0.30(-1.20397) + 0.10(-2.30259) - 0.40(-0.91629)\n$$\n$$\n\\Delta H_{3,4} \\approx -0.361191 - 0.230259 + 0.366516 = -0.224934\n$$\nThe total change in entropy is:\n$$\n\\Delta H = \\Delta H_{1,2} + \\Delta H_{3,4} \\approx -0.264625 - 0.224934 = -0.489559\n$$\nRounding this result to four significant figures gives $-0.4896$. The units are nats.", "answer": "$$\n\\boxed{-0.4896}\n$$", "id": "4613027"}, {"introduction": "Having established that first-order statistics disregard spatial information, we now turn to methods designed to capture it. The Gray-Level Co-occurrence Matrix (GLCM) is a classical and powerful tool that quantifies the spatial relationships between pairs of pixels. This practice focuses on computing the GLCM correlation, a feature that measures the linear dependency between the gray level of a pixel and its neighbor at a specific offset [@problem_id:4612945]. This hands-on calculation that not only defines a key texture feature but also reinforces the fundamental statistical concept of independence.", "problem": "A normalized Gray-Level Co-occurrence Matrix (GLCM) is widely used to characterize texture by modeling the empirical joint distribution of gray levels at a fixed spatial offset. Consider a stationary texture process observed in a medical image, where gray levels are discretized to the set $\\{1, 2\\}$ and the normalized GLCM at a given offset is\n$$\np = \\begin{bmatrix}\n0.1 & 0.1 \\\\\n0.4 & 0.4\n\\end{bmatrix},\n$$\nwith rows and columns indexed by the gray levels $\\{1,2\\}$. Interpreting $p(i,j)$ as the joint probability mass function of two discrete random variables $X$ and $Y$ representing the reference pixel and its neighbor at the specified offset, use the core definitions of expectation, variance, and covariance from probability theory to compute the correlation coefficient of $(X,Y)$ induced by this GLCM. Provide the numerical value of the correlation coefficient. Additionally, explain what the sign and magnitude of the computed correlation imply about the linear association between the paired gray levels at this offset in the texture. No rounding is necessary.", "solution": "The problem asks for the computation and interpretation of the correlation coefficient between two random variables, $X$ and $Y$, whose joint probability distribution is described by a given normalized Gray-Level Co-occurrence Matrix (GLCM). A GLCM is a statistical tool used for texture analysis. It quantifies the spatial relationship of pixels by creating a matrix that represents the frequency of co-occurring gray level values at a given offset.\n\nThe random variables $X$ and $Y$ represent the gray levels of a reference pixel and its neighbor, respectively. The set of possible gray levels is given as $\\{1, 2\\}$. The normalized GLCM, denoted by $p$, acts as the joint probability mass function (PMF) $p(i,j) = P(X=i, Y=j)$, where $i, j \\in \\{1, 2\\}$. The given matrix is:\n$$\np = \\begin{bmatrix}\np(1,1) & p(1,2) \\\\\np(2,1) & p(2,2)\n\\end{bmatrix} = \\begin{bmatrix}\n0.1 & 0.1 \\\\\n0.4 & 0.4\n\\end{bmatrix}\n$$\nThe correlation coefficient, $\\rho_{XY}$, is defined as:\n$$\n\\rho_{XY} = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n$$\nwhere $\\text{Cov}(X, Y)$ is the covariance of $X$ and $Y$, and $\\sigma_X$ and $\\sigma_Y$ are their respective standard deviations.\n\nA key property of probability distributions is statistical independence. Two discrete random variables $X$ and $Y$ are independent if and only if their joint PMF is the product of their marginal PMFs, i.e., $p(i,j) = p_X(i) p_Y(j)$ for all possible values of $i$ and $j$. If $X$ and $Y$ are independent, their covariance is zero, which in turn means their correlation coefficient is zero (assuming non-zero variances). We will first check for independence.\n\nFirst, we compute the marginal PMFs, $p_X(i)$ and $p_Y(j)$.\nThe marginal PMF for $X$ is obtained by summing the probabilities across the rows of the matrix $p$:\n$$\np_X(1) = P(X=1) = p(1,1) + p(1,2) = 0.1 + 0.1 = 0.2\n$$\n$$\np_X(2) = P(X=2) = p(2,1) + p(2,2) = 0.4 + 0.4 = 0.8\n$$\nThe marginal PMF for $Y$ is obtained by summing the probabilities down the columns of the matrix $p$:\n$$\np_Y(1) = P(Y=1) = p(1,1) + p(2,1) = 0.1 + 0.4 = 0.5\n$$\n$$\np_Y(2) = P(Y=2) = p(1,2) + p(2,2) = 0.1 + 0.4 = 0.5\n$$\nNow, we test for independence by checking if $p(i,j) = p_X(i) p_Y(j)$ for all pairs $(i, j)$:\n- For $(i,j) = (1,1)$: $p_X(1) p_Y(1) = (0.2)(0.5) = 0.1$. This matches $p(1,1) = 0.1$.\n- For $(i,j) = (1,2)$: $p_X(1) p_Y(2) = (0.2)(0.5) = 0.1$. This matches $p(1,2) = 0.1$.\n- For $(i,j) = (2,1)$: $p_X(2) p_Y(1) = (0.8)(0.5) = 0.4$. This matches $p(2,1) = 0.4$.\n- For $(i,j) = (2,2)$: $p_X(2) p_Y(2) = (0.8)(0.5) = 0.4$. This matches $p(2,2) = 0.4$.\n\nSince the condition $p(i,j) = p_X(i) p_Y(j)$ holds for all possible pairs of $(i,j)$, the random variables $X$ and $Y$ are statistically independent.\n\nFor independent random variables, the covariance is zero:\n$$\n\\text{Cov}(X, Y) = E[XY] - E[X]E[Y]\n$$\nBy independence, $E[XY] = E[X]E[Y]$, so\n$$\n\\text{Cov}(X, Y) = E[X]E[Y] - E[X]E[Y] = 0\n$$\nTo ensure the correlation coefficient is well-defined and equal to zero, we must confirm that the standard deviations $\\sigma_X$ and $\\sigma_Y$ are non-zero. This requires the variances to be non-zero. A variance of zero would imply the random variable is constant, which is not the case here as both $X$ and $Y$ can take two distinct values with non-zero probabilities. For completeness, we calculate the variances:\n$$\nE[X] = \\sum_i i \\cdot p_X(i) = (1)(0.2) + (2)(0.8) = 0.2 + 1.6 = 1.8\n$$\n$$\nE[X^2] = \\sum_i i^2 \\cdot p_X(i) = (1^2)(0.2) + (2^2)(0.8) = 0.2 + 3.2 = 3.4\n$$\n$$\n\\sigma_X^2 = \\text{Var}(X) = E[X^2] - (E[X])^2 = 3.4 - (1.8)^2 = 3.4 - 3.24 = 0.16\n$$\nSince $\\sigma_X^2 = 0.16 > 0$, the standard deviation $\\sigma_X = \\sqrt{0.16} = 0.4$ is non-zero.\n$$\nE[Y] = \\sum_j j \\cdot p_Y(j) = (1)(0.5) + (2)(0.5) = 0.5 + 1.0 = 1.5\n$$\n$$\nE[Y^2] = \\sum_j j^2 \\cdot p_Y(j) = (1^2)(0.5) + (2^2)(0.5) = 0.5 + 2.0 = 2.5\n$$\n$$\n\\sigma_Y^2 = \\text{Var}(Y) = E[Y^2] - (E[Y])^2 = 2.5 - (1.5)^2 = 2.5 - 2.25 = 0.25\n$$\nSince $\\sigma_Y^2 = 0.25 > 0$, the standard deviation $\\sigma_Y = \\sqrt{0.25} = 0.5$ is also non-zero.\n\nThe correlation coefficient is therefore:\n$$\n\\rho_{XY} = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y} = \\frac{0}{(0.4)(0.5)} = \\frac{0}{0.2} = 0\n$$\nThe numerical value of the correlation coefficient is $0$.\n\nThe correlation coefficient measures the strength and direction of the linear relationship between two variables.\n-   **Sign and Magnitude**: A correlation coefficient of $0$ has no sign (it is neither positive nor negative) and its magnitude is zero.\n-   **Implication**: A value of $\\rho_{XY} = 0$ indicates a total absence of a linear association between the gray level of a reference pixel, $X$, and its neighbor, $Y$, at the specified offset. In this particular case, the zero correlation is a consequence of the stronger condition of statistical independence. This means that knowing the gray level of a pixel provides no predictive information about the gray level of its neighbor. In the context of texture analysis, this implies that at the scale and orientation defined by the GLCM's offset, the texture is completely random; there is no discernible structure or pattern in the pairwise arrangement of gray levels. This could be observed in an image region dominated by random noise or a texture whose structural features are much smaller or larger than the chosen offset.", "answer": "$$\\boxed{0}$$", "id": "4612945"}, {"introduction": "While GLCMs analyze texture through pairwise statistics, an alternative and highly effective approach is to describe local structural micro-patterns. The Local Binary Pattern (LBP) operator accomplishes this by generating a binary code that summarizes whether a center pixel's neighbors are brighter or darker. In this problem, you will compute the standard $LBP$ code for a small image patch and then derive its rotation-invariant uniform label, a more robust variant widely used in practice [@problem_id:4612936]. This hands-on calculation demystifies the LBP encoding process, showing how complex neighborhood topographies can be captured in a simple, yet powerful, feature.", "problem": "In radiomics-driven analysis of Magnetic Resonance Imaging (MRI) textures, Local Binary Patterns (LBP) provide a compact representation of local micro-structures that is robust to monotonic grayscale transformations. Consider a single-channel grayscale $3\\times 3$ patch extracted from a $T_2$-weighted MRI slice. Let the center intensity be $g_c = 10$ and the $8$ neighbors sampled on a circle of radius $R=1$ in clockwise order starting from the neighbor at angle $0$ (the positive $x$-axis, “east”) be the sequence $[12, 9, 11, 8, 10, 13, 7, 10]$. Using the standard Local Binary Patterns (LBP) operator with $P=8$ neighbors and radius $R=1$, define the thresholding indicator for each neighbor intensity $g_p$ as $s(g_p - g_c)$, where $s(t)$ equals $1$ if $t \\ge 0$ and $0$ otherwise. Form the circular binary pattern in the given clockwise order, and interpret this pattern as a base-$2$ integer with the first neighbor (at angle $0$) assigned the least-significant bit and bit weights increasing clockwise. Then, determine the rotation-invariant uniform label by the canonical rule: if the circular binary pattern exhibits at most two transitions between $0$ and $1$, the label equals the number of ones in the pattern; otherwise, the label equals $P+1$. Compute the resulting $LBP_{8,1}$ code and its rotation-invariant uniform label. Report both values without units. The final answer must be a calculation and expressed as a single row matrix. No rounding is required.", "solution": "The problem requires the computation of the Local Binary Patterns ($LBP$) code and the corresponding rotation-invariant uniform label for a given $3\\times3$ image patch.\n\nThe validation of the problem statement is performed first.\n\n**Step 1: Extract Givens**\n- The image patch is a $3 \\times 3$ single-channel grayscale region.\n- The center pixel intensity is $g_c = 10$.\n- The number of neighbors is $P=8$ on a circle of radius $R=1$.\n- The sequence of $P=8$ neighbor intensities, starting from the east ($0$ degrees) and proceeding clockwise, is given as $[12, 9, 11, 8, 10, 13, 7, 10]$. Let's denote this sequence by $\\{g_p\\}_{p=0}^{7}$, so $g_0=12$, $g_1=9$, and so on.\n- The thresholding function is defined as $s(t)$, where $s(t) = 1$ if $t \\ge 0$ and $s(t) = 0$ if $t < 0$.\n- The binary pattern is formed from the sequence of thresholded differences $s(g_p - g_c)$ for $p=0, 1, \\dots, 7$.\n- The $LBP$ code is the decimal value of the resulting $8$-bit binary number, where the bit from the first neighbor ($p=0$) is the least-significant bit (LSB), and bit weights increase clockwise.\n- The rotation-invariant uniform label is determined by a rule based on the number of spatial transitions (bit-flips from $0$ to $1$ or $1$ to $0$) in the circular binary pattern. Let this be $U(LBP)$.\n    - If $U(LBP) \\le 2$, the pattern is \"uniform\", and its label is the number of '1's in the pattern.\n    - If $U(LBP) > 2$, the pattern is \"non-uniform\", and its label is $P+1$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded as it concerns the standard Local Binary Patterns operator, a fundamental technique in texture analysis and radiomics. It is well-posed, providing all necessary parameters, data, and unambiguous rules for computation. The language is objective and formal. The problem is complete, consistent, and computationally feasible. There are no violations of scientific principles, logical inconsistencies, or ambiguities.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n**Solution Derivation**\n\nFirst, we compute the binary pattern by comparing each neighbor's intensity $g_p$ with the center intensity $g_c=10$. We apply the thresholding function $s(g_p - g_c)$.\n\nThe neighbor intensities are $g_0=12, g_1=9, g_2=11, g_3=8, g_4=10, g_5=13, g_6=7, g_7=10$.\n\nThe thresholded values, which form the bits of the pattern, are calculated as follows:\n- For $p=0$: $s(g_0 - g_c) = s(12 - 10) = s(2) = 1$.\n- For $p=1$: $s(g_1 - g_c) = s(9 - 10) = s(-1) = 0$.\n- For $p=2$: $s(g_2 - g_c) = s(11 - 10) = s(1) = 1$.\n- For $p=3$: $s(g_3 - g_c) = s(8 - 10) = s(-2) = 0$.\n- For $p=4$: $s(g_4 - g_c) = s(10 - 10) = s(0) = 1$.\n- For $p=5$: $s(g_5 - g_c) = s(13 - 10) = s(3) = 1$.\n- For $p=6$: $s(g_6 - g_c) = s(7 - 10) = s(-3) = 0$.\n- For $p=7$: $s(g_7 - g_c) = s(10 - 10) = s(0) = 1$.\n\nThe sequence of bits, corresponding to neighbors $p=0, \\dots, 7$, is $\\{s_p\\}_{p=0}^7 = \\{1, 0, 1, 0, 1, 1, 0, 1\\}$.\n\nNext, we calculate the $LBP_{8,1}$ code. The problem specifies that the bit from neighbor $p=0$ is the LSB. The formula for the $LBP$ code is:\n$$ LBP_{P,R} = \\sum_{p=0}^{P-1} s(g_p - g_c) \\cdot 2^p $$\nUsing $P=8$ and the bits we calculated:\n$$ LBP_{8,1} = s_0 \\cdot 2^0 + s_1 \\cdot 2^1 + s_2 \\cdot 2^2 + s_3 \\cdot 2^3 + s_4 \\cdot 2^4 + s_5 \\cdot 2^5 + s_6 \\cdot 2^6 + s_7 \\cdot 2^7 $$\nThe binary string, read from $s_7$ to $s_0$, is $10110101_2$.\n$$ LBP_{8,1} = 1 \\cdot 2^0 + 0 \\cdot 2^1 + 1 \\cdot 2^2 + 0 \\cdot 2^3 + 1 \\cdot 2^4 + 1 \\cdot 2^5 + 0 \\cdot 2^6 + 1 \\cdot 2^7 $$\n$$ LBP_{8,1} = 1 \\cdot 1 + 0 \\cdot 2 + 1 \\cdot 4 + 0 \\cdot 8 + 1 \\cdot 16 + 1 \\cdot 32 + 0 \\cdot 64 + 1 \\cdot 128 $$\n$$ LBP_{8,1} = 1 + 4 + 16 + 32 + 128 = 181 $$\nThe first required value, the $LBP_{8,1}$ code, is $181$.\n\nNow, we determine the rotation-invariant uniform label, denoted as $LBP_{P,R}^{riu2}$. We must count the number of transitions $U$ in the circular binary pattern $(s_0, s_1, s_2, s_3, s_4, s_5, s_6, s_7)$.\nThe pattern is $(1, 0, 1, 0, 1, 1, 0, 1)$.\nThe number of transitions $U$ is given by:\n$$ U = |s_{P-1} - s_0| + \\sum_{p=1}^{P-1} |s_p - s_{p-1}| $$\nWith $P=8$, the pattern is $(s_0, s_1, s_2, s_3, s_4, s_5, s_6, s_7) = (1, 0, 1, 0, 1, 1, 0, 1)$.\nLet's count the transitions sequentially:\n- $s_0 \\to s_1$: $1 \\to 0$, transition. ($1$)\n- $s_1 \\to s_2$: $0 \\to 1$, transition. ($2$)\n- $s_2 \\to s_3$: $1 \\to 0$, transition. ($3$)\n- $s_3 \\to s_4$: $0 \\to 1$, transition. ($4$)\n- $s_4 \\to s_5$: $1 \\to 1$, no transition.\n- $s_5 \\to s_6$: $1 \\to 0$, transition. ($5$)\n- $s_6 \\to s_7$: $0 \\to 1$, transition. ($6$)\n- $s_7 \\to s_0$ (circular part): $1 \\to 1$, no transition.\nThe total number of transitions is $U=6$.\n\nAccording to the rule for uniform patterns, a pattern is uniform if $U \\le 2$. Since $U=6$, which is greater than $2$, the pattern is non-uniform.\nFor non-uniform patterns, the rotation-invariant uniform label is defined as $P+1$.\nGiven $P=8$, the label is $8+1=9$.\n\nThe two computed values are the $LBP_{8,1}$ code, which is $181$, and its rotation-invariant uniform label, which is $9$. The final answer should be presented as a single row matrix.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n181 & 9\n\\end{pmatrix}\n}\n$$", "id": "4612936"}]}