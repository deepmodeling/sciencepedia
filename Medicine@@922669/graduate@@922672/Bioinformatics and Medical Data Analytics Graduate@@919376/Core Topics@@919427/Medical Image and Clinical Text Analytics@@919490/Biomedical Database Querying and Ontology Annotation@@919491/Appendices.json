{"hands_on_practices": [{"introduction": "The integrity of any analysis depends on the quality of the underlying data. In biomedical ontologies, logical rules called axioms enforce consistency; for instance, a 'disjointness' axiom asserts that a gene product cannot simultaneously be part of two mutually exclusive cellular components. This exercise [@problem_id:4543539] challenges you to implement a validation pipeline that automatically detects and resolves such contradictions, a critical skill for building robust and reliable annotation databases.", "problem": "You are tasked with implementing validation rules for a Gene Ontology (GO) annotation ingestion pipeline that automatically detects and enforces consistency with disjointness axioms. The Gene Ontology (GO) is modeled as a directed graph of classes with subclass edges; disjointness axioms state that certain classes cannot have overlapping instances. In the ingestion pipeline, each entity (e.g., a gene product) is annotated with one or more GO classes. An annotation is considered contradictory if, after inferring all ancestral classes via subclass transitivity, an entity is simultaneously annotated to two classes that are declared disjoint.\n\nFundamental base and definitions:\n- Let the ontology classes be represented by integers and the subclass relation by directed edges. For a class $c$, let $parents(c)$ be the set of immediate superclasses, and let $anc(c)$ be the set of all ancestors of $c$ including $c$ itself, computed via transitive closure over $parents(\\cdot)$.\n- A disjointness axiom between classes $x$ and $y$ means $x \\cap y = \\varnothing$ in the set-theoretic sense.\n- For an entity with a set of annotated classes $A = \\{a_1, a_2, \\dots, a_n\\}$, its inferred types are $I = \\bigcup_{i=1}^{n} anc(a_i)$.\n- A contradiction exists for an entity if there exists a pair $(x,y)$ declared disjoint such that $x \\in I$ and $y \\in I$.\n\nValidation rules to implement:\n1. Subclass closure rule: For each annotation $a$, include all ancestors $anc(a)$ when evaluating disjointness.\n2. Disjointness detection rule: Flag an entity as contradictory if any declared disjoint pair $(x,y)$ is jointly present in the inferred types.\n3. Automated enforcement rule: For each contradictory entity, remove the minimal number of annotations from its original set $A$ such that, after recomputing inference $I$, no disjoint pair $(x,y)$ is jointly present. The minimality criterion is the smallest cardinality of removed annotations that yields a contradiction-free inferred set.\n\nMathematical constraints and requirements:\n- Subclass closure must be computed in the presence of cycles; termination must be guaranteed by using a visited set.\n- Disjointness axioms are symmetric; treat $(x,y)$ as unordered.\n- The enforcement must find a minimal removal, not a heuristic or greedy approximation.\n\nInput for test suite and coverage:\nYour program must hard-code and process the following four test cases. Each test case consists of:\n- A set of subclass edges $(child \\rightarrow parent)$ specified as ordered pairs.\n- A set of disjoint pairs of classes.\n- A list of entities where each entity is a list of annotated classes.\n\nTest case $1$ (happy path and direct disjointness):\n- Subclass edges: $(1 \\rightarrow 0)$, $(2 \\rightarrow 0)$, $(3 \\rightarrow 0)$, $(4 \\rightarrow 1)$, $(5 \\rightarrow 2)$, $(6 \\rightarrow 3)$.\n- Disjoint pairs: $(1,2)$ and $(2,3)$.\n- Entities:\n  - Entity $1$: $[4]$.\n  - Entity $2$: $[5, 6]$.\n  - Entity $3$: $[4,5]$.\n\nTest case $2$ (ancestor-only conflict detection):\n- Subclass edges: $(10 \\rightarrow 0)$, $(11 \\rightarrow 0)$, $(12 \\rightarrow 10)$, $(13 \\rightarrow 11)$.\n- Disjoint pairs: $(10,11)$.\n- Entities:\n  - Entity $1$: $[12,13]$.\n  - Entity $2$: $[12]$.\n  - Entity $3$: $[10,11]$.\n\nTest case $3$ (cycle robustness):\n- Subclass edges: $(20 \\rightarrow 21)$, $(21 \\rightarrow 20)$, $(22 \\rightarrow 0)$.\n- Disjoint pairs: $(21,22)$.\n- Entities:\n  - Entity $1$: $[20,22]$.\n  - Entity $2$: $[21]$.\n  - Entity $3$: $[]$.\n\nTest case $4$ (multiple independent conflicts requiring more than one removal):\n- Subclass edges: $(30 \\rightarrow 0)$, $(31 \\rightarrow 0)$, $(32 \\rightarrow 0)$, $(33 \\rightarrow 0)$, $(34 \\rightarrow 30)$, $(35 \\rightarrow 31)$, $(36 \\rightarrow 32)$, $(37 \\rightarrow 33)$.\n- Disjoint pairs: $(30,31)$ and $(32,33)$.\n- Entities:\n  - Entity $1$: $[34,35,36,37]$.\n\nOutput specification:\n- For each test case $i \\in \\{1,2,3,4\\}$, compute two integers:\n  - $c_i$: the number of entities initially detected as contradictory before enforcement.\n  - $r_i$: the total number of annotation removals performed by the enforcement step across all entities in the test case to achieve a contradiction-free dataset.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the list $[c_i, r_i]$ for the corresponding test case. For example, the output format must be exactly of the form $[[c_1,r_1],[c_2,r_2],[c_3,r_3],[c_4,r_4]]$ with integers only.\n\nNo angles or physical units are involved. All outputs must be integers or lists of integers, as specified, and the code must be self-contained with no external input.", "solution": "The problem requires the implementation of a validation and enforcement system for Gene Ontology (GO) annotations. This system must detect and resolve contradictions arising from subclass relationships and disjointness axioms. A solution can be designed in three principal stages: (1) pre-computation of the ontology's class hierarchy, (2) detection of contradictory annotation sets, and (3) enforcement of consistency by minimal annotation removal.\n\n### 1. Ontology Pre-processing: Transitive Closure\n\nThe GO class structure is a directed graph where an edge $(c \\rightarrow p)$ signifies that class $c$ is a subclass of class $p$. The set of all ancestors of a class $c$, denoted $anc(c)$, is the transitive closure of this subclass relation, including $c$ itself. To efficiently query ancestors, we pre-compute $anc(c)$ for every class $c$ in the ontology.\n\nLet the set of subclass edges define a directed graph $G=(V, E)$, where $V$ is the set of all classes and $E$ is the set of subclass edges. The parents of a class $c$ are given by $parents(c) = \\{p \\in V \\mid (c, p) \\in E\\}$. The ancestor set $anc(c)$ can be defined recursively:\n$$\nanc(c) = \\{c\\} \\cup \\bigcup_{p \\in parents(c)} anc(p)\n$$\nThis computation can be implemented using a recursive Depth-First Search (DFS) algorithm with memoization to store the results for already-computed classes, thereby avoiding redundant calculations. To guarantee termination in the presence of cycles in the graph, the traversal for any given class must keep track of the nodes in its current recursion path. If the algorithm encounters a node already in the current path, it is part of a cycle and should not be explored further.\n\nThe algorithm proceeds as follows:\n- A dictionary, `memo`, stores the computed ancestor sets.\n- A recursive function, `compute_ancestors(c, path_stack)`, is defined. `path_stack` is a set of nodes in the current DFS traversal path.\n- For a class $c$, if $c$ is in `memo`, the stored result is returned.\n- Otherwise, $c$ is added to `path_stack`. The ancestor set is initialized as $A_c = \\{c\\}$.\n- For each parent $p$ of $c$, if $p$ is not in `path_stack`, `compute_ancestors(p, path_stack)` is called, and its result is unioned into $A_c$.\n- Before returning, $c$ is removed from `path_stack`, and $A_c$ is stored in `memo`.\n\nThis process is executed for all classes present in the ontology, fully populating the ancestor map.\n\n### 2. Contradiction Detection\n\nAn entity is annotated with a set of classes $A = \\{a_1, a_2, \\ldots, a_n\\}$. The full set of classes implied by these annotations, the inferred types $I$, is the union of the ancestor sets of each annotation:\n$$\nI = \\bigcup_{a \\in A} anc(a)\n$$\nA contradiction exists if this set $I$ violates a disjointness axiom. A disjointness axiom between classes $x$ and $y$ states that they cannot have common instances. In our model, this means an entity cannot be inferred to belong to both $x$ and $y$.\n\nThe detection algorithm is:\n- Given an entity's annotations $A$, compute the inferred type set $I$ using the pre-computed ancestor map.\n- For each disjoint pair $(x, y)$ provided in the problem, check if both $x \\in I$ and $y \\in I$.\n- If such a pair is found, the annotation set $A$ is contradictory. Otherwise, it is consistent.\n\nThe total number of initially-contradictory entities, $c_i$, for a given test case $i$, is found by applying this detection algorithm to every entity in the test case.\n\n### 3. Minimal Annotation Removal for Enforcement\n\nFor each contradictory annotation set $A$, the enforcement rule requires removing a minimal number of annotations to restore consistency. This is a combinatorial optimization problem. We must find a subset of annotations to remove, $R \\subseteq A$, such that $A' = A \\setminus R$ is consistent, and the cardinality $|R|$ is minimized.\n\nThis is equivalent to finding a subset of annotations to *keep*, $A_{keep} \\subseteq A$, that is consistent and has the maximum possible cardinality. The number of removed annotations would then be $|A| - |A_{keep}|$.\n\nAn exhaustive search strategy guarantees finding the minimal removal set. Since the number of annotations per entity in the given test cases is small, this approach is computationally feasible.\nThe algorithm is as follows:\n- Let the original annotations be the set $A$ of size $n = |A|$.\n- We search for the smallest number of removals, $k$, starting from $k=1$ up to $n$.\n- For a given $k$, generate all combinations of annotations to remove, $R \\subset A$ with $|R|=k$.\n- For each such combination $R$, form the new annotation set $A' = A \\setminus R$.\n- Check if $A'$ is contradictory using the detection algorithm from step 2.\n- If $A'$ is found to be consistent, then $k$ is the minimal number of removals required for this entity. The search for this entity terminates, and we add $k$ to the total removal count, $r_i$.\n- This process is repeated for every contradictory entity in the test case. The sum of minimal removals across all entities gives the total $r_i$.\n\nFor example, to find a minimal removal set for an entity with annotations $A=\\{a_1, a_2, a_3, a_4\\}$:\n1. Check all $1$-annotation removals: $\\{a_1\\}, \\{a_2\\}, \\{a_3\\}, \\{a_4\\}$. If removing one of them, say $\\{a_2\\}$, makes the remaining set $\\{a_1, a_3, a_4\\}$ consistent, the minimal removal count is $1$.\n2. If no $1$-annotation removal works, check all $2$-annotation removals (e.g., $\\{a_1, a_2\\}$), and so on.\n\nThe final output for each test case $i$ is the pair $[c_i, r_i]$, where $c_i$ is the count of initially contradictory entities and $r_i$ is the sum of minimal removals over all entities.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import defaultdict\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print a formatted result.\n    \"\"\"\n    test_cases = [\n        {\n            \"subclass_edges\": [(1, 0), (2, 0), (3, 0), (4, 1), (5, 2), (6, 3)],\n            \"disjoint_pairs\": [(1, 2), (2, 3)],\n            \"entities\": [[4], [5, 6], [4, 5]]\n        },\n        {\n            \"subclass_edges\": [(10, 0), (11, 0), (12, 10), (13, 11)],\n            \"disjoint_pairs\": [(10, 11)],\n            \"entities\": [[12, 13], [12], [10, 11]]\n        },\n        {\n            \"subclass_edges\": [(20, 21), (21, 20), (22, 0)],\n            \"disjoint_pairs\": [(21, 22)],\n            \"entities\": [[20, 22], [21], []]\n        },\n        {\n            \"subclass_edges\": [(30, 0), (31, 0), (32, 0), (33, 0), (34, 30), (35, 31), (36, 32), (37, 33)],\n            \"disjoint_pairs\": [(30, 31), (32, 33)],\n            \"entities\": [[34, 35, 36, 37]]\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        ci, ri = _process_case(case[\"subclass_edges\"], case[\"disjoint_pairs\"], case[\"entities\"])\n        all_results.append([ci, ri])\n    \n    # Use repr to get a string representation and remove spaces for exact format matching.\n    final_output = repr(all_results).replace(\" \", \"\")\n    print(final_output)\n\ndef _process_case(edges, disjoints, entities_list):\n    \"\"\"\n    Processes a single test case.\n    \"\"\"\n    graph = defaultdict(list)\n    all_nodes = set()\n    for child, parent in edges:\n        graph[child].append(parent)\n        all_nodes.add(child)\n        all_nodes.add(parent)\n    \n    for entity_annotations in entities_list:\n        all_nodes.update(entity_annotations)\n    \n    for pair in disjoints:\n        all_nodes.update(pair)\n\n    # 1. Build Ancestor Map (Transitive Closure)\n    ancestor_map = {}\n    for node in all_nodes:\n        if node not in ancestor_map:\n            _get_ancestors_recursive(node, graph, ancestor_map, set())\n    \n    # Frozen set for disjoint pairs for potential optimization, though list of tuples is fine.\n    disjoint_pairs_set = [tuple(sorted(p)) for p in disjoints]\n\n    # 2. Initial Contradiction Detection\n    contradictory_entity_indices = []\n    for i, annotations in enumerate(entities_list):\n        if _is_contradictory(annotations, ancestor_map, disjoint_pairs_set):\n            contradictory_entity_indices.append(i)\n    \n    c_i = len(contradictory_entity_indices)\n    r_i = 0\n\n    # 3. Enforcement (Minimal Removal)\n    for i in contradictory_entity_indices:\n        annotations = entities_list[i]\n        removals_needed = _find_minimal_removals(annotations, ancestor_map, disjoint_pairs_set)\n        r_i += removals_needed\n\n    return c_i, r_i\n\ndef _get_ancestors_recursive(node, graph, memo, path):\n    \"\"\"\n    Computes all ancestors of a node using memoized, cycle-aware DFS.\n    \"\"\"\n    if node in memo:\n        return memo[node]\n    if node in path: # Cycle detected\n        return set()\n\n    path.add(node)\n    \n    ancestors = {node}\n    for parent in graph.get(node, []):\n        ancestors.update(_get_ancestors_recursive(parent, graph, memo, path))\n    \n    path.remove(node)\n    memo[node] = ancestors\n    return ancestors\n\ndef _is_contradictory(annotations, ancestor_map, disjoint_pairs):\n    \"\"\"\n    Checks if a set of annotations is contradictory.\n    \"\"\"\n    if not annotations:\n        return False\n\n    inferred_types = set()\n    for ann in annotations:\n        inferred_types.update(ancestor_map.get(ann, {ann}))\n\n    for x, y in disjoint_pairs:\n        if x in inferred_types and y in inferred_types:\n            return True\n    \n    return False\n\ndef _find_minimal_removals(annotations, ancestor_map, disjoint_pairs):\n    \"\"\"\n    Finds the minimum number of annotations to remove to resolve a contradiction.\n    \"\"\"\n    n = len(annotations)\n    # Iterate on the number of annotations to remove, k\n    for k in range(1, n + 1):\n        # Iterate through all combinations of annotations to remove\n        for removal_candidate in combinations(annotations, k):\n            remaining_annotations = list(set(annotations) - set(removal_candidate))\n            if not _is_contradictory(remaining_annotations, ancestor_map, disjoint_pairs):\n                return k\n    return 0 # Should not be reached for contradictory sets, but for completeness.\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "4543539"}, {"introduction": "Once data is validated, a primary task is to retrieve specific information from vast knowledge bases. This practice [@problem_id:4543585] focuses on translating a precise biological question into a formal query using SPARQL, the standard language for querying RDF graph data. Mastering this skill is essential for effectively leveraging large, interconnected datasets to assemble the specific evidence needed for analysis.", "problem": "You are given a simplified, in-memory representation of Resource Description Framework (RDF) data and asked to construct and evaluate a Structured Query Language for RDF (SPARQL) query that retrieves Gene Ontology (GO) annotations meeting specific biological and ontological constraints. The goal is to formalize the query using the semantics of conjunctive query evaluation over RDF graphs and to compute the number of distinct matching annotations in each of several test datasets.\n\nFoundational base and definitions to use:\n- Resource Description Framework (RDF): An RDF graph is a set of triples, each triple being an ordered tuple of subject, predicate, and object. Denote a graph by a set $G \\subseteq U \\times U \\times (U \\cup L \\cup B)$, where $U$ is the set of Uniform Resource Identifiers (URIs), $L$ is the set of literals, and $B$ is the set of blank nodes.\n- SPARQL basic graph patterns: A basic graph pattern is a finite set of triple patterns with variables. A solution mapping is a partial function $\\mu: V \\to (U \\cup L \\cup B)$, where $V$ is the set of variables. A triple pattern $(s,p,o)$ matches a triple $(s',p',o')$ under $\\mu$ if, for each component, either it is a constant equal to the constant in the triple or it is a variable $v \\in V$ and $\\mu(v)$ equals the corresponding component of the triple; variables may be unbound before matching and become bound during evaluation. A basic graph pattern evaluates to the set of mappings that satisfy all triple patterns conjunctively. Filters apply a boolean predicate on mappings. Projection selects specified variables, and DISTINCT yields set semantics over projected tuples.\n- Gene Ontology (GO): GO terms are categorized into three aspects: Molecular Function, Biological Process, and Cellular Component. The task focuses on filtering annotations by the Molecular Function aspect.\n- Evidence code: In GO, the code \"EXP\" denotes \"Inferred from Experiment\". Treat \"EXP\" as a specific constant in the data model.\n\nYour task:\n- Construct a SPARQL query that retrieves all distinct annotation nodes for which the evidence code is \"EXP\" and the associated GO term is in the Molecular Function namespace. Use the following simplified vocabulary (prefix \"ex:\" is implied for domain-specific terms):\n  - ex:Annotation (class for annotation nodes)\n  - rdf:type (type predicate)\n  - ex:hasEvidence (annotation to evidence code)\n  - ex:EXP (evidence code for \"Inferred from Experiment\")\n  - ex:hasGO (annotation to GO term)\n  - ex:hasAspect (GO term to aspect)\n  - ex:MolecularFunction, ex:BiologicalProcess, ex:CellularComponent (GO aspects)\n- You must justify each triple pattern and each filter by mapping it to a necessary biological or semantic constraint grounded in the above definitions.\n- Implement a program that evaluates your query over multiple test graphs under the formal semantics of basic graph patterns as homomorphisms. For this problem, you must treat FILTER isIRI on the annotation variable as a necessary filter to exclude blank node annotations, thereby ensuring reportable identifiers. Use projection on the annotation variable and DISTINCT to avoid duplicate reporting of the same annotation.\n\nFormal evaluation requirements:\n- Let $G$ be an RDF graph and let $P$ be the set of triple patterns in your query. Evaluation must proceed by constructing the set of solution mappings starting from the empty mapping and iteratively joining with matches of each triple pattern. Apply the FILTER condition $isIRI(?ann)$ to exclude mappings where the value bound to $?ann$ is not a URI. Project the variable $?ann$ and apply DISTINCT to form a set of unique annotation identifiers. The final result for a graph $G$ is the cardinality of this set, which is a nonnegative integer.\n\nData model for tests:\n- Each RDF triple is represented as a tuple of three strings. URIs are strings like \"ex:annA\" or \"rdf:type\". Blank nodes are strings starting with \"_:\". Literals are strings enclosed in double quotes (not used in this test suite). The graphs below are expressed in terms of these triples.\n\nTest suite:\n- There are $4$ test graphs. For each, compute the integer equal to the number of distinct annotation URIs returned by your query evaluation.\n\nTest graph $G_1$ (general case with mixed qualifying and non-qualifying annotations):\n- (\"ex:annA\",\"rdf:type\",\"ex:Annotation\")\n- (\"ex:annA\",\"ex:hasEvidence\",\"ex:EXP\")\n- (\"ex:annA\",\"ex:hasGO\",\"ex:GO_MF\")\n- (\"ex:GO_MF\",\"ex:hasAspect\",\"ex:MolecularFunction\")\n- (\"ex:annB\",\"rdf:type\",\"ex:Annotation\")\n- (\"ex:annB\",\"ex:hasEvidence\",\"ex:IDA\")\n- (\"ex:annB\",\"ex:hasGO\",\"ex:GO_MF\")\n- (\"ex:annC\",\"rdf:type\",\"ex:Annotation\")\n- (\"ex:annC\",\"ex:hasEvidence\",\"ex:EXP\")\n- (\"ex:annC\",\"ex:hasGO\",\"ex:GO_BP\")\n- (\"ex:GO_BP\",\"ex:hasAspect\",\"ex:BiologicalProcess\")\n- (\"ex:annD\",\"rdf:type\",\"ex:Annotation\")\n- (\"ex:annD\",\"ex:hasEvidence\",\"ex:EXP\")\n- (\"ex:annD\",\"ex:hasGO\",\"ex:GO_MF2\")\n- (\"ex:GO_MF2\",\"ex:hasAspect\",\"ex:MolecularFunction\")\n\nTest graph $G_2$ (boundary case with zero matches):\n- (\"ex:annE\",\"rdf:type\",\"ex:Annotation\")\n- (\"ex:annE\",\"ex:hasEvidence\",\"ex:IDA\")\n- (\"ex:annE\",\"ex:hasGO\",\"ex:GO_MF\")\n- (\"ex:GO_MF\",\"ex:hasAspect\",\"ex:MolecularFunction\")\n- (\"ex:annF\",\"rdf:type\",\"ex:Annotation\")\n- (\"ex:annF\",\"ex:hasEvidence\",\"ex:EXP\")\n\nTest graph $G_3$ (edge case with a blank node annotation and a GO term with multiple aspects):\n- (\"ex:annG\",\"rdf:type\",\"ex:Annotation\")\n- (\"ex:annG\",\"ex:hasEvidence\",\"ex:EXP\")\n- (\"ex:annG\",\"ex:hasGO\",\"ex:GO_MFCC\")\n- (\"_:b1\",\"rdf:type\",\"ex:Annotation\")\n- (\"_:b1\",\"ex:hasEvidence\",\"ex:EXP\")\n- (\"_:b1\",\"ex:hasGO\",\"ex:GO_MFCC\")\n- (\"ex:GO_MFCC\",\"ex:hasAspect\",\"ex:MolecularFunction\")\n- (\"ex:GO_MFCC\",\"ex:hasAspect\",\"ex:CellularComponent\")\n\nTest graph $G_4$ (edge case with multiple evidence statements and mixed aspects):\n- (\"ex:annH\",\"rdf:type\",\"ex:Annotation\")\n- (\"ex:annH\",\"ex:hasEvidence\",\"ex:EXP\")\n- (\"ex:annH\",\"ex:hasEvidence\",\"ex:IPI\")\n- (\"ex:annH\",\"ex:hasGO\",\"ex:GO_POISED\")\n- (\"ex:GO_POISED\",\"ex:hasAspect\",\"ex:MolecularFunction\")\n- (\"ex:annI\",\"rdf:type\",\"ex:Annotation\")\n- (\"ex:annI\",\"ex:hasEvidence\",\"ex:EXP\")\n- (\"ex:annI\",\"ex:hasGO\",\"ex:GO_BPONLY\")\n- (\"ex:GO_BPONLY\",\"ex:hasAspect\",\"ex:BiologicalProcess\")\n\nProgramming task and output specification:\n- Implement a complete program that:\n  - Constructs the SPARQL query string with appropriate PREFIX declarations, a SELECT DISTINCT clause on the annotation variable, the necessary triple patterns, and a FILTER ensuring $isIRI(?ann)$.\n  - Implements a basic graph pattern evaluator as described above to evaluate the query against each $G_i$.\n  - For each $G_i$, computes the integer equal to the number of distinct annotation URIs satisfying the query.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $[|Q(G_1)|,|Q(G_2)|,|Q(G_3)|,|Q(G_4)|]$, where $|Q(G_i)|$ denotes the cardinality of the distinct projected solutions for graph $G_i$.", "solution": "We begin from first principles of Resource Description Framework (RDF) graphs and Structured Query Language for RDF (SPARQL) evaluation. An RDF graph is a set $G \\subseteq U \\times U \\times (U \\cup L \\cup B)$, where $U$ is the set of Uniform Resource Identifiers (URIs), $L$ is the set of literals, and $B$ is the set of blank nodes. A SPARQL basic graph pattern is a finite set $P = \\{t_1,\\dots,t_k\\}$ of triple patterns, each $t_j$ being a triple over $(U \\cup V) \\times (U \\cup V) \\times (U \\cup L \\cup B \\cup V)$, where $V$ is the set of variables such that $V \\cap (U \\cup L \\cup B) = \\emptyset$. A solution mapping is a partial function $\\mu: V \\to (U \\cup L \\cup B)$.\n\nA triple pattern $t=(s,p,o)$ matches a triple $(s',p',o') \\in G$ under a mapping $\\mu$ if for each position we have either a constant equality (if the component is in $U \\cup L \\cup B$) or a variable $v \\in V$ such that either $v \\notin \\mathrm{dom}(\\mu)$ and we extend $\\mu$ by $\\{v \\mapsto s'\\}$ (or $p'$ or $o'$ as appropriate), or $v \\in \\mathrm{dom}(\\mu)$ and $\\mu(v)$ equals the corresponding component of the triple. The evaluation of a basic graph pattern $P$ over $G$ yields the set\n$$\n\\llbracket P \\rrbracket_G = \\{\\mu \\mid \\mu \\text{ is a mapping that makes all } t \\in P \\text{ simultaneously match some triples in } G\\}.\n$$\nA filter condition is a boolean predicate $\\phi$ over variables; applying FILTER keeps only those $\\mu \\in \\llbracket P \\rrbracket_G$ for which $\\phi(\\mu)$ evaluates to true. Projection on variables $W \\subseteq V$ yields the multiset or set (with DISTINCT) of tuples $\\mu|_W$. We will use DISTINCT to ensure set semantics over the projected solutions. The specific filter used is $isIRI(?ann)$, which enforces that $\\mu(?ann) \\in U$ and excludes $\\mu(?ann) \\in B$ or $\\mu(?ann) \\in L$.\n\nMapping the biological problem to triple patterns:\n- We require that the result is an annotation node. This is enforced by the pattern $t_1 = (?ann, rdf{:}type, ex{:}Annotation)$, which ensures that the subject bound to the variable $?ann$ is of type ex:Annotation.\n- We require that the annotation has experimental evidence code \"EXP\". This is enforced by the pattern $t_2 = (?ann, ex{:}hasEvidence, ex{:}EXP)$, using a constant object ex:EXP to match the \"Inferred from Experiment\" evidence code.\n- We require that the annotation refers to a Gene Ontology (GO) term. This is enforced by the pattern $t_3 = (?ann, ex{:}hasGO, ?go)$, which binds the variable $?go$ to the referenced GO term.\n- We require that the GO term is within the Molecular Function namespace (aspect). This is enforced by the pattern $t_4 = (?go, ex{:}hasAspect, ex{:}MolecularFunction)$.\n- We must ensure that the reported identifier is an Internationalized Resource Identifier (IRI), not a blank node, for downstream interoperability. This is enforced by the filter $\\mathrm{isIRI}(?ann)$, a predicate that accepts only $\\mu$ satisfying $\\mu(?ann) \\in U$.\n- We must avoid duplicates if multiple supporting triples could produce the same $?ann$ binding (for example, if a GO term had multiple aspects or the annotation had multiple statements that do not change $?ann$). Therefore, we use SELECT DISTINCT over $?ann$ so that the projection yields a set of unique annotation identifiers.\n\nPutting these elements together yields the SPARQL query structure:\n- PREFIX declarations for ex: and rdf:.\n- SELECT DISTINCT ?ann\n- WHERE with the conjunction of $t_1, t_2, t_3, t_4$ and FILTER isIRI(?ann).\n\nAlgorithmic evaluation design:\n- Let $P = [t_1, t_2, t_3, t_4]$ be the ordered list of triple patterns. We evaluate the basic graph pattern by iterative join:\n  1. Initialize the set of partial mappings $M_0 = \\{\\emptyset\\}$.\n  2. For $j = 1$ to $4$, compute\n     $$\n     M_j = \\{\\mu' \\mid \\mu \\in M_{j-1},\\ \\exists (s',p',o') \\in G: \\text{$t_j$ matches $(s',p',o')$ under $\\mu$ and $\\mu'$ is $\\mu$ extended consistently}\\}.\n     $$\n  3. Apply the filter: $M_f = \\{\\mu \\in M_4 \\mid \\mathrm{isIRI}(\\mu(?ann))\\}$.\n  4. Project on $?ann$ and apply DISTINCT to obtain $S = \\{\\mu(?ann) \\mid \\mu \\in M_f\\}$.\n  5. The result is the integer $\\lvert S \\rvert$.\n- The function $\\mathrm{isIRI}(x)$ is implemented as true if and only if $x$ is a string denoting a URI, which in our representation means it does not start with the blank node prefix \"_:\" and is not a quoted literal.\n\nCorrectness justification:\n- By RDF typing, $t_1$ restricts candidates to annotation resources, which is necessary to avoid conflating other nodes (such as GO terms or general resources) with annotations.\n- By evidence modeling, ex:hasEvidence with object ex:EXP precisely picks out annotations supported by experimental evidence, aligning with the intended Evidence and Conclusion Ontology (ECO) code \"EXP\".\n- By the structure of GO annotation, an annotation must refer to a GO term; $t_3$ binds this term to $?go$.\n- By the definition of GO aspects, ex:hasAspect ensures that only GO terms in the Molecular Function aspect are accepted; $t_4$ enforces the biological namespace constraint.\n- The filter $\\mathrm{isIRI}(?ann)$ enforces that results are in $U$, excluding blank nodes that cannot be dereferenced or globally referenced.\n- DISTINCT on $?ann$ ensures that the final set $S$ contains each annotation at most once even if multiple supporting triples would otherwise yield multiple solution mappings with the same $?ann$ binding; thus, the output reflects the count of unique annotations.\n\nApplying to the test suite:\n- For $G_1$, annotations ex:annA and ex:annD satisfy all patterns and the filter; ex:annB fails $t_2$ (evidence not ex:EXP) and ex:annC fails $t_4$ (aspect is BiologicalProcess). Thus $\\lvert S \\rvert = 2$.\n- For $G_2$, ex:annE fails $t_2$ (evidence not ex:EXP), and ex:annF fails $t_3$ (no GO term bound), so no mapping satisfies all patterns; thus $\\lvert S \\rvert = 0$.\n- For $G_3$, both ex:annG and the blank node \"_:b1\" satisfy the basic graph pattern, but the filter $\\mathrm{isIRI}(?ann)$ excludes the blank node, leaving only ex:annG; thus $\\lvert S \\rvert = 1$.\n- For $G_4$, ex:annH satisfies all patterns and the filter (multiple evidence statements include ex:EXP, and the GO term has aspect MolecularFunction), while ex:annI fails $t_4$ (aspect is BiologicalProcess). Thus $\\lvert S \\rvert = 1$.\n\nTherefore, the computed results in order $[|Q(G_1)|,|Q(G_2)|,|Q(G_3)|,|Q(G_4)|]$ are $[2, 0, 1, 1]$.\n\nThe program to be implemented constructs the SPARQL query string, evaluates the basic graph pattern with the filter and DISTINCT projection over each $G_i$, and prints the single-line output containing the four integers as a comma-separated list enclosed in square brackets.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nfrom typing import List, Tuple, Dict\n\nTriple = Tuple[str, str, str]\nMapping = Dict[str, str]\n\ndef is_variable(term: str) -> bool:\n    return term.startswith(\"?\")\n\ndef substitute(pattern: Tuple[str, str, str], mapping: Mapping) -> Tuple[str, str, str]:\n    s, p, o = pattern\n    s_sub = mapping.get(s, s) if is_variable(s) else s\n    p_sub = mapping.get(p, p) if is_variable(p) else p\n    o_sub = mapping.get(o, o) if is_variable(o) else o\n    return (s_sub, p_sub, o_sub)\n\ndef match_and_extend(pattern: Tuple[str, str, str], triple: Triple, mapping: Mapping) -> Mapping | None:\n    # Attempt to match pattern to triple under existing mapping; return extended mapping if consistent.\n    s_pat, p_pat, o_pat = pattern\n    s_tr, p_tr, o_tr = triple\n    new_mapping = dict(mapping)\n\n    # Helper to unify one component\n    def unify(pat: str, trm: str) -> bool:\n        if is_variable(pat):\n            if pat in new_mapping:\n                return new_mapping[pat] == trm\n            else:\n                new_mapping[pat] = trm\n                return True\n        else:\n            return pat == trm\n\n    if not unify(s_pat, s_tr):\n        return None\n    if not unify(p_pat, p_tr):\n        return None\n    if not unify(o_pat, o_tr):\n        return None\n    return new_mapping\n\ndef evaluate_bgp(graph: List[Triple], patterns: List[Tuple[str, str, str]]) -> List[Mapping]:\n    # Iterative join over triples for each pattern\n    mappings: List[Mapping] = [dict()]\n    for pat in patterns:\n        next_mappings: List[Mapping] = []\n        for m in mappings:\n            # Apply current mapping to pattern (for bound variables)\n            s, p, o = pat\n            s_eff = m.get(s, s) if is_variable(s) else s\n            p_eff = m.get(p, p) if is_variable(p) else p\n            o_eff = m.get(o, o) if is_variable(o) else o\n            eff_pat = (s_eff, p_eff, o_eff)\n            for triple in graph:\n                ext = match_and_extend(eff_pat, triple, m)\n                if ext is not None:\n                    next_mappings.append(ext)\n        mappings = next_mappings\n        if not mappings:\n            break\n    return mappings\n\ndef is_iri(value: str) -> bool:\n    # In our representation, IRIs are non-blank, non-literal strings.\n    if value.startswith(\"_:\"):\n        return False\n    if len(value) >= 2 and value.startswith('\"') and value.endswith('\"'):\n        return False\n    return True\n\ndef project_distinct(mappings: List[Mapping], vars_to_project: List[str]) -> List[Tuple[str, ...]]:\n    seen = set()\n    results: List[Tuple[str, ...]] = []\n    for m in mappings:\n        tup = tuple(m[v] for v in vars_to_project if v in m)\n        if len(tup) != len(vars_to_project):\n            # Skip mappings that do not bind all projected variables\n            continue\n        if tup not in seen:\n            seen.add(tup)\n            results.append(tup)\n    return results\n\ndef build_query_string() -> str:\n    # Construct the SPARQL query string as specified\n    prefixes = [\n        \"PREFIX ex: <http://example.org/ex#>\",\n        \"PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\"\n    ]\n    select = \"SELECT DISTINCT ?ann WHERE {\"\n    patterns = [\n        \"  ?ann rdf:type ex:Annotation .\",\n        \"  ?ann ex:hasEvidence ex:EXP .\",\n        \"  ?ann ex:hasGO ?go .\",\n        \"  ?go ex:hasAspect ex:MolecularFunction .\",\n        \"  FILTER isIRI(?ann)\"\n    ]\n    closing = \"}\"\n    return \"\\n\".join(prefixes + [select] + patterns + [closing])\n\ndef solve():\n    # Define the test cases from the problem statement.\n    G1: List[Triple] = [\n        (\"ex:annA\",\"rdf:type\",\"ex:Annotation\"),\n        (\"ex:annA\",\"ex:hasEvidence\",\"ex:EXP\"),\n        (\"ex:annA\",\"ex:hasGO\",\"ex:GO_MF\"),\n        (\"ex:GO_MF\",\"ex:hasAspect\",\"ex:MolecularFunction\"),\n        (\"ex:annB\",\"rdf:type\",\"ex:Annotation\"),\n        (\"ex:annB\",\"ex:hasEvidence\",\"ex:IDA\"),\n        (\"ex:annB\",\"ex:hasGO\",\"ex:GO_MF\"),\n        (\"ex:annC\",\"rdf:type\",\"ex:Annotation\"),\n        (\"ex:annC\",\"ex:hasEvidence\",\"ex:EXP\"),\n        (\"ex:annC\",\"ex:hasGO\",\"ex:GO_BP\"),\n        (\"ex:GO_BP\",\"ex:hasAspect\",\"ex:BiologicalProcess\"),\n        (\"ex:annD\",\"rdf:type\",\"ex:Annotation\"),\n        (\"ex:annD\",\"ex:hasEvidence\",\"ex:EXP\"),\n        (\"ex:annD\",\"ex:hasGO\",\"ex:GO_MF2\"),\n        (\"ex:GO_MF2\",\"ex:hasAspect\",\"ex:MolecularFunction\"),\n    ]\n\n    G2: List[Triple] = [\n        (\"ex:annE\",\"rdf:type\",\"ex:Annotation\"),\n        (\"ex:annE\",\"ex:hasEvidence\",\"ex:IDA\"),\n        (\"ex:annE\",\"ex:hasGO\",\"ex:GO_MF\"),\n        (\"ex:GO_MF\",\"ex:hasAspect\",\"ex:MolecularFunction\"),\n        (\"ex:annF\",\"rdf:type\",\"ex:Annotation\"),\n        (\"ex:annF\",\"ex:hasEvidence\",\"ex:EXP\"),\n    ]\n\n    G3: List[Triple] = [\n        (\"ex:annG\",\"rdf:type\",\"ex:Annotation\"),\n        (\"ex:annG\",\"ex:hasEvidence\",\"ex:EXP\"),\n        (\"ex:annG\",\"ex:hasGO\",\"ex:GO_MFCC\"),\n        (\"_:b1\",\"rdf:type\",\"ex:Annotation\"),\n        (\"_:b1\",\"ex:hasEvidence\",\"ex:EXP\"),\n        (\"_:b1\",\"ex:hasGO\",\"ex:GO_MFCC\"),\n        (\"ex:GO_MFCC\",\"ex:hasAspect\",\"ex:MolecularFunction\"),\n        (\"ex:GO_MFCC\",\"ex:hasAspect\",\"ex:CellularComponent\"),\n    ]\n\n    G4: List[Triple] = [\n        (\"ex:annH\",\"rdf:type\",\"ex:Annotation\"),\n        (\"ex:annH\",\"ex:hasEvidence\",\"ex:EXP\"),\n        (\"ex:annH\",\"ex:hasEvidence\",\"ex:IPI\"),\n        (\"ex:annH\",\"ex:hasGO\",\"ex:GO_POISED\"),\n        (\"ex:GO_POISED\",\"ex:hasAspect\",\"ex:MolecularFunction\"),\n        (\"ex:annI\",\"rdf:type\",\"ex:Annotation\"),\n        (\"ex:annI\",\"ex:hasEvidence\",\"ex:EXP\"),\n        (\"ex:annI\",\"ex:hasGO\",\"ex:GO_BPONLY\"),\n        (\"ex:GO_BPONLY\",\"ex:hasAspect\",\"ex:BiologicalProcess\"),\n    ]\n\n    test_cases = [G1, G2, G3, G4]\n\n    # Define the query as triple patterns and a filter\n    triple_patterns: List[Tuple[str, str, str]] = [\n        (\"?ann\", \"rdf:type\", \"ex:Annotation\"),\n        (\"?ann\", \"ex:hasEvidence\", \"ex:EXP\"),\n        (\"?ann\", \"ex:hasGO\", \"?go\"),\n        (\"?go\", \"ex:hasAspect\", \"ex:MolecularFunction\"),\n    ]\n\n    # Construct the SPARQL query string (not used for evaluation but built per problem)\n    _query_string = build_query_string()\n\n    results: List[int] = []\n    for G in test_cases:\n        mappings = evaluate_bgp(G, triple_patterns)\n        # Apply FILTER isIRI(?ann)\n        mappings = [m for m in mappings if (\"?ann\" in m and is_iri(m[\"?ann\"]))]\n        # Project and apply DISTINCT on ?ann\n        projected = project_distinct(mappings, [\"?ann\"])\n        results.append(len(projected))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "4543585"}, {"introduction": "A common output of a high-throughput experiment is a list of interesting genes, but this list alone offers little biological insight. This practice [@problem_id:4543495] guides you through the statistical machinery of gene set enrichment analysis, which tests whether certain biological functions are over-represented in your gene list. You will apply the hypergeometric test and learn the critical importance of correcting for multiple hypotheses to ensure your conclusions are statistically sound.", "problem": "A research team is studying differential expression results and seeks to evaluate biological process enrichment using the Gene Ontology (GO; Gene Ontology Consortium) within a curated experiment-specific universe. In this experiment, the analysis universe contains $N=20$ protein-coding genes, and the query gene set (significantly upregulated) contains $M=6$ genes. Six GO biological process terms are preselected based on prior knowledge, with the following annotation counts in the universe and observed overlaps with the query set: term $T_{1}$ has $K_{1}=8$ annotated genes with an observed overlap $x_{1}=4$; term $T_{2}$ has $K_{2}=7$ with $x_{2}=4$; term $T_{3}$ has $K_{3}=5$ with $x_{3}=3$; term $T_{4}$ has $K_{4}=10$ with $x_{4}=5$; term $T_{5}$ has $K_{5}=4$ with $x_{5}=2$; term $T_{6}$ has $K_{6}=9$ with $x_{6}=1$.\n\nStarting from the combinatorial model of sampling without replacement for annotation enrichment and the principle that the False Discovery Rate (FDR) is controlled by the Benjamini–Hochberg (BH) procedure (Benjamini and Hochberg), derive the one-sided enrichment $p$-values for each GO term as the probability of observing at least the reported overlap under the null hypothesis that the $M$ genes are drawn uniformly at random from the $N$-gene universe. Then, apply the BH procedure across the $m=6$ tests to obtain $q$-values, and determine which terms are significant at $q \\le 0.05$.\n\nReport as your final answer the total number of significant GO terms at $q \\le 0.05$. Express your final answer as a single real number. No rounding instruction is necessary for this count.", "solution": "The appropriate null model for over-representation testing of Gene Ontology (GO) terms is sampling without replacement from a finite universe. Under the null, drawing $M$ genes from a universe of $N$ genes with $K$ of them annotated to a given term is described by the hypergeometric distribution. The number of annotated genes $X$ observed among the $M$ draws has probability mass function\n$$\n\\Pr(X=t) \\;=\\; \\frac{\\binom{K}{t}\\,\\binom{N-K}{M-t}}{\\binom{N}{M}},\n$$\nfor integer $t$ with $0 \\le t \\le \\min\\{M,K\\}$ and $M-t \\le N-K$. A one-sided enrichment test considers the right tail,\n$$\np\\text{-value} \\;=\\; \\Pr(X \\ge x) \\;=\\; \\sum_{t=x}^{\\min\\{M,K\\}} \\frac{\\binom{K}{t}\\,\\binom{N-K}{M-t}}{\\binom{N}{M}},\n$$\nwhere $x$ is the observed overlap.\n\nWe are given $N=20$ and $M=6$, so the denominator for all terms is\n$$\n\\binom{N}{M} \\;=\\; \\binom{20}{6} \\;=\\; 38{,}760.\n$$\nWe now compute each term’s tail probability.\n\nTerm $T_{1}$ with $K_{1}=8$ and $x_{1}=4$ requires $t=4,5,6$:\n\\begin{align*}\n\\Pr(X \\ge 4) &= \\frac{\\binom{8}{4}\\binom{12}{2} + \\binom{8}{5}\\binom{12}{1} + \\binom{8}{6}\\binom{12}{0}}{\\binom{20}{6}} \\\\\n&= \\frac{70 \\cdot 66 + 56 \\cdot 12 + 28 \\cdot 1}{38{,}760} \\\\\n&= \\frac{4{,}620 + 672 + 28}{38{,}760} \\\\\n&= \\frac{5{,}320}{38{,}760} \\;=\\; \\frac{133}{969} \\approx 0.1372.\n\\end{align*}\n\nTerm $T_{2}$ with $K_{2}=7$ and $x_{2}=4$ uses $t=4,5,6$:\n\\begin{align*}\n\\Pr(X \\ge 4) &= \\frac{\\binom{7}{4}\\binom{13}{2} + \\binom{7}{5}\\binom{13}{1} + \\binom{7}{6}\\binom{13}{0}}{\\binom{20}{6}} \\\\\n&= \\frac{35 \\cdot 78 + 21 \\cdot 13 + 7 \\cdot 1}{38{,}760} \\\\\n&= \\frac{2{,}730 + 273 + 7}{38{,}760} \\\\\n&= \\frac{3{,}010}{38{,}760} \\;=\\; \\frac{301}{3{,}876} \\approx 0.0776.\n\\end{align*}\n\nTerm $T_{3}$ with $K_{3}=5$ and $x_{3}=3$ uses $t=3,4,5$:\n\\begin{align*}\n\\Pr(X \\ge 3) &= \\frac{\\binom{5}{3}\\binom{15}{3} + \\binom{5}{4}\\binom{15}{2} + \\binom{5}{5}\\binom{15}{1}}{\\binom{20}{6}} \\\\\n&= \\frac{10 \\cdot 455 + 5 \\cdot 105 + 1 \\cdot 15}{38{,}760} \\\\\n&= \\frac{4{,}550 + 525 + 15}{38{,}760} \\\\\n&= \\frac{5{,}090}{38{,}760} \\;=\\; \\frac{509}{3{,}876} \\approx 0.1313.\n\\end{align*}\n\nTerm $T_{4}$ with $K_{4}=10$ and $x_{4}=5$ uses $t=5,6$:\n\\begin{align*}\n\\Pr(X \\ge 5) &= \\frac{\\binom{10}{5}\\binom{10}{1} + \\binom{10}{6}\\binom{10}{0}}{\\binom{20}{6}} \\\\\n&= \\frac{252 \\cdot 10 + 210 \\cdot 1}{38{,}760} \\\\\n&= \\frac{2{,}520 + 210}{38{,}760} \\\\\n&= \\frac{2{,}730}{38{,}760} \\;=\\; \\frac{91}{1{,}292} \\approx 0.0704.\n\\end{align*}\n\nTerm $T_{5}$ with $K_{5}=4$ and $x_{5}=2$ uses $t=2,3,4$:\n\\begin{align*}\n\\Pr(X \\ge 2) &= \\frac{\\binom{4}{2}\\binom{16}{4} + \\binom{4}{3}\\binom{16}{3} + \\binom{4}{4}\\binom{16}{2}}{\\binom{20}{6}} \\\\\n&= \\frac{6 \\cdot 1{,}820 + 4 \\cdot 560 + 1 \\cdot 120}{38{,}760} \\\\\n&= \\frac{10{,}920 + 2{,}240 + 120}{38{,}760} \\\\\n&= \\frac{13{,}280}{38{,}760} \\;=\\; \\frac{332}{969} \\approx 0.3426.\n\\end{align*}\n\nTerm $T_{6}$ with $K_{6}=9$ and $x_{6}=1$ has a simpler complement form $\\Pr(X \\ge 1) = 1 - \\Pr(X=0)$:\n\\begin{align*}\n\\Pr(X \\ge 1) &= 1 - \\frac{\\binom{9}{0}\\binom{11}{6}}{\\binom{20}{6}} \\\\\n&= 1 - \\frac{462}{38{,}760} \\\\\n&= 1 - \\frac{77}{6{,}460} \\approx 1 - 0.0119 \\approx 0.9881.\n\\end{align*}\n\nCollect the six $p$-values (approximations shown for ordering): \n$$\np_{1} \\approx 0.1372,\\quad p_{2} \\approx 0.0776,\\quad p_{3} \\approx 0.1313,\\quad p_{4} \\approx 0.0704,\\quad p_{5} \\approx 0.3426,\\quad p_{6} \\approx 0.9881.\n$$\n\nApply the Benjamini–Hochberg (BH) procedure across $m=6$ hypotheses. First sort the $p$-values in ascending order, indexing them as $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(6)}$:\n$$\np_{(1)} = p_{4} \\approx 0.0704,\\quad\np_{(2)} = p_{2} \\approx 0.0776,\\quad\np_{(3)} = p_{3} \\approx 0.1313,\\quad\np_{(4)} = p_{1} \\approx 0.1372,\\quad\np_{(5)} = p_{5} \\approx 0.3426,\\quad\np_{(6)} = p_{6} \\approx 0.9881.\n$$\nDefine the initial BH transforms $r_{i} = \\frac{m}{i} p_{(i)}$ for $i=1,\\dots,6$:\n\\begin{align*}\nr_{1} &\\approx \\frac{6}{1} \\cdot 0.0704 \\approx 0.4224, \\\\\nr_{2} &\\approx \\frac{6}{2} \\cdot 0.0776 \\approx 0.2328, \\\\\nr_{3} &\\approx \\frac{6}{3} \\cdot 0.1313 \\approx 0.2626, \\\\\nr_{4} &\\approx \\frac{6}{4} \\cdot 0.1372 \\approx 0.2058, \\\\\nr_{5} &\\approx \\frac{6}{5} \\cdot 0.3426 \\approx 0.4111, \\\\\nr_{6} &\\approx \\frac{6}{6} \\cdot 0.9881 \\approx 0.9881.\n\\end{align*}\nNext, enforce monotonicity of the adjusted values by setting\n$$\nq_{(6)} = \\min\\{r_{6}, 1\\},\\quad q_{(i)} = \\min\\{r_{i}, q_{(i+1)}\\}\\ \\text{for}\\ i=5,4,3,2,1.\n$$\nThis yields\n\\begin{align*}\nq_{(6)} &\\approx 0.9881, \\\\\nq_{(5)} &\\approx \\min\\{0.4111,\\,0.9881\\} = 0.4111, \\\\\nq_{(4)} &\\approx \\min\\{0.2058,\\,0.4111\\} = 0.2058, \\\\\nq_{(3)} &\\approx \\min\\{0.2626,\\,0.2058\\} = 0.2058, \\\\\nq_{(2)} &\\approx \\min\\{0.2328,\\,0.2058\\} = 0.2058, \\\\\nq_{(1)} &\\approx \\min\\{0.4224,\\,0.2058\\} = 0.2058.\n\\end{align*}\nThus, all BH $q$-values are greater than $0.05$. Therefore, the number of significant GO terms at $q \\le 0.05$ is $0$.", "answer": "$$\\boxed{0}$$", "id": "4543495"}]}