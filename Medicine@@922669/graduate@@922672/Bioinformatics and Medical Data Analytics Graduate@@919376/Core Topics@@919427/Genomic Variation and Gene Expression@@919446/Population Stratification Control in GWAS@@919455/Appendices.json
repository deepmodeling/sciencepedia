{"hands_on_practices": [{"introduction": "To effectively control for population stratification, we must first understand its mechanism at a fundamental level. This practice guides you through a derivation from first principles, demonstrating mathematically how spurious associations can arise in a case-control study when underlying population structure is ignored [@problem_id:4596444]. By working through the hypothetical scenario presented, you will gain a concrete understanding of how differing allele frequencies and disease prevalences across subpopulations can create a statistical signal for a non-causal variant.", "problem": "Consider a Genome-Wide Association Study (GWAS) conducted under a case-control design in a source population composed of two subpopulations. Let the subpopulations be indexed by $i \\in \\{1,2\\}$. The mixing proportions of the subpopulations in the source population are $r_1$ and $r_2$, with $r_1 + r_2 = 1$ and $0 < r_i < 1$. The binary phenotype $Y \\in \\{0,1\\}$ has subpopulation-specific mean (prevalence) $\\mu_i = \\Pr(Y = 1 \\mid i)$, which may differ across subpopulations. A single nucleotide polymorphism (SNP) has a minor allele $A$ with subpopulation-specific allele frequencies $p_i = \\Pr(A \\mid i)$, which may also differ across subpopulations.\n\nAssume the SNP is non-causal for the phenotype, in the sense that within each subpopulation $i$, the SNP genotype is independent of the phenotype given the subpopulation label. Specifically, for $i \\in \\{1,2\\}$, assume $\\Pr(A \\mid Y, i) = \\Pr(A \\mid i) = p_i$. A case-control sample is drawn by sampling $n_1$ cases ($Y=1$) uniformly from all cases in the source population and $n_0$ controls ($Y=0$) uniformly from all controls in the source population, with $n_1, n_0$ large so that expectations coincide with population probabilities. In the subsequent analysis, population labels are ignored.\n\nDefine the expected spurious association for the non-causal SNP as the expected log-odds ratio comparing the allele $A$ frequency in cases versus controls that would be estimated by a simple allele-based logistic regression model ignoring subpopulation labels. Starting only from the laws of conditional probability, the law of total probability, and the case-control sampling scheme described above, derive a closed-form analytic expression for this expected log-odds ratio in terms of $r_1, r_2, \\mu_1, \\mu_2, p_1, p_2$.\n\nYour final answer must be a single closed-form analytic expression. No numerical approximation is required and no units are involved.", "solution": "The problem asks for the expected log-odds ratio for a non-causal SNP in a case-control study where population structure is ignored. The population is a mixture of two subpopulations, $i \\in \\{1,2\\}$, with mixing proportions $r_1, r_2$, subpopulation-specific disease prevalences $\\mu_i = \\Pr(Y=1 \\mid i)$, and subpopulation-specific allele frequencies $p_i = \\Pr(A \\mid i)$. The SNP is non-causal, meaning $\\Pr(A \\mid Y, i) = \\Pr(A \\mid i) = p_i$.\n\nThe expected log-odds ratio, which we denote as $\\text{log-OR}$, is defined based on the allele frequencies in the case population ($Y=1$) and the control population ($Y=0$). Let $P_{\\text{case}} = \\Pr(A \\mid Y=1)$ be the frequency of allele $A$ among all cases in the source population, and $P_{\\text{control}} = \\Pr(A \\mid Y=0)$ be the frequency of allele $A$ among all controls.\n\nThe odds of allele $A$ in cases is $\\frac{P_{\\text{case}}}{1 - P_{\\text{case}}}$.\nThe odds of allele $A$ in controls is $\\frac{P_{\\text{control}}}{1 - P_{\\text{control}}}$.\n\nThe odds ratio (OR) is the ratio of these two odds:\n$$\n\\text{OR} = \\frac{P_{\\text{case}} / (1 - P_{\\text{case}})}{P_{\\text{control}} / (1 - P_{\\text{control}})}\n$$\nThe quantity to be derived is the natural logarithm of this expression, $\\text{log-OR} = \\ln(\\text{OR})$. The derivation proceeds by first finding expressions for $P_{\\text{case}}$ and $P_{\\text{control}}$.\n\nFirst, we calculate the overall disease prevalence, $\\mu_{\\text{total}} = \\Pr(Y=1)$, in the source population using the law of total probability, summing over the subpopulations:\n$$\n\\mu_{\\text{total}} = \\Pr(Y=1) = \\sum_{i=1}^{2} \\Pr(Y=1 \\mid i) \\Pr(i) = \\mu_1 r_1 + \\mu_2 r_2\n$$\nSimilarly, the overall probability of being a control is:\n$$\n\\Pr(Y=0) = 1 - \\Pr(Y=1) = 1 - (\\mu_1 r_1 + \\mu_2 r_2)\n$$\n\nNow, we derive the allele frequency in cases, $P_{\\text{case}} = \\Pr(A \\mid Y=1)$. Using the law of total probability, conditioning on the subpopulation label $i$:\n$$\nP_{\\text{case}} = \\Pr(A \\mid Y=1) = \\sum_{i=1}^{2} \\Pr(A \\mid Y=1, i) \\Pr(i \\mid Y=1)\n$$\nThe problem states that the SNP is non-causal within each subpopulation, which is formally given as $\\Pr(A \\mid Y, i) = \\Pr(A \\mid i) = p_i$. Therefore, $\\Pr(A \\mid Y=1, i) = p_i$.\n\nNext, we find the probability that a case comes from subpopulation $i$, $\\Pr(i \\mid Y=1)$, using Bayes' theorem:\n$$\n\\Pr(i \\mid Y=1) = \\frac{\\Pr(Y=1 \\mid i) \\Pr(i)}{\\Pr(Y=1)} = \\frac{\\mu_i r_i}{\\mu_1 r_1 + \\mu_2 r_2}\n$$\nSubstituting these into the expression for $P_{\\text{case}}$:\n$$\nP_{\\text{case}} = \\sum_{i=1}^{2} p_i \\left( \\frac{\\mu_i r_i}{\\mu_1 r_1 + \\mu_2 r_2} \\right) = \\frac{p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2}{\\mu_1 r_1 + \\mu_2 r_2}\n$$\n\nNext, we derive the allele frequency in controls, $P_{\\text{control}} = \\Pr(A \\mid Y=0)$. The logic is analogous.\n$$\nP_{\\text{control}} = \\Pr(A \\mid Y=0) = \\sum_{i=1}^{2} \\Pr(A \\mid Y=0, i) \\Pr(i \\mid Y=0)\n$$\nAgain, due to the non-causal assumption, $\\Pr(A \\mid Y=0, i) = p_i$. We find the probability that a control comes from subpopulation $i$, $\\Pr(i \\mid Y=0)$, using Bayes' theorem:\n$$\n\\Pr(i \\mid Y=0) = \\frac{\\Pr(Y=0 \\mid i) \\Pr(i)}{\\Pr(Y=0)}\n$$\nSince $\\Pr(Y=0 \\mid i) = 1 - \\Pr(Y=1 \\mid i) = 1 - \\mu_i$, we have:\n$$\n\\Pr(i \\mid Y=0) = \\frac{(1 - \\mu_i) r_i}{1 - (\\mu_1 r_1 + \\mu_2 r_2)}\n$$\nSubstituting these into the expression for $P_{\\text{control}}$:\n$$\nP_{\\text{control}} = \\sum_{i=1}^{2} p_i \\left( \\frac{(1 - \\mu_i) r_i}{1 - (\\mu_1 r_1 + \\mu_2 r_2)} \\right) = \\frac{p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2}{1 - (\\mu_1 r_1 + \\mu_2 r_2)}\n$$\n\nNow we assemble the odds ratio. Let's first compute the odds for cases:\n$$\n\\frac{P_{\\text{case}}}{1 - P_{\\text{case}}} = \\frac{\\frac{p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2}{\\mu_1 r_1 + \\mu_2 r_2}}{1 - \\frac{p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2}{\\mu_1 r_1 + \\mu_2 r_2}} = \\frac{p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2}{(\\mu_1 r_1 + \\mu_2 r_2) - (p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2)} = \\frac{p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2}{(1-p_1)\\mu_1 r_1 + (1-p_2)\\mu_2 r_2}\n$$\nAnd the odds for controls:\n$$\n\\frac{P_{\\text{control}}}{1 - P_{\\text{control}}} = \\frac{\\frac{p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2}{1 - (\\mu_1 r_1 + \\mu_2 r_2)}}{1 - \\frac{p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2}{1 - (\\mu_1 r_1 + \\mu_2 r_2)}} = \\frac{p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2}{(1 - (\\mu_1 r_1 + \\mu_2 r_2)) - (p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2)}\n$$\nThe denominator simplifies to $(1-p_1)(1 - \\mu_1) r_1 + (1-p_2)(1 - \\mu_2) r_2$. So the odds for controls are:\n$$\n\\frac{P_{\\text{control}}}{1 - P_{\\text{control}}} = \\frac{p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2}{(1-p_1)(1 - \\mu_1) r_1 + (1-p_2)(1 - \\mu_2) r_2}\n$$\nThe odds ratio $\\text{OR}$ is the ratio of the odds in cases to the odds in controls:\n$$\n\\text{OR} = \\frac{\\frac{p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2}{(1-p_1)\\mu_1 r_1 + (1-p_2)\\mu_2 r_2}}{\\frac{p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2}{(1-p_1)(1 - \\mu_1) r_1 + (1-p_2)(1 - \\mu_2) r_2}}\n$$\n$$\n\\text{OR} = \\left( \\frac{p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2}{(1-p_1)\\mu_1 r_1 + (1-p_2)\\mu_2 r_2} \\right) \\left( \\frac{(1-p_1)(1 - \\mu_1) r_1 + (1-p_2)(1 - \\mu_2) r_2}{p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2} \\right)\n$$\nThe expected log-odds ratio is the natural logarithm of this expression. This spurious association arises when both allele frequencies ($p_1 \\neq p_2$) and disease prevalences ($\\mu_1 \\neq \\mu_2$) differ across subpopulations. If either $p_1 = p_2$ or $\\mu_1 = \\mu_2$, the expression for the OR simplifies to $1$, and the log-OR becomes $0$.\n\nThe final closed-form expression for the log-odds ratio is:\n$$\n\\text{log-OR} = \\ln \\left[ \\left( \\frac{p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2}{(1-p_1)\\mu_1 r_1 + (1-p_2)\\mu_2 r_2} \\right) \\left( \\frac{(1-p_1)(1 - \\mu_1) r_1 + (1-p_2)(1 - \\mu_2) r_2}{p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2} \\right) \\right]\n$$\nThis expression can also be written as a sum of logarithms:\n$$\n\\text{log-OR} = \\ln(p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2) + \\ln((1-p_1)(1 - \\mu_1) r_1 + (1-p_2)(1 - \\mu_2) r_2) - \\ln((1-p_1)\\mu_1 r_1 + (1-p_2)\\mu_2 r_2) - \\ln(p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2)\n$$\nBoth forms are equivalent. The first form is more compact.", "answer": "$$\n\\boxed{\\ln\\left(\\frac{\\left(p_1 \\mu_1 r_1 + p_2 \\mu_2 r_2\\right)\\left((1-p_1)(1 - \\mu_1) r_1 + (1-p_2)(1 - \\mu_2) r_2\\right)}{\\left((1-p_1)\\mu_1 r_1 + (1-p_2)\\mu_2 r_2\\right)\\left(p_1 (1 - \\mu_1) r_1 + p_2 (1 - \\mu_2) r_2\\right)}\\right)}\n$$", "id": "4596444"}, {"introduction": "Having established how stratification can induce false positives, we now turn to a core component of modern control methods: the Genetic Relationship Matrix (GRM). The GRM is the cornerstone of Linear Mixed Models (LMMs), which account for the subtle, continuous degrees of relatedness among all individuals in a study. This exercise provides direct, hands-on experience in constructing a GRM from raw genotype data, emphasizing the critical role of variance standardization in ensuring that each genetic marker contributes equitably to the final estimate of relatedness [@problem_id:4596615].", "problem": "A Genome-Wide Association Study (GWAS) seeks to control population stratification by modeling phenotypes with a Linear Mixed Model (LMM), where the random genetic effect has covariance proportional to a Genetic Relationship Matrix (GRM). The GRM should reflect realized genomic relatedness in a way that is comparable across genetic markers with different allele frequencies, under a scientifically reasonable generative model for genotypes.\n\nAssume the following setting. There are $N = 3$ individuals and $M = 3$ independent biallelic single-nucleotide polymorphisms (SNPs), coded as minor-allele counts $x_{im} \\in \\{0,1,2\\}$ for individual $i \\in \\{1,2,3\\}$ and marker $m \\in \\{1,2,3\\}$. For each marker $m$, the sample minor-allele frequency is defined as $p_m = \\frac{1}{2N}\\sum_{i=1}^{N} x_{im}$. Under Hardy–Weinberg Equilibrium (HWE), the genotype $X_m$ at marker $m$ has mean $2p_m$ and variance $2p_m(1 - p_m)$. The GRM is constructed as the empirical average of outer products of variance-standardized genotype vectors across markers.\n\nYou are given the genotype data for the $M=3$ SNPs:\n- For marker $m=1$: $\\mathbf{x}_1 = \\begin{pmatrix}2 \\\\ 1 \\\\ 0\\end{pmatrix}$.\n- For marker $m=2$: $\\mathbf{x}_2 = \\begin{pmatrix}0 \\\\ 1 \\\\ 1\\end{pmatrix}$.\n- For marker $m=3$: $\\mathbf{x}_3 = \\begin{pmatrix}1 \\\\ 0 \\\\ 2\\end{pmatrix}$.\n\nTasks:\n1. Using the variance-standardized genotype construction justified by HWE, compute the full $3 \\times 3$ Genetic Relationship Matrix $\\mathbf{K}$ for these $N=3$ individuals as an exact expression with rational entries. Do not round; provide the exact rational values.\n2. Starting from the Hardy–Weinberg Equilibrium model and the requirement that each marker contribute equally in expectation to realized relatedness, justify mathematically why allele-frequency-based variance standardization is the appropriate weighting to use when constructing $\\mathbf{K}$ in the LMM for GWAS.\n\nYour final answer must be the single matrix $\\mathbf{K}$, expressed with exact rational entries, and no rounding. No units are required.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It describes a standard bioinformatics procedure for constructing a Genetic Relationship Matrix (GRM) for use in a Linear Mixed Model (LMM) to control for population stratification in a Genome-Wide Association Study (GWAS). All necessary data and definitions are provided, and the task is a direct, formalizable application of these principles. The problem is therefore deemed **valid**.\n\nThe solution is divided into two parts, corresponding to the two tasks. Task 2, the theoretical justification, is presented first as it establishes the foundation for the calculation in Task 1.\n\n### Task 2: Justification for Variance Standardization\n\nThe objective is to construct a Genetic Relationship Matrix, $\\mathbf{K}$, such that each genetic marker $m$ contributes equally in expectation to the estimate of realized relatedness. The GRM is constructed as the average of contributions from $M$ markers. The contribution of a single marker $m$ to the relationship between individuals $i$ and $j$ is based on their genotypes, $x_{im}$ and $x_{jm}$.\n\nLet $\\mathbf{x}_m$ be the column vector of genotype counts for marker $m$. These counts are coded as $x_{im} \\in \\{0, 1, 2\\}$ representing the number of minor alleles for individual $i$ at marker $m$. The problem states that under Hardy–Weinberg Equilibrium (HWE), and using the sample minor-allele frequency $p_m$ as an estimate for the population frequency, the genotype variable $X_m$ has a mean $E[X_m] = 2p_m$ and a variance $Var(X_m) = 2p_m(1-p_m)$.\n\nThe variance of a marker's genotypes, $2p_m(1-p_m)$, is a function of its allele frequency $p_m$. Markers with intermediate allele frequencies (i.e., $p_m$ close to $0.5$) have higher variance than markers with rare alleles (i.e., $p_m$ close to $0$ or $1$). If we were to use the raw, unstandardized genotypes to compute relatedness, markers with higher variance would disproportionately influence the final GRM. This is undesirable as the relatedness should be an aggregate measure over the entire genome, not dominated by a subset of high-variance markers.\n\nTo ensure each marker contributes equally, we must standardize the genotype values. A standard approach is to transform the genotype variable for each marker to have a mean of $0$ and a variance of $1$. Let $Z_{im}$ be the standardized genotype for individual $i$ at marker $m$:\n$$\nZ_{im} = \\frac{x_{im} - E[X_m]}{\\sqrt{Var(X_m)}} = \\frac{x_{im} - 2p_m}{\\sqrt{2p_m(1-p_m)}}\n$$\nBy construction, for any marker $m$, the standardized variable $Z_m$ has an expected value of $E[Z_m] = 0$ and an expected variance of $Var(Z_m) = 1$. The second moment is therefore $E[Z_m^2] = Var(Z_m) + (E[Z_m])^2 = 1 + 0^2 = 1$.\n\nThe GRM, $\\mathbf{K}$, is defined as the empirical average of the outer products of these standardized genotype vectors. Let $\\mathbf{z}_m$ be the column vector of standardized genotypes for marker $m$. The entry $K_{ij}$ of the GRM is:\n$$\nK_{ij} = \\frac{1}{M} \\sum_{m=1}^{M} z_{im} z_{jm}\n$$\nThe contribution of each marker to the diagonal elements of $\\mathbf{K}$, which represent self-relatedness or inbreeding, is $z_{im}^2$. The expected contribution is $E[z_{im}^2]$. As shown above, treating the genotypes as random variables, $E[Z_{im}^2]=1$ for all markers $m$. Therefore, the expected contribution of any marker to the diagonal of the GRM is identical and independent of its allele frequency $p_m$.\n\nThis standardization places all markers on an equal footing, fulfilling the requirement that \"each marker contribute equally in expectation to realized relatedness\". This prevents common variants from dominating the kinship estimate and ensures that shared rare variants, which can be highly informative about recent co-ancestry, are appropriately weighted. This method of constructing $\\mathbf{K}$ from variance-standardized genotypes is a cornerstone of modern LMM-based GWAS analysis.\n\n### Task 1: Computation of the Genetic Relationship Matrix $\\mathbf{K}$\n\nThe GRM $\\mathbf{K}$ is given by the formula:\n$$\n\\mathbf{K} = \\frac{1}{M} \\sum_{m=1}^{M} \\frac{(\\mathbf{x}_m - 2p_m\\mathbf{1})(\\mathbf{x}_m - 2p_m\\mathbf{1})^T}{2p_m(1-p_m)}\n$$\nwhere $M=3$ is the number of markers, $\\mathbf{x}_m$ is the genotype vector for marker $m$, $p_m$ is the sample minor-allele frequency, and $\\mathbf{1}$ is a vector of ones. We compute the contribution for each marker individually.\n\n**Marker $m=1$**:\nThe genotype vector is $\\mathbf{x}_1 = \\begin{pmatrix}2 \\\\ 1 \\\\ 0\\end{pmatrix}$.\nThe number of individuals is $N=3$.\nThe sample minor-allele frequency is $p_1 = \\frac{1}{2N}\\sum_{i=1}^{N} x_{i1} = \\frac{1}{2 \\cdot 3}(2+1+0) = \\frac{3}{6} = \\frac{1}{2}$.\nThe mean is $\\mu_1 = 2p_1 = 2 \\left(\\frac{1}{2}\\right) = 1$.\nThe variance is $\\sigma_1^2 = 2p_1(1-p_1) = 2 \\left(\\frac{1}{2}\\right) \\left(1-\\frac{1}{2}\\right) = \\frac{1}{2}$.\nThe centered genotype vector is $\\mathbf{y}_1 = \\mathbf{x}_1 - \\mu_1\\mathbf{1} = \\begin{pmatrix}2-1 \\\\ 1-1 \\\\ 0-1\\end{pmatrix} = \\begin{pmatrix}1 \\\\ 0 \\\\ -1\\end{pmatrix}$.\nThe contribution from marker $1$ is $\\mathbf{K}_1 = \\frac{\\mathbf{y}_1 \\mathbf{y}_1^T}{\\sigma_1^2} = \\frac{1}{1/2} \\begin{pmatrix}1 \\\\ 0 \\\\ -1\\end{pmatrix} \\begin{pmatrix}1 & 0 & -1\\end{pmatrix} = 2 \\begin{pmatrix}1 & 0 & -1 \\\\ 0 & 0 & 0 \\\\ -1 & 0 & 1\\end{pmatrix} = \\begin{pmatrix}2 & 0 & -2 \\\\ 0 & 0 & 0 \\\\ -2 & 0 & 2\\end{pmatrix}$.\n\n**Marker $m=2$**:\nThe genotype vector is $\\mathbf{x}_2 = \\begin{pmatrix}0 \\\\ 1 \\\\ 1\\end{pmatrix}$.\nThe sample minor-allele frequency is $p_2 = \\frac{1}{2 \\cdot 3}(0+1+1) = \\frac{2}{6} = \\frac{1}{3}$.\nThe mean is $\\mu_2 = 2p_2 = 2 \\left(\\frac{1}{3}\\right) = \\frac{2}{3}$.\nThe variance is $\\sigma_2^2 = 2p_2(1-p_2) = 2 \\left(\\frac{1}{3}\\right) \\left(1-\\frac{1}{3}\\right) = 2 \\left(\\frac{1}{3}\\right) \\left(\\frac{2}{3}\\right) = \\frac{4}{9}$.\nThe centered genotype vector is $\\mathbf{y}_2 = \\mathbf{x}_2 - \\mu_2\\mathbf{1} = \\begin{pmatrix}0 - 2/3 \\\\ 1 - 2/3 \\\\ 1 - 2/3\\end{pmatrix} = \\begin{pmatrix}-2/3 \\\\ 1/3 \\\\ 1/3\\end{pmatrix}$.\nThe contribution from marker $2$ is $\\mathbf{K}_2 = \\frac{\\mathbf{y}_2 \\mathbf{y}_2^T}{\\sigma_2^2} = \\frac{1}{4/9} \\begin{pmatrix}-2/3 \\\\ 1/3 \\\\ 1/3\\end{pmatrix} \\begin{pmatrix}-2/3 & 1/3 & 1/3\\end{pmatrix} = \\frac{9}{4} \\begin{pmatrix}4/9 & -2/9 & -2/9 \\\\ -2/9 & 1/9 & 1/9 \\\\ -2/9 & 1/9 & 1/9\\end{pmatrix} = \\begin{pmatrix}1 & -1/2 & -1/2 \\\\ -1/2 & 1/4 & 1/4 \\\\ -1/2 & 1/4 & 1/4\\end{pmatrix}$.\n\n**Marker $m=3$**:\nThe genotype vector is $\\mathbf{x}_3 = \\begin{pmatrix}1 \\\\ 0 \\\\ 2\\end{pmatrix}$.\nThe sample minor-allele frequency is $p_3 = \\frac{1}{2 \\cdot 3}(1+0+2) = \\frac{3}{6} = \\frac{1}{2}$.\nThe mean is $\\mu_3 = 2p_3 = 2 \\left(\\frac{1}{2}\\right) = 1$.\nThe variance is $\\sigma_3^2 = 2p_3(1-p_3) = 2 \\left(\\frac{1}{2}\\right) \\left(1-\\frac{1}{2}\\right) = \\frac{1}{2}$.\nThe centered genotype vector is $\\mathbf{y}_3 = \\mathbf{x}_3 - \\mu_3\\mathbf{1} = \\begin{pmatrix}1-1 \\\\ 0-1 \\\\ 2-1\\end{pmatrix} = \\begin{pmatrix}0 \\\\ -1 \\\\ 1\\end{pmatrix}$.\nThe contribution from marker $3$ is $\\mathbf{K}_3 = \\frac{\\mathbf{y}_3 \\mathbf{y}_3^T}{\\sigma_3^2} = \\frac{1}{1/2} \\begin{pmatrix}0 \\\\ -1 \\\\ 1\\end{pmatrix} \\begin{pmatrix}0 & -1 & 1\\end{pmatrix} = 2 \\begin{pmatrix}0 & 0 & 0 \\\\ 0 & 1 & -1 \\\\ 0 & -1 & 1\\end{pmatrix} = \\begin{pmatrix}0 & 0 & 0 \\\\ 0 & 2 & -2 \\\\ 0 & -2 & 2\\end{pmatrix}$.\n\n**Final GRM Calculation**:\nNow, we sum the contributions and divide by $M=3$.\n$$\n\\mathbf{K} = \\frac{1}{3} (\\mathbf{K}_1 + \\mathbf{K}_2 + \\mathbf{K}_3)\n$$\n$$\n\\mathbf{K} = \\frac{1}{3} \\left( \\begin{pmatrix}2 & 0 & -2 \\\\ 0 & 0 & 0 \\\\ -2 & 0 & 2\\end{pmatrix} + \\begin{pmatrix}1 & -1/2 & -1/2 \\\\ -1/2 & 1/4 & 1/4 \\\\ -1/2 & 1/4 & 1/4\\end{pmatrix} + \\begin{pmatrix}0 & 0 & 0 \\\\ 0 & 2 & -2 \\\\ 0 & -2 & 2\\end{pmatrix} \\right)\n$$\nSumming the matrices inside the parentheses:\n$$\n\\mathbf{K}_1 + \\mathbf{K}_2 + \\mathbf{K}_3 = \\begin{pmatrix} 2+1+0 & 0-1/2+0 & -2-1/2+0 \\\\ 0-1/2+0 & 0+1/4+2 & 0+1/4-2 \\\\ -2-1/2+0 & 0+1/4-2 & 2+1/4+2 \\end{pmatrix} = \\begin{pmatrix} 3 & -1/2 & -5/2 \\\\ -1/2 & 9/4 & -7/4 \\\\ -5/2 & -7/4 & 17/4 \\end{pmatrix}\n$$\nFinally, multiplying by $\\frac{1}{3}$:\n$$\n\\mathbf{K} = \\frac{1}{3} \\begin{pmatrix} 3 & -1/2 & -5/2 \\\\ -1/2 & 9/4 & -7/4 \\\\ -5/2 & -7/4 & 17/4 \\end{pmatrix} = \\begin{pmatrix} 1 & -1/6 & -5/6 \\\\ -1/6 & 3/4 & -7/12 \\\\ -5/6 & -7/12 & 17/12 \\end{pmatrix}\n$$\nThis is the final Genetic Relationship Matrix $\\mathbf{K}$.", "answer": "$$\n\\boxed{\\begin{pmatrix}\n1 & -\\frac{1}{6} & -\\frac{5}{6} \\\\\n-\\frac{1}{6} & \\frac{3}{4} & -\\frac{7}{12} \\\\\n-\\frac{5}{6} & -\\frac{7}{12} & \\frac{17}{12}\n\\end{pmatrix}}\n$$", "id": "4596615"}, {"introduction": "While LMMs provide a powerful framework for control, another common approach involves adjusting for top principal components (PCs) of the genotype data as fixed-effect covariates. However, this method is not without its own subtleties. This problem explores an advanced topic in causal inference known as collider bias, which can arise when the variant being tested itself influences the PCs used for adjustment [@problem_id:4596404]. By analyzing the provided causal model, you will learn to identify the conditions that lead to this bias and understand the rationale behind advanced techniques like Leave-One-Chromosome-Out (LOCO) PCs, which are designed to mitigate this issue.", "problem": "A Genome-Wide Association Study (GWAS) tests whether a single-nucleotide polymorphism (SNP) $X$ is associated with a quantitative phenotype $Y$, controlling for population structure by including principal components (PCs) $P$ derived from Principal Component Analysis (PCA) of genome-wide genotypes. Consider a causal data-generating process with an unobserved ancestry variable $A$ that affects both genotype and phenotype. Use the following structural equations and causal relations as the fundamental base for reasoning: ancestry $A$ influences allele frequencies of the tested variant $X$ and the phenotype $Y$, and PCs $P$ summarize genome-wide genetic variation. Formally, assume\n$$\nX = \\lambda_A A + \\varepsilon_X\n$$\n$$\nY = \\beta_X X + \\beta_A A + \\varepsilon_Y\n$$\n$$\nP = \\gamma_A A + \\gamma_X X + \\varepsilon_P\n$$\nwhere $\\varepsilon_X$, $\\varepsilon_Y$, and $\\varepsilon_P$ are mutually independent noise terms with zero mean. The above implies a Directed Acyclic Graph (DAG) in which $A \\rightarrow X$, $A \\rightarrow Y$, $A \\rightarrow P$, and $X \\rightarrow P$, with a possible $X \\rightarrow Y$ effect to be estimated. In practice, one often fits a linear regression $Y$ on $X$ and $P$ to adjust for population structure:\n$$\nY = \\theta_X X + \\theta_P P + \\varepsilon\n$$\nand interprets $\\theta_X$ as an adjusted association between $X$ and $Y$. From first principles about collider variables and linear regression decomposition, analyze the consequences of conditioning on $P$ when $P$ is influenced by both $A$ and $X$, and consider how Leave-One-Chromosome-Out (LOCO) PCs—computed by performing PCA on genome-wide genotypes excluding all variants on the chromosome containing $X$—change these consequences.\n\nWhich of the following statements are correct?\n\nA. Conditioning on $P$ can introduce collider bias because $P$ is a common effect of $A$ and $X$, and regression adjustment on $P$ can open a spurious path $X \\leftrightarrow P \\leftrightarrow A \\rightarrow Y$; computing PCs in a LOCO manner reduces or removes the $X \\rightarrow P$ dependence for the tested $X$, mitigating this collider.\n\nB. Conditioning on $P$ cannot introduce bias in $\\theta_X$ because PCs are unsupervised summaries and no single variant $X$ can influence them; therefore LOCO PCs are unnecessary.\n\nC. Collider bias would only arise if $Y$ directly influenced $P$; since $Y$ does not cause $P$ by construction, regressing on $P$ is unbiased with respect to $\\theta_X$, and the LOCO approach is unrelated to bias control.\n\nD. The bias in $\\theta_X$ under adjustment by $P$ depends on the loading of $X$ on $P$ and the projection of $A$ onto $P$; LOCO PCs reduce the loading of the tested $X$ onto $P$ while retaining ancestry capture via $A$, thereby reducing bias without discarding population structure adjustment.\n\nE. The only way to avoid collider bias from $P$ is to avoid any PC adjustment entirely; LOCO PCs cannot mitigate collider bias because they still condition on a descendant of $A$.\n\nSelect all correct options.", "solution": "The user has provided a problem concerning the use of Principal Components (PCs) to control for population stratification in Genome-Wide Association Studies (GWAS) and the potential for collider bias, along with a proposed mitigation strategy using Leave-One-Chromosome-Out (LOCO) PCs.\n\n### Step 1: Extract Givens\n-   **Topic:** Genome-Wide Association Study (GWAS) testing the association between a single-nucleotide polymorphism (SNP) $X$ and a quantitative phenotype $Y$.\n-   **Control Variable:** Principal components ($P$) derived from PCA on genome-wide genotypes.\n-   **Unobserved Variable:** An ancestry variable $A$.\n-   **Structural Equations / Causal Model:**\n    1.  $X = \\lambda_A A + \\varepsilon_X$\n    2.  $Y = \\beta_X X + \\beta_A A + \\varepsilon_Y$\n    3.  $P = \\gamma_A A + \\gamma_X X + \\varepsilon_P$\n-   **Assumptions:** $\\varepsilon_X$, $\\varepsilon_Y$, and $\\varepsilon_P$ are mutually independent, zero-mean noise terms.\n-   **Implied Directed Acyclic Graph (DAG):** From the equations, the causal structure is:\n    -   $A \\rightarrow X$ (Ancestry influences allele frequency)\n    -   $A \\rightarrow Y$ (Ancestry influences phenotype, e.g., through environment or other genetic factors)\n    -   $A \\rightarrow P$ (Ancestry is the primary driver of major PCs)\n    -   $X \\rightarrow P$ (The SNP being tested is part of the genotype matrix used to compute PCs)\n    -   $X \\rightarrow Y$ (The direct genetic effect to be estimated, with coefficient $\\beta_X$)\n-   **Statistical Model:** A linear regression is fitted: $Y = \\theta_X X + \\theta_P P + \\varepsilon$.\n-   **Parameter of Interest:** $\\theta_X$ is used as an estimate of the true effect $\\beta_X$.\n-   **Proposed Method:** Leave-One-Chromosome-Out (LOCO) PCs, where PCs are computed excluding all variants on the chromosome containing $X$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is critically evaluated.\n\n-   **Scientifically Grounded:** The problem is firmly grounded in statistical genetics and causal inference. The issue of population stratification is a cornerstone of GWAS methodology. The use of PCs is the standard approach to control for it. The potential for the test SNP to influence the PCs, thereby creating a subtle bias (often termed \"proximal contamination\" or a form of collider bias), is a known and well-documented issue in the field. The provided structural equations and the corresponding DAG are a valid and standard way to formalize and analyze this problem. The LOCO-PC approach is a published and recognized method to address this specific issue. The problem is scientifically sound.\n-   **Well-Posed:** The problem is well-posed. It provides a clear causal model and a specific statistical procedure. The question asks for an analysis of the consequences based on established principles of causal inference (d-separation, collider bias) and linear regression. A unique, reasoned conclusion about the validity of the provided statements can be derived.\n-   **Objective:** The language is formal, precise, and objective, using standard terminology from statistics and genetics.\n\nThe problem statement has no identifiable flaws. It is not unsound, incomplete, ambiguous, or trivial. It represents a valid and non-trivial challenge in the analysis of biomedical data.\n\n### Step 3: Verdict and Action\nThe problem is valid. The solution will proceed by analyzing the causal model and then evaluating each option.\n\n### Derivation from First Principles\n\nThe objective is to obtain an unbiased estimate of $\\beta_X$, the true causal effect of SNP $X$ on phenotype $Y$, as specified by the equation $Y = \\beta_X X + \\beta_A A + \\varepsilon_Y$.\n\nThe unobserved variable $A$ is a confounder because it is a common cause of both $X$ and $Y$. This is evident from the backdoor path $X \\leftarrow A \\rightarrow Y$ in the causal graph. If this path is not blocked, the estimated association between $X$ and $Y$ will be a mixture of the true causal effect $\\beta_X$ and the spurious association flowing through this path.\n\nThe standard procedure is to condition on PCs, $P$, in a regression model: $Y \\sim \\theta_X X + \\theta_P P$. The hope is that conditioning on $P$ will block the confounding path. Since $A \\rightarrow P$, $P$ is a proxy for $A$, and conditioning on it can indeed help block the $X \\leftarrow A \\rightarrow Y$ path.\n\nHowever, the problem statement specifies that $P = \\gamma_A A + \\gamma_X X + \\varepsilon_P$. This means $P$ is a \"collider\" or a \"common effect\" of $A$ and $X$, as represented by the converging arrows $X \\rightarrow P \\leftarrow A$ in the DAG.\n\nAccording to the rules of d-separation in causal inference, conditioning on a collider (or a descendant of a collider) opens the path between its parents. In our case, conditioning on $P$ in the regression opens the path between $X$ and $A$. This creates a new, non-causal path from $X$ to $Y$ that was previously blocked: $X \\rightarrow P \\leftarrow A \\rightarrow Y$.\n\nSpurious association flows along this newly opened path, introducing a bias in the estimate $\\theta_X$. This is known as collider bias. The magnitude of this bias is a function of the path coefficients: the strength of the $X \\rightarrow P$ link ($\\gamma_X$), the strength of the $A \\rightarrow P$ link ($\\gamma_A$), and the strength of the $A \\rightarrow Y$ link ($\\beta_A$).\n\nNow, consider the Leave-One-Chromosome-Out (LOCO) approach. Let's denote the LOCO PCs as $P_{loco}$. These PCs are calculated from genome-wide genetic data *excluding* the chromosome on which the test SNP $X$ resides. Due to the assumption of linkage equilibrium between non-homologous chromosomes, the genotype of $X$ is conditionally independent of the genotypes on other chromosomes, given ancestry $A$. This means that $X$ has no direct causal influence on $P_{loco}$.\n\nThe structural equation for $P_{loco}$ is therefore approximately:\n$$\nP_{loco} = \\gamma'_A A + \\varepsilon'_{P_{loco}}\n$$\nThe key change is that the term $\\gamma_X X$ is absent, meaning the coefficient corresponding to $\\gamma_X$ is effectively zero. In the DAG, this corresponds to removing the edge $X \\rightarrow P_{loco}$.\n\nWith this modification, $P_{loco}$ is no longer a collider on a path between $X$ and $A$. It is simply a child of $A$ ($A \\rightarrow P_{loco}$). When we now fit the regression $Y \\sim \\theta_X X + \\theta'_{P} P_{loco}$, conditioning on $P_{loco}$ serves its original purpose: to partially block the confounding path $X \\leftarrow A \\rightarrow Y$ by conditioning on a proxy for $A$. Crucially, it no longer opens the spurious collider path because $P_{loco}$ is not a collider between $X$ and $A$.\n\nTherefore, the LOCO approach mitigates the collider bias present when using standard PCs, leading to a less biased estimate of $\\beta_X$.\n\n### Option-by-Option Analysis\n\n**A. Conditioning on $P$ can introduce collider bias because $P$ is a common effect of $A$ and $X$, and regression adjustment on $P$ can open a spurious path $X \\leftrightarrow P \\leftrightarrow A \\rightarrow Y$; computing PCs in a LOCO manner reduces or removes the $X \\rightarrow P$ dependence for the tested $X$, mitigating this collider.**\nThis statement is fully consistent with the derivation above.\n-   $P$ is a common effect (collider) of $A$ and $X$, as defined by the structural equations ($A \\rightarrow P$ and $X \\rightarrow P$).\n-   Conditioning on the collider $P$ opens a spurious path between $X$ and $Y$ through $A$. The notation $X \\leftrightarrow P \\leftrightarrow A \\rightarrow Y$ captures the essence of this opened path.\n-   The LOCO procedure, by construction, computes PCs on data that does not include $X$, thereby breaking or severely weakening the $X \\rightarrow P$ link.\n-   By breaking this link, $P$ is no longer a collider between $X$ and $A$, and the specific collider bias is mitigated.\n**Verdict:** **Correct**.\n\n**B. Conditioning on $P$ cannot introduce bias in $\\theta_X$ because PCs are unsupervised summaries and no single variant $X$ can influence them; therefore LOCO PCs are unnecessary.**\nThis statement contains a critical factual error.\n-   While the influence of a single SNP $X$ on a top PC is small, it is not zero in theory or in practice. The parameter $\\gamma_X$ in the model is generally non-zero. The problem is exacerbated when considering the combined influence of all SNPs in linkage disequilibrium with $X$ on the same chromosome. The premise that \"no single variant $X$ can influence them\" is false.\n-   The fact that PCA is \"unsupervised\" is irrelevant to the causal structure and the potential for induced bias.\n-   Because the premise is false, the conclusion that LOCO PCs are unnecessary is invalid.\n**Verdict:** **Incorrect**.\n\n**C. Collider bias would only arise if $Y$ directly influenced $P$; since $Y$ does not cause $P$ by construction, regressing on $P$ is unbiased with respect to $\\theta_X$, and the LOCO approach is unrelated to bias control.**\nThis statement fundamentally misunderstands the mechanism of collider bias.\n-   Collider bias in the estimation of the $X \\rightarrow Y$ effect arises from conditioning on a variable $P$ that is a common effect of $X$ and another variable $A$ which is a cause of $Y$. The structure is $X \\rightarrow P \\leftarrow A \\rightarrow Y$.\n-   It is not necessary for $Y$ to cause $P$ for this bias to occur. The statement incorrectly specifies the required causal structure for collider bias in this context.\n-   Thus, the subsequent conclusions that the regression is unbiased and that LOCO is unrelated to bias control are false.\n**Verdict:** **Incorrect**.\n\n**D. The bias in $\\theta_X$ under adjustment by $P$ depends on the loading of $X$ on $P$ and the projection of $A$ onto $P$; LOCO PCs reduce the loading of the tested $X$ onto $P$ while retaining ancestry capture via $A$, thereby reducing bias without discarding population structure adjustment.**\nThis statement provides a precise and accurate summary.\n-   The \"loading of $X$ on $P$\" corresponds to the coefficient $\\gamma_X$. The \"projection of $A$ onto $P$\" corresponds to the coefficient $\\gamma_A$. As derived, the collider bias path $X \\rightarrow P \\leftarrow A \\rightarrow Y$ depends on the strengths of these links (as well as the $A \\rightarrow Y$ link, $\\beta_A$). So the first part is correct.\n-   \"LOCO PCs reduce the loading of the tested $X$ onto $P$\" correctly describes that the LOCO procedure aims to make $\\gamma_X \\approx 0$.\n-   \"while retaining ancestry capture via $A$\" correctly notes that $P_{loco}$ is still computed on the vast majority of the genome and thus remains a good proxy for $A$ (the $\\gamma'_A$ coefficient remains).\n-   The conclusion that this reduces bias while still adjusting for population structure is the correct synthesis of the two previous points.\n**Verdict:** **Correct**.\n\n**E. The only way to avoid collider bias from $P$ is to avoid any PC adjustment entirely; LOCO PCs cannot mitigate collider bias because they still condition on a descendant of $A$.**\nThis statement's reasoning and conclusion are flawed.\n-   Avoiding PC adjustment entirely would mean failing to control for the confounding path $X \\leftarrow A \\rightarrow Y$. This typically leads to a much larger problem of spurious associations due to population stratification than the collider bias under discussion. Thus, \"no adjustment\" is not a viable solution.\n-   The reason LOCO PCs supposedly fail is stated as \"because they still condition on a descendant of $A$.\" This is incorrect reasoning. Conditioning on a descendant of a confounder ($A$) is precisely how one controls for that confounding when the confounder itself is unobserved. The problem is not that $P$ is a descendant of $A$; the problem is that $P$ is a descendant of *both* $X$ and $A$. LOCO fixes this by ensuring $P_{loco}$ is not a descendant of $X$.\n**Verdict:** **Incorrect**.", "answer": "$$\\boxed{AD}$$", "id": "4596404"}]}