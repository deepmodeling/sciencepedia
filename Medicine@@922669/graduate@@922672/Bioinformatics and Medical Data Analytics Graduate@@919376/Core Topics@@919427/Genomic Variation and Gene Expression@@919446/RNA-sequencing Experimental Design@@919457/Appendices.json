{"hands_on_practices": [{"introduction": "At the heart of any robust RNA-sequencing experiment lies the principle of replication. Without a proper understanding of this concept, an entire study can be rendered invalid. This exercise [@problem_id:2385533] challenges you to critique a common but fundamentally flawed experimental design, forcing you to distinguish between biological variance—the true variation between individuals—and technical variance. Mastering this distinction is the first and most critical step toward designing experiments that can yield statistically meaningful conclusions.", "problem": "An investigator wants to assess Differential Gene Expression (DGE) between a control condition and a treatment. They collect tissue from $n_c$ control donors and $n_t$ treatment donors, extract total ribonucleic acid (RNA), and create two pools: one by combining equal RNA mass from all control donors and one by combining equal RNA mass from all treatment donors. They construct one sequencing library from each pool on different days and perform high-depth RNA sequencing (RNA-seq), obtaining gene-level count data for $G$ genes. They plan to identify differentially expressed genes by applying a standard DGE pipeline that outputs $p$-values and False Discovery Rate (FDR) $q$-values.\n\nWhich statement is the most accurate critique of this design, together with an appropriate remedy?\n\nA. The fundamental flaw is the absence of independent biological replicates, which makes the between-sample variance unidentifiable and renders inferential $p$-values for differential expression invalid; reads within a library are not independent experimental units. Pooling also masks donor-to-donor heterogeneity. The appropriate remedy is to include at least $k\\geq 3$ independent biological replicates per condition, randomized and balanced across library-preparation batches, so that variance can be estimated and batch effects can be separated from condition effects.\n\nB. The design is acceptable if the sequencing depth is extremely high (for example, $\\geq 10^8$ reads per library), because the law of large numbers ensures that per-gene means and variances are estimated with sufficient precision to yield valid hypothesis tests without biological replicates.\n\nC. Biological replication is unnecessary if multiple technical replicates are generated by sequencing the same two pooled libraries across $r\\geq 3$ lanes each; lane-to-lane variation provides the variance needed for valid differential expression testing between conditions.\n\nD. External spike-in controls allow complete normalization and hypothesis testing without biological replicates; with appropriate spike-ins, one can compute valid $p$-values for each gene despite having only one pooled sample per condition.\n\nE. Even with one pooled library per condition, a permutation test can be constructed by shuffling reads between the two libraries to create an empirical null distribution for each gene, enabling valid $p$-values without biological replicates.", "solution": "The central task in differential gene expression (DGE) analysis is to test the hypothesis that a gene's mean expression differs between populations (e.g., control vs. treatment). A valid statistical test requires an estimate of the effect size (the difference in means) and an estimate of the uncertainty associated with that effect, which is driven primarily by biological variance.\n\nIn RNA-seq, total variance arises from two main sources:\n1.  **Biological Variance**: This is the true, natural variation in gene expression among different individuals (donors) within the same condition. Quantifying this donor-to-donor variability is essential for making inferences about the populations.\n2.  **Technical Variance**: This is noise introduced during the experimental measurement process (RNA extraction, library preparation, sequencing).\n\nThe fundamental flaw in the proposed design is the complete absence of **independent biological replicates**. By physically pooling RNA from all donors within a condition into a single library, the investigator creates an effective sample size of $n=1$ per group. With only one measurement per condition, it is mathematically impossible to estimate the biological variance. Any observed difference between the two pools is confounded: it could be due to a true treatment effect, random differences between the specific groups of donors, or a technical artifact (a **batch effect**, as the libraries were prepared on different days).\n\nReads within a single library are merely technical measurements of that one pooled sample. Increasing sequencing depth reduces technical variance, providing a very precise measurement of the *pool*, but it provides zero information about the biological variance of the *population* of donors. Standard DGE software requires biological replicates to model this variance; without them, the resulting $p$-values and FDRs are statistically invalid.\n\nLet's evaluate the options based on this principle:\n\n**A.** This option correctly identifies the lack of biological replicates as the core flaw, explains that this makes biological variance unidentifiable and statistical inference invalid, and correctly notes that pooling hides individual heterogeneity. The proposed remedy—using at least three biological replicates per condition in a randomized, balanced design—is the gold standard for robust DGE analysis. It allows for proper variance estimation and mitigation of batch effects. This is a comprehensive and correct critique.\n\n**B.** This is incorrect. High sequencing depth only reduces technical sampling noise for a single sample. It cannot substitute for the biological sampling of multiple individuals from the population, which is necessary to estimate biological variance.\n\n**C.** This describes the use of technical replicates (re-sequencing the same library). This is incorrect. Technical replicates only measure technical variance, which is typically much smaller than biological variance. Using technical variance in a statistical test would lead to an extremely high rate of false positives, misinterpreting small technical fluctuations as significant biological effects.\n\n**D.** This is incorrect. External spike-in controls measure technical performance and can help with normalization, but they are not subject to the biological regulation of the host organism. They provide no information about the biological variance of the genes of interest and thus cannot replace biological replicates.\n\n**E.** This is incorrect. A permutation test requires exchangeable units under the null hypothesis, which in this context are the independent biological replicates. With only one unit (the pool) per condition, there is nothing to permute. Shuffling individual reads between libraries is not a valid statistical procedure as reads are not independent experimental units.\n\nTherefore, Option A is the only one that correctly identifies the critical flaw and proposes the appropriate solution.", "answer": "$$\\boxed{A}$$", "id": "2385533"}, {"introduction": "A well-conceived experimental design is only the beginning; the quality of the data generated is paramount for valid inference. In practice, samples can fail for numerous technical reasons, and identifying these failures is a critical skill. This problem [@problem_id:4605754] presents a realistic case study of an outlier sample, providing a rich set of quality control metrics from Principal Component Analysis (PCA) to RNA Integrity Numbers (RIN) and spike-in controls. By weighing the evidence, you will learn to make a scientifically defensible decision, protecting your analysis from the distorting effects of failed measurements.", "problem": "A study of messenger Ribonucleic Acid sequencing (RNA-seq) aims to estimate gene expression differences between a disease condition and controls. There are $n=12$ libraries: $6$ disease cases and $6$ controls. Library preparation was performed in two batches $\\mathcal{B}_1$ and $\\mathcal{B}_2$, each containing $3$ cases and $3$ controls, using the same kit and protocol. For each sample $i$, the observed count for gene $g$, denoted $Y_{gi}$, is modeled as coming from a sampling process in which fragments from expressed transcripts are stochastically captured and sequenced. A well-tested base model for count data assumes a Negative Binomial distribution with mean $\\mu_{gi}$ and variance $\\mu_{gi} + \\alpha_g \\mu_{gi}^2$, where $\\mu_{gi} = s_i q_{gi}$, $s_i$ is a sample-specific library size (size factor), $q_{gi}$ is the underlying expression level for gene $g$ in sample $i$, and $\\alpha_g$ is a gene-specific dispersion. Technical failures can distort $s_i$ and induce gene- and transcript-length-dependent biases in $q_{gi}$ (for example, due to degradation causing $3'$ end enrichment), thereby violating the assumption that differences are captured by fixed design covariates.\n\nQuality control (QC) summaries are available for all samples and include total reads $R_i$, uniquely mapped fraction $\\hat{p}_{u,i}$, duplication rate $d_i$, ribosomal fraction $r_i$, $3'$ to $5'$ end coverage ratio $b_i$, RNA Integrity Number $q_i$ (RIN), and estimated size factor $s_i$ by the median ratio method. Principal Component Analysis (PCA) was performed on log-transformed, normalized counts across genes, computing the eigendecomposition of the sample covariance matrix to obtain principal components with eigenvalues $\\lambda_1, \\lambda_2, \\ldots$; the first two components explain $\\lambda_1 / \\sum_j \\lambda_j$ and $\\lambda_2 / \\sum_j \\lambda_j$ of the variance, respectively.\n\nOne case sample, labeled $S7$, is a distinct outlier in the PCA. The first principal component explains $35\\%$ of variance (that is, $\\lambda_1 / \\sum_j \\lambda_j = 0.35$) and the second explains $18\\%$ of variance (that is, $\\lambda_2 / \\sum_j \\lambda_j = 0.18$). The PCA coordinates for $S7$ are $z_{1,7} = 5.2$ on principal component $1$ and $z_{2,7} = -0.4$ on principal component $2$, while all other samples satisfy $|z_{1,i}|  1.0$ and $|z_{2,i}|  1.2$. Coloring by batch shows overlapping clusters for $\\mathcal{B}_1$ and $\\mathcal{B}_2$, with $S7$ separating from both batches.\n\nQC metrics for $S7$ versus the ranges for other samples are:\n- $R_7 = 2.8 \\times 10^7$ reads (others: $R_i \\in [3.0 \\times 10^7, 4.1 \\times 10^7]$),\n- $\\hat{p}_{u,7} = 0.52$ (others: $\\hat{p}_{u,i} \\in [0.76, 0.88]$),\n- $d_7 = 0.65$ (others: $d_i \\in [0.22, 0.44]$),\n- $r_7 = 0.23$ (others: $r_i \\in [0.04, 0.09]$),\n- $b_7 = 2.3$ (others: $b_i \\in [0.93, 1.15]$),\n- $q_7 = 5.1$ (others: $q_i \\in [7.8, 9.2]$),\n- $s_7 = 0.42$ (others: $s_i \\in [0.84, 1.15]$).\n\nIn addition, External RNA Controls Consortium (ERCC) spike-in molecules were added at known quantities. For $S7$, the Spearman correlation between observed ERCC counts and expected concentrations is $\\rho_7 = 0.31$ (others: $\\rho_i \\in [0.78, 0.92]$). The remaining input RNA material available for $S7$ is $M_7 = 0.8 \\,\\mu\\text{g}$, and the library kit’s specification requires $\\geq 1.0 \\,\\mu\\text{g}$ of high-quality input RNA.\n\nYou plan to fit a generalized linear model to the counts $Y_{gi}$ using a design matrix $X$ with an intercept and condition indicator, and potentially batch covariates or additional nuisance factors. Based on the above, choose the most appropriate course of action for $S7$ to ensure scientifically valid inference and justify your choice from first principles of the data-generating and analysis models.\n\nWhich action is most appropriate?\n\nA. Exclude $S7$ from downstream differential expression analysis and document exclusion due to technical failure.\n\nB. Rerun library preparation for $S7$ using the remaining RNA material to recover a usable library.\n\nC. Retain $S7$ and include a batch indicator in the design matrix $X$ to account for the outlier.\n\nD. Retain $S7$ and apply surrogate variable analysis to capture hidden factors while keeping the sample.\n\nE. Retain $S7$ and filter out ribosomal RNA-aligning reads; proceed otherwise unchanged.", "solution": "The problem requires determining the most appropriate course of action for handling a sample, $S7$, which appears to be a significant outlier in an RNA-sequencing experiment. The decision must be grounded in the principles of experimental design, data quality control, and statistical modeling to ensure the scientific validity of the final conclusions.\n\nFirst, I will summarize and interpret the extensive evidence provided regarding sample $S7$. The goal is to determine if the sample's outlier status reflects a genuine biological phenomenon or a technical failure.\n\n**Analysis of Evidence Pertaining to Sample $S7$**\n\nThe data present a compelling and multi-faceted case for a severe technical failure in the processing of sample $S7$.\n\n1.  **Principal Component Analysis (PCA):** The sample $S7$ is a dramatic outlier on the first principal component (PC1), with a coordinate $z_{1,7} = 5.2$ while all other samples have $|z_{1,i}|  1.0$. Since PC1 explains $35\\%$ of the total variance in the dataset ($\\lambda_1 / \\sum_j \\lambda_j = 0.35$), this single sample is responsible for driving the dominant pattern of variation. A primary source of variation driven by a single sample, rather than by the experimental condition of interest, is a strong indicator of a technical artifact, not a biologically extreme phenotype. The fact that $S7$ separates from both batches $\\mathcal{B}_1$ and $\\mathcal{B}_2$ confirms that this is not a simple batch effect.\n\n2.  **RNA Quality and Degradation:** The RNA Integrity Number (RIN) for $S7$ is $q_7 = 5.1$, which is substantially lower than the range for other samples ($q_i \\in [7.8, 9.2]$). A RIN score below $6.0$ indicates severely degraded RNA. This is corroborated by the high $3'$-to-$5'$ end coverage ratio of $b_7 = 2.3$ (others: $b_i \\in [0.93, 1.15]$). RNA degradation in conjunction with poly-A-tailed library preparation methods leads to an accumulation of reads at the $3'$ end of transcripts. This creates a gene-length-dependent bias in quantification that cannot be corrected by a single, sample-specific size factor $s_i$.\n\n3.  **Library Quality:** The library generated from $S7$ is of poor quality. The duplication rate is extremely high ($d_7 = 0.65$ vs. others in $[0.22, 0.44]$), suggesting a low-complexity library where PCR amplification was excessive to achieve sufficient yield. This reduces the effective sequencing depth and the precision of expression estimates. The uniquely mapped fraction is very low ($\\hat{p}_{u,7} = 0.52$ vs. others in $[0.76, 0.88]$), which could indicate contamination or other library preparation failures like adapter-dimer formation.\n\n4.  **Sequencing Efficiency and Contamination:** The ribosomal RNA fraction is markedly elevated ($r_7 = 0.23$ vs. others in $[0.04, 0.09]$), indicating that the poly-A selection or rRNA depletion step was inefficient. A large portion of sequencing resources was thus wasted on non-target molecules. This, combined with a slightly lower total read count ($R_7 = 2.8 \\times 10^7$), contributes to a very low estimated size factor ($s_7 = 0.42$), meaning the effective library size for coding transcripts is a fraction of that of the other samples.\n\n5.  **Quantitative Accuracy (Ground Truth):** The most definitive evidence of failure comes from the External RNA Controls Consortium (ERCC) spike-in data. The Spearman correlation between observed counts and expected concentrations for $S7$ is only $\\rho_7 = 0.31$, while for all other samples it is high ($\\rho_i \\in [0.78, 0.92]$). This demonstrates that the quantitative measurements from sample $S7$ do not faithfully reflect the true abundance of molecules in the original sample. The entire quantitative basis of the measurement is compromised.\n\n**Implications for the Statistical Model**\n\nThe intended analysis uses a Negative Binomial model where the mean count $\\mu_{gi}$ is modeled as $\\mu_{gi} = s_i q_{gi}$. This model assumes that all sample-specific technical effects can be captured by a single scaling factor $s_i$, leaving $q_{gi}$ to represent the biological quantity of interest. The evidence for $S7$ demonstrates that this assumption is grossly violated. The RNA degradation has introduced complex, gene-dependent biases (e.g., related to transcript length) that a single factor $s_7$ cannot possibly correct. Including this sample in the analysis would inflate variance estimates (the dispersion $\\alpha_g$), drastically reduce statistical power, and introduce a high risk of false positive and false negative differential expression calls due to the massive, unmodeled technical noise.\n\nBased on this analysis, we can evaluate the proposed actions.\n\n**Option-by-Option Analysis**\n\n**A. Exclude $S7$ from downstream differential expression analysis and document exclusion due to technical failure.**\nThe evidence is conclusive: the data from $S7$ are not a valid representation of the sample's biology due to a cascade of technical failures beginning with poor quality input RNA. The fundamental assumptions of the downstream statistical analysis are violated in a way that is not computationally correctable. In such cases, the most scientifically rigorous and defensible action is to exclude the sample. This prioritizes the validity and integrity of the study's conclusions over a marginal loss in sample size. The final analysis would proceed with $5$ cases versus $6$ controls. The exclusion and the detailed reasons for it must be documented transparently.\n**Verdict: Correct.**\n\n**B. Rerun library preparation for $S7$ using the remaining RNA material to recover a usable library.**\nThe problem states that the remaining RNA material is $M_7 = 0.8 \\,\\mu\\text{g}$, while the kit requires $\\geq 1.0 \\,\\mu\\text{g}$. Furthermore, this remaining RNA is the same stock that was established to be of very poor quality ($q_7 = 5.1$). Attempting to generate a new library from insufficient and degraded starting material is a violation of the protocol and is almost certain to result in another failed library. This action would be a waste of time and resources.\n**Verdict: Incorrect.**\n\n**C. Retain $S7$ and include a batch indicator in the design matrix $X$ to account for the outlier.**\nA batch effect is a systematic technical variation that affects a group of samples processed together. The PCA plot shows that $S7$ is an outlier with respect to *all* other samples, including those from its own batch. Therefore, its variation is not a batch effect. Including a batch covariate in the model would not account for the unique deviation of $S7$. Modeling $S7$ as its own batch is an ad-hoc fix that does not address the underlying non-linear, gene-dependent biases (like $3'$ bias) and the fundamental lack of quantitative accuracy confirmed by the ERCC data.\n**Verdict: Incorrect.**\n\n**D. Retain $S7$ and apply surrogate variable analysis to capture hidden factors while keeping the sample.**\nSurrogate Variable Analysis (SVA) is a method to estimate and account for unmeasured sources of systematic variation. While SVA is powerful, it is not intended to salvage data from a single, catastrophic sample failure. The variation from $S7$ is so dominant ($\\lambda_1 / \\sum_j \\lambda_j = 0.35$) and its technical cause is so well-documented (degradation, low complexity, etc.) that it is not a \"hidden\" factor. More importantly, SVA and other linear model adjustments cannot fix the fundamental problem that the data are not quantitative, as shown by the low ERCC correlation ($\\rho_7 = 0.31$). Best practice is to remove samples with known, severe technical artifacts *before* applying methods like SVA to find more subtle, unknown confounders.\n**Verdict: Incorrect.**\n\n**E. Retain $S7$ and filter out ribosomal RNA-aligning reads; proceed otherwise unchanged.**\nFiltering rRNA reads is a standard data processing step. The high rRNA fraction ($r_7 = 0.23$) is a symptom of a failed library preparation, not the root cause. Removing these reads would not fix the underlying problems of RNA degradation ($q_7 = 5.1$, $b_7 = 2.3$), low library complexity ($d_7 = 0.65$), or the resulting loss of quantitative accuracy ($\\rho_7 = 0.31$). The remaining non-rRNA reads would still carry all these technical artifacts, rendering them unsuitable for differential expression analysis.\n**Verdict: Incorrect.**\n\nIn conclusion, the overwhelming and consistent evidence from multiple, independent QC metrics points to an unrecoverable technical failure for sample $S7$. The only scientifically sound action is to exclude the sample to maintain the integrity of the analysis.", "answer": "$$\\boxed{A}$$", "id": "4605754"}, {"introduction": "Modern biological experiments often involve multiple factors, such as treatment, sex, and technical batches, which may interact in complex ways. To accurately dissect these effects, we must translate our experimental design into a precise mathematical framework. This practice problem [@problem_id:4605716] guides you through the process of building a full-rank design matrix for a multifactorial experiment and defining a linear contrast to test a specific, nuanced hypothesis involving a treatment-by-sex interaction. This exercise develops the essential skill of mapping complex biological questions onto the powerful and flexible language of generalized linear models.", "problem": "A study aims to measure the effect of a drug treatment on messenger Ribonucleic Acid sequencing (RNA-seq) counts while adjusting for batch and sex, and allowing a sex-by-treatment interaction. Consider a single gene analyzed across $N=12$ samples collected under the following scientifically realistic conditions: three laboratory batches (Batch $B1$, Batch $B2$, Batch $B3$), two biological sexes (Female, Male), and two treatment groups (Control, Drug). The sample layout is balanced within each batch:\n- Batch $B1$: Female-Control, Female-Drug, Male-Control, Male-Drug.\n- Batch $B2$: Female-Control, Female-Drug, Male-Control, Male-Drug.\n- Batch $B3$: Female-Control, Female-Drug, Male-Control, Male-Drug.\n\nAssume a generalized linear model for counts with a Negative Binomial distribution, a logarithmic link, and a sample-specific offset equal to the logarithm of the library size factor. Specifically, for sample $i$, the linear predictor is\n$$\n\\eta_i \\equiv \\ln(\\mu_i) = \\ln(s_i) + \\boldsymbol{X}_i \\boldsymbol{\\beta},\n$$\nwhere $\\mu_i$ is the expected count, $s_i$ is the known library size factor, $\\boldsymbol{X}_i$ is the design row for sample $i$, and $\\boldsymbol{\\beta}$ is the coefficient vector. Use an indicator (dummy) coding with an intercept and the following columns in order:\n- Column $1$: Intercept ($1$ for all samples).\n- Column $2$: Treatment indicator $T$ ($0$ for Control, $1$ for Drug).\n- Column $3$: Sex indicator $S$ ($0$ for Female, $1$ for Male).\n- Column $4$: Interaction $T\\!:\\!S$ defined as the product $T \\times S$.\n- Column $5$: Batch indicator $D_{B1}$ ($1$ for Batch $B1$, $0$ otherwise).\n- Column $6$: Batch indicator $D_{B2}$ ($1$ for Batch $B2$, $0$ otherwise), with Batch $B3$ as the reference (so $D_{B3}$ is omitted to ensure full rank).\n\nConstruct the full-rank design matrix $X$ for the $12$ samples in this column order. Then, under this model, define the adjusted treatment effect on the log scale as the average difference in the linear predictor between Drug and Control, marginalized over the observed sex distribution in the dataset and holding batch effects fixed by inclusion in the model (that is, the average sex-specific treatment effect under the sample’s empirical sex composition). Derive the linear contrast vector $\\boldsymbol{c}$ (conforming to the specified column order) such that $\\boldsymbol{c}^{\\top}\\boldsymbol{\\beta}$ equals this adjusted treatment effect. Express the final contrast vector as a row vector with $6$ elements. Use exact values; do not round. No units are required for the final answer.", "solution": "The first step is to construct the $12 \\times 6$ design matrix $X$. Let us order the $N=12$ samples systematically by Batch, then Sex, then Treatment. The columns of $X$ correspond to the intercept, treatment indicator $T$, sex indicator $S$, interaction term $T \\times S$, and batch indicators $D_{B1}$ and $D_{B2}$. The coding is as follows: $T=0$ for Control and $T=1$ for Drug; $S=0$ for Female and $S=1$ for Male; $D_{B1}=1$ for Batch $B1$ and $0$ otherwise; $D_{B2}=1$ for Batch $B2$ and $0$ otherwise. Batch $B3$ serves as the reference level for the batch effect, so it is coded as $D_{B1}=0$ and $D_{B2}=0$.\n\nThe linear predictor for a sample $i$ is given by $\\eta_i = \\boldsymbol{X}_i \\boldsymbol{\\beta}$, where $\\boldsymbol{X}_i$ is the $i$-th row of $X$ and $\\boldsymbol{\\beta} = [\\beta_1, \\beta_2, \\beta_3, \\beta_4, \\beta_5, \\beta_6]^{\\top}$ is the vector of coefficients. The full model can be written as:\n$$\n\\eta = \\beta_1 + \\beta_2 T + \\beta_3 S + \\beta_4 (T \\times S) + \\beta_5 D_{B1} + \\beta_6 D_{B2}\n$$\nHere, $\\beta_1$ is the intercept, $\\beta_2$ is the main effect for treatment, $\\beta_3$ is the main effect for sex, $\\beta_4$ is the treatment-by-sex interaction effect, and $\\beta_5$, $\\beta_6$ are the effects for Batch $B1$ and $B2$ relative to Batch $B3$.\n\nThe primary goal is to find the linear contrast vector $\\boldsymbol{c}$ that corresponds to the adjusted treatment effect. This quantity is defined as the average difference in the linear predictor, $\\eta$, between the Drug and Control groups, marginalized over the observed sex distribution.\n\nFirst, let's determine the treatment effect on the log scale, conditioned on sex. This is the difference $\\eta(\\text{Drug}) - \\eta(\\text{Control})$ for a fixed sex and batch.\nFor a female subject ($S=0$), the treatment effect is:\n$$\n\\Delta_F = \\eta(T=1, S=0) - \\eta(T=0, S=0)\n$$\nUsing the linear model, where batch terms are constant and thus cancel out:\n$$\n\\Delta_F = (\\beta_1 + \\beta_2(1) + \\beta_3(0) + \\beta_4(1 \\times 0) + \\text{batch effects}) - (\\beta_1 + \\beta_2(0) + \\beta_3(0) + \\beta_4(0 \\times 0) + \\text{batch effects})\n$$\n$$\n\\Delta_F = (\\beta_1 + \\beta_2) - (\\beta_1) = \\beta_2\n$$\nFor a male subject ($S=1$), the treatment effect is:\n$$\n\\Delta_M = \\eta(T=1, S=1) - \\eta(T=0, S=1)\n$$\n$$\n\\Delta_M = (\\beta_1 + \\beta_2(1) + \\beta_3(1) + \\beta_4(1 \\times 1) + \\text{batch effects}) - (\\beta_1 + \\beta_2(0) + \\beta_3(1) + \\beta_4(0 \\times 1) + \\text{batch effects})\n$$\n$$\n\\Delta_M = (\\beta_1 + \\beta_2 + \\beta_3 + \\beta_4) - (\\beta_1 + \\beta_3) = \\beta_2 + \\beta_4\n$$\nThe treatment effect is $\\beta_2$ for females and $\\beta_2+\\beta_4$ for males. The interaction term $\\beta_4$ represents the additional effect of the drug in males compared to females.\n\nNext, we must marginalize this sex-specific effect over the observed sex distribution in the dataset. The experimental design is balanced: in each of the $3$ batches, there are $2$ female and $2$ male samples. Thus, out of the total $N=12$ samples, there are $6$ females and $6$ males. The observed proportions are:\n$$\nP(\\text{Sex}=\\text{Female}) = P(S=0) = \\frac{6}{12} = \\frac{1}{2}\n$$\n$$\nP(\\text{Sex}=\\text{Male}) = P(S=1) = \\frac{6}{12} = \\frac{1}{2}\n$$\nThe adjusted treatment effect, which we denote as $\\theta$, is the weighted average of the sex-specific effects, with weights given by these proportions:\n$$\n\\theta = P(S=0) \\cdot \\Delta_F + P(S=1) \\cdot \\Delta_M\n$$\n$$\n\\theta = \\frac{1}{2} (\\beta_2) + \\frac{1}{2} (\\beta_2 + \\beta_4)\n$$\n$$\n\\theta = \\frac{1}{2}\\beta_2 + \\frac{1}{2}\\beta_2 + \\frac{1}{2}\\beta_4 = \\beta_2 + \\frac{1}{2}\\beta_4\n$$\nThis expression, $\\theta = \\beta_2 + \\frac{1}{2}\\beta_4$, is a linear combination of the model coefficients. We are asked to find the contrast vector $\\boldsymbol{c}$ such that $\\theta = \\boldsymbol{c}^{\\top}\\boldsymbol{\\beta}$.\nGiven $\\boldsymbol{\\beta} = [\\beta_1, \\beta_2, \\beta_3, \\beta_4, \\beta_5, \\beta_6]^{\\top}$ and $\\boldsymbol{c}^{\\top} = [c_1, c_2, c_3, c_4, c_5, c_6]$, we write:\n$$\n\\boldsymbol{c}^{\\top}\\boldsymbol{\\beta} = c_1\\beta_1 + c_2\\beta_2 + c_3\\beta_3 + c_4\\beta_4 + c_5\\beta_5 + c_6\\beta_6\n$$\nBy equating the coefficients of this expression with those in our derived expression for $\\theta$:\n$$\n\\theta = (0)\\beta_1 + (1)\\beta_2 + (0)\\beta_3 + (\\frac{1}{2})\\beta_4 + (0)\\beta_5 + (0)\\beta_6\n$$\nwe can directly determine the elements of the contrast vector:\n$c_1 = 0$\n$c_2 = 1$\n$c_3 = 0$\n$c_4 = \\frac{1}{2}$\n$c_5 = 0$\n$c_6 = 0$\nThe resulting contrast, expressed as a row vector, is $\\boldsymbol{c}^{\\top} = [0, 1, 0, \\frac{1}{2}, 0, 0]$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0  1  0  \\frac{1}{2}  0  0\n\\end{pmatrix}\n}\n$$", "id": "4605716"}]}