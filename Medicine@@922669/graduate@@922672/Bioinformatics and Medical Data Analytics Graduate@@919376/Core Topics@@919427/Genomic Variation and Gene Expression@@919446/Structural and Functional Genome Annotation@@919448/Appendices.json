{"hands_on_practices": [{"introduction": "Identifying genes from a raw DNA sequence is a central challenge in genomics, forming the basis of structural annotation. This practice explores the algorithmic heart of *ab initio* gene finding by focusing on Generalized Hidden Markov Models (GHMMs), a powerful statistical framework for this task. By deriving and applying the Viterbi algorithm [@problem_id:4611367], you will work with the dynamic programming method used to find the most probable gene structure, gaining a fundamental understanding of how computational models parse genomic information.", "problem": "A gene finder based on a Generalized Hidden Markov Model (GHMM) with explicit duration models exon segments as lasting for a random number of nucleotides drawn from a specified duration distribution. Consider a two-state GHMM with states intergenic, denoted by $I$, and exon, denoted by $E$, that generates a fixed-length observed deoxyribonucleic acid (DNA) sequence $x_{1:L}$ (alphabet $\\{A,C,G,T\\}$). The model obeys the following generative assumptions, grounded in the Hidden Markov Model (HMM) definition and the dynamic programming principle of optimality: the joint probability of a path and emissions factorizes into an initial state probability, segment-to-segment transition probabilities, explicit state duration probabilities, and per-position emission probabilities. Assume the segment sequence begins in $I$ with probability $1$, segments have independent durations conditional on their state, emissions within a segment are independent and identically distributed conditional on the state, and segment transitions are only $I \\to E$ or $E \\to I$ (no self-transitions that create consecutive segments of the same label). The path terminates exactly at position $L$.\n\nTask 1 (derivation): Starting from the standard Viterbi algorithm for a discrete-time Hidden Markov Model (HMM), extend the dynamic programming recursion to the GHMM case with explicit durations for exons. Define a dynamic programming score $V(s,t)$ as the maximum log-probability of any segmentation that ends exactly at position $t$ with state $s \\in \\{I,E\\}$. Derive the recurrence that updates $V(s,t)$ by considering all possible durations $d$ of the final segment and all permissible predecessor states, in terms of the transition probabilities $a_{s',s}$, the duration distributions $p_s(d)$, and the emission probabilities $e_s(x)$. Clearly specify base cases for $t=0$.\n\nTask 2 (computation on a toy sequence): Use the recurrence you derived to compute the maximum log-probability for the most likely segmentation of the sequence $x_{1:6} = A\\,T\\,G\\,C\\,G\\,C$ under the following parameterization:\n- Initial state: start in $I$ with probability $1$.\n- Segment transitions: $a_{I,E} = 0.3$, $a_{E,I} = 1$, and transitions creating consecutive segments of the same state have probability $0$.\n- Explicit durations:\n  - For intergenic, $p_I(d) = 0.5^{d}$ for all integers $d \\ge 1$.\n  - For exon, $p_E(2) = 0.6$, $p_E(3) = 0.4$, and $p_E(d) = 0$ for all other $d$.\n- Emissions:\n  - In intergenic, $e_I(A)=0.35$, $e_I(T)=0.35$, $e_I(C)=0.15$, $e_I(G)=0.15$.\n  - In exon, $e_E(A)=0.10$, $e_E(T)=0.10$, $e_E(C)=0.40$, $e_E(G)=0.40$.\n- The path must end exactly at $t=L$ with an $I$ or $E$ segment; any implicit termination after the last segment has probability $1$.\n\nCompute the maximum natural logarithm of the joint probability of the most likely path and emissions for $x_{1:6}$ under this model. Report only this maximum natural logarithm value. Round your final numeric answer to four significant figures. Do not report the path or segmentation. Express your answer without units.", "solution": "The user wants me to act as a meticulous STEM professor and solve a two-part problem related to Generalized Hidden Markov Models (GHMMs).\n\n### Problem Validation\n\nThe user wants me to act as a meticulous STEM professor to solve a problem about Generalized Hidden Markov Models (GHMMs).\n\n**_Problem Validation_**\n\nI must first validate the problem statement as per the instructions.\n\n**Step 1: Extract Givens**\n\n*   **Model:** A two-state Generalized Hidden Markov Model (GHMM) with states $S = \\{I, E\\}$ (intergenic, exon).\n*   **Observation Sequence:** $x_{1:L}$ from the alphabet $\\{A,C,G,T\\}$.\n*   **Generative Assumptions:**\n    1.  The joint probability of a path and emissions factorizes into initial state probability, segment-to-segment transition probabilities, explicit state duration probabilities, and per-position emission probabilities.\n    2.  The segment sequence begins in state $I$ with probability $1$.\n    3.  Durations are independent conditional on the state.\n    4.  Emissions are i.i.d. conditional on the state.\n    5.  Segment transitions are only $I \\to E$ or $E \\to I$.\n    6.  The path terminates exactly at position $L$.\n*   **Task 1 (Derivation):**\n    *   Define $V(s,t)$ as the maximum log-probability of a segmentation ending at position $t$ in state $s$.\n    *   Derive the dynamic programming recurrence for $V(s,t)$.\n    *   The recurrence must be in terms of transition probabilities $a_{s',s}$, duration distributions $p_s(d)$, and emission probabilities $e_s(x)$.\n    *   Specify base cases for $t=0$.\n*   **Task 2 (Computation):**\n    *   Sequence: $x_{1:6} = A\\,T\\,G\\,C\\,G\\,C$, so $L=6$.\n    *   Parameters:\n        *   Initial state: start in $I$ with probability $1$.\n        *   Transitions: $a_{I,E} = 0.3$, $a_{E,I} = 1$. Transitions $I \\to I$ and $E \\to E$ have probability $0$.\n        *   Durations: $p_I(d) = 0.5^d$ for $d \\ge 1$; $p_E(2) = 0.6$, $p_E(3) = 0.4$, and $p_E(d)=0$ otherwise.\n        *   Emissions: $e_I(A)=0.35, e_I(T)=0.35, e_I(C)=0.15, e_I(G)=0.15$; $e_E(A)=0.10, e_E(T)=0.10, e_E(C)=0.40, e_E(G)=0.40$.\n    *   Objective: Compute the maximum natural logarithm of the joint probability for the sequence $x_{1:6}$. This is $\\max(V(I,L), V(E,L))$.\n    *   Report the final numerical answer rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientifically Grounded:** The problem describes a GHMM, a standard and fundamental model in bioinformatics for gene structure annotation. All components (states, transitions, emissions, durations) are standard elements of such models. The provided probabilities are valid (sum to $1$ or less where applicable). The problem is scientifically sound.\n*   **Well-Posed:** The problem is clearly structured into a derivation task and a computational task. The model is fully parameterized, and the objective function (maximum log-probability) is unambiguously defined. The Viterbi algorithm for GHMMs guarantees the existence and uniqueness of a solution. The problem is well-posed.\n*   **Objective:** The language is formal and precise, using established terminology from computational biology and probability theory. All parameters are given as exact numbers or functions. The problem is objective.\n*   **Flaw Checklist:** A thorough review against the flaw checklist reveals no issues. The problem is not unsound, incomplete, contradictory, unrealistic, ill-posed, or trivial. It is a standard, formal problem in its field.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. I will proceed to the solution.\n\n### Task 1: Derivation of the GHMM Viterbi Recurrence\n\nLet $V(s,t)$ be the maximum log-probability of any valid segmentation of the observed sequence $x_{1:t}$ that ends exactly at position $t$ with a segment of state $s \\in \\{I, E\\}$. Our goal is to derive a recurrence relation for $V(s,t)$.\n\nA path ending at position $t$ with a segment of state $s$ must have a final segment of duration $d$, where $1 \\le d \\le t$. This final segment spans from position $t-d+1$ to $t$. This segment is preceded by a segmentation of the sequence $x_{1:t-d}$. The Viterbi algorithm's principle of optimality states that the optimal path to $(s,t)$ must be an extension of an optimal path to a preceding configuration.\n\nLet us formalize the start of the sequence. We introduce a non-emitting start state $S_0$. The sequence of segments begins by a transition from $S_0$ to the first state, which must be $I$ according to the problem. We can model the initial state probabilities $\\pi_s$ as transition probabilities from this start state, i.e., $a_{S_0,s} = \\pi_s$. Per the problem, $\\pi_I = 1$ and $\\pi_E = 0$.\n\nThe dynamic programming table $V(s,t)$ can be computed for $t = 1, \\dots, L$ and $s \\in \\{I,E\\}$. To anchor the recursion, we define base cases at $t=0$. The score of a path of length zero is zero, which we can assign to the start state.\nBase Cases for $t=0$:\n$$V(S_0, 0) = 0$$\nAnd for the real states:\n$$V(I, 0) = -\\infty$$\n$$V(E, 0) = -\\infty$$\nAlso, for any $t>0$, $V(S_0, t) = -\\infty$, as the start state only exists at $t=0$.\n\nNow, we build the recurrence for $V(s,t)$ for $t \\geq 1$. A path ending at $(s,t)$ with a final segment of duration $d$ is formed by extending a path ending at $t-d$ in some legal predecessor state $s'$. The total log-probability is the sum of the score of the preceding path ($V(s', t-d)$), the log-transition probability ($\\ln(a_{s',s})$), the log-duration probability ($\\ln(p_s(d))$), and the log-emission probability of the segment ($\\sum_{i=t-d+1}^t \\ln(e_s(x_i))$). We must maximize over all possible durations $d$ and all valid predecessor states $s'$.\n\nThe general recurrence relation is:\n$$V(s, t) = \\max_{1 \\le d \\le t} \\left( \\ln(p_s(d)) + \\sum_{i=t-d+1}^t \\ln(e_s(x_i)) + \\max_{s' \\in \\{S_0, I, E\\}, s' \\neq s} \\left[ V(s', t-d) + \\ln(a_{s',s}) \\right] \\right)$$\nThe constraint $s' \\neq s$ comes from the problem statement that there are no self-transitions between segments ($I \\to I$ or $E \\to E$ are disallowed).\n\nLet's specialize this for states $I$ and $E$:\nFor state $I$, the predecessor state $s'$ can be $S_0$ (if it is the first segment) or $E$.\n$$V(I, t) = \\max_{1 \\le d \\le t} \\left( \\ln(p_I(d)) + \\sum_{i=t-d+1}^t \\ln(e_I(x_i)) + \\max \\begin{cases} V(S_0, t-d) + \\ln(a_{S_0,I}) & \\text{if } s'=S_0 \\\\ V(E, t-d) + \\ln(a_{E,I}) & \\text{if } s'=E \\end{cases} \\right)$$\nUsing our base cases, $V(S_0, t-d)$ is $0$ only if $t-d=0$ (i.e., $d=t$) and $-\\infty$ otherwise. Also, $V(E,0)=-\\infty$. This simplifies the inner maximization:\n$$ \\max_{s' \\in \\{S_0, E\\}} [ \\dots ] = \\begin{cases} \\ln(a_{S_0,I}) & \\text{if } d=t \\\\ V(E, t-d) + \\ln(a_{E,I}) & \\text{if } d<t \\end{cases} $$\nGiven $a_{S_0,I} = \\pi_I = 1$, the first case term is $\\ln(1)=0$.\n\nFor state $E$, the predecessor state $s'$ can be $S_0$ or $I$.\n$$V(E, t) = \\max_{1 \\le d \\le t} \\left( \\ln(p_E(d)) + \\sum_{i=t-d+1}^t \\ln(e_E(x_i)) + \\max \\begin{cases} V(S_0, t-d) + \\ln(a_{S_0,E}) & \\text{if } s'=S_0 \\\\ V(I, t-d) + \\ln(a_{I,E}) & \\text{if } s'=I \\end{cases} \\right)$$\nGiven $a_{S_0,E} = \\pi_E = 0$, its logarithm is $-\\infty$. The inner maximization becomes:\n$$ \\max_{s' \\in \\{S_0, I\\}} [ \\dots ] = \\begin{cases} -\\infty & \\text{if } d=t \\\\ V(I, t-d) + \\ln(a_{I,E}) & \\text{if } d<t \\end{cases} $$\nThis correctly enforces that the first segment cannot be of state $E$.\n\n### Task 2: Computation\n\nWe apply the derived recurrence to the sequence $x_{1:6} = A\\,T\\,G\\,C\\,G\\,C$. The final answer is $\\max(V(I, 6), V(E, 6))$. All calculations use the natural logarithm, $\\ln$.\n\nFirst, we pre-calculate necessary log-probabilities:\n*   Transitions: $\\ln(a_{I,E}) = \\ln(0.3) \\approx -1.2040$; $\\ln(a_{E,I}) = \\ln(1) = 0$.\n*   Durations ($I$): $\\ln(p_I(d)) = d \\ln(0.5) \\approx -0.6931 d$.\n*   Durations ($E$): $\\ln(p_E(2)) = \\ln(0.6) \\approx -0.5108$; $\\ln(p_E(3)) = \\ln(0.4) \\approx -0.9163$. $\\ln(p_E(d)) = -\\infty$ for $d \\notin \\{2, 3\\}$.\n*   Emissions: We compute the log-emission probability for each character in the sequence for each state, $\\ln(e_s(x_i))$. For efficient calculation of segment scores, we also compute the cumulative sums $C_s(t) = \\sum_{i=1}^t \\ln(e_s(x_i))$. The segment score $\\sum_{i=t-d+1}^t \\ln(e_s(x_i))$ is then $C_s(t) - C_s(t-d)$.\n\n| $i$ | $x_i$ | $\\ln(e_I(x_i))$ | $C_I(t)$  | $\\ln(e_E(x_i))$ | $C_E(t)$  |\n|-----|-------|-----------------|-----------|-----------------|-----------|\n| 1   | A     | $-1.0498$       | $-1.0498$ | $-2.3026$       | $-2.3026$ |\n| 2   | T     | $-1.0498$       | $-2.0996$ | $-2.3026$       | $-4.6052$ |\n| 3   | G     | $-1.8971$       | $-3.9967$ | $-0.9163$       | $-5.5215$ |\n| 4   | C     | $-1.8971$       | $-5.8938$ | $-0.9163$       | $-6.4378$ |\n| 5   | G     | $-1.8971$       | $-7.7909$ | $-0.9163$       | $-7.3541$ |\n| 6   | C     | $-1.8971$       | $-9.6880$ | $-0.9163$       | $-8.2704$ |\n\nWe fill the DP table $V(s,t)$ for $t=1, \\dots, 6$.\nLet $S_I(t,d) = \\ln(p_I(d)) + C_I(t) - C_I(t-d)$ and $S_E(t,d) = \\ln(p_E(d)) + C_E(t) - C_E(t-d)$.\n\n$t=1$:\n$V(I,1) = S_I(1,1) = -0.6931 - 1.0498 = -1.7429$\n$V(E,1) = -\\infty$\n\n$t=2$:\n$V(I,2) = S_I(2,2) = -1.3863 - 2.0996 = -3.4859$\n$V(E,2) = -\\infty$ (since $d$ must be $<2$, but valid durations for $E$ are $2,3$).\n\n$t=3$:\n$V(I,3) = S_I(3,3) = -2.0794 - 3.9967 = -6.0761$\n$V(E,3) = V(I,1) + \\ln(a_{I,E}) + S_E(3,2)$ (for $d=2$)\n$V(E,3) = -1.7429 - 1.2040 + (-0.5108 + C_E(3) - C_E(1)) = -1.7429 - 1.2040 - 0.5108 - 3.2189 = -6.6766$\n\n$t=4$:\n$V(I,4) = \\max \\left( S_I(4,4), \\quad V(E,3) + \\ln(a_{E,I}) + S_I(4,1) \\right)$\n$S_I(4,4) = -2.7726 - 5.8938 = -8.6664$\nPath 2: $-6.6766 + 0 + (-0.6931 - 1.8971) = -9.2668$\n$V(I,4) = \\max(-8.6664, -9.2668) = -8.6664$\n\n$V(E,4) = \\max \\left( V(I,2) + \\ln(a_{I,E}) + S_E(4,2), \\quad V(I,1) + \\ln(a_{I,E}) + S_E(4,3) \\right)$\n$d=2$: $-3.4859 - 1.2040 + (-0.5108 - 1.8326) = -7.0333$\n$d=3$: $-1.7429 - 1.2040 + (-0.9163 - 4.1352) = -7.9984$\n$V(E,4) = \\max(-7.0333, -7.9984) = -7.0333$\n\n$t=5$:\n$V(I,5) = \\max \\left( S_I(5,5), \\quad V(E,4)+\\ln(a_{E,I})+S_I(5,1), \\quad V(E,3)+\\ln(a_{E,I})+S_I(5,2) \\right)$\n$d=5$: $-3.4657 - 7.7909 = -11.2566$\n$d=1$: $-7.0333 + 0 + (-0.6931 - 1.8971) = -9.6235$\n$d=2$: $-6.6766 + 0 + (-1.3863 - 3.7942) = -11.8571$\n$V(I,5) = -9.6235$\n\n$V(E,5) = \\max \\left( V(I,3) + \\ln(a_{I,E}) + S_E(5,2), \\quad V(I,2) + \\ln(a_{I,E}) + S_E(5,3) \\right)$\n$d=2$: $-6.0761 - 1.2040 + (-0.5108 - 1.8326) = -9.6235$\n$d=3$: $-3.4859 - 1.2040 + (-0.9163 - 2.7489) = -8.3551$\n$V(E,5) = -8.3551$\n\n$t=6$:\n$V(I,6) = \\max \\left( S_I(6,6), \\quad V(E,5)+S_I(6,1), \\quad V(E,4)+S_I(6,2), \\quad V(E,3)+S_I(6,3) \\right)$\n$d=6$: $-4.1589 - 9.6880 = -13.8469$\n$d=1$: $-8.3551 + (-0.6931 - 1.8971) = -10.9453$\n$d=2$: $-7.0333 + (-1.3863 - 3.7942) = -12.2138$\n$d=3$: $-6.6766 + (-2.0794 - 5.6913) = -14.4473$\n$V(I,6) = -10.9453$\n\n$V(E,6) = \\max \\left( V(I,4)+\\ln(a_{I,E})+S_E(6,2), \\quad V(I,3)+\\ln(a_{I,E})+S_E(6,3) \\right)$\n$d=2$: $-8.6664 - 1.2040 + (-0.5108-1.8326) = -12.2138$\n$d=3$: $-6.0761 - 1.2040 + (-0.9163-2.7489) = -10.9453$\n$V(E,6) = -10.9453$\n\nThe maximum log-probability for the sequence is $\\max(V(I,6), V(E,6)) = \\max(-10.9453, -10.9453) = -10.9453$.\n\nRounding to four significant figures, we get $-10.95$.", "answer": "$$\n\\boxed{-10.95}\n$$", "id": "4611367"}, {"introduction": "Once a set of gene annotations is produced, how do we measure its accuracy against a known truth? This practice provides the essential toolkit for evaluating annotation quality by applying standard metrics like precision, recall, and the F1-score [@problem_id:4611315]. You will learn to compute and distinguish between nucleotide-level and feature-level (e.g., whole exon) accuracy, a critical nuance in assessing and comparing the performance of different gene finding algorithms.", "problem": "A structural genome annotation system is evaluated against a curated ground truth on a single contiguous genomic locus. In structural annotation, exons are represented as closed genomic intervals with integer coordinates, and evaluation can be done at the base level (nucleotide-by-nucleotide) or at the feature level (whole exon objects). Start from first principles: sets, counting measure on integer coordinates, and the definition of a confusion matrix. Using these, formally define base-wise precision, base-wise recall, the base-wise harmonic mean of precision and recall (F1 score), and feature-wise counterparts based on an explicit matching rule. Then compute these metrics for the provided data.\n\nFundamental base and definitions to use:\n- Consider a locus with integer coordinate set $\\Omega \\subset \\mathbb{Z}$ and the counting measure $\\mu$ that assigns to any finite subset $A \\subset \\Omega$ the value $\\mu(A)$ equal to the number of elements in $A$.\n- Let the ground truth exon set be a finite collection of closed intervals on $\\Omega$, $T = \\{[s_i, e_i]\\}_{i=1}^{n}$ with $s_i, e_i \\in \\mathbb{Z}$ and $s_i \\leq e_i$. The union of bases covered by truth is $U_T = \\bigcup_{i=1}^{n} [s_i, e_i]$.\n- Let the predicted exon set be $P = \\{[a_j, b_j]\\}_{j=1}^{m}$, with union of bases covered by predictions $U_P = \\bigcup_{j=1}^{m} [a_j, b_j]$.\n- Base-wise confusion counts are defined from sets: true positive bases $TP_{\\text{b}} = \\mu(U_P \\cap U_T)$, false positive bases $FP_{\\text{b}} = \\mu(U_P \\setminus U_T)$, and false negative bases $FN_{\\text{b}} = \\mu(U_T \\setminus U_P)$.\n- Base-wise precision is $P_{\\text{b}} = \\frac{TP_{\\text{b}}}{TP_{\\text{b}} + FP_{\\text{b}}}$, base-wise recall is $R_{\\text{b}} = \\frac{TP_{\\text{b}}}{TP_{\\text{b}} + FN_{\\text{b}}}$, and base-wise F1 is $F1_{\\text{b}} = \\frac{2 P_{\\text{b}} R_{\\text{b}}}{P_{\\text{b}} + R_{\\text{b}}}$.\n- Feature-wise evaluation treats exons as atomic features. Define Intersection over Union (IoU), also known as Jaccard index, between a predicted interval $[a,b]$ and a truth interval $[s,e]$ by $\\mathrm{IoU}([a,b],[s,e]) = \\frac{\\mu([a,b] \\cap [s,e])}{\\mu([a,b] \\cup [s,e])}$. Use a one-to-one matching protocol: construct matches greedily in descending order of IoU, allowing at most one match per predicted exon and at most one match per truth exon, and declare a match valid if and only if its IoU is at least the threshold $\\tau = 0.5$. Under this protocol, the feature-level true positives $TP_{\\text{f}}$ are the number of valid matches, the feature-level false positives $FP_{\\text{f}}$ are the number of predicted exons left unmatched, and the feature-level false negatives $FN_{\\text{f}}$ are the number of truth exons left unmatched.\n- Feature-wise precision is $P_{\\text{f}} = \\frac{TP_{\\text{f}}}{TP_{\\text{f}} + FP_{\\text{f}}}$, feature-wise recall is $R_{\\text{f}} = \\frac{TP_{\\text{f}}}{TP_{\\text{f}} + FN_{\\text{f}}}$, and feature-wise F1 is $F1_{\\text{f}} = \\frac{2 P_{\\text{f}} R_{\\text{f}}}{P_{\\text{f}} + R_{\\text{f}}}$.\n\nData:\n- Truth exons $T$: $[1000,1199]$, $[1500,1699]$, $[2000,2199]$.\n- Predicted exons $P$: $[995,1205]$, $[1600,1799]$, $[1900,2099]$, $[3000,3099]$.\n- All lengths are computed inclusively: the length of an interval $[x,y]$ is $y - x + 1$.\n\nTasks:\n1. Using the above fundamental definitions, compute $TP_{\\text{b}}$, $FP_{\\text{b}}$, and $FN_{\\text{b}}$, then compute $P_{\\text{b}}$, $R_{\\text{b}}$, and $F1_{\\text{b}}$.\n2. Using the IoU-based one-to-one matching with threshold $\\tau = 0.5$, compute $TP_{\\text{f}}$, $FP_{\\text{f}}$, and $FN_{\\text{f}}$, then compute $P_{\\text{f}}$, $R_{\\text{f}}$, and $F1_{\\text{f}}$.\n\nRound each reported metric to four significant figures and express each as a decimal. Report your six metrics in the order: base-wise precision, base-wise recall, base-wise F1, feature-wise precision, feature-wise recall, feature-wise F1.", "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded in standard bioinformatics evaluation methodologies, is well-posed with a complete and consistent set of definitions and data, and is expressed in objective, formal language. A unique solution can be derived from the provided information. We will now proceed with the solution, which is divided into two parts as per the tasks.\n\nPart 1: Base-wise evaluation\n\nThe ground truth annotation consists of a set of $n=3$ exons, $T = \\{T_1, T_2, T_3\\}$, where $T_1 = [1000, 1199]$, $T_2 = [1500, 1699]$, and $T_3 = [2000, 2199]$. The predicted annotation consists of a set of $m=4$ exons, $P = \\{P_1, P_2, P_3, P_4\\}$, where $P_1 = [995, 1205]$, $P_2 = [1600, 1799]$, $P_3 = [1900, 2099]$, and $P_4 = [3000, 3099]$. The measure of a set of integer coordinates is its cardinality, and for an interval $[x,y]$, this is $\\mu([x,y]) = y-x+1$.\n\nFirst, we calculate the total number of bases in the ground truth, $\\mu(U_T)$, and in the prediction, $\\mu(U_P)$. The intervals in $T$ are disjoint, as are the intervals in $P$.\nThe lengths of the truth exons are:\n$\\mu(T_1) = 1199 - 1000 + 1 = 200$\n$\\mu(T_2) = 1699 - 1500 + 1 = 200$\n$\\mu(T_3) = 2199 - 2000 + 1 = 200$\nThe union of truth bases is $U_T = T_1 \\cup T_2 \\cup T_3$, and its measure is $\\mu(U_T) = \\mu(T_1) + \\mu(T_2) + \\mu(T_3) = 600$. This corresponds to the total number of positive instances ($TP_{\\text{b}} + FN_{\\text{b}}$).\n\nThe lengths of the predicted exons are:\n$\\mu(P_1) = 1205 - 995 + 1 = 211$\n$\\mu(P_2) = 1799 - 1600 + 1 = 200$\n$\\mu(P_3) = 2099 - 1900 + 1 = 200$\n$\\mu(P_4) = 3099 - 3000 + 1 = 100$\nThe union of predicted bases is $U_P = P_1 \\cup P_2 \\cup P_3 \\cup P_4$, and its measure is $\\mu(U_P) = \\mu(P_1) + \\mu(P_2) + \\mu(P_3) + \\mu(P_4) = 211 + 200 + 200 + 100 = 711$. This corresponds to the total number of predicted positive instances ($TP_{\\text{b}} + FP_{\\text{b}}$).\n\nNext, we identify the set of true positive bases, which is the intersection of the two union sets, $U_P \\cap U_T$. We find the intersections of the constituent intervals:\n$P_1 \\cap T_1 = [995, 1205] \\cap [1000, 1199] = [1000, 1199]$. Its measure is $\\mu([1000, 1199]) = 200$.\n$P_2 \\cap T_2 = [1600, 1799] \\cap [1500, 1699] = [1600, 1699]$. Its measure is $\\mu([1600, 1699]) = 100$.\n$P_3 \\cap T_3 = [1900, 2099] \\cap [2000, 2199] = [2000, 2099]$. Its measure is $\\mu([2000, 2099]) = 100$.\nAll other pairwise intersections of intervals from $P$ and $T$ are empty sets.\nThe measure of the true positive bases is the sum of the measures of these disjoint intersections:\n$TP_{\\text{b}} = \\mu(U_P \\cap U_T) = 200 + 100 + 100 = 400$.\n\nNow we can compute the number of false positive and false negative bases:\n$FP_{\\text{b}} = \\mu(U_P \\setminus U_T) = \\mu(U_P) - \\mu(U_P \\cap U_T) = 711 - 400 = 311$.\n$FN_{\\text{b}} = \\mu(U_T \\setminus U_P) = \\mu(U_T) - \\mu(U_P \\cap U_T) = 600 - 400 = 200$.\n\nUsing these counts, we compute the base-wise precision ($P_{\\text{b}}$), recall ($R_{\\text{b}}$), and F1 score ($F1_{\\text{b}}$):\n$P_{\\text{b}} = \\frac{TP_{\\text{b}}}{TP_{\\text{b}} + FP_{\\text{b}}} = \\frac{400}{400 + 311} = \\frac{400}{711} \\approx 0.5625879...$\n$R_{\\text{b}} = \\frac{TP_{\\text{b}}}{TP_{\\text{b}} + FN_{\\text{b}}} = \\frac{400}{400 + 200} = \\frac{400}{600} = \\frac{2}{3} \\approx 0.666666...$\n$F1_{\\text{b}} = \\frac{2 P_{\\text{b}} R_{\\text{b}}}{P_{\\text{b}} + R_{\\text{b}}} = \\frac{2 TP_{\\text{b}}}{2 TP_{\\text{b}} + FP_{\\text{b}} + FN_{\\text{b}}} = \\frac{2 \\cdot 400}{2 \\cdot 400 + 311 + 200} = \\frac{800}{1311} \\approx 0.6102212...$\n\nRounding to four significant figures, the base-wise metrics are: $P_{\\text{b}} = 0.5626$, $R_{\\text{b}} = 0.6667$, and $F1_{\\text{b}} = 0.6102$.\n\nPart 2: Feature-wise evaluation\n\nFor feature-wise evaluation, we pair predicted exons with truth exons based on Intersection over Union (IoU), with a threshold of $\\tau = 0.5$. The matching is one-to-one and greedy, proceeding in descending order of IoU.\n$\\mathrm{IoU}([a,b],[s,e]) = \\frac{\\mu([a,b] \\cap [s,e])}{\\mu([a,b] \\cup [s,e])} = \\frac{\\mu([a,b] \\cap [s,e])}{\\mu([a,b]) + \\mu([s,e]) - \\mu([a,b] \\cap [s,e])}$.\n\nWe calculate the IoU for all pairs $(P_j, T_i)$ that have a non-empty intersection:\n1.  For $(P_1, T_1)$: $\\mu(P_1 \\cap T_1) = 200$. $\\mu(P_1) = 211$, $\\mu(T_1) = 200$.\n    $\\mathrm{IoU}(P_1, T_1) = \\frac{200}{211 + 200 - 200} = \\frac{200}{211} \\approx 0.947867$.\n2.  For $(P_2, T_2)$: $\\mu(P_2 \\cap T_2) = 100$. $\\mu(P_2) = 200$, $\\mu(T_2) = 200$.\n    $\\mathrm{IoU}(P_2, T_2) = \\frac{100}{200 + 200 - 100} = \\frac{100}{300} = \\frac{1}{3} \\approx 0.333333$.\n3.  For $(P_3, T_3)$: $\\mu(P_3 \\cap T_3) = 100$. $\\mu(P_3) = 200$, $\\mu(T_3) = 200$.\n    $\\mathrm{IoU}(P_3, T_3) = \\frac{100}{200 + 200 - 100} = \\frac{100}{300} = \\frac{1}{3} \\approx 0.333333$.\n\nAll other pairs have an intersection of $\\emptyset$ and thus an IoU of $0$.\nThe list of non-zero IoU pairs in descending order is: $(\\mathrm{IoU}(P_1, T_1) \\approx 0.9479)$, $(\\mathrm{IoU}(P_2, T_2) \\approx 0.3333)$, $(\\mathrm{IoU}(P_3, T_3) \\approx 0.3333)$.\n\nApplying the greedy matching protocol:\n1.  The highest IoU is $\\mathrm{IoU}(P_1, T_1) \\approx 0.9479$, which is greater than the threshold $\\tau=0.5$. We accept this as a valid match. $P_1$ and $T_1$ are now considered matched.\n2.  The next highest IoU is $\\mathrm{IoU}(P_2, T_2) \\approx 0.3333$, which is less than $\\tau=0.5$. This is not a valid match.\n3.  The next highest IoU is $\\mathrm{IoU}(P_3, T_3) \\approx 0.3333$, which is also less than $\\tau=0.5$. This is not a valid match.\n\nTherefore, there is only one valid match: $(P_1, T_1)$. We now compute the feature-wise confusion counts:\n$TP_{\\text{f}}$ = number of valid matches = $1$.\n$FP_{\\text{f}}$ = number of unmatched predicted exons = $|\\{P_2, P_3, P_4\\}| = 3$.\n$FN_{\\text{f}}$ = number of unmatched truth exons = $|\\{T_2, T_3\\}| = 2$.\nThe total number of predictions is $m = TP_{\\text{f}} + FP_{\\text{f}} = 1 + 3 = 4$. The total number of truth features is $n = TP_{\\text{f}} + FN_{\\text{f}} = 1 + 2 = 3$. These counts are consistent.\n\nUsing these counts, we compute the feature-wise precision ($P_{\\text{f}}$), recall ($R_{\\text{f}}$), and F1 score ($F1_{\\text{f}}$):\n$P_{\\text{f}} = \\frac{TP_{\\text{f}}}{TP_{\\text{f}} + FP_{\\text{f}}} = \\frac{1}{1 + 3} = \\frac{1}{4} = 0.25$.\n$R_{\\text{f}} = \\frac{TP_{\\text{f}}}{TP_{\\text{f}} + FN_{\\text{f}}} = \\frac{1}{1 + 2} = \\frac{1}{3} \\approx 0.333333...$\n$F1_{\\text{f}} = \\frac{2 P_{\\text{f}} R_{\\text{f}}}{P_{\\text{f}} + R_{\\text{f}}} = \\frac{2 \\cdot (1/4) \\cdot (1/3)}{(1/4) + (1/3)} = \\frac{2/12}{7/12} = \\frac{2}{7} \\approx 0.285714...$\n\nRounding to four significant figures, the feature-wise metrics are: $P_{\\text{f}} = 0.2500$, $R_{\\text{f}} = 0.3333$, and $F1_{\\text{f}} = 0.2857$.\n\nFinal Summary of Metrics:\nBase-wise Precision ($P_{\\text{b}}$): $0.5626$\nBase-wise Recall ($R_{\\text{b}}$): $0.6667$\nBase-wise F1 ($F1_{\\text{b}}$): $0.6102$\nFeature-wise Precision ($P_{\\text{f}}$): $0.2500$\nFeature-wise Recall ($R_{\\text{f}}$): $0.3333$\nFeature-wise F1 ($F1_{\\text{f}}$): $0.2857$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.5626 & 0.6667 & 0.6102 & 0.2500 & 0.3333 & 0.2857\n\\end{pmatrix}\n}\n$$", "id": "4611315"}, {"introduction": "Real-world genome annotation rarely relies on a single source of information; instead, it involves integrating multiple, often contradictory, data types. This advanced exercise demonstrates how to use Bayesian decision theory to make an optimal choice between competing hypotheses, such as resolving conflicting exon boundaries suggested by RNA-seq and protein homology [@problem_id:4611300]. By formalizing the problem with priors, likelihoods, and a loss function, you will practice making principled, data-driven decisions under uncertainty.", "problem": "A gene model under structural and functional genome annotation has a single disputed exon boundary with two competing hypotheses: the boundary suggested by Ribonucleic Acid sequencing (RNA-seq), denoted $H_{R}$, and the boundary suggested by protein homology alignment, denoted $H_{P}$. The annotation pipeline must choose one boundary to maximize expected accuracy under a specified loss function, given observed evidence $d$ from both RNA-seq splice junctions and protein homology alignment scores.\n\nUse the following foundational base:\n- The Central Dogma of Molecular Biology states that genes encode messenger ribonucleic acid (mRNA) which translates into proteins. Exon boundaries determine the coding frame; misannotation can cause frameshifts or functional domain truncations.\n- Bayesian decision theory: posterior probability is given by Bayes’ theorem, and the optimal action minimizes expected loss. Formally, the posterior odds satisfy $$\\frac{P(H_{R}\\,|\\,d)}{P(H_{P}\\,|\\,d)}=\\frac{\\pi_{R}}{\\pi_{P}} \\cdot \\frac{p(d\\,|\\,H_{R})}{p(d\\,|\\,H_{P})},$$ where $\\pi_{R}$ and $\\pi_{P}$ are prior probabilities and $p(d\\,|\\,H)$ is the likelihood of the evidence under hypothesis $H$.\n\nAssume conditional independence of the RNA-seq and protein homology evidence given the true boundary, so that $$p(d\\,|\\,H)=p(d_{\\mathrm{RNA}}\\,|\\,H)\\cdot p(d_{\\mathrm{PROT}}\\,|\\,H).$$ Priors are informed by splice motif strength and comparative genomics: $$\\pi_{R}=0.6,\\quad \\pi_{P}=0.4.$$ Likelihoods of the observed data $d$ under each hypothesis, estimated from a calibrated generative model of junction read counts and alignment scores, are:\n- RNA-seq junction evidence: $$p(d_{\\mathrm{RNA}}\\,|\\,H_{R})=0.92,\\quad p(d_{\\mathrm{RNA}}\\,|\\,H_{P})=0.12.$$\n- Protein homology evidence: $$p(d_{\\mathrm{PROT}}\\,|\\,H_{R})=0.35,\\quad p(d_{\\mathrm{PROT}}\\,|\\,H_{P})=0.78.$$\n\nThe loss function penalizes incorrect choices asymmetrically due to potential frameshift versus in-frame truncation:\n- Choosing $H_{R}$ when $H_{P}$ is true incurs loss $$L(H_{R},H_{P})=9.$$\n- Choosing $H_{P}$ when $H_{R}$ is true incurs loss $$L(H_{P},H_{R})=3.$$\n- Choosing the true boundary incurs zero loss: $$L(H_{R},H_{R})=0,\\quad L(H_{P},H_{P})=0.$$\n\nTasks:\n1. Starting from Bayes’ theorem and the definition of expected loss, derive a decision rule that minimizes expected loss in terms of the posterior odds $\\frac{P(H_{R}\\,|\\,d)}{P(H_{P}\\,|\\,d)}$ and the loss ratio.\n2. Using the provided priors and likelihoods, compute the posterior odds and apply the decision rule to select the optimal boundary.\n3. Express your final choice as a single number with no units: output $0$ if the optimal action is to choose the RNA-seq-supported boundary $H_{R}$, and output $1$ if the optimal action is to choose the protein-homology-supported boundary $H_{P}$.\n\nNo rounding is required for the final choice. All steps must be justified from the stated base without invoking any unprovided shortcut formulas.", "solution": "The problem statement is first validated against the specified criteria.\n\n### Step 1: Extract Givens\n- **Hypotheses**: $H_{R}$ (boundary from RNA-seq), $H_{P}$ (boundary from protein homology).\n- **Evidence**: $d = (d_{\\mathrm{RNA}}, d_{\\mathrm{PROT}})$.\n- **Bayesian Framework**:\n  - Posterior Odds: $\\frac{P(H_{R}\\,|\\,d)}{P(H_{P}\\,|\\,d)}=\\frac{\\pi_{R}}{\\pi_{P}} \\cdot \\frac{p(d\\,|\\,H_{R})}{p(d\\,|\\,H_{P})}$.\n  - Conditional Independence: $p(d\\,|\\,H)=p(d_{\\mathrm{RNA}}\\,|\\,H)\\cdot p(d_{\\mathrm{PROT}}\\,|\\,H)$.\n- **Prior Probabilities**: $\\pi_{R} = P(H_{R}) = 0.6$, $\\pi_{P} = P(H_{P}) = 0.4$.\n- **Likelihoods for RNA-seq evidence ($d_{\\mathrm{RNA}}$)**:\n  - $p(d_{\\mathrm{RNA}}\\,|\\,H_{R}) = 0.92$.\n  - $p(d_{\\mathrm{RNA}}\\,|\\,H_{P}) = 0.12$.\n- **Likelihoods for Protein Homology evidence ($d_{\\mathrm{PROT}}$)**:\n  - $p(d_{\\mathrm{PROT}}\\,|\\,H_{R}) = 0.35$.\n  - $p(d_{\\mathrm{PROT}}\\,|\\,H_{P}) = 0.78$.\n- **Loss Function ($L(\\text{action}, \\text{truth})$)**:\n  - $L(H_{R}, H_{P}) = 9$.\n  - $L(H_{P}, H_{R}) = 3$.\n  - $L(H_{R}, H_{R}) = 0$.\n  - $L(H_{P}, H_{P}) = 0$.\n- **Tasks**:\n  1. Derive a decision rule to minimize expected loss.\n  2. Compute posterior odds and apply the rule.\n  3. Output $0$ for choosing $H_{R}$ or $1$ for choosing $H_{P}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated as follows:\n- **Scientifically Grounded**: The problem is grounded in the principles of bioinformatics and molecular biology, specifically genome annotation. The use of Bayesian decision theory to integrate conflicting evidence from RNA-seq and protein homology is a standard and scientifically sound approach.\n- **Well-Posed**: The problem is well-posed. It provides all necessary information: a complete set of hypotheses, prior probabilities that sum to $1$ ($0.6 + 0.4 = 1$), a full set of likelihoods for the evidence under each hypothesis, and a clearly defined loss function. The tasks are specific and lead to a unique, computable solution.\n- **Objective**: The problem is stated in precise, quantitative, and objective language, free of ambiguity or subjective claims.\n\nThe problem does not exhibit any of the enumerated invalidity flaws. It is scientifically sound, formally specified, complete, and logically consistent.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution is provided below.\n\n### Task 1: Derivation of the Decision Rule\n\nThe goal is to select an action, either choosing $H_R$ or choosing $H_P$, that minimizes the expected loss. The expectation is taken over the possible true states of nature ($H_R$ or $H_P$), conditioned on the observed evidence $d$. The posterior probabilities $P(H_{R}\\,|\\,d)$ and $P(H_{P}\\,|\\,d)$ are used for this purpose.\n\nThe expected loss of choosing action $H_R$, denoted $E[L\\,|\\,a=H_R]$, is:\n$$ E[L\\,|\\,a=H_{R}] = L(H_{R}, H_{R}) \\cdot P(H_{R}\\,|\\,d) + L(H_{R}, H_{P}) \\cdot P(H_{P}\\,|\\,d) $$\nGiven $L(H_{R}, H_{R}) = 0$, this simplifies to:\n$$ E[L\\,|\\,a=H_{R}] = L(H_{R}, H_{P}) \\cdot P(H_{P}\\,|\\,d) $$\n\nThe expected loss of choosing action $H_P$, denoted $E[L\\,|\\,a=H_P]$, is:\n$$ E[L\\,|\\,a=H_{P}] = L(H_{P}, H_{R}) \\cdot P(H_{R}\\,|\\,d) + L(H_{P}, H_{P}) \\cdot P(H_{P}\\,|\\,d) $$\nGiven $L(H_{P}, H_{P}) = 0$, this simplifies to:\n$$ E[L\\,|\\,a=H_{P}] = L(H_{P}, H_{R}) \\cdot P(H_{R}\\,|\\,d) $$\n\nTo minimize expected loss, we should choose action $H_R$ if its expected loss is less than the expected loss of choosing $H_P$. That is, we choose $H_R$ if:\n$$ E[L\\,|\\,a=H_{R}] < E[L\\,|\\,a=H_{P}] $$\nSubstituting the expressions for expected loss:\n$$ L(H_{R}, H_{P}) \\cdot P(H_{P}\\,|\\,d) < L(H_{P}, H_{R}) \\cdot P(H_{R}\\,|\\,d) $$\nTo express this in terms of the posterior odds, we rearrange the inequality. Since posterior probabilities and losses are non-negative, and assuming $P(H_{P}\\,|\\,d) > 0$ and $L(H_{P}, H_{R}) > 0$, we can divide without changing the inequality's direction:\n$$ \\frac{L(H_{R}, H_{P})}{L(H_{P}, H_{R})} < \\frac{P(H_{R}\\,|\\,d)}{P(H_{P}\\,|\\,d)} $$\nThis is the desired decision rule: Choose $H_R$ if the posterior odds in favor of $H_R$ are greater than the ratio of the losses for incorrect decisions. Conversely, choose $H_P$ if the posterior odds are less than the loss ratio.\n\n### Task 2: Computation and Application of the Decision Rule\n\nFirst, we compute the loss ratio from the given loss function:\n$$ \\text{Loss Ratio} = \\frac{L(H_{R}, H_{P})}{L(H_{P}, H_{R})} = \\frac{9}{3} = 3 $$\nSo, the decision rule is: Choose $H_R$ if $\\frac{P(H_{R}\\,|\\,d)}{P(H_{P}\\,|\\,d)} > 3$.\n\nNext, we compute the posterior odds using the provided formula and data. The posterior odds are the product of the prior odds and the Bayes factor (the ratio of likelihoods).\nThe prior odds are:\n$$ \\frac{\\pi_{R}}{\\pi_{P}} = \\frac{0.6}{0.4} = 1.5 $$\nThe Bayes factor, $BF$, is the likelihood ratio, which, due to the conditional independence of evidence, is:\n$$ BF = \\frac{p(d\\,|\\,H_{R})}{p(d\\,|\\,H_{P})} = \\frac{p(d_{\\mathrm{RNA}}\\,|\\,H_{R}) \\cdot p(d_{\\mathrm{PROT}}\\,|\\,H_{R})}{p(d_{\\mathrm{RNA}}\\,|\\,H_{P}) \\cdot p(d_{\\mathrm{PROT}}\\,|\\,H_{P})} $$\nSubstituting the given likelihood values:\n$$ BF = \\frac{0.92 \\cdot 0.35}{0.12 \\cdot 0.78} = \\frac{0.322}{0.0936} $$\nNow, we compute the posterior odds:\n$$ \\frac{P(H_{R}\\,|\\,d)}{P(H_{P}\\,|\\,d)} = \\frac{\\pi_{R}}{\\pi_{P}} \\cdot BF = 1.5 \\cdot \\frac{0.322}{0.0936} = \\frac{0.483}{0.0936} $$\nTo compare this value with the loss ratio of $3$, we can perform the division:\n$$ \\frac{0.483}{0.0936} \\approx 5.16025... $$\nAlternatively, we can perform the comparison without division:\nIs $\\frac{0.483}{0.0936} > 3$?\nThis is equivalent to asking if $0.483 > 3 \\cdot 0.0936$.\n$3 \\cdot 0.0936 = 0.2808$.\nSince $0.483 > 0.2808$, the inequality holds.\n\nThe posterior odds ($\\approx 5.16$) are greater than the loss ratio ($3$).\nAccording to our derived decision rule, the optimal action is to choose the RNA-seq-supported boundary, $H_R$.\n\n### Task 3: Final Choice\nThe problem specifies to output $0$ if the optimal action is to choose $H_R$ and $1$ if the optimal action is to choose $H_P$. Since our analysis concluded that choosing $H_R$ is the optimal action to minimize expected loss, the final output is $0$.", "answer": "$$\\boxed{0}$$", "id": "4611300"}]}