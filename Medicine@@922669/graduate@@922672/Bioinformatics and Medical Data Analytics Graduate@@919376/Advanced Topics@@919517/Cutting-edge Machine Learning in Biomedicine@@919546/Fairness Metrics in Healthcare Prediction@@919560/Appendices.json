{"hands_on_practices": [{"introduction": "Before we can mitigate bias, we must first be able to measure it. This foundational exercise starts with the raw output of a clinical risk model—the confusion matrix—for two distinct demographic groups. By calculating essential performance metrics such as sensitivity and positive predictive value for each group, you will gain hands-on experience in quantifying the real-world impact of algorithmic disparities. [@problem_id:4562365]", "problem": "A hospital deploys a binary disease-risk classifier to triage patients for early intervention. For each patient, let $Y \\in \\{0,1\\}$ denote the true disease status ($Y=1$ indicates disease present, $Y=0$ indicates disease absent), and let $\\hat{Y} \\in \\{0,1\\}$ denote the classifier’s predicted label ($\\hat{Y}=1$ indicates predicted disease, $\\hat{Y}=0$ indicates predicted no disease). Two demographic groups, labeled Group A and Group B, have the following observed confusion matrix counts over a fixed evaluation period: Group A has True Positive (TP) $=40$, False Positive (FP) $=10$, True Negative (TN) $=150$, and False Negative (FN) $=20$; Group B has True Positive (TP) $=30$, False Positive (FP) $=5$, True Negative (TN) $=80$, and False Negative (FN) $=35$. \n\nUsing only core definitions from probability and frequentist estimation, proceed as follows:\n- For each group, define and compute the empirical sensitivity (the probability of predicting positive among truly positive cases), specificity (the probability of predicting negative among truly negative cases), Positive Predictive Value (PPV; the probability of truly positive among predicted positive cases), and Negative Predictive Value (NPV; the probability of truly negative among predicted negative cases), expressed as decimals.\n- Quantify the fairness-related disparity for each of these four rates as the absolute difference between Group A and Group B’s values.\n- Define a composite disparity index as the arithmetic mean of these four absolute differences and compute it.\n\nExpress the final composite disparity index as a decimal rounded to four significant figures. No percentage symbols are permitted in the answer.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n-   **Classifier:** Binary disease-risk classifier.\n-   **True Status:** $Y \\in \\{0, 1\\}$, where $Y=1$ indicates disease present and $Y=0$ indicates disease absent.\n-   **Predicted Label:** $\\hat{Y} \\in \\{0, 1\\}$, where $\\hat{Y}=1$ indicates predicted disease and $\\hat{Y}=0$ indicates predicted no disease.\n-   **Demographic Groups:** Group A and Group B.\n-   **Confusion Matrix Counts for Group A:**\n    -   True Positives ($TP_A$): $40$\n    -   False Positives ($FP_A$): $10$\n    -   True Negatives ($TN_A$): $150$\n    -   False Negatives ($FN_A$): $20$\n-   **Confusion Matrix Counts for Group B:**\n    -   True Positives ($TP_B$): $30$\n    -   False Positives ($FP_B$): $5$\n    -   True Negatives ($TN_B$): $80$\n    -   False Negatives ($FN_B$): $35$\n-   **Task:**\n    1.  For each group, compute empirical sensitivity ($Sens$), specificity ($Spec$), Positive Predictive Value ($PPV$), and Negative Predictive Value ($NPV$).\n    2.  Quantify the disparity for each metric as the absolute difference between the values for Group A and Group B.\n    3.  Define and compute a composite disparity index as the arithmetic mean of the four absolute differences.\n    4.  The final result should be a decimal rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientific Grounding:** The problem is firmly based on standard, fundamental concepts in statistics and machine learning evaluation (confusion matrices, sensitivity, specificity, PPV, NPV). These are core metrics used in assessing classifier performance and fairness in medical data analytics. The problem is scientifically sound.\n-   **Well-Posedness:** All necessary data (TP, FP, TN, FN counts for both groups) are provided. The definitions of the required metrics are standard and lead to a unique, stable, and meaningful solution.\n-   **Objectivity:** The problem statement is expressed using precise, quantitative, and unbiased language. It is free from subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is self-contained, scientifically sound, and well-posed. The solution process may proceed.\n\n### Solution Derivation\n\nThe analysis begins by defining the four performance metrics in terms of the confusion matrix components. Let $G$ denote a group, either A or B.\n\n1.  **Sensitivity ($Sens_G$)**: The probability of a positive prediction given that the condition is truly present. It is estimated as:\n    $$Sens_G = P(\\hat{Y}=1 | Y=1) \\approx \\frac{TP_G}{TP_G + FN_G}$$\n2.  **Specificity ($Spec_G$)**: The probability of a negative prediction given that the condition is truly absent. It is estimated as:\n    $$Spec_G = P(\\hat{Y}=0 | Y=0) \\approx \\frac{TN_G}{TN_G + FP_G}$$\n3.  **Positive Predictive Value ($PPV_G$)**: The probability that the condition is truly present given a positive prediction. It is estimated as:\n    $$PPV_G = P(Y=1 | \\hat{Y}=1) \\approx \\frac{TP_G}{TP_G + FP_G}$$\n4.  **Negative Predictive Value ($NPV_G$)**: The probability that the condition is truly absent given a negative prediction. It is estimated as:\n    $$NPV_G = P(Y=0 | \\hat{Y}=0) \\approx \\frac{TN_G}{TN_G + FN_G}$$\n\nNext, we compute these four metrics for each group using the provided data.\n\n**For Group A:**\n$TP_A = 40$, $FP_A = 10$, $TN_A = 150$, $FN_A = 20$.\n-   $Sens_A = \\frac{TP_A}{TP_A + FN_A} = \\frac{40}{40 + 20} = \\frac{40}{60} = \\frac{2}{3} \\approx 0.6667$\n-   $Spec_A = \\frac{TN_A}{TN_A + FP_A} = \\frac{150}{150 + 10} = \\frac{150}{160} = \\frac{15}{16} = 0.9375$\n-   $PPV_A = \\frac{TP_A}{TP_A + FP_A} = \\frac{40}{40 + 10} = \\frac{40}{50} = \\frac{4}{5} = 0.8$\n-   $NPV_A = \\frac{TN_A}{TN_A + FN_A} = \\frac{150}{150 + 20} = \\frac{150}{170} = \\frac{15}{17} \\approx 0.8824$\n\n**For Group B:**\n$TP_B = 30$, $FP_B = 5$, $TN_B = 80$, $FN_B = 35$.\n-   $Sens_B = \\frac{TP_B}{TP_B + FN_B} = \\frac{30}{30 + 35} = \\frac{30}{65} = \\frac{6}{13} \\approx 0.4615$\n-   $Spec_B = \\frac{TN_B}{TN_B + FP_B} = \\frac{80}{80 + 5} = \\frac{80}{85} = \\frac{16}{17} \\approx 0.9412$\n-   $PPV_B = \\frac{TP_B}{TP_B + FP_B} = \\frac{30}{30 + 5} = \\frac{30}{35} = \\frac{6}{7} \\approx 0.8571$\n-   $NPV_B = \\frac{TN_B}{TN_B + FN_B} = \\frac{80}{80 + 35} = \\frac{80}{115} = \\frac{16}{23} \\approx 0.6957$\n\nNow, we compute the fairness-related disparities, defined as the absolute difference for each metric between the two groups.\n-   $\\Delta_{Sens} = |Sens_A - Sens_B| = |\\frac{2}{3} - \\frac{6}{13}| = |\\frac{26 - 18}{39}| = \\frac{8}{39} \\approx 0.205128$\n-   $\\Delta_{Spec} = |Spec_A - Spec_B| = |\\frac{15}{16} - \\frac{16}{17}| = |\\frac{255 - 256}{272}| = \\frac{1}{272} \\approx 0.003676$\n-   $\\Delta_{PPV} = |PPV_A - PPV_B| = |\\frac{4}{5} - \\frac{6}{7}| = |\\frac{28 - 30}{35}| = \\frac{2}{35} \\approx 0.057143$\n-   $\\Delta_{NPV} = |NPV_A - NPV_B| = |\\frac{15}{17} - \\frac{16}{23}| = |\\frac{345 - 272}{391}| = \\frac{73}{391} \\approx 0.186701$\n\nFinally, we compute the composite disparity index ($I_D$) as the arithmetic mean of these four absolute differences.\n$$I_D = \\frac{1}{4} (\\Delta_{Sens} + \\Delta_{Spec} + \\Delta_{PPV} + \\Delta_{NPV})$$\n$$I_D \\approx \\frac{1}{4} (0.205128 + 0.003676 + 0.057143 + 0.186701)$$\n$$I_D \\approx \\frac{1}{4} (0.452648)$$\n$$I_D \\approx 0.113162$$\n\nRounding the result to four significant figures gives $0.1132$.", "answer": "$$\\boxed{0.1132}$$", "id": "4562365"}, {"introduction": "A common assumption is that a model behaving identically across groups, in terms of its ability to identify positive cases (Equal Opportunity), is fair. This practice challenges that notion by exploring the intricate relationship between model performance, group-specific disease prevalence, and the reliability of a positive prediction (Predictive Parity). This exercise demonstrates a fundamental tension in fairness, showing how satisfying one metric does not guarantee another, a critical insight rooted in Bayes' theorem. [@problem_id:4562332]", "problem": "A hospital system deploys a binary clinical decision support model to flag patients at high risk for a post-operative complication. Let the ground-truth outcome be a binary variable $Y \\in \\{0,1\\}$ where $Y=1$ indicates the complication occurs within $30$ days, and let the model’s binary alert be $\\hat{Y} \\in \\{0,1\\}$. Two clinically distinct subpopulations, Group A and Group B, have different base rates (prevalences) of the outcome. Suppose that the model is calibrated to the same operating point across both groups, yielding the same True Positive Rate (TPR) and False Positive Rate (FPR) across groups. Specifically, assume the following:\n- Group A prevalence (base rate): $\\pi_A = \\mathbb{P}(Y=1 \\mid \\text{A}) = 0.2$.\n- Group B prevalence (base rate): $\\pi_B = \\mathbb{P}(Y=1 \\mid \\text{B}) = 0.4$.\n- True Positive Rate (TPR, also called sensitivity): $\\mathrm{TPR}_A = \\mathrm{TPR}_B = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1) = 0.85$.\n- False Positive Rate (FPR): $\\mathrm{FPR}_A = \\mathrm{FPR}_B = \\mathbb{P}(\\hat{Y}=1 \\mid Y=0) = 0.15$.\n\nThese settings satisfy the fairness notion of Equal Opportunity (equal True Positive Rate across groups). Another fairness notion, Predictive Parity, requires equal Positive Predictive Value (PPV) across groups, where the Positive Predictive Value is defined as $\\mathrm{PPV} = \\mathbb{P}(Y=1 \\mid \\hat{Y}=1)$.\n\nUsing only the foundational definitions above, Bayes’ theorem, and the law of total probability, first derive a general expression for $\\mathrm{PPV}$ in terms of $\\pi$, $\\mathrm{TPR}$, and $\\mathrm{FPR}$ for a generic group with prevalence $\\pi$. Then, evaluate the derived expression for Group A and Group B using the numerical values given above to obtain $\\mathrm{PPV}_A$ and $\\mathrm{PPV}_B$. Finally, report the pair $\\left(\\mathrm{PPV}_A, \\mathrm{PPV}_B\\right)$.\n\nExpress both values as decimals. Round your answer to $4$ significant figures. Report the pair as a single row matrix.", "solution": "The problem is subjected to validation before proceeding to a solution.\n\n### Step 1: Extract Givens\nThe problem provides the following definitions and values:\n- Ground-truth outcome: $Y \\in \\{0, 1\\}$, where $Y=1$ indicates a complication.\n- Model's binary prediction: $\\hat{Y} \\in \\{0, 1\\}$, where $\\hat{Y}=1$ is an alert for high risk.\n- Group A prevalence: $\\pi_A = \\mathbb{P}(Y=1 \\mid \\text{A}) = 0.2$.\n- Group B prevalence: $\\pi_B = \\mathbb{P}(Y=1 \\mid \\text{B}) = 0.4$.\n- True Positive Rate for both groups: $\\mathrm{TPR}_A = \\mathrm{TPR}_B = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1) = 0.85$.\n- False Positive Rate for both groups: $\\mathrm{FPR}_A = \\mathrm{FPR}_B = \\mathbb{P}(\\hat{Y}=1 \\mid Y=0) = 0.15$.\n- Definition of Positive Predictive Value (PPV): $\\mathrm{PPV} = \\mathbb{P}(Y=1 \\mid \\hat{Y}=1)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria.\n- **Scientifically Grounded:** The problem is firmly rooted in probability theory, statistics, and the standard evaluation of classification models, which are central to bioinformatics and medical data analytics. The concepts of TPR, FPR, prevalence, and PPV are fundamental definitions in this field. The given numerical values are plausible for a real-world clinical scenario.\n- **Well-Posed:** The problem is well-posed. It provides all necessary information (prevalences, TPR, and FPR for two distinct groups) and clearly defines the quantity to be calculated (PPV for each group). The derivation and subsequent calculations lead to a unique, stable, and meaningful solution.\n- **Objective:** The problem is stated using precise, objective mathematical language. It is free of ambiguity, subjectivity, and bias.\n\nThe problem does not exhibit any of the flaws listed in the validation checklist. It is a standard and important exercise in understanding how classifier performance metrics interact with population base rates, which is a critical consideration in assessing algorithmic fairness.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\nThe primary task is to derive an expression for the Positive Predictive Value ($\\mathrm{PPV}$) and then compute it for two distinct groups, A and B.\n\nFirst, we derive the general expression for $\\mathrm{PPV}$ for a group with prevalence $\\pi = \\mathbb{P}(Y=1)$, True Positive Rate $\\mathrm{TPR} = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1)$, and False Positive Rate $\\mathrm{FPR} = \\mathbb{P}(\\hat{Y}=1 \\mid Y=0)$.\n\nThe definition of $\\mathrm{PPV}$ is the conditional probability of the true outcome being positive given that the model predicts a positive outcome:\n$$\n\\mathrm{PPV} = \\mathbb{P}(Y=1 \\mid \\hat{Y}=1)\n$$\nUsing Bayes' theorem, which states $\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(B|A)\\mathbb{P}(A)}{\\mathbb{P}(B)}$, we can rewrite the expression for $\\mathrm{PPV}$ as:\n$$\n\\mathrm{PPV} = \\frac{\\mathbb{P}(\\hat{Y}=1 \\mid Y=1) \\mathbb{P}(Y=1)}{\\mathbb{P}(\\hat{Y}=1)}\n$$\nThe terms in the numerator correspond to the given definitions: $\\mathbb{P}(\\hat{Y}=1 \\mid Y=1) = \\mathrm{TPR}$ and $\\mathbb{P}(Y=1) = \\pi$.\nThe denominator, $\\mathbb{P}(\\hat{Y}=1)$, is the overall probability of the model issuing an alert. We can expand this term using the law of total probability, conditioning on the true outcome $Y$:\n$$\n\\mathbb{P}(\\hat{Y}=1) = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1)\\mathbb{P}(Y=1) + \\mathbb{P}(\\hat{Y}=1 \\mid Y=0)\\mathbb{P}(Y=0)\n$$\nWe can substitute the known quantities into this expansion. We have:\n- $\\mathbb{P}(\\hat{Y}=1 \\mid Y=1) = \\mathrm{TPR}$\n- $\\mathbb{P}(Y=1) = \\pi$\n- $\\mathbb{P}(\\hat{Y}=1 \\mid Y=0) = \\mathrm{FPR}$\n- $\\mathbb{P}(Y=0) = 1 - \\mathbb{P}(Y=1) = 1 - \\pi$\n\nSubstituting these into the expression for $\\mathbb{P}(\\hat{Y}=1)$ gives:\n$$\n\\mathbb{P}(\\hat{Y}=1) = (\\mathrm{TPR} \\cdot \\pi) + (\\mathrm{FPR} \\cdot (1 - \\pi))\n$$\nNow, we substitute this expanded denominator back into the Bayes' theorem formula for $\\mathrm{PPV}$:\n$$\n\\mathrm{PPV} = \\frac{\\mathrm{TPR} \\cdot \\pi}{(\\mathrm{TPR} \\cdot \\pi) + (\\mathrm{FPR} \\cdot (1 - \\pi))}\n$$\nThis is the required general expression for $\\mathrm{PPV}$ in terms of $\\pi$, $\\mathrm{TPR}$, and $\\mathrm{FPR}$.\n\nNext, we evaluate this expression for Group A and Group B using the provided numerical values. For both groups, $\\mathrm{TPR} = 0.85$ and $\\mathrm{FPR} = 0.15$.\n\nFor Group A, the prevalence is $\\pi_A = 0.2$. The Positive Predictive Value for Group A, $\\mathrm{PPV}_A$, is:\n$$\n\\mathrm{PPV}_A = \\frac{0.85 \\cdot 0.2}{(0.85 \\cdot 0.2) + (0.15 \\cdot (1 - 0.2))}\n$$\n$$\n\\mathrm{PPV}_A = \\frac{0.17}{0.17 + (0.15 \\cdot 0.8)}\n$$\n$$\n\\mathrm{PPV}_A = \\frac{0.17}{0.17 + 0.12}\n$$\n$$\n\\mathrm{PPV}_A = \\frac{0.17}{0.29} \\approx 0.586206...\n$$\nRounding to $4$ significant figures, we get $\\mathrm{PPV}_A \\approx 0.5862$.\n\nFor Group B, the prevalence is $\\pi_B = 0.4$. The Positive Predictive Value for Group B, $\\mathrm{PPV}_B$, is:\n$$\n\\mathrm{PPV}_B = \\frac{0.85 \\cdot 0.4}{(0.85 \\cdot 0.4) + (0.15 \\cdot (1 - 0.4))}\n$$\n$$\n\\mathrm{PPV}_B = \\frac{0.34}{0.34 + (0.15 \\cdot 0.6)}\n$$\n$$\n\\mathrm{PPV}_B = \\frac{0.34}{0.34 + 0.09}\n$$\n$$\n\\mathrm{PPV}_B = \\frac{0.34}{0.43} \\approx 0.790697...\n$$\nRounding to $4$ significant figures, we get $\\mathrm{PPV}_B \\approx 0.7907$.\n\nThe final result is the pair of values $(\\mathrm{PPV}_A, \\mathrm{PPV}_B)$. This result demonstrates that even when the model's operating characteristics (TPR and FPR) are identical across groups, differences in the underlying prevalence of the condition lead to different Positive Predictive Values. Thus, satisfying Equal Opportunity ($\\mathrm{TPR}_A = \\mathrm{TPR}_B$) does not guarantee Predictive Parity ($\\mathrm{PPV}_A = \\mathrm{PPV}_B$), a crucial insight in the study of algorithmic fairness.", "answer": "$$\\boxed{\\begin{pmatrix} 0.5862 & 0.7907 \\end{pmatrix}}$$", "id": "4562332"}, {"introduction": "Identifying disparities is only the first step; the next is to intervene. This practice moves from binary classifiers to more common continuous-score models and introduces a powerful post-processing technique: setting group-specific decision thresholds to enforce a fairness criterion. By working with score distributions, you will learn how to mathematically derive the precise thresholds needed to achieve Equal Opportunity, translating a fairness goal into a concrete clinical policy. [@problem_id:4562360]", "problem": "A hospital deploys a continuous-risk sepsis prediction model that outputs a real-valued score $S$ for each patient. Let $Y \\in \\{0,1\\}$ denote the true sepsis status ($Y=1$ for sepsis within the prediction horizon), and let $G \\in \\{\\text{A},\\text{B}\\}$ denote a protected attribute indicating two demographic groups. The clinical policy is to intervene when $S > t_G$, where $t_G$ is a group-specific decision threshold. The hospital adopts the equal opportunity fairness criterion: the True Positive Rate (TPR) must be equal across groups, where the True Positive Rate (TPR) is defined as $\\mathbb{P}(S>t_G \\mid Y=1,G)$. To ensure minimum sensitivity for safety, the hospital further mandates that this equalized TPR must be at least $0.8$ for each group.\n\nAssume the following scientifically plausible score-generating process, which has been validated on held-out clinical data: for group $\\text{A}$, $S \\mid (Y=1,G=\\text{A}) \\sim \\mathcal{N}(1,1)$ and $S \\mid (Y=0,G=\\text{A}) \\sim \\mathcal{N}(0,1)$; for group $\\text{B}$, $S \\mid (Y=1,G=\\text{B}) \\sim \\mathcal{N}(1.2,1)$ and $S \\mid (Y=0,G=\\text{B}) \\sim \\mathcal{N}(0,1)$. Here $\\mathcal{N}(\\mu,\\sigma^{2})$ denotes a Gaussian distribution with mean $\\mu$ and variance $\\sigma^{2}$. Let $\\Phi$ denote the cumulative distribution function of the standard normal distribution.\n\nStarting only from the definitions of TPR as a conditional probability and the properties of the Gaussian distribution (including its cumulative distribution function), derive the decision thresholds $t_{\\text{A}}$ and $t_{\\text{B}}$ that satisfy the equal opportunity requirement with an equalized TPR level of $0.8$. Express your final numeric thresholds rounded to four significant figures. No units are required.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n-   Sepsis risk score: $S \\in \\mathbb{R}$\n-   True sepsis status: $Y \\in \\{0, 1\\}$\n-   Protected attribute (group): $G \\in \\{\\text{A}, \\text{B}\\}$\n-   Decision rule: Intervene if $S > t_G$, where $t_G$ is a group-specific threshold.\n-   Fairness criterion: Equal opportunity, defined as equal True Positive Rate (TPR) across groups.\n-   TPR definition: $\\text{TPR}_G = \\mathbb{P}(S > t_G \\mid Y=1, G)$\n-   Performance requirement: The equalized TPR must be $0.8$.\n-   Score distribution for group A, positive class: $S \\mid (Y=1, G=\\text{A}) \\sim \\mathcal{N}(\\mu_{\\text{A},1}=1, \\sigma^2=1)$\n-   Score distribution for group A, negative class: $S \\mid (Y=0, G=\\text{A}) \\sim \\mathcal{N}(0, 1)$\n-   Score distribution for group B, positive class: $S \\mid (Y=1, G=\\text{B}) \\sim \\mathcal{N}(\\mu_{\\text{B},1}=1.2, \\sigma^2=1)$\n-   Score distribution for group B, negative class: $S \\mid (Y=0, G=\\text{B}) \\sim \\mathcal{N}(0, 1)$\n-   $\\Phi$ is the cumulative distribution function (CDF) of the standard normal distribution $\\mathcal{N}(0,1)$.\n-   The task is to find the numerical values of $t_{\\text{A}}$ and $t_{\\text{B}}$ rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, belonging to the established field of algorithmic fairness in medical machine learning. The use of Gaussian distributions to model scores is a standard and valid simplifying assumption. The concepts of True Positive Rate and equal opportunity are well-defined statistical metrics. The problem is well-posed; it provides all necessary information (distributions and target TPR) to uniquely determine the thresholds $t_{\\text{A}}$ and $t_{\\text{B}}$. The language is precise and objective. The information about the negative class distributions is extraneous to the calculation of TPR-based thresholds but does not create a contradiction. The problem is valid.\n\n### Step 3: Derivation\nThe objective is to find the decision thresholds $t_{\\text{A}}$ and $t_{\\text{B}}$ for groups A and B, respectively, that satisfy the equal opportunity criterion at a TPR level of $0.8$. This means we must solve for $t_{\\text{A}}$ and $t_{\\text{B}}$ such that:\n$$\n\\text{TPR}_{\\text{A}} = \\mathbb{P}(S > t_{\\text{A}} \\mid Y=1, G=\\text{A}) = 0.8\n$$\n$$\n\\text{TPR}_{\\text{B}} = \\mathbb{P}(S > t_{\\text{B}} \\mid Y=1, G=\\text{B}) = 0.8\n$$\n\nLet's derive each threshold separately.\n\n**Derivation of $t_{\\text{A}}$:**\nWe are given that the distribution of scores for septic patients in group A is $S \\mid (Y=1, G=\\text{A}) \\sim \\mathcal{N}(\\mu_{\\text{A},1}=1, \\sigma^2=1)$. The standard deviation is $\\sigma = \\sqrt{1} = 1$.\nTo calculate the probability $\\mathbb{P}(S > t_{\\text{A}})$, we first standardize the random variable $S$. Let $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0,1)$. The transformation is:\n$$\nZ = \\frac{S - \\mu_{\\text{A},1}}{\\sigma} = \\frac{S-1}{1} = S-1\n$$\nThe condition $S > t_{\\text{A}}$ is equivalent to $S-1 > t_{\\text{A}}-1$, which in terms of $Z$ is $Z > t_{\\text{A}}-1$.\nThe requirement on $\\text{TPR}_{\\text{A}}$ becomes:\n$$\n\\mathbb{P}(Z > t_{\\text{A}}-1) = 0.8\n$$\nThe probability $\\mathbb{P}(Z>z)$ for a standard normal variable $Z$ is related to its cumulative distribution function $\\Phi(z) = \\mathbb{P}(Z \\le z)$ by $\\mathbb{P}(Z>z) = 1 - \\Phi(z)$.\nThus, we have:\n$$\n1 - \\Phi(t_{\\text{A}}-1) = 0.8\n$$\nSolving for $\\Phi(t_{\\text{A}}-1)$:\n$$\n\\Phi(t_{\\text{A}}-1) = 1 - 0.8 = 0.2\n$$\nTo find the value of $t_{\\text{A}}-1$, we use the inverse of the standard normal CDF, also known as the quantile function, denoted $\\Phi^{-1}$:\n$$\nt_{\\text{A}}-1 = \\Phi^{-1}(0.2)\n$$\nSolving for $t_{\\text{A}}$:\n$$\nt_{\\text{A}} = 1 + \\Phi^{-1}(0.2)\n$$\nFrom standard statistical tables or computational software, the value of the $20$th percentile of the standard normal distribution is $\\Phi^{-1}(0.2) \\approx -0.8416212$.\nSubstituting this value:\n$$\nt_{\\text{A}} \\approx 1 + (-0.8416212) = 0.1583788\n$$\nRounding to four significant figures, we get $t_{\\text{A}} = 0.1584$.\n\n**Derivation of $t_{\\text{B}}$:**\nThe procedure for group B is analogous. We are given the score distribution for septic patients in group B: $S \\mid (Y=1, G=\\text{B}) \\sim \\mathcal{N}(\\mu_{\\text{B},1}=1.2, \\sigma^2=1)$. The standard deviation is again $\\sigma = 1$.\nThe standardization for $S$ under this condition is:\n$$\nZ = \\frac{S - \\mu_{\\text{B},1}}{\\sigma} = \\frac{S-1.2}{1} = S-1.2\n$$\nThe condition $S > t_{\\text{B}}$ is equivalent to $Z > t_{\\text{B}}-1.2$.\nThe requirement $\\text{TPR}_{\\text{B}} = 0.8$ becomes:\n$$\n\\mathbb{P}(Z > t_{\\text{B}}-1.2) = 0.8\n$$\nUsing the CDF $\\Phi$:\n$$\n1 - \\Phi(t_{\\text{B}}-1.2) = 0.8\n$$\n$$\n\\Phi(t_{\\text{B}}-1.2) = 0.2\n$$\nApplying the inverse CDF $\\Phi^{-1}$:\n$$\nt_{\\text{B}}-1.2 = \\Phi^{-1}(0.2)\n$$\nSolving for $t_{\\text{B}}$:\n$$\nt_{\\text{B}} = 1.2 + \\Phi^{-1}(0.2)\n$$\nUsing the same numerical value $\\Phi^{-1}(0.2) \\approx -0.8416212$:\n$$\nt_{\\text{B}} \\approx 1.2 + (-0.8416212) = 0.3583788\n$$\nRounding to four significant figures, we get $t_{\\text{B}} = 0.3584$.\n\nThe required thresholds are $t_{\\text{A}} \\approx 0.1584$ and $t_{\\text{B}} \\approx 0.3584$. The different thresholds are necessary to achieve the same TPR because the underlying score distributions for the positive class differ in their mean between the two groups.", "answer": "$$\\boxed{\\begin{pmatrix} 0.1584 & 0.3584 \\end{pmatrix}}$$", "id": "4562360"}]}