{"hands_on_practices": [{"introduction": "The Laplace mechanism is a cornerstone of differential privacy, providing a straightforward way to protect data by adding precisely calibrated noise. This first exercise takes you from foundational theory to hands-on practice. You will derive the necessary noise scale from the formal definition of $\\epsilon$-differential privacy and then use simulation to explore the tangible trade-off between the strength of the privacy guarantee, $\\epsilon$, and the accuracy of the released statistic [@problem_id:4556484].", "problem": "Consider releasing an integer-valued count derived from a health registry query (for example, the number of individuals with a specific diagnosis in a hospital’s database) under the mathematical framework of Differential Privacy (DP). Let two datasets be called neighboring datasets if they differ in the records of exactly one individual. Let the query function be a deterministic count with global sensitivity defined as the maximum change in the function’s output over all neighboring datasets. Suppose a mechanism releases the noisy result by adding noise drawn from a centered Laplace distribution. Starting from the formal definition of $\\epsilon$-Differential Privacy (DP) and the definition of global sensitivity, derive the necessary condition on the noise distribution such that the mechanism satisfies $\\epsilon$-DP, and from this condition, derive the scale parameter of the Laplace distribution required for a count query with a given sensitivity. Then, for the specific parameter values provided below, compute the Laplace noise scale and estimate, by Monte Carlo simulation, the probability that the absolute deviation between the released value and the true count is at least a specified nonnegative threshold. The probability must be expressed as a decimal.\n\nFundamental base to use:\n- The formal definition of $\\epsilon$-Differential Privacy (DP): for all measurable sets $S$ and all neighboring datasets $D$ and $D'$, the mechanism $\\mathcal{M}$ must satisfy $\\Pr[\\mathcal{M}(D) \\in S] \\leq e^{\\epsilon} \\Pr[\\mathcal{M}(D') \\in S]$.\n- The global sensitivity of a function $f$ is $\\Delta f = \\max_{D,D'} \\lvert f(D) - f(D') \\rvert$ over all neighboring datasets $D$ and $D'$.\n- The Laplace distribution with location $0$ and scale $b$ has probability density function $p(x) = \\frac{1}{2b} \\exp\\!\\left(-\\frac{\\lvert x \\rvert}{b}\\right)$.\n\nTasks:\n- Using the above foundational definitions, derive the scale parameter $b$ of the Laplace distribution required to achieve $\\epsilon$-DP for a deterministic count query with global sensitivity $\\Delta f$.\n- For each test case, compute the scale $b$ and estimate, by Monte Carlo with a fixed random seed, the probability $\\Pr(\\lvert X \\rvert \\geq \\tau)$ where $X$ is the Laplace noise added to the true count and $\\tau \\ge 0$ is the threshold. Also compute the exact probability analytically as a function of $b$ and $\\tau$ derived from the Laplace distribution.\n\nSimulation protocol:\n- For each test case, draw $N$ independent samples from $\\mathrm{Laplace}(0,b)$ and estimate the deviation probability as the fraction of samples with $\\lvert X \\rvert \\geq \\tau$.\n- Use a fixed random seed of $123456$ for reproducibility.\n\nTest suite:\n- Case $1$: $\\epsilon = 0.5$, $\\Delta f = 1$, $\\tau = 3$, $N = 200000$.\n- Case $2$: $\\epsilon = 0.05$, $\\Delta f = 1$, $\\tau = 3$, $N = 200000$.\n- Case $3$: $\\epsilon = 5.0$, $\\Delta f = 1$, $\\tau = 3$, $N = 200000$.\n- Case $4$: $\\epsilon = 0.5$, $\\Delta f = 2$, $\\tau = 3$, $N = 200000$.\n- Case $5$: $\\epsilon = 0.5$, $\\Delta f = 1$, $\\tau = 0$, $N = 200000$.\n- Case $6$: $\\epsilon = 0.5$, $\\Delta f = 1$, $\\tau = 3.5$, $N = 200000$.\n- Case $7$: $\\epsilon = 0.5$, $\\Delta f = 1$, $\\tau = 50$, $N = 200000$.\n\nAnswer specification:\n- For each test case, output a list containing three floating-point numbers: the Laplace scale $b$, the simulated probability estimate, and the exact analytical probability. Each number must be reported as a decimal, and each result must be rounded to six decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is itself a list of the three rounded decimals in the order $[b, p_{\\text{sim}}, p_{\\text{exact}}]$. For example, the format is $[[b_1,p_{\\text{sim},1},p_{\\text{exact},1}],[b_2,p_{\\text{sim},2},p_{\\text{exact},2}],\\dots]$.", "solution": "The problem requires a formal derivation of the scale parameter for the Laplace mechanism in differential privacy, followed by a computational analysis for several test cases. The analysis involves both a Monte Carlo simulation and an analytical calculation of a deviation probability.\n\n### Step 1: Derivation of the Laplace Scale Parameter\n\nThe objective is to determine the scale parameter $b$ of a centered Laplace distribution such that adding noise drawn from this distribution to the output of a function $f$ satisfies $\\epsilon$-differential privacy ($\\epsilon$-DP).\n\nLet $f: \\mathcal{D}^n \\to \\mathbb{Z}$ be a deterministic integer-valued count query. The mechanism $\\mathcal{M}$ releases a noisy version of the query result: $\\mathcal{M}(D) = f(D) + X$, where $X$ is a random variable drawn from a Laplace distribution with location $0$ and scale $b > 0$. The probability density function (PDF) of this noise is $p(x) = \\frac{1}{2b} \\exp(-\\frac{\\lvert x \\rvert}{b})$.\n\nThe probability of the mechanism $\\mathcal{M}$ on a database $D$ producing an output $z \\in \\mathbb{R}$ is given by the PDF of the noise evaluated at $z - f(D)$:\n$$\np(z|D) = \\frac{1}{2b} \\exp\\left(-\\frac{\\lvert z - f(D) \\rvert}{b}\\right)\n$$\n\nThe definition of $\\epsilon$-DP states that for any two neighboring datasets $D$ and $D'$ (differing by one individual's record) and for any set of possible outputs $S$, the following inequality must hold:\n$$\n\\Pr[\\mathcal{M}(D) \\in S] \\leq e^{\\epsilon} \\Pr[\\mathcal{M}(D') \\in S]\n$$\nThis condition is satisfied if, for any possible output $z$, the ratio of the probability densities is bounded:\n$$\n\\frac{p(z|D)}{p(z|D')} \\leq e^{\\epsilon}\n$$\nLet us evaluate this ratio:\n$$\n\\frac{p(z|D)}{p(z|D')} = \\frac{\\frac{1}{2b} \\exp\\left(-\\frac{\\lvert z - f(D) \\rvert}{b}\\right)}{\\frac{1}{2b} \\exp\\left(-\\frac{\\lvert z - f(D') \\rvert}{b}\\right)} = \\exp\\left(\\frac{\\lvert z - f(D') \\rvert - \\lvert z - f(D) \\rvert}{b}\\right)\n$$\nTo ensure the DP condition, we must bound the term in the exponent. By the reverse triangle inequality, $\\lvert a \\rvert - \\lvert c \\rvert \\leq \\lvert a - c \\rvert$. Let $a = z - f(D')$ and $c = z - f(D)$. Then:\n$$\n\\lvert z - f(D') \\rvert - \\lvert z - f(D) \\rvert \\leq \\lvert (z - f(D')) - (z - f(D)) \\rvert = \\lvert f(D) - f(D') \\rvert\n$$\nThe global sensitivity, $\\Delta f$, is defined as the maximum possible value of this difference over all pairs of neighboring datasets $D, D'$:\n$$\n\\Delta f = \\max_{D,D'} \\lvert f(D) - f(D') \\rvert\n$$\nFor a simple count query, where adding or removing one individual's record changes the count by at most $1$, the global sensitivity is $\\Delta f = 1$.\n\nSubstituting this maximum into our inequality for the exponent yields the upper bound for the probability ratio:\n$$\n\\frac{p(z|D)}{p(z|D')} \\leq \\exp\\left(\\frac{\\Delta f}{b}\\right)\n$$\nTo satisfy $\\epsilon$-DP, this bound must be no greater than $e^{\\epsilon}$:\n$$\n\\exp\\left(\\frac{\\Delta f}{b}\\right) \\leq e^{\\epsilon}\n$$\nTaking the natural logarithm of both sides gives:\n$$\n\\frac{\\Delta f}{b} \\leq \\epsilon\n$$\nTo add the minimum amount of noise that satisfies the privacy guarantee (i.e., to maximize utility), we select the smallest possible value for $b$, which is achieved at equality:\n$$\nb = \\frac{\\Delta f}{\\epsilon}\n$$\nThis is the required scale parameter for the Laplace mechanism to achieve $\\epsilon$-DP for a function with global sensitivity $\\Delta f$.\n\n### Step 2: Analytical Calculation of Deviation Probability\n\nThe problem asks for the probability that the absolute deviation of the noise, $\\lvert X \\rvert$, is at least some threshold $\\tau \\geq 0$, where $X \\sim \\mathrm{Laplace}(0,b)$.\n$$\n\\Pr(\\lvert X \\rvert \\geq \\tau)\n$$\nThis is equivalent to $1 - \\Pr(\\lvert X \\rvert < \\tau) = 1 - \\Pr(-\\tau < X < \\tau)$. Alternatively, due to the symmetry of the Laplace distribution around $0$, we can write:\n$$\n\\Pr(\\lvert X \\rvert \\geq \\tau) = \\Pr(X \\geq \\tau) + \\Pr(X \\leq -\\tau) = 2 \\Pr(X \\geq \\tau)\n$$\nWe compute $\\Pr(X \\geq \\tau)$ by integrating the PDF from $\\tau$ to $\\infty$. For $x \\geq \\tau \\geq 0$, $\\lvert x \\rvert = x$:\n$$\n\\Pr(X \\geq \\tau) = \\int_{\\tau}^{\\infty} \\frac{1}{2b} \\exp\\left(-\\frac{x}{b}\\right) dx\n$$\n$$\n= \\frac{1}{2b} \\left[ -b \\exp\\left(-\\frac{x}{b}\\right) \\right]_{\\tau}^{\\infty} = -\\frac{1}{2} \\left[ \\lim_{x \\to \\infty} \\exp\\left(-\\frac{x}{b}\\right) - \\exp\\left(-\\frac{\\tau}{b}\\right) \\right]\n$$\n$$\n= -\\frac{1}{2} \\left[ 0 - \\exp\\left(-\\frac{\\tau}{b}\\right) \\right] = \\frac{1}{2} \\exp\\left(-\\frac{\\tau}{b}\\right)\n$$\nTherefore, the total probability is:\n$$\n\\Pr(\\lvert X \\rvert \\geq \\tau) = 2 \\times \\frac{1}{2} \\exp\\left(-\\frac{\\tau}{b}\\right) = \\exp\\left(-\\frac{\\tau}{b}\\right)\n$$\nFor the special case where $\\tau = 0$, the probability is $\\exp(0) = 1$, as expected.\n\n### Step 3: Computational Implementation\n\nFor each test case defined by parameters $(\\epsilon, \\Delta f, \\tau, N)$:\n1.  The Laplace scale parameter is computed as $b = \\Delta f / \\epsilon$.\n2.  A Monte Carlo simulation is performed. A total of $N=200000$ random samples are drawn from the $\\mathrm{Laplace}(0, b)$ distribution using a fixed random seed of $123456$ for reproducibility.\n3.  The simulated probability, $p_{\\text{sim}}$, is estimated as the fraction of samples whose absolute value is greater than or equal to the threshold $\\tau$.\n4.  The exact analytical probability, $p_{\\text{exact}}$, is computed using the derived formula $p_{\\text{exact}} = \\exp(-\\tau/b)$.\n5.  The results for each test case, consisting of the scale $b$, the simulated probability $p_{\\text{sim}}$, and the exact probability $p_{\\text{exact}}$, are rounded to six decimal places. The final output is a list of these results, formatted as specified.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the differential privacy problem for the given test suite.\n    \n    For each case, it computes:\n    1. The Laplace scale parameter 'b'.\n    2. The simulated probability that the noise exceeds a threshold.\n    3. The exact analytical probability for the same event.\n    \"\"\"\n\n    # Test suite as specified in the problem statement.\n    # Each case is a tuple: (epsilon, delta_f, tau, N)\n    test_cases = [\n        (0.5, 1, 3, 200000),   # Case 1\n        (0.05, 1, 3, 200000),  # Case 2\n        (5.0, 1, 3, 200000),   # Case 3\n        (0.5, 2, 3, 200000),   # Case 4\n        (0.5, 1, 0, 200000),   # Case 5\n        (0.5, 1, 3.5, 200000), # Case 6\n        (0.5, 1, 50, 200000)   # Case 7\n    ]\n\n    # Initialize the random number generator with a fixed seed for reproducibility.\n    # The use of default_rng is the modern, recommended practice in NumPy.\n    rng = np.random.default_rng(123456)\n\n    all_results = []\n\n    for epsilon, delta_f, tau, N in test_cases:\n        # Step 1: Compute the Laplace scale parameter 'b'.\n        # b = sensitivity / epsilon\n        if epsilon <= 0:\n            # Epsilon must be positive. Handle this edge case, though not in test suite.\n            b = np.inf\n        else:\n            b = delta_f / epsilon\n\n        # Step 2: Estimate the probability via Monte Carlo simulation.\n        # Draw N samples from the Laplace distribution with location 0 and scale b.\n        laplace_samples = rng.laplace(loc=0.0, scale=b, size=N)\n        \n        # Count the number of samples where the absolute value is >= tau.\n        deviation_count = np.sum(np.abs(laplace_samples) >= tau)\n        \n        # The simulated probability is the fraction of such samples.\n        p_sim = deviation_count / N\n\n        # Step 3: Compute the exact analytical probability.\n        # The probability is P(|X| >= tau) = exp(-tau / b) for X ~ Laplace(0, b).\n        if b == 0: # Sensitivity is 0\n            p_exact = 1.0 if tau == 0 else 0.0\n        elif np.isinf(b): # Epsilon is 0\n            p_exact = 1.0 # Infinite noise, always deviates\n        else:\n            p_exact = np.exp(-tau / b)\n\n        # Store the results, rounded to six decimal places, as required.\n        result_triplet = [b, p_sim, p_exact]\n        all_results.append(result_triplet)\n\n    # Format the final output string as a list of lists of floats,\n    # with each number formatted to six decimal places.\n    case_strings = []\n    for res in all_results:\n        # rounding is done here before formatting to match the requirement\n        b_rounded = round(res[0], 6)\n        psim_rounded = round(res[1], 6)\n        pexact_rounded = round(res[2], 6)\n\n        # f-string formatting ensures trailing zeros are printed for 6 decimal places\n        b_str = f\"{b_rounded:.6f}\"\n        psim_str = f\"{psim_rounded:.6f}\"\n        pexact_str = f\"{pexact_rounded:.6f}\"\n        case_strings.append(f\"[{b_str},{psim_str},{pexact_str}]\")\n    \n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```", "id": "4556484"}, {"introduction": "While noise addition is key to privacy, it can sometimes produce outputs that are nonsensical in the real world, such as a negative count of patients. This practice introduces the Gaussian mechanism, another fundamental tool, and confronts this issue directly. You will analyze the probability of generating an invalid output and, more importantly, explore the powerful principle of post-processing—a way to clean up noisy results into a valid format without any additional privacy cost [@problem_id:4556466].", "problem": "A hospital intends to publish a differentially private daily count of laboratory-confirmed cases of a respiratory virus. Let the true count be a nonnegative integer $c \\in \\mathbb{Z}_{\\ge 0}$. The hospital uses the Gaussian mechanism: it releases $\\tilde{c} = c + Z$, where $Z \\sim \\mathcal{N}(0, \\sigma^{2})$, and the global sensitivity of the count query under neighboring datasets differing by one record is $1$. Assume the Gaussian mechanism has been calibrated to satisfy $(\\varepsilon, \\delta)$-differential privacy (differential privacy (DP)), but you do not need the calibration formula.\n\nUsing only fundamental definitions of the normal distribution and the post-processing invariance of differential privacy, do the following:\n\n1. Derive from first principles an exact expression for the probability that the released value is negative, $\\mathbb{P}[\\tilde{c} < 0]$, as a function of $c$ and $\\sigma$.\n2. Specialize your expression to the case $c = 23$ and $\\sigma = 5.7$ and evaluate the probability numerically. Round your answer to $4$ significant figures and express it as a decimal (not a percentage).\n3. Propose a deterministic post-processing mapping that ensures the finally published value is never negative, and justify rigorously why applying this mapping preserves differential privacy without changing $(\\varepsilon, \\delta)$.\n\nYour final numeric answer should be only the probability requested in part $2$.", "solution": "The problem asks for a three-part analysis of a Gaussian mechanism for differential privacy applied to a daily count of virus cases.\n\n### Part 1: Derivation of the Probability of a Negative Released Value\n\nWe are given that the true count is a non-negative integer $c \\in \\mathbb{Z}_{\\ge 0}$. The released value is $\\tilde{c} = c + Z$, where the noise term $Z$ is drawn from a normal distribution with mean $0$ and variance $\\sigma^2$, denoted as $Z \\sim \\mathcal{N}(0, \\sigma^2)$. We are asked to find the probability that the released value $\\tilde{c}$ is negative, i.e., $\\mathbb{P}[\\tilde{c} < 0]$.\n\nWe start by substituting the definition of $\\tilde{c}$:\n$$\n\\mathbb{P}[\\tilde{c} < 0] = \\mathbb{P}[c + Z < 0]\n$$\nThis inequality can be rearranged to isolate the random variable $Z$:\n$$\n\\mathbb{P}[Z < -c]\n$$\nTo evaluate this probability, we standardize the normal random variable $Z$. A standard normal random variable, let's call it $S$, has a mean of $0$ and a standard deviation of $1$, i.e., $S \\sim \\mathcal{N}(0, 1)$. The variable $Z$ is related to $S$ by the transformation $Z = \\sigma S$. Substituting this into our inequality gives:\n$$\n\\mathbb{P}[\\sigma S < -c]\n$$\nSince $\\sigma$ is a standard deviation, it is strictly positive ($\\sigma > 0$). We can therefore divide the inequality by $\\sigma$ without changing its direction:\n$$\n\\mathbb{P}\\left[S < -\\frac{c}{\\sigma}\\right]\n$$\nThis is the probability that a standard normal random variable $S$ takes a value less than $-\\frac{c}{\\sigma}$. This probability is given by the cumulative distribution function (CDF) of the standard normal distribution, which is conventionally denoted by $\\Phi(z)$.\n$$\n\\mathbb{P}\\left[S < z\\right] = \\Phi(z)\n$$\nTherefore, the desired probability is:\n$$\n\\mathbb{P}[\\tilde{c} < 0] = \\Phi\\left(-\\frac{c}{\\sigma}\\right)\n$$\nThe problem asks for a derivation from first principles. The CDF $\\Phi(z)$ is defined by the integral of the probability density function (PDF) of the standard normal distribution, which is $\\phi(t) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{t^2}{2}\\right)$. The exact expression for the probability is thus:\n$$\n\\mathbb{P}[\\tilde{c} < 0] = \\int_{-\\infty}^{-c/\\sigma} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{t^2}{2}\\right) dt\n$$\nThis expression is a function of $c$ and $\\sigma$, as required. It is also often expressed using the complementary error function, $\\text{erfc}(x)$, where $\\Phi(z) = \\frac{1}{2}\\text{erfc}(-z/\\sqrt{2})$. Due to the symmetry of the normal distribution, $\\Phi(-z) = 1 - \\Phi(z)$, so the probability can also be written as $1 - \\Phi(c/\\sigma)$.\n\n### Part 2: Numerical Evaluation\n\nWe are asked to evaluate the expression for the specific case where the true count is $c = 23$ and the noise standard deviation is $\\sigma = 5.7$.\nThe argument of the CDF is:\n$$\nz = -\\frac{c}{\\sigma} = -\\frac{23}{5.7}\n$$\nCalculating this value:\n$$\nz \\approx -4.035087719...\n$$\nThe probability is $\\Phi(-4.035087719...)$. This value must be found using numerical methods or statistical software, as the integral does not have a closed-form elementary solution.\nUsing a standard numerical library, we find:\n$$\n\\mathbb{P}[\\tilde{c} < 0] = \\Phi(-4.035087719...) \\approx 0.0000272363...\n$$\nThe problem requires rounding this result to $4$ significant figures. The first significant figure is the first non-zero digit, which is $2$.\nThe first four significant figures are $2$, $7$, $2$, $3$. The fifth significant figure is $6$, which is greater than or equal to $5$, so we round up the last digit ($3$) to $4$.\nThe rounded value is $0.00002724$.\n\n### Part 3: Post-processing for Non-negativity\n\nThe Gaussian mechanism can produce negative values, which are nonsensical for a count. We need a deterministic post-processing mapping to ensure the final published value is always non-negative.\n\nA suitable and widely-used mapping is to replace any negative output with $0$, while leaving non-negative outputs unchanged. Let the post-processed value be $c_{final}$. The mapping function $f: \\mathbb{R} \\to \\mathbb{R}_{\\ge 0}$ is applied to the noisy output $\\tilde{c}$:\n$$\nc_{final} = f(\\tilde{c}) = \\max(0, \\tilde{c})\n$$\nThis can be written piecewise as:\n$$\nf(\\tilde{c}) = \\begin{cases} \\tilde{c} & \\text{if } \\tilde{c} \\ge 0 \\\\ 0 & \\text{if } \\tilde{c} < 0 \\end{cases}\n$$\nThis mapping ensures the final published value is never negative.\n\nWe must now justify rigorously why this post-processing step preserves the $(\\varepsilon, \\delta)$-differential privacy of the original mechanism. This justification relies on the post-processing invariance property of differential privacy.\n\n**Justification:**\nLet $\\mathcal{M}$ be the original Gaussian mechanism which, on a database $D$, outputs $\\tilde{c} = c(D) + Z$. We are given that $\\mathcal{M}$ is $(\\varepsilon, \\delta)$-differentially private. By definition, this means for any two neighboring databases $D_1$ and $D_2$ (differing in one individual's record) and for any set of possible outputs $S \\subseteq \\text{range}(\\mathcal{M})$, the following inequality holds:\n$$\n\\mathbb{P}[\\mathcal{M}(D_1) \\in S] \\le \\exp(\\varepsilon) \\cdot \\mathbb{P}[\\mathcal{M}(D_2) \\in S] + \\delta\n$$\nOur post-processed mechanism is $\\mathcal{M}' = f \\circ \\mathcal{M}$, where $f(\\tilde{c}) = \\max(0, \\tilde{c})$. We want to show that $\\mathcal{M}'$ is also $(\\varepsilon, \\delta)$-differentially private.\n\nLet $S'$ be any set of possible outputs from the post-processed mechanism $\\mathcal{M}'$ (so $S' \\subseteq \\mathbb{R}_{\\ge 0}$). We need to prove:\n$$\n\\mathbb{P}[\\mathcal{M}'(D_1) \\in S'] \\le \\exp(\\varepsilon) \\cdot \\mathbb{P}[\\mathcal{M}'(D_2) \\in S'] + \\delta\n$$\nThe event $\\mathcal{M}'(D_1) \\in S'$ is equivalent to $f(\\mathcal{M}(D_1)) \\in S'$. This, in turn, is equivalent to the original mechanism's output falling into the pre-image of the set $S'$ under the function $f$. Let this pre-image be $S_{pre} = f^{-1}(S') = \\{y \\in \\mathbb{R} \\mid f(y) \\in S'\\}$.\n\nThus, we can rewrite the probability for $\\mathcal{M}'$ in terms of $\\mathcal{M}$:\n$$\n\\mathbb{P}[\\mathcal{M}'(D_1) \\in S'] = \\mathbb{P}[\\mathcal{M}(D_1) \\in S_{pre}]\n$$\nAnd similarly for $D_2$:\n$$\n\\mathbb{P}[\\mathcal{M}'(D_2) \\in S'] = \\mathbb{P}[\\mathcal{M}(D_2) \\in S_{pre}]\n$$\nSince $\\mathcal{M}$ is $(\\varepsilon, \\delta)$-DP, the privacy inequality holds for the set $S_{pre}$:\n$$\n\\mathbb{P}[\\mathcal{M}(D_1) \\in S_{pre}] \\le \\exp(\\varepsilon) \\cdot \\mathbb{P}[\\mathcal{M}(D_2) \\in S_{pre}] + \\delta\n$$\nSubstituting the equivalent expressions for $\\mathcal{M}'$ back into this inequality, we obtain:\n$$\n\\mathbb{P}[\\mathcal{M}'(D_1) \\in S'] \\le \\exp(\\varepsilon) \\cdot \\mathbb{P}[\\mathcal{M}'(D_2) \\in S'] + \\delta\n$$\nThis is the definition of $(\\varepsilon, \\delta)$-differential privacy for the mechanism $\\mathcal{M}'$. The function $f$ is independent of the private database and is applied to the output of the private mechanism. Therefore, any data-independent processing of the output of a differentially private mechanism does not degrade its privacy guarantee. The privacy parameters $(\\varepsilon, \\delta)$ remain unchanged.", "answer": "$$\n\\boxed{0.00002724}\n$$", "id": "4556466"}, {"introduction": "Real-world data analysis rarely involves a single, one-off query; instead, analysts often perform a series of related queries over time. Each query leaks a small amount of information, and the total privacy loss accumulates. This final practice addresses this crucial challenge by exploring composition theorems, which allow us to rigorously track the total privacy budget. You will quantify the cumulative privacy loss for a realistic longitudinal analysis using the advanced composition theorem, a vital skill for deploying responsible, long-term private data systems [@problem_id:4556441].", "problem": "A hospital maintains a cohort of $M = 1000$ patients with daily normalized serum creatinine values $x_{i,t} \\in [0,1]$ for patient $i \\in \\{1,\\dots,M\\}$ and day $t$. Each day $t$ the hospital releases a sliding-window aggregate defined as the $30$-day window average of the cohort’s daily means, namely the query\n$$\nf_{t}(D) \\;=\\; \\frac{1}{w}\\sum_{s=t-w+1}^{t} \\left(\\frac{1}{M}\\sum_{i=1}^{M} x_{i,s}\\right),\n$$\nwith window length $w=30$. The hospital uses the Laplace mechanism to privatize each release: it publishes $f_{t}(D) + Z_{t}$ where $Z_{t}$ is a Laplace random variable with scale chosen to achieve a per-release privacy parameter $\\epsilon_{0} = 0.05$ under Differential Privacy (DP). Assume neighboring datasets differ in one individual’s entire record across all times. The hospital performs this release once per day for $k=365$ consecutive days using independent noise, so the windows are overlapping.\n\nStarting from the core definition of Differential Privacy (DP), the global sensitivity of the query, and the advanced composition theorem for DP, determine the cumulative privacy loss parameter $\\epsilon_{\\text{total}}$ after all $k$ releases under the advanced composition bound with slack parameter $\\delta' = 10^{-6}$.\n\nProvide your final numerical value for $\\epsilon_{\\text{total}}$ rounded to four significant figures. No physical units are required in your answer.", "solution": "The user requests the calculation of the cumulative privacy loss parameter, $\\epsilon_{\\text{total}}$, for a series of privatized data releases, using the advanced composition theorem for Differential Privacy (DP).\n\nFirst, I will validate the problem statement.\n\n**Step 1: Extract Givens**\n- Number of patients: $M = 1000$.\n- Patient data range: $x_{i,t} \\in [0,1]$.\n- Query function: $f_{t}(D) = \\frac{1}{w}\\sum_{s=t-w+1}^{t} \\left(\\frac{1}{M}\\sum_{i=1}^{M} x_{i,s}\\right)$.\n- Window length for the moving average: $w=30$.\n- Privatization mechanism: Laplace mechanism, $f_{t}(D) + Z_{t}$.\n- Per-release privacy parameter: $\\epsilon_{0} = 0.05$.\n- Number of consecutive daily releases (and mechanisms): $k=365$.\n- Adjacency condition: Neighboring datasets differ in one individual’s entire record across all times.\n- Slack parameter for advanced composition: $\\delta' = 10^{-6}$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is based on the established mathematical theory of Differential Privacy, utilizing standard concepts like the Laplace mechanism, global sensitivity, and the advanced composition theorem. The scenario described is a canonical application of DP in medical data analysis. The problem is scientifically sound.\n- **Well-Posed:** All parameters required for the calculation ($\\epsilon_0$, $k$, $\\delta'$, $M$, $w$) are provided and are unambiguous. The goal is to compute a single, specific value, $\\epsilon_{\\text{total}}$, based on a standard theorem. The problem is well-posed.\n- **Objective:** The problem is stated in precise, quantitative terms. It is free from subjective or ambiguous language.\n- **Other criteria:** The problem is self-contained, its constraints are consistent, the data are plausible, and it is not trivial.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will now proceed with the solution.\n\nThe solution requires three main steps:\n1.  Determine the global sensitivity of the query function $f_t$.\n2.  Confirm that each release satisfies $(\\epsilon_0, 0)$-DP.\n3.  Apply the advanced composition theorem to find the total privacy loss $\\epsilon_{\\text{total}}$ after $k$ releases.\n\n**1. Global Sensitivity of the Query**\nA randomized mechanism $\\mathcal{M}$ provides $(\\epsilon, \\delta)$-Differential Privacy if, for any two neighboring datasets $D$ and $D'$ and any set of possible outputs $S$, the following inequality holds: $\\text{Pr}(\\mathcal{M}(D) \\in S) \\le \\exp(\\epsilon) \\text{Pr}(\\mathcal{M}(D') \\in S) + \\delta$. For the Laplace mechanism, which provides $(\\epsilon, 0)$-DP, we need the $L_1$ global sensitivity of the query function, $\\Delta_1 f$. It is defined as the maximum possible change in the query's output when moving between any two neighboring datasets:\n$$\n\\Delta_1 f = \\max_{D, D'} |f(D) - f(D')|\n$$\nIn this problem, the query is $f_{t}(D) = \\frac{1}{wM}\\sum_{s=t-w+1}^{t} \\sum_{i=1}^{M} x_{i,s}$. Neighboring datasets $D$ and $D'$ differ in the entire record of a single patient, say patient $j$. This means $x_{i,s}$ in dataset $D$ is identical to $x'_{i,s}$ in dataset $D'$ for all $i \\ne j$ and all $s$. The difference in the query output is:\n$$\n|f_t(D) - f_t(D')| = \\left| \\frac{1}{wM}\\sum_{s=t-w+1}^{t} \\sum_{i=1}^{M} x_{i,s} - \\frac{1}{wM}\\sum_{s=t-w+1}^{t} \\sum_{i=1}^{M} x'_{i,s} \\right|\n$$\nDue to the adjacency definition, this simplifies to:\n$$\n|f_t(D) - f_t(D')| = \\left| \\frac{1}{wM}\\sum_{s=t-w+1}^{t} (x_{j,s} - x'_{j,s}) \\right|\n$$\nUsing the triangle inequality:\n$$\n|f_t(D) - f_t(D')| \\le \\frac{1}{wM}\\sum_{s=t-w+1}^{t} |x_{j,s} - x'_{j,s}|\n$$\nThe patient data are normalized such that $x_{i,s}, x'_{i,s} \\in [0,1]$. Therefore, the maximum possible value for $|x_{j,s} - x'_{j,s}|$ is $|1 - 0| = 1$. To maximize the total difference, we assume this maximum change occurs for all $s$ within the window of size $w$. The global sensitivity $\\Delta_1 f_t$ is therefore:\n$$\n\\Delta_1 f_t = \\max_{D, D'} |f_t(D) - f_t(D')| = \\frac{1}{wM}\\sum_{s=t-w+1}^{t} (1) = \\frac{1}{wM} \\cdot w = \\frac{1}{M}\n$$\nGiven $M=1000$, the global sensitivity for each daily query is:\n$$\n\\Delta_1 f_t = \\frac{1}{1000}\n$$\n\n**2. Per-Release Privacy Guarantee**\nThe hospital uses the Laplace mechanism, which adds noise $Z_t \\sim \\text{Lap}(b)$ to the query result $f_t(D)$. To satisfy $\\epsilon_0$-DP (i.e., $(\\epsilon_0, 0)$-DP), the scale parameter $b$ of the Laplace distribution must be set to $b = \\Delta_1 f_t / \\epsilon_0$. For each release, this is:\n$$\nb = \\frac{1/M}{\\epsilon_0} = \\frac{1/1000}{0.05} = \\frac{0.001}{0.05} = \\frac{1}{50} = 0.02\n$$\nThe problem states that each release is designed to achieve $\\epsilon_0 = 0.05$ privacy, which implies that each of the $k=365$ mechanisms is $(\\epsilon_0, 0)$-DP with $\\epsilon_0 = 0.05$.\n\n**3. Advanced Composition**\nWe are composing $k=365$ mechanisms, each satisfying $(\\epsilon_0, 0)$-DP, where $\\epsilon_0 = 0.05$. The advanced composition theorem provides a tighter bound on the cumulative privacy loss than simple linear composition. It states that for any $\\delta' > 0$, the composition of $k$ independent $(\\epsilon_0, 0)$-DP mechanisms is $(\\epsilon_{\\text{total}}, \\delta')$-DP, where $\\epsilon_{\\text{total}}$ is given by:\n$$\n\\epsilon_{\\text{total}} = \\sqrt{2k \\ln(1/\\delta')} \\epsilon_0 + k \\epsilon_0 (\\exp(\\epsilon_0) - 1)\n$$\nWe are given the following parameters:\n- $k = 365$\n- $\\epsilon_0 = 0.05$\n- $\\delta' = 10^{-6}$\n\nSubstituting these values into the formula:\n$$\n\\epsilon_{\\text{total}} = \\sqrt{2(365) \\ln(1/10^{-6})} (0.05) + (365)(0.05) (\\exp(0.05) - 1)\n$$\nFirst, calculate the arguments of the main terms:\n$$\n\\ln(1/10^{-6}) = \\ln(10^6) = 6 \\ln(10) \\approx 6 \\times 2.302585 = 13.81551\n$$\nNow, we can compute the two parts of the expression for $\\epsilon_{\\text{total}}$.\nThe first term is:\n$$\n\\sqrt{2 \\times 365 \\times 13.81551} \\times 0.05 = \\sqrt{10085.3223} \\times 0.05 \\approx 100.4257 \\times 0.05 \\approx 5.021285\n$$\nThe second term is:\n$$\n(365 \\times 0.05) (\\exp(0.05) - 1) = 18.25 \\times (1.051271 - 1) = 18.25 \\times 0.051271 \\approx 0.935606\n$$\nAdding the two terms gives the total privacy loss:\n$$\n\\epsilon_{\\text{total}} \\approx 5.021285 + 0.935606 = 5.956891\n$$\nThe problem asks for the result to be rounded to four significant figures.\n$$\n\\epsilon_{\\text{total}} \\approx 5.957\n$$\nThus, after $365$ daily releases, the cumulative privacy guarantee is $(5.957, 10^{-6})$-DP. The value of the cumulative privacy loss parameter is $\\epsilon_{\\text{total}} \\approx 5.957$.", "answer": "$$\\boxed{5.957}$$", "id": "4556441"}]}