{"hands_on_practices": [{"introduction": "This exercise grounds our analysis in the fundamental relationship between a tumor's biological properties and the sequencing data it produces. By deriving and applying the formula for expected Variant Allele Fraction ($VAF$), you will gain a quantitative understanding of how tumor purity, copy number alterations, and mutation multiplicity jointly influence the signal we observe in bulk sequencing data. This skill is the cornerstone of interpreting somatic variant calls. [@problem_id:4608601]", "problem": "A bulk whole-genome sequencing sample consists of a mixture of tumor and normal cells. Let $p$ denote the tumor cell fraction (tumor purity), $c_{t}$ the total copy number at a locus in tumor cells, and $c_{n}$ the total copy number at the locus in normal cells. Consider a clonal somatic mutation that is present in all tumor cells and is heterozygous within tumor cells, meaning it occupies exactly $m=1$ mutated copy among the $c_{t}$ copies in each tumor cell, and is absent from normal cells. Assume random sampling of DNA molecules, no allelic bias, and that read sampling is proportional to allele copy counts. By the definition of Variant Allele Fraction (VAF), the expected VAF equals the fraction of mutated allele copies among the total allele copies present in the bulk sample.\n\nUsing only these definitions and assumptions, first derive the expected VAF, denoted $v_{\\mathrm{exp}}$, for general $p$, $c_{t}$, $c_{n}$, and $m$. Then, for $p=0.6$, $c_{t}=3$, $c_{n}=2$, and $m=1$, compute the numerical value of $v_{\\mathrm{exp}}$. A sequencing experiment reports a measured VAF $v=0.22$ at this locus. To quantitatively assess consistency of the measurement with the model, compute the absolute deviation $r=|v-v_{\\mathrm{exp}}|$. Express $r$ as a decimal and round your final answer to four significant figures. No units are required.", "solution": "The problem statement has been validated and is scientifically grounded, well-posed, and objective. All necessary information is provided, and the assumptions are standard in the field of cancer genomics. We may proceed with the solution.\n\nThe problem asks for three quantities: first, a general formula for the expected Variant Allele Fraction ($v_{\\mathrm{exp}}$); second, its numerical value for a specific case; and third, the absolute deviation ($r$) between this expected value and a given measured value.\n\nFirst, we derive the general formula for $v_{\\mathrm{exp}}$. The expected VAF is defined as the fraction of mutated allele copies among the total number of allele copies in the bulk sample. The sample is a mixture of tumor cells (fraction $p$) and normal cells (fraction $1-p$).\n\nLet's account for the total number of mutated copies.\n- In tumor cells, the number of mutated copies at the locus is given as $m$. The contribution of tumor cells to the total pool of mutated alleles is proportional to the tumor purity $p$ and the number of mutated copies per tumor cell $m$. Thus, the contribution is proportional to $p \\cdot m$.\n- In normal cells, the somatic mutation is absent, so the number of mutated copies is $0$. The contribution of normal cells to the pool of mutated alleles is proportional to $(1-p) \\cdot 0 = 0$.\nThe total number of mutated copies in the bulk sample is therefore proportional to $p \\cdot m$.\n\nNext, let's account for the total number of allele copies (both mutated and wild-type) at the locus.\n- In tumor cells, the total copy number at the locus is $c_t$. The contribution of tumor cells to the total pool of alleles is proportional to $p \\cdot c_t$.\n- In normal cells, the total copy number at the locus is $c_n$. The contribution of normal cells to the total pool of alleles is proportional to $(1-p) \\cdot c_n$.\nThe total number of allele copies in the bulk sample is therefore proportional to the sum of these contributions: $p \\cdot c_t + (1-p) \\cdot c_n$.\n\nThe expected VAF, $v_{\\mathrm{exp}}$, is the ratio of the total number of mutated copies to the total number of all copies.\n$$v_{\\mathrm{exp}} = \\frac{p \\cdot m}{p \\cdot c_t + (1-p) \\cdot c_n}$$\n\nSecond, we compute the numerical value of $v_{\\mathrm{exp}}$ using the provided parameters: tumor purity $p=0.6$, tumor cell copy number $c_t=3$, normal cell copy number $c_n=2$, and mutated allele count in tumor cells $m=1$.\nSubstituting these values into the derived formula:\n$$v_{\\mathrm{exp}} = \\frac{(0.6) \\cdot 1}{(0.6) \\cdot 3 + (1-0.6) \\cdot 2}$$\n$$v_{\\mathrm{exp}} = \\frac{0.6}{1.8 + (0.4) \\cdot 2}$$\n$$v_{\\mathrm{exp}} = \\frac{0.6}{1.8 + 0.8}$$\n$$v_{\\mathrm{exp}} = \\frac{0.6}{2.6}$$\nThis fraction simplifies to:\n$$v_{\\mathrm{exp}} = \\frac{6}{26} = \\frac{3}{13}$$\n\nThird, we compute the absolute deviation $r = |v - v_{\\mathrm{exp}}|$, where $v$ is the measured VAF, given as $v=0.22$.\n$$r = \\left|0.22 - \\frac{3}{13}\\right|$$\nTo perform the subtraction, we can express both terms as fractions or decimals. Let's convert $0.22$ to a fraction: $0.22 = \\frac{22}{100} = \\frac{11}{50}$.\n$$r = \\left|\\frac{11}{50} - \\frac{3}{13}\\right|$$\n$$r = \\left|\\frac{11 \\cdot 13 - 3 \\cdot 50}{50 \\cdot 13}\\right|$$\n$$r = \\left|\\frac{143 - 150}{650}\\right|$$\n$$r = \\left|\\frac{-7}{650}\\right|$$\n$$r = \\frac{7}{650}$$\nTo provide the answer as a decimal rounded to four significant figures, we compute the value of the fraction:\n$$r = \\frac{7}{650} \\approx 0.01076923...$$\nThe first significant figure is $1$. The first four significant figures are $1$, $0$, $7$, and $6$. The fifth significant figure is $9$, which is greater than or equal to $5$, so we round up the fourth significant figure.\n$$r \\approx 0.01077$$\nThis is the final numerical answer for the absolute deviation.", "answer": "$$\n\\boxed{0.01077}\n$$", "id": "4608601"}, {"introduction": "Moving from theory to a realistic clinical scenario, this practice tackles the critical challenge of distinguishing a true tumor-derived somatic mutation from Clonal Hematopoiesis of Indeterminate Potential (CHIP). You will construct a log-likelihood ratio test, a powerful statistical tool, to compare these competing hypotheses based on $VAF$s from matched tumor and normal samples. This exercise demonstrates how quantitative modeling allows us to resolve ambiguous variant origins, which has direct implications for diagnosis and treatment. [@problem_id:4608598]", "problem": "A genomic locus in the Janus Kinase 2 (JAK2) gene is sequenced by targeted high-throughput sequencing in matched tumor and normal samples from a patient with a myeloproliferative neoplasm. The goal is to decide whether the observed single-nucleotide variant is Clonal Hematopoiesis of Indeterminate Potential (CHIP) originating from the hematopoietic compartment, or tumor-derived from the cancer cells. Use the following fundamental bases:\n\n- The Variant Allele Fraction (VAF) in a bulk sample is defined by the mixture of cell populations contributing DNA, weighted by their fractions and copy number states, and the number of mutated copies per cell.\n- Sequencing reads at a locus can be modeled as independent Bernoulli trials with success probability equal to the true VAF for the sample, leading to a binomial sampling model for the number of alternate (mutant) reads given total reads.\n- In the tumor sample, the fraction of cancer cells is the tumor purity $p$, and the remaining fraction $1 - p$ is normal cells. The total copy number at the locus in cancer cells is $c_{t}$, and in normal cells is $c_{n} = 2$.\n- Under the tumor-derived hypothesis, the variant is absent from normal cells except for sequencing error at rate $\\epsilon$, and is present in cancer cells on $m$ mutated copies per cancer cell.\n- Under the CHIP hypothesis, the variant is present in a fraction of normal hematopoietic cells; the effective normal-sample VAF measured at the locus is used to represent the CHIP clone’s contribution in normal DNA.\n\nFrom these bases, derive a decision rule by constructing the log-likelihood ratio that compares the joint binomial likelihood of observing the alternate read counts in tumor and normal under the tumor-derived hypothesis versus the CHIP hypothesis. Then evaluate the decision rule numerically for the following data and parameters:\n\n- Tumor total reads $N_{t} = 800$ and tumor alternate reads $A_{t} = 240$.\n- Normal total reads $N_{n} = 1000$ and normal alternate reads $A_{n} = 45$.\n- Tumor purity $p = 0.7$.\n- Tumor total copy number at the locus $c_{t} = 3$.\n- Mutated-copy multiplicity in cancer cells under the tumor-derived hypothesis $m = 1$.\n- Normal copy number $c_{n} = 2$.\n- Sequencing error rate $\\epsilon = 1 \\times 10^{-3}$.\n\nAssume a clonal tumor-derived variant under the tumor-derived hypothesis and use the empirically observed normal-sample VAF $v_{n} = A_{n}/N_{n}$ to parameterize the CHIP hypothesis. Round your final numerical answer for the log-likelihood ratio to four significant figures. Express the final result as a single real number with no units.", "solution": "The task is to derive a decision rule based on the log-likelihood ratio (LLR) to distinguish between a tumor-derived somatic variant and Clonal Hematopoiesis of Indeterminate Potential (CHIP). After deriving the rule, we must evaluate it numerically using the provided data.\n\nFirst, we formalize the statistical model. The number of alternate (mutant) reads, $A$, given a total number of sequencing reads, $N$, at a specific locus is modeled as a random variable following a binomial distribution. The probability of success for each read (i.e., the probability of observing a mutant allele) is the true Variant Allele Fraction (VAF) at that locus, which we denote as $v$.\nThe probability mass function for observing $A$ alternate reads out of $N$ total reads is given by:\n$$ P(A | N, v) = \\binom{N}{A} v^{A} (1-v)^{N-A} $$\nWe have two independent samples: a tumor sample (t) and a normal sample (n). The observed data are the read counts $(A_t, N_t)$ and $(A_n, N_n)$. The joint likelihood of the data, given the VAFs in the tumor ($v_t$) and normal ($v_n$) samples, is the product of the individual likelihoods:\n$$ L(A_t, A_n | N_t, N_n, v_t, v_n) = P(A_t | N_t, v_t) \\times P(A_n | N_n, v_n) $$\n\nNext, we define the theoretical VAFs under each of the two competing hypotheses, $H_{\\text{tumor}}$ (tumor-derived variant) and $H_{\\text{CHIP}}$ (CHIP-derived variant). The VAF in a bulk sample is the ratio of the total number of mutant alleles to the total number of alleles at the locus, contributed by all cell populations.\n\n**Hypothesis 1: Tumor-derived variant ($H_{\\text{tumor}}$)**\nUnder this hypothesis, the mutation is present only in cancer cells.\nThe tumor sample is a mixture of cancer cells (fraction $p$) and normal cells (fraction $1-p$). The total copy number is $c_t$ in cancer cells and $c_n$ in normal cells. The mutation is present on $m$ copies in each cancer cell. Normal cells do not carry the mutation.\nThe expected VAF in the tumor sample, $v_{t, \\text{tumor}}$, is the ratio of mutant alleles from cancer cells to the total alleles from both cancer and normal cells:\n$$ v_{t, \\text{tumor}} = \\frac{p \\cdot m}{p \\cdot c_t + (1-p) \\cdot c_n} $$\nIn the normal sample, the variant is absent. Any observed alternate reads are assumed to be due to sequencing error, which occurs at a rate of $\\epsilon$. Thus, the expected VAF in the normal sample is:\n$$ v_{n, \\text{tumor}} = \\epsilon $$\n\n**Hypothesis 2: CHIP variant ($H_{\\text{CHIP}}$)**\nUnder this hypothesis, the mutation originates from the hematopoietic (normal) compartment and is absent in the tumor cells. The VAF of this clonal population within the normal hematopoietic cells is denoted as $v_{\\text{CHIP}}$. The problem specifies to use the empirically observed VAF from the normal sample to estimate this parameter.\n$$ v_{\\text{CHIP}} = \\frac{A_n}{N_n} $$\nThe expected VAF in the normal sample, $v_{n, \\text{CHIP}}$, is therefore set to this empirically observed value:\n$$ v_{n, \\text{CHIP}} = \\frac{A_n}{N_n} $$\nIn the tumor sample, the mutation is only present in the admixed normal cells (fraction $1-p$). The VAF of the mutation within this normal cell population is $v_{\\text{CHIP}}$. The total number of alleles from the normal cell fraction is proportional to $(1-p) \\cdot c_n$, and the number of mutant alleles is proportional to $(1-p) \\cdot c_n \\cdot v_{\\text{CHIP}}$. The total number of alleles in the mixed tumor sample is proportional to $p \\cdot c_t + (1-p) \\cdot c_n$. Therefore, the expected VAF in the tumor sample is:\n$$ v_{t, \\text{CHIP}} = \\frac{(1-p) \\cdot c_n \\cdot v_{\\text{CHIP}}}{p \\cdot c_t + (1-p) \\cdot c_n} $$\n\n**Log-Likelihood Ratio (LLR) Decision Rule**\nThe decision rule is based on the LLR, which compares the likelihood of the observed data under $H_{\\text{tumor}}$ versus $H_{\\text{CHIP}}$.\n$$ \\text{LLR} = \\ln\\left(\\frac{L(\\text{data} | H_{\\text{tumor}})}{L(\\text{data} | H_{\\text{CHIP}})}\\right) = \\ln(L(\\text{data} | H_{\\text{tumor}})) - \\ln(L(\\text{data} | H_{\\text{CHIP}})) $$\nThe log-likelihood for a given hypothesis $H$ is:\n$$ \\ln(L(H)) = \\ln\\binom{N_t}{A_t} + A_t \\ln(v_t) + (N_t-A_t)\\ln(1-v_t) + \\ln\\binom{N_n}{A_n} + A_n \\ln(v_n) + (N_n-A_n)\\ln(1-v_n) $$\nWhen computing the LLR, the binomial coefficient terms $\\ln\\binom{N_t}{A_t}$ and $\\ln\\binom{N_n}{A_n}$ are identical for both hypotheses and cancel out. The LLR simplifies to:\n$$ \\text{LLR} = \\left[ A_t \\ln(v_{t, \\text{tumor}}) + (N_t - A_t) \\ln(1 - v_{t, \\text{tumor}}) \\right] - \\left[ A_t \\ln(v_{t, \\text{CHIP}}) + (N_t - A_t) \\ln(1 - v_{t, \\text{CHIP}}) \\right] \\\\ + \\left[ A_n \\ln(v_{n, \\text{tumor}}) + (N_n - A_n) \\ln(1 - v_{n, \\text{tumor}}) \\right] - \\left[ A_n \\ln(v_{n, \\text{CHIP}}) + (N_n - A_n) \\ln(1 - v_{n, \\text{CHIP}}) \\right] $$\nThis can be grouped by sample:\n$$ \\text{LLR} = \\left[ A_t \\ln\\left(\\frac{v_{t, \\text{tumor}}}{v_{t, \\text{CHIP}}}\\right) + (N_t - A_t) \\ln\\left(\\frac{1 - v_{t, \\text{tumor}}}{1 - v_{t, \\text{CHIP}}}\\right) \\right] + \\left[ A_n \\ln\\left(\\frac{v_{n, \\text{tumor}}}{v_{n, \\text{CHIP}}}\\right) + (N_n - A_n) \\ln\\left(\\frac{1 - v_{n, \\text{tumor}}}{1 - v_{n, \\text{CHIP}}}\\right) \\right] $$\n\n**Numerical Evaluation**\nWe are given the following data:\n- Tumor reads: $N_t = 800$, $A_t = 240$.\n- Normal reads: $N_n = 1000$, $A_n = 45$.\n- Tumor purity: $p = 0.7$.\n- Tumor copy number: $c_t = 3$.\n- Cancer cell mutation multiplicity: $m = 1$.\n- Normal cell copy number: $c_n = 2$.\n- Sequencing error rate: $\\epsilon = 1 \\times 10^{-3} = 0.001$.\n\nFirst, we calculate the denominator for VAFs in the tumor sample:\n$$ p \\cdot c_t + (1-p) \\cdot c_n = (0.7)(3) + (1-0.7)(2) = 2.1 + (0.3)(2) = 2.1 + 0.6 = 2.7 $$\n\nNow, we calculate the VAFs for each hypothesis:\nUnder $H_{\\text{tumor}}$:\n$$ v_{t, \\text{tumor}} = \\frac{0.7 \\times 1}{2.7} = \\frac{0.7}{2.7} = \\frac{7}{27} $$\n$$ v_{n, \\text{tumor}} = 0.001 $$\n\nUnder $H_{\\text{CHIP}}$:\nFirst, calculate $v_{\\text{CHIP}}$:\n$$ v_{\\text{CHIP}} = \\frac{A_n}{N_n} = \\frac{45}{1000} = 0.045 $$\nThen, calculate the expected VAFs for the CHIP hypothesis:\n$$ v_{n, \\text{CHIP}} = 0.045 $$\n$$ v_{t, \\text{CHIP}} = \\frac{(1-0.7) \\cdot 2 \\cdot 0.045}{2.7} = \\frac{0.3 \\cdot 2 \\cdot 0.045}{2.7} = \\frac{0.6 \\cdot 0.045}{2.7} = \\frac{0.027}{2.7} = 0.01 $$\n\nWe can now substitute these values into the LLR formula.\nThe LLR is the sum of the LLR from the tumor sample ($LLR_t$) and the normal sample ($LLR_n$).\n\nFor the tumor sample ($A_t=240, N_t-A_t=560$):\n$$ LLR_t = 240 \\ln\\left(\\frac{7/27}{0.01}\\right) + 560 \\ln\\left(\\frac{1 - 7/27}{1 - 0.01}\\right) = 240 \\ln\\left(\\frac{700}{27}\\right) + 560 \\ln\\left(\\frac{20/27}{0.99}\\right) = 240 \\ln\\left(\\frac{700}{27}\\right) + 560 \\ln\\left(\\frac{2000}{2673}\\right) $$\n$$ LLR_t \\approx 240 \\times (3.255243) + 560 \\times (-0.290054) \\approx 781.258 - 162.430 = 618.828 $$\n\nFor the normal sample ($A_n=45, N_n-A_n=955$):\n$$ LLR_n = 45 \\ln\\left(\\frac{0.001}{0.045}\\right) + 955 \\ln\\left(\\frac{1-0.001}{1-0.045}\\right) = 45 \\ln\\left(\\frac{1}{45}\\right) + 955 \\ln\\left(\\frac{0.999}{0.955}\\right) $$\n$$ LLR_n \\approx 45 \\times (-3.806662) + 955 \\times (0.045045) \\approx -171.300 + 43.018 = -128.282 $$\n\nThe total LLR is the sum of these two components:\n$$ \\text{LLR} = LLR_t + LLR_n \\approx 618.828 - 128.282 = 490.546 $$\n\nA positive LLR indicates that the data are more likely under the tumor-derived hypothesis ($H_{\\text{tumor}}$) than the CHIP hypothesis ($H_{\\text{CHIP}}$). The large positive value provides strong evidence in favor of the variant being tumor-derived.\n\nRounding the final numerical answer to four significant figures gives $490.5$.", "answer": "$$\\boxed{490.5}$$", "id": "4608598"}, {"introduction": "Real-world cancer genomic analyses involve testing thousands or millions of potential variant sites, creating a massive multiple hypothesis testing problem. This exercise introduces the Benjamini–Hochberg procedure to control the False Discovery Rate ($FDR$), ensuring the statistical robustness of your variant call set. By implementing this procedure and applying practical quality filters, you will learn the essential final steps in generating a high-confidence list of somatic variants from raw statistical output. [@problem_id:4608579]", "problem": "You are analyzing somatic variant hypotheses in tumor-normal sequencing, where each hypothesis test yields a $p$-value reflecting evidence against the null hypothesis of no somatic signal. Multiple testing must be controlled by the False Discovery Rate (FDR), using the Benjamini–Hochberg (BH) procedure at target level $q=0.1$ expressed as a decimal. In addition to statistical significance, you will interpret the resulting call set by applying practical filters on read support and allelic signal: a variant is called if and only if it is BH-significant and meets a minimum tumor read depth and a minimum Variant Allele Fraction (VAF). The BH method should be derived from the fundamental definitions of hypothesis testing and FDR control, not by invoking any shortcut formulas without justification.\n\nFundamental base for derivation:\n- Under the null hypothesis, the $p$-value for a valid test is stochastically at least uniform on $[0,1]$, and for continuous tests is uniform on $[0,1]$.\n- The False Discovery Rate (FDR) is the expected proportion of false positives among all rejected hypotheses.\n- The Benjamini–Hochberg (BH) step-up procedure controls FDR under independence or positive dependence by ordering $p$-values and selecting a data-dependent cutoff.\n\nTasks:\n1. Given arrays of $p$-values $\\{p_i\\}_{i=1}^n$ for $n$ hypotheses (variants), compute BH-adjusted $p$-values that represent, for each hypothesis $i$, the smallest FDR level at which hypothesis $i$ would be rejected by BH.\n2. Determine BH significance for each hypothesis at $q=0.1$ as a boolean decision.\n3. Interpret the resulting call set for each test case by marking a variant as “called” if its BH significance decision is true and it meets both filters: tumor read depth $d_i \\ge d_{\\min}$ and variant allele fraction $f_i \\ge f_{\\min}$, with $d_{\\min}=30$ and $f_{\\min}=0.05$ (decimal).\n\nAngle units are not applicable, and no physical units are required. Percent quantities such as the FDR target must always be expressed in decimal form.\n\nTest suite:\nUse the following test cases, each specified by three lists: $p$-values, tumor read depths, and variant allele fractions (VAF). The minimum depth $d_{\\min}=30$ and minimum VAF $f_{\\min}=0.05$ apply to all cases, and the BH target is $q=0.1$.\n\n- Case A (general case, unsorted with varied magnitudes): $p = [0.0008, 0.012, 0.075, 0.2, 0.0001, 0.5]$, $d = [120, 80, 45, 35, 200, 40]$, $f = [0.12, 0.08, 0.04, 0.06, 0.2, 0.03]$.\n- Case B (boundary conditions with $p=0$ and $p=1$ present): $p = [0.0, 1.0, 0.1, 0.05]$, $d = [500, 60, 10, 120]$, $f = [0.9, 0.01, 0.06, 0.07]$.\n- Case C (ties among small $p$-values and mixed filter outcomes): $p = [0.01, 0.01, 0.01, 0.5, 0.2]$, $d = [100, 29, 35, 50, 80]$, $f = [0.04, 0.07, 0.08, 0.05, 0.12]$.\n- Case D (all large $p$-values, expected no discoveries): $p = [0.6, 0.7, 0.8, 0.9, 1.0]$, $d = [60, 70, 80, 90, 100]$, $f = [0.2, 0.1, 0.05, 0.04, 0.03]$.\n- Case E (single hypothesis, edge case $n=1$): $p = [0.11]$, $d = [100]$, $f = [0.2]$.\n\nRequired final output format:\nYour program should produce a single line of output containing the results of all test cases as a comma-separated list enclosed in square brackets. Each test case’s result must itself be a list of three lists: the BH-adjusted $p$-values (floats), the BH significance decisions (booleans), and the final calls (booleans). Thus the overall output must be a single compact list of length $5$, where element $i$ is of the form $[\\text{padj}_i,\\text{sign}_i,\\text{call}_i]$ with no spaces in the printed representation. For example, the structure is $[[\\ldots],[\\ldots],[\\ldots],[\\ldots],[\\ldots]]$ with commas separating elements and brackets enclosing lists, and booleans printed as $\\text{True}$ or $\\text{False}$.", "solution": "We begin from the core properties of hypothesis tests and the definition of False Discovery Rate (FDR). For a valid hypothesis test of a null hypothesis, the $p$-value, denoted $p_i$, satisfies that under the null it is stochastically at least uniform on $[0,1]$, and when the test is continuous, exactly uniform on $[0,1]$. The False Discovery Rate (FDR) is defined as the expected proportion of false rejections among all rejections, a quantity that controls the rate of Type I errors when many hypotheses are tested simultaneously.\n\nThe Benjamini–Hochberg (BH) procedure, which is a step-up method, controls the FDR at target level $q$ under independence or certain forms of positive dependence. Its construction is grounded in ordering the evidence against the null and comparing it to rank-dependent thresholds. Specifically, let there be $n$ hypotheses with $p$-values $\\{p_i\\}_{i=1}^n$. Define the order statistics of the $p$-values by sorting them increasingly: $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(n)}$, with corresponding indices $\\{i_{(1)}, i_{(2)}, \\ldots, i_{(n)}\\}$ mapping ranks back to original hypotheses.\n\nThe BH step-up decision rule selects the largest rank $k^\\star$ such that\n$$\np_{(k^\\star)} \\le \\frac{k^\\star}{n} q,\n$$\nand rejects all hypotheses with ranks $1 \\le k \\le k^\\star$. This rule arises by comparing each ordered $p$-value to a linear, nondecreasing sequence of thresholds $\\frac{k}{n}q$, ensuring that if the $k^\\star$-th ordered $p$ meets the threshold, then all preceding (smaller) $p$-values also meet their respective thresholds.\n\nTo obtain BH-adjusted $p$-values, one asks for each hypothesis $i$ the smallest FDR level at which it would be rejected by the BH step-up rule. For the hypothesis at ordered position $k$, this quantity is given by the smallest $q$ satisfying $p_{(k)} \\le \\frac{k}{n} q$, or equivalently $q \\ge \\frac{n}{k} p_{(k)}$. However, because the BH rejection decision depends on the largest $k$ for which the inequality is satisfied and because increasing $q$ must not decrease the set of rejections, the adjusted values must be monotone nonincreasing in rank when mapped back to the ordered list. This monotonicity is enforced by taking a cumulative minimum from the tail of the sequence $\\left\\{ \\frac{n}{k} p_{(k)} \\right\\}_{k=1}^n$:\n$$\n\\tilde{p}_{(k)} = \\min_{j \\ge k} \\left( \\frac{n}{j} p_{(j)} \\right),\n$$\nand then bounding by $1$ so that adjusted values remain in $[0,1]$:\n$$\n\\text{padj}_{(k)} = \\min\\left( 1, \\tilde{p}_{(k)} \\right).\n$$\nFinally, one returns these adjusted values to the original hypothesis order using the inverse permutation of the sorting step. The BH significance decision at target $q$ for hypothesis $i$ is then computed by comparing its adjusted value to $q$:\n$$\n\\text{significant}_i = \\left( \\text{padj}_i \\le q \\right).\n$$\n\nWith the statistical decisions in hand, interpretation of the somatic variant call set is obtained by further imposing practical filters. Define $d_i$ as the tumor read depth for variant $i$ and $f_i$ as the Variant Allele Fraction (VAF), the fraction of reads supporting the variant allele among all tumor reads at that locus. Set thresholds $d_{\\min} = 30$ and $f_{\\min} = 0.05$ (expressed as decimals). A variant is “called” if and only if it is BH-significant and meets both filters:\n$$\n\\text{called}_i = \\left( \\text{padj}_i \\le q \\right) \\land \\left( d_i \\ge d_{\\min} \\right) \\land \\left( f_i \\ge f_{\\min} \\right).\n$$\n\nAlgorithmic design:\n1. For each test case, take the list of $p$-values and compute their sorted order indices. Extract the sorted $p$-values $p_{(k)}$ and compute the sequence $s_k = \\frac{n}{k} p_{(k)}$ for $k=1,\\ldots,n$.\n2. Compute the reverse cumulative minimum of $s_k$, that is $\\tilde{s}_k = \\min_{j \\ge k} s_j$, to enforce monotonicity across ranks. Bound $\\tilde{s}_k$ by $1$ to obtain $\\text{padj}_{(k)}$, and then map these adjusted values back to the original hypothesis order via the inverse permutation.\n3. Determine BH significance by checking whether $\\text{padj}_i \\le q$ for each hypothesis $i$.\n4. Apply the filters using $d_{\\min}=30$ and $f_{\\min}=0.05$ to obtain the final call decisions: $\\text{called}_i = \\left( \\text{padj}_i \\le q \\right) \\land \\left( d_i \\ge 30 \\right) \\land \\left( f_i \\ge 0.05 \\right)$.\n5. Produce the final output as a single line containing a list of five elements, one per test case, where each element is a list of three lists: the BH-adjusted $p$-values (floats), the BH significance decisions (booleans), and the final calls (booleans). The printed representation must have no spaces, with brackets and commas delimiting the lists, and booleans printed as True or False.\n\nThis design directly implements the BH procedure derived from the foundational definitions and yields a rigorous, interpretable call set under FDR control for somatic variant hypotheses.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef bh_adjust(pvals):\n    \"\"\"\n    Compute Benjamini-Hochberg adjusted p-values.\n    Steps:\n    - Sort p-values ascending.\n    - Compute s_k = (n / k) * p_(k).\n    - Compute reverse cumulative minima to enforce monotonicity.\n    - Clip to 1.0 and map back to original order.\n    \"\"\"\n    pvals = np.asarray(pvals, dtype=float)\n    n = pvals.size\n    if n == 0:\n        return []\n    order = np.argsort(pvals)\n    ranked = pvals[order]\n    ranks = np.arange(1, n + 1, dtype=float)\n    s = (n / ranks) * ranked\n    # Reverse cumulative minimum\n    rev_cummin = np.minimum.accumulate(s[::-1])[::-1]\n    padj_sorted = np.minimum(rev_cummin, 1.0)\n    # Map back to original order\n    padj = np.empty_like(pvals)\n    padj[order] = padj_sorted\n    return padj.tolist()\n\ndef to_compact_str(obj):\n    \"\"\"\n    Serialize Python lists and primitives to a compact string with no spaces.\n    Booleans are printed as 'True' or 'False'. Floats/ints use repr().\n    \"\"\"\n    if isinstance(obj, list):\n        return \"[\" + \",\".join(to_compact_str(x) for x in obj) + \"]\"\n    elif isinstance(obj, bool):\n        return \"True\" if obj else \"False\"\n    elif isinstance(obj, (int, float, np.floating, np.integer)):\n        return repr(float(obj)) if isinstance(obj, (float, np.floating)) else repr(int(obj))\n    else:\n        # Fallback for other types\n        return repr(obj)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (p_values, depths, vafs)\n    test_cases = [\n        ([0.0008, 0.012, 0.075, 0.2, 0.0001, 0.5],\n         [120, 80, 45, 35, 200, 40],\n         [0.12, 0.08, 0.04, 0.06, 0.2, 0.03]),\n        ([0.0, 1.0, 0.1, 0.05],\n         [500, 60, 10, 120],\n         [0.9, 0.01, 0.06, 0.07]),\n        ([0.01, 0.01, 0.01, 0.5, 0.2],\n         [100, 29, 35, 50, 80],\n         [0.04, 0.07, 0.08, 0.05, 0.12]),\n        ([0.6, 0.7, 0.8, 0.9, 1.0],\n         [60, 70, 80, 90, 100],\n         [0.2, 0.1, 0.05, 0.04, 0.03]),\n        ([0.11],\n         [100],\n         [0.2]),\n    ]\n\n    # Parameters\n    q = 0.1  # FDR target level as decimal\n    d_min = 30\n    f_min = 0.05\n\n    results = []\n    for pvals, depths, vafs in test_cases:\n        padj = bh_adjust(pvals)\n        # Significance decisions\n        signif = [pv = q for pv in padj]\n        # Final calls: BH significant AND pass depth and VAF filters\n        calls = [(signif[i] and (depths[i] = d_min) and (vafs[i] = f_min)) for i in range(len(pvals))]\n        results.append([padj, signif, calls])\n\n    # Final print statement in the exact required format (compact, no spaces).\n    print(to_compact_str(results))\n\nsolve()\n```", "id": "4608579"}]}