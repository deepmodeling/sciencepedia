{"hands_on_practices": [{"introduction": "To truly master fine-mapping, we must first understand the data it relies on. This practice guides you through building a complete simulation pipeline, starting from fundamental haplotype data and culminating in the generation of Genome-Wide Association Study (GWAS) summary statistics ($z$-scores) and a Linkage Disequilibrium (LD) matrix. By implementing this process, you will gain a concrete understanding of the additive genetic model, heritability, and the precise definitions of the data inputs essential for any fine-mapping analysis [@problem_id:4564276].", "problem": "Design and implement a complete simulation pipeline for fine-mapping of causal Single Nucleotide Polymorphisms (SNPs) using haplotype data in the context of Genome-Wide Association Study (GWAS)-style summary statistics. Start from first principles of the additive linear genetic model and validated definitions used in statistical genetics, and derive every computation step required to simulate phenotypes, produce per-SNP marginal association statistics, and compute the Linkage Disequilibrium (LD) correlation matrix.\n\nUse the following fundamental bases and core definitions:\n- The additive linear genetic model states that the phenotype vector $y \\in \\mathbb{R}^n$ for $n$ individuals can be written as $y = X \\beta + \\varepsilon$, where $X \\in \\mathbb{R}^{n \\times p}$ is the standardized genotype matrix with $p$ SNPs, $\\beta \\in \\mathbb{R}^p$ is the vector of SNP effect sizes, and $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_\\varepsilon^2 I_n)$ is the noise vector with variance $\\sigma_\\varepsilon^2$.\n- The LD correlation matrix is defined as $R = \\frac{1}{n} X^\\top X$ when the columns of $X$ are standardized to have mean $0$ and variance $1$ (using the population variance definition with denominator $n$).\n- Given standardized $X$ and standardized $y$ (mean $0$ and variance $1$ using denominator $n$), define the vector of per-SNP summary statistics $z \\in \\mathbb{R}^p$ by $z = \\frac{1}{\\sqrt{n}} X^\\top y$.\n- Narrow-sense heritability $h^2$ is defined as $h^2 = \\frac{\\operatorname{Var}(X \\beta)}{\\operatorname{Var}(X \\beta) + \\sigma_\\varepsilon^2}$. In simulation, one can set $\\sigma_\\varepsilon^2$ to satisfy a target $h^2$ using the empirical variance of the genetic component $g = X \\beta$.\n\nYou are given haplotype panels $H \\in \\{0,1\\}^{M \\times P}$, where $M$ is the number of haplotypes and $P$ is the number of SNPs. To simulate $n$ diploid individuals, sample two haplotypes with replacement for each individual and sum the two haplotype rows to form an unstandardized genotype matrix $G \\in \\{0,1,2\\}^{n \\times P}$. Then:\n1. Center and scale each SNP column of $G$ to construct $X$ with mean $0$ and variance $1$ per column using the population definitions:\n   - For a vector $v \\in \\mathbb{R}^n$, define the mean $\\mu(v) = \\frac{1}{n} \\sum_{i=1}^n v_i$ and variance $s^2(v) = \\frac{1}{n} \\sum_{i=1}^n (v_i - \\mu(v))^2$. Standardization is $v^{\\text{std}} = \\frac{v - \\mu(v) \\mathbf{1}}{s(v)}$ when $s(v) > 0$.\n   - If a SNP has zero variance (monomorphic in the simulated sample), remove that SNP before all downstream computations.\n2. Select $k$ causal SNPs uniformly at random among the retained SNPs and draw their effect sizes independently from a normal distribution, with non-causal SNP effects set to $0$. Let the resulting effect size vector be $\\beta$.\n3. Compute the genetic component $g = X \\beta$. Let $\\widehat{\\operatorname{Var}}(g)$ be the empirical variance using denominator $n$. Set the environmental noise variance $\\sigma_\\varepsilon^2$ to achieve the target heritability $h^2 \\in (0,1)$ via\n   $$\\sigma_\\varepsilon^2 = \\widehat{\\operatorname{Var}}(g) \\cdot \\frac{1 - h^2}{h^2}.$$\n   Sample $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_\\varepsilon^2 I_n)$ and set $y = g + \\varepsilon$. Standardize $y$ to have mean $0$ and variance $1$ using the same population definitions as above.\n4. Compute $R = \\frac{1}{n} X^\\top X$ and $z = \\frac{1}{\\sqrt{n}} X^\\top y$.\n\nYour task is to implement a program that performs the above simulation for the test suite below. The program must be fully deterministic by using the given random seeds.\n\nInput data for the test suite (fixed within the program; no external input is allowed):\n- Test case $1$ (happy path):\n  - Haplotype panel $H_1 \\in \\{0,1\\}^{8 \\times 6}$:\n    - Rows (each row is a haplotype of length $6$):\n      - $[0,0,0,0,0,0]$\n      - $[0,0,1,1,1,1]$\n      - $[1,1,1,1,0,0]$\n      - $[1,1,0,0,1,1]$\n      - $[0,1,0,1,0,1]$\n      - $[1,0,1,0,1,0]$\n      - $[0,1,1,1,0,1]$\n      - $[1,0,0,0,1,0]$\n  - Number of individuals $n = 50$.\n  - Number of causal SNPs $k = 2$.\n  - Target heritability $h^2 = 0.5$ (as a decimal).\n  - Random seed $s = 123$.\n- Test case $2$ (edge case with a monomorphic SNP that must be dropped):\n  - Haplotype panel $H_2 \\in \\{0,1\\}^{6 \\times 5}$:\n    - Rows:\n      - $[0,0,0,0,0]$\n      - $[1,0,1,0,0]$\n      - $[0,1,0,1,0]$\n      - $[1,1,1,1,0]$\n      - $[0,0,1,1,0]$\n      - $[1,0,0,0,0]$\n    - Note: The last column is monomorphic and must be removed after simulating genotypes if it remains monomorphic in the $n$ sampled individuals.\n  - Number of individuals $n = 10$.\n  - Number of causal SNPs $k = 1$.\n  - Target heritability $h^2 = 0.3$.\n  - Random seed $s = 321$.\n- Test case $3$ (strong LD with perfectly correlated SNPs):\n  - Haplotype panel $H_3 \\in \\{0,1\\}^{10 \\times 4}$:\n    - Rows:\n      - $[0,0,0,1]$\n      - $[1,1,0,0]$\n      - $[0,0,1,1]$\n      - $[1,1,1,0]$\n      - $[0,0,0,0]$\n      - $[1,1,1,1]$\n      - $[0,0,1,0]$\n      - $[1,1,0,1]$\n      - $[0,0,0,1]$\n      - $[1,1,1,0]$\n    - Columns $1$ and $2$ are identical, inducing perfect LD.\n  - Number of individuals $n = 40$.\n  - Number of causal SNPs $k = 2$.\n  - Target heritability $h^2 = 0.7$.\n  - Random seed $s = 999$.\n\nImplementation requirements:\n- For each test case, simulate genotypes by sampling two haplotypes with replacement per individual uniformly from the given panel and summing them to obtain $G \\in \\{0,1,2\\}^{n \\times P}$.\n- Standardize columns to build $X$ using the population mean and variance; drop any column with zero variance before further steps. If, after dropping monomorphic SNPs, the number of available SNPs is less than $k$, you must sample causal SNPs without replacement from the available set of SNPs of size $p$ assuming that $k \\le p$ is satisfied in the test suite.\n- Draw nonzero entries of $\\beta$ independently from a standard normal distribution $\\mathcal{N}(0,1)$ for causal SNPs, with all other entries set to $0$.\n- Compute $g = X \\beta$, set $\\sigma_\\varepsilon^2 = \\widehat{\\operatorname{Var}}(g) \\cdot \\frac{1 - h^2}{h^2}$, draw $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_\\varepsilon^2 I_n)$, set $y = g + \\varepsilon$ and standardize $y$ to have mean $0$ and variance $1$ using the population definitions.\n- Compute $R = \\frac{1}{n} X^\\top X$ and $z = \\frac{1}{\\sqrt{n}} X^\\top y$.\n\nNumerical and algorithmic details:\n- Use only the provided parameters and matrices; do not require any external input or files.\n- All random draws must be performed using the specified seed for each test case to ensure determinism.\n- No physical units are involved. The heritability $h^2$ must be interpreted as a decimal in $(0,1)$, not a percentage.\n- Your implementation must be robust to exact-zero variance columns by dropping them.\n\nFinal output specification:\n- For each test case, produce a list that concatenates the entries of $z$ followed by the upper triangular entries (including the diagonal) of $R$ in row-major order. Specifically, if $R \\in \\mathbb{R}^{p \\times p}$, output $[z_1, z_2, \\dots, z_p, R_{11}, R_{12}, \\dots, R_{1p}, R_{22}, R_{23}, \\dots, R_{2p}, \\dots, R_{pp}]$.\n- Aggregate the results of all test cases into a single flat list by appending the per-test-case lists in the order of test cases $1$, $2$, then $3$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\text{result}_3]$).", "solution": "The problem requires the design and implementation of a deterministic simulation pipeline for generating Genome-Wide Association Study (GWAS) summary statistics from haplotype data. The process is grounded in the principles of statistical genetics, specifically the additive linear model for phenotypes. We will validate the problem statement and, finding it valid, proceed to a detailed derivation of the required computational steps.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n-   **Model**: The phenotype vector $y \\in \\mathbb{R}^n$ for $n$ individuals is modeled as $y = X \\beta + \\varepsilon$.\n    -   $X \\in \\mathbb{R}^{n \\times p}$ is the standardized genotype matrix for $p$ SNPs.\n    -   $\\beta \\in \\mathbb{R}^p$ is the vector of SNP effect sizes.\n    -   $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_\\varepsilon^2 I_n)$ is the environmental noise vector.\n-   **Linkage Disequilibrium (LD)**: The LD correlation matrix is $R = \\frac{1}{n} X^\\top X$, where columns of $X$ have mean $0$ and variance $1$.\n-   **Summary Statistics**: The vector of per-SNP summary statistics is $z = \\frac{1}{\\sqrt{n}} X^\\top y$, where both $X$ and $y$ are standardized (mean $0$, variance $1$).\n-   **Heritability**: Narrow-sense heritability is $h^2 = \\frac{\\operatorname{Var}(X \\beta)}{\\operatorname{Var}(X \\beta) + \\sigma_\\varepsilon^2}$.\n-   **Simulation Inputs**:\n    -   Haplotype panel $H \\in \\{0,1\\}^{M \\times P}$.\n    -   Number of individuals $n$.\n    -   Number of causal SNPs $k$.\n    -   Target heritability $h^2$.\n    -   Random seed $s$.\n-   **Simulation Steps**:\n    1.  Generate an unstandardized genotype matrix $G \\in \\{0,1,2\\}^{n \\times P}$ by sampling and summing two haplotypes per individual from $H$.\n    2.  Standardize columns of $G$ to obtain $X$. The standardization uses population mean $\\mu(v) = \\frac{1}{n} \\sum_{i=1}^n v_i$ and variance $s^2(v) = \\frac{1}{n} \\sum_{i=1}^n (v_i - \\mu(v))^2$. SNPs with zero variance are removed.\n    3.  Select $k$ causal SNPs uniformly at random. Their effect sizes are drawn from $\\mathcal{N}(0,1)$, while others are set to $0$. This defines $\\beta$.\n    4.  Compute the genetic component $g = X \\beta$. Set noise variance $\\sigma_\\varepsilon^2 = \\widehat{\\operatorname{Var}}(g) \\cdot \\frac{1 - h^2}{h^2}$. Generate phenotype $y = g + \\varepsilon$ where $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_\\varepsilon^2 I_n)$. Standardize $y$.\n    5.  Compute the outputs $R = \\frac{1}{n} X^\\top X$ and $z = \\frac{1}{\\sqrt{n}} X^\\top y$.\n-   **Test Cases**: Three specific test cases are provided with all necessary parameters ($H_1, H_2, H_3, n, k, h^2, s$).\n-   **Output Format**: A flattened list containing concatenated $z$ vectors and the upper-triangular parts of the corresponding $R$ matrices for all test cases.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is assessed against the validation criteria.\n\n-   **Scientifically Grounded**: The problem is fundamentally sound. The additive linear model, the definitions of heritability, LD, and summary statistics are all standard and widely accepted in statistical genetics and bioinformatics. The simulation pipeline described is a common and valid method for generating synthetic data to test fine-mapping algorithms.\n-   **Well-Posed**: The problem is well-posed. It provides a complete, sequential, and unambiguous set of instructions. The inclusion of random seeds ensures that the entire process is deterministic and results in a unique, verifiable solution. All required data and parameters are provided for each test case.\n-   **Objective**: The problem is stated in precise, objective mathematical and algorithmic language, free from any subjective or opinion-based content.\n\nThe problem does not exhibit any of the defined flaws (e.g., factual unsoundness, incompleteness, ambiguity). The test cases are well-designed to cover a standard scenario (Test Case $1$), an edge case with monomorphic variants (Test Case $2$), and a case with perfect LD (Test Case $3$), which are all relevant challenges in genetic data analysis.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. We will proceed with a full solution.\n\n### Derivation and Algorithmic Design\n\nThe solution implements the simulation pipeline as specified. A deterministic pseudo-random number generator is initialized for each test case to ensure reproducibility.\n\n**1. Genotype Simulation**\n\nWe are given a haplotype panel $H \\in \\{0,1\\}^{M \\times P}$, where $M$ is the number of reference haplotypes and $P$ is the number of SNPs. To simulate a diploid genotype matrix $G \\in \\{0,1,2\\}^{n \\times P}$ for $n$ individuals, we perform the following for each individual $i \\in \\{1, \\dots, n\\}$:\n-   Sample two haplotype indices, $j_1$ and $j_2$, uniformly with replacement from $\\{1, \\dots, M\\}$.\n-   The genotype vector for individual $i$, denoted $G_{i, \\cdot}$, is the element-wise sum of the two sampled haplotypes: $G_{i, \\cdot} = H_{j_1, \\cdot} + H_{j_2, \\cdot}$. The entries of $G$ are thus in $\\{0, 1, 2\\}$, representing the count of the alternate allele at each SNP.\n\n**2. Genotype Standardization and Filtering**\n\nThe raw genotype matrix $G$ must be standardized to have columns with zero mean and unit variance. For each SNP (column) $j \\in \\{1, \\dots, P\\}$, let $G_{\\cdot, j}$ be the corresponding vector of genotypes across $n$ individuals.\n-   The mean is computed as $\\mu_j = \\frac{1}{n} \\sum_{i=1}^n G_{i,j}$.\n-   The population variance is computed as $\\sigma_j^2 = \\frac{1}{n} \\sum_{i=1}^n (G_{i,j} - \\mu_j)^2$. The standard deviation is $\\sigma_j = \\sqrt{\\sigma_j^2}$.\n\nA SNP is monomorphic in the sample if all individuals have the same genotype, which implies its variance is $\\sigma_j^2 = 0$. Such SNPs carry no information for association and must be removed. We filter $G$ to retain only columns where $\\sigma_j > 0$. Let the resulting filtered genotype matrix be $G' \\in \\{0,1,2\\}^{n \\times p}$, where $p \\le P$ is the number of polymorphic SNPs.\n\nThe standardized genotype matrix $X \\in \\mathbb{R}^{n \\times p}$ is then constructed by standardizing each column of $G'$:\n$$X_{\\cdot, j} = \\frac{G'_{\\cdot, j} - \\mu_j \\mathbf{1}}{\\sigma_j}$$\nwhere $\\mu_j$ and $\\sigma_j$ are the mean and standard deviation of the $j$-th column of $G'$, and $\\mathbf{1}$ is a vector of ones of length $n$. Each column of $X$ now has a mean of $0$ and a variance of $1$.\n\n**3. Causal Variant and Effect Size Simulation**\n\nWe model a scenario where a small number of SNPs, $k$, are causal for the phenotype.\n-   We select a set $\\mathcal{C}$ of $k$ distinct indices uniformly at random from $\\{1, \\dots, p\\}$. These are the causal SNPs.\n-   The effect size vector $\\beta \\in \\mathbb{R}^p$ is constructed. For each causal SNP $j \\in \\mathcal{C}$, its effect size $\\beta_j$ is drawn independently from a standard normal distribution, $\\beta_j \\sim \\mathcal{N}(0, 1)$.\n-   For all non-causal SNPs $j \\notin \\mathcal{C}$, the effect size is $\\beta_j = 0$.\n\n**4. Phenotype Simulation**\n\nThe phenotype $y$ is simulated based on the additive linear model $y = g + \\varepsilon$, where $g$ is the genetic component and $\\varepsilon$ is the environmental noise.\n-   The genetic component for all $n$ individuals is computed as $g = X\\beta$. This is a vector in $\\mathbb{R}^n$.\n-   The proportion of phenotypic variance explained by genetics is determined by the narrow-sense heritability, $h^2$. By definition, $h^2 = \\frac{\\operatorname{Var}(g)}{\\operatorname{Var}(g) + \\operatorname{Var}(\\varepsilon)}$. In our simulation, we use the empirical variance of $g$, $\\widehat{\\operatorname{Var}}(g) = \\frac{1}{n}\\sum_{i=1}^n (g_i - \\bar{g})^2$, and set the noise variance $\\sigma_\\varepsilon^2 = \\operatorname{Var}(\\varepsilon)$ to achieve the target $h^2$. This gives:\n  $$\\sigma_\\varepsilon^2 = \\widehat{\\operatorname{Var}}(g) \\left( \\frac{1 - h^2}{h^2} \\right)$$\n  This formula holds assuming $\\operatorname{Var}(g) > 0$. If $k=0$ or all $\\beta_j$ happen to be near $0$, this variance can be zero. However, the problem setup ensures $k>0$ and the random sampling makes $\\widehat{\\operatorname{Var}}(g)=0$ highly improbable.\n-   The environmental noise vector $\\varepsilon \\in \\mathbb{R}^n$ is sampled with each component drawn independently from $\\mathcal{N}(0, \\sigma_\\varepsilon^2)$.\n-   The final phenotype vector is $y = g + \\varepsilon$.\n-   For calculating the summary statistics, this phenotype vector $y$ must be standardized to have mean $0$ and variance $1$, using the same population definitions as for the genotypes. Let this be $y_{\\text{std}}$.\n\n**5. Computation of Summary Statistics and LD Matrix**\n\nWith the standardized genotype matrix $X$ and the standardized phenotype vector $y_{\\text{std}}$, we compute the two required outputs.\n-   The LD correlation matrix $R \\in \\mathbb{R}^{p \\times p}$ is defined as:\n  $$R = \\frac{1}{n} X^\\top X$$\n  The entry $R_{ij}$ represents the correlation between SNP $i$ and SNP $j$. Since the columns of $X$ have unit variance, the diagonal entries $R_{ii}$ are all equal to $1$.\n-   The vector of GWAS summary statistics (Z-scores) $z \\in \\mathbb{R}^p$ is defined as:\n  $$z = \\frac{1}{\\sqrt{n}} X^\\top y_{\\text{std}}$$\n  Each entry $z_j$ is proportional to the marginal correlation between SNP $j$ and the phenotype.\n\nFinally, for each test case, the results are formatted by concatenating the vector $z$ with the upper-triangular elements of $R$ (including the diagonal) taken in row-major order. The results from all test cases are then aggregated into a single list.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation pipeline for all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"H\": np.array([\n                [0, 0, 0, 0, 0, 0],\n                [0, 0, 1, 1, 1, 1],\n                [1, 1, 1, 1, 0, 0],\n                [1, 1, 0, 0, 1, 1],\n                [0, 1, 0, 1, 0, 1],\n                [1, 0, 1, 0, 1, 0],\n                [0, 1, 1, 1, 0, 1],\n                [1, 0, 0, 0, 1, 0]\n            ], dtype=np.int8),\n            \"n\": 50,\n            \"k\": 2,\n            \"h2\": 0.5,\n            \"seed\": 123\n        },\n        {\n            \"H\": np.array([\n                [0, 0, 0, 0, 0],\n                [1, 0, 1, 0, 0],\n                [0, 1, 0, 1, 0],\n                [1, 1, 1, 1, 0],\n                [0, 0, 1, 1, 0],\n                [1, 0, 0, 0, 0]\n            ], dtype=np.int8),\n            \"n\": 10,\n            \"k\": 1,\n            \"h2\": 0.3,\n            \"seed\": 321\n        },\n        {\n            \"H\": np.array([\n                [0, 0, 0, 1],\n                [1, 1, 0, 0],\n                [0, 0, 1, 1],\n                [1, 1, 1, 0],\n                [0, 0, 0, 0],\n                [1, 1, 1, 1],\n                [0, 0, 1, 0],\n                [1, 1, 0, 1],\n                [0, 0, 0, 1],\n                [1, 1, 1, 0]\n            ], dtype=np.int8),\n            \"n\": 40,\n            \"k\": 2,\n            \"h2\": 0.7,\n            \"seed\": 999\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        H, n, k, h2, seed = case[\"H\"], case[\"n\"], case[\"k\"], case[\"h2\"], case[\"seed\"]\n        M, P = H.shape\n        rng = np.random.default_rng(seed)\n\n        # 1. Genotype Simulation\n        hap1_indices = rng.integers(0, M, size=n)\n        hap2_indices = rng.integers(0, M, size=n)\n        G = H[hap1_indices, :] + H[hap2_indices, :]\n\n        # 2. Genotype Standardization and Filtering\n        # Using population std dev (denominator n), numpy default ddof=0\n        mu_G = G.mean(axis=0)\n        std_G = G.std(axis=0)\n\n        polymorphic_mask = std_G > 0\n        if not np.any(polymorphic_mask):\n             # This case should not happen with the given test data\n             # but is a safe guard.\n            all_results.append([])\n            continue\n\n        G_poly = G[:, polymorphic_mask]\n        mu_G_poly = mu_G[polymorphic_mask]\n        std_G_poly = std_G[polymorphic_mask]\n\n        # Standardize G to get X\n        X = (G_poly - mu_G_poly) / std_G_poly\n        n_individuals, p = X.shape\n\n        # 3. Causal Variant and Effect Size Simulation\n        causal_indices = rng.choice(p, size=k, replace=False)\n        beta = np.zeros(p)\n        beta[causal_indices] = rng.standard_normal(size=k)\n\n        # 4. Phenotype Simulation\n        g = X @ beta\n        var_g = np.var(g) # ddof=0 (population variance)\n        \n        # Handle case where var(g) is zero\n        if var_g == 0:\n            sigma2_eps = 1.0 # arbitrary non-zero variance if no genetic effect\n        else:\n            sigma2_eps = var_g * (1 - h2) / h2\n\n        epsilon = rng.normal(loc=0, scale=np.sqrt(sigma2_eps), size=n_individuals)\n        y = g + epsilon\n        \n        # Standardize phenotype vector y\n        y_std = (y - y.mean()) / y.std() # ddof=0\n\n        # 5. Compute Summary Statistics and LD Matrix\n        R = (X.T @ X) / n_individuals\n        z = (X.T @ y_std) / np.sqrt(n_individuals)\n\n        # Format output for the case\n        upper_tri_indices = np.triu_indices(p)\n        R_upper_tri = R[upper_tri_indices]\n        \n        case_results = list(z) + list(R_upper_tri)\n        all_results.extend(case_results)\n\n    # Final print statement\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "4564276"}, {"introduction": "With summary statistics in hand, the central task of fine-mapping is to weigh the evidence for each variant's causality. This exercise provides a hands-on calculation of Posterior Inclusion Probabilities (PIPs), the core output of Bayesian fine-mapping methods. Working through a tangible two-SNP example, you will apply Bayes' theorem to see how prior beliefs are updated with observed $z$-scores and LD information to quantify the posterior probability that each SNP is causal [@problem_id:4564208].", "problem": "Consider a locus with two Single Nucleotide Polymorphisms (SNPs), indexed by $j \\in \\{1,2\\}$. Let the vector of observed marginal $z$-scores be $z = (z_{1}, z_{2})^{\\top}$ and let the $2 \\times 2$ pairwise linkage disequilibrium correlation matrix of genotypes be $R$. Assume the following generative framework grounded in Gaussian linear models and standard summary-statistics approximations:\n\n- Under the null model with no causal effects, the vector $z$ is distributed as a mean-zero multivariate normal with covariance $R$, i.e., $z \\sim \\mathcal{N}(0, R)$.\n- For any subset $S \\subseteq \\{1,2\\}$ indicating the indices of included causal SNPs, the conditional distribution of $z$ given the effect sizes $\\beta_{S}$ satisfies $z \\mid \\beta_{S} \\sim \\mathcal{N}(R_{:,S} \\beta_{S}, R)$, where $R_{:,S}$ denotes the columns of $R$ indexed by $S$. The prior on included effects is independent across included SNPs: $\\beta_{S} \\sim \\mathcal{N}(0, \\sigma_{\\beta}^{2} I_{|S|})$, and excluded effects are fixed at zero.\n- The prior inclusion indicators are independent across SNPs with inclusion probability $p$ for each SNP, so the prior model probability for $S$ is $P(S) = \\prod_{j \\in S} p \\prod_{j \\notin S} (1-p)$.\n- The marginal likelihood for $z$ under model $S$ is obtained by integrating out $\\beta_{S}$ using Gaussian conjugacy.\n\nYou are given the following data and hyperparameters:\n- $z = \\begin{pmatrix} 3.2 \\\\ 1.8 \\end{pmatrix}$,\n- $R = \\begin{pmatrix} 1 & 0.6 \\\\ 0.6 & 1 \\end{pmatrix}$,\n- prior inclusion probability $p = 0.1$,\n- prior variance on included effects $\\sigma_{\\beta}^{2} = 0.05$.\n\nUsing Bayesâ€™ theorem with the above assumptions, compute the Posterior Inclusion Probability (PIP) for each SNP, defined as the posterior probability that a given SNP is included in the causal set, obtained by summing the posterior model probabilities over all models $S$ that include that SNP. Round your final numerical answers to four significant figures.", "solution": "The user wants me to compute the Posterior Inclusion Probability (PIP) for each of two SNPs based on a Bayesian fine-mapping framework.\n\n### Step 1: Problem Validation\n\n**1.1. Extract Givens**\n- Number of SNPs: $2$, indexed by $j \\in \\{1,2\\}$.\n- Observed marginal $z$-scores vector: $z = \\begin{pmatrix} 3.2 \\\\ 1.8 \\end{pmatrix}$.\n- Linkage disequilibrium (LD) correlation matrix: $R = \\begin{pmatrix} 1 & 0.6 \\\\ 0.6 & 1 \\end{pmatrix}$.\n- Prior inclusion probability for each SNP: $p = 0.1$.\n- Prior variance on included (non-zero) effects: $\\sigma_{\\beta}^{2} = 0.05$.\n\n**1.2. Model Specification**\n- The set of causal SNPs is denoted by $S \\subseteq \\{1,2\\}$.\n- The prior probability of a model (causal set) $S$ is $P(S) = p^{|S|} (1-p)^{2-|S|}$.\n- The conditional distribution of the $z$-score vector given the causal effects $\\beta_S$ for model $S$ is $z \\mid \\beta_{S} \\sim \\mathcal{N}(R_{:,S} \\beta_{S}, R)$.\n- The prior distribution for the causal effects is $\\beta_{S} \\sim \\mathcal{N}(0, \\sigma_{\\beta}^{2} I_{|S|})$.\n- The marginal likelihood $P(z|S)$ is obtained by integrating out $\\beta_S$: $P(z|S) = \\int p(z | \\beta_S) p(\\beta_S) d\\beta_S$.\n\n**1.3. Validation Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective.\n- **Scientific Soundness**: The described model is a standard formulation for Bayesian fine-mapping using summary statistics (z-scores). The use of multivariate normal distributions for z-scores, priors on effect sizes, and model probabilities is central to methods like FINEMAP and SuSiE. All assumptions are consistent with established statistical genetics principles.\n- **Well-Posedness**: The problem provides all necessary data ($z$, $R$) and hyperparameters ($p$, $\\sigma_{\\beta}^{2}$) to compute the desired quantities (PIPs). The task is mathematically well-defined, and a unique solution exists.\n- **Objectivity**: The problem is stated using precise mathematical and statistical language, free of ambiguity or subjectivity.\n\n**1.4. Verdict**\nThe problem is valid.\n\n### Step 2: Solution Derivation\n\nThe goal is to compute the Posterior Inclusion Probability (PIP) for each SNP, defined as $PIP_j = \\sum_{S: j \\in S} P(S|z)$. We use Bayes' theorem to find the posterior probability of each model $S$:\n$$P(S|z) = \\frac{P(z|S)P(S)}{\\sum_{S'} P(z|S')P(S')}$$\nThe term $P(z|S)$ is the marginal likelihood for model $S$. It is convenient to work with Bayes Factors (BF), which compare the marginal likelihood of a model $S$ to the null model $S_0 = \\emptyset$.\n$$BF_S = \\frac{P(z|S)}{P(z|S_0)}$$\nThen, the posterior probability can be written as:\n$$P(S|z) = \\frac{BF_S \\cdot P(S)}{\\sum_{S'} BF_{S'} \\cdot P(S')}$$\nThere are $2^2=4$ possible models: $S_0 = \\emptyset$, $S_1 = \\{1\\}$, $S_2 = \\{2\\}$, and $S_{12} = \\{1,2\\}$.\n\n**2.1. Prior Model Probabilities**\nWith $p=0.1$:\n- $P(S_0) = (1-p)^2 = 0.9^2 = 0.81$\n- $P(S_1) = p(1-p) = 0.1 \\cdot 0.9 = 0.09$\n- $P(S_2) = (1-p)p = 0.9 \\cdot 0.1 = 0.09$\n- $P(S_{12}) = p^2 = 0.1^2 = 0.01$\n\n**2.2. Bayes Factor Calculation**\nThe marginal likelihood $P(z|S)$ is derived by integrating the product of two Gaussian distributions: $p(z | \\beta_S) = \\mathcal{N}(z; R_{:,S} \\beta_S, R)$ and $p(\\beta_S) = \\mathcal{N}(\\beta_S; 0, \\sigma_{\\beta}^2 I_{|S|})$. The result is a multivariate normal distribution for $z$ under model $S$:\n$$z \\mid S \\sim \\mathcal{N}(0, V_S) \\quad \\text{where} \\quad V_S = R + \\sigma_{\\beta}^2 R_{:,S} R_{S,:}$$\nThe log-marginal likelihood is $\\log P(z|S) = -\\frac{d}{2}\\log(2\\pi) - \\frac{1}{2}\\log(\\det(V_S)) - \\frac{1}{2}z^T V_S^{-1} z$, where $d=2$ is the dimension of $z$.\nThe log-Bayes factor for model $S$ versus the null $S_0$ (for which $V_{S_0}=R$) is:\n$$\\log(BF_S) = \\log P(z|S) - \\log P(z|S_0) = \\frac{1}{2}\\left[ \\log\\left(\\frac{\\det(R)}{\\det(V_S)}\\right) - z^T(V_S^{-1} - R^{-1})z \\right]$$\nWe will calculate this for each model.\nGiven data: $z = \\begin{pmatrix} 3.2 \\\\ 1.8 \\end{pmatrix}$, $R = \\begin{pmatrix} 1 & 0.6 \\\\ 0.6 & 1 \\end{pmatrix}$, $\\sigma_{\\beta}^2=0.05$.\n$\\det(R) = 1 \\cdot 1 - 0.6^2 = 0.64$.\n$R^{-1} = \\frac{1}{0.64} \\begin{pmatrix} 1 & -0.6 \\\\ -0.6 & 1 \\end{pmatrix} = \\begin{pmatrix} 1.5625 & -0.9375 \\\\ -0.9375 & 1.5625 \\end{pmatrix}$.\n\n- **Model $S_0 = \\emptyset$**: By definition, $BF_{S_0} = 1$, so $\\log(BF_{S_0}) = 0$.\n\n- **Model $S_1 = \\{1\\}$**:\nA standard result for a single causal SNP model $S=\\{j\\}$ is $\\log(BF_{S_j}) = -\\frac{1}{2}\\log(1+\\sigma_\\beta^2) + \\frac{1}{2} z_j^2 \\frac{\\sigma_\\beta^2}{1+\\sigma_\\beta^2}$.\nFor $S_1 = \\{1\\}$, we have $z_1 = 3.2$:\n$\\log(BF_{S_1}) = -\\frac{1}{2}\\log(1+0.05) + \\frac{1}{2} (3.2)^2 \\frac{0.05}{1+0.05} = -\\frac{1}{2}\\log(1.05) + \\frac{1}{2} (10.24) \\frac{1}{21}$\n$\\log(BF_{S_1}) \\approx -0.5 \\cdot 0.048790 + 5.12 \\cdot 0.047619 \\approx -0.024395 + 0.24379 \\approx 0.2194$\n$BF_{S_1} = \\exp(0.2194) \\approx 1.2453$\n\n- **Model $S_2 = \\{2\\}$**:\nUsing the same formula for $j=2$ with $z_2 = 1.8$:\n$\\log(BF_{S_2}) = -\\frac{1}{2}\\log(1.05) + \\frac{1}{2} (1.8)^2 \\frac{1}{21} = -\\frac{1}{2}\\log(1.05) + \\frac{1}{2} (3.24) \\frac{1}{21}$\n$\\log(BF_{S_2}) \\approx -0.024395 + 1.62 \\cdot 0.047619 \\approx -0.024395 + 0.077143 \\approx 0.05275$\n$BF_{S_2} = \\exp(0.05275) \\approx 1.0542$\n\n- **Model $S_{12} = \\{1,2\\}$**:\nUsing the formula $\\log(BF_{S}) = -1/2 \\log(\\det(I + \\sigma_\\beta^2 R_{S,S}^{-1})) + 1/2 z_S^T (R_{S,S} + \\sigma_\\beta^{-2}I)^{-1} z_S$ is a bit messy. A more direct formula based on the full $z$ vector is $\\log(BF_S) = -1/2 \\log(\\det(I + \\sigma_\\beta^2 R_{S,S})) + 1/2 (R_{:,S}z)^T (R_{S,S} + \\sigma_\\beta^{-2}I)^{-1} (R_{:,S}z)$.\nLet's use another correct formulation: $\\log(BF_{S}) = -1/2 \\log(\\det(I + \\sigma_\\beta^2 R)) + 1/2 z^T (\\sigma_\\beta^{-2}I + R)^{-1} z$.\n$I + \\sigma_\\beta^2 R = \\begin{pmatrix} 1.05 & 0.03 \\\\ 0.03 & 1.05 \\end{pmatrix}$, $\\det(I + \\sigma_\\beta^2 R) = 1.05^2 - 0.03^2 = 1.1016$.\n$\\sigma_\\beta^{-2} = 1/0.05 = 20$.\n$\\sigma_\\beta^{-2}I+R = \\begin{pmatrix} 21 & 0.6 \\\\ 0.6 & 21 \\end{pmatrix}$, $\\det(\\sigma_\\beta^{-2}I+R) = 21^2-0.6^2 = 440.64$.\n$(\\sigma_\\beta^{-2}I+R)^{-1} = \\frac{1}{440.64}\\begin{pmatrix} 21 & -0.6 \\\\ -0.6 & 21 \\end{pmatrix}$.\n$z^T(\\sigma_\\beta^{-2}I+R)^{-1}z = \\frac{1}{440.64} \\begin{pmatrix} 3.2 & 1.8 \\end{pmatrix} \\begin{pmatrix} 21 & -0.6 \\\\ -0.6 & 21 \\end{pmatrix} \\begin{pmatrix} 3.2 \\\\ 1.8 \\end{pmatrix} = \\frac{276.168}{440.64} \\approx 0.626738$.\n$\\log(BF_{S_{12}}) = -1/2 \\log(1.1016) + 1/2 (0.626738) \\approx -1/2(0.09678) + 0.313369 \\approx 0.26498$.\n$BF_{S_{12}} = \\exp(0.26498) \\approx 1.3034$.\n\n**2.3. Posterior Model Probabilities**\nWe compute the unnormalized posterior weights $w_S = BF_S \\cdot P(S)$:\n- $w_{S_0} = 1 \\cdot 0.81 = 0.81$\n- $w_{S_1} = 1.2453 \\cdot 0.09 = 0.112077$\n- $w_{S_2} = 1.0542 \\cdot 0.09 = 0.094878$\n- $w_{S_{12}} = 1.3034 \\cdot 0.01 = 0.013034$\n\nThe normalization constant is $C = \\sum_S w_S = 0.81 + 0.112077 + 0.094878 + 0.013034 = 1.029989$.\nThe posterior probabilities are $P(S|z) = w_S/C$:\n- $P(S_0|z) = 0.81 / 1.029989 \\approx 0.786417$\n- $P(S_1|z) = 0.112077 / 1.029989 \\approx 0.108814$\n- $P(S_2|z) = 0.094878 / 1.029989 \\approx 0.092116$\n- $P(S_{12}|z) = 0.013034 / 1.029989 \\approx 0.012654$\n\n**2.4. Posterior Inclusion Probabilities (PIPs)**\nThe PIP for a SNP is the sum of posterior probabilities of all models that include it.\n- $PIP_1 = P(S_1|z) + P(S_{12}|z) \\approx 0.108814 + 0.012654 = 0.121468$\n- $PIP_2 = P(S_2|z) + P(S_{12}|z) \\approx 0.092116 + 0.012654 = 0.104770$\n\nRounding to four significant figures:\n- $PIP_1 \\approx 0.1215$\n- $PIP_2 \\approx 0.1048$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.1215 & 0.1048\n\\end{pmatrix}\n}\n$$", "id": "4564208"}, {"introduction": "A list of PIPs across many variants needs to be distilled into a concise, interpretable result for guiding future research. The concept of a credible set provides a rigorous way to summarize posterior uncertainty and identify a high-confidence set of candidate causal variants. This practice demonstrates how to construct a minimal credible set from a given list of PIPs, a critical skill for interpreting and reporting the findings of a fine-mapping analysis [@problem_id:4564210].", "problem": "You are analyzing a single genomic locus under a single-causal-variant assumption, where exactly one Single Nucleotide Polymorphism (SNP) is causal. The posterior inclusion probability (PIP) for SNP $i$ is defined as the posterior probability that SNP $i$ is the causal variant given the observed data and the model assumptions. A credible set at level $c$ is defined as the smallest set of variants such that the sum of their PIPs is at least $c$.\n\nYou are given the posterior inclusion probabilities for $10$ SNPs at this locus (in arbitrary labels $s_{1},\\dots,s_{10}$):\n- $s_{1}: 0.35$\n- $s_{2}: 0.22$\n- $s_{3}: 0.18$\n- $s_{4}: 0.08$\n- $s_{5}: 0.06$\n- $s_{6}: 0.04$\n- $s_{7}: 0.03$\n- $s_{8}: 0.02$\n- $s_{9}: 0.01$\n- $s_{10}: 0.01$\n\nAssume these PIPs are properly normalized under the single-causal-variant model so that their sum is $1$. Using the definitions above as the fundamental base, construct the minimal credible set at target credible level $c = 0.90$ by ordering SNPs in descending PIP and including variants until the cumulative sum first reaches or exceeds $c$. Determine the size of this minimal credible set and its cumulative inclusion probability (the posterior probability that the causal variant lies in the set). Provide the size of the minimal credible set as your final answer (an integer, unitless). No rounding is required for the final answer.", "solution": "The problem requires the construction of a minimal credible set for a given set of posterior inclusion probabilities (PIPs) and a specified credible level. The task is to determine the size of this set.\n\nThe fundamental definitions are provided:\n1.  A single-causal-variant model is assumed, meaning exactly one of the $10$ Single Nucleotide Polymorphisms (SNPs) is causal.\n2.  The PIP for a SNP is the posterior probability that it is the causal variant. Under the model assumption, the sum of all PIPs must be $1$.\n3.  A credible set at level $c$ is the smallest set of variants whose PIPs sum to at least $c$.\n4.  The construction method specified is to order the SNPs by their PIPs in descending order and sequentially add them to the set until the cumulative sum of their PIPs reaches or exceeds the target level $c$.\n\nThe givens are:\n- The number of SNPs is $10$.\n- The PIPs for the SNPs, denoted as $P(s_i)$ for SNP $s_i$, are provided and already sorted in descending order:\n    - $P(s_1) = 0.35$\n    - $P(s_2) = 0.22$\n    - $P(s_3) = 0.18$\n    - $P(s_4) = 0.08$\n    - $P(s_5) = 0.06$\n    - $P(s_6) = 0.04$\n    - $P(s_7) = 0.03$\n    - $P(s_8) = 0.02$\n    - $P(s_9) = 0.01$\n    - $P(s_{10}) = 0.01$\n- The target credible level is $c = 0.90$.\n\nThe problem states that the PIPs are normalized to sum to $1$. We can verify this:\n$$ \\sum_{i=1}^{10} P(s_i) = 0.35 + 0.22 + 0.18 + 0.08 + 0.06 + 0.04 + 0.03 + 0.02 + 0.01 + 0.01 = 1.00 $$\nThe condition is satisfied.\n\nTo construct the minimal credible set, we calculate the cumulative sum of the ordered PIPs and stop when the sum is greater than or equal to $c = 0.90$. Let $S_k$ be the cumulative sum of the PIPs for the top $k$ SNPs.\n\n1.  Include the SNP with the highest PIP, $s_1$:\n    $S_1 = P(s_1) = 0.35$.\n    This is less than $0.90$. The set is $\\{s_1\\}$. Size is $1$.\n\n2.  Add the next SNP, $s_2$:\n    $S_2 = P(s_1) + P(s_2) = 0.35 + 0.22 = 0.57$.\n    This is less than $0.90$. The set is $\\{s_1, s_2\\}$. Size is $2$.\n\n3.  Add the next SNP, $s_3$:\n    $S_3 = S_2 + P(s_3) = 0.57 + 0.18 = 0.75$.\n    This is less than $0.90$. The set is $\\{s_1, s_2, s_3\\}$. Size is $3$.\n\n4.  Add the next SNP, $s_4$:\n    $S_4 = S_3 + P(s_4) = 0.75 + 0.08 = 0.83$.\n    This is less than $0.90$. The set is $\\{s_1, s_2, s_3, s_4\\}$. Size is $4$.\n\n5.  Add the next SNP, $s_5$:\n    $S_5 = S_4 + P(s_5) = 0.83 + 0.06 = 0.89$.\n    This is less than $0.90$. The set is $\\{s_1, s_2, s_3, s_4, s_5\\}$. Size is $5$.\n\n6.  Add the next SNP, $s_6$:\n    $S_6 = S_5 + P(s_6) = 0.89 + 0.04 = 0.93$.\n    This value, $0.93$, is greater than or equal to the target credible level $c = 0.90$.\n\nThe process stops here. The minimal credible set required to achieve at least a $0.90$ cumulative probability is $\\{s_1, s_2, s_3, s_4, s_5, s_6\\}$.\n\nThe size of this set is the number of SNPs it contains, which is $6$.\nThe cumulative inclusion probability for this set is the final sum, $S_6 = 0.93$, which is the posterior probability that the causal variant is contained within this set of $6$ SNPs.\n\nThe problem asks for the size of this minimal credible set. Based on the step-by-step construction, the size is $6$.", "answer": "$$\\boxed{6}$$", "id": "4564210"}]}