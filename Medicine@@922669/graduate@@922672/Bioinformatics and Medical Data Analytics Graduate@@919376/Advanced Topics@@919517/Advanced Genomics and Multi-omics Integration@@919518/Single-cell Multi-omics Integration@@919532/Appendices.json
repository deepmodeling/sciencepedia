{"hands_on_practices": [{"introduction": "A critical first step in any single-cell multi-omics integration workflow is the independent preprocessing of each modality. For single-cell RNA sequencing data, this involves transforming raw transcript counts into a stabilized scale that corrects for differences in cellular library size. This practice will guide you through the calculation of log-normalized expression, a cornerstone technique that makes gene expression values comparable across cells and prepares the data for robust downstream analysis and integration [@problem_id:4607704].", "problem": "A clinical study aims to integrate single-cell RNA sequencing (scRNA-seq) and single-cell Assay for Transposase-Accessible Chromatin using sequencing (scATAC-seq) profiles to discover gene regulatory programs associated with therapy response in a heterogeneous tumor microenvironment. To construct a joint latent space, the scRNA-seq modality must first be transformed to a stabilized, relative abundance scale that is comparable across cells of varying sequencing depths. In scRNA-seq, Unique Molecular Identifier (UMI) counts $c_{ig}$ for gene $g$ in cell $i$ are proportional to the number of captured transcript molecules, and the total $\\sum_{g} c_{ig}$ reflects the library size for cell $i$.\n\nStarting from the following well-tested processing steps grounded in standard practice for single-cell transcript quantification:\n- Relative abundance is obtained by dividing the raw count for a gene by the cell’s total UMI count, yielding a fraction $c_{ig} / \\sum_{g} c_{ig}$.\n- To render the scale interpretable and mitigate the extreme sparsity typical in single-cell data while maintaining comparability across cells, this fraction is rescaled to counts per $10^{4}$ by multiplying by $10^{4}$.\n- To stabilize variance and dampen the influence of highly expressed genes, apply a logarithm with base $2$ to the rescaled quantity, adding a pseudocount of $1$ before the log to avoid taking a logarithm of zero.\n\nUsing these definitions, derive the symbolic expression for the log-normalized expression $\\tilde{x}_{ig}$ and then compute its value for a cell with raw UMI count $c_{ig} = 50$ for a particular gene and total UMI count $\\sum_{g} c_{ig} = 5000$. Express your final answer as a dimensionless value and round to four significant figures.", "solution": "The problem statement is a valid and well-posed request within the domain of bioinformatics and computational biology. It describes a standard procedure for single-cell RNA sequencing (scRNA-seq) data normalization, a critical preprocessing step for downstream analyses such as multi-omics integration. All provided information is scientifically sound, self-contained, and sufficient to derive a unique solution.\n\nThe task is to first derive the symbolic expression for the log-normalized expression, denoted as $\\tilde{x}_{ig}$, for gene $g$ in cell $i$, and then to compute its numerical value given specific UMI counts. We will follow the prescribed sequence of operations.\n\nLet $c_{ig}$ be the raw Unique Molecular Identifier (UMI) count for gene $g$ in cell $i$.\nLet $C_i = \\sum_{g} c_{ig}$ be the total UMI count for cell $i$, which is also referred to as the library size of the cell.\n\nThe normalization process consists of three defined steps:\n\nStep 1: Compute the relative abundance of the gene's transcripts in the cell. This is achieved by dividing the raw count for the gene by the total UMI count for the cell.\n$$ \\text{Relative Abundance} = \\frac{c_{ig}}{C_i} = \\frac{c_{ig}}{\\sum_{g} c_{ig}} $$\n\nStep 2: Rescale the relative abundance to a common scale, typically \"counts per 10,000\" (CP10k) or \"transcripts per 10,000\" (TP10k), to facilitate comparison across cells with different library sizes. This is done by multiplying the relative abundance by a scale factor of $10^4$.\n$$ \\text{Rescaled Value} = \\left( \\frac{c_{ig}}{\\sum_{g} c_{ig}} \\right) \\times 10^4 $$\n\nStep 3: Apply a log-transformation to the rescaled value. This transformation helps to stabilize the variance across genes with different expression levels and reduces the skewness of the data distribution. A pseudocount of $1$ is added before taking the logarithm to ensure that the argument of the logarithm is always positive, thus avoiding issues with genes that have zero counts. The base of the logarithm is specified as $2$.\nThe log-normalized expression $\\tilde{x}_{ig}$ is therefore:\n$$ \\tilde{x}_{ig} = \\log_{2}\\left( \\left( \\frac{c_{ig}}{\\sum_{g} c_{ig}} \\right) \\times 10^4 + 1 \\right) $$\nThis is the required symbolic expression.\n\nNow, we will compute the value of $\\tilde{x}_{ig}$ for the given data:\n- Raw UMI count for the gene of interest: $c_{ig} = 50$\n- Total UMI count for the cell: $\\sum_{g} c_{ig} = 5000$\n\nSubstituting these values into the symbolic expression:\n$$ \\tilde{x}_{ig} = \\log_{2}\\left( \\left( \\frac{50}{5000} \\right) \\times 10^4 + 1 \\right) $$\n\nFirst, we calculate the fraction:\n$$ \\frac{50}{5000} = \\frac{5}{500} = \\frac{1}{100} = 0.01 $$\n\nNext, we perform the rescaling:\n$$ 0.01 \\times 10^4 = 0.01 \\times 10000 = 100 $$\n\nThen, we add the pseudocount of $1$:\n$$ 100 + 1 = 101 $$\n\nFinally, we take the logarithm with base $2$:\n$$ \\tilde{x}_{ig} = \\log_{2}(101) $$\n\nTo compute the numerical value, we can use the change of base formula for logarithms, $\\log_{b}(a) = \\frac{\\ln(a)}{\\ln(b)}$:\n$$ \\tilde{x}_{ig} = \\frac{\\ln(101)}{\\ln(2)} $$\n\nUsing standard values for natural logarithms:\n$$ \\ln(101) \\approx 4.6151205168 $$\n$$ \\ln(2) \\approx 0.6931471806 $$\n\n$$ \\tilde{x}_{ig} \\approx \\frac{4.6151205168}{0.6931471806} \\approx 6.6582115934 $$\n\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $6$, $6$, $5$, and $8$. The fifth significant figure is $2$, which is less than $5$, so we round down (i.e., we do not change the last digit).\n\nTherefore, the log-normalized expression value is approximately $6.658$. This value is dimensionless, as the units of counts in the numerator and denominator of the initial fraction cancel out.", "answer": "$$\n\\boxed{6.658}\n$$", "id": "4607704"}, {"introduction": "The goal of integration is to align datasets while preserving biological heterogeneity, but how do we measure success? This exercise introduces a principled benchmarking framework to quantitatively evaluate the quality of a multi-omic embedding. By computing metrics for both batch mixing and biological conservation, you will learn to assess the fundamental trade-off in integration and develop a nuanced understanding of what constitutes a \"good\" result, which is an indispensable skill for any computational biologist [@problem_id:4381611].", "problem": "A central aim of single-cell multi-omics integration in precision medicine and genomic diagnostics is to produce an embedding that simultaneously mixes technical batches while preserving biological structure (for example, cell types). A balanced benchmarking protocol should therefore quantify two orthogonal properties: local batch mixing and biological conservation. Starting from well-tested definitions used in ecology and clustering validation, you will derive and compute two complementary metrics and aggregate them into a single balanced score.\n\nConsider a toy integrated embedding of $n=6$ single cells on a one-dimensional axis (use Euclidean distance). The cells have batch labels from two batches $B \\in \\{\\mathrm{B1}, \\mathrm{B2}\\}$ and cell type labels from two types $T \\in \\{\\mathrm{T1}, \\mathrm{T2}\\}$. The embedding coordinate $x$, batch $B$, and type $T$ for each cell $C_i$ are:\n- $C_1: x=0.0$, $B=\\mathrm{B1}$, $T=\\mathrm{T1}$.\n- $C_2: x=0.2$, $B=\\mathrm{B2}$, $T=\\mathrm{T1}$.\n- $C_3: x=0.4$, $B=\\mathrm{B1}$, $T=\\mathrm{T2}$.\n- $C_4: x=1.2$, $B=\\mathrm{B2}$, $T=\\mathrm{T2}$.\n- $C_5: x=1.4$, $B=\\mathrm{B1}$, $T=\\mathrm{T1}$.\n- $C_6: x=1.6$, $B=\\mathrm{B2}$, $T=\\mathrm{T1}$.\n\nProtocol requirements:\n1. For batch mixing, use the Local Inverse Simpson’s Index (LISI), computed on a $k$-nearest neighbor set that includes the query cell. Construct the $k$-nearest neighbor graph using Euclidean distance on $x$ with neighborhood size $k=3$ (the query cell plus its two nearest neighbors). For each cell $C_i$, compute the inverse Simpson’s index on the empirical batch label distribution within its local set, then average across all cells to obtain a dataset-level batch mixing score $L$.\n2. For biological conservation, use the Average Silhouette Width (ASW) computed on the cell type labels using Euclidean distances on $x$. For each cell $C_i$, compute its silhouette width $s(i)$ from the average distance to other cells of the same type and to cells of the other type, then average across all cells to obtain a dataset-level biological conservation score $A$.\n3. To achieve balance and comparability, linearly normalize each metric to the unit interval $[0,1]$ using its canonical range: with $B=2$ batches, normalize $L$ by its theoretical maximum; normalize $A$ from its standard range to $[0,1]$ by an affine transformation. Combine the normalized scores by the geometric mean to obtain the balanced integration score $S_B$.\n\nCompute $S_B$ for the above dataset, and round your final answer to four significant figures. No units are required.", "solution": "The goal is to derive and compute a balanced integration score that reflects both batch mixing and biological conservation. We begin from fundamental, well-tested definitions.\n\nBatch mixing via Local Inverse Simpson’s Index (LISI):\n- The Simpson diversity index for a categorical distribution $\\{p_{j}\\}$ is $\\sum_{j} p_{j}^{2}$.\n- The inverse Simpson index is $1/\\left(\\sum_{j} p_{j}^{2}\\right)$.\n- The Local Inverse Simpson’s Index (LISI) applies this to the local neighborhood label distribution. With $k=3$ (the query cell plus its two nearest neighbors), for each cell $C_i$ we compute the empirical batch proportions $p_{\\mathrm{B1},i}$ and $p_{\\mathrm{B2},i}$ in its local set, then $L_i = \\left(p_{\\mathrm{B1},i}^{2} + p_{\\mathrm{B2},i}^{2}\\right)^{-1}$. The dataset-level batch mixing score is $L = \\frac{1}{n}\\sum_{i=1}^{n} L_i$.\n\nBiological conservation via Average Silhouette Width (ASW):\n- For each cell $C_i$, let $a(i)$ be the average Euclidean distance to other cells of the same type, and $b(i)$ be the average Euclidean distance to cells of the other type. The silhouette width is $s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}$, which lies in $[-1,1]$. The dataset-level ASW is $A = \\frac{1}{n}\\sum_{i=1}^{n} s(i)$.\n\nNormalization and balanced aggregation:\n- With $B=2$ batches, the inverse Simpson index has a theoretical maximum of $2$ under perfectly uniform proportions ($p_{\\mathrm{B1}}=p_{\\mathrm{B2}}=1/2$), independent of neighborhood size in the continuous limit. Thus define the normalized batch mixing score $\\tilde{L} = \\frac{L}{2}$.\n- The silhouette mean $A$ lies in $[-1,1]$. A linear map to $[0,1]$ is $\\tilde{A} = \\frac{A + 1}{2}$.\n- A symmetric and scale-invariant balanced aggregation is the geometric mean, so define $S_B = \\sqrt{\\tilde{L}\\,\\tilde{A}}$.\n\nWe now compute each term for the given dataset.\n\nStep 1: $k$-nearest neighbors and LISI.\nWe use Euclidean distance on the one-dimensional coordinates $x$.\n\nCompute nearest neighbors (two nearest) for each cell:\n- $C_1$ at $x=0.0$: distances to others are $|0.0 - 0.2| = 0.2$ ($C_2$), $|0.0 - 0.4| = 0.4$ ($C_3$), $|0.0 - 1.2| = 1.2$ ($C_4$), $|0.0 - 1.4| = 1.4$ ($C_5$), $|0.0 - 1.6| = 1.6$ ($C_6$). The two nearest neighbors are $C_2$ and $C_3$. Local set: $\\{C_1, C_2, C_3\\}$ with batches $\\{\\mathrm{B1}, \\mathrm{B2}, \\mathrm{B1}\\}$. Thus $p_{\\mathrm{B1},1} = \\frac{2}{3}$, $p_{\\mathrm{B2},1} = \\frac{1}{3}$, giving $L_1 = \\left(\\left(\\frac{2}{3}\\right)^{2} + \\left(\\frac{1}{3}\\right)^{2}\\right)^{-1} = \\left(\\frac{4}{9} + \\frac{1}{9}\\right)^{-1} = \\left(\\frac{5}{9}\\right)^{-1} = \\frac{9}{5}$.\n- $C_2$ at $x=0.2$: distances to $C_1$ and $C_3$ are $0.2$ and $0.2$; these are the two nearest. Local set: $\\{C_2, C_1, C_3\\}$ with batches $\\{\\mathrm{B2}, \\mathrm{B1}, \\mathrm{B1}\\}$. Thus $p_{\\mathrm{B1},2} = \\frac{2}{3}$, $p_{\\mathrm{B2},2} = \\frac{1}{3}$, so $L_2 = \\frac{9}{5}$.\n- $C_3$ at $x=0.4$: nearest to $C_2$ ($0.2$) and $C_1$ ($0.4$). Local set: $\\{C_3, C_2, C_1\\}$ with batches $\\{\\mathrm{B1}, \\mathrm{B2}, \\mathrm{B1}\\}$. Thus $L_3 = \\frac{9}{5}$.\n- $C_4$ at $x=1.2$: nearest to $C_5$ ($0.2$) and $C_6$ ($0.4$). Local set: $\\{C_4, C_5, C_6\\}$ with batches $\\{\\mathrm{B2}, \\mathrm{B1}, \\mathrm{B2}\\}$. Thus $L_4 = \\frac{9}{5}$.\n- $C_5$ at $x=1.4$: nearest to $C_6$ ($0.2$) and $C_4$ ($0.2$). Local set: $\\{C_5, C_6, C_4\\}$ with batches $\\{\\mathrm{B1}, \\mathrm{B2}, \\mathrm{B2}\\}$. Thus $L_5 = \\frac{9}{5}$.\n- $C_6$ at $x=1.6$: nearest to $C_5$ ($0.2$) and $C_4$ ($0.4$). Local set: $\\{C_6, C_5, C_4\\}$ with batches $\\{\\mathrm{B2}, \\mathrm{B1}, \\mathrm{B2}\\}$. Thus $L_6 = \\frac{9}{5}$.\n\nTherefore, the dataset average is\n$$\nL = \\frac{1}{6}\\sum_{i=1}^{6} L_i = \\frac{1}{6}\\left(6 \\cdot \\frac{9}{5}\\right) = \\frac{9}{5}.\n$$\n\nStep 2: ASW on cell types.\nWe compute $a(i)$ and $b(i)$ using all cells of the same or other type.\n\nType sets: $\\mathrm{T1} = \\{C_1(0.0), C_2(0.2), C_5(1.4), C_6(1.6)\\}$, $\\mathrm{T2} = \\{C_3(0.4), C_4(1.2)\\}$.\n\nDistances needed:\n- Within $\\mathrm{T1}$: $d(C_1,C_2)=0.2$, $d(C_1,C_5)=1.4$, $d(C_1,C_6)=1.6$; $d(C_2,C_5)=1.2$, $d(C_2,C_6)=1.4$; $d(C_5,C_6)=0.2$.\n- Between $\\mathrm{T1}$ and $\\mathrm{T2}$: $d(C_1,C_3)=0.4$, $d(C_1,C_4)=1.2$; $d(C_2,C_3)=0.2$, $d(C_2,C_4)=1.0$; $d(C_5,C_3)=1.0$, $d(C_5,C_4)=0.2$; $d(C_6,C_3)=1.2$, $d(C_6,C_4)=0.4$.\n- Within $\\mathrm{T2}$: $d(C_3,C_4)=0.8$.\n\nCompute $a(i)$ and $b(i)$ for each $C_i$:\n- $C_1 \\in \\mathrm{T1}$: $a(C_1) = \\frac{0.2 + 1.4 + 1.6}{3} = \\frac{3.2}{3} = \\frac{16}{15}$; $b(C_1) = \\frac{0.4 + 1.2}{2} = 0.8 = \\frac{12}{15}$. Then\n$$\ns(C_1) = \\frac{b(C_1) - a(C_1)}{\\max\\{a(C_1), b(C_1)\\}} = \\frac{\\frac{12}{15} - \\frac{16}{15}}{\\frac{16}{15}} = \\frac{-\\frac{4}{15}}{\\frac{16}{15}} = -\\frac{1}{4}.\n$$\n- $C_2 \\in \\mathrm{T1}$: $a(C_2) = \\frac{0.2 + 1.2 + 1.4}{3} = \\frac{2.8}{3} = \\frac{14}{15}$; $b(C_2) = \\frac{0.2 + 1.0}{2} = 0.6 = \\frac{9}{15}$. Then\n$$\ns(C_2) = \\frac{\\frac{9}{15} - \\frac{14}{15}}{\\frac{14}{15}} = \\frac{-\\frac{5}{15}}{\\frac{14}{15}} = -\\frac{1}{3}\\cdot \\frac{15}{14} = -\\frac{5}{14}.\n$$\n- $C_5 \\in \\mathrm{T1}$: $a(C_5) = \\frac{1.4 + 1.2 + 0.2}{3} = \\frac{2.8}{3} = \\frac{14}{15}$; $b(C_5) = \\frac{1.0 + 0.2}{2} = 0.6 = \\frac{9}{15}$. Thus $s(C_5) = -\\frac{5}{14}$.\n- $C_6 \\in \\mathrm{T1}$: $a(C_6) = \\frac{1.6 + 1.4 + 0.2}{3} = \\frac{3.2}{3} = \\frac{16}{15}$; $b(C_6) = \\frac{1.2 + 0.4}{2} = 0.8 = \\frac{12}{15}$. Thus $s(C_6) = -\\frac{1}{4}$.\n- $C_3 \\in \\mathrm{T2}$: $a(C_3) = d(C_3,C_4) = 0.8 = \\frac{4}{5}$; $b(C_3) = \\frac{0.4 + 0.2 + 1.0 + 1.2}{4} = \\frac{2.8}{4} = 0.7 = \\frac{7}{10}$. Then\n$$\ns(C_3) = \\frac{\\frac{7}{10} - \\frac{4}{5}}{\\max\\left\\{\\frac{4}{5}, \\frac{7}{10}\\right\\}} = \\frac{\\frac{7}{10} - \\frac{8}{10}}{\\frac{4}{5}} = \\frac{-\\frac{1}{10}}{\\frac{4}{5}} = -\\frac{1}{10}\\cdot \\frac{5}{4} = -\\frac{1}{8}.\n$$\n- $C_4 \\in \\mathrm{T2}$: $a(C_4) = d(C_4,C_3) = 0.8 = \\frac{4}{5}$; $b(C_4) = \\frac{1.2 + 1.0 + 0.2 + 0.4}{4} = \\frac{2.8}{4} = 0.7 = \\frac{7}{10}$. Thus $s(C_4) = -\\frac{1}{8}$.\n\nAverage silhouette width:\n$$\nA = \\frac{1}{6}\\left(-\\frac{1}{4} - \\frac{5}{14} - \\frac{5}{14} - \\frac{1}{4} - \\frac{1}{8} - \\frac{1}{8}\\right).\n$$\nGroup terms:\n$$\n-\\frac{1}{4} - \\frac{1}{4} = -\\frac{1}{2}, \\quad -\\frac{1}{8} - \\frac{1}{8} = -\\frac{1}{4}, \\quad -\\frac{5}{14} - \\frac{5}{14} = -\\frac{10}{14} = -\\frac{5}{7}.\n$$\nThus the sum is $-\\frac{1}{2} - \\frac{1}{4} - \\frac{5}{7}$. With common denominator $28$,\n$$\n-\\frac{14}{28}, \\quad -\\frac{7}{28}, \\quad -\\frac{20}{28},\n$$\nso the total is $-\\frac{41}{28}$ and\n$$\nA = \\frac{-\\frac{41}{28}}{6} = -\\frac{41}{168}.\n$$\n\nStep 3: Normalize and aggregate.\n- Normalize LISI by the theoretical maximum for $B=2$ batches:\n$$\n\\tilde{L} = \\frac{L}{2} = \\frac{\\frac{9}{5}}{2} = \\frac{9}{10}.\n$$\n- Normalize ASW from $[-1,1]$ to $[0,1]$:\n$$\n\\tilde{A} = \\frac{A + 1}{2} = \\frac{-\\frac{41}{168} + 1}{2} = \\frac{\\frac{127}{168}}{2} = \\frac{127}{336}.\n$$\n- Balanced integration score via geometric mean:\n$$\nS_B = \\sqrt{\\tilde{L}\\,\\tilde{A}} = \\sqrt{\\frac{9}{10} \\cdot \\frac{127}{336}} = \\sqrt{\\frac{1143}{3360}} = \\sqrt{\\frac{381}{1120}}.\n$$\n\nFor a numerical value rounded to four significant figures, evaluate $\\sqrt{\\frac{381}{1120}} \\approx 0.583248\\ldots$, which rounds to $0.5832$ to four significant figures.\n\nThis protocol is balanced because:\n- $\\tilde{L}$ increases when batches are better mixed locally, as captured by diversity of batch labels within neighborhoods.\n- $\\tilde{A}$ increases when biological types form more coherent structures relative to other types.\n- The geometric mean $\\sqrt{\\tilde{L}\\,\\tilde{A}}$ penalizes imbalance: if either component is low, the product decreases, ensuring neither property dominates the overall score.\n\nThus, the final balanced integration score for the given dataset is $S_B \\approx 0.5832$ (four significant figures).", "answer": "$$\\boxed{0.5832}$$", "id": "4381611"}, {"introduction": "Beyond aligning datasets, the true power of multi-omics integration lies in uncovering novel biological mechanisms, such as linking distal regulatory elements to their target genes. This hands-on exercise frames this challenge as a sparse regression problem, where the expression of a gene is predicted from the accessibility of nearby chromatin peaks. You will work with the Lasso ($L_1$ penalized) regression model, a powerful technique to select the most predictive regulatory elements from a large set of candidates, thereby generating testable hypotheses about gene regulatory networks [@problem_id:4381567].", "problem": "You are given a task rooted in precision medicine and genomic diagnostics that focuses on single-cell multi-omics integration. Consider modeling the normalized messenger ribonucleic acid (mRNA) expression of a single gene across a population of single cells as a linear function of the accessibility of its candidate regulatory peaks within a window of $100$ kilobases around the gene’s transcription start site. Let the feature matrix be denoted by $X \\in \\mathbb{R}^{n \\times p}$, where $n$ is the number of single cells and $p$ is the number of candidate regulatory peaks, and let the response vector be denoted by $y \\in \\mathbb{R}^{n}$. Your task is to implement a penalized linear model for predicting $y$ from $X$ using an $L_1$ regularization that encourages sparse selection of peaks, and to construct and justify the choice of a regularization path. The task must be framed and solved purely in mathematical and algorithmic terms, with no reliance on external data sources.\n\nStarting from foundational principles relevant to this domain, including the Central Dogma of Molecular Biology and the concept that chromatin accessibility at regulatory elements modulates gene transcription, formalize the problem of selecting a sparse set of regulatory peaks that explain the variation in $y$ from $X$. Express all mathematical entities using LaTeX. The solution must implement a convex optimization procedure that finds a sparse coefficient vector $w \\in \\mathbb{R}^{p}$, and must explore a sequence of regularization strengths that begins at a value that yields the all-zero solution and then decreases in a geometrically spaced path to capture progressively more complex models.\n\nYour program must perform the following:\n- Standardize the columns of $X$ to zero mean and unit variance and center $y$ to zero mean, ensuring that all features are comparably scaled and that any intercept is effectively removed.\n- Construct a regularization path as a geometrically spaced sequence of regularization values descending from a data-dependent maximum value to a specified fraction of this maximum.\n- For each regularization value in the path, solve the penalized regression via an algorithm that exploits the convexity of the objective and promotes sparsity in $w$.\n- Select the best regularization value along the path using a principled model selection criterion grounded in likelihood and complexity considerations, and return the indices of the peaks selected by the corresponding sparse solution.\n- Justify the choice of the regularization path in terms of optimization stability and interpretability for genomic diagnostics.\n\nTest Suite:\nYou must implement the program to run the following four deterministic test cases, each specified by fixed integers and real values. For each test case, the synthetic data generation protocol is as follows: draw peak distances $d_j$ uniformly over $[0,100000]$ base pairs, define a covariance matrix for the peaks $\\Sigma \\in \\mathbb{R}^{p \\times p}$ with entries $\\Sigma_{ij} = \\exp\\left(-\\frac{|d_i - d_j|}{\\ell}\\right) + \\delta_{ij}\\cdot 10^{-3}$, draw $X$ row-wise from a multivariate normal distribution with covariance $\\Sigma$, standardize the columns of $X$ to zero mean and unit variance, choose a sparse ground-truth coefficient vector $w^{\\star}$ with nonzero entries at specified indices and magnitudes, and set $y = X w^{\\star} + \\varepsilon$, where $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2 I_n)$. The variables $n$, $p$, $\\ell$, the seed, the nonzero indices of $w^{\\star}$, the corresponding magnitudes, and $\\sigma$ are specified below. All values must be treated as pure numbers without units in the algorithm; the mention of kilobases is contextual only, and no unit conversion is required. The regularization path should be constructed with the following parameters: number of points $K = 60$ and minimum ratio $\\alpha = 0.05$ of the smallest to largest regularization values.\n\n- Test Case $1$ (general case):\n  - Seed: $42$.\n  - $n = 300$, $p = 40$, $\\ell = 20000$.\n  - Nonzero indices of $w^{\\star}$: $\\{2, 7, 15, 21\\}$ with magnitudes $\\{1.2, -0.8, 1.5, 0.7\\}$.\n  - Noise standard deviation $\\sigma = 0.5$.\n\n- Test Case $2$ (boundary case: no signal):\n  - Seed: $43$.\n  - $n = 200$, $p = 30$, $\\ell = 25000$.\n  - Nonzero indices of $w^{\\star}$: empty set $\\{\\}$.\n  - Noise standard deviation $\\sigma = 1.0$.\n\n- Test Case $3$ (edge case: highly correlated peaks):\n  - Seed: $44$.\n  - $n = 150$, $p = 25$, $\\ell = 30000$.\n  - Force peaks at indices $5$ and $6$ to be highly correlated by setting their distances equal.\n  - Nonzero indices of $w^{\\star}$: $\\{5, 6\\}$ with magnitudes $\\{1.0, 1.0\\}$.\n  - Noise standard deviation $\\sigma = 0.3$.\n\n- Test Case $4$ (high-dimensional case: $p > n$):\n  - Seed: $45$.\n  - $n = 80$, $p = 120$, $\\ell = 18000$.\n  - Nonzero indices of $w^{\\star}$: $\\{10, 11, 27, 42, 86, 90\\}$ with magnitudes $\\{1.2, -1.0, 0.8, 1.4, -0.6, 1.1\\}$.\n  - Noise standard deviation $\\sigma = 0.7$.\n\nModel selection and final output:\n- For each test case, choose the regularization value along the path by minimizing a model selection criterion derived from the Gaussian likelihood penalized by the complexity of the model, where the complexity is quantified by the number of nonzero coefficients.\n- For the chosen model in each test case, return the sorted list of selected peak indices, where an index $j$ is considered selected if the corresponding coefficient $w_j$ is nonzero within a numerical tolerance.\n- Your program should produce a single line of output containing the results for the four test cases as a comma-separated list enclosed in square brackets, where each element is the inner list of selected indices for that test case (e.g., $[[i_1,i_2],[\\,],[j_1,j_2,j_3],[k_1]]$). No additional text should be printed.\n\nConstraints:\n- Implement everything from first principles using only algorithms consistent with convex optimization and sparse regularization, and ensure that the design is consistent with biological plausibility for the integration of single-cell ribonucleic acid sequencing and single-cell assay for transposase-accessible chromatin sequencing modalities.\n- Use deterministic random number generation with the specified seeds.\n- The final output must be a list of lists of integers, with exact formatting as described.", "solution": "The posed problem addresses a cornerstone of precision medicine and genomic diagnostics: deciphering the regulatory logic that governs gene expression. Specifically, we aim to identify which candidate regulatory elements, characterized by their chromatin accessibility, are responsible for modulating the expression of a particular gene. The problem is contextualized within single-cell multi-omics, where technologies like single-cell RNA-sequencing (scRNA-seq) measure messenger ribonucleic acid (mRNA) abundance ($y$), and single-cell Assay for Transposase-Accessible Chromatin using sequencing (scATAC-seq) quantifies chromatin accessibility ($X$) across thousands of individual cells.\n\nThe foundational biological principle is an extension of the Central Dogma: the rate of transcription of a gene into mRNA is controlled by regulatory proteins (transcription factors) that bind to specific DNA sequences (regulatory elements, such as enhancers and promoters). The accessibility of these DNA sequences, i.e., whether they are open or closed within the chromatin structure, is a prerequisite for transcription factor binding and, consequently, gene activation or repression. We are thus modeling gene expression as a function of the accessibility of nearby regulatory elements, often referred to as peaks in ATAC-seq data.\n\nGiven the high-dimensional nature of genomic data, where the number of candidate peaks ($p$) can be much larger than the number of observed cells ($n$), and the biological expectation that only a small subset of these peaks are truly functional for any given gene, a method that encourages sparse solutions is required. This leads to the formulation of the problem as a penalized linear regression using the Lasso (Least Absolute Shrinkage and Selection Operator).\n\nLet the centered mRNA expression vector be $y \\in \\mathbb{R}^{n}$ and the standardized peak accessibility matrix be $X \\in \\mathbb{R}^{n \\times p}$. We seek a sparse coefficient vector $w \\in \\mathbb{R}^{p}$, where each coefficient $w_j$ represents the influence of peak $j$ on gene expression. The sparse solution is found by solving the following convex optimization problem:\n$$\n\\hat{w}^{(\\lambda)} = \\arg\\min_{w \\in \\mathbb{R}^p} \\left\\{ \\frac{1}{2n} \\|y - Xw\\|_2^2 + \\lambda \\|w\\|_1 \\right\\}\n$$\nThe objective function consists of two parts: the residual sum of squares ($RSS$) term, $\\frac{1}{2n} \\|y - Xw\\|_2^2$, which ensures the model fits the data, and an $L_1$ penalty term, $\\lambda \\|w\\|_1 = \\lambda \\sum_{j=1}^{p} |w_j|$, which induces sparsity by shrinking some coefficients to exactly zero. The regularization parameter $\\lambda \\ge 0$ controls the trade-off between model fit and sparsity.\n\nPrior to solving, the data must be preprocessed. The response vector $y$ is centered to have a mean of zero. Each column of the feature matrix $X$ is standardized to have a mean of zero and a standard deviation of one. This standardization is critical, as it ensures that the penalty term $\\lambda$ is applied equitably to all coefficients, making them comparable regardless of the original scale of their corresponding accessibility measurements. This procedure also effectively removes the need for an explicit intercept term in the model.\n\nThe solution is found not for a single $\\lambda$, but over a regularization path, which is a sequence of $\\lambda$ values. This path is constructed to explore models ranging from the simplest (the null model with all coefficients being zero) to progressively more complex ones. A principled starting point for the path is $\\lambda_{max}$, the smallest value of $\\lambda$ for which the solution is guaranteed to be $w=0$. For a standardized matrix $X$, this value is given by:\n$$\n\\lambda_{max} = \\frac{1}{n} \\|X^T y\\|_{\\infty} = \\max_{j} \\left| \\frac{1}{n} \\sum_{i=1}^{n} x_{ij} y_i \\right|\n$$\nThe path then descends geometrically from $\\lambda_{max}$ to a minimum value $\\lambda_{min} = \\alpha \\cdot \\lambda_{max}$, where $\\alpha$ is a small ratio (e.g., $0.05$). The sequence of $K$ values is defined as:\n$$\n\\lambda_k = \\lambda_{max} \\cdot \\alpha^{k/(K-1)} \\quad \\text{for } k = 0, 1, \\dots, K-1\n$$\nThis logarithmic spacing allows for a dense exploration of models when coefficients are first entering the model and a sparser exploration for more complex models.\n\nFor each $\\lambda$ in the path, we solve the Lasso objective using a coordinate descent algorithm. This iterative method optimizes the objective function with respect to a single coefficient $w_j$ at a time, holding all other coefficients fixed. The update rule for each coefficient has a closed-form solution involving the soft-thresholding operator, $S_a(z) = \\text{sign}(z) \\max(|z| - a, 0)$. The update for $w_j$ is:\n$$\nw_j \\leftarrow S_{\\lambda}(\\rho_j)\n$$\nwhere $\\rho_j = \\frac{1}{n} \\sum_{i=1}^{n} x_{ij} (y_i - \\sum_{k \\neq j} x_{ik} w_k)$ is the simple regression coefficient of the partial residual onto the $j$-th column of $X$. The algorithm cycles through all coefficients until convergence. This method is computationally efficient, avoids matrix inversion, and is particularly well-suited for high-dimensional problems. Using the solution for a given $\\lambda$ as a \"warm start\" for the next, smaller $\\lambda$ significantly accelerates the computation along the entire path.\n\nFinally, to select the best model from the path, we employ a model selection criterion that balances goodness-of-fit with model complexity. The Bayesian Information Criterion (BIC) is an excellent choice for this task, as its penalty for model complexity is stronger than that of other criteria like AIC, making it more suitable for feature selection and the identification of a parsimonious, interpretable model. The BIC is calculated for each model $w^{(\\lambda_k)}$ along the path:\n$$\n\\text{BIC}_k = n \\ln\\left(\\frac{RSS_k}{n}\\right) + \\ln(n) \\cdot d_k\n$$\nwhere $RSS_k = \\|y - X w^{(\\lambda_k)}\\|_2^2$ is the residual sum of squares and $d_k = \\|w^{(\\lambda_k)}\\|_0$ is the number of non-zero coefficients (the model's effective degrees of freedom). The model corresponding to the minimum BIC value is chosen as the optimal one. The non-zero coefficients of this model identify the selected regulatory peaks, providing a sparse, data-driven hypothesis about the gene's regulatory architecture.", "answer": "[[2,7,15,21],[],[5,6],[10,11,27,42,86,90]]", "id": "4381567"}]}