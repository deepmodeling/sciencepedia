{"hands_on_practices": [{"introduction": "Before estimating a causal effect, a critical first step in any Mendelian Randomization (MR) study is to confirm that the chosen genetic instruments are sufficiently strong. The \"relevance\" assumption requires that instruments are robustly associated with the exposure, a property quantified by the first-stage $F$-statistic. This practice [@problem_id:4583111] will guide you through the fundamental calculation of per-variant and aggregate instrument strength from summary statistics, an essential skill for validating an instrument set and avoiding weak instrument bias.", "problem": "A Mendelian randomization (MR) analysis in omics seeks to estimate the causal effect of an omics exposure (for example, the normalized expression level of a gene) on a downstream phenotype using genetic variants as instruments. Instrument relevance is assessed from the first-stage regression of the exposure on each genotype. Use the following summary associations for genotype-to-exposure ($G \\!-\\! X$) effects, assumed to be estimated by ordinary least squares in a single large sample under independence of instruments (no linkage disequilibrium) and homoscedastic residuals:\n\n- Variant $1$: $\\hat{\\beta}_{XG,1} = 0.06$, $\\operatorname{SE}(\\hat{\\beta}_{XG,1}) = 0.012$.\n- Variant $2$: $\\hat{\\beta}_{XG,2} = 0.04$, $\\operatorname{SE}(\\hat{\\beta}_{XG,2}) = 0.010$.\n- Variant $3$: $\\hat{\\beta}_{XG,3} = 0.03$, $\\operatorname{SE}(\\hat{\\beta}_{XG,3}) = 0.015$.\n- Variant $4$: $\\hat{\\beta}_{XG,4} = 0.09$, $\\operatorname{SE}(\\hat{\\beta}_{XG,4}) = 0.008$.\n- Variant $5$: $\\hat{\\beta}_{XG,5} = 0.05$, $\\operatorname{SE}(\\hat{\\beta}_{XG,5}) = 0.011$.\n\nStarting from fundamental statistical definitions for linear regression and classical test statistics, compute the per-variant first-stage $F$-statistics for instrument relevance. Then, to assess the overall instrument set strength in a way consistent with generalized least squares across independent instruments, aggregate these per-variant strengths using a precision-weighted approach where each variantâ€™s contribution is proportional to the inverse of the variance of its exposure association. Provide the final instrument set strength as a single scalar equal to the inverse-variance weighted mean of the per-variant first-stage $F$-statistics. Round your answer to four significant figures. No units are required for the final scalar.", "solution": "The problem requires the calculation of an aggregated instrument strength for a set of genetic variants used in a Mendelian randomization (MR) analysis. This involves two main steps: first, computing the per-variant first-stage $F$-statistic for instrument relevance, and second, aggregating these statistics using a specific precision-weighted averaging scheme.\n\n### Step 1: Per-Variant First-Stage $F$-Statistics\n\nThe first-stage of an MR analysis regresses the exposure, $X$, on a genetic instrument, $G_j$. For a single instrument $j$, the simple linear regression model is:\n$$\nX = \\alpha_j + \\beta_{XG,j} G_j + \\epsilon_j\n$$\nwhere $\\beta_{XG,j}$ is the coefficient representing the association between the instrument $G_j$ and the exposure $X$. The problem provides the ordinary least squares (OLS) estimates of these coefficients, $\\hat{\\beta}_{XG,j}$, and their standard errors, $\\operatorname{SE}(\\hat{\\beta}_{XG,j})$.\n\nThe relevance of an instrument is assessed by testing the null hypothesis $H_0: \\beta_{XG,j} = 0$. In large samples, the Wald test statistic for this hypothesis is the $t$-statistic, calculated as the ratio of the estimate to its standard error:\n$$\nt_j = \\frac{\\hat{\\beta}_{XG,j}}{\\operatorname{SE}(\\hat{\\beta}_{XG,j})}\n$$\nFor a simple linear regression with a single predictor, the $F$-statistic for the significance of the regression is the square of the corresponding $t$-statistic:\n$$\nF_j = t_j^2 = \\left( \\frac{\\hat{\\beta}_{XG,j}}{\\operatorname{SE}(\\hat{\\beta}_{XG,j})} \\right)^2\n$$\nWe compute this value for each of the $5$ variants provided.\n\n- **Variant 1:**\n  $\\hat{\\beta}_{XG,1} = 0.06$, $\\operatorname{SE}(\\hat{\\beta}_{XG,1}) = 0.012$\n  $$ F_1 = \\left( \\frac{0.06}{0.012} \\right)^2 = 5^2 = 25 $$\n\n- **Variant 2:**\n  $\\hat{\\beta}_{XG,2} = 0.04$, $\\operatorname{SE}(\\hat{\\beta}_{XG,2}) = 0.010$\n  $$ F_2 = \\left( \\frac{0.04}{0.010} \\right)^2 = 4^2 = 16 $$\n\n- **Variant 3:**\n  $\\hat{\\beta}_{XG,3} = 0.03$, $\\operatorname{SE}(\\hat{\\beta}_{XG,3}) = 0.015$\n  $$ F_3 = \\left( \\frac{0.03}{0.015} \\right)^2 = 2^2 = 4 $$\n\n- **Variant 4:**\n  $\\hat{\\beta}_{XG,4} = 0.09$, $\\operatorname{SE}(\\hat{\\beta}_{XG,4}) = 0.008$\n  $$ F_4 = \\left( \\frac{0.09}{0.008} \\right)^2 = (11.25)^2 = 126.5625 $$\n\n- **Variant 5:**\n  $\\hat{\\beta}_{XG,5} = 0.05$, $\\operatorname{SE}(\\hat{\\beta}_{XG,5}) = 0.011$\n  $$ F_5 = \\left( \\frac{0.05}{0.011} \\right)^2 \\approx (4.5454...)^2 \\approx 20.661157 $$\n\n### Step 2: Aggregated Instrument Strength\n\nThe problem specifies that the overall instrument set strength should be calculated as the inverse-variance weighted mean of the per-variant first-stage $F$-statistics. The weight for each variant's contribution is proportional to its precision, which is the inverse of the variance of its exposure association estimate.\n\nLet $F_j$ be the $F$-statistic for variant $j$. The weight $w_j$ is given by:\n$$\nw_j = \\frac{1}{\\operatorname{Var}(\\hat{\\beta}_{XG,j})} = \\frac{1}{(\\operatorname{SE}(\\hat{\\beta}_{XG,j}))^2}\n$$\nThe inverse-variance weighted mean of the $F$-statistics, denoted $\\bar{F}_{IVW}$, is then:\n$$\n\\bar{F}_{IVW} = \\frac{\\sum_{j=1}^{5} w_j F_j}{\\sum_{j=1}^{5} w_j}\n$$\nSubstituting the expressions for $w_j$ and $F_j$:\n$$\n\\bar{F}_{IVW} = \\frac{\\sum_{j=1}^{5} \\frac{1}{(\\operatorname{SE}(\\hat{\\beta}_{XG,j}))^2} \\left( \\frac{\\hat{\\beta}_{XG,j}}{\\operatorname{SE}(\\hat{\\beta}_{XG,j})} \\right)^2}{\\sum_{j=1}^{5} \\frac{1}{(\\operatorname{SE}(\\hat{\\beta}_{XG,j}))^2}} = \\frac{\\sum_{j=1}^{5} \\frac{\\hat{\\beta}_{XG,j}^2}{(\\operatorname{SE}(\\hat{\\beta}_{XG,j}))^4}}{\\sum_{j=1}^{5} \\frac{1}{(\\operatorname{SE}(\\hat{\\beta}_{XG,j}))^2}}\n$$\nNow, we calculate the numerator and denominator separately.\n\n**Denominator (Sum of weights):**\n$$\n\\sum_{j=1}^{5} w_j = \\frac{1}{(0.012)^2} + \\frac{1}{(0.010)^2} + \\frac{1}{(0.015)^2} + \\frac{1}{(0.008)^2} + \\frac{1}{(0.011)^2}\n$$\n$$\n\\sum_{j=1}^{5} w_j = \\frac{1}{0.000144} + \\frac{1}{0.0001} + \\frac{1}{0.000225} + \\frac{1}{0.000064} + \\frac{1}{0.000121}\n$$\n$$\n\\sum_{j=1}^{5} w_j \\approx 6944.4444 + 10000 + 4444.4444 + 15625 + 8264.4628 \\approx 45278.3517\n$$\n\n**Numerator (Sum of weighted F-statistics):**\n$$\n\\sum_{j=1}^{5} w_j F_j = \\frac{25}{(0.012)^2} + \\frac{16}{(0.010)^2} + \\frac{4}{(0.015)^2} + \\frac{126.5625}{(0.008)^2} + \\frac{(0.05/0.011)^2}{(0.011)^2}\n$$\n$$\n\\sum_{j=1}^{5} w_j F_j \\approx 173611.1111 + 160000 + 17777.7778 + 1977539.0625 + 170756.0959\n$$\n$$\n\\sum_{j=1}^{5} w_j F_j \\approx 2499684.0473\n$$\n\n**Final Calculation:**\n$$\n\\bar{F}_{IVW} = \\frac{2499684.0473}{45278.3517} \\approx 55.20667\n$$\nThe problem requires rounding the final answer to four significant figures.\n$$\n\\bar{F}_{IVW} \\approx 55.21\n$$", "answer": "$$\\boxed{55.21}$$", "id": "4583111"}, {"introduction": "Two-sample MR analyses synthesize data from separate genome-wide association studies (GWAS) for the exposure and outcome. A crucial bioinformatic challenge is to ensure that the effect of a given single nucleotide polymorphism (SNP) is defined with respect to the same allele in both datasets. This exercise [@problem_id:4583355] provides hands-on practice in the vital data-cleaning step of allele harmonization, including the logic for handling ambiguous palindromic SNPs, to prevent spurious findings arising from misaligned data.", "problem": "You are given pairs of Single Nucleotide Polymorphism (SNP) summary-statistic datasets representing an exposure and an outcome for Mendelian Randomization (MR). Each dataset for a SNP comprises: SNP identifier, effect allele, non-effect allele, effect size, and optionally the Effect Allele Frequency (EAF). Your task is to implement allele harmonization and palindromic SNP exclusion using first principles of nucleotide complementarity and frequency-based ambiguity resolution.\n\nFundamental base:\n- A nucleotide complement mapping $c(\\cdot)$ is defined by $c(A)=T$, $c(T)=A$, $c(C)=G$, $c(G)=C$.\n- Allele orientation is determined with respect to the effect allele. Reversing which allele is designated as the effect allele multiplies the reported effect size by $-1$ and replaces an effect allele frequency $f$ with $1-f$.\n- A SNP allele pair is palindromic if its unordered set is $\\{A,T\\}$ or $\\{C,G\\}$, which creates strand ambiguity unless resolved by Effect Allele Frequency (EAF) information.\n- Effect Allele Frequency (EAF) determines the frequency of the effect allele; the minor allele frequency is $\\min\\{f,1-f\\}$.\n\nDefinitions to apply:\n- A SNP is harmonized by transforming the outcome alleles to match the exposure alleles using only the following operations in this order: exact allele match, allele reversal, strand complement, and complemented reversal. If outcome alleles cannot be matched to exposure alleles under these operations, the SNP is excluded as incompatible.\n- If the exposure SNP allele pair is palindromic, then the SNP must be excluded unless EAFs are present and permit unambiguous orientation. Use the following rule: with tolerance $\\epsilon = 0.05$ and ambiguity threshold $\\tau = 0.42$, keep a palindromic SNP only if both exposure and outcome have EAFs, both minor allele frequencies are $\\le \\tau$, and the aligned outcome EAF equals either the exposure EAF or its complement within $\\epsilon$ after applying the harmonization orientation to the outcome EAF. Otherwise, exclude the SNP as palindromic ambiguous.\n- Harmonization must align the outcome to the exposure so that the effect allele refers to the same biological allele in both. If reversal is required, multiply the outcome effect size by $-1$; if strand complementation is required, only the allele labels change, while the effect size is unchanged except when reversal is also applied. When reversal is applied, replace the outcome EAF $f$ by $1-f$ for EAF consistency checks.\n\nObjective:\n- For each test case, after harmonization and exclusion steps, compute:\n  1. The number of retained harmonized SNPs $n_{\\text{keep}}$ (an integer).\n  2. The number of excluded palindromic SNPs $n_{\\text{pal\\_excluded}}$ (an integer).\n  3. A checksum defined as $\\sum_i \\beta_{\\text{exp},i}\\cdot \\tilde{\\beta}_{\\text{out},i}$ over retained SNPs, where $\\tilde{\\beta}_{\\text{out},i}$ is the harmonized outcome effect size aligned to the exposure effect allele. Report the checksum as a float rounded to $6$ decimal places.\n\nInput for implementation is embedded in the program as three test cases. Each test case consists of two lists: exposure and outcome summary data with records of the form [snp, a1, a2, beta, eaf], where a1 is the effect allele, a2 is the non-effect allele, beta is the effect size, and eaf is the effect allele frequency (which may be null). All allele symbols are from the set $\\{A, C, G, T\\}$.\n\nTest suite:\n- Test case $1$:\n  - Exposure:\n    - [rs1, A, G, $0.2$, $0.20$]\n    - [rs2, C, T, $-0.3$, $0.35$]\n    - [rs3, A, T, $0.1$, $0.49$]\n    - [rs4, C, G, $0.05$, $0.10$]\n    - [rs5, A, C, $0.4$, $0.60$]\n  - Outcome:\n    - [rs1, A, G, $0.1$, $0.19$]\n    - [rs2, T, C, $0.5$, $0.65$]\n    - [rs3, T, A, $0.2$, $0.51$]\n    - [rs4, G, C, $-0.07$, $0.90$]\n    - [rs5, T, G, $0.3$, $0.40$]\n- Test case $2$:\n  - Exposure:\n    - [rs10, G, T, $0.2$, $0.58$]\n    - [rs11, A, T, $-0.12$, $0.20$]\n    - [rs12, C, G, $0.05$, null]\n    - [rs13, A, C, $0.3$, $0.45$]\n    - [rs14, A, G, $-0.25$, $0.33$]\n  - Outcome:\n    - [rs10, C, A, $0.15$, $0.42$]\n    - [rs11, T, A, $0.3$, $0.80$]\n    - [rs12, G, C, $0.02$, $0.90$]\n    - [rs13, A, G, $-0.2$, $0.45$]\n    - [rs14, C, T, $0.5$, $0.67$]\n- Test case $3$:\n  - Exposure:\n    - [rs20, A, T, $0.5$, $0.42$]\n    - [rs21, C, G, $-0.2$, $0.58$]\n    - [rs22, A, C, $0.1$, $0.30$]\n    - [rs23, G, T, $-0.05$, $0.51$]\n    - [rs24, T, A, $0.2$, $0.50$]\n  - Outcome:\n    - [rs20, T, A, $-0.1$, $0.58$]\n    - [rs21, C, G, $0.4$, $0.58$]\n    - [rs22, T, G, $0.2$, $0.70$]\n    - [rs23, A, C, $0.06$, $0.49$]\n    - [rs24, A, T, $0.1$, $0.50$]\n\nEdge cases covered include: exact matches, allele reversals, strand complements, complemented reversals, palindromic SNPs near $0.5$ EAF, palindromic SNPs resolvable by EAF, missing EAF leading to exclusion, and incompatible alleles that cannot be matched.\n\nYour program must:\n- Implement harmonization and palindromic exclusion according to the definitions above using $\\epsilon = 0.05$ and $\\tau = 0.42$.\n- For each test case, compute $n_{\\text{keep}}$, $n_{\\text{pal\\_excluded}}$, and the checksum rounded to $6$ decimals.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a list in the form [$n_{\\text{keep}}$, $n_{\\text{pal\\_excluded}}$, checksum]. For example: \"[[x1,y1,z1],[x2,y2,z2],[x3,y3,z3]]\".", "solution": "The user-provided problem has been assessed and is determined to be **valid**. It is a scientifically grounded, well-posed, and objective problem statement rooted in the standard bioinformatic procedures of Mendelian Randomization (MR) analysis. The problem provides a complete set of definitions, data, and constraints, allowing for the development of a unique, verifiable solution. The logic for allele harmonization and the handling of palindromic Single Nucleotide Polymorphisms (SNPs) are consistent with established methods in genetic epidemiology.\n\n### Principle-Based Algorithmic Design\n\nThe core task is to harmonize summary statistics from two studies (exposure and outcome) on a per-SNP basis, ensuring that the effect allele and its corresponding effect size ($\\beta$) refer to the same biological variant. This process involves aligning allele labels, handling strand orientation, and applying specific rules to exclude SNPs where orientation is ambiguous.\n\n#### 1. Fundamental Genetic Definitions\n\nThe algorithm relies on the Watson-Crick pairing of nucleotide bases. We define a complement function, $c(\\cdot)$, such that:\n$$ c(A) = T, \\quad c(T) = A, \\quad c(C) = G, \\quad c(G) = C $$\nA SNP is defined by a pair of alleles, for instance, $(A, G)$. In summary statistics, one allele is designated the effect allele ($a_1$) and the other the non-effect allele ($a_2$). The effect size, $\\beta$, represents the change in a trait associated with each copy of $a_1$. Reversing the designation, such that $a_2$ becomes the effect allele, inverts the sign of the effect, so $\\beta$ becomes $-\\beta$. Concurrently, the Effect Allele Frequency (EAF), $f$, which is the frequency of $a_1$, is transformed to $1-f$.\n\nA SNP is classified as **palindromic** if its alleles are complements of each other. The unordered allele set is either $\\{A, T\\}$ or $\\{C, G\\}$. This creates an ambiguity because, for example, on a forward strand an $A/T$ SNP has a complementary representation of $T/A$ on the reverse strand. Without further information, it is impossible to know if an observed $A$ allele in one dataset corresponds to the $A$ or the $T$ allele in another.\n\n#### 2. Harmonization of Non-Palindromic SNPs\n\nFor a given SNP, we align the outcome data to the exposure data. Let the exposure SNP have alleles $(a_{1,exp}, a_{2,exp})$ and the outcome SNP have alleles $(a_{1,out}, a_{2,out})$. The goal is to find a transformation that maps $(a_{1,out}, a_{2,out})$ to $(a_{1,exp}, a_{2,exp})$ and apply the corresponding change to the outcome effect size, $\\beta_{out}$. The following operations are assessed in a specific order:\n\n1.  **Identity Match**: If $a_{1,out} = a_{1,exp}$ and $a_{2,out} = a_{2,exp}$. The data are already aligned. The harmonized outcome effect is $\\tilde{\\beta}_{out} = \\beta_{out}$.\n2.  **Allele Reversal**: If $a_{1,out} = a_{2,exp}$ and $a_{2,out} = a_{1,exp}$. The outcome study chose the other allele as the effect allele. The effect is reversed: $\\tilde{\\beta}_{out} = -\\beta_{out}$.\n3.  **Strand Complement**: If $c(a_{1,out}) = a_{1,exp}$ and $c(a_{2,out}) = a_{2,exp}$. The outcome data were reported for the opposite strand but with the same reference allele orientation. The effect size is not altered by a strand flip alone: $\\tilde{\\beta}_{out} = \\beta_{out}$.\n4.  **Complemented Reversal**: If $c(a_{1,out}) = a_{2,exp}$ and $c(a_{2,out}) = a_{1,exp}$. The outcome data are on the opposite strand and used the other allele as the effect allele. Both a strand complement and an allele reversal are applied. The effect is reversed: $\\tilde{\\beta}_{out} = -\\beta_{out}$.\n\nIf none of these conditions are met, the alleles are incompatible (e.g., exposure $A/C$ vs. outcome $A/G$), and the SNP is excluded from the analysis.\n\n#### 3. Harmonization and Exclusion of Palindromic SNPs\n\nPalindromic SNPs require a special procedure due to their inherent strand ambiguity. This ambiguity can sometimes be resolved using EAF data. A palindromic SNP is retained only if it passes a three-part test:\n\n1.  **EAF Availability**: Both the exposure and outcome datasets must provide an EAF for the SNP. Let these be $f_{exp}$ and $f_{out}$. If either is missing, the ambiguity cannot be resolved, and the SNP is excluded. This adds to the count $n_{\\text{pal\\_excluded}}$.\n\n2.  **Frequency Ambiguity Threshold**: The EAF must be sufficiently far from $0.5$ to be informative. If an EAF is, for example, $0.5$, then its complement, $1-f$, is also $0.5$, providing no information for disambiguation. This is formalized by requiring the minor allele frequency (MAF), $\\min(f, 1-f)$, to be below a certain threshold, $\\tau$. The condition is that both `maf_exp` and `maf_out` must be less than or equal to the specified threshold $\\tau = 0.42$. If `maf_exp` $> \\tau$ or `maf_out` $> \\tau$, the SNP is excluded and contributes to $n_{\\text{pal\\_excluded}}$.\n\n3.  **EAF-based Disambiguation**: If the above checks pass, the EAFs are used to infer the correct orientation. Two scenarios are possible:\n    *   The effect alleles are the same (forward alignment). This is likely if $f_{out}$ is close to $f_{exp}$.\n    *   The effect allele in the outcome corresponds to the non-effect allele in the exposure (reverse alignment). This is likely if $f_{out}$ is close to $1-f_{exp}$, which is equivalent to $1-f_{out}$ being close to $f_{exp}$.\n\n    We formalize this using the tolerance $\\epsilon = 0.05$:\n    *   Let `forward_match` be true if $|\\,f_{out} - f_{exp}| \\le \\epsilon$.\n    *   Let `reverse_match` be true if $|\\,(1-f_{out}) - f_{exp}| \\le \\epsilon$.\n\n    If exactly one of these conditions is true (`forward_match` XOR `reverse_match`), the orientation is unambiguous.\n    *   If `forward_match` is true, no effect reversal is needed ($\\tilde{\\beta}_{out} = \\beta_{out}$).\n    *   If `reverse_match` is true, an effect reversal is required ($\\tilde{\\beta}_{out} = -\\beta_{out}$).\n\n    If both or neither condition is true, the EAFs are not informative enough to resolve the ambiguity. The SNP is excluded and adds to $n_{\\text{pal\\_excluded}}$.\n\n#### 4. Final Computations\n\nAfter processing all SNPs for a given exposure-outcome pair, the final metrics are calculated:\n1.  $n_{\\text{keep}}$: The total count of SNPs that were successfully harmonized and retained.\n2.  $n_{\\text{pal\\_excluded}}$: The total count of SNPs that were identified as palindromic and subsequently excluded due to ambiguity.\n3.  Checksum: The sum of products of the exposure effect size and the harmonized outcome effect size for all retained SNPs, $\\sum_i \\beta_{\\text{exp},i} \\cdot \\tilde{\\beta}_{\\text{out},i}$. This value is reported rounded to $6$ decimal places.\n\nThis systematic procedure ensures that only high-confidence, correctly aligned SNPs are used in downstream MR analyses, preventing spurious causal inferences that can arise from misaligned alleles.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the Mendelian Randomization harmonization analysis on the test suite.\n    \"\"\"\n    \n    test_cases = [\n        # Test case 1\n        (\n            [\n                ['rs1', 'A', 'G', 0.2, 0.20],\n                ['rs2', 'C', 'T', -0.3, 0.35],\n                ['rs3', 'A', 'T', 0.1, 0.49],\n                ['rs4', 'C', 'G', 0.05, 0.10],\n                ['rs5', 'A', 'C', 0.4, 0.60]\n            ],\n            [\n                ['rs1', 'A', 'G', 0.1, 0.19],\n                ['rs2', 'T', 'C', 0.5, 0.65],\n                ['rs3', 'T', 'A', 0.2, 0.51],\n                ['rs4', 'G', 'C', -0.07, 0.90],\n                ['rs5', 'T', 'G', 0.3, 0.40]\n            ]\n        ),\n        # Test case 2\n        (\n            [\n                ['rs10', 'G', 'T', 0.2, 0.58],\n                ['rs11', 'A', 'T', -0.12, 0.20],\n                ['rs12', 'C', 'G', 0.05, None],\n                ['rs13', 'A', 'C', 0.3, 0.45],\n                ['rs14', 'A', 'G', -0.25, 0.33]\n            ],\n            [\n                ['rs10', 'C', 'A', 0.15, 0.42],\n                ['rs11', 'T', 'A', 0.3, 0.80],\n                ['rs12', 'G', 'C', 0.02, 0.90],\n                ['rs13', 'A', 'G', -0.2, 0.45],\n                ['rs14', 'C', 'T', 0.5, 0.67]\n            ]\n        ),\n        # Test case 3\n        (\n            [\n                ['rs20', 'A', 'T', 0.5, 0.42],\n                ['rs21', 'C', 'G', -0.2, 0.58],\n                ['rs22', 'A', 'C', 0.1, 0.30],\n                ['rs23', 'G', 'T', -0.05, 0.51],\n                ['rs24', 'T', 'A', 0.2, 0.50]\n            ],\n            [\n                ['rs20', 'T', 'A', -0.1, 0.58],\n                ['rs21', 'C', 'G', 0.4, 0.58],\n                ['rs22', 'T', 'G', 0.2, 0.70],\n                ['rs23', 'A', 'C', 0.06, 0.49],\n                ['rs24', 'A', 'T', 0.1, 0.50]\n            ]\n        )\n    ]\n\n    results = []\n    for exp_data, out_data in test_cases:\n        results.append(process_case(exp_data, out_data))\n\n    # Format the final output as a single-line string\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef process_case(exposure_data, outcome_data):\n    \"\"\"\n    Processes a single test case for SNP harmonization.\n    \n    Args:\n        exposure_data (list): List of exposure SNP records.\n        outcome_data (list): List of outcome SNP records.\n        \n    Returns:\n        list: A list containing [n_keep, n_pal_excluded, checksum].\n    \"\"\"\n    EPSILON = 0.05\n    TAU = 0.42\n    COMPLEMENT = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n    \n    n_keep = 0\n    n_pal_excluded = 0\n    checksum = 0.0\n\n    # Create a dictionary for outcome data for efficient lookup\n    outcome_map = {\n        rec[0]: {'id': rec[0], 'a1': rec[1], 'a2': rec[2], 'beta': rec[3], 'eaf': rec[4]}\n        for rec in outcome_data\n    }\n\n    for rec in exposure_data:\n        exp_snp = {'id': rec[0], 'a1': rec[1], 'a2': rec[2], 'beta': rec[3], 'eaf': rec[4]}\n        out_snp = outcome_map.get(exp_snp['id'])\n\n        if not out_snp:\n            continue\n\n        a1e, a2e = exp_snp['a1'], exp_snp['a2']\n        a1o, a2o = out_snp['a1'], out_snp['a2']\n        b_e, b_o = exp_snp['beta'], out_snp['beta']\n        f_e, f_o = exp_snp['eaf'], out_snp['eaf']\n\n        # Determine if the exposure SNP is palindromic\n        is_pal = {a1e, a2e} in [{'A', 'T'}, {'C', 'G'}]\n\n        harmonized_beta_out = None\n        \n        if is_pal:\n            # Palindromic SNP handling\n            # 1. EAFs must be present\n            if f_e is None or f_o is None:\n                n_pal_excluded += 1\n                continue\n            \n            # 2. Minor Allele Frequencies must be = tau\n            maf_e = f_e if f_e = 0.5 else 1.0 - f_e\n            maf_o = f_o if f_o = 0.5 else 1.0 - f_o\n            if maf_e > TAU or maf_o > TAU:\n                n_pal_excluded += 1\n                continue\n\n            # 3. EAF-based disambiguation\n            forward_match = abs(f_o - f_e) = EPSILON\n            reverse_match = abs((1.0 - f_o) - f_e) = EPSILON\n\n            if forward_match and not reverse_match:\n                harmonized_beta_out = b_o\n            elif reverse_match and not forward_match:\n                harmonized_beta_out = -b_o\n            else: # Ambiguous (both true or both false)\n                n_pal_excluded += 1\n                continue\n        else:\n            # Non-palindromic SNP harmonization\n            c_a1o, c_a2o = COMPLEMENT[a1o], COMPLEMENT[a2o]\n            \n            if a1e == a1o and a2e == a2o: # Identity\n                harmonized_beta_out = b_o\n            elif a1e == a2o and a2e == a1o: # Reversal\n                harmonized_beta_out = -b_o\n            elif a1e == c_a1o and a2e == c_a2o: # Complement\n                harmonized_beta_out = b_o\n            elif a1e == c_a2o and a2e == c_a1o: # Complemented Reversal\n                harmonized_beta_out = -b_o\n            else: # Incompatible\n                continue\n        \n        # If harmonization was successful\n        if harmonized_beta_out is not None:\n            n_keep += 1\n            checksum += b_e * harmonized_beta_out\n            \n    return [n_keep, n_pal_excluded, round(checksum, 6)]\n\n# Run the solver\nsolve()\n```", "id": "4583355"}, {"introduction": "A primary threat to the validity of an MR study is horizontal pleiotropy, where a genetic instrument affects the outcome through a pathway independent of the exposure. While the standard Inverse-Variance Weighted (IVW) method is efficient, it is sensitive to such pleiotropy. This practice [@problem_id:4583451] introduces robust MR methods like the weighted median and weighted mode, which provide more reliable estimates when some instruments are invalid. By calculating and comparing these different estimates, you will learn to perform sensitivity analyses to probe the robustness of your causal conclusions.", "problem": "A consortium investigates the causal effect of a circulating metabolite, denoted by $X$, on a binary disease outcome, denoted by $Y$, using Mendelian randomization (MR). Seven independent genetic variants (single-nucleotide polymorphisms, SNPs) serve as instruments, with two-sample summary association estimates from genome-wide association studies (GWAS). For each SNP $i \\in \\{1,\\dots,7\\}$, you are given the association with the exposure $X$ as $\\beta_{X,i}$, the association with the outcome $Y$ as $\\beta_{Y,i}$, and the standard error of the outcome association $\\sigma_{Y,i}$. The exposure associations are from a very large sample such that the no-measurement-error assumption for $\\beta_{X,i}$ is reasonable.\n\nData:\n- SNP $1$: $\\beta_{X,1} = 0.10$, $\\beta_{Y,1} = 0.052$, $\\sigma_{Y,1} = 0.010$.\n- SNP $2$: $\\beta_{X,2} = 0.12$, $\\beta_{Y,2} = 0.060$, $\\sigma_{Y,2} = 0.012$.\n- SNP $3$: $\\beta_{X,3} = 0.08$, $\\beta_{Y,3} = 0.040$, $\\sigma_{Y,3} = 0.010$.\n- SNP $4$: $\\beta_{X,4} = 0.11$, $\\beta_{Y,4} = 0.0572$, $\\sigma_{Y,4} = 0.011$.\n- SNP $5$: $\\beta_{X,5} = 0.09$, $\\beta_{Y,5} = 0.045$, $\\sigma_{Y,5} = 0.009$.\n- SNP $6$: $\\beta_{X,6} = 0.10$, $\\beta_{Y,6} = 0.130$, $\\sigma_{Y,6} = 0.010$.\n- SNP $7$: $\\beta_{X,7} = 0.13$, $\\beta_{Y,7} = 0.065$, $\\sigma_{Y,7} = 0.013$.\n\nStarting from first principles of instrumental variables and Mendelian randomization:\n1. Using the instrumental variable ratio logic for linear associations under no horizontal pleiotropy and the no-measurement-error assumption for $\\beta_{X,i}$, define the per-variant Wald ratio $r_i$ and derive its approximate variance by a first-order delta method. Use this to construct inverse-variance weights $w_i$ for each instrument.\n2. Using a fixed-effect inverse-variance weighted (IVW) model with a zero intercept (i.e., constraining the pleiotropy intercept to zero), compute the pooled causal effect estimate $\\hat{\\theta}_{\\mathrm{IVW}}$ from the set $\\{r_i, w_i\\}_{i=1}^{7}$.\n3. Compute the weighted median estimator $\\hat{\\theta}_{\\mathrm{WM}}$ as the weighted median of $\\{r_i\\}$ with weights $\\{w_i\\}$.\n4. Compute the weighted mode estimator $\\hat{\\theta}_{\\mathrm{WMode}}$ in the zero-bandwidth limit, defined here as the value of $r_i$ that maximizes the total weight aggregated over instruments sharing exactly the same $r$ value. If there is a tie, choose the smaller value.\n\nBriefly explain, in your working, what any discrepancy among $\\hat{\\theta}_{\\mathrm{IVW}}$, $\\hat{\\theta}_{\\mathrm{WM}}$, and $\\hat{\\theta}_{\\mathrm{WMode}}$ implies about instrument validity and horizontal pleiotropy.\n\nReport your three numerical estimates in a single row matrix in the order $[\\hat{\\theta}_{\\mathrm{IVW}}, \\hat{\\theta}_{\\mathrm{WM}}, \\hat{\\theta}_{\\mathrm{WMode}}]$, with each entry rounded to four significant figures. Express the final answer as a pure number with no units.", "solution": "The problem is evaluated to be scientifically sound, well-posed, and objective. It presents a standard set of calculations in the field of Mendelian randomization using valid assumptions and clearly defined estimators. All necessary data are provided. We proceed with the solution.\n\nThe core principle of Mendelian randomization (MR) is to use genetic variants as instrumental variables (IVs) to infer the causal effect of an exposure ($X$) on an outcome ($Y$). Let $\\theta$ be the true causal effect. Under the IV assumptions and assuming linear relationships, the true association of a genetic instrument $i$ with the outcome, $\\beta_{Y,i}$, is proportional to its association with the exposure, $\\beta_{X,i}$, such that $\\beta_{Y,i} = \\theta \\beta_{X,i}$. This holds if the instrument has no direct effect on the outcome that bypasses the exposure, a condition known as the absence of horizontal pleiotropy.\n\n**1. Wald Ratio, Variance, and Inverse-Variance Weights**\n\nFor a single instrument $i$, the ratio of its estimated association with the outcome ($\\beta_{Y,i}$) to its estimated association with the exposure ($\\beta_{X,i}$) provides an estimate of the causal effect. This is the Wald ratio, $r_i$.\n$$\nr_i = \\frac{\\beta_{Y,i}}{\\beta_{X,i}}\n$$\nTo determine the variance of this ratio, $\\operatorname{Var}(r_i)$, we apply the delta method. However, the problem specifies the \"no-measurement-error\" (NOME) assumption for the exposure associations, $\\beta_{X,i}$. This implies that $\\operatorname{Var}(\\beta_{X,i}) \\approx 0$, and $\\beta_{X,i}$ can be treated as a constant. Under this simplifying assumption, the variance of $r_i$ is derived from the variance of $\\beta_{Y,i}$ using standard variance propagation rules:\n$$\n\\operatorname{Var}(r_i) = \\operatorname{Var}\\left(\\frac{\\beta_{Y,i}}{\\beta_{X,i}}\\right) = \\frac{1}{\\beta_{X,i}^2} \\operatorname{Var}(\\beta_{Y,i})\n$$\nWe are given the standard error of the outcome association, $\\sigma_{Y,i}$, where $\\operatorname{Var}(\\beta_{Y,i}) = \\sigma_{Y,i}^2$. Thus, the variance of the Wald ratio is:\n$$\n\\operatorname{Var}(r_i) = \\frac{\\sigma_{Y,i}^2}{\\beta_{X,i}^2}\n$$\nThe inverse-variance weight, $w_i$, for each instrument's ratio estimate is the reciprocal of its variance:\n$$\nw_i = \\frac{1}{\\operatorname{Var}(r_i)} = \\frac{\\beta_{X,i}^2}{\\sigma_{Y,i}^2}\n$$\nWe now calculate $r_i$ and $w_i$ for each of the $7$ SNPs.\n\n- SNP $1$: $r_1 = \\frac{0.052}{0.10} = 0.52$. $w_1 = \\frac{0.10^2}{0.010^2} = \\frac{0.01}{0.0001} = 100$.\n- SNP $2$: $r_2 = \\frac{0.060}{0.12} = 0.50$. $w_2 = \\frac{0.12^2}{0.012^2} = \\frac{0.0144}{0.000144} = 100$.\n- SNP $3$: $r_3 = \\frac{0.040}{0.08} = 0.50$. $w_3 = \\frac{0.08^2}{0.010^2} = \\frac{0.0064}{0.0001} = 64$.\n- SNP $4$: $r_4 = \\frac{0.0572}{0.11} = 0.52$. $w_4 = \\frac{0.11^2}{0.011^2} = \\frac{0.0121}{0.000121} = 100$.\n- SNP $5$: $r_5 = \\frac{0.045}{0.09} = 0.50$. $w_5 = \\frac{0.09^2}{0.009^2} = \\frac{0.0081}{0.000081} = 100$.\n- SNP $6$: $r_6 = \\frac{0.130}{0.10} = 1.30$. $w_6 = \\frac{0.10^2}{0.010^2} = \\frac{0.01}{0.0001} = 100$.\n- SNP $7$: $r_7 = \\frac{0.065}{0.13} = 0.50$. $w_7 = \\frac{0.13^2}{0.013^2} = \\frac{0.0169}{0.000169} = 100$.\n\n**2. Inverse-Variance Weighted (IVW) Estimator**\n\nThe fixed-effect IVW estimator combines the individual Wald ratios by taking their weighted average, where the weights are the inverse variances $w_i$. This method provides the most precise estimate if all instruments are valid (i.e., there is no horizontal pleiotropy).\n$$\n\\hat{\\theta}_{\\mathrm{IVW}} = \\frac{\\sum_{i=1}^{7} w_i r_i}{\\sum_{i=1}^{7} w_i}\n$$\nThe sum of the weights is:\n$$\n\\sum_{i=1}^{7} w_i = 100 + 100 + 64 + 100 + 100 + 100 + 100 = 664\n$$\nThe weighted sum of the ratios is:\n$$\n\\sum_{i=1}^{7} w_i r_i = (100 \\times 0.52) + (100 \\times 0.50) + (64 \\times 0.50) + (100 \\times 0.52) + (100 \\times 0.50) + (100 \\times 1.30) + (100 \\times 0.50)\n$$\n$$\n= 52 + 50 + 32 + 52 + 50 + 130 + 50 = 416\n$$\nThe IVW estimate is therefore:\n$$\n\\hat{\\theta}_{\\mathrm{IVW}} = \\frac{416}{664} \\approx 0.626506...\n$$\nRounded to four significant figures, $\\hat{\\theta}_{\\mathrm{IVW}} = 0.6265$.\n\n**3. Weighted Median (WM) Estimator**\n\nThe weighted median estimator provides a consistent causal estimate if at least $50\\%$ of the weight in the analysis comes from valid instruments. It is robust to pleiotropic outliers. To find the weighted median, we first sort the individual ratio estimates $r_i$ and then find the value at which the cumulative sum of weights reaches $50\\%$ of the total weight.\n\nThe ordered pairs of $(r_i, w_i)$ are:\n$(0.50, 100)$, $(0.50, 64)$, $(0.50, 100)$, $(0.50, 100)$, $(0.52, 100)$, $(0.52, 100)$, $(1.30, 100)$.\nThe total weight is $\\sum w_i = 664$. The halfway point is $\\frac{664}{2} = 332$.\nWe compute the cumulative sum of weights for the ordered ratios:\n- For $r_i = 0.50$: cumulative weight is $100 + 64 + 100 + 100 = 364$.\nSince this cumulative weight ($364$) is the first to exceed the halfway point ($332$), the weighted median is the corresponding ratio value.\n$$\n\\hat{\\theta}_{\\mathrm{WM}} = 0.50\n$$\nTo be reported to four significant figures, $\\hat{\\theta}_{\\mathrm{WM}} = 0.5000$.\n\n**4. Weighted Mode (WMode) Estimator**\n\nThe weighted mode estimator is based on the principle that the a valid causal estimate should be supported by a plurality of instruments. The problem defines a simplified \"zero-bandwidth\" version: the value of $r_i$ corresponding to the group of instruments with the largest sum of weights. We group the instruments by their exact $r_i$ value and sum the weights within each group.\n\n- Group $r=0.50$: SNPs $\\{2, 3, 5, 7\\}$. Total weight = $w_2 + w_3 + w_5 + w_7 = 100 + 64 + 100 + 100 = 364$.\n- Group $r=0.52$: SNPs $\\{1, 4\\}$. Total weight = $w_1 + w_4 = 100 + 100 = 200$.\n- Group $r=1.30$: SNP $\\{6\\}$. Total weight = $w_6 = 100$.\n\nThe largest aggregated weight is $364$, which corresponds to the ratio value $r=0.50$.\n$$\n\\hat{\\theta}_{\\mathrm{WMode}} = 0.50\n$$\nTo be reported to four significant figures, $\\hat{\\theta}_{\\mathrm{WMode}} = 0.5000$.\n\n**Interpretation of Discrepancy**\n\nThe three estimates are $\\hat{\\theta}_{\\mathrm{IVW}} = 0.6265$, $\\hat{\\theta}_{\\mathrm{WM}} = 0.5000$, and $\\hat{\\theta}_{\\mathrm{WMode}} = 0.5000$. The notable discrepancy between the IVW estimate and the robust median and mode estimates is a strong indicator of violations of the MR assumptions, specifically the presence of directional horizontal pleiotropy. The IVW estimator assumes all instruments are valid and is therefore sensitive to outliers. The ratio for SNP $6$ ($r_6 = 1.30$) is a significant outlier compared to the others, which cluster around $0.50$. Since the IVW is a weighted average, this pleiotropic outlier, which has a large weight ($w_6=100$), biases the estimate upwards. In contrast, the weighted median and weighted mode estimators are robust to such outliers. They both provide an estimate of $0.5000$, suggesting that the largest cluster of instruments, comprising over $50\\%$ of the total weight, consistently points to a causal effect of this magnitude. The agreement between the median and mode estimators reinforces the conclusion that the true causal effect is likely close to $0.50$ and that the IVW estimate is biased due to pleiotropy from at least one instrument (SNP $6$).\n\nFinal Numerical Results (4 significant figures):\n- $\\hat{\\theta}_{\\mathrm{IVW}} \\approx 0.6265$\n- $\\hat{\\theta}_{\\mathrm{WM}} = 0.5000$\n- $\\hat{\\theta}_{\\mathrm{WMode}} = 0.5000$", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.6265  0.5000  0.5000 \\end{pmatrix}}\n$$", "id": "4583451"}]}