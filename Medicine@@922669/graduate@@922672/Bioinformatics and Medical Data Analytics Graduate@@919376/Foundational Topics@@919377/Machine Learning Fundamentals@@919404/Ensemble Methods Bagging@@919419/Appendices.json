{"hands_on_practices": [{"introduction": "The power of bootstrap aggregating, or bagging, comes from averaging diverse models. This diversity originates from the bootstrap sampling process itself, where each base learner is trained on a slightly different subset of the original data. This first exercise provides a hands-on look at this fundamental mechanism by asking you to derive from first principles the expected number of unique data points in a single bootstrap sample [@problem_id:4559772]. Understanding this quantity is key to grasping why bagging is so effective at reducing variance and controlling overfitting, especially in high-dimensional settings common to genomics.", "problem": "In a supervised genomic classification study, you have an original cohort of $n=200$ patients, each represented by high-dimensional gene expression profiles. To build a bagged ensemble of base learners, each model is trained on a bootstrap sample: $n$ draws with replacement from the $n$ patients, where each draw selects one patient uniformly at random and all draws are independent and identically distributed (i.i.d.). Using only these definitions and first principles such as indicator random variables and linearity of expectation, derive from first principles an exact expression for the expected number of unique patients contained in a single bootstrap sample as a function of $n$, and then evaluate it for $n=200$. Round your numerical answer to four significant figures and report it as the number of patients. Finally, interpret the magnitude of this expectation in the context of variance reduction and overfitting control in bootstrap aggregating (bagging) for high-dimensional genomic classifiers, including the role of Out-of-Bag (OOB) evaluation (define Out-of-Bag (OOB) on its first appearance). Your final reported answer must be the rounded expected number of patients only.", "solution": "The objective is to derive an exact expression for the expected number of unique patients in a single bootstrap sample of size $n$, drawn with replacement from an original cohort of $n$ patients.\n\nLet the set of original patients be $C = \\{p_1, p_2, \\dots, p_n\\}$. A bootstrap sample is constructed by drawing $n$ times from $C$ with replacement. All draws are independent and identically distributed (i.i.d.), and each patient has a probability of $\\frac{1}{n}$ of being selected in any single draw.\n\nLet $X$ be the random variable representing the number of unique patients in a bootstrap sample. To find the expectation of $X$, we can express $X$ as a sum of indicator random variables, as suggested. For each patient $j \\in \\{1, 2, \\dots, n\\}$, let $I_j$ be an indicator random variable defined as:\n$$\nI_j = \\begin{cases} 1  \\text{if patient } j \\text{ is included in the bootstrap sample at least once} \\\\ 0  \\text{if patient } j \\text{ is not included in the bootstrap sample} \\end{cases}\n$$\nThe total number of unique patients in the sample is the sum of these indicators:\n$$\nX = \\sum_{j=1}^{n} I_j\n$$\nBy the linearity of expectation, the expected number of unique patients is the sum of the expectations of the individual indicator variables:\n$$\nE[X] = E\\left[\\sum_{j=1}^{n} I_j\\right] = \\sum_{j=1}^{n} E[I_j]\n$$\nThe expectation of an indicator random variable is equal to the probability of the event it indicates. Thus, $E[I_j] = P(I_j = 1)$.\nThe event $I_j=1$ occurs if patient $j$ is selected at least once in the $n$ draws. It is simpler to calculate the probability of the complementary event, $P(I_j = 0)$, which is the event that patient $j$ is never selected in the $n$ draws.\n\nIn a single draw, the probability of selecting any specific patient $j$ is $\\frac{1}{n}$.\nTherefore, the probability of *not* selecting patient $j$ in a single draw is $1 - \\frac{1}{n}$.\nSince the $n$ draws are independent, the probability of not selecting patient $j$ in any of the $n$ draws is the product of the probabilities of not selecting patient $j$ in each draw:\n$$\nP(I_j = 0) = \\left(1 - \\frac{1}{n}\\right) \\times \\left(1 - \\frac{1}{n}\\right) \\times \\dots \\times \\left(1 - \\frac{1}{n}\\right) = \\left(1 - \\frac{1}{n}\\right)^n\n$$\nThe probability that patient $j$ is selected at least once is therefore:\n$$\nP(I_j = 1) = 1 - P(I_j = 0) = 1 - \\left(1 - \\frac{1}{n}\\right)^n\n$$\nSo, the expectation of the indicator variable is $E[I_j] = 1 - \\left(1 - \\frac{1}{n}\\right)^n$.\nBecause the sampling is uniform, this probability is the same for all patients $j=1, \\dots, n$.\n\nSubstituting this back into the expression for $E[X]$:\n$$\nE[X] = \\sum_{j=1}^{n} \\left[1 - \\left(1 - \\frac{1}{n}\\right)^n\\right]\n$$\nSince the term inside the summation is constant with respect to the index $j$, the sum is simply $n$ times this term:\n$$\nE[X] = n \\left[1 - \\left(1 - \\frac{1}{n}\\right)^n\\right]\n$$\nThis is the exact expression for the expected number of unique patients in a single bootstrap sample.\n\nNow, we evaluate this expression for $n=200$:\n$$\nE[X] = 200 \\left[1 - \\left(1 - \\frac{1}{200}\\right)^{200}\\right] = 200 \\left[1 - \\left(\\frac{199}{200}\\right)^{200}\\right]\n$$\nCalculating the value of the term in parentheses:\n$$\n\\left(\\frac{199}{200}\\right)^{200} = (0.995)^{200} \\approx 0.3669528...\n$$\nSubstituting this value back into the expression for the expectation:\n$$\nE[X] \\approx 200 [1 - 0.3669528] = 200 [0.6330472] \\approx 126.60944\n$$\nRounding to four significant figures, the expected number of unique patients is $126.6$.\n\nThis means that, on average, a bootstrap sample contains approximately $126.6$ of the original $200$ patients, which is about $63.3\\%$. The remaining $200 - 126.6 = 73.4$ patients on average, or about $36.7\\%$, are not included. These excluded samples are termed **Out-of-Bag (OOB)** samples, which are the observations from the original dataset not present in a given bootstrap sample.\n\nThe magnitude of this expectation is central to the effectiveness of bootstrap aggregating (bagging).\n1.  **Variance Reduction and Overfitting Control**: Bagging reduces the variance of an estimate by averaging the predictions of multiple models. For this averaging to be effective, the models must be diverse, i.e., they must make different errors. By training each base learner on a different bootstrap sample, which contains only about $63.3\\%$ of the unique data, we ensure this diversity. In high-dimensional genomic studies, classifiers (like decision trees) are highly prone to overfitting the training data by capturing spurious noise. Bagging mitigates this by having each tree overfit to a different subset of the data; when their predictions are averaged, a large portion of this model-specific noise cancels out, leading to a smoother decision boundary and a more robust ensemble model with better generalization performance. The fact that a substantial fraction of the original data is omitted from each training run is what drives this crucial decorrelation of the base learners.\n\n2.  **Role of Out-of-Bag (OOB) Evaluation**: The OOB samples provide a \"free\" and unbiased validation set for each base learner. To evaluate the performance of the entire bagged ensemble, one can take each patient from the original dataset and aggregate the predictions of only those models for which that patient was in the OOB set. The resulting \"OOB error\" is a reliable estimate of the ensemble's generalization error, calculated without the need for a separate hold-out test set or a computationally expensive cross-validation procedure. The substantial size of the OOB set (on average, $73.4$ patients per-model basis) ensures that this estimate is stable and trustworthy, which is a significant advantage in medical data analytics where data is often limited.", "answer": "$$\\boxed{126.6}$$", "id": "4559772"}, {"introduction": "A key advantage of bagging is that the data points left out of each bootstrap sample, known as out-of-bag (OOB) observations, provide a \"free\" and computationally efficient way to estimate the ensemble's generalization error. However, how does this OOB error estimate compare to other standard validation techniques like $K$-fold cross-validation? This next practice challenges you to think critically about the statistical properties of these error estimators, specifically their bias, in the context of a realistic clinical dataset with noisy labels [@problem_id:4559762]. This analysis is crucial for any practitioner needing to make sound judgments about model performance and selection.", "problem": "A clinical dataset provides $N$ independent and identically distributed patient records $\\{(X_i, Y_i)\\}_{i=1}^N$ drawn from an unknown distribution, where $Y_i \\in \\{0,1\\}$ denotes disease status. The labels are subject to symmetric label noise with rate $\\varepsilon \\in (0, 1/2)$ due to imperfect diagnostic gold standards, and features $X_i$ include routine laboratory results and demographics. A bagged classifier is constructed by aggregating $M$ Classification and Regression Tree (CART) base learners, each trained on a bootstrap sample of size $N$ from the full dataset. Consider the following two estimators of the generalization error (expected risk) of the bagged classifier built on the full dataset:\n1. The out-of-bag (OOB) error, where for each observation $i$, the prediction is formed by averaging only those trees whose bootstrap sample did not include observation $i$, and the overall error is the average of the loss over all $i$.\n2. The $K$-fold cross-validation (CV) error with $K=5$, where the data are partitioned into $5$ disjoint folds, and for each fold, a bagged classifier is trained on the other $4$ folds and evaluated on the held-out fold; the errors are averaged across folds.\n\nAssume $M \\gg 1$ so that Monte Carlo fluctuations due to a finite number of trees are negligible. Use only fundamental definitions of expected risk $\\mathbb{E}[\\ell(\\hat{f}(X), Y)]$, properties of bootstrap sampling, and the construction of $K$-fold cross-validation to reason about the direction of bias of these two error estimators relative to the true generalization error of the bagged classifier trained on all $N$ observations under the noisy clinical data-generating process. Which statement is most accurate?\n\nA. For $M \\to \\infty$, the out-of-bag error is asymptotically unbiased for the generalization error of the bagged classifier trained on the full dataset, whereas $5$-fold cross-validation is pessimistically biased because each fold trains on only $80\\%$ of the data.\n\nB. For $M \\to \\infty$, both out-of-bag error and $5$-fold cross-validation are unbiased for the generalization error of the bagged classifier trained on the full dataset, even when $N$ is finite.\n\nC. Out-of-bag error is optimistically biased in noisy clinical datasets because many trees are trained on bootstrap samples that contain the target observation, which leaks information.\n\nD. $5$-fold cross-validation is optimistically biased relative to the generalization error of the bagged classifier trained on the full dataset because it averages losses on held-out folds that are easier to predict than the full distribution.\n\nE. The bias difference between out-of-bag error and $5$-fold cross-validation disappears only if $K=N$ (leave-one-out cross-validation); for $K=5$, out-of-bag error is always more biased.", "solution": "### Derivation\nLet $S = \\{(X_i, Y_i)\\}_{i=1}^N$ be the full dataset of size $N$. Let $\\hat{f}_S$ denote the bagged classifier trained on $S$. This classifier is an aggregation of $M$ base learners, $\\{\\hat{h}_b\\}_{b=1}^M$, where each $\\hat{h}_b$ is a CART trained on a bootstrap sample $S^{*b}$ of size $N$ drawn from $S$.\nThe target quantity we wish to estimate is the true generalization error (or expected risk) of $\\hat{f}_S$, defined as:\n$$ R(\\hat{f}_S) = \\mathbb{E}_{(X,Y)}[\\ell(\\hat{f}_S(X), Y)] $$\nwhere the expectation is over the true, unknown data-generating distribution, and $\\ell$ is a suitable loss function (e.g., $0$-$1$ loss for classification). The classifier $\\hat{f}_S$ is fixed by the dataset $S$. Our goal is to analyze the bias of two estimators, $\\hat{Err}_{OOB}$ and $\\hat{Err}_{CV}$, for this quantity $R(\\hat{f}_S)$.\n\n**Bias of an estimator**: The bias of an estimator $\\hat{\\theta}$ for a parameter $\\theta$ is $\\mathbb{E}[\\hat{\\theta}] - \\theta$. A positive bias is called a pessimistic bias (overestimation), and a negative bias is an optimistic bias (underestimation). For error estimation, we are typically interested in the expectation of the estimator over the distribution of training sets, compared to the expected true error. Let $Err(n)$ denote the expected generalization error of a classifier trained on a dataset of size $n$, i.e., $Err(n) = \\mathbb{E}_{S_n}[R(\\hat{f}_{S_n})]$. Generally, for a stable learning algorithm, $Err(n)$ is a non-increasing function of $n$. More data leads to a better model, which has lower generalization error.\n\n**1. Analysis of 5-Fold Cross-Validation (CV) Error**\nIn $K$-fold CV with $K=5$, the dataset $S$ is partitioned into $5$ disjoint folds. For each fold $k \\in \\{1,...,5\\}$, a *new* bagged classifier, let's call it $\\hat{f}_{\\neg k}$, is trained on the remaining $4$ folds. The size of this training set is $N(1-1/K) = N(1-1/5) = 4N/5 = 0.8N$. The error of $\\hat{f}_{\\neg k}$ is then estimated on the held-out fold $k$. The final CV error, $\\hat{Err}_{CV}$, is the average of these $5$ error estimates.\n\nCrucially, $\\hat{Err}_{CV}$ is an estimate of the generalization error of a classifier trained on a dataset of size $0.8N$, not $N$. Since the performance of most classifiers, including bagged trees, improves with more training data, the learning curve $Err(n)$ is a decreasing function of $n$. Therefore, we expect:\n$$ \\mathbb{E}[\\hat{Err}_{CV}] \\approx Err(0.8N)  Err(N) $$\nBecause the CV procedure evaluates models trained on smaller-than-full datasets, these models are expected to be less accurate (have higher error) than the final model trained on the full dataset. Thus, the $K$-fold CV error estimator is **pessimistically biased**; it tends to overestimate the true generalization error of the final model.\n\n**2. Analysis of Out-of-Bag (OOB) Error**\nThe OOB error estimator, $\\hat{Err}_{OOB}$, works differently. It uses the *single* bagged classifier $\\hat{f}_S$ that was trained on the full dataset $S$. For each observation $(X_i, Y_i) \\in S$, its prediction is made by aggregating only those trees $\\{\\hat{h}_b\\}$ for which $(X_i, Y_i)$ was not in the corresponding bootstrap sample $S^{*b}$. These are the \"out-of-bag\" trees for observation $i$.\nThe probability that a specific observation $i$ is not selected in a bootstrap sample of size $N$ is $(1 - 1/N)^N$. As $N \\to \\infty$, this probability converges to $1/e \\approx 0.368$. Thus, on average, each observation is \"out-of-bag\" for about $36.8\\%$ of the trees.\nThe OOB error for observation $i$ is calculated using a prediction where $(X_i, Y_i)$ was effectively held out, acting as a test point for that sub-ensemble of trees. $\\hat{Err}_{OOB}$ is the average of these errors over all $i=1,...,N$.\n\nBecause the OOB procedure uses the observations that were not seen during the training of the specific base learners to test them, it provides a valid mechanism for error estimation that avoids optimistic bias from testing on training data. The canonical view, originating with Breiman, is that the OOB error is an almost unbiased estimator of the true generalization error. Unlike $K$-fold CV, it does not require retraining new models on smaller data partitions. It estimates the error of the very model $\\hat{f}_S$ we built.\n\nWhile more detailed theoretical analyses have shown that OOB error can have a small pessimistic bias for finite $N$ (due to correlations between the base learners in the OOB sub-ensembles), this bias is generally much smaller than the pessimistic bias of $K$-fold CV (especially for small $K$ like $5$). For many practical and theoretical purposes, particularly as $N$ grows, the OOB error is considered asymptotically unbiased.\n\n**Summary of Biases**:\n- **5-Fold CV**: Has a significant pessimistic bias because it evaluates models trained on only $80\\%$ of the data.\n- **OOB Error**: Is either unbiased or has a small pessimistic bias. It is a much less biased estimator of $R(\\hat{f}_S)$ than $5$-fold CV.\n\nThe presence of symmetric label noise with rate $\\varepsilon \\in (0, 1/2)$ increases the irreducible error and makes the learning problem harder, but it does not alter the fundamental direction of the biases of these two estimators, which stems from the way they use the training data.\n\n### Option-by-Option Analysis\n\n**A. For $M \\to \\infty$, the out-of-bag error is asymptotically unbiased for the generalization error of the bagged classifier trained on the full dataset, whereas $5$-fold cross-validation is pessimistically biased because each fold trains on only $80\\%$ of the data.**\nThis statement is accurate. The pessimistic bias of $5$-fold CV and its cause are correctly identified. The description of OOB error as \"asymptotically unbiased\" is the standard and correct characterization in this context, especially in contrast to the more substantially biased CV. The bias of OOB, if any, is known to be small and diminishes with sample size. **Correct**.\n\n**B. For $M \\to \\infty$, both out-of-bag error and $5$-fold cross-validation are unbiased for the generalization error of the bagged classifier trained on the full dataset, even when $N$ is finite.**\nThis is incorrect. As derived, $5$-fold cross-validation has a pessimistic bias for finite $N$ because it trains on smaller datasets. This bias does not vanish simply because $M \\to \\infty$. **Incorrect**.\n\n**C. Out-of-bag error is optimistically biased in noisy clinical datasets because many trees are trained on bootstrap samples that contain the target observation, which leaks information.**\nThis statement fundamentally misrepresents how OOB error is calculated. The error for a given observation is computed using *only* the trees that were *not* trained on it. This procedure is specifically designed to prevent information leakage and the resulting optimistic bias. The bias of OOB is generally considered pessimistic, not optimistic. **Incorrect**.\n\n**D. $5$-fold cross-validation is optimistically biased relative to the generalization error of the bagged classifier trained on the full dataset because it averages losses on held-out folds that are easier to predict than the full distribution.**\nThis statement is incorrect on two counts. First, the bias is pessimistic, not optimistic. Second, the reason is wrong; the held-out folds are random samples and are not systematically \"easier to predict\" than any other data from the same distribution. The bias comes from training on smaller datasets. **Incorrect**.\n\n**E. The bias difference between out-of-bag error and $5$-fold cross-validation disappears only if $K=N$ (leave-one-out cross-validation); for $K=5$, out-of-bag error is always more biased.**\nThis statement is incorrect. The bias of $K$-fold CV is a function of $K$, and for $K=N$ (LOOCV), the bias is minimal but still pessimistic ($Err(N-1)  Err(N)$). OOB error is often considered a computationally efficient approximation to LOOCV. However, claiming the bias difference *disappears* is too strong. More importantly, the claim that for $K=5$, OOB error is \"always more biased\" is contrary to established theory and practice. The bias of $5$-fold CV, due to a $20\\%$ reduction in training set size, is substantially larger than the bias of OOB. **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "4559762"}, {"introduction": "Moving from foundational principles to a concrete application, this final practice demonstrates how to implement OOB evaluation in a specialized and highly relevant bioinformatics domain: survival analysis. The exercise requires you to adapt the general concept of OOB evaluation to a specific performance metric, the Concordance Index (C-index), which is tailored for right-censored data [@problem_id:4559822]. Working through this problem will solidify your understanding of how to apply bagging and its associated evaluation techniques to complex, real-world medical data analytics challenges.", "problem": "A central task in bioinformatics and medical data analytics is evaluating predictive concordance for survival models trained under Bootstrap Aggregating (bagging). Consider a survival dataset with right-censoring where the true survival time for subject $i$ is $T_i$, the censoring time is $C_i$, the observed time is $t_i = \\min\\{T_i, C_i\\}$, and the event indicator is $\\delta_i = \\mathbf{1}\\{T_i \\leq C_i\\}$. Let an ensemble of $B$ bootstrap models be trained on resampled datasets, producing Out-Of-Bag (OOB) predictions only for subjects not included in the training set of a given model. The predictive quantity of interest is a risk score $s_{i,m}$ for subject $i$ from model $m$, where higher values indicate higher instantaneous hazard and therefore earlier failure times.\n\nStarting from the definitions of right-censoring and the probability-of-concordance interpretation of the Concordance Index (C-index), derive a sample-based estimator for the Out-Of-Bag (OOB) C-index of a bagged survival model that (i) aggregates OOB risk scores per subject by averaging across the models where the subject is OOB and (ii) counts concordant pairs using only comparable pairs under right-censoring. Then compute its numerical value for the following ensemble and data:\n\n- Subjects $i \\in \\{1,2,3,4,5\\}$ with $(t_i, \\delta_i)$ given by:\n  - Subject $1$: $(t_1, \\delta_1) = (5, 1)$\n  - Subject $2$: $(t_2, \\delta_2) = (7, 0)$\n  - Subject $3$: $(t_3, \\delta_3) = (10, 1)$\n  - Subject $4$: $(t_4, \\delta_4) = (13, 1)$\n  - Subject $5$: $(t_5, \\delta_5) = (18, 0)$\n- Four bootstrap models ($B=4$) yield the following OOB risk scores $s_{i,m}$ (entries not shown are in-bag and thus not available for OOB aggregation):\n  - Model $1$: $s_{1,1} = 0.85$, $s_{3,1} = 0.70$, $s_{5,1} = 0.45$\n  - Model $2$: $s_{2,2} = 0.52$, $s_{3,2} = 0.73$, $s_{4,2} = 0.56$\n  - Model $3$: $s_{1,3} = 0.80$, $s_{2,3} = 0.55$, $s_{5,3} = 0.68$\n  - Model $4$: $s_{3,4} = 0.69$, $s_{4,4} = 0.52$, $s_{5,4} = 0.65$\n\nDefine the OOB aggregate risk score for subject $i$ as the arithmetic mean over the models where $i$ is OOB. Use the standard right-censoring comparability rule: a pair $(i,j)$ is comparable if $\\min\\{t_i, t_j\\}$ corresponds to an observed event (that is, if $t_i  t_j$ and $\\delta_i = 1$, or if $t_j  t_i$ and $\\delta_j = 1$). A comparable pair is concordant if the subject with the smaller observed event time has a larger aggregate risk score. Assume there are no ties in observed times or aggregate risk scores. Provide the final OOB C-index as a single exact fraction. If you choose to present a decimal approximation instead, round your answer to four significant figures.", "solution": "The problem requires the derivation of a sample-based estimator for the Out-Of-Bag (OOB) Concordance Index (C-index) for a bagged survival model, followed by its computation for a given dataset.\n\nFirst, we establish the formal definition of the OOB C-index estimator. Let there be a set of $N$ subjects, indexed by $i \\in \\{1, 2, \\dots, N\\}$. For each subject $i$, we have the observed time $t_i$ and the event indicator $\\delta_i$. An ensemble of $B$ models is trained on bootstrap samples. For each subject $i$, let $M_i^{\\text{OOB}}$ be the set of model indices $m$ for which subject $i$ was in the out-of-bag sample. The risk score predicted for subject $i$ by model $m \\in M_i^{\\text{OOB}}$ is $s_{i,m}$.\n\nThe OOB aggregate risk score for subject $i$, denoted $\\bar{s}_i$, is defined as the arithmetic mean of the OOB risk scores for that subject:\n$$\n\\bar{s}_i = \\frac{1}{|M_i^{\\text{OOB}}|} \\sum_{m \\in M_i^{\\text{OOB}}} s_{i,m}\n$$\nThe C-index evaluates the model's ability to discriminate between outcomes for pairs of subjects. Given the presence of right-censoring, not all pairs of subjects are comparable. A pair $(i, j)$ is considered comparable only if we can unambiguously determine which subject had a shorter survival time. This is possible if the subject with the earlier observed time, say $i$ (i.e., $t_i  t_j$), experienced an event ($\\delta_i = 1$). If subject $i$ were censored ($\\delta_i = 0$), their true event time $T_i$ would be unknown and could be greater than $t_j$, making the ordering of event times uncertain.\n\nTherefore, the set of all comparable pairs, $N_{\\text{comp}}$, is defined as:\n$$\nN_{\\text{comp}} = \\left\\{ (i, j) \\mid i \\neq j, (t_i  t_j \\text{ and } \\delta_i = 1) \\text{ or } (t_j  t_i \\text{ and } \\delta_j = 1) \\right\\}\n$$\nA comparable pair is concordant if the model's risk prediction aligns with the observed outcome. Since a higher risk score $\\bar{s}$ is indicative of a higher hazard and thus an earlier event time, a pair $(i, j)$ with $t_i  t_j$ is concordant if $\\bar{s}_i  \\bar{s}_j$. The set of concordant pairs, $N_{\\text{conc}}$, is a subset of $N_{\\text{comp}}$ defined as:\n$$\nN_{\\text{conc}} = \\left\\{ (i, j) \\in N_{\\text{comp}} \\mid (t_i  t_j \\text{ and } \\bar{s}_i  \\bar{s}_j) \\text{ or } (t_j  t_i \\text{ and } \\bar{s}_j  \\bar{s}_i) \\right\\}\n$$\nThe sample-based estimator for the OOB C-index, $C_{\\text{OOB}}$, is the ratio of the number of concordant pairs to the number of comparable pairs:\n$$\nC_{\\text{OOB}} = \\frac{|N_{\\text{conc}}|}{|N_{\\text{comp}}|}\n$$\nThis assumes no ties in either the observed times $t_i$ or the aggregate risk scores $\\bar{s}_i$, as stated in the problem.\n\nNow, we compute the value of $C_{\\text{OOB}}$ for the provided data.\n\nThe dataset consists of $5$ subjects with the following survival data:\n- Subject $1$: $(t_1, \\delta_1) = (5, 1)$\n- Subject $2$: $(t_2, \\delta_2) = (7, 0)$\n- Subject $3$: $(t_3, \\delta_3) = (10, 1)$\n- Subject $4$: $(t_4, \\delta_4) = (13, 1)$\n- Subject $5$: $(t_5, \\delta_5) = (18, 0)$\n\nThere are $B=4$ models. The OOB risk scores $s_{i,m}$ are given.\n\n**Step 1: Calculate the OOB aggregate risk scores $\\bar{s}_i$.**\n\n- For subject $1$, OOB models are $m \\in \\{1, 3\\}$:\n  $\\bar{s}_1 = \\frac{s_{1,1} + s_{1,3}}{2} = \\frac{0.85 + 0.80}{2} = \\frac{1.65}{2} = 0.825$.\n- For subject $2$, OOB models are $m \\in \\{2, 3\\}$:\n  $\\bar{s}_2 = \\frac{s_{2,2} + s_{2,3}}{2} = \\frac{0.52 + 0.55}{2} = \\frac{1.07}{2} = 0.535$.\n- For subject $3$, OOB models are $m \\in \\{1, 2, 4\\}$:\n  $\\bar{s}_3 = \\frac{s_{3,1} + s_{3,2} + s_{3,4}}{3} = \\frac{0.70 + 0.73 + 0.69}{3} = \\frac{2.12}{3} \\approx 0.7067$.\n- For subject $4$, OOB models are $m \\in \\{2, 4\\}$:\n  $\\bar{s}_4 = \\frac{s_{4,2} + s_{4,4}}{2} = \\frac{0.56 + 0.52}{2} = \\frac{1.08}{2} = 0.54$.\n- For subject $5$, OOB models are $m \\in \\{1, 3, 4\\}$:\n  $\\bar{s}_5 = \\frac{s_{5,1} + s_{5,3} + s_{5,4}}{3} = \\frac{0.45 + 0.68 + 0.65}{3} = \\frac{1.78}{3} \\approx 0.5933$.\n\n**Step 2: Identify all comparable pairs.**\n\nWe examine all $\\binom{5}{2} = 10$ unique pairs of subjects. A pair $(i, j)$ is comparable if the one with the smaller $t$ has $\\delta=1$.\n\n- Pair $(1, 2)$: $t_1 = 5  t_2 = 7$ and $\\delta_1 = 1$. **Comparable.**\n- Pair $(1, 3)$: $t_1 = 5  t_3 = 10$ and $\\delta_1 = 1$. **Comparable.**\n- Pair $(1, 4)$: $t_1 = 5  t_4 = 13$ and $\\delta_1 = 1$. **Comparable.**\n- Pair $(1, 5)$: $t_1 = 5  t_5 = 18$ and $\\delta_1 = 1$. **Comparable.**\n- Pair $(2, 3)$: $t_2 = 7  t_3 = 10$ but $\\delta_2 = 0$. Not comparable.\n- Pair $(2, 4)$: $t_2 = 7  t_4 = 13$ but $\\delta_2 = 0$. Not comparable.\n- Pair $(2, 5)$: $t_2 = 7  t_5 = 18$ but $\\delta_2 = 0$. Not comparable.\n- Pair $(3, 4)$: $t_3 = 10  t_4 = 13$ and $\\delta_3 = 1$. **Comparable.**\n- Pair $(3, 5)$: $t_3 = 10  t_5 = 18$ and $\\delta_3 = 1$. **Comparable.**\n- Pair $(4, 5)$: $t_4 = 13  t_5 = 18$ and $\\delta_4 = 1$. **Comparable.**\n\nThe total number of comparable pairs is $|N_{\\text{comp}}| = 7$.\n\n**Step 3: Check for concordance among comparable pairs.**\n\nA comparable pair is concordant if the subject with the smaller event time has a larger aggregate risk score.\n\n- Pair $(1, 2)$: $t_1  t_2$. We check if $\\bar{s}_1  \\bar{s}_2$.\n  $\\bar{s}_1 = 0.825 > \\bar{s}_2 = 0.535$. **Concordant.**\n- Pair $(1, 3)$: $t_1  t_3$. We check if $\\bar{s}_1  \\bar{s}_3$.\n  $\\bar{s}_1 = 0.825 > \\bar{s}_3 \\approx 0.7067$. **Concordant.**\n- Pair $(1, 4)$: $t_1  t_4$. We check if $\\bar{s}_1  \\bar{s}_4$.\n  $\\bar{s}_1 = 0.825 > \\bar{s}_4 = 0.54$. **Concordant.**\n- Pair $(1, 5)$: $t_1  t_5$. We check if $\\bar{s}_1  \\bar{s}_5$.\n  $\\bar{s}_1 = 0.825 > \\bar{s}_5 \\approx 0.5933$. **Concordant.**\n- Pair $(3, 4)$: $t_3  t_4$. We check if $\\bar{s}_3  \\bar{s}_4$.\n  $\\bar{s}_3 \\approx 0.7067 > \\bar{s}_4 = 0.54$. **Concordant.**\n- Pair $(3, 5)$: $t_3  t_5$. We check if $\\bar{s}_3  \\bar{s}_5$.\n  $\\bar{s}_3 \\approx 0.7067 > \\bar{s}_5 \\approx 0.5933$. **Concordant.**\n- Pair $(4, 5)$: $t_4  t_5$. We check if $\\bar{s}_4  \\bar{s}_5$.\n  $\\bar{s}_4 = 0.54  \\bar{s}_5 \\approx 0.5933$. Discordant.\n\nThe total number of concordant pairs is $|N_{\\text{conc}}| = 6$.\n\n**Step 4: Compute the OOB C-index.**\n\nUsing the derived formula:\n$$\nC_{\\text{OOB}} = \\frac{|N_{\\text{conc}}|}{|N_{\\text{comp}}|} = \\frac{6}{7}\n$$\nThe OOB C-index for this bagged survival model on the given data is $\\frac{6}{7}$.", "answer": "$$\\boxed{\\frac{6}{7}}$$", "id": "4559822"}]}