{"hands_on_practices": [{"introduction": "Before diving into complex models, it's essential to understand how a Receiver Operating Characteristic (ROC) curve is built from the ground up. This exercise guides you through the manual process of translating a small set of classifier scores from diseased and non-diseased individuals into a concrete ROC curve [@problem_id:4918235]. By calculating the True Positive Rate ($\\mathrm{TPR}$) and False Positive Rate ($\\mathrm{FPR}$) at each potential threshold, you will construct the curve point-by-point and then compute the Area Under the Curve (AUC) using the trapezoidal rule, solidifying the fundamental geometric interpretation of this powerful diagnostic tool.", "problem": "A binary diagnostic task in medical imaging is evaluated using Receiver Operating Characteristic (ROC) analysis. A classifier produces continuous confidence scores in the interval $[0,1]$ that reflect the likelihood of disease. For a threshold $\\tau$, the decision rule is: declare an image positive (diseased) if its score is $\\ge \\tau$ and negative (nondiseased) otherwise. The True Positive Rate ($\\mathrm{TPR}$, sensitivity) at threshold $\\tau$ is defined as the fraction of diseased cases declared positive, and the False Positive Rate ($\\mathrm{FPR}$, one minus specificity) is the fraction of nondiseased cases declared positive.\n\nYou are given three diseased-case scores $\\{0.3,\\,0.6,\\,0.9\\}$ and four nondiseased-case scores $\\{0.1,\\,0.2,\\,0.4,\\,0.8\\}$. Using the empirical definitions above:\n\n1) Construct the empirical ROC curve by enumerating the unique thresholds $\\tau$ drawn from the union of the given scores, augmented with endpoint conventions $\\tau\\max$ (no cases positive) and $\\tau\\le\\min$ (all cases positive). For each threshold, compute the corresponding point $(\\mathrm{FPR},\\,\\mathrm{TPR})$.\n\n2) From the empirical ROC curve, compute the Area Under the Curve (AUC) by summing the areas of the trapezoids formed between successive points along the $\\mathrm{FPR}$ axis.\n\nExpress the final AUC as a single exact fraction. No units are required.", "solution": "The problem statement has been validated and found to be scientifically grounded, well-posed, and objective. It represents a standard application of Receiver Operating Characteristic (ROC) analysis in evaluating a binary classifier. All necessary data and definitions are provided and are internally consistent. We may therefore proceed with the solution.\n\nThe problem requires the construction of an empirical ROC curve and the calculation of the Area Under this Curve (AUC) for a given set of classifier scores.\n\nFirst, we establish the given information. The set of scores for diseased cases is $S_D = \\{0.3, 0.6, 0.9\\}$, and the number of diseased cases is $N_D = 3$. The set of scores for nondiseased cases is $S_{ND} = \\{0.1, 0.2, 0.4, 0.8\\}$, and the number of nondiseased cases is $N_{ND} = 4$.\n\nA decision threshold $\\tau$ is applied to the scores. A case is classified as positive if its score is greater than or equal to $\\tau$.\nThe True Positive Rate, $\\mathrm{TPR}(\\tau)$, is the fraction of diseased cases with scores $\\ge \\tau$:\n$$ \\mathrm{TPR}(\\tau) = \\frac{|\\{s \\in S_D \\mid s \\ge \\tau\\}|}{N_D} $$\nThe False Positive Rate, $\\mathrm{FPR}(\\tau)$, is the fraction of nondiseased cases with scores $\\ge \\tau$:\n$$ \\mathrm{FPR}(\\tau) = \\frac{|\\{s \\in S_{ND} \\mid s \\ge \\tau\\}|}{N_{ND}} $$\nThe ROC curve is a plot of $\\mathrm{TPR}$ versus $\\mathrm{FPR}$ for all possible thresholds $\\tau$.\n\nPart 1: Construct the empirical ROC curve.\nThe vertices of the empirical ROC curve are generated by considering thresholds at the values of the given scores. A standard method is to sort all scores in descending order and move the threshold down past each score. This generates a path on the $\\mathrm{FPR}$-$\\mathrm{TPR}$ plane.\nThe combined set of scores, sorted in descending order with their class (D for diseased, ND for nondiseased), is:\n$0.9(\\text{D}), 0.8(\\text{ND}), 0.6(\\text{D}), 0.4(\\text{ND}), 0.3(\\text{D}), 0.2(\\text{ND}), 0.1(\\text{ND})$\n\nThe curve starts at the point $(0, 0)$, which corresponds to a threshold $\\tau > 0.9$ where no cases are classified as positive. As the threshold is lowered, for each diseased case encountered, the curve moves up by a step of size $\\frac{1}{N_D} = \\frac{1}{3}$. For each nondiseased case encountered, the curve moves to the right by a step of size $\\frac{1}{N_{ND}} = \\frac{1}{4}$.\n\nLet the ordered points on the ROC curve be $(x_i, y_i)$, where $x_i = \\mathrm{FPR}$ and $y_i = \\mathrm{TPR}$.\n1.  Start at point $p_0 = (x_0, y_0) = (0, 0)$.\n2.  The highest score is $0.9$, which is from a diseased case. The curve moves up. $p_1 = (0, 0 + \\frac{1}{3}) = (0, \\frac{1}{3})$.\n3.  The next score is $0.8$, from a nondiseased case. The curve moves right. $p_2 = (0 + \\frac{1}{4}, \\frac{1}{3}) = (\\frac{1}{4}, \\frac{1}{3})$.\n4.  The next score is $0.6$, from a diseased case. The curve moves up. $p_3 = (\\frac{1}{4}, \\frac{1}{3} + \\frac{1}{3}) = (\\frac{1}{4}, \\frac{2}{3})$.\n5.  The next score is $0.4$, from a nondiseased case. The curve moves right. $p_4 = (\\frac{1}{4} + \\frac{1}{4}, \\frac{2}{3}) = (\\frac{1}{2}, \\frac{2}{3})$.\n6.  The next score is $0.3$, from a diseased case. The curve moves up. $p_5 = (\\frac{1}{2}, \\frac{2}{3} + \\frac{1}{3}) = (\\frac{1}{2}, 1)$.\n7.  The next score is $0.2$, from a nondiseased case. The curve moves right. $p_6 = (\\frac{1}{2} + \\frac{1}{4}, 1) = (\\frac{3}{4}, 1)$.\n8.  The final score is $0.1$, from a nondiseased case. The curve moves right. $p_7 = (\\frac{3}{4} + \\frac{1}{4}, 1) = (1, 1)$.\n\nThe sequence of vertices for the empirical ROC curve is:\n$p_0 = (0, 0)$\n$p_1 = (0, \\frac{1}{3})$\n$p_2 = (\\frac{1}{4}, \\frac{1}{3})$\n$p_3 = (\\frac{1}{4}, \\frac{2}{3})$\n$p_4 = (\\frac{1}{2}, \\frac{2}{3})$\n$p_5 = (\\frac{1}{2}, 1)$\n$p_6 = (\\frac{3}{4}, 1)$\n$p_7 = (1, 1)$\n\nPart 2: Compute the Area Under the Curve (AUC).\nThe AUC is calculated by summing the areas of the trapezoids formed by consecutive points $(x_{i-1}, y_{i-1})$ and $(x_i, y_i)$ and the $\\mathrm{FPR}$ axis. The area of each trapezoid is given by the formula:\n$$ A_i = (x_i - x_{i-1}) \\times \\frac{y_i + y_{i-1}}{2} $$\nThe total AUC is the sum of these areas:\n$$ \\mathrm{AUC} = \\sum_{i=1}^{7} A_i = \\sum_{i=1}^{7} (x_i - x_{i-1}) \\times \\frac{y_i + y_{i-1}}{2} $$\nWe compute the area for each segment of the curve:\n-   Area between $p_0$ and $p_1$: $A_1 = (0 - 0) \\times \\frac{\\frac{1}{3} + 0}{2} = 0$.\n-   Area between $p_1$ and $p_2$: $A_2 = (\\frac{1}{4} - 0) \\times \\frac{\\frac{1}{3} + \\frac{1}{3}}{2} = \\frac{1}{4} \\times \\frac{1}{3} = \\frac{1}{12}$.\n-   Area between $p_2$ and $p_3$: $A_3 = (\\frac{1}{4} - \\frac{1}{4}) \\times \\frac{\\frac{2}{3} + \\frac{1}{3}}{2} = 0$.\n-   Area between $p_3$ and $p_4$: $A_4 = (\\frac{1}{2} - \\frac{1}{4}) \\times \\frac{\\frac{2}{3} + \\frac{2}{3}}{2} = \\frac{1}{4} \\times \\frac{2}{3} = \\frac{2}{12} = \\frac{1}{6}$.\n-   Area between $p_4$ and $p_5$: $A_5 = (\\frac{1}{2} - \\frac{1}{2}) \\times \\frac{1 + \\frac{2}{3}}{2} = 0$.\n-   Area between $p_5$ and $p_6$: $A_6 = (\\frac{3}{4} - \\frac{1}{2}) \\times \\frac{1 + 1}{2} = \\frac{1}{4} \\times 1 = \\frac{1}{4}$.\n-   Area between $p_6$ and $p_7$: $A_7 = (1 - \\frac{3}{4}) \\times \\frac{1 + 1}{2} = \\frac{1}{4} \\times 1 = \\frac{1}{4}$.\n\nThe total AUC is the sum of these individual areas:\n$$ \\mathrm{AUC} = 0 + \\frac{1}{12} + 0 + \\frac{1}{6} + 0 + \\frac{1}{4} + \\frac{1}{4} $$\nTo sum these fractions, we find a common denominator, which is $12$:\n$$ \\mathrm{AUC} = \\frac{1}{12} + \\frac{2}{12} + \\frac{3}{12} + \\frac{3}{12} = \\frac{1+2+3+3}{12} = \\frac{9}{12} $$\nSimplifying the fraction gives the final result:\n$$ \\mathrm{AUC} = \\frac{3}{4} $$\nThis result can be verified using the Wilcoxon-Mann-Whitney U statistic, which states that the AUC is the probability that a randomly selected diseased case will have a higher score than a randomly selected nondiseased case. The number of pairs of one diseased and one nondiseased case is $N_D \\times N_{ND} = 3 \\times 4 = 12$. The number of pairs where the diseased score is higher is found to be $9$. Thus, the AUC is $\\frac{9}{12} = \\frac{3}{4}$, confirming our calculation.", "answer": "$$\\boxed{\\frac{3}{4}}$$", "id": "4918235"}, {"introduction": "While manual construction is instructive, real-world bioinformatics requires efficient, automated methods for performance evaluation. This practice challenges you to implement and compare two distinct but mathematically equivalent algorithms for calculating the AUC [@problem_id:4604304]. You will first compute the AUC geometrically using the trapezoidal rule on an empirically constructed ROC curve, then compute it probabilistically using the pairwise rank-sum formulation. This exercise not only builds crucial programming skills but also deepens your understanding of the AUC as both a geometric area and a measure of ranking quality.", "problem": "You are given several binary-labeled datasets consisting of real-valued scores from a classifier applied to biological samples. For each dataset, denote the labels by a vector $y \\in \\{0,1\\}^n$ with $y_i = 1$ for a positive sample and $y_i = 0$ for a negative sample, and denote the corresponding real-valued scores by a vector $s \\in \\mathbb{R}^n$. Let $P$ be the number of positives and $N$ be the number of negatives, with $P \\ge 1$ and $N \\ge 1$. Your task is to compute the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) in two ways and compare them.\n\nFundamental definitions to use:\n- Receiver Operating Characteristic (ROC) curve plots the False Positive Rate (FPR) on the horizontal axis versus the True Positive Rate (TPR) on the vertical axis as a discrimination threshold moves over the score range.\n- True Positive Rate (TPR) is defined as $\\mathrm{TPR} = \\mathrm{TP}/P$, where $\\mathrm{TP}$ is the number of true positives at a given threshold.\n- False Positive Rate (FPR) is defined as $\\mathrm{FPR} = \\mathrm{FP}/N$, where $\\mathrm{FP}$ is the number of false positives at a given threshold.\n- Area Under the Curve (AUC) is the area under the ROC curve.\n\nCompute the AUC as follows for each dataset:\n1) Empirical ROC with trapezoidal rule:\n   - Sweep a threshold from $+\\infty$ down to $-\\infty$. At each threshold, predict positive if $s_i \\ge \\tau$. Construct the empirical ROC by:\n     - Initializing at $(\\mathrm{FPR}, \\mathrm{TPR}) = (0,0)$.\n     - Processing distinct score levels in strictly decreasing order. At each distinct score value, simultaneously include all samples having that score (this correctly handles ties). Update $\\mathrm{TP}$ and $\\mathrm{FP}$, then compute the new $(\\mathrm{FPR}, \\mathrm{TPR})$ point and append it to the ROC polyline.\n     - The ROC ends at $(1,1)$ once all samples are included.\n   - Compute the AUC by applying the trapezoidal rule over the piecewise-linear ROC in the $\\mathrm{FPR}$–$\\mathrm{TPR}$ plane:\n     $$\\mathrm{AUC}_{\\text{trap}} = \\sum_{k=1}^{K} \\frac{\\mathrm{TPR}_{k} + \\mathrm{TPR}_{k-1}}{2}\\left(\\mathrm{FPR}_{k} - \\mathrm{FPR}_{k-1}\\right),$$\n     where the ROC points are indexed in order of increasing $\\mathrm{FPR}$, starting from $(\\mathrm{FPR}_0,\\mathrm{TPR}_0)=(0,0)$.\n2) Pairwise rank formulation:\n   - For every positive–negative pair $(i,j)$ with $y_i = 1$ and $y_j = 0$, compare their scores $s_i$ and $s_j$ and define a contribution of $1$ if $s_i  s_j$, a contribution of $0$ if $s_i  s_j$, and a contribution of $1/2$ if $s_i = s_j$.\n   - Define the pairwise AUC as the average contribution over all $P \\cdot N$ such pairs. Denote this by $\\mathrm{AUC}_{\\text{rank}}$.\n\nYour program must, for each dataset in the test suite below, compute:\n- $\\mathrm{AUC}_{\\text{trap}}$ via the empirical ROC and trapezoidal rule as described,\n- $\\mathrm{AUC}_{\\text{rank}}$ via the pairwise definition above,\n- The absolute difference $\\lvert \\mathrm{AUC}_{\\text{trap}} - \\mathrm{AUC}_{\\text{rank}} \\rvert$.\n\nAll three values for each dataset must be returned as floating-point numbers rounded to $6$ decimal places.\n\nTest suite:\n- Dataset $1$: $y = [\\,1,0,1,0,1,0,0,1,0,1\\,]$, $s = [\\,0.92,0.85,0.85,0.85,0.60,0.60,0.55,0.55,0.40,0.40\\,]$.\n- Dataset $2$: $y = [\\,1,1,1,0,0,0\\,]$, $s = [\\,0.90,0.80,0.70,0.60,0.20,0.10\\,]$.\n- Dataset $3$: $y = [\\,1,1,0,0\\,]$, $s = [\\,0.10,0.20,0.80,0.90\\,]$.\n- Dataset $4$: $y = [\\,1,1,0,0,0\\,]$, $s = [\\,0.50,0.50,0.50,0.50,0.50\\,]$.\n- Dataset $5$: $y = [\\,1,0,0,0\\,]$, $s = [\\,0.50,0.10,0.50,0.90\\,]$.\n- Dataset $6$: $y = [\\,1,1,1,0\\,]$, $s = [\\,0.20,0.50,0.80,0.50\\,]$.\n\nFinal output format:\n- Your program should produce a single line of output containing a single list that aggregates the results for all datasets in order. For each dataset, append three values in this order: $\\mathrm{AUC}_{\\text{trap}}$, $\\mathrm{AUC}_{\\text{rank}}$, and the absolute difference. Concatenate all datasets’ triples into one flat list. The final line must be a single comma-separated list enclosed in square brackets, with no spaces, for example $[\\text{v}_1,\\text{v}_2,\\ldots,\\text{v}_{3M}]$ for $M$ datasets.\n- All floats must be rounded to $6$ decimal places before printing.", "solution": "The problem requires the computation of the Area Under the Receiver Operating Characteristic Curve (AUC) for several datasets using two distinct, prescribed methods. The core scientific principle underlying this problem is the mathematical equivalence between the geometric interpretation of the AUC (as the area under a curve) and its probabilistic interpretation (related to the Mann-Whitney U statistic). We will first validate this principle by implementing both algorithms as specified and then comparing their outputs.\n\nA Receiver Operating Characteristic (ROC) curve is a graphical plot illustrating the diagnostic ability of a binary classifier system as its discrimination threshold is varied. It is created by plotting the True Positive Rate ($\\mathrm{TPR}$) against the False Positive Rate ($\\mathrm{FPR}$) at various threshold settings.\n- The True Positive Rate is given by $\\mathrm{TPR} = \\mathrm{TP}/P$, where $\\mathrm{TP}$ is the number of true positives and $P$ is the total number of positive samples.\n- The False Positive Rate is given by $\\mathrm{FPR} = \\mathrm{FP}/N$, where $\\mathrm{FP}$ is the number of false positives and $N$ is the total number of negative samples.\n\nThe AUC provides an aggregate measure of performance across all possible classification thresholds. An AUC of $1.0$ represents a perfect classifier, while an AUC of $0.5$ represents a classifier with no discriminative ability, equivalent to random guessing.\n\n### Method 1: Empirical ROC with Trapezoidal Rule ($\\mathrm{AUC}_{\\text{trap}}$)\n\nThis method constructs the ROC curve geometrically and then calculates the area underneath it. The algorithm proceeds as follows:\n\n1.  **Preparation**: Given the label vector $y$ and score vector $s$, we first determine the total counts of positive ($P$) and negative ($N$) samples.\n2.  **Thresholding and Point Generation**: The ROC curve is constructed by sweeping a decision threshold $\\tau$ from $+\\infty$ to $-\\infty$. A sample $i$ is classified as positive if its score $s_i \\ge \\tau$.\n    - We begin at the point $(\\mathrm{FPR}, \\mathrm{TPR}) = (0,0)$, which corresponds to a threshold $\\tau = +\\infty$ where no samples are classified as positive.\n    - The vertices of the ROC curve are generated by considering each unique score value present in the data, processed in strictly decreasing order.\n    - At each unique score value, we consider all samples that have this score. The change in the number of true positives ($\\Delta \\mathrm{TP}$) and false positives ($\\Delta \\mathrm{FP}$) is determined by the labels of these samples.\n    - The cumulative counts of true positives ($\\mathrm{TP}$) and false positives ($\\mathrm{FP}$) are updated.\n    - A new point on the ROC curve, $(\\mathrm{FPR}, \\mathrm{TPR}) = (\\mathrm{FP}/N, \\mathrm{TP}/P)$, is then recorded. This handling of ties ensures that a block of samples with the same score corresponds to a single diagonal segment on the ROC curve.\n    - The process continues until all samples have been included, at which point the curve terminates at $(\\mathrm{FPR}, \\mathrm{TPR}) = (1,1)$.\n3.  **Area Calculation**: The sequence of generated points defines a piecewise-linear path from $(0,0)$ to $(1,1)$. The area under this path, $\\mathrm{AUC}_{\\text{trap}}$, is calculated by applying the trapezoidal rule. For a sequence of ROC points $(\\mathrm{FPR}_k, \\mathrm{TPR}_k)$ indexed by increasing $\\mathrm{FPR}$:\n    $$\n    \\mathrm{AUC}_{\\text{trap}} = \\sum_{k=1}^{K} \\frac{\\mathrm{TPR}_{k} + \\mathrm{TPR}_{k-1}}{2}\\left(\\mathrm{FPR}_{k} - \\mathrm{FPR}_{k-1}\\right)\n    $$\n    where $(\\mathrm{FPR}_0, \\mathrm{TPR}_0) = (0,0)$. Each term in the sum represents the area of a single trapezoid formed by two consecutive points on the ROC curve and their projections onto the FPR axis.\n\n### Method 2: Pairwise Rank Formulation ($\\mathrm{AUC}_{\\text{rank}}$)\n\nThis method is based on the probabilistic interpretation of AUC. The AUC is equivalent to the probability that a randomly chosen positive sample is ranked higher than a randomly chosen negative sample. This can be calculated directly by examining all positive-negative pairs.\n\n1.  **Pairwise Comparison**: We form all possible pairs of samples $(i, j)$ such that sample $i$ is positive ($y_i=1$) and sample $j$ is negative ($y_j=0$). There are $P \\cdot N$ such pairs.\n2.  **Scoring**: Each pair is scored based on the classifier's output scores, $s_i$ and $s_j$:\n    - The pair contributes $1$ if the positive sample has a higher score ($s_i  s_j$).\n    - The pair contributes $0.5$ if the scores are tied ($s_i = s_j$).\n    - The pair contributes $0$ if the positive sample has a lower score ($s_i  s_j$).\n3.  **Averaging**: The value of $\\mathrm{AUC}_{\\text{rank}}$ is the sum of all these contributions, divided by the total number of pairs, $P \\cdot N$. This gives the average contribution, which is the empirical probability of correct ranking.\n    $$\n    \\mathrm{AUC}_{\\text{rank}} = \\frac{1}{P \\cdot N} \\sum_{i: y_i=1} \\sum_{j: y_j=0} \\mathbf{I}(s_i, s_j)\n    $$\n    where $\\mathbf{I}(s_i, s_j)$ is the scoring function defined above.\n\n### Equivalence and Implementation\n\nThe two formulations, $\\mathrm{AUC}_{\\text{trap}}$ and $\\mathrm{AUC}_{\\text{rank}}$, are mathematically equivalent. The problem requires implementing both distinct algorithms to demonstrate this equivalence numerically. The absolute difference $|\\mathrm{AUC}_{\\text{trap}} - \\mathrm{AUC}_{\\text{rank}}|$ is expected to be zero, or a very small number attributable to floating-point precision errors. Our implementation will compute these two values, along with their absolute difference, for each test dataset. All final numerical results will be rounded to six decimal places as required.", "answer": "```python\nimport numpy as np\n\ndef calculate_auc_trap(y, s):\n    \"\"\"\n    Computes AUC using the empirical ROC and trapezoidal rule.\n    \"\"\"\n    y = np.array(y)\n    s = np.array(s)\n\n    # Ensure there are both positive and negative samples\n    pos_mask = (y == 1)\n    neg_mask = (y == 0)\n    P = np.sum(pos_mask)\n    N = np.sum(neg_mask)\n    \n    if P == 0 or N == 0:\n        # According to the problem statement, P=1 and N=1.\n        # This case should not be reached with valid inputs.\n        return np.nan\n\n    # Get unique scores and sort them in descending order\n    unique_scores = np.unique(s)[::-1]\n    \n    # Initialize ROC curve points and counters\n    roc_points = [(0.0, 0.0)]\n    tp, fp = 0, 0\n    \n    # Process each distinct score level\n    for thresh in unique_scores:\n        # Find all samples with the current score\n        mask = (s == thresh)\n        \n        # Count positives and negatives at this score\n        delta_tp = np.sum(pos_mask[mask])\n        delta_fp = np.sum(neg_mask[mask])\n        \n        # Update cumulative counts\n        tp += delta_tp\n        fp += delta_fp\n        \n        # Calculate TPR and FPR and add a new point to the ROC curve\n        tpr = tp / P\n        fpr = fp / N\n        roc_points.append((fpr, tpr))\n        \n    # Calculate AUC using the trapezoidal rule\n    auc = 0.0\n    for i in range(1, len(roc_points)):\n        fpr_i, tpr_i = roc_points[i]\n        fpr_im1, tpr_im1 = roc_points[i-1]\n        \n        # Area of the trapezoid between point i-1 and i\n        auc += (tpr_i + tpr_im1) * (fpr_i - fpr_im1) / 2.0\n            \n    return auc\n\ndef calculate_auc_rank(y, s):\n    \"\"\"\n    Computes AUC using the pairwise rank formulation.\n    \"\"\"\n    y = np.array(y)\n    s = np.array(s)\n\n    # Separate scores for positive and negative samples\n    pos_scores = s[y == 1]\n    neg_scores = s[y == 0]\n    \n    P = len(pos_scores)\n    N = len(neg_scores)\n    \n    if P == 0 or N == 0:\n        # According to the problem statement, P=1 and N=1.\n        # This case should not be reached with valid inputs.\n        return np.nan\n        \n    # Sum contributions from all positive-negative pairs\n    rank_sum = 0.0\n    for s_pos in pos_scores:\n        for s_neg in neg_scores:\n            if s_pos  s_neg:\n                rank_sum += 1.0\n            elif s_pos == s_neg:\n                rank_sum += 0.5\n    \n    # The AUC is the average contribution\n    auc = rank_sum / (P * N)\n    return auc\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        (\n            [1, 0, 1, 0, 1, 0, 0, 1, 0, 1],\n            [0.92, 0.85, 0.85, 0.85, 0.60, 0.60, 0.55, 0.55, 0.40, 0.40]\n        ),\n        (\n            [1, 1, 1, 0, 0, 0],\n            [0.90, 0.80, 0.70, 0.60, 0.20, 0.10]\n        ),\n        (\n            [1, 1, 0, 0],\n            [0.10, 0.20, 0.80, 0.90]\n        ),\n        (\n            [1, 1, 0, 0, 0],\n            [0.50, 0.50, 0.50, 0.50, 0.50]\n        ),\n        (\n            [1, 0, 0, 0],\n            [0.50, 0.10, 0.50, 0.90]\n        ),\n        (\n            [1, 1, 1, 0],\n            [0.20, 0.50, 0.80, 0.50]\n        )\n    ]\n\n    all_results = []\n    \n    for y_data, s_data in test_cases:\n        # Compute AUC using both methods\n        auc_trap = calculate_auc_trap(y_data, s_data)\n        auc_rank = calculate_auc_rank(y_data, s_data)\n        \n        # Compute the absolute difference\n        diff = abs(auc_trap - auc_rank)\n        \n        # Append the formatted results to the list\n        all_results.append(\"{:.6f}\".format(auc_trap))\n        all_results.append(\"{:.6f}\".format(auc_rank))\n        all_results.append(\"{:.6f}\".format(diff))\n\n    # Print the final list in the specified format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "4604304"}, {"introduction": "In scientific practice, a single point estimate like the AUC is incomplete without a measure of its statistical uncertainty. This advanced exercise moves beyond simple calculation to the critical task of statistical inference for the AUC [@problem_id:4604295]. You will explore the DeLong method, a standard non-parametric approach based on U-statistics, to estimate the variance of the empirical AUC. By applying this method to compute a confidence interval, you will learn how to quantify the reliability of your performance metric, a vital skill for making sound statistical conclusions about classifier performance.", "problem": "Consider a binary classification biomarker studied in a case-control design, where the biomarker score $S$ is measured on $n_1$ diseased subjects and $n_0$ non-diseased subjects. The Receiver Operating Characteristic (ROC) curve is the set of points tracing the True Positive Rate against the False Positive Rate as the decision threshold varies, and the Area Under the Curve (AUC) is defined as the probability that a randomly chosen diseased subject has a higher score than a randomly chosen non-diseased subject. Formally, for diseased scores $S_1$ and non-diseased scores $S_0$ drawn independently from their respective populations, the Area Under the Curve (AUC) satisfies $AUC = \\mathbb{P}(S_1  S_0)$.\n\nStarting from the definition of $AUC$ as the expectation of an indicator kernel, $AUC = \\mathbb{E}\\big[\\mathbf{1}\\{S_1  S_0\\}\\big]$, and the theory of U-statistics, derive an asymptotically valid variance estimator for the empirical $AUC$ based on the indicator kernel $\\mathbf{1}\\{S_1  S_0\\}$ under the assumptions of independent and identically distributed samples within each class and independence across classes. Use this derivation to obtain a consistent estimator for the asymptotic variance in terms of the per-diseased and per-non-diseased influence values. Then, apply your derivation to the following observed biomarker scores, which contain no ties:\n- Diseased ($n_1 = 6$): $0.82,\\, 0.76,\\, 0.67,\\, 0.59,\\, 0.71,\\, 0.64$.\n- Non-diseased ($n_0 = 7$): $0.41,\\, 0.55,\\, 0.49,\\, 0.58,\\, 0.62,\\, 0.73,\\, 0.60$.\n\nCompute the empirical $AUC$, the DeLong variance estimator derived via the U-statistics influence-function decomposition, and use asymptotic normality to construct the $(1 - \\alpha)$ confidence interval with $\\alpha = 0.05$. Report only the upper endpoint of this confidence interval as your final answer. Round your final answer to four significant figures. Express the final number as a decimal.", "solution": "This problem requires the derivation and application of the DeLong method to estimate the variance of the empirical Area Under the Curve (AUC) and construct a 95% confidence interval.\n\n**1. Derivation and Formulation**\n\nLet $\\{X_i\\}_{i=1}^{n_1}$ be the scores from $n_1$ diseased subjects and $\\{Y_j\\}_{j=1}^{n_0}$ be scores from $n_0$ non-diseased subjects. The empirical AUC is a U-statistic given by:\n$$ \\widehat{AUC} = \\frac{1}{n_1 n_0} \\sum_{i=1}^{n_1} \\sum_{j=1}^{n_0} \\mathbf{1}\\{X_i > Y_j\\} $$\nThe DeLong method estimates the variance of $\\widehat{AUC}$ based on the sample variances of its influence components. For each diseased score $X_i$ and non-diseased score $Y_j$, we define these components as:\n$$ V_{10}(X_i) = \\frac{1}{n_0} \\sum_{k=1}^{n_0} \\mathbf{1}\\{X_i > Y_k\\} \\quad \\text{and} \\quad V_{01}(Y_j) = \\frac{1}{n_1} \\sum_{k=1}^{n_1} \\mathbf{1}\\{X_k > Y_j\\} $$\nThe sample variances of these components, $S_{10}$ and $S_{01}$, are computed as:\n$$ S_{10} = \\frac{1}{n_1-1} \\sum_{i=1}^{n_1} (V_{10}(X_i) - \\widehat{AUC})^2 \\quad \\text{and} \\quad S_{01} = \\frac{1}{n_0-1} \\sum_{j=1}^{n_0} (V_{01}(Y_j) - \\widehat{AUC})^2 $$\nThe DeLong variance estimator for $\\widehat{AUC}$ is then:\n$$ \\widehat{\\text{Var}}(\\widehat{AUC}) = \\frac{S_{10}}{n_1} + \\frac{S_{01}}{n_0} $$\nA $(1-\\alpha)$ confidence interval for the true AUC is constructed using the normal approximation:\n$$ \\widehat{AUC} \\pm z_{1-\\alpha/2} \\sqrt{\\widehat{\\text{Var}}(\\widehat{AUC})} $$\n\n**2. Calculation**\n\nGiven data:\n- Diseased ($n_1 = 6$): $D = \\{0.82,\\, 0.76,\\, 0.67,\\, 0.59,\\, 0.71,\\, 0.64\\}$\n- Non-diseased ($n_0 = 7$): $N = \\{0.41,\\, 0.55,\\, 0.49,\\, 0.58,\\, 0.62,\\, 0.73,\\, 0.60\\}$\n\nFirst, we compute the empirical AUC by counting pairs $(X_i, Y_j)$ with $X_i > Y_j$. The total count is $7+7+6+4+6+6 = 36$.\n$$ \\widehat{AUC} = \\frac{36}{6 \\times 7} = \\frac{36}{42} = \\frac{6}{7} $$\n\nNext, we calculate the components $V_{10}(X_i)$ and their sample variance $S_{10}$:\n- $V_{10}$ components: $\\{7/7, 7/7, 6/7, 4/7, 6/7, 6/7\\}$\n$$ S_{10} = \\frac{1}{5} \\left[ 2 \\cdot (1 - \\frac{6}{7})^2 + (\\frac{4}{7} - \\frac{6}{7})^2 \\right] = \\frac{1}{5} \\left[ 2 \\cdot (\\frac{1}{49}) + \\frac{4}{49} \\right] = \\frac{6}{245} $$\n\nThen, we calculate the components $V_{01}(Y_j)$ and their sample variance $S_{01}$. For each $Y_j$, we count how many $X_i$ scores are greater, which yields counts of $\\{6, 6, 6, 6, 5, 2, 5\\}$.\n- $V_{01}$ components: $\\{6/6, 6/6, 6/6, 6/6, 5/6, 2/6, 5/6\\}$\n$$ S_{01} = \\frac{1}{6} \\left[ 4(1-\\frac{6}{7})^2 + 2(\\frac{5}{6}-\\frac{6}{7})^2 + (\\frac{2}{6}-\\frac{6}{7})^2 \\right] = \\frac{1}{6} \\left[ 4(\\frac{1}{49}) + 2(\\frac{1}{1764}) + (\\frac{-11}{21})^2 \\right] $$\n$$ S_{01} = \\frac{1}{6} \\left[ \\frac{144+2+484}{1764} \\right] = \\frac{1}{6} \\frac{630}{1764} = \\frac{5}{84} $$\nThe variance of $\\widehat{AUC}$ is:\n$$ \\widehat{\\text{Var}}(\\widehat{AUC}) = \\frac{S_{10}}{n_1} + \\frac{S_{01}}{n_0} = \\frac{6/245}{6} + \\frac{5/84}{7} = \\frac{1}{245} + \\frac{5}{588} = \\frac{12+25}{2940} = \\frac{37}{2940} $$\n\n**3. Confidence Interval**\n\nFor a 95% confidence interval, $z_{0.975} \\approx 1.96$.\nThe standard error is $SE(\\widehat{AUC}) = \\sqrt{37/2940} \\approx 0.112183$.\nThe upper endpoint of the confidence interval is:\n$$ \\text{Upper Endpoint} = \\widehat{AUC} + z_{0.975} \\times SE(\\widehat{AUC}) = \\frac{6}{7} + 1.96 \\times \\sqrt{\\frac{37}{2940}} $$\n$$ \\text{Upper Endpoint} \\approx 0.857143 + 1.96 \\times 0.112183 \\approx 1.077022 $$\nRounding to four significant figures, the upper endpoint is 1.077. The value exceeds 1 because the normal approximation was used on a small sample, which is a known possibility for this method.", "answer": "$$\\boxed{1.077}$$", "id": "4604295"}]}