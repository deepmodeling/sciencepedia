{"hands_on_practices": [{"introduction": "The most intuitive metric, accuracy, measures the overall fraction of correct predictions. However, in medical diagnostics where datasets are often highly imbalanced, accuracy can be a misleading indicator of a model's utility. This exercise [@problem_id:4561150] provides a hands-on calculation to demonstrate this pitfall, tasking you with computing and comparing standard accuracy against balanced accuracy for a sepsis detection model, revealing how the latter provides a more honest assessment of performance across different classes.", "problem": "A hospital quality improvement team is evaluating a binary classifier for early Sepsis-3 detection from electronic health records in an adult intensive care unit. The test set contains $N$ patient-episodes, each labeled by clinicians as either sepsis-positive or sepsis-negative within a $6$-hour prediction window. The evaluation yields the following confusion matrix counts: True Positive (TP) cases $TP = 280$, False Positive (FP) cases $FP = 2{,}880$, True Negative (TN) cases $TN = 16{,}320$, and False Negative (FN) cases $FN = 520$. Using the canonical definitions of class-conditional rates and overall correctness grounded in the confusion matrix, compute both the standard accuracy and the balanced accuracy for this classifier. Then, quantify their discrepancy as the difference defined by $($standard accuracy$)$ $-$ $($balanced accuracy$)$. Report only this discrepancy as your final numerical answer, expressed as a decimal fraction and rounded to four significant figures.", "solution": "The user has requested the computation of the discrepancy between standard accuracy and balanced accuracy for a binary classifier based on a provided confusion matrix.\n\nFirst, a validation of the problem statement is necessary.\n\n**Step 1: Extract Givens**\nThe problem provides the following counts from a confusion matrix for a binary classification task:\n-   True Positives: $TP = 280$\n-   False Positives: $FP = 2,880$\n-   True Negatives: $TN = 16,320$\n-   False Negatives: $FN = 520$\nThe task is to compute the difference: $($standard accuracy$)$ $-$ $($balanced accuracy$)$, and report the result rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, using standard and well-defined metrics from the field of machine learning and medical statistics (accuracy, balanced accuracy, confusion matrix). The context of Sepsis-3 detection is a valid and significant area of research in bioinformatics. The provided data are numerical counts, which are internally consistent. The total number of patient-episodes, $N$, can be calculated as the sum of all confusion matrix entries. The problem is well-posed, objective, and contains all necessary information to derive a unique solution. No scientific principles are violated, and the data, while indicative of a highly imbalanced dataset, are plausible for a real-world medical screening scenario.\n\n**Verdict**\nThe problem is valid. The solution process may proceed.\n\n**Solution Derivation**\nThe objective is to compute the discrepancy, $\\Delta$, defined as the difference between the standard accuracy ($ACC$) and the balanced accuracy ($BA$).\n$$ \\Delta = ACC - BA $$\n\nFirst, we define the standard accuracy. It is the ratio of all correct predictions to the total number of predictions.\n$$ ACC = \\frac{TP + TN}{TP + FP + TN + FN} $$\n\nNext, we define the balanced accuracy. It is the arithmetic mean of the True Positive Rate ($TPR$) and the True Negative Rate ($TNR$).\n$$ BA = \\frac{TPR + TNR}{2} $$\n\nThe True Positive Rate, also known as sensitivity or recall, is the proportion of actual positives that are correctly identified.\n$$ TPR = \\frac{TP}{TP + FN} $$\n\nThe True Negative Rate, also known as specificity, is the proportion of actual negatives that are correctly identified.\n$$ TNR = \\frac{TN}{TN + FP} $$\n\nWe now substitute the given values into these definitions.\n-   $TP = 280$\n-   $FP = 2,880$\n-   $TN = 16,320$\n-   $FN = 520$\n\nFirst, let us compute the total number of samples, $N$.\n$$ N = TP + FP + TN + FN = 280 + 2,880 + 16,320 + 520 = 20,000 $$\n\nNow, we compute the standard accuracy ($ACC$).\n$$ ACC = \\frac{TP + TN}{N} = \\frac{280 + 16,320}{20,000} = \\frac{16,600}{20,000} = 0.83 $$\n\nNext, we compute the number of actual positives ($P$) and actual negatives ($N_{neg}$).\n-   Actual Positives: $P = TP + FN = 280 + 520 = 800$\n-   Actual Negatives: $N_{neg} = TN + FP = 16,320 + 2,880 = 19,200$\n\nWe can now calculate the $TPR$ and $TNR$.\n$$ TPR = \\frac{TP}{P} = \\frac{280}{800} = \\frac{28}{80} = \\frac{7}{20} = 0.35 $$\n$$ TNR = \\frac{TN}{N_{neg}} = \\frac{16,320}{19,200} = \\frac{1,632}{1,920} = \\frac{17 \\times 96}{20 \\times 96} = \\frac{17}{20} = 0.85 $$\n\nWith $TPR$ and $TNR$, we compute the balanced accuracy ($BA$).\n$$ BA = \\frac{TPR + TNR}{2} = \\frac{0.35 + 0.85}{2} = \\frac{1.20}{2} = 0.60 $$\n\nFinally, we compute the required discrepancy, $\\Delta$.\n$$ \\Delta = ACC - BA = 0.83 - 0.60 = 0.23 $$\n\nThe problem requires the answer to be expressed as a decimal fraction rounded to four significant figures. The calculated value $0.23$ can be written as $0.2300$ to adhere to this requirement. This discrepancy highlights how standard accuracy can be a misleading metric in the presence of class imbalance. The high accuracy of $83\\%$ is primarily driven by the model's ability to correctly classify the majority negative class, whereas the balanced accuracy of $60\\%$ provides a more honest assessment by equally weighting the performance on both the positive and negative classes, revealing poor performance on the clinically critical positive (sepsis) class ($TPR = 35\\%$).", "answer": "$$\\boxed{0.2300}$$", "id": "4561150"}, {"introduction": "Building on the issue of class imbalance, we now explore the 'accuracy paradox' using the $F_1$-score, a metric that provides the harmonic mean of precision and recall. A classifier can achieve very high accuracy simply by predicting the majority class, yet be completely useless for identifying rare positive cases. In this practice [@problem_id:4561157], you will analyze several classifier outputs to identify which ones exhibit this deceptive combination of high accuracy and a near-zero $F_1$-score, sharpening your ability to critically evaluate model performance beyond a single, simplistic number.", "problem": "A rare adverse drug reaction phenotype is screened in a biobank cohort using a binary classifier. Let the cohort size be $N = 100{,}000$, with disease prevalence $\\pi = 0.001$, so the number of truly positive individuals is $P = \\pi N = 100$ and the number of truly negative individuals is $N - P = 99{,}900$. For any binary classifier, the confusion matrix counts are defined as True Positive (TP), False Positive (FP), True Negative (TN), and False Negative (FN). The standard evaluation metrics in classification, namely accuracy, precision, recall, and the $F_1$-score (the $F_1$-score is the harmonic mean of precision and recall), are derived from these counts through their foundational definitions.\n\nConsider five candidate operating points of the same model, each yielding a different confusion matrix on this cohort. Using only the fundamental definitions of the confusion matrix counts and the named evaluation metrics, determine which options simultaneously exhibit both high accuracy and near-zero $F_1$-score in the sense that accuracy is at least $99\\%$ and $F_1 \\le 0.02$.\n\nSelect all that apply.\n\nA. $(TP, FP, TN, FN) = ($0$, $0$, $99{,}900$, $100)$\n\nB. $(TP, FP, TN, FN) = ($1$, $9$, $99{,}891$, $99)$\n\nC. $(TP, FP, TN, FN) = ($80$, $20$, $99{,}880$, $20)$\n\nD. $(TP, FP, TN, FN) = ($20$, $5{,}000$, $94{,}900$, $80)$\n\nE. $(TP, FP, TN, FN) = ($5$, $500$, $99{,}400$, $95)$", "solution": "The problem statement will be validated before proceeding to a solution.\n\n### Step 1: Extract Givens\n\n- Cohort size: $N = 100{,}000$\n- Disease prevalence: $\\pi = 0.001$\n- Number of truly positive individuals (cases): $P = \\pi N = 0.001 \\times 100{,}000 = 100$\n- Number of truly negative individuals (controls): $N - P = 100{,}000 - 100 = 99{,}900$\n- Confusion matrix counts: True Positive ($TP$), False Positive ($FP$), True Negative ($TN$), False Negative ($FN$).\n- Evaluation metrics: accuracy, precision, recall, and the $F_1$-score.\n- $F_1$-score definition: harmonic mean of precision and recall.\n- Conditions for selection:\n    1. Accuracy $\\ge 99\\%$ (i.e., $\\ge 0.99$)\n    2. $F_1$-score $\\le 0.02$\n- Candidate operating points as tuples of $(TP, FP, TN, FN)$:\n    - A: $(0, 0, 99{,}900, 100)$\n    - B: $(1, 9, 99{,}891, 99)$\n    - C: $(80, 20, 99{,}880, 20)$\n    - D: $(20, 5{,}000, 94{,}900, 80)$\n    - E: $(5, 500, 99{,}400, 95)$\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement must be evaluated for scientific soundness, consistency, and well-posedness.\n\n1.  **Scientific Grounding and Objectivity**: The problem is grounded in the standard, universally accepted definitions of classification evaluation metrics used in machine learning, statistics, and bioinformatics. All terms are objective and precisely defined.\n2.  **Well-Posedness and Consistency**: A crucial consistency check is whether the provided confusion matrix counts for each option sum to the correct number of positive and negative cases.\n    - Total positives must equal $P = TP + FN = 100$.\n    - Total negatives must equal $N - P = TN + FP = 99{,}900$.\n\n    Let's check each option:\n    - **A**: $TP + FN = 0 + 100 = 100$. $TN + FP = 99{,}900 + 0 = 99{,}900$. **Consistent.**\n    - **B**: $TP + FN = 1 + 99 = 100$. $TN + FP = 99{,}891 + 9 = 99{,}900$. **Consistent.**\n    - **C**: $TP + FN = 80 + 20 = 100$. $TN + FP = 99{,}880 + 20 = 99{,}900$. **Consistent.**\n    - **D**: $TP + FN = 20 + 80 = 100$. $TN + FP = 94{,}900 + 5{,}000 = 99{,}900$. **Consistent.**\n    - **E**: $TP + FN = 5 + 95 = 100$. $TN + FP = 99{,}400 + 500 = 99{,}900$. **Consistent.**\n\nAll options are internally consistent with the specified cohort composition. The problem is unambiguous, provides all necessary information, and does not violate any scientific or mathematical principles.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. A solution will be derived.\n\n### Derivation of Metrics and Option Analysis\n\nThe required evaluation metrics are defined as follows:\n\n-   **Accuracy**: $Accuracy = \\frac{TP + TN}{TP + FP + TN + FN} = \\frac{TP + TN}{N}$\n-   **Precision**: $Precision = \\frac{TP}{TP + FP}$\n-   **Recall**: $Recall = \\frac{TP}{TP + FN} = \\frac{TP}{P}$\n-   **$F_1$-score**: The harmonic mean of precision and recall.\n    $$F_1 = \\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall} = \\frac{2TP}{2TP + FP + FN}$$\n    If $TP = 0$, then $Precision$ and $Recall$ are $0$, and by convention, $F_1 = 0$. The formula provided is robust to this case.\n\nThe conditions to be met are $Accuracy \\ge 0.99$ and $F_1 \\le 0.02$. We will now evaluate each option against these two conditions.\n\n#### Option A: $(TP, FP, TN, FN) = (0, 0, 99{,}900, 100)$\n\n-   **Accuracy**:\n    $$Accuracy = \\frac{0 + 99{,}900}{100{,}000} = 0.999$$\n    The condition $0.999 \\ge 0.99$ is **satisfied**.\n-   **$F_1$-score**:\n    Since $TP = 0$, by definition, $F_1 = 0$.\n    The condition $0 \\le 0.02$ is **satisfied**.\n\nBoth conditions are met. Therefore, option A is correct.\n\n#### Option B: $(TP, FP, TN, FN) = (1, 9, 99{,}891, 99)$\n\n-   **Accuracy**:\n    $$Accuracy = \\frac{1 + 99{,}891}{100{,}000} = \\frac{99{,}892}{100{,}000} = 0.99892$$\n    The condition $0.99892 \\ge 0.99$ is **satisfied**.\n-   **$F_1$-score**:\n    $$F_1 = \\frac{2TP}{2TP + FP + FN} = \\frac{2 \\cdot 1}{2 \\cdot 1 + 9 + 99} = \\frac{2}{2 + 108} = \\frac{2}{110} \\approx 0.01818$$\n    The condition $0.01818 \\le 0.02$ is **satisfied**.\n\nBoth conditions are met. Therefore, option B is correct.\n\n#### Option C: $(TP, FP, TN, FN) = (80, 20, 99{,}880, 20)$\n\n-   **Accuracy**:\n    $$Accuracy = \\frac{80 + 99{,}880}{100{,}000} = \\frac{99{,}960}{100{,}000} = 0.9996$$\n    The condition $0.9996 \\ge 0.99$ is **satisfied**.\n-   **$F_1$-score**:\n    $$F_1 = \\frac{2TP}{2TP + FP + FN} = \\frac{2 \\cdot 80}{2 \\cdot 80 + 20 + 20} = \\frac{160}{160 + 40} = \\frac{160}{200} = 0.8$$\n    The condition $0.8 \\le 0.02$ is **not satisfied**.\n\nOne condition is not met. Therefore, option C is incorrect.\n\n#### Option D: $(TP, FP, TN, FN) = (20, 5{,}000, 94{,}900, 80)$\n\n-   **Accuracy**:\n    $$Accuracy = \\frac{20 + 94{,}900}{100{,}000} = \\frac{94{,}920}{100{,}000} = 0.9492$$\n    The condition $0.9492 \\ge 0.99$ is **not satisfied**.\n\nAs the accuracy condition is not met, there is no need to calculate the $F_1$-score. Therefore, option D is incorrect.\n\n#### Option E: $(TP, FP, TN, FN) = (5, 500, 99{,}400, 95)$\n\n-   **Accuracy**:\n    $$Accuracy = \\frac{5 + 99{,}400}{100{,}000} = \\frac{99{,}405}{100{,}000} = 0.99405$$\n    The condition $0.99405 \\ge 0.99$ is **satisfied**.\n-   **$F_1$-score**:\n    $$F_1 = \\frac{2TP}{2TP + FP + FN} = \\frac{2 \\cdot 5}{2 \\cdot 5 + 500 + 95} = \\frac{10}{10 + 595} = \\frac{10}{605} = \\frac{2}{121} \\approx 0.01653$$\n    The condition $0.01653 \\le 0.02$ is **satisfied**.\n\nBoth conditions are met. Therefore, option E is correct.\n\n### Summary of Option Evaluation\n- **Option A**: Accuracy is $99.9\\%$. $F_1$-score is $0$. **Correct.**\n- **Option B**: Accuracy is $99.892\\%$. $F_1$-score is $\\approx 0.0182$. **Correct.**\n- **Option C**: Accuracy is $99.96\\%$. $F_1$-score is $0.8$. **Incorrect.**\n- **Option D**: Accuracy is $94.92\\%$. **Incorrect.**\n- **Option E**: Accuracy is $99.405\\%$. $F_1$-score is $\\approx 0.0165$. **Correct.**\n\nThe options that satisfy both conditions ($Accuracy \\ge 0.99$ and $F_1 \\le 0.02$) are A, B, and E.", "answer": "$$\\boxed{ABE}$$", "id": "4561157"}, {"introduction": "We now advance from threshold-specific metrics to the Area Under the ROC Curve ($AUC$), a popular metric that assesses a model's ability to discriminate between classes across all possible thresholds. While a high $AUC$ indicates good discriminative power, it is agnostic to class prevalence and may not reflect a model's practical utility. This challenging exercise [@problem_id:3118923] guides you to derive from first principles how a model with excellent $AUC$ can have an extremely low Positive Predictive Value ($PPV$), underscoring why reporting prevalence-sensitive metrics like $PPV$ is essential in real-world applications.", "problem": "A binary classifier produces a continuous score $S$ used to decide class membership by thresholding: predict $\\hat{Y} = 1$ if $S \\ge \\tau$ and $\\hat{Y} = 0$ otherwise. Suppose the class-conditional score distributions are Gaussian with equal variance and a location shift: $S \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$ and $S \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$, with $\\mu_{0} = 0$, $\\mu_{1} = 0.2$, and $\\sigma = 0.1$. The prevalence of the positive class is $\\pi = \\mathbb{P}(Y=1) = 0.001$, representing an extremely imbalanced scenario. Use the following core definitions: the Area Under the Receiver Operating Characteristic (ROC) Curve (AUC) is $AUC = \\mathbb{P}(S_{1}  S_{0})$ where $S_{1} \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$ and $S_{0} \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$ are independent; the True Positive Rate (TPR) and False Positive Rate (FPR) at threshold $\\tau$ are $\\mathrm{TPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=1)$ and $\\mathrm{FPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=0)$; the Positive Predictive Value (PPV) at threshold $\\tau$ is $\\mathrm{PPV}(\\tau) = \\mathbb{P}(Y=1 \\mid S \\ge \\tau)$.\n\nStarting from these definitions and without using any pre-derived shortcut formulas, do the following:\n1. Derive $AUC$ from first principles using the stated Gaussian model and confirm numerically that $AUC  0.9$.\n2. Derive $\\mathrm{TPR}(\\tau)$ and $\\mathrm{FPR}(\\tau)$ for the Gaussian model, then use Bayes’ rule to express $\\mathrm{PPV}(\\tau)$ in terms of $\\pi$, $\\mathrm{TPR}(\\tau)$, and $\\mathrm{FPR}(\\tau)$. Define “reasonable thresholds” as those satisfying $\\mathrm{TPR}(\\tau) \\ge 0.5$. Show which $\\tau$ in this set maximizes $\\mathrm{PPV}(\\tau)$ and compute the corresponding maximal $\\mathrm{PPV}$ value. Round your final numerical answer to four significant figures and express it as a plain decimal (no percent sign).\n\nFinally, interpret the result to explain why, in extremely imbalanced settings, reporting the Positive Predictive Value (PPV) alongside the Area Under the Receiver Operating Characteristic Curve (AUC) is necessary to understand practical utility.\n\nProvide only the numerical value of the maximal $\\mathrm{PPV}$ under the constraint $\\mathrm{TPR}(\\tau) \\ge 0.5$, rounded to four significant figures, as your final answer.", "solution": "The problem is assessed to be valid as it is scientifically grounded in probability theory and statistical learning, well-posed with all necessary definitions and parameters, and objective. There are no contradictions, ambiguities, or factual unsoundness.\n\nThe problem asks for a multi-part derivation and calculation concerning binary classifier evaluation metrics under a specific Gaussian model.\n\n**Part 1: AUC Derivation and Confirmation**\n\nThe Area Under the ROC Curve (AUC) is defined as the probability that a randomly drawn positive instance has a higher score than a randomly drawn negative instance: $AUC = \\mathbb{P}(S_{1} > S_{0})$. Here, $S_{1} \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$ and $S_{0} \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$ are independent random variables representing scores from the positive and negative classes, respectively.\n\nLet us define a new random variable $D = S_{1} - S_{0}$. The probability we wish to compute is $\\mathbb{P}(D > 0)$. Since $S_{1}$ and $S_{0}$ are independent Gaussian random variables, their difference $D$ is also a Gaussian random variable. Its mean and variance are:\n$$\n\\mathbb{E}[D] = \\mathbb{E}[S_{1}] - \\mathbb{E}[S_{0}] = \\mu_{1} - \\mu_{0}\n$$\n$$\n\\mathrm{Var}(D) = \\mathrm{Var}(S_{1} - S_{0}) = \\mathrm{Var}(S_{1}) + (-1)^{2}\\mathrm{Var}(S_{0}) = \\sigma^{2} + \\sigma^{2} = 2\\sigma^{2}\n$$\nSo, $D \\sim \\mathcal{N}(\\mu_{1} - \\mu_{0}, 2\\sigma^{2})$. To find $\\mathbb{P}(D > 0)$, we standardize the variable $D$:\n$$\n\\mathbb{P}(D > 0) = \\mathbb{P}\\left(\\frac{D - (\\mu_{1} - \\mu_{0})}{\\sqrt{2\\sigma^{2}}} > \\frac{0 - (\\mu_{1} - \\mu_{0})}{\\sqrt{2\\sigma^{2}}}\\right)\n$$\nLet $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$. The expression becomes:\n$$\nAUC = \\mathbb{P}\\left(Z > -\\frac{\\mu_{1} - \\mu_{0}}{\\sigma\\sqrt{2}}\\right)\n$$\nUsing the symmetry of the standard normal distribution, $\\mathbb{P}(Z > -z) = \\mathbb{P}(Z  z)$, which is the cumulative distribution function (CDF) of the standard normal distribution, denoted $\\Phi(z)$.\n$$\nAUC = \\Phi\\left(\\frac{\\mu_{1} - \\mu_{0}}{\\sigma\\sqrt{2}}\\right)\n$$\nWe are given $\\mu_{1} = 0.2$, $\\mu_{0} = 0$, and $\\sigma = 0.1$. Substituting these values:\n$$\nAUC = \\Phi\\left(\\frac{0.2 - 0}{0.1\\sqrt{2}}\\right) = \\Phi\\left(\\frac{2}{\\sqrt{2}}\\right) = \\Phi(\\sqrt{2})\n$$\nNumerically, $\\sqrt{2} \\approx 1.414$. The value of the standard normal CDF is $\\Phi(1.414) \\approx 0.92135$. This value is greater than $0.9$, which confirms the condition stated in the problem.\n\n**Part 2: PPV Derivation and Maximization**\n\nFirst, we derive the expressions for the True Positive Rate ($\\mathrm{TPR}$) and False Positive Rate ($\\mathrm{FPR}$) at a given threshold $\\tau$.\n$\\mathrm{TPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=1)$. The score distribution for the positive class is $S \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$.\n$$\n\\mathrm{TPR}(\\tau) = \\mathbb{P}\\left(\\frac{S - \\mu_{1}}{\\sigma} \\ge \\frac{\\tau - \\mu_{1}}{\\sigma} \\mid Y=1\\right) = \\mathbb{P}\\left(Z \\ge \\frac{\\tau - \\mu_{1}}{\\sigma}\\right) = 1 - \\Phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right)\n$$\n$\\mathrm{FPR}(\\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=0)$. The score distribution for the negative class is $S \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$.\n$$\n\\mathrm{FPR}(\\tau) = \\mathbb{P}\\left(\\frac{S - \\mu_{0}}{\\sigma} \\ge \\frac{\\tau - \\mu_{0}}{\\sigma} \\mid Y=0\\right) = \\mathbb{P}\\left(Z \\ge \\frac{\\tau - \\mu_{0}}{\\sigma}\\right) = 1 - \\Phi\\left(\\frac{\\tau - \\mu_{0}}{\\sigma}\\right)\n$$\nNext, we express the Positive Predictive Value ($\\mathrm{PPV}$) using Bayes' rule.\n$$\n\\mathrm{PPV}(\\tau) = \\mathbb{P}(Y=1 \\mid S \\ge \\tau) = \\frac{\\mathbb{P}(S \\ge \\tau \\mid Y=1) \\mathbb{P}(Y=1)}{\\mathbb{P}(S \\ge \\tau)}\n$$\nThe denominator is the total probability $\\mathbb{P}(S \\ge \\tau) = \\mathbb{P}(S \\ge \\tau \\mid Y=1)\\mathbb{P}(Y=1) + \\mathbb{P}(S \\ge \\tau \\mid Y=0)\\mathbb{P}(Y=0)$.\nUsing the a priori definitions with prevalence $\\pi = \\mathbb{P}(Y=1)$:\n$$\n\\mathrm{PPV}(\\tau) = \\frac{\\mathrm{TPR}(\\tau) \\cdot \\pi}{\\mathrm{TPR}(\\tau) \\cdot \\pi + \\mathrm{FPR}(\\tau) \\cdot (1-\\pi)}\n$$\nWe need to maximize this $\\mathrm{PPV}(\\tau)$ for \"reasonable thresholds\" defined by $\\mathrm{TPR}(\\tau) \\ge 0.5$.\n$$\n1 - \\Phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right) \\ge 0.5 \\implies \\Phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right) \\le 0.5\n$$\nSince $\\Phi(z)$ is a monotonically increasing function and $\\Phi(0) = 0.5$, this inequality is equivalent to:\n$$\n\\frac{\\tau - \\mu_{1}}{\\sigma} \\le 0 \\implies \\tau \\le \\mu_{1}\n$$\nSo, the set of reasonable thresholds is the interval $(-\\infty, \\mu_{1}]$. To maximize $\\mathrm{PPV}(\\tau)$, we can analyze the behavior of the likelihood ratio $L(\\tau) = \\frac{\\mathrm{TPR}(\\tau)}{\\mathrm{FPR}(\\tau)}$, as $\\mathrm{PPV}(\\tau) = \\frac{L(\\tau)\\pi}{L(\\tau)\\pi + (1-\\pi)}$ is a monotonically increasing function of $L(\\tau)$.\n$$\nL(\\tau) = \\frac{1 - \\Phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right)}{1 - \\Phi\\left(\\frac{\\tau - \\mu_{0}}{\\sigma}\\right)}\n$$\nThe derivative of $\\ln(L(\\tau))$ with respect to $\\tau$ is given by:\n$$\n\\frac{d}{d\\tau}\\ln(L(\\tau)) = \\frac{1}{\\sigma}\\left[ \\frac{\\phi\\left(\\frac{\\tau - \\mu_{0}}{\\sigma}\\right)}{1 - \\Phi\\left(\\frac{\\tau - \\mu_{0}}{\\sigma}\\right)} - \\frac{\\phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right)}{1 - \\Phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right)} \\right]\n$$\nwhere $\\phi(z)$ is the standard normal PDF. The term $h(z) = \\frac{\\phi(z)}{1-\\Phi(z)}$ is the hazard rate of the standard normal distribution, which is a strictly increasing function of $z$.\nSince $\\mu_{1} > \\mu_{0}$, we have $\\frac{\\tau - \\mu_{1}}{\\sigma}  \\frac{\\tau - \\mu_{0}}{\\sigma}$. Because $h(z)$ is increasing, $h\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right)  h\\left(\\frac{\\tau - \\mu_{0}}{\\sigma}\\right)$. Consequently, the derivative $\\frac{d}{d\\tau}\\ln(L(\\tau))$ is always positive. This means $L(\\tau)$ is a monotonically increasing function of $\\tau$, and therefore $\\mathrm{PPV}(\\tau)$ is also monotonically increasing with $\\tau$.\n\nTo maximize $\\mathrm{PPV}(\\tau)$ over the set $\\tau \\in (-\\infty, \\mu_{1}]$, we must choose the largest possible value of $\\tau$, which is the right boundary of the interval, $\\tau = \\mu_{1}$.\n\nSo, the maximal PPV is achieved at $\\tau = \\mu_{1} = 0.2$. Let's compute the value.\nAt $\\tau = 0.2$:\n$$\n\\mathrm{TPR}(0.2) = 1 - \\Phi\\left(\\frac{0.2 - 0.2}{0.1}\\right) = 1 - \\Phi(0) = 1 - 0.5 = 0.5\n$$\n$$\n\\mathrm{FPR}(0.2) = 1 - \\Phi\\left(\\frac{0.2 - 0}{0.1}\\right) = 1 - \\Phi(2)\n$$\nUsing the value $\\Phi(2) \\approx 0.97725$, we get $\\mathrm{FPR}(0.2) \\approx 1 - 0.97725 = 0.02275$.\nThe prevalence is $\\pi = 0.001$. Now we compute the maximal PPV:\n$$\n\\mathrm{PPV}_{\\max} = \\mathrm{PPV}(0.2) = \\frac{0.5 \\times 0.001}{0.5 \\times 0.001 + (1 - \\Phi(2)) \\times (1 - 0.001)}\n$$\n$$\n\\mathrm{PPV}_{\\max} \\approx \\frac{0.0005}{0.0005 + 0.02275 \\times 0.999} = \\frac{0.0005}{0.0005 + 0.02272725} = \\frac{0.0005}{0.02322725} \\approx 0.02152644\n$$\nRounding to four significant figures, the maximal PPV is $0.02153$.\n\n**Interpretation**\n\nThe result reveals a critical disconnect between two key performance metrics. The AUC of approximately $0.921$ suggests the classifier has excellent discriminative capability, meaning it is very good at ranking positive instances higher than negative ones. In a prevalence-agnostic sense, the model is strong.\n\nHowever, the maximal Positive Predictive Value (PPV) under a reasonable constraint ($\\mathrm{TPR} \\ge 0.5$) is only about $0.0215$. This means that even when the classifier is tuned to its optimal point within this range, only about $2.15\\%$ of the instances it predicts as positive are actually positive. Over $97\\%$ of its positive predictions are false alarms.\n\nThis discrepancy arises because of the extreme class imbalance ($\\pi=0.001$). The AUC is independent of class prevalence, measuring only the separation of the score distributions. In contrast, the PPV is highly sensitive to prevalence. With a vast majority of negative instances ($99.9\\%$), even a low False Positive Rate (FPR $\\approx 2.28\\%$) generates an absolute number of false positives that completely overwhelms the number of true positives.\n\nTherefore, for practical applications in imbalanced domains like rare disease screening or fraud detection, reporting a high AUC alone can be dangerously misleading. It advertises a model's potential but hides its poor real-world performance. The PPV provides the necessary context, revealing the high cost of false alarms and giving a realistic assessment of the model's practical utility. Reporting both metrics is essential: AUC for the model's intrinsic separability and PPV for its predictive performance in the context of the actual class distribution.", "answer": "$$\\boxed{0.02153}$$", "id": "3118923"}]}