{"hands_on_practices": [{"introduction": "While statistical software can fit a logistic regression model in an instant, a deep understanding requires looking under the hood at the optimization algorithm. This first practice invites you to perform one step of the Iteratively Reweighted Least Squares (IRLS) algorithm, which is equivalent to Fisher scoring for logistic regression. By manually calculating the update for the model parameters, you will gain a concrete understanding of how the model learns from data by iteratively minimizing error, a foundational concept in machine learning and statistical inference. [@problem_id:4579254]", "problem": "A translational oncology team is modeling the probability that a breast tumor exhibits an aggressive phenotype as a function of a single standardized messenger ribonucleic acid (mRNA) biomarker’s log-expression. For patient $i$ with standardized log-expression $z_i$, the binary outcome $y_i \\in \\{0,1\\}$ indicates non-aggressive ($y_i = 0$) or aggressive ($y_i = 1$). The team fits a binary logistic regression with canonical logit link, linear predictor $\\eta_i = \\alpha + \\beta z_i$, and mean response $\\mu_i = \\Pr(y_i = 1 \\mid z_i)$. They plan to compute one iteration of Iteratively Reweighted Least Squares (IRLS) or equivalently one Fisher scoring step starting from the initial parameter vector $(\\alpha, \\beta) = (0, 0)$.\n\nYou are given $n = 5$ patients with standardized biomarker values and outcomes\n$$(z_1, z_2, z_3, z_4, z_5) = (-2, -1, 0, 1, 2), \\quad (y_1, y_2, y_3, y_4, y_5) = (0, 0, 0, 1, 1).$$\nAssume the canonical logit link for binary outcomes and use the standard generalized linear model framework grounded in the Bernoulli likelihood, the score function, and the expected Fisher information. From these principles, derive the one-step Fisher scoring (IRLS) update and compute the updated slope parameter $\\beta$ after this single iteration starting from $(\\alpha, \\beta) = (0, 0)$. Express your final answer as an exact real number. No rounding is required.", "solution": "The user wants to compute one Fisher scoring update for the slope parameter of a logistic regression model.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   Model: Binary logistic regression with canonical logit link.\n-   Response variable: $y_i \\in \\{0,1\\}$, where $1$ denotes an aggressive phenotype.\n-   Predictor variable: $z_i$, a standardized log-expression of a biomarker.\n-   Linear predictor: $\\eta_i = \\alpha + \\beta z_i$.\n-   Mean response: $\\mu_i = \\Pr(y_i = 1 \\mid z_i) = \\frac{\\exp(\\eta_i)}{1 + \\exp(\\eta_i)}$.\n-   Algorithm: One iteration of Fisher scoring (or Iteratively Reweighted Least Squares, IRLS).\n-   Initial parameters: $(\\alpha^{(0)}, \\beta^{(0)}) = (0, 0)$.\n-   Number of patients: $n=5$.\n-   Predictor values: $(z_1, z_2, z_3, z_4, z_5) = (-2, -1, 0, 1, 2)$.\n-   Outcome values: $(y_1, y_2, y_3, y_4, y_5) = (0, 0, 0, 1, 1)$.\n-   Objective: Compute the updated slope parameter $\\beta$ after one iteration, denoted as $\\beta^{(1)}$.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The problem is based on the standard and well-established theory of Generalized Linear Models (GLMs), specifically logistic regression and the Fisher scoring algorithm. This is a fundamental topic in biostatistics and medical data analytics. The problem is scientifically sound.\n-   **Well-Posed**: The problem is clearly defined, with all necessary data and initial conditions provided. The task is to compute a single, uniquely determined value.\n-   **Objective**: The problem is stated in precise, objective mathematical and statistical terms.\n-   **Completeness and Consistency**: The problem is self-contained. The number of data points for predictors and outcomes match ($n=5$). No contradictions are present.\n-   **Realism and Feasibility**: The data values are simple integers, typical for a textbook problem, and are not physically or dimensionally inconsistent.\n-   **Structure and Other Criteria**: The problem is well-structured and is a standard application of the Fisher scoring algorithm. It is not trivial, metaphorical, or unverifiable.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n### Solution\n\nThe problem requires a single step of the Fisher scoring algorithm to update the parameters of a logistic regression model. The general form of the Fisher scoring update for the parameter vector $\\boldsymbol{\\theta}$ at iteration $k$ is:\n$$ \\boldsymbol{\\theta}^{(k+1)} = \\boldsymbol{\\theta}^{(k)} + \\boldsymbol{I}(\\boldsymbol{\\theta}^{(k)})^{-1} \\boldsymbol{U}(\\boldsymbol{\\theta}^{(k)}) $$\nwhere $\\boldsymbol{U}(\\boldsymbol{\\theta}^{(k)})$ is the score vector (the gradient of the log-likelihood) and $\\boldsymbol{I}(\\boldsymbol{\\theta}^{(k)})$ is the expected Fisher information matrix, both evaluated at $\\boldsymbol{\\theta}^{(k)}$.\n\nFor a Generalized Linear Model (GLM) with a canonical link function, such as the logit link for a Bernoulli response, these components have specific forms. The parameter vector is $\\boldsymbol{\\theta} = \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}$.\n\nThe score vector is given by $\\boldsymbol{U}(\\boldsymbol{\\theta}) = \\boldsymbol{X}^T (\\boldsymbol{y} - \\boldsymbol{\\mu})$, where $\\boldsymbol{X}$ is the design matrix, $\\boldsymbol{y}$ is the vector of outcomes, and $\\boldsymbol{\\mu}$ is the vector of mean responses (probabilities).\n\nThe Fisher information matrix is given by $\\boldsymbol{I}(\\boldsymbol{\\theta}) = \\boldsymbol{X}^T \\boldsymbol{W} \\boldsymbol{X}$, where $\\boldsymbol{W}$ is a diagonal matrix of weights with diagonal elements $W_{ii} = \\text{Var}(y_i) = \\mu_i (1 - \\mu_i)$.\n\nSo, the update rule becomes:\n$$ \\boldsymbol{\\theta}^{(k+1)} = \\boldsymbol{\\theta}^{(k)} + (\\boldsymbol{X}^T \\boldsymbol{W}^{(k)} \\boldsymbol{X})^{-1} \\boldsymbol{X}^T (\\boldsymbol{y} - \\boldsymbol{\\mu}^{(k)}) $$\n\nWe are asked to perform one iteration, starting from $k=0$ with $\\boldsymbol{\\theta}^{(0)} = \\begin{pmatrix} \\alpha^{(0)} \\\\ \\beta^{(0)} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n\n**1. Define the matrices and vectors from the given data:**\nThe number of observations is $n=5$.\nThe vector of outcomes is $\\boldsymbol{y} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 1 \\end{pmatrix}$.\nThe design matrix $\\boldsymbol{X}$ includes a column of $1$s for the intercept $\\alpha$ and a column of $z_i$ values for the slope $\\beta$:\n$$ \\boldsymbol{X} = \\begin{pmatrix} 1  z_1 \\\\ 1  z_2 \\\\ 1  z_3 \\\\ 1  z_4 \\\\ 1  z_5 \\end{pmatrix} = \\begin{pmatrix} 1  -2 \\\\ 1  -1 \\\\ 1  0 \\\\ 1  1 \\\\ 1  2 \\end{pmatrix} $$\n\n**2. Calculate initial values at $k=0$:**\nThe initial parameter vector is $\\boldsymbol{\\theta}^{(0)} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\nThe linear predictor is $\\boldsymbol{\\eta}^{(0)} = \\boldsymbol{X} \\boldsymbol{\\theta}^{(0)} = \\begin{pmatrix} 1  -2 \\\\ 1  -1 \\\\ 1  0 \\\\ 1  1 \\\\ 1  2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$.\n\nThe mean response $\\mu_i$ is calculated using the inverse logit (logistic) function: $\\mu_i = \\frac{1}{1 + \\exp(-\\eta_i)}$.\nFor each patient $i$, $\\eta_i^{(0)} = 0$, so the initial predicted probability is:\n$$ \\mu_i^{(0)} = \\frac{1}{1 + \\exp(-0)} = \\frac{1}{1 + 1} = \\frac{1}{2} $$\nThe vector of initial mean responses is $\\boldsymbol{\\mu}^{(0)} = \\begin{pmatrix} 1/2 \\\\ 1/2 \\\\ 1/2 \\\\ 1/2 \\\\ 1/2 \\end{pmatrix}$.\n\n**3. Calculate the components for the update:**\nFirst, the vector of residuals $(\\boldsymbol{y} - \\boldsymbol{\\mu}^{(0)})$ is:\n$$ \\boldsymbol{y} - \\boldsymbol{\\mu}^{(0)} = \\begin{pmatrix} 0 - 1/2 \\\\ 0 - 1/2 \\\\ 0 - 1/2 \\\\ 1 - 1/2 \\\\ 1 - 1/2 \\end{pmatrix} = \\begin{pmatrix} -1/2 \\\\ -1/2 \\\\ -1/2 \\\\ 1/2 \\\\ 1/2 \\end{pmatrix} $$\n\nNext, the weight matrix $\\boldsymbol{W}^{(0)}$ has diagonal elements $W_{ii}^{(0)} = \\mu_i^{(0)}(1 - \\mu_i^{(0)})$.\n$$ W_{ii}^{(0)} = \\frac{1}{2} \\left(1 - \\frac{1}{2}\\right) = \\frac{1}{4} \\quad \\text{for all } i=1, \\dots, 5 $$\nSo, $\\boldsymbol{W}^{(0)}$ is a diagonal matrix with all diagonal entries equal to $\\frac{1}{4}$:\n$$ \\boldsymbol{W}^{(0)} = \\frac{1}{4} \\boldsymbol{I}_5, \\quad \\text{where } \\boldsymbol{I}_5 \\text{ is the } 5 \\times 5 \\text{ identity matrix.} $$\n\n**4. Calculate the score vector $\\boldsymbol{U}(\\boldsymbol{\\theta}^{(0)})$:**\n$$ \\boldsymbol{U}(\\boldsymbol{\\theta}^{(0)}) = \\boldsymbol{X}^T (\\boldsymbol{y} - \\boldsymbol{\\mu}^{(0)}) = \\begin{pmatrix} 1  1  1  1  1 \\\\ -2  -1  0  1  2 \\end{pmatrix} \\begin{pmatrix} -1/2 \\\\ -1/2 \\\\ -1/2 \\\\ 1/2 \\\\ 1/2 \\end{pmatrix} $$\nThe first component is $\\sum_{i=1}^5 (y_i - \\mu_i^{(0)}) = 1(-\\frac{1}{2}) + 1(-\\frac{1}{2}) + 1(-\\frac{1}{2}) + 1(\\frac{1}{2}) + 1(\\frac{1}{2}) = -\\frac{1}{2}$.\nThe second component is $\\sum_{i=1}^5 z_i (y_i - \\mu_i^{(0)}) = (-2)(-\\frac{1}{2}) + (-1)(-\\frac{1}{2}) + (0)(-\\frac{1}{2}) + (1)(\\frac{1}{2}) + (2)(\\frac{1}{2}) = 1 + \\frac{1}{2} + 0 + \\frac{1}{2} + 1 = 3$.\nSo, the score vector is $\\boldsymbol{U}(\\boldsymbol{\\theta}^{(0)}) = \\begin{pmatrix} -1/2 \\\\ 3 \\end{pmatrix}$.\n\n**5. Calculate the Fisher information matrix $\\boldsymbol{I}(\\boldsymbol{\\theta}^{(0)})$:**\n$$ \\boldsymbol{I}(\\boldsymbol{\\theta}^{(0)}) = \\boldsymbol{X}^T \\boldsymbol{W}^{(0)} \\boldsymbol{X} = \\boldsymbol{X}^T \\left(\\frac{1}{4}\\boldsymbol{I}_5\\right) \\boldsymbol{X} = \\frac{1}{4} \\boldsymbol{X}^T \\boldsymbol{X} $$\nWe first compute $\\boldsymbol{X}^T \\boldsymbol{X}$:\n$$ \\boldsymbol{X}^T \\boldsymbol{X} = \\begin{pmatrix} \\sum 1  \\sum z_i \\\\ \\sum z_i  \\sum z_i^2 \\end{pmatrix} $$\n$\\sum 1 = 5$.\n$\\sum z_i = -2 - 1 + 0 + 1 + 2 = 0$.\n$\\sum z_i^2 = (-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2 = 4 + 1 + 0 + 1 + 4 = 10$.\nSo, $\\boldsymbol{X}^T \\boldsymbol{X} = \\begin{pmatrix} 5  0 \\\\ 0  10 \\end{pmatrix}$.\nThe Fisher information matrix is:\n$$ \\boldsymbol{I}(\\boldsymbol{\\theta}^{(0)}) = \\frac{1}{4} \\begin{pmatrix} 5  0 \\\\ 0  10 \\end{pmatrix} = \\begin{pmatrix} 5/4  0 \\\\ 0  10/4 \\end{pmatrix} = \\begin{pmatrix} 5/4  0 \\\\ 0  5/2 \\end{pmatrix} $$\n\n**6. Compute the updated parameter vector $\\boldsymbol{\\theta}^{(1)}$:**\nThe inverse of the Fisher information matrix is:\n$$ \\boldsymbol{I}(\\boldsymbol{\\theta}^{(0)})^{-1} = \\begin{pmatrix} 5/4  0 \\\\ 0  5/2 \\end{pmatrix}^{-1} = \\begin{pmatrix} 4/5  0 \\\\ 0  2/5 \\end{pmatrix} $$\nNow we can compute the update step:\n$$ \\boldsymbol{I}(\\boldsymbol{\\theta}^{(0)})^{-1} \\boldsymbol{U}(\\boldsymbol{\\theta}^{(0)}) = \\begin{pmatrix} 4/5  0 \\\\ 0  2/5 \\end{pmatrix} \\begin{pmatrix} -1/2 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} (4/5)(-1/2) \\\\ (2/5)(3) \\end{pmatrix} = \\begin{pmatrix} -4/10 \\\\ 6/5 \\end{pmatrix} = \\begin{pmatrix} -2/5 \\\\ 6/5 \\end{pmatrix} $$\nThe updated parameter vector is:\n$$ \\boldsymbol{\\theta}^{(1)} = \\boldsymbol{\\theta}^{(0)} + \\boldsymbol{I}(\\boldsymbol{\\theta}^{(0)})^{-1} \\boldsymbol{U}(\\boldsymbol{\\theta}^{(0)}) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} -2/5 \\\\ 6/5 \\end{pmatrix} = \\begin{pmatrix} -2/5 \\\\ 6/5 \\end{pmatrix} $$\nThis gives the updated parameters $\\alpha^{(1)} = -2/5$ and $\\beta^{(1)} = 6/5$.\n\nThe problem asks for the updated slope parameter $\\beta$ after this single iteration, which is $\\beta^{(1)}$.\n$$ \\beta^{(1)} = \\frac{6}{5} $$", "answer": "$$\\boxed{\\frac{6}{5}}$$", "id": "4579254"}, {"introduction": "Once a model is fit, the next crucial step is interpretation. The coefficients in a logistic regression model live on the log-odds scale, which can be hard to translate into clinical impact. This exercise guides you through calculating the marginal effect of a predictor on the probability scale, a much more intuitive metric. You will see firsthand how the effect of a biomarker on disease risk is not a fixed number but changes depending on a patient's other characteristics, a vital concept when working with complex models that include interaction terms. [@problem_id:4579257]", "problem": "A clinical bioinformatics study investigates the occurrence of Acute Kidney Injury (AKI) within $48$ hours ($Y \\in \\{0,1\\}$) among Intensive Care Unit patients. The binary outcome $Y$ is modeled with logistic regression, where the log-odds of AKI are a linear function of covariates. The predictors are: standardized log-transformed Interleukin-$6$ messenger Ribonucleic Acid (mRNA) expression from Ribonucleic Acid sequencing (RNA-seq) quantified as transcripts per million ($x_1$), baseline serum creatinine standardized to the cohort ($x_2$), and a Single Nucleotide Polymorphism (SNP) genotype indicator ($x_3 \\in \\{0,1\\}$) for presence of the minor allele. An interaction between gene expression and genotype is included, yielding the linear predictor with coefficients $\\beta_0$, $\\beta_1$, $\\beta_2$, $\\beta_3$, and $\\beta_{13}$.\n\nThe fitted coefficients are $\\beta_0=-1.5$, $\\beta_1=0.9$, $\\beta_2=0.6$, $\\beta_3=-0.4$, and $\\beta_{13}=0.7$. Consider three held-out patients with covariates:\n- Patient A: $x_1=0.3$, $x_2=1.1$, $x_3=1$.\n- Patient B: $x_1=-0.5$, $x_2=0.9$, $x_3=0$.\n- Patient C: $x_1=1.0$, $x_2=1.5$, $x_3=1$.\n\nStarting from the core definition that logistic regression models the log-odds linearly in the covariates and connects the probability $\\Pr(Y=1 \\mid \\mathbf{x})$ to the linear predictor through the inverse-logit mapping, derive from first principles the instantaneous marginal effect of $x_1$ on $\\Pr(Y=1 \\mid \\mathbf{x})$ and use it to obtain a first-order approximation of the average change in the probability of AKI across these three patients when $x_1$ is increased by a small increment $\\Delta x_1=0.1$ while $x_2$ and $x_3$ are held fixed at their given values.\n\nExpress your final scalar answer as a decimal and round to four significant figures.", "solution": "The problem is scientifically grounded, well-posed, objective, and complete. It describes a standard application of logistic regression in biostatistics, providing a fully specified model, all necessary parameters, and a clear, answerable question. Therefore, it is a valid problem.\n\nLet $Y$ be the binary outcome variable, where $Y=1$ indicates the occurrence of Acute Kidney Injury (AKI) and $Y=0$ indicates its absence. The vector of covariates is $\\mathbf{x} = (x_1, x_2, x_3)^T$. The logistic regression model links the probability of AKI, $p(\\mathbf{x}) = \\Pr(Y=1 \\mid \\mathbf{x})$, to a linear predictor, $\\eta(\\mathbf{x})$, through the logit link function. The inverse of the logit link, the logistic (or sigmoid) function, gives the probability:\n$$p(\\mathbf{x}) = \\frac{\\exp(\\eta(\\mathbf{x}))}{1 + \\exp(\\eta(\\mathbf{x}))} = \\frac{1}{1 + \\exp(-\\eta(\\mathbf{x}))}$$\nThe problem specifies that the model includes an interaction between the gene expression predictor $x_1$ and the SNP genotype indicator $x_3$. The linear predictor is therefore:\n$$\\eta(\\mathbf{x}) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_{13} x_1 x_3$$\n\nThe first task is to derive the instantaneous marginal effect of $x_1$ on the probability $p(\\mathbf{x})$, which is the partial derivative $\\frac{\\partial p(\\mathbf{x})}{\\partial x_1}$. We use the chain rule:\n$$\\frac{\\partial p(\\mathbf{x})}{\\partial x_1} = \\frac{dp}{d\\eta} \\frac{\\partial \\eta}{\\partial x_1}$$\n\nFirst, we find the derivative of the logistic function $p(\\eta)$ with respect to its argument $\\eta$:\n$$\\frac{dp}{d\\eta} = \\frac{d}{d\\eta} \\left( \\frac{\\exp(\\eta)}{1 + \\exp(\\eta)} \\right)$$\nUsing the quotient rule, we have:\n$$\\frac{dp}{d\\eta} = \\frac{\\exp(\\eta)(1 + \\exp(\\eta)) - \\exp(\\eta)(\\exp(\\eta))}{(1 + \\exp(\\eta))^2} = \\frac{\\exp(\\eta)}{(1 + \\exp(\\eta))^2}$$\nThis expression can be rewritten in terms of $p(\\eta)$ itself:\n$$\\frac{dp}{d\\eta} = \\left( \\frac{\\exp(\\eta)}{1 + \\exp(\\eta)} \\right) \\left( \\frac{1}{1 + \\exp(\\eta)} \\right) = p(\\eta)(1 - p(\\eta))$$\n\nNext, we find the partial derivative of the linear predictor $\\eta(\\mathbf{x})$ with respect to $x_1$:\n$$\\frac{\\partial \\eta}{\\partial x_1} = \\frac{\\partial}{\\partial x_1} (\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_{13} x_1 x_3) = \\beta_1 + \\beta_{13} x_3$$\nNote that this derivative depends on the value of $x_3$ due to the interaction term.\n\nCombining these two results, the instantaneous marginal effect of $x_1$ is:\n$$\\frac{\\partial p(\\mathbf{x})}{\\partial x_1} = p(\\mathbf{x})(1-p(\\mathbf{x}))(\\beta_1 + \\beta_{13} x_3)$$\n\nThe problem asks for a first-order approximation of the change in probability, $\\Delta p$, for a small increment $\\Delta x_1$. This is given by:\n$$\\Delta p(\\mathbf{x}) \\approx \\frac{\\partial p(\\mathbf{x})}{\\partial x_1} \\Delta x_1 = p(\\mathbf{x})(1-p(\\mathbf{x}))(\\beta_1 + \\beta_{13} x_3) \\Delta x_1$$\nWe are given the coefficients: $\\beta_0=-1.5$, $\\beta_1=0.9$, $\\beta_2=0.6$, $\\beta_3=-0.4$, $\\beta_{13}=0.7$, and the increment $\\Delta x_1 = 0.1$. We will now compute this quantity for each of the three patients.\n\nFor Patient A: $x_1 = 0.3$, $x_2 = 1.1$, $x_3 = 1$.\n1.  Calculate the linear predictor $\\eta_A$:\n    $$\\eta_A = -1.5 + (0.9)(0.3) + (0.6)(1.1) + (-0.4)(1) + (0.7)(0.3)(1)$$\n    $$\\eta_A = -1.5 + 0.27 + 0.66 - 0.4 + 0.21 = -0.76$$\n2.  Calculate the probability $p_A$:\n    $$p_A = \\frac{1}{1 + \\exp(-\\eta_A)} = \\frac{1}{1 + \\exp(0.76)} \\approx 0.318642$$\n3.  Calculate the approximate change in probability $\\Delta p_A$:\n    $$\\frac{\\partial \\eta_A}{\\partial x_1} = \\beta_1 + \\beta_{13} x_{A,3} = 0.9 + (0.7)(1) = 1.6$$\n    $$\\Delta p_A \\approx p_A(1-p_A)\\left(\\frac{\\partial \\eta_A}{\\partial x_1}\\right)\\Delta x_1 \\approx (0.318642)(1-0.318642)(1.6)(0.1)$$\n    $$\\Delta p_A \\approx (0.217093)(1.6)(0.1) \\approx 0.034735$$\n\nFor Patient B: $x_1 = -0.5$, $x_2 = 0.9$, $x_3 = 0$.\n1.  Calculate the linear predictor $\\eta_B$:\n    $$\\eta_B = -1.5 + (0.9)(-0.5) + (0.6)(0.9) + (-0.4)(0) + (0.7)(-0.5)(0)$$\n    $$\\eta_B = -1.5 - 0.45 + 0.54 + 0 + 0 = -1.41$$\n2.  Calculate the probability $p_B$:\n    $$p_B = \\frac{1}{1 + \\exp(-\\eta_B)} = \\frac{1}{1 + \\exp(1.41)} \\approx 0.196233$$\n3.  Calculate the approximate change in probability $\\Delta p_B$:\n    $$\\frac{\\partial \\eta_B}{\\partial x_1} = \\beta_1 + \\beta_{13} x_{B,3} = 0.9 + (0.7)(0) = 0.9$$\n    $$\\Delta p_B \\approx p_B(1-p_B)\\left(\\frac{\\partial \\eta_B}{\\partial x_1}\\right)\\Delta x_1 \\approx (0.196233)(1-0.196233)(0.9)(0.1)$$\n    $$\\Delta p_B \\approx (0.157718)(0.9)(0.1) \\approx 0.014195$$\n\nFor Patient C: $x_1 = 1.0$, $x_2 = 1.5$, $x_3 = 1$.\n1.  Calculate the linear predictor $\\eta_C$:\n    $$\\eta_C = -1.5 + (0.9)(1.0) + (0.6)(1.5) + (-0.4)(1) + (0.7)(1.0)(1)$$\n    $$\\eta_C = -1.5 + 0.9 + 0.9 - 0.4 + 0.7 = 0.6$$\n2.  Calculate the probability $p_C$:\n    $$p_C = \\frac{1}{1 + \\exp(-\\eta_C)} = \\frac{1}{1 + \\exp(-0.6)} \\approx 0.645656$$\n3.  Calculate the approximate change in probability $\\Delta p_C$:\n    $$\\frac{\\partial \\eta_C}{\\partial x_1} = \\beta_1 + \\beta_{13} x_{C,3} = 0.9 + (0.7)(1) = 1.6$$\n    $$\\Delta p_C \\approx p_C(1-p_C)\\left(\\frac{\\partial \\eta_C}{\\partial x_1}\\right)\\Delta x_1 \\approx (0.645656)(1-0.645656)(1.6)(0.1)$$\n    $$\\Delta p_C \\approx (0.228803)(1.6)(0.1) \\approx 0.036608$$\n\nFinally, we compute the average of these three changes in probability:\n$$\\overline{\\Delta p} = \\frac{\\Delta p_A + \\Delta p_B + \\Delta p_C}{3}$$\n$$\\overline{\\Delta p} \\approx \\frac{0.034735 + 0.014195 + 0.036608}{3} = \\frac{0.085538}{3} \\approx 0.0285127$$\nRounding to four significant figures, the average change in probability is $0.02851$.", "answer": "$$\\boxed{0.02851}$$", "id": "4579257"}, {"introduction": "The ultimate goal of many predictive models in medicine is to aid in decision-making by classifying patients. A logistic regression model provides a probability, but turning that into a classification requires choosing a decision threshold. This exercise simulates this critical final step, where you will evaluate a model's performance on a validation set, calculate its sensitivity and specificity at different thresholds, and use the Youden index to determine the optimal cutoff point for classification. [@problem_id:4579262]", "problem": "A clinical bioinformatics team trains a binary logistic regression model to predict early sepsis onset within $24$ hours from two predictors: a normalized gene-expression signature score $x_{g}$ (unitless $z$-score) and a vital-sign composite score $x_{v}$ (unitless). The model is specified by the log-odds (logit) of sepsis,\n$$\n\\eta_{i} \\equiv \\beta_{0} + \\beta_{g}\\,x_{g,i} + \\beta_{v}\\,x_{v,i},\n$$\nand the predicted probability\n$$\n\\hat{p}_{i} \\equiv \\frac{1}{1+\\exp\\!\\left(-\\eta_{i}\\right)}.\n$$\nOn a held-out validation set of $8$ patients, the estimated coefficients are $\\beta_{0}=-1$, $\\beta_{g}=0.8$, and $\\beta_{v}=-0.6$. The observed outcomes are $y_{i}\\in\\{0,1\\}$ with $1$ indicating sepsis. The predictor values and outcomes are:\n- Patient $1$: $(x_{g,1},x_{v,1})=(1,0)$, $y_{1}=0$.\n- Patient $2$: $(x_{g,2},x_{v,2})=(2,0)$, $y_{2}=1$.\n- Patient $3$: $(x_{g,3},x_{v,3})=(0,1)$, $y_{3}=0$.\n- Patient $4$: $(x_{g,4},x_{v,4})=(1,1)$, $y_{4}=0$.\n- Patient $5$: $(x_{g,5},x_{v,5})=(2,1)$, $y_{5}=1$.\n- Patient $6$: $(x_{g,6},x_{v,6})=(1,2)$, $y_{6}=0$.\n- Patient $7$: $(x_{g,7},x_{v,7})=(0,0)$, $y_{7}=0$.\n- Patient $8$: $(x_{g,8},x_{v,8})=(3,0)$, $y_{8}=1$.\n\nTo evaluate predictive performance as a function of a classification threshold $t\\in[0,1]$, adopt the rule “predict sepsis if and only if $\\hat{p}_{i}\\ge t$.” Define sensitivity as $\\mathrm{Se}(t)\\equiv \\mathrm{TP}(t)/P$ and specificity as $\\mathrm{Sp}(t)\\equiv \\mathrm{TN}(t)/N$, where $P$ and $N$ are the total counts of positives and negatives, respectively, and $\\mathrm{TP}(t)$ and $\\mathrm{TN}(t)$ are true positives and true negatives under threshold $t$. Consider the Youden index $J(t)\\equiv \\mathrm{Se}(t)+\\mathrm{Sp}(t)-1$.\n\nUsing only the model definition above and these core definitions, compute the predicted probabilities $\\hat{p}_{i}$, generate the set of candidate thresholds given by the midpoints between consecutive unique values of the $\\hat{p}_{i}$ (in increasing order), evaluate $J(t)$ at these candidates, and determine the threshold $t^{\\star}$ that maximizes $J(t)$. Round your final reported $t^{\\star}$ to four significant figures and express it as a decimal in $[0,1]$ with no unit.", "solution": "The problem statement provides a complete and consistent set of definitions, data, and objectives for evaluating a binary logistic regression model. It is scientifically grounded in standard statistical and bioinformatics practices and is well-posed, admitting a unique solution through a clearly defined procedure. Therefore, the problem is deemed valid.\n\nThe solution proceeds in the following steps:\n1.  Calculate the log-odds $\\eta_i$ and the predicted probability $\\hat{p}_i$ for each of the $N_{total}=8$ patients.\n2.  Identify the number of positive ($P$) and negative ($N$) cases from the observed outcomes $y_i$.\n3.  Sort the patients by their predicted probability $\\hat{p}_i$ and identify the unique values.\n4.  Determine the set of candidate thresholds $t$ as the midpoints between consecutive unique probabilities.\n5.  For each candidate threshold, calculate the number of true positives ($\\mathrm{TP}(t)$) and true negatives ($\\mathrm{TN}(t)$).\n6.  For each threshold, compute sensitivity $\\mathrm{Se}(t)$, specificity $\\mathrm{Sp}(t)$, and the Youden index $J(t)$.\n7.  Identify the threshold $t^{\\star}$ that maximizes $J(t)$.\n\nThe log-odds $\\eta_i$ and predicted probability $\\hat{p}_i$ are given by:\n$$\n\\eta_{i} = \\beta_{0} + \\beta_{g}\\,x_{g,i} + \\beta_{v}\\,x_{v,i}\n$$\n$$\n\\hat{p}_{i} = \\frac{1}{1+\\exp(-\\eta_{i})}\n$$\nWith the given coefficients $\\beta_{0}=-1$, $\\beta_{g}=0.8$, and $\\beta_{v}=-0.6$, we calculate $\\eta_i$ and $\\hat{p}_i$ for each patient $i=1, \\dots, 8$.\n\n- Patient $1$: $(x_{g,1},x_{v,1})=(1,0)$, $y_{1}=0$.\n  $\\eta_1 = -1 + 0.8(1) - 0.6(0) = -0.2$.\n  $\\hat{p}_1 = \\frac{1}{1+\\exp(0.2)} \\approx 0.450166$.\n\n- Patient $2$: $(x_{g,2},x_{v,2})=(2,0)$, $y_{2}=1$.\n  $\\eta_2 = -1 + 0.8(2) - 0.6(0) = 0.6$.\n  $\\hat{p}_2 = \\frac{1}{1+\\exp(-0.6)} \\approx 0.645656$.\n\n- Patient $3$: $(x_{g,3},x_{v,3})=(0,1)$, $y_{3}=0$.\n  $\\eta_3 = -1 + 0.8(0) - 0.6(1) = -1.6$.\n  $\\hat{p}_3 = \\frac{1}{1+\\exp(1.6)} \\approx 0.167982$.\n\n- Patient $4$: $(x_{g,4},x_{v,4})=(1,1)$, $y_{4}=0$.\n  $\\eta_4 = -1 + 0.8(1) - 0.6(1) = -0.8$.\n  $\\hat{p}_4 = \\frac{1}{1+\\exp(0.8)} \\approx 0.310026$.\n\n- Patient $5$: $(x_{g,5},x_{v,5})=(2,1)$, $y_{5}=1$.\n  $\\eta_5 = -1 + 0.8(2) - 0.6(1) = 0.0$.\n  $\\hat{p}_5 = \\frac{1}{1+\\exp(0)} = 0.5$.\n\n- Patient $6$: $(x_{g,6},x_{v,6})=(1,2)$, $y_{6}=0$.\n  $\\eta_6 = -1 + 0.8(1) - 0.6(2) = -1.4$.\n  $\\hat{p}_6 = \\frac{1}{1+\\exp(1.4)} \\approx 0.197816$.\n\n- Patient $7$: $(x_{g,7},x_{v,7})=(0,0)$, $y_{7}=0$.\n  $\\eta_7 = -1 + 0.8(0) - 0.6(0) = -1$.\n  $\\hat{p}_7 = \\frac{1}{1+\\exp(1)} \\approx 0.268941$.\n\n- Patient $8$: $(x_{g,8},x_{v,8})=(3,0)$, $y_{8}=1$.\n  $\\eta_8 = -1 + 0.8(3) - 0.6(0) = 1.4$.\n  $\\hat{p}_8 = \\frac{1}{1+\\exp(-1.4)} \\approx 0.802184$.\n\nThe observed outcomes are $\\{y_i\\}_{i=1}^8 = \\{0, 1, 0, 0, 1, 0, 0, 1\\}$.\nThe total number of positive cases (sepsis, $y=1$) is $P=3$ (Patients $2, 5, 8$).\nThe total number of negative cases (no sepsis, $y=0$) is $N=5$ (Patients $1, 3, 4, 6, 7$).\n\nNext, we list the pairs $(\\hat{p}_i, y_i)$ and sort them by $\\hat{p}_i$ in increasing order:\n- Patient $3$: $(\\hat{p}_3, y_3) \\approx (0.167982, 0)$\n- Patient $6$: $(\\hat{p}_6, y_6) \\approx (0.197816, 0)$\n- Patient $7$: $(\\hat{p}_7, y_7) \\approx (0.268941, 0)$\n- Patient $4$: $(\\hat{p}_4, y_4) \\approx (0.310026, 0)$\n- Patient $1$: $(\\hat{p}_1, y_1) \\approx (0.450166, 0)$\n- Patient $5$: $(\\hat{p}_5, y_5) = (0.500000, 1)$\n- Patient $2$: $(\\hat{p}_2, y_2) \\approx (0.645656, 1)$\n- Patient $8$: $(\\hat{p}_8, y_8) \\approx (0.802184, 1)$\n\nThe unique values of $\\hat{p}_i$, denoted $v_k$, are all distinct. The candidate thresholds $t_k$ are the midpoints between consecutive values of $v_k$:\n$t_1 = (\\hat{p}_3 + \\hat{p}_6)/2 \\approx 0.182899$\n$t_2 = (\\hat{p}_6 + \\hat{p}_7)/2 \\approx 0.233379$\n$t_3 = (\\hat{p}_7 + \\hat{p}_4)/2 \\approx 0.289484$\n$t_4 = (\\hat{p}_4 + \\hat{p}_1)/2 \\approx 0.380096$\n$t_5 = (\\hat{p}_1 + \\hat{p}_5)/2 \\approx 0.475083$\n$t_6 = (\\hat{p}_5 + \\hat{p}_2)/2 \\approx 0.572828$\n$t_7 = (\\hat{p}_2 + \\hat{p}_8)/2 \\approx 0.723920$\n\nNow, we evaluate $J(t) = \\mathrm{Se}(t) + \\mathrm{Sp}(t) - 1$ for each candidate threshold. A prediction is positive if $\\hat{p}_i \\ge t$.\n$\\mathrm{Se}(t) = \\mathrm{TP}(t)/P = \\mathrm{TP}(t)/3$.\n$\\mathrm{Sp}(t) = \\mathrm{TN}(t)/N = \\mathrm{TN}(t)/5$.\n\n- For $t_1 \\approx 0.1829$:\n  $\\mathrm{TP}(t_1) = 3$ (all positives have $\\hat{p}_i  t_1$) $\\implies \\mathrm{Se}(t_1) = 3/3 = 1.0$.\n  $\\mathrm{TN}(t_1) = 1$ (only patient 3 is correctly classified as negative) $\\implies \\mathrm{Sp}(t_1) = 1/5 = 0.2$.\n  $J(t_1) = 1.0 + 0.2 - 1 = 0.2$.\n\n- For $t_2 \\approx 0.2334$:\n  $\\mathrm{TP}(t_2) = 3 \\implies \\mathrm{Se}(t_2) = 3/3 = 1.0$.\n  $\\mathrm{TN}(t_2) = 2$ (patients 3, 6) $\\implies \\mathrm{Sp}(t_2) = 2/5 = 0.4$.\n  $J(t_2) = 1.0 + 0.4 - 1 = 0.4$.\n\n- For $t_3 \\approx 0.2895$:\n  $\\mathrm{TP}(t_3) = 3 \\implies \\mathrm{Se}(t_3) = 3/3 = 1.0$.\n  $\\mathrm{TN}(t_3) = 3$ (patients 3, 6, 7) $\\implies \\mathrm{Sp}(t_3) = 3/5 = 0.6$.\n  $J(t_3) = 1.0 + 0.6 - 1 = 0.6$.\n\n- For $t_4 \\approx 0.3801$:\n  $\\mathrm{TP}(t_4) = 3 \\implies \\mathrm{Se}(t_4) = 3/3 = 1.0$.\n  $\\mathrm{TN}(t_4) = 4$ (patients 3, 6, 7, 4) $\\implies \\mathrm{Sp}(t_4) = 4/5 = 0.8$.\n  $J(t_4) = 1.0 + 0.8 - 1 = 0.8$.\n\n- For $t_5 \\approx 0.4751$:\n  $\\mathrm{TP}(t_5) = 3$ (patients 5, 2, 8 all have $\\hat{p}_i \\ge 0.5  t_5$) $\\implies \\mathrm{Se}(t_5) = 3/3 = 1.0$.\n  $\\mathrm{TN}(t_5) = 5$ (all negatives have $\\hat{p}_i \\le \\hat{p}_1 \\approx 0.45  t_5$) $\\implies \\mathrm{Sp}(t_5) = 5/5 = 1.0$.\n  $J(t_5) = 1.0 + 1.0 - 1 = 1.0$.\n\n- For $t_6 \\approx 0.5728$:\n  $\\mathrm{TP}(t_6) = 2$ (patient 5 is missed, $\\hat{p}_5=0.5  t_6$) $\\implies \\mathrm{Se}(t_6) = 2/3$.\n  $\\mathrm{TN}(t_6) = 5 \\implies \\mathrm{Sp}(t_6) = 5/5 = 1.0$.\n  $J(t_6) = 2/3 + 1.0 - 1 = 2/3 \\approx 0.667$.\n\n- For $t_7 \\approx 0.7239$:\n  $\\mathrm{TP}(t_7) = 1$ (patients 5, 2 are missed) $\\implies \\mathrm{Se}(t_7) = 1/3$.\n  $\\mathrm{TN}(t_7) = 5 \\implies \\mathrm{Sp}(t_7) = 5/5 = 1.0$.\n  $J(t_7) = 1/3 + 1.0 - 1 = 1/3 \\approx 0.333$.\n\nComparing the Youden index values $\\{0.2, 0.4, 0.6, 0.8, 1.0, 2/3, 1/3\\}$, the maximum value is $J_{max}=1.0$. This maximum is achieved at the threshold $t_5$.\n\nThe optimal threshold $t^{\\star}$ is therefore:\n$$\nt^{\\star} = t_5 = \\frac{\\hat{p}_1 + \\hat{p}_5}{2} = \\frac{1}{2} \\left( \\frac{1}{1+\\exp(0.2)} + 0.5 \\right)\n$$\n$$\nt^{\\star} \\approx \\frac{1}{2} (0.45016600 + 0.5) = 0.47508300\n$$\nRounding this to four significant figures gives $0.4751$.", "answer": "$$\\boxed{0.4751}$$", "id": "4579262"}]}