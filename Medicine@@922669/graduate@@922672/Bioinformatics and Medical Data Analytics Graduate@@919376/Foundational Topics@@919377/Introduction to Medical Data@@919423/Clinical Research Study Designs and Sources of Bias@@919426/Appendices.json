{"hands_on_practices": [{"introduction": "The Randomized Controlled Trial (RCT) is the cornerstone of evidence-based medicine, yet the method of randomization itself has profound implications for a study's precision. This exercise will guide you through a quantitative comparison of simple, block, and stratified randomization schemes. By deriving the variance of the treatment effect estimator under each design, you will gain a first-principles understanding of how strategic randomization can reduce variance and increase the statistical power of a trial [@problem_id:4547834].", "problem": "A randomized controlled clinical trial enrolls $n = 240$ participants to compare a binary treatment ($T_i \\in \\{0, 1\\}$). The primary outcome for participant $i$ is modeled by a linear data-generating process\n$$\nY_{i} = \\beta_{0} + \\beta_{T} T_{i} + \\beta_{X} X_{i} + \\epsilon_{i},\n$$\nwhere $X_i$ is a baseline covariate with population mean $0$ and variance $\\sigma_X^2 = 4$, $\\epsilon_i$ is an independent error term with mean $0$ and variance $\\sigma_\\epsilon^2 = 9$, and $\\beta_X = 0.5$. All $(X_i, \\epsilon_i)$ are independent and identically distributed across $i$, and independent of the treatment assignment mechanism. Consider the unadjusted difference-in-means estimator of the treatment effect,\n$$\n\\hat{\\Delta} = \\bar{Y}_{T} - \\bar{Y}_{C},\n$$\nwhere $\\bar{Y}_T$ and $\\bar{Y}_C$ denote the sample means of $Y_i$ among treated and control participants, respectively.\n\nCompare three randomization schemes:\n- Simple randomization: each participant is independently assigned to treatment with probability $1/2$, leading to a random treated sample size $n_T \\sim \\mathrm{Binomial}(n, 1/2)$ and $n_C = n - n_T$.\n- Block randomization: permuted blocks guaranteeing overall 1:1 allocation, so $n_T = n_C = n/2$ exactly.\n- Stratified randomization: participants are classified into three strata by a categorical baseline variable $Z \\in \\{1,2,3\\}$, with stratum sizes $n_1 = n_2 = n_3 = 80$. Within each stratum, the allocation is exactly 1:1, so $n_{T,z} = n_{C,z} = n_z/2$ for each stratum $z$. The within-stratum variance of $X$ satisfies $\\mathrm{Var}(X \\mid Z = 1) = 1$, $\\mathrm{Var}(X \\mid Z = 2) = 2$, $\\mathrm{Var}(X \\mid Z = 3) = 3$, and the overall variance $\\sigma_X^2 = 4$ is consistent with the law of total variance.\n\nStarting from first principles about independent sampling, the variance of sample means, and the law of total variance, derive the large-sample variance of $\\hat{\\Delta}$ under each scheme. For simple randomization, you may use a second-order expansion around $n/2$ for the expectation $\\mathbb{E}[1/n_{T} + 1/n_{C}]$ when $n_T \\sim \\mathrm{Binomial}(n,1/2)$, with $n$ large. Express your final answers as exact closed-form analytic expressions (no rounding). Report the three variances as a row matrix in the order $(\\text{simple}, \\text{block}, \\text{stratified})$.", "solution": "The problem asks for the large-sample variance of the unadjusted difference-in-means estimator, $\\hat{\\Delta} = \\bar{Y}_{T} - \\bar{Y}_{C}$, under three different randomization schemes.\n\nThe data-generating process for the outcome $Y_i$ for participant $i$ is given by the linear model:\n$$\nY_{i} = \\beta_{0} + \\beta_{T} T_{i} + \\beta_{X} X_{i} + \\epsilon_{i}\n$$\nwhere $T_i=1$ for treatment and $T_i=0$ for control. The covariate $X_i$ and error $\\epsilon_i$ are random variables with the following properties:\n$\\mathbb{E}[X_i] = 0$, $\\mathrm{Var}(X_i) = \\sigma_X^2 = 4$.\n$\\mathbb{E}[\\epsilon_i] = 0$, $\\mathrm{Var}(\\epsilon_i) = \\sigma_\\epsilon^2 = 9$.\nThe coefficient for the covariate is $\\beta_X = 0.5$. The sets of random variables $\\{X_i\\}_{i=1}^n$ and $\\{\\epsilon_i\\}_{i=1}^n$ are independent of each other and of the treatment assignment vector $T=(T_1, \\dots, T_n)$.\n\nThe estimator $\\hat{\\Delta}$ can be expressed in terms of the model components. Let $\\bar{Y}_T$ and $\\bar{Y}_C$ be the sample means in the treatment and control groups, with sizes $n_T$ and $n_C$ respectively.\n$$\n\\bar{Y}_{T} = \\frac{1}{n_T}\\sum_{i:T_i=1} Y_i = \\frac{1}{n_T}\\sum_{i:T_i=1} (\\beta_0 + \\beta_T + \\beta_X X_i + \\epsilon_i) = \\beta_0 + \\beta_T + \\beta_X \\bar{X}_T + \\bar{\\epsilon}_T\n$$\n$$\n\\bar{Y}_{C} = \\frac{1}{n_C}\\sum_{i:T_i=0} Y_i = \\frac{1}{n_C}\\sum_{i:T_i=0} (\\beta_0 + \\beta_X X_i + \\epsilon_i) = \\beta_0 + \\beta_X \\bar{X}_C + \\bar{\\epsilon}_C\n$$\nwhere $\\bar{X}_T, \\bar{\\epsilon}_T$ and $\\bar{X}_C, \\bar{\\epsilon}_C$ are the respective sample means of the covariates and errors in each group.\nThe estimator is therefore:\n$$\n\\hat{\\Delta} = \\bar{Y}_T - \\bar{Y}_C = \\beta_T + \\beta_X(\\bar{X}_T - \\bar{X}_C) + (\\bar{\\epsilon}_T - \\bar{\\epsilon}_C)\n$$\nTo find the variance of $\\hat{\\Delta}$, we note that $\\beta_T$ is a constant. Because the sets of random variables $\\{X_i\\}$ and $\\{\\epsilon_i\\}$ are independent, any functions of them, such as $(\\bar{X}_T - \\bar{X}_C)$ and $(\\bar{\\epsilon}_T - \\bar{\\epsilon}_C)$, are also independent. Thus, the variance of their sum is the sum of their variances:\n$$\n\\mathrm{Var}(\\hat{\\Delta}) = \\mathrm{Var}\\left(\\beta_X(\\bar{X}_T - \\bar{X}_C) + (\\bar{\\epsilon}_T - \\bar{\\epsilon}_C)\\right) = \\beta_X^2 \\mathrm{Var}(\\bar{X}_T - \\bar{X}_C) + \\mathrm{Var}(\\bar{\\epsilon}_T - \\bar{\\epsilon}_C)\n$$\nWe will now compute the two variance terms for each randomization scheme. We use the law of total variance, conditioning on the treatment allocation vector $T$, which itself is random. For any random variable $A$, $\\mathrm{Var}(A) = \\mathbb{E}[\\mathrm{Var}(A|T)] + \\mathrm{Var}(\\mathbb{E}[A|T])$.\n\nLet's analyze the term $\\mathrm{Var}(\\bar{X}_T - \\bar{X}_C)$.\n$\\mathbb{E}[\\bar{X}_T|T] = \\frac{1}{n_T}\\sum_{i:T_i=1}\\mathbb{E}[X_i] = 0$, and similarly $\\mathbb{E}[\\bar{X}_C|T]=0$. Thus, $\\mathbb{E}[\\bar{X}_T - \\bar{X}_C|T] = 0$.\nThis implies that $\\mathrm{Var}(\\mathbb{E}[\\bar{X}_T - \\bar{X}_C|T]) = \\mathrm{Var}(0) = 0$.\nSo, $\\mathrm{Var}(\\bar{X}_T - \\bar{X}_C) = \\mathbb{E}[\\mathrm{Var}(\\bar{X}_T - \\bar{X}_C|T)]$.\nConditional on $T$, the treatment and control groups are disjoint sets of participants. The random variables $X_i$ are independent. Therefore, $\\bar{X}_T$ and $\\bar{X}_C$ are independent conditional on $T$.\n$\\mathrm{Var}(\\bar{X}_T - \\bar{X}_C|T) = \\mathrm{Var}(\\bar{X}_T|T) + \\mathrm{Var}(\\bar{X}_C|T)$.\nFor a group of size $k$ of i.i.d variables with variance $\\sigma_X^2$, the variance of the sample mean is $\\sigma_X^2/k$.\n$\\mathrm{Var}(\\bar{X}_T|T) = \\sigma_X^2/n_T$ and $\\mathrm{Var}(\\bar{X}_C|T) = \\sigma_X^2/n_C$.\nSo, $\\mathrm{Var}(\\bar{X}_T - \\bar{X}_C|T) = \\sigma_X^2(\\frac{1}{n_T} + \\frac{1}{n_C})$.\nThe unconditional variance is the expectation over the randomization scheme:\n$\\mathrm{Var}(\\bar{X}_T - \\bar{X}_C) = \\mathbb{E}\\left[\\sigma_X^2\\left(\\frac{1}{n_T} + \\frac{1}{n_C}\\right)\\right] = \\sigma_X^2 \\mathbb{E}\\left[\\frac{1}{n_T} + \\frac{1}{n_C}\\right]$.\nBy identical logic, $\\mathrm{Var}(\\bar{\\epsilon}_T - \\bar{\\epsilon}_C) = \\sigma_\\epsilon^2 \\mathbb{E}\\left[\\frac{1}{n_T} + \\frac{1}{n_C}\\right]$.\nThis general formula holds for simple and block randomization where participants are not stratified. Let's define an effective outcome variance $\\sigma^2_{\\text{eff}} = \\beta_X^2 \\sigma_X^2 + \\sigma_\\epsilon^2 = (0.5)^2(4) + 9 = 1 + 9 = 10$.\nThen, for these schemes, $\\mathrm{Var}(\\hat{\\Delta}) = \\sigma^2_{\\text{eff}} \\mathbb{E}\\left[\\frac{1}{n_T} + \\frac{1}{n_C}\\right]$.\n\n**1. Simple Randomization**\nEach participant is assigned to treatment with probability $p=1/2$. The number of treated participants $n_T$ follows a binomial distribution, $n_T \\sim \\mathrm{Binomial}(n, 1/2)$, with $n=240$.\nThe expectation is $\\mathbb{E}[n_T] = np = 120$ and the variance is $\\mathrm{Var}(n_T) = np(1-p) = 240(1/2)(1/2) = 60$.\nTo find $\\mathbb{E}[1/n_T + 1/(n-n_T)]$, we use the suggested second-order Taylor expansion of $f(k) = 1/k + 1/(n-k)$ around $\\mathbb{E}[n_T] = n/2$.\n$\\mathbb{E}[f(n_T)] \\approx f(n/2) + \\frac{1}{2}f''(n/2)\\mathrm{Var}(n_T)$.\n$f(n/2) = 1/(n/2) + 1/(n/2) = 4/n$.\n$f'(k) = -1/k^2 + 1/(n-k)^2$, so $f'(n/2) = 0$.\n$f''(k) = 2/k^3 + 2/(n-k)^3$, so $f''(n/2) = 2/(n/2)^3 + 2/(n/2)^3 = 32/n^3$.\n$\\mathbb{E}\\left[\\frac{1}{n_T} + \\frac{1}{n_C}\\right] \\approx \\frac{4}{n} + \\frac{1}{2}\\left(\\frac{32}{n^3}\\right)\\left(\\frac{n}{4}\\right) = \\frac{4}{n} + \\frac{4}{n^2}$.\nFor $n=240$: $\\mathbb{E}[\\dots] \\approx \\frac{4}{240} + \\frac{4}{240^2} = \\frac{1}{60} + \\frac{4}{57600} = \\frac{1}{60} + \\frac{1}{14400} = \\frac{240+1}{14400} = \\frac{241}{14400}$.\nThe variance of the estimator is:\n$\\mathrm{Var}(\\hat{\\Delta})_{\\text{simple}} = 10 \\times \\frac{241}{14400} = \\frac{241}{1440}$.\n\n**2. Block Randomization**\nThe allocation is fixed with $n_T = n_C = n/2 = 120$. Thus, the expectation is trivial.\n$\\mathbb{E}\\left[\\frac{1}{n_T} + \\frac{1}{n_C}\\right] = \\frac{1}{n/2} + \\frac{1}{n/2} = \\frac{4}{n}$.\nFor $n=240$: $\\frac{4}{240} = \\frac{1}{60}$.\nThe variance of the estimator is:\n$\\mathrm{Var}(\\hat{\\Delta})_{\\text{block}} = 10 \\times \\frac{4}{n} = 10 \\times \\frac{1}{60} = \\frac{1}{6}$.\n\n**3. Stratified Randomization**\nThe population is stratified by $Z \\in \\{1,2,3\\}$ with $n_1=n_2=n_3=80$. Within each stratum $z$, allocation is fixed: $n_{T,z}=n_{C,z}=40$. The total sample sizes are also fixed: $n_T = \\sum_z n_{T,z} = 120$ and $n_C = \\sum_z n_{C,z} = 120$.\nThe unadjusted sample means $\\bar{X}_T$ and $\\bar{X}_C$ are weighted averages of the stratum-specific means:\n$\\bar{X}_T = \\frac{1}{n_T}\\sum_z n_{T,z}\\bar{X}_{T,z} = \\frac{40}{120}\\sum_z \\bar{X}_{T,z} = \\frac{1}{3}\\sum_z \\bar{X}_{T,z}$. Similarly, $\\bar{X}_C = \\frac{1}{3}\\sum_z \\bar{X}_{C,z}$.\nThe difference is $\\bar{X}_T - \\bar{X}_C = \\frac{1}{3}\\sum_{z=1}^3 (\\bar{X}_{T,z} - \\bar{X}_{C,z})$.\nSince samples from different strata are independent, the variance is:\n$\\mathrm{Var}(\\bar{X}_T - \\bar{X}_C) = \\frac{1}{9}\\sum_{z=1}^3 \\mathrm{Var}(\\bar{X}_{T,z} - \\bar{X}_{C,z})$.\nWithin each stratum $z$, participants are drawn from a subpopulation with covariate variance $\\sigma_{X,z}^2 = \\mathrm{Var}(X|Z=z)$.\n$\\mathrm{Var}(\\bar{X}_{T,z} - \\bar{X}_{C,z}) = \\mathrm{Var}(\\bar{X}_{T,z}) + \\mathrm{Var}(\\bar{X}_{C,z}) = \\frac{\\sigma_{X,z}^2}{n_{T,z}} + \\frac{\\sigma_{X,z}^2}{n_{C,z}} = \\sigma_{X,z}^2\\left(\\frac{1}{40}+\\frac{1}{40}\\right) = \\frac{\\sigma_{X,z}^2}{20}$.\n$\\mathrm{Var}(\\bar{X}_T - \\bar{X}_C) = \\frac{1}{9}\\sum_{z=1}^3 \\frac{\\sigma_{X,z}^2}{20} = \\frac{1}{180}(\\sigma_{X,1}^2 + \\sigma_{X,2}^2 + \\sigma_{X,3}^2)$.\nUsing the given values $\\mathrm{Var}(X|Z=1)=1, \\mathrm{Var}(X|Z=2)=2, \\mathrm{Var}(X|Z=3)=3$:\n$\\mathrm{Var}(\\bar{X}_T - \\bar{X}_C) = \\frac{1}{180}(1+2+3) = \\frac{6}{180} = \\frac{1}{30}$.\nFor the error term, $\\epsilon_i$ is i.i.d. with variance $\\sigma_\\epsilon^2=9$ regardless of stratum. So, $\\mathrm{Var}(\\epsilon|Z=z)=\\sigma_\\epsilon^2=9$ for all $z$.\n$\\mathrm{Var}(\\bar{\\epsilon}_T - \\bar{\\epsilon}_C) = \\frac{1}{9}\\sum_{z=1}^3 \\mathrm{Var}(\\bar{\\epsilon}_{T,z} - \\bar{\\epsilon}_{C,z}) = \\frac{1}{9}\\sum_{z=1}^3 \\frac{\\sigma_\\epsilon^2}{20} = \\frac{3 \\times (9/20)}{9} = \\frac{3}{20}$.\nThe total variance for the stratified scheme is:\n$\\mathrm{Var}(\\hat{\\Delta})_{\\text{strat}} = \\beta_X^2 \\mathrm{Var}(\\bar{X}_T - \\bar{X}_C) + \\mathrm{Var}(\\bar{\\epsilon}_T - \\bar{\\epsilon}_C) = (0.5)^2\\left(\\frac{1}{30}\\right) + \\frac{3}{20}$.\n$\\mathrm{Var}(\\hat{\\Delta})_{\\text{strat}} = \\frac{1}{4}\\cdot\\frac{1}{30} + \\frac{3}{20} = \\frac{1}{120} + \\frac{18}{120} = \\frac{19}{120}$.\n\nThe three variances are:\n- Simple randomization: $\\frac{241}{1440}$\n- Block randomization: $\\frac{1}{6}$\n- Stratified randomization: $\\frac{19}{120}$\n\nTo compare, we can use a common denominator of $1440$:\n- Simple: $\\frac{241}{1440} \\approx 0.16736$\n- Block: $\\frac{1}{6} = \\frac{240}{1440} \\approx 0.16667$\n- Stratified: $\\frac{19}{120} = \\frac{19 \\times 12}{120 \\times 12} = \\frac{228}{1440} \\approx 0.15833$\nThe results show that block randomization offers a marginal improvement over simple randomization by eliminating variance from random sample sizes. Stratified randomization provides a more substantial improvement by balancing the prognostic covariate $X$ across treatment groups, which reduces the variance component associated with that covariate.\n\nFinal answers are reported as exact fractions.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{241}{1440} & \\frac{1}{6} & \\frac{19}{120}\n\\end{pmatrix}\n}\n$$", "id": "4547834"}, {"introduction": "A diagnostic test's performance is often summarized by its sensitivity and specificity, but its true clinical utility depends on the context in which it is used. This practice will challenge you to derive the Positive and Negative Predictive Values (PPV and NPV) and demonstrate how they are critically dependent on the prevalence of the disease [@problem_id:4547844]. By working through a realistic scenario for a rare condition, you will confront the base-rate fallacy and appreciate why even highly accurate tests can have a surprisingly low PPV.", "problem": "A bioinformatics-enabled clinical research team is evaluating a binary screening assay for a rare condition in a large cohort. Let $D \\in \\{0, 1\\}$ denote disease status ($D=1$ indicates disease present), and let $T \\in \\{0, 1\\}$ denote the test result ($T=1$ indicates a positive result). The following core definitions are assumed:\n- Prevalence $\\pi$ is $P(D=1)$.\n- Sensitivity $Se$ is $P(T=1 \\mid D=1)$.\n- Specificity $Sp$ is $P(T=0 \\mid D=0)$.\n- Positive Predictive Value (PPV) is $P(D=1 \\mid T=1)$.\n- Negative Predictive Value (NPV) is $P(D=0 \\mid T=0)$.\n\nUsing only the above definitions, the law of total probability, and Bayes’ theorem, perform the following:\n\n1. Derive closed-form expressions for $\\mathrm{PPV}$ and $\\mathrm{NPV}$ in terms of $Se$, $Sp$, and $\\pi$, without introducing any other parameters.\n2. For a screening context with $Se = 0.99$, $Sp = 0.98$, and $\\pi = 0.005$, compute the numerical values of $\\mathrm{PPV}$ and $\\mathrm{NPV}$. Report both as decimals, not percentages, and round your answers to $5$ significant figures.\n\nReport your final numerical answers in the order $\\mathrm{PPV}$, then $\\mathrm{NPV}$. The final answer must be expressed as a single row vector.", "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and complete. It presents a standard, formalizable problem in biostatistics and epidemiology, based on fundamental principles of probability theory. There are no contradictions, ambiguities, or factual inaccuracies. We may therefore proceed with the solution.\n\nThe problem is divided into two parts: the derivation of expressions for Positive Predictive Value ($\\mathrm{PPV}$) and Negative Predictive Value ($\\mathrm{NPV}$), followed by their numerical computation using supplied parameters.\n\nLet $D$ be the random variable for disease status, with $D=1$ indicating disease presence and $D=0$ indicating absence. Let $T$ be the random variable for the test result, with $T=1$ for a positive result and $T=0$ for a negative result. The given definitions are:\n- Prevalence: $\\pi = P(D=1)$. Consequently, $P(D=0) = 1 - \\pi$.\n- Sensitivity: $Se = P(T=1 \\mid D=1)$.\n- Specificity: $Sp = P(T=0 \\mid D=0)$.\n- Positive Predictive Value: $\\mathrm{PPV} = P(D=1 \\mid T=1)$.\n- Negative Predictive Value: $\\mathrm{NPV} = P(D=0 \\mid T=0)$.\n\nAlso, we can define the false positive rate as $P(T=1 \\mid D=0) = 1 - P(T=0 \\mid D=0) = 1 - Sp$.\nThe false negative rate is $P(T=0 \\mid D=1) = 1 - P(T=1 \\mid D=1) = 1 - Se$.\n\n**Part 1: Derivation of $\\mathrm{PPV}$ and $\\mathrm{NPV}$**\n\n**Derivation of Positive Predictive Value ($\\mathrm{PPV}$)**\nWe seek an expression for $\\mathrm{PPV} = P(D=1 \\mid T=1)$. Using Bayes' theorem:\n$$ \\mathrm{PPV} = P(D=1 \\mid T=1) = \\frac{P(T=1 \\mid D=1) P(D=1)}{P(T=1)} $$\nThe numerator's terms are given directly by the definitions: $P(T=1 \\mid D=1) = Se$ and $P(D=1) = \\pi$.\nThe denominator, $P(T=1)$, is the overall probability of a positive test result. We expand this using the law of total probability, conditioning on the disease status $D$:\n$$ P(T=1) = P(T=1 \\mid D=1) P(D=1) + P(T=1 \\mid D=0) P(D=0) $$\nSubstituting the defined terms:\n- $P(T=1 \\mid D=1) = Se$\n- $P(D=1) = \\pi$\n- $P(T=1 \\mid D=0) = 1 - Sp$\n- $P(D=0) = 1 - \\pi$\n\nThis gives:\n$$ P(T=1) = (Se)(\\pi) + (1 - Sp)(1 - \\pi) $$\nSubstituting this denominator back into the Bayes' theorem expression for $\\mathrm{PPV}$:\n$$ \\mathrm{PPV} = \\frac{Se \\cdot \\pi}{Se \\cdot \\pi + (1 - Sp)(1 - \\pi)} $$\nThis is the required closed-form expression for $\\mathrm{PPV}$.\n\n**Derivation of Negative Predictive Value ($\\mathrm{NPV}$)**\nWe seek an expression for $\\mathrm{NPV} = P(D=0 \\mid T=0)$. Using Bayes' theorem:\n$$ \\mathrm{NPV} = P(D=0 \\mid T=0) = \\frac{P(T=0 \\mid D=0) P(D=0)}{P(T=0)} $$\nThe numerator's terms are given by the definitions: $P(T=0 \\mid D=0) = Sp$ and $P(D=0) = 1-\\pi$.\nThe denominator, $P(T=0)$, is the overall probability of a negative test result. Using the law of total probability:\n$$ P(T=0) = P(T=0 \\mid D=0) P(D=0) + P(T=0 \\mid D=1) P(D=1) $$\nSubstituting the defined terms:\n- $P(T=0 \\mid D=0) = Sp$\n- $P(D=0) = 1 - \\pi$\n- $P(T=0 \\mid D=1) = 1 - Se$\n- $P(D=1) = \\pi$\n\nThis gives:\n$$ P(T=0) = (Sp)(1 - \\pi) + (1 - Se)(\\pi) $$\nSubstituting this denominator back into the Bayes' theorem expression for $\\mathrm{NPV}$:\n$$ \\mathrm{NPV} = \\frac{Sp \\cdot (1 - \\pi)}{Sp \\cdot (1 - \\pi) + (1 - Se)\\pi} $$\nThis is the required closed-form expression for $\\mathrm{NPV}$.\n\n**Part 2: Numerical Computation**\n\nWe are given the following values:\n- $Se = 0.99$\n- $Sp = 0.98$\n- $\\pi = 0.005$\n\nWe also compute the complementary probabilities:\n- $1 - Se = 1 - 0.99 = 0.01$\n- $1 - Sp = 1 - 0.98 = 0.02$\n- $1 - \\pi = 1 - 0.005 = 0.995$\n\n**Computation of $\\mathrm{PPV}$**\nUsing the derived formula:\n$$ \\mathrm{PPV} = \\frac{Se \\cdot \\pi}{Se \\cdot \\pi + (1 - Sp)(1 - \\pi)} $$\n$$ \\mathrm{PPV} = \\frac{0.99 \\times 0.005}{(0.99 \\times 0.005) + (0.02 \\times 0.995)} $$\n$$ \\mathrm{PPV} = \\frac{0.00495}{0.00495 + 0.0199} $$\n$$ \\mathrm{PPV} = \\frac{0.00495}{0.02485} \\approx 0.19919517... $$\nRounding to $5$ significant figures, we get $\\mathrm{PPV} = 0.19920$.\n\n**Computation of $\\mathrm{NPV}$**\nUsing the derived formula:\n$$ \\mathrm{NPV} = \\frac{Sp \\cdot (1 - \\pi)}{Sp \\cdot (1 - \\pi) + (1 - Se)\\pi} $$\n$$ \\mathrm{NPV} = \\frac{0.98 \\times 0.995}{(0.98 \\times 0.995) + (0.01 \\times 0.005)} $$\n$$ \\mathrm{NPV} = \\frac{0.9751}{0.9751 + 0.00005} $$\n$$ \\mathrm{NPV} = \\frac{0.9751}{0.97515} \\approx 0.99994872... $$\nRounding to $5$ significant figures, we get $\\mathrm{NPV} = 0.99995$.\n\nThe results demonstrate a crucial concept in screening for rare diseases: even with a highly sensitive and specific test, the positive predictive value can be low due to the low prevalence of the condition. Conversely, the negative predictive value is extremely high.", "answer": "$$\\boxed{\\begin{pmatrix} 0.19920 & 0.99995 \\end{pmatrix}}$$", "id": "4547844"}, {"introduction": "In many clinical studies, particularly in oncology, patients are at risk for multiple, mutually exclusive outcomes, creating a scenario of competing risks. A naïve analysis that ignores this complexity can lead to significant bias in estimating the probability of an event. This problem will have you quantify this bias directly by comparing an incorrect, cause-specific analysis with the correct subdistribution function approach, providing a critical lesson in the proper analysis of time-to-event data [@problem_id:4547838].", "problem": "A retrospective cohort study in precision oncology uses curated Electronic Health Record (EHR) data to evaluate time-to-event outcomes with two mutually exclusive endpoints: event $A$ (disease-specific death) and event $B$ (non-disease death). Investigators estimate constant cause-specific hazards over time from a stratified Cox-type analysis that stabilizes at the baseline level for this cohort. The estimated cause-specific hazards are $h_A(t) = \\lambda_A$ and $h_B(t) = \\lambda_B$, where $\\lambda_A = 0.1\\,\\text{year}^{-1}$ and $\\lambda_B = 0.05\\,\\text{year}^{-1}$. Consider a follow-up horizon of $t = 6\\,\\text{years}$.\n\nUsing the fundamental definitions for hazards, survival, and cumulative incidence in the presence of competing risks, do the following:\n- Under the incorrect modeling assumption that there is no competing risk (i.e., using only the cause-specific hazard for event $A$ to estimate the risk of event $A$ by time $t$), compute the naïve estimator of the cumulative incidence at time $t$.\n- Derive and compute the correct cumulative incidence function (also called the subdistribution function) for event $A$ at time $t$, accounting for the joint risk of both endpoints through the overall survival from any event.\n- Finally, report the absolute bias defined as the naïve estimator minus the correct subdistribution function evaluated at $t = 6$.\n\nExpress your final answer as a decimal fraction. Round your final answer to four significant figures. No percentage signs are permitted in the final expression.", "solution": "We begin from core definitions of competing risks. Let there be two mutually exclusive causes of failure, $A$ and $B$, with cause-specific hazards $h_{A}(t)$ and $h_{B}(t)$. The overall hazard of failing from any cause at time $t$ is $h(t) = h_{A}(t) + h_{B}(t)$. The overall survival function from any event by time $t$ is\n$$\nS(t) = \\exp\\Big(-\\int_{0}^{t} h(u)\\,du\\Big) = \\exp\\Big(-\\int_{0}^{t} \\big(h_{A}(u) + h_{B}(u)\\big)\\,du\\Big).\n$$\nThe cumulative incidence function (subdistribution function) for cause $A$ by time $t$ is defined by\n$$\nF_{A}(t) = \\int_{0}^{t} S(u)\\,h_{A}(u)\\,du,\n$$\nwhich represents the probability of failure from cause $A$ by time $t$ while correctly accounting for the depletion of the at-risk set due to all causes.\n\nBy contrast, a common but incorrect approach is to ignore the competing risk $B$ and use only the cause-specific hazard for $A$ to compute the cumulative probability of event $A$ via the relationship between hazard and survival for a single-cause model. Under this mis-specified model, the survival against $A$ alone is\n$$\n\\tilde{S}_{A}(t) = \\exp\\Big(-\\int_{0}^{t} h_{A}(u)\\,du\\Big),\n$$\nand the naïve cumulative incidence estimator (incorrect in the presence of competing risks) is\n$$\n\\tilde{F}_{A}(t) = 1 - \\tilde{S}_{A}(t) = 1 - \\exp\\Big(-\\int_{0}^{t} h_{A}(u)\\,du\\Big).\n$$\n\nIn the present study, the hazards are constant: $h_{A}(t) = \\lambda_{A}$ and $h_{B}(t) = \\lambda_{B}$ with $\\lambda_{A} = 0.1\\,\\text{year}^{-1}$ and $\\lambda_{B} = 0.05\\,\\text{year}^{-1}$. Therefore, the integrals simplify.\n\nFirst, compute the naïve estimator at $t = 6$:\n$$\n\\int_{0}^{t} h_{A}(u)\\,du = \\int_{0}^{6} \\lambda_{A}\\,du = \\lambda_{A} \\cdot 6 = 0.1 \\cdot 6 = 0.6,\n$$\nso\n$$\n\\tilde{F}_{A}(6) = 1 - \\exp(-0.6).\n$$\n\nSecond, compute the correct cumulative incidence function at $t = 6$. For constant hazards, the overall survival is\n$$\nS(t) = \\exp\\Big(-\\int_{0}^{t} (\\lambda_{A} + \\lambda_{B})\\,du\\Big) = \\exp\\big(-(\\lambda_{A} + \\lambda_{B}) t\\big) = \\exp\\big(-0.15 \\cdot t\\big).\n$$\nHence,\n$$\nF_{A}(t) = \\int_{0}^{t} S(u)\\,h_{A}(u)\\,du = \\int_{0}^{t} \\exp\\big(-(\\lambda_{A} + \\lambda_{B}) u\\big)\\,\\lambda_{A}\\,du.\n$$\nThis integral is elementary:\n$$\nF_{A}(t) = \\lambda_{A} \\int_{0}^{t} \\exp\\big(-(\\lambda_{A} + \\lambda_{B}) u\\big)\\,du = \\lambda_{A} \\cdot \\frac{1 - \\exp\\big(-(\\lambda_{A} + \\lambda_{B}) t\\big)}{\\lambda_{A} + \\lambda_{B}}.\n$$\nSubstitute $t = 6$ and $(\\lambda_{A}, \\lambda_{B}) = (0.1, 0.05)$ to obtain\n$$\nF_{A}(6) = \\frac{\\lambda_{A}}{\\lambda_{A} + \\lambda_{B}} \\Big(1 - \\exp\\big(-(\\lambda_{A} + \\lambda_{B}) \\cdot 6\\big)\\Big) = \\frac{0.1}{0.15} \\Big(1 - \\exp(-0.9)\\Big).\n$$\n\nThe absolute bias, defined as the naïve estimator minus the correct subdistribution function at $t = 6$, is\n$$\n\\text{Bias} = \\tilde{F}_{A}(6) - F_{A}(6) = \\Big(1 - \\exp(-0.6)\\Big) - \\frac{0.1}{0.15} \\Big(1 - \\exp(-0.9)\\Big).\n$$\n\nEvaluate numerically to four significant figures. First, compute the exponentials symbolically and then approximate:\n$$\n\\exp(-0.6) \\approx 0.548811636,\\qquad \\exp(-0.9) \\approx 0.406569660.\n$$\nThus,\n$$\n\\tilde{F}_{A}(6) \\approx 1 - 0.548811636 = 0.451188364,\n$$\nand\n$$\nF_{A}(6) \\approx \\frac{0.1}{0.15} \\Big(1 - 0.406569660\\Big) = \\frac{2}{3} \\cdot 0.593430340 \\approx 0.395620227.\n$$\nTherefore,\n$$\n\\text{Bias} \\approx 0.451188364 - 0.395620227 = 0.055568137.\n$$\nRounded to four significant figures and expressed as a decimal fraction, the final answer is $0.05557$.", "answer": "$$\\boxed{0.05557}$$", "id": "4547838"}]}