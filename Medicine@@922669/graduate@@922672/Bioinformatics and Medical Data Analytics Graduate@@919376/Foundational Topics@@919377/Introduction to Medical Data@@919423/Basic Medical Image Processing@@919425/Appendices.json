{"hands_on_practices": [{"introduction": "Gaussian smoothing is a cornerstone of medical image processing, but its practical implementation requires careful design. While we often specify a desired smoothing effect using a perceptual metric like the Full Width at Half Maximum (FWHM), the filter kernel itself is defined by its standard deviation, $\\sigma$. This exercise [@problem_id:4540821] provides hands-on practice in this crucial translation, bridging the gap between theoretical specification and practical, finite implementation by forcing you to manage the trade-off between kernel size and truncation error.", "problem": "A one-dimensional Gaussian smoothing kernel is to be applied to line profiles extracted from a high-resolution histopathology whole-slide image to reduce high-frequency noise prior to edge detection. The acquisition pixel spacing along the line profile is $\\Delta x = 1.25\\,\\mathrm{mm}$ per pixel. You are asked to design a discrete, symmetric Gaussian kernel sampled at integer pixel offsets $n \\in \\mathbb{Z}$ with entries proportional to $g[n] = \\exp\\!\\big(-\\frac{(n \\Delta x)^2}{2\\sigma^2}\\big)$, followed by normalization so that the kernel sums to one.\n\nThe Gaussian smoothing is specified by the desired Full Width at Half Maximum (FWHM). Full Width at Half Maximum (FWHM) is defined as the width of the Gaussian at half of its maximum amplitude. The target is $\\mathrm{FWHM} = 5.0\\,\\mathrm{mm}$. The kernel will be truncated to an odd length $K = 2R + 1$ by retaining samples $n = -R, \\ldots, R$. Define the truncation error as the total mass omitted by truncation, upper-bounded by the corresponding continuous Gaussian tail beyond radius $R$.\n\nStarting from the definition of a Gaussian function and the definition of Full Width at Half Maximum (FWHM), first determine the standard deviation $\\sigma$ that achieves the specified $\\mathrm{FWHM}$. Then, using a rigorous upper bound based on the continuous Gaussian tail, determine the minimal odd integer kernel length $K$ such that the truncation error is less than $\\epsilon = 1.0 \\times 10^{-6}$. Express the final answer as the minimal odd kernel length $K$. No rounding instructions are required beyond selecting the minimal odd integer that satisfies the inequality. Do not include units in your final answer.", "solution": "The problem requires the design of a one-dimensional discrete Gaussian smoothing kernel, specifically determining its minimal size $K$ to satisfy a given truncation error tolerance. This involves two main steps: first, calculating the standard deviation $\\sigma$ of the Gaussian function from its specified Full Width at Half Maximum (FWHM), and second, determining the kernel's half-width $R$ (and thus its full length $K=2R+1$) based on the maximum allowable truncation error.\n\n**Step 1: Determine the standard deviation $\\sigma$ from the FWHM**\n\nA one-dimensional continuous Gaussian function centered at zero is given by:\n$$G(x) = A \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$$\nwhere $A$ is the amplitude and $\\sigma$ is the standard deviation. The maximum value of the function occurs at $x=0$, with $G(0)=A$.\n\nThe Full Width at Half Maximum (FWHM) is defined as the width of the function at half of its maximum amplitude, i.e., $A/2$. Let $\\pm x_{1/2}$ be the coordinates where the function's value is $G(\\pm x_{1/2}) = A/2$. We can write:\n$$A \\exp\\left(-\\frac{x_{1/2}^2}{2\\sigma^2}\\right) = \\frac{A}{2}$$\nDividing by $A$ and taking the natural logarithm of both sides gives:\n$$-\\frac{x_{1/2}^2}{2\\sigma^2} = \\ln\\left(\\frac{1}{2}\\right) = -\\ln(2)$$\nSolving for $x_{1/2}^2$:\n$$x_{1/2}^2 = 2\\sigma^2 \\ln(2)$$\n$$x_{1/2} = \\sigma \\sqrt{2\\ln(2)}$$\nThe FWHM is the total width, which is $2$ times $x_{1/2}$:\n$$\\mathrm{FWHM} = 2x_{1/2} = 2\\sigma\\sqrt{2\\ln(2)}$$\nWe can now solve for $\\sigma$ in terms of the FWHM:\n$$\\sigma = \\frac{\\mathrm{FWHM}}{2\\sqrt{2\\ln(2)}}$$\nThe problem specifies $\\mathrm{FWHM} = 5.0\\,\\mathrm{mm}$. Substituting this value:\n$$\\sigma = \\frac{5.0}{2\\sqrt{2\\ln(2)}}\\,\\mathrm{mm}$$\nThis expression for $\\sigma$ will be used in the next step.\n\n**Step 2: Determine the minimal kernel length $K$**\n\nThe discrete kernel has a length $K = 2R+1$, with samples at integer indices $n$ from $-R$ to $R$. The physical locations are $n\\Delta x$. The problem specifies that the truncation error should be upper-bounded by the omitted mass of the corresponding continuous, normalized Gaussian function beyond the kernel's extent. A normalized Gaussian has a total area (mass) of $1$.\nThe normalized Gaussian function is:\n$$g_c(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$$\nThe truncation error, $\\epsilon_{err}$, is the area under the tails of this distribution. To properly account for the discrete nature of the kernel, we define a continuous cutoff radius $r_c$ halfway between the last included sample location ($R\\Delta x$) and the first excluded one ($(R+1)\\Delta x$).\n$$r_c = (R+0.5)\\Delta x$$\nThe truncation error is the integral of $g_c(x)$ from $-\\infty$ to $-r_c$ and from $r_c$ to $\\infty$:\n$$\\epsilon_{err} = \\int_{-\\infty}^{-r_c} g_c(x)dx + \\int_{r_c}^{\\infty} g_c(x)dx = 2 \\int_{r_c}^{\\infty} g_c(x)dx$$\n$$\\epsilon_{err} = 2 \\int_{r_c}^{\\infty} \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) dx$$\nThis integral can be expressed in terms of the complementary error function, $\\mathrm{erfc}(z)$, which is defined as:\n$$\\mathrm{erfc}(z) = \\frac{2}{\\sqrt{\\pi}} \\int_{z}^{\\infty} \\exp(-t^2) dt$$\nBy substituting $t = x/(\\sigma\\sqrt{2})$, we find that the truncation error is:\n$$\\epsilon_{err} = \\mathrm{erfc}\\left(\\frac{r_c}{\\sigma\\sqrt{2}}\\right)$$\nWe are given the constraint that this error must be less than $\\epsilon = 1.0 \\times 10^{-6}$:\n$$\\mathrm{erfc}\\left(\\frac{r_c}{\\sigma\\sqrt{2}}\\right) < 1.0 \\times 10^{-6}$$\nSince $\\mathrm{erfc}(z)$ is a monotonically decreasing function for $z \\ge 0$, we can apply its inverse, $\\mathrm{erfcinv}(y)$, to both sides of the inequality, which reverses the inequality sign:\n$$\\frac{r_c}{\\sigma\\sqrt{2}} > \\mathrm{erfcinv}(1.0 \\times 10^{-6})$$\nLet $z_0 = \\mathrm{erfcinv}(1.0 \\times 10^{-6})$. From standard mathematical libraries or tables, $z_0 \\approx 3.59929$.\nNow, we substitute $r_c = (R+0.5)\\Delta x$ and solve for the integer half-width $R$:\n$$\\frac{(R+0.5)\\Delta x}{\\sigma\\sqrt{2}} > z_0$$\n$$R+0.5 > \\frac{z_0 \\sigma \\sqrt{2}}{\\Delta x}$$\n$$R > \\frac{z_0 \\sigma \\sqrt{2}}{\\Delta x} - 0.5$$\nSubstitute the expression for $\\sigma$ from Step 1:\n$$R > \\frac{z_0 \\sqrt{2}}{\\Delta x} \\left(\\frac{\\mathrm{FWHM}}{2\\sqrt{2\\ln(2)}}\\right) - 0.5$$\n$$R > \\frac{z_0 \\, \\mathrm{FWHM}}{2\\Delta x \\sqrt{\\ln(2)}} - 0.5$$\nNow we can substitute the given numerical values: $\\mathrm{FWHM} = 5.0\\,\\mathrm{mm}$, $\\Delta x = 1.25\\,\\mathrm{mm}$, and $z_0 \\approx 3.59929$.\n$$R > \\frac{(3.59929)(5.0)}{2(1.25)\\sqrt{\\ln(2)}} - 0.5$$\n$$R > \\frac{17.99645}{2.5\\sqrt{\\ln(2)}} - 0.5$$\nUsing $\\ln(2) \\approx 0.693147$, we get $\\sqrt{\\ln(2)} \\approx 0.832555$:\n$$R > \\frac{17.99645}{2.5 \\times 0.832555} - 0.5$$\n$$R > \\frac{17.99645}{2.081388} - 0.5$$\n$$R > 8.6464 - 0.5$$\n$$R > 8.1464$$\nSince $R$ must be an integer, the minimal integer value for $R$ that satisfies this inequality is $R=9$.\n\nThe minimal odd integer kernel length $K$ is given by $K = 2R+1$.\n$$K = 2(9) + 1 = 18 + 1 = 19$$\nTherefore, the minimal odd kernel length required is $19$.", "answer": "$$\n\\boxed{19}\n$$", "id": "4540821"}, {"introduction": "An effective image processing pipeline depends on selecting the right tool for the job. This is particularly true for noise reduction, where linear filters like Gaussian smoothing and non-linear, order-statistic filters like the median filter have vastly different effects. This simulation-based practice [@problem_id:4540916] offers a powerful demonstration of this difference, building critical intuition about why a median filter excels at removing impulse noise, such as salt-and-pepper artifacts, while better preserving the sharp edges vital for clinical interpretation.", "problem": "You are given a two-dimensional discrete image model and asked to compare how two filters affect edge localization under salt-and-pepper noise. The core of this task is to construct a binary step-edge image, corrupt it with salt-and-pepper noise, filter it using two different strategies, estimate the edge location from the filtered result, and quantify which filter preserves the edge location better.\n\nStart from the following foundational base:\n- A discrete image is a function $I: \\mathbb{Z}^2 \\to [0,1]$ indexed by integer pixel coordinates.\n- A binary step edge along columns is represented by an image that is constant $0$ on one side of a vertical boundary and constant $1$ on the other.\n- Salt-and-pepper noise is an impulse noise model in which each pixel is independently corrupted: with probability $p/2$ it is set to a minimum value, with probability $p/2$ it is set to a maximum value, and with probability $1-p$ it is left unchanged.\n- Median filtering is a non-linear order-statistic filter that, at each pixel, replaces the value by the median of values in a local neighborhood window.\n- Gaussian smoothing is a linear filtering operation that smooths the image by convolving with an isotropic Gaussian kernel with standard deviation $\\sigma$ (in pixels).\n\nYour program must implement the following scenario and computations precisely:\n1. Construct a clean binary step-edge image $I_0 \\in \\{0,1\\}^{H \\times W}$ of height $H$ and width $W$ with a vertical edge at column index $x_0$. For all pixel coordinates $(y,x)$ with $0 \\le y < H$ and $0 \\le x < W$, define $I_0(y,x) = 0$ if $x < x_0$ and $I_0(y,x) = 1$ if $x \\ge x_0$.\n2. Add salt-and-pepper noise with parameter $p \\in [0,1]$ to obtain $I_\\text{noisy}$. For each pixel independently, draw a uniform random variate $r \\in [0,1)$. If $r < p/2$, set the pixel to $0$; else if $p/2 \\le r < p$, set the pixel to $1$; else leave the pixel unchanged. Use pseudorandom number generation with a specified integer seed $s$ for reproducibility. All random draws must be independent across pixels. All intensity values remain within $[0,1]$.\n3. Apply a two-dimensional median filter to $I_\\text{noisy}$ with a square window of odd side length $k$ (measured in pixels), producing $I_\\text{med}$. Use reflection at image boundaries.\n4. Apply Gaussian smoothing to $I_\\text{noisy}$ with isotropic standard deviation $\\sigma$ (in pixels), producing $I_\\text{gauss}$. Use reflection at image boundaries.\n5. From each filtered image, estimate the edge location along the central row. Let $y_c = \\lfloor H/2 \\rfloor$ be the central row index. Define the one-dimensional row signals $r_\\text{med}[i] = I_\\text{med}(y_c,i)$ and $r_\\text{gauss}[i] = I_\\text{gauss}(y_c,i)$ for integer $i$ with $0 \\le i < W$. Compute the forward discrete difference $d[i] = r[i+1] - r[i]$ for $0 \\le i \\le W-2$ and its absolute value $|d[i]|$. Define the estimated edge index $\\hat{\\imath}$ as the smallest index $i$ at which $|d[i]|$ attains its maximum. Do this separately for the median-filtered and Gaussian-smoothed rows to obtain $\\hat{\\imath}_\\text{med}$ and $\\hat{\\imath}_\\text{gauss}$. The ground-truth edge index for this forward-difference estimator is $i^\\star = x_0 - 1$ (the left pixel of the true transition).\n6. Quantify the edge localization error for each filter as the absolute pixel difference to ground truth: $e_\\text{med} = |\\hat{\\imath}_\\text{med} - i^\\star|$ and $e_\\text{gauss} = |\\hat{\\imath}_\\text{gauss} - i^\\star|$. Report the difference $d^\\star = e_\\text{gauss} - e_\\text{med}$ in pixels. Positive $d^\\star$ indicates that the median filter preserved the edge location better than Gaussian smoothing for that case. All errors and differences are measured in pixels.\n7. All computations are to be performed on finite arrays with reflected boundary conditions for the two filtering steps. The final numerical answers must be expressed in pixels as floating-point numbers rounded to $3$ decimals.\n\nTest suite:\nExecute your program on the following parameter sets. Each test case is a tuple $(H, W, x_0, p, k, \\sigma, s)$ where $H$ and $W$ are integers in pixels, $x_0$ is the integer column index of the step, $p$ is the salt-and-pepper probability as a decimal in $[0,1]$, $k$ is an odd integer window size in pixels, $\\sigma$ is a positive real in pixels, and $s$ is an integer random seed:\n- Case $1$: $(H,W,x_0,p,k,\\sigma,s) = (\\,64,\\,128,\\,64,\\,0.2,\\,3,\\,1.0,\\,42\\,)$\n- Case $2$: $(\\,64,\\,128,\\,64,\\,0.4,\\,3,\\,1.0,\\,7\\,)$\n- Case $3$: $(\\,64,\\,128,\\,64,\\,0.3,\\,5,\\,2.0,\\,123\\,)$\n- Case $4$: $(\\,64,\\,128,\\,5,\\,0.3,\\,3,\\,1.0,\\,999\\,)$\n- Case $5$: $(\\,64,\\,128,\\,64,\\,0.02,\\,3,\\,1.0,\\,2024\\,)$\n- Case $6$: $(\\,64,\\,128,\\,64,\\,0.6,\\,5,\\,1.5,\\,31415\\,)$\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for the cases in the exact order above. Each entry must be the value of $d^\\star$ for the corresponding case, expressed in pixels and rounded to $3$ decimals. For example, a valid output looks like \"[0.125,-0.500,0.000,0.250,0.125,0.375]\".", "solution": "The problem requires a quantitative comparison of a median filter and a Gaussian filter in terms of their ability to preserve edge location in an image corrupted by salt-and-pepper noise. The solution involves a multi-step simulation: creating a synthetic image with a known edge, corrupting it with noise, applying each filter, estimating the edge location from the filtered images, and calculating the localization error. The-core scientific principle being investigated is the differential performance of non-linear versus linear filters on impulse noise.\n\nFirst, a pristine digital image $I_0$ is constructed as a $2$-dimensional array of size $H \\times W$. This image represents a perfect vertical step edge. For any pixel at coordinates $(y,x)$, where $0 \\le y < H$ and $0 \\le x < W$, its intensity is defined as $I_0(y,x) = 0$ if $x < x_0$ and $I_0(y,x) = 1$ if $x \\ge x_0$. The integer $x_0$ marks the column where the edge transition occurs.\n\nNext, this clean image $I_0$ is corrupted to simulate data acquisition artifacts, specifically salt-and-pepper noise. This type of noise is characterized by a probability $p \\in [0,1]$. For each pixel in $I_0$, a random number $r$ is drawn from a uniform distribution on $[0,1)$. If $r < p/2$, the pixel's value is set to the minimum intensity, $0$. If $p/2 \\le r < p$, it is set to the maximum intensity, $1$. Otherwise, with probability $1-p$, the pixel's original value is retained. This process is performed independently for all pixels, resulting in a noisy image $I_\\text{noisy}$. For reproducibility, the pseudorandom number generator is initialized with a specific integer seed $s$.\n\nThe noisy image $I_\\text{noisy}$ is then processed by two distinct filtering methods. Boundary effects during filtering are handled using reflection.\n\nThe first filter is a $2$-dimensional median filter with a square neighborhood of side length $k$ (an odd integer). This is a non-linear, order-statistic filter. At each pixel, it considers all the values in its $k \\times k$ neighborhood, sorts them, and replaces the central pixel's value with the median of the sorted list. The fundamental principle is that impulse noise, such as salt-and-pepper, manifests as extreme values (outliers) in a local neighborhood. The median is robust to such outliers. Consequently, the median filter is highly effective at removing this type of noise while preserving sharp features like edges. The output of this operation is the median-filtered image, $I_\\text{med}$.\n\nThe second filter is a Gaussian smoothing filter, defined by an isotropic Gaussian kernel with standard deviation $\\sigma$. This is a linear filter that operates by convolving the image with the kernel. This is equivalent to replacing each pixel's value with a weighted average of its neighbors, where the weights are given by the Gaussian function and decrease with distance from the center. While this is an optimal linear filter for additive Gaussian noise, it is not well-suited for impulse noise. The extreme values of salt-and-pepper noise are included in the averaging process, which blurs them into their surroundings, thereby smearing the noise rather than eliminating it. This same blurring effect also degrades sharp edges. The output of this operation is the Gaussian-filtered image, $I_\\text{gauss}$.\n\nTo quantify the performance of each filter, the edge location is estimated from the filtered images. The analysis is focused on the central row of each image, indexed by $y_c = \\lfloor H/2 \\rfloor$. The $1$-dimensional signals are extracted: $r_\\text{med}[i] = I_\\text{med}(y_c,i)$ and $r_\\text{gauss}[i] = I_\\text{gauss}(y_c,i)$. An edge is physically a location of high intensity gradient. The gradient is approximated numerically using the forward discrete difference, $d[i] = r[i+1] - r[i]$, for $i$ from $0$ to $W-2$. The estimated edge location, $\\hat{\\imath}$, is defined as the index where the magnitude of this difference is maximal: $\\hat{\\imath} = \\arg\\max_i |d[i]|$. In case of a tie, the smallest index is chosen. This procedure yields two estimates: $\\hat{\\imath}_\\text{med}$ from $r_\\text{med}$ and $\\hat{\\imath}_\\text{gauss}$ from $r_\\text{gauss}$.\n\nThe ground-truth location of the edge, as detected by the forward-difference operator, is at the pixel immediately to the left of the intensity step. The step occurs between column $x_0-1$ (value $0$) and column $x_0$ (value $1$). The forward difference $d[x_0-1] = r[x_0] - r[x_0-1]$ will capture this transition. Thus, the ground-truth index is $i^\\star = x_0-1$.\n\nFinally, the localization error for each filter is computed as the absolute deviation from the ground truth: $e_\\text{med} = |\\hat{\\imath}_\\text{med} - i^\\star|$ and $e_\\text{gauss} = |\\hat{\\imath}_\\text{gauss} - i^\\star|$. To directly compare the two filters, the difference in their errors is calculated: $d^\\star = e_\\text{gauss} - e_\\text{med}$. A positive value of $d^\\star$ signifies that the median filter resulted in a smaller localization error and thus performed better under the given conditions. This entire procedure is executed for each set of parameters provided in the test suite to generate the final results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.ndimage import median_filter, gaussian_filter\n\ndef solve():\n    \"\"\"\n    Implements the full simulation pipeline to compare median and Gaussian\n    filters for edge localization under salt-and-pepper noise.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (H, W, x0, p, k, sigma, s)\n        (64, 128, 64, 0.2, 3, 1.0, 42),\n        (64, 128, 64, 0.4, 3, 1.0, 7),\n        (64, 128, 64, 0.3, 5, 2.0, 123),\n        (64, 128, 5, 0.3, 3, 1.0, 999),\n        (64, 128, 64, 0.02, 3, 1.0, 2024),\n        (64, 128, 64, 0.6, 5, 1.5, 31415),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        H, W, x0, p, k, sigma, s = case\n\n        # Step 1: Construct the clean binary step-edge image\n        I0 = np.zeros((H, W), dtype=np.float64)\n        if x0 < W:\n            I0[:, x0:] = 1.0\n\n        # Step 2: Add salt-and-pepper noise\n        # Use a modern random number generator for better practice\n        rng = np.random.default_rng(s)\n        noise_map = rng.random((H, W))\n        I_noisy = I0.copy()\n        \n        # Pixels to be set to 0\n        I_noisy[noise_map < p / 2.0] = 0.0\n        # Pixels to be set to 1\n        I_noisy[(noise_map >= p / 2.0) & (noise_map < p)] = 1.0\n\n        # Step 3: Apply median filter\n        I_med = median_filter(I_noisy, size=k, mode='reflect')\n\n        # Step 4: Apply Gaussian filter\n        I_gauss = gaussian_filter(I_noisy, sigma=sigma, mode='reflect')\n\n        # Step 5: Estimate edge location from each filtered image\n        y_c = H // 2\n\n        # For Median Filtered Image\n        r_med = I_med[y_c, :]\n        d_med = np.diff(r_med)\n        # argmax returns the first occurrence of max, fulfilling the \"smallest index\" rule\n        i_hat_med = np.argmax(np.abs(d_med))\n\n        # For Gaussian Filtered Image\n        r_gauss = I_gauss[y_c, :]\n        d_gauss = np.diff(r_gauss)\n        i_hat_gauss = np.argmax(np.abs(d_gauss))\n\n        # Step 6: Quantify edge localization error\n        i_star = x0 - 1\n        \n        e_med = np.abs(i_hat_med - i_star)\n        e_gauss = np.abs(i_hat_gauss - i_star)\n        \n        d_star = float(e_gauss - e_med)\n        results.append(d_star)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{val:.3f}\" for val in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4540916"}, {"introduction": "Real-world medical images rarely have uniform resolution; a common example is computed tomography (CT) data with thick slices, leading to anisotropic voxels. Applying a simple isotropic filter to such data can severely degrade image quality by blurring features along the low-resolution axis. This advanced practice [@problem_id:4540846] challenges you to design an anisotropic filter that respects the data's inherent structure, integrating spatial-domain smoothing goals with frequency-domain sharpness constraints via the Modulation Transfer Function (MTF) to achieve a clinically sensible result.", "problem": "You are given a three-dimensional image sampling grid intended to represent a computed tomography (CT) acquisition with anisotropic voxel spacing. The voxel spacings along the orthogonal axes are denoted by $s_x$, $s_y$, and $s_z$ in millimeters. You are tasked with designing a three-dimensional linear smoothing strategy using a Gaussian kernel that preserves in-plane denoising while avoiding through-plane blurring of thin structures. The design should be carried out using first principles that start from the definitions of convolution, the Gaussian point spread function, and the modulation transfer function, and should explicitly reason about sampling along the through-plane direction.\n\nStart from the following core definitions and facts: convolution in discrete space as a sum weighted by a kernel, the Gaussian function as a well-tested smoothing kernel, the concept of a point spread function as the impulse response of a linear shift-invariant system, and the modulation transfer function as the magnitude of the Fourier transform of the point spread function. Use these as the foundational starting point to derive your design. Do not assume any pre-derived \"shortcut\" formula beyond these foundational definitions.\n\nYour program must implement the following specification.\n\n1. Baseline and anisotropic designs\n   - Inputs per test case:\n     - A voxel spacing triplet $(s_x, s_y, s_z)$, each in millimeters.\n     - A target in-plane smoothing scale $\\sigma_{\\text{in}}$ in millimeters.\n   - Baseline isotropic-in-physical-units design:\n     - Use a three-dimensional Gaussian with standard deviations $\\sigma_x = \\sigma_{\\text{in}}$, $\\sigma_y = \\sigma_{\\text{in}}$, and $\\sigma_z = \\sigma_{\\text{in}}$ in millimeters.\n   - Proposed anisotropic design:\n     - Keep in-plane the same as the baseline: $\\sigma_x = \\sigma_{\\text{in}}$ and $\\sigma_y = \\sigma_{\\text{in}}$ in millimeters.\n     - Choose $\\sigma_z$ in millimeters by enforcing a through-plane sharpness constraint at the through-plane Nyquist frequency. Specifically, require that the modulation transfer function along the $z$-axis at $f_z = 0.5$ cycles per voxel is at least a fixed threshold $T_0$ (a decimal). Among all Gaussian $\\sigma_z$ that satisfy this constraint, choose the largest one that does not exceed the baseline value, that is, choose $\\sigma_z$ such that $0 \\le \\sigma_z \\le \\sigma_{\\text{in}}$ and the modulation transfer function requirement holds with equality if possible. The frequency variable $f_z$ is measured in cycles per voxel along the $z$-axis, and the threshold $T_0$ must be treated as dimensionless.\n\n2. Discrete leakage metric along the through-plane direction\n   - For any one-dimensional Gaussian standard deviation expressed in voxel units $\\sigma_{\\text{vox}}$, construct a symmetric, normalized, one-dimensional discrete Gaussian kernel $k[n]$ along the $z$-axis by sampling the continuous Gaussian on integer positions $n$ from $-R$ to $R$, where $R = \\lceil 3 \\sigma_{\\text{vox}} \\rceil$. Use weights proportional to $\\exp\\!\\left(-\\frac{n^2}{2 \\sigma_{\\text{vox}}^2}\\right)$, and then normalize the weights so that they sum to $1$. If $\\sigma_{\\text{vox}} = 0$, interpret the kernel as a Kronecker delta at $n = 0$.\n   - Define the through-plane leakage fraction $L_z$ as the total probability mass outside the central slice:\n     $$L_z = 1 - \\frac{k[0]}{\\sum_{n=-R}^{R} k[n]}.$$\n     Under exact normalization, the denominator equals $1$, but you must implement the discrete construction explicitly and compute the leakage from the resulting normalized kernel.\n\n3. Modulation transfer function evaluation\n   - Model the modulation transfer function along the $z$-axis using the Gaussian point spread function, evaluated at frequency $f_z = 0.5$ cycles per voxel. Provide a principled derivation in your solution for how to compute the modulation transfer function of a Gaussian in terms of its standard deviation in voxel units. Then, use that to compute the modulation transfer function values $M_z$ for both the baseline design and the anisotropic design at $f_z = 0.5$ cycles per voxel.\n\n4. Comparison criterion\n   - For each test case, output a boolean indicating whether the proposed anisotropic design strictly reduces through-plane leakage and strictly increases through-plane modulation transfer at Nyquist compared to the baseline isotropic-in-physical-units design. Formally, compute $L_z^{\\text{base}}$, $M_z^{\\text{base}}$, $L_z^{\\text{aniso}}$, and $M_z^{\\text{aniso}}$. Output true if and only if $L_z^{\\text{aniso}} < L_z^{\\text{base}}$ and $M_z^{\\text{aniso}} > M_z^{\\text{base}}$.\n\n5. Units and conversions\n   - When computing the discrete kernels and modulation transfer function along $z$, convert any through-plane standard deviation given in millimeters to voxel units by dividing by $s_z$ (in millimeters). The through-plane Nyquist frequency of $f_z = 0.5$ must be interpreted in cycles per voxel.\n\n6. Global design constant\n   - Use a fixed modulation transfer threshold $T_0 = 0.9$ for all test cases.\n\n7. Test suite\n   - Your program must evaluate exactly the following five test cases, each specified as $((s_x,s_y,s_z), \\sigma_{\\text{in}})$ with spacings in millimeters and smoothing scale in millimeters:\n     - Case $1$: $((0.6, 0.6, 3.0), 1.0)$\n     - Case $2$: $((0.8, 0.8, 1.0), 0.8)$\n     - Case $3$: $((0.5, 0.7, 5.0), 1.2)$\n     - Case $4$: $((0.5, 0.5, 10.0), 1.0)$\n     - Case $5$: $((0.5, 0.5, 3.0), 0.2)$\n\n8. Final output format\n   - Your program should produce a single line of output containing the results as a comma-separated list of lowercase booleans enclosed in square brackets, for example, \"[true,false,true,false,true]\". No additional text or spaces are permitted in the output. Angles are not involved, so no angle units are required. All quantities expressed in millimeters must be handled as specified above, and the final outputs are unitless booleans.", "solution": "The problem is valid. It is scientifically grounded in the principles of linear systems and signal processing, is well-posed with all necessary information provided, and is formulated objectively. We will now proceed with a complete, reasoned solution.\n\nThe objective is to design and compare two Gaussian smoothing strategies for anisotropic three-dimensional image data, starting from foundational principles. The comparison hinges on the through-plane modulation transfer function (MTF) and a discrete leakage metric.\n\n### Foundational Principles: PSF and MTF\n\nA linear shift-invariant (LSI) filtering operation is described by convolution. The output signal is the convolution of the input signal with the filter's impulse response, known as the Point Spread Function (PSF). For our one-dimensional analysis along the $z$-axis, the PSF is a continuous Gaussian function, $g(z; \\sigma_z)$, with standard deviation $\\sigma_z$ in physical units (e.g., millimeters):\n$$g(z; \\sigma_z) = \\frac{1}{\\sqrt{2\\pi}\\sigma_z} e^{-\\frac{z^2}{2\\sigma_z^2}}$$\nThis function is normalized such that $\\int_{-\\infty}^{\\infty} g(z; \\sigma_z) dz = 1$.\n\nThe Modulation Transfer Function (MTF) is a crucial metric for characterizing the resolution of an imaging system or filter. It is defined as the magnitude of the Fourier Transform of the PSF. Let $k_z$ be the spatial frequency along the $z$-axis in units of cycles per millimeter. The Fourier Transform of the PSF, $G(k_z)$, is:\n$$G(k_z) = \\mathcal{F}\\{g(z; \\sigma_z)\\} = \\int_{-\\infty}^{\\infty} g(z; \\sigma_z) e^{-i 2\\pi k_z z} dz$$\nUsing the known Fourier transform pair for a Gaussian function, which states that the Fourier transform of $e^{-ax^2}$ is $\\sqrt{\\pi/a} e^{-(\\pi k)^2/a}$, we can derive $G(k_z)$. Our function is proportional to $e^{-z^2 / (2\\sigma_z^2)}$. The transform is:\n$$G(k_z) = \\frac{1}{\\sqrt{2\\pi}\\sigma_z} \\mathcal{F}\\left\\{e^{-\\frac{z^2}{2\\sigma_z^2}}\\right\\} = \\frac{1}{\\sqrt{2\\pi}\\sigma_z} \\left( \\sqrt{2\\pi\\sigma_z^2} e^{-\\frac{(2\\pi k_z)^2}{4 \\cdot (1/(2\\sigma_z^2))}} \\right) = e^{-2\\pi^2 k_z^2 \\sigma_z^2}$$\nThe MTF, $M(k_z)$, is the magnitude of $G(k_z)$. Since $G(k_z)$ is real and positive, the MTF is simply:\n$$M(k_z) = |G(k_z)| = e^{-2\\pi^2 k_z^2 \\sigma_z^2}$$\nThe problem specifies frequency in dimensionless units of cycles per voxel, denoted $f_z$. The relationship between physical frequency $k_z$ (cycles/mm) and discrete frequency $f_z$ (cycles/voxel) is $k_z = f_z / s_z$, where $s_z$ is the voxel spacing in millimeters. Substituting this into the MTF equation gives:\n$$M(f_z) = e^{-2\\pi^2 (f_z/s_z)^2 \\sigma_z^2} = e^{-2\\pi^2 f_z^2 (\\sigma_z/s_z)^2}$$\nLet us define the standard deviation in voxel units as $\\sigma_{z, \\text{vox}} = \\sigma_z / s_z$. The MTF equation simplifies to:\n$$M(f_z) = e^{-2\\pi^2 f_z^2 \\sigma_{z, \\text{vox}}^2}$$\nThis is the central formula for our MTF calculations.\n\n### Design and Analysis\n\nWe will analyze two designs: a baseline isotropic design and a proposed anisotropic design.\n\n#### 1. Baseline Isotropic Design\nIn this design, the smoothing is isotropic in physical space. The through-plane standard deviation is set to the in-plane target:\n$$\\sigma_{z, \\text{base}} = \\sigma_{\\text{in}}$$\nTo evaluate its MTF, we first convert this to voxel units:\n$$\\sigma_{z, \\text{base, vox}} = \\frac{\\sigma_{z, \\text{base}}}{s_z} = \\frac{\\sigma_{\\text{in}}}{s_z}$$\nThe MTF at the through-plane Nyquist frequency, $f_z = 0.5$ cycles/voxel, is:\n$$M_z^{\\text{base}} = M(f_z=0.5) = e^{-2\\pi^2 (0.5)^2 \\sigma_{z, \\text{base, vox}}^2} = e^{-(\\pi^2/2) (\\sigma_{\\text{in}}/s_z)^2}$$\n\n#### 2. Proposed Anisotropic Design\nThis design aims to preserve through-plane sharpness by constraining the MTF. The in-plane smoothing remains $\\sigma_x = \\sigma_y = \\sigma_{\\text{in}}$. The through-plane standard deviation, $\\sigma_{z, \\text{aniso}}$, is chosen to be the largest value satisfying two conditions:\n1.  The MTF at the Nyquist frequency ($f_z=0.5$) is at least $T_0$: $M(0.5) \\geq T_0$.\n2.  The smoothing is no greater than the baseline: $0 \\le \\sigma_{z, \\text{aniso}} \\le \\sigma_{\\text{in}}$.\n\nLet's solve the MTF constraint for $\\sigma_{z, \\text{aniso, vox}}$:\n$$e^{-(\\pi^2/2) \\sigma_{z, \\text{aniso, vox}}^2} \\geq T_0$$\nTaking the natural logarithm of both sides (and noting $\\ln(T_0)$ is negative for $T_0=0.9$):\n$$-(\\pi^2/2) \\sigma_{z, \\text{aniso, vox}}^2 \\geq \\ln(T_0)$$\n$$\\sigma_{z, \\text{aniso, vox}}^2 \\leq -\\frac{2\\ln(T_0)}{\\pi^2}$$\n$$\\sigma_{z, \\text{aniso, vox}} \\leq \\sqrt{-\\frac{2\\ln(T_0)}{\\pi^2}}$$\nTo maximize $\\sigma_{z, \\text{aniso}}$ (and thus $\\sigma_{z, \\text{aniso, vox}}$), we take the upper bound. The target standard deviation in physical units that meets the MTF constraint with equality is:\n$$\\sigma_{z, \\text{max_allowed}} = s_z \\cdot \\sqrt{-\\frac{2\\ln(T_0)}{\\pi^2}}$$\nApplying the second condition, $0 \\le \\sigma_{z, \\text{aniso}} \\le \\sigma_{\\text{in}}$, the final choice for the anisotropic standard deviation is:\n$$\\sigma_{z, \\text{aniso}} = \\min\\left(\\sigma_{\\text{in}}, \\sigma_{z, \\text{max_allowed}}\\right) = \\min\\left(\\sigma_{\\text{in}}, s_z \\sqrt{-\\frac{2\\ln(0.9)}{\\pi^2}}\\right)$$\nThe corresponding MTF is calculated using $\\sigma_{z, \\text{aniso, vox}} = \\sigma_{z, \\text{aniso}} / s_z$:\n$$M_z^{\\text{aniso}} = e^{-(\\pi^2/2) \\sigma_{z, \\text{aniso, vox}}^2}$$\n\n#### 3. Through-Plane Leakage Metric ($L_z$)\nThe leakage fraction $L_z$ quantifies how much of the smoothing kernel's mass \"leaks\" into adjacent $z$-slices. It is calculated from a discrete 1D Gaussian kernel, $k[n]$. For a given standard deviation in voxel units, $\\sigma_{\\text{vox}}$, the kernel is constructed as follows.\nFirst, determine the kernel's half-width: $R = \\lceil 3\\sigma_{\\text{vox}} \\rceil$. The kernel support is $n \\in \\{-R, -R+1, \\dots, R-1, R\\}$.\nThe unnormalized weights are given by sampling the Gaussian function at integer locations:\n$$w[n] = e^{-\\frac{n^2}{2\\sigma_{\\text{vox}}^2}}$$\nThe sum of these weights is $S = \\sum_{n=-R}^{R} w[n]$. The normalized kernel is $k[n] = w[n]/S$.\nThe leakage fraction is the mass outside the central element ($n=0$):\n$$L_z = 1 - k[0]$$\nSince $w[0] = e^0 = 1$, we have $k[0] = 1/S$. Therefore,\n$$L_z = 1 - \\frac{1}{\\sum_{n=-R}^{R} e^{-n^2 / (2\\sigma_{\\text{vox}}^2)}}$$\nThis calculation is performed for both $\\sigma_{z, \\text{base, vox}}$ and $\\sigma_{z, \\text{aniso, vox}}$ to obtain $L_z^{\\text{base}}$ and $L_z^{\\text{aniso}}$, respectively. If $\\sigma_{\\text{vox}}=0$, the kernel is a Kronecker delta, $k[0]=1$ and $L_z=0$.\n\n#### 4. Comparison Criterion\nThe final output for each test case is a boolean value indicating if the anisotropic design is strictly superior to the baseline in both sharpness and leakage. This is true if and only if both of the following strict inequalities hold:\n$$M_z^{\\text{aniso}} > M_z^{\\text{base}} \\quad \\text{and} \\quad L_z^{\\text{aniso}} < L_z^{\\text{base}}$$\nBoth the MTF and the leakage fraction are monotonically related to $\\sigma_{z, \\text{vox}}$. A smaller $\\sigma_{z, \\text{vox}}$ results in a sharper kernel, which corresponds to a higher MTF value and lower leakage. Thus, both inequalities are simultaneously satisfied if and only if $\\sigma_{z, \\text{aniso, vox}} < \\sigma_{z, \\text{base, vox}}$, which is equivalent to $\\sigma_{z, \\text{aniso}} < \\sigma_{z, \\text{base}}$. This occurs precisely when the baseline MTF is below the threshold $T_0$, i.e., $M_z^{\\text{base}} < T_0 = 0.9$, forcing the anisotropic design to use a smaller, non-baseline $\\sigma_z$. If $M_z^{\\text{base}} \\ge T_0$, then $\\sigma_{z, \\text{aniso}} = \\sigma_{z, \\text{base}}$, and the strict inequalities are not met. The implementation will compute all four metrics explicitly and perform the comparison.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_metrics(sigma_mm: float, s_z: float):\n    \"\"\"\n    Calculates the through-plane MTF and leakage for a given smoothing standard deviation.\n\n    Args:\n        sigma_mm: The Gaussian standard deviation in millimeters.\n        s_z: The voxel spacing along the z-axis in millimeters.\n\n    Returns:\n        A tuple (mtf, leakage).\n    \"\"\"\n    # If sigma_mm is zero, sigma_vox is also zero.\n    # The PSF is a Dirac delta, its Fourier transform is flat (MTF=1).\n    # The discrete kernel is a Kronecker delta, so all mass is at n=0 (leakage=0).\n    if sigma_mm == 0.0 or s_z == 0.0:\n        return 1.0, 0.0\n\n    sigma_vox = sigma_mm / s_z\n\n    # Calculate MTF at the Nyquist frequency (f_z = 0.5 cycles/voxel)\n    # Formula: M(f_z) = exp(-2 * pi^2 * f_z^2 * sigma_vox^2)\n    # With f_z = 0.5, this simplifies to M = exp(-(pi^2 / 2) * sigma_vox^2)\n    mtf = np.exp(-(np.pi**2 / 2.0) * (sigma_vox**2))\n\n    # Calculate through-plane leakage L_z\n    # The kernel radius is R = ceil(3 * sigma_vox)\n    R = int(np.ceil(3.0 * sigma_vox))\n    \n    # integer positions n from -R to R\n    n_values = np.arange(-R, R + 1)\n    \n    # Unnormalized kernel weights w[n] = exp(-n^2 / (2 * sigma_vox^2))\n    weights = np.exp(-(n_values**2) / (2.0 * sigma_vox**2))\n    \n    # Sum of weights for normalization\n    total_weight = np.sum(weights)\n    \n    # The central weight k[0] is w[0]/S. Since w[0] = exp(0) = 1, k[0] = 1/S.\n    # We must handle the case where total_weight is zero or numerically unstable,\n    # though for this problem it should always be >= 1.0.\n    if total_weight == 0.0:\n        k_0 = 0.0\n    else:\n        k_0 = 1.0 / total_weight\n    \n    # Leakage L_z = 1 - k[0]\n    leakage = 1.0 - k_0\n\n    return mtf, leakage\n\ndef solve():\n    \"\"\"\n    Solves the problem for the specified test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Format: ((s_x, s_y, s_z), sigma_in)\n    test_cases = [\n        ((0.6, 0.6, 3.0), 1.0),\n        ((0.8, 0.8, 1.0), 0.8),\n        ((0.5, 0.7, 5.0), 1.2),\n        ((0.5, 0.5, 10.0), 1.0),\n        ((0.5, 0.5, 3.0), 0.2),\n    ]\n\n    # Global design constant\n    T0 = 0.9\n\n    results = []\n    for case in test_cases:\n        (sx, sy, sz), sigma_in = case\n\n        # 1. Baseline isotropic-in-physical-units design\n        sigma_z_base = sigma_in\n        mtf_base, leakage_base = calculate_metrics(sigma_z_base, sz)\n\n        # 2. Proposed anisotropic design\n        # First, find the maximum sigma_z (in mm) that satisfies MTF >= T0\n        # M = exp(-(pi^2/2) * (sigma_vox^2)) >= T0\n        # sigma_vox <= sqrt(-2 * log(T0) / pi^2)\n        # sigma_mm <= sz * sqrt(-2 * log(T0) / pi^2)\n        log_T0 = np.log(T0)\n        # Check for invalid log domain, though T0=0.9 is safe.\n        if log_T0 > 0:\n            sigma_z_max_allowed = 0.0 # No positive sigma satisfies the constraint\n        else:\n            sigma_z_max_allowed = sz * np.sqrt(-2.0 * log_T0 / np.pi**2)\n        \n        # The anisotropic sigma_z is the largest value satisfying both constraints\n        # sigma_z <= sigma_in AND sigma_z <= sigma_z_max_allowed\n        sigma_z_aniso = min(sigma_in, sigma_z_max_allowed)\n\n        mtf_aniso, leakage_aniso = calculate_metrics(sigma_z_aniso, sz)\n        \n        # 3. Comparison Criterion\n        # Output true if anisotropic design is strictly better on both metrics\n        is_strictly_better = (leakage_aniso < leakage_base) and (mtf_aniso > mtf_base)\n        \n        results.append(str(is_strictly_better).lower())\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "4540846"}]}