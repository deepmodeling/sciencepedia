{"hands_on_practices": [{"introduction": "A solid grasp of statistical power begins with deriving its core formula from first principles. This exercise [@problem_id:4610103] challenges you to build the power and sample size equations for a one-sample $z$-test from the ground up. By working through this fundamental case, you will gain a deep, mechanistic understanding of how study parameters—effect size, variance, sample size, and significance level—interact to determine the probability of detecting a true effect.", "problem": "A translational genomics team is evaluating whether the mean $\\log_2$-normalized expression level of a therapy-responsive biomarker in a single-arm study exceeds a clinically relevant threshold. Prior platform calibration and extensive historical controls justify treating the measurement standard deviation as known and stable across subjects. Let the null hypothesis be $H_{0}: \\mu = \\mu_{0}$ and the scientific alternative be $H_{1}: \\mu > \\mu_{0}$, where $\\mu$ is the true population mean biomarker expression and $\\mu_{0}$ is the threshold.\n\nFundamental base assumptions: by the Central Limit Theorem (CLT), for independent subjects the sample mean $\\bar{X}$ of $n$ subjects is approximately normal with mean $\\mu$ and variance $\\sigma^{2}/n$; a one-sample $z$-test uses the standardized statistic $Z = (\\bar{X} - \\mu_{0})/(\\sigma/\\sqrt{n})$, where $\\sigma$ is treated as known from prior calibration. The significance level $\\alpha$ is the Type I error probability, and the statistical power is $1 - \\beta$, where $\\beta$ is the Type II error probability under a specific true mean $\\mu_{1}$.\n\nScenario: suppose the clinically relevant threshold is $\\mu_{0} = 0$, the anticipated true mean under the therapy is $\\mu_{1} = 0.3$, the known standard deviation is $\\sigma = 0.6$, the planned pilot sample size is $n = 30$, and the study will use a one-sided test at $\\alpha = 0.01$.\n\nTasks:\n1. Using only the fundamental base above, derive the sampling distribution of the $z$-statistic under $H_{0}$ and under the specific alternative $\\mu = \\mu_{1}$, and from first principles compute the exact analytic form of the power function for the one-sided test at significance level $\\alpha$. Then evaluate the power at the given values $\\mu_{0}$, $\\mu_{1}$, $\\sigma$, $n$, and $\\alpha$. Express the power as a decimal (not a percentage).\n2. Invert the derived power expression to obtain a closed-form expression for the minimum sample size $n$ required to achieve target power $1 - \\beta = 0.9$ at the same $\\alpha$ for detecting the shift from $\\mu_{0}$ to $\\mu_{1}$ with known $\\sigma$.\n3. Compute this minimum $n$ numerically for the given $\\mu_{0}$, $\\mu_{1}$, $\\sigma$, and $\\alpha$. Report your final numerical answer as the smallest integer $n$ that meets or exceeds the target power.\n\nThe final answer must be a single number. No rounding instruction is needed beyond reporting the smallest integer $n$.", "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\nThe verbatim givens extracted from the problem statement are:\n- Null hypothesis: $H_{0}: \\mu = \\mu_{0}$\n- Alternative hypothesis: $H_{1}: \\mu > \\mu_{0}$\n- $\\mu$: true population mean biomarker expression\n- $\\mu_{0}$: clinically relevant threshold\n- Sample mean distribution: $\\bar{X} \\sim N(\\mu, \\sigma^{2}/n)$ approximately, for $n$ independent subjects\n- Test statistic: $Z = (\\bar{X} - \\mu_{0})/(\\sigma/\\sqrt{n})$\n- $\\sigma$: known standard deviation\n- $\\alpha$: significance level (Type I error probability)\n- $1 - \\beta$: statistical power\n- $\\beta$: Type II error probability under a specific true mean $\\mu_{1}$\n- Scenario values for Task 1: $\\mu_{0} = 0$, $\\mu_{1} = 0.3$, $\\sigma = 0.6$, $n = 30$, $\\alpha = 0.01$ (one-sided test)\n- Target values for Task 2 & 3: Power $1 - \\beta = 0.9$, $\\alpha = 0.01$, $\\mu_{0} = 0$, $\\mu_{1} = 0.3$, $\\sigma = 0.6$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity:\n- **Scientifically Grounded**: The problem is a canonical application of statistical hypothesis testing, power analysis, and sample size determination based on the normal distribution and the Central Limit Theorem. The context of biomarker analysis in translational genomics is a standard and appropriate setting for such methods. The problem is fundamentally sound.\n- **Well-Posed**: All necessary parameters ($\\mu_0, \\mu_1, \\sigma, \\alpha, \\text{target power}, n$) are provided for each task. The objectives are clearly stated, leading to a unique and meaningful solution for each part.\n- **Objective**: The problem is stated using precise, standard statistical terminology and quantitative values. It is free from ambiguity, subjectivity, or opinion-based claims.\n- **Other Flaws**: The problem does not violate any other validity criteria. It is complete, consistent, realistic, and directly relevant to the specified topic of statistical power in bioinformatics.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A complete, reasoned solution will now be provided.\n\n---\n\n### Solution Derivations\n\n#### Task 1: Power Function Derivation and Evaluation\n\n**Distribution of the Test Statistic**\n\nThe problem states that the sample mean $\\bar{X}$ is approximately normally distributed, $\\bar{X} \\sim N(\\mu, \\sigma^2/n)$. The test statistic is $Z = (\\bar{X} - \\mu_{0})/(\\sigma/\\sqrt{n})$.\n\n1.  **Under the null hypothesis ($H_{0}$)**: The true mean is $\\mu = \\mu_{0}$. The distribution of the sample mean is $\\bar{X} \\sim N(\\mu_{0}, \\sigma^2/n)$. The test statistic $Z = (\\bar{X} - \\mu_{0})/(\\sigma/\\sqrt{n})$ is a standard linear transformation of a normal variable to its standard form. Thus, under $H_{0}$, the statistic $Z$ follows a standard normal distribution:\n    $$Z \\sim N(0, 1)$$\n\n2.  **Under the specific alternative hypothesis ($H_{1}$)**: The true mean is specified as $\\mu = \\mu_{1}$. The distribution of the sample mean is $\\bar{X} \\sim N(\\mu_{1}, \\sigma^2/n)$. The test statistic $Z$ is still calculated with respect to $\\mu_{0}$. Its distribution under this alternative is found by calculating its expectation and variance:\n    $$E[Z] = E\\left[\\frac{\\bar{X} - \\mu_{0}}{\\sigma/\\sqrt{n}}\\right] = \\frac{E[\\bar{X}] - \\mu_{0}}{\\sigma/\\sqrt{n}} = \\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}}$$\n    $$Var(Z) = Var\\left(\\frac{\\bar{X} - \\mu_{0}}{\\sigma/\\sqrt{n}}\\right) = \\frac{Var(\\bar{X})}{(\\sigma/\\sqrt{n})^2} = \\frac{\\sigma^2/n}{\\sigma^2/n} = 1$$\n    Thus, under the specific alternative $\\mu=\\mu_1$, the statistic $Z$ follows a non-standard normal distribution:\n    $$Z \\sim N\\left(\\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}}, 1\\right)$$\n\n**Derivation of the Power Function**\n\nFor a one-sided test $H_1: \\mu > \\mu_0$ at significance level $\\alpha$, we reject $H_0$ if the observed test statistic $Z_{obs}$ exceeds the critical value $z_{\\alpha}$. The critical value $z_{\\alpha}$ is defined as the upper $\\alpha$-quantile of the standard normal distribution, satisfying $P(Z > z_{\\alpha} | H_0) = \\alpha$, where $Z \\sim N(0, 1)$.\n\nPower ($1-\\beta$) is the probability of correctly rejecting $H_0$ when the alternative hypothesis is true, i.e., when $\\mu = \\mu_{1}$.\n$$1 - \\beta = \\text{Power} = P(Z_{obs} > z_{\\alpha} | \\mu = \\mu_{1})$$\nSince $Z_{obs} = (\\bar{X} - \\mu_{0})/(\\sigma/\\sqrt{n})$, and under $\\mu = \\mu_1$, we have $\\bar{X} \\sim N(\\mu_1, \\sigma^2/n)$, we can standardize this probability statement with respect to the true mean $\\mu_1$.\n$$\\text{Power} = P\\left(\\frac{\\bar{X} - \\mu_{0}}{\\sigma/\\sqrt{n}} > z_{\\alpha}\\right)$$\nWe manipulate the term inside the probability:\n$$\\frac{\\bar{X} - \\mu_{0}}{\\sigma/\\sqrt{n}} = \\frac{(\\bar{X} - \\mu_{1}) + (\\mu_{1} - \\mu_{0})}{\\sigma/\\sqrt{n}} = \\frac{\\bar{X} - \\mu_{1}}{\\sigma/\\sqrt{n}} + \\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}}$$\nThe term $Z' = (\\bar{X} - \\mu_{1})/(\\sigma/\\sqrt{n})$ is a standard normal variable, $Z' \\sim N(0, 1)$, because $\\bar{X} \\sim N(\\mu_1, \\sigma^2/n)$. Substituting this back into the power expression:\n$$\\text{Power} = P\\left(Z' + \\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}} > z_{\\alpha}\\right) = P\\left(Z' > z_{\\alpha} - \\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}}\\right)$$\nLet $\\Phi(\\cdot)$ be the cumulative distribution function (CDF) of the standard normal distribution. Then $P(Z' > k) = 1 - \\Phi(k)$. Using the symmetry property $\\Phi(-x) = 1 - \\Phi(x)$, this can also be written as $\\Phi(-k)$. Therefore, the exact analytic form of the power function is:\n$$\\text{Power}(\\mu_1) = 1 - \\Phi\\left(z_{\\alpha} - \\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}}\\right) = \\Phi\\left(\\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}} - z_{\\alpha}\\right)$$\n\n**Evaluation of Power**\n\nGiven values are: $\\mu_{0} = 0$, $\\mu_{1} = 0.3$, $\\sigma = 0.6$, $n = 30$, and $\\alpha = 0.01$.\nFirst, find the critical value $z_{\\alpha} = z_{0.01}$. This value satisfies $\\Phi(z_{0.01}) = 1 - 0.01 = 0.99$. From standard normal tables or a calculator, $z_{0.01} \\approx 2.3263$.\nNow substitute the values into the power formula:\n$$\\text{Power} = \\Phi\\left(\\frac{0.3 - 0}{0.6/\\sqrt{30}} - 2.3263\\right)$$\n$$\\text{Power} = \\Phi\\left(\\frac{0.3\\sqrt{30}}{0.6} - 2.3263\\right) = \\Phi\\left(0.5\\sqrt{30} - 2.3263\\right)$$\nNumerically evaluating the argument:\n$$0.5\\sqrt{30} - 2.3263 \\approx 0.5 \\times 5.4772 - 2.3263 = 2.7386 - 2.3263 = 0.4123$$\n$$\\text{Power} = \\Phi(0.4123) \\approx 0.6600$$\nThe power of the study with $n=30$ is approximately $0.6600$.\n\n#### Task 2: Derivation of the Sample Size Formula\n\nThe goal is to find the minimum sample size $n$ to achieve a target power of $1 - \\beta$. We start from the power expression derived in Task 1:\n$$\\text{Power} = 1 - \\beta = \\Phi\\left(\\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}} - z_{\\alpha}\\right)$$\nApplying the inverse normal CDF, $\\Phi^{-1}$, to both sides:\n$$\\Phi^{-1}(1 - \\beta) = \\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}} - z_{\\alpha}$$\nThe standard notation for the upper $\\beta$-quantile is $z_{\\beta}$, which satisfies $P(Z > z_{\\beta}) = \\beta$, or $\\Phi(z_{\\beta}) = 1 - \\beta$. Therefore, $\\Phi^{-1}(1-\\beta)$ is simply $z_{\\beta}$.\n$$z_{\\beta} = \\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}} - z_{\\alpha}$$\nNow, we rearrange the equation to solve for $n$:\n$$z_{\\alpha} + z_{\\beta} = \\frac{\\mu_{1} - \\mu_{0}}{\\sigma/\\sqrt{n}}$$\n$$\\sqrt{n} = \\frac{\\sigma(z_{\\alpha} + z_{\\beta})}{\\mu_{1} - \\mu_{0}}$$\nSquaring both sides gives the closed-form expression for the sample size $n$:\n$$n = \\left(\\frac{\\sigma(z_{\\alpha} + z_{\\beta})}{\\mu_{1} - \\mu_{0}}\\right)^2$$\n\n#### Task 3: Numerical Calculation of Sample Size $n$\n\nWe are given: $\\mu_{0} = 0$, $\\mu_{1} = 0.3$, $\\sigma = 0.6$, $\\alpha = 0.01$, and target power $1 - \\beta = 0.9$, which implies $\\beta = 0.1$.\n\nWe need the critical values for $\\alpha$ and $\\beta$:\n1.  $z_{\\alpha} = z_{0.01}$: The upper $1\\%$ point of the standard normal distribution. $P(Z > z_{0.01}) = 0.01$. As before, $z_{0.01} \\approx 2.3263$.\n2.  $z_{\\beta} = z_{0.1}$: The upper $10\\%$ point of the standard normal distribution. $P(Z > z_{0.1}) = 0.1$. From tables, $z_{0.1} \\approx 1.2816$.\n\nSubstitute these values into the derived formula for $n$:\n$$n = \\left(\\frac{0.6(2.3263 + 1.2816)}{0.3 - 0}\\right)^2$$\n$$n = \\left(\\frac{0.6(3.6079)}{0.3}\\right)^2$$\n$$n = (2 \\times 3.6079)^2$$\n$$n = (7.2158)^2$$\n$$n \\approx 52.0677$$\nSince the sample size $n$ must be an integer, and we need to meet or exceed the target power, we must round the calculated value up to the next integer.\n$$n_{min} = \\lceil 52.0677 \\rceil = 53$$\nTherefore, the minimum required sample size is $53$.", "answer": "$$\\boxed{53}$$", "id": "4610103"}, {"introduction": "Moving from initial discovery to validated science requires successful replication, but many promising findings fail this test. This practice [@problem_id:4610085] explores a key reason: the \"winner's curse,\" a statistical phenomenon where the effect sizes of initial, significant findings tend to be inflated. You will quantify how this initial overestimation impacts the true power of a subsequent replication study, providing a crucial lesson in tempering expectations and planning for robust validation.", "problem": "A translational oncology team investigates a protein biomarker whose effect on a continuous clinical risk score has been standardized so that the discovery and replication analyses can be conducted using a one-sided $z$-test. In the initial discovery study, the team targeted power $\\pi_{0}$ against a right-sided alternative at significance level $\\alpha_{0}$, and achieved that power based on the true noncentral mean $ \\mu_{1}$ of the $z$-statistic under the alternative. The biology and data-generating mechanism in both studies are stable, so the standardized $z$-statistic under the alternative in each study can be modeled as $Z \\sim \\mathcal{N}(\\mu,1)$, where $\\mu$ is the study-specific noncentral mean.\n\nAfter discovery, they plan a direction-consistent replication using the same standardized one-sided $z$-test at replication significance level $\\alpha_{\\mathrm{rep}}$. However, due to selection on statistical significance, the initial estimate of the effect is inflated (winner’s curse), and the true noncentral mean carried into replication is attenuated by a multiplicative factor $b \\in (0,1)$ relative to $\\mu_{1}$.\n\nAssume the following scientifically plausible quantities for this biomarker analysis:\n- Initial power $\\pi_{0} = 0.80$ for a one-sided right-tailed $z$-test at $\\alpha_{0} = 0.005$.\n- Winner’s curse attenuation factor $b = 0.65$, meaning the replication noncentral mean is $\\mu_{2} = b \\mu_{1}$.\n- Replication uses a one-sided right-tailed $z$-test at $\\alpha_{\\mathrm{rep}} = 0.025$.\n\nUsing only fundamental definitions of hypothesis testing for the normal model, compute the probability that the replication study will yield a statistically significant result in the same direction at level $\\alpha_{\\mathrm{rep}}$. Express your final answer as a decimal and round to four significant figures.", "solution": "The user wants me to solve a statistical power problem related to a replication study in bioinformatics. I must first validate the problem statement.\n\n### Step 1: Extract Givens\n- The test is a one-sided, right-tailed $z$-test.\n- The test statistic under the alternative is modeled as $Z \\sim \\mathcal{N}(\\mu,1)$, where $\\mu$ is the study-specific noncentral mean.\n- Initial discovery study power: $\\pi_{0} = 0.80$.\n- Initial discovery study significance level: $\\alpha_{0} = 0.005$.\n- The true noncentral mean in the discovery study is $\\mu_{1}$.\n- Replication study significance level: $\\alpha_{\\mathrm{rep}} = 0.025$.\n- Winner’s curse attenuation factor: $b = 0.65$.\n- The noncentral mean for the replication study is $\\mu_{2} = b \\mu_{1}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the required criteria:\n- **Scientifically Grounded**: The problem is well-grounded in the statistical theory of hypothesis testing. The concepts of power, significance level, noncentrality parameters for a $z$-test, and the 'winner's curse' are standard and widely applied in fields like biostatistics and medical data analytics. The provided model $Z \\sim \\mathcal{N}(\\mu,1)$ is a standard theoretical framework for $z$-statistics derived from large samples. The numerical values for power and significance levels are conventional.\n- **Well-Posed**: The problem asks for a specific, calculable quantity: the probability of a significant result in the replication study (i.e., its statistical power). It provides sufficient information to determine this value uniquely. The relationship between the given parameters ($\\pi_0, \\alpha_0, \\alpha_{\\text{rep}}, b$) and the desired outcome is mathematically well-defined.\n- **Objective**: The problem is stated in precise, formal, and unbiased language. It is free of subjective or opinion-based assertions.\n- **Completeness and Consistency**: The problem is self-contained. All necessary data and relationships are provided, and they are internally consistent without contradiction.\n- **Realism**: The scenario described is a realistic challenge in translational research, where initial findings may be subject to effect size inflation, and replication power is a critical concern.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is scientifically sound, well-posed, objective, and complete. I will proceed with a full solution.\n\nThe solution will be derived in three main steps:\n1.  Determine the noncentral mean of the discovery study, $\\mu_{1}$, based on its specified power $\\pi_{0}$ and significance level $\\alpha_{0}$.\n2.  Calculate the attenuated noncentral mean for the replication study, $\\mu_{2}$, using the winner's curse factor $b$.\n3.  Compute the power of the replication study, $\\pi_{\\mathrm{rep}}$, which is the desired probability of obtaining a significant result at significance level $\\alpha_{\\mathrm{rep}}$ with the noncentral mean $\\mu_{2}$.\n\nFor a one-sided, right-tailed $z$-test conducted at a significance level $\\alpha$, the null hypothesis is rejected if the observed test statistic $Z_{obs}$ is greater than the critical value $z_{1-\\alpha}$. The critical value $z_{1-\\alpha}$ is the $(1-\\alpha)$-quantile of the standard normal distribution, defined by $\\Phi(z_{1-\\alpha}) = 1-\\alpha$, where $\\Phi$ is the cumulative distribution function (CDF) of the standard normal distribution $\\mathcal{N}(0,1)$.\n\nThe statistical power, $\\pi$, is the probability of correctly rejecting the null hypothesis when the alternative hypothesis is true. Under the alternative, the test statistic $Z$ follows a noncentral normal distribution $Z \\sim \\mathcal{N}(\\mu, 1)$, where $\\mu > 0$. The power is given by:\n$$ \\pi = P(Z > z_{1-\\alpha} | Z \\sim \\mathcal{N}(\\mu,1)) $$\nTo evaluate this probability, we standardize the variable $Z$:\n$$ \\pi = P\\left(\\frac{Z-\\mu}{1} > \\frac{z_{1-\\alpha}-\\mu}{1}\\right) $$\nSince $(Z-\\mu)$ follows a standard normal distribution, we have:\n$$ \\pi = P(\\mathcal{N}(0,1) > z_{1-\\alpha} - \\mu) = 1 - \\Phi(z_{1-\\alpha} - \\mu) $$\nThis is the fundamental equation linking power $\\pi$, significance level $\\alpha$, and noncentrality parameter $\\mu$. This equation can be rearranged to solve for $\\mu$:\n$$ \\Phi(z_{1-\\alpha} - \\mu) = 1 - \\pi $$\n$$ z_{1-\\alpha} - \\mu = \\Phi^{-1}(1 - \\pi) $$\n$$ \\mu = z_{1-\\alpha} - \\Phi^{-1}(1 - \\pi) = \\Phi^{-1}(1 - \\alpha) - \\Phi^{-1}(1 - \\pi) $$\n\n**Step 1: Calculate the noncentral mean of the discovery study ($\\mu_{1}$)**\nWe apply the derived formula using the parameters of the discovery study: $\\pi_{0} = 0.80$ and $\\alpha_{0} = 0.005$.\n$$ \\mu_{1} = \\Phi^{-1}(1 - \\alpha_{0}) - \\Phi^{-1}(1 - \\pi_{0}) $$\n$$ \\mu_{1} = \\Phi^{-1}(1 - 0.005) - \\Phi^{-1}(1 - 0.80) $$\n$$ \\mu_{1} = \\Phi^{-1}(0.995) - \\Phi^{-1}(0.20) $$\nWe use standard values for the quantiles of the normal distribution:\n- $\\Phi^{-1}(0.995) \\approx 2.575829$\n- $\\Phi^{-1}(0.20) = -\\Phi^{-1}(0.80) \\approx -0.841621$\nSubstituting these values:\n$$ \\mu_{1} \\approx 2.575829 - (-0.841621) = 3.417450 $$\n\n**Step 2: Calculate the noncentral mean of the replication study ($\\mu_{2}$)**\nThe problem states that the true effect size is attenuated due to the winner's curse. The noncentral mean for the replication study, $\\mu_{2}$, is given by $\\mu_{2} = b \\mu_{1}$, with $b=0.65$.\n$$ \\mu_{2} = 0.65 \\times \\mu_{1} $$\n$$ \\mu_{2} \\approx 0.65 \\times 3.417450 \\approx 2.221343 $$\n\n**Step 3: Calculate the power of the replication study ($\\pi_{\\mathrm{rep}}$)**\nThe probability that the replication study yields a statistically significant result is, by definition, its statistical power, $\\pi_{\\mathrm{rep}}$. We use the general power formula with the parameters for the replication study: $\\alpha_{\\mathrm{rep}} = 0.025$ and the calculated noncentral mean $\\mu_{2}$.\nThe critical value for the replication study is $z_{1-\\alpha_{\\mathrm{rep}}} = \\Phi^{-1}(1 - 0.025) = \\Phi^{-1}(0.975)$.\n$$ \\pi_{\\mathrm{rep}} = 1 - \\Phi(z_{1-\\alpha_{\\mathrm{rep}}} - \\mu_{2}) $$\n$$ \\pi_{\\mathrm{rep}} = 1 - \\Phi(\\Phi^{-1}(0.975) - \\mu_{2}) $$\nWe use the standard value $\\Phi^{-1}(0.975) \\approx 1.959964$.\nSubstituting the values for $\\Phi^{-1}(0.975)$ and $\\mu_{2}$:\n$$ \\pi_{\\mathrm{rep}} \\approx 1 - \\Phi(1.959964 - 2.221343) $$\n$$ \\pi_{\\mathrm{rep}} \\approx 1 - \\Phi(-0.261379) $$\nUsing the symmetry property of the normal CDF, $\\Phi(-x) = 1 - \\Phi(x)$, we have:\n$$ \\pi_{\\mathrm{rep}} \\approx 1 - (1 - \\Phi(0.261379)) = \\Phi(0.261379) $$\nEvaluating the CDF of the standard normal distribution at this point gives:\n$$ \\pi_{\\mathrm{rep}} \\approx 0.603094 $$\nThe problem requires the answer to be rounded to four significant figures.\n$$ \\pi_{\\mathrm{rep}} \\approx 0.6031 $$\nThis is the probability that the replication study will be statistically significant.", "answer": "$$\n\\boxed{0.6031}\n$$", "id": "4610085"}, {"introduction": "Modern clinical trials are increasingly adaptive, using incoming data to make decisions mid-study. This hands-on problem [@problem_id:4610096] introduces you to Bayesian adaptive design by asking you to implement a futility stopping rule based on the predictive probability of success. You will learn to calculate when a trial has become so unlikely to succeed that it is ethical and efficient to terminate it early, a core skill in contemporary biostatistical practice.", "problem": "A single-arm biomarker-targeted oncology study plans a binary responder endpoint for a cohort of patients defined by a genomic signature. Let the true responder probability be denoted by $p$. The design employs a Bayesian interim futility rule at an interim sample size based on a Predictive Probability of Success (PPS), where Predictive Probability of Success (PPS) is defined as the posterior predictive probability, at the interim, that the final analysis will declare treatment efficacy relative to a fixed benchmark responder probability.\n\nAssume a Beta prior $p \\sim \\text{Beta}(a,b)$ and a Binomial sampling model for responders at both interim and final analyses. Let the study plan a total sample size of $n$ patients, with an interim analysis after $n_1$ patients. Let the historical benchmark responder probability be $p_0$, and define the final Bayesian success criterion as: at the end of the study, the posterior probability that $p$ exceeds $p_0$ is at least a fixed threshold $\\tau$, that is, the study declares success if $\\Pr(p > p_0 \\mid \\text{final data}) \\ge \\tau$. At the interim, the Data Monitoring Board decides to stop for futility if the Predictive Probability of Success (PPS), computed conditional on the observed interim data, is less than a fixed threshold $\\gamma$; otherwise, the study continues to the full $n$.\n\nYour tasks, starting from the foundations of Bayes' theorem and the conjugacy of the Beta prior with the Binomial likelihood, are:\n\n- Derive and implement a method to compute the minimal total number of final responders $k^\\star$ (an integer threshold on the total number of responders among $n$ patients) that would satisfy the final Bayesian success criterion defined above.\n- Derive and implement a method to compute, at the interim with $x$ observed responders among $n_1$ patients, the Predictive Probability of Success (PPS), namely the posterior predictive probability that the total number of responders at $n$ will be at least $k^\\star$.\n- Prove or provide a clear argument from first principles that the PPS is a nondecreasing function of the interim responder count $x$ under the stated model assumptions, and use this property to define an integer futility boundary $c$ such that the study stops early if and only if the interim responder count satisfies $x \\le c$, and continues otherwise.\n- Quantify the expected sample size reduction attributable to this futility boundary under a specified true responder probability $p_{\\text{true}}$, by computing the expected sample size $\\mathbb{E}[N]$ of the adaptive design with futility stopping, and the savings $n - \\mathbb{E}[N]$ relative to always accruing the full $n$.\n\nAll probabilities must be expressed as decimals in $[0,1]$ rather than percentages. All angles are irrelevant to this problem. No physical units are involved. Round all floating-point outputs to six decimal places.\n\nImplement a single program that, for each test case below, returns a list containing:\n- the derived futility boundary $c$ (an integer),\n- the expected sample size $\\mathbb{E}[N]$ (a float),\n- the expected savings $n - \\mathbb{E}[N]$ (a float),\n- the savings fraction $(n - \\mathbb{E}[N])/n$ (a float).\n\nTest suite parameter sets, each given as a tuple $(n, n_1, p_0, a, b, \\tau, \\gamma, p_{\\text{true}})$:\n\n- Case A (underperforming treatment): $(100, 40, 0.25, 1, 1, 0.95, 0.10, 0.20)$, where $n = 100$, $n_1 = 40$, $p_0 = 0.25$, $a = 1$, $b = 1$, $\\tau = 0.95$, $\\gamma = 0.10$, $p_{\\text{true}} = 0.20$.\n- Case B (borderline efficacy): $(100, 40, 0.25, 1, 1, 0.95, 0.10, 0.30)$, where $p_{\\text{true}} = 0.30$.\n- Case C (clearly efficacious): $(100, 40, 0.25, 1, 1, 0.95, 0.10, 0.50)$, where $p_{\\text{true}} = 0.50$.\n- Case D (stricter interim futility and looser final success): $(100, 40, 0.25, 1, 1, 0.90, 0.50, 0.20)$, where $\\tau = 0.90$, $\\gamma = 0.50$, $p_{\\text{true}} = 0.20$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of per-case sublists enclosed in square brackets, with no spaces. For example, the output structure must be like: \"[[c_A,EN_A,S_A,F_A],[c_B,EN_B,S_B,F_B],[c_C,EN_C,S_C,F_C],[c_D,EN_D,S_D,F_D]]\", where $c_{\\cdot}$ are integers and $EN_{\\cdot}$, $S_{\\cdot}$, $F_{\\cdot}$ are floats rounded to six decimals.\n\nYour implementation must not hard-code the target formulas in the problem statement; it must derive them from the fundamental definitions above and compute the quantities required by the test suite in a general way consistent with the stated model.", "solution": "The problem statement is a well-posed and scientifically grounded exercise in Bayesian adaptive clinical trial design. It is self-contained, with all necessary parameters and definitions provided. The concepts, including the Beta-Binomial conjugate model, posterior probability, and Predictive Probability of Success (PPS), are standard in the field of biostatistics. The problem is therefore deemed **valid**.\n\nThe solution is developed in four parts, corresponding to the tasks outlined in the problem statement. All mathematical derivations are performed from first principles.\n\n### Part 1: Final Analysis and Success Threshold ($k^\\star$)\n\nThe Bayesian framework for this problem consists of a Beta prior distribution for the unknown responder probability $p$, and a Binomial likelihood for the observed number of responders.\n\nThe prior distribution for $p$ is given as $p \\sim \\text{Beta}(a,b)$. The probability density function (PDF) is:\n$$\nf(p; a, b) = \\frac{p^{a-1}(1-p)^{b-1}}{B(a,b)} \\quad \\text{for } p \\in [0,1]\n$$\nwhere $B(a,b)$ is the Beta function.\n\nThe data from the trial consist of the number of responders, $k$, in a total of $n$ patients. This is modeled by a Binomial distribution, with likelihood function $L(p \\mid k,n) \\propto p^k(1-p)^{n-k}$.\n\nDue to the conjugacy of the Beta prior and Binomial likelihood, the posterior distribution of $p$ after observing $k$ responders in $n$ patients is also a Beta distribution. The posterior is derived by Bayes' theorem:\n$$\n\\text{Posterior} \\propto \\text{Likelihood} \\times \\text{Prior}\n$$\n$$\nf(p \\mid k, n) \\propto p^k(1-p)^{n-k} \\times p^{a-1}(1-p)^{b-1} = p^{a+k-1}(1-p)^{b+n-k-1}\n$$\nThis kernel corresponds to a Beta distribution with updated parameters:\n$$\np \\mid k, n \\sim \\text{Beta}(a+k, b+n-k)\n$$\n\nThe final success criterion is that the posterior probability of $p$ exceeding the benchmark $p_0$ is at least $\\tau$. Mathematically, this is $\\Pr(p > p_0 \\mid k,n) \\ge \\tau$.\nThis probability is the survival function (or complementary cumulative distribution function, CCDF) of the posterior Beta distribution, evaluated at $p_0$:\n$$\n\\Pr(p > p_0 \\mid k,n) = 1 - F_{\\text{Beta}(a+k, b+n-k)}(p_0)\n$$\nwhere $F_{\\text{Beta}(\\alpha, \\beta)}(z)$ is the cumulative distribution function (CDF) of a Beta distribution with parameters $\\alpha$ and $\\beta$.\n\nThe task is to find the minimal integer number of total responders, $k^\\star$, that satisfies this criterion.\n$$\nk^\\star = \\min \\{ k \\in \\{0, 1, \\ldots, n\\} \\mid 1 - F_{\\text{Beta}(a+k, b+n-k)}(p_0) \\ge \\tau \\}\n$$\nThe function $g(k) = 1 - F_{\\text{Beta}(a+k, b+n-k)}(p_0)$ is a monotonically nondecreasing function of $k$. As $k$ increases, the posterior distribution $\\text{Beta}(a+k, b+n-k)$ shifts towards larger values of $p$, which increases the probability mass for which $p > p_0$. Therefore, $k^\\star$ can be found by a simple iterative search, starting from $k=0$ and incrementing until the condition is met. The first value of $k$ that satisfies the inequality is $k^\\star$.\n\n### Part 2: Interim Analysis and Predictive Probability of Success (PPS)\n\nAt an interim analysis after $n_1$ patients, $x$ responders have been observed. The posterior distribution for $p$ is updated based on this interim data:\n$$\np \\mid x, n_1 \\sim \\text{Beta}(a', b') \\quad \\text{where } a' = a+x \\text{ and } b' = b+n_1-x\n$$\nThe study will continue to enroll the remaining $n_2 = n - n_1$ patients. Let $Y$ be the number of responders among these future patients. The distribution of $Y$ conditional on a specific value of $p$ is Binomial: $Y \\mid p \\sim \\text{Binomial}(n_2, p)$.\n\nThe Predictive Probability of Success (PPS) is the probability, from the perspective of the interim analysis, that the final study outcome will be a success. Success is defined as the total number of responders, $x+Y$, being at least $k^\\star$. The PPS is calculated by marginalizing over the uncertainty in $p$, as captured by the interim posterior distribution:\n$$\n\\text{PPS}(x) = \\Pr(x+Y \\ge k^\\star \\mid x, n_1) = \\Pr(Y \\ge k^\\star - x \\mid x, n_1)\n$$\nThis requires the posterior predictive distribution of $Y$. This distribution is found by integrating the conditional distribution of $Y$ over the interim posterior of $p$:\n$$\n\\Pr(Y=y \\mid x, n_1) = \\int_0^1 \\Pr(Y=y \\mid p) f(p \\mid x, n_1) \\, dp\n$$\nwhere $\\Pr(Y=y \\mid p) = \\binom{n_2}{y} p^y (1-p)^{n_2-y}$ and $f(p \\mid x, n_1)$ is the PDF of the $\\text{Beta}(a', b')$ distribution. This integral defines the Beta-Binomial distribution:\n$$\n\\Pr(Y=y \\mid x, n_1) = \\binom{n_2}{y} \\frac{B(a'+y, b'+n_2-y)}{B(a', b')}\n$$\nThe PPS is then the sum of these probabilities over all values of $y$ that would lead to a successful trial outcome:\n$$\n\\text{PPS}(x) = \\sum_{y=\\max(0, k^\\star-x)}^{n_2} \\Pr(Y=y \\mid x, n_1) = \\sum_{y=\\max(0, k^\\star-x)}^{n_2} \\binom{n_2}{y} \\frac{B(a+x+y, b+n_1-x+n_2-y)}{B(a+x, b+n_1-x)}\n$$\nFor numerical stability, computations involving the Beta function $B(\\cdot, \\cdot)$ and binomial coefficients $\\binom{\\cdot}{\\cdot}$ are best performed in log-space using log-gamma ($\\text{gammaln}$) or log-beta ($\\text{betaln}$) functions.\n\n### Part 3: Futility Boundary ($c$)\n\nThe problem requires a clear argument that $\\text{PPS}(x)$ is a nondecreasing function of the interim responder count $x$. An increase in $x$ impacts the PPS in two ways:\n1.  **Reduced future requirement:** The number of additional responders needed for success, $k^\\star - x$, decreases as $x$ increases. This makes the target easier to achieve for any given future responder rate.\n2.  **Updated belief about $p$:** An increase in $x$ for a fixed $n_1$ shifts the interim posterior distribution $p \\mid x, n_1 \\sim \\text{Beta}(a+x, b+n_1-x)$ towards higher values of $p$. Formally, if $x_2 > x_1$, the posterior distribution for $p$ given $x_2$ first-order stochastically dominates the posterior given $x_1$. This means that the probability assigned to any upper-tail event for $p$ increases. Since the future number of responders $Y$ is positively correlated with $p$, a stronger belief in higher values of $p$ leads to a stronger belief in higher values of $Y$.\n\nBoth effects work in the same direction: they increase the probability of achieving the final success goal. Therefore, $\\text{PPS}(x)$ is a nondecreasing function of $x$.\n\nThe futility rule states that the trial stops if $\\text{PPS}(x) < \\gamma$. Because $\\text{PPS}(x)$ is nondecreasing in $x$, there exists an integer threshold $c$ such that for all interim outcomes $x \\le c$, the futility condition is met, and for all $x > c$, it is not. The futility boundary $c$ is the highest number of interim responders for which the trial is stopped.\n$$\nc = \\max \\{ x \\in \\{0, 1, \\ldots, n_1\\} \\mid \\text{PPS}(x) < \\gamma \\}\n$$\nIf $\\text{PPS}(x) \\ge \\gamma$ for all possible values of $x$ (from $0$ to $n_1$), then no futility stopping occurs, and we define $c = -1$.\nThe value of $c$ can be found by calculating $\\text{PPS}(x)$ for $x = n_1, n_1-1, \\ldots, 0$ and identifying the first value for which the futility condition is met.\n\n### Part 4: Expected Sample Size and Savings\n\nThe sample size of the adaptive design, $N$, is a random variable. It takes the value $n_1$ if the trial stops at the interim analysis for futility, and $n$ if it continues. The trial stops if the observed interim responder count $X$ satisfies $X \\le c$.\n\nTo evaluate the operating characteristics of this design, we assume a true underlying responder probability, $p_{\\text{true}}$. Under this assumption, the number of interim responders, $X$, follows a Binomial distribution:\n$$\nX \\sim \\text{Binomial}(n_1, p_{\\text{true}})\n$$\nThe probability of stopping for futility, $P_{\\text{stop}}$, is the probability of observing an outcome in the futility region:\n$$\nP_{\\text{stop}} = \\Pr(X \\le c) = \\sum_{i=0}^{c} \\binom{n_1}{i} p_{\\text{true}}^i (1-p_{\\text{true}})^{n_1-i}\n$$\nThis is the CDF of the $\\text{Binomial}(n_1, p_{\\text{true}})$ distribution evaluated at $c$. If $c=-1$, then $P_{\\text{stop}}=0$.\n\nThe expected sample size, $\\mathbb{E}[N]$, is the weighted average of the two possible sample sizes, with weights given by their respective probabilities:\n$$\n\\mathbb{E}[N] = n_1 \\cdot P_{\\text{stop}} + n \\cdot (1 - P_{\\text{stop}})\n$$\nThe expected sample size saving is the difference between the fixed maximum sample size $n$ and the expected sample size $\\mathbb{E}[N]$:\n$$\n\\text{Savings} = n - \\mathbb{E}[N] = n - (n_1 P_{\\text{stop}} + n - n P_{\\text{stop}}) = (n - n_1) P_{\\text{stop}}\n$$\nThe savings fraction is this saving expressed as a proportion of the maximum sample size $n$:\n$$\n\\text{Savings Fraction} = \\frac{\\text{Savings}}{n} = \\frac{(n-n_1)P_{\\text{stop}}}{n}\n$$\nThese quantities are computed for each test case using the derived futility boundary $c$ and the given $p_{\\text{true}}$.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import beta, binom\nfrom scipy.special import betaln, gammaln\n\ndef solve():\n    \"\"\"\n    Main function to solve the Bayesian adaptive design problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # (n, n1, p0, a, b, tau, gamma, p_true)\n        (100, 40, 0.25, 1, 1, 0.95, 0.10, 0.20),  # Case A\n        (100, 40, 0.25, 1, 1, 0.95, 0.10, 0.30),  # Case B\n        (100, 40, 0.25, 1, 1, 0.95, 0.10, 0.50),  # Case C\n        (100, 40, 0.25, 1, 1, 0.90, 0.50, 0.20),  # Case D\n    ]\n\n    results = []\n    for case in test_cases:\n        n, n1, p0, a, b, tau, gamma_thresh, p_true = case\n\n        # Part 1: Find the minimal number of final responders for success, k_star\n        k_star = -1\n        for k in range(n + 1):\n            # Posterior distribution: Beta(a+k, b+n-k)\n            # Success prob. is Pr(p > p0 | final data) = 1 - CDF(p0) = SF(p0)\n            success_prob = beta.sf(p0, a + k, b + n - k)\n            if success_prob >= tau:\n                k_star = k\n                break\n        \n        if k_star == -1:\n            # This case should not occur with the given parameters, but it's a safeguard.\n            # It means even with n responders, the success criterion is not met.\n            c = n1\n            expected_n = float(n)\n            savings = 0.0\n            savings_fraction = 0.0\n            results.append([int(c), round(expected_n, 6), round(savings, 6), round(savings_fraction, 6)])\n            continue\n\n        n2 = n - n1\n\n        # Part 2 & 3: Compute PPS and find futility boundary c\n        memo_pps = {}\n\n        def get_pps(x, n1, n2, a, b, k_star):\n            \"\"\"\n            Calculates the Predictive Probability of Success (PPS) for a given\n            interim outcome of x responders in n1 patients.\n            \"\"\"\n            if x in memo_pps:\n                return memo_pps[x]\n\n            a_prime = a + x\n            b_prime = b + n1 - x\n            \n            y_min = k_star - x\n            if y_min > n2:\n                memo_pps[x] = 0.0\n                return 0.0\n            \n            # The number of future responders Y follows a Beta-Binomial distribution\n            # Y ~ BetaBinom(n2, a_prime, b_prime)\n            # We calculate PPS = Pr(Y >= y_min)\n            \n            # Use log probabilities for numerical stability\n            log_beta_ab_prime = betaln(a_prime, b_prime)\n            \n            total_prob = 0.0\n            for y in range(max(0, y_min), n2 + 1):\n                # Log of the Beta-Binomial PMF:\n                # log(C(n2, y)) + log(B(a'+y, b'+n2-y)) - log(B(a', b'))\n                log_C_n2_y = gammaln(n2 + 1) - gammaln(y + 1) - gammaln(n2 - y + 1)\n                log_beta_term = betaln(a_prime + y, b_prime + n2 - y)\n                log_pmf = log_C_n2_y + log_beta_term - log_beta_ab_prime\n                total_prob += np.exp(log_pmf)\n            \n            memo_pps[x] = total_prob\n            return total_prob\n\n        # Search for futility boundary c\n        c = -1\n        for x in range(n1, -1, -1):\n            pps_val = get_pps(x, n1, n2, a, b, k_star)\n            if pps_val < gamma_thresh:\n                c = x\n                break\n\n        # Part 4: Quantify expected sample size and savings\n        if c == -1:\n            # No futility boundary found, trial always continues to n\n            prob_stop = 0.0\n        else:\n            # Probability of stopping is Pr(X <= c) where X ~ Binomial(n1, p_true)\n            prob_stop = binom.cdf(c, n1, p_true)\n        \n        expected_n = n1 * prob_stop + n * (1 - prob_stop)\n        savings = n - expected_n\n        savings_fraction = savings / n if n > 0 else 0.0\n\n        results.append([int(c), round(expected_n, 6), round(savings, 6), round(savings_fraction, 6)])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\".replace(\" \", \"\"))\n\nsolve()\n```", "id": "4610096"}]}