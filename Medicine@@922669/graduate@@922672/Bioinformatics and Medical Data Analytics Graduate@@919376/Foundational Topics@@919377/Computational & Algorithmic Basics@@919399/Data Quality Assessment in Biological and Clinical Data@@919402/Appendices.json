{"hands_on_practices": [{"introduction": "The foundation of any robust genomic analysis is high-quality raw data. This exercise bridges the gap between the abstract flags of a quality control report, like those from FastQC, and their tangible impact on scientific conclusions. By building a model from first principles, you will quantify how metrics such as base quality, duplication, and contamination directly affect the statistical power to detect genetic variants, transforming quality assessment from a procedural checklist into a quantitative risk analysis [@problem_id:4551926].", "problem": "You are given a task in the context of data quality assessment in biological and clinical data for Next-Generation Sequencing (NGS). You must write a complete program that, for each dataset, performs the following: compute a FastQC-style summary, identify Quality Control (QC) failures, and quantify the expected loss in downstream single-nucleotide variant (SNV) calling sensitivity attributable to the observed QC metrics. Your derivation and implementation must be based on first principles: the Phred quality definition and a binomial test for variant detection.\n\nUse the following foundations and definitions:\n- Phred quality score is defined by $Q = -10 \\log_{10}(e)$, where $e$ is the base-calling error probability. Hence $e = 10^{-Q/10}$.\n- Assume a diploid heterozygous variant with true alternate allele fraction $f = 0.5$. Let $n$ be the effective number of independent observations (effective coverage) at a locus. Assume independence of reads at the locus after accounting for duplication.\n- Define the null hypothesis $H_0$ (no real variant): the probability that an alternate base call equals a specific non-reference allele is $p_0 = e/3$ (assuming equal distribution of substitution errors among the three non-reference bases).\n- Define the alternative hypothesis $H_1$ (a true heterozygous variant): the probability that a read is observed as the specific alternate allele is $p_1 = f \\cdot (1 - e) + (1 - f) \\cdot (e/3)$.\n- Set a per-site false positive tail probability budget of $\\alpha = 10^{-6}$. Define the minimum integer threshold $t$ for a variant call at depth $n$ as the smallest $t$ such that $\\Pr[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_0)] \\le \\alpha$. If no such $t \\le n$ exists, sensitivity is defined to be $0$.\n- The sensitivity under $H_1$ (power) is $S = \\Pr[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_1)]$.\n\nDefine the effective coverage $n$ from raw coverage and QC metrics as follows. Let $C_{\\text{raw}}$ be raw nominal coverage. The effective coverage is\n$$\nn = \\left\\lfloor C_{\\text{raw}} \\cdot m \\cdot (1 - d) \\cdot (1 - a) \\cdot (1 - n_f) \\cdot (1 - o) \\right\\rfloor,\n$$\nwhere $m$ is mapping rate (decimal), $d$ is duplication rate (decimal), $a$ is adapter contamination fraction (decimal), $o$ is overrepresented sequences fraction (decimal), and $n_f$ is per-base ambiguous call fraction (decimal). The floor function $\\lfloor \\cdot \\rfloor$ returns the greatest integer less than or equal to its argument. All fractions must be provided as decimals, not percentages.\n\nCompute a FastQC-style module summary with pass/warn/fail per dataset for the following $6$ modules using these thresholds:\n- Per-base sequence quality using mean Phred quality $Q_m$: pass if $Q_m \\ge 28$, warn if $23 \\le Q_m < 28$, fail if $Q_m < 23$.\n- Per-sequence GC content deviation $|g - g_0|$ where $g$ is observed GC fraction and $g_0$ is expected GC fraction: pass if $|g - g_0| \\le 0.05$, warn if $0.05 < |g - g_0| \\le 0.10$, fail if $|g - g_0| > 0.10$.\n- Sequence duplication levels using duplication rate $d$: pass if $d \\le 0.20$, warn if $0.20 < d \\le 0.50$, fail if $d > 0.50$.\n- Adapter content $a$: pass if $a \\le 0.01$, warn if $0.01 < a \\le 0.05$, fail if $a > 0.05$.\n- Overrepresented sequences fraction $o$: pass if $o \\le 0.01$, warn if $0.01 < o \\le 0.10$, fail if $o > 0.10$.\n- Per-base $N$ content $n_f$: pass if $n_f \\le 0.01$, warn if $0.01 < n_f \\le 0.03$, fail if $n_f > 0.03$.\n\nMap pass/warn/fail to integer codes as follows: pass $\\to +1$, warn $\\to 0$, fail $\\to -1$. The module order must be fixed as:\n$[$Per-base sequence quality, GC deviation, Duplication, Adapter, Overrepresented sequences, $N$ content$]$.\n\nDefine sensitivity loss relative to a per-dataset baseline with ideal QC at the same raw coverage: for the baseline, set $Q_m^{\\mathrm{base}} = 35$, $m^{\\mathrm{base}} = 1$, $d^{\\mathrm{base}} = 0$, $a^{\\mathrm{base}} = 0$, $o^{\\mathrm{base}} = 0$, $n_f^{\\mathrm{base}} = 0$, and compute $n_{\\mathrm{base}} = \\lfloor C_{\\text{raw}} \\rfloor$. Compute $S_{\\mathrm{base}}$ using $e_{\\mathrm{base}} = 10^{-Q_m^{\\mathrm{base}}/10}$ and the same $\\alpha$ and $f$. The sensitivity loss is $L = S_{\\mathrm{base}} - S$, which must be reported as a decimal in $[0,1]$.\n\nInput for each dataset consists of the following parameters, all dimensionless and provided as decimals where applicable:\n- Read length $L$ (bases) [used only for reporting consistency, not in the computation],\n- Raw coverage $C_{\\text{raw}}$,\n- Mean Phred quality $Q_m$,\n- Mapping rate $m$,\n- Duplication rate $d$,\n- Adapter contamination fraction $a$,\n- Overrepresented sequences fraction $o$,\n- Per-base $N$ fraction $n_f$,\n- Observed GC fraction $g$,\n- Expected GC fraction $g_0$.\n\nUse the following test suite of datasets, each specified as a tuple $(L, C_{\\text{raw}}, Q_m, m, d, a, o, n_f, g, g_0)$ with all numeric values written as decimals:\n- Test case $1$: $(150, 30, 32, 0.97, 0.12, 0.008, 0.006, 0.004, 0.41, 0.41)$.\n- Test case $2$: $(100, 20, 25, 0.95, 0.35, 0.02, 0.03, 0.015, 0.36, 0.41)$.\n- Test case $3$: $(150, 40, 20, 0.70, 0.70, 0.10, 0.15, 0.04, 0.50, 0.41)$.\n- Test case $4$: $(75, 10, 30, 0.20, 0.50, 0.02, 0.01, 0.01, 0.41, 0.41)$.\n\nYour program must, for each test case, compute:\n- The vector of module status codes in the fixed order specified above,\n- The integer count of failed modules (the number of entries equal to $-1$),\n- The sensitivity loss $L$ as a floating-point number.\n\nFinal output format:\nYour program should produce a single line of output containing a list of length $4$, where each element corresponds to a test case and is itself a list of the form $[$status\\_codes, fail\\_count, loss$]$. The $status\\_codes$ must be a list of $6$ integers in the fixed module order. For example, the overall structure must look like\n$[[[s_{11},\\dots,s_{16}], f_1, \\ell_1], [[s_{21},\\dots,s_{26}], f_2, \\ell_2], [[s_{31},\\dots,s_{36}], f_3, \\ell_3], [[s_{41},\\dots,s_{46}], f_4, \\ell_4]]$,\nwhere $s_{ij} \\in \\{-1,0,1\\}$, $f_i$ is an integer, and $\\ell_i$ is a decimal number in $[0,1]$. Print the list exactly in this single-line format using commas to separate values and square brackets to denote lists.", "solution": "We construct a principled solution grounded in the definitions of Phred quality and hypothesis testing with the binomial distribution. The aim is to translate observable Quality Control (QC) metrics into an effective coverage model and then quantify the impact of imperfect QC on variant detection sensitivity for single-nucleotide variants (SNVs).\n\nFirst, we use the Phred quality definition. The Phred score $Q$ and the error probability $e$ obey $Q = -10 \\log_{10}(e)$, so $e = 10^{-Q/10}$. For a dataset with mean Phred quality $Q_m$, we model the per-base error probability as $e = 10^{-Q_m/10}$. This is a well-tested relationship in sequencing technologies.\n\nSecond, we compute effective coverage $n$ as a product of raw coverage and multiplicative penalties from mapping, duplication, adapter contamination, overrepresented sequences, and ambiguous bases. Let $C_{\\text{raw}}$ be the nominal coverage. The effective coverage is\n$$\nn = \\left\\lfloor C_{\\text{raw}} \\cdot m \\cdot (1 - d) \\cdot (1 - a) \\cdot (1 - n_f) \\cdot (1 - o) \\right\\rfloor.\n$$\nThis formula is based on the rationale that:\n- Only a fraction $m$ of reads map to the reference and contribute to coverage.\n- Duplication rate $d$ indicates the proportion of non-independent reads; thus, a factor $(1-d)$ preserves unique observations.\n- Adapter contamination $a$ often leads to trimming or unusable bases; we penalize by $(1-a)$.\n- Per-base $N$ fraction $n_f$ indicates ambiguous calls that cannot inform SNV detection; we penalize by $(1-n_f)$.\n- Overrepresented sequences $o$ often reflect contamination or technical artifacts; we penalize by $(1-o)$.\nWe apply the floor $\\lfloor \\cdot \\rfloor$ to define $n$ as a non-negative integer count of independent Bernoulli trials.\n\nThird, we formalize the decision rule for variant detection using a hypothesis test on the binomial distribution. Under the null hypothesis $H_0$ (no true variant), any alternate observation arises from sequencing error. If the error probability is $e$, and assuming uniform miscall distribution among the three non-reference bases, the probability of observing a specific pre-specified alternate is\n$$\np_0 = \\frac{e}{3}.\n$$\nWe set a stringent false positive budget per site of $\\alpha = 10^{-6}$. The detection threshold $t$ is the smallest integer such that\n$$\n\\Pr\\!\\left[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_0)\\right] \\le \\alpha.\n$$\nIf such a $t$ exceeds $n$ (i.e., no $t \\le n$ satisfies the inequality), then no call is possible at the given $n$ and $e$, and we set the sensitivity to $0$.\n\nUnder the alternative hypothesis $H_1$ (true heterozygous variant with allele fraction $f = 0.5$), a read supports the specific alternate because either it comes from the alternate chromosome and is correctly called, or it comes from the reference chromosome and is miscalled as the specific alternate. Hence,\n$$\np_1 = f \\cdot (1 - e) + (1 - f) \\cdot \\frac{e}{3}.\n$$\nThe sensitivity (power) is then\n$$\nS = \\Pr\\!\\left[X \\ge t \\mid X \\sim \\mathrm{Binomial}(n, p_1)\\right].\n$$\nThis expression equals the survival function of the binomial distribution at $t-1$ with parameters $(n, p_1)$.\n\nFourth, to quantify sensitivity loss attributable to QC, we define a per-dataset baseline that fixes raw coverage but removes QC penalties and uses high quality. For the baseline, let $Q_m^{\\mathrm{base}} = 35$ (so $e_{\\mathrm{base}} = 10^{-3.5}$), $m^{\\mathrm{base}} = 1$, $d^{\\mathrm{base}} = 0$, $a^{\\mathrm{base}} = 0$, $o^{\\mathrm{base}} = 0$, $n_f^{\\mathrm{base}} = 0$, and\n$$\nn_{\\mathrm{base}} = \\left\\lfloor C_{\\text{raw}} \\right\\rfloor.\n$$\nWe compute the baseline threshold $t_{\\mathrm{base}}$ analogously using $p_0^{\\mathrm{base}} = e_{\\mathrm{base}}/3$ and $\\alpha$, and the baseline sensitivity $S_{\\mathrm{base}}$ using $p_1^{\\mathrm{base}} = f \\cdot (1 - e_{\\mathrm{base}}) + (1 - f) \\cdot e_{\\mathrm{base}}/3$. The sensitivity loss is\n$$\nL = S_{\\mathrm{base}} - S.\n$$\n\nFifth, we map QC to FastQC-style module statuses using thresholds:\n- Per-base sequence quality with $Q_m$: pass if $Q_m \\ge 28$, warn if $23 \\le Q_m &lt; 28$, fail if $Q_m &lt; 23$.\n- Per-sequence GC content deviation $|g - g_0|$: pass if $\\le 0.05$, warn if $\\in (0.05, 0.10]$, fail if $&gt; 0.10$.\n- Sequence duplication levels $d$: pass if $\\le 0.20$, warn if $\\in (0.20, 0.50]$, fail if $&gt; 0.50$.\n- Adapter content $a$: pass if $\\le 0.01$, warn if $\\in (0.01, 0.05]$, fail if $&gt; 0.05$.\n- Overrepresented sequences $o$: pass if $\\le 0.01$, warn if $\\in (0.01, 0.10]$, fail if $&gt; 0.10$.\n- Per-base $N$ content $n_f$: pass if $\\le 0.01$, warn if $\\in (0.01, 0.03]$, fail if $&gt; 0.03$.\n\nWe map pass $\\to +1$, warn $\\to 0$, fail $\\to -1$, and compute the total number of failures by counting the number of $-1$ statuses across the six modules.\n\nAlgorithmic design:\n- For each dataset, compute $e = 10^{-Q_m/10}$, then $n$ via the multiplicative penalties and floor. Compute $p_0 = e/3$ and find the smallest threshold $t$ with binomial tail $\\le \\alpha$. If $t &gt; n$, set $S = 0$; else compute $p_1$ and $S$ as the binomial survival function at $t-1$.\n- Compute the baseline values $e_{\\mathrm{base}}$, $n_{\\mathrm{base}}$, $p_0^{\\mathrm{base}}$, $t_{\\mathrm{base}}$, $p_1^{\\mathrm{base}}$, and $S_{\\mathrm{base}}$ analogously.\n- Output $L = S_{\\mathrm{base}} - S$ along with the module status vector and the count of failures.\n- The test suite consists of four datasets as specified, each with $(L, C_{\\text{raw}}, Q_m, m, d, a, o, n_f, g, g_0)$ given by:\n  - $(150, 30, 32, 0.97, 0.12, 0.008, 0.006, 0.004, 0.41, 0.41)$,\n  - $(100, 20, 25, 0.95, 0.35, 0.02, 0.03, 0.015, 0.36, 0.41)$,\n  - $(150, 40, 20, 0.70, 0.70, 0.10, 0.15, 0.04, 0.50, 0.41)$,\n  - $(75, 10, 30, 0.20, 0.50, 0.02, 0.01, 0.01, 0.41, 0.41)$.\nThese cover a high-quality case, boundary warnings without failures, severe failures, and low effective coverage.\n\nThe program computes the requested outputs and prints a single line in the specified nested list format:\n$[[[s_{11},\\dots,s_{16}], f_1, \\ell_1], [[s_{21},\\dots,s_{26}], f_2, \\ell_2], [[s_{31},\\dots,s_{36}], f_3, \\ell_3], [[s_{41},\\dots,s_{46}], f_4, \\ell_4]]$,\nwith $s_{ij} \\in \\{-1,0,1\\}$, $f_i$ integer, and $\\ell_i \\in [0,1]$ as a decimal (not a percentage).", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom math import floor\nfrom scipy.stats import binom\n\n# Fixed parameters for the detection model\nALPHA = 1e-6  # per-site false positive tail probability\nF = 0.5       # heterozygous allele fraction\nQ_BASE = 35.0 # baseline mean Phred quality\n\n# Module thresholds and order:\n# [Per-base quality, GC deviation, Duplication, Adapter, Overrepresented, N content]\ndef classify_modules(Qm, g, g0, d, a, o, nf):\n    statuses = []\n    # Per-base sequence quality\n    if Qm >= 28:\n        statuses.append(1)\n    elif Qm >= 23:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # GC deviation\n    gc_dev = abs(g - g0)\n    if gc_dev <= 0.05:\n        statuses.append(1)\n    elif gc_dev <= 0.10:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # Duplication\n    if d <= 0.20:\n        statuses.append(1)\n    elif d <= 0.50:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # Adapter\n    if a <= 0.01:\n        statuses.append(1)\n    elif a <= 0.05:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # Overrepresented sequences\n    if o <= 0.01:\n        statuses.append(1)\n    elif o <= 0.10:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    # N content\n    if nf <= 0.01:\n        statuses.append(1)\n    elif nf <= 0.03:\n        statuses.append(0)\n    else:\n        statuses.append(-1)\n    return statuses\n\ndef phred_to_error(Q):\n    # e = 10^{-Q/10}\n    return 10.0 ** (-Q / 10.0)\n\ndef effective_coverage(C_raw, m, d, a, o, nf):\n    eff = C_raw * m * (1.0 - d) * (1.0 - a) * (1.0 - nf) * (1.0 - o)\n    n = int(np.floor(eff)) if eff > 0 else 0\n    return max(n, 0)\n\ndef find_threshold(n, p0, alpha):\n    # Find the smallest integer t such that P[X >= t | Bin(n, p0)] <= alpha\n    # We scan from t=0 to n+1; at t=n+1, the tail prob is 0 by definition.\n    # Use survival function for numerical stability.\n    for t in range(0, n + 2):\n        tail = binom.sf(t - 1, n, p0)  # P[X >= t]\n        if tail <= alpha:\n            return t\n    # Should never reach here due to n+1 guard\n    return n + 1\n\ndef sensitivity_at_params(n, Qm, alpha, f):\n    # Compute sensitivity given effective coverage n and mean Phred Qm\n    if n <= 0:\n        return 0.0\n    e = phred_to_error(Qm)\n    p0 = e / 3.0\n    t = find_threshold(n, p0, alpha)\n    if t > n:\n        return 0.0\n    p1 = f * (1.0 - e) + (1.0 - f) * (e / 3.0)\n    # Sensitivity = P[X >= t | Bin(n, p1)] = sf(t-1)\n    S = float(binom.sf(t - 1, n, p1))\n    # Clip to [0,1] to avoid minor numerical issues\n    if S < 0.0:\n        S = 0.0\n    elif S > 1.0:\n        S = 1.0\n    return S\n\ndef compute_loss(C_raw, Qm, m, d, a, o, nf):\n    # Current dataset sensitivity\n    n_eff = effective_coverage(C_raw, m, d, a, o, nf)\n    S_curr = sensitivity_at_params(n_eff, Qm, ALPHA, F)\n    # Baseline sensitivity\n    n_base = int(np.floor(C_raw)) if C_raw > 0 else 0\n    S_base = sensitivity_at_params(n_base, Q_BASE, ALPHA, F)\n    loss = S_base - S_curr\n    # Clip for safety\n    if loss < 0.0:\n        loss = 0.0\n    if loss > 1.0:\n        loss = 1.0\n    return loss\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (L, C_raw, Qm, m, d, a, o, nf, g, g0)\n    test_cases = [\n        (150, 30.0, 32.0, 0.97, 0.12, 0.008, 0.006, 0.004, 0.41, 0.41),\n        (100, 20.0, 25.0, 0.95, 0.35, 0.02, 0.03, 0.015, 0.36, 0.41),\n        (150, 40.0, 20.0, 0.70, 0.70, 0.10, 0.15, 0.04, 0.50, 0.41),\n        (75,  10.0, 30.0, 0.20, 0.50, 0.02, 0.01, 0.01, 0.41, 0.41),\n    ]\n\n    results = []\n    for case in test_cases:\n        L, C_raw, Qm, m, d, a, o, nf, g, g0 = case\n        status_codes = classify_modules(Qm, g, g0, d, a, o, nf)\n        fail_count = sum(1 for s in status_codes if s == -1)\n        loss = compute_loss(C_raw, Qm, m, d, a, o, nf)\n        # Round loss moderately for stable display\n        loss_rounded = float(np.round(loss, 6))\n        results.append([status_codes, fail_count, loss_rounded])\n\n    # Final print statement in the exact required format.\n    # Ensure no extra spaces for compact single-line output\n    def list_to_str(obj):\n        if isinstance(obj, list):\n            return \"[\" + \",\".join(list_to_str(x) for x in obj) + \"]\"\n        elif isinstance(obj, float):\n            # Use repr-like but controlled: avoid scientific for small numbers if possible\n            s = f\"{obj:.6f}\"\n            # Strip trailing zeros and possible trailing dot\n            s = s.rstrip('0').rstrip('.') if '.' in s else s\n            if s == \"\":\n                s = \"0\"\n            return s\n        else:\n            return str(obj)\n\n    print(list_to_str(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "4551926"}, {"introduction": "When comparing gene expression across different samples, true biological signals can be easily masked by technical artifacts like varying sequencing depth. This practice delves into a cornerstone of RNA-seq analysis: the median-of-ratios normalization method. By implementing this algorithm, you will gain a hands-on understanding of how to create a stable, robust estimate of library size to ensure that expression levels are truly comparable across your experimental conditions [@problem_id:4552062].", "problem": "A clinical RNA sequencing study produces integer count data across three sequencing libraries (samples) for eight genes. The study aims to normalize for differences in library size using the Differential Expression by Sequencing (DESeq) median-of-ratios method, then to quantify the stability of the resulting size factor estimates. The following raw count matrix is given, where each entry is the observed read count for gene $G_{i}$ in sample $S_{j}$: for $G_{1}$, $S_{1}$ has $4$, $S_{2}$ has $5$, $S_{3}$ has $6$; for $G_{2}$, $S_{1}$ has $8$, $S_{2}$ has $10$, $S_{3}$ has $12$; for $G_{3}$, $S_{1}$ has $12$, $S_{2}$ has $15$, $S_{3}$ has $18$; for $G_{4}$, $S_{1}$ has $20$, $S_{2}$ has $25$, $S_{3}$ has $30$; for $G_{5}$, $S_{1}$ has $40$, $S_{2}$ has $50$, $S_{3}$ has $60$; for $G_{6}$, $S_{1}$ has $60$, $S_{2}$ has $75$, $S_{3}$ has $90$; for $G_{7}$, $S_{1}$ has $80$, $S_{2}$ has $100$, $S_{3}$ has $120$; for $G_{8}$, $S_{1}$ has $160$, $S_{2}$ has $200$, $S_{3}$ has $240$.\n\nAssume that the underlying biological expression profile across genes is stable between samples, and that inter-sample differences arise from multiplicative library size effects and sampling variation. Apply the DESeq median-of-ratios normalization protocol to compute library size factors for $S_{1}$, $S_{2}$, and $S_{3}$, by performing the following operations on the given count table: for each gene, compute the geometric mean across samples; for each sample, compute the ratio of its count to the gene’s geometric mean; and for each sample, take the median of these ratios across all genes to obtain the sample’s size factor.\n\nThen assess the stability of the estimated size factors by computing the coefficient of variation, defined as $\\mathrm{CV} = \\sigma / \\mu$, where $\\mu$ is the mean of the three estimated size factors and $\\sigma$ is their standard deviation computed with denominator $n$ (that is, $\\sigma = \\sqrt{\\frac{1}{n} \\sum_{j=1}^{n} (x_{j}-\\mu)^{2}}$ for $n=3$). Express the stability metric as a decimal and round your final answer to four significant figures. No unit is required.", "solution": "The solution proceeds by applying the specified steps of the DESeq median-of-ratios normalization method to the provided count matrix, and then computing the coefficient of variation for the resulting size factors.\n\nLet the count matrix be denoted by $K$, where $K_{ij}$ is the count for gene $i$ in sample $j$:\n$$\nK = \\begin{pmatrix}\n4 & 5 & 6 \\\\\n8 & 10 & 12 \\\\\n12 & 15 & 18 \\\\\n20 & 25 & 30 \\\\\n40 & 50 & 60 \\\\\n60 & 75 & 90 \\\\\n80 & 100 & 120 \\\\\n160 & 200 & 240\n\\end{pmatrix}\n$$\nThe counts for any gene $i$ across the three samples ($S_1, S_2, S_3$) can be written in the form $(c_i, 1.25 c_i, 1.5 c_i)$, where $c_i = K_{i1}$. This perfect proportionality simplifies the calculation.\n\n**1. Compute the geometric mean for each gene.**\nFor a given gene $i$, the counts are $K_{i1} = c_i$, $K_{i2} = 1.25 c_i$, and $K_{i3} = 1.5 c_i$. The geometric mean, $\\bar{K}_{i, \\text{geom}}$, is:\n$$\n\\bar{K}_{i, \\text{geom}} = (K_{i1} \\cdot K_{i2} \\cdot K_{i3})^{1/3} = (c_i \\cdot 1.25 c_i \\cdot 1.5 c_i)^{1/3} = (c_i^3 \\cdot 1.25 \\cdot 1.5)^{1/3}\n$$\n$$\n\\bar{K}_{i, \\text{geom}} = c_i (1.875)^{1/3}\n$$\nThis relationship holds for all genes $i \\in \\{1, ..., 8\\}$.\n\n**2. Compute ratios for each sample.**\nFor each sample $j$, we compute the ratio of its count $K_{ij}$ to the gene's geometric mean $\\bar{K}_{i, \\text{geom}}$.\n\nFor sample $S_1$ (where $j=1$):\n$$\nR_{i1} = \\frac{K_{i1}}{\\bar{K}_{i, \\text{geom}}} = \\frac{c_i}{c_i (1.875)^{1/3}} = (1.875)^{-1/3}\n$$\nThis ratio is constant for all genes $i=1, ..., 8$.\n\nFor sample $S_2$ (where $j=2$):\n$$\nR_{i2} = \\frac{K_{i2}}{\\bar{K}_{i, \\text{geom}}} = \\frac{1.25 c_i}{c_i (1.875)^{1/3}} = 1.25 \\cdot (1.875)^{-1/3}\n$$\nThis ratio is also constant for all genes.\n\nFor sample $S_3$ (where $j=3$):\n$$\nR_{i3} = \\frac{K_{i3}}{\\bar{K}_{i, \\text{geom}}} = \\frac{1.5 c_i}{c_i (1.875)^{1/3}} = 1.5 \\cdot (1.875)^{-1/3}\n$$\nThis ratio is also constant for all genes.\n\n**3. Determine the size factor for each sample.**\nThe size factor $s_j$ for sample $j$ is the median of the ratios $\\{R_{1j}, R_{2j}, ..., R_{8j}\\}$. Since all ratios within a sample are identical, the median is simply this constant value.\n$$\ns_1 = \\text{median}_{i} \\{R_{i1}\\} = (1.875)^{-1/3}\n$$\n$$\ns_2 = \\text{median}_{i} \\{R_{i2}\\} = 1.25 \\cdot (1.875)^{-1/3}\n$$\n$$\ns_3 = \\text{median}_{i} \\{R_{i3}\\} = 1.5 \\cdot (1.875)^{-1/3}\n$$\nThe set of size factors is $\\{s_1, s_2, s_3\\}$.\n\n**4. Compute the Coefficient of Variation (CV).**\nThe coefficient of variation is defined as $\\mathrm{CV} = \\sigma / \\mu$. The CV is a scale-invariant measure. We can factor out the common term $k = (1.875)^{-1/3}$ and compute the CV for the set of values $\\{1, 1.25, 1.5\\}$. Let this set be denoted by $X = \\{x_1, x_2, x_3\\}$ where $x_1=1$, $x_2=1.25$, and $x_3=1.5$. The number of values is $n=3$.\n\nFirst, we compute the mean $\\mu$:\n$$\n\\mu = \\frac{1}{3} \\sum_{j=1}^{3} x_j = \\frac{1 + 1.25 + 1.5}{3} = \\frac{3.75}{3} = 1.25\n$$\nNext, we compute the standard deviation $\\sigma$ using the specified formula with denominator $n$:\n$$\n\\sigma^2 = \\frac{1}{3} \\sum_{j=1}^{3} (x_j - \\mu)^2\n$$\n$$\n\\sigma^2 = \\frac{1}{3} \\left[ (1 - 1.25)^2 + (1.25 - 1.25)^2 + (1.5 - 1.25)^2 \\right]\n$$\n$$\n\\sigma^2 = \\frac{1}{3} \\left[ (-0.25)^2 + (0)^2 + (0.25)^2 \\right]\n$$\n$$\n\\sigma^2 = \\frac{1}{3} \\left[ 0.0625 + 0 + 0.0625 \\right] = \\frac{0.125}{3} = \\frac{1/8}{3} = \\frac{1}{24}\n$$\n$$\n\\sigma = \\sqrt{\\frac{1}{24}} = \\frac{1}{\\sqrt{24}} = \\frac{1}{2\\sqrt{6}} = \\frac{\\sqrt{6}}{12}\n$$\nFinally, we compute the CV:\n$$\n\\mathrm{CV} = \\frac{\\sigma}{\\mu} = \\frac{\\sqrt{6}/12}{1.25} = \\frac{\\sqrt{6}/12}{5/4} = \\frac{\\sqrt{6}}{12} \\cdot \\frac{4}{5} = \\frac{\\sqrt{6}}{15}\n$$\nNow we compute the numerical value and round to four significant figures.\n$$\n\\mathrm{CV} = \\frac{\\sqrt{6}}{15} \\approx \\frac{2.44948974}{15} \\approx 0.163299316\n$$\nRounding to four significant figures gives $0.1633$.", "answer": "$$\n\\boxed{0.1633}\n$$", "id": "4552062"}, {"introduction": "In the clinical setting, it is crucial to understand how a new measurement method compares to an existing standard. This exercise introduces the rigorous statistical framework for method comparison, moving beyond simple correlation. You will use Passing-Bablok regression to robustly estimate systematic and proportional bias, and Bland-Altman analysis to define the limits of agreement, providing a comprehensive assessment of whether two assays can be used interchangeably [@problem_id:4552070].", "problem": "You are given paired measurements from two clinical assays assessed on the same specimens. The goal is to evaluate method comparison and agreement using a robust linear estimator and a distribution-based agreement metric. Assume a linear relationship between the two assays expressed as $y = a + b x$, where $x$ denotes the measurement from Assay $X$ and $y$ denotes the measurement from Assay $Y$. You must implement a nonparametric robust regression to estimate the constant bias $a$ and proportional error $b$ under the following constraints: the estimator must be invariant under monotone transformations and must rely on order statistics rather than parametric distributional assumptions. Additionally, you must implement a distribution-based agreement assessment using the framework of differences, computing the mean difference and the Limits of Agreement (LoA), defined for the difference $d_i = y_i - x_i$ as the interval $[\\overline{d} - 1.96 s_d, \\overline{d} + 1.96 s_d]$, where $\\overline{d}$ is the sample mean of differences and $s_d$ is the sample standard deviation of differences. The LoA are to be interpreted on the same scale as the measurements and must be computed as real numbers.\n\nFundamental basis and definitions to be used for derivation and implementation:\n- The linear model $y = a + b x$ with unknown $a$ and $b$.\n- Robust estimation principles based on medians and order statistics to mitigate the influence of outliers and avoid reliance on normality.\n- Differences-based agreement metrics: for paired data $(x_i,y_i)$, the difference $d_i = y_i - x_i$, the mean $\\overline{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_i$, and the sample standard deviation $s_d = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (d_i - \\overline{d})^2}$.\n- Limits of Agreement (LoA): $[\\overline{d} - 1.96 s_d, \\overline{d} + 1.96 s_d]$.\n\nYou must produce a program that, for each test case, returns a list $[b,a,\\overline{d},\\text{LoA}_{\\text{low}},\\text{LoA}_{\\text{high}}]$, where $b$ and $a$ are the robust slope and intercept estimates for the linear relationship $y = a + b x$, $\\overline{d}$ is the mean difference, and $\\text{LoA}_{\\text{low}}$ and $\\text{LoA}_{\\text{high}}$ are the lower and upper Limits of Agreement. All quantities are to be treated as dimensionless numeric values; no physical units are involved. The Limits of Agreement are to be computed using the constant $1.96$, reflecting two-sided coverage under the assumption that the distribution of differences is approximately symmetric.\n\nTest suite:\n- Case $1$ (general case; moderate proportional error and small bias): \n  $x = [\\,8,12,18,25,35,48,60,72,85,100\\,]$ and \n  $y = [\\,0.98\\cdot 8 + 1.7 + 0.3,\\;0.98\\cdot 12 + 1.7 - 0.4,\\;0.98\\cdot 18 + 1.7 + 0.2,\\;0.98\\cdot 25 + 1.7 - 0.1,\\;0.98\\cdot 35 + 1.7 + 0.5,\\;0.98\\cdot 48 + 1.7 - 0.2,\\;0.98\\cdot 60 + 1.7 + 0.1,\\;0.98\\cdot 72 + 1.7 + 0.0,\\;0.98\\cdot 85 + 1.7 - 0.3,\\;0.98\\cdot 100 + 1.7 + 0.4\\,]$.\n- Case $2$ (boundary with repeated $x$ values; tests handling of zero-denominator pairs): \n  $x = [\\,50,50,60,60,60,80,80,80,90,110\\,]$ and \n  $y = [\\,1.05\\cdot 50 - 3 + 1.0,\\;1.05\\cdot 50 - 3 - 2.0,\\;1.05\\cdot 60 - 3 + 0.5,\\;1.05\\cdot 60 - 3 - 1.5,\\;1.05\\cdot 60 - 3 + 0.4,\\;1.05\\cdot 80 - 3 + 1.2,\\;1.05\\cdot 80 - 3 - 0.8,\\;1.05\\cdot 80 - 3 + 0.3,\\;1.05\\cdot 90 - 3 + 0.0,\\;1.05\\cdot 110 - 3 - 0.6\\,]$.\n- Case $3$ (outliers present; tests robustness): \n  $x = [\\,5,15,25,35,45,55,65,75,85,95\\,]$ and \n  $y = [\\,1.2\\cdot 5 - 4 + 0.2,\\;1.2\\cdot 15 - 4 - 0.1,\\;1.2\\cdot 25 - 4 + 0.3,\\;1.2\\cdot 35 - 4 + 15.0,\\;1.2\\cdot 45 - 4 - 0.5,\\;1.2\\cdot 55 - 4 + 0.0,\\;1.2\\cdot 65 - 4 + 0.4,\\;1.2\\cdot 75 - 4 - 12.0,\\;1.2\\cdot 85 - 4 + 0.1,\\;1.2\\cdot 95 - 4 - 0.2\\,]$.\n- Case $4$ (near-agreement; small random deviations): \n  $x = [\\,10,20,30,40,50,60,70,80,90,100\\,]$ and \n  $y = [\\,10 + 0.05,\\;20 - 0.02,\\;30 + 0.03,\\;40 + 0.01,\\;50 - 0.04,\\;60 + 0.02,\\;70 - 0.03,\\;80 + 0.00,\\;90 + 0.04,\\;100 - 0.01\\,]$.\n\nYour program must:\n- Implement the robust estimator for $a$ and $b$ based on order statistics derived from pairwise relationships between points, avoiding zero-denominator computations when $x_j = x_i$.\n- Implement the Limits of Agreement calculation with the differences $d_i = y_i - x_i$, computing $\\overline{d}$ and $s_d$, then $\\overline{d} \\pm 1.96 s_d$.\n- For each test case, produce the list $[b,a,\\overline{d},\\text{LoA}_{\\text{low}},\\text{LoA}_{\\text{high}}]$ as real numbers.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each item is the list for one test case. For example, the output must be of the form $[[b_1,a_1,\\overline{d}_1,\\text{LoA}_{\\text{low},1},\\text{LoA}_{\\text{high},1}],[b_2,a_2,\\overline{d}_2,\\text{LoA}_{\\text{low},2},\\text{LoA}_{\\text{high},2}],\\ldots]$ with no additional text.", "solution": "The solution implements a statistical methodology for comparing two clinical assays. This involves two main components: first, a robust linear regression to model the relationship between the two methods, and second, an agreement analysis to quantify the differences between their measurements. The solution is derived and implemented based on standard, well-established techniques in biostatistics and clinical chemistry: Passing-Bablok regression and Bland-Altman analysis.\n\n### Part 1: Robust Linear Regression using Passing-Bablok Estimator\n\nThe Passing-Bablok method is a nonparametric procedure for fitting a linear regression line that is robust to outliers. It aligns perfectly with the problem's requirements. The estimation proceeds in two steps: first the slope $b$, then the intercept $a$.\n\n**Step 1.1: Slope Estimation ($\\hat{b}$)**\n\nGiven $n$ paired data points $(x_i, y_i)$, the first step is to compute all possible pairwise slopes. For any two distinct points $i$ and $j$ ($1 \\le i < j \\le n$), a slope $s_{ij}$ is calculated, provided that the denominator is non-zero. The set of all such valid slopes, $S$, is given by:\n$$\nS = \\left\\{ s_{ij} = \\frac{y_j - y_i}{x_j - x_i} \\quad \\forall i < j \\text{ such that } x_i \\ne x_j \\right\\}\n$$\nThe problem explicitly states that pairs with $x_i = x_j$ should be ignored for slope calculation, which is a defining feature of this method. Let $N$ be the number of elements in the set $S$. The robust estimate of the slope, $\\hat{b}$, is the median of this set of pairwise slopes:\n$$\n\\hat{b} = \\text{median}(S)\n$$\nThe median is chosen for its robustness. For a sorted set of $N$ slopes, if $N$ is odd, the median is the value at position $(N+1)/2$. If $N$ is even, the median is the average of the two central values at positions $N/2$ and $N/2+1$. This estimator relies on order statistics (the median) and makes no assumptions about the distribution of the data or errors.\n\n**Step 1.2: Intercept Estimation ($\\hat{a}$)**\n\nOnce the slope estimate $\\hat{b}$ is obtained, the intercept $a$ can be estimated. For each data point $(x_i, y_i)$, an intercept candidate $c_i$ is calculated by rearranging the linear equation:\n$$\nc_i = y_i - \\hat{b} x_i\n$$\nThis results in a set of $n$ intercept candidates $\\{c_1, c_2, \\ldots, c_n\\}$. The robust estimate of the intercept, $\\hat{a}$, is the median of this set:\n$$\n\\hat{a} = \\text{median}(\\{c_1, c_2, \\ldots, c_n\\})\n$$\nThis two-step process yields the robust regression line $\\hat{y} = \\hat{a} + \\hat{b} x$.\n\n### Part 2: Agreement Analysis using Bland-Altman Method\n\nWhile regression analysis describes the systematic relationship between two methods, agreement analysis quantifies the random differences between them. The Bland-Altman approach is the standard for this task.\n\n**Step 2.1: Calculation of Differences ($d_i$)**\n\nThe fundamental quantity is the difference between the paired measurements:\n$$\nd_i = y_i - x_i\n$$\nThis represents the error or disagreement for the $i$-th specimen.\n\n**Step 2.2: Mean and Standard Deviation of Differences**\n\nThe average of these differences, $\\overline{d}$, represents the mean bias between the two assays. A value of $\\overline{d}$ close to $0$ indicates low systematic bias. It is calculated as:\n$$\n\\overline{d} = \\frac{1}{n} \\sum_{i=1}^{n} d_i\n$$\nThe scatter of the differences around the mean is quantified by the sample standard deviation, $s_d$. The problem provides the formula for the unbiased sample standard deviation, which divides by $n-1$:\n$$\ns_d = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (d_i - \\overline{d})^2}\n$$\n\n**Step 2.3: Limits of Agreement (LoA)**\n\nThe Limits of Agreement define the range within which most differences between the two methods are expected to fall. Assuming the differences are approximately normally distributed, this range is typically a $95\\%$ prediction interval. The problem specifies using the constant $1.96$, which corresponds to the appropriate z-score from the standard normal distribution ($z_{0.025}$).\n\nThe lower and upper Limits of Agreement are calculated as:\n$$\n\\text{LoA}_{\\text{low}} = \\overline{d} - 1.96 s_d\n$$\n$$\n\\text{LoA}_{\\text{high}} = \\overline{d} + 1.96 s_d\n$$\nThese two values, along with the mean difference $\\overline{d}$, provide a complete summary of the agreement between the assays.\n\n### Summary of Calculations\nFor each test case, the program will execute these steps to compute the five required values: the robust slope $\\hat{b}$, the robust intercept $\\hat{a}$, the mean difference $\\overline{d}$, the lower limit of agreement $\\text{LoA}_{\\text{low}}$, and the upper limit of agreement $\\text{LoA}_{\\text{high}}$. These will be returned as a list $[\\hat{b}, \\hat{a}, \\overline{d}, \\text{LoA}_{\\text{low}}, \\text{LoA}_{\\text{high}}]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the method comparison problem for all test cases.\n    Implements Passing-Bablok regression and Bland-Altman analysis.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (general case; moderate proportional error and small bias)\n        (\n            np.array([8, 12, 18, 25, 35, 48, 60, 72, 85, 100], dtype=float),\n            np.array([9.84, 13.06, 19.54, 26.1, 36.5, 48.54, 60.6, 72.26, 84.7, 100.1], dtype=float)\n        ),\n        # Case 2 (boundary with repeated x values; tests handling of zero-denominator pairs)\n        (\n            np.array([50, 50, 60, 60, 60, 80, 80, 80, 90, 110], dtype=float),\n            np.array([50.5, 47.5, 60.5, 58.5, 60.4, 82.2, 80.2, 81.3, 91.5, 111.9], dtype=float)\n        ),\n        # Case 3 (outliers present; tests robustness)\n        (\n            np.array([5, 15, 25, 35, 45, 55, 65, 75, 85, 95], dtype=float),\n            np.array([2.2, 13.9, 26.3, 53.0, 49.5, 62.0, 74.4, 74.0, 98.1, 109.8], dtype=float)\n        ),\n        # Case 4 (near-agreement; small random deviations)\n        (\n            np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100], dtype=float),\n            np.array([10.05, 19.98, 30.03, 40.01, 49.96, 60.02, 69.97, 80.00, 90.04, 99.99], dtype=float)\n        )\n    ]\n\n    results = []\n    \n    for x, y in test_cases:\n        # Part 1: Passing-Bablok Regression for b and a\n        \n        # Step 1.1: Estimate slope b\n        n = len(x)\n        slopes = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                if x[j] - x[i] != 0:\n                    slope_ij = (y[j] - y[i]) / (x[j] - x[i])\n                    slopes.append(slope_ij)\n        \n        b = np.median(slopes)\n        \n        # Step 1.2: Estimate intercept a\n        intercept_residuals = y - b * x\n        a = np.median(intercept_residuals)\n        \n        # Part 2: Bland-Altman Analysis for agreement\n        \n        # Step 2.1: Calculate differences\n        differences = y - x\n        \n        # Step 2.2: Calculate mean and std dev of differences\n        mean_diff = np.mean(differences)\n        # ddof=1 for sample standard deviation (division by n-1)\n        std_diff = np.std(differences, ddof=1)\n        \n        # Step 2.3: Calculate Limits of Agreement (LoA)\n        loa_low = mean_diff - 1.96 * std_diff\n        loa_high = mean_diff + 1.96 * std_diff\n        \n        # Compile results for the current test case\n        case_result = [b, a, mean_diff, loa_low, loa_high]\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    # The default str() representation for a list is '[item1, item2, ...]', which is what's needed.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4552070"}]}