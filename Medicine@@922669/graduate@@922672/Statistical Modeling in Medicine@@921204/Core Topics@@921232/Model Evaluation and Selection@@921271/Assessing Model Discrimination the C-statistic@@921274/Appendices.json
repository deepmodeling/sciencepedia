{"hands_on_practices": [{"introduction": "To build a solid understanding of the c-statistic, we begin with its fundamental definition. This exercise [@problem_id:4952017] tasks you with calculating the c-statistic from first principles by manually enumerating all possible pairs of cases and controls from a small dataset. By directly counting concordant, discordant, and tied pairs, you will gain a concrete intuition for how this metric quantifies a model's ability to rank patients correctly.", "problem": "A clinical prediction model for $30$-day all-cause mortality in sepsis was developed and evaluated on an out-of-sample validation cohort. The model outputs predicted probabilities for each patient. For the purpose of assessing discrimination via the concordance statistic (also known as the Area Under the Receiver Operating Characteristic (ROC) curve), focus on a subset of patients comprised of $n_{1}=5$ observed deaths (cases) and $n_{0}=6$ survivors (controls). The predicted probabilities for the cases are $0.82$, $0.61$, $0.34$, $0.77$, and $0.50$. The predicted probabilities for the controls are $0.40$, $0.61$, $0.29$, $0.73$, $0.50$, and $0.15$.\n\nAssume the following principles:\n- Patients are independently sampled and scored, and the model produces valid probability scores in $[0,1]$ that can be used for ranking.\n- The concordance statistic is interpreted as the probability that a randomly selected case has a strictly higher predicted probability than a randomly selected control, with exact ties between a case and a control contributing symmetrically.\n\nCompute the concordance statistic for this subset by explicitly enumerating all case–control pairs and assessing whether each pair is concordant, discordant, or tied. Report the final value as a decimal in $[0,1]$ rounded to four significant figures.", "solution": "The problem requires the computation of the concordance statistic (c-statistic), also known as the Area Under the Receiver Operating Characteristic curve (AUC), for a given set of predicted probabilities for cases and controls.\n\nFirst, we identify the provided data.\nThe number of cases (deaths) is $n_{1} = 5$.\nThe number of controls (survivors) is $n_{0} = 6$.\nThe set of predicted probabilities for the cases is $P_{1} = \\{0.82, 0.61, 0.34, 0.77, 0.50\\}$.\nThe set of predicted probabilities for the controls is $P_{0} = \\{0.40, 0.61, 0.29, 0.73, 0.50, 0.15\\}$.\n\nThe c-statistic is defined as the probability that a randomly selected case will have a higher predicted probability than a randomly selected control. When ties occur, they are to be handled symmetrically. This means each tied pair contributes $0.5$ to the count of \"favorable\" outcomes.\n\nThe total number of possible case-control pairs is the product of the number of cases and the number of controls:\n$$ N_{\\text{total}} = n_{1} \\times n_{0} = 5 \\times 6 = 30 $$\n\nThe formula for the c-statistic is:\n$$ C = \\frac{N_{C} + (0.5 \\times N_{T})}{N_{\\text{total}}} $$\nwhere $N_{C}$ is the number of concordant pairs (case probability is strictly greater than control probability) and $N_{T}$ is the number of tied pairs (case probability is equal to control probability).\n\nTo find $N_{C}$ and $N_{T}$, we must systematically compare each of the $5$ case probabilities against each of the $6$ control probabilities.\n\nLet's denote a case probability as $p_{\\text{case}}$ and a control probability as $p_{\\text{control}}$. A pair is:\n- Concordant if $p_{\\text{case}} > p_{\\text{control}}$.\n- Tied if $p_{\\text{case}} = p_{\\text{control}}$.\n- Discordant if $p_{\\text{case}}  p_{\\text{control}}$.\n\nWe will enumerate the comparisons for each case:\n\n1.  For case probability $p_{\\text{case}} = 0.82$:\n    - vs $0.40$ (Concordant)\n    - vs $0.61$ (Concordant)\n    - vs $0.29$ (Concordant)\n    - vs $0.73$ (Concordant)\n    - vs $0.50$ (Concordant)\n    - vs $0.15$ (Concordant)\n    This case contributes $6$ concordant pairs and $0$ tied pairs.\n\n2.  For case probability $p_{\\text{case}} = 0.61$:\n    - vs $0.40$ (Concordant)\n    - vs $0.61$ (Tied)\n    - vs $0.29$ (Concordant)\n    - vs $0.73$ (Discordant)\n    - vs $0.50$ (Concordant)\n    - vs $0.15$ (Concordant)\n    This case contributes $4$ concordant pairs and $1$ tied pair.\n\n3.  For case probability $p_{\\text{case}} = 0.34$:\n    - vs $0.40$ (Discordant)\n    - vs $0.61$ (Discordant)\n    - vs $0.29$ (Concordant)\n    - vs $0.73$ (Discordant)\n    - vs $0.50$ (Discordant)\n    - vs $0.15$ (Concordant)\n    This case contributes $2$ concordant pairs and $0$ tied pairs.\n\n4.  For case probability $p_{\\text{case}} = 0.77$:\n    - vs $0.40$ (Concordant)\n    - vs $0.61$ (Concordant)\n    - vs $0.29$ (Concordant)\n    - vs $0.73$ (Concordant)\n    - vs $0.50$ (Concordant)\n    - vs $0.15$ (Concordant)\n    This case contributes $6$ concordant pairs and $0$ tied pairs.\n\n5.  For case probability $p_{\\text{case}} = 0.50$:\n    - vs $0.40$ (Concordant)\n    - vs $0.61$ (Discordant)\n    - vs $0.29$ (Concordant)\n    - vs $0.73$ (Discordant)\n    - vs $0.50$ (Tied)\n    - vs $0.15$ (Concordant)\n    This case contributes $3$ concordant pairs and $1$ tied pair.\n\nNow, we sum the counts from all comparisons:\nTotal number of concordant pairs, $N_{C} = 6 + 4 + 2 + 6 + 3 = 21$.\nTotal number of tied pairs, $N_{T} = 0 + 1 + 0 + 0 + 1 = 2$.\n\nThe number of discordant pairs is $30 - 21 - 2 = 7$, which is a useful check but not directly needed for the formula.\n\nWe can now substitute these values into the formula for the c-statistic:\n$$ C = \\frac{21 + (0.5 \\times 2)}{30} $$\n$$ C = \\frac{21 + 1}{30} $$\n$$ C = \\frac{22}{30} $$\n$$ C = \\frac{11}{15} $$\n\nTo provide the answer as a decimal rounded to four significant figures, we perform the division:\n$$ C = 0.733333... $$\nRounding to four significant figures gives $0.7333$.", "answer": "$$\n\\boxed{0.7333}\n$$", "id": "4952017"}, {"introduction": "The c-statistic is numerically equivalent to the Area Under the Receiver Operating Characteristic (ROC) curve, a powerful visualization of a model's performance across all classification thresholds. This practice problem [@problem_id:4951977] guides you through the process of constructing an empirical ROC curve from patient-level data and calculating its area using the trapezoidal rule. This exercise will help you master the geometric interpretation of the c-statistic and understand the relationship between predicted probabilities, classification thresholds, and model discrimination.", "problem": "A logistic regression model was developed to predict in-hospital sepsis mortality. For a hold-out set of $12$ patients, the model’s predicted probabilities $\\hat{p}$ and the observed outcomes $y \\in \\{0,1\\}$ (with $1$ indicating death) are given below. Construct the empirical Receiver Operating Characteristic (ROC) curve from these data using the fundamental definitions of the true positive rate and false positive rate, taking the classification rule “predict positive if $\\hat{p} \\ge t$” for a threshold $t$ that varies from above the maximum $\\hat{p}$ to below the minimum $\\hat{p}$. Treat all identical scores at a given threshold as entering simultaneously, and connect successive $(\\mathrm{FPR}, \\mathrm{TPR})$ points with straight line segments. Then compute the area under this empirical ROC curve using the trapezoidal rule.\n\nPatient-level data:\n- Patient $1$: $\\hat{p} = 0.80$, $y = 0$\n- Patient $2$: $\\hat{p} = 0.58$, $y = 0$\n- Patient $3$: $\\hat{p} = 0.95$, $y = 1$\n- Patient $4$: $\\hat{p} = 0.51$, $y = 0$\n- Patient $5$: $\\hat{p} = 0.72$, $y = 1$\n- Patient $6$: $\\hat{p} = 0.84$, $y = 0$\n- Patient $7$: $\\hat{p} = 0.66$, $y = 0$\n- Patient $8$: $\\hat{p} = 0.78$, $y = 1$\n- Patient $9$: $\\hat{p} = 0.89$, $y = 1$\n- Patient $10$: $\\hat{p} = 0.71$, $y = 0$\n- Patient $11$: $\\hat{p} = 0.51$, $y = 0$\n- Patient $12$: $\\hat{p} = 0.73$, $y = 1$\n\nUse only the definitions of the true positive rate $\\mathrm{TPR} = \\mathrm{TP}/P$ and false positive rate $\\mathrm{FPR} = \\mathrm{FP}/N$ (with $P$ the number of positives and $N$ the number of negatives) and the trapezoidal rule for numerical integration of a piecewise-linear curve. Round your final numeric answer to four significant figures. Express the final area as a pure decimal (dimensionless).", "solution": "The problem requires constructing the empirical Receiver Operating Characteristic (ROC) curve and calculating the area under it (AUC).\n\n### Step 1: Data Preparation and Sorting\nFirst, we count the total number of actual positive cases ($P$) and actual negative cases ($N$) in the dataset.\n- Positive cases ($y=1$): Patients 3, 5, 8, 9, 12. Thus, $P=5$.\n- Negative cases ($y=0$): Patients 1, 2, 4, 6, 7, 10, 11. Thus, $N=7$.\n\nTo construct the ROC curve, we sort the patients by their predicted probability $\\hat{p}$ in descending order, noting their true outcome $y$.\n1.  P3: $\\hat{p} = 0.95, y = 1$\n2.  P9: $\\hat{p} = 0.89, y = 1$\n3.  P6: $\\hat{p} = 0.84, y = 0$\n4.  P1: $\\hat{p} = 0.80, y = 0$\n5.  P8: $\\hat{p} = 0.78, y = 1$\n6.  P12: $\\hat{p} = 0.73, y = 1$\n7.  P5: $\\hat{p} = 0.72, y = 1$\n8.  P10: $\\hat{p} = 0.71, y = 0$\n9.  P7: $\\hat{p} = 0.66, y = 0$\n10. P2: $\\hat{p} = 0.58, y = 0$\n11. P4: $\\hat{p} = 0.51, y = 0$ (Tied)\n12. P11: $\\hat{p} = 0.51, y = 0$ (Tied)\n\n### Step 2: Constructing the ROC Curve Points\nThe ROC curve is a plot of the True Positive Rate ($\\mathrm{TPR} = \\mathrm{TP}/P$) versus the False Positive Rate ($\\mathrm{FPR} = \\mathrm{FP}/N$). We start at $(0,0)$ and move through the sorted list. A true positive ($y=1$) increases TPR by $1/P = 1/5$. A false positive ($y=0$) increases FPR by $1/N = 1/7$.\n\nFollowing the sorted list, we generate the vertices of the ROC curve:\n- Start at $P_0 = (0, 0)$.\n- P3 ($y=1$): TP increases by 1. Point $P_1 = (0, 1/5)$.\n- P9 ($y=1$): TP increases by 1. Point $P_2 = (0, 2/5)$.\n- P6 ($y=0$): FP increases by 1. Point $P_3 = (1/7, 2/5)$.\n- P1 ($y=0$): FP increases by 1. Point $P_4 = (2/7, 2/5)$.\n- P8 ($y=1$): TP increases by 1. Point $P_5 = (2/7, 3/5)$.\n- P12 ($y=1$): TP increases by 1. Point $P_6 = (2/7, 4/5)$.\n- P5 ($y=1$): TP increases by 1. Point $P_7 = (2/7, 5/5) = (2/7, 1)$.\n- P10 ($y=0$): FP increases by 1. Point $P_8 = (3/7, 1)$.\n- P7 ($y=0$): FP increases by 1. Point $P_9 = (4/7, 1)$.\n- P2 ($y=0$): FP increases by 1. Point $P_{10} = (5/7, 1)$.\n- P4  P11 ($y=0$, tied): FP increases by 2. Point $P_{11} = ((5+2)/7, 1) = (1, 1)$.\n\nThe sequence of points $(\\mathrm{FPR}_i, \\mathrm{TPR}_i)$ is:\n$P_0 = (0, 0)$, $P_1 = (0, 1/5)$, $P_2 = (0, 2/5)$, $P_3 = (1/7, 2/5)$, $P_4 = (2/7, 2/5)$, $P_5 = (2/7, 3/5)$, $P_6 = (2/7, 4/5)$, $P_7 = (2/7, 1)$, $P_8 = (3/7, 1)$, $P_9 = (4/7, 1)$, $P_{10} = (5/7, 1)$, $P_{11} = (1, 1)$.\n\n### Step 3: Calculation of the Area Under the Curve (AUC)\nThe AUC is calculated using the trapezoidal rule for the area under the piecewise-linear curve:\n$$ \\mathrm{AUC} = \\sum_{i=1}^{k} \\frac{1}{2} (\\mathrm{TPR}_{i-1} + \\mathrm{TPR}_i) (\\mathrm{FPR}_i - \\mathrm{FPR}_{i-1}) $$\nWe sum the areas of the segments where FPR changes. The vertical segments (where FPR does not change) contribute zero area.\n- Segment $P_2 \\to P_3$: Area = $\\frac{1}{2}(\\frac{2}{5} + \\frac{2}{5})(\\frac{1}{7} - 0) = \\frac{2}{5} \\times \\frac{1}{7} = \\frac{2}{35}$.\n- Segment $P_3 \\to P_4$: Area = $\\frac{1}{2}(\\frac{2}{5} + \\frac{2}{5})(\\frac{2}{7} - \\frac{1}{7}) = \\frac{2}{5} \\times \\frac{1}{7} = \\frac{2}{35}$.\n- Segment $P_7 \\to P_8$: Area = $\\frac{1}{2}(1 + 1)(\\frac{3}{7} - \\frac{2}{7}) = 1 \\times \\frac{1}{7} = \\frac{5}{35}$.\n- Segment $P_8 \\to P_9$: Area = $\\frac{1}{2}(1 + 1)(\\frac{4}{7} - \\frac{3}{7}) = 1 \\times \\frac{1}{7} = \\frac{5}{35}$.\n- Segment $P_9 \\to P_{10}$: Area = $\\frac{1}{2}(1 + 1)(\\frac{5}{7} - \\frac{4}{7}) = 1 \\times \\frac{1}{7} = \\frac{5}{35}$.\n- Segment $P_{10} \\to P_{11}$: Area = $\\frac{1}{2}(1 + 1)(1 - \\frac{5}{7}) = 1 \\times \\frac{2}{7} = \\frac{10}{35}$.\n\nTotal AUC is the sum of these areas:\n$$ \\mathrm{AUC} = \\frac{2}{35} + \\frac{2}{35} + \\frac{5}{35} + \\frac{5}{35} + \\frac{5}{35} + \\frac{10}{35} = \\frac{2+2+5+5+5+10}{35} = \\frac{29}{35} $$\nFinally, we convert this fraction to a decimal and round to four significant figures:\n$$ \\mathrm{AUC} = \\frac{29}{35} \\approx 0.8285714... $$\nRounding to four significant figures gives $0.8286$.", "answer": "$$\\boxed{0.8286}$$", "id": "4951977"}, {"introduction": "A crucial property of the c-statistic is that it measures only discrimination—the ability to rank subjects correctly—and is insensitive to the absolute magnitude of the predicted probabilities. This practice [@problem_id:4952027] challenges you to prove from first principles why the c-statistic remains unchanged after applying a monotonic transformation to a model's predictions, even as the model's calibration is altered. Successfully completing this exercise will solidify your understanding of the fundamental distinction between model discrimination and calibration, a key concept in rigorous model evaluation.", "problem": "A clinical team is studying the discrimination and calibration properties of risk models for a binary outcome $Y \\in \\{0,1\\}$, such as occurrence of a postoperative complication. Let $X$ denote a continuous biomarker, measured preoperatively. Assume the data are generated from a logistic regression model in which the true conditional probability of the event is given by\n$$\n\\mathbb{P}(Y=1 \\mid X=x) \\;=\\; \\sigma\\!\\left(\\alpha^\\star + \\beta^\\star x\\right),\n$$\nwhere $\\sigma(z) = \\dfrac{1}{1+e^{-z}}$ is the logistic function, and $\\alpha^\\star \\in \\mathbb{R}$, $\\beta^\\star \\in \\mathbb{R}$ are fixed parameters. Consider two fitted models that produce subject-level predicted probabilities:\n$$\np_i^{(1)} \\;=\\; \\sigma\\!\\left(\\alpha^\\star + \\beta^\\star X_i\\right),\n\\qquad\np_i^{(2)} \\;=\\; \\sigma\\!\\left(a + b\\left(\\alpha^\\star + \\beta^\\star X_i\\right)\\right),\n$$\nfor constants $a \\in \\mathbb{R}$ and $b0$ chosen by the analyst independently of the data-generating parameters. The team will assess model discrimination using the $c$-statistic (also called Area Under the Receiver Operating Characteristic Curve (AUC)), defined as\n$$\nc \\;=\\; \\mathbb{P}\\!\\left(S_i  S_j \\,\\middle|\\, Y_i=1,\\, Y_j=0\\right),\n$$\nwhere $S_k$ is a scalar score used to rank individuals (for probabilistic classifiers, $S_k$ can be taken as any strictly increasing transform of $p_k$). They will assess calibration using logistic recalibration, by fitting\n$$\n\\logit\\!\\left(\\mathbb{P}(Y=1)\\right) \\;=\\; \\gamma_0 + \\gamma_1 \\logit\\!\\left(p\\right),\n$$\nwhere $\\logit(u)=\\log\\!\\left(\\dfrac{u}{1-u}\\right)$, and interpreting $\\gamma_0$ as the calibration-in-the-large (intercept) and $\\gamma_1$ as the calibration slope. Starting only from these definitions and the stated data-generating model, reason from first principles to determine whether models with $p^{(1)}$ and $p^{(2)}$ have identical $c$-statistics, and derive the calibration intercept and slope for the second model when recalibrated against the true data-generating mechanism. Explain why identical discrimination can coexist with different calibration metrics. Then select the correct statement below.\n\nA. Both models have identical $c$-statistics because $p^{(2)}$ is a strictly increasing transform of $p^{(1)}$; the recalibration of $Y$ on $\\logit\\!\\left(p^{(2)}\\right)$ yields calibration slope $1/b$ and calibration intercept $-a/b$.\n\nB. Both models have identical $c$-statistics and identical calibration slope and intercept, regardless of $a$ and $b$.\n\nC. The second model has a larger $c$-statistic whenever $b1$, because scaling the linear predictor by $b$ increases separation between cases and controls in probability space.\n\nD. The $c$-statistic is unchanged only if $a=0$; any nonzero $a$ alters ranking and thus changes the $c$-statistic.\n\nE. If $b0$, the $c$-statistic would still be unchanged because the ordering by magnitude of the scores is preserved under sign reversal.", "solution": "The solution requires analyzing the effect of a transformation on a model's discrimination ($c$-statistic) and calibration.\n\n### Part 1: Discrimination Analysis (c-statistic)\n\nThe $c$-statistic measures a model's ability to rank subjects. It is defined as $c = \\mathbb{P}(S_i > S_j \\mid Y_i=1, Y_j=0)$, where $S$ is a score used for ranking. The score $S$ can be the predicted probability $p$ or any strictly increasing transformation of it. This means the $c$-statistic depends only on the rank ordering of the predicted probabilities, not their absolute values.\n\nLet's analyze the relationship between the predicted probabilities of the two models, $p^{(1)}$ and $p^{(2)}$.\nThe linear predictor of the true model is $L_i = \\alpha^\\star + \\beta^\\star X_i$. The predicted probability is $p_i^{(1)} = \\sigma(L_i)$. The inverse relationship is $L_i = \\logit(p_i^{(1)})$.\n\nThe predicted probability of the second model is $p_i^{(2)} = \\sigma(a + b L_i)$.\nBy substituting $L_i = \\logit(p_i^{(1)})$, we get the transformation from $p^{(1)}$ to $p^{(2)}$:\n$$ p_i^{(2)} = \\sigma(a + b \\cdot \\logit(p_i^{(1)})) $$\nTo determine if this transformation preserves rank ordering, we need to check if it is a strictly increasing function. We can examine the derivative of $p^{(2)}$ with respect to $p^{(1)}$. Using the chain rule:\n$$ \\frac{dp^{(2)}}{dp^{(1)}} = \\frac{d}{dp^{(1)}} \\sigma(a + b \\cdot \\logit(p^{(1)})) = \\sigma'(a + b \\cdot \\logit(p^{(1)})) \\cdot b \\cdot \\frac{d}{dp^{(1)}}(\\logit(p^{(1)})) $$\nThe derivatives of the component functions are:\n- $\\frac{d}{dz} \\sigma(z) = \\sigma(z)(1-\\sigma(z))$, which is always positive.\n- $\\frac{d}{dp} \\logit(p) = \\frac{1}{p(1-p)}$, which is always positive for $p \\in (0,1)$.\n\nThe problem states that the constant $b > 0$. Since all three terms in the product ($\\sigma'(\\cdot)$, $b$, and $\\frac{d}{dp}\\logit(p)$) are positive, the derivative $\\frac{dp^{(2)}}{dp^{(1)}}$ is strictly positive. This proves that $p^{(2)}$ is a strictly increasing function of $p^{(1)}$.\n\nBecause the transformation is strictly increasing, the rank ordering of subjects is identical for both models: $p_i^{(1)} > p_j^{(1)} \\iff p_i^{(2)} > p_j^{(2)}$. Therefore, the set of concordant pairs is the same for both models, and their $c$-statistics are identical.\n\n### Part 2: Calibration Analysis\n\nCalibration is assessed by fitting the model $\\logit(\\mathbb{P}(Y=1)) = \\gamma_0 + \\gamma_1 \\logit(p)$, where $\\mathbb{P}(Y=1)$ is the true probability. For model 2, this becomes:\n$$ \\logit(\\text{True Probability}) = \\gamma_0 + \\gamma_1 \\logit(p^{(2)}) $$\nThe true probability is given by $p^{(1)}$, so $\\logit(\\text{True Probability}) = \\logit(p^{(1)})$. We need to find the linear relationship between $\\logit(p^{(1)})$ and $\\logit(p^{(2)})$.\n\nFrom the definition of model 2, we have:\n$$ p_i^{(2)} = \\sigma(a + b(\\alpha^\\star + \\beta^\\star X_i)) $$\nApplying the $\\logit$ function (the inverse of $\\sigma$) to both sides gives:\n$$ \\logit(p_i^{(2)}) = a + b(\\alpha^\\star + \\beta^\\star X_i) $$\nSince $\\logit(p_i^{(1)}) = \\alpha^\\star + \\beta^\\star X_i$, we can substitute this in:\n$$ \\logit(p_i^{(2)}) = a + b \\cdot \\logit(p_i^{(1)}) $$\nTo match the form of the calibration equation, we rearrange to solve for $\\logit(p^{(1)})$:\n$$ b \\cdot \\logit(p_i^{(1)}) = \\logit(p_i^{(2)}) - a $$\n$$ \\logit(p_i^{(1)}) = -\\frac{a}{b} + \\frac{1}{b} \\logit(p_i^{(2)}) $$\nBy comparing this to the calibration equation $\\logit(\\text{True Probability}) = \\gamma_0 + \\gamma_1 \\logit(p^{(2)})$, we can identify the calibration parameters for model 2:\n- Calibration intercept: $\\gamma_0 = -a/b$\n- Calibration slope: $\\gamma_1 = 1/b$\n\n### Conclusion and Option Selection\n\n- Both models have identical $c$-statistics because $p^{(2)}$ is a strictly increasing monotonic transformation of $p^{(1)}$ (since $b>0$).\n- The calibration of model 2 is different from model 1 (which is perfectly calibrated with $\\gamma_0=0, \\gamma_1=1$), unless $a=0$ and $b=1$. The calibration intercept is $\\gamma_0 = -a/b$ and the slope is $\\gamma_1 = 1/b$.\n\nThis analysis directly matches the statement in option A. All other options make incorrect claims about the $c$-statistic or the calibration parameters.", "answer": "$$\\boxed{A}$$", "id": "4952027"}]}