{"hands_on_practices": [{"introduction": "Understanding survival analysis with truncated data begins with mastering the construction of the risk set at each event time. This exercise provides a hands-on opportunity to apply the fundamental definition of a risk set that accounts for both delayed entry (left truncation) and loss to follow-up (right censoring). By manually calculating the number of subjects at risk at each failure, you will build a solid foundation for accurately estimating survival probabilities using the Kaplan-Meier product-limit method.", "problem": "A clinical study follows patients for the time to a first cardiovascular event measured in months. Each patient can enter the study after some delay due to late recruitment, producing left truncation, and may be right censored if lost to follow-up or if the study ends before an event occurs. For patient $i$, the observed data are the left truncation time $L_i$, the observed time $T_i$, and the event indicator $\\delta_i$, where $\\delta_i = 1$ denotes an event at time $T_i$ and $\\delta_i = 0$ denotes right censoring at time $T_i$. The dataset for $8$ patients is:\n- Patient $1$: $(L_1 = 0, T_1 = 3, \\delta_1 = 1)$.\n- Patient $2$: $(L_2 = 1, T_2 = 5, \\delta_2 = 1)$.\n- Patient $3$: $(L_3 = 2, T_3 = 6, \\delta_3 = 0)$.\n- Patient $4$: $(L_4 = 4, T_4 = 7, \\delta_4 = 1)$.\n- Patient $5$: $(L_5 = 0.5, T_5 = 9, \\delta_5 = 1)$.\n- Patient $6$: $(L_6 = 3.2, T_6 = 8, \\delta_6 = 0)$.\n- Patient $7$: $(L_7 = 5.5, T_7 = 10, \\delta_7 = 0)$.\n- Patient $8$: $(L_8 = 0, T_8 = 4, \\delta_8 = 0)$.\n\nAssume there are no tied failures and no censorings occurring at the exact same time as a failure.\n\nUsing only the fundamental definitions of risk sets and counting processes in survival analysis, compute the risk set size $Y(u)$ and the number of events $d(u)$ at each distinct observed failure time $u$. Verify, at each failure time $u$, that the risk set excludes those who have not yet entered (i.e., with $L_i \\ge u$) or who have already been censored or failed before $u$. Then, using these values and the product-limit principle, compute the Kaplan–Meier (KM) survival estimate at $t = 9$ months, denoted $\\hat{S}(9)$. Express your final answer as an exact fraction. Do not round.", "solution": "We begin with standard counting process notation for survival data with left truncation and right censoring. For each individual $i$, define the event counting process\n$$\nN_i(t) = \\mathbf{1}\\{T_i \\le t, \\delta_i = 1\\},\n$$\nand the at-risk indicator\n$$\nY_i(t) = \\mathbf{1}\\{L_i  t \\le T_i\\}.\n$$\nThe risk set at time $t$ is $R(t) = \\{i : Y_i(t) = 1\\}$, and its size is $Y(t) = |R(t)|$. The number of events at time $t$ is $d(t) = \\sum_{i=1}^{n} \\mathbf{1}\\{T_i = t, \\delta_i = 1\\}$. With left truncation, an individual contributes to the risk set only after entering the study (i.e., only for times $t$ greater than their $L_i$), and with right censoring, an individual leaves the risk set strictly after their censoring time.\n\nThe distinct observed failure times in the dataset are $u \\in \\{3, 5, 7, 9\\}$. We compute $R(u)$ and $Y(u)$ at each failure time $u$, and verify the exclusions required by left truncation and right censoring.\n\nAt $u = 3$:\n- Include those with $L_i  3$ and $T_i \\ge 3$: patients $1$ ($L_1 = 0, T_1 = 3$), $2$ ($L_2 = 1, T_2 = 5$), $3$ ($L_3 = 2, T_3 = 6$), $5$ ($L_5 = 0.5, T_5 = 9$), and $8$ ($L_8 = 0, T_8 = 4$).\n- Exclude those not yet entered: $4$ ($L_4 = 4$), $6$ ($L_6 = 3.2$), $7$ ($L_7 = 5.5$).\n- No one has yet been censored or failed before $3$.\nThus, $R(3) = \\{1, 2, 3, 5, 8\\}$, so $Y(3) = 5$, and $d(3) = 1$ (patient $1$ fails at $3$).\n\nAt $u = 5$:\n- Remove those who failed or were censored before $5$: patient $1$ (failed at $3$) and patient $8$ (censored at $4$) are no longer at risk.\n- Include those with $L_i  5$ and $T_i \\ge 5$: patients $2$ ($L_2 = 1, T_2 = 5$), $3$ ($L_3 = 2, T_3 = 6$), $4$ ($L_4 = 4, T_4 = 7$), $5$ ($L_5 = 0.5, T_5 = 9$), and $6$ ($L_6 = 3.2, T_6 = 8$).\n- Exclude those not yet entered: patient $7$ ($L_7 = 5.5$).\nThis verifies exclusion of the not-yet-entered and already removed. Hence, $R(5) = \\{2, 3, 4, 5, 6\\}$, so $Y(5) = 5$, and $d(5) = 1$ (patient $2$ fails at $5$).\n\nAt $u = 7$:\n- Remove those who failed or were censored before $7$: patient $2$ (failed at $5$) is removed; patient $3$ (censored at $6$) is removed.\n- Include those with $L_i  7$ and $T_i \\ge 7$: patients $4$ ($L_4 = 4, T_4 = 7$), $5$ ($L_5 = 0.5, T_5 = 9$), $6$ ($L_6 = 3.2, T_6 = 8$), and $7$ ($L_7 = 5.5, T_7 = 10$).\nThis again verifies exclusion of those censored before $7$ and inclusion only after left truncation. Therefore, $R(7) = \\{4, 5, 6, 7\\}$, so $Y(7) = 4$, and $d(7) = 1$ (patient $4$ fails at $7$).\n\nAt $u = 9$:\n- Remove those who failed or were censored before $9$: patient $4$ (failed at $7$) and patient $6$ (censored at $8$) are removed.\n- Include those with $L_i  9$ and $T_i \\ge 9$: patients $5$ ($L_5 = 0.5, T_5 = 9$) and $7$ ($L_7 = 5.5, T_7 = 10$).\nThus, $R(9) = \\{5, 7\\}$, so $Y(9) = 2$, and $d(9) = 1$ (patient $5$ fails at $9$).\n\nWe have verified at each failure time that $R(u)$ excludes those not yet entered (those with $L_i \\ge u$) and those who have already failed or been censored before $u$. With these risk set sizes and event counts, we compute the Kaplan–Meier (KM) product-limit estimate of survival at $t = 9$ months:\n$$\n\\hat{S}(9) = \\prod_{u \\in \\{3, 5, 7, 9\\}} \\left(1 - \\frac{d(u)}{Y(u)}\\right) = \\left(1 - \\frac{1}{5}\\right)\\left(1 - \\frac{1}{5}\\right)\\left(1 - \\frac{1}{4}\\right)\\left(1 - \\frac{1}{2}\\right).\n$$\nEvaluating the product,\n$$\n\\hat{S}(9) = \\frac{4}{5} \\cdot \\frac{4}{5} \\cdot \\frac{3}{4} \\cdot \\frac{1}{2} = \\frac{48}{200} = \\frac{6}{25}.\n$$\nTherefore, the KM survival estimate at $t = 9$ months is $\\hat{S}(9) = \\frac{6}{25}$.", "answer": "$$\\boxed{\\frac{6}{25}}$$", "id": "4985814"}, {"introduction": "Having established the correct procedure for handling left-truncated data, we now explore the consequences of failing to do so. This practice is a crucial thought experiment that demonstrates a common and serious error in survival analysis: immortal time bias. By comparing a correctly specified Kaplan-Meier estimator with a naive one that ignores delayed entry, you will quantify the resulting bias and gain a deep, practical understanding of why proper risk set construction is essential for valid inference. [@problem_id:4985814]", "problem": "A radiomics cohort evaluates time-to-death from cancer diagnosis and includes only patients who had a baseline imaging scan after diagnosis, at a patient-specific entry time. Inclusion creates left truncation: a patient with event time shorter than their entry time is not observed. Let the time origin be diagnosis, and let each patient have a left-truncation time $L_{i}$ (entry time since diagnosis), an observed time $X_{i}$, and an event indicator $\\delta_{i}$, where $\\delta_{i} = 1$ if the event occurred at $X_{i}$ and $\\delta_{i} = 0$ if right-censored at $X_{i}$. The observed patients are:\n- Patient $E$: $L_{E} = 0$, $X_{E} = 7$, $\\delta_{E} = 1$\n- Patient $A$: $L_{A} = 2$, $X_{A} = 5$, $\\delta_{A} = 1$\n- Patient $G$: $L_{G} = 4$, $X_{G} = 6$, $\\delta_{G} = 1$\n- Patient $B$: $L_{B} = 6$, $X_{B} = 9$, $\\delta_{B} = 1$\n- Patient $F$: $L_{F} = 10$, $X_{F} = 11$, $\\delta_{F} = 0$\n- Patient $C$: $L_{C} = 12$, $X_{C} = 14$, $\\delta_{C} = 1$\n- Patient $D$: $L_{D} = 1$, $X_{D} = 20$, $\\delta_{D} = 0$\n\nStarting from the definitions of the survival function $S(t) = \\Pr(T > t)$, hazard function $h(t)$ as the instantaneous failure rate, and the product-limit (Kaplan–Meier) estimator for left-truncated and right-censored data using appropriate risk sets, compute the Kaplan–Meier survival estimate at $t = 12$ months in two ways:\n1. The correct estimator that accounts for left truncation, where the risk set at time $t$ is $\\{i: L_{i}  t \\le X_{i}\\}$.\n2. The naive estimator that ignores left truncation by treating all $L_{i}$ as $0$, so the risk set at time $t$ is $\\{i: t \\le X_{i}\\}$.\n\nDefine the signed bias at $t = 12$ months as $b(12) = S_{\\text{naive}}(12) - S_{\\text{LTRC}}(12)$, where $S_{\\text{LTRC}}(t)$ denotes the left-truncation-aware estimator and $S_{\\text{naive}}(t)$ denotes the estimator that ignores left truncation. In your derivation, justify qualitatively whether the bias is upward or downward by describing how the distorted risk sets alter the ratio of events to the number at risk, and relate this to the hazard function shape often observed in radiomics cohorts with prevalent cases. Report $b(12)$ as a single real number, rounded to four significant figures. Times are in months; the final reported bias is dimensionless.", "solution": "The problem requires the computation and comparison of two Kaplan-Meier survival estimates at time $t=12$ months: one that correctly accounts for left-truncated and right-censored (LTRC) data, and a naive one that ignores left truncation.\n\nThe Kaplan-Meier or product-limit estimator for the survival function $S(t) = \\Pr(T > t)$ is given by:\n$$ \\hat{S}(t) = \\prod_{j: t_j \\leq t} \\left(1 - \\frac{d_j}{n_j}\\right) $$\nwhere $t_j$ are the distinct event times, $d_j$ is the number of events at time $t_j$, and $n_j$ is the number of individuals at risk just before time $t_j$. The definition of the risk set, and thus the value of $n_j$, is the critical difference between the two estimators.\n\nThe provided data consists of $N=7$ patients. The unique event times are $t \\in \\{5, 6, 7, 9, 14\\}$. We need to compute the survival probabilities at $t=12$ months.\n\n**1. Left-Truncation Aware Estimator ($S_{\\text{LTRC}}$)**\n\nThe risk set at time $t$ is correctly defined as $R(t) = \\{i: L_i  t \\le X_i\\}$. The number at risk, $n_j$, for an event at time $t_j$ is the cardinality of the set $\\{i: L_i  t_j \\text{ and } X_i \\ge t_j\\}$.\n\n- At event time $t_1 = 5$:\nThe risk set $R(5)$ includes patients who entered the study before time $5$ and were still in the study at time $5$.\n$R(5) = \\{\\text{A, G, E, D}\\}$, since $L_A=2  5$, $L_G=4  5$, $L_E=0  5$, $L_D=1  5$, and their $X_i \\ge 5$. Patients B, F, C have entry times $L_i \\ge 5$.\nThe number at risk is $n_1 = 4$. One event occurred (Patient A), so $d_1 = 1$.\nThe survival factor is $1 - \\frac{d_1}{n_1} = 1 - \\frac{1}{4} = \\frac{3}{4}$.\n\n- At event time $t_2 = 6$:\nThe risk set $R(6)$ includes patients with $L_i  6$ and $X_i \\ge 6$. Patient A has had an event.\n$R(6) = \\{\\text{G, E, D}\\}$. Patient B is not at risk since their entry time is $L_B=6$, not strictly less than $6$.\nThe number at risk is $n_2 = 3$. One event occurred (Patient G), so $d_2 = 1$.\nThe survival factor is $1 - \\frac{d_2}{n_2} = 1 - \\frac{1}{3} = \\frac{2}{3}$.\n\n- At event time $t_3 = 7$:\nThe risk set $R(7)$ includes patients with $L_i  7$ and $X_i \\ge 7$. Patient G has had an event. Patient B now enters the risk set ($L_B=6  7$).\n$R(7) = \\{\\text{E, B, D}\\}$.\nThe number at risk is $n_3 = 3$. One event occurred (Patient E), so $d_3 = 1$.\nThe survival factor is $1 - \\frac{d_3}{n_3} = 1 - \\frac{1}{3} = \\frac{2}{3}$.\n\n- At event time $t_4 = 9$:\nThe risk set $R(9)$ includes patients with $L_i  9$ and $X_i \\ge 9$. Patient E has had an event.\n$R(9) = \\{\\text{B, D}\\}$.\nThe number at risk is $n_4 = 2$. One event occurred (Patient B), so $d_4 = 1$.\nThe survival factor is $1 - \\frac{d_4}{n_4} = 1 - \\frac{1}{2} = \\frac{1}{2}$.\n\nThe next event is at $t_5 = 14$, which is after $t=12$. Thus, the survival probability is constant between $t=9$ and the next event/censoring time.\n$$ S_{\\text{LTRC}}(12) = \\left(1 - \\frac{1}{4}\\right) \\times \\left(1 - \\frac{1}{3}\\right) \\times \\left(1 - \\frac{1}{3}\\right) \\times \\left(1 - \\frac{1}{2}\\right) = \\frac{3}{4} \\times \\frac{2}{3} \\times \\frac{2}{3} \\times \\frac{1}{2} = \\frac{12}{72} = \\frac{1}{6} $$\n\n**2. Naive Estimator ($S_{\\text{naive}}$)**\n\nThis estimator ignores left truncation, treating all entry times as $L_i = 0$. The risk set at time $t$ becomes $\\{i: t \\le X_i\\}$. All $N=7$ patients are considered at risk from $t=0$.\n\n- At event time $t_1 = 5$: The number at risk is $n_1 = 7$. $d_1 = 1$. Survival factor: $1 - \\frac{1}{7} = \\frac{6}{7}$.\n- At event time $t_2 = 6$: Patient A is removed. The number at risk is $n_2 = 6$. $d_2 = 1$. Survival factor: $1 - \\frac{1}{6} = \\frac{5}{6}$.\n- At event time $t_3 = 7$: Patient G is removed. The number at risk is $n_3 = 5$. $d_3 = 1$. Survival factor: $1 - \\frac{1}{5} = \\frac{4}{5}$.\n- At event time $t_4 = 9$: Patient E is removed. The number at risk is $n_4 = 4$. $d_4 = 1$. Survival factor: $1 - \\frac{1}{4} = \\frac{3}{4}$.\n\nThe survival probability $S_{\\text{naive}}(12)$ is calculated up to the last event before $t=12$, which is at $t=9$:\n$$ S_{\\text{naive}}(12) = \\left(1 - \\frac{1}{7}\\right) \\times \\left(1 - \\frac{1}{6}\\right) \\times \\left(1 - \\frac{1}{5}\\right) \\times \\left(1 - \\frac{1}{4}\\right) = \\frac{6}{7} \\times \\frac{5}{6} \\times \\frac{4}{5} \\times \\frac{3}{4} = \\frac{3}{7} $$\n\n**3. Bias Calculation and Qualitative Justification**\n\nThe signed bias at $t=12$ months is $b(12) = S_{\\text{naive}}(12) - S_{\\text{LTRC}}(12)$.\n$$ b(12) = \\frac{3}{7} - \\frac{1}{6} = \\frac{3 \\times 6 - 1 \\times 7}{7 \\times 6} = \\frac{18 - 7}{42} = \\frac{11}{42} $$\nAs a decimal, $b(12) \\approx 0.2619047$. Rounded to four significant figures, this is $0.2619$.\n\nThe positive sign of the bias indicates that the naive estimator overestimates the survival probability, an upward bias. This systematic error is known as **immortal time bias**.\n\nThe bias arises because the naive estimator incorrectly defines the risk sets. By assuming all patients are at risk from time $t=0$, it includes individuals in the risk set during periods when they could not have been observed to have an event. For example, at the first event time $t=5$, the naive risk set size is $n_{\\text{naive}}(5) = 7$, while the correct risk set size is $n_{\\text{LTRC}}(5) = 4$. The naive method incorrectly includes patients B, F, and C, who were not yet under observation.\n\nThis inflation of the denominator $n_j$ in the hazard contribution term $d_j/n_j$ occurs at each early event time. Consequently, the naive estimator systematically underestimates the instantaneous hazard rate: $\\hat{h}_{\\text{naive}}(t_j) = d_j/n_{j, \\text{naive}}  d_j/n_{j, \\text{LTRC}} = \\hat{h}_{\\text{LTRC}}(t_j)$. A lower hazard rate implies a higher probability of survival. The survival function is a product of terms of the form $(1 - d_j/n_j)$. Since each of these terms is larger for the naive estimator (closer to $1$), their cumulative product $S_{\\text{naive}}(t)$ is larger than $S_{\\text{LTRC}}(t)$, leading to an optimistic survival curve.\n\nIn radiomics cohorts with prevalent cases (patients who have already survived for some time since diagnosis), left truncation is inherent. These cohorts are biased towards \"fitter\" individuals, as those with very aggressive disease would have experienced an event before meeting the study's imaging inclusion criteria. The true population hazard is often high initially and then decreases. The LTRC estimator correctly captures the higher hazard among those at risk at early times. The naive estimator, by including subjects who are \"immortal\" during their truncation interval $(0, L_i)$, fails to observe this early high-risk phase and averages the risk over an incorrectly large group, thus distorting the hazard shape and overestimating survival.", "answer": "$$\\boxed{0.2619}$$", "id": "4562470"}, {"introduction": "The principle of correctly defining the risk set is not limited to survival curve estimation; it is a cornerstone of all time-to-event analysis, including hypothesis testing. This exercise extends the concept to the log-rank test, which is used to compare survival distributions between two or more groups. You will design an algorithm from first principles to compute observed and expected event counts, explicitly accounting for left truncation, to see how the null hypothesis of equal hazards is tested in this more complex data structure.", "problem": "A medical survival cohort is partitioned into two groups labeled $0$ and $1$. Each subject $i$ has a left truncation (delayed entry) time $L_i \\ge 0$, an observed exit time $T_i > 0$, an event indicator $\\Delta_i \\in \\{0,1\\}$, and a group label $G_i \\in \\{0,1\\}$. The data-generation process is assumed to be continuous-time with possibly tied event times due to measurement resolution. Right censoring occurs when $\\Delta_i = 0$. Consider the log-rank framework for comparing survival distributions between the two groups under the null hypothesis $H_0$ that the groups have equal hazard functions over time.\n\nYour task is to design and implement a complete algorithm to compute event-time risk sets with both left truncation and right censoring, and to analyze its effect on the expected event counts under $H_0$. The algorithm must be constructed from fundamental definitions and must not rely on shortcut formulas beyond first principles. Specifically:\n\n- Define the set of distinct event times $\\{t_j\\}$ as the sorted unique values of $T_i$ for which $\\Delta_i = 1$.\n- At each event time $t_j$, define the risk set $R(t_j)$ as all subjects $i$ such that $L_i  t_j \\le T_i$. This convention ensures that subjects are not at risk at their exact entry time $L_i$ and that subjects who experience the event at $t_j$ are included in the risk set at $t_j$.\n- Let $n_j = |R(t_j)|$ be the total number at risk at $t_j$, and $n_{g j} = \\sum_{i \\in R(t_j)} \\mathbb{1}(G_i = g)$ be the number at risk in group $g \\in \\{0,1\\}$ at $t_j$.\n- Let $d_j = \\sum_{i} \\mathbb{1}(\\Delta_i = 1, T_i = t_j)$ be the total number of events at time $t_j$ (accounting for ties), and $d_{g j} = \\sum_{i} \\mathbb{1}(\\Delta_i = 1, T_i = t_j, G_i = g)$ be the number of events in group $g$ at $t_j$.\n\nUnder $H_0$ (equal hazards between groups), conditioned on $n_j$ and $d_j$, the group allocation of $d_j$ events at time $t_j$ follows the sampling-without-replacement mechanism implied by equal instantaneous risk within the risk set. The expected number of events at $t_j$ in group $g$ is\n$$\n\\mathbb{E}[d_{g j} \\mid d_j, n_{g j}, n_j] \\;=\\; d_j \\cdot \\frac{n_{g j}}{n_j}.\n$$\nThe cumulative expected number of events in group $g$ across all event times is $\\sum_j d_j \\cdot (n_{g j}/n_j)$, and the log-rank score for group $0$ is\n$$\nU \\;=\\; \\sum_j \\left( d_{0 j} - d_j \\cdot \\frac{n_{0 j}}{n_j} \\right),\n$$\nwhose expectation under $H_0$ is $0$.\n\nImplement a program that, for each provided test case, computes:\n- The total expected number of events in group $0$: $\\sum_j d_j \\cdot \\frac{n_{0 j}}{n_j}$.\n- The total expected number of events in group $1$: $\\sum_j d_j \\cdot \\frac{n_{1 j}}{n_j}$.\n- The total observed number of events in group $0$: $\\sum_j d_{0 j}$.\n- The total observed number of events in group $1$: $\\sum_j d_{1 j}$.\n- The log-rank score for group $0$: $U = \\sum_j \\left( d_{0 j} - d_j \\cdot \\frac{n_{0 j}}{n_j} \\right)$.\n\nYour algorithm must:\n- Construct $R(t_j)$ using $L_i  t_j \\le T_i$ for each $t_j$.\n- Properly handle ties in event times by computing $d_j$ and $d_{g j}$ as the counts of all events at $t_j$.\n- Treat censored observations ($\\Delta_i = 0$) as contributing to the risk set only when $T_i \\ge t_j$ and not contributing any events at $t_j$.\n- Be robust when there are no events (i.e., the set $\\{t_j\\}$ is empty), in which case all expected and observed counts are $0$, and the log-rank score is $0$.\n\nDesign your solution using only the definitions and logic specified above.\n\nTest Suite:\nFor each test case, the input consists of four arrays $(L, T, \\Delta, G)$, where each array is aligned by subject index.\n\n- Test case $1$ (balanced risk sets, mixed truncation and censoring):\n  - Group $0$: $L = [0, 2]$, $T = [5, 8]$, $\\Delta = [1, 0]$, $G = [0, 0]$.\n  - Group $1$: $L = [1, 3]$, $T = [5, 7]$, $\\Delta = [1, 1]$, $G = [1, 1]$.\n  Combine the two groups into concatenated arrays for $(L, T, \\Delta, G)$.\n\n- Test case $2$ (boundary entry after an early event):\n  - Group $0$: $L = [6, 0]$, $T = [9, 5]$, $\\Delta = [1, 1]$, $G = [0, 0]$.\n  - Group $1$: $L = [0, 4]$, $T = [5, 6]$, $\\Delta = [0, 1]$, $G = [1, 1]$.\n  Concatenate arrays.\n\n- Test case $3$ (multiple concurrent events in one group with ties):\n  - Group $0$: $L = [0, 0, 0]$, $T = [10, 10, 10]$, $\\Delta = [0, 0, 0]$, $G = [0, 0, 0]$.\n  - Group $1$: $L = [0, 0, 0]$, $T = [10, 10, 10]$, $\\Delta = [1, 1, 1]$, $G = [1, 1, 1]$.\n  Concatenate arrays.\n\n- Test case $4$ (no events, all censored):\n  - Group $0$: $L = [0]$, $T = [4]$, $\\Delta = [0]$, $G = [0]$.\n  - Group $1$: $L = [1]$, $T = [3]$, $\\Delta = [0]$, $G = [1]$.\n  Concatenate arrays.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is itself a list of five numbers in the order $[E_0, E_1, O_0, O_1, U]$. Here $E_0$ and $E_1$ are floats for the total expected events in groups $0$ and $1$, $O_0$ and $O_1$ are integers for the total observed events in groups $0$ and $1$, and $U$ is a float for the log-rank score for group $0$. Express all floats rounded to $6$ decimal places. For example: $[[e_{0,1},e_{1,1},o_{0,1},o_{1,1},u_1],[e_{0,2},e_{1,2},o_{0,2},o_{1,2},u_2],\\ldots]$.", "solution": "We begin from the foundational definitions of survival analysis with left truncation and right censoring. Each subject $i$ is characterized by a delayed entry time $L_i$, an observed time $T_i$, a binary event indicator $\\Delta_i$, and a group label $G_i$. The survival process is observed only for $t$ such that $t > L_i$, meaning the subject is left truncated at $L_i$ and thus not part of the risk set before entry. If a subject is right censored, $\\Delta_i = 0$, and no event occurs at $T_i$, but the subject remains under observation and contributes to the risk set up to time $T_i$ inclusive.\n\nThe comparison of survival distributions via the log-rank test examines event counts across groups at observed event times. Under the null hypothesis $H_0$ that groups have equal hazards (instantaneous event rates), the probability that any given individual in the risk set experiences the event at an event time is uniform across the risk set, conditional on the total number of events occurring at that time (to accommodate ties).\n\nConstructing the risk sets:\n- Define distinct event times $\\{t_j\\}$ as the sorted unique values of $T_i$ for which $\\Delta_i = 1$.\n- For each event time $t_j$, define the risk set\n$$\nR(t_j) = \\{ i : L_i  t_j \\le T_i \\}.\n$$\nThis ensures a subject contributes to risk only after entering ($L_i  t_j$) and is still under observation at $t_j$ ($t_j \\le T_i$). Including $t_j \\le T_i$ incorporates subjects whose events occur precisely at $t_j$.\n\nCounting at risk and events:\n- The total number at risk at $t_j$ is\n$$\nn_j = |R(t_j)|.\n$$\n- The number at risk in group $g \\in \\{0,1\\}$ is\n$$\nn_{g j} = \\sum_{i \\in R(t_j)} \\mathbb{1}(G_i = g).\n$$\n- The total number of events at $t_j$ is\n$$\nd_j = \\sum_{i} \\mathbb{1}(\\Delta_i = 1, T_i = t_j).\n$$\n- The number of events in group $g$ at $t_j$ is\n$$\nd_{g j} = \\sum_{i} \\mathbb{1}(\\Delta_i = 1, T_i = t_j, G_i = g).\n$$\n\nDeriving expected counts under $H_0$:\nUnder $H_0$, hazards are equal between groups, implying that, within the risk set $R(t_j)$, the instantaneous risk of an event at $t_j$ does not depend on group membership. Conditional on $n_j$ and $d_j$, the allocation of $d_j$ events to the groups follows the combinatorial structure of sampling without replacement: from $n_j$ subjects at risk with $n_{0j}$ in group $0$ and $n_{1j} = n_j - n_{0j}$ in group $1$, we observe $d_j$ events at $t_j$. The distribution of $d_{0j}$ (events in group $0$) conditional on $n_j$ and $d_j$ is hypergeometric with parameters $(n_j, n_{0j}, d_j)$. The expected value of a hypergeometric random variable equals draws times success fraction, giving\n$$\n\\mathbb{E}[d_{0 j} \\mid d_j, n_{0 j}, n_j] = d_j \\cdot \\frac{n_{0 j}}{n_j}.\n$$\nSimilarly for group $1$,\n$$\n\\mathbb{E}[d_{1 j} \\mid d_j, n_{1 j}, n_j] = d_j \\cdot \\frac{n_{1 j}}{n_j}.\n$$\nSumming over all event times yields the total expected number of events per group:\n$$\nE_0 = \\sum_j d_j \\cdot \\frac{n_{0 j}}{n_j}, \\quad E_1 = \\sum_j d_j \\cdot \\frac{n_{1 j}}{n_j}.\n$$\nThe observed totals are $O_0 = \\sum_j d_{0 j}$ and $O_1 = \\sum_j d_{1 j}$. The log-rank score for group $0$ is the cumulative deviation of observed from expected:\n$$\nU = \\sum_j \\left( d_{0 j} - d_j \\cdot \\frac{n_{0 j}}{n_j} \\right).\n$$\nUnder $H_0$, $\\mathbb{E}[U] = 0$ because each term has zero expectation by the derivation above.\n\nAlgorithmic design:\n- Input: Arrays $L$, $T$, $\\Delta$, $G$.\n- Step $1$: Extract event times $t_j$ by collecting unique values of $T_i$ where $\\Delta_i = 1$ and sorting them in ascending order.\n- Step $2$: For each $t_j$:\n  - Compute the risk set mask $m_i(t_j) = \\mathbb{1}(L_i  t_j \\le T_i)$.\n  - Compute $n_j = \\sum_i m_i(t_j)$ and $n_{0 j} = \\sum_i m_i(t_j) \\cdot \\mathbb{1}(G_i = 0)$, $n_{1 j} = n_j - n_{0 j}$.\n  - Compute $d_j = \\sum_i \\mathbb{1}(\\Delta_i = 1, T_i = t_j)$ and $d_{0 j} = \\sum_i \\mathbb{1}(\\Delta_i = 1, T_i = t_j, G_i = 0)$, $d_{1 j} = d_j - d_{0 j}$.\n  - Compute expected counts $e_{0 j} = d_j \\cdot \\frac{n_{0 j}}{n_j}$ and $e_{1 j} = d_j \\cdot \\frac{n_{1 j}}{n_j}$. By construction, $n_j > 0$ at an event time, otherwise the data would be inconsistent with the risk set definition.\n- Step $3$: Aggregate totals $E_0 = \\sum_j e_{0 j}$, $E_1 = \\sum_j e_{1 j}$, $O_0 = \\sum_j d_{0 j}$, $O_1 = \\sum_j d_{1 j}$, and $U = \\sum_j (d_{0 j} - e_{0 j})$.\n- Step $4$: If there are no event times (i.e., $\\{t_j\\}$ is empty), set $E_0 = 0$, $E_1 = 0$, $O_0 = 0$, $O_1 = 0$, and $U = 0$.\n\nScientific realism and effects analysis:\n- Left truncation ($L_i$) removes subjects from the risk set at early times when $t \\le L_i$, thus reducing $n_j$ and $n_{g j}$ at those times. This shifts expected counts $d_j \\cdot (n_{g j}/n_j)$ towards the composition of subjects who have already entered, potentially changing the group fractions. Subjects entering after an early event time do not contribute to early $n_j$ and thus do not influence early expected counts.\n- Right censoring ($\\Delta_i = 0$) excludes subjects from risk sets for times $t > T_i$. If censoring occurs before an event time, the subject does not contribute to $n_j$ at that time and cannot experience an event, thereby altering $n_{g j}$ and the expected allocation at later times.\n- Tied events at a time $t_j$ are handled by $d_j$ counting all events at $t_j$. The expected allocation across groups remains $d_j \\cdot (n_{g j}/n_j)$ due to the exchangeability under $H_0$ within the risk set, matching the expectation of the hypergeometric distribution.\n- When one group has zero at risk at an event time ($n_{g j} = 0$), the expected number of events for that group at that time is $0$. Conversely, if all risk at $t_j$ is in a single group, all expected events at $t_j$ fall in that group.\n\nImplementation details:\n- Use array operations to construct masks and counts efficiently.\n- Ensure numerical robustness by checking that $n_j > 0$ at each $t_j$; in a valid survival dataset with an event at $t_j$, at least the event subjects themselves satisfy $L_i  t_j \\le T_i$, making $n_j \\ge d_j \\ge 1$.\n- Round floats to $6$ decimals in the final output string as required.\n\nThe program applies this algorithm to the four specified test cases, computing $[E_0, E_1, O_0, O_1, U]$ for each, and prints a single-line nested list aggregating the results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_logrank_expected(L, T, D, G):\n    \"\"\"\n    Compute total expected events in groups 0 and 1 under H0 (equal hazards),\n    total observed events in groups 0 and 1, and the log-rank score for group 0.\n    Risk set at time t uses L_i  t = T_i. Handles ties at event times.\n    \"\"\"\n    L = np.asarray(L, dtype=float)\n    T = np.asarray(T, dtype=float)\n    D = np.asarray(D, dtype=int)\n    G = np.asarray(G, dtype=int)\n\n    # Event times: unique T where D == 1\n    event_times = np.unique(T[D == 1])\n    # If no events, return zeros\n    if event_times.size == 0:\n        return 0.0, 0.0, 0, 0, 0.0\n\n    E0 = 0.0\n    E1 = 0.0\n    O0 = 0\n    O1 = 0\n    U0 = 0.0\n\n    for tj in event_times:\n        # Risk set mask: L  tj = T\n        risk_mask = (L  tj)  (T >= tj)\n        n_j = int(np.sum(risk_mask))\n        # Sanity: if data are consistent, n_j = 1 at an event time\n        if n_j == 0:\n            # No one at risk at an event time: set contributions to zero to avoid division by zero.\n            # This should not occur in a well-formed dataset.\n            continue\n\n        # Counts at risk per group\n        at_risk_group0 = risk_mask  (G == 0)\n        at_risk_group1 = risk_mask  (G == 1)\n        n0_j = int(np.sum(at_risk_group0))\n        n1_j = int(np.sum(at_risk_group1))\n\n        # Events at time tj\n        events_at_t = (D == 1)  (T == tj)\n        d_j = int(np.sum(events_at_t))\n        d0_j = int(np.sum(events_at_t  (G == 0)))\n        d1_j = d_j - d0_j\n\n        # Expected counts under H0\n        e0_j = d_j * (n0_j / n_j)\n        e1_j = d_j * (n1_j / n_j)\n\n        # Aggregate\n        E0 += e0_j\n        E1 += e1_j\n        O0 += d0_j\n        O1 += d1_j\n        U0 += (d0_j - e0_j)\n\n    return E0, E1, O0, O1, U0\n\ndef format_case_result(result):\n    \"\"\"\n    Format a single test case result [E0, E1, O0, O1, U0] with floats rounded to 6 decimals.\n    \"\"\"\n    E0, E1, O0, O1, U0 = result\n    return f\"[{E0:.6f},{E1:.6f},{O0},{O1},{U0:.6f}]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Test case 1: balanced risk sets, mixed truncation and censoring\n    L1 = [0, 2, 1, 3]\n    T1 = [5, 8, 5, 7]\n    D1 = [1, 0, 1, 1]\n    G1 = [0, 0, 1, 1]\n\n    # Test case 2: boundary entry after an early event\n    L2 = [6, 0, 0, 4]\n    T2 = [9, 5, 5, 6]\n    D2 = [1, 1, 0, 1]\n    G2 = [0, 0, 1, 1]\n\n    # Test case 3: multiple concurrent events (ties) in one group\n    L3 = [0, 0, 0, 0, 0, 0]\n    T3 = [10, 10, 10, 10, 10, 10]\n    D3 = [0, 0, 0, 1, 1, 1]\n    G3 = [0, 0, 0, 1, 1, 1]\n\n    # Test case 4: no events, all censored\n    L4 = [0, 1]\n    T4 = [4, 3]\n    D4 = [0, 0]\n    G4 = [0, 1]\n\n    test_cases = [\n        (L1, T1, D1, G1),\n        (L2, T2, D2, G2),\n        (L3, T3, D3, G3),\n        (L4, T4, D4, G4),\n    ]\n\n    results = []\n    for case in test_cases:\n        L, T, D, G = case\n        result = compute_logrank_expected(L, T, D, G)\n        results.append(format_case_result(result))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "4990707"}]}