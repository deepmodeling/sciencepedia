{"hands_on_practices": [{"introduction": "Mastering a statistical test begins with understanding its fundamental mechanics. This first practice exercise demystifies the log-rank test by guiding you through a step-by-step calculation of its core components for a small, hypothetical dataset. By computing the observed-minus-expected score ($U$), its variance ($V$), and the resulting standardized statistic ($Z$), you will gain a concrete understanding of how the test aggregates evidence across different event times. [@problem_id:4608348]", "problem": "An epidemiology study follows two independent cohorts, Group A and Group B, to compare time-to-event outcomes using survival analysis. Assume that at any distinct event time, conditional on the risk set composition just before that time, the allocation of observed events across groups is governed by sampling without replacement from the pooled risk set under the null hypothesis of equal hazard functions. This corresponds to a score test in the Cox Proportional Hazards (CPH) model and yields the classical log-rank test.\n\nThere are three distinct event times, with the following risk set sizes and observed numbers of events in each group at each time:\n- At time $t_1$: Group A has $10$ at risk and Group B has $10$ at risk; observed events are $1$ in Group A and $0$ in Group B.\n- At time $t_2$: Group A has $8$ at risk and Group B has $9$ at risk; observed events are $1$ in Group A and $2$ in Group B.\n- At time $t_3$: Group A has $6$ at risk and Group B has $7$ at risk; observed events are $0$ in Group A and $3$ in Group B.\n\nBetween event times, some individuals may be censored; the given risk set sizes already account for prior events and censoring.\n\nUsing the log-rank framework based on the null of equal hazards, compute the log-rank score $U$ for Group A, its variance $V$, and the standardized statistic $Z = U / \\sqrt{V}$. Justify the expected value and variance used at each event time from first principles. Round the final standardized statistic $Z$ to four significant figures. No units are required. Briefly interpret the value of $Z$ in terms of whether there is evidence of a difference in hazards between the two groups, but provide only the value of $Z$ as your final answer.", "solution": "The fundamental basis for the log-rank test is the null hypothesis of equal hazard functions across groups. Under this null, at any distinct event time $t_j$, conditional on the pooled risk set just prior to $t_j$, the $d_j$ events observed at $t_j$ are allocated across the two groups as if drawn without replacement from the $n_j$ individuals at risk. This implies a hypergeometric model for the number of events from Group A at $t_j$, denoted $O_{A,j}$, with parameters:\n- Population size $n_j = n_{A,j} + n_{B,j}$,\n- Number of “successes” (Group A at risk) $n_{A,j}$,\n- Sample size $d_j$ (number of events at $t_j$).\n\nFor a hypergeometric random variable,\n$$\n\\mathbb{E}[O_{A,j}] = d_j \\frac{n_{A,j}}{n_j},\n\\quad\n\\mathrm{Var}(O_{A,j}) = d_j \\frac{n_{A,j}}{n_j} \\left(1 - \\frac{n_{A,j}}{n_j}\\right) \\frac{n_j - d_j}{n_j - 1}.\n$$\nEquivalently,\n$$\n\\mathrm{Var}(O_{A,j}) = \\frac{d_j (n_j - d_j) n_{A,j} n_{B,j}}{n_j^2 (n_j - 1)}.\n$$\n\nThe log-rank score $U$ for Group A is the sum over event times of observed minus expected events:\n$$\nU = \\sum_{j=1}^{3} \\left(O_{A,j} - \\mathbb{E}[O_{A,j}]\\right),\n$$\nand the variance is\n$$\nV = \\sum_{j=1}^{3} \\mathrm{Var}(O_{A,j}).\n$$\nThe standardized statistic is $Z = U / \\sqrt{V}$, which is approximately standard normal by large-sample theory (Central Limit Theorem (CLT) applied to the score test in the Cox Proportional Hazards (CPH) model).\n\nWe now compute these quantities at each time.\n\nTime $t_1$:\n- Risk sets: $n_{A,1} = 10$, $n_{B,1} = 10$, $n_1 = 20$.\n- Events: $d_1 = 1$, with $O_{A,1} = 1$.\n- Expected:\n$$\n\\mathbb{E}[O_{A,1}] = d_1 \\frac{n_{A,1}}{n_1} = 1 \\cdot \\frac{10}{20} = \\frac{1}{2}.\n$$\n- Variance:\n$$\n\\mathrm{Var}(O_{A,1}) = \\frac{d_1 (n_1 - d_1) n_{A,1} n_{B,1}}{n_1^2 (n_1 - 1)} = \\frac{1 \\cdot 19 \\cdot 10 \\cdot 10}{20^2 \\cdot 19} = \\frac{1}{4}.\n$$\n- Contribution to $U$: $O_{A,1} - \\mathbb{E}[O_{A,1}] = 1 - \\frac{1}{2} = \\frac{1}{2}$.\n\nTime $t_2$:\n- Risk sets: $n_{A,2} = 8$, $n_{B,2} = 9$, $n_2 = 17$.\n- Events: $d_2 = 3$, with $O_{A,2} = 1$.\n- Expected:\n$$\n\\mathbb{E}[O_{A,2}] = d_2 \\frac{n_{A,2}}{n_2} = 3 \\cdot \\frac{8}{17} = \\frac{24}{17}.\n$$\n- Variance:\n$$\n\\mathrm{Var}(O_{A,2}) = \\frac{d_2 (n_2 - d_2) n_{A,2} n_{B,2}}{n_2^2 (n_2 - 1)} = \\frac{3 \\cdot 14 \\cdot 8 \\cdot 9}{17^2 \\cdot 16} = \\frac{3024}{4624} = \\frac{189}{289}.\n$$\n- Contribution to $U$: $O_{A,2} - \\mathbb{E}[O_{A,2}] = 1 - \\frac{24}{17} = -\\frac{7}{17}$.\n\nTime $t_3$:\n- Risk sets: $n_{A,3} = 6$, $n_{B,3} = 7$, $n_3 = 13$.\n- Events: $d_3 = 3$, with $O_{A,3} = 0$.\n- Expected:\n$$\n\\mathbb{E}[O_{A,3}] = d_3 \\frac{n_{A,3}}{n_3} = 3 \\cdot \\frac{6}{13} = \\frac{18}{13}.\n$$\n- Variance:\n$$\n\\mathrm{Var}(O_{A,3}) = \\frac{d_3 (n_3 - d_3) n_{A,3} n_{B,3}}{n_3^2 (n_3 - 1)} = \\frac{3 \\cdot 10 \\cdot 6 \\cdot 7}{13^2 \\cdot 12} = \\frac{1260}{2028} = \\frac{105}{169}.\n$$\n- Contribution to $U$: $O_{A,3} - \\mathbb{E}[O_{A,3}] = 0 - \\frac{18}{13} = -\\frac{18}{13}$.\n\nSumming across times,\n$$\nU = \\left( \\frac{1}{2} \\right) + \\left( -\\frac{7}{17} \\right) + \\left( -\\frac{18}{13} \\right)\n= \\frac{1}{2} - \\frac{7}{17} - \\frac{18}{13}\n= \\frac{221 - 182 - 612}{442}\n= -\\frac{573}{442}.\n$$\nNumerically, $U \\approx -1.2963800905$.\n\nSimilarly,\n$$\nV = \\left( \\frac{1}{4} \\right) + \\left( \\frac{189}{289} \\right) + \\left( \\frac{105}{169} \\right).\n$$\nNumerically,\n$$\n\\frac{1}{4} = 0.25,\\quad \\frac{189}{289} \\approx 0.6539792388,\\quad \\frac{105}{169} \\approx 0.6213017751,\n$$\nso\n$$\nV \\approx 0.25 + 0.6539792388 + 0.6213017751 = 1.5252810139.\n$$\nTherefore,\n$$\nZ = \\frac{U}{\\sqrt{V}} \\approx \\frac{-1.2963800905}{\\sqrt{1.5252810139}} \\approx \\frac{-1.2963800905}{1.235022672} \\approx -1.049681.\n$$\nRounded to four significant figures, $Z \\approx -1.050$.\n\nInterpretation: The standardized log-rank statistic is close to zero in magnitude (approximately $-1.05$), which under the standard normal approximation corresponds to a two-sided tail probability near $0.29$. There is no strong evidence against the null hypothesis of equal hazards between Group A and Group B based on this small dataset.\n\nOnly the value of $Z$ is required as the final answer, rounded as specified.", "answer": "$$\\boxed{-1.050}$$", "id": "4608348"}, {"introduction": "Moving from manual calculation to automated processing is a vital skill in statistical analysis. This practice challenges you to design a computational algorithm that implements the log-rank calculation, turning theoretical formulas into a practical tool for analyzing survival data. By processing several test cases, including those with tied event times and censoring, you will solidify your understanding of how risk sets and event counts are systematically handled in a real-world data structure. [@problem_id:4990751]", "problem": "Consider a clinical survival dataset consisting of independent subjects indexed by $i$ with observed follow-up time $T_i \\ge 0$, event indicator $\\delta_i \\in \\{0,1\\}$ where $\\delta_i = 1$ denotes an event and $\\delta_i = 0$ denotes right-censoring, and a categorical group label $g_i \\in \\{0,1,\\dots,G-1\\}$ for $G$ disjoint groups. Define the ordered set of distinct event times $\\{t_j\\}_{j=1}^J$ where for each $j$ there exists at least one subject with $\\delta_i = 1$ and $T_i = t_j$. For each $t_j$, define the risk set size $n_j$ as the number of subjects with $T_i \\ge t_j$, the number of events $d_j$ as the number of subjects with $\\delta_i = 1$ and $T_i = t_j$, and for each group $g \\in \\{0,1,\\dots,G-1\\}$ the group-specific risk set size $n_{gj}$ as the number of subjects with $g_i = g$ and $T_i \\ge t_j$, and the group-specific number of events $d_{gj}$ as the number of subjects with $g_i = g$, $\\delta_i = 1$, and $T_i = t_j$. Under the null hypothesis of equal hazard functions across groups, at each event time $t_j$ the expected number of events in group $g$ is given by $E_{gj} = d_j \\cdot \\frac{n_{gj}}{n_j}$. The log-rank test constructs the aggregated difference $O_g - E_g = \\sum_{j=1}^J \\left(d_{gj} - E_{gj}\\right)$ for each group $g$.\n\nYour task is to implement an algorithm that, given arrays of group labels, event indicators, and times, computes $n_j$, $d_j$, $n_{gj}$, $d_{gj}$ at each $t_j$, and returns the aggregated $O_g - E_g$ for each group $g$ across all $j \\in \\{1,\\dots,J\\}$. The algorithm must treat ties as follows: if multiple events occur at the same time $t_j$, then $d_j$ equals the number of events at $t_j$; if censoring occurs at time $t_j$, censored subjects are included in the risk set at $t_j$ because they satisfy $T_i \\ge t_j$, but they do not contribute to $d_j$. Subjects who experience events or are censored at $t_j$ are included in the risk set at $t_j$ when computing $n_j$ and $n_{gj}$.\n\nUse the following test suite, where the time unit is months (units are provided for context, but your outputs are dimensionless counts or differences and therefore do not require unit specification):\n\n- Test case $1$ (two groups, mixed events and censoring with ties and censoring at the same event time):\n  - Times $\\mathbf{t} = (5,8,12,12,15,17,20,22,22,25)$\n  - Events $\\boldsymbol{\\delta} = (1,0,1,1,0,1,0,1,0,1)$\n  - Groups $\\mathbf{g} = (0,0,1,1,0,1,0,1,0,0)$\n\n- Test case $2$ (boundary case: no events, all censored):\n  - Times $\\mathbf{t} = (3,7,10,12)$\n  - Events $\\boldsymbol{\\delta} = (0,0,0,0)$\n  - Groups $\\mathbf{g} = (0,1,0,1)$\n\n- Test case $3$ (one group has no events but is at risk):\n  - Times $\\mathbf{t} = (4,7,9,12,15,18)$\n  - Events $\\boldsymbol{\\delta} = (1,1,1,0,0,0)$\n  - Groups $\\mathbf{g} = (0,0,0,1,1,1)$\n\n- Test case $4$ (three groups with multiple ties and mixed censoring):\n  - Times $\\mathbf{t} = (2,2,5,5,5,8,10,10,10,12)$\n  - Events $\\boldsymbol{\\delta} = (1,0,1,1,0,0,1,0,1,0)$\n  - Groups $\\mathbf{g} = (0,1,0,1,2,2,0,1,2,2)$\n\nYour program must compute, for each test case, the vector of aggregated differences $\\left(O_g - E_g\\right)$ for all groups $g$, ordered by increasing group label. The final output must aggregate the results of all test cases into a single line as a comma-separated list enclosed in square brackets, where each entry is the result vector for one test case. For example, the output format should be $[ \\text{result}_1, \\text{result}_2, \\text{result}_3, \\text{result}_4 ]$ with each $\\text{result}_k$ itself represented as a list in standard programming notation. The outputs must be real numbers (floats), and no other units or symbols should be printed.", "solution": "The task is to compute the aggregated observed-minus-expected event count, $O_g - E_g$, for each group $g$ in a survival dataset, a core component of the log-rank test. The log-rank test is a hypothesis test used to compare the survival distributions of two or more groups. It operates under the null hypothesis $H_0$ that there is no difference in the hazard functions (and thus survival functions) between the groups.\n\nThe fundamental principle is to perform a comparison at each distinct time an event occurs. At each such time, $t_j$, we tabulate the number of subjects at risk of an event and the number of subjects who actually experience an event, stratified by group. Under $H_0$, the events that occur at $t_j$ should be distributed among the groups in proportion to their respective sizes within the risk set at that moment. The test statistic aggregates the deviations from this expectation across all event times.\n\nThe algorithm proceeds as follows:\n\n1.  **Identify Distinct Event Times**: First, we must identify the unique time points $\\{t_j\\}_{j=1}^J$ where at least one event ($\\delta_i=1$) occurred. Censoring times that do not coincide with an event time are not used to form the set $\\{t_j\\}$. The set is sorted in ascending order. If no events occur in the dataset, this set is empty, and the calculation terminates with all $O_g - E_g$ values equal to $0$.\n\n2.  **Initialize Aggregators**: We initialize a vector of accumulators for the $O_g - E_g$ values, one for each group $g \\in \\{0, 1, \\dots, G-1\\}$, to zero. Let this vector be denoted by $\\mathbf{S}$.\n\n3.  **Iterate Through Event Times**: For each distinct event time $t_j$ in the sorted set from Step 1:\n    a.  **Determine the Risk Set**: The risk set at time $t_j$ consists of all subjects $i$ who have not yet experienced an event or been censored prior to $t_j$. This is equivalent to finding all subjects with an observed time $T_i \\ge t_j$. The total number of individuals in this set is $n_j$.\n    b.  **Count Events**: The total number of events occurring at time $t_j$ is counted. This is the number of subjects $i$ with $T_i=t_j$ and $\\delta_i=1$. This count is denoted $d_j$.\n    c.  **Stratify by Group**: For each group $g$:\n        i.  Count the number of subjects from group $g$ in the risk set. This is $n_{gj}$, the count of subjects with $g_i=g$ and $T_i \\ge t_j$.\n        ii. Count the number of subjects from group $g$ who experience an event at time $t_j$. This is the observed count $d_{gj}$, which is the number of subjects with $g_i=g$, $T_i=t_j$, and $\\delta_i=1$.\n    d.  **Calculate Expected Events**: For each group $g$, the expected number of events under the null hypothesis is calculated using the formula $E_{gj} = d_j \\cdot \\frac{n_{gj}}{n_j}$. This formula assumes that from the $n_j$ subjects at risk, the $d_j$ events are drawn without replacement, and the probability of any given subject experiencing an event is equal regardless of group.\n    e.  **Update Aggregators**: For each group $g$, the difference $d_{gj} - E_{gj}$ is calculated and added to the corresponding accumulator in the vector $\\mathbf{S}$. That is, $S_g \\leftarrow S_g + (d_{gj} - E_{gj})$.\n\n4.  **Final Result**: After iterating through all unique event times, the vector $\\mathbf{S}$ contains the final aggregated values $\\left(O_g - E_g\\right)$ for each group $g$. A property of this calculation is that the sum of the components must be zero, i.e., $\\sum_{g=0}^{G-1} (O_g - E_g) = 0$, because at each time $t_j$, $\\sum_g d_{gj} = d_j$ and $\\sum_g E_{gj} = \\sum_g d_j \\frac{n_{gj}}{n_j} = \\frac{d_j}{n_j} \\sum_g n_{gj} = \\frac{d_j}{n_j} n_j = d_j$. This serves as a useful consistency check.\n\nThis procedure correctly handles ties in event times (by counting all events at $t_j$ in $d_j$) and censoring at event times (by including such subjects in the risk set $n_j$ but not in the event count $d_j$), as specified by the problem statement.", "answer": "[[-1.8666666666666667, 1.8666666666666667], [0.0, 0.0], [1.85, -1.85], [1.7, -0.3, -1.4]]", "id": "4990751"}, {"introduction": "A powerful statistical test is only as good as the assumptions it rests upon. This final exercise shifts from calculation to critical thinking, exploring a scenario where the proportional hazards assumption—central to the log-rank test's optimality—is violated. By analyzing a case of crossing hazard functions, you will discover how the unweighted nature of the log-rank statistic can lead to a loss of power, providing insight into the test's limitations. [@problem_id:4990713]", "problem": "A two-arm randomized clinical trial compares a novel therapy (group $1$) with standard care (group $2$). Let $S_1(t)$ and $S_2(t)$ denote the survival functions, and suppose the hazard functions $h_1(t)$ and $h_2(t)$ cross exactly once at time $t^\\star$, with $h_1(t) < h_2(t)$ for $t < t^\\star$ and $h_1(t) > h_2(t)$ for $t > t^\\star$. Consider the log-rank test, which compares the observed and expected number of events in group $1$ across distinct event times under the null hypothesis of equal hazards. At each distinct event time $t_j$, let $O_1(t_j)$ be the observed number of events in group $1$ and $E_1(t_j)$ be the expected number of events in group $1$ under the null, computed conditional on the risk set at $t_j$. The log-rank numerator is the unweighted sum $\\sum_j \\{O_1(t_j) - E_1(t_j)\\}$ over all distinct event times.\n\nTo make concrete the qualitative behavior around the crossing, suppose there are two sets of tied event times arising from discretized assessment schedules:\n- An early tied set at time $t_E < t^\\star$ with total events $d_E$ among a risk set of sizes $n_{1E}$ in group $1$ and $n_{2E}$ in group $2$, where the observed event count in group $1$ is $d_{1E}$.\n- A late tied set at time $t_L > t^\\star$ with total events $d_L$ among a risk set of sizes $n_{1L}$ in group $1$ and $n_{2L}$ in group $2$, where the observed event count in group $1$ is $d_{1L}$.\n\nAssume the following plausible values at the starts of these tied sets: $n_{1E} = 95$, $n_{2E} = 95$, $d_E = 20$, $d_{1E} = 7$; and $n_{1L} = 70$, $n_{2L} = 60$, $d_L = 25$, $d_{1L} = 16$. No additional events occur outside these tied sets. Under the null hypothesis of equal hazards, events within a tied set are exchangeable across individuals in the risk set.\n\nWhich statement best characterizes the sign pattern of $O_1(t_j) - E_1(t_j)$ across time and the consequence for the unweighted log-rank numerator $\\sum_j \\{O_1(t_j) - E_1(t_j)\\}$ in this crossing-hazards scenario?\n\nA. Because $h_1(t) < h_2(t)$ for $t < t^\\star$ and $h_1(t) > h_2(t)$ for $t > t^\\star$, the early contributions $O_1(t_j) - E_1(t_j)$ tend to be negative and the late contributions tend to be positive, leading to cancellation in the unweighted sum and a reduced magnitude of the overall test statistic.\n\nB. Because $h_1(t) < h_2(t)$ for $t < t^\\star$ and $h_1(t) > h_2(t)$ for $t > t^\\star$, the early contributions $O_1(t_j) - E_1(t_j)$ tend to be positive and the late contributions tend to be negative, leading to reinforcement in the unweighted sum and an increased magnitude of the overall test statistic.\n\nC. Differences in risk set sizes across time imply that late contributions necessarily dominate, so cancellation of early and late contributions cannot occur when hazards cross once.\n\nD. The log-rank test automatically reweights time periods to neutralize the effect of a single crossing, so the unweighted sum is unaffected by sign changes across time and the test retains full sensitivity.", "solution": "The core of the problem is to understand the sign of the contribution to the log-rank statistic, $O_1(t_j) - E_1(t_j)$, at different time points when the hazard functions cross. The log-rank test's numerator is the unweighted sum of these contributions. The expected number of events in group 1, $E_1(t_j)$, is calculated under the null hypothesis of equal hazards ($h_1(t) = h_2(t)$) as $E_1(t_j) = d_j \\frac{n_{1j}}{n_{1j} + n_{2j}}$, where $d_j$ is the total number of events at time $t_j$ and $n_{1j}, n_{2j}$ are the number of subjects at risk in each group.\n\n**1. Analysis at the Early Time Point ($t_E < t^\\star$):**\nAt this time, the true hazard for group 1 is lower than for group 2 ($h_1(t) < h_2(t)$). We would therefore expect to observe *fewer* events in group 1 than predicted by the null hypothesis. Let's verify with the data:\n- Observed events in group 1: $O_1(t_E) = d_{1E} = 7$.\n- Total events $d_E = 20$. Risk set sizes $n_{1E} = 95, n_{2E} = 95$.\n- Expected events in group 1: $E_1(t_E) = 20 \\times \\frac{95}{95 + 95} = 20 \\times 0.5 = 10$.\n- The contribution to the statistic is $O_1(t_E) - E_1(t_E) = 7 - 10 = -3$. This contribution is negative, as expected.\n\n**2. Analysis at the Late Time Point ($t_L > t^\\star$):**\nAt this time, the true hazard for group 1 is now *higher* than for group 2 ($h_1(t) > h_2(t)$). We would expect to observe *more* events in group 1 than predicted by the null hypothesis.\n- Observed events in group 1: $O_1(t_L) = d_{1L} = 16$.\n- Total events $d_L = 25$. Risk set sizes $n_{1L} = 70, n_{2L} = 60$.\n- Expected events in group 1: $E_1(t_L) = 25 \\times \\frac{70}{70 + 60} = 25 \\times \\frac{70}{130} \\approx 13.46$.\n- The contribution to the statistic is $O_1(t_L) - E_1(t_L) = 16 - 13.46 \\approx +2.54$. This contribution is positive, as expected.\n\n**Conclusion:**\nThe standard (unweighted) log-rank test simply sums these contributions: $\\sum_j (O_1(t_j) - E_1(t_j)) \\approx -3 + 2.54 = -0.46$. The negative contribution from the early period and the positive contribution from the late period partially cancel each other out. This leads to a test statistic with a small magnitude, which reduces the test's power to detect a real, but non-proportional, difference in survival. Option A accurately describes this phenomenon. The other options are incorrect: B has the signs reversed, C makes false claims about late contributions dominating, and D incorrectly suggests the unweighted test can adapt to crossing hazards.", "answer": "$$\\boxed{A}$$", "id": "4990713"}]}