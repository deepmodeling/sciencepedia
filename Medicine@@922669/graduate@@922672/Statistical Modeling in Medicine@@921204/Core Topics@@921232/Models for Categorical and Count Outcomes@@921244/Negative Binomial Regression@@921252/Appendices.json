{"hands_on_practices": [{"introduction": "Before fitting any complex model, a crucial first step is to assess whether the assumptions of simpler models, like the Poisson, are met. In medical count data, a common finding is overdispersion, where the variance in the data is greater than the mean, violating a key assumption of the Poisson distribution. This first exercise provides a hands-on method for diagnosing and quantifying overdispersion using fundamental sample statistics. By deriving an estimator for the dispersion parameter and calculating the inflation of standard errors, you will gain a clear, quantitative understanding of why ignoring overdispersion can lead to erroneous conclusions about statistical significance.", "problem": "A hospital-based cohort study tracks the number of acute exacerbations of chronic obstructive pulmonary disease (COPD) per patient-year. Let $Y_{i}$ denote the count for patient $i$. The sample mean and sample variance across $n$ patients are observed to be $\\bar{y}=2.4$ and $s^{2}=7.8$, respectively. Starting from the fundamental definition of equidispersion under the Poisson model, where $\\operatorname{Var}(Y)=\\mathbb{E}[Y]$, and the well-tested variance structure of the Negative Binomial model with quadratic mean function (NB2), where $\\operatorname{Var}(Y)=\\mu+\\alpha \\mu^{2}$ with $\\mu=\\mathbb{E}[Y]$ and $\\alpha>0$ indicating overdispersion, proceed as follows:\n\n- Define a principled measure of departure from equidispersion based on $\\bar{y}$ and $s^{2}$, and derive the corresponding method-of-moments estimator for the NB2 overdispersion parameter $\\alpha$ using the NB2 variance structure.\n- Using the framework of Generalized Linear Models (GLM), deduce how misspecification of equidispersion affects the asymptotic standard errors of Poisson regression coefficients when the true variance at the observed mean follows the NB2 form, and identify the implied multiplicative inflation factor for those standard errors at $\\mu=\\bar{y}$.\n\nReport the final multiplicative inflation factor as a single real number. Round your final answer to four significant figures. Do not include any units in your final answer.", "solution": "The solution is developed in two parts as requested by the problem statement.\n\n**Part 1: Method-of-Moments Estimator for the Overdispersion Parameter $\\alpha$**\n\nThe Poisson model is characterized by equidispersion, where the variance of the random variable is equal to its expectation: $\\operatorname{Var}(Y) = \\mathbb{E}[Y]$. An immediate sign of departure from this assumption is when the sample variance $s^2$ is markedly different from the sample mean $\\bar{y}$. In this problem, we are given $\\bar{y} = 2.4$ and $s^2 = 7.8$. Since $s^2 > \\bar{y}$, the data exhibit overdispersion.\n\nThe Negative Binomial model with a quadratic variance function (NB2) provides a parametric form for this overdispersion. The variance is given by $\\operatorname{Var}(Y) = \\mu + \\alpha \\mu^2$, where $\\mu = \\mathbb{E}[Y]$ and $\\alpha$ is the overdispersion parameter. When $\\alpha=0$, the NB2 variance reduces to the Poisson variance. Thus, $\\alpha$ serves as a natural measure of departure from equidispersion.\n\nTo derive the method-of-moments (MoM) estimator for $\\alpha$, we equate the population moments to their corresponding sample-based estimators.\nThe first population moment is the mean, $\\mu = \\mathbb{E}[Y]$. Its MoM estimator is the sample mean, $\\hat{\\mu} = \\bar{y}$.\nThe second central population moment is the variance, $\\operatorname{Var}(Y)$. Its MoM estimator is the sample variance, $s^2$.\n\nWe substitute these estimators into the NB2 variance equation:\n$$s^2 = \\hat{\\mu} + \\hat{\\alpha} \\hat{\\mu}^2$$\nReplacing $\\hat{\\mu}$ with $\\bar{y}$, we get an equation for the MoM estimator $\\hat{\\alpha}$:\n$$s^2 = \\bar{y} + \\hat{\\alpha} \\bar{y}^2$$\nSolving for $\\hat{\\alpha}$:\n$$\\hat{\\alpha} \\bar{y}^2 = s^2 - \\bar{y}$$\n$$\\hat{\\alpha} = \\frac{s^2 - \\bar{y}}{\\bar{y}^2}$$\nThis is the method-of-moments estimator for the NB2 overdispersion parameter $\\alpha$.\n\n**Part 2: Multiplicative Inflation Factor for Standard Errors**\n\nWe consider a scenario where a Poisson regression model is incorrectly fitted to data that are truly generated from a Negative Binomial process. This is a case of a misspecified variance function in a Generalized Linear Model (GLM). We need to determine the effect on the standard errors of the estimated regression coefficients, $\\hat{\\boldsymbol{\\beta}}$.\n\nIn a GLM, the asymptotic covariance matrix of $\\hat{\\boldsymbol{\\beta}}$ is given by the sandwich estimator, which remains consistent even when the variance function is misspecified. For a Poisson model with the canonical log link, $\\ln(\\mu_i) = \\mathbf{x}_i^T \\boldsymbol{\\beta}$, the naive or model-based covariance matrix is $\\operatorname{Cov}_{\\text{naive}}(\\hat{\\boldsymbol{\\beta}}) = (\\sum_i \\mathbf{x}_i \\mathbf{x}_i^T \\mu_i)^{-1}$. The true (robust) covariance is given by $\\operatorname{Cov}_{\\text{true}}(\\hat{\\boldsymbol{\\beta}}) = \\operatorname{Cov}_{\\text{naive}}(\\hat{\\boldsymbol{\\beta}}) (\\sum_i \\mathbf{x}_i \\mathbf{x}_i^T \\operatorname{Var}_{\\text{true}}(Y_i)) \\operatorname{Cov}_{\\text{naive}}(\\hat{\\boldsymbol{\\beta}})$.\n\nThe ratio of the true variance to the assumed Poisson variance is the dispersion factor, $\\phi_i$:\n$$\\phi_i = \\frac{\\operatorname{Var}_{\\text{true}}(Y_i)}{\\operatorname{Var}_{\\text{Poisson}}(Y_i)} = \\frac{\\mu_i + \\alpha \\mu_i^2}{\\mu_i} = 1 + \\alpha \\mu_i$$\nIf we assume this dispersion factor is approximately constant across all observations, $\\phi_i \\approx \\phi$, the true covariance matrix simplifies to $\\operatorname{Cov}_{\\text{true}}(\\hat{\\boldsymbol{\\beta}}) \\approx \\phi \\operatorname{Cov}_{\\text{naive}}(\\hat{\\boldsymbol{\\beta}})$. This shows that the true variances of the regression coefficients are inflated by the factor $\\phi$ compared to the naively estimated variances. Consequently, the standard errors, which are the square roots of the variances, are inflated by a factor of $\\sqrt{\\phi}$.\n\nThe problem asks for this inflation factor evaluated at the observed mean, $\\mu = \\bar{y}$. We can estimate the dispersion factor $\\phi$ using the sample moments:\n$$\\hat{\\phi} = 1 + \\hat{\\alpha} \\bar{y}$$\nSubstituting our MoM estimator for $\\hat{\\alpha}$:\n$$\\hat{\\phi} = 1 + \\left(\\frac{s^2 - \\bar{y}}{\\bar{y}^2}\\right) \\bar{y} = 1 + \\frac{s^2 - \\bar{y}}{\\bar{y}} = \\frac{\\bar{y} + s^2 - \\bar{y}}{\\bar{y}} = \\frac{s^2}{\\bar{y}}$$\nThis provides a direct and intuitive estimator for the dispersion parameter: the ratio of the sample variance to the sample mean.\n\nUsing the given data, we calculate the estimated dispersion factor:\n$$\\hat{\\phi} = \\frac{s^2}{\\bar{y}} = \\frac{7.8}{2.4} = 3.25$$\nThe multiplicative inflation factor for the standard errors is the square root of this value:\n$$\\text{Inflation Factor} = \\sqrt{\\hat{\\phi}} = \\sqrt{3.25}$$\nCalculating the numerical value:\n$$\\sqrt{3.25} \\approx 1.8027756...$$\nRounding to four significant figures, we get $1.803$. This is the factor by which the standard errors from a Poisson regression would need to be multiplied to correct for the observed level of overdispersion.", "answer": "$$\\boxed{1.803}$$", "id": "4822241"}, {"introduction": "Having established that overdispersion invalidates the standard Poisson model, we now turn to understanding the structure of the Negative Binomial (NB) model. One of its most powerful features is its ability to naturally accommodate the extra variability often seen in real-world count data. This practice guides you through the theoretical foundation of the NB distribution as a Poisson-Gamma mixture. By deriving the probability of observing zero events, you will see how the NB model intrinsically predicts a higher frequency of zeros compared to a Poisson model with the same mean, providing a vital tool for accurately modeling phenomena like the absence of adverse events or disease symptoms.", "problem": "A hospital-based pharmacovigilance study models the annual count of emergency department visits attributed to adverse drug reactions for individual patients. To account for overdispersion due to unobserved heterogeneity, analysts fit a negative binomial (NB) regression using the parameterization in which the conditional mean is $\\mu$ and the variance is $\\mu + \\alpha \\mu^{2}$, where $\\alpha > 0$ is the overdispersion parameter. For a specific patient, the fitted model yields $\\mu = 0.8$ and $\\alpha = 0.4$. To assess how overdispersion affects the predicted probability of zero events, proceed from first principles:\n\n- Use the characterization of the NB model as a Poisson–Gamma mixture, where the count $Y$ given the latent rate $\\lambda$ follows a Poisson distribution with mean $\\lambda$, and $\\lambda$ follows a Gamma distribution chosen so that the unconditional mean of $Y$ is $\\mu$ and the unconditional variance is $\\mu + \\alpha \\mu^{2}$.\n- Derive an analytic expression for the NB model’s predicted probability of zero events, $P_{\\mathrm{NB}}(Y=0)$, as a function of $\\mu$ and $\\alpha$, without invoking any shortcut formulas.\n- Using the Poisson model with mean $\\mu$, derive the predicted probability of zero events, $P_{\\mathrm{Pois}}(Y=0)$.\n\nDefine the comparison metric as the ratio $R = \\dfrac{P_{\\mathrm{NB}}(Y=0)}{P_{\\mathrm{Pois}}(Y=0)}$. Compute $R$ for $\\mu = 0.8$ and $\\alpha = 0.4$. Express the final answer as a decimal number and round your answer to four significant figures.", "solution": "The problem asks for a comparison of the probability of observing zero events, $P(Y=0)$, under a Negative Binomial (NB) model and a standard Poisson model. The NB distribution is derived from a Poisson-Gamma mixture.\n\nFirst, we determine the parameters of the Gamma distribution for the latent rate $\\lambda$. Let the count $Y$ conditional on $\\lambda$ follow a Poisson distribution: $Y | \\lambda \\sim \\mathrm{Poisson}(\\lambda)$. The latent rate $\\lambda$ is assumed to follow a Gamma distribution, which we parameterize by shape $k$ and scale $\\theta$, so $\\lambda \\sim \\mathrm{Gamma}(k, \\theta)$. The moments of this Gamma distribution are $E[\\lambda] = k\\theta$ and $\\mathrm{Var}(\\lambda) = k\\theta^2$.\n\nThe unconditional moments of $Y$ are found using the laws of total expectation and variance:\n$$ E[Y] = E[E[Y|\\lambda]] = E[\\lambda] = k\\theta $$\n$$ \\mathrm{Var}(Y) = E[\\mathrm{Var}(Y|\\lambda)] + \\mathrm{Var}(E[Y|\\lambda]) = E[\\lambda] + \\mathrm{Var}(\\lambda) = k\\theta + k\\theta^2 $$\nThe problem states that the unconditional mean is $E[Y] = \\mu$ and the variance is $\\mathrm{Var}(Y) = \\mu + \\alpha\\mu^2$. Equating the moments gives us a system of equations:\n1. $\\mu = k\\theta$\n2. $\\mu + \\alpha\\mu^2 = k\\theta + k\\theta^2$\n\nSubstituting (1) into (2) yields $\\alpha\\mu^2 = k\\theta^2$. Dividing this by the square of equation (1) gives $\\frac{k\\theta^2}{(k\\theta)^2} = \\frac{\\alpha\\mu^2}{\\mu^2}$, which simplifies to $1/k = \\alpha$. Thus, the shape parameter is $k = 1/\\alpha$. Substituting this back into (1) gives $\\mu = (1/\\alpha)\\theta$, so the scale parameter is $\\theta = \\alpha\\mu$. The latent rate $\\lambda$ follows a $\\mathrm{Gamma}(k=1/\\alpha, \\theta=\\alpha\\mu)$ distribution.\n\nNext, we derive the probability of zero events for the NB model, $P_{\\mathrm{NB}}(Y=0)$, by marginalizing the conditional probability $P(Y=0|\\lambda) = e^{-\\lambda}$ over the distribution of $\\lambda$:\n$$ P_{\\mathrm{NB}}(Y=0) = \\int_0^\\infty P(Y=0|\\lambda) f(\\lambda; k, \\theta) d\\lambda = \\int_0^\\infty e^{-\\lambda} \\left( \\frac{\\lambda^{k-1} e^{-\\lambda/\\theta}}{\\theta^k \\Gamma(k)} \\right) d\\lambda $$\n$$ P_{\\mathrm{NB}}(Y=0) = \\frac{1}{\\theta^k \\Gamma(k)} \\int_0^\\infty \\lambda^{k-1} e^{-\\lambda(1 + 1/\\theta)} d\\lambda = \\frac{1}{\\theta^k \\Gamma(k)} \\int_0^\\infty \\lambda^{k-1} e^{-\\lambda \\left(\\frac{\\theta+1}{\\theta}\\right)} d\\lambda $$\nThe integral is the kernel of a Gamma distribution with shape $k$ and scale $\\theta' = \\frac{\\theta}{\\theta+1}$. Its value is $(\\theta')^k \\Gamma(k) = \\left(\\frac{\\theta}{\\theta+1}\\right)^k \\Gamma(k)$.\nSubstituting this back, we get:\n$$ P_{\\mathrm{NB}}(Y=0) = \\frac{1}{\\theta^k \\Gamma(k)} \\left[ \\left(\\frac{\\theta}{\\theta+1}\\right)^k \\Gamma(k) \\right] = \\left(\\frac{1}{\\theta+1}\\right)^k $$\nNow, substituting the expressions for $k$ and $\\theta$ in terms of $\\mu$ and $\\alpha$:\n$$ P_{\\mathrm{NB}}(Y=0) = \\left(\\frac{1}{\\alpha\\mu + 1}\\right)^{1/\\alpha} = (1+\\alpha\\mu)^{-1/\\alpha} $$\n\nFor the Poisson model with mean $\\mu$, the probability of zero events is:\n$$ P_{\\mathrm{Pois}}(Y=0) = \\frac{\\mu^0 e^{-\\mu}}{0!} = e^{-\\mu} $$\n\nThe comparison ratio is $R = \\dfrac{P_{\\mathrm{NB}}(Y=0)}{P_{\\mathrm{Pois}}(Y=0)}$.\n$$ R = \\frac{(1+\\alpha\\mu)^{-1/\\alpha}}{\\exp(-\\mu)} = \\frac{\\exp(\\mu)}{(1+\\alpha\\mu)^{1/\\alpha}} $$\n\nFinally, we compute $R$ for $\\mu = 0.8$ and $\\alpha = 0.4$:\n$$ R = \\frac{\\exp(0.8)}{\\left(1 + (0.4)(0.8)\\right)^{1/0.4}} = \\frac{\\exp(0.8)}{(1.32)^{2.5}} $$\nNumerically:\n$$ \\exp(0.8) \\approx 2.2255409 $$\n$$ (1.32)^{2.5} \\approx 2.0018804 $$\n$$ R \\approx \\frac{2.2255409}{2.0018804} \\approx 1.11172605 $$\nRounding to four significant figures gives $1.112$.", "answer": "$$\\boxed{1.112}$$", "id": "4822214"}, {"introduction": "The ultimate goal of statistical modeling in medicine is not just to fit a model, but to extract clinically meaningful insights that can inform practice and policy. While a Negative Binomial regression provides a relative measure of effect, the Incidence Rate Ratio (IRR), clinicians often need to understand the absolute impact of an intervention. This final exercise challenges you to translate a model's statistical output into a practically relevant quantity: the absolute reduction in events. This practice is essential for effective communication of research findings and also introduces the critical concept of variance propagation via the Delta method, allowing you to properly quantify the uncertainty of your derived conclusions.", "problem": "A multicenter randomized trial in clinical infectious disease compared a prophylactic intervention with standard care. The primary outcome was the count of infection events per person-time, with variable follow-up across participants. Exploratory analysis showed overdispersion relative to the Poisson model, so the analysis used a Negative Binomial regression with a logarithmic link and an offset for person-time, reporting an incidence rate ratio (IRR) for the intervention versus control. Suppose the fitted model yielded an IRR of 0.75 for the intervention. In the standard care group, the observed baseline rate of infection was 4 events per $100$ person-years.\n\nUsing only the definitions of an incidence rate, the meaning of an incidence rate ratio, and the interpretation of a logarithmic-link Negative Binomial model with a person-time offset, translate the reported IRR into the absolute reduction in expected events per $100$ person-years at this baseline rate. Provide the point estimate only. Express your final numeric answer in units of events per $100$ person-years, and round to two significant figures.\n\nAdditionally, justify—starting from first principles—how one would obtain uncertainty on this absolute scale from the Negative Binomial fit under large-sample theory, identifying the relevant parameter transformation and variance propagation approach. You do not need to compute a numerical interval; provide only the reasoning steps and the mathematical form of the transformation involved. Your final numeric answer should consist solely of the point estimate requested above.", "solution": "The problem requires two parts: first, the calculation of a point estimate for the absolute reduction in expected infection events, and second, a justification of the method for obtaining an uncertainty interval for this estimate.\n\n**Part 1: Calculation of the Point Estimate**\n\nAn incidence rate, $\\lambda$, is the expected number of events per unit of time. The model is a Negative Binomial regression with a log link, so the rate for a group is modeled as $\\lambda = \\exp(\\mathbf{X} \\boldsymbol{\\beta})$. In this trial with a control group and an intervention group, the rates are $\\lambda_{\\text{control}}$ and $\\lambda_{\\text{int}}$.\n\nThe Incidence Rate Ratio (IRR) is the ratio of the incidence rates:\n$$ \\text{IRR} = \\frac{\\lambda_{\\text{int}}}{\\lambda_{\\text{control}}} $$\nThe problem provides the following givens:\n1.  The baseline rate in the standard care group is $\\lambda_{\\text{control}} = 4$ events per $100$ person-years.\n2.  The fitted model yields an IRR of $0.75$.\n\nUsing these values, we can find the estimated expected rate in the intervention group:\n$$ \\hat{\\lambda}_{\\text{int}} = \\hat{\\lambda}_{\\text{control}} \\times \\text{IRR} $$\n$$ \\hat{\\lambda}_{\\text{int}} = (4 \\text{ events per } 100 \\text{ person-years}) \\times 0.75 = 3 \\text{ events per } 100 \\text{ person-years} $$\nThe absolute reduction in expected events is the Absolute Rate Reduction (ARR), which is the difference between the rates:\n$$ \\text{ARR} = \\lambda_{\\text{control}} - \\lambda_{\\text{int}} $$\nSubstituting the estimated values:\n$$ \\widehat{\\text{ARR}} = \\hat{\\lambda}_{\\text{control}} - \\hat{\\lambda}_{\\text{int}} = 4 - 3 = 1 $$\nThe units are events per $100$ person-years. The problem requires rounding to two significant figures. The number $1$ is therefore expressed as $1.0$.\n\n**Part 2: Justification for Uncertainty Estimation**\n\nTo obtain the uncertainty (e.g., a confidence interval) for the ARR, one must propagate the uncertainty from the estimated model coefficients, $\\hat{\\beta}_0$ and $\\hat{\\beta}_1$, to the derived quantity $\\widehat{\\text{ARR}}$. The ARR is a function of the model parameters. Let the model for the log-rate be $\\ln(\\lambda_i) = \\beta_0 + \\beta_1 Z_i$, where $Z_i=0$ for control and $Z_i=1$ for intervention.\nThen $\\lambda_{\\text{control}} = \\exp(\\beta_0)$ and $\\lambda_{\\text{int}} = \\exp(\\beta_0 + \\beta_1)$.\nThe ARR is:\n$$ \\text{ARR}(\\beta_0, \\beta_1) = \\exp(\\beta_0) - \\exp(\\beta_0 + \\beta_1) $$\nThe justification for estimating uncertainty proceeds from these first principles:\n\n1.  **Asymptotic Normality of Estimators**: The Negative Binomial regression coefficients $(\\hat{\\beta}_0, \\hat{\\beta}_1)$ are maximum likelihood estimators. For a large sample, the vector of estimators $(\\hat{\\beta}_0, \\hat{\\beta}_1)^T$ is asymptotically multivariate normal with mean $(\\beta_0, \\beta_1)^T$ and a variance-covariance matrix, $\\boldsymbol{\\Sigma}_{\\hat{\\beta}}$, which is a standard output from statistical software:\n    $$ \\hat{\\boldsymbol{\\Sigma}}_{\\hat{\\beta}} = \\begin{pmatrix} \\widehat{\\text{Var}}(\\hat{\\beta}_0) & \\widehat{\\text{Cov}}(\\hat{\\beta}_0, \\hat{\\beta}_1) \\\\ \\widehat{\\text{Cov}}(\\hat{\\beta}_0, \\hat{\\beta}_1) & \\widehat{\\text{Var}}(\\hat{\\beta}_1) \\end{pmatrix} $$\n\n2.  **Parameter Transformation and the Delta Method**: Since ARR is a non-linear function of $\\beta_0$ and $\\beta_1$, we use the Delta method to find the variance of the estimated ARR, $\\widehat{\\text{ARR}} = \\text{ARR}(\\hat{\\beta}_0, \\hat{\\beta}_1)$. The Delta method provides a first-order Taylor series approximation for the variance of a function of asymptotically normal random variables. The general formula for the variance of a transformed parameter $g(\\boldsymbol{\\beta})$ is $\\text{Var}(\\widehat{g(\\boldsymbol{\\beta})}) \\approx (\\nabla g)^T \\boldsymbol{\\Sigma}_{\\hat{\\beta}} (\\nabla g)$, where $\\nabla g$ is the gradient of the function $g$.\n\n3.  **Derivation of the Variance of ARR**: Let $g(\\beta_0, \\beta_1) = \\text{ARR}(\\beta_0, \\beta_1)$. We compute the gradient of this function:\n    $$ \\nabla g = \\begin{pmatrix} \\frac{\\partial g}{\\partial \\beta_0} \\\\ \\frac{\\partial g}{\\partial \\beta_1} \\end{pmatrix} $$\n    The partial derivatives are:\n    $$ \\frac{\\partial g}{\\partial \\beta_0} = \\frac{\\partial}{\\partial \\beta_0} \\left( \\exp(\\beta_0) - \\exp(\\beta_0 + \\beta_1) \\right) = \\exp(\\beta_0) - \\exp(\\beta_0 + \\beta_1) = \\text{ARR} $$\n    $$ \\frac{\\partial g}{\\partial \\beta_1} = \\frac{\\partial}{\\partial \\beta_1} \\left( \\exp(\\beta_0) - \\exp(\\beta_0 + \\beta_1) \\right) = -\\exp(\\beta_0 + \\beta_1) = -\\lambda_{\\text{int}} $$\n    The approximate variance of $\\widehat{\\text{ARR}}$ is the quadratic form:\n    $$ \\text{Var}(\\widehat{\\text{ARR}}) \\approx \\begin{pmatrix} \\text{ARR} & -\\lambda_{\\text{int}} \\end{pmatrix} \\boldsymbol{\\Sigma}_{\\hat{\\beta}} \\begin{pmatrix} \\text{ARR} \\\\ -\\lambda_{\\text{int}} \\end{pmatrix} $$\n    Expanding this gives:\n    $$ \\text{Var}(\\widehat{\\text{ARR}}) \\approx (\\text{ARR})^2 \\text{Var}(\\hat{\\beta}_0) + (\\lambda_{\\text{int}})^2 \\text{Var}(\\hat{\\beta}_1) - 2(\\text{ARR})(\\lambda_{\\text{int}}) \\text{Cov}(\\hat{\\beta}_0, \\hat{\\beta}_1) $$\n\n4.  **Construction of the Confidence Interval**: All terms in the variance formula are evaluated at their estimated values. The estimator $\\widehat{\\text{ARR}}$ is asymptotically normally distributed. Therefore, an approximate $(1-\\alpha) \\times 100\\%$ confidence interval for the true ARR is constructed using the Wald method:\n    $$ \\widehat{\\text{ARR}} \\pm z_{1-\\alpha/2} \\sqrt{\\widehat{\\text{Var}}(\\widehat{\\text{ARR}})} $$\n    where $z_{1-\\alpha/2}$ is the appropriate quantile of the standard normal distribution (e.g., $1.96$ for a $95\\%$ CI). This provides the required measure of uncertainty for the absolute reduction.", "answer": "$$ \\boxed{1.0} $$", "id": "4822293"}]}