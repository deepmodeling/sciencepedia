{"hands_on_practices": [{"introduction": "A crucial first step in mastering overdispersion is to understand its origins from first principles. This exercise guides you through a foundational derivation for the Zero-Inflated Poisson (ZIP) model, a common structure used when a dataset contains more zeros than expected under a standard Poisson process. By applying the laws of total expectation and total variance, you will mathematically demonstrate how mixing a subpopulation of \"structural zeros\" with a Poisson-distributed subpopulation inherently leads to a variance that exceeds the mean, providing a clear and tangible source of overdispersion [@problem_id:4950089].", "problem": "In a longitudinal study of patients with chronic obstructive pulmonary disease, clinicians record the number of acute exacerbations experienced by each patient over a fixed 1-year period. To accommodate structural zeros arising from patients who are not at risk of exacerbation (for example, due to a stable phenotype or sustained adherence to preventive therapy), model the count $Y$ using a Zero-Inflated Poisson (ZIP) specification. Let the structural-zero indicator $Z$ be a latent variable with $Z \\sim \\text{Bernoulli}(\\pi)$, where $Z=1$ denotes a structural zero and $Z=0$ denotes susceptibility to events. Conditional on $Z$, define\n- $Y \\mid Z=1 = 0$ almost surely, and\n- $Y \\mid Z=0 \\sim \\text{Poisson}(\\lambda)$,\nwith $Z$ independent of the Poisson component. Here, $\\pi \\in [0,1)$ is the probability of a structural zero and $\\lambda>0$ is the Poisson rate among susceptible patients.\n\nStarting only from fundamental probability laws and the core properties that the Poisson distribution has mean equal to its rate and variance equal to its rate, derive closed-form expressions for the unconditional mean $\\mathbb{E}[Y]$ and variance $\\operatorname{Var}(Y)$ of $Y$ as functions of $\\pi$ and $\\lambda$. Then, interpret how the presence of structural zeros contributes to dispersion relative to a non-inflated Poisson model that has the same mean as $Y$.\n\nProvide your final answer as the pair consisting of the mean and the variance in a single row matrix. No numerical evaluation is required.", "solution": "The problem statement is a well-posed and scientifically grounded exercise in elementary probability theory and statistical modeling. All components are clearly defined, and the premises are consistent with the established formulation of a Zero-Inflated Poisson (ZIP) model. Thus, the problem is valid. We proceed with the derivation.\n\nThe random variable $Y$ represents the count of exacerbations. Its distribution is a mixture determined by a latent Bernoulli variable $Z$. The properties provided are:\n- $Z \\sim \\text{Bernoulli}(\\pi)$, such that $P(Z=1) = \\pi$ and $P(Z=0) = 1-\\pi$.\n- The conditional distributions of $Y$ given $Z$ are:\n  - $Y \\mid Z=1 = 0$ (a point mass at $0$).\n  - $Y \\mid Z=0 \\sim \\text{Poisson}(\\lambda)$.\n- The core properties of a Poisson($\\mu$) distribution are $\\mathbb{E}[\\text{Poisson}(\\mu)] = \\mu$ and $\\operatorname{Var}(\\text{Poisson}(\\mu)) = \\mu$.\n\nOur objective is to find the unconditional mean $\\mathbb{E}[Y]$ and unconditional variance $\\operatorname{Var}(Y)$.\n\n**1. Derivation of the Mean $\\mathbb{E}[Y]$**\n\nWe use the Law of Total Expectation, which states that $\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y \\mid Z]]$.\nFirst, we compute the conditional expectation $\\mathbb{E}[Y \\mid Z]$ for each possible value of $Z$.\n- If $Z=1$, the count $Y$ is fixed at $0$. Thus, its expectation is $\\mathbb{E}[Y \\mid Z=1] = 0$.\n- If $Z=0$, the count $Y$ follows a Poisson distribution with rate $\\lambda$. Thus, its expectation is $\\mathbb{E}[Y \\mid Z=0] = \\lambda$.\n\nThe expression $\\mathbb{E}[Y \\mid Z]$ is itself a random variable, which takes the value $0$ with probability $P(Z=1) = \\pi$ and the value $\\lambda$ with probability $P(Z=0) = 1-\\pi$.\nNow, we take the expectation of this random variable over the distribution of $Z$:\n$$ \\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y \\mid Z]] = \\mathbb{E}[Y \\mid Z=0] \\cdot P(Z=0) + \\mathbb{E}[Y \\mid Z=1] \\cdot P(Z=1) $$\nSubstituting the values we found:\n$$ \\mathbb{E}[Y] = \\lambda \\cdot (1-\\pi) + 0 \\cdot \\pi = \\lambda(1-\\pi) $$\nThis is the unconditional mean of the ZIP-distributed random variable $Y$.\n\n**2. Derivation of the Variance $\\operatorname{Var}(Y)$**\n\nWe use the Law of Total Variance, which states:\n$$ \\operatorname{Var}(Y) = \\mathbb{E}[\\operatorname{Var}(Y \\mid Z)] + \\operatorname{Var}(\\mathbb{E}[Y \\mid Z]) $$\nWe will compute each of the two terms separately.\n\n**Term 1: $\\mathbb{E}[\\operatorname{Var}(Y \\mid Z)]$ (The expected conditional variance)**\n\nFirst, we find the conditional variance $\\operatorname{Var}(Y \\mid Z)$ for each value of $Z$.\n- If $Z=1$, the count $Y$ is fixed at the constant value $0$. The variance of a constant is $0$, so $\\operatorname{Var}(Y \\mid Z=1) = 0$.\n- If $Z=0$, the count $Y$ follows a Poisson distribution with rate $\\lambda$. The variance of a Poisson($\\lambda$) distribution is equal to its rate, so $\\operatorname{Var}(Y \\mid Z=0) = \\lambda$.\n\nThe expression $\\operatorname{Var}(Y \\mid Z)$ is a random variable taking the value $0$ with probability $\\pi$ and $\\lambda$ with probability $1-\\pi$. We compute its expectation:\n$$ \\mathbb{E}[\\operatorname{Var}(Y \\mid Z)] = \\operatorname{Var}(Y \\mid Z=0) \\cdot P(Z=0) + \\operatorname{Var}(Y \\mid Z=1) \\cdot P(Z=1) $$\n$$ \\mathbb{E}[\\operatorname{Var}(Y \\mid Z)] = \\lambda \\cdot (1-\\pi) + 0 \\cdot \\pi = \\lambda(1-\\pi) $$\n\n**Term 2: $\\operatorname{Var}(\\mathbb{E}[Y \\mid Z])$ (The variance of the conditional expectation)**\n\nAs determined earlier, $\\mathbb{E}[Y \\mid Z]$ is a random variable that takes the value $\\lambda$ with probability $1-\\pi$ and $0$ with probability $\\pi$. Let's call this Bernoulli-like random variable $W$. We need to find its variance, $\\operatorname{Var}(W)$.\nThe variance is given by $\\operatorname{Var}(W) = \\mathbb{E}[W^2] - (\\mathbb{E}[W])^2$.\nWe already know the mean of $W$: $\\mathbb{E}[W] = \\mathbb{E}[\\mathbb{E}[Y \\mid Z]] = \\mathbb{E}[Y] = \\lambda(1-\\pi)$.\nNext, we compute the second moment, $\\mathbb{E}[W^2]$:\n$$ \\mathbb{E}[W^2] = (\\lambda)^2 \\cdot P(Z=0) + (0)^2 \\cdot P(Z=1) = \\lambda^2(1-\\pi) + 0 = \\lambda^2(1-\\pi) $$\nNow we can compute the variance of $W$:\n$$ \\operatorname{Var}(\\mathbb{E}[Y \\mid Z]) = \\operatorname{Var}(W) = \\mathbb{E}[W^2] - (\\mathbb{E}[W])^2 $$\n$$ \\operatorname{Var}(\\mathbb{E}[Y \\mid Z]) = \\lambda^2(1-\\pi) - (\\lambda(1-\\pi))^2 $$\n$$ \\operatorname{Var}(\\mathbb{E}[Y \\mid Z]) = \\lambda^2(1-\\pi) - \\lambda^2(1-\\pi)^2 = \\lambda^2(1-\\pi) [1 - (1-\\pi)] = \\lambda^2\\pi(1-\\pi) $$\n\n**Combining the terms:**\n\nFinally, we sum the two terms to get the unconditional variance of $Y$:\n$$ \\operatorname{Var}(Y) = \\mathbb{E}[\\operatorname{Var}(Y \\mid Z)] + \\operatorname{Var}(\\mathbb{E}[Y \\mid Z]) $$\n$$ \\operatorname{Var}(Y) = \\lambda(1-\\pi) + \\lambda^2\\pi(1-\\pi) $$\nWe can factor this expression to obtain a more compact form:\n$$ \\operatorname{Var}(Y) = \\lambda(1-\\pi) (1 + \\lambda\\pi) $$\n\n**3. Interpretation of Dispersion**\n\nLet $\\mu_Y = \\mathbb{E}[Y] = \\lambda(1-\\pi)$ be the mean of the ZIP-distributed variable $Y$.\nA standard (non-inflated) Poisson model with the same mean would have its rate parameter equal to $\\mu_Y$. For such a Poisson model, say with random variable $Y_P \\sim \\text{Poisson}(\\mu_Y)$, the variance is equal to the mean:\n$$ \\operatorname{Var}(Y_P) = \\mu_Y = \\lambda(1-\\pi) $$\nNow, we compare this to the variance of our ZIP model, $\\operatorname{Var}(Y)$:\n$$ \\operatorname{Var}(Y) = \\lambda(1-\\pi) + \\lambda^2\\pi(1-\\pi) = \\mu_Y + \\lambda^2\\pi(1-\\pi) $$\nThe term $\\lambda^2\\pi(1-\\pi)$ represents the contribution to variance from the zero-inflation component.\nGiven the constraints $\\lambda > 0$ and $\\pi \\in [0,1)$, this term is non-negative.\n- If $\\pi = 0$, there is no zero-inflation. The ZIP model collapses to a standard Poisson($\\lambda$) model, and $\\operatorname{Var}(Y) = \\mu_Y$.\n- If $\\pi \\in (0,1)$, the term $\\lambda^2\\pi(1-\\pi)$ is strictly positive. Therefore, $\\operatorname{Var}(Y) > \\mu_Y$.\n\nThis condition where the variance exceeds the mean is known as **overdispersion**. The presence of structural zeros ($\\pi > 0$) introduces an additional source of variability into the population. The population is a heterogeneous mixture of two groups: a \"never-event\" group and an \"at-risk\" group. This heterogeneity inflates the overall variance beyond what would be expected for a homogeneous Poisson process with the same average event rate. The quantity $\\lambda^2\\pi(1-\\pi)$ precisely quantifies this excess variance due to the underlying mixture structure.\n\nThe final derived expressions for the mean and variance are:\nMean: $\\mathbb{E}[Y] = \\lambda(1-\\pi)$\nVariance: $\\operatorname{Var}(Y) = \\lambda(1-\\pi)(1 + \\lambda\\pi)$", "answer": "$$\\boxed{\\begin{pmatrix} \\lambda(1-\\pi) & \\lambda(1-\\pi)(1+\\lambda\\pi) \\end{pmatrix}}$$", "id": "4950089"}, {"introduction": "After developing a theoretical intuition for overdispersion, the next practical skill is to test for its presence formally. This exercise introduces the score test, an efficient and powerful statistical tool for comparing a simpler, nested model (Poisson) against a more complex alternative that accommodates overdispersion (Negative Binomial). You will first derive the test statistic from the underlying likelihood theory and then apply it to a concrete dataset, bridging the gap between statistical theory and hands-on model diagnostics [@problem_id:4950109].", "problem": "In a hospital-based cohort of chronic disease patients, the number of emergency department visits for each patient over a fixed follow-up period is modeled via a Poisson generalized linear model (GLM) with a log link and an offset for person-time. The baseline model under the null hypothesis assumes Poisson variation: for patient $i$, the count $Y_i$ has mean $E(Y_i \\mid \\boldsymbol{x}_i) = \\mu_i$ and variance $\\operatorname{Var}(Y_i \\mid \\boldsymbol{x}_i) = \\mu_i$. Consider an alternative in which the counts follow a Negative Binomial (NB) distribution with the same mean but with variance $\\operatorname{Var}(Y_i \\mid \\boldsymbol{x}_i) = \\mu_i + \\alpha \\mu_i^2$, where $\\alpha \\ge 0$ is an overdispersion parameter. You are to construct a score test for extra-Poisson variation based on the NB alternative, where the test is performed at $\\alpha = 0$ and nuisance parameters in $\\mu_i$ are estimated under the null via the Poisson GLM.\n\nStarting from the fundamental definitions of the Poisson likelihood and the Negative Binomial likelihood parameterized by $(\\mu_i, \\alpha)$, perform the following:\n\n1) Derive the score with respect to $\\alpha$ at $\\alpha = 0$, holding $\\mu_i$ fixed, and show how to obtain its variance under the null model. Use these to construct the score test statistic in closed form in terms of $\\{Y_i, \\mu_i\\}_{i=1}^n$. Clearly specify the null distribution of the test statistic.\n\n2) For the following $n = 10$ patients, a Poisson GLM has already been fit under the null hypothesis, yielding fitted means $\\hat{\\mu}_i$ along with the observed counts $y_i$. Use your derived expression to compute the numerical value of the score test statistic $S$ by plugging in $\\hat{\\mu}_i$ for $\\mu_i$:\n- Patient $1$: $y_1 = 0$, $\\hat{\\mu}_1 = 0.4$.\n- Patient $2$: $y_2 = 1$, $\\hat{\\mu}_2 = 0.6$.\n- Patient $3$: $y_3 = 0$, $\\hat{\\mu}_3 = 0.5$.\n- Patient $4$: $y_4 = 2$, $\\hat{\\mu}_4 = 1.1$.\n- Patient $5$: $y_5 = 3$, $\\hat{\\mu}_5 = 1.5$.\n- Patient $6$: $y_6 = 0$, $\\hat{\\mu}_6 = 0.7$.\n- Patient $7$: $y_7 = 4$, $\\hat{\\mu}_7 = 2.1$.\n- Patient $8$: $y_8 = 1$, $\\hat{\\mu}_8 = 0.9$.\n- Patient $9$: $y_9 = 2$, $\\hat{\\mu}_9 = 1.2$.\n- Patient $10$: $y_{10} = 5$, $\\hat{\\mu}_{10} = 3.0$.\n\nCompute $S$ and report its value. Round your answer to four significant figures.\n\nNote: For part (1), begin from the likelihood definitions, not from any pre-memorized test formula. For part (2), use your result from part (1) and the provided $\\hat{\\mu}_i$ values. The final reported answer must be the single numerical value of $S$ as specified.", "solution": "### Step 1: Extract Givens\n-   **Model under Null Hypothesis ($H_0$)**: For patient $i$, the count $Y_i$ follows a Poisson distribution.\n    -   Mean: $E(Y_i \\mid \\boldsymbol{x}_i) = \\mu_i$.\n    -   Variance: $\\operatorname{Var}(Y_i \\mid \\boldsymbol{x}_i) = \\mu_i$.\n    -   The mean is modeled via a Poisson GLM with a log link: $\\ln(\\mu_i) = \\boldsymbol{x}_i^T \\boldsymbol{\\beta}$.\n-   **Model under Alternative Hypothesis ($H_A$)**: The count $Y_i$ follows a Negative Binomial (NB) distribution.\n    -   Mean: $E(Y_i \\mid \\boldsymbol{x}_i) = \\mu_i$.\n    -   Variance: $\\operatorname{Var}(Y_i \\mid \\boldsymbol{x}_i) = \\mu_i + \\alpha \\mu_i^2$, where $\\alpha \\ge 0$ is an overdispersion parameter.\n-   **Hypothesis Test**: A score test for $H_0: \\alpha=0$ against $H_A: \\alpha > 0$.\n-   **Nuisance Parameters**: The parameters defining $\\mu_i$ (i.e., $\\boldsymbol{\\beta}$) are estimated under $H_0$ using a Poisson GLM.\n-   **Data for Part 2**: A sample of $n=10$ patients with observed counts $y_i$ and fitted means $\\hat{\\mu}_i$ from the null Poisson model.\n    - Patient $1$: $y_1=0$, $\\hat{\\mu}_1 = 0.4$.\n    - Patient $2$: $y_2=1$, $\\hat{\\mu}_2 = 0.6$.\n    - Patient $3$: $y_3=0$, $\\hat{\\mu}_3 = 0.5$.\n    - Patient $4$: $y_4=2$, $\\hat{\\mu}_4 = 1.1$.\n    - Patient $5$: $y_5=3$, $\\hat{\\mu}_5 = 1.5$.\n    - Patient $6$: $y_6=0$, $\\hat{\\mu}_6 = 0.7$.\n    - Patient $7$: $y_7=4$, $\\hat{\\mu}_7 = 2.1$.\n    - Patient $8$: $y_8=1$, $\\hat{\\mu}_8 = 0.9$.\n    - Patient $9$: $y_9=2$, $\\hat{\\mu}_9 = 1.2$.\n    - Patient $10$: $y_{10}=5$, $\\hat{\\mu}_{10} = 3.0$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, being a standard topic in biostatistics and generalized linear models. The specified Negative Binomial variance form, $\\mu + \\alpha\\mu^2$, is one of a family of standard parameterizations (the NB2 family). The task of deriving a score test is a well-defined statistical procedure. The problem is self-contained, providing all necessary theoretical context and numerical data. The language is precise and objective. There are no contradictions, ambiguities, or unrealistic assumptions. The problem is well-posed and solvable.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n***\n\n### Part 1: Derivation of the Score Test\n\nThe score test is constructed from the gradient of the log-likelihood of the alternative model, evaluated under the null hypothesis.\n\nThe Negative Binomial (NB) distribution with mean $\\mu$ and variance $\\mu + \\alpha \\mu^2$ has a probability mass function (PMF) given by:\n$$ P(Y=y; \\mu, \\alpha) = \\frac{\\Gamma(y + \\alpha^{-1})}{\\Gamma(\\alpha^{-1}) y!} \\left(\\frac{\\alpha\\mu}{1+\\alpha\\mu}\\right)^y \\left(\\frac{1}{1+\\alpha\\mu}\\right)^{\\alpha^{-1}} $$\nfor $y = 0, 1, 2, ...$. As $\\alpha \\to 0$, this distribution approaches the Poisson distribution with mean $\\mu$.\n\nThe log-likelihood for a single observation $Y_i$ is:\n$$ \\ell_i(\\mu_i, \\alpha) = \\ln \\Gamma(y_i + \\alpha^{-1}) - \\ln \\Gamma(\\alpha^{-1}) - \\ln(y_i!) + y_i \\ln(\\alpha\\mu_i) - (y_i + \\alpha^{-1}) \\ln(1+\\alpha\\mu_i) $$\nThe total log-likelihood for $n$ independent observations is $\\ell(\\boldsymbol{\\mu}, \\alpha) = \\sum_{i=1}^n \\ell_i(\\mu_i, \\alpha)$.\n\nDirect differentiation with respect to $\\alpha$ is cumbersome due to the $\\alpha^{-1}$ terms. A more tractable approach is to find the Taylor series expansion of $\\ell_i$ around $\\alpha=0$. It can be shown that the log-likelihood can be approximated as:\n$$ \\ell_i(\\mu_i, \\alpha) \\approx \\ell_{Poisson}(\\mu_i; y_i) + \\frac{\\alpha}{2} \\left[ (y_i - \\mu_i)^2 - y_i \\right] + O(\\alpha^2) $$\nwhere $\\ell_{Poisson}(\\mu_i; y_i) = y_i \\ln(\\mu_i) - \\mu_i - \\ln(y_i!)$ is the log-likelihood of the Poisson distribution.\n\nThe score with respect to $\\alpha$ is the partial derivative of the total log-likelihood with respect to $\\alpha$. For a single observation, the score component is:\n$$ U_i(\\alpha) = \\frac{\\partial \\ell_i}{\\partial \\alpha} $$\nEvaluating at $\\alpha=0$, we get:\n$$ U_i(0) = \\left. \\frac{\\partial \\ell_i}{\\partial \\alpha} \\right|_{\\alpha=0} = \\frac{1}{2} \\left[ (y_i - \\mu_i)^2 - y_i \\right] $$\nThe total score, $U(\\alpha)$, evaluated at $\\alpha=0$ is the sum over all observations:\n$$ U(0) = \\sum_{i=1}^n U_i(0) = \\frac{1}{2} \\sum_{i=1}^n \\left[ (Y_i - \\mu_i)^2 - Y_i \\right] $$\nThe score test requires that nuisance parameters ($\\boldsymbol{\\beta}$ in $\\mu_i$) be replaced by their maximum likelihood estimates under $H_0$. Let $\\hat{\\mu}_i$ be the fitted values from the Poisson GLM. The score statistic is then based on:\n$$ U(0)|_{\\mu=\\hat{\\mu}} = \\frac{1}{2} \\sum_{i=1}^n \\left[ (Y_i - \\hat{\\mu}_i)^2 - Y_i \\right] $$\n\nNext, we need the variance of the score under $H_0: \\alpha=0$, which is the Fisher information $I_{\\alpha\\alpha}(0)$. Under $H_0$, $Y_i \\sim \\text{Poisson}(\\mu_i)$.\nFirst, we verify that the score has expectation zero under $H_0$:\n$$ E[U_i(0)] = E\\left[ \\frac{1}{2} \\left( (Y_i - \\mu_i)^2 - Y_i \\right) \\right] = \\frac{1}{2} \\left( E[(Y_i - \\mu_i)^2] - E[Y_i] \\right) $$\nFor a Poisson distribution, $E[Y_i] = \\mu_i$ and the variance $E[(Y_i - \\mu_i)^2] = \\mu_i$. Thus,\n$$ E[U_i(0)] = \\frac{1}{2} (\\mu_i - \\mu_i) = 0 $$\nThe variance of the score for observation $i$ is $\\operatorname{Var}(U_i(0)) = E[U_i(0)^2] - (E[U_i(0)])^2 = E[U_i(0)^2]$.\n$$ \\operatorname{Var}(U_i(0)) = E\\left[ \\left( \\frac{1}{2} \\left[ (Y_i - \\mu_i)^2 - Y_i \\right] \\right)^2 \\right] = \\frac{1}{4} E\\left[ \\left( (Y_i - \\mu_i)^2 - Y_i \\right)^2 \\right] $$\n$$ = \\frac{1}{4} E\\left[ (Y_i - \\mu_i)^4 - 2Y_i(Y_i - \\mu_i)^2 + Y_i^2 \\right] $$\nWe use the moments of the Poisson distribution:\n-   $E[(Y_i - \\mu_i)^2] = \\mu_i$\n-   $E[(Y_i - \\mu_i)^3] = \\mu_i$\n-   $E[(Y_i - \\mu_i)^4] = 3\\mu_i^2 + \\mu_i$\nWe also need two other expectations:\n-   $E[Y_i^2] = \\operatorname{Var}(Y_i) + (E[Y_i])^2 = \\mu_i + \\mu_i^2$\n-   $E[Y_i(Y_i-\\mu_i)^2] = E[(\\mu_i + (Y_i-\\mu_i))(Y_i-\\mu_i)^2] = E[\\mu_i(Y_i-\\mu_i)^2 + (Y_i-\\mu_i)^3] = \\mu_i E[(Y_i-\\mu_i)^2] + E[(Y_i-\\mu_i)^3] = \\mu_i(\\mu_i) + \\mu_i = \\mu_i^2 + \\mu_i$\nSubstituting these into the variance expression:\n$$ \\operatorname{Var}(U_i(0)) = \\frac{1}{4} \\left[ (3\\mu_i^2 + \\mu_i) - 2(\\mu_i^2 + \\mu_i) + (\\mu_i^2 + \\mu_i) \\right] $$\n$$ = \\frac{1}{4} [ (3-2+1)\\mu_i^2 + (1-2+1)\\mu_i ] = \\frac{1}{4} [2\\mu_i^2] = \\frac{\\mu_i^2}{2} $$\nSince the observations are independent, the total information is the sum of individual variances:\n$$ I_{\\alpha\\alpha}(0) = \\operatorname{Var}(U(0)) = \\sum_{i=1}^n \\operatorname{Var}(U_i(0)) = \\sum_{i=1}^n \\frac{\\mu_i^2}{2} = \\frac{1}{2} \\sum_{i=1}^n \\mu_i^2 $$\nThe score test statistic, $S$, is constructed as $S = \\frac{U(0)^2}{I_{\\alpha\\alpha}(0)}$, with $\\mu_i$ replaced by $\\hat{\\mu}_i$:\n$$ S = \\frac{\\left( \\frac{1}{2} \\sum_{i=1}^n \\left[ (Y_i - \\hat{\\mu}_i)^2 - Y_i \\right] \\right)^2}{\\frac{1}{2} \\sum_{i=1}^n \\hat{\\mu}_i^2} $$\n$$ S = \\frac{\\frac{1}{4} \\left( \\sum_{i=1}^n \\left[ (Y_i - \\hat{\\mu}_i)^2 - Y_i \\right] \\right)^2}{\\frac{1}{2} \\sum_{i=1}^n \\hat{\\mu}_i^2} = \\frac{\\left( \\sum_{i=1}^n \\left[ (Y_i - \\hat{\\mu}_i)^2 - Y_i \\right] \\right)^2}{2 \\sum_{i=1}^n \\hat{\\mu}_i^2} $$\nThis is the closed-form expression for the score test statistic. Under the null hypothesis $H_0: \\alpha=0$, this statistic asymptotically follows a chi-squared distribution with one degree of freedom, $S \\sim \\chi_1^2$.\n\n### Part 2: Calculation of the Test Statistic\n\nWe use the derived formula for $S$ with the given data, substituting $\\hat{\\mu}_i$ for $\\mu_i$ and $y_i$ for $Y_i$.\nThe numerator of $S$ is $\\left( \\sum_{i=1}^{10} \\left[ (y_i - \\hat{\\mu}_i)^2 - y_i \\right] \\right)^2$.\nLet's compute the term $d_i = (y_i - \\hat{\\mu}_i)^2 - y_i$ for each patient:\n-   $d_1 = (0 - 0.4)^2 - 0 = 0.16$\n-   $d_2 = (1 - 0.6)^2 - 1 = 0.16 - 1 = -0.84$\n-   $d_3 = (0 - 0.5)^2 - 0 = 0.25$\n-   $d_4 = (2 - 1.1)^2 - 2 = 0.81 - 2 = -1.19$\n-   $d_5 = (3 - 1.5)^2 - 3 = 2.25 - 3 = -0.75$\n-   $d_6 = (0 - 0.7)^2 - 0 = 0.49$\n-   $d_7 = (4 - 2.1)^2 - 4 = 3.61 - 4 = -0.39$\n-   $d_8 = (1 - 0.9)^2 - 1 = 0.01 - 1 = -0.99$\n-   $d_9 = (2 - 1.2)^2 - 2 = 0.64 - 2 = -1.36$\n-   $d_{10} = (5 - 3.0)^2 - 5 = 4.0 - 5 = -1.00$\n\nThe sum is:\n$$ \\sum_{i=1}^{10} d_i = 0.16 - 0.84 + 0.25 - 1.19 - 0.75 + 0.49 - 0.39 - 0.99 - 1.36 - 1.00 = -5.62 $$\nThe numerator is $(-5.62)^2 = 31.5844$.\n\nThe denominator of $S$ is $2 \\sum_{i=1}^{10} \\hat{\\mu}_i^2$.\nLet's compute $\\hat{\\mu}_i^2$ for each patient:\n-   $\\hat{\\mu}_1^2 = 0.4^2 = 0.16$\n-   $\\hat{\\mu}_2^2 = 0.6^2 = 0.36$\n-   $\\hat{\\mu}_3^2 = 0.5^2 = 0.25$\n-   $\\hat{\\mu}_4^2 = 1.1^2 = 1.21$\n-   $\\hat{\\mu}_5^2 = 1.5^2 = 2.25$\n-   $\\hat{\\mu}_6^2 = 0.7^2 = 0.49$\n-   $\\hat{\\mu}_7^2 = 2.1^2 = 4.41$\n-   $\\hat{\\mu}_8^2 = 0.9^2 = 0.81$\n-   $\\hat{\\mu}_9^2 = 1.2^2 = 1.44$\n-   $\\hat{\\mu}_{10}^2 = 3.0^2 = 9.00$\n\nThe sum is:\n$$ \\sum_{i=1}^{10} \\hat{\\mu}_i^2 = 0.16 + 0.36 + 0.25 + 1.21 + 2.25 + 0.49 + 4.41 + 0.81 + 1.44 + 9.00 = 20.38 $$\nThe denominator is $2 \\times 20.38 = 40.76$.\n\nFinally, the score test statistic $S$ is:\n$$ S = \\frac{31.5844}{40.76} \\approx 0.77493621197 $$\nRounding to four significant figures, we get $S = 0.7749$.", "answer": "$$\n\\boxed{0.7749}\n$$", "id": "4950109"}, {"introduction": "Real-world data analysis often requires nuanced judgment that goes beyond simple hypothesis tests. This advanced case study challenges you to distinguish between two different sources of overdispersion: general event-rate heterogeneity, well-captured by a Negative Binomial (NB) model, and a distinct excess of zero counts, which may require a Zero-Inflated Negative Binomial (ZINB) model. By synthesizing multiple pieces of evidence—including expected zero frequencies, formal model comparison tests, and advanced residual diagnostics—you will practice the art of evidence-based model selection that is essential for robust and interpretable statistical inference in medicine [@problem_id:4950087].", "problem": "A multi-center observational study of patients with chronic obstructive pulmonary disease records the number of acute exacerbations per patient over exactly 1 year of follow-up. Let $Y_i$ denote the annual count for patient $i$, assumed independent across patients. Investigators suspect both excess zeros and general overdispersion. A summary of the $n=800$ counts shows an empirical mean $\\bar{y}=\\mu_{\\text{obs}}=1.20$, variance $s^2=3.60$, and a proportion of zeros $\\hat{p}_0=0.55$. Consider the following modeling steps already carried out by the analysis team:\n- A Poisson regression with only an intercept was fit, producing $\\hat{\\lambda}=1.20$.\n- A Negative Binomial (NB) regression with only an intercept was fit, using the canonical “size” parameterization with mean $\\mu$ and size $k$ (so that $E[Y]=\\mu$ and $Var(Y)=\\mu\\left(1+\\frac{\\mu}{k}\\right)$), yielding $\\hat{\\mu}=1.20$ and $\\hat{k}=0.80$.\n- Randomized Quantile Residuals (RQR) under the NB fit exhibit a cluster of large negative residuals at observed zeros and mild right-tail deviations for small counts $y\\in\\{1,2\\}$ in a hanging rootogram.\n- A score test for zero inflation nested within the NB count model reports a $p$-value of $0.030$ for the null of no extra zero component.\n- A Vuong non-nested test comparing the NB versus a Zero-Inflated Negative Binomial (ZINB) model yields a test statistic $z=1.75$ with a standard normal $p$-value of $0.080$. A parametric bootstrap version of the same comparison (using the NB as the null-generating model) returns a $p$-value of $0.042$.\nStarting from fundamental distributional definitions, one can compute the expected frequency of zeros under different count models and use diagnostics to localize lack of fit. Based on this scenario, which option describes a principled workflow to separate general overdispersion from true zero inflation using the frequency of zeros, residual diagnostics, and targeted tests?\n\nA. Declare zero inflation solely because $\\hat{p}_0=0.55$ exceeds the Poisson expectation at $\\hat{\\lambda}=1.20$, and proceed with a Zero-Inflated Poisson (ZIP) model without further checks; residual diagnostics and alternative overdispersed counts are unnecessary.\n\nB. Use the NB model as the baseline to accommodate general overdispersion and compute its implied zero probability from first principles; if the observed $\\hat{p}_0$ meaningfully exceeds the NB-expected zeros, apply a formal score test for zero inflation, compare NB versus Zero-Inflated Negative Binomial (ZINB) by Vuong and parametric bootstrap, and interrogate RQR and rootograms to confirm that misfit is concentrated at $y=0$ and small counts; incorporate clinically plausible covariates in the zero component to represent structural zeros, and decide between NB and ZINB based on the combined evidence rather than the variance-to-mean ratio alone.\n\nC. Fit a quasi-Poisson with dispersion $\\phi$, and if $\\hat{\\phi}>1$, conclude both overdispersion and zero inflation are present; a single dispersion parameter suffices to diagnose and explain excess zeros without further testing.\n\nD. Fit a hurdle model immediately and choose the final model solely by Akaike Information Criterion (AIC), ignoring residual diagnostics and tests for the presence of an explicit extra-zero component; the high proportion of zeros automatically justifies a hurdle specification regardless of the NB zero probability.", "solution": "### Step 1: Extract Givens\n\nThe problem provides the following data and modeling results for a study on chronic obstructive pulmonary disease exacerbations:\n-   Sample size: $n=800$ patients.\n-   Follow-up period: exactly 1 year.\n-   Outcome variable: $Y_i$, the annual count of acute exacerbations for patient $i$.\n-   Empirical mean of counts: $\\bar{y} = \\mu_{\\text{obs}} = 1.20$.\n-   Empirical variance of counts: $s^2 = 3.60$.\n-   Empirical proportion of zeros: $\\hat{p}_0 = 0.55$.\n-   Intercept-only Poisson model fit: $\\hat{\\lambda}=1.20$.\n-   Intercept-only Negative Binomial (NB) model fit with mean $\\mu$ and size $k$: $\\hat{\\mu}=1.20$ and $\\hat{k}=0.80$. The variance for this parameterization is $Var(Y)=\\mu\\left(1+\\frac{\\mu}{k}\\right)$.\n-   Randomized Quantile Residuals (RQR) from the NB fit show a cluster of large negative residuals for observations where $Y_i=0$ and deviations for small positive counts ($y\\in\\{1,2\\}$).\n-   A score test for zero inflation against the NB model yields a $p$-value of $0.030$.\n-   A Vuong test comparing NB vs. Zero-Inflated Negative Binomial (ZINB) gives a statistic $z=1.75$ and a standard normal $p$-value of $0.080$.\n-   A parametric bootstrap version of the Vuong test gives a $p$-value of $0.042$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement is scientifically and statistically sound.\n-   **Scientifically Grounded**: The context is modeling count data (disease exacerbations) in a medical study, which is a standard application of statistical methods. The models discussed (Poisson, NB, ZINB, Hurdle) and diagnostic tools (RQR, score test, Vuong test) are all established and appropriate for this context.\n-   **Well-Posed**: The problem is well-defined. It presents a realistic scenario with consistent quantitative information and asks for the identification of a principled workflow based on this evidence. A unique answer is discernible by applying statistical principles.\n-   **Objective**: The language is precise and objective, providing numerical results from statistical analyses without subjective interpretation.\n-   **Consistency Check**:\n    - The sample variance $s^2=3.60$ is greater than the sample mean $\\bar{y}=1.20$, indicating overdispersion relative to a Poisson distribution, where variance equals the mean. The ratio is $3.60/1.20 = 3$. This justifies considering models beyond the simple Poisson.\n    - For the intercept-only Poisson fit, the maximum likelihood estimate (MLE) of the rate parameter $\\lambda$ is the sample mean, so $\\hat{\\lambda}=\\bar{y}=1.20$ is correct.\n    - For the intercept-only NB fit, the MLE of the mean parameter $\\mu$ is also the sample mean, so $\\hat{\\mu}=\\bar{y}=1.20$ is correct.\n    - The variance implied by the fitted NB model is $Var(Y) = \\hat{\\mu}(1+\\hat{\\mu}/\\hat{k}) = 1.20(1+1.20/0.80) = 1.20(1+1.5) = 1.20(2.5) = 3.00$. This value is close to the sample variance $s^2=3.60$, showing that the NB model captures a substantial portion of the overdispersion.\n    - All provided information is internally consistent and reflects a standard, realistic data analysis scenario.\n\n### Step 3: Verdict and Action\n\nThe problem is valid. The solution will proceed by evaluating each option.\n\n### Derivation and Option Analysis\n\nThe core of the problem is to distinguish between two phenomena that both lead to overdispersion (variance greater than the mean): (1) general heterogeneity in the event rate across subjects, which can be captured by a Negative Binomial model, and (2) a \"true\" or \"structural\" zero-inflation process, where a subpopulation of subjects is not at risk of experiencing the event at all, which is modeled by a zero-inflated or hurdle model. A principled workflow must systematically disentangle these possibilities.\n\nFirst, let's calculate the expected proportion of zeros under the two initial models.\n1.  **Poisson Model**: The probability of a zero count is $P(Y=0|\\lambda) = e^{-\\lambda}$. With $\\hat{\\lambda}=1.20$, the expected proportion of zeros is $P(Y=0) = e^{-1.20} \\approx 0.301$.\n2.  **Negative Binomial Model**: The probability mass function for the NB distribution with mean $\\mu$ and size $k$ is $P(Y=y) = \\frac{\\Gamma(y+k)}{\\Gamma(k)y!} \\left(\\frac{k}{k+\\mu}\\right)^k \\left(\\frac{\\mu}{k+\\mu}\\right)^y$. For $y=0$, this simplifies to $P(Y=0|\\mu,k) = \\left(\\frac{k}{k+\\mu}\\right)^k$. With $\\hat{\\mu}=1.20$ and $\\hat{k}=0.80$, the expected proportion of zeros is $P(Y=0) = \\left(\\frac{0.80}{0.80+1.20}\\right)^{0.80} = (0.4)^{0.8} \\approx 0.478$.\n\nThe observed proportion of zeros is $\\hat{p}_0 = 0.55$.\n-   The Poisson model drastically under-predicts zeros ($0.301$ vs $0.55$).\n-   The NB model does a much better job, but still under-predicts zeros ($0.478$ vs $0.55$), suggesting there might be remaining zero-inflation that even the NB's heterogeneity parameter cannot fully account for.\n\nNow, we evaluate each option.\n\n**A. Declare zero inflation solely because $\\hat{p}_0=0.55$ exceeds the Poisson expectation at $\\hat{\\lambda}=1.20$, and proceed with a Zero-Inflated Poisson (ZIP) model without further checks; residual diagnostics and alternative overdispersed counts are unnecessary.**\n\nThis option describes a flawed and superficial workflow. While the discrepancy between $\\hat{p}_0$ and the Poisson expectation correctly identifies a problem with the Poisson model, it does not uniquely diagnose zero-inflation. General overdispersion, as captured by an NB model, also leads to excess zeros relative to the Poisson model. Jumping to a ZIP model ignores the possibility that a simple NB model might be sufficient or that a ZINB model might be necessary (since the data is overdispersed even apart from the zeros). The dismissal of diagnostics (\"without further checks\") is contrary to all sound statistical practice.\n**Verdict: Incorrect.**\n\n**B. Use the NB model as the baseline to accommodate general overdispersion and compute its implied zero probability from first principles; if the observed $\\hat{p}_0$ meaningfully exceeds the NB-expected zeros, apply a formal score test for zero inflation, compare NB versus Zero-Inflated Negative Binomial (ZINB) by Vuong and parametric bootstrap, and interrogate RQR and rootograms to confirm that misfit is concentrated at $y=0$ and small counts; incorporate clinically plausible covariates in the zero component to represent structural zeros, and decide between NB and ZINB based on the combined evidence rather than the variance-to-mean ratio alone.**\n\nThis option outlines a comprehensive and rigorous workflow that aligns perfectly with modern statistical practice for count data.\n1.  It correctly establishes the NB model as the proper baseline for handling general overdispersion, a necessary first step before claiming specific zero-inflation.\n2.  It uses the discrepancy between observed zeros ($\\hat{p}_0=0.55$) and the NB-predicted zeros ($P(Y=0)\\approx 0.478$) as initial evidence.\n3.  It follows up with formal hypothesis testing: the score test ($p=0.030$) and the more reliable parametric bootstrap Vuong test ($p=0.042$) both provide statistical evidence supporting the ZINB over the NB model.\n4.  It incorporates graphical diagnostics (RQR, rootograms) to confirm that the lack of fit in the NB model is localized at the zero count, which is the signature of zero-inflation. The mention of \"large negative residuals at observed zeros\" correctly interprets the output of RQRs in this context.\n5.  It includes the crucial step of model refinement by considering covariates for the zero-inflation component, which enhances interpretability.\n6.  It correctly concludes that the final model choice should be based on a synthesis of all available evidence (tests, diagnostics, fit statistics, scientific plausibility), not a single metric.\nThis entire process is a textbook example of a principled approach to a complex modeling problem.\n**Verdict: Correct.**\n\n**C. Fit a quasi-Poisson with dispersion $\\phi$, and if $\\hat{\\phi}>1$, conclude both overdispersion and zero inflation are present; a single dispersion parameter suffices to diagnose and explain excess zeros without further testing.**\n\nThis option is based on a fundamental misunderstanding of the quasi-Poisson model. A quasi-Poisson model assumes the variance is $Var(Y) = \\phi E[Y]$. An estimate of $\\hat{\\phi} > 1$ (here, $\\hat{\\phi} \\approx s^2/\\bar{y} = 3.60/1.20 = 3.00$) confirms overdispersion but provides no information about its source. It does not distinguish between general heterogeneity and a specific zero-inflation process. The dispersion parameter $\\phi$ is simply a post-hoc correction factor for standard errors; it does not change the model's fitted values or its predicted zero probability from the underlying Poisson structure. Therefore, it cannot \"diagnose\" or \"explain\" excess zeros in a mechanistic way. Further testing and more structured models (like NB or ZI models) are required to probe the nature of the overdispersion.\n**Verdict: Incorrect.**\n\n**D. Fit a hurdle model immediately and choose the final model solely by Akaike Information Criterion (AIC), ignoring residual diagnostics and tests for the presence of an explicit extra-zero component; the high proportion of zeros automatically justifies a hurdle specification regardless of the NB zero probability.**\n\nThis workflow is hasty and methodologically weak. While a hurdle model is a valid alternative to a ZI model, fitting it \"immediately\" and \"automatically\" based on a high zero count is unprincipled. One should first assess if a simpler model, like the NB, is sufficient. The statement \"regardless of the NB zero probability\" is a critical error; comparing the observed zero count to the NB's expectation is a crucial step. Furthermore, relying \"solely\" on AIC for model selection is poor practice. AIC is a valuable tool for comparing non-nested models, but it does not reveal *why* or *where* a model fits poorly. Ignoring residual diagnostics and formal hypothesis tests means flying blind and potentially choosing a model that has a good overall AIC score but fails to capture important features of the data.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{B}$$", "id": "4950087"}]}