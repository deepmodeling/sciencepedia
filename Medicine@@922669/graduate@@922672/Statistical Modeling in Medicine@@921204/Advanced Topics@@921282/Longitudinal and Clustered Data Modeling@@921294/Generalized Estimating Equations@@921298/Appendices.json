{"hands_on_practices": [{"introduction": "The fundamental reason for using Generalized Estimating Equations (GEE) is to properly account for correlated data, which is common in medical studies with repeated measures or clustered designs. This exercise provides a foundational understanding of *why* this is necessary by guiding you through the derivation of the variance inflation factor, or \"design effect\" [@problem_id:4964749]. By quantifying how much the variance of a treatment effect is underestimated when intracluster correlation is ignored, you will appreciate the critical need for methods like GEE.", "problem": "Consider a cluster-randomized medical study analyzed with Generalized Estimating Equations (GEE) using an identity link for a continuous outcome (e.g., systolic blood pressure), where treatment is assigned at the cluster level. Suppose there are $K$ clusters per arm and each cluster has exactly $n$ individuals (balanced cluster sizes). Let $Y_{kj}$ denote the outcome for individual $j \\in \\{1,\\dots,n\\}$ in cluster $k \\in \\{1,\\dots,K\\}$. Assume a marginal mean model with constant variance $ \\operatorname{Var}(Y_{kj}) = \\sigma^{2}$ and an exchangeable intracluster correlation structure with intracluster correlation coefficient (ICC) $\\rho$, so that for $j \\neq \\ell$ within the same cluster,\n$$\n\\operatorname{Cov}(Y_{kj}, Y_{k\\ell}) = \\rho \\sigma^{2},\n$$\nand outcomes from different clusters are independent.\n\nDefine the marginal treatment effect estimator as the difference in arm means,\n$$\n\\hat{\\Delta} = \\bar{Y}_{\\text{T}} - \\bar{Y}_{\\text{C}},\n$$\nwhere $\\bar{Y}_{\\text{T}}$ and $\\bar{Y}_{\\text{C}}$ are the sample means of all individuals in the treatment and control arms, respectively. Using only foundational properties of variances and covariances (e.g., $ \\operatorname{Var}\\!\\left(\\sum_{i} Z_{i}\\right)=\\sum_{i} \\operatorname{Var}(Z_{i}) + 2 \\sum_{i<j} \\operatorname{Cov}(Z_{i}, Z_{j})$) and the exchangeable covariance structure described above, derive the variance of $\\hat{\\Delta}$ under the presence of intracluster correlation and compare it to the variance that would arise if outcomes were independent within clusters (i.e., $\\rho = 0$). From this comparison, obtain the multiplicative variance inflation factor, known as the design effect for balanced cluster sizes, as a closed-form function of $n$ and $\\rho$.\n\nProvide the final analytic expression for the design effect in terms of $n$ and $\\rho$. Do not provide a numerical approximation; no rounding is required, and no units should be included in the final expression.", "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- **Study Design**: Cluster-randomized trial with treatment assigned at the cluster level.\n- **Arms**: Treatment (T) and Control (C).\n- **Clusters**: $K$ clusters per arm.\n- **Cluster Size**: $n$ individuals per cluster (balanced).\n- **Outcome**: $Y_{kj}$ for individual $j \\in \\{1,\\dots,n\\}$ in cluster $k \\in \\{1,\\dots,K\\}$ is a continuous variable.\n- **Estimator**: The marginal treatment effect estimator is $\\hat{\\Delta} = \\bar{Y}_{\\text{T}} - \\bar{Y}_{\\text{C}}$, where $\\bar{Y}_{\\text{T}}$ and $\\bar{Y}_{\\text{C}}$ are the sample means of all individuals in the respective arms.\n- **Variance**: The marginal variance of any individual outcome is constant, $\\operatorname{Var}(Y_{kj}) = \\sigma^{2}$.\n- **Covariance Structure**: The covariance follows an exchangeable structure.\n  - For individuals $j, \\ell$ in the same cluster $k$ ($j \\neq \\ell$): $\\operatorname{Cov}(Y_{kj}, Y_{k\\ell}) = \\rho \\sigma^{2}$, where $\\rho$ is the intracluster correlation coefficient (ICC).\n  - For individuals in different clusters: Outcomes are independent, implying their covariance is zero.\n- **Task**:\n  1. Derive the variance of $\\hat{\\Delta}$, denoted $\\operatorname{Var}(\\hat{\\Delta})$, using foundational properties of variance and covariance.\n  2. Compare this variance to the variance that would result if all outcomes were independent (i.e., $\\rho=0$).\n  3. Derive the design effect, which is the multiplicative variance inflation factor, as a function of $n$ and $\\rho$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is firmly rooted in the statistical theory of clinical trials, specifically the analysis of cluster-randomized designs. The concepts of GEE, exchangeable correlation, ICC, and design effect are standard and fundamental in this field.\n- **Well-Posed**: The problem is clearly defined with all necessary parameters ($K, n, \\sigma^2, \\rho$), assumptions (balanced design, exchangeable correlation, independence between clusters), and a specific estimand ($\\hat{\\Delta}$) provided. The objective is to derive a well-known analytical result. A unique solution exists.\n- **Objective**: The problem is stated in precise, formal mathematical and statistical language, free of ambiguity or subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a well-posed, scientifically grounded exercise in statistical derivation. Proceeding with the solution.\n\n#### Derivation of the Variance of the Treatment Effect Estimator\n\nThe estimator for the treatment effect is given by $\\hat{\\Delta} = \\bar{Y}_{\\text{T}} - \\bar{Y}_{\\text{C}}$. Since individuals in the treatment arm are distinct from individuals in the control arm, and clusters are assigned to one arm or the other, the two sample means $\\bar{Y}_{\\text{T}}$ and $\\bar{Y}_{\\text{C}}$ are independent. Therefore, the variance of their difference is the sum of their variances:\n$$\n\\operatorname{Var}(\\hat{\\Delta}) = \\operatorname{Var}(\\bar{Y}_{\\text{T}} - \\bar{Y}_{\\text{C}}) = \\operatorname{Var}(\\bar{Y}_{\\text{T}}) + \\operatorname{Var}(\\bar{Y}_{\\text{C}})\n$$\nDue to the balanced design ($K$ clusters of size $n$ in each arm) and identical variance-covariance structure, the variance of the mean will be the same for both arms. Thus, $\\operatorname{Var}(\\bar{Y}_{\\text{T}}) = \\operatorname{Var}(\\bar{Y}_{\\text{C}})$. We can focus on deriving the variance for one arm, say the treatment arm, and then multiply the result by $2$.\n\nThe total number of individuals in the treatment arm is $nK$. The sample mean for the treatment arm is the average of all outcomes in that arm:\n$$\n\\bar{Y}_{\\text{T}} = \\frac{1}{nK} \\sum_{k=1}^{K} \\sum_{j=1}^{n} Y_{kj}^{\\text{T}}\n$$\nwhere $Y_{kj}^{\\text{T}}$ denotes the outcome for individual $j$ in cluster $k$ of the treatment arm. For notational simplicity, we will omit the superscript T. The variance of this mean is:\n$$\n\\operatorname{Var}(\\bar{Y}_{\\text{T}}) = \\operatorname{Var}\\left(\\frac{1}{nK} \\sum_{k=1}^{K} \\sum_{j=1}^{n} Y_{kj}\\right) = \\frac{1}{(nK)^2} \\operatorname{Var}\\left(\\sum_{k=1}^{K} \\sum_{j=1}^{n} Y_{kj}\\right)\n$$\nThe problem states that outcomes from different clusters are independent. This implies that the variance of a sum across clusters is the sum of the variances for each cluster's total.\n$$\n\\operatorname{Var}\\left(\\sum_{k=1}^{K} \\sum_{j=1}^{n} Y_{kj}\\right) = \\sum_{k=1}^{K} \\operatorname{Var}\\left(\\sum_{j=1}^{n} Y_{kj}\\right)\n$$\nNow, we must find the variance of the sum of outcomes within a single cluster $k$. Using the general formula for the variance of a sum of random variables:\n$$\n\\operatorname{Var}\\left(\\sum_{j=1}^{n} Y_{kj}\\right) = \\sum_{j=1}^{n} \\operatorname{Var}(Y_{kj}) + \\sum_{j=1}^{n} \\sum_{\\ell \\neq j} \\operatorname{Cov}(Y_{kj}, Y_{k\\ell})\n$$\nWe are given the following from the problem statement:\n1.  The variance of each individual outcome is $\\operatorname{Var}(Y_{kj}) = \\sigma^2$.\n2.  The covariance for any pair of distinct individuals within the same cluster is $\\operatorname{Cov}(Y_{kj}, Y_{k\\ell}) = \\rho \\sigma^2$ for $j \\neq \\ell$.\n\nThere are $n$ variance terms in the first summation. There are $n(n-1)$ ordered pairs of distinct indices $(j, \\ell)$, so there are $n(n-1)$ covariance terms. Substituting the given values:\n$$\n\\sum_{j=1}^{n} \\operatorname{Var}(Y_{kj}) = \\sum_{j=1}^{n} \\sigma^2 = n\\sigma^2\n$$\n$$\n\\sum_{j=1}^{n} \\sum_{\\ell \\neq j} \\operatorname{Cov}(Y_{kj}, Y_{k\\ell}) = n(n-1) \\rho \\sigma^2\n$$\nCombining these, the variance of the sum of outcomes within a single cluster is:\n$$\n\\operatorname{Var}\\left(\\sum_{j=1}^{n} Y_{kj}\\right) = n\\sigma^2 + n(n-1)\\rho\\sigma^2 = n\\sigma^2 \\left(1 + (n-1)\\rho\\right)\n$$\nSince this holds for any cluster $k$, and there are $K$ independent clusters in the arm, the variance of the total sum for the arm is:\n$$\n\\operatorname{Var}\\left(\\sum_{k=1}^{K} \\sum_{j=1}^{n} Y_{kj}\\right) = \\sum_{k=1}^{K} \\left[ n\\sigma^2(1 + (n-1)\\rho) \\right] = Kn\\sigma^2(1 + (n-1)\\rho)\n$$\nWe can now find the variance of the arm mean, $\\operatorname{Var}(\\bar{Y}_{\\text{T}})$:\n$$\n\\operatorname{Var}(\\bar{Y}_{\\text{T}}) = \\frac{1}{(nK)^2} \\left[ Kn\\sigma^2(1 + (n-1)\\rho) \\right] = \\frac{\\sigma^2(1 + (n-1)\\rho)}{nK}\n$$\nFinally, we calculate the variance of the estimator $\\hat{\\Delta}$:\n$$\n\\operatorname{Var}(\\hat{\\Delta}) = \\operatorname{Var}(\\bar{Y}_{\\text{T}}) + \\operatorname{Var}(\\bar{Y}_{\\text{C}}) = 2 \\operatorname{Var}(\\bar{Y}_{\\text{T}}) = \\frac{2\\sigma^2(1 + (n-1)\\rho)}{nK}\n$$\nThis expression is the variance of the treatment effect estimator under the specified intracluster correlation structure.\n\n#### Comparison with Independent Outcomes\n\nThe second step is to find the variance under the counterfactual scenario where all outcomes are independent, even within clusters. This corresponds to setting the intracluster correlation coefficient $\\rho=0$. Let's denote this variance as $\\operatorname{Var}_{\\text{indep}}(\\hat{\\Delta})$.\nSetting $\\rho=0$ in our derived formula:\n$$\n\\operatorname{Var}_{\\text{indep}}(\\hat{\\Delta}) = \\frac{2\\sigma^2(1 + (n-1)(0))}{nK} = \\frac{2\\sigma^2}{nK}\n$$\nThis result is consistent with first principles. If all $nK$ individuals in an arm are independent observations with variance $\\sigma^2$, the variance of their mean is $\\frac{\\sigma^2}{nK}$. The variance of the difference between two such independent means would be $\\frac{\\sigma^2}{nK} + \\frac{\\sigma^2}{nK} = \\frac{2\\sigma^2}{nK}$.\n\n#### Derivation of the Design Effect\n\nThe design effect (DEFF) is defined as the ratio of the variance of an estimator under the actual (clustered) sampling design to the variance that would have been obtained from a simple random sample of the same total size.\n$$\n\\text{DEFF} = \\frac{\\operatorname{Var}(\\hat{\\Delta})}{\\operatorname{Var}_{\\text{indep}}(\\hat{\\Delta})}\n$$\nSubstituting the expressions we derived:\n$$\n\\text{DEFF} = \\frac{\\frac{2\\sigma^2(1 + (n-1)\\rho)}{nK}}{\\frac{2\\sigma^2}{nK}}\n$$\nCanceling the common term $\\frac{2\\sigma^2}{nK}$ from the numerator and denominator yields the design effect:\n$$\n\\text{DEFF} = 1 + (n-1)\\rho\n$$\nThis is the required closed-form expression for the multiplicative variance inflation factor as a function of the cluster size $n$ and the intracluster correlation coefficient $\\rho$.", "answer": "$$\\boxed{1 + (n-1)\\rho}$$", "id": "4964749"}, {"introduction": "Once a GEE model is fitted, interpreting its coefficients correctly is paramount. This practice focuses on one of the most common applications: modeling a binary outcome with a logistic link to estimate a population-averaged effect [@problem_id:4964705]. You will learn how to translate a regression coefficient, $\\beta_T$, into a marginal odds ratio, a crucial step for drawing meaningful conclusions about treatment efficacy from longitudinal or clustered data.", "problem": "A multi-center longitudinal study of an anti-inflammatory therapy follows $n$ patients over $m$ clinic visits to assess whether a flare occurred at each visit. Let $Y_{ij} \\in \\{0,1\\}$ denote whether patient $i$ had a flare at visit $j$. The treatment assignment is a dichotomous indicator $T_i \\in \\{0,1\\}$ measured at baseline and held constant over time. The marginal mean of $Y_{ij}$ given covariates is modeled with a logistic link using Generalized Estimating Equations (GEE) with an exchangeable working correlation:\n$$\n\\ln\\!\\left(\\frac{\\mathbb{E}[Y_{ij} \\mid \\mathbf{X}_{ij}]}{1-\\mathbb{E}[Y_{ij} \\mid \\mathbf{X}_{ij}]}\\right)\n\\;=\\;\n\\beta_0 \\;+\\; \\beta_T T_i \\;+\\; \\beta_A \\,\\text{Age}_i \\;+\\; \\beta_S \\,\\text{Severity}_i \\;+\\; \\beta_{t2} I\\{j=2\\} \\;+\\; \\beta_{t3} I\\{j=3\\} \\;+\\; \\beta_{t4} I\\{j=4\\},\n$$\nwith no interactions. Here $\\text{Age}_i$ is baseline age in years, $\\text{Severity}_i$ is a standardized baseline severity score, and $I\\{j=k\\}$ are visit indicators. The GEE is fit with a robust sandwich variance, and the following coefficient estimates are obtained:\n$$\n\\hat{\\beta}_0 = -1.62,\\quad \\hat{\\beta}_T = -0.3147107,\\quad \\hat{\\beta}_A = 0.011,\\quad \\hat{\\beta}_S = 0.207,\\quad \\hat{\\beta}_{t2} = 0.10,\\quad \\hat{\\beta}_{t3} = 0.05,\\quad \\hat{\\beta}_{t4} = 0.02.\n$$\nThe working correlation parameter estimate is $\\hat{\\alpha} = 0.22$ under the exchangeable structure.\n\nStarting only from the definitions of the logistic link and the odds for a binary outcome, and treating the GEE mean model as the population-averaged specification for $\\mathbb{E}[Y_{ij}\\mid \\mathbf{X}_{ij}]$, do the following:\n\n1) Derive an expression, in terms of $\\beta_T$, for the population-averaged odds ratio comparing $T_i=1$ to $T_i=0$ while holding the other covariates fixed (no interaction terms are present).\n\n2) Using the reported estimate $\\hat{\\beta}_T$, compute the estimated marginal odds ratio. Round your numerical answer to four significant figures.\n\n3) Briefly state the interpretation of this odds ratio in the population-averaged sense with respect to repeated measures and covariate adjustment. Do not compute any confidence intervals.\n\nYour final reported answer must be only the numerical value from part $2$, rounded to four significant figures and with no units.", "solution": "We begin from two foundational definitions:\n\n- For a binary outcome with probability $p$, the odds are $p/(1-p)$.\n\n- Under a logistic link, the log-odds (logit) of the marginal mean is linear in covariates: if $p = \\mathbb{E}[Y_{ij}\\mid \\mathbf{X}_{ij}]$, then $\\ln\\!\\left(\\frac{p}{1-p}\\right) = \\mathbf{X}_{ij}^{\\top}\\boldsymbol{\\beta}$.\n\nPart $1$. Let $\\mathbf{Z}_{ij}$ collect all covariates except the treatment indicator $T_i$. Under the stated GEE mean model with no interactions, for any fixed $\\mathbf{Z}_{ij}$, define\n$$\np_1 \\equiv \\Pr(Y_{ij}=1\\mid T_i=1,\\mathbf{Z}_{ij}),\\qquad\np_0 \\equiv \\Pr(Y_{ij}=1\\mid T_i=0,\\mathbf{Z}_{ij}).\n$$\nBy the logistic mean specification,\n$$\n\\ln\\!\\left(\\frac{p_1}{1-p_1}\\right) = \\beta_0 + \\beta_T\\cdot 1 + \\mathbf{Z}_{ij}^{\\top}\\boldsymbol{\\beta}_Z\n\\quad\\text{and}\\quad\n\\ln\\!\\left(\\frac{p_0}{1-p_0}\\right) = \\beta_0 + \\beta_T\\cdot 0 + \\mathbf{Z}_{ij}^{\\top}\\boldsymbol{\\beta}_Z,\n$$\nwhere $\\boldsymbol{\\beta}_Z$ are the coefficients for the non-treatment covariates. Subtracting these two equalities yields\n$$\n\\ln\\!\\left(\\frac{p_1}{1-p_1}\\right) - \\ln\\!\\left(\\frac{p_0}{1-p_0}\\right) \\;=\\; \\beta_T.\n$$\nExponentiating both sides gives\n$$\n\\frac{\\dfrac{p_1}{1-p_1}}{\\dfrac{p_0}{1-p_0}} \\;=\\; \\exp(\\beta_T).\n$$\nThe left-hand side is precisely the odds ratio comparing $T_i=1$ to $T_i=0$ holding $\\mathbf{Z}_{ij}$ fixed. Therefore, in this marginal (population-averaged) logistic GEE, the population-averaged odds ratio for treatment is\n$$\n\\text{OR}_{\\text{PA}} \\;=\\; \\exp(\\beta_T).\n$$\n\nPart $2$. Using the estimate $\\hat{\\beta}_T = -0.3147107$, the estimated marginal odds ratio is\n$$\n\\widehat{\\text{OR}}_{\\text{PA}} \\;=\\; \\exp(\\hat{\\beta}_T) \\;=\\; \\exp(-0.3147107).\n$$\nCompute this value:\n$$\n\\exp(-0.3147107) \\approx 0.7300000\\ldots\n$$\nRounding to four significant figures gives $0.7300$.\n\nPart $3$. Interpretation. In a Generalized Estimating Equations framework with a logistic link, $\\boldsymbol{\\beta}$ parameterizes the marginal mean $\\mathbb{E}[Y_{ij}\\mid \\mathbf{X}_{ij}]$ for the population, not subject-specific conditional means given latent random effects. With no treatment interactions, $\\exp(\\beta_T)$ is the factor by which the population-averaged odds of a flare at any visit change when comparing the treated population ($T_i=1$) to the untreated population ($T_i=0$), holding the covariates $\\text{Age}_i$, $\\text{Severity}_i$, and visit indicators fixed. Thus $\\widehat{\\text{OR}}_{\\text{PA}}\\approx 0.7300$ indicates that, at the same covariate values and at any visit, the population-averaged odds of a flare under treatment are about $0.73$ times those under no treatment. This is a marginal (population-averaged across the within-subject correlation) effect and is distinct from a subject-specific odds ratio from a random-effects logistic model; it remains conditional on the included covariates due to the non-collapsibility of the odds ratio. The working correlation $\\hat{\\alpha} = 0.22$ influences efficiency but does not alter this mean-structure-based interpretation.", "answer": "$$\\boxed{0.7300}$$", "id": "4964705"}, {"introduction": "GEE is celebrated for its robustness, as it provides consistent estimates of mean parameters even when the working correlation structure is misspecified. However, this robustness has a critical boundary, which this exercise explores [@problem_id:4964692]. You will demonstrate analytically that GEE is *not* robust to misspecification of the mean model, proving that an omitted confounder leads to biased estimates and reinforcing the maxim that correct mean model specification is essential for valid inference.", "problem": "Consider a repeated-measures clinical study with $n$ independent patients indexed by $i \\in \\{1,\\dots,n\\}$, each observed at $m \\geq 2$ visits indexed by $j \\in \\{1,\\dots,m\\}$. Let the outcome be $Y_{ij} \\in \\mathbb{R}$. The analyst fits a Generalized Estimating Equations (GEE) model with identity link and correctly specified working correlation matrix equal to the true within-patient correlation. Specifically, the analyst uses the misspecified mean model $E\\!\\left(Y_{ij} \\mid A_i\\right) = \\beta_0 + \\beta_1 A_i$, where $A_i \\in \\mathbb{R}$ is a patient-level exposure that is constant across visits $j$ for patient $i$.\n\nAssume the true data-generating mechanism is linear with an omitted, patient-level confounder $Z_i \\in \\mathbb{R}$:\n$$\nY_{ij} = \\beta_0^{\\star} + \\beta_1^{\\star} A_i + \\gamma Z_i + \\varepsilon_{ij},\n$$\nwhere $\\gamma \\neq 0$, $Z_i \\sim \\mathcal{N}(0,\\sigma_Z^2)$, and the exposure is generated as\n$$\nA_i = \\delta Z_i + \\eta_i,\n$$\nwith $\\eta_i \\sim \\mathcal{N}(0,\\sigma_{\\eta}^2)$, independent of $Z_i$. The noise vector $\\varepsilon_i = (\\varepsilon_{i1},\\dots,\\varepsilon_{im})^{\\top}$ has mean zero, is independent of $(A_i,Z_i)$, and has covariance $\\operatorname{Cov}(\\varepsilon_i) = \\sigma^2 R_m(\\rho)$, where $R_m(\\rho)$ is the $m \\times m$ exchangeable correlation matrix with common correlation parameter $\\rho \\in (-1/(m-1),1)$.\n\nThe analyst fits the misspecified mean $E\\!\\left(Y_{ij} \\mid A_i\\right) = \\beta_0 + \\beta_1 A_i$ by solving the GEE with correctly specified working covariance $V_i = \\sigma^2 R_m(\\rho)$:\n$$\n\\sum_{i=1}^{n} D_i(\\beta)^{\\top} V_i^{-1} \\left\\{ Y_i - \\mu_i(\\beta) \\right\\} = 0,\n$$\nwhere $Y_i = (Y_{i1},\\dots,Y_{im})^{\\top}$, $\\mu_i(\\beta) = (\\beta_0 + \\beta_1 A_i)\\, \\mathbf{1}_m$, $D_i(\\beta)$ is the $m \\times 2$ derivative matrix with columns $\\partial \\mu_i/\\partial \\beta_0 = \\mathbf{1}_m$ and $\\partial \\mu_i/\\partial \\beta_1 = A_i \\mathbf{1}_m$, and $\\mathbf{1}_m$ is the $m$-vector of ones.\n\nStarting from the foundational population GEE (the probability limit of the sample estimating equation),\n$$\nE\\!\\left[ D_i(\\beta)^{\\top} V_i^{-1} \\left\\{ Y_i - \\mu_i(\\beta) \\right\\} \\right] = 0,\n$$\nderive the large-sample (asymptotic) limit of the slope estimator $\\hat{\\beta}_1$ under the above misspecified mean but correctly specified working correlation, and demonstrate explicitly that the asymptotic limit differs from $\\beta_1^{\\star}$ when $\\gamma \\neq 0$. In the process, compute a closed-form expression for the asymptotic bias $\\operatorname{Bias}(\\hat{\\beta}_1) = \\lim_{n \\to \\infty} E(\\hat{\\beta}_1) - \\beta_1^{\\star}$ in terms of $\\gamma$, $\\delta$, $\\sigma_Z^2$, and $\\sigma_{\\eta}^2$, and show how and why it does not depend on $\\rho$.\n\nYour final answer must be the single closed-form analytic expression for $\\operatorname{Bias}(\\hat{\\beta}_1)$ as a function of $(\\gamma,\\delta,\\sigma_Z^2,\\sigma_{\\eta}^2)$; no numerical evaluation or rounding is required.", "solution": "The problem statement has been validated and is deemed valid. It is a well-posed, scientifically grounded problem in statistical theory concerning Generalized Estimating Equations (GEE). All necessary information is provided, and the problem is internally consistent and objective.\n\nThe goal is to find the asymptotic limit of the estimator $\\hat{\\beta}_1$, denoted by $\\beta_1$, which is obtained by solving the population GEE, and then to compute the asymptotic bias, $\\beta_1 - \\beta_1^{\\star}$. The population GEE is given by:\n$$\nE\\left[ D_i(\\beta)^{\\top} V_i^{-1} \\left\\{ Y_i - \\mu_i(\\beta) \\right\\} \\right] = 0\n$$\nThe components of this equation are defined as:\n- $Y_i = (Y_{i1}, \\dots, Y_{im})^{\\top}$ is the vector of outcomes for patient $i$.\n- The true data-generating process for $Y_i$ is $Y_{ij} = \\beta_0^{\\star} + \\beta_1^{\\star} A_i + \\gamma Z_i + \\varepsilon_{ij}$. In vector form:\n  $$Y_i = (\\beta_0^{\\star} + \\beta_1^{\\star} A_i + \\gamma Z_i) \\mathbf{1}_m + \\varepsilon_i$$\n  where $\\mathbf{1}_m$ is an $m \\times 1$ vector of ones and $\\varepsilon_i = (\\varepsilon_{i1}, \\dots, \\varepsilon_{im})^{\\top}$.\n- The misspecified mean model is $\\mu_i(\\beta) = E(Y_i \\mid A_i) = (\\beta_0 + \\beta_1 A_i) \\mathbf{1}_m$.\n- The derivative matrix is $D_i(\\beta) = \\frac{\\partial \\mu_i(\\beta)}{\\partial \\beta^{\\top}} = \\begin{pmatrix} \\frac{\\partial \\mu_i}{\\partial \\beta_0} & \\frac{\\partial \\mu_i}{\\partial \\beta_1} \\end{pmatrix} = \\begin{pmatrix} \\mathbf{1}_m & A_i \\mathbf{1}_m \\end{pmatrix}$.\n- The working covariance matrix is $V_i = \\sigma^2 R_m(\\rho)$, where $R_m(\\rho)$ is the $m \\times m$ exchangeable correlation matrix.\n\nSubstituting these into the population GEE:\n$$\nE\\left[ \\begin{pmatrix} \\mathbf{1}_m^{\\top} \\\\ A_i \\mathbf{1}_m^{\\top} \\end{pmatrix} V_i^{-1} \\left\\{ ((\\beta_0^{\\star} + \\beta_1^{\\star} A_i + \\gamma Z_i) \\mathbf{1}_m + \\varepsilon_i) - ((\\beta_0 + \\beta_1 A_i) \\mathbf{1}_m) \\right\\} \\right] = 0\n$$\nThis can be rewritten as:\n$$\nE\\left[ \\begin{pmatrix} \\mathbf{1}_m^{\\top} \\\\ A_i \\mathbf{1}_m^{\\top} \\end{pmatrix} V_i^{-1} ((\\beta_0^{\\star} - \\beta_0) + (\\beta_1^{\\star} - \\beta_1) A_i + \\gamma Z_i) \\mathbf{1}_m \\right] + E\\left[ \\begin{pmatrix} \\mathbf{1}_m^{\\top} \\\\ A_i \\mathbf{1}_m^{\\top} \\end{pmatrix} V_i^{-1} \\varepsilon_i \\right] = 0\n$$\nLet's analyze the second term. The expectation is taken over the joint distribution of $A_i, Z_i, \\varepsilon_i$. Since $\\varepsilon_i$ is independent of $A_i$ and $Z_i$ (and thus independent of $D_i$) and has mean zero, we can use the law of total expectation:\n$$\nE\\left[ D_i^{\\top} V_i^{-1} \\varepsilon_i \\right] = E\\left[ E\\left[ D_i^{\\top} V_i^{-1} \\varepsilon_i \\mid A_i, Z_i \\right] \\right] = E\\left[ D_i^{\\top} V_i^{-1} E\\left[ \\varepsilon_i \\mid A_i, Z_i \\right] \\right] = E\\left[ D_i^{\\top} V_i^{-1} \\cdot 0 \\right] = 0\n$$\nThus, the population GEE simplifies to:\n$$\nE\\left[ \\begin{pmatrix} \\mathbf{1}_m^{\\top} \\\\ A_i \\mathbf{1}_m^{\\top} \\end{pmatrix} V_i^{-1} \\mathbf{1}_m ((\\beta_0^{\\star} - \\beta_0) + (\\beta_1^{\\star} - \\beta_1) A_i + \\gamma Z_i) \\right] = 0\n$$\nThe term $\\mathbf{1}_m^{\\top} V_i^{-1} \\mathbf{1}_m$ is a scalar. Let's compute it. The working covariance is $V_i = \\sigma^2 R_m(\\rho) = \\sigma^2((1-\\rho)I_m + \\rho \\mathbf{1}_m\\mathbf{1}_m^{\\top})$. Its inverse is $V_i^{-1} = \\frac{1}{\\sigma^2(1-\\rho)}\\left(I_m - \\frac{\\rho}{1+(m-1)\\rho}\\mathbf{1}_m\\mathbf{1}_m^{\\top}\\right)$.\nThen,\n$$\n\\mathbf{1}_m^{\\top} V_i^{-1} \\mathbf{1}_m = \\frac{1}{\\sigma^2(1-\\rho)}\\left(\\mathbf{1}_m^{\\top}I_m\\mathbf{1}_m - \\frac{\\rho}{1+(m-1)\\rho}\\mathbf{1}_m^{\\top}\\mathbf{1}_m\\mathbf{1}_m^{\\top}\\mathbf{1}_m\\right)\n$$\n$$\n= \\frac{1}{\\sigma^2(1-\\rho)}\\left(m - \\frac{\\rho m^2}{1+(m-1)\\rho}\\right) = \\frac{m(1+(m-1)\\rho) - m^2\\rho}{\\sigma^2(1-\\rho)(1+(m-1)\\rho)}\n$$\n$$\n= \\frac{m+m^2\\rho-m\\rho - m^2\\rho}{\\sigma^2(1-\\rho)(1+(m-1)\\rho)} = \\frac{m(1-\\rho)}{\\sigma^2(1-\\rho)(1+(m-1)\\rho)} = \\frac{m}{\\sigma^2(1+(m-1)\\rho)}\n$$\nLet's call this scalar constant $W = \\frac{m}{\\sigma^2(1+(m-1)\\rho)}$. Since $m \\geq 2$ and $\\rho \\in (-1/(m-1), 1)$, the denominator is non-zero, so $W$ is a well-defined non-zero constant.\nThe population GEE becomes:\n$$\nE\\left[ \\begin{pmatrix} 1 \\\\ A_i \\end{pmatrix} W ((\\beta_0^{\\star} - \\beta_0) + (\\beta_1^{\\star} - \\beta_1) A_i + \\gamma Z_i) \\right] = 0\n$$\nSince $W$ is a non-zero constant, we can divide it out. This is the crucial step that demonstrates why the result does not depend on the working correlation parameter $\\rho$ (or the scale parameter $\\sigma^2$).\n$$\nE\\left[ \\begin{pmatrix} 1 \\\\ A_i \\end{pmatrix} ((\\beta_0^{\\star} - \\beta_0) + (\\beta_1^{\\star} - \\beta_1) A_i + \\gamma Z_i) \\right] = 0\n$$\nThis yields a system of two equations:\n1. $E\\left[ (\\beta_0^{\\star} - \\beta_0) + (\\beta_1^{\\star} - \\beta_1) A_i + \\gamma Z_i \\right] = 0$\n2. $E\\left[ A_i ((\\beta_0^{\\star} - \\beta_0) + (\\beta_1^{\\star} - \\beta_1) A_i + \\gamma Z_i) \\right] = 0$\n\nUsing the linearity of expectation, we get:\n1. $(\\beta_0^{\\star} - \\beta_0) + (\\beta_1^{\\star} - \\beta_1) E[A_i] + \\gamma E[Z_i] = 0$\n2. $(\\beta_0^{\\star} - \\beta_0) E[A_i] + (\\beta_1^{\\star} - \\beta_1) E[A_i^2] + \\gamma E[A_i Z_i] = 0$\n\nWe need to compute the expectations $E[Z_i]$, $E[A_i]$, $E[A_i^2]$, and $E[A_i Z_i]$.\nGiven $Z_i \\sim \\mathcal{N}(0, \\sigma_Z^2)$, we have $E[Z_i] = 0$ and $\\operatorname{Var}(Z_i) = E[Z_i^2] = \\sigma_Z^2$.\nGiven $A_i = \\delta Z_i + \\eta_i$ with $\\eta_i \\sim \\mathcal{N}(0, \\sigma_{\\eta}^2)$ and $Z_i, \\eta_i$ independent:\n- $E[A_i] = E[\\delta Z_i + \\eta_i] = \\delta E[Z_i] + E[\\eta_i] = \\delta(0) + 0 = 0$.\n- $E[A_i^2] = \\operatorname{Var}(A_i) + (E[A_i])^2 = \\operatorname{Var}(\\delta Z_i + \\eta_i) + 0^2 = \\delta^2 \\operatorname{Var}(Z_i) + \\operatorname{Var}(\\eta_i) = \\delta^2 \\sigma_Z^2 + \\sigma_{\\eta}^2$.\n- $E[A_i Z_i] = E[(\\delta Z_i + \\eta_i) Z_i] = E[\\delta Z_i^2 + \\eta_i Z_i] = \\delta E[Z_i^2] + E[\\eta_i]E[Z_i] = \\delta \\sigma_Z^2 + (0)(0) = \\delta \\sigma_Z^2$.\n\nSubstitute these expectations into the system of equations:\n1. $(\\beta_0^{\\star} - \\beta_0) + (\\beta_1^{\\star} - \\beta_1)(0) + \\gamma(0) = 0 \\implies \\beta_0^{\\star} - \\beta_0 = 0 \\implies \\beta_0 = \\beta_0^{\\star}$.\n   The intercept estimator is asymptotically unbiased.\n\n2. $(\\beta_0^{\\star} - \\beta_0)(0) + (\\beta_1^{\\star} - \\beta_1)E[A_i^2] + \\gamma E[A_i Z_i] = 0$\n   $(\\beta_1^{\\star} - \\beta_1) (\\delta^2 \\sigma_Z^2 + \\sigma_{\\eta}^2) + \\gamma (\\delta \\sigma_Z^2) = 0$.\n\nWe solve for $\\beta_1$, the asymptotic limit of $\\hat{\\beta}_1$:\n$(\\beta_1 - \\beta_1^{\\star}) (\\delta^2 \\sigma_Z^2 + \\sigma_{\\eta}^2) = \\gamma \\delta \\sigma_Z^2$.\n$\\beta_1 = \\beta_1^{\\star} + \\frac{\\gamma \\delta \\sigma_Z^2}{\\delta^2 \\sigma_Z^2 + \\sigma_{\\eta}^2}$.\n\nThe asymptotic limit $\\beta_1$ differs from the true parameter $\\beta_1^{\\star}$ due to the omitted confounder $Z_i$. The difference is non-zero as long as $\\gamma \\neq 0$ (confounder affects outcome), $\\delta \\neq 0$ (confounder affects exposure), and $\\sigma_Z^2 > 0$ (confounder has variance).\n\nThe asymptotic bias of $\\hat{\\beta}_1$ is defined as $\\operatorname{Bias}(\\hat{\\beta}_1) = \\lim_{n \\to \\infty} E(\\hat{\\beta}_1) - \\beta_1^{\\star} = \\beta_1 - \\beta_1^{\\star}$.\nFrom the previous equation, we obtain the closed-form expression for the bias:\n$$\n\\operatorname{Bias}(\\hat{\\beta}_1) = \\frac{\\gamma \\delta \\sigma_Z^2}{\\delta^2 \\sigma_Z^2 + \\sigma_{\\eta}^2}\n$$\nThis expression depends on the parameters governing the confounding structure ($\\gamma, \\delta, \\sigma_Z^2$) and the exposure model ($\\sigma_{\\eta}^2$), but is independent of the within-patient correlation $\\rho$ and error variance $\\sigma^2$. This independence is due to the specific structure of the GEE with an identity link and patient-level covariates, which causes the term containing $\\rho$ and $\\sigma^2$ to cancel from the population estimating equations.", "answer": "$$\n\\boxed{\\frac{\\gamma \\delta \\sigma_Z^2}{\\delta^2 \\sigma_Z^2 + \\sigma_{\\eta}^2}}\n$$", "id": "4964692"}]}