{"hands_on_practices": [{"introduction": "To effectively use Directed Acyclic Graphs, we must first master their grammar: the rules of d-separation. These rules allow us to determine which variables are conditionally independent of others simply by inspecting the graph's structure. This first exercise provides practice with a fundamental and often counter-intuitive aspect of d-separationâ€”the behavior of a collider, where two arrows meet head-to-head. [@problem_id:4557701]", "problem": "In a causal analysis for medical data, consider a Directed Acyclic Graph (DAG) representing a simplified pathway in translational bioinformatics where $X$ denotes a genetic variant, $Y$ denotes an environmental exposure, $Z$ denotes a molecular biomarker, and $W$ denotes a downstream clinical outcome. The DAG has node set $\\{X, Y, Z, W\\}$ and directed edges $X \\to Z$, $Y \\to Z$, $Z \\to W$, and no other edges. Using the formal definition of $d$-separation in Directed Acyclic Graphs, proceed as follows:\n\n- Enumerate all simple paths (paths with no repeated nodes) between $X$ and $Y$.\n- For each simple path $p$ between $X$ and $Y$, let $I(p)$ be an indicator defined by $I(p) = 1$ if the path is blocked when conditioning on $Z$ under $d$-separation, and $I(p) = 0$ otherwise.\n- Define the quantity $D$ by\n$$\nD \\;=\\; \\prod_{p \\in \\mathcal{P}(X,Y)} I(p),\n$$\nwhere $\\mathcal{P}(X,Y)$ is the set of all simple paths between $X$ and $Y$.\n\nCompute the value of $D$. The final answer must be reported as a single real number. No rounding is required and no units are to be included in the final answer.", "solution": "The problem requires the computation of a quantity $D$ related to the concept of $d$-separation in a specified Directed Acyclic Graph (DAG). We must first validate the problem statement.\n\nThe problem provides the following givens:\n- A set of nodes $V = \\{X, Y, Z, W\\}$, representing a genetic variant ($X$), an environmental exposure ($Y$), a molecular biomarker ($Z$), and a clinical outcome ($W$).\n- A set of directed edges $E = \\{(X,Z), (Y,Z), (Z,W)\\}$, which correspond to the graphical structure $X \\to Z$, $Y \\to Z$, and $Z \\to W$.\n- The constraint that no other edges exist in the graph.\n- A definition for an indicator function $I(p)$ for any simple path $p$ between $X$ and $Y$. $I(p)=1$ if path $p$ is blocked by conditioning on $Z$, and $I(p)=0$ otherwise.\n- A definition for the quantity $D = \\prod_{p \\in \\mathcal{P}(X,Y)} I(p)$, where $\\mathcal{P}(X,Y)$ is the set of all simple paths between $X$ and $Y$.\n\nThe problem is scientifically grounded, as it uses standard, well-defined concepts from the theory of graphical models and causal inference, specifically DAGs and $d$-separation. The structure and variables are typical of a simplified model in bioinformatics. The problem is well-posed, with a fully specified graph and a clear objective. It is objective, complete, and contains no contradictions. Therefore, the problem is deemed valid and we may proceed with the solution.\n\nThe solution process involves three steps:\n1.  Identify the set of all simple paths between $X$ and $Y$, denoted $\\mathcal{P}(X,Y)$.\n2.  For each path in this set, determine if it is blocked by conditioning on $Z$.\n3.  Compute the value of $D$ based on these determinations.\n\nStep 1: Enumerate simple paths between $X$ and $Y$.\nA path in a graph is a sequence of nodes connected by edges, where the direction of the edges is disregarded for the purpose of path traversal. A simple path is one that does not contain repeated nodes.\nThe graph structure is given by the edges $X \\to Z$, $Y \\to Z$, and $Z \\to W$.\nTo find a path from $X$ to $Y$, we start at $X$. The only node adjacent to $X$ is $Z$. From $Z$, the adjacent nodes are $X$, $Y$, and $W$. To reach $Y$ without repeating nodes, the only possible next step from $Z$ is to $Y$.\nThus, there is exactly one simple path between $X$ and $Y$: the path $p_1 = (X, Z, Y)$.\nThe set of all simple paths is $\\mathcal{P}(X,Y) = \\{p_1\\}$.\n\nStep 2: Apply the rules of $d$-separation to the path $p_1$.\nThe path $p_1 = (X, Z, Y)$ consists of the edges $X \\to Z$ and $Y \\to Z$. When viewed as a segment of a path, this structure is $X \\to Z \\leftarrow Y$.\nIn the terminology of $d$-separation, the node $Z$ is a **collider** on this path, because two arrowheads meet at $Z$.\n\nThe rules for a path being blocked by a conditioning set $S$ are as follows:\nA path is blocked if it contains a node $N$ such that:\n(a) $N$ is a chain node ($\\to N \\to$) or a fork node ($\\leftarrow N \\to$) on the path, and $N \\in S$.\n(b) $N$ is a collider node ($\\to N \\leftarrow$) on the path, and neither $N$ nor any of its descendants are in $S$.\n\nWe are asked to determine if the path $p_1$ is blocked when conditioning on the set $S = \\{Z\\}$.\nThe path $p_1$ contains the collider node $Z$. We apply rule (b).\nFor the path to be blocked by the collider, the condition is that neither the collider itself ($Z$) nor any of its descendants must be in the conditioning set $S$.\nIn this case, the conditioning set is $S = \\{Z\\}$. The collider node $Z$ is itself in the conditioning set.\nTherefore, the condition for the path to be blocked is not met. A path that is not blocked is said to be open or unblocked.\nConditioning on a collider (or one of its descendants) opens the path of association.\nSo, the path $p_1$ is **not blocked** when conditioning on $Z$.\n\nStep 3: Compute the value of $D$.\nThe indicator function $I(p)$ is defined as $I(p)=1$ if the path $p$ is blocked, and $I(p)=0$ otherwise.\nFor our path $p_1$, since it is not blocked by conditioning on $Z$, the value of the indicator is $I(p_1) = 0$.\n\nThe quantity $D$ is the product of these indicator values over all simple paths between $X$ and $Y$.\n$$\nD = \\prod_{p \\in \\mathcal{P}(X,Y)} I(p)\n$$\nSince $\\mathcal{P}(X,Y) = \\{p_1\\}$, this product simplifies to:\n$$\nD = I(p_1)\n$$\nSubstituting the value we found for $I(p_1)$:\n$$\nD = 0\n$$\nThe final value is $0$.", "answer": "$$\\boxed{0}$$", "id": "4557701"}, {"introduction": "With the rules of d-separation in hand, we can move to one of the most critical applications of DAGs in medical research: identifying and controlling for confounding. This exercise challenges you to apply the backdoor criterion, a formal procedure for selecting a set of variables to adjust for in order to obtain an unbiased estimate of a causal effect. Choosing a valid adjustment set is a cornerstone of robust causal analysis. [@problem_id:4557728]", "problem": "In a bioinformatics and medical data analytics study, consider a causal model represented as a Directed Acyclic Graph (DAG) on variables $W$, $Z$, $X$, and $Y$, where $W$ denotes a baseline genomic variant, $Z$ denotes a proximal biomarker influenced by $W$, $X$ denotes a treatment assignment, and $Y$ denotes a clinical outcome. The causal structure is given by the directed edges $W \\to Z$, $W \\to X$, $Z \\to X$, $Z \\to Y$, and $X \\to Y$. Assume all variables are observed, and there are no additional arrows beyond those specified.\n\nUsing the fundamental definitions of $d$-separation and the backdoor criterion in causal inference, determine whether the sets $\\{Z,W\\}$, $\\{Z\\}$, and $\\{W\\}$ are valid adjustment sets for identifying the causal effect of $X$ on $Y$ under this DAG by analyzing blocked and unblocked backdoor paths. Let $N$ denote the number of these three candidate sets that satisfy the backdoor criterion. Your task is to compute $N$. Express your final answer as a single real-valued number. No rounding is required.", "solution": "We begin from the fundamental definitions used in causal directed acyclic graph analysis:\n\n1. The backdoor criterion for a set $\\mathcal{S}$ relative to an ordered pair $(X,Y)$ requires that (i) no element of $\\mathcal{S}$ is a descendant of $X$, and (ii) all backdoor paths from $X$ to $Y$, defined as paths that start with an arrow into $X$, are blocked by $\\mathcal{S}$.\n2. Under $d$-separation, a path is blocked if it contains a non-collider node that is conditioned on, or contains a collider node that is not conditioned on and none of whose descendants are conditioned on. A non-collider is a node on the path where the two arrows along the path do not both point into the node; a collider is a node where the two arrows along the path both point into the node.\n\nThe specified Directed Acyclic Graph (DAG) includes the edges $W \\to Z$, $W \\to X$, $Z \\to X$, $Z \\to Y$, and $X \\to Y$. We are interested in identifying the causal effect of $X$ on $Y$. We enumerate the backdoor paths from $X$ to $Y$, that is, paths from $X$ to $Y$ that start with an arrow into $X$.\n\nFrom the given edges, the parents of $X$ are $W$ and $Z$. Therefore, any backdoor path must begin $X \\leftarrow W$ or $X \\leftarrow Z$. Considering simple paths without node repetition, the relevant backdoor paths are:\n- Path $P_{1}$: $X \\leftarrow Z \\to Y$.\n- Path $P_{2}$: $X \\leftarrow W \\to Z \\to Y$.\n\nWe analyze blocking properties under candidate adjustment sets.\n\nFirst, we verify condition (i) of the backdoor criterion. The sets $\\{Z,W\\}$, $\\{Z\\}$, and $\\{W\\}$ contain only $W$ and $Z$, both of which are parents of $X$, hence neither is a descendant of $X$. Therefore, condition (i) holds for all three sets.\n\nWe now check condition (ii) for each set:\n\n- Set $\\{Z\\}$:\n  - On path $P_{1}: X \\leftarrow Z \\to Y$, the node $Z$ is a non-collider (the arrows along the path are $Z \\to X$ and $Z \\to Y$). Conditioning on $Z$ blocks $P_{1}$.\n  - On path $P_{2}: X \\leftarrow W \\to Z \\to Y$, the nodes $W$ and $Z$ are non-colliders along the path. Conditioning on $Z$ blocks $P_{2}$ at $Z$ (a non-collider being conditioned on).\n  Therefore, $\\{Z\\}$ blocks all backdoor paths and satisfies the backdoor criterion.\n\n- Set $\\{W\\}$:\n  - On path $P_{1}: X \\leftarrow Z \\to Y$, the node $Z$ is a non-collider and is not conditioned upon when adjusting for $W$ only. Hence $P_{1}$ remains unblocked under $\\{W\\}$.\n  - On path $P_{2}: X \\leftarrow W \\to Z \\to Y$, conditioning on $W$ blocks $P_{2}$ at $W$ (a non-collider being conditioned on).\n  Since $P_{1}$ remains open, $\\{W\\}$ fails to block all backdoor paths and does not satisfy the backdoor criterion.\n\n- Set $\\{Z,W\\}$:\n  - On path $P_{1}: X \\leftarrow Z \\to Y$, conditioning on $Z$ blocks $P_{1}$.\n  - On path $P_{2}: X \\leftarrow W \\to Z \\to Y$, conditioning on either $W$ or $Z$ suffices to block the path; with both conditioned, the path is certainly blocked.\n  Therefore, $\\{Z,W\\}$ blocks all backdoor paths and satisfies the backdoor criterion.\n\nSummarizing, $\\{Z\\}$ and $\\{Z,W\\}$ are valid adjustment sets, while $\\{W\\}$ is not. Letting\n$$\nN \\equiv \\mathbf{1}\\{\\{Z,W\\}\\ \\text{valid}\\} + \\mathbf{1}\\{\\{Z\\}\\ \\text{valid}\\} + \\mathbf{1}\\{\\{W\\}\\ \\text{valid}\\},\n$$\nwe have $\\mathbf{1}\\{\\{Z,W\\}\\ \\text{valid}\\} = 1$, $\\mathbf{1}\\{\\{Z\\}\\ \\text{valid}\\} = 1$, and $\\mathbf{1}\\{\\{W\\}\\ \\text{valid}\\} = 0$, hence $N = 1 + 1 + 0 = 2$.\n\nTherefore, the number of valid adjustment sets among the three candidates is $2$.", "answer": "$$\\boxed{2}$$", "id": "4557728"}, {"introduction": "While the previous exercise demonstrated how to remove bias by conditioning on confounders, this final practice explores a critical pitfall where conditioning can induce bias. Using a quantitative structural equation model, you will investigate the phenomenon of collider bias, where adjusting for a common effect of two variables creates a spurious association between them. This exercise illustrates why the choice of covariates for adjustment must be guided by the causal structure, not just statistical association. [@problem_id:4960221]", "problem": "A clinician triages patients to specialty care based on laboratory markers. Consider the Directed Acyclic Graph (DAG) where an unobserved inflammatory burden $L$ causes both the C-reactive protein $X$ and the erythrocyte sedimentation rate $Y$, and the triage decision $M$ is a function of $X$ and $Y$: $L \\rightarrow X$, $L \\rightarrow Y$, $X \\rightarrow M$, $Y \\rightarrow M$. In Structural Equation Model (SEM) form, assume joint Gaussian random variables and the following linear relations with independent noise terms:\n$$\nL \\sim \\mathcal{N}(0,1),\\quad e_{X} \\sim \\mathcal{N}(0,\\sigma_{X}^{2}),\\quad e_{Y} \\sim \\mathcal{N}(0,\\sigma_{Y}^{2}),\\quad e_{M} \\sim \\mathcal{N}(0,\\sigma_{M}^{2}),\n$$\n$$\nX = a\\,L + e_{X},\\quad Y = b\\,L + e_{Y},\\quad M = c_{X}\\,X + c_{Y}\\,Y + e_{M},\n$$\nwith parameters $a=1.2$, $b=1.0$, $\\sigma_{X}^{2}=0.5$, $\\sigma_{Y}^{2}=0.5$, $c_{X}=1.5$, $c_{Y}=1.2$, and $\\sigma_{M}^{2}=0.2$. This DAG encodes that $M$ is a collider on the path $X \\rightarrow M \\leftarrow Y$.\n\nStarting only from the definitions of Directed Acyclic Graphs (DAGs), colliders, and the properties of multivariate Gaussian distributions, determine the unconditional association between $X$ and $Y$ and the association between $X$ and $Y$ conditional on $M$. Use correlation as the measure of association. Then, define the magnitude of reversal as\n$$\n\\Delta \\equiv \\left| \\rho_{XY\\mid M} - \\rho_{XY} \\right|,\n$$\nwhere $\\rho_{XY}$ is the unconditional correlation and $\\rho_{XY\\mid M}$ is the correlation conditional on $M$. Compute $\\Delta$ for the given parameters. Round your final numeric answer to four significant figures.", "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It presents a standard problem in causal inference involving a linear Structural Equation Model (SEM) with Gaussian variables, commonly used to illustrate the phenomenon of collider bias. All necessary parameters and distributional assumptions are provided, and the task is to compute well-defined statistical quantities. Therefore, I will proceed with a full solution.\n\nThe problem requires the computation of the unconditional correlation $\\rho_{XY}$ and the conditional correlation $\\rho_{XY\\mid M}$. The variables $X$, $Y$, and $M$ are linear combinations of independent Gaussian random variables ($L, e_X, e_Y, e_M$), and as such, they form a multivariate Gaussian system. We can determine the correlations by calculating the relevant variances and covariances. All variables have a mean of $0$ since they are linear combinations of zero-mean variables.\n\nFirst, we calculate the unconditional variances and covariance of $X$ and $Y$.\nThe variance of $X$ is given by:\n$$\n\\mathrm{Var}(X) = \\mathrm{Var}(aL + e_{X})\n$$\nSince $L$ and $e_X$ are independent, we have:\n$$\n\\mathrm{Var}(X) = a^2\\mathrm{Var}(L) + \\mathrm{Var}(e_{X}) = a^2(1) + \\sigma_{X}^{2}\n$$\nSubstituting the given parameter values, $a=1.2$ and $\\sigma_{X}^{2}=0.5$:\n$$\n\\mathrm{Var}(X) = (1.2)^2 + 0.5 = 1.44 + 0.5 = 1.94\n$$\nSimilarly, the variance of $Y$ is:\n$$\n\\mathrm{Var}(Y) = \\mathrm{Var}(bL + e_{Y}) = b^2\\mathrm{Var}(L) + \\mathrm{Var}(e_{Y}) = b^2(1) + \\sigma_{Y}^{2}\n$$\nSubstituting the given parameter values, $b=1.0$ and $\\sigma_{Y}^{2}=0.5$:\n$$\n\\mathrm{Var}(Y) = (1.0)^2 + 0.5 = 1.0 + 0.5 = 1.5\n$$\nThe covariance of $X$ and $Y$ is:\n$$\n\\mathrm{Cov}(X, Y) = \\mathrm{Cov}(aL + e_{X}, bL + e_{Y})\n$$\nBy the bilinearity of covariance and the independence of $L$, $e_X$, and $e_Y$:\n$$\n\\mathrm{Cov}(X, Y) = ab\\,\\mathrm{Cov}(L, L) + a\\,\\mathrm{Cov}(L, e_Y) + b\\,\\mathrm{Cov}(e_X, L) + \\mathrm{Cov}(e_X, e_Y) = ab\\,\\mathrm{Var}(L) = ab\n$$\nSubstituting the given parameter values, $a=1.2$ and $b=1.0$:\n$$\n\\mathrm{Cov}(X, Y) = (1.2)(1.0) = 1.2\n$$\nThe unconditional correlation $\\rho_{XY}$ is the ratio of the covariance to the product of the standard deviations:\n$$\n\\rho_{XY} = \\frac{\\mathrm{Cov}(X, Y)}{\\sqrt{\\mathrm{Var}(X)\\mathrm{Var}(Y)}} = \\frac{1.2}{\\sqrt{(1.94)(1.5)}} = \\frac{1.2}{\\sqrt{2.91}}\n$$\nNumerically, this is $\\rho_{XY} \\approx 0.70345$.\n\nNext, we determine the association between $X$ and $Y$ conditional on $M$. The conditional correlation $\\rho_{XY\\mid M}$ is given by the formula for partial correlation in a multivariate Gaussian distribution:\n$$\n\\rho_{XY\\mid M} = \\frac{\\mathrm{Cov}(X, Y \\mid M)}{\\sqrt{\\mathrm{Var}(X \\mid M)\\mathrm{Var}(Y \\mid M)}}\n$$\nThe terms of this expression are given by:\n$$\n\\mathrm{Var}(X \\mid M) = \\mathrm{Var}(X) - \\frac{\\mathrm{Cov}(X, M)^2}{\\mathrm{Var}(M)}\n$$\n$$\n\\mathrm{Var}(Y \\mid M) = \\mathrm{Var}(Y) - \\frac{\\mathrm{Cov}(Y, M)^2}{\\mathrm{Var}(M)}\n$$\n$$\n\\mathrm{Cov}(X, Y \\mid M) = \\mathrm{Cov}(X, Y) - \\frac{\\mathrm{Cov}(X, M)\\mathrm{Cov}(Y, M)}{\\mathrm{Var}(M)}\n$$\nWe must first compute the moments involving $M$.\nThe covariance between $X$ and $M$:\n$$\n\\mathrm{Cov}(X, M) = \\mathrm{Cov}(X, c_X X + c_Y Y + e_M) = c_X\\mathrm{Var}(X) + c_Y\\mathrm{Cov}(X, Y) + \\mathrm{Cov}(X, e_M)\n$$\nSince $X=aL+e_X$, $X$ is independent of $e_M$, so $\\mathrm{Cov}(X, e_M) = 0$.\n$$\n\\mathrm{Cov}(X, M) = c_X\\mathrm{Var}(X) + c_Y\\mathrm{Cov}(X, Y) = (1.5)(1.94) + (1.2)(1.2) = 2.91 + 1.44 = 4.35\n$$\nThe covariance between $Y$ and $M$:\n$$\n\\mathrm{Cov}(Y, M) = \\mathrm{Cov}(Y, c_X X + c_Y Y + e_M) = c_X\\mathrm{Cov}(Y, X) + c_Y\\mathrm{Var}(Y) + \\mathrm{Cov}(Y, e_M)\n$$\nSince $Y=bL+e_Y$, $Y$ is independent of $e_M$, so $\\mathrm{Cov}(Y, e_M) = 0$.\n$$\n\\mathrm{Cov}(Y, M) = c_X\\mathrm{Cov}(X, Y) + c_Y\\mathrm{Var}(Y) = (1.5)(1.2) + (1.2)(1.5) = 1.8 + 1.8 = 3.6\n$$\nThe variance of $M$:\n$$\n\\mathrm{Var}(M) = \\mathrm{Var}(c_X X + c_Y Y + e_M)\n$$\nSince $X$ and $Y$ are functions of $L, e_X, e_Y$, they are independent of $e_M$.\n$$\n\\mathrm{Var}(M) = \\mathrm{Var}(c_X X + c_Y Y) + \\mathrm{Var}(e_M) = c_X^2\\mathrm{Var}(X) + c_Y^2\\mathrm{Var}(Y) + 2c_X c_Y \\mathrm{Cov}(X, Y) + \\sigma_M^2\n$$\nSubstituting the numerical values:\n$$\n\\mathrm{Var}(M) = (1.5^2)(1.94) + (1.2^2)(1.5) + 2(1.5)(1.2)(1.2) + 0.2\n$$\n$$\n\\mathrm{Var}(M) = (2.25)(1.94) + (1.44)(1.5) + (3.6)(1.2) + 0.2 = 4.365 + 2.16 + 4.32 + 0.2 = 11.045\n$$\nNow we can compute the conditional variances and covariance:\n$$\n\\mathrm{Cov}(X, Y \\mid M) = 1.2 - \\frac{(4.35)(3.6)}{11.045} = 1.2 - \\frac{15.66}{11.045} \\approx 1.2 - 1.417836 = -0.217836\n$$\n$$\n\\mathrm{Var}(X \\mid M) = 1.94 - \\frac{(4.35)^2}{11.045} = 1.94 - \\frac{18.9225}{11.045} \\approx 1.94 - 1.713255 = 0.226745\n$$\n$$\n\\mathrm{Var}(Y \\mid M) = 1.5 - \\frac{(3.6)^2}{11.045} = 1.5 - \\frac{12.96}{11.045} \\approx 1.5 - 1.173382 = 0.326618\n$$\nNow, we compute the conditional correlation $\\rho_{XY\\mid M}$:\n$$\n\\rho_{XY\\mid M} \\approx \\frac{-0.217836}{\\sqrt{(0.226745)(0.326618)}} = \\frac{-0.217836}{\\sqrt{0.074059}} \\approx \\frac{-0.217836}{0.272138} \\approx -0.80046\n$$\nThe problem asks for the magnitude of reversal, $\\Delta = \\left| \\rho_{XY\\mid M} - \\rho_{XY} \\right|$.\n$$\n\\Delta \\approx \\left| -0.80046 - 0.70345 \\right| = \\left| -1.50391 \\right| = 1.50391\n$$\nRounding to four significant figures, we get $1.504$.\n\nThe unconditional correlation $\\rho_{XY}$ is positive, reflecting the common cause $L$. The conditional correlation $\\rho_{XY\\mid M}$ is negative. This sign reversal is a classic example of collider bias. Conditioning on the common effect $M$ of two variables $X$ and $Y$ induces an association between them, which in this case is negative and strong enough to overwhelm the initial positive association.", "answer": "$$\\boxed{1.504}$$", "id": "4960221"}]}