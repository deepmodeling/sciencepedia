{"hands_on_practices": [{"introduction": "This first exercise provides a foundational link between the abstract counterfactual framework and applied statistical estimation. We begin with the ideal scenario of a randomized clinical trial, where assumptions like exchangeability allow for the direct identification of the Average Treatment Effect (ATE). This practice will guide you through using a Bayesian approach to estimate this effect, demonstrating how prior knowledge can be formally combined with trial data to produce a posterior distribution for the causal estimand of interest [@problem_id:4987069].", "problem": "In a randomized clinical trial evaluating a new immunomodulatory therapy for adult patients with septic shock, let $A \\in \\{0,1\\}$ denote treatment assignment, with $A=1$ indicating receipt of the new therapy and $A=0$ indicating standard care. Let $Y \\in \\{0,1\\}$ denote the indicator of $30$-day mortality, where $Y=1$ indicates death by $30$ days. Adopt the potential outcomes framework, where each patient has well-defined potential outcomes $Y(1)$ and $Y(0)$ corresponding to their mortality outcomes under treatment and control, respectively. Assume the Stable Unit Treatment Value Assumption (SUTVA), consistency (i.e., $Y = Y(A)$), and that randomization ensures exchangeability and positivity.\n\nDefine the Average Treatment Effect (ATE) on the probability of death as\n$$\\tau = \\mathbb{E}\\big[Y(1) - Y(0)\\big].$$\n\nSuppose a Bayesian causal model is specified for the arm-specific death probabilities $p_1 = \\mathbb{P}(Y=1 \\mid A=1)$ and $p_0 = \\mathbb{P}(Y=1 \\mid A=0)$ with independent priors $p_1 \\sim \\mathrm{Beta}(\\alpha_1,\\beta_1)$ and $p_0 \\sim \\mathrm{Beta}(\\alpha_0,\\beta_0)$. Consider the following prior hyperparameters and observed data:\n- Prior hyperparameters: $\\alpha_1 = 3$, $\\beta_1 = 12$; $\\alpha_0 = 4$, $\\beta_0 = 11$.\n- Observed counts: in the treatment arm, $y_1 = 68$ deaths out of $n_1 = 320$ patients; in the control arm, $y_0 = 88$ deaths out of $n_0 = 300$ patients.\n\nStarting from the counterfactual definitions and identification under randomization and SUTVA, and using the Bayesian model above, derive the posterior expectation $\\mathbb{E}[\\tau \\mid \\text{data}]$ and compute its numerical value under the specified priors and data. Express your final answer as a decimal, rounded to four significant figures. Do not use a percentage sign.", "solution": "The problem is valid as it is scientifically grounded in the potential outcomes framework for causal inference and standard Bayesian statistical modeling. It is well-posed, objective, and contains all necessary information to derive a unique solution.\n\nThe objective is to compute the posterior expectation of the Average Treatment Effect (ATE), denoted $\\mathbb{E}[\\tau \\mid \\text{data}]$. The ATE, $\\tau$, is defined in the counterfactual framework as:\n$$\n\\tau = \\mathbb{E}\\big[Y(1) - Y(0)\\big]\n$$\nwhere $Y(1)$ and $Y(0)$ are the potential outcomes for an individual under treatment and control, respectively.\n\nBy the linearity of expectation, the ATE can be expressed as the difference in the marginal expectations of the potential outcomes:\n$$\n\\tau = \\mathbb{E}\\big[Y(1)\\big] - \\mathbb{E}\\big[Y(0)\\big]\n$$\nSince $Y(a)$ for $a \\in \\{0, 1\\}$ is a binary indicator variable, its expectation is equal to the probability of the event it indicates:\n$$\n\\mathbb{E}\\big[Y(a)\\big] = \\mathbb{P}(Y(a)=1)\n$$\nThus, the ATE is the difference in the marginal probabilities of death under treatment and control:\n$$\n\\tau = \\mathbb{P}(Y(1)=1) - \\mathbb{P}(Y(0)=1)\n$$\nThe problem states that the study is a randomized clinical trial, which ensures exchangeability. Exchangeability means that the potential outcomes are independent of treatment assignment, i.e., $(Y(1), Y(0)) \\perp A$. This key assumption allows us to identify the marginal probabilities of the potential outcomes from the conditional probabilities of the observed outcome given treatment. Specifically, for $a \\in \\{0, 1\\}$:\n$$\n\\mathbb{P}(Y(a)=1) = \\mathbb{P}(Y(a)=1 \\mid A=a)\n$$\nUsing the consistency assumption, which states that $Y = Y(A)$ (the observed outcome for an individual is the potential outcome corresponding to the treatment they actually received), we have:\n$$\n\\mathbb{P}(Y(a)=1 \\mid A=a) = \\mathbb{P}(Y=1 \\mid A=a)\n$$\nThese are the arm-specific probabilities of death, which are denoted as $p_1 = \\mathbb{P}(Y=1 \\mid A=1)$ and $p_0 = \\mathbb{P}(Y=1 \\mid A=0)$. Therefore, under the stated assumptions, the causal ATE is identified by the difference in these observable conditional probabilities:\n$$\n\\tau = p_1 - p_0\n$$\nIn the Bayesian framework, $p_1$ and $p_0$ are treated as random variables. The quantity of interest is the posterior expectation of $\\tau$ given the observed data:\n$$\n\\mathbb{E}[\\tau \\mid \\text{data}] = \\mathbb{E}[p_1 - p_0 \\mid \\text{data}]\n$$\nBy linearity of expectation, this becomes:\n$$\n\\mathbb{E}[\\tau \\mid \\text{data}] = \\mathbb{E}[p_1 \\mid \\text{data}] - \\mathbb{E}[p_0 \\mid \\text{data}]\n$$\nThe problem specifies a Beta-Binomial conjugate model. For each arm $a \\in \\{0, 1\\}$, the number of deaths $y_a$ among $n_a$ patients is assumed to follow a Binomial distribution given the probability $p_a$:\n$$\ny_a \\mid p_a \\sim \\mathrm{Binomial}(n_a, p_a)\n$$\nThe prior for the probability $p_a$ is a Beta distribution:\n$$\np_a \\sim \\mathrm{Beta}(\\alpha_a, \\beta_a)\n$$\nDue to the conjugacy of the Beta prior and the Binomial likelihood, the posterior distribution for $p_a$ after observing $y_a$ deaths in $n_a$ patients is also a Beta distribution with updated parameters:\n$$\np_a \\mid y_a, n_a \\sim \\mathrm{Beta}(\\alpha_a + y_a, \\beta_a + n_a - y_a)\n$$\nFor the treatment arm ($A=1$), the prior is $p_1 \\sim \\mathrm{Beta}(\\alpha_1, \\beta_1)$ with $\\alpha_1=3$ and $\\beta_1=12$. The observed data are $y_1=68$ deaths out of $n_1=320$ patients. The posterior distribution for $p_1$ is:\n$$\np_1 \\mid \\text{data} \\sim \\mathrm{Beta}(3 + 68, 12 + 320 - 68) = \\mathrm{Beta}(71, 264)\n$$\nFor the control arm ($A=0$), the prior is $p_0 \\sim \\mathrm{Beta}(\\alpha_0, \\beta_0)$ with $\\alpha_0=4$ and $\\beta_0=11$. The observed data are $y_0=88$ deaths out of $n_0=300$ patients. The posterior distribution for $p_0$ is:\n$$\np_0 \\mid \\text{data} \\sim \\mathrm{Beta}(4 + 88, 11 + 300 - 88) = \\mathrm{Beta}(92, 223)\n$$\nThe expectation of a random variable $X$ following a Beta distribution, $X \\sim \\mathrm{Beta}(\\alpha, \\beta)$, is given by $\\mathbb{E}[X] = \\frac{\\alpha}{\\alpha + \\beta}$. We use this to find the posterior expectations of $p_1$ and $p_0$.\nThe posterior expectation of $p_1$ is:\n$$\n\\mathbb{E}[p_1 \\mid \\text{data}] = \\frac{71}{71 + 264} = \\frac{71}{335}\n$$\nThe posterior expectation of $p_0$ is:\n$$\n\\mathbb{E}[p_0 \\mid \\text{data}] = \\frac{92}{92 + 223} = \\frac{92}{315}\n$$\nFinally, we compute the posterior expectation of the ATE:\n$$\n\\mathbb{E}[\\tau \\mid \\text{data}] = \\mathbb{E}[p_1 \\mid \\text{data}] - \\mathbb{E}[p_0 \\mid \\text{data}] = \\frac{71}{335} - \\frac{92}{315}\n$$\nNow, we compute the numerical value:\n$$\n\\frac{71}{335} \\approx 0.2119402985...\n$$\n$$\n\\frac{92}{315} \\approx 0.2920634920...\n$$\n$$\n\\mathbb{E}[\\tau \\mid \\text{data}] \\approx 0.2119402985 - 0.2920634920 = -0.0801231935...\n$$\nRounding this result to four significant figures gives $-0.08012$.\nThis negative value suggests that, based on the model, the data, and the priors, the new therapy is associated with a decrease in the probability of $30$-day mortality compared to standard care.", "answer": "$$\n\\boxed{-0.08012}\n$$", "id": "4987069"}, {"introduction": "Real-world trials often face complications such as non-compliance, where participants do not adhere to their assigned treatment. This exercise introduces principal stratification, a powerful concept for defining causal effects in such settings. By classifying individuals based on their potential adherence behavior, we can move beyond the simple intention-to-treat analysis to identify the Local Average Treatment Effect (LATE)—the effect for the subpopulation of \"compliers\"—using the logic of instrumental variables [@problem_id:4987082].", "problem": "A randomized inpatient study evaluates whether initiating a prophylactic antiviral reduces the probability of polymerase chain reaction confirmed respiratory infection by day $30$. Let $Z \\in \\{0,1\\}$ denote the randomized assignment, where $Z=1$ indicates being offered immediate initiation and $Z=0$ indicates usual care. Let $D(z) \\in \\{0,1\\}$ denote the potential treatment uptake indicator under assignment $z$, where $D(z)=1$ means the patient would initiate the antiviral under assignment $z$. Let $Y(d) \\in \\{0,1\\}$ denote the potential outcome indicating infection by day $30$ if the patient were to have uptake $d$. The observed uptake is $D= D(Z)$, and the observed outcome is $Y = Y(D)$.\n\nAssume the following fundamentals:\n- Stable Unit Treatment Value Assumption (SUTVA): no interference between units and well-defined treatments, so observed variables equal their corresponding potential outcomes under the realized assignment and uptake, and there is only one version of uptake $d$.\n- Randomization: $Z$ is independent of all potential variables, so $Z \\perp \\{D(1), D(0), Y(1), Y(0)\\}$.\n- Exclusion restriction: assignment $Z$ affects $Y$ only through uptake $D$, so for any unit, if $D(1)=D(0)$ then $Y(1)=Y(0)$, equivalently $Y(z)=Y(D(z))$ for $z \\in \\{0,1\\}$.\n- Monotonicity: no defiers, so $D(1) \\ge D(0)$ almost surely.\n- Positivity and instrument relevance: $\\mathbb{P}(Z=1)0$, $\\mathbb{P}(Z=0)0$, and $\\mathbb{P}(D=1 \\mid Z=1) \\ne \\mathbb{P}(D=1 \\mid Z=0)$.\n\nDefine the principal stratum $G=(D(1),D(0))$ and let the complier stratum be those with $D(1)=1$ and $D(0)=0$. Consider the complier average causal effect, also known as the Local Average Treatment Effect (LATE), defined as $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right] = \\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)=1, D(0)=0 \\right]$.\n\nWhich of the following statements is correct under the assumptions above?\n\nA. The ratio $\\dfrac{\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]}{\\mathbb{E}[D \\mid Z=1] - \\mathbb{E}[D \\mid Z=0]}$ identifies $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right]$.\n\nB. The difference $\\mathbb{E}[Y \\mid D=1] - \\mathbb{E}[Y \\mid D=0]$ identifies $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right]$.\n\nC. The difference $\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]$ identifies $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right]$.\n\nD. The ratio $\\dfrac{\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]}{\\mathbb{E}[D \\mid Z=1] - \\mathbb{E}[D \\mid Z=0]}$ identifies $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)=1, D(0)=1 \\right]$.\n\nE. Under monotonicity alone, without exclusion restriction, the difference $\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]$ equals $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right]$.", "solution": "The problem statement describes a randomized controlled trial with imperfect compliance, a scenario where Instrumental Variable (IV) methods are applicable. The task is to identify the correct statement regarding the estimation of a causal effect under a set of specific assumptions.\n\n### Step 1: Extract Givens\n\nThe problem provides the following definitions and assumptions:\n-   **Randomized Assignment (Instrument):** $Z \\in \\{0,1\\}$, with $Z=1$ for offering treatment and $Z=0$ for usual care.\n-   **Potential Treatment Uptake:** $D(z) \\in \\{0,1\\}$, the uptake decision if assigned to group $z$.\n-   **Potential Outcome:** $Y(d) \\in \\{0,1\\}$, the outcome if uptake status is $d$.\n-   **Observed Variables:** $D = D(Z)$ is the observed uptake, and $Y = Y(D)$ is the observed outcome.\n-   **Stable Unit Treatment Value Assumption (SUTVA):** No interference between units and well-defined potential outcomes. This implies $D = D(Z)$ and $Y = Y(D(Z))$.\n-   **Randomization:** $Z \\perp \\{D(1), D(0), Y(1), Y(0)\\}$. The assignment $Z$ is statistically independent of all potential outcomes and potential uptakes.\n-   **Exclusion Restriction:** The assignment $Z$ affects the outcome $Y$ only through the uptake $D$. Formally, for any unit, if $D(1)=D(0)$, then $Y(1)=Y(0)$. An equivalent formulation is $Y(z) = Y(D(z))$ for $z \\in \\{0,1\\}$, where $Y(z)$ is the potential outcome under assignment $z$.\n-   **Monotonicity:** $D(1) \\ge D(0)$ for all units. This rules out the existence of \"defiers,\" i.e., units for whom $D(1)=0$ and $D(0)=1$.\n-   **Positivity and Instrument Relevance:** $\\mathbb{P}(Z=1)0$, $\\mathbb{P}(Z=0)0$, and $\\mathbb{P}(D=1 \\mid Z=1) \\ne \\mathbb{P}(D=1 \\mid Z=0)$.\n-   **Principal Stratum:** Defined by the pair of potential uptakes $G=(D(1),D(0))$.\n-   **Complier Stratum:** The subpopulation of units for whom $(D(1),D(0)) = (1,0)$, which is equivalent to $D(1)D(0)$ under monotonicity and binary uptake.\n-   **Causal Estimand of Interest:** The Complier Average Causal Effect (CACE) or Local Average Treatment Effect (LATE), defined as $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right]$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement is a standard, canonical formulation of instrumental variable analysis within the potential outcomes framework (also known as the Rubin Causal Model), as developed by Imbens and Angrist.\n\n-   **Scientifically Grounded:** The entire problem is rooted in established statistical and econometric theory for causal inference. The setup and assumptions are the standard ones required to identify the LATE.\n-   **Well-Posed:** The problem is clearly stated, with all necessary definitions and assumptions provided to derive a unique answer. The question asks for identification of a specific causal estimand, which is a well-defined mathematical problem.\n-   **Objective:** The problem is phrased using precise, formal mathematical notation and terminology, free from ambiguity or subjective content.\n\nAll subsidiary checks for invalidity are passed. The problem is not unsound, incomplete, contradictory, unrealistic, ill-posed, or trivial. The problem is a valid exercise in formal causal inference.\n\n### Step 3: Derivation and Option Evaluation\n\nWe are asked to determine which expression correctly identifies the Local Average Treatment Effect (LATE), $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right]$. We will analyze the expression in option A, commonly known as the IV estimand or Wald estimand, and then evaluate the other options.\n\nThe expression is $\\dfrac{\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]}{\\mathbb{E}[D \\mid Z=1] - \\mathbb{E}[D \\mid Z=0]}$.\n\n**Analysis of the Numerator: $\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]$**\n\nThis is the Intention-to-Treat (ITT) effect on the outcome $Y$.\n-   Using SUTVA, the observed outcome is $Y=Y(D(Z))$.\n-   So, $\\mathbb{E}[Y \\mid Z=1] = \\mathbb{E}[Y(D(1)) \\mid Z=1]$. By the randomization assumption, $Z$ is independent of potential outcomes, so $\\mathbb{E}[Y(D(1)) \\mid Z=1] = \\mathbb{E}[Y(D(1))]$.\n-   Similarly, $\\mathbb{E}[Y \\mid Z=0] = \\mathbb{E}[Y(D(0)) \\mid Z=0] = \\mathbb{E}[Y(D(0))]$.\n-   The numerator is thus $\\mathbb{E}[Y(D(1))] - \\mathbb{E}[Y(D(0))]$.\n\nWe partition the population by the principal strata $G=(D(1),D(0))$. Due to the monotonicity assumption ($D(1) \\ge D(0)$), the only possible strata are:\n-   **Always-Takers (AT):** $(D(1),D(0))=(1,1)$. Let their population proportion be $\\pi_{AT}$.\n-   **Compliers (CO):** $(D(1),D(0))=(1,0)$. Let their population proportion be $\\pi_{CO}$.\n-   **Never-Takers (NT):** $(D(1),D(0))=(0,0)$. Let their population proportion be $\\pi_{NT}$.\n\nUsing the law of total expectation, we can expand the numerator. The exclusion restriction, in the form $Y(z)=Y(D(z))$, is now critical.\n$$ \\mathbb{E}[Y(D(1))] = \\mathbb{E}[Y(D(1)) \\mid AT]\\pi_{AT} + \\mathbb{E}[Y(D(1)) \\mid CO]\\pi_{CO} + \\mathbb{E}[Y(D(1)) \\mid NT]\\pi_{NT} $$\nFor Always-Takers, $D(1)=1$, so $\\mathbb{E}[Y(D(1)) \\mid AT] = \\mathbb{E}[Y(1) \\mid AT]$.\nFor Compliers, $D(1)=1$, so $\\mathbb{E}[Y(D(1)) \\mid CO] = \\mathbb{E}[Y(1) \\mid CO]$.\nFor Never-Takers, $D(1)=0$, so $\\mathbb{E}[Y(D(1)) \\mid NT] = \\mathbb{E}[Y(0) \\mid NT]$.\n$$ \\Rightarrow \\mathbb{E}[Y(D(1))] = \\mathbb{E}[Y(1) \\mid AT]\\pi_{AT} + \\mathbb{E}[Y(1) \\mid CO]\\pi_{CO} + \\mathbb{E}[Y(0) \\mid NT]\\pi_{NT} $$\nSimilarly, for $\\mathbb{E}[Y(D(0))]$:\n$$ \\mathbb{E}[Y(D(0))] = \\mathbb{E}[Y(D(0)) \\mid AT]\\pi_{AT} + \\mathbb{E}[Y(D(0)) \\mid CO]\\pi_{CO} + \\mathbb{E}[Y(D(0)) \\mid NT]\\pi_{NT} $$\nFor Always-Takers, $D(0)=1$, so $\\mathbb{E}[Y(D(0)) \\mid AT] = \\mathbb{E}[Y(1) \\mid AT]$.\nFor Compliers, $D(0)=0$, so $\\mathbb{E}[Y(D(0)) \\mid CO] = \\mathbb{E}[Y(0) \\mid CO]$.\nFor Never-Takers, $D(0)=0$, so $\\mathbb{E}[Y(D(0)) \\mid NT] = \\mathbb{E}[Y(0) \\mid NT]$.\n$$ \\Rightarrow \\mathbb{E}[Y(D(0))] = \\mathbb{E}[Y(1) \\mid AT]\\pi_{AT} + \\mathbb{E}[Y(0) \\mid CO]\\pi_{CO} + \\mathbb{E}[Y(0) \\mid NT]\\pi_{NT} $$\nSubtracting the two expressions, the terms for AT and NT cancel out:\n$$ \\mathbb{E}[Y(D(1))] - \\mathbb{E}[Y(D(0))] = (\\mathbb{E}[Y(1) \\mid CO] - \\mathbb{E}[Y(0) \\mid CO])\\pi_{CO} $$\nThis is precisely $\\mathbb{E}[Y(1)-Y(0) \\mid D(1)D(0)] \\cdot \\mathbb{P}(D(1)D(0))$, or $LATE \\cdot \\pi_{CO}$.\n\n**Analysis of the Denominator: $\\mathbb{E}[D \\mid Z=1] - \\mathbb{E}[D \\mid Z=0]$**\n\nThis is the ITT effect on treatment uptake $D$.\n-   Using SUTVA, $D=D(Z)$.\n-   $\\mathbb{E}[D \\mid Z=1] = \\mathbb{E}[D(1) \\mid Z=1] = \\mathbb{E}[D(1)]$ by randomization. Since $D$ is binary, this is $\\mathbb{P}(D(1)=1)$.\n-   $\\mathbb{E}[D \\mid Z=0] = \\mathbb{E}[D(0) \\mid Z=0] = \\mathbb{E}[D(0)]$ by randomization. This is $\\mathbb{P}(D(0)=1)$.\n-   The denominator is $\\mathbb{P}(D(1)=1) - \\mathbb{P}(D(0)=1)$.\n\nExpanding over the strata:\n-   $\\mathbb{P}(D(1)=1) = \\mathbb{P}(D(1)=1 \\text{ and } G=AT) + \\mathbb{P}(D(1)=1 \\text{ and } G=CO) + \\mathbb{P}(D(1)=1 \\text{ and } G=NT) = \\pi_{AT} + \\pi_{CO}$.\n-   $\\mathbb{P}(D(0)=1) = \\mathbb{P}(D(0)=1 \\text{ and } G=AT) + \\mathbb{P}(D(0)=1 \\text{ and } G=CO) + \\mathbb{P}(D(0)=1 \\text{ and } G=NT) = \\pi_{AT}$.\n-   The denominator is $(\\pi_{AT} + \\pi_{CO}) - \\pi_{AT} = \\pi_{CO}$, which is the proportion of compliers, $\\mathbb{P}(D(1)D(0))$. The instrument relevance assumption ensures $\\pi_{CO} \\ne 0$.\n\n**Combining the Numerator and Denominator**\n\n$$ \\frac{\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]}{\\mathbb{E}[D \\mid Z=1] - \\mathbb{E}[D \\mid Z=0]} = \\frac{LATE \\cdot \\pi_{CO}}{\\pi_{CO}} = LATE $$\nThe ratio correctly identifies the Local Average Treatment Effect.\n\n**Option-by-Option Analysis**\n\n**A. The ratio $\\dfrac{\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]}{\\mathbb{E}[D \\mid Z=1] - \\mathbb{E}[D \\mid Z=0]}$ identifies $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right]$.**\n-   The derivation above confirms this statement. This is the central result of the LATE framework.\n-   **Verdict: Correct.**\n\n**B. The difference $\\mathbb{E}[Y \\mid D=1] - \\mathbb{E}[Y \\mid D=0]$ identifies $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right]$.**\n-   This is the \"as-treated\" or \"per-protocol\" estimator. It compares the average outcome among all who received treatment, $\\mathbb{E}[Y(1) \\mid D=1]$, to the average outcome among all who did not, $\\mathbb{E}[Y(0) \\mid D=0]$. The groups $\\{D=1\\}$ and $\\{D=0\\}$ are not randomized; they are formed by self-selection and are therefore likely to differ in ways other than treatment, leading to confounding. For example, the group with $D=1$ is a mix of compliers and always-takers, while the group with $D=0$ is a mix of compliers and never-takers. These groups are not directly comparable. This estimator is biased for the LATE.\n-   **Verdict: Incorrect.**\n\n**C. The difference $\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]$ identifies $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right]$.**\n-   This is the Intention-to-Treat (ITT) effect. As shown in our derivation of the numerator, $\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0] = LATE \\cdot \\pi_{CO}$. This is equal to LATE only if $\\pi_{CO}=1$, i.e., the entire population consists of compliers (perfect compliance). This is not true in general.\n-   **Verdict: Incorrect.**\n\n**D. The ratio $\\dfrac{\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]}{\\mathbb{E}[D \\mid Z=1] - \\mathbb{E}[D \\mid Z=0]}$ identifies $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)=1, D(0)=1 \\right]$.**\n-   The ratio identifies the LATE, which is the average treatment effect for compliers, i.e., $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)=1, D(0)=0 \\right]$. The expression on the right is the average treatment effect for Always-Takers. The IV estimand does not identify the effect for always-takers.\n-   **Verdict: Incorrect.**\n\n**E. Under monotonicity alone, without exclusion restriction, the difference $\\mathbb{E}[Y \\mid Z=1] - \\mathbb{E}[Y \\mid Z=0]$ equals $\\mathbb{E}\\!\\left[ Y(1)-Y(0) \\mid D(1)D(0) \\right]$.**\n-   This statement is incorrect for two reasons. First, as shown in the analysis of option C, the ITT difference equals $LATE \\cdot \\pi_{CO}$, not LATE. Second, the exclusion restriction is a necessary condition for this result. Without it, the ITT effect would be a mixture of the LATE and direct effects of the instrument $Z$ on the outcomes of always-takers and never-takers, which do not cancel out.\n-   **Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "4987082"}, {"introduction": "Even in a perfectly randomized trial, analytical choices can introduce significant bias. This practice explores the critical issue of collider-stratification bias, a common pitfall that arises from conditioning on a post-treatment variable. By working through a structural causal model, you will analytically derive the bias induced by this flawed adjustment, providing a concrete understanding of how it creates a spurious association between treatment and outcome and why it must be avoided in causal analysis [@problem_id:4987084].", "problem": "A randomized trial in critical care medicine evaluates the effect of a new anti-inflammatory therapy on day-$7$ C-reactive protein. Let $A \\in \\{0,1\\}$ denote treatment assignment, with $A=1$ indicating receipt of the therapy. Randomization is balanced, so $\\Pr(A=1)=\\Pr(A=0)=0.5$. Let $M$ be an early post-treatment biomarker measured $24$ hours after randomization, and let $Y$ be the day-$7$ log C-reactive protein outcome. Consider the potential outcomes framework, where $Y(a)$ denotes the outcome that would be observed under treatment level $a \\in \\{0,1\\}$, and $M(a)$ denotes the post-treatment biomarker under $a$. Assume the Stable Unit Treatment Value Assumption (SUTVA) holds and that randomization implies no unmeasured confounding of $A$ on potential outcomes.\n\nSuppose the data-generating mechanism is consistent with the following linear structural model, with independent components:\n- An unmeasured patient frailty $U$ with $U \\sim \\mathcal{N}(0,1)$.\n- A post-treatment biomarker equation $M = \\alpha A + \\beta U + \\varepsilon_{M}$, where $\\varepsilon_{M} \\sim \\mathcal{N}(0,\\sigma_{M}^{2})$ and is independent of $(A,U)$.\n- An outcome equation $Y = \\tau A + \\theta M + \\delta U + \\varepsilon_{Y}$, where $\\varepsilon_{Y} \\sim \\mathcal{N}(0,\\sigma_{Y}^{2})$ and is independent of $(A,U,\\varepsilon_{M})$.\n\nThe Directed Acyclic Graph (DAG) implied by the model has arrows $A \\to M \\to Y$, $A \\to Y$, and $U \\to M$, $U \\to Y$. Because $M$ is affected by both $A$ and $U$, $M$ is a collider on the path $A \\to M \\leftarrow U \\to Y$.\n\nA common but flawed analytic practice is to regress $Y$ on $A$ and $M$ and interpret the coefficient of $A$ as a causal effect of treatment. Let $\\beta_{A}$ denote the probability limit (large-sample limit) of the Ordinary Least Squares (OLS) coefficient on $A$ in the linear regression model $\\mathbb{E}[Y \\mid A, M] = \\beta_{0} + \\beta_{A} A + \\beta_{M} M$ fit to data generated by the model above.\n\nStarting from the counterfactual definitions and the structural model, derive $\\beta_{A}$ in closed form as a function of $(\\alpha, \\beta, \\tau, \\theta, \\delta, \\sigma_{M}^{2})$. Your final answer must be a single closed-form analytic expression. No rounding is required, and no units are needed.", "solution": "The problem is first validated to ensure it is self-contained, consistent, and scientifically sound.\n\n### Step 1: Extract Givens\n- Treatment assignment: $A \\in \\{0,1\\}$, with randomization $\\Pr(A=1)=\\Pr(A=0)=0.5$.\n- Unmeasured patient frailty: $U \\sim \\mathcal{N}(0,1)$.\n- Post-treatment biomarker: $M = \\alpha A + \\beta U + \\varepsilon_{M}$, where $\\varepsilon_{M} \\sim \\mathcal{N}(0,\\sigma_{M}^{2})$ and is independent of $(A,U)$.\n- Outcome: $Y = \\tau A + \\theta M + \\delta U + \\varepsilon_{Y}$, where $\\varepsilon_{Y} \\sim \\mathcal{N}(0,\\sigma_{Y}^{2})$ and is independent of $(A,U,\\varepsilon_{M})$.\n- Assumptions: Stable Unit Treatment Value Assumption (SUTVA) holds. Randomization implies $A$ is independent of $U$ and all potential outcomes (and their error terms).\n- Target quantity: The probability limit, $\\beta_A$, of the Ordinary Least Squares (OLS) coefficient on $A$ in the linear regression model $\\mathbb{E}[Y \\mid A, M] = \\beta_{0} + \\beta_{A} A + \\beta_{M} M$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard theoretical exercise in causal inference, using linear structural models and potential outcomes to illustrate collider-stratification bias. This is a core topic in statistics, econometrics, and epidemiology. The setup is scientifically and mathematically sound.\n- **Well-Posed:** The problem provides all necessary definitions, structural equations, and distributional assumptions to derive the target quantity, $\\beta_A$. A unique analytical solution can be determined.\n- **Objective:** The problem is stated in precise mathematical and statistical language, free of ambiguity or subjective claims.\n\nThe problem does not exhibit any of the invalidity flaws listed. The DAG structure described is consistent with the structural equations. The question asks for the derivation of a well-defined statistical quantity under a stylized, but coherent, model.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will be provided.\n\n### Solution Derivation\nThe target quantity, $\\beta_A$, is the probability limit of the OLS estimator for the coefficient of $A$ in a multiple linear regression of $Y$ on $A$ and $M$. The formula for this coefficient in a regression with two predictors is given by the population analogue of the OLS estimator:\n$$ \\beta_{A} = \\frac{\\text{Cov}(A, Y) \\text{Var}(M) - \\text{Cov}(M, Y) \\text{Cov}(A, M)}{\\text{Var}(A) \\text{Var}(M) - (\\text{Cov}(A, M))^2} $$\nWe must compute each variance and covariance term using the provided structural model and the properties of the random variables.\n\n1.  **Properties of the treatment assignment variable $A$:**\n    Since $A$ is a Bernoulli random variable with $\\Pr(A=1)=0.5$:\n    -   $\\mathbb{E}[A] = 1 \\cdot \\Pr(A=1) + 0 \\cdot \\Pr(A=0) = 0.5$.\n    -   $\\text{Var}(A) = \\mathbb{E}[A^2] - (\\mathbb{E}[A])^2 = (1^2 \\cdot 0.5 + 0^2 \\cdot 0.5) - (0.5)^2 = 0.5 - 0.25 = 0.25$.\n\n2.  **Express $Y$ in terms of exogenous variables:**\n    To simplify covariance calculations, we substitute the expression for $M$ into the equation for $Y$:\n    $$ Y = \\tau A + \\theta (\\alpha A + \\beta U + \\varepsilon_{M}) + \\delta U + \\varepsilon_{Y} $$\n    $$ Y = (\\tau + \\theta\\alpha) A + (\\theta\\beta + \\delta) U + \\theta\\varepsilon_{M} + \\varepsilon_{Y} $$\n\n3.  **Calculate Covariances and Variances:**\n    We use the property that $A$, $U$, $\\varepsilon_{M}$, and $\\varepsilon_{Y}$ are mutually independent. We also know $\\mathbb{E}[U]=0$, $\\mathbb{E}[\\varepsilon_M]=0$, $\\mathbb{E}[\\varepsilon_Y]=0$, $\\text{Var}(U)=1$, $\\text{Var}(\\varepsilon_M)=\\sigma_M^2$, and $\\text{Var}(\\varepsilon_Y)=\\sigma_Y^2$.\n\n    -   **$\\text{Cov}(A, M)$**:\n        $$ \\text{Cov}(A, M) = \\text{Cov}(A, \\alpha A + \\beta U + \\varepsilon_{M}) = \\alpha \\text{Cov}(A, A) + \\beta \\text{Cov}(A, U) + \\text{Cov}(A, \\varepsilon_{M}) $$\n        Since $A$ is independent of $U$ and $\\varepsilon_M$, $\\text{Cov}(A, U)=0$ and $\\text{Cov}(A, \\varepsilon_M)=0$.\n        $$ \\text{Cov}(A, M) = \\alpha \\text{Var}(A) = 0.25\\alpha $$\n\n    -   **$\\text{Var}(M)$**:\n        $$ \\text{Var}(M) = \\text{Var}(\\alpha A + \\beta U + \\varepsilon_{M}) $$\n        Due to independence of $A$, $U$, and $\\varepsilon_M$:\n        $$ \\text{Var}(M) = \\alpha^2 \\text{Var}(A) + \\beta^2 \\text{Var}(U) + \\text{Var}(\\varepsilon_{M}) = 0.25\\alpha^2 + \\beta^2 \\cdot 1 + \\sigma_{M}^{2} $$\n        $$ \\text{Var}(M) = 0.25\\alpha^2 + \\beta^2 + \\sigma_{M}^{2} $$\n\n    -   **$\\text{Cov}(A, Y)$**:\n        Using the expanded form of $Y$:\n        $$ \\text{Cov}(A, Y) = \\text{Cov}(A, (\\tau + \\theta\\alpha) A + (\\theta\\beta + \\delta) U + \\theta\\varepsilon_{M} + \\varepsilon_{Y}) $$\n        Due to independence of $A$ from $U, \\varepsilon_M, \\varepsilon_Y$:\n        $$ \\text{Cov}(A, Y) = (\\tau + \\theta\\alpha) \\text{Var}(A) = 0.25(\\tau + \\theta\\alpha) $$\n\n    -   **$\\text{Cov}(M, Y)$**:\n        Using the definitions of $M$ and the expanded form of $Y$:\n        $$ \\text{Cov}(M, Y) = \\text{Cov}(\\alpha A + \\beta U + \\varepsilon_{M}, (\\tau + \\theta\\alpha) A + (\\theta\\beta + \\delta) U + \\theta\\varepsilon_{M} + \\varepsilon_{Y}) $$\n        Expanding using the bilinearity of covariance and the mutual independence of $A, U, \\varepsilon_M, \\varepsilon_Y$:\n        $$ \\text{Cov}(M, Y) = \\text{Cov}(\\alpha A, (\\tau + \\theta\\alpha) A) + \\text{Cov}(\\beta U, (\\theta\\beta + \\delta) U) + \\text{Cov}(\\varepsilon_{M}, \\theta\\varepsilon_{M}) $$\n        All cross-term covariances are zero.\n        $$ \\text{Cov}(M, Y) = \\alpha(\\tau + \\theta\\alpha)\\text{Var}(A) + \\beta(\\theta\\beta + \\delta)\\text{Var}(U) + \\theta\\text{Var}(\\varepsilon_{M}) $$\n        $$ \\text{Cov}(M, Y) = \\alpha(\\tau + \\theta\\alpha)(0.25) + \\beta(\\theta\\beta + \\delta)(1) + \\theta\\sigma_{M}^{2} $$\n        $$ \\text{Cov}(M, Y) = 0.25\\alpha\\tau + 0.25\\theta\\alpha^2 + \\theta\\beta^2 + \\beta\\delta + \\theta\\sigma_{M}^{2} $$\n\n4.  **Assemble the expression for $\\beta_A$:**\n    First, let's compute the denominator of the main formula for $\\beta_A$:\n    $$ D = \\text{Var}(A) \\text{Var}(M) - (\\text{Cov}(A, M))^2 $$\n    $$ D = (0.25)(0.25\\alpha^2 + \\beta^2 + \\sigma_{M}^{2}) - (0.25\\alpha)^2 $$\n    $$ D = 0.0625\\alpha^2 + 0.25\\beta^2 + 0.25\\sigma_{M}^{2} - 0.0625\\alpha^2 $$\n    $$ D = 0.25(\\beta^2 + \\sigma_{M}^{2}) $$\n\n    Next, let's compute the numerator:\n    $$ N = \\text{Cov}(A, Y) \\text{Var}(M) - \\text{Cov}(M, Y) \\text{Cov}(A, M) $$\n    $$ N = [0.25(\\tau + \\theta\\alpha)][0.25\\alpha^2 + \\beta^2 + \\sigma_{M}^{2}] - [0.25\\alpha\\tau + 0.25\\theta\\alpha^2 + \\theta\\beta^2 + \\beta\\delta + \\theta\\sigma_{M}^{2}][0.25\\alpha] $$\n    We can factor out $0.25$ from the entire expression:\n    $$ N = 0.25 \\left( (\\tau + \\theta\\alpha)(0.25\\alpha^2 + \\beta^2 + \\sigma_{M}^{2}) - \\alpha(0.25\\alpha\\tau + 0.25\\theta\\alpha^2 + \\theta\\beta^2 + \\beta\\delta + \\theta\\sigma_{M}^{2}) \\right) $$\n    Expanding the terms inside the parentheses:\n    $$ (\\tau + \\theta\\alpha)(\\dots) = 0.25\\alpha^2\\tau + \\beta^2\\tau + \\sigma_M^2\\tau + 0.25\\alpha^3\\theta + \\alpha\\beta^2\\theta + \\alpha\\sigma_M^2\\theta $$\n    $$ -\\alpha(\\dots) = -0.25\\alpha^2\\tau - 0.25\\alpha^3\\theta - \\alpha\\beta^2\\theta - \\alpha\\beta\\delta - \\alpha\\sigma_M^2\\theta $$\n    Adding these two expansions, several terms cancel out:\n    - $0.25\\alpha^2\\tau$ cancels with $-0.25\\alpha^2\\tau$.\n    - $0.25\\alpha^3\\theta$ cancels with $-0.25\\alpha^3\\theta$.\n    - $\\alpha\\beta^2\\theta$ cancels with $-\\alpha\\beta^2\\theta$.\n    - $\\alpha\\sigma_M^2\\theta$ cancels with $-\\alpha\\sigma_M^2\\theta$.\n    The remaining terms are $\\beta^2\\tau + \\sigma_M^2\\tau - \\alpha\\beta\\delta = \\tau(\\beta^2 + \\sigma_M^2) - \\alpha\\beta\\delta$.\n    So, the numerator is:\n    $$ N = 0.25(\\tau(\\beta^2 + \\sigma_{M}^{2}) - \\alpha\\beta\\delta) $$\n\n    Finally, we compute the ratio $\\beta_A = N/D$:\n    $$ \\beta_A = \\frac{0.25(\\tau(\\beta^2 + \\sigma_{M}^{2}) - \\alpha\\beta\\delta)}{0.25(\\beta^2 + \\sigma_{M}^{2})} $$\n    $$ \\beta_A = \\frac{\\tau(\\beta^2 + \\sigma_{M}^{2}) - \\alpha\\beta\\delta}{\\beta^2 + \\sigma_{M}^{2}} $$\n    This can be simplified to:\n    $$ \\beta_A = \\tau - \\frac{\\alpha\\beta\\delta}{\\beta^2 + \\sigma_{M}^{2}} $$\n    This expression reveals that the OLS coefficient $\\beta_A$ is the sum of the direct causal effect of $A$ on $Y$ ($\\tau$) and a bias term. This bias, $-\\frac{\\alpha\\beta\\delta}{\\beta^2 + \\sigma_{M}^{2}}$, arises because regression conditioning on the biomarker $M$ opens a spurious path between the treatment $A$ and the outcome $Y$ through the unmeasured confounder $U$. This phenomenon is known as collider-stratification bias.", "answer": "$$\\boxed{\\tau - \\frac{\\alpha\\beta\\delta}{\\beta^2 + \\sigma_{M}^{2}}}$$", "id": "4987084"}]}