## Introduction
The gold standard for establishing causality is the randomized controlled trial (RCT), but in many real-world settings—especially in medicine, public health, and the social sciences—randomization is not feasible or ethical. We are often left with observational data where treatment assignment is not random, leading to a significant challenge: [confounding bias](@entry_id:635723). How can we draw reliable causal conclusions about a treatment's effect when the groups receiving and not receiving it differ systematically on key baseline characteristics? Answering this question requires statistical methods that can adjust for these differences, effectively emulating the balance that randomization provides.

This article introduces Propensity Score Matching (PSM) as a powerful framework to address this challenge. In the first chapter, **"Principles and Mechanisms,"** we will delve into the foundational assumptions for causal inference, explore the propensity score as a [dimensionality reduction](@entry_id:142982) tool, and detail the methods for estimating causal effects. The second chapter, **"Applications and Interdisciplinary Connections,"** will demonstrate the versatility of PSM across various fields, from comparative effectiveness research in medicine to program evaluation in sociology and ecology. Finally, **"Hands-On Practices"** will offer practical exercises to solidify your understanding of these core concepts. We begin by laying the theoretical groundwork, exploring the principles that allow us to move from observed associations to causal estimates.

## Principles and Mechanisms

To estimate causal effects from observational data, we must bridge the gap between the real-world data we collect and the counterfactual outcomes we wish to understand. This requires a rigorous theoretical framework built upon a set of core principles and assumptions. This chapter elucidates these foundational principles, introduces the [propensity score](@entry_id:635864) as a central tool for satisfying them, and details the mechanisms through which causal effects are estimated and validated.

### Foundational Assumptions for Causal Inference

The primary challenge of causal inference is that for any individual, we can only observe the outcome under the treatment they actually received. We can never simultaneously observe their outcome had they received an alternative treatment. To identify causal effects such as the Average Treatment Effect (ATE), defined as $E[Y(1) - Y(0)]$, where $Y(1)$ and $Y(0)$ are the potential outcomes under treatment and control, we must rely on a set of untestable assumptions that link the unobserved potential outcomes to the observed data $(Y, A, X)$, where $Y$ is the observed outcome, $A$ is the treatment indicator, and $X$ is a vector of pre-treatment covariates.

The standard set of assumptions comprises the Stable Unit Treatment Value Assumption (SUTVA) and strong ignorability.

**Stable Unit Treatment Value Assumption (SUTVA)**
SUTVA is a foundational assumption that posits a well-defined and stable relationship between treatment assignment and outcomes. It consists of two distinct components:
1.  **No Interference**: The potential outcomes for any given individual are not affected by the treatment assignments of other individuals. This means, for instance, that a patient's health outcome does not depend on whether their neighbor received the same or a different medication.
2.  **Consistency**: An individual's observed outcome under a specific treatment is the same as their potential outcome under that same treatment. Formally, if a unit receives treatment $A=a$, then their observed outcome $Y$ is equal to $Y(a)$. This is often written compactly as $Y = Y(A)$. This assumption rules out hidden versions of the treatment; for example, it assumes that "treatment" is administered in the same way to all who receive it.

**Strong Ignorability**
Strong ignorability is the crucial assumption that allows us to use observational data to emulate a randomized experiment. It asserts that after accounting for the measured pre-treatment covariates $X$, treatment assignment is effectively random. Like SUTVA, it has two components:
1.  **Conditional Exchangeability (or Unconfoundedness)**: Conditional on the vector of covariates $X$, treatment assignment $A$ is independent of the potential outcomes $(Y(0), Y(1))$. This is formally stated as $(Y(0), Y(1)) \perp A \mid X$. This is the primary assumption for controlling [confounding bias](@entry_id:635723). It implies that within any stratum of individuals defined by a specific set of covariate values $X=x$, the group that received the treatment and the group that did not are, on average, comparable with respect to their potential outcomes. For this to be plausible, the set of covariates $X$ must be sufficiently "rich" to include all common causes of the treatment and the outcome.
2.  **Positivity (or Overlap)**: For every combination of covariates $X=x$ present in the population, there is a non-zero probability of receiving any given treatment level. For a binary treatment, this means $0 \lt \mathbb{P}(A=1 \mid X=x) \lt 1$ for all $x$ in the support of $X$. This assumption ensures that for any type of individual (as defined by their characteristics $X$), a comparison between treated and untreated subjects is theoretically possible. A violation of positivity, for instance if $\mathbb{P}(A=1 \mid X=x) = 1$ for a certain subpopulation, means that no individuals with characteristics $x$ were left untreated. In this case, the counterfactual outcome $Y(0)$ for this subpopulation is unobservable, and the causal effect cannot be identified from the data. This assumption is critical for the mechanics of methods like [inverse probability](@entry_id:196307) weighting, where weights like $1/(1-e(X))$ would become undefined if the propensity score $e(X) = \mathbb{P}(A=1 \mid X)$ were equal to 1. [@problem_id:4830500]

Under these assumptions, we can identify the ATE. The derivation proceeds by the law of [iterated expectations](@entry_id:169521):
$$ E[Y(1)] = E_X[E[Y(1) \mid X]] $$
By conditional exchangeability, $E[Y(1) \mid X] = E[Y(1) \mid A=1, X]$. By consistency, for those who received the treatment ($A=1$), $Y(1)$ is simply their observed outcome $Y$. Therefore, $E[Y(1) \mid A=1, X] = E[Y \mid A=1, X]$. This links the unobserved potential outcome to an observable quantity. A symmetric argument applies to $E[Y(0)]$. The identified ATE is thus:
$$ \text{ATE} = E_X \left\{ E[Y \mid A=1, X] - E[Y \mid A=0, X] \right\} $$
This quantity is estimable from the observed data, and propensity score methods are statistical techniques designed to estimate it. [@problem_id:4830481]

### The Propensity Score: A Dimensionality Reduction Tool

The identification formula requires conditioning on the full vector of covariates $X$. In practice, $X$ can be high-dimensional, making direct conditioning (e.g., stratification on all covariates simultaneously) infeasible. This is often called the "[curse of dimensionality](@entry_id:143920)." The **[propensity score](@entry_id:635864)**, defined as the conditional probability of receiving treatment given the covariates, $e(X) = \mathbb{P}(A=1 \mid X)$, provides an elegant solution to this problem.

A seminal result by Rosenbaum and Rubin (1983) established two powerful properties of the propensity score:
1.  **Balancing Score Property**: At any given value of the [propensity score](@entry_id:635864), the distribution of the full covariate vector $X$ is the same for treated and control subjects. Formally, $X \perp A \mid e(X)$. This means that if we match a treated subject with a control subject who has the same [propensity score](@entry_id:635864), we have on average balanced the entire vector of covariates $X$ between them.
2.  **Sufficiency for Unconfoundedness**: If treatment assignment is strongly ignorable given $X$, then it is also strongly ignorable given the scalar propensity score $e(X)$. That is, if $(Y(0), Y(1)) \perp A \mid X$, then it follows that $(Y(0), Y(1)) \perp A \mid e(X)$.

This second property is profound: it implies that we can control for confounding from a high-dimensional set of covariates $X$ by simply conditioning on the one-dimensional [propensity score](@entry_id:635864) $e(X)$. This reduction in dimensionality preserves the [identifiability](@entry_id:194150) of the causal effect. However, while collapsing $X$ to $e(X)$ is powerful, it can mask localized regions of poor overlap (weak positivity), as different covariate patterns can map to the same propensity score. This makes careful diagnostic assessment essential. [@problem_id:4830535]

### Covariate Selection for Propensity Score Models

The validity of a propensity score analysis hinges critically on the assumption that the correct set of covariates $X$ has been included in the model. The choice of covariates is a causal question, not a statistical prediction problem. The goal is not merely to predict treatment assignment accurately, but to condition on a set of variables that is sufficient to remove confounding. **Directed Acyclic Graphs (DAGs)** provide a formal framework for this causal reasoning.

To estimate the total causal effect of a treatment $A$ on an outcome $Y$, we must find a set of covariates $X$ that satisfies the **[backdoor criterion](@entry_id:637856)**. A set $X$ satisfies this criterion if:
1.  No variable in $X$ is a descendant of the treatment $A$.
2.  The variables in $X$ block every non-causal "backdoor" path between $A$ and $Y$.

Applying this criterion leads to clear rules for [variable selection](@entry_id:177971):
-   **Confounders**: Variables that are common causes of both treatment and outcome must be included in $X$ to block the confounding path. For example, in a study of a medical intervention, baseline factors like age, socioeconomic status (S), and comorbidity burden (C) often influence both the treatment decision (A) and the outcome (Y) and must be included to block paths like $A \leftarrow C \rightarrow Y$. [@problem_id:4980793]
-   **Mediators**: Variables that lie on the causal pathway between treatment and outcome (e.g., $A \rightarrow M \rightarrow Y$) are descendants of the treatment. Including them in the conditioning set would block part of the causal effect, leading to an estimate of the direct effect, not the total effect. They must be excluded if the total effect is the target estimand. [@problem_id:4980793]
-   **Colliders**: A [collider](@entry_id:192770) is a variable that is a common effect of two other variables (e.g., $V_1 \rightarrow C \leftarrow V_2$). A path containing a [collider](@entry_id:192770) is naturally blocked. Conditioning on a collider *unblocks* this path, which can induce a spurious association and introduce bias. This is a critical and often misunderstood point. For example, if an unmeasured factor like patient frailty ($U$) and the treatment ($A$) both affect a post-treatment lab value like lactate ($C$), then $C$ is a [collider](@entry_id:192770) ($A \rightarrow C \leftarrow U$). If $U$ also affects the outcome $Y$, conditioning on $C$ opens the non-causal path $A \rightarrow C \leftarrow U \rightarrow Y$, introducing bias even if the analysis was unconfounded without adjusting for $C$. Including such a variable in a [propensity score](@entry_id:635864) model is a serious error, even if it is highly predictive of treatment. [@problem_id:4830498] This type of bias can also be induced by conditioning on pre-treatment colliders, for example in a so-called M-structure ($A \leftarrow L_1 \rightarrow C \leftarrow L_2 \rightarrow Y$). [@problem_id:4830498]

### Estimating Causal Effects and Target Estimands

Once a valid [propensity score](@entry_id:635864) model is estimated, several methods can be used to estimate causal effects. The choice of method often depends on the specific causal question, as different methods can target different estimands. The three most common estimands are:
-   **Average Treatment Effect (ATE)**: The average effect of the treatment for the entire population, $E[Y(1) - Y(0)]$. This answers the question: "What would be the effect, on average, if everyone in the population were treated versus if everyone were not treated?"
-   **Average Treatment Effect on the Treated (ATT)**: The average effect of the treatment for those who actually received it, $E[Y(1) - Y(0) \mid A=1]$. This answers the question: "What was the effect, on average, for the patients who actually received the treatment?"
-   **Average Treatment Effect on the Controls (ATC)**: The average effect of the treatment for those who did not receive it, $E[Y(1) - Y(0) \mid A=0]$. This answers the question: "What would have been the effect, on average, had the control group been treated?"

Different [propensity score](@entry_id:635864) methods are naturally suited to different estimands [@problem_id:4830491]:

-   **Propensity Score Matching (PSM)**: In its most common form, PSM involves finding for each treated unit one or more control units with a similar [propensity score](@entry_id:635864). By averaging the outcome differences within these matched pairs, PSM directly estimates the **ATT**. To estimate the ATC, one would reverse the process, finding treated matches for each [control unit](@entry_id:165199).

-   **Propensity Score Stratification**: This method involves dividing the population into several strata (e.g., quintiles) based on the propensity score. The treatment effect is calculated within each stratum and then averaged. The final estimand depends on the weights used to average the stratum-specific effects. Weighting by the proportion of the total population in each stratum targets the **ATE**. Weighting by the proportion of treated individuals in each stratum targets the **ATT**.

-   **Inverse Probability of Treatment Weighting (IPTW)**: This powerful method creates a pseudo-population in which the covariates are no longer associated with treatment assignment. Each individual is weighted by the inverse of the probability of receiving the treatment they actually received.
    -   To estimate the **ATE**, the weight for an individual $i$ is $w_i = \frac{A_i}{e(X_i)} + \frac{1-A_i}{1-e(X_i)}$. This upweights treated individuals with a low propensity score and control individuals with a high propensity score to create a pseudo-population representative of the full population.
    -   To estimate the **ATT**, the treated group is the target population, so they receive a weight of 1. Control units are reweighted to look like the treated units, using weights $w_i = \frac{e(X_i)}{1-e(X_i)}$.
    -   To estimate the **ATC**, control units receive a weight of 1, and treated units are reweighted to look like the controls, using weights $w_i = \frac{1-e(X_i)}{e(X_i)}$.

### Assessing Covariate Balance: A Crucial Diagnostic Step

Fitting a propensity score model does not guarantee that it has successfully balanced the covariates. It is an absolutely essential step to perform **balance diagnostics** to verify that the chosen method (matching, stratification, or weighting) has created comparable treatment groups.

The goal is to assess whether the distribution of each covariate $X_j$ is similar between the treated and control groups *after* adjustment. This assessment should rely on metrics that are not sensitive to sample size. While p-values from hypothesis tests are commonly reported, they are poor measures of balance because in large studies, even trivial and clinically meaningless differences can be statistically significant.

A preferred metric is the **Standardized Mean Difference (SMD)**, or standardized difference. For a continuous covariate $X_j$, it is defined as:
$$ \Delta_j = \frac{\bar{X}_{1j} - \bar{X}_{0j}}{\sqrt{(s_{1j}^2 + s_{0j}^2)/2}} $$
where $\bar{X}_{tj}$ and $s_{tj}^2$ are the sample mean and variance in treatment group $t$. This metric is scale-free, allowing for comparison across covariates with different units. A widely adopted rule of thumb suggests that an absolute standardized difference of $|\Delta_j| \le 0.1$ indicates acceptable balance. For binary covariates, the formula specializes to $\Delta_j = \frac{p_{1j}-p_{0j}}{\sqrt{(p_{1j}(1-p_{1j})+p_{0j}(1-p_{0j}))/2}}$, where $p_{tj}$ is the proportion in group $t$. When using weighting or stratification, these statistics must be computed using the appropriate weighted means and variances or within each stratum. [@problem_id:4830450]

Beyond comparing means, it is important to assess the balance of the entire distribution of continuous covariates. This can be done graphically by plotting the **Empirical Cumulative Distribution Functions (ECDFs)** for the treated and control groups and visually inspecting their overlap. A quantitative summary of the difference between ECDFs is the **Kolmogorov-Smirnov (KS) statistic**, which is the maximum vertical distance between the two ECDF curves. A smaller KS statistic indicates better distributional balance. [@problem_id:4830542]

### Advanced Mechanisms and Considerations

**Doubly Robust Estimation**
Both [propensity score](@entry_id:635864) methods and outcome regression models (which directly model $E[Y \mid A, X]$) rely on the correct specification of their respective models. A **doubly robust estimator**, also known as an Augmented Inverse Propensity Weighted (AIPW) estimator, combines both approaches. The AIPW estimator for the ATE has the form:
$$ \hat{\tau}_{DR} = \frac{1}{n} \sum_{i=1}^n \left( (\hat{m}_1(X_i) - \hat{m}_0(X_i)) + \frac{A_i(Y_i - \hat{m}_1(X_i))}{\hat{e}(X_i)} - \frac{(1-A_i)(Y_i - \hat{m}_0(X_i))}{1-\hat{e}(X_i)} \right) $$
where $\hat{m}_t(X)$ are the estimated outcome regression models. This estimator has the remarkable property of being consistent if *either* the [propensity score](@entry_id:635864) model is correctly specified *or* the outcome regression models are correctly specified (not necessarily both). This "double protection" against [model misspecification](@entry_id:170325) makes it a highly attractive choice in practice. [@problem_id:4980792]

**Sensitivity to Unmeasured Confounding**
The assumption of conditional exchangeability—that we have measured and adjusted for all confounders—is untestable. Therefore, it is crucial to assess how robust a study's conclusions are to potential unmeasured confounding. **Sensitivity analysis** is a quantitative method for this purpose. It does not prove or disprove the existence of unmeasured confounding, but rather calculates how strong an unmeasured confounder would need to be, in terms of its association with both the treatment and the outcome, to change the qualitative conclusion of the study (e.g., to "explain away" an observed effect).

For a binary unmeasured confounder $U$, the maximum bias factor $B$ by which confounding can shift the observed risk ratio away from the true risk ratio is bounded by:
$$ B_{max} = \frac{RR_{AU} \cdot RR_{UY}}{RR_{AU} + RR_{UY} - 1} $$
where $RR_{AU}$ is the risk ratio relating the confounder to the treatment and $RR_{UY}$ is the risk ratio relating the confounder to the outcome. By calculating the minimum values of $RR_{AU}$ and $RR_{UY}$ that would be required to shift an observed risk ratio to the null value of 1, we can assess the plausibility of unmeasured confounding as an alternative explanation for our findings. Reporting such a sensitivity analysis is a critical component of rigorous observational research. [@problem_id:4980775]