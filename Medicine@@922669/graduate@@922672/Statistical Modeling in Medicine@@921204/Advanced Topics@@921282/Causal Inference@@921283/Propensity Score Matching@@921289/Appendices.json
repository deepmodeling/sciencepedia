{"hands_on_practices": [{"introduction": "This exercise grounds the theory of potential outcomes and the Average Treatment effect on the Treated ($\\\\text{ATT}$) in a direct, tangible calculation. By working through a hypothetical dataset, you will see precisely how one-to-one matching on the propensity score constructs a synthetic control group. This allows for the estimation of the counterfactual outcome, $E[Y(0) \\\\mid A=1]$, which is the cornerstone of identifying the $\\\\text{ATT}$ from observational data [@problem_id:4830538].", "problem": "A hospital-based observational cohort study evaluates a lipid-lowering therapy ($A=1$) versus usual care ($A=0$) on the $6$-month reduction in low-density lipoprotein cholesterol (LDL-C), measured in $\\mathrm{mg/dL}$. Let the potential outcomes be $Y(1)$ and $Y(0)$ for each patient, and assume the Stable Unit Treatment Value Assumption (SUTVA) and strong ignorability, that is, $Y(a) \\perp A \\mid X$ for $a \\in \\{0,1\\}$ and no unmeasured confounding given covariates $X$. The propensity score is $e(X) = \\Pr(A=1 \\mid X)$, and matching is conducted by nearest-neighbor on the logit propensity score among treated units with a conservative caliper, on the region of common support. The scientific goal is to target the Average Treatment effect on the Treated (ATT).\n\nFrom first principles of the potential outcomes framework and the balancing property of the propensity score, formalize the parameter being targeted by matching on the treated units, and explain why nearest-neighbor matching on the estimated propensity score (with appropriate common support and calipers) identifies that parameter under the stated assumptions. Then, using the matched treated-control pairs below, compute the sample matched-pair estimator for this parameter as the average over treated units of the within-pair outcome differences.\n\nThe study yields $n_T = 5$ matched pairs (one control per treated), with observed $6$-month LDL-C reductions (in $\\mathrm{mg/dL}$) as follows:\n- Pair $1$: treated $Y^{\\mathrm{obs}} = 38.4$, matched control $Y^{\\mathrm{obs}} = 25.6$.\n- Pair $2$: treated $Y^{\\mathrm{obs}} = 22.1$, matched control $Y^{\\mathrm{obs}} = 15.9$.\n- Pair $3$: treated $Y^{\\mathrm{obs}} = 41.0$, matched control $Y^{\\mathrm{obs}} = 27.3$.\n- Pair $4$: treated $Y^{\\mathrm{obs}} = 35.2$, matched control $Y^{\\mathrm{obs}} = 29.0$.\n- Pair $5$: treated $Y^{\\mathrm{obs}} = 30.5$, matched control $Y^{\\mathrm{obs}} = 18.1$.\n\nReport the final estimate as the scalar average of treated-minus-matched-control differences, expressed in $\\mathrm{mg/dL}$. Round your answer to four significant figures.", "solution": "The problem asks for a formal definition of the Average Treatment effect on the Treated (ATT), an explanation of its identification through propensity score matching, and the computation of a sample estimate. The problem is well-posed and scientifically grounded within the framework of causal inference.\n\nFirst, we formalize the target parameter, the Average Treatment effect on the Treated (ATT). Let $Y(1)$ be the potential outcome (LDL-C reduction) for a patient if they receive the lipid-lowering therapy ($A=1$), and $Y(0)$ be the potential outcome if they receive usual care ($A=0$). The ATT is defined as the expected causal effect of the treatment for the subpopulation of individuals who were actually treated:\n$$\n\\text{ATT} = E[Y(1) - Y(0) \\mid A=1]\n$$\nBy linearity of expectation, this can be written as:\n$$\n\\text{ATT} = E[Y(1) \\mid A=1] - E[Y(0) \\mid A=1]\n$$\nThe first term, $E[Y(1) \\mid A=1]$, is the expected outcome under treatment for the treated group. Under the Stable Unit Treatment Value Assumption (SUTVA), the observed outcome for a treated individual is their potential outcome under treatment, i.e., $Y^{\\mathrm{obs}} = Y(1)$ if $A=1$. Therefore, this term is directly identifiable from the data and can be estimated by the sample mean of the observed outcomes among the treated: $E[Y^{\\mathrm{obs}} \\mid A=1]$.\n\nThe second term, $E[Y(0) \\mid A=1]$, is the expected outcome under control for the treated group. This is a counterfactual quantity because we cannot observe what the outcome would have been for treated individuals had they received the control. Its identification is the central challenge in observational studies.\n\nIdentification is achieved under the stated assumption of strong ignorability, $Y(a) \\perp A \\mid X$ for $a \\in \\{0,1\\}$, which means that treatment assignment $A$ is independent of the potential outcomes $Y(a)$ conditional on the set of observed covariates $X$. For the counterfactual mean of interest, this implies:\n$$\nE[Y(0) \\mid A=1, X] = E[Y(0) \\mid A=0, X]\n$$\nThis equation states that within strata defined by the covariates $X$, the expected potential outcome under control is the same for both treated and control groups. The right-hand side is observable, as for the control group ($A=0$), $Y^{\\mathrm{obs}} = Y(0)$. Thus, $E[Y(0) \\mid A=0, X] = E[Y^{\\mathrm{obs}} \\mid A=0, X]$.\n\nTo obtain the overall counterfactual mean for the treated population, we average over the distribution of covariates $X$ among the treated ($A=1$):\n$$\nE[Y(0) \\mid A=1] = E_{X \\mid A=1} [E[Y(0) \\mid A=1, X]]\n$$\nSubstituting the result from the ignorability assumption:\n$$\nE[Y(0) \\mid A=1] = E_{X \\mid A=1} [E[Y(0) \\mid A=0, X]] = E_{X \\mid A=1} [E[Y^{\\mathrm{obs}} \\mid A=0, X]]\n$$\nThis expression shows that the counterfactual mean for the treated can be identified by taking the outcomes of the control subjects and re-weighting or standardizing them to match the covariate distribution of the treated subjects.\n\nPropensity score matching is a method to achieve this standardization. The propensity score, $e(X) = \\Pr(A=1 \\mid X)$, has a key balancing property, established by Rosenbaum and Rubin: conditional on the propensity score, the distribution of covariates $X$ is the same between treated and control groups. This property allows us to replace conditioning on the multidimensional $X$ with conditioning on the scalar $e(X)$. The strong ignorability assumption, $Y(a) \\perp A \\mid X$, implies a similar ignorability conditional on the propensity score: $Y(a) \\perp A \\mid e(X)$.\n\nTherefore, we can write:\n$$\nE[Y(0) \\mid A=1, e(X)] = E[Y(0) \\mid A=0, e(X)] = E[Y^{\\mathrm{obs}} \\mid A=0, e(X)]\n$$\nMatching on the treated works by finding for each treated individual $i$ a control individual $j(i)$ with a nearly identical propensity score, $e(X_i) \\approx e(X_{j(i)})$. This process creates a matched control group that, by virtue of having a similar propensity score distribution to the treated group, also has a similar distribution of the covariates $X$. Consequently, the simple average of outcomes in this matched control group provides an unbiased estimate of $E_{X \\mid A=1} [E[Y^{\\mathrm{obs}} \\mid A=0, X]]$, which is our target counterfactual mean $E[Y(0) \\mid A=1]$.\n\nThus, the ATT is identified by:\n$$\n\\text{ATT} = E[Y^{\\mathrm{obs}} \\mid A=1] - E[Y^{\\mathrm{obs}}_{\\text{matched controls}}]\n$$\nThe sample matched-pair estimator for the ATT is the sample analogue of this expression. For a set of $n_T$ treated individuals, each matched to a unique control, the estimator is the average of the within-pair differences:\n$$\n\\widehat{\\text{ATT}} = \\frac{1}{n_T} \\sum_{i=1}^{n_T} (Y_i^{\\mathrm{obs, treated}} - Y_{j(i)}^{\\mathrm{obs, control}})\n$$\nwhere $Y_{j(i)}^{\\mathrm{obs, control}}$ is the observed outcome of the control unit matched to the $i$-th treated unit.\n\nNow, we compute this estimator using the provided data for $n_T = 5$ pairs.\nThe differences for each pair are:\n- Pair $1$: $\\Delta_1 = 38.4 - 25.6 = 12.8$\n- Pair $2$: $\\Delta_2 = 22.1 - 15.9 = 6.2$\n- Pair $3$: $\\Delta_3 = 41.0 - 27.3 = 13.7$\n- Pair $4$: $\\Delta_4 = 35.2 - 29.0 = 6.2$\n- Pair $5$: $\\Delta_5 = 30.5 - 18.1 = 12.4$\n\nThe sample ATT is the average of these differences:\n$$\n\\widehat{\\text{ATT}} = \\frac{1}{5} \\sum_{i=1}^{5} \\Delta_i = \\frac{12.8 + 6.2 + 13.7 + 6.2 + 12.4}{5}\n$$\n$$\n\\widehat{\\text{ATT}} = \\frac{51.3}{5} = 10.26\n$$\nThe problem requires the answer to be rounded to four significant figures. The calculated value $10.26$ already has four significant figures.\n\nThe final estimate for the Average Treatment effect on the Treated is $10.26 \\, \\mathrm{mg/dL}$.", "answer": "$$\\boxed{10.26}$$", "id": "4830538"}, {"introduction": "Moving beyond individual matching, this practice introduces propensity score stratification as a powerful alternative for covariate adjustment. You will explore how partitioning subjects into strata based on their propensity score can achieve balance across the entire sample. This exercise guides you through calculating stratum-specific effects and combining them to estimate the overall Average Treatment Effect ($\\\\text{ATE}$), highlighting a method that utilizes all study participants [@problem_id:4830519].", "problem": "A clinical effectiveness study uses observational cohort data to estimate the causal effect of initiating a new antihypertensive therapy on $6$-month change in systolic blood pressure. Let the binary treatment indicator be $T \\in \\{0,1\\}$, the baseline covariates be $X$, and the outcome be $Y$, defined as the change in systolic blood pressure from baseline to $6$ months in millimeters of mercury (mmHg), with negative values indicating reductions. Assume the Stable Unit Treatment Value Assumption (SUTVA) and strong ignorability hold, that is, $(Y(0),Y(1)) \\perp T \\mid X$ and positivity, where $Y(0)$ and $Y(1)$ denote the potential outcomes under control and treatment, respectively. The propensity score is $e(X) = \\Pr(T=1 \\mid X)$.\n\nThe study estimates $e(X)$ and stratifies the sample into $K$ subclasses using quintiles of the estimated propensity score (so $K=5$). Within each subclass $k \\in \\{1,2,3,4,5\\}$, the sample sizes of the treated and control groups are $N_{1k}$ and $N_{0k}$, and the observed sample means of $Y$ in the treated and control groups are $\\bar{Y}_{1k}$ and $\\bar{Y}_{0k}$, respectively. The data are as follows, where all counts and means are scientifically plausible and derived from the cohort:\n\n- Quintile $k=1$: $N_{1,1} = 40$, $N_{0,1} = 160$, $\\bar{Y}_{1,1} = -12.4$, $\\bar{Y}_{0,1} = -8.7$.\n- Quintile $k=2$: $N_{1,2} = 60$, $N_{0,2} = 140$, $\\bar{Y}_{1,2} = -10.2$, $\\bar{Y}_{0,2} = -7.9$.\n- Quintile $k=3$: $N_{1,3} = 110$, $N_{0,3} = 90$, $\\bar{Y}_{1,3} = -9.5$, $\\bar{Y}_{0,3} = -6.1$.\n- Quintile $k=4$: $N_{1,4} = 150$, $N_{0,4} = 50$, $\\bar{Y}_{1,4} = -8.0$, $\\bar{Y}_{0,4} = -5.0$.\n- Quintile $k=5$: $N_{1,5} = 180$, $N_{0,5} = 20$, $\\bar{Y}_{1,5} = -7.1$, $\\bar{Y}_{0,5} = -3.4$.\n\nLet $N_k = N_{1k} + N_{0k}$ and $N = \\sum_{k=1}^{5} N_k$. Define propensity score stratification into $K$ subclasses such as quintiles, starting from fundamental principles valid in observational causal inference. Using those principles, derive the within-stratum difference-in-means estimator for subclass $k$ and the weighted aggregation across subclasses that targets the Average Treatment Effect (ATE) in the study sample. Then calculate the resulting ATE estimate using the data provided. Express the final answer in millimeters of mercury (mmHg) and round your answer to four significant figures.", "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information to estimate the Average Treatment Effect (ATE) using propensity score stratification. We will first derive the estimator from fundamental principles of causal inference and then apply it to the provided data.\n\nThe goal is to estimate the Average Treatment Effect (ATE), defined as the expected difference between the potential outcome under treatment ($Y(1)$) and the potential outcome under control ($Y(0)$) over the entire population:\n$$\n\\tau_{ATE} = E[Y(1) - Y(0)]\n$$\nIn an observational study, we cannot directly observe both $Y(1)$ and $Y(0)$ for the same individual. A naive comparison of treated and control groups, $E[Y \\mid T=1] - E[Y \\mid T=0]$, is generally biased due to confounding, where the covariates $X$ that influence treatment assignment $T$ also influence the outcome $Y$.\n\nThe problem states the assumption of **strong ignorability**, which consists of two parts:\n$1$. Unconfoundedness: $(Y(0), Y(1)) \\perp T \\mid X$. This means that conditional on the baseline covariates $X$, treatment assignment $T$ is independent of the potential outcomes.\n$2$. Positivity (or overlap): $0 < \\Pr(T=1 \\mid X) < 1$. This ensures that for any set of covariates $X$, there is a non-zero probability of being in either the treatment or control group.\n\nUnder unconfoundedness, we can identify the conditional expected potential outcomes:\n$$\nE[Y(t) \\mid X] = E[Y(t) \\mid T=t, X] = E[Y \\mid T=t, X] \\quad \\text{for } t \\in \\{0,1\\}\n$$\nThe ATE can then be expressed as the expectation over the distribution of the covariates $X$:\n$$\n\\tau_{ATE} = E_X[E[Y(1) \\mid X] - E[Y(0) \\mid X]] = E_X[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]]\n$$\nDirectly conditioning on a high-dimensional vector $X$ is often impractical. Rosenbaum and Rubin (1983) showed that conditioning on the one-dimensional propensity score, $e(X) = \\Pr(T=1 \\mid X)$, is sufficient to remove confounding bias, as it is a balancing score. Specifically, if $(Y(0), Y(1)) \\perp T \\mid X$, then it is also true that $(Y(0), Y(1)) \\perp T \\mid e(X)$.\n\n**Propensity Score Stratification**\nThis method approximates conditioning on the continuous propensity score $e(X)$ by dividing the population into $K$ strata based on quantiles of the estimated propensity score, $\\hat{e}(X)$. Within each stratum $k$, individuals have similar propensity scores, and thus the distributions of their covariates $X$ are expected to be approximately balanced between the treated and control groups.\n\n**Within-Stratum Estimator**\nWithin a given stratum $k$, the unconfoundedness assumption is assumed to hold approximately. Therefore, the average treatment effect within stratum $k$, denoted $\\tau_k$, can be estimated by the simple difference in the mean outcomes between the treated and control subjects in that stratum.\n$$\n\\tau_k = E[Y(1) - Y(0) \\mid \\text{subject in stratum } k]\n$$\nIts sample-based estimator is the **within-stratum difference-in-means estimator**:\n$$\n\\hat{\\tau}_k = \\bar{Y}_{1k} - \\bar{Y}_{0k}\n$$\nwhere $\\bar{Y}_{1k}$ is the sample mean of the outcome for a treated unit in stratum $k$, and $\\bar{Y}_{0k}$ is the sample mean for a control unit in stratum $k$.\n\n**Aggregation to Estimate ATE**\nThe overall ATE is the weighted average of the stratum-specific treatment effects, where the weights are the proportion of the total sample size in each stratum.\nBy the law of total expectation, the ATE can be written as:\n$$\n\\tau_{ATE} = \\sum_{k=1}^K \\Pr(\\text{stratum } k) \\cdot E[Y(1) - Y(0) \\mid \\text{stratum } k] = \\sum_{k=1}^K \\Pr(\\text{stratum } k) \\cdot \\tau_k\n$$\nWe estimate this by substituting the sample proportions for the probabilities and the stratum-specific estimators $\\hat{\\tau}_k$ for $\\tau_k$. Let $N_k = N_{1k} + N_{0k}$ be the number of subjects in stratum $k$, and $N = \\sum_{k=1}^K N_k$ be the total sample size. The estimator for the ATE in the study sample is:\n$$\n\\hat{\\tau}_{ATE} = \\sum_{k=1}^K \\frac{N_k}{N} \\hat{\\tau}_k = \\sum_{k=1}^K \\frac{N_{1k} + N_{0k}}{N} (\\bar{Y}_{1k} - \\bar{Y}_{0k})\n$$\n\n**Calculation**\nWe are given data for $K=5$ strata (quintiles). Let's first calculate the total number of subjects in each stratum and the total sample size.\n- Stratum $k=1$: $N_1 = N_{1,1} + N_{0,1} = 40 + 160 = 200$\n- Stratum $k=2$: $N_2 = N_{1,2} + N_{0,2} = 60 + 140 = 200$\n- Stratum $k=3$: $N_3 = N_{1,3} + N_{0,3} = 110 + 90 = 200$\n- Stratum $k=4$: $N_4 = N_{1,4} + N_{0,4} = 150 + 50 = 200$\n- Stratum $k=5$: $N_5 = N_{1,5} + N_{0,5} = 180 + 20 = 200$\n\nThe total sample size is $N = \\sum_{k=1}^5 N_k = 200 + 200 + 200 + 200 + 200 = 1000$.\n\nThe weight for each stratum is $\\frac{N_k}{N} = \\frac{200}{1000} = \\frac{1}{5} = 0.2$. Since the strata are quintiles and contain equal numbers of subjects, the weights are all equal.\n\nNext, we calculate the within-stratum difference-in-means, $\\hat{\\tau}_k$:\n- Stratum $k=1$: $\\hat{\\tau}_1 = \\bar{Y}_{1,1} - \\bar{Y}_{0,1} = -12.4 - (-8.7) = -3.7$\n- Stratum $k=2$: $\\hat{\\tau}_2 = \\bar{Y}_{1,2} - \\bar{Y}_{0,2} = -10.2 - (-7.9) = -2.3$\n- Stratum $k=3$: $\\hat{\\tau}_3 = \\bar{Y}_{1,3} - \\bar{Y}_{0,3} = -9.5 - (-6.1) = -3.4$\n- Stratum $k=4$: $\\hat{\\tau}_4 = \\bar{Y}_{1,4} - \\bar{Y}_{0,4} = -8.0 - (-5.0) = -3.0$\n- Stratum $k=5$: $\\hat{\\tau}_5 = \\bar{Y}_{1,5} - \\bar{Y}_{0,5} = -7.1 - (-3.4) = -3.7$\n\nFinally, we compute the ATE estimate as the weighted average of these stratum-specific effects:\n$$\n\\hat{\\tau}_{ATE} = \\sum_{k=1}^5 \\frac{N_k}{N} \\hat{\\tau}_k = \\frac{1}{5} \\sum_{k=1}^5 \\hat{\\tau}_k\n$$\n$$\n\\hat{\\tau}_{ATE} = \\frac{1}{5} (-3.7 - 2.3 - 3.4 - 3.0 - 3.7)\n$$\n$$\n\\hat{\\tau}_{ATE} = \\frac{1}{5} (-16.1)\n$$\n$$\n\\hat{\\tau}_{ATE} = -3.22\n$$\nThe problem asks for the answer to be rounded to four significant figures. The calculated value is $-3.22$. To express this with four significant figures, we write it as $-3.220$. The negative sign indicates that the therapy is associated with a reduction in systolic blood pressure, as expected. The estimated average causal effect of the therapy is a reduction of $3.220$ mmHg.", "answer": "$$\n\\boxed{-3.220}\n$$", "id": "4830519"}, {"introduction": "A well-specified propensity score model requires careful causal reasoning, not just maximizing predictive power. This simulation practice demonstrates a critical pitfall known as M-bias, which arises from inappropriately conditioning on a collider variable. By intentionally misspecifying a model and comparing its performance to a correct one, you will gain hands-on insight into how collider stratification bias can corrupt an analysis and why Directed Acyclic Graphs (DAGs) are essential tools for variable selection [@problem_id:3162896].", "problem": "You are asked to design and implement a simulation-based demonstration of M-bias in Propensity Score Matching (PSM) within the potential outcomes framework for causal inference in statistical learning. Begin from the following fundamental base: under the potential outcomes framework, the Average Treatment Effect (ATE) is defined as the average difference between the potential outcomes under treatment and control, and the propensity score is the probability of treatment conditional on observed covariates. A collider is a variable that is caused by two (or more) variables; conditioning on a collider can induce a spurious statistical association (M-bias) between otherwise independent causes, which can bias causal effect estimates if those causes affect the outcome and treatment along different paths.\n\nConstruct a data-generating process (DGP) embodying the canonical M-bias structure using the Directed Acyclic Graph (DAG) concept (Directed Acyclic Graph (DAG)). The DAG is as follows: there exist latent variables $U$ and $V$ such that $U$ influences treatment $T$ but not outcome $Y$, $V$ influences outcome $Y$ but not treatment $T$, and the collider $C$ is influenced by both $U$ and $V$. There is also an observed covariate $X$. The structural equations are:\n- Latent causes: $U \\sim \\mathcal{N}(0,1)$, $V \\sim \\mathcal{N}(0,1)$.\n- Observed covariate: $X \\sim \\mathcal{N}(0,1)$.\n- Collider: $C = \\gamma_U U + \\gamma_V V + \\varepsilon_C$, with $\\varepsilon_C \\sim \\mathcal{N}(0,1)$.\n- Treatment assignment: $T \\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha_0 + \\alpha_U U + \\alpha_X X))$, where $\\text{logit}^{-1}(z) = \\dfrac{1}{1 + e^{-z}}$.\n- Outcome: $Y = \\beta_T T + \\beta_V V + \\beta_X X + \\varepsilon_Y$, with $\\varepsilon_Y \\sim \\mathcal{N}(0,1)$.\n\nUnder this DGP, the true Average Treatment Effect (ATE) equals $\\beta_T$.\n\nYour program must, for each test case, do the following:\n1. Simulate $N$ independent observations according to the DGP above.\n2. Estimate two propensity score models for $T$ using logistic regression (maximum likelihood), each with an intercept term:\n   - Incorrect model (with collider): covariates $\\{X, C\\}$.\n   - Correct model (excluding collider): covariates $\\{X\\}$.\n3. For each fitted propensity score, perform nearest-neighbor matching with replacement and a caliper on the absolute propensity score difference. Specifically:\n   - For each treated unit, find the single closest control unit in propensity score distance; include the pair if the distance is less than or equal to the caliper.\n   - For each control unit, find the single closest treated unit in propensity score distance; include the pair if the distance is less than or equal to the caliper.\n   - Compute the matched estimate of the Average Treatment Effect by averaging all available matched pair differences $Y_{\\text{treated}} - Y_{\\text{control}}$ formed from both directions (this symmetrized matching estimator approximates the Average Treatment Effect rather than only the Average Treatment Effect on the Treated).\n   - If no pairs satisfy the caliper, re-run the nearest-neighbor matching without any caliper (i.e., caliper $= +\\infty$).\n4. Compute the bias of each matched estimator relative to the true ATE:\n   - Bias including collider: $b_{\\text{incl}} = \\widehat{\\text{ATE}}_{\\text{incl}} - \\beta_T$.\n   - Bias excluding collider: $b_{\\text{excl}} = \\widehat{\\text{ATE}}_{\\text{excl}} - \\beta_T$.\n   - Excess absolute bias attributable to including the collider: $\\Delta = |b_{\\text{incl}}| - |b_{\\text{excl}}|$.\n5. Aggregate the results across all test cases into a single line of output as a comma-separated list of per-case triples, where each triple is a bracketed list $[b_{\\text{incl}}, b_{\\text{excl}}, \\Delta]$. The complete output must be enclosed in square brackets. For example: $[[b_1^{\\text{incl}}, b_1^{\\text{excl}}, \\Delta_1],[b_2^{\\text{incl}}, b_2^{\\text{excl}}, \\Delta_2]]$.\n\nTest Suite and Parameters:\nImplement the procedure for the following four test cases. Use the specified random seed to ensure reproducibility.\n\n- Case $1$ (baseline, moderate collider):\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 0.8$, $\\gamma_V = 0.8$, caliper $= 0.05$, seed $= 42$.\n\n- Case $2$ (boundary, no collider effect):\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 0.0$, $\\gamma_V = 0.0$, caliper $= 0.05$, seed $= 1$.\n\n- Case $3$ (strong collider influence):\n  - $N = 4000$, $\\alpha_0 = 0$, $\\alpha_U = 1.2$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 2.5$, $\\gamma_V = 2.5$, caliper $= 0.05$, seed $= 7$.\n\n- Case $4$ (small sample, moderate collider):\n  - $N = 600$, $\\alpha_0 = 0$, $\\alpha_U = 1.0$, $\\alpha_X = 0.5$, $\\beta_T = 2.0$, $\\beta_V = 1.0$, $\\beta_X = 0.0$, $\\gamma_U = 1.0$, $\\gamma_V = 1.0$, caliper $= 0.07$, seed $= 123$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list of per-case triples, each triple itself being a comma-separated list in square brackets, with the entire output enclosed in square brackets. For example: $[[r_{11},r_{12},r_{13}],[r_{21},r_{22},r_{23}],[r_{31},r_{32},r_{33}],[r_{41},r_{42},r_{43}]]$. Each $r_{ij}$ must be a floating-point number.", "solution": "The problem statement has been validated and is deemed valid. It presents a well-posed, scientifically grounded simulation exercise in the field of causal inference and statistical learning. The objective is to demonstrate M-bias, a specific type of bias that arises from conditioning on a collider variable, within the context of Propensity Score Matching (PSM). All parameters, models, and procedures are explicitly defined, enabling a reproducible computational solution.\n\n### Theoretical Framework\n\nThe problem is rooted in the potential outcomes framework for causal inference. The goal is to estimate the Average Treatment Effect (ATE), defined as $\\mathbb{E}[Y(1) - Y(0)]$, where $Y(1)$ and $Y(0)$ are the potential outcomes under treatment and control, respectively. The data generating process (DGP) is specified by a set of structural equations that correspond to a Directed Acyclic Graph (DAG). The core of this DAG is the \"M-structure\":\n1. An unobserved variable $U$ is a cause of the treatment $T$ ($U \\rightarrow T$).\n2. Another unobserved variable $V$ is a cause of the outcome $Y$ ($V \\rightarrow Y$).\n3. $U$ and $V$ are independent, i.e., there is no path between them.\n4. $U$ and $V$ are both causes of an observed variable $C$, the collider ($U \\rightarrow C \\leftarrow V$).\n\nIn this structure, $T$ and $Y$ are not associated through the path involving $U$ and $V$ because the path $T \\leftarrow U \\rightarrow C \\leftarrow V \\rightarrow Y$ is blocked by the collider $C$. However, if one conditions on the collider $C$ (e.g., by including it in a regression model), this path becomes unblocked, inducing a spurious statistical association between $U$ and $V$. This spurious association between the causes of treatment ($U$) and outcome ($V$) creates a non-causal statistical association between $T$ and $Y$, leading to biased estimates of the causal effect.\n\nThe specified DGP is given by:\n- Latent causes: $U \\sim \\mathcal{N}(0,1)$, $V \\sim \\mathcal{N}(0,1)$.\n- Observed covariate: $X \\sim \\mathcal{N}(0,1)$.\n- Collider: $C = \\gamma_U U + \\gamma_V V + \\varepsilon_C$, with $\\varepsilon_C \\sim \\mathcal{N}(0,1)$.\n- Treatment assignment: $T \\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha_0 + \\alpha_U U + \\alpha_X X))$.\n- Outcome: $Y = \\beta_T T + \\beta_V V + \\beta_X X + \\varepsilon_Y$, with $\\varepsilon_Y \\sim \\mathcal{N}(0,1)$.\n\nThe true ATE is given by the coefficient $\\beta_T$. The variable $X$ is included as an observed predictor of treatment ($X \\rightarrow T$). In the given test cases, $\\beta_X=0$, so $X$ is not a confounder (i.e., there is no open backdoor path $T \\leftarrow X \\rightarrow Y$). Nevertheless, including predictors of treatment in a propensity score model is standard practice. The \"correct\" propensity score model includes predictors that block all backdoor paths between $T$ and $Y$ without opening new ones. Here, that means adjusting for $X$ but crucially not for the collider $C$.\n\n### Simulation and Estimation Procedure\n\nFor each test case, the following steps are executed:\n\n1.  **Data Generation**: A dataset of $N$ observations is simulated based on the structural equations and the specified parameters. A fixed random seed ensures reproducibility. Variables $U, V, X, \\varepsilon_C, \\varepsilon_Y$ are drawn from standard normal distributions. The collider $C$, binary treatment $T$, and continuous outcome $Y$ are then constructed according to their definitions.\n\n2.  **Propensity Score Estimation**: The propensity score, $e(Z) = P(T=1|Z)$, is estimated using two different logistic regression models, where $Z$ is the set of covariates. The model coefficients are estimated by maximizing the log-likelihood function using a numerical optimization algorithm (BFGS).\n    - **Incorrect Model**: Includes the collider $C$ in the set of covariates, $Z = \\{X, C\\}$. The estimated propensity score is $\\hat{e}_{\\text{incl}}(X, C)$. This model is expected to produce biased results due to conditioning on the collider.\n    - **Correct Model**: Excludes the collider, $Z = \\{X\\}$. The estimated propensity score is $\\hat{e}_{\\text{excl}}(X)$. This model avoids M-bias.\n\n3.  **ATE Estimation via Matching**: For each of the two estimated propensity scores, a matched estimate of the ATE is computed using symmetric nearest-neighbor matching with replacement and a caliper.\n    - **Symmetric Matching**: To estimate the ATE (as opposed to the ATT or ATC), matches are sought from both directions. For each treated unit, the closest control unit (in propensity score distance) is found. Symmetrically, for each control unit, the closest treated unit is found.\n    - **Caliper**: A pair is considered a valid match only if the absolute difference in their propensity scores is within a specified caliper value.\n    - **Fallback**: If no pairs satisfy the caliper condition, the procedure is repeated with an infinite caliper (i.e., finding the nearest neighbor regardless of distance).\n    - **Estimator**: The ATE is estimated as the simple arithmetic mean of the outcome differences, $Y_{\\text{treated}} - Y_{\\text{control}}$, across all valid matched pairs found in both matching directions.\n\n4.  **Bias Analysis**: The performance of each estimator is evaluated by its bias, which is the difference between the estimate and the true ATE ($\\beta_T$).\n    - Bias (collider included): $b_{\\text{incl}} = \\widehat{\\text{ATE}}_{\\text{incl}} - \\beta_T$.\n    - Bias (collider excluded): $b_{\\text{excl}} = \\widehat{\\text{ATE}}_{\\text{excl}} - \\beta_T$.\n    - Excess Absolute Bias: $\\Delta = |b_{\\text{incl}}| - |b_{\\text{excl}}|$. A positive $\\Delta$ indicates that including the collider has amplified the estimation bias, demonstrating the detrimental effect of M-bias.\n\nThe simulation is expected to show that $|b_{\\text{incl}}|$ is significantly larger than $|b_{\\text{excl}}|$ when the collider path strengths ($\\gamma_U, \\gamma_V$) are non-zero, and that this difference, $\\Delta$, increases with the strength of the collider. When $\\gamma_U = \\gamma_V = 0$, the M-structure is absent, and both models should yield similar, low-bias estimates, resulting in a $\\Delta$ near zero.", "answer": "[[-0.0943260717208442,0.01220455584501431,0.08212151587582989],[-0.000371900135399564,0.00763294373449275,-0.007261043599093186],[-0.511326442036662,-0.005110599066661331,0.5062158429699996],[-0.1615024479549302,0.03053648177576579,0.1309659661791644]]", "id": "3162896"}]}