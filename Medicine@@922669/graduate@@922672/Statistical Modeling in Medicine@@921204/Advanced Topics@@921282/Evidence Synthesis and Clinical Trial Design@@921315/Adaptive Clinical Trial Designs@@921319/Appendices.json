{"hands_on_practices": [{"introduction": "Planning a clinical trial requires making assumptions about parameters like the outcome variance. This exercise explores a common adaptive strategy, blinded sample size re-estimation (SSR), which allows for course correction if initial assumptions prove inaccurate. By working from first principles, you will see how to adjust the trial's sample size based on an interim variance estimate to ensure the study remains adequately powered, a crucial skill for designing robust trials. [@problem_id:4772912]", "problem": "A two-arm, equal-allocation, parallel-group superiority trial with a continuous primary endpoint is planned using a normal-theory framework justified by the Central Limit Theorem (CLT). Let the individual outcomes be independently and identically distributed with variance $\\sigma^2$ in each arm, and suppose the treatment effect is defined as a mean difference $\\delta = \\mu_1 - \\mu_2$. The test is one-sided at type I error $\\alpha = 0.025$ and targets power $1 - \\beta = 0.9$ to detect $\\delta = 0.3$. The initial planning assumed $\\sigma^2 = 1$. The design uses blinded sample size re-estimation based on the information function at an interim information time $t = 0.5$, where the pooled blinded variance estimate is $\\hat{\\sigma}^{2} = 1.44$.\n\nStarting from first principles—namely, the sampling distribution of the difference in sample means under the null and alternative hypotheses, the definition of type I error and power, and the behavior of the one-sided $z$-test—derive the continuous target for the total re-estimated sample size across both arms, $N_{\\text{new}}$, when the blinded interim estimate $\\hat{\\sigma}^{2}$ replaces the planning value $\\sigma^{2}$. Assume equal allocation, no other adaptations, and preservation of the originally planned critical value. Ignore integer constraints; report the real-valued $N_{\\text{new}}$ rounded to four significant figures.", "solution": "The problem requires the derivation of the re-estimated total sample size, $N_{\\text{new}}$, for a two-arm superiority clinical trial, based on an interim blinded variance estimate. We will begin from first principles, namely the statistical framework of the two-sample $z$-test for means.\n\nLet $X_{1j}$ and $X_{2j}$ be the continuous outcomes for the $j$-th subject in the treatment arm (arm $1$) and control arm (arm $2$), respectively. The outcomes are assumed to be independent and (approximately) normally distributed, $X_{ij} \\sim N(\\mu_i, \\sigma^2)$ for $i \\in \\{1, 2\\}$, with a common variance $\\sigma^2$. This is justified by the Central Limit Theorem. The treatment effect is the difference in means, $\\delta = \\mu_1 - \\mu_2$.\n\nThe trial uses equal allocation, so the sample sizes in each arm are $n_1 = n_2 = N/2$, where $N$ is the total sample size. The estimator for the treatment effect is the difference in sample means, $\\hat{\\delta} = \\bar{X}_1 - \\bar{X}_2$.\n\nThe sampling distribution of $\\hat{\\delta}$ is normal with mean $E[\\hat{\\delta}] = \\mu_1 - \\mu_2 = \\delta$ and variance $\\text{Var}(\\hat{\\delta}) = \\text{Var}(\\bar{X}_1) + \\text{Var}(\\bar{X}_2) = \\frac{\\sigma^2}{n_1} + \\frac{\\sigma^2}{n_2} = \\frac{\\sigma^2}{N/2} + \\frac{\\sigma^2}{N/2} = \\frac{4\\sigma^2}{N}$. Thus, $\\hat{\\delta} \\sim N(\\delta, \\frac{4\\sigma^2}{N})$.\n\nThe trial is designed to test the one-sided null hypothesis $H_0: \\delta \\le 0$ against the alternative $H_1: \\delta > 0$. For constructing the test, we consider the boundary case $H_0: \\delta = 0$. The standardized test statistic is:\n$$ Z = \\frac{\\hat{\\delta} - 0}{\\sqrt{\\text{Var}(\\hat{\\delta})}} = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{4\\sigma^2/N}} $$\nUnder $H_0$, $Z$ follows a standard normal distribution, $Z \\sim N(0, 1)$.\n\nThe one-sided type I error rate is specified as $\\alpha = 0.025$. The null hypothesis is rejected if the test statistic $Z$ exceeds a critical value, $c$. This critical value is determined by $P(Z > c | H_0) = \\alpha$. For a standard normal variable, this implies $c = z_{1-\\alpha}$, the $(1-\\alpha)$-quantile of the standard normal distribution. Given $\\alpha = 0.025$, the critical value is $c = z_{1-0.025} = z_{0.975}$.\n\nPower is the probability of correctly rejecting $H_0$ when a specific alternative hypothesis is true. The trial is powered to detect a treatment effect $\\delta_A = 0.3$ with power $1 - \\beta = 0.9$.\n$$ 1 - \\beta = P\\left(Z > z_{1-\\alpha} \\mid \\delta = \\delta_A\\right) $$\nSubstituting the definition of $Z$:\n$$ 1 - \\beta = P\\left(\\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{4\\sigma^2/N}} > z_{1-\\alpha} \\mid \\delta = \\delta_A\\right) $$\nTo evaluate this probability under the alternative hypothesis (where $E[\\bar{X}_1 - \\bar{X}_2] = \\delta_A$), we standardize the expression differently:\n$$ 1 - \\beta = P\\left(\\frac{(\\bar{X}_1 - \\bar{X}_2) - \\delta_A}{\\sqrt{4\\sigma^2/N}} > z_{1-\\alpha} - \\frac{\\delta_A}{\\sqrt{4\\sigma^2/N}}\\right) $$\nThe expression on the left inside the probability is a standard normal variable. Let $Z' \\sim N(0,1)$. Then:\n$$ P\\left(Z' > z_{1-\\alpha} - \\frac{\\delta_A \\sqrt{N}}{2\\sigma}\\right) = 1 - \\beta $$\nThis implies that the argument of the probability must be the $\\beta$-quantile of the standard normal distribution, $z_{\\beta}$, which is equal to $-z_{1-\\beta}$.\n$$ z_{1-\\alpha} - \\frac{\\delta_A \\sqrt{N}}{2\\sigma} = -z_{1-\\beta} $$\nSolving for the total sample size $N$ gives the general formula:\n$$ z_{1-\\alpha} + z_{1-\\beta} = \\frac{\\delta_A \\sqrt{N}}{2\\sigma} $$\n$$ \\sqrt{N} = \\frac{2\\sigma (z_{1-\\alpha} + z_{1-\\beta})}{\\delta_A} $$\n$$ N = \\frac{4\\sigma^2 (z_{1-\\alpha} + z_{1-\\beta})^2}{\\delta_A^2} $$\nThe problem describes a blinded sample size re-estimation procedure. This involves using an interim estimate of the variance, $\\hat{\\sigma}^2 = 1.44$, to recalculate the required sample size to achieve the target power. The re-estimation preserves the originally planned critical value ($z_{1-\\alpha}$), the target power ($1-\\beta$), and the effect size of interest ($\\delta_A$). Therefore, we can use the derived sample size formula, replacing the planning variance $\\sigma^2 = 1$ with the interim estimate $\\hat{\\sigma}^2 = 1.44$. All other parameters remain the same.\n\nThe re-estimated total sample size, $N_{\\text{new}}$, is given by:\n$$ N_{\\text{new}} = \\frac{4\\hat{\\sigma}^2 (z_{1-\\alpha} + z_{1-\\beta})^2}{\\delta_A^2} $$\nWe substitute the given values:\n$\\hat{\\sigma}^2 = 1.44$\n$\\delta_A = 0.3$\n$\\alpha = 0.025 \\implies z_{1-\\alpha} = z_{0.975}$\n$1-\\beta = 0.9 \\implies z_{1-\\beta} = z_{0.9}$\n\nThe required quantiles from the standard normal distribution are $z_{0.975} \\approx 1.959964$ and $z_{0.9} \\approx 1.281552$.\nPlugging these into the equation for $N_{\\text{new}}$:\n$$ N_{\\text{new}} = \\frac{4(1.44) (z_{0.975} + z_{0.9})^2}{(0.3)^2} $$\n$$ N_{\\text{new}} = \\frac{5.76}{0.09} (1.959964 + 1.281552)^2 $$\n$$ N_{\\text{new}} = 64 \\times (3.241516)^2 $$\n$$ N_{\\text{new}} = 64 \\times 10.507427... $$\n$$ N_{\\text{new}} = 672.4753... $$\nThe problem requires the result to be rounded to four significant figures.\n$$ N_{\\text{new}} \\approx 672.5 $$\nThis value represents the continuous target for the total sample size across both arms needed to achieve $90\\%$ power under the observed interim variance.", "answer": "$$\n\\boxed{672.5}\n$$", "id": "4772912"}, {"introduction": "A core challenge in adaptive trials is combining data from multiple stages without inflating the Type I error rate. This practice introduces Fisher's combination test, a classic and intuitive method for pooling evidence from independent study stages. You will apply this technique to combine stage-wise $p$-values into a single, overall conclusion, thereby learning a foundational method for maintaining statistical validity in a multi-stage design. [@problem_id:4987179]", "problem": "In a translational medicine program evaluating a targeted therapy, a sponsor implements a pre-planned adaptive clinical trial with a $2$-stage design to allow sample size modification at interim while preserving the family-wise type I error rate. The primary hypothesis is one-sided, and the stage-wise $p$-values are computed from independent patient cohorts due to the internal pilot nature of the design. Assume that, under the global null hypothesis and given the independence of the stage-wise test statistics, the stage-wise $p$-values are independent and each is uniformly distributed on $(0,1)$. The observed stage-wise $p$-values are $p_1=0.08$ and $p_2=0.01$. Using Fisher’s combination testing framework, compute the combined $p$-value for these two stages and assess whether the trial achieves significance at one-sided $\\alpha=0.025$ while controlling the type I error under the null. Report only the combined $p$-value as a decimal number, rounded to four significant figures. Do not include any symbols or units in your final reported value.", "solution": "The task is to compute a combined $p$-value from two independent stages of a clinical trial using Fisher's combination testing framework. The given stage-wise $p$-values are $p_1 = 0.08$ and $p_2 = 0.01$. The problem states that under the global null hypothesis ($H_0$), these $p$-values are independent and uniformly distributed on the interval $(0, 1)$, which are the requisite assumptions for Fisher's method.\n\nFisher's method combines $k$ independent $p$-values ($p_1, p_2, \\dots, p_k$) into a single test statistic, denoted as $X^2$. The formula for this statistic is:\n$$ X^2 = -2 \\sum_{i=1}^{k} \\ln(p_i) $$\nUnder the global null hypothesis, this $X^2$ statistic follows a chi-squared ($\\chi^2$) distribution with $2k$ degrees of freedom. The combined $p$-value, $p_{comb}$, is then the probability of observing a value of the $\\chi^2$ statistic as extreme or more extreme than the one calculated from the observed $p$-values. This corresponds to the right-tail probability of the $\\chi^2_{2k}$ distribution.\n\nIn this problem, we have $k=2$ stages. The observed $p$-values are $p_1 = 0.08$ and $p_2 = 0.01$.\nFirst, we calculate the value of the test statistic, $X^2_{obs}$:\n$$ X^2_{obs} = -2 (\\ln(p_1) + \\ln(p_2)) $$\nSubstituting the given values:\n$$ X^2_{obs} = -2 (\\ln(0.08) + \\ln(0.01)) $$\nUsing the properties of the natural logarithm, we find the numerical values:\n$$ \\ln(0.08) \\approx -2.5257286 $$\n$$ \\ln(0.01) \\approx -4.6051702 $$\nThus, the test statistic is:\n$$ X^2_{obs} \\approx -2 (-2.5257286 - 4.6051702) = -2(-7.1308988) = 14.2617976 $$\n\nNext, we determine the degrees of freedom ($df$) for the chi-squared distribution:\n$$ df = 2k = 2 \\times 2 = 4 $$\nSo, our test statistic $X^2_{obs}$ is to be compared against a $\\chi^2$ distribution with $4$ degrees of freedom.\n\nThe combined $p$-value, $p_{comb}$, is the probability $P(\\chi^2_4 \\ge X^2_{obs})$. The cumulative distribution function (CDF) for a $\\chi^2$ distribution with $4$ degrees of freedom is $F(x; 4) = 1 - (1 + \\frac{x}{2})\\exp(-\\frac{x}{2})$. The $p$-value is the survival function, $1 - F(x; 4)$.\n$$ p_{comb} = P(\\chi^2_4 \\ge X^2_{obs}) = \\left(1 + \\frac{X^2_{obs}}{2}\\right) \\exp\\left(-\\frac{X^2_{obs}}{2}\\right) $$\nSubstituting the calculated value of $X^2_{obs}$:\n$$ p_{comb} \\approx \\left(1 + \\frac{14.2617976}{2}\\right) \\exp\\left(-\\frac{14.2617976}{2}\\right) $$\n$$ p_{comb} \\approx (1 + 7.1308988) \\exp(-7.1308988) $$\n$$ p_{comb} \\approx 8.1308988 \\times 0.00079998 $$\n$$ p_{comb} \\approx 0.0065046 $$\n\nThe problem asks for the result to be rounded to four significant figures. The first significant figure is $6$, followed by $5$, $0$, and $4$. The next digit is $6$, which requires rounding up the fourth significant digit.\n$$ p_{comb} \\approx 0.006505 $$\n\nThe problem also requests an assessment of significance at the one-sided $\\alpha=0.025$ level. We compare our combined $p$-value to $\\alpha$:\n$$ 0.006505  0.025 $$\nSince $p_{comb}  \\alpha$, the result is statistically significant. The global null hypothesis would be rejected, suggesting that the targeted therapy has a significant effect.\n\nThe final reported value is the combined $p$-value rounded to four significant figures.", "answer": "$$\\boxed{0.006505}$$", "id": "4987179"}, {"introduction": "Moving beyond $p$-value combination, the inverse-normal method offers a more flexible and widely used framework for analyzing adaptive trials. This method combines standardized test statistics ($Z$-scores) and naturally allows for weighting stages by their information content. This practice guides you through deriving the combination statistic from the fundamental principle of information additivity, illustrating a powerful and elegant approach central to modern adaptive design. [@problem_id:4950399]", "problem": "Consider a two-stage adaptive clinical trial using a preplanned combination testing framework to preserve Type I error under data-dependent adaptations between stages. Let the stagewise standardized efficient score statistics be $z_1$ and $z_2$, each computed from independent patient cohorts at stages $1$ and $2$, respectively. Under the null hypothesis of no treatment effect, assume the standard asymptotic properties for generalized linear models: the efficient score $U$ satisfies $U \\approx \\mathcal{N}(0, I)$, where $I$ is the Fisher information, and Fisher information adds across independent stages. Specifically, let $U_j$ be the stage-$j$ efficient score with variance $I_j$, and define the stagewise standardized statistics by $z_j = U_j / \\sqrt{I_j}$, which are independent and identically distributed as $\\mathcal{N}(0,1)$ under the null. Let the total Fisher information be $I = I_1 + I_2$ and the information fractions be $w_1 = I_1 / I$ and $w_2 = I_2 / I$.\n\nUsing only these principles—the additivity of efficient scores and Fisher information under independent sampling, and standardization by the square root of Fisher information—derive the linear combination $Z_{comb}$ of $z_1$ and $z_2$ that is standardized to $\\mathcal{N}(0,1)$ under the null and respects information-based weighting. Then, for $w_1 = 0.4$, $w_2 = 0.6$, $z_1 = 1.0$, and $z_2 = 2.1$, compute the numerical value of $Z_{comb}$ and the one-sided $p$-value for superiority defined as $p = \\Pr(Z \\geq Z_{comb})$ for $Z \\sim \\mathcal{N}(0,1)$. Express the $p$-value as a decimal. Round both $Z_{comb}$ and $p$ to four significant figures.", "solution": "The first step is to derive the expression for the combined test statistic, $Z_{comb}$. The problem requires that this statistic be a linear combination of the stagewise standardized statistics, $z_1$ and $z_2$, that it be standardized to a standard normal distribution $\\mathcal{N}(0,1)$ under the null hypothesis, and that it respects information-based weighting.\n\nWe begin with the fundamental principles stated: the additivity of the efficient score $U$ and the Fisher information $I$. For a two-stage trial with independent cohorts, the total efficient score is the sum of the stagewise scores, and the total Fisher information is the sum of the stagewise information measures.\n$$U_{total} = U_1 + U_2$$\n$$I_{total} = I_1 + I_2$$\nThe overall standardized test statistic for the full dataset, if it were analyzed in a single step, is defined as the total efficient score divided by the square root of the total Fisher information. Let us call this statistic $Z$.\n$$Z = \\frac{U_{total}}{\\sqrt{I_{total}}} = \\frac{U_1 + U_2}{\\sqrt{I_1 + I_2}}$$\nUnder the null hypothesis and appropriate regularity conditions, this overall statistic $Z$ is asymptotically distributed as $\\mathcal{N}(0,1)$.\n\nThe problem defines the stagewise standardized statistics as $z_j = U_j / \\sqrt{I_j}$ for $j=1, 2$. We can rearrange this definition to express the stagewise efficient scores in terms of the standardized statistics:\n$$U_1 = z_1 \\sqrt{I_1}$$\n$$U_2 = z_2 \\sqrt{I_2}$$\nNow, we substitute these expressions back into the formula for the overall statistic $Z$. This will yield the desired combination statistic $Z_{comb}$.\n$$Z_{comb} = \\frac{z_1 \\sqrt{I_1} + z_2 \\sqrt{I_2}}{\\sqrt{I_1 + I_2}}$$\nTo express this in terms of the information fractions $w_1 = I_1 / I_{total}$ and $w_2 = I_2 / I_{total}$, we can rewrite the expression as:\n$$Z_{comb} = \\frac{\\sqrt{I_1}}{\\sqrt{I_1 + I_2}} z_1 + \\frac{\\sqrt{I_2}}{\\sqrt{I_1 + I_2}} z_2$$\nRecognizing that $\\sqrt{w_1} = \\sqrt{I_1 / (I_1+I_2)} = \\sqrt{I_1} / \\sqrt{I_1+I_2}$ and similarly for $w_2$, we arrive at the final form for the information-weighted combination statistic:\n$$Z_{comb} = \\sqrt{w_1} z_1 + \\sqrt{w_2} z_2$$\nThis derivation successfully uses the principle of information additivity to construct a combined statistic from the stagewise components. As a check, we can verify its distribution. Given that $z_1, z_2 \\sim \\mathcal{N}(0,1)$ and are independent, the mean of $Z_{comb}$ is $E[Z_{comb}] = \\sqrt{w_1} E[z_1] + \\sqrt{w_2} E[z_2] = \\sqrt{w_1}(0) + \\sqrt{w_2}(0) = 0$. The variance is $Var(Z_{comb}) = Var(\\sqrt{w_1} z_1 + \\sqrt{w_2} z_2) = (\\sqrt{w_1})^2 Var(z_1) + (\\sqrt{w_2})^2 Var(z_2) = w_1(1) + w_2(1) = w_1 + w_2$. By definition, $w_1 + w_2 = (I_1/I_{total}) + (I_2/I_{total}) = (I_1+I_2)/I_{total} = 1$. Thus, $Var(Z_{comb}) = 1$. Since $Z_{comb}$ is a linear combination of independent normal variables, it is also normally distributed. Therefore, $Z_{comb} \\sim \\mathcal{N}(0,1)$, as required.\n\nNext, we compute the numerical value of $Z_{comb}$ using the provided data: $w_1 = 0.4$, $w_2 = 0.6$, $z_1 = 1.0$, and $z_2 = 2.1$.\n$$Z_{comb} = \\sqrt{0.4} (1.0) + \\sqrt{0.6} (2.1)$$\n$$Z_{comb} \\approx (0.63245553) (1.0) + (0.77459667) (2.1)$$\n$$Z_{comb} \\approx 0.63245553 + 1.62665290$$\n$$Z_{comb} \\approx 2.25910843$$\nRounding to four significant figures, we get $Z_{comb} = 2.259$.\n\nFinally, we compute the one-sided $p$-value, defined as $p = \\Pr(Z \\geq Z_{comb})$ for a standard normal random variable $Z \\sim \\mathcal{N}(0,1)$. This is calculated as $1 - \\Phi(Z_{comb})$, where $\\Phi$ is the cumulative distribution function (CDF) of the standard normal distribution. Using the unrounded value of $Z_{comb}$ for precision:\n$$p = \\Pr(Z \\geq 2.25910843)$$\n$$p = 1 - \\Phi(2.25910843)$$\nUsing a standard normal distribution table or computational software, we find the value.\n$$p \\approx 1 - 0.98806392 = 0.01193608$$\nRounding this value to four significant figures gives $p = 0.01194$.\nThe two requested values are the combined test statistic $Z_{comb}$ and the corresponding one-sided $p$-value.", "answer": "$$\\boxed{\\begin{pmatrix} 2.259  0.01194 \\end{pmatrix}}$$", "id": "4950399"}]}