{"hands_on_practices": [{"introduction": "A cornerstone of statistical inference is the construction of a confidence interval for a single proportion. This exercise goes beyond simple formulas to explore the theoretical underpinnings of interval estimation, tasking you with deriving and critiquing the common Wald interval and the superior Wilson score interval from first principles [@problem_id:4957390]. By examining the case of zero observed events, you will gain a critical appreciation for how an interval's construction method determines its performance and reliability, particularly at the boundaries of the parameter space.", "problem": "A multicenter Phase II oncology study monitors the incidence of immediate hypersensitivity during infusion of a novel monoclonal antibody. Let $p$ denote the true probability that any given infusion results in a hypersensitivity reaction. Across $n$ independent infusions, the number of observed reactions $X$ is modeled as a binomial random variable with probability mass function $P(X=x \\mid p) = \\binom{n}{x} p^{x} (1-p)^{n-x}$ for $x \\in \\{0,1,\\dots,n\\}$. In this study, $n$ consecutive infusions were observed with $x=0$ reactions.\n\nTask:\n1. Starting from the binomial model and the Central Limit Theorem (CLT), construct the so-called Wald confidence interval for the binomial proportion $p$ by using the maximum likelihood estimator (MLE) of $p$ and its asymptotic distribution. Provide a principled critique of the Wald interval’s coverage properties, focusing on parameter boundary behavior $p \\approx 0$ and $p \\approx 1$, and discuss why these properties arise from its construction.\n2. Starting from the score test for $H_{0}: p=p_{0}$ under the binomial model, invert the two-sided test to derive the Wilson score confidence interval for $p$ at nominal confidence level $1-\\alpha$. Your derivation should make clear how the test inversion leads to a quadratic inequality in $p$ and yields an interval that differs in center and scale from the Wald interval. Do not assume any shortcut formula; derive the analytic expression from first principles.\n3. Apply your derived Wilson score interval to the study case with $n=62$, $x=0$, and $1-\\alpha=0.95$ (so that $z_{1-\\alpha/2} \\approx 1.96$ is the quantile of the standard normal distribution). Compute the Wilson interval’s upper bound for $p$ for this case. Express the final answer as a decimal proportion and round your answer to four significant figures.", "solution": "This problem addresses the construction and properties of confidence intervals for a binomial proportion, $p$. We will first derive and critique the Wald interval, then derive the superior Wilson score interval, and finally apply the Wilson interval to the given clinical study data.\n\n**Part 1: The Wald Confidence Interval and its Critique**\n\nThe number of observed reactions $X$ in $n$ infusions follows a binomial distribution, $X \\sim \\text{Binomial}(n, p)$. The likelihood function for $p$ given an observation $X=x$ is proportional to $p^x (1-p)^{n-x}$. The log-likelihood function is $\\ell(p; x) = x \\ln(p) + (n-x) \\ln(1-p)$.\n\nTo find the maximum likelihood estimator (MLE) of $p$, we differentiate $\\ell(p)$ with respect to $p$ and set the result to zero:\n$$\n\\frac{d\\ell}{dp} = \\frac{x}{p} - \\frac{n-x}{1-p} = 0\n$$\nSolving for $p$ yields the MLE, $\\hat{p} = \\frac{x}{n}$.\n\nThe Central Limit Theorem (CLT), as applied to the sum of independent Bernoulli trials, states that the sample proportion $\\hat{p}$ is asymptotically normally distributed. More formally, from the properties of MLEs, $\\hat{p}$ is consistent and asymptotically normal with mean $p$ and variance equal to the inverse of the Fisher Information. The Fisher information for $n$ trials is $I_n(p) = \\frac{n}{p(1-p)}$. Thus, the asymptotic variance of $\\hat{p}$ is $\\text{Var}(\\hat{p}) = \\frac{p(1-p)}{n}$.\nThe asymptotic distribution is:\n$$\n\\hat{p} \\stackrel{a}{\\sim} N\\left(p, \\frac{p(1-p)}{n}\\right)\n$$\nFrom this, we can form a standardized pivotal quantity:\n$$\nZ = \\frac{\\hat{p} - p}{\\sqrt{\\frac{p(1-p)}{n}}} \\stackrel{a}{\\sim} N(0,1)\n$$\nThe Wald confidence interval is constructed by replacing the unknown parameter $p$ in the standard error term with its consistent estimator $\\hat{p}$. The resulting statistic is:\n$$\nW = \\frac{\\hat{p} - p}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}} \\stackrel{a}{\\sim} N(0,1)\n$$\nA $100(1-\\alpha)\\%$ confidence interval is found by taking the set of $p$ values for which $|W| \\le z_{1-\\alpha/2}$, where $z_{1-\\alpha/2}$ is the upper $1-\\alpha/2$ quantile of the standard normal distribution. This leads to the interval:\n$$\n\\hat{p} \\pm z_{1-\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n$$\nCritique of the Wald Interval: The Wald interval, despite its simple and intuitive construction, possesses poor performance, particularly when the true parameter $p$ is near the boundaries of the parameter space, i.e., $p \\approx 0$ or $p \\approx 1$. These poor coverage properties arise directly from its construction. The critical flaw is the \"plug-in\" estimation of the standard error, $\\sqrt{\\hat{p}(1-\\hat{p})/n}$. When the observed number of successes $x$ is $0$ or $n$, the MLE $\\hat{p}$ is $0$ or $1$, respectively.\n- If $x=0$, then $\\hat{p}=0$. The estimated standard error becomes $\\sqrt{0(1-0)/n} = 0$. The Wald interval collapses to $[0, 0]$, a zero-width interval. This absurdly implies that $p$ is exactly $0$ with $100(1-\\alpha)\\%$ confidence, which is an unjustifiably strong conclusion from a finite sample. If the true $p$ is small but positive, this interval will fail to cover it, leading to an actual coverage probability of $0$.\n- Similarly, if $x=n$, then $\\hat{p}=1$, and the interval collapses to $[1, 1]$.\nThis degeneracy at the boundaries is a severe failure. Furthermore, for values of $p$ near $0$ or $1$, the distribution of $\\hat{p}$ is highly skewed and the normal approximation is poor unless $n$ is extremely large. Consequently, the actual coverage probability of the Wald interval can be much lower than the nominal $1-\\alpha$ level and can fluctuate erratically as a function of $p$ and $n$.\n\n**Part 2: The Wilson Score Confidence Interval**\n\nThe Wilson interval is derived by inverting the score test, which avoids the problematic plug-in estimation of the standard error found in the Wald interval's construction. The score test for the null hypothesis $H_0: p = p_0$ uses the test statistic:\n$$\nZ(p_0) = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}\n$$\nUnder $H_0$, this statistic is asymptotically distributed as $N(0,1)$. Observe that the standard error in the denominator is a function of the hypothesized value $p_0$, not the estimate $\\hat{p}$.\n\nA $100(1-\\alpha)\\%$ confidence interval is formed by the set of all values $p_0$ for which we would *not* reject the null hypothesis $H_0: p=p_0$ at significance level $\\alpha$. For a two-sided test, this non-rejection region is defined by $|Z(p_0)| \\le z_{1-\\alpha/2}$. Letting $z = z_{1-\\alpha/2}$, this is equivalent to:\n$$\n(Z(p_0))^2 \\le z^2\n$$\nSubstituting the expression for the score statistic yields the inequality:\n$$\n\\frac{(\\hat{p} - p_0)^2}{\\frac{p_0(1-p_0)}{n}} \\le z^2\n$$\nThis inequality must now be solved for $p_0$. Multiplying both sides by the denominator gives:\n$$\nn(\\hat{p} - p_0)^2 \\le z^2 p_0(1-p_0)\n$$\nThis is the quadratic inequality in $p_0$ that the problem asks for. To find the interval, we expand and rearrange the terms to the standard quadratic form $A p_0^2 + B p_0 + C \\le 0$:\n$$\nn(\\hat{p}^2 - 2\\hat{p}p_0 + p_0^2) \\le z^2 p_0 - z^2 p_0^2\n$$\n$$\n(n+z^2)p_0^2 - (2n\\hat{p} + z^2)p_0 + n\\hat{p}^2 \\le 0\n$$\nThis describes an upward-opening parabola in $p_0$, as the leading coefficient $A=(n+z^2)$ is positive. The inequality holds for values of $p_0$ between the roots of the corresponding quadratic equation:\n$$\n(n+z^2)p_0^2 - (2n\\hat{p} + z^2)p_0 + n\\hat{p}^2 = 0\n$$\nUsing the quadratic formula, $p_0 = \\frac{-B \\pm \\sqrt{B^2-4AC}}{2A}$, the roots are:\n$$\np_0 = \\frac{(2n\\hat{p} + z^2) \\pm \\sqrt{(2n\\hat{p} + z^2)^2 - 4(n+z^2)(n\\hat{p}^2)}}{2(n+z^2)}\n$$\nSimplifying the discriminant:\n$$\n(2n\\hat{p} + z^2)^2 - 4(n+z^2)(n\\hat{p}^2) = 4n^2\\hat{p}^2 + 4n\\hat{p}z^2 + z^4 - 4n^2\\hat{p}^2 - 4nz^2\\hat{p}^2 = z^2(z^2 + 4n\\hat{p}(1-\\hat{p}))\n$$\nThe roots, which form the lower and upper bounds of the Wilson interval, are:\n$$\n\\frac{2n\\hat{p} + z^2 \\pm z\\sqrt{4n\\hat{p}(1-\\hat{p}) + z^2}}{2(n+z^2)}\n$$\nThis expression can be rearranged to highlight the difference in center and scale from the Wald interval. The center of the Wilson interval is $\\frac{n\\hat{p} + z^2/2}{n+z^2} = \\frac{x+z^2/2}{n+z^2}$, which is a weighted average of the sample proportion $\\hat{p}$ and $1/2$. This pulls the center away from the boundaries $0$ and $1$, improving performance. The scale (half-width) is also more complex and does not become zero when $\\hat{p}=0$ or $\\hat{p}=1$.\n\n**Part 3: Application to the Study Case**\n\nWe are given the following data: $n=62$ infusions, $x=0$ reactions. The desired confidence level is $1-\\alpha=0.95$, so $\\alpha=0.05$. The corresponding standard normal quantile is $z_{1-\\alpha/2} = z_{0.975} \\approx 1.96$.\n\nThe sample proportion is $\\hat{p} = x/n = 0/62 = 0$. We use the formula derived for the Wilson interval's bounds. We are asked to compute the upper bound.\n$$\n\\text{Upper Bound} = \\frac{2n\\hat{p} + z^2 + z\\sqrt{4n\\hat{p}(1-\\hat{p}) + z^2}}{2(n+z^2)}\n$$\nSubstituting the given values:\n$$\n\\text{Upper Bound} = \\frac{2(62)(0) + (1.96)^2 + 1.96\\sqrt{4(62)(0)(1-0) + (1.96)^2}}{2(62+(1.96)^2)}\n$$\n$$\n= \\frac{(1.96)^2 + 1.96\\sqrt{(1.96)^2}}{2(62+(1.96)^2)}\n$$\n$$\n= \\frac{(1.96)^2 + 1.96(1.96)}{2(62+(1.96)^2)} = \\frac{2(1.96)^2}{2(62+(1.96)^2)}\n$$\n$$\n= \\frac{(1.96)^2}{62+(1.96)^2} = \\frac{3.8416}{62+3.8416} = \\frac{3.8416}{65.8416}\n$$\nPerforming the division gives approximately $0.05834800$.\n\nThe problem requires rounding the final answer to four significant figures. The first significant figure is $5$, the second is $8$, the third is $3$, and the fourth is $4$. The fifth significant figure is $8$. Since $8 \\ge 5$, we round up the fourth significant figure.\nTherefore, the upper bound is $0.05835$.\n\nThe full Wilson interval is $[0, 0.05835]$. This interval, unlike the Wald interval's $[0,0]$, correctly reflects the uncertainty in $p$ and provides a non-zero upper limit on the plausible rate of hypersensitivity reactions.", "answer": "$$\n\\boxed{0.05835}\n$$", "id": "4957390"}, {"introduction": "Building upon single-parameter estimation, we often need to compare parameters from two independent populations, for instance, by calculating a risk ratio. This practice introduces the delta method, a fundamental tool for approximating the variance of a function of asymptotically normal estimators [@problem_id:4957413]. By deriving the confidence interval for a risk ratio on the log scale, you will develop the skills to handle non-linear parameter transformations, a common challenge in medical statistics.", "problem": "A clinical epidemiology team evaluates the effect of a new perioperative antiseptic protocol on the risk of surgical-site infection in adult patients. In a prospective multicenter cohort, arm $1$ (hospitals that adopted the protocol) enrolled $n_{1}$ patients, of whom $x_{1}$ developed infection, and arm $2$ (hospitals that maintained prior practice) enrolled $n_{2}$ patients, of whom $x_{2}$ developed infection. Assume independent Bernoulli sampling within arms, and let $p_{1}$ and $p_{2}$ denote the true infection risks in arms $1$ and $2$, respectively. The parameter of interest is the risk ratio $\\text{RR} = p_{1} / p_{2}$.\n\nStarting from the Central Limit Theorem (CLT) for sample proportions under Bernoulli sampling and the delta method for smooth transformations of asymptotically normal estimators, derive the large-sample variance of the log risk ratio estimator $\\log \\hat{\\text{RR}}$ under binomial sampling, and use this to construct a two-sided $95\\%$ confidence interval on the natural scale for $\\text{RR}$. In your derivation, treat $\\hat{p}_{i} = x_{i} / n_{i}$ as the Maximum Likelihood Estimator (MLE) of $p_{i}$ in each arm, justify the independence of $\\hat{p}_{1}$ and $\\hat{p}_{2}$, and apply the delta method to the transformation $g(p_{1}, p_{2}) = \\log p_{1} - \\log p_{2}$.\n\nNow consider the following data: arm $1$ has $n_{1} = 800$ patients with $x_{1} = 120$ infections, and arm $2$ has $n_{2} = 900$ patients with $x_{2} = 180$ infections. Using a two-sided confidence level of $95\\%$ and the standard normal quantile $z_{0.975} = 1.96$, compute the confidence interval bounds on the log scale and then transform them back to the $\\text{RR}$ scale by exponentiation. Report only the lower limit of the $95\\%$ confidence interval for $\\text{RR}$, rounded to four significant figures. No units are required.", "solution": "### Derivation and Solution\n\nThe problem requires the derivation of a confidence interval for the risk ratio, $\\text{RR} = p_1 / p_2$. The standard approach, as specified, involves working on the logarithmic scale to improve the normal approximation, then transforming back.\n\nLet $\\hat{p}_1 = x_1/n_1$ and $\\hat{p}_2 = x_2/n_2$ be the sample proportions of infections in arm $1$ and arm $2$, respectively. These are the Maximum Likelihood Estimators (MLEs) for the true proportions $p_1$ and $p_2$.\n\nUnder the assumption of Bernoulli sampling with a large sample size $n_i$, the Central Limit Theorem (CLT) states that the distribution of the sample proportion $\\hat{p}_i$ is approximately normal:\n$$ \\hat{p}_i \\approx \\mathcal{N}\\left(p_i, \\frac{p_i(1-p_i)}{n_i}\\right) $$\nfor $i \\in \\{1, 2\\}$.\n\nThe problem states that the two arms of the cohort study are independent. Arm $1$ consists of hospitals adopting the new protocol, and arm $2$ consists of different hospitals maintaining the prior practice. Since the samples are drawn from two distinct and non-overlapping populations (or arms of a study), the estimators $\\hat{p}_1$ and $\\hat{p}_2$ are statistically independent.\n\nWe are interested in the function $g(p_1, p_2) = \\log(p_1) - \\log(p_2)$. The estimator for this quantity is $\\log(\\hat{\\text{RR}}) = g(\\hat{p}_1, \\hat{p}_2) = \\log(\\hat{p}_1) - \\log(\\hat{p}_2)$. We apply the multivariate delta method to find its large-sample variance. The variance of a function $g(\\hat{\\theta})$ of a random vector $\\hat{\\theta}$ is approximately $(\\nabla g)^T \\Sigma (\\nabla g)$, where $\\nabla g$ is the gradient of $g$ and $\\Sigma$ is the covariance matrix of $\\hat{\\theta}$.\n\nHere, the vector of estimators is $\\hat{\\theta} = (\\hat{p}_1, \\hat{p}_2)^T$. The gradient of $g(p_1, p_2)$ is:\n$$ \\nabla g(p_1, p_2) = \\begin{pmatrix} \\frac{\\partial g}{\\partial p_1} \\\\ \\frac{\\partial g}{\\partial p_2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{p_1} \\\\ -\\frac{1}{p_2} \\end{pmatrix} $$\nDue to the independence of $\\hat{p}_1$ and $\\hat{p}_2$, their covariance is $0$. The covariance matrix of $(\\hat{p}_1, \\hat{p}_2)^T$ is diagonal:\n$$ \\Sigma = \\begin{pmatrix} \\text{Var}(\\hat{p}_1)  0 \\\\ 0  \\text{Var}(\\hat{p}_2) \\end{pmatrix} = \\begin{pmatrix} \\frac{p_1(1-p_1)}{n_1}  0 \\\\ 0  \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix} $$\nThe asymptotic variance of $\\log(\\hat{\\text{RR}})$ is then:\n$$ \\text{Var}(\\log \\hat{\\text{RR}}) \\approx [\\nabla g(p_1, p_2)]^T \\Sigma [\\nabla g(p_1, p_2)] $$\n$$ \\text{Var}(\\log \\hat{\\text{RR}}) \\approx \\begin{pmatrix} \\frac{1}{p_1}  -\\frac{1}{p_2} \\end{pmatrix} \\begin{pmatrix} \\frac{p_1(1-p_1)}{n_1}  0 \\\\ 0  \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{p_1} \\\\ -\\frac{1}{p_2} \\end{pmatrix} $$\n$$ \\text{Var}(\\log \\hat{\\text{RR}}) \\approx \\left(\\frac{1}{p_1}\\right)^2 \\text{Var}(\\hat{p}_1) + \\left(-\\frac{1}{p_2}\\right)^2 \\text{Var}(\\hat{p}_2) $$\n$$ \\text{Var}(\\log \\hat{\\text{RR}}) \\approx \\frac{1}{p_1^2} \\left(\\frac{p_1(1-p_1)}{n_1}\\right) + \\frac{1}{p_2^2} \\left(\\frac{p_2(1-p_2)}{n_2}\\right) $$\n$$ \\text{Var}(\\log \\hat{\\text{RR}}) \\approx \\frac{1-p_1}{n_1 p_1} + \\frac{1-p_2}{n_2 p_2} $$\nTo construct a confidence interval, we need to estimate this variance from the data. We substitute the estimators $\\hat{p}_1$ and $\\hat{p}_2$ for the true parameters $p_1$ and $p_2$. The estimated variance, which is the square of the standard error of $\\log(\\hat{\\text{RR}})$, is:\n$$ \\widehat{\\text{Var}}(\\log \\hat{\\text{RR}}) = \\frac{1-\\hat{p}_1}{n_1 \\hat{p}_1} + \\frac{1-\\hat{p}_2}{n_2 \\hat{p}_2} $$\nSubstituting $\\hat{p}_i = x_i/n_i$:\n$$ \\widehat{\\text{Var}}(\\log \\hat{\\text{RR}}) = \\frac{1 - x_1/n_1}{n_1 (x_1/n_1)} + \\frac{1 - x_2/n_2}{n_2 (x_2/n_2)} = \\frac{(n_1-x_1)/n_1}{x_1} + \\frac{(n_2-x_2)/n_2}{x_2} $$\n$$ \\widehat{\\text{Var}}(\\log \\hat{\\text{RR}}) = \\frac{n_1-x_1}{n_1 x_1} + \\frac{n_2-x_2}{n_2 x_2} = \\left(\\frac{1}{x_1} - \\frac{1}{n_1}\\right) + \\left(\\frac{1}{x_2} - \\frac{1}{n_2}\\right) $$\nA two-sided $95\\%$ confidence interval for $\\log(\\text{RR})$ is constructed as:\n$$ \\log(\\hat{\\text{RR}}) \\pm z_{0.975} \\sqrt{\\widehat{\\text{Var}}(\\log \\hat{\\text{RR}})} $$\nTo obtain the confidence interval for $\\text{RR}$ itself, we exponentiate the limits of the interval for $\\log(\\text{RR})$.\n\nNow, we apply this to the given data:\n- Arm $1$: $n_1 = 800$, $x_1 = 120$.\n- Arm $2$: $n_2 = 900$, $x_2 = 180$.\n\nFirst, compute the point estimates:\n$$ \\hat{p}_1 = \\frac{x_1}{n_1} = \\frac{120}{800} = 0.15 $$\n$$ \\hat{p}_2 = \\frac{x_2}{n_2} = \\frac{180}{900} = 0.20 $$\nThe estimated risk ratio is:\n$$ \\hat{\\text{RR}} = \\frac{\\hat{p}_1}{\\hat{p}_2} = \\frac{0.15}{0.20} = 0.75 $$\nThe natural logarithm of the estimated risk ratio is:\n$$ \\log(\\hat{\\text{RR}}) = \\ln(0.75) \\approx -0.28768 $$\nNext, compute the estimated variance of $\\log(\\hat{\\text{RR}})$:\n$$ \\widehat{\\text{Var}}(\\log \\hat{\\text{RR}}) = \\frac{1}{x_1} - \\frac{1}{n_1} + \\frac{1}{x_2} - \\frac{1}{n_2} = \\frac{1}{120} - \\frac{1}{800} + \\frac{1}{180} - \\frac{1}{900} $$\nLet's compute the terms:\n$$ \\frac{1}{120} \\approx 0.0083333... $$\n$$ \\frac{1}{800} = 0.00125 $$\n$$ \\frac{1}{180} \\approx 0.0055555... $$\n$$ \\frac{1}{900} \\approx 0.0011111... $$\n$$ \\widehat{\\text{Var}}(\\log \\hat{\\text{RR}}) \\approx 0.0083333 - 0.00125 + 0.0055556 - 0.0011111 \\approx 0.0115278 $$\nUsing fractions for precision:\n$$ \\widehat{\\text{Var}}(\\log \\hat{\\text{RR}}) = \\left(\\frac{1}{120} - \\frac{1}{800}\\right) + \\left(\\frac{1}{180} - \\frac{1}{900}\\right) = \\left(\\frac{20-3}{2400}\\right) + \\left(\\frac{5-1}{900}\\right) = \\frac{17}{2400} + \\frac{4}{900} = \\frac{17}{2400} + \\frac{1}{225} $$\nThe least common multiple of $2400$ and $225$ is $7200$.\n$$ \\widehat{\\text{Var}}(\\log \\hat{\\text{RR}}) = \\frac{17 \\times 3}{7200} + \\frac{1 \\times 32}{7200} = \\frac{51+32}{7200} = \\frac{83}{7200} $$\nThe standard error (SE) is the square root of the variance:\n$$ \\text{SE}(\\log \\hat{\\text{RR}}) = \\sqrt{\\frac{83}{7200}} \\approx 0.107368 $$\nThe $95\\%$ confidence interval for $\\log(\\text{RR})$ is:\n$$ \\log(\\hat{\\text{RR}}) \\pm z_{0.975} \\times \\text{SE}(\\log \\hat{\\text{RR}}) $$\n$$ -0.28768 \\pm 1.96 \\times 0.107368 $$\n$$ -0.28768 \\pm 0.210441 $$\nThe lower limit for $\\log(\\text{RR})$ is:\n$$ \\text{LL}_{\\log} = -0.28768 - 0.210441 = -0.498121 $$\nThe upper limit for $\\log(\\text{RR})$ is:\n$$ \\text{UL}_{\\log} = -0.28768 + 0.210441 = -0.077239 $$\nTo get the confidence interval for $\\text{RR}$, we exponentiate these bounds. The question asks for the lower limit of the $95\\%$ confidence interval for $\\text{RR}$.\n$$ \\text{LL}_{\\text{RR}} = \\exp(\\text{LL}_{\\log}) = \\exp(-0.498121) \\approx 0.60767 $$\nRounding to four significant figures, the lower limit is $0.6077$.", "answer": "$$\\boxed{0.6077}$$", "id": "4957413"}, {"introduction": "A well-constructed confidence interval is not just a tool for analysis but also a critical component of study design. This final exercise shifts the focus from analyzing data to planning a study, requiring you to determine the sample size needed to achieve a desired level of precision [@problem_id:4957371]. This task will solidify your understanding of the factors that govern an interval's width and highlight the essential distinction between statistical precision and the magnitude of a clinically relevant effect.", "problem": "A parallel two-arm randomized clinical trial will compare a new antihypertensive drug against placebo on the primary endpoint of change in systolic blood pressure, measured in $\\mathrm{mmHg}$. Investigators judge that a mean difference of $\\delta^{\\star} = 5$ $\\mathrm{mmHg}$ in favor of the drug would be clinically relevant in magnitude, but they wish to design the study for statistical precision: specifically, they want the two-sided Confidence Interval (CI) for the between-arm mean difference to have a prespecified total width $W^{\\star} = 6$ $\\mathrm{mmHg}$ at confidence level $0.95$. Historical data from a comparable population suggest a common outcome standard deviation of $\\sigma = 12$ $\\mathrm{mmHg}$. Assume equal allocation, independent participants, and that outcome values are independent and identically distributed conditionally on treatment arm with a common variance. For planning, use the standard normal quantile corresponding to two-sided coverage $0.95$. Anticipate a loss to follow-up proportion of $d = 0.15$ that renders those participants’ outcomes unusable for the primary analysis.\n\nStarting only from definitions and well-tested facts about sampling distributions of sample means and the construction of two-sided confidence intervals for a normal location parameter, derive the relationship between sample size and CI width for the difference in two independent means under equal allocation. Use this derivation to compute the smallest total number of participants to enroll so that, after losses to follow-up at proportion $d$, the primary analysis will achieve CI width no greater than $W^{\\star}$ with confidence level $0.95$.\n\nIn your derivation, make explicit the distinction between statistical precision (interval width) and clinical relevance (effect magnitude) by identifying which quantities encode each concept. Report the final answer as the minimal total enrollment count (a single integer). No rounding to a set number of significant figures is required; report the exact minimal integer that satisfies the design requirement.", "solution": "The problem requires the calculation of the total number of participants to enroll in a two-arm randomized clinical trial to achieve a prespecified confidence interval width for the difference in means. The solution is derived from the fundamental principles of statistical estimation.\n\nLet the treatment arm be denoted by the subscript $T$ and the placebo arm by $P$. The true mean changes in systolic blood pressure are $\\mu_T$ and $\\mu_P$, respectively. The parameter of interest is the difference in these means, $\\Delta = \\mu_T - \\mu_P$.\n\nThe study design specifies equal allocation. Let $n$ be the number of participants per arm whose data are available for the primary analysis. The total sample size for analysis is $N_{analysis} = 2n$. Let $\\bar{X}_T$ and $\\bar{X}_P$ be the sample mean changes in SBP for the treatment and placebo arms. The point estimator for $\\Delta$ is $\\hat{\\Delta} = \\bar{X}_T - \\bar{X}_P$.\n\nThe problem states that outcomes are independent and identically distributed conditionally on the treatment arm, with a common outcome standard deviation $\\sigma$. From foundational statistical theory, the sampling distributions of the sample means are approximately normal (due to the Central Limit Theorem, or exactly normal if the underlying data are normal):\n$\\bar{X}_T \\sim \\mathcal{N}(\\mu_T, \\sigma^2/n)$\n$\\bar{X}_P \\sim \\mathcal{N}(\\mu_P, \\sigma^2/n)$\n\nBecause the two arms are independent, the sampling distribution of the estimator $\\hat{\\Delta}$ is also normal. The expectation of the estimator is $E[\\hat{\\Delta}] = E[\\bar{X}_T] - E[\\bar{X}_P] = \\mu_T - \\mu_P = \\Delta$, which means $\\hat{\\Delta}$ is an unbiased estimator of $\\Delta$. The variance of the estimator is the sum of the variances of the sample means:\n$$\n\\mathrm{Var}(\\hat{\\Delta}) = \\mathrm{Var}(\\bar{X}_T) + \\mathrm{Var}(\\bar{X}_P) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n} = \\frac{2\\sigma^2}{n}\n$$\nThe standard error of the estimator is the square root of its variance:\n$$\n\\mathrm{SE}(\\hat{\\Delta}) = \\sqrt{\\frac{2\\sigma^2}{n}} = \\sigma\\sqrt{\\frac{2}{n}}\n$$\nA two-sided confidence interval (CI) for $\\Delta$ at a confidence level of $1-\\alpha$ is constructed as:\n$$\n\\hat{\\Delta} \\pm z_{1-\\alpha/2} \\cdot \\mathrm{SE}(\\hat{\\Delta})\n$$\nwhere $z_{1-\\alpha/2}$ is the $(1-\\alpha/2)$-th quantile of the standard normal distribution. The total width, $W$, of this confidence interval is the difference between its upper and lower bounds:\n$$\nW = (\\hat{\\Delta} + z_{1-\\alpha/2} \\cdot \\mathrm{SE}(\\hat{\\Delta})) - (\\hat{\\Delta} - z_{1-\\alpha/2} \\cdot \\mathrm{SE}(\\hat{\\Delta})) = 2 \\cdot z_{1-\\alpha/2} \\cdot \\mathrm{SE}(\\hat{\\Delta})\n$$\nSubstituting the expression for the standard error, we derive the relationship between sample size and CI width:\n$$\nW = 2 \\cdot z_{1-\\alpha/2} \\cdot \\sigma\\sqrt{\\frac{2}{n}}\n$$\nThis equation formalizes the concept of statistical precision. The CI width $W$ is determined by the confidence level ($1-\\alpha$, via $z_{1-\\alpha/2}$), the outcome variability ($\\sigma$), and the per-arm sample size ($n$). The problem specifies a precision-based sample size calculation, requiring the achieved width $W$ to be no greater than a target width $W^{\\star} = 6$ $\\mathrm{mmHg}$. The confidence level is given as $0.95$.\n\nIt is crucial to distinguish this concept of statistical precision from clinical relevance. Clinical relevance is encoded by the quantity $\\delta^{\\star} = 5$ $\\mathrm{mmHg}$, which represents the magnitude of the treatment effect considered clinically meaningful. This value would be used in a power-based sample size calculation (i.e., to ensure a high probability of detecting such an effect if it exists) but is not part of the precision-based calculation requested here.\n\nTo find the required sample size, we set $W$ to the target width $W^{\\star}$ and solve for the number of participants. It is more convenient to first solve for the total analysis sample size, $N_{analysis} = 2n$. Since $n = N_{analysis}/2$, we can rewrite the standard error as $\\mathrm{SE}(\\hat{\\Delta}) = \\sigma\\sqrt{2/(N_{analysis}/2)} = \\sigma\\sqrt{4/N_{analysis}} = 2\\sigma/\\sqrt{N_{analysis}}$.\nThe width becomes:\n$$\nW^{\\star} = 2 \\cdot z_{1-\\alpha/2} \\cdot \\frac{2\\sigma}{\\sqrt{N_{analysis}}} = \\frac{4 \\cdot z_{1-\\alpha/2} \\cdot \\sigma}{\\sqrt{N_{analysis}}}\n$$\nSolving for $N_{analysis}$:\n$$\n\\sqrt{N_{analysis}} = \\frac{4 \\cdot z_{1-\\alpha/2} \\cdot \\sigma}{W^{\\star}} \\implies N_{analysis} = \\left(\\frac{4 \\cdot z_{1-\\alpha/2} \\cdot \\sigma}{W^{\\star}}\\right)^2\n$$\nNow we substitute the given values into this derived formula:\n- Target CI width: $W^{\\star} = 6$ $\\mathrm{mmHg}$.\n- Common standard deviation: $\\sigma = 12$ $\\mathrm{mmHg}$.\n- Confidence level: $1-\\alpha = 0.95$, so $\\alpha = 0.05$. The required quantile is $z_{1-0.05/2} = z_{0.975}$, which for a standard normal distribution is approximately $1.96$.\n\n$$\nN_{analysis} = \\left(\\frac{4 \\cdot 1.96 \\cdot 12}{6}\\right)^2 = \\left(4 \\cdot 1.96 \\cdot 2\\right)^2 = (15.68)^2 = 245.8624\n$$\nThis is the minimum number of participants with complete data needed to achieve the desired CI width.\n\nThe problem states that a proportion $d = 0.15$ of participants are expected to be lost to follow-up. To account for this, we must enroll a larger number of participants, $N_{enroll}$, such that the number remaining after attrition is at least $N_{analysis}$.\nThe number of participants available for analysis is $N_{enroll} \\cdot (1-d)$. We require:\n$$\nN_{enroll} \\cdot (1-d) \\ge N_{analysis}\n$$\nSolving for $N_{enroll}$:\n$$\nN_{enroll} \\ge \\frac{N_{analysis}}{1-d} = \\frac{245.8624}{1-0.15} = \\frac{245.8624}{0.85} \\approx 289.25\n$$\nSince the number of enrolled participants must be an integer, we must take the ceiling of this value to satisfy the inequality. The smallest integer value for $N_{enroll}$ is $290$. This total enrollment can be split equally between the two arms, with $145$ participants per arm, satisfying the equal allocation constraint.", "answer": "$$\n\\boxed{290}\n$$", "id": "4957371"}]}