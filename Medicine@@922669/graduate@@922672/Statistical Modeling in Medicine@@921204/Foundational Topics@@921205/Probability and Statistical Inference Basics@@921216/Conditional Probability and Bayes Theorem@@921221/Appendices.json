{"hands_on_practices": [{"introduction": "A cornerstone of Bayesian statistics is the ability to formally update our knowledge about an unknown parameter in light of new evidence. This exercise demonstrates this process using the classic Beta-Binomial conjugate model, a workhorse for modeling rates and proportions in medicine. By deriving the posterior distribution for an infection probability, you will practice the fundamental mechanics of Bayes' theorem and see how prior beliefs are combined with observed data to yield an updated state of knowledge [@problem_id:5220970].", "problem": "A hospital deploys an Artificial Intelligence (AI) clinical decision support model to flag early postoperative infections from wearable temperature data streams. In a 24-hour monitoring window for a new surgical cohort of $n=157$ patients, the system flags $x=41$ cases that are later confirmed to be true infections by microbiological gold-standard tests. To update the infection-flagging model’s parameter $\\theta$ (the true probability of infection per monitored patient in this cohort), a Bayesian practitioner specifies a Beta prior reflecting credible historical data: $\\theta \\sim \\text{Beta}(\\alpha,\\beta)$ with $\\alpha=2.3$ and $\\beta=5.7$. The practitioner models the cohort data as $X \\mid \\theta \\sim \\text{Binomial}(n,\\theta)$.\n\nStarting from the axioms of probability and the definition of conditional probability, derive the posterior distribution $p(\\theta \\mid x)$ in closed form by applying Bayes’ theorem, using the standard probability mass function of the Binomial model and the standard probability density function of the Beta prior. Then, deduce the posterior mean $\\mathbb{E}[\\theta \\mid x]$ as a closed-form analytic expression and compute its numerical value for the given parameters.\n\nExpress the final numerical answer as a decimal and round your answer to four significant figures. No units are required.", "solution": "The problem asks for the derivation of the posterior distribution $p(\\theta \\mid x)$ and the posterior mean $\\mathbb{E}[\\theta \\mid x]$ for a Bayesian inference problem, and to compute the numerical value of the posterior mean.\n\nFirst, we validate the problem statement.\nThe givens are:\n-   The number of patients (trials) is $n=157$.\n-   The number of observed infections (successes) is $x=41$.\n-   The data $X$ is modeled by a Binomial distribution given the parameter $\\theta$, written as $X \\mid \\theta \\sim \\text{Binomial}(n,\\theta)$.\n-   The prior distribution for the true probability of infection, $\\theta$, is a Beta distribution, $\\theta \\sim \\text{Beta}(\\alpha,\\beta)$.\n-   The parameters of the prior distribution are $\\alpha=2.3$ and $\\beta=5.7$.\n\nThe problem is scientifically grounded, well-posed, and objective. It describes a standard application of Bayesian inference using conjugate priors, a fundamental technique in statistics and data science. All necessary information is provided, and there are no contradictions or ambiguities. The problem is valid.\n\nWe begin by stating Bayes' theorem for a continuous parameter $\\theta$ and discrete data $x$. The theorem is derived from the definition of conditional probability, $P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}$. For continuous and discrete random variables, this relationship is expressed in terms of probability density functions (PDFs) and probability mass functions (PMFs) as:\n$$p(\\theta \\mid x) = \\frac{p(x \\mid \\theta) p(\\theta)}{p(x)}$$\nHere, $p(\\theta \\mid x)$ is the posterior PDF of $\\theta$ given the data $x$, $p(x \\mid \\theta)$ is the likelihood of observing data $x$ given parameter $\\theta$, $p(\\theta)$ is the prior PDF of $\\theta$, and $p(x)$ is the marginal likelihood of the data (also called the evidence), which acts as a normalizing constant. The marginal likelihood is given by the integral $p(x) = \\int p(x \\mid \\theta) p(\\theta) \\, d\\theta$.\n\nWe can also express Bayes' theorem using proportionality, as $p(x)$ is constant with respect to $\\theta$:\n$$p(\\theta \\mid x) \\propto p(x \\mid \\theta) p(\\theta)$$\n\nThe problem specifies the likelihood and prior distributions.\nThe likelihood function $p(x \\mid \\theta)$ is given by the PMF of the Binomial distribution $\\text{Binomial}(n, \\theta)$:\n$$p(x \\mid \\theta) = \\binom{n}{x} \\theta^x (1-\\theta)^{n-x}$$\nfor $x \\in \\{0, 1, \\dots, n\\}$.\n\nThe prior distribution $p(\\theta)$ is given by the PDF of the Beta distribution $\\text{Beta}(\\alpha, \\beta)$:\n$$p(\\theta) = \\frac{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}$$\nfor $\\theta \\in [0, 1]$. Here, $B(\\alpha, \\beta)$ is the Beta function, which serves as the normalizing constant for the prior, defined as $B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$.\n\nNow we combine the likelihood and the prior to find the posterior distribution:\n$$p(\\theta \\mid x) \\propto p(x \\mid \\theta) p(\\theta)$$\n$$p(\\theta \\mid x) \\propto \\left[ \\binom{n}{x} \\theta^x (1-\\theta)^{n-x} \\right] \\left[ \\frac{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)} \\right]$$\n\nSince we are looking for the functional form of the posterior distribution in terms of $\\theta$, we can drop all terms that are constant with respect to $\\theta$. These include $\\binom{n}{x}$ and $B(\\alpha, \\beta)$.\n$$p(\\theta \\mid x) \\propto \\theta^x (1-\\theta)^{n-x} \\cdot \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}$$\nCombining the powers of $\\theta$ and $(1-\\theta)$:\n$$p(\\theta \\mid x) \\propto \\theta^{x+\\alpha-1} (1-\\theta)^{n-x+\\beta-1}$$\n\nThis functional form is the kernel of a Beta distribution. We can recognize this as a Beta PDF with updated parameters. Let the posterior parameters be $\\alpha' = \\alpha+x$ and $\\beta' = \\beta+n-x$. The posterior distribution is therefore:\n$$\\theta \\mid x \\sim \\text{Beta}(\\alpha+x, \\beta+n-x)$$\nThe closed-form expression for the posterior PDF is:\n$$p(\\theta \\mid x) = \\frac{\\theta^{(\\alpha+x)-1} (1-\\theta)^{(\\beta+n-x)-1}}{B(\\alpha+x, \\beta+n-x)}$$\nThis is a demonstration of the conjugacy between the Beta prior and the Binomial likelihood.\n\nNext, we must deduce the posterior mean, $\\mathbb{E}[\\theta \\mid x]$. The expected value of a random variable $Y$ following a Beta distribution $\\text{Beta}(a, b)$ is given by the formula $\\mathbb{E}[Y] = \\frac{a}{a+b}$.\nApplying this formula to our posterior distribution $\\theta \\mid x \\sim \\text{Beta}(\\alpha', \\beta')$, we get:\n$$\\mathbb{E}[\\theta \\mid x] = \\frac{\\alpha'}{\\alpha'+\\beta'}$$\nSubstituting the expressions for $\\alpha'$ and $\\beta'$:\n$$\\mathbb{E}[\\theta \\mid x] = \\frac{\\alpha+x}{(\\alpha+x) + (\\beta+n-x)}$$\nSimplifying the denominator, we arrive at the closed-form analytic expression for the posterior mean:\n$$\\mathbb{E}[\\theta \\mid x] = \\frac{\\alpha+x}{\\alpha+\\beta+n}$$\n\nFinally, we compute the numerical value for the given parameters: $n=157$, $x=41$, $\\alpha=2.3$, and $\\beta=5.7$.\nSubstituting these values into the expression for the posterior mean:\n$$\\mathbb{E}[\\theta \\mid x] = \\frac{2.3+41}{2.3+5.7+157}$$\n$$\\mathbb{E}[\\theta \\mid x] = \\frac{43.3}{8.0+157}$$\n$$\\mathbb{E}[\\theta \\mid x] = \\frac{43.3}{165.0}$$\n$$ \\mathbb{E}[\\theta \\mid x] \\approx 0.26242424... $$\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $2$, $6$, $2$, and $4$. The fifth digit is $2$, which is less than $5$, so we round down (i.e., we do not change the fourth digit).\nThe numerical value is $0.2624$.", "answer": "$$\\boxed{0.2624}$$", "id": "5220970"}, {"introduction": "Observational data in medicine are rife with hidden complexities, and a naive analysis can lead to dangerously incorrect conclusions. This practice confronts the issue of confounding by demonstrating Simpson's paradox, a phenomenon where an association observed in aggregated data is reversed within the subgroups that form it. By working through this hypothetical sepsis treatment scenario, you will develop the crucial skill of using stratification to control for confounding variables and uncover the true underlying effect [@problem_id:4956904].", "problem": "A hospital conducts an observational cohort study on patients with suspected sepsis, stratifying baseline severity using the Sequential Organ Failure Assessment (SOFA) score. Let $H$ denote the event \"high baseline severity\" and $L$ denote the event \"low baseline severity\" determined by a pre-specified SOFA threshold. Let $T$ denote the event \"patient received the new adjunctive therapy\" and $C$ denote the event \"patient did not receive the adjunctive therapy.\" Let $S$ denote the event \"patient survived to $30$ days.\" The cohort consists of the following counts, recorded prospectively and adjudicated using standard definitions:\n\n- In the $H$ stratum: $900$ treated patients ($T$), of whom $270$ survived ($S$) and $630$ did not survive ($\\neg S$); and $100$ untreated patients ($C$), of whom $20$ survived and $80$ did not survive.\n- In the $L$ stratum: $100$ treated patients ($T$), of whom $90$ survived and $10$ did not survive; and $900$ untreated patients ($C$), of whom $720$ survived and $180$ did not survive.\n\nFrom the foundational definitions of conditional probability and the law of total probability, rigorously articulate what Simpson’s paradox means in terms of conditioning on covariates in observational medical data, and why confounding by severity can cause directional reversal when aggregating across strata. Use the recorded counts to construct the $2 \\times 2$ tables for each stratum and for the aggregated cohort, and demonstrate that the therapy is beneficial within each stratum (higher survival under $T$ than under $C$) but appears harmful when the strata are aggregated.\n\nThen, derive the posterior probability $P(H \\mid S, T)$ using only the axioms of probability and core definitions, without invoking any shortcut formulas, and compute its numerical value based on the provided counts. Express all probabilities as decimals. Round your final numerical answer to four significant figures.", "solution": "The problem asks for an articulation and demonstration of Simpson's paradox using provided observational data, and for the derivation and calculation of a specific posterior probability. The analysis proceeds in two parts.\n\nFirst, we address the phenomenon of Simpson's paradox. Simpson's paradox occurs when an association or trend observed within individual subgroups of data reverses direction when the subgroups are combined. In medical statistics, this is often caused by a confounding variable that is correlated with both the exposure (e.g., treatment) and the outcome (e.g., survival). When not accounted for, the confounder can create a spurious association in the aggregated (crude) data.\n\nIn this problem, the exposure is the adjunctive therapy (events $T$ for treated, $C$ for control), the outcome is survival (event $S$), and the potential confounder is the baseline severity of illness, stratified into high severity ($H$) and low severity ($L$). A variable is a confounder if it is a common cause of both the exposure and the outcome, or is associated with both for other reasons, and is not on the causal pathway between them. We must verify if severity acts as a confounder.\n\n1.  **Association between Severity and Treatment (Exposure)**: We examine if sicker patients were more or less likely to receive the therapy. The probability of receiving treatment given high severity is $P(T \\mid H)$, and given low severity is $P(T \\mid L)$.\n    From the data, the total number of high-severity patients is $N(H) = N(H, T) + N(H, C) = 900 + 100 = 1000$. The number of treated high-severity patients is $N(H, T) = 900$.\n    Thus, $P(T \\mid H) = \\frac{N(H, T)}{N(H)} = \\frac{900}{1000} = 0.9$.\n    The total number of low-severity patients is $N(L) = N(L, T) + N(L, C) = 100 + 900 = 1000$. The number of treated low-severity patients is $N(L, T) = 100$.\n    Thus, $P(T \\mid L) = \\frac{N(L, T)}{N(L)} = \\frac{100}{1000} = 0.1$.\n    Since $P(T \\mid H) = 0.9$ is substantially different from $P(T \\mid L) = 0.1$, there is a strong association between severity and treatment assignment. Patients with high severity were much more likely to receive the new therapy. This is a classic example of \"confounding by indication\".\n\n2.  **Association between Severity and Survival (Outcome)**: We examine if severity is independently associated with the survival outcome. We can assess this by comparing the overall survival rates in the two strata, $P(S \\mid H)$ and $P(S \\mid L)$.\n    The number of survivors in the high-severity stratum is $N(S, H) = N(S, H, T) + N(S, H, C) = 270 + 20 = 290$.\n    Thus, $P(S \\mid H) = \\frac{N(S, H)}{N(H)} = \\frac{290}{1000} = 0.29$.\n    The number of survivors in the low-severity stratum is $N(S, L) = N(S, L, T) + N(S, L, C) = 90 + 720 = 810$.\n    Thus, $P(S \\mid L) = \\frac{N(S, L)}{N(L)} = \\frac{810}{1000} = 0.81$.\n    Since $P(S \\mid H) = 0.29$ is much lower than $P(S \\mid L) = 0.81$, baseline severity is a strong predictor of survival.\n\nBecause severity is associated with both treatment choice and survival, it is a confounder. Confounding by severity can cause a directional reversal because the aggregated comparison of treated versus untreated groups is not a fair comparison. The treated group is disproportionately composed of high-severity patients ($900$ of $1000$ treated patients were high-severity) who have a poor prognosis, while the untreated group is disproportionately composed of low-severity patients ($900$ of $1000$ untreated patients were low-severity) who have a good prognosis. This compositional imbalance biases the crude analysis, potentially masking a true treatment benefit and even reversing its apparent direction.\n\nTo demonstrate this, we compute the stratum-specific and aggregated effects.\n\n**Stratum-Specific Analysis:**\n\nFor the high-severity ($H$) stratum:\n| **High Severity** | Survived ($S$) | Did not survive ($\\neg S$) | Total |\n|:---|---:|---:|---:|\n| Treated ($T$) | 270 | 630 | 900 |\n| Control ($C$) | 20 | 80 | 100 |\n| **Total** | 290 | 710 | 1000 |\n\nThe conditional probability of survival given treatment in this stratum is $P(S \\mid H, T) = \\frac{N(S, H, T)}{N(H, T)} = \\frac{270}{900} = 0.3$.\nThe conditional probability of survival given no treatment (control) is $P(S \\mid H, C) = \\frac{N(S, H, C)}{N(H, C)} = \\frac{20}{100} = 0.2$.\nSince $P(S \\mid H, T) > P(S \\mid H, C)$ ($0.3 > 0.2$), the therapy appears beneficial for high-severity patients.\n\nFor the low-severity ($L$) stratum:\n| **Low Severity** | Survived ($S$) | Did not survive ($\\neg S$) | Total |\n|:---|---:|---:|---:|\n| Treated ($T$) | 90 | 10 | 100 |\n| Control ($C$) | 720 | 180 | 900 |\n| **Total** | 810 | 190 | 1000 |\n\nThe conditional probability of survival given treatment in this stratum is $P(S \\mid L, T) = \\frac{N(S, L, T)}{N(L, T)} = \\frac{90}{100} = 0.9$.\nThe conditional probability of survival given no treatment (control) is $P(S \\mid L, C) = \\frac{N(S, L, C)}{N(L, C)} = \\frac{720}{900} = 0.8$.\nSince $P(S \\mid L, T) > P(S \\mid L, C)$ ($0.9 > 0.8$), the therapy also appears beneficial for low-severity patients.\n\n**Aggregated (Crude) Analysis:**\n\nWe combine the counts from both strata to get the aggregated table:\nTotal treated patients: $N(T) = 900+100=1000$. Total treated survivors: $N(S, T) = 270+90=360$.\nTotal control patients: $N(C) = 100+900=1000$. Total control survivors: $N(S, C) = 20+720=740$.\n\n| **Aggregated Data** | Survived ($S$) | Did not survive ($\\neg S$) | Total |\n|:---|---:|---:|---:|\n| Treated ($T$) | 360 | 640 | 1000 |\n| Control ($C$) | 740 | 260 | 1000 |\n| **Total** | 1100 | 900 | 2000 |\n\nThe overall probability of survival given treatment is $P(S \\mid T) = \\frac{N(S, T)}{N(T)} = \\frac{360}{1000} = 0.36$.\nThe overall probability of survival given no treatment is $P(S \\mid C) = \\frac{N(S, C)}{N(C)} = \\frac{740}{1000} = 0.74$.\nIn the aggregated data, $P(S \\mid T)  P(S \\mid C)$ ($0.36  0.74$), which suggests the therapy is harmful. This reversal of the conclusion from the stratified analysis ($0.3 > 0.2$ and $0.9 > 0.8$) is precisely Simpson's paradox. The stratified analysis, which controls for the confounder, provides the correct assessment of the therapy's effect.\n\nNow, we proceed to the second part of the problem: deriving and computing the posterior probability $P(H \\mid S, T)$. This is the probability that a patient had high baseline severity, given that they survived and received the therapy.\n\nWe start from the core definition of conditional probability, which states that for any two events $A$ and $B$ with $P(B)0$, $P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}$.\nLet our event of interest be $A=H$ and our conditioning event be $B=(S \\cap T)$. We seek $P(H \\mid S \\cap T)$.\nApplying the definition:\n$$ P(H \\mid S, T) = \\frac{P(H \\cap S \\cap T)}{P(S \\cap T)} $$\nThe probabilities can be estimated from the provided counts, where $P(\\text{event}) = \\frac{N(\\text{event})}{N(\\text{total})}$. Let $N_{total}$ be the total number of patients in the cohort, $N_{total}=2000$.\nThe numerator is $P(H \\cap S \\cap T) = \\frac{N(H, S, T)}{N_{total}}$.\nThe denominator, $P(S \\cap T)$, is the probability of the joint event that a patient survived and was treated. This event can be partitioned by the mutually exclusive and exhaustive severity strata, $\\{H, L\\}$. Using the law of total probability:\n$$ P(S \\cap T) = P((S \\cap T) \\cap H) + P((S \\cap T) \\cap L) = P(H \\cap S \\cap T) + P(L \\cap S \\cap T) $$\nThis can be expressed in terms of counts:\n$$ P(S \\cap T) = \\frac{N(H, S, T)}{N_{total}} + \\frac{N(L, S, T)}{N_{total}} = \\frac{N(H, S, T) + N(L, S, T)}{N_{total}} $$\nSubstituting these expressions back into the formula for $P(H \\mid S, T)$:\n$$ P(H \\mid S, T) = \\frac{\\frac{N(H, S, T)}{N_{total}}}{\\frac{N(H, S, T) + N(L, S, T)}{N_{total}}} $$\nThe $N_{total}$ terms cancel out, yielding a formula directly in terms of counts:\n$$ P(H \\mid S, T) = \\frac{N(H, S, T)}{N(H, S, T) + N(L, S, T)} $$\nThis derivation uses only the definition of conditional probability and the law of total probability, as requested.\n\nNow, we compute the numerical value using the provided counts:\nFrom the problem statement for the $H$ stratum: $N(H, S, T) = 270$.\nFrom the problem statement for the $L$ stratum: $N(L, S, T) = 90$.\nSubstituting these values:\n$$ P(H \\mid S, T) = \\frac{270}{270 + 90} = \\frac{270}{360} $$\nSimplifying the fraction:\n$$ P(H \\mid S, T) = \\frac{27}{36} = \\frac{3 \\times 9}{4 \\times 9} = \\frac{3}{4} $$\nAs a decimal, this is $0.75$. The problem requires the answer to be expressed to four significant figures.", "answer": "$$\\boxed{0.7500}$$", "id": "4956904"}, {"introduction": "Beyond confounding, another subtle trap in analyzing medical data is selection bias, which can arise when the study population is not representative of the target population. This exercise reveals this issue through the lens of Berkson's paradox, where conditioning on a common effect (like hospital admission) artificially creates an association between two otherwise independent variables. This practice will sharpen your critical eye for study design and the potential biases introduced when analyzing restricted datasets, such as those from hospital records [@problem_id:4956993].", "problem": "A hospital-based study is investigating the association between a binary risk factor $R \\in \\{0,1\\}$ and a binary disease $D \\in \\{0,1\\}$ in an urban population, while recognizing that the available dataset contains only admitted patients. Let $A \\in \\{0,1\\}$ indicate hospital admission. Suppose the following are true in the source population:\n- The disease prevalence is $P(D=1)=0.10$ and the risk factor prevalence is $P(R=1)=0.30$.\n- The risk factor and the disease are independent in the population, that is, $P(R=1,D=1)=P(R=1)P(D=1)$.\n- Admission is influenced by both $R$ and $D$ through the following mechanism:\n  - $P(A=1 \\mid R=1,D=1)=0.50$,\n  - $P(A=1 \\mid R=1,D=0)=0.10$,\n  - $P(A=1 \\mid R=0,D=1)=0.20$,\n  - $P(A=1 \\mid R=0,D=0)=0.01$.\n\nUsing only the definitions of conditional probability, Bayes’ theorem, and the definition of odds and odds ratio, and without invoking any pre-packaged formulas not derived from these definitions, do the following:\n1. Compute the population odds ratio comparing the odds of disease for $R=1$ versus $R=0$ when admission is ignored.\n2. Compute the odds ratio comparing the odds of disease for $R=1$ versus $R=0$ conditional on being admitted ($A=1$).\n\nReport your two numerical answers rounded to four significant figures, in the order (population odds ratio, admitted-patients odds ratio).", "solution": "The solution is presented in two parts as requested. First, we compute the population odds ratio, and second, we compute the odds ratio conditional on hospital admission.\n\nThe odds of an event $E$ is defined as $\\text{Odds}(E) = \\frac{P(E)}{1-P(E)} = \\frac{P(E)}{P(E^c)}$.\nThe odds ratio ($OR$) for the disease $D$ comparing the exposed group ($R=1$) to the unexposed group ($R=0$) is defined as:\n$$OR = \\frac{\\text{Odds}(D=1 \\mid R=1)}{\\text{Odds}(D=1 \\mid R=0)} = \\frac{P(D=1 \\mid R=1) / P(D=0 \\mid R=1)}{P(D=1 \\mid R=0) / P(D=0 \\mid R=0)}$$\n\n**Part 1: Population Odds Ratio ($OR_{\\text{pop}}$)**\n\nIn the general population, the risk factor $R$ and the disease $D$ are stated to be independent. A direct consequence of independence is that the conditional probability of $D$ given $R$ is equal to the marginal probability of $D$.\n$$P(D=1 \\mid R=1) = P(D=1) = 0.10$$\n$$P(D=1 \\mid R=0) = P(D=1) = 0.10$$\nFrom this, we can find the probabilities of not having the disease for each group:\n$$P(D=0 \\mid R=1) = 1 - P(D=1 \\mid R=1) = 1 - 0.10 = 0.90$$\n$$P(D=0 \\mid R=0) = 1 - P(D=1 \\mid R=0) = 1 - 0.10 = 0.90$$\nNow we compute the odds for each group:\n$$\\text{Odds}(D=1 \\mid R=1) = \\frac{P(D=1 \\mid R=1)}{P(D=0 \\mid R=1)} = \\frac{0.10}{0.90} = \\frac{1}{9}$$\n$$\\text{Odds}(D=1 \\mid R=0) = \\frac{P(D=1 \\mid R=0)}{P(D=0 \\mid R=0)} = \\frac{0.10}{0.90} = \\frac{1}{9}$$\nThe population odds ratio is the ratio of these two odds:\n$$OR_{\\text{pop}} = \\frac{1/9}{1/9} = 1$$\nAn odds ratio of $1$ confirms that there is no association between the risk factor and the disease in the general population, which is the expected result given the independence assumption.\n\n**Part 2: Admitted-Patients Odds Ratio ($OR_{A=1}$)**\n\nWe now compute the odds ratio conditional on admission to the hospital ($A=1$). The formula for the odds ratio is now conditional on $A=1$:\n$$OR_{A=1} = \\frac{\\text{Odds}(D=1 \\mid R=1, A=1)}{\\text{Odds}(D=1 \\mid R=0, A=1)} = \\frac{P(D=1 \\mid R=1, A=1) / P(D=0 \\mid R=1, A=1)}{P(D=1 \\mid R=0, A=1) / P(D=0 \\mid R=0, A=1)}$$\nTo calculate the required conditional probabilities, we first need to determine the joint probabilities of $R$, $D$, and $A$ in the population.\n\nFirst, we calculate the joint probabilities $P(R=r, D=d)$ for all combinations of $r$ and $d$ in the population, using the independence of $R$ and $D$.\n-   $P(R=1, D=1) = P(R=1)P(D=1) = 0.30 \\times 0.10 = 0.03$\n-   $P(R=1, D=0) = P(R=1)P(D=0) = 0.30 \\times (1-0.10) = 0.30 \\times 0.90 = 0.27$\n-   $P(R=0, D=1) = P(R=0)P(D=1) = (1-0.30) \\times 0.10 = 0.70 \\times 0.10 = 0.07$\n-   $P(R=0, D=0) = P(R=0)P(D=0) = (1-0.30) \\times (1-0.10) = 0.70 \\times 0.90 = 0.63$\n\nNext, we calculate the joint probabilities $P(A=1, R=r, D=d)$ using the formula $P(A=1, R=r, D=d) = P(A=1 \\mid R=r, D=d) P(R=r, D=d)$.\n-   $P(A=1, R=1, D=1) = P(A=1 \\mid R=1, D=1) P(R=1, D=1) = 0.50 \\times 0.03 = 0.0150$\n-   $P(A=1, R=1, D=0) = P(A=1 \\mid R=1, D=0) P(R=1, D=0) = 0.10 \\times 0.27 = 0.0270$\n-   $P(A=1, R=0, D=1) = P(A=1 \\mid R=0, D=1) P(R=0, D=1) = 0.20 \\times 0.07 = 0.0140$\n-   $P(A=1, R=0, D=0) = P(A=1 \\mid R=0, D=0) P(R=0, D=0) = 0.01 \\times 0.63 = 0.0063$\n\nNow we are equipped to calculate the terms for the odds ratio. The odds can be calculated directly from these joint probabilities. Notice that for the first set of odds:\n$$\\text{Odds}(D=1 \\mid R=1, A=1) = \\frac{P(D=1 \\mid R=1, A=1)}{P(D=0 \\mid R=1, A=1)} = \\frac{P(D=1, R=1, A=1) / P(R=1, A=1)}{P(D=0, R=1, A=1) / P(R=1, A=1)} = \\frac{P(A=1, R=1, D=1)}{P(A=1, R=1, D=0)}$$\nSimilarly for the second set of odds:\n$$\\text{Odds}(D=1 \\mid R=0, A=1) = \\frac{P(A=1, R=0, D=1)}{P(A=1, R=0, D=0)}$$\nPlugging in the numbers we calculated:\n$$\\text{Odds}(D=1 \\mid R=1, A=1) = \\frac{0.0150}{0.0270} = \\frac{15}{27} = \\frac{5}{9}$$\n$$\\text{Odds}(D=1 \\mid R=0, A=1) = \\frac{0.0140}{0.0063} = \\frac{140}{63} = \\frac{20 \\times 7}{9 \\times 7} = \\frac{20}{9}$$\nFinally, we compute the odds ratio for the admitted patients by taking the ratio of these two odds:\n$$OR_{A=1} = \\frac{\\text{Odds}(D=1 \\mid R=1, A=1)}{\\text{Odds}(D=1 \\mid R=0, A=1)} = \\frac{5/9}{20/9} = \\frac{5}{20} = \\frac{1}{4} = 0.25$$\nThis result shows a strong negative association between the risk factor and the disease among the hospital-admitted population, even though they are independent in the general population. This inversion of association is a classic example of selection bias.\n\nThe two numerical answers, the population odds ratio and the admitted-patients odds ratio, rounded to four significant figures are $1.000$ and $0.2500$ respectively.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1.000  0.2500 \\end{pmatrix}}\n$$", "id": "4956993"}]}