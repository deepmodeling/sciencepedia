{"hands_on_practices": [{"introduction": "The performance of a diagnostic test in a real-world clinical setting depends not only on its intrinsic characteristics, like sensitivity ($Se$) and specificity ($Sp$), but also critically on the prevalence of the disease in the population being tested. This exercise provides a hands-on derivation of the Positive Predictive Value ($PPV$) and uses it to quantitatively demonstrate how a test with excellent accuracy can have dramatically different clinical utility when applied to a low-prevalence screening population versus a high-prevalence specialty clinic population. Understanding this relationship is fundamental to the appropriate application and interpretation of diagnostic tests. [@problem_id:4959520]", "problem": "A hospital considers deploying a new screening assay for a rare disease. Let the disease status be a binary variable, with event $D$ denoting that a patient truly has the disease, and $+$ denoting a positive test result. The pretest probability equals the population prevalence, so $P(D)=\\pi$. The test has sensitivity (true positive rate) defined as $Se = P(+ \\mid D)$ and specificity (true negative rate) defined as $Sp = P(- \\mid \\neg D)$. The positive predictive value (PPV) is defined as $PPV = P(D \\mid +)$.\n\nStarting from the basic definitions of conditional probability, the Law of Total Probability, and Bayes’ theorem, derive an expression for $PPV$ in terms of $Se$, $Sp$, and $\\pi$. Then, using $Se = 0.97$, $Sp = 0.995$, compute $PPV$ in two populations:\n- a primary care population with prevalence $\\pi = 0.002$,\n- a specialty clinic population with prevalence $\\pi = 0.20$.\n\nFinally, report the exact simplified value of the ratio\n$$\\frac{PPV(\\pi = 0.002)}{PPV(\\pi = 0.20)}.$$\nProvide your final answer as a single fraction or a single decimal number without a percentage sign. No rounding is required.", "solution": "The first task is to derive an expression for the Positive Predictive Value, $PPV$, defined as $PPV = P(D \\mid +)$. We begin with Bayes' theorem, which states that for any two events $A$ and $B$, $P(A \\mid B) = \\frac{P(B \\mid A)P(A)}{P(B)}$. Applying this to our context, we have:\n$$PPV = P(D \\mid +) = \\frac{P(+ \\mid D) P(D)}{P(+)}$$\nThe terms in the numerator are given by the problem's definitions: $P(+ \\mid D) = Se$ and $P(D) = \\pi$.\n\nThe denominator, $P(+)$, is the overall probability of a positive test result. This is the marginal probability, which can be found using the Law of Total Probability by conditioning on the disease status $D$:\n$$P(+) = P(+ \\mid D) P(D) + P(+ \\mid \\neg D) P(\\neg D)$$\nWe must express the terms on the right-hand side using the given quantities $Se$, $Sp$, and $\\pi$.\n- $P(+ \\mid D) = Se$\n- $P(D) = \\pi$\n- The probability of not having the disease is $P(\\neg D) = 1 - P(D) = 1 - \\pi$.\n- The term $P(+ \\mid \\neg D)$ is the false positive rate. It is the complement of the true negative rate, which is the specificity $Sp = P(- \\mid \\neg D)$. Therefore, $P(+ \\mid \\neg D) = 1 - P(- \\mid \\neg D) = 1 - Sp$.\n\nSubstituting these into the expression for $P(+)$:\n$$P(+) = (Se)(\\pi) + (1 - Sp)(1 - \\pi)$$\nNow, substituting this denominator back into the Bayes' theorem expression for $PPV$:\n$$PPV = \\frac{Se \\cdot \\pi}{Se \\cdot \\pi + (1 - Sp)(1 - \\pi)}$$\nThis is the desired general expression for $PPV$.\n\nNext, we compute the $PPV$ for the two specified populations using the given values $Se = 0.97$ and $Sp = 0.995$. From these, we calculate the false positive rate: $1 - Sp = 1 - 0.995 = 0.005$.\n\nFor the primary care population, the prevalence is $\\pi_1 = 0.002$. The $PPV$ is:\n$$PPV_1 = PPV(\\pi = 0.002) = \\frac{(0.97)(0.002)}{(0.97)(0.002) + (0.005)(1 - 0.002)}$$\n$$PPV_1 = \\frac{0.00194}{0.00194 + (0.005)(0.998)}$$\n$$PPV_1 = \\frac{0.00194}{0.00194 + 0.00499} = \\frac{0.00194}{0.00693} = \\frac{194}{693}$$\n\nFor the specialty clinic population, the prevalence is $\\pi_2 = 0.20$. The $PPV$ is:\n$$PPV_2 = PPV(\\pi = 0.20) = \\frac{(0.97)(0.20)}{(0.97)(0.20) + (0.005)(1 - 0.20)}$$\n$$PPV_2 = \\frac{0.194}{0.194 + (0.005)(0.80)}$$\n$$PPV_2 = \\frac{0.194}{0.194 + 0.004} = \\frac{0.194}{0.198} = \\frac{194}{198}$$\nThis fraction can be simplified by dividing the numerator and denominator by their greatest common divisor, which is $2$:\n$$PPV_2 = \\frac{97}{99}$$\n\nFinally, we compute the ratio $\\frac{PPV_1}{PPV_2}$:\n$$\\frac{PPV_1}{PPV_2} = \\frac{\\frac{194}{693}}{\\frac{97}{99}} = \\frac{194}{693} \\times \\frac{99}{97}$$\nWe can simplify this expression. Note that $194 = 2 \\times 97$ and $693 = 7 \\times 99$.\n$$\\frac{PPV_1}{PPV_2} = \\frac{2 \\times 97}{7 \\times 99} \\times \\frac{99}{97}$$\nCanceling the common terms $97$ and $99$ from the numerator and denominator, we are left with:\n$$\\frac{PPV_1}{PPV_2} = \\frac{2}{7}$$\nThis is the final exact simplified value of the ratio.", "answer": "$$\n\\boxed{\\frac{2}{7}}\n$$", "id": "4959520"}, {"introduction": "When we report a diagnostic metric like sensitivity from a study, we are providing a point estimate that is subject to sampling error. To convey the precision of this estimate, it is essential to also report a confidence interval. This practice delves into the statistical underpinnings of this process, guiding you to derive the variance of the sample sensitivity ($\\hat{Se}$) from a binomial model and construct a robust confidence interval using a normal approximation with continuity correction. [@problem_id:4959510]", "problem": "A prospective diagnostic accuracy study enrolls a cohort of patients and verifies disease status with a gold standard. Among those with confirmed disease, each patient independently yields a positive test result with probability equal to the true sensitivity, denoted by $Se$. Let the number of true positives (TP) among diseased patients be $TP$, the number of false negatives (FN) be $FN$, and the total number of diseased patients be $n_{D} = TP + FN$. The sample estimate of sensitivity is $\\hat{Se} = \\frac{TP}{n_{D}}$.\n\nStarting only from the binomial model for $TP$ under independent trials, derive the sampling variance of $\\hat{Se}$ and the associated standard error. Then construct a large-sample two-sided confidence interval (CI) for $Se$ based on normal theory that incorporates continuity correction by adjusting the binomial count by $\\pm 0.5$ before invoking the normal approximation, and then translating the correction to the proportion scale. Explicitly state any approximations you make in moving from the exact binomial to the approximate normal-based CI.\n\nApply your result to the following data: $TP = 198$, $FN = 49$. Use a two-sided $0.95$ confidence level and the corresponding standard normal quantile $z_{1-\\alpha/2}$. Express the final CI bounds as decimals, and round both bounds to four significant figures. Report the lower and upper bounds as a single row matrix $\\begin{pmatrix}\\text{lower}  \\text{upper}\\end{pmatrix}$ with no units and no percent signs.", "solution": "**Derivation of Sampling Variance and Standard Error**\n\nThe problem states that the number of true positives, $TP$, is the result of $n_D$ independent Bernoulli trials, where the probability of success (a positive test) in each trial is the true sensitivity, $Se$. Therefore, $TP$ follows a binomial distribution:\n$$ TP \\sim \\text{Binomial}(n_D, Se) $$\nThe variance of a binomial random variable $X \\sim \\text{Binomial}(n, p)$ is given by $\\text{Var}(X) = np(1-p)$. Applying this to $TP$, we get:\n$$ \\text{Var}(TP) = n_D Se (1 - Se) $$\nThe sample estimate of sensitivity, $\\hat{Se}$, is defined as $\\hat{Se} = \\frac{TP}{n_D}$. To find its sampling variance, we use the property of variance that for a constant $c$, $\\text{Var}(cX) = c^2 \\text{Var}(X)$. Here, $c = \\frac{1}{n_D}$.\n$$ \\text{Var}(\\hat{Se}) = \\text{Var}\\left(\\frac{TP}{n_D}\\right) = \\left(\\frac{1}{n_D}\\right)^2 \\text{Var}(TP) = \\frac{1}{n_D^2} [n_D Se(1-Se)] $$\nSimplifying this expression gives the sampling variance of $\\hat{Se}$:\n$$ \\text{Var}(\\hat{Se}) = \\frac{Se(1-Se)}{n_D} $$\nThe standard error ($SE$) is the square root of the sampling variance:\n$$ SE(\\hat{Se}) = \\sqrt{\\text{Var}(\\hat{Se})} = \\sqrt{\\frac{Se(1-Se)}{n_D}} $$\n\n**Construction of a Large-Sample Confidence Interval with Continuity Correction**\n\nFor a large sample size $n_D$, the Central Limit Theorem (specifically, the De Moivre-Laplace theorem) states that the sampling distribution of $\\hat{Se}$ can be approximated by a normal distribution:\n$$ \\hat{Se} \\approx N\\left(Se, \\frac{Se(1-Se)}{n_D}\\right) $$\nA standard $(1-\\alpha)$ confidence interval (the Wald interval) is based on this approximation and is given by $\\hat{Se} \\pm z_{1-\\alpha/2} \\times \\widehat{SE}(\\hat{Se})$, where the unknown $Se$ in the standard error term is replaced by its estimate $\\hat{Se}$.\n\nThe problem requires incorporating a continuity correction. The normal distribution is continuous, while the binomial distribution is discrete. The continuity correction adjusts for this by considering the discrete count $TP$ to represent the continuous interval $[TP-0.5, TP+0.5]$. On the proportion scale, this adjustment is $\\pm \\frac{0.5}{n_D} = \\pm \\frac{1}{2n_D}$.\n\nA common method for constructing a continuity-corrected large-sample interval is to add this correction term to the margin of error of the Wald interval. This widens the confidence interval, making it more conservative and improving the approximation. The formula for the two-sided $(1-\\alpha)$ confidence interval with continuity correction is:\n$$ CI = \\hat{Se} \\pm \\left( z_{1-\\alpha/2} \\sqrt{\\frac{\\hat{Se}(1-\\hat{Se})}{n_D}} + \\frac{1}{2n_D} \\right) $$\nThe approximations made in this construction are:\n$1$. The binomial distribution of counts is approximated by a normal distribution. This is justified for large $n_D$ (typically when $n_D \\hat{Se} > 5$ and $n_D (1-\\hat{Se}) > 5$).\n$2$. The true parameter $Se$ in the standard error term is replaced by its sample estimate $\\hat{Se}$. This is a standard approximation for large-sample (Wald-type) confidence intervals.\n\n**Application to Provided Data**\n\nWe are given:\n-   $TP = 198$\n-   $FN = 49$\n-   Confidence level = $0.95$\n\nFirst, we calculate the necessary sample statistics:\n$$ n_D = TP + FN = 198 + 49 = 247 $$\n$$ \\hat{Se} = \\frac{TP}{n_D} = \\frac{198}{247} $$\nNumerically, $\\hat{Se} \\approx 0.80161943...$\n\nFor a $0.95$ confidence level, $\\alpha = 1 - 0.95 = 0.05$. The required normal quantile is:\n$$ z_{1-\\alpha/2} = z_{1-0.025} = z_{0.975} $$\nThe standard value for $z_{0.975}$ is approximately $1.96$.\n\nNow, we compute the two components of the margin of error:\n$1$. The standard error component of the margin of error:\n$$ M_{SE} = z_{1-\\alpha/2} \\sqrt{\\frac{\\hat{Se}(1-\\hat{Se})}{n_D}} = 1.96 \\sqrt{\\frac{(\\frac{198}{247})(1-\\frac{198}{247})}{247}} = 1.96 \\sqrt{\\frac{(\\frac{198}{247})(\\frac{49}{247})}{247}} $$\n$$ M_{SE} = 1.96 \\sqrt{\\frac{198 \\times 49}{247^3}} = 1.96 \\sqrt{\\frac{9702}{15069223}} \\approx 1.96 \\times 0.0253733 \\approx 0.0497317 $$\n$2$. The continuity correction term:\n$$ C = \\frac{1}{2n_D} = \\frac{1}{2 \\times 247} = \\frac{1}{494} \\approx 0.0020243 $$\nThe total margin of error, $M$, is the sum of these two components:\n$$ M = M_{SE} + C \\approx 0.0497317 + 0.0020243 = 0.0517560 $$\nThe confidence interval bounds are $\\hat{Se} \\pm M$:\nLower bound:\n$$ L = \\hat{Se} - M \\approx 0.8016194 - 0.0517560 = 0.7498634 $$\nUpper bound:\n$$ U = \\hat{Se} + M \\approx 0.8016194 + 0.0517560 = 0.8533754 $$\nFinally, we round both bounds to four significant figures:\n-   Lower bound: $0.7498634 \\to 0.7499$\n-   Upper bound: $0.8533754 \\to 0.8534$\n\nThe resulting $95\\%$ confidence interval for the true sensitivity $Se$ is $(0.7499, 0.8534)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.7499  0.8534 \\end{pmatrix}}\n$$", "id": "4959510"}, {"introduction": "A frequent and important task in medical research is to determine if a new diagnostic test offers a significant improvement over an existing one. When both tests are evaluated on the same cohort of patients—a powerful paired-study design—their results are correlated, and this correlation must be accounted for in the statistical comparison. This advanced practice introduces DeLong's nonparametric method for comparing the Areas Under the ROC Curve ($AUC$s) of two correlated tests, a widely used technique for robustly assessing relative diagnostic performance. [@problem_id:4959538]", "problem": "A clinical study evaluates two diagnostic scoring rules, Test A and Test B, measured on the same cohort of subjects to discriminate diseased from non-diseased individuals. There are $m=5$ diseased and $n=6$ non-diseased subjects. For each test, the area under the Receiver Operating Characteristic (ROC) curve (Area Under the Curve (AUC)) is estimated from the empirical case-control comparisons. Define, for each diseased subject $i$, the case-wise placement value for a given test as the average over the $n$ non-diseased subjects of the indicator that the diseased subject’s score exceeds the non-diseased subject’s score (with standard $0.5$ handling for ties). Similarly, define, for each non-diseased subject $j$, the control-wise placement value as the average over the $m$ diseased subjects of the same indicator (with the same tie handling). These summaries are provided below and are to be used as the inputs for DeLong’s nonparametric method to account for the correlation between the two tests.\n\nCase-wise placement values (length $m=5$):\n- Test A: $[\\,0.83,\\;0.75,\\;0.92,\\;0.68,\\;0.72\\,]$\n- Test B: $[\\,0.90,\\;0.82,\\;0.96,\\;0.78,\\;0.79\\,]$\n\nControl-wise placement values (length $n=6$):\n- Test A: $[\\,0.80,\\;0.72,\\;0.85,\\;0.76,\\;0.79,\\;0.76\\,]$\n- Test B: $[\\,0.90,\\;0.80,\\;0.92,\\;0.84,\\;0.85,\\;0.79\\,]$\n\nUsing DeLong’s method for two correlated ROC curves from paired data, construct the two-sided $95\\%$ confidence interval (CI) for the difference in AUCs, defined as $\\Delta=\\text{AUC}_{B}-\\text{AUC}_{A}$, under the large-sample normal approximation. What is the lower bound of this CI? Round your answer to four significant figures and express it as a decimal fraction (do not use a percentage sign).", "solution": "The objective is to compute the lower bound of the $95\\%$ confidence interval for the difference in AUCs, $\\Delta = \\text{AUC}_{B} - \\text{AUC}_{A}$, using DeLong's method. The number of diseased subjects is $m=5$ and the number of non-diseased subjects is $n=6$.\n\nFirst, we calculate the point estimate of the difference, $\\hat{\\Delta}$. The empirical AUC for each test is the average of its case-wise placement values.\nFor Test A, the case-wise values are $V_A^{\\text{case}} = [\\,0.83,\\;0.75,\\;0.92,\\;0.68,\\;0.72\\,]$. The estimated AUC is:\n$$ \\widehat{\\text{AUC}}_{A} = \\frac{1}{m} \\sum_{i=1}^{m} V_{1,i}^{(A)} = \\frac{1}{5} (0.83 + 0.75 + 0.92 + 0.68 + 0.72) = \\frac{3.9}{5} = 0.78 $$\nFor Test B, the case-wise values are $V_B^{\\text{case}} = [\\,0.90,\\;0.82,\\;0.96,\\;0.78,\\;0.79\\,]$. The estimated AUC is:\n$$ \\widehat{\\text{AUC}}_{B} = \\frac{1}{m} \\sum_{i=1}^{m} V_{1,i}^{(B)} = \\frac{1}{5} (0.90 + 0.82 + 0.96 + 0.78 + 0.79) = \\frac{4.25}{5} = 0.85 $$\nThe point estimate for the difference is:\n$$ \\hat{\\Delta} = \\widehat{\\text{AUC}}_{B} - \\widehat{\\text{AUC}}_{A} = 0.85 - 0.78 = 0.07 $$\nA $95\\%$ confidence interval based on the normal approximation is given by $\\hat{\\Delta} \\pm z_{1-\\alpha/2} \\sqrt{\\widehat{\\text{Var}}(\\hat{\\Delta})}$. For a $95\\%$ CI, $\\alpha=0.05$ and the critical value is $z_{0.975} \\approx 1.96$.\n\nTo estimate the variance of the difference, $\\widehat{\\text{Var}}(\\hat{\\Delta})$, we first compute the difference vectors for the placement values.\nThe case-wise difference vector, $L_D$, is the element-wise difference $V_B^{\\text{case}} - V_A^{\\text{case}}$:\n$$ L_{D} = [0.90-0.83, \\; 0.82-0.75, \\; 0.96-0.92, \\; 0.78-0.68, \\; 0.79-0.72] $$\n$$ L_{D} = [0.07, \\; 0.07, \\; 0.04, \\; 0.10, \\; 0.07] $$\nThe control-wise difference vector, $L_C$, is the element-wise difference $V_B^{\\text{control}} - V_A^{\\text{control}}$:\n$$ L_{C} = [0.90-0.80, \\; 0.80-0.72, \\; 0.92-0.85, \\; 0.84-0.76, \\; 0.85-0.79, \\; 0.79-0.76] $$\n$$ L_{C} = [0.10, \\; 0.08, \\; 0.07, \\; 0.08, \\; 0.06, \\; 0.03] $$\nThe mean of both difference vectors is equal to $\\hat{\\Delta} = 0.07$.\n\nNext, we calculate the sample variance of each difference vector.\nFor the case-wise differences $L_D$, the sample variance $S_D^2$ is:\n$$ S_D^2 = \\frac{1}{m-1} \\sum_{i=1}^{m} (L_{D,i} - \\hat{\\Delta})^2 $$\n$$ S_D^2 = \\frac{1}{5-1} [ (0.07-0.07)^2 + (0.07-0.07)^2 + (0.04-0.07)^2 + (0.10-0.07)^2 + (0.07-0.07)^2 ] $$\n$$ S_D^2 = \\frac{1}{4} [ 0^2 + 0^2 + (-0.03)^2 + (0.03)^2 + 0^2 ] = \\frac{1}{4} [ 0.0009 + 0.0009 ] = \\frac{0.0018}{4} = 0.00045 $$\nFor the control-wise differences $L_C$, the sample variance $S_C^2$ is:\n$$ S_C^2 = \\frac{1}{n-1} \\sum_{j=1}^{n} (L_{C,j} - \\hat{\\Delta})^2 $$\n$$ S_C^2 = \\frac{1}{6-1} [ (0.10-0.07)^2 + (0.08-0.07)^2 + (0.07-0.07)^2 + (0.08-0.07)^2 + (0.06-0.07)^2 + (0.03-0.07)^2 ] $$\n$$ S_C^2 = \\frac{1}{5} [ (0.03)^2 + (0.01)^2 + 0^2 + (0.01)^2 + (-0.01)^2 + (-0.04)^2 ] $$\n$$ S_C^2 = \\frac{1}{5} [ 0.0009 + 0.0001 + 0 + 0.0001 + 0.0001 + 0.0016 ] = \\frac{0.0028}{5} = 0.00056 $$\nThe variance of the difference in AUCs is estimated by:\n$$ \\widehat{\\text{Var}}(\\hat{\\Delta}) = \\frac{S_D^2}{m} + \\frac{S_C^2}{n} = \\frac{0.00045}{5} + \\frac{0.00056}{6} $$\n$$ \\widehat{\\text{Var}}(\\hat{\\Delta}) = 0.00009 + 0.00009333... = 0.00018333... $$\nThe standard error of $\\hat{\\Delta}$ is the square root of this variance:\n$$ \\text{SE}(\\hat{\\Delta}) = \\sqrt{0.00018333...} \\approx 0.01354006 $$\nThe margin of error (ME) for the $95\\%$ confidence interval is:\n$$ \\text{ME} = z_{0.975} \\times \\text{SE}(\\hat{\\Delta}) \\approx 1.96 \\times 0.01354006 \\approx 0.02653852 $$\nThe lower bound of the confidence interval is:\n$$ \\text{Lower Bound} = \\hat{\\Delta} - \\text{ME} \\approx 0.07 - 0.02653852 \\approx 0.04346148 $$\nRounding the lower bound to four significant figures gives $0.04346$.", "answer": "$$\n\\boxed{0.04346}\n$$", "id": "4959538"}]}