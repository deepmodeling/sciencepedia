{"hands_on_practices": [{"introduction": "Understanding the mathematical properties of measurement scales is fundamental to sound statistical practice. Ordinal data, such as pain scores or disease severity stages, are ubiquitous in medicine, yet they are often mishandled. This exercise provides a hands-on proof demonstrating why the sample mean is not an admissible statistic for ordinal scales, as it is not invariant to permissible transformations, whereas the median robustly preserves the data's central tendency [@problem_id:4993155].", "problem": "A clinical trial collects a Patient-Reported Outcome (PRO) pain rating on a $5$-level ordinal Likert scale, with categories labeled by integers $1,2,3,4,5$. Suppose the observed counts are $n_{1}=22$, $n_{2}=19$, $n_{3}=40$, $n_{4}=13$, $n_{5}=6$. In statistical modeling for medical data, admissible statistics for an ordinal measurement scale must be invariant under the class of strictly increasing transformations of the category labels because only relative order is meaningful on such scales. Starting from this foundational definition of ordinal scales and the standard definitions of the sample mean and median, do the following:\n\n1. From first principles, explain why strictly increasing transformations preserve the order of observations and therefore must leave any order-based statistic (such as the median) invariant in terms of category choice.\n\n2. Let $f(k)=k^{2}$ be a strictly increasing transformation on $\\{1,2,3,4,5\\}$. Compute the sample mean of the original coded data and the sample mean of the transformed data. Use these computations to demonstrate, without appealing to pre-stated results, that the mean is not invariant under strictly increasing transformations and thus is not admissible for ordinal data.\n\n3. Determine the median category before and after applying $f$, and justify why the median category is invariant under $f$.\n\nReport, as your final answer, the numerical value of the change in the mean induced by $f$, expressed as an exact fraction. Do not include units and do not round.", "solution": "The problem statement is a valid exercise in foundational statistical theory, specifically measurement theory as it applies to medical data. It is scientifically grounded, well-posed, and objective. We will proceed with a full solution.\n\nThe total number of patients in the clinical trial is the sum of the counts for each category:\n$$N = n_{1} + n_{2} + n_{3} + n_{4} + n_{5} = 22 + 19 + 40 + 13 + 6 = 100$$\n\n**1. Invariance of Order-based Statistics (e.g., Median)**\n\nAn ordinal scale implies that the data can be ranked or ordered, but the magnitude of the difference between categories is not meaningful. The integer labels $\\{1, 2, 3, 4, 5\\}$ represent an order, such that a patient reporting '$2$' has a higher pain level than one reporting '$1$', and lower than one reporting '$3$', but we cannot claim the difference in pain between '$1$' and '$2$' is the same as between '$2$' and '$3$'.\n\nAn admissible transformation for ordinal data is any strictly increasing function, $f$. By definition, a function $f$ is strictly increasing if for any two values $a$ and $b$ in its domain, $a < b$ implies $f(a) < f(b)$.\n\nLet the complete set of $N$ observations be denoted by $\\{x_1, x_2, \\dots, x_N\\}$, where each $x_i$ is one of the category labels. Let's sort these observations to get the ordered set $x_{(1)} \\le x_{(2)} \\le \\dots \\le x_{(N)}$.\nNow, let's apply a strictly increasing transformation $f$ to each observation, creating a new set of transformed observations $\\{f(x_1), f(x_2), \\dots, f(x_N)\\}$.\nIf we consider any two original observations $x_{(i)}$ and $x_{(j)}$ from the sorted list such that $i < j$, we must have $x_{(i)} \\le x_{(j)}$.\nIf $x_{(i)} < x_{(j)}$, the property of the strictly increasing function $f$ guarantees that $f(x_{(i)}) < f(x_{(j)})$.\nIf $x_{(i)} = x_{(j)}$, then $f(x_{(i)}) = f(x_{(j)})$.\nCombining these, $x_{(i)} \\le x_{(j)}$ implies $f(x_{(i)}) \\le f(x_{(j)})$. This means that the transformation $f$ preserves the rank-ordering of the entire dataset. The sorted list of transformed observations is simply $f(x_{(1)}) \\le f(x_{(2)}) \\le \\dots \\le f(x_{(N)})$.\n\nAn order-based statistic is any statistic that depends only on the rank-ordering of the data. The median is the canonical example. The median of a dataset of size $N$ is determined by the value of the observation at the middle position(s) in the sorted list. Since the transformation $f$ does not change the position of any observation in the sorted list, the observation at the median position remains the same. While its numerical *value* is transformed from $x_{(\\text{median-pos})}$ to $f(x_{(\\text{median-pos})})$, the observation itself, and thus its original category, is invariant. Therefore, the median *category* is an admissible statistic for ordinal data.\n\n**2. Non-invariance of the Mean**\n\nThe sample mean of the original data, denoted $\\bar{x}$, is calculated as the sum of all observations divided by the total number of observations. Using the provided counts:\n$$\\bar{x} = \\frac{1}{N} \\sum_{k=1}^{5} n_{k} \\cdot k = \\frac{1}{100} (n_{1} \\cdot 1 + n_{2} \\cdot 2 + n_{3} \\cdot 3 + n_{4} \\cdot 4 + n_{5} \\cdot 5)$$\n$$\\bar{x} = \\frac{1}{100} (22 \\cdot 1 + 19 \\cdot 2 + 40 \\cdot 3 + 13 \\cdot 4 + 6 \\cdot 5)$$\n$$\\bar{x} = \\frac{1}{100} (22 + 38 + 120 + 52 + 30) = \\frac{262}{100} = 2.62$$\nThe problem defines a strictly increasing transformation $f(k) = k^{2}$ on the domain $\\{1, 2, 3, 4, 5\\}$. The new category labels are $f(1)=1$, $f(2)=4$, $f(3)=9$, $f(4)=16$, and $f(5)=25$.\nThe sample mean of the transformed data, denoted $\\bar{y}$, is:\n$$\\bar{y} = \\frac{1}{N} \\sum_{k=1}^{5} n_{k} \\cdot f(k) = \\frac{1}{100} \\sum_{k=1}^{5} n_{k} \\cdot k^{2}$$\n$$\\bar{y} = \\frac{1}{100} (22 \\cdot 1^{2} + 19 \\cdot 2^{2} + 40 \\cdot 3^{2} + 13 \\cdot 4^{2} + 6 \\cdot 5^{2})$$\n$$\\bar{y} = \\frac{1}{100} (22 \\cdot 1 + 19 \\cdot 4 + 40 \\cdot 9 + 13 \\cdot 16 + 6 \\cdot 25)$$\n$$\\bar{y} = \\frac{1}{100} (22 + 76 + 360 + 208 + 150) = \\frac{816}{100} = 8.16$$\nWe observe that $\\bar{y} \\ne \\bar{x}$. Furthermore, the transformation applied to the original mean would be $f(\\bar{x}) = f(2.62) = (2.62)^{2} = 6.8644$, which is not equal to $\\bar{y}$. The mean is not invariant under this strictly increasing transformation. This is because the calculation of the mean treats the category labels as if they were on an interval scale, where distances between values are meaningful. The transformation $f(k)=k^2$ is non-linear and disproportionately changes these distances, thus altering the mean. This demonstrates that the mean is not an admissible statistic for ordinal data.\n\n**3. Invariance of the Median Category**\n\nThe total number of observations is $N=100$, an even number. The median is located between the $50$-th and $51$-st observations in the sorted dataset. We find the category for these positions by examining the cumulative counts:\n- Category 1: includes observations $1$ through $22$.\n- Category 2: includes observations $23$ through $22+19=41$.\n- Category 3: includes observations $42$ through $41+40=81$.\n- Category 4: includes observations $82$ through $81+13=94$.\n- Category 5: includes observations $95$ through $94+6=100$.\n\nBoth the $50$-th and $51$-st observations fall within the range for Category $3$. Thus, the median category of the original data is $3$.\n\nNow consider the data after applying the transformation $f(k)=k^2$. As established in Part 1, a strictly increasing transformation preserves the rank-order of all observations. The first $22$ observations are now labeled $1$, the next $19$ are labeled $4$, the next $40$ are labeled $9$, and so on. The observation that was $50$-th in the original sorted list is still $50$-th in the transformed sorted list. The observation that was $51$-st is still $51$-st.\nThe cumulative counts remain structurally identical. The observations at positions $50$ and $51$ still belong to the third group of observations. The original category for this group was $3$. So, the median category for the transformed data is also the one corresponding to the original category $3$. The numerical value of the median is now $f(3) = 3^2 = 9$. However, the *median category* (the third category in the ordered sequence) is unchanged, demonstrating its invariance.\n\nThe change in the mean induced by the transformation $f$ is the difference between the new mean and the original mean:\n$$\\Delta \\bar{x} = \\bar{y} - \\bar{x} = \\frac{816}{100} - \\frac{262}{100} = \\frac{554}{100}$$\nAs an exact fraction, this simplifies to:\n$$\\frac{554 \\div 2}{100 \\div 2} = \\frac{277}{50}$$\nThe numerator $277$ is a prime number, so this is the simplest form.", "answer": "$$\\boxed{\\frac{277}{50}}$$", "id": "4993155"}, {"introduction": "Building on the properties of single variables, we now explore how measurement scales affect the analysis of relationships between two variables. The choice of a correlation coefficient must respect the nature of the data to avoid misleading conclusions. This practice contrasts rank-based measures like Spearman’s $\\rho$ and Kendall’s $\\tau$ with the familiar Pearson’s $r$, illustrating how only the former are invariant under the monotonic transformations appropriate for ordinal scales or non-linear relationships [@problem_id:4993177].", "problem": "A clinical research team encodes disease severity for $n=6$ patients using an ordinal scale $X \\in \\{1,2,3,4,5,6\\}$, where larger $X$ indicates strictly worse severity. A laboratory biomarker $Y$ is measured on a ratio scale (concentration in arbitrary units) and is known to increase monotonically with severity in this cohort such that $Y$ doubles with each increment of $X$. Concretely, the observed data are the pairs $(x_i,y_i)$ for $i \\in \\{1,2,3,4,5,6\\}$ given by\n$$\n(x_1,y_1)=(1,1),\\quad (x_2,y_2)=(2,2),\\quad (x_3,y_3)=(3,4),\\quad (x_4,y_4)=(4,8),\\quad (x_5,y_5)=(5,16),\\quad (x_6,y_6)=(6,32).\n$$\nConsider the strictly increasing transformation $T:\\mathbb{R}_{+}\\to\\mathbb{R}$ defined by $T(y)=\\ln(y)$, which converts the biomarker to a log scale appropriate for certain modeling tasks.\n\nStarting from core definitions of measurement scales and correlation measures used in statistical modeling in medicine:\n- Ordinal scales preserve only order under strictly monotonic transformations.\n- Spearman’s rank correlation $\\rho$ is defined as the Pearson correlation applied to the ranks of the variables.\n- Kendall’s $\\tau$ measures the standardized difference between the number of concordant and discordant pairs and depends only on order.\n- Pearson’s correlation $r$ is defined in terms of centered covariance and standard deviations and is sensitive to measurement units and nonlinear rescalings.\n\nPerform the following:\n1. Treat $X$ and $Y$ as given above. Compute Spearman’s rank correlation $\\rho(X,Y)$ and Kendall’s $\\tau(X,Y)$ from first principles of ranks and concordance, respectively.\n2. Apply the transformation $Y' = T(Y) = \\ln(Y)$ and compute $\\rho(X,Y')$ and $\\tau(X,Y')$ using the same principles. Argue briefly why these values must equal their counterparts from part $1$.\n3. Compute Pearson’s correlation $r(X,Y)$ using the definition $r(X,Y) = S_{XY}/\\sqrt{S_{XX}S_{YY}}$ where $S_{XY}=\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y})$ and similarly for $S_{XX}$ and $S_{YY}$. Then compute $r(X,Y')$ and explain the change relative to $r(X,Y)$ in light of measurement scale properties.\n\nRound any non-integer numerical answers to four significant figures. Express your final answer as a single row matrix (use the order: $\\rho(X,Y)$, $\\rho(X,Y')$, $\\tau(X,Y)$, $\\tau(X,Y')$, $r(X,Y)$, $r(X,Y')$).", "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in the principles of statistical measurement, well-posed with all necessary data and definitions, and expressed in objective language. It presents a clear, solvable problem in biostatistics without any factual unsoundness, ambiguity, or contradiction.\n\nThe solution proceeds in three parts as requested.\n\n**Part 1: Computation of $\\rho(X,Y)$ and $\\tau(X,Y)$**\n\nSpearman’s rank correlation, $\\rho(X,Y)$, is the Pearson correlation coefficient applied to the ranks of the variables $X$ and $Y$.\nThe variable $X$ is given by the sequence $X = \\{1, 2, 3, 4, 5, 6\\}$. As these values are already sorted and unique, their ranks, denoted $R_X$, are identical to the values themselves: $R_X = \\{1, 2, 3, 4, 5, 6\\}$.\nThe variable $Y$ is given by the sequence $Y = \\{1, 2, 4, 8, 16, 32\\}$. This sequence is strictly increasing. Therefore, the ranks of $Y$, denoted $R_Y$, are $R_Y = \\{1, 2, 3, 4, 5, 6\\}$.\nSince the ranks are identical, $R_X = R_Y$, the relationship between the ranks is perfectly linear with a positive slope. The Pearson correlation of a variable with itself is $1$. Thus,\n$$\n\\rho(X,Y) = r(R_X, R_Y) = 1\n$$\n\nKendall’s rank correlation, $\\tau(X,Y)$, is defined as $\\tau = (N_c - N_d) / (N_c + N_d)$, where $N_c$ is the number of concordant pairs and $N_d$ is the number of discordant pairs. The total number of unique pairs of observations is $\\binom{n}{2} = \\binom{6}{2} = \\frac{6 \\times 5}{2} = 15$.\nA pair of observations $(x_i, y_i)$ and $(x_j, y_j)$ is concordant if the signs of $(x_i - x_j)$ and $(y_i - y_j)$ are the same.\nThe data for $X$ are $\\{1, 2, 3, 4, 5, 6\\}$, which is a strictly increasing sequence.\nThe data for $Y$ are $\\{1, 2, 4, 8, 16, 32\\}$, which is also a strictly increasing sequence.\nFor any two indices $i < j$, we will always have $x_i < x_j$ and $y_i < y_j$. This means $(x_i - x_j) < 0$ and $(y_i - y_j) < 0$, so their signs are the same. Consequently, all $15$ possible pairs of observations are concordant.\nTherefore, $N_c = 15$ and $N_d = 0$.\nThe value of Kendall's $\\tau$ is:\n$$\n\\tau(X,Y) = \\frac{15 - 0}{15 + 0} = 1\n$$\n\n**Part 2: Computation of $\\rho(X,Y')$ and $\\tau(X,Y')$**\n\nThe transformation is $Y' = T(Y) = \\ln(Y)$. The original values of $Y$ are $\\{1, 2, 4, 8, 16, 32\\}$.\nThe transformed values are $Y' = \\{\\ln(1), \\ln(2), \\ln(4), \\ln(8), \\ln(16), \\ln(32)\\} = \\{0, \\ln(2), 2\\ln(2), 3\\ln(2), 4\\ln(2), 5\\ln(2)\\}$.\nThe function $T(y) = \\ln(y)$ is a strictly monotonic increasing function for its domain $y \\in \\mathbb{R}_{+}$.\nSpearman's $\\rho$ and Kendall's $\\tau$ are both rank-based measures of correlation. A strictly monotonic transformation applied to a variable does not alter the ordering of its values. Therefore, the ranks of $Y$ and $Y'$ are identical. The set of ranks for $Y'$ is $R_{Y'} = \\{1, 2, 3, 4, 5, 6\\}$, which is the same as $R_Y$.\nSince the ranks are unchanged, the calculation for $\\rho(X,Y')$ is identical to that for $\\rho(X,Y)$.\n$$\n\\rho(X,Y') = \\rho(X,Y) = 1\n$$\nSimilarly, since the ordering of the $Y$ values is preserved, the concordance or discordance of every pair of observations remains the same. The number of concordant pairs for $(X, Y')$ is still $N_c = 15$ and the number of discordant pairs is $N_d = 0$.\n$$\n\\tau(X,Y') = \\tau(X,Y) = 1\n$$\nThis invariance property is a fundamental characteristic of rank-based correlation coefficients, making them suitable for analyzing monotonic relationships on ordinal or transformed ratio/interval scales.\n\n**Part 3: Computation of $r(X,Y)$ and $r(X,Y')$**\n\nPearson’s correlation, $r(X,Y)$, is given by $r(X,Y) = S_{XY}/\\sqrt{S_{XX}S_{YY}}$. First, we compute the necessary summary statistics for $X$ and $Y$ with $n=6$.\nThe means are:\n$\\bar{x} = \\frac{1+2+3+4+5+6}{6} = \\frac{21}{6} = 3.5$\n$\\bar{y} = \\frac{1+2+4+8+16+32}{6} = \\frac{63}{6} = 10.5$\n\nThe sums of squared deviations are:\n$S_{XX} = \\sum_{i=1}^n (x_i - \\bar{x})^2 = (1-3.5)^2 + (2-3.5)^2 + \\dots + (6-3.5)^2 = (-2.5)^2 + (-1.5)^2 + (-0.5)^2 + (0.5)^2 + (1.5)^2 + (2.5)^2 = 6.25 + 2.25 + 0.25 + 0.25 + 2.25 + 6.25 = 17.5$.\n$S_{YY} = \\sum_{i=1}^n (y_i - \\bar{y})^2 = (1-10.5)^2 + (2-10.5)^2 + \\dots + (32-10.5)^2 = (-9.5)^2 + (-8.5)^2 + (-6.5)^2 + (-2.5)^2 + (5.5)^2 + (21.5)^2 = 90.25 + 72.25 + 42.25 + 6.25 + 30.25 + 462.25 = 703.5$.\n\nThe sum of cross-products of deviations is:\n$S_{XY} = \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y}) = (-2.5)(-9.5) + (-1.5)(-8.5) + (-0.5)(-6.5) + (0.5)(-2.5) + (1.5)(5.5) + (2.5)(21.5) = 23.75 + 12.75 + 3.25 - 1.25 + 8.25 + 53.75 = 100.5$.\n\nNow, we compute $r(X,Y)$:\n$$\nr(X,Y) = \\frac{100.5}{\\sqrt{17.5 \\times 703.5}} = \\frac{100.5}{\\sqrt{12311.25}} \\approx \\frac{100.5}{110.95607} \\approx 0.90576\n$$\nRounding to four significant figures, $r(X,Y) \\approx 0.9058$.\n\nNext, we compute $r(X,Y')$. The relationship between $X$ and $Y$ is given by $y_i = 2^{x_i-1}$. Applying the transformation $Y'=\\ln(Y)$, we find the relationship between $X$ and $Y'$:\n$$\ny'_i = \\ln(y_i) = \\ln(2^{x_i-1}) = (x_i-1)\\ln(2) = (\\ln 2)x_i - \\ln 2\n$$\nThis equation shows that $Y'$ is a perfect linear function of $X$ of the form $Y' = aX+b$, where the slope is $a = \\ln(2) > 0$ and the intercept is $b = -\\ln(2)$.\nPearson's correlation coefficient measures the strength of a linear relationship. When two variables have a perfect linear relationship with a positive slope, their Pearson correlation is exactly $1$. Therefore,\n$$\nr(X,Y') = 1\n$$\n\nThe change in Pearson's correlation from $r(X,Y) \\approx 0.9058$ to $r(X,Y') = 1$ is due to the nature of the measure. Pearson's $r$ is sensitive to nonlinear transformations. The relationship between $X$ and $Y$ is exponential, which is monotonic but nonlinear. Pearson's $r$ for this relationship is high but not equal to $1$, reflecting the deviation from perfect linearity. The logarithmic transformation linearizes this exponential relationship, resulting in a perfect linear association between $X$ and $Y'$. This demonstrates that while Pearson's $r$ is invariant under linear transformations, it is not invariant under nonlinear transformations, unlike the rank-based correlations $\\rho$ and $\\tau$. The change in $r$ correctly reflects the change in the geometric form of the relationship from exponential to linear.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1 & 1 & 1 & 1 & 0.9058 & 1 \\end{pmatrix}}\n$$", "id": "4993177"}, {"introduction": "Medical research frequently involves tracking patients over time, generating time-to-event data, which is measured on a ratio scale. However, real-world cohort studies often include complexities like delayed entry, where patients are not observed from the start. This exercise demonstrates the critical importance of correctly defining the at-risk set in survival analysis to account for such left-truncation, ensuring an unbiased estimation of the hazard ratio from a Cox proportional hazards model [@problem_id:4993170].", "problem": "A hospital-based observational cohort study of patients with acute decompensated heart failure investigates time-to-event data for in-hospital mortality under delayed entry (left truncation). The exposure is early diuretic optimization, recorded as a binary nominal covariate $X \\in \\{0,1\\}$ where $X=1$ indicates early optimization and $X=0$ indicates usual care. The time origin is the calendar time of hospital admission. Patients become eligible for observation only after clinical stabilization, so each patient $i$ has a left-truncation (delayed entry) time $L_i$ and an exit time $R_i$ with an event indicator $\\delta_i \\in \\{0,1\\}$ indicating death ($\\delta_i=1$) or right-censoring ($\\delta_i=0$). The time-to-event and entry times are ratio-scale times, the exposure $X$ is binary nominal, and $\\delta$ is binary.\n\nThe study follows $5$ patients with the following records, where times are measured in days from admission:\n- Patient $A$: $X=1$, $L_A=2$, $R_A=5$, $\\delta_A=1$.\n- Patient $B$: $X=1$, $L_B=6$, $R_B=11$, $\\delta_B=0$.\n- Patient $C$: $X=0$, $L_C=0$, $R_C=9$, $\\delta_C=1$.\n- Patient $D$: $X=0$, $L_D=7$, $R_D=12$, $\\delta_D=0$.\n- Patient $E$: $X=0$, $L_E=8$, $R_E=10$, $\\delta_E=0$.\n\nAssume the Cox proportional hazards model $h(t \\mid X)=h_0(t)\\exp(\\beta X)$ with an unspecified baseline hazard $h_0(t)$, and that the risk set at event time $t$ under left truncation is defined as $R(t)=\\{i: L_i < t \\leq R_i\\}$. Using only the two observed event times and the correct risk sets induced by left truncation, compute the maximum partial-likelihood estimate of the hazard ratio $\\exp(\\beta)$ comparing $X=1$ to $X=0$. Express your final answer as a single exact value (no rounding).", "solution": "### Step 1: Extract Givens\nThe problem provides the following information:\n-   **Model**: A Cox proportional hazards model, $h(t \\mid X) = h_0(t)\\exp(\\beta X)$.\n-   **Covariate**: $X$ is a binary nominal covariate, where $X=1$ for early diuretic optimization and $X=0$ for usual care.\n-   **Data Structure**: The data is for $5$ patients, with left-truncation (delayed entry) time $L_i$, exit time $R_i$, and event indicator $\\delta_i$. Times are on a ratio scale.\n-   **Risk Set Definition**: The risk set at event time $t$ is explicitly defined as $R(t)=\\{i: L_i < t \\leq R_i\\}$.\n-   **Patient Data**: Times are in days.\n    -   Patient A: $X_A=1$, $L_A=2$, $R_A=5$, $\\delta_A=1$ (event).\n    -   Patient B: $X_B=1$, $L_B=6$, $R_B=11$, $\\delta_B=0$ (censored).\n    -   Patient C: $X_C=0$, $L_C=0$, $R_C=9$, $\\delta_C=1$ (event).\n    -   Patient D: $X_D=0$, $L_D=7$, $R_D=12$, $\\delta_D=0$ (censored).\n    -   Patient E: $X_E=0$, $L_E=8$, $R_E=10$, $\\delta_E=0$ (censored).\n-   **Objective**: Compute the maximum partial-likelihood estimate of the hazard ratio $\\exp(\\beta)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is validated as follows:\n-   **Scientifically Grounded**: The problem is set within the standard framework of survival analysis, a core discipline in biostatistics and epidemiology. The Cox proportional hazards model is a fundamental tool, and left-truncation is a common feature of observational study data. All concepts are well-established.\n-   **Well-Posed**: The problem is well-posed. It provides a clear model, a specific dataset, and a precise definition for the risk set. The objective is to find the maximum likelihood estimate for a parameter of the model, which is a standard and solvable statistical inference problem. A unique solution is expected.\n-   **Objective**: The language is precise and technical. All terms like \"left truncation\", \"risk set\", \"proportional hazards\", and \"partial-likelihood\" are standard and have unambiguous definitions in the field. The data is provided objectively.\n\nThe problem is self-contained, scientifically sound, and free of any flaws listed in the validation checklist. It is therefore deemed **valid**.\n\n### Step 3: Proceed with Solution\n\nThe goal is to find the maximum partial-likelihood estimate of the hazard ratio, $\\theta = \\exp(\\beta)$. The partial likelihood function for a Cox model with a single binary covariate $X$, in the presence of left-truncation and right-censoring, is constructed as a product over the observed event times.\n\nThe general form of the partial likelihood is:\n$$ L(\\beta) = \\prod_{j \\text{ where } \\delta_j=1} \\frac{h(t_j \\mid X_j)}{\\sum_{k \\in R(t_j)} h(t_k \\mid X_k)} $$\nwhere $t_j$ is the event time for subject $j$. Substituting the Cox model $h(t \\mid X) = h_0(t)\\exp(\\beta X)$:\n$$ L(\\beta) = \\prod_{j \\text{ where } \\delta_j=1} \\frac{h_0(t_j) \\exp(\\beta X_j)}{\\sum_{k \\in R(t_j)} h_0(t_j) \\exp(\\beta X_k)} = \\prod_{j \\text{ where } \\delta_j=1} \\frac{\\exp(\\beta X_j)}{\\sum_{k \\in R(t_j)} \\exp(\\beta X_k)} $$\n\nFirst, we identify the ordered event times from the data. Events are indicated by $\\delta_i=1$.\n-   Patient A had an event at time $R_A=5$.\n-   Patient C had an event at time $R_C=9$.\nThe other patients were censored. Thus, the ordered event times are $t_{(1)} = 5$ days and $t_{(2)} = 9$ days.\n\nNext, we construct the risk set $R(t)=\\{i: L_i < t \\leq R_i\\}$ for each event time.\n\n**Event 1: $t_{(1)} = 5$ (Patient A)**\nThe patient experiencing the event is Patient A, for whom $X_A=1$. The risk set $R(5)$ consists of all patients $i$ for whom $L_i < 5 \\leq R_i$.\n-   Patient A: $L_A=2, R_A=5$. The condition $2 < 5 \\leq 5$ is true. Patient A is in $R(5)$. $X_A=1$.\n-   Patient B: $L_B=6, R_B=11$. The condition $6 < 5$ is false. Patient B is not in $R(5)$.\n-   Patient C: $L_C=0, R_C=9$. The condition $0 < 5 \\leq 9$ is true. Patient C is in $R(5)$. $X_C=0$.\n-   Patient D: $L_D=7, R_D=12$. The condition $7 < 5$ is false. Patient D is not in $R(5)$.\n-   Patient E: $L_E=8, R_E=10$. The condition $8 < 5$ is false. Patient E is not in $R(5)$.\nSo, the risk set is $R(5) = \\{A, C\\}$.\n\nThe contribution to the partial likelihood from this event is:\n$$ L_1(\\beta) = \\frac{\\exp(\\beta X_A)}{\\exp(\\beta X_A) + \\exp(\\beta X_C)} = \\frac{\\exp(\\beta \\cdot 1)}{\\exp(\\beta \\cdot 1) + \\exp(\\beta \\cdot 0)} = \\frac{\\exp(\\beta)}{\\exp(\\beta) + 1} $$\n\n**Event 2: $t_{(2)} = 9$ (Patient C)**\nThe patient experiencing the event is Patient C, for whom $X_C=0$. The risk set $R(9)$ consists of all patients $i$ for whom $L_i < 9 \\leq R_i$.\n-   Patient A: $R_A=5$. The condition $9 \\leq 5$ is false. Patient A is not in $R(9)$.\n-   Patient B: $L_B=6, R_B=11$. The condition $6 < 9 \\leq 11$ is true. Patient B is in $R(9)$. $X_B=1$.\n-   Patient C: $L_C=0, R_C=9$. The condition $0 < 9 \\leq 9$ is true. Patient C is in $R(9)$. $X_C=0$.\n-   Patient D: $L_D=7, R_D=12$. The condition $7 < 9 \\leq 12$ is true. Patient D is in $R(9)$. $X_D=0$.\n-   Patient E: $L_E=8, R_E=10$. The condition $8 < 9 \\leq 10$ is true. Patient E is in $R(9)$. $X_E=0$.\nSo, the risk set is $R(9) = \\{B, C, D, E\\}$.\n\nThe contribution to the partial likelihood from this event is:\n$$ L_2(\\beta) = \\frac{\\exp(\\beta X_C)}{\\exp(\\beta X_B) + \\exp(\\beta X_C) + \\exp(\\beta X_D) + \\exp(\\beta X_E)} = \\frac{\\exp(\\beta \\cdot 0)}{\\exp(\\beta \\cdot 1) + \\exp(\\beta \\cdot 0) + \\exp(\\beta \\cdot 0) + \\exp(\\beta \\cdot 0)} = \\frac{1}{\\exp(\\beta) + 3} $$\n\nThe full partial likelihood is $L(\\beta) = L_1(\\beta) \\times L_2(\\beta)$:\n$$ L(\\beta) = \\frac{\\exp(\\beta)}{\\exp(\\beta) + 1} \\cdot \\frac{1}{\\exp(\\beta) + 3} $$\n\nTo find the maximum likelihood estimate, it is simpler to maximize the log-partial likelihood, $\\ell(\\beta) = \\ln(L(\\beta))$:\n$$ \\ell(\\beta) = \\ln(\\exp(\\beta)) - \\ln(\\exp(\\beta) + 1) - \\ln(\\exp(\\beta) + 3) $$\n$$ \\ell(\\beta) = \\beta - \\ln(\\exp(\\beta) + 1) - \\ln(\\exp(\\beta) + 3) $$\n\nWe differentiate $\\ell(\\β)$ with respect to $\\beta$ to get the score function, $U(\\beta)$, and set it to zero.\n$$ U(\\beta) = \\frac{d\\ell}{d\\beta} = 1 - \\frac{\\exp(\\beta)}{\\exp(\\beta) + 1} - \\frac{\\exp(\\beta)}{\\exp(\\beta) + 3} $$\nSetting $U(\\beta)=0$:\n$$ 1 = \\frac{\\exp(\\beta)}{\\exp(\\beta) + 1} + \\frac{\\exp(\\beta)}{\\exp(\\beta) + 3} $$\n\nLet $\\theta = \\exp(\\beta)$ be the hazard ratio we wish to estimate. The equation becomes:\n$$ 1 = \\frac{\\theta}{\\theta + 1} + \\frac{\\theta}{\\theta + 3} $$\nTo solve for $\\theta$, we find a common denominator for the right side:\n$$ 1 = \\frac{\\theta(\\theta + 3) + \\theta(\\theta + 1)}{(\\theta + 1)(\\theta + 3)} $$\n$$ (\\theta + 1)(\\theta + 3) = \\theta^2 + 3\\theta + \\theta^2 + \\theta $$\n$$ \\theta^2 + 4\\theta + 3 = 2\\theta^2 + 4\\theta $$\nSubtracting $4\\theta$ from both sides gives:\n$$ \\theta^2 + 3 = 2\\theta^2 $$\nSubtracting $\\theta^2$ from both sides gives:\n$$ 3 = \\theta^2 $$\nSince the hazard ratio $\\theta = \\exp(\\beta)$ must be positive, we take the positive square root:\n$$ \\theta = \\sqrt{3} $$\nThe maximum partial-likelihood estimate of the hazard ratio $\\exp(\\beta)$ is $\\sqrt{3}$.", "answer": "$$ \\boxed{\\sqrt{3}} $$", "id": "4993170"}]}