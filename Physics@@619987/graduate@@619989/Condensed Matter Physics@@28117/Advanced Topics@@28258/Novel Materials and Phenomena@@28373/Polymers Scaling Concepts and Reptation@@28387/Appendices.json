{"hands_on_practices": [{"introduction": "Understanding the behavior of a single polymer chain is the first step towards describing complex polymer materials. This exercise guides you through the foundational calculation of an ideal chain's size using a random walk model, which establishes the famous scaling law $R \\sim N^{1/2}$. You will then use this result to estimate the overlap concentration $c^*$, a critical parameter that defines the boundary between dilute and semi-dilute solutions. [@problem_id:3010813]", "problem": "Consider a flexible polymer in a theta solvent, modeled as an ideal freely jointed chain consisting of $N$ Kuhn segments of fixed length $b$. Let the end-to-end vector be $\\mathbf{R} = \\sum_{i=1}^{N} \\mathbf{a}_i$, where the segment vectors satisfy $\\langle \\mathbf{a}_i \\rangle = \\mathbf{0}$ and $\\langle \\mathbf{a}_i \\cdot \\mathbf{a}_j \\rangle = b^{2} \\delta_{ij}$, with $\\delta_{ij}$ the Kronecker delta. Using only these definitions and standard properties of isotropic random walks, derive the scaling form for the coil size $R \\equiv \\sqrt{\\langle R^{2} \\rangle}$ as a function of $N$ and $b$. Then, using the definition that the overlap concentration $c^{*}$ is the monomer number density at which coils just begin to interpenetrate so that the volume available per chain is comparable to the volume occupied by a single coil, obtain the scaling expression for $c^{*}$ in terms of $N$ and $b$. \n\nInstructions:\n- Treat numerical prefactors of order unity as negligible; report leading scaling dependences only.\n- Express your final results as closed-form analytic expressions in terms of $N$ and $b$.\n- Report $c^{*}$ in monomer number density units (monomers per unit volume).\n- No numerical substitution is required; no rounding is needed.\n- Provide both the coil size $R$ and the overlap concentration $c^{*}$ as your final answers.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It presents a standard derivation in statistical polymer physics based on the ideal freely jointed chain model, which is appropriate for a polymer in a theta solvent. All definitions and conditions are standard and self-consistent.\n\nWe are tasked with deriving the scaling forms for the coil size, $R$, and the overlap concentration, $c^{*}$, for a flexible polymer chain modeled as an ideal freely jointed chain.\n\nFirst, we determine the coil size, $R$, which is defined as the root-mean-square end-to-end distance, $R \\equiv \\sqrt{\\langle R^{2} \\rangle}$. The end-to-end vector, $\\mathbf{R}$, is given as the sum of $N$ segment vectors $\\mathbf{a}_i$:\n$$\n\\mathbf{R} = \\sum_{i=1}^{N} \\mathbf{a}_i\n$$\nThe mean-square end-to-end distance, $\\langle R^{2} \\rangle$, is the statistical average of the squared magnitude of this vector:\n$$\n\\langle R^{2} \\rangle = \\langle \\mathbf{R} \\cdot \\mathbf{R} \\rangle = \\left\\langle \\left( \\sum_{i=1}^{N} \\mathbf{a}_i \\right) \\cdot \\left( \\sum_{j=1}^{N} \\mathbf{a}_j \\right) \\right\\rangle\n$$\nWe can expand the dot product into a double summation:\n$$\n\\langle R^{2} \\rangle = \\left\\langle \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\mathbf{a}_i \\cdot \\mathbf{a}_j \\right\\rangle\n$$\nBy the linearity of the expectation operator (the average), we can move the summation outside the average:\n$$\n\\langle R^{2} \\rangle = \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\langle \\mathbf{a}_i \\cdot \\mathbf{a}_j \\rangle\n$$\nThe problem states that the segment vectors are uncorrelated, which is formally expressed as $\\langle \\mathbf{a}_i \\cdot \\mathbf{a}_j \\rangle = b^{2} \\delta_{ij}$, where $b$ is the Kuhn segment length and $\\delta_{ij}$ is the Kronecker delta. Substituting this into our expression gives:\n$$\n\\langle R^{2} \\rangle = \\sum_{i=1}^{N} \\sum_{j=1}^{N} b^{2} \\delta_{ij}\n$$\nThe Kronecker delta, $\\delta_{ij}$, is equal to $1$ if $i=j$ and $0$ if $i \\neq j$. Therefore, the inner summation over $j$ is non-zero only for the term where $j=i$. This collapses the double summation into a single summation:\n$$\n\\langle R^{2} \\rangle = \\sum_{i=1}^{N} b^{2}\n$$\nThis is a sum of $N$ identical terms, $b^{2}$. Thus, the result is:\n$$\n\\langle R^{2} \\rangle = N b^{2}\n$$\nThe coil size $R$ is the square root of this quantity:\n$$\nR = \\sqrt{\\langle R^{2} \\rangle} = \\sqrt{N b^{2}} = b N^{1/2}\n$$\nThis gives the characteristic size of an ideal polymer coil, which follows the scaling of a random walk, $R \\sim N^{1/2}$.\n\nNext, we derive the scaling expression for the overlap concentration, $c^{*}$. The overlap concentration is defined as the monomer number density at which the polymer coils, which are dispersed in a solvent, begin to touch and interpenetrate. At this specific concentration, the total volume of the system is densely filled with coils, meaning the volume available per chain is approximately equal to the volume occupied by a single coil.\n\nLet $c^{*}$ be the overlap concentration in units of monomers (Kuhn segments) per unit volume. The total number of monomers in a volume $V_{sys}$ is $c^{*} V_{sys}$. If each polymer chain consists of $N$ monomers, then the number of chains, $n_{chains}$, in the system is given by:\n$$\nn_{chains} = \\frac{c^{*} V_{sys}}{N}\n$$\nThe volume per chain is therefore:\n$$\n\\frac{V_{sys}}{n_{chains}} = \\frac{N}{c^{*}}\n$$\nThe condition for overlap is that this volume per chain is comparable to the volume occupied by a single coil, $V_{coil}$. We can approximate the volume of a single coil as a sphere of radius $R$. Ignoring numerical prefactors of order unity (like $\\frac{4}{3}\\pi$), the scaling of the coil volume is:\n$$\nV_{coil} \\sim R^{3}\n$$\nSubstituting the previously derived expression for $R = bN^{1/2}$:\n$$\nV_{coil} \\sim (bN^{1/2})^{3} = b^{3} N^{3/2}\n$$\nNow, we equate the volume per chain to the coil volume at the overlap concentration:\n$$\n\\frac{N}{c^{*}} \\sim V_{coil} \\sim b^{3} N^{3/2}\n$$\nSolving for $c^{*}$ gives the desired scaling relationship:\n$$\nc^{*} \\sim \\frac{N}{b^{3} N^{3/2}} = N^{1 - 3/2} b^{-3} = N^{-1/2} b^{-3}\n$$\nThis is the scaling expression for the overlap concentration. It indicates that for longer chains (larger $N$), the concentration required for coils to overlap is lower, which is physically intuitive as larger coils occupy more space.\n\nThe final results for the scaling forms are $R = b N^{1/2}$ for the coil size and $c^{*} \\sim b^{-3} N^{-1/2}$ for the overlap concentration.", "answer": "$$\n\\boxed{\\begin{pmatrix} b N^{1/2} & b^{-3} N^{-1/2} \\end{pmatrix}}\n$$", "id": "3010813"}, {"introduction": "When polymer chains overlap in a semi-dilute solution, their interactions screen the excluded volume effect, introducing a new characteristic length scale. This practice introduces the powerful blob model, a cornerstone of polymer scaling theory, which allows us to describe the chain's conformation in this complex environment. By applying scaling arguments, you will derive the concentration dependence of the correlation length $\\xi$ and the number of monomers per blob $g$, revealing the hierarchical structure of chains in solution. [@problem_id:3010784]", "problem": "A flexible linear polymer of $N$ monomers, each of size $a$, is dissolved in a good or $\\theta$ solvent at monomer number concentration $c$ (monomers per unit volume), in the semidilute regime where interchain overlap screens excluded-volume interactions beyond a correlation length $\\xi$. Within this regime, polymer conformations on length scales smaller than $\\xi$ are governed by the same statistics as in dilute solution, characterized by the Flory scaling exponent $\\nu$ for the end-to-end distance of a subchain of $g$ monomers.\n\nUsing scaling concepts and the definition of a correlation blob, derive the semidilute correlation length $\\xi$ and the number of monomers per blob $g$ as analytic expressions in terms of $a$, $c$, and $\\nu$. Then, under the assumption $N \\gg g$, estimate the number of blobs per chain $N/g$ as an analytic expression. Express the final answer as a single row matrix using the LaTeX $\\texttt{pmatrix}$ environment, with entries ordered as $\\xi$, $g$, and $N/g$.\n\nUse $a$ in meters and $c$ in $\\text{m}^{-3}$ so that $\\xi$ is obtained in meters; $g$ and $N/g$ are dimensionless. No numerical rounding is required; provide exact closed-form expressions.", "solution": "The problem statement is scientifically sound, self-contained, and well-posed. It is grounded in the established principles of polymer physics, specifically the scaling theory of semidilute polymer solutions developed by de Gennes. The concepts of correlation length, Flory exponent, and scaling blobs are standard and clearly defined. The problem asks for a rigorous derivation of canonical results within this framework. Therefore, the problem is valid and a solution will be provided.\n\nThe derivation is based on two fundamental scaling relations that define the properties of the system in the semidilute regime.\n\n1.  **The Correlation Blob Model**: In a semidilute solution, polymer chains overlap. The correlation length, $\\xi$, defines a characteristic length scale. On length scales smaller than $\\xi$, a chain segment does not interact with other chains and thus behaves as if it were in a dilute solution. A \"correlation blob\" is a subchain of $g$ monomers with a size equal to the correlation length $\\xi$. The relationship between the size of this subchain and the number of monomers it contains follows the Flory scaling for a single chain in the given solvent (good or $\\theta$). This is described by the Flory exponent $\\nu$. Assuming the monomer size $a$ acts as the fundamental length scale, this relationship is:\n    $$ \\xi = a g^{\\nu} \\quad (1) $$\n\n2.  **Space-Filling Condition**: The semidilute regime is characterized by a \"sea\" of these correlation blobs. The blobs are assumed to be roughly close-packed, meaning the overall monomer number concentration $c$ of the solution is approximately equal to the concentration of monomers within a single blob. The volume of a single blob in three-dimensional space is of the order $\\xi^3$. The monomer concentration inside a blob is therefore $g / \\xi^3$. Equating this to the overall concentration $c$ gives our second scaling relation:\n    $$ c = \\frac{g}{\\xi^3} \\quad (2) $$\n\nWe now have a system of two equations with two unknowns, $\\xi$ and $g$. We can solve this system to express $\\xi$ and $g$ in terms of the given parameters $a$, $c$, and $\\nu$.\n\nFirst, we solve for the correlation length $\\xi$. From equation (2), we can express $g$ in terms of $c$ and $\\xi$:\n$$ g = c \\xi^3 $$\nSubstituting this expression for $g$ into equation (1):\n$$ \\xi = a (c \\xi^3)^{\\nu} $$\n$$ \\xi = a c^{\\nu} (\\xi^3)^{\\nu} = a c^{\\nu} \\xi^{3\\nu} $$\nNow we rearrange this equation to solve for $\\xi$. Divide both sides by $\\xi^{3\\nu}$:\n$$ \\xi^{1 - 3\\nu} = a c^{\\nu} $$\nTo isolate $\\xi$, we raise both sides to the power of $\\frac{1}{1 - 3\\nu}$:\n$$ \\xi = \\left( a c^{\\nu} \\right)^{\\frac{1}{1 - 3\\nu}} = a^{\\frac{1}{1 - 3\\nu}} c^{\\frac{\\nu}{1 - 3\\nu}} $$\nThis expression can be rewritten in a more conventional form by factoring out a term of $a$:\n$$ \\xi = a \\cdot a^{\\frac{1}{1 - 3\\nu} - 1} c^{\\frac{\\nu}{1 - 3\\nu}} = a \\cdot a^{\\frac{1 - (1 - 3\\nu)}{1 - 3\\nu}} c^{\\frac{\\nu}{1 - 3\\nu}} $$\n$$ \\xi = a \\cdot a^{\\frac{3\\nu}{1 - 3\\nu}} c^{\\frac{\\nu}{1 - 3\\nu}} = a \\cdot (a^3)^{\\frac{\\nu}{1 - 3\\nu}} c^{\\frac{\\nu}{1 - 3\\nu}} $$\n$$ \\xi = a (a^3 c)^{\\frac{\\nu}{1 - 3\\nu}} $$\nFor physical systems in three dimensions, the Flory exponent $\\nu$ is in the range $[\\frac{1}{2}, \\frac{3}{5}]$. In this range, the denominator $1 - 3\\nu$ is negative. It is common to write the exponent with a positive denominator by factoring out $-1$: $1 - 3\\nu = -(3\\nu - 1)$. The expression becomes:\n$$ \\xi = a (a^3 c)^{-\\frac{\\nu}{3\\nu - 1}} $$\n\nNext, we solve for the number of monomers per blob, $g$. We can use the relation $g = c \\xi^3$. Substituting the derived expression for $\\xi$:\n$$ g = c \\left( a (a^3 c)^{\\frac{\\nu}{1 - 3\\nu}} \\right)^3 $$\n$$ g = c \\cdot a^3 \\left( (a^3 c)^{\\frac{\\nu}{1 - 3\\nu}} \\right)^3 $$\n$$ g = (a^3 c) \\cdot (a^3 c)^{\\frac{3\\nu}{1 - 3\\nu}} $$\n$$ g = (a^3 c)^{1 + \\frac{3\\nu}{1 - 3\\nu}} $$\nThe exponent is $1 + \\frac{3\\nu}{1 - 3\\nu} = \\frac{1 - 3\\nu + 3\\nu}{1 - 3\\nu} = \\frac{1}{1 - 3\\nu}$.\nSo, we have:\n$$ g = (a^3 c)^{\\frac{1}{1 - 3\\nu}} $$\nAgain, using the convention of a positive denominator in the exponent:\n$$ g = (a^3 c)^{-\\frac{1}{3\\nu - 1}} $$\n\nFinally, we need to find the number of blobs per chain, $N/g$, under the assumption that the total number of monomers in a chain $N$ is much larger than the number of monomers in a blob $g$ ($N \\gg g$). This is a simple division:\n$$ \\frac{N}{g} = N g^{-1} = N \\left( (a^3 c)^{\\frac{1}{1 - 3\\nu}} \\right)^{-1} $$\n$$ \\frac{N}{g} = N (a^3 c)^{-\\frac{1}{1 - 3\\nu}} $$\nUsing the positive denominator convention:\n$$ \\frac{N}{g} = N (a^3 c)^{\\frac{1}{3\\nu - 1}} $$\n\nThe three requested quantities are:\n1.  Correlation length: $\\xi = a (a^3 c)^{-\\frac{\\nu}{3\\nu - 1}}$\n2.  Monomers per blob: $g = (a^3 c)^{-\\frac{1}{3\\nu - 1}}$\n3.  Blobs per chain: $\\frac{N}{g} = N (a^3 c)^{\\frac{1}{3\\nu - 1}}$\n\nThese results are general for the specified range of $\\nu$. For a good solvent, $\\nu \\approx 3/5$, which gives $3\\nu - 1 = 4/5$. The exponents become $\\xi \\sim c^{-3/4}$ and $g \\sim c^{-5/4}$. For a $\\theta$ solvent, $\\nu=1/2$, which gives $3\\nu - 1 = 1/2$. The exponents become $\\xi \\sim c^{-1}$ and $g \\sim c^{-2}$. These match the well-known results from polymer scaling theory.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\na (a^3 c)^{\\frac{-\\nu}{3\\nu-1}} & (a^3 c)^{\\frac{-1}{3\\nu-1}} & N (a^3 c)^{\\frac{1}{3\\nu-1}}\n\\end{pmatrix}\n}\n$$", "id": "3010784"}, {"introduction": "In a dense polymer melt, chains are heavily interpenetrated, leading to topological constraints known as entanglements, which govern the material's slow dynamics and viscoelastic properties. This computational exercise connects the microscopic picture of a chain's 'primitive path'—its shortest topological contour within the melt—to the macroscopic plateau modulus, a key quantity measured in rheology. By analyzing simulated data, you will estimate the entanglement length $N_e$ and validate the fundamental relationship between microscopic structure and bulk mechanical response. [@problem_id:3010808]", "problem": "You are provided with synthetic ensemble-averaged data extracted from molecular dynamics trajectories of monodisperse polymer melts. Each melt consists of chains with the same number of monomers $N$. For each melt, a standard primitive path analysis (PPA) algorithm has been applied to each stored snapshot to generate the primitive path length $L_{\\mathrm{pp}}$ for each chain while preserving topological constraints. Alongside, the mean-squared end-to-end distance $R^2$ of each chain in its original (pre-PPA) configuration is available. Your task is to use these data to estimate the entanglement length $N_e$ and to validate the result against independent rheological measurements of the plateau shear modulus $G_N^0$.\n\nFundamental base to use:\n- Gaussian chain statistics in melts: for a random walk with $n_K$ Kuhn segments of length $a$, the mean-squared end-to-end vector satisfies $R^2 = n_K a^2$ and the contour length is $L = n_K a$.\n- For the primitive path, define its Kuhn length $a_{\\mathrm{pp}}$ via $R^2 = a_{\\mathrm{pp}} L_{\\mathrm{pp}}$, which follows from Gaussian statistics at the coarse-grained primitive-path level.\n- The number of entanglement strands per chain $Z$ is identified with the number of Kuhn segments along the primitive path, $Z = L_{\\mathrm{pp}} / a_{\\mathrm{pp}}$.\n- The entanglement length is defined by $Z = N/N_e$.\n- The classical tube model (generalized rubber elasticity) connects the plateau shear modulus to the entanglement length by $G_N^0 = \\frac{4}{5}\\,\\rho_m k_B T \\, N_e^{-1}$, where $\\rho_m$ is the monomer number density, $k_B$ is the Boltzmann constant, and $T$ is the absolute temperature. Use $k_B = 1.380649\\times 10^{-23}\\,\\mathrm{J/K}$.\n\nTasks:\n1. For each melt, given time series of $R^2$ and $L_{\\mathrm{pp}}^2$ from the trajectory, compute the estimate of $N_e$ using only the fundamental base above. You must derive the working relation you use in your solution.\n2. Average appropriately over the provided snapshots to obtain a single $N_e$ per melt.\n3. Using the resulting $N_e$ and the provided $\\rho_m$ and $T$, compute the predicted plateau modulus $G_{N,\\mathrm{pred}}^0$ in $\\mathrm{Pa}$.\n4. Given a measured plateau modulus $G_{N,\\mathrm{meas}}^0$ in $\\mathrm{Pa}$, compute the relative error as the absolute difference divided by the measured value; report this as a decimal (not a percentage).\n\nInput data (test suite):\nFor each test case, you are given $N$, $\\rho_m$ in $\\mathrm{m}^{-3}$, $T$ in $\\mathrm{K}$, arrays of per-snapshot values for $R^2$ and $L_{\\mathrm{pp}}^2$, and $G_{N,\\mathrm{meas}}^0$ in $\\mathrm{Pa}$. Use these exact values in your program.\n\n- Test case A (typical entangled melt):\n  - $N = 500$\n  - $\\rho_m = 6.0\\times 10^{27}\\,\\mathrm{m}^{-3}$\n  - $T = 450\\,\\mathrm{K}$\n  - $R^2$ snapshots: $[3000, 3100, 2900, 3050, 2950]$\n  - $L_{\\mathrm{pp}}^2$ snapshots: $[30600, 30380, 29290, 30195, 29500]$\n  - $G_{N,\\mathrm{meas}}^0 = 5.95\\times 10^{5}\\,\\mathrm{Pa}$\n\n- Test case B (near the unentangled boundary, $Z\\approx 1$):\n  - $N = 20$\n  - $\\rho_m = 6.0\\times 10^{27}\\,\\mathrm{m}^{-3}$\n  - $T = 450\\,\\mathrm{K}$\n  - $R^2$ snapshots: $[100, 98, 103, 101]$\n  - $L_{\\mathrm{pp}}^2$ snapshots: $[102, 98, 106, 100]$\n  - $G_{N,\\mathrm{meas}}^0 = 1.50\\times 10^{6}\\,\\mathrm{Pa}$\n\n- Test case C (highly entangled melt):\n  - $N = 2000$\n  - $\\rho_m = 5.0\\times 10^{27}\\,\\mathrm{m}^{-3}$\n  - $T = 500\\,\\mathrm{K}$\n  - $R^2$ snapshots: $[12000, 11800, 12100, 11950, 12050]$\n  - $L_{\\mathrm{pp}}^2$ snapshots: $[606000, 584100, 617100, 597500, 608525]$\n  - $G_{N,\\mathrm{meas}}^0 = 6.95\\times 10^{5}\\,\\mathrm{Pa}$\n\nOutput requirements:\n- Physical unit: Report the predicted moduli $G_{N,\\mathrm{pred}}^0$ in $\\mathrm{Pa}$.\n- Angle units: Not applicable.\n- Percentages: Report the relative error as a decimal (for example, $0.032$), not with a percentage sign.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list of per-case results, with each per-case result itself being a three-element list of the form $[N_e, G_{N,\\mathrm{pred}}^0, \\mathrm{relative\\_error}]$. For example, the printed line must look like\n  \"[[Ne_caseA,Gpred_caseA,relerr_caseA],[Ne_caseB,Gpred_caseB,relerr_caseB],[Ne_caseC,Gpred_caseC,relerr_caseC]]\"\n  with the numeric values replacing the placeholders.\n\nDesign for coverage:\n- Test case A is a general \"happy path\" with moderate entanglement.\n- Test case B probes the boundary regime $Z\\approx 1$.\n- Test case C is a strongly entangled regime with large $Z$.\n\nYour program must be self-contained, must not read any external input, and must reproduce the results using the above constants and data exactly as specified.", "solution": "We begin from the fundamental statistical description of a Gaussian polymer chain in a melt. A Gaussian chain with $n_K$ Kuhn segments of length $a$ has mean-squared end-to-end distance $R^2 = n_K a^2$ and contour length $L = n_K a$. The primitive path is a coarse-grained representation obtained by primitive path analysis (PPA), which topologically constrains the chain while minimizing its contour. The primitive path is taken to obey Gaussian statistics at its coarse-grained scale. Denote the primitive path length by $L_{\\mathrm{pp}}$ and its Kuhn length by $a_{\\mathrm{pp}}$. By Gaussian statistics at this level,\n$$\nR^2 = n_{\\mathrm{pp}} a_{\\mathrm{pp}}^2, \\quad L_{\\mathrm{pp}} = n_{\\mathrm{pp}} a_{\\mathrm{pp}} \\quad \\Rightarrow \\quad R^2 = a_{\\mathrm{pp}} L_{\\mathrm{pp}}.\n$$\nSolving for $a_{\\mathrm{pp}}$ yields\n$$\na_{\\mathrm{pp}} = \\frac{R^2}{L_{\\mathrm{pp}}}.\n$$\nThe number of Kuhn segments along the primitive path is $n_{\\mathrm{pp}} = L_{\\mathrm{pp}}/a_{\\mathrm{pp}}$. In the tube model interpretation, the number of entanglement strands per chain $Z$ is identified with $n_{\\mathrm{pp}}$:\n$$\nZ = \\frac{L_{\\mathrm{pp}}}{a_{\\mathrm{pp}}} = \\frac{L_{\\mathrm{pp}}^2}{R^2}.\n$$\nBy definition, $Z = N / N_e$, where $N$ is the number of monomers per chain and $N_e$ is the entanglement length in monomers. Therefore,\n$$\n\\frac{N}{N_e} = \\frac{L_{\\mathrm{pp}}^2}{R^2} \\quad \\Rightarrow \\quad N_e = N \\frac{R^2}{L_{\\mathrm{pp}}^2}.\n$$\nGiven multiple snapshots (and potentially multiple chains), an unbiased estimator for $N_e$ is obtained by averaging the ratio $N R^2/L_{\\mathrm{pp}}^2$ over the ensemble. In practice, it is more stable to average the numerator and denominator separately and form the ratio of means, consistent with the definition of $a_{\\mathrm{pp}}$ at the ensemble level. Using the ensemble averages $\\langle R^2 \\rangle$ and $\\langle L_{\\mathrm{pp}}^2 \\rangle$, we use\n$$\nN_e = N \\frac{\\langle R^2 \\rangle}{\\langle L_{\\mathrm{pp}}^2 \\rangle}.\n$$\n\nTo validate against rheology, we use the well-tested relation from the classical tube model (generalized rubber elasticity) for the plateau shear modulus:\n$$\nG_N^0 = \\frac{4}{5}\\,\\rho_m k_B T \\frac{1}{N_e},\n$$\nwhere $\\rho_m$ is the monomer number density, $k_B$ is the Boltzmann constant, and $T$ is the absolute temperature. The factor $\\frac{4}{5}$ accounts for the constraint release and slip-link corrections in the entanglement network compared to an ideal phantom network.\n\nAlgorithmic steps for each test case:\n1. Read $N$, $\\rho_m$, $T$, an array of $R^2$ snapshot values $\\{R^2_s\\}$, and an array of $L_{\\mathrm{pp}}^2$ snapshot values $\\{L_{\\mathrm{pp},s}^2\\}$, plus the measured plateau modulus $G_{N,\\mathrm{meas}}^0$.\n2. Compute ensemble means\n$$\n\\langle R^2 \\rangle = \\frac{1}{S}\\sum_{s=1}^{S} R^2_s, \\quad \\langle L_{\\mathrm{pp}}^2 \\rangle = \\frac{1}{S}\\sum_{s=1}^{S} L_{\\mathrm{pp},s}^2,\n$$\nwhere $S$ is the number of snapshots provided.\n3. Compute\n$$\nN_e = N \\frac{\\langle R^2 \\rangle}{\\langle L_{\\mathrm{pp}}^2 \\rangle}.\n$$\n4. Compute the predicted plateau modulus\n$$\nG_{N,\\mathrm{pred}}^0 = \\frac{4}{5}\\,\\rho_m k_B T \\frac{1}{N_e}.\n$$\n5. Compute the relative error (as a decimal, not a percentage)\n$$\n\\mathrm{relative\\ error} = \\frac{\\left|G_{N,\\mathrm{pred}}^0 - G_{N,\\mathrm{meas}}^0\\right|}{G_{N,\\mathrm{meas}}^0}.\n$$\n6. Report the triple $[N_e, G_{N,\\mathrm{pred}}^0, \\mathrm{relative\\ error}]$ for each test case.\n\nEdge and boundary considerations:\n- If $\\langle L_{\\mathrm{pp}}^2 \\rangle \\approx \\langle R^2 \\rangle$, then $Z \\approx 1$ and $N_e \\approx N$, corresponding to the boundary of entanglement onset. This is explicitly tested in the second case.\n- The strongly entangled regime has $\\langle L_{\\mathrm{pp}}^2 \\rangle \\gg \\langle R^2 \\rangle$, resulting in $N_e \\ll N$, as in the third case.\n- All provided arrays have strictly positive values, making the estimator well-defined.\n\nFinally, using the provided numerical values in the test suite, the program computes the requested outputs for all cases and prints them in a single line as a list of three-element lists, with $G_{N,\\mathrm{pred}}^0$ in $\\mathrm{Pa}$ and the relative error as a decimal.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    k_B = 1.380649e-23  # J/K\n\n    # Define the test cases from the problem statement.\n    # Each case: (N, rho_m [1/m^3], T [K], R2_list, Lpp2_list, G_meas [Pa])\n    test_cases = [\n        (\n            500,\n            6.0e27,\n            450.0,\n            [3000.0, 3100.0, 2900.0, 3050.0, 2950.0],\n            [30600.0, 30380.0, 29290.0, 30195.0, 29500.0],\n            5.95e5\n        ),\n        (\n            20,\n            6.0e27,\n            450.0,\n            [100.0, 98.0, 103.0, 101.0],\n            [102.0, 98.0, 106.0, 100.0],\n            1.50e6\n        ),\n        (\n            2000,\n            5.0e27,\n            500.0,\n            [12000.0, 11800.0, 12100.0, 11950.0, 12050.0],\n            [606000.0, 584100.0, 617100.0, 597500.0, 608525.0],\n            6.95e5\n        ),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, rho_m, T, R2_list, Lpp2_list, G_meas = case\n\n        R2_arr = np.array(R2_list, dtype=float)\n        Lpp2_arr = np.array(Lpp2_list, dtype=float)\n\n        mean_R2 = float(np.mean(R2_arr))\n        mean_Lpp2 = float(np.mean(Lpp2_arr))\n\n        Ne_est = N * mean_R2 / mean_Lpp2\n\n        # Predicted plateau modulus: G_N^0 = (4/5) * rho_m * k_B * T / Ne\n        G_pred = (4.0/5.0) * rho_m * k_B * T / Ne_est\n\n        # Relative error versus measured\n        rel_err = abs(G_pred - G_meas) / G_meas\n\n        results.append([Ne_est, G_pred, rel_err])\n\n    # Final print statement in the exact required format.\n    # Print as a single line list of lists with numeric values.\n    print(f\"[{','.join(str(item) for item in results)}]\")\n\nsolve()\n```", "id": "3010808"}]}