{"hands_on_practices": [{"introduction": "The concept of a \"jammed\" state, while intuitive, has a precise mechanical definition rooted in linear stability analysis. This foundational exercise guides you through the process of translating this definition into a concrete computational algorithm. You will construct the compatibility matrix $A$ and the Hessian matrix $H$ from first principles for simple central-force networks, providing the essential link between particle positions and the system's potential energy landscape [@problem_id:2997429]. By analyzing the null space of the Hessian, you will learn to rigorously distinguish between under-constrained (floppy) and rigid systems, mastering a fundamental skill for studying amorphous materials.", "problem": "Consider a finite set of $N$ point particles in spatial dimension $d$ with positions $\\{\\mathbf{r}_i\\}_{i=1}^N$, where $\\mathbf{r}_i \\in \\mathbb{R}^d$. Suppose particles interact via frictionless, central-force contacts along specified pairs $(i,j)$, each acting as a linear spring of stiffness $k$ that resists only changes in the separation along the line joining the two particles. Assume small displacements $\\{\\mathbf{u}_i\\}_{i=1}^N$ from the reference positions and zero temperature. The fundamental basis for the problem is the combination of Hooke’s law for linear springs and Newton’s second law, leading to linear elasticity in the small-displacement limit.\n\nFor a contact between particles $i$ and $j$, define the unit normal $\\mathbf{n}_{ij}$ along the line from $i$ to $j$ in the reference configuration. The linearized extension of this contact under displacements is the projection of the relative displacement onto $\\mathbf{n}_{ij}$. The total quadratic energy can be written as a sum of squared extensions weighted by $k$. The linear mapping from particle displacements to contact extensions is represented by the compatibility matrix, and the quadratic energy is represented by the Hessian (also known as the dynamical matrix). Mechanical stability in the linear regime is determined by the positive semidefiniteness of the Hessian and the absence of nontrivial floppy modes.\n\nDefine the following quantities:\n- Degrees of Freedom (DOF): $dN$.\n- Number of contacts: $M$.\n- Rigid-body zero modes for free boundary conditions: $d(d+1)/2$, consisting of $d$ global translations and $d(d-1)/2$ global rotations.\n- States of Self-Stress (SSS): independent solutions of contact force balance with zero net force on each particle that do not change extensions.\n\nA configuration is deemed jammed if, in the linearized regime:\n- The Hessian is positive semidefinite.\n- The nullity (number of zero eigenvalues) of the Hessian equals the rigid-body count $d(d+1)/2$, meaning there are no floppy modes beyond global translations and rotations.\n- The contact count satisfies the Maxwell criterion $M \\ge dN - d(d+1)/2$.\n\nYour task is to construct the compatibility matrix and Hessian from first principles for central-force, frictionless contacts, and evaluate whether each provided configuration is jammed according to the above definition. Use the following test suite of configurations, with positions in dimensionless units and $k = 1$:\n\nTest case $1$ (two-dimensional triangle, isostatic):\n- $d = 2$, $N = 3$.\n- Positions: $\\mathbf{r}_1 = (0,0)$, $\\mathbf{r}_2 = (1,0)$, $\\mathbf{r}_3 = (0.3,0.8)$.\n- Contacts: $(1,2)$, $(2,3)$, $(3,1)$.\n- $M = 3$.\n\nTest case $2$ (two-dimensional square, underconstrained):\n- $d = 2$, $N = 4$.\n- Positions: $\\mathbf{r}_1 = (0,0)$, $\\mathbf{r}_2 = (1,0)$, $\\mathbf{r}_3 = (1,1)$, $\\mathbf{r}_4 = (0,1)$.\n- Contacts: $(1,2)$, $(2,3)$, $(3,4)$, $(4,1)$.\n- $M = 4$.\n\nTest case $3$ (two-dimensional square with one diagonal, isostatic):\n- $d = 2$, $N = 4$.\n- Positions: $\\mathbf{r}_1 = (0,0)$, $\\mathbf{r}_2 = (1,0)$, $\\mathbf{r}_3 = (1,1)$, $\\mathbf{r}_4 = (0,1)$.\n- Contacts: $(1,2)$, $(2,3)$, $(3,4)$, $(4,1)$, $(1,3)$.\n- $M = 5$.\n\nTest case $4$ (three-dimensional tetrahedron, isostatic):\n- $d = 3$, $N = 4$.\n- Positions: $\\mathbf{r}_1 = (0,0,0)$, $\\mathbf{r}_2 = (1,0,0)$, $\\mathbf{r}_3 = (0.2,0.9,0)$, $\\mathbf{r}_4 = (0.3,0.2,0.8)$.\n- Contacts: $(1,2)$, $(1,3)$, $(1,4)$, $(2,3)$, $(2,4)$, $(3,4)$.\n- $M = 6$.\n\nTest case $5$ (three-dimensional, underconstrained network):\n- $d = 3$, $N = 5$.\n- Positions: $\\mathbf{r}_1 = (0,0,0)$, $\\mathbf{r}_2 = (1,0,0)$, $\\mathbf{r}_3 = (2,0,0)$, $\\mathbf{r}_4 = (0.5,0.8,0)$, $\\mathbf{r}_5 = (1.5,0.8,0.1)$.\n- Contacts: $(1,2)$, $(2,3)$, $(4,5)$, $(2,4)$, $(3,5)$.\n- $M = 5$.\n\nImplementation requirements:\n- Construct the compatibility matrix $A$ of size $M \\times dN$ as follows: for each contact $(i,j)$, compute the unit normal $\\mathbf{n}_{ij}$ from $\\mathbf{r}_i$ to $\\mathbf{r}_j$; the corresponding row in $A$ has entries $+\\mathbf{n}_{ij}$ in the block for particle $i$ and entries $-\\mathbf{n}_{ij}$ in the block for particle $j$, with zeros elsewhere.\n- Construct the Hessian $H$ as $H = A^\\top A$ (taking spring stiffness $k = 1$).\n- Compute the eigenvalues of $H$ and count how many are zero up to a numerical tolerance. Choose a tolerance that scales with the largest eigenvalue to remain dimensionless and robust.\n- Decide jammed status per test case as a boolean by checking the three conditions above.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, `[`result1`,`result2`,`result3`,`result4`,`result5`]`, where each result is a boolean `True` or `False` for the corresponding test case.", "solution": "The problem requires an evaluation of the mechanical stability of several particulate systems, specifically to determine if they are in a \"jammed\" state. A jammed state, in this context, is a specific form of mechanical rigidity at the level of linear response to small perturbations. The solution involves constructing the appropriate mathematical objects from first principles of linear elasticity and then testing them against the provided criteria for jamming.\n\nThe physical model consists of $N$ point particles in $d$-dimensional Euclidean space, interacting via $M$ central-force springs. The total potential energy $E$ of the system is the sum of the energies stored in each spring. For a linear spring of stiffness $k$, the energy is quadratic in its extension or compression. Let $\\delta l_c$ be the change in length of the spring corresponding to contact $c$. The total energy is:\n$$E = \\frac{k}{2} \\sum_{c=1}^{M} (\\delta l_c)^2$$\nWe consider small displacements $\\{\\mathbf{u}_i\\}_{i=1}^N$ of each particle $i$ from its reference position $\\mathbf{r}_i$. The new position is $\\mathbf{r}'_i = \\mathbf{r}_i + \\mathbf{u}_i$. For a contact between particles $i$ and $j$, the change in length $\\delta l_{ij}$ is $\\lvert \\mathbf{r}'_j - \\mathbf{r}'_i \\rvert - \\lvert \\mathbf{r}_j - \\mathbf{r}_i \\rvert$. In the limit of small displacements, this can be linearized. Letting $\\mathbf{u}_{ij} = \\mathbf{u}_j - \\mathbf{u}_i$ and $\\mathbf{n}_{ij} = (\\mathbf{r}_j - \\mathbf{r}_i) / \\lvert \\mathbf{r}_j - \\mathbf{r}_i \\rvert$ be the unit vector along the contact, the linearized extension is:\n$$\\delta l_{ij} \\approx \\mathbf{u}_{ij} \\cdot \\mathbf{n}_{ij} = (\\mathbf{u}_j - \\mathbf{u}_i) \\cdot \\mathbf{n}_{ij}$$\nThis relationship can be expressed in matrix form. Let $\\mathbf{U}$ be the $dN \\times 1$ column vector that concatenates all particle displacement vectors: $\\mathbf{U} = (\\mathbf{u}_1^T, \\mathbf{u}_2^T, \\dots, \\mathbf{u}_N^T)^T$. Let $\\mathbf{e}$ be the $M \\times 1$ column vector of all contact extensions $\\delta l_c$. The linear relationship between them is $\\mathbf{e} = A \\mathbf{U}$, where $A$ is the $M \\times dN$ compatibility matrix. According to the problem's specified convention, for a contact $(i, j)$, the corresponding row of $A$ contains the vector component entries of $+\\mathbf{n}_{ij}$ in the $d$-dimensional block for particle $i$ and $-\\mathbf{n}_{ij}$ in the block for particle $j$. This convention yields an extension vector whose sign is opposite to the standard derivation, but since the energy depends on the square of the extensions, this choice is immaterial for the stability analysis.\n\nWith this matrix formulation, the total potential energy is:\n$$E = \\frac{k}{2} \\mathbf{e}^T \\mathbf{e} = \\frac{k}{2} (A \\mathbf{U})^T (A \\mathbf{U}) = \\frac{1}{2} \\mathbf{U}^T (k A^T A) \\mathbf{U}$$\nThe Hessian matrix, $H$, represents the quadratic form of the energy and is defined by $E = \\frac{1}{2} \\mathbf{U}^T H \\mathbf{U}$. Therefore, $H = k A^T A$. Since the problem specifies $k=1$, the Hessian is simply $H = A^T A$.\n\nA configuration is defined as jammed if it satisfies three conditions:\n1.  The Hessian $H$ is positive semidefinite. By construction, $H = A^T A$ is always positive semidefinite for any real matrix $A$, as for any vector $\\mathbf{U}$, $\\mathbf{U}^T H \\mathbfU = \\mathbf{U}^T A^T A \\mathbf{U} = (A \\mathbf{U})^T (A \\mathbf{U}) = \\lVert A \\mathbf{U} \\rVert^2 \\ge 0$. This condition is therefore automatically satisfied.\n2.  The number of contacts $M$ must satisfy the Maxwell criterion for stability, $M \\geq dN - N_{rb}$. Here, $N_{rb} = d(d+1)/2$ is the number of rigid-body modes of motion (translations and rotations) for free boundary conditions, which do not stretch any contacts. This is a counting argument comparing degrees of freedom ($dN$) with the number of constraints ($M$).\n3.  The structure must be mechanically rigid, aside from the global rigid-body motions. This means there are no \"floppy modes\" (internal mechanisms or non-trivial zero-energy deformations). The null space of the Hessian $H$ corresponds to all zero-energy displacement modes. For a rigid structure, these modes must be spanned exclusively by the rigid-body motions. Therefore, the nullity of $H$ (the dimension of its null space, or the number of its zero eigenvalues) must be exactly equal to $N_{rb}$.\n\nThe algorithmic procedure to determine if a configuration is jammed is as follows:\nFirst, for a given test case with parameters $d$, $N$, particle positions $\\{\\mathbf{r}_i\\}$, and contacts, we compute the number of contacts $M$ and the number of required rigid-body modes $N_{rb} = d(d+1)/2$.\nSecond, we check the Maxwell criterion: $M \\geq dN - N_{rb}$. If this is not met, the system is not jammed.\nThird, if the Maxwell criterion is met, we proceed to construct the $M \\times dN$ compatibility matrix $A$ according to the rules.\nFourth, we compute the $dN \\times dN$ Hessian matrix $H=A^T A$.\nFifth, we compute the eigenvalues of $H$. Since $H$ is a real, symmetric, and positive-semidefinite matrix, all its eigenvalues are real and non-negative.\nSixth, we count the number of eigenvalues that are zero, using a small numerical tolerance (e.g., $10^{-9}$) to account for floating-point inaccuracies. Let this count be $N_{zero}$.\nFinally, we check the nullity condition: $N_{zero} = N_{rb}$. The configuration is jammed if and only if both the Maxwell criterion and this nullity condition are satisfied.\n\nThis procedure is systematically applied to each test case provided.", "answer": "```python\nimport numpy as np\n\ndef check_jamming(d, N, positions, contacts):\n    \"\"\"\n    Checks if a configuration of particles is jammed based on linear stability analysis.\n\n    Args:\n        d (int): The spatial dimension.\n        N (int): The number of particles.\n        positions (np.ndarray): An N x d array of particle positions.\n        contacts (list of tuple): A list of (i, j) tuples representing contacts,\n                                  using 1-based indexing.\n\n    Returns:\n        bool: True if the configuration is jammed, False otherwise.\n    \"\"\"\n    M = len(contacts)\n    dN = d * N\n\n    # Condition 1: Maxwell criterion\n    num_rigid_body_modes = d * (d + 1) // 2\n    maxwell_count = dN - num_rigid_body_modes\n    is_maxwell = (M = maxwell_count)\n\n    # If Maxwell criterion is not met, the system cannot be jammed.\n    if not is_maxwell:\n        return False\n\n    # Construct the compatibility matrix A (size M x dN)\n    A = np.zeros((M, dN))\n\n    for k, (i_raw, j_raw) in enumerate(contacts):\n        # Convert from 1-based to 0-based indexing\n        i, j = i_raw - 1, j_raw - 1\n\n        r_i = positions[i]\n        r_j = positions[j]\n\n        r_ij = r_j - r_i\n        dist = np.linalg.norm(r_ij)\n\n        # Handle the unlikely case of overlapping particles\n        if dist  1e-12:\n            return False\n\n        n_ij = r_ij / dist\n        \n        # Populate the k-th row of A according to the problem statement:\n        # +n_ij in block for particle i, -n_ij in block for particle j\n        A[k, i * d : (i + 1) * d] = n_ij\n        A[k, j * d : (j + 1) * d] = -n_ij\n\n    # Construct the Hessian matrix H (size dN x dN)\n    # H = A^T A, with spring constant k=1\n    H = A.T @ A\n\n    # Compute eigenvalues of H. eigvalsh is efficient for real symmetric matrices.\n    eigenvalues = np.linalg.eigvalsh(H)\n\n    # Condition 2: Nullity of Hessian\n    # Count the number of zero eigenvalues within a numerical tolerance.\n    # The eigenvalues are non-negative, so we check for eigenvalues  tol.\n    tolerance = 1e-9\n    num_zero_modes = np.sum(eigenvalues  tolerance)\n    \n    is_rigid = (num_zero_modes == num_rigid_body_modes)\n\n    # A configuration is jammed if both Maxwell and rigidity conditions are met.\n    # The positive-semidefinite condition is met by construction.\n    is_jammed = is_maxwell and is_rigid\n\n    return is_jammed\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (two-dimensional triangle, isostatic)\n        {\n            \"d\": 2, \"N\": 3,\n            \"positions\": np.array([[0.0, 0.0], [1.0, 0.0], [0.3, 0.8]]),\n            \"contacts\": [(1, 2), (2, 3), (3, 1)]\n        },\n        # Test case 2 (two-dimensional square, underconstrained)\n        {\n            \"d\": 2, \"N\": 4,\n            \"positions\": np.array([[0.0, 0.0], [1.0, 0.0], [1.0, 1.0], [0.0, 1.0]]),\n            \"contacts\": [(1, 2), (2, 3), (3, 4), (4, 1)]\n        },\n        # Test case 3 (two-dimensional square with one diagonal, isostatic)\n        {\n            \"d\": 2, \"N\": 4,\n            \"positions\": np.array([[0.0, 0.0], [1.0, 0.0], [1.0, 1.0], [0.0, 1.0]]),\n            \"contacts\": [(1, 2), (2, 3), (3, 4), (4, 1), (1, 3)]\n        },\n        # Test case 4 (three-dimensional tetrahedron, isostatic)\n        {\n            \"d\": 3, \"N\": 4,\n            \"positions\": np.array([[0.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.2, 0.9, 0.0], [0.3, 0.2, 0.8]]),\n            \"contacts\": [(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n        },\n        # Test case 5 (three-dimensional, underconstrained network)\n        {\n            \"d\": 3, \"N\": 5,\n            \"positions\": np.array([[0.0, 0.0, 0.0], [1.0, 0.0, 0.0], [2.0, 0.0, 0.0], [0.5, 0.8, 0.0], [1.5, 0.8, 0.1]]),\n            \"contacts\": [(1, 2), (2, 3), (4, 5), (2, 4), (3, 5)]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = check_jamming(\n            d=case[\"d\"],\n            N=case[\"N\"],\n            positions=case[\"positions\"],\n            contacts=case[\"contacts\"]\n        )\n        results.append(result)\n\n    # Print results in the specified format: [True,False,...]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2997429"}, {"introduction": "Building on the static stability analysis, we now explore the dynamic consequences of a network's structure. The Hessian matrix not only determines rigidity but also governs the system's vibrational dynamics, where its eigenvalues correspond to the squared frequencies $\\omega^2$ of the normal modes. This practice delves into the concept of \"soft modes\"—anomalously low-frequency vibrations that are characteristic of disordered solids near the jamming transition—and connects them to the Maxwell criterion and the principle of marginal stability [@problem_id:2997433]. By computationally verifying how the removal of a single contact can induce a floppy mode in an isostatic network, you will gain direct insight into the delicate, on-the-edge-of-instability nature of marginally jammed materials.", "problem": "Consider a network of $N$ point particles in $d$ spatial dimensions with unit mass $m=1$ and central harmonic contacts of unit stiffness $k=1$ along an undirected graph of contacts. Let $\\mathbf{r}_i \\in \\mathbb{R}^d$ denote the equilibrium position of particle $i$, and let $\\mathbf{u}_i \\in \\mathbb{R}^d$ denote its small displacement. For a contact $(i,j)$, define the contact unit vector $\\hat{\\mathbf{e}}_{ij} = (\\mathbf{r}_i - \\mathbf{r}_j)/\\|\\mathbf{r}_i - \\mathbf{r}_j\\|$. In the harmonic approximation, the potential energy is\n$$\nE = \\frac{k}{2}\\sum_{(i,j)} \\left[\\hat{\\mathbf{e}}_{ij}\\cdot(\\mathbf{u}_i - \\mathbf{u}_j)\\right]^2.\n$$\nThis quadratic energy defines the Hessian matrix $H$ of size $dN \\times dN$ such that the normal mode equation is $H\\mathbf{v} = \\omega^2 \\mathbf{v}$, where $\\omega$ is the angular frequency and $\\mathbf{v}$ is the mode vector. The eigenvalues $\\lambda$ of $H$ satisfy $\\lambda = \\omega^2$ and have units of $k/m$; with $k=1$ and $m=1$, $\\omega$ is in $\\text{s}^{-1}$.\n\nSoft modes are defined as eigenvectors associated with eigenvalues $\\lambda$ that are effectively zero within a numerical tolerance. In free-floating networks of central forces, there are $d(d+1)/2$ trivial rigid-body modes (uniform translations and rotations) that always yield zero eigenvalues. Floppy modes are additional zero modes beyond these trivial ones. The Maxwell count gives the predicted number of floppy modes:\n$$\nF_{\\text{Maxwell}} = dN - N_c - \\frac{d(d+1)}{2},\n$$\nwhere $N_c$ is the number of contacts. A network is isostatic when $F_{\\text{Maxwell}} = 0$; such networks at the threshold of rigidity are marginally stable: removing any single contact produces at least one floppy mode. In jamming transitions of frictionless amorphous materials, marginal stability is associated with an average coordination approaching $z = 2d$ as $N\\to\\infty$, where\n$$\nz = \\frac{2N_c}{N}.\n$$\n\nYour task is to implement the following, starting only from the physical definitions above and basic linear algebra:\n\n1. Construct $H$ by assembling the $d\\times d$ rank-one projector $k\\,\\hat{\\mathbf{e}}_{ij}\\hat{\\mathbf{e}}_{ij}^\\top$ on the blocks corresponding to particles $i$ and $j$ for each contact $(i,j)$, with the standard form that reflects the quadratic energy in the displacements:\n   - Add $k\\,\\hat{\\mathbf{e}}_{ij}\\hat{\\mathbf{e}}_{ij}^\\top$ to the $(i,i)$ block.\n   - Add $k\\,\\hat{\\mathbf{e}}_{ij}\\hat{\\mathbf{e}}_{ij}^\\top$ to the $(j,j)$ block.\n   - Add $-k\\,\\hat{\\mathbf{e}}_{ij}\\hat{\\mathbf{e}}_{ij}^\\top$ to the $(i,j)$ block.\n   - Add $-k\\,\\hat{\\mathbf{e}}_{ij}\\hat{\\mathbf{e}}_{ij}^\\top$ to the $(j,i)$ block.\n2. Compute all eigenvalues of $H$ and identify soft modes using a numerical threshold $\\varepsilon = 10^{-9}$ in units of $k/m$. Define the integer $n_{\\text{soft}}$ as the number of eigenvalues $\\lambda \\le \\varepsilon$ beyond the $d(d+1)/2$ trivial rigid-body zero modes.\n3. Define the minimal nonzero angular frequency $\\omega_{\\min}$ as $\\sqrt{\\lambda_{\\min}}$, where $\\lambda_{\\min}$ is the smallest eigenvalue strictly greater than $\\varepsilon$. Express $\\omega_{\\min}$ in $\\text{s}^{-1}$.\n4. Define a boolean $b_{\\text{marginal}}$ that is true if and only if:\n   - The Maxwell count yields $F_{\\text{Maxwell}} = 0$, and\n   - Upon removing one contact (specifically, the last contact in the deterministic construction order specified below), the number of soft modes increases by at least one (i.e., at least one additional eigenvalue falls below $\\varepsilon$ beyond the trivial rigid-body modes).\n\nNetwork construction protocol (deterministic and physically plausible):\n- Work in $d=2$.\n- Generate $\\mathbf{r}_i$ by sampling $N$ points uniformly in the unit square $[0,1]^2$ using the specified pseudorandom seeds for reproducibility.\n- Build a connected spanning tree by sequentially connecting each new particle $t$ ($t=1,\\dots,N-1$) to the nearest previously added particle $j\\in\\{0,\\dots,t-1\\}$ in Euclidean distance.\n- Compute all remaining pairwise distances for unordered pairs $(i,j)$ with $0 \\le i  j  N$ not already in the edge set, sort these pairs by increasing distance, and add contacts in that order until the target $N_c$ is reached. The deterministic construction order is the spanning tree edges in the sequence they were added, followed by the sorted-by-distance added edges. The “last contact” mentioned above is the last contact in this final ordered list.\n\nTest suite:\n- Case 1 (hypostatic): $N=30$, $d=2$, seed $=123$, target $N_c = dN - \\frac{d(d+1)}{2} - 4 = 53$.\n- Case 2 (isostatic/marginal candidate): $N=30$, $d=2$, seed $=456$, target $N_c = dN - \\frac{d(d+1)}{2} = 57$.\n- Case 3 (hyperstatic): $N=30$, $d=2$, seed $=789$, target $N_c = 70$.\n\nYour program must output, for each case, the list $[n_{\\text{soft}}, \\omega_{\\min}, b_{\\text{marginal}}]$, and aggregate the three case results into a single line of output as a comma-separated list enclosed in square brackets, with no spaces, in the form\n$$\n[[n_{\\text{soft}}^{(1)},\\omega_{\\min}^{(1)},b_{\\text{marginal}}^{(1)}],[n_{\\text{soft}}^{(2)},\\omega_{\\min}^{(2)},b_{\\text{marginal}}^{(2)}],[n_{\\text{soft}}^{(3)},\\omega_{\\min}^{(3)},b_{\\text{marginal}}^{(3)}]].\n$$\nAngular frequencies must be reported in $\\text{s}^{-1}$. All outputs must be computed using the construction protocol and definitions provided, with $\\varepsilon = 10^{-9}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., `[[1,0.123,True],[0,0.456,False],[2,0.078,False]]`). No input is provided; all parameters are defined above.", "solution": "The goal is to connect soft modes and marginal stability at the jamming threshold to first principles of harmonic networks. We begin from the quadratic form of the energy for central-force contacts. For small displacements, Hooke’s law implies that only the longitudinal component of relative motion along a contact contributes to energy; transverse motion does not change the bond length to linear order. For a single contact $(i,j)$ with unit vector $\\hat{\\mathbf{e}}_{ij}$ along the bond, the energy contribution is\n$$\nE_{ij} = \\frac{k}{2}\\left[\\hat{\\mathbf{e}}_{ij}\\cdot(\\mathbf{u}_i - \\mathbf{u}_j)\\right]^2,\n$$\nwhich is a rank-one quadratic form in the displacement difference. Summing over contacts yields\n$$\nE = \\frac{1}{2}\\sum_{(i,j)} \\left(\\mathbf{u}^\\top P_{ij}\\mathbf{u}\\right),\\quad P_{ij} = k\\,\\mathbf{B}_{ij},\\quad \\mathbf{B}_{ij} \\text{ assembled from } \\hat{\\mathbf{e}}_{ij}\\hat{\\mathbf{e}}_{ij}^\\top,\n$$\nwhere $\\mathbf{u}$ stacks all particle displacements into a vector in $\\mathbb{R}^{dN}$. The Hessian $H$ is the sum of the $P_{ij}$ operators. For a contact $(i,j)$, the contributions to block entries are:\n- $(i,i)$ block: $k\\,\\hat{\\mathbf{e}}_{ij}\\hat{\\mathbf{e}}_{ij}^\\top$,\n- $(j,j)$ block: $k\\,\\hat{\\mathbf{e}}_{ij}\\hat{\\mathbf{e}}_{ij}^\\top$,\n- $(i,j)$ block: $-k\\,\\hat{\\mathbf{e}}_{ij}\\hat{\\mathbf{e}}_{ij}^\\top$,\n- $(j,i)$ block: $-k\\,\\hat{\\mathbf{e}}_{ij}\\hat{\\mathbf{e}}_{ij}^\\top$.\n\nThis $H$ is symmetric and positive semidefinite. With unit mass $m=1$, the normal modes satisfy\n$$\nH\\mathbf{v} = \\omega^2 \\mathbf{v},\n$$\nand the eigenvalues are $\\lambda = \\omega^2$ with units $k/m$. In a free-floating central-force network, there are $d(d+1)/2$ trivial zero modes from rigid-body motions (translations and rotations). Any additional eigenvalues at or below a small threshold $\\varepsilon$ represent floppy soft modes beyond trivial rigid-body motions. We choose a numerical tolerance $\\varepsilon = 10^{-9}$, so we define\n$$\nn_{\\text{soft}} = \\max\\left(0,\\#\\{\\lambda \\mid \\lambda \\le \\varepsilon\\} - \\frac{d(d+1)}{2}\\right).\n$$\nWe define the minimal nonzero angular frequency by selecting the smallest eigenvalue strictly greater than $\\varepsilon$, denoted $\\lambda_{\\min}$, and computing\n$$\n\\omega_{\\min} = \\sqrt{\\lambda_{\\min}}.\n$$\nWe express $\\omega_{\\min}$ in $\\text{s}^{-1}$ since $k=1$ and $m=1$.\n\nMarginal stability connects to isostaticity. The Maxwell count predicts the number of floppy modes:\n$$\nF_{\\text{Maxwell}} = dN - N_c - \\frac{d(d+1)}{2}.\n$$\nThe isostatic condition is $F_{\\text{Maxwell}} = 0$. A marginally stable network is minimally rigid: removing any single contact produces a floppy mode, i.e., at least one additional soft mode appears. Therefore, we define the boolean\n$$\nb_{\\text{marginal}} = \\left(F_{\\text{Maxwell}} = 0\\right)\\ \\wedge\\ \\left(n_{\\text{soft}}^{\\text{(after removing one contact)}} \\ge n_{\\text{soft}} + 1\\right),\n$$\nwhere we remove the last contact in the deterministic construction order to ensure reproducibility.\n\nTo construct physically plausible contact graphs without special degeneracies, we use a deterministic protocol:\n1. Sample $N$ positions $\\{\\mathbf{r}_i\\}$ uniformly in $[0,1]^2$ using a fixed seed. This controls randomness and reproducibility.\n2. Build a connected spanning tree: for each particle $t$ from $1$ to $N-1$, connect it to the nearest previously added particle $j \\in \\{0,\\dots,t-1\\}$ based on Euclidean distance. This ensures the network is connected with $N-1$ edges.\n3. Compute all remaining pairwise distances for pairs not yet connected, sort ascending, and add edges until the target number of contacts $N_c$ is reached. The resulting construction order is the sequence of spanning-tree edges followed by sorted-by-distance added edges.\n4. Assemble $H$ according to the rank-one projector rule for each contact, with $k=1$. Then compute all eigenvalues using a symmetric eigensolver.\n5. Identify soft modes by counting eigenvalues $\\le \\varepsilon$, subtract $d(d+1)/2$ trivial rigid modes, and compute $n_{\\text{soft}}$. Compute $\\omega_{\\min}$ as the square root of the smallest eigenvalue $\\varepsilon$.\n6. For $b_{\\text{marginal}}$, evaluate $F_{\\text{Maxwell}}$. If $F_{\\text{Maxwell}}=0$, remove the last contact in the construction order, rebuild $H$, recompute the soft mode count, and check whether it increases by at least $1$.\n\nThe test suite probes distinct regimes:\n- Hypostatic ($N_c$ below isostatic): We expect $F_{\\text{Maxwell}}  0$, additional soft modes, and non-marginality.\n- Isostatic (candidate for marginal stability): $F_{\\text{Maxwell}} = 0$, zero extra floppy modes initially, and removing one contact should produce at least one additional soft mode, indicating marginal stability.\n- Hyperstatic ($N_c$ above isostatic): Redundant constraints yield a strictly positive spectrum above the trivial zero modes, and removing one contact typically does not create floppy modes; non-marginal.\n\nParameters and units:\n- $d=2$, $k=1$ (newton per meter), $m=1$ (kilogram), so $\\omega$ is reported in $\\text{s}^{-1}$.\n- Numerical tolerance $\\varepsilon = 10^{-9}$ in units of $k/m$ for eigenvalues.\n\nFinal output specification:\nFor each case, produce $[n_{\\text{soft}}, \\omega_{\\min}, b_{\\text{marginal}}]$ and aggregate the three case results into a single line with no spaces, as\n$$\n[[n_{\\text{soft}}^{(1)},\\omega_{\\min}^{(1)},b_{\\text{marginal}}^{(1)}],[n_{\\text{soft}}^{(2)},\\omega_{\\min}^{(2)},b_{\\text{marginal}}^{(2)}],[n_{\\text{soft}}^{(3)},\\omega_{\\min}^{(3)},b_{\\text{marginal}}^{(3)}]].\n$$\nThis procedure embodies soft modes and marginal stability from first principles of harmonic central-force networks and allows algorithmic verification via the eigen-spectrum of the Hessian and the Maxwell count.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_positions(N, seed):\n    rng = np.random.RandomState(seed)\n    # Uniform positions in [0,1]^2\n    pos = rng.rand(N, 2)\n    return pos\n\ndef build_spanning_tree_edges(positions):\n    N = positions.shape[0]\n    edges = []\n    # Connect each node t to the nearest previous node\n    for t in range(1, N):\n        prev_indices = np.arange(0, t)\n        diffs = positions[prev_indices] - positions[t]\n        dists = np.linalg.norm(diffs, axis=1)\n        j = prev_indices[np.argmin(dists)]\n        edges.append((t, j))\n    return edges\n\ndef build_full_edge_set(positions, target_nc):\n    N = positions.shape[0]\n    # Start with a connected spanning tree\n    edges = build_spanning_tree_edges(positions)\n    existing = set()\n    for (i, j) in edges:\n        if i  j:\n            i, j = j, i\n        existing.add((i, j))\n    current_nc = len(edges)\n    if current_nc  target_nc:\n        # Should not happen with construction, but guard\n        return edges[:target_nc]\n    # Generate all remaining pairs and sort by distance\n    pairs = []\n    for i in range(N):\n        for j in range(i+1, N):\n            if (i, j) not in existing:\n                d = np.linalg.norm(positions[i] - positions[j])\n                pairs.append((d, i, j))\n    pairs.sort(key=lambda x: x[0])  # sort by ascending distance\n    # Add edges until reaching target_nc\n    k = 0\n    while current_nc  target_nc and k  len(pairs):\n        _, i, j = pairs[k]\n        edges.append((i, j))\n        existing.add((i, j))\n        current_nc += 1\n        k += 1\n    return edges\n\ndef assemble_hessian(positions, edges, k=1.0):\n    N = positions.shape[0]\n    d = positions.shape[1]\n    size = N * d\n    H = np.zeros((size, size), dtype=float)\n    for (i, j) in edges:\n        ri = positions[i]\n        rj = positions[j]\n        vec = ri - rj\n        norm = np.linalg.norm(vec)\n        # Guard against zero-length due to numerical issues\n        if norm = 1e-15:\n            continue\n        e = vec / norm  # unit vector\n        # Rank-one projector\n        P = k * np.outer(e, e)  # d x d\n        # Indices in Hessian\n        ii = slice(i*d, (i+1)*d)\n        jj = slice(j*d, (j+1)*d)\n        # Assemble blocks\n        H[ii, ii] += P\n        H[jj, jj] += P\n        H[ii, jj] -= P\n        H[jj, ii] -= P\n    return H\n\ndef analyze_network(positions, edges, epsilon=1e-9, k=1.0, m=1.0):\n    d = positions.shape[1]\n    N = positions.shape[0]\n    H = assemble_hessian(positions, edges, k=k)\n    # Symmetric eigen-decomposition\n    w = np.linalg.eigvalsh(H)\n    # Correct small negative numerical artifacts\n    w = np.where(w  0, w, w)  # keep as is; eigvalsh should be fine\n    # Count zeros within tolerance\n    trivial_zeros = d * (d + 1) // 2  # rigid-body modes\n    count_zero = int(np.sum(w = epsilon))\n    n_soft = max(0, count_zero - trivial_zeros)\n    # Minimal nonzero eigenvalue\n    positive = w[w  epsilon]\n    if positive.size  0:\n        lambda_min = float(np.min(positive))\n        omega_min = float(np.sqrt(lambda_min / (m)))  # since lambda = k/m * ... and k=1\n    else:\n        omega_min = 0.0\n    # Marginal stability: Maxwell F = dN - Nc - d(d+1)/2\n    Nc = len(edges)\n    F_maxwell = d * N - Nc - d * (d + 1) // 2\n    is_isostatic = (F_maxwell == 0)\n    # Remove the last edge, recompute soft modes\n    if len(edges)  0:\n        edges_removed = edges[:-1]\n    else:\n        edges_removed = edges\n    H2 = assemble_hessian(positions, edges_removed, k=k)\n    w2 = np.linalg.eigvalsh(H2)\n    count_zero2 = int(np.sum(w2 = epsilon))\n    n_soft2 = max(0, count_zero2 - trivial_zeros)\n    b_marginal = bool(is_isostatic and (n_soft2 = n_soft + 1))\n    return n_soft, omega_min, b_marginal\n\ndef format_result(res):\n    n_soft, omega_min, b_marginal = res\n    # Ensure no spaces in the nested list formatting\n    return f\"[{n_soft},{omega_min},{b_marginal}]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (N, d, seed, target_Nc)\n    test_cases = [\n        (30, 2, 123, 53),  # Hypostatic\n        (30, 2, 456, 57),  # Isostatic/marginal candidate\n        (30, 2, 789, 70),  # Hyperstatic\n    ]\n\n    epsilon = 1e-9\n    results = []\n    for (N, d, seed, target_Nc) in test_cases:\n        positions = generate_positions(N, seed)\n        edges = build_full_edge_set(positions, target_Nc)\n        res = analyze_network(positions, edges, epsilon=epsilon, k=1.0, m=1.0)\n        results.append(res)\n\n    # Final print statement in the exact required format: nested lists, no spaces.\n    print(f\"[{','.join(format_result(r) for r in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2997433"}, {"introduction": "Having explored the properties of single configurations, we now scale up our perspective to analyze the jamming transition as a critical phenomenon. In simulations and experiments, we inevitably deal with finite-sized systems, and finite-size scaling (FSS) is the essential theoretical framework for extracting universal, thermodynamic-limit properties from such data. This capstone exercise provides hands-on experience with this powerful research technique by having you implement a full FSS analysis workflow [@problem_id:2997438]. You will generate synthetic data mimicking results near the transition and then perform a data collapse analysis to estimate critical parameters like the jamming threshold $\\phi_J^\\infty$ and the correlation length exponent $\\nu$, revealing their crucial dependence on the system's preparation protocol.", "problem": "Consider frictionless, athermal, repulsive particles undergoing a jamming transition in an amorphous configuration. Let the control parameter be the packing fraction $\\phi$, and let the thermodynamic-limit jamming threshold be $\\phi_{\\mathrm{J}}^{\\infty}$ for a given preparation protocol. Define the reduced control parameter $\\delta \\phi = \\phi - \\phi_{\\mathrm{J}}^{\\infty}$. Empirically and theoretically, near the transition, the correlation length $\\xi$ diverges as $\\xi \\sim |\\delta \\phi|^{-\\nu}$ with a positive critical exponent $\\nu$. In a finite system with $N$ particles in spatial dimension $d$, the linear size $L$ scales as $L \\propto N^{1/d}$. The principle of finite-size scaling (FSS) asserts that, near the transition, observables depend on the single scaling combination $x = \\delta \\phi L^{1/\\nu}$, up to smooth nonuniversal details. Consequently, the fraction of jammed configurations $F(N,\\phi)$ for a fixed protocol should be well described by a smooth sigmoid-like function of $x$.\n\nIn this problem, you will operationalize these principles to infer the protocol-dependent thermodynamic jamming threshold $\\phi_{\\mathrm{J}}^{\\infty}$ and the correlation-length exponent $\\nu$ from synthetic, noisy data, and you will algorithmically quantify protocol dependence. You must write a complete, runnable program that:\n- Generates synthetic datasets according to the FSS framework described below.\n- For each dataset and protocol, estimates $(\\phi_{\\mathrm{J}}^{\\infty}, \\nu)$ by minimizing a quantitative collapse error derived from the FSS ansatz.\n- Reports the estimated parameters with specified rounding, and a boolean indicating whether the two protocols in the dataset have distinct thermodynamic jamming thresholds beyond a specified tolerance.\n\nData generation model:\n- For each dataset and each protocol $p \\in \\{\\mathrm{A}, \\mathrm{B}\\}$, define a smooth sigmoid for the jammed fraction as $F_{p}(N,\\phi) = \\left[1 + \\exp\\left(-\\dfrac{x}{s_p}\\right)\\right]^{-1}$ with $x = (\\phi - \\phi_{\\mathrm{J},p}^{\\infty}) N^{1/(d \\nu_{\\mathrm{true}})}$, where $s_p  0$ is a protocol-dependent width parameter and $\\nu_{\\mathrm{true}}$ is the true exponent used to generate the synthetic data. Add independent Gaussian noise $\\eta \\sim \\mathcal{N}(0,\\sigma^2)$ to $F_{p}(N,\\phi)$, and clip the result to the interval $[0,1]$. Use a fixed pseudorandom number generator seed $12345$ to ensure reproducibility.\n\nParameter inference task (for each dataset and protocol, independently):\n- Given the noisy evaluations of $F_{p}(N,\\phi)$ on a grid of $(N,\\phi)$ pairs, estimate $(\\phi_{\\mathrm{J}}^{\\infty}, \\nu)$ by minimizing a collapse error consistent with the FSS ansatz. For any trial pair $(\\phi_{\\mathrm{J}}, \\nu)$, compute $x_{i} = (\\phi_{i} - \\phi_{\\mathrm{J}}) N_{i}^{1/(d \\nu)}$ for each data point $i$, then:\n  1. Bin the values of $x_{i}$ into $B$ equal-width bins spanning the observed range of $x_{i}$ (use $B = 25$).\n  2. In each bin $b$, compute the mean $\\overline{F}_{b}$ of the $F$-values falling into the bin.\n  3. Define the collapse error $E(\\phi_{\\mathrm{J}}, \\nu)$ as the mean of squared deviations of the data from the bin means, that is, the average of $(F_{i} - \\overline{F}_{b(i)})^{2}$ over all points $i$ with $b(i)$ the bin containing $x_{i}$.\n- Minimize $E(\\phi_{\\mathrm{J}}, \\nu)$ over a two-stage grid search:\n  1. Coarse search: $\\phi_{\\mathrm{J}}$ on a uniform grid spanning $[\\phi_{\\min} + 0.001, \\phi_{\\max} - 0.001]$ with step $0.0005$, and $\\nu$ on a uniform grid spanning $[0.5, 1.5]$ with step $0.05$.\n  2. Refinement: Recenter uniform grids around the best coarse pair $(\\phi_{\\mathrm{J}}^{\\star}, \\nu^{\\star})$, with $\\phi_{\\mathrm{J}}$ in $[\\phi_{\\mathrm{J}}^{\\star} - 0.002, \\phi_{\\mathrm{J}}^{\\star} + 0.002]$ with step $0.0001$, and $\\nu$ in $[\\nu^{\\star} - 0.1, \\nu^{\\star} + 0.1]$ with step $0.01$. Clip refined ranges to stay within the coarse bounds.\n- Round the final estimates as follows: report $\\phi_{\\mathrm{J}}^{\\infty}$ to $5$ decimals and $\\nu$ to $3$ decimals.\n\nProtocol dependence decision:\n- For each dataset, after estimating $\\phi_{\\mathrm{J},\\mathrm{A}}^{\\infty}$ and $\\phi_{\\mathrm{J},\\mathrm{B}}^{\\infty}$, declare the thresholds distinct if $|\\phi_{\\mathrm{J},\\mathrm{A}}^{\\infty} - \\phi_{\\mathrm{J},\\mathrm{B}}^{\\infty}| \\ge \\tau$, with tolerance $\\tau = 0.002$. Output a boolean for this decision.\n\nTest suite:\nYou must implement exactly the following three datasets. In all cases, use the fixed random seed $12345$, bin count $B = 25$, and the two-stage grid search above.\n- Dataset $1$ (two-dimensional, moderately large sizes, different widths):\n  - Spatial dimension $d = 2$.\n  - System sizes $N \\in \\{64, 128, 256, 512\\}$.\n  - Packing fraction grid $\\phi \\in [0.820, 0.870]$ with step $0.001$.\n  - True exponent $\\nu_{\\mathrm{true}} = 1.0$.\n  - Noise standard deviation $\\sigma = 0.015$.\n  - Protocol $\\mathrm{A}$: $\\phi_{\\mathrm{J},\\mathrm{A}}^{\\infty} = 0.842$, width $s_{\\mathrm{A}} = 0.60$.\n  - Protocol $\\mathrm{B}$: $\\phi_{\\mathrm{J},\\mathrm{B}}^{\\infty} = 0.835$, width $s_{\\mathrm{B}} = 0.40$.\n- Dataset $2$ (two-dimensional, smaller sizes, closer thresholds):\n  - Spatial dimension $d = 2$.\n  - System sizes $N \\in \\{16, 32, 64\\}$.\n  - Packing fraction grid $\\phi \\in [0.820, 0.865]$ with step $0.001$.\n  - True exponent $\\nu_{\\mathrm{true}} = 1.0$.\n  - Noise standard deviation $\\sigma = 0.020$.\n  - Protocol $\\mathrm{A}$: $\\phi_{\\mathrm{J},\\mathrm{A}}^{\\infty} = 0.842$, width $s_{\\mathrm{A}} = 0.90$.\n  - Protocol $\\mathrm{B}$: $\\phi_{\\mathrm{J},\\mathrm{B}}^{\\infty} = 0.838$, width $s_{\\mathrm{B}} = 0.90$.\n- Dataset $3$ (three-dimensional, different exponent, moderate sizes):\n  - Spatial dimension $d = 3$.\n  - System sizes $N \\in \\{125, 250, 500, 1000\\}$.\n  - Packing fraction grid $\\phi \\in [0.630, 0.665]$ with step $0.001$.\n  - True exponent $\\nu_{\\mathrm{true}} = 0.7$.\n  - Noise standard deviation $\\sigma = 0.015$.\n  - Protocol $\\mathrm{A}$: $\\phi_{\\mathrm{J},\\mathrm{A}}^{\\infty} = 0.648$, width $s_{\\mathrm{A}} = 0.70$.\n  - Protocol $\\mathrm{B}$: $\\phi_{\\mathrm{J},\\mathrm{B}}^{\\infty} = 0.645$, width $s_{\\mathrm{B}} = 0.60$.\n\nFinal output format:\n- For each dataset $k \\in \\{1,2,3\\}$, in order, output the list of five elements\n  $[\\phi_{\\mathrm{J},\\mathrm{A}}^{\\infty}\\text{(rounded to $5$ decimals)}, \\nu_{\\mathrm{A}}\\text{(rounded to $3$ decimals)}, \\phi_{\\mathrm{J},\\mathrm{B}}^{\\infty}\\text{(rounded to $5$ decimals)}, \\nu_{\\mathrm{B}}\\text{(rounded to $3$ decimals)}, \\text{distinct}]$,\n  where $\\text{distinct}$ is the boolean decision described above.\n- Aggregate the three per-dataset lists into a single flat list in the order $1 \\to 3$, resulting in $15$ outputs total.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_{1},r_{2},\\dots,r_{15}]$). There must be no additional text.\n\nNo physical unit is required because all quantities are dimensionless. Angles are not used. Percentages are not used. All computations should be deterministic from the specified pseudorandom seed. Your algorithm must be general and rely only on the FSS framework, not on any special-case knowledge of the chosen parameters.", "solution": "The user requires a solution to a computational physics problem involving the analysis of the jamming transition in amorphous materials using the principle of finite-size scaling (FSS). The tasks are to generate synthetic data according to a specified model, perform parameter estimation for the jamming threshold ($\\phi_{\\mathrm{J}}^{\\infty}$) and a critical exponent ($\\nu$) using a data collapse technique, and finally, decide if two different preparation protocols lead to statistically distinct jamming thresholds.\n\nThe solution is structured into three main parts: data generation, parameter estimation, and result aggregation, all orchestrated within a single program.\n\n### Principle-Based Design\n\n1.  **Finite-Size Scaling (FSS) Framework**: The entire problem is grounded in FSS, a cornerstone of the theory of critical phenomena. Near a continuous phase transition, the system's behavior is dictated by a single diverging correlation length, $\\xi \\sim |\\delta \\phi|^{-\\nu}$, where $\\delta \\phi = \\phi - \\phi_{\\mathrm{J}}^{\\infty}$ is the distance from the critical point. In a finite system of linear size $L$, physical observables $O$ do not depend on $\\phi$ and $L$ independently but rather on the ratio $L/\\xi$. This leads to a scaling law of the form $O(\\phi, L) = \\mathcal{G}(L/\\xi) = \\mathcal{F}(L^{1/\\nu} \\delta \\phi)$. The problem specifies the system size through particle number $N$ in $d$ dimensions, where $L \\propto N^{1/d}$. The scaling variable is therefore $x = (\\phi - \\phi_{\\mathrm{J}}^{\\infty}) (N^{1/d})^{1/\\nu} = (\\phi - \\phi_{\\mathrm{J}}^{\\infty}) N^{1/(d\\nu)}$. The observable is the jamming fraction $F(N, \\phi)$, which is modeled as a sigmoid function of $x$. This setup is standard in studies of critical phenomena.\n\n2.  **Data Generation**: The first step is to create synthetic data that adheres to the FSS model. For each of the three datasets, and for each of the two protocols (A and B), we generate data for the jamming fraction $F_p(N, \\phi)$. The model is given by $F_{p}(N,\\phi) = \\left[1 + \\exp\\left(-x/s_p\\right)\\right]^{-1}$, where $x = (\\phi - \\phi_{\\mathrm{J},p}^{\\infty}) N^{1/(d \\nu_{\\mathrm{true}})}$. The true parameters ($\\phi_{\\mathrm{J},p}^{\\infty}$, $\\nu_{\\mathrm{true}}$, $s_p$, $d$, $\\sigma$) are provided for each case. The generation process involves:\n    a. Constructing a grid of $(\\phi_i, N_i)$ pairs.\n    b. Calculating the \"true\" jamming fraction $F_{true}$ using the sigmoid formula.\n    c. Adding Gaussian noise $\\eta \\sim \\mathcal{N}(0, \\sigma^2)$, drawn from a generator initialized with a fixed seed ($12345$) for reproducibility.\n    d. Clipping the noisy values to the physical range $[0, 1]$.\n    This produces a set of data points $(N_i, \\phi_i, F_i)$ for each protocol.\n\n3.  **Parameter Estimation via Data Collapse**: The core of the analysis is to reverse the process: given the noisy data $(N_i, \\phi_i, F_i)$, we must estimate the unknown parameters $(\\phi_{\\mathrm{J}}, \\nu)$. The FSS ansatz implies that if we guess the correct $(\\phi_{\\mathrm{J}}, \\nu)$, plotting $F_i$ against the corresponding scaling variable $x_i = (\\phi_i - \\phi_{\\mathrm{J}}) N_i^{1/(d\\nu)}$ should cause the data from all different system sizes $N_i$ to \"collapse\" onto a single master curve. The quality of this collapse can be quantified. The problem specifies a collapse error metric, $E(\\phi_{\\mathrm{J}}, \\nu)$:\n    a. For a trial pair $(\\phi_{\\mathrm{J}}, \\nu)$, compute all $x_i$.\n    b. Bin the data points based on their $x_i$ values into $B=25$ equal-width bins.\n    c. For each bin $b$, calculate the mean $\\overline{F}_b$ of all $F_i$ values whose corresponding $x_i$ fall into that bin.\n    d. The error is the mean squared deviation of the individual data points from their respective bin means: $E = \\langle (F_i - \\overline{F}_{b(i)})^2 \\rangle_i$.\n    This error metric is minimized when the intra-bin variance is minimized, which occurs when the data collapse is optimal. The implementation uses `scipy.stats.binned_statistic` for robust and efficient calculation of bin means and assignments.\n\n4.  **Grid Search Minimization**: We find the optimal $(\\phi_{\\mathrm{J}}, \\nu)$ that minimizes $E$ by performing a two-stage grid search as specified:\n    a. **Coarse Search**: A broad search over a grid defined by steps of $\\Delta \\phi_{\\mathrm{J}} = 0.0005$ and $\\Delta\\nu = 0.05$. The ranges are based on the problem's specifications.\n    b. **Refined Search**: A finer search in a smaller region centered on the best parameters $(\\phi_{\\mathrm{J}}^{\\star}, \\nu^{\\star})$ found in the coarse stage. The step sizes are smaller ($\\Delta \\phi_{\\mathrm{J}} = 0.0001$, $\\Delta\\nu = 0.01$), and the search ranges are clipped to remain within the initial coarse search boundaries.\n    This two-stage approach efficiently homes in on the minimum of the error function.\n\n5.  **Protocol Dependence Analysis**: After obtaining the best-fit estimates $(\\hat{\\phi}_{\\mathrm{J},\\mathrm{A}}, \\hat{\\nu}_{\\mathrm{A}})$ and $(\\hat{\\phi}_{\\mathrm{J},\\mathrm{B}}, \\hat{\\nu}_{\\mathrm{B}})$ for a given dataset, the final step is to assess whether the jamming thresholds are distinct. This is determined by a simple criterion: if the absolute difference $|\\hat{\\phi}_{\\mathrm{J},\\mathrm{A}} - \\hat{\\phi}_{\\mathrm{J},\\mathrm{B}}|$ is greater than or equal to a given tolerance $\\tau=0.002$, the protocols are declared distinct. This yields a boolean result.\n\n6.  **Final Output**: The results for each dataset—the two estimated pairs $(\\phi_{\\mathrm{J}}^{\\infty}, \\nu)$ and the boolean decision—are collected. The numerical results are rounded to the specified number of decimal places using string formatting to ensure correct representation. All results are aggregated into a single flat list and printed in the precise format required. The entire process is deterministic due to the fixed random seed.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import binned_statistic\n\n# Constants defined in the problem statement\nSEED = 12345\nBINS = 25\nTOLERANCE = 0.002\n\ndef generate_data(d, N_list, phi_range_params, nu_true, sigma, phi_J_true, s, rng):\n    \"\"\"\n    Generates synthetic noisy data for the jamming fraction F(N, phi).\n    \"\"\"\n    phi_min, phi_max, phi_step = phi_range_params\n    phi_vals = np.arange(phi_min, phi_max + phi_step / 2.0, phi_step)\n    \n    N_all, phi_all, F_all = [], [], []\n    for N in N_list:\n        x = (phi_vals - phi_J_true) * N**(1.0 / (d * nu_true))\n        F_true = 1.0 / (1.0 + np.exp(-x / s))\n        noise = rng.normal(0, sigma, size=len(F_true))\n        F_noisy = np.clip(F_true + noise, 0, 1)\n        \n        N_all.extend([N] * len(phi_vals))\n        phi_all.extend(phi_vals)\n        F_all.extend(F_noisy)\n        \n    return np.array(N_all), np.array(phi_all), np.array(F_all)\n\ndef calculate_collapse_error(phi_J, nu, d, N, phi, F):\n    \"\"\"\n    Calculates the collapse error for a given trial (phi_J, nu).\n    \"\"\"\n    if nu = 1e-9:  # Avoid division by zero and extreme exponents\n        return np.inf\n\n    x = (phi - phi_J) * (N**(1.0 / (d * nu)))\n    \n    x_min, x_max = x.min(), x.max()\n    if abs(x_max - x_min)  1e-9: # All points collapse to a single x-value\n        return np.var(F)\n\n    # Use binned_statistic to compute means per bin\n    bin_means, _, bin_numbers = binned_statistic(x, F, statistic='mean', bins=BINS, range=(x_min, x_max))\n\n    # bin_numbers are 1-based. Correct for points on the max edge.\n    bin_numbers = np.minimum(bin_numbers, BINS)\n    \n    means_for_points = bin_means[bin_numbers - 1]\n    \n    error = np.mean((F - means_for_points)**2)\n    return error\n\ndef estimate_params(d, data_N, data_phi, data_F):\n    \"\"\"\n    Performs the two-stage grid search to find the best (phi_J, nu).\n    \"\"\"\n    phi_min_data, phi_max_data = data_phi.min(), data_phi.max()\n    \n    # Coarse search\n    coarse_phiJ_min, coarse_phiJ_max = phi_min_data + 0.001, phi_max_data - 0.001\n    coarse_nu_min, coarse_nu_max = 0.5, 1.5\n    \n    phiJ_grid_coarse = np.arange(coarse_phiJ_min, coarse_phiJ_max + 0.0005 / 2, 0.0005)\n    nu_grid_coarse = np.arange(coarse_nu_min, coarse_nu_max + 0.05 / 2, 0.05)\n    \n    min_error = np.inf\n    best_phiJ_coarse, best_nu_coarse = 0, 0\n    \n    for phi_J in phiJ_grid_coarse:\n        for nu in nu_grid_coarse:\n            error = calculate_collapse_error(phi_J, nu, d, data_N, data_phi, data_F)\n            if error  min_error:\n                min_error = error\n                best_phiJ_coarse = phi_J\n                best_nu_coarse = nu\n\n    # Refined search\n    refine_phiJ_start = max(coarse_phiJ_min, best_phiJ_coarse - 0.002)\n    refine_phiJ_end = min(coarse_phiJ_max, best_phiJ_coarse + 0.002)\n    refine_nu_start = max(coarse_nu_min, best_nu_coarse - 0.1)\n    refine_nu_end = min(coarse_nu_max, best_nu_coarse + 0.1)\n    \n    phiJ_grid_refine = np.arange(refine_phiJ_start, refine_phiJ_end + 0.0001 / 2, 0.0001)\n    nu_grid_refine = np.arange(refine_nu_start, refine_nu_end + 0.01 / 2, 0.01)\n\n    min_error = np.inf\n    best_phiJ_final, best_nu_final = best_phiJ_coarse, best_nu_coarse\n\n    if len(phiJ_grid_refine)  0 and len(nu_grid_refine)  0:\n        for phi_J in phiJ_grid_refine:\n            for nu in nu_grid_refine:\n                error = calculate_collapse_error(phi_J, nu, d, data_N, data_phi, data_F)\n                if error  min_error:\n                    min_error = error\n                    best_phiJ_final = phi_J\n                    best_nu_final = nu\n            \n    return best_phiJ_final, best_nu_final\n\n\ndef solve():\n    \"\"\"\n    Main function to run the full analysis for all datasets and print the final result.\n    \"\"\"\n    rng = np.random.default_rng(SEED)\n\n    test_cases = [\n        {\n            \"d\": 2, \"N_list\": [64, 128, 256, 512],\n            \"phi_range\": (0.820, 0.870, 0.001), \"nu_true\": 1.0, \"sigma\": 0.015,\n            \"protocols\": {\n                \"A\": {\"phi_J_true\": 0.842, \"s\": 0.60},\n                \"B\": {\"phi_J_true\": 0.835, \"s\": 0.40},\n            }\n        },\n        {\n            \"d\": 2, \"N_list\": [16, 32, 64],\n            \"phi_range\": (0.820, 0.865, 0.001), \"nu_true\": 1.0, \"sigma\": 0.020,\n            \"protocols\": {\n                \"A\": {\"phi_J_true\": 0.842, \"s\": 0.90},\n                \"B\": {\"phi_J_true\": 0.838, \"s\": 0.90},\n            }\n        },\n        {\n            \"d\": 3, \"N_list\": [125, 250, 500, 1000],\n            \"phi_range\": (0.630, 0.665, 0.001), \"nu_true\": 0.7, \"sigma\": 0.015,\n            \"protocols\": {\n                \"A\": {\"phi_J_true\": 0.648, \"s\": 0.70},\n                \"B\": {\"phi_J_true\": 0.645, \"s\": 0.60},\n            }\n        },\n    ]\n\n    final_results = []\n    for case in test_cases:\n        d, N_list, phi_range = case[\"d\"], case[\"N_list\"], case[\"phi_range\"]\n        nu_true, sigma = case[\"nu_true\"], case[\"sigma\"]\n        \n        # Protocol A processing\n        params_A = case[\"protocols\"][\"A\"]\n        data_N_A, data_phi_A, data_F_A = generate_data(\n            d, N_list, phi_range, nu_true, sigma, params_A[\"phi_J_true\"], params_A[\"s\"], rng\n        )\n        phiJ_A, nu_A = estimate_params(d, data_N_A, data_phi_A, data_F_A)\n\n        # Protocol B processing\n        params_B = case[\"protocols\"][\"B\"]\n        data_N_B, data_phi_B, data_F_B = generate_data(\n            d, N_list, phi_range, nu_true, sigma, params_B[\"phi_J_true\"], params_B[\"s\"], rng\n        )\n        phiJ_B, nu_B = estimate_params(d, data_N_B, data_phi_B, data_F_B)\n        \n        # Decision on protocol dependence\n        distinct = abs(phiJ_A - phiJ_B) = TOLERANCE\n        \n        # Append results with specified formatting\n        final_results.extend([\n            f\"{phiJ_A:.5f}\", f\"{nu_A:.3f}\",\n            f\"{phiJ_B:.5f}\", f\"{nu_B:.3f}\",\n            str(distinct)\n        ])\n\n    print(f\"[{','.join(final_results)}]\")\n\nsolve()\n```", "id": "2997438"}]}