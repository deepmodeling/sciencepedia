{"hands_on_practices": [{"introduction": "The threshold theorem is built upon the powerful concept of concatenated codes, where errors are suppressed recursively across multiple levels of encoding. This first practice problem explores the fundamental condition required for concatenation to be effective. By analyzing the crossover point where a two-level code begins to outperform a single-level code, you will gain a hands-on understanding of why a physical error threshold must exist for fault tolerance to be possible [@problem_id:175898].", "problem": "In the theory of fault-tolerant quantum computation, concatenated codes provide a powerful method for arbitrarily suppressing the logical error rate, provided the physical error rate is below a certain threshold. Consider a base quantum error-correcting code designed to protect against single-qubit errors. For a small physical error probability $p$ per qubit per time step, the logical error probability after one level of encoding, $p_L^{(1)}$, is dominated by events where two physical errors occur, leading to a scaling law of the form:\n$$p_L^{(1)} = C p^2$$\nHere, $C$ is a constant greater than 1 that depends on the specific code and the details of the fault-tolerant circuit implementation.\n\nA two-level concatenated code is constructed by replacing each physical qubit of the base code with an entire block of qubits already encoded with the same base code. The effective physical error rate for this second level of encoding is the logical error rate of the first level, $p_L^{(1)}$. Assuming the same scaling law holds for the second level of concatenation, the logical error probability of the two-level code, $p_L^{(2)}$, can be expressed in terms of the new effective physical error rate.\n\nThe utility of concatenation depends on the physical error rate $p$. For very high $p$, adding more encoding layers can actually increase the overall logical error rate. There exists a crossover physical error probability, $p_{cross}$, below which concatenation becomes beneficial.\n\nYour task is to find the crossover physical error probability $p_{cross}$ for this system. This is the value of $p$ at which the logical error rate of the two-level concatenated code is exactly equal to the logical error rate of the single-level code. For any physical error rate $p < p_{cross}$, the two-level code will outperform the single-level code. Express your answer in terms of the constant $C$.", "solution": "We are given the logical error probability for a single-level concatenated code:\n$$p_L^{(1)} = C p^2$$\nwhere $p$ is the physical error probability and $C > 1$ is a constant.\n\nFor a two-level concatenated code, the effective physical error rate at the second level is $p_L^{(1)}$. Applying the same scaling law, the logical error probability for the two-level code is:\n$$p_L^{(2)} = C \\left( p_L^{(1)} \\right)^2$$\nSubstitute the expression for $p_L^{(1)}$:\n$$p_L^{(2)} = C \\left( C p^2 \\right)^2 = C \\cdot C^2 p^4 = C^3 p^4$$\n\nThe crossover physical error probability $p_{cross}$ is defined by the condition where the logical error rate of the two-level code equals that of the single-level code:\n$$p_L^{(2)} = p_L^{(1)}$$\nSubstitute the expressions:\n$$C^3 p_{cross}^4 = C p_{cross}^2$$\n\nSince $C > 1$ and $p_{cross} > 0$, divide both sides by $C$:\n$$C^2 p_{cross}^4 = p_{cross}^2$$\n\nRearrange the equation:\n$$C^2 p_{cross}^4 - p_{cross}^2 = 0$$\n\nFactor out $p_{cross}^2$:\n$$p_{cross}^2 \\left( C^2 p_{cross}^2 - 1 \\right) = 0$$\n\nThe solution $p_{cross}^2 = 0$ is extraneous (as $p_{cross} > 0$). Solve the remaining equation:\n$$C^2 p_{cross}^2 - 1 = 0$$\n$$C^2 p_{cross}^2 = 1$$\n$$p_{cross}^2 = \\frac{1}{C^2}$$\n\nTake the positive square root (since $p_{cross} > 0$):\n$$p_{cross} = \\frac{1}{C}$$\n\nThus, the crossover physical error probability is $\\frac{1}{C}$.", "answer": "$$\\boxed{\\dfrac{1}{C}}$$", "id": "175898"}, {"introduction": "While the scaling relationship $p_{L} \\propto p^2$ is a cornerstone of the threshold theorem, the constant pre-factor determines the practical overhead of a code. This exercise provides a concrete look into how this pre-factor is determined for the well-known [[5,1,3]] perfect code. By systematically counting the weight-two error configurations that defeat the correction mechanism, you will connect the abstract power law to the specific structure of a quantum code and its decoder [@problem_id:177896].", "problem": "A cornerstone of fault-tolerant quantum computation (FTQC) is the threshold theorem, which states that arbitrarily long quantum computations can be performed with high fidelity, provided the physical error rate per gate is below a certain threshold. A key component in the proof and analysis of the threshold theorem involves estimating the logical error rate $\\epsilon_L$ of an encoded qubit as a function of the physical error probability $p$.\n\nConsider the [[5,1,3]] quantum error-correcting code, which encodes one logical qubit into five physical qubits and can correct any single-qubit error. This code is known to be a *perfect code*, which implies that every possible non-trivial error syndrome corresponds to a unique single-qubit Pauli error. It is a known property of this code that it possesses exactly $N_3$ logical Pauli operators of weight 3, where a logical Pauli operator is an operator that commutes with all stabilizers of the code but is not a stabilizer itself. For this problem, you are given that $N_3=60$.\n\nThe physical qubits are subject to independent, identically distributed depolarizing noise. The single-qubit depolarizing channel acts on a qubit's density matrix $\\rho$ as $\\mathcal{E}(\\rho) = (1-p)\\rho + \\frac{p}{3}(X\\rho X + Y\\rho Y + Z\\rho Z)$. This means that with probability $p$, an error occurs, and this error is an $X$, $Y$, or $Z$ Pauli operator with equal probability $p/3$.\n\nError correction for the [[5,1,3]] code is performed using a standard lookup-table decoder. After measuring the stabilizer generators to obtain an error syndrome, the decoder applies the unique single-qubit Pauli operator that would cause that syndrome.\n\nFor small $p$, the logical error rate is dominated by the lowest-order physical error events that can defeat the error correction. For a distance-3 code, this corresponds to physical errors of weight two. The logical error rate can thus be approximated by the formula $\\epsilon_L \\approx C p^2$. Your task is to calculate the pre-factor $C$ by enumerating all distinct weight-two error configurations that lead to a logical failure.", "solution": "1. The [[5,1,3]] code has $N_3=60$ logical Pauli operators of weight 3. Any logical failure from two physical errors arises when a weight‐2 Pauli error $E_{ij}=P_iP_j$ has the same syndrome as a weight‐1 Pauli $E_k$, so that the decoder applies $E_k$ and the residual operator \n$$E_kE_{ij}=g$$ \nis a nontrivial logical of weight 3.\n\n2. For each weight‐3 logical $g$ (there are 60) and each of its 3 support qubits, choosing $E_k$ on that qubit cancels one factor of $g$ and leaves a weight‐2 Pauli $E_{ij}$.  Thus there are \n$$60\\times3=180$$ \ndistinct weight‐2 error patterns leading to logical failure.\n\n3. Each such two‐qubit error occurs with probability $(p/3)^2=\\tfrac{p^2}{9}$. Summing over all 180 gives $\\epsilon_L\\approx 180\\cdot\\frac{p^2}{9}=20\\,p^2$. Hence the prefactor $C$ is $C=20$.", "answer": "$$\\boxed{20}$$", "id": "177896"}, {"introduction": "The performance of a fault-tolerant quantum computer depends not only on the chosen error-correcting code but also on the characteristics of the physical hardware. This final exercise delves into a crucial real-world optimization problem: the trade-off between the speed of logical gates and their fidelity. By balancing the increase in gate errors at high speeds against the accumulation of memory errors over longer durations, you will determine the optimal operating conditions to minimize the total failure probability of a quantum algorithm [@problem_id:175906].", "problem": "In the theory of fault-tolerant quantum computation, the performance of an algorithm is limited by the accumulation of errors in logical qubits. These errors arise from two primary sources: imperfect logical gate operations and degradation of qubits stored in memory. There is often a trade-off between the speed of a gate and its fidelity.\n\nConsider a quantum algorithm that consists of a sequence of $N_g$ logical gates. The algorithm operates on a quantum register of $N_q$ logical qubits. Each gate in the sequence is assumed to have a duration of $\\tau$.\n\nThe error model for the computation is as follows:\n1.  **Logical Gate Error:** The probability of failure for a single logical gate, $p_{\\text{gate}}(\\tau)$, depends on its duration $\\tau$. Faster gates (smaller $\\tau$) are noisier. The probability is given by the expression:\n    $$p_{\\text{gate}}(\\tau) = \\epsilon_0 + \\frac{\\alpha}{\\tau^2}$$\n    where $\\epsilon_0$ is a constant baseline error probability and $\\alpha$ is a positive constant that characterizes the time-dependent portion of the gate error.\n\n2.  **Logical Memory Error:** While a gate is being applied, all $N_q$ qubits must be maintained in memory. Each logical qubit has a constant probability per unit time, $\\gamma$, of decohering. Thus, the probability of a memory error occurring on a single, specific qubit during one gate step of duration $\\tau$ is $\\gamma\\tau$. We assume this probability is small.\n\nThe total probability of failure for the entire algorithm, $P_{\\text{fail}}(\\tau)$, is approximated by the sum of the probabilities of all possible error events (one for each gate, and one for each qubit during each gate step). This is a standard first-order approximation (union bound) valid for small error probabilities.\n\nFind the optimal logical gate time, $\\tau_{\\text{opt}}$, that minimizes the total algorithm failure probability, $P_{\\text{fail}}(\\tau)$. Express your answer in terms of the given parameters $\\alpha$, $\\gamma$, and $N_q$.", "solution": "1. The total failure probability (union bound) for $N_g$ gates on $N_q$ qubits is\n$$\nP_{\\rm fail}(\\tau)\\approx N_g\\Bigl[p_{\\rm gate}(\\tau)+N_q\\,\\gamma\\tau\\Bigr]\n= N_g\\Bigl[\\epsilon_0+\\frac{\\alpha}{\\tau^2}+N_q\\gamma\\tau\\Bigr].\n$$\n\n2. Since $\\epsilon_0$ is independent of $\\tau$, minimize\n$$\nf(\\tau)=\\frac{\\alpha}{\\tau^2}+N_q\\gamma\\tau.\n$$\n\n3. Compute derivative and set to zero:\n$$\n\\frac{df}{d\\tau}\n=-2\\,\\frac{\\alpha}{\\tau^3}+N_q\\gamma\n\\stackrel{!}{=}0\n\\quad\\Longrightarrow\\quad\nN_q\\gamma=\\frac{2\\alpha}{\\tau^3}.\n$$\n\n4. Solve for $\\tau$:\n$$\n\\tau^3=\\frac{2\\alpha}{N_q\\gamma}\n\\quad\\Longrightarrow\\quad\n\\tau_{\\rm opt}=\\Bigl(\\frac{2\\alpha}{N_q\\gamma}\\Bigr)^{1/3}.\n$$", "answer": "$$\\boxed{\\Bigl(\\frac{2\\alpha}{N_q\\gamma}\\Bigr)^{1/3}}$$", "id": "175906"}]}