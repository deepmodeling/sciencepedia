{"hands_on_practices": [{"introduction": "We begin our hands-on practice with the Pauli channel, a cornerstone model for errors in quantum computation. This exercise explores a qubit that experiences bit-flips ($X$), phase-flips ($Z$), or a combination ($Y$) with certain probabilities. As a unital channel, its analysis is simplified, making it an ideal starting point to apply the entanglement-assisted capacity formula and understand the crucial role of entropy exchange in quantifying information loss [@problem_id:153530].", "problem": "A single-qubit Pauli channel $\\mathcal{E}$ is a quantum channel that describes a process where a qubit state $\\rho$ is either left untouched with probability $p_I$, or subjected to a Pauli $X$, $Y$, or $Z$ error with probabilities $p_x, p_y, p_z$, respectively. The probabilities sum to one: $p_I + p_x + p_y + p_z = 1$. The action of the channel on a density matrix $\\rho$ is given by:\n$$\n\\mathcal{E}(\\rho) = p_I \\rho + p_x \\sigma_x \\rho \\sigma_x + p_y \\sigma_y \\rho \\sigma_y + p_z \\sigma_z \\rho \\sigma_z\n$$\nwhere $\\sigma_x, \\sigma_y, \\sigma_z$ are the standard Pauli matrices.\n\nThe entanglement-assisted classical capacity of a quantum channel, $C_{ea}(\\mathcal{E})$, quantifies the maximum rate of classical information transmission if the sender and receiver share an unlimited amount of prior entanglement. It is given by the formula:\n$$\nC_{ea}(\\mathcal{E}) = \\max_{\\rho} \\left[ S(\\rho) + S(\\mathcal{E}(\\rho)) - S_e(\\rho, \\mathcal{E}) \\right]\n$$\nwhere:\n- $\\rho$ is the input quantum state from the sender's signal ensemble.\n- $S(\\sigma) = -\\text{Tr}(\\sigma \\log_2 \\sigma)$ is the von Neumann entropy.\n- $S_e(\\rho, \\mathcal{E})$ is the entropy exchange, defined as $S_e(\\rho, \\mathcal{E}) = S((\\mathcal{I} \\otimes \\mathcal{E})(\\psi_\\rho))$, where $\\psi_\\rho$ is any purification of $\\rho$ and $\\mathcal{I}$ is the identity map on the purifying system.\n\nFor a unital channel, one for which $\\mathcal{E}(I) = I$ (where $I$ is the identity operator), the maximum in the capacity formula is achieved for the maximally mixed input state, $\\rho = I/d$, where $d$ is the dimension of the Hilbert space.\n\nYour task is to calculate the entanglement-assisted classical capacity $C_{ea}(\\mathcal{E})$ for the general single-qubit Pauli channel with error probabilities $p_x, p_y, p_z$. Express your answer as a single closed-form analytic expression in terms of $p_x, p_y$, and $p_z$.", "solution": "The entanglement-assisted classical capacity for a unital channel is achieved at the maximally mixed input state $\\rho = I / d$, where $d = 2$ for a qubit. Thus, $\\rho = I / 2$.\n\nThe von Neumann entropy of $\\rho$ is:\n$$\nS(\\rho) = -\\text{Tr}(\\rho \\log_2 \\rho) = -\\sum_i \\lambda_i \\log_2 \\lambda_i,\n$$\nwhere $\\lambda_i$ are the eigenvalues of $\\rho$. For $\\rho = I/2$, the eigenvalues are $1/2$ and $1/2$, so:\n$$\nS(\\rho) = -2 \\left( \\frac{1}{2} \\log_2 \\frac{1}{2} \\right) = -\\log_2 \\frac{1}{2} = \\log_2 2 = 1.\n$$\n\nThe channel output is:\n$$\n\\mathcal{E}(\\rho) = p_I \\rho + p_x \\sigma_x \\rho \\sigma_x + p_y \\sigma_y \\rho \\sigma_y + p_z \\sigma_z \\rho \\sigma_z.\n$$\nSubstituting $\\rho = I/2$ and using $\\sigma_k^2 = I$ for $k = x, y, z$:\n$$\n\\sigma_k \\rho \\sigma_k = \\sigma_k (I/2) \\sigma_k = (I/2) \\sigma_k^2 = (I/2) I = I/2.\n$$\nThus:\n$$\n\\mathcal{E}(\\rho) = p_I (I/2) + p_x (I/2) + p_y (I/2) + p_z (I/2) = (p_I + p_x + p_y + p_z) (I/2) = I/2,\n$$\nsince $p_I + p_x + p_y + p_z = 1$. Therefore, $\\mathcal{E}(\\rho) = I/2$, and:\n$$\nS(\\mathcal{E}(\\rho)) = S(I/2) = 1.\n$$\n\nThe entropy exchange $S_e(\\rho, \\mathcal{E})$ is:\n$$\nS_e(\\rho, \\mathcal{E}) = S((\\mathcal{I} \\otimes \\mathcal{E})(|\\Phi^+\\rangle\\langle\\Phi^+|)),\n$$\nwhere $|\\Phi^+\\rangle = (|00\\rangle + |11\\rangle)/\\sqrt{2}$ is a purification of $\\rho = I/2$.\n\nApplying $\\mathcal{I} \\otimes \\mathcal{E}$:\n$$\n(\\mathcal{I} \\otimes \\mathcal{E})(|\\Phi^+\\rangle \\langle \\Phi^+|) = p_I |\\Phi^+\\rangle \\langle \\Phi^+| + p_x (\\mathcal{I} \\otimes \\sigma_x) |\\Phi^+\\rangle \\langle \\Phi^+| (\\mathcal{I} \\otimes \\sigma_x)^\\dagger + p_y (\\mathcal{I} \\otimes \\sigma_y) |\\Phi^+\\rangle \\langle \\Phi^+| (\\mathcal{I} \\otimes \\sigma_y)^\\dagger + p_z (\\mathcal{I} \\otimes \\sigma_z) |\\Phi^+\\rangle \\langle \\Phi^+| (\\mathcal{I} \\otimes \\sigma_z)^\\dagger.\n$$\nSince $\\sigma_k$ is unitary and Hermitian ($\\sigma_k^\\dagger = \\sigma_k$), and using the fact that Pauli operators transform Bell states into other Bell states:\n- $(\\mathcal{I} \\otimes \\sigma_x) |\\Phi^+\\rangle = |\\Psi^+\\rangle = (|01\\rangle + |10\\rangle)/\\sqrt{2}$,\n- $(\\mathcal{I} \\otimes \\sigma_y) |\\Phi^+\\rangle = i|\\Psi^-\\rangle = i(|01\\rangle - |10\\rangle)/\\sqrt{2}$, which gives the density matrix $|\\Psi^-\\rangle \\langle \\Psi^-|$,\n- $(\\mathcal{I} \\otimes \\sigma_z) |\\Phi^+\\rangle = |\\Phi^-\\rangle = (|00\\rangle - |11\\rangle)/\\sqrt{2}$,\n\nthe output state is a mixture of orthogonal Bell states:\n$$\n(\\mathcal{I} \\otimes \\mathcal{E})(|\\Phi^+\\rangle \\langle \\Phi^+|) = p_I |\\Phi^+\\rangle \\langle \\Phi^+| + p_x |\\Psi^+\\rangle \\langle \\Psi^+| + p_y |\\Psi^-\\rangle \\langle \\Psi^-| + p_z |\\Phi^-\\rangle \\langle \\Phi^-|.\n$$\nThe eigenvalues are the probabilities $p_I$, $p_x$, $p_y$, $p_z$. The von Neumann entropy is the Shannon entropy of this distribution:\n$$\nS_e(\\rho, \\mathcal{E}) = -p_I \\log_2 p_I - p_x \\log_2 p_x - p_y \\log_2 p_y - p_z \\log_2 p_z,\n$$\nwith $p_I = 1 - p_x - p_y - p_z$.\n\nThe capacity is:\n$$\nC_{ea}(\\mathcal{E}) = S(\\rho) + S(\\mathcal{E}(\\rho)) - S_e(\\rho, \\mathcal{E}) = 1 + 1 - \\left( -p_I \\log_2 p_I - p_x \\log_2 p_x - p_y \\log_2 p_y - p_z \\log_2 p_z \\right).\n$$\nSimplifying:\n$$\nC_{ea}(\\mathcal{E}) = 2 + p_I \\log_2 p_I + p_x \\log_2 p_x + p_y \\log_2 p_y + p_z \\log_2 p_z.\n$$\nSubstituting $p_I = 1 - p_x - p_y - p_z$:\n$$\nC_{ea}(\\mathcal{E}) = 2 + (1 - p_x - p_y - p_z) \\log_2 (1 - p_x - p_y - p_z) + p_x \\log_2 p_x + p_y \\log_2 p_y + p_z \\log_2 p_z.\n$$", "answer": "$$ \\boxed{2 + (1 - p_x - p_y - p_z) \\log_2 (1 - p_x - p_y - p_z) + p_x \\log_2 p_x + p_y \\log_2 p_y + p_z \\log_2 p_z} $$", "id": "153530"}, {"introduction": "Moving to a more physically motivated scenario, we next consider the amplitude damping channel, which models energy dissipation or spontaneous emission in a two-level system. Unlike the Pauli channel, this channel is non-unital, representing an asymmetric noise process. This practice problem [@problem_id:153535] challenges you to work backward: given a target capacity of one bit, you must determine the corresponding physical damping parameter $\\gamma$, providing insight into how a channel's physical properties constrain its ability to transmit information.", "problem": "The entanglement-assisted classical capacity, $C_{ea}(\\mathcal{N})$, of a quantum channel $\\mathcal{N}$ is the highest rate at which classical information can be transmitted through the channel, given that the sender and receiver have access to an unlimited supply of shared entanglement. It is given by the maximization of the quantum mutual information over all possible input states:\n$$C_{ea}(\\mathcal{N}) = \\max_{\\rho_A} I(A:B)$$\nwhere $I(A:B) = S(\\rho_A) + S(\\rho_B) - S(\\rho_{AB})$. Here, $\\rho_{A}$ is the state of the input system $A$, $\\rho_B = \\mathcal{N}(\\rho_A)$ is the state of the output system $B$, and $\\rho_{AB}$ is the joint state of a purifying reference system $R$ and the output system $B$, after one part of a pure bipartite state $|\\psi\\rangle_{RA}$ (a purification of $\\rho_A$) is sent through the channel. The von Neumann entropy is denoted by $S(\\rho) = -\\text{Tr}(\\rho \\log_2 \\rho)$.\n\nAn equivalent and often more practical formula expresses the capacity as:\n$$C_{ea}(\\mathcal{N}) = \\max_{\\rho_A} \\left[ S(\\rho_A) + S(\\mathcal{N}(\\rho_A)) - S_e(\\mathcal{N}, \\rho_A) \\right]$$\nwhere $S_e(\\mathcal{N}, \\rho_A)$ is the entropy exchange of the channel for the input state $\\rho_A$. The entropy exchange is the von Neumann entropy of the environment state after the interaction with the system initially in state $\\rho_A$.\n\nConsider the single-qubit amplitude damping channel, $\\mathcal{N}_\\gamma$, which models energy dissipation. Its action on a density matrix $\\rho$ is described by the operator-sum representation:\n$$\\mathcal{N}_\\gamma(\\rho) = E_0 \\rho E_0^\\dagger + E_1 \\rho E_1^\\dagger$$\nwith Kraus operators:\n$$E_0 = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\sqrt{1-\\gamma} \\end{pmatrix}, \\quad E_1 = \\begin{pmatrix} 0 & \\sqrt{\\gamma} \\\\ 0 & 0 \\end{pmatrix}$$\nThe parameter $\\gamma \\in [0, 1]$ represents the probability of the qubit's excited state $|1\\rangle$ decaying to the ground state $|0\\rangle$.\n\nFor the amplitude damping channel $\\mathcal{N}_\\gamma$, the maximum in the expression for $C_{ea}$ is achieved when the input state $\\rho_A$ is the maximally mixed state, $\\rho_A = I/2$, where $I$ is the $2 \\times 2$ identity matrix.\n\nYour task is to find the value of the damping parameter $\\gamma$ for which the entanglement-assisted capacity $C_{ea}(\\mathcal{N}_\\gamma)$ is exactly equal to one bit per channel use.", "solution": "For the maximally mixed input $\\rho_A=I/2$, the entanglement-assisted capacity is $C_{ea}(\\mathcal{N}_\\gamma)=S(\\rho_A)+S(\\mathcal{N}_\\gamma(\\rho_A))-S_e(\\mathcal{N}_\\gamma,\\rho_A)$.\nThe input entropy is $S(\\rho_A)=1$. The output state is $\\rho_B=\\mathcal{N}_\\gamma(I/2)$:\n$$\\rho_B=E_0\\frac{I}{2}E_0^\\dagger+E_1\\frac{I}{2}E_1^\\dagger = \\frac{1}{2}\\begin{pmatrix}1+\\gamma & 0 \\\\ 0 & 1-\\gamma\\end{pmatrix}$$\nThe eigenvalues of $\\rho_B$ are $\\lambda_\\pm=(1\\pm\\gamma)/2$, so its entropy is $S(\\rho_B)=H_2\\left(\\frac{1+\\gamma}{2}\\right)$, where $H_2$ is the binary entropy function.\nThe entropy exchange is calculated from the probability $p_1=\\text{Tr}(E_1(I/2)E_1^\\dagger) = \\frac{\\gamma}{2}$. Thus, $S_e(\\mathcal{N}_\\gamma,\\rho_A)=H_2\\left(\\frac{\\gamma}{2}\\right)$.\nWe impose the condition that the capacity is 1:\n$$1 + H_2\\left(\\frac{1+\\gamma}{2}\\right) - H_2\\left(\\frac{\\gamma}{2}\\right) = 1$$\n$$\\implies H_2\\left(\\frac{1+\\gamma}{2}\\right)=H_2\\left(\\frac{\\gamma}{2}\\right)$$\nSince the binary entropy function $H_2(p)$ is symmetric, $H_2(p)=H_2(1-p)$, the non-trivial solution requires $\\frac{1+\\gamma}{2} = 1-\\frac{\\gamma}{2}$.\n$$ \\implies 1+\\gamma=2-\\gamma \\implies 2\\gamma=1 \\implies \\gamma=\\frac{1}{2} $$", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "153535"}, {"introduction": "Our final practice problem ventures into the advanced topic of channels with memory, where errors in successive channel uses are correlated. Here, the sequence of Pauli errors is governed by a classical Markov chain, a common model for realistic noise in physical systems. This exercise [@problem_id:153565] demonstrates a profound connection between quantum capacity and classical information theory, showing that the entanglement-assisted capacity is determined by the entropy rate of the underlying Markov process, a measure of its intrinsic randomness.", "problem": "The entanglement-assisted capacity of a quantum channel quantifies the maximum rate at which classical information can be transmitted reliably through the channel, given that the sender and receiver have access to an unlimited supply of shared entangled states (e.g., EPR pairs).\n\nFor a memoryless (i.i.d.) qubit Pauli channel $\\mathcal{N}(\\rho) = \\sum_{k=0}^3 p_k \\sigma_k \\rho \\sigma_k$, where $\\sigma_k \\in \\{I, X, Y, Z\\}$ are the Pauli operators, the entanglement-assisted capacity is given by $C_{ea}(\\mathcal{N}) = 2 - H(\\{p_k\\})$, where $H(\\{p_k\\}) = -\\sum_k p_k \\log_2 p_k$ is the Shannon entropy of the error probability distribution.\n\nConsider a quantum channel with memory that acts on a single qubit at discrete time steps $t=1, 2, 3, \\ldots$. At each time step $t$, the channel applies a single Pauli error $\\sigma_{s_t}$ to the input qubit, where the index $s_t \\in S = \\{0, 1, 2, 3\\}$ corresponds to the operators $\\{I, X, Y, Z\\}$ respectively. The sequence of errors is governed by a classical, ergodic Markov chain whose state at time $t$ is $s_t$. The transition probability matrix $M$ of this chain, with entries $M_{ij} = P(s_{t+1}=j | s_t=i)$, is defined as follows:\n- The probability of transitioning from the no-error state ($s=0$) to any of the three error states ($s \\in \\{1,2,3\\}$) is $a/3$. Thus, $M_{0j} = a/3$ for $j \\in \\{1,2,3\\}$. Consequently, the probability of remaining in the no-error state is $M_{00} = 1-a$.\n- The probability of transitioning from any error state ($s \\in \\{1,2,3\\}$) to the no-error state ($s=0$) is $b$. Thus, $M_{i0}=b$ for $i \\in \\{1,2,3\\}$.\n- The probability of transitioning from an error state $i \\in \\{1,2,3\\}$ to any error state $j \\in \\{1,2,3\\}$ is $(1-b)/3$ for each $j$. Thus, $M_{ij} = (1-b)/3$ for $i,j \\in \\{1,2,3\\}$.\n\nThe parameters $a$ and $b$ satisfy $0 < a < 1$ and $0 < b < 1$.\n\nThe entanglement-assisted capacity $C_{ea}$ for such a channel with memory is given by $C_{ea} = 2 - H(\\mathcal{S})$, where $H(\\mathcal{S})$ is the entropy rate of the underlying Markov chain $\\mathcal{S}$ in bits.\n\nDerive a closed-form expression for the entanglement-assisted capacity $C_{ea}$ of this channel in bits per channel use, as a function of the parameters $a$ and $b$.", "solution": "Let $\\pi_i$ be the stationary probability of state $i\\in\\{0,1,2,3\\}$. By symmetry, we can set $\\pi_0=\\alpha$ and $\\pi_1=\\pi_2=\\pi_3=\\beta$, where $\\alpha+3\\beta=1$. \nThe stationarity condition $\\pi M = \\pi$ gives the equation for the first state:\n$$\\alpha=\\alpha(1-a)+3\\beta b$$\nSubstituting $3\\beta = 1-\\alpha$ gives $\\alpha=\\alpha(1-a)+ (1-\\alpha)b$, which simplifies to $\\alpha(a+b)=b$.\nThus, the stationary probabilities are:\n$$\\alpha=\\frac{b}{a+b}, \\quad \\beta=\\frac{1-\\alpha}{3}=\\frac{a}{3(a+b)}$$\nThe entropy rate of the Markov chain $\\mathcal{S}$ is $H(\\mathcal S)=-\\sum_{i,j}\\pi_i M_{ij}\\log_2 M_{ij} = \\sum_i \\pi_i H_i$, where $H_i$ is the entropy of the transitions from state $i$.\nFor the no-error state $i=0$, the row-entropy is:\n$$H_0=-(1-a)\\log_2(1-a)-3\\frac{a}{3}\\log_2\\frac{a}{3} =-(1-a)\\log_2(1-a)-a\\log_2\\frac{a}{3}$$ \nFor any error state $i\\in\\{1,2,3\\}$, the row-entropy is:\n$$H_1=-b\\log_2 b-3\\frac{1-b}{3}\\log_2\\frac{1-b}{3} =-b\\log_2 b-(1-b)\\log_2\\frac{1-b}{3}$$\nThe total entropy rate is $H(\\mathcal S) = \\alpha H_0+3\\beta H_1$:\n$$H(\\mathcal S) =\\frac{b}{a+b}H_0+\\frac{a}{a+b}H_1 = -\\frac{b\\left[(1-a)\\log_2(1-a)+a\\log_2\\frac{a}{3}\\right] +a\\left[b\\log_2 b+(1-b)\\log_2\\frac{1-b}{3}\\right]}{a+b}$$\nFinally, the entanglement-assisted capacity is $C_{ea}=2-H(\\mathcal S)$:\n$$C_{ea} = 2+\\frac{b\\left[(1-a)\\log_2(1-a)+a\\log_2\\frac{a}{3}\\right] + a\\left[b\\log_2 b+(1-b)\\log_2\\frac{1-b}{3}\\right]}{a+b}$$", "answer": "$$\\boxed{2+\\frac{b\\left((1-a)\\log_2(1-a)+a\\log_2\\frac{a}{3}\\right) + a\\left(b\\log_2 b+(1-b)\\log_2\\frac{1-b}{3}\\right)}{a+b}}$$", "id": "153565"}]}