{"hands_on_practices": [{"introduction": "The direct coding theorem relies on averaging over many randomly chosen codewords. This first exercise explores the properties of the \"grand average\" output state, a central object in random coding arguments. By calculating the entropy of the average output for a symmetric set of input states sent through a dephasing channel, you'll gain insight into how the Holevo information—a cornerstone of channel capacity—is determined. [@problem_id:152080]", "problem": "In the context of Shannon's noisy channel coding theorem, a key element is the use of random codes. An analogous strategy is employed in the proof of the direct coding theorem for quantum channels. Consider a simple random coding scheme where the sender prepares a qubit in a state chosen from a specific ensemble.\n\nThe quantum channel is a qubit dephasing channel $\\mathcal{E}$ with a dephasing probability $p \\in [0, 1]$. Its action on a density matrix $\\rho$ is given by the operator-sum representation:\n$$\n\\mathcal{E}(\\rho) = (1-p)\\rho + p \\sigma_z \\rho \\sigma_z\n$$\nwhere $\\sigma_z$ is the Pauli-Z operator.\n\nThe input ensemble consists of the four pure states $\\{|0\\rangle, |1\\rangle, |+\\rangle, |-\\rangle \\}$, where $|0\\rangle$ and $|1\\rangle$ are the eigenstates of $\\sigma_z$, and $|+\\rangle$ and $|-\\rangle$ are the eigenstates of the Pauli-X operator $\\sigma_x$. Each state is chosen with equal probability.\n\nThe average state at the output of the channel, $\\bar{\\rho}_{out}$, is the probabilistic mixture of the resulting states. Compute the von Neumann entropy, $S(\\bar{\\rho}_{out}) = -\\text{Tr}(\\bar{\\rho}_{out} \\log_2 \\bar{\\rho}_{out})$, of this average output state. The result is independent of the dephasing probability $p$.", "solution": "We have the dephasing channel \n$$\n\\mathcal{E}(\\rho) \\;=\\;(1-p)\\,\\rho \\;+\\;p\\,\\sigma_z\\,\\rho\\,\\sigma_z.\n$$\nThe input ensemble is $\\{|0\\rangle, |1\\rangle, |+\\rangle, |-\\rangle\\}$, each with probability $1/4$.  We compute each output:\n\n1. For $|0\\rangle$:\n$$\n\\mathcal{E}(|0\\rangle\\langle0|)\n=(1-p)|0\\rangle\\langle0|+p\\,\\sigma_z|0\\rangle\\langle0|\\sigma_z\n=|0\\rangle\\langle0|.\n$$\n\n2. For $|1\\rangle$:\n$$\n\\mathcal{E}(|1\\rangle\\langle1|)\n=(1-p)|1\\rangle\\langle1|+p\\,\\sigma_z|1\\rangle\\langle1|\\sigma_z\n=|1\\rangle\\langle1|.\n$$\n\n3. For $|+\\rangle$:\n$$\n\\mathcal{E}(|+\\rangle\\langle+|)\n=(1-p)|+\\rangle\\langle+|+p\\,\\sigma_z|+\\rangle\\langle+|\\sigma_z\n=(1-p)|+\\rangle\\langle+|+p\\,|-\\rangle\\langle-|.\n$$\n\n4. For $|-\\rangle$:\n$$\n\\mathcal{E}(|-\\rangle\\langle-|)\n=(1-p)|-\\rangle\\langle-|+p\\,|+\\rangle\\langle+|.\n$$\n\nThe average output state is\n$$\n\\bar\\rho_{out}\n=\\tfrac14\\bigl(|0\\rangle\\langle0|+|1\\rangle\\langle1|+\\mathcal{E}(|+\\rangle\\langle+|)+\\mathcal{E}(|-\\rangle\\langle-|)\\bigr).\n$$\nSubstitute and combine:\n$$\n\\bar\\rho_{out}\n=\\tfrac14\\bigl(\n|0\\rangle\\langle0|+|1\\rangle\\langle1|\n+(1-p)|+\\rangle\\langle+|+p|-\\rangle\\langle-|\n+p|+\\rangle\\langle+|+(1-p)|-\\rangle\\langle-|\n\\bigr)\n=\\tfrac14(2I)\n=\\tfrac12\\,I.\n$$\n\nHence\n$$\nS(\\bar\\rho_{out})\n=-\\Tr\\!\\bigl(\\tfrac12I\\log_2(\\tfrac12I)\\bigr)\n=-2\\cdot\\tfrac12\\log_2\\tfrac12\n=1.\n$$", "answer": "$$\\boxed{1}$$", "id": "152080"}, {"introduction": "A key concept in the proof of the direct coding theorem is \"typicality,\" which allows us to distinguish signal from noise. In this exercise, we will use the typical subspace of one codeword's output as a decoding region and calculate the probability that the output from a *different* codeword erroneously lands in it. This \"crossover error\" calculation provides a concrete look at the error analysis central to proving the achievability of a communication rate. [@problem_id:152064]", "problem": "An amplitude damping channel $\\mathcal{E}$ with a damping parameter $\\gamma \\in [0, 1]$ models the process of energy dissipation for a two-level quantum system (a qubit). Its action on an arbitrary single-qubit state $\\rho$ is given by the operator-sum representation $\\mathcal{E}(\\rho) = E_0 \\rho E_0^\\dagger + E_1 \\rho E_1^\\dagger$, with the Kraus operators defined as:\n$$\nE_0 = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\sqrt{1-\\gamma} \\end{pmatrix}, \\quad E_1 = \\begin{pmatrix} 0 & \\sqrt{\\gamma} \\\\ 0 & 0 \\end{pmatrix}\n$$\nIn the context of quantum information theory, the reliability of transmitting information through a noisy channel is fundamental. Consider a simple repetition code using two length-$n$ codewords: $|c_0\\rangle = |0\\rangle^{\\otimes n}$ and $|c_1\\rangle = |1\\rangle^{\\otimes n}$. When these codewords are sent through $n$ independent instances of the channel $\\mathcal{E}$, the resulting output states are $\\rho_0^{(n)} = \\mathcal{E}^{\\otimes n}(|c_0\\rangle\\langle c_0|)$ and $\\rho_1^{(n)} = \\mathcal{E}^{\\otimes n}(|c_1\\rangle\\langle c_1|)$, respectively.\n\nA key concept in proving channel coding theorems is the typical subspace. For a quantum source described by a density matrix $\\sigma$, the typical subspace $T_{n,\\delta}(\\sigma)$ for a sequence of $n$ outputs is defined by the system's statistics. Formally, it is the subspace spanned by the eigenvectors of $\\sigma^{\\otimes n}$ whose eigenvalues $\\lambda$ fall within the range $2^{-n(S(\\sigma)+\\delta)} \\le \\lambda \\le 2^{-n(S(\\sigma)-\\delta)}$. Here, $S(\\sigma) = -\\text{Tr}(\\sigma \\log_2 \\sigma)$ is the von Neumann entropy of the single-system state $\\sigma$, and $\\delta$ is an arbitrarily small positive constant. Let $P_{n,\\delta}(\\sigma)$ denote the projector onto this typical subspace.\n\nIn a typical subspace decoding scheme, one might define the decoding region for message '0' as the typical subspace associated with the output state when $|c_0\\rangle$ is sent. An error, known as a crossover error, occurs if the message '1' was sent, yet the output state is detected in the decoding region for '0'.\n\nLet $\\sigma_0 = \\mathcal{E}(|0\\rangle\\langle 0|)$ be the single-qubit output state for the input state $|0\\rangle$. The crossover probability is given by $p_{1\\to 0} = \\text{Tr}(P_{n,\\delta}(\\sigma_0) \\, \\rho_1^{(n)})$.\n\nCalculate this crossover probability. Your final expression should be in terms of $n$ and $\\gamma$, and it must hold for any choice of sufficiently small $\\delta > 0$.", "solution": "1. The single‐qubit output states are\n$$\n\\sigma_0 = \\mathcal{E}(|0\\rangle\\langle0|), \n\\quad\n\\sigma_1 = \\mathcal{E}(|1\\rangle\\langle1|).\n$$\n\n2. From the Kraus operators,\n$$\nE_0|0\\rangle = |0\\rangle,\\quad E_1|0\\rangle = 0\n\\quad\\Longrightarrow\\quad\n\\sigma_0 = |0\\rangle\\langle0|.\n$$\n\n3. Hence \n$$\n\\sigma_0^{\\otimes n} = |0^n\\rangle\\langle0^n|\n$$ \nhas a single nonzero eigenvalue $1$, so for any $\\delta>0$ the typical projector is\n$$\nP_{n,\\delta}(\\sigma_0) = |0^n\\rangle\\langle0^n|.\n$$\n\n4. Likewise,\n$$\nE_0|1\\rangle = \\sqrt{1-\\gamma}\\,|1\\rangle,\\quad\nE_1|1\\rangle = \\sqrt{\\gamma}\\,|0\\rangle,\n$$\nso\n$$\n\\sigma_1 = (1-\\gamma)\\,|1\\rangle\\langle1| + \\gamma\\,|0\\rangle\\langle0|.\n$$\n\n5. For $n$ independent uses,\n$$\n\\rho_1^{(n)} = \\sigma_1^{\\otimes n},\n$$\nand the crossover probability is\n$$\np_{1\\to0}\n= \\Tr\\bigl(P_{n,\\delta}(\\sigma_0)\\,\\rho_1^{(n)}\\bigr)\n= \\langle0^n|\\sigma_1^{\\otimes n}|0^n\\rangle\n= \\bigl\\langle0|\\sigma_1|0\\bigr\\rangle^n\n= \\gamma^n.\n$$", "answer": "$$\\boxed{\\gamma^n}$$", "id": "152064"}, {"introduction": "The direct coding theorem doesn't just promise that reliable communication is possible; it provides quantitative bounds on performance. This final practice demonstrates the theorem's practical power by using the random coding error exponent to estimate the minimum code blocklength $n$ needed to achieve a target error probability. By working through this problem for a Binary Erasure Channel, you'll see how abstract information-theoretic results translate into concrete engineering design parameters. [@problem_id:152123]", "problem": "The direct coding theorem in information theory states that for any communication rate $R$ below the channel capacity $C$, there exists a sequence of codes of blocklength $n$ for which the average probability of error $P_e^{(n)}$ decreases exponentially with $n$. A common upper bound on this error probability, derived from a random coding argument, is given by\n$$ P_e^{(n)} \\le \\exp(-n E_r(R_{nats})) $$\nwhere $E_r(R_{nats})$ is the random coding error exponent (or Gallager exponent) and $R_{nats} = R_{bits} \\ln 2$ is the rate in units of nats per channel use.\n\nConsider a Binary Erasure Channel (BEC), characterized by a single parameter $\\epsilon \\in [0, 1)$, the probability of erasure. An input bit $X \\in \\{0, 1\\}$ is transmitted correctly with probability $1-\\epsilon$, or is erased (replaced by a symbol $E$) with probability $\\epsilon$. The channel's transition probabilities are:\n$P(Y=0|X=0) = 1-\\epsilon$\n$P(Y=E|X=0) = \\epsilon$\n$P(Y=1|X=1) = 1-\\epsilon$\n$P(Y=E|X=1) = \\epsilon$\nAll other conditional probabilities are zero.\n\nThe capacity of this channel is $C = 1-\\epsilon$ bits per channel use, and this is achieved with a uniform input distribution, $\\pi(X=0) = \\pi(X=1) = 1/2$. For a general discrete memoryless channel, the random coding exponent for a given input distribution $\\pi(x)$ is given by:\n$$ E_r(R_{nats}) = \\max_{0 \\le \\rho \\le 1} \\left[ E_0(\\rho, \\pi) - \\rho R_{nats} \\right] $$\nwhere\n$$ E_0(\\rho, \\pi) = - \\ln \\sum_{y \\in \\mathcal{Y}} \\left( \\sum_{x \\in \\mathcal{X}} \\pi(x) P(y|x)^{\\frac{1}{1+\\rho}} \\right)^{1+\\rho} $$\nand $\\mathcal{X}$, $\\mathcal{Y}$ are the input and output alphabets respectively.\n\nYour task is to calculate the minimum required blocklength $n$ to transmit data through the BEC at a rate $R = C/2$ with an average error probability $P_e^{(n)}$ no greater than a specified value $\\delta$. Provide your answer as a symbolic expression in terms of the channel parameter $\\epsilon$ and the desired error tolerance $\\delta$. For simplicity, you may treat $n$ as a real number representing the lower bound, rather than restricting it to be an integer.", "solution": "1. For the BEC with uniform input $\\pi(0)=\\pi(1)=\\tfrac12$, the Gallager function is\n$$\nE_0(\\rho)\n=-\\ln\\sum_{y\\in\\{0,1,E\\}}\\Bigl(\\sum_{x\\in\\{0,1\\}}\\pi(x)P(y|x)^{\\frac1{1+\\rho}}\\Bigr)^{1+\\rho}.\n$$\nCompute the inner sums:\n\n$$\ny=0:\\quad \\sum_x\\pi(x)P(0|x)^{\\frac1{1+\\rho}}\n=\\tfrac12(1-\\epsilon)^{\\frac1{1+\\rho}}, \n\\quad\n(y=1\\text{ same}),\n$$\n\n\n$$\ny=E:\\quad \\sum_x\\pi(x)\\epsilon^{\\frac1{1+\\rho}}\n=\\epsilon^{\\frac1{1+\\rho}}.\n$$\n\nThus\n\n$$\n\\sum_y(\\cdots)^{1+\\rho}\n=2\\Bigl[\\tfrac12(1-\\epsilon)^{\\frac1{1+\\rho}}\\Bigr]^{1+\\rho}\n+\\bigl[\\epsilon^{\\frac1{1+\\rho}}\\bigr]^{1+\\rho}\n=2^{-(1+\\rho)}\\cdot2(1-\\epsilon)+\\epsilon\n=(1-\\epsilon)2^{-\\rho}+\\epsilon.\n$$\n\nHence\n\n$$\nE_0(\\rho)=-\\ln\\bigl[(1-\\epsilon)2^{-\\rho}+\\epsilon\\bigr].\n$$\n\n2. For rate $R=\\tfrac12C=\\tfrac12(1-\\epsilon)$ bits, in nats\n\n$$\nR_{\\text{nats}}=R\\ln2=\\tfrac{1-\\epsilon}{2}\\ln2.\n$$\n\nThe random-coding exponent is\n\n$$\nE_r(R_{\\text{nats}})\n=\\max_{0\\le\\rho\\le1}\\Bigl\\{E_0(\\rho)-\\rho\\,R_{\\text{nats}}\\Bigr\\}.\n$$\n\nThe unconstrained optimizer solves\n\n$$\n\\frac{d}{d\\rho}\\bigl[-\\ln((1-\\epsilon)2^{-\\rho}+\\epsilon)-\\rho R_{\\text{nats}}\\bigr]=0\n\\;\\Longrightarrow\\;\n2^{-\\rho}=\\frac{\\epsilon}{1+\\epsilon},\n$$\n\ngiving $\\rho^*=\\log_2\\frac{1+\\epsilon}{\\epsilon}>1$.  Thus on $[0,1]$ the maximum is at $\\rho=1$:\n\n$$\nE_r\n=E_0(1)-1\\cdot R_{\\text{nats}}\n=-\\ln\\Bigl[\\tfrac{1-\\epsilon}{2}+\\epsilon\\Bigr]\n-\\tfrac{1-\\epsilon}{2}\\ln2\n=-\\ln\\Bigl(\\frac{1+\\epsilon}{2}\\Bigr) - \\frac{1-\\epsilon}{2}\\ln2\n=\\frac{1+\\epsilon}{2}\\ln2-\\ln(1+\\epsilon).\n$$\n\n3. The error bound $P_e^{(n)}\\le e^{-nE_r}$ implies to achieve $P_e^{(n)}\\le\\delta$,\n\n$$\ne^{-nE_r}\\le\\delta\n\\;\\Longrightarrow\\;\nn\\ge\\frac{\\ln(1/\\delta)}{E_r}\n=\\frac{\\ln(1/\\delta)}{\\frac{1+\\epsilon}{2}\\ln2-\\ln(1+\\epsilon)}.\n$$", "answer": "$$\\boxed{\\frac{\\ln\\!\\bigl(1/\\delta\\bigr)}{\\tfrac{1+\\epsilon}{2}\\ln2-\\ln(1+\\epsilon)}}$$", "id": "152123"}]}