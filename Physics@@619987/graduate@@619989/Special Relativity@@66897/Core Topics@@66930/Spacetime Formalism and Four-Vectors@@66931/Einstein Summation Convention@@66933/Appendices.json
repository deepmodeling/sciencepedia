{"hands_on_practices": [{"introduction": "To begin our journey with the Einstein summation convention, we start with its most fundamental building block: the Kronecker delta, $\\delta_{ij}$. This exercise [@problem_id:1833058] provides essential practice in applying the core rule of summing over repeated indices, a process known as contraction. By calculating the full contraction of two Kronecker delta symbols, you will discover a simple but profound result that directly relates to the dimensionality of the space you are working in.", "problem": "In the context of linear algebra and tensor analysis in Euclidean space, the Einstein summation convention is a notational shortcut where summation over a set of indexed terms is implicitly assumed when an index variable appears twice in a single term, once as a subscript and once as a superscript. The sum is taken over all possible integer values of the index, which is determined by the dimension of the space.\n\nA fundamental tool in this notation is the Kronecker delta. In a Cartesian coordinate system, its components can be written with either upper or lower indices, and are defined as:\n$$\n\\delta_{ij} = \\delta^{ij} = \\delta^{i}_{j} = \\begin{cases} 1  \\text{if } i = j \\\\ 0  \\text{if } i \\neq j \\end{cases}\n$$\nConsider a 3-dimensional Euclidean space, where all indices (such as $i$ and $j$) can take on the integer values 1, 2, or 3.\n\nUsing the Einstein summation convention, calculate the numerical value of the scalar quantity $\\delta_{ij}\\delta^{ij}$.", "solution": "The quantity we need to compute is $\\delta_{ij}\\delta^{ij}$. The Einstein summation convention implies that we must sum over both index $i$ and index $j$ because each appears twice in the expression (once as a subscript and once as a superscript, although in this Euclidean context the position does not change the value of the Kronecker delta). Since the space is 3-dimensional, the indices $i$ and $j$ range from 1 to 3.\n\nThe expression $\\delta_{ij}\\delta^{ij}$ is a concise way of writing the double summation:\n$$\n\\delta_{ij}\\delta^{ij} = \\sum_{i=1}^{3} \\sum_{j=1}^{3} \\delta_{ij} \\delta^{ij}\n$$\nThe problem statement gives the definition of the Kronecker delta, $\\delta_{ij}$, which is 1 if $i=j$ and 0 if $i \\neq j$. The same definition applies to $\\delta^{ij}$. Therefore, the product $\\delta_{ij}\\delta^{ij}$ is non-zero only when the condition $i=j$ is met. If $i \\neq j$, then $\\delta_{ij}=0$, and the term $\\delta_{ij}\\delta^{ij}$ becomes $0 \\cdot \\delta^{ij} = 0$.\n\nConsequently, we only need to sum the terms for which $i=j$:\n$$\n\\delta_{ij}\\delta^{ij} = \\sum_{i=j} \\delta_{ij} \\delta^{ij} = \\delta_{11}\\delta^{11} + \\delta_{22}\\delta^{22} + \\delta_{33}\\delta^{33}\n$$\nAll other terms in the nine-term expansion of the double sum, such as $\\delta_{12}\\delta^{12}$ or $\\delta_{21}\\delta^{21}$, are zero.\n\nAccording to the definition of the Kronecker delta:\n$\\delta_{11} = 1$ and $\\delta^{11} = 1$\n$\\delta_{22} = 1$ and $\\delta^{22} = 1$\n$\\delta_{33} = 1$ and $\\delta^{33} = 1$\n\nSubstituting these values into our sum:\n$$\n\\delta_{ij}\\delta^{ij} = (1)(1) + (1)(1) + (1)(1) = 1 + 1 + 1 = 3\n$$\nAlternatively, we can perform the summation one index at a time. Let's first sum over $j$:\n$$\n\\delta_{ij}\\delta^{ij} = \\sum_{i=1}^{3} \\left( \\sum_{j=1}^{3} \\delta_{ij} \\delta^{ij} \\right)\n$$\nConsider the inner sum $\\sum_{j=1}^{3} \\delta_{ij} \\delta^{ij}$ for a fixed value of $i$. This sum expands to:\n$$\n\\delta_{i1}\\delta^{i1} + \\delta_{i2}\\delta^{i2} + \\delta_{i3}\\delta^{i3}\n$$\nFor a fixed $i$, only one of the terms $\\delta_{i1}, \\delta_{i2}, \\delta_{i3}$ is non-zero. Specifically, $\\delta_{ij}$ is 1 only when $j=i$. So, the sum simplifies to just the term where $j=i$:\n$$\n\\sum_{j=1}^{3} \\delta_{ij} \\delta^{ij} = \\delta_{ii}\\delta^{ii} = (1)(1) = 1\n$$\nThis result holds for any choice of $i \\in \\{1, 2, 3\\}$. Now, we substitute this result back into the outer sum over $i$:\n$$\n\\delta_{ij}\\delta^{ij} = \\sum_{i=1}^{3} (1) = 1 + 1 + 1 = 3\n$$\nBoth methods yield the same result. The value of the expression is the dimension of the space, which is a common result for such contractions of the Kronecker delta.", "answer": "$$\\boxed{3}$$", "id": "1833058"}, {"introduction": "Once you are comfortable with the mechanics of index summation, we can explore how this notation elegantly describes the fundamental properties of tensors. This problem [@problem_id:385677] challenges you to use the definitions of symmetry ($T^{\\mu\\nu} = T^{\\nu\\mu}$) and tracelessness ($T^\\mu_\\mu = 0$) to determine the number of independent components in a rank-2 tensor. This practice is not just a mathematical exercise; it reveals the true degrees of freedom for many important physical quantities, such as the stress-energy tensor in general relativity.", "problem": "In a $D$-dimensional real vector space equipped with a non-degenerate metric $g_{\\mu\\nu}$, a rank-2 tensor is an object that transforms according to specific rules under a change of coordinates. The components of such a tensor can be written as $T^{\\mu\\nu}$ or $T_{\\mu\\nu}$, where the indices $\\mu, \\nu$ run from $0$ to $D-1$.\n\nConsider a contravariant rank-2 tensor $T^{\\mu\\nu}$ that possesses the following two properties:\n1.  **Symmetry:** The tensor is symmetric under the exchange of its indices, i.e., $T^{\\mu\\nu} = T^{\\nu\\mu}$.\n2.  **Tracelessness:** The trace of the mixed tensor $T^\\mu_\\nu \\equiv g_{\\nu\\lambda}T^{\\mu\\lambda}$ is zero. Using the Einstein summation convention, this condition is written as $T^\\mu_\\mu = 0$.\n\nCalculate the number of independent components of such a tensor $T^{\\mu\\nu}$ as a function of the spacetime dimension $D$.", "solution": "1. A general rank-2 contravariant tensor $T^{\\mu\\nu}$ in $D$ dimensions has $D^2$ components.\n\n2. Imposing symmetry $T^{\\mu\\nu}=T^{\\nu\\mu}$ reduces the count to $N_{\\text{sym}}=\\frac{D(D+1)}{2}$.\n\n3. Tracelessness is the single condition $T^\\mu_{\\ \\mu}=g_{\\mu\\nu}T^{\\mu\\nu}=0$, which removes one independent component.\n\n4. Therefore the number of independent components is\n$$N_{\\text{indep}} =N_{\\text{sym}}-1 =\\frac{D(D+1)}{2}-1 =\\frac{D^2+D-2}{2} =\\frac{(D-1)(D+2)}{2}.$$", "answer": "$$\\boxed{\\frac{(D-1)(D+2)}{2}}$$", "id": "385677"}, {"introduction": "Now, we apply our skills to the domain where the Einstein summation convention truly shines: relativistic physics. In this exercise [@problem_id:385712], you will calculate the four-divergence, $\\partial_\\mu V^\\mu$, of a vector field in Minkowski spacetime, a common operation in electrodynamics and field theory. This task requires combining the product rule of differentiation with the rules of index manipulation, showcasing how this powerful notation streamlines complex calculus in four dimensions.", "problem": "In four-dimensional Minkowski spacetime, let the spacetime coordinates be denoted by the four-vector $x^\\mu = (x^0, x^1, x^2, x^3)$, where $x^0$ is the time coordinate multiplied by the speed of light $c$. The Einstein summation convention is implied for repeated upper and lower indices.\n\nLet $k^\\mu$ be a constant four-vector, meaning its components are independent of the spacetime coordinates $x^\\nu$. The covariant components of this vector are given by $k_\\mu = \\eta_{\\mu\\nu}k^\\nu$, where $\\eta_{\\mu\\nu}$ is the Minkowski metric tensor.\n\nConsider the four-vector field $V^\\mu(x)$ defined as:\n$$ V^\\mu(x) = (k_\\alpha x^\\alpha) x^\\mu $$\nThis field is a product of the scalar field $\\phi(x) = k_\\alpha x^\\alpha$ and the position four-vector $x^\\mu$.\n\nYour task is to calculate the four-divergence of this vector field, $\\partial_\\mu V^\\mu$, where $\\partial_\\mu = \\frac{\\partial}{\\partial x^\\mu}$ is the four-gradient operator. Express your answer as a scalar function of $k_\\mu$ and $x^\\mu$.", "solution": "We wish to compute $\\partial_\\mu V^\\mu$, where $V^\\mu=(k_\\alpha x^\\alpha)\\,x^\\mu$.\n\n1.  Write $V^\\mu=\\phi\\,x^\\mu$ with $\\phi=k_\\alpha x^\\alpha$. Then  \n$$\\partial_\\mu V^\\mu =\\partial_\\mu(\\phi\\,x^\\mu) =(\\partial_\\mu\\phi)\\,x^\\mu+\\phi\\,\\partial_\\mu x^\\mu.$$\n\n2.  Compute the derivatives:  \n$$\\partial_\\mu\\phi =\\partial_\\mu(k_\\alpha x^\\alpha) =k_\\alpha\\partial_\\mu x^\\alpha =k_\\alpha\\delta^\\alpha_\\mu =k_\\mu,$$\n$$\\partial_\\mu x^\\mu=\\delta^\\mu_\\mu=4.$$\n\n3.  Substitute back:  \n$$\\partial_\\mu V^\\mu =x^\\mu k_\\mu+4\\,(k_\\alpha x^\\alpha) =(1+4)\\,k_\\alpha x^\\alpha =5\\,k_\\alpha x^\\alpha.$$", "answer": "$$\\boxed{5\\,k_\\mu x^\\mu}$$", "id": "385712"}]}