{"hands_on_practices": [{"introduction": "The most fundamental model of a random point process is the Poisson process, characterized by the statistical independence of its points. This first exercise provides a gentle entry point by calculating the variance of a simple linear statistic, the \"center of mass,\" without yet invoking the full machinery of correlation functions. By applying the law of total variance, this problem reinforces core probabilistic reasoning and builds intuition for the statistical properties of point distributions [@problem_id:884093].", "problem": "Consider a one-dimensional homogeneous Poisson point process on the interval $[0, L]$. The process is characterized by a constant density $\\lambda > 0$. This means that for any subinterval of length $\\ell \\le L$, the number of points falling within it follows a Poisson distribution with mean $\\lambda \\ell$, and the numbers of points in disjoint subintervals are independent random variables.\n\nLet the total number of points in the interval $[0, L]$ be denoted by the random variable $N$, and their positions by $x_1, x_2, \\dots, x_N$. A key property of the homogeneous Poisson process is that, conditional on there being $N=n$ points in $[0, L]$, their positions $x_1, \\dots, x_n$ are independent and identically distributed random variables, drawn from a uniform distribution on $[0, L]$.\n\nWe define a statistic $C$, which is the sum of the positions of all points in the process:\n$$\nC = \\sum_{i=1}^{N} x_i\n$$\nIf $N=0$, the sum is empty and $C=0$.\n\nYour task is to calculate the variance of this statistic, $\\text{Var}(C)$, as a function of the parameters $\\lambda$ and $L$.", "solution": "1. Relevant equations  \nBy the law of total variance,  \n$$\n\\mathrm{Var}(C)=\\mathbb{E}[\\mathrm{Var}(C\\mid N)]+\\mathrm{Var}(\\mathbb{E}[C\\mid N]).\n$$\nConditional on $N=n$, the $x_i$ are i.i.d.\\ Uniform$(0,L)$, so  \n$$\n\\mathbb{E}[C\\mid N=n]=n\\frac{L}{2},\\qquad\n\\mathrm{Var}(C\\mid N=n)=n\\frac{L^2}{12}.\n$$\n\n2. Compute each term  \nSince $N\\sim\\mathrm{Poisson}(\\lambda L)$, $\\mathbb{E}[N]=\\mathrm{Var}(N)=\\lambda L$.  \n$$\n\\mathbb{E}[\\mathrm{Var}(C\\mid N)]\n=\\mathbb{E}\\Bigl[N\\frac{L^2}{12}\\Bigr]\n=\\frac{L^2}{12}\\,\\mathbb{E}[N]\n=\\frac{\\lambda L^3}{12},\n$$\n$$\n\\mathrm{Var}(\\mathbb{E}[C\\mid N])\n=\\mathrm{Var}\\Bigl[N\\frac{L}{2}\\Bigr]\n=\\frac{L^2}{4}\\,\\mathrm{Var}(N)\n=\\frac{\\lambda L^3}{4}.\n$$\n\n3. Sum to get the total variance  \n$$\n\\mathrm{Var}(C)\n=\\frac{\\lambda L^3}{12}+\\frac{\\lambda L^3}{4}\n=\\lambda L^3\\Bigl(\\frac{1}{12}+\\frac{3}{12}\\Bigr)\n=\\frac{4\\lambda L^3}{12} = \\frac{\\lambda L^3}{3}.\n$$", "answer": "$$\\boxed{\\frac{\\lambda L^3}{3}}$$", "id": "884093"}, {"introduction": "While the previous exercise relied on conditional probability, a more powerful and general approach uses N-point correlation functions. This practice introduces this formalism directly by asking you to calculate the number variance, $\\Sigma^{2}(L)$, for a non-homogeneous Poisson process. This exercise demonstrates the fundamental relationship between the correlation functions ($R_1$ and $R_2$) and number statistics, and it confirms the hallmark property of any Poisson process: the variance of the count equals its mean [@problem_id:884179].", "problem": "A one-dimensional non-homogeneous Poisson process is a random point process on the real line characterized by a position-dependent intensity function (or density) $\\rho(x)$. For such a process, the positions of the points are statistically independent, which implies that the two-point correlation function is separable and given by $R_2(x_1, x_2) = \\rho(x_1)\\rho(x_2)$.\n\nThe mean number of points, $\\langle N(L) \\rangle$, in an interval $[0, L]$ is given by the integral of the one-point correlation function $R_1(x) = \\rho(x)$ over that interval. The number variance, $\\Sigma^2(L) = \\langle N(L)^2 \\rangle - \\langle N(L) \\rangle^2$, quantifies the fluctuations in the number of points and can be calculated from the one- and two-point correlation functions using the general formula:\n$$ \\Sigma^2(L) = \\int_0^L R_1(x) dx + \\int_0^L \\int_0^L R_2(x_1, x_2) dx_1 dx_2 - \\left( \\int_0^L R_1(x) dx \\right)^2 $$\n\nConsider a non-homogeneous Poisson process on the positive real line defined by a density function $\\rho(x) = C x$ for $x \\ge 0$, where $C$ is a positive constant.\n\nUsing the formalism of correlation functions provided above, calculate the number variance $\\Sigma^2(L)$ for the number of points in the interval $[0, L]$.", "solution": "The problem asks for the number variance $\\Sigma^2(L)$ in the interval $[0, L]$ for a non-homogeneous Poisson process with density $\\rho(x) = C x$. The variance is to be calculated using the provided formula relating it to the correlation functions.\n\nThe given formula for the number variance is:\n$$ \\Sigma^2(L) = \\int_0^L R_1(x) dx + \\int_0^L \\int_0^L R_2(x_1, x_2) dx_1 dx_2 - \\left( \\int_0^L R_1(x) dx \\right)^2 $$\n\nFirst, we identify the necessary correlation functions based on the given density $\\rho(x) = C x$.\n\nThe one-point correlation function is simply the density itself:\n$R_1(x) = \\rho(x) = C x$\n\nFor a non-homogeneous Poisson process, the two-point correlation function is the product of the densities at the two points:\n$R_2(x_1, x_2) = \\rho(x_1) \\rho(x_2) = (C x_1)(C x_2) = C^2 x_1 x_2$\n\nNow, let's compute the integrals appearing in the formula for $\\Sigma^2(L)$.\n\nThe first term is the single integral of $R_1(x)$:\n$$ \\int_0^L R_1(x) dx = \\int_0^L C x \\,dx $$\nThis integral evaluates to:\n$$ C \\left[ \\frac{x^2}{2} \\right]_0^L = C \\left(\\frac{L^2}{2} - 0\\right) = \\frac{C L^2}{2} $$\nThis term also corresponds to the mean number of points, $\\langle N(L) \\rangle$.\n\nThe second term is the double integral of $R_2(x_1, x_2)$:\n$$ \\int_0^L \\int_0^L R_2(x_1, x_2) dx_1 dx_2 = \\int_0^L \\int_0^L C^2 x_1 x_2 \\,dx_1 dx_2 $$\nSince the integrand and the integration limits are separable, we can write the double integral as a product of two identical single integrals:\n$$ = C^2 \\left( \\int_0^L x_1 \\,dx_1 \\right) \\left( \\int_0^L x_2 \\,dx_2 \\right) $$\nEach integral evaluates to:\n$$ \\int_0^L x \\,dx = \\left[ \\frac{x^2}{2} \\right]_0^L = \\frac{L^2}{2} $$\nTherefore, the double integral is:\n$$ C^2 \\left( \\frac{L^2}{2} \\right) \\left( \\frac{L^2}{2} \\right) = \\frac{C^2 L^4}{4} $$\n\nThe third term in the variance formula is the square of the first integral:\n$$ \\left( \\int_0^L R_1(x) dx \\right)^2 = \\left( \\frac{C L^2}{2} \\right)^2 = \\frac{C^2 L^4}{4} $$\n\nNow, we substitute these results back into the expression for $\\Sigma^2(L)$:\n$$ \\Sigma^2(L) = \\left(\\frac{C L^2}{2}\\right) + \\left(\\frac{C^2 L^4}{4}\\right) - \\left(\\frac{C^2 L^4}{4}\\right) $$\nThe second and third terms cancel out, leaving:\n$$ \\Sigma^2(L) = \\frac{C L^2}{2} $$\n\nThis result is consistent with the well-known property of all Poisson processes (both homogeneous and non-homogeneous) that the variance of the number of counts in any region is equal to the mean number of counts in that region. Here, $\\langle N(L) \\rangle = \\int_0^L \\rho(x) dx = \\frac{CL^2}{2}$, so we have confirmed that $\\Sigma^2(L) = \\langle N(L) \\rangle$.", "answer": "$$ \\boxed{\\frac{C L^2}{2}} $$", "id": "884179"}, {"introduction": "The true power of correlation functions becomes apparent when analyzing systems with non-trivial interactions between points, such as the eigenvalues of random matrices, which exhibit strong correlations. This final exercise moves from the uncorrelated Poisson world to the highly structured Circular Unitary Ensemble (CUE), a key model in quantum chaos. You will compute the variance of a linear statistic by integrating the CUE's two-point correlation function, directly engaging with the mathematical signature of \"level repulsion\" that characterizes such systems [@problem_id:884143].", "problem": "In the study of quantum chaotic systems, the statistics of energy levels are often modeled by the eigenvalues of large random matrices. For systems with time-reversal symmetry broken, the Circular Unitary Ensemble (CUE) is of particular importance. The eigenvalues of an $N \\times N$ CUE matrix lie on the unit circle and can be written as $e^{i\\theta_j}$ for $j=1, \\dots, N$, where the eigenphases $\\theta_j$ are in the interval $[0, 2\\pi)$.\n\nThe statistical properties of these eigenphases are described by their correlation functions. For large $N$, the one-point correlation function, which gives the density of eigenphases, is uniform:\n$$R_1(\\theta) = \\left\\langle \\sum_{j=1}^N \\delta(\\theta - \\theta_j) \\right\\rangle = \\frac{N}{2\\pi}$$\nwhere $\\langle \\cdot \\rangle$ denotes the ensemble average.\n\nThe two-point correlation function is given by:\n$$R_2(\\theta_1, \\theta_2) = \\left\\langle \\sum_{i \\ne j}^N \\delta(\\theta_1 - \\theta_i) \\delta(\\theta_2 - \\theta_j) \\right\\rangle = \\left(\\frac{N}{2\\pi}\\right)^2 \\left(1 - \\frac{\\sin^2(N(\\theta_1-\\theta_2)/2)}{N^2 \\sin^2((\\theta_1-\\theta_2)/2)}\\right)$$\nThe kernel appearing in this expression has a well-known Fourier series representation:\n$$\\left(\\frac{\\sin(Nx/2)}{\\sin(x/2)}\\right)^2 = \\sum_{m=-(N-1)}^{N-1} (N-|m|)e^{imx}$$\nConsider the linear statistic $A_k = \\sum_{j=1}^N \\cos^2(k \\theta_j)$, where $k$ is a positive integer. Calculate the variance of this statistic, $\\text{Var}(A_k)$, in the limit of large matrix size $N \\to \\infty$, under the assumption that $k$ is a fixed integer much smaller than $N$ (specifically, $2k  N$). What is the value of $\\text{Var}(A_k)$?", "solution": "We wish to compute the variance of $A_k=\\sum_{j=1}^N\\cos^2(k\\theta_j)$, which is $\\mathrm{Var}(A_k)=\\langle A_k^2\\rangle-\\langle A_k\\rangle^2$, for the CUE in the limit $N\\to\\infty$ with fixed $k\\ll N$.  \n\n1.  Rewrite the observable. Using $\\cos^2(k\\theta)=\\frac{1+\\cos(2k\\theta)}{2}$, we define $S=\\sum_{j=1}^N\\cos(2k\\theta_j)$. Then, $A_k=\\frac{N}{2}+\\frac{1}{2}\\,S$. Hence, $\\mathrm{Var}(A_k)=\\frac{1}{4}\\,\\mathrm{Var}(S)$, since $\\langle S\\rangle=0$.\n\n2.  Variance of a linear statistic. For a general linear statistic $S=\\sum_j f(\\theta_j)$, the variance is given by\n$$\\mathrm{Var}(S)\n=\\int_0^{2\\pi}f(\\theta)^2R_1(\\theta)\\,d\\theta\n+\\iint_0^{2\\pi}f(\\theta)f(\\phi)\\,R_2(\\theta,\\phi)\\,d\\theta\\,d\\phi\n-\\Bigl[\\int_0^{2\\pi}f(\\theta)R_1(\\theta)\\,d\\theta\\Bigr]^2.$$\nHere $f(\\theta)=\\cos(2k\\theta)$, $R_1(\\theta)=N/(2\\pi)$, and \n$$R_2(\\theta,\\phi)=\\Bigl(\\frac N{2\\pi}\\Bigr)^2\n\\Bigl[1-\\frac{\\sin^2\\bigl(\\tfrac N2(\\theta-\\phi)\\bigr)}\n{N^2\\sin^2\\bigl(\\tfrac12(\\theta-\\phi)\\bigr)}\\Bigr].$$\nThe third term vanishes because $\\int \\cos(2k\\theta) d\\theta = 0$.\n\n3.  Compute the one‐point term:\n$$T_1=\\int_0^{2\\pi}\\cos^2(2k\\theta)\\,\\frac N{2\\pi}\\,d\\theta\n=\\frac N{2\\pi}\\cdot\\pi=\\frac N2.$$\n\n4.  Compute the two‐point term. Let $T_2=\\iint_0^{2\\pi}\\cos(2k\\theta)\\cos(2k\\phi)\\,R_2(\\theta,\\phi)\\,d\\theta\\,d\\phi$. Substituting the expression for $R_2$, the integral involving the constant term `1` vanishes due to orthogonality. We are left with\n$$T_2=-\\left(\\frac{N}{2\\pi}\\right)^2 \\frac{1}{N^2} \\iint_0^{2\\pi}\\cos(2k\\theta)\\cos(2k\\phi)\\frac{\\sin^2\\bigl(\\tfrac N2(\\theta-\\phi)\\bigr)}{\\sin^2\\bigl(\\tfrac12(\\theta-\\phi)\\bigr)}\\,d\\theta d\\phi$$\nWe use the Fourier series for the kernel: $\\frac{\\sin^2(\\tfrac{N}2u)}{\\sin^2(\\tfrac12u)} = \\sum_{m=-(N-1)}^{N-1}(N-|m|)\\,e^{imu}$.\nLet $u=\\theta-\\phi$. The integral can be shown to depend only on $u$.\n$$T_2=-\\frac{1}{4\\pi^2}\\int_0^{2\\pi} \\left(\\pi \\cos(2ku)\\right) \\left(\\sum_{m=-(N-1)}^{N-1}(N-|m|)\\,e^{imu}\\right) du$$\nUsing $\\cos(2ku) = \\frac{e^{i2ku} + e^{-i2ku}}{2}$ and orthogonality, only the terms $m=\\pm 2k$ contribute.\n$$T_2=-\\frac{1}{4\\pi} \\int_0^{2\\pi} \\left(\\frac{e^{i2ku} + e^{-i2ku}}{2}\\right) \\left((N-2k)e^{-i2ku} + (N-2k)e^{i2ku}\\right) du$$\nSince $2k  N$, $|m|=2k  N$.\n$$T_2=-\\frac{1}{4\\pi} \\left( \\frac{1}{2} (N-2k) (2\\pi) + \\frac{1}{2} (N-2k) (2\\pi) \\right) = -\\frac{1}{2}(N-2k)$$\n\n5.  Combine terms:\n$$\\mathrm{Var}(S)=T_1+T_2=\\frac{N}{2}-\\frac{1}{2}(N-2k)=k$$\nand finally\n$$\\mathrm{Var}(A_k)=\\frac{1}{4}\\,\\mathrm{Var}(S)=\\frac k4$$", "answer": "$$\\boxed{\\frac{k}{4}}$$", "id": "884143"}]}