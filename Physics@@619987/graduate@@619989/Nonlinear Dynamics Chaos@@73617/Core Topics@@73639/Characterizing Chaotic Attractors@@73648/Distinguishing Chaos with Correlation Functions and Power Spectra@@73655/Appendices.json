{"hands_on_practices": [{"introduction": "Before analyzing the complex time series from continuous chaotic systems, it is instructive to explore correlation functions in a simpler setting. Symbolic dynamics provides a powerful bridge by coarse-graining the phase space into a sequence of symbols, which can often be modeled as a Markov process. This exercise provides foundational practice by asking you to compute the one-step autocorrelation, $C(1)$, from the underlying transition probabilities of such a system [@problem_id:864169].", "problem": "In the study of nonlinear dynamics, complex, chaotic behavior of a system evolving in continuous phase space can often be simplified by using **symbolic dynamics**. This is achieved by partitioning the phase space into a finite number of regions, each labeled by a symbol. The time evolution of the system is then represented by a sequence of these symbols. For certain chaotic maps, this symbolic sequence can be well-approximated by a Markov process.\n\nConsider a two-state Markov chain describing the symbolic dynamics of a system. The states are represented by symbols $S_0$ and $S_1$, which are mapped to numerical values $x \\in \\{-1, +1\\}$, with $S_0 \\to -1$ and $S_1 \\to +1$. The transition probabilities are given by the stochastic matrix $P$:\n$$\nP = \\begin{pmatrix} P_{00} & P_{01} \\\\ P_{10} & P_{11} \\end{pmatrix} = \\begin{pmatrix} p & 1-p \\\\ 1-q & q \\end{pmatrix}\n$$\nHere, $p$ is the probability of staying in state $S_0$ (i.e., transitioning from $S_0$ to $S_0$), and $q$ is the probability of staying in state $S_1$. The parameters $p$ and $q$ are constants with $0 \\le p \\le 1$ and $0 \\le q \\le 1$, and we assume the process is ergodic (i.e., it is not the case that $p=1$ and $q=1$ simultaneously).\n\nFor a stationary time series $\\{x_n\\}$ generated by this process, the autocorrelation function is defined as:\n$$\nC(k) = \\langle x_n x_{n+k} \\rangle - \\langle x_n \\rangle \\langle x_{n+k} \\rangle\n$$\nwhere $\\langle \\cdot \\rangle$ denotes the expectation value in the stationary state. Due to stationarity, $\\langle x_n \\rangle = \\langle x_{n+k} \\rangle = \\langle x \\rangle$.\n\nYour task is to calculate the one-step autocorrelation function, $C(1)$, for this system. Express your answer in terms of the parameters $p$ and $q$.", "solution": "1. Stationary distribution π satisfies π = πP and π₀+π₁=1.  Solving\n   $$\\pi_0=\\pi_0\\,p+\\pi_1\\,(1-q),\\qquad \\pi_1=1-\\pi_0$$\n   gives\n   $$\\pi_0=\\frac{1-q}{2-p-q},\\qquad \\pi_1=\\frac{1-p}{2-p-q}.$$\n\n2. Mean value\n   $$\\langle x\\rangle=\\pi_1\\,(+1)+\\pi_0\\,(-1)=\\frac{(1-p)-(1-q)}{2-p-q}\n   =\\frac{q-p}{2-p-q}.$$\n\n3. One-step moment\n   $$\\langle x_nx_{n+1}\\rangle\n   =\\sum_{i,j}x_i\\,x_j\\,\\pi_iP_{ij}\n   =\\pi_0\\,(2p-1)+\\pi_1\\,(2q-1)\n   =\\frac{3(p+q)-4pq-2}{2-p-q}.$$\n\n4. Hence the autocovariance\n   $$C(1)=\\langle x_nx_{n+1}\\rangle-\\langle x\\rangle^2\n   =\\frac{3(p+q)-4pq-2}{2-p-q}\n    -\\Bigl(\\frac{q-p}{2-p-q}\\Bigr)^2.$$\n\n5. Equivalently, using the second eigenvalue $\\lambda=p+q-1$ and $\\text{Var}(x)=1-\\langle x\\rangle^2$,\n   $$C(1)=\\lambda\\bigl(1-\\langle x\\rangle^2\\bigr)\n   =(p+q-1)\\Bigl(1-\\frac{(q-p)^2}{(2-p-q)^2}\\Bigr)\n   =\\frac{4(1-p)(1-q)(p+q-1)}{(2-p-q)^2}.$$", "answer": "$$\\boxed{\\frac{4(1-p)(1-q)(p+q-1)}{(2-p-q)^2}}$$", "id": "864169"}, {"introduction": "Chaotic systems are characterized by broadband power spectra, in contrast to the discrete lines of periodic signals. The total power, found by integrating the power spectrum, corresponds to the signal's variance, which is equivalent to the autocorrelation function at lag zero, $C(0)$. This practice applies this principle to the logistic map at full chaos ($r=4$), where you will calculate the variance from its known invariant probability density function, solidifying the link between the attractor's statistical properties and the signal's power [@problem_id:864192].", "problem": "In the study of nonlinear dynamical systems, the power spectrum is a crucial tool for distinguishing between different types of behavior, such as periodic, quasiperiodic, and chaotic motion. For a time series $\\{x_n\\}$ generated by a discrete map, the power spectrum $S(\\omega)$ reveals the frequency content of the dynamics. While periodic and quasiperiodic systems exhibit power spectra with discrete delta-function peaks, chaotic systems are characterized by continuous, broadband spectra.\n\nThe total power, obtained by integrating the power spectrum over all frequencies, is related to the autocorrelation function $C(k) = \\langle (x_{n+k} - \\langle x \\rangle)(x_n - \\langle x \\rangle) \\rangle$ at lag $k=0$. Specifically, for a stationary process, the total integrated power is proportional to the variance of the signal, $C(0) = \\text{Var}(x)$.\n\nFor an ergodic system, the time average $\\langle \\cdot \\rangle$ can be replaced by an ensemble average over the invariant probability density function, $\\rho(x)$. The variance is then given by:\n$$\n\\text{Var}(x) = \\langle (x - \\langle x \\rangle)^2 \\rangle = \\int (x - \\langle x \\rangle)^2 \\rho(x) dx\n$$\nwhere $\\langle x \\rangle = \\int x' \\rho(x') dx'$.\n\nConsider the logistic map, a classic example of a system exhibiting chaos, defined by the recurrence relation:\n$$\nx_{n+1} = r x_n (1 - x_n)\n$$\nwith $x_n \\in [0, 1]$. At the parameter value $r=4$, the system is in a fully chaotic state. For this specific case, the invariant probability density function $\\rho(x)$ for the state variable $x$ on the interval $(0, 1)$ is known to be:\n$$\n\\rho(x) = \\frac{1}{\\pi\\sqrt{x(1-x)}}\n$$\nYour task is to compute the total integrated power for the logistic map at $r=4$. As established, this is equivalent to calculating the variance of $x$ with respect to its invariant density.", "solution": "We wish to compute \n$$\n\\text{Var}(x)=\\int_0^1 (x-\\langle x\\rangle)^2\\,\\rho(x)\\,dx,\n$$ \nwith \n$$\n\\rho(x)=\\frac1{\\pi\\sqrt{x(1-x)}}, \n\\qquad \\langle x\\rangle=\\int_0^1 x\\,\\rho(x)\\,dx.\n$$\n\n1. Compute the mean $\\langle x\\rangle$ via the Beta integral.  Define\n$$\nE[x^n]=\\int_0^1 x^n\\,\\rho(x)\\,dx\n=\\frac1\\pi\\int_0^1 x^n\\,x^{-\\tfrac12}(1-x)^{-\\tfrac12}dx\n=\\frac1\\pi B\\bigl(n+\\tfrac12,\\tfrac12\\bigr).\n$$\nFor $n=1$,\n$$\n\\langle x\\rangle=E[x]\n=\\frac1\\pi B\\bigl(\\tfrac32,\\tfrac12\\bigr)\n=\\frac1\\pi\\frac{\\Gamma(\\tfrac32)\\,\\Gamma(\\tfrac12)}{\\Gamma(2)}.\n$$\nUsing $\\Gamma(\\tfrac12)=\\sqrt\\pi$ and $\\Gamma(\\tfrac32)=\\tfrac12\\sqrt\\pi$, \n$$\nB\\bigl(\\tfrac32,\\tfrac12\\bigr)\n=\\frac{\\tfrac12\\sqrt\\pi\\cdot\\sqrt\\pi}{1}\n=\\frac{\\pi}{2},\n$$\nso \n$$\n\\langle x\\rangle=\\frac1\\pi\\cdot\\frac{\\pi}{2}=\\frac12.\n$$\n\n2. Compute $E[x^2]$ similarly:\n$$\nE[x^2]\n=\\frac1\\pi B\\bigl(\\tfrac52,\\tfrac12\\bigr)\n=\\frac1\\pi\\frac{\\Gamma(\\tfrac52)\\,\\Gamma(\\tfrac12)}{\\Gamma(3)}.\n$$\nUsing $\\Gamma(\\tfrac52)=\\tfrac32\\cdot\\tfrac12\\sqrt\\pi=\\tfrac{3}{4}\\sqrt\\pi$ and $\\Gamma(3)=2$,\n$$\nB\\bigl(\\tfrac52,\\tfrac12\\bigr)\n=\\frac{\\tfrac{3}{4}\\sqrt\\pi\\cdot\\sqrt\\pi}{2}\n=\\frac{3\\pi}{8},\n$$\nhence\n$$\nE[x^2]=\\frac1\\pi\\cdot\\frac{3\\pi}{8}=\\frac{3}{8}.\n$$\n\n3. Therefore the variance is\n$$\n\\text{Var}(x)=E[x^2]-\\bigl(E[x]\\bigr)^2\n=\\frac{3}{8}-\\Bigl(\\frac12\\Bigr)^2\n=\\frac{3}{8}-\\frac{1}{4}\n=\\frac{1}{8}.\n$$", "answer": "$$\\boxed{1/8}$$", "id": "864192"}, {"introduction": "A central challenge in time series analysis is distinguishing deterministic chaos from a purely stochastic process. While a chaotic signal is deterministic, it can appear random and exhibit decaying correlations, much like a stochastic autoregressive (AR) process. In this problem, you will explore this ambiguity by tuning an AR(1) model to match the one-step autocorrelation of a chaotic tent map and then investigate how the correlation structures diverge at longer time lags [@problem_id:864236].", "problem": "In the study of nonlinear dynamics, a key question is whether a given time series is generated by a deterministic chaotic system or a stochastic process. Statistical tools like the autocorrelation function (ACF) are often used to probe the underlying dynamics. While some chaotic systems can produce time series that are uncorrelated (like white noise), many exhibit short-term correlations that decay over time.\n\nA simple stochastic model that can exhibit exponentially decaying correlations is the autoregressive process of order 1, or AR(1) process. A time series $\\{y_n\\}$ is an AR(1) process if it is generated by the map $y_n = \\alpha y_{n-1} + \\epsilon_n$, where $|\\alpha| < 1$ is a constant parameter and $\\{\\epsilon_n\\}$ is a sequence of zero-mean, i.i.d. random variables (white noise) that are uncorrelated with past values of $y$. The normalized autocorrelation function for a stationary AR(1) process is given by $C_{AR(1)}(k) = \\alpha^k$ for $k \\ge 0$.\n\nConsider a deterministic chaotic map $f_p(x)$ on the unit interval $[0,1]$ defined by:\n$$\nx_{n+1} = f_p(x_n) = \\begin{cases}\nx_n/p & \\text{if } 0 \\le x_n \\le p \\\\\n(1-x_n)/(1-p) & \\text{if } p < x_n \\le 1\n\\end{cases}\n$$\nwhere $p$ is a parameter such that $0 < p < 1$ and $p \\neq 1/2$. For any such $p$, this map is chaotic and ergodic with a uniform invariant probability density function, $\\rho(x)=1$ for $x \\in [0,1]$. A time series $\\{x_n\\}$ is generated by iterating this map. The normalized autocorrelation function for this deterministic time series is defined as $C_{map}(k) = \\frac{\\langle (x_{n+k} - \\mu)(x_n - \\mu) \\rangle}{\\sigma^2}$, where $\\mu$ is the mean, $\\sigma^2$ is the variance, and $\\langle \\cdot \\rangle$ denotes an average over the invariant distribution.\n\nAn AR(1) process is to be constructed as a simple stochastic model that mimics the one-step correlation of the chaotic map. To do this, its parameter $\\alpha$ is chosen such that the one-step autocorrelation of the AR(1) process matches that of the chaotic map, i.e., $C_{AR(1)}(1) = C_{map}(1)$.\n\nYour task is to find the two-step autocorrelation, $C_{AR(1)}(2)$, for this specially constructed AR(1) process. Express your answer in terms of the parameter $p$.", "solution": "We wish to match an AR(1) process parameter $\\alpha=C_{\\rm map}(1)$ and then compute \n$$C_{AR(1)}(2)=\\alpha^2\\,. $$\n\n1. Invariant density $\\rho(x)=1$ on $[0,1]$ ⇒ \n   $$\\mu=E[x]=\\int_0^1x\\,dx=\\frac12,\\qquad \n     \\sigma^2=E[x^2]-\\mu^2=\\frac1{3}-\\frac1{4}=\\frac1{12}\\,. $$\n\n2. Compute $E[x_nx_{n+1}]=E[x\\,f_p(x)]$:\n   Split the integral at $x=p$,\n   \n$$\n   E[x\\,f_p(x)]\n   =\\int_0^p x\\frac{x}{p}\\,dx+\\int_p^1 x\\frac{1-x}{1-p}\\,dx\n   =\\frac1p\\int_0^p x^2dx+\\frac1{1-p}\\int_p^1 x(1-x)dx.\n   $$\n\n   Evaluate:\n   \n$$\n     \\frac1p\\cdot\\frac{p^3}{3}\n     =\\frac{p^2}{3},\n     \\quad\n     \\int_p^1x(1-x)dx\n     =\\frac{1-p^2}{2}-\\frac{1-p^3}{3}\n     =\\frac{1-3p^2+2p^3}{6},\n   $$\n\n   so\n   \n$$\n     \\frac{1}{1-p}\\cdot\\frac{1-3p^2+2p^3}{6}\n     =\\frac{-2p^2+p+1}{6}.\n   $$\n\n   Hence\n   \n$$\n     E[x_nx_{n+1}]\n     =\\frac{p^2}{3}+\\frac{-2p^2+p+1}{6}\n     =\\frac{p+1}{6}\\,.\n   $$\n\n\n3. The one-step autocovariance is\n   \n$$\n     \\text{Cov}(x_n,x_{n+1})\n     =E[x_nx_{n+1}]-\\mu^2\n     =\\frac{p+1}{6}-\\frac14\n     =\\frac{2p-1}{12}\\,,\n   $$\n\n   so the normalized one-step autocorrelation is\n   \n$$\n     C_{\\rm map}(1)\n     =\\frac{\\text{Cov}(x_n,x_{n+1})}{\\sigma^2}\n     =\\frac{\\tfrac{2p-1}{12}}{\\tfrac{1}{12}}\n     =2p-1\n     \\equiv \\alpha.\n   $$\n\n\n4. Therefore the two-step autocorrelation of the AR(1) process is\n   $$\n     C_{AR(1)}(2)=\\alpha^2=(2p-1)^2.\n   $$", "answer": "$$\\boxed{(2p-1)^2}$$", "id": "864236"}]}