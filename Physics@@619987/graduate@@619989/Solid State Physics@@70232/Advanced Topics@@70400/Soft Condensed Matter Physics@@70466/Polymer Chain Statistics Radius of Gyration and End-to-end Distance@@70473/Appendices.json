{"hands_on_practices": [{"introduction": "The ideal Gaussian chain, or random walk model, is the cornerstone of polymer physics, providing a powerful yet simple framework for understanding the statistical properties of flexible macromolecules. This first exercise invites you to explore the most fundamental measure of a polymer's size: its mean-square end-to-end distance. By calculating and comparing the size of a segment of the chain to the size of the whole chain, you will directly verify the characteristic scaling law, $\\langle R^2 \\rangle \\propto N$, that governs these random structures and build a solid intuition for the model [@problem_id:190443].", "problem": "Consider an ideal Gaussian polymer chain, which can be modeled as a random walk. The chain consists of $N$ segments, each with a mean-square length of $b^2$, connecting $N+1$ monomers. The monomers are indexed from $i=0$ to $i=N$, and the position of the $i$-th monomer is denoted by the vector $\\vec{R}_i$. Let $N$ be a large, even integer.\n\nThe segment vectors, defined as $\\vec{b}_i = \\vec{R}_i - \\vec{R}_{i-1}$ for $i=1, 2, \\dots, N$, are statistically independent. Their statistical properties are given by:\n$$\n\\langle \\vec{b}_i \\rangle = \\vec{0}\n$$\n$$\n\\langle \\vec{b}_i \\cdot \\vec{b}_j \\rangle = b^2 \\delta_{ij}\n$$\nwhere $\\langle \\dots \\rangle$ denotes an average over all possible conformations of the chain, and $\\delta_{ij}$ is the Kronecker delta.\n\nThe mean-square end-to-end distance of the entire chain is a standard measure of the polymer's size, defined as $\\langle R_E^2 \\rangle = \\langle (\\vec{R}_N - \\vec{R}_0)^2 \\rangle$. The \"central monomer\" of the chain is the monomer with index $i = N/2$.\n\nCalculate the ratio of the mean-square distance between the first monomer (index 0) and the central monomer (index $N/2$) to the mean-square end-to-end distance of the entire chain.", "solution": "The mean-square distance between two monomers is calculated using the segment vectors $\\vec{b}_i$. The position of the $k$-th monomer relative to the $0$-th monomer is:\n\n$$\n\\vec{R}_k - \\vec{R}_0 = \\sum_{i=1}^{k} \\vec{b}_i\n$$\n\nThe mean-square distance is:\n\n$$\n\\langle (\\vec{R}_k - \\vec{R}_0)^2 \\rangle = \\left\\langle \\left( \\sum_{i=1}^{k} \\vec{b}_i \\right) \\cdot \\left( \\sum_{j=1}^{k} \\vec{b}_j \\right) \\right\\rangle = \\sum_{i=1}^{k} \\sum_{j=1}^{k} \\langle \\vec{b}_i \\cdot \\vec{b}_j \\rangle\n$$\n\nGiven the statistical properties:\n\n$$\n\\langle \\vec{b}_i \\cdot \\vec{b}_j \\rangle = b^2 \\delta_{ij}\n$$\n\nso:\n\n$$\n\\langle (\\vec{R}_k - \\vec{R}_0)^2 \\rangle = \\sum_{i=1}^{k} \\sum_{j=1}^{k} b^2 \\delta_{ij} = b^2 \\sum_{i=1}^{k} 1 = b^2 k\n$$\n\nFor the central monomer at index $k = N/2$:\n\n$$\n\\langle (\\vec{R}_{N/2} - \\vec{R}_0)^2 \\rangle = b^2 \\left( \\frac{N}{2} \\right)\n$$\n\nFor the end-to-end distance of the entire chain ($k = N$):\n\n$$\n\\langle (\\vec{R}_N - \\vec{R}_0)^2 \\rangle = b^2 N\n$$\n\nThe ratio is:\n\n$$\n\\frac{\\langle (\\vec{R}_{N/2} - \\vec{R}_0)^2 \\rangle}{\\langle (\\vec{R}_N - \\vec{R}_0)^2 \\rangle} = \\frac{b^2 (N/2)}{b^2 N} = \\frac{N/2}{N} = \\frac{1}{2}\n$$", "answer": "$$ \\boxed{\\dfrac{1}{2}} $$", "id": "190443"}, {"introduction": "While the ideal chain model provides a crucial starting point, real polymer chains exhibit local stiffness due to steric hindrances and bond angle constraints. This exercise introduces a simple yet insightful model to account for such effects: the non-reversing random walk on a lattice. By calculating the asymptotic characteristic ratio, $C_{\\infty}$, you will quantify how a simple local constraint—the inability of a step to immediately reverse itself—propagates into a global increase in the chain's effective size, a key step toward understanding real polymers [@problem_id:190512].", "problem": "A polymer chain can be modeled as a sequence of $N$ connected segments. A simple model for the conformation of such a chain in space is a random walk. We consider a polymer chain on a $d$-dimensional hypercubic lattice, where each segment has a fixed length $b$, corresponding to the lattice constant. The position of the monomers is given by the vertices of the lattice.\n\nThe conformation of the chain is described by a non-reversing random walk (NRRW) of $N$ steps. In an NRRW, the direction of step $i+1$ is chosen randomly and with equal probability from all possible lattice directions, with the exception that it cannot be the direct reversal of step $i$. Specifically, if $\\vec{r}_i$ is the vector for the $i$-th segment, then $\\vec{r}_{i+1}$ can be any of the allowed moves on the hypercubic lattice except for $-\\vec{r}_i$. The total number of available directions on a $d$-dimensional hypercubic lattice is $2d$.\n\nThe size of the polymer is often characterized by its mean-squared end-to-end distance, $\\langle R_N^2 \\rangle$, where $\\vec{R}_N = \\sum_{i=1}^N \\vec{r}_i$ is the end-to-end vector. The characteristic ratio, $C_N$, is a dimensionless measure of the chain's stiffness, defined as:\n$$\nC_N = \\frac{\\langle R_N^2 \\rangle}{N b^2}\n$$\nFor a freely-jointed chain, where the directions of segments are completely uncorrelated, $C_N=1$.\n\nFor a very long polymer chain ($N \\to \\infty$), the characteristic ratio approaches a constant value, $C_{\\infty} = \\lim_{N \\to \\infty} C_N$.\n\nFind the asymptotic characteristic ratio $C_{\\infty}$ for a polymer chain modeled by a non-reversing random walk on a $d$-dimensional hypercubic lattice, for any integer dimension $d \\ge 2$. Express your answer as a function of $d$.", "solution": "The mean-squared end-to-end distance $\\langle R_N^2 \\rangle$ for a chain of $N$ segments is given by:\n$$\n\\langle R_N^2 \\rangle = \\left\\langle \\left( \\sum_{i=1}^N \\vec{r}_i \\right) \\cdot \\left( \\sum_{j=1}^N \\vec{r}_j \\right) \\right\\rangle = \\sum_{i=1}^N \\sum_{j=1}^N \\langle \\vec{r}_i \\cdot \\vec{r}_j \\rangle\n$$\nWe can separate the diagonal terms ($i=j$) from the off-diagonal terms ($i \\neq j$). Since each segment has length $b$, we have $\\vec{r}_i \\cdot \\vec{r}_i = |\\vec{r}_i|^2 = b^2$.\n$$\n\\langle R_N^2 \\rangle = \\sum_{i=1}^N b^2 + \\sum_{i \\neq j} \\langle \\vec{r}_i \\cdot \\vec{r}_j \\rangle = N b^2 + 2 \\sum_{i=1}^{N-1} \\sum_{j=i+1}^N \\langle \\vec{r}_i \\cdot \\vec{r}_j \\rangle\n$$\nThe correlation $\\langle \\vec{r}_i \\cdot \\vec{r}_j \\rangle$ for a stationary process depends only on the separation $k = |i-j|$ along the chain. We can write this as $\\langle \\vec{r}_i \\cdot \\vec{r}_{i+k} \\rangle$. The sum can be rewritten by letting $k = j-i$:\n$$\n\\langle R_N^2 \\rangle = N b^2 + 2 \\sum_{i=1}^{N-1} \\sum_{k=1}^{N-i} \\langle \\vec{r}_i \\cdot \\vec{r}_{i+k} \\rangle\n$$\nSumming over $i$ for a fixed $k$ gives $(N-k)$ identical terms:\n$$\n\\langle R_N^2 \\rangle = N b^2 + 2 \\sum_{k=1}^{N-1} (N-k) \\langle \\vec{r}_i \\cdot \\vec{r}_{i+k} \\rangle\n$$\nThe characteristic ratio $C_N$ is then:\n$$\nC_N = \\frac{\\langle R_N^2 \\rangle}{N b^2} = 1 + \\frac{2}{N b^2} \\sum_{k=1}^{N-1} (N-k) \\langle \\vec{r}_i \\cdot \\vec{r}_{i+k} \\rangle = 1 + \\frac{2}{b^2} \\sum_{k=1}^{N-1} \\left(1-\\frac{k}{N}\\right) \\langle \\vec{r}_i \\cdot \\vec{r}_{i+k} \\rangle\n$$\nIn the limit of an infinitely long chain ($N \\to \\infty$), the term $k/N \\to 0$, and the sum extends to infinity:\n$$\nC_{\\infty} = \\lim_{N\\to\\infty} C_N = 1 + \\frac{2}{b^2} \\sum_{k=1}^{\\infty} \\langle \\vec{r}_i \\cdot \\vec{r}_{i+k} \\rangle\n$$\nTo evaluate this sum, we need to compute the correlation terms $\\langle \\vec{r}_i \\cdot \\vec{r}_{i+k} \\rangle$. The choice of step $\\vec{r}_{j+1}$ depends only on the previous step $\\vec{r}_j$, which makes the sequence of bond vectors a Markov chain.\n\nLet's first calculate $\\langle \\vec{r}_i \\cdot \\vec{r}_{i+1} \\rangle$. The average is taken over all possible choices of $\\vec{r}_i$ and $\\vec{r}_{i+1}$.\n$$\n\\langle \\vec{r}_i \\cdot \\vec{r}_{i+1} \\rangle = \\left\\langle \\left\\langle \\vec{r}_i \\cdot \\vec{r}_{i+1} | \\vec{r}_i \\right\\rangle \\right\\rangle_{\\vec{r}_i}\n$$\nwhere the inner average is over the choices of $\\vec{r}_{i+1}$ for a fixed $\\vec{r}_i$, and the outer average is over all choices of $\\vec{r}_i$. Given $\\vec{r}_i$, the next step $\\vec{r}_{i+1}$ is chosen with uniform probability from the $2d-1$ allowed directions.\nLet $S$ be the set of all $2d$ possible step vectors on the lattice. The sum over all vectors in $S$ is zero: $\\sum_{\\vec{v} \\in S} \\vec{v} = \\vec{0}$.\nThe expected vector for $\\vec{r}_{i+1}$ given $\\vec{r}_i$ is:\n$$\n\\langle \\vec{r}_{i+1} | \\vec{r}_i \\rangle = \\frac{1}{2d-1} \\sum_{\\vec{v} \\in S, \\vec{v} \\neq -\\vec{r}_i} \\vec{v} = \\frac{1}{2d-1} \\left( \\left(\\sum_{\\vec{v} \\in S} \\vec{v}\\right) - (-\\vec{r}_i) \\right) = \\frac{1}{2d-1} (\\vec{0} + \\vec{r}_i) = \\frac{\\vec{r}_i}{2d-1}\n$$\nNow, we compute the correlation:\n$$\n\\langle \\vec{r}_i \\cdot \\vec{r}_{i+1} \\rangle = \\left\\langle \\vec{r}_i \\cdot \\left( \\frac{\\vec{r}_i}{2d-1} \\right) \\right\\rangle_{\\vec{r}_i} = \\frac{1}{2d-1} \\langle \\vec{r}_i \\cdot \\vec{r}_i \\rangle = \\frac{b^2}{2d-1}\n$$\nNext, we generalize to $\\langle \\vec{r}_i \\cdot \\vec{r}_{i+k} \\rangle$. We use the Markov property iteratively:\n$$\n\\langle \\vec{r}_{i+k} | \\vec{r}_i \\rangle = \\langle \\langle \\vec{r}_{i+k} | \\vec{r}_{i+k-1} \\rangle | \\vec{r}_i \\rangle = \\left\\langle \\frac{\\vec{r}_{i+k-1}}{2d-1} \\right\\rangle_{\\text{cond. on } \\vec{r}_i} = \\frac{1}{2d-1} \\langle \\vec{r}_{i+k-1} | \\vec{r}_i \\rangle\n$$\nThis recurrence relation gives $\\langle \\vec{r}_{i+k} | \\vec{r}_i \\rangle = \\frac{\\vec{r}_i}{(2d-1)^k}$.\nSo, the correlation is:\n$$\n\\langle \\vec{r}_i \\cdot \\vec{r}_{i+k} \\rangle = \\left\\langle \\vec{r}_i \\cdot \\langle \\vec{r}_{i+k} | \\vec{r}_i \\rangle \\right\\rangle_{\\vec{r}_i} = \\left\\langle \\vec{r}_i \\cdot \\frac{\\vec{r}_i}{(2d-1)^k} \\right\\rangle = \\frac{\\langle \\vec{r}_i^2 \\rangle}{(2d-1)^k} = \\frac{b^2}{(2d-1)^k}\n$$\nNow we can substitute this result back into the expression for $C_{\\infty}$:\n$$\nC_{\\infty} = 1 + \\frac{2}{b^2} \\sum_{k=1}^{\\infty} \\frac{b^2}{(2d-1)^k} = 1 + 2 \\sum_{k=1}^{\\infty} \\left(\\frac{1}{2d-1}\\right)^k\n$$\nThis is a geometric series with ratio $x = \\frac{1}{2d-1}$. For $d \\ge 2$, we have $|x| < 1$, so the series converges.\nThe sum of the geometric series is $\\sum_{k=1}^{\\infty} x^k = \\frac{x}{1-x}$.\n$$\n\\sum_{k=1}^{\\infty} \\left(\\frac{1}{2d-1}\\right)^k = \\frac{\\frac{1}{2d-1}}{1-\\frac{1}{2d-1}} = \\frac{\\frac{1}{2d-1}}{\\frac{2d-1-1}{2d-1}} = \\frac{1}{2d-2}\n$$\nSubstituting this sum back into the expression for $C_{\\infty}$:\n$$\nC_{\\infty} = 1 + 2 \\left( \\frac{1}{2d-2} \\right) = 1 + \\frac{1}{d-1} = \\frac{(d-1)+1}{d-1} = \\frac{d}{d-1}\n$$", "answer": "$$ \\boxed{\\frac{d}{d-1}} $$", "id": "190512"}, {"introduction": "Moving beyond simple scalar measures of size, this problem delves into the shape of a polymer coil under an external constraint. By fixing the chain's end-to-end vector, we break its average spherical symmetry, a scenario relevant to understanding polymer elasticity. You will explore this induced anisotropy by calculating the principal components of the radius of gyration tensor, offering a rich description of how a polymer deforms from a random coil into an elongated shape when stretched [@problem_id:190444].", "problem": "An ideal continuous Gaussian polymer chain is a theoretical model for a flexible polymer. In this model, the chain consists of $N$ statistical segments, each of Kuhn length $b$. The chain's conformation is described by the path $\\boldsymbol{r}(s)$, where $s \\in [0, N]$ is a contour variable, $\\boldsymbol{r}(0) = \\boldsymbol{0}$, and $\\boldsymbol{r}(N) = \\boldsymbol{R}_{ee}$ is the end-to-end vector.\n\nThe size and shape of the polymer coil are characterized by the radius of gyration tensor, $\\boldsymbol{S}$, defined by its components:\n$$S_{\\alpha\\beta} = \\frac{1}{N} \\int_{0}^{N} \\left(r_\\alpha(s) - R_{CM,\\alpha}\\right) \\left(r_\\beta(s) - R_{CM,\\beta}\\right) ds$$\nwhere $\\boldsymbol{R}_{CM} = \\frac{1}{N} \\int_0^N \\boldsymbol{r}(s) ds$ is the center of mass of the chain, and $\\alpha, \\beta$ denote the Cartesian components $\\{x, y, z\\}$.\n\nConsider a chain that is conditioned to have a specific, fixed end-to-end vector, $\\boldsymbol{R}_{ee} \\equiv \\boldsymbol{R}$. This constraint breaks the isotropic nature of the chain's average configuration. The ensemble average of the gyration tensor, $\\langle \\boldsymbol{S} \\rangle_{\\boldsymbol{R}}$, will exhibit axial symmetry with respect to the vector $\\boldsymbol{R}$. Consequently, $\\langle \\boldsymbol{S} \\rangle_{\\boldsymbol{R}}$ has two distinct principal components (eigenvalues): one parallel to $\\boldsymbol{R}$, denoted $\\langle R_{g,\\|}^2 \\rangle$, and one perpendicular to $\\boldsymbol{R}$, denoted $\\langle R_{g,\\perp}^2 \\rangle$.\n\nDerive the difference between the longitudinal and transverse principal components, $\\Delta \\langle R_g^2 \\rangle = \\langle R_{g,\\|}^2 \\rangle - \\langle R_{g,\\perp}^2 \\rangle$, as a function of the magnitude of the end-to-end vector, $R=|\\boldsymbol{R}|$.", "solution": "The gyration tensor components are given by:\n\n$$\nS_{\\alpha\\beta} = \\frac{1}{N} \\int_{0}^{N} \\left(r_\\alpha(s) - R_{CM,\\alpha}\\right) \\left(r_\\beta(s) - R_{CM,\\beta}\\right) ds\n$$\n\nwhere $\\boldsymbol{R}_{CM} = \\frac{1}{N} \\int_0^N \\boldsymbol{r}(s) ds$. Expanding the product:\n\n$$\nS_{\\alpha\\beta} = \\frac{1}{N} \\int_{0}^{N} r_\\alpha(s) r_\\beta(s)  ds - R_{CM,\\alpha} R_{CM,\\beta}\n$$\n\nThe ensemble average conditioned on $\\boldsymbol{r}(N) = \\boldsymbol{R}$ (with $\\boldsymbol{r}(0) = \\boldsymbol{0}$) is:\n\n$$\n\\langle S_{\\alpha\\beta} \\rangle_{\\boldsymbol{R}} = \\left\\langle \\frac{1}{N} \\int_{0}^{N} r_\\alpha(s) r_\\beta(s)  ds \\right\\rangle_{\\boldsymbol{R}} - \\langle R_{CM,\\alpha} R_{CM,\\beta} \\rangle_{\\boldsymbol{R}}\n$$\n\nFor a Gaussian chain, the conditional two-point correlation is:\n\n$$\n\\langle r_\\alpha(s) r_\\beta(s') \\rangle_{\\boldsymbol{R}} = \\delta_{\\alpha\\beta} b \\left[ \\min(s, s') - \\frac{s s'}{N} \\right] + \\frac{s s'}{N^2} R_\\alpha R_\\beta\n$$\n\nFirst, compute the integral term:\n\n$$\n\\left\\langle \\frac{1}{N} \\int_{0}^{N} r_\\alpha(s) r_\\beta(s)  ds \\right\\rangle_{\\boldsymbol{R}} = \\frac{1}{N} \\int_{0}^{N} \\langle r_\\alpha(s) r_\\beta(s) \\rangle_{\\boldsymbol{R}}  ds\n$$\n\nAt $s' = s$:\n\n$$\n\\langle r_\\alpha(s) r_\\beta(s) \\rangle_{\\boldsymbol{R}} = \\delta_{\\alpha\\beta} b \\left( s - \\frac{s^2}{N} \\right) + \\frac{s^2}{N^2} R_\\alpha R_\\beta\n$$\n\nIntegrating:\n\n$$\n\\int_{0}^{N} \\delta_{\\alpha\\beta} b \\left( s - \\frac{s^2}{N} \\right) ds = \\delta_{\\alpha\\beta} b \\left[ \\frac{s^2}{2} - \\frac{s^3}{3N} \\right]_{0}^{N} = \\delta_{\\alpha\\beta} b \\left( \\frac{N^2}{2} - \\frac{N^2}{3} \\right) = \\delta_{\\alpha\\beta} b \\frac{N^2}{6}\n$$\n\n\n$$\n\\int_{0}^{N} \\frac{s^2}{N^2} R_\\alpha R_\\beta  ds = \\frac{R_\\alpha R_\\beta}{N^2} \\left[ \\frac{s^3}{3} \\right]_{0}^{N} = \\frac{R_\\alpha R_\\beta}{N^2} \\cdot \\frac{N^3}{3} = \\frac{R_\\alpha R_\\beta N}{3}\n$$\n\nThus:\n\n$$\n\\frac{1}{N} \\int_{0}^{N} \\langle r_\\alpha(s) r_\\beta(s) \\rangle_{\\boldsymbol{R}}  ds = \\frac{1}{N} \\left( \\delta_{\\alpha\\beta} b \\frac{N^2}{6} + \\frac{R_\\alpha R_\\beta N}{3} \\right) = \\delta_{\\alpha\\beta} \\frac{b N}{6} + \\frac{R_\\alpha R_\\beta}{3}\n$$\n\nNext, compute $\\langle R_{CM,\\alpha} R_{CM,\\beta} \\rangle_{\\boldsymbol{R}}$:\n\n$$\n\\langle R_{CM,\\alpha} R_{CM,\\beta} \\rangle_{\\boldsymbol{R}} = \\frac{1}{N^2} \\int_{0}^{N} \\int_{0}^{N} \\langle r_\\alpha(s) r_\\beta(s') \\rangle_{\\boldsymbol{R}}  ds  ds'\n$$\n\nSubstituting the correlation:\n\n$$\n\\langle R_{CM,\\alpha} R_{CM,\\beta} \\rangle_{\\boldsymbol{R}} = \\frac{1}{N^2} \\int_{0}^{N} \\int_{0}^{N} \\left[ \\delta_{\\alpha\\beta} b \\left( \\min(s, s') - \\frac{s s'}{N} \\right) + \\frac{s s'}{N^2} R_\\alpha R_\\beta \\right]  ds  ds'\n$$\n\nThe second term is:\n\n$$\n\\frac{1}{N^2} \\int_{0}^{N} \\int_{0}^{N} \\frac{s s'}{N^2} R_\\alpha R_\\beta  ds  ds' = \\frac{R_\\alpha R_\\beta}{N^4} \\left( \\int_{0}^{N} s  ds \\right)^2 = \\frac{R_\\alpha R_\\beta}{N^4} \\left( \\frac{N^2}{2} \\right)^2 = \\frac{R_\\alpha R_\\beta}{N^4} \\cdot \\frac{N^4}{4} = \\frac{R_\\alpha R_\\beta}{4}\n$$\n\nThe first term is:\n\n$$\n\\delta_{\\alpha\\beta} \\frac{b}{N^2} \\int_{0}^{N} \\int_{0}^{N} \\left( \\min(s, s') - \\frac{s s'}{N} \\right)  ds  ds'\n$$\n\nThe double integral splits into two regions:\n\n$$\n\\int_{0}^{N} \\int_{0}^{N} \\min(s, s')  ds  ds' = 2 \\int_{0}^{N} \\int_{0}^{s} s'  ds'  ds = 2 \\int_{0}^{N} \\left[ \\frac{s'^2}{2} \\right]_{0}^{s}  ds = \\int_{0}^{N} s^2  ds = \\frac{N^3}{3}\n$$\n\n\n$$\n\\int_{0}^{N} \\int_{0}^{N} \\frac{s s'}{N}  ds  ds' = \\frac{1}{N} \\left( \\int_{0}^{N} s  ds \\right)^2 = \\frac{1}{N} \\left( \\frac{N^2}{2} \\right)^2 = \\frac{1}{N} \\cdot \\frac{N^4}{4} = \\frac{N^3}{4}\n$$\n\nThus:\n\n$$\n\\int_{0}^{N} \\int_{0}^{N} \\left( \\min(s, s') - \\frac{s s'}{N} \\right)  ds  ds' = \\frac{N^3}{3} - \\frac{N^3}{4} = \\frac{N^3}{12}\n$$\n\nSo:\n\n$$\n\\delta_{\\alpha\\beta} \\frac{b}{N^2} \\cdot \\frac{N^3}{12} = \\delta_{\\alpha\\beta} \\frac{b N}{12}\n$$\n\nCombining:\n\n$$\n\\langle R_{CM,\\alpha} R_{CM,\\beta} \\rangle_{\\boldsymbol{R}} = \\delta_{\\alpha\\beta} \\frac{b N}{12} + \\frac{R_\\alpha R_\\beta}{4}\n$$\n\nNow, the gyration tensor average is:\n\n$$\n\\langle S_{\\alpha\\beta} \\rangle_{\\boldsymbol{R}} = \\left( \\delta_{\\alpha\\beta} \\frac{b N}{6} + \\frac{R_\\alpha R_\\beta}{3} \\right) - \\left( \\delta_{\\alpha\\beta} \\frac{b N}{12} + \\frac{R_\\alpha R_\\beta}{4} \\right) = \\delta_{\\alpha\\beta} b N \\left( \\frac{1}{6} - \\frac{1}{12} \\right) + R_\\alpha R_\\beta \\left( \\frac{1}{3} - \\frac{1}{4} \\right)\n$$\n\nSimplifying:\n\n$$\n\\langle S_{\\alpha\\beta} \\rangle_{\\boldsymbol{R}} = \\delta_{\\alpha\\beta} \\frac{b N}{12} + \\frac{R_\\alpha R_\\beta}{12}\n$$\n\nThis tensor has axial symmetry along $\\boldsymbol{R}$. Let $\\boldsymbol{n} = \\boldsymbol{R}/R$ be the unit vector. The eigenvalues are found by expressing the tensor as $\\langle \\boldsymbol{S} \\rangle_{\\boldsymbol{R}} = A\\boldsymbol{I} + B \\boldsymbol{n} \\otimes \\boldsymbol{n}$. Here, $A = \\frac{bN}{12}$ and $B \\boldsymbol{n} \\otimes \\boldsymbol{n} = \\frac{\\boldsymbol{R} \\otimes \\boldsymbol{R}}{12}$, so $B = \\frac{R^2}{12}$. The eigenvalues are:\n- Parallel to $\\boldsymbol{n}$: $\\lambda_{\\parallel} = A + B = \\frac{b N}{12} + \\frac{R^2}{12}$\n- Perpendicular to $\\boldsymbol{n}$: $\\lambda_{\\perp} = A = \\frac{b N}{12}$ (twofold degenerate)\n\nThus:\n\n$$\n\\langle R_{g,\\parallel}^2 \\rangle = \\lambda_{\\parallel} = \\frac{b N}{12} + \\frac{R^2}{12}, \\quad \\langle R_{g,\\perp}^2 \\rangle = \\lambda_{\\perp} = \\frac{b N}{12}\n$$\n\nThe difference is:\n\n$$\n\\Delta \\langle R_g^2 \\rangle = \\langle R_{g,\\parallel}^2 \\rangle - \\langle R_{g,\\perp}^2 \\rangle = \\left( \\frac{b N}{12} + \\frac{R^2}{12} \\right) - \\frac{b N}{12} = \\frac{R^2}{12}\n$$", "answer": "$$\\boxed{\\dfrac{R^{2}}{12}}$$", "id": "190444"}]}