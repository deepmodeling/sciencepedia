{"hands_on_practices": [{"introduction": "The Freely-Jointed Chain (FJC) is the quintessential starting point for understanding polymer conformations, treating the polymer as a random walk in three dimensions. This exercise [@problem_id:126300] challenges you to generalize this model by considering a chain where the length of each segment is not fixed but instead follows a statistical distribution. By working through this problem, you will reinforce your understanding of how the mean-square end-to-end distance is calculated and discover how robust the fundamental principles of the FJC model are.", "problem": "A polymer chain is modeled as a freely-jointed chain consisting of $N$ segments. In a standard textbook model, each segment has a fixed length. Here, we consider a more general case where the length $b_i = |\\vec{b}_i|$ of each segment vector $\\vec{b}_i$ is an independent random variable. The orientation of each segment is random and completely uncorrelated with the orientations of all other segments. Further, the length of a segment is independent of its orientation and the lengths and orientations of all other segments.\n\nThe probability distribution for the length $b$ of any given segment is described by an exponential distribution with a characteristic length $\\ell$:\n$$\nP(b) = \\frac{1}{\\ell} e^{-b/\\ell}, \\quad \\text{for } b \\ge 0\n$$\nThe chain has a total of $N$ such segments. The end-to-end vector of the chain is given by $\\vec{R} = \\sum_{i=1}^{N} \\vec{b}_i$.\n\nCalculate the mean-square end-to-end distance, $\\langle R^2 \\rangle$, for this polymer chain. Express your answer in terms of $N$ and $\\ell$.", "solution": "The end-to-end vector is $\\vec{R} = \\sum_{i=1}^{N} \\vec{b}_i$, so the squared magnitude is:\n$$ R^2 = \\vec{R} \\cdot \\vec{R} = \\left( \\sum_{i=1}^{N} \\vec{b}_i \\right) \\cdot \\left( \\sum_{j=1}^{N} \\vec{b}_j \\right) = \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\vec{b}_i \\cdot \\vec{b}_j. $$\n\nThe mean-square end-to-end distance is the expectation:\n$$ \\langle R^2 \\rangle = \\left\\langle \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\vec{b}_i \\cdot \\vec{b}_j \\right\\rangle = \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\langle \\vec{b}_i \\cdot \\vec{b}_j \\rangle. $$\n\nFor $i = j$, the dot product is:\n$$ \\langle \\vec{b}_i \\cdot \\vec{b}_i \\rangle = \\langle |\\vec{b}_i|^2 \\rangle = \\langle b_i^2 \\rangle. $$\n\nFor $i \\neq j$, the dot product is:\n$$ \\langle \\vec{b}_i \\cdot \\vec{b}_j \\rangle = \\langle |\\vec{b}_i| |\\vec{b}_j| \\cos \\theta_{ij} \\rangle, $$\nwhere $\\theta_{ij}$ is the angle between segments $i$ and $j$. Since the orientations are random, uncorrelated, and isotropic, the average over orientations gives $\\langle \\cos \\theta_{ij} \\rangle = 0$. Additionally, the length $b_i$ is independent of $b_j$ and orientation, so:\n$$ \\langle |\\vec{b}_i| |\\vec{b}_j| \\cos \\theta_{ij} \\rangle = \\langle b_i \\rangle \\langle b_j \\rangle \\langle \\cos \\theta_{ij} \\rangle = \\langle b_i \\rangle \\langle b_j \\rangle \\cdot 0 = 0. $$\n\nThus, only the diagonal terms ($i = j$) contribute:\n$$ \\langle R^2 \\rangle = \\sum_{i=1}^{N} \\langle b_i^2 \\rangle. $$\n\nSince all segments are identical and independent, $\\langle b_i^2 \\rangle = \\langle b^2 \\rangle$ for all $i$, so:\n$$ \\langle R^2 \\rangle = N \\langle b^2 \\rangle. $$\n\nThe length $b$ of any segment follows an exponential distribution:\n$$ P(b) = \\frac{1}{\\ell} e^{-b/\\ell}, \\quad b \\geq 0. $$\nThe second moment is:\n$$ \\langle b^2 \\rangle = \\int_{0}^{\\infty} b^2 P(b)  db = \\int_{0}^{\\infty} b^2 \\cdot \\frac{1}{\\ell} e^{-b/\\ell}  db. $$\n\nSubstitute $u = b / \\ell$, so $b = \\ell u$, $db = \\ell  du$:\n$$ \\langle b^2 \\rangle = \\int_{0}^{\\infty} (\\ell u)^2 \\cdot \\frac{1}{\\ell} e^{-u} \\ell  du = \\ell^2 \\int_{0}^{\\infty} u^2 e^{-u}  du. $$\n\nThe integral is the Gamma function $\\Gamma(3)$:\n$$ \\int_{0}^{\\infty} u^2 e^{-u}  du = \\Gamma(3) = 2! = 2. $$\nThus:\n$$ \\langle b^2 \\rangle = \\ell^2 \\cdot 2 = 2\\ell^2. $$\n\nSubstituting back:\n$$ \\langle R^2 \\rangle = N \\cdot 2\\ell^2 = 2N\\ell^2. $$", "answer": "$$ \\boxed{2N\\ell^{2}} $$", "id": "126300"}, {"introduction": "Real polymer chains exhibit some degree of local stiffness, a feature absent in the simple Freely-Jointed Chain model. The Freely-Rotating Chain (FRC) model introduces this by fixing the angle between adjacent bonds, creating correlations in their orientation. This practice problem [@problem_id:126202] asks you to explore the consequences of this local correlation in a special, illuminating case, helping you build intuition for how microscopic constraints influence macroscopic chain properties.", "problem": "A freely-rotating chain (FRC) is a simple model for a polymer, consisting of $N$ bond vectors, $\\mathbf{b}_1, \\mathbf{b}_2, \\ldots, \\mathbf{b}_N$. All bonds have a fixed length $b$, so $|\\mathbf{b}_i| = b$ for all $i$. The angle between any two consecutive bonds, $\\mathbf{b}_i$ and $\\mathbf{b}_{i+1}$, is fixed to a constant value $\\theta$. The chain exhibits free rotation, meaning the dihedral angle specifying the rotation of the bond $\\mathbf{b}_{i+1}$ around the axis defined by $\\mathbf{b}_i$ is random and uniformly distributed. The end-to-end vector of the chain is given by the sum of all bond vectors, $\\mathbf{R} = \\sum_{i=1}^{N} \\mathbf{b}_i$.\n\nConsider a specific freely-rotating chain with a bond angle of $\\theta = \\pi/2$. For a chain with $N \\ge 2$ bonds, calculate the statistical average of the projection of the end-to-end vector $\\mathbf{R}$ onto the second bond vector $\\mathbf{b}_2$. Your final answer should be a closed-form expression in terms of the bond length $b$.\n\nThe quantity to be calculated is $\\langle \\mathbf{R} \\cdot \\mathbf{b}_2 \\rangle$.", "solution": "The end-to-end vector is given by $\\mathbf{R} = \\sum_{i=1}^{N} \\mathbf{b}_i$. The quantity to compute is the statistical average $\\langle \\mathbf{R} \\cdot \\mathbf{b}_2 \\rangle$:\n\n$$\n\\langle \\mathbf{R} \\cdot \\mathbf{b}_2 \\rangle = \\left\\langle \\left( \\sum_{i=1}^{N} \\mathbf{b}_i \\right) \\cdot \\mathbf{b}_2 \\right\\rangle = \\sum_{i=1}^{N} \\langle \\mathbf{b}_i \\cdot \\mathbf{b}_2 \\rangle,\n$$\n\nby the linearity of expectation.\n\nThe bond vectors $\\mathbf{b}_i$ have fixed length $b$, and the angle between consecutive bonds is fixed at $\\theta = \\pi/2$. The dihedral angles are random and uniformly distributed. The average dot product $\\langle \\mathbf{b}_i \\cdot \\mathbf{b}_2 \\rangle$ depends only on the separation $|i - 2|$ due to the chain's homogeneity. For a freely-rotating chain, the correlation between bonds separated by $k$ steps is:\n\n$$\n\\langle \\mathbf{b}_i \\cdot \\mathbf{b}_{i+k} \\rangle = b^2 (\\cos \\theta)^k,\n$$\n\nfor $k \\geq 0$. With $\\theta = \\pi/2$, $\\cos \\theta = \\cos(\\pi/2) = 0$. Thus:\n\n$$\n\\langle \\mathbf{b}_i \\cdot \\mathbf{b}_2 \\rangle = b^2 \\cdot 0^{|i-2|}.\n$$\n\n\n- When $i = 2$, $|i - 2| = 0$, and $0^0 = 1$ (by convention for correlation at zero separation), so:\n  \n$$\n  \\langle \\mathbf{b}_2 \\cdot \\mathbf{b}_2 \\rangle = b^2 \\cdot 1 = b^2.\n  $$\n\n- When $i \\neq 2$, $|i - 2| \\geq 1$, and $0^{|i-2|} = 0$ for $|i-2| \\geq 1$, so:\n  \n$$\n  \\langle \\mathbf{b}_i \\cdot \\mathbf{b}_2 \\rangle = b^2 \\cdot 0 = 0.\n  $$\n\n\nTherefore:\n\n$$\n\\sum_{i=1}^{N} \\langle \\mathbf{b}_i \\cdot \\mathbf{b}_2 \\rangle = \\langle \\mathbf{b}_2 \\cdot \\mathbf{b}_2 \\rangle + \\sum_{i \\neq 2} \\langle \\mathbf{b}_i \\cdot \\mathbf{b}_2 \\rangle = b^2 + \\sum_{i \\neq 2} 0 = b^2,\n$$\n\nsince the sum over $i \\neq 2$ contributes zero. This holds for all $N \\geq 2$.\n\nThe statistical average is $b^2$, independent of $N$.", "answer": "$$ \\boxed{b^2} $$", "id": "126202"}, {"introduction": "At large length scales, the discrete nature of a polymer chain can be approximated by a continuous, flexible thread described by the Gaussian chain model. This model is particularly powerful for understanding how polymers respond to external forces. In this thought experiment [@problem_id:126175], we investigate a \"Gaussian bridge\"—a chain whose ends are held at a fixed distance—to see how individual segments behave under this global constraint, providing a foundational insight into the origins of polymer elasticity.", "problem": "Consider a Gaussian polymer chain composed of $N$ links, where the vector for the $i$-th link is $\\vec{r}_i$. The chain is modeled by a joint probability distribution for the link vectors given by $P(\\{\\vec{r}_j\\}_{j=1}^N) = \\prod_{j=1}^N P_0(\\vec{r}_j)$, where the probability distribution for a single unconstrained link vector is $P_0(\\vec{r}) = \\left(\\frac{3}{2 \\pi b^2}\\right)^{3/2} \\exp\\left(-\\frac{3 \\vec{r}^2}{2 b^2}\\right)$, and $b^2$ is the mean-squared length of a link. The chain is subject to the constraint that its end-to-end vector, $\\vec{R} = \\sum_{i=1}^N \\vec{r}_i$, is fixed to a specific, non-zero vector. This constrained system is known as a Gaussian bridge.\n\nFor a specific link $i$ (where $1 \\le i \\le N$), derive the conditional expectation value of its projection onto the end-to-end vector. This quantity is given by $\\left\\langle \\vec{r}_i \\cdot \\frac{\\vec{R}}{|\\vec{R}|} \\right\\rangle_{\\vec{R}_{\\text{fixed}}}$. Express your answer in terms of the total number of links $N$ and the magnitude of the end-to-end vector, $R=|\\vec{R}|$.", "solution": "The joint probability distribution for the link vectors is given by:\n\n$$\nP(\\{\\vec{r}_j\\}_{j=1}^N) = \\prod_{j=1}^N P_0(\\vec{r}_j), \\quad P_0(\\vec{r}) = \\left(\\frac{3}{2 \\pi b^2}\\right)^{3/2} \\exp\\left(-\\frac{3 \\vec{r}^2}{2 b^2}\\right),\n$$\n\nwith the end-to-end vector $\\vec{R} = \\sum_{i=1}^N \\vec{r}_i$ fixed to a specific vector. The goal is to compute the conditional expectation:\n\n$$\n\\left\\langle \\vec{r}_i \\cdot \\frac{\\vec{R}}{|\\vec{R}|} \\right\\rangle_{\\vec{R}_{\\text{fixed}}}.\n$$\n\n\nThe vectors $\\{\\vec{r}_j\\}$ and $\\vec{R}$ are jointly Gaussian. The mean of each $\\vec{r}_i$ is zero, and the mean of $\\vec{R}$ is also zero. The covariance between $\\vec{r}_i$ and $\\vec{R}$ is:\n\n$$\n\\operatorname{Cov}(\\vec{r}_i, \\vec{R}) = \\langle \\vec{r}_i \\vec{R}^T \\rangle = \\left\\langle \\vec{r}_i \\left( \\sum_{j=1}^N \\vec{r}_j \\right)^T \\right\\rangle.\n$$\n\nDue to independence and isotropy, $\\langle \\vec{r}_i \\vec{r}_j^T \\rangle = \\mathbf{0}$ for $i \\neq j$, and:\n\n$$\n\\langle \\vec{r}_i \\vec{r}_i^T \\rangle = \\frac{b^2}{3} \\mathbf{I},\n$$\n\nsince each component has variance $b^2/3$. Thus:\n\n$$\n\\operatorname{Cov}(\\vec{r}_i, \\vec{R}) = \\frac{b^2}{3} \\mathbf{I}.\n$$\n\nThe covariance of $\\vec{R}$ is:\n\n$$\n\\operatorname{Cov}(\\vec{R}, \\vec{R}) = \\langle \\vec{R} \\vec{R}^T \\rangle = \\left\\langle \\left( \\sum_{j=1}^N \\vec{r}_j \\right) \\left( \\sum_{k=1}^N \\vec{r}_k \\right)^T \\right\\rangle = \\sum_{j=1}^N \\langle \\vec{r}_j \\vec{r}_j^T \\rangle = N \\cdot \\frac{b^2}{3} \\mathbf{I}.\n$$\n\nFor jointly Gaussian vectors, the conditional expectation of $\\vec{r}_i$ given $\\vec{R}$ is:\n\n$$\n\\langle \\vec{r}_i \\mid \\vec{R} \\rangle = \\operatorname{Cov}(\\vec{r}_i, \\vec{R}) \\left[ \\operatorname{Cov}(\\vec{R}, \\vec{R}) \\right]^{-1} \\vec{R}.\n$$\n\nSubstituting the covariances:\n\n$$\n\\left[ \\operatorname{Cov}(\\vec{R}, \\vec{R}) \\right]^{-1} = \\left( N \\cdot \\frac{b^2}{3} \\mathbf{I} \\right)^{-1} = \\frac{3}{N b^2} \\mathbf{I},\n$$\n\n\n$$\n\\langle \\vec{r}_i \\mid \\vec{R} \\rangle = \\left( \\frac{b^2}{3} \\mathbf{I} \\right) \\left( \\frac{3}{N b^2} \\mathbf{I} \\right) \\vec{R} = \\frac{1}{N} \\vec{R}.\n$$\n\nThe projection of $\\vec{r}_i$ onto the unit vector $\\hat{n} = \\vec{R} / |\\vec{R}|$ is:\n\n$$\n\\vec{r}_i \\cdot \\hat{n} = \\vec{r}_i \\cdot \\frac{\\vec{R}}{|\\vec{R}|}.\n$$\n\nThe conditional expectation of this projection is:\n\n$$\n\\left\\langle \\vec{r}_i \\cdot \\hat{n} \\mid \\vec{R} \\right\\rangle = \\langle \\vec{r}_i \\mid \\vec{R} \\rangle \\cdot \\hat{n} = \\left( \\frac{1}{N} \\vec{R} \\right) \\cdot \\frac{\\vec{R}}{|\\vec{R}|} = \\frac{1}{N} \\frac{\\vec{R} \\cdot \\vec{R}}{|\\vec{R}|} = \\frac{|\\vec{R}|^2}{N |\\vec{R}|} = \\frac{|\\vec{R}|}{N}.\n$$\n\nLet $R = |\\vec{R}|$. The result is:\n\n$$\n\\left\\langle \\vec{r}_i \\cdot \\frac{\\vec{R}}{|\\vec{R}|} \\right\\rangle_{\\vec{R}_{\\text{fixed}}} = \\frac{R}{N}.\n$$\n\nThis expression is independent of the index $i$.", "answer": "$$\\boxed{\\dfrac{R}{N}}$$", "id": "126175"}]}