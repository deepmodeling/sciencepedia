{"hands_on_practices": [{"introduction": "Many fundamental systems in physics and engineering, from mechanical oscillators to electrical circuits, are initially described by second-order (or higher) differential equations. To unlock the full power of linear algebra for analyzing their behavior, our first step is to translate these descriptions into a universal language: the state-space representation. This exercise provides foundational practice in this essential skill by guiding you through the conversion of the classic damped harmonic oscillator equation into the standard first-order matrix form $\\dot{\\mathbf{y}} = A\\mathbf{y} + \\mathbf{b}$ [@problem_id:1692588]. Mastering this process is the gateway to understanding stability, controllability, and observability in dynamical systems.", "problem": "In civil engineering, a simplified model for the horizontal displacement of a tall building subjected to a sudden, constant wind gust can be described by the equation of a damped harmonic oscillator with a constant driving force. The second-order ordinary differential equation for the horizontal displacement $x(t)$ is given by:\n$$ m\\frac{d^2x}{dt^2} + c\\frac{dx}{dt} + kx = F_0 $$\nHere, $m$ is the effective mass of the structure, $c$ is the damping coefficient representing energy dissipation, $k$ is the effective spring constant representing the building's stiffness, and $F_0$ is the constant force exerted by the wind.\n\nTo analyze this system using state-space methods, it is necessary to convert this single second-order equation into a system of two first-order linear differential equations. This system is expressed in the standard matrix form $\\dot{\\mathbf{y}} = A\\mathbf{y} + \\mathbf{b}$, where the state vector $\\mathbf{y}$ is defined as $\\mathbf{y}(t) = \\begin{pmatrix} x(t) \\\\ \\frac{dx}{dt} \\end{pmatrix}$.\n\nIdentify the correct state matrix $A$ and the constant input vector $\\mathbf{b}$ for this system from the options below.\n\nA. $A = \\begin{pmatrix} 0 & 1 \\\\ -\\frac{k}{m} & -\\frac{c}{m} \\end{pmatrix}, \\mathbf{b} = \\begin{pmatrix} \\frac{F_0}{m} \\\\ 0 \\end{pmatrix}$\n\nB. $A = \\begin{pmatrix} 0 & 1 \\\\ \\frac{k}{m} & \\frac{c}{m} \\end{pmatrix}, \\mathbf{b} = \\begin{pmatrix} 0 \\\\ F_0 \\end{pmatrix}$\n\nC. $A = \\begin{pmatrix} 0 & 1 \\\\ -\\frac{k}{m} & -\\frac{c}{m} \\end{pmatrix}, \\mathbf{b} = \\begin{pmatrix} 0 \\\\ \\frac{F_0}{m} \\end{pmatrix}$\n\nD. $A = \\begin{pmatrix} 0 & -k \\\\ 1 & -c \\end{pmatrix}, \\mathbf{b} = \\begin{pmatrix} 0 \\\\ F_0 \\end{pmatrix}$\n\nE. $A = \\begin{pmatrix} 1 & 0 \\\\ -\\frac{k}{m} & -\\frac{c}{m} \\end{pmatrix}, \\mathbf{b} = \\begin{pmatrix} 0 \\\\ \\frac{F_0}{m} \\end{pmatrix}$", "solution": "Starting from the given second-order ordinary differential equation\n$$\nm\\frac{d^{2}x}{dt^{2}} + c\\frac{dx}{dt} + kx = F_{0},\n$$\ndefine the state vector $\\mathbf{y}(t) = \\begin{pmatrix} x(t) \\\\ \\frac{dx}{dt} \\end{pmatrix}$. Let $y_{1} = x$ and $y_{2} = \\frac{dx}{dt}$. Then\n$$\n\\frac{dy_{1}}{dt} = y_{2},\n$$\nand, solving the original equation for $\\frac{d^{2}x}{dt^{2}}$,\n$$\n\\frac{d^{2}x}{dt^{2}} = \\frac{F_{0} - c\\frac{dx}{dt} - kx}{m} = -\\frac{k}{m}y_{1} - \\frac{c}{m}y_{2} + \\frac{F_{0}}{m}.\n$$\nThus,\n$$\n\\frac{dy_{2}}{dt} = -\\frac{k}{m}y_{1} - \\frac{c}{m}y_{2} + \\frac{F_{0}}{m}.\n$$\nCollecting these, the state-space form $\\dot{\\mathbf{y}} = A\\mathbf{y} + \\mathbf{b}$ is\n$$\n\\begin{pmatrix} \\frac{dy_1}{dt} \\\\ \\frac{dy_2}{dt} \\end{pmatrix}\n=\n\\begin{pmatrix} 0 & 1 \\\\ -\\frac{k}{m} & -\\frac{c}{m} \\end{pmatrix}\n\\begin{pmatrix} y_{1} \\\\ y_{2} \\end{pmatrix}\n+\n\\begin{pmatrix} 0 \\\\ \\frac{F_{0}}{m} \\end{pmatrix}.\n$$\nSince $y_{1} = x$ and $y_{2} = \\frac{dx}{dt}$, the correct choice is\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ -\\frac{k}{m} & -\\frac{c}{m} \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 0 \\\\ \\frac{F_{0}}{m} \\end{pmatrix},\n$$\nwhich corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1692588"}, {"introduction": "While many problems begin with a known physical law, scientists and engineers often face the inverse challenge: deducing the governing laws from observed behavior. This practice moves from theoretical modeling to empirical system identification. Using hypothetical population data from a two-species ecosystem, you will determine the unknown system matrix $A$ that governs the species' interactions [@problem_id:1692581]. This exercise demonstrates how the matrix representation serves as a powerful framework for building predictive models directly from experimental measurements.", "problem": "An ecologist is studying the population dynamics of two competing species, P and Q, within a controlled, isolated ecosystem. The populations of these species, measured in thousands of individuals at discrete time intervals, are represented by a state vector $\\mathbf{z}_k = \\begin{pmatrix} p_k \\\\ q_k \\end{pmatrix}$, where $p_k$ and $q_k$ are the populations of species P and Q at time step $k$, respectively. The evolution of the system is well-described by a linear discrete-time model:\n$$\n\\mathbf{z}_{k+1} = A \\mathbf{z}_k\n$$\nwhere $A$ is an unknown $2 \\times 2$ matrix of constant coefficients that encapsulates the growth, decay, and interaction rates of the species.\n\nTo determine the matrix $A$, the ecologist performs two independent experiments.\n\nIn the first experiment, the ecosystem is initialized with populations $\\mathbf{z}_0 = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$. After one time step, the populations are measured to be $\\mathbf{z}_1 = \\begin{pmatrix} 1.4 \\\\ 1.3 \\end{pmatrix}$.\n\nIn the second experiment, the system is reset and initialized with different populations $\\mathbf{w}_0 = \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}$. After one time step, these populations evolve to $\\mathbf{w}_1 = \\begin{pmatrix} 0.2 \\\\ 3.4 \\end{pmatrix}$.\n\nUsing the data from both experiments, determine the system matrix $A$. Present your answer as a $2 \\times 2$ matrix of real numbers.", "solution": "We use the linear discrete-time model $\\mathbf{z}_{k+1} = A \\mathbf{z}_{k}$. For any two linearly independent initial states placed as columns of a matrix, say $X = [\\mathbf{z}_{0}\\ \\mathbf{w}_{0}]$, and their images after one step placed as $Y = [\\mathbf{z}_{1}\\ \\mathbf{w}_{1}]$, linearity implies\n$$\nA X = Y \\quad \\Rightarrow \\quad A = Y X^{-1}.\n$$\nFrom the experiments,\n$$\nX = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} 1.4 & 0.2 \\\\ 1.3 & 3.4 \\end{pmatrix}.\n$$\nSince $\\det(X) = 2 \\cdot 3 - 1 \\cdot 1 = 5 \\neq 0$, $X$ is invertible with\n$$\nX^{-1} = \\frac{1}{5} \\begin{pmatrix} 3 & -1 \\\\ -1 & 2 \\end{pmatrix}.\n$$\nConvert $Y$ to exact fractions for exact arithmetic:\n$$\nY = \\begin{pmatrix} \\tfrac{7}{5} & \\tfrac{1}{5} \\\\ \\tfrac{13}{10} & \\tfrac{17}{5} \\end{pmatrix}.\n$$\nCompute the product\n$$\nM = Y \\begin{pmatrix} 3 & -1 \\\\ -1 & 2 \\end{pmatrix}\n= \\begin{pmatrix}\n\\frac{7}{5} \\cdot 3 + \\frac{1}{5} \\cdot (-1) & \\frac{7}{5} \\cdot (-1) + \\frac{1}{5} \\cdot 2 \\\\\n\\frac{13}{10} \\cdot 3 + \\frac{17}{5} \\cdot (-1) & \\frac{13}{10} \\cdot (-1) + \\frac{17}{5} \\cdot 2\n\\end{pmatrix}\n= \\begin{pmatrix}\n4 & -1 \\\\\n\\frac{1}{2} & \\frac{11}{2}\n\\end{pmatrix}.\n$$\nThen\n$$\nA = Y X^{-1} = \\frac{1}{5} M = \\begin{pmatrix} \\frac{4}{5} & -\\frac{1}{5} \\\\ \\frac{1}{10} & \\frac{11}{10} \\end{pmatrix}.\n$$\nVerification:\n$$\nA \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{8}{5} - \\frac{1}{5} \\\\ \\frac{2}{10} + \\frac{11}{10} \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{5} \\\\ \\frac{13}{10} \\end{pmatrix} = \\begin{pmatrix} 1.4 \\\\ 1.3 \\end{pmatrix}, \\quad\nA \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{5} - \\frac{3}{5} \\\\ \\frac{1}{10} + \\frac{33}{10} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{5} \\\\ \\frac{34}{10} \\end{pmatrix} = \\begin{pmatrix} 0.2 \\\\ 3.4 \\end{pmatrix}.\n$$\nThus the matrix $A$ is uniquely determined as above.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{4}{5} & -\\frac{1}{5} \\\\ \\frac{1}{10} & \\frac{11}{10}\\end{pmatrix}}$$", "id": "1692581"}, {"introduction": "The matrix representation of a system is not merely a notational convenience; its mathematical properties have profound, practical consequences, especially in the age of computational science. This final practice bridges theory and application, challenging you to investigate how the properties of a system matrix affect the numerical simulation of its dynamics. By analyzing a chain of coupled oscillators, you will explore the critical link between the matrix's condition number, $\\kappa_{2}(A)$, and the stability of a time-integration algorithm, learning why this abstract value dictates the maximum permissible time step $\\Delta t$ for a reliable simulation [@problem_id:2412352].", "problem": "Consider a one-dimensional chain of $N$ identical point masses, each of mass $m$ (in kilograms), connected by identical linear springs of stiffness $k$ (in newtons per meter) to their nearest neighbors and with the two end masses attached to fixed walls by identical springs. The small-displacement linearized dynamics of the displacement vector $x(t) \\in \\mathbb{R}^N$ is governed by the matrix second-order ordinary differential equation $M \\,\\ddot{x}(t) + K \\, x(t) = 0$, where $M = m I$ and $K$ is the symmetric tridiagonal stiffness matrix with $2k$ on the diagonal and $-k$ on the first sub- and super-diagonals.\n\nIn a widely used unconditionally stable time-integration scheme for second-order linear systems, each time step requires solving a symmetric positive-definite (SPD) linear system with an effective matrix\n$$\nK_{\\mathrm{eff}} = K + \\frac{4m}{\\Delta t^2} I,\n$$\nwhere $\\Delta t$ is the time step (in seconds) and $I$ is the identity matrix. The $2$-norm condition number of an SPD matrix $A$ is defined by\n$$\n\\kappa_2(A) = \\frac{\\sigma_{\\max}(A)}{\\sigma_{\\min}(A)} = \\frac{\\lambda_{\\max}(A)}{\\lambda_{\\min}(A)},\n$$\nwhere $\\sigma_{\\max}$ and $\\sigma_{\\min}$ are the largest and smallest singular values, and $\\lambda_{\\max}$ and $\\lambda_{\\min}$ are the largest and smallest eigenvalues, respectively.\n\nTask: For each test case below, you must:\n- Construct $K$ and $K_{\\mathrm{eff}}$ as specified.\n- Compute $\\kappa_2(K_{\\mathrm{eff}})$.\n- Decide whether $\\kappa_2(K_{\\mathrm{eff}}) \\le \\kappa_\\star$ holds, where $\\kappa_\\star$ is a given threshold that serves as a proxy for numerical safety of the repeated linear solves in the time-evolution simulation.\n- Compute the maximal time step $\\Delta t_{\\max}$ (in seconds) such that $\\kappa_2\\!\\left(K + \\frac{4m}{\\Delta t^2} I\\right) \\le \\kappa_\\star$ holds. If there is no finite upper bound on $\\Delta t$ for which the inequality holds, report the special value $-1.0$ for $\\Delta t_{\\max}$.\n\nYour program must apply the above to the following test suite of parameter tuples $(N, m, k, \\Delta t, \\kappa_\\star)$:\n- Test $1$: $(N, m, k, \\Delta t, \\kappa_\\star) = (\\,10,\\, 1.0,\\, 50.0,\\, 0.1,\\, 20.0\\,)$.\n- Test $2$ (edge case with zero coupling): $(N, m, k, \\Delta t, \\kappa_\\star) = (\\,10,\\, 1.0,\\, 0.0,\\, 0.5,\\, 1.05\\,)$.\n- Test $3$ (large chain, strong coupling): $(N, m, k, \\Delta t, \\kappa_\\star) = (\\,50,\\, 1.0,\\, 500.0,\\, 0.5,\\, 80.0\\,)$.\n- Test $4$ (unbounded-step admissibility check): $(N, m, k, \\Delta t, \\kappa_\\star) = (\\,3,\\, 1.0,\\, 100.0,\\, 1.0,\\, 6.0\\,)$.\n- Test $5$ (near-threshold behavior): $(N, m, k, \\Delta t, \\kappa_\\star) = (\\,10,\\, 1.0,\\, 1000.0,\\, 0.3,\\, 30.0\\,)$.\n\nOutput specification:\n- For each test case, produce a list with three entries $[\\kappa_2(K_{\\mathrm{eff}}),\\, \\mathrm{safe},\\, \\Delta t_{\\max}]$, where $\\mathrm{safe}$ is a boolean that is $\\,\\mathrm{True}\\,$ if and only if $\\kappa_2(K_{\\mathrm{eff}}) \\le \\kappa_\\star$ and $\\,\\mathrm{False}\\,$ otherwise, and $\\Delta t_{\\max}$ is the maximal time step in seconds as defined above (use $-1.0$ if unbounded).\n- Your program should produce a single line of output containing the results for the five test cases as a comma-separated list enclosed in square brackets, in the order of the tests above, for example:\n$[\\,[\\kappa_2^{(1)},\\mathrm{safe}^{(1)},\\Delta t_{\\max}^{(1)}],\\,[\\kappa_2^{(2)},\\mathrm{safe}^{(2)},\\Delta t_{\\max}^{(2)}],\\,\\ldots\\,]$.\nAll dimensionful quantities must be in the stated units, and no angles or percentages appear in this problem.", "solution": "The problem statement has been rigorously validated and is determined to be scientifically grounded, well-posed, and objective. It presents a standard problem in computational mechanics and numerical linear algebra. There are no scientific flaws, inconsistencies, or ambiguities.\n\nThe task is to analyze the numerical properties of a time-integration scheme for a one-dimensional chain of masses and springs. Specifically, for five given test cases, we must compute three quantities: the condition number $\\kappa_2(K_{\\mathrm{eff}})$ of an effective stiffness matrix, a boolean flag indicating if this condition number is below a given safety threshold $\\kappa_\\star$, and the maximum allowable time step $\\Delta t_{\\max}$ that respects this threshold.\n\nThe governing equation of motion for the system is given as $M \\ddot{x}(t) + K x(t) = 0$, where $M = mI$ is the mass matrix and $K$ is the stiffness matrix. The matrix $K$ is an $N \\times N$ symmetric tridiagonal matrix with $2k$ on the main diagonal and $-k$ on the first off-diagonals.\n$$\nK = k \\begin{pmatrix}\n2 & -1 & 0 & \\dots & 0 \\\\\n-1 & 2 & -1 & \\dots & 0 \\\\\n0 & -1 & 2 & \\dots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & -1 \\\\\n0 & 0 & \\dots & -1 & 2\n\\end{pmatrix}\n$$\nThis is a standard form for a discrete second derivative operator with Neumann boundary conditions, corresponding physically to the end masses being connected to fixed walls.\n\nThe eigenvalues of this specific tridiagonal Toeplitz matrix are known analytically. For an $N \\times N$ matrix of this form, the eigenvalues of $K$ are given by:\n$$\n\\lambda_j(K) = 2k \\left(1 - \\cos\\left(\\frac{j\\pi}{N+1}\\right)\\right) = 4k \\sin^2\\left(\\frac{j\\pi}{2(N+1)}\\right), \\quad \\text{for } j = 1, 2, \\dots, N\n$$\nFor $k > 0$, all eigenvalues are positive, so $K$ is positive definite. The minimum and maximum eigenvalues correspond to $j=1$ and $j=N$, respectively:\n$$\n\\lambda_{\\min}(K) = \\lambda_1(K) = 4k \\sin^2\\left(\\frac{\\pi}{2(N+1)}\\right)\n$$\n$$\n\\lambda_{\\max}(K) = \\lambda_N(K) = 4k \\sin^2\\left(\\frac{N\\pi}{2(N+1)}\\right)\n$$\nIf $k=0$, all eigenvalues of $K$ are $0$.\n\nThe time-integration scheme involves an effective stiffness matrix $K_{\\mathrm{eff}} = K + \\alpha I$, where $\\alpha = \\frac{4m}{\\Delta t^2}$ and $I$ is the $N \\times N$ identity matrix. The eigenvalues of $K_{\\mathrm{eff}}$ are simply the eigenvalues of $K$ shifted by $\\alpha$:\n$$\n\\lambda_j(K_{\\mathrm{eff}}) = \\lambda_j(K) + \\alpha\n$$\nHence, the minimum and maximum eigenvalues of $K_{\\mathrm{eff}}$ are $\\lambda_{\\min}(K_{\\mathrm{eff}}) = \\lambda_{\\min}(K) + \\alpha$ and $\\lambda_{\\max}(K_{\\mathrm{eff}}) = \\lambda_{\\max}(K) + \\alpha$.\n\nThe $2$-norm condition number of the symmetric positive-definite matrix $K_{\\mathrm{eff}}$ is the ratio of its largest to smallest eigenvalue:\n$$\n\\kappa_2(K_{\\mathrm{eff}}) = \\frac{\\lambda_{\\max}(K_{\\mathrm{eff}})}{\\lambda_{\\min}(K_{\\mathrm{eff}})} = \\frac{\\lambda_{\\max}(K) + \\frac{4m}{\\Delta t^2}}{\\lambda_{\\min}(K) + \\frac{4m}{\\Delta t^2}}\n$$\nThis formula allows for the direct computation of the first required output for each test case. The safety check is then a direct comparison: $\\mathrm{safe} = (\\kappa_2(K_{\\mathrm{eff}}) \\le \\kappa_\\star)$.\n\nTo find the maximal time step $\\Delta t_{\\max}$, we must solve the inequality $\\kappa_2(K_{\\mathrm{eff}}) \\le \\kappa_\\star$ for $\\Delta t$.\n$$\n\\frac{\\lambda_{\\max}(K) + \\frac{4m}{\\Delta t^2}}{\\lambda_{\\min}(K) + \\frac{4m}{\\Delta t^2}} \\le \\kappa_\\star\n$$\nLet's analyze the behavior of $\\kappa_2(K_{\\mathrm{eff}})$ as a function of $\\Delta t$. As $\\Delta t \\to 0$, $\\alpha \\to \\infty$, and $\\kappa_2(K_{\\mathrm{eff}}) \\to 1$. As $\\Delta t \\to \\infty$, $\\alpha \\to 0$, and $\\kappa_2(K_{\\mathrm{eff}}) \\to \\frac{\\lambda_{\\max}(K)}{\\lambda_{\\min}(K)} = \\kappa_2(K)$. The function is monotonic increasing with $\\Delta t$.\n\nThis leads to two scenarios for determining $\\Delta t_{\\max}$:\n$1$. If the limiting condition number $\\kappa_2(K)$ is already less than or equal to the threshold $\\kappa_\\star$ (i.e., $\\kappa_2(K) \\le \\kappa_\\star$), then the inequality holds for all $\\Delta t > 0$. In this case, there is no finite upper bound for the time step, so we report $\\Delta t_{\\max} = -1.0$.\n\n$2$. If $\\kappa_2(K) > \\kappa_\\star$, the inequality will be violated for sufficiently large $\\Delta t$. The maximal time step $\\Delta t_{\\max}$ is found by solving the equation at the boundary of the inequality, $\\kappa_2(K_{\\mathrm{eff}}) = \\kappa_\\star$:\n$$\n\\lambda_{\\max}(K) + \\frac{4m}{\\Delta t_{\\max}^2} = \\kappa_\\star \\left( \\lambda_{\\min}(K) + \\frac{4m}{\\Delta t_{\\max}^2} \\right)\n$$\nRearranging for $\\Delta t_{\\max}^2$:\n$$\n\\lambda_{\\max}(K) - \\kappa_\\star \\lambda_{\\min}(K) = (\\kappa_\\star - 1) \\frac{4m}{\\Delta t_{\\max}^2}\n$$\n$$\n\\Delta t_{\\max}^2 = \\frac{4m(\\kappa_\\star - 1)}{\\lambda_{\\max}(K) - \\kappa_\\star \\lambda_{\\min}(K)}\n$$\nThe denominator is positive because $\\kappa_2(K) > \\kappa_\\star$ implies $\\lambda_{\\max}(K) > \\kappa_\\star \\lambda_{\\min}(K)$. Thus, a real solution for $\\Delta t_{\\max}$ exists:\n$$\n\\Delta t_{\\max} = \\sqrt{\\frac{4m(\\kappa_\\star - 1)}{\\lambda_{\\max}(K) - \\kappa_\\star \\lambda_{\\min}(K)}}\n$$\n\nA special case occurs when $k=0$. Here, $K$ is the zero matrix, so $\\lambda_{\\min}(K) = \\lambda_{\\max}(K) = 0$. Then $K_{\\mathrm{eff}} = \\alpha I$, and $\\kappa_2(K_{\\mathrm{eff}}) = 1$. The condition becomes $1 \\le \\kappa_\\star$. Since all provided $\\kappa_\\star$ values are $\\ge 1$, this holds for all $\\Delta t > 0$, and thus $\\Delta t_{\\max} = -1.0$.\n\nFor the implementation, we will numerically construct the matrices $K$ and $K_{\\mathrm{eff}}$ and compute their eigenvalues using `numpy.linalg.eigvalsh`. This approach is robust and directly follows the problem's instruction to construct the matrices. The analytical framework derived above provides the logic for calculating $\\Delta t_{\\max}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the computational physics problem for a suite of test cases.\n\n    For each case, it calculates:\n    1. The condition number of the effective stiffness matrix.\n    2. A boolean indicating if the linear system is numerically \"safe\".\n    3. The maximum time step that maintains this safety.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each tuple is (N, m, k, delta_t, kappa_star)\n    test_cases = [\n        (10, 1.0, 50.0, 0.1, 20.0),      # Test 1\n        (10, 1.0, 0.0, 0.5, 1.05),     # Test 2\n        (50, 1.0, 500.0, 0.5, 80.0),     # Test 3\n        (3, 1.0, 100.0, 1.0, 6.0),      # Test 4\n        (10, 1.0, 1000.0, 0.3, 30.0),    # Test 5\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, m, k, delta_t, kappa_star = case\n\n        # Construct the stiffness matrix K\n        if N == 1:\n            K = np.array([[2. * k]])\n        else:\n            diag = np.full(N, 2. * k)\n            off_diag = np.full(N - 1, -k)\n            K = np.diag(diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1)\n        \n        # --- Part 1: Compute kappa_2(K_eff) and safety ---\n        \n        alpha = (4. * m) / (delta_t**2)\n        K_eff = K + alpha * np.identity(N)\n\n        # K_eff is symmetric, so we use eigvalsh for efficiency and sorted eigenvalues\n        eigvals_eff = np.linalg.eigvalsh(K_eff)\n        \n        lambda_min_eff = eigvals_eff[0]\n        lambda_max_eff = eigvals_eff[-1]\n        \n        # Condition number computation\n        # Since alpha > 0, K_eff is positive definite and lambda_min_eff > 0.\n        kappa_2_K_eff = lambda_max_eff / lambda_min_eff\n        \n        # Safety check\n        is_safe = kappa_2_K_eff = kappa_star\n\n        # --- Part 2: Compute delta_t_max ---\n        \n        # Handle the special case where k=0\n        if k == 0.0:\n            # K is the zero matrix, K_eff = alpha*I, kappa_2(K_eff) = 1.\n            # The condition 1 = kappa_star is always met for kappa_star >= 1.\n            # Thus, no finite upper bound on delta_t.\n            dt_max = -1.0\n        else:\n            # For k > 0, K is positive definite.\n            eigvals_K = np.linalg.eigvalsh(K)\n            lambda_min_K = eigvals_K[0]\n            lambda_max_K = eigvals_K[-1]\n\n            kappa_2_K = lambda_max_K / lambda_min_K\n            \n            if kappa_2_K = kappa_star:\n                # The condition number never exceeds the threshold, even as delta_t -> infinity.\n                dt_max = -1.0\n            else:\n                # A finite delta_t_max exists.\n                numerator = 4. * m * (kappa_star - 1.)\n                denominator = lambda_max_K - kappa_star * lambda_min_K\n                dt_max = np.sqrt(numerator / denominator)\n        \n        results.append([kappa_2_K_eff, is_safe, dt_max])\n\n    # Final print statement in the exact required format.\n    # The format is a list of lists, without extra spaces after commas.\n    # Ex: [[item1,item2],[item3,item4]]\n    result_strings = []\n    for res in results:\n        # Format each sublist to [val1,val2,val3] string representation\n        # str(bool) correctly gives 'True' or 'False'.\n        result_strings.append(f\"[{res[0]},{res[1]},{res[2]}]\")\n    \n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "2412352"}]}