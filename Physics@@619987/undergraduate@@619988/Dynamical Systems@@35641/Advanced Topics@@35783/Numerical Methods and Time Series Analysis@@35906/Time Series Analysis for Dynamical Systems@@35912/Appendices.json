{"hands_on_practices": [{"introduction": "A crucial first step in analyzing any real-world time series is often to distinguish the underlying signal from measurement noise. This practice introduces a fundamental technique for signal processing: the moving average. By calculating a centered moving average for a noisy temperature dataset, you will gain hands-on experience in applying a simple filter to smooth out high-frequency fluctuations and reveal a clearer trend, a skill essential for preparing data for more advanced analysis [@problem_id:1723028].", "problem": "A researcher is analyzing the temperature stability of a new material. A sensor records the material's temperature once every second, but the raw data is affected by high-frequency electronic noise. To discern the underlying temperature trend, a common signal processing technique known as a moving average is applied.\n\nConsider the following sequence of nine consecutive temperature measurements, $T_i$, recorded at time indices $i=1, 2, ..., 9$:\n$T = \\{35.3, 36.2, 35.1, 34.7, 35.8, 35.2, 36.1, 34.9, 35.5\\}$\n\nThe value of the smoothed time series at a given time index, $i$, is calculated using a 5-point centered moving average. This is defined as the arithmetic mean of the data point at index $i$, the two immediately preceding data points, and the two immediately succeeding data points.\n\nUsing this definition, calculate the smoothed temperature value at the time index $i=6$. Express your answer in degrees Celsius, rounded to three significant figures.", "solution": "A 5-point centered moving average at index $i$ is defined as the arithmetic mean of the values at indices $i-2$, $i-1$, $i$, $i+1$, and $i+2$. Denote the smoothed value by $\\overline{T}_{i}$. Then\n$$\n\\overline{T}_{i}=\\frac{1}{5}\\sum_{k=-2}^{2}T_{i+k}.\n$$\nFor $i=6$, the required indices are $4,5,6,7,8$ with values $T_{4}=34.7$, $T_{5}=35.8$, $T_{6}=35.2$, $T_{7}=36.1$, and $T_{8}=34.9$. The sum is\n$$\n34.7+35.8=70.5,\\quad 70.5+35.2=105.7,\\quad 105.7+36.1=141.8,\\quad 141.8+34.9=176.7.\n$$\nThus,\n$$\n\\overline{T}_{6}=\\frac{176.7}{5}=35.34.\n$$\nRounding to three significant figures gives $35.3$.", "answer": "$$\\boxed{35.3}$$", "id": "1723028"}, {"introduction": "Beyond simple trends, time series from dynamical systems can exhibit abrupt, qualitative changes in behavior known as bifurcations. This exercise moves from data processing to the theoretical underpinnings of such changes, focusing on the celebrated logistic map. By analytically deriving the points of a period-2 cycle, you will see precisely how a system transitions from a single steady state to a stable oscillation, providing a foundational mathematical insight into the origins of complex dynamics [@problem_id:1723003].", "problem": "A simplified model for the population dynamics of an insect species with non-overlapping generations is given by the discrete logistic map. Let $x_n$ be the population fraction (a value between 0 and 1) in the $n$-th generation. The population in the next generation, $x_{n+1}$, is determined by the equation:\n$$x_{n+1} = r x_n (1 - x_n)$$\nwhere $r$ is a positive parameter representing the combined effects of reproduction and starvation.\n\nFor certain values of $r$ (specifically for $r>3$), the population does not settle to a single, constant equilibrium value. Instead, after many generations, it enters a stable state where it alternates indefinitely between two distinct population fractions. This behavior is known as a period-2 cycle.\n\nLet the two population fractions in this stable cycle be denoted by $p_1$ and $p_2$. Find the analytical expressions for $p_1$ and $p_2$ in terms of the parameter $r$. Provide your answer as an ordered pair of expressions $(p_1, p_2)$, where $p_1 < p_2$.", "solution": "We consider the logistic map $f(x) = r x (1 - x) = r x - r x^{2}$. A period-2 cycle consists of two distinct points $p_{1}$ and $p_{2}$ such that $f(p_{1}) = p_{2}$ and $f(p_{2}) = p_{1}$, which means they are fixed points of the second iterate $f^{(2)}(x)$ but not fixed points of $f(x)$. Therefore we solve $f(f(x)) = x$ and discard the fixed points of $f$.\n\nFirst compute $f(f(x))$. Let $y = f(x) = r x - r x^{2}$. Then\n$$\nf(f(x)) = f(y) = r y - r y^{2} = r (r x - r x^{2}) - r (r x - r x^{2})^{2}.\n$$\nExpanding gives\n$$\nf(f(x)) = r^{2} x - r^{2} x^{2} - r^{3} x^{2} + 2 r^{3} x^{3} - r^{3} x^{4}.\n$$\nSetting $f(f(x)) = x$ yields\n$$\n- r^{3} x^{4} + 2 r^{3} x^{3} - r^{2} (1 + r) x^{2} + (r^{2} - 1) x = 0.\n$$\nFactor out $x$:\n$$\nx\\left(- r^{3} x^{3} + 2 r^{3} x^{2} - r^{2} (1 + r) x + (r^{2} - 1)\\right) = 0.\n$$\nThus $x=0$ is a solution (a fixed point of $f$). The cubic factor also has the other fixed point $x^{*} = 1 - \\frac{1}{r}$ as a root since any fixed point of $f$ also satisfies $f^{(2)}(x)=x$. Factoring the cubic by $(x - x^{*})$ gives a quadratic $Q(x)$:\n$$\n- r^{3} x^{3} + 2 r^{3} x^{2} - r^{2} (1 + r) x + (r^{2} - 1) = - (x - (1 - \\tfrac{1}{r})) \\left(r^{3} x^{2} - r^{2} (r + 1) x + (r^{2} + r)\\right).\n$$\nTherefore, excluding the fixed points $x=0$ and $x=1 - \\frac{1}{r}$, the period-2 points are the roots of\n$$\nr^{3} x^{2} - r^{2} (r + 1) x + (r^{2} + r) = 0.\n$$\nDividing by $r$ (since $r>0$) and then by $r^{2}$ simplifies this to\n$$\nr^{2} x^{2} - r (r + 1) x + (r + 1) = 0 \\quad \\Longleftrightarrow \\quad x^{2} - \\frac{r+1}{r} x + \\frac{r+1}{r^{2}} = 0.\n$$\nApplying the quadratic formula,\n$$\nx = \\frac{\\frac{r+1}{r} \\pm \\sqrt{\\left(\\frac{r+1}{r}\\right)^{2} - 4 \\cdot \\frac{r+1}{r^{2}}}}{2} = \\frac{1}{2}\\left(\\frac{r+1}{r} \\pm \\frac{\\sqrt{(r+1)(r-3)}}{r}\\right) = \\frac{r+1 \\pm \\sqrt{(r+1)(r-3)}}{2 r}.\n$$\nFor $r>3$ the discriminant $(r+1)(r-3)$ is positive, giving two distinct real values in $(0,1)$. Ordering them as $p_{1} < p_{2}$, we take the minus sign for $p_{1}$ and the plus sign for $p_{2}$:\n$$\np_{1} = \\frac{r+1 - \\sqrt{(r+1)(r-3)}}{2 r}, \\qquad p_{2} = \\frac{r+1 + \\sqrt{(r+1)(r-3)}}{2 r}.\n$$\nThese are the analytical expressions for the stable period-2 cycle points of the logistic map when $r>3$.", "answer": "$$\\boxed{\\left(\\frac{r+1-\\sqrt{(r+1)(r-3)}}{2 r}, \\frac{r+1+\\sqrt{(r+1)(r-3)}}{2 r}\\right)}$$", "id": "1723003"}, {"introduction": "This final practice synthesizes theoretical concepts and computational methods to tackle a core challenge in modern science: detecting bifurcations from observational data alone, without knowledge of the system's governing equations. You will implement a complete, sophisticated analysis pipeline that reconstructs a system's attractor from a time series, quantifies its complexity, and uses surrogate data to statistically test for a change in dynamics. This exercise [@problem_id:2376563] represents a powerful approach used in fields from climatology to neuroscience to identify critical transitions in complex systems.", "problem": "You are given a conceptual task grounded in time-delay embedding and surrogate data methods to analyze scalar discrete-time series for evidence of a qualitative change in dynamics that is consistent with a bifurcation. You must write a complete and runnable program that, for each provided test case, reconstructs a state-space using time-delay embedding, estimates a nonlinear invariant across two time windows, builds a surrogate-data null distribution that preserves linear properties, and performs a hypothesis test to decide whether there is statistically significant evidence of a bifurcation-like change between the two windows. The final output must be a single line containing a comma-separated list of booleans in square brackets.\n\nBegin from fundamental definitions. A scalar time series is a sequence $\\{x_n\\}_{n=0}^{N-1}$ sampled at uniform intervals. According to Takensâ€™ embedding theorem, a diffeomorphic image of the underlying attractor of a smooth dynamical system can be reconstructed from a single observable by forming delay vectors $\\mathbf{X}_n = \\left(x_n, x_{n-\\tau}, \\dots, x_{n-(m-1)\\tau}\\right)$ for embedding dimension $m$ and delay $\\tau$. You will estimate structural complexity of the reconstructed attractor using the correlation sum, defined for $M$ embedded points $\\{\\mathbf{X}_i\\}_{i=0}^{M-1}$ by\n$$\nC(r) = \\frac{2}{M(M-1)} \\sum_{0 \\le i < j \\le M-1} \\Theta\\!\\left(r - \\left\\|\\mathbf{X}_i - \\mathbf{X}_j\\right\\|\\right),\n$$\nwhere $\\Theta$ is the Heaviside step function and $\\|\\cdot\\|$ is the Euclidean norm. Over a suitable scaling range of $r$, the slope of $\\log C(r)$ versus $\\log r$ provides a proxy for the correlation dimension, which is a standard complexity measure for an attractor.\n\nTo make the computation statistically robust and computationally efficient for finite data, you must:\n- Use a Theiler window to exclude temporally adjacent pairs when forming distances, specifically requiring $|i-j| > w$ with $w = m\\tau$.\n- Estimate the slope by selecting radii $r$ in a scale range based on quantiles of the sampled pairwise distances. You may use a fixed number of radii values spaced logarithmically between two quantiles of the distance distribution, and obtain the slope by linear regression of $\\log C(r)$ on $\\log r$ over that range.\n- Approximate the correlation sum using a large uniform random sample of distinct pairs $(i,j)$ with $i \\ne j$ and $|i-j| > w$.\n\nTo test for a bifurcation-like change between an early window and a late window of the time series, construct a surrogate-data null model using the Amplitude-Adjusted Fourier Transform (AAFT) method, which preserves the marginal amplitude distribution and approximates the power spectrum (hence autocorrelation). For each window:\n- Generate $S$ independent AAFT surrogates.\n- For each window and each surrogate, compute the same slope statistic described above.\n- Let $\\Delta_{\\mathrm{obs}}$ be the observed difference between the late and early slopes. Build a Monte Carlo null distribution of differences by pairing surrogates across windows to obtain $\\{\\Delta_s\\}_{s=1}^S$ and compute the two-sided Monte Carlo $p$-value as\n$$\np = \\frac{1 + \\#\\{s : |\\Delta_s| \\ge |\\Delta_{\\mathrm{obs}}|\\}}{S+1}.\n$$\nDecide that there is evidence of a bifurcation if $p < \\alpha$ for a chosen significance level $\\alpha$.\n\nImplement the following test suite. In all cases, use embedding dimension $m = 3$, delay $\\tau = 1$, Theiler window $w = m\\tau$, surrogate count $S = 20$, pair sample size $P = 8000$, significance level $\\alpha = 0.05$, and a fixed random seed for reproducibility. The program must internally generate each time series and must standardize each analysis window by subtracting its mean and dividing by its standard deviation before embedding.\n\n- Test case $1$ (stationary nonlinear dynamics, no bifurcation expected): Logistic map with fixed parameter $r = 3.70$. Generate $N = 4096$ points from $x_{n+1} = r x_n (1 - x_n)$ starting from $x_0 = 0.2$ and discard the first $512$ values as transients before analysis.\n- Test case $2$ (slow parameter drift crossing a qualitative change, bifurcation expected): Logistic map with a linearly ramped parameter $r_n$ from $r_{\\min} = 3.20$ to $r_{\\max} = 3.70$ across $N = 4096$ points, starting at $x_0 = 0.2$, discarding the first $256$ points before analysis.\n- Test case $3$ (linear stochastic dynamics, no bifurcation expected): Autoregressive process of order $1$ given by $x_{n+1} = \\phi x_n + \\epsilon_n$ with $\\phi = 0.8$, $\\epsilon_n \\sim \\mathcal{N}(0,\\sigma^2)$ with $\\sigma = 0.5$, generating $N = 4096$ points and discarding the first $512$ points as transients before analysis.\n\nYour program must, for each test case, perform the procedure described above and decide whether there is statistically significant evidence of a bifurcation between the early and late halves of the time series. The final output must be a single line containing the three boolean results in order for test cases $1$, $2$, and $3$, formatted as a comma-separated list enclosed in square brackets (e.g., \"[True,False,True]\"). There are no physical units involved in this task. Angles, if any appear in intermediate computations, are in radians by default.\n\nYour implementation must be complete and self-contained, and must not require any user input. The program should produce exactly one line of output in the specified format.", "solution": "The problem presents a valid, well-posed computational task in the field of nonlinear time series analysis. It is grounded in established scientific principles and provides a clear, objective, and complete specification for its implementation. The task is to create a program that tests for a bifurcation-like change in dynamics within a scalar time series by comparing a complexity measure across two time windows and using a surrogate-data-based hypothesis test for statistical significance.\n\nThe solution is structured by first implementing the fundamental components of the analysis and then integrating them into a complete hypothesis-testing procedure applied to the specified test cases. The core principles are state-space reconstruction, correlation dimension as a complexity measure, and the Amplitude-Adjusted Fourier Transform (AAFT) method for generating null-hypothesis data.\n\nFirst, we address the principle of state-space reconstruction. According to Takens' embedding theorem, the dynamics of a system can be reconstructed from a single time series observable $\\{x_n\\}$. This is achieved by forming $m$-dimensional delay vectors $\\mathbf{X}_n = (x_n, x_{n-\\tau}, \\dots, x_{n-(m-1)\\tau})$, where $m$ is the embedding dimension and $\\tau$ is the time delay. For this problem, we use the specified values $m=3$ and $\\tau=1$. The collection of these vectors, $\\{\\mathbf{X}_n\\}$, forms a trajectory in an $m$-dimensional state space that is, under certain conditions, diffeomorphic to the original system's attractor.\n\nSecond, we quantify the geometric complexity of the reconstructed attractor using a proxy for the correlation dimension, $\\nu$. The correlation sum, $C(r)$, measures the probability that two randomly chosen points on the attractor are separated by a distance less than $r$. It is formally defined for $M$ points as:\n$$\nC(r) = \\frac{2}{M(M-1)} \\sum_{0 \\le i < j \\le M-1} \\Theta(r - \\|\\mathbf{X}_i - \\mathbf{X}_j\\|)\n$$\nwhere $\\Theta$ is the Heaviside step function. For a fractal attractor, $C(r)$ exhibits a power-law scaling over a range of radii, $C(r) \\propto r^\\nu$. The exponent $\\nu$ is the correlation dimension. We estimate $\\nu$ by calculating the slope of $\\log{C(r)}$ versus $\\log{r}$ via linear regression. To make this computation efficient, we approximate $C(r)$ by sampling a large number, $P=8000$, of distinct pairs of points $(\\mathbf{X}_i, \\mathbf{X}_j)$ and calculating the fraction of pairwise distances less than or equal to $r$. To avoid spurious correlations from temporally adjacent points, a Theiler window $w=m\\tau=3$ is employed, requiring that sampled pairs satisfy $|i-j| > w$. The scaling region for the linear fit is determined dynamically by selecting about $20$ radii, spaced logarithmically between the $5$-th and $95$-th percentiles of the sampled distance distribution.\n\nThird, we construct a statistical test for a change in dynamics based on surrogate data. The null hypothesis, $H_0$, is that the time series is generated by a stationary process. If $H_0$ is true, the correlation dimension estimated from an early window of the series should be statistically indistinguishable from that of a late window. A significant difference, $\\Delta_{\\mathrm{obs}} = \\nu_{\\mathrm{late}} - \\nu_{\\mathrm{early}}$, would suggest a change in the underlying dynamics, consistent with a bifurcation. To assess significance, we generate a null distribution for $\\Delta$ using the Amplitude-Adjusted Fourier Transform (AAFT) method. For each of the early and late windows, we generate $S=20$ surrogate time series. AAFT surrogates are designed to preserve the exact amplitude distribution and approximate the power spectrum (and thus the autocorrelation function) of the original data segment. They represent stationary data with linear properties similar to the original window. By computing the slope difference $\\Delta_s$ for each pair of surrogates, we build a Monte Carlo null distribution.\n\nThe statistical significance of the observed difference $\\Delta_{\\mathrm{obs}}$ is then quantified by a two-sided $p$-value, calculated as:\n$$\np = \\frac{1 + \\#\\{s : |\\Delta_s| \\ge |\\Delta_{\\mathrm{obs}}|\\}}{S+1}\n$$\nIf this $p$-value is less than the specified significance level $\\alpha=0.05$, we reject the null hypothesis of stationarity and conclude that there is evidence of a bifurcation-like change.\n\nThe entire procedure is encapsulated in a Python program. This program first generates time series for three distinct test cases: (1) a stationary chaotic logistic map, (2) a non-stationary logistic map with a drifting parameter, and (3) a stationary linear stochastic AR(1) process. Each series is divided into an early and a late half. Before analysis, each window is standardized to have zero mean and unit variance. The hypothesis test is then performed for each case, and the boolean result (True for significant change, False otherwise) is recorded. All computations involving randomness (data generation, pair sampling, surrogate creation) are governed by a single, fixed random seed to ensure full reproducibility.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import linregress\n\ndef solve():\n    \"\"\"\n    Main function to execute the bifurcation detection analysis for all test cases.\n    \"\"\"\n    # Set a fixed random seed for reproducibility of the entire script.\n    SEED = 42\n    rng = np.random.default_rng(SEED)\n\n    # --- Global parameters from the problem statement ---\n    M_DIM = 3\n    TAU = 1\n    THEILER_W = M_DIM * TAU\n    N_SURROGATES = 20\n    N_PAIRS = 8000\n    ALPHA = 0.05\n\n    # --- Time series generation functions ---\n\n    def generate_logistic(r_param, N, x0, discard, rng):\n        \"\"\"Generates a time series from the logistic map.\"\"\"\n        x = np.zeros(N)\n        x[0] = x0\n        if np.isscalar(r_param):\n            for i in range(N - 1):\n                x[i + 1] = r_param * x[i] * (1 - x[i])\n        else:  # Ramped parameter\n            for i in range(N - 1):\n                x[i + 1] = r_param[i] * x[i] * (1 - x[i])\n        return x[discard:]\n\n    def generate_ar1(phi, sigma, N, x0, discard, rng):\n        \"\"\"Generates a time series from an AR(1) process.\"\"\"\n        x = np.zeros(N)\n        x[0] = x0\n        noise = rng.normal(0, sigma, N)\n        for i in range(N - 1):\n            x[i + 1] = phi * x[i] + noise[i]\n        return x[discard:]\n\n    # --- Core analysis functions ---\n\n    def embed(series, m, tau):\n        \"\"\"Performs time-delay embedding on a series.\"\"\"\n        n_points = len(series) - (m - 1) * tau\n        # This check is added for robustness with short series\n        if n_points = 0:\n            return np.empty((0, m))\n        embedded = np.lib.stride_tricks.as_strided(\n            series,\n            shape=(n_points, m),\n            strides=(series.strides[0], series.strides[0] * tau)\n        )\n        return embedded\n\n    def generate_aaft_surrogate(series, rng):\n        \"\"\"Generates one Amplitude-Adjusted Fourier Transform (AAFT) surrogate.\"\"\"\n        n = len(series)\n        \n        # 1. Create a linear time series with the same power spectrum as the original\n        #    but with a Gaussian amplitude distribution.\n        fft_original = np.fft.rfft(series)\n        magnitudes_original = np.abs(fft_original)\n        \n        # Generate a random signal to get random phases with correct symmetry\n        noise = rng.standard_normal(n)\n        fft_noise = np.fft.rfft(noise)\n        random_phases = np.angle(fft_noise)\n        \n        # Create the new spectrum and inverse transform\n        surrogate_fft = magnitudes_original * np.exp(1j * random_phases)\n        linear_surrogate = np.fft.irfft(surrogate_fft, n=n)\n        \n        # 2. Impose the original amplitude distribution onto the linear surrogate\n        #    by rank ordering.\n        sorted_original = np.sort(series)\n        ranks = np.argsort(np.argsort(linear_surrogate))\n        \n        aaft_surrogate = sorted_original[ranks]\n        \n        return aaft_surrogate\n\n    def compute_slope(series, m, tau, w, n_pairs, rng):\n        \"\"\"Computes the correlation dimension slope for a given series.\"\"\"\n        embedded_series = embed(series, m, tau)\n        m_points = len(embedded_series)\n        \n        if m_points  w + 2:\n            return 0.0\n\n        # Sample pairs of points respecting the Theiler window\n        # Oversample to efficiently find n_pairs valid pairs\n        max_attempts = n_pairs * 5\n        cand_i = rng.integers(0, m_points, size=max_attempts)\n        cand_j = rng.integers(0, m_points, size=max_attempts)\n        \n        valid_mask = (cand_i != cand_j)  (np.abs(cand_i - cand_j) > w)\n        \n        pairs_i = cand_i[valid_mask][:n_pairs]\n        pairs_j = cand_j[valid_mask][:n_pairs]\n        \n        if len(pairs_i)  n_pairs: # Fallback if not enough pairs were found\n            return 0.0\n\n        # Compute distances and determine scaling range for radii\n        distances = np.linalg.norm(embedded_series[pairs_i] - embedded_series[pairs_j], axis=1)\n        \n        # Filter out zero distances to avoid issues with quantiles/log\n        pos_distances = distances[distances > 1e-12]\n        if len(pos_distances)  2:\n            return 0.0\n        \n        q_low, q_high = np.quantile(pos_distances, [0.05, 0.95])\n        \n        if q_high = q_low:\n             return 0.0\n        \n        radii = np.geomspace(q_low, q_high, num=20)\n        \n        # Approximate correlation sum C(r)\n        c_r = np.array([np.sum(distances = r) for r in radii]) / n_pairs\n        \n        # Perform linear regression on log-log plot to find the slope\n        valid_mask = (c_r > 1e-9)  (c_r  1.0)\n        log_radii = np.log(radii[valid_mask])\n        log_c_r = np.log(c_r[valid_mask])\n        \n        if len(log_radii)  2:\n            return 0.0 # Cannot perform regression\n        \n        slope, _, _, _, _ = linregress(log_radii, log_c_r)\n        \n        return slope if np.isfinite(slope) else 0.0\n\n    def run_test_case(series_generator, gen_params, m, tau, w, s_count, p_count, alpha_level, rng_instance):\n        \"\"\"Runs the entire hypothesis test for a single case.\"\"\"\n        ts_full = series_generator(**gen_params, rng=rng_instance)\n        \n        # Split into early and late windows\n        midpoint = len(ts_full) // 2\n        ts_early = ts_full[:midpoint]\n        ts_late = ts_full[midpoint:]\n\n        # Standardize each window\n        ts_early_std = (ts_early - np.mean(ts_early)) / np.std(ts_early)\n        ts_late_std = (ts_late - np.mean(ts_late)) / np.std(ts_late)\n        \n        # Compute observed difference in slopes\n        slope_early_obs = compute_slope(ts_early_std, m, tau, w, p_count, rng_instance)\n        slope_late_obs = compute_slope(ts_late_std, m, tau, w, p_count, rng_instance)\n        delta_obs = slope_late_obs - slope_early_obs\n\n        # Generate null distribution from surrogates\n        delta_surrogates = []\n        for _ in range(s_count):\n            surr_early = generate_aaft_surrogate(ts_early, rng_instance)\n            surr_late = generate_aaft_surrogate(ts_late, rng_instance)\n            \n            surr_early_std = (surr_early - np.mean(surr_early)) / np.std(surr_early)\n            surr_late_std = (surr_late - np.mean(surr_late)) / np.std(surr_late)\n            \n            slope_early_surr = compute_slope(surr_early_std, m, tau, w, p_count, rng_instance)\n            slope_late_surr = compute_slope(surr_late_std, m, tau, w, p_count, rng_instance)\n            \n            delta_surrogates.append(slope_late_surr - slope_early_surr)\n        \n        delta_surrogates = np.array(delta_surrogates)\n        \n        # Compute Monte Carlo p-value and make a decision\n        num_exceed = np.sum(np.abs(delta_surrogates) >= np.abs(delta_obs))\n        p_value = (1 + num_exceed) / (s_count + 1)\n        \n        return p_value  alpha_level\n\n    # --- Define and run test cases ---\n    \n    test_cases = [\n        # Case 1: Stationary Logistic Map (no bifurcation expected)\n        {\n            'generator': generate_logistic,\n            'params': {'r_param': 3.70, 'N': 4096, 'x0': 0.2, 'discard': 512}\n        },\n        # Case 2: Non-stationary Logistic Map (bifurcation expected)\n        {\n            'generator': generate_logistic,\n            'params': {'r_param': np.linspace(3.20, 3.70, 4096), 'N': 4096, 'x0': 0.2, 'discard': 256}\n        },\n        # Case 3: Stationary AR(1) Process (no bifurcation expected)\n        {\n            'generator': generate_ar1,\n            'params': {'phi': 0.8, 'sigma': 0.5, 'N': 4096, 'x0': 0.0, 'discard': 512}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(\n            series_generator=case['generator'],\n            gen_params=case['params'],\n            m=M_DIM,\n            tau=TAU,\n            w=THEILER_W,\n            s_count=N_SURROGATES,\n            p_count=N_PAIRS,\n            alpha_level=ALPHA,\n            rng_instance=rng\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2376563"}]}