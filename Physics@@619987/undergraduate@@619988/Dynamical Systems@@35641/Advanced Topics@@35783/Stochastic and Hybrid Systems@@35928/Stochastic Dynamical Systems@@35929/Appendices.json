{"hands_on_practices": [{"introduction": "The one-dimensional random walk is a foundational model in the study of stochastic processes, representing phenomena from molecular diffusion to stock price fluctuations. This first exercise invites you to explore its most fundamental property: how uncertainty evolves over time [@problem_id:1710639]. By calculating the variance of the particle's final position, you will build a quantitative understanding of how microscopic, independent random events accumulate into macroscopic, predictable statistical behavior.", "problem": "A particle undergoes a one-dimensional symmetric random walk, which serves as a simplified model for phenomena like diffusion along a polymer chain. The particle starts at an initial position of $x=0$. The walk consists of a total of $N$ discrete steps. In each step, the particle moves a fixed distance $L$ along the x-axis, with an equal probability of moving to the left (a displacement of $-L$) or to the right (a displacement of $+L$). The outcome of each step is independent of all previous steps.\n\nDetermine the variance of the particle's final position after $N$ steps. Express your answer as a closed-form analytic expression in terms of $N$ and $L$.", "solution": "Let $X_{i}$ denote the displacement at step $i$, with $X_{i} \\in \\{+L,-L\\}$ and $\\mathbb{P}(X_{i}=+L)=\\mathbb{P}(X_{i}=-L)=\\frac{1}{2}$. The steps are independent and identically distributed.\n\nThe final position after $N$ steps is the sum\n$$\nS_{N}=\\sum_{i=1}^{N} X_{i}.\n$$\nCompute the mean of a single step:\n$$\n\\mathbb{E}[X_{i}] = (+L)\\cdot \\frac{1}{2} + (-L)\\cdot \\frac{1}{2} = 0.\n$$\nSince $X_{i}^{2}=L^{2}$ always, the variance of a single step is\n$$\n\\operatorname{Var}(X_{i}) = \\mathbb{E}[X_{i}^{2}] - \\left(\\mathbb{E}[X_{i}]\\right)^{2} = L^{2} - 0 = L^{2}.\n$$\nBy linearity of expectation,\n$$\n\\mathbb{E}[S_{N}] = \\sum_{i=1}^{N} \\mathbb{E}[X_{i}] = 0.\n$$\nUsing independence, the variance of a sum is the sum of variances:\n$$\n\\operatorname{Var}(S_{N}) = \\sum_{i=1}^{N} \\operatorname{Var}(X_{i}) = \\sum_{i=1}^{N} L^{2} = N L^{2}.\n$$\nThus, the variance of the particle’s final position after $N$ steps is $N L^{2}$.", "answer": "$$\\boxed{N L^{2}}$$", "id": "1710639"}, {"introduction": "While discrete random walks are intuitive, many physical systems evolve continuously. This problem introduces the Ornstein-Uhlenbeck process, a classic continuous-time model for phenomena like the velocity of a particle in a fluid [@problem_id:1710620]. Here, you will practice a powerful technique: taking the ensemble average of a stochastic differential equation to derive a deterministic equation for the mean velocity, revealing how friction damps the initial velocity on average, despite the constant random kicks.", "problem": "The motion of a small colloidal particle suspended in a fluid at constant temperature is influenced by two main effects: a systematic frictional drag force from the fluid and random collisions from the much smaller fluid molecules. A simplified one-dimensional model for the particle's velocity, $v(t)$, is given by the Ornstein-Uhlenbeck process, which is described by the following stochastic differential equation:\n$$\ndv = -\\gamma v dt + \\sigma dW_t\n$$\nHere, $v$ is the velocity of the particle, $\\gamma$ is a positive constant representing the viscous drag coefficient, and $\\sigma$ is a positive constant that quantifies the strength of the random thermal fluctuations. The term $dW_t$ represents the increment of a standard Wiener process, which models the random kicks from the fluid molecules.\n\nConsider a large collection (an ensemble) of identical, non-interacting particles, each governed by this equation. At time $t=0$, every particle in the ensemble is prepared with the same initial velocity $v(0) = v_0$. Determine the ensemble average velocity, denoted as $\\langle v(t) \\rangle$, as a function of time $t$ and the given parameters $\\gamma$ and $v_0$.", "solution": "We consider the Ornstein-Uhlenbeck stochastic differential equation\n$$\ndv(t) = -\\gamma v(t)\\,dt + \\sigma\\, dW_{t},\n$$\nwith deterministic initial condition $v(0)=v_{0}$. Taking the ensemble average $\\langle \\cdot \\rangle$ and using linearity, we obtain\n$$\n\\frac{d}{dt}\\langle v(t)\\rangle = \\left\\langle -\\gamma v(t) \\right\\rangle + \\sigma \\left\\langle \\frac{dW_{t}}{dt} \\right\\rangle.\n$$\nSince $\\langle dW_{t} \\rangle = 0$, the second term vanishes in the mean, yielding the ordinary differential equation for the mean\n$$\n\\frac{d}{dt}\\langle v(t)\\rangle = -\\gamma \\langle v(t)\\rangle,\n$$\nwith initial condition $\\langle v(0)\\rangle = v_{0}$. Solving this first-order linear ODE (e.g., by separation of variables or integrating factor) gives\n$$\n\\langle v(t)\\rangle = v_{0}\\exp(-\\gamma t).\n$$\nEquivalently, solving the SDE explicitly via the integrating factor method gives\n$$\nd\\big(v(t)\\exp(\\gamma t)\\big) = \\sigma \\exp(\\gamma t)\\, dW_{t},\n$$\nso that\n$$\nv(t) = v_{0}\\exp(-\\gamma t) + \\sigma \\int_{0}^{t} \\exp\\big(-\\gamma (t-s)\\big)\\, dW_{s}.\n$$\nTaking the ensemble average and using the zero-mean property of the Itô integral,\n$$\n\\left\\langle \\int_{0}^{t} \\exp\\big(-\\gamma (t-s)\\big)\\, dW_{s} \\right\\rangle = 0,\n$$\nrecovers the same result\n$$\n\\langle v(t)\\rangle = v_{0}\\exp(-\\gamma t).\n$$", "answer": "$$\\boxed{v_{0}\\exp(-\\gamma t)}$$", "id": "1710620"}, {"introduction": "Having seen how to analyze the average behavior of a stochastic system, we now explore a more profound and counter-intuitive effect of noise. This exercise [@problem_id:1710671] investigates a system that is inherently unstable in a deterministic world but can be stabilized by adding a specific type of randomness, a phenomenon known as noise-induced stabilization. This practice introduces the application of Itô's lemma, a cornerstone of stochastic calculus, to determine the long-term, almost-sure behavior of a system's trajectory, showing how noise can fundamentally alter system stability.", "problem": "Consider a simple model for a population whose size is denoted by $x(t)$. In a deterministic and constant environment, its dynamics are described by the ordinary differential equation $dx/dt = a x$, where $a > 0$ is the constant net growth rate. This model predicts unbounded exponential growth for any initial population $x(0) > 0$, making the extinction state $x=0$ an unstable equilibrium.\n\nNow, let's account for random environmental fluctuations that affect the growth rate. We model this by introducing a multiplicative noise term, leading to the following Itô Stochastic Differential Equation (SDE):\n$$dX_t = a X_t dt + \\sigma X_t dW_t$$\nHere, $X_t$ is the population size at time $t$, $a$ and $\\sigma$ are positive real constants representing the mean growth rate and noise intensity respectively, and $W_t$ is a standard one-dimensional Wiener process.\n\nFor the deterministic system ($\\sigma = 0$), the origin $x=0$ is unstable. However, for a sufficiently large noise intensity $\\sigma$, the multiplicative noise can drive the population to extinction. This phenomenon is known as noise-induced stabilization. Determine the critical value of the noise intensity, $\\sigma_{crit}$, such that for any $\\sigma > \\sigma_{crit}$, the system trajectory converges to the origin almost surely (i.e., $\\lim_{t \\to \\infty} X_t = 0$ with probability 1) for any initial condition $X_0 > 0$. Express your answer for $\\sigma_{crit}$ as a symbolic expression in terms of the parameter $a$.", "solution": "We analyze the Itô SDE $dX_{t} = a X_{t} dt + \\sigma X_{t} dW_{t}$ with $a > 0$, $\\sigma > 0$, and $X_{0} > 0$.\n\nFirst, apply Itô's lemma to $f(x) = \\ln x$ for $X_{t} > 0$. Using $f'(x) = \\frac{1}{x}$, $f''(x) = -\\frac{1}{x^{2}}$, and the Itô rule $(dW_{t})^{2} = dt$, we have\n$$\nd(\\ln X_{t}) = \\frac{1}{X_{t}}\\,dX_{t} + \\frac{1}{2}\\left(-\\frac{1}{X_{t}^{2}}\\right)(dX_{t})^{2}.\n$$\nSubstituting $dX_{t} = a X_{t} dt + \\sigma X_{t} dW_{t}$ gives\n$$\n\\frac{1}{X_{t}}\\,dX_{t} = a\\,dt + \\sigma\\,dW_{t}, \\quad\n(dX_{t})^{2} = \\sigma^{2} X_{t}^{2}\\,dt,\n$$\nhence\n$$\nd(\\ln X_{t}) = \\left(a - \\frac{1}{2}\\sigma^{2}\\right)dt + \\sigma\\,dW_{t}.\n$$\nIntegrating from $0$ to $t$ yields\n$$\n\\ln X_{t} = \\ln X_{0} + \\left(a - \\frac{1}{2}\\sigma^{2}\\right)t + \\sigma W_{t},\n$$\nso the explicit solution is\n$$\nX_{t} = X_{0}\\,\\exp\\!\\left(\\left(a - \\frac{1}{2}\\sigma^{2}\\right)t + \\sigma W_{t}\\right).\n$$\n\nTo determine almost sure long-time behavior, use the strong law of large numbers for Brownian motion, which states\n$$\n\\lim_{t \\to \\infty} \\frac{W_{t}}{t} = 0 \\quad \\text{almost surely}.\n$$\nTherefore,\n$$\n\\lim_{t \\to \\infty} \\frac{\\ln X_{t}}{t} = a - \\frac{1}{2}\\sigma^{2} \\quad \\text{almost surely}.\n$$\nThere are three regimes:\n- If $a - \\frac{1}{2}\\sigma^{2} < 0$, then $\\ln X_{t} \\to -\\infty$ almost surely, hence $X_{t} \\to 0$ almost surely.\n- If $a - \\frac{1}{2}\\sigma^{2} > 0$, then $\\ln X_{t} \\to +\\infty$ almost surely, hence $X_{t} \\to \\infty$ almost surely.\n- If $a - \\frac{1}{2}\\sigma^{2} = 0$, then $\\ln X_{t} = \\ln X_{0} + \\sigma W_{t}$, and almost surely $\\liminf_{t \\to \\infty} \\ln X_{t} = -\\infty$ and $\\limsup_{t \\to \\infty} \\ln X_{t} = +\\infty$, so $X_{t}$ does not converge (with $\\liminf X_{t} = 0$ and $\\limsup X_{t} = \\infty$ almost surely).\n\nThus, the critical noise intensity separating almost sure extinction from growth is determined by $a - \\frac{1}{2}\\sigma^{2} = 0$, which gives\n$$\n\\sigma_{\\text{crit}} = \\sqrt{2 a}.\n$$\nFor any $\\sigma > \\sigma_{\\text{crit}}$, we have $\\lim_{t \\to \\infty} X_{t} = 0$ almost surely for any $X_{0} > 0$.", "answer": "$$\\boxed{\\sqrt{2 a}}$$", "id": "1710671"}]}