{"hands_on_practices": [{"introduction": "Let's begin with a foundational example from probability theory: the binomial distribution. Many complex systems in statistical mechanics, from magnetic spins to gas molecules, can be modeled as a collection of independent components. This exercise [@problem_id:1958739] demonstrates a powerful property of the cumulant generating function (CGF): for a sum of independent and identically distributed random variables, the total CGF is simply the sum of the individual CGFs. By calculating the CGF for the total number of heads in a series of coin tosses, you will master a core technique for analyzing large, complex systems.", "problem": "Consider a sequence of $N$ independent tosses of a fair coin, where the probability of observing heads on any single toss is exactly $1/2$. Let the discrete random variable $X$ represent the total number of heads observed in these $N$ tosses.\n\nIn statistical mechanics, the properties of a random variable are often analyzed using generating functions. The Moment Generating Function (MGF) for a discrete random variable $Y$ with possible outcomes $y_i$ is defined as $M_Y(t) = \\mathbb{E}[\\exp(tY)] = \\sum_i \\exp(ty_i) P(Y=y_i)$, where $\\mathbb{E}[...]$ denotes the expectation value and $P(Y=y_i)$ is the probability of outcome $y_i$. The Cumulant Generating Function (CGF), denoted as $K_Y(t)$, is defined as the natural logarithm of the MGF: $K_Y(t) = \\ln(M_Y(t))$.\n\nDetermine the Cumulant Generating Function, $K_X(t)$, for the random variable $X$. Express your answer as a function of $N$ and $t$.", "solution": "Let $X$ be the total number of heads in $N$ independent tosses of a fair coin. Write $X$ as a sum of $N$ independent and identically distributed Bernoulli random variables: $X=\\sum_{i=1}^{N} Y_{i}$, where $P(Y_{i}=1)=\\frac{1}{2}$ and $P(Y_{i}=0)=\\frac{1}{2}$.\n\nBy definition, the Moment Generating Function (MGF) of $Y_{i}$ is\n$$\nM_{Y_{i}}(t)=\\mathbb{E}[\\exp(tY_{i})]=\\exp(t)\\cdot P(Y_{i}=1)+\\exp(0)\\cdot P(Y_{i}=0)=\\frac{1}{2}\\exp(t)+\\frac{1}{2}.\n$$\nSince the $Y_{i}$ are independent, the MGF of $X$ is the product of the individual MGFs:\n$$\nM_{X}(t)=\\prod_{i=1}^{N}M_{Y_{i}}(t)=\\left(\\frac{1}{2}\\exp(t)+\\frac{1}{2}\\right)^{N}=\\left(\\frac{1+\\exp(t)}{2}\\right)^{N}.\n$$\nThe Cumulant Generating Function (CGF) is the natural logarithm of the MGF:\n$$\nK_{X}(t)=\\ln\\left(M_{X}(t)\\right)=N\\,\\ln\\left(\\frac{1+\\exp(t)}{2}\\right).\n$$\nThis gives $K_{X}(t)$ explicitly in terms of $N$ and $t$.", "answer": "$$\\boxed{N\\,\\ln\\!\\left(\\frac{1+\\exp(t)}{2}\\right)}$$", "id": "1958739"}, {"introduction": "The Poisson distribution is ubiquitous in science, describing phenomena from radioactive decays to photon arrivals from a laser. While the CGF provides a compact summary of a distribution, its true power lies in its derivatives, which yield the cumulants. This practice [@problem_id:1958741] challenges you to calculate the cumulants for the Poisson distribution and discover their surprisingly simple structure, revealing a deep statistical property that makes this distribution so fundamental in physics.", "problem": "In a quantum optics experiment, a highly sensitive detector is used to count photons arriving from a coherent source of light, such as a highly attenuated laser. The number of photons, $k$, detected in a fixed time interval is a discrete random variable. It is found that the probability of detecting exactly $k$ photons follows the Poisson distribution, given by:\n$$P(k; \\lambda) = \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$$\nwhere $k$ can be any non-negative integer ($k=0, 1, 2, \\dots$) and $\\lambda$ is a positive real parameter representing the average number of detected photons in the interval.\n\nTo analyze the statistical fluctuations of the photon counts, physicists use cumulants. The cumulants, $\\kappa_n$ (for $n=1, 2, 3, \\dots$), are derived from the cumulant-generating function (CGF), $K(t)$, which is defined as the natural logarithm of the moment-generating function (MGF), $M(t)$. The MGF is defined as the expectation value $M(t) = \\langle \\exp(tk) \\rangle$. The $n$-th cumulant is then found by taking the $n$-th derivative of the CGF with respect to $t$ and evaluating it at $t=0$:\n$$\\kappa_n = \\left. \\frac{d^n K(t)}{dt^n} \\right|_{t=0}$$\nFor the given Poisson distribution of photon counts, determine a general expression for the $n$-th cumulant, $\\kappa_n$, for any positive integer $n$. Your answer should be an analytic expression in terms of the parameter $\\lambda$.", "solution": "We are given a Poisson distribution with parameter $\\lambda$ for the photon count $k$. The moment-generating function is defined by $M(t)=\\langle \\exp(tk)\\rangle$. Using the definition of expectation with the Poisson probability mass function,\n$$\nM(t)=\\sum_{k=0}^{\\infty}P(k;\\lambda)\\exp(tk)=\\sum_{k=0}^{\\infty}\\frac{\\lambda^{k}\\exp(-\\lambda)}{k!}\\exp(tk).\n$$\nFactor out the constant $\\exp(-\\lambda)$ and combine the terms inside the sum:\n$$\nM(t)=\\exp(-\\lambda)\\sum_{k=0}^{\\infty}\\frac{\\left(\\lambda\\exp(t)\\right)^{k}}{k!}.\n$$\nRecognizing the exponential series $\\sum_{k=0}^{\\infty}a^{k}/k!=\\exp(a)$ with $a=\\lambda\\exp(t)$, we obtain\n$$\nM(t)=\\exp(-\\lambda)\\exp\\!\\left(\\lambda\\exp(t)\\right)=\\exp\\!\\left(\\lambda\\left(\\exp(t)-1\\right)\\right).\n$$\nThe cumulant-generating function is $K(t)=\\ln M(t)$, hence\n$$\nK(t)=\\ln\\!\\left(\\exp\\!\\left(\\lambda\\left(\\exp(t)-1\\right)\\right)\\right)=\\lambda\\left(\\exp(t)-1\\right).\n$$\nThe $n$-th cumulant is $\\kappa_{n}=\\left.\\frac{d^{n}K(t)}{dt^{n}}\\right|_{t=0}$. For $n\\geq 1$, differentiating $K(t)=\\lambda(\\exp(t)-1)$ yields\n$$\n\\frac{d^{n}K(t)}{dt^{n}}=\\lambda\\exp(t),\n$$\nsince each derivative of $\\exp(t)$ is $\\exp(t)$ and the derivative of the constant $-\\lambda$ is zero for $n\\ge 1$. Evaluating at $t=0$ gives\n$$\n\\kappa_{n}=\\left.\\lambda\\exp(t)\\right|_{t=0}=\\lambda.\n$$\nTherefore, for every positive integer $n$, the $n$-th cumulant equals $\\lambda$.", "answer": "$$\\boxed{\\lambda}$$", "id": "1958741"}, {"introduction": "Our exploration now transitions from discrete events to continuous processes, which are essential for describing phenomena like particle lifetimes. This exercise [@problem_id:1958773] introduces the calculation of cumulants for a continuous random variable using the exponential distribution, a key model for spontaneous decay processes. By working through this problem, you will learn how to adapt the generating function framework using integration, a crucial skill for analyzing a wide range of continuous systems in statistical physics.", "problem": "In a simplified model of spontaneous emission, a single atom is initially in an excited energy state. The process by which it decays to the ground state is random. The lifetime $T$ of the atom in the excited state is described by an exponential probability distribution. The probability density function for the atom to decay at a specific time $t \\ge 0$ is given by $p(t) = \\lambda \\exp(-\\lambda t)$, where $\\lambda$ is a positive constant known as the decay rate. For this distribution, calculate the first three cumulants, denoted by $\\kappa_1$, $\\kappa_2$, and $\\kappa_3$.\n\nProvide your answer as a set of three analytic expressions in terms of $\\lambda$.", "solution": "We are given the exponential probability density function $p(t)=\\lambda \\exp(-\\lambda t)$ for $t\\ge 0$ with rate $\\lambda>0$. Let $T$ denote the random lifetime. The cumulant generating function is defined as $K(s)=\\ln M_{T}(s)$, where the moment generating function is\n$$\nM_{T}(s)=\\mathbb{E}[\\exp(sT)]=\\int_{0}^{\\infty} \\exp(st)\\,\\lambda \\exp(-\\lambda t)\\,dt=\\lambda \\int_{0}^{\\infty} \\exp\\!\\big(-( \\lambda - s)t\\big)\\,dt,\n$$\nwhich converges for $s<\\lambda$. Evaluating the integral using $\\int_{0}^{\\infty} \\exp(-a t)\\,dt=\\frac{1}{a}$ for $a>0$ gives\n$$\nM_{T}(s)=\\frac{\\lambda}{\\lambda - s}.\n$$\nTherefore,\n$$\nK(s)=\\ln M_{T}(s)=\\ln\\!\\left(\\frac{\\lambda}{\\lambda - s}\\right)=-\\ln\\!\\left(1-\\frac{s}{\\lambda}\\right).\n$$\nThe $n$th cumulant is $\\kappa_{n}=K^{(n)}(0)$. We compute the first three derivatives explicitly. First,\n$$\nK'(s)=\\frac{d}{ds}\\left[\\ln(\\lambda)-\\ln(\\lambda - s)\\right]=\\frac{1}{\\lambda - s},\n$$\nso\n$$\n\\kappa_{1}=K'(0)=\\frac{1}{\\lambda}.\n$$\nNext,\n$$\nK''(s)=\\frac{d}{ds}\\left[(\\lambda - s)^{-1}\\right]=(\\lambda - s)^{-2},\n$$\nso\n$$\n\\kappa_{2}=K''(0)=\\frac{1}{\\lambda^{2}}.\n$$\nFinally,\n$$\nK'''(s)=\\frac{d}{ds}\\left[(\\lambda - s)^{-2}\\right]=2(\\lambda - s)^{-3},\n$$\nso\n$$\n\\kappa_{3}=K'''(0)=\\frac{2}{\\lambda^{3}}.\n$$\nThus, the first three cumulants are $\\kappa_{1}=\\frac{1}{\\lambda}$, $\\kappa_{2}=\\frac{1}{\\lambda^{2}}$, and $\\kappa_{3}=\\frac{2}{\\lambda^{3}}$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{\\lambda} & \\frac{1}{\\lambda^{2}} & \\frac{2}{\\lambda^{3}}\\end{pmatrix}}$$", "id": "1958773"}]}