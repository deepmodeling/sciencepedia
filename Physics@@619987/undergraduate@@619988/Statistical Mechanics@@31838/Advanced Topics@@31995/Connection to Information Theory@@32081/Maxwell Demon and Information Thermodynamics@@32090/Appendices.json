{"hands_on_practices": [{"introduction": "The bridge between thermodynamics and information begins with a precise way to quantify information itself. This first exercise introduces Shannon's definition of information, not as meaning, but as the reduction of uncertainty after a measurement. By analyzing a simple system of two particles in a box, you will practice calculating the information gained from a partial measurement, laying the groundwork for understanding the physical nature of information. [@problem_id:1978334]", "problem": "Consider a simplified model for a non-volatile memory cell composed of two non-interacting classical particles, labeled 1 and 2. The memory cell consists of a small, one-dimensional box. This box is conceptually divided into two equal compartments: a \"Left\" compartment and a \"Right\" compartment. The state of this two-particle system is specified by which compartment each particle occupies. Since the particles are non-interacting and their exact position within a compartment is not considered, there are four possible, equally likely microstates for the system: (Left, Left), (Left, Right), (Right, Left), and (Right, Right).\n\nA diagnostic measurement is performed on the system. This measurement, functioning like a Maxwell's demon, does not determine the full state but provides a single piece of information: it reports that both particles are located in the *same* compartment. Upon receiving this report, our knowledge about the system's microstate is updated.\n\nUsing the principles of information theory, calculate the Shannon information gained from this measurement. Express your answer in units of bits.", "solution": "We model the system with four equally likely microstates: $(L,L)$, $(L,R)$, $(R,L)$, and $(R,R)$, each with probability $p_{i}=\\frac{1}{4}$. The prior Shannon entropy is\n$$\nH_{\\text{prior}}=-\\sum_{i=1}^{4} p_{i}\\log_{2} p_{i}\n=-4\\left(\\frac{1}{4}\\right)\\log_{2}\\left(\\frac{1}{4}\\right)\n=\\log_{2} 4=2 \\text{ bits}.\n$$\nThe measurement reports the event $E$ that both particles are in the same compartment, i.e., $E=\\{(L,L),(R,R)\\}$. Its prior probability is\n$$\nP(E)=\\frac{2}{4}=\\frac{1}{2}.\n$$\nThe self-information (surprisal) of the observed outcome is\n$$\nI(E)=-\\log_{2} P(E)=-\\log_{2}\\left(\\frac{1}{2}\\right)=1 \\text{ bit}.\n$$\nConditioned on $E$, the posterior distribution is uniform over the two remaining microstates, so the posterior entropy is\n$$\nH_{\\text{post}}=-2\\left(\\frac{1}{2}\\right)\\log_{2}\\left(\\frac{1}{2}\\right)=1 \\text{ bit}.\n$$\nTherefore, the Shannon information gained, defined as the reduction in entropy, is\n$$\n\\Delta I=H_{\\text{prior}}-H_{\\text{post}}=2-1=1 \\text{ bit},\n$$\nwhich matches the self-information of the measurement outcome.", "answer": "$$\\boxed{1}$$", "id": "1978334"}, {"introduction": "Having quantified information in abstract bits, we now connect it to the physical world of thermodynamics. This problem explores how information is physically embodied, using a simplified protein chain as a model for a data storage medium. You will calculate the thermodynamic entropy associated with the vast number of possible protein sequences, directly applying Boltzmann's entropy formula, $S = k_{B} \\ln W$, to an informational context. [@problem_id:1978343]", "problem": "In the field of molecular biophysics, proteins are often conceptualized as informational polymers. The specific sequence of their constituent building blocks, known as amino acids, encodes the instructions for their three-dimensional structure and function. Consider a simplified model for a short, newly discovered peptide chain. This chain consists of a sequence of $L=10$ amino acids. There are $M=20$ common types of amino acids found in nature.\n\nFor this particular model, we assume that at any of the 10 positions in the chain, any of the 20 amino acid types can be placed with equal probability. Furthermore, the choice of amino acid at any given position is completely independent of the choices at all other positions.\n\nUsing this model, calculate the total informational entropy of this 10-amino-acid chain. The value of the Boltzmann constant is $k_B = 1.38 \\times 10^{-23}$ J/K.\n\nExpress your final answer in Joules per Kelvin (J/K), rounded to three significant figures.", "solution": "Each of the $L$ positions can independently take any of the $M$ amino acid types with equal probability. Therefore, the total number of distinct sequences (microstates) is\n$$\nW = M^{L}.\n$$\nFor equiprobable microstates, the thermodynamic (Boltzmann) entropy is\n$$\nS = k_{B} \\ln W.\n$$\nSubstituting $W = M^{L}$ gives\n$$\nS = k_{B} \\ln\\left(M^{L}\\right) = k_{B} L \\ln M.\n$$\nWith $L = 10$ and $M = 20$,\n$$\nS = k_{B} \\cdot 10 \\cdot \\ln 20.\n$$\nUsing the given $k_{B} = 1.38 \\times 10^{-23}\\ \\text{J/K}$ and $\\ln 20 \\approx 2.9957322736$,\n$$\nS \\approx \\left(1.38 \\times 10^{-23}\\right) \\times 10 \\times 2.9957322736\n= \\left(1.38 \\times 29.957322736\\right) \\times 10^{-23}\n\\approx 4.134 \\times 10^{-22}.\n$$\nRounded to three significant figures,\n$$\nS \\approx 4.13 \\times 10^{-22}\\ \\text{J/K}.\n$$", "answer": "$$\\boxed{4.13 \\times 10^{-22}}$$", "id": "1978343"}, {"introduction": "We now arrive at the heart of the matter: resolving the Maxwell's demon paradox. This culminating practice simulates a full operational cycle, from observing a rare fluctuation to extracting work and, crucially, resetting the demon's memory. By calculating both the work gained from the gas and the work spent erasing the information according to Landauer's principle, you will quantitatively verify that information is not free and that the second law of thermodynamics remains inviolate. [@problem_id:1978325]", "problem": "A sealed, rigid container of volume $V$ is held at a constant temperature $T$ and contains $n$ moles of a monatomic ideal gas. A hypothetical device, a \"Maxwell's Demon,\" is set up to monitor the positions of all the gas particles. The demon is programmed to act only when it observes the extremely rare statistical fluctuation where all gas particles spontaneously occupy the leftmost 1.00% of the container's volume. Upon detecting this specific event, the demon instantaneously inserts a massless, frictionless partition, trapping the gas in this smaller volume.\n\nThis trapped gas is then utilized to perform work on an external system by allowing it to expand isothermally back to the original volume $V$. This completes the \"work extraction\" phase of a full operational cycle.\n\nTo complete the cycle and prepare for the next observation, the demon must reset its internal memory. This memory erasure requires a certain amount of work, which is ultimately dissipated as heat into the surrounding thermal reservoir, also at temperature $T$. The demon's erasure mechanism is inefficient and requires an amount of work that is 50.0% greater than the theoretical minimum required for an isothermal process as dictated by information theory (Landauer's principle).\n\nGiven $n = 1.00$ mole and $T = 300.0$ K, calculate the total net work, $W_{net}$, performed *by* the combined system (gas + demon) on its surroundings over one complete cycle. A positive value for $W_{net}$ indicates net work done by the system, while a negative value indicates net work done on the system. Use the ideal gas constant $R = 8.314 \\text{ J/(mol·K)}$.\n\nExpress your final answer in kilojoules (kJ) and round it to three significant figures.", "solution": "The gas initially occupies a fraction $f=0.0100$ of the container volume when the fluctuation occurs. The partition insertion is instantaneous and frictionless, so no work is done during insertion. The gas then expands isothermally from $V_{i}=fV$ to $V_{f}=V$ at temperature $T$.\n\nFor an ideal gas undergoing isothermal expansion, the work done by the gas on the surroundings is\n$$\nW_{\\text{exp}}=\\int_{V_{i}}^{V_{f}} P\\,\\mathrm{d}V=nRT\\ln\\!\\left(\\frac{V_{f}}{V_{i}}\\right)=nRT\\ln\\!\\left(\\frac{1}{f}\\right).\n$$\nWith $f=0.0100$, this gives\n$$\nW_{\\text{exp}}=nRT\\ln(100).\n$$\n\nAccording to Landauer’s principle, the minimal work required to erase information with Shannon information content $I$ (in nats) at temperature $T$ is\n$$\nW_{\\min}=k_{B}TI.\n$$\nThe demon’s observation corresponds to the rare event that all $N$ particles lie in the left fraction $f$ of the volume. Assuming independence, the probability of this event is $p=f^{N}$, so the information content (surprisal) of this event is\n$$\nI=-\\ln p=-\\ln\\!\\left(f^{N}\\right)=N\\ln\\!\\left(\\frac{1}{f}\\right).\n$$\nTherefore the theoretical minimal erasure work for one completed cycle (conditioned on the event occurring) is\n$$\nW_{\\min}=k_{B}TN\\ln\\!\\left(\\frac{1}{f}\\right).\n$$\nUsing $N=nN_{A}$ and $k_{B}N_{A}=R$, this becomes\n$$\nW_{\\min}=nRT\\ln\\!\\left(\\frac{1}{f}\\right)=nRT\\ln(100).\n$$\nThe demon’s erasure mechanism requires $50.0\\%$ more than this minimum, so the actual erasure work input is\n$$\nW_{\\text{erase}}=1.5\\,W_{\\min}=1.5\\,nRT\\ln(100).\n$$\n\nThe net work done by the combined system (gas + demon) on the surroundings over one full cycle is\n$$\nW_{\\text{net}}=W_{\\text{exp}}-W_{\\text{erase}}=nRT\\ln(100)-1.5\\,nRT\\ln(100)=-0.5\\,nRT\\ln(100).\n$$\n\nSubstituting $n=1.00$, $R=8.314\\ \\text{J/(mol·K)}$, $T=300.0\\ \\text{K}$, and $\\ln(100)=4.605170186$,\n$$\nW_{\\text{net}}=-0.5\\times(1.00)(8.314)(300.0)\\times 4.605170186\\ \\text{J}.\n$$\nCompute $nRT=(1.00)(8.314)(300.0)=2494.2\\ \\text{J}$, so\n$$\nW_{\\text{net}}=-0.5\\times 2494.2\\times 4.605170186\\ \\text{J}=-5743.1\\ \\text{J}=-5.743\\ \\text{kJ}.\n$$\nRounded to three significant figures in kilojoules,\n$$\nW_{\\text{net}}=-5.74\\ \\text{kJ}.\n$$", "answer": "$$\\boxed{-5.74}$$", "id": "1978325"}]}