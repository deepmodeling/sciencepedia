{"hands_on_practices": [{"introduction": "要真正掌握能级间距分布，第一步是深入理解其数学形态。高斯正交系综（GOE）的维格纳猜想是理解具有时间反演对称性的复杂系统的基石。通过求解其分布函数的拐点，我们不仅能练习应用微积分来分析物理中有意义的函数，还能更直观地把握能级排斥现象在数学上的体现，即分布函数在原点附近是如何从快速增长转变为逐渐衰减的 [@problem_id:881630]。", "problem": "在随机矩阵理论中，复杂量子系统的能级的统计特性通过大随机矩阵的特征值来建模。一个关键的统计量是相邻能级间距 $s$ 的分布，这是在经过一个称为“展开”（unfolding）的归一化过程之后得到的，该过程将平均间距设为1。\n\n对于具有时间反演不变性的系统，其哈密顿量可以由一个实对称矩阵表示，相关的矩阵系综是高斯正交系综（GOE）。展开的能级间距的概率分布 $P(s)$ 可以由 Wigner 猜想很好地近似，该猜想是从 2x2 矩阵的精确解推导出来的。GOE Wigner 猜想由以下概率密度函数给出：\n$$\nP(s) = \\frac{\\pi s}{2} \\exp\\left(-\\frac{\\pi s^2}{4}\\right) \\quad \\text{for } s \\ge 0\n$$\n该分布表现出能级排斥，即当 $s \\to 0$ 时 $P(s) \\to 0$。它有一个单峰，并在大间距处快速衰减。\n\n函数的拐点是其图像上曲率或凹凸性改变符号的点。对于一个二阶可导函数，拐点出现在其二阶导数为零且改变符号的地方。\n\n确定与 GOE Wigner 猜想分布 $P(s)$ 的非平凡拐点相对应的展开能级间距 $s$ 的值。", "solution": "我们有\n$$P(s)=\\frac{\\pi s}{2}\\exp\\!\\biggl(-\\frac{\\pi s^2}{4}\\biggr)\\,. $$\n1. 计算一阶导数：\n$$P'(s)=\\frac{\\pi}{2}\\frac{d}{ds}\\Bigl[s\\,e^{-B s^2}\\Bigr],\\quad B=\\frac{\\pi}{4}.$$\n使用乘法法则，\n$$P'(s)=\\frac{\\pi}{2}\\Bigl(e^{-B s^2}+s(-2B s)e^{-B s^2}\\Bigr)\n=\\frac{\\pi}{2}e^{-B s^2}\\bigl(1-2B s^2\\bigr).$$\n2. 计算二阶导数：\n$$P''(s)=\\frac{\\pi}{2}\\frac{d}{ds}\\Bigl[e^{-B s^2}(1-2B s^2)\\Bigr].$$\n再次使用乘法法则得到\n$$P''(s)=\\frac{\\pi}{2}\\,e^{-B s^2}\\Bigl[-2B s(1-2B s^2)-4B s\\Bigr]\n=\\frac{\\pi}{2}e^{-B s^2}\\bigl(4B^2s^3-6Bs\\bigr).$$\n提取公因式 $2B s$：\n$$P''(s)=\\frac{\\pi}{2}e^{-B s^2}\\,2B s\\,(2B s^2-3).$$\n3. 拐点满足 $P''(s)=0$。排除平凡解 $s=0$ 后，我们令\n$$2B s^2-3=0\\quad\\Longrightarrow\\quad s^2=\\frac{3}{2B}=\\frac{3}{2\\cdot(\\pi/4)}=\\frac{6}{\\pi}\\,. $$\n因此，非平凡拐点是\n$$s=\\sqrt{\\frac{6}{\\pi}}\\,. $$", "answer": "$$\\boxed{\\sqrt{\\frac{6}{\\pi}}}$$", "id": "881630"}, {"introduction": "随机矩阵理论根据哈密顿量的对称性将系统分为不同类别，其中最基本的是高斯正交系综 (GOE) 和高斯酉系综 (GUE)，它们分别描述了具有和不具有时间反演对称性的系统。这两种系综表现出不同强度的能级排斥，GUE 的排斥 ($P(s) \\sim s^2$) 比 GOE ($P(s) \\sim s$) 更强。本练习通过一个直接的概率计算，让你量化比较这两种基本分布，从而加深对不同对称性类别如何影响能级统计的理解 [@problem_id:881650]。", "problem": "在量子混沌的研究中，一个量子系统的能级间距的统计特性常常与来自特定系综的随机矩阵的本征值间距进行比较。Wigner 猜想为最近邻间距分布 $P(s)$ 提供了一个极好的近似，其中 $s$ 是经平均间距归一化的间距。\n\n对于具有时间反演对称性的系统，相应的系综是高斯正交系综 (GOE)，其归一化间距分布由下式给出：\n$$P_{GOE}(s) = \\frac{\\pi}{2} s \\exp\\left(-\\frac{\\pi}{4} s^2\\right), \\quad s \\ge 0$$\n\n对于时间反演对称性被破坏的系统，相应的系综是高斯酉系综 (GUE)，其分布为：\n$$P_{GUE}(s) = \\frac{32}{\\pi^2} s^2 \\exp\\left(-\\frac{4}{\\pi} s^2\\right), \\quad s \\ge 0$$\n\n注意能级排斥的差异：当 $s$ 很小时，$P_{GOE}(s) \\sim s$，而 $P_{GUE}(s) \\sim s^2$。这表明在 GUE 系统中，小间距被更强烈地抑制。\n\n考虑一个从 GOE 分布中抽取的随机间距 $S_1$ 和一个从 GUE 分布中抽取的独立随机间距 $S_2$。计算 GOE 系统的间距小于 GUE 系统的间距的概率，即求 $P(S_1  S_2)$ 的值。", "solution": "我们需要计算 $P(S_1  S_2)$，其中 $S_1$ 从 GOE 分布中抽取，$S_2$ 从 GUE 分布中抽取。由于两者是独立的，该概率可以通过在区域 $S_1  S_2$ 上对联合概率密度进行积分得到。\n$$\nP(S_1  S_2) = \\int_0^\\infty dS_2 \\, P_{GUE}(S_2) \\int_0^{S_2} dS_1 \\, P_{GOE}(S_1)\n$$\n内部的积分是 GOE 分布的累积分布函数 (CDF)，即 $F_{GOE}(S_2)$。\n$$\nF_{GOE}(S_2) = \\int_0^{S_2} \\frac{\\pi}{2} s_1 e^{-\\frac{\\pi}{4}s_1^2} ds_1 = \\left[ -e^{-\\frac{\\pi}{4}s_1^2} \\right]_0^{S_2} = 1 - e^{-\\frac{\\pi}{4}S_2^2}\n$$\n我们将此结果代入外部积分：\n$$\nP(S_1  S_2) = \\int_0^\\infty P_{GUE}(S_2) \\left( 1 - e^{-\\frac{\\pi}{4}S_2^2} \\right) dS_2\n$$\n这可以分解为两个积分：\n$$\nP(S_1  S_2) = \\int_0^\\infty P_{GUE}(S_2) dS_2 - \\int_0^\\infty P_{GUE}(S_2) e^{-\\frac{\\pi}{4}S_2^2} dS_2\n$$\n第一项积分为 1，因为 $P_{GUE}$ 是一个概率密度函数。第二项积分 $I$ 为：\n$$\nI = \\int_0^\\infty \\left( \\frac{32}{\\pi^2} S_2^2 e^{-\\frac{4}{\\pi}S_2^2} \\right) e^{-\\frac{\\pi}{4}S_2^2} dS_2\n$$\n合并指数项：\n$$\nI = \\frac{32}{\\pi^2} \\int_0^\\infty S_2^2 \\exp\\left( -\\left(\\frac{4}{\\pi} + \\frac{\\pi}{4}\\right)S_2^2 \\right) dS_2\n$$\n令指数中的系数为 $A = \\frac{4}{\\pi} + \\frac{\\pi}{4} = \\frac{16 + \\pi^2}{4\\pi}$。积分变为：\n$$\nI = \\frac{32}{\\pi^2} \\int_0^\\infty S_2^2 e^{-A S_2^2} dS_2\n$$\n我们使用标准高斯积分公式 $\\int_0^\\infty x^2 e^{-ax^2} dx = \\frac{\\sqrt{\\pi}}{4a^{3/2}}$。将 $a=A$ 代入，我们得到：\n$$\nI = \\frac{32}{\\pi^2} \\left( \\frac{\\sqrt{\\pi}}{4A^{3/2}} \\right) = \\frac{8\\sqrt{\\pi}}{\\pi^2 A^{3/2}} = \\frac{8}{(\\pi A)^{3/2}}\n$$\n代入 $A$ 的表达式：\n$$\nI = \\frac{8}{\\left(\\pi \\frac{16 + \\pi^2}{4\\pi}\\right)^{3/2}} = \\frac{8}{\\left(\\frac{16 + \\pi^2}{4}\\right)^{3/2}} = \\frac{8 \\cdot 4^{3/2}}{(16 + \\pi^2)^{3/2}} = \\frac{8 \\cdot 8}{(16 + \\pi^2)^{3/2}} = \\frac{64}{(\\pi^2 + 16)^{3/2}}\n$$\n最终，概率为 $P(S_1  S_2) = 1 - I$。\n$$\nP(S_1  S_2) = 1 - \\frac{64}{(\\pi^2 + 16)^{3/2}}\n$$", "answer": "$$\\boxed{1-\\frac{64}{(\\pi^2+16)^{3/2}}}$$", "id": "881650"}, {"introduction": "理论的价值最终体现在其预测与实验或模拟结果的吻合程度上。维格纳猜想为能级间距提供了一个简洁的解析形式，但亲手验证这一理论是巩固理解的关键一步。这个计算实践引导你完成一个完整的数值实验：从生成高斯正交系综（GOE）的随机矩阵，到计算其本征值间距，再到使用柯尔莫哥洛夫-斯米尔诺夫检验等统计工具来量化经验数据与理论预测的符合程度，从而在理论和计算之间建立起一座坚实的桥梁 [@problem_id:2387505]。", "problem": "考虑高斯正交系综 (GOE)。一个大小为 $N$ 的 GOE 矩阵是一个实对称随机矩阵 $H \\in \\mathbb{R}^{N \\times N}$，其构造方式为：对角线上方的元素是均值为 $0$、方差为 $1$ 的独立同分布正态随机变量，对角线上的元素是均值为 $0$、方差为 $2$ 的独立正态随机变量，并且 $H_{ij} = H_{ji}$。等价地，可以定义 $H = \\left(R + R^{\\mathsf{T}}\\right)/\\sqrt{2}$，其中 $R$ 的元素是独立同分布的标准正态分布。对于每个矩阵 $H$，令其有序特征值为 $\\lambda_1 \\leq \\lambda_2 \\leq \\cdots \\leq \\lambda_N$。定义最近邻间距为 $s_k = \\lambda_{k+1} - \\lambda_k$，其中 $k = 1, 2, \\ldots, N-1$。对于给定的 $N$，将指定数量的独立抽取矩阵的所有此类间距聚合起来。通过除以样本均值来归一化这些间距，使得归一化后的间距具有单位均值。对于 GOE，归一化最近邻间距的概率密度函数的 Wigner 猜想是\n$$\nP_{\\mathrm{W}}(s) = \\frac{\\pi}{2} s \\, e^{-\\frac{\\pi}{4} s^2}, \\quad s \\ge 0,\n$$\n其累积分布函数为\n$$\nF_{\\mathrm{W}}(s) = \\int_0^s P_{\\mathrm{W}}(t)\\, dt = 1 - e^{-\\frac{\\pi}{4} s^2}.\n$$\n令 $F_n(s)$ 表示在给定测试案例中，由归一化间距构建的经验累积分布函数。使用 Kolmogorov–Smirnov 距离来量化与 Wigner 猜想的一致性\n$$\nD = \\sup_{s \\ge 0} \\left| F_n(s) - F_{\\mathrm{W}}(s) \\right|.\n$$\n您的任务是编写一个完整的程序，对于下方的每个测试案例，按照描述构造 GOE 间距，将其归一化至单位均值，计算归一化间距的经验分布与 $F_{\\mathrm{W}}(s)$ 之间的 Kolmogorov–Smirnov 距离 $D$，并输出 $D$。\n\n测试套件（每个测试案例是一个三元组 $(N, M, s)$，其中 $N$ 是矩阵大小，$M$ 是独立抽取的矩阵数量，$s$ 是伪随机数生成器的种子）：\n- 案例 1：$(N, M, s) = (2, 10000, 17)$。\n- 案例 2：$(N, M, s) = (40, 120, 2024)$。\n- 案例 3：$(N, M, s) = (3, 200, 7)$。\n\n所有数值输出必须表示为纯十进制数。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的结果与上述案例顺序相同，每个 Kolmogorov–Smirnov 距离四舍五入到六位小数（例如，$[0.012345,0.067890,0.123456]$）。", "solution": "所述问题是有效的。它提出了一个明确定义的计算任务，该任务植根于随机矩阵理论 (RMT) 的既定原则，这是数学物理学的一个关键领域。该问题具有科学依据，对高斯正交系综 (GOE)、能级间距的 Wigner 猜想以及适当的统计度量——Kolmogorov-Smirnov 距离，都给出了正确的定义。数值模拟的参数已完全指定，包括矩阵维度、样本大小和随机种子，这确保了问题的自包含性和解的可复现性。不存在逻辑矛盾、含糊不清或事实错误。\n\n解将通过直接数值模拟获得，遵循问题陈述中概述的明确步骤。对于每个测试案例，其特征在于矩阵维度 $N$、矩阵实现数量 $M$ 以及伪随机数生成器种子 $s$，我们将执行以下系统性步骤。\n\n首先，我们使用提供的种子 $s$ 初始化随机数生成器。这对于结果的可复现性至关重要。\n\n该程序的核心是生成特征值间距的统计系综。我们重复以下步骤 $M$ 次：\n1.  构造 GOE 矩阵：我们生成一个 $N \\times N$ 的 GOE 矩阵 $H$。问题给出了一个高效的构造性定义，$H = (R + R^{\\mathsf{T}})/\\sqrt{2}$，其中 $R$ 是一个矩阵，其元素 $R_{ij}$ 独立地从标准正态分布 $\\mathcal{N}(0, 1)$ 中抽取。此方法正确地生成了一个实对称矩阵 $H$，其中对角元素 $H_{ii}$ 服从 $\\mathcal{N}(0, 2)$ 分布，非对角元素 $H_{ij}$ (对于 $i \\neq j$) 服从 $\\mathcal{N}(0, 1)$ 分布，满足 GOE 的定义。\n2.  特征值计算：对于每个生成的矩阵 $H$，我们计算其 $N$ 个特征值。由于 $H$ 是实对称的，其特征值保证为实数。我们使用为对称矩阵优化的数值稳定算法，例如 `numpy.linalg.eigh` 函数提供的算法。该函数还有一个额外的好处，即按升序返回特征值，$\\lambda_1 \\le \\lambda_2 \\le \\cdots \\le \\lambda_N$。\n3.  间距计算：从排序后的特征值列表中，我们计算 $N-1$ 个最近邻间距，定义为 $s_k = \\lambda_{k+1} - \\lambda_k$，其中 $k=1, 2, \\ldots, N-1$。\n\n对所有 $M$ 个矩阵重复此过程后，我们将得到的 $M(N-1)$ 个间距聚合到一个数据集中。\n\n下一步是归一化。理论上的 Wigner 分布是基于单位均值间距的。为了将我们的经验数据与该理论进行比较，我们必须重新缩放我们的数据集。我们计算所有收集到的间距的样本均值 $\\bar{s}$，然后通过除以该均值来归一化每个间距 $s_k$：$s'_k = s_k / \\bar{s}$。得到的归一化间距集合 $\\{s'_k\\}$ 的样本均值现在为 $1$。\n\n最后，我们使用 Kolmogorov-Smirnov (KS) 距离 $D$ 来量化我们的归一化间距的经验分布与理论上的 Wigner 猜想之间的一致性。KS 距离是数据的经验累积分布函数 $F_n(s)$ 与理论累积分布函数 $F_{\\mathrm{W}}(s)$ 之间的最大绝对差：\n$$\nD = \\sup_{s \\ge 0} \\left| F_n(s) - F_{\\mathrm{W}}(s) \\right|\n$$\nWigner 猜想的累积分布函数 (CDF) 已给出：\n$$\nF_{\\mathrm{W}}(s) = 1 - e^{-\\frac{\\pi}{4} s^2}\n$$\n经验累积分布函数 $F_n(s)$ 是一个由归一化间距构造的阶跃函数。为了计算 $D$，我们将利用 `scipy.stats` 库中提供的一种标准的、稳健的单样本 KS 检验实现。这个函数 `kstest` 将我们的归一化间距样本和一个代表理论累积分布函数 $F_{\\mathrm{W}}(s)$ 的可调用对象作为输入，并返回 KS 距离 $D$。\n\n对每个指定的测试案例执行此计算过程。然后将得到的 $D$ 值格式化为六位小数，并以要求的输出格式呈现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import kstest\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases.\n    For each case, it generates GOE matrices, computes eigenvalue spacings,\n    normalizes them, and calculates the Kolmogorov-Smirnov distance\n    to the Wigner surmise CDF.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2, 10000, 17),    # Case 1: (N, M, seed)\n        (40, 120, 2024),   # Case 2: (N, M, seed)\n        (3, 200, 7),       # Case 3: (N, M, seed)\n    ]\n\n    results = []\n    \n    # Define the Wigner surmise cumulative distribution function (CDF)\n    # for the Gaussian Orthogonal Ensemble (GOE).\n    def F_W(s):\n        return 1.0 - np.exp(-np.pi / 4.0 * s**2)\n\n    for N, M, seed in test_cases:\n        # Initialize the random number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n        \n        all_spacings = []\n\n        # Generate M matrices and collect their eigenvalue spacings.\n        for _ in range(M):\n            # Generate an N x N matrix with i.i.d. standard normal entries.\n            R = rng.standard_normal(size=(N, N))\n            \n            # Construct the symmetric GOE matrix H.\n            H = (R + R.T) / np.sqrt(2.0)\n            \n            # Calculate eigenvalues. eigh is for Hermitian (real-symmetric)\n            # matrices and returns sorted eigenvalues.\n            eigenvalues = np.linalg.eigh(H)[0]\n            \n            # Calculate the nearest-neighbor spacings.\n            spacings = np.diff(eigenvalues)\n            all_spacings.append(spacings)\n\n        # Concatenate all spacings from all matrices into a single array.\n        # This check is for the edge case where M*(N-1) is 0.\n        if not all_spacings:\n            # If no spacings, KS distance is undefined.\n            # As per problem constraints N=2, so this won't happen.\n            ks_dist = 0.0\n        else:\n            flat_spacings = np.concatenate(all_spacings)\n            \n            # Normalize the spacings to have a unit mean.\n            mean_spacing = np.mean(flat_spacings)\n            if mean_spacing  0:\n                normalized_spacings = flat_spacings / mean_spacing\n            else:\n                # This case is highly improbable with this generator.\n                # If mean is 0, normalization is not meaningful.\n                # We can skip KS-test as the data is pathological.\n                # We expect positive spacings from sorted distinct eigenvalues.\n                normalized_spacings = flat_spacings\n            \n            # Compute the Kolmogorov-Smirnov distance D between the\n            # empirical distribution of spacings and the Wigner surmise CDF.\n            # The kstest returns the statistic (D) and the p-value.\n            ks_dist, _ = kstest(normalized_spacings, F_W)\n\n        results.append(ks_dist)\n\n    # Final print statement in the exact required format.\n    # The output is a comma-separated list of D values rounded to six decimal places.\n    print(f\"[{','.join(f'{d:.6f}' for d in results)}]\")\n\nsolve()\n```", "id": "2387505"}]}