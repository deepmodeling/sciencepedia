{
    "hands_on_practices": [
        {
            "introduction": "An optimal cross-correlation analysis requires weighting each spectral data point by its uncertainty, a process that maximizes the signal-to-noise ratio of the final detection. This practice dives into the fundamentals of noise modeling for high-resolution spectrographs, asking you to derive the total variance for a spectral pixel from first principles. You will learn to combine various noise sources—including photon shot noise, detector read noise, and dark current—to build a realistic error budget, a critical skill for any observational astronomer.",
            "id": "4163453",
            "problem": "A high-resolution echelle spectrograph records a two-dimensional detector image in which each wavelength pixel index $i$ is sampled across five spatial pixels $j=1,\\dots,5$. You extract the one-dimensional spectrum at wavelength pixel $i$ using optimal weights $w_j$ that sum to unity. The instrument gain is $g$ electrons per Analog-to-Digital Unit (ADU), the per-pixel read noise has Gaussian statistics with standard deviation $\\sigma_r$ electrons, and the dark current rate is $d$ electrons per second with exposure time $t$. The bias level is estimated from an overscan region and subtracted from each detector pixel prior to extraction; the bias estimate has Gaussian uncertainty with standard deviation $\\sigma_b$ electrons and is common to all $j$ at fixed $i$. You may assume all photon-counting processes (object and sky) obey Poisson statistics, the read noise and bias errors are independent of photon noise and of each other, and the sky background at pixel $i$ is estimated and included in the counts without sky subtraction. You then continuum-normalize the extracted flux $F_i$ by dividing by a local continuum estimate $C_i$ (in electrons) obtained from a smooth fit; the continuum estimate has negligible uncertainty.\n\nFor a specific wavelength pixel $i$, the data and parameters are:\n- Optimal extraction weights $w_1=w_5=0.06$, $w_2=w_4=0.24$, $w_3=0.40$.\n- Object counts in ADU across spatial pixels: $O_{i,j} \\in \\{120,\\,480,\\,800,\\,480,\\,120\\}$ for $j=1,\\dots,5$.\n- Sky counts in ADU across spatial pixels: $S_{i,j}=20$ for all $j$.\n- Gain: $g=1.7$ electrons per ADU.\n- Read noise standard deviation: $\\sigma_r=3.5$ electrons.\n- Dark current rate: $d=0.01$ electrons per second; exposure time: $t=1200$ seconds.\n- Bias estimate standard deviation: $\\sigma_b=1.2$ electrons.\n- Continuum estimate: $C_i=1000$ electrons.\n\nStarting from first principles of Poisson and Gaussian noise and the rules of uncertainty propagation, derive the per-pixel variance of the normalized flux $f_i=F_i/C_i$ to be used for optimal weighting in the cross-correlation function (CCF). Compute the numerical value for this wavelength pixel. Express the final variance in dimensionless units and round your answer to four significant figures.",
            "solution": "The problem requires the derivation and calculation of the variance of a continuum-normalized flux measurement from a high-resolution spectrograph. The process involves identifying all sources of noise, both independent and correlated, and propagating them through the flux extraction and normalization steps.\n\nLet the measured signal in Analog-to-Digital Units (ADU) for a given wavelength pixel $i$ and spatial pixel $j$ be denoted by the sum of object and sky counts, $D_{i,j} = O_{i,j} + S_{i,j}$. The conversion from ADU to electrons is determined by the gain, $g$. The signal in electrons from photons is thus $g D_{i,j}$. Additionally, there is a contribution from dark current, which accumulates over the exposure time $t$ at a rate $d$. The total number of signal electrons generated in the pixel is the sum of photon-generated electrons and dark current electrons. Both are Poisson processes. The mean number of signal electrons in spatial pixel $j$ is given by:\n$$ \\mu_j = g (O_{i,j} + S_{i,j}) + d \\times t $$\nThe variance of this signal generation process, due to the Poisson nature of both photon counting and dark current, is equal to the mean number of electrons: $\\text{Var}_{\\text{signal}} = \\mu_j$.\n\nThe measurement process introduces additional noise. Let $\\tilde{N}_j$ be the final measured electron count for spatial pixel $j$ (at fixed wavelength $i$) after all processing steps (bias subtraction, gain conversion). This measurement can be modeled as the sum of a true signal component and several independent noise components. We must, however, properly account for the bias subtraction uncertainty, which is a common error for all pixels.\n\nLet us model the measured value $\\tilde{N}_j$ for pixel $j$ as:\n$$ \\tilde{N}_j = P_j + D_j + \\epsilon_{r,j} + \\epsilon_b $$\nwhere:\n- $P_j$ is the Poisson-distributed number of photoelectrons, with mean and variance both equal to $g(O_{i,j} + S_{i,j})$.\n- $D_j$ is the Poisson-distributed number of dark current electrons, with mean and variance both equal to $d \\times t$.\n- $\\epsilon_{r,j}$ is the Gaussian-distributed read noise for pixel $j$, with mean $0$ and variance $\\sigma_r^2$. The read noise is independent for each pixel.\n- $\\epsilon_b$ is the Gaussian-distributed error in the bias subtraction, with mean $0$ and variance $\\sigma_b^2$. This error is common to all spatial pixels $j=1, \\dots, 5$ for the given wavelength pixel $i$.\n\nLet us define an independent noise component for each pixel, $U_j$, and a common noise component, $C$.\nThe total measured signal is $\\tilde{N}_j = U_j + C$, where:\n- $U_j = P_j + D_j + \\epsilon_{r,j}$ represents the components that are independent from pixel to pixel. Its variance is $\\text{Var}(U_j) = \\text{Var}(P_j) + \\text{Var}(D_j) + \\text{Var}(\\epsilon_{r,j}) = g(O_{i,j} + S_{i,j}) + d \\times t + \\sigma_r^2 = \\mu_j + \\sigma_r^2$.\n- $C = \\epsilon_b$ represents the common error component. Its variance is $\\text{Var}(C) = \\sigma_b^2$.\n\nThe extracted one-dimensional flux, $F_i$, is the optimal-weighted sum of the signals from the $5$ spatial pixels:\n$$ F_i = \\sum_{j=1}^{5} w_j \\tilde{N}_j = \\sum_{j=1}^{5} w_j (U_j + C) = \\sum_{j=1}^{5} w_j U_j + C \\sum_{j=1}^{5} w_j $$\nThe variance of the extracted flux, $\\text{Var}(F_i)$, is found by propagating the variances of the components. Since the $U_j$ terms are independent of each other and of $C$, the variance of the sum is:\n$$ \\text{Var}(F_i) = \\text{Var}\\left(\\sum_{j=1}^{5} w_j U_j\\right) + \\text{Var}\\left(C \\sum_{j=1}^{5} w_j\\right) $$\n$$ \\text{Var}(F_i) = \\sum_{j=1}^{5} w_j^2 \\text{Var}(U_j) + \\left(\\sum_{j=1}^{5} w_j\\right)^2 \\text{Var}(C) $$\nSubstituting the expressions for the variances and noting the given condition that the weights sum to unity, $\\sum_{j=1}^{5} w_j = 1$:\n$$ \\text{Var}(F_i) = \\sum_{j=1}^{5} w_j^2 (\\mu_j + \\sigma_r^2) + (1)^2 \\sigma_b^2 = \\sum_{j=1}^{5} w_j^2 (\\mu_j + \\sigma_r^2) + \\sigma_b^2 $$\nThis is the general expression for the variance of the extracted flux in electrons squared.\n\nThe flux $F_i$ is then continuum-normalized by dividing by the continuum estimate $C_i$. The normalized flux is $f_i = F_i / C_i$. The problem states that the uncertainty in $C_i$ is negligible, so $C_i$ can be treated as a constant. The variance of the normalized flux is therefore:\n$$ \\text{Var}(f_i) = \\text{Var}\\left(\\frac{F_i}{C_i}\\right) = \\frac{1}{C_i^2} \\text{Var}(F_i) $$\nCombining the expressions, we arrive at the final formula for the variance of the normalized flux:\n$$ \\text{Var}(f_i) = \\frac{1}{C_i^2} \\left[ \\sum_{j=1}^{5} w_j^2 (\\mu_j + \\sigma_r^2) + \\sigma_b^2 \\right] $$\n\nNow, we compute the numerical value using the provided data.\nGiven parameters:\n- $g = 1.7 \\, \\text{e}^-/\\text{ADU}$\n- $\\sigma_r = 3.5 \\, \\text{e}^-$\n- $d = 0.01 \\, \\text{e}^-/\\text{s}$\n- $t = 1200 \\, \\text{s}$\n- $\\sigma_b = 1.2 \\, \\text{e}^-$\n- $C_i = 1000 \\, \\text{e}^-$\n- Weights: $w_1=w_5=0.06$, $w_2=w_4=0.24$, $w_3=0.40$\n- Counts (ADU): $O_{i,j} \\in \\{120, 480, 800, 480, 120\\}$, $S_{i,j}=20$ for all $j$.\n\nFirst, calculate the constant variance terms:\n- Read noise variance: $\\sigma_r^2 = (3.5)^2 = 12.25 \\, \\text{e}^{-2}$\n- Bias uncertainty variance: $\\sigma_b^2 = (1.2)^2 = 1.44 \\, \\text{e}^{-2}$\n- Dark current contribution to mean signal: $d \\times t = 0.01 \\times 1200 = 12 \\, \\text{e}^-$\n\nNext, calculate the mean signal $\\mu_j$ for each spatial pixel:\n- For $j=1,5$: $O_{i,1} + S_{i,1} = 120 + 20 = 140 \\, \\text{ADU}$.\n  $\\mu_1 = \\mu_5 = g(140) + d \\times t = 1.7 \\times 140 + 12 = 238 + 12 = 250 \\, \\text{e}^-$\n- For $j=2,4$: $O_{i,2} + S_{i,2} = 480 + 20 = 500 \\, \\text{ADU}$.\n  $\\mu_2 = \\mu_4 = g(500) + d \\times t = 1.7 \\times 500 + 12 = 850 + 12 = 862 \\, \\text{e}^-$\n- For $j=3$: $O_{i,3} + S_{i,3} = 800 + 20 = 820 \\, \\text{ADU}$.\n  $\\mu_3 = g(820) + d \\times t = 1.7 \\times 820 + 12 = 1394 + 12 = 1406 \\, \\text{e}^-$\n\nNow, compute the sum $\\sum_{j=1}^{5} w_j^2 (\\mu_j + \\sigma_r^2)$. We can group terms by symmetry:\n- $w_1^2=w_5^2 = (0.06)^2 = 0.0036$\n- $w_2^2=w_4^2 = (0.24)^2 = 0.0576$\n- $w_3^2 = (0.40)^2 = 0.1600$\n\n- Term for $j=1,5$: $w_1^2(\\mu_1+\\sigma_r^2) = 0.0036 \\times (250 + 12.25) = 0.0036 \\times 262.25 = 0.9441$\n- Term for $j=2,4$: $w_2^2(\\mu_2+\\sigma_r^2) = 0.0576 \\times (862 + 12.25) = 0.0576 \\times 874.25 = 50.3568$\n- Term for $j=3$: $w_3^2(\\mu_3+\\sigma_r^2) = 0.1600 \\times (1406 + 12.25) = 0.1600 \\times 1418.25 = 226.92$\n\nThe full sum is:\n$$ \\sum_{j=1}^{5} w_j^2(\\mu_j + \\sigma_r^2) = 2 \\times (0.9441) + 2 \\times (50.3568) + 226.92 $$\n$$ = 1.8882 + 100.7136 + 226.92 = 329.5218 \\, \\text{e}^{-2} $$\n\nNow, calculate the total variance of the extracted flux, $\\text{Var}(F_i)$:\n$$ \\text{Var}(F_i) = 329.5218 + \\sigma_b^2 = 329.5218 + 1.44 = 330.9618 \\, \\text{e}^{-2} $$\n\nFinally, calculate the variance of the normalized flux, $\\text{Var}(f_i)$:\n$$ \\text{Var}(f_i) = \\frac{\\text{Var}(F_i)}{C_i^2} = \\frac{330.9618}{(1000)^2} = \\frac{330.9618}{1000000} = 0.0003309618 $$\nThis is a dimensionless quantity, as it is the variance of a normalized flux. Rounding to four significant figures gives $0.0003310$.\n\nIn scientific notation, this is $3.310 \\times 10^{-4}$.",
            "answer": "$$ \\boxed{3.310 \\times 10^{-4}} $$"
        },
        {
            "introduction": "Once the spectrum and its associated uncertainties are established, the next step is to perform the cross-correlation. While the cross-correlation function is the mathematical engine of this technique, its practical implementation for modern data hinges on computational efficiency. This exercise guides you through a crucial comparison of the direct time-domain method and the much faster frequency-domain method using the Fast Fourier Transform (FFT), revealing the dramatic difference in scalability that makes analyses of spectra with millions of samples feasible.",
            "id": "4163454",
            "problem": "A high-resolution spectrograph used for exoplanet atmosphere detection produces an observed, continuum-normalized, telluric-corrected spectrum sampled on a uniform wavelength grid as a real-valued sequence $\\{x[n]\\}_{n=0}^{N-1}$ with $N$ samples. To detect a faint planetary signal, a template spectrum $\\{t[n]\\}_{n=0}^{N-1}$ is cross-correlated with the observation across all integer lags corresponding to Doppler shifts. Consider computing the full linear cross-correlation $\\rho[k]$ for all output indices $k \\in \\{0,1,\\dots,2N-2\\}$, where the discrete cross-correlation is defined, for real sequences, by\n$$\n\\rho[k] = \\sum_{n=0}^{N-1} x[n]\\,t[n+k]\n$$\nwith $t[\\cdot]$ extended by zero-padding outside $[0,N-1]$, so that $\\rho[k]$ has length $2N-1$.\n\nTwo algorithmic strategies are considered:\n\n1. A direct time-domain computation that evaluates $\\rho[k]$ by forming each sum explicitly, counting one floating-point multiplication and one floating-point addition per term of the sum.\n\n2. A frequency-domain method using the Fast Fourier Transform (FFT), invoking the convolution theorem and computing $\\rho$ via zero-padding both inputs to length $L$, forming two forward FFTs, one pointwise complex multiplication $X(\\omega)\\,\\overline{T(\\omega)}$, and one inverse FFT. Assume $L$ is chosen as the smallest power of two satisfying $L \\ge 2N-1$. Adopt the following widely used operation models for a radix-$2$ complex FFT of length $L$: exactly $5L\\log_{2}L$ real floating-point operations (flops) per transform, and exactly $6L$ real flops for the pointwise complex multiplication over $L$ frequencies.\n\na) Starting from the discrete cross-correlation definition and zero-padding, derive the exact total floating-point operation count $F_{\\mathrm{dir}}(N)$ for the direct method as a function of $N$, and the total floating-point operation count $F_{\\mathrm{fft}}(N)$ for the FFT-based method as a function of $N$ via $L(N)=2^{\\lceil \\log_{2}(2N-1)\\rceil}$.\n\nb) State the asymptotic computational complexities for both methods, in terms of $N$.\n\nc) For an exoplanet cross-correlation run with $N=10^{6}$ samples, take $L$ as defined above. Suppose the direct method executes at a sustained rate of $r_{\\mathrm{dir}}=8.0\\times 10^{9}$ flops per second, and the FFT-based pipeline (including the transforms and the pointwise multiplication) executes at $r_{\\mathrm{fft}}=4.0\\times 10^{10}$ flops per second. Using your operation-count models from part (a), estimate the wall-clock runtime in seconds for each method.\n\nRound your two runtime estimates to three significant figures, and express the final pair of runtimes in seconds as a row matrix with the first entry being the direct method runtime and the second entry being the FFT-based method runtime.",
            "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in the principles of digital signal processing and its application to astrophysics, well-posed with clear definitions and sufficient data, and objective in its formulation. The problem constitutes a standard, non-trivial exercise in computational complexity analysis. We may therefore proceed with the solution.\n\na) Derivation of Floating-Point Operation Counts\n\nFirst, we determine the total floating-point operation (flop) count for the direct time-domain method, $F_{\\mathrm{dir}}(N)$. The cross-correlation is defined as $\\rho[k] = \\sum_{n=0}^{N-1} x[n]\\,t[n+k]$. To compute the full linear cross-correlation of two sequences of length $N$, the resulting sequence has length $2N-1$. The lags range from $-(N-1)$ to $N-1$. Let us assume the output index $k$ in the problem maps to this range. The number of non-zero terms in the sum for a given lag, which we can denote as $k'$, where $k' \\in \\{-(N-1), \\dots, N-1\\}$, is given by the size of the overlap between the two sequences. This number is $N - |k'|$.\n\nThe total number of terms across all sums is the sum of terms for each lag:\n$$\n\\text{Total Terms} = \\sum_{k'=-(N-1)}^{N-1} (N - |k'|)\n$$\nThis sum can be split:\n$$\n\\text{Total Terms} = (N - |0|) + \\sum_{k'=1}^{N-1} (N - k') + \\sum_{k'=- (N-1)}^{-1} (N - (-k'))\n$$\n$$\n= N + 2 \\sum_{k'=1}^{N-1} (N - k')\n$$\nLet $j = N - k'$. As $k'$ goes from $1$ to $N-1$, $j$ goes from $N-1$ down to $1$.\n$$\n\\text{Total Terms} = N + 2 \\sum_{j=1}^{N-1} j = N + 2 \\frac{(N-1)N}{2} = N + N^2 - N = N^2\n$$\nThe problem specifies that we count \"one floating-point multiplication and one floating-point addition per term of the sum\". This is interpreted as a cost of $2$ flops for each non-zero product $x[n]t[n+k]$ that is computed and accumulated. Therefore, the total flop count is twice the total number of terms.\n$$\nF_{\\mathrm{dir}}(N) = 2 \\times (\\text{Total Terms}) = 2N^2\n$$\nNext, we determine the flop count for the FFT-based method, $F_{\\mathrm{fft}}(N)$. This method involves the following steps:\n1.  Two forward Fast Fourier Transforms (FFTs) of length $L$ on the zero-padded input sequences.\n2.  One pointwise complex multiplication of the resulting spectra, $X(\\omega)\\overline{T(\\omega)}$.\n3.  One inverse FFT of length $L$ to transform the result back to the time domain.\n\nThe length $L$ is given as $L = 2^{\\lceil \\log_{2}(2N-1)\\rceil}$. The flop counts for the components are given:\n-   Cost of one complex FFT (forward or inverse): $5L\\log_{2}L$ flops.\n-   Cost of pointwise complex multiplication for $L$ points: $6L$ flops.\n\nThe total flop count is the sum of the costs of two forward FFTs, one inverse FFT, and the pointwise multiplication.\n$$\nF_{\\mathrm{fft}}(N) = (\\text{FFT of } x) + (\\text{FFT of } t) + (\\text{pointwise mult}) + (\\text{IFFT of product})\n$$\n$$\nF_{\\mathrm{fft}}(N) = (5L\\log_{2}L) + (5L\\log_{2}L) + 6L + (5L\\log_{2}L)\n$$\n$$\nF_{\\mathrm{fft}}(N) = 15L\\log_{2}L + 6L = L(15\\log_{2}L + 6)\n$$\nSubstituting the expression for $L = L(N)$:\n$$\nF_{\\mathrm{fft}}(N) = 2^{\\lceil \\log_{2}(2N-1)\\rceil} \\left( 15\\log_{2}\\left(2^{\\lceil \\log_{2}(2N-1)\\rceil}\\right) + 6 \\right)\n$$\nSince $\\log_{2}(2^p) = p$, this simplifies to:\n$$\nF_{\\mathrm{fft}}(N) = 2^{\\lceil \\log_{2}(2N-1)\\rceil} \\left( 15 \\lceil \\log_{2}(2N-1)\\rceil + 6 \\right)\n$$\n\nb) Asymptotic Computational Complexities\n\nFor the direct method, the flop count is $F_{\\mathrm{dir}}(N) = 2N^2$. As $N \\to \\infty$, the complexity is determined by the highest power of $N$. Thus, the asymptotic complexity is:\n$$\nO(N^2)\n$$\nFor the FFT-based method, we analyze the behavior of $L(N) = 2^{\\lceil \\log_{2}(2N-1)\\rceil}$ for large $N$. The ceiling function ensures that $\\log_{2}(2N-1) \\le \\lceil \\log_{2}(2N-1)\\rceil < \\log_{2}(2N-1) + 1$. This implies $2N-1 \\le L < 2(2N-1)$. Therefore, $L$ is of the order of $N$, i.e., $L \\in O(N)$. Correspondingly, $\\log_{2}L \\in O(\\log N)$.\nThe flop count is $F_{\\mathrm{fft}}(N) \\approx 15L\\log_{2}L$. The asymptotic complexity is therefore:\n$$\nO(N \\log N)\n$$\n\nc) Wall-Clock Runtime Estimation\n\nGiven $N = 10^6$, we calculate the specific flop counts and runtimes.\n\nFor the direct method:\nThe total number of floating-point operations is:\n$$\nF_{\\mathrm{dir}}(10^6) = 2 \\times (10^6)^2 = 2 \\times 10^{12} \\text{ flops}\n$$\nThe sustained execution rate is $r_{\\mathrm{dir}} = 8.0 \\times 10^9$ flops/s. The estimated runtime is:\n$$\nT_{\\mathrm{dir}} = \\frac{F_{\\mathrm{dir}}(10^6)}{r_{\\mathrm{dir}}} = \\frac{2 \\times 10^{12}}{8.0 \\times 10^9} \\, \\text{s} = 0.25 \\times 10^3 \\, \\text{s} = 250 \\, \\text{s}\n$$\nTo three significant figures, this is $250$ s.\n\nFor the FFT-based method:\nFirst, we determine the FFT length $L$. The required length is at least $2N-1 = 2 \\times 10^6 - 1 = 1,999,999$.\nWe need to find the smallest power of two, $L = 2^k$, such that $L \\ge 1,999,999$.\n$$\n\\log_{2}(1,999,999) = \\frac{\\ln(1,999,999)}{\\ln(2)} \\approx \\frac{14.50865}{0.69315} \\approx 20.93\n$$\nThe smallest integer exponent $k$ must be $\\lceil 20.93 \\rceil = 21$.\nSo, $L = 2^{21} = 2,097,152$.\nThe term $\\log_{2}L$ is exactly $21$.\n\nNow, we calculate the total number of floating-point operations:\n$$\nF_{\\mathrm{fft}}(10^6) = L(15\\log_{2}L + 6) = 2^{21} (15 \\times 21 + 6)\n$$\n$$\nF_{\\mathrm{fft}}(10^6) = 2,097,152 \\times (315 + 6) = 2,097,152 \\times 321 = 673,185,792 \\text{ flops}\n$$\nThe sustained execution rate is $r_{\\mathrm{fft}} = 4.0 \\times 10^{10}$ flops/s. The estimated runtime is:\n$$\nT_{\\mathrm{fft}} = \\frac{F_{\\mathrm{fft}}(10^6)}{r_{\\mathrm{fft}}} = \\frac{673,185,792}{4.0 \\times 10^{10}} \\, \\text{s} \\approx 0.0168296 \\, \\text{s}\n$$\nRounding to three significant figures, we get $0.0168$ s.\n\nThe pair of runtimes (direct method, FFT-based method) is $(250 \\, \\text{s}, 0.0168 \\, \\text{s})$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 250 & 0.0168 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "After efficiently computing the cross-correlation function, the final step is interpretation. Detecting an exoplanet's atmosphere relies on a template spectrum that accurately represents the planet's own signal, and physical mismatches—such as an incorrect temperature—can significantly weaken the result. This exercise explores this crucial systematic effect by having you model molecular line strengths as a function of temperature from fundamental physics, allowing you to quantify the degradation of the cross-correlation signal when the model template is imperfect.",
            "id": "4163447",
            "problem": "You are tasked with quantifying how a mismatch in template temperature affects the amplitude of a cross-correlation function (CCF) in high-resolution spectroscopy for exoplanet atmosphere detection. Assume an isothermal exoplanet atmosphere with temperature $T_{\\mathrm{p}}$, while the template spectrum used in cross-correlation is generated at a mismatched temperature $T_{\\mathrm{t}} = T_{\\mathrm{p}} + \\Delta T$. Consider a set of spectral transitions characterized by their wavenumbers and lower-state energies. Your goal is to compute the CCF amplitude as the normalized weighted inner product of line-strength vectors at $T_{\\mathrm{p}}$ and $T_{\\mathrm{t}}$, with line strengths computed from first principles.\n\nUse the following physically grounded base:\n\n- The population of absorbers in the lower state with energy $E_{\\ell}$ at temperature $T$ follows the Boltzmann distribution: $n_{\\ell}(T) \\propto g_{\\ell}\\,\\exp(-E_{\\ell}/(k_{\\mathrm{B}} T))$, where $g_{\\ell}$ is the level degeneracy and $k_{\\mathrm{B}}$ is the Boltzmann constant.\n- The transition absorption scaling is proportional to the population in the lower level multiplied by the line oscillator strength and corrected by stimulated emission through the factor $\\left(1 - \\exp(-h \\nu/(k_{\\mathrm{B}} T))\\right)$, where $h$ is Planck’s constant and $\\nu$ is the transition frequency.\n- The total internal partition function $Q(T)$ normalizes the level populations. For a single species over the temperature range considered, approximate it as $Q(T) = \\alpha\\,T^{\\beta}$, with given constants $\\alpha$ and $\\beta$.\n- To avoid carrying explicit conversion factors, use the second radiation constant $c_{2} = h c / k_{\\mathrm{B}}$, with $c_{2} = 1.438776877\\,\\mathrm{K\\,cm}$, and describe energies and transition positions using wavenumbers (in $\\mathrm{cm}^{-1}$). If a quantity $\\tilde{x}$ is given in $\\mathrm{cm}^{-1}$, then $x/(k_{\\mathrm{B}} T) = c_{2}\\,\\tilde{x}/T$.\n\nDefine the line strength for transition $i$ at temperature $T$ up to an overall multiplicative constant (which cancels in the final normalization) as\n$$\nS_{i}(T) \\propto (g f)_{i}\\,\\exp\\!\\left(-\\frac{c_{2}\\,\\tilde{E}_{\\ell,i}}{T}\\right)\\,\\left(1 - \\exp\\!\\left(-\\frac{c_{2}\\,\\tilde{\\nu}_{i}}{T}\\right)\\right)\\,\\frac{1}{Q(T)},\n$$\nwhere $(g f)_{i}$ is the product of degeneracy and oscillator strength for line $i$, $\\tilde{E}_{\\ell,i}$ is the lower-state energy in $\\mathrm{cm}^{-1}$, and $\\tilde{\\nu}_{i}$ is the line wavenumber in $\\mathrm{cm}^{-1}$. Take $Q(T) = \\alpha\\,T^{\\beta}$ with given $\\alpha$ and $\\beta$.\n\nDefine the CCF amplitude for a given set of lines and weights as the normalized weighted inner product:\n$$\n\\mathrm{CCF}(T_{\\mathrm{p}}, T_{\\mathrm{t}}) = \\frac{\\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{p}})\\,S_{i}(T_{\\mathrm{t}})}{\\sqrt{\\left(\\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{p}})^{2}\\right)\\left(\\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{t}})^{2}\\right)}}.\n$$\nThis is dimensionless and lies in the interval $\\left[0,1\\right]$. The numerator and denominator are to be computed using the same $w_{i}$, and any common multiplicative constant in $S_{i}(T)$ cancels out.\n\nUse the following fixed set of five transitions, each defined by $(\\tilde{\\nu}_{i}, \\tilde{E}_{\\ell,i}, (g f)_{i})$:\n- Line $1$: $(\\tilde{\\nu}_{1}, \\tilde{E}_{\\ell,1}, (g f)_{1}) = (3000, 0, 1.0)$\n- Line $2$: $(\\tilde{\\nu}_{2}, \\tilde{E}_{\\ell,2}, (g f)_{2}) = (3100, 500, 0.8)$\n- Line $3$: $(\\tilde{\\nu}_{3}, \\tilde{E}_{\\ell,3}, (g f)_{3}) = (3200, 1000, 0.6)$\n- Line $4$: $(\\tilde{\\nu}_{4}, \\tilde{E}_{\\ell,4}, (g f)_{4}) = (5000, 2000, 0.4)$\n- Line $5$: $(\\tilde{\\nu}_{5}, \\tilde{E}_{\\ell,5}, (g f)_{5}) = (10000, 4000, 0.2)$\n\nAll wavenumbers and energies here are in $\\mathrm{cm}^{-1}$, and $(g f)$ is dimensionless. Use $c_{2} = 1.438776877\\,\\mathrm{K\\,cm}$ exactly as written.\n\nImplement $Q(T) = \\alpha\\,T^{\\beta}$ with specified $(\\alpha,\\beta)$ in each test case. Temperatures must be in $\\mathrm{K}$. The final CCF amplitude is unitless.\n\nTest suite. Compute the CCF amplitude for the following four parameter sets:\n- Case A (happy path): $T_{\\mathrm{p}} = 1800\\,\\mathrm{K}$, $\\Delta T = 0\\,\\mathrm{K}$, $\\alpha = 1.0$, $\\beta = 1.5$, weights $w = [1.0, 1.0, 1.0, 1.0, 1.0]$.\n- Case B (moderate mismatch, cooler template): $T_{\\mathrm{p}} = 1800\\,\\mathrm{K}$, $\\Delta T = -400\\,\\mathrm{K}$, $\\alpha = 1.0$, $\\beta = 1.5$, weights $w = [1.0, 1.0, 1.0, 1.0, 1.0]$.\n- Case C (moderate mismatch, hotter template): $T_{\\mathrm{p}} = 1000\\,\\mathrm{K}$, $\\Delta T = 800\\,\\mathrm{K}$, $\\alpha = 1.0$, $\\beta = 1.5$, weights $w = [1.0, 1.0, 1.0, 1.0, 1.0]$.\n- Case D (boundary with strong mismatch and nonuniform weights): $T_{\\mathrm{p}} = 500\\,\\mathrm{K}$, $\\Delta T = 1500\\,\\mathrm{K}$, $\\alpha = 1.0$, $\\beta = 1.5$, weights $w = [1.0, 1.0, 1.0, 0.5, 0.2]$.\n\nAngle units are not involved. No other physical units appear in the output. All input numbers above must be used as given.\n\nYour program must:\n- Implement the above physics to compute $S_{i}(T)$ for each line and the normalized $\\mathrm{CCF}(T_{\\mathrm{p}}, T_{\\mathrm{t}})$ for each case.\n- Ensure $T_{\\mathrm{t}} = T_{\\mathrm{p}} + \\Delta T$ is strictly positive in all cases; the provided test cases satisfy this requirement.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each CCF amplitude rounded to six decimal places, in the order [Case A, Case B, Case C, Case D]. For example, the output format must be like $[0.123456,0.234567,0.345678,0.456789]$.\n\nThe final output is dimensionless and requires no unit label.",
            "solution": "The problem requires the computation of the cross-correlation function (CCF) amplitude, which quantifies the signal degradation when a spectroscopic template at temperature $T_{\\mathrm{t}}$ is used to search for a signal from an exoplanet atmosphere at temperature $T_{\\mathrm{p}}$. The problem is well-posed, scientifically grounded in the principles of statistical mechanics and radiative transfer, and provides all necessary data and constants for a unique solution.\n\nThe core of the problem lies in calculating the temperature-dependent line strength, $S_{i}(T)$, for a set of spectral transitions, and then using these strengths to compute the CCF amplitude via a normalized weighted inner product.\n\nFirst, let us formalize the calculation of the line strength $S_{i}(T)$ for a transition $i$ at a given absolute temperature $T$. The problem provides the following model, derived from fundamental principles:\n$$\nS_{i}(T) \\propto (g f)_{i}\\,\\exp\\!\\left(-\\frac{c_{2}\\,\\tilde{E}_{\\ell,i}}{T}\\right)\\,\\left(1 - \\exp\\!\\left(-\\frac{c_{2}\\,\\tilde{\\nu}_{i}}{T}\\right)\\right)\\,\\frac{1}{Q(T)}\n$$\nHere, $(g f)_{i}$ is the product of the statistical weight of the lower energy level and the oscillator strength of the transition, $\\tilde{E}_{\\ell,i}$ is the lower-state energy in wavenumbers ($\\mathrm{cm}^{-1}$), $\\tilde{\\nu}_{i}$ is the transition wavenumber ($\\mathrm{cm}^{-1}$), and $c_{2} = h c / k_{\\mathrm{B}}$ is the second radiation constant, given as $1.438776877\\,\\mathrm{K\\,cm}$. The term $\\exp(-c_{2}\\,\\tilde{E}_{\\ell,i}/T)$ is the Boltzmann factor, describing the population of the lower energy state. The term $(1 - \\exp(-c_{2}\\,\\tilde{\\nu}_{i}/T))$ is a correction for stimulated emission. The entire expression is normalized by the total internal partition function, $Q(T)$, which for this problem is approximated by the power law $Q(T) = \\alpha\\,T^{\\beta}$. Since any overall multiplicative constants cancel in the final CCF calculation, we can define the line strength for our purposes as:\n$$\nS_{i}(T) = (g f)_{i}\\,\\frac{\\exp\\left(-\\frac{c_{2}\\,\\tilde{E}_{\\ell,i}}{T}\\right)\\left(1 - \\exp\\left(-\\frac{c_{2}\\,\\tilde{\\nu}_{i}}{T}\\right)\\right)}{\\alpha\\,T^{\\beta}}\n$$\n\nNext, the CCF amplitude is defined as the normalized weighted inner product of the line-strength vectors corresponding to the planet's temperature $T_{\\mathrm{p}}$ and the template's temperature $T_{\\mathrm{t}}$. Let $\\mathbf{S}(T_{\\mathrm{p}})$ be the vector of line strengths $[S_{1}(T_{\\mathrm{p}}), S_{2}(T_{\\mathrm{p}}), \\dots, S_{N}(T_{\\mathrm{p}})]$ and $\\mathbf{S}(T_{\\mathrm{t}})$ be the vector $[S_{1}(T_{\\mathrm{t}}), S_{2}(T_{\\mathrm{t}}), \\dots, S_{N}(T_{\\mathrm{t}})]$. The CCF amplitude is given by:\n$$\n\\mathrm{CCF}(T_{\\mathrm{p}}, T_{\\mathrm{t}}) = \\frac{\\sum_{i=1}^{N} w_{i}\\,S_{i}(T_{\\mathrm{p}})\\,S_{i}(T_{\\mathrm{t}})}{\\sqrt{\\left(\\sum_{i=1}^{N} w_{i}\\,S_{i}(T_{\\mathrm{p}})^{2}\\right)\\left(\\sum_{i=1}^{N} w_{i}\\,S_{i}(T_{\\mathrm{t}})^{2}\\right)}}\n$$\nwhere $w_{i}$ are the weights for each line $i$. This expression is equivalent to the cosine of the angle between the two vectors in a vector space endowed with a weighted inner product, or a weighted Pearson correlation coefficient. Its value ranges from $0$ (no correlation) to $1$ (perfect correlation).\n\nThe computational procedure for each test case is as follows:\n1.  Identify the parameters for the case: planet temperature $T_{\\mathrm{p}}$, temperature mismatch $\\Delta T$, partition function parameters $\\alpha$ and $\\beta$, and the vector of weights $\\mathbf{w}$. The fixed physical data for the five spectral lines $(\\tilde{\\nu}_{i}, \\tilde{E}_{\\ell,i}, (g f)_{i})$ and the constant $c_{2}$ are used for all cases.\n2.  Calculate the template temperature $T_{\\mathrm{t}} = T_{\\mathrm{p}} + \\Delta T$.\n3.  For each of the five spectral lines, calculate the line strength at the planet temperature, $S_{i}(T_{\\mathrm{p}})$, and at the template temperature, $S_{i}(T_{\\mathrm{t}})$. This results in two vectors of line strengths, $\\mathbf{S}(T_{\\mathrm{p}})$ and $\\mathbf{S}(T_{\\mathrm{t}})$.\n4.  Using these vectors and the weights $\\mathbf{w}$, compute the three sums required for the CCF formula:\n    -   The weighted cross-term sum: $\\Sigma_{\\mathrm{pt}} = \\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{p}})\\,S_{i}(T_{\\mathrm{t}})$\n    -   The weighted sum of squares for $T_{\\mathrm{p}}$: $\\Sigma_{\\mathrm{pp}} = \\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{p}})^{2}$\n    -   The weighted sum of squares for $T_{\\mathrm{t}}$: $\\Sigma_{\\mathrm{tt}} = \\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{t}})^{2}$\n5.  Calculate the final CCF amplitude as $\\mathrm{CCF} = \\Sigma_{\\mathrm{pt}} / \\sqrt{\\Sigma_{\\mathrm{pp}} \\cdot \\Sigma_{\\mathrm{tt}}}$.\n6.  The result for each case is rounded to six decimal places.\n\nFor Case A, we have $T_{\\mathrm{p}} = 1800\\,\\mathrm{K}$ and $\\Delta T = 0\\,\\mathrm{K}$, which implies $T_{\\mathrm{t}} = T_{\\mathrm{p}}$. In this situation, $S_{i}(T_{\\mathrm{p}}) = S_{i}(T_{\\mathrm{t}})$ for all lines $i$. The CCF formula simplifies to:\n$$\n\\mathrm{CCF}(T_{\\mathrm{p}}, T_{\\mathrm{p}}) = \\frac{\\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{p}})^{2}}{\\sqrt{\\left(\\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{p}})^{2}\\right)\\left(\\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{p}})^{2}\\right)}} = \\frac{\\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{p}})^{2}}{\\sum_{i} w_{i}\\,S_{i}(T_{\\mathrm{p}})^{2}} = 1\n$$\nThis provides a useful validation point. For any non-zero temperature mismatch ($\\Delta T \\neq 0$), the ratio of line strengths will change, leading to a CCF amplitude less than $1$. The greater the mismatch, the lower the expected amplitude, reflecting the degradation of the correlation signal.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the CCF amplitude for given sets of physical parameters.\n    \"\"\"\n    \n    # Define constants and fixed line data\n    c2 = 1.438776877  # K cm\n    \n    # Line data: (wavenumber [cm^-1], lower-state energy [cm^-1], gf-value)\n    line_data = np.array([\n        [3000.0, 0.0, 1.0],      # Line 1\n        [3100.0, 500.0, 0.8],    # Line 2\n        [3200.0, 1000.0, 0.6],   # Line 3\n        [5000.0, 2000.0, 0.4],   # Line 4\n        [10000.0, 4000.0, 0.2]    # Line 5\n    ])\n\n    # Test cases: (Tp [K], delta_T [K], alpha, beta, weights)\n    test_cases = [\n        (1800.0, 0.0, 1.0, 1.5, np.array([1.0, 1.0, 1.0, 1.0, 1.0])),  # Case A\n        (1800.0, -400.0, 1.0, 1.5, np.array([1.0, 1.0, 1.0, 1.0, 1.0])), # Case B\n        (1000.0, 800.0, 1.0, 1.5, np.array([1.0, 1.0, 1.0, 1.0, 1.0])),  # Case C\n        (500.0, 1500.0, 1.0, 1.5, np.array([1.0, 1.0, 1.0, 0.5, 0.2]))  # Case D\n    ]\n\n    def calculate_line_strengths(T, alpha, beta):\n        \"\"\"\n        Calculates line strengths for all lines at a given temperature T.\n        \n        S_i(T) propto (gf)_i * exp(-c2*E_i/T) * (1 - exp(-c2*nu_i/T)) / Q(T)\n        where Q(T) = alpha * T^beta\n        \"\"\"\n        nu = line_data[:, 0]\n        E_lower = line_data[:, 1]\n        gf = line_data[:, 2]\n        \n        if T <= 0:\n            return np.zeros_like(nu)\n\n        Q_T = alpha * (T ** beta)\n        \n        boltzmann_factor = np.exp(-c2 * E_lower / T)\n        stim_emission_factor = 1.0 - np.exp(-c2 * nu / T)\n        \n        strengths = gf * boltzmann_factor * stim_emission_factor / Q_T\n        return strengths\n\n    results = []\n    for case in test_cases:\n        Tp, delta_T, alpha, beta, weights = case\n        Tt = Tp + delta_T\n\n        # Calculate line strength vectors for planet and template\n        S_p = calculate_line_strengths(Tp, alpha, beta)\n        S_t = calculate_line_strengths(Tt, alpha, beta)\n        \n        # Compute the weighted inner product terms for the CCF formula\n        # Numerator: sum(w_i * S_p_i * S_t_i)\n        numerator = np.sum(weights * S_p * S_t)\n        \n        # Denominator: sqrt(sum(w_i * S_p_i^2) * sum(w_i * S_t_i^2))\n        sum_sq_p = np.sum(weights * S_p**2)\n        sum_sq_t = np.sum(weights * S_t**2)\n        \n        denominator = np.sqrt(sum_sq_p * sum_sq_t)\n\n        # Handle potential division by zero, though not expected for these cases\n        if denominator == 0:\n            ccf_amplitude = 0.0\n        else:\n            ccf_amplitude = numerator / denominator\n        \n        results.append(ccf_amplitude)\n\n    # Format the results as specified\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}