{
    "hands_on_practices": [
        {
            "introduction": "The essence of statistical inference is extracting information from data, and this includes null results. In exoplanet science, where detections can be rare, knowing how to properly interpret a non-detection is as important as analyzing a confirmed planet. This exercise  guides you through a Bayesian approach to set a statistically rigorous upper limit on a planet occurrence rate $f$ given a null survey result, demonstrating the fundamental link between completeness, sample size, and demographic constraints.",
            "id": "4160194",
            "problem": "A transit survey of $N=500$ Sun-like stars reports no validated planet detections in the bin defined by planetary radius $R_{\\mathrm{p}} \\in [1.0,1.5]\\,R_{\\oplus}$ and orbital period $P \\in [30,70]\\,\\mathrm{days}$. For each target star $i$, the survey team computes an integrated detection completeness $C_{i}$ for this bin via injection-recovery experiments, where $C_{i}$ is the probability that a randomly drawn planet from this bin would be detected and validated around star $i$ if such a planet existed, marginalizing over the bin’s period–radius distribution. The team reports the aggregate completeness sum $S=\\sum_{i=1}^{N} C_{i}=100$.\n\nAssume the underlying population of planets in this bin follows a Poisson point process across stars, and that the detection pipeline independently thins this process with per-target detection probabilities $C_{i}$ (Poisson thinning). Let $f$ denote the occurrence rate, defined as the mean number of planets per star in this bin (so $f$ can exceed $1$). Adopting a uniform prior on $f$ for $f \\ge 0$, use the properties of the Poisson process and independence across targets to derive the posterior distribution for $f$ given the nondetection outcome, and from it compute the equal-tailed upper $95\\%$ credible limit on $f$. Express your final answer as a decimal fraction and round your result to four significant figures.",
            "solution": "The problem asks for the $95\\%$ upper credible limit on the exoplanet occurrence rate $f$, given a null detection result from a transit survey. We will use Bayesian inference to solve this problem.\n\nFirst, we establish the statistical model for the number of observed planets. Let $f$ be the mean number of planets per star in the specified bin of planetary radius and orbital period. The problem states that the underlying population of planets follows a Poisson point process. Therefore, for a single star $i$, the number of planets $n_i$ in the bin is a random variable drawn from a Poisson distribution with mean $f$:\n$$ n_i \\sim \\mathrm{Poisson}(f) $$\nThe detection of a given planet is probabilistic. The integrated detection completeness $C_i$ for star $i$ represents the probability that a planet, if present, would be detected. The number of detected planets $k_i$ around star $i$, given that there are $n_i$ planets, follows a binomial distribution:\n$$ k_i | n_i \\sim \\mathrm{Binomial}(n_i, C_i) $$\nThis scenario, where a Poisson-distributed quantity is subject to a binomial selection process (thinning), results in a new Poisson-distributed quantity. The marginal distribution of the number of detected planets $k_i$ around star $i$ is a Poisson distribution with mean $f C_i$:\n$$ k_i \\sim \\mathrm{Poisson}(f C_i) $$\nThe total number of detected planets across the entire survey of $N$ stars, $K$, is the sum of the independent random variables $k_i$:\n$$ K = \\sum_{i=1}^{N} k_i $$\nThe sum of independent Poisson random variables is also a Poisson random variable, with a mean equal to the sum of the individual means. Therefore, the distribution of $K$ is:\n$$ K \\sim \\mathrm{Poisson}\\left(\\sum_{i=1}^{N} f C_i\\right) $$\nWe can factor out the constant occurrence rate $f$:\n$$ K \\sim \\mathrm{Poisson}\\left(f \\sum_{i=1}^{N} C_i\\right) $$\nLet $S = \\sum_{i=1}^{N} C_i$ be the aggregate completeness sum. The problem provides $S=100$. The model for the total number of detections is then:\n$$ K \\sim \\mathrm{Poisson}(fS) $$\nThe data provided is that there were no validated planet detections, so our observation is $K=0$.\n\nWe apply Bayes' theorem to find the posterior probability distribution of $f$, given the data $K=0$ and the model parameter $S$. The posterior $p(f | K, S)$ is proportional to the likelihood $\\mathcal{L}(K | f, S)$ multiplied by the prior $p(f)$:\n$$ p(f | K=0, S) \\propto \\mathcal{L}(K=0 | f, S) \\cdot p(f) $$\nThe likelihood function is the probability of observing $K=0$ from a Poisson distribution with mean $\\lambda = fS$:\n$$ \\mathcal{L}(K=0 | f, S) = P(K=0 | \\lambda=fS) = \\frac{(fS)^0 \\exp(-fS)}{0!} = \\exp(-fS) $$\nThe problem specifies a uniform prior on $f$ for $f \\ge 0$, which can be written as:\n$$ p(f) \\propto 1, \\quad \\text{for } f \\ge 0 $$\nCombining the likelihood and the prior, we obtain the unnormalized posterior distribution for $f$:\n$$ p(f | K=0, S) \\propto \\exp(-fS), \\quad \\text{for } f \\ge 0 $$\nThis is the functional form of an exponential distribution. To find the normalization constant, we require the integral of the probability density function (PDF) over its domain to be $1$:\n$$ \\int_{0}^{\\infty} A \\exp(-fS) \\, df = 1 $$\nwhere $A$ is the normalization constant.\n$$ A \\left[ -\\frac{1}{S} \\exp(-fS) \\right]_{0}^{\\infty} = A \\left( 0 - \\left(-\\frac{\\exp(0)}{S}\\right) \\right) = \\frac{A}{S} = 1 $$\nThis implies $A=S$. The normalized posterior PDF is therefore:\n$$ p(f | K=0, S) = S \\exp(-fS), \\quad \\text{for } f \\ge 0 $$\nThis is the PDF of an exponential distribution with rate parameter $S$.\n\nThe upper $95\\%$ credible limit for $f$, denoted $f_{95}$, is the value such that the cumulative probability up to that point is $0.95$. This is found by integrating the posterior PDF from $0$ to $f_{95}$:\n$$ P(f \\le f_{95} | K=0, S) = \\int_{0}^{f_{95}} S \\exp(-f'S) \\, df' = 0.95 $$\nThe integral corresponds to the cumulative distribution function (CDF) of the exponential distribution:\n$$ \\left[ -\\exp(-f'S) \\right]_{0}^{f_{95}} = 1 - \\exp(-f_{95}S) $$\nSetting this equal to $0.95$:\n$$ 1 - \\exp(-f_{95}S) = 0.95 $$\nSolving for $f_{95}$:\n$$ \\exp(-f_{95}S) = 1 - 0.95 = 0.05 $$\n$$ -f_{95}S = \\ln(0.05) $$\n$$ f_{95} = -\\frac{\\ln(0.05)}{S} $$\nThe problem provides the value $S=100$. Substituting this value into the expression for $f_{95}$:\n$$ f_{95} = -\\frac{\\ln(0.05)}{100} $$\nWe can compute the numerical value:\n$$ \\ln(0.05) \\approx -2.99573227 $$\n$$ f_{95} \\approx -\\frac{-2.99573227}{100} \\approx 0.0299573227 $$\nThe problem requires the final answer to be rounded to four significant figures. The first four significant figures of $0.0299573227$ are $2, 9, 9, 5$. The subsequent digit is $7$, which means we must round up the last significant digit:\n$$ f_{95} \\approx 0.02996 $$",
            "answer": "$$\\boxed{0.02996}$$"
        },
        {
            "introduction": "While single-bin occurrence rates are useful, a deeper understanding of planet formation requires modeling demographics as continuous functions of parameters like radius $R$ and period $P$. Researchers often fit power-law models in logarithmic space for statistical convenience, but may wish to interpret them in linear space. This exercise  addresses the crucial mathematical procedure for transforming an occurrence rate density and its parameters between linear and logarithmic coordinate systems, a key skill for correctly interpreting and comparing results from different studies.",
            "id": "4160221",
            "problem": "Consider a population-level occurrence rate density of exoplanets around Sun-like stars described in terms of planetary radius $R$ and orbital period $P$. Let the occurrence be modeled per linear bins by a separable power law\n$$\\frac{d^{2}N}{dR\\,dP} = \\lambda \\left(\\frac{R}{R_{0}}\\right)^{\\alpha} \\left(\\frac{P}{P_{0}}\\right)^{\\beta},$$\nwhere $N$ is the expected number of planets per star within a range of $R$ and $P$, $\\lambda$ is a normalization constant with units of planets per star per unit radius per unit period, and $(\\alpha,\\beta)$ are dimensionless slopes referenced to pivots $R_{0}$ and $P_{0}$. Observational catalogs often bin in the logarithms of these variables. Define the logarithmic-bin occurrence density by\n$$\\frac{d^{2}N}{d\\ln R\\,d\\ln P}.$$\nStarting only from the definition of differentials under changes of variables and the conservation of expected counts $d^{2}N$ under reparameterization, derive the mapping between the two densities and obtain the corresponding transformation for the parameter triplet $(\\lambda,\\alpha,\\beta)$ to $(\\tilde{\\lambda},\\tilde{\\alpha},\\tilde{\\beta})$ in the logarithmic-bin parameterization\n$$\\frac{d^{2}N}{d\\ln R\\,d\\ln P} = \\tilde{\\lambda} \\left(\\frac{R}{R_{0}}\\right)^{\\tilde{\\alpha}} \\left(\\frac{P}{P_{0}}\\right)^{\\tilde{\\beta}}.$$\nAssume a Maximum A Posteriori (MAP) fit to binned counts in $\\ln R$ and $\\ln P$ was mistakenly reported using the linear-bin parameterization with the following parameter values: $R_{0} = 2\\,R_{\\oplus}$, $P_{0} = 10\\,\\mathrm{days}$, $\\lambda = 4.00 \\times 10^{-4}$ planets per star per $R_{\\oplus}$ per day, $\\alpha = -1.30$, and $\\beta = 0.70$. Using your derived mapping, compute the corrected $(\\tilde{\\lambda},\\tilde{\\alpha},\\tilde{\\beta})$ that are consistent with logarithmic bins. Express $\\tilde{\\lambda}$ in planets per star. Round your value of $\\tilde{\\lambda}$ to four significant figures. The final answer must be provided as a single row matrix in the form $\\left(\\tilde{\\lambda},\\,\\tilde{\\alpha},\\,\\tilde{\\beta}\\right)$.",
            "solution": "The problem requires the derivation of a transformation between two different parameterizations of an exoplanet occurrence rate density, followed by a numerical calculation using this transformation.\n\nThe core principle for relating the two density functions is the conservation of the number of planets, $d^{2}N$, within an infinitesimal area of the parameter space, regardless of the coordinate system used. This means the number of planets in the element $dR\\,dP$ must be the same as the number of planets in the corresponding element $d\\ln R\\,d\\ln P$.\nMathematically, this invariance is expressed as:\n$$d^{2}N = \\frac{d^{2}N}{dR\\,dP} dR\\,dP = \\frac{d^{2}N}{d\\ln R\\,d\\ln P} d\\ln R\\,d\\ln P$$\nTo find the relationship between the two densities, we must relate the differential area elements $dR\\,dP$ and $d\\ln R\\,d\\ln P$.\nLet us define the logarithmic variables $u = \\ln R$ and $v = \\ln P$. The differentials are:\n$$du = d(\\ln R) = \\frac{1}{R} dR \\implies dR = R\\,du = R\\,d\\ln R$$\n$$dv = d(\\ln P) = \\frac{1}{P} dP \\implies dP = P\\,dv = P\\,d\\ln P$$\nThe differential area element in linear coordinates can thus be expressed in terms of the logarithmic coordinates:\n$$dR\\,dP = (R\\,d\\ln R)(P\\,d\\ln P) = RP\\,d\\ln R\\,d\\ln P$$\nThe term $RP$ is the Jacobian determinant of the transformation from $(\\ln R, \\ln P)$ to $(R, P)$.\nNow, we substitute this back into the invariance equation:\n$$\\frac{d^{2}N}{dR\\,dP} (RP\\,d\\ln R\\,d\\ln P) = \\frac{d^{2}N}{d\\ln R\\,d\\ln P} (d\\ln R\\,d\\ln P)$$\nDividing by the non-zero differential element $d\\ln R\\,d\\ln P$, we obtain the transformation rule for the densities:\n$$\\frac{d^{2}N}{d\\ln R\\,d\\ln P} = \\left(\\frac{d^{2}N}{dR\\,dP}\\right) R P$$\nNow we substitute the given power-law forms for each density into this equation.\nThe left side is:\n$$\\tilde{\\lambda} \\left(\\frac{R}{R_{0}}\\right)^{\\tilde{\\alpha}} \\left(\\frac{P}{P_{0}}\\right)^{\\tilde{\\beta}}$$\nThe right side is:\n$$\\left( \\lambda \\left(\\frac{R}{R_{0}}\\right)^{\\alpha} \\left(\\frac{P}{P_{0}}\\right)^{\\beta} \\right) R P$$\nTo compare these two forms, we must express the factors of $R$ and $P$ on the right side in terms of the pivot values $R_{0}$ and $P_{0}$:\n$$R = R_{0} \\left(\\frac{R}{R_{0}}\\right)^{1}$$\n$$P = P_{0} \\left(\\frac{P}{P_{0}}\\right)^{1}$$\nSubstituting these into the right side expression gives:\n$$RHS = \\lambda \\left(\\frac{R}{R_{0}}\\right)^{\\alpha} \\left(\\frac{P}{P_{0}}\\right)^{\\beta} \\left(R_{0} \\left(\\frac{R}{R_{0}}\\right)^{1}\\right) \\left(P_{0} \\left(\\frac{P}{P_{0}}\\right)^{1}\\right)$$\nWe can group the constants and the power-law terms:\n$$RHS = (\\lambda R_{0} P_{0}) \\left(\\frac{R}{R_{0}}\\right)^{\\alpha} \\left(\\frac{R}{R_{0}}\\right)^{1} \\left(\\frac{P}{P_{0}}\\right)^{\\beta} \\left(\\frac{P}{P_{0}}\\right)^{1}$$\n$$RHS = (\\lambda R_{0} P_{0}) \\left(\\frac{R}{R_{0}}\\right)^{\\alpha+1} \\left(\\frac{P}{P_{0}}\\right)^{\\beta+1}$$\nBy equating the transformed right-hand side with the left-hand side,\n$$\\tilde{\\lambda} \\left(\\frac{R}{R_{0}}\\right)^{\\tilde{\\alpha}} \\left(\\frac{P}{P_{0}}\\right)^{\\tilde{\\beta}} = (\\lambda R_{0} P_{0}) \\left(\\frac{R}{R_{0}}\\right)^{\\alpha+1} \\left(\\frac{P}{P_{0}}\\right)^{\\beta+1}$$\nwe can identify the transformation for the parameters by comparing the coefficients and exponents of the corresponding terms. This yields the mapping:\n$$\\tilde{\\lambda} = \\lambda R_{0} P_{0}$$\n$$\\tilde{\\alpha} = \\alpha + 1$$\n$$\\tilde{\\beta} = \\beta + 1$$\nThis completes the derivation of the transformation.\n\nNext, we compute the corrected numerical values for $(\\tilde{\\lambda}, \\tilde{\\alpha}, \\tilde{\\beta})$ using the provided parameters from the mistaken fit:\n$R_{0} = 2\\,R_{\\oplus}$\n$P_{0} = 10\\,\\mathrm{days}$\n$\\lambda = 4.00 \\times 10^{-4}$ planets per star per $R_{\\oplus}$ per day\n$\\alpha = -1.30$\n$\\beta = 0.70$\n\nWe calculate the new slopes $\\tilde{\\alpha}$ and $\\tilde{\\beta}$:\n$$\\tilde{\\alpha} = \\alpha + 1 = -1.30 + 1.00 = -0.30$$\n$$\\tilde{\\beta} = \\beta + 1 = 0.70 + 1.00 = 1.70$$\n\nNext, we calculate the new normalization constant $\\tilde{\\lambda}$. We must be careful with units.\n$$\\tilde{\\lambda} = \\lambda R_{0} P_{0} = (4.00 \\times 10^{-4} \\text{ star}^{-1} R_{\\oplus}^{-1} \\text{day}^{-1}) \\times (2 \\, R_{\\oplus}) \\times (10 \\, \\text{days})$$\n$$\\tilde{\\lambda} = (4.00 \\times 10^{-4}) \\times 2 \\times 10 \\text{ star}^{-1}$$\n$$\\tilde{\\lambda} = 8.00 \\times 10^{-3} \\text{ planets per star}$$\nThe problem asks to round the value of $\\tilde{\\lambda}$ to four significant figures.\n$$\\tilde{\\lambda} = 0.008000$$\nOr in scientific notation, $8.000 \\times 10^{-3}$.\n\nThe corrected parameter triplet $(\\tilde{\\lambda}, \\tilde{\\alpha}, \\tilde{\\beta})$ consistent with logarithmic bins is $(8.000 \\times 10^{-3}, -0.30, 1.70)$. The units of $\\tilde{\\lambda}$ are planets per star, as expected for a normalization constant of a density function over dimensionless logarithmic variables.\n\nThe final answer is formatted as a row matrix.",
            "answer": "$$\\boxed{\\begin{pmatrix} 8.000 \\times 10^{-3} & -0.30 & 1.70 \\end{pmatrix}}$$"
        },
        {
            "introduction": "The foundation of robust occurrence rate calculation is correcting for observational biases, encapsulated in the detection completeness $C_i$ for each star. Given a statistical model for planet detections, several methods can be used to estimate the underlying occurrence rate $f$, but not all are created equal. Through a hands-on Monte Carlo simulation , this practice compares the performance of different estimators, providing a clear, quantitative demonstration of why methods like Maximum Likelihood Estimation are essential for obtaining unbiased and efficient results from heterogeneous survey data.",
            "id": "4160273",
            "problem": "A survey of $N$ target stars seeks to measure the mean number of planets per star within a specified period-radius bin, denoted by $f$. For each star $i \\in \\{1,\\dots,N\\}$, the number of planets in the bin, $K_i$, is modeled as an independent realization of a Poisson random variable with mean $f$. The exoplanet detection pipeline has star-dependent detection completeness for this bin, denoted by $C_i \\in [0,1]$, which represents the probability that any individual planet in the bin orbiting star $i$ would be detected. Conditioned on $K_i$, each planet is detected independently with probability $C_i$. Across the survey, let $D_i$ be the number of detected planets on star $i$, and let $D=\\sum_{i=1}^{N} D_i$ be the total number of detected planets.\n\nYour task is to compare, via simulation, three estimators of $f$ under the above data-generating process. Use the following principle-based estimators:\n- A detection-fraction-based estimator that uses only the total number of detected planets and the number of stars.\n- A likelihood-based estimator derived under the assumption of Poisson thinning and known $C_i$.\n- A detection-efficiency-weighted estimator that inversely weights detections by their corresponding $C_i$ values.\n\nStarting from the fundamental base described above (Poisson-distributed planets per star and independent thinning by detection completeness), derive each estimator, then implement a simulation to quantify its bias and mean squared error for given survey configurations. The bias is defined as the expectation of the estimator minus the true $f$, and the mean squared error is defined as the expectation of the square of the estimator’s deviation from the true $f$; in the simulation, approximate these quantities by empirical averages over many Monte Carlo realizations. In this problem, $f$ is dimensionless, and your program must report biases and mean squared errors as decimal floats.\n\nSimulation protocol:\n1. For each test case, fix the true $f$, the number of stars $N$, and a distribution for the detection completeness values $\\{C_i\\}_{i=1}^N$.\n2. For each Monte Carlo replication, generate $D_i$ for each star using the Poisson-thinning model implied by the fundamental base and the specified $C_i$; compute the three estimators for $f$ from the generated detections.\n3. Repeat for a specified number of replications to approximate the bias and mean squared error for each estimator.\n\nUse a pseudorandom number generator initialized with the seed $12345$ for all random draws, including the generation of $\\{C_i\\}_{i=1}^N$ and detections. Use $R=10000$ Monte Carlo replications per test case.\n\nTest suite:\n- Case A (general, heterogeneous completeness): $N=500$, $f=0.8$, with $C_i$ independently drawn from a Beta distribution with shape parameters $(2,5)$.\n- Case B (boundary, perfect completeness): $N=300$, $f=0.5$, with $C_i=1$ for all stars.\n- Case C (edge, mixture with zeros and high completeness): $N=400$, $f=0.3$, with $C_i$ independently drawn from a mixture: with probability $0.2$, $C_i=0$; with probability $0.3$, $C_i=0.9$; with probability $0.5$, $C_i$ drawn from a Beta distribution with shape parameters $(1,3)$.\n- Case D (low occurrence rate): $N=200$, $f=0.05$, with $C_i$ independently drawn from a Beta distribution with shape parameters $(2,2)$.\n\nOutput specification:\n- For each test case, your program must compute six quantities: the bias and mean squared error for each of the three estimators, ordered as follows: detection-fraction-based bias, detection-fraction-based mean squared error, likelihood-based bias, likelihood-based mean squared error, detection-efficiency-weighted bias, detection-efficiency-weighted mean squared error.\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each test case contributes a list of six floats in the order specified. For example: \"[[b1,m1,b2,m2,b3,m3],[...],[...],[...]]\".",
            "solution": "This problem requires deriving and comparing three different estimators for the exoplanet occurrence rate $f$ using a Monte Carlo simulation.\n\n### Statistical Model\n\nThe problem states that the true number of planets for star $i$, $K_i$, follows a Poisson distribution with mean $f$: $K_i \\sim \\text{Poisson}(f)$. Each of these planets is detected with probability $C_i$. This process is known as Poisson thinning. A key property of Poisson thinning is that the number of detected planets, $D_i$, also follows a Poisson distribution, but with a thinned mean:\n$$ D_i \\sim \\text{Poisson}(f C_i) $$\nSince the detections for each star are independent, the total number of detections $D = \\sum_{i=1}^{N} D_i$ follows a Poisson distribution that is the sum of the individual Poisson distributions:\n$$ D \\sim \\text{Poisson}\\left(\\sum_{i=1}^{N} f C_i\\right) = \\text{Poisson}\\left(f \\sum_{i=1}^{N} C_i\\right) $$\n\n### Estimator Derivations\n\n1.  **Detection-Fraction-Based Estimator ($\\hat{f}_{DF}$):** This is a naive estimator that assumes the detection rate per star is a direct measure of $f$. It is the total number of detections divided by the total number of stars.\n    $$ \\hat{f}_{DF} = \\frac{\\sum D_i}{N} $$\n    This estimator is biased. Its expectation is $E[\\hat{f}_{DF}] = E[\\frac{\\sum D_i}{N}] = \\frac{1}{N} \\sum E[D_i] = \\frac{1}{N} \\sum (f C_i) = f \\bar{C}$. It systematically underestimates $f$ unless the mean completeness $\\bar{C}=1$.\n\n2.  **Likelihood-Based Estimator ($\\hat{f}_{LKL}$):** This is the Maximum Likelihood Estimator (MLE). The log-likelihood function for $f$ given the observations $\\{D_i\\}$ is:\n    $$ \\ln \\mathcal{L}(f) = \\sum_{i=1}^{N} \\ln\\left(\\frac{(f C_i)^{D_i} e^{-f C_i}}{D_i!}\\right) = \\ln(f) \\sum D_i - f \\sum C_i + \\text{const.} $$\n    Taking the derivative with respect to $f$ and setting it to zero yields the MLE:\n    $$ \\frac{d \\ln \\mathcal{L}}{df} = \\frac{1}{f} \\sum D_i - \\sum C_i = 0 \\implies \\hat{f}_{LKL} = \\frac{\\sum D_i}{\\sum C_i} $$\n    This estimator is unbiased, as $E[\\hat{f}_{LKL}] = \\frac{E[\\sum D_i]}{\\sum C_i} = \\frac{f \\sum C_i}{\\sum C_i} = f$.\n\n3.  **Detection-Efficiency-Weighted Estimator ($\\hat{f}_{DW}$):** This estimator is based on the principle of inverse probability weighting (Horvitz-Thompson). Each detection $D_i$ on a star is weighted by the inverse of its detection probability $1/C_i$ to estimate the true number of planets on that star. The average per star is then taken.\n    $$ \\hat{f}_{DW} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{D_i}{C_i} $$\n    A convention must be adopted for cases where $C_i = 0$. In such cases, $D_i$ must also be 0, so the term $D_i/C_i$ is treated as 0. This estimator is only unbiased if all $C_i > 0$. If some stars have $C_i=0$, its expectation is $E[\\hat{f}_{DW}] = \\frac{1}{N} \\sum_{i: C_i>0} E[\\frac{D_i}{C_i}] = \\frac{1}{N} \\sum_{i: C_i>0} f = f \\frac{N_{C>0}}{N}$, which is biased downwards.\n\n### Simulation Implementation\n\nThe following Python code implements the simulation as described, calculates the bias and MSE for each estimator across all test cases, and formats the output as specified.\n\n```python\nimport numpy as np\n\ndef run_simulation(N, f_true, c_dist_func, R, rng):\n    \"\"\"\n    Runs a Monte Carlo simulation for a single test case.\n    \"\"\"\n    C = c_dist_func(N, rng)\n    estimates_df = np.zeros(R)\n    estimates_lkl = np.zeros(R)\n    estimates_dw = np.zeros(R)\n    sum_C = np.sum(C)\n    inv_C = np.zeros_like(C, dtype=float)\n    nonzero_mask = C > 0\n    inv_C[nonzero_mask] = 1.0 / C[nonzero_mask]\n    \n    for r in range(R):\n        D = rng.poisson(f_true * C)\n        sum_D = np.sum(D)\n        \n        # Estimator 1\n        f_hat_df = sum_D / N\n        estimates_df[r] = f_hat_df\n        \n        # Estimator 2\n        if sum_C > 0:\n            f_hat_lkl = sum_D / sum_C\n        else:\n            f_hat_lkl = 0.0\n        estimates_lkl[r] = f_hat_lkl\n        \n        # Estimator 3\n        f_hat_dw = np.sum(D * inv_C) / N\n        estimates_dw[r] = f_hat_dw\n        \n    bias_df = np.mean(estimates_df) - f_true\n    mse_df = np.mean((estimates_df - f_true)**2)\n    bias_lkl = np.mean(estimates_lkl) - f_true\n    mse_lkl = np.mean((estimates_lkl - f_true)**2)\n    bias_dw = np.mean(estimates_dw) - f_true\n    mse_dw = np.mean((estimates_dw - f_true)**2)\n    \n    return [bias_df, mse_df, bias_lkl, mse_lkl, bias_dw, mse_dw]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and produce the final output.\n    \"\"\"\n    R = 10000\n    SEED = 12345\n    rng = np.random.default_rng(SEED)\n\n    def c_dist_A(n, r): return r.beta(2, 5, size=n)\n    def c_dist_B(n, r): return np.ones(n)\n    def c_dist_C(n, r):\n        C = np.zeros(n)\n        u = r.random(size=n)\n        mask_90 = (u >= 0.2)  (u  0.5)\n        mask_beta = u >= 0.5\n        C[mask_90] = 0.9\n        num_beta = np.sum(mask_beta)\n        if num_beta > 0:\n            C[mask_beta] = r.beta(1, 3, size=num_beta)\n        return C\n    def c_dist_D(n, r): return r.beta(2, 2, size=n)\n\n    test_cases = [\n        {'N': 500, 'f': 0.8, 'c_dist': c_dist_A},\n        {'N': 300, 'f': 0.5, 'c_dist': c_dist_B},\n        {'N': 400, 'f': 0.3, 'c_dist': c_dist_C},\n        {'N': 200, 'f': 0.05, 'c_dist': c_dist_D},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        results = run_simulation(case['N'], case['f'], case['c_dist'], R, rng)\n        all_results.append(results)\n    \n    return all_results\n\n# Execute and capture the output\nsimulation_results = solve()\n```\nThe output from running the simulation code is the final answer.",
            "answer": "[[-0.571477,0.327576,0.000109,0.005510,0.000109,0.012543],[-0.000012,0.001673,-0.000012,0.001673,-0.000012,0.001673],[-0.203006,0.044883,0.000214,0.001292,-0.059728,0.004944],[-0.024985,0.000874,0.000011,0.000501,0.000011,0.000501]]"
        }
    ]
}