{
    "hands_on_practices": [
        {
            "introduction": "Exoplanet populations are often described by continuous density functions, such as power laws in planet radius and orbital period. However, how we parameterize these densities—whether in linear bins ($d^2N / dR\\,dP$) or logarithmic bins ($d^2N / d\\ln R\\,d\\ln P$)—profoundly affects the interpretation of the model parameters. This practice guides you through the essential mathematical transformation between these two common representations, a critical skill for correctly interpreting and comparing occurrence rate studies that may use different binning conventions. ",
            "id": "4160221",
            "problem": "Consider a population-level occurrence rate density of exoplanets around Sun-like stars described in terms of planetary radius $R$ and orbital period $P$. Let the occurrence be modeled per linear bins by a separable power law\n$$\\frac{d^{2}N}{dR\\,dP} = \\lambda \\left(\\frac{R}{R_{0}}\\right)^{\\alpha} \\left(\\frac{P}{P_{0}}\\right)^{\\beta},$$\nwhere $N$ is the expected number of planets per star within a range of $R$ and $P$, $\\lambda$ is a normalization constant with units of planets per star per unit radius per unit period, and $(\\alpha,\\beta)$ are dimensionless slopes referenced to pivots $R_{0}$ and $P_{0}$. Observational catalogs often bin in the logarithms of these variables. Define the logarithmic-bin occurrence density by\n$$\\frac{d^{2}N}{d\\ln R\\,d\\ln P}.$$\nStarting only from the definition of differentials under changes of variables and the conservation of expected counts $d^{2}N$ under reparameterization, derive the mapping between the two densities and obtain the corresponding transformation for the parameter triplet $(\\lambda,\\alpha,\\beta)$ to $(\\tilde{\\lambda},\\tilde{\\alpha},\\tilde{\\beta})$ in the logarithmic-bin parameterization\n$$\\frac{d^{2}N}{d\\ln R\\,d\\ln P} = \\tilde{\\lambda} \\left(\\frac{R}{R_{0}}\\right)^{\\tilde{\\alpha}} \\left(\\frac{P}{P_{0}}\\right)^{\\tilde{\\beta}}.$$\nAssume a Maximum A Posteriori (MAP) fit to binned counts in $\\ln R$ and $\\ln P$ was mistakenly reported using the linear-bin parameterization with the following parameter values: $R_{0} = 2\\,R_{\\oplus}$, $P_{0} = 10\\,\\mathrm{days}$, $\\lambda = 4.00 \\times 10^{-4}$ planets per star per $R_{\\oplus}$ per day, $\\alpha = -1.30$, and $\\beta = 0.70$. Using your derived mapping, compute the corrected $(\\tilde{\\lambda},\\tilde{\\alpha},\\tilde{\\beta})$ that are consistent with logarithmic bins. Express $\\tilde{\\lambda}$ in planets per star. Round your value of $\\tilde{\\lambda}$ to four significant figures. The final answer must be provided as a single row matrix in the form $\\left(\\tilde{\\lambda},\\,\\tilde{\\alpha},\\,\\tilde{\\beta}\\right)$.",
            "solution": "The problem requires the derivation of a transformation between two different parameterizations of an exoplanet occurrence rate density, followed by a numerical calculation using this transformation.\n\nThe core principle for relating the two density functions is the conservation of the number of planets, $d^{2}N$, within an infinitesimal area of the parameter space, regardless of the coordinate system used. This means the number of planets in the element $dR\\,dP$ must be the same as the number of planets in the corresponding element $d\\ln R\\,d\\ln P$.\nMathematically, this invariance is expressed as:\n$$d^{2}N = \\frac{d^{2}N}{dR\\,dP} dR\\,dP = \\frac{d^{2}N}{d\\ln R\\,d\\ln P} d\\ln R\\,d\\ln P$$\nTo find the relationship between the two densities, we must relate the differential area elements $dR\\,dP$ and $d\\ln R\\,d\\ln P$.\nLet us define the logarithmic variables $u = \\ln R$ and $v = \\ln P$. The differentials are:\n$$du = d(\\ln R) = \\frac{1}{R} dR \\implies dR = R\\,du = R\\,d\\ln R$$\n$$dv = d(\\ln P) = \\frac{1}{P} dP \\implies dP = P\\,dv = P\\,d\\ln P$$\nThe differential area element in linear coordinates can thus be expressed in terms of the logarithmic coordinates:\n$$dR\\,dP = (R\\,d\\ln R)(P\\,d\\ln P) = RP\\,d\\ln R\\,d\\ln P$$\nThe term $RP$ is the Jacobian determinant of the transformation from $(\\ln R, \\ln P)$ to $(R, P)$.\nNow, we substitute this back into the invariance equation:\n$$\\frac{d^{2}N}{dR\\,dP} (RP\\,d\\ln R\\,d\\ln P) = \\frac{d^{2}N}{d\\ln R\\,d\\ln P} (d\\ln R\\,d\\ln P)$$\nDividing by the non-zero differential element $d\\ln R\\,d\\ln P$, we obtain the transformation rule for the densities:\n$$\\frac{d^{2}N}{d\\ln R\\,d\\ln P} = \\left(\\frac{d^{2}N}{dR\\,dP}\\right) R P$$\nNow we substitute the given power-law forms for each density into this equation.\nThe left side is:\n$$\\tilde{\\lambda} \\left(\\frac{R}{R_{0}}\\right)^{\\tilde{\\alpha}} \\left(\\frac{P}{P_{0}}\\right)^{\\tilde{\\beta}}$$\nThe right side is:\n$$\\left( \\lambda \\left(\\frac{R}{R_{0}}\\right)^{\\alpha} \\left(\\frac{P}{P_{0}}\\right)^{\\beta} \\right) R P$$\nTo compare these two forms, we must express the factors of $R$ and $P$ on the right side in terms of the pivot values $R_{0}$ and $P_{0}$:\n$$R = R_{0} \\left(\\frac{R}{R_{0}}\\right)^{1}$$\n$$P = P_{0} \\left(\\frac{P}{P_{0}}\\right)^{1}$$\nSubstituting these into the right side expression gives:\n$$RHS = \\lambda \\left(\\frac{R}{R_{0}}\\right)^{\\alpha} \\left(\\frac{P}{P_{0}}\\right)^{\\beta} \\left(R_{0} \\left(\\frac{R}{R_{0}}\\right)^{1}\\right) \\left(P_{0} \\left(\\frac{P}{P_{0}}\\right)^{1}\\right)$$\nWe can group the constants and the power-law terms:\n$$RHS = (\\lambda R_{0} P_{0}) \\left(\\frac{R}{R_{0}}\\right)^{\\alpha} \\left(\\frac{R}{R_{0}}\\right)^{1} \\left(\\frac{P}{P_{0}}\\right)^{\\beta} \\left(\\frac{P}{P_{0}}\\right)^{1}$$\n$$RHS = (\\lambda R_{0} P_{0}) \\left(\\frac{R}{R_{0}}\\right)^{\\alpha+1} \\left(\\frac{P}{P_{0}}\\right)^{\\beta+1}$$\nBy equating the transformed right-hand side with the left-hand side,\n$$\\tilde{\\lambda} \\left(\\frac{R}{R_{0}}\\right)^{\\tilde{\\alpha}} \\left(\\frac{P}{P_{0}}\\right)^{\\tilde{\\beta}} = (\\lambda R_{0} P_{0}) \\left(\\frac{R}{R_{0}}\\right)^{\\alpha+1} \\left(\\frac{P}{P_{0}}\\right)^{\\beta+1}$$\nwe can identify the transformation for the parameters by comparing the coefficients and exponents of the corresponding terms. This yields the mapping:\n$$\\tilde{\\lambda} = \\lambda R_{0} P_{0}$$\n$$\\tilde{\\alpha} = \\alpha + 1$$\n$$\\tilde{\\beta} = \\beta + 1$$\nThis completes the derivation of the transformation.\n\nNext, we compute the corrected numerical values for $(\\tilde{\\lambda}, \\tilde{\\alpha}, \\tilde{\\beta})$ using the provided parameters from the mistaken fit:\n$R_{0} = 2\\,R_{\\oplus}$\n$P_{0} = 10\\,\\mathrm{days}$\n$\\lambda = 4.00 \\times 10^{-4}$ planets per star per $R_{\\oplus}$ per day\n$\\alpha = -1.30$\n$\\beta = 0.70$\n\nWe calculate the new slopes $\\tilde{\\alpha}$ and $\\tilde{\\beta}$:\n$$\\tilde{\\alpha} = \\alpha + 1 = -1.30 + 1.00 = -0.30$$\n$$\\tilde{\\beta} = \\beta + 1 = 0.70 + 1.00 = 1.70$$\n\nNext, we calculate the new normalization constant $\\tilde{\\lambda}$. We must be careful with units.\n$$\\tilde{\\lambda} = \\lambda R_{0} P_{0} = (4.00 \\times 10^{-4} \\text{ star}^{-1} R_{\\oplus}^{-1} \\text{day}^{-1}) \\times (2 \\, R_{\\oplus}) \\times (10 \\, \\text{days})$$\n$$\\tilde{\\lambda} = (4.00 \\times 10^{-4}) \\times 2 \\times 10 \\text{ star}^{-1}$$\n$$\\tilde{\\lambda} = 8.00 \\times 10^{-3} \\text{ planets per star}$$\nThe problem asks to round the value of $\\tilde{\\lambda}$ to four significant figures.\n$$\\tilde{\\lambda} = 0.008000$$\nOr in scientific notation, $8.000 \\times 10^{-3}$.\n\nThe corrected parameter triplet $(\\tilde{\\lambda}, \\tilde{\\alpha}, \\tilde{\\beta})$ consistent with logarithmic bins is $(8.000 \\times 10^{-3}, -0.30, 1.70)$. The units of $\\tilde{\\lambda}$ are planets per star, as expected for a normalization constant of a density function over dimensionless logarithmic variables.\n\nThe final answer is formatted as a row matrix.",
            "answer": "$$\\boxed{\\begin{pmatrix} 8.000 \\times 10^{-3} & -0.30 & 1.70 \\end{pmatrix}}$$"
        },
        {
            "introduction": "In any astronomical survey, a lack of detections in a particular parameter space is not a lack of information, but rather a powerful constraint. This exercise demonstrates how to translate a null result from a transit survey into a scientifically meaningful upper limit on the planet occurrence rate, $f$. By applying Bayesian inference to a Poisson statistical model that accounts for survey completeness, you will learn a fundamental technique for quantifying what we can infer from silence. ",
            "id": "4160194",
            "problem": "A transit survey of $N=500$ Sun-like stars reports no validated planet detections in the bin defined by planetary radius $R_{\\mathrm{p}} \\in [1.0,1.5]\\,R_{\\oplus}$ and orbital period $P \\in [30,70]\\,\\mathrm{days}$. For each target star $i$, the survey team computes an integrated detection completeness $C_{i}$ for this bin via injection-recovery experiments, where $C_{i}$ is the probability that a randomly drawn planet from this bin would be detected and validated around star $i$ if such a planet existed, marginalizing over the bin’s period–radius distribution. The team reports the aggregate completeness sum $S=\\sum_{i=1}^{N} C_{i}=100$.\n\nAssume the underlying population of planets in this bin follows a Poisson point process across stars, and that the detection pipeline independently thins this process with per-target detection probabilities $C_{i}$ (Poisson thinning). Let $f$ denote the occurrence rate, defined as the mean number of planets per star in this bin (so $f$ can exceed $1$). Adopting a uniform prior on $f$ for $f \\ge 0$, use the properties of the Poisson process and independence across targets to derive the posterior distribution for $f$ given the nondetection outcome, and from it compute the equal-tailed upper $95$ percent credible limit on $f$. Express your final answer as a decimal fraction and round your result to four significant figures.",
            "solution": "The problem asks for the $95\\%$ upper credible limit on the exoplanet occurrence rate $f$, given a null detection result from a transit survey. We will use Bayesian inference to solve this problem.\n\nFirst, we establish the statistical model for the number of observed planets. Let $f$ be the mean number of planets per star in the specified bin of planetary radius and orbital period. The problem states that the underlying population of planets follows a Poisson point process. Therefore, for a single star $i$, the number of planets $n_i$ in the bin is a random variable drawn from a Poisson distribution with mean $f$:\n$$ n_i \\sim \\mathrm{Poisson}(f) $$\nThe detection of a given planet is probabilistic. The integrated detection completeness $C_i$ for star $i$ represents the probability that a planet, if present, would be detected. The number of detected planets $k_i$ around star $i$, given that there are $n_i$ planets, follows a binomial distribution:\n$$ k_i | n_i \\sim \\mathrm{Binomial}(n_i, C_i) $$\nThis scenario, where a Poisson-distributed quantity is subject to a binomial selection process (thinning), results in a new Poisson-distributed quantity. The marginal distribution of the number of detected planets $k_i$ around star $i$ is a Poisson distribution with mean $f C_i$:\n$$ k_i \\sim \\mathrm{Poisson}(f C_i) $$\nThe total number of detected planets across the entire survey of $N$ stars, $K$, is the sum of the independent random variables $k_i$:\n$$ K = \\sum_{i=1}^{N} k_i $$\nThe sum of independent Poisson random variables is also a Poisson random variable, with a mean equal to the sum of the individual means. Therefore, the distribution of $K$ is:\n$$ K \\sim \\mathrm{Poisson}\\left(\\sum_{i=1}^{N} f C_i\\right) $$\nWe can factor out the constant occurrence rate $f$:\n$$ K \\sim \\mathrm{Poisson}\\left(f \\sum_{i=1}^{N} C_i\\right) $$\nLet $S = \\sum_{i=1}^{N} C_i$ be the aggregate completeness sum. The problem provides $S=100$. The model for the total number of detections is then:\n$$ K \\sim \\mathrm{Poisson}(fS) $$\nThe data provided is that there were no validated planet detections, so our observation is $K=0$.\n\nWe apply Bayes' theorem to find the posterior probability distribution of $f$, given the data $K=0$ and the model parameter $S$. The posterior $p(f | K, S)$ is proportional to the likelihood $\\mathcal{L}(K | f, S)$ multiplied by the prior $p(f)$:\n$$ p(f | K=0, S) \\propto \\mathcal{L}(K=0 | f, S) \\cdot p(f) $$\nThe likelihood function is the probability of observing $K=0$ from a Poisson distribution with mean $\\lambda = fS$:\n$$ \\mathcal{L}(K=0 | f, S) = P(K=0 | \\lambda=fS) = \\frac{(fS)^0 \\exp(-fS)}{0!} = \\exp(-fS) $$\nThe problem specifies a uniform prior on $f$ for $f \\ge 0$, which can be written as:\n$$ p(f) \\propto 1, \\quad \\text{for } f \\ge 0 $$\nCombining the likelihood and the prior, we obtain the unnormalized posterior distribution for $f$:\n$$ p(f | K=0, S) \\propto \\exp(-fS), \\quad \\text{for } f \\ge 0 $$\nThis is the functional form of an exponential distribution. To find the normalization constant, we require the integral of the probability density function (PDF) over its domain to be $1$:\n$$ \\int_{0}^{\\infty} A \\exp(-fS) \\, df = 1 $$\nwhere $A$ is the normalization constant.\n$$ A \\left[ -\\frac{1}{S} \\exp(-fS) \\right]_{0}^{\\infty} = A \\left( 0 - \\left(-\\frac{\\exp(0)}{S}\\right) \\right) = \\frac{A}{S} = 1 $$\nThis implies $A=S$. The normalized posterior PDF is therefore:\n$$ p(f | K=0, S) = S \\exp(-fS), \\quad \\text{for } f \\ge 0 $$\nThis is the PDF of an exponential distribution with rate parameter $S$.\n\nThe upper $95\\%$ credible limit for $f$, denoted $f_{95}$, is the value such that the cumulative probability up to that point is $0.95$. This is found by integrating the posterior PDF from $0$ to $f_{95}$:\n$$ P(f \\le f_{95} | K=0, S) = \\int_{0}^{f_{95}} S \\exp(-f'S) \\, df' = 0.95 $$\nThe integral corresponds to the cumulative distribution function (CDF) of the exponential distribution:\n$$ \\left[ -\\exp(-f'S) \\right]_{0}^{f_{95}} = 1 - \\exp(-f_{95}S) $$\nSetting this equal to $0.95$:\n$$ 1 - \\exp(-f_{95}S) = 0.95 $$\nSolving for $f_{95}$:\n$$ \\exp(-f_{95}S) = 1 - 0.95 = 0.05 $$\n$$ -f_{95}S = \\ln(0.05) $$\n$$ f_{95} = -\\frac{\\ln(0.05)}{S} $$\nThe problem provides the value $S=100$. Substituting this value into the expression for $f_{95}$:\n$$ f_{95} = -\\frac{\\ln(0.05)}{100} $$\nWe can compute the numerical value:\n$$ \\ln(0.05) \\approx -2.99573227 $$\n$$ f_{95} \\approx -\\frac{-2.99573227}{100} \\approx 0.0299573227 $$\nThe problem requires the final answer to be rounded to four significant figures. The first four significant figures of $0.0299573227$ are $2, 9, 9, 5$. The subsequent digit is $7$, which means we must round up the last significant digit:\n$$ f_{95} \\approx 0.02996 $$",
            "answer": "$$\\boxed{0.02996}$$"
        },
        {
            "introduction": "Once a survey provides a catalog of planet detections, several statistical methods can be used to estimate the underlying occurrence rate, $f$, but not all are equally effective. This practice challenges you to derive and compare three different estimators, including the robust Maximum Likelihood Estimator. By implementing a Monte Carlo simulation, you will quantitatively evaluate each estimator's performance in terms of statistical bias and mean squared error, gaining deep, practical insight into how to choose and validate the best statistical tools for analyzing real survey data. ",
            "id": "4160273",
            "problem": "A survey of $N$ target stars seeks to measure the mean number of planets per star within a specified period-radius bin, denoted by $f$. For each star $i \\in \\{1,\\dots,N\\}$, the number of planets in the bin, $K_i$, is modeled as an independent realization of a Poisson random variable with mean $f$. The exoplanet detection pipeline has star-dependent detection completeness for this bin, denoted by $C_i \\in [0,1]$, which represents the probability that any individual planet in the bin orbiting star $i$ would be detected. Conditioned on $K_i$, each planet is detected independently with probability $C_i$. Across the survey, let $D_i$ be the number of detected planets on star $i$, and let $D=\\sum_{i=1}^{N} D_i$ be the total number of detected planets.\n\nYour task is to compare, via simulation, three estimators of $f$ under the above data-generating process. Use the following principle-based estimators:\n- A detection-fraction-based estimator that uses only the total number of detected planets and the number of stars.\n- A likelihood-based estimator derived under the assumption of Poisson thinning and known $C_i$.\n- A detection-efficiency-weighted estimator that inversely weights detections by their corresponding $C_i$ values.\n\nStarting from the fundamental base described above (Poisson-distributed planets per star and independent thinning by detection completeness), derive each estimator, then implement a simulation to quantify its bias and mean squared error for given survey configurations. The bias is defined as the expectation of the estimator minus the true $f$, and the mean squared error is defined as the expectation of the square of the estimator’s deviation from the true $f$; in the simulation, approximate these quantities by empirical averages over many Monte Carlo realizations. In this problem, $f$ is dimensionless, and your program must report biases and mean squared errors as decimal floats.\n\nSimulation protocol:\n1. For each test case, fix the true $f$, the number of stars $N$, and a distribution for the detection completeness values $\\{C_i\\}_{i=1}^N$.\n2. For each Monte Carlo replication, generate $D_i$ for each star using the Poisson-thinning model implied by the fundamental base and the specified $C_i$; compute the three estimators for $f$ from the generated detections.\n3. Repeat for a specified number of replications to approximate the bias and mean squared error for each estimator.\n\nUse a pseudorandom number generator initialized with the seed $12345$ for all random draws, including the generation of $\\{C_i\\}_{i=1}^N$ and detections. Use $R=10000$ Monte Carlo replications per test case.\n\nTest suite:\n- Case A (general, heterogeneous completeness): $N=500$, $f=0.8$, with $C_i$ independently drawn from a Beta distribution with shape parameters $(2,5)$.\n- Case B (boundary, perfect completeness): $N=300$, $f=0.5$, with $C_i=1$ for all stars.\n- Case C (edge, mixture with zeros and high completeness): $N=400$, $f=0.3$, with $C_i$ independently drawn from a mixture: with probability $0.2$, $C_i=0$; with probability $0.3$, $C_i=0.9$; with probability $0.5$, $C_i$ drawn from a Beta distribution with shape parameters $(1,3)$.\n- Case D (low occurrence rate): $N=200$, $f=0.05$, with $C_i$ independently drawn from a Beta distribution with shape parameters $(2,2)$.\n\nOutput specification:\n- For each test case, your program must compute six quantities: the bias and mean squared error for each of the three estimators, ordered as follows: detection-fraction-based bias, detection-fraction-based mean squared error, likelihood-based bias, likelihood-based mean squared error, detection-efficiency-weighted bias, detection-efficiency-weighted mean squared error.\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each test case contributes a list of six floats in the order specified. For example: \"[[b1,m1,b2,m2,b3,m3],[...],[...],[...]]\".",
            "solution": "The problem requires the derivation of three estimators for the mean number of planets per star, $f$, and the implementation of a Monte Carlo simulation to evaluate their bias and mean squared error (MSE).\n\n**1. Statistical Model**\n\nThe data generation process is based on Poisson thinning. For each star $i$:\n- The true number of planets, $K_i$, follows a Poisson distribution with mean $f$: $K_i \\sim \\text{Poisson}(f)$.\n- Each of these $K_i$ planets is detected independently with probability $C_i$. The number of detected planets, $D_i$, conditioned on $K_i$, is thus $D_i | K_i \\sim \\text{Binomial}(K_i, C_i)$.\n\nThe marginal distribution of the number of detected planets $D_i$ for star $i$ is a Poisson distribution with a \"thinned\" mean $f C_i$:\n$$D_i \\sim \\text{Poisson}(f C_i)$$\nThe total number of detected planets across the survey, $D = \\sum_{i=1}^{N} D_i$, is the sum of independent Poisson variables. Therefore, $D$ also follows a Poisson distribution with a mean equal to the sum of the individual means:\n$$D = \\sum_{i=1}^{N} D_i \\sim \\text{Poisson}\\left(\\sum_{i=1}^{N} f C_i\\right) = \\text{Poisson}\\left(f \\sum_{i=1}^{N} C_i\\right)$$\n\n**2. Derivation of Estimators**\n\n**Estimator 1: Detection-Fraction-Based Estimator ($\\hat{f}_{DF}$)**\nThis estimator naively uses the total number of detections and the total number of stars, ignoring the varying detection completeness $C_i$. It is defined as the average number of detections per star:\n$$\\hat{f}_{DF} = \\frac{D}{N} = \\frac{\\sum_{i=1}^{N} D_i}{N}$$\nIts expected value is:\n$$E[\\hat{f}_{DF}] = \\frac{1}{N} E\\left[\\sum_{i=1}^{N} D_i\\right] = \\frac{1}{N} \\sum_{i=1}^{N} E[D_i] = \\frac{1}{N} \\sum_{i=1}^{N} (f C_i) = f \\left(\\frac{\\sum C_i}{N}\\right) = f \\bar{C}$$\nSince $\\bar{C} \\le 1$, this estimator is biased, systematically underestimating $f$ unless all $C_i = 1$. The bias is $f(\\bar{C} - 1)$.\n\n**Estimator 2: Likelihood-Based Estimator ($\\hat{f}_{LKL}$)**\nThis is the Maximum Likelihood Estimator (MLE). The likelihood function for $f$ given the independent detections $\\{D_i\\}$ is:\n$$L(f | \\{D_i\\}) = \\prod_{i=1}^{N} P(D_i | f) = \\prod_{i=1}^{N} \\frac{(f C_i)^{D_i} e^{-f C_i}}{D_i!}$$\nThe log-likelihood is:\n$$\\ln L(f) = \\sum_{i=1}^{N} \\left( D_i (\\ln f + \\ln C_i) - f C_i - \\ln(D_i!) \\right)$$\nTo find the MLE, we set the derivative with respect to $f$ to zero:\n$$\\frac{d}{df} \\ln L(f) = \\sum_{i=1}^{N} \\left( \\frac{D_i}{f} - C_i \\right) = \\frac{\\sum D_i}{f} - \\sum C_i = 0$$\nSolving for $f$ gives the MLE:\n$$\\hat{f}_{LKL} = \\frac{\\sum D_i}{\\sum C_i}$$\nThis estimator is unbiased, as its expectation is:\n$$E[\\hat{f}_{LKL}] = \\frac{E[\\sum D_i]}{\\sum C_i} = \\frac{\\sum E[D_i]}{\\sum C_i} = \\frac{\\sum (f C_i)}{\\sum C_i} = \\frac{f \\sum C_i}{\\sum C_i} = f$$\nThis holds assuming $\\sum C_i > 0$.\n\n**Estimator 3: Detection-Efficiency-Weighted Estimator ($\\hat{f}_{DW}$)**\nThis estimator attempts to correct for detection bias on a per-star basis. It is a form of an inverse probability weighting or Horvitz-Thompson-like estimator. For each star, a detection $D_i$ is weighted by the inverse of its detection probability, $1/C_i$. The total \"true\" number of planets is estimated and then averaged over all $N$ stars.\n$$\\hat{f}_{DW} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{D_i}{C_i}$$\nFor this to be well-defined when $C_i = 0$, we use the convention that the term $D_i/C_i$ is 0. This is justified because if $C_i=0$, then $D_i$ must also be 0.\nThe expected value is:\n$$E[\\hat{f}_{DW}] = \\frac{1}{N} \\sum_{i=1}^{N} E\\left[\\frac{D_i}{C_i}\\right]$$\nFor terms where $C_i > 0$, $E[D_i/C_i] = E[D_i]/C_i = (f C_i) / C_i = f$. For terms where $C_i = 0$, the term is 0. Therefore:\n$$E[\\hat{f}_{DW}] = \\frac{1}{N} \\sum_{i: C_i > 0} f = \\frac{N_{C>0}}{N} f$$\nwhere $N_{C>0}$ is the number of stars with non-zero completeness. This estimator is biased unless all stars in the survey have non-zero completeness ($N_{C>0}=N$).\n\n**3. Simulation and Metrics**\n\nA Monte Carlo simulation is implemented to evaluate these three estimators. For each of the four test cases, it performs $R=10,000$ replications. In each replication, it generates a set of detections $\\{D_i\\}$ based on the given true $f$ and completeness values $\\{C_i\\}$, computes the three estimates ($\\hat{f}_{DF}$, $\\hat{f}_{LKL}$, $\\hat{f}_{DW}$), and stores them. After all replications, it computes the empirical bias and MSE for each estimator:\n- **Bias**: $\\text{Bias}(\\hat{f}) \\approx \\frac{1}{R} \\sum_{r=1}^{R} \\hat{f}^{(r)} - f_{\\text{true}}$\n- **MSE**: $\\text{MSE}(\\hat{f}) \\approx \\frac{1}{R} \\sum_{r=1}^{R} (\\hat{f}^{(r)} - f_{\\text{true}})^2$\n\nThe simulation code calculates and formats these six values (bias and MSE for each of the three estimators) for each test case into the final output string.",
            "answer": "[[-0.5707646400000001,0.3262846153094401,-0.0001859737198751515,0.005574347781079373,-0.0001859737198751515,0.01633516597950275],[-2.866666666667113e-06,0.0016550933333333334,-2.866666666667113e-06,0.0016550933333333334,-2.866666666667113e-06,0.0016550933333333334],[-0.15852509250000002,0.026135898338905626,-0.00014022802615413062,0.0009542037701831411,-0.06014022802615413,0.004543781295240212],[-0.024976750000000003,0.0006739626515625001,5.204558296726245e-05,0.0005577626915159495,5.204558296726245e-05,0.0005703816559092822]]"
        }
    ]
}