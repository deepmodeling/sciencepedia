{"hands_on_practices": [{"introduction": "In quantum mechanics, physical observables correspond to operators, which in turn are represented by matrices when a basis set is chosen. Performing successive operations, such as applying an operator twice, translates to matrix multiplication. This exercise [@problem_id:1379886] provides foundational practice in this essential skill, highlighting the manipulation of complex numbers that are ubiquitous in the quantum domain.", "problem": "In the quantum mechanical description of a two-state system, an operator $\\hat{A}$ represents a particular physical observable. The system is defined with respect to an orthonormal basis $\\{|\\psi_1\\rangle, |\\psi_2\\rangle\\}$. In this basis, the matrix representation of the operator $\\hat{A}$ is given by the matrix $A$, where the elements are defined as $A_{ij} = \\langle \\psi_i | \\hat{A} | \\psi_j \\rangle$.\n\nThe specific matrix for the operator $\\hat{A}$ is:\n$$\nA = \\begin{pmatrix} 1 & 2-3i \\\\ 2+3i & 1 \\end{pmatrix}\n$$\nwhere $i$ is the imaginary unit, satisfying $i^2 = -1$.\n\nDetermine the matrix representation for the operator $\\hat{A}^2$ in the same basis. Present your final answer as a 2x2 matrix.", "solution": "We are given the matrix representation of the operator $\\hat{A}$ in the orthonormal basis $\\{|\\psi_{1}\\rangle,|\\psi_{2}\\rangle\\}$ as\n$$\nA=\\begin{pmatrix}1 & 2-3i \\\\ 2+3i & 1\\end{pmatrix}.\n$$\nThe matrix representation of $\\hat{A}^{2}$ in the same basis is the matrix square $A^{2}=A\\cdot A$. Writing $A=\\begin{pmatrix}a & b \\\\ c & d\\end{pmatrix}$ with $a=d=1$, $b=2-3i$, and $c=2+3i$, the product is\n$$\nA^{2}=\\begin{pmatrix}a^{2}+bc & ab+bd \\\\ ca+dc & cb+d^{2}\\end{pmatrix}.\n$$\nCompute each entry explicitly:\n- For the diagonal terms, use $bc=(2-3i)(2+3i)=4-9i^{2}=4+9=13$ since $i^{2}=-1$. Thus\n$$\na^{2}+bc=1+13=14,\\qquad cb+d^{2}=13+1=14.\n$$\n- For the off-diagonal terms,\n$$\nab+bd=b(a+d)=(2-3i)(1+1)=2(2-3i)=4-6i,\n$$\n$$\nca+dc=c(a+d)=(2+3i)(1+1)=2(2+3i)=4+6i.\n$$\nTherefore,\n$$\nA^{2}=\\begin{pmatrix}14 & 4-6i \\\\ 4+6i & 14\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}14 & 4-6i \\\\ 4+6i & 14\\end{pmatrix}}$$", "id": "1379886"}, {"introduction": "A central task in quantum chemistry is to determine the allowed energy levels of electrons in a molecule, which are found by solving a secular equation. This equation is elegantly expressed using a determinant, making the calculation of determinants a critical skill for any quantum chemist. This problem [@problem_id:1379862] applies this concept to the Hückel Molecular Orbital (HMO) model, a powerful framework for approximating the energies of $\\pi$ electrons in conjugated systems.", "problem": "In the context of Hückel Molecular Orbital (HMO) theory, the electronic structure of conjugated molecules can be approximated by solving a secular equation involving a Hückel matrix. Consider a linear chain of three conjugated carbon atoms, such as the allyl radical. The Hückel matrix $\\mathbf{H}$ for this system is constructed using the following rules:\n1.  The diagonal elements, $H_{ii}$, are assigned the Coulomb integral, denoted by the symbol $\\alpha$.\n2.  The off-diagonal elements, $H_{ij}$, are assigned the resonance integral, denoted by $\\beta$, if atoms $i$ and $j$ are directly bonded.\n3.  The off-diagonal elements, $H_{ij}$, are set to $0$ if atoms $i$ and $j$ are not directly bonded.\n\nFor the linear three-carbon system (C1-C2-C3), atom 1 is bonded to atom 2, atom 2 is bonded to atoms 1 and 3, and atom 3 is bonded to atom 2. This results in the following 3x3 Hückel matrix:\n\n$$\n\\mathbf{H} = \\begin{pmatrix} \\alpha & \\beta & 0 \\\\ \\beta & \\alpha & \\beta \\\\ 0 & \\beta & \\alpha \\end{pmatrix}\n$$\n\nCalculate the determinant of this Hückel matrix $\\mathbf{H}$. Your final answer should be an analytic expression in terms of $\\alpha$ and $\\beta$.", "solution": "We are to compute the determinant of the Hückel matrix\n$$\n\\mathbf{H}=\\begin{pmatrix}\n\\alpha & \\beta & 0 \\\\\n\\beta & \\alpha & \\beta \\\\\n0 & \\beta & \\alpha\n\\end{pmatrix}.\n$$\nUsing cofactor expansion along the first row, the determinant is\n$$\n\\det(\\mathbf{H})=\\alpha \\det\\begin{pmatrix}\\alpha & \\beta \\\\ \\beta & \\alpha\\end{pmatrix}-\\beta \\det\\begin{pmatrix}\\beta & \\beta \\\\ 0 & \\alpha\\end{pmatrix}+0\\cdot\\det(\\cdots).\n$$\nCompute each minor determinant:\n$$\n\\det\\begin{pmatrix}\\alpha & \\beta \\\\ \\beta & \\alpha\\end{pmatrix}=\\alpha^{2}-\\beta^{2}, \\qquad\n\\det\\begin{pmatrix}\\beta & \\beta \\\\ 0 & \\alpha\\end{pmatrix}=\\beta\\alpha-0\\cdot\\beta=\\alpha\\beta.\n$$\nSubstitute back:\n$$\n\\det(\\mathbf{H})=\\alpha(\\alpha^{2}-\\beta^{2})-\\beta(\\alpha\\beta)=\\alpha^{3}-\\alpha\\beta^{2}-\\alpha\\beta^{2}=\\alpha^{3}-2\\alpha\\beta^{2}.\n$$\nTherefore,\n$$\n\\det(\\mathbf{H})=\\alpha(\\alpha^{2}-2\\beta^{2}).\n$$", "answer": "$$\\boxed{\\alpha^{3}-2\\alpha\\beta^{2}}$$", "id": "1379862"}, {"introduction": "Unlike the algebra of ordinary numbers, the order of matrix multiplication matters—a property known as non-commutation. This has profound physical consequences in quantum mechanics, forming the mathematical basis of Heisenberg's uncertainty principle. This advanced exercise [@problem_id:1379891] explores a key result of non-commutation through matrix exponentiation, demonstrating concretely why $e^{A+B}$ is not generally equal to $e^A e^B$ for matrices.", "problem": "In the quantum theory of spin, the Pauli matrices are fundamental operators. For a spin-1/2 particle, two of these matrices are given by:\n$$ \\sigma_x = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad \\sigma_y = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix} $$\nwhere $i^2 = -1$.\n\nA key property of matrix exponentiation is that for non-commuting matrices $A$ and $B$, $e^{A+B} \\neq e^A e^B$. Consider the difference matrix $D(\\alpha)$ defined for a real parameter $\\alpha$ as:\n$$ D(\\alpha) = e^{\\alpha(\\sigma_x + \\sigma_y)} - e^{\\alpha\\sigma_x} e^{\\alpha\\sigma_y} $$\nBy performing a series expansion of the matrix exponentials for small $\\alpha$, this difference can be approximated as a power series in $\\alpha$. Determine the matrix $M$ which represents the coefficient of the lowest-order non-vanishing term in this expansion. Specifically, find the matrix $M$ such that $D(\\alpha) = M \\alpha^2 + O(\\alpha^3)$, where $O(\\alpha^3)$ denotes terms of order $\\alpha^3$ and higher.", "solution": "Our goal is to find the matrix coefficient $M$ of the $\\alpha^2$ term in the series expansion of $D(\\alpha) = e^{\\alpha(\\sigma_x + \\sigma_y)} - e^{\\alpha\\sigma_x} e^{\\alpha\\sigma_y}$. We will use the Taylor series for a matrix exponential, $e^X = I + X + \\frac{X^2}{2!} + \\frac{X^3}{3!} + \\dots$, where $I$ is the identity matrix. We need to expand both terms in the expression for $D(\\alpha)$ up to the order of $\\alpha^2$.\n\nFirst, let's analyze the term $e^{\\alpha(\\sigma_x + \\sigma_y)}$. Let $A = \\alpha(\\sigma_x + \\sigma_y)$. The expansion is:\n$$ e^A = I + A + \\frac{A^2}{2} + O(\\alpha^3) $$\nWe need to compute $A^2$:\n$$ A^2 = (\\alpha(\\sigma_x + \\sigma_y))^2 = \\alpha^2 (\\sigma_x + \\sigma_y)^2 = \\alpha^2 (\\sigma_x^2 + \\sigma_x\\sigma_y + \\sigma_y\\sigma_x + \\sigma_y^2) $$\nLet's compute the necessary matrix products:\n$$ \\sigma_x^2 = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = I $$\n$$ \\sigma_y^2 = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix} \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix} = \\begin{pmatrix} (-i)(i) & 0 \\\\ 0 & (i)(-i) \\end{pmatrix} = \\begin{pmatrix} -i^2 & 0 \\\\ 0 & -i^2 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = I $$\n$$ \\sigma_x\\sigma_y = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix} = \\begin{pmatrix} i & 0 \\\\ 0 & -i \\end{pmatrix} $$\n$$ \\sigma_y\\sigma_x = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} -i & 0 \\\\ 0 & i \\end{pmatrix} $$\nSubstituting these back into the expression for $A^2$:\n$$ A^2 = \\alpha^2 (I + \\sigma_x\\sigma_y + \\sigma_y\\sigma_x + I) = \\alpha^2 (2I + \\sigma_x\\sigma_y + \\sigma_y\\sigma_x) $$\nSo, the first exponential term is:\n$$ e^{\\alpha(\\sigma_x + \\sigma_y)} = I + \\alpha(\\sigma_x + \\sigma_y) + \\frac{\\alpha^2}{2}(2I + \\sigma_x\\sigma_y + \\sigma_y\\sigma_x) + O(\\alpha^3) $$\n$$ e^{\\alpha(\\sigma_x + \\sigma_y)} = I + \\alpha(\\sigma_x + \\sigma_y) + \\alpha^2 I + \\frac{\\alpha^2}{2}(\\sigma_x\\sigma_y + \\sigma_y\\sigma_x) + O(\\alpha^3) $$\n\nNext, we analyze the term $e^{\\alpha\\sigma_x} e^{\\alpha\\sigma_y}$. We expand each exponential separately up to order $\\alpha^2$ and then multiply them.\n$$ e^{\\alpha\\sigma_x} = I + \\alpha\\sigma_x + \\frac{(\\alpha\\sigma_x)^2}{2} + O(\\alpha^3) = I + \\alpha\\sigma_x + \\frac{\\alpha^2}{2}\\sigma_x^2 + O(\\alpha^3) = I + \\alpha\\sigma_x + \\frac{\\alpha^2}{2}I + O(\\alpha^3) $$\n$$ e^{\\alpha\\sigma_y} = I + \\alpha\\sigma_y + \\frac{(\\alpha\\sigma_y)^2}{2} + O(\\alpha^3) = I + \\alpha\\sigma_y + \\frac{\\alpha^2}{2}\\sigma_y^2 + O(\\alpha^3) = I + \\alpha\\sigma_y + \\frac{\\alpha^2}{2}I + O(\\alpha^3) $$\nNow, we multiply these two expansions and keep terms up to order $\\alpha^2$:\n$$ e^{\\alpha\\sigma_x} e^{\\alpha\\sigma_y} = \\left( I + \\alpha\\sigma_x + \\frac{\\alpha^2}{2}I \\right) \\left( I + \\alpha\\sigma_y + \\frac{\\alpha^2}{2}I \\right) + O(\\alpha^3) $$\n$$ = I(I + \\alpha\\sigma_y + \\frac{\\alpha^2}{2}I) + \\alpha\\sigma_x(I + \\alpha\\sigma_y + \\dots) + \\frac{\\alpha^2}{2}I(I + \\dots) + O(\\alpha^3) $$\n$$ = (I + \\alpha\\sigma_y + \\frac{\\alpha^2}{2}I) + (\\alpha\\sigma_x + \\alpha^2\\sigma_x\\sigma_y) + \\frac{\\alpha^2}{2}I + O(\\alpha^3) $$\nCollecting terms by powers of $\\alpha$:\n$$ e^{\\alpha\\sigma_x} e^{\\alpha\\sigma_y} = I + \\alpha(\\sigma_x + \\sigma_y) + \\alpha^2\\left(\\frac{1}{2}I + \\sigma_x\\sigma_y + \\frac{1}{2}I\\right) + O(\\alpha^3) $$\n$$ e^{\\alpha\\sigma_x} e^{\\alpha\\sigma_y} = I + \\alpha(\\sigma_x + \\sigma_y) + \\alpha^2(I + \\sigma_x\\sigma_y) + O(\\alpha^3) $$\n\nFinally, we compute the difference $D(\\alpha)$:\n$$ D(\\alpha) = e^{\\alpha(\\sigma_x + \\sigma_y)} - e^{\\alpha\\sigma_x} e^{\\alpha\\sigma_y} $$\n$$ D(\\alpha) = \\left[ I + \\alpha(\\sigma_x + \\sigma_y) + \\alpha^2 I + \\frac{\\alpha^2}{2}(\\sigma_x\\sigma_y + \\sigma_y\\sigma_x) \\right] - \\left[ I + \\alpha(\\sigma_x + \\sigma_y) + \\alpha^2(I + \\sigma_x\\sigma_y) \\right] + O(\\alpha^3) $$\nThe terms of order $\\alpha^0$ and $\\alpha^1$ cancel out. The terms proportional to $\\alpha^2 I$ also cancel.\n$$ D(\\alpha) = \\left[ \\frac{\\alpha^2}{2}(\\sigma_x\\sigma_y + \\sigma_y\\sigma_x) \\right] - \\left[ \\alpha^2\\sigma_x\\sigma_y \\right] + O(\\alpha^3) $$\n$$ D(\\alpha) = \\alpha^2 \\left( \\frac{1}{2}\\sigma_x\\sigma_y + \\frac{1}{2}\\sigma_y\\sigma_x - \\sigma_x\\sigma_y \\right) + O(\\alpha^3) $$\n$$ D(\\alpha) = \\alpha^2 \\left( \\frac{1}{2}\\sigma_y\\sigma_x - \\frac{1}{2}\\sigma_x\\sigma_y \\right) + O(\\alpha^3) $$\n$$ D(\\alpha) = \\frac{\\alpha^2}{2} (\\sigma_y\\sigma_x - \\sigma_x\\sigma_y) + O(\\alpha^3) $$\nBy definition, $D(\\alpha) = M\\alpha^2 + O(\\alpha^3)$, so we can identify the matrix $M$:\n$$ M = \\frac{1}{2} (\\sigma_y\\sigma_x - \\sigma_x\\sigma_y) $$\nUsing our previously computed matrices:\n$$ M = \\frac{1}{2} \\left( \\begin{pmatrix} -i & 0 \\\\ 0 & i \\end{pmatrix} - \\begin{pmatrix} i & 0 \\\\ 0 & -i \\end{pmatrix} \\right) = \\frac{1}{2} \\begin{pmatrix} -2i & 0 \\\\ 0 & 2i \\end{pmatrix} = \\begin{pmatrix} -i & 0 \\\\ 0 & i \\end{pmatrix} $$\nThis is the coefficient matrix of the leading non-zero term in the expansion.", "answer": "$$\\boxed{\\begin{pmatrix} -i & 0 \\\\ 0 & i \\end{pmatrix}}$$", "id": "1379891"}]}