{"hands_on_practices": [{"introduction": "The cornerstone of single-molecule kinetic analysis is extracting rate constants from an observed trajectory of state-to-state transitions. This exercise challenges you to derive the fundamental Maximum Likelihood Estimator (MLE) for a two-state system, a statistically robust method applicable across many scientific fields. By correctly incorporating both complete and right-censored data, you will develop a rigorous understanding of how to turn raw dwell times into meaningful kinetic parameters [@problem_id:2667815].", "problem": "A single molecule switches between two conformational states $A$ and $B$ and is monitored with perfect state detection at a temporal resolution much faster than any dwell time. Assume the dynamics are a continuous-time, time-homogeneous, memoryless two-state process: when in state $A$ the molecule leaves to $B$ with rate constant $k_{AB}$, and when in state $B$ it leaves to $A$ with rate constant $k_{BA}$. Under these conditions, dwell times in $A$ and $B$ are independently and identically distributed exponential random variables parameterized by $k_{AB}$ and $k_{BA}$, respectively. A single trajectory is recorded that begins immediately after a transition into $A$ and ends during a dwell in $A$ (that is, the final $A$ dwell is right-censored by the recording ending; all $B$ dwells are complete).\n\nYou are given the dwell-time histograms for $A$ and $B$, from which the unbinned dwell durations (in seconds) have been extracted as follows:\n- State $A$ dwell times (in order of occurrence): $0.41,\\,0.88,\\,0.35,\\,0.77,\\,0.62,\\,0.55,\\,0.49,\\,0.93$. The last $A$ dwell of duration $0.93$ is right-censored by the recording end.\n- State $B$ dwell times (in order of occurrence): $0.21,\\,0.44,\\,0.19,\\,0.55,\\,0.36,\\,0.27,\\,0.40$. All $B$ dwells are complete.\n\nStarting only from the core definitions of a continuous-time Markov process and the exponential waiting-time law implied by the memoryless property, construct the likelihood for the observed data that correctly accounts for complete and right-censored dwells. From this likelihood, derive the Maximum Likelihood Estimator (MLE) for $k_{AB}$ and $k_{BA}$, expressing each estimator solely in terms of the number of observed transitions of the corresponding type and the total time spent in the originating state.\n\nThen, using the provided dwell times, evaluate your estimators numerically. Express the final numerical values of the rate constants in $\\mathrm{s}^{-1}$, and round your answers to four significant figures. Report the two values in the order $\\hat{k}_{AB}$, $\\hat{k}_{BA}$.", "solution": "The fundamental base consists of the following principles:\n- A continuous-time, time-homogeneous Markov process with two states $A$ and $B$ is memoryless. Thus, the dwell time in state $A$ before leaving to $B$ is exponentially distributed with rate $k_{AB}$, and the dwell time in state $B$ before leaving to $A$ is exponentially distributed with rate $k_{BA}$.\n- For an exponential distribution with rate $k$, the probability density function for a complete observed dwell time $t$ is $k \\exp(-k t)$, whereas the contribution of a right-censored dwell of length $t$ (no observed exit) is the survival probability $\\exp(-k t)$.\n\nLet the observed data be a sequence of alternating $A$ and $B$ dwells. Denote by $N_{AB}$ the number of observed $A \\to B$ transitions (that is, the number of complete $A$ dwells), and by $N_{BA}$ the number of observed $B \\to A$ transitions (the number of complete $B$ dwells). Let $T_{A}$ be the total time spent in state $A$ during the observation window, including any right-censored final dwell in $A$, and $T_{B}$ the total time spent in state $B$, including any right-censored final dwell in $B$ (not present here).\n\nBecause dwells are conditionally independent given the rates and the Markov property, the likelihood factors over states and over dwells. For state $A$, the contribution to the likelihood is the product over complete $A$ dwells of $k_{AB} \\exp(-k_{AB} t_i)$ times the product over right-censored $A$ dwells of $\\exp(-k_{AB} t_j)$. Collecting terms yields\n$$\n\\mathcal{L}_{A}(k_{AB}) \\;=\\; k_{AB}^{N_{AB}} \\exp\\!\\big(-k_{AB} T_{A}\\big),\n$$\nwhere $T_{A}$ is the sum of all $A$ dwell durations, complete and censored. Analogously, for state $B$,\n$$\n\\mathcal{L}_{B}(k_{BA}) \\;=\\; k_{BA}^{N_{BA}} \\exp\\!\\big(-k_{BA} T_{B}\\big).\n$$\nAssuming independence between the $A$ and $B$ contributions given the rates, the full likelihood is\n$$\n\\mathcal{L}(k_{AB},k_{BA}) \\;=\\; \\mathcal{L}_{A}(k_{AB}) \\,\\mathcal{L}_{B}(k_{BA}) \\;=\\; k_{AB}^{N_{AB}} \\exp\\!\\big(-k_{AB} T_{A}\\big)\\; k_{BA}^{N_{BA}} \\exp\\!\\big(-k_{BA} T_{B}\\big).\n$$\n\nTaking the logarithm,\n$$\n\\ln \\mathcal{L}(k_{AB},k_{BA}) \\;=\\; N_{AB}\\,\\ln k_{AB} \\;-\\; k_{AB} T_{A} \\;+\\; N_{BA}\\,\\ln k_{BA} \\;-\\; k_{BA} T_{B}.\n$$\nMaximizing with respect to $k_{AB}$ and $k_{BA}$ separately by setting partial derivatives to zero,\n$$\n\\frac{\\partial}{\\partial k_{AB}} \\ln \\mathcal{L} \\;=\\; \\frac{N_{AB}}{k_{AB}} \\;-\\; T_{A} \\;=\\; 0 \\;\\;\\Rightarrow\\;\\; \\hat{k}_{AB} \\;=\\; \\frac{N_{AB}}{T_{A}},\n$$\n$$\n\\frac{\\partial}{\\partial k_{BA}} \\ln \\mathcal{L} \\;=\\; \\frac{N_{BA}}{k_{BA}} \\;-\\; T_{B} \\;=\\; 0 \\;\\;\\Rightarrow\\;\\; \\hat{k}_{BA} \\;=\\; \\frac{N_{BA}}{T_{B}}.\n$$\nSecond derivatives are negative, since\n$$\n\\frac{\\partial^{2}}{\\partial k_{AB}^{2}} \\ln \\mathcal{L} \\;=\\; -\\frac{N_{AB}}{k_{AB}^{2}} \\;\\; 0,\\quad \\frac{\\partial^{2}}{\\partial k_{BA}^{2}} \\ln \\mathcal{L} \\;=\\; -\\frac{N_{BA}}{k_{BA}^{2}} \\;\\; 0,\n$$\nconfirming a maximum.\n\nWe now evaluate $N_{AB}$, $N_{BA}$, $T_{A}$, and $T_{B}$ from the provided dwell times. The process begins immediately after an entry into $A$ and ends during a dwell in $A$, so all $B$ dwells are complete and the last $A$ dwell is right-censored. The $A$ dwell durations (in seconds) are $0.41,\\,0.88,\\,0.35,\\,0.77,\\,0.62,\\,0.55,\\,0.49,\\,0.93$, of which the final $0.93$ is censored but contributes to exposure time. The $B$ dwell durations (in seconds) are $0.21,\\,0.44,\\,0.19,\\,0.55,\\,0.36,\\,0.27,\\,0.40$, all complete.\n\n- The number of complete $A$ dwells equals the number of $A \\to B$ transitions: since there are $7$ complete $B$ dwells separated by entries from $A$, and the trajectory starts in $A$ and ends in $A$, we have $N_{AB} \\;=\\; 7$ and $N_{BA} \\;=\\; 7$.\n- The total exposure in $A$ is the sum of all $A$ dwells, including the censored final dwell:\n$$\nT_{A} \\;=\\; (0.41 + 0.88 + 0.35 + 0.77 + 0.62 + 0.55 + 0.49 + 0.93)\\,\\mathrm{s} \\;=\\; 5.00\\,\\mathrm{s}.\n$$\n- The total exposure in $B$ is\n$$\nT_{B} \\;=\\; (0.21 + 0.44 + 0.19 + 0.55 + 0.36 + 0.27 + 0.40)\\,\\mathrm{s} \\;=\\; 2.42\\,\\mathrm{s}.\n$$\n\nTherefore,\n$$\n\\hat{k}_{AB} \\;=\\; \\frac{N_{AB}}{T_{A}} \\;=\\; \\frac{7}{5.00}\\,\\mathrm{s}^{-1} \\;=\\; 1.4\\,\\mathrm{s}^{-1},\n$$\n$$\n\\hat{k}_{BA} \\;=\\; \\frac{N_{BA}}{T_{B}} \\;=\\; \\frac{7}{2.42}\\,\\mathrm{s}^{-1} \\;\\approx\\; 2.892561983\\,\\mathrm{s}^{-1}.\n$$\nRounded to four significant figures and expressed in $\\mathrm{s}^{-1}$, these are $1.400$ and $2.893$, reported in the order $\\hat{k}_{AB}$, $\\hat{k}_{BA}$.", "answer": "$$\\boxed{\\begin{pmatrix}1.400  2.893\\end{pmatrix}}$$", "id": "2667815"}, {"introduction": "Single-molecule experiments uniquely reveal that chemically identical molecules can exhibit different kinetic behaviors, a phenomenon known as static heterogeneity. This practice moves beyond the simple one-rate model to explore a mixture of subpopulations, each with its own characteristic rate constant. You will derive the time-dependent hazard rate for this mixture and discover how it serves as a powerful diagnostic signature for uncovering underlying static disorder from waiting-time distributions [@problem_id:2667784].", "problem": "A single molecule belongs, at time $t=0$, to one of two long-lived subpopulations that differ in their unimolecular transition (first-order) rate constants. With probability $\\alpha \\in (0,1)$ the molecule is in subpopulation $1$ with rate constant $k_1$ and with probability $(1-\\alpha)$ it is in subpopulation $2$ with rate constant $k_2$. Conditional on the subpopulation, the waiting time $T$ to the next observable transition is exponentially distributed, consistent with a first-order process and the memoryless property. Let $p(t)$ denote the overall waiting-time probability density for $T$ and $S(t)=\\Pr(Tt)$ the corresponding survival function. The hazard rate is defined as $h(t)=p(t)/S(t)$.\n\nStarting only from fundamental definitions (law of total probability for mixtures, the exponential waiting-time density for a first-order process, and the definition of the survival function and hazard rate), derive expressions for $p(t)$ and $S(t)$ for this static mixture and obtain a closed-form expression for the hazard rate $h(t)$ as a function of $t$, $k_1$, $k_2$, and $\\alpha$. Briefly explain, in terms of the time dependence of $h(t)$, why this setting reveals static heterogeneity when $k_1 \\neq k_2$.\n\nReport only the final closed-form expression for $h(t)$ as your boxed answer. Take $k_1$ and $k_2$ in $\\mathrm{s}^{-1}$, $t$ in $\\mathrm{s}$, and $\\alpha$ dimensionless. Do not include units in your final boxed answer. No numerical rounding is required.", "solution": "Let the event that the molecule belongs to subpopulation $i$ be denoted by $C_i$, for $i \\in \\{1, 2\\}$. We are given $\\Pr(C_1) = \\alpha$ and $\\Pr(C_2) = 1-\\alpha$.\n\nThe waiting time $T$ for a first-order process with rate constant $k$ follows an exponential distribution. The conditional probability density function (PDF) of the waiting time $T$, given that the molecule is in subpopulation $i$, is therefore:\n$$ p(t | C_1) = k_1 \\exp(-k_1 t) $$\n$$ p(t | C_2) = k_2 \\exp(-k_2 t) $$\nfor $t \\ge 0$.\n\nUsing the law of total probability, the overall waiting-time PDF, $p(t)$, is the weighted sum of the conditional PDFs:\n$$ p(t) = p(t | C_1) \\Pr(C_1) + p(t | C_2) \\Pr(C_2) $$\nSubstituting the known expressions, we obtain the PDF for this static mixture:\n$$ p(t) = \\alpha k_1 \\exp(-k_1 t) + (1-\\alpha) k_2 \\exp(-k_2 t) $$\nThis distribution is a biexponential mixture.\n\nNext, we derive the survival function $S(t) = \\Pr(Tt)$. This can be found either by integrating $p(t)$ from $t$ to $\\infty$, or more directly by applying the law of total probability to the conditional survival functions. The conditional survival function for an exponential distribution with rate $k$ is $S(t|k) = \\exp(-kt)$.\nTherefore:\n$$ S(t | C_1) = \\exp(-k_1 t) $$\n$$ S(t | C_2) = \\exp(-k_2 t) $$\nThe overall survival function is:\n$$ S(t) = \\Pr(Tt | C_1) \\Pr(C_1) + \\Pr(Tt | C_2) \\Pr(C_2) $$\n$$ S(t) = S(t | C_1) \\alpha + S(t | C_2) (1-\\alpha) $$\nSubstituting the expressions gives:\n$$ S(t) = \\alpha \\exp(-k_1 t) + (1-\\alpha) \\exp(-k_2 t) $$\n\nFinally, we derive the hazard rate, $h(t)$, using its definition $h(t) = p(t) / S(t)$. Substituting the expressions for $p(t)$ and $S(t)$:\n$$ h(t) = \\frac{\\alpha k_1 \\exp(-k_1 t) + (1-\\alpha) k_2 \\exp(-k_2 t)}{\\alpha \\exp(-k_1 t) + (1-\\alpha) \\exp(-k_2 t)} $$\nThis is the closed-form expression for the hazard rate.\n\nTo understand how this reveals static heterogeneity, we analyze the time dependence of $h(t)$ when $k_1 \\neq k_2$.\nFor a single, homogeneous population (e.g., $\\alpha=1$ or $k_1=k_2=k$), the hazard rate is constant: $h(t)=k$. This signifies a memoryless process where the instantaneous probability of an event is independent of time.\nFor the heterogeneous mixture, $h(t)$ is not constant. Let us examine its behavior at $t=0$ and as $t \\to \\infty$.\nAt $t=0$:\n$$ h(0) = \\frac{\\alpha k_1 \\exp(0) + (1-\\alpha) k_2 \\exp(0)}{\\alpha \\exp(0) + (1-\\alpha) \\exp(0)} = \\frac{\\alpha k_1 + (1-\\alpha) k_2}{\\alpha + 1 - \\alpha} = \\alpha k_1 + (1-\\alpha) k_2 $$\nThe initial hazard rate is the weighted average of the individual rate constants.\n\nAs $t \\to \\infty$:\nAssume, without loss of generality, that $k_1  k_2$. The term $\\exp(-k_1 t)$ will decay to zero much faster than $\\exp(-k_2 t)$. To see the limit, we can divide the numerator and denominator by $\\exp(-k_2 t)$:\n$$ h(t) = \\frac{\\alpha k_1 \\exp(-(k_1 - k_2)t) + (1-\\alpha) k_2}{\\alpha \\exp(-(k_1 - k_2)t) + (1-\\alpha)} $$\nSince $k_1 - k_2  0$, the term $\\exp(-(k_1 - k_2)t)$ approaches $0$ as $t \\to \\infty$.\n$$ \\lim_{t\\to\\infty} h(t) = \\frac{0 + (1-\\alpha) k_2}{0 + (1-\\alpha)} = k_2 $$\nThe hazard rate decreases over time from the average rate $\\alpha k_1 + (1-\\alpha) k_2$ to the rate constant of the slower subpopulation, $k_2 = \\min(k_1, k_2)$.\n\nThis time dependence is the key signature of static heterogeneity. At early times, transitions from both fast ($k_1$) and slow ($k_2$) subpopulations contribute to the observed rate. As time progresses, the faster subpopulation is preferentially depleted because its members undergo transitions more quickly. At long times, the remaining population of molecules consists almost entirely of members of the slower subpopulation. The observed rate thus decreases and asymptotically approaches the slowest rate in the mixture. This phenomenon, which would not be present for a single homogeneous population, directly reveals the underlying static distribution of rate constants.", "answer": "$$ \\boxed{ \\frac{\\alpha k_1 \\exp(-k_1 t) + (1-\\alpha) k_2 \\exp(-k_2 t)}{\\alpha \\exp(-k_1 t) + (1-\\alpha) \\exp(-k_2 t)} } $$", "id": "2667784"}, {"introduction": "Translating raw photon counts from a single-molecule FRET experiment into a precise biophysical parameter requires a careful physical model and statistical treatment. This problem guides you through the process of correcting for experimental non-idealities, such as spectral leakage and direct acceptor excitation, to derive an accurate estimator for the FRET efficiency. Furthermore, you will apply the delta method to quantify the shot-noise limited uncertainty in your estimate, a crucial step in any quantitative measurement [@problem_id:2667864].", "problem": "A single fluorescent molecule is observed under donor excitation using FÃ¶rster Resonance Energy Transfer (FRET). Photons are detected in two spectral channels: donor channel and acceptor channel. Let the observed donor-channel and acceptor-channel photon counts over a fixed acquisition window be $N_D$ and $N_A$, respectively. Assume the following physically motivated model.\n\n1. Photophysics and detection:\n- The FRET transfer efficiency is $E \\in (0,1)$, which is the probability that an excitation of the donor results in nonradiative energy transfer to the acceptor.\n- The detected donor-channel mean count is $\\mu_D = \\eta_D \\phi_D (1-E) S$, where $\\eta_D$ is the donor-channel detection efficiency, $\\phi_D$ is the donor quantum yield, and $S$ is the mean number of donor excitations contributing to detected photons within the window.\n- The detected acceptor-channel mean count has three contributions: FRET-sensitized emission, donor spectral leakage into the acceptor channel quantified by a leakage coefficient $L \\ge 0$, and direct acceptor excitation during donor excitation with a known mean $\\Delta \\ge 0$. Thus $\\mu_A = \\eta_A \\phi_A E S + L \\mu_D + \\Delta$, where $\\eta_A$ is the acceptor-channel detection efficiency and $\\phi_A$ is the acceptor quantum yield.\n- Define the standard correction factor $\\gamma = \\frac{\\eta_A \\phi_A}{\\eta_D \\phi_D}$, which converts donor-channel counts to the acceptor detection scale.\n\n2. Counting statistics:\n- Photon detection events are modeled as realizations of independent Poisson processes (by Poisson superposition and thinning), so $N_D \\sim \\mathrm{Poisson}(\\mu_D)$, $N_A \\sim \\mathrm{Poisson}(\\mu_A)$, and $N_D$ and $N_A$ are independent.\n\nBackground has been separately measured and subtracted from $N_D$ and $N_A$, and the direct-excitation offset $\\Delta$ is known from an acceptor-only control.\n\nStarting only from these definitions and the Poisson counting model, derive:\n- A closed-form estimator $\\widehat{E}$ for the FRET efficiency $E$ in terms of $N_D$, $N_A$, $L$, $\\gamma$, and $\\Delta$.\n- The leading-order shot-noise variance $\\mathrm{Var}(\\widehat{E})$ under the Poisson model, expressed as a closed-form function of $N_D$, $N_A$, $L$, $\\gamma$, and $\\Delta$ by applying the multivariate delta method about the mean and then using the standard plug-in replacement of unknown means by the observed counts.\n\nExpress your final answer as two closed-form analytic expressions in the order $\\widehat{E}$ and $\\mathrm{Var}(\\widehat{E})$. No units are required. Do not round the expressions. The final answer must be a single row matrix containing these two expressions.", "solution": "**Derivation of the Estimator $\\widehat{E}$**\n\nThe objective is to express the FRET efficiency $E$ as a function of the mean counts $\\mu_D$ and $\\mu_A$ and the known parameters $L$, $\\gamma$, and $\\Delta$. The estimator $\\widehat{E}$ is then found by applying the method of moments, which in this simple case amounts to replacing the population means with their sample observations.\n\nThe given relations for the mean counts are:\n$$\n\\mu_D = \\eta_D \\phi_D (1-E) S\n$$\n$$\n\\mu_A = \\eta_A \\phi_A E S + L \\mu_D + \\Delta\n$$\nThe instrumental correction factor is defined as $\\gamma = \\frac{\\eta_A \\phi_A}{\\eta_D \\phi_D}$. We must eliminate the unobserved scaling factor $S$. From the expression for $\\mu_D$, we can write:\n$$\n\\eta_D \\phi_D S = \\frac{\\mu_D}{1-E}\n$$\nNow, we rewrite the term $\\eta_A \\phi_A E S$ in the expression for $\\mu_A$ using the definition of $\\gamma$:\n$$\n\\eta_A \\phi_A E S = (\\gamma \\eta_D \\phi_D) E S = \\gamma E (\\eta_D \\phi_D S)\n$$\nSubstituting the expression for $\\eta_D \\phi_D S$ yields:\n$$\n\\eta_A \\phi_A E S = \\gamma E \\left(\\frac{\\mu_D}{1-E}\\right) = \\frac{\\gamma E \\mu_D}{1-E}\n$$\nWe substitute this back into the equation for $\\mu_A$:\n$$\n\\mu_A = \\frac{\\gamma E \\mu_D}{1-E} + L \\mu_D + \\Delta\n$$\nThe next step is to solve this equation for $E$. First, isolate the term containing $E$:\n$$\n\\mu_A - L \\mu_D - \\Delta = \\frac{\\gamma E \\mu_D}{1-E}\n$$\nMultiplying both sides by $(1-E)$ gives:\n$$\n(\\mu_A - L \\mu_D - \\Delta)(1-E) = \\gamma E \\mu_D\n$$\nExpanding the left side and rearranging to group terms with $E$:\n$$\n\\mu_A - L \\mu_D - \\Delta = E(\\mu_A - L \\mu_D - \\Delta) + \\gamma E \\mu_D\n$$\n$$\n\\mu_A - L \\mu_D - \\Delta = E (\\mu_A - L \\mu_D - \\Delta + \\gamma \\mu_D)\n$$\nSimplifying the coefficient of $E$:\n$$\n\\mu_A - L \\mu_D - \\Delta = E (\\mu_A + (\\gamma - L) \\mu_D - \\Delta)\n$$\nFinally, solving for $E$ yields the exact relationship:\n$$\nE = \\frac{\\mu_A - L \\mu_D - \\Delta}{\\mu_A + (\\gamma - L) \\mu_D - \\Delta}\n$$\nThe estimator $\\widehat{E}$ is obtained by replacing the mean counts $\\mu_D$ and $\\mu_A$ with the observed counts $N_D$ and $N_A$, respectively:\n$$\n\\widehat{E} = \\frac{N_A - L N_D - \\Delta}{N_A + (\\gamma - L) N_D - \\Delta}\n$$\n\n**Derivation of the Variance $\\mathrm{Var}(\\widehat{E})$**\n\nThe variance of the estimator $\\widehat{E}$ is derived using the multivariate delta method. The estimator $\\widehat{E}$ is a function of the two independent random variables $N_D$ and $N_A$. Let this function be $f(N_D, N_A)$. The leading-order approximation for the variance is:\n$$\n\\mathrm{Var}(\\widehat{E}) \\approx \\left(\\frac{\\partial f}{\\partial N_D}\\right)^2 \\mathrm{Var}(N_D) + \\left(\\frac{\\partial f}{\\partial N_A}\\right)^2 \\mathrm{Var}(N_A) + 2 \\frac{\\partial f}{\\partial N_D}\\frac{\\partial f}{\\partial N_A} \\mathrm{Cov}(N_D, N_A)\n$$\nThe derivatives are evaluated at the mean values $(\\mu_D, \\mu_A)$. From the problem statement, $N_D$ and $N_A$ are independent Poisson variables, so $\\mathrm{Var}(N_D) = \\mu_D$, $\\mathrm{Var}(N_A) = \\mu_A$, and $\\mathrm{Cov}(N_D, N_A) = 0$. The variance expression simplifies to:\n$$\n\\mathrm{Var}(\\widehat{E}) \\approx \\left(\\frac{\\partial f}{\\partial \\mu_D}\\right)^2 \\mu_D + \\left(\\frac{\\partial f}{\\partial \\mu_A}\\right)^2 \\mu_A\n$$\nWe compute the partial derivatives of $f(x, y) = \\frac{y - Lx - \\Delta}{y + (\\gamma - L)x - \\Delta}$. Let $V = y + (\\gamma - L)x - \\Delta$.\n\nThe partial derivative with respect to $x$ (for $N_D$):\n$$\n\\frac{\\partial f}{\\partial x} = \\frac{(-L)(y + (\\gamma - L)x - \\Delta) - (y - Lx - \\Delta)(\\gamma - L)}{V^2} = \\frac{-\\gamma(y-\\Delta)}{V^2}\n$$\nSo, $\\frac{\\partial f}{\\partial N_D} = \\frac{-\\gamma(N_A - \\Delta)}{(N_A + (\\gamma - L)N_D - \\Delta)^2}$.\n\nThe partial derivative with respect to $y$ (for $N_A$):\n$$\n\\frac{\\partial f}{\\partial y} = \\frac{(1)(y + (\\gamma - L)x - \\Delta) - (y - Lx - \\Delta)(1)}{V^2} = \\frac{\\gamma x}{V^2}\n$$\nSo, $\\frac{\\partial f}{\\partial N_A} = \\frac{\\gamma N_D}{(N_A + (\\gamma - L)N_D - \\Delta)^2}$.\n\nSubstituting these derivatives into the variance formula, evaluated at the means:\n$$\n\\mathrm{Var}(\\widehat{E}) \\approx \\left( \\frac{-\\gamma(\\mu_A - \\Delta)}{(\\mu_A + (\\gamma - L)\\mu_D - \\Delta)^2} \\right)^2 \\mu_D + \\left( \\frac{\\gamma \\mu_D}{(\\mu_A + (\\gamma - L)\\mu_D - \\Delta)^2} \\right)^2 \\mu_A\n$$\n$$\n\\mathrm{Var}(\\widehat{E}) \\approx \\frac{\\gamma^2 (\\mu_A - \\Delta)^2 \\mu_D}{(\\mu_A + (\\gamma - L)\\mu_D - \\Delta)^4} + \\frac{\\gamma^2 \\mu_D^2 \\mu_A}{(\\mu_A + (\\gamma - L)\\mu_D - \\Delta)^4}\n$$\n$$\n\\mathrm{Var}(\\widehat{E}) \\approx \\frac{\\gamma^2 \\left( (\\mu_A - \\Delta)^2 \\mu_D + \\mu_D^2 \\mu_A \\right)}{(\\mu_A + (\\gamma - L)\\mu_D - \\Delta)^4}\n$$\nFinally, as requested, we employ the plug-in principle, replacing the unknown means $\\mu_D$ and $\\mu_A$ with the observed counts $N_D$ and $N_A$ to obtain the final expression for the variance estimate:\n$$\n\\mathrm{Var}(\\widehat{E}) \\approx \\frac{\\gamma^2 \\left( (N_A - \\Delta)^2 N_D + N_D^2 N_A \\right)}{\\left( N_A + (\\gamma - L)N_D - \\Delta \\right)^4}\n$$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{N_A - L N_D - \\Delta}{N_A + (\\gamma - L) N_D - \\Delta}  \\frac{\\gamma^{2} \\left( (N_A - \\Delta)^{2} N_D + N_D^{2} N_A \\right)}{\\left( N_A + (\\gamma - L) N_D - \\Delta \\right)^{4}}\n\\end{pmatrix}\n}\n$$", "id": "2667864"}]}