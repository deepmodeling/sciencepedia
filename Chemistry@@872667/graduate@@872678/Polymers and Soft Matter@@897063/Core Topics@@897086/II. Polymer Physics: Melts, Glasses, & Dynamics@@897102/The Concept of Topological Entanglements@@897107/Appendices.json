{"hands_on_practices": [{"introduction": "To build a robust understanding of topological entanglements, we begin with the simplest possible case: the linking of two closed curves. This exercise grounds the abstract concept of entanglement in the rigorous mathematics of vector calculus. You will derive the famous Gauss linking integral, a powerful tool that provides an integer measure of how two loops are intertwined, and discover its topological invariance—the property that makes it so fundamental to describing entanglements [@problem_id:2930867]. This practice solidifies the connection between physical laws, such as those from electromagnetism, and the purely geometric and topological properties of knotted and linked polymers.", "problem": "A polymer physicist models two disjoint circular ring polymers as smooth closed curves embedded in three-dimensional Euclidean space. The rings form a Hopf link, which is the simplest nontrivial topological entanglement. Consider two smooth closed curves $C_1$ and $C_2$ representing the centerlines of the rings. One may define an integer that counts how many times $C_1$ is linked with $C_2$ via a double line integral that is invariant under smooth deformations that avoid crossings.\n\nStarting from magnetostatics and vector calculus, and without assuming any target formulas in advance, do the following:\n\n1. Using the Biot–Savart law for the magnetic field produced by a steady current $I$ flowing along $C_1$, together with Stokes’ theorem and the identification of the algebraic number of times $C_1$ pierces an oriented surface spanning $C_2$, derive an expression for the linking number as a double line integral over $C_1$ and $C_2$. Your derivation must begin from well-tested formulas, namely the Biot–Savart law and Stokes’ theorem, and show why the resulting integral is an integer topological invariant under smooth deformations that keep the curves disjoint.\n\n2. Evaluate that double line integral for a Hopf link realized by two circles of common radius $R$ in perpendicular planes with parameters $R>a>0$, given by\n   - $C_1$: $\\mathbf{r}_1(t) = \\big(a + R\\cos t,\\; R\\sin t,\\; 0\\big)$ for $t \\in [0,2\\pi)$,\n   - $C_2$: $\\mathbf{r}_2(s) = \\big(0,\\; a + R\\cos s,\\; -R\\sin s\\big)$ for $s \\in [0,2\\pi)$,\n   with orientations corresponding to increasing $t$ and $s$. Justify your evaluation by first principles: either compute the double integral directly or use its equivalence to the algebraic intersection number of $C_2$ with an oriented spanning surface of $C_1$ (together with smooth deformation invariance) to reduce the computation to counting signed intersections. State the final value of the linking number $Lk$ as a single exact integer.\n\nNo rounding is required. The final answer must be given as a bare integer with no units.", "solution": "The problem presented is a valid exercise in mathematical physics and topology. It is well-posed, scientifically grounded, and contains all necessary information for a unique solution. We shall proceed with the derivation and calculation as requested.\n\nThe problem is divided into two parts. First, the derivation of the Gauss linking integral from the principles of magnetostatics. Second, the application of this result, or its topological equivalent, to compute the linking number for a specific configuration of a Hopf link.\n\nPart 1: Derivation of the Linking Number Integral\n\nThe linking number $Lk(C_1, C_2)$ of two disjoint, oriented, closed curves $C_1$ and $C_2$ in three-dimensional Euclidean space $\\mathbb{R}^3$ is defined topologically as the net number of times one curve pierces an oriented surface bounded by the other. To derive the integral expression, we employ an analogy from magnetostatics.\n\nLet the curve $C_2$ carry a steady electrical current $I_2$. According to Ampere's circuital law, the line integral of the resulting magnetic field $\\mathbf{B}_2$ around a closed loop $C_1$ is proportional to the total current that passes through any surface $S_1$ bounded by $C_1$. The total current piercing $S_1$ is the current $I_2$ multiplied by the integer number of times the curve $C_2$ passes through the surface $S_1$. This integer is precisely the linking number $Lk(C_2, C_1)$, which is symmetric, i.e., $Lk(C_2, C_1) = Lk(C_1, C_2)$.\nMathematically, Ampere's law states:\n$$ \\oint_{C_1} \\mathbf{B}_2 \\cdot d\\mathbf{l}_1 = \\mu_0 I_{\\text{enclosed}} = \\mu_0 I_2 Lk(C_1, C_2) $$\nwhere $d\\mathbf{l}_1$ is the line element along $C_1$ and $\\mu_0$ is the permeability of free space. To simplify the expression and focus on the geometrical aspect, we may work with a system of units where $\\mu_0=1$ and consider a unit current $I_2=1$. This gives:\n$$ Lk(C_1, C_2) = \\oint_{C_1} \\mathbf{B}_2 \\cdot d\\mathbf{l}_1 $$\nThis relation demonstrates that the linking number must be an integer, as it arises from counting discrete piercing events.\n\nNow, we introduce the Biot-Savart law to express the magnetic field $\\mathbf{B}_2$ generated by the current in loop $C_2$. The field at a position $\\mathbf{r}_1$ on curve $C_1$ due to a line element $d\\mathbf{l}_2$ at position $\\mathbf{r}_2$ on curve $C_2$ is:\n$$ d\\mathbf{B}_2(\\mathbf{r}_1) = \\frac{\\mu_0 I_2}{4\\pi} \\frac{d\\mathbf{l}_2 \\times (\\mathbf{r}_1 - \\mathbf{r}_2)}{|\\mathbf{r}_1 - \\mathbf{r}_2|^3} $$\nIntegrating this expression over the entire loop $C_2$ gives the total magnetic field at $\\mathbf{r}_1$:\n$$ \\mathbf{B}_2(\\mathbf{r}_1) = \\frac{\\mu_0 I_2}{4\\pi} \\oint_{C_2} \\frac{d\\mathbf{l}_2 \\times (\\mathbf{r}_1 - \\mathbf{r}_2)}{|\\mathbf{r}_1 - \\mathbf{r}_2|^3} $$\nSubstituting this expression for $\\mathbf{B}_2$ into our equation for the linking number, we obtain a double line integral:\n$$ Lk(C_1, C_2) = \\frac{1}{\\mu_0 I_2} \\oint_{C_1} \\left( \\frac{\\mu_0 I_2}{4\\pi} \\oint_{C_2} \\frac{d\\mathbf{l}_2 \\times (\\mathbf{r}_1 - \\mathbf{r}_2)}{|\\mathbf{r}_1 - \\mathbf{r}_2|^3} \\right) \\cdot d\\mathbf{l}_1 $$\nThe constants $\\mu_0$ and $I_2$ cancel, leaving a purely geometric expression:\n$$ Lk(C_1, C_2) = \\frac{1}{4\\pi} \\oint_{C_1} \\oint_{C_2} \\frac{(d\\mathbf{l}_2 \\times (\\mathbf{r}_1 - \\mathbf{r}_2)) \\cdot d\\mathbf{l}_1}{|\\mathbf{r}_1 - \\mathbf{r}_2|^3} $$\nUsing the property of the scalar triple product, $(A \\times B) \\cdot C = (C \\times A) \\cdot B = A \\cdot (B \\times C)$, we can rearrange the integrand:\n$$ (d\\mathbf{l}_2 \\times (\\mathbf{r}_1 - \\mathbf{r}_2)) \\cdot d\\mathbf{l}_1 = (\\mathbf{r}_1 - \\mathbf{r}_2) \\cdot (d\\mathbf{l}_1 \\times d\\mathbf{l}_2) $$\nThis yields the final form of the Gauss linking integral:\n$$ Lk(C_1, C_2) = \\frac{1}{4\\pi} \\oint_{C_1} \\oint_{C_2} \\frac{(\\mathbf{r}_1 - \\mathbf{r}_2) \\cdot (d\\mathbf{l}_1 \\times d\\mathbf{l}_2)}{|\\mathbf{r}_1 - \\mathbf{r}_2|^3} $$\nThis integral is an integer because it was derived from Ampere's law which counts discrete current penetrations. It is a topological invariant because any smooth deformation (isotopy) of the curves $C_1$ or $C_2$ that avoids self-intersection or intersection between the curves will vary the value of the integral continuously. As the integral must always evaluate to an integer, it cannot jump between values and must therefore remain constant throughout the deformation. The problem statement itself mentions Stokes' theorem; its role is implicit in Ampere's law, which can be derived from the differential form $\\nabla \\times \\mathbf{B} = \\mu_0 \\mathbf{J}$ by integrating over a surface $S_1$ and applying Stokes' theorem.\n\nPart 2: Evaluation for a Specific Hopf Link\n\nWe are asked to evaluate this integral for the curves:\n- $C_1$: $\\mathbf{r}_1(t) = (a + R\\cos t, R\\sin t, 0)$ for $t \\in [0, 2\\pi)$\n- $C_2$: $\\mathbf{r}_2(s) = (0, a + R\\cos s, -R\\sin s)$ for $s \\in [0, 2\\pi)$\n\nDirect computation of the double integral is laborious. A more efficient method, as suggested by the problem, is to use the topological definition of the linking number: $Lk(C_1, C_2)$ is the algebraic sum of the number of times $C_2$ intersects a surface $S_1$ whose oriented boundary is $C_1$.\n\nThe curve $C_1$ is a circle of radius $R$ in the $z=0$ plane, centered at $(a, 0, 0)$. The simplest choice for the spanning surface $S_1$ is the flat disk enclosed by this circle:\n$$ S_1 = \\{ (x, y, z) \\in \\mathbb{R}^3 \\mid (x-a)^2 + y^2 \\leq R^2, z=0 \\} $$\nThe orientation of $C_1$ corresponds to increasing $t$. At $t=0$, $\\mathbf{r}_1(0)=(a+R,0,0)$; at $t=\\pi/2$, $\\mathbf{r}_1(\\pi/2)=(a,R,0)$. This describes a counter-clockwise traversal in the $xy$-plane. By the right-hand rule, the normal vector $\\mathbf{n}$ to the surface $S_1$ points in the positive $z$-direction, so $\\mathbf{n} = (0, 0, 1)$.\n\nNext, we find the intersection points of the curve $C_2$ with the plane containing $S_1$, which is the plane $z=0$. For a point $\\mathbf{r}_2(s)$ on $C_2$, the $z$-coordinate is $-R\\sin s$. Setting this to zero:\n$$ -R\\sin s = 0 $$\nSince $R > 0$, this implies $\\sin s = 0$. In the interval $s \\in [0, 2\\pi)$, the solutions are $s=0$ and $s=\\pi$.\n\nWe must test if these two potential intersection points lie within the boundary of the disk $S_1$.\nCase 1: $s=0$.\nThe point on $C_2$ is $\\mathbf{r}_2(0) = (0, a + R\\cos 0, -R\\sin 0) = (0, a+R, 0)$.\nWe check if this point satisfies the inequality $(x-a)^2 + y^2 \\leq R^2$:\n$$ (0-a)^2 + (a+R)^2 = a^2 + (a^2 + 2aR + R^2) = 2a^2 + 2aR + R^2 $$\nSince we are given $R > a > 0$, the term $2a^2 + 2aR$ is strictly positive. Thus, $2a^2 + 2aR + R^2 > R^2$. The point lies outside the disk $S_1$. No intersection here.\n\nCase 2: $s=\\pi$.\nThe point on $C_2$ is $\\mathbf{r}_2(\\pi) = (0, a + R\\cos\\pi, -R\\sin\\pi) = (0, a-R, 0)$.\nWe check the inequality:\n$$ (0-a)^2 + (a-R)^2 = a^2 + (a^2 - 2aR + R^2) = 2a^2 - 2aR + R^2 $$\nWe test if $2a^2 - 2aR + R^2 \\leq R^2$, which simplifies to $2a^2 - 2aR \\leq 0$, or $2a(a-R) \\leq 0$.\nSince $a>0$ and $R>a$, the term $(a-R)$ is negative. Therefore, $2a(a-R)$ is negative, and the inequality is satisfied. This point lies within the disk $S_1$.\n\nWe have found exactly one intersection point. To find the linking number, we must determine the sign of this intersection. The sign is given by the sign of the dot product of the tangent vector to $C_2$ at the intersection point and the normal vector to $S_1$.\nThe tangent vector to $C_2$ is $\\mathbf{v}_2(s) = \\frac{d\\mathbf{r}_2}{ds} = (0, -R\\sin s, -R\\cos s)$.\nAt the intersection point $s=\\pi$:\n$$ \\mathbf{v}_2(\\pi) = (0, -R\\sin\\pi, -R\\cos\\pi) = (0, 0, -R(-1)) = (0, 0, R) $$\nThe normal vector to $S_1$ is $\\mathbf{n} = (0, 0, 1)$.\nThe dot product is:\n$$ \\mathbf{v}_2(\\pi) \\cdot \\mathbf{n} = (0, 0, R) \\cdot (0, 0, 1) = R $$\nSince $R>0$, the dot product is positive. The sign of the intersection is $+1$.\n\nThe linking number is the sum of all signed intersections. As there is only one intersection with sign $+1$, the linking number is $1$.\n$$ Lk(C_1, C_2) = +1 $$\nThis integer value is independent of the specific values of $R$ and $a$, as long as the condition $R>a>0$ holds, confirming it as a topological property.", "answer": "$$\\boxed{1}$$", "id": "2930867"}, {"introduction": "From the idealized picture of two rings, we now move to the complex reality of a long polymer chain entangled with its environment. This problem bridges the gap by asking you to implement a computational algorithm to estimate the entanglement length, $N_e$, a key parameter in the tube model of polymer dynamics. By modeling topological constraints as fixed \"slip-links,\" you will calculate the contour length of the chain's \"primitive path\" and relate it to the chain's overall span [@problem_id:2930833]. This hands-on coding exercise provides direct experience with the practical methods used in simulations to quantify entanglement, including the crucial detail of handling periodic boundary conditions.", "problem": "You are tasked with constructing a complete, runnable program that estimates the entanglement length $N_e$ from a single-frame molecular dynamics configuration of bead-spring polymer chains under periodic boundary conditions. The goal is to compute $N_e$ using a primitive-path-based estimate that prevents chain crossings and minimizes end effects. Your program must implement the following physically grounded workflow based on fundamental principles and standard conventions:\n\n1. Definitions and modeling assumptions:\n   - A polymer chain is a sequence of $N$ beads with positions $\\{\\mathbf{r}_i\\}_{i=0}^{N-1}$ in a cubic periodic box of edge length $L$. Distances must be computed using the minimum-image convention for periodic boundary conditions.\n   - A set of pinned monomer indices (slip-links) $\\mathcal{P} \\subset \\{0,\\dots,N-1\\}$ models topological constraints that prevent chain crossings. These pins are treated as fixed topological constraints that the primitive path must pass through.\n   - To minimize end effects, you will ignore $s$ beads at each chain end. Define the interior indices $i_0 = s$ and $i_1 = N-1-s$ with $i_0 \\le i_1$. The effective pin set is\n     $$\\mathcal{P}_{\\mathrm{eff}} = \\big(\\mathcal{P} \\cup \\{i_0, i_1\\}\\big) \\cap \\{i_0,i_0+1,\\dots,i_1\\}.$$\n     Sort $\\mathcal{P}_{\\mathrm{eff}}$ in increasing order and remove duplicates.\n   - Under the slip-link representation and contour-length minimization with fixed bead order and pins, the primitive path within the interior is piecewise straight between successive pins. The primitive-path contour length in the interior is\n     $$L_{\\mathrm{pp}} = \\sum_{j=0}^{K-2} \\left\\| \\mathbf{r}_{p_{j+1}} - \\mathbf{r}_{p_j} \\right\\|_{\\mathrm{mic}},$$\n     where $\\{p_0,\\dots,p_{K-1}\\} = \\mathrm{sorted}(\\mathcal{P}_{\\mathrm{eff}})$ and $\\|\\cdot\\|_{\\mathrm{mic}}$ denotes the norm of a vector reduced by the minimum-image convention in the periodic box.\n   - The interior end-to-end vector is $\\mathbf{R}_{\\mathrm{int}} = \\mathbf{r}_{i_1} - \\mathbf{r}_{i_0}$ reduced by the minimum-image convention, and $R_{\\mathrm{int}}^2 = \\|\\mathbf{R}_{\\mathrm{int}}\\|^2$.\n   - The number of interior bonds considered is\n     $$N_{\\mathrm{eff}} = (N-1) - 2s.$$\n   - The topological entanglement count per chain is approximated by the tube-model relation $Z = L_{\\mathrm{pp}}^2 / R_{\\mathrm{int}}^2$, yielding the entanglement length\n     $$N_e = \\frac{N_{\\mathrm{eff}}}{Z} = N_{\\mathrm{eff}} \\frac{R_{\\mathrm{int}}^2}{L_{\\mathrm{pp}}^2}.$$\n\n2. Computational requirements:\n   - Implement the minimum-image convention for a cubic box of size $L$ as follows. For a displacement vector $\\Delta \\mathbf{r} = \\mathbf{r}_2 - \\mathbf{r}_1$,\n     $$\\Delta \\mathbf{r}_{\\mathrm{mic}} = \\Delta \\mathbf{r} - L \\cdot \\mathrm{round}\\left(\\frac{\\Delta \\mathbf{r}}{L}\\right),$$\n     where the division and rounding are applied component-wise.\n   - For each test case, compute $N_e$ using the formula above, with all distances in nanometers. The final $N_e$ is dimensionless.\n\n3. Test suite:\n   Your program must compute $N_e$ for each of the following three test cases. Each test uses a single chain ($M=1$). All coordinates are in nanometers, and the cubic periodic box has edge length $L$ in nanometers.\n\n   - Test case $1$ (happy path, straight chain, no interior slip-links):\n     - $L = 10$.\n     - $N = 6$ beads with coordinates\n       $$\\big[(1,5,5),(2,5,5),(3,5,5),(4,5,5),(5,5,5),(6,5,5)\\big].$$\n     - Pinned indices $\\mathcal{P} = \\varnothing$.\n     - End trimming $s = 1$.\n     - Interpretation: Effective pins are $i_0 = 1$ and $i_1 = 4$, so the primitive path is the straight segment between beads $1$ and $4$.\n\n   - Test case $2$ (interior slip-link causing a detour; non-collinear pins):\n     - $L = 20$.\n     - $N = 10$ beads with coordinates\n       $$\\big[(1,1,5),(3,2,5),(5,5,5),(6,6,5),(7,7,5),(8,9,5),(10,7,5),(12,5,5),(15,4,5),(18,3,5)\\big].$$\n     - Pinned indices $\\mathcal{P} = \\{5\\}$.\n     - End trimming $s = 2$.\n     - Interpretation: Effective pins are $i_0 = 2$, index $5$, and $i_1 = 7$, giving a piecewise straight primitive path passing through indices $2 \\to 5 \\to 7$.\n\n   - Test case $3$ (periodic boundary wrap; non-collinear pins across the boundary):\n     - $L = 10$.\n     - $N = 8$ beads with coordinates\n       $$\\big[(0.5,1,1),(9,1,1),(9.5,2,1),(0,5,1),(1.5,3,1),(1.8,2,1),(2,1,1),(2.5,0.5,1)\\big].$$\n     - Pinned indices $\\mathcal{P} = \\{3\\}$.\n     - End trimming $s = 1$.\n     - Interpretation: Effective pins are $i_0 = 1$, index $3$, and $i_1 = 6$, forcing a piecewise straight path that crosses the periodic boundary using the minimum-image convention.\n\n4. Output specification:\n   - For each test case, compute $N_e$ as a float and round to six decimal places.\n   - Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as test case $1$, test case $2$, test case $3$. For example, an output of the form\n     $$[x_1,x_2,x_3],$$\n     where each $x_j$ is the six-decimal-place rounded value of $N_e$ for test case $j$.\n   - $N_e$ is dimensionless; do not include any units or additional text.\n\nImplement the algorithm exactly as described above. Use only the libraries and versions specified. No input should be read from standard input; all data must be hard-coded into your program.", "solution": "The problem statement is subjected to validation.\n\nGivens are extracted verbatim.\n1. A polymer chain is a sequence of $N$ beads with positions $\\{\\mathbf{r}_i\\}_{i=0}^{N-1}$ in a cubic periodic box of edge length $L$.\n2. Distances use the minimum-image convention (MIC).\n3. A set of pinned monomer indices is $\\mathcal{P} \\subset \\{0,\\dots,N-1\\}$.\n4. To minimize end effects, $s$ beads at each chain end are ignored. Interior indices are $i_0 = s$ and $i_1 = N-1-s$.\n5. The effective pin set is $\\mathcal{P}_{\\mathrm{eff}} = \\big(\\mathcal{P} \\cup \\{i_0, i_1\\}\\big) \\cap \\{i_0,i_0+1,\\dots,i_1\\}$, sorted in increasing order with duplicates removed.\n6. The primitive-path contour length is $L_{\\mathrm{pp}} = \\sum_{j=0}^{K-2} \\left\\| \\mathbf{r}_{p_{j+1}} - \\mathbf{r}_{p_j} \\right\\|_{\\mathrm{mic}}$, where $\\{p_0,\\dots,p_{K-1}\\} = \\mathrm{sorted}(\\mathcal{P}_{\\mathrm{eff}})$.\n7. The interior end-to-end vector is $\\mathbf{R}_{\\mathrm{int}} = \\mathbf{r}_{i_1} - \\mathbf{r}_{i_0}$ reduced by MIC, and $R_{\\mathrm{int}}^2 = \\|\\mathbf{R}_{\\mathrm{int}}\\|^2$.\n8. The number of interior bonds is $N_{\\mathrm{eff}} = (N-1) - 2s$.\n9. The entanglement length is $N_e = N_{\\mathrm{eff}} \\frac{R_{\\mathrm{int}}^2}{L_{\\mathrm{pp}}^2}$.\n10. The MIC formula for a displacement vector $\\Delta \\mathbf{r}$ is $\\Delta \\mathbf{r}_{\\mathrm{mic}} = \\Delta \\mathbf{r} - L \\cdot \\mathrm{round}\\left(\\frac{\\Delta \\mathbf{r}}{L}\\right)$.\n11. Three test cases are provided with specific values for $L$, $N$, bead coordinates, $\\mathcal{P}$, and $s$.\n12. The final output must be a single line with $N_e$ values for each test case, rounded to six decimal places, in the format $[x_1,x_2,x_3]$.\n\nThe problem is evaluated against validation criteria. The verdict is that the problem is **valid**. It is scientifically grounded, employing standard, albeit simplified, models from polymer physics such as the primitive path analysis and the tube model for estimating topological entanglements. It is well-posed, providing all necessary data, definitions, and explicit formulae to compute a unique result for each test case. The language is objective and precise. The problem is a self-contained, algorithmically solvable task that is neither trivial nor ill-defined. There are no contradictions, ambiguities, or factual errors.\n\nThe solution proceeds as follows. The objective is to compute the entanglement length, $N_e$, which quantifies the average number of monomers between topological constraints in a polymer chain. The provided methodology is a computational estimate based on a static snapshot of a polymer configuration.\n\nThe foundational principle is the concept of the primitive path. For a given chain, its primitive path is its shortest possible contour, assuming it cannot cross surrounding topological obstacles. These obstacles are modeled here as a discrete set of pinned points, or slip-links, through which the chain must pass. The primitive path is therefore approximated as a series of straight line segments connecting these consecutive pins.\n\nThe algorithm to compute $N_e$ is constructed by following the definitions provided in the problem statement meticulously.\n\nFirst, we establish the computational toolkit. The system is under periodic boundary conditions in a cubic box of side length $L$. All distance and vector calculations must adhere to the minimum-image convention (MIC). For any displacement vector $\\Delta\\mathbf{r} = \\mathbf{r}_2 - \\mathbf{r}_1$, its MIC-reduced form is given by the component-wise operation:\n$$\n\\Delta \\mathbf{r}_{\\mathrm{mic}} = \\Delta \\mathbf{r} - L \\cdot \\mathrm{round}\\left(\\frac{\\Delta \\mathbf{r}}{L}\\right)\n$$\nThe norm of this vector, $\\|\\Delta \\mathbf{r}_{\\mathrm{mic}}\\|$, is the shortest distance between points $\\mathbf{r}_1$ and $\\mathbf{r}_2$ in the periodic space.\n\nFor each test case, the calculation follows these steps:\n1.  Identify the parameters: chain length $N$, box size $L$, bead coordinates $\\{\\mathbf{r}_i\\}$, initial pin set $\\mathcal{P}$, and end-trimming parameter $s$.\n2.  Determine the interior segment of the chain. To mitigate artifacts from chain ends which are less constrained, we exclude $s$ beads from each end. The interior part of the chain is defined by the bead indices from $i_0 = s$ to $i_1 = N-1-s$.\n3.  Construct the effective pin set, $\\mathcal{P}_{\\mathrm{eff}}$. This set defines the vertices of the primitive path. It is formed by taking the provided set $\\mathcal{P}$, adding the start and end indices of the interior segment ($i_0$ and $i_1$), and then retaining only those pins that lie within the interior segment (indices from $i_0$ to $i_1$). The resulting set of indices is sorted and duplicates are removed to ensure a unique, ordered path. Let the sorted, unique pins be $\\{p_0, p_1, \\dots, p_{K-1}\\}$.\n4.  Calculate the primitive path contour length, $L_{\\mathrm{pp}}$. This is the total length of the piecewise linear path through the effective pins. It is the sum of the MIC distances between consecutive pins:\n$$\nL_{\\mathrm{pp}} = \\sum_{j=0}^{K-2} \\|\\mathbf{r}_{p_{j+1}} - \\mathbf{r}_{p_j}\\|_{\\mathrm{mic}}\n$$\nA special case arises if $L_{\\mathrm{pp}} = R_{\\mathrm{int}}$, corresponding to a straight path with no detours, where the number of entanglements $Z$ is $1$. If the path is a straight line, then $\\mathcal{P}_{\\mathrm{eff}}$ contains only two points, $i_0$ and $i_1$. In this case, $L_{\\mathrm{pp}}$ is simply the MIC distance between $\\mathbf{r}_{i_0}$ and $\\mathbf{r}_{i_1}$.\n5.  Calculate the squared direct distance between the ends of the interior segment, $R_{\\mathrm{int}}^2$. This represents the square of the span of the primitive path.\n$$\n\\mathbf{R}_{\\mathrm{int}} = \\text{mic}(\\mathbf{r}_{i_1} - \\mathbf{r}_{i_0}, L)\n$$\n$$\nR_{\\mathrm{int}}^2 = \\mathbf{R}_{\\mathrm{int}} \\cdot \\mathbf{R}_{\\mathrm{int}}\n$$\n6.  Calculate the number of effective Kuhn segments, or bonds, in the interior region, $N_{\\mathrm{eff}}$. This is given by the number of bonds in the full chain, $N-1$, minus the bonds in the trimmed sections, $2s$.\n$$\nN_{\\mathrm{eff}} = (N-1) - 2s\n$$\n7.  Finally, compute the entanglement length $N_e$. The number of entanglements, $Z$, is estimated from the tube model as the ratio of the squared contour length to the squared span, $Z = L_{\\mathrm{pp}}^2 / R_{\\mathrm{int}}^2$. The entanglement length, being the number of monomers per entanglement, is then $N_e = N_{\\mathrm{eff}} / Z$.\n$$\nN_e = N_{\\mathrm{eff}} \\frac{R_{\\mathrm{int}}^2}{L_{\\mathrm{pp}}^2}\n$$\nThis formula is implemented for each test case. The result is rounded to six decimal places as required. A potential division by zero could occur if $L_{\\mathrm{pp}} = 0$. This would imply all pins are at the same spatial location, which also means $R_{\\mathrm{int}} = 0$, leading to an indeterminate form $0/0$. Physically, this corresponds to an unentangled, collapsed state. However, for the given test cases, $L_{\\mathrm{pp}}$ is always non-zero.\n\nThe provided Python code implements this logic. It defines the test case data, iterates through them, and applies the described sequence of calculations using functions from the `numpy` library for vector operations. The MIC calculation is encapsulated in a helper function for clarity and reuse. The final results are collected and formatted into the required output string.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the entanglement length Ne for a set of polymer configurations.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"L\": 10.0,\n            \"N\": 6,\n            \"coords\": np.array([\n                [1.0, 5.0, 5.0], [2.0, 5.0, 5.0], [3.0, 5.0, 5.0],\n                [4.0, 5.0, 5.0], [5.0, 5.0, 5.0], [6.0, 5.0, 5.0]\n            ]),\n            \"P\": set(),\n            \"s\": 1\n        },\n        {\n            \"L\": 20.0,\n            \"N\": 10,\n            \"coords\": np.array([\n                [1.0, 1.0, 5.0], [3.0, 2.0, 5.0], [5.0, 5.0, 5.0],\n                [6.0, 6.0, 5.0], [7.0, 7.0, 5.0], [8.0, 9.0, 5.0],\n                [10.0, 7.0, 5.0], [12.0, 5.0, 5.0], [15.0, 4.0, 5.0],\n                [18.0, 3.0, 5.0]\n            ]),\n            \"P\": {5},\n            \"s\": 2\n        },\n        {\n            \"L\": 10.0,\n            \"N\": 8,\n            \"coords\": np.array([\n                [0.5, 1.0, 1.0], [9.0, 1.0, 1.0], [9.5, 2.0, 1.0],\n                [0.0, 5.0, 1.0], [1.5, 3.0, 1.0], [1.8, 2.0, 1.0],\n                [2.0, 1.0, 1.0], [2.5, 0.5, 1.0]\n            ]),\n            \"P\": {3},\n            \"s\": 1\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        L = case[\"L\"]\n        N = case[\"N\"]\n        coords = case[\"coords\"]\n        P = case[\"P\"]\n        s = case[\"s\"]\n\n        def mic_vector(dr, box_L):\n            \"\"\"Applies minimum image convention to a displacement vector.\"\"\"\n            return dr - box_L * np.round(dr / box_L)\n\n        # Step 1: Define interior indices and effective pin set\n        i0 = s\n        i1 = N - 1 - s\n        \n        # P_eff = (P U {i0, i1}) intersect {i0, ..., i1}\n        P_eff_set = (P.union({i0, i1})).intersection(set(range(i0, i1 + 1)))\n        P_eff_sorted = sorted(list(P_eff_set))\n\n        # Step 2: Calculate R_int^2\n        r_i0 = coords[i0]\n        r_i1 = coords[i1]\n        R_int_vec = mic_vector(r_i1 - r_i0, L)\n        R_int_sq = np.dot(R_int_vec, R_int_vec)\n\n        # Step 3: Calculate L_pp\n        L_pp = 0.0\n        if len(P_eff_sorted) > 1:\n            for j in range(len(P_eff_sorted) - 1):\n                p_curr = P_eff_sorted[j]\n                p_next = P_eff_sorted[j+1]\n                \n                r_curr = coords[p_curr]\n                r_next = coords[p_next]\n                \n                dr_segment = mic_vector(r_next - r_curr, L)\n                L_pp += np.linalg.norm(dr_segment)\n\n        # Step 4: Calculate N_eff\n        N_eff = (N - 1) - 2 * s\n        \n        # Step 5: Calculate Ne\n        if L_pp == 0:\n            # This case implies R_int_sq is also 0, an unentangled chain.\n            # The formula would be 0/0. Physical interpretation yields Z=1 for an ideal chain.\n            # If L_pp = 0, R must be 0, so L_pp^2/R_int^2 is ill-defined.\n            # For a straight chain with no detours, L_pp = R_int, Z=1, Ne = N_eff.\n            # If L_pp is 0, the path has zero length, so it's a point. R_int is 0.\n            # Let's assume based on problem context that L_pp > 0 for all valid cases.\n            if R_int_sq > 0:\n                # Infinite entanglements, Ne = 0 (a collapsed loop).\n                Ne = 0.0\n            else: # R_int_sq = 0 as well.\n                # Corresponds to a single point. No length, no entanglements.\n                # Or a straight line. If Lpp = R_int, Z=1.\n                # In Case 1, L_pp=3, R_int=3, so Z=1. Ne = N_eff = 3.\n                # If L_pp==0 because there's only one pin, Lpp should be taken as R_int for consistency? No.\n                # The sum for L_pp runs up to K-2. If K=1, L_pp=0.\n                # In the problem, K is at least 2 due to i0, i1.\n                Ne = float('inf') # Or some other indicator of an issue.\n        else:\n            Ne = N_eff * (R_int_sq / (L_pp * L_pp))\n            \n        results.append(round(Ne, 6))\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2930833"}, {"introduction": "Having learned how to define and compute entanglement metrics, the final step is to apply them in a real-world scientific context. This practice focuses on the critical task of model validation, where we assess how well a coarse-grained slip-link model captures the physics of a more detailed atomistic simulation. You will develop a quantitative framework to compare model predictions and reference data for both structural metrics, like the entanglement count $Z$, and macroscopic properties, such as the shear relaxation modulus $G(t)$ [@problem_id:2930842]. This exercise highlights the ultimate goal of entanglement analysis: to build and verify predictive models that link microscopic topology to the observable mechanical and flow behavior of polymeric materials.", "problem": "You are given a validation task for slip-link coarse-grained models of entangled polymer melts. The objective is to quantify the agreement between model predictions and reference values obtained by Primitive Path Analysis (PPA) from atomistic simulations. The comparison must be conducted on three observables: the shear relaxation modulus as a function of time, the entanglement count per chain, and the mean primitive path length.\n\nBackground and core definitions:\n- The shear relaxation modulus, denoted by $G(t)$, is the stress response to a unit step strain. For polymer melts, a well-tested representation of $G(t)$ over many decades of time is the multi-mode Maxwell spectrum:\n$$\nG(t) = \\sum_{k=1}^{M} g_k \\, \\exp\\!\\bigl(-t/\\tau_k\\bigr),\n$$\nwhere $M$ is the number of modes, $g_k$ are mode amplitudes (with units of pascal), and $\\tau_k$ are mode relaxation times (with units of seconds).\n- Slip-link models represent topological entanglements as constraints that restrict chain motion while allowing slippage at constraint points. Primitive Path Analysis (PPA) on atomistic simulations yields reference values for structural metrics, including the entanglement count per chain $Z$ (dimensionless) and the mean primitive path length $\\langle L_{\\mathrm{pp}} \\rangle$ (with units of length).\n\nDefine the following validation metrics:\n1. A log-time-weighted, log-modulus root-mean-square deviation for the modulus trajectories:\n$$\nE_G = \\left( \\frac{\\int_{\\ln t_{\\min}}^{\\ln t_{\\max}} \\left[ \\ln G_{\\mathrm{model}}(t) - \\ln G_{\\mathrm{ref}}(t) \\right]^2 \\, \\mathrm{d}(\\ln t)}{\\int_{\\ln t_{\\min}}^{\\ln t_{\\max}} \\mathrm{d}(\\ln t)} \\right)^{1/2}.\n$$\nUse the natural logarithm in all occurrences of $\\ln(\\cdot)$, and assume that $G(t) \\gt 0$ for all times.\n2. A relative absolute error for the entanglement count:\n$$\nE_Z = \\frac{\\left| Z_{\\mathrm{model}} - Z_{\\mathrm{ref}} \\right|}{Z_{\\mathrm{ref}}}.\n$$\n3. A relative absolute error for the mean primitive path length:\n$$\nE_L = \\frac{\\left| \\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{model}} - \\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{ref}} \\right|}{\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{ref}}}.\n$$\n4. A composite score aggregating the three metrics:\n$$\nQ = \\sqrt{E_G^2 + E_Z^2 + E_L^2}.\n$$\nThis composite $Q$ is dimensionless.\n\nNumerical discretization rules:\n- Evaluate $E_G$ on a logarithmically spaced time grid $\\{ t_i \\}_{i=0}^{N-1}$ with $N = 31$ points from $t_{\\min} = 10^{-6} \\,\\mathrm{s}$ to $t_{\\max} = 10^{2} \\,\\mathrm{s}$, defined by\n$$\nt_i = 10^{\\, -6 + i \\cdot \\frac{2 - (-6)}{30} } \\,\\mathrm{s}, \\quad i = 0,1,\\dots,30.\n$$\n- Discretize the integral in $E_G$ with a trapezoidal rule in $\\ln t$. Let $\\ell_i = \\ln t_i$. Define nonnegative weights $\\{ w_i \\}$ by\n$$\nw_0 = \\tfrac{1}{2}(\\ell_{1} - \\ell_{0}), \\quad\nw_{i} = \\tfrac{1}{2}(\\ell_{i+1} - \\ell_{i-1}) \\text{ for } i=1,\\dots,N-2, \\quad\nw_{N-1} = \\tfrac{1}{2}(\\ell_{N-1} - \\ell_{N-2}).\n$$\nThen approximate\n$$\nE_G \\approx \\left( \\frac{\\sum_{i=0}^{N-1} w_i \\left[ \\ln G_{\\mathrm{model}}(t_i) - \\ln G_{\\mathrm{ref}}(t_i) \\right]^2}{\\sum_{i=0}^{N-1} w_i} \\right)^{1/2}.\n$$\n\nTest suite:\nFor each test case, you are given a reference multi-mode Maxwell spectrum $(\\{ g^{\\mathrm{ref}}_k \\}, \\{ \\tau^{\\mathrm{ref}}_k \\})$, a model spectrum $(\\{ g^{\\mathrm{model}}_k \\}, \\{ \\tau^{\\mathrm{model}}_k \\})$, and scalar structural values $Z_{\\mathrm{ref}}$, $Z_{\\mathrm{model}}$, $\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{ref}}$, and $\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{model}}$. All moduli $g_k$ are in pascal (write results in pascal internally but the metrics are dimensionless), all times $\\tau_k$ are in seconds, and all primitive path lengths $\\langle L_{\\mathrm{pp}} \\rangle$ are in nanometers. The entanglement count $Z$ is dimensionless.\n\n- Test case A (general case):\n  - Reference spectrum: $M=3$, with $\\{ g^{\\mathrm{ref}}_k \\} = \\{ 1.5 \\times 10^{5},\\, 8.0 \\times 10^{4},\\, 3.0 \\times 10^{4} \\}$ and $\\{ \\tau^{\\mathrm{ref}}_k \\} = \\{ 1.0 \\times 10^{-4},\\, 1.0 \\times 10^{-1},\\, 1.0 \\times 10^{1} \\}$.\n  - Model spectrum: $M=3$, with $\\{ g^{\\mathrm{model}}_k \\} = \\{ 1.4 \\times 10^{5},\\, 8.5 \\times 10^{4},\\, 2.8 \\times 10^{4} \\}$ and $\\{ \\tau^{\\mathrm{model}}_k \\} = \\{ 1.2 \\times 10^{-4},\\, 8.0 \\times 10^{-2},\\, 1.2 \\times 10^{1} \\}$.\n  - Entanglement counts: $Z_{\\mathrm{ref}} = 20$, $Z_{\\mathrm{model}} = 19$.\n  - Mean primitive path lengths: $\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{ref}} = 120 \\,\\mathrm{nm}$, $\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{model}} = 118 \\,\\mathrm{nm}$.\n\n- Test case B (perfect agreement boundary):\n  - Reference spectrum: $M=3$, with $\\{ g^{\\mathrm{ref}}_k \\} = \\{ 1.5 \\times 10^{5},\\, 8.0 \\times 10^{4},\\, 3.0 \\times 10^{4} \\}$ and $\\{ \\tau^{\\mathrm{ref}}_k \\} = \\{ 1.0 \\times 10^{-4},\\, 1.0 \\times 10^{-1},\\, 1.0 \\times 10^{1} \\}$.\n  - Model spectrum: identical to reference.\n  - Entanglement counts: $Z_{\\mathrm{ref}} = 20$, $Z_{\\mathrm{model}} = 20$.\n  - Mean primitive path lengths: $\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{ref}} = 120 \\,\\mathrm{nm}$, $\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{model}} = 120 \\,\\mathrm{nm}$.\n\n- Test case C (mismatch edge case):\n  - Reference spectrum: $M=3$, with $\\{ g^{\\mathrm{ref}}_k \\} = \\{ 1.5 \\times 10^{5},\\, 8.0 \\times 10^{4},\\, 3.0 \\times 10^{4} \\}$ and $\\{ \\tau^{\\mathrm{ref}}_k \\} = \\{ 1.0 \\times 10^{-4},\\, 1.0 \\times 10^{-1},\\, 1.0 \\times 10^{1} \\}$.\n  - Model spectrum: $M=3$, with $\\{ g^{\\mathrm{model}}_k \\} = \\{ 7.5 \\times 10^{4},\\, 4.0 \\times 10^{4},\\, 1.5 \\times 10^{4} \\}$ and $\\{ \\tau^{\\mathrm{model}}_k \\} = \\{ 5.0 \\times 10^{-5},\\, 5.0 \\times 10^{-2},\\, 5.0 \\times 10^{0} \\}$.\n  - Entanglement counts: $Z_{\\mathrm{ref}} = 20$, $Z_{\\mathrm{model}} = 10$.\n  - Mean primitive path lengths: $\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{ref}} = 120 \\,\\mathrm{nm}$, $\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{model}} = 200 \\,\\mathrm{nm}$.\n\nProgramming task:\n- For each test case, construct $G_{\\mathrm{ref}}(t_i)$ and $G_{\\mathrm{model}}(t_i)$ on the specified time grid using the given multi-mode Maxwell spectra, then compute $E_G$, $E_Z$, $E_L$, and $Q$ using the definitions above and the logarithmic trapezoidal rule.\n- All three metrics and the composite score are dimensionless. No angle units are involved. No additional physical constants are needed.\n- Your program should produce a single line of output containing a list of lists, one inner list per test case in the order A, B, C. Each inner list must contain the four numbers $[E_G, E_Z, E_L, Q]$, each rounded to six decimal places. The exact output format must be a single line like\n$[ [eG_A,eZ_A,eL_A,Q_A], [eG_B,eZ_B,eL_B,Q_B], [eG_C,eZ_C,eL_C,Q_C] ]$\nwithout any spaces, but with commas separating entries, namely\n$[[eG_A,eZ_A,eL_A,Q_A],[eG_B,eZ_B,eL_B,Q_B],[eG_C,eZ_C,eL_C,Q_C]]$.", "solution": "The problem statement is subjected to rigorous validation.\n\nStep 1: Extracted Givens.\nThe problem provides the following quantities and definitions:\n- The shear relaxation modulus $G(t)$ is given by a multi-mode Maxwell spectrum:\n$$G(t) = \\sum_{k=1}^{M} g_k \\, \\exp\\!\\bigl(-t/\\tau_k\\bigr)$$\n- Observables for comparison: the shear relaxation modulus $G(t)$, the entanglement count per chain $Z$, and the mean primitive path length $\\langle L_{\\mathrm{pp}} \\rangle$.\n- Validation metrics are defined as:\n  1. Root-mean-square deviation for the modulus, $E_G$:\n  $$E_G = \\left( \\frac{\\int_{\\ln t_{\\min}}^{\\ln t_{\\max}} \\left[ \\ln G_{\\mathrm{model}}(t) - \\ln G_{\\mathrm{ref}}(t) \\right]^2 \\, \\mathrm{d}(\\ln t)}{\\int_{\\ln t_{\\min}}^{\\ln t_{\\max}} \\mathrm{d}(\\ln t)} \\right)^{1/2}$$\n  2. Relative error for entanglement count, $E_Z$:\n  $$E_Z = \\frac{\\left| Z_{\\mathrm{model}} - Z_{\\mathrm{ref}} \\right|}{Z_{\\mathrm{ref}}}$$\n  3. Relative error for primitive path length, $E_L$:\n  $$E_L = \\frac{\\left| \\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{model}} - \\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{ref}} \\right|}{\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{ref}}}$$\n  4. A composite score, $Q$:\n  $$Q = \\sqrt{E_G^2 + E_Z^2 + E_L^2}$$\n- Numerical integration for $E_G$ is specified:\n  - Time grid: $N = 31$ points from $t_{\\min} = 10^{-6}$ s to $t_{\\max} = 10^{2}$ s, defined by $t_i = 10^{\\, -6 + i \\cdot \\frac{8}{30} }$ s for $i = 0, \\dots, 30$.\n  - Discretization method: Trapezoidal rule in logarithmic time, $\\ell_i = \\ln t_i$, with weights $w_0 = \\tfrac{1}{2}(\\ell_{1} - \\ell_{0})$, $w_{i} = \\tfrac{1}{2}(\\ell_{i+1} - \\ell_{i-1})$ for $i=1, \\dots, N-2$, and $w_{N-1} = \\tfrac{1}{2}(\\ell_{N-1} - \\ell_{N-2})$.\n  - The approximation is:\n  $$E_G \\approx \\left( \\frac{\\sum_{i=0}^{N-1} w_i \\left[ \\ln G_{\\mathrm{model}}(t_i) - \\ln G_{\\mathrm{ref}}(t_i) \\right]^2}{\\sum_{i=0}^{N-1} w_i} \\right)^{1/2}$$\n- Three test cases (A, B, C) are provided with complete sets of reference and model parameters for $(\\{g_k\\}, \\{\\tau_k\\})$, $Z$, and $\\langle L_{\\mathrm{pp}} \\rangle$.\n\nStep 2: Validation of Givens.\nThe problem is evaluated against the validation criteria:\n- **Scientifically Grounded**: The problem is rooted in polymer physics and rheology, utilizing standard models ($G(t)$ as a Maxwell spectrum) and analysis techniques (Primitive Path Analysis). The defined metrics are reasonable quantitative measures for model validation. The provided physical parameters are realistic.\n- **Well-Posed**: The problem is specified with mathematical precision. All functions, parameters, numerical methods, and data are explicitly defined, permitting the calculation of a unique solution.\n- **Objective**: The language is formal and devoid of subjective claims. The task is a purely computational one based on objective data and formulas.\n- **No Flaws**: The problem does not violate any fundamental principles. It is computationally tractable, self-contained, and free from contradiction, ambiguity, or triviality (with the exception of Test Case B, which serves as a valid null-case test). The specification of a trapezoidal rule on a logarithmic grid is coherent and well-defined.\n\nStep 3: Verdict and Action.\nThe problem is **valid**. A complete, reasoned solution will be provided.\n\n**Solution Procedure**\n\nThe task is to compute the four validation metrics $E_G$, $E_Z$, $E_L$, and $Q$ for three distinct test cases. The procedure is structured as follows:\n\n1.  **Define the Time Grid**: A logarithmic time grid $\\{t_i\\}$ of $N=31$ points is generated spanning from $t_{\\min} = 10^{-6}$ s to $t_{\\max} = 10^2$ s. The grid points are given by $t_i = 10^{-6 + i \\cdot (8/30)}$ for $i = 0, \\dots, 30$. This corresponds to a uniform grid in logarithmic time.\n\n2.  **Calculate Shear Modulus $G(t)$**: For each test case, the reference modulus $G_{\\mathrm{ref}}(t)$ and model modulus $G_{\\mathrm{model}}(t)$ are calculated at each point $t_i$ on the time grid using the provided multi-mode Maxwell spectrum:\n    $$G(t_i) = \\sum_{k=1}^{M} g_k \\exp(-t_i/\\tau_k)$$\n    This calculation is performed for both the reference and model parameter sets.\n\n3.  **Compute the Modulus Error $E_G$**: The error metric $E_G$ is calculated using the specified discrete approximation.\n    - First, the logarithmic time points $\\ell_i = \\ln t_i$ are computed.\n    - The step size in logarithmic time, $\\Delta\\ell = \\ell_{i+1} - \\ell_i$, is constant due to the logarithmic spacing of $\\{t_i\\}$. $\\Delta\\ell = \\frac{\\ln(t_{\\max}) - \\ln(t_{\\min})}{N-1} = \\frac{(2 - (-6))\\ln 10}{30} = \\frac{8}{30}\\ln 10$.\n    - The weights $\\{w_i\\}$ for the trapezoidal rule are calculated. For a uniform grid in $\\ell$, these simplify to $w_0 = w_{N-1} = \\frac{1}{2}\\Delta\\ell$ and $w_i = \\Delta\\ell$ for $i=1, \\dots, N-2$.\n    - The sum of weights is $\\sum_{i=0}^{N-1} w_i = (N-1)\\Delta\\ell = \\ln(t_{\\max}/\\t_{\\min})$.\n    - The squared difference of the logarithmic moduli, $(\\ln G_{\\mathrm{model}}(t_i) - \\ln G_{\\mathrm{ref}}(t_i))^2$, is computed for each point $t_i$.\n    - $E_G$ is then the square root of the weighted average of these squared differences:\n    $$E_G = \\sqrt{\\frac{\\sum_{i=0}^{N-1} w_i (\\ln G_{\\mathrm{model}}(t_i) - \\ln G_{\\mathrm{ref}}(t_i))^2}{\\sum_{i=0}^{N-1} w_i}}$$\n\n4.  **Compute Scalar Errors $E_Z$ and $E_L$**: The relative errors for the entanglement count and primitive path length are calculated directly from their definitions:\n    $$E_Z = \\frac{| Z_{\\mathrm{model}} - Z_{\\mathrm{ref}} |}{Z_{\\mathrm{ref}}}$$\n    $$E_L = \\frac{| \\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{model}} - \\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{ref}} |}{\\langle L_{\\mathrm{pp}} \\rangle_{\\mathrm{ref}}}$$\n\n5.  **Compute Composite Score $Q$**: The individual error metrics are combined into the composite score $Q$:\n    $$Q = \\sqrt{E_G^2 + E_Z^2 + E_L^2}$$\n\nThis entire procedure is implemented in a computer program, which iterates through each of the three test cases (A, B, and C), calculates the four metrics $[E_G, E_Z, E_L, Q]$, and formats the results as specified.\n\nFor example, in Test Case A:\n- $E_Z = \\frac{|19 - 20|}{20} = 0.05$.\n- $E_L = \\frac{|118 - 120|}{120} = \\frac{2}{120} \\approx 0.016667$.\n- $E_G$ requires the full numerical procedure outlined above. Once $E_G$ is found, $Q$ is computed.\n\nFor Test Case B, where model and reference data are identical, all error metrics ($E_G$, $E_Z$, $E_L$) and the composite score $Q$ will be exactly zero, providing a useful verification of the implementation's correctness.\nThe final program implements these steps for all test cases and produces the required output format.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Validates slip-link model predictions against reference data by computing\n    error metrics EG, EZ, EL, and a composite score Q.\n    \"\"\"\n\n    test_cases = [\n        # Test case A (general case)\n        {\n            \"ref\": {\"g\": [1.5e5, 8.0e4, 3.0e4], \"tau\": [1.0e-4, 1.0e-1, 1.0e1], \"Z\": 20.0, \"L\": 120.0},\n            \"model\": {\"g\": [1.4e5, 8.5e4, 2.8e4], \"tau\": [1.2e-4, 8.0e-2, 1.2e1], \"Z\": 19.0, \"L\": 118.0},\n        },\n        # Test case B (perfect agreement boundary)\n        {\n            \"ref\": {\"g\": [1.5e5, 8.0e4, 3.0e4], \"tau\": [1.0e-4, 1.0e-1, 1.0e1], \"Z\": 20.0, \"L\": 120.0},\n            \"model\": {\"g\": [1.5e5, 8.0e4, 3.0e4], \"tau\": [1.0e-4, 1.0e-1, 1.0e1], \"Z\": 20.0, \"L\": 120.0},\n        },\n        # Test case C (mismatch edge case)\n        {\n            \"ref\": {\"g\": [1.5e5, 8.0e4, 3.0e4], \"tau\": [1.0e-4, 1.0e-1, 1.0e1], \"Z\": 20.0, \"L\": 120.0},\n            \"model\": {\"g\": [7.5e4, 4.0e4, 1.5e4], \"tau\": [5.0e-5, 5.0e-2, 5.0e0], \"Z\": 10.0, \"L\": 200.0},\n        },\n    ]\n\n    def calculate_g_t(t_grid, g_k, tau_k):\n        \"\"\"Calculates the shear modulus G(t) over a time grid.\"\"\"\n        g_t = np.zeros_like(t_grid, dtype=np.float64)\n        for g, tau in zip(g_k, tau_k):\n            g_t += g * np.exp(-t_grid / tau)\n        return g_t\n\n    def compute_metrics(case):\n        \"\"\"Computes all four metrics for a single test case.\"\"\"\n        # Unpack reference and model data\n        ref_data = case[\"ref\"]\n        model_data = case[\"model\"]\n\n        # Calculate E_Z\n        if ref_data[\"Z\"] == 0:\n            e_z = np.inf if model_data[\"Z\"] != 0 else 0.0\n        else:\n            e_z = np.abs(model_data[\"Z\"] - ref_data[\"Z\"]) / ref_data[\"Z\"]\n\n        # Calculate E_L\n        if ref_data[\"L\"] == 0:\n            e_l = np.inf if model_data[\"L\"] != 0 else 0.0\n        else:\n            e_l = np.abs(model_data[\"L\"] - ref_data[\"L\"]) / ref_data[\"L\"]\n\n        # Setup for E_G calculation\n        N = 31\n        t_min, t_max = 1e-6, 1e2\n        t_grid = np.logspace(np.log10(t_min), np.log10(t_max), num=N, dtype=np.float64)\n\n        g_ref = calculate_g_t(t_grid, ref_data[\"g\"], ref_data[\"tau\"])\n        g_model = calculate_g_t(t_grid, model_data[\"g\"], model_data[\"tau\"])\n\n        # Prevent log(0) issues, although problem states G(t) > 0.\n        if np.any(g_ref = 0) or np.any(g_model = 0):\n            # This case should not be reached according to problem statement\n            return [np.nan, e_z, e_l, np.nan]\n\n        ln_g_ref = np.log(g_ref)\n        ln_g_model = np.log(g_model)\n        \n        # Calculate E_G using trapezoidal rule in log-time\n        ln_t_grid = np.log(t_grid)\n        \n        # Trapezoidal weights calculation\n        delta_ln_t = ln_t_grid[1:] - ln_t_grid[:-1]\n        \n        weights = np.zeros(N, dtype=np.float64)\n        weights[0] = 0.5 * delta_ln_t[0]\n        weights[1:-1] = 0.5 * (delta_ln_t[1:] + delta_ln_t[:-1])\n        weights[-1] = 0.5 * delta_ln_t[-1]\n\n        # Since the grid is uniform in log-space, the calculation simplifies,\n        # but the general form is used for correctness.\n        \n        sum_weights = np.sum(weights)\n        \n        # Sum of weighted squared differences\n        integrand = (ln_g_model - ln_g_ref)**2\n        integral_val = np.sum(weights * integrand)\n        \n        if sum_weights > 0:\n            e_g = np.sqrt(integral_val / sum_weights)\n        else:\n            e_g = 0.0\n\n        # Calculate composite score Q\n        q_score = np.sqrt(e_g**2 + e_z**2 + e_l**2)\n        \n        return [e_g, e_z, e_l, q_score]\n\n    all_results = []\n    for case in test_cases:\n        results = compute_metrics(case)\n        all_results.append(results)\n\n    # Format the output string as per the strict requirement\n    outer_parts = []\n    for res_list in all_results:\n        inner_parts = [f\"{x:.6f}\" for x in res_list]\n        outer_parts.append(f\"[{','.join(inner_parts)}]\")\n    \n    final_output = f\"[{','.join(outer_parts)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2930842"}]}