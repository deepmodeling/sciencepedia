{"hands_on_practices": [{"introduction": "The first step in analyzing a stiff chemical system is to diagnose the source of stiffness: the presence of processes occurring on vastly different timescales. In this exercise, you will explore how the mathematical properties of the system's Jacobian matrix—specifically its eigenvalues and eigenvectors—allow us to identify and characterize these fast and slow dynamic modes. This practice provides foundational, hands-on experience in linking linear algebra to the physical behavior of a reaction network [@problem_id:2634427].", "problem": "Consider the linearized mass-action model of a reversible isomerization network with a slow interconversion that induces stiffness. Let the chemical species be $A$, $B$, $C$, and $D$, and the elementary reactions be\n- $A \\rightarrow B$ with rate constant $k_{1f}$,\n- $B \\rightarrow A$ with rate constant $k_{1r}$,\n- $B \\rightarrow C$ with rate constant $k_{s}$,\n- $C \\rightarrow D$ with rate constant $k_{2f}$,\n- $D \\rightarrow C$ with rate constant $k_{2r}$.\n\nLet the species concentration vector be $x = [x_A, x_B, x_C, x_D]^\\top$. Under mass-action kinetics, the reaction rate vector $v(x)$ has entries $v_1 = k_{1f} x_A$, $v_2 = k_{1r} x_B$, $v_3 = k_s x_B$, $v_4 = k_{2f} x_C$, $v_5 = k_{2r} x_D$. The stoichiometry matrix $S$ is given by the columns corresponding to the above reactions:\n$$\nS = \\begin{bmatrix}\n-1  +1  0  0  0 \\\\\n+1  -1  -1  0  0 \\\\\n0  0  +1  -1  +1 \\\\\n0  0  0  +1  -1\n\\end{bmatrix}.\n$$\nThe governing ordinary differential equation is $dx/dt = S\\,v(x)$. The Jacobian matrix $J$ at any state $x$ is defined by $J = \\frac{\\partial}{\\partial x} (S\\,v(x)) = S \\, \\frac{\\partial v}{\\partial x}$. For this unimolecular network, $J$ is independent of $x$ and equals\n$$\nJ = \\begin{bmatrix}\n- k_{1f}  k_{1r}  0  0 \\\\\nk_{1f}  - (k_{1r} + k_s)  0  0 \\\\\n0  k_s  - k_{2f}  k_{2r} \\\\\n0  0  k_{2f}  - k_{2r}\n\\end{bmatrix}.\n$$\nIn the framework of Computational Singular Perturbation (CSP), fast modes are associated with eigenvalues $\\lambda$ of $J$ having large negative real parts (units of $\\mathrm{s}^{-1}$ because the rate constants are in $\\mathrm{s}^{-1}$), and their right eigenvectors reveal which species participate dominantly in those modes. For a reversible reaction pair, a fast equilibration mode typically displays an eigenvector with dominant components on the species in that pair and with opposite signs between those two species.\n\nYour task is to write a complete program that:\n1. Constructs $J$ from the given rate constants $k_{1f}$, $k_{1r}$, $k_s$, $k_{2f}$, $k_{2r}$ (all in $\\mathrm{s}^{-1}$).\n2. Computes numerically the eigenvalues and right eigenvectors of $J$ using double-precision floating point arithmetic.\n3. Sorts eigenvalues $\\lambda_i$ by ascending real parts (more negative first). Let the sorted eigenpairs be $\\{(\\lambda_i, r_i)\\}_{i=1}^4$ where $r_i$ is the corresponding right eigenvector.\n4. Identifies which eigenmodes correspond to fast equilibration of the reaction pair $A \\leftrightarrow B$ and which correspond to fast equilibration of the reaction pair $C \\leftrightarrow D$ by inspecting the eigenvector components:\n   - For a pair $\\{u, v\\}$, define the participation score of eigenvector $r_i$ as\n     $$\n     \\sigma_{\\{u,v\\}}(i) = \\left(\\frac{r_{i,u}^2 + r_{i,v}^2}{\\sum_{j \\in \\{A,B,C,D\\}} r_{i,j}^2}\\right) \\cdot \\chi\\Big(r_{i,u}\\, r_{i,v}  0 \\Big),\n     $$\n     where $r_{i,j}$ denotes the $j$-th component of $r_i$ (using the real parts if complex), and $\\chi(\\cdot)$ is the indicator function that is $1$ if its argument is true and $0$ otherwise. Intuitively, the first factor measures how concentrated the mode is on the two species of the pair, and the indicator enforces opposite signs on the two components in that pair.\n   - An eigenmode is declared “fast” if its real part satisfies $-\\mathrm{Re}(\\lambda_i) \\ge \\gamma \\cdot \\min\\{-\\mathrm{Re}(\\lambda_j) : \\mathrm{Re}(\\lambda_j)  0\\}$, where $\\gamma0$ is a user-specified timescale separation factor, and the minimum is taken over strictly negative real parts (ignoring any zero eigenvalues).\n   - For each pair ($A \\leftrightarrow B$ and $C \\leftrightarrow D$), among the eigenmodes that are “fast,” select the index $i$ that maximizes $\\sigma_{\\{u,v\\}}(i)$. If no “fast” eigenmode has a strictly positive participation score for the pair, return $-1$ for that pair.\n\nYou must apply this procedure to the following test suite of parameter sets (all rate constants in $\\mathrm{s}^{-1}$; list entries are $(k_{1f}, k_{1r}, k_s, k_{2f}, k_{2r}, \\gamma)$):\n- Test $1$: $(10^3, 8 \\cdot 10^2, 10^{-1}, 1.2 \\cdot 10^3, 1.1 \\cdot 10^3, 10)$,\n- Test $2$: $(5 \\cdot 10^2, 7 \\cdot 10^2, 5 \\cdot 10^{-2}, 5, 6, 50)$,\n- Test $3$: $(50, 50, 10^{-1}, 2 \\cdot 10^{-1}, 3 \\cdot 10^{-1}, 10)$,\n- Test $4$: $(2 \\cdot 10^3, 1.5 \\cdot 10^3, 10^{-4}, 1.8 \\cdot 10^3, 2.2 \\cdot 10^3, 10)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case in order, the program must output a two-element list $[i_{AB}, i_{CD}]$, where $i_{AB}$ is the index (in the sorted eigenvalue order $i \\in \\{0,1,2,3\\}$ with $0$ being the most negative real part) of the identified fast equilibration mode for $A \\leftrightarrow B$ or $-1$ if none qualifies, and similarly $i_{CD}$ for $C \\leftrightarrow D$. Thus the final output is a list of four such two-element lists, e.g., $[[i_{AB}^{(1)}, i_{CD}^{(1)}],[i_{AB}^{(2)}, i_{CD}^{(2)}],[i_{AB}^{(3)}, i_{CD}^{(3)}],[i_{AB}^{(4)}, i_{CD}^{(4)}]]$ with each $i$ an integer.", "solution": "The problem presented is a valid and well-posed exercise in the application of Computational Singular Perturbation (CSP) theory to a linear chemical reaction network. It requires a numerical analysis of the system's Jacobian matrix to identify and classify fast dynamic modes. The problem is scientifically grounded, employing standard principles of chemical kinetics and linear algebra. All parameters and procedures are explicitly defined, permitting a unique and verifiable solution. We shall proceed with the solution.\n\nThe core of the problem lies in analyzing the linearized dynamics of the system around a state, which is governed by the Jacobian matrix, $\\mathbf{J}$. The system describes a network of unimolecular reactions, for which the governing ordinary differential equation, $\\frac{d\\mathbf{x}}{dt} = \\mathbf{S}\\mathbf{v}(\\mathbf{x})$, is already linear in the concentration vector $\\mathbf{x}$. Consequently, the Jacobian matrix, $\\mathbf{J} = \\frac{\\partial(\\mathbf{S}\\mathbf{v})}{\\partial \\mathbf{x}}$, is constant and fully describes the system's dynamics for any concentration profile. The given Jacobian is:\n$$\n\\mathbf{J} = \\begin{bmatrix}\n-k_{1f}  k_{1r}  0  0 \\\\\nk_{1f}  -(k_{1r} + k_s)  0  0 \\\\\n0  k_s  -k_{2f}  k_{2r} \\\\\n0  0  k_{2f}  -k_{2r}\n\\end{bmatrix}\n$$\nThe eigenvalues $\\lambda_i$ of $\\mathbf{J}$ represent the inverse timescales of the system's fundamental modes of motion. A large negative real part, $\\mathrm{Re}(\\lambda_i) \\ll 0$, corresponds to a fast-decaying mode with a characteristic timescale $\\tau_i = 1/|\\mathrm{Re}(\\lambda_i)|$. The corresponding right eigenvector, $\\mathbf{r}_i$, reveals the combination of species concentrations that participate in that mode. For a fast equilibration mode between two species, say $U$ and $V$, the eigenvector components corresponding to these species, $r_{i,U}$ and $r_{i,V}$, will be dominant and have opposite signs, signifying a rapid, balanced exchange of mass between them.\n\nThe specified algorithmic procedure is as follows. For each set of rate constants $(k_{1f}, k_{1r}, k_s, k_{2f}, k_{2r})$ and timescale separation factor $\\gamma$:\n\n1.  **Construct the Jacobian Matrix**: The $4 \\times 4$ matrix $\\mathbf{J}$ is assembled using the provided rate constants.\n\n2.  **Eigenvalue Decomposition**: The eigenvalues $\\{\\lambda_i\\}_{i=0}^3$ and their corresponding right eigenvectors $\\{\\mathbf{r}_i\\}_{i=0}^3$ of $\\mathbf{J}$ are computed numerically. For a real matrix like $\\mathbf{J}$, any complex eigenvalues appear in conjugate pairs, but as established by analyzing the characteristic polynomial of its diagonal blocks, all eigenvalues of this specific $\\mathbf{J}$ are real and non-positive. Thus, the eigenvectors can also be chosen to be real.\n\n3.  **Sort Eigenpairs**: The eigenpairs $(\\lambda_i, \\mathbf{r}_i)$ are sorted based on the eigenvalue's real part in ascending order: $\\mathrm{Re}(\\lambda_0) \\le \\mathrm{Re}(\\lambda_1) \\le \\mathrm{Re}(\\lambda_2) \\le \\mathrm{Re}(\\lambda_3)$. The index $i \\in \\{0, 1, 2, 3\\}$ thus labels the modes from fastest to slowest. Due to the conservation of total mass $\\sum x_j$, one eigenvalue, $\\lambda_3$, will be zero.\n\n4.  **Identify Fast Modes**: A mode $i$ is classified as \"fast\" if its rate of decay, $-\\mathrm{Re}(\\lambda_i)$, is significantly larger than the slowest non-zero decay rate in the system. The threshold is determined by the parameter $\\gamma$. First, we find the minimum decay rate among all stable modes:\n    $$\n    R_{min} = \\min \\{-\\mathrm{Re}(\\lambda_j) : \\mathrm{Re}(\\lambda_j)  0\\}\n    $$\n    A mode $i$ is then declared fast if $-\\mathrm{Re}(\\lambda_i) \\ge \\gamma \\cdot R_{min}$. We denote the set of indices of these fast modes as $I_{\\text{fast}}$.\n\n5.  **Identify Equilibration Modes**: For each reaction pair of interest, $\\{A, B\\}$ and $\\{C, D\\}$, we must find which fast mode, if any, corresponds to its equilibration. This is achieved using the specified participation score, $\\sigma$. For a generic pair $\\{u, v\\}$ and an eigenvector $\\mathbf{r}_i$, the score is:\n    $$\n    \\sigma_{\\{u,v\\}}(i) = \\left(\\frac{r_{i,u}^2 + r_{i,v}^2}{\\sum_{j \\in \\{A,B,C,D\\}} r_{i,j}^2}\\right) \\cdot \\chi(r_{i,u} \\cdot r_{i,v}  0)\n    $$\n    where $r_{i,j}$ is the $j$-th component of the eigenvector $\\mathbf{r}_i$ and $\\chi$ is the indicator function. The species are indexed as $A \\to 0, B \\to 1, C \\to 2, D \\to 3$.\n    For each pair $\\{u,v\\}$, we search within the set of fast modes $I_{\\text{fast}}$ for the one that maximizes this score:\n    $$\n    i^*_{\\{u,v\\}} = \\underset{i \\in I_{\\text{fast}}}{\\mathrm{argmax}} \\, \\sigma_{\\{u,v\\}}(i)\n    $$\n    If $I_{\\text{fast}}$ is empty, or if the maximum score is zero (i.e., no fast mode exhibits the required opposing-sign structure for the pair), the index is reported as $-1$. Otherwise, the resulting index $i^*_{\\{u,v\\}}$ is reported. This procedure is performed for both the $\\{A, B\\}$ pair (yielding $i_{AB}$) and the $\\{C, D\\}$ pair (yielding $i_{CD}$).\n\nThe final output for each test case is the ordered pair $[i_{AB}, i_{CD}]$. This entire process is then repeated for all test suites provided.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the computational singular perturbation problem for a given set of test cases.\n    \"\"\"\n    # Test cases: (k1f, k1r, ks, k2f, k2r, gamma)\n    test_cases = [\n        (1e3, 8e2, 1e-1, 1.2e3, 1.1e3, 10),\n        (5e2, 7e2, 5e-2, 5, 6, 50),\n        (50, 50, 1e-1, 2e-1, 3e-1, 10),\n        (2e3, 1.5e3, 1e-4, 1.8e3, 2.2e3, 10),\n    ]\n\n    results = []\n    for params in test_cases:\n        result = process_case(params)\n        results.append(result)\n\n    # Format the final output string as per requirements.\n    formatted_results = [f\"[{res[0]},{res[1]}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef process_case(params):\n    \"\"\"\n    Constructs the Jacobian, computes eigenpairs, and identifies fast equilibration modes.\n    \n    Args:\n        params (tuple): A tuple containing the rate constants (k1f, k1r, ks, k2f, k2r)\n                        and the timescale separation factor gamma.\n    \n    Returns:\n        list: A two-element list [i_ab, i_cd] containing the indices of the identified\n              fast modes for pairs A-B and C-D, or -1 if none is found.\n    \"\"\"\n    k1f, k1r, ks, k2f, k2r, gamma = params\n\n    # 1. Construct the Jacobian matrix J\n    J = np.array([\n        [-k1f, k1r, 0, 0],\n        [k1f, -(k1r + ks), 0, 0],\n        [0, ks, -k2f, k2r],\n        [0, 0, k2f, -k2r]\n    ])\n\n    # 2. Compute eigenvalues and right eigenvectors\n    eigvals, eigvecs = np.linalg.eig(J)\n\n    # Eigenvalues for real matrices can have small imaginary parts due to numerical error.\n    # The theory for this problem guarantees real eigenvalues, so we take the real part.\n    eigvals = np.real(eigvals)\n    eigvecs = np.real(eigvecs)\n\n    # 3. Sort eigenpairs by ascending real part of eigenvalues\n    sorted_indices = np.argsort(eigvals)\n    sorted_eigvals = eigvals[sorted_indices]\n    sorted_eigvecs = eigvecs[:, sorted_indices]\n\n    # 4. Identify fast modes\n    # Find minimum decay rate among stable (non-zero eigenvalue) modes\n    neg_eigvals = sorted_eigvals[~np.isclose(sorted_eigvals, 0)]\n    if len(neg_eigvals) == 0:\n        # No stable modes, this case should not happen for this problem\n        return [-1, -1]\n    \n    min_decay_rate = np.min(-neg_eigvals)\n    fast_threshold = gamma * min_decay_rate\n    \n    fast_indices = [i for i, val in enumerate(sorted_eigvals) \n                    if -val >= fast_threshold and not np.isclose(val, 0)]\n\n    # 5. Identify equilibration modes\n    i_ab, i_cd = -1, -1\n    max_score_ab, max_score_cd = 0.0, 0.0\n\n    # Species indices: A=0, B=1, C=2, D=3\n    species_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n    u_ab, v_ab = species_map['A'], species_map['B']\n    u_cd, v_cd = species_map['C'], species_map['D']\n\n    if not fast_indices:\n        return [-1, -1]\n\n    for i in fast_indices:\n        r = sorted_eigvecs[:, i]\n        norm_sq = np.sum(r**2)\n        if np.isclose(norm_sq, 0): continue\n\n        # Calculate participation score for A -> B\n        r_u_ab, r_v_ab = r[u_ab], r[v_ab]\n        if r_u_ab * r_v_ab  0:\n            score = (r_u_ab**2 + r_v_ab**2) / norm_sq\n            if score > max_score_ab:\n                max_score_ab = score\n                i_ab = i\n\n        # Calculate participation score for C -> D\n        r_u_cd, r_v_cd = r[u_cd], r[v_cd]\n        if r_u_cd * r_v_cd  0:\n            score = (r_u_cd**2 + r_v_cd**2) / norm_sq\n            if score > max_score_cd:\n                max_score_cd = score\n                i_cd = i\n                \n    return [i_ab, i_cd]\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2634427"}, {"introduction": "Once fast and slow modes are identified, the goal of model reduction is to describe the system's evolution along a lower-dimensional 'slow invariant manifold'. This exercise moves from diagnosis to construction, asking you to analytically derive this manifold for a simple system using a perturbation expansion. By completing this practice [@problem_id:2634419], you will see how the familiar Quasi-Steady-State (QSS) approximation emerges as the leading-order term and how singular perturbation theory provides a systematic way to calculate higher-order corrections for improved accuracy.", "problem": "Consider a two-species linear reaction network that models a slowly decaying reactant and a fast intermediate, expressed in nondimensional form with a small separation parameter $\\varepsilon \\in (0,1]$. Let $x(t)$ denote the slow variable (reactant) and $y(t)$ denote the fast variable (intermediate). The dynamics are given by the linear time-invariant system\n$$\n\\frac{dx}{dt} \\;=\\; -k_{s}\\,x \\;-\\; k_{c}\\,y, \n\\qquad\n\\varepsilon\\,\\frac{dy}{dt} \\;=\\; k_{c}\\,x \\;-\\; k_{f}\\,y,\n$$\nwith positive parameters $k_{s}>0$, $k_{c}>0$, and $k_{f}>0$. This system arises from mass-action kinetics with one slow consumption channel of $x$ of rate $k_{s}$ and a fast exchange between $x$ and $y$ characterized by $k_{c}$ and $k_{f}$. The Quasi-Steady State (QSS) approximation corresponds to the lowest-order slow invariant manifold $y=h_{0}(x)$ obtained by setting the fast right-hand side to zero.\n\nUsing singular perturbation theory consistent with Computational Singular Perturbation (CSP), construct the slow invariant manifold as a regular expansion $y=h(x;\\varepsilon)=h_{0}(x)+\\varepsilon h_{1}(x)+\\mathcal{O}(\\varepsilon^{2})$ by enforcing invariance under the full dynamics to first order in $\\varepsilon$. Start from fundamental principles, namely mass-action kinetics and the chain rule for invariant manifolds, and derive the condition that determines $h_{0}(x)$ and $h_{1}(x)$ without invoking any prepackaged formula.\n\nReport only the closed-form analytic expression for the first-order correction $h_{1}(x)$ in terms of $x$, $k_{s}$, $k_{c}$, and $k_{f}$. No numerical evaluation is required. The final answer must be a single analytic expression. Do not include units.", "solution": "The problem presented is judged to be valid. It is a well-posed, scientifically grounded problem in the field of chemical kinetics and singular perturbation theory. All necessary data and conditions are provided, and the problem is free of contradictions, ambiguities, or factual unsoundness. We may therefore proceed with the derivation of the solution.\n\nThe system of ordinary differential equations describing the dynamics of the slow variable $x(t)$ and the fast variable $y(t)$ is given by:\n$$\n\\frac{dx}{dt} = f(x, y) = -k_{s}x - k_{c}y\n$$\n$$\n\\varepsilon \\frac{dy}{dt} = g(x, y) = k_{c}x - k_{f}y\n$$\nwhere $k_{s}$, $k_{c}$, and $k_{f}$ are positive rate constants and $\\varepsilon$ is a small, positive parameter, $\\varepsilon \\ll 1$.\n\nWe seek to find the slow invariant manifold, which is a curve $y = h(x; \\varepsilon)$ in the phase space such that any trajectory that starts on this manifold remains on it for all subsequent time. The mathematical expression of this invariance property is that the time evolution of a point $(x(t), y(t))$ on the manifold must be tangent to the manifold at that point. If $y(t) = h(x(t); \\varepsilon)$, then by the chain rule, their time derivatives must be related by:\n$$\n\\frac{dy}{dt} = \\frac{dh(x; \\varepsilon)}{dx} \\frac{dx}{dt}\n$$\nThis is the fundamental invariance condition. We can substitute the expressions for $\\frac{dx}{dt}$ and $\\frac{dy}{dt}$ from the given system dynamics into this condition. From the second equation, we have $\\frac{dy}{dt} = \\frac{1}{\\varepsilon} g(x,y)$, so the invariance condition becomes:\n$$\n\\frac{1}{\\varepsilon} g(x, y) = \\frac{dh}{dx} f(x, y)\n$$\nSubstituting $y = h(x; \\varepsilon)$ into this equation yields the defining functional-differential equation for the invariant manifold $h(x; \\varepsilon)$:\n$$\nk_{c}x - k_{f}h(x; \\varepsilon) = \\varepsilon \\frac{dh(x; \\varepsilon)}{dx} (-k_{s}x - k_{c}h(x; \\varepsilon))\n$$\nThe problem asks for the first-order approximation of this manifold, which we represent as a regular perturbation expansion in $\\varepsilon$:\n$$\nh(x; \\varepsilon) = h_{0}(x) + \\varepsilon h_{1}(x) + \\mathcal{O}(\\varepsilon^{2})\n$$\nThe derivative with respect to $x$ is accordingly:\n$$\n\\frac{dh(x; \\varepsilon)}{dx} = \\frac{dh_{0}(x)}{dx} + \\varepsilon \\frac{dh_{1}(x)}{dx} + \\mathcal{O}(\\varepsilon^{2})\n$$\nWe now substitute these expansions into the invariance equation:\n$$\nk_{c}x - k_{f}(h_{0} + \\varepsilon h_{1} + \\dots) = \\varepsilon \\left(\\frac{dh_{0}}{dx} + \\varepsilon \\frac{dh_{1}}{dx} + \\dots\\right) \\left(-k_{s}x - k_{c}(h_{0} + \\varepsilon h_{1} + \\dots)\\right)\n$$\nTo solve for $h_{0}(x)$ and $h_{1}(x)$, we expand both sides and collect terms of like powers in $\\varepsilon$.\n\nThe left-hand side (LHS) expands to:\n$$\n\\text{LHS} = (k_{c}x - k_{f}h_{0}(x)) - \\varepsilon k_{f}h_{1}(x) + \\mathcal{O}(\\varepsilon^{2})\n$$\nThe right-hand side (RHS) expands to:\n$$\n\\text{RHS} = \\varepsilon \\left(\\frac{dh_{0}}{dx}\\right) (-k_{s}x - k_{c}h_{0}(x)) + \\mathcal{O}(\\varepsilon^{2})\n$$\nEquating the expressions for the LHS and RHS, we obtain:\n$$\n(k_{c}x - k_{f}h_{0}) - \\varepsilon k_{f}h_{1} + \\mathcal{O}(\\varepsilon^{2}) = \\varepsilon \\frac{dh_{0}}{dx}(-k_{s}x - k_{c}h_{0}) + \\mathcal{O}(\\varepsilon^{2})\n$$\nNow we equate the coefficients of corresponding powers of $\\varepsilon$.\n\nAt order $\\mathcal{O}(\\varepsilon^{0})$:\nThe terms independent of $\\varepsilon$ must be equal.\n$$\nk_{c}x - k_{f}h_{0}(x) = 0\n$$\nSolving for $h_{0}(x)$ gives the zeroth-order approximation to the slow manifold, which is the Quasi-Steady State (QSS) approximation:\n$$\nh_{0}(x) = \\frac{k_{c}}{k_{f}}x\n$$\n\nAt order $\\mathcal{O}(\\varepsilon^{1})$:\nThe terms proportional to $\\varepsilon$ must be equal.\n$$\n-k_{f}h_{1}(x) = \\frac{dh_{0}}{dx}(-k_{s}x - k_{c}h_{0}(x))\n$$\nWe have already determined $h_{0}(x)$. We can now find its derivative:\n$$\n\\frac{dh_{0}}{dx} = \\frac{d}{dx}\\left(\\frac{k_{c}}{k_{f}}x\\right) = \\frac{k_{c}}{k_{f}}\n$$\nSubstituting the expressions for $h_{0}(x)$ and $\\frac{dh_{0}}{dx}$ into the $\\mathcal{O}(\\varepsilon^{1})$ equation:\n$$\n-k_{f}h_{1}(x) = \\left(\\frac{k_{c}}{k_{f}}\\right) \\left(-k_{s}x - k_{c}\\left(\\frac{k_{c}}{k_{f}}x\\right)\\right)\n$$\nWe can factor out $x$ on the right-hand side:\n$$\n-k_{f}h_{1}(x) = \\left(\\frac{k_{c}}{k_{f}}\\right) \\left(-k_{s} - \\frac{k_{c}^{2}}{k_{f}}\\right) x\n$$\n$$\n-k_{f}h_{1}(x) = -\\frac{k_{c}}{k_{f}} \\left(k_{s} + \\frac{k_{c}^{2}}{k_{f}}\\right) x\n$$\nNow, we solve for $h_{1}(x)$ by dividing by $-k_{f}$:\n$$\nh_{1}(x) = \\frac{k_{c}}{k_{f}^{2}} \\left(k_{s} + \\frac{k_{c}^{2}}{k_{f}}\\right) x\n$$\nTo present this in a more compact form, we combine the terms inside the parenthesis:\n$$\nh_{1}(x) = \\frac{k_{c}}{k_{f}^{2}} \\left(\\frac{k_{s}k_{f} + k_{c}^{2}}{k_{f}}\\right) x\n$$\n$$\nh_{1}(x) = \\frac{k_{c}(k_{s}k_{f} + k_{c}^{2})}{k_{f}^{3}} x\n$$\nThis is the closed-form analytic expression for the first-order correction, $h_{1}(x)$, to the slow invariant manifold. The full first-order manifold is $y = h_{0}(x) + \\varepsilon h_{1}(x)$. The problem asks only for the expression for $h_{1}(x)$.", "answer": "$$\n\\boxed{\\frac{k_{c}(k_{s}k_{f} + k_{c}^{2})}{k_{f}^{3}} x}\n$$", "id": "2634419"}, {"introduction": "Theory must be validated by practice. This final exercise applies the principles of slow manifold construction to a nonlinear chemical network, culminating in a numerical experiment to quantify the benefits of model reduction. You will implement both a basic zero-order and a more refined first-order CSP model and compare their simulations against the true dynamics of the full system [@problem_id:2634446]. This capstone problem demonstrates the practical power of CSP, showing how higher-order corrections lead to measurably more accurate and reliable reduced models.", "problem": "Implement a complete program that, for a specified two-species nonlinear reaction network with a clear slow-fast structure, constructs zero-order and first-order Computational Singular Perturbation (CSP) slow manifolds, projects the dynamics onto these manifolds to obtain reduced one-dimensional dynamics, and quantitatively compares the resulting trajectories to the full two-dimensional dynamics over one slow timescale. All concentrations and time are nondimensional. The program must use only the Python standard library, NumPy, and SciPy as specified in the execution environment.\n\nThe network is defined by two species, denoted by $x$ (slow) and $y$ (fast), with governing equations\n$$\n\\frac{dx}{dt} = \\varepsilon \\, f(x,y), \\quad \\frac{dy}{dt} = g(x,y),\n$$\nwhere $\\varepsilon$ is a small positive parameter. The functions $f$ and $g$ are derived from mass-action kinetics for the following schematic network: a slow inflow and decay of $x$ and a fast reversible interconversion between $x$ and $y$ together with a nonlinear quadratic sink of $y$ and a linear decay of $y$. Concretely, let\n$$\nf(x,y) = s - d \\, x - k_f \\, x + k_b \\, y,\n$$\n$$\ng(x,y) = k_f \\, x - k_b \\, y - 2 k_2 \\, y^2 - k_3 \\, y,\n$$\nwith parameters $s, d, k_f, k_b, k_2, k_3  0$. This yields a standard Computational Singular Perturbation (CSP) setup of the form $\\dot{x} = \\varepsilon f(x,y)$, $\\dot{y} = g(x,y)$.\n\nYour tasks are:\n- Use the foundational principles of mass-action kinetics (with rate expressions of the form $k \\, \\prod c_i^{\\nu_i}$ for concentration $c_i$ and stoichiometric coefficient $\\nu_i$) and the invariance condition for slow manifolds to construct the zero-order and first-order CSP manifolds. The zero-order manifold $y = h_0(x)$ is defined by the quasi-steady-state condition for the fast variable,\n$$\ng(x,h_0(x)) = 0.\n$$\nGiven the quadratic nonlinearity in $y$, explicitly solve for $h_0(x)$ by solving $2 k_2 \\, y^2 + (k_b+k_3) \\, y - k_f \\, x = 0$ and choosing the nonnegative root,\n$$\nh_0(x) = \\frac{- (k_b + k_3) + \\sqrt{(k_b + k_3)^2 + 8 \\, k_2 \\, k_f \\, x}}{4 \\, k_2}.\n$$\n- Derive the first-order correction $h_1(x)$ using the invariance condition. The invariance condition states that along the slow manifold $y=h(x,\\varepsilon)$, one must have $g(x,h(x,\\varepsilon)) = \\varepsilon \\, h'(x,\\varepsilon) \\, f(x,h(x,\\varepsilon))$. With the expansion $h(x,\\varepsilon) = h_0(x) + \\varepsilon h_1(x) + \\mathcal{O}(\\varepsilon^2)$ and denoting $g_y = \\partial g / \\partial y$ and $g_x = \\partial g / \\partial x$, the order $\\varepsilon^0$ condition yields $g(x,h_0(x))=0$, and differentiating implicitly gives $h_0'(x) = - g_x(x,h_0(x)) / g_y(x,h_0(x))$. The order $\\varepsilon^1$ condition yields\n$$\ng_y(x,h_0(x)) \\, h_1(x) = h_0'(x) \\, f(x,h_0(x)),\n$$\nhence\n$$\nh_1(x) = \\frac{h_0'(x) \\, f(x,h_0(x))}{g_y(x,h_0(x))}.\n$$\nFor this network, compute $g_x(x,y) = k_f$ and $g_y(x,y) = -k_b - k_3 - 4 k_2 \\, y$, so that $h_0'(x) = \\dfrac{k_f}{k_b + k_3 + 4 k_2 \\, h_0(x)}$ and then $h_1(x)$ follows from the formula above.\n\n- Define the reduced one-dimensional slow dynamics obtained by substituting the manifold approximations into the slow equation:\n  - Zero-order CSP reduced dynamics: $\\dfrac{dx}{dt} = \\varepsilon \\, f\\!\\left(x, h_0(x)\\right)$ with $y(t) = h_0(x(t))$.\n  - First-order CSP reduced dynamics: $\\dfrac{dx}{dt} = \\varepsilon \\, f\\!\\left(x, h_0(x) + \\varepsilon \\, h_1(x)\\right)$ with $y(t) = h_0(x(t)) + \\varepsilon \\, h_1(x(t))$.\n\n- For each parameter set given in the test suite below, perform the following numerical experiment:\n  1. Integrate the full two-dimensional system from the specified initial condition $(x(0),y(0))$ over the time interval $[0, T]$ with $T = 1/\\varepsilon$.\n  2. Integrate the zero-order reduced one-dimensional system over the same time interval, starting from $x(0)$ equal to the same initial $x(0)$ as the full system, and reconstruct $y(t)$ from the manifold relation $y=h_0(x(t))$.\n  3. Integrate the first-order reduced one-dimensional system over the same time interval, starting from $x(0)$ equal to the same initial $x(0)$, and reconstruct $y(t)$ from $y=h_0(x(t))+\\varepsilon h_1(x(t))$.\n  4. On a common time grid spanning $[0,T]$, compute the maximum-in-time Euclidean norm of the concentration error between each reduced trajectory and the full trajectory,\n  $$\n  e_0 = \\max_{t \\in [0,T]} \\left\\| \\begin{bmatrix} x_{\\text{red},0}(t) - x_{\\text{full}}(t) \\\\ y_{\\text{red},0}(t) - y_{\\text{full}}(t) \\end{bmatrix} \\right\\|_2, \\quad\n  e_1 = \\max_{t \\in [0,T]} \\left\\| \\begin{bmatrix} x_{\\text{red},1}(t) - x_{\\text{full}}(t) \\\\ y_{\\text{red},1}(t) - y_{\\text{full}}(t) \\end{bmatrix} \\right\\|_2.\n  $$\n  5. Report, for each test case, the triple $[e_0, e_1, \\text{improved}]$, where $\\text{improved}$ is a boolean that is true if and only if $e_1  e_0$.\n\nTest suite:\n- Case $1$: $\\varepsilon = 0.02$, $k_f = 5.0$, $k_b = 1.0$, $k_2 = 2.0$, $k_3 = 0.5$, $s = 1.0$, $d = 0.1$, initial $(x(0),y(0)) = (0.5, 0.05)$.\n- Case $2$: $\\varepsilon = 0.005$, $k_f = 6.0$, $k_b = 1.0$, $k_2 = 4.0$, $k_3 = 0.2$, $s = 0.8$, $d = 0.05$, initial $(x(0),y(0)) = (0.3, 0.9)$.\n- Case $3$: $\\varepsilon = 0.02$, $k_f = 3.0$, $k_b = 1.0$, $k_2 = 0.1$, $k_3 = 0.4$, $s = 0.5$, $d = 0.05$, initial $(x(0),y(0)) = (0.4, 0.1)$.\n- Case $4$: $\\varepsilon = 0.10$, $k_f = 4.0$, $k_b = 1.2$, $k_2 = 1.5$, $k_3 = 0.6$, $s = 1.2$, $d = 0.2$, initial $(x(0),y(0)) = (0.6, 0.2)$.\n\nNumerical requirements:\n- Use an implicit stiff solver appropriate for stiff dynamics (for example, a backward differentiation formula) for the full two-dimensional system, and any suitable accurate integrator for the reduced systems. Use a uniform time grid on $[0,T]$ for error evaluation with at least $200$ points.\n- All computations are nondimensional; no physical units are required.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each test case result is itself a list of the form $[e_0, e_1, \\text{improved}]$. For example, an output with two cases would look like $[[0.1,0.05,True],[0.2,0.18,True]]$.", "solution": "We begin with a two-species system in standard slow-fast form,\n$$\n\\frac{dx}{dt} = \\varepsilon \\, f(x,y), \\quad \\frac{dy}{dt} = g(x,y),\n$$\nwhere $\\varepsilon$ is small and positive, so that $x$ evolves on a slow timescale and $y$ relaxes rapidly. The functions $f$ and $g$ arise from mass-action kinetics, a foundational principle stating that reaction rates have the form $k \\, \\prod c_i^{\\nu_i}$, where $k$ is a rate constant, $c_i$ are species concentrations, and $\\nu_i$ are stoichiometric exponents. The chosen network yields\n$$\nf(x,y) = s - d \\, x - k_f \\, x + k_b \\, y,\n$$\n$$\ng(x,y) = k_f \\, x - k_b \\, y - 2 k_2 \\, y^2 - k_3 \\, y,\n$$\nwith positive rate parameters $s, d, k_f, k_b, k_2, k_3$.\n\nComputational Singular Perturbation (CSP) approximates the slow invariant manifold on which the fast dynamics is equilibrated, using an asymptotic expansion in $\\varepsilon$. The invariance condition for a manifold $y=h(x,\\varepsilon)$ states that the vector field evaluated at points on the manifold is tangent to the manifold graph:\n$$\n\\frac{dy}{dt} = \\frac{d}{dt} h(x,\\varepsilon) = \\frac{\\partial h}{\\partial x}(x,\\varepsilon) \\, \\frac{dx}{dt},\n$$\nand since on the manifold $\\dfrac{dx}{dt} = \\varepsilon f(x,h(x,\\varepsilon))$ and $\\dfrac{dy}{dt} = g(x,h(x,\\varepsilon))$, the invariance condition becomes\n$$\ng(x,h(x,\\varepsilon)) = \\varepsilon \\, h'(x,\\varepsilon) \\, f(x,h(x,\\varepsilon)).\n$$\nWe seek an asymptotic expansion $h(x,\\varepsilon) = h_0(x) + \\varepsilon h_1(x) + \\mathcal{O}(\\varepsilon^2)$, and substitute into the invariance condition. Expanding the left-hand side to order $\\varepsilon$ gives\n$$\ng(x,h_0(x) + \\varepsilon h_1(x)) = g(x,h_0(x)) + \\varepsilon \\, g_y(x,h_0(x)) \\, h_1(x) + \\mathcal{O}(\\varepsilon^2),\n$$\nwhere $g_y = \\partial g / \\partial y$. The right-hand side to order $\\varepsilon$ is\n$$\n\\varepsilon \\, h'(x,\\varepsilon) \\, f(x,h(x,\\varepsilon)) = \\varepsilon \\, h_0'(x) \\, f(x,h_0(x)) + \\mathcal{O}(\\varepsilon^2).\n$$\nEquating orders of $\\varepsilon$ yields:\n- Order $\\varepsilon^0$: $g(x,h_0(x)) = 0$, which defines the zero-order slow manifold $h_0$ as the quasi-steady-state for the fast dynamics.\n- Order $\\varepsilon^1$: $g_y(x,h_0(x)) \\, h_1(x) = h_0'(x) \\, f(x,h_0(x))$, which determines the first-order correction $h_1(x)$ once $h_0$ is known and differentiable.\n\nFor the specific $g(x,y)$ given, $g(x,y) = k_f x - k_b y - 2 k_2 y^2 - k_3 y$, the zero-order manifold solves\n$$\n2 k_2 \\, y^2 + (k_b + k_3) \\, y - k_f \\, x = 0,\n$$\nwhich yields\n$$\nh_0(x) = \\frac{- (k_b + k_3) + \\sqrt{(k_b + k_3)^2 + 8 k_2 k_f x}}{4 k_2},\n$$\nselecting the nonnegative root. Differentiating the identity $g(x,h_0(x)) \\equiv 0$ with respect to $x$ gives\n$$\ng_x(x,h_0(x)) + g_y(x,h_0(x)) \\, h_0'(x) = 0 \\quad \\Rightarrow \\quad h_0'(x) = -\\frac{g_x(x,h_0(x))}{g_y(x,h_0(x))},\n$$\nand here $g_x(x,y) = k_f$ and $g_y(x,y) = -k_b - k_3 - 4 k_2 y$, so\n$$\nh_0'(x) = \\frac{k_f}{k_b + k_3 + 4 k_2 \\, h_0(x)}.\n$$\nThe first-order correction then follows from the order $\\varepsilon^1$ condition:\n$$\nh_1(x) = \\frac{h_0'(x) \\, f(x,h_0(x))}{g_y(x,h_0(x))}.\n$$\n\nTo assess the fidelity of these manifolds in reproducing the full dynamics over one slow timescale, define $T = 1/\\varepsilon$. We compare:\n- The full trajectory $(x_{\\text{full}}(t), y_{\\text{full}}(t))$ solving the two-dimensional system from the given initial condition $(x(0),y(0))$ over $t \\in [0,T]$.\n- The zero-order reduced trajectory $(x_{\\text{red},0}(t), y_{\\text{red},0}(t))$ solving $\\dot{x} = \\varepsilon f(x,h_0(x))$ with $x(0)$ matching the full system's initial $x(0)$ and $y_{\\text{red},0}(t) = h_0(x_{\\text{red},0}(t))$.\n- The first-order reduced trajectory $(x_{\\text{red},1}(t), y_{\\text{red},1}(t))$ solving $\\dot{x} = \\varepsilon f(x,h_0(x)+\\varepsilon h_1(x))$ with $x(0)$ matching the full system's initial $x(0)$ and $y_{\\text{red},1}(t) = h_0(x_{\\text{red},1}(t)) + \\varepsilon h_1(x_{\\text{red},1}(t))$.\n\nOn a uniform grid of times in $[0,T]$, we compute the maximum Euclidean concentration error over the interval,\n$$\ne_0 = \\max_{t \\in [0,T]} \\left\\| \\begin{bmatrix} x_{\\text{red},0}(t) - x_{\\text{full}}(t) \\\\ y_{\\text{red},0}(t) - y_{\\text{full}}(t) \\end{bmatrix} \\right\\|_2, \\quad\ne_1 = \\max_{t \\in [0,T]} \\left\\| \\begin{bmatrix} x_{\\text{red},1}(t) - x_{\\text{full}}(t) \\\\ y_{\\text{red},1}(t) - y_{\\text{full}}(t) \\end{bmatrix} \\right\\|_2.\n$$\nWe then output $[e_0, e_1, \\text{improved}]$ for each case, where $\\text{improved}$ is true if $e_1  e_0$.\n\nAlgorithmic design:\n- Construct $h_0(x)$ explicitly via the quadratic formula to satisfy $g(x,h_0(x))=0$.\n- Compute $h_0'(x)$ via implicit differentiation as $h_0'(x) = - g_x / g_y$, using the known partial derivatives.\n- Compute $h_1(x)$ via $h_1(x) = h_0'(x) f(x,h_0(x)) / g_y(x,h_0(x))$.\n- Integrate the full two-dimensional system with a stiff solver, such as a backward differentiation formula, to handle the rapidly relaxing $y$ dynamics.\n- Integrate the one-dimensional reduced dynamics for both zero-order and first-order approximations. Reconstruct $y$ along each reduced trajectory from the corresponding manifold relation.\n- Evaluate the maximum Euclidean error on a uniform time grid over $[0,T]$ for each reduced trajectory compared to the full trajectory.\n- Assemble and print the results as specified.\n\nThe provided test suite includes four parameter sets probing different aspects: a typical stiff case, a more extreme stiffness with stronger nonlinearity, a near-linear fast dynamics case with small quadratic nonlinearity, and a borderline case with larger $\\varepsilon$. The boolean indicator reveals whether the first-order CSP manifold improves the approximation over the zero-order manifold in each scenario.\n\nAll quantities are nondimensional, so no physical units are involved. The final output is a single line containing a Python-like list of lists, one per test case, each holding two floating-point errors and one boolean as described.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef make_params(eps, kf, kb, k2, k3, s, d, x0, y0):\n    return {\n        \"eps\": float(eps),\n        \"kf\": float(kf),\n        \"kb\": float(kb),\n        \"k2\": float(k2),\n        \"k3\": float(k3),\n        \"s\": float(s),\n        \"d\": float(d),\n        \"x0\": float(x0),\n        \"y0\": float(y0),\n    }\n\ndef f_slow(x, y, p):\n    return p[\"s\"] - p[\"d\"] * x - p[\"kf\"] * x + p[\"kb\"] * y\n\ndef g_fast(x, y, p):\n    return p[\"kf\"] * x - p[\"kb\"] * y - 2.0 * p[\"k2\"] * y * y - p[\"k3\"] * y\n\ndef h0(x, p):\n    # Solve 2*k2*y^2 + (kb+k3)*y - kf*x = 0 for nonnegative y\n    a = 2.0 * p[\"k2\"]\n    b = p[\"kb\"] + p[\"k3\"]\n    disc = b * b + 8.0 * p[\"k2\"] * p[\"kf\"] * x\n    # Numerical safety: ensure nonnegative discriminant\n    disc = max(disc, 0.0)\n    y = (-b + np.sqrt(disc)) / (2.0 * a)\n    return y\n\ndef g_x(p):\n    return p[\"kf\"]\n\ndef g_y_at(x, y, p):\n    return -p[\"kb\"] - p[\"k3\"] - 4.0 * p[\"k2\"] * y\n\ndef h0_prime(x, p):\n    y = h0(x, p)\n    gy = g_y_at(x, y, p)\n    # h0' = -g_x / g_y\n    return -g_x(p) / gy\n\ndef h1(x, p):\n    y0 = h0(x, p)\n    gy = g_y_at(x, y0, p)\n    h0p = h0_prime(x, p)\n    f0 = f_slow(x, y0, p)\n    return (h0p * f0) / gy\n\ndef full_system_rhs(t, z, p):\n    x, y = z\n    dxdt = p[\"eps\"] * f_slow(x, y, p)\n    dydt = g_fast(x, y, p)\n    return [dxdt, dydt]\n\ndef reduced_zero_rhs(t, x, p):\n    # dx/dt = eps * f(x, h0(x))\n    return p[\"eps\"] * f_slow(x, h0(x, p), p)\n\ndef reduced_first_rhs(t, x, p):\n    # dx/dt = eps * f(x, h0(x) + eps * h1(x))\n    y_approx = h0(x, p) + p[\"eps\"] * h1(x, p)\n    return p[\"eps\"] * f_slow(x, y_approx, p)\n\ndef integrate_full(p, T, t_eval):\n    z0 = [p[\"x0\"], p[\"y0\"]]\n    sol = solve_ivp(\n        fun=lambda t, z: full_system_rhs(t, z, p),\n        t_span=(0.0, T),\n        y0=z0,\n        method=\"BDF\",\n        t_eval=t_eval,\n        rtol=1e-10,\n        atol=1e-12,\n    )\n    if not sol.success:\n        raise RuntimeError(\"Full system integration failed: \" + sol.message)\n    return sol.t, sol.y[0, :], sol.y[1, :]\n\ndef integrate_reduced(rhs, p, T, t_eval):\n    x0 = p[\"x0\"]\n    sol = solve_ivp(\n        fun=lambda t, x: rhs(t, x, p),\n        t_span=(0.0, T),\n        y0=[x0],\n        method=\"BDF\",\n        t_eval=t_eval,\n        rtol=1e-12,\n        atol=1e-14,\n    )\n    if not sol.success:\n        raise RuntimeError(\"Reduced system integration failed: \" + sol.message)\n    return sol.t, sol.y[0, :]\n\ndef max_traj_error(xr, yr, xf, yf):\n    # Compute max over time of Euclidean norm error between reduced and full trajectories\n    dx = xr - xf\n    dy = yr - yf\n    errs = np.sqrt(dx * dx + dy * dy)\n    return float(np.max(errs))\n\ndef run_case(p):\n    # Define slow timescale horizon\n    T = 1.0 / p[\"eps\"]\n    # Time grid for error evaluation\n    n_points = 401  # dense enough while efficient\n    t_eval = np.linspace(0.0, T, n_points)\n\n    # Integrate full system\n    t_full, x_full, y_full = integrate_full(p, T, t_eval)\n\n    # Integrate zero-order reduced system and reconstruct y\n    t0, x0 = integrate_reduced(reduced_zero_rhs, p, T, t_eval)\n    y0 = np.array([h0(x, p) for x in x0])\n\n    # Integrate first-order reduced system and reconstruct y\n    t1, x1 = integrate_reduced(reduced_first_rhs, p, T, t_eval)\n    y1 = np.array([h0(x, p) + p[\"eps\"] * h1(x, p) for x in x1])\n\n    # Compute errors (ensure time grids align)\n    assert np.allclose(t_full, t0) and np.allclose(t_full, t1)\n    e0 = max_traj_error(x0, y0, x_full, y_full)\n    e1 = max_traj_error(x1, y1, x_full, y_full)\n    improved = e1  e0\n    return [e0, e1, improved]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        make_params(eps=0.02, kf=5.0, kb=1.0, k2=2.0, k3=0.5, s=1.0, d=0.1, x0=0.5, y0=0.05),\n        make_params(eps=0.005, kf=6.0, kb=1.0, k2=4.0, k3=0.2, s=0.8, d=0.05, x0=0.3, y0=0.9),\n        make_params(eps=0.02, kf=3.0, kb=1.0, k2=0.1, k3=0.4, s=0.5, d=0.05, x0=0.4, y0=0.1),\n        make_params(eps=0.10, kf=4.0, kb=1.2, k2=1.5, k3=0.6, s=1.2, d=0.2, x0=0.6, y0=0.2),\n    ]\n\n    results = []\n    for p in test_cases:\n        res = run_case(p)\n        # Convert floats to a reasonable precision for stable output\n        e0, e1, improved = res\n        e0_out = float(np.float64(e0))\n        e1_out = float(np.float64(e1))\n        results.append([e0_out, e1_out, improved])\n\n    # Final print statement in the exact required format.\n    # Ensure booleans are represented as True/False without quotes.\n    def elem_to_str(elem):\n        if isinstance(elem, bool):\n            return \"True\" if elem else \"False\"\n        if isinstance(elem, float):\n            # Format with repr to avoid scientific notation ambiguity while keeping precision\n            return repr(elem)\n        if isinstance(elem, int):\n            return str(elem)\n        if isinstance(elem, list):\n            return \"[\" + \",\".join(elem_to_str(e) for e in elem) + \"]\"\n        return str(elem)\n\n    print(\"[\" + \",\".join(elem_to_str(r) for r in results) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2634446"}]}