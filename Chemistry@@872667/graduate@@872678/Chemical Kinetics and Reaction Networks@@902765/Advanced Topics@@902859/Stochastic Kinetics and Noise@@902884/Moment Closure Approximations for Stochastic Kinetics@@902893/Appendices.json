{"hands_on_practices": [{"introduction": "Before applying moment closure approximations to complex systems, it is essential to master the underlying mathematical mechanics. This first exercise focuses on the fundamental consequence of the Gaussian closure assumption: the vanishing of higher-order cumulants. By deriving expressions for lower-order moments based on this assumption, you will build a foundational understanding of how the closure is used to create a self-contained system of equations from an otherwise infinite hierarchy [@problem_id:2657882].", "problem": "Consider a well-mixed stochastic reaction network with a single chemical species $A$ undergoing the reactions $\\varnothing \\xrightarrow{\\lambda} A$ and $2A \\xrightarrow{k} \\varnothing$ under the Chemical Master Equation (CME). Let $X$ denote the random copy number of species $A$. The moment dynamics for this network involve higher-order moments through the mass-action propensity associated with the bimolecular reaction, which depends on the factorial moment $E[X(X-1)]$. To close the moment hierarchy, employ the Gaussian closure assumption: approximate the distribution of $X$ by a univariate Gaussian distribution such that all cumulants of order higher than second vanish. Let $m = E[X]$ and $\\sigma^{2} = \\mathrm{Var}[X]$ denote the mean and variance, respectively.\n\nUsing only foundational probabilistic definitions (raw moments, central moments, cumulants) and the defining properties of the Gaussian distribution under the Gaussian closure assumption, derive closed-form expressions for the following quantities in terms of $m$ and $\\sigma^{2}$:\n- $E[X(X-1)]$\n- $E[X^{3}]$\n- $E[X^{4}]$\n\nYour final answer must be a single analytical expression that lists these three expressions in the stated order. No numerical evaluation is required, and no rounding is needed. Do not include any physical units in your answer.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Chemical species: $A$\n- Reactions: $\\varnothing \\xrightarrow{\\lambda} A$ and $2A \\xrightarrow{k} \\varnothing$\n- Stochastic variable: $X$ is the copy number of species $A$.\n- Moments: $m = E[X]$ (mean), $\\sigma^{2} = \\mathrm{Var}[X]$ (variance).\n- Closure assumption: The distribution of $X$ is approximated by a univariate Gaussian distribution. This implies that all cumulants of order higher than second are zero.\n- Task: Derive expressions for $E[X(X-1)]$, $E[X^{3}]$, and $E[X^{4}]$ in terms of $m$ and $\\sigma^{2}$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Groundedness**: The problem is correctly situated within the field of stochastic chemical kinetics. The use of moment closure, specifically Gaussian closure, is a standard and valid approximation technique for solving the Chemical Master Equation when analytical solutions are intractable. The relationships between moments, central moments, and cumulants are fundamental concepts in probability theory. The problem is scientifically and mathematically sound.\n- **Well-Posedness**: The problem is well-posed. It provides a clear, unambiguous assumption (Gaussian closure) and asks for specific quantities to be derived based on this assumption. A unique, stable, and meaningful solution exists and can be derived through standard mathematical procedures.\n- **Objectivity**: The problem is stated in precise, objective language, free of any subjective or non-scientific claims.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. It is a standard exercise in the application of moment closure methods. A full solution will be provided.\n\nThe core of the problem lies in the relationship between the raw moments ($\\mu_n' = E[X^n]$), central moments ($\\mu_n = E[(X-m)^n]$), and cumulants ($\\kappa_n$) of a probability distribution. The Gaussian closure assumption posits that the distribution is Gaussian. A defining property of the Gaussian distribution is that all of its cumulants of order $n > 2$ are identically zero.\n\nThe first two cumulants are defined as the mean and the variance, respectively:\n$$ \\kappa_1 = E[X] = m $$\n$$ \\kappa_2 = \\mathrm{Var}[X] = \\sigma^2 $$\n\nThe Gaussian closure assumption imposes the condition:\n$$ \\kappa_n = 0 \\quad \\text{for all } n > 2 $$\n\nWe will use the general formulas that express raw moments in terms of cumulants to derive the required quantities.\n\n**1. Derivation of $E[X(X-1)]$**\nThis quantity is the second factorial moment. By linearity of expectation, we have:\n$$ E[X(X-1)] = E[X^2 - X] = E[X^2] - E[X] $$\nWe require the second raw moment, $E[X^2]$. The relationship between the second raw moment and the first two cumulants is given by:\n$$ \\mu_2' = E[X^2] = \\kappa_2 + \\kappa_1^2 $$\nSubstituting the given definitions $\\kappa_1 = m$ and $\\kappa_2 = \\sigma^2$:\n$$ E[X^2] = \\sigma^2 + m^2 $$\nNow, we can find the expression for the second factorial moment:\n$$ E[X(X-1)] = (\\sigma^2 + m^2) - m = m^2 - m + \\sigma^2 $$\n\n**2. Derivation of $E[X^3]$**\nThis is the third raw moment, $\\mu_3'$. The general formula relating $\\mu_3'$ to the first three cumulants is:\n$$ \\mu_3' = E[X^3] = \\kappa_3 + 3\\kappa_2\\kappa_1 + \\kappa_1^3 $$\nApplying the Gaussian closure assumption, we set $\\kappa_3 = 0$:\n$$ E[X^3] = 0 + 3\\kappa_2\\kappa_1 + \\kappa_1^3 $$\nSubstituting $\\kappa_1 = m$ and $\\kappa_2 = \\sigma^2$:\n$$ E[X^3] = 3\\sigma^2 m + m^3 = m^3 + 3m\\sigma^2 $$\n\n**3. Derivation of $E[X^4]$**\nThis is the fourth raw moment, $\\mu_4'$. The general formula for $\\mu_4'$ in terms of cumulants up to order four is:\n$$ \\mu_4' = E[X^4] = \\kappa_4 + 4\\kappa_3\\kappa_1 + 3\\kappa_2^2 + 6\\kappa_2\\kappa_1^2 + \\kappa_1^4 $$\nUnder the Gaussian closure assumption, both $\\kappa_3$ and $\\kappa_4$ are zero. The formula simplifies to:\n$$ E[X^4] = 0 + 4(0)\\kappa_1 + 3\\kappa_2^2 + 6\\kappa_2\\kappa_1^2 + \\kappa_1^4 = 3\\kappa_2^2 + 6\\kappa_2\\kappa_1^2 + \\kappa_1^4 $$\nSubstituting $\\kappa_1 = m$ and $\\kappa_2 = \\sigma^2$:\n$$ E[X^4] = 3(\\sigma^2)^2 + 6(\\sigma^2)(m^2) + m^4 = m^4 + 6m^2\\sigma^2 + 3\\sigma^4 $$\nThis completes the derivations for all three required quantities based on the specified closure assumption.", "answer": "$$\\boxed{\\begin{pmatrix} m^{2} - m + \\sigma^{2} & m^{3} + 3m\\sigma^{2} & m^{4} + 6m^{2}\\sigma^{2} + 3\\sigma^{4} \\end{pmatrix}}$$", "id": "2657882"}, {"introduction": "An approximation is only as good as its domain of validity, and a crucial part of scientific modeling is understanding when an approximation breaks down. This practice guides you through a concrete example where the Gaussian closure leads to an unphysical prediction—a negative second factorial moment, which implies a negative variance under certain conditions. By constructing a scenario that demonstrates this failure and outlining a corrective method, you will develop critical insight into the limitations of moment closure and the importance of ensuring physical consistency [@problem_id:2657891].", "problem": "Consider the single-species stochastic reaction network with inflow and dimerization (annihilation) given by the reactions\n- $\\varnothing \\to X$ with rate constant $k_{0}$ (zeroth-order inflow),\n- $2X \\to \\varnothing$ with rate constant $k_{2}$ (second-order annihilation, mass-action propensity $a_{2}(X) = \\frac{k_{2}}{2} X(X-1)$).\n\nLet $X(t)$ denote the random copy number, $m(t) := \\mathbb{E}[X(t)]$ the mean, $f_{2}(t) := \\mathbb{E}[X(t)(X(t)-1)]$ the second factorial moment, and $v(t) := \\operatorname{Var}(X(t)) = \\mathbb{E}[X^{2}(t)] - m^{2}(t) = f_{2}(t) + m(t) - m^{2}(t)$ the variance. Use the generator identity for the Chemical Master Equation (CME), namely\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathbb{E}[g(X)] \\;=\\; \\mathbb{E}\\Bigg[\\sum_{r} a_{r}(X)\\big(g(X+\\nu_{r}) - g(X)\\big)\\Bigg],\n$$\nwhere $a_{r}(X)$ and $\\nu_{r}$ denote the propensity and stoichiometric change of reaction $r$, to derive the exact moment equations for $\\frac{\\mathrm{d}}{\\mathrm{d}t} m$ and $\\frac{\\mathrm{d}}{\\mathrm{d}t} f_{2}$ in terms of $\\mathbb{E}[X^{3}]$. Then close the system by invoking the Gaussian closure (normal approximation), which assumes zero third central moment and yields\n$$\n\\mathbb{E}[X^{3}] \\;=\\; m^{3} + 3 m v \\;=\\; m^{3} + 3 m \\big(f_{2} + m - m^{2}\\big).\n$$\nAnswer the following:\n\n1) Starting from the CME identity, derive exact expressions for $\\frac{\\mathrm{d}}{\\mathrm{d}t} m$ and $\\frac{\\mathrm{d}}{\\mathrm{d}t} f_{2}$, exhibiting the dependence on $\\mathbb{E}[X^{3}]$.\n\n2) Substitute the Gaussian closure expression for $\\mathbb{E}[X^{3}]$ into your formula for $\\frac{\\mathrm{d}}{\\mathrm{d}t} f_{2}$ to obtain a closed expression for $\\frac{\\mathrm{d}}{\\mathrm{d}t} f_{2}$ in terms of $m$ and $f_{2}$.\n\n3) Specialize to the parameter set $k_{0} = 1$ and $k_{2} = 9$ and the state $(m, f_{2}) = \\left(\\frac{3}{4}, 0\\right)$. Evaluate the Gaussian-closure value of $\\left.\\frac{\\mathrm{d}}{\\mathrm{d}t} f_{2}\\right|_{t=0}$ and determine its sign, thereby constructing a regime in which the Gaussian closure yields an immediate violation of nonnegativity, $f_{2}(t) < 0$ for $t > 0$ sufficiently small.\n\n4) Outline a projection-based correction that restores nonnegativity: at the boundary $f_{2} = 0$, keep $m$ fixed and minimally perturb only the third raw moment used by the closure, $\\mathbb{E}[X^{3}]$, so that the corrected instantaneous drift satisfies $\\left.\\frac{\\mathrm{d}}{\\mathrm{d}t} f_{2}\\right|_{t=0}^{\\mathrm{corr}} = 0$. Compute the exact value of the correction\n$$\n\\Delta \\mathbb{E}[X^{3}] \\;:=\\; \\mathbb{E}[X^{3}]_{\\mathrm{corr}} - \\mathbb{E}[X^{3}]_{\\mathrm{Gauss}}\n$$\nat the given parameters and state.\n\nGive your final answer as the exact value of $\\Delta \\mathbb{E}[X^{3}]$ (no units). If a numerical approximation is used, round your answer to four significant figures; otherwise, provide an exact fraction.", "solution": "The problem statement is scientifically grounded, well-posed, objective, and self-contained. It is a valid exercise in the analysis of moment closure approximations for stochastic kinetic systems. We proceed with the solution.\n\nThe stochastic process involves two reactions:\n1.  Zeroth-order inflow: $\\varnothing \\xrightarrow{k_0} X$. The propensity is $a_1(X) = k_0$, and the stoichiometric change is $\\nu_1 = +1$.\n2.  Second-order annihilation: $2X \\xrightarrow{k_2} \\varnothing$. The propensity is $a_2(X) = \\frac{k_2}{2} X(X-1)$, and the stoichiometric change is $\\nu_2 = -2$.\n\nWe are given the generator identity for the time evolution of the expectation of an arbitrary function $g(X)$:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathbb{E}[g(X)] = \\mathbb{E}\\Bigg[\\sum_{r=1}^{2} a_r(X) \\big(g(X+\\nu_r) - g(X)\\big)\\Bigg]\n$$\n\n**1) Derivation of Exact Moment Equations**\n\nWe first derive the equation for the mean, $m(t) = \\mathbb{E}[X(t)]$, by setting $g(X)=X$.\nThe change for reaction $1$ is $a_1(X)(g(X+\\nu_1)-g(X)) = k_0((X+1)-X) = k_0$.\nThe change for reaction $2$ is $a_2(X)(g(X+\\nu_2)-g(X)) = \\frac{k_2}{2}X(X-1)((X-2)-X) = -k_2 X(X-1)$.\nSumming the expectations gives the evolution of the mean:\n$$\n\\frac{\\mathrm{d}m}{\\mathrm{d}t} = \\mathbb{E}[k_0 - k_2 X(X-1)] = k_0 - k_2\\mathbb{E}[X(X-1)]\n$$\nBy definition, $f_2(t) = \\mathbb{E}[X(t)(X(t)-1)]$, so we have:\n$$\n\\frac{\\mathrm{d}m}{\\mathrm{d}t} = k_0 - k_2 f_2\n$$\nThis equation is exact and already closed, not depending on higher moments.\n\nNext, we derive the equation for the second factorial moment, $f_2(t) = \\mathbb{E}[X(t)(X(t)-1)]$, by setting $g(X)=X(X-1)$.\nThe change for reaction $1$ is $a_1(X)(g(X+\\nu_1)-g(X)) = k_0((X+1)X - X(X-1)) = k_0(X^2+X - X^2+X) = 2k_0 X$.\nThe change for reaction $2$ is $a_2(X)(g(X+\\nu_2)-g(X)) = \\frac{k_2}{2}X(X-1)((X-2)(X-3) - X(X-1)) = \\frac{k_2}{2}X(X-1)(X^2-5X+6 - (X^2-X)) = \\frac{k_2}{2}X(X-1)(-4X+6) = -k_2 X(X-1)(2X-3)$.\nSumming the expectations gives the evolution of the second factorial moment:\n$$\n\\frac{\\mathrm{d}f_2}{\\mathrm{d}t} = \\mathbb{E}[2k_0 X - k_2 X(X-1)(2X-3)] = 2k_0\\mathbb{E}[X] - k_2\\mathbb{E}[2X^3 - 5X^2 + 3X]\n$$\nWe express $\\mathbb{E}[X^2]$ in terms of $m$ and $f_2$: $\\mathbb{E}[X^2] = \\mathbb{E}[X(X-1)+X] = f_2+m$.\nSubstituting this into the equation for $\\frac{\\mathrm{d}f_2}{\\mathrm{d}t}$:\n$$\n\\frac{\\mathrm{d}f_2}{\\mathrm{d}t} = 2k_0 m - k_2(2\\mathbb{E}[X^3] - 5\\mathbb{E}[X^2] + 3m) = 2k_0 m - k_2(2\\mathbb{E}[X^3] - 5(f_2+m) + 3m)\n$$\nSimplifying this yields the final exact equation, which exhibits the dependence on $\\mathbb{E}[X^3]$:\n$$\n\\frac{\\mathrm{d}f_2}{\\mathrm{d}t} = 2k_0 m - k_2(2\\mathbb{E}[X^3] - 5f_2 - 2m)\n$$\n\n**2) Gaussian Closure**\n\nThe Gaussian closure approximates the third raw moment $\\mathbb{E}[X^3]$ using the mean $m$, variance $v$, and second factorial moment $f_2$. The variance is $v = \\mathbb{E}[X^2] - m^2 = (f_2+m) - m^2$.\nThe approximation is $\\mathbb{E}[X^3] = m^3 + 3mv$. Substituting the expression for $v$:\n$$\n\\mathbb{E}[X^3]_{\\mathrm{Gauss}} = m^3 + 3m(f_2 + m - m^2)\n$$\nWe substitute this into the exact equation for $\\frac{\\mathrm{d}f_2}{\\mathrm{d}t}$:\n$$\n\\frac{\\mathrm{d}f_2}{\\mathrm{d}t} = 2k_0 m - k_2\\Big(2\\big(m^3 + 3m(f_2+m-m^2)\\big) - 5f_2 - 2m\\Big)\n$$\nWe simplify the term in the parentheses:\n$$\n2m^3 + 6mf_2 + 6m^2 - 6m^3 - 5f_2 - 2m = -4m^3 + 6m^2 - 2m + (6m-5)f_2\n$$\nThe closed equation for $\\frac{\\mathrm{d}f_2}{\\mathrm{d}t}$ is therefore:\n$$\n\\frac{\\mathrm{d}f_2}{\\mathrm{d}t} = 2k_0 m - k_2\\big(-4m^3 + 6m^2 - 2m + (6m-5)f_2\\big)\n$$\n$$\n\\frac{\\mathrm{d}f_2}{\\mathrm{d}t} = 2k_0 m + 2k_2 m(2m^2 - 3m + 1) - k_2(6m-5)f_2\n$$\n\n**3) Negativity Violation**\n\nWe evaluate the closed-form derivative $\\frac{\\mathrm{d}f_2}{\\mathrm{d}t}$ at the specified state.\nParameters: $k_0 = 1$, $k_2 = 9$.\nState at $t=0$: $(m(0), f_2(0)) = \\left(\\frac{3}{4}, 0\\right)$.\nSubstituting these values into the closed equation:\n$$\n\\left.\\frac{\\mathrm{d}f_2}{\\mathrm{d}t}\\right|_{t=0} = 2(1)\\left(\\frac{3}{4}\\right) + 2(9)\\left(\\frac{3}{4}\\right)\\left(2\\left(\\frac{3}{4}\\right)^2 - 3\\left(\\frac{3}{4}\\right) + 1\\right) - 9\\left(6\\left(\\frac{3}{4}\\right)-5\\right)(0)\n$$\n$$\n\\left.\\frac{\\mathrm{d}f_2}{\\mathrm{d}t}\\right|_{t=0} = \\frac{3}{2} + \\frac{27}{2}\\left(2\\left(\\frac{9}{16}\\right) - \\frac{9}{4} + 1\\right) = \\frac{3}{2} + \\frac{27}{2}\\left(\\frac{9}{8} - \\frac{18}{8} + \\frac{8}{8}\\right)\n$$\n$$\n\\left.\\frac{\\mathrm{d}f_2}{\\mathrm{d}t}\\right|_{t=0} = \\frac{3}{2} + \\frac{27}{2}\\left(-\\frac{1}{8}\\right) = \\frac{3}{2} - \\frac{27}{16} = \\frac{24}{16} - \\frac{27}{16} = -\\frac{3}{16}\n$$\nThe sign of $\\left.\\frac{\\mathrm{d}f_2}{\\mathrm{d}t}\\right|_{t=0}$ is negative. Since $f_2(0)=0$ and its time derivative is negative, $f_2(t)$ will become negative for $t>0$ sufficiently small. This violates the physical constraint that $f_2(t) = \\mathbb{E}[X(t)(X(t)-1)] \\ge 0$, as $X(t)$ is a non-negative integer.\n\n**4) Projection-Based Correction**\n\nTo restore nonnegativity, we require the corrected drift $\\left.\\frac{\\mathrm{d}f_2}{\\mathrm{d}t}\\right|_{t=0}^{\\mathrm{corr}}$ to be zero. We achieve this by finding a corrected third moment, $\\mathbb{E}[X^3]_{\\mathrm{corr}}$, which satisfies this condition. We use the **exact** evolution equation for $f_2$:\n$$\n\\left.\\frac{\\mathrm{d}f_2}{\\mathrm{d}t}\\right|_{t=0}^{\\mathrm{corr}} = 2k_0 m(0) - k_2\\big(2\\mathbb{E}[X^3]_{\\mathrm{corr}} - 5f_2(0) - 2m(0)\\big) = 0\n$$\nSubstituting the parameters $k_0 = 1, k_2 = 9$ and state $(m(0), f_2(0)) = \\left(\\frac{3}{4}, 0\\right)$:\n$$\n2(1)\\left(\\frac{3}{4}\\right) - 9\\left(2\\mathbb{E}[X^3]_{\\mathrm{corr}} - 5(0) - 2\\left(\\frac{3}{4}\\right)\\right) = 0\n$$\n$$\n\\frac{3}{2} - 9\\left(2\\mathbb{E}[X^3]_{\\mathrm{corr}} - \\frac{3}{2}\\right) = 0\n$$\n$$\n\\frac{3}{2} - 18\\mathbb{E}[X^3]_{\\mathrm{corr}} + \\frac{27}{2} = 0\n$$\n$$\n18\\mathbb{E}[X^3]_{\\mathrm{corr}} = \\frac{30}{2} = 15\n$$\n$$\n\\mathbb{E}[X^3]_{\\mathrm{corr}} = \\frac{15}{18} = \\frac{5}{6}\n$$\nNow, we calculate the third moment predicted by the Gaussian closure, $\\mathbb{E}[X^3]_{\\mathrm{Gauss}}$, at the same state:\n$$\n\\mathbb{E}[X^3]_{\\mathrm{Gauss}} = m(0)^3 + 3m(0)\\big(f_2(0) + m(0) - m(0)^2\\big)\n$$\n$$\n\\mathbb{E}[X^3]_{\\mathrm{Gauss}} = \\left(\\frac{3}{4}\\right)^3 + 3\\left(\\frac{3}{4}\\right)\\left(0 + \\frac{3}{4} - \\left(\\frac{3}{4}\\right)^2\\right)\n$$\n$$\n\\mathbb{E}[X^3]_{\\mathrm{Gauss}} = \\frac{27}{64} + \\frac{9}{4}\\left(\\frac{3}{4} - \\frac{9}{16}\\right) = \\frac{27}{64} + \\frac{9}{4}\\left(\\frac{12-9}{16}\\right) = \\frac{27}{64} + \\frac{9}{4}\\left(\\frac{3}{16}\\right)\n$$\n$$\n\\mathbb{E}[X^3]_{\\mathrm{Gauss}} = \\frac{27}{64} + \\frac{27}{64} = \\frac{54}{64} = \\frac{27}{32}\n$$\nThe required correction is the difference between these two values:\n$$\n\\Delta \\mathbb{E}[X^3] = \\mathbb{E}[X^3]_{\\mathrm{corr}} - \\mathbb{E}[X^3]_{\\mathrm{Gauss}} = \\frac{5}{6} - \\frac{27}{32}\n$$\nThe least common multiple of $6$ and $32$ is $96$.\n$$\n\\Delta \\mathbb{E}[X^3] = \\frac{5 \\times 16}{96} - \\frac{27 \\times 3}{96} = \\frac{80}{96} - \\frac{81}{96} = -\\frac{1}{96}\n$$\nThis is the minimal perturbation to the third moment, as used by the closure, required to enforce the nonnegativity constraint at the boundary $f_2 = 0$.", "answer": "$$\n\\boxed{-\\frac{1}{96}}\n$$", "id": "2657891"}, {"introduction": "Moving from single-species toy models to more realistic multi-species networks introduces new challenges in implementation and validation. This final practice involves applying a Gaussian closure in the form of the Linear Noise Approximation (LNA) to a reversible dimerization reaction and implementing a numerical solver for the resulting moment equations. The exercise emphasizes the practical aspects of simulation, requiring you to design and implement tests that verify the preservation of fundamental system properties, such as linear conservation laws and the positive-semidefinite nature of the covariance matrix, which can be violated by numerical error or failures of the approximation itself [@problem_id:2657875].", "problem": "Consider the stochastic reaction network with two chemical species, denoted by $A$ and $B$, undergoing reversible dimerization under mass-action kinetics:\n- Reaction $R_1$: $2A \\rightarrow B$ with stoichiometric change vector $\\nu_1 = (-2, +1)^\\top$ and propensity $a_1(X) = k_1 \\, X_A (X_A - 1)/2$,\n- Reaction $R_2$: $B \\rightarrow 2A$ with stoichiometric change vector $\\nu_2 = (+2, -1)^\\top$ and propensity $a_2(X) = k_2 \\, X_B$,\nwhere $X = (X_A, X_B)^\\top$ is the copy-number random vector, $k_1$ and $k_2$ are nonnegative rate constants, and the stoichiometry matrix is $S = [\\nu_1,\\nu_2]$.\n\nYour task is to implement a program that:\n1) Derives and integrates closed ordinary differential equations for the mean vector $\\mu(t) = \\mathbb{E}[X(t)] \\in \\mathbb{R}^2$ and covariance matrix $\\Sigma(t) \\in \\mathbb{R}^{2\\times 2}$ using a Gaussian moment closure consistent with the Linear Noise Approximation. Specifically, use the approximation $\\mathbb{E}[a_r(X)] \\approx a_r(\\mu)$ for each reaction $r$ and assume vanishing third and higher-order cumulants. This yields closed equations in terms of $\\mu$ and $\\Sigma$ only. You must integrate these equations over time using an adaptive step-size method.\n2) Designs and executes numerical tests that verify both:\n   - Conservation invariant preservation: the linear conserved quantity $C^\\top \\mu(t)$ with $C = (1,2)^\\top$ should remain constant in time because $C^\\top S = 0$. Quantify violations by computing the maximum absolute deviation of $C^\\top \\mu(t)$ from its initial value over the adaptive solver’s internal steps. Treat the invariant as preserved if the maximum deviation is below a tolerance of $\\varepsilon_{\\text{inv}} = 10^{-6} \\times (1 + |C^\\top \\mu(0)|)$.\n   - Positive semidefinite (PSD) preservation of the covariance: at every accepted adaptive time step, the symmetric matrix $\\Sigma(t)$ must be numerically positive semidefinite. Quantify violations by the most negative eigenvalue of $\\Sigma(t)$. Treat the PSD property as preserved if, for all steps, the minimum eigenvalue is not less than $-\\varepsilon_{\\text{psd}}(t)$ with $\\varepsilon_{\\text{psd}}(t) = 10^{-8} \\times \\left(1 + \\max(\\Sigma_{11}(t), \\Sigma_{22}(t))\\right)$.\n\nFundamental base and modeling assumptions:\n- Start from the Chemical Master Equation framework for well-mixed Markov jump processes, mass-action propensities, and the definitions of the first two moments $\\mu(t)$ and $\\Sigma(t)$.\n- Close the moment hierarchy using the Gaussian assumption and the Linear Noise Approximation such that $\\dot{\\mu}(t)$ equals the deterministic drift evaluated at $\\mu(t)$ and $\\dot{\\Sigma}(t)$ has the standard Lyapunov-type form with Jacobian $J(\\mu(t))$ and noise covariance $Q(\\mu(t))$ that depends on the propensities. All expressions must be functions of $\\mu$ and $\\Sigma$ only.\n\nNumerical integration and units:\n- Time $t$ must be expressed in seconds (s), rate constants $k_1$ and $k_2$ in $\\text{s}^{-1}$, and copy-number means and covariances are dimensionless. Use an adaptive Runge–Kutta method with relative tolerance $10^{-8}$ and absolute tolerance $10^{-10}$ for integrating the closed moment equations.\n\nTest suite:\nRun your program on the following parameter sets. Each case uses initial time $t=0$ and integrates to the specified final time $T$.\n- Case $1$: $k_1 = 0.01$ $\\text{s}^{-1}$, $k_2 = 1.0$ $\\text{s}^{-1}$, $\\mu(0) = (40, 20)^\\top$, $\\Sigma(0) = \\begin{bmatrix} 5 & 0 \\\\ 0 & 5 \\end{bmatrix}$, $T = 5.0$ s.\n- Case $2$: $k_1 = 0.02$ $\\text{s}^{-1}$, $k_2 = 0.5$ $\\text{s}^{-1}$, $\\mu(0) = (2, 1)^\\top$, $\\Sigma(0) = \\begin{bmatrix} 0.2 & 0 \\\\ 0 & 0.1 \\end{bmatrix}$, $T = 5.0$ s.\n- Case $3$ (stiff reverse reaction): $k_1 = 0.1$ $\\text{s}^{-1}$, $k_2 = 100.0$ $\\text{s}^{-1}$, $\\mu(0) = (30, 10)^\\top$, $\\Sigma(0) = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$, $T = 0.5$ s.\n- Case $4$ (pure monomer start): $k_1 = 0.05$ $\\text{s}^{-1}$, $k_2 = 2.0$ $\\text{s}^{-1}$, $\\mu(0) = (100, 0)^\\top$, $\\Sigma(0) = \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix}$, $T = 2.0$ s.\n- Case $5$: $k_1 = 10^{-4}$ $\\text{s}^{-1}$, $k_2 = 0.5$ $\\text{s}^{-1}$, $\\mu(0) = (5, 0)^\\top$, $\\Sigma(0) = \\begin{bmatrix} 0.1 & 0 \\\\ 0 & 0.1 \\end{bmatrix}$, $T = 5.0$ s.\n\nFor each case, your program must:\n- Construct the closed moment equations for $\\dot{\\mu}(t)$ and $\\dot{\\Sigma}(t)$ under the specified closure.\n- Integrate these equations adaptively over $[0,T]$.\n- Along the internally chosen adaptive steps, verify the conservation invariant and the PSD condition as defined above.\n- Produce, for each case, a boolean result that is $\\mathrm{True}$ if and only if both tests pass for that case and $\\mathrm{False}$ otherwise.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list of Python booleans enclosed in square brackets. For example, the format must be exactly like $[b_1,b_2,b_3,b_4,b_5]$ where each $b_i$ is either $\\mathrm{True}$ or $\\mathrm{False}$.", "solution": "The problem is well-defined, scientifically grounded, and internally consistent. It poses a standard task in stochastic chemical kinetics: the derivation and numerical analysis of moment equations under a Gaussian or Linear Noise Approximation (LNA) closure. All parameters, initial conditions, and validation criteria are specified unambiguously. Therefore, the problem is valid, and a solution will be provided.\n\nThe core of the problem is to analyze the dynamics of the first two moments of a stochastic dimerization process. The system consists of two chemical species, $A$ and $B$, involved in the reversible reaction $2A \\rightleftharpoons B$.\nThe reactions are:\n$R_1: 2A \\xrightarrow{k_1} B$, with propensity $a_1(X) = \\frac{k_1}{2} X_A (X_A-1)$ and stoichiometry $\\nu_1 = (-2, 1)^\\top$.\n$R_2: B \\xrightarrow{k_2} 2A$, with propensity $a_2(X) = k_2 X_B$ and stoichiometry $\\nu_2 = (2, -1)^\\top$.\nHere, $X = (X_A, X_B)^\\top$ is the vector of copy numbers, and $k_1, k_2$ are rate constants. The stoichiometry matrix is $S = [\\nu_1, \\nu_2] = \\begin{bmatrix} -2 & 2 \\\\ 1 & -1 \\end{bmatrix}$.\n\nThe objective is to derive and solve the closed ordinary differential equations (ODEs) for the mean vector $\\mu(t) = \\mathbb{E}[X(t)]$ and the covariance matrix $\\Sigma(t) = \\mathbb{E}[(X(t)-\\mu(t))(X(t)-\\mu(t))^\\top]$.\n\nFirst, we derive the equation for the mean vector $\\mu(t) = (\\mu_A(t), \\mu_B(t))^\\top$. The exact evolution is given by $\\dot{\\mu} = S \\mathbb{E}[a(X)]$. The problem specifies applying the Linear Noise Approximation, which involves approximating the expectation of the propensity functions by the propensities evaluated at the mean, i.e., $\\mathbb{E}[a_r(X)] \\approx a_r(\\mu)$.\nApplying this approximation, we get:\n$\\mathbb{E}[a_1(X)] \\approx a_1(\\mu) = \\frac{k_1}{2} \\mu_A(\\mu_A-1)$\n$\\mathbb{E}[a_2(X)] \\approx a_2(\\mu) = k_2 \\mu_B$\n\nThe closed ODE system for the mean is then the deterministic rate equation:\n$$\n\\frac{d\\mu}{dt} = S a(\\mu) = \\begin{pmatrix} -2 & 2 \\\\ 1 & -1 \\end{pmatrix} \\begin{pmatrix} \\frac{k_1}{2} \\mu_A(\\mu_A-1) \\\\ k_2 \\mu_B \\end{pmatrix}\n$$\nThis yields the component-wise equations:\n$$\n\\frac{d\\mu_A}{dt} = -k_1 \\mu_A(\\mu_A-1) + 2k_2 \\mu_B\n$$\n$$\n\\frac{d\\mu_B}{dt} = \\frac{k_1}{2} \\mu_A(\\mu_A-1) - k_2 \\mu_B\n$$\n\nNext, we derive the equation for the covariance matrix $\\Sigma(t)$. Under the LNA, this equation takes the form of a continuous-time Lyapunov equation:\n$$\n\\frac{d\\Sigma}{dt} = J(\\mu) \\Sigma + \\Sigma J(\\mu)^\\top + Q(\\mu)\n$$\nHere, $J(\\mu)$ is the Jacobian matrix of the deterministic rate vector field $F(\\mu) = S a(\\mu)$, and $Q(\\mu)$ is the noise matrix.\n\nThe vector field is $F(\\mu) = \\left( -k_1 \\mu_A(\\mu_A-1) + 2k_2 \\mu_B, \\frac{k_1}{2} \\mu_A(\\mu_A-1) - k_2 \\mu_B \\right)^\\top$. The Jacobian matrix $J(\\mu) = \\frac{\\partial F}{\\partial \\mu}$ is:\n$$\nJ(\\mu) = \\begin{pmatrix} \\frac{\\partial F_A}{\\partial \\mu_A} & \\frac{\\partial F_A}{\\partial \\mu_B} \\\\ \\frac{\\partial F_B}{\\partial \\mu_A} & \\frac{\\partial F_B}{\\partial \\mu_B} \\end{pmatrix} = \\begin{pmatrix} -k_1(2\\mu_A - 1) & 2k_2 \\\\ \\frac{k_1}{2}(2\\mu_A - 1) & -k_2 \\end{pmatrix}\n$$\n\nThe noise matrix $Q(\\mu)$ is defined as $Q(\\mu) = \\sum_{r} \\nu_r \\nu_r^\\top a_r(\\mu) = S \\cdot \\text{diag}(a(\\mu)) \\cdot S^\\top$. Since $\\nu_1 = -\\nu_2$, we have $\\nu_1\\nu_1^\\top = \\nu_2\\nu_2^\\top = \\begin{pmatrix} 4 & -2 \\\\ -2 & 1 \\end{pmatrix}$. Thus,\n$$\nQ(\\mu) = \\nu_1\\nu_1^\\top a_1(\\mu) + \\nu_2\\nu_2^\\top a_2(\\mu) = (a_1(\\mu) + a_2(\\mu)) \\begin{pmatrix} 4 & -2 \\\\ -2 & 1 \\end{pmatrix}\n$$\nwhere $a_1(\\mu) = \\frac{k_1}{2}\\mu_A(\\mu_A-1)$ and $a_2(\\mu) = k_2\\mu_B$.\n\nThe overall system of ODEs is defined on a $5$-dimensional state vector $y(t) = (\\mu_A(t), \\mu_B(t), \\Sigma_{11}(t), \\Sigma_{12}(t), \\Sigma_{22}(t))^\\top$, where we only track the unique elements of the symmetric matrix $\\Sigma$. The component-wise equations for the covariance matrix are derived from $\\dot{\\Sigma} = J\\Sigma + \\Sigma J^\\top + Q$:\n$$\n\\frac{d\\Sigma_{11}}{dt} = 2(J_{11}\\Sigma_{11} + J_{12}\\Sigma_{12}) + Q_{11}\n$$\n$$\n\\frac{d\\Sigma_{12}}{dt} = J_{11}\\Sigma_{12} + J_{12}\\Sigma_{22} + J_{21}\\Sigma_{11} + J_{22}\\Sigma_{12} + Q_{12}\n$$\n$$\n\\frac{d\\Sigma_{22}}{dt} = 2(J_{21}\\Sigma_{12} + J_{22}\\Sigma_{22}) + Q_{22}\n$$\n\nThis system of five coupled ODEs is integrated numerically using an adaptive step-size Runge-Kutta method as provided by `scipy.integrate.solve_ivp`, with a relative tolerance of $10^{-8}$ and an absolute tolerance of $10^{-10}$. For each of the five test cases, we perform the following checks at each accepted time step from the integrator:\n\n1.  **Conservation Invariant Preservation**: The reaction stoichiometry implies a linear conservation law $C^\\top X = \\text{constant}$ for $C=(1, 2)^\\top$, because $C^\\top S = [1, 2]\\begin{bmatrix}-2 & 2 \\\\ 1 & -1\\end{bmatrix} = [0, 0]$. This property must hold for the mean, i.e., $C^\\top\\mu(t) = \\mu_A(t) + 2\\mu_B(t)$ must be constant. We compute the initial value $L_0 = C^\\top\\mu(0)$ and check if the maximum absolute deviation $|C^\\top\\mu(t) - L_0|$ over the integration interval remains below the tolerance $\\varepsilon_{\\text{inv}} = 10^{-6} \\times (1 + |L_0|)$. The derived mean equations analytically preserve this invariant, so any deviation is due to numerical integration error.\n\n2.  **Positive Semidefinite (PSD) Preservation**: The covariance matrix $\\Sigma(t)$ must be positive semidefinite by definition. We check this numerically at each time step. A symmetric $2\\times2$ matrix is PSD if and only if its trace and determinant are non-negative. Equivalently, its eigenvalues must be non-negative. We calculate the minimum eigenvalue $\\lambda_{\\min}(t)$ of $\\Sigma(t)$ and check if it satisfies $\\lambda_{\\min}(t) \\ge -\\varepsilon_{\\text{psd}}(t)$, where the tolerance is defined as $\\varepsilon_{\\text{psd}}(t) = 10^{-8} \\times (1 + \\max(\\Sigma_{11}(t), \\Sigma_{22}(t)))$. This allows for small numerical violations relative to the magnitude of the variances. The LNA is known to sometimes fail this property, especially for systems with low copy numbers.\n\nA test case is considered successful (evaluates to `True`) if and only if both the conservation and PSD tests pass for the entire integration trajectory. The final program will execute these checks for each specified parameter set and report the boolean outcomes.", "answer": "```\n[True, True, True, True, True]\n```", "id": "2657875"}]}