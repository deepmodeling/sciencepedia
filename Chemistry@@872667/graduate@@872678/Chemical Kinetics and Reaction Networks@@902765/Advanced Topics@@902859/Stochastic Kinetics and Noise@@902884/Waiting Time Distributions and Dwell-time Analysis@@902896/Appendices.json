{"hands_on_practices": [{"introduction": "To analyze dwell times, we must first understand their fundamental probabilistic nature. This first practice takes you back to foundational principles, asking you to derive the waiting time distribution for a system with multiple competing reaction channels [@problem_id:2694227]. By working from the definition of a reaction propensity as an instantaneous hazard rate, you will see precisely why elementary stochastic reactions give rise to exponentially distributed waiting times and how to calculate the probability of which reaction occurs first.", "problem": "In a well-mixed isothermal reactor at constant volume, consider a single-molecule kinetic subsystem with three reaction channels whose propensities are time-independent over the time interval of interest. Let the propensities be $a_1=2$, $a_2=3$, and $a_3=5$, each in units of $\\mathrm{s}^{-1}$. Assume the Chemical Master Equation (CME) description applies and that propensities represent instantaneous hazards for the corresponding channels. Starting from first principles for competing exponential hazards, derive the waiting-time distribution for the next reaction event and the probability that each channel fires first. Explicitly: from the infinitesimal definition that the probability that channel $i$ fires in $[t,t+\\mathrm{d}t)$, conditioned on no prior event, is $a_i\\,\\mathrm{d}t+o(\\mathrm{d}t)$, derive the survival function, the probability density function of the waiting time $T$, and the next-reaction channel probabilities. \n\nUse time in seconds. Provide the analytic expression for the probability density function $f_T(t)$ for $t \\ge 0$ and the probabilities $p_1$, $p_2$, and $p_3$ that channels $1$, $2$, and $3$ are the next event, respectively. Give exact expressions; no rounding is required. \n\nReport your final answer as a row matrix $\\big(f_T(t),\\,p_1,\\,p_2,\\,p_3\\big)$.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and contains all necessary information for a unique and meaningful solution. It is a standard problem in the theory of stochastic chemical kinetics, specifically relating to the Gillespie algorithm's foundation. The problem is valid. We will proceed with the derivation from first principles.\n\nLet $T$ be the random variable representing the waiting time until the next reaction event. We are given three independent competing reaction channels, indexed by $i \\in \\{1, 2, 3\\}$. The propensity for each channel, $a_i$, represents the instantaneous hazard rate for that reaction. The probability that channel $i$ fires in the infinitesimal time interval $[t, t+\\mathrm{d}t)$, given that no reaction has occurred before time $t$, is given as $a_i\\,\\mathrm{d}t + o(\\mathrm{d}t)$.\n\nThe total propensity for *any* reaction to occur is the sum of the individual propensities, as the channels represent mutually exclusive events for the first reaction. Let $a_0$ be the total propensity:\n$$a_0 = \\sum_{i=1}^{3} a_i$$\nThe probability that *any* reaction occurs in $[t, t+\\mathrm{d}t)$, conditioned on survival until time $t$, is thus $a_0\\,\\mathrm{d}t + o(\\mathrm{d}t)$.\n\nFirst, we derive the survival function, $S(t) = P(T  t)$, which is the probability that no reaction has occurred by time $t$. The probability of surviving past time $t+\\mathrm{d}t$ is the probability of surviving past time $t$ multiplied by the probability of no event occurring in the interval $[t, t+\\mathrm{d}t)$.\n$$S(t + \\mathrm{d}t) = S(t) \\times P(\\text{no event in } [t, t+\\mathrm{d}t) | T  t)$$\nThe probability of an event occurring in $[t, t+\\mathrm{d}t)$ is $a_0\\,\\mathrm{d}t$, so the probability of no event is $1 - a_0\\,\\mathrm{d}t$. We ignore higher-order terms $o(\\mathrm{d}t)$.\n$$S(t + \\mathrm{d}t) = S(t) (1 - a_0\\,\\mathrm{d}t)$$\nRearranging this expression gives the differential form:\n$$\\frac{S(t + \\mathrm{d}t) - S(t)}{\\mathrm{d}t} = -a_0 S(t)$$\nTaking the limit as $\\mathrm{d}t \\to 0$, we obtain a first-order ordinary differential equation for $S(t)$:\n$$\\frac{\\mathrm{d}S(t)}{\\mathrm{d}t} = -a_0 S(t)$$\nThe initial condition is that survival at time $t=0$ is certain, so $S(0) = 1$. The solution to this differential equation is:\n$$S(t) = \\exp(-a_0 t)$$\n\nNext, we derive the probability density function (PDF) of the waiting time, $f_T(t)$. The PDF is related to the cumulative distribution function (CDF), $F_T(t) = P(T \\le t)$, by $f_T(t) = \\frac{\\mathrm{d}F_T(t)}{\\mathrm{d}t}$. The CDF is related to the survival function by $F_T(t) = 1 - S(t)$. Therefore:\n$$f_T(t) = \\frac{\\mathrm{d}}{\\mathrm{d}t} (1 - S(t)) = -\\frac{\\mathrm{d}S(t)}{\\mathrm{d}t}$$\nSubstituting the expression for $S(t)$:\n$$f_T(t) = -\\frac{\\mathrm{d}}{\\mathrm{d}t} (\\exp(-a_0 t)) = -(-a_0 \\exp(-a_0 t)) = a_0 \\exp(-a_0 t)$$\nThis is the PDF of an exponential distribution with rate parameter $a_0$.\nUsing the given propensities:\n$a_1 = 2 \\, \\mathrm{s}^{-1}$\n$a_2 = 3 \\, \\mathrm{s}^{-1}$\n$a_3 = 5 \\, \\mathrm{s}^{-1}$\nThe total propensity is:\n$$a_0 = a_1 + a_2 + a_3 = 2 + 3 + 5 = 10 \\, \\mathrm{s}^{-1}$$\nThus, the PDF for the waiting time $T$ is:\n$$f_T(t) = 10 \\exp(-10 t) \\quad \\text{for } t \\ge 0$$\n\nFinally, we derive the probability, $p_i$, that channel $i$ is the specific channel that fires. This is the probability that reaction $i$ \"wins the race\". The joint probability that channel $i$ fires in the interval $[t, t+\\mathrm{d}t)$ and is the first event to do so is the product of the probability of no event until time $t$, $S(t)$, and the probability of channel $i$ firing in $[t, t+\\mathrm{d}t)$, which is $a_i\\,\\mathrm{d}t$. The probability element is therefore $S(t) a_i\\,\\mathrm{d}t = a_i \\exp(-a_0 t)\\,\\mathrm{d}t$. To find the total probability $p_i$, we integrate this over all possible waiting times $t \\in [0, \\infty)$:\n$$p_i = \\int_0^\\infty a_i \\exp(-a_0 t) \\,\\mathrm{d}t$$\nSince $a_i$ is a constant with respect to time, we can take it out of the integral:\n$$p_i = a_i \\int_0^\\infty \\exp(-a_0 t) \\,\\mathrm{d}t = a_i \\left[ -\\frac{1}{a_0} \\exp(-a_0 t) \\right]_0^\\infty$$\n$$p_i = a_i \\left( -\\frac{1}{a_0} (0) - \\left(-\\frac{1}{a_0} (1)\\right) \\right) = \\frac{a_i}{a_0}$$\nThis confirms the well-known result that for competing Poisson processes, the probability of a specific process being the first to occur is the ratio of its rate to the total rate.\nWe now compute the specific probabilities:\n$$p_1 = \\frac{a_1}{a_0} = \\frac{2}{10} = \\frac{1}{5}$$\n$$p_2 = \\frac{a_2}{a_0} = \\frac{3}{10}$$\n$$p_3 = \\frac{a_3}{a_0} = \\frac{5}{10} = \\frac{1}{2}$$\nAs a check, the sum of these probabilities must be unity: $p_1 + p_2 + p_3 = \\frac{2}{10} + \\frac{3}{10} + \\frac{5}{10} = \\frac{10}{10} = 1$, which is correct.\n\nThe required quantities are the PDF $f_T(t)$ and the probabilities $p_1$, $p_2$, and $p_3$.\n$f_T(t) = 10 \\exp(-10 t)$\n$p_1 = \\frac{1}{5}$\n$p_2 = \\frac{3}{10}$\n$p_3 = \\frac{1}{2}$", "answer": "$$\\boxed{\\begin{pmatrix} 10 \\exp(-10 t)  \\frac{1}{5}  \\frac{3}{10}  \\frac{1}{2} \\end{pmatrix}}$$", "id": "2694227"}, {"introduction": "Once we have a theoretical model for dwell-time distributions, the next step is to confront it with data. This exercise delves into the statistical challenge of distinguishing between competing kinetic models using a key summary statistic, the coefficient of variation [@problem_id:2694248]. You will explore the power and limitations of hypothesis testing, learning how the sample size fundamentally constrains our ability to make definitive conclusions from single-molecule time traces.", "problem": "A single catalytic enzyme is monitored in a force-clamp experiment, producing a short time trace of $n$ independent dwell times between turnovers. Consider two competing kinetic models for the dwell-time $T$: (i) an exponential waiting time with rate $k$ (so $T \\sim \\mathrm{Exp}(k)$), and (ii) a deterministic time $T = t_0$ (a degenerate distribution concentrated at $t_0$). To summarize temporal variability in a scale-free way, an experimentalist proposes to use the coefficient of variation, defined at the population level by $c = \\sigma/\\mu$, where $\\mu = \\mathbb{E}[T]$ and $\\sigma = \\sqrt{\\mathrm{Var}(T)}$. From a short trace of $n$ events, the experimentalist computes the sample moments $M_1 = \\frac{1}{n}\\sum_{i=1}^n T_i$ and $M_2 = \\frac{1}{n}\\sum_{i=1}^n T_i^2$, and forms the plug-in estimator $\\hat c = \\sqrt{M_2 - M_1^2}/M_1$. They would like to decide, based on $\\hat c$, whether the data are more consistent with the exponential model or with the deterministic model when $n$ is small. Assume ideal time resolution and no measurement noise. Throughout, let $z_p$ denote the $p$-quantile of a standard normal distribution.\nThe experimentalist considers a one-sided coefficient-of-variation test of the exponential model $H_0$ that rejects $H_0$ in favor of the deterministic alternative for sufficiently small $\\hat c$. They calibrate the critical value by appealing to the large-$n$ asymptotic distribution of $\\hat c$ under the exponential model so that the test has (asymptotic) size $\\alpha \\in (0,1)$.\nWhich of the following statements are correct? Select all that apply.\n\nA. The population coefficient of variation equals $1$ under the exponential model and equals $0$ under the deterministic model. If the level-$\\alpha$ rejection region is taken to be $\\{\\hat c  1 - z_{1-\\alpha}/\\sqrt{n}\\}$ based on the asymptotic distribution under $H_0$, then whenever $n \\le z_{1-\\alpha}^2$ the critical value is non-positive and no sample can fall in the rejection region; with such short traces, this test cannot distinguish the models at level $\\alpha$.\n\nB. Using the delta method on $(M_1,M_2)$, one finds that under the exponential model $\\sqrt{n}\\,(\\hat c - 1)$ is approximately standard normal and does not depend on $k$; hence the test that rejects for $\\hat c  1 - z_{1-\\alpha}/\\sqrt{n}$ has asymptotic Type I error $\\alpha$ and its power against the deterministic alternative tends to $1$ as $n \\to \\infty$.\n\nC. For the deterministic model, $\\hat c \\equiv 0$ for any $n$, so even with $n=1$ the exponential model will be rejected by the above test for any $\\alpha  0.5$.\n\nD. Under the exponential model, $\\mathrm{Var}(\\hat c) \\approx 1/(2n)$, so to achieve a misclassification probability below $5\\%$ one needs $n \\gtrsim 1.35$.\n\nE. The level-$\\alpha$ critical value for the coefficient-of-variation test depends on the unknown exponential rate $k$ and must be calibrated by first estimating $k$; otherwise the test is not valid.", "solution": "The problem statement is scrutinized for validity.\n\n**Step 1: Extract Givens**\n- A sample of $n$ independent dwell times: $T_1, T_2, \\ldots, T_n$.\n- Model (i) / Null Hypothesis $H_0$: $T \\sim \\mathrm{Exp}(k)$, an exponential distribution with rate $k$.\n- Model (ii) / Alternative: $T = t_0$, a deterministic (degenerate) distribution.\n- Population coefficient of variation: $c = \\sigma/\\mu$, where $\\mu = \\mathbb{E}[T]$ and $\\sigma = \\sqrt{\\mathrm{Var}(T)}$.\n- Sample moments: $M_1 = \\frac{1}{n}\\sum_{i=1}^n T_i$ and $M_2 = \\frac{1}{n}\\sum_{i=1}^n T_i^2$.\n- Estimator for $c$: $\\hat c = \\sqrt{M_2 - M_1^2}/M_1$.\n- Hypothesis test: Reject $H_0$ for small $\\hat c$.\n- Test size: Asymptotic size $\\alpha$.\n- Critical value is based on the large-$n$ asymptotic distribution of $\\hat c$ under $H_0$.\n- $z_p$ is the $p$-quantile of a standard normal distribution $\\mathcal{N}(0,1)$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is sound. Exponential waiting times are a cornerstone of simple kinetic models (Poisson processes). The deterministic model is a valid, simple alternative. The coefficient of variation is a standard dimensionless measure of variability. The use of sample moments, the delta method, and hypothesis testing are standard statistical procedures. The context is single-molecule biophysics, which is appropriate.\n- **Well-Posed:** The problem provides two clearly defined models and a well-defined estimator and testing framework. The questions asked in the options are precise and can be evaluated mathematically.\n- **Objective:** The language is formal and mathematical, with no subjective content.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. A rigorous analysis can proceed.\n\n**Derivation of Fundamental Properties**\n\nFirst, we establish the properties of the two models.\n\n1.  **Exponential Model ($H_0$)**: Let $T \\sim \\mathrm{Exp}(k)$. Its probability density function is $f(t;k) = k e^{-kt}$ for $t \\ge 0$.\n    The moments are well-known:\n    - Mean: $\\mu = \\mathbb{E}[T] = 1/k$.\n    - Variance: $\\sigma^2 = \\mathrm{Var}(T) = 1/k^2$.\n    - Standard deviation: $\\sigma = \\sqrt{1/k^2} = 1/k$.\n    - The population coefficient of variation is $c = \\sigma/\\mu = (1/k) / (1/k) = 1$.\n\n2.  **Deterministic Model**: Let $T = t_0$ for some constant $t_0  0$.\n    - Mean: $\\mu = \\mathbb{E}[T] = t_0$.\n    - Variance: $\\sigma^2 = \\mathrm{Var}(T) = \\mathbb{E}[(T-\\mu)^2] = \\mathbb{E}[(t_0-t_0)^2] = 0$.\n    - Standard deviation: $\\sigma = 0$.\n    - The population coefficient of variation is $c = \\sigma/\\mu = 0/t_0 = 0$.\n\nNext, we determine the asymptotic distribution of the estimator $\\hat c$ under the null hypothesis, $H_0$. The estimator is $\\hat c = g(M_1, M_2)$ where $g(m_1, m_2) = \\sqrt{m_2 - m_1^2}/m_1$. We use the multivariate delta method.\nBy the Central Limit Theorem, $\\sqrt{n} \\left( \\begin{pmatrix} M_1 \\\\ M_2 \\end{pmatrix} - \\begin{pmatrix} \\mathbb{E}[T] \\\\ \\mathbb{E}[T^2] \\end{pmatrix} \\right) \\xrightarrow{d} \\mathcal{N}\\left(\\mathbf{0}, \\Sigma\\right)$, where $\\Sigma$ is the covariance matrix of the vector $(T, T^2)$.\n\nUnder $H_0$, we need the first four moments of $T \\sim \\mathrm{Exp}(k)$:\n- $\\mathbb{E}[T] = 1/k$\n- $\\mathbb{E}[T^2] = 2!/k^2 = 2/k^2$\n- $\\mathbb{E}[T^3] = 3!/k^3 = 6/k^3$\n- $\\mathbb{E}[T^4] = 4!/k^4 = 24/k^4$\n\nThe entries of the covariance matrix $\\Sigma$ are:\n- $\\Sigma_{11} = \\mathrm{Var}(T) = \\mathbb{E}[T^2] - (\\mathbb{E}[T])^2 = 2/k^2 - (1/k)^2 = 1/k^2$.\n- $\\Sigma_{22} = \\mathrm{Var}(T^2) = \\mathbb{E}[T^4] - (\\mathbb{E}[T^2])^2 = 24/k^4 - (2/k^2)^2 = 20/k^4$.\n- $\\Sigma_{12} = \\mathrm{Cov}(T, T^2) = \\mathbb{E}[T^3] - \\mathbb{E}[T]\\mathbb{E}[T^2] = 6/k^3 - (1/k)(2/k^2) = 4/k^3$.\nSo, $\\Sigma = \\begin{pmatrix} 1/k^2  4/k^3 \\\\ 4/k^3  20/k^4 \\end{pmatrix}$.\n\nThe gradient of $g(m_1, m_2)$ is $\\nabla g = (\\partial g/\\partial m_1, \\partial g/\\partial m_2)^T$.\n- $\\frac{\\partial g}{\\partial m_1} = \\frac{-m_2}{m_1^2 \\sqrt{m_2-m_1^2}}$\n- $\\frac{\\partial g}{\\partial m_2} = \\frac{1}{2 m_1 \\sqrt{m_2-m_1^2}}$\n\nWe evaluate the gradient at the population moments under $H_0$: $(m_1, m_2) = (1/k, 2/k^2)$.\nAt this point, $\\sqrt{m_2-m_1^2} = \\sqrt{2/k^2 - 1/k^2} = 1/k$.\n- $\\frac{\\partial g}{\\partial m_1} = \\frac{-2/k^2}{(1/k)^2 (1/k)} = -2k$.\n- $\\frac{\\partial g}{\\partial m_2} = \\frac{1}{2(1/k)(1/k)} = k^2/2$.\nSo, $\\nabla g = \\begin{pmatrix} -2k \\\\ k^2/2 \\end{pmatrix}$.\n\nThe asymptotic variance of $\\sqrt{n}(\\hat c - c)$ is $\\nabla g^T \\Sigma \\nabla g$.\n$\\nabla g^T \\Sigma \\nabla g = \\begin{pmatrix} -2k  k^2/2 \\end{pmatrix} \\begin{pmatrix} 1/k^2  4/k^3 \\\\ 4/k^3  20/k^4 \\end{pmatrix} \\begin{pmatrix} -2k \\\\ k^2/2 \\end{pmatrix}$\n$= \\begin{pmatrix} -2k/k^2 + (k^2/2)(4/k^3)  -2k(4/k^3) + (k^2/2)(20/k^4) \\end{pmatrix} \\begin{pmatrix} -2k \\\\ k^2/2 \\end{pmatrix}$\n$= \\begin{pmatrix} -2/k + 2/k  -8/k^2 + 10/k^2 \\end{pmatrix} \\begin{pmatrix} -2k \\\\ k^2/2 \\end{pmatrix}$\n$= \\begin{pmatrix} 0  2/k^2 \\end{pmatrix} \\begin{pmatrix} -2k \\\\ k^2/2 \\end{pmatrix} = 0 \\cdot (-2k) + (2/k^2)(k^2/2) = 1$.\n\nThus, under $H_0$, $\\sqrt{n}(\\hat c - 1) \\xrightarrow{d} \\mathcal{N}(0, 1)$. The asymptotic distribution is a standard normal, and critically, it is pivotal—it does not depend on the unknown parameter $k$.\n\n**Option-by-Option Analysis**\n\n- **A. The population coefficient of variation equals $1$ under the exponential model and equals $0$ under the deterministic model. If the level-$\\alpha$ rejection region is taken to be $\\{\\hat c  1 - z_{1-\\alpha}/\\sqrt{n}\\}$ based on the asymptotic distribution under $H_0$, then whenever $n \\le z_{1-\\alpha}^2$ the critical value is non-positive and no sample can fall in the rejection region; with such short traces, this test cannot distinguish the models at level $\\alpha$.**\nThe first part is correct, as shown above, $c=1$ for exponential and $c=0$ for deterministic models.\nThe test rejects $H_0$ if the test statistic is in the lower $\\alpha$-tail of its null distribution. From $\\sqrt{n}(\\hat c - 1) \\sim \\mathcal{N}(0, 1)$, the rejection region is $\\sqrt{n}(\\hat c - 1)  z_\\alpha$. Since $z_\\alpha = -z_{1-\\alpha}$, this becomes $\\hat c - 1  -z_{1-\\alpha}/\\sqrt{n}$, or $\\hat c  1 - z_{1-\\alpha}/\\sqrt{n}$. The form of the rejection region is correct.\nThe critical value is $C = 1 - z_{1-\\alpha}/\\sqrt{n}$. For $C \\le 0$, we need $1 \\le z_{1-\\alpha}/\\sqrt{n}$, which means $\\sqrt{n} \\le z_{1-\\alpha}$, or $n \\le z_{1-\\alpha}^2$. The condition is correct.\nThe estimator $\\hat c = \\sqrt{M_2 - M_1^2}/M_1$ is the ratio of the sample standard deviation to the sample mean. For a sample of positive dwell times, $M_1  0$. The sample standard deviation is always non-negative. Therefore, $\\hat c \\ge 0$. If the critical value $C$ is non-positive, the rejection condition $\\hat c  C$ cannot be fulfilled by any sample (unless $\\hat c = C = 0$, but this is a boundary case of measure zero and still not strictly less). Thus, for $n \\le z_{1-\\alpha}^2$, the test will never reject $H_0$. For example, if $\\alpha=0.05$, then $z_{0.95} \\approx 1.645$, and $z_{0.95}^2 \\approx 2.7$. For $n=1$ or $n=2$, this test cannot reject at the $5\\%$ level. The statement is entirely correct.\n**Verdict: Correct.**\n\n- **B. Using the delta method on $(M_1,M_2)$, one finds that under the exponential model $\\sqrt{n}(\\hat c - 1)$ is approximately standard normal and does not depend on $k$; hence the test that rejects for $\\hat c  1 - z_{1-\\alpha}/\\sqrt{n}$ has asymptotic Type I error $\\alpha$ and its power against the deterministic alternative tends to $1$ as $n \\to \\infty$.**\nOur derivation showed that $\\sqrt{n}(\\hat c - 1) \\xrightarrow{d} \\mathcal{N}(0, 1)$, a standard normal distribution, which is independent of $k$. This part is correct.\nThe test rejects when $\\sqrt{n}(\\hat c - 1)  -z_{1-\\alpha} = z_\\alpha$. Under $H_0$, the probability of this event converges to $\\mathbb{P}(\\mathcal{N}(0,1)  z_\\alpha) = \\alpha$. Thus, the asymptotic Type I error is $\\alpha$. This is correct.\nPower is the probability of rejecting $H_0$ when the alternative is true. Under the deterministic model, every observation is $T_i = t_0$. Thus, $M_1 = t_0$ and $M_2 = t_0^2$. The estimator becomes $\\hat c = \\sqrt{t_0^2 - (t_0)^2}/t_0 = 0$. The test rejects if $0  1 - z_{1-\\alpha}/\\sqrt{n}$, which is true when $\\sqrt{n}  z_{1-\\alpha}$. For any fixed $\\alpha$, this inequality holds for all sufficiently large $n$. Thus, the power of the test approaches $1$ as $n \\to \\infty$. The statement is entirely correct.\n**Verdict: Correct.**\n\n- **C. For the deterministic model, $\\hat c \\equiv 0$ for any $n$, so even with $n=1$ the exponential model will be rejected by the above test for any $\\alpha  0.5$.**\nAs shown for B, under the deterministic model, $\\hat c = 0$ for any sample size $n \\ge 1$. This part is correct.\nThe test rejects if $\\hat c  1 - z_{1-\\alpha}/\\sqrt{n}$. With $\\hat c=0$ and $n=1$, this becomes $0  1 - z_{1-\\alpha}$, or $z_{1-\\alpha}  1$.\nThe claim is that this holds for *any* $\\alpha  0.5$. If $\\alpha  0.5$, then $1-\\alpha  0.5$. The quantile $z_{1-\\alpha}$ is a value on the standard normal distribution. Since $z_{0.5}=0$, $z_{1-\\alpha}$ will be positive. However, it is not guaranteed to be less than $1$. For example, if we choose $\\alpha = 0.1$, then $1-\\alpha = 0.9$, and $z_{0.9} \\approx 1.28$, which is not less than $1$. In this case, the test would not reject. The condition $z_{1-\\alpha}  1$ requires $1-\\alpha  \\Phi(1) \\approx 0.8413$, or $\\alpha  0.1587$. The statement that rejection occurs for *any* $\\alpha  0.5$ is false.\n**Verdict: Incorrect.**\n\n- **D. Under the exponential model, $\\mathrm{Var}(\\hat c) \\approx 1/(2n)$, so to achieve a misclassification probability below $5\\%$ one needs $n \\gtrsim 1.35$.**\nOur derivation showed that the asymptotic variance of $\\sqrt{n}(\\hat c - 1)$ is $1$. This implies that the asymptotic variance of $\\hat c$ is $\\mathrm{Var}(\\hat c) \\approx 1/n$. The statement claims this variance is approximately $1/(2n)$. This is mathematically incorrect and contradicts our finding and option B.\nEven if we were to accept the premise $\\mathrm{Var}(\\hat c) \\approx 1/(2n)$, the second part of the statement is based on a specific, unstated interpretation of \"misclassification probability\". A plausible interpretation is that the separation between the means under the two hypotheses ($1 - 0 = 1$) should be $z_{0.95}$ standard deviations, leading to a one-sided misclassification rate of $5\\%$. This would mean $1 = z_{0.95} \\cdot \\sigma_{\\hat c} \\approx 1.645 / \\sqrt{2n}$, which solves to $n \\approx 1.645^2/2 \\approx 1.35$. While this calculation may be what the question designer intended, it is predicated on the false premise about the variance. Therefore, the entire statement is flawed.\n**Verdict: Incorrect.**\n\n- **E. The level-$\\alpha$ critical value for the coefficient-of-variation test depends on the unknown exponential rate $k$ and must be calibrated by first estimating $k$; otherwise the test is not valid.**\nOur derivation showed that the asymptotic distribution of $\\sqrt{n}(\\hat c - 1)$ is $\\mathcal{N}(0, 1)$, which is a pivotal quantity—its distribution does not depend on the unknown parameter $k$. Consequently, the critical value for the test, $C = 1 - z_{1-\\alpha}/\\sqrt{n}$, is also independent of $k$. No estimation of $k$ is necessary to perform the test. The statement is the opposite of the truth.\n**Verdict: Incorrect.**\n\nFinal conclusion: Statements A and B are correct.", "answer": "$$\\boxed{AB}$$", "id": "2694248"}, {"introduction": "Real-world single-molecule recordings are finite, which introduces an unavoidable complication known as right-censoring. This final practice addresses this common experimental reality by guiding you through the construction of a proper likelihood function for datasets containing both completed and censored dwell times [@problem_id:2694303]. Mastering this technique is essential, as it allows you to extract accurate Maximum Likelihood Estimators (MLEs) for kinetic rates, ensuring that no information is lost from your valuable experimental data.", "problem": "A single-molecule receptor switches between an \"on\" state and an \"off\" state according to a continuous-time two-state reversible reaction network. When the receptor is in the \"on\" state, it exits that state with a first-order rate constant $k_{\\mathrm{off}}$; when the receptor is in the \"off\" state, it exits that state with a first-order rate constant $k_{\\mathrm{on}}$. Under standard dwell-time analysis assumptions, the sojourn (dwell) time in each state is independent and exponentially distributed with the corresponding exit rate. A finite observation window of duration $T_{\\mathrm{obs}}$ produces independent right-censoring: any dwell that is ongoing at time $T_{\\mathrm{obs}}$ is recorded only up to its observed length and marked as censored.\n\nYou observe $d_{\\mathrm{on}}$ completed \"on\"-state dwells with durations $\\{t_{i}^{\\mathrm{on}}\\}_{i=1}^{d_{\\mathrm{on}}}$ (each satisfying $0t_{i}^{\\mathrm{on}}T_{\\mathrm{obs}}$) and $c_{\\mathrm{on}}$ right-censored \"on\"-state dwells with observed lengths $\\{u_{j}^{\\mathrm{on}}\\}_{j=1}^{c_{\\mathrm{on}}}$, where each $u_{j}^{\\mathrm{on}}$ equals $T_{\\mathrm{obs}}-s_{j}^{\\mathrm{on}}$ for the corresponding start time $s_{j}^{\\mathrm{on}}\\in[0,T_{\\mathrm{obs}})$. Similarly, you observe $d_{\\mathrm{off}}$ completed \"off\"-state dwells with durations $\\{t_{i}^{\\mathrm{off}}\\}_{i=1}^{d_{\\mathrm{off}}}$ and $c_{\\mathrm{off}}$ right-censored \"off\"-state dwells with observed lengths $\\{u_{j}^{\\mathrm{off}}\\}_{j=1}^{c_{\\mathrm{off}}}$, where each $u_{j}^{\\mathrm{off}}=T_{\\mathrm{obs}}-s_{j}^{\\mathrm{off}}$ for some $s_{j}^{\\mathrm{off}}\\in[0,T_{\\mathrm{obs}})$. Assume independent sampling and non-informative censoring (the stopping at $T_{\\mathrm{obs}}$ is independent of the underlying transition dynamics).\n\nStarting only from the exponential probability density function $f(t\\mid \\lambda)=\\lambda \\exp(-\\lambda t)$ for $t0$ and its survival function $S(t\\mid \\lambda)=\\exp(-\\lambda t)$, and from the product rule for likelihoods of independent observations, perform the following:\n\n1. Formulate the full likelihood function for the observed data under right-censoring in terms of $k_{\\mathrm{off}}$ and $k_{\\mathrm{on}}$.\n2. Derive the maximum likelihood estimators for $k_{\\mathrm{off}}$ and $k_{\\mathrm{on}}$ under this censoring scheme, expressing each estimator purely in terms of the observed completed dwell durations and the observed censored lengths for the corresponding state.\n\nProvide your final answer as closed-form analytic expressions for $\\hat{k}_{\\mathrm{off}}$ and $\\hat{k}_{\\mathrm{on}}$ in terms of $d_{\\mathrm{on}}$, $d_{\\mathrm{off}}$, $\\{t_{i}^{\\mathrm{on}}\\}$, $\\{u_{j}^{\\mathrm{on}}\\}$, $\\{t_{i}^{\\mathrm{off}}\\}$, and $\\{u_{j}^{\\mathrm{off}}\\}$. Express rates in $\\mathrm{s}^{-1}$, but do not include units in the boxed final answer. No numerical approximation or rounding is required.", "solution": "The problem statement is subjected to validation and is found to be valid. It is scientifically grounded in the principles of chemical kinetics and statistical inference, well-posed, objective, and contains all necessary information for a rigorous solution. No inconsistencies, contradictions, or unscientific premises are present. We may therefore proceed with the derivation.\n\nThe problem requires the derivation of the maximum likelihood estimators (MLEs) for the rate constants $k_{\\mathrm{off}}$ and $k_{\\mathrm{on}}$ of a two-state kinetic system, based on a dataset containing both completed (uncensored) and right-censored dwell times for each state.\n\nThe fundamental principle for constructing a likelihood function for a set of independent observations, some of which may be right-censored, is as follows:\n1. For an uncensored observation, i.e., an event that is observed to complete at time $t$, its contribution to the likelihood is the probability density function (PDF) evaluated at $t$, $f(t)$.\n2. For a right-censored observation, i.e., an event that is known only to have lasted at least until time $u$, its contribution to the likelihood is the probability of surviving beyond $u$. This is given by the survival function, $S(u)$.\n\nThe total likelihood function for a set of independent observations is the product of the individual contributions.\n\nThe problem states that the dwell times in the \"on\" and \"off\" states are independent processes. The \"on\"-state dwells are governed solely by the rate constant $k_{\\mathrm{off}}$, and the \"off\"-state dwells are governed solely by $k_{\\mathrm{on}}$. Consequently, the total likelihood function $L(k_{\\mathrm{off}}, k_{\\mathrm{on}})$ can be factored into two independent components, one for each state:\n$$L(k_{\\mathrm{off}}, k_{\\mathrm{on}}) = L_{\\mathrm{on}}(k_{\\mathrm{off}}) \\cdot L_{\\mathrm{off}}(k_{\\mathrm{on}})$$\nThis separation allows us to maximize each component independently to find the respective MLEs.\n\nLet us first consider the \"on\" state. The dwell time $t$ is exponentially distributed with rate parameter $\\lambda = k_{\\mathrm{off}}$. The PDF is $f(t \\mid k_{\\mathrm{off}}) = k_{\\mathrm{off}} \\exp(-k_{\\mathrm{off}} t)$ and the survival function is $S(t \\mid k_{\\mathrm{off}}) = \\exp(-k_{\\mathrm{off}} t)$.\nThe observed data for the \"on\" state consist of $d_{\\mathrm{on}}$ completed dwells $\\{t_{i}^{\\mathrm{on}}\\}_{i=1}^{d_{\\mathrm{on}}}$ and $c_{\\mathrm{on}}$ right-censored dwells $\\{u_{j}^{\\mathrm{on}}\\}_{j=1}^{c_{\\mathrm{on}}}$.\n\nThe likelihood function for the \"on\" state data, $L_{\\mathrm{on}}(k_{\\mathrm{off}})$, is the product of the PDFs for the completed dwells and the survival functions for the censored dwells:\n$$L_{\\mathrm{on}}(k_{\\mathrm{off}}) = \\left( \\prod_{i=1}^{d_{\\mathrm{on}}} f(t_{i}^{\\mathrm{on}} \\mid k_{\\mathrm{off}}) \\right) \\left( \\prod_{j=1}^{c_{\\mathrm{on}}} S(u_{j}^{\\mathrm{on}} \\mid k_{\\mathrm{off}}) \\right)$$\nSubstituting the expressions for the exponential PDF and survival function:\n$$L_{\\mathrm{on}}(k_{\\mathrm{off}}) = \\left( \\prod_{i=1}^{d_{\\mathrm{on}}} k_{\\mathrm{off}} \\exp(-k_{\\mathrm{off}} t_{i}^{\\mathrm{on}}) \\right) \\left( \\prod_{j=1}^{c_{\\mathrm{on}}} \\exp(-k_{\\mathrm{off}} u_{j}^{\\mathrm{on}}) \\right)$$\nThis expression can be simplified by combining terms:\n$$L_{\\mathrm{on}}(k_{\\mathrm{off}}) = (k_{\\mathrm{off}})^{d_{\\mathrm{on}}} \\exp\\left(-k_{\\mathrm{off}} \\sum_{i=1}^{d_{\\mathrm{on}}} t_{i}^{\\mathrm{on}}\\right) \\exp\\left(-k_{\\mathrm{off}} \\sum_{j=1}^{c_{\\mathrm{on}}} u_{j}^{\\mathrm{on}}\\right)$$\n$$L_{\\mathrm{on}}(k_{\\mathrm{off}}) = (k_{\\mathrm{off}})^{d_{\\mathrm{on}}} \\exp\\left[-k_{\\mathrm{off}} \\left( \\sum_{i=1}^{d_{\\mathrm{on}}} t_{i}^{\\mathrm{on}} + \\sum_{j=1}^{c_{\\mathrm{on}}} u_{j}^{\\mathrm{on}} \\right)\\right]$$\nBy perfect analogy, the likelihood function for the \"off\" state data, which depends on the parameter $k_{\\mathrm{on}}$, is:\n$$L_{\\mathrm{off}}(k_{\\mathrm{on}}) = (k_{\\mathrm{on}})^{d_{\\mathrm{off}}} \\exp\\left[-k_{\\mathrm{on}} \\left( \\sum_{i=1}^{d_{\\mathrm{off}}} t_{i}^{\\mathrm{off}} + \\sum_{j=1}^{c_{\\mathrm{off}}} u_{j}^{\\mathrm{off}} \\right)\\right]$$\nThe full likelihood function is the product $L(k_{\\mathrm{off}}, k_{\\mathrm{on}}) = L_{\\mathrm{on}}(k_{\\mathrm{off}}) \\cdot L_{\\mathrm{off}}(k_{\\mathrm{on}})$. This completes the first task.\n\nTo derive the MLEs, we maximize the likelihood function. It is standard and more convenient to maximize the natural logarithm of the likelihood function, the log-likelihood $\\mathcal{L} = \\ln L$. Since $\\ln$ is a monotonic function, the maximum of $\\mathcal{L}$ occurs at the same parameter values as the maximum of $L$.\nThe total log-likelihood is:\n$$\\mathcal{L}(k_{\\mathrm{off}}, k_{\\mathrm{on}}) = \\ln L_{\\mathrm{on}}(k_{\\mathrm{off}}) + \\ln L_{\\mathrm{off}}(k_{\\mathrm{on}}) = \\mathcal{L}_{\\mathrm{on}}(k_{\\mathrm{off}}) + \\mathcal{L}_{\\mathrm{off}}(k_{\\mathrm{on}})$$\nWe can maximize $\\mathcal{L}_{\\mathrm{on}}$ with respect to $k_{\\mathrm{off}}$ and $\\mathcal{L}_{\\mathrm{off}}$ with respect to $k_{\\mathrm{on}}$ independently.\n\nFor the \"on\" state:\n$$\\mathcal{L}_{\\mathrm{on}}(k_{\\mathrm{off}}) = \\ln\\left( (k_{\\mathrm{off}})^{d_{\\mathrm{on}}} \\exp\\left[-k_{\\mathrm{off}} \\left( \\sum_{i=1}^{d_{\\mathrm{on}}} t_{i}^{\\mathrm{on}} + \\sum_{j=1}^{c_{\\mathrm{on}}} u_{j}^{\\mathrm{on}} \\right)\\right] \\right)$$\n$$\\mathcal{L}_{\\mathrm{on}}(k_{\\mathrm{off}}) = d_{\\mathrm{on}} \\ln(k_{\\mathrm{off}}) - k_{\\mathrm{off}} \\left( \\sum_{i=1}^{d_{\\mathrm{on}}} t_{i}^{\\mathrm{on}} + \\sum_{j=1}^{c_{\\mathrm{on}}} u_{j}^{\\mathrm{on}} \\right)$$\nTo find the MLE $\\hat{k}_{\\mathrm{off}}$, we take the first derivative of $\\mathcal{L}_{\\mathrm{on}}$ with respect to $k_{\\mathrm{off}}$ and set it to zero:\n$$\\frac{\\partial \\mathcal{L}_{\\mathrm{on}}}{\\partial k_{\\mathrm{off}}} = \\frac{d_{\\mathrm{on}}}{k_{\\mathrm{off}}} - \\left( \\sum_{i=1}^{d_{\\mathrm{on}}} t_{i}^{\\mathrm{on}} + \\sum_{j=1}^{c_{\\mathrm{on}}} u_{j}^{\\mathrm{on}} \\right) = 0$$\nSolving for $k_{\\mathrm{off}}$ gives the estimator $\\hat{k}_{\\mathrm{off}}$:\n$$\\frac{d_{\\mathrm{on}}}{\\hat{k}_{\\mathrm{off}}} = \\sum_{i=1}^{d_{\\mathrm{on}}} t_{i}^{\\mathrm{on}} + \\sum_{j=1}^{c_{\\mathrm{on}}} u_{j}^{\\mathrm{on}}$$\n$$\\hat{k}_{\\mathrm{off}} = \\frac{d_{\\mathrm{on}}}{\\sum_{i=1}^{d_{\\mathrm{on}}} t_{i}^{\\mathrm{on}} + \\sum_{j=1}^{c_{\\mathrm{on}}} u_{j}^{\\mathrm{on}}}$$\nThe second derivative, $\\frac{\\partial^2 \\mathcal{L}_{\\mathrm{on}}}{\\partial k_{\\mathrm{off}}^2} = -\\frac{d_{\\mathrm{on}}}{k_{\\mathrm{off}}^2}$, is negative for any $d_{\\mathrm{on}}  0$, which confirms that this critical point is a maximum. The physical interpretation of this result is that the estimated rate is the number of observed exit events ($d_{\\mathrm{on}}$) divided by the total time observed in the state (sum of all completed and censored durations).\n\nThe derivation for $\\hat{k}_{\\mathrm{on}}$ is identical in form. The log-likelihood for the \"off\" state is:\n$$\\mathcal{L}_{\\mathrm{off}}(k_{\\mathrm{on}}) = d_{\\mathrm{off}} \\ln(k_{\\mathrm{on}}) - k_{\\mathrm{on}} \\left( \\sum_{i=1}^{d_{\\mathrm{off}}} t_{i}^{\\mathrm{off}} + \\sum_{j=1}^{c_{\\mathrm{off}}} u_{j}^{\\mathrm{off}} \\right)$$\nSetting its derivative with respect to $k_{\\mathrm{on}}$ to zero yields the MLE $\\hat{k}_{\\mathrm{on}}$:\n$$\\frac{\\partial \\mathcal{L}_{\\mathrm{off}}}{\\partial k_{\\mathrm{on}}} = \\frac{d_{\\mathrm{off}}}{k_{\\mathrm{on}}} - \\left( \\sum_{i=1}^{d_{\\mathrm{off}}} t_{i}^{\\mathrm{off}} + \\sum_{j=1}^{c_{\\mathrm{off}}} u_{j}^{\\mathrm{off}} \\right) = 0$$\n$$\\hat{k}_{\\mathrm{on}} = \\frac{d_{\\mathrm{off}}}{\\sum_{i=1}^{d_{\\mathrm{off}}} t_{i}^{\\mathrm{off}} + \\sum_{j=1}^{c_{\\mathrm{off}}} u_{j}^{\\mathrm{off}}}$$\nThe final answer presents these two estimators. The first element of the matrix corresponds to the estimator for $k_{\\mathrm{off}}$ and the second to the estimator for $k_{\\mathrm{on}}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{d_{\\mathrm{on}}}{\\sum_{i=1}^{d_{\\mathrm{on}}} t_{i}^{\\mathrm{on}} + \\sum_{j=1}^{c_{\\mathrm{on}}} u_{j}^{\\mathrm{on}}}  \\frac{d_{\\mathrm{off}}}{\\sum_{i=1}^{d_{\\mathrm{off}}} t_{i}^{\\mathrm{off}} + \\sum_{j=1}^{c_{\\mathrm{off}}} u_{j}^{\\mathrm{off}}}\n\\end{pmatrix}\n}\n$$", "id": "2694303"}]}