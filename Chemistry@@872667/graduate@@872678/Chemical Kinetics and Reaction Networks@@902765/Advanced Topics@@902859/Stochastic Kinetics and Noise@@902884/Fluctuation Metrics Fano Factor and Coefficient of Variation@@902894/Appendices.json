{"hands_on_practices": [{"introduction": "To effectively use fluctuation metrics, we must first understand their behavior in a foundational model system. This exercise analyzes the simplest stochastic chemical process: the immigration-death or birth-death process. By deriving the Fano factor for this system, you will establish the crucial benchmark for Poissonian noise, where the Fano factor is unity, which is a reference point for all more complex systems [@problem_id:2643669].", "problem": "Consider a well-mixed, isothermal system with a single chemical species $X$ undergoing two reactions under stochastic mass-action kinetics: immigration $\\varnothing \\to X$ with constant rate $\\alpha$ and linear death $X \\to \\varnothing$ with propensity $\\mu X$, where $\\alpha gt; 0$ and $\\mu gt; 0$. Let $P_{n}(t)$ denote the probability that the copy number of $X$ is $n \\in \\{0,1,2,\\dots\\}$ at time $t$. Assume the system admits a stationary distribution.\n\nStarting from the chemical master equation and standard principles of continuous-time Markov chains for reaction networks, do the following:\n\n- Derive the steady-state probability mass function $p_{n} := \\lim_{t \\to \\infty} P_{n}(t)$ in closed form, expressed in terms of $n$, $\\alpha$, and $\\mu$.\n- Compute the stationary mean $\\mathbb{E}[X]$ and stationary variance $\\mathrm{Var}[X]$.\n- Using the definitions of the Fano factor $F := \\mathrm{Var}[X]/\\mathbb{E}[X]$ and the squared coefficient of variation $\\mathrm{CV}^{2} := \\mathrm{Var}[X]/\\big(\\mathbb{E}[X]\\big)^{2}$, express $F$ and $\\mathrm{CV}^{2}$ in terms of $\\alpha$ and $\\mu$.\n\nProvide your final answer as a single row matrix with $4$ entries in the following order:\n$$(\\mathbb{E}[X],\\; p_{n},\\; F,\\; \\mathrm{CV}^{2}).$$\nNo units are required. If you introduce any auxiliary symbols, define them unambiguously. Do not use any approximations.", "solution": "The problem posed is a standard, well-posed problem in the theory of stochastic chemical kinetics and is therefore valid. We shall proceed with its solution.\n\nLet $n$ denote the copy number of the chemical species $X$, which is a non-negative integer, $n \\in \\{0, 1, 2, \\dots\\}$. The system is governed by two elementary reactions:\n1.  Immigration: $\\varnothing \\xrightarrow{\\alpha} X$. This is a zeroth-order reaction that creates a molecule of $X$. Its rate is a constant, $\\alpha$, which represents the propensity of this reaction. This process transitions the system from state $n$ to state $n+1$.\n2.  Linear Death: $X \\xrightarrow{\\mu} \\varnothing$. This is a first-order reaction that consumes a molecule of $X$. Its propensity is $\\mu n$, where $\\mu$ is the rate constant. This process transitions the system from state $n$ to state $n-1$.\n\nThe chemical master equation describes the time evolution of $P_n(t)$, the probability of the system being in state $n$ at time $t$. For $n \\ge 1$, the change in $P_n(t)$ is due to four processes:\n-   Gain from state $n-1$ via immigration (rate $\\alpha$).\n-   Gain from state $n+1$ via death (rate $\\mu(n+1)$).\n-   Loss from state $n$ via immigration (rate $\\alpha$).\n-   Loss from state $n$ via death (rate $\\mu n$).\n\nThis leads to the following system of ordinary differential equations:\n$$ \\frac{dP_n(t)}{dt} = \\alpha P_{n-1}(t) + \\mu(n+1)P_{n+1}(t) - (\\alpha + \\mu n)P_n(t), \\quad \\text{for } n \\ge 1 $$\nFor the state $n=0$, molecules can only be created by immigration. Molecules cannot be consumed as there are none. The master equation for $n=0$ is:\n$$ \\frac{dP_0(t)}{dt} = \\mu P_1(t) - \\alpha P_0(t) $$\n\nAt steady state, the probabilities are constant in time, i.e., $\\lim_{t \\to \\infty} P_n(t) = p_n$, and thus $\\frac{dp_n}{dt} = 0$ for all $n$. The steady-state master equations are:\n$$ 0 = \\alpha p_{n-1} + \\mu(n+1)p_{n+1} - (\\alpha + \\mu n)p_n, \\quad \\text{for } n \\ge 1 \\quad (1)$$\n$$ 0 = \\mu p_1 - \\alpha p_0, \\quad \\text{for } n=0 \\quad (2)$$\n\nFor a one-dimensional birth-death process such as this, the steady state is characterized by detailed balance, where the net probability flux between any two adjacent states is zero. The flux from state $n$ to $n+1$ via immigration is $\\alpha p_n$. The flux from state $n+1$ to $n$ via death is $\\mu(n+1)p_{n+1}$. Equating these gives:\n$$ \\alpha p_n = \\mu(n+1)p_{n+1} $$\nThis yields the recurrence relation:\n$$ p_{n+1} = \\frac{\\alpha}{\\mu(n+1)} p_n, \\quad \\text{for } n \\ge 0 $$\nOne can verify this relation satisfies the full master equations $(1)$ and $(2)$. For $n=0$, it gives $\\mu p_1 = \\alpha p_0$, which is exactly equation $(2)$. For $n \\ge 1$, substituting $p_{n+1}$ and $p_{n-1}$ (from the recurrence) into equation $(1)$ confirms it holds.\n\nWe solve this recurrence relation for $p_n$ in terms of $p_0$:\n$$ p_1 = \\frac{\\alpha}{\\mu(1)} p_0 $$\n$$ p_2 = \\frac{\\alpha}{\\mu(2)} p_1 = \\frac{\\alpha}{\\mu(2)} \\frac{\\alpha}{\\mu(1)} p_0 = \\frac{1}{2!} \\left(\\frac{\\alpha}{\\mu}\\right)^2 p_0 $$\nBy induction, the general solution is:\n$$ p_n = \\frac{1}{n!} \\left(\\frac{\\alpha}{\\mu}\\right)^n p_0 $$\n\nTo determine $p_0$, we use the normalization condition $\\sum_{n=0}^{\\infty} p_n = 1$:\n$$ \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\frac{\\alpha}{\\mu}\\right)^n p_0 = p_0 \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\frac{\\alpha}{\\mu}\\right)^n = 1 $$\nThe summation is the Taylor series for the exponential function, $\\sum_{k=0}^{\\infty} \\frac{x^k}{k!} = \\exp(x)$.\n$$ p_0 \\exp\\left(\\frac{\\alpha}{\\mu}\\right) = 1 \\implies p_0 = \\exp\\left(-\\frac{\\alpha}{\\mu}\\right) $$\nSubstituting this back, we obtain the steady-state probability mass function:\n$$ p_n = \\frac{(\\alpha/\\mu)^n \\exp(-\\alpha/\\mu)}{n!} $$\nThis is the probability mass function of a Poisson distribution with parameter $\\lambda = \\alpha/\\mu$.\n\nThe mean $\\mathbb{E}[X]$ and variance $\\mathrm{Var}[X]$ of a Poisson distribution with parameter $\\lambda$ are both equal to $\\lambda$. Therefore:\n$$ \\mathbb{E}[X] = \\frac{\\alpha}{\\mu} $$\n$$ \\mathrm{Var}[X] = \\frac{\\alpha}{\\mu} $$\nAlternatively, we can compute these moments directly. The mean is:\n$$ \\mathbb{E}[X] = \\sum_{n=0}^{\\infty} n p_n = \\sum_{n=1}^{\\infty} n \\frac{(\\alpha/\\mu)^n \\exp(-\\alpha/\\mu)}{n!} = \\frac{\\alpha}{\\mu} \\exp\\left(-\\frac{\\alpha}{\\mu}\\right) \\sum_{n=1}^{\\infty} \\frac{(\\alpha/\\mu)^{n-1}}{(n-1)!} $$\nLetting $k=n-1$, the sum is $\\sum_{k=0}^{\\infty} \\frac{(\\alpha/\\mu)^k}{k!} = \\exp(\\alpha/\\mu)$. Thus, $\\mathbb{E}[X] = \\frac{\\alpha}{\\mu}$.\nFor the variance, we compute the second factorial moment:\n$$ \\mathbb{E}[X(X-1)] = \\sum_{n=0}^{\\infty} n(n-1) p_n = \\sum_{n=2}^{\\infty} n(n-1) \\frac{(\\alpha/\\mu)^n \\exp(-\\alpha/\\mu)}{n!} = \\left(\\frac{\\alpha}{\\mu}\\right)^2 \\exp\\left(-\\frac{\\alpha}{\\mu}\\right) \\sum_{n=2}^{\\infty} \\frac{(\\alpha/\\mu)^{n-2}}{(n-2)!} $$\nThe sum again evaluates to $\\exp(\\alpha/\\mu)$, yielding $\\mathbb{E}[X(X-1)] = (\\alpha/\\mu)^2$.\nThe variance is $\\mathrm{Var}[X] = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 = \\mathbb{E}[X(X-1)] + \\mathbb{E}[X] - (\\mathbb{E}[X])^2$.\n$$ \\mathrm{Var}[X] = \\left(\\frac{\\alpha}{\\mu}\\right)^2 + \\frac{\\alpha}{\\mu} - \\left(\\frac{\\alpha}{\\mu}\\right)^2 = \\frac{\\alpha}{\\mu} $$\n\nNow, we compute the required fluctuation metrics. The Fano factor $F$ is defined as:\n$$ F = \\frac{\\mathrm{Var}[X]}{\\mathbb{E}[X]} = \\frac{\\alpha/\\mu}{\\alpha/\\mu} = 1 $$\nThe squared coefficient of variation $\\mathrm{CV}^2$ is defined as:\n$$ \\mathrm{CV}^2 = \\frac{\\mathrm{Var}[X]}{(\\mathbb{E}[X])^2} = \\frac{\\alpha/\\mu}{(\\alpha/\\mu)^2} = \\frac{\\mu}{\\alpha} $$\n\nThe requested quantities are thus determined. We assemble them in the specified order $(\\mathbb{E}[X], p_n, F, \\mathrm{CV}^2)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{\\alpha}{\\mu}  \\frac{\\left(\\frac{\\alpha}{\\mu}\\right)^{n} \\exp\\left(-\\frac{\\alpha}{\\mu}\\right)}{n!}  1  \\frac{\\mu}{\\alpha} \\end{pmatrix}}\n$$", "id": "2643669"}, {"introduction": "Building on the single-species benchmark, this practice explores how fluctuation metrics apply to a derived quantity—the difference between two independent molecular populations. This exercise will challenge you to apply the basic properties of expectation and variance to a composite variable, $Z = X - Y$. The resulting expression for the Fano factor reveals important, and perhaps surprising, behaviors, highlighting situations where the metric can diverge and requires careful interpretation [@problem_id:2643661].", "problem": "Consider two chemically independent birth–death processes representing two noninteracting gene products in a well-mixed reactor of constant volume. Species $X$ is produced by a zero-order reaction $\\varnothing \\to X$ at constant rate $\\alpha_X$ (molecules per unit time) and degraded by a first-order reaction $X \\to \\varnothing$ at rate $\\delta X$, where $\\delta$ (per unit time) is the same degradation constant for both species. Species $Y$ is produced by $\\varnothing \\to Y$ at rate $\\alpha_Y$ and degraded by $Y \\to \\varnothing$ at rate $\\delta Y$. Assume the two reaction channels are statistically independent and the system is at stationary steady state under the Chemical Master Equation (CME).\n\nIt is a well-tested fact for such linear birth–death kinetics that the stationary distribution of each species is Poisson with mean equal to its variance. Define the random variables $X$ and $Y$ as the steady-state molecule counts of the two species, and define the difference $Z = X - Y$. The Fano factor (FF) of a random variable $W$ is defined as $\\mathrm{FF}(W) = \\mathrm{Var}(W)/\\mathbb{E}[W]$. The coefficient of variation (CV) of $W$ is defined as $\\mathrm{CV}(W) = \\sqrt{\\mathrm{Var}(W)}/|\\mathbb{E}[W]|$.\n\nUsing only these foundational definitions and properties of independent random variables, derive a closed-form expression for the Fano factor of $Z$ in terms of $\\alpha_X$, $\\alpha_Y$, and $\\delta$. Then, briefly discuss how this expression should be interpreted when $\\mathbb{E}[Z]$ is small or equal to $0$.\n\nExpress your final answer as a single closed-form analytic expression for $\\mathrm{FF}(Z)$ in terms of $\\alpha_X$, $\\alpha_Y$, and $\\delta$. Do not include any units in the final answer. No numerical evaluation is required.", "solution": "The problem statement is scientifically grounded, well-posed, objective, and self-contained. It describes a canonical model in stochastic chemical kinetics—the linear birth–death process—and its known statistical properties. The definitions are standard and the objective is clear. Thus, the problem is valid, and we may proceed with the derivation.\n\nThe objective is to derive an expression for the Fano factor of the random variable $Z$, defined as the difference between the molecule counts of two species, $X$ and $Y$. The definition of the Fano factor for a random variable $W$ is given as $\\mathrm{FF}(W) = \\frac{\\mathrm{Var}(W)}{\\mathbb{E}[W]}$. For our variable $Z = X - Y$, this becomes:\n$$\n\\mathrm{FF}(Z) = \\frac{\\mathrm{Var}(Z)}{\\mathbb{E}[Z]} = \\frac{\\mathrm{Var}(X - Y)}{\\mathbb{E}[X - Y]}\n$$\nWe must first determine the mean, $\\mathbb{E}[Z]$, and variance, $\\mathrm{Var}(Z)$, of $Z$.\n\nThe species $X$ and $Y$ are generated by independent birth–death processes.\nFor species $X$, the reactions are $\\varnothing \\xrightarrow{\\alpha_X} X$ and $X \\xrightarrow{\\delta} \\varnothing$. At stationary steady state, the average rate of production must equal the average rate of degradation. The production rate is a constant, $\\alpha_X$. The degradation rate is $\\delta X$, so its average is $\\delta \\mathbb{E}[X]$. Equating these gives:\n$$\n\\alpha_X = \\delta \\mathbb{E}[X]\n$$\nSolving for the mean number of molecules of $X$ yields:\n$$\n\\mathbb{E}[X] = \\frac{\\alpha_X}{\\delta}\n$$\nSimilarly, for species $Y$, with reactions $\\varnothing \\xrightarrow{\\alpha_Y} Y$ and $Y \\xrightarrow{\\delta} \\varnothing$, the steady-state mean is:\n$$\n\\mathbb{E}[Y] = \\frac{\\alpha_Y}{\\delta}\n$$\nThe problem states that for such linear kinetics, the stationary distribution of each species is Poisson. A defining property of the Poisson distribution is that its variance is equal to its mean. Therefore:\n$$\n\\mathrm{Var}(X) = \\mathbb{E}[X] = \\frac{\\alpha_X}{\\delta}\n$$\n$$\n\\mathrm{Var(Y)} = \\mathbb{E}[Y] = \\frac{\\alpha_Y}{\\delta}\n$$\nNow we can compute the mean and variance of $Z = X - Y$.\nUsing the linearity of the expectation operator, the mean of $Z$ is:\n$$\n\\mathbb{E}[Z] = \\mathbb{E}[X - Y] = \\mathbb{E}[X] - \\mathbb{E}[Y] = \\frac{\\alpha_X}{\\delta} - \\frac{\\alpha_Y}{\\delta} = \\frac{\\alpha_X - \\alpha_Y}{\\delta}\n$$\nThe problem states that the reaction channels are statistically independent, which implies that the random variables $X$ and $Y$ are independent. For the variance of a difference of two independent random variables, we have $\\mathrm{Var}(A - B) = \\mathrm{Var}(A) + \\mathrm{Var}(B)$. Applying this property to $Z$:\n$$\n\\mathrm{Var}(Z) = \\mathrm{Var}(X - Y) = \\mathrm{Var}(X) + \\mathrm{Var}(Y) = \\frac{\\alpha_X}{\\delta} + \\frac{\\alpha_Y}{\\delta} = \\frac{\\alpha_X + \\alpha_Y}{\\delta}\n$$\nWith the expressions for the mean and variance of $Z$, we can now construct the Fano factor:\n$$\n\\mathrm{FF}(Z) = \\frac{\\mathrm{Var}(Z)}{\\mathbb{E}[Z]} = \\frac{\\left(\\frac{\\alpha_X + \\alpha_Y}{\\delta}\\right)}{\\left(\\frac{\\alpha_X - \\alpha_Y}{\\delta}\\right)}\n$$\nThe degradation constant $\\delta$ cancels from the numerator and denominator, yielding the final expression:\n$$\n\\mathrm{FF}(Z) = \\frac{\\alpha_X + \\alpha_Y}{\\alpha_X - \\alpha_Y}\n$$\nThis expression holds provided that the denominator is non-zero, i.e., $\\alpha_X \\neq \\alpha_Y$.\n\nThe problem also requests a discussion of the interpretation when $\\mathbb{E}[Z]$ is small or equal to $0$. From our derivation, $\\mathbb{E}[Z] = \\frac{\\alpha_X - \\alpha_Y}{\\delta}$. This mean is equal to $0$ if and only if $\\alpha_X = \\alpha_Y$.\nIf $\\alpha_X = \\alpha_Y$, the denominator of our expression for $\\mathrm{FF}(Z)$ becomes $0$. The numerator, however, becomes $\\alpha_X + \\alpha_Y = 2\\alpha_X  0$ (assuming non-trivial production). In this case, the Fano factor is mathematically undefined as it involves division by zero.\n\nThe interpretation of this divergence is fundamental. The Fano factor is a metric of *relative* fluctuation, scaled by the mean. When the mean is zero, any non-zero fluctuation (variance) becomes infinitely large relative to the mean. In our case, when $\\alpha_X = \\alpha_Y$, the variance is $\\mathrm{Var}(Z) = \\frac{2\\alpha_X}{\\delta}$, which is a finite, positive quantity. The Fano factor diverges, signaling that it is not an appropriate or useful metric for characterizing fluctuations around a zero mean. The variance itself, $\\mathrm{Var}(Z)$, remains well-defined and serves as the proper absolute measure of the noise magnitude. As $\\mathbb{E}[Z]$ approaches $0$, the Fano factor $|\\mathrm{FF}(Z)| \\to \\infty$, indicating that the intrinsic noise of the system completely dominates the average signal.", "answer": "$$\n\\boxed{\\frac{\\alpha_X + \\alpha_Y}{\\alpha_X - \\alpha_Y}}\n$$", "id": "2643661"}, {"introduction": "This final practice connects the theoretical analysis of intrinsic noise to the practical realities of experimental measurement. Real-world detectors are rarely perfect, and this exercise models the observation process as an independent \"thinning\" of the true molecular population with a certain detection probability $p$. By analyzing this scenario, you will learn how measurement limitations affect the observed Fano factor and coefficient of variation, providing insight into what can be concluded from noisy experimental data [@problem_id:2643680].", "problem": "A single molecular species is produced and degraded in a well-mixed volume at stationarity, so that the intrinsic molecule count $X$ at the time of measurement is Poisson-distributed with mean $\\mu$, i.e., $\\mathbb{E}[X]=\\mu$ and $\\mathrm{Var}(X)=\\mu$. An imaging detector registers each molecule independently with probability $p \\in (0,1)$, producing an observed count $Y$ obtained by independent Bernoulli trials on the $X$ molecules. Thus, conditional on $X=x$, the reported count is $Y \\mid X=x \\sim \\mathrm{Binomial}(x,p)$.\n\nUsing only the definitions of expectation, variance, the law of total expectation and the law of total variance, and the definitions of the Fano factor (F) and the coefficient of variation (CV), derive the observed Fano factor $F_{\\mathrm{obs}}$ and the observed coefficient of variation $\\mathrm{CV}_{\\mathrm{obs}}$ of $Y$ in terms of $p$ and the true mean $\\mu$. Provide your final answer as a row matrix $\\left(F_{\\mathrm{obs}}, \\mathrm{CV}_{\\mathrm{obs}}\\right)$, with no units. No numerical rounding is required.", "solution": "The problem statement is scientifically grounded, well-posed, and self-contained. It describes a standard model of binomial subsampling of a Poisson-distributed population, a process often referred to as \"thinning\". All required information for a unique solution is provided. The task is to derive fluctuation metrics using fundamental laws of probability, which is a valid and non-trivial exercise. I will therefore proceed with the derivation.\n\nThe objective is to compute the observed Fano factor, $F_{\\mathrm{obs}}$, and the observed coefficient of variation, $\\mathrm{CV}_{\\mathrm{obs}}$, for the random variable $Y$. These are defined as:\n$$\nF_{\\mathrm{obs}} = \\frac{\\mathrm{Var}(Y)}{\\mathbb{E}[Y]}\n$$\n$$\n\\mathrm{CV}_{\\mathrm{obs}} = \\frac{\\sqrt{\\mathrm{Var}(Y)}}{\\mathbb{E}[Y]}\n$$\nTo compute these quantities, we must first determine the expectation, $\\mathbb{E}[Y]$, and the variance, $\\mathrm{Var}(Y)$, of the observed count $Y$. The problem specifies that this must be done using the law of total expectation and the law of total variance.\n\nWe are given the following:\n1.  The true molecule count $X$ follows a Poisson distribution with mean $\\mu$. Thus, $\\mathbb{E}[X] = \\mu$ and $\\mathrm{Var}(X) = \\mu$.\n2.  Conditional on the true count being $X=x$, the observed count $Y$ follows a Binomial distribution, $Y \\mid X=x \\sim \\mathrm{Binomial}(x,p)$, where $p$ is the detection probability.\n\nFirst, we compute the expectation of $Y$.\nAccording to the law of total expectation, $\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y \\mid X]]$.\nThe conditional expectation of $Y$ given $X=x$ is the expectation of a $\\mathrm{Binomial}(x,p)$ distribution, which is $xp$.\nTherefore, the random variable $\\mathbb{E}[Y \\mid X]$ is given by the expression $Xp$.\nNow, we take the expectation of this random variable with respect to the distribution of $X$:\n$$\n\\mathbb{E}[Y] = \\mathbb{E}[Xp] = p \\mathbb{E}[X]\n$$\nSubstituting the given mean of $X$, $\\mathbb{E}[X] = \\mu$, we obtain the mean of $Y$:\n$$\n\\mathbb{E}[Y] = p\\mu\n$$\n\nNext, we compute the variance of $Y$.\nAccording to the law of total variance, $\\mathrm{Var}(Y) = \\mathbb{E}[\\mathrm{Var}(Y \\mid X)] + \\mathrm{Var}(\\mathbb{E}[Y \\mid X])$. We evaluate each term separately.\n\nThe first term is the expectation of the conditional variance, $\\mathbb{E}[\\mathrm{Var}(Y \\mid X)]$.\nThe conditional variance of $Y$ given $X=x$ is the variance of a $\\mathrm{Binomial}(x,p)$ distribution, which is $xp(1-p)$.\nSo, the random variable $\\mathrm{Var}(Y \\mid X)$ is given by $Xp(1-p)$.\nTaking the expectation with respect to $X$:\n$$\n\\mathbb{E}[\\mathrm{Var}(Y \\mid X)] = \\mathbb{E}[Xp(1-p)] = p(1-p)\\mathbb{E}[X]\n$$\nUsing $\\mathbb{E}[X] = \\mu$, this term becomes:\n$$\n\\mathbb{E}[\\mathrm{Var}(Y \\mid X)] = \\mu p(1-p)\n$$\n\nThe second term is the variance of the conditional expectation, $\\mathrm{Var}(\\mathbb{E}[Y \\mid X])$.\nAs determined earlier, the random variable $\\mathbb{E}[Y \\mid X]$ is $Xp$.\nIts variance is calculated as:\n$$\n\\mathrm{Var}(\\mathbb{E}[Y \\mid X]) = \\mathrm{Var}(Xp)\n$$\nUsing the variance property $\\mathrm{Var}(aZ) = a^2\\mathrm{Var}(Z)$, where $a$ is a constant, we get:\n$$\n\\mathrm{Var}(Xp) = p^2\\mathrm{Var}(X)\n$$\nSubstituting the given variance of $X$, $\\mathrm{Var}(X) = \\mu$:\n$$\n\\mathrm{Var}(\\mathbb{E}[Y \\mid X]) = p^2\\mu\n$$\n\nNow, we sum the two terms to find the total variance of $Y$:\n$$\n\\mathrm{Var}(Y) = \\mathbb{E}[\\mathrm{Var}(Y \\mid X)] + \\mathrm{Var}(\\mathbb{E}[Y \\mid X]) = \\mu p(1-p) + p^2\\mu\n$$\nFactoring out $\\mu p$:\n$$\n\\mathrm{Var}(Y) = \\mu p ( (1-p) + p ) = \\mu p (1)\n$$\n$$\n\\mathrm{Var}(Y) = p\\mu\n$$\nWe find that $\\mathrm{Var}(Y)=\\mathbb{E}[Y]=p\\mu$. This implies that the observed count $Y$ also follows a Poisson distribution, specifically $Y \\sim \\mathrm{Poisson}(p\\mu)$.\n\nWith the mean and variance of $Y$ established, we can now calculate the required fluctuation metrics.\n\nThe observed Fano factor, $F_{\\mathrm{obs}}$, is:\n$$\nF_{\\mathrm{obs}} = \\frac{\\mathrm{Var}(Y)}{\\mathbb{E}[Y]} = \\frac{p\\mu}{p\\mu} = 1\n$$\nThe Fano factor is unity, which is characteristic of a Poisson process. The original process was Poissonian with $F_X = \\frac{\\mu}{\\mu} = 1$, and the binomial observation process preserves this property.\n\nThe observed coefficient of variation, $\\mathrm{CV}_{\\mathrm{obs}}$, is:\n$$\n\\mathrm{CV}_{\\mathrm{obs}} = \\frac{\\sqrt{\\mathrm{Var}(Y)}}{\\mathbb{E}[Y]} = \\frac{\\sqrt{p\\mu}}{p\\mu}\n$$\nSimplifying this expression:\n$$\n\\mathrm{CV}_{\\mathrm{obs}} = \\frac{(p\\mu)^{1/2}}{(p\\mu)^1} = (p\\mu)^{-1/2} = \\frac{1}{\\sqrt{p\\mu}}\n$$\nThis result is contingent on $\\mu  0$ and $p  0$, as the coefficient of variation is undefined if the mean is zero. The problem specifies $p \\in (0,1)$, and a non-trivial case implies $\\mu  0$.\n\nThe final results are $F_{\\mathrm{obs}} = 1$ and $\\mathrm{CV}_{\\mathrm{obs}} = \\frac{1}{\\sqrt{p\\mu}}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1  \\frac{1}{\\sqrt{\\mu p}}\n\\end{pmatrix}\n}\n$$", "id": "2643680"}]}