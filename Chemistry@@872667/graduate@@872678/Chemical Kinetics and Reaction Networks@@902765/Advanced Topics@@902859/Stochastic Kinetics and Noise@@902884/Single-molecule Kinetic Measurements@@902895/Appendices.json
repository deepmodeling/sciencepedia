{"hands_on_practices": [{"introduction": "A crucial aspect of single-molecule analysis is understanding and correcting for the limitations of our measurement apparatus. This practice addresses the \"detector dead time\" problem, where very short-lived events are missed entirely, leading to a systematic bias in observed kinetic rates. By working through this exercise, you will learn how to quantify this bias and, more importantly, how to derive a statistically sound correction using the principle of maximum likelihood, ensuring your estimated rates accurately reflect the true molecular dynamics. [@problem_id:2674069]", "problem": "In a single-molecule dwell-time experiment, the true residence time in a state is modeled as an independent and identically distributed exponential random variable with rate parameter $k$, so that the probability density function is $f(t \\mid k) = k \\exp(-k t)$ for $t \\ge 0$. The detector has a fixed dead time $\\tau_{d} > 0$, meaning that any event with true duration $T  \\tau_{d}$ is completely unobserved and hence absent from the recorded data set. For events with $T \\ge \\tau_{d}$, the full true duration $T$ is recorded without error. Let the observed sample be $\\{t_{i}\\}_{i=1}^{n}$ with each $t_{i} \\ge \\tau_{d}$, arising from the conditional distribution of $T$ given $T \\ge \\tau_{d}$.\n\nAn experimentalist naively estimates $k$ by treating $\\{t_{i}\\}$ as if they were untruncated and uses the estimator $\\hat{k}_{\\text{naive}} = 1/\\bar{t}$, where $\\bar{t} = \\frac{1}{n} \\sum_{i=1}^{n} t_{i}$. Starting from the definitions of conditional densities and the law of large numbers, and using the likelihood principle for independent observations:\n\n1. Define the asymptotic bias of the naive estimator as $\\operatorname{plim}_{n \\to \\infty} \\hat{k}_{\\text{naive}} - k$ and derive it as an explicit function of $k$ and $\\tau_{d}$.\n2. Derive, from first principles, the maximum likelihood estimator under the correctly truncated exponential likelihood, expressed in closed form in terms of $\\bar{t}$ and $\\tau_{d}$.\n\nProvide your final answer as a single row matrix containing two entries: first, the asymptotic bias from part 1, and second, the corrected maximum likelihood estimator from part 2. No numerical evaluation is required, and no rounding is needed. Report only the analytic expressions.", "solution": "The problem statement is scientifically sound, well-posed, and objective. It represents a standard and non-trivial problem in the statistical analysis of experimental data subject to truncation, which is a common occurrence in single-molecule biophysics and chemical kinetics. All necessary information is provided for a complete derivation. Therefore, the problem is valid, and a solution will be provided.\n\nThe problem asks for two derivations related to the estimation of a rate constant $k$ from a truncated exponential distribution.\n\nPart 1: Asymptotic Bias of the Naive Estimator\n\nThe true residence time $T$ follows an exponential distribution with probability density function (PDF) $f(t \\mid k) = k \\exp(-k t)$ for $t \\ge 0$. Due to detector dead time $\\tau_{d}$, only events with $T \\ge \\tau_{d}$ are observed. The observed data $\\{t_{i}\\}$ are therefore drawn from the distribution of $T$ conditional on $T \\ge \\tau_{d}$.\n\nThe naive estimator is given by $\\hat{k}_{\\text{naive}} = 1/\\bar{t}$, where $\\bar{t} = \\frac{1}{n} \\sum_{i=1}^{n} t_{i}$. The asymptotic bias is defined as $\\operatorname{plim}_{n \\to \\infty} \\hat{k}_{\\text{naive}} - k$.\n\nBy the law of large numbers, the sample mean $\\bar{t}$ converges in probability to the expected value of the observed random variable. Let us denote the observed time as a random variable $T_{obs}$. The distribution of $T_{obs}$ is that of $T$ conditioned on the event $T \\ge \\tau_{d}$. Thus, $\\operatorname{plim}_{n \\to \\infty} \\bar{t} = E[T \\mid T \\ge \\tau_{d}]$.\n\nUsing the continuous form of the law of large numbers and properties of probability limits, we have:\n$$\n\\operatorname{plim}_{n \\to \\infty} \\hat{k}_{\\text{naive}} = \\operatorname{plim}_{n \\to \\infty} \\frac{1}{\\bar{t}} = \\frac{1}{\\operatorname{plim}_{n \\to \\infty} \\bar{t}} = \\frac{1}{E[T \\mid T \\ge \\tau_{d}]}\n$$\nThe asymptotic bias is therefore $\\frac{1}{E[T \\mid T \\ge \\tau_{d}]} - k$.\n\nTo calculate the conditional expectation $E[T \\mid T \\ge \\tau_{d}]$, we first need the probability of the conditioning event:\n$$\nP(T \\ge \\tau_{d}) = \\int_{\\tau_{d}}^{\\infty} f(t \\mid k) \\, dt = \\int_{\\tau_{d}}^{\\infty} k \\exp(-kt) \\, dt = \\left[ -\\exp(-kt) \\right]_{\\tau_{d}}^{\\infty} = 0 - (-\\exp(-k\\tau_{d})) = \\exp(-k\\tau_{d})\n$$\nThe PDF of the truncated distribution, let's call it $g(t)$, for an observed time $t \\ge \\tau_{d}$ is:\n$$\ng(t) = \\frac{f(t \\mid k)}{P(T \\ge \\tau_{d})} = \\frac{k \\exp(-kt)}{\\exp(-k\\tau_{d})} = k \\exp(-k(t - \\tau_{d})), \\quad \\text{for } t \\ge \\tau_{d}\n$$\nNow, we compute the conditional expectation:\n$$\nE[T \\mid T \\ge \\tau_{d}] = \\int_{\\tau_{d}}^{\\infty} t \\cdot g(t) \\, dt = \\int_{\\tau_{d}}^{\\infty} t \\cdot k \\exp(-k(t - \\tau_{d})) \\, dt\n$$\nLet's perform a change of variables with $u = t - \\tau_{d}$, which implies $t = u + \\tau_{d}$ and $dt = du$. The lower limit of integration becomes $u = \\tau_{d} - \\tau_{d} = 0$, and the upper limit remains $\\infty$.\n$$\nE[T \\mid T \\ge \\tau_{d}] = \\int_{0}^{\\infty} (u + \\tau_{d}) \\cdot k \\exp(-ku) \\, du = \\int_{0}^{\\infty} uk \\exp(-ku) \\, du + \\tau_{d} \\int_{0}^{\\infty} k \\exp(-ku) \\, du\n$$\nThe first integral is the expected value of a standard exponential random variable with rate $k$, which is $1/k$. The second integral is the integral of the exponential PDF over its support, which is $1$.\n$$\nE[T \\mid T \\ge \\tau_{d}] = \\frac{1}{k} + \\tau_{d}\n$$\nThis result is a manifestation of the memoryless property of the exponential distribution. The expected additional time to wait, given that $\\tau_{d}$ has already passed, is the same as the original unconditional expected time, $1/k$. So the total expected time is $\\tau_{d} + 1/k$.\n\nSubstituting this back into the expression for the asymptotic bias:\n$$\n\\text{Asymptotic Bias} = \\frac{1}{\\frac{1}{k} + \\tau_{d}} - k = \\frac{k}{1 + k\\tau_{d}} - k = k \\left( \\frac{1}{1 + k\\tau_{d}} - 1 \\right) = k \\left( \\frac{1 - (1 + k\\tau_{d})}{1 + k\\tau_{d}} \\right) = -\\frac{k^{2} \\tau_{d}}{1 + k \\tau_{d}}\n$$\n\nPart 2: Maximum Likelihood Estimator (MLE)\n\nThe likelihood function $L(k)$ for the observed independent and identically distributed sample $\\{t_{i}\\}_{i=1}^{n}$ is the product of the PDFs of the truncated distribution evaluated at each data point:\n$$\nL(k; \\{t_{i}\\}) = \\prod_{i=1}^{n} g(t_{i}) = \\prod_{i=1}^{n} k \\exp(-k(t_{i} - \\tau_{d}))\n$$\nIt is more convenient to work with the log-likelihood function, $\\mathcal{L}(k) = \\ln(L(k))$:\n$$\n\\mathcal{L}(k) = \\ln \\left( \\prod_{i=1}^{n} k \\exp(-k(t_{i} - \\tau_{d})) \\right) = \\sum_{i=1}^{n} \\ln(k \\exp(-k(t_{i} - \\tau_{d})))\n$$\n$$\n\\mathcal{L}(k) = \\sum_{i=1}^{n} \\left[ \\ln(k) - k(t_{i} - \\tau_{d}) \\right] = n \\ln(k) - k \\sum_{i=1}^{n} (t_{i} - \\tau_{d})\n$$\nWe can express the sum in terms of the sample mean $\\bar{t} = \\frac{1}{n} \\sum_{i=1}^{n} t_{i}$.\n$$\n\\sum_{i=1}^{n} (t_{i} - \\tau_{d}) = \\left(\\sum_{i=1}^{n} t_{i}\\right) - n\\tau_{d} = n\\bar{t} - n\\tau_{d} = n(\\bar{t} - \\tau_{d})\n$$\nSo, the log-likelihood is:\n$$\n\\mathcal{L}(k) = n \\ln(k) - n k (\\bar{t} - \\tau_{d})\n$$\nTo find the maximum likelihood estimator $\\hat{k}_{\\text{MLE}}$, we differentiate $\\mathcal{L}(k)$ with respect to $k$ and set the result to zero:\n$$\n\\frac{d\\mathcal{L}(k)}{dk} = \\frac{n}{k} - n(\\bar{t} - \\tau_{d}) = 0\n$$\nSolving for $k$ gives the estimator $\\hat{k}_{\\text{MLE}}$:\n$$\n\\frac{n}{\\hat{k}_{\\text{MLE}}} = n(\\bar{t} - \\tau_{d}) \\implies \\hat{k}_{\\text{MLE}} = \\frac{1}{\\bar{t} - \\tau_{d}}\n$$\nTo verify that this is a maximum, we examine the second derivative:\n$$\n\\frac{d^{2}\\mathcal{L}(k)}{dk^{2}} = \\frac{d}{dk} \\left( \\frac{n}{k} - n(\\bar{t} - \\tau_{d}) \\right) = -\\frac{n}{k^{2}}\n$$\nSince $n > 0$ and $k^{2} > 0$, the second derivative is always negative, which confirms that the log-likelihood function is concave and our solution corresponds to a maximum.\n\nThe two requested quantities are the asymptotic bias, $-\\frac{k^{2} \\tau_{d}}{1 + k \\tau_{d}}$, and the maximum likelihood estimator, $\\frac{1}{\\bar{t} - \\tau_{d}}$.", "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{k^{2} \\tau_{d}}{1 + k \\tau_{d}}  \\frac{1}{\\bar{t} - \\tau_{d}} \\end{pmatrix}}\n$$", "id": "2674069"}, {"introduction": "In single-molecule fluorescence experiments, a common observation is \"blinking,\" where the signal intermittently disappears. This could be due to the biomolecule switching to a non-fluorescent conformation (a kinetic process) or a fluorophore-intrinsic process like entering a triplet state (a photophysical artifact). This exercise provides a powerful conceptual framework for experimental design, demonstrating how varying the excitation laser power can create a clear, quantitative signature to distinguish between these fundamentally different mechanisms. [@problem_id:2674086]", "problem": "You are investigating fluorescence blinking in a single-molecule experiment on a labeled biomolecule observed as a $2$-state trajectory with an emissive bright state $B$ and a non-emissive dark state $X$. You consider two mechanistic hypotheses for the origin of the dark state. Hypothesis K (kinetic off-state): $B \\rightleftarrows X$ are conformational or binding transitions of the biomolecule with effective first-order rate constants $k_{BX}$ and $k_{XB}$ that do not depend on the excitation intensity $I$. Hypothesis P (photophysical dark state): $X$ is a light-accessible photophysical dark state, entered from $B$ through a single-photon driven step with rate proportional to $I$, and exited by a thermally activated step independent of $I$. Experiments are conducted in a regime where photobleaching is negligible on the observation timescale and excitation is far from saturation of the emissive transition.\n\nUse only the following fundamental bases: (i) for a continuous-time Markov two-state process, dwell times in each state are exponentially distributed with mean equal to the inverse of the total exit rate from that state; (ii) for a single-photon induced transition, the rate is proportional to the excitation intensity $I$; (iii) at steady state, the fraction of time in a state equals the ratio of the incoming rate to the sum of incoming and outgoing rates.\n\nYou acquire long time traces at several excitation intensities $I$ and extract the mean on-time $\\langle \\tau_{\\mathrm{on}} \\rangle$ (time spent in $B$ between dark excursions), the mean off-time $\\langle \\tau_{\\mathrm{off}} \\rangle$ (time spent in $X$ between returns to $B$), and the steady-state dark fraction $f_{\\mathrm{dark}}$. Which of the following statements correctly explains how to distinguish kinetic off-states from photophysical dark states using excitation-power dependence, and proposes a quantitative diagnostic based on rate scaling with $I$? Select all that apply.\n\nA. Under Hypothesis P with single-photon entry to $X$ and intensity-independent recovery, $\\langle \\tau_{\\mathrm{on}} \\rangle$ scales as $I^{-1}$ while $\\langle \\tau_{\\mathrm{off}} \\rangle$ is independent of $I$; under Hypothesis K, both $\\langle \\tau_{\\mathrm{on}} \\rangle$ and $\\langle \\tau_{\\mathrm{off}} \\rangle$ are independent of $I$. A quantitative diagnostic is to estimate the log-log slopes $s_{\\mathrm{on}} = \\mathrm{d}\\ln \\langle \\tau_{\\mathrm{on}} \\rangle / \\mathrm{d}\\ln I$ and $s_{\\mathrm{off}} = \\mathrm{d}\\ln \\langle \\tau_{\\mathrm{off}} \\rangle / \\mathrm{d}\\ln I$: diagnose Hypothesis P if $s_{\\mathrm{on}} \\approx -1$ and $s_{\\mathrm{off}} \\approx 0$, and Hypothesis K if $s_{\\mathrm{on}} \\approx 0$ and $s_{\\mathrm{off}} \\approx 0$.\n\nB. Under Hypothesis P, $\\langle \\tau_{\\mathrm{off}} \\rangle$ scales as $I^{-1}$ while $\\langle \\tau_{\\mathrm{on}} \\rangle$ is independent of $I$; under Hypothesis K, both are independent of $I$. A quantitative diagnostic is to fit a line to $\\ln \\langle \\tau_{\\mathrm{off}} \\rangle$ versus $\\ln I$ and expect slope $-1$ for Hypothesis P.\n\nC. The Power Spectral Density (PSD) corner frequency of the fluorescence intensity should scale as $I^{2}$ under Hypothesis P and be independent of $I$ under Hypothesis K. A quantitative diagnostic is to compute the PSD of the on-off trajectory and fit the knee frequency as a function of $I$; a quadratic dependence indicates Hypothesis P.\n\nD. A quantitative diagnostic is to estimate the apparent on-rate $k_{\\mathrm{on,app}} = 1/\\langle \\tau_{\\mathrm{off}} \\rangle$ and plot it versus $I$: for Hypothesis P, $k_{\\mathrm{on,app}}$ increases linearly with $I$ because more photons promote exit from $X$, whereas for Hypothesis K it is independent of $I$.\n\nE. Under Hypothesis P with single-photon entry to $X$ and intensity-independent recovery, the steady-state dark fraction obeys $f_{\\mathrm{dark}}(I) = \\alpha I / (\\alpha I + k_{\\mathrm{rec}})$ for some constants $\\alpha$ and $k_{\\mathrm{rec}}$, whereas under Hypothesis K, $f_{\\mathrm{dark}}$ is independent of $I$. A quantitative diagnostic is to measure $f_{\\mathrm{dark}}$ at several $I$ and fit to a rectangular hyperbola; a good fit with nonzero $\\alpha$ supports Hypothesis P, while a flat dependence supports Hypothesis K.", "solution": "The problem statement must first be validated for scientific soundness and logical consistency before a solution is attempted.\n\n**Problem Validation**\n\n**Step 1: Extracted Givens**\n- **System**: A single biomolecule observed via fluorescence, exhibiting a $2$-state trajectory between a bright state ($B$) and a dark state ($X$).\n- **Hypothesis K (Kinetic)**: The transition $B \\rightleftarrows X$ is governed by first-order rate constants $k_{BX}$ and $k_{XB}$ that are independent of excitation intensity $I$.\n- **Hypothesis P (Photophysical)**: The transition $B \\to X$ is driven by single-photon absorption, with a rate proportional to intensity $I$. The recovery transition $X \\to B$ is thermally activated and its rate is independent of $I$.\n- **Conditions**: Photobleaching is negligible. Excitation is far from saturation.\n- **Observables**: Mean on-time $\\langle \\tau_{\\mathrm{on}} \\rangle$, mean off-time $\\langle \\tau_{\\mathrm{off}} \\rangle$, and steady-state dark fraction $f_{\\mathrm{dark}}$.\n- **Fundamental Bases**:\n    (i) For a continuous-time Markov two-state process, the mean dwell time in a state is the inverse of the total exit rate from that state.\n    (ii) The rate of a single-photon induced transition is proportional to the excitation intensity $I$.\n    (iii) The steady-state fraction of time in a state is the ratio of the incoming rate to the sum of the incoming and outgoing rates for that state.\n\n**Step 2: Validation of Givens**\n- The problem is **scientifically grounded**. The two hypotheses, kinetic ($K$) and photophysical ($P$), represent standard, physically realistic models used to interpret fluorescence blinking in single-molecule studies.\n- The problem is **well-posed**. The descriptions of the two models are clear, mutually exclusive, and sufficient to derive unique predictions for the experimental observables.\n- The problem is **objective**. It is framed in precise scientific language without subjective or ambiguous terminology.\n- The provided \"fundamental bases\" are correct statements of principles from the theory of stochastic processes and chemical kinetics. The assumption of non-saturating excitation simplifies the analysis by ensuring the rate of photon absorption is linear with intensity, which is consistent with basis (ii).\n\n**Step 3: Verdict**\nThe problem statement is valid. It is a standard, well-formulated problem in single-molecule biophysics. A solution can be derived from the provided principles.\n\n**Derivation of Theoretical Predictions**\n\nLet us analyze the behavior of the observables under each hypothesis using the given fundamental bases.\n\n**Analysis of Hypothesis K (Kinetic Model)**\nThe reaction scheme is $B \\underset{k_{XB}}{\\stackrel{k_{BX}}{\\rightleftarrows}} X$.\nThe rate constants $k_{BX}$ and $k_{XB}$ are independent of intensity $I$.\n\n1.  **Mean On-Time ($\\langle \\tau_{\\mathrm{on}} \\rangle$)**: This is the mean dwell time in the bright state $B$. The only exit pathway from $B$ is the transition to $X$ with rate $k_{BX}$. According to basis (i):\n    $$ \\langle \\tau_{\\mathrm{on}} \\rangle = \\frac{1}{k_{BX}} $$\n    Since $k_{BX}$ is independent of $I$, $\\langle \\tau_{\\mathrm{on}} \\rangle$ is independent of $I$.\n\n2.  **Mean Off-Time ($\\langle \\tau_{\\mathrm{off}} \\rangle$)**: This is the mean dwell time in the dark state $X$. The only exit pathway from $X$ is the transition to $B$ with rate $k_{XB}$. According to basis (i):\n    $$ \\langle \\tau_{\\mathrm{off}} \\rangle = \\frac{1}{k_{XB}} $$\n    Since $k_{XB}$ is independent of $I$, $\\langle \\tau_{\\mathrm{off}} \\rangle$ is independent of $I$.\n\n3.  **Steady-State Dark Fraction ($f_{\\mathrm{dark}}$)**: This is the fraction of time spent in state $X$. According to basis (iii), this is the rate into $X$ ($k_{BX}$) divided by the sum of rates into and out of $X$ ($k_{BX} + k_{XB}$):\n    $$ f_{\\mathrm{dark}} = \\frac{k_{BX}}{k_{BX} + k_{XB}} $$\n    Since both rate constants are independent of $I$, $f_{\\mathrm{dark}}$ is independent of $I$.\n\n**Analysis of Hypothesis P (Photophysical Model)**\nThe reaction scheme is $B \\underset{k_{\\mathrm{rec}}}{\\stackrel{k_{\\mathrm{photo}}(I)}{\\rightleftarrows}} X$.\n\n- The rate of entry into the dark state, $B \\to X$, is proportional to intensity $I$ (basis (ii)). We define this rate as $k_{\\mathrm{photo}}(I) = \\alpha I$, where $\\alpha$ is a proportionality constant.\n- The rate of exit from the dark state, $X \\to B$, is independent of intensity. We define this rate as $k_{\\mathrm{rec}}$.\n\n1.  **Mean On-Time ($\\langle \\tau_{\\mathrm{on}} \\rangle$)**: The exit rate from state $B$ is $k_{\\mathrm{photo}}(I)$. According to basis (i):\n    $$ \\langle \\tau_{\\mathrm{on}} \\rangle = \\frac{1}{k_{\\mathrm{photo}}(I)} = \\frac{1}{\\alpha I} $$\n    Thus, $\\langle \\tau_{\\mathrm{on}} \\rangle$ is inversely proportional to $I$, i.e., $\\langle \\tau_{\\mathrm{on}} \\rangle \\propto I^{-1}$.\n\n2.  **Mean Off-Time ($\\langle \\tau_{\\mathrm{off}} \\rangle$)**: The exit rate from state $X$ is $k_{\\mathrm{rec}}$. According to basis (i):\n    $$ \\langle \\tau_{\\mathrm{off}} \\rangle = \\frac{1}{k_{\\mathrm{rec}}} $$\n    Since $k_{\\mathrm{rec}}$ is independent of $I$, $\\langle \\tau_{\\mathrm{off}} \\rangle$ is independent of $I$.\n\n3.  **Steady-State Dark Fraction ($f_{\\mathrm{dark}}$)**: The rate into state $X$ is $k_{\\mathrm{photo}}(I) = \\alpha I$, and the rate out is $k_{\\mathrm{rec}}$. According to basis (iii):\n    $$ f_{\\mathrm{dark}}(I) = \\frac{k_{\\mathrm{photo}}(I)}{k_{\\mathrm{photo}}(I) + k_{\\mathrm{rec}}} = \\frac{\\alpha I}{\\alpha I + k_{\\mathrm{rec}}} $$\n    This fraction is a saturating function of the intensity $I$.\n\n**Evaluation of Options**\n\n**A.** The option states that for Hypothesis P, $\\langle \\tau_{\\mathrm{on}} \\rangle \\propto I^{-1}$ and $\\langle \\tau_{\\mathrm{off}} \\rangle$ is constant, while for Hypothesis K, both are constant. This is in exact agreement with our derivation. It further proposes a diagnostic using log-log slopes: $s_{\\mathrm{on}} = \\mathrm{d}\\ln \\langle \\tau_{\\mathrm{on}} \\rangle / \\mathrm{d}\\ln I$ and $s_{\\mathrm{off}} = \\mathrm{d}\\ln \\langle \\tau_{\\mathrm{off}} \\rangle / \\mathrm{d}\\ln I$.\nFor Hypothesis P: $\\langle \\tau_{\\mathrm{on}} \\rangle = (\\alpha)^{-1} I^{-1} \\implies \\ln \\langle \\tau_{\\mathrm{on}} \\rangle = -\\ln \\alpha - \\ln I$, yielding $s_{\\mathrm{on}} = -1$. $\\langle \\tau_{\\mathrm{off}} \\rangle = (k_{\\mathrm{rec}})^{-1} I^0 \\implies \\ln \\langle \\tau_{\\mathrm{off}} \\rangle = -\\ln k_{\\mathrm{rec}}$, yielding $s_{\\mathrm{off}} = 0$.\nFor Hypothesis K: Both lifetimes are constant, $\\propto I^0$, so $s_{\\mathrm{on}} = 0$ and $s_{\\mathrm{off}} = 0$.\nThe diagnostic correctly distinguishes the two hypotheses.\nVerdict: **Correct**.\n\n**B.** The option states that for Hypothesis P, $\\langle \\tau_{\\mathrm{off}} \\rangle \\propto I^{-1}$ and $\\langle \\tau_{\\mathrm{on}} \\rangle$ is constant. This contradicts our derivation, which shows the opposite dependencies. The option has inverted the roles of on-time and off-time.\nVerdict: **Incorrect**.\n\n**C.** The option discusses the Power Spectral Density (PSD) corner frequency. For a two-state Markov process, the relaxation rate, which corresponds to the PSD corner frequency, is the sum of the forward and reverse rate constants, $\\lambda = k_{forward} + k_{reverse}$.\nFor Hypothesis K: $\\lambda_K = k_{BX} + k_{XB}$, which is independent of $I$.\nFor Hypothesis P: $\\lambda_P = k_{\\mathrm{photo}}(I) + k_{\\mathrm{rec}} = \\alpha I + k_{\\mathrm{rec}}$. This shows a linear dependence on $I$.\nThe option claims a scaling of $I^2$ for Hypothesis P, which is incorrect. The scaling is linear with $I$.\nVerdict: **Incorrect**.\n\n**D.** The option defines the apparent on-rate as $k_{\\mathrm{on,app}} = 1/\\langle \\tau_{\\mathrm{off}} \\rangle$. This rate corresponds to the exit from the dark state $X$.\nFor Hypothesis K: $k_{\\mathrm{on,app}} = 1/\\langle \\tau_{\\mathrm{off}} \\rangle = k_{XB}$, which is independent of $I$.\nFor Hypothesis P: $k_{\\mathrm{on,app}} = 1/\\langle \\tau_{\\mathrm{off}} \\rangle = k_{\\mathrm{rec}}$, which is independent of $I$.\nThe option incorrectly claims that for Hypothesis P, $k_{\\mathrm{on,app}}$ increases linearly with $I$. It also provides a false justification that photons promote exit from $X$, contradicting the problem definition.\nVerdict: **Incorrect**.\n\n**E.** The option describes the behavior of the steady-state dark fraction, $f_{\\mathrm{dark}}$.\nFor Hypothesis P, it gives the form $f_{\\mathrm{dark}}(I) = \\alpha I / (\\alpha I + k_{\\mathrm{rec}})$. This is in exact agreement with our derivation.\nFor Hypothesis K, it states $f_{\\mathrm{dark}}$ is independent of $I$. This also agrees with our derivation.\nThe proposed diagnostic is to fit the measured $f_{\\mathrm{dark}}(I)$ to this functional form (a rectangular hyperbola, or saturating curve) versus a constant. This is a valid and standard method for distinguishing the two models based on the $f_{\\mathrm{dark}}$ observable.\nVerdict: **Correct**.", "answer": "$$\\boxed{AE}$$", "id": "2674086"}, {"introduction": "Single-molecule data are often noisy, with overlapping signal distributions that make it difficult to definitively assign the system's state at any given moment. Hidden Markov Models (HMMs) provide a robust probabilistic framework to overcome this challenge by inferring the most likely sequence of hidden states from the noisy observations. This hands-on coding practice will guide you in building the forward-backward algorithm, the computational engine for HMM inference, from first principles, while also tackling the critical issue of numerical stability that arises when dealing with long data traces. [@problem_id:2674022]", "problem": "Consider a discrete-time Hidden Markov Model (HMM) for a single-molecule observation trace, where a biomolecule switches among hidden conformational states that form a time-homogeneous Markov chain. At each time index $t \\in \\{1,\\dots,T\\}$ there is a hidden state $s_t \\in \\{1,\\dots,K\\}$ with initial distribution $p(s_1=i)=\\pi_i$ and transition probabilities $p(s_{t}=j \\mid s_{t-1}=i)=A_{ij}$ for all $i,j \\in \\{1,\\dots,K\\}$. The observation at time $t$ is a real-valued scalar $y_t \\in \\mathbb{R}$ whose distribution depends only on the current hidden state $s_t$ (conditional independence). Assume that given $s_t=i$, the observation distribution is Gaussian with mean $\\mu_i$ and standard deviation $\\sigma_i$, so that the emission probability density is $b_i(y_t) = \\mathcal{N}(y_t \\mid \\mu_i,\\sigma_i^2)$. All model parameters $(\\boldsymbol{\\pi}, \\mathbf{A}, \\boldsymbol{\\mu}, \\boldsymbol{\\sigma})$ are known.\n\nYour task is to construct the forward–backward algorithm from first principles to compute the posterior marginal state probabilities $p(s_t=i \\mid y_{1:T})$ for all $t \\in \\{1,\\dots,T\\}$ and all $i \\in \\{1,\\dots,K\\}$, and to implement two numerically stable strategies to prevent underflow: (1) a scaled forward–backward recursion using per-time scaling factors, and (2) a log-domain recursion using the log-sum-exp transformation. The derivation must start from basic probability rules such as the definition of conditional probability, the Markov property, and the law of total probability, and it must not assume any pre-written formulas for the forward or backward recursions.\n\nProgram requirements:\n- Implement two independent computations of the posterior matrix $\\boldsymbol{\\gamma}$ where $\\gamma_{i,t} = p(s_t=i \\mid y_{1:T})$:\n  1. A scaled forward–backward method that maintains forward variables and backward variables scaled by time-dependent positive factors to avoid numerical underflow, and that recovers the sequence log-likelihood $\\log p(y_{1:T})$ from the scaling factors.\n  2. A log-domain forward–backward method that uses the log-sum-exp identity to compute the same posterior matrix and the same sequence log-likelihood.\n- For each test case below, compute the maximum absolute difference between the two posterior matrices elementwise and verify that it is less than a specified tolerance $\\varepsilon = 10^{-8}$. Also verify that for every time index $t$, the posterior entries sum to one within a tolerance $\\delta = 10^{-12}$, i.e., $\\left|\\sum_{i=1}^K \\gamma_{i,t} - 1\\right| \\le \\delta$. Finally, verify that the two log-likelihood values agree within tolerance $\\eta = 10^{-8}$ in absolute difference.\n- For each test case, return a boolean result that is true if and only if all three verifications pass.\n\nTest suite:\n- Case 1 (two-state conformational switching with moderately distinct Gaussian emissions):\n  - Number of states $K = 2$.\n  - Initial distribution $\\boldsymbol{\\pi} = [\\,0.5,\\,0.5\\,]$.\n  - Transition matrix $\\mathbf{A} = \\begin{bmatrix} 0.95  0.05 \\\\ 0.04  0.96 \\end{bmatrix}$.\n  - Emission parameters $\\boldsymbol{\\mu} = [\\,0.2,\\,0.8\\,]$, $\\boldsymbol{\\sigma} = [\\,0.05,\\,0.05\\,]$.\n  - Observation sequence of length $T=20$: $[\\,0.18,\\,0.22,\\,0.19,\\,0.81,\\,0.79,\\,0.82,\\,0.21,\\,0.20,\\,0.78,\\,0.83,\\,0.18,\\,0.17,\\,0.82,\\,0.80,\\,0.22,\\,0.19,\\,0.77,\\,0.84,\\,0.23,\\,0.20\\,]$.\n- Case 2 (three-state model with a single observation to test boundary conditions):\n  - Number of states $K = 3$.\n  - Initial distribution $\\boldsymbol{\\pi} = [\\,0.2,\\,0.5,\\,0.3\\,]$.\n  - Transition matrix $\\mathbf{A} = \\begin{bmatrix} 0.90  0.05  0.05 \\\\ 0.10  0.80  0.10 \\\\ 0.05  0.15  0.80 \\end{bmatrix}$.\n  - Emission parameters $\\boldsymbol{\\mu} = [\\,0.1,\\,0.5,\\,0.9\\,]$, $\\boldsymbol{\\sigma} = [\\,0.1,\\,0.05,\\,0.1\\,]$.\n  - Observation sequence of length $T=1$: $[\\,0.52\\,]$.\n- Case 3 (two-state model with long trace and emissions far from state means to stress numerical stability):\n  - Number of states $K = 2$.\n  - Initial distribution $\\boldsymbol{\\pi} = [\\,0.5,\\,0.5\\,]$.\n  - Transition matrix $\\mathbf{A} = \\begin{bmatrix} 0.995  0.005 \\\\ 0.003  0.997 \\end{bmatrix}$.\n  - Emission parameters $\\boldsymbol{\\mu} = [\\,0.2,\\,0.8\\,]$, $\\boldsymbol{\\sigma} = [\\,0.1,\\,0.1\\,]$.\n  - Observation sequence of length $T=120$: the first $60$ entries equal to $0.45$ followed by the next $60$ entries equal to $0.55$, i.e., $[\\,\\underbrace{0.45,\\,\\dots,\\,0.45}_{60\\ \\text{times}},\\,\\underbrace{0.55,\\,\\dots,\\,0.55}_{60\\ \\text{times}}\\,]$.\n\nNumerical tolerances (dimensionless):\n- Posterior agreement tolerance $\\varepsilon = 10^{-8}$.\n- Per-time posterior normalization tolerance $\\delta = 10^{-12}$.\n- Log-likelihood agreement tolerance $\\eta = 10^{-8}$.\n\nFinal output format:\n- Your program should produce a single line of output containing a list of booleans for the three test cases in the order given above, for example $[\\,\\mathrm{True},\\mathrm{False},\\mathrm{True}\\,]$. The list must be printed exactly as a comma-separated list enclosed in square brackets, with each element rendered as the Python boolean literals.", "solution": "The problem posed is a standard and well-defined task in computational statistics, specifically the inference of hidden states in a Hidden Markov Model (HMM). The parameters of the model are fully specified, and the objective is to compute the posterior marginal probabilities of the hidden states given a sequence of observations. This problem is valid, scientifically grounded, and admits a unique solution via the forward-backward algorithm. We will now derive this algorithm from first principles, and then develop two numerically stable implementations as required.\n\nLet the set of hidden states be $\\{1, \\dots, K\\}$ and the sequence of observations be $y_{1:T} = (y_1, \\dots, y_T)$. The model is defined by the initial state probabilities $\\boldsymbol{\\pi}$, where $\\pi_i = p(s_1=i)$; the transition probability matrix $\\mathbf{A}$, where $A_{ij} = p(s_{t}=j \\mid s_{t-1}=i)$; and the emission probability densities $b_i(y_t) = p(y_t \\mid s_t=i)$, which are given as Gaussian distributions $\\mathcal{N}(y_t \\mid \\mu_i, \\sigma_i^2)$.\n\nOur objective is to compute the posterior marginal probability $\\gamma_t(i) = p(s_t=i \\mid y_{1:T})$ for each time step $t \\in \\{1, \\dots, T\\}$ and each state $i \\in \\{1, \\dots, K\\}$.\n\nBy the definition of conditional probability, we have:\n$$\n\\gamma_t(i) = p(s_t=i \\mid y_{1:T}) = \\frac{p(s_t=i, y_{1:T})}{p(y_{1:T})}\n$$\nThe numerator is the joint probability of being in state $i$ at time $t$ and observing the entire sequence $y_{1:T}$. We can split the observation sequence into past ($y_{1:t}$) and future ($y_{t+1:T}$) parts relative to time $t$. Using the chain rule of probability:\n$$\np(s_t=i, y_{1:T}) = p(s_t=i, y_{1:t}, y_{t+1:T}) = p(y_{t+1:T} \\mid s_t=i, y_{1:t}) p(s_t=i, y_{1:t})\n$$\nDue to the conditional independence properties of an HMM, the future observations $y_{t+1:T}$ are independent of past observations $y_{1:t}$ given the current state $s_t=i$. Therefore, $p(y_{t+1:T} \\mid s_t=i, y_{1:t}) = p(y_{t+1:T} \\mid s_t=i)$.\nThis allows us to write:\n$$\np(s_t=i, y_{1:T}) = p(y_{t+1:T} \\mid s_t=i) p(s_t=i, y_{1:t})\n$$\nThis decomposition leads to the definition of the forward and backward variables.\nThe forward variable, $\\alpha_t(i)$, is the joint probability of the partial observation sequence $y_{1:t}$ and the state $s_t=i$:\n$$\n\\alpha_t(i) \\triangleq p(s_t=i, y_{1:t})\n$$\nThe backward variable, $\\beta_t(i)$, is the conditional probability of the future observation sequence $y_{t+1:T}$ given the state $s_t=i$:\n$$\n\\beta_t(i) \\triangleq p(y_{t+1:T} \\mid s_t=i)\n$$\nSubstituting these into the expression for the posterior, we get:\n$$\n\\gamma_t(i) = \\frac{\\alpha_t(i) \\beta_t(i)}{p(y_{1:T})}\n$$\nThe denominator, the marginal probability of the entire observation sequence (also known as the evidence or likelihood), can be obtained by marginalizing the numerator over all states $i$:\n$$\np(y_{1:T}) = \\sum_{j=1}^K p(s_t=j, y_{1:T}) = \\sum_{j=1}^K \\alpha_t(j) \\beta_t(j)\n$$\nThis relationship holds for any time step $t$. A particularly convenient choice is $t=T$, where $\\beta_T(j)$ is defined as $1$, leading to $p(y_{1:T}) = \\sum_{j=1}^K \\alpha_T(j)$.\n\nWe now derive the recursive formulas for $\\alpha_t(i)$ and $\\beta_t(i)$.\n\n**Forward Recursion**\nFor $t=1$, the forward variable is:\n$$\n\\alpha_1(i) = p(s_1=i, y_1) = p(y_1 \\mid s_1=i) p(s_1=i) = b_i(y_1) \\pi_i\n$$\nFor $t > 1$, we expand $\\alpha_t(i)$ by marginalizing over the state at time $t-1$:\n$$\n\\alpha_t(i) = p(s_t=i, y_{1:t}) = p(y_t \\mid s_t=i) \\sum_{j=1}^K p(s_t=i, s_{t-1}=j, y_{1:t-1})\n$$\nUsing the chain rule and HMM properties:\n$$\np(s_t=i, s_{t-1}=j, y_{1:t-1}) = p(s_t=i \\mid s_{t-1}=j, y_{1:t-1}) p(s_{t-1}=j, y_{1:t-1})\n$$\nBy the Markov property, $p(s_t=i \\mid s_{t-1}=j, y_{1:t-1}) = p(s_t=i \\mid s_{t-1}=j) = A_{ji}$. The second term is simply $\\alpha_{t-1}(j)$.\nThis yields the forward recursion:\n$$\n\\alpha_t(i) = b_i(y_t) \\sum_{j=1}^K \\alpha_{t-1}(j) A_{ji} \\quad \\text{for } t=2, \\dots, T\n$$\n\n**Backward Recursion**\nFor the base case $t=T$, $\\beta_T(i) = p(y_{T+1:T} \\mid s_T=i)$. Since there are no future observations, this is the probability of a certain event, so we define $\\beta_T(i) = 1$ for all $i$.\nFor $t  T$, we derive the recursion by marginalizing over the state at time $t+1$:\n$$\n\\beta_t(i) = p(y_{t+1:T} \\mid s_t=i) = \\sum_{j=1}^K p(y_{t+1:T}, s_{t+1}=j \\mid s_t=i)\n$$\nUsing the chain rule:\n$$\np(y_{t+1:T}, s_{t+1}=j \\mid s_t=i) = p(y_{t+1:T} \\mid s_{t+1}=j, s_t=i) p(s_{t+1}=j \\mid s_t=i)\n$$\nFrom HMM properties: $p(s_{t+1}=j \\mid s_t=i) = A_{ij}$, and $p(y_{t+1:T} \\mid s_{t+1}=j, s_t=i) = p(y_{t+1:T} \\mid s_{t+1}=j)$.\nWe further expand $p(y_{t+1:T} \\mid s_{t+1}=j) = p(y_{t+1}, y_{t+2:T} \\mid s_{t+1}=j) = p(y_{t+1} \\mid s_{t+1}=j) p(y_{t+2:T} \\mid s_{t+1}=j) = b_j(y_{t+1}) \\beta_{t+1}(j)$.\nThis yields the backward recursion:\n$$\n\\beta_t(i) = \\sum_{j=1}^K A_{ij} b_j(y_{t+1}) \\beta_{t+1}(j) \\quad \\text{for } t=T-1, \\dots, 1\n$$\n\n**Numerical Stabilization Strategy 1: Scaling**\nThe values of $\\alpha_t(i)$ decrease exponentially with $t$ and can cause numerical underflow. To prevent this, we introduce scaled forward variables $\\hat{\\alpha}_t(i) = p(s_t=i \\mid y_{1:t})$. These are normalized at each time step.\nThe scaling factors are $c_t = p(y_t \\mid y_{1:t-1})$. The forward pass becomes:\n1. Initialize ($t=1$): $\\alpha'_1(i) = \\pi_i b_i(y_1)$. The scaling factor is $c_1 = \\sum_j \\alpha'_1(j)$. The scaled variable is $\\hat{\\alpha}_1(i) = \\alpha'_1(i) / c_1$.\n2. Recurse ($t=2, \\dots, T$): Compute an intermediate value $\\alpha'_t(i) = b_i(y_t) \\sum_j \\hat{\\alpha}_{t-1}(j) A_{ji}$. The scaling factor is $c_t = \\sum_j \\alpha'_t(j)$. The scaled variable is $\\hat{\\alpha}_t(i) = \\alpha'_t(i) / c_t$.\n\nThe log-likelihood of the observations is $\\log p(y_{1:T}) = \\sum_{t=1}^T \\log c_t$.\n\nFor the backward pass, we define scaled backward variables $\\hat{\\beta}_t(i)$ using the same scaling factors: $\\hat{\\beta}_t(i) = \\beta_t(i) / \\prod_{k=t+1}^T c_k$.\n1. Initialize ($t=T$): $\\hat{\\beta}_T(i) = \\beta_T(i) = 1$.\n2. Recurse ($t=T-1, \\dots, 1$): The recursion for $\\hat{\\beta}_t(i)$ becomes $\\hat{\\beta}_t(i) = \\frac{1}{c_{t+1}} \\sum_{j=1}^K A_{ij} b_j(y_{t+1}) \\hat{\\beta}_{t+1}(j)$.\n\nThe posterior probability $\\gamma_t(i)$ is then computed using these scaled variables.\n$$\n\\gamma_t(i) = \\frac{\\alpha_t(i)\\beta_t(i)}{\\sum_j \\alpha_t(j)\\beta_t(j)} = \\frac{\\hat{\\alpha}_t(i) \\hat{\\beta}_t(i)}{\\sum_j \\hat{\\alpha}_t(j) \\hat{\\beta}_t(j)}\n$$\nThe product term involving the scaling factors cancels out, and the posterior is obtained by normalizing the elementwise product of the scaled forward and backward variables at each time step.\n\n**Numerical Stabilization Strategy 2: Log-Domain Computation**\nAn alternative to scaling is to perform all calculations in the logarithmic domain. We define $\\ln\\alpha_t(i) = \\log \\alpha_t(i)$ and $\\ln\\beta_t(i) = \\log \\beta_t(i)$. The product operations in the original recursions become sums in the log domain. Summations are handled using the log-sum-exp transformation: $\\log(\\sum_i e^{x_i}) = X + \\log(\\sum_i e^{x_i - X})$ where $X=\\max_i x_i$. This operation is numerically stable.\n\nThe log-forward recursion is:\n1. Initialize ($t=1$): $\\ln\\alpha_1(i) = \\log\\pi_i + \\log b_i(y_1)$.\n2. Recurse ($t=2, \\dots, T$): $\\ln\\alpha_t(i) = \\log b_i(y_t) + \\underset{j}{\\text{log-sum-exp}}(\\ln\\alpha_{t-1}(j) + \\log A_{ji})$.\n\nThe log-backward recursion is:\n1. Initialize ($t=T$): $\\ln\\beta_T(i) = \\log 1 = 0$.\n2. Recurse ($t=T-1, \\dots, 1$): $\\ln\\beta_t(i) = \\underset{j}{\\text{log-sum-exp}}(\\log A_{ij} + \\log b_j(y_{t+1}) + \\ln\\beta_{t+1}(j))$.\n\nThe sequence log-likelihood is $\\log p(y_{1:T}) = \\underset{i}{\\text{log-sum-exp}}(\\ln\\alpha_T(i))$.\nThe log-posterior is computed as:\n$$\n\\log \\gamma_t(i) = \\ln\\alpha_t(i) + \\ln\\beta_t(i) - \\underset{j}{\\text{log-sum-exp}}(\\ln\\alpha_t(j) + \\ln\\beta_t(j))\n$$\nThe final posteriors $\\gamma_t(i)$ are obtained by exponentiating: $\\gamma_t(i) = e^{\\log\\gamma_t(i)}$. The emission log-probability $\\log b_i(y_t)$ for a Gaussian distribution $\\mathcal{N}(y_t \\mid \\mu_i, \\sigma_i^2)$ is computed as $-\\log\\sigma_i - \\frac{1}{2}\\log(2\\pi) - \\frac{(y_t - \\mu_i)^2}{2\\sigma_i^2}$.\n\nBoth strategies will now be implemented and verified for correctness and numerical agreement.", "answer": "```python\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Solves the HMM inference problem for the given test cases using two\n    numerically stable forward-backward algorithm implementations.\n    \"\"\"\n\n    def gaussian_log_pdf(y, mu, sigma):\n        \"\"\"\n        Computes the log of the Gaussian probability density function.\n        More stable than taking log of the pdf.\n        \"\"\"\n        return -np.log(sigma) - 0.5 * np.log(2 * np.pi) - 0.5 * ((y - mu) / sigma) ** 2\n\n    def scaled_forward_backward(pi, A, mu, sigma, y, K, T):\n        \"\"\"\n        Computes posterior state probabilities and log-likelihood using the\n        scaled forward-backward algorithm.\n        \"\"\"\n        # Pre-compute emission probabilities\n        emissions = np.zeros((T, K))\n        for t in range(T):\n            for i in range(K):\n                # We can use log-pdf and exponentiate, it is safer than pdf for tiny values\n                emissions[t, i] = np.exp(gaussian_log_pdf(y[t], mu[i], sigma[i]))\n\n        # Forward pass (scaled)\n        alpha_hat = np.zeros((T, K))\n        c = np.zeros(T)\n\n        alpha_hat_t_unscaled = pi * emissions[0, :]\n        c[0] = np.sum(alpha_hat_t_unscaled)\n        alpha_hat[0, :] = alpha_hat_t_unscaled / c[0]\n\n        for t in range(1, T):\n            alpha_hat_t_unscaled = (alpha_hat[t-1, :] @ A) * emissions[t, :]\n            c[t] = np.sum(alpha_hat_t_unscaled)\n            alpha_hat[t, :] = alpha_hat_t_unscaled / c[t]\n\n        log_likelihood = np.sum(np.log(c))\n\n        # Backward pass (scaled)\n        beta_hat = np.zeros((T, K))\n        beta_hat[T-1, :] = 1.0\n\n        for t in range(T - 2, -1, -1):\n            beta_hat[t, :] = (A @ (emissions[t+1, :] * beta_hat[t+1, :])) / c[t+1]\n\n        # Posteriors\n        gamma_unnorm = alpha_hat * beta_hat\n        gamma = gamma_unnorm / np.sum(gamma_unnorm, axis=1, keepdims=True)\n\n        return gamma.T, log_likelihood  # Return as (K, T)\n\n    def log_domain_forward_backward(pi, A, mu, sigma, y, K, T):\n        \"\"\"\n        Computes posterior state probabilities and log-likelihood using the\n        log-domain forward-backward algorithm.\n        \"\"\"\n        log_pi = np.log(pi)\n        log_A = np.log(A)\n\n        log_emissions = np.zeros((T, K))\n        for t in range(T):\n            for i in range(K):\n                log_emissions[t, i] = gaussian_log_pdf(y[t], mu[i], sigma[i])\n\n        # Log-Forward pass\n        log_alpha = np.zeros((T, K))\n        log_alpha[0, :] = log_pi + log_emissions[0, :]\n\n        for t in range(1, T):\n            for j in range(K):\n                log_alpha[t, j] = log_emissions[t, j] + logsumexp(log_alpha[t - 1, :] + log_A[:, j])\n\n        log_likelihood = logsumexp(log_alpha[T - 1, :])\n\n        # Log-Backward pass\n        log_beta = np.zeros((T, K))\n        # log_beta[T-1, :] is already 0.0\n\n        for t in range(T - 2, -1, -1):\n            for i in range(K):\n                log_beta[t, i] = logsumexp(log_A[i, :] + log_emissions[t + 1, :] + log_beta[t + 1, :])\n\n        # Log-Posteriors\n        log_gamma_unnorm = log_alpha + log_beta\n        log_normalizer = logsumexp(log_gamma_unnorm, axis=1, keepdims=True)\n        log_gamma = log_gamma_unnorm - log_normalizer\n        \n        gamma = np.exp(log_gamma)\n\n        return gamma.T, log_likelihood # Return as (K, T)\n\n    test_cases = [\n        {\n            \"K\": 2, \"T\": 20,\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([[0.95, 0.05], [0.04, 0.96]]),\n            \"mu\": np.array([0.2, 0.8]), \"sigma\": np.array([0.05, 0.05]),\n            \"y\": np.array([0.18, 0.22, 0.19, 0.81, 0.79, 0.82, 0.21, 0.20, 0.78, 0.83, 0.18, 0.17, 0.82, 0.80, 0.22, 0.19, 0.77, 0.84, 0.23, 0.20]),\n        },\n        {\n            \"K\": 3, \"T\": 1,\n            \"pi\": np.array([0.2, 0.5, 0.3]),\n            \"A\": np.array([[0.90, 0.05, 0.05], [0.10, 0.80, 0.10], [0.05, 0.15, 0.80]]),\n            \"mu\": np.array([0.1, 0.5, 0.9]), \"sigma\": np.array([0.1, 0.05, 0.1]),\n            \"y\": np.array([0.52]),\n        },\n        {\n            \"K\": 2, \"T\": 120,\n            \"pi\": np.array([0.5, 0.5]),\n            \"A\": np.array([[0.995, 0.005], [0.003, 0.997]]),\n            \"mu\": np.array([0.2, 0.8]), \"sigma\": np.array([0.1, 0.1]),\n            \"y\": np.concatenate([np.full(60, 0.45), np.full(60, 0.55)]),\n        }\n    ]\n\n    epsilon = 1e-8\n    delta = 1e-12\n    eta = 1e-8\n\n    results = []\n    \n    for case in test_cases:\n        K, T = case[\"K\"], case[\"T\"]\n        pi, A, mu, sigma, y = case[\"pi\"], case[\"A\"], case[\"mu\"], case[\"sigma\"], case[\"y\"]\n\n        # Suppress warnings for log(0) which is handled correctly as -inf\n        with np.errstate(divide='ignore'):\n            gamma_scaled, ll_scaled = scaled_forward_backward(pi, A, mu, sigma, y, K, T)\n            gamma_log, ll_log = log_domain_forward_backward(pi, A, mu, sigma, y, K, T)\n\n        # 1. Posterior agreement check\n        posterior_diff = np.max(np.abs(gamma_scaled - gamma_log))\n        check1 = posterior_diff  epsilon\n       \n        # 2. Per-time posterior normalization check\n        # We only need to check one result as check1 ensures they are close\n        normalization_diffs = np.abs(np.sum(gamma_log, axis=0) - 1.0)\n        check2 = np.all(normalization_diffs = delta)\n\n        # 3. Log-likelihood agreement check\n        ll_diff = np.abs(ll_scaled - ll_log)\n        check3 = ll_diff  eta\n\n        results.append(check1 and check2 and check3)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2674022"}]}