{"hands_on_practices": [{"introduction": "Gradient-based optimization algorithms are the workhorses of computational chemistry, but they depend on one crucial input: the gradient of the potential energy surface. This first exercise takes you under the hood to compute this gradient numerically using the finite difference method. By applying Richardson extrapolation to a series of energy calculations, you will not only obtain a highly accurate gradient but also learn a powerful technique for error estimation and control, a vital skill for any computational scientist. [@problem_id:2894227]", "problem": "In the Born–Oppenheimer (BO) approximation, the adiabatic electronic energy $E(q)$ of a molecule is an analytic function of a one-dimensional internal coordinate $q$ near a reference geometry $q=0$. Consider displacements $q=\\pm h$, $q=\\pm h/2$, and $q=\\pm h/4$ along a single mass-unweighted normal coordinate (in bohr). You performed high-accuracy electronic energy calculations at these displaced geometries and obtained the following total energies (in Hartree):\n- $E(+h) = -99.99982079201315556$, $E(-h) = -99.99985919198648889$ with $h = 0.02$ bohr,\n- $E\\!\\left(+\\frac{h}{2}\\right) = -99.99995009999950041$, $E\\!\\left(-\\frac{h}{2}\\right) = -99.99996989999949958$,\n- $E\\!\\left(+\\frac{h}{4}\\right) = -99.99998501249996876$, $E\\!\\left(-\\frac{h}{4}\\right) = -99.99999498749996874$.\n\nStarting only from the Taylor expansion of $E(q)$ about $q=0$ and the definition of a derivative, do the following:\n- Derive the central finite-difference estimator for the gradient $G(h)$ at $q=0$ using step size $h$, and its leading-order truncation error scaling in $h$.\n- Compute $G(h)$, $G(h/2)$, and $G(h/4)$ from the given energies.\n- Apply Richardson extrapolation to form two improved gradient estimates,\n  $$G_{1}=\\frac{4\\,G(h/2)-G(h)}{3}, \\qquad G_{2}=\\frac{4\\,G(h/4)-G(h/2)}{3},$$\n  and, assuming the error series of $G(h)$ is dominated by even powers of $h$, estimate the remaining truncation error in $G_{2}$ using $|G_{2}-G_{1}|/15$.\n- Report only the Richardson-extrapolated gradient $G_{2}$, rounded to ten significant figures. Express the gradient in Hartree per bohr.", "solution": "The problem presented is a standard exercise in numerical analysis as applied to quantum chemistry, specifically the calculation of molecular gradients for geometry optimization. The problem is scientifically grounded, well-posed, and contains all necessary information for its resolution. I will proceed with the solution.\n\nThe central task is to determine the gradient of the electronic energy, $G(0) = E'(0)$, at the reference geometry $q=0$. The method will be based on a finite-difference approximation derived from the Taylor series expansion of the energy function $E(q)$.\n\nFirst, we establish the central finite-difference formula for the first derivative. The function $E(q)$ is stated to be analytic near $q=0$. We can therefore write its Taylor series expansion around this point:\n$$ E(q) = E(0) + E'(0)q + \\frac{1}{2!}E''(0)q^2 + \\frac{1}{3!}E'''(0)q^3 + \\frac{1}{4!}E''''(0)q^4 + \\frac{1}{5!}E^{(5)}(0)q^5 + O(q^6) $$\nLet us evaluate this expansion at the points $q=+h$ and $q=-h$:\n$$ E(+h) = E(0) + E'(0)h + \\frac{1}{2}E''(0)h^2 + \\frac{1}{6}E'''(0)h^3 + \\frac{1}{24}E''''(0)h^4 + \\frac{1}{120}E^{(5)}(0)h^5 + O(h^6) $$\n$$ E(-h) = E(0) - E'(0)h + \\frac{1}{2}E''(0)h^2 - \\frac{1}{6}E'''(0)h^3 + \\frac{1}{24}E''''(0)h^4 - \\frac{1}{120}E^{(5)}(0)h^5 + O(h^6) $$\nSubtracting the second expression from the first yields:\n$$ E(+h) - E(-h) = 2E'(0)h + \\frac{2}{6}E'''(0)h^3 + \\frac{2}{120}E^{(5)}(0)h^5 + O(h^7) $$\nSolving for the gradient $E'(0)$, we find:\n$$ E'(0) = \\frac{E(+h) - E(-h)}{2h} - \\frac{1}{6}E'''(0)h^2 - \\frac{1}{60}E^{(5)}(0)h^4 - O(h^6) $$\nThe central finite-difference estimator for the gradient, which we denote $G(h)$, is the first term on the right-hand side:\n$$ G(h) = \\frac{E(+h) - E(-h)}{2h} $$\nThe true gradient $G_{true} = E'(0)$ can be expressed in terms of the estimator $G(h)$ and its truncation error:\n$$ G_{true} = G(h) - \\frac{1}{6}E'''(0)h^2 - \\frac{1}{60}E^{(5)}(0)h^4 - \\dots $$\nThis shows that the truncation error of the estimator $G(h)$ can be written as a series in even powers of $h$:\n$$ G(h) = G_{true} + c_2 h^2 + c_4 h^4 + c_6 h^6 + \\dots $$\nwhere $c_2 = \\frac{1}{6}E'''(0)$, $c_4 = \\frac{1}{60}E^{(5)}(0)$, and so on. The leading-order truncation error is $c_2 h^2$, which scales as $O(h^2)$.\n\nNext, we compute the numerical values of the gradient estimators $G(h)$, $G(h/2)$, and $G(h/4)$ using the provided energy values and the step size $h = 0.02$ bohr. The units of the gradient will be Hartree/bohr.\n\nFor $s = h = 0.02$:\n$$ G(h) = \\frac{E(+h) - E(-h)}{2h} = \\frac{-99.99982079201315556 - (-99.99985919198648889)}{2 \\times 0.02} $$\n$$ G(h) = \\frac{0.00003839997333333333}{0.04} = 0.00095999933333333325 $$\n\nFor $s = h/2 = 0.01$:\n$$ G(h/2) = \\frac{E(+h/2) - E(-h/2)}{2(h/2)} = \\frac{-99.99995009999950041 - (-99.99996989999949958)}{0.02} $$\n$$ G(h/2) = \\frac{0.00001979999999917}{0.02} = 0.0009899999999585 $$\n\nFor $s = h/4 = 0.005$:\n$$ G(h/4) = \\frac{E(+h/4) - E(-h/4)}{2(h/4)} = \\frac{-99.99998501249996876 - (-99.99999498749996874)}{0.01} $$\n$$ G(h/4) = \\frac{0.00000997499999998}{0.01} = 0.000997499999998 $$\n\nNow, we apply Richardson extrapolation to improve these estimates. The error series is $G(s) = G_{true} + c_2 s^2 + c_4 s^4 + O(s^6)$. Let us consider two step sizes, $h$ and $h/2$:\n$$ G(h) = G_{true} + c_2 h^2 + c_4 h^4 + O(h^6) $$\n$$ G(h/2) = G_{true} + c_2 (h/2)^2 + c_4 (h/2)^4 + O(h^6) = G_{true} + \\frac{1}{4}c_2 h^2 + \\frac{1}{16}c_4 h^4 + O(h^6) $$\nTo eliminate the $O(h^2)$ term, we construct a linear combination. Multiplying the second equation by $4$ and subtracting the first gives:\n$$ 4G(h/2) - G(h) = 3G_{true} - \\frac{3}{4}c_4 h^4 + O(h^6) $$\nThe first extrapolated estimate, $G_1$, is then:\n$$ G_1 = \\frac{4G(h/2) - G(h)}{3} = G_{true} - \\frac{1}{4}c_4 h^4 + O(h^6) $$\nThis estimate has a leading error of order $O(h^4)$. Using our calculated values:\n$$ G_1 = \\frac{4(0.0009899999999585) - 0.00095999933333325}{3} $$\n$$ G_1 = \\frac{0.003959999999834 - 0.00095999933333325}{3} = \\frac{0.00300000066650075}{3} \\approx 0.0010000002221669 $$\n\nThe second extrapolated estimate, $G_2$, is formed in the same manner using step sizes $h/2$ and $h/4$:\n$$ G_2 = \\frac{4G(h/4) - G(h/2)}{3} $$\nThis cancels the $O((h/2)^2)$ error term, resulting in an estimate with a leading error of order $O((h/2)^4) = O(h^4/16)$.\n$$ G_2 = \\frac{4(0.000997499999998) - 0.0009899999999585}{3} $$\n$$ G_2 = \\frac{0.003989999999992 - 0.0009899999999585}{3} = \\frac{0.0030000000000335}{3} \\approx 0.0010000000000112 $$\n\nThe problem asks to estimate the remaining truncation error in $G_2$. Let $A(h)$ be the extrapolated value, so $G_1 = A(h)$ and $G_2 = A(h/2)$. We have shown that $A(s) = G_{true} + K_4 s^4 + O(s^6)$ for some constant $K_4 = -c_4/4$.\n$$ G_1 = G_{true} + K_4 h^4 + O(h^6) $$\n$$ G_2 = G_{true} + K_4 (h/2)^4 + O(h^6) = G_{true} + \\frac{1}{16}K_4 h^4 + O(h^6) $$\nSubtracting these two equations, we get $G_1 - G_2 \\approx \\frac{15}{16}K_4 h^4$.\nThe error in $G_2$ is $Err(G_2) = G_2 - G_{true} \\approx \\frac{1}{16}K_4 h^4$.\nFrom these, we can see that $Err(G_2) \\approx \\frac{1}{15}(G_1 - G_2)$. The magnitude of the error is therefore estimated as $|G_2 - G_1|/15$, confirming the formula provided in the problem statement. This provides a method to assess the accuracy of the extrapolation.\n\nThe final task is to report the Richardson-extrapolated gradient $G_2$, rounded to ten significant figures.\nThe calculated value is $G_2 \\approx 0.0010000000000112$. In scientific notation, this is $1.0000000000112 \\times 10^{-3}$.\nThe first ten significant figures are $1$, followed by nine $0$s. The eleventh significant figure is $0$, so when rounding, the tenth significant digit (a $0$) remains unchanged.\nThe final result is $1.000000000 \\times 10^{-3}$ Hartree/bohr.", "answer": "$$\n\\boxed{1.000000000 \\times 10^{-3}}\n$$", "id": "2894227"}, {"introduction": "Knowing the direction of steepest descent is only the first part of the puzzle; an efficient optimizer must also decide how far to step. This practice delves into the engine of modern geometry optimization by focusing on the Limited-memory BFGS (L-BFGS) algorithm. You will manually execute the famous two-loop recursion to see how information from past steps is used to approximate the inverse Hessian and generate a sophisticated new search direction, moving far beyond a simple gradient descent. [@problem_id:2894174]", "problem": "You are minimizing the Born–Oppenheimer potential energy surface (PES) $E(\\mathbf{R})$ of a small molecule in mass-weighted Cartesian coordinates using a quasi-Newton geometry optimization. At the current iterate $\\mathbf{R}_{k+1}$, you have the gradient $\\mathbf{g}_{k+1} = \\nabla E(\\mathbf{R}_{k+1})$. The Limited-memory Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) method forms a step $\\mathbf{p}_{k+1} = - H_{k+1} \\mathbf{g}_{k+1}$ by applying an implicit inverse-Hessian approximation $H_{k+1}$, constructed from the past displacement and gradient-difference pairs that satisfy the secant condition. Assume a $2$-dimensional subspace spanned by two internal coordinates (in atomic units), and that the last $3$ pairs are, from oldest to most recent,\n$\\mathbf{s}_{0} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}\\,\\text{bohr}$, $\\mathbf{y}_{0} = \\begin{pmatrix}2 \\\\ 0\\end{pmatrix}\\,\\text{Ha}\\,\\text{bohr}^{-1}$,\n$\\mathbf{s}_{1} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}\\,\\text{bohr}$, $\\mathbf{y}_{1} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}\\,\\text{Ha}\\,\\text{bohr}^{-1}$,\n$\\mathbf{s}_{2} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}\\,\\text{bohr}$, $\\mathbf{y}_{2} = \\begin{pmatrix}2 \\\\ 1\\end{pmatrix}\\,\\text{Ha}\\,\\text{bohr}^{-1}$.\nAt $\\mathbf{R}_{k+1}$ the gradient is\n$\\mathbf{g}_{k+1} = \\begin{pmatrix}3 \\\\ 2\\end{pmatrix}\\,\\text{Ha}\\,\\text{bohr}^{-1}$.\nUse the standard two-loop recursion for the L-BFGS inverse-Hessian product with memory $m=3$, initialized with the scalar-multiple identity $H_{0} = \\gamma I$ where $\\gamma = \\dfrac{\\mathbf{s}_{2}^{\\top} \\mathbf{y}_{2}}{\\mathbf{y}_{2}^{\\top} \\mathbf{y}_{2}}$, to compute the step $\\mathbf{p}_{k+1} = -H_{k+1}\\mathbf{g}_{k+1}$. Then, report the Euclidean norm $\\|\\mathbf{p}_{k+1}\\|_{2}$.\nRound your answer to four significant figures and express the final result in bohr.\nYour final answer must be a single real-valued number.", "solution": "The problem requires the computation of a search direction, or step, $\\mathbf{p}_{k+1}$ for a geometry optimization using the Limited-memory Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) algorithm. The step is given by $\\mathbf{p}_{k+1} = -H_{k+1}\\mathbf{g}_{k+1}$, where $H_{k+1}$ is the approximate inverse Hessian and $\\mathbf{g}_{k+1}$ is the gradient of the potential energy at the current geometry $\\mathbf{R}_{k+1}$. The calculation is to be performed using the standard L-BFGS two-loop recursion.\n\nFirst, let us verify the validity of the problem statement. The problem provides all necessary information: the gradient vector $\\mathbf{g}_{k+1}$, the memory size $m=3$, the history of the last $m$ displacement vectors $\\mathbf{s}_i$ and gradient difference vectors $\\mathbf{y}_i$, and the specific formula for the initial inverse Hessian approximation $H_0$. The L-BFGS method requires that the curvature condition $\\mathbf{s}_i^\\top \\mathbf{y}_i  0$ is satisfied for all pairs in memory to ensure that the Hessian approximation remains positive definite. Let us check this condition for the given data.\nFor $i=0$: $\\mathbf{s}_{0}^{\\top} \\mathbf{y}_{0} = \\begin{pmatrix}1  0\\end{pmatrix} \\begin{pmatrix}2 \\\\ 0\\end{pmatrix} = 2  0$.\nFor $i=1$: $\\mathbf{s}_{1}^{\\top} \\mathbf{y}_{1} = \\begin{pmatrix}0  1\\end{pmatrix} \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} = 1  0$.\nFor $i=2$: $\\mathbf{s}_{2}^{\\top} \\mathbf{y}_{2} = \\begin{pmatrix}1  1\\end{pmatrix} \\begin{pmatrix}2 \\\\ 1\\end{pmatrix} = (1)(2) + (1)(1) = 3  0$.\nAll pairs satisfy the curvature condition. The problem is well-posed and scientifically sound. We proceed with the solution.\n\nThe L-BFGS two-loop recursion computes the product $\\mathbf{r} = H_{k+1}\\mathbf{g}_{k+1}$ without forming the matrix $H_{k+1}$ explicitly. The algorithm is as follows, adapted to the problem's indexing ($i=0, 1, 2$ from oldest to most recent):\n\nLet $\\mathbf{g} = \\mathbf{g}_{k+1} = \\begin{pmatrix}3 \\\\ 2\\end{pmatrix}$.\nThe historical pairs are:\n$\\mathbf{s}_{0} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$, $\\mathbf{y}_{0} = \\begin{pmatrix}2 \\\\ 0\\end{pmatrix}$\n$\\mathbf{s}_{1} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$, $\\mathbf{y}_{1} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$\n$\\mathbf{s}_{2} = \\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$, $\\mathbf{y}_{2} = \\begin{pmatrix}2 \\\\ 1\\end{pmatrix}$\n\nWe first compute the scalars $\\rho_i = 1 / (\\mathbf{y}_i^\\top \\mathbf{s}_i)$:\n$\\rho_0 = (\\mathbf{y}_0^\\top \\mathbf{s}_0)^{-1} = (2)^{-1} = \\frac{1}{2}$.\n$\\rho_1 = (\\mathbf{y}_1^\\top \\mathbf{s}_1)^{-1} = (1)^{-1} = 1$.\n$\\rho_2 = (\\mathbf{y}_2^\\top \\mathbf{s}_2)^{-1} = (3)^{-1} = \\frac{1}{3}$.\n\nThe two-loop recursion proceeds as follows:\nInitialize $\\mathbf{q} = \\mathbf{g} = \\begin{pmatrix}3 \\\\ 2\\end{pmatrix}$.\n\n**First loop (from $i=2$ down to $0$):**\nFor $i=2$:\n$\\alpha_2 = \\rho_2 \\mathbf{s}_2^\\top \\mathbf{q} = \\frac{1}{3} \\begin{pmatrix}1  1\\end{pmatrix} \\begin{pmatrix}3 \\\\ 2\\end{pmatrix} = \\frac{1}{3}(3+2) = \\frac{5}{3}$.\n$\\mathbf{q} \\leftarrow \\mathbf{q} - \\alpha_2 \\mathbf{y}_2 = \\begin{pmatrix}3 \\\\ 2\\end{pmatrix} - \\frac{5}{3} \\begin{pmatrix}2 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}3 - \\frac{10}{3} \\\\ 2 - \\frac{5}{3}\\end{pmatrix} = \\begin{pmatrix}-\\frac{1}{3} \\\\ \\frac{1}{3}\\end{pmatrix}$.\n\nFor $i=1$:\n$\\alpha_1 = \\rho_1 \\mathbf{s}_1^\\top \\mathbf{q} = 1 \\begin{pmatrix}0  1\\end{pmatrix} \\begin{pmatrix}-\\frac{1}{3} \\\\ \\frac{1}{3}\\end{pmatrix} = \\frac{1}{3}$.\n$\\mathbf{q} \\leftarrow \\mathbf{q} - \\alpha_1 \\mathbf{y}_1 = \\begin{pmatrix}-\\frac{1}{3} \\\\ \\frac{1}{3}\\end{pmatrix} - \\frac{1}{3} \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}-\\frac{1}{3} \\\\ 0\\end{pmatrix}$.\n\nFor $i=0$:\n$\\alpha_0 = \\rho_0 \\mathbf{s}_0^\\top \\mathbf{q} = \\frac{1}{2} \\begin{pmatrix}1  0\\end{pmatrix} \\begin{pmatrix}-\\frac{1}{3} \\\\ 0\\end{pmatrix} = -\\frac{1}{6}$.\n$\\mathbf{q} \\leftarrow \\mathbf{q} - \\alpha_0 \\mathbf{y}_0 = \\begin{pmatrix}-\\frac{1}{3} \\\\ 0\\end{pmatrix} - (-\\frac{1}{6}) \\begin{pmatrix}2 \\\\ 0\\end{pmatrix} = \\begin{pmatrix}-\\frac{1}{3} + \\frac{2}{6} \\\\ 0\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$.\n\nAfter the first loop, the vector $\\mathbf{q}$ is $\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$. The computed coefficients are $\\alpha_0 = -1/6$, $\\alpha_1 = 1/3$, $\\alpha_2 = 5/3$.\n\n**Scaling and initial step:**\nThe initial inverse Hessian is $H_0 = \\gamma I$, where $\\gamma = \\frac{\\mathbf{s}_{2}^{\\top} \\mathbf{y}_{2}}{\\mathbf{y}_{2}^{\\top} \\mathbf{y}_{2}}$.\n$\\mathbf{s}_{2}^{\\top} \\mathbf{y}_{2} = 3$.\n$\\mathbf{y}_{2}^{\\top} \\mathbf{y}_{2} = \\begin{pmatrix}2  1\\end{pmatrix} \\begin{pmatrix}2 \\\\ 1\\end{pmatrix} = 2^2 + 1^2 = 5$.\nSo, $\\gamma = \\frac{3}{5}$.\nThe initial step vector $\\mathbf{r}$ is calculated as $\\mathbf{r} = H_0 \\mathbf{q} = \\frac{3}{5} I \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$.\n\n**Second loop (from $i=0$ up to $2$):**\nInitialize $\\mathbf{r} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$.\n\nFor $i=0$:\n$\\beta_0 = \\rho_0 \\mathbf{y}_0^\\top \\mathbf{r} = \\frac{1}{2} \\begin{pmatrix}2  0\\end{pmatrix} \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} = 0$.\n$\\mathbf{r} \\leftarrow \\mathbf{r} + \\mathbf{s}_0 (\\alpha_0 - \\beta_0) = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} + \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} (-\\frac{1}{6} - 0) = \\begin{pmatrix}-\\frac{1}{6} \\\\ 0\\end{pmatrix}$.\n\nFor $i=1$:\n$\\beta_1 = \\rho_1 \\mathbf{y}_1^\\top \\mathbf{r} = 1 \\begin{pmatrix}0  1\\end{pmatrix} \\begin{pmatrix}-\\frac{1}{6} \\\\ 0\\end{pmatrix} = 0$.\n$\\mathbf{r} \\leftarrow \\mathbf{r} + \\mathbf{s}_1 (\\alpha_1 - \\beta_1) = \\begin{pmatrix}-\\frac{1}{6} \\\\ 0\\end{pmatrix} + \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} (\\frac{1}{3} - 0) = \\begin{pmatrix}-\\frac{1}{6} \\\\ \\frac{1}{3}\\end{pmatrix}$.\n\nFor $i=2$:\n$\\beta_2 = \\rho_2 \\mathbf{y}_2^\\top \\mathbf{r} = \\frac{1}{3} \\begin{pmatrix}2  1\\end{pmatrix} \\begin{pmatrix}-\\frac{1}{6} \\\\ \\frac{1}{3}\\end{pmatrix} = \\frac{1}{3}(-\\frac{2}{6} + \\frac{1}{3}) = \\frac{1}{3}(-\\frac{1}{3} + \\frac{1}{3}) = 0$.\n$\\mathbf{r} \\leftarrow \\mathbf{r} + \\mathbf{s}_2 (\\alpha_2 - \\beta_2) = \\begin{pmatrix}-\\frac{1}{6} \\\\ \\frac{1}{3}\\end{pmatrix} + \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} (\\frac{5}{3} - 0) = \\begin{pmatrix}-\\frac{1}{6} + \\frac{5}{3} \\\\ \\frac{1}{3} + \\frac{5}{3}\\end{pmatrix} = \\begin{pmatrix}-\\frac{1}{6} + \\frac{10}{6} \\\\ \\frac{6}{3}\\end{pmatrix} = \\begin{pmatrix}\\frac{9}{6} \\\\ 2\\end{pmatrix} = \\begin{pmatrix}1.5 \\\\ 2\\end{pmatrix}$.\n\nThe result of the two-loop recursion is $\\mathbf{r} = H_{k+1}\\mathbf{g}_{k+1} = \\begin{pmatrix}1.5 \\\\ 2\\end{pmatrix}$.\nThe L-BFGS step is $\\mathbf{p}_{k+1} = -\\mathbf{r} = \\begin{pmatrix}-1.5 \\\\ -2\\end{pmatrix}$. The units of this vector are bohr.\n\nThe final task is to compute the Euclidean norm of this step vector, $\\|\\mathbf{p}_{k+1}\\|_2$.\n$$\n\\|\\mathbf{p}_{k+1}\\|_2 = \\left\\| \\begin{pmatrix}-1.5 \\\\ -2\\end{pmatrix} \\right\\|_2 = \\sqrt{(-1.5)^2 + (-2)^2} = \\sqrt{2.25 + 4} = \\sqrt{6.25} = 2.5\n$$\nThe value is exactly $2.5$. The problem requests the answer to be rounded to four significant figures. Thus, the result is $2.500$.", "answer": "$$ \\boxed{2.500} $$", "id": "2894174"}, {"introduction": "This final exercise challenges you to think critically about the optimization process as a whole, using the classic case of ammonia $\\mathrm{NH_3}$ inversion. It highlights how the topology of the energy surface and algorithmic choices, such as the enforcement of symmetry, can lead to scientifically meaningful but unintended outcomes. Understanding why an optimizer might converge to a transition state instead of a stable minimum is crucial for correctly interpreting computational results and troubleshooting complex calculations. [@problem_id:2458444]", "problem": "Consider a geometry optimization of ammonia $\\mathrm{NH_3}$ on the Born–Oppenheimer (BO) potential energy surface (PES), starting from a planar $D_{3h}$ nuclear geometry. The target global minimum is known experimentally to be a pyramidal $C_{3v}$ structure. The optimizer uses exact electronic energy gradients and a standard Hessian-update scheme, and it can optionally preserve the point-group symmetry of the current molecular geometry at each step. Which explanation best accounts for why such an optimization might fail to find the $C_{3v}$ global minimum when started from the planar $D_{3h}$ structure?\n\nA. The planar $D_{3h}$ structure is a stationary point with $\\nabla E = \\mathbf{0}$ and a Hessian with $1$ negative eigenvalue corresponding to the out-of-plane inversion coordinate; if the optimization enforces $D_{3h}$ symmetry so that trial displacements transform as the totally symmetric irreducible representation, the symmetry-breaking inversion mode is excluded, preventing motion off the saddle and leading to convergence at the $D_{3h}$ structure rather than descent to the $C_{3v}$ minimum.\n\nB. The $C_{3v}$ structure does not exist on the BO PES of $\\mathrm{NH_3}$; it appears only at finite temperature due to entropic stabilization, so at $T=0$ the only stationary structure is the planar $D_{3h}$ geometry.\n\nC. Use of a sufficiently large one-electron basis set always raises the energy of lower-symmetry structures relative to higher-symmetry ones, so the optimizer prefers the higher-symmetry $D_{3h}$ geometry over the lower-symmetry $C_{3v}$ structure.\n\nD. Gradient-based optimizers cannot change the electronic state during optimization, and the $C_{3v}$ structure of $\\mathrm{NH_3}$ is a different spin state than the $D_{3h}$ structure; the optimization therefore remains on the $D_{3h}$ surface and cannot reach $C_{3v}$.", "solution": "The validity of the problem statement must first be established.\n\n**Step 1: Extract Givens**\n- System: Ammonia, $\\mathrm{NH_3}$\n- Process: Geometry optimization on the Born–Oppenheimer (BO) potential energy surface (PES).\n- Initial Geometry: Planar $D_{3h}$ nuclear geometry.\n- Target Geometry: Pyramidal $C_{3v}$ structure, which is the experimentally known global minimum.\n- Optimizer Method: Uses exact electronic energy gradients and a standard Hessian-update scheme.\n- Optimizer Constraint: Can optionally preserve the point-group symmetry of the current molecular geometry at each step.\n- Question: Explain why such an optimization might fail to find the $C_{3v}$ global minimum when started from the planar $D_{3h}$ structure.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is scientifically grounded, well-posed, and objective. It describes a classic and standard problem in computational quantum chemistry: the optimization of ammonia's geometry. The existence of a pyramidal $C_{3v}$ global minimum and a planar $D_{3h}$ transition state for the inversion motion are well-established facts. The concepts of a potential energy surface, gradient-based optimizers, Hessians, and the use of symmetry constraints are all fundamental to the field. The question asks for a causal explanation for a known computational phenomenon, which has a unique and correct answer based on these principles. The problem is self-contained and does not violate any scientific laws or contain ambiguities.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A full solution will be derived.\n\n**Derivation**\nA geometry optimization algorithm seeks to find stationary points on a potential energy surface (PES), which are points where the gradient of the energy $E$ with respect to all nuclear coordinates is the zero vector, i.e., $\\nabla E = \\mathbf{0}$. Stationary points are classified based on the eigenvalues of the Hessian matrix (the matrix of second partial derivatives of energy). A local minimum has a Hessian with all non-negative eigenvalues. A first-order saddle point, typically a transition state, has a Hessian with exactly one negative eigenvalue.\n\nFor ammonia, $\\mathrm{NH_3}$, the PES has two key stationary points of interest for the inversion process:\n$1$. The global minimum energy structure, which is a pyramid with $C_{3v}$ point group symmetry.\n$2$. A first-order saddle point, which is the planar structure with $D_{3h}$ point group symmetry. This structure represents the transition state for the inversion of the pyramid.\n\nAn optimization starting from the planar $D_{3h}$ structure is positioned precisely at a stationary point. Since $\\nabla E = \\mathbf{0}$ at this geometry, a simple gradient-based optimizer would immediately test for convergence. The character of this stationary point (minimum or saddle point) is determined by the Hessian. As the $D_{3h}$ structure is a transition state for inversion, its Hessian has exactly $1$ negative eigenvalue. The eigenvector corresponding to this negative eigenvalue describes the nuclear displacements of the inversion mode: the nitrogen atom moving out of the plane of the three hydrogen atoms. This motion breaks the $D_{3h}$ symmetry and leads downhill on the PES towards one of the two equivalent $C_{3v}$ minima.\n\nThe problem specifies that the optimizer can be constrained to preserve point-group symmetry. When this option is active for the $D_{3h}$ point group, the optimizer is restricted to exploring displacements that transform as the totally symmetric irreducible representation (irrep) of the $D_{3h}$ group, which is $A_1'$. Any step the optimizer takes must not break the $D_{3h}$ symmetry.\n\nThe inversion coordinate, which is the only direction leading downhill from the saddle point, involves the nitrogen atom's motion perpendicular to the molecular plane. In the $D_{3h}$ point group, this out-of-plane motion transforms as the $A_2''$ irreducible representation. Because this mode is not totally symmetric (i.e., $A_2'' \\neq A_1'$), a symmetry-constrained optimizer is \"blind\" to it. It cannot generate a trial step along this coordinate.\n\nConsequently, if the optimization begins at the $D_{3h}$ geometry and is constrained to preserve $D_{3h}$ symmetry, it finds that the gradient is zero ($\\nabla E = \\mathbf{0}$). It cannot find any symmetry-allowed direction to move that would lower the energy. The only available path to the true minimum requires a symmetry-breaking step, which is explicitly forbidden by the constraint. The algorithm therefore concludes, incorrectly, that it has found a minimum and terminates at the $D_{3h}$ saddle point.\n\n**Option-by-Option Analysis**\n\n**A. The planar $D_{3h}$ structure is a stationary point with $\\nabla E = \\mathbf{0}$ and a Hessian with $1$ negative eigenvalue corresponding to the out-of-plane inversion coordinate; if the optimization enforces $D_{3h}$ symmetry so that trial displacements transform as the totally symmetric irreducible representation, the symmetry-breaking inversion mode is excluded, preventing motion off the saddle and leading to convergence at the $D_{3h}$ structure rather than descent to the $C_{3v}$ minimum.**\nThis statement is a precise and accurate description of the situation. It correctly identifies the $D_{3h}$ structure as a first-order saddle point ($\\nabla E = \\mathbf{0}$, $1$ negative Hessian eigenvalue). It correctly identifies the role of the symmetry constraint in limiting search directions to the totally symmetric irrep. It correctly concludes that this constraint prevents the optimizer from following the symmetry-breaking inversion mode, causing it to fail to find the $C_{3v}$ minimum.\n**Verdict: Correct**\n\n**B. The $C_{3v}$ structure does not exist on the BO PES of $\\mathrm{NH_3}$; it appears only at finite temperature due to entropic stabilization, so at $T=0$ the only stationary structure is the planar $D_{3h}$ geometry.**\nThis statement is factually incorrect. The Born-Oppenheimer PES is a concept defined at absolute zero kelvin ($T=0$ K), representing the electronic energy as a function of nuclear positions. On this surface, the pyramidal $C_{3v}$ structure is the true global minimum for $\\mathrm{NH_3}$. Entropic effects at finite temperature do not create new stationary points on the electronic PES.\n**Verdict: Incorrect**\n\n**C. Use of a sufficiently large one-electron basis set always raises the energy of lower-symmetry structures relative to higher-symmetry ones, so the optimizer prefers the higher-symmetry $D_{3h}$ geometry over the lower-symmetry $C_{3v}$ structure.**\nThis statement is false. There is no general principle stating that large basis sets energetically favor higher-symmetry structures. The relative energies of isomers or conformers are determined by the complex physics of electron correlation and nuclear repulsion. For $\\mathrm{NH_3}$, accurate calculations with large basis sets correctly show the $C_{3v}$ structure is lower in energy than the $D_{3h}$ structure. The failure is a limitation of the search algorithm, not an artifact of the energy calculation or basis set.\n**Verdict: Incorrect**\n\n**D. Gradient-based optimizers cannot change the electronic state during optimization, and the $C_{3v}$ structure of $\\mathrm{NH_3}$ is a different spin state than the $D_{3h}$ structure; the optimization therefore remains on the $D_{3h}$ surface and cannot reach $C_{3v}$.**\nThis statement is incorrect. While it is true that a standard geometry optimization proceeds on a single PES corresponding to a single electronic state (e.g., the ground state), the premise that the $C_{3v}$ and $D_{3h}$ structures of $\\mathrm{NH_3}$ have different spin states is false. Both the pyramidal minimum and the planar transition state for the ground state of $\\mathrm{NH_3}$ are closed-shell singlets. The optimization failure is not due to a change in electronic state.\n**Verdict: Incorrect**", "answer": "$$\\boxed{A}$$", "id": "2458444"}]}