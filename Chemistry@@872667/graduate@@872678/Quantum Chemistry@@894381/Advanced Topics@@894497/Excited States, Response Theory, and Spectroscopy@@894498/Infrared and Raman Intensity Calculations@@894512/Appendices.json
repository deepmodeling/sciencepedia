{"hands_on_practices": [{"introduction": "Calculating IR and Raman intensities begins with accurately computing the derivatives of the molecular dipole moment $\\boldsymbol{\\mu}$ and polarizability $\\boldsymbol{\\alpha}$. In practice, these are often found using numerical finite difference methods, which introduces a fundamental trade-off between truncation error from the mathematical formula and propagation of numerical noise from the underlying quantum chemical calculation. This exercise [@problem_id:2898195] challenges you to design an optimal calculation by quantitatively analyzing and minimizing the total error, a critical skill for any computational scientist seeking reliable results.", "problem": "In molecular infrared (IR) and Raman spectroscopy, the band intensities for a normal mode $Q_k$ are governed by the first derivatives $\\partial \\mu_\\alpha/\\partial Q_k$ and $\\partial \\alpha_{ij}/\\partial Q_k$ of the dipole moment component $\\mu_\\alpha$ and polarizability tensor component $\\alpha_{ij}$ evaluated at the equilibrium geometry. Consider the symmetric stretch normal coordinate $Q_s$ of gas-phase water as a representative case. Assume that near $Q_s = 0$ the property surfaces along $Q_s$ are well approximated by odd-power Taylor expansions (consistent with the symmetry of a totally symmetric mode) as\n$$\n\\mu_z(Q_s) = \\mu_0 + \\mu_1 Q_s + \\frac{\\mu_3}{6} Q_s^3 + \\frac{\\mu_5}{120} Q_s^5,\n$$\n$$\n\\alpha_{zz}(Q_s) = a_0 + a_1 Q_s + \\frac{a_3}{6} Q_s^3 + \\frac{a_5}{120} Q_s^5,\n$$\nwith $\\mu_0 = 0.728$ (atomic units $e\\,a_0$), $\\mu_1 = 0.400$, $\\mu_3 = 1.200$, $\\mu_5 = 2.000$, $a_0 = 9.86$ (in $a_0^3$), $a_1 = 0.150$, $a_3 = 0.500$, and $a_5 = 1.000$. Here $a_0$ is the Bohr radius. Assume further that each ab initio property evaluation (at any given $Q_s$) is contaminated by independent, zero-mean, Gaussian numerical noise with known standard deviations $\\sigma_\\mu = 1.0\\times 10^{-6}$ for $\\mu_z$ and $\\sigma_\\alpha = 2.0\\times 10^{-6}$ for $\\alpha_{zz}$, reflecting tight but finite numerical thresholds.\n\nYou must design a robust central finite-difference scheme to estimate the first derivatives $\\left.\\partial \\mu_z/\\partial Q_s\\right|_{0}$ and $\\left.\\partial \\alpha_{zz}/\\partial Q_s\\right|_{0}$ that minimizes the mean-squared error arising from the competition between truncation (step-size) error and propagated numerical noise. You may choose among central schemes that are symmetric about $Q_s=0$, namely:\n- a two-point centered difference using $Q_s=\\pm h$,\n- a four-point centered difference using $Q_s=\\pm h,\\pm 2h$,\n- a two-level Richardson extrapolation constructed from centered differences at $h$ and $h/2$.\n\nStarting from Taylor’s theorem and standard Gaussian error propagation, determine for each property which scheme and step size $h$ minimize the mean-squared error under the stated model, and quantify:\n- the one-sigma numerical uncertainty (from noise propagation),\n- the leading truncation bias at the chosen $h$ (state its sign),\n- the resulting expected derivative estimate (bias applied to the true derivative),\nall reported to three significant figures.\n\nWhich option below correctly provides such a robust design (scheme, step sizes, and quantitative error breakdown) for both $\\partial \\mu_z/\\partial Q_s$ and $\\partial \\alpha_{zz}/\\partial Q_s$?\n\nA. Use the two-point centered difference with optimally balanced steps $h_\\mu \\approx 0.0136$ and $h_\\alpha \\approx 0.0229$. Predicted performance:\n- $\\partial \\mu_z/\\partial Q_s \\approx 0.400037$, one-sigma numerical uncertainty $\\pm 5.20\\times 10^{-5}$, truncation bias $+3.70\\times 10^{-5}$, root-mean-square error $\\approx 6.38\\times 10^{-5}$.\n- $\\partial \\alpha_{zz}/\\partial Q_s \\approx 0.150044$, one-sigma numerical uncertainty $\\pm 6.18\\times 10^{-5}$, truncation bias $+4.37\\times 10^{-5}$, root-mean-square error $\\approx 7.53\\times 10^{-5}$.\n\nB. Use the four-point centered difference with optimally balanced steps $h_\\mu \\approx 0.0936$ and $h_\\alpha \\approx 0.123$. Predicted performance:\n- $\\partial \\mu_z/\\partial Q_s \\approx 0.399995$, one-sigma numerical uncertainty $\\pm 1.02\\times 10^{-5}$, truncation bias $-5.10\\times 10^{-6}$, root-mean-square error $\\approx 1.13\\times 10^{-5}$.\n- $\\partial \\alpha_{zz}/\\partial Q_s \\approx 0.149992$, one-sigma numerical uncertainty $\\pm 1.55\\times 10^{-5}$, truncation bias $-7.63\\times 10^{-6}$, root-mean-square error $\\approx 1.73\\times 10^{-5}$.\n\nC. Use the four-point centered difference with a conservative common step $h_\\mu=h_\\alpha=0.0200$. Predicted performance:\n- $\\partial \\mu_z/\\partial Q_s \\approx 0.400000$, one-sigma numerical uncertainty $\\pm 4.75\\times 10^{-5}$, truncation bias $-1.07\\times 10^{-8}$, root-mean-square error $\\approx 4.75\\times 10^{-5}$.\n- $\\partial \\alpha_{zz}/\\partial Q_s \\approx 0.150000$, one-sigma numerical uncertainty $\\pm 9.50\\times 10^{-5}$, truncation bias $-5.33\\times 10^{-9}$, root-mean-square error $\\approx 9.50\\times 10^{-5}$.\n\nD. Use two-level Richardson extrapolation with steps $h_\\mu \\approx 0.0936$ and $h_\\alpha \\approx 0.123$. Predicted performance:\n- $\\partial \\mu_z/\\partial Q_s \\approx 0.400000$, one-sigma numerical uncertainty $\\pm 1.02\\times 10^{-5}$, truncation bias $-3.19\\times 10^{-7}$, root-mean-square error $\\approx 1.02\\times 10^{-5}$.\n- $\\partial \\alpha_{zz}/\\partial Q_s \\approx 0.150000$, one-sigma numerical uncertainty $\\pm 1.55\\times 10^{-5}$, truncation bias $-4.77\\times 10^{-7}$, root-mean-square error $\\approx 1.55\\times 10^{-5}$.\n\nSelect the single option that both correctly minimizes the mean-squared error under the stated noise model for each property and accurately reports the corresponding step sizes and quantitative error breakdown.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\nThe properties, dipole moment component $\\mu_z$ and polarizability tensor component $\\alpha_{zz}$, are given as functions of the normal coordinate $Q_s$. Near the equilibrium geometry ($Q_s=0$), their expansions are:\n$$\n\\mu_z(Q_s) = \\mu_0 + \\mu_1 Q_s + \\frac{\\mu_3}{6} Q_s^3 + \\frac{\\mu_5}{120} Q_s^5\n$$\n$$\n\\alpha_{zz}(Q_s) = a_0 + a_1 Q_s + \\frac{a_3}{6} Q_s^3 + \\frac{a_5}{120} Q_s^5\n$$\nCoefficients for $\\mu_z(Q_s)$ are: $\\mu_0 = 0.728$, $\\mu_1 = 0.400$, $\\mu_3 = 1.200$, $\\mu_5 = 2.000$ in atomic units.\nCoefficients for $\\alpha_{zz}(Q_s)$ are: $a_0 = 9.86$, $a_1 = 0.150$, $a_3 = 0.500$, $a_5 = 1.000$ in atomic units.\nThe true first derivatives at $Q_s=0$ are $\\left.\\partial \\mu_z/\\partial Q_s\\right|_{0} = \\mu_1 = 0.400$ and $\\left.\\partial \\alpha_{zz}/\\partial Q_s\\right|_{0} = a_1 = 0.150$.\nThe problem states that each property evaluation is contaminated by independent, zero-mean, Gaussian numerical noise with standard deviations $\\sigma_\\mu = 1.0\\times 10^{-6}$ for $\\mu_z$ and $\\sigma_\\alpha = 2.0\\times 10^{-6}$ for $\\alpha_{zz}$.\nThe task is to find the optimal central finite-difference scheme among three candidates (two-point centered, four-point centered, two-level Richardson extrapolation) and the corresponding optimal step size $h$ that minimizes the mean-squared error (MSE) for the estimation of the first derivatives.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded. The context is quantum chemistry, specifically the calculation of IR and Raman intensities, which depend on dipole and polarizability derivatives. The use of Taylor series to approximate property surfaces is a standard technique. The concept of balancing truncation and numerical noise errors in finite-difference calculations is a fundamental topic in numerical analysis. The problem is well-posed, providing all necessary functional forms, coefficient values, and a precise noise model to uniquely determine an optimal numerical strategy. The language is objective and the data are consistent. The problem does not violate any of the invalidity criteria.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be derived.\n\n**Derivation**\nThe goal is to estimate a first derivative $f'(0)$ of a function $f(Q_s)$ with a given Taylor series expansion $f(Q_s) = f_0 + f_1 Q_s + f_2 Q_s^2/2! + f_3 Q_s^3/3! + ...$, where evaluations of $f$ are subject to noise with standard deviation $\\sigma$. The problem states that the expansions contain only odd powers of $Q_s$ beyond the constant term, so $f_{2n}=0$ for $n \\ge 1$. Thus, $f(Q_s) = f_0 + f_1 Q_s + f_3 Q_s^3/6 + f_5 Q_s^5/120 + O(Q_s^7)$. We seek to minimize the Mean-Squared Error (MSE) of the estimate, which is the sum of the squared truncation bias and the propagated noise variance: $\\text{MSE} = (\\epsilon_T)^2 + \\sigma_N^2$.\n\n**Scheme 1: Two-point centered difference ($D_2$)**\nThe formula is $D_2(h) = \\frac{f(h) - f(-h)}{2h}$.\nUsing Taylor series for $f(h)$ and $f(-h)$:\n$f(h) - f(-h) = (f_0 + f_1 h + \\frac{f_3}{6}h^3 + ...) - (f_0 - f_1 h - \\frac{f_3}{6}h^3 + ...)$\n$f(h) - f(-h) = 2f_1 h + \\frac{f_3}{3} h^3 + O(h^5)$.\n$D_2(h) = f_1 + \\frac{f_3}{6}h^2 + O(h^4)$.\nThe leading truncation error (bias) is $\\epsilon_T(h) = \\frac{f_3}{6}h^2$.\nThe noise variance is $\\sigma_N^2 = \\text{Var}\\left(\\frac{f_{\\text{noisy}}(h) - f_{\\text{noisy}}(-h)}{2h}\\right) = \\frac{\\sigma^2 + \\sigma^2}{(2h)^2} = \\frac{2\\sigma^2}{4h^2} = \\frac{\\sigma^2}{2h^2}$.\nThe MSE is $\\text{MSE}(h) = \\left(\\frac{f_3}{6}h^2\\right)^2 + \\frac{\\sigma^2}{2h^2} = \\frac{f_3^2}{36}h^4 + \\frac{\\sigma^2}{2}h^{-2}$.\nMinimizing with respect to $h$: $\\frac{d(\\text{MSE})}{dh} = \\frac{4f_3^2}{36}h^3 - \\frac{2\\sigma^2}{2}h^{-3} = 0 \\implies \\frac{f_3^2}{9}h^3 = \\sigma^2h^{-3}$.\nThe optimal step size is $h_{\\text{opt}} = \\left(\\frac{9\\sigma^2}{f_3^2}\\right)^{1/6}$.\n\n**Scheme 2: Four-point centered difference ($D_4$)**\nThe formula is $D_4(h) = \\frac{f(-2h) - 8f(-h) + 8f(h) - f(2h)}{12h}$.\nThis is a standard $O(h^4)$ formula. The leading truncation error is $\\epsilon_T(h) = -\\frac{f_5}{30}h^4$.\nThe noise variance is $\\sigma_N^2 = \\text{Var}\\left(\\frac{f_{\\text{noisy}}(-2h) - 8f_{\\text{noisy}}(-h) + ...}{12h}\\right) = \\frac{1^2+8^2+8^2+1^2}{(12h)^2}\\sigma^2 = \\frac{130}{144h^2}\\sigma^2 = \\frac{65}{72h^2}\\sigma^2$.\nThe MSE is $\\text{MSE}(h) = \\left(-\\frac{f_5}{30}h^4\\right)^2 + \\frac{65\\sigma^2}{72h^2} = \\frac{f_5^2}{900}h^8 + \\frac{65\\sigma^2}{72}h^{-2}$.\nMinimizing with respect to $h$: $\\frac{d(\\text{MSE})}{dh} = \\frac{8f_5^2}{900}h^7 - \\frac{130\\sigma^2}{72}h^{-3} = 0 \\implies \\frac{f_5^2}{112.5}h^7 = \\frac{65}{36}\\sigma^2h^{-3}$.\nThe optimal step size is $h_{\\text{opt}} = \\left(\\frac{112.5 \\times 65}{36} \\frac{\\sigma^2}{f_5^2}\\right)^{1/10} = \\left(203.125 \\frac{\\sigma^2}{f_5^2}\\right)^{1/10}$.\n\n**Scheme 3: Two-level Richardson extrapolation ($R$)**\nThis scheme combines two estimates from the $D_2$ scheme: $R(h) = \\frac{4D_2(h/2) - D_2(h)}{3}$.\nThe leading truncation error is $\\epsilon_T(h) = -\\frac{f_5}{480}h^4$.\nThe noise variance is $\\sigma_N^2 = \\text{Var}\\left(\\frac{4}{3}D_2(h/2) - \\frac{1}{3}D_2(h)\\right)$. Assuming independent noise at points $\\pm h, \\pm h/2$:\n$\\sigma_N^2 = \\left(\\frac{4}{3}\\right)^2 \\text{Var}(D_2(h/2)) + \\left(-\\frac{1}{3}\\right)^2 \\text{Var}(D_2(h)) = \\frac{16}{9} \\left(\\frac{\\sigma^2}{2(h/2)^2}\\right) + \\frac{1}{9} \\left(\\frac{\\sigma^2}{2h^2}\\right) = \\frac{16}{9}\\frac{2\\sigma^2}{h^2} + \\frac{1}{18}\\frac{\\sigma^2}{h^2} = \\left(\\frac{32}{9}+\\frac{1}{18}\\right)\\frac{\\sigma^2}{h^2} = \\frac{65}{18h^2}\\sigma^2$.\nThe MSE is $\\text{MSE}(h) = \\left(-\\frac{f_5}{480}h^4\\right)^2 + \\frac{65\\sigma^2}{18h^2} = \\frac{f_5^2}{230400}h^8 + \\frac{65\\sigma^2}{18}h^{-2}$.\nMinimizing with respect to $h$: $\\frac{d(\\text{MSE})}{dh} = \\frac{8f_5^2}{230400}h^7 - \\frac{130\\sigma^2}{18}h^{-3} = 0$.\nThe optimal step size is $h_{\\text{opt}} = \\left(\\frac{230400 \\times 130}{8 \\times 18} \\frac{\\sigma^2}{f_5^2}\\right)^{1/10} = \\left(208000 \\frac{\\sigma^2}{f_5^2}\\right)^{1/10}$.\n\n**Comparison of Schemes and Error Analysis**\nWe now apply these formulas to both properties to find the minimum Root Mean-Squared Error (RMSE = $\\sqrt{\\text{MSE}}$) for each scheme.\n\nFor $\\mu_z$: $f_1=\\mu_1=0.400$, $f_3=\\mu_3=1.200$, $f_5=\\mu_5=2.000$, $\\sigma=\\sigma_\\mu=1.0\\times 10^{-6}$.\n- $D_2$: $h_{\\text{opt}} = (\\frac{9(10^{-6})^2}{1.2^2})^{1/6} \\approx 0.0136$.\n    - $\\epsilon_T = \\frac{1.2}{6}(0.0136)^2 \\approx +3.70\\times 10^{-5}$.\n    - $\\sigma_N = \\sqrt{\\frac{(10^{-6})^2}{2(0.0136)^2}} \\approx 5.20\\times 10^{-5}$.\n    - RMSE = $\\sqrt{(3.70\\times 10^{-5})^2 + (5.20\\times 10^{-5})^2} \\approx 6.38\\times 10^{-5}$.\n- $D_4$: $h_{\\text{opt}} = (203.125 \\frac{(10^{-6})^2}{2.0^2})^{1/10} \\approx 0.0936$.\n    - $\\epsilon_T = -\\frac{2.0}{30}(0.0936)^4 \\approx -5.10\\times 10^{-6}$.\n    - $\\sigma_N = \\sqrt{\\frac{65(10^{-6})^2}{72(0.0936)^2}} \\approx 1.02\\times 10^{-5}$.\n    - RMSE = $\\sqrt{(-5.10\\times 10^{-6})^2 + (1.02\\times 10^{-5})^2} \\approx 1.14\\times 10^{-5}$.\n- $R$: $h_{\\text{opt}} = (208000 \\frac{(10^{-6})^2}{2.0^2})^{1/10} \\approx 0.118$.\n    - RMSE $\\approx 1.61\\times 10^{-5}$.\n\nFor $\\alpha_{zz}$: $f_1=a_1=0.150$, $f_3=a_3=0.500$, $f_5=a_5=1.000$, $\\sigma=\\sigma_\\alpha=2.0\\times 10^{-6}$.\n- $D_2$: $h_{\\text{opt}} = (\\frac{9(2 \\times 10^{-6})^2}{0.5^2})^{1/6} \\approx 0.0229$.\n    - $\\epsilon_T = \\frac{0.5}{6}(0.0229)^2 \\approx +4.37\\times 10^{-5}$.\n    - $\\sigma_N = \\sqrt{\\frac{(2 \\times 10^{-6})^2}{2(0.0229)^2}} \\approx 6.18\\times 10^{-5}$.\n    - RMSE = $\\sqrt{(4.37\\times 10^{-5})^2 + (6.18\\times 10^{-5})^2} \\approx 7.57\\times 10^{-5}$.\n- $D_4$: $h_{\\text{opt}} = (203.125 \\frac{(2 \\times 10^{-6})^2}{1.0^2})^{1/10} \\approx 0.123$.\n    - $\\epsilon_T = -\\frac{1.0}{30}(0.123)^4 \\approx -7.63\\times 10^{-6}$.\n    - $\\sigma_N = \\sqrt{\\frac{65(2 \\times 10^{-6})^2}{72(0.123)^2}} \\approx 1.55\\times 10^{-5}$.\n    - RMSE = $\\sqrt{(-7.63\\times 10^{-6})^2 + (1.55\\times 10^{-5})^2} \\approx 1.73\\times 10^{-5}$.\n- $R$: $h_{\\text{opt}} = (208000 \\frac{(2 \\times 10^{-6})^2}{1.0^2})^{1/10} \\approx 0.156$.\n    - RMSE $\\approx 2.44\\times 10^{-5}$.\n\n**Conclusion**\nFor both properties, the four-point centered difference ($D_4$) scheme provides the smallest minimum mean-squared error.\nFor $\\mu_z$: minimum RMSE is $\\approx 1.14\\times 10^{-5}$.\nFor $\\alpha_{zz}$: minimum RMSE is $\\approx 1.73\\times 10^{-5}$.\nTherefore, the $D_4$ scheme with its corresponding optimal step sizes is the correct design.\n\n**Option-by-Option Analysis**\n\nA. This option proposes the two-point centered difference scheme. The calculated step sizes and error breakdown are correct for this scheme. However, this scheme is not optimal, as the four-point scheme yields a significantly lower MSE for both properties. Therefore, this option is **Incorrect**.\n\nB. This option proposes the four-point centered difference scheme, which my analysis identified as optimal. The proposed step sizes ($h_\\mu \\approx 0.0936, h_\\alpha \\approx 0.123$) match our calculated optimal values for this scheme. The reported performance metrics (numerical uncertainty, truncation bias, RMS error, and expected derivative) for both properties are consistent with my derivations. For $\\partial \\mu_z/\\partial Q_s$: uncertainty $\\approx 1.02\\times 10^{-5}$, bias $\\approx -5.10\\times 10^{-6}$, RMSE $\\approx 1.14\\times 10^{-5}$, derivative $\\approx 0.400 - 5.10\\times 10^{-6} = 0.3999949 \\approx 0.399995$. For $\\partial \\alpha_{zz}/\\partial Q_s$: uncertainty $\\approx 1.55\\times 10^{-5}$, bias $\\approx -7.63\\times 10^{-6}$, RMSE $\\approx 1.73\\times 10^{-5}$, derivative $\\approx 0.150 - 7.63\\times 10^{-6} = 0.14999237 \\approx 0.149992$. All values are in agreement. This option appears to be correct. Therefore, this option is **Correct**.\n\nC. This option proposes the correct scheme (four-point) but uses a non-optimal \"conservative\" step size $h=0.0200$. While the error analysis for this specific step size is arithmetically correct, this choice does not minimize the mean-squared error. The resulting RMSEs are substantially larger than those achievable with the optimal step sizes presented in option B. Therefore, this option is **Incorrect**.\n\nD. This option proposes Richardson extrapolation. My analysis shows this scheme is suboptimal compared to the four-point formula. Furthermore, the option incorrectly uses the optimal step sizes for the four-point formula ($h_\\mu \\approx 0.0936, h_\\alpha \\approx 0.123$) instead of the correct optimal step sizes for Richardson extrapolation ($h_\\mu \\approx 0.118, h_\\alpha \\approx 0.156$). Critically, it then uses the noise propagation formula for the four-point scheme ($\\sigma_N \\propto 1/h$) instead of the correct one for Richardson extrapolation ($\\sigma_N \\propto 1/h$), leading to incorrect numerical uncertainty values. Therefore, this option is fundamentally flawed and **Incorrect**.", "answer": "$$\\boxed{B}$$", "id": "2898195"}, {"introduction": "The normal modes of vibration obtained from a calculation are often delocalized over the entire molecule and can be difficult to interpret in simple chemical terms. To understand why a particular mode has a certain IR or Raman intensity, we must connect these abstract mathematical vectors to intuitive motions like bond stretches and angle bends. This practice [@problem_id:2898215] guides you through implementing a principled sensitivity analysis based on linear algebra, allowing you to quantitatively determine which local motions are the primary drivers of a spectral feature's intensity.", "problem": "Design and implement a complete program that performs a principled sensitivity analysis to identify which internal coordinates dominate a given vibrational mode’s infrared (IR) or Raman intensity by projecting property derivatives onto internal coordinate directions. Your derivation and algorithm must start from foundational principles in quantum chemistry and linear algebra and must not assume any special formulas beyond standard, well-tested definitions. The program must execute the following tasks for each test case and return the index (zero-based) of the single most dominant internal coordinate.\n\nFoundational starting points you must use:\n- Infrared intensity for a normal mode is proportional to the square of the directional derivative of the molecular dipole moment along the mode. If $g \\in \\mathbb{R}^{M}$ denotes the Cartesian gradient of a scalar dipole component with respect to nuclear Cartesian coordinates, and $v \\in \\mathbb{R}^{M}$ is the Cartesian normal mode direction (not necessarily mass-weighted for this problem), then by the chain rule the directional derivative is $g \\cdot v$ and the intensity is proportional to $(g \\cdot v)^{2}$.\n- Raman activity for a normal mode is obtained from rotational invariants of the polarizability derivative tensor. If $\\alpha' \\in \\mathbb{R}^{3 \\times 3}$ is the polarizability derivative tensor along the mode, then the standard randomly oriented Raman activity is proportional to $45\\,a^{2} + 7\\,\\gamma^{2}$, where $a = \\tfrac{1}{3}\\operatorname{Tr}(\\alpha')$ is the isotropic invariant and $\\gamma^{2}$ is the anisotropy invariant built from the tensor’s symmetric components. The tensor $\\alpha'$ arises linearly from per-coordinate tensor derivatives $\\{A_{i}\\}_{i=1}^{M}$ and the mode components $\\{v_{i}\\}_{i=1}^{M}$ via $\\alpha' = \\sum_{i=1}^{M} v_{i} A_{i}$.\n\nProjection framework and sensitivity definition you must implement:\n- You are given $K$ internal coordinate direction vectors in Cartesian space, assembled as columns of a matrix $D \\in \\mathbb{R}^{M \\times K}$ with columns $\\{d_{k}\\}_{k=1}^{K}$. Assume $D$ has full column rank. Define the Gram matrix $S = D^{\\top} D \\in \\mathbb{R}^{K \\times K}$ and the internal-coordinate decomposition coefficients $c \\in \\mathbb{R}^{K}$ by solving $S\\,c = D^{\\top} v$. This produces the unique decomposition of the mode direction $v$ within the span of the internal coordinate directions: $v = \\sum_{k=1}^{K} c_{k}\\, d_{k}$.\n- For IR sensitivity: Define the signed contribution of internal coordinate $k$ to the mode’s dipole directional derivative as $t_{k} = g \\cdot (c_{k} d_{k})$. Use the intensity-relevant sensitivity weight $s_{k} = t_{k}^{2}$ to rank dominance. The dominant internal coordinate is the index $k$ that maximizes $s_{k}$.\n- For Raman sensitivity: Let $\\alpha' = \\sum_{i=1}^{M} v_{i} A_{i}$ and let $S_{\\mathrm{R}}(\\alpha')$ denote the activity proportional to $45\\,a^{2} + 7\\,\\gamma^{2}$ constructed from $\\alpha'$. Define the internal-coordinate-resolved tensor contributions $\\alpha'_{(k)} = \\sum_{i=1}^{M} (c_{k}\\, d_{k,i})\\, A_{i}$. Use a first-order (linearized) sensitivity around $\\alpha'$ by computing the tensor gradient $\\nabla_{\\alpha'} S_{\\mathrm{R}}(\\alpha')$ and the signed linear contribution $L_{k} = \\langle \\alpha'_{(k)}, \\nabla_{\\alpha'} S_{\\mathrm{R}}(\\alpha') \\rangle$, where $\\langle X,Y\\rangle = \\sum_{a,b} X_{ab} Y_{ab}$ is the Frobenius inner product. Rank dominance by the largest absolute linearized contribution $\\lvert L_{k} \\rvert$.\n\nInput data for the test suite:\n- All numeric values are to be interpreted as dimensionless, in arbitrary consistent units. No physical-unit conversion is required.\n- You must treat all matrices in the Raman cases as symmetric $3 \\times 3$ tensors.\n\nImplement your program to process the following three test cases, each specified by $(D, v, \\text{type}, \\text{properties})$:\n\n1) IR, orthonormal internal directions:\n- $M = 4$, $K = 3$.\n- $D = \\begin{bmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1 \\\\\n0  0  0\n\\end{bmatrix}$ whose columns are $d_{1} = (1,0,0,0)^{\\top}$, $d_{2} = (0,1,0,0)^{\\top}$, $d_{3} = (0,0,1,0)^{\\top}$.\n- $v = \\left(\\tfrac{1}{\\sqrt{2}}, \\tfrac{1}{\\sqrt{2}}, 0, 0\\right)^{\\top}$.\n- IR property gradient $g = (2.0, -1.0, 0.5, 3.0)^{\\top}$.\n- Determine the index $k \\in \\{0,1,2\\}$ with the largest $s_{k}$.\n\n2) IR, non-orthogonal internal directions:\n- $M = 3$, $K = 3$.\n- Columns $d_{1} = (1,0,0)^{\\top}$, $d_{2} = (1,1,0)^{\\top}$, $d_{3} = (0,1,1)^{\\top}$, so $D = \\begin{bmatrix}1  1  0 \\\\ 0  1  1 \\\\ 0  0  1\\end{bmatrix}$ after column assembly as stated (equivalently, the three $d_{k}$ vectors listed above).\n- $v = (1,2,1)^{\\top}$.\n- IR property gradient $g = (0.5, -0.2, 0.8)^{\\top}$.\n- Determine the index $k \\in \\{0,1,2\\}$ with the largest $s_{k}$.\n\n3) Raman, linearized sensitivity:\n- $M = 2$, $K = 2$.\n- Columns $d_{1} = (1,0)^{\\top}$, $d_{2} = (1,1)^{\\top}$, so $D = \\begin{bmatrix}1  1 \\\\ 0  1\\end{bmatrix}$ after column assembly as stated (equivalently, the two $d_{k}$ vectors listed above).\n- $v = (2,1)^{\\top}$.\n- Per-coordinate symmetric polarizability derivative tensors:\n  $A_{1} = \\begin{bmatrix}\n1.0  0.2  0.0 \\\\\n0.2  0.5  0.1 \\\\\n0.0  0.1  0.3\n\\end{bmatrix}$ and\n  $A_{2} = \\begin{bmatrix}\n0.3  0.0  0.1 \\\\\n0.0  0.7  0.2 \\\\\n0.1  0.2  0.4\n\\end{bmatrix}$.\n- Construct $\\alpha' = v_{1} A_{1} + v_{2} A_{2}$, compute the activity $S_{\\mathrm{R}}(\\alpha') \\propto 45\\,a^{2} + 7\\,\\gamma^{2}$, form $\\nabla_{\\alpha'} S_{\\mathrm{R}}(\\alpha')$, then compute $L_{k}$ for $k \\in \\{0,1\\}$ from the projected contributions $\\alpha'_{(k)}$ defined above. Determine the index with the largest $\\lvert L_{k} \\rvert$.\n\nFinal output specification:\n- Your program must process all three cases in order and produce a single line of output containing the three zero-based dominant indices as a comma-separated list enclosed in square brackets, with no spaces, for example `[i_1,i_2,i_3]`.", "solution": "The problem presented is a valid and well-posed exercise in computational quantum chemistry, requiring the application of linear algebra and differential calculus to analyze vibrational spectroscopic intensities. It is scientifically grounded in the fundamental principles of infrared (IR) and Raman spectroscopy and provides a complete, self-contained set of definitions and data. We shall now proceed with a rigorous, first-principles derivation and algorithmic solution.\n\nThe central task is to attribute the intensity of a vibrational mode, represented by a Cartesian displacement vector $v \\in \\mathbb{R}^{M}$, to a set of $K$ predefined internal coordinates. These internal coordinates, representing physically intuitive motions like bond stretches or angle bends, are given as direction vectors $\\{d_k\\}_{k=0}^{K-1}$ in the same $M$-dimensional Cartesian space. They form the columns of a matrix $D \\in \\mathbb{R}^{M \\times K}$. A fundamental step is to decompose the mode vector $v$ into components along these internal coordinate directions. As the problem specifies that $v$ lies within the span of the columns of $D$, we seek the unique coefficients $c \\in \\mathbb{R}^{K}$ such that $v = \\sum_{k=0}^{K-1} c_k d_k$, or in matrix form, $v = Dc$.\n\nTo find these coefficients, we employ a standard projection formalism. Multiplying by $D^\\top$ from the left yields $D^\\top v = D^\\top D c$. We define the Gram matrix $S = D^\\top D \\in \\mathbb{R}^{K \\times K}$, which encodes the overlaps between the internal coordinate vectors. The system to be solved is the normal equation $Sc = D^\\top v$. The problem statement guarantees that $D$ has full column rank, which ensures that the Gram matrix $S$ is symmetric, positive definite, and therefore invertible. The unique solution for the coefficients is thus $c = S^{-1}(D^\\top v)$. This vector $c$ provides the unique representation of the mode $v$ in the basis of internal coordinates.\n\nWith this decomposition, we can analyze the IR and Raman intensities.\n\n**Infrared (IR) Sensitivity Analysis**\n\nThe IR intensity of a vibrational mode is proportional to the squared change in the molecular dipole moment along that mode's direction. Given the gradient of a dipole moment component with respect to Cartesian coordinates, $g \\in \\mathbb{R}^{M}$, and the mode vector $v$, the directional derivative is given by the scalar product $g \\cdot v$. The intensity is proportional to $(g \\cdot v)^2$.\n\nTo determine the contribution of each internal coordinate, we substitute the decomposition of $v$:\n$$\ng \\cdot v = g \\cdot \\left(\\sum_{k=0}^{K-1} c_k d_k\\right) = \\sum_{k=0}^{K-1} c_k (g \\cdot d_k)\n$$\nThe problem defines the signed contribution of the $k$-th internal coordinate as the $k$-th term of this sum, $t_k = c_k (g \\cdot d_k)$. This term represents the projection of the gradient $g$ onto the component of the mode vector $v$ that corresponds to the internal coordinate $d_k$, scaled by the coefficient $c_k$. The total dipole derivative is the sum of these individual contributions, $\\sum_k t_k$.\n\nThe sensitivity weight for the $k$-th coordinate is defined as $s_k = t_k^2$. This quantity isolates the squared magnitude of each term, neglecting cross-terms $(t_j t_k, j \\neq k)$, to provide a direct measure of that coordinate's importance to the total intensity. The dominant internal coordinate is identified as the one with the maximum sensitivity weight $s_k$.\n\nThe complete algorithm for an IR case is:\n1.  Construct the matrices $D$, $v$, and $g$ from the given data.\n2.  Compute the Gram matrix $S = D^\\top D$.\n3.  Compute the vector $b = D^\\top v$.\n4.  Solve the linear system $Sc = b$ to find the coefficient vector $c$.\n5.  For each internal coordinate index $k = 0, \\ldots, K-1$, calculate the sensitivity weight $s_k = (c_k (g \\cdot d_k))^2$.\n6.  The result is the index $k$ that maximizes $s_k$.\n\n**Raman Sensitivity Analysis**\n\nRaman activity arises from the change in the molecular polarizability tensor $\\alpha$ during a vibration. For a mode $v$, this change is captured by the polarizability derivative tensor $\\alpha' = \\sum_{i=0}^{M-1} v_i A_i$, where $A_i$ is the derivative of the polarizability tensor with respect to the $i$-th Cartesian coordinate.\n\nFor randomly oriented molecules, the Raman activity $S_R$ is proportional to $45a^2 + 7\\gamma^2$, where $a$ is the isotropic invariant and $\\gamma^2$ is the anisotropy invariant of $\\alpha'$. We define the activity function (up to a constant factor) as $S_R(\\alpha') = 45a^2 + 7\\gamma^2$. For a symmetric tensor $\\alpha'$, these invariants are given by $a = \\frac{1}{3}\\operatorname{Tr}(\\alpha')$ and $\\gamma^2 = \\frac{3}{2}\\operatorname{Tr}(\\alpha'^2) - \\frac{1}{2}(\\operatorname{Tr}(\\alpha'))^2$. Substituting these into the activity expression and simplifying yields a more convenient form:\n$$\nS_R(\\alpha') = 1.5 (\\operatorname{Tr}(\\alpha'))^2 + 10.5 \\operatorname{Tr}(\\alpha'^2)\n$$\nThe sensitivity analysis for the Raman case is based on a linearized model. We first compute the gradient of the activity function $S_R$ with respect to the tensor $\\alpha'$, denoted $\\nabla_{\\alpha'} S_R(\\alpha')$. Using standard rules of matrix calculus for symmetric matrices ($\\nabla_X \\operatorname{Tr}(X) = I$ and $\\nabla_X \\operatorname{Tr}(X^2) = 2X$), we obtain the gradient tensor $G$:\n$$\nG = \\nabla_{\\alpha'} S_R(\\alpha') = 1.5 \\cdot (2 \\operatorname{Tr}(\\alpha') I) + 10.5 \\cdot (2\\alpha') = 3 \\operatorname{Tr}(\\alpha') I + 21 \\alpha'\n$$\nNext, we determine the portion of the polarizability derivative tensor $\\alpha'$ that arises from each internal coordinate $k$. Using the decomposition $v = \\sum_k c_k d_k$, we define the resolved tensor contribution:\n$$\n\\alpha'_{(k)} = \\sum_{i=0}^{M-1} (c_k d_{k,i}) A_i\n$$\nwhere $d_{k,i}$ is the $i$-th component of the vector $d_k$. Note that these contributions are additive: $\\sum_k \\alpha'_{(k)} = \\alpha'$.\n\nThe signed linear contribution $L_k$ of coordinate $k$ is defined by projecting its tensor contribution $\\alpha'_{(k)}$ onto the gradient tensor $G$. This corresponds to the first-order term in a Taylor expansion of $S_R$ and is computed using the Frobenius inner product $\\langle X, Y \\rangle = \\sum_{a,b} X_{ab} Y_{ab}$:\n$$\nL_k = \\langle \\alpha'_{(k)}, G \\rangle\n$$\nThe dominant internal coordinate is the one whose absolute contribution $|\\lvert L_k \\rvert|$ is greatest.\n\nThe complete algorithm for a Raman case is:\n1.  Construct $D$, $v$, and the set of tensors $\\{A_i\\}$.\n2.  Calculate the coefficients $c$ by solving $Sc = D^\\top v$, as in the IR case.\n3.  Compute the total polarizability derivative tensor $\\alpha' = \\sum_{i=0}^{M-1} v_i A_i$.\n4.  Compute the gradient tensor $G = 3 \\operatorname{Tr}(\\alpha') I + 21 \\alpha'$.\n5.  For each index $k = 0, \\ldots, K-1$:\n    a. Construct the resolved tensor contribution $\\alpha'_{(k)} = c_k \\sum_{i=0}^{M-1} d_{k,i} A_i$.\n    b. Calculate the sensitivity $L_k = \\langle \\alpha'_{(k)}, G \\rangle$.\n6.  The result is the index $k$ that maximizes $|\\lvert L_k \\rvert|$.\n\nThis principled framework provides a systematic and quantitative method for interpreting complex vibrational modes in terms of chemically intuitive internal coordinates.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef analyze_ir(D, v, g):\n    \"\"\"\n    Performs IR sensitivity analysis for a single vibrational mode.\n\n    Args:\n        D (np.ndarray): Matrix (M x K) of internal coordinate direction vectors.\n        v (np.ndarray): Cartesian normal mode vector (M-dim).\n        g (np.ndarray): Cartesian dipole gradient vector (M-dim).\n\n    Returns:\n        int: The zero-based index of the dominant internal coordinate.\n    \"\"\"\n    M, K = D.shape\n    \n    # Step 1: Solve for internal coordinate coefficients c\n    S = D.T @ D  # Gram matrix S = D^T * D\n    D_T_v = D.T @ v\n    c = np.linalg.solve(S, D_T_v)\n    \n    # Step 2: Calculate sensitivity weights s_k for each coordinate\n    s = np.zeros(K)\n    for k in range(K):\n        d_k = D[:, k]\n        g_dot_d_k = np.dot(g, d_k)\n        t_k = c[k] * g_dot_d_k\n        s[k] = t_k**2\n        \n    # Step 3: Find the index of the maximum sensitivity weight\n    return np.argmax(s)\n\ndef analyze_raman(D, v, A_tensors):\n    \"\"\"\n    Performs Raman sensitivity analysis for a single vibrational mode.\n\n    Args:\n        D (np.ndarray): Matrix (M x K) of internal coordinate direction vectors.\n        v (np.ndarray): Cartesian normal mode vector (M-dim).\n        A_tensors (list of np.ndarray): List of M per-coordinate polarizability\n                                       derivative tensors (3x3).\n\n    Returns:\n        int: The zero-based index of the dominant internal coordinate.\n    \"\"\"\n    M, K = D.shape\n    \n    # Step 1: Solve for internal coordinate coefficients c\n    S = D.T @ D\n    D_T_v = D.T @ v\n    c = np.linalg.solve(S, D_T_v)\n    \n    # Step 2: Compute the total polarizability derivative tensor alpha_prime\n    alpha_prime = np.zeros((3, 3))\n    for i in range(M):\n        alpha_prime += v[i] * A_tensors[i]\n        \n    # Step 3: Compute the gradient tensor G\n    trace_alpha_prime = np.trace(alpha_prime)\n    identity_3x3 = np.eye(3)\n    G = 3 * trace_alpha_prime * identity_3x3 + 21 * alpha_prime\n    \n    # Step 4: Calculate linearized sensitivity L_k for each coordinate\n    L = np.zeros(K)\n    for k in range(K):\n        d_k = D[:, k]\n        \n        # Compute the resolved tensor contribution alpha_prime_(k)\n        alpha_prime_k = np.zeros((3, 3))\n        for i in range(M):\n            alpha_prime_k += d_k[i] * A_tensors[i]\n        alpha_prime_k *= c[k]\n        \n        # Compute the Frobenius inner product alpha_prime_(k), G\n        L[k] = np.sum(alpha_prime_k * G)\n        \n    # Step 5: Find the index of the maximum absolute sensitivity |L_k|\n    return np.argmax(np.abs(L))\n\ndef solve():\n    \"\"\"\n    Processes all test cases and prints the results in the required format.\n    \"\"\"\n    test_cases = [\n        # Case 1: IR, orthonormal\n        {\n            \"type\": \"IR\",\n            \"D\": np.array([\n                [1.0, 0.0, 0.0],\n                [0.0, 1.0, 0.0],\n                [0.0, 0.0, 1.0],\n                [0.0, 0.0, 0.0]\n            ]),\n            \"v\": np.array([1.0/np.sqrt(2), 1.0/np.sqrt(2), 0.0, 0.0]),\n            \"properties\": {\"g\": np.array([2.0, -1.0, 0.5, 3.0])}\n        },\n        # Case 2: IR, non-orthogonal\n        {\n            \"type\": \"IR\",\n            \"D\": np.array([\n                [1.0, 1.0, 0.0],\n                [0.0, 1.0, 1.0],\n                [0.0, 0.0, 1.0]\n            ]),\n            \"v\": np.array([1.0, 2.0, 1.0]),\n            \"properties\": {\"g\": np.array([0.5, -0.2, 0.8])}\n        },\n        # Case 3: Raman, linearized\n        {\n            \"type\": \"Raman\",\n            \"D\": np.array([\n                [1.0, 1.0],\n                [0.0, 1.0]\n            ]),\n            \"v\": np.array([2.0, 1.0]),\n            \"properties\": {\"A_tensors\": [\n                np.array([\n                    [1.0, 0.2, 0.0],\n                    [0.2, 0.5, 0.1],\n                    [0.0, 0.1, 0.3]\n                ]),\n                np.array([\n                    [0.3, 0.0, 0.1],\n                    [0.0, 0.7, 0.2],\n                    [0.1, 0.2, 0.4]\n                ])\n            ]}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        if case[\"type\"] == \"IR\":\n            result = analyze_ir(case[\"D\"], case[\"v\"], case[\"properties\"][\"g\"])\n        elif case[\"type\"] == \"Raman\":\n            result = analyze_raman(case[\"D\"], case[\"v\"], case[\"properties\"][\"A_tensors\"])\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2898215"}, {"introduction": "The ultimate test of a computational model is its comparison with experiment, but raw theoretical outputs—harmonic frequencies and intensities—form a \"stick spectrum\" that differs greatly from a broadened, real-world experimental spectrum. An experimental spectrum often includes baseline distortions and frequency shifts from effects like anharmonicity, which must be accounted for in a meaningful comparison. This comprehensive exercise [@problem_id:2898174] provides a robust protocol to bridge this gap by implementing a fitting procedure for scaling, broadening, and baseline effects, and then using quantitative metrics to validate your theoretical results against experimental data.", "problem": "You are given the task of designing and implementing a protocol to compare computed infrared (IR) intensities with experimental molar absorptivities in a way that is quantitative, reproducible, and algorithmic. The protocol must incorporate scaling of harmonic frequencies, baseline corrections, and well-defined metrics of agreement. Your implementation must be a complete, runnable program that takes no input and instead evaluates a fixed test suite specified below. The program must generate the experimental spectra synthetically according to the rules in this problem statement, and then compute the best-fit parameters and metrics of agreement.\n\nStart from the following fundamental definitions and facts:\n\n- The Beer–Lambert law states that $A(\\tilde{\\nu}) = \\epsilon(\\tilde{\\nu}) \\, c \\, \\ell$, where $A(\\tilde{\\nu})$ is the absorbance, $\\epsilon(\\tilde{\\nu})$ is the molar absorptivity in $\\mathrm{L\\,mol^{-1}\\,cm^{-1}}$, $c$ is the concentration in $\\mathrm{mol\\,L^{-1}}$, $\\ell$ is the path length in $\\mathrm{cm}$, and $\\tilde{\\nu}$ is the wavenumber in $\\mathrm{cm^{-1}}$.\n- Computed harmonic IR spectra are represented as sticks at harmonic wavenumbers $\\{\\tilde{\\nu}_i^{\\mathrm{harm}}\\}$ weighted by line intensities $\\{I_i\\}$ (e.g., in $\\mathrm{km\\,mol^{-1}}$).\n- Experimental spectra contain baseline drift that is well captured, over a limited spectral window, by a linear baseline $b(\\tilde{\\nu}) = \\beta_0 + \\beta_1 \\tilde{\\nu}$.\n- Empirically, harmonic frequencies require a global scale factor $s$ to approximate anharmonic experimental peak positions. Broadening is modeled by convolution with a Gaussian of width (standard deviation) $\\sigma$ in $\\mathrm{cm^{-1}}$.\n- To compare to molar absorptivity, use an unknown proportionality factor $\\alpha$ converting the stick spectrum into the absorptivity scale. This avoids reliance on external calibration constants and remains consistent with the Beer–Lambert law.\n\nMathematically, define the Gaussian kernel\n$$\n\\mathcal{G}(\\Delta; \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{\\Delta^2}{2\\sigma^2}\\right),\n$$\nand the simulated spectrum\n$$\n\\hat{\\epsilon}(\\tilde{\\nu}; s,\\alpha,\\sigma) = \\alpha \\sum_{i} I_i \\, \\mathcal{G}\\!\\left(\\tilde{\\nu} - s \\tilde{\\nu}_i^{\\mathrm{harm}}; \\sigma\\right).\n$$\nOver a grid $\\{\\tilde{\\nu}_k\\}$, the modeled experimental signal is\n$$\ny_{\\mathrm{model}}(\\tilde{\\nu}_k) = \\hat{\\epsilon}(\\tilde{\\nu}_k; s,\\alpha,\\sigma) + \\beta_0 + \\beta_1 \\tilde{\\nu}_k.\n$$\n\nYour program must implement the following protocol, grounded in the definitions above:\n\n1. Given sets $\\{\\tilde{\\nu}_i^{\\mathrm{harm}}\\}$ and $\\{I_i\\}$, a wavenumber grid $\\{\\tilde{\\nu}_k\\}$, and a synthetic experimental spectrum $y_{\\mathrm{exp}}(\\tilde{\\nu}_k)$ (constructed as described in the test suite), compute the best-fit scale factor $s$, amplitude factor $\\alpha$, and baseline parameters $(\\beta_0,\\beta_1)$, together with a chosen Gaussian width $\\sigma$, by minimizing the sum of squared residuals\n$$\n\\Phi(s,\\alpha,\\beta_0,\\beta_1,\\sigma) = \\sum_k \\left[y_{\\mathrm{exp}}(\\tilde{\\nu}_k) - y_{\\mathrm{model}}(\\tilde{\\nu}_k)\\right]^2.\n$$\n2. Treat $s$ as a continuous variable constrained to $s \\in [0.94, 1.02]$. Treat $\\sigma$ as selected from a discrete candidate set $\\{\\sigma_j\\}$. For any fixed $s$ and $\\sigma$, determine $(\\alpha,\\beta_0,\\beta_1)$ by linear least squares using the fact that $y_{\\mathrm{model}}$ is linear in $(\\alpha,\\beta_0,\\beta_1)$.\n3. After obtaining the minimizing $(\\hat{s},\\hat{\\sigma},\\hat{\\alpha},\\hat{\\beta}_0,\\hat{\\beta}_1)$, compute these quantitative metrics:\n   - The Pearson correlation coefficient $r$ between the baseline-corrected experimental spectrum $\\tilde{y}(\\tilde{\\nu}_k) = y_{\\mathrm{exp}}(\\tilde{\\nu}_k) - \\hat{\\beta}_0 - \\hat{\\beta}_1 \\tilde{\\nu}_k$ and the simulated absorptivity $\\hat{\\epsilon}(\\tilde{\\nu}_k; \\hat{s},\\hat{\\alpha},\\hat{\\sigma})$.\n   - The root-mean-square deviation (RMSD) of peak positions in $\\mathrm{cm^{-1}}$ after assignment by nearest-neighbor matching with a tolerance $\\Delta$ defined below. Define predicted peak positions as $\\{\\hat{s}\\,\\tilde{\\nu}_i^{\\mathrm{harm}}\\}$. Detect experimental peaks as the local maxima of $\\tilde{y}(\\tilde{\\nu}_k)$. Assign each predicted peak to the nearest experimental peak within tolerance $\\Delta$ and compute\n     $$\n     \\mathrm{RMSD} = \\sqrt{\\frac{1}{N_{\\mathrm{match}}}\\sum_{m=1}^{N_{\\mathrm{match}}} \\left(\\tilde{\\nu}^{\\mathrm{(pred)}}_m - \\tilde{\\nu}^{\\mathrm{(exp)}}_m\\right)^2}.\n     $$\n     If $N_{\\mathrm{match}}=0$, report a sentinel value of $9999.0$ for RMSD.\n   - The normalized $\\ell_2$ error\n     $$\n     E_{\\mathrm{norm}} = \\frac{\\left\\|\\tilde{y} - \\hat{\\epsilon}(\\cdot; \\hat{s},\\hat{\\alpha},\\hat{\\sigma})\\right\\|_2}{\\left\\|\\tilde{y}\\right\\|_2}.\n     $$\n4. Define a pass/fail diagnostic as follows: return a pass indicator if $r \\ge 0.95$, $\\mathrm{RMSD} \\le 12$ (in $\\mathrm{cm^{-1}}$), and $E_{\\mathrm{norm}} \\le 0.5$. Otherwise return a fail indicator.\n\nYour program must implement robust local-maximum detection for experimental peaks as follows: a grid-point $\\tilde{\\nu}_k$ is a peak if $\\tilde{y}(\\tilde{\\nu}_{k-1})  \\tilde{y}(\\tilde{\\nu}_k)$ and $\\tilde{y}(\\tilde{\\nu}_k)  \\tilde{y}(\\tilde{\\nu}_{k+1})$ and $\\tilde{y}(\\tilde{\\nu}_k)$ exceeds a prominence threshold given by $0.1 \\times \\max_k \\tilde{y}(\\tilde{\\nu}_k)$. Use a nearest-neighbor greedy matching within tolerance $\\Delta = 20\\,\\mathrm{cm^{-1}}$.\n\nTest suite specification. For each test case, you are given harmonic frequencies in $\\mathrm{cm^{-1}}$, intensities in $\\mathrm{km\\,mol^{-1}}$, a wavenumber grid in $\\mathrm{cm^{-1}}$, and the procedure to synthesize the experimental spectrum:\n- Compute the noise-free experimental signal $y_0(\\tilde{\\nu}_k) = \\alpha_{\\mathrm{true}}\\sum_i I_i \\,\\mathcal{G}(\\tilde{\\nu}_k - s_{\\mathrm{true}} \\tilde{\\nu}_i^{\\mathrm{harm}};\\sigma_{\\mathrm{true}}) + \\beta_{0,\\mathrm{true}} + \\beta_{1,\\mathrm{true}} \\tilde{\\nu}_k$.\n- Add independent Gaussian noise of zero mean and standard deviation $\\eta_{\\mathrm{true}}$ to each grid point to obtain $y_{\\mathrm{exp}}$.\n- Use a fixed random number generator seed for reproducibility as specified below.\n\nUse the discrete candidate set of Gaussian widths $\\{\\sigma\\} = \\{5, 8, 10, 12, 15\\}$ in $\\mathrm{cm^{-1}}$. Constrain $s \\in [0.94, 1.02]$. Use the peak matching tolerance $\\Delta = 20$ in $\\mathrm{cm^{-1}}$.\n\nProvide four test cases:\n\n- Case $1$:\n  - Harmonic frequencies $\\{\\tilde{\\nu}_i^{\\mathrm{harm}}\\} = \\{1100, 1450, 1750, 2950\\}$.\n  - Intensities $\\{I_i\\} = \\{120, 80, 150, 60\\}$.\n  - Grid $\\tilde{\\nu}_k$ from $800$ to $3200$ in steps of $2$ $\\mathrm{cm^{-1}}$.\n  - Synthesis parameters: $s_{\\mathrm{true}} = 0.965$, $\\sigma_{\\mathrm{true}} = 10$, $\\alpha_{\\mathrm{true}} = 1.8\\times 10^{-3}$, $\\beta_{0,\\mathrm{true}} = 0.5$, $\\beta_{1,\\mathrm{true}} = -5\\times 10^{-4}$, $\\eta_{\\mathrm{true}} = 0.03$, random seed $12345$.\n\n- Case $2$:\n  - Harmonic frequencies $\\{\\tilde{\\nu}_i^{\\mathrm{harm}}\\} = \\{1000, 1012, 1600, 1615, 3050\\}$.\n  - Intensities $\\{I_i\\} = \\{60, 55, 90, 85, 40\\}$.\n  - Grid $\\tilde{\\nu}_k$ from $900$ to $3300$ in steps of $2$ $\\mathrm{cm^{-1}}$.\n  - Synthesis parameters: $s_{\\mathrm{true}} = 0.98$, $\\sigma_{\\mathrm{true}} = 15$, $\\alpha_{\\mathrm{true}} = 2.0\\times 10^{-3}$, $\\beta_{0,\\mathrm{true}} = 0.2$, $\\beta_{1,\\mathrm{true}} = 3\\times 10^{-4}$, $\\eta_{\\mathrm{true}} = 0.02$, random seed $67890$.\n\n- Case $3$:\n  - Harmonic frequencies $\\{\\tilde{\\nu}_i^{\\mathrm{harm}}\\} = \\{2100\\}$.\n  - Intensities $\\{I_i\\} = \\{200\\}$.\n  - Grid $\\tilde{\\nu}_k$ from $1800$ to $2400$ in steps of $1$ $\\mathrm{cm^{-1}}$.\n  - Synthesis parameters: $s_{\\mathrm{true}} = 1.0$, $\\sigma_{\\mathrm{true}} = 5$, $\\alpha_{\\mathrm{true}} = 1.5\\times 10^{-3}$, $\\beta_{0,\\mathrm{true}} = 0.0$, $\\beta_{1,\\mathrm{true}} = 0.0$, $\\eta_{\\mathrm{true}} = 0.01$, random seed $13579$.\n\n- Case $4$:\n  - Harmonic frequencies $\\{\\tilde{\\nu}_i^{\\mathrm{harm}}\\} = \\{900, 1200, 1500, 1800, 2100, 2400, 2700, 3000\\}$.\n  - Intensities $\\{I_i\\} = \\{30, 50, 45, 70, 65, 40, 55, 35\\}$.\n  - Grid $\\tilde{\\nu}_k$ from $800$ to $3200$ in steps of $4$ $\\mathrm{cm^{-1}}$.\n  - Synthesis parameters: $s_{\\mathrm{true}} = 0.97$, $\\sigma_{\\mathrm{true}} = 12$, $\\alpha_{\\mathrm{true}} = 1.2\\times 10^{-3}$, $\\beta_{0,\\mathrm{true}} = 0.0$, $\\beta_{1,\\mathrm{true}} = 1\\times 10^{-3}$, $\\eta_{\\mathrm{true}} = 0.05$, random seed $24680$.\n\nAngle units are not applicable. Physical units: wavenumbers must be in $\\mathrm{cm^{-1}}$, molar absorptivities must be in $\\mathrm{L\\,mol^{-1}\\,cm^{-1}}$. The RMSD must be expressed in $\\mathrm{cm^{-1}}$. The correlation coefficient and normalized error are dimensionless.\n\nOutput specification. For each case, return a list with five entries: the estimated scale factor $\\hat{s}$ rounded to $5$ decimals, the Pearson correlation $r$ rounded to $4$ decimals, the RMSD (in $\\mathrm{cm^{-1}}$) rounded to $2$ decimals, the normalized error $E_{\\mathrm{norm}}$ rounded to $3$ decimals, and a pass/fail indicator as an integer in $\\{0,1\\}$ (with $1$ meaning pass). Your program should produce a single line of output containing the results for all four test cases as a comma-separated list of these per-case lists, enclosed in square brackets. For example: $[[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot]]$.", "solution": "The problem presented, upon rigorous examination, is determined to be valid. It is scientifically grounded in the principles of vibrational spectroscopy and numerical analysis, well-posed with a clear objective function and constraints, and formulated with objective, unambiguous language. It outlines a complete and formal protocol for the quantitative comparison of computed and experimental infrared spectra. We shall proceed with the derivation of the solution.\n\nThe core of the problem is to find a set of parameters $(s, \\sigma, \\alpha, \\beta_0, \\beta_1)$ that minimizes the sum of squared residuals between a modeled spectrum and a synthetic experimental spectrum. The objective function is given by\n$$\n\\Phi(s, \\alpha, \\beta_0, \\beta_1, \\sigma) = \\sum_k \\left[y_{\\mathrm{exp}}(\\tilde{\\nu}_k) - y_{\\mathrm{model}}(\\tilde{\\nu}_k)\\right]^2,\n$$\nwhere the model is\n$$\ny_{\\mathrm{model}}(\\tilde{\\nu}_k) = \\alpha \\left( \\sum_{i} I_i \\, \\mathcal{G}\\!\\left(\\tilde{\\nu}_k - s \\tilde{\\nu}_i^{\\mathrm{harm}}; \\sigma\\right) \\right) + \\beta_0 + \\beta_1 \\tilde{\\nu}_k.\n$$\nHere, $\\mathcal{G}$ is the Gaussian kernel, $\\{\\tilde{\\nu}_k\\}$ is the wavenumber grid, $\\{\\tilde{\\nu}_i^{\\mathrm{harm}}\\}$ are the harmonic frequencies, and $\\{I_i\\}$ are the corresponding intensities.\n\nThe optimization problem exhibits a structure that permits a separation of parameters. For any fixed pair of non-linear parameters, the frequency scaling factor $s$ and the broadening width $\\sigma$, the model $y_{\\mathrm{model}}$ is linear with respect to the remaining parameters: the amplitude factor $\\alpha$, and the baseline coefficients $\\beta_0$ and $\\beta_1$. This structure suggests a nested optimization strategy.\n\nFirst, let us define the unscaled, broadened theoretical lineshape as\n$$\nS(\\tilde{\\nu}_k; s, \\sigma) = \\sum_{i} I_i \\, \\mathcal{G}\\!\\left(\\tilde{\\nu}_k - s \\tilde{\\nu}_i^{\\mathrm{harm}}; \\sigma\\right).\n$$\nThe model can then be rewritten as\n$$\ny_{\\mathrm{model}}(\\tilde{\\nu}_k) = \\alpha S(\\tilde{\\nu}_k; s, \\sigma) + \\beta_0 \\cdot 1 + \\beta_1 \\tilde{\\nu}_k.\n$$\nFor a fixed $(s, \\sigma)$, finding the optimal $(\\alpha, \\beta_0, \\beta_1)$ is a standard linear least-squares problem. We seek to find the parameter vector $\\mathbf{b} = [\\alpha, \\beta_0, \\beta_1]^T$ that minimizes $\\|\\mathbf{y}_{\\mathrm{exp}} - \\mathbf{X}\\mathbf{b}\\|_2^2$. The design matrix $\\mathbf{X}$ is constructed with its columns being the basis functions evaluated on the grid $\\{\\tilde{\\nu}_k\\}$:\n$$\n\\mathbf{X} = \n\\begin{bmatrix}\nS(\\tilde{\\nu}_1; s, \\sigma)  1  \\tilde{\\nu}_1 \\\\\nS(\\tilde{\\nu}_2; s, \\sigma)  1  \\tilde{\\nu}_2 \\\\\n\\vdots  \\vdots  \\vdots \\\\\nS(\\tilde{\\nu}_N; s, \\sigma)  1  \\tilde{\\nu}_N\n\\end{bmatrix}.\n$$\nThe solution to this linear system is given by $\\hat{\\mathbf{b}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}_{\\mathrm{exp}}$. This is solved numerically for stability, for instance, via QR decomposition or Singular Value Decomposition as implemented in standard linear algebra libraries.\n\nWith this inner optimization solved, the problem reduces to finding the optimal non-linear parameters $(s, \\sigma)$ that minimize the resulting sum of squared residuals. The parameter $\\sigma$ is chosen from a discrete set of candidates $\\{\\sigma_j\\} = \\{5, 8, 10, 12, 15\\}\\,\\mathrm{cm^{-1}}$. The parameter $s$ is a continuous variable in the interval $[0.94, 1.02]$. The overall optimization procedure is as follows:\n$1$. For each candidate width $\\sigma_j$ from the discrete set:\n    a. Define an objective function $f(s) = \\Phi(s, \\hat{\\alpha}(s, \\sigma_j), \\hat{\\beta}_0(s, \\sigma_j), \\hat{\\beta}_1(s, \\sigma_j), \\sigma_j)$, where the hat denotes parameters found by the inner linear least-squares fit for a given $s$ and $\\sigma_j$.\n    b. Find the optimal scaling factor $s_j^*$ by minimizing $f(s)$ over the bounded interval $s \\in [0.94, 1.02]$. This is a one-dimensional numerical optimization problem.\n    c. Record the minimum residual achieved, $\\Phi_j^* = f(s_j^*)$.\n$2$. After iterating through all $\\sigma_j$, identify the global optimum $(\\hat{s}, \\hat{\\sigma})$ corresponding to the minimum value among all $\\{\\Phi_j^*\\}$.\n\nOnce the globally optimal parameters $(\\hat{s}, \\hat{\\sigma}, \\hat{\\alpha}, \\hat{\\beta}_0, \\hat{\\beta}_1)$ are determined, the final step is to compute the specified quality metrics.\n- The baseline-corrected experimental spectrum is defined as $\\tilde{y}(\\tilde{\\nu}_k) = y_{\\mathrm{exp}}(\\tilde{\\nu}_k) - (\\hat{\\beta}_0 + \\hat{\\beta}_1 \\tilde{\\nu}_k)$.\n- The final simulated absorptivity spectrum is $\\hat{\\epsilon}(\\tilde{\\nu}_k) = \\hat{\\alpha} S(\\tilde{\\nu}_k; \\hat{s}, \\hat{\\sigma})$.\n- The Pearson correlation coefficient $r$ is computed between the vectors $\\tilde{\\mathbf{y}}$ and $\\hat{\\mathbf{\\epsilon}}$.\n- The normalized $\\ell_2$ error is $E_{\\mathrm{norm}} = \\|\\tilde{\\mathbf{y}} - \\hat{\\mathbf{\\epsilon}}\\|_2 / \\|\\tilde{\\mathbf{y}}\\|_2$.\n- The root-mean-square deviation (RMSD) of peak positions requires peak identification and matching.\n    - Experimental peaks are identified as local maxima in $\\tilde{y}(\\tilde{\\nu}_k)$ that satisfy $\\tilde{y}(\\tilde{\\nu}_{k-1})  \\tilde{y}(\\tilde{\\nu}_k)  \\tilde{y}(\\tilde{\\nu}_{k+1})$ and exceed a prominence threshold of $0.1 \\times \\max_k \\tilde{y}(\\tilde{\\nu}_k)$.\n    - Predicted peaks are given by $\\{\\hat{s}\\,\\tilde{\\nu}_i^{\\mathrm{harm}}\\}$.\n    - A greedy matching algorithm is employed: for each predicted peak, the nearest unmatched experimental peak is found. If the distance is within the tolerance $\\Delta = 20\\,\\mathrm{cm^{-1}}$, the pair is considered a match, and the experimental peak is removed from the pool for subsequent matching.\n    - The RMSD is calculated over the $N_{\\mathrm{match}}$ matched pairs. If $N_{\\mathrm{match}} = 0$, a sentinel value of $9999.0$ is used.\nFinally, a diagnostic flag is set to $1$ (pass) if $r \\ge 0.95$, $\\mathrm{RMSD} \\le 12\\,\\mathrm{cm^{-1}}$, and $E_{\\mathrm{norm}} \\le 0.5$; otherwise, it is set to $0$ (fail).\n\nThis comprehensive protocol is implemented for each test case provided. The synthetic nature of the test data, with specified true parameters and a fixed random seed for noise generation, ensures the reproducibility of the entire procedure.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test suite for comparing theoretical\n    and experimental infrared spectra.\n    \"\"\"\n    \n    # Test cases as defined in the problem statement.\n    test_cases = [\n        {\n            \"nu_harm\": np.array([1100, 1450, 1750, 2950]),\n            \"I\": np.array([120, 80, 150, 60]),\n            \"grid_params\": (800, 3200, 2),\n            \"synth_params\": {\n                \"s_true\": 0.965, \"sigma_true\": 10, \"alpha_true\": 1.8e-3,\n                \"beta0_true\": 0.5, \"beta1_true\": -5e-4, \"eta_true\": 0.03,\n                \"seed\": 12345\n            }\n        },\n        {\n            \"nu_harm\": np.array([1000, 1012, 1600, 1615, 3050]),\n            \"I\": np.array([60, 55, 90, 85, 40]),\n            \"grid_params\": (900, 3300, 2),\n            \"synth_params\": {\n                \"s_true\": 0.98, \"sigma_true\": 15, \"alpha_true\": 2.0e-3,\n                \"beta0_true\": 0.2, \"beta1_true\": 3e-4, \"eta_true\": 0.02,\n                \"seed\": 67890\n            }\n        },\n        {\n            \"nu_harm\": np.array([2100]),\n            \"I\": np.array([200]),\n            \"grid_params\": (1800, 2400, 1),\n            \"synth_params\": {\n                \"s_true\": 1.0, \"sigma_true\": 5, \"alpha_true\": 1.5e-3,\n                \"beta0_true\": 0.0, \"beta1_true\": 0.0, \"eta_true\": 0.01,\n                \"seed\": 13579\n            }\n        },\n        {\n            \"nu_harm\": np.array([900, 1200, 1500, 1800, 2100, 2400, 2700, 3000]),\n            \"I\": np.array([30, 50, 45, 70, 65, 40, 55, 35]),\n            \"grid_params\": (800, 3200, 4),\n            \"synth_params\": {\n                \"s_true\": 0.97, \"sigma_true\": 12, \"alpha_true\": 1.2e-3,\n                \"beta0_true\": 0.0, \"beta1_true\": 1e-3, \"eta_true\": 0.05,\n                \"seed\": 24680\n            }\n        }\n    ]\n\n    s_bounds = (0.94, 1.02)\n    sigma_candidates = [5, 8, 10, 12, 15]\n    match_tolerance = 20.0\n\n    all_results = []\n    for case in test_cases:\n        # 1. Generate synthetic experimental spectrum\n        nu_grid = np.arange(case[\"grid_params\"][0], case[\"grid_params\"][1] + case[\"grid_params\"][2], case[\"grid_params\"][2])\n        sp = case[\"synth_params\"]\n        \n        # Noise-free spectrum\n        y0_shape = calculate_simulated_shape(nu_grid, case[\"nu_harm\"], case[\"I\"], sp[\"s_true\"], sp[\"sigma_true\"])\n        y0 = sp[\"alpha_true\"] * y0_shape + sp[\"beta0_true\"] + sp[\"beta1_true\"] * nu_grid\n        \n        # Add noise\n        rng = np.random.default_rng(sp[\"seed\"])\n        noise = rng.normal(0, sp[\"eta_true\"], size=nu_grid.shape)\n        y_exp = y0 + noise\n        \n        # 2. Find best fit parameters\n        best_fit = find_best_fit(nu_grid, y_exp, case[\"nu_harm\"], case[\"I\"], s_bounds, sigma_candidates)\n        \n        # 3. Calculate metrics\n        metrics = calculate_metrics(nu_grid, y_exp, case[\"nu_harm\"], case[\"I\"], best_fit, match_tolerance)\n        all_results.append(metrics)\n\n    # Final formatting\n    result_str_list = []\n    for res in all_results:\n        s_hat, r, rmsd, e_norm, flag = res\n        s_str = f\"{s_hat:.5f}\"\n        r_str = f\"{r:.4f}\"\n        rmsd_str = f\"{rmsd:.2f}\"\n        enorm_str = f\"{e_norm:.3f}\"\n        flag_str = str(flag)\n        result_str_list.append(f\"[{s_str},{r_str},{rmsd_str},{enorm_str},{flag_str}]\")\n    \n    print(f\"[{','.join(result_str_list)}]\")\n\ndef gaussian(delta, sigma):\n    \"\"\"Computes the Gaussian kernel.\"\"\"\n    return (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * (delta / sigma)**2)\n\ndef calculate_simulated_shape(nu_grid, nu_harm, I, s, sigma):\n    \"\"\"Calculates the unscaled, broadened theoretical spectrum S(nu).\"\"\"\n    shape = np.zeros_like(nu_grid, dtype=float)\n    for nu_i, I_i in zip(nu_harm, I):\n        delta = nu_grid - s * nu_i\n        shape += I_i * gaussian(delta, sigma)\n    return shape\n\ndef find_best_fit(nu_grid, y_exp, nu_harm, I, s_bounds, sigma_candidates):\n    \"\"\"\n    Finds the optimal (s, sigma, alpha, beta0, beta1) by nested optimization.\n    \"\"\"\n    best_s = None\n    best_sigma = None\n    min_residual = np.inf\n\n    def objective_for_s(s, sigma_val):\n        # Calculate theoretical shape S(nu) for given s and sigma\n        sim_shape = calculate_simulated_shape(nu_grid, nu_harm, I, s, sigma_val)\n        \n        # Set up design matrix for linear least squares\n        X = np.vstack([sim_shape, np.ones_like(nu_grid), nu_grid]).T\n        \n        # Solve for linear parameters (alpha, beta0, beta1)\n        params, residuals, _, _ = np.linalg.lstsq(X, y_exp, rcond=None)\n        \n        return residuals[0]\n\n    for sigma in sigma_candidates:\n        res = minimize_scalar(objective_for_s, bounds=s_bounds, method='bounded', args=(sigma,))\n        if res.fun  min_residual:\n            min_residual = res.fun\n            best_s = res.x\n            best_sigma = sigma\n\n    # Re-calculate final optimal linear parameters with best s and sigma\n    final_sim_shape = calculate_simulated_shape(nu_grid, nu_harm, I, best_s, best_sigma)\n    X = np.vstack([final_sim_shape, np.ones_like(nu_grid), nu_grid]).T\n    final_params = np.linalg.lstsq(X, y_exp, rcond=None)[0]\n    \n    best_alpha, best_beta0, best_beta1 = final_params\n    \n    return {\n        \"s\": best_s, \"sigma\": best_sigma, \"alpha\": best_alpha,\n        \"beta0\": best_beta0, \"beta1\": best_beta1\n    }\n\ndef calculate_metrics(nu_grid, y_exp, nu_harm, I, fit_params, match_tolerance):\n    \"\"\"\n    Calculates Pearson r, RMSD, E_norm, and the pass/fail flag.\n    \"\"\"\n    s, sigma, alpha, b0, b1 = fit_params[\"s\"], fit_params[\"sigma\"], fit_params[\"alpha\"], fit_params[\"beta0\"], fit_params[\"beta1\"]\n\n    # Baseline-corrected experimental spectrum\n    y_corrected = y_exp - (b0 + b1 * nu_grid)\n    \n    # Final simulated absorptivity\n    epsilon_sim_shape = calculate_simulated_shape(nu_grid, nu_harm, I, s, sigma)\n    epsilon_sim = alpha * epsilon_sim_shape\n\n    # Pearson correlation coefficient\n    r = np.corrcoef(y_corrected, epsilon_sim)[0, 1]\n\n    # Normalized l2 error\n    norm_diff = np.linalg.norm(y_corrected - epsilon_sim)\n    norm_y = np.linalg.norm(y_corrected)\n    e_norm = norm_diff / norm_y if norm_y  0 else 0.0\n\n    # RMSD of peak positions\n    # 1. Find experimental peaks\n    prominence_threshold = 0.1 * np.max(y_corrected)\n    exp_peaks_idx = []\n    for k in range(1, len(y_corrected) - 1):\n        if y_corrected[k]  y_corrected[k-1] and y_corrected[k]  y_corrected[k+1]:\n            if y_corrected[k]  prominence_threshold:\n                exp_peaks_idx.append(k)\n    exp_peaks = [nu_grid[i] for i in exp_peaks_idx]\n\n    # 2. Predicted peaks\n    pred_peaks = s * nu_harm\n    \n    # 3. Greedy nearest-neighbor matching\n    matched_pairs = []\n    unmatched_exp_peaks = list(exp_peaks)\n    \n    for p_peak in sorted(pred_peaks):\n        if not unmatched_exp_peaks:\n            break\n        distances = [abs(p_peak - e_peak) for e_peak in unmatched_exp_peaks]\n        min_dist_idx = np.argmin(distances)\n        min_dist = distances[min_dist_idx]\n        \n        if min_dist = match_tolerance:\n            best_match_exp_peak = unmatched_exp_peaks[min_dist_idx]\n            matched_pairs.append((p_peak, best_match_exp_peak))\n            unmatched_exp_peaks.pop(min_dist_idx)\n    \n    # 4. Calculate RMSD\n    if not matched_pairs:\n        rmsd = 9999.0\n    else:\n        sum_sq_err = sum([(p - e)**2 for p, e in matched_pairs])\n        rmsd = np.sqrt(sum_sq_err / len(matched_pairs))\n\n    # Pass/Fail diagnostic\n    pass_flag = 1 if (r = 0.95 and rmsd = 12.0 and e_norm = 0.5) else 0\n\n    return s, r, rmsd, e_norm, pass_flag\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2898174"}]}