{"hands_on_practices": [{"introduction": "A cornerstone of the bra-ket formalism is the sesquilinear nature of the inner product, which is conjugate-linear in the bra and linear in the ket. This exercise serves as a critical hands-on demonstration of this property, contrasting the physically correct energy expectation value with a spurious result obtained by incorrectly neglecting complex conjugation [@problem_id:2896475]. Successfully completing this calculation will solidify your understanding of why matrix representations of expectation values must use the conjugate transpose ($c^\\dagger H c$), a rule fundamental to all of quantum mechanics.", "problem": "In a complex Hilbert space relevant to quantum chemistry, the inner product is conjugate-linear (antilinear) in its first argument and linear in its second. Consider a one-electron state in the two-dimensional subspace spanned by two real atomic orbitals $\\{\\,|\\chi_{1}\\rangle,|\\chi_{2}\\rangle\\,\\}$ that are not orthonormal. The overlap matrix elements are $S_{ij}=\\langle \\chi_{i}|\\chi_{j}\\rangle$ and the Hamiltonian matrix elements are $H_{ij}=\\langle \\chi_{i}|\\hat{H}|\\chi_{j}\\rangle$, with\n$$\nS=\\begin{pmatrix}1  0.2\\\\ 0.2  1\\end{pmatrix},\\qquad\nH=\\begin{pmatrix}-1.0  -0.1\\\\ -0.1  -0.8\\end{pmatrix},\n$$\nin Hartree units. A trial state is prepared as $|\\psi\\rangle=c_{1}|\\chi_{1}\\rangle+c_{2}|\\chi_{2}\\rangle$ with complex coefficients $c_{1}=1+i$ and $c_{2}=2-i$.\n\nA common but incorrect manipulation replaces bras by transposes rather than conjugate transposes, effectively treating the sesquilinear form as bilinear and thus dropping complex conjugation. This leads to a spurious “energy” computed as the Rayleigh quotient with transposes,\n$$\nE_{\\mathrm{wrong}}=\\frac{c^{T}H\\,c}{c^{T}S\\,c},\n$$\nwhere $c=\\begin{pmatrix}c_{1}\\\\ c_{2}\\end{pmatrix}$. In contrast, the physically meaningful expectation value must use the conjugate transpose,\n$$\nE=\\frac{\\langle \\psi|\\hat{H}|\\psi\\rangle}{\\langle \\psi|\\psi\\rangle}.\n$$\n\nStarting only from the definitions of the inner product and its antilinearity, and the meaning of matrix elements as $\\langle \\chi_{i}|\\chi_{j}\\rangle$ and $\\langle \\chi_{i}|\\hat{H}|\\chi_{j}\\rangle$, do the following:\n1. Show explicitly how the antilinearity leads to $\\langle \\psi|\\phi\\rangle=c^{\\dagger}S\\,d$ for $|\\psi\\rangle=\\sum_{i}c_{i}|\\chi_{i}\\rangle$ and $|\\phi\\rangle=\\sum_{j}d_{j}|\\chi_{j}\\rangle$, and hence why $E=(c^{\\dagger}H\\,c)/(c^{\\dagger}S\\,c)$.\n2. Evaluate $E_{\\mathrm{wrong}}$ to demonstrate the error that arises from dropping conjugation.\n3. Compute the correct normalized energy $E$ by properly tracking complex conjugation throughout.\n\nProvide the final energy as an exact rational number in Hartree (do not round and do not convert to decimal). Your final answer should be the single exact rational number only (no units) corresponding to the correct $E$.", "solution": "The problem presented is a standard exercise in quantum chemistry that emphasizes the mathematical foundations of quantum mechanics, specifically the properties of the inner product in a complex Hilbert space. It is scientifically sound, well-posed, and objective. We shall proceed with the solution as requested.\n\nThe state of the system is given by the ket $|\\psi\\rangle = c_1|\\chi_1\\rangle + c_2|\\chi_2\\rangle = \\sum_{i=1}^{2} c_i|\\chi_i\\rangle$, where the basis kets $\\{|\\chi_1\\rangle, |\\chi_2\\rangle\\}$ are non-orthogonal real atomic orbitals and the coefficients $\\{c_1, c_2\\}$ are complex numbers.\n\nFirst, we address the derivation of the matrix expression for the energy expectation value. The inner product in a complex Hilbert space, denoted $\\langle \\phi | \\psi \\rangle$, is sesquilinear. This means it is conjugate-linear (antilinear) in its first argument (the bra) and linear in its second argument (the ket). Let us consider two arbitrary states $|\\psi\\rangle = \\sum_i c_i |\\chi_i\\rangle$ and $|\\phi\\rangle = \\sum_j d_j |\\chi_j\\rangle$. To form the bra $\\langle\\psi|$, we take the Hermitian adjoint of the ket $|\\psi\\rangle$. Due to the conjugate-linearity of this operation, we have:\n$$\n\\langle\\psi| = \\left(\\sum_i c_i |\\chi_i\\rangle\\right)^\\dagger = \\sum_i c_i^* \\langle\\chi_i|\n$$\nwhere $c_i^*$ is the complex conjugate of $c_i$. The inner product $\\langle\\psi|\\phi\\rangle$ is then calculated by applying this bra to the ket $|\\phi\\rangle$. Using linearity in the second argument:\n$$\n\\langle\\psi|\\phi\\rangle = \\left(\\sum_i c_i^* \\langle\\chi_i|\\right) \\left(\\sum_j d_j |\\chi_j\\rangle\\right) = \\sum_i \\sum_j c_i^* d_j \\langle\\chi_i|\\chi_j\\rangle\n$$\nThe overlap matrix elements are defined as $S_{ij} = \\langle\\chi_i|\\chi_j\\rangle$. Substituting this definition gives:\n$$\n\\langle\\psi|\\phi\\rangle = \\sum_i \\sum_j c_i^* S_{ij} d_j\n$$\nThis expression is the definition of a matrix product. If we define column vectors $c$ and $d$ with components $c_i$ and $d_j$, respectively, and a matrix $S$ with elements $S_{ij}$, the expression becomes:\n$$\n\\langle\\psi|\\phi\\rangle = c^\\dagger S d\n$$\nwhere $c^\\dagger$ is the conjugate transpose (Hermitian conjugate) of $c$.\n\nThe physically meaningful energy $E$ is the expectation value of the Hamiltonian operator $\\hat{H}$, given by the Rayleigh quotient:\n$$\nE = \\frac{\\langle\\psi|\\hat{H}|\\psi\\rangle}{\\langle\\psi|\\psi\\rangle}\n$$\nThe denominator is the squared norm of the state, $\\langle\\psi|\\psi\\rangle$. Using our derived formula with $|\\phi\\rangle = |\\psi\\rangle$ (i.e., $d=c$), we get:\n$$\n\\langle\\psi|\\psi\\rangle = c^\\dagger S c\n$$\nFor the numerator, we consider the ket $\\hat{H}|\\psi\\rangle$. Since $\\hat{H}$ is a linear operator:\n$$\n\\hat{H}|\\psi\\rangle = \\hat{H}\\left(\\sum_j c_j |\\chi_j\\rangle\\right) = \\sum_j c_j (\\hat{H}|\\chi_j\\rangle)\n$$\nThen the inner product $\\langle\\psi|\\hat{H}|\\psi\\rangle$ is:\n$$\n\\langle\\psi|\\hat{H}|\\psi\\rangle = \\left(\\sum_i c_i^* \\langle\\chi_i|\\right) \\left(\\sum_j c_j (\\hat{H}|\\chi_j\\rangle)\\right) = \\sum_i \\sum_j c_i^* c_j \\langle\\chi_i|\\hat{H}|\\chi_j\\rangle\n$$\nThe Hamiltonian matrix elements are defined as $H_{ij} = \\langle\\chi_i|\\hat{H}|\\chi_j\\rangle$. Substituting this definition, we obtain:\n$$\n\\langle\\psi|\\hat{H}|\\psi\\rangle = \\sum_i \\sum_j c_i^* H_{ij} c_j = c^\\dagger H c\n$$\nCombining the numerator and denominator gives the correct matrix expression for the energy:\n$$\nE = \\frac{c^\\dagger H c}{c^\\dagger S c}\n$$\nThis completes the first part of the problem.\n\nNext, we evaluate the spurious \"energy\" $E_{\\mathrm{wrong}} = \\frac{c^T H c}{c^T S c}$, which incorrectly uses the transpose $c^T$ instead of the conjugate transpose $c^\\dagger$. The given coefficients are $c_1 = 1+i$ and $c_2 = 2-i$. The matrices are, in fractional form:\n$$\nS=\\begin{pmatrix}1  1/5\\\\ 1/5  1\\end{pmatrix},\\qquad\nH=\\begin{pmatrix}-1  -1/10\\\\ -1/10  -4/5\\end{pmatrix}\n$$\nWe calculate the quadratic form $c^T M c = \\sum_{i,j} c_i M_{ij} c_j = M_{11}c_1^2 + M_{22}c_2^2 + (M_{12}+M_{21})c_1c_2$.\nFirst, we find $c_1^2 = (1+i)^2 = 1^2 + 2i + i^2 = 2i$, $c_2^2 = (2-i)^2 = 4 - 4i + i^2 = 3-4i$, and $c_1c_2 = (1+i)(2-i) = 2-i+2i-i^2 = 3+i$.\nFor the denominator $c^T S c$:\n$$\nc^T S c = S_{11}c_1^2 + S_{22}c_2^2 + 2S_{12}c_1c_2 = (1)(2i) + (1)(3-4i) + 2(1/5)(3+i)\n$$\n$$\nc^T S c = 2i + 3 - 4i + 6/5 + 2i/5 = (3 + 6/5) + (2 - 4 + 2/5)i = \\frac{21}{5} - \\frac{8}{5}i\n$$\nFor the numerator $c^T H c$:\n$$\nc^T H c = H_{11}c_1^2 + H_{22}c_2^2 + 2H_{12}c_1c_2 = (-1)(2i) + (-4/5)(3-4i) + 2(-1/10)(3+i)\n$$\n$$\nc^T H c = -2i - 12/5 + 16i/5 - 3/5 - i/5 = (-12/5 - 3/5) + (-2 + 16/5 - 1/5)i = -3 + (\\frac{-10+16-1}{5})i = -3+i\n$$\nThus, the spurious energy is:\n$$\nE_{\\mathrm{wrong}} = \\frac{-3+i}{(21/5) - (8/5)i} = \\frac{5(-3+i)}{21-8i} = \\frac{5(-3+i)(21+8i)}{(21-8i)(21+8i)} = \\frac{5(-63-24i+21i-8)}{21^2+8^2} = \\frac{5(-71-3i)}{441+64} = \\frac{-355-15i}{505} = -\\frac{71}{101} - \\frac{3}{101}i\n$$\nThe result is a complex number, which is physically nonsensical for the energy of a system described by a Hermitian Hamiltonian, demonstrating the mathematical error.\n\nFinally, we compute the correct energy $E = \\frac{c^\\dagger H c}{c^\\dagger S c}$. We calculate the Hermitian form $c^\\dagger M c = \\sum_{i,j} c_i^* M_{ij} c_j = M_{11}|c_1|^2 + M_{22}|c_2|^2 + M_{12}c_1^*c_2 + M_{21}c_2^*c_1$. Since the matrices $H$ and $S$ are real and symmetric ($M_{12}=M_{21}$), this simplifies to $M_{11}|c_1|^2 + M_{22}|c_2|^2 + M_{12}(c_1^*c_2 + c_2^*c_1)$.\nFirst, we find the required terms:\n$|c_1|^2 = c_1^*c_1 = (1-i)(1+i) = 1^2 - i^2 = 2$.\n$|c_2|^2 = c_2^*c_2 = (2+i)(2-i) = 2^2 - i^2 = 5$.\n$c_1^*c_2 = (1-i)(2-i) = 2 - i - 2i + i^2 = 1-3i$.\n$c_2^*c_1 = (2+i)(1+i) = 2 + 2i + i + i^2 = 1+3i$.\n$c_1^*c_2 + c_2^*c_1 = (1-3i) + (1+3i) = 2$.\n\nFor the denominator $c^\\dagger S c$:\n$$\nc^\\dagger S c = S_{11}|c_1|^2 + S_{22}|c_2|^2 + S_{12}(c_1^*c_2 + c_2^*c_1) = (1)(2) + (1)(5) + (1/5)(2) = 7 + 2/5 = \\frac{37}{5}\n$$\nFor the numerator $c^\\dagger H c$:\n$$\nc^\\dagger H c = H_{11}|c_1|^2 + H_{22}|c_2|^2 + H_{12}(c_1^*c_2 + c_2^*c_1) = (-1)(2) + (-4/5)(5) + (-1/10)(2) = -2 - 4 - 1/5 = -6 - 1/5 = -\\frac{31}{5}\n$$\nBoth quadratic forms are real numbers, as required for expectation values of Hermitian operators. The correct energy is the ratio of these two values:\n$$\nE = \\frac{c^\\dagger H c}{c^\\dagger S c} = \\frac{-31/5}{37/5} = -\\frac{31}{37}\n$$\nThis is a real, physically meaningful value for the energy expectation value.", "answer": "$$\n\\boxed{-\\frac{31}{37}}\n$$", "id": "2896475"}, {"introduction": "While physical basis sets are often non-orthogonal, orthonormal bases are invaluable for simplifying theoretical derivations and computations. This practice guides you through the Gram-Schmidt process, the standard algorithm for constructing an orthonormal basis from a linearly independent set of functions in a Hilbert space [@problem_id:2896435]. By applying this procedure to a set of simple polynomials, you will gain practical skill in using the inner product and see how an orthonormal basis leads to a simple and powerful representation of the projection operator.", "problem": "Consider the Hilbert space $L^{2}([0,1])$ of square-integrable complex functions on the interval $[0,1]$ with the inner product defined by $\\langle f \\mid g \\rangle = \\int_{0}^{1} f^{\\ast}(x)\\,g(x)\\,dx$. In the bra-ket formalism, let $\\lvert f \\rangle$ denote an abstract vector with coordinate representation $\\langle x \\mid f \\rangle = f(x)$. The set $\\{\\lvert f_{1} \\rangle, \\lvert f_{2} \\rangle, \\lvert f_{3} \\rangle\\}$ with $\\langle x \\mid f_{1} \\rangle = 1$, $\\langle x \\mid f_{2} \\rangle = x$, and $\\langle x \\mid f_{3} \\rangle = x^{2}$ is linearly independent in $L^{2}([0,1])$.\n\nUsing only the definitions of inner product, norm, orthogonality, and the Gram–Schmidt process, carry out the following:\n\n1. Apply the Gram–Schmidt orthonormalization to construct an orthonormal family $\\{\\lvert e_{0} \\rangle, \\lvert e_{1} \\rangle, \\lvert e_{2} \\rangle\\}$ that spans the same closed linear subspace as $\\{\\lvert f_{1} \\rangle, \\lvert f_{2} \\rangle, \\lvert f_{3} \\rangle\\}$.\n\n2. Define the operator $\\hat{P} = \\sum_{k=0}^{2} \\lvert e_{k} \\rangle \\langle e_{k} \\rvert$ and verify the resolution of the identity on the closed linear span of $\\{\\lvert f_{1} \\rangle, \\lvert f_{2} \\rangle, \\lvert f_{3} \\rangle\\}$ by showing that $\\hat{P}\\lvert \\psi \\rangle = \\lvert \\psi \\rangle$ for every $\\lvert \\psi \\rangle$ in that span.\n\n3. In the coordinate representation, determine the integral kernel $K(x,y) = \\langle x \\mid \\hat{P} \\mid y \\rangle$ as an explicit symmetric polynomial in $x$ and $y$.\n\nProvide $K(x,y)$ as your final answer in exact, fully simplified form. Do not round. The final answer must be a single closed-form analytic expression with no units.", "solution": "The problem has been validated and is found to be scientifically grounded, well-posed, and objective. It presents a standard exercise in functional analysis within the context of quantum mechanical formalism, using well-defined mathematical objects and operations. All necessary information is provided, and the problem is free of contradictions or ambiguities. We may proceed with the solution.\n\nThe problem requires a three-part procedure. We will execute these tasks sequentially.\n\nFirst, we apply the Gram–Schmidt orthonormalization process to the set of linearly independent vectors $\\{\\lvert f_{1} \\rangle, \\lvert f_{2} \\rangle, \\lvert f_{3} \\rangle\\}$, whose coordinate representations are given by the functions $f_{1}(x) = \\langle x \\mid f_{1} \\rangle = 1$, $f_{2}(x) = \\langle x \\mid f_{2} \\rangle = x$, and $f_{3}(x) = \\langle x \\mid f_{3} \\rangle = x^{2}$. We will construct the orthonormal set $\\{\\lvert e_{0} \\rangle, \\lvert e_{1} \\rangle, \\lvert e_{2} \\rangle\\}$. The inner product is $\\langle g \\mid h \\rangle = \\int_{0}^{1} g^{\\ast}(x)h(x)dx$. Since our functions are real, $g^{\\ast}(x) = g(x)$.\n\nStep 1: Construct $\\lvert e_{0} \\rangle$.\nWe start with an unnormalized vector $\\lvert v_{0} \\rangle = \\lvert f_{1} \\rangle$.\nThe squared norm is $\\|v_{0}\\|^{2} = \\langle v_{0} \\mid v_{0} \\rangle = \\langle f_{1} \\mid f_{1} \\rangle = \\int_{0}^{1} (1)(1) dx = 1$.\nThe norm is $\\|v_{0}\\| = 1$.\nThe first orthonormal vector is $\\lvert e_{0} \\rangle = \\frac{\\lvert v_{0} \\rangle}{\\|v_{0}\\|} = \\lvert f_{1} \\rangle$.\nIts coordinate representation is $\\langle x \\mid e_{0} \\rangle = e_{0}(x) = 1$.\n\nStep 2: Construct $\\lvert e_{1} \\rangle$.\nWe define an intermediate vector $\\lvert v_{1} \\rangle$ by subtracting from $\\lvert f_{2} \\rangle$ its projection onto $\\lvert e_{0} \\rangle$:\n$ \\lvert v_{1} \\rangle = \\lvert f_{2} \\rangle - \\langle e_{0} \\mid f_{2} \\rangle \\lvert e_{0} \\rangle $.\nThe projection coefficient is $\\langle e_{0} \\mid f_{2} \\rangle = \\int_{0}^{1} e_{0}^{\\ast}(x) f_{2}(x) dx = \\int_{0}^{1} (1)(x) dx = \\left[\\frac{x^{2}}{2}\\right]_{0}^{1} = \\frac{1}{2}$.\nThus, $\\langle x \\mid v_{1} \\rangle = v_{1}(x) = f_{2}(x) - \\frac{1}{2} e_{0}(x) = x - \\frac{1}{2}$.\nThe squared norm is $\\|v_{1}\\|^{2} = \\langle v_{1} \\mid v_{1} \\rangle = \\int_{0}^{1} (x - \\frac{1}{2})^{2} dx = \\int_{0}^{1} (x^{2} - x + \\frac{1}{4}) dx = \\left[\\frac{x^{3}}{3} - \\frac{x^{2}}{2} + \\frac{x}{4}\\right]_{0}^{1} = \\frac{1}{3} - \\frac{1}{2} + \\frac{1}{4} = \\frac{4-6+3}{12} = \\frac{1}{12}$.\nThe norm is $\\|v_{1}\\| = \\sqrt{\\frac{1}{12}} = \\frac{1}{2\\sqrt{3}}$.\nThe second orthonormal vector is $\\lvert e_{1} \\rangle = \\frac{\\lvert v_{1} \\rangle}{\\|v_{1}\\|} = 2\\sqrt{3} \\lvert v_{1} \\rangle$.\nIts coordinate representation is $e_{1}(x) = 2\\sqrt{3}(x - \\frac{1}{2}) = \\sqrt{3}(2x-1)$.\n\nStep 3: Construct $\\lvert e_{2} \\rangle$.\nWe define $\\lvert v_{2} \\rangle$ by subtracting from $\\lvert f_{3} \\rangle$ its projections onto $\\lvert e_{0} \\rangle$ and $\\lvert e_{1} \\rangle$:\n$\\lvert v_{2} \\rangle = \\lvert f_{3} \\rangle - \\langle e_{0} \\mid f_{3} \\rangle \\lvert e_{0} \\rangle - \\langle e_{1} \\mid f_{3} \\rangle \\lvert e_{1} \\rangle$.\nThe projection coefficients are:\n$\\langle e_{0} \\mid f_{3} \\rangle = \\int_{0}^{1} (1)(x^{2}) dx = \\left[\\frac{x^{3}}{3}\\right]_{0}^{1} = \\frac{1}{3}$.\n$\\langle e_{1} \\mid f_{3} \\rangle = \\int_{0}^{1} (\\sqrt{3}(2x-1))(x^{2}) dx = \\sqrt{3} \\int_{0}^{1} (2x^{3} - x^{2}) dx = \\sqrt{3} \\left[2\\frac{x^{4}}{4} - \\frac{x^{3}}{3}\\right]_{0}^{1} = \\sqrt{3} (\\frac{1}{2} - \\frac{1}{3}) = \\frac{\\sqrt{3}}{6}$.\nThe coordinate representation $v_{2}(x)$ is:\n$v_{2}(x) = f_{3}(x) - \\frac{1}{3} e_{0}(x) - \\frac{\\sqrt{3}}{6} e_{1}(x) = x^{2} - \\frac{1}{3}(1) - \\frac{\\sqrt{3}}{6}(\\sqrt{3}(2x-1)) = x^{2} - \\frac{1}{3} - \\frac{3}{6}(2x-1) = x^{2} - \\frac{1}{3} - x + \\frac{1}{2} = x^{2} - x + \\frac{1}{6}$.\nThe squared norm is $\\|v_{2}\\|^{2} = \\int_{0}^{1} (x^{2} - x + \\frac{1}{6})^{2} dx = \\int_{0}^{1} (x^{4} - 2x^{3} + \\frac{4}{3}x^{2} - \\frac{x}{3} + \\frac{1}{36}) dx$.\n$\\|v_{2}\\|^{2} = \\left[\\frac{x^{5}}{5} - \\frac{2x^{4}}{4} + \\frac{4x^{3}}{9} - \\frac{x^{2}}{6} + \\frac{x}{36}\\right]_{0}^{1} = \\frac{1}{5} - \\frac{1}{2} + \\frac{4}{9} - \\frac{1}{6} + \\frac{1}{36} = \\frac{36-90+80-30+5}{180} = \\frac{1}{180}$.\nThe norm is $\\|v_{2}\\| = \\sqrt{\\frac{1}{180}} = \\frac{1}{6\\sqrt{5}}$.\nThe third orthonormal vector is $\\lvert e_{2} \\rangle = 6\\sqrt{5} \\lvert v_{2} \\rangle$.\nIts coordinate representation is $e_{2}(x) = 6\\sqrt{5}(x^{2} - x + \\frac{1}{6}) = \\sqrt{5}(6x^{2} - 6x + 1)$.\n\nThe resulting orthonormal basis functions for the subspace are:\n$e_{0}(x) = 1$\n$e_{1}(x) = \\sqrt{3}(2x-1)$\n$e_{2}(x) = \\sqrt{5}(6x^{2}-6x+1)$\n\nSecond, we address the operator $\\hat{P} = \\sum_{k=0}^{2} \\lvert e_{k} \\rangle \\langle e_{k} \\rvert$. This is the projection operator onto the subspace spanned by $\\{\\lvert e_{k} \\rangle\\}$, which is the same subspace spanned by $\\{\\lvert f_{j} \\rangle\\}$. For any vector $\\lvert \\psi \\rangle$ in this subspace, its expansion in the orthonormal basis is exact: $\\lvert \\psi \\rangle = \\sum_{k=0}^{2} c_{k} \\lvert e_{k} \\rangle$, where the coefficients are given by the projection $c_{k} = \\langle e_{k} \\mid \\psi \\rangle$.\nTherefore, $\\lvert \\psi \\rangle = \\sum_{k=0}^{2} \\lvert e_{k} \\rangle \\langle e_{k} \\mid \\psi \\rangle$.\nApplying $\\hat{P}$ to $\\lvert \\psi \\rangle$:\n$\\hat{P} \\lvert \\psi \\rangle = \\left(\\sum_{j=0}^{2} \\lvert e_{j} \\rangle \\langle e_{j} \\rvert\\right) \\lvert \\psi \\rangle = \\sum_{j=0}^{2} \\lvert e_{j} \\rangle \\langle e_{j} \\mid \\psi \\rangle$.\nComparing the two expressions, we see that $\\hat{P} \\lvert \\psi \\rangle = \\lvert \\psi \\rangle$ for any $\\lvert \\psi \\rangle$ in the span. This verifies that $\\hat{P}$ acts as the identity operator on this subspace.\n\nThird, we determine the integral kernel $K(x,y) = \\langle x \\mid \\hat{P} \\mid y \\rangle$.\nWe insert the definition of $\\hat{P}$:\n$K(x,y) = \\langle x \\mid \\left(\\sum_{k=0}^{2} \\lvert e_{k} \\rangle \\langle e_{k} \\rvert\\right) \\mid y \\rangle = \\sum_{k=0}^{2} \\langle x \\mid e_{k} \\rangle \\langle e_{k} \\mid y \\rangle$.\nUsing $\\langle x \\mid e_{k} \\rangle = e_{k}(x)$ and $\\langle e_{k} \\mid y \\rangle = \\langle y \\mid e_{k} \\rangle^{\\ast} = e_{k}(y)^{\\ast}$, and noting that our functions are real, we have:\n$K(x,y) = \\sum_{k=0}^{2} e_{k}(x)e_{k}(y)$.\nWe compute the sum term by term:\n$e_{0}(x)e_{0}(y) = (1)(1) = 1$.\n$e_{1}(x)e_{1}(y) = [\\sqrt{3}(2x-1)][\\sqrt{3}(2y-1)] = 3(2x-1)(2y-1) = 3(4xy - 2x - 2y + 1) = 12xy - 6x - 6y + 3$.\n$e_{2}(x)e_{2}(y) = [\\sqrt{5}(6x^{2}-6x+1)][\\sqrt{5}(6y^{2}-6y+1)] = 5(6x^{2}-6x+1)(6y^{2}-6y+1)$\n$= 5(36x^{2}y^{2} - 36x^{2}y + 6x^{2} - 36xy^{2} + 36xy - 6x + 6y^{2} - 6y + 1)$\n$= 180x^{2}y^{2} - 180x^{2}y + 30x^{2} - 180xy^{2} + 180xy - 30x + 30y^{2} - 30y + 5$.\n\nSumming the three terms:\n$K(x,y) = (1) + (12xy - 6x - 6y + 3) + (180x^{2}y^{2} - 180x^{2}y - 180xy^{2} + 30x^{2} + 30y^{2} + 180xy - 30x - 30y + 5)$.\nCombine like terms to obtain the final polynomial expression:\n$K(x,y) = 180x^{2}y^{2} - 180(x^{2}y + xy^{2}) + 30(x^{2} + y^{2}) + (12+180)xy - (6+30)(x+y) + (1+3+5)$\n$K(x,y) = 180x^{2}y^{2} - 180x^{2}y - 180xy^{2} + 30x^{2} + 30y^{2} + 192xy - 36x - 36y + 9$.\nThis is the explicit symmetric polynomial for the kernel $K(x,y)$.", "answer": "$$\n\\boxed{180x^{2}y^{2} - 180(x^{2}y + xy^{2}) + 30(x^{2} + y^{2}) + 192xy - 36(x+y) + 9}\n$$", "id": "2896435"}, {"introduction": "In most quantum chemical applications, we work directly with non-orthogonal basis sets like atomic orbitals, making it essential to have tools that do not require an orthonormal representation. This exercise develops a more general and powerful form of the projection operator that works directly with a non-orthogonal basis, using its Gram matrix of overlaps [@problem_id:2896438]. Deriving and applying this formula for the projector, $\\hat{P} = \\sum_{ij} |v_i\\rangle (G^{-1})_{ij} \\langle v_j|$, provides deep insight into handling non-orthogonality and is a key piece of machinery in advanced electronic structure theory.", "problem": "In the Hilbert space formalism of quantum chemistry, one often works with non-orthogonal basis functions, such as atomic orbitals, whose overlaps are encoded by the Gram matrix. Let $\\mathcal{H}$ be a finite-dimensional complex Hilbert space with inner product $\\langle \\cdot | \\cdot \\rangle$. Consider a set of $m$ linearly independent vectors $\\{|v_i\\rangle\\}_{i=1}^m \\subset \\mathcal{H}$, and let $\\mathcal{S} = \\mathrm{span}\\{|v_i\\rangle\\}_{i=1}^m$. Define the Gram matrix $G \\in \\mathbb{C}^{m \\times m}$ by $G_{ij} = \\langle v_i | v_j \\rangle$, which is invertible because the $\\{|v_i\\rangle\\}$ are linearly independent.\n\nStarting only from the defining properties of the orthogonal projection $P$ onto $\\mathcal{S}$, namely that $P$ is linear, $\\mathrm{Ran}(P) = \\mathcal{S}$, $P^2 = P$, and $P = P^{\\dagger}$, derive a closed-form expression for $P$ in terms of the vectors $\\{|v_i\\rangle\\}$ and the Gram matrix $G$. Prove from first principles that your expression satisfies $P = P^{\\dagger}$ and $P^2 = P$, and that for any $|x\\rangle \\in \\mathcal{H}$ the vector $P|x\\rangle$ is the unique element of $\\mathcal{S}$ that minimizes the norm $\\| |x\\rangle - |y\\rangle \\|$ over $|y\\rangle \\in \\mathcal{S}$.\n\nThen, consider the concrete model where $\\mathcal{H} = \\mathbb{C}^3$ with the standard inner product, equipped with an orthonormal basis $\\{|e_1\\rangle, |e_2\\rangle, |e_3\\rangle\\}$. Let $|v_1\\rangle = |e_1\\rangle + |e_2\\rangle$ and $|v_2\\rangle = |e_2\\rangle + |e_3\\rangle$, so that $\\mathcal{S} = \\mathrm{span}\\{|v_1\\rangle, |v_2\\rangle\\}$. Using your general formula, construct the projector $P$ onto $\\mathcal{S}$ and evaluate the scalar $\\langle \\psi | P | \\psi \\rangle$ for the state $|\\psi\\rangle = |e_1\\rangle + |e_3\\rangle$. Report the value of $\\langle \\psi | P | \\psi \\rangle$ as your final answer. Do not round; give the exact value.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is a standard problem in linear algebra with direct applications in quantum chemistry, framed within the bra-ket formalism of quantum mechanics. All required data and definitions are provided, and there are no contradictions or ambiguities. The problem is valid and a complete solution can be constructed.\n\nWe begin by deriving the closed-form expression for the orthogonal projection operator $P$ onto the subspace $\\mathcal{S} = \\mathrm{span}\\{|v_i\\rangle\\}_{i=1}^m$.\n\nLet $|x\\rangle$ be an arbitrary vector in the Hilbert space $\\mathcal{H}$. The projection of $|x\\rangle$ onto $\\mathcal{S}$, denoted by $P|x\\rangle$, must be an element of $\\mathcal{S}$. Therefore, it can be expressed as a linear combination of the basis vectors of $\\mathcal{S}$:\n$$P|x\\rangle = \\sum_{j=1}^m c_j |v_j\\rangle$$\nfor some set of complex coefficients $\\{c_j\\}_{j=1}^m$.\n\nThe defining property of an orthogonal projection is that the vector difference between $|x\\rangle$ and its projection, $|x\\rangle - P|x\\rangle$, must be orthogonal to the subspace $\\mathcal{S}$. This is equivalent to the condition that this difference vector is orthogonal to every basis vector $|v_k\\rangle$ of $\\mathcal{S}$. For each $k \\in \\{1, 2, \\dots, m\\}$, we must have:\n$$\\langle v_k | (|x\\rangle - P|x\\rangle) = 0$$\nUsing the linearity of the inner product, this expands to:\n$$\\langle v_k | x \\rangle - \\langle v_k | P|x\\rangle = 0$$\nSubstituting the expression for $P|x\\rangle$:\n$$\\langle v_k | x \\rangle - \\left\\langle v_k \\left| \\sum_{j=1}^m c_j |v_j\\rangle \\right. \\right\\rangle = 0$$\n$$\\langle v_k | x \\rangle - \\sum_{j=1}^m c_j \\langle v_k | v_j \\rangle = 0$$\nWe recognize the term $\\langle v_k | v_j \\rangle$ as the element $G_{kj}$ of the Gram matrix $G$. The equation becomes:\n$$\\langle v_k | x \\rangle = \\sum_{j=1}^m G_{kj} c_j$$\nThis represents a system of $m$ linear equations for the $m$ unknown coefficients $c_j$. In matrix notation, this is $\\mathbf{b} = G \\mathbf{c}$, where $\\mathbf{c}$ is a column vector with entries $c_j$ and $\\mathbf{b}$ is a column vector with entries $b_k = \\langle v_k | x \\rangle$. Since the vectors $\\{|v_i\\rangle\\}$ are linearly independent, the Gram matrix $G$ is invertible. We can therefore solve for the coefficients:\n$$\\mathbf{c} = G^{-1} \\mathbf{b}$$\nIn component form, this is:\n$$c_j = \\sum_{k=1}^m (G^{-1})_{jk} b_k = \\sum_{k=1}^m (G^{-1})_{jk} \\langle v_k | x \\rangle$$\nNow, we substitute these coefficients back into the expression for $P|x\\rangle$:\n$$P|x\\rangle = \\sum_{j=1}^m |v_j\\rangle c_j = \\sum_{j=1}^m |v_j\\rangle \\left( \\sum_{k=1}^m (G^{-1})_{jk} \\langle v_k | x \\rangle \\right)$$\nRearranging the sums, we can identify the operator $P$:\n$$P|x\\rangle = \\left( \\sum_{j=1}^m \\sum_{k=1}^m |v_j\\rangle (G^{-1})_{jk} \\langle v_k | \\right) |x\\rangle$$\nFrom this, we extract the expression for the projection operator $P$:\n$$P = \\sum_{j=1}^m \\sum_{k=1}^m |v_j\\rangle (G^{-1})_{jk} \\langle v_k |$$\nThis is the required closed-form expression for the projector onto a subspace spanned by a non-orthogonal basis.\n\nNext, we prove from first principles that this operator satisfies $P=P^{\\dagger}$ and $P^2=P$.\nTo prove $P = P^{\\dagger}$ (Hermiticity), we take the adjoint of $P$:\n$$P^{\\dagger} = \\left( \\sum_{j,k} |v_j\\rangle (G^{-1})_{jk} \\langle v_k | \\right)^{\\dagger} = \\sum_{j,k} (|v_j\\rangle (G^{-1})_{jk} \\langle v_k |)^{\\dagger}$$\nUsing the property $(ABC)^{\\dagger} = C^{\\dagger}B^{\\dagger}A^{\\dagger}$ and noting that $(G^{-1})_{jk}$ is a scalar, we have:\n$$P^{\\dagger} = \\sum_{j,k} (|v_k\\rangle)^{\\dagger} ((G^{-1})_{jk})^* (|v_j\\rangle)^{\\dagger} = \\sum_{j,k} |v_k\\rangle ((G^{-1})_{jk})^* \\langle v_j |$$\nThe Gram matrix $G$ is Hermitian since $G_{ij} = \\langle v_i | v_j \\rangle$ and $G_{ji} = \\langle v_j | v_i \\rangle = (\\langle v_i | v_j \\rangle)^* = (G_{ij})^*$. The inverse of a Hermitian matrix is also Hermitian, so $G^{-1} = (G^{-1})^{\\dagger}$. In component form, this means $(G^{-1})_{kj} = ((G^{-1})_{jk})^*$. Substituting this into the expression for $P^{\\dagger}$:\n$$P^{\\dagger} = \\sum_{j,k} |v_k\\rangle (G^{-1})_{kj} \\langle v_j |$$\nBy relabeling the summation indices ($k \\leftrightarrow j$), we obtain:\n$$P^{\\dagger} = \\sum_{k,j} |v_j\\rangle (G^{-1})_{jk} \\langle v_k | = P$$\nThe Hermiticity is proven.\n\nTo prove $P^2 = P$ (idempotency), we compute the product $P \\cdot P$:\n$$P^2 = \\left( \\sum_{j,k} |v_j\\rangle (G^{-1})_{jk} \\langle v_k | \\right) \\left( \\sum_{l,m} |v_l\\rangle (G^{-1})_{lm} \\langle v_m | \\right)$$\n$$P^2 = \\sum_{j,k,l,m} |v_j\\rangle (G^{-1})_{jk} \\langle v_k | v_l \\rangle (G^{-1})_{lm} \\langle v_m |$$\nRecognizing $\\langle v_k | v_l \\rangle = G_{kl}$:\n$$P^2 = \\sum_{j,k,l,m} |v_j\\rangle (G^{-1})_{jk} G_{kl} (G^{-1})_{lm} \\langle v_m |$$\nWe can group the sums over $k$ and $l$ to evaluate the matrix product $G^{-1} G G^{-1}$:\n$$P^2 = \\sum_{j,m} |v_j\\rangle \\left( \\sum_{k,l} (G^{-1})_{jk} G_{kl} (G^{-1})_{lm} \\right) \\langle v_m |$$\nThe term in the parenthesis is the $(j,m)$-th element of $G^{-1} G G^{-1}$. Since $G^{-1}G = I$ (the identity matrix), we have $G^{-1}GG^{-1} = I G^{-1} = G^{-1}$. Thus, the parenthetical expression is simply $(G^{-1})_{jm}$.\n$$P^2 = \\sum_{j,m} |v_j\\rangle (G^{-1})_{jm} \\langle v_m | = P$$\nThe idempotency is proven.\n\nNext, we prove that for any $|x\\rangle \\in \\mathcal{H}$, the vector $P|x\\rangle$ is the unique element of $\\mathcal{S}$ that minimizes the norm $\\| |x\\rangle - |y\\rangle \\|$ for $|y\\rangle \\in \\mathcal{S}$. We seek to minimize the squared norm $D(|y\\rangle) = \\| |x\\rangle - |y\\rangle \\|^2$. Let us rewrite the argument of the norm:\n$$|x\\rangle - |y\\rangle = (|x\\rangle - P|x\\rangle) + (P|x\\rangle - |y\\rangle)$$\nLet $|e\\rangle = |x\\rangle - P|x\\rangle = (I-P)|x\\rangle$ and $|d\\rangle = P|x\\rangle - |y\\rangle$. The vector $|e\\rangle$ is, by construction of the orthogonal projector $P$, orthogonal to the subspace $\\mathcal{S}$. Since $|y\\rangle \\in \\mathcal{S}$ and $P|x\\rangle \\in \\mathcal{S}$, their difference $|d\\rangle$ is also in $\\mathcal{S}$. Therefore, $\\langle d|e \\rangle = 0$.\nThe squared norm is:\n$$\\| |x\\rangle - |y\\rangle \\|^2 = \\| |e\\rangle + |d\\rangle \\|^2 = \\langle e+d | e+d \\rangle = \\langle e|e \\rangle + \\langle d|d \\rangle + \\langle e|d \\rangle + \\langle d|e \\rangle$$\nSince $\\langle d|e \\rangle = 0$ and $\\langle e|d \\rangle = (\\langle d|e \\rangle)^* = 0$, the expression simplifies due to the Pythagorean theorem in Hilbert space:\n$$\\| |x\\rangle - |y\\rangle \\|^2 = \\| |e\\rangle \\|^2 + \\| |d\\rangle \\|^2 = \\| |x\\rangle - P|x\\rangle \\|^2 + \\| P|x\\rangle - |y\\rangle \\|^2$$\nThe first term is fixed for a given $|x\\rangle$ and is independent of $|y\\rangle$. The second term, $\\| P|x\\rangle - |y\\rangle \\|^2$, is a non-negative real number. To minimize the total sum, we must minimize this second term. Its minimum value is $0$, which is achieved if and only if $|y\\rangle = P|x\\rangle$. Therefore, $P|x\\rangle$ is the unique vector in $\\mathcal{S}$ that minimizes the distance to $|x\\rangle$.\n\nNow, we apply this formalism to the concrete problem in $\\mathcal{H} = \\mathbb{C}^3$.\nThe given vectors are $|v_1\\rangle = |e_1\\rangle + |e_2\\rangle$ and $|v_2\\rangle = |e_2\\rangle + |e_3\\rangle$. In the standard basis, they correspond to column vectors $v_1 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$ and $v_2 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}$.\nThe Gram matrix $G$ has elements $G_{ij} = \\langle v_i | v_j \\rangle$:\n$G_{11} = \\langle v_1 | v_1 \\rangle = 1^2 + 1^2 + 0^2 = 2$\n$G_{12} = \\langle v_1 | v_2 \\rangle = 1 \\cdot 0 + 1 \\cdot 1 + 0 \\cdot 1 = 1$\n$G_{21} = \\langle v_2 | v_1 \\rangle = 0 \\cdot 1 + 1 \\cdot 1 + 1 \\cdot 0 = 1$\n$G_{22} = \\langle v_2 | v_2 \\rangle = 0^2 + 1^2 + 1^2 = 2$\nSo, the Gram matrix is $G = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix}$.\n\nThe inverse of $G$ is:\n$G^{-1} = \\frac{1}{\\det(G)} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} = \\frac{1}{2 \\cdot 2 - 1 \\cdot 1} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix}$.\n\nThe state of interest is $|\\psi\\rangle = |e_1\\rangle + |e_3\\rangle$, corresponding to the vector $\\psi = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}$. We need to compute $\\langle \\psi | P | \\psi \\rangle$.\nSince $P$ is a projector, $P=P^{\\dagger}$ and $P^2=P$. Thus, $\\langle \\psi | P | \\psi \\rangle = \\langle \\psi | P^{\\dagger} P | \\psi \\rangle = \\langle P\\psi | P\\psi \\rangle = \\| P|\\psi\\rangle \\|^2$.\nLet's find the projection of $|\\psi\\rangle$, which is $P|\\psi\\rangle = \\sum_{j=1}^2 c_j |v_j\\rangle$. The coefficients are given by $c_j = \\sum_{k=1}^2 (G^{-1})_{jk} \\langle v_k | \\psi \\rangle$.\nFirst, we compute the required inner products:\n$\\langle v_1 | \\psi \\rangle = (1 \\cdot 1) + (1 \\cdot 0) + (0 \\cdot 1) = 1$\n$\\langle v_2 | \\psi \\rangle = (0 \\cdot 1) + (1 \\cdot 0) + (1 \\cdot 1) = 1$\nNow we find the coefficients $c_1$ and $c_2$:\n$\\begin{pmatrix} c_1 \\\\ c_2 \\end{pmatrix} = G^{-1} \\begin{pmatrix} \\langle v_1 | \\psi \\rangle \\\\ \\langle v_2 | \\psi \\rangle \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 2-1 \\\\ -1+2 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\nSo, $c_1 = \\frac{1}{3}$ and $c_2 = \\frac{1}{3}$.\nThe projected vector is $P|\\psi\\rangle = c_1 |v_1\\rangle + c_2 |v_2\\rangle = \\frac{1}{3} |v_1\\rangle + \\frac{1}{3} |v_2\\rangle$.\n$P|\\psi\\rangle = \\frac{1}{3} \\left( (|e_1\\rangle + |e_2\\rangle) + (|e_2\\rangle + |e_3\\rangle) \\right) = \\frac{1}{3} (|e_1\\rangle + 2|e_2\\rangle + |e_3\\rangle)$.\n\nFinally, we compute the expectation value $\\langle \\psi | P | \\psi \\rangle$:\n$$\\langle \\psi | P | \\psi \\rangle = \\langle e_1+e_3 | \\frac{1}{3}(|e_1\\rangle + 2|e_2\\rangle + |e_3\\rangle) \\rangle$$\n$$\\langle \\psi | P | \\psi \\rangle = \\frac{1}{3} \\left( \\langle e_1 | e_1 \\rangle + 2\\langle e_1 | e_2 \\rangle + \\langle e_1 | e_3 \\rangle + \\langle e_3 | e_1 \\rangle + 2\\langle e_3 | e_2 \\rangle + \\langle e_3 | e_3 \\rangle \\right)$$\nUsing the orthonormality of the basis $\\{|e_i\\rangle\\}$, where $\\langle e_i | e_j \\rangle = \\delta_{ij}$:\n$$\\langle \\psi | P | \\psi \\rangle = \\frac{1}{3} (1 + 0 + 0 + 0 + 0 + 1) = \\frac{2}{3}$$\nAlternatively, using $\\langle \\psi | P | \\psi \\rangle = \\sum_{j=1}^2 c_j^* \\langle \\psi | v_j \\rangle$ and knowing $c_j$ are real and $\\langle \\psi | v_j \\rangle = (\\langle v_j | \\psi \\rangle)^*$, we find:\n$$\\langle \\psi | P | \\psi \\rangle = c_1 \\langle v_1 | \\psi \\rangle + c_2 \\langle v_2 | \\psi \\rangle = \\frac{1}{3}(1) + \\frac{1}{3}(1) = \\frac{2}{3}$$\nBoth methods yield the same result. The calculation is correct.", "answer": "$$\\boxed{\\frac{2}{3}}$$", "id": "2896438"}]}