{"hands_on_practices": [{"introduction": "The principle of dimensional homogeneity is a cornerstone of the scientific method, asserting that any physically meaningful equation must have consistent dimensions on both sides. Before an empirical law can be tested or falsified, it must first be dimensionally sound. This foundational exercise [@problem_id:2961548] provides practice in applying this principle to a power-law kinetic model, a common form in chemical reaction engineering, and reinforces the understanding of how a model's structure dictates the dimensions of its parameters.", "problem": "A core requirement in measurement theory and the scientific method is dimensional homogeneity: any proposed empirical law must be dimensionally consistent to be testable and falsifiable by measurement. Consider a homogeneous liquid-phase reaction studied in a well-mixed, isothermal batch reactor. The rate of formation of a product species is modeled by a power-law rate expression of the form $r = k[A]^{m}[B]^{n}$, where $r$ denotes an experimentally measured reaction rate, $k$ is an empirical rate constant, $[A]$ and $[B]$ are molar concentrations of reactants $A$ and $B$, and $m$ and $n$ are reaction orders determined by regression of rate data. The rate $r$ is operationally defined as the time derivative of the amount of product per unit volume, and is reported in the International System of Units (SI) as $\\mathrm{mol\\,m^{-3}\\,s^{-1}}$. Concentrations are reported in SI as $\\mathrm{mol\\,m^{-3}}$. Assume $m$ and $n$ are dimensionless.\n\nUsing only the base SI dimensions of amount of substance, length, and time, and enforcing dimensional homogeneity, derive symbolically the SI units of $k$ as a function of $m$ and $n$. Your derivation must start from the definitions of rate and concentration and the requirement that both sides of the rate law share identical dimensions.\n\nAnswer specification:\n- Express your final result as the ordered triple of exponents on the base units $\\mathrm{mol}$, $\\mathrm{m}$, and $\\mathrm{s}$, respectively, corresponding to the SI units of $k$. That is, if $[k] = \\mathrm{mol}^{\\alpha}\\,\\mathrm{m}^{\\beta}\\,\\mathrm{s}^{\\gamma}$, report the row vector $(\\alpha\\ \\beta\\ \\gamma)$.\n- The final answer must be a single closed-form analytic expression. Do not include units in your final boxed answer.", "solution": "The problem statement is subjected to validation and is found to be valid. It is scientifically grounded in the principles of dimensional analysis as applied to chemical kinetics, it is well-posed, objective, and contains all necessary information for a unique solution. The problem is a standard exercise in applying the principle of dimensional homogeneity.\n\nThe fundamental principle to be applied is that of dimensional homogeneity, which dictates that for any physically meaningful equation, the dimensions of the terms on both sides of the equality must be identical. The given rate law is:\n$$r = k[A]^{m}[B]^{n}$$\nTo analyze the dimensions, we denote the dimensions of a physical quantity $X$ as $[X]$. Applying this to the rate law, we have:\n$$[r] = [k[A]^{m}[B]^{n}]$$\nUsing the property that the dimensions of a product are the product of the dimensions, we can separate the terms:\n$$[r] = [k] [A]^{m} [B]^{n}$$\nThe base SI dimensions relevant to this problem are amount of substance ($\\mathrm{mol}$), length ($\\mathrm{m}$), and time ($\\mathrm{s}$). For dimensional analysis, we can represent these base units with the symbols $N$ (amount of substance), $L$ (length), and $T$ (time).\n\nThe problem provides the SI units for the rate, $r$, and concentrations, $[A]$ and $[B]$. We translate these into their fundamental dimensions:\nThe dimension of the reaction rate, $r$, is given as $\\mathrm{mol\\,m^{-3}\\,s^{-1}}$. In terms of our base dimensions, this is:\n$$[r] = N L^{-3} T^{-1}$$\nThe dimension of molar concentration, for both $[A]$ and $[B]$, is given as $\\mathrm{mol\\,m^{-3}}$. In terms of our base dimensions, this is:\n$$[A] = [B] = N L^{-3}$$\nThe reaction orders, $m$ and $n$, are stated to be dimensionless numbers. Therefore, they do not contribute to the dimensional equation themselves, but only act as exponents on the dimensions of the concentrations.\n\nWe now substitute these dimensional expressions back into the primary dimensional equation:\n$$N^{1} L^{-3} T^{-1} = [k] (N L^{-3})^{m} (N L^{-3})^{n}$$\nThe right-hand side can be simplified by combining the concentration terms using the law of exponents:\n$$(N L^{-3})^{m} (N L^{-3})^{n} = (N L^{-3})^{m+n} = N^{m+n} (L^{-3})^{m+n} = N^{m+n} L^{-3(m+n)}$$\nThe dimensional equation now becomes:\n$$N^{1} L^{-3} T^{-1} = [k] N^{m+n} L^{-3(m+n)}$$\nTo find the dimensions of the rate constant, $k$, we must isolate $[k]$ by dividing both sides of the equation by the dimensional group for the concentration terms:\n$$[k] = \\frac{N^{1} L^{-3} T^{-1}}{N^{m+n} L^{-3(m+n)}}$$\nBy applying the rules for division of exponents ($x^{a}/x^{b} = x^{a-b}$), we can determine the net exponent for each base dimension:\nFor the dimension of amount of substance, $N$:\n$$\\text{Exponent} = 1 - (m+n) = 1 - m - n$$\nFor the dimension of length, $L$:\n$$\\text{Exponent} = -3 - (-3(m+n)) = -3 + 3m + 3n = 3(m+n-1)$$\nFor the dimension of time, $T$:\n$$\\text{Exponent} = -1$$\nCombining these results, the dimensions of the rate constant $k$ are:\n$$[k] = N^{1-m-n} L^{3(m+n-1)} T^{-1}$$\nThe problem asks for the result to be expressed as an ordered triple of exponents $(\\alpha, \\beta, \\gamma)$ corresponding to the units $\\mathrm{mol}^{\\alpha}\\,\\mathrm{m}^{\\beta}\\,\\mathrm{s}^{\\gamma}$. By direct comparison with our derived dimensional expression, we identify:\n$$\\alpha = 1 - m - n$$\n$$\\beta = 3(m+n-1)$$\n$$\\gamma = -1$$\nThis result provides the exponents for the SI units of the rate constant $k$ as a function of the reaction orders $m$ and $n$, consistent with the principle of dimensional homogeneity. The requested format is a row vector of these exponents.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 - m - n & 3(m+n-1) & -1\n\\end{pmatrix}\n}\n$$", "id": "2961548"}, {"introduction": "A dimensionally consistent model is a necessary but not sufficient condition for its validity; it must also accurately describe experimental observations. A critical step in the scientific method is to rigorously test a proposed model against empirical data, distinguishing systematic model deficiencies from random measurement noise. This practice [@problem_id:2961596] guides you through a formal lack-of-fit test, a powerful statistical technique for model validation. By analyzing data from an ion-selective electrode, you will learn to quantitatively assess whether a simple linear Nernstian model is adequate or if the data reveal significant, systematic non-Nernstian behavior.", "problem": "An ion-selective electrode (monovalent cation, charge number $z=+1$) is calibrated in aqueous standards of ionic activity $a$ at temperature $T$ that is effectively constant. The Nernst relation for the mean electrode potential $E$ is the fundamental starting point:\n$$\nE \\;=\\; E^{\\circ} \\;+\\; \\frac{RT}{zF}\\,\\ln a \\;=\\; \\beta_0 \\;+\\; \\beta_1\\,x,\n$$\nwhere $R$ is the gas constant, $F$ is the Faraday constant, and $x=\\log_{10} a$ with $\\beta_1=\\left(\\frac{2.303\\,RT}{zF}\\right)$ in units of millivolts per decade when $E$ is reported in millivolts. Under ideal Nernstian behavior, the mean function $E(x)$ is linear in $x$ with slope fixed by thermodynamics, while realized measurements scatter about the line due to random error.\n\nTo assess model adequacy from first principles of statistical calibration and measurement theory, a residual-based lack-of-fit test partitions the total residual variability into a pure (replicate) error component and a systematic component attributable to model misspecification. Consider $k=5$ distinct standards with equal replicate count $r=3$ at each $x_i\\in\\{-5,-4,-3,-2,-1\\}$, corresponding to $a\\in\\{10^{-5},10^{-4},10^{-3},10^{-2},10^{-1}\\}$. The replicate sample means $\\bar y_i$ (in millivolts) and within-level sample variances $s_i^2$ (in millivolts squared) are:\n- $x_1=-5$: $\\bar y_1=254.2$, $s_1^2=1.21$,\n- $x_2=-4$: $\\bar y_2=295.36$, $s_2^2=0.81$,\n- $x_3=-3$: $\\bar y_3=340.52$, $s_3^2=0.64$,\n- $x_4=-2$: $\\bar y_4=389.68$, $s_4^2=0.64$,\n- $x_5=-1$: $\\bar y_5=442.84$, $s_5^2=0.81$.\n\nYou are to design and execute a residual-based lack-of-fit test for the Nernstian linear-in-$\\log_{10} a$ mean function using these replicated standards. Use only the following base definitions and laws:\n- The Nernst relation implies a linear mean function $E=\\beta_0+\\beta_1 x$ in the predictor $x=\\log_{10} a$ under ideal behavior.\n- An ordinary least squares fit of the linear mean function minimizes $\\sum_{i=1}^{k}\\sum_{j=1}^{r} \\big(y_{ij}-\\hat \\beta_0 - \\hat \\beta_1 x_i\\big)^2$.\n- For replicated $x_i$, the total residual sum of squares can be decomposed as\n$$\n\\mathrm{SSE} \\;=\\; \\underbrace{\\sum_{i=1}^{k}\\sum_{j=1}^{r}\\big(y_{ij}-\\bar y_i\\big)^2}_{\\text{pure error sum of squares, }SS_{\\mathrm{PE}}}\n\\;+\\;\n\\underbrace{\\sum_{i=1}^{k} r\\,\\big(\\bar y_i - \\hat y_i\\big)^2}_{\\text{lack-of-fit sum of squares, }SS_{\\mathrm{LOF}}},\n$$\nwhere $\\hat y_i=\\hat \\beta_0+\\hat \\beta_1 x_i$.\n- The lack-of-fit $F$-statistic is\n$$\nF \\;=\\; \\frac{SS_{\\mathrm{LOF}}/(k-p)}{SS_{\\mathrm{PE}}/(N-k)},\n$$\nwith $p=2$ parameters in the linear mean function, $N=kr$ total observations, and independent, identically distributed normal errors under the null hypothesis that the linear mean function is correct.\n\nTasks:\n- Fit the linear relation $E=\\beta_0+\\beta_1 x$ to the replicated data by first principles, obtaining $\\hat \\beta_0$ and $\\hat \\beta_1$ from the $k$ distinct $x_i$ and $\\bar y_i$ (you may use the fact that all $r$ are equal).\n- Compute $SS_{\\mathrm{PE}}$, $SS_{\\mathrm{LOF}}$, the corresponding degrees of freedom, and the lack-of-fit $F$-statistic and its qualitative $p$-value magnitude.\n- Interpret the pattern of the mean-residuals $\\bar y_i-\\hat y_i$ across $x$ in the context of Nernstian versus non-Nernstian behavior, making explicit reference to what pattern would be expected under ideality.\n\nWhich option best reflects the correct test outcome and interpretation?\n\nA. The linear Nernstian mean function is adequate: the lack-of-fit test is not significant (e.g., $p>0.05$), and the residuals versus $x$ show no systematic pattern.\n\nB. There is a highly significant lack-of-fit (e.g., $p\\ll 0.001$), with a symmetric, curved residual pattern (positive at extreme $x$, negative near the center) consistent with systematic non-Nernstian behavior such as activity-coefficient or junction-potential induced curvature; a higher-order or extended model is warranted.\n\nC. The apparent lack-of-fit arises from heteroscedastic noise (variance increasing with $|x|$) rather than mean-function misspecification; a variance-stabilizing transformation of $E$ removes the issue without changing the mean model.\n\nD. The lack-of-fit is driven by outliers at a single concentration level; exclusion of those replicates restores adequacy of the linear Nernstian mean without evidence of curvature.", "solution": "We proceed from first principles of the Nernst relation and the statistical definitions of residuals and sums of squares.\n\nStep 1: Mean function implied by Nernst. For a monovalent ion at fixed $T$, the Nernst equation implies a linear mean function in the predictor $x=\\log_{10} a$,\n$$\nE \\;=\\; \\beta_0 + \\beta_1 x,\n$$\nwith $\\beta_1=\\left(\\frac{2.303\\,RT}{F}\\right)$ under ideal Nernstian behavior. The adequacy question is whether the observed mean response across replicated standards is compatible with this linear mean function.\n\nStep 2: Fit the linear mean function to the $k=5$ distinct $x_i$ values using the $k$ cell means $\\bar y_i$ (this is justified because all $r=3$ are equal; the ordinary least squares estimate using all $N=kr=15$ points equals the weighted least squares fit to the $k$ means with equal weights). Let $\\bar x = \\frac{1}{k}\\sum_{i=1}^{k} x_i$ and $\\bar{\\bar y} = \\frac{1}{k}\\sum_{i=1}^{k} \\bar y_i$.\n\nCompute $\\bar x$:\n$$\n\\bar x \\;=\\; \\frac{(-5)+(-4)+(-3)+(-2)+(-1)}{5} \\;=\\; \\frac{-15}{5} \\;=\\; -3.\n$$\n\nCompute $\\bar{\\bar y}$:\n$$\n\\bar{\\bar y} \\;=\\; \\frac{254.2+295.36+340.52+389.68+442.84}{5} \\;=\\; \\frac{1722.6}{5} \\;=\\; 344.52.\n$$\n\nCompute the slope using $\\hat \\beta_1=\\dfrac{\\sum_{i=1}^{k} (x_i-\\bar x)(\\bar y_i-\\bar{\\bar y})}{\\sum_{i=1}^{k} (x_i-\\bar x)^2}$.\n\nFirst, $(x_i-\\bar x)$ are $\\{-2,-1,0,1,2\\}$, so $\\sum_{i=1}^{k} (x_i-\\bar x)^2 = 4+1+0+1+4 = 10$.\n\nNext, compute $(\\bar y_i-\\bar{\\bar y})$:\n- For $x=-5$: $254.2-344.52=-90.32$.\n- For $x=-4$: $295.36-344.52=-49.16$.\n- For $x=-3$: $340.52-344.52=-4.00$.\n- For $x=-2$: $389.68-344.52=45.16$.\n- For $x=-1$: $442.84-344.52=98.32$.\n\nThen $\\sum_{i=1}^{k} (x_i-\\bar x)(\\bar y_i-\\bar{\\bar y})$ equals\n$$\n(-2)(-90.32) + (-1)(-49.16) + 0(-4.00) + (1)(45.16) + (2)(98.32) \\;=\\; 180.64+49.16+0+45.16+196.64 \\;=\\; 471.6.\n$$\n\nTherefore,\n$$\n\\hat \\beta_1 \\;=\\; \\frac{471.6}{10} \\;=\\; 47.16,\n\\qquad\n\\hat \\beta_0 \\;=\\; \\bar{\\bar y} - \\hat \\beta_1 \\bar x \\;=\\; 344.52 - 47.16(-3) \\;=\\; 344.52 + 141.48 \\;=\\; 486.00.\n$$\n\nThe fitted mean function is thus\n$$\n\\hat y(x) \\;=\\; 486.00 + 47.16\\,x \\quad \\text{(millivolts)}.\n$$\n\nNote that the estimated slope $\\hat \\beta_1=47.16$ millivolts per decade is substantially below the ideal Nernstian value at typical laboratory temperatures (e.g., near $59$ millivolts per decade at $T\\approx 298\\,\\mathrm{K}$), which already suggests potential non-Nernstian behavior; however, the formal adequacy test uses replicated residuals.\n\nStep 3: Pure error sum of squares. By definition,\n$$\nSS_{\\mathrm{PE}} \\;=\\; \\sum_{i=1}^{k}\\sum_{j=1}^{r} (y_{ij}-\\bar y_i)^2.\n$$\nGiven the within-level sample variances $s_i^2$ computed from $r=3$ replicates, the identity $\\sum_{j=1}^{r} (y_{ij}-\\bar y_i)^2 = (r-1)s_i^2$ yields\n$$\nSS_{\\mathrm{PE}} \\;=\\; \\sum_{i=1}^{5} (r-1)\\,s_i^2 \\;=\\; 2\\,(1.21+0.81+0.64+0.64+0.81) \\;=\\; 2\\,(4.11) \\;=\\; 8.22.\n$$\nThe pure error degrees of freedom are $df_{\\mathrm{PE}}=N-k=15-5=10$, so\n$$\nMS_{\\mathrm{PE}} \\;=\\; \\frac{SS_{\\mathrm{PE}}}{df_{\\mathrm{PE}}} \\;=\\; \\frac{8.22}{10} \\;=\\; 0.822.\n$$\n\nStep 4: Lack-of-fit sum of squares. By definition,\n$$\nSS_{\\mathrm{LOF}} \\;=\\; \\sum_{i=1}^{k} r\\,(\\bar y_i - \\hat y_i)^2,\n$$\nwith $\\hat y_i=\\hat y(x_i)$. Compute $\\hat y_i$ and the mean residuals:\n- For $x=-5$: $\\hat y_1 = 486.00 + 47.16(-5) = 486.00 - 235.80 = 250.20$, so $\\bar y_1-\\hat y_1=254.20-250.20=4.00$.\n- For $x=-4$: $\\hat y_2 = 486.00 + 47.16(-4) = 486.00 - 188.64 = 297.36$, so $\\bar y_2-\\hat y_2=295.36-297.36=-2.00$.\n- For $x=-3$: $\\hat y_3 = 486.00 + 47.16(-3) = 486.00 - 141.48 = 344.52$, so $\\bar y_3-\\hat y_3=340.52-344.52=-4.00$.\n- For $x=-2$: $\\hat y_4 = 486.00 + 47.16(-2) = 486.00 - 94.32 = 391.68$, so $\\bar y_4-\\hat y_4=389.68-391.68=-2.00$.\n- For $x=-1$: $\\hat y_5 = 486.00 + 47.16(-1) = 486.00 - 47.16 = 438.84$, so $\\bar y_5-\\hat y_5=442.84-438.84=4.00$.\n\nThus,\n$$\nSS_{\\mathrm{LOF}} \\;=\\; 3\\left(4.00^2 + (-2.00)^2 + (-4.00)^2 + (-2.00)^2 + 4.00^2\\right)\n\\;=\\; 3\\,(16+4+16+4+16)\n\\;=\\; 3\\,(56)\n\\;=\\; 168.\n$$\nThe lack-of-fit degrees of freedom are $df_{\\mathrm{LOF}}=k-p=5-2=3$, so\n$$\nMS_{\\mathrm{LOF}} \\;=\\; \\frac{SS_{\\mathrm{LOF}}}{df_{\\mathrm{LOF}}} \\;=\\; \\frac{168}{3} \\;=\\; 56.0.\n$$\n\nStep 5: Lack-of-fit $F$-statistic and $p$-value. The test statistic comparing the mean-function misspecification to pure measurement error is\n$$\nF \\;=\\; \\frac{MS_{\\mathrm{LOF}}}{MS_{\\mathrm{PE}}} \\;=\\; \\frac{56.0}{0.822} \\;\\approx\\; 68.1,\n$$\nto be referenced to an $F$ distribution with $(df_{\\mathrm{LOF}},df_{\\mathrm{PE}})=(3,10)$ under the null hypothesis that the linear mean function $E=\\beta_0+\\beta_1 x$ is correct. The observed $F\\approx 68.1$ is extremely large; the corresponding $p$-value satisfies $p\\ll 0.001$ (indeed, numerically $p$ is far smaller than $0.001$), leading to a decisive rejection of the linear Nernstian mean function over this range.\n\nStep 6: Interpret the residual pattern. The mean residuals $\\bar y_i-\\hat y_i$ across $x$ are $\\{+4.00,-2.00,-4.00,-2.00,+4.00\\}$ for $x\\in\\{-5,-4,-3,-2,-1\\}$, showing a symmetric, curved pattern: positive at the extremes, most negative near the center. Under ideal Nernstian behavior, the residuals should be centered around zero without systematic structure across $x$. The observed pattern indicates curvature relative to the best-fitting line, consistent with non-Nernstian behavior such as systematic deviations due to activity-coefficient variation at higher ionic strength, liquid junction potentials, or interfering ions described by extended models (e.g., the Nikolskiiâ€“Eisenman formulation), and suggests that a higher-order calibration or a restricted linear working range is required. The within-level variances $s_i^2=\\{1.21,0.81,0.64,0.64,0.81\\}$ are comparable, arguing against heteroscedasticity as the primary cause.\n\nOption-by-option analysis:\n- Option A: Claims adequacy with nonsignificant lack-of-fit and no residual pattern. This contradicts the computed $F\\approx 68.1$ with $p\\ll 0.001$ and the evident curved residual structure. Incorrect.\n- Option B: States a highly significant lack-of-fit with a symmetric curved residual pattern indicating non-Nernstian behavior and recommends an extended model. This matches both the statistical outcome and the physical interpretation. Correct.\n- Option C: Attributes the issue to heteroscedasticity that can be addressed by transforming $E$. The within-level variances $s_i^2=\\{1.21,0.81,0.64,0.64,0.81\\}$ are comparable, and the mean residuals show systematic curvature rather than variance trends, so this does not explain the lack-of-fit. Incorrect.\n- Option D: Attributes lack-of-fit to outliers at a single level. The mean residuals are structured across multiple levels, and the lack-of-fit remains after averaging replicates, so a single-level outlier explanation is inconsistent with the data. Incorrect.", "answer": "$$\\boxed{B}$$", "id": "2961596"}, {"introduction": "Once a model has been validated, its primary purpose is often to estimate underlying physical parameters, such as the activation energy ($E_a$) from the Arrhenius equation. A parameter estimate is scientifically incomplete without a corresponding statement of its uncertainty. This advanced problem [@problem_id:2961572] delves into the propagation of uncertainty in a realistic scenario where both the independent variable ($1/T$) and the dependent variable ($\\ln k$) are subject to measurement error. Mastering this technique allows for a rigorous quantification of confidence in parameters extracted from complex experimental data.", "problem": "A kineticist measures temperature $T_i$ and rate constants $k_i$ for a unimolecular reaction at $n$ distinct conditions, with independent, unbiased, Gaussian measurement errors. The Arrhenius law states that $k = A \\exp(-E_a/(R T))$, where $A$ is the pre-exponential factor, $E_a$ is the activation energy, and $R$ is the universal gas constant. Define the transformed variables $x_i = 1/T_i$ and $y_i = \\ln k_i$. The linearized mean model is $y_i = \\alpha + \\beta x_i$ with $\\alpha = \\ln A$ and $\\beta = -E_a/R$.\n\nAssume the following measurement-theoretic model:\n1. The reported $T_i$ are noisy measurements of the true temperatures $T_i^{\\mathrm{true}}$ with standard uncertainties $u(T_i)$ (one-standard-deviation values), independent across $i$ and independent of all other errors.\n2. The reported $k_i$ are noisy measurements of the true rate constants $k_i^{\\mathrm{true}}$ with standard uncertainties $u(k_i)$, independent across $i$ and independent of the temperature errors.\n3. The uncertainties are sufficiently small that first-order uncertainty propagation is valid.\n\nUnder these conditions, $x_i = 1/T_i$ and $y_i = \\ln k_i$ inherit standard uncertainties\n$$\nu(x_i) \\approx \\frac{u(T_i)}{T_i^2}, \\qquad u(y_i) \\approx \\frac{u(k_i)}{k_i}.\n$$\nBecause $x_i$ appears as an input to the linear mean function $y_i = \\alpha + \\beta x_i$, the uncertainty in $x_i$ contributes to the dispersion in $y_i$ through first-order propagation, yielding a parameter-dependent diagonal covariance matrix for the responses with diagonal elements\n$$\nv_i(\\beta) \\equiv \\operatorname{Var}(y_i) \\approx u(y_i)^2 + \\beta^2 u(x_i)^2, \\quad i=1,\\dots,n.\n$$\nLet $X$ be the $n \\times 2$ design matrix with first column equal to $1$ and second column equal to $x_i$, and let $W(\\beta)$ be the diagonal weight matrix with entries $w_i(\\beta) = 1/v_i(\\beta)$.\n\nWorking from first principles of the maximum likelihood method under Gaussian errors and linearization, and treating the parameter dependence of $W(\\beta)$ by inserting the slope estimate $\\hat{\\beta}$ obtained at the maximum likelihood solution into $W(\\hat{\\beta})$ (that is, using the standard first-order feasible generalized least squares approximation to the information matrix), derive a closed-form analytical expression for the standard uncertainty of the activation energy $u(E_a)$ in terms of the weighted sums\n$$\nS_0 = \\sum_{i=1}^{n} w_i(\\hat{\\beta}), \\quad\nS_1 = \\sum_{i=1}^{n} w_i(\\hat{\\beta}) x_i, \\quad\nS_2 = \\sum_{i=1}^{n} w_i(\\hat{\\beta}) x_i^2,\n$$\nwhere $w_i(\\hat{\\beta}) = 1/\\big(u(y_i)^2 + \\hat{\\beta}^{\\,2} u(x_i)^2\\big)$, and $\\hat{\\beta}$ is the maximum likelihood estimate of $\\beta$ under the same model. Your final expression must be a single closed-form expression for $u(E_a)$ in terms of $R$, $S_0$, $S_1$, and $S_2$ as defined above. Do not numerically evaluate your result. If you choose to reference the energy unit, it is joules per mole when $R$ is expressed in joules per mole-kelvin; however, do not include units in your final boxed expression.", "solution": "The problem as stated is subjected to validation.\n\n**Step 1: Extract Givens**\n- Data: $n$ pairs of temperature and rate constant measurements, $(T_i, k_i)$.\n- Model: The Arrhenius law, $k = A \\exp(-E_a/(R T))$, is linearized to $y_i = \\alpha + \\beta x_i$ via the transformations $x_i = 1/T_i$ and $y_i = \\ln k_i$.\n- Parameter definitions: $\\alpha = \\ln A$ and $\\beta = -E_a/R$.\n- Error structure: Independent, unbiased, Gaussian errors in both $T_i$ and $k_i$, with standard uncertainties $u(T_i)$ and $u(k_i)$.\n- Uncertainty propagation: For the transformed variables, $u(x_i) \\approx u(T_i)/T_i^2$ and $u(y_i) \\approx u(k_i)/k_i$.\n- Variance of response: The total variance of each $y_i$, accounting for uncertainty in $x_i$, is $v_i(\\beta) = \\operatorname{Var}(y_i) \\approx u(y_i)^2 + \\beta^2 u(x_i)^2$.\n- Statistical method: Maximum likelihood estimation, which for this model corresponds to weighted least squares with weights $w_i(\\beta) = 1/v_i(\\beta)$. The problem specifies using the feasible generalized least squares approximation where the final estimate $\\hat{\\beta}$ is used to compute the weights $w_i(\\hat{\\beta})$.\n- Matrix definitions: $X$ is the $n \\times 2$ design matrix, $W(\\beta)$ is the diagonal weight matrix.\n- Summary statistics: $S_0 = \\sum_{i=1}^{n} w_i(\\hat{\\beta})$, $S_1 = \\sum_{i=1}^{n} w_i(\\hat{\\beta}) x_i$, and $S_2 = \\sum_{i=1}^{n} w_i(\\hat{\\beta}) x_i^2$.\n- Objective: Derive a closed-form expression for the standard uncertainty of the activation energy, $u(E_a)$, in terms of $R$, $S_0$, $S_1$, and $S_2$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Soundness**: The problem is anchored in fundamental principles of chemical kinetics (Arrhenius law) and established statistical theory (maximum likelihood, generalized least squares, error propagation). It is scientifically rigorous.\n- **Well-Posedness**: The problem is clearly specified. It defines the model, the data structure, the error assumptions, and the estimation methodology, leading to a unique, derivable result.\n- **Objectivity**: The problem is stated in precise, objective, and quantitative language.\n- **Completeness**: All necessary information, definitions, and constraints for the derivation are provided. The problem is self-contained.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a standard, albeit non-trivial, exercise in advanced data analysis for physical chemistry. The solution will now be derived from first principles as requested.\n\nThe objective is to find the standard uncertainty of the activation energy, $u(E_a)$. The estimation of parameters $(\\alpha, \\beta)$ of the linear model $y_i = \\alpha + \\beta x_i$ is based on minimizing a weighted sum of squares, which is equivalent to maximizing the Gaussian log-likelihood. The quantity to be minimized is:\n$$\nS(\\alpha, \\beta) = \\sum_{i=1}^{n} w_i(\\beta) (y_i - \\alpha - \\beta x_i)^2\n$$\nwhere the weights $w_i(\\beta) = 1/v_i(\\beta)$ are themselves functions of the parameter $\\beta$. In matrix form, we minimize $S(\\boldsymbol{\\theta}) = (\\mathbf{y} - X\\boldsymbol{\\theta})^T W(\\beta) (\\mathbf{y} - X\\boldsymbol{\\theta})$, where $\\boldsymbol{\\theta} = \\begin{pmatrix} \\alpha & \\beta \\end{pmatrix}^T$.\n\nThe problem states to use the standard feasible generalized least squares (GLS) approximation. In this framework, the covariance matrix of the estimated parameter vector $\\hat{\\boldsymbol{\\theta}}$ is given by the inverse of the Fisher information matrix, which is approximated as $(X^T W(\\hat{\\beta}) X)^{-1}$. Here, $W(\\hat{\\beta})$ is the weight matrix evaluated at the maximum likelihood estimate of the slope, $\\hat{\\beta}$.\n\nLet $\\mathbf{C}_{\\hat{\\boldsymbol{\\theta}}}$ be the covariance matrix of the estimated parameters $\\hat{\\alpha}$ and $\\hat{\\beta}$.\n$$\n\\mathbf{C}_{\\hat{\\boldsymbol{\\theta}}} = \\operatorname{Cov}(\\hat{\\boldsymbol{\\theta}}) \\approx \\left( X^T W(\\hat{\\beta}) X \\right)^{-1}\n$$\nThe design matrix $X$ and the diagonal weight matrix $W(\\hat{\\beta})$ are:\n$$\nX = \\begin{pmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{pmatrix}, \\qquad W(\\hat{\\beta}) = \\operatorname{diag}\\left(w_1(\\hat{\\beta}), w_2(\\hat{\\beta}), \\dots, w_n(\\hat{\\beta})\\right)\n$$\nWe compute the matrix product $X^T W(\\hat{\\beta}) X$. For notational simplicity, let $w_i = w_i(\\hat{\\beta})$.\n$$\nX^T W(\\hat{\\beta}) X = \\begin{pmatrix} 1 & 1 & \\dots & 1 \\\\ x_1 & x_2 & \\dots & x_n \\end{pmatrix} \\begin{pmatrix} w_1 & 0 & \\dots & 0 \\\\ 0 & w_2 & \\dots & 0 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\dots & w_n \\end{pmatrix} \\begin{pmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{pmatrix}\n$$\nPerforming the multiplication yields a $2 \\times 2$ matrix:\n$$\nX^T W(\\hat{\\beta}) X = \\begin{pmatrix} \\sum_{i=1}^{n} w_i & \\sum_{i=1}^{n} w_i x_i \\\\ \\sum_{i=1}^{n} w_i x_i & \\sum_{i=1}^{n} w_i x_i^2 \\end{pmatrix}\n$$\nUsing the definitions provided in the problem statement:\n$S_0 = \\sum_{i=1}^{n} w_i$, $S_1 = \\sum_{i=1}^{n} w_i x_i$, and $S_2 = \\sum_{i=1}^{n} w_i x_i^2$.\nThe matrix can be written concisely as:\n$$\nX^T W(\\hat{\\beta}) X = \\begin{pmatrix} S_0 & S_1 \\\\ S_1 & S_2 \\end{pmatrix}\n$$\nThe covariance matrix $\\mathbf{C}_{\\hat{\\boldsymbol{\\theta}}}$ is the inverse of this matrix. The determinant of this matrix is $\\det(X^T W(\\hat{\\beta}) X) = S_0 S_2 - S_1^2$. The inverse is:\n$$\n\\mathbf{C}_{\\hat{\\boldsymbol{\\theta}}} = \\begin{pmatrix} S_0 & S_1 \\\\ S_1 & S_2 \\end{pmatrix}^{-1} = \\frac{1}{S_0 S_2 - S_1^2} \\begin{pmatrix} S_2 & -S_1 \\\\ -S_1 & S_0 \\end{pmatrix}\n$$\nThis matrix contains the variances and covariance of the parameter estimates:\n$$\n\\mathbf{C}_{\\hat{\\boldsymbol{\\theta}}} = \\begin{pmatrix} \\operatorname{Var}(\\hat{\\alpha}) & \\operatorname{Cov}(\\hat{\\alpha}, \\hat{\\beta}) \\\\ \\operatorname{Cov}(\\hat{\\alpha}, \\hat{\\beta}) & \\operatorname{Var}(\\hat{\\beta}) \\end{pmatrix}\n$$\nBy inspection, the variance of the slope estimate $\\hat{\\beta}$ is the $(2,2)$ element of this matrix:\n$$\n\\operatorname{Var}(\\hat{\\beta}) = \\frac{S_0}{S_0 S_2 - S_1^2}\n$$\nThe standard uncertainty of $\\hat{\\beta}$, denoted $u(\\hat{\\beta})$, is the square root of its variance:\n$$\nu(\\hat{\\beta}) = \\sqrt{\\operatorname{Var}(\\hat{\\beta})} = \\sqrt{\\frac{S_0}{S_0 S_2 - S_1^2}}\n$$\nThe activation energy $E_a$ is related to $\\beta$ through the definition $\\beta = -E_a/R$, which rearranges to $E_a = -R\\beta$. The corresponding estimate is $\\hat{E}_a = -R\\hat{\\beta}$. To find the uncertainty in $E_a$, we use first-order propagation of uncertainty. Since $R$ is a defined constant with no uncertainty:\n$$\nu(E_a)^2 \\approx \\left( \\frac{\\partial E_a}{\\partial \\beta} \\right)^2 u(\\hat{\\beta})^2\n$$\nThe partial derivative is:\n$$\n\\frac{\\partial E_a}{\\partial \\beta} = \\frac{\\partial}{\\partial \\beta}(-R\\beta) = -R\n$$\nSubstituting this into the propagation formula:\n$$\nu(E_a)^2 = (-R)^2 u(\\hat{\\beta})^2 = R^2 u(\\hat{\\beta})^2\n$$\nTaking the square root and noting that the universal gas constant $R$ and standard uncertainties are non-negative quantities, we find:\n$$\nu(E_a) = R \\cdot u(\\hat{\\beta})\n$$\nFinally, substituting the expression for $u(\\hat{\\beta})$ gives the desired result:\n$$\nu(E_a) = R \\sqrt{\\frac{S_0}{S_0 S_2 - S_1^2}}\n$$\nThis is the closed-form analytical expression for the standard uncertainty of the activation energy, derived from the specified principles and expressed in terms of the given quantities.", "answer": "$$\n\\boxed{R \\sqrt{\\frac{S_0}{S_0 S_2 - S_1^2}}}\n$$", "id": "2961572"}]}