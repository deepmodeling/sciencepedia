{"hands_on_practices": [{"introduction": "In experimental chemistry, most quantities of interest are not measured directly but are calculated from other measured variables. This practice solidifies the foundational skill of propagating uncertainty through a calculation, a cornerstone of rigorous data analysis. You will apply the standard rules for error propagation to determine the uncertainty in an equilibrium constant, a common task that reinforces how different mathematical operations weight the contributions of individual measurement uncertainties. [@problem_id:2952265]", "problem": "A reversible dimerization reaction of a solute in aqueous solution is monitored spectrophotometrically at constant temperature, $2\\,\\mathrm{R} \\rightleftharpoons \\mathrm{P},$ for which the equilibrium constant in terms of molar concentrations is defined as $K = \\frac{c_{\\mathrm{P}}}{\\left(c_{\\mathrm{R}}\\right)^{2}},$ where $c_{\\mathrm{P}}$ and $c_{\\mathrm{R}}$ denote the equilibrium molar concentrations of product and reactant, respectively. The concentration $c_{\\mathrm{P}}$ is obtained from a calibrated absorbance using a single-wavelength Beer–Lambert determination, and $c_{\\mathrm{R}}$ is obtained from a separate multiwavelength fit; the two determinations are statistically independent. Treat the reported uncertainties as relative standard uncertainties (one standard deviation) arising from random effects only, and assume that the uncertainties are sufficiently small for first-order linearization to be valid. The relative standard uncertainties are $u_{r}\\!\\left(c_{\\mathrm{P}}\\right)=5\\%$ and $u_{r}\\!\\left(c_{\\mathrm{R}}\\right)=2\\%$, where, by definition, $u_{r}(x)=\\frac{u(x)}{x}$ and $u(x)$ is the standard uncertainty of $x$. Under these conditions, compute the relative standard uncertainty of $K$, denoted $u_{r}(K)$. Round your final answer to $3$ significant figures and express it as a pure decimal (no percent sign). The final answer must be a single real number.", "solution": "The problem statement has been scrutinized and is found to be scientifically grounded, well-posed, and free of contradictions or ambiguities. The premises are physically realistic and all necessary information for a unique solution is provided. The task is a standard application of the principles of uncertainty propagation in metrology, a fundamental concept in experimental science. Therefore, we proceed with the solution.\n\nThe problem requires the calculation of the relative standard uncertainty of the equilibrium constant, $u_r(K)$, given the relative standard uncertainties of the concentrations from which it is derived. The equilibrium constant $K$ is defined by the function:\n$$K = \\frac{c_{\\mathrm{P}}}{\\left(c_{\\mathrm{R}}\\right)^{2}}$$\nwhere $c_{\\mathrm{P}}$ is the molar concentration of the product and $c_{\\mathrm{R}}$ is the molar concentration of the reactant. The problem states that the measurements of $c_{\\mathrm{P}}$ and $c_{\\mathrm{R}}$ are statistically independent.\n\nFor a general function of the form $Y = f(X_1, X_2, \\dots, X_n)$, where the input quantities $X_i$ are independent, the square of the combined standard uncertainty, $u^2(Y)$, is given by the law of propagation of uncertainty:\n$$u^2(Y) = \\sum_{i=1}^{n} \\left(\\frac{\\partial f}{\\partial X_i}\\right)^2 u^2(X_i)$$\nThis can be expressed in terms of relative uncertainties. For a function that is a product of powers, such as $Y = C X_1^{a_1} X_2^{a_2} \\cdots X_n^{a_n}$, where $C$ is a constant with no uncertainty, the square of the relative standard uncertainty, $u_r^2(Y)$, simplifies to a weighted sum of the squares of the individual relative standard uncertainties:\n$$u_r^2(Y) = \\left(\\frac{u(Y)}{Y}\\right)^2 = \\sum_{i=1}^{n} a_i^2 \\left(\\frac{u(X_i)}{X_i}\\right)^2 = \\sum_{i=1}^{n} a_i^2 u_r^2(X_i)$$\nThe equilibrium constant is of this form, which can be written as $K = c_{\\mathrm{P}}^{1} c_{\\mathrm{R}}^{-2}$. The variables are $c_{\\mathrm{P}}$ and $c_{\\mathrm{R}}$, with corresponding exponents $a_{\\mathrm{P}} = 1$ and $a_{\\mathrm{R}} = -2$.\n\nApplying the simplified rule for propagation of relative uncertainties, the square of the relative standard uncertainty of $K$ is:\n$$u_r^2(K) = (a_{\\mathrm{P}})^2 u_r^2(c_{\\mathrm{P}}) + (a_{\\mathrm{R}})^2 u_r^2(c_{\\mathrm{R}})$$\nSubstituting the exponents $a_{\\mathrm{P}} = 1$ and $a_{\\mathrm{R}} = -2$:\n$$u_r^2(K) = (1)^2 u_r^2(c_{\\mathrm{P}}) + (-2)^2 u_r^2(c_{\\mathrm{R}})$$\n$$u_r^2(K) = u_r^2(c_{\\mathrm{P}}) + 4 u_r^2(c_{\\mathrm{R}})$$\nThe problem provides the following relative standard uncertainties:\n$$u_{r}(c_{\\mathrm{P}}) = 5\\% = 0.05$$\n$$u_{r}(c_{\\mathrm{R}}) = 2\\% = 0.02$$\nWe substitute these numerical values into the derived equation:\n$$u_r^2(K) = (0.05)^2 + 4(0.02)^2$$\nThe calculation proceeds as follows:\n$$u_r^2(K) = 0.0025 + 4(0.0004)$$\n$$u_r^2(K) = 0.0025 + 0.0016$$\n$$u_r^2(K) = 0.0041$$\nTo find the relative standard uncertainty $u_r(K)$, we take the square root of this value:\n$$u_r(K) = \\sqrt{0.0041}$$\n$$u_r(K) \\approx 0.06403124237$$\nThe problem requires the final answer to be rounded to $3$ significant figures. The first non-zero digit is $6$, so the three significant figures are $6$, $4$, and $0$.\n$$u_r(K) = 0.0640$$\nThis is the final numerical answer expressed as a pure decimal.", "answer": "$$\\boxed{0.0640}$$", "id": "2952265"}, {"introduction": "The precision of a final result depends not only on measurement uncertainty but also on the computational methods used in data processing. This exercise addresses the critical issue of numerical stability by examining \"catastrophic cancellation,\" a phenomenon where subtracting nearly equal numbers can lead to a drastic loss of significant figures. By algebraically reformulating a problematic expression, you will learn a vital technique to preserve precision and ensure the accuracy of your computational results. [@problem_id:2952312]", "problem": "A recurring numerical pattern in data processing for general chemistry experiments is the evaluation of small differences between large quantities, which risks losing significant figures due to subtractive cancellation. Consider the function $f(x) = \\sqrt{x+1} - \\sqrt{x}$ for large positive $x$. This pattern can arise, for example, when comparing adjacent readings of a detector whose response scales as a square root of an underlying signal intensity.\n\nYou will use two ingredients as the fundamental base: (i) exact algebra over the real numbers and (ii) the core definitions of significant figures and rounding in finite-precision decimal arithmetic.\n\nTasks:\n1) Using only exact algebra, derive an expression for $f(x)$ that is mathematically equivalent but avoids direct subtraction of two nearly equal square roots.\n2) Consider a decimal arithmetic model with exactly five significant figures retained at every elementary operation (addition, subtraction, multiplication, division, and square root), using rounding to nearest with ties to even. Starting from $x$ represented as $x_{0} = 1.0000 \\times 10^{8}$ within this model, evaluate $f(x)$ at $x = 10^{8}$:\n   - First by the direct expression $f_{\\text{naive}} = \\sqrt{x+1} - \\sqrt{x}$, applying rounding after each operation as specified.\n   - Second by the algebraic expression you derived in part (1), applying the same rounding rules after each operation.\n   Show the rounded intermediate values that lead to each result to explicitly demonstrate catastrophic cancellation in the first case.\n3) Let $f_{\\text{true}}$ denote the exact real value of $f(10^{8})$ (no rounding). Compute the absolute relative error of the stable evaluation from part (2), defined as $\\left|f_{\\text{stable}} - f_{\\text{true}}\\right|/|f_{\\text{true}}|$, where $f_{\\text{stable}}$ is the result from the algebraically reformulated expression under the five-significant-figure rounding model.\n\nProvide your final answer for the absolute relative error as a decimal number, with no units, and round your final answer to four significant figures.", "solution": "We begin from fundamental principles: real algebra and the definitions of significant figures and rounding. Catastrophic cancellation occurs when subtracting nearly equal numbers, causing the leading significant digits to cancel and leaving a result that contains mostly rounding error. To mitigate this, one should reformulate expressions to avoid such subtractions whenever possible.\n\nPart (1): Algebraic reformulation.\nLet $f(x) = \\sqrt{x+1} - \\sqrt{x}$ for $x > 0$. Multiply numerator and denominator by the conjugate:\n$$\nf(x) = \\left(\\sqrt{x+1} - \\sqrt{x}\\right)\\frac{\\sqrt{x+1} + \\sqrt{x}}{\\sqrt{x+1} + \\sqrt{x}} = \\frac{(x+1) - x}{\\sqrt{x+1} + \\sqrt{x}} = \\frac{1}{\\sqrt{x+1} + \\sqrt{x}}.\n$$\nThis identity is exact over the real numbers and avoids subtracting two nearly equal quantities when $x$ is large.\n\nPart (2): Five-significant-figure decimal arithmetic with rounding to nearest, ties to even, after each elementary operation. We start from $x_{0} = 1.0000 \\times 10^{8}$ as the representable value of $x$.\n\nNaive pathway $f_{\\text{naive}} = \\sqrt{x+1} - \\sqrt{x}$ with rounding after each operation:\n- Compute $x + 1$: the exact real is $100000000 + 1 = 100000001$. Rounding to five significant figures gives $1.0000 \\times 10^{8}$, because $100000001$ rounded to five significant figures is $100000000$ (the sixth significant digit is $0$, so rounding yields $1.0000 \\times 10^{8}$).\n- Compute $\\sqrt{x}$: $\\sqrt{1.0000 \\times 10^{8}}$ is exactly $10000$ in real arithmetic. Rounded to five significant figures, this is $1.0000 \\times 10^{4}$.\n- Compute $\\sqrt{x+1}$: since rounding has returned $x+1$ to $1.0000 \\times 10^{8}$, we get the same square root, $\\sqrt{x+1} \\to 1.0000 \\times 10^{4}$ after rounding.\n- Subtract: $(1.0000 \\times 10^{4}) - (1.0000 \\times 10^{4}) = 0$. After rounding to five significant figures, this remains $0$.\nThus $f_{\\text{naive}} = 0$ in this arithmetic, which demonstrates catastrophic cancellation: all significant digits are lost.\n\nStable pathway $f_{\\text{stable}} = \\dfrac{1}{\\sqrt{x+1} + \\sqrt{x}}$ with rounding after each operation:\n- As above, $\\sqrt{x} \\to 1.0000 \\times 10^{4}$ and $\\sqrt{x+1} \\to 1.0000 \\times 10^{4}$ after rounding to five significant figures at each step.\n- Sum: $(1.0000 \\times 10^{4}) + (1.0000 \\times 10^{4}) = 2.0000 \\times 10^{4}$ (already in five significant figures).\n- Reciprocal: $1 / (2.0000 \\times 10^{4}) = 5.0000 \\times 10^{-5}$ after rounding to five significant figures.\nTherefore $f_{\\text{stable}} = 5.0000 \\times 10^{-5}$ in the five-significant-figure arithmetic.\n\nPart (3): Absolute relative error of the stable evaluation.\nThe exact real value at $x = 10^{8}$ is\n$$\nf_{\\text{true}} = \\sqrt{100000001} - \\sqrt{100000000} = \\frac{1}{\\sqrt{100000001} + \\sqrt{100000000}} = \\frac{1}{\\sqrt{100000001} + 10000}.\n$$\nTo quantify the error, we approximate $\\sqrt{100000001}$ analytically. Write\n$$\n\\sqrt{100000001} = 10000 \\sqrt{1 + 10^{-8}}.\n$$\nUsing the binomial series for the square root,\n$$\n\\sqrt{1 + \\varepsilon} = 1 + \\frac{1}{2}\\varepsilon - \\frac{1}{8}\\varepsilon^{2} + \\frac{1}{16}\\varepsilon^{3} - \\frac{5}{128}\\varepsilon^{4} + \\cdots,\n$$\nwith $\\varepsilon = 10^{-8}$, we obtain\n$$\n\\sqrt{100000001} = 10000\\left(1 + \\frac{1}{2}\\cdot 10^{-8} - \\frac{1}{8}\\cdot 10^{-16} + O(10^{-24})\\right)\n= 10000 + 5 \\times 10^{-5} - 1.25 \\times 10^{-13} + O(10^{-21}).\n$$\nThus\n$$\nf_{\\text{true}} = \\left(10000 + 5 \\times 10^{-5} - 1.25 \\times 10^{-13} + \\cdots\\right) - 10000\n= 5 \\times 10^{-5} - 1.25 \\times 10^{-13} + O(10^{-21}).\n$$\nThe stable finite-precision result is $f_{\\text{stable}} = 5.0000 \\times 10^{-5}$. Hence the absolute relative error is\n$$\n\\frac{|f_{\\text{stable}} - f_{\\text{true}}|}{|f_{\\text{true}}|}\n= \\frac{\\left|5.0000 \\times 10^{-5} - \\left(5 \\times 10^{-5} - 1.25 \\times 10^{-13} + O(10^{-21})\\right)\\right|}{5 \\times 10^{-5} - 1.25 \\times 10^{-13} + O(10^{-21})}\n= \\frac{1.25 \\times 10^{-13} + O(10^{-21})}{5 \\times 10^{-5} - 1.25 \\times 10^{-13} + O(10^{-21})}.\n$$\nNeglecting the $O(10^{-21})$ terms, this is\n$$\n\\frac{1.25 \\times 10^{-13}}{5 \\times 10^{-5} - 1.25 \\times 10^{-13}}\n= \\frac{1.25 \\times 10^{-13}}{4.9999999999875 \\times 10^{-5}}.\n$$\nCompute the leading value:\n$$\n\\frac{1.25 \\times 10^{-13}}{5 \\times 10^{-5}} = 2.5 \\times 10^{-9},\n$$\nand the correction from replacing $5 \\times 10^{-5}$ by $5 \\times 10^{-5} - 1.25 \\times 10^{-13}$ changes the result only in the ninth significant figure. Therefore, to four significant figures,\n$$\n\\frac{|f_{\\text{stable}} - f_{\\text{true}}|}{|f_{\\text{true}}|} = 2.500 \\times 10^{-9}.\n$$\nThis confirms that the algebraic reformulation preserves essentially all significant figures in this case, in stark contrast to the naive subtraction which yielded $0$ under the specified rounding model.\n\nRounded to four significant figures as required, the final numerical value is $2.500 \\times 10^{-9}$.", "answer": "$$\\boxed{2.500 \\times 10^{-9}}$$", "id": "2952312"}, {"introduction": "While analytical methods for uncertainty propagation are essential, they can become unwieldy or inaccurate for complex, non-linear models or when data are subject to physical constraints. This advanced practice introduces the Monte Carlo method, a powerful computational technique for simulating uncertainty that elegantly handles such complexities. You will implement a simulation to model a common scenario in spectroscopy—censored data—and discover how this more realistic approach provides a more accurate assessment of uncertainty than idealized models. [@problem_id:2952283]", "problem": "You are modeling measurement and reporting for a spectroscopy-based concentration assay in general chemistry under a physically meaningful censoring constraint. A detector returns a baseline-corrected absorbance $A$ that, by the physics of absorption and the calibration pipeline, must satisfy $A \\ge 0$. The pre-censoring noise can be modeled with a Normal distribution with mean $\\mu_A$ and standard deviation $\\sigma_A$, which is a widely accepted empirical model for many instrumental noise sources. The concentration $c$ of the analyte is related to the absorbance by a linear calibration that follows Beer–Lambert law: $c = A / (\\varepsilon \\, \\ell)$, where $\\varepsilon$ is the molar absorptivity and $\\ell$ is the optical path length. You will demonstrate that Monte Carlo propagation can directly accommodate the censoring $A \\ge 0$ by sampling from the correctly truncated distribution, and you will show how censoring affects the mean and the central $95\\%$ credible interval of $c$ compared to an uncensored model.\n\nFundamental bases you may use: the law of large numbers, definitions of expected value and quantiles, properties of the Normal distribution, and the Beer–Lambert law. Do not use any closed-form formulas for truncated Normal moments. You must approximate by Monte Carlo sampling.\n\nDefinitions to use:\n- The expected value of a random variable $Z$ is $\\mathbb{E}[Z]$.\n- The central $95\\%$ credible interval of a sample of $Z$ is the interval between the empirical quantiles at probabilities $0.025$ and $0.975$.\n- A censored (truncated) Normal for $A$ enforces $A \\ge 0$ by drawing from the Normal distribution and rejecting values $A < 0$; programmatically you must draw directly from the truncated distribution to avoid inefficiency.\n- For reporting with significant figures, let $m$ be the Monte Carlo estimate of the mean of $c$ and let $L$ and $U$ be the lower and upper bounds of the central $95\\%$ credible interval. Define the half-width $h = (U - L)/2$. To create a report compliant with common uncertainty-reporting practice in general chemistry, round $h$ to one significant figure, and then round $m$ to the same decimal place as the rounded $h$. Then, report the rounded interval as $[m - h_{\\mathrm{rounded}}, \\, m + h_{\\mathrm{rounded}}]$. This produces values consistent with significant-figure rules tied to uncertainty. All concentrations must be expressed in $\\mathrm{mol}\\,\\mathrm{L}^{-1}$.\n\nYour program must, for each test case, perform both of the following Monte Carlo propagations with the same number of draws $N$:\n- Uncensored model: draw $A_{\\mathrm{unc}} \\sim \\mathcal{N}(\\mu_A, \\sigma_A^2)$ without enforcing $A \\ge 0$.\n- Censored model: draw $A_{\\mathrm{cen}} \\sim \\mathcal{N}(\\mu_A, \\sigma_A^2)$ truncated to $A \\ge 0$.\n\nThen transform to concentration by $c = A/(\\varepsilon \\, \\ell)$ to obtain samples $c_{\\mathrm{unc}}$ and $c_{\\mathrm{cen}}$. For each model, compute the sample mean $m$, the central $95\\%$ credible interval $[L, U]$, the half-width $h = (U-L)/2$, and then produce the rounded triple $(m_{\\mathrm{rounded}}, L_{\\mathrm{rounded}}, U_{\\mathrm{rounded}})$ as defined above.\n\nPhysical units:\n- Report and internally compute $c$ in $\\mathrm{mol}\\,\\mathrm{L}^{-1}$, $\\varepsilon$ in $\\mathrm{L}\\,\\mathrm{mol}^{-1}\\,\\mathrm{cm}^{-1}$, $\\ell$ in $\\mathrm{cm}$, and $A$ unitless. Your final program output must be numerical floats representing $\\mathrm{mol}\\,\\mathrm{L}^{-1}$; do not print units.\n\nAngle units are not applicable.\n\nTest suite:\nUse $N = 200{,}000$ draws per test case and the following parameter sets to exercise distinct regimes. Each case is a tuple $(\\mu_A, \\sigma_A, \\varepsilon, \\ell)$.\n- Case $1$ (well above the censoring threshold; censoring negligible): $(\\mu_A = 0.500, \\ \\sigma_A = 0.010, \\ \\varepsilon = 12500, \\ \\ell = 1.00)$.\n- Case $2$ (near the threshold; moderate skew from censoring): $(\\mu_A = 0.050, \\ \\sigma_A = 0.050, \\ \\varepsilon = 12500, \\ \\ell = 1.00)$.\n- Case $3$ (close to zero; strong censoring effect): $(\\mu_A = 0.005, \\ \\sigma_A = 0.010, \\ \\varepsilon = 12500, \\ \\ell = 1.00)$.\n- Case $4$ (negative mean; physical constraint dominates): $(\\mu_A = -0.002, \\ \\sigma_A = 0.005, \\ \\varepsilon = 12500, \\ \\ell = 1.00)$.\n\nAnswer specification:\n- For each test case, compute two rounded triples $(m_{\\mathrm{unc}}, L_{\\mathrm{unc}}, U_{\\mathrm{unc}})$ and $(m_{\\mathrm{cen}}, L_{\\mathrm{cen}}, U_{\\mathrm{cen}})$, each in $\\mathrm{mol}\\,\\mathrm{L}^{-1}$ and rounded by the significant-figure rule above.\n- Aggregate each test case’s results into a list of six floats in the order: $[m_{\\mathrm{unc}}, L_{\\mathrm{unc}}, U_{\\mathrm{unc}}, m_{\\mathrm{cen}}, L_{\\mathrm{cen}}, U_{\\mathrm{cen}}]$.\n- Final output format: your program should produce a single line of output containing a list of the four per-case lists, for the four cases in the order given above. For example, the outer structure must look like $[[\\dots],[\\dots],[\\dots],[\\dots]]$ with numeric floats.\n\nScientific realism:\n- Use a fixed random seed to ensure reproducible results.\n- Do not assume any closed forms for truncated moments; approximate by sampling.\n- Ensure that censoring is implemented by sampling from the truncated Normal distribution.\n\nYour program must produce only the specified single-line output and nothing else. All numerical answers represent concentrations in $\\mathrm{mol}\\,\\mathrm{L}^{-1}$, rounded according to the stated significant-figure rule.", "solution": "The problem presented requires a quantitative analysis of a physically motivated censoring constraint in a common analytical chemistry scenario. We are to compare an idealized, uncensored model of a measurement with a more realistic, censored model where the physical quantity, absorbance, cannot be negative. The comparison is to be performed using Monte Carlo uncertainty propagation. The problem, as stated, is scientifically sound, well-posed, and provides all necessary information for a rigorous computational solution. We shall proceed.\n\nThe core of the problem lies in the propagation of uncertainty from a noisy absorbance measurement, $A$, to a derived concentration, $c$. The relationship between these quantities is given by the Beer-Lambert law:\n$$ c = \\frac{A}{\\varepsilon \\ell} $$\nwhere $\\varepsilon$ is the molar absorptivity and $\\ell$ is the optical path length. For convenience, we define a constant $k = \\varepsilon \\ell$ for each experimental setup, so that $c = A/k$.\n\nThe problem specifies two models for the absorbance measurement, $A$:\n\n1.  **Uncensored Model**: This is an idealized model where the measurement noise is assumed to be perfectly Gaussian. We generate a large number, $N$, of absorbance samples, $\\{A_{\\mathrm{unc}, i}\\}_{i=1}^N$, by drawing from a Normal distribution, $A_{\\mathrm{unc}} \\sim \\mathcal{N}(\\mu_A, \\sigma_A^2)$. This model can produce non-physical negative absorbance values.\n\n2.  **Censored Model**: This model incorporates the physical constraint that absorbance cannot be negative, $A \\ge 0$. We generate $N$ samples, $\\{A_{\\mathrm{cen}, i}\\}_{i=1}^N$, by drawing from the same Normal distribution, $\\mathcal{N}(\\mu_A, \\sigma_A^2)$, but truncated to the interval $[0, \\infty)$. This is the correct statistical representation of a measurement process that is fundamentally non-negative. Programmatically, this is achieved by sampling from a truncated Normal distribution, which is more efficient than a naive reject/accept loop.\n\nFor both models, each absorbance sample $A_i$ is transformed into a concentration sample $c_i = A_i/k$. This yields two sets of concentration samples, $\\{c_{\\mathrm{unc}, i}\\}$ and $\\{c_{\\mathrm{cen}, i}\\}$.\n\nFrom these samples, we perform statistical analysis as prescribed. For each set:\n- The mean concentration, $m$, is estimated as the sample mean: $m \\approx \\frac{1}{N} \\sum_{i=1}^{N} c_i$.\n- The central $95\\%$ credible interval, $[L, U]$, is determined by the empirical quantiles of the concentration samples at probabilities $p=0.025$ and $p=0.975$.\n- A reporting-friendly interval is constructed based on a specified rounding procedure. The half-width of the credible interval, $h = (U - L)/2$, is calculated and rounded to one significant figure to obtain $h_{\\mathrm{rounded}}$. The mean, $m$, is then rounded to the same decimal place as $h_{\\mathrm{rounded}}$, yielding $m_{\\mathrm{rounded}}$. The final reported interval is $[m_{\\mathrm{rounded}} - h_{\\mathrm{rounded}}, m_{\\mathrm{rounded}} + h_{\\mathrm{rounded}}]$, and the reported triple is $(m_{\\mathrm{rounded}}, L_{\\mathrm{rounded}}, U_{\\mathrm{rounded}})$.\n\nThe implementation uses `numpy` for array operations and random number generation, and `scipy.stats.truncnorm` for efficient sampling from the truncated Normal distribution. The parameters for `truncnorm` are derived from the problem's $\\mu_A$, $\\sigma_A$, and the lower truncation bound of $a=0$. The corresponding standardized lower bound is $\\alpha = (a - \\mu_A) / \\sigma_A = -\\mu_A / \\sigma_A$, while the upper bound is $\\beta = \\infty$. A fixed random seed ensures the reproducibility of the Monte Carlo simulation.\n\nThe selected test cases will illustrate the varying impact of censoring:\n- **Case 1 ($\\mu_A = 0.500, \\sigma_A = 0.010$)**: Here $\\mu_A \\gg \\sigma_A$, so the probability of $A<0$ is negligible. The censored and uncensored results should be nearly identical.\n- **Case 2 ($\\mu_A = 0.050, \\sigma_A = 0.050$)**: With $\\mu_A = \\sigma_A$, a significant fraction of the uncensored distribution is negative. Censoring will truncate this tail, leading to a higher mean concentration and a right-skewed distribution.\n- **Case 3 ($\\mu_A = 0.005, \\sigma_A = 0.010$)**: With $\\mu_A < \\sigma_A$, the censoring effect is even more pronounced. The mean of the censored distribution will be substantially shifted to a positive value, and the distribution will be highly distorted compared to the parent Normal.\n- **Case 4 ($\\mu_A = -0.002, \\sigma_A = 0.005$)**: The true mean absorbance is negative, a scenario that can occur due to baseline overcorrection. The uncensored model would yield an unphysical negative mean concentration. The censored model correctly reflects the physical reality, producing only non-negative absorbances and thus a physically meaningful, positive mean concentration. This case highlights the critical importance of proper physical modeling.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import truncnorm\nimport math\n\ndef calculate_and_round(c_samples):\n    \"\"\"\n    Calculates the mean, 95% credible interval, and rounded reporting values.\n    \"\"\"\n    m = np.mean(c_samples)\n    L, U = np.quantile(c_samples, [0.025, 0.975])\n    h = (U - L) / 2.0\n\n    if h <= 0:\n        # This case is not expected with N=200,000 but handled for robustness.\n        # If uncertainty is zero or negative, no rounding rule is applicable.\n        return m, m, m\n\n    # Round h to one significant figure\n    power_h = math.floor(math.log10(h))\n    factor_h = 10**power_h\n    h_rounded = round(h / factor_h) * factor_h\n\n    # Round m to the same decimal place as h_rounded\n    # The 'decimal place' is determined by the magnitude of h_rounded\n    if h_rounded == 0:\n        # This should not happen if h > 0 because 1 <= h/factor_h < 10,\n        # so round(h/factor_h) >= 1. Safeguard is for theoretical robustness.\n        m_rounded = m\n    else:\n        power_m_round = math.floor(math.log10(h_rounded))\n        factor_m = 10**power_m_round\n        m_rounded = round(m / factor_m) * factor_m\n\n    L_rounded = m_rounded - h_rounded\n    U_rounded = m_rounded + h_rounded\n    \n    return m_rounded, L_rounded, U_rounded\n\ndef solve():\n    \"\"\"\n    Main solver function to run simulations and print results.\n    \"\"\"\n    # Set a fixed random seed for reproducibility.\n    np.random.seed(0)\n    \n    # Number of Monte Carlo draws\n    N = 200000\n\n    # Test suite: tuples of (mu_A, sigma_A, epsilon, ell)\n    test_cases = [\n        (0.500, 0.010, 12500, 1.00),\n        (0.050, 0.050, 12500, 1.00),\n        (0.005, 0.010, 12500, 1.00),\n        (-0.002, 0.005, 12500, 1.00),\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        mu_A, sigma_A, epsilon, ell = case\n        k = epsilon * ell\n\n        # Uncensored model\n        A_unc = np.random.normal(loc=mu_A, scale=sigma_A, size=N)\n        c_unc = A_unc / k\n        unc_triple = calculate_and_round(c_unc)\n\n        # Censored model\n        a_std = (0 - mu_A) / sigma_A\n        b_std = np.inf\n        A_cen = truncnorm.rvs(a=a_std, b=b_std, loc=mu_A, scale=sigma_A, size=N)\n        c_cen = A_cen / k\n        cen_triple = calculate_and_round(c_cen)\n\n        # Aggregate results for this case\n        case_results = [*unc_triple, *cen_triple]\n        all_results.append(case_results)\n\n    # Format the final output string as a list of lists.\n    # Using repr() for canonical string representation of floats.\n    output_parts = []\n    for res_list in all_results:\n        output_parts.append(f\"[{','.join(map(repr, res_list))}]\")\n    final_output = f\"[{','.join(output_parts)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "2952283"}]}