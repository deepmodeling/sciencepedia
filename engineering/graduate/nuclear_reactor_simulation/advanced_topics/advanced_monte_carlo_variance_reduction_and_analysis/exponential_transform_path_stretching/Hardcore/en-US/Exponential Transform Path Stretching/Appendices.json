{
    "hands_on_practices": [
        {
            "introduction": "Before applying any variance reduction technique, it is crucial to understand its mathematical underpinnings. This first exercise guides you through the derivation of the variance of the Exponential Transform (ET) estimator from first principles, including the essential likelihood ratio weight correction. By then determining the analytical form of the optimal path-stretching parameter, $\\alpha^{\\star}$, you will gain fundamental insight into how to tune the method for maximum efficiency .",
            "id": "4224668",
            "problem": "Consider one-speed neutral particle transport through a homogeneous planar slab of thickness $d$ and macroscopic total cross section $\\Sigma_{t}0$. The slab is purely absorbing (no scattering and no sources within the slab). A monoenergetic, mono-directional particle starts at $x=0$ and moves along the slab normal toward $x=d$.\n\nFundamental facts to be used:\n- In a homogeneous absorber, the free-path length $s$ to the first collision has the exponential probability density function (PDF) $f(s)=\\Sigma_{t}\\exp(-\\Sigma_{t} s)$ for $s\\geq 0$.\n- The leakage (transmission) probability through the slab is the probability that the first collision distance exceeds $d$, namely $P_{\\mathrm{leak}}=\\exp(-\\Sigma_{t} d)$.\n- In Monte Carlo (MC) simulation, variance reduction by importance sampling must preserve unbiasedness via a likelihood ratio. If a biased PDF $f_{\\alpha}(s)$ is used to sample $s$, then an unbiased estimator of any event functional is obtained by multiplying the event indicator by the likelihood ratio $L(s)=f(s)/f_{\\alpha}(s)$.\n\nTo estimate $P_{\\mathrm{leak}}$ using the exponential transform path-stretching method, introduce a bias parameter $\\alpha$ with the constraint $\\alpha1$ and replace $f(s)$ by the biased PDF\n$$\nf_{\\alpha}(s)=(1-\\alpha)\\,\\Sigma_{t}\\,\\exp\\!\\big(-(1-\\alpha)\\,\\Sigma_{t}\\,s\\big), \\quad s\\geq 0,\n$$\nwhile using the unbiased leakage estimator\n$$\nY_{\\alpha}=\\mathbf{1}_{\\{sd\\}}\\,L(s), \\quad L(s)=\\frac{f(s)}{f_{\\alpha}(s)}.\n$$\nHere $\\mathbf{1}_{\\{sd\\}}$ is the indicator of the event that the sampled free path exceeds the slab thickness.\n\nStarting only from the fundamental facts and definitions above, and without introducing any additional pre-derived formulas, do the following:\n\n1. Derive a closed-form expression for the variance $\\mathrm{Var}[Y_{\\alpha}]$ as a function of $\\alpha$, $\\Sigma_{t}$, and $d$.\n2. Determine, for $\\alpha1$, the value $\\alpha^{\\star}$ that minimizes $\\mathrm{Var}[Y_{\\alpha}]$. Express your result in closed form as a function of the optical thickness $\\Sigma_{t}d$.\n3. Based on your expression for $\\alpha^{\\star}$, explain qualitatively how the optimum behaves as $\\Sigma_{t} d$ increases, but report only the exact closed-form $\\alpha^{\\star}$ as your final answer.\n\nReport the final answer as a single, closed-form analytical expression for $\\alpha^{\\star}$, with no units. Do not round.",
            "solution": "The problem asks for the derivation of the variance of a Monte Carlo estimator for particle leakage, the optimization of a biasing parameter, and a qualitative analysis of the result. We will address these three parts in sequence.\n\nFirst, the problem must be validated.\n**Step 1: Extract Givens**\n- One-speed neutral particle transport, homogeneous planar slab, thickness $d$, macroscopic total cross section $\\Sigma_{t}0$.\n- Purely absorbing slab (no scattering, no internal sources).\n- Monoenergetic, mono-directional particle starts at $x=0$, moves toward $x=d$.\n- Free-path length probability density function (PDF): $f(s)=\\Sigma_{t}\\exp(-\\Sigma_{t} s)$ for $s\\geq 0$.\n- Leakage (transmission) probability: $P_{\\mathrm{leak}}=\\exp(-\\Sigma_{t} d)$.\n- Biased PDF for importance sampling: $f_{\\alpha}(s)=(1-\\alpha)\\,\\Sigma_{t}\\,\\exp(-(1-\\alpha)\\,\\Sigma_{t}\\,s)$, with $s\\geq 0$ and $\\alpha1$.\n- Unbiased leakage estimator: $Y_{\\alpha}=\\mathbf{1}_{\\{sd\\}}\\,L(s)$, where $L(s)=f(s)/f_{\\alpha}(s)$ is the likelihood ratio and $\\mathbf{1}_{\\{sd\\}}$ is the indicator function for the event $sd$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, being a standard exercise in the theory of Monte Carlo methods for particle transport, specifically concerning the exponential transform variance reduction technique. It is well-posed, with all necessary definitions and constraints provided for a unique mathematical solution. The language is objective and precise. The problem is self-contained and free of contradictions or scientifically unsound premises.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We proceed with the solution.\n\n**1. Derivation of the Variance $\\mathrm{Var}[Y_{\\alpha}]$**\n\nThe variance of the random variable $Y_{\\alpha}$, where the expectation $\\mathrm{E}_{\\alpha}[\\cdot]$ is taken with respect to the biased PDF $f_{\\alpha}(s)$, is given by the formula:\n$$\n\\mathrm{Var}[Y_{\\alpha}] = \\mathrm{E}_{\\alpha}[Y_{\\alpha}^2] - (\\mathrm{E}_{\\alpha}[Y_{\\alpha}])^2\n$$\nWe first compute the mean of the estimator, $\\mathrm{E}_{\\alpha}[Y_{\\alpha}]$. By definition,\n$$\n\\mathrm{E}_{\\alpha}[Y_{\\alpha}] = \\int_{0}^{\\infty} Y_{\\alpha}(s) f_{\\alpha}(s) \\, ds = \\int_{0}^{\\infty} \\mathbf{1}_{\\{sd\\}} L(s) f_{\\alpha}(s) \\, ds\n$$\nSubstituting $L(s) = f(s)/f_{\\alpha}(s)$, we get:\n$$\n\\mathrm{E}_{\\alpha}[Y_{\\alpha}] = \\int_{0}^{\\infty} \\mathbf{1}_{\\{sd\\}} \\frac{f(s)}{f_{\\alpha}(s)} f_{\\alpha}(s) \\, ds = \\int_{0}^{\\infty} \\mathbf{1}_{\\{sd\\}} f(s) \\, ds\n$$\nThe indicator function restricts the integration domain to $sd$:\n$$\n\\mathrm{E}_{\\alpha}[Y_{\\alpha}] = \\int_{d}^{\\infty} f(s) \\, ds = \\int_{d}^{\\infty} \\Sigma_{t}\\exp(-\\Sigma_{t} s) \\, ds = \\left[-\\exp(-\\Sigma_{t} s)\\right]_{d}^{\\infty} = 0 - (-\\exp(-\\Sigma_{t} d)) = \\exp(-\\Sigma_{t} d)\n$$\nThis confirms that the estimator is unbiased, i.e., its expected value is the true leakage probability $P_{\\mathrm{leak}}$. The square of the mean is therefore $(\\mathrm{E}_{\\alpha}[Y_{\\alpha}])^2 = (\\exp(-\\Sigma_{t} d))^2 = \\exp(-2\\Sigma_{t} d)$.\n\nNext, we compute the second moment, $\\mathrm{E}_{\\alpha}[Y_{\\alpha}^2]$.\n$$\n\\mathrm{E}_{\\alpha}[Y_{\\alpha}^2] = \\int_{0}^{\\infty} Y_{\\alpha}^2(s) f_{\\alpha}(s) \\, ds = \\int_{0}^{\\infty} (\\mathbf{1}_{\\{sd\\}} L(s))^2 f_{\\alpha}(s) \\, ds\n$$\nSince $(\\mathbf{1}_{\\{sd\\}})^2 = \\mathbf{1}_{\\{sd\\}}$, we have:\n$$\n\\mathrm{E}_{\\alpha}[Y_{\\alpha}^2] = \\int_{d}^{\\infty} (L(s))^2 f_{\\alpha}(s) \\, ds\n$$\nFirst, we express the likelihood ratio $L(s)$ explicitly:\n$$\nL(s) = \\frac{f(s)}{f_{\\alpha}(s)} = \\frac{\\Sigma_{t}\\exp(-\\Sigma_{t} s)}{(1-\\alpha)\\Sigma_{t}\\exp(-(1-\\alpha)\\Sigma_{t}s)} = \\frac{1}{1-\\alpha} \\exp(-\\Sigma_{t}s + (1-\\alpha)\\Sigma_{t}s) = \\frac{1}{1-\\alpha} \\exp(-\\alpha\\Sigma_{t}s)\n$$\nNow we substitute $L(s)$ and $f_{\\alpha}(s)$ into the integral for the second moment:\n$$\n\\mathrm{E}_{\\alpha}[Y_{\\alpha}^2] = \\int_{d}^{\\infty} \\left(\\frac{1}{1-\\alpha} \\exp(-\\alpha\\Sigma_{t}s)\\right)^2 \\left((1-\\alpha)\\Sigma_{t}\\exp(-(1-\\alpha)\\Sigma_{t}s)\\right) \\, ds\n$$\n$$\n= \\int_{d}^{\\infty} \\frac{1}{(1-\\alpha)^2} \\exp(-2\\alpha\\Sigma_{t}s) (1-\\alpha)\\Sigma_{t}\\exp(-(1-\\alpha)\\Sigma_{t}s) \\, ds\n$$\n$$\n= \\frac{\\Sigma_{t}}{1-\\alpha} \\int_{d}^{\\infty} \\exp\\big(-2\\alpha\\Sigma_{t}s - (1-\\alpha)\\Sigma_{t}s\\big) \\, ds\n$$\nThe exponent simplifies to $-2\\alpha\\Sigma_{t}s - \\Sigma_{t}s + \\alpha\\Sigma_{t}s = -(1+\\alpha)\\Sigma_{t}s$. The integral becomes:\n$$\n\\mathrm{E}_{\\alpha}[Y_{\\alpha}^2] = \\frac{\\Sigma_{t}}{1-\\alpha} \\int_{d}^{\\infty} \\exp(-(1+\\alpha)\\Sigma_{t}s) \\, ds\n$$\nFor this integral to converge, the argument of the exponential must be negative, which requires $(1+\\alpha)\\Sigma_{t}  0$. Since $\\Sigma_{t}0$, we must have $1+\\alpha0$, or $\\alpha  -1$. Evaluating the integral:\n$$\n\\int_{d}^{\\infty} \\exp(-(1+\\alpha)\\Sigma_{t}s) \\, ds = \\left[ \\frac{\\exp(-(1+\\alpha)\\Sigma_{t}s)}{-(1+\\alpha)\\Sigma_{t}} \\right]_d^{\\infty} = 0 - \\frac{\\exp(-(1+\\alpha)\\Sigma_{t}d)}{-(1+\\alpha)\\Sigma_{t}} = \\frac{\\exp(-(1+\\alpha)\\Sigma_{t}d)}{(1+\\alpha)\\Sigma_{t}}\n$$\nSubstituting this result back into the expression for the second moment:\n$$\n\\mathrm{E}_{\\alpha}[Y_{\\alpha}^2] = \\frac{\\Sigma_{t}}{1-\\alpha} \\cdot \\frac{\\exp(-(1+\\alpha)\\Sigma_{t}d)}{(1+\\alpha)\\Sigma_{t}} = \\frac{\\exp(-(1+\\alpha)\\Sigma_{t}d)}{(1-\\alpha)(1+\\alpha)} = \\frac{\\exp(-(1+\\alpha)\\Sigma_{t}d)}{1-\\alpha^2}\n$$\nFinally, we assemble the variance:\n$$\n\\mathrm{Var}[Y_{\\alpha}] = \\mathrm{E}_{\\alpha}[Y_{\\alpha}^2] - (\\mathrm{E}_{\\alpha}[Y_{\\alpha}])^2 = \\frac{\\exp(-(1+\\alpha)\\Sigma_{t}d)}{1-\\alpha^2} - \\exp(-2\\Sigma_{t}d)\n$$\n\n**2. Determination of the Optimal Parameter $\\alpha^{\\star}$**\n\nTo find the value of $\\alpha$ that minimizes $\\mathrm{Var}[Y_{\\alpha}]$, we differentiate the variance with respect to $\\alpha$ and set the derivative to zero. Let's denote the optical thickness as $T = \\Sigma_{t}d  0$. The variance is:\n$$\nV(\\alpha) = \\frac{\\exp(-(1+\\alpha)T)}{1-\\alpha^2} - \\exp(-2T)\n$$\nWe need to solve $\\frac{dV}{d\\alpha} = 0$. The term $\\exp(-2T)$ is constant with respect to $\\alpha$.\n$$\n\\frac{dV}{d\\alpha} = \\frac{d}{d\\alpha} \\left( \\frac{\\exp(-T - \\alpha T)}{1-\\alpha^2} \\right) = 0\n$$\nUsing the quotient rule for differentiation, $\\frac{d}{dx}(\\frac{u}{v}) = \\frac{u'v - uv'}{v^2}$:\n$$\n\\frac{(-T \\exp(-T-\\alpha T))(1-\\alpha^2) - (\\exp(-T-\\alpha T))(-2\\alpha)}{(1-\\alpha^2)^2} = 0\n$$\nSince $\\exp(-T-\\alpha T)$ is always positive and the denominator is non-zero for $\\alpha \\in (-1, 1)$, we can simplify the equation by setting the numerator to zero:\n$$\n-T(1-\\alpha^2) + 2\\alpha = 0\n$$\n$$\n-T + T\\alpha^2 + 2\\alpha = 0 \\implies T\\alpha^2 + 2\\alpha - T = 0\n$$\nThis is a quadratic equation for $\\alpha$. Using the quadratic formula $\\alpha = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$ with $a=T$, $b=2$, and $c=-T$:\n$$\n\\alpha = \\frac{-2 \\pm \\sqrt{2^2 - 4(T)(-T)}}{2T} = \\frac{-2 \\pm \\sqrt{4 + 4T^2}}{2T} = \\frac{-2 \\pm 2\\sqrt{1+T^2}}{2T} = \\frac{-1 \\pm \\sqrt{1+T^2}}{T}\n$$\nThis gives two possible solutions:\n$$\n\\alpha_1 = \\frac{-1 + \\sqrt{1+T^2}}{T} \\quad \\text{and} \\quad \\alpha_2 = \\frac{-1 - \\sqrt{1+T^2}}{T}\n$$\nWe must check these solutions against the constraints $\\alpha  1$ and $\\alpha  -1$. For $T  0$, $\\sqrt{1+T^2}  \\sqrt{T^2} = T$, and $\\sqrt{1+T^2}  \\sqrt{1+2T+T^2} = 1+T$.\nFor $\\alpha_1$:\nThe numerator satisfies $0  -1 + \\sqrt{1+T^2}  T$. Since $T0$, dividing by $T$ gives $0  \\alpha_1  1$. This solution is within the valid range.\nFor $\\alpha_2$:\nThe numerator is $-1 - \\sqrt{1+T^2}  -2$. Thus, $\\alpha_2 = \\frac{-1 - \\sqrt{1+T^2}}{T}$ is negative. Further analysis shows that $\\alpha_2  -1$ for all $T0$. This solution lies outside the domain where the variance is finite.\nThe second derivative test confirms that $\\alpha_1$ corresponds to a minimum. Therefore, the optimal parameter is $\\alpha^{\\star} = \\alpha_1$. Substituting $T=\\Sigma_{t}d$:\n$$\n\\alpha^{\\star} = \\frac{-1 + \\sqrt{1 + (\\Sigma_t d)^2}}{\\Sigma_t d}\n$$\n\n**3. Qualitative Behavior of $\\alpha^{\\star}$**\n\nWe analyze the behavior of $\\alpha^{\\star}$ as a function of the optical thickness $T = \\Sigma_{t} d$.\n- As the optical thickness becomes very large ($T \\to \\infty$), leakage becomes a rare event. We examine the limit:\n$$\n\\lim_{T\\to\\infty} \\alpha^{\\star} = \\lim_{T\\to\\infty} \\frac{-1 + \\sqrt{1+T^2}}{T} = \\lim_{T\\to\\infty} \\frac{T\\sqrt{1/T^2+1}-1}{T} = \\lim_{T\\to\\infty} \\left(\\sqrt{1/T^2+1} - 1/T\\right) = 1\n$$\nSo, $\\alpha^{\\star}$ approaches $1$. An $\\alpha$ value close to $1$ corresponds to a heavily biased (\"stretched\") path length distribution that preferentially samples long paths, increasing the likelihood of observing the rare leakage event in a simulation.\n- As the optical thickness becomes very small ($T \\to 0$), leakage is a very probable event. Using the Taylor expansion $\\sqrt{1+x} \\approx 1+\\frac{1}{2}x$ for small $x$:\n$$\n\\alpha^{\\star} \\approx \\frac{-1 + (1 + \\frac{1}{2}T^2)}{T} = \\frac{\\frac{1}{2}T^2}{T} = \\frac{1}{2}T\n$$\nSo, $\\alpha^{\\star}$ approaches $0$. An $\\alpha$ value close to $0$ corresponds to almost no biasing, which is appropriate when the event of interest is not rare.\nIn summary, as the slab's optical thickness $\\Sigma_t d$ increases, the optimal biasing parameter $\\alpha^{\\star}$ increases from $0$ towards $1$, reflecting the need for stronger importance sampling to efficiently simulate the increasingly rare event of particle transmission.",
            "answer": "$$\\boxed{\\frac{-1 + \\sqrt{1 + (\\Sigma_{t} d)^{2}}}{\\Sigma_{t} d}}$$"
        },
        {
            "introduction": "The Exponential Transform is one of several techniques designed to improve simulation efficiency. This practice challenges you to distinguish ET from another common method, forced collision, by closely examining their respective sampling schemes and weight adjustments . This conceptual comparison is vital for developing a nuanced understanding and for choosing the right tool for a given simulation problem.",
            "id": "4224682",
            "problem": "Consider a monoenergetic neutron of initial statistical weight $w_0$ entering a convex reactor cell with constant macroscopic total cross section $\\Sigma_t$ and traveling in a fixed direction such that the straight-line distance to the nearest boundary along its flight path is $D0$. Assume standard Monte Carlo (MC) neutron transport in which free-flight distances in homogeneous media follow the Beer–Lambert law: the probability of no collision up to distance $s$ is $e^{-\\Sigma_t s}$, and the corresponding analog free-flight Probability Density Function (PDF) is $f(s)=\\Sigma_t e^{-\\Sigma_t s}$ for $s\\ge 0$. Two variance-reduction strategies are under consideration:\n\n1. A cell-local forced collision scheme that conditions on the event that a collision occurs before escape from the cell.\n2. An Exponential Transform (ET) path-stretching scheme that globally reshapes the free-flight distribution using a bias parameter $\\alpha$, with $0\\alpha\\Sigma_t$.\n\nWhich of the following statements are correct descriptions of these methods and their weight adjustments?\n\nA. In forced collision, the collision distance $s$ is sampled from the conditional (truncated) exponential PDF $f(s\\mid sD)=\\dfrac{\\Sigma_t e^{-\\Sigma_t s}}{1-e^{-\\Sigma_t D}}$ for $0sD$, and the colliding particle’s weight is set to $w_c=w_0\\left(1-e^{-\\Sigma_t D}\\right)$ while an optional escaping branch of weight $w_e=w_0 e^{-\\Sigma_t D}$ can be tallied as an escape without interaction.\n\nB. In forced collision, the colliding particle’s weight after sampling $s$ is $w_c=w_0 e^{-\\Sigma_t D}$ because $e^{-\\Sigma_t D}$ is the probability that the neutron escapes without collision.\n\nC. In ET with parameter $\\alpha\\in(0,\\Sigma_t)$, the biased free-flight PDF is $g_\\alpha(s)=(\\Sigma_t-\\alpha)e^{-(\\Sigma_t-\\alpha)s}$ for $s\\ge 0$, and the unbiased likelihood-ratio weight correction applied at the interaction location is $R(s)=\\dfrac{f(s)}{g_\\alpha(s)}=\\dfrac{\\Sigma_t}{\\Sigma_t-\\alpha}\\,e^{-\\alpha s}$.\n\nD. ET reshapes only flights within the current cell by truncating the exponential at $D$, and its weight correction does not depend on the sampled flight distance $s$.\n\nE. For deep-penetration problems, one should choose $\\alpha\\Sigma_t$ to stretch long paths, because the only constraint on $\\alpha$ is that it be positive.\n\nSelect all that apply.",
            "solution": "The problem statement describes a standard scenario in Monte Carlo neutron transport and asks to evaluate the correctness of statements concerning two common variance reduction techniques: forced collision and the exponential transform.\n\n### **Problem Validation**\n\n**Step 1: Extract Givens**\n- Initial statistical weight of a monoenergetic neutron is $w_0$.\n- The neutron enters a convex reactor cell with a constant macroscopic total cross section $\\Sigma_t$.\n- The straight-line distance to the nearest boundary along its flight path is $D  0$.\n- The analog probability of no collision up to distance $s$ is $e^{-\\Sigma_t s}$.\n- The analog free-flight Probability Density Function (PDF) is $f(s)=\\Sigma_t e^{-\\Sigma_t s}$ for $s \\ge 0$.\n- Strategy 1: Cell-local forced collision, conditioned on collision before escape.\n- Strategy 2: Exponential Transform (ET) path-stretching with bias parameter $\\alpha$, where $0  \\alpha  \\Sigma_t$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-defined within the context of nuclear reactor physics and Monte Carlo methods.\n- **Scientifically Grounded:** The concepts presented (Beer-Lambert law, macroscopic cross section, statistical weights, forced collision, exponential transform) are fundamental and standard in neutron transport theory. The mathematical forms for the PDFs and probabilities are correct.\n- **Well-Posed:** The problem provides sufficient information to assess the validity of the statements about the specified variance reduction methods.\n- **Objective:** The language is technical, precise, and free of ambiguity or subjective claims.\n- **Completeness and Consistency:** The givens are self-consistent. The PDF $f(s)$ is the correct derivative of $1 - P(\\text{no collision up to } s) = 1 - e^{-\\Sigma_t s}$. The constraint $0  \\alpha  \\Sigma_t$ for the ET is physically necessary to ensure the biased cross section remains positive, which is a correct and crucial detail.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. I will proceed with a full solution.\n\n### **Theoretical Derivation**\n\nThe fundamental principle of variance reduction via biasing is that if we sample an event (like a free-flight distance $s$) from a biased PDF, $g(s)$, instead of its true, or \"analog\", PDF, $f(s)$, we must adjust the particle's statistical weight to maintain an unbiased estimate of any tallied quantity. The weight is multiplied by the likelihood ratio, $R(s) = \\frac{f(s)}{g(s)}$.\n\n**1. Forced Collision Analysis**\nIn the analog simulation, a neutron starting with weight $w_0$ at the cell entrance has two possible outcomes along its initial flight path:\n- It collides within the cell, i.e., at a distance $s  D$. The probability of this event is $P(s  D) = \\int_{0}^{D} f(s) ds = \\int_{0}^{D} \\Sigma_t e^{-\\Sigma_t s} ds = \\left[-e^{-\\Sigma_t s}\\right]_0^D = 1 - e^{-\\Sigma_t D}$.\n- It escapes the cell without collision, i.e., travels a distance $s \\ge D$. The probability is $P(s \\ge D) = 1 - P(s  D) = e^{-\\Sigma_t D}$.\n\nThe forced collision technique eliminates the random choice between these two outcomes. It forces the particle to collide within the cell (i.e., for $s  D$). This means we are sampling from a new distribution conditioned on the event $s  D$.\nThe biased PDF, $g(s)$, is therefore the conditional PDF:\n$$g(s) = f(s \\mid s  D) = \\frac{f(s)}{P(s  D)} = \\frac{\\Sigma_t e^{-\\Sigma_t s}}{1 - e^{-\\Sigma_t D}}, \\quad \\text{for } 0 \\le s  D$$\nand $g(s)=0$ for $s \\ge D$.\n\nTo preserve the unbiased nature of the simulation, the particle's weight must be adjusted. The weight correction is not the standard likelihood ratio here because we have fundamentally altered the event space. Instead, we can view this as a form of splitting. An initial particle of weight $w_0$ is split into two \"virtual\" particles: one that is guaranteed to collide and one that is guaranteed to escape.\n- The colliding particle's weight becomes $w_c = w_0 \\times P(s  D) = w_0 (1 - e^{-\\Sigma_t D})$. This particle's flight distance $s$ is then sampled from the conditional PDF $g(s)$ above.\n- The escaping particle is not physically simulated. Its weight, $w_e = w_0 \\times P(s \\ge D) = w_0 e^{-\\Sigma_t D}$, is directly tallied as an escape, contributing to leakage tallies. This part is optional depending on the implementation but represents the correct weight accounting for the escape fraction.\n\n**2. Exponential Transform (ET) Analysis**\nThe ET method modifies the analog PDF, $f(s) = \\Sigma_t e^{-\\Sigma_t s}$, by altering the macroscopic cross section. The total cross section $\\Sigma_t$ is replaced by a biased cross section $\\Sigma_t' = \\Sigma_t - \\alpha$. The parameter $\\alpha$ is chosen to \"stretch\" or \"shrink\" particle paths. For deep penetration, a positive $\\alpha$ is chosen to decrease the effective cross section, thus increasing the mean free path and allowing particles to travel farther.\nThe constraint $0  \\alpha  \\Sigma_t$ ensures that $\\Sigma_t'  0$, which is a necessary condition for $\\Sigma_t'$ to be a physical cross section and for the resulting PDF to be normalizable.\n\nThe biased PDF, $g_\\alpha(s)$, is an exponential distribution with the new cross section $\\Sigma_t'$:\n$$g_\\alpha(s) = \\Sigma_t' e^{-\\Sigma_t' s} = (\\Sigma_t - \\alpha) e^{-(\\Sigma_t - \\alpha)s}, \\quad \\text{for } s \\ge 0$$\nAfter sampling a distance $s$ from this biased PDF, the particle's weight must be multiplied by the likelihood ratio $R(s)$:\n$$R(s) = \\frac{f(s)}{g_\\alpha(s)} = \\frac{\\Sigma_t e^{-\\Sigma_t s}}{(\\Sigma_t - \\alpha) e^{-(\\Sigma_t - \\alpha)s}} = \\frac{\\Sigma_t}{\\Sigma_t - \\alpha} e^{(-\\Sigma_t + (\\Sigma_t - \\alpha))s} = \\frac{\\Sigma_t}{\\Sigma_t - \\alpha} e^{-\\alpha s}$$\nThis weight correction is applied at the collision site. The new weight is $w_{new} = w_{old} \\times R(s)$.\n\n### **Option-by-Option Analysis**\n\n**A. In forced collision, the collision distance $s$ is sampled from the conditional (truncated) exponential PDF $f(s\\mid sD)=\\dfrac{\\Sigma_t e^{-\\Sigma_t s}}{1-e^{-\\Sigma_t D}}$ for $0sD$, and the colliding particle’s weight is set to $w_c=w_0\\left(1-e^{-\\Sigma_t D}\\right)$ while an optional escaping branch of weight $w_e=w_0 e^{-\\Sigma_t D}$ can be tallied as an escape without interaction.**\n- The conditional PDF provided, $\\dfrac{\\Sigma_t e^{-\\Sigma_t s}}{1-e^{-\\Sigma_t D}}$, matches our derivation for sampling a collision distance given that the collision occurs before $D$.\n- The weight of the colliding particle, $w_c=w_0\\left(1-e^{-\\Sigma_t D}\\right)$, matches our derivation, as it is the initial weight multiplied by the probability of the event being forced.\n- The weight of the escaping branch, $w_e=w_0 e^{-\\Sigma_t D}$, also matches our derivation.\nThis statement provides a complete and accurate description of the forced collision technique.\n**Verdict: Correct**\n\n**B. In forced collision, the colliding particle’s weight after sampling $s$ is $w_c=w_0 e^{-\\Sigma_t D}$ because $e^{-\\Sigma_t D}$ is the probability that the neutron escapes without collision.**\nThe weight update must correspond to the probability of the event that occurs. In forced collision, the event that occurs is a collision within distance $D$. The probability of this is $1-e^{-\\Sigma_t D}$, not $e^{-\\Sigma_t D}$. The weight $w_0 e^{-\\Sigma_t D}$ is the weight associated with the particle escaping, not colliding. Therefore, this statement incorrectly assigns the weight.\n**Verdict: Incorrect**\n\n**C. In ET with parameter $\\alpha\\in(0,\\Sigma_t)$, the biased free-flight PDF is $g_\\alpha(s)=(\\Sigma_t-\\alpha)e^{-(\\Sigma_t-\\alpha)s}$ for $s\\ge 0$, and the unbiased likelihood-ratio weight correction applied at the interaction location is $R(s)=\\dfrac{f(s)}{g_\\alpha(s)}=\\dfrac{\\Sigma_t}{\\Sigma_t-\\alpha}\\,e^{-\\alpha s}$.**\n- The biased PDF, $g_\\alpha(s)$, is correctly stated as the exponential PDF corresponding to the modified cross section $\\Sigma_t' = \\Sigma_t - \\alpha$.\n- The likelihood-ratio weight correction, $R(s)$, is correctly derived as the ratio of the analog PDF to the biased PDF, resulting in $\\frac{\\Sigma_t}{\\Sigma_t-\\alpha}\\,e^{-\\alpha s}$.\nThis statement is a textbook definition of the exponential transform.\n**Verdict: Correct**\n\n**D. ET reshapes only flights within the current cell by truncating the exponential at $D$, and its weight correction does not depend on the sampled flight distance $s$.**\nThis statement makes two false claims. First, ET is generally a global (or regional) variance reduction technique that modifies the transport kernel itself, not one that is inherently tied to cell boundaries via truncation. The technique that truncates the distribution at the cell boundary $D$ is forced collision. Second, the weight correction for ET, $R(s)=\\frac{\\Sigma_t}{\\Sigma_t-\\alpha}\\,e^{-\\alpha s}$, explicitly depends on the sampled flight distance $s$ through the exponential term $e^{-\\alpha s}$.\n**Verdict: Incorrect**\n\n**E. For deep-penetration problems, one should choose $\\alpha\\Sigma_t$ to stretch long paths, because the only constraint on $\\alpha$ is that it be positive.**\nThis statement is incorrect and dangerous from a practical standpoint. If $\\alpha  \\Sigma_t$, the biased cross section $\\Sigma_t' = \\Sigma_t - \\alpha$ becomes negative. A negative cross section is unphysical. It would imply a \"PDF\" $g_\\alpha(s)$ that grows exponentially with $s$ and whose integral over $[0, \\infty)$ diverges, thus it is not a probability distribution. The constraint on $\\alpha$ is not just that it be positive; it must also be smaller than $\\Sigma_t$ to ensure $\\Sigma_t'  0$. The problem setup correctly states the valid range as $0  \\alpha  \\Sigma_t$.\n**Verdict: Incorrect**",
            "answer": "$$\\boxed{AC}$$"
        },
        {
            "introduction": "Theory becomes tangible through implementation, and the true test of a variance reduction method lies in its performance. This final practice is a computational exercise where you will implement the ET method to solve a benchmark shielding problem . You will perform a pilot study to find a practical optimal $\\alpha$ and use the Figure of Merit (FOM) to quantitatively demonstrate the dramatic improvement in efficiency compared to an analog simulation.",
            "id": "4224733",
            "problem": "Consider a one-dimensional slab shielding benchmark in nuclear reactor simulation. A monoenergetic particle starts at the entrance $x=0$ and travels in the $+x$ direction through a homogeneous, purely absorbing medium of macroscopic total cross section $\\Sigma_t$ measured in $\\mathrm{cm}^{-1}$. The slab has thickness $L$ measured in $\\mathrm{cm}$. The quantity of interest is the transmitted fraction (flux) at $x=L$, which equals the probability that a particle has no interaction before leaving the slab.\n\nFundamental base:\n- Beer–Lambert law of exponential attenuation for a purely absorbing medium states that the survival probability through a path length $s$ is $\\exp(-\\Sigma_t s)$.\n- In analog Monte Carlo sampling, the free path length $s$ is sampled from an exponential distribution with rate $\\Sigma_t$ according to the macroscopic total cross section definition.\n\nExponential transform path stretching is a variance-reduction technique that biases the free-path sampling by reducing the exponential rate and compensates with an appropriate weight to preserve unbiasedness. Let $\\alpha$ (measured in $\\mathrm{cm}^{-1}$) be the path-stretching parameter, chosen such that $0 \\le \\alpha  \\Sigma_t$ to keep the biased sampling well-defined. The biased sampling rate becomes $(\\Sigma_t - \\alpha)$, and an unbiased estimator for the transmitted fraction must be derived using a rigorous likelihood ratio between the analog and biased sampling laws and the indicator of transmission. No shortcut formulas for the unbiased estimator are provided here; the estimator must be obtained from first principles beginning from the stated fundamental base.\n\nDefine the Figure of Merit (FOM) as follows. Let $N$ denote the number of particle histories (this is the computational effort; treat it as the \"time\" measured in units of histories), $\\hat{\\mu}$ the sample mean estimator of the transmitted fraction, and $\\hat{\\sigma}^2$ its unbiased sample variance. The relative error is $R = \\hat{\\sigma}/|\\hat{\\mu}|$. The Figure of Merit (FOM) is $1/(R^2 N)$ and must be reported in units of $\\mathrm{histories}^{-1}$.\n\nTask:\n1. For a given $(\\Sigma_t, L)$, perform a pilot study over a discrete set of candidate $\\alpha$ values to estimate the FOM for each candidate. Use the pilot to choose the $\\alpha$ that maximizes the estimated FOM. This $\\alpha$ is deemed \"optimal\" under the pilot discretization (express $\\alpha$ in $\\mathrm{cm}^{-1}$).\n2. Validate the choice by performing a production run and comparing the FOM of:\n   - the analog case ($\\alpha = 0$),\n   - the pilot-chosen optimal $\\alpha$,\n   - a demonstrably nonoptimal $\\alpha$ selected from the pilot set that has strictly lower pilot FOM than the optimal choice.\n3. For each test case, report:\n   - the optimal $\\alpha$ in $\\mathrm{cm}^{-1}$,\n   - the production-run FOM for the optimal $\\alpha$ in $\\mathrm{histories}^{-1}$,\n   - the production-run FOM for the analog case in $\\mathrm{histories}^{-1}$,\n   - the production-run FOM for the chosen nonoptimal $\\alpha$ in $\\mathrm{histories}^{-1}$,\n   - a boolean confirming the optimal FOM is strictly greater than the analog FOM,\n   - a boolean confirming the optimal FOM is strictly greater than the nonoptimal FOM.\n\nEstimator and algorithm requirements:\n- Derive the unbiased estimator for the transmitted fraction under exponential transform path stretching starting from the fundamental base above, using the change-of-distribution likelihood ratio combined with the transmission indicator $I[s \\ge L]$.\n- Implement the Monte Carlo using independent and identically distributed sampling of free path length $s$ from the biased exponential distribution with rate $(\\Sigma_t - \\alpha)$ for each candidate $\\alpha$, including the analog case by setting $\\alpha = 0$.\n- For each run, compute the sample mean, unbiased sample variance, the relative error $R$, and the FOM $1/(R^2 N)$, all in the units specified above.\n\nTest suite:\nExecute your program for the following test cases, each with its own pilot and production run sizes:\n- Test case $1$: $\\Sigma_t = 1.0\\,\\mathrm{cm}^{-1}$, $L = 10.0\\,\\mathrm{cm}$, $N_{\\text{pilot}} = 20000$ histories, $N_{\\text{prod}} = 100000$ histories.\n- Test case $2$: $\\Sigma_t = 0.2\\,\\mathrm{cm}^{-1}$, $L = 5.0\\,\\mathrm{cm}$, $N_{\\text{pilot}} = 20000$ histories, $N_{\\text{prod}} = 100000$ histories.\n- Test case $3$: $\\Sigma_t = 2.0\\,\\mathrm{cm}^{-1}$, $L = 1.0\\,\\mathrm{cm}$, $N_{\\text{pilot}} = 20000$ histories, $N_{\\text{prod}} = 100000$ histories.\n\nPilot candidate set:\nFor each test case, consider a discrete set of five candidate $\\alpha$ values defined as fractions of $\\Sigma_t$: $\\{0.0, 0.2, 0.5, 0.8, 0.95\\}\\times \\Sigma_t$, with the understanding that the biased rate $(\\Sigma_t - \\alpha)$ must be positive; if needed, cap $\\alpha$ strictly below $\\Sigma_t$.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets, where each test case result is itself a list in the order:\n$[\\alpha_{\\text{opt}}, \\mathrm{FOM}_{\\text{opt}}, \\mathrm{FOM}_{\\text{analog}}, \\mathrm{FOM}_{\\text{nonopt}}, \\text{opt\\_gt\\_analog}, \\text{opt\\_gt\\_nonopt}]$.\nFor example, the overall outer list should appear as $[[\\cdots],[\\cdots],[\\cdots]]$ with numerical values and booleans, and all $\\alpha$ values must be in $\\mathrm{cm}^{-1}$ while all FOM values must be in $\\mathrm{histories}^{-1}$.",
            "solution": "The problem presented is a valid and well-posed exercise in the field of Monte Carlo methods for particle transport. It is scientifically grounded in the principles of radiation physics and statistical estimation, and all necessary parameters and objectives are clearly defined. We shall therefore proceed with a complete solution.\n\nThe primary objective is to evaluate the effectiveness of the exponential transform path stretching variance reduction technique for a one-dimensional, purely absorbing shielding problem. This involves deriving the unbiased estimator, implementing a Monte Carlo simulation, and using it to find an optimal path-stretching parameter $\\alpha$.\n\n**1. Derivation of the Unbiased Estimator**\n\nThe quantity of interest is the transmitted fraction, $\\mu$, which is the probability that a particle travels a distance greater than or equal to the slab thickness $L$ without an interaction. The particle's free path length, $s$, is a random variable.\n\nIn the analog (unbiased) physical model, the probability density function (PDF) for the free path length $s$ is given by the exponential distribution:\n$$\np(s) = \\Sigma_t e^{-\\Sigma_t s}, \\quad s \\ge 0\n$$\nwhere $\\Sigma_t$ is the macroscopic total cross section.\n\nThe transmitted fraction $\\mu$ is the survival probability $P(s \\ge L)$. This can be expressed as the expectation of an indicator function, $I[s \\ge L]$, which is $1$ if $s \\ge L$ and $0$ otherwise.\n$$\n\\mu = E_p[I[s \\ge L]] = \\int_0^\\infty I[s \\ge L] p(s) ds = \\int_L^\\infty \\Sigma_t e^{-\\Sigma_t s} ds = e^{-\\Sigma_t L}\n$$\nThe analog Monte Carlo method estimates $\\mu$ by sampling $s_i$ from $p(s)$ and averaging $I[s_i \\ge L]$. For deep penetration problems where $\\Sigma_t L \\gg 1$, $\\mu$ is very small, and this analog approach is inefficient as most histories result in a score of $0$.\n\nThe exponential transform technique, a form of importance sampling, biases the sampling to increase the probability of transmission. We sample the path length $s'$ from a biased PDF, $p'(s)$:\n$$\np'(s) = (\\Sigma_t - \\alpha) e^{-(\\Sigma_t - \\alpha)s}, \\quad s \\ge 0\n$$\nwhere $\\alpha$ is the path-stretching parameter, with $0 \\le \\alpha  \\Sigma_t$. This biased distribution has a larger mean free path ($1/(\\Sigma_t - \\alpha)$) than the analog one ($1/\\Sigma_t$), hence encouraging longer paths.\n\nTo ensure the estimator remains unbiased, we must introduce a weight, $w(s')$, to correct for the change in probability measure. The expectation is rewritten as:\n$$\n\\mu = \\int_0^\\infty I[s \\ge L] p(s) ds = \\int_0^\\infty I[s \\ge L] \\frac{p(s)}{p'(s)} p'(s) ds = E_{p'}\\left[I[s' \\ge L] \\frac{p(s')}{p'(s')}\\right]\n$$\nThe term in the expectation is the score for a single history sampled from $p'(s')$. The weight $w(s')$ is the likelihood ratio:\n$$\nw(s') = \\frac{p(s')}{p'(s')} = \\frac{\\Sigma_t e^{-\\Sigma_t s'}}{(\\Sigma_t - \\alpha) e^{-(\\Sigma_t - \\alpha)s'}} = \\frac{\\Sigma_t}{\\Sigma_t - \\alpha} e^{-[\\Sigma_t - (\\Sigma_t - \\alpha)]s'} = \\frac{\\Sigma_t}{\\Sigma_t - \\alpha} e^{-\\alpha s'}\n$$\nThus, for each particle history $i$, we sample a path length $s'_i$ from $p'(s')$. The score for that history, $X_i$, is:\n$$\nX_i = \\begin{cases} \\frac{\\Sigma_t}{\\Sigma_t - \\alpha} e^{-\\alpha s'_i}  \\text{if } s'_i \\ge L \\\\ 0  \\text{if } s'_i  L \\end{cases}\n$$\nThis is the unbiased estimator for a single history. The sample mean over $N$ histories, $\\hat{\\mu} = \\frac{1}{N} \\sum_{i=1}^N X_i$, is an unbiased estimator of the true transmitted fraction $\\mu$.\n\n**2. Monte Carlo Algorithm and Figure of Merit (FOM)**\n\nThe simulation proceeds as follows for a given set of parameters $(\\Sigma_t, L, \\alpha)$ and a total of $N$ particle histories:\n1.  For each history $i=1, \\dots, N$, sample a path length $s'_i$ from an exponential distribution with rate $\\Sigma'_t = \\Sigma_t - \\alpha$.\n2.  If $s'_i \\ge L$, calculate the score $X_i = \\frac{\\Sigma_t}{\\Sigma_t - \\alpha} e^{-\\alpha s'_i}$.\n3.  If $s'_i  L$, the score is $X_i = 0$.\n\nAfter running $N$ histories, we compute the following statistics from the set of scores $\\{X_1, X_2, \\dots, X_N\\}$:\n-   **Sample Mean:** $\\hat{\\mu} = \\frac{1}{N} \\sum_{i=1}^N X_i$\n-   **Unbiased Sample Variance:** $\\hat{\\sigma}^2 = \\frac{1}{N-1} \\sum_{i=1}^N (X_i - \\hat{\\mu})^2$\n\nAs per the problem definition, the relative error $R$ and the Figure of Merit (FOM) are defined as:\n-   **Relative Error:** $R = \\frac{\\hat{\\sigma}}{|\\hat{\\mu}|}$\n-   **Figure of Merit:** $\\mathrm{FOM} = \\frac{1}{R^2 N} = \\frac{1}{(\\hat{\\sigma}^2 / \\hat{\\mu}^2) N} = \\frac{\\hat{\\mu}^2}{N \\hat{\\sigma}^2}$\n\nThe units of FOM are $\\mathrm{histories}^{-1}$, as required. A higher FOM indicates a more efficient simulation, meaning fewer histories are needed to achieve a given level of statistical precision.\n\n**3. Parameter Optimization and Validation**\n\nThe efficacy of the exponential transform is highly dependent on the choice of $\\alpha$. The procedure to find a suitable $\\alpha$ and validate its performance is:\n\n1.  **Pilot Study:** For a given test case $(\\Sigma_t, L)$, simulations are run with $N_{\\text{pilot}}$ histories for a discrete set of candidate $\\alpha$ values: $\\{0.0, 0.2, 0.5, 0.8, 0.95\\} \\times \\Sigma_t$. The FOM is estimated for each candidate. The value of $\\alpha$ that yields the highest estimated FOM is designated as the optimal parameter, $\\alpha_{\\text{opt}}$.\n\n2.  **Production Run and Validation:** To obtain more statistically robust results, production runs are performed with a larger number of histories, $N_{\\text{prod}}$. The FOM is calculated for three specific cases:\n    -   The **analog case**: $\\alpha = 0$. This represents the baseline performance without variance reduction.\n    -   The **optimal case**: $\\alpha = \\alpha_{\\text{opt}}$, as determined by the pilot study.\n    -   The **non-optimal case**: $\\alpha = \\alpha_{\\text{nonopt}}$. This is chosen to be the candidate $\\alpha$ from the pilot study that resulted in the lowest FOM, providing a benchmark for a poor parameter choice.\n\nFinally, we report the key results: $\\alpha_{\\text{opt}}$, and the production-run FOMs for the optimal, analog, and non-optimal cases. We also confirm that the optimal FOM is strictly greater than both the analog and non-optimal FOMs, thereby demonstrating the success of the optimization procedure.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_monte_carlo_simulation(sigma_t, L, alpha, N):\n    \"\"\"\n    Performs a Monte Carlo simulation for the 1D shielding problem.\n\n    Args:\n        sigma_t (float): Macroscopic total cross section (cm^-1).\n        L (float): Slab thickness (cm).\n        alpha (float): Path-stretching parameter (cm^-1).\n        N (int): Number of particle histories.\n\n    Returns:\n        tuple: (sample_mean, sample_variance, figure_of_merit)\n    \"\"\"\n    if N = 1:\n        return 0.0, 0.0, 0.0\n\n    # For the analog case, alpha=0, the biased rate is the same as the analog\n    # but the logic for weight calculation remains. We handle any floating\n    # point issues if alpha is extremely close to sigma_t.\n    if alpha = sigma_t:\n        raise ValueError(\"alpha must be strictly less than sigma_t.\")\n\n    biased_rate = sigma_t - alpha\n    \n    # Generate N random path lengths from the biased exponential distribution\n    # scale = 1/lambda, where lambda is the rate.\n    path_lengths = np.random.exponential(scale=1.0/biased_rate, size=N)\n\n    # Identify transmitted particles\n    transmitted_mask = path_lengths = L\n    transmitted_paths = path_lengths[transmitted_mask]\n\n    # Calculate scores for all histories\n    scores = np.zeros(N)\n    if transmitted_paths.size  0:\n        # The weight is applied only to transmitted particles\n        weight_factor = sigma_t / biased_rate\n        weights = weight_factor * np.exp(-alpha * transmitted_paths)\n        scores[transmitted_mask] = weights\n\n    # Calculate statistics\n    mu_hat = np.mean(scores)\n\n    # If mu_hat is 0, it means no particles were transmitted (or scores were zero).\n    # In this case, the variance is 0, and the FOM is 0.\n    if mu_hat == 0.0:\n        return 0.0, 0.0, 0.0\n\n    # Unbiased sample variance (ddof=1 for N-1 in denominator)\n    sigma_sq = np.var(scores, ddof=1)\n    \n    # If variance is 0 but mean is not, this implies a perfect estimator (infinite FOM).\n    # This shouldn't happen for this problem with N  1.\n    if sigma_sq == 0.0:\n        fom = np.inf\n    else:\n        # Based on problem def: R = hat_sigma / |hat_mu|, where hat_sigma is std dev of scores\n        # FOM = 1 / (R^2 * N)\n        # R^2 = sigma_sq / mu_hat^2\n        R_sq = sigma_sq / (mu_hat**2)\n        # Figure of Merit: FOM = 1 / (R^2 * N)\n        fom = 1.0 / (R_sq * N)\n\n    return mu_hat, sigma_sq, fom\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and produce the final output.\n    \"\"\"\n    test_cases = [\n        # (Sigma_t, L, N_pilot, N_prod)\n        (1.0, 10.0, 20000, 100000),\n        (0.2, 5.0, 20000, 100000),\n        (2.0, 1.0, 20000, 100000),\n    ]\n\n    alpha_factors = [0.0, 0.2, 0.5, 0.8, 0.95]\n    \n    final_results = []\n\n    for sigma_t, L, n_pilot, n_prod in test_cases:\n        # --- Pilot Study ---\n        pilot_results = {}\n        candidate_alphas = [factor * sigma_t for factor in alpha_factors]\n\n        for alpha in candidate_alphas:\n            _, _, fom = run_monte_carlo_simulation(sigma_t, L, alpha, n_pilot)\n            pilot_results[alpha] = fom\n        \n        # --- Parameter Selection ---\n        # Find optimal alpha (max FOM in pilot run)\n        alpha_opt = max(pilot_results, key=pilot_results.get)\n        \n        # Find a demonstrably non-optimal alpha (min FOM in pilot run)\n        # Ensure it's not the same as optimal alpha if all FOMs are equal\n        non_opt_candidates = {a: f for a, f in pilot_results.items() if a != alpha_opt}\n        if not non_opt_candidates: # all FOMs were the same\n            alpha_nonopt = min(k for k in candidate_alphas if k != alpha_opt)\n        else:\n            alpha_nonopt = min(non_opt_candidates, key=non_opt_candidates.get)\n\n        # The analog case is always a candidate for comparison\n        alpha_analog = 0.0\n\n        # --- Production Runs ---\n        _, _, fom_opt = run_monte_carlo_simulation(sigma_t, L, alpha_opt, n_prod)\n        _, _, fom_analog = run_monte_carlo_simulation(sigma_t, L, alpha_analog, n_prod)\n        _, _, fom_nonopt = run_monte_carlo_simulation(sigma_t, L, alpha_nonopt, n_prod)\n\n        # --- Validation  Reporting ---\n        opt_gt_analog = fom_opt  fom_analog\n        opt_gt_nonopt = fom_opt  fom_nonopt\n\n        result_for_case = [\n            alpha_opt,\n            fom_opt,\n            fom_analog,\n            fom_nonopt,\n            opt_gt_analog,\n            opt_gt_nonopt\n        ]\n        final_results.append(result_for_case)\n\n    # Format the final output string as specified\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        }
    ]
}