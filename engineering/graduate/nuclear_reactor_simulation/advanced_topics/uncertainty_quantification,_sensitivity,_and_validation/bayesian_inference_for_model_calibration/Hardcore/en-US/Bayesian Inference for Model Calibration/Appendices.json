{
    "hands_on_practices": [
        {
            "introduction": "Before tackling complex computational methods, it is essential to master the fundamental mechanics of Bayesian inference. This first exercise provides a foundational \"pencil-and-paper\" task to demonstrate the principle of conjugacy, where the posterior distribution belongs to the same family as the prior. You will derive the posterior distribution for the noise precision of a Gaussian measurement model, a classic example of how prior beliefs are analytically updated by data .",
            "id": "4215202",
            "problem": "In a pressurized water reactor core simulation, suppose a high-fidelity neutron transport model predicts a stable in-core detector count rate with known expected value $\\mu$ under a fixed operating condition. You collect $n$ independent detector readings $y_{1},\\dots,y_{n}$ from the same condition, and model the measurement and unresolved modeling noise as Gaussian with precision $\\tau = 1/\\sigma^{2}$, so that the likelihood for each observation satisfies $y_{i} \\mid \\tau \\sim \\mathcal{N}(\\mu,\\tau^{-1})$ and the observations are conditionally independent given $\\tau$. To reflect prior knowledge of the noise precision in this reactor configuration, you place a Gamma prior on $\\tau$ with shape-rate parameters $(a_{0}, b_{0})$, so that $p(\\tau) \\propto \\tau^{a_{0}-1} \\exp(-b_{0}\\tau)$ for $\\tau > 0$.\n\nStarting only from Bayes’ theorem and the standard definition of the Gaussian likelihood and Gamma prior density, derive the normalized posterior density $p(\\tau \\mid y_{1},\\dots,y_{n},\\mu)$ in closed form and demonstrate that the Gamma family is conjugate to the Gaussian likelihood with known mean.\n\nYour final answer must be a single closed-form analytic expression for the normalized posterior density $p(\\tau \\mid y_{1},\\dots,y_{n},\\mu)$, expressed symbolically in terms of $a_{0}$, $b_{0}$, $n$, $\\mu$, and $\\sum_{i=1}^{n} (y_{i}-\\mu)^{2}$. Do not substitute numerical values. No rounding is required. Do not include units in the final expression.",
            "solution": "The problem statement is evaluated as scientifically sound, well-posed, objective, and complete. It presents a standard, formalizable problem in Bayesian statistics applied to a plausible scenario in nuclear reactor simulation. No flaws are identified. We may therefore proceed with the derivation.\n\nThe objective is to derive the posterior probability density function (PDF) for the noise precision $\\tau$, denoted as $p(\\tau \\mid \\mathbf{y}, \\mu)$, where $\\mathbf{y}$ is the vector of observations $(y_{1}, \\dots, y_{n})$. The derivation begins with Bayes' theorem, which states that the posterior is proportional to the product of the likelihood and the prior:\n$$p(\\tau \\mid \\mathbf{y}, \\mu) \\propto p(\\mathbf{y} \\mid \\tau, \\mu) p(\\tau)$$\n\nFirst, we formulate the likelihood function, $p(\\mathbf{y} \\mid \\tau, \\mu)$. The problem states that the observations $y_{i}$ are conditionally independent given $\\tau$ and $\\mu$. Therefore, the joint likelihood of the entire dataset $\\mathbf{y}$ is the product of the individual likelihoods for each observation $y_{i}$:\n$$p(\\mathbf{y} \\mid \\tau, \\mu) = \\prod_{i=1}^{n} p(y_{i} \\mid \\tau, \\mu)$$\nEach observation $y_{i}$ is drawn from a Gaussian (Normal) distribution with a known mean $\\mu$ and precision $\\tau$, i.e., $y_{i} \\sim \\mathcal{N}(\\mu, \\tau^{-1})$. The PDF for a single observation is:\n$$p(y_{i} \\mid \\tau, \\mu) = \\frac{1}{\\sqrt{2\\pi(\\tau^{-1})}} \\exp\\left( -\\frac{(y_{i} - \\mu)^{2}}{2(\\tau^{-1})} \\right) = \\left(\\frac{\\tau}{2\\pi}\\right)^{\\frac{1}{2}} \\exp\\left( -\\frac{\\tau}{2}(y_{i} - \\mu)^{2} \\right)$$\nSubstituting this into the product for the joint likelihood gives:\n$$p(\\mathbf{y} \\mid \\tau, \\mu) = \\prod_{i=1}^{n} \\left[ \\left(\\frac{\\tau}{2\\pi}\\right)^{\\frac{1}{2}} \\exp\\left( -\\frac{\\tau}{2}(y_{i} - \\mu)^{2} \\right) \\right]$$\n$$p(\\mathbf{y} \\mid \\tau, \\mu) = \\left(\\frac{\\tau}{2\\pi}\\right)^{\\frac{n}{2}} \\exp\\left( -\\frac{\\tau}{2} \\sum_{i=1}^{n} (y_{i} - \\mu)^{2} \\right)$$\n\nNext, we specify the prior distribution for $\\tau$. The problem states that $\\tau$ follows a Gamma distribution with shape parameter $a_{0}$ and rate parameter $b_{0}$, denoted $\\tau \\sim \\text{Gamma}(a_{0}, b_{0})$. The PDF of the prior is given in its proportional form:\n$$p(\\tau) \\propto \\tau^{a_{0}-1} \\exp(-b_{0}\\tau)$$\n\nNow, we combine the likelihood and the prior using Bayes' theorem. We are interested in the posterior distribution of $\\tau$, so we can drop any factors that are not functions of $\\tau$.\n$$p(\\tau \\mid \\mathbf{y}, \\mu) \\propto p(\\mathbf{y} \\mid \\tau, \\mu) p(\\tau)$$\n$$p(\\tau \\mid \\mathbf{y}, \\mu) \\propto \\left[ \\left(\\frac{\\tau}{2\\pi}\\right)^{\\frac{n}{2}} \\exp\\left( -\\frac{\\tau}{2} \\sum_{i=1}^{n} (y_{i} - \\mu)^{2} \\right) \\right] \\times \\left[ \\tau^{a_{0}-1} \\exp(-b_{0}\\tau) \\right]$$\nDropping the constant factor $(2\\pi)^{-\\frac{n}{2}}$ and combining the terms involving $\\tau$:\n$$p(\\tau \\mid \\mathbf{y}, \\mu) \\propto \\tau^{\\frac{n}{2}} \\exp\\left( -\\frac{\\tau}{2} \\sum_{i=1}^{n} (y_{i} - \\mu)^{2} \\right) \\tau^{a_{0}-1} \\exp(-b_{0}\\tau)$$\n$$p(\\tau \\mid \\mathbf{y}, \\mu) \\propto \\tau^{\\frac{n}{2} + a_{0} - 1} \\exp\\left( -b_{0}\\tau - \\frac{\\tau}{2} \\sum_{i=1}^{n} (y_{i} - \\mu)^{2} \\right)$$\nFactoring $\\tau$ out of the exponent:\n$$p(\\tau \\mid \\mathbf{y}, \\mu) \\propto \\tau^{(a_{0} + \\frac{n}{2}) - 1} \\exp\\left( -\\left[b_{0} + \\frac{1}{2} \\sum_{i=1}^{n} (y_{i} - \\mu)^{2}\\right]\\tau \\right)$$\n\nThis expression is the kernel of a probability distribution for $\\tau$. We recognize this functional form, $\\tau^{\\text{shape}-1}\\exp(-\\text{rate} \\cdot \\tau)$, as the kernel of a Gamma distribution. The posterior distribution for $\\tau$ is therefore another Gamma distribution, $p(\\tau \\mid \\mathbf{y}, \\mu) \\sim \\text{Gamma}(a_{n}, b_{n})$, with updated parameters:\nThe posterior shape parameter, $a_{n}$, is:\n$$a_{n} = a_{0} + \\frac{n}{2}$$\nThe posterior rate parameter, $b_{n}$, is:\n$$b_{n} = b_{0} + \\frac{1}{2} \\sum_{i=1}^{n} (y_{i} - \\mu)^{2}$$\n\nSince the prior distribution for $\\tau$ is from the Gamma family and the resulting posterior distribution is also from the Gamma family, we have demonstrated that the Gamma distribution is a conjugate prior for the precision parameter of a Gaussian likelihood with known mean.\n\nTo obtain the normalized posterior density, we use the standard form of the Gamma PDF, which is $p(x \\mid a, b) = \\frac{b^{a}}{\\Gamma(a)}x^{a-1}\\exp(-bx)$, where $\\Gamma(\\cdot)$ is the gamma function. By substituting the posterior parameters $a_{n}$ and $b_{n}$, we arrive at the final closed-form expression for the normalized posterior density of $\\tau$:\n$$p(\\tau \\mid y_{1},\\dots,y_{n},\\mu) = \\frac{b_{n}^{a_{n}}}{\\Gamma(a_{n})} \\tau^{a_{n}-1} \\exp(-b_{n}\\tau)$$\n$$p(\\tau \\mid y_{1},\\dots,y_{n},\\mu) = \\frac{\\left(b_{0} + \\frac{1}{2} \\sum_{i=1}^{n} (y_{i}-\\mu)^{2}\\right)^{a_{0} + \\frac{n}{2}}}{\\Gamma\\left(a_{0} + \\frac{n}{2}\\right)} \\tau^{\\left(a_{0} + \\frac{n}{2}\\right) - 1} \\exp\\left(-\\left(b_{0} + \\frac{1}{2} \\sum_{i=1}^{n} (y_{i}-\\mu)^{2}\\right)\\tau\\right)$$\nThis is the complete analytical expression for the normalized posterior density.",
            "answer": "$$\\boxed{\\frac{\\left(b_{0} + \\frac{1}{2} \\sum_{i=1}^{n} (y_{i}-\\mu)^{2}\\right)^{a_{0} + \\frac{n}{2}}}{\\Gamma\\left(a_{0} + \\frac{n}{2}\\right)} \\tau^{\\left(a_{0} + \\frac{n}{2}\\right) - 1} \\exp\\left(-\\left(b_{0} + \\frac{1}{2} \\sum_{i=1}^{n} (y_{i}-\\mu)^{2}\\right)\\tau\\right)}$$"
        },
        {
            "introduction": "A correct model structure is just as important as the data used for calibration, and a common pitfall is failing to account for systematic errors or model discrepancies. This practice confronts this critical challenge by simulating a scenario where a persistent bias affects reactivity measurements. By comparing the posterior distribution of a sensitivity parameter from a model that correctly includes a bias term with one that naively ignores it, you will quantify how model misspecification leads to distorted parameter estimates and dangerously overconfident conclusions .",
            "id": "4215247",
            "problem": "Consider a simplified calibration scenario for a nuclear reactor simulation where the objective is to infer a scalar sensitivity parameter that linearly relates small perturbations in reactor conditions to measured reactivity. Reactivity is defined as $\\rho = \\frac{k_{\\mathrm{eff}} - 1}{k_{\\mathrm{eff}}}$, where $k_{\\mathrm{eff}}$ is the effective multiplication factor. For sufficiently small perturbations, first-order perturbation theory and reactor sensitivity analysis justify a linear model for the measured reactivity across a set of experiments. Specifically, suppose each experiment $i$ yields a reactivity measurement $y_i$ satisfying the model\n$$\ny_i = s_i\\,\\theta + b + \\varepsilon_i,\n$$\nwhere $s_i$ is a known dimensionless sensitivity multiplier for experiment $i$, $\\theta$ is the unknown scalar sensitivity parameter, $b$ is an unknown systematic bias term representing a model discrepancy or instrumentation offset, and $\\varepsilon_i$ is a zero-mean Gaussian measurement noise with variance $\\sigma^2$. All reactivities $y_i$, the sensitivity parameter $\\theta$, the bias $b$, and the noise $\\varepsilon_i$ must be expressed in per cent mille (pcm). The multipliers $s_i$ are dimensionless.\n\nAdopt a Bayesian formulation with Gaussian priors and Gaussian likelihood. Let the prior for $\\theta$ be $\\theta \\sim \\mathcal{N}(\\theta_0, \\sigma_{\\theta,0}^2)$ and the prior for $b$ be $b \\sim \\mathcal{N}(0, \\sigma_{b,0}^2)$, independent of $\\theta$. The likelihood is $\\mathbf{y} \\mid \\theta, b \\sim \\mathcal{N}(\\mathbf{H}\\mathbf{x}, \\sigma^2 \\mathbf{I})$, where $\\mathbf{x} = \\begin{bmatrix}\\theta \\\\ b\\end{bmatrix}$, $\\mathbf{H}$ is the $N \\times 2$ design matrix with rows $\\begin{bmatrix}s_i & 1\\end{bmatrix}$, and $\\mathbf{y}$ is the $N \\times 1$ vector of observations. Under this linear-Gaussian model, the posterior $\\mathbf{x} \\mid \\mathbf{y}$ is multivariate normal.\n\nNow consider the distortion that arises when the bias term is ignored in the calibration, i.e., one incorrectly assumes $b = 0$ and fits the reduced model $y_i = s_i\\,\\theta + \\varepsilon_i$. This omission can cause the posterior for $\\theta$ to absorb systematic offsets, leading to biased estimates and miscalibrated uncertainty.\n\nYour task is to:\n\n- Derive, from Bayes' theorem and properties of linear-Gaussian models, the posterior distribution for $\\theta$ with and without the bias term $b$.\n- Quantify the effect of ignoring $b$ by comparing the marginal posterior of $\\theta$ under the bias-aware model to the posterior under the bias-ignorant model via:\n  1. The absolute difference of posterior means $\\left|\\mu_{\\theta,\\mathrm{aware}} - \\mu_{\\theta,\\mathrm{ignorant}}\\right|$ in pcm.\n  2. The ratio of posterior variances $\\sigma^2_{\\theta,\\mathrm{ignorant}} / \\sigma^2_{\\theta,\\mathrm{aware}}$ (dimensionless).\n  3. The Kullback–Leibler divergence $D_{\\mathrm{KL}}\\left(\\mathcal{N}(\\mu_{\\theta,\\mathrm{aware}}, \\sigma^2_{\\theta,\\mathrm{aware}})\\,\\|\\,\\mathcal{N}(\\mu_{\\theta,\\mathrm{ignorant}}, \\sigma^2_{\\theta,\\mathrm{ignorant}})\\right)$ (dimensionless).\n\nUse the following test suite with specified parameters and units. In each case, construct $\\mathbf{y}$ deterministically using the given true values and a fixed noise realization. All $y_i$, $\\theta$, $b$, and $\\varepsilon_i$ are in pcm; $\\sigma$ is in pcm; variances are in $\\mathrm{pcm}^2$.\n\nTest Case A (general case):\n- Number of experiments $N = 6$.\n- Sensitivity multipliers $\\mathbf{s} = [\\,0.5,\\, 0.8,\\, 1.2,\\, -0.7,\\, 0.0,\\, 0.3\\,]$.\n- Prior mean and variance for $\\theta$: $\\theta_0 = 0$ and $\\sigma_{\\theta,0}^2 = 10{,}000$.\n- Prior variance for $b$: $\\sigma_{b,0}^2 = 2{,}500$.\n- Noise standard deviation: $\\sigma = 20$.\n- True values: $\\theta_{\\mathrm{true}} = 100$, $b_{\\mathrm{true}} = 50$.\n- Fixed noise realization: $\\boldsymbol{\\varepsilon} = [\\,10,\\,-15,\\,5,\\,0,\\,8,\\,-12\\,]$.\n- Observations: $y_i = s_i\\,\\theta_{\\mathrm{true}} + b_{\\mathrm{true}} + \\varepsilon_i$.\n\nTest Case B (high bias, low noise):\n- Number of experiments $N = 4$.\n- Sensitivity multipliers $\\mathbf{s} = [\\,1.0,\\, 1.1,\\, 0.9,\\, 1.3\\,]$.\n- Prior mean and variance for $\\theta$: $\\theta_0 = 0$ and $\\sigma_{\\theta,0}^2 = 5{,}000$.\n- Prior variance for $b$: $\\sigma_{b,0}^2 = 5{,}000$.\n- Noise standard deviation: $\\sigma = 5$.\n- True values: $\\theta_{\\mathrm{true}} = 20$, $b_{\\mathrm{true}} = 200$.\n- Fixed noise realization: $\\boldsymbol{\\varepsilon} = [\\,3,\\,-2,\\,1,\\,0\\,]$.\n- Observations: $y_i = s_i\\,\\theta_{\\mathrm{true}} + b_{\\mathrm{true}} + \\varepsilon_i$.\n\nTest Case C (zero bias, high noise, includes zero/negative sensitivities):\n- Number of experiments $N = 5$.\n- Sensitivity multipliers $\\mathbf{s} = [\\,0.2,\\,-0.1,\\, 0.0,\\, 0.05,\\,-0.3\\,]$.\n- Prior mean and variance for $\\theta$: $\\theta_0 = 0$ and $\\sigma_{\\theta,0}^2 = 20{,}000$.\n- Prior variance for $b$: $\\sigma_{b,0}^2 = 20{,}000$.\n- Noise standard deviation: $\\sigma = 50$.\n- True values: $\\theta_{\\mathrm{true}} = 40$, $b_{\\mathrm{true}} = 0$.\n- Fixed noise realization: $\\boldsymbol{\\varepsilon} = [\\,20,\\,-10,\\,5,\\,0,\\,-5\\,]$.\n- Observations: $y_i = s_i\\,\\theta_{\\mathrm{true}} + b_{\\mathrm{true}} + \\varepsilon_i$.\n\nYour program must compute, for each test case, the three metrics listed above and produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s results must be an inner list of three floats in the order described, so the final output must look like\n$$\n[\\,[\\delta\\mu_{\\mathrm{A}}, r_{\\mathrm{A}}, D_{\\mathrm{KL},\\mathrm{A}}],\\,[\\delta\\mu_{\\mathrm{B}}, r_{\\mathrm{B}}, D_{\\mathrm{KL},\\mathrm{B}}],\\,[\\delta\\mu_{\\mathrm{C}}, r_{\\mathrm{C}}, D_{\\mathrm{KL},\\mathrm{C}}]\\,].\n$$\nAll mean differences $\\delta\\mu$ must be in pcm, all variance ratios $r$ must be dimensionless, and all Kullback–Leibler divergences $D_{\\mathrm{KL}}$ must be dimensionless. The final print must contain only this single line in the specified format.",
            "solution": "We begin with the physical grounding and statistical formulation. Reactivity $\\rho$ is defined by $\\rho = \\frac{k_{\\mathrm{eff}} - 1}{k_{\\mathrm{eff}}}$. For small perturbations in a reactor parameter, first-order perturbation theory and sensitivity analysis imply that the change in reactivity is approximately linear in the perturbation. Therefore, across a set of experiments indexed by $i \\in \\{1,\\dots,N\\}$, we model reactivity measurements $y_i$ as\n$$\ny_i = s_i\\,\\theta + b + \\varepsilon_i,\n$$\nwhere $s_i$ is a known dimensionless multiplier, $\\theta$ is a scalar sensitivity parameter in per cent mille, $b$ is a systematic bias term in per cent mille, and $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ are independent Gaussian noise terms with variance $\\sigma^2$ in $\\mathrm{pcm}^2$. This linear formulation follows from the well-tested principle that first-order sensitivities map small parameter perturbations to observable response changes.\n\nWe adopt independent Gaussian priors for $\\theta$ and $b$:\n$$\n\\theta \\sim \\mathcal{N}(\\theta_0,\\sigma_{\\theta,0}^2), \\quad b \\sim \\mathcal{N}(0,\\sigma_{b,0}^2).\n$$\nLet $\\mathbf{x} = \\begin{bmatrix}\\theta \\\\ b\\end{bmatrix}$, $\\mathbf{y} = \\begin{bmatrix}y_1 \\\\ \\vdots \\\\ y_N\\end{bmatrix}$, and $\\mathbf{H}$ be the $N \\times 2$ design matrix with rows $\\begin{bmatrix}s_i & 1\\end{bmatrix}$. Then the likelihood is\n$$\n\\mathbf{y} \\mid \\mathbf{x} \\sim \\mathcal{N}(\\mathbf{H}\\mathbf{x}, \\sigma^2 \\mathbf{I}),\n$$\nand the prior is\n$$\n\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0, \\boldsymbol{\\Sigma}_0), \\quad \\boldsymbol{\\mu}_0 = \\begin{bmatrix}\\theta_0 \\\\ 0\\end{bmatrix}, \\quad \\boldsymbol{\\Sigma}_0 = \\begin{bmatrix}\\sigma_{\\theta,0}^2 & 0 \\\\ 0 & \\sigma_{b,0}^2\\end{bmatrix}.\n$$\nBy Bayes' theorem for linear-Gaussian models, the posterior is multivariate normal:\n$$\n\\mathbf{x} \\mid \\mathbf{y} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_{\\mathrm{post}}, \\boldsymbol{\\Sigma}_{\\mathrm{post}}),\n$$\nwith\n$$\n\\boldsymbol{\\Sigma}_{\\mathrm{post}} = \\left(\\boldsymbol{\\Sigma}_0^{-1} + \\frac{1}{\\sigma^2}\\mathbf{H}^\\top \\mathbf{H}\\right)^{-1}, \\quad\n\\boldsymbol{\\mu}_{\\mathrm{post}} = \\boldsymbol{\\Sigma}_{\\mathrm{post}}\\left(\\boldsymbol{\\Sigma}_0^{-1}\\boldsymbol{\\mu}_0 + \\frac{1}{\\sigma^2}\\mathbf{H}^\\top \\mathbf{y}\\right).\n$$\nThe marginal posterior for $\\theta$ under this bias-aware model is the first component of $\\boldsymbol{\\mu}_{\\mathrm{post}}$ with variance given by the $(1,1)$ element of $\\boldsymbol{\\Sigma}_{\\mathrm{post}}$:\n$$\n\\theta \\mid \\mathbf{y}, \\text{bias-aware} \\sim \\mathcal{N}\\left(\\mu_{\\theta,\\mathrm{aware}}, \\sigma^2_{\\theta,\\mathrm{aware}}\\right),\n$$\nwhere $\\mu_{\\theta,\\mathrm{aware}} = [\\boldsymbol{\\mu}_{\\mathrm{post}}]_1$ and $\\sigma^2_{\\theta,\\mathrm{aware}} = [\\boldsymbol{\\Sigma}_{\\mathrm{post}}]_{11}$.\n\nIf one ignores the bias term by erroneously fixing $b = 0$, the reduced model becomes $y_i = s_i\\,\\theta + \\varepsilon_i$. The likelihood simplifies to\n$$\n\\mathbf{y} \\mid \\theta \\sim \\mathcal{N}(\\mathbf{s}\\,\\theta, \\sigma^2 \\mathbf{I}),\n$$\nwhere $\\mathbf{s} = \\begin{bmatrix}s_1 \\\\ \\vdots \\\\ s_N\\end{bmatrix}$, and the prior remains $\\theta \\sim \\mathcal{N}(\\theta_0, \\sigma_{\\theta,0}^2)$. This is a conjugate normal-normal setup with scalar parameter $\\theta$. The posterior is\n$$\n\\theta \\mid \\mathbf{y}, \\text{bias-ignorant} \\sim \\mathcal{N}\\left(\\mu_{\\theta,\\mathrm{ignorant}}, \\sigma^2_{\\theta,\\mathrm{ignorant}}\\right),\n$$\nwhere\n$$\n\\sigma^2_{\\theta,\\mathrm{ignorant}} = \\left(\\frac{1}{\\sigma_{\\theta,0}^2} + \\frac{1}{\\sigma^2}\\sum_{i=1}^N s_i^2\\right)^{-1},\n\\quad\n\\mu_{\\theta,\\mathrm{ignorant}} = \\sigma^2_{\\theta,\\mathrm{ignorant}}\\left(\\frac{\\theta_0}{\\sigma_{\\theta,0}^2} + \\frac{1}{\\sigma^2}\\sum_{i=1}^N s_i y_i\\right).\n$$\nThese expressions follow from completing the square in the exponent of the joint Gaussian density and using the normal-normal conjugacy.\n\nIgnoring the bias term distorts the posterior because the additive offset $b$ shifts all $y_i$ in the same direction, and in the reduced model this systematic offset is attributed to $\\theta$ through the projection onto $\\mathbf{s}$. Specifically, when $\\sum_{i=1}^N s_i \\neq 0$, the sufficient statistic $\\sum_{i=1}^N s_i y_i$ includes a contribution $\\sum_{i=1}^N s_i b$ that inflates or deflates $\\mu_{\\theta,\\mathrm{ignorant}}$ relative to $\\mu_{\\theta,\\mathrm{aware}}$. Moreover, the variance $\\sigma^2_{\\theta,\\mathrm{ignorant}}$ is artificially reduced because uncertainty from $b$ is not propagated, yielding overconfident estimates.\n\nTo quantify the distortion, we compute for each test case:\n1. The absolute posterior mean difference\n$$\n\\delta\\mu = \\left|\\mu_{\\theta,\\mathrm{aware}} - \\mu_{\\theta,\\mathrm{ignorant}}\\right| \\quad \\text{(pcm)}.\n$$\n2. The posterior variance ratio\n$$\nr = \\frac{\\sigma^2_{\\theta,\\mathrm{ignorant}}}{\\sigma^2_{\\theta,\\mathrm{aware}}} \\quad \\text{(dimensionless)}.\n$$\n3. The Kullback–Leibler divergence for univariate normal distributions,\n$$\nD_{\\mathrm{KL}}\\left(\\mathcal{N}(\\mu_0,\\sigma_0^2)\\,\\|\\,\\mathcal{N}(\\mu_1,\\sigma_1^2)\\right)\n= \\frac{1}{2}\\left[\\ln\\left(\\frac{\\sigma_1^2}{\\sigma_0^2}\\right) + \\frac{\\sigma_0^2 + (\\mu_0 - \\mu_1)^2}{\\sigma_1^2} - 1\\right],\n$$\nevaluated with $\\mu_0 = \\mu_{\\theta,\\mathrm{aware}}$, $\\sigma_0^2 = \\sigma^2_{\\theta,\\mathrm{aware}}$, $\\mu_1 = \\mu_{\\theta,\\mathrm{ignorant}}$, and $\\sigma_1^2 = \\sigma^2_{\\theta,\\mathrm{ignorant}}$.\n\nAlgorithmically, for each test case:\n- Assemble $\\mathbf{s}$, the prior parameters $\\theta_0$, $\\sigma_{\\theta,0}^2$, and $\\sigma_{b,0}^2$, the noise variance $\\sigma^2$, and the observation vector $\\mathbf{y}$ using the given true values and fixed noise realization.\n- Compute the bias-aware posterior by forming $\\mathbf{H}$, evaluating $\\boldsymbol{\\Sigma}_{\\mathrm{post}}$ and $\\boldsymbol{\\mu}_{\\mathrm{post}}$, and extracting $\\mu_{\\theta,\\mathrm{aware}}$ and $\\sigma^2_{\\theta,\\mathrm{aware}}$.\n- Compute the bias-ignorant posterior using the scalar formulas for $\\mu_{\\theta,\\mathrm{ignorant}}$ and $\\sigma^2_{\\theta,\\mathrm{ignorant}}$.\n- Compute $\\delta\\mu$, $r$, and $D_{\\mathrm{KL}}$ as specified.\n- Output the results for all test cases in the single-line list format.\n\nThis procedure cleanly integrates the physical linear-response foundation with Bayesian inference to reveal, numerically, how ignoring a systematic bias term can skew posterior estimates and uncertainty quantification for reactor sensitivity calibration.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef posterior_bias_aware(s, y, theta0, var_theta0, var_b0, sigma2):\n    \"\"\"\n    Compute posterior for [theta, b] under the bias-aware linear-Gaussian model.\n    Returns marginal mean and variance for theta.\n    \"\"\"\n    s = np.asarray(s, dtype=float)\n    y = np.asarray(y, dtype=float)\n    N = s.size\n    # Design matrix H with columns [s, 1]\n    H = np.column_stack([s, np.ones(N)])\n    # Prior mean and covariance\n    mu0 = np.array([theta0, 0.0])\n    Sigma0 = np.diag([var_theta0, var_b0])\n    # Posterior covariance and mean\n    inv_Sigma0 = np.linalg.inv(Sigma0)\n    Sigma_post = np.linalg.inv(inv_Sigma0 + (H.T @ H) / sigma2)\n    mu_post = Sigma_post @ (inv_Sigma0 @ mu0 + (H.T @ y) / sigma2)\n    # Marginal for theta\n    mu_theta = float(mu_post[0])\n    var_theta = float(Sigma_post[0, 0])\n    return mu_theta, var_theta\n\ndef posterior_bias_ignorant(s, y, theta0, var_theta0, sigma2):\n    \"\"\"\n    Compute posterior for theta under the bias-ignorant model (b fixed to 0).\n    Returns mean and variance for theta.\n    \"\"\"\n    s = np.asarray(s, dtype=float)\n    y = np.asarray(y, dtype=float)\n    sum_s2 = float(np.sum(s**2))\n    sum_sy = float(np.sum(s * y))\n    var_post = 1.0 / (1.0 / var_theta0 + sum_s2 / sigma2)\n    mu_post = var_post * (theta0 / var_theta0 + sum_sy / sigma2)\n    return float(mu_post), float(var_post)\n\ndef kl_normal(mu0, var0, mu1, var1):\n    \"\"\"\n    KL divergence D_KL(N(mu0,var0) || N(mu1,var1)) for univariate normals.\n    \"\"\"\n    return 0.5 * (np.log(var1 / var0) + (var0 + (mu0 - mu1) ** 2) / var1 - 1.0)\n\ndef build_observations(s, theta_true, b_true, eps):\n    s = np.asarray(s, dtype=float)\n    eps = np.asarray(eps, dtype=float)\n    return list(s * theta_true + b_true + eps)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case A\n        {\n            \"s\": [0.5, 0.8, 1.2, -0.7, 0.0, 0.3],\n            \"theta0\": 0.0,\n            \"var_theta0\": 10000.0,  # pcm^2\n            \"var_b0\": 2500.0,       # pcm^2\n            \"sigma\": 20.0,          # pcm\n            \"theta_true\": 100.0,    # pcm\n            \"b_true\": 50.0,         # pcm\n            \"eps\": [10.0, -15.0, 5.0, 0.0, 8.0, -12.0],  # pcm\n        },\n        # Test Case B\n        {\n            \"s\": [1.0, 1.1, 0.9, 1.3],\n            \"theta0\": 0.0,\n            \"var_theta0\": 5000.0,   # pcm^2\n            \"var_b0\": 5000.0,       # pcm^2\n            \"sigma\": 5.0,           # pcm\n            \"theta_true\": 20.0,     # pcm\n            \"b_true\": 200.0,        # pcm\n            \"eps\": [3.0, -2.0, 1.0, 0.0],  # pcm\n        },\n        # Test Case C\n        {\n            \"s\": [0.2, -0.1, 0.0, 0.05, -0.3],\n            \"theta0\": 0.0,\n            \"var_theta0\": 20000.0,  # pcm^2\n            \"var_b0\": 20000.0,      # pcm^2\n            \"sigma\": 50.0,          # pcm\n            \"theta_true\": 40.0,     # pcm\n            \"b_true\": 0.0,          # pcm\n            \"eps\": [20.0, -10.0, 5.0, 0.0, -5.0],  # pcm\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        s = case[\"s\"]\n        theta0 = case[\"theta0\"]\n        var_theta0 = case[\"var_theta0\"]\n        var_b0 = case[\"var_b0\"]\n        sigma2 = case[\"sigma\"] ** 2\n        theta_true = case[\"theta_true\"]\n        b_true = case[\"b_true\"]\n        eps = case[\"eps\"]\n\n        # Build observations deterministically\n        y = build_observations(s, theta_true, b_true, eps)\n\n        # Posterior including bias term\n        mu_a, var_a = posterior_bias_aware(s, y, theta0, var_theta0, var_b0, sigma2)\n\n        # Posterior ignoring bias term\n        mu_i, var_i = posterior_bias_ignorant(s, y, theta0, var_theta0, sigma2)\n\n        # Metrics\n        delta_mu = abs(mu_a - mu_i)  # pcm\n        var_ratio = var_i / var_a    # dimensionless\n        dkl = kl_normal(mu_a, var_a, mu_i, var_i)  # dimensionless\n\n        results.append([delta_mu, var_ratio, dkl])\n\n    # Final print statement in the exact required format.\n    # Ensure single-line output of nested list with comma-separated floats.\n    print(f\"[{','.join('[' + ','.join(map(str, triple)) + ']' for triple in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The final step in a robust Bayesian workflow is model checking. After calibrating your parameters, you must ask: \"Is the model adequate for its purpose?\" This exercise introduces the powerful technique of Posterior Predictive Checking (PPC) to answer that question, using a model of a reactor's axial power distribution. You will use the calibrated model to generate replicate datasets, allowing you to systematically check if the model can reproduce key features of the actual observed data .",
            "id": "4215171",
            "problem": "Consider the axial power distribution in a pressurized water reactor core modeled along the axial coordinate $z \\in [0,H]$ where $H$ is the active core height expressed in meters. Under the One-Group Neutron Diffusion Equation in slab geometry with vacuum boundary conditions, axial neutron flux eigenfunctions are sinusoidal. A truncated basis is used to approximate the normalized axial power profile. Define three basis functions $f_0(z) = 1$, $f_1(z) = \\sin\\left(\\pi z / H\\right)$, and $f_2(z) = \\sin\\left(2\\pi z / H\\right)$. Let $N$ be the number of instrumented axial levels, and let $z_i = i \\cdot H/(N-1)$ for $i = 0,1,\\dots,N-1$.\n\nAssume a linear model for the observed axial power at these levels,\n$$\ny_i = \\theta_0 f_0(z_i) + \\theta_1 f_1(z_i) + \\theta_2 f_2(z_i) + \\varepsilon_i,\n$$\nwhere $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ independently across $i$ and $\\sigma^2$ is known. In matrix form, with $y \\in \\mathbb{R}^N$, $\\theta \\in \\mathbb{R}^3$, and design matrix $A \\in \\mathbb{R}^{N\\times 3}$ whose columns are the basis functions evaluated at $\\{z_i\\}$, this is\n$$\ny = A \\theta + \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0,\\sigma^2 I_N).\n$$\n\nAdopt a Gaussian prior on the coefficients,\n$$\n\\theta \\sim \\mathcal{N}(\\mu_0,\\Sigma_0),\n$$\nwith specified mean vector $\\mu_0 \\in \\mathbb{R}^3$ and covariance matrix $\\Sigma_0 \\in \\mathbb{R}^{3\\times 3}$ that is symmetric positive definite.\n\nYour task is to calibrate the model via Bayesian inference and then construct a Posterior Predictive Check (PPC). Let the axial peaking factor statistic be\n$$\nT(y) = \\frac{\\max_i y_i}{\\frac{1}{N} \\sum_{i=1}^N y_i}.\n$$\nDefine the posterior predictive $p$-value\n$$\np = \\Pr\\{T(y^{\\text{rep}}) \\ge T(y) \\mid y\\},\n$$\nwhere $y^{\\text{rep}}$ is a replicate dataset generated from the posterior predictive distribution. The posterior predictive distribution is defined by integrating the sampling distribution $y^{\\text{rep}} \\mid \\theta$ against the posterior distribution $\\theta \\mid y$. The program must approximate $p$ by Monte Carlo sampling: draw $\\theta^{(m)} \\sim p(\\theta \\mid y)$ and then $y^{\\text{rep},(m)} \\sim p(y^{\\text{rep}} \\mid \\theta^{(m)})$, for $m=1,\\dots,M$, and estimate\n$$\n\\hat{p} = \\frac{1}{M} \\sum_{m=1}^M \\mathbf{1}\\left\\{T\\left(y^{\\text{rep},(m)}\\right) \\ge T(y)\\right\\}.\n$$\n\nStart from well-tested physical and statistical foundations: the One-Group Neutron Diffusion Equation motivates sinusoidal axial modes, and linear-Gaussian models imply Gaussian posteriors under Gaussian priors. Derive the posterior distribution $p(\\theta \\mid y)$ from these foundations, without invoking any shortcut formulas not implied directly by these bases.\n\nThe observed data $y$ for each test case must be generated inside your program using the specified parameters and a fixed random seed as part of the test definition. For each test case, use the positions $z_i$ defined above and generate $y$ via the sampling model using a specified “true” coefficient vector $\\theta^{\\text{true}}$; then compute the posterior and the PPC $p$-value based on that $y$.\n\nPhysical units: The height $H$ must be specified in meters. The axial peaking factor $T(y)$ and the $p$-value are dimensionless quantities. Report the final $p$-values as decimals.\n\nAngle unit: All angles inside trigonometric functions are dimensionless arguments formed as ratios of lengths; no angle unit conversion is required because $\\sin(\\cdot)$ is evaluated on dimensionless quantities $\\pi z/H$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[p_1,p_2,p_3,p_4]$).\n\nTest suite. Implement the following four test cases, each with a fixed Monte Carlo sample size $M = 20000$ and independent random seed. For reproducibility, use the specified seed for both generating the observed data and for posterior predictive sampling within that case.\n\n- Case $1$ (general case): $H=4.0$ meters, $N=41$, $\\sigma = 0.02$, $\\mu_0 = [1.0, 0.0, 0.0]$, $\\Sigma_0 = \\operatorname{diag}([0.05^2, 0.2^2, 0.2^2])$, $\\theta^{\\text{true}} = [1.05, 0.15, -0.05]$, seed $= 12345$.\n- Case $2$ (near-deterministic boundary): $H=4.0$ meters, $N=41$, $\\sigma = 0.0001$, $\\mu_0 = [1.0, 0.0, 0.0]$, $\\Sigma_0 = \\operatorname{diag}([0.05^2, 0.2^2, 0.2^2])$, $\\theta^{\\text{true}} = [1.05, 0.15, -0.05]$, seed $= 23456$.\n- Case $3$ (low-resolution edge): $H=4.0$ meters, $N=3$, $\\sigma = 0.05$, $\\mu_0 = [1.0, 0.1, 0.0]$, $\\Sigma_0 = \\operatorname{diag}([0.1^2, 0.3^2, 0.3^2])$, $\\theta^{\\text{true}} = [1.1, 0.3, 0.0]$, seed $= 34567$.\n- Case $4$ (strong prior influence): $H=4.0$ meters, $N=21$, $\\sigma = 0.02$, $\\mu_0 = [0.9, 0.0, 0.0]$, $\\Sigma_0 = \\operatorname{diag}([0.01^2, 0.02^2, 0.02^2])$, $\\theta^{\\text{true}} = [1.2, 0.25, 0.05]$, seed $= 45678$.\n\nOutput specification: Your program should produce a single line of output containing the four estimated posterior predictive $p$-values for the above cases, formatted as a comma-separated list enclosed in square brackets, with each value rounded to six decimal places, in the order of the cases $1$ through $4$, i.e., $[p_1,p_2,p_3,p_4]$.",
            "solution": "The user-provided problem has been analyzed and validated.\n\n\\textbf{Step 1: Extract Givens}\n- Domain: Axial coordinate $z \\in [0,H]$, $H$ is core height in meters.\n- Basis Functions: $f_0(z) = 1$, $f_1(z) = \\sin(\\pi z / H)$, $f_2(z) = \\sin(2\\pi z / H)$.\n- Discretization: $N$ levels, $z_i = i \\cdot H/(N-1)$ for $i=0,\\dots,N-1$.\n- Likelihood Model: $y_i = \\theta_0 f_0(z_i) + \\theta_1 f_1(z_i) + \\theta_2 f_2(z_i) + \\varepsilon_i$, with $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ i.i.d.\n- Matrix Form: $y = A \\theta + \\varepsilon$, where $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2 I_N)$.\n- Prior Distribution: $\\theta \\sim \\mathcal{N}(\\mu_0, \\Sigma_0)$, with $\\Sigma_0$ symmetric positive definite.\n- Test Statistic: Axial peaking factor, $T(y) = \\frac{\\max_i y_i}{\\frac{1}{N} \\sum_{i=1}^N y_i}$.\n- Objective: Estimate the posterior predictive $p$-value, $p = \\Pr\\{T(y^{\\text{rep}}) \\ge T(y) \\mid y\\}$, via Monte Carlo simulation with $M$ samples.\n- Data Generation: Observed data $y$ for each case is to be generated from the likelihood model using a provided \"true\" parameter vector $\\theta^{\\text{true}}$ and a fixed random seed.\n- Test Suite: Four specific test cases are provided with all necessary parameters: $H, N, \\sigma, \\mu_0, \\Sigma_0, \\theta^{\\text{true}}, M, \\text{seed}$.\n\n\\textbf{Step 2: Validate Using Extracted Givens}\nThe problem is assessed to be valid.\n- It is scientifically grounded, using a standard simplified model for reactor physics (diffusion theory basis functions) and a standard statistical methodology (Bayesian inference for a linear-Gaussian model).\n- It is well-posed. All mathematical objects are well-defined, and the provision of a positive definite prior covariance matrix $\\Sigma_0$ ensures that the posterior distribution is well-defined and proper, even if the design matrix $A$ were to have linearly dependent columns (which occurs in Case 3, but is handled correctly by the Bayesian framework).\n- It is objective and self-contained, providing all necessary data and definitions for a unique solution.\n- The parameters are physically plausible within the context of a simplified simulation.\n\n\\textbf{Step 3: Verdict and Action}\nThe problem is valid. A complete, reasoned solution will be provided.\n\n\\rule{12cm}{0.4pt}\n\nThe task is to perform a Bayesian model calibration and a subsequent posterior predictive check. This requires deriving the posterior distribution for the model parameters $\\theta$ and then using this distribution to generate replicate data for comparison with the observed data.\n\n\\textbf{Derivation of the Posterior Distribution $p(\\theta \\mid y)$}\n\nThe posterior distribution is given by Bayes' theorem:\n$$\np(\\theta \\mid y) \\propto p(y \\mid \\theta) p(\\theta)\n$$\nThe likelihood $p(y \\mid \\theta)$ corresponds to the model $y = A\\theta + \\varepsilon$ with $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_N)$. Its probability density function is:\n$$\np(y \\mid \\theta) = \\frac{1}{(2\\pi\\sigma^2)^{N/2}} \\exp\\left(-\\frac{1}{2\\sigma^2}(y - A\\theta)^T(y - A\\theta)\\right)\n$$\nThe prior $p(\\theta)$ is given as a multivariate normal distribution $\\mathcal{N}(\\mu_0, \\Sigma_0)$:\n$$\np(\\theta) = \\frac{1}{(2\\pi)^{3/2}|\\Sigma_0|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\theta - \\mu_0)^T \\Sigma_0^{-1}(\\theta - \\mu_0)\\right)\n$$\nThe posterior density is proportional to the product of these two densities. We focus on the exponents, as the normalization constant can be determined at the end. The argument of the exponential for the posterior is the sum of the arguments of the exponentials for the likelihood and the prior:\n$$\n\\text{Exponent} = -\\frac{1}{2\\sigma^2}(y - A\\theta)^T(y - A\\theta) - \\frac{1}{2}(\\theta - \\mu_0)^T \\Sigma_0^{-1}(\\theta - \\mu_0)\n$$\nExpanding the terms:\n$$\n\\text{Exponent} = -\\frac{1}{2}\\left[ \\frac{1}{\\sigma^2}(y^T y - 2y^T A\\theta + \\theta^T A^T A \\theta) + (\\theta^T \\Sigma_0^{-1}\\theta - 2\\mu_0^T \\Sigma_0^{-1}\\theta + \\mu_0^T \\Sigma_0^{-1}\\mu_0) \\right]\n$$\nTo identify the form of the posterior distribution, we collect terms involving $\\theta$:\n$$\n\\text{Exponent} = -\\frac{1}{2} \\left[ \\theta^T\\left(\\frac{1}{\\sigma^2}A^T A + \\Sigma_0^{-1}\\right)\\theta - 2\\left(\\frac{1}{\\sigma^2}y^T A + \\mu_0^T \\Sigma_0^{-1}\\right)\\theta \\right] + C\n$$\nwhere $C$ contains terms not dependent on $\\theta$. This expression is a quadratic form in $\\theta$, which indicates that the posterior distribution $p(\\theta \\mid y)$ is also a multivariate normal distribution, let's say $\\mathcal{N}(\\mu_N, \\Sigma_N)$. The density of such a distribution is proportional to $\\exp\\left(-\\frac{1}{2}(\\theta - \\mu_N)^T\\Sigma_N^{-1}(\\theta - \\mu_N)\\right)$, which expands to:\n$$\n\\text{Exponent} = -\\frac{1}{2}\\left[ \\theta^T \\Sigma_N^{-1}\\theta - 2\\mu_N^T \\Sigma_N^{-1}\\theta \\right] + C'\n$$\nBy comparing the coefficients of the quadratic and linear terms in $\\theta$, we can identify the posterior parameters $\\mu_N$ and $\\Sigma_N$.\n\nThe inverse posterior covariance, $\\Sigma_N^{-1}$, is the term multiplying $\\theta^T(\\dots)\\theta$:\n$$\n\\Sigma_N^{-1} = \\frac{1}{\\sigma^2}A^T A + \\Sigma_0^{-1}\n$$\nThe posterior covariance is its inverse:\n$$\n\\Sigma_N = \\left(\\frac{1}{\\sigma^2}A^T A + \\Sigma_0^{-1}\\right)^{-1}\n$$\nThe linear term gives the relation for the posterior mean $\\mu_N$:\n$$\n\\mu_N^T \\Sigma_N^{-1} = \\frac{1}{\\sigma^2}y^T A + \\mu_0^T \\Sigma_0^{-1}\n$$\nTransposing and right-multiplying by $\\Sigma_N$ yields:\n$$\n\\mu_N = \\Sigma_N \\left( \\frac{1}{\\sigma^2}A^T y + \\Sigma_0^{-1} \\mu_0 \\right)\n$$\nThus, the posterior distribution is $p(\\theta \\mid y) = \\mathcal{N}(\\mu_N, \\Sigma_N)$ with the parameters as derived.\n\n\\textbf{Posterior Predictive Check (PPC)}\n\nThe PPC is a method to assess the goodness-of-fit of a model. We generate replicate data $y^{\\text{rep}}$ from the posterior predictive distribution, $p(y^{\\text{rep}} \\mid y)$, and compare its properties to the observed data $y$. The posterior predictive distribution is defined as:\n$$\np(y^{\\text{rep}} \\mid y) = \\int p(y^{\\text{rep}} \\mid \\theta) p(\\theta \\mid y) d\\theta\n$$\nSampling from this distribution is a two-step generative process:\n1.  Draw a parameter vector $\\theta^{(m)}$ from the posterior distribution: $\\theta^{(m)} \\sim p(\\theta \\mid y)$.\n2.  Generate a replicate dataset $y^{\\text{rep},(m)}$ from the likelihood using this parameter vector: $y^{\\text{rep},(m)} \\sim p(y \\mid \\theta^{(m)})$.\n\nThe check is performed using a test statistic $T(y)$. The problem defines the axial peaking factor:\n$$\nT(y) = \\frac{\\max_i y_i}{\\frac{1}{N} \\sum_{i=0}^{N-1} y_i}\n$$\nNote: The problem text notation $\\sum_{i=1}^N y_i$ is interpreted as the sum over all $N$ elements, which are indexed $0$ to $N-1$, as this represents the standard definition of a sample mean.\n\nThe posterior predictive $p$-value measures the probability that the test statistic calculated on replicate data is more extreme than that calculated on the observed data. It is estimated via Monte Carlo simulation:\n$$\n\\hat{p} = \\frac{1}{M} \\sum_{m=1}^{M} \\mathbf{1}\\left\\{T\\left(y^{\\text{rep},(m)}\\right) \\ge T(y)\\right\\}\n$$\nA $p$-value close to $0$ or $1$ suggests that the model is unable to reproduce the specific aspect of the data captured by the test statistic, indicating potential model misspecification or prior-data conflict.\n\n\\textbf{Algorithm for Implementation}\n\nFor each test case, the following steps are executed:\n1.  Initialize parameters from the test case: $H, N, \\sigma, \\mu_0, \\Sigma_0, \\theta^{\\text{true}}, M$, and the random number generator `seed`.\n2.  Construct the $N \\times 3$ design matrix $A$, where the columns are the basis functions $f_0, f_1, f_2$ evaluated at the $N$ axial locations $z_i = i \\cdot H/(N-1)$.\n3.  Generate the observed data vector $y$. First, compute the true mean $\\mu_y = A \\theta^{\\text{true}}$. Then, add Gaussian noise: $y = \\mu_y + \\varepsilon$, where $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2 I_N)$.\n4.  Calculate the posterior distribution parameters $\\mu_N$ and $\\Sigma_N$ using the derived formulas and the generated data $y$. This involves matrix inversions and multiplications.\n5.  Calculate the observed test statistic $T_{obs} = T(y)$.\n6.  Begin the Monte Carlo simulation with $M$ iterations:\n    a. Draw a parameter sample $\\theta^{(m)}$ from the posterior distribution $\\mathcal{N}(\\mu_N, \\Sigma_N)$.\n    b. Generate a replicate dataset $y^{\\text{rep},(m)} = A\\theta^{(m)} + \\varepsilon^{(m)}$, where $\\varepsilon^{(m)} \\sim \\mathcal{N}(0, \\sigma^2 I_N)$ is a new noise sample.\n    c. Calculate the replicate test statistic $T_{rep}^{(m)} = T(y^{\\text{rep},(m)})$.\n7.  Count the number of iterations where $T_{rep}^{(m)} \\ge T_{obs}$.\n8.  The estimated $p$-value is this count divided by $M$.\nThe final results for all test cases are collected and formatted as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are needed for this problem.\n\ndef solve():\n    \"\"\"\n    Solves the Bayesian model calibration and posterior predictive check problem\n    for a series of test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"H\": 4.0, \"N\": 41, \"sigma\": 0.02,\n            \"mu0\": np.array([1.0, 0.0, 0.0]),\n            \"Sigma0\": np.diag([0.05**2, 0.2**2, 0.2**2]),\n            \"theta_true\": np.array([1.05, 0.15, -0.05]),\n            \"M\": 20000, \"seed\": 12345\n        },\n        {\n            \"H\": 4.0, \"N\": 41, \"sigma\": 0.0001,\n            \"mu0\": np.array([1.0, 0.0, 0.0]),\n            \"Sigma0\": np.diag([0.05**2, 0.2**2, 0.2**2]),\n            \"theta_true\": np.array([1.05, 0.15, -0.05]),\n            \"M\": 20000, \"seed\": 23456\n        },\n        {\n            \"H\": 4.0, \"N\": 3, \"sigma\": 0.05,\n            \"mu0\": np.array([1.0, 0.1, 0.0]),\n            \"Sigma0\": np.diag([0.1**2, 0.3**2, 0.3**2]),\n            \"theta_true\": np.array([1.1, 0.3, 0.0]),\n            \"M\": 20000, \"seed\": 34567\n        },\n        {\n            \"H\": 4.0, \"N\": 21, \"sigma\": 0.02,\n            \"mu0\": np.array([0.9, 0.0, 0.0]),\n            \"Sigma0\": np.diag([0.01**2, 0.02**2, 0.02**2]),\n            \"theta_true\": np.array([1.2, 0.25, 0.05]),\n            \"M\": 20000, \"seed\": 45678\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Unpack parameters for the current case\n        H, N, sigma, mu0, Sigma0, theta_true, M, seed = case.values()\n        \n        # Initialize Random Number Generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # 1. Construct the design matrix A\n        z = np.linspace(0, H, N)\n        A = np.zeros((N, 3))\n        A[:, 0] = 1.0\n        A[:, 1] = np.sin(np.pi * z / H)\n        A[:, 2] = np.sin(2 * np.pi * z / H)\n\n        # 2. Generate the \"observed\" data y\n        mu_y_true = A @ theta_true\n        epsilon_obs = rng.normal(loc=0.0, scale=sigma, size=N)\n        y_obs = mu_y_true + epsilon_obs\n\n        # 3. Calculate posterior distribution parameters (mu_N, Sigma_N)\n        Sigma0_inv = np.linalg.inv(Sigma0)\n        AtA = A.T @ A\n        \n        # Posterior inverse covariance\n        Sigma_N_inv = (1 / sigma**2) * AtA + Sigma0_inv\n        \n        # Posterior covariance\n        Sigma_N = np.linalg.inv(Sigma_N_inv)\n        \n        # Posterior mean\n        Aty_obs = A.T @ y_obs\n        mu_N = Sigma_N @ ((1 / sigma**2) * Aty_obs + Sigma0_inv @ mu0)\n\n        # 4. Define the test statistic T(y)\n        def T(y_data):\n            mean_val = np.mean(y_data)\n            if mean_val == 0:\n                # This case is highly improbable given the model setup\n                return np.inf if np.max(y_data) > 0 else 0\n            return np.max(y_data) / mean_val\n\n        # 5. Calculate the statistic for the observed data\n        T_obs = T(y_obs)\n\n        # 6. Perform Monte Carlo simulation for PPC\n        \n        # Step 6a: Draw M samples from the posterior distribution of theta\n        theta_samples = rng.multivariate_normal(mu_N, Sigma_N, size=M)\n\n        # Step 6b: Generate M replicate datasets y_rep\n        # Vectorized calculation for efficiency\n        mu_rep_samples = theta_samples @ A.T  # Shape (M, N)\n        epsilon_rep_samples = rng.normal(loc=0.0, scale=sigma, size=(M, N))\n        y_rep_samples = mu_rep_samples + epsilon_rep_samples\n\n        # Step 6c: Calculate the test statistic for each replicate dataset\n        max_y_rep = np.max(y_rep_samples, axis=1)\n        mean_y_rep = np.mean(y_rep_samples, axis=1)\n        \n        # Create an array to hold T_rep values, handling potential division by zero\n        T_rep = np.full_like(mean_y_rep, np.inf)\n        # Avoid division by zero, though unlikely\n        valid_means_mask = mean_y_rep != 0\n        T_rep[valid_means_mask] = max_y_rep[valid_means_mask] / mean_y_rep[valid_means_mask]\n\n        # Step 6d  7: Count and estimate the p-value\n        num_exceed = np.sum(T_rep >= T_obs)\n        p_value = num_exceed / M\n        \n        results.append(f\"{p_value:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}