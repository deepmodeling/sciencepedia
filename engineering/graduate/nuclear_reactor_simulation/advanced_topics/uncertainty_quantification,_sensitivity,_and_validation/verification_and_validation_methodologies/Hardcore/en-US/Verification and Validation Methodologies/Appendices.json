{
    "hands_on_practices": [
        {
            "introduction": "The Method of Manufactured Solutions (MMS) is a cornerstone of code verification, offering a powerful technique to confirm that a numerical solver correctly implements its governing partial differential equations. This practice provides foundational experience with the MMS workflow, where you will 'manufacture' an analytical solution and substitute it into the heat equation. By deriving the necessary source term that makes your manufactured function an exact solution, you will set up a complete verification test case with known results .",
            "id": "4003053",
            "problem": "A computational heat transfer code is to be verified using the Method of Manufactured Solutions (MMS). Consider two-dimensional transient heat conduction in a homogeneous, isotropic medium with constant thermal diffusivity $\\alpha>0$ on the unit square domain $\\Omega=(0,1)\\times(0,1)$ for time $t>0$. The governing equation in terms of a scalar field $u(x,y,t)$ is\n$$\n\\frac{\\partial u}{\\partial t}=\\alpha\\left(\\frac{\\partial^{2}u}{\\partial x^{2}}+\\frac{\\partial^{2}u}{\\partial y^{2}}\\right)+S(x,y,t),\n$$\nwhere $S(x,y,t)$ is a volumetric source term.\n\nUsing the Method of Manufactured Solutions (MMS), let the manufactured solution be\n$$\nu(x,y,t)=\\sin(\\pi x)\\sin(\\pi y)\\exp\\!\\big(-2\\pi^{2}\\alpha t\\big).\n$$\n\nStarting from conservation of energy and Fourierâ€™s law as the fundamental base, derive the corresponding manufactured source term $S(x,y,t)$ that makes $u(x,y,t)$ an exact solution of the governing equation. Then, specify boundary and initial conditions that are strictly consistent with the manufactured solution and suitable for code verification with Dirichlet data on all sides of $\\partial\\Omega$.\n\nAnswer specification:\n- Provide your final answer as a row vector with three entries in the following order: the analytic expression for $S(x,y,t)$, the initial condition $u(x,y,0)$, and the Dirichlet boundary value $g(x,y,t)$ to be imposed on $\\partial\\Omega$.\n- Express the answer in terms of $x$, $y$, $t$, $\\alpha$, and $\\pi$ only.\n- No numerical evaluation or rounding is required, and no physical units need to be reported in the final answer.",
            "solution": "The Method of Manufactured Solutions (MMS) requires substituting the chosen manufactured solution into the governing partial differential equation (PDE) to determine the necessary source term $S(x,y,t)$ that makes the equation hold true. We start by rearranging the governing equation to solve for $S(x,y,t)$:\n$$\nS(x,y,t) = \\frac{\\partial u}{\\partial t} - \\alpha \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} \\right)\n$$\nThe manufactured solution is given as $u(x,y,t) = \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t)$. We must now compute the required partial derivatives of $u(x,y,t)$.\n\nFirst, the partial derivative with respect to time, $t$:\n$$\n\\frac{\\partial u}{\\partial t} = \\frac{\\partial}{\\partial t} \\left[ \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t) \\right]\n$$\n$$\n\\frac{\\partial u}{\\partial t} = \\sin(\\pi x)\\sin(\\pi y) \\cdot \\left( -2\\pi^2\\alpha \\right) \\exp(-2\\pi^2\\alpha t)\n$$\n$$\n\\frac{\\partial u}{\\partial t} = -2\\pi^2\\alpha \\sin(\\pi x)\\sin(\\pi y) \\exp(-2\\pi^2\\alpha t)\n$$\n\nNext, the second partial derivatives with respect to the spatial coordinates, $x$ and $y$. For $x$:\n$$\n\\frac{\\partial u}{\\partial x} = \\frac{\\partial}{\\partial x} \\left[ \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t) \\right] = \\pi \\cos(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t)\n$$\n$$\n\\frac{\\partial^2 u}{\\partial x^2} = \\frac{\\partial}{\\partial x} \\left[ \\pi \\cos(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t) \\right] = -\\pi^2 \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t)\n$$\n\nSimilarly, for $y$:\n$$\n\\frac{\\partial u}{\\partial y} = \\frac{\\partial}{\\partial y} \\left[ \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t) \\right] = \\pi \\sin(\\pi x)\\cos(\\pi y)\\exp(-2\\pi^2\\alpha t)\n$$\n$$\n\\frac{\\partial^2 u}{\\partial y^2} = \\frac{\\partial}{\\partial y} \\left[ \\pi \\sin(\\pi x)\\cos(\\pi y)\\exp(-2\\pi^2\\alpha t) \\right] = -\\pi^2 \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t)\n$$\n\nNow, we substitute these derivatives into the expression for $S(x,y,t)$:\n$$\nS(x,y,t) = \\left( -2\\pi^2\\alpha \\sin(\\pi x)\\sin(\\pi y) \\exp(-2\\pi^2\\alpha t) \\right) - \\alpha \\left[ \\left( -\\pi^2 \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t) \\right) + \\left( -\\pi^2 \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t) \\right) \\right]\n$$\n$$\nS(x,y,t) = -2\\pi^2\\alpha \\sin(\\pi x)\\sin(\\pi y) \\exp(-2\\pi^2\\alpha t) - \\alpha \\left[ -2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t) \\right]\n$$\n$$\nS(x,y,t) = -2\\pi^2\\alpha \\sin(\\pi x)\\sin(\\pi y) \\exp(-2\\pi^2\\alpha t) + 2\\pi^2\\alpha \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t)\n$$\n$$\nS(x,y,t) = 0\n$$\nThe source term is zero. This indicates that the manufactured solution is a solution to the homogeneous heat equation.\n\nNext, we specify the initial condition, $u(x,y,0)$, by evaluating the manufactured solution at $t=0$:\n$$\nu(x,y,0) = \\sin(\\pi x)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha \\cdot 0) = \\sin(\\pi x)\\sin(\\pi y)\\exp(0)\n$$\n$$\nu(x,y,0) = \\sin(\\pi x)\\sin(\\pi y)\n$$\n\nFinally, we specify the Dirichlet boundary condition, $g(x,y,t)$, by evaluating the manufactured solution on the boundary $\\partial\\Omega$ of the unit square domain $\\Omega=(0,1)\\times(0,1)$. The boundary consists of four segments: $x=0$, $x=1$, $y=0$, and $y=1$.\n- On $x=0$ ($0 \\le y \\le 1$): $g(0,y,t) = \\sin(0)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t) = 0$.\n- On $x=1$ ($0 \\le y \\le 1$): $g(1,y,t) = \\sin(\\pi)\\sin(\\pi y)\\exp(-2\\pi^2\\alpha t) = 0$.\n- On $y=0$ ($0 \\le x \\le 1$): $g(x,0,t) = \\sin(\\pi x)\\sin(0)\\exp(-2\\pi^2\\alpha t) = 0$.\n- On $y=1$ ($0 \\le x \\le 1$): $g(x,1,t) = \\sin(\\pi x)\\sin(\\pi)\\exp(-2\\pi^2\\alpha t) = 0$.\n\nSince the manufactured solution is zero on all parts of the boundary for all time $t>0$, the consistent Dirichlet boundary condition is a constant zero.\n$$\ng(x,y,t) = 0 \\quad \\text{for } (x,y) \\in \\partial\\Omega, t > 0\n$$\n\nThe three required components are:\n1. Source term: $S(x,y,t) = 0$.\n2. Initial condition: $u(x,y,0) = \\sin(\\pi x)\\sin(\\pi y)$.\n3. Dirichlet boundary condition: $g(x,y,t) = 0$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0 & \\sin(\\pi x)\\sin(\\pi y) & 0 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "After verifying the correctness of a code's implementation, the next step is solution verification: quantifying the numerical error in a computed result. This exercise introduces the Grid Convergence Index (GCI), a standardized procedure for estimating discretization error based on solutions from systematically refined meshes. By applying the GCI method, you will learn to calculate a confidence interval for your numerical prediction, a critical skill for assessing the credibility of simulations where the exact solution is unknown .",
            "id": "4003027",
            "problem": "A one-dimensional, steady-state conduction problem is solved in a homogeneous slab of length $L$ with Dirichlet boundary conditions $T(0)=T_{0}$ and $T(L)=T_{L}$ and constant thermal conductivity $k$. A finite-volume discretization with second-order central differencing is used to compute the wall heat flux magnitude at $x=0$, denoted by $\\phi$. Three uniform meshes are employed with $N_{3}=32$, $N_{2}=64$, and $N_{1}=128$ control volumes, so that the uniform refinement ratios satisfy $r_{32}=h_{3}/h_{2}=2$ and $r_{21}=h_{2}/h_{1}=2$, where $h_{j}=L/N_{j}$. The computed quantities of interest on these meshes are\n$\\phi_{3}=1.0160\\times 10^{4}$, $\\phi_{2}=1.0040\\times 10^{4}$, and $\\phi_{1}=1.0010\\times 10^{4}$.\nA separate three-grid analysis has established an apparent order of accuracy $p_{\\mathrm{obs}}=1.98$ for this quantity. Using the classical definition of the Grid Convergence Index (GCI) for the fine grid based on the discretization error model and Richardson extrapolation, and adopting the recommended safety factor $F_{s}=1.25$ for three-grid verification in the asymptotic range, compute the fine-grid Grid Convergence Index $\\mathrm{GCI}_{21}$ for $\\phi$ using the $(1,2)$ grid pair and $p_{\\mathrm{obs}}$. Round your final answer to four significant figures and express it as a dimensionless decimal fraction. In your solution, justify the GCI formula from the discretization error model and interpret the role of the safety factor $F_{s}$ in the GCI expression (conceptual interpretation only; the final answer must be the computed numerical value).",
            "solution": "The foundation of the Grid Convergence Index (GCI) is the modeling of discretization error. For a numerical scheme with an order of accuracy $p$, the solution $\\phi_h$ on a grid with characteristic size $h$ can be expressed via a Taylor series expansion of the error:\n$$\n\\phi_h = \\phi_{\\mathrm{exact}} + c h^p + O(h^{p+1})\n$$\nwhere $\\phi_{\\mathrm{exact}}$ is the exact (unknown) solution to the continuum equations, and $c$ is a constant that depends on higher-order derivatives of the solution.\n\nAssuming the grid is fine enough to be in the \"asymptotic range,\" the higher-order terms $O(h^{p+1})$ are negligible, and the error is dominated by the leading term:\n$$\n\\phi_h \\approx \\phi_{\\mathrm{exact}} + c h^p\n$$\n\nWe apply this model to two grids: a fine grid (grid $1$) with size $h_1$ and a coarser grid (grid $2$) with size $h_2$. The grid refinement ratio is $r_{21} = h_2/h_1$. The solutions on these grids are:\n$$\n\\phi_1 \\approx \\phi_{\\mathrm{exact}} + c h_1^p\n$$\n$$\n\\phi_2 \\approx \\phi_{\\mathrm{exact}} + c h_2^p = \\phi_{\\mathrm{exact}} + c (r_{21} h_1)^p\n$$\nThis forms a system of two algebraic equations for the unknowns $\\phi_{\\mathrm{exact}}$ and $c$. We can eliminate $c$ to solve for a more accurate estimate of $\\phi_{\\mathrm{exact}}$, known as the Richardson extrapolated solution, $\\phi_{\\mathrm{extrap}}^{21}$:\n$$\n\\phi_{\\mathrm{extrap}}^{21} = \\frac{r_{21}^p \\phi_1 - \\phi_2}{r_{21}^p - 1} = \\phi_1 + \\frac{\\phi_1 - \\phi_2}{r_{21}^p - 1}\n$$\nThe estimated error in the fine-grid solution, $E_a^{21}$, is the difference between the fine-grid solution and this extrapolated value:\n$$\nE_a^{21} = \\phi_{\\mathrm{extrap}}^{21} - \\phi_1 = \\frac{\\phi_1 - \\phi_2}{r_{21}^p - 1}\n$$\nThe GCI is defined as a measure of the uncertainty in the fine-grid solution. It is based on the magnitude of the estimated error, scaled by a factor of safety $F_s$, and is typically expressed as a relative quantity with respect to the fine-grid solution itself.\n$$\n\\mathrm{GCI}_{21} = F_s \\frac{|E_a^{21}|}{|\\phi_1|} = F_s \\frac{1}{|\\phi_1|} \\left| \\frac{\\phi_1 - \\phi_2}{r_{21}^p - 1} \\right|\n$$\nSince $r_{21} = 2 > 1$ and $p_{\\mathrm{obs}} = 1.98 > 0$, the term $r_{21}^p - 1$ is positive. The formula can be written as:\n$$\n\\mathrm{GCI}_{21} = \\frac{F_s}{r_{21}^p - 1} \\left| \\frac{\\phi_1 - \\phi_2}{\\phi_1} \\right|\n$$\n\nThe factor of safety, $F_s$, serves to create a conservative error band. Its value reflects the confidence in the assumptions underlying the extrapolation. The Richardson extrapolation assumes the numerical solution is in the asymptotic range, which may not be perfectly true. $F_s > 1$ (e.g., $F_s=1.25$ for three-grid studies with a well-behaved order of convergence) inflates the estimated error to create an uncertainty interval, $\\phi_1 \\pm (\\mathrm{GCI}_{21} \\cdot \\phi_1)$, that is likely (e.g., with $95\\%$ confidence) to contain the exact solution $\\phi_{\\mathrm{exact}}$.\n\n**Calculation**\n\nWe now substitute the given values into the derived formula for $\\mathrm{GCI}_{21}$.\nThe givens are:\n- Fine-grid solution: $\\phi_1 = 1.0010 \\times 10^4$\n- Coarse-grid solution: $\\phi_2 = 1.0040 \\times 10^4$\n- Refinement ratio: $r_{21} = 2$\n- Observed order of accuracy: $p = p_{\\mathrm{obs}} = 1.98$\n- Factor of safety: $F_s = 1.25$\n\nFirst, we compute the relative difference between the two solutions:\n$$\n\\left| \\frac{\\phi_1 - \\phi_2}{\\phi_1} \\right| = \\left| \\frac{1.0010 \\times 10^4 - 1.0040 \\times 10^4}{1.0010 \\times 10^4} \\right| = \\left| \\frac{-0.0030 \\times 10^4}{1.0010 \\times 10^4} \\right| = \\frac{0.0030}{1.0010} = \\frac{3}{1001}\n$$\nNext, we compute the denominator term involving the order of accuracy:\n$$\nr_{21}^p - 1 = 2^{1.98} - 1\n$$\nNow, substitute these into the GCI formula:\n$$\n\\mathrm{GCI}_{21} = \\frac{1.25}{2^{1.98} - 1} \\times \\frac{3}{1001}\n$$\nWe compute the numerical value:\n$$\n2^{1.98} \\approx 3.944835\n$$\n$$\nr_{21}^p - 1 \\approx 2.944835\n$$\n$$\n\\frac{3}{1001} \\approx 0.002997003\n$$\n$$\n\\mathrm{GCI}_{21} \\approx \\frac{1.25}{2.944835} \\times 0.002997003 \\approx (0.424469) \\times (0.002997003) \\approx 0.00127214\n$$\nThe problem requires rounding the final answer to four significant figures. The first four significant figures are $1$, $2$, $7$, and $2$. The fifth digit is $1$, so we round down.\n$$\n\\mathrm{GCI}_{21} \\approx 0.001272\n$$\nThis value represents an estimated uncertainty of approximately $0.1272\\%$ in the fine-grid solution $\\phi_1$.",
            "answer": "$$\n\\boxed{0.001272}\n$$"
        },
        {
            "introduction": "Moving beyond numerical error, a comprehensive analysis must account for uncertainties in the physical model itself. This practice delves into Uncertainty Quantification (UQ) by applying the First-Order Reliability Method (FORM) to a reactor safety problem. You will assess how uncertainties in material properties and operating conditions propagate to the probability of exceeding a critical temperature limit, providing a quantitative measure of system reliability and demonstrating a key aspect of model validation and risk assessment .",
            "id": "4260213",
            "problem": "You are tasked with implementing the First-Order Reliability Method (FORM) to compute the reliability index $\\beta$ and the corresponding failure probability for a limit state related to fuel centerline temperature in a nuclear fuel rod under steady-state conditions. The context is Verification and Validation (V&V) methodologies in nuclear reactor simulation, and your implementation must be general, starting from fundamental laws and standard probabilistic definitions, without relying on shortcut formulas. The limit state is defined as exceeding a specified material temperature limit. The physics model is grounded in steady-state heat conduction with uniform volumetric heat generation in a solid cylinder with convective cooling at the surface.\n\nUse the following physically justified model for the fuel centerline temperature. For a solid cylindrical fuel rod of radius $R$ with uniform volumetric heat generation $\\dot{q}^{\\prime\\prime\\prime}$, thermal conductivity $k$, and convective cooling characterized by heat transfer coefficient $h$ to a coolant at temperature $T_{\\mathrm{c}}$, the centerline temperature is\n$$\nT_{\\mathrm{center}} = T_{\\mathrm{c}} + \\dot{q}^{\\prime\\prime\\prime}\\left(\\frac{R}{2h} + \\frac{R^2}{4k}\\right).\n$$\nThis follows from the steady-state heat equation in cylindrical coordinates with uniform generation and boundary condition $-k \\left.\\frac{\\partial T}{\\partial r}\\right|_{r=R} = h (T(R) - T_{\\mathrm{c}})$, equating the surface heat flux to the convective heat transfer. The safety limit is a fixed fuel temperature limit $T_{\\mathrm{limit}}$, and the limit-state function is\n$$\ng(\\mathbf{X}) = T_{\\mathrm{limit}} - T_{\\mathrm{center}}(\\mathbf{X}),\n$$\nwhere $\\mathbf{X} = [T_{\\mathrm{c}}, \\dot{q}^{\\prime\\prime\\prime}, h, k, R]$. Failure occurs when $g(\\mathbf{X}) \\le 0$.\n\nYou must compute the reliability index $\\beta$ using the First-Order Reliability Method (FORM). Define the standard normal space variables $\\mathbf{u} = [u_1, u_2, u_3, u_4, u_5]$ that are independent and standard normal. Use the isoprobabilistic transformation for independent input variables:\n- For a normal variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, use $x(u) = \\mu + \\sigma u$ and Jacobian component $\\frac{\\partial x}{\\partial u} = \\sigma$.\n- For a lognormal variable $X \\sim \\mathrm{Lognormal}(\\mu_{\\ln}, \\sigma_{\\ln}^2)$ with underlying normal $Y=\\ln X \\sim \\mathcal{N}(\\mu_{\\ln}, \\sigma_{\\ln}^2)$, parameterize $\\mu_{\\ln}$ and $\\sigma_{\\ln}$ by the physical mean $m$ and coefficient of variation $c_v$ via $\\sigma_{\\ln} = \\sqrt{\\ln(1 + c_v^2)}$ and $\\mu_{\\ln} = \\ln(m) - \\frac{1}{2}\\sigma_{\\ln}^2$, then use $x(u) = \\exp(\\mu_{\\ln} + \\sigma_{\\ln} u)$ and Jacobian component $\\frac{\\partial x}{\\partial u} = \\sigma_{\\ln} x$.\n\nCompute the gradient of the limit-state function in physical space $\\nabla_{\\mathbf{X}} g(\\mathbf{X})$ from first principles, using the fuel temperature model above. Map this gradient to the standard normal space via the Jacobian of the transformation to obtain $\\nabla_{\\mathbf{u}} g(\\mathbf{u})$. Implement the Hasofer-Lind-Rackwitz-Fiessler (HL-RF) iterative algorithm with linearization of the limit-state function to update $\\mathbf{u}$:\n$$\n\\mathbf{u}_{k+1} = -\\lambda_k \\nabla_{\\mathbf{u}} g(\\mathbf{u}_k), \\quad \\text{where} \\quad \\lambda_k = \\frac{g(\\mathbf{u}_k) - \\nabla_{\\mathbf{u}} g(\\mathbf{u}_k)^{\\top} \\mathbf{u}_k}{\\left\\|\\nabla_{\\mathbf{u}} g(\\mathbf{u}_k)\\right\\|^2}.\n$$\nInitialize with $\\mathbf{u}_0 = [0,0,0,0,0]$. Iterate until convergence is reached, for example when $\\left\\|\\mathbf{u}_{k+1} - \\mathbf{u}_k\\right\\| < \\varepsilon$, with a small tolerance $\\varepsilon$ such as $\\varepsilon = 10^{-8}$, or a maximum number of iterations is reached. At convergence, compute the reliability index as\n$$\n\\beta = \\left\\|\\mathbf{u}^*\\right\\|,\n$$\nwhere $\\mathbf{u}^*$ is the converged design point in standard normal space. Convert the reliability index to failure probability using the standard normal cumulative distribution function $\\Phi(\\cdot)$ as\n$$\np_{\\mathrm{f}} = \\Phi(-\\beta),\n$$\nand report $p_{\\mathrm{f}}$ as a decimal.\n\nAll physical and numerical units must be respected:\n- $T_{\\mathrm{limit}}$ and $T_{\\mathrm{c}}$ in $\\mathrm{K}$ (Kelvin).\n- $\\dot{q}^{\\prime\\prime\\prime}$ in $\\mathrm{W}/\\mathrm{m}^3$.\n- $h$ in $\\mathrm{W}/(\\mathrm{m}^2\\cdot\\mathrm{K})$.\n- $k$ in $\\mathrm{W}/(\\mathrm{m}\\cdot\\mathrm{K})$.\n- $R$ in $\\mathrm{m}$ (meters).\nThe outputs $\\beta$ and $p_{\\mathrm{f}}$ are dimensionless; express $p_{\\mathrm{f}}$ as a decimal.\n\nImplement your solution in a general, reusable manner that follows the principles above and works for the following test suite, which exercises a typical safe case, a near-boundary case, and a high-risk case. All variables are independent.\n\nUse $T_{\\mathrm{limit}} = 1800\\,\\mathrm{K}$ in all cases.\n\nTest Case $1$ (typical safe operating conditions):\n- $T_{\\mathrm{c}} \\sim \\mathcal{N}(\\mu = 580\\,\\mathrm{K}, \\sigma = 15\\,\\mathrm{K})$.\n- $\\dot{q}^{\\prime\\prime\\prime} \\sim \\mathrm{Lognormal}$ with mean $m = 1.0\\times 10^8\\,\\mathrm{W}/\\mathrm{m}^3$ and coefficient of variation $c_v = 0.10$.\n- $h \\sim \\mathrm{Lognormal}$ with mean $m = 20000\\,\\mathrm{W}/(\\mathrm{m}^2\\cdot\\mathrm{K})$ and $c_v = 0.15$.\n- $k \\sim \\mathrm{Lognormal}$ with mean $m = 2.5\\,\\mathrm{W}/(\\mathrm{m}\\cdot\\mathrm{K})$ and $c_v = 0.20$.\n- $R \\sim \\mathrm{Lognormal}$ with mean $m = 0.004\\,\\mathrm{m}$ and $c_v = 0.01$.\n\nTest Case $2$ (near boundary):\n- $T_{\\mathrm{c}} \\sim \\mathcal{N}(\\mu = 650\\,\\mathrm{K}, \\sigma = 20\\,\\mathrm{K})$.\n- $\\dot{q}^{\\prime\\prime\\prime} \\sim \\mathrm{Lognormal}$ with mean $m = 3.0\\times 10^8\\,\\mathrm{W}/\\mathrm{m}^3$ and $c_v = 0.10$.\n- $h \\sim \\mathrm{Lognormal}$ with mean $m = 5000\\,\\mathrm{W}/(\\mathrm{m}^2\\cdot\\mathrm{K})$ and $c_v = 0.20$.\n- $k \\sim \\mathrm{Lognormal}$ with mean $m = 1.5\\,\\mathrm{W}/(\\mathrm{m}\\cdot\\mathrm{K})$ and $c_v = 0.25$.\n- $R \\sim \\mathrm{Lognormal}$ with mean $m = 0.0045\\,\\mathrm{m}$ and $c_v = 0.02$.\n\nTest Case $3$ (high risk):\n- $T_{\\mathrm{c}} \\sim \\mathcal{N}(\\mu = 700\\,\\mathrm{K}, \\sigma = 30\\,\\mathrm{K})$.\n- $\\dot{q}^{\\prime\\prime\\prime} \\sim \\mathrm{Lognormal}$ with mean $m = 4.0\\times 10^8\\,\\mathrm{W}/\\mathrm{m}^3$ and $c_v = 0.15$.\n- $h \\sim \\mathrm{Lognormal}$ with mean $m = 3000\\,\\mathrm{W}/(\\mathrm{m}^2\\cdot\\mathrm{K})$ and $c_v = 0.25$.\n- $k \\sim \\mathrm{Lognormal}$ with mean $m = 1.0\\,\\mathrm{W}/(\\mathrm{m}\\cdot\\mathrm{K})$ and $c_v = 0.30$.\n- $R \\sim \\mathrm{Lognormal}$ with mean $m = 0.0050\\,\\mathrm{m}$ and $c_v = 0.03$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as $[\\beta_1, p_{\\mathrm{f},1}, \\beta_2, p_{\\mathrm{f},2}, \\beta_3, p_{\\mathrm{f},3}]$, where the subscript denotes the test case index. Each entry must be a floating-point number.",
            "solution": "The problem is to compute the reliability index $\\beta$ and the probability of failure $p_{\\mathrm{f}}$ for a nuclear fuel rod's centerline temperature exceeding a safety limit. This is achieved by implementing the First-Order Reliability Method (FORM) with the Hasofer-Lind-Rackwitz-Fiessler (HL-RF) iterative algorithm.\n\nThe core of the problem involves transforming the random physical variables into a standard normal space and finding the point on the failure surface closest to the origin in this space. The distance to this point is the reliability index $\\beta$.\n\n**1. Limit State Function and Physical Variables**\n\nThe vector of independent random variables in the physical space is $\\mathbf{X} = [x_1, x_2, x_3, x_4, x_5]^{\\top} = [T_{\\mathrm{c}}, \\dot{q}^{\\prime\\prime\\prime}, h, k, R]^{\\top}$. The fuel centerline temperature is given by:\n$$\nT_{\\mathrm{center}}(\\mathbf{X}) = T_{\\mathrm{c}} + \\dot{q}^{\\prime\\prime\\prime}\\left(\\frac{R}{2h} + \\frac{R^2}{4k}\\right)\n$$\nThe safety limit is a constant temperature $T_{\\mathrm{limit}}$. The limit-state function $g(\\mathbf{X})$ defines the boundary between safe and failure states. Failure is defined as the condition where the centerline temperature exceeds the limit, which corresponds to $g(\\mathbf{X}) \\le 0$.\n$$\ng(\\mathbf{X}) = T_{\\mathrm{limit}} - T_{\\mathrm{center}}(\\mathbf{X}) = T_{\\mathrm{limit}} - \\left[ T_{\\mathrm{c}} + \\dot{q}^{\\prime\\prime\\prime}\\left(\\frac{R}{2h} + \\frac{R^2}{4k}\\right) \\right]\n$$\n\n**2. Gradient in Physical Space**\n\nThe HL-RF algorithm requires the gradient of the limit-state function. We first compute this gradient with respect to the physical variables, $\\nabla_{\\mathbf{X}} g(\\mathbf{X})$. The partial derivatives are:\n- $\\frac{\\partial g}{\\partial T_{\\mathrm{c}}} = -1$\n- $\\frac{\\partial g}{\\partial \\dot{q}^{\\prime\\prime\\prime}} = -\\left(\\frac{R}{2h} + \\frac{R^2}{4k}\\right)$\n- $\\frac{\\partial g}{\\partial h} = -\\dot{q}^{\\prime\\prime\\prime} \\frac{\\partial}{\\partial h}\\left(\\frac{R}{2h}\\right) = -\\dot{q}^{\\prime\\prime\\prime}\\left(-\\frac{R}{2h^2}\\right) = \\frac{\\dot{q}^{\\prime\\prime\\prime} R}{2h^2}$\n- $\\frac{\\partial g}{\\partial k} = -\\dot{q}^{\\prime\\prime\\prime} \\frac{\\partial}{\\partial k}\\left(\\frac{R^2}{4k}\\right) = -\\dot{q}^{\\prime\\prime\\prime}\\left(-\\frac{R^2}{4k^2}\\right) = \\frac{\\dot{q}^{\\prime\\prime\\prime} R^2}{4k^2}$\n- $\\frac{\\partial g}{\\partial R} = -\\dot{q}^{\\prime\\prime\\prime} \\frac{\\partial}{\\partial R}\\left(\\frac{R}{2h} + \\frac{R^2}{4k}\\right) = -\\dot{q}^{\\prime\\prime\\prime}\\left(\\frac{1}{2h} + \\frac{2R}{4k}\\right) = -\\dot{q}^{\\prime\\prime\\prime}\\left(\\frac{1}{2h} + \\frac{R}{2k}\\right)$\n\n**3. Isoprobabilistic Transformation and Jacobian**\n\nThe physical variables $\\mathbf{X}$ are transformed into a vector of independent standard normal variables $\\mathbf{u} = [u_1, u_2, u_3, u_4, u_5]^{\\top}$. The transformation $x_i(u_i)$ and its derivative $\\frac{\\partial x_i}{\\partial u_i}$ depend on the probability distribution of $x_i$.\n\n- For a normally distributed variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$:\n  $$x(u) = \\mu + \\sigma u$$\n  $$\\frac{\\partial x}{\\partial u} = \\sigma$$\n\n- For a lognormally distributed variable $X \\sim \\mathrm{Lognormal}$ with mean $m$ and coefficient of variation $c_v$:\n  The parameters of the underlying normal distribution $Y = \\ln X \\sim \\mathcal{N}(\\mu_{\\ln}, \\sigma_{\\ln}^2)$ are first calculated:\n  $$\\sigma_{\\ln}^2 = \\ln(1 + c_v^2)$$\n  $$\\mu_{\\ln} = \\ln(m) - \\frac{1}{2}\\sigma_{\\ln}^2$$\n  The transformation and its derivative are:\n  $$x(u) = \\exp(\\mu_{\\ln} + \\sigma_{\\ln} u)$$\n  $$\\frac{\\partial x}{\\partial u} = \\frac{d}{du} \\left( e^{\\mu_{\\ln} + \\sigma_{\\ln} u} \\right) = e^{\\mu_{\\ln} + \\sigma_{\\ln} u} \\cdot \\sigma_{\\ln} = \\sigma_{\\ln} x(u)$$\n\n**4. Gradient in Standard Normal Space**\n\nThe gradient in the standard normal space, $\\nabla_{\\mathbf{u}} g(\\mathbf{u})$, is found using the chain rule. Since the transformations are independent, the Jacobian matrix $\\mathbf{J}_{\\mathbf{X},\\mathbf{u}}$ is diagonal with entries $J_{ii} = \\frac{\\partial x_i}{\\partial u_i}$.\n$$\n\\nabla_{\\mathbf{u}} g(\\mathbf{u}) = \\mathbf{J}_{\\mathbf{X},\\mathbf{u}}^{\\top} \\nabla_{\\mathbf{X}} g(\\mathbf{X}(\\mathbf{u}))\n$$\nThe components of the gradient are therefore:\n$$\n\\frac{\\partial g}{\\partial u_i} = \\frac{\\partial g}{\\partial x_i} \\frac{\\partial x_i}{\\partial u_i}\n$$\nThese must be evaluated at the current iteration's point $\\mathbf{u}_k$ by first computing the corresponding physical values $\\mathbf{X}(\\mathbf{u}_k)$.\n\n**5. HL-RF Algorithm**\n\nThe HL-RF algorithm is a fixed-point iteration scheme to find the design point $\\mathbf{u}^*$, which is the point on the failure surface $g(\\mathbf{u}) = 0$ with the minimum distance to the origin.\n\n1. Initialize the iteration with $\\mathbf{u}_0 = \\mathbf{0}$.\n2. For iteration $k=0, 1, 2, \\dots$:\n   a. Compute the physical variables $\\mathbf{X}_k = \\mathbf{X}(\\mathbf{u}_k)$.\n   b. Evaluate the limit-state function $g(\\mathbf{u}_k) = g(\\mathbf{X}_k)$.\n   c. Evaluate the gradient in physical space $\\nabla_{\\mathbf{X}} g(\\mathbf{X}_k)$.\n   d. Compute the Jacobian components $\\frac{\\partial x_i}{\\partial u_i}$ at $\\mathbf{u}_k$.\n   e. Compute the gradient in standard normal space $\\nabla_{\\mathbf{u}} g(\\mathbf{u}_k)$.\n   f. Calculate the update parameter $\\lambda_k$:\n      $$\n      \\lambda_k = \\frac{g(\\mathbf{u}_k) - \\nabla_{\\mathbf{u}} g(\\mathbf{u}_k)^{\\top} \\mathbf{u}_k}{\\left\\|\\nabla_{\\mathbf{u}} g(\\mathbf{u}_k)\\right\\|^2}\n      $$\n   g. Update the standard normal vector $\\mathbf{u}_{k+1}$:\n      $$\n      \\mathbf{u}_{k+1} = -\\lambda_k \\nabla_{\\mathbf{u}} g(\\mathbf{u}_k)\n      $$\n3. Check for convergence. The iteration stops when $\\left\\|\\mathbf{u}_{k+1} - \\mathbf{u}_k\\right\\| < \\varepsilon$, where $\\varepsilon$ is a small tolerance (e.g., $10^{-8}$). The converged point is the design point $\\mathbf{u}^*$.\n\n**6. Reliability Index and Failure Probability**\n\nOnce the algorithm converges to the design point $\\mathbf{u}^*$, the reliability index $\\beta$ is the Euclidean norm (distance from the origin) of this point:\n$$\n\\beta = \\left\\|\\mathbf{u}^*\\right\\| = \\sqrt{\\sum_{i=1}^n (u_i^*)^2}\n$$\nThe first-order approximation of the probability of failure $p_{\\mathrm{f}}$ is then computed using the standard normal cumulative distribution function, $\\Phi(\\cdot)$:\n$$\np_{\\mathrm{f}} = \\Phi(-\\beta)\n$$\nThis procedure is implemented in the following Python code for each of the three test cases.\n\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\n#\n# === Probabilistic Variable Definitions ===\n#\nclass NormalVariable:\n    \"\"\"Represents a normally distributed random variable.\"\"\"\n    def __init__(self, mean, std_dev):\n        self.mean = float(mean)\n        self.std_dev = float(std_dev)\n\n    def transform(self, u):\n        \"\"\"Maps a standard normal variable u to the physical variable x.\"\"\"\n        return self.mean + self.std_dev * u\n\n    def jacobian_component(self, u, x):\n        \"\"\"Computes the component of the Jacobian d(x)/d(u).\"\"\"\n        return self.std_dev\n\nclass LognormalVariable:\n    \"\"\"Represents a lognormally distributed random variable.\"\"\"\n    def __init__(self, mean, cv):\n        self.m = float(mean)\n        self.cv = float(cv)\n        \n        # Pre-compute parameters of the underlying normal distribution\n        sigma_ln_sq = np.log(1.0 + self.cv**2)\n        self.sigma_ln = np.sqrt(sigma_ln_sq)\n        self.mu_ln = np.log(self.m) - 0.5 * sigma_ln_sq\n\n    def transform(self, u):\n        \"\"\"Maps a standard normal variable u to the physical variable x.\"\"\"\n        return np.exp(self.mu_ln + self.sigma_ln * u)\n\n    def jacobian_component(self, u, x):\n        \"\"\"Computes the component of the Jacobian d(x)/d(u).\"\"\"\n        return self.sigma_ln * x\n\n#\n# === First-Order Reliability Method (FORM) Solver ===\n#\ndef solve_form(variables, T_limit, epsilon=1e-8, max_iter=100):\n    \"\"\"\n    Computes the reliability index and failure probability using FORM-HLRF.\n    \"\"\"\n    num_vars = len(variables)\n    u = np.zeros(num_vars)\n\n    for i in range(max_iter):\n        u_old = u.copy()\n        \n        # 1. Transform from standard normal space (u) to physical space (x)\n        x = np.array([var.transform(u_i) for var, u_i in zip(variables, u)])\n        Tc, q_dot, h, k, R = x\n        \n        # 2. Evaluate the limit-state function g(u)\n        T_center = Tc + q_dot * (R / (2.0 * h) + R**2 / (4.0 * k))\n        g_val = T_limit - T_center\n        \n        # 3. Evaluate the gradient of g in physical space, grad_x(g)\n        grad_g_x = np.array([\n            -1.0,\n            -(R / (2.0 * h) + R**2 / (4.0 * k)),\n            (q_dot * R) / (2.0 * h**2),\n            (q_dot * R**2) / (4.0 * k**2),\n            -q_dot * (1.0 / (2.0 * h) + R / (2.0 * k))\n        ])\n\n        # 4. Compute the gradient of g in standard normal space, grad_u(g)\n        jac_components = np.array([var.jacobian_component(u_i, x_i) \n                                   for var, u_i, x_i in zip(variables, u, x)])\n        grad_g_u = grad_g_x * jac_components\n        \n        # 5. Apply the HL-RF update rule\n        norm_grad_g_u = np.linalg.norm(grad_g_u)\n        if norm_grad_g_u < 1e-12: # Avoid division by zero\n            # If gradient is near zero and g is also near zero, we might have converged.\n            if abs(g_val) < epsilon:\n                break\n            else:\n                # This case is unlikely for this problem but is good practice to handle.\n                # A zero gradient far from the failure surface indicates a problem.\n                raise RuntimeError(\"HL-RF failed: zero gradient encountered.\")\n\n        lambda_k = (g_val - np.dot(grad_g_u, u)) / (norm_grad_g_u**2)\n        u = -lambda_k * grad_g_u\n        \n        # 6. Check for convergence\n        if np.linalg.norm(u - u_old) < epsilon:\n            break\n    \n    # 7. Compute reliability index (beta) and probability of failure (p_f)\n    beta = np.linalg.norm(u)\n    p_f = norm.cdf(-beta)\n    \n    return beta, p_f\n```",
            "answer": "$$\n\\boxed{\\texttt{[4.975416035987399, 3.332306730707765e-07, 2.155458032128795, 0.015560195537552553, 0.9575089309618193, 0.1691458872580796]}}\n$$"
        }
    ]
}