{
    "hands_on_practices": [
        {
            "introduction": "The convergence rate of any iterative method is of paramount importance, and the simplest Krylov techniques provide the clearest insight into this behavior. This first exercise explores the power iteration, connecting its performance directly to a key spectral property: the dominance ratio, $r$. By calculating the number of iterations needed to suppress unwanted eigenmodes to a certain tolerance, you will gain a quantitative feel for how the separation of eigenvalues governs the speed of convergence in reactor physics simulations .",
            "id": "4232451",
            "problem": "Consider a steady-state neutron balance leading to the multigroup fission–source eigenvalue formulation in a heterogeneous thermal reactor core. Let $A$ denote the loss operator (including absorption, out-scattering, and leakage) and $F$ denote the fission production operator. The multiplication operator is defined by $K = A^{-1} F$, so that the fundamental eigenpair satisfies $K \\phi_1 = \\lambda_1 \\phi_1$, where $\\lambda_1 = k_{\\text{eff}}$ is the effective neutron multiplication factor (with $k_{\\text{eff}} \\approx 1$ near criticality). Assume $K$ is diagonalizable with a complete set of right eigenvectors $\\{\\phi_i\\}_{i=1}^{N}$ ordered by magnitude of eigenvalues $|\\lambda_1|  |\\lambda_2| \\ge \\cdots \\ge 0$. The dominance ratio is defined by $r = |\\lambda_2/\\lambda_1|$, which characterizes the asymptotic decay rate of non-fundamental modes in Krylov subspace iterations.\n\nA Krylov subspace method is applied via the simple power iteration without orthogonalization or deflation: starting from an initial guess $\\phi^{(0)}$, subsequent iterates are $\\phi^{(n)} = K^{n} \\phi^{(0)}$, and each iterate is scaled so that its norm is fixed (assume a consistent norm induced by the inner product under which the eigenvectors are orthonormal).\n\nSuppose:\n- The dominance ratio is $r = 0.92$.\n- The initial guess is a normalized two-mode mixture, $\\phi^{(0)} = c_1 \\phi_1 + c_2 \\phi_2$, with $c_1 = 0.8$ and $c_2 = 0.6$, and higher-mode components are negligible.\n- The error factor $E(n)$ is defined to be the ratio of the magnitude of the second-mode component to the magnitude of the fundamental-mode component in the normalized iterate after $n$ Krylov steps.\n\nUsing only the above physical setup and definitions, determine the smallest integer number of Krylov iterations $n$ required so that the error factor satisfies $E(n) \\le \\epsilon$ with $\\epsilon = 1.0 \\times 10^{-7}$. Express your final answer as an integer with no units.",
            "solution": "The problem asks for the minimum number of Krylov iterations, $n$, required for the error factor, $E(n)$, to be less than or equal to a specified tolerance $\\epsilon$. The Krylov method used is the power iteration for finding the dominant eigenpair of the multiplication operator $K$.\n\nLet the initial guess for the eigenvector be $\\phi^{(0)}$. The problem specifies a two-mode mixture:\n$$\n\\phi^{(0)} = c_1 \\phi_1 + c_2 \\phi_2\n$$\nwhere $\\phi_1$ and $\\phi_2$ are the eigenvectors corresponding to the fundamental and first higher-order modes, respectively. The coefficients are given as $c_1 = 0.8$ and $c_2 = 0.6$. The set of eigenvectors $\\{\\phi_i\\}$ is stated to be orthonormal under a consistent inner product.\n\nThe power iteration method generates a sequence of vectors. The un-normalized vector after $n$ iterations, which we denote as $\\psi^{(n)}$, is obtained by applying the operator $K$ for $n$ times to the initial guess $\\phi^{(0)}$:\n$$\n\\psi^{(n)} = K^n \\phi^{(0)}\n$$\nSubstituting the expression for $\\phi^{(0)}$ and using the linearity of the operator $K^n$:\n$$\n\\psi^{(n)} = K^n (c_1 \\phi_1 + c_2 \\phi_2) = c_1 K^n \\phi_1 + c_2 K^n \\phi_2\n$$\nBy definition, $\\phi_i$ is an eigenvector of $K$ with eigenvalue $\\lambda_i$, so $K \\phi_i = \\lambda_i \\phi_i$. This implies that $K^n \\phi_i = \\lambda_i^n \\phi_i$. Applying this property, we get:\n$$\n\\psi^{(n)} = c_1 \\lambda_1^n \\phi_1 + c_2 \\lambda_2^n \\phi_2\n$$\nThis vector $\\psi^{(n)}$ represents the state of the solution after $n$ iterations, before normalization. The fundamental-mode component is $c_1 \\lambda_1^n \\phi_1$ and the second-mode component is $c_2 \\lambda_2^n \\phi_2$.\n\nThe problem defines the error factor $E(n)$ as the ratio of the magnitude of the second-mode component to the magnitude of the fundamental-mode component in the *normalized* iterate $\\phi^{(n)}$. The normalized iterate is $\\phi^{(n)} = \\psi^{(n)}/\\|\\psi^{(n)}\\|$. Since the eigenvectors are orthonormal, the coefficients of the normalized iterate are $d_1 = \\frac{c_1 \\lambda_1^n}{\\|\\psi^{(n)}\\|}$ and $d_2 = \\frac{c_2 \\lambda_2^n}{\\|\\psi^{(n)}\\|}$. The magnitude of each component in the normalized eigenvector expansion is the absolute value of its coefficient. Thus, the error factor is:\n$$\nE(n) = \\frac{|d_2|}{|d_1|} = \\frac{\\left| \\frac{c_2 \\lambda_2^n}{\\|\\psi^{(n)}\\|} \\right|}{\\left| \\frac{c_1 \\lambda_1^n}{\\|\\psi^{(n)}\\|} \\right|} = \\frac{|c_2| |\\lambda_2|^n}{|c_1| |\\lambda_1|^n}\n$$\nThe normalization constant $\\|\\psi^{(n)}\\|$ cancels out. The expression for the error factor simplifies to:\n$$\nE(n) = \\frac{|c_2|}{|c_1|} \\left( \\frac{|\\lambda_2|}{|\\lambda_1|} \\right)^n\n$$\nThe problem defines the dominance ratio as $r = |\\lambda_2/\\lambda_1|$. Substituting this definition and the given values for the coefficients $|c_1| = 0.8$ and $|c_2| = 0.6$:\n$$\nE(n) = \\frac{0.6}{0.8} r^n = 0.75 \\ r^n\n$$\nWe are given that the dominance ratio is $r = 0.92$. The required condition is that the error factor $E(n)$ must be less than or equal to the tolerance $\\epsilon = 1.0 \\times 10^{-7}$. We can now set up the inequality to solve for $n$:\n$$\n0.75 \\times (0.92)^n \\le 1.0 \\times 10^{-7}\n$$\nTo solve for $n$, we first isolate the term with the exponent:\n$$\n(0.92)^n \\le \\frac{1.0 \\times 10^{-7}}{0.75} = \\frac{4}{3} \\times 10^{-7}\n$$\nNext, we take the natural logarithm of both sides of the inequality:\n$$\n\\ln((0.92)^n) \\le \\ln\\left(\\frac{4}{3} \\times 10^{-7}\\right)\n$$\n$$\nn \\ln(0.92) \\le \\ln\\left(\\frac{4}{3}\\right) + \\ln(10^{-7})\n$$\nSince $0.92  1$, its natural logarithm $\\ln(0.92)$ is a negative number. Therefore, when we divide by $\\ln(0.92)$ to solve for $n$, we must reverse the direction of the inequality:\n$$\nn \\ge \\frac{\\ln\\left(\\frac{4}{3} \\times 10^{-7}\\right)}{\\ln(0.92)}\n$$\nNow, we can compute the numerical value:\n$$\nn \\ge \\frac{\\ln(1.333... \\times 10^{-7})}{\\ln(0.92)}\n$$\nThe values of the logarithms are approximately:\n$$\n\\ln(1.333... \\times 10^{-7}) \\approx -15.83041\n$$\n$$\n\\ln(0.92) \\approx -0.08338\n$$\nSubstituting these values:\n$$\nn \\ge \\frac{-15.83041}{-0.08338} \\approx 189.856\n$$\nSince $n$ must be an integer representing the number of iterations, we must take the smallest integer value that satisfies this condition. This is found by taking the ceiling of the result:\n$$\nn = \\lceil 189.856 \\rceil = 190\n$$\nTherefore, a minimum of $190$ iterations are required to reduce the error factor to the desired tolerance.",
            "answer": "$$\\boxed{190}$$"
        },
        {
            "introduction": "Real-world operators in reactor physics, especially those arising from transport theory discretizations, are often non-normal. This exercise reveals a critical and often counter-intuitive consequence: the transient behavior of Ritz values generated by methods like Arnoldi can be misleadingly far from the true spectrum. You will compute a one-step Ritz value for a representative non-normal operator and see how it reflects the operator's field of values rather than its eigenvalues, illustrating a key challenge in applying and accelerating Krylov methods for complex systems .",
            "id": "4232489",
            "problem": "Consider a simplified one-speed, one-direction model of neutron transport in a slab, discretized by a coarse-mesh upwind finite-volume scheme widely used in nuclear reactor simulation. The resulting iteration operator for a k-eigenvalue model can be abstracted as a non-normal matrix $A \\in \\mathbb{C}^{3 \\times 3}$ acting on the three-cell coarse-mesh flux vector. In this simplified setting, the fission-to-loss iteration is captured by\n$$\nA \\;=\\; I \\;+\\; N, \\quad\nN \\;=\\; \\begin{pmatrix}\n0  L  0 \\\\\n0  0  L \\\\\n0  0  0\n\\end{pmatrix},\n$$\nwith $L$ a dimensionless streaming-coupling parameter arising from the upwind discretization. Assume $L = 2\\sqrt{2}$. This $A$ is non-normal but has all eigenvalues equal to $1$, reflecting the fact that the underlying physical target (dominant k-eigenvalue) is near unity while discretization-induced non-normality may distort transient Rayleigh quotient behavior.\n\nLet the field of values (also known as numerical range) be defined by\n$$\nW(A) \\;=\\; \\left\\{ \\frac{x^{*} A x}{x^{*} x} \\;:\\; x \\in \\mathbb{C}^{3} \\setminus \\{0\\} \\right\\},\n$$\nand let the Hermitian part be\n$$\nH \\;=\\; \\frac{A + A^{*}}{2}.\n$$\nIn Krylov subspace methods (for example, the Arnoldi method) used in reactor criticality and alpha-eigenvalue computations, Ritz values at low iteration counts can transiently reflect the field of values rather than the spectrum, complicating the choice of spectral shifts for acceleration and targeting.\n\nStarting from the above definitions and the foundational property that the extreme real parts of $W(A)$ are the extreme eigenvalues of the Hermitian part $H$ (which follows from the variational characterization of Rayleigh quotients for Hermitian matrices), consider the $1$-step Arnoldi process initialized with the unit vector $v_{1}$ taken to be the normalized eigenvector of $H$ corresponding to its smallest eigenvalue. The $1$-step Ritz value equals $h_{11} = v_{1}^{*} A v_{1}$.\n\nTask: Derive $H$ explicitly, determine its smallest eigenvalue and a corresponding normalized eigenvector $v_{1}$, and then compute the $1$-step Ritz value $h_{11} = v_{1}^{*} A v_{1}$ for the given $A$ with $L=2\\sqrt{2}$. Explain why this $h_{11}$ quantifies a temporary drift of the Ritz value away from the true eigenvalues of $A$ and thus illustrates how shift selection can be misled by early iterates when the field of values is far from the spectral cluster. Express your final answer for $h_{11}$ as a single real number. No rounding is required.",
            "solution": "The analysis proceeds by first constructing the matrix $A$, then its Hermitian part $H$, and subsequently determining the spectral properties of $H$ required to find the starting vector $v_{1}$. Finally, the $1$-step Ritz value $h_{11}$ is computed.\n\nGiven the parameter $L = 2\\sqrt{2}$, the matrix $N$ is:\n$$\nN = \\begin{pmatrix}\n0  2\\sqrt{2}  0 \\\\\n0  0  2\\sqrt{2} \\\\\n0  0  0\n\\end{pmatrix}\n$$\nThe matrix $A$ is defined as $A = I + N$, where $I$ is the $3 \\times 3$ identity matrix.\n$$\nA = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix} + \\begin{pmatrix}\n0  2\\sqrt{2}  0 \\\\\n0  0  2\\sqrt{2} \\\\\n0  0  0\n\\end{pmatrix} = \\begin{pmatrix}\n1  2\\sqrt{2}  0 \\\\\n0  1  2\\sqrt{2} \\\\\n0  0  1\n\\end{pmatrix}\n$$\nNext, we compute the conjugate transpose of $A$, denoted $A^{*}$. Since all entries of $A$ are real, this is equivalent to the transpose $A^{T}$.\n$$\nA^{*} = \\begin{pmatrix}\n1  0  0 \\\\\n2\\sqrt{2}  1  0 \\\\\n0  2\\sqrt{2}  1\n\\end{pmatrix}\n$$\nThe Hermitian part of $A$ is $H = \\frac{A + A^{*}}{2}$.\n$$\nH = \\frac{1}{2} \\left( \\begin{pmatrix}\n1  2\\sqrt{2}  0 \\\\\n0  1  2\\sqrt{2} \\\\\n0  0  1\n\\end{pmatrix} + \\begin{pmatrix}\n1  0  0 \\\\\n2\\sqrt{2}  1  0 \\\\\n0  2\\sqrt{2}  1\n\\end{pmatrix} \\right) = \\frac{1}{2} \\begin{pmatrix}\n2  2\\sqrt{2}  0 \\\\\n2\\sqrt{2}  2  2\\sqrt{2} \\\\\n0  2\\sqrt{2}  2\n\\end{pmatrix} = \\begin{pmatrix}\n1  \\sqrt{2}  0 \\\\\n\\sqrt{2}  1  \\sqrt{2} \\\\\n0  \\sqrt{2}  1\n\\end{pmatrix}\n$$\nTo find the eigenvalues of $H$, we solve the characteristic equation $\\det(H - \\lambda I) = 0$.\n$$\n\\det \\begin{pmatrix}\n1-\\lambda  \\sqrt{2}  0 \\\\\n\\sqrt{2}  1-\\lambda  \\sqrt{2} \\\\\n0  \\sqrt{2}  1-\\lambda\n\\end{pmatrix} = 0\n$$\nExpanding the determinant along the first row:\n$$\n(1-\\lambda) \\left[(1-\\lambda)^2 - (\\sqrt{2})^2\\right] - \\sqrt{2} \\left[\\sqrt{2}(1-\\lambda) - 0\\right] = 0\n$$\n$$\n(1-\\lambda) \\left((1-\\lambda)^2 - 2\\right) - 2(1-\\lambda) = 0\n$$\nFactoring out the term $(1-\\lambda)$:\n$$\n(1-\\lambda) \\left[ (1-\\lambda)^2 - 2 - 2 \\right] = 0\n$$\n$$\n(1-\\lambda) \\left[ (1-\\lambda)^2 - 4 \\right] = 0\n$$\nThis gives three possible solutions for $\\lambda$:\n$1 - \\lambda = 0 \\implies \\lambda_1 = 1$\n$(1 - \\lambda)^2 = 4 \\implies 1 - \\lambda = \\pm 2$\n$1 - \\lambda = 2 \\implies \\lambda_2 = -1$\n$1 - \\lambda = -2 \\implies \\lambda_3 = 3$\nThe eigenvalues of $H$ are $\\{-1, 1, 3\\}$. The smallest eigenvalue is $\\lambda_{\\min} = -1$.\n\nNow we find the eigenvector $v$ corresponding to $\\lambda_{\\min} = -1$ by solving $(H - \\lambda_{\\min} I)v = 0$, which is $(H+I)v=0$.\n$$\n\\begin{pmatrix}\n1+1  \\sqrt{2}  0 \\\\\n\\sqrt{2}  1+1  \\sqrt{2} \\\\\n0  \\sqrt{2}  1+1\n\\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\implies \\begin{pmatrix}\n2  \\sqrt{2}  0 \\\\\n\\sqrt{2}  2  \\sqrt{2} \\\\\n0  \\sqrt{2}  2\n\\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nFrom the first row: $2x + \\sqrt{2}y = 0 \\implies y = -\\frac{2}{\\sqrt{2}}x = -\\sqrt{2}x$.\nFrom the third row: $\\sqrt{2}y + 2z = 0 \\implies z = -\\frac{\\sqrt{2}}{2}y = -\\frac{\\sqrt{2}}{2}(-\\sqrt{2}x) = x$.\nThe second row, $\\sqrt{2}x + 2y + \\sqrt{2}z = \\sqrt{2}x + 2(-\\sqrt{2}x) + \\sqrt{2}x = 2\\sqrt{2}x - 2\\sqrt{2}x = 0$, is consistent.\nSo, any eigenvector is of the form $c \\begin{pmatrix} 1 \\\\ -\\sqrt{2} \\\\ 1 \\end{pmatrix}$ for a non-zero constant $c$. We choose $c=1$.\nThe problem states that the starting vector $v_1$ must be normalized. We compute the Euclidean norm:\n$$\n\\|v\\|_2 = \\sqrt{1^2 + (-\\sqrt{2})^2 + 1^2} = \\sqrt{1 + 2 + 1} = \\sqrt{4} = 2\n$$\nThe normalized eigenvector $v_1$ is:\n$$\nv_1 = \\frac{v}{\\|v\\|_2} = \\frac{1}{2}\\begin{pmatrix} 1 \\\\ -\\sqrt{2} \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1/2 \\\\ -\\sqrt{2}/2 \\\\ 1/2 \\end{pmatrix}\n$$\nFinally, we compute the $1$-step Ritz value $h_{11} = v_{1}^{*} A v_{1}$.\nFirst, we compute the product $A v_{1}$:\n$$\nA v_1 = \\begin{pmatrix}\n1  2\\sqrt{2}  0 \\\\\n0  1  2\\sqrt{2} \\\\\n0  0  1\n\\end{pmatrix} \\begin{pmatrix} 1/2 \\\\ -\\sqrt{2}/2 \\\\ 1/2 \\end{pmatrix} = \\begin{pmatrix}\n1(1/2) + 2\\sqrt{2}(-\\sqrt{2}/2) + 0 \\\\\n0 + 1(-\\sqrt{2}/2) + 2\\sqrt{2}(1/2) \\\\\n0 + 0 + 1(1/2)\n\\end{pmatrix} = \\begin{pmatrix}\n1/2 - 2 \\\\\n-\\sqrt{2}/2 + \\sqrt{2} \\\\\n1/2\n\\end{pmatrix} = \\begin{pmatrix}\n-3/2 \\\\\n\\sqrt{2}/2 \\\\\n1/2\n\\end{pmatrix}\n$$\nNow, we compute the inner product $v_1^{*} (A v_1)$. Since $v_1$ is real, $v_1^{*} = v_1^{T}$.\n$$\nh_{11} = \\begin{pmatrix} 1/2  -\\sqrt{2}/2  1/2 \\end{pmatrix} \\begin{pmatrix} -3/2 \\\\ \\sqrt{2}/2 \\\\ 1/2 \\end{pmatrix}\n$$\n$$\nh_{11} = \\left(\\frac{1}{2}\\right)\\left(-\\frac{3}{2}\\right) + \\left(-\\frac{\\sqrt{2}}{2}\\right)\\left(\\frac{\\sqrt{2}}{2}\\right) + \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) = -\\frac{3}{4} - \\frac{2}{4} + \\frac{1}{4} = \\frac{-3-2+1}{4} = \\frac{-4}{4} = -1\n$$\nThe computed $1$-step Ritz value is $h_{11} = -1$.\n\n### Explanation of Significance\nThe matrix $A$ is upper triangular, so its eigenvalues are its diagonal entries. Thus, the spectrum of $A$ is $\\sigma(A) = \\{1\\}$. The goal of an eigenvalue algorithm applied to $A$ would be to find this eigenvalue.\n\nThe Arnoldi method generates Ritz values, which are approximations to the eigenvalues of $A$. A key property is that all Ritz values must lie within the field of values $W(A)$. The real part of any point $z \\in W(A)$ is given by $\\Re(z) = \\frac{x^{*}Hx}{x^{*}x}$. A fundamental theorem states that the minimum and maximum of $\\Re(z)$ over $W(A)$ are the minimum and maximum eigenvalues of $H$. We found $\\lambda_{\\min}(H) = -1$ and $\\lambda_{\\max}(H) = 3$. This means the field of values $W(A)$ extends in the real direction from $-1$ to $3$, which is significantly larger than the convex hull of the spectrum, which is just the single point $\\{1\\}$. This discrepancy is a hallmark of a non-normal matrix.\n\nThe problem specified a starting vector $v_1$ that is the eigenvector of $H$ for $\\lambda_{\\min}(H) = -1$. This vector specifically probes the extremal boundary of the field of values. The resulting $1$-step Ritz value $h_{11} = v_1^{*} A v_1$ yielded $-1$. This value is identical to $\\lambda_{\\min}(H)$, which is the minimum possible real part of any point in $W(A)$.\n\nThis result illustrates a critical challenge in using Krylov methods for non-normal eigenvalue problems found in reactor physics. The first approximation to the eigenvalue ($h_{11} = -1$) is extremely far from the true eigenvalue ($\\lambda = 1$). In a practical simulation aiming to find the dominant k-eigenvalue (which is physically near $1$), an initial estimate of $-1$ is highly misleading. If this early Ritz value were used to select a shift parameter for accelerating convergence (e.g., in a shift-and-invert Arnoldi method), the chosen shift would be very poor, potentially leading to extremely slow convergence or convergence to a non-physical mode. The phenomenon of early Ritz values exploring the boundary of the field of values rather than clustering around the eigenvalues is a direct consequence of the matrix's non-normality, driven in this model by the upwind discretization parameter $L$.",
            "answer": "$$\n\\boxed{-1}\n$$"
        },
        {
            "introduction": "The ultimate goal of algorithm design is not just correctness but efficiency, especially in large-scale simulations. This final practice moves into the realm of performance modeling, where you must balance algorithmic parameters to minimize the total time to solution under realistic hardware constraints. By constructing and optimizing a cost model for a restarted block Arnoldi method, you will engage in the kind of practical, high-level tuning that is essential for deploying Krylov solvers effectively in high-performance computing environments .",
            "id": "4232472",
            "problem": "In a three-dimensional pressurized water reactor k-eigenvalue simulation, consider the dominant eigenpair of the multigroup neutron transport operator approximated by a matrix-free fission-transport operator application. The iterative solver uses a restarted block Arnoldi method to build a Krylov subspace for Rayleigh–Ritz extraction. Assume the following foundational modeling elements:\n\n- The neutron transport eigenvalue problem for the fundamental mode is modeled by the spectral problem $A x = \\lambda x$, where $A$ is the linearized fixed-source operator that encapsulates transport sweeps, scattering, and fission source application. The transport sweeps are performed without explicitly assembling $A$, and the action of $A$ on a vector is implemented through a source application followed by a transport sweep.\n- The restarted block Arnoldi method with block size $b$ and restart length $m$ builds a subspace of dimension $m b$ per cycle, orthogonalizes each new block of $b$ vectors against the existing basis, and performs Rayleigh–Ritz extraction at the end of each cycle.\n\nYou are given the following physically and computationally motivated parameters and constraints for this reactor problem:\n\n1. Spectral separation for the fundamental mode: let $q = |\\lambda_{2} / \\lambda_{1}| = 0.92$, where $\\lambda_{1}$ is the dominant eigenvalue and $\\lambda_{2}$ is the next largest in magnitude. Assume a polynomial filtering model for restarted Arnoldi in which the residual reduction per cycle is approximately $q^{m}$, so that achieving a residual reduction from $1$ to $10^{-6}$ requires a total effective polynomial degree of at least $d^{\\star}$ satisfying $q^{d^{\\star}} \\leq 10^{-6}$.\n2. Memory constraint: storing the basis vectors dominates memory. Each vector requires $40$ megabytes, and the total available memory is $3.2$ gigabytes. This imposes $m b \\leq 80$.\n3. Robust extraction constraint: to ensure stable Ritz value and vector extraction and reduce stagnation risk, require $m \\geq 6$.\n4. Per-step cost model within a cycle:\n   - Source application and transport sweep time per Arnoldi step acting on a block of size $b$ is modeled as $T_{\\mathrm{src}}(b) = \\theta_{0} + \\theta_{1} b$, with $\\theta_{0} = 0.06$ seconds accounting for setup and boundary condition processing amortized over the block, and $\\theta_{1} = 0.08$ seconds per right-hand side capturing the linear scaling of sweep work with $b$.\n   - Block classical Gram–Schmidt (two passes) orthogonalization of the incoming block of $b$ vectors against the existing $j b$ basis vectors at step $j$ (with $j = 1, 2, \\dots, m$ within the cycle) is modeled as\n     $$T_{\\mathrm{orth,step}}(j, b) = 2 \\big( t_{\\mathrm{dot}} + t_{\\mathrm{axpy}} \\big) \\, j b^{2},$$\n     with $t_{\\mathrm{dot}} = 0.002$ seconds per block inner-product-equivalent and $t_{\\mathrm{axpy}} = 0.003$ seconds per block update-equivalent, giving $T_{\\mathrm{orth,step}}(j, b) = 0.01 \\, j b^{2}$ seconds.\n   - Per-cycle Rayleigh–Ritz and small dense eigenproblem time is approximated as a constant $T_{\\mathrm{rr}} = 0.02$ seconds per cycle.\n\n5. The total time per cycle for given $b$ and $m$ is the sum of $m$ source applications over the cycle, the cumulative orthogonalization across the cycle, and the Rayleigh–Ritz time:\n   $$T_{\\mathrm{cycle}}(b, m) = m \\, T_{\\mathrm{src}}(b) + \\sum_{j=1}^{m} T_{\\mathrm{orth,step}}(j, b) + T_{\\mathrm{rr}}.$$\n\n6. The number of cycles $L$ required to achieve the target residual reduction is the smallest integer satisfying $q^{L m} \\leq 10^{-6}$.\n\nUsing these definitions and constraints:\n\n- Derive $d^{\\star}$ and the expression for $L$ in terms of $m$.\n- Derive a closed-form expression for $T_{\\mathrm{cycle}}(b, m)$.\n- Construct the total predicted time to solution $T_{\\mathrm{total}}(b, m) = L \\, T_{\\mathrm{cycle}}(b, m)$ under the given model.\n- Over the feasible integer pairs $(b, m)$ satisfying $b \\geq 1$, $m \\geq 6$, and $m b \\leq 80$, determine the pair $(b^{\\star}, m^{\\star})$ that minimizes $T_{\\mathrm{total}}(b, m)$.\n\nReport the selected block size and restart length as a single row matrix $\\begin{pmatrix} b^{\\star}  m^{\\star} \\end{pmatrix}$. No rounding is required for the final answer. If any intermediate numerical evaluation is performed, carry it out exactly and do not round the final selection values.",
            "solution": "First, we derive the total required polynomial degree $d^{\\star}$ and the number of cycles $L$. The condition for convergence is that the total polynomial degree, which is the product of the number of cycles $L$ and the degree per cycle $m$, must satisfy $q^{L m} \\leq 10^{-6}$.\nLet $d^{\\star}$ be the minimum total degree required. Then $q^{d^{\\star}} = 10^{-6}$.\n$$\nd^{\\star} \\ln(q) = \\ln(10^{-6}) = -6 \\ln(10)\n$$\n$$\nd^{\\star} = \\frac{-6 \\ln(10)}{\\ln(q)} = \\frac{-6 \\ln(10)}{\\ln(0.92)}\n$$\nThe number of cycles $L$ must be the smallest integer such that $L m \\geq d^{\\star}$. This can be written as:\n$$\nL = \\left\\lceil \\frac{d^{\\star}}{m} \\right\\rceil\n$$\nNext, we derive a closed-form expression for the time per cycle, $T_{\\mathrm{cycle}}(b, m)$.\n$$\nT_{\\mathrm{cycle}}(b, m) = m \\, T_{\\mathrm{src}}(b) + \\sum_{j=1}^{m} T_{\\mathrm{orth,step}}(j, b) + T_{\\mathrm{rr}}\n$$\nSubstituting the given models:\n$$\nT_{\\mathrm{cycle}}(b, m) = m (\\theta_{0} + \\theta_{1} b) + \\sum_{j=1}^{m} (0.01 \\, j b^{2}) + T_{\\mathrm{rr}}\n$$\nThe summation term is an arithmetic series:\n$$\n\\sum_{j=1}^{m} (0.01 \\, j b^{2}) = 0.01 \\, b^{2} \\sum_{j=1}^{m} j = 0.01 \\, b^{2} \\frac{m(m+1)}{2} = 0.005 \\, m (m+1) b^{2}\n$$\nSo, the cycle time is:\n$$\nT_{\\mathrm{cycle}}(b, m) = m (\\theta_{0} + \\theta_{1} b) + 0.005 \\, m (m+1) b^{2} + T_{\\mathrm{rr}}\n$$\nSubstituting the numerical values $\\theta_{0}=0.06$, $\\theta_{1}=0.08$, and $T_{\\mathrm{rr}}=0.02$:\n$$\nT_{\\mathrm{cycle}}(b, m) = m(0.06 + 0.08 b) + 0.005 \\, m (m+1) b^{2} + 0.02\n$$\nThe total time to solution is:\n$$\nT_{\\mathrm{total}}(b, m) = L \\cdot T_{\\mathrm{cycle}}(b, m) = \\left\\lceil \\frac{d^{\\star}}{m} \\right\\rceil \\left( 0.06 m + 0.08 m b + 0.005 m(m+1) b^2 + 0.02 \\right)\n$$\nWe need to minimize this function over the set of feasible integer pairs $(b, m)$ defined by $b \\geq 1$, $m \\geq 6$, and $m b \\leq 80$.\n\nLet's analyze the dependence of $T_{\\mathrm{total}}(b, m)$ on $b$ for a fixed value of $m$. The number of cycles $L = \\lceil d^{\\star}/m \\rceil$ does not depend on $b$. We only need to analyze $T_{\\mathrm{cycle}}(b, m)$.\n$$\nT_{\\mathrm{cycle}}(b, m) = (0.06 m + 0.02) + (0.08 m) b + (0.005 m(m+1)) b^2\n$$\nFor a fixed $m \\geq 6$, this is a quadratic function of $b$. The coefficients of the $b$ and $b^2$ terms, $0.08 m$ and $0.005 m(m+1)$, are both positive. Therefore, $T_{\\mathrm{cycle}}(b, m)$ is a strictly increasing function of $b$ for $b \\geq 1$. Consequently, $T_{\\mathrm{total}}(b, m)$ is also strictly increasing with respect to $b$ for any fixed $m$. This implies that for any given restart length $m$, the minimum time is achieved at the smallest possible block size, which is $b=1$.\nThus, the optimal block size is $b^{\\star}=1$.\n\nThe problem is now reduced to a one-dimensional optimization problem: find the integer $m$ that minimizes $T_{\\mathrm{total}}(1, m)$ over the feasible range defined by $m \\geq 6$ and $1 \\cdot m \\leq 80$. We search for $m^{\\star}$ in the integer interval $[6, 80]$.\nLet's define the function to minimize:\n$$\nf(m) = T_{\\mathrm{total}}(1, m) = \\left\\lceil \\frac{d^{\\star}}{m} \\right\\rceil \\left( 0.005 m^2 + 0.145 m + 0.02 \\right)\n$$\nWe need the numerical value for $d^{\\star}$:\n$d^{\\star} = \\frac{-6 \\ln(10)}{\\ln(0.92)} \\approx \\frac{-6 \\times 2.302585}{-0.0833816} \\approx 165.69055$.\n\nThe function $f(m)$ is a product of a non-increasing step function $L(m) = \\lceil d^{\\star}/m \\rceil$ and a strictly increasing quadratic function $T(m) = 0.005 m^2 + 0.145 m + 0.02$. The resulting function is not monotonic, so we must evaluate it for the feasible range of $m$. The general trend for $m \\ge 6$ is increasing because the quadratic growth of $T(m)$ tends to dominate the $1/m$ decrease of $L(m)$. The minimum is thus likely to be at or near the lower bound $m=6$.\n\nLet's evaluate at $m=6$:\n$L(6) = \\lceil 165.69055 / 6 \\rceil = \\lceil 27.615 \\rceil = 28$.\n$T(6) = 0.005(6^2) + 0.145(6) + 0.02 = 0.18 + 0.87 + 0.02 = 1.07$.\n$f(6) = 28 \\times 1.07 = 29.96$.\n\nLet's evaluate at $m=7$:\n$L(7) = \\lceil 165.69055 / 7 \\rceil = \\lceil 23.67 \\rceil = 24$.\n$T(7) = 0.005(7^2) + 0.145(7) + 0.02 = 0.245 + 1.015 + 0.02 = 1.28$.\n$f(7) = 24 \\times 1.28 = 30.72$.\n\nSince $f(7) > f(6)$, and given the general increasing trend of the function for $m \\ge 6$, the minimum value in the feasible range $[6, 80]$ will occur at the lowest possible value, $m=6$.\n\nThus, the optimal restart length is $m^{\\star}=6$.\nThe optimal pair is $(b^{\\star}, m^{\\star}) = (1, 6)$. This pair satisfies all constraints: $b=1 \\geq 1$, $m=6 \\geq 6$, and $mb = 1 \\times 6 = 6 \\leq 80$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1  6\n\\end{pmatrix}\n}\n$$"
        }
    ]
}