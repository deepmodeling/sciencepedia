{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of Probabilistic Risk Assessment (PRA) is Fault Tree Analysis (FTA), a top-down deductive method used to determine the root causes of a system failure. This practice focuses on quantifying the probability of a \"top event,\" such as the failure of a critical safety system, from the probabilities of its basic component failures. By working through this problem , you will gain experience with minimal cut sets, which represent the minimal combinations of failures that can cause the system to fail, and apply the principle of inclusion-exclusion for an exact probability calculation, contrasting it with the practical and widely used rare-event approximation.",
            "id": "4242381",
            "problem": "A reactor has just undergone a shutdown, and the Decay Heat Removal system is required to operate over a mission time of $24$ hours to remove residual heat. In a Probabilistic Risk Assessment (PRA) context for nuclear reactor simulation, consider the top event defined as the failure of the Decay Heat Removal function during the mission time. The fault tree for the top event has the following minimal cut sets (each a conjunction of independent basic component failures):\n- $M_{1} = \\{A, B\\}$,\n- $M_{2} = \\{B, C\\}$,\n- $M_{3} = \\{C, D\\}$,\n- $M_{4} = \\{A, D\\}$.\n\nAssume the basic events are statistically independent with the following mission-time failure probabilities:\n- $P(A) = 1.5 \\times 10^{-3}$,\n- $P(B) = 8.0 \\times 10^{-4}$,\n- $P(C) = 1.2 \\times 10^{-3}$,\n- $P(D) = 9.0 \\times 10^{-4}$.\n\nUsing only fundamental probability axioms and the inclusion-exclusion principle developed from first principles, compute the exact probability of the top event as the union of the minimal cut set failure events. Also compute the rare-event approximation to the top event probability obtained by summing the minimal cut set probabilities and compare them qualitatively. Express the final (exact) top event probability as a decimal, rounded to six significant figures. Do not use a percentage sign.",
            "solution": "The user wants me to solve this problem.\n\n**Step 1: Extract Givens**\n\n- **Mission Time**: $24$ hours\n- **Top Event**: Failure of the Decay Heat Removal function.\n- **Minimal Cut Sets (MCS)**:\n  - $M_{1} = \\{A, B\\}$\n  - $M_{2} = \\{B, C\\}$\n  - $M_{3} = \\{C, D\\}$\n  - $M_{4} = \\{A, D\\}$\n- **Basic Event Independence**: Basic events are statistically independent.\n- **Basic Event Failure Probabilities**:\n  - $P(A) = 1.5 \\times 10^{-3}$\n  - $P(B) = 8.0 \\times 10^{-4}$\n  - $P(C) = 1.2 \\times 10^{-3}$\n  - $P(D) = 9.0 \\times 10^{-4}$\n- **Tasks**:\n  1. Compute the exact probability of the top event using the inclusion-exclusion principle.\n  2. Compute the rare-event approximation.\n  3. Qualitatively compare the exact and approximate probabilities.\n  4. Express the final exact probability as a decimal rounded to six significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded**: The problem is based on the principles of Probabilistic Risk Assessment (PRA) and Fault Tree Analysis (FTA), which are standard, well-established methodologies in nuclear engineering and reliability theory. The scenario is a credible and important one in reactor safety analysis. The values are of a realistic magnitude. This criterion is met.\n- **Well-Posed**: The problem provides all necessary data (minimal cut sets, basic event probabilities, independence) to calculate a unique solution. The objective is clearly stated. This criterion is met.\n- **Objective**: The problem is stated in precise, quantitative, and unbiased technical language. This criterion is met.\n\nThe problem does not exhibit any of the flaws listed in the instructions (e.g., scientific unsoundness, missing data, ambiguity, etc.). The logical structure is sound and it presents a standard, albeit detailed, calculation in reliability engineering.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. A full solution will be provided.\n\nThe top event, let us denote it by $T$, is the failure of the Decay Heat Removal function. This event occurs if and only if at least one of the minimal cut sets (MCS) occurs. Let $E_i$ be the event corresponding to the failure of all basic components in the minimal cut set $M_i$. The top event is the union of these events:\n$$\nT = E_1 \\cup E_2 \\cup E_3 \\cup E_4\n$$\nThe events $E_i$ are defined as the conjunction (intersection) of their respective basic events:\n- $E_1 = A \\cap B$\n- $E_2 = B \\cap C$\n- $E_3 = C \\cap D$\n- $E_4 = A \\cap D$\n\nThe probability of the top event, $P(T)$, is $P(E_1 \\cup E_2 \\cup E_3 \\cup E_4)$. We must use the principle of inclusion-exclusion to find the exact value. The formula for four events is:\n$$\nP(T) = \\sum_{i=1}^{4} P(E_i) - \\sum_{1 \\le i < j \\le 4} P(E_i \\cap E_j) + \\sum_{1 \\le i < j < k \\le 4} P(E_i \\cap E_j \\cap E_k) - P(E_1 \\cap E_2 \\cap E_3 \\cap E_4)\n$$\n\nFirst, we calculate the probabilities of the individual MCS events, $P(E_i)$. Since the basic events A, B, C, D are statistically independent, the probability of their intersection is the product of their individual probabilities.\n$$\nP(E_1) = P(A \\cap B) = P(A)P(B) = (1.5 \\times 10^{-3})(8.0 \\times 10^{-4}) = 1.2 \\times 10^{-6}\n$$\n$$\nP(E_2) = P(B \\cap C) = P(B)P(C) = (8.0 \\times 10^{-4})(1.2 \\times 10^{-3}) = 9.6 \\times 10^{-7} = 0.96 \\times 10^{-6}\n$$\n$$\nP(E_3) = P(C \\cap D) = P(C)P(D) = (1.2 \\times 10^{-3})(9.0 \\times 10^{-4}) = 1.08 \\times 10^{-6}\n$$\n$$\nP(E_4) = P(A \\cap D) = P(A)P(D) = (1.5 \\times 10^{-3})(9.0 \\times 10^{-4}) = 1.35 \\times 10^{-6}\n$$\n\nThe first term of the inclusion-exclusion series is the sum of these probabilities, which is also known as the rare-event approximation, $P(T)_{approx}$.\n$$\nP(T)_{approx} = \\sum_{i=1}^{4} P(E_i) = (1.2 + 0.96 + 1.08 + 1.35) \\times 10^{-6} = 4.59 \\times 10^{-6}\n$$\n\nNext, we calculate the probabilities of the pairwise intersections, $P(E_i \\cap E_j)$.\n$$\nP(E_1 \\cap E_2) = P((A \\cap B) \\cap (B \\cap C)) = P(A \\cap B \\cap C) = P(A)P(B)P(C) = (1.2 \\times 10^{-6})(1.2 \\times 10^{-3}) = 1.44 \\times 10^{-9}\n$$\n$$\nP(E_1 \\cap E_3) = P((A \\cap B) \\cap (C \\cap D)) = P(A \\cap B \\cap C \\cap D) = P(A)P(B)P(C)P(D) = (1.44 \\times 10^{-9})(9.0 \\times 10^{-4}) = 1.296 \\times 10^{-12}\n$$\n$$\nP(E_1 \\cap E_4) = P((A \\cap B) \\cap (A \\cap D)) = P(A \\cap B \\cap D) = P(A)P(B)P(D) = (1.2 \\times 10^{-6})(9.0 \\times 10^{-4}) = 1.08 \\times 10^{-9}\n$$\n$$\nP(E_2 \\cap E_3) = P((B \\cap C) \\cap (C \\cap D)) = P(B \\cap C \\cap D) = P(B)P(C)P(D) = (0.96 \\times 10^{-6})(9.0 \\times 10^{-4}) = 8.64 \\times 10^{-10} = 0.864 \\times 10^{-9}\n$$\n$$\nP(E_2 \\cap E_4) = P((B \\cap C) \\cap (A \\cap D)) = P(A \\cap B \\cap C \\cap D) = 1.296 \\times 10^{-12}\n$$\n$$\nP(E_3 \\cap E_4) = P((C \\cap D) \\cap (A \\cap D)) = P(A \\cap C \\cap D) = P(A)P(C)P(D) = (1.5 \\times 10^{-3})(1.2 \\times 10^{-3})(9.0 \\times 10^{-4}) = 1.62 \\times 10^{-9}\n$$\nThe sum of these pairwise intersection probabilities is:\n$$\n\\sum_{1 \\le i < j \\le 4} P(E_i \\cap E_j) = (1.44 + 1.08 + 0.864 + 1.62) \\times 10^{-9} + 2 \\times (1.296 \\times 10^{-12})\n$$\n$$\n= 5.004 \\times 10^{-9} + 2.592 \\times 10^{-12} = 5.004 \\times 10^{-9} + 0.002592 \\times 10^{-9} = 5.006592 \\times 10^{-9}\n$$\n\nNext, we calculate the probabilities of the three-way intersections, $P(E_i \\cap E_j \\cap E_k)$.\n$$\nP(E_1 \\cap E_2 \\cap E_3) = P((A \\cap B) \\cap (B \\cap C) \\cap (C \\cap D)) = P(A \\cap B \\cap C \\cap D) = 1.296 \\times 10^{-12}\n$$\n$$\nP(E_1 \\cap E_2 \\cap E_4) = P((A \\cap B) \\cap (B \\cap C) \\cap (A \\cap D)) = P(A \\cap B \\cap C \\cap D) = 1.296 \\times 10^{-12}\n$$\n$$\nP(E_1 \\cap E_3 \\cap E_4) = P((A \\cap B) \\cap (C \\cap D) \\cap (A \\cap D)) = P(A \\cap B \\cap C \\cap D) = 1.296 \\times 10^{-12}\n$$\n$$\nP(E_2 \\cap E_3 \\cap E_4) = P((B \\cap C) \\cap (C \\cap D) \\cap (A \\cap D)) = P(A \\cap B \\cap C \\cap D) = 1.296 \\times 10^{-12}\n$$\nThe sum of these three-way intersection probabilities is:\n$$\n\\sum_{1 \\le i < j < k \\le 4} P(E_i \\cap E_j \\cap E_k) = 4 \\times P(A \\cap B \\cap C \\cap D) = 4 \\times (1.296 \\times 10^{-12}) = 5.184 \\times 10^{-12}\n$$\n\nFinally, the probability of the four-way intersection is:\n$$\nP(E_1 \\cap E_2 \\cap E_3 \\cap E_4) = P(A \\cap B \\cap C \\cap D) = 1.296 \\times 10^{-12}\n$$\n\nNow, we substitute all these terms back into the inclusion-exclusion formula to find the exact probability $P(T)$.\n$$\nP(T) = (4.59 \\times 10^{-6}) - (5.006592 \\times 10^{-9}) + (5.184 \\times 10^{-12}) - (1.296 \\times 10^{-12})\n$$\n$$\nP(T) = 4.59 \\times 10^{-6} - 0.005006592 \\times 10^{-6} + 0.000005184 \\times 10^{-6} - 0.000001296 \\times 10^{-6}\n$$\n$$\nP(T) = (4.59 - 0.005006592 + 0.000003888) \\times 10^{-6}\n$$\n$$\nP(T) = (4.584993408 + 0.000003888) \\times 10^{-6}\n$$\n$$\nP(T) = 4.584997296 \\times 10^{-6}\n$$\n\nFor the qualitative comparison, the rare-event approximation is $P(T)_{approx} = 4.59 \\times 10^{-6}$, and the exact probability is $P(T)_{exact} = 4.584997296 \\times 10^{-6}$. The approximation is an overestimate, which is expected. The sum $\\sum P(E_i)$ double-counts the probability of the intersections of the events $E_i$. The inclusion-exclusion principle corrects for this by subtracting the probabilities of pairwise intersections, adding back the triple intersections, and so on. For rare events, the probabilities of intersections are much smaller than the probabilities of single events, so the first term dominates, and truncating the series after the first term (the rare-event approximation) provides a good estimate. This estimate is conservative as it overstates the probability of failure. The relative error is very small, on the order of $0.1\\%$:\n$$\n\\frac{P(T)_{approx} - P(T)_{exact}}{P(T)_{exact}} \\approx \\frac{4.59 \\times 10^{-6} - 4.585 \\times 10^{-6}}{4.585 \\times 10^{-6}} = \\frac{0.005}{4.585} \\approx 0.00109\n$$\n\nFinally, we express the exact top event probability as a decimal rounded to six significant figures.\n$$\nP(T) = 4.584997296 \\times 10^{-6}\n$$\nRounding to six significant figures gives $4.58500 \\times 10^{-6}$. As a decimal, this is $0.00000458500$.",
            "answer": "$$\n\\boxed{0.00000458500}\n$$"
        },
        {
            "introduction": "Beyond hardware reliability, a comprehensive PRA must rigorously account for the role of human operators, a field known as Human Reliability Analysis (HRA). Operator actions during an emergency are often sequential, and the outcome of one step can significantly influence performance on subsequent steps. This exercise  demonstrates how to model such dependencies using a Bayesian network, allowing you to calculate the composite Human Error Probability (HEP) for a multi-step procedure by applying the chain rule of probability. Mastering this technique is essential for realistically assessing the risk of sequences involving critical human interventions.",
            "id": "4242403",
            "problem": "A pressurized water reactor emergency response procedure comprises a sequential three-step operator action to maintain core cooling after a turbine trip with loss of offsite power. In a Probabilistic Risk Assessment (PRA) for a nuclear reactor simulation, the analyst must quantify the Human Error Probability (HEP) for the composite procedure failure, recognizing dependence between steps due to cognitive carryover, time pressure, and evolving plant cues. To ground the dependence model, assume a Bayesian network (BN) with binary error nodes $E_1$, $E_2$, and $E_3$, where $E_i$ denotes an error in step $i$, and directed edges $E_1 \\rightarrow E_2$ and $E_1 \\rightarrow E_3$, $E_2 \\rightarrow E_3$ capture sequential dependence.\n\nStep definitions:\n- Step $1$: Diagnose plant state and select the correct emergency cooling strategy.\n- Step $2$: Align the boron injection pathway and verify valve positions.\n- Step $3$: Start the injection pump and confirm stable flow indication.\n\nAssume the following marginal and conditional probabilities for the BN, reflecting performance shaping and cognitive dependence:\n- $P(E_1)=0.08$.\n- $P(E_2 \\mid E_1)=0.25$, $P(E_2 \\mid \\overline{E_1})=0.03$.\n- $P(E_3 \\mid \\overline{E_1},\\overline{E_2})=0.02$, $P(E_3 \\mid E_1,\\overline{E_2})=0.10$, $P(E_3 \\mid \\overline{E_1},E_2)=0.12$, $P(E_3 \\mid E_1,E_2)=0.20$.\n\nFor this scenario, define the composite procedure failure event $F$ as “at least one step error occurs,” i.e., $F=\\{E_1 \\cup E_2 \\cup E_3\\}$, and the procedure success event $S$ as “no errors occur,” i.e., $S=\\{\\overline{E_1} \\cap \\overline{E_2} \\cap \\overline{E_3}\\}$.\n\nStarting only from the axioms of probability and the definition of conditional probability, derive a mathematically valid expression for $P(F)$ in terms of $P(\\overline{E_1})$, $P(\\overline{E_2} \\mid \\overline{E_1})$, and $P(\\overline{E_3} \\mid \\overline{E_1},\\overline{E_2})$, then evaluate it using the given BN parameters. Express the final composite HEP $P(F)$ as a decimal number (unitless). Round your answer to four significant figures.",
            "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in probabilistic risk assessment and probability theory, self-contained, well-posed, and objective. All necessary data and definitions for a unique solution are provided.\n\nThe objective is to determine the composite Human Error Probability (HEP), denoted by $P(F)$, for a three-step sequential procedure. The failure event $F$ is defined as the occurrence of at least one error across the three steps, formally expressed as the union of the individual error events $E_1$, $E_2$, and $E_3$:\n$$F = E_1 \\cup E_2 \\cup E_3$$\nA more direct method for calculating the probability of a union of events is often to calculate the probability of its complement. The complement of the failure event $F$ is the success event $S$, which corresponds to no errors occurring in any of the three steps. Using De Morgan's laws, the complement of $F$, denoted $\\overline{F}$, is:\n$$\\overline{F} = \\overline{E_1 \\cup E_2 \\cup E_3} = \\overline{E_1} \\cap \\overline{E_2} \\cap \\overline{E_3} = S$$\nAccording to the axioms of probability, the probability of an event and its complement sum to $1$. Therefore:\n$$P(F) + P(\\overline{F}) = 1$$\n$$P(F) = 1 - P(\\overline{F}) = 1 - P(S)$$\nThe task is now reduced to finding the probability of the success event, $P(S) = P(\\overline{E_1} \\cap \\overline{E_2} \\cap \\overline{E_3})$.\n\nTo derive the expression for $P(S)$, we employ the chain rule of probability, which is a consequence of the definition of conditional probability, $P(A \\cap B) = P(A \\mid B)P(B)$. For three events, the chain rule states:\n$$P(\\overline{E_1} \\cap \\overline{E_2} \\cap \\overline{E_3}) = P(\\overline{E_3} \\mid \\overline{E_1} \\cap \\overline{E_2}) P(\\overline{E_2} \\cap \\overline{E_1})$$\nApplying the definition of conditional probability again to the term $P(\\overline{E_2} \\cap \\overline{E_1})$:\n$$P(\\overline{E_2} \\cap \\overline{E_1}) = P(\\overline{E_2} \\mid \\overline{E_1}) P(\\overline{E_1})$$\nSubstituting this back yields the full expression for $P(S)$:\n$$P(S) = P(\\overline{E_1}) P(\\overline{E_2} \\mid \\overline{E_1}) P(\\overline{E_3} \\mid \\overline{E_1}, \\overline{E_2})$$\nThis is the structure dictated by the problem, which naturally arises from the specified Bayesian Network's causal dependencies ($E_1 \\rightarrow E_2$, $E_1 \\rightarrow E_3$, $E_2 \\rightarrow E_3$).\n\nThe composite failure probability $P(F)$ is therefore:\n$$P(F) = 1 - \\left( P(\\overline{E_1}) P(\\overline{E_2} \\mid \\overline{E_1}) P(\\overline{E_3} \\mid \\overline{E_1}, \\overline{E_2}) \\right)$$\nWe now evaluate each term using the provided data. The probability of an event's complement $\\overline{A}$ is $P(\\overline{A}) = 1 - P(A)$.\n\n1.  Calculate $P(\\overline{E_1})$:\n    Given $P(E_1) = 0.08$.\n    $$P(\\overline{E_1}) = 1 - P(E_1) = 1 - 0.08 = 0.92$$\n\n2.  Calculate $P(\\overline{E_2} \\mid \\overline{E_1})$:\n    Given $P(E_2 \\mid \\overline{E_1}) = 0.03$.\n    $$P(\\overline{E_2} \\mid \\overline{E_1}) = 1 - P(E_2 \\mid \\overline{E_1}) = 1 - 0.03 = 0.97$$\n\n3.  Calculate $P(\\overline{E_3} \\mid \\overline{E_1}, \\overline{E_2})$:\n    Given $P(E_3 \\mid \\overline{E_1}, \\overline{E_2}) = 0.02$.\n    $$P(\\overline{E_3} \\mid \\overline{E_1}, \\overline{E_2}) = 1 - P(E_3 \\mid \\overline{E_1}, \\overline{E_2}) = 1 - 0.02 = 0.98$$\n\nNow, substitute these probabilities into the expression for $P(S)$:\n$$P(S) = (0.92) \\times (0.97) \\times (0.98)$$\n$$P(S) = 0.8924 \\times 0.98$$\n$$P(S) = 0.874552$$\n\nFinally, calculate the composite HEP, $P(F)$:\n$$P(F) = 1 - P(S) = 1 - 0.874552 = 0.125448$$\nThe problem requires the answer to be rounded to four significant figures.\n$$P(F) \\approx 0.1254$$\nThis value represents the total probability of at least one human error occurring during the three-step emergency procedure, accounting for the specified cognitive and sequential dependencies.",
            "answer": "$$\\boxed{0.1254}$$"
        },
        {
            "introduction": "Individual calculations of system reliability and human error are building blocks for a complete plant-level risk model, which often combines event trees and fault trees. Crucially, the input parameters for these models—such as failure rates and initiating event frequencies—are not known with certainty. This computational exercise  integrates these concepts and introduces you to Monte Carlo simulation, the standard method for propagating parameter uncertainty through a PRA model. By implementing this simulation, you will generate a probability distribution for the overall Core Damage Frequency (CDF), allowing you to quantify not just a point estimate of risk, but also the confidence we have in that estimate.",
            "id": "4242362",
            "problem": "You are tasked with implementing a program that propagates parameter uncertainty through an event tree and associated fault trees using Monte Carlo sampling to produce the distribution of the Core Damage Frequency (CDF) and its credible intervals. The problem is set within the context of nuclear reactor probabilistic risk assessment (PRA). Your implementation must be general, scientifically grounded, and strictly adhere to the specified output format.\n\nStart from the following fundamental base and core definitions:\n- The event tree represents mutually exclusive initiating events leading to potential sequences. The Core Damage Frequency (CDF) is defined as the sum of initiating event frequencies times the conditional core damage probabilities along the relevant sequences. Formally, if there are $M$ initiating events, then\n$$\n\\text{CDF} = \\sum_{i=1}^{M} f_i \\, P_i,\n$$\nwhere $f_i$ is the initiating event frequency (per reactor-year) and $P_i$ is the conditional probability of core damage for event $i$.\n- Fault trees encode how system failures combine via logic gates such as AND and OR, under independence of basic component failure events. If $A$ and $B$ are independent failures, then for an AND gate,\n$$\nP(A \\land B) = P(A) \\, P(B),\n$$\nand for an OR gate,\n$$\nP(A \\lor B) = P(A) + P(B) - P(A) P(B).\n$$\n- Component on-demand failure probabilities are modeled as random variables with Beta distributions, reflecting uncertainty. If $p$ is the failure probability, then $p \\sim \\text{Beta}(\\alpha,\\beta)$ with mean $\\mathbb{E}[p] = \\frac{\\alpha}{\\alpha + \\beta}$.\n- Time-dependent run failures are modeled as a Poisson process with rate $\\lambda$ (failures per hour). The probability of at least one failure during mission time $t$ hours is\n$$\nq = 1 - e^{-\\lambda t}.\n$$\n- Initiating event frequencies $f_i$ (per reactor-year) are modeled as independent lognormal random variables, $f_i \\sim \\text{Lognormal}(\\mu_i, \\sigma_i)$, where $\\mu_i$ and $\\sigma_i$ are the mean and standard deviation of the natural logarithm (so that $\\log f_i \\sim \\mathcal{N}(\\mu_i, \\sigma_i^2)$).\n\nThe event tree and fault tree structures to be modeled are as follows:\n- Initiating events: Loss-of-Coolant Accident (LOCA), Station Blackout (SBO), and Anticipated Transient Without Scram (ATWS). Let the index set be $i \\in \\{\\text{LOCA}, \\text{SBO}, \\text{ATWS}\\}$.\n- Fault tree top-event logic is defined as:\n    - For LOCA, core damage occurs if both High-Pressure Injection (HPI) and Low-Pressure Injection (LPI) fail on demand, modeled by an AND gate: \n      $$\n      P_{\\text{LOCA}} = p_{\\text{HPI}} \\cdot p_{\\text{LPI}}.\n      $$\n    - For ATWS, core damage occurs if Auxiliary Feedwater (AFW) fails on demand and Low-Pressure Injection (LPI) fails on demand, also an AND gate:\n      $$\n      P_{\\text{ATWS}} = p_{\\text{AFW}} \\cdot p_{\\text{LPI}}.\n      $$\n    - For SBO, core damage occurs if fewer than $k$ out of $n$ Emergency Diesel Generators (EDGs) run successfully for the specified mission time. Let $q$ denote the per-generator run failure probability during the mission time, assumed identical and independent across generators. Then the probability that fewer than $k$ generators run is the binomial cumulative probability:\n      $$\n      P_{\\text{SBO}} = \\sum_{s=0}^{k-1} \\binom{n}{s} (1-q)^s \\, q^{n-s}.\n      $$\n\nUncertainty propagation and the Monte Carlo approach:\n- For each Monte Carlo realization:\n    - Sample component on-demand failure probabilities $p_{\\text{HPI}} \\sim \\text{Beta}(\\alpha_{\\text{HPI}}, \\beta_{\\text{HPI}})$, $p_{\\text{LPI}} \\sim \\text{Beta}(\\alpha_{\\text{LPI}}, \\beta_{\\text{LPI}})$, $p_{\\text{AFW}} \\sim \\text{Beta}(\\alpha_{\\text{AFW}}, \\beta_{\\text{AFW}})$, which are shared across all initiating events in that realization.\n    - Sample the Emergency Diesel Generator run failure rate $\\lambda_{\\text{EDG}}$ from a lognormal distribution with parameters $(\\mu_{\\lambda}, \\sigma_{\\lambda})$ (parameters of the natural logarithm) and compute $q = 1 - e^{-\\lambda_{\\text{EDG}} t}$, where $t$ is the mission time in hours. These EDG parameters are also common across events in that realization.\n    - Sample initiating event frequencies $f_{\\text{LOCA}}$, $f_{\\text{SBO}}$, and $f_{\\text{ATWS}}$ independently from their specified lognormal distributions.\n    - Compute $P_{\\text{LOCA}}$, $P_{\\text{SBO}}$, and $P_{\\text{ATWS}}$ using the gate logic formulas above, and then compute \n      $$\n      \\text{CDF} = f_{\\text{LOCA}} P_{\\text{LOCA}} + f_{\\text{SBO}} P_{\\text{SBO}} + f_{\\text{ATWS}} P_{\\text{ATWS}}.\n      $$\n- Repeat for $N$ realizations to obtain a distribution of $\\text{CDF}$. Report the empirical mean and a two-sided credible interval at level $c$ (for example, $c = 0.95$). The two-sided credible interval endpoints are the $(\\frac{1-c}{2})$ and $(1-\\frac{1-c}{2})$ empirical quantiles of the sampled CDF distribution.\n\nPhysical and numerical units:\n- Report all CDF and interval values in $1/\\text{year}$ (per reactor-year). Express the numerical outputs as dimensionless floats whose implied unit is $1/\\text{year}$.\n\nAngle units do not apply. Percentages should not be used; express all probabilities as decimal fractions.\n\nTest suite:\nImplement your program to run the following four test cases and return the results for each in the specified format. The program must use a fixed random seed for reproducibility.\n\n- Test Case $1$ (moderate uncertainties, baseline architecture):\n    - Monte Carlo samples: $N = 20000$.\n    - Credible level: $c = 0.95$.\n    - Mission time: $t = 8$ hours.\n    - EDGs: $n = 2$, $k = 1$.\n    - Beta parameters (on-demand failures):\n        - HPI: $(\\alpha_{\\text{HPI}}, \\beta_{\\text{HPI}}) = (10, 190)$.\n        - LPI: $(\\alpha_{\\text{LPI}}, \\beta_{\\text{LPI}}) = (8, 192)$.\n        - AFW: $(\\alpha_{\\text{AFW}}, \\beta_{\\text{AFW}}) = (12, 288)$.\n    - Lognormal parameters for EDG run failure rate (per hour): $(\\mu_{\\lambda}, \\sigma_{\\lambda}) = (\\log(0.01), 0.5)$.\n    - Lognormal parameters for initiating event frequencies (per year):\n        - LOCA: $(\\mu, \\sigma) = (\\log(10^{-3}), 0.5)$.\n        - SBO: $(\\mu, \\sigma) = (\\log(5 \\cdot 10^{-4}), 0.6)$.\n        - ATWS: $(\\mu, \\sigma) = (\\log(10^{-4}), 0.7)$.\n\n- Test Case $2$ (low uncertainty, shorter mission time):\n    - Monte Carlo samples: $N = 10000$.\n    - Credible level: $c = 0.90$.\n    - Mission time: $t = 4$ hours.\n    - EDGs: $n = 2$, $k = 1$.\n    - Beta parameters (on-demand failures):\n        - HPI: $(\\alpha_{\\text{HPI}}, \\beta_{\\text{HPI}}) = (100, 1900)$.\n        - LPI: $(\\alpha_{\\text{LPI}}, \\beta_{\\text{LPI}}) = (120, 2880)$.\n        - AFW: $(\\alpha_{\\text{AFW}}, \\beta_{\\text{AFW}}) = (150, 3675)$.\n    - Lognormal parameters for EDG run failure rate (per hour): $(\\mu_{\\lambda}, \\sigma_{\\lambda}) = (\\log(0.01), 0.2)$.\n    - Lognormal parameters for initiating event frequencies (per year):\n        - LOCA: $(\\mu, \\sigma) = (\\log(8 \\cdot 10^{-4}), 0.3)$.\n        - SBO: $(\\mu, \\sigma) = (\\log(3 \\cdot 10^{-4}), 0.4)$.\n        - ATWS: $(\\mu, \\sigma) = (\\log(2 \\cdot 10^{-4}), 0.35)$.\n\n- Test Case $3$ (heavy-tailed uncertainties, long mission time):\n    - Monte Carlo samples: $N = 15000$.\n    - Credible level: $c = 0.95$.\n    - Mission time: $t = 24$ hours.\n    - EDGs: $n = 2$, $k = 1$.\n    - Beta parameters (on-demand failures):\n        - HPI: $(\\alpha_{\\text{HPI}}, \\beta_{\\text{HPI}}) = (2, 38)$.\n        - LPI: $(\\alpha_{\\text{LPI}}, \\beta_{\\text{LPI}}) = (2, 48)$.\n        - AFW: $(\\alpha_{\\text{AFW}}, \\beta_{\\text{AFW}}) = (3, 72)$.\n    - Lognormal parameters for EDG run failure rate (per hour): $(\\mu_{\\lambda}, \\sigma_{\\lambda}) = (\\log(0.02), 0.8)$.\n    - Lognormal parameters for initiating event frequencies (per year):\n        - LOCA: $(\\mu, \\sigma) = (\\log(5 \\cdot 10^{-4}), 1.0)$.\n        - SBO: $(\\mu, \\sigma) = (\\log(8 \\cdot 10^{-4}), 1.1)$.\n        - ATWS: $(\\mu, \\sigma) = (\\log(1.5 \\cdot 10^{-4}), 1.2)$.\n\n- Test Case $4$ (redundancy architecture variation, multiple generators required):\n    - Monte Carlo samples: $N = 12000$.\n    - Credible level: $c = 0.95$.\n    - Mission time: $t = 12$ hours.\n    - EDGs: $n = 3$, $k = 2$.\n    - Beta parameters (on-demand failures):\n        - HPI: $(\\alpha_{\\text{HPI}}, \\beta_{\\text{HPI}}) = (20, 380)$.\n        - LPI: $(\\alpha_{\\text{LPI}}, \\beta_{\\text{LPI}}) = (16, 384)$.\n        - AFW: $(\\alpha_{\\text{AFW}}, \\beta_{\\text{AFW}}) = (25, 600)$.\n    - Lognormal parameters for EDG run failure rate (per hour): $(\\mu_{\\lambda}, \\sigma_{\\lambda}) = (\\log(0.005), 0.7)$.\n    - Lognormal parameters for initiating event frequencies (per year):\n        - LOCA: $(\\mu, \\sigma) = (\\log(7 \\cdot 10^{-4}), 0.6)$.\n        - SBO: $(\\mu, \\sigma) = (\\log(4 \\cdot 10^{-4}), 0.6)$.\n        - ATWS: $(\\mu, \\sigma) = (\\log(10^{-4}), 0.7)$.\n\nProgram requirements:\n- Use a fixed random seed for reproducibility.\n- For each test case, perform Monte Carlo sampling to obtain the CDF distribution and compute the empirical mean, the lower credible bound, and the upper credible bound at the specified level $c$. The credible bounds must be the $\\left(\\frac{1-c}{2}\\right)$ and $\\left(1 - \\frac{1-c}{2}\\right)$ quantiles of the sampled CDF.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a list of three floats $[\\text{mean},\\text{lower},\\text{upper}]$ corresponding to each test case, in order. For example, the output format must be\n$$\n\\big[ [m_1,\\ell_1,u_1],[m_2,\\ell_2,u_2],[m_3,\\ell_3,u_3],[m_4,\\ell_4,u_4] \\big],\n$$\nwhere all values are in $1/\\text{year}$ and represented as decimals (unit not printed).",
            "solution": "The problem statement has been meticulously reviewed and validated against the specified criteria.\n\n### Step 1: Extract Givens\n\n- **Core Damage Frequency (CDF) Definition**: $\\text{CDF} = \\sum_{i=1}^{M} f_i \\, P_i$ for $M$ initiating events.\n- **Initiating Events**: $i \\in \\{\\text{LOCA}, \\text{SBO}, \\text{ATWS}\\}$, so $M=3$.\n- **Fault Tree Logic**:\n    - AND Gate: $P(A \\land B) = P(A) \\, P(B)$ for independent events.\n    - OR Gate: $P(A \\lor B) = P(A) + P(B) - P(A) P(B)$ for independent events.\n- **Conditional Core Damage Probabilities ($P_i$)**:\n    - $P_{\\text{LOCA}} = p_{\\text{HPI}} \\cdot p_{\\text{LPI}}$\n    - $P_{\\text{ATWS}} = p_{\\text{AFW}} \\cdot p_{\\text{LPI}}$\n    - $P_{\\text{SBO}} = \\sum_{s=0}^{k-1} \\binom{n}{s} (1-q)^s q^{n-s}$\n- **Probabilistic Models for Basic Events**:\n    - On-demand failure probability: $p \\sim \\text{Beta}(\\alpha, \\beta)$.\n    - Time-dependent run failure probability: $q = 1 - e^{-\\lambda t}$, where $\\lambda$ is the failure rate (per hour) and $t$ is the mission time (hours).\n- **Uncertainty Models for Parameters**:\n    - On-demand failure probabilities $p_{\\text{HPI}}$, $p_{\\text{LPI}}$, $p_{\\text{AFW}}$ are sampled from their respective Beta distributions once per Monte Carlo realization.\n    - EDG run failure rate $\\lambda_{\\text{EDG}}$ is sampled from a Lognormal distribution: $\\log(\\lambda_{\\text{EDG}}) \\sim \\mathcal{N}(\\mu_{\\lambda}, \\sigma_{\\lambda}^2)$.\n    - Initiating event frequencies $f_i$ are sampled from Lognormal distributions: $\\log(f_i) \\sim \\mathcal{N}(\\mu_i, \\sigma_i^2)$. All frequencies are in units of $1/\\text{year}$.\n- **Monte Carlo Procedure**:\n    - For each of $N$ realizations, sample all base parameters ($p$'s, $\\lambda$, $f$'s), calculate $q$, then $P_i$'s, and finally the total CDF.\n    - Compute the empirical mean and the $(\\frac{1-c}{2})$ and $(1-\\frac{1-c}{2})$ empirical quantiles of the $N$ CDF samples to form a credible interval at level $c$.\n- **Test Cases**: Four distinct test cases are provided, each specifying $N, c, t, n, k$, and the parameters for all Beta and Lognormal distributions.\n- **Program Requirements**: Use a fixed random seed. Output the results for all four test cases as a list of lists: $\\big[ [m_1,\\ell_1,u_1],[m_2,\\ell_2,u_2],[m_3,\\ell_3,u_3],[m_4,\\ell_4,u_4] \\big]$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is reviewed for validity:\n- **Scientifically Grounded**: The problem is an exemplary application of Probabilistic Risk Assessment (PRA) principles, a cornerstone of nuclear safety engineering. The use of event trees, fault trees, Monte Carlo methods, and specific probability distributions (Beta for probabilities, Lognormal for frequencies and rates) is standard and correct practice in the field.\n- **Well-Posed**: The problem is fully specified. It provides a complete set of models, parameters, and computational instructions. The objective—to compute the mean and credible interval for the CDF—is clearly defined. The requirement of a fixed random seed ensures that the computational result is deterministic and reproducible.\n- **Objective**: The problem is stated in precise, quantitative, and unbiased language. All definitions and parameters are formal and unambiguous.\n- **Consistency and Completeness**: The setup is internally consistent and complete. All necessary data for each of the four test cases are provided. The relationships between variables (e.g., $\\lambda_{\\text{EDG}}$ and $q$) are explicitly defined. The shared nature of the LPI system failure probability ($p_{\\text{LPI}}$) across two event sequences is a realistic feature correctly incorporated into the model.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. It is a well-structured, scientifically sound, and computationally tractable problem in the domain of nuclear reactor simulation and risk assessment. A solution will be developed.\n\n### Solution\n\nThe objective is to implement a Monte Carlo simulation to propagate uncertainties through a simplified PRA model and calculate the distribution of the Core Damage Frequency (CDF). From this distribution, we will determine the mean CDF and its credible interval for several specified test cases.\n\n**Theoretical Framework**\n\nThe total Core Damage Frequency is the sum of the frequencies of all accident sequences leading to core damage. In this model, we have three mutually exclusive initiating events (IEs): Loss-of-Coolant Accident (LOCA), Station Blackout (SBO), and Anticipated Transient Without Scram (ATWS). The CDF is therefore:\n$$\n\\text{CDF} = f_{\\text{LOCA}} P_{\\text{LOCA}} + f_{\\text{SBO}} P_{\\text{SBO}} + f_{\\text{ATWS}} P_{\\text{ATWS}}\n$$\nwhere $f_i$ is the frequency of initiating event $i$ and $P_i$ is the conditional probability of core damage given that event $i$ has occurred.\n\nThe uncertainty in the model parameters is propagated by treating them as random variables. For each Monte Carlo realization, we draw a sample for each parameter from its specified probability distribution.\n\n**1. Parameter Sampling:**\n- **Initiating Event Frequencies ($f_i$)**: The frequencies are modeled by Lognormal distributions. We sample $f_i$ from $\\text{Lognormal}(\\mu_i, \\sigma_i)$, where $\\mu_i$ and $\\sigma_i$ are the mean and standard deviation of $\\log(f_i)$.\n- **On-Demand Failure Probabilities ($p$)**: The probabilities of systems failing on demand ($p_{\\text{HPI}}$, $p_{\\text{LPI}}$, $p_{\\text{AFW}}$) are modeled by Beta distributions. We sample each from its respective $\\text{Beta}(\\alpha, \\beta)$ distribution. Note that a single sampled value for $p_{\\text{LPI}}$ is used for both the LOCA and ATWS sequences within the same realization, correctly modeling it as a shared dependency.\n- **Time-Dependent Failure Rate ($\\lambda_{\\text{EDG}}$)**: The failure rate of the Emergency Diesel Generators (EDGs) is sampled from a Lognormal distribution, $\\lambda_{\\text{EDG}} \\sim \\text{Lognormal}(\\mu_{\\lambda}, \\sigma_{\\lambda})$. From this, the probability of an EDG failing to run for the mission time $t$ is calculated as $q = 1 - e^{-\\lambda_{\\text{EDG}} t}$.\n\n**2. Conditional Probability Calculation ($P_i$):**\n- **$P_{\\text{LOCA}}$**: Core damage following a LOCA requires the failure of both the High-Pressure Injection (HPI) and Low-Pressure Injection (LPI) systems. Assuming independence, this is an AND gate:\n$$\nP_{\\text{LOCA}} = p_{\\text{HPI}} \\cdot p_{\\text{LPI}}\n$$\n- **$P_{\\text{ATWS}}$**: Core damage following an ATWS requires the failure of both the Auxiliary Feedwater (AFW) and LPI systems. This is also an AND gate:\n$$\nP_{\\text{ATWS}} = p_{\\text{AFW}} \\cdot p_{\\text{LPI}}\n$$\n- **$P_{\\text{SBO}}$**: Core damage following an SBO occurs if the emergency power system fails. This system consists of $n$ EDGs, and at least $k$ must run successfully. Failure occurs if fewer than $k$ EDGs run. Let $S$ be the number of successfully running EDGs. The probability of a single EDG running is $(1-q)$. Assuming independent failures, $S$ follows a binomial distribution, $S \\sim \\text{Binomial}(n, 1-q)$. The probability of system failure is $P(S < k) = P(S \\le k-1)$, which is the cumulative distribution function (CDF) of the binomial distribution:\n$$\nP_{\\text{SBO}} = \\sum_{s=0}^{k-1} \\binom{n}{s} (1-q)^s q^{n-s}\n$$\n\n**Monte Carlo Simulation Algorithm**\n\nThe simulation proceeds as follows for each test case:\n1.  **Initialization**: Set a fixed random number generator seed for reproducibility. Initialize an empty list to store the calculated CDF values for each realization.\n2.  **Vectorized Sampling**: For a total of $N$ Monte Carlo samples, generate $N$ random variates for each uncertain parameter simultaneously. This is computationally efficient.\n    -   Generate an array of $N$ samples for $p_{\\text{HPI}}, p_{\\text{LPI}}, p_{\\text{AFW}}$ from their Beta distributions.\n    -   Generate an array of $N$ samples for $\\lambda_{\\text{EDG}}$ from its Lognormal distribution.\n    -   Generate arrays of $N$ samples for $f_{\\text{LOCA}}, f_{\\text{SBO}}, f_{\\text{ATWS}}$ from their Lognormal distributions.\n3.  **Vectorized Calculation**: Perform arithmetic operations on these arrays to compute the CDF for all $N$ realizations at once.\n    -   Calculate the array of $q$ values: $q_{\\text{samples}} = 1 - \\exp(-\\lambda_{\\text{EDG\\_samples}} \\cdot t)$.\n    -   Calculate the array of $P_{\\text{SBO}}$ values using the binomial CDF for each element in $q_{\\text{samples}}$.\n    -   Calculate the arrays for $P_{\\text{LOCA}}$ and $P_{\\text{ATWS}}$.\n    -   Combine these to get the final array of $N$ CDF samples: $\\text{CDF}_{\\text{samples}} = (f_{\\text{LOCA}} \\cdot P_{\\text{LOCA}} + f_{\\text{SBO}} \\cdot P_{\\text{SBO}} + f_{\\text{ATWS}} \\cdot P_{\\text{ATWS}})_{\\text{samples}}$.\n4.  **Statistical Analysis**:\n    -   Calculate the empirical mean of the $\\text{CDF}_{\\text{samples}}$ array.\n    -   Calculate the credible interval. For a credibility level $c$, the lower and upper bounds are the empirical quantiles corresponding to probabilities $p_L = (1-c)/2$ and $p_U = 1 - (1-c)/2$.\n5.  **Output Formatting**: Store the resulting triplet of [mean, lower bound, upper bound] for the test case. Repeat for all four cases and format the final output as specified.\n\nThis vectorized approach leverages numerical libraries like `NumPy` and `SciPy` for high performance, which is essential for running tens of thousands of simulations efficiently.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import binom\n\ndef solve():\n    \"\"\"\n    Main function to run the Monte Carlo simulation for all specified test cases\n    and print the results in the required format.\n    \"\"\"\n    # A fixed random seed is used for reproducibility of the Monte Carlo simulation.\n    RANDOM_SEED = 42\n    rng = np.random.default_rng(RANDOM_SEED)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1: moderate uncertainties, baseline architecture\n        {\n            \"N\": 20000, \"c\": 0.95, \"t\": 8.0, \"edg_n\": 2, \"edg_k\": 1,\n            \"beta_hpi\": (10, 190), \"beta_lpi\": (8, 192), \"beta_afw\": (12, 288),\n            \"lognorm_edg_rate\": (np.log(0.01), 0.5),\n            \"lognorm_loca_freq\": (np.log(1e-3), 0.5),\n            \"lognorm_sbo_freq\": (np.log(5e-4), 0.6),\n            \"lognorm_atws_freq\": (np.log(1e-4), 0.7),\n        },\n        # Test Case 2: low uncertainty, shorter mission time\n        {\n            \"N\": 10000, \"c\": 0.90, \"t\": 4.0, \"edg_n\": 2, \"edg_k\": 1,\n            \"beta_hpi\": (100, 1900), \"beta_lpi\": (120, 2880), \"beta_afw\": (150, 3675),\n            \"lognorm_edg_rate\": (np.log(0.01), 0.2),\n            \"lognorm_loca_freq\": (np.log(8e-4), 0.3),\n            \"lognorm_sbo_freq\": (np.log(3e-4), 0.4),\n            \"lognorm_atws_freq\": (np.log(2e-4), 0.35),\n        },\n        # Test Case 3: heavy-tailed uncertainties, long mission time\n        {\n            \"N\": 15000, \"c\": 0.95, \"t\": 24.0, \"edg_n\": 2, \"edg_k\": 1,\n            \"beta_hpi\": (2, 38), \"beta_lpi\": (2, 48), \"beta_afw\": (3, 72),\n            \"lognorm_edg_rate\": (np.log(0.02), 0.8),\n            \"lognorm_loca_freq\": (np.log(5e-4), 1.0),\n            \"lognorm_sbo_freq\": (np.log(8e-4), 1.1),\n            \"lognorm_atws_freq\": (np.log(1.5e-4), 1.2),\n        },\n        # Test Case 4: redundancy architecture variation, multiple generators required\n        {\n            \"N\": 12000, \"c\": 0.95, \"t\": 12.0, \"edg_n\": 3, \"edg_k\": 2,\n            \"beta_hpi\": (20, 380), \"beta_lpi\": (16, 384), \"beta_afw\": (25, 600),\n            \"lognorm_edg_rate\": (np.log(0.005), 0.7),\n            \"lognorm_loca_freq\": (np.log(7e-4), 0.6),\n            \"lognorm_sbo_freq\": (np.log(4e-4), 0.6),\n            \"lognorm_atws_freq\": (np.log(1e-4), 0.7),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        N = case[\"N\"]\n        \n        # Step 1: Sample all uncertain parameters (vectorized)\n        \n        # Sample on-demand failure probabilities from Beta distributions\n        p_hpi = rng.beta(case[\"beta_hpi\"][0], case[\"beta_hpi\"][1], size=N)\n        p_lpi = rng.beta(case[\"beta_lpi\"][0], case[\"beta_lpi\"][1], size=N)\n        p_afw = rng.beta(case[\"beta_afw\"][0], case[\"beta_afw\"][1], size=N)\n\n        # Sample EDG run failure rate and compute run failure probability q\n        lambda_edg = rng.lognormal(case[\"lognorm_edg_rate\"][0], case[\"lognorm_edg_rate\"][1], size=N)\n        mission_time = case[\"t\"]\n        q_edg = 1 - np.exp(-lambda_edg * mission_time)\n\n        # Sample initiating event frequencies from Lognormal distributions\n        f_loca = rng.lognormal(case[\"lognorm_loca_freq\"][0], case[\"lognorm_loca_freq\"][1], size=N)\n        f_sbo = rng.lognormal(case[\"lognorm_sbo_freq\"][0], case[\"lognorm_sbo_freq\"][1], size=N)\n        f_atws = rng.lognormal(case[\"lognorm_atws_freq\"][0], case[\"lognorm_atws_freq\"][1], size=N)\n        \n        # Step 2: Calculate conditional core damage probabilities (P_i)\n        \n        # P_LOCA = p_HPI * p_LPI (AND gate)\n        P_loca = p_hpi * p_lpi\n        \n        # P_ATWS = p_AFW * p_LPI (AND gate)\n        P_atws = p_afw * p_lpi\n\n        # P_SBO: Binomial probability of fewer than k successes out of n trials.\n        # Success = EDG runs, probability of success = 1 - q_edg\n        n, k = case[\"edg_n\"], case[\"edg_k\"]\n        P_sbo = binom.cdf(k - 1, n, 1 - q_edg)\n\n        # Step 3: Calculate the total CDF for each realization\n        cdf_samples = (f_loca * P_loca) + (f_sbo * P_sbo) + (f_atws * P_atws)\n        \n        # Step 4: Compute summary statistics (mean and credible interval)\n        mean_cdf = np.mean(cdf_samples)\n        \n        c = case[\"c\"]\n        lower_quantile = (1 - c) / 2\n        upper_quantile = 1 - lower_quantile\n        \n        lower_bound = np.quantile(cdf_samples, lower_quantile)\n        upper_bound = np.quantile(cdf_samples, upper_quantile)\n        \n        results.append([mean_cdf, lower_bound, upper_bound])\n\n    # Final print statement in the exact required format.\n    # str() on a list produces '[a, b, c]', which includes spaces.\n    # This is joined by commas, producing '[a, b, c],[d, e, f]'.\n    # This is then wrapped in brackets: '[[a, b, c],[d, e, f]]'.\n    # This matches the desired structure.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}