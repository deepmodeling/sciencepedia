{
    "hands_on_practices": [
        {
            "introduction": "Before deploying a powerful mathematical tool like the matrix exponential, it is crucial to verify its correctness on a problem with a known, trusted solution. This practice guides you through a fundamental check: demonstrating that the matrix exponential formulation for a simple two-nuclide decay chain yields the exact same result as the classic Bateman equations derived directly from the underlying ordinary differential equations (ODEs). Successfully completing this exercise builds essential intuition and confidence in the state transition matrix, $\\exp(A \\Delta t)$, as a physical propagator.",
            "id": "4234748",
            "problem": "In a homogeneous, zero-flux cell, consider a two-nuclide chain where nuclide $1$ decays to nuclide $2$ with decay constant $\\lambda_{1} > 0$, and nuclide $2$ decays to a stable sink with decay constant $\\lambda_{2} > 0$. There are no other reactions or sources. Let the inventory vector be $n(t) = \\begin{pmatrix} n_{1}(t) \\\\ n_{2}(t) \\end{pmatrix}$, with initial condition $n(0) = \\begin{pmatrix} n_{1,0} \\\\ n_{2,0} \\end{pmatrix}$. The depletion equations are linear and time-invariant and can be written as $\\frac{d}{dt} n(t) = A n(t)$, where $A$ is a constant matrix. Assume $\\lambda_{1} \\neq \\lambda_{2}$.\n\nUsing only the fundamental radioactive decay law and the definition of the matrix exponential as the solution operator for linear time-invariant systems, perform the following:\n\n- Identify the system matrix $A$ implied by the physical description.\n- Derive a closed-form expression for $n_{2}(\\Delta t)$ in terms of $n_{1,0}$, $n_{2,0}$, $\\lambda_{1}$, $\\lambda_{2}$, and $\\Delta t$, starting from the scalar ordinary differential equations (ODEs).\n- Independently, starting from the definition of the state transition matrix $\\Phi(t) = \\exp(A t)$ as the unique solution of $\\frac{d}{dt}\\Phi(t) = A \\Phi(t)$ with $\\Phi(0) = I$, determine the $(2,1)$ entry of $\\exp(A \\Delta t)$.\n- Verify that applying $\\exp(A \\Delta t)$ to $n(0)$ reproduces the closed-form $n_{2}(\\Delta t)$ for arbitrary $n_{1,0}$ and $n_{2,0}$.\n\nProvide as your final answer the symbolic expression for the $(2,1)$ entry of $\\exp(A \\Delta t)$. No numerical evaluation is required, and no units are to be reported. The answer should be a single closed-form analytic expression.",
            "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and free of contradictions or ambiguities. It represents a standard problem in nuclear engineering and mathematical physics. We may therefore proceed with a full solution.\n\nThe problem asks for a multi-step derivation and verification concerning a two-nuclide radioactive decay chain. Let $n_1(t)$ and $n_2(t)$ be the concentrations of nuclide $1$ and nuclide $2$ at time $t$, respectively.\n\n**1. Identification of the System Matrix $A$**\n\nThe physical process is a decay chain $1 \\rightarrow 2 \\rightarrow \\text{stable}$.\nThe rate of change of the concentration of nuclide $1$, $n_1(t)$, is governed solely by its own radioactive decay. The rate of decay is proportional to its concentration, with the decay constant being $\\lambda_1$.\n$$ \\frac{d n_1(t)}{dt} = -\\lambda_1 n_1(t) $$\nThe rate of change of the concentration of nuclide $2$, $n_2(t)$, has two contributions: a source term from the decay of nuclide $1$ and a loss term from its own decay. The production rate from nuclide $1$ is $\\lambda_1 n_1(t)$, and the loss rate is $\\lambda_2 n_2(t)$.\n$$ \\frac{d n_2(t)}{dt} = \\lambda_1 n_1(t) - \\lambda_2 n_2(t) $$\nThese two coupled first-order linear ordinary differential equations can be expressed in matrix form as $\\frac{d}{dt} n(t) = A n(t)$:\n$$ \\frac{d}{dt} \\begin{pmatrix} n_1(t) \\\\ n_2(t) \\end{pmatrix} = \\begin{pmatrix} -\\lambda_1 & 0 \\\\ \\lambda_1 & -\\lambda_2 \\end{pmatrix} \\begin{pmatrix} n_1(t) \\\\ n_2(t) \\end{pmatrix} $$\nBy inspection, the system matrix $A$ is:\n$$ A = \\begin{pmatrix} -\\lambda_1 & 0 \\\\ \\lambda_1 & -\\lambda_2 \\end{pmatrix} $$\n\n**2. Derivation of $n_2(\\Delta t)$ from Scalar ODEs**\n\nFirst, we solve the ODE for $n_1(t)$ with the initial condition $n_1(0) = n_{1,0}$:\n$$ \\frac{dn_1}{dt} = -\\lambda_1 n_1(t) \\implies n_1(t) = n_{1,0} \\exp(-\\lambda_1 t) $$\nNext, we substitute this solution into the ODE for $n_2(t)$:\n$$ \\frac{dn_2}{dt} = \\lambda_1 n_{1,0} \\exp(-\\lambda_1 t) - \\lambda_2 n_2(t) $$\nThis can be rewritten as a standard first-order linear ODE:\n$$ \\frac{dn_2}{dt} + \\lambda_2 n_2(t) = \\lambda_1 n_{1,0} \\exp(-\\lambda_1 t) $$\nWe solve this using an integrating factor, $\\mu(t) = \\exp\\left(\\int \\lambda_2 dt\\right) = \\exp(\\lambda_2 t)$. Multiplying the equation by $\\mu(t)$:\n$$ \\exp(\\lambda_2 t) \\frac{dn_2}{dt} + \\lambda_2 \\exp(\\lambda_2 t) n_2(t) = \\lambda_1 n_{1,0} \\exp((\\lambda_2 - \\lambda_1)t) $$\nThe left side is the derivative of the product $n_2(t)\\mu(t)$:\n$$ \\frac{d}{dt} \\left( n_2(t) \\exp(\\lambda_2 t) \\right) = \\lambda_1 n_{1,0} \\exp((\\lambda_2 - \\lambda_1)t) $$\nIntegrating both sides from $0$ to $t$:\n$$ \\int_0^t \\frac{d}{d\\tau} \\left( n_2(\\tau) \\exp(\\lambda_2 \\tau) \\right) d\\tau = \\int_0^t \\lambda_1 n_{1,0} \\exp((\\lambda_2 - \\lambda_1)\\tau) d\\tau $$\n$$ \\left[ n_2(\\tau) \\exp(\\lambda_2 \\tau) \\right]_0^t = \\lambda_1 n_{1,0} \\left[ \\frac{\\exp((\\lambda_2 - \\lambda_1)\\tau)}{\\lambda_2 - \\lambda_1} \\right]_0^t $$\nThis step is valid because the problem states $\\lambda_1 \\neq \\lambda_2$.\n$$ n_2(t) \\exp(\\lambda_2 t) - n_2(0) \\exp(0) = \\frac{\\lambda_1 n_{1,0}}{\\lambda_2 - \\lambda_1} \\left( \\exp((\\lambda_2 - \\lambda_1)t) - 1 \\right) $$\nUsing the initial condition $n_2(0) = n_{2,0}$:\n$$ n_2(t) \\exp(\\lambda_2 t) = n_{2,0} + \\frac{\\lambda_1 n_{1,0}}{\\lambda_2 - \\lambda_1} \\left( \\exp(\\lambda_2 t)\\exp(-\\lambda_1 t) - 1 \\right) $$\nMultiplying by $\\exp(-\\lambda_2 t)$ to isolate $n_2(t)$:\n$$ n_2(t) = n_{2,0} \\exp(-\\lambda_2 t) + \\frac{\\lambda_1 n_{1,0}}{\\lambda_2 - \\lambda_1} \\left( \\exp(-\\lambda_1 t) - \\exp(-\\lambda_2 t) \\right) $$\nFinally, evaluating at time $t = \\Delta t$:\n$$ n_2(\\Delta t) = n_{2,0} \\exp(-\\lambda_2 \\Delta t) + \\frac{\\lambda_1 n_{1,0}}{\\lambda_2 - \\lambda_1} \\left( \\exp(-\\lambda_1 \\Delta t) - \\exp(-\\lambda_2 \\Delta t) \\right) $$\n\n**3. Determination of the $(2,1)$ Entry of $\\exp(A \\Delta t)$**\n\nLet $\\Phi(t) = \\exp(A t)$ be the state transition matrix. It is the unique solution to the matrix differential equation $\\frac{d}{dt}\\Phi(t) = A \\Phi(t)$ with the initial condition $\\Phi(0) = I$, the identity matrix. Let $\\Phi(t) = \\begin{pmatrix} \\Phi_{11}(t) & \\Phi_{12}(t) \\\\ \\Phi_{21}(t) & \\Phi_{22}(t) \\end{pmatrix}$.\nThe matrix equation expands to a system of ODEs for the entries of $\\Phi(t)$:\n$$ \\frac{d}{dt} \\begin{pmatrix} \\Phi_{11} & \\Phi_{12} \\\\ \\Phi_{21} & \\Phi_{22} \\end{pmatrix} = \\begin{pmatrix} -\\lambda_1 & 0 \\\\ \\lambda_1 & -\\lambda_2 \\end{pmatrix} \\begin{pmatrix} \\Phi_{11} & \\Phi_{12} \\\\ \\Phi_{21} & \\Phi_{22} \\end{pmatrix} = \\begin{pmatrix} -\\lambda_1 \\Phi_{11} & -\\lambda_1 \\Phi_{12} \\\\ \\lambda_1 \\Phi_{11} - \\lambda_2 \\Phi_{21} & \\lambda_1 \\Phi_{12} - \\lambda_2 \\Phi_{22} \\end{pmatrix} $$\nThe initial conditions are $\\Phi_{11}(0) = 1$, $\\Phi_{12}(0) = 0$, $\\Phi_{21}(0) = 0$, and $\\Phi_{22}(0) = 1$.\nTo find the $(2,1)$ entry, $\\Phi_{21}(t)$, we must solve the ODE:\n$$ \\frac{d\\Phi_{21}}{dt} = \\lambda_1 \\Phi_{11}(t) - \\lambda_2 \\Phi_{21}(t) $$\nThis requires first finding $\\Phi_{11}(t)$. From the matrix system, its ODE is $\\frac{d\\Phi_{11}}{dt} = -\\lambda_1 \\Phi_{11}$, with initial condition $\\Phi_{11}(0)=1$. The solution is $\\Phi_{11}(t) = \\exp(-\\lambda_1 t)$.\nSubstituting this into the equation for $\\Phi_{21}(t)$:\n$$ \\frac{d\\Phi_{21}}{dt} + \\lambda_2 \\Phi_{21}(t) = \\lambda_1 \\exp(-\\lambda_1 t) $$\nThis is a first-order linear ODE with initial condition $\\Phi_{21}(0) = 0$. This equation is of the same form as the one for $n_2(t)$, but with $n_{1,0}$ replaced by $1$ and $n_{2,0}$ replaced by $0$. Using the same integrating factor method or by direct substitution into the general solution form derived previously:\n$$ \\Phi_{21}(t) = 0 \\cdot \\exp(-\\lambda_2 t) + \\frac{\\lambda_1 \\cdot 1}{\\lambda_2 - \\lambda_1} \\left( \\exp(-\\lambda_1 t) - \\exp(-\\lambda_2 t) \\right) $$\n$$ \\Phi_{21}(t) = \\frac{\\lambda_1}{\\lambda_2 - \\lambda_1} \\left(\\exp(-\\lambda_1 t) - \\exp(-\\lambda_2 t)\\right) $$\nThe $(2,1)$ entry of $\\exp(A \\Delta t)$ is therefore:\n$$ (\\exp(A \\Delta t))_{2,1} = \\Phi_{21}(\\Delta t) = \\frac{\\lambda_1}{\\lambda_2 - \\lambda_1} \\left(\\exp(-\\lambda_1 \\Delta t) - \\exp(-\\lambda_2 \\Delta t)\\right) $$\n\n**4. Verification**\n\nThe solution to the system is given by $n(\\Delta t) = \\exp(A \\Delta t) n(0)$. We focus on the second component of this vector equation:\n$$ n_2(\\Delta t) = (\\exp(A \\Delta t))_{2,1} n_{1,0} + (\\exp(A \\Delta t))_{2,2} n_{2,0} $$\nWe have already found $(\\exp(A \\Delta t))_{2,1}$. We now find $(\\exp(A \\Delta t))_{2,2} = \\Phi_{22}(\\Delta t)$. The ODE is $\\frac{d\\Phi_{22}}{dt} = \\lambda_1 \\Phi_{12} - \\lambda_2 \\Phi_{22}$ with $\\Phi_{22}(0)=1$. First, we need $\\Phi_{12}(t)$. Its ODE is $\\frac{d\\Phi_{12}}{dt} = -\\lambda_1 \\Phi_{12}$ with $\\Phi_{12}(0)=0$. The only solution is $\\Phi_{12}(t)=0$.\nThe ODE for $\\Phi_{22}$ simplifies to $\\frac{d\\Phi_{22}}{dt} = -\\lambda_2 \\Phi_{22}$, with $\\Phi_{22}(0)=1$. The solution is $\\Phi_{22}(t)=\\exp(-\\lambda_2 t)$.\nSubstituting the expressions for $\\Phi_{21}(\\Delta t)$ and $\\Phi_{22}(\\Delta t)$ into the equation for $n_2(\\Delta t)$:\n$$ n_2(\\Delta t) = \\left( \\frac{\\lambda_1}{\\lambda_2 - \\lambda_1} \\left(\\exp(-\\lambda_1 \\Delta t) - \\exp(-\\lambda_2 \\Delta t)\\right) \\right) n_{1,0} + \\left( \\exp(-\\lambda_2 \\Delta t) \\right) n_{2,0} $$\nThis expression is identical to the one derived in part 2 by solving the scalar ODEs. The results are consistent, thus verifying the calculation. The $(2,1)$ entry of the matrix exponential correctly represents the contribution of the initial concentration of nuclide $1$ to the final concentration of nuclide $2$.",
            "answer": "$$\\boxed{\\frac{\\lambda_{1}}{\\lambda_{2} - \\lambda_{1}} (\\exp(-\\lambda_{1} \\Delta t) - \\exp(-\\lambda_{2} \\Delta t))}$$"
        },
        {
            "introduction": "Having confirmed that the matrix exponential method and the analytical Bateman solution are mathematically equivalent , a practical question arises: why not always use the seemingly simpler analytical formula? This practice explores the critical numerical reasons that make robust matrix exponential solvers indispensable. You will analyze how the direct evaluation of the analytical solution can fail due to catastrophic cancellation when eigenvalues of the depletion matrix are close, a common occurrence in complex depletion chains, thereby justifying the superior stability of matrix-level algorithms.",
            "id": "4234753",
            "problem": "Consider a linear depletion chain in a nuclear reactor simulation with two nuclides, where nuclide $1$ transmutes or decays into nuclide $2$ with decay constants $\\lambda_1$ and $\\lambda_2$, respectively. The number densities $N_1(t)$ and $N_2(t)$ satisfy the linear system\n$$\n\\frac{d}{dt}\n\\begin{pmatrix}\nN_1(t)\\\\\nN_2(t)\n\\end{pmatrix}\n=\nA\n\\begin{pmatrix}\nN_1(t)\\\\\nN_2(t)\n\\end{pmatrix},\n\\quad\nA=\n\\begin{pmatrix}\n-\\lambda_1 & 0\\\\\n\\lambda_1 & -\\lambda_2\n\\end{pmatrix},\n$$\nwith prescribed initial condition $\\begin{pmatrix}N_1(0)\\\\N_2(0)\\end{pmatrix}$. The fundamental solution to such a system is given by the matrix exponential $e^{A t}$, so that $\\begin{pmatrix}N_1(t)\\\\N_2(t)\\end{pmatrix}=e^{A t}\\begin{pmatrix}N_1(0)\\\\N_2(0)\\end{pmatrix}$. In practice, closed-form Bateman-type expressions that decompose the solution into sums of exponentials are often evaluated directly; however, when $\\lambda_1$ and $\\lambda_2$ are nearly equal, numerical evaluation can be delicate. Assume double-precision floating-point arithmetic as standardized by the Institute of Electrical and Electronics Engineers (IEEE) Standard $754$, with machine epsilon $\\epsilon_{\\mathrm{mach}}\\approx 2^{-53}\\approx 1.11\\times 10^{-16}$.\n\nUsing only the foundational facts that linear time-invariant systems are solved by $e^{A t}$, and that when eigenvalues coalesce the Jordan normal form introduces polynomial factors multiplying exponentials, analyze the numerical behavior for $\\lambda_1\\approx \\lambda_2$ and justify robust computation strategies. Which of the following statements are correct?\n\nA. When $\\lambda_1\\approx \\lambda_2$, the direct closed-form evaluation that separates solutions into sums of exponentials suffers from catastrophic cancellation in expressions like $e^{-\\lambda_1 t}-e^{-\\lambda_2 t}$ divided by $\\lambda_2-\\lambda_1$. Computing $e^{A t}$ via a scaling-and-squaring algorithm with Padé approximants yields the correct limiting behavior, including the $t e^{-\\lambda t}$ term that arises from a $2\\times 2$ Jordan block as the eigenvalues coalesce, thereby avoiding the cancellation.\n\nB. Diagonalizing $A$ as $A=V\\Lambda V^{-1}$ and evaluating $e^{A t}=V e^{\\Lambda t} V^{-1}$ is always numerically stable when $\\lambda_1\\approx \\lambda_2$, because the eigenvector matrix $V$ is necessarily close to unitary in that regime.\n\nC. If $\\lambda_1=\\lambda_2$, the same closed-form expression used for distinct decay constants can be retained by adding a small regularization parameter in the denominator $\\lambda_2-\\lambda_1$ to avoid division by zero; this ad hoc regularization is preferable to using the Jordan form limit.\n\nD. For depletion matrices dominated by decay-only chains, which are upper- or lower-triangular, the matrix exponential is trivial to evaluate and nearly equal decay constants do not introduce any numerical issues in practice.\n\nE. Matrix-level methods such as uniformization (randomization) for suitable generator-like matrices or scaling-and-squaring with Padé approximants avoid subtractive cancellation because they approximate $e^{A t}$ directly; moreover, as $\\lambda_1\\to \\lambda_2=\\lambda$, the off-diagonal of $e^{A t}$ converges to $t e^{-\\lambda t}$, a bounded quantity that is well-resolved in floating point arithmetic.",
            "solution": "The user has requested a validation of the problem statement, followed by a full solution and evaluation of the provided options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\nThe problem statement provides the following information:\n- A linear system of ordinary differential equations for two nuclide number densities, $N_1(t)$ and $N_2(t)$:\n$$\n\\frac{d}{dt}\n\\begin{pmatrix}\nN_1(t)\\\\\nN_2(t)\n\\end{pmatrix}\n=\nA\n\\begin{pmatrix}\nN_1(t)\\\\\nN_2(t)\n\\end{pmatrix}\n$$\n- The depletion matrix is given by:\n$$\nA=\n\\begin{pmatrix}\n-\\lambda_1 & 0\\\\\n\\lambda_1 & -\\lambda_2\n\\end{pmatrix}\n$$\n- $\\lambda_1$ and $\\lambda_2$ are the decay constants for nuclide $1$ and nuclide $2$, respectively.\n- An initial condition $\\begin{pmatrix}N_1(0)\\\\N_2(0)\\end{pmatrix}$ is prescribed.\n- The solution is given by the matrix exponential:\n$$\n\\begin{pmatrix}N_1(t)\\\\N_2(t)\\end{pmatrix}=e^{A t}\\begin{pmatrix}N_1(0)\\\\N_2(0)\\end{pmatrix}\n$$\n- A numerical context is specified: double-precision floating-point arithmetic (IEEE 754), with machine epsilon $\\epsilon_{\\mathrm{mach}}\\approx 2^{-53}\\approx 1.11\\times 10^{-16}$.\n- The core of the problem is to analyze the numerical behavior for the case where $\\lambda_1\\approx \\lambda_2$.\n- The analysis should be based on two foundational facts: (1) linear time-invariant systems are solved by $e^{A t}$, and (2) coalescing eigenvalues lead to polynomial factors (Jordan normal form).\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem describes the Bateman equations for a simple two-nuclide radioactive decay chain ($1 \\to 2 \\to \\text{stable}$), which is a fundamental model in nuclear physics and reactor engineering. The matrix formulation is standard. The numerical issues associated with nearly equal decay constants (or, more generally, nearly equal eigenvalues of the depletion matrix) are a well-documented and critical topic in computational reactor physics. The problem is scientifically and mathematically sound.\n- **Well-Posed:** The problem is a well-posed initial value problem for a linear system of ODEs. The question asks for an analysis of numerical methods for computing the solution, which is a standard and well-defined task in numerical analysis.\n- **Objective:** The problem is stated in precise, objective, and technical language. There are no subjective or opinion-based assertions.\n\n**Step 3: Verdict and Action**\nThe problem statement is scientifically sound, well-posed, and objective. It is a valid problem in numerical linear algebra applied to nuclear engineering. We may proceed to a full solution.\n\n### Derivation of the Solution\n\nThe solution to the system is $e^{At}\\mathbf{N}(0)$. We shall analyze the structure of $e^{At}$ by considering the eigenvalues of $A$. The matrix $A = \\begin{pmatrix} -\\lambda_1 & 0 \\\\ \\lambda_1 & -\\lambda_2 \\end{pmatrix}$ is lower triangular, so its eigenvalues are its diagonal entries, which are $s_1 = -\\lambda_1$ and $s_2 = -\\lambda_2$.\n\n**Case 1: Distinct Eigenvalues ($\\lambda_1 \\neq \\lambda_2$)**\nIf the eigenvalues are distinct, the matrix $A$ is diagonalizable. We can write $A = V \\Lambda V^{-1}$, where $\\Lambda$ is the diagonal matrix of eigenvalues and $V$ is the matrix of corresponding eigenvectors. The matrix exponential is then $e^{At} = V e^{\\Lambda t} V^{-1}$.\nThe eigenvectors are:\n- For $s_1 = -\\lambda_1$: an eigenvector is $v_1 = \\begin{pmatrix} \\lambda_2 - \\lambda_1 \\\\ \\lambda_1 \\end{pmatrix}$.\n- For $s_2 = -\\lambda_2$: an eigenvector is $v_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\n\nThe eigenvector matrix and its inverse are:\n$$\nV = \\begin{pmatrix} \\lambda_2 - \\lambda_1 & 0 \\\\ \\lambda_1 & 1 \\end{pmatrix}, \\quad V^{-1} = \\frac{1}{\\lambda_2 - \\lambda_1} \\begin{pmatrix} 1 & 0 \\\\ -\\lambda_1 & \\lambda_2 - \\lambda_1 \\end{pmatrix}\n$$\nThe matrix exponential is then:\n$$\ne^{At} = V e^{\\Lambda t} V^{-1} = \\begin{pmatrix} \\lambda_2 - \\lambda_1 & 0 \\\\ \\lambda_1 & 1 \\end{pmatrix} \\begin{pmatrix} e^{-\\lambda_1 t} & 0 \\\\ 0 & e^{-\\lambda_2 t} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\lambda_2 - \\lambda_1} & 0 \\\\ \\frac{-\\lambda_1}{\\lambda_2 - \\lambda_1} & 1 \\end{pmatrix}\n$$\nPerforming the matrix multiplication yields:\n$$\ne^{At} = \\begin{pmatrix} e^{-\\lambda_1 t} & 0 \\\\ \\lambda_1 \\frac{e^{-\\lambda_1 t} - e^{-\\lambda_2 t}}{\\lambda_2 - \\lambda_1} & e^{-\\lambda_2 t} \\end{pmatrix}\n$$\nThe off-diagonal term (element $(2,1)$) has the form of a divided difference. When $\\lambda_1 \\approx \\lambda_2$, let $\\lambda_2 = \\lambda_1 + \\delta$, where $|\\delta|$ is small. The numerator becomes $e^{-\\lambda_1 t} - e^{-(\\lambda_1 + \\delta)t} \\approx e^{-\\lambda_1 t} - e^{-\\lambda_1 t}(1-\\delta t) = \\delta t e^{-\\lambda_1 t}$. The term is approximately $\\frac{\\delta t e^{-\\lambda_1 t}}{\\delta} = t e^{-\\lambda_1 t}$. However, in floating-point arithmetic, the direct evaluation of $e^{-\\lambda_1 t} - e^{-\\lambda_2 t}$ involves the subtraction of two nearly equal numbers, which leads to a loss of relative precision known as catastrophic cancellation. The subsequent division by the small number $\\delta = \\lambda_2 - \\lambda_1$ magnifies this error.\n\n**Case 2: Coalescent Eigenvalues ($\\lambda_1 = \\lambda_2 = \\lambda$)**\nWhen $\\lambda_1 = \\lambda_2 = \\lambda$, the matrix becomes $A = \\begin{pmatrix} -\\lambda & 0 \\\\ \\lambda & -\\lambda \\end{pmatrix}$. The only eigenvalue is $s = -\\lambda$ with algebraic multiplicity $2$. The eigenspace is found by solving $(A - (-\\lambda)I)v = 0$, which is $\\begin{pmatrix} 0 & 0 \\\\ \\lambda & 0 \\end{pmatrix}v=0$. This implies the eigenvectors are of the form $\\begin{pmatrix} 0 \\\\ c \\end{pmatrix}$, a one-dimensional space. Since the geometric multiplicity ($1$) is less than the algebraic multiplicity ($2$), the matrix is not diagonalizable (it is defective).\n\nThe solution requires the Jordan normal form. We can write $A = S + N$ where $S = -\\lambda I$ is the diagonal part and $N = \\begin{pmatrix} 0 & 0 \\\\ \\lambda & 0 \\end{pmatrix}$ is the nilpotent part. Since $S$ is a multiple of the identity, it commutes with any matrix, so $SN=NS$. Therefore, $e^{At} = e^{(S+N)t} = e^{St}e^{Nt}$.\n- $e^{St} = e^{-\\lambda I t} = e^{-\\lambda t} I$.\n- $N^2 = \\begin{pmatrix} 0 & 0 \\\\ \\lambda & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ \\lambda & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}$. Since $N^2=0$, the series for $e^{Nt}$ truncates: $e^{Nt} = I + Nt = \\begin{pmatrix} 1 & 0 \\\\ \\lambda t & 1 \\end{pmatrix}$.\n\nCombining these results:\n$$\ne^{At} = (e^{-\\lambda t}I)(I+Nt) = \\begin{pmatrix} e^{-\\lambda t} & 0 \\\\ 0 & e^{-\\lambda t} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ \\lambda t & 1 \\end{pmatrix} = \\begin{pmatrix} e^{-\\lambda t} & 0 \\\\ \\lambda t e^{-\\lambda t} & e^{-\\lambda t} \\end{pmatrix}\n$$\nThe off-diagonal term is $\\lambda t e^{-\\lambda t}$. By L'Hôpital's rule on the expression from Case 1, we can verify this is the correct limit:\n$$\n\\lim_{\\lambda_2 \\to \\lambda_1} \\lambda_1 \\frac{e^{-\\lambda_1 t} - e^{-\\lambda_2 t}}{\\lambda_2 - \\lambda_1} = \\lambda_1 \\left. \\frac{d}{d\\lambda_2} (-e^{-\\lambda_2 t}) \\right|_{\\lambda_2=\\lambda_1} = \\lambda_1 ( -(-t)e^{-\\lambda_2 t} ) |_{\\lambda_2=\\lambda_1} = \\lambda_1 t e^{-\\lambda_1 t}\n$$\nThis confirms that the coalescent eigenvalue case introduces a polynomial factor of $t$, as stated in the problem.\n\n### Option-by-Option Analysis\n\n**A. When $\\lambda_1\\approx \\lambda_2$, the direct closed-form evaluation that separates solutions into sums of exponentials suffers from catastrophic cancellation in expressions like $e^{-\\lambda_1 t}-e^{-\\lambda_2 t}$ divided by $\\lambda_2-\\lambda_1$. Computing $e^{A t}$ via a scaling-and-squaring algorithm with Padé approximants yields the correct limiting behavior, including the $t e^{-\\lambda t}$ term that arises from a $2\\times 2$ Jordan block as the eigenvalues coalesce, thereby avoiding the cancellation.**\nThis statement is entirely correct.\n1. The analysis of catastrophic cancellation in the term $\\frac{e^{-\\lambda_1 t} - e^{-\\lambda_2 t}}{\\lambda_2 - \\lambda_1}$ is accurate, as demonstrated in the derivation above.\n2. Algorithms like scaling-and-squaring with Padé approximants compute approximations to $e^X$ using rational functions of the matrix $X$ itself (e.g., $e^X \\approx [p(X)]^{-1}q(X)$). These methods do not rely on eigendecomposition. Their accuracy depends on the norm of the matrix, not the separation of its eigenvalues.\n3. Because these methods approximate the exponential function through its analytic properties (e.g., its Taylor series, on which Padé approximants are based), they naturally and robustly handle matrices that are close to defective. The polynomial terms associated with Jordan blocks emerge correctly from the matrix polynomial/rational evaluation. They directly approximate $e^{At}$ without ever computing eigen-related differences, thus avoiding the source of cancellation.\n**Verdict: Correct**\n\n**B. Diagonalizing $A$ as $A=V\\Lambda V^{-1}$ and evaluating $e^{A t}=V e^{\\Lambda t} V^{-1}$ is always numerically stable when $\\lambda_1\\approx \\lambda_2$, because the eigenvector matrix $V$ is necessarily close to unitary in that regime.**\nThis statement is incorrect. It makes a claim that is the opposite of the truth.\n1. As $\\lambda_1 \\to \\lambda_2$, the matrix $A$ approaches a defective matrix. A defining characteristic of such a situation is that the basis of eigenvectors becomes ill-conditioned.\n2. In our case, the eigenvectors $v_1 = \\begin{pmatrix} \\lambda_2 - \\lambda_1 \\\\ \\lambda_1 \\end{pmatrix}$ and $v_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$ become nearly collinear as $\\lambda_2 - \\lambda_1 \\to 0$. The angle between them approaches zero.\n3. The condition number of the eigenvector matrix $V$ is $\\kappa(V) = \\|V\\|\\|V^{-1}\\|$. From our derivation, $V^{-1}$ contains terms proportional to $1/(\\lambda_2-\\lambda_1)$, which diverge as $\\lambda_1 \\to \\lambda_2$. Thus, $\\kappa(V) \\to \\infty$.\n4. An ill-conditioned eigenvector matrix is the primary cause of numerical instability in eigendecomposition-based methods. The claim that $V$ is \"close to unitary\" is false; a unitary matrix is perfectly conditioned with $\\kappa(V)=1$.\n**Verdict: Incorrect**\n\n**C. If $\\lambda_1=\\lambda_2$, the same closed-form expression used for distinct decay constants can be retained by adding a small regularization parameter in the denominator $\\lambda_2-\\lambda_1$ to avoid division by zero; this ad hoc regularization is preferable to using the Jordan form limit.**\nThis statement is incorrect.\n1. The expression for distinct constants gives a $\\frac{0}{0}$ form when $\\lambda_1=\\lambda_2$.\n2. If one literally adds a parameter $\\epsilon$ to the denominator, $(\\lambda_2-\\lambda_1)+\\epsilon$, while the numerator is strictly zero (because $\\lambda_1=\\lambda_2$), the result is zero. This is incorrect; the correct limit is $\\lambda t e^{-\\lambda t}$.\n3. If one perturbs an eigenvalue, e.g., setting $\\lambda_2 = \\lambda_1 + \\delta$, one re-introduces the very problem of catastrophic cancellation that robust algorithms seek to avoid. This is not a solution but a restatement of the problem.\n4. The correct approach for nearly equal eigenvalues is to switch to a specialized, stable formula, such as one based on a Taylor expansion of the exponential function, or to evaluate the limit `(the Jordan form case)` directly. This is numerically superior to ad hoc regularization, not the other way around. The claim that an ad hoc fix is \"preferable\" to the mathematically correct and numerically stable limit is false.\n**Verdict: Incorrect**\n\n**D. For depletion matrices dominated by decay-only chains, which are upper- or lower-triangular, the matrix exponential is trivial to evaluate and nearly equal decay constants do not introduce any numerical issues in practice.**\nThis statement is incorrect.\n1. The very matrix $A$ given in the problem is a lower-triangular matrix from a decay-only chain.\n2. As our entire analysis has shown, this matrix is the canonical example of a case where nearly equal decay constants (i.e., eigenvalues) *do* introduce severe numerical issues in the form of catastrophic cancellation if the wrong evaluation method is used.\n3. While algorithms exist to compute the exponential of a triangular matrix, they are not \"trivial,\" and care must be taken to handle the off-diagonal elements correctly, especially in the presence of nearly equal diagonal elements. The statement that no issues arise is factually wrong.\n**Verdict: Incorrect**\n\n**E. Matrix-level methods such as uniformization (randomization) for suitable generator-like matrices or scaling-and-squaring with Padé approximants avoid subtractive cancellation because they approximate $e^{A t}$ directly; moreover, as $\\lambda_1\\to \\lambda_2=\\lambda$, the off-diagonal of $e^{A t}$ converges to $t e^{-\\lambda t}$, a bounded quantity that is well-resolved in floating point arithmetic.**\nThis statement is correct. It is a comprehensive and accurate summary of the situation.\n1. It correctly identifies that matrix-level methods (like Padé approximants, mentioned in A, and uniformization, another robust method) operate on the matrix $A$ directly as an algebraic object, rather than on its individual eigenvalues and eigenvectors. This is precisely why they avoid the instabilities associated with eigendecomposition when eigenvectors are ill-conditioned.\n2. It correctly states the limit of the off-diagonal element of $e^{At}$ as $\\lambda t e^{-\\lambda t}$. (Here \"off-diagonal\" refers to the non-zero $(2,1)$ element).\n3. It correctly characterizes this limiting quantity as \"bounded\" and \"well-resolved in floating point arithmetic\". This is key: the target value itself is benign. The numerical problem lies entirely within the naive computational path (the closed-form expression), not the result itself. Robust methods provide a stable path to this benign result.\n**Verdict: Correct**\n\nBoth statements A and E are correct. They provide complementary and accurate descriptions of the numerical problem and its solution.",
            "answer": "$$\\boxed{AE}$$"
        },
        {
            "introduction": "Our previous practices assumed a constant depletion matrix $A$ over the time step  . In realistic, coupled reactor simulations, however, reaction rates evolve as flux, temperature, and material compositions change, making the operator a function of time, $A(t)$. This exercise tackles this advanced scenario by introducing a step-doubling technique to estimate and control the error from approximating $A(t)$ as constant over a short interval, which is a key step toward building robust, adaptive solvers for dynamic, multi-physics problems.",
            "id": "4234758",
            "problem": "You are given a linear time-dependent nuclide depletion model formulated as an ordinary differential equation (ODE) for the vector of nuclide number densities. The model is\n$$\n\\frac{d\\mathbf{N}(t)}{dt} = \\mathbf{A}(t)\\,\\mathbf{N}(t),\n$$\nwhere $\\mathbf{N}(t) \\in \\mathbb{R}^3$ is the vector of nuclide number densities with components expressed in atoms per cubic centimeter (atoms/cm$^3$), and $\\mathbf{A}(t) \\in \\mathbb{R}^{3\\times 3}$ is the depletion operator with entries expressed in inverse seconds ($\\mathrm{s}^{-1}$). The operator varies linearly in time within each step, i.e.,\n$$\n\\mathbf{A}(t) = \\mathbf{A}_0 + (t - t_n)\\,\\mathbf{B},\n$$\nwhere $t_n$ is the step start time, $\\mathbf{A}_0 = \\mathbf{A}(t_n)$, and $\\mathbf{B} = \\frac{d\\mathbf{A}}{dt}\\bigg|_{t=t_n}$ is constant over the step.\n\nYou must implement a step-doubling procedure to estimate the local error introduced by freezing the operator over a time step. Consider a single step of size $\\Delta t$ starting at $t_n$, and define two propagations:\n\n1. A single full step with the operator frozen at the start of the step, producing $\\mathbf{N}_{\\mathrm{full}}$.\n2. Two half steps, where the first half uses the operator at $t_n$ and the second half updates the operator to the midpoint $t_n + \\tfrac{\\Delta t}{2}$, producing $\\mathbf{N}_{\\mathrm{half\\_2}}$.\n\nDefine the local error estimate as the componentwise difference $\\mathbf{e} = \\mathbf{N}_{\\mathrm{half\\_2}} - \\mathbf{N}_{\\mathrm{full}}$. Use a weighted infinity norm to produce a dimensionless scalar error measure,\n$$\n\\eta = \\max_i \\frac{|e_i|}{\\mathrm{atol} + \\mathrm{rtol}\\,|\\left(\\mathbf{N}_{\\mathrm{half\\_2}}\\right)_i|},\n$$\nwhere $\\mathrm{atol}$ is an absolute tolerance (atoms/cm$^3$) and $\\mathrm{rtol}$ is a relative tolerance (dimensionless). Accept the step if and only if $\\eta \\le 1$. Recommend a new step size\n$$\n\\Delta t_{\\mathrm{new}} = \\Delta t \\times \\operatorname{clip}\\left(s\\,\\eta^{-\\frac{1}{p+1}}, f_{\\min}, f_{\\max}\\right),\n$$\nwhere $p$ is the method order, $s$ is a safety factor, $f_{\\min}$ is a minimum growth/shrink factor, and $f_{\\max}$ is a maximum growth/shrink factor. In this problem take $p=1$, $s=0.9$, $f_{\\min}=0.2$, and $f_{\\max}=5.0$. Express the recommended next step size in seconds.\n\nThe test suite is defined by four cases. For all cases, take the initial time as $t_n = 0$, and the initial number densities as\n$$\n\\mathbf{N}_0 = \\begin{bmatrix} 3.0\\times 10^{20} \\\\ 0.0 \\\\ 0.0 \\end{bmatrix}\\ \\text{atoms/cm}^3.\n$$\nDefine a simple transmutation/decay chain with three nuclides such that the operator has the structure\n$$\n\\mathbf{A}(t) = \\begin{bmatrix}\n-(\\lambda_{12} + r_1(t)) & 0 & 0 \\\\\n\\lambda_{12} + r_1(t) & -(\\lambda_{23} + r_2(t)) & 0 \\\\\n0 & \\lambda_{23} + r_2(t) & 0\n\\end{bmatrix},\n$$\nwith\n$$\nr_1(t) = r_{10} + \\beta_1 t,\\quad r_2(t) = r_{20} + \\beta_2 t,\n$$\nwhere $\\lambda_{12}$ and $\\lambda_{23}$ are decay rates (in $\\mathrm{s}^{-1}$), $r_{10}$ and $r_{20}$ are initial reaction rates (in $\\mathrm{s}^{-1}$), and $\\beta_1$ and $\\beta_2$ are their time derivatives (in $\\mathrm{s}^{-2}$). Then\n$$\n\\mathbf{A}_0 = \\mathbf{A}(t_n) = \\mathbf{A}(0),\\quad \\mathbf{B} = \\frac{d\\mathbf{A}}{dt}\\bigg|_{t=0} = \\begin{bmatrix}\n-\\beta_1 & 0 & 0 \\\\\n\\beta_1 & -\\beta_2 & 0 \\\\\n0 & \\beta_2 & 0\n\\end{bmatrix}.\n$$\n\nUse the following numerical values in each case:\n\n- Case $1$ (mild operator variation, happy path):\n  - $\\Delta t = 3600.0$ seconds,\n  - $\\lambda_{12} = 1.0\\times 10^{-6}\\ \\mathrm{s}^{-1}$,\n  - $\\lambda_{23} = 2.0\\times 10^{-6}\\ \\mathrm{s}^{-1}$,\n  - $r_{10} = 5.0\\times 10^{-8}\\ \\mathrm{s}^{-1}$,\n  - $r_{20} = 1.0\\times 10^{-8}\\ \\mathrm{s}^{-1}$,\n  - $\\beta_1 = 1.0\\times 10^{-12}\\ \\mathrm{s}^{-2}$,\n  - $\\beta_2 = 5.0\\times 10^{-13}\\ \\mathrm{s}^{-2}$,\n  - $\\mathrm{rtol} = 1.0\\times 10^{-8}$,\n  - $\\mathrm{atol} = 1.0\\times 10^{10}$ atoms/cm$^3$.\n\n- Case $2$ (strong operator variation, likely rejection):\n  - $\\Delta t = 3600.0$ seconds,\n  - $\\lambda_{12} = 1.0\\times 10^{-6}\\ \\mathrm{s}^{-1}$,\n  - $\\lambda_{23} = 2.0\\times 10^{-6}\\ \\mathrm{s}^{-1}$,\n  - $r_{10} = 5.0\\times 10^{-8}\\ \\mathrm{s}^{-1}$,\n  - $r_{20} = 1.0\\times 10^{-8}\\ \\mathrm{s}^{-1}$,\n  - $\\beta_1 = 1.0\\times 10^{-10}\\ \\mathrm{s}^{-2}$,\n  - $\\beta_2 = 5.0\\times 10^{-11}\\ \\mathrm{s}^{-2}$,\n  - $\\mathrm{rtol} = 1.0\\times 10^{-8}$,\n  - $\\mathrm{atol} = 1.0\\times 10^{10}$ atoms/cm$^3$.\n\n- Case $3$ (boundary-like scenario):\n  - $\\Delta t = 7200.0$ seconds,\n  - $\\lambda_{12} = 1.0\\times 10^{-6}\\ \\mathrm{s}^{-1}$,\n  - $\\lambda_{23} = 2.0\\times 10^{-6}\\ \\mathrm{s}^{-1}$,\n  - $r_{10} = 3.0\\times 10^{-8}\\ \\mathrm{s}^{-1}$,\n  - $r_{20} = 0.5\\times 10^{-8}\\ \\mathrm{s}^{-1}$,\n  - $\\beta_1 = 5.0\\times 10^{-12}\\ \\mathrm{s}^{-2}$,\n  - $\\beta_2 = 2.5\\times 10^{-12}\\ \\mathrm{s}^{-2}$,\n  - $\\mathrm{rtol} = 1.0\\times 10^{-8}$,\n  - $\\mathrm{atol} = 1.0\\times 10^{10}$ atoms/cm$^3$.\n\n- Case $4$ (no operator variation, edge case):\n  - $\\Delta t = 3600.0$ seconds,\n  - $\\lambda_{12} = 1.0\\times 10^{-6}\\ \\mathrm{s}^{-1}$,\n  - $\\lambda_{23} = 2.0\\times 10^{-6}\\ \\mathrm{s}^{-1}$,\n  - $r_{10} = 5.0\\times 10^{-8}\\ \\mathrm{s}^{-1}$,\n  - $r_{20} = 1.0\\times 10^{-8}\\ \\mathrm{s}^{-1}$,\n  - $\\beta_1 = 0.0\\ \\mathrm{s}^{-2}$,\n  - $\\beta_2 = 0.0\\ \\mathrm{s}^{-2}$,\n  - $\\mathrm{rtol} = 1.0\\times 10^{-8}$,\n  - $\\mathrm{atol} = 1.0\\times 10^{10}$ atoms/cm$^3$.\n\nYour program must, for each case, construct $\\mathbf{A}_0$ and $\\mathbf{B}$, perform the one full step and the two half steps as described, compute the error measure $\\eta$, decide step acceptance, and compute the recommended next step size $\\Delta t_{\\mathrm{new}}$ in seconds. The final output for each case must be a list\n$$\n[\\text{accept},\\ \\Delta t_{\\mathrm{new}},\\ \\eta],\n$$\nwhere $\\text{accept}$ is a boolean indicating whether the step is accepted, $\\Delta t_{\\mathrm{new}}$ is a floating-point number in seconds, and $\\eta$ is a floating-point number. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$). Angles are not involved in this problem. There are no percentages involved; all quantities are to be expressed as booleans or floating-point numbers as specified. All time-related quantities must be in seconds, and all density-related quantities must be in atoms/cm$^3$.",
            "solution": "The problem requires the implementation of an adaptive time-stepping algorithm based on a step-doubling error estimation procedure for a system of linear ordinary differential equations (ODEs) that models nuclide depletion. The core of the solution involves comparing a less accurate numerical propagation with a more accurate one to estimate the local error and adjust the step size accordingly.\n\nThe governing physical model is the nuclide depletion equation:\n$$\n\\frac{d\\mathbf{N}(t)}{dt} = \\mathbf{A}(t)\\,\\mathbf{N}(t)\n$$\nwhere $\\mathbf{N}(t)$ is the vector of nuclide number densities and $\\mathbf{A}(t)$ is the time-dependent depletion operator matrix. For this problem, the operator's time dependence is assumed to be linear within a single time step $[t_n, t_n + \\Delta t]$:\n$$\n\\mathbf{A}(t) = \\mathbf{A}(t_n) + (t - t_n)\\,\\mathbf{B} = \\mathbf{A}_0 + (t - t_n)\\,\\mathbf{B}\n$$\nwhere $\\mathbf{A}_0$ is the operator at the beginning of the step and $\\mathbf{B}$ is its constant time derivative over that step.\n\nThe fundamental numerical method used for propagation is based on approximating the operator $\\mathbf{A}(t)$ as constant over a given interval. The solution to the constant-coefficient ODE $\\frac{d\\mathbf{N}}{dt} = \\mathbf{A}_{\\text{const}}\\mathbf{N}$ is $\\mathbf{N}(t_n+h) = e^{\\mathbf{A}_{\\text{const}}h}\\mathbf{N}(t_n)$, where $e^{(\\cdot)}$ denotes the matrix exponential. This problem uses a predictor-corrector-style approach to estimate the error introduced by this constant-coefficient approximation.\n\nThe error estimation is performed via a step-doubling (or embedded Runge-Kutta-like) procedure. Two different numerical solutions for the state at time $t_n + \\Delta t$ are computed:\n1.  **Full Step Solution ($\\mathbf{N}_{\\mathrm{full}}$)**: A single propagation over the full step duration $\\Delta t$ is performed, using the operator frozen at the start time $t_n$. This serves as the lower-order, less accurate solution.\n    $$\n    \\mathbf{N}_{\\mathrm{full}} = e^{\\mathbf{A}_0 \\Delta t} \\mathbf{N}(t_n)\n    $$\n2.  **Two Half-Steps Solution ($\\mathbf{N}_{\\mathrm{half\\_2}}$)**: The propagation is split into two steps of size $\\frac{\\Delta t}{2}$. The operator is re-evaluated at the midpoint, providing a more accurate representation of its time dependence. This serves as the higher-order, more accurate \"reference\" solution.\n    -   The first half-step propagates the solution from $t_n$ to $t_n + \\frac{\\Delta t}{2}$ using the operator at the start, $\\mathbf{A}_0 = \\mathbf{A}(t_n)$:\n        $$\n        \\mathbf{N}_{\\mathrm{half\\_1}} = e^{\\mathbf{A}_0 \\frac{\\Delta t}{2}} \\mathbf{N}(t_n)\n        $$\n    -   The second half-step propagates from $t_n + \\frac{\\Delta t}{2}$ to $t_n + \\Delta t$. For this step, the operator is updated to its value at the midpoint, $\\mathbf{A}_{\\mathrm{mid}} = \\mathbf{A}(t_n + \\frac{\\Delta t}{2}) = \\mathbf{A}_0 + \\mathbf{B}\\frac{\\Delta t}{2}$:\n        $$\n        \\mathbf{N}_{\\mathrm{half\\_2}} = e^{\\mathbf{A}_{\\mathrm{mid}} \\frac{\\Delta t}{2}} \\mathbf{N}_{\\mathrm{half\\_1}} = e^{(\\mathbf{A}_0 + \\frac{\\Delta t}{2}\\mathbf{B})\\frac{\\Delta t}{2}} e^{\\mathbf{A}_0 \\frac{\\Delta t}{2}} \\mathbf{N}(t_n)\n        $$\n\nThe difference between these two solutions, $\\mathbf{e} = \\mathbf{N}_{\\mathrm{half\\_2}} - \\mathbf{N}_{\\mathrm{full}}$, provides an estimate of the local error of the less accurate full-step method. To obtain a single dimensionless scalar error measure $\\eta$, a weighted infinity norm is used:\n$$\n\\eta = \\max_i \\frac{|e_i|}{\\mathrm{atol} + \\mathrm{rtol}\\,|\\left(\\mathbf{N}_{\\mathrm{half\\_2}}\\right)_i|}\n$$\nwhere $\\mathrm{atol}$ and $\\mathrm{rtol}$ are user-defined absolute and relative tolerances, respectively. The step is deemed acceptable if this normalized error is less than or equal to $1$, i.e., $\\eta \\le 1$.\n\nBased on the value of $\\eta$, a new step size for the next integration step is recommended using the standard formula for adaptive step size control:\n$$\n\\Delta t_{\\mathrm{new}} = \\Delta t \\times \\operatorname{clip}\\left(s\\,\\eta^{-\\frac{1}{p+1}}, f_{\\min}, f_{\\max}\\right)\n$$\nThe parameters are given as the safety factor $s=0.9$, the minimum and maximum step size change factors $f_{\\min}=0.2$ and $f_{\\max}=5.0$, and the method order $p=1$. The order $p=1$ is appropriate because the underlying full-step method is a first-order approximation (analogous to Forward Euler in its treatment of the operator's time dependence).\n\nThe implementation proceeds by first constructing the matrices $\\mathbf{A}_0$ and $\\mathbf{B}$ for each test case from the provided parameters $\\lambda_{12}, \\lambda_{23}, r_{10}, r_{20}, \\beta_1, \\beta_2$. The initial density vector $\\mathbf{N}_0$ is constant for all cases. The matrix exponential operations are performed using the `scipy.linalg.expm` function. The two propagation paths are calculated, followed by the computation of the error vector $\\mathbf{e}$ and the scalar measure $\\eta$. A special check is included for the case where $\\eta$ is numerically zero (as in Case 4 where $\\mathbf{B}=\\mathbf{0}$), in which case the step size growth is limited by $f_{\\max}$ to prevent division by zero and ensure a maximal, but bounded, step increase. Finally, the acceptance boolean, the new step size $\\Delta t_{\\mathrm{new}}$, and the error measure $\\eta$ are compiled for each case and formatted into the required output structure.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the test cases and printing of results.\n    \"\"\"\n\n    def _calculate_step_result(params):\n        \"\"\"\n        Performs the step-doubling error estimation for a single case.\n\n        Args:\n            params (tuple): A tuple containing the parameters for a single test case.\n\n        Returns:\n            list: A list containing [accept, dt_new, eta].\n        \"\"\"\n        dt, lambda12, lambda23, r10, r20, beta1, beta2, rtol, atol = params\n        \n        # Fixed parameters from problem statement\n        N0 = np.array([3.0e20, 0.0, 0.0])\n        p = 1.0      # Method order\n        s = 0.9      # Safety factor\n        f_min = 0.2  # Minimum growth/shrink factor\n        f_max = 5.0  # Maximum growth/shrink factor\n\n        # Construct the operator matrix at t=t_n=0 (A0) and its time derivative (B)\n        A0 = np.array([\n            [-(lambda12 + r10), 0, 0],\n            [  lambda12 + r10, -(lambda23 + r20), 0],\n            [  0,               lambda23 + r20,  0]\n        ])\n        \n        B = np.array([\n            [-beta1,    0, 0],\n            [ beta1, -beta2, 0],\n            [     0,  beta2, 0]\n        ])\n\n        # 1. Full step propagation: Propagate from t_n to t_n + dt using A0\n        M_full = A0 * dt\n        N_full = expm(M_full) @ N0\n\n        # 2. Two half-steps propagation\n        dt_half = dt / 2.0\n        \n        # First half-step: Propagate from t_n to t_n + dt/2 using A0\n        M_half1 = A0 * dt_half\n        N_half_1 = expm(M_half1) @ N0\n\n        # Second half-step: Propagate from t_n + dt/2 to t_n + dt using A(t_n + dt/2)\n        A_mid = A0 + B * dt_half\n        M_half2 = A_mid * dt_half\n        N_half_2 = expm(M_half2) @ N_half_1\n\n        # 3. Compute the scalar error measure, eta\n        error_vec = N_half_2 - N_full\n        \n        # Denominator for the weighted norm: atol + rtol * |(N_half_2)_i|\n        tolerance_vec = atol + rtol * np.abs(N_half_2)\n\n        # Calculate eta = max_i (|e_i| / tolerance_i)\n        # Add a small float to the denominator for numerical stability, though atol > 0 should suffice.\n        eta_vec = np.abs(error_vec) / (tolerance_vec + np.finfo(float).tiny)\n        eta = np.max(eta_vec)\n\n        # 4. Decide step acceptance and recommend new step size\n        accept = eta <= 1.0\n        \n        # Handle the case where eta is zero or very close to it to avoid division by zero\n        # and to correctly apply the maximum step size growth factor. A small\n        # floating point tolerance is appropriate.\n        if eta < 1e-15:\n            factor = f_max\n        else:\n            # The method order p is 1. The formula is s * eta**(-1/(p+1)).\n            factor = s * (eta ** (-1.0 / (p + 1.0)))\n            factor = np.clip(factor, f_min, f_max)\n        \n        dt_new = dt * factor\n        \n        # Return a standard Python bool for consistent string formatting\n        return [bool(accept), dt_new, eta]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (mild operator variation, happy path)\n        (3600.0, 1.0e-6, 2.0e-6, 5.0e-8, 1.0e-8, 1.0e-12, 5.0e-13, 1.0e-8, 1.0e10),\n        # Case 2 (strong operator variation, likely rejection)\n        (3600.0, 1.0e-6, 2.0e-6, 5.0e-8, 1.0e-8, 1.0e-10, 5.0e-11, 1.0e-8, 1.0e10),\n        # Case 3 (boundary-like scenario)\n        (7200.0, 1.0e-6, 2.0e-6, 3.0e-8, 0.5e-8, 5.0e-12, 2.5e-12, 1.0e-8, 1.0e10),\n        # Case 4 (no operator variation, edge case)\n        (3600.0, 1.0e-6, 2.0e-6, 5.0e-8, 1.0e-8, 0.0, 0.0, 1.0e-8, 1.0e10),\n    ]\n\n    results = []\n    for case_params in test_cases:\n        result = _calculate_step_result(case_params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The str() representation of a list in Python is '[item1, item2, ...]',\n    # which preserves the required spaces and boolean capitalization.\n    # The overall format will be [[res1], [res2], ...].\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}