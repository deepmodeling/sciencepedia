{
    "hands_on_practices": [
        {
            "introduction": "To map soil properties, we must first transform raw spectral reflectance data into meaningful physical indicators. A crucial first step is to isolate specific absorption features from general variations in soil brightness, or albedo. This practice  guides you through the fundamental technique of continuum removal to calculate the band depth, a robust measure of absorption strength that is directly linked to the concentration of materials like clay minerals.",
            "id": "3848675",
            "problem": "You are given discrete soil reflectance spectra sampled at wavelength positions and a set of upper convex hull vertices for each spectrum. The objective is to derive the convex hull continuum at a target wavelength and compute the absorption band depth at that wavelength for each case. Your program must implement the following tasks for each test case.\n\nFoundational base and definitions:\n- Let $R(\\lambda)$ denote the bidirectional reflectance factor (dimensionless) of a soil surface measured at wavelength $\\lambda$ in micrometers ($\\mu\\text{m}$). Absorption features manifest as local depressions in $R(\\lambda)$ relative to a smooth, slowly varying baseline called the continuum.\n- The continuum in spectral analysis is defined as the upper boundary of the convex hull of the set of points $\\{(\\lambda_i, R(\\lambda_i))\\}$ in the $\\lambda$-$R$ plane. The convex hull is the smallest convex set that contains all points; its upper boundary is a piecewise-linear concave envelope formed by connecting selected hull vertices $\\{(\\lambda_{h,j}, R_{h,j})\\}$ with straight line segments.\n- For a target wavelength $\\lambda^\\star$, the continuum $C(\\lambda^\\star)$ is obtained by linear interpolation along the hull segment that brackets $\\lambda^\\star$. If $\\lambda^\\star$ coincides with a hull vertex, then $C(\\lambda^\\star) = R_{h,j}$ at that vertex.\n- Band depth at $\\lambda^\\star$ is defined as the continuum-removed absorption measure\n$$\nBD(\\lambda^\\star) = 1 - \\frac{R(\\lambda^\\star)}{C(\\lambda^\\star)} ,\n$$\nexpressed as a unitless decimal fraction.\n\nAlgorithmic requirements for each test case:\n1. Inputs:\n   - A strictly increasing list of wavelengths $\\Lambda = [\\lambda_1, \\lambda_2, \\dots, \\lambda_n]$ in micrometers ($\\mu\\text{m}$).\n   - A list of reflectances $\\mathcal{R} = [R(\\lambda_1), R(\\lambda_2), \\dots, R(\\lambda_n)]$, each a dimensionless number in $[0,1]$.\n   - A list of hull vertices $\\mathcal{H} = [(\\lambda_{h,1}, R_{h,1}), (\\lambda_{h,2}, R_{h,2}), \\dots, (\\lambda_{h,m}, R_{h,m})]$ sorted by increasing $\\lambda_{h,j}$, which define the upper convex hull continuum by straight line segments between consecutive hull vertices.\n   - A target wavelength $\\lambda^\\star = 2.20\\,\\mu\\text{m}$.\n2. Compute $R(\\lambda^\\star)$:\n   - If $\\lambda^\\star$ is exactly one of the $\\lambda_i$, set $R(\\lambda^\\star)$ to the corresponding reflectance value.\n   - Otherwise, find indices $i$ and $i+1$ such that $\\lambda_i \\le \\lambda^\\star \\le \\lambda_{i+1}$ and linearly interpolate\n   $$\n   R(\\lambda^\\star) = R(\\lambda_i) + \\left( \\frac{\\lambda^\\star - \\lambda_i}{\\lambda_{i+1} - \\lambda_i} \\right) \\left( R(\\lambda_{i+1}) - R(\\lambda_i) \\right) .\n   $$\n3. Compute $C(\\lambda^\\star)$:\n   - If $\\lambda^\\star$ is exactly one of the $\\lambda_{h,j}$, set $C(\\lambda^\\star) = R_{h,j}$.\n   - Otherwise, find consecutive hull vertices $(\\lambda_{h,j}, R_{h,j})$ and $(\\lambda_{h,j+1}, R_{h,j+1})$ such that $\\lambda_{h,j} \\le \\lambda^\\star \\le \\lambda_{h,j+1}$ and linearly interpolate\n   $$\n   C(\\lambda^\\star) = R_{h,j} + \\left( \\frac{\\lambda^\\star - \\lambda_{h,j}}{\\lambda_{h,j+1} - \\lambda_{h,j}} \\right) \\left( R_{h,j+1} - R_{h,j} \\right) .\n   $$\n4. Compute $BD(\\lambda^\\star)$ using the formula above. The output must be expressed as a decimal fraction (no percentage sign), dimensionless.\n\nScientific realism and applicability: The band depth at $\\lambda^\\star = 2.20\\,\\mu\\text{m}$ is commonly used to quantify the $Al$-$OH$ absorption feature that relates to clay content in soils. The convex hull continuum stabilizes this measurement against broad-scale albedo variations. The procedure is purely geometric and numerical, based on interpolation and convexity.\n\nTest suite:\n- First case (general absorption feature with explicit $\\lambda^\\star$ sample):\n  - $\\Lambda = [2.00, 2.10, 2.15, 2.20, 2.25, 2.30, 2.40]$ in $\\mu\\text{m}$.\n  - $\\mathcal{R} = [0.52, 0.50, 0.48, 0.35, 0.47, 0.52, 0.55]$.\n  - $\\mathcal{H} = [(2.00, 0.52), (2.40, 0.55)]$.\n- Second case (boundary where $\\lambda^\\star$ coincides with a hull vertex, producing zero band depth):\n  - $\\Lambda = [2.18, 2.20, 2.22, 2.24]$ in $\\mu\\text{m}$.\n  - $\\mathcal{R} = [0.49, 0.52, 0.51, 0.50]$.\n  - $\\mathcal{H} = [(2.18, 0.49), (2.20, 0.52), (2.24, 0.50)]$.\n- Third case (minimal spectrum with three samples and endpoints as hull vertices):\n  - $\\Lambda = [2.10, 2.20, 2.30]$ in $\\mu\\text{m}$.\n  - $\\mathcal{R} = [0.60, 0.40, 0.62]$.\n  - $\\mathcal{H} = [(2.10, 0.60), (2.30, 0.62)]$.\n- Fourth case (target not sampled; $R(\\lambda^\\star)$ must be interpolated from neighbors):\n  - $\\Lambda = [2.17, 2.19, 2.21, 2.23, 2.26, 2.30]$ in $\\mu\\text{m}$.\n  - $\\mathcal{R} = [0.53, 0.51, 0.46, 0.49, 0.52, 0.54]$.\n  - $\\mathcal{H} = [(2.17, 0.53), (2.30, 0.54)]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the band depths for the four test cases as a comma-separated list enclosed in square brackets, for example $[b_1,b_2,b_3,b_4]$, where each $b_k$ is a float computed as specified above. Wavelengths must be treated in $\\mu\\text{m}$, and the band depths must be returned as unitless decimal fractions.",
            "solution": "The problem as stated is valid. It is scientifically grounded in the principles of quantitative spectroscopy, well-posed with a clear and complete set of definitions and data, and objective in its formulation. No contradictions, ambiguities, or factual errors were found. The problem can be solved by direct application of the provided algorithms.\n\nThe central task is to compute the absorption band depth, denoted as $BD(\\lambda^\\star)$, at a specified target wavelength, $\\lambda^\\star$, for several soil reflectance spectra. The band depth is a standard measure in spectroscopy for quantifying the strength of an absorption feature. It is defined as a continuum-removed quantity, which normalizes the reflectance spectrum with respect to a continuum baseline, $C(\\lambda)$.\n\nThe formula for band depth is given as:\n$$\nBD(\\lambda^\\star) = 1 - \\frac{R(\\lambda^\\star)}{C(\\lambda^\\star)}\n$$\nwhere $R(\\lambda^\\star)$ is the reflectance value at the target wavelength $\\lambda^\\star$, and $C(\\lambda^\\star)$ is the value of the spectral continuum at the same wavelength. The computation thus involves determining these two values for each test case.\n\n**1. Determination of Reflectance $R(\\lambda^\\star)$**\n\nThe reflectance spectrum is provided as a discrete set of measurements, $(\\lambda_i, R(\\lambda_i))$, where $\\Lambda = [\\lambda_1, \\lambda_2, \\dots, \\lambda_n]$ is a strictly increasing list of wavelengths. The target wavelength is specified as $\\lambda^\\star = 2.20 \\, \\mu\\text{m}$.\n\nThe value of $R(\\lambda^\\star)$ is obtained as follows:\n- **Case A: Exact Match:** If the target wavelength $\\lambda^\\star$ coincides exactly with one of the sampled wavelengths $\\lambda_i$ in the list $\\Lambda$, then $R(\\lambda^\\star)$ is simply the corresponding measured reflectance value, $R(\\lambda_i)$.\n- **Case B: Interpolation:** If $\\lambda^\\star$ falls between two sampled wavelengths, $\\lambda_i < \\lambda^\\star < \\lambda_{i+1}$, its reflectance $R(\\lambda^\\star)$ is estimated via linear interpolation between the two adjacent points $(\\lambda_i, R(\\lambda_i))$ and $(\\lambda_{i+1}, R(\\lambda_{i+1}))$. The formula for linear interpolation is:\n$$\nR(\\lambda^\\star) = R(\\lambda_i) + \\left( \\frac{\\lambda^\\star - \\lambda_i}{\\lambda_{i+1} - \\lambda_i} \\right) \\left( R(\\lambda_{i+1}) - R(\\lambda_i) \\right)\n$$\nThis assumes a locally linear behavior of the spectrum between sample points, a standard practice for high-resolution spectral data.\n\n**2. Determination of Continuum $C(\\lambda^\\star)$**\n\nThe continuum, $C(\\lambda)$, is defined as the upper envelope of the spectrum, constructed from a given set of upper convex hull vertices $\\mathcal{H} = [(\\lambda_{h,1}, R_{h,1}), \\dots, (\\lambda_{h,m}, R_{h,m})]$. This envelope is a piecewise linear function connecting consecutive vertices.\n\nThe value of $C(\\lambda^\\star)$ is determined similarly to $R(\\lambda^\\star)$, but using the hull vertices instead of the full spectral data:\n- **Case A: Exact Match:** If the target wavelength $\\lambda^\\star$ coincides with the wavelength of a hull vertex, $\\lambda^\\star = \\lambda_{h,j}$, then the continuum value is the reflectance of that vertex, $C(\\lambda^\\star) = R_{h,j}$.\n- **Case B: Interpolation:** If $\\lambda^\\star$ falls between two consecutive hull vertices, $\\lambda_{h,j} < \\lambda^\\star < \\lambda_{h,j+1}$, the continuum value $C(\\lambda^\\star)$ is found by linear interpolation along the line segment connecting these two vertices, $(\\lambda_{h,j}, R_{h,j})$ and $(\\lambda_{h,j+1}, R_{h,j+1})$:\n$$\nC(\\lambda^\\star) = R_{h,j} + \\left( \\frac{\\lambda^\\star - \\lambda_{h,j}}{\\lambda_{h,j+1} - \\lambda_{h,j}} \\right) \\left( R_{h,j+1} - R_{h,j} \\right)\n$$\nThis procedure provides the value of the smooth upper-boundary reference against which the absorption is measured.\n\n**3. Algorithmic Implementation**\n\nFor each test case, the overall algorithm proceeds as follows:\n1.  Define the input data: the wavelength list $\\Lambda$, the reflectance list $\\mathcal{R}$, and the hull vertices list $\\mathcal{H}$. The target wavelength is constant at $\\lambda^\\star = 2.20 \\, \\mu\\text{m}$.\n2.  Implement a generic linear interpolation function that, given a target $x$-coordinate and a set of sorted $(x,y)$ points, returns the corresponding $y$-coordinate. This function must handle both exact matches and interpolation cases.\n3.  Call this interpolation function with $\\lambda^\\star$ and the spectrum points $\\{(\\lambda_i, R(\\lambda_i))\\}$ to compute $R(\\lambda^\\star)$.\n4.  Call the same interpolation function with $\\lambda^\\star$ and the hull vertices $\\{(\\lambda_{h,j}, R_{h,j})\\}$ to compute $C(\\lambda^\\star)$.\n5.  Calculate the band depth $BD(\\lambda^\\star)$ using the primary formula. Since all reflectances $R(\\lambda_i)$ are in the range $[0, 1]$ and the convex hull sits above the spectrum, $C(\\lambda^\\star)$ will be positive for non-zero spectra, preventing division by zero.\n6.  The final result for each case is the computed dimensionless decimal fraction for $BD(\\lambda^\\star)$.\n\nThis procedure is deterministic and directly follows the provided definitions, ensuring a correct and verifiable solution based on fundamental geometric and numerical principles.",
            "answer": "```python\nimport numpy as np\n\ndef _linear_interpolate(x_target, points):\n    \"\"\"\n    Performs linear interpolation on a set of 2D points.\n\n    Args:\n        x_target (float): The x-coordinate at which to interpolate.\n        points (list of tuple/list): A list of (x, y) points, sorted by x.\n\n    Returns:\n        float: The interpolated y-value.\n    \"\"\"\n    points_arr = np.array(points)\n    x_coords = points_arr[:, 0]\n    y_coords = points_arr[:, 1]\n    \n    # Case 1: x_target is one of the existing x-coordinates\n    match_indices = np.where(x_coords == x_target)[0]\n    if len(match_indices) > 0:\n        return y_coords[match_indices[0]]\n\n    # Case 2: x_target needs interpolation.\n    # np.searchsorted finds the index where x_target would be inserted to maintain order.\n    idx = np.searchsorted(x_coords, x_target)\n\n    # The problem setup ensures x_target is always bracketed by the given points.\n    # Therefore, we do not need to handle extrapolation cases.\n    x1, y1 = points_arr[idx - 1]\n    x2, y2 = points_arr[idx]\n    \n    # Standard linear interpolation formula\n    y_target = y1 + ((x_target - x1) * (y2 - y1) / (x2 - x1))\n    \n    return y_target\n\ndef calculate_band_depth(lmbda, R, H, lambda_star):\n    \"\"\"\n    Calculates the band depth at a target wavelength.\n\n    Args:\n        lmbda (list): List of wavelengths.\n        R (list): List of reflectances.\n        H (list of tuple): List of convex hull vertices.\n        lambda_star (float): The target wavelength.\n\n    Returns:\n        float: The calculated band depth.\n    \"\"\"\n    # 1. Compute R(lambda_star) by interpolating the spectrum\n    spectrum_points = list(zip(lmbda, R))\n    R_star = _linear_interpolate(lambda_star, spectrum_points)\n\n    # 2. Compute C(lambda_star) by interpolating the hull vertices\n    C_star = _linear_interpolate(lambda_star, H)\n\n    # 3. Compute BD(lambda_star)\n    # The problem context implies C_star will not be zero.\n    if C_star == 0:\n        return np.nan # Should not be reached with the given test cases\n\n    band_depth = 1.0 - (R_star / C_star)\n    return band_depth\n\ndef solve():\n    \"\"\"\n    Solves the band depth calculation problem for the given test cases.\n    \"\"\"\n    lambda_star = 2.20\n\n    test_cases = [\n        # Case 1: General absorption feature\n        (\n            [2.00, 2.10, 2.15, 2.20, 2.25, 2.30, 2.40],\n            [0.52, 0.50, 0.48, 0.35, 0.47, 0.52, 0.55],\n            [(2.00, 0.52), (2.40, 0.55)]\n        ),\n        # Case 2: Target wavelength is a hull vertex\n        (\n            [2.18, 2.20, 2.22, 2.24],\n            [0.49, 0.52, 0.51, 0.50],\n            [(2.18, 0.49), (2.20, 0.52), (2.24, 0.50)]\n        ),\n        # Case 3: Minimal spectrum\n        (\n            [2.10, 2.20, 2.30],\n            [0.60, 0.40, 0.62],\n            [(2.10, 0.60), (2.30, 0.62)]\n        ),\n        # Case 4: Target wavelength is not sampled\n        (\n            [2.17, 2.19, 2.21, 2.23, 2.26, 2.30],\n            [0.53, 0.51, 0.46, 0.49, 0.52, 0.54],\n            [(2.17, 0.53), (2.30, 0.54)]\n        )\n    ]\n\n    results = []\n    for lmbda, R, H in test_cases:\n        bd = calculate_band_depth(lmbda, R, H, lambda_star)\n        results.append(bd)\n\n    # Format the output as a comma-separated list of floats in brackets\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While spectral data offers insights into composition, radar is highly sensitive to soil moisture. However, retrieving fine-scale moisture variations from coarse-resolution radar data is a classic ill-posed inverse problem, where the solution is highly unstable and sensitive to noise. This exercise  introduces Tikhonov regularization, a foundational technique for stabilizing such inversions by incorporating prior knowledge and allows you to explore the critical trade-off between estimation bias and variance.",
            "id": "3848656",
            "problem": "You are tasked with demonstrating why inverting normalized radar cross section for soil moisture is ill-posed and how Tikhonov regularization stabilizes the retrieval. Consider a simplified coarse-resolution Synthetic Aperture Radar (SAR) observation model where multiple fine-scale soil moisture states are mixed within a radar footprint. The normalized radar cross section (often written as $\\sigma^{0}$) in linear units is modeled as a linear mixture of fine-scale soil moisture states with additive noise. The estimation is aided by a prior derived from an optical spectral index (e.g., a vegetation-sensitive index), treated as a mean of a Gaussian prior on soil moisture.\n\nAssume the following model and definitions as the fundamental starting point:\n- The forward model is $y = H m + \\varepsilon$, where $y \\in \\mathbb{R}^{p}$ are observed coarse-resolution normalized radar cross section values (in linear units), $H \\in \\mathbb{R}^{p \\times n}$ is a known mixing/sensitivity matrix, $m \\in \\mathbb{R}^{n}$ are the unknown fine-scale volumetric soil moisture states expressed in $\\mathrm{m}^3/\\mathrm{m}^3$, and $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{p})$ is additive Gaussian noise with variance $\\sigma^{2}$ in linear backscatter units.\n- A prior derived from optical spectral data is represented as a Gaussian prior $m \\sim \\mathcal{N}(m_0, \\tau^2 I_n)$, with $m_0 \\in \\mathbb{R}^n$ given. The regularization parameter is $\\lambda = \\sigma^2/\\tau^2$, and the penalty operator is the identity matrix, corresponding to a zero-order Tikhonov regularization centered at $m_0$.\n- The ill-posedness arises because $p < n$ and the columns of $H$ are not well separated, making the inversion sensitive to noise and causing non-uniqueness.\n\nYour tasks are as follows:\n1. Starting from the Gaussian likelihood for the forward model and the Gaussian prior defined above, derive the Maximum A Posteriori (MAP) estimator for $m$ as a function of $H$, $y$, $m_0$, and $\\lambda$ using only first principles of linear algebra and probability for Gaussian models. From this, derive an expression for the expected estimation bias $b_{\\lambda} = \\mathbb{E}[\\hat{m}_{\\lambda}] - m_{\\text{true}}$ and the covariance matrix $\\mathrm{Cov}(\\hat{m}_{\\lambda})$ as functions of $H$, $\\sigma^{2}$, $m_0$, $m_{\\text{true}}$, and $\\lambda$.\n2. Handle the degenerate case $\\lambda = 0$ by using the minimum-norm least-squares solution based on the Moore–Penrose pseudoinverse for underdetermined systems, and derive corresponding expressions for the bias and covariance in this case.\n3. Implement a program that, for each test case, computes two scalar diagnostics as functions of $\\lambda$: the Euclidean norm of the bias vector $\\|b_{\\lambda}\\|_2$ (in $\\mathrm{m}^3/\\mathrm{m}^3$) and the trace of the covariance matrix $\\mathrm{tr}(\\mathrm{Cov}(\\hat{m}_{\\lambda}))$ (in $(\\mathrm{m}^3/\\mathrm{m}^3)^2$). No Monte Carlo simulation is permitted; use the closed-form expressions implied by the derivations in steps $1$ and $2$.\n\nUse the following test suite. The physical units are as above: all soil moisture values and their biases must be in $\\mathrm{m}^3/\\mathrm{m}^3$, and variances must be in $(\\mathrm{m}^3/\\mathrm{m}^3)^2$. The normalized radar cross section is dimensionless in linear units.\n\n- Test case $1$ (underdetermined mixture, moderate noise):\n  - $p = 3$, $n = 5$,\n  - $H = \\begin{bmatrix}\n  0.48 & 0.46 & 0.06 & 0.00 & 0.00 \\\\\n  0.26 & 0.22 & 0.52 & 0.00 & 0.00 \\\\\n  0.10 & 0.12 & 0.18 & 0.30 & 0.30\n  \\end{bmatrix}$,\n  - $m_{\\text{true}} = \\begin{bmatrix} 0.12 \\\\ 0.18 \\\\ 0.22 \\\\ 0.30 \\\\ 0.35 \\end{bmatrix}$ in $\\mathrm{m}^3/\\mathrm{m}^3$,\n  - $m_0 = \\begin{bmatrix} 0.15 \\\\ 0.20 \\\\ 0.25 \\\\ 0.25 \\\\ 0.30 \\end{bmatrix}$ in $\\mathrm{m}^3/\\mathrm{m}^3$,\n  - $\\sigma = 0.004$,\n  - $\\lambda$ values: $[0.0, 0.01, 0.1, 1.0, 10.0, 100.0]$.\n\n- Test case $2$ (same mixing, higher noise):\n  - $H$ and $m_{\\text{true}}$, $m_0$ as in test case $1$,\n  - $\\sigma = 0.02$,\n  - $\\lambda$ values: $[1.0, 10.0]$.\n\n- Test case $3$ (more severe ill-conditioning):\n  - $p = 3$, $n = 5$,\n  - $H = \\begin{bmatrix}\n  0.50 & 0.49 & 0.01 & 0.00 & 0.00 \\\\\n  0.25 & 0.245 & 0.505 & 0.00 & 0.00 \\\\\n  0.125 & 0.1225 & 0.2525 & 0.25 & 0.25\n  \\end{bmatrix}$,\n  - $m_{\\text{true}} = \\begin{bmatrix} 0.12 \\\\ 0.18 \\\\ 0.22 \\\\ 0.30 \\\\ 0.35 \\end{bmatrix}$ in $\\mathrm{m}^3/\\mathrm{m}^3$,\n  - $m_0 = \\begin{bmatrix} 0.15 \\\\ 0.20 \\\\ 0.25 \\\\ 0.25 \\\\ 0.30 \\end{bmatrix}$ in $\\mathrm{m}^3/\\mathrm{m}^3$,\n  - $\\sigma = 0.004$,\n  - $\\lambda$ values: $[0.0, 0.1, 1000.0]$.\n\nYour program must:\n- Compute, for each test case and each $\\lambda$ in its list, the pair of diagnostics $\\left(\\|b_{\\lambda}\\|_2, \\mathrm{tr}(\\mathrm{Cov}(\\hat{m}_{\\lambda}))\\right)$ using the analytic expressions derived in steps $1$ and $2$.\n- Aggregate the results for all provided test cases into a single line of output in the following format: a list of lists where each inner list corresponds to one test case and contains lists of three numbers $\\left[\\lambda, \\|b_{\\lambda}\\|_2, \\mathrm{tr}(\\mathrm{Cov}(\\hat{m}_{\\lambda}))\\right]$ for each $\\lambda$ of that case. For example, the output must look like $[[[\\lambda_{1},b_{1},v_{1}],\\ldots],[\\ldots],[\\ldots]]$ with all numbers in decimal form.\n- Express $\\|b_{\\lambda}\\|_2$ in $\\mathrm{m}^3/\\mathrm{m}^3$ and $\\mathrm{tr}(\\mathrm{Cov}(\\hat{m}_{\\lambda}))$ in $(\\mathrm{m}^3/\\mathrm{m}^3)^2$.\n\nThe final output must be a single line containing the exact list structure described, with no additional text. No randomization is permitted; the solution must be fully deterministic from the provided inputs.",
            "solution": "We start from the linear forward model $y = H m + \\varepsilon$ with $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2 I_p)$. The likelihood of $y$ given $m$ is Gaussian with mean $H m$ and covariance $\\sigma^2 I_p$. A prior based on optical spectral information is represented as $m \\sim \\mathcal{N}(m_0, \\tau^2 I_n)$. The Maximum A Posteriori (MAP) estimator follows by maximizing the posterior density, equivalently minimizing the negative log posterior. Up to additive constants independent of $m$, the objective is\n$$\nJ(m) = \\frac{1}{\\sigma^2} \\| H m - y \\|_{2}^{2} + \\frac{1}{\\tau^2} \\| m - m_0 \\|_{2}^{2}.\n$$\nUsing the regularization parameter $\\lambda = \\sigma^2/\\tau^2$, this becomes (up to a constant factor) the zero-order Tikhonov objective\n$$\n\\tilde{J}(m) = \\| H m - y \\|_{2}^{2} + \\lambda \\| m - m_0 \\|_{2}^{2}.\n$$\nTaking the gradient with respect to $m$ and setting it to zero yields the normal equations\n$$\n(H^{\\top} H + \\lambda I_n) m = H^{\\top} y + \\lambda m_0.\n$$\nAssuming $\\lambda > 0$, the coefficient matrix $H^{\\top} H + \\lambda I_n$ is positive definite, thus invertible. The MAP estimator is\n$$\n\\hat{m}_{\\lambda} = (H^{\\top} H + \\lambda I_n)^{-1} (H^{\\top} y + \\lambda m_0).\n$$\nTo compute the bias, substitute $y = H m_{\\text{true}} + \\varepsilon$ and take expectation with respect to $\\varepsilon$:\n$$\n\\mathbb{E}[\\hat{m}_{\\lambda}] = (H^{\\top} H + \\lambda I_n)^{-1} (H^{\\top} H\\, m_{\\text{true}} + \\lambda m_0).\n$$\nTherefore the bias vector is\n$$\nb_{\\lambda} = \\mathbb{E}[\\hat{m}_{\\lambda}] - m_{\\text{true}} = \\left[(H^{\\top} H + \\lambda I_n)^{-1} (H^{\\top} H) - I_n\\right] m_{\\text{true}} + (H^{\\top} H + \\lambda I_n)^{-1} \\lambda (m_0 - m_{\\text{true}}).\n$$\nUsing the identity $(H^{\\top} H + \\lambda I_n)^{-1} (H^{\\top} H) = I_n - \\lambda (H^{\\top} H + \\lambda I_n)^{-1}$, this simplifies to\n$$\nb_{\\lambda} = \\lambda (H^{\\top} H + \\lambda I_n)^{-1} (m_0 - m_{\\text{true}}).\n$$\nThus the bias is zero when $m_0 = m_{\\text{true}}$ and increases in magnitude with $\\lambda$ for a biased prior.\n\nThe covariance of $\\hat{m}_{\\lambda}$ follows from the linearity in $y$:\n$$\n\\hat{m}_{\\lambda} = (H^{\\top} H + \\lambda I_n)^{-1} H^{\\top} y + (H^{\\top} H + \\lambda I_n)^{-1} \\lambda m_0.\n$$\nThe second term is deterministic, so\n$$\n\\mathrm{Cov}(\\hat{m}_{\\lambda}) = (H^{\\top} H + \\lambda I_n)^{-1} H^{\\top} \\mathrm{Cov}(y) H (H^{\\top} H + \\lambda I_n)^{-1}.\n$$\nWith $\\mathrm{Cov}(y) = \\sigma^2 I_p$, we obtain\n$$\n\\mathrm{Cov}(\\hat{m}_{\\lambda}) = \\sigma^2 (H^{\\top} H + \\lambda I_n)^{-1} H^{\\top} H (H^{\\top} H + \\lambda I_n)^{-1}.\n$$\nThese expressions quantify the variance reduction as $\\lambda$ increases, at the cost of increasing bias towards $m_0$.\n\nFor the degenerate case $\\lambda = 0$, the optimization reduces to least squares with potentially infinitely many solutions because $p  n$. The conventional choice is the minimum-norm solution given by the Moore–Penrose pseudoinverse:\n$$\n\\hat{m}_{0} = H^{+} y \\quad \\text{with} \\quad H^{+} = H^{\\top} (H H^{\\top})^{-1},\n$$\nassuming $H$ has full row rank (i.e., $H H^{\\top}$ invertible, which is satisfied in the provided tests). The expectation and covariance are\n$$\n\\mathbb{E}[\\hat{m}_{0}] = H^{+} H m_{\\text{true}}, \\quad \\mathrm{Cov}(\\hat{m}_{0}) = \\sigma^2 H^{+} (H^{+})^{\\top}.\n$$\nThus the bias at $\\lambda = 0$ is\n$$\nb_{0} = \\mathbb{E}[\\hat{m}_{0}] - m_{\\text{true}} = (H^{+} H - I_n) m_{\\text{true}},\n$$\nwhich is nonzero whenever $m_{\\text{true}}$ has components in the nullspace of $H$; this expresses the ill-posedness and non-identifiability of components unobserved by the radar mixing.\n\nThe requested diagnostics are the Euclidean norm of the bias, $\\|b_{\\lambda}\\|_2$, with units $\\mathrm{m}^3/\\mathrm{m}^3$, and the trace of the covariance, $\\mathrm{tr}(\\mathrm{Cov}(\\hat{m}_{\\lambda}))$, with units $(\\mathrm{m}^3/\\mathrm{m}^3)^2$. For $\\lambda > 0$, we compute $b_{\\lambda}$ and $\\mathrm{Cov}(\\hat{m}_{\\lambda})$ from the closed forms above. For $\\lambda = 0$, we use the pseudoinverse-based formulas. This produces deterministic results for each test case and each specified $\\lambda$ without any simulation.\n\nTo implement efficiently and stably:\n- For $\\lambda > 0$, solve linear systems with $(H^{\\top} H + \\lambda I_n)$ rather than forming matrix inverses explicitly when possible. Since $n = 5$, computing an explicit inverse by solving against the identity is also numerically stable here.\n- For $\\lambda = 0$, compute $H^{+}$ via $H^{\\top} (H H^{\\top})^{-1}$, given full row rank. Then compute $b_0$ and $\\mathrm{Cov}(\\hat{m}_0)$ directly.\n\nThe program evaluates all test cases:\n- Test case $1$ demonstrates the underdetermined, moderately noisy scenario with a range of $\\lambda$ values including $\\lambda = 0$ to illustrate instability and variance, and larger $\\lambda$ to show stabilization with bias increase.\n- Test case $2$ increases $\\sigma$ to show that variance scales with $\\sigma^2$ and larger $\\lambda$ is needed to stabilize.\n- Test case $3$ uses a more ill-conditioned $H$ to emphasize the effect of poorly separated columns and the role of $\\lambda$.\n\nThe output aggregates, for each test case, lists of triples $[\\lambda, \\|b_{\\lambda}\\|_2, \\mathrm{tr}(\\mathrm{Cov}(\\hat{m}_{\\lambda}))]$ in a single top-level list, printed on one line, as required.",
            "answer": "```python\nimport numpy as np\nimport json\n\ndef bias_and_var_metrics(H, sigma, m_true, m0, lambdas):\n    \"\"\"\n    Compute [lambda, ||bias||2, trace(covariance)] for each lambda.\n    Units:\n      - ||bias||2 in m^3/m^3\n      - trace(covariance) in (m^3/m^3)^2\n    \"\"\"\n    H = np.array(H, dtype=float)\n    m_true = np.array(m_true, dtype=float).reshape(-1, 1)\n    m0 = np.array(m0, dtype=float).reshape(-1, 1)\n    p, n = H.shape\n\n    Ht = H.T\n    HtH = Ht @ H\n    I_n = np.eye(n)\n\n    results = []\n\n    # Precompute pseudoinverse components for lambda=0 case\n    # Assume full row rank: H H^T invertible\n    HHt = H @ Ht\n    # Slight regularization if needed (not expected for given test cases)\n    HHt_inv = np.linalg.inv(HHt)\n    H_pinv = Ht @ HHt_inv  # Moore-Penrose for full row-rank H\n\n    for lam in lambdas:\n        if lam == 0.0:\n            # Minimum-norm LS solution\n            # Bias: (H^+ H - I) m_true\n            # Cov: sigma^2 H^+ (H^+)^T\n            P = H_pinv @ H  # projector onto row-space of H\n            bias_vec = (P - I_n) @ m_true\n            cov = (sigma ** 2) * (H_pinv @ H_pinv.T)\n        else:\n            A = HtH + lam * I_n\n            # Compute A_inv stably by solving A X = I\n            A_inv = np.linalg.inv(A)\n\n            # Bias: lam * A_inv @ (m0 - m_true)\n            bias_vec = lam * (A_inv @ (m0 - m_true))\n\n            # Cov: sigma^2 * A_inv @ HtH @ A_inv\n            cov = (sigma ** 2) * (A_inv @ HtH @ A_inv)\n\n        bias_norm = float(np.linalg.norm(bias_vec, 2))\n        var_trace = float(np.trace(cov))\n        results.append([float(lam), bias_norm, var_trace])\n\n    return results\n\ndef solve():\n    # Test case 1\n    H1 = [\n        [0.48, 0.46, 0.06, 0.00, 0.00],\n        [0.26, 0.22, 0.52, 0.00, 0.00],\n        [0.10, 0.12, 0.18, 0.30, 0.30],\n    ]\n    m_true = [0.12, 0.18, 0.22, 0.30, 0.35]  # m^3/m^3\n    m0 = [0.15, 0.20, 0.25, 0.25, 0.30]      # m^3/m^3\n\n    sigma1 = 0.004\n    lambdas1 = [0.0, 0.01, 0.1, 1.0, 10.0, 100.0]\n\n    # Test case 2: higher noise\n    sigma2 = 0.02\n    lambdas2 = [1.0, 10.0]\n\n    # Test case 3: more severe ill-conditioning\n    H2 = [\n        [0.50, 0.49, 0.01, 0.00, 0.00],\n        [0.25, 0.245, 0.505, 0.00, 0.00],\n        [0.125, 0.1225, 0.2525, 0.25, 0.25],\n    ]\n    sigma3 = 0.004\n    lambdas3 = [0.0, 0.1, 1000.0]\n\n    res1 = bias_and_var_metrics(H1, sigma1, m_true, m0, lambdas1)\n    res2 = bias_and_var_metrics(H1, sigma2, m_true, m0, lambdas2)\n    res3 = bias_and_var_metrics(H2, sigma3, m_true, m0, lambdas3)\n\n    all_results = [res1, res2, res3]\n    print(json.dumps(all_results))\n\nsolve()\n```"
        },
        {
            "introduction": "Building on the concept of regularization, we can frame data fusion in a powerful probabilistic context. The Bayesian framework allows us to formally combine a physical model (relating SAR backscatter to moisture) with prior information (derived from spectral data) to produce a refined estimate with a rigorous measure of uncertainty. In this final practice , you will derive a Bayesian posterior distribution for soil moisture and compute its credible interval, demonstrating a state-of-the-art approach to data fusion.",
            "id": "3848603",
            "problem": "A soil pixel over an agricultural field is observed by Synthetic Aperture Radar (SAR) at C-band. Over bare soil under low vegetation cover, the SAR backscatter in decibels is approximately linear in volumetric soil moisture due to the monotonic increase of the effective dielectric constant with water content. For a small range of soil moisture, assume the forward model $y$ in decibels is $y = \\alpha\\, m_v + \\beta + \\epsilon$, where $m_v \\in [0,1]$ is the volumetric soil moisture (dimensionless), $\\alpha$ and $\\beta$ are known calibration coefficients for the site and incidence geometry, and $\\epsilon$ is random sensor and model discrepancy with $\\epsilon \\sim \\mathcal{N}(0,\\sigma_{\\epsilon}^{2})$. A hyperspectral mapping from a Normalized Difference Infrared Index (NDII) provides a prior estimate of $m_v$ through a regression that yields a Gaussian prior $m_v \\sim \\mathcal{N}(m_0,\\sigma_{m,0}^{2})$. \n\nStarting from Bayes’ theorem and the definitions of the Gaussian density, derive the posterior distribution $p(m_v \\mid y)$ and show that it is Gaussian. Then, using the posterior distribution, derive the general expression for a two-sided $0.95$ credible interval for $m_v$ in terms of the posterior mean and variance. Finally, for a specific pixel with the following parameters: $\\alpha = 10$ (decibels per unit $m_v$), $\\beta = -15$ (decibels), $y = -12.3$ (decibels), $\\sigma_{\\epsilon}^{2} = 0.64$ (decibels squared), $m_0 = 0.24$, and $\\sigma_{m,0}^{2} = 0.0016$, compute the $0.95$ credible interval bounds for $m_v$. Express the final bounds as a pair in a single row using the LaTeX $\\texttt{pmatrix}$ environment, in decimal fraction form (dimensionless), and round both bounds to four significant figures.",
            "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- Forward model for SAR backscatter $y$ in decibels: $y = \\alpha\\, m_v + \\beta + \\epsilon$.\n- $m_v$: volumetric soil moisture, $m_v \\in [0,1]$, dimensionless.\n- $\\alpha$, $\\beta$: known calibration coefficients.\n- $\\epsilon$: random error term, with distribution $\\epsilon \\sim \\mathcal{N}(0,\\sigma_{\\epsilon}^{2})$.\n- Prior distribution for soil moisture: $m_v \\sim \\mathcal{N}(m_0,\\sigma_{m,0}^{2})$.\n- Task 1: Derive the posterior distribution $p(m_v \\mid y)$ and show it is Gaussian.\n- Task 2: Derive the general expression for a two-sided $0.95$ credible interval for $m_v$.\n- Task 3: Compute the $0.95$ credible interval bounds for a specific pixel with the following parameters:\n    - $\\alpha = 10$ (decibels per unit $m_v$)\n    - $\\beta = -15$ (decibels)\n    - $y = -12.3$ (decibels)\n    - $\\sigma_{\\epsilon}^{2} = 0.64$ (decibels squared)\n    - $m_0 = 0.24$ (dimensionless)\n    - $\\sigma_{m,0}^{2} = 0.0016$ (dimensionless squared)\n- Final answer format: a pair of bounds in a `pmatrix`, as decimal fractions, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded:** The problem describes a standard Bayesian data fusion method used in remote sensing to estimate a physical parameter (soil moisture). The linear model for SAR backscatter is a common and physically motivated approximation under specific conditions (e.g., C-band, low vegetation). The use of a Gaussian prior from an independent data source (hyperspectral index) is a valid and established technique in data assimilation.\n2.  **Well-Posed:** The problem provides a clear objective, a forward model (likelihood), a prior distribution, and all necessary parameters to derive the posterior distribution and calculate the requested credible interval. It is a standard problem in Bayesian statistics, admitting a unique and stable solution.\n3.  **Objective:** The problem is stated using precise, unambiguous mathematical and scientific language.\n4.  **Completeness and Consistency:** The problem is self-contained. All constants and initial conditions required for both the symbolic derivation and the numerical calculation are provided. The values are physically reasonable for the described scenario. While $m_v$ is physically constrained to $[0,1]$, the use of Gaussian distributions (defined over the entire real line) is a common and acceptable approximation, provided the resulting posterior distribution is concentrated well within the physical bounds. A post-calculation check can verify this.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, mathematically well-posed, and complete. It is therefore deemed **valid**. The solution will be derived as requested.\n\n### Derivation of the Posterior Distribution\n\nAccording to Bayes' theorem, the posterior probability density function (PDF) of the volumetric soil moisture $m_v$ given the measurement $y$ is proportional to the product of the likelihood and the prior PDF:\n$$p(m_v \\mid y) \\propto p(y \\mid m_v) \\, p(m_v)$$\nThe prior distribution is given as Gaussian:\n$$p(m_v) = \\frac{1}{\\sqrt{2\\pi\\sigma_{m,0}^{2}}} \\exp\\left(-\\frac{(m_v - m_0)^2}{2\\sigma_{m,0}^{2}}\\right)$$\nThe forward model is $y = \\alpha m_v + \\beta + \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2})$. From this, the likelihood function $p(y \\mid m_v)$ can be constructed. For a given $m_v$, $y$ is a random variable with mean $\\mathbb{E}[y \\mid m_v] = \\alpha m_v + \\beta$ and variance $\\text{Var}(y \\mid m_v) = \\sigma_{\\epsilon}^2$. Thus, the likelihood is also a Gaussian PDF:\n$$p(y \\mid m_v) = \\frac{1}{\\sqrt{2\\pi\\sigma_{\\epsilon}^{2}}} \\exp\\left(-\\frac{(y - (\\alpha m_v + \\beta))^2}{2\\sigma_{\\epsilon}^{2}}\\right)$$\nThe posterior PDF is then proportional to the product of these two Gaussians. We can ignore the normalization constants, as they do not depend on $m_v$.\n$$p(m_v \\mid y) \\propto \\exp\\left( -\\frac{(y - \\alpha m_v - \\beta)^2}{2\\sigma_{\\epsilon}^{2}} - \\frac{(m_v - m_0)^2}{2\\sigma_{m,0}^{2}} \\right)$$\nTo show that the posterior is Gaussian, we must show that the expression in the exponent is a quadratic function of $m_v$ of the form $-\\frac{(m_v - \\mu_{post})^2}{2\\sigma_{post}^2}$. Let's expand the argument of the exponential:\n$$S(m_v) = -\\frac{1}{2} \\left[ \\frac{(\\alpha m_v - (y - \\beta))^2}{\\sigma_{\\epsilon}^{2}} + \\frac{(m_v - m_0)^2}{\\sigma_{m,0}^{2}} \\right]$$\n$$S(m_v) = -\\frac{1}{2} \\left[ \\frac{\\alpha^2 m_v^2 - 2\\alpha(y-\\beta)m_v + (y-\\beta)^2}{\\sigma_{\\epsilon}^{2}} + \\frac{m_v^2 - 2m_0 m_v + m_0^2}{\\sigma_{m,0}^{2}} \\right]$$\nWe collect terms in $m_v^2$ and $m_v$:\n$$S(m_v) = -\\frac{1}{2} \\left[ m_v^2 \\left( \\frac{\\alpha^2}{\\sigma_{\\epsilon}^2} + \\frac{1}{\\sigma_{m,0}^2} \\right) - 2m_v \\left( \\frac{\\alpha(y-\\beta)}{\\sigma_{\\epsilon}^2} + \\frac{m_0}{\\sigma_{m,0}^2} \\right) + C \\right]$$\nwhere $C$ contains terms not dependent on $m_v$. This is a quadratic form in $m_v$. By completing the square, we can identify the mean and variance of the resulting Gaussian posterior. A Gaussian PDF for a variable $x$ with mean $\\mu$ and variance $\\sigma^2$ has an exponent of $-\\frac{x^2 - 2\\mu x + \\mu^2}{2\\sigma^2} = -\\frac{1}{2\\sigma^2}x^2 + \\frac{\\mu}{\\sigma^2}x - \\frac{\\mu^2}{2\\sigma^2}$.\n\nBy comparing the coefficients of the $m_v^2$ term, we find the inverse of the posterior variance, $\\sigma_{post}^{-2}$:\n$$\\frac{1}{\\sigma_{post}^2} = \\frac{\\alpha^2}{\\sigma_{\\epsilon}^2} + \\frac{1}{\\sigma_{m,0}^2}$$\nwhich implies the posterior variance is:\n$$\\sigma_{post}^2 = \\left( \\frac{\\alpha^2}{\\sigma_{\\epsilon}^2} + \\frac{1}{\\sigma_{m,0}^2} \\right)^{-1}$$\nBy comparing the coefficients of the $m_v$ term, we find the expression for the posterior mean, $\\mu_{post}$:\n$$\\frac{\\mu_{post}}{\\sigma_{post}^2} = \\frac{\\alpha(y-\\beta)}{\\sigma_{\\epsilon}^2} + \\frac{m_0}{\\sigma_{m,0}^2}$$\n$$\\mu_{post} = \\sigma_{post}^2 \\left( \\frac{\\alpha(y-\\beta)}{\\sigma_{\\epsilon}^2} + \\frac{m_0}{\\sigma_{m,0}^2} \\right)$$\nSince the exponent is a quadratic function of $m_v$, the posterior distribution $p(m_v \\mid y)$ is indeed Gaussian, with the derived mean $\\mu_{post}$ and variance $\\sigma_{post}^2$.\n$$p(m_v \\mid y) \\sim \\mathcal{N}(\\mu_{post}, \\sigma_{post}^2)$$\n\n### Derivation of the Credible Interval\n\nA two-sided credible interval for a parameter contains a specified probability mass of the posterior distribution. For a $(1-\\gamma)$ credible interval from a Gaussian posterior distribution $\\mathcal{N}(\\mu, \\sigma^2)$, the interval is symmetric about the mean $\\mu$ and is given by:\n$$[\\mu - z_{\\gamma/2}\\sigma, \\mu + z_{\\gamma/2}\\sigma]$$\nwhere $z_{\\gamma/2}$ is the critical value of the standard normal distribution such that $P(Z > z_{\\gamma/2}) = \\gamma/2$, where $Z \\sim \\mathcal{N}(0,1)$.\n\nFor a $0.95$ credible interval, we have $1-\\gamma = 0.95$, so $\\gamma=0.05$ and $\\gamma/2 = 0.025$. The critical value $z_{0.025}$ is the value such that the cumulative distribution function (CDF) is $1-0.025=0.975$. From standard statistical tables, this value is approximately $z_{0.025} \\approx 1.96$.\nThe general expression for the $0.95$ credible interval for $m_v$ is therefore:\n$$[\\mu_{post} - z_{0.025}\\,\\sigma_{post}, \\mu_{post} + z_{0.025}\\,\\sigma_{post}]$$\nwhere $\\mu_{post}$ and $\\sigma_{post}$ are the posterior mean and standard deviation derived above.\n\n### Numerical Computation\n\nWe are given the following parameters:\n$\\alpha = 10$, $\\beta = -15$, $y = -12.3$, $\\sigma_{\\epsilon}^{2} = 0.64$, $m_0 = 0.24$, and $\\sigma_{m,0}^{2} = 0.0016$.\n\nFirst, we compute the posterior variance $\\sigma_{post}^2$:\n$$\\frac{1}{\\sigma_{post}^2} = \\frac{\\alpha^2}{\\sigma_{\\epsilon}^2} + \\frac{1}{\\sigma_{m,0}^2} = \\frac{10^2}{0.64} + \\frac{1}{0.0016} = \\frac{100}{0.64} + \\frac{1}{0.0016}$$\n$$\\frac{1}{\\sigma_{post}^2} = 156.25 + 625 = 781.25$$\n$$\\sigma_{post}^2 = \\frac{1}{781.25} = 0.00128$$\nThe posterior standard deviation is $\\sigma_{post} = \\sqrt{0.00128}$.\n\nNext, we compute the posterior mean $\\mu_{post}$:\n$$\\mu_{post} = \\sigma_{post}^2 \\left( \\frac{\\alpha(y-\\beta)}{\\sigma_{\\epsilon}^2} + \\frac{m_0}{\\sigma_{m,0}^2} \\right)$$\n$$\\mu_{post} = 0.00128 \\left( \\frac{10(-12.3 - (-15))}{0.64} + \\frac{0.24}{0.0016} \\right)$$\n$$\\mu_{post} = 0.00128 \\left( \\frac{10(2.7)}{0.64} + 150 \\right)$$\n$$\\mu_{post} = 0.00128 \\left( \\frac{27}{0.64} + 150 \\right)$$\n$$\\mu_{post} = 0.00128 (42.1875 + 150) = 0.00128 (192.1875) = 0.246$$\n\nNow, we compute the $0.95$ credible interval bounds using $\\mu_{post}=0.246$, $\\sigma_{post}=\\sqrt{0.00128}$, and the critical value $z_{0.025} \\approx 1.959964$.\n$$\\sigma_{post} = \\sqrt{0.00128} \\approx 0.0357770876$$\nThe margin of error is:\n$$E = z_{0.025} \\cdot \\sigma_{post} \\approx 1.959964 \\times 0.0357770876 \\approx 0.07012164$$\n\nLower bound:\n$$L = \\mu_{post} - E \\approx 0.246 - 0.07012164 = 0.17587836$$\nUpper bound:\n$$U = \\mu_{post} + E \\approx 0.246 + 0.07012164 = 0.31612164$$\n\nRounding both bounds to four significant figures:\nLower bound $\\approx 0.1759$\nUpper bound $\\approx 0.3161$\n\nThe interval $[0.1759, 0.3161]$ is well within the physical domain $[0,1]$, justifying the use of the Gaussian approximation.",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.1759  0.3161 \\end{pmatrix}}$$"
        }
    ]
}