{
    "hands_on_practices": [
        {
            "introduction": "在贝叶斯分析中，共轭先验是基石概念之一，它使得后验分布与先验分布属于同一函数族，从而极大地简化了计算。本练习将通过一个经典的层次模型，指导您从第一性原理出发，为高斯似然函数下的未知精度参数推导其共轭伽马后验分布。掌握这一过程对于理解贝叶斯更新的核心机制至关重要。",
            "id": "3798296",
            "problem": "一个遥感数据融合任务旨在通过结合两种卫星仪器：微波辐射计 (MWR) 和合成孔径雷达 (SAR)，来估计 $n$ 个共置像素上的近地表土壤湿度的潜在环境状态。设由一个基于物理的陆面模型产生的确定性背景状态为 $\\{s_{i}\\}_{i=1}^{n}$，对于这些像素，该状态被视为已知（例如，作为数据同化周期中的当前状态）。MWR 和 SAR 分别提供观测值 $\\{x_{i}\\}_{i=1}^{n}$ 和 $\\{y_{i}\\}_{i=1}^{n}$。假设一个分层贝叶斯融合模型，其中传感器误差是可加的，并且在条件上是独立同分布的高斯分布，具有一个共同的未知精度参数 $\\tau$：\n$$\nx_{i} \\mid s_{i}, \\tau \\sim \\mathcal{N}\\!\\left(s_{i},\\, \\tau^{-1}\\right), \\quad y_{i} \\mid s_{i}, \\tau \\sim \\mathcal{N}\\!\\left(s_{i},\\, \\tau^{-1}\\right), \\quad \\text{对于 } i=1,\\dots,n \\text{ 独立}。\n$$\n对未知精度参数采用共轭先验，\n$$\n\\tau \\sim \\text{Gamma}(a,b),\n$$\n其形状-率参数化 $\\text{Gamma}(a,b)$ 的密度定义为 $p(\\tau)=\\frac{b^{a}}{\\Gamma(a)}\\,\\tau^{a-1}\\exp(-b\\tau)$，对于 $\\tau>0$。从贝叶斯定理和用精度表示的高斯似然出发，推导闭式后验密度 $p(\\tau \\mid x, y)$，用 $a$、$b$、$n$ 和残差和\n$$\nS \\equiv \\sum_{i=1}^{n}\\Big[(x_{i}-s_{i})^{2} + (y_{i}-s_{i})^{2}\\Big]\n$$\n来表示。\n你的最终答案必须是 $p(\\tau \\mid x, y)$ 的一个单一闭式解析表达式，作为 $\\tau$、$a$、$b$、$n$ 和 $S$ 的函数。最终答案中不要包含任何等号。不需要进行数值评估。",
            "solution": "该问题是有效的，因为它提出了一个适定且有科学依据的贝叶斯统计问题，提供了一套完整且一致的定义和前提。任务是推导分层模型中参数的后验分布，这是该领域的标准程序。\n\n目标是推导精度参数 $\\tau$ 的后验概率密度函数 (PDF) $p(\\tau \\mid x, y)$。根据贝叶斯定理，后验密度与似然函数和先验密度的乘积成正比：\n$$\np(\\tau \\mid x, y) \\propto p(x, y \\mid \\tau) p(\\tau)\n$$\n此处，对已知背景状态 $\\{s_i\\}$ 的依赖性隐含在似然项中。我们将分别推导右侧的每个分量。\n\n首先，我们构建似然函数 $p(x, y \\mid \\tau)$。问题陈述，对于 $i=1, \\dots, n$，观测值 $x_i$ 和 $y_i$ 在给定状态 $s_i$ 和精度 $\\tau$ 的条件下是条件独立的。完整的观测集由 $2n$ 个独立测量组成。总似然是所有观测值的单个概率密度的乘积。\n对于均值为 $\\mu$、精度为 $\\tau$ 的单个高斯观测值 $z$，其 PDF 由下式给出：\n$$\np(z \\mid \\mu, \\tau) = \\mathcal{N}(z \\mid \\mu, \\tau^{-1}) = \\sqrt{\\frac{\\tau}{2\\pi}} \\exp\\left(-\\frac{\\tau}{2}(z - \\mu)^2\\right)\n$$\n对于我们的观测集 $\\{x_i\\}_{i=1}^{n}$ 和 $\\{y_i\\}_{i=1}^{n}$ 的似然函数为：\n$$\np(x, y \\mid \\tau) = \\left( \\prod_{i=1}^{n} p(x_i \\mid s_i, \\tau) \\right) \\left( \\prod_{i=1}^{n} p(y_i \\mid s_i, \\tau) \\right)\n$$\n将每个项的高斯 PDF 代入：\n$$\np(x, y \\mid \\tau) = \\left( \\prod_{i=1}^{n} \\sqrt{\\frac{\\tau}{2\\pi}} \\exp\\left(-\\frac{\\tau}{2}(x_i - s_i)^2\\right) \\right) \\left( \\prod_{i=1}^{n} \\sqrt{\\frac{\\tau}{2\\pi}} \\exp\\left(-\\frac{\\tau}{2}(y_i - s_i)^2\\right) \\right)\n$$\n这是一个总共 $2n$ 项的乘积。我们可以合并这些项：\n$$\np(x, y \\mid \\tau) = \\left(\\sqrt{\\frac{\\tau}{2\\pi}}\\right)^{2n} \\exp\\left( -\\sum_{i=1}^{n} \\frac{\\tau}{2}(x_i - s_i)^2 - \\sum_{i=1}^{n} \\frac{\\tau}{2}(y_i - s_i)^2 \\right)\n$$\n简化表达式：\n$$\np(x, y \\mid \\tau) = \\left(\\frac{\\tau}{2\\pi}\\right)^{n} \\exp\\left( -\\frac{\\tau}{2} \\sum_{i=1}^{n} \\left[ (x_i - s_i)^2 + (y_i - s_i)^2 \\right] \\right)\n$$\n使用提供的残差和 $S = \\sum_{i=1}^{n}\\Big[(x_{i}-s_{i})^{2} + (y_{i}-s_{i})^{2}\\Big]$ 的定义，似然函数变为：\n$$\np(x, y \\mid \\tau) = \\left(\\frac{1}{2\\pi}\\right)^n \\tau^n \\exp\\left( -\\frac{S}{2} \\tau \\right)\n$$\n为了找到 $\\tau$ 的后验分布，我们可以将任何不依赖于 $\\tau$ 的因子视为比例常数的一部分。似然函数的核是：\n$$\np(x, y \\mid \\tau) \\propto \\tau^n \\exp\\left( -\\frac{S}{2} \\tau \\right)\n$$\n\n接下来，我们考虑 $\\tau$ 的先验分布。问题指定了一个形状参数为 $a$、率参数为 $b$ 的伽马分布：\n$$\np(\\tau) = \\text{Gamma}(\\tau \\mid a, b) = \\frac{b^a}{\\Gamma(a)} \\tau^{a-1} \\exp(-b\\tau)\n$$\n先验分布的核是：\n$$\np(\\tau) \\propto \\tau^{a-1} \\exp(-b\\tau)\n$$\n\n现在我们将似然核与先验核结合，以求得后验分布的核：\n$$\np(\\tau \\mid x, y) \\propto \\left( \\tau^n \\exp\\left( -\\frac{S}{2} \\tau \\right) \\right) \\times \\left( \\tau^{a-1} \\exp(-b\\tau) \\right)\n$$\n$$\np(\\tau \\mid x, y) \\propto \\tau^{n+a-1} \\exp\\left( -\\frac{S}{2} \\tau - b\\tau \\right)\n$$\n$$\np(\\tau \\mid x, y) \\propto \\tau^{(a+n)-1} \\exp\\left( -\\left(b + \\frac{S}{2}\\right) \\tau \\right)\n$$\n这个得到的核可以识别为伽马分布的核。一个具有形状 $\\alpha'$ 和率 $\\beta'$ 的通用伽马 PDF 具有以下形式：\n$$\np(\\tau \\mid \\alpha', \\beta') = \\frac{(\\beta')^{\\alpha'}}{\\Gamma(\\alpha')} \\tau^{\\alpha'-1} \\exp(-\\beta' \\tau)\n$$\n通过将后验核与此形式进行比较，我们可以识别后验分布的参数。后验形状参数 $\\alpha'$ 和率参数 $\\beta'$ 是：\n$$\n\\alpha' = a+n\n$$\n$$\n\\beta' = b + \\frac{S}{2}\n$$\n因此，$\\tau$ 的后验分布是一个伽马分布，$\\tau \\mid x, y \\sim \\text{Gamma}\\left(a+n, b + \\frac{S}{2}\\right)$。\n\n最后一步是通过将这些新参数代入伽马 PDF 公式来写出完整的、归一化的后验密度函数：\n$$\np(\\tau \\mid x, y) = \\frac{\\left(b + \\frac{S}{2}\\right)^{a+n}}{\\Gamma(a+n)} \\tau^{(a+n)-1} \\exp\\left( -\\left(b + \\frac{S}{2}\\right) \\tau \\right)\n$$\n这个表达式是 $\\tau$ 作为给定量的函数的闭式后验密度。",
            "answer": "$$\\boxed{\\frac{\\left(b + \\frac{S}{2}\\right)^{a+n}}{\\Gamma(a+n)} \\tau^{a+n-1} \\exp\\left(- \\left(b + \\frac{S}{2}\\right) \\tau \\right)}$$"
        },
        {
            "introduction": "在建立复杂的融合框架时，我们常常需要对噪声特性等关键假设做出选择。本练习将介绍贝叶斯因子，这是一个用于比较不同模型假设的原则性工具。您将通过计算比较高斯噪声模型和更稳健的学生-$t$分布模型，亲身体会如何量化证据，以应对遥感数据中普遍存在的异常值问题。",
            "id": "3798379",
            "problem": "一个多光谱地球观测（EO）传感器正在一个贝叶斯数据融合框架内进行校准，以将其大气层顶反射率与一个融合参考模型进行协调。假设融合模型提供反射率预测值，并且对于单个波段，在 $N=7$ 个并置点上的残差（观测值减去预测值），以反射率单位表示，为\n$$\nr_{1}=0.021,\\quad r_{2}=-0.034,\\quad r_{3}=0.018,\\quad r_{4}=0.027,\\quad r_{5}=-0.015,\\quad r_{6}=0.031,\\quad r_{7}=0.420.\n$$\n你需要比较针对这些残差的两种噪声模型：\n\n- 模型 $\\mathcal{M}_{G}$（高斯）：残差是独立同分布（i.i.d.）的高斯分布，均值为零，已知标准差为 $\\sigma=0.05$。\n- 模型 $\\mathcal{M}_{T}$（学生t）：残差是独立同分布（i.i.d.）的学生t分布，均值为零，已知自由度为 $\\nu=3$，已知尺度参数为 $s=0.05$。\n\n比较必须通过贝叶斯因子（BF）进行，其定义为边际似然的比值 $BF=\\frac{p(\\mathbf{r}\\mid \\mathcal{M}_{T})}{p(\\mathbf{r}\\mid \\mathcal{M}_{G})}$，其中 $\\mathbf{r}=(r_{1},\\dots,r_{7})$。为了从第一性原理构建 $p(\\mathbf{r}\\mid \\mathcal{M}_{T})$，请使用学生t分布的一个有效的分层表示，即作为具有适当混合分布的高斯尺度混合，并显式地积分掉潜在的讨厌参数。然后，使用得到的 $p(\\mathbf{r}\\mid \\mathcal{M}_{T})$ 和 $p(\\mathbf{r}\\mid \\mathcal{M}_{G})$ 的闭式密度，为所提供的数据计算贝叶斯因子。\n\n在遥感定标中易出现离群值的残差的背景下，解释计算出的贝叶斯因子的含义。贝叶斯因子是无量纲的；请将其报告为一个纯数。将您的最终数值答案四舍五入到三位有效数字。",
            "solution": "问题陈述已经过严格验证，并被认为是有效的。它具有科学依据，是良定的、客观的，并包含推导出唯一且有意义解所需的所有信息。\n\n目标是为一个给定的残差集 $\\mathbf{r}=(r_{1},\\dots,r_{7})$，计算比较学生t噪声模型（$\\mathcal{M}_{T}$）和高斯噪声模型（$\\mathcal{M}_{G}$）的贝叶斯因子（BF）。贝叶斯因子定义为它们的边际似然之比：\n$$\nBF=\\frac{p(\\mathbf{r}\\mid \\mathcal{M}_{T})}{p(\\mathbf{r}\\mid \\mathcal{M}_{G})}\n$$\n提供的数据是 $N=7$ 个残差：$r_{1}=0.021$, $r_{2}=-0.034$, $r_{3}=0.018$, $r_{4}=0.027$, $r_{5}=-0.015$, $r_{6}=0.031$, 以及 $r_{7}=0.420$。\n\n首先，我们构建高斯模型 $\\mathcal{M}_{G}$ 的边际似然。在此模型下，残差 $r_i$ 独立同分布（i.i.d.），服从均值为 $0$、已知标准差为 $\\sigma=0.05$ 的高斯分布。单个残差 $r_i$ 的概率密度函数（PDF）为：\n$$\np(r_i \\mid \\mathcal{M}_G) = \\mathcal{N}(r_i \\mid 0, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{r_i^2}{2\\sigma^2}\\right)\n$$\n由于残差是独立同分布的，向量 $\\mathbf{r}$ 的联合似然是各个似然的乘积：\n$$\np(\\mathbf{r} \\mid \\mathcal{M}_G) = \\prod_{i=1}^{N} p(r_i \\mid \\mathcal{M}_G) = \\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right)^N \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} r_i^2\\right)\n$$\n该表达式即为边际似然，因为所有参数（$\\sigma$）都是已知的。\n\n接下来，我们构建学生t模型 $\\mathcal{M}_{T}$ 的边际似然。题目要求从学生t分布作为高斯尺度混合的分层表示中推导。如果一个随机变量 $r_i$ 按如下方式分层生成，那么它就服从位置参数为 $0$、自由度为 $\\nu$、尺度参数为 $s$ 的学生t分布：\n1. 一个潜在的精度-尺度变量 $\\lambda_i$ 从伽马分布中抽取：$\\lambda_i \\sim \\text{Gamma}(\\frac{\\nu}{2}, \\frac{\\nu}{2})$。\n2. 残差 $r_i$ 从一个高斯分布中抽取，其方差由 $\\lambda_i$ 缩放：$r_i \\mid \\lambda_i \\sim \\mathcal{N}(0, \\frac{s^2}{\\lambda_i})$。\n\n伽马分布的PDF为 $p(\\lambda_i) = \\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)} \\lambda_i^{\\nu/2 - 1} \\exp(-\\frac{\\nu}{2}\\lambda_i)$。$r_i$ 的条件PDF为 $p(r_i \\mid \\lambda_i) = \\sqrt{\\frac{\\lambda_i}{2\\pi s^2}} \\exp(-\\frac{\\lambda_i r_i^2}{2s^2})$。\n\n为了求得单个残差的边际似然 $p(r_i \\mid \\mathcal{M}_T)$，我们积分掉潜在变量 $\\lambda_i$：\n$$\np(r_i \\mid \\mathcal{M}_T) = \\int_{0}^{\\infty} p(r_i \\mid \\lambda_i) p(\\lambda_i) d\\lambda_i\n$$\n$$\np(r_i \\mid \\mathcal{M}_T) = \\int_{0}^{\\infty} \\left(\\sqrt{\\frac{\\lambda_i}{2\\pi s^2}}\\right) \\exp\\left(-\\frac{\\lambda_i r_i^2}{2s^2}\\right) \\left(\\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)} \\lambda_i^{\\nu/2 - 1} \\exp\\left(-\\frac{\\nu}{2}\\lambda_i\\right)\\right) d\\lambda_i\n$$\n$$\np(r_i \\mid \\mathcal{M}_T) = \\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)\\sqrt{2\\pi s^2}} \\int_{0}^{\\infty} \\lambda_i^{(\\frac{\\nu+1}{2}) - 1} \\exp\\left(-\\lambda_i \\left(\\frac{r_i^2}{2s^2} + \\frac{\\nu}{2}\\right)\\right) d\\lambda_i\n$$\n该积分是伽马分布的核。回顾 $\\int_0^\\infty x^{\\alpha-1} e^{-\\beta x} dx = \\frac{\\Gamma(\\alpha)}{\\beta^\\alpha}$，我们可以令 $\\alpha = (\\nu+1)/2$ 和 $\\beta = (r_i^2/(2s^2) + \\nu/2)$ 来解该积分。\n$$\np(r_i \\mid \\mathcal{M}_T) = \\frac{(\\nu/2)^{\\nu/2}}{\\Gamma(\\nu/2)\\sqrt{2\\pi s^2}} \\frac{\\Gamma((\\nu+1)/2)}{\\left(\\frac{r_i^2}{2s^2} + \\frac{\\nu}{2}\\right)^{(\\nu+1)/2}}\n$$\n化简此表达式可得到学生t分布的PDF：\n$$\np(r_i \\mid \\mathcal{M}_T) = \\frac{\\Gamma((\\nu+1)/2)}{\\Gamma(\\nu/2) \\sqrt{\\nu\\pi} s} \\left(1 + \\frac{1}{\\nu}\\left(\\frac{r_i}{s}\\right)^2\\right)^{-(\\nu+1)/2}\n$$\n在模型 $\\mathcal M_T$ 下，残差也是独立同分布的。因此，联合边际似然是各个密度的乘积：\n$$\np(\\mathbf{r} \\mid \\mathcal{M}_T) = \\prod_{i=1}^{N} \\left[ \\frac{\\Gamma((\\nu+1)/2)}{\\Gamma(\\nu/2) \\sqrt{\\nu\\pi} s} \\left(1 + \\frac{r_i^2}{\\nu s^2}\\right)^{-(\\nu+1)/2} \\right]\n$$\n\n为避免因似然值过小而导致的数值下溢，最好先计算对数似然。\n高斯模型的对数似然为：\n$$\n\\ln p(\\mathbf{r} \\mid \\mathcal{M}_G) = -\\frac{N}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{N} r_i^2\n$$\n学生t模型的对数似然为：\n$$\n\\ln p(\\mathbf{r} \\mid \\mathcal{M}_T) = N \\ln\\left(\\frac{\\Gamma((\\nu+1)/2)}{\\Gamma(\\nu/2) \\sqrt{\\nu\\pi} s}\\right) - \\frac{\\nu+1}{2}\\sum_{i=1}^{N}\\ln\\left(1 + \\frac{r_i^2}{\\nu s^2}\\right)\n$$\n贝叶斯因子的对数为 $\\ln(BF) = \\ln p(\\mathbf{r} \\mid \\mathcal{M}_T) - \\ln p(\\mathbf{r} \\mid \\mathcal{M}_G)$。\n\n现在，我们代入数值。\n对于两个模型，$N=7$。\n残差平方和为：\n$\\sum_{i=1}^{7} r_i^2 = (0.021)^2 + (-0.034)^2 + (0.018)^2 + (0.027)^2 + (-0.015)^2 + (0.031)^2 + (0.420)^2$\n$\\sum_{i=1}^{7} r_i^2 = 0.000441 + 0.001156 + 0.000324 + 0.000729 + 0.000225 + 0.000961 + 0.1764 = 0.180236$。\n\n对于 $\\mathcal{M}_{G}$：$\\sigma=0.05$，所以 $\\sigma^2=0.0025$。\n$\\ln p(\\mathbf{r} \\mid \\mathcal{M}_G) = -\\frac{7}{2}\\ln(2\\pi \\times 0.0025) - \\frac{1}{2 \\times 0.0025} (0.180236)$\n$\\ln p(\\mathbf{r} \\mid \\mathcal{M}_G) = -3.5\\ln(0.015708) - 200 \\times 0.180236$\n$\\ln p(\\mathbf{r} \\mid \\mathcal{M}_G) \\approx -3.5 \\times (-4.15333) - 36.0472 \\approx 14.53666 - 36.0472 = -21.51054$。\n\n对于 $\\mathcal{M}_{T}$：$\\nu=3$，$s=0.05$。\n对数似然的常数部分是：\n$N \\ln\\left(\\frac{\\Gamma((3+1)/2)}{\\Gamma(3/2) \\sqrt{3\\pi} \\times 0.05}\\right) = 7 \\ln\\left(\\frac{\\Gamma(2)}{\\Gamma(1.5) \\sqrt{3\\pi} \\times 0.05}\\right)$\n使用 $\\Gamma(2)=1$ 和 $\\Gamma(1.5)=\\sqrt{\\pi}/2$：\n$7 \\ln\\left(\\frac{1}{(\\sqrt{\\pi}/2) \\sqrt{3\\pi} \\times 0.05}\\right) = 7 \\ln\\left(\\frac{2}{\\pi\\sqrt{3} \\times 0.05}\\right) = 7 \\ln\\left(\\frac{40}{\\pi\\sqrt{3}}\\right)$\n$7 \\ln(7.35104) \\approx 7 \\times 1.99484 \\approx 13.96388$。\n求和部分，其中 $\\nu s^2 = 3 \\times (0.05)^2 = 0.0075$：\n$-\\frac{3+1}{2} \\sum_{i=1}^{7}\\ln\\left(1 + \\frac{r_i^2}{0.0075}\\right) = -2 \\sum_{i=1}^{7}\\ln\\left(1 + \\frac{r_i^2}{0.0075}\\right)$\n求和中的各项是：\n$\\ln(1+0.021^2/0.0075) \\approx 0.05713$\n$\\ln(1+(-0.034)^2/0.0075) \\approx 0.14336$\n$\\ln(1+0.018^2/0.0075) \\approx 0.04229$\n$\\ln(1+0.027^2/0.0075) \\approx 0.09276$\n$\\ln(1+(-0.015)^2/0.0075) \\approx 0.02956$\n$\\ln(1+0.031^2/0.0075) \\approx 0.12056$\n$\\ln(1+0.420^2/0.0075) = \\ln(1+23.52) \\approx 3.19946$\n和约为 $\\approx 3.68512$。\n所以，对数似然的这一部分是 $-2 \\times 3.68512 = -7.37024$。\n$\\ln p(\\mathbf{r} \\mid \\mathcal{M}_T) \\approx 13.96388 - 7.37024 = 6.59364$。\n\n现在，我们计算对数贝叶斯因子：\n$\\ln(BF) = \\ln p(\\mathbf{r} \\mid \\mathcal{M}_T) - \\ln p(\\mathbf{r} \\mid \\mathcal{M}_G) \\approx 6.59364 - (-21.51054) = 28.10418$\n贝叶斯因子为：\n$BF = \\exp(28.10418) \\approx 1.5973 \\times 10^{12}$。\n四舍五入到三位有效数字，我们得到 $1.60 \\times 10^{12}$。\n\n贝叶斯因子的极大值提供了压倒性的证据，支持学生t模型（$\\mathcal{M}_{T}$）优于高斯模型（$\\mathcal{M}_{G}$）。这是数据中包含一个显著离群值 $r_{7}=0.420$ 的直接结果。其他残差都在均值（$0$）的大约一个标准差（$\\sigma=0.05$）范围内，但 $r_7$ 距离均值有 $0.420/0.05 = 8.4$ 个标准差。\n高斯分布具有指数衰减的尾部，这意味着它对此类极端事件分配了极低的概率。这单个离群值使得整个数据集在高斯模型下变得极不可能，从而严重惩罚了其边际似然。\n相比之下，学生t分布具有更重的、多项式衰减的尾部。它是一种稳健的分布，可以通过为离群值分配一个虽小但并非天文数字般小的概率来容纳它们。在重尾的学生t模型下，离群值 $r_7$ 的合理性远高于在瘦尾的高斯模型下。\n在遥感定标的背景下，这一结果凸显了稳健统计建模的重要性。来自地球观测传感器的数据经常受到未建模效应（例如，未检测到的云、气溶胶羽流、地表异常）的污染，这些效应在残差中表现为离群值。使用标准高斯噪声模型可能导致模型拟合不佳和有偏的定标参数，因为模型会受到离群值不成比例的影响。对学生t模型的强烈偏好表明，采用稳健的重尾噪声模型能更忠实地描述数据，防止离群值扭曲定标结果，从而得出更可靠的科学结论。",
            "answer": "$$\n\\boxed{1.60 \\times 10^{12}}\n$$"
        },
        {
            "introduction": "一个完整的贝叶斯模型通常涉及先验分布中的超参数，但这些参数的取值本身可能并不确定。本练习将介绍经验贝叶斯方法，也称为第二类最大似然法，它利用数据本身来估计这些超参数。通过推导并最大化边际似然函数，您将学会一种数据驱动的方法来设定先验，从而在贝叶斯和频率主义思想之间架起一座桥梁。",
            "id": "3798344",
            "problem": "一个基于卫星的遥感系统测量两个地点的近地表气温异常，该过程在一个贝叶斯数据融合框架内建模，该框架将一个基于过程的陆面模型与带噪声的观测数据相结合。令 $x \\in \\mathbb{R}^{n}$ 表示潜在模型状态（以开尔文为单位的温度异常），令 $y \\in \\mathbb{R}^{m}$ 表示卫星观测值（也以开尔文为单位）。假设线性高斯数据融合模型为\n$$\ny = H x + \\varepsilon,\n$$\n其中 $H \\in \\mathbb{R}^{m \\times n}$ 是一个已知的线性观测算子，$x \\sim \\mathcal{N}(0, \\sigma^{2} K)$，其中 $K \\in \\mathbb{R}^{n \\times n}$ 是已知的半正定矩阵，$\\sigma^{2} > 0$ 是未知的标量振幅，$\\varepsilon \\sim \\mathcal{N}(0, R)$，其中 $R \\in \\mathbb{R}^{m \\times m}$ 是未知的正定观测误差协方差。超参数为 $\\theta = \\{\\sigma^{2}, R\\}$。\n\n1) 从多元正态分布的定义和对联合高斯向量进行边缘化的规则出发，推导边际似然 $p(y \\mid \\theta)$，并用协方差 $S(\\theta)$ 表示。\n\n2) 写出对数边际似然，并推导其关于 $\\sigma^{2}$ 和 $R$ 的梯度（使用矩阵微积分），从而说明如何通过最大化边际似然来获得经验贝叶斯估计 $\\hat{\\theta}$。\n\n3) 考虑一个科学上现实的特殊情况，即两个地点 ($m = n = 2$)，观测算子为单位矩阵 $H = I_{2}$，对角结构 $K = \\operatorname{diag}(k_{1}, k_{2})$，其中 $k_{1} = 0.5$ 和 $k_{2} = 2.5$（无量纲结构权重），以及同方差的观测误差协方差 $R = \\rho I_{2}$，其中未知的 $\\rho > 0$（单位为 $\\mathrm{K}^{2}$）。观测到的异常值为 $y = (0.8, 1.4)^{\\top}$（单位为开尔文）。使用你在第(1)–(2)部分得到的结果，求出此情况下的经验贝叶斯估计值 $\\hat{\\sigma}^{2}$ 和 $\\hat{\\rho}$。将你的数值估计四舍五入到三位有效数字。最终的方差以 $\\mathrm{K}^{2}$ 为单位表示。",
            "solution": "所述问题具有科学依据，是适定的、客观的且内部一致的。它描述了经验贝叶斯（也称为第二类最大似然）在线性高斯模型中的一个标准应用，这是遥感和环境科学领域数据同化和融合框架中的一项常见任务。为得到唯一且有意义的解，所有必要的数据和定义均已提供。因此，该问题被认为是有效的，可以构建一个完整的解。\n\n### 第1部分：边际似然的推导\n\n问题定义了一个分层模型。潜在状态 $x \\in \\mathbb{R}^{n}$ 的先验分布由下式给出：\n$$\np(x \\mid \\sigma^{2}) = \\mathcal{N}(x \\mid 0, \\sigma^{2}K)\n$$\n观测值 $y \\in \\mathbb{R}^{m}$ 通过似然函数与潜在状态 $x$ 相关联：\n$$\np(y \\mid x, R) = \\mathcal{N}(y \\mid Hx, R)\n$$\n其中模型为 $y = Hx + \\varepsilon$，观测误差 $\\varepsilon$ 服从分布 $\\varepsilon \\sim \\mathcal{N}(0, R)$。超参数集合为 $\\theta = \\{\\sigma^{2}, R\\}$。\n\n边际似然 $p(y \\mid \\theta)$ 是通过对潜在状态 $x$ 的所有可能值积分联合分布 $p(y, x \\mid \\theta)$ 得到的：\n$$\np(y \\mid \\theta) = \\int p(y, x \\mid \\theta) \\, dx\n$$\n根据概率的链式法则，联合分布为 $p(y, x \\mid \\theta) = p(y \\mid x, \\theta) p(x \\mid \\theta)$。由于 $y$ 和 $x$ 的分布仅依赖于 $\\theta$ 的特定部分，因此这可以写作 $p(y \\mid x, R) p(x \\mid \\sigma^{2})$。\n$$\np(y \\mid \\theta) = \\int p(y \\mid x, R) p(x \\mid \\sigma^{2}) \\, dx\n$$\n对于线性高斯模型，一种替代且更直接的方法是利用高斯随机向量线性变换的性质。观测值 $y$ 是两个独立高斯随机向量 $x$ 和 $\\varepsilon$ 的线性函数。\n\n首先，我们求出项 $Hx$ 的分布。由于 $x \\sim \\mathcal{N}(0, \\sigma^{2}K)$，线性变换 $Hx$ 也是高斯分布的。其均值为：\n$$\n\\mathbb{E}[Hx] = H \\mathbb{E}[x] = H \\cdot 0 = 0\n$$\n其协方差为：\n$$\n\\text{Cov}(Hx) = H \\text{Cov}(x) H^{\\top} = H (\\sigma^{2}K) H^{\\top} = \\sigma^{2}HKH^{\\top}\n$$\n所以，$Hx \\sim \\mathcal{N}(0, \\sigma^{2}HKH^{\\top})$。\n\n现在，由于 $y = Hx + \\varepsilon$，并且 $x$ 和 $\\varepsilon$ 是独立的，所以 $Hx$ 和 $\\varepsilon$ 也是独立的。$y$ 的分布是高斯分布。其均值是均值之和：\n$$\n\\mathbb{E}[y \\mid \\theta] = \\mathbb{E}[Hx] + \\mathbb{E}[\\varepsilon] = 0 + 0 = 0\n$$\n其协方差是协方差之和：\n$$\n\\text{Cov}(y \\mid \\theta) = \\text{Cov}(Hx) + \\text{Cov}(\\varepsilon) = \\sigma^{2}HKH^{\\top} + R\n$$\n我们定义边际协方差矩阵为 $S(\\theta) = \\sigma^{2}HKH^{\\top} + R$。\n因此，给定超参数 $\\theta$ 的 $y$ 的边际分布是一个均值为零、协方差为 $S(\\theta)$ 的多元正态分布：\n$$\np(y \\mid \\theta) \\sim \\mathcal{N}(y \\mid 0, S(\\theta))\n$$\n作为边际似然的概率密度函数由下式给出：\n$$\np(y \\mid \\theta) = \\frac{1}{(2\\pi)^{m/2} |S(\\theta)|^{1/2}} \\exp\\left(-\\frac{1}{2} y^{\\top} S(\\theta)^{-1} y\\right)\n$$\n\n### 第2部分：对数边际似然和梯度\n\n对数边际似然，记为 $L(\\theta)$，是 $p(y \\mid \\theta)$ 的自然对数：\n$$\nL(\\theta) = \\ln p(y \\mid \\theta) = -\\frac{m}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|S(\\theta)| - \\frac{1}{2}y^{\\top}S(\\theta)^{-1}y\n$$\n其中 $S(\\theta) = \\sigma^{2}HKH^{\\top} + R$。经验贝叶斯估计 $\\hat{\\theta}$ 是通过最大化 $L(\\theta)$ 来找到的，这涉及到将其关于超参数的梯度设为零。\n\n**关于 $\\sigma^{2}$ 的梯度：**\n我们计算 $L(\\theta)$ 关于标量超参数 $\\sigma^{2}$ 的导数。第一项是常数。我们使用两个标准的矩阵微积分恒等式：$\\frac{\\partial}{\\partial \\alpha}\\ln|A| = \\text{Tr}\\left(A^{-1}\\frac{\\partial A}{\\partial \\alpha}\\right)$ 和 $\\frac{\\partial}{\\partial \\alpha} z^{\\top}A^{-1}z = -z^{\\top}A^{-1}\\frac{\\partial A}{\\partial \\alpha}A^{-1}z$。\n$S(\\theta)$ 关于 $\\sigma^{2}$ 的导数是：\n$$\n\\frac{\\partial S(\\theta)}{\\partial \\sigma^{2}} = HKH^{\\top}\n$$\n对数行列式项的导数是：\n$$\n\\frac{\\partial}{\\partial \\sigma^{2}} \\ln|S(\\theta)| = \\text{Tr}\\left(S(\\theta)^{-1} \\frac{\\partial S(\\theta)}{\\partial \\sigma^{2}}\\right) = \\text{Tr}\\left(S(\\theta)^{-1}HKH^{\\top}\\right)\n$$\n二次型项的导数是：\n$$\n\\frac{\\partial}{\\partial \\sigma^{2}} y^{\\top}S(\\theta)^{-1}y = -y^{\\top}S(\\theta)^{-1}\\left(\\frac{\\partial S(\\theta)}{\\partial \\sigma^{2}}\\right)S(\\theta)^{-1}y = -y^{\\top}S(\\theta)^{-1}HKH^{\\top}S(\\theta)^{-1}y\n$$\n将这些结合起来，对数边际似然关于 $\\sigma^{2}$ 的梯度是：\n$$\n\\frac{\\partial L(\\theta)}{\\partial \\sigma^{2}} = -\\frac{1}{2}\\text{Tr}\\left(S(\\theta)^{-1}HKH^{\\top}\\right) - \\frac{1}{2}\\left(-y^{\\top}S(\\theta)^{-1}HKH^{\\top}S(\\theta)^{-1}y\\right)\n$$\n$$\n\\frac{\\partial L(\\theta)}{\\partial \\sigma^{2}} = \\frac{1}{2}\\left(y^{\\top}S(\\theta)^{-1}HKH^{\\top}S(\\theta)^{-1}y - \\text{Tr}\\left(S(\\theta)^{-1}HKH^{\\top}\\right)\\right)\n$$\n将此梯度设为零，得到求解最优超参数所需的方程之一。\n\n**关于 $R$ 的梯度：**\n我们计算 $L(\\theta)$ 关于矩阵超参数 $R$ 的矩阵导数。我们使用恒等式：$\\frac{\\partial}{\\partial A}\\ln|A| = (A^{-1})^{\\top}$ 和 $\\frac{\\partial}{\\partial A} z^{\\top}A^{-1}z = -(A^{-1}zz^{\\top}A^{-1})^{\\top}$。由于 $S(\\theta)$ 是对称的，其逆矩阵也是对称的。\n$S(\\theta)$ 关于 $R$ 的导数是适当维度的单位矩阵，$\\frac{\\partial S(\\theta)}{\\partial R} = I$。\n对数行列式项的导数是：\n$$\n\\frac{\\partial}{\\partial R} \\ln|S(\\theta)| = (S(\\theta)^{-1})^{\\top} = S(\\theta)^{-1}\n$$\n二次型项的导数是：\n$$\n\\frac{\\partial}{\\partial R} y^{\\top}S(\\theta)^{-1}y = -(S(\\theta)^{-1}yy^{\\top}S(\\theta)^{-1})^{\\top} = -S(\\theta)^{-1}yy^{\\top}S(\\theta)^{-1}\n$$\n将这些结合起来，对数边际似然关于 $R$ 的梯度是：\n$$\n\\frac{\\partial L(\\theta)}{\\partial R} = -\\frac{1}{2}S(\\theta)^{-1} - \\frac{1}{2}\\left(-S(\\theta)^{-1}yy^{\\top}S(\\theta)^{-1}\\right)\n$$\n$$\n\\frac{\\partial L(\\theta)}{\\partial R} = \\frac{1}{2}\\left(S(\\theta)^{-1}yy^{\\top}S(\\theta)^{-1} - S(\\theta)^{-1}\\right)\n$$\n将此梯度设为零，得到 $S(\\theta)^{-1}yy^{\\top}S(\\theta)^{-1} = S(\\theta)^{-1}$。前后同乘以 $S(\\theta)$ 得到 $yy^{\\top} = S(\\theta)$。\n经验贝叶斯估计 $\\hat{\\theta} = \\{\\hat{\\sigma}^{2}, \\hat{R}\\}$ 是通过同时求解这些梯度为零所产生的方程组得到的。\n\n### 第3部分：特殊情况与数值估计\n\n对于这个特殊情况，我们已知：\n- $m = n = 2$\n- $H = I_{2}$ ($2 \\times 2$ 单位矩阵)\n- $K = \\text{diag}(k_{1}, k_{2}) = \\text{diag}(0.5, 2.5)$\n- $R = \\rho I_{2}$，其中标量 $\\rho > 0$ 未知\n- $y = (0.8, 1.4)^{\\top}$\n\n边际协方差 $S$ 简化为：\n$$\nS(\\theta) = \\sigma^{2}I_{2} K I_{2}^{\\top} + \\rho I_{2} = \\sigma^{2}K + \\rho I_{2}\n$$\n由于 $K$ 和 $I_{2}$ 都是对角矩阵，$S$ 也是对角矩阵：\n$$\nS = \\sigma^{2}\\begin{pmatrix} 0.5 & 0 \\\\ 0 & 2.5 \\end{pmatrix} + \\rho\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0.5\\sigma^2 + \\rho & 0 \\\\ 0 & 2.5\\sigma^2 + \\rho \\end{pmatrix}\n$$\n令 $s_{1} = 0.5\\sigma^2 + \\rho$ 且 $s_{2} = 2.5\\sigma^2 + \\rho$。所以，$S = \\text{diag}(s_{1}, s_{2})$。\n对数边际似然变为：\n$$\nL(\\sigma^{2}, \\rho) = -\\ln(2\\pi) - \\frac{1}{2}(\\ln(s_{1}) + \\ln(s_{2})) - \\frac{1}{2}\\left(\\frac{y_{1}^{2}}{s_{1}} + \\frac{y_{2}^{2}}{s_{2}}\\right)\n$$\n我们需要求出关于 $\\sigma^{2}$ 和 $\\rho$ 的梯度，并令它们为零。\n\n关于 $\\rho$ 的导数：\n$$\n\\frac{\\partial L}{\\partial \\rho} = -\\frac{1}{2}\\left(\\frac{1}{s_{1}}\\frac{\\partial s_{1}}{\\partial \\rho} + \\frac{1}{s_{2}}\\frac{\\partial s_{2}}{\\partial \\rho}\\right) - \\frac{1}{2}\\left(-\\frac{y_{1}^{2}}{s_{1}^{2}}\\frac{\\partial s_{1}}{\\partial \\rho} - \\frac{y_{2}^{2}}{s_{2}^{2}}\\frac{\\partial s_{2}}{\\partial \\rho}\\right)\n$$\n因为 $\\frac{\\partial s_{1}}{\\partial \\rho} = 1$ 且 $\\frac{\\partial s_{2}}{\\partial \\rho} = 1$，令 $\\frac{\\partial L}{\\partial \\rho} = 0$ 可得：\n$$\n\\left(\\frac{y_{1}^{2}}{s_{1}^{2}} - \\frac{1}{s_{1}}\\right) + \\left(\\frac{y_{2}^{2}}{s_{2}^{2}} - \\frac{1}{s_{2}}\\right) = 0\n$$\n\n关于 $\\sigma^{2}$ 的导数：\n$$\n\\frac{\\partial L}{\\partial \\sigma^{2}} = -\\frac{1}{2}\\left(\\frac{1}{s_{1}}\\frac{\\partial s_{1}}{\\partial \\sigma^{2}} + \\frac{1}{s_{2}}\\frac{\\partial s_{2}}{\\partial \\sigma^{2}}\\right) - \\frac{1}{2}\\left(-\\frac{y_{1}^{2}}{s_{1}^{2}}\\frac{\\partial s_{1}}{\\partial \\sigma^{2}} - \\frac{y_{2}^{2}}{s_{2}^{2}}\\frac{\\partial s_{2}}{\\partial \\sigma^{2}}\\right)\n$$\n使用 $\\frac{\\partial s_{1}}{\\partial \\sigma^{2}} = k_{1} = 0.5$ 且 $\\frac{\\partial s_{2}}{\\partial \\sigma^{2}} = k_{2} = 2.5$，令 $\\frac{\\partial L}{\\partial \\sigma^{2}} = 0$ 可得：\n$$\nk_{1}\\left(\\frac{y_{1}^{2}}{s_{1}^{2}} - \\frac{1}{s_{1}}\\right) + k_{2}\\left(\\frac{y_{2}^{2}}{s_{2}^{2}} - \\frac{1}{s_{2}}\\right) = 0\n$$\n\n令 $z_{i} = \\frac{y_{i}^{2}}{s_{i}^{2}} - \\frac{1}{s_{i}}$，对于 $i=1,2$。方程组为：\n$$\n\\begin{cases} z_{1} + z_{2} = 0 \\\\ k_{1}z_{1} + k_{2}z_{2} = 0 \\end{cases} \\implies \\begin{pmatrix} 1 & 1 \\\\ k_{1} & k_{2} \\end{pmatrix} \\begin{pmatrix} z_{1} \\\\ z_{2} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n系数矩阵的行列式是 $k_{2} - k_{1} = 2.5 - 0.5 = 2.0 \\neq 0$。由于该矩阵是可逆的，这个齐次线性方程组的唯一解是平凡解，即 $z_{1} = 0$ 和 $z_{2} = 0$。\n\n对于 $z_{1} = 0$：\n$$\n\\frac{y_{1}^{2}}{s_{1}^{2}} - \\frac{1}{s_{1}} = 0 \\implies \\frac{1}{s_{1}}\\left(\\frac{y_{1}^{2}}{s_{1}} - 1\\right) = 0\n$$\n由于 $s_{1}$ 必须为正（它是一个方差），这意味着 $\\frac{y_{1}^{2}}{s_{1}} = 1$，或 $s_{1} = y_{1}^{2}$。\n\n对于 $z_{2} = 0$：\n$$\n\\frac{y_{2}^{2}}{s_{2}^{2}} - \\frac{1}{s_{2}} = 0 \\implies s_{2} = y_{2}^{2}\n$$\n所以我们得到了经验贝叶斯估计的条件 $s_{1} = y_{1}^{2}$ 和 $s_{2} = y_{2}^{2}$。代入 $s_{1}$ 和 $s_{2}$ 的定义：\n$$\n0.5\\hat{\\sigma}^2 + \\hat{\\rho} = y_{1}^{2}\n$$\n$$\n2.5\\hat{\\sigma}^2 + \\hat{\\rho} = y_{2}^{2}\n$$\n我们已知 $y = (0.8, 1.4)^{\\top}$，所以 $y_{1}^{2} = 0.8^{2} = 0.64$ 且 $y_{2}^{2} = 1.4^{2} = 1.96$。\n我们求解关于 $\\hat{\\sigma}^{2}$ 和 $\\hat{\\rho}$ 的线性方程组：\n$$\n0.5\\hat{\\sigma}^2 + \\hat{\\rho} = 0.64 \\quad (1)\n$$\n$$\n2.5\\hat{\\sigma}^2 + \\hat{\\rho} = 1.96 \\quad (2)\n$$\n方程(2)减去方程(1)：\n$$\n(2.5 - 0.5)\\hat{\\sigma}^2 = 1.96 - 0.64\n$$\n$$\n2.0\\hat{\\sigma}^2 = 1.32\n$$\n$$\n\\hat{\\sigma}^2 = \\frac{1.32}{2.0} = 0.66\n$$\n将此值代回方程(1)：\n$$\n0.5(0.66) + \\hat{\\rho} = 0.64\n$$\n$$\n0.33 + \\hat{\\rho} = 0.64\n$$\n$$\n\\hat{\\rho} = 0.64 - 0.33 = 0.31\n$$\n经验贝叶斯估计值为 $\\hat{\\sigma}^2 = 0.66 \\, \\text{K}^2$ 和 $\\hat{\\rho} = 0.31 \\, \\text{K}^2$。两个值都为正，与模型约束一致。四舍五入到三位有效数字，得到：\n$\\hat{\\sigma}^2 = 0.660 \\, \\text{K}^2$\n$\\hat{\\rho} = 0.310 \\, \\text{K}^2$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.660 & 0.310 \\end{pmatrix}}\n$$"
        }
    ]
}