{
    "hands_on_practices": [
        {
            "introduction": "A fundamental step in analyzing SAR imagery is to quantify the level of speckle, a parameter captured by the Equivalent Number of Looks ($L$). This exercise guides you through deriving a standard moment-based estimator for $L$ from local image statistics, a common task in sensor calibration and image quality assessment. You will then explore how this estimate is biased by non-stationarity in the underlying scene, providing critical insight into why adaptive approaches are necessary for robust analysis in real-world scenarios .",
            "id": "3852478",
            "problem": "A two-dimensional intensity image acquired by Synthetic Aperture Radar (SAR) over a nominally homogeneous agricultural field is corrupted by speckle consistent with the multiplicative model. In a rectangular analysis window of size $31 \\times 31$ pixels centered on a portion of the field, the sample mean of the intensity is $\\hat{m} = 0.82$ and the sample variance is $\\hat{v} = 0.21$. Assume multi-look processing under fully developed speckle and that the image values are proportional to radar intensity (not amplitude). Starting from the multiplicative speckle model and the well-established statistical characterization of multi-look SAR intensity for fully developed speckle, derive an estimator for the Equivalent Number of Looks (ENL) solely in terms of the first two moments of the intensity, and then use the provided window statistics to compute a numerical estimate. Round your ENL estimate to four significant figures.\n\nNow suppose that the underlying backscatter field within the same window is not exactly stationary but has a slow linear trend in the mean intensity given by $\\mu(x,y) = \\mu_{0} + g_{x} x + g_{y} y$, where $(x,y)$ are discrete pixel coordinates with the origin at the window center, $x,y \\in \\{-15,-14,\\dots,0,\\dots,14,15\\}$, and the gradients are $g_{x} = 2 \\times 10^{-3}$ and $g_{y} = 2 \\times 10^{-3}$ (intensity per pixel). Using first principles of spatial moment analysis, derive an expression for the additional deterministic variance across the window induced by this trend, and explain how this nonstationarity biases the ENL estimator obtained from the first two moments.\n\nFinally, discuss qualitatively and quantitatively (by deriving a symbolic expression) how random texture in the backscatter, modeled as an independent stationary random field with mean $\\mu_{X}$ and variance $\\sigma_{X}^{2}$, alters the relationship between ENL and the first two moments of the observed intensity under the multiplicative model. You may assume the speckle component has unit mean and variance equal to the reciprocal of the number of looks. You do not need to report any bias expressions in the final boxed answer; only the ENL estimate computed from the provided window statistics should be given, rounded to four significant figures and expressed without units.",
            "solution": "The problem as stated is scientifically grounded, well-posed, internally consistent, and contains sufficient information to derive the requested quantities. The problem uses established models from Synthetic Aperture Radar (SAR) signal processing, namely the multiplicative model for speckle, the Gamma distribution for multi-look intensity, and standard statistical methods for parameter estimation and bias analysis. The parameters provided are physically realistic. Therefore, the problem is valid and a solution can be derived.\n\nThe problem is addressed in three parts: first, deriving and calculating the Equivalent Number of Looks (ENL) for a homogeneous scene; second, analyzing the bias introduced by a deterministic trend in the mean backscatter; and third, analyzing the effect of random texture in the backscatter.\n\n**Part 1: ENL Estimation in a Homogeneous Scene**\n\nThe multiplicative model for speckle in an intensity SAR image is given by:\n$$I = X \\cdot S$$\nwhere $I$ is the measured pixel intensity, $X$ is the true radar backscatter of the scene, and $S$ is the speckle noise. For a nominally homogeneous region, the true backscatter $X$ is assumed to be constant, a value we denote as $\\mu$. Thus, $I = \\mu \\cdot S$.\n\nFor multi-look, fully developed speckle, the noise component $S$ is well-modeled by a Gamma distribution with a probability density function:\n$$p(s) = \\frac{L^L}{\\Gamma(L)} s^{L-1} \\exp(-Ls), \\quad s \\ge 0$$\nwhere $L$ is the Equivalent Number of Looks (ENL). For this distribution to be properly normalized for the multiplicative model, it is standard to set its mean to unity. The moments of this Gamma distribution are:\n$$E[S] = 1$$\n$$\\operatorname{Var}(S) = \\frac{1}{L}$$\n\nUsing these properties, we can find the first two a-priori moments of the observed intensity $I$:\nThe mean of the observed intensity is:\n$$E[I] = E[\\mu \\cdot S] = \\mu \\cdot E[S] = \\mu \\cdot 1 = \\mu$$\nThe variance of the observed intensity is:\n$$\\operatorname{Var}(I) = \\operatorname{Var}(\\mu \\cdot S) = \\mu^2 \\cdot \\operatorname{Var}(S) = \\frac{\\mu^2}{L}$$\n\nFrom these two relationships, we can derive an expression for $L$. By substituting $\\mu = E[I]$ into the variance equation, we get:\n$$\\operatorname{Var}(I) = \\frac{(E[I])^2}{L}$$\nRearranging for $L$ yields:\n$$L = \\frac{(E[I])^2}{\\operatorname{Var}(I)}$$\nThis is a moment-based estimator for the ENL. We can apply this formula to the sample statistics provided from the analysis window. The sample mean $\\hat{m}$ is an estimator for $E[I]$, and the sample variance $\\hat{v}$ is an estimator for $\\operatorname{Var}(I)$. Therefore, the estimate for the ENL, denoted $\\hat{L}$, is:\n$$\\hat{L} = \\frac{\\hat{m}^2}{\\hat{v}}$$\nThe problem provides the sample statistics from a $31 \\times 31$ pixel window: $\\hat{m} = 0.82$ and $\\hat{v} = 0.21$. Substituting these values into the estimator:\n$$\\hat{L} = \\frac{(0.82)^2}{0.21} = \\frac{0.6724}{0.21} \\approx 3.20190476...$$\nRounding to four significant figures as requested, the estimated ENL is $3.202$.\n\n**Part 2: Bias due to a Non-stationary Mean**\n\nNow, we consider the case where the underlying backscatter is not stationary but exhibits a slow linear trend across the analysis window. The mean intensity is given by $\\mu(x,y) = \\mu_{0} + g_{x} x + g_{y} y$, where $(x,y)$ are the centered pixel coordinates. The observed intensity at each pixel is $I(x,y) = \\mu(x,y) \\cdot S(x,y)$, where $S(x,y)$ is a stationary speckle field with $E[S]=1$ and $\\operatorname{Var}(S)=1/L$.\n\nThe total measured variance in the window, $\\hat{v}$, now captures variance from two sources: the speckle noise and the deterministic variation of the mean. We can formalize this using the law of total variance. If we consider the pixels in the window as a population, the total variance of $I$ is:\n$$\\operatorname{Var}(I) = E_{\\text{spatial}}[\\operatorname{Var}(I|\\mu)] + \\operatorname{Var}_{\\text{spatial}}(E[I|\\mu])$$\nThe conditional moments at a given location $(x,y)$ are:\n$$E[I|\\mu(x,y)] = E[\\mu(x,y) S] = \\mu(x,y)E[S] = \\mu(x,y)$$\n$$\\operatorname{Var}(I|\\mu(x,y)) = \\operatorname{Var}(\\mu(x,y) S) = \\mu(x,y)^2 \\operatorname{Var}(S) = \\frac{\\mu(x,y)^2}{L}$$\nThe total variance is the spatial average of these quantities over the window. Let $\\langle \\cdot \\rangle$ denote the spatial average operator over all pixels in the window.\n$$Var_{\\text{total}} = \\left\\langle \\frac{\\mu(x,y)^2}{L} \\right\\rangle + \\operatorname{Var}(\\mu(x,y))$$\nwhere $\\operatorname{Var}(\\mu(x,y)) = \\langle \\mu(x,y)^2 \\rangle - \\langle \\mu(x,y) \\rangle^2$.\n\nThe \"additional deterministic variance\" is precisely this second term, $\\operatorname{Var}(\\mu(x,y))$. Let's derive it. The window size is $N \\times N$ with $N=31$. The coordinates run from $-K$ to $K$, where $K=(N-1)/2 = 15$.\nThe spatial mean of $\\mu(x,y)$ is:\n$$\\langle \\mu(x,y) \\rangle = \\frac{1}{N^2} \\sum_{x=-K}^{K} \\sum_{y=-K}^{K} (\\mu_{0} + g_{x} x + g_{y} y)$$\nDue to symmetry, $\\sum_{i=-K}^{K} i = 0$. Thus, $\\langle \\mu(x,y) \\rangle = \\mu_0$. The sample mean $\\hat{m}$ estimates this central value $\\mu_0$.\nThe variance of the mean is:\n$$\\operatorname{Var}(\\mu) = \\langle (\\mu(x,y) - \\mu_0)^2 \\rangle = \\langle (g_{x} x + g_{y} y)^2 \\rangle = \\langle g_{x}^2 x^2 + g_{y}^2 y^2 + 2g_{x}g_{y}xy \\rangle$$\n$$\\operatorname{Var}(\\mu) = g_{x}^2 \\langle x^2 \\rangle + g_{y}^2 \\langle y^2 \\rangle + 2g_{x}g_{y} \\langle xy \\rangle$$\nThe average of the cross-term is zero: $\\langle xy \\rangle = (\\frac{1}{N}\\sum_x x)(\\frac{1}{N}\\sum_y y) = 0$.\nThe term $\\langle x^2 \\rangle$ is the spatial average of $x^2$ over the window, which due to separability is just the average over one dimension:\n$$\\langle x^2 \\rangle = \\frac{1}{N} \\sum_{i=-K}^{K} i^2 = \\frac{1}{2K+1} \\left( 2 \\sum_{i=1}^{K} i^2 \\right) = \\frac{2}{2K+1} \\frac{K(K+1)(2K+1)}{6} = \\frac{K(K+1)}{3}$$\nWith $K=15$, $\\langle x^2 \\rangle = \\langle y^2 \\rangle = \\frac{15(16)}{3} = 80$.\nThe additional deterministic variance is therefore:\n$$\\operatorname{Var}(\\mu) = (g_{x}^2 + g_{y}^2) \\frac{K(K+1)}{3}$$\nWith the given gradients $g_x = g_y = 2 \\times 10^{-3}$, this variance is $((2 \\times 10^{-3})^2 + (2 \\times 10^{-3})^2) \\times 80 = (8 \\times 10^{-6}) \\times 80 = 6.4 \\times 10^{-4}$.\n\nThe simple ENL estimator $\\hat{L} = \\hat{m}^2/\\hat{v}$ uses the total measured variance $\\hat{v}$ in the denominator. This total variance is approximately $\\hat{v} \\approx \\frac{\\mu_0^2}{L} + \\operatorname{Var}(\\mu)$. The estimator becomes:\n$$\\hat{L}_{\\text{biased}} = \\frac{\\mu_0^2}{\\frac{\\mu_0^2}{L} + \\operatorname{Var}(\\mu)}$$\nSince $\\operatorname{Var}(\\mu) > 0$, the denominator is larger than $\\mu_0^2/L$. This means $\\hat{L}_{\\text{biased}} < L$. The presence of the deterministic trend adds variance that is not due to speckle. The simple estimator misinterprets this additional variance as more intense speckle noise, leading to an underestimation of the true ENL, $L$.\n\n**Part 3: Effect of Random Texture**\n\nFinally, we consider a scene where the backscatter $X$ is itself a random field, independent of the speckle $S$. We assume $X$ is stationary with mean $\\mu_X$ and variance $\\sigma_X^2$. Speckle $S$ has $E[S]=1$ and $\\operatorname{Var}(S)=1/L$. The observed intensity is $I = X \\cdot S$.\n\nThe mean of the observed intensity is:\n$$E[I] = E[X \\cdot S] = E[X] E[S] = \\mu_X \\cdot 1 = \\mu_X$$\nTo find the variance, we use the property for the product of two independent random variables $Y$ and $Z$: $\\operatorname{Var}(YZ) = E[Y^2]E[Z^2] - (E[Y]E[Z])^2$.\nWe have $E[X^2] = \\operatorname{Var}(X) + (E[X])^2 = \\sigma_X^2 + \\mu_X^2$, and $E[S^2] = \\operatorname{Var}(S) + (E[S])^2 = 1/L + 1^2 = 1 + 1/L$.\nThus, the second moment of $I$ is:\n$$E[I^2] = E[X^2]E[S^2] = (\\sigma_X^2 + \\mu_X^2)(1+1/L)$$\nThe variance of $I$ is:\n$$\\operatorname{Var}(I) = E[I^2] - (E[I])^2 = (\\sigma_X^2 + \\mu_X^2)(1+1/L) - \\mu_X^2$$\n$$\\operatorname{Var}(I) = \\sigma_X^2 + \\frac{\\sigma_X^2}{L} + \\mu_X^2 + \\frac{\\mu_X^2}{L} - \\mu_X^2 = \\frac{\\mu_X^2}{L} + \\sigma_X^2(1 + \\frac{1}{L})$$\nThis expression shows that the total variance is the sum of the pure speckle variance term ($\\mu_X^2/L$) and a term related to the texture variance $\\sigma_X^2$.\n\nA more insightful way to express this relationship is through the squared coefficient of variation, $C^2 = Var/Mean^2$.\nFor the observed intensity $I$: $C_I^2 = \\frac{\\operatorname{Var}(I)}{(E[I])^2}$.\nFor the texture $X$: $C_X^2 = \\frac{\\sigma_X^2}{\\mu_X^2}$.\nFor the speckle $S$: $C_S^2 = \\frac{\\operatorname{Var}(S)}{(E[S])^2} = \\frac{1/L}{1^2} = \\frac{1}{L}$.\n\nFrom the expression for $\\operatorname{Var}(I)$:\n$$C_I^2 = \\frac{\\frac{\\mu_X^2}{L} + \\sigma_X^2(1 + \\frac{1}{L})}{\\mu_X^2} = \\frac{1}{L} + \\frac{\\sigma_X^2}{\\mu_X^2} (1 + \\frac{1}{L}) = C_S^2 + C_X^2(1 + C_S^2) = C_S^2 + C_X^2 + C_S^2 C_X^2$$\nThis can be factored into the well-known form:\n$$1 + C_I^2 = (1 + C_X^2)(1 + C_S^2)$$\nThis equation is the symbolic expression that shows how the observed statistics ($C_I^2$) are altered by the random texture ($C_X^2$) and the speckle ($C_S^2 = 1/L$). If one uses the simple estimator $\\hat{L} = 1/C_I^2$, the result is $\\hat{L} = 1/(C_S^2 + C_X^2 + C_S^2 C_X^2)$, which is clearly not equal to the true ENL, $L=1/C_S^2$. The texture introduces intrinsic variability that, like the deterministic trend, inflates the measured variance and causes the simple ENL estimator to underestimate the true number of looks.",
            "answer": "$$\n\\boxed{3.202}\n$$"
        },
        {
            "introduction": "Adaptive filters tailor their behavior based on local image content, typically by first classifying regions as either homogeneous or textured. This practice demonstrates how to formalize this decision using a statistical hypothesis test based on the sample coefficient of variation ($\\hat{C}$). You will derive the statistical properties of $\\hat{C}$ under the null hypothesis of homogeneity and construct a decision rule to identify textured areas, a core mechanism that enables filters to smooth speckle while preserving true scene details .",
            "id": "3852481",
            "problem": "A square window of size $7 \\times 7$ pixels is extracted from a multilook Synthetic Aperture Radar (SAR) intensity image used in environmental modeling. Assume fully developed speckle and that, under homogeneity, each pixel intensity $I_i$ in the window is an independent and identically distributed realization from a Gamma distribution with shape parameter $L$ (the equivalent number of looks) and scale parameter $\\theta = \\mu/L$, where $\\mu$ is the constant but unknown backscatter mean within the window. For a Gamma distribution with shape $k$ and scale $\\theta$, the raw moments satisfy $E[X^r] = \\theta^r \\Gamma(k+r)/\\Gamma(k)$.\n\nYou are tasked with deciding whether the window is homogeneous using the coefficient of variation (CV) test with a user-specified one-sided probability of false alarm (type I error) $\\alpha$. Let the window size be $n = 49$ pixels and the equivalent number of looks be $L = 4$. Define the sample coefficient of variation as $\\hat{C} = S/\\bar{I}$, where $\\bar{I}$ is the sample mean and $S$ is the sample standard deviation of the intensities in the window.\n\nStarting only from the assumptions stated above and standard large-sample theory (Central Limit Theorem for sample moments and the delta method), do the following:\n- Formulate the null hypothesis $H_0$ of homogeneity and the alternative $H_1$ that the window is not homogeneous due to texture or mixture causing an increase in dispersion.\n- Derive, under $H_0$, the theoretical population coefficient of variation $C_0$ as a function of $L$.\n- Using the joint asymptotic normality of the sample mean and sample second raw moment and applying the delta method to $\\hat{C} = \\sqrt{m_2 - m_1^2}/m_1$ with $m_1 = \\bar{I}$ and $m_2 = \\frac{1}{n}\\sum I_i^2$, derive an explicit large-$n$ expression for the asymptotic variance $\\operatorname{Var}(\\hat{C}\\,|\\,H_0)$ as a function of $n$ and $L$.\n- Construct a right-tailed test that rejects $H_0$ for large values of $\\hat{C}$ at level $\\alpha = 0.01$ by computing a threshold $\\tau_C$ such that $P(\\hat{C} > \\tau_C \\mid H_0) = \\alpha$.\n\nCompute the numerical value of the threshold $\\tau_C$ for $n = 49$, $L = 4$, and $\\alpha = 0.01$. Round your final threshold to four significant figures. Express the final threshold as a pure number with no units.",
            "solution": "The problem statement is first validated against the required criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- Window size: square, $7 \\times 7$ pixels.\n- Total number of pixels in window: $n = 49$.\n- Image type: multilook Synthetic Aperture Radar (SAR) intensity image.\n- Speckle model: fully developed.\n- Under homogeneity, pixel intensity $I_i$ is an independent and identically distributed (i.i.d.) random variable.\n- Distribution of $I_i$ under homogeneity: Gamma distribution, with shape parameter $L$ and scale parameter $\\theta = \\mu/L$.\n- Equivalent number of looks: $L = 4$.\n- Backscatter mean: $\\mu$, constant but unknown under homogeneity.\n- Formula for raw moments of a Gamma($k$, $\\theta$) distribution: $E[X^r] = \\theta^r \\Gamma(k+r)/\\Gamma(k)$.\n- Sample coefficient of variation definition: $\\hat{C} = S/\\bar{I}$, where $\\bar{I}$ is the sample mean and $S$ is the sample standard deviation.\n- Probability of false alarm (Type I error): $\\alpha = 0.01$.\n- Test type: one-sided, right-tailed.\n- Task: Derive hypotheses, theoretical CV ($C_0$), asymptotic variance of $\\hat{C}$ under the null hypothesis, and the decision threshold $\\tau_C$.\n- Numerical values for final computation: $n = 49$, $L = 4$, $\\alpha = 0.01$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly rooted in the statistical theory of SAR image processing. The Gamma distribution is the standard model for the intensity of multilook SAR data under the assumption of fully developed speckle. The coefficient of variation is a standard and widely used metric for testing the homogeneity of a region in a SAR image. The use of large-sample theory, including the Central Limit Theorem for sample moments and the delta method, is a standard approach for deriving the distribution of estimators.\n- **Well-Posed:** The problem is clearly specified. It provides all necessary data ($n$, $L$, $\\alpha$) and a precise definition of the quantities to be derived. The objective is unambiguous: to compute a numerical threshold $\\tau_C$ based on a rigorous derivation.\n- **Objective:** The problem is stated in precise, formal, and unbiased scientific language.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically sound, well-posed, and objective. It contains no invalidating flaws. Therefore, the problem is **valid**. A full solution will be provided.\n\n### Solution Derivation\n\nThe solution proceeds in four stages as outlined in the problem.\n\n**1. Formulation of Hypotheses**\nThe null hypothesis, $H_0$, corresponds to the case where the image window is homogeneous. In this scenario, the observed pixel intensities $I_i$ are i.i.d. draws from a single Gamma distribution, and any variation is due solely to speckle noise. The population coefficient of variation has a specific theoretical value, $C_0$.\n\nThe alternative hypothesis, $H_1$, corresponds to a heterogeneous window. This heterogeneity can arise from underlying texture (spatial variation in the mean backscatter $\\mu$) or from the presence of edges or point targets. Such conditions lead to an increase in the dispersion of pixel intensities beyond what is expected from speckle alone. This results in a population coefficient of variation $C$ that is greater than the theoretical value $C_0$ for pure speckle.\n\nThe hypotheses are therefore formulated as a right-tailed test on the coefficient of variation:\n$$ H_0: C = C_0 \\quad (\\text{homogeneous region}) $$\n$$ H_1: C > C_0 \\quad (\\text{heterogeneous region}) $$\nThe test will be conducted using the sample coefficient of variation, $\\hat{C}$, by rejecting $H_0$ if $\\hat{C}$ is significantly large.\n\n**2. Derivation of the Theoretical Population Coefficient of Variation, $C_0$**\nUnder $H_0$, the intensity $I$ follows a Gamma distribution with shape parameter $L$ and scale parameter $\\theta$. The population coefficient of variation is defined as $C_0 = \\frac{\\sqrt{\\operatorname{Var}(I)}}{E[I]}$. We first compute the mean and variance of $I$.\n\nUsing the given formula for raw moments, $E[I^r] = \\theta^r \\frac{\\Gamma(L+r)}{\\Gamma(L)}$, we find the first two moments:\nThe mean (first raw moment, $r=1$):\n$$ E[I] = \\mu_1 = \\theta^1 \\frac{\\Gamma(L+1)}{\\Gamma(L)} = \\theta \\frac{L\\Gamma(L)}{\\Gamma(L)} = L\\theta $$\nThe second raw moment ($r=2$):\n$$ E[I^2] = \\mu_2 = \\theta^2 \\frac{\\Gamma(L+2)}{\\Gamma(L)} = \\theta^2 \\frac{(L+1)L\\Gamma(L)}{\\Gamma(L)} = L(L+1)\\theta^2 $$\nThe variance is $\\operatorname{Var}(I) = E[I^2] - (E[I])^2$:\n$$ \\operatorname{Var}(I) = L(L+1)\\theta^2 - (L\\theta)^2 = (L^2\\theta^2 + L\\theta^2) - L^2\\theta^2 = L\\theta^2 $$\nNow we can compute the theoretical coefficient of variation under $H_0$:\n$$ C_0 = \\frac{\\sqrt{\\operatorname{Var}(I)}}{E[I]} = \\frac{\\sqrt{L\\theta^2}}{L\\theta} = \\frac{\\sqrt{L}\\theta}{L\\theta} = \\frac{1}{\\sqrt{L}} $$\n\n**3. Derivation of the Asymptotic Variance of $\\hat{C}$**\nWe use the delta method for the function $g(m_1, m_2) = \\frac{\\sqrt{m_2 - m_1^2}}{m_1}$, where $m_1 = \\frac{1}{n}\\sum I_i$ and $m_2 = \\frac{1}{n}\\sum I_i^2$ are the first two sample raw moments. The asymptotic variance of $\\hat{C} = g(m_1, m_2)$ is given by:\n$$ \\operatorname{Var}(\\hat{C}) \\approx (\\nabla g)^T \\Sigma_{\\mathbf{m}} (\\nabla g) $$\nwhere $\\nabla g$ is the gradient of $g$ evaluated at the population moments $(\\mu_1, \\mu_2)$, and $\\Sigma_{\\mathbf{m}}$ is the covariance matrix of the sample moments $(m_1, m_2)$. For large $n$, $\\Sigma_{\\mathbf{m}} \\approx \\frac{1}{n}\\Sigma'$, where $\\Sigma'_{ij} = E[I^{i+j}] - E[I^i]E[I^j]$.\n\nFirst, we find the partial derivatives of $g(m_1, m_2)$:\n$$ \\frac{\\partial g}{\\partial m_1} = \\frac{-m_2}{m_1^2 \\sqrt{m_2-m_1^2}} $$\n$$ \\frac{\\partial g}{\\partial m_2} = \\frac{1}{2m_1 \\sqrt{m_2-m_1^2}} $$\nWe evaluate these at the population moments under $H_0$. Let $\\sigma_I = \\sqrt{\\mu_2-\\mu_1^2} = \\sqrt{L\\theta^2} = \\sqrt{L}\\theta$.\n$$ J_1 = \\left. \\frac{\\partial g}{\\partial m_1} \\right|_{(\\mu_1, \\mu_2)} = \\frac{-\\mu_2}{\\mu_1^2 \\sigma_I} = \\frac{-L(L+1)\\theta^2}{(L\\theta)^2 (\\sqrt{L}\\theta)} = \\frac{-(L+1)}{L\\sqrt{L}\\theta} $$\n$$ J_2 = \\left. \\frac{\\partial g}{\\partial m_2} \\right|_{(\\mu_1, \\mu_2)} = \\frac{1}{2\\mu_1 \\sigma_I} = \\frac{1}{2(L\\theta)(\\sqrt{L}\\theta)} = \\frac{1}{2L\\sqrt{L}\\theta^2} $$\nNext, we find the elements of the matrix $\\Sigma'$. We need up to the fourth raw moment of $I$.\n$$ \\mu_3 = E[I^3] = L(L+1)(L+2)\\theta^3 $$\n$$ \\mu_4 = E[I^4] = L(L+1)(L+2)(L+3)\\theta^4 $$\nThe elements of $\\Sigma'$ are:\n$$ \\Sigma'_{11} = \\operatorname{Var}(I) = \\mu_2 - \\mu_1^2 = L\\theta^2 $$\n$$ \\Sigma'_{12} = \\operatorname{Cov}(I, I^2) = \\mu_3 - \\mu_1\\mu_2 = L(L+1)(L+2)\\theta^3 - (L\\theta)(L(L+1)\\theta^2) = 2L(L+1)\\theta^3 $$\n$$ \\Sigma'_{22} = \\operatorname{Var}(I^2) = \\mu_4 - \\mu_2^2 = L(L+1)(L+2)(L+3)\\theta^4 - (L(L+1)\\theta^2)^2 = 2L(L+1)(2L+3)\\theta^4 $$\nThe asymptotic variance is $\\operatorname{Var}(\\hat{C}) \\approx \\frac{1}{n}(J_1^2 \\Sigma'_{11} + 2J_1J_2\\Sigma'_{12} + J_2^2\\Sigma'_{22})$.\n$$ J_1^2\\Sigma'_{11} = \\left(\\frac{-(L+1)}{L\\sqrt{L}\\theta}\\right)^2 (L\\theta^2) = \\frac{(L+1)^2}{L^3\\theta^2} L\\theta^2 = \\frac{(L+1)^2}{L^2} $$\n$$ 2J_1J_2\\Sigma'_{12} = 2 \\left(\\frac{-(L+1)}{L\\sqrt{L}\\theta}\\right) \\left(\\frac{1}{2L\\sqrt{L}\\theta^2}\\right) (2L(L+1)\\theta^3) = \\frac{-(L+1)}{L^2\\theta^3} (L(L+1)\\theta^3) = -\\frac{2(L+1)^2}{L^2} $$\n$$ J_2^2\\Sigma'_{22} = \\left(\\frac{1}{2L\\sqrt{L}\\theta^2}\\right)^2 (2L(L+1)(2L+3)\\theta^4) = \\frac{1}{4L^3\\theta^4} (2L(L+1)(2L+3)\\theta^4) = \\frac{(L+1)(2L+3)}{2L^2} $$\nSumming these terms:\n$$ n\\operatorname{Var}(\\hat{C}) \\approx \\frac{(L+1)^2}{L^2} - \\frac{2(L+1)^2}{L^2} + \\frac{(L+1)(2L+3)}{2L^2} = \\frac{-2(L+1)^2 + (L+1)(2L+3)}{2L^2} $$\n$$ = \\frac{(L+1)[-2(L+1) + (2L+3)]}{2L^2} = \\frac{(L+1)[-2L-2+2L+3]}{2L^2} = \\frac{L+1}{2L^2} $$\nThus, the asymptotic variance of the sample coefficient of variation under $H_0$ is:\n$$ \\operatorname{Var}(\\hat{C} \\mid H_0) \\approx \\frac{L+1}{2nL^2} $$\n\n**4. Construction of the Test and Computation of the Threshold $\\tau_C$**\nFor large $n$, $\\hat{C}$ is asymptotically normally distributed around the true value $C_0$ with the variance derived above:\n$$ \\hat{C} \\mid H_0 \\sim N\\left(C_0, \\operatorname{Var}(\\hat{C} \\mid H_0)\\right) \\implies \\hat{C} \\mid H_0 \\sim N\\left(\\frac{1}{\\sqrt{L}}, \\frac{L+1}{2nL^2}\\right) $$\nWe want to find a threshold $\\tau_C$ such that $P(\\hat{C} > \\tau_C \\mid H_0) = \\alpha$. We standardize $\\hat{C}$ to a standard normal variable $Z \\sim N(0,1)$:\n$$ Z = \\frac{\\hat{C} - C_0}{\\sqrt{\\operatorname{Var}(\\hat{C} \\mid H_0)}} $$\nThe condition $P(\\hat{C} > \\tau_C) = \\alpha$ becomes $P\\left(Z > \\frac{\\tau_C - C_0}{\\sqrt{\\operatorname{Var}(\\hat{C} \\mid H_0)}}\\right) = \\alpha$.\nLet $z_\\alpha$ be the upper $\\alpha$-quantile of the standard normal distribution, where $P(Z > z_\\alpha) = \\alpha$. We have:\n$$ \\frac{\\tau_C - C_0}{\\sqrt{\\operatorname{Var}(\\hat{C} \\mid H_0)}} = z_\\alpha $$\nSolving for $\\tau_C$:\n$$ \\tau_C = C_0 + z_\\alpha \\sqrt{\\operatorname{Var}(\\hat{C} \\mid H_0)} = \\frac{1}{\\sqrt{L}} + z_\\alpha \\sqrt{\\frac{L+1}{2nL^2}} $$\nNow, we substitute the given numerical values: $n=49$, $L=4$, and $\\alpha=0.01$. The corresponding quantile is $z_{0.01} \\approx 2.3263$.\nFirst, calculate $C_0$:\n$$ C_0 = \\frac{1}{\\sqrt{4}} = \\frac{1}{2} = 0.5 $$\nNext, calculate the standard deviation term:\n$$ \\sqrt{\\frac{L+1}{2nL^2}} = \\sqrt{\\frac{4+1}{2(49)(4^2)}} = \\sqrt{\\frac{5}{2(49)(16)}} = \\sqrt{\\frac{5}{1568}} \\approx 0.056472 $$\nNow, compute the threshold $\\tau_C$:\n$$ \\tau_C \\approx 0.5 + 2.3263 \\times 0.056472 $$\n$$ \\tau_C \\approx 0.5 + 0.1313817... $$\n$$ \\tau_C \\approx 0.6313817... $$\nRounding to four significant figures, the final threshold is $0.6314$.",
            "answer": "$$\\boxed{0.6314}$$"
        },
        {
            "introduction": "This practice synthesizes theoretical concepts into a complete, practical filtering application. You will implement the classic Lee adaptive filter, which relies on the rapid calculation of local statisticsâ€”the very quantities explored in the previous exercises. By using the highly efficient integral image technique, you will build a filter capable of real-time processing and quantitatively evaluate its performance, bridging the gap between statistical theory and computational practice in remote sensing .",
            "id": "3852489",
            "problem": "You are asked to design and implement a program that demonstrates how integral images can be used to compute local statistics efficiently for large images in real-time filtering, specifically for Synthetic Aperture Radar (SAR) speckle noise reduction within remote sensing and environmental modeling. The program must generate synthetic SAR intensity data with multiplicative speckle noise, compute local statistics via integral images, and apply an adaptive filter based on these statistics. It must also verify the correctness of the integral-image-based local statistics against a reference method and report quantitative accuracy and denoising performance.\n\nFundamental base:\n- The multiplicative speckle model assumes that observed SAR intensity $I$ is given by $I = X \\cdot N$, where $X$ is the unknown backscatter reflectivity, and $N$ is a unit-mean speckle noise random variable with variance determined by the number of looks $L$.\n- For multi-look intensity SAR data, speckle $N$ is commonly modeled as Gamma-distributed with shape parameter $L$ and scale parameter $1/L$, yielding $\\mathbb{E}[N] = 1$ and $\\operatorname{Var}(N) = 1/L$.\n- An integral image (summed area table) of a two-dimensional array $A \\in \\mathbb{R}^{H \\times W}$ is defined as the cumulative sum\n$$\nS(i,j) = \\sum_{u=0}^{i-1} \\sum_{v=0}^{j-1} A(u,v),\n$$\nusing a convention with zero-padding so that $S$ has shape $(H+1) \\times (W+1)$ and $S(0,\\cdot)=S(\\cdot,0)=0$.\n- The sum of any axis-aligned rectangular window of height $h$ and width $w$ with its top-left corner at $(i,j)$ (zero-indexed), where $0 \\le i \\le H-h$ and $0 \\le j \\le W-w$, is given by the inclusion-exclusion formula\n$$\n\\text{sum}(i,j; h,w) = S(i+h,j+w) - S(i,j+w) - S(i+h,j) + S(i,j).\n$$\n- The local mean and variance inside each window are computed as\n$$\n\\mu(i,j) = \\frac{1}{hw}\\sum_{u=i}^{i+h-1}\\sum_{v=j}^{j+w-1} I(u,v), \\quad\n\\sigma^2(i,j) = \\frac{1}{hw}\\sum_{u=i}^{i+h-1}\\sum_{v=j}^{j+w-1} I(u,v)^2 - \\mu(i,j)^2,\n$$\nwhich can be obtained by using integral images of $I$ and $I^2$.\n\nAdaptive filter:\n- Consider the Lee filter, derived under the multiplicative speckle assumption, which produces a filtered output $F$ by blending the local mean $\\mu$ and the observed center pixel $I_c$ according to\n$$\nF = \\mu + W\\left(I_c - \\mu\\right),\n$$\nwhere\n$$\nW = \\max\\left(0, \\min\\left(1, \\frac{\\sigma^2 - \\sigma_n^2}{\\sigma^2 + \\epsilon}\\right)\\right), \\quad \\sigma_n^2 = \\frac{\\mu^2}{L}.\n$$\nHere, $\\sigma_n^2$ is the noise variance in intensity domain when the mean reflectivity is $\\mu$, and $\\epsilon$ is a small positive constant to avoid division by zero. The filter output for a given window is assigned to the pixel at the window center with indices $(i + \\lfloor h/2 \\rfloor, j + \\lfloor w/2 \\rfloor)$.\n\nYour program must:\n1. Generate synthetic reflectivity fields $X$ of specified sizes, then synthesize observed intensities $I = X \\cdot N$ by drawing speckle $N$ from a Gamma distribution with shape $L$ and scale $1/L$, using the provided random seeds to ensure reproducibility.\n2. Implement integral-image-based computation of local sums of $I$ and $I^2$ and derive corresponding local means and variances on the \"valid\" domain (only positions where the full window fits inside the image), yielding arrays of shape $(H-h+1, W-w+1)$ indexed by $(i,j)$ as the window top-left coordinate.\n3. Implement a reference method to compute the same local sums by two-dimensional convolution using an $h \\times w$ all-ones kernel with \"valid\" mode (no padding), then compute local means and variances from those sums.\n4. Compute the maximum absolute differences between integral-image local means and reference local means, and between integral-image local variances and reference local variances, for each test case. These must be reported as floating-point values.\n5. Apply the Lee filter using the integral-image local statistics. The filtered values must be assigned to the center pixel of each window, which yields a filtered output array of shape $(H-h+1, W-w+1)$. Compute the root mean square error (RMSE) between the filtered output and the ground-truth reflectivity $X$ sampled at the same center pixels. Report the RMSE as a floating-point value for each test case.\n\nTest suite:\nUse the following test cases. In all cases, express intensities and reflectivities as unitless real numbers. No angles appear, and no percentages are required.\n\n- Case $1$ (general case):\n    - Image size: $H=256$, $W=256$.\n    - Window: $h=7$, $w=7$.\n    - Looks: $L=4$.\n    - Seed: $s=12345$.\n    - Reflectivity $X$: a base horizontal gradient plus a central bright block:\n      $X(u,v) = 0.5 + 0.5 \\cdot \\frac{v}{W-1} + B(u,v)$, where $B(u,v)=1.5$ if $H/4 \\le u < 3H/4$ and $W/4 \\le v < 3W/4$, else $B(u,v)=0$.\n\n- Case $2$ (boundary window size and identity behavior):\n    - Image size: $H=128$, $W=192$.\n    - Window: $h=1$, $w=1$.\n    - Looks: $L=8$.\n    - Seed: $s=23456$.\n    - Reflectivity $X$: sinusoidal texture,\n      $X(u,v) = 1.0 + 0.3 \\sin\\left(2\\pi \\cdot \\frac{4u}{H}\\right)\\sin\\left(2\\pi \\cdot \\frac{6v}{W}\\right)$.\n\n- Case $3$ (high speckle, anisotropic window):\n    - Image size: $H=256$, $W=256$.\n    - Window: $h=11$, $w=5$.\n    - Looks: $L=1$.\n    - Seed: $s=34567$.\n    - Reflectivity $X$: checkerboard of two levels with block size $b=8$:\n      $X(u,v) = 0.75$ if $\\left\\lfloor \\frac{u}{b} \\right\\rfloor + \\left\\lfloor \\frac{v}{b} \\right\\rfloor$ is even, else $X(u,v)=1.25$.\n\n- Case $4$ (large window relative to image):\n    - Image size: $H=64$, $W=64$.\n    - Window: $h=33$, $w=33$.\n    - Looks: $L=16$.\n    - Seed: $s=45678$.\n    - Reflectivity $X$: gentle ramp,\n      $X(u,v) = 0.1 + \\frac{u+v}{H+W}$.\n\nFinal output format:\nYour program should produce a single line of output containing all results aggregated in order per case as a comma-separated list enclosed in square brackets. For each case, output three floating-point values in the order: maximum absolute error of local means, maximum absolute error of local variances, RMSE of the Lee-filtered output versus the ground-truth reflectivity at window centers. Therefore, the overall output must contain $12$ floats for the $4$ cases, for example:\n\"[mean_err_case1,var_err_case1,rmse_case1,mean_err_case2,var_err_case2,rmse_case2,mean_err_case3,var_err_case3,rmse_case3,mean_err_case4,var_err_case4,rmse_case4]\".",
            "solution": "The problem is valid. It is a well-defined computational task in the field of remote sensing and image processing, grounded in established scientific models and algorithms. All necessary parameters and definitions are provided for a unique and verifiable solution. The problem asks for the implementation and verification of an efficient filtering pipeline for Synthetic Aperture Radar (SAR) imagery, which is a standard and relevant topic.\n\nThe solution will be implemented by following the sequence of tasks outlined in the problem statement. First, we will define functions to generate the synthetic ground-truth reflectivity fields ($X$) for each of the four test cases. These functions will be based on the explicit mathematical formulas provided.\n\nSecond, a function will generate the noisy SAR intensity image ($I$) according to the multiplicative model $I = X \\cdot N$. The speckle noise $N$ is drawn from a Gamma distribution with shape parameter $L$ (number of looks) and scale parameter $1/L$. A fixed random seed ensures reproducibility for each case.\n\nThird, we will implement the core of the problem: the computation of local image statistics (mean and variance). Two methods will be implemented:\n1.  An efficient method using integral images (also known as summed-area tables). Two integral images will be computed, one for the intensity image $I$ and another for the squared-intensity image $I^2$. From these, the sum of values and sum of squared values within any rectangular window can be calculated in constant time. The local mean and variance are then derived directly from these sums. The formula for the sum over a window with top-left corner $(i,j)$ and size $h \\times w$ using an integral image $S$ is:\n    $$ \\text{sum}(i,j; h,w) = S(i+h, j+w) - S(i, j+w) - S(i+h, j) + S(i, j) $$\n    The local mean $\\mu(i,j)$ and variance $\\sigma^2(i,j)$ are then:\n    $$ \\mu(i,j) = \\frac{\\text{sum}_I(i,j; h,w)}{hw}, \\quad \\sigma^2(i,j) = \\frac{\\text{sum}_{I^2}(i,j; h,w)}{hw} - \\mu(i,j)^2 $$\n    This will be implemented for all windows in a vectorized manner for efficiency.\n2.  A reference method using two-dimensional convolution. The local sums are computed by convolving the images $I$ and $I^2$ with an $h \\times w$ kernel of all ones, using the 'valid' mode to ensure the output size matches the integral image method. The local mean and variance are then calculated from these sums.\n\nFourth, to verify the correctness of the integral image implementation, the maximum absolute difference between the local means and local variances computed by the two methods will be calculated. These differences are expected to be close to zero, within the limits of floating-point precision.\n\nFifth, the Lee adaptive filter will be applied. The filter estimates the restored pixel value $F$ as a weighted average of the observed center pixel $I_c$ and the local mean $\\mu$, with the weight $W$ depending on the local signal-to-noise ratio. The formulas are:\n$$ F = \\mu + W(I_c - \\mu) $$\n$$ W = \\max\\left(0, \\min\\left(1, \\frac{\\sigma^2 - \\sigma_n^2}{\\sigma^2 + \\epsilon}\\right)\\right) $$\nwhere $\\sigma_n^2 = \\mu^2/L$ is the estimated speckle noise variance and $\\epsilon$ is a small positive constant (we will use $\\epsilon=10^{-8}$) to prevent division by zero. The filtered value for each window is assigned to the pixel at the window's center.\n\nFinally, the performance of the filter will be quantified by computing the Root Mean Square Error (RMSE) between the filtered image $F$ and the corresponding central pixels of the original ground-truth reflectivity image $X$.\n\nThe entire process will be executed for each of the four specified test cases, and the three resulting metrics for each case (mean error, variance error, RMSE) will be collected and formatted into a single output string as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import convolve2d\n\ndef generate_reflectivity(H, W, params):\n    \"\"\"\n    Generates the ground-truth reflectivity field X for a given case.\n    \"\"\"\n    case_id = params['case_id']\n    vv, uu = np.meshgrid(np.arange(W, dtype=float), np.arange(H, dtype=float))\n\n    if case_id == 1:\n        X = 0.5 + 0.5 * vv / (W - 1)\n        X[H // 4 : 3 * H // 4, W // 4 : 3 * W // 4] += 1.5\n    elif case_id == 2:\n        X = 1.0 + 0.3 * np.sin(2 * np.pi * 4 * uu / H) * np.sin(2 * np.pi * 6 * vv / W)\n    elif case_id == 3:\n        b = params['b']\n        is_even = ((uu // b) + (vv // b)) % 2 == 0\n        X = np.full((H, W), 1.25)\n        X[is_even] = 0.75\n    elif case_id == 4:\n        X = 0.1 + (uu + vv) / (H + W)\n    else:\n        raise ValueError(\"Invalid case_id\")\n    return X\n\ndef generate_sar_intensity(X, L, seed):\n    \"\"\"\n    Generates the noisy SAR intensity image I from X, L, and seed.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    # Speckle noise N ~ Gamma(shape=L, scale=1/L)\n    # This gives E[N]=1, Var(N)=1/L\n    noise = rng.gamma(L, 1.0 / L, size=X.shape)\n    I = X * noise\n    return I\n\ndef compute_integral_image(img):\n    \"\"\"\n    Computes the integral image (summed-area table) of a 2D array.\n    \"\"\"\n    # Pad with one row and one column of zeros on top and left\n    padded_img = np.pad(img, ((1, 0), (1, 0)), 'constant', constant_values=0)\n    # Cumulative sum over both axes\n    return padded_img.cumsum(axis=0).cumsum(axis=1)\n\ndef compute_stats_integral_image(I, h, w):\n    \"\"\"\n    Computes local mean and variance using integral images.\n    \"\"\"\n    H, W = I.shape\n    I_sq = I**2\n    \n    # Compute integral images for I and I^2\n    S_I = compute_integral_image(I)\n    S_I2 = compute_integral_image(I_sq)\n\n    # Use array slicing to compute sums over all valid windows\n    # Top-left corner (i,j), bottom-right (i+h, j+w) in S indexing\n    # sum_val = S(i+h,j+w) - S(i,j+w) - S(i+h,j) + S(i,j)\n    sum_I = S_I[h:, w:] - S_I[:-h, w:] - S_I[h:, :-w] + S_I[:-h, :-w]\n    sum_I2 = S_I2[h:, w:] - S_I2[:-h, w:] - S_I2[h:, :-w] + S_I2[:-h, :-w]\n\n    num_pixels = h * w\n    local_mean = sum_I / num_pixels\n    # Var(X) = E[X^2] - (E[X])^2\n    local_var = sum_I2 / num_pixels - local_mean**2\n\n    return local_mean, local_var\n\ndef compute_stats_reference(I, h, w):\n    \"\"\"\n    Computes local mean and variance using 2D convolution.\n    \"\"\"\n    kernel = np.ones((h, w))\n    num_pixels = h * w\n\n    sum_I = convolve2d(I, kernel, mode='valid')\n    sum_I2 = convolve2d(I**2, kernel, mode='valid')\n\n    local_mean = sum_I / num_pixels\n    local_var = sum_I2 / num_pixels - local_mean**2\n    \n    return local_mean, local_var\n\ndef apply_lee_filter(I, local_mean, local_var, L, h, w, epsilon):\n    \"\"\"\n    Applies the Lee adaptive filter.\n    \"\"\"\n    H, W = I.shape\n    h_off, w_off = h // 2, w // 2\n    \n    # Output dimensions\n    H_out, W_out = H - h + 1, W - w + 1\n    \n    # Extract Intensity at center of each window\n    I_c = I[h_off : h_off + H_out, w_off : w_off + W_out]\n\n    # Estimated noise variance\n    noise_var = (local_mean**2) / L\n    \n    # Lee filter weight\n    W_lee = (local_var - noise_var) / (local_var + epsilon)\n    W_lee = np.maximum(0, np.minimum(1, W_lee))\n\n    # Apply filter\n    F = local_mean + W_lee * (I_c - local_mean)\n    \n    return F\n\ndef solve():\n    test_cases = [\n        {'H': 256, 'W': 256, 'h': 7, 'w': 7, 'L': 4, 's': 12345, 'case_id': 1},\n        {'H': 128, 'W': 192, 'h': 1, 'w': 1, 'L': 8, 's': 23456, 'case_id': 2},\n        {'H': 256, 'W': 256, 'h': 11, 'w': 5, 'L': 1, 's': 34567, 'case_id': 3, 'b': 8},\n        {'H': 64, 'W': 64, 'h': 33, 'w': 33, 'L': 16, 's': 45678, 'case_id': 4},\n    ]\n\n    all_results = []\n    epsilon = 1e-8\n\n    for params in test_cases:\n        H, W, h, w, L, s = params['H'], params['W'], params['h'], params['w'], params['L'], params['s']\n\n        # 1. Generate synthetic data\n        X = generate_reflectivity(H, W, params)\n        I = generate_sar_intensity(X, L, s)\n\n        # 2. Compute statistics with integral image method\n        mean_ii, var_ii = compute_stats_integral_image(I, h, w)\n\n        # 3. Compute statistics with reference convolution method\n        mean_ref, var_ref = compute_stats_reference(I, h, w)\n        \n        # 4. Compute maximum absolute errors to verify integral image method\n        mean_err = np.max(np.abs(mean_ii - mean_ref))\n        var_err = np.max(np.abs(var_ii - var_ref))\n\n        # 5. Apply Lee filter and compute RMSE\n        filtered_image = apply_lee_filter(I, mean_ii, var_ii, L, h, w, epsilon)\n        \n        # Extract ground truth at window centers for comparison\n        h_off, w_off = h // 2, w // 2\n        H_out, W_out = H - h + 1, W - w + 1\n        X_center = X[h_off : h_off + H_out, w_off : w_off + W_out]\n        \n        rmse = np.sqrt(np.mean((filtered_image - X_center)**2))\n\n        # Clamp variance error to 0 if it's extremely small due to precision\n        if var_err < 1e-15:\n            var_err = 0.0\n\n        all_results.extend([mean_err, var_err, rmse])\n    \n    # Format final output string as specified\n    print(f\"[{','.join(f'{r:.8f}' for r in all_results)}]\")\n\nsolve()\n```"
        }
    ]
}