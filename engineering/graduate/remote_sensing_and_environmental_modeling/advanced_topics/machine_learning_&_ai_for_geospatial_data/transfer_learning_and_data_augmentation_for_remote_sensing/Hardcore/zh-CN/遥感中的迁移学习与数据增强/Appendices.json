{
    "hands_on_practices": [
        {
            "introduction": "遥感领域的数据增强必须尊重物理原理，以确保生成的数据在科学上是合理的。本练习将指导您构建一种基于物理的辐射增强方法，该方法通过模拟传感器校准和信噪比的合理变化来扰动多光谱地表反射率。这项实践对于训练能够泛化到不同采集条件下的稳健模型至关重要，并加深了您对遥感数据不确定性来源的理解。",
            "id": "3862712",
            "problem": "您的任务是为遥感中的多光谱地表反射率设计一种基于物理的辐射增强方法。该增强方法通过一个乘性因子扰动每个波段的反射率，以模拟合理的辐射定标变异性。您的推导和实现必须从辐射度学的基本测量和不确定性原理出发，不得依赖于快捷公式。\n\n从以下基本事实和定义开始：\n\n- 令 $D_b$ 表示波段 $b$ 的数字计数值（digital number），$L_b$ 表示波段 $b$ 的传感器处辐亮度。一个标准的线性定标模型将它们关联为 $L_b = g_b \\,(D_b - d_b) + o_b$，其中 $g_b$ 是增益，$d_b$ 是暗电平，$o_b$ 是偏移量。假设经过预处理后偏移量可忽略不计，因此 $L_b \\approx g_b\\,(D_b - d_b)$。\n- 波段 $b$ 的无量纲地表反射率，记为 $\\rho_b$，通过一个经过充分检验的辐射关系与传感器处辐亮度相关联，形式为 $\\rho_b = \\kappa_b \\, L_b$，其中 $\\kappa_b$ 聚合了大气校正后的确定性项，如大气外太阳辐照度、太阳天顶角、大气透射率和几何因子，因此 $L_b$ 中的乘性定标误差会以乘性方式传播到 $\\rho_b$。\n- 设增益不确定性表示为相对标准不确定度 $u_b$（一个标准差），并设波段 $b$ 的信噪比（SNR）为 $s_b$（定义为平均信号除以噪声标准差，即 $s_b = \\mu_b/\\sigma_b$）。\n- 对于高斯近似下的 $95\\%$ 置信类边界，使用一个二倍标准差的边界。在独立相对不确定度的保守相加（三角不等式）下，总相对扰动边界为\n$$\n\\alpha_b = \\min\\!\\left(2\\,u_b + \\frac{2}{s_b}, \\, \\alpha_{\\mathrm{cap}}\\right),\n$$\n其中 $\\alpha_{\\mathrm{cap}}$ 是为避免不切实际的扰动而选择的一个硬上限。\n- 地表反射率是物理上无量纲的，且位于闭区间 $[0,1]$ 内。对于已知的各波段最大期望反射率 $r^{\\max}_b \\in (0,1]$（源自地表属性和光照条件），对乘性增强因子 $f_b$ 的界定必须确保对于所有 $\\rho_b \\in [0, r_b^{\\max}]$，都有 $\\rho_b' = f_b \\,\\rho_b \\in [0,1]$。这意味着\n$$\nf_b \\in \\left[\\max\\!\\left(1 - \\alpha_b,\\, 0\\right),\\; \\min\\!\\left(1 + \\alpha_b,\\, \\frac{1}{r_b^{\\max}}\\right)\\right].\n$$\n- 增强过程应在上述区间内为每个波段 $b$ 均匀采样 $f_b$，然后形成增强后的反射率 $\\rho_b' = \\mathrm{clip}(f_b \\rho_b,\\, 0,\\, 1)$，以保守地强制执行物理边界。\n\n您的程序必须实现上述逻辑。在所有测试用例中，使用以下固定常量：\n- 用于定标和噪声贡献的置信度缩放因子均为 $2$。\n- 增强上限 $\\alpha_{\\mathrm{cap}} = 0.25$。\n- 随机数生成器种子设置为 $2025$，以确保采样的确定性。\n- 每个 $f_b$ 的采样分布是在上述逐波段区间上的均匀分布。\n\n输入已隐含在提供的测试套件中，不应读取任何外部输入。反射率值是无量纲的，必须如此处理。所有相对不确定度和 $s_b$ 值都是无量纲的。\n\n测试套件。对于每个案例 $i$，给定长度相同的数组 $u_b$、$s_b$、$r_b^{\\max}$ 和一个观测到的反射率向量 $\\rho_b$。通过使用固定种子对因子进行采样，计算逐波段的边界和一次增强反射率的实现：\n- 案例1（理想情况，中等不确定度和高信噪比）：\n  - $u_b = [0.02,\\, 0.02,\\, 0.03,\\, 0.03]$,\n  - $s_b = [200,\\, 220,\\, 180,\\, 150]$,\n  - $r_b^{\\max} = [0.6,\\, 0.7,\\, 0.8,\\, 0.5]$,\n  - $\\rho_b = [0.1,\\, 0.2,\\, 0.3,\\, 0.4]$。\n- 案例2（上界受接近于1的高最大反射率限制）：\n  - $u_b = [0.03,\\, 0.03]$,\n  - $s_b = [250,\\, 250]$,\n  - $r_b^{\\max} = [0.95,\\, 0.95]$,\n  - $\\rho_b = [0.9,\\, 0.95]$。\n- 案例3（低信噪比波段，不确定性较大，但低于上限）：\n  - $u_b = [0.05,\\, 0.04,\\, 0.05]$,\n  - $s_b = [30,\\, 40,\\, 20]$,\n  - $r_b^{\\max} = [0.7,\\, 0.6,\\, 0.4]$,\n  - $\\rho_b = [0.5,\\, 0.3,\\, 0.2]$。\n- 案例4（上限激活的极端情况，上限前组合不确定性非常大）：\n  - $u_b = [0.2]$,\n  - $s_b = [10]$,\n  - $r_b^{\\max} = [0.8]$,\n  - $\\rho_b = [0.5]$。\n\n输出要求：\n- 对于每个案例，计算逐波段边界 $[L_b, U_b]$，其中 $L_b = \\max(1 - \\alpha_b, 0)$，$U_b = \\min(1 + \\alpha_b, 1/r_b^{\\max})$。\n- 使用固定种子，为每个波段从 $\\mathrm{Uniform}(L_b, U_b)$ 中采样一个 $f_b$，并计算 $\\rho_b' = \\mathrm{clip}(f_b \\rho_b, 0, 1)$。\n- 将所有浮点数输出四舍五入到 $6$ 位小数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个长度为 $4$ 的列表（每个案例一个）。每个元素是包含两个元素的列表：\n  1. 针对该案例的逐波段双元素列表 $[L_b, U_b]$ 的列表。\n  2. 针对该案例的增强反射率 $\\rho_b'$ 的列表。\n- 该行必须打印为无空格的类JSON列表，例如：\n  - 每个案例为 $[ [[L_1,U_1],\\ldots], [\\rho'_1,\\ldots] ]$，并汇总到一个包含 $4$ 个案例的顶层列表中。",
            "solution": "该问题是有效的。它在科学上基于辐射度学和误差传播原理，问题陈述清晰，提供了所有必要信息，并且其表述是客观的。我们现在将进行完整的求解。\n\n目标是为多光谱地表反射率 $\\rho_b$（其中 $b$ 是光谱波段的索引）制定并实现一种基于物理的辐射增强方法。该增强方法通过对每个波段的反射率应用一个随机的乘性因子 $f_b$ 来模拟源于传感器定标不确定性和噪声的变异性。推导过程从第一性原理出发。\n\n首先，我们确定界定增强范围的总相对不确定度。问题提供了两个主要的不确定性来源：\n$1$. 传感器增益 $g_b$ 具有相对标准不确定度 $u_b$。\n$2$. 信号本身受到噪声的影响，由信噪比 $s_b$ 表征。由噪声引起的相对不确定度可以取为信噪比的倒数 $1/s_b$。\n\n问题指定使用一个 $95\\%$ 的置信类区间，通过二倍标准差（$2\\sigma$）边界来近似。来自增益和噪声的不确定性被视为独立的，它们的影响被线性相加，这代表了一种保守的（最坏情况）求和方式。因此，每个波段 $b$ 的组合相对扰动边界 $\\alpha_b$ 是通过将两个来源的 $2\\sigma$ 贡献相加而构建的。这个总扰动随后被一个最大值 $\\alpha_{\\mathrm{cap}}$ 封顶，以防止出现不符合物理现实的增强。这被形式化为：\n$$\n\\alpha_b = \\min\\!\\left(2\\,u_b + \\frac{2}{s_b}, \\, \\alpha_{\\mathrm{cap}}\\right)\n$$\n$\\alpha_{\\mathrm{cap}}$ 的值给定为 $0.25$，置信度缩放因子为 $2$。\n\n接下来，我们推导乘性增强因子 $f_b$ 的有效区间。因子 $f_b$ 旨在扰动反射率，因此它将从一个以 $1$ 为中心、宽度与 $\\alpha_b$ 相关的区间中采样。增强后的反射率为 $\\rho_b' = f_b \\rho_b$。一个关键的物理约束是，任何有效的地表反射率，无论是原始的还是增强后的，都必须位于闭区间 $[0, 1]$ 内。这一约束不仅必须对给定的 $\\rho_b$ 成立，而且必须对任何物理上可能的、直至各波段最大期望值 $r^{\\max}_b \\in (0,1]$ 的反射率都成立。\n\n这导致对 $f_b$ 的两个约束：\n$1$. **下界**：由于 $\\rho_b \\ge 0$，为确保 $\\rho_b' = f_b \\rho_b \\ge 0$，我们必须有 $f_b \\ge 0$。从不确定性模型推导出的下界是 $1 - \\alpha_b$。结合这两者，$f_b$ 的下界，记为 $L_b$，是 $L_b = \\max(1 - \\alpha_b, 0)$。\n$2$. **上界**：为确保对于所有可能的反射率 $\\rho_b \\in [0, r_b^{\\max}]$ 都有 $\\rho_b' = f_b \\rho_b \\le 1$，最严格的条件施加在最大反射率处，即 $\\rho_b = r_b^{\\max}$。这得出 $f_b r_b^{\\max} \\le 1$，意味着 $f_b \\le 1/r_b^{\\max}$。从不确定性模型推导出的上界是 $1 + \\alpha_b$。为了同时满足这两个条件，我们取两者的最小值。因此，$f_b$ 的上界，记为 $U_b$，是 $U_b = \\min(1 + \\alpha_b, 1/r_b^{\\max})$。\n\n综合这些，每个波段的乘性因子 $f_b$ 的采样区间为：\n$$\nf_b \\in [L_b, U_b] = \\left[\\max\\!\\left(1 - \\alpha_b, 0\\right), \\min\\!\\left(1 + \\alpha_b, \\frac{1}{r_b^{\\max}}\\right)\\right]\n$$\n\n增强流程如下：\n$1$. 对于给定的多光谱观测中的每个波段 $b$，计算总相对扰动边界 $\\alpha_b$。\n$2$. 使用 $\\alpha_b$ 和各波段最大反射率 $r_b^{\\max}$，确定采样区间 $[L_b, U_b]$。\n$3$. 对于每个波段 $b$，从其对应的区间 $[L_b, U_b]$ 上的均匀分布中抽取一个随机样本 $f_b$。为确保可复现性，使用固定的种子（$2025$）来初始化随机数生成器。\n$4$. 计算增强后的反射率 $\\rho_b' = f_b \\rho_b$。\n$5$. 作为最后的安全措施，将结果裁剪到物理范围 $[0, 1]$ 内：$\\rho_b' = \\mathrm{clip}(f_b \\rho_b, 0, 1)$。\n\n程序将为提供的四个测试用例实现此逻辑。对于每个案例，它将计算逐波段的边界 $[L_b, U_b]$ 和增强反射率向量 $\\rho_b'$ 的一次实现。所有数值结果将四舍五入到 $6$ 位小数，并格式化为指定的单行类JSON字符串。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a physically grounded radiometric augmentation for multispectral surface reflectance.\n    \"\"\"\n    # Define fixed constants\n    confidence_factor = 2.0\n    alpha_cap = 0.25\n    seed = 2025\n\n    # Initialize a random number generator with a fixed seed for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    # Test suite as defined in the problem statement\n    test_cases = [\n        {\n            \"u_b\": [0.02, 0.02, 0.03, 0.03],\n            \"s_b\": [200, 220, 180, 150],\n            \"r_max_b\": [0.6, 0.7, 0.8, 0.5],\n            \"rho_b\": [0.1, 0.2, 0.3, 0.4],\n        },\n        {\n            \"u_b\": [0.03, 0.03],\n            \"s_b\": [250, 250],\n            \"r_max_b\": [0.95, 0.95],\n            \"rho_b\": [0.9, 0.95],\n        },\n        {\n            \"u_b\": [0.05, 0.04, 0.05],\n            \"s_b\": [30, 40, 20],\n            \"r_max_b\": [0.7, 0.6, 0.4],\n            \"rho_b\": [0.5, 0.3, 0.2],\n        },\n        {\n            \"u_b\": [0.2],\n            \"s_b\": [10],\n            \"r_max_b\": [0.8],\n            \"rho_b\": [0.5],\n        },\n    ]\n\n    all_results = []\n\n    for case_data in test_cases:\n        # Extract data and convert to NumPy arrays for vectorized operations\n        u_b = np.array(case_data[\"u_b\"], dtype=float)\n        s_b = np.array(case_data[\"s_b\"], dtype=float)\n        r_max_b = np.array(case_data[\"r_max_b\"], dtype=float)\n        rho_b = np.array(case_data[\"rho_b\"], dtype=float)\n\n        # Step 1: Calculate the total relative perturbation bound, alpha_b\n        alpha_b = np.minimum(confidence_factor * u_b + confidence_factor / s_b, alpha_cap)\n\n        # Step 2: Calculate the bounds [L_b, U_b] for the multiplicative factor f_b\n        L_b = np.maximum(1.0 - alpha_b, 0.0)\n        U_b = np.minimum(1.0 + alpha_b, 1.0 / r_max_b)\n\n        # Step 3: Sample f_b from a uniform distribution over [L_b, U_b]\n        f_b = rng.uniform(L_b, U_b, size=u_b.shape)\n\n        # Step 4: Compute the augmented reflectance and clip to the physical range [0, 1]\n        rho_prime_b = np.clip(f_b * rho_b, 0.0, 1.0)\n        \n        # Step 5: Round results to 6 decimal places as required\n        L_b_rounded = np.round(L_b, 6)\n        U_b_rounded = np.round(U_b, 6)\n        rho_prime_b_rounded = np.round(rho_prime_b, 6)\n\n        # Structure the results for the current case\n        bounds_list = [[l, u] for l, u in zip(L_b_rounded, U_b_rounded)]\n        rhos_list = rho_prime_b_rounded.tolist()\n        \n        case_result = [bounds_list, rhos_list]\n        all_results.append(case_result)\n\n    # Print the final output in the specified compact JSON-like format\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "迁移学习中的一个核心挑战是“域偏移”，即源域和目标域的数据分布存在差异。为了解决这个问题，我们需要首先量化这种差异。本练习将重点介绍相关性对齐 (CORAL) 损失，这是一种通过比较源域和目标域特征的二阶统计量（协方差）来衡量域偏移的常用方法。通过亲手计算 CORAL 损失，您将掌握许多无监督域自适应算法的关键组成部分。",
            "id": "3862784",
            "problem": "给定两个有限的特征向量集合，它们分别代表来自两个不同大陆的编码后的作物区块，一个集合被指定为源域，另一个为目标域。您的任务是计算相关性对齐（CORAL）损失，该损失用于惩罚源域和目标域特征分布之间二阶统计量的差异。CORAL 损失定义为源协方差矩阵和目标协方差矩阵之差的弗罗贝尼乌斯范数的平方。\n\n从以下基本定义开始：\n\n- 令 $X \\in \\mathbb{R}^{n \\times d}$ 表示一个数据矩阵，其中有 $n$ 个样本（行）和 $d$ 个特征（列）。\n- 样本均值向量为 $\\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_i$，其中 $x_i$ 是 $X$ 的第 $i$ 行。\n- 中心化数据矩阵为 $X_c = X - \\mathbf{1}_n \\mu^\\top$，其中 $\\mathbf{1}_n \\in \\mathbb{R}^{n \\times 1}$ 是一个全为一的列向量。\n- 无偏样本协方差矩阵（当 $n \\ge 2$ 时）为 $C = \\frac{1}{n-1} X_c^\\top X_c \\in \\mathbb{R}^{d \\times d}$。对于 $n \\le 1$ 的情况，约定 $C = 0_{d \\times d}$。\n- 弗罗贝尼乌斯范数为 $\\lVert A \\rVert_F = \\sqrt{\\sum_{i,j} a_{ij}^2}$，适用于任何矩阵 $A$。\n- 具有协方差 $C_S$ 和 $C_T$ 的源特征集和目标特征集之间的 CORAL 损失为\n$$\nL_{\\text{CORAL}} = \\lVert C_S - C_T \\rVert_F^2 = \\operatorname{trace}\\!\\big((C_S - C_T)^\\top(C_S - C_T)\\big).\n$$\n\n在迁移学习中，特征是通过将预训练的编码器应用于原始输入而获得的。在本问题中，将编码器建模为一个无仿射变换的线性映射，后接一个逐点激活函数。具体来说，给定原始输入 $X \\in \\mathbb{R}^{n \\times m}$ 和编码器权重矩阵 $W \\in \\mathbb{R}^{m \\times d}$，编码后的特征定义为\n$$\nF = \\phi(X W),\n$$\n其中 $\\phi$ 是逐元素应用的恒等激活函数 $\\phi(z) = z$，或者是逐元素应用的修正线性单元（ReLU）$\\phi(z) = \\max(0, z)$。\n\n对于下面的每个测试用例，您必须：\n$1.$ 计算 $F_S = \\phi(X_S W)$ 和 $F_T = \\phi(X_T W)$。\n$2.$ 根据 $F_S$ 和 $F_T$ 计算无偏样本协方差矩阵 $C_S$ 和 $C_T$，当 $n \\ge 2$ 时使用 $C = \\frac{1}{n-1} X_c^\\top X_c$，当 $n \\le 1$ 时使用 $C = 0_{d \\times d}$。\n$3.$ 计算 $L_{\\text{CORAL}} = \\lVert C_S - C_T \\rVert_F^2$。\n将每个 $L_{\\text{CORAL}}$ 作为浮点数返回，并四舍五入到 $6$ 位小数。\n\n测试套件（所有矩阵都已明确给出）：\n\n- 案例 $1$（通用情况，恒等激活函数）：\n  - $X_S^{(1)} = \\begin{bmatrix}\n  1  2  3 \\\\\n  2  1  0 \\\\\n  0  1  2 \\\\\n  3  5  7\n  \\end{bmatrix}$，\n  $X_T^{(1)} = \\begin{bmatrix}\n  2  0  1 \\\\\n  1  1  1 \\\\\n  4  2  0 \\\\\n  0  3  6\n  \\end{bmatrix}$，\n  $W^{(1)} = \\begin{bmatrix}\n  1  0 \\\\\n  0  1 \\\\\n  1  -1\n  \\end{bmatrix}$，\n  $\\phi$ 是恒等函数。\n\n- 案例 $2$（相同域，ReLU激活函数）：\n  - $X_S^{(2)} = \\begin{bmatrix}\n  1  0  1 \\\\\n  0  1  1 \\\\\n  2  2  2\n  \\end{bmatrix}$，\n  $X_T^{(2)} = \\begin{bmatrix}\n  1  0  1 \\\\\n  0  1  1 \\\\\n  2  2  2\n  \\end{bmatrix}$，\n  $W^{(2)} = \\begin{bmatrix}\n  1  0 \\\\\n  0  1 \\\\\n  1  -1\n  \\end{bmatrix}$，\n  $\\phi$ 是 ReLU，$\\phi(z) = \\max(0, z)$ 逐元素应用。\n\n- 案例 $3$（使用 ReLU 的一维编码特征，源域方差为零）：\n  - $X_S^{(3)} = \\begin{bmatrix}\n  1  1 \\\\\n  2  1 \\\\\n  0  2\n  \\end{bmatrix}$，\n  $X_T^{(3)} = \\begin{bmatrix}\n  3  1 \\\\\n  1  0 \\\\\n  0  3\n  \\end{bmatrix}$，\n  $W^{(3)} = \\begin{bmatrix}\n  1 \\\\\n  -2\n  \\end{bmatrix}$，\n  $\\phi$ 是 ReLU，$\\phi(z) = \\max(0, z)$ 逐元素应用。\n\n- 案例 $4$（边界条件，单个源样本，恒等激活函数）：\n  - $X_S^{(4)} = \\begin{bmatrix}\n  10  10\n  \\end{bmatrix}$，\n  $X_T^{(4)} = \\begin{bmatrix}\n  9  11 \\\\\n  11  9\n  \\end{bmatrix}$，\n  $W^{(4)} = \\begin{bmatrix}\n  1  0 \\\\\n  0  1\n  \\end{bmatrix}$，\n  $\\phi$ 是恒等函数。\n\n实现要求：\n- 当 $n \\ge 2$ 时，使用无偏协方差估计量 $C = \\frac{1}{n-1} X_c^\\top X_c$；当 $n \\le 1$ 时，使用 $C = 0_{d \\times d}$。\n- 最终输出必须是单行文本，包含按顺序排列的四个结果的列表，四舍五入到 $6$ 位小数，并格式化为方括号内由逗号分隔的列表，例如 $[r_1,r_2,r_3,r_4]$，无空格。\n- 本问题不涉及物理单位，也不涉及角度。不要将任何量表示为百分比；所有输出必须是浮点数。\n\n您的程序必须计算每个案例的 $L_{\\text{CORAL}}$，并按规定格式打印单行聚合结果。",
            "solution": "该问题定义明确且科学合理。解决此问题需要系统地应用线性代数和统计学中的标准定义。目标是计算相关性对齐（CORAL）损失，其定义为源样本协方差矩阵和目标样本协方差矩阵之差的弗罗贝尼乌斯范数的平方：$L_{\\text{CORAL}} = \\lVert C_S - C_T \\rVert_F^2$。\n\n计算过程包括三个连续步骤：\n$1$. **特征编码**：原始输入数据矩阵 $X_S$ 和 $X_T$ 分别被转换为编码后的特征矩阵 $F_S$ 和 $F_T$。这是通过指定的映射 $F = \\phi(XW)$ 实现的，其中 $\\phi$ 是一个逐元素的激活函数（恒等函数或 ReLU）。\n$2$. **协方差矩阵计算**：从编码后的特征 $F_S$ 和 $F_T$ 计算无偏样本协方差矩阵 $C_S$ 和 $C_T$。对于一个给定的特征矩阵 $F \\in \\mathbb{R}^{n \\times d}$，其中有 $n$ 个样本和 $d$ 个特征，协方差矩阵 $C$ 的计算如下：\n- 如果 $n \\ge 2$，无偏样本协方差为 $C = \\frac{1}{n-1} F_c^\\top F_c$，其中 $F_c = F - \\mathbf{1}_n \\mu^\\top$ 是中心化数据矩阵，$\\mu$ 是 $F$ 的样本均值向量。\n- 如果 $n \\le 1$，协方差矩阵定义为 $d \\times d$ 的零矩阵，$C = 0_{d \\times d}$。\n$3$. **损失计算**：CORAL 损失是差异矩阵 $C_S - C_T$ 中所有元素平方的和。即 $L_{\\text{CORAL}} = \\sum_{i,j} ( (C_S - C_T)_{ij} )^2$。\n\n现在我们将此过程应用于所提供的四个测试用例中的每一个。\n\n**案例 1：通用情况，恒等激活函数**\n给定 $X_S^{(1)}$、$X_T^{(1)}$、$W^{(1)}$ 和 $\\phi(z)=z$。\n编码后的特征为 $F_S^{(1)} = X_S^{(1)} W^{(1)}$ 和 $F_T^{(1)} = X_T^{(1)} W^{(1)}$。\n$$\nF_S^{(1)} = \\begin{bmatrix} 1  2  3 \\\\ 2  1  0 \\\\ 0  1  2 \\\\ 3  5  7 \\end{bmatrix} \\begin{bmatrix} 1  0 \\\\ 0  1 \\\\ 1  -1 \\end{bmatrix} = \\begin{bmatrix} 4  -1 \\\\ 2  1 \\\\ 2  -1 \\\\ 10  -2 \\end{bmatrix}\n$$\n$$\nF_T^{(1)} = \\begin{bmatrix} 2  0  1 \\\\ 1  1  1 \\\\ 4  2  0 \\\\ 0  3  6 \\end{bmatrix} \\begin{bmatrix} 1  0 \\\\ 0  1 \\\\ 1  -1 \\end{bmatrix} = \\begin{bmatrix} 3  -1 \\\\ 2  0 \\\\ 4  2 \\\\ 6  -3 \\end{bmatrix}\n$$\n样本大小为 $n_S=4$ 和 $n_T=4$，均大于或等于 $2$。我们计算无偏样本协方差矩阵。\n对于源域，$\\mu_S = [4.5, -0.75]$。协方差矩阵为：\n$$ C_S^{(1)} = \\frac{1}{3} \\begin{bmatrix} 43  -10.5 \\\\ -10.5  4.75 \\end{bmatrix} = \\begin{bmatrix} 14.333\\dots  -3.5 \\\\ -3.5  1.5833\\dots \\end{bmatrix} $$\n对于目标域，$\\mu_T = [3.75, -0.5]$。协方差矩阵为：\n$$ C_T^{(1)} = \\frac{1}{3} \\begin{bmatrix} 8.75  -5.5 \\\\ -5.5  13 \\end{bmatrix} = \\begin{bmatrix} 2.9166\\dots  -1.8333\\dots \\\\ -1.8333\\dots  4.3333\\dots \\end{bmatrix} $$\nCORAL 损失是 $C_S^{(1)} - C_T^{(1)}$ 的弗罗贝尼烏斯范数的平方：\n$$ L_{\\text{CORAL}}^{(1)} = \\left\\lVert \\frac{1}{3} \\begin{bmatrix} 34.25  -5 \\\\ -5  -8.25 \\end{bmatrix} \\right\\rVert_F^2 = \\frac{1}{9} (34.25^2 + (-5)^2 + (-5)^2 + (-8.25)^2) = \\frac{1291.125}{9} = 143.458333\\dots $$\n\n**案例 2：相同域，ReLU 激活函数**\n给定 $X_S^{(2)} = X_T^{(2)}$、$W^{(2)}$ 和 $\\phi(z)=\\max(0,z)$。\n由于源域和目标域的原始输入相同（$X_S^{(2)} = X_T^{(2)}$），并且它们由相同的编码器（$W^{(2)}$ 和 $\\phi$）处理，因此它们的特征表示也将相同：$F_S^{(2)} = \\phi(X_S^{(2)}W^{(2)}) = \\phi(X_T^{(2)}W^{(2)}) = F_T^{(2)}$。因此，它们的协方差矩阵必然相等，$C_S^{(2)} = C_T^{(2)}$。\n差异矩阵 $C_S^{(2)} - C_T^{(2)}$ 是零矩阵。因此，损失为零。\n$$ L_{\\text{CORAL}}^{(2)} = \\lVert 0 \\rVert_F^2 = 0 $$\n\n**案例 3：一维特征，ReLU 激活函数**\n给定 $X_S^{(3)}$、$X_T^{(3)}$、$W^{(3)}$ 和 $\\phi(z)=\\max(0,z)$。编码后的特征将是一维的（$d=1$）。\n$$ Z_S^{(3)} = X_S^{(3)} W^{(3)} = \\begin{bmatrix} 1  1 \\\\ 2  1 \\\\ 0  2 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix} = \\begin{bmatrix} -1 \\\\ 0 \\\\ -4 \\end{bmatrix} \\implies F_S^{(3)} = \\phi(Z_S^{(3)}) = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix} $$\n由于所有源特征均为 $0$，方差为 $0$。$C_S^{(3)} = [0]$。\n$$ Z_T^{(3)} = X_T^{(3)} W^{(3)} = \\begin{bmatrix} 3  1 \\\\ 1  0 \\\\ 0  3 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\\\ -6 \\end{bmatrix} \\implies F_T^{(3)} = \\phi(Z_T^{(3)}) = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} $$\n对于目标特征，$n_T=3$，$\\mu_T = [2/3]$。中心化数据为 $[1/3, 1/3, -2/3]^\\top$。协方差（对于 $d=1$ 即为方差）为：\n$$ C_T^{(3)} = \\frac{1}{3-1} \\left( (1/3)^2 + (1/3)^2 + (-2/3)^2 \\right) = \\frac{1}{2} \\left( \\frac{6}{9} \\right) = \\left[\\frac{1}{3}\\right] $$\nCORAL 损失为：\n$$ L_{\\text{CORAL}}^{(3)} = \\lVert [0] - [1/3] \\rVert_F^2 = (-1/3)^2 = 1/9 = 0.111111\\dots $$\n\n**案例 4：边界条件，单个源样本**\n给定 $X_S^{(4)}$、$X_T^{(4)}$、$W^{(4)}$ 和 $\\phi(z)=z$。\n源域只有一个样本，$n_S = 1$。根据问题定义，对于 $n \\le 1$ 的情况，协方差矩阵为零矩阵。特征维度为 $d=2$。\n$$ C_S^{(4)} = \\begin{bmatrix} 0  0 \\\\ 0  0 \\end{bmatrix} $$\n对于目标域，$n_T = 2$。使用恒等激活函数且 $W^{(4)}$ 为单位矩阵，则 $F_T^{(4)} = X_T^{(4)} = \\begin{bmatrix} 9  11 \\\\ 11  9 \\end{bmatrix}$。均值为 $\\mu_T = [10, 10]$。中心化数据为 $F_{T,c}^{(4)} = \\begin{bmatrix} -1  1 \\\\ 1  -1 \\end{bmatrix}$。协方差矩阵为：\n$$ C_T^{(4)} = \\frac{1}{2-1} (F_{T,c}^{(4)})^\\top F_{T,c}^{(4)} = \\begin{bmatrix} -1  1 \\\\ 1  -1 \\end{bmatrix} \\begin{bmatrix} -1  1 \\\\ 1  -1 \\end{bmatrix} = \\begin{bmatrix} 2  -2 \\\\ -2  2 \\end{bmatrix} $$\nCORAL 损失为：\n$$ L_{\\text{CORAL}}^{(4)} = \\left\\lVert \\begin{bmatrix} 0  0 \\\\ 0  0 \\end{bmatrix} - \\begin{bmatrix} 2  -2 \\\\ -2  2 \\end{bmatrix} \\right\\rVert_F^2 = (-2)^2 + 2^2 + 2^2 + (-2)^2 = 4+4+4+4=16 $$",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_covariance(F):\n    \"\"\"\n    Computes the unbiased sample covariance matrix for a feature matrix F.\n    Handles the case n = 1 as specified in the problem.\n    \"\"\"\n    if F.ndim == 1:\n        F = F.reshape(-1, 1)\n    \n    n, d = F.shape\n\n    if n = 1:\n        return np.zeros((d, d))\n    else:\n        mu = np.mean(F, axis=0)\n        F_c = F - mu\n        # Using (F_c.T @ F_c) / (n - 1) as per the definition\n        C = np.dot(F_c.T, F_c) / (n - 1)\n        return C\n\ndef compute_coral_loss(X_S, X_T, W, activation):\n    \"\"\"\n    Computes the CORAL loss for given source and target data, and an encoder.\n    \"\"\"\n    X_S_np = np.array(X_S, dtype=np.float64)\n    X_T_np = np.array(X_T, dtype=np.float64)\n    W_np = np.array(W, dtype=np.float64)\n\n    # 1. Encode features\n    Z_S = X_S_np @ W_np\n    Z_T = X_T_np @ W_np\n\n    if activation == 'relu':\n        F_S = np.maximum(0, Z_S)\n        F_T = np.maximum(0, Z_T)\n    else:  # identity\n        F_S = Z_S\n        F_T = Z_T\n\n    # 2. Compute covariance matrices\n    C_S = compute_covariance(F_S)\n    C_T = compute_covariance(F_T)\n\n    # 3. Compute CORAL loss\n    C_diff = C_S - C_T\n    loss = np.sum(C_diff**2)  # Squared Frobenius norm\n\n    return loss\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (\n            [[1, 2, 3], [2, 1, 0], [0, 1, 2], [3, 5, 7]], \n            [[2, 0, 1], [1, 1, 1], [4, 2, 0], [0, 3, 6]],\n            [[1, 0], [0, 1], [1, -1]], \n            'identity'\n        ),\n        # Case 2\n        (\n            [[1, 0, 1], [0, 1, 1], [2, 2, 2]],\n            [[1, 0, 1], [0, 1, 1], [2, 2, 2]],\n            [[1, 0], [0, 1], [1, -1]],\n            'relu'\n        ),\n        # Case 3\n        (\n            [[1, 1], [2, 1], [0, 2]],\n            [[3, 1], [1, 0], [0, 3]],\n            [[1], [-2]],\n            'relu'\n        ),\n        # Case 4\n        (\n            [[10, 10]],\n            [[9, 11], [11, 9]],\n            [[1, 0], [0, 1]],\n            'identity'\n        )\n    ]\n\n    results = []\n    for case in test_cases:\n        X_S, X_T, W, activation = case\n        coral_loss = compute_coral_loss(X_S, X_T, W, activation)\n        results.append(coral_loss)\n\n    # Final print statement in the exact required format.\n    # Results are formatted to 6 decimal places.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "超越简单的模型微调，元学习（或“学习如何学习”）旨在训练出能够快速适应新任务的模型初始状态。模型无关元学习 (MAML) 是实现这一目标的强大框架。本练习要求您从第一性原理出发，推导 MAML 算法在遥感图像分割任务中的核心更新法则，包括其精确的二阶外循环更新。完成此推导将为您提供关于高级迁移学习策略背后机制的深刻见解。",
            "id": "3862756",
            "problem": "考虑在异构农业气候区中，为划定作物类型而进行的多光谱卫星图像分割。您正在设计一个基于模型无关元学习 (Model-Agnostic Meta-Learning, MAML) 的元学习流程，以利用每个任务的 $K$-shot 支持集，使分割网络能适应未见过的作物类型。设分割网络为 $f_{\\theta}$，其参数为 $\\theta$，通过一个 softmax 输出层将输入图像 $x$ 映射为 $C$ 个作物类型类别的逐像素类别概率。每个元任务 $i$ 对应一个新的作物类型域（例如，区域-年份组合），包含一个支持集 $\\{(x_{i,k}, y_{i,k})\\}_{k=1}^{K}$ 和一个查询集 $\\{(x_{i,j}^{\\mathrm{val}}, y_{i,j}^{\\mathrm{val}})\\}_{j=1}^{J_{i}}$，其中 $y$ 表示 one-hot 形式的逐像素标签。数据增强遵循一个关于几何-辐射度变换 $T$（例如，旋转、缩放、波段噪声）的变换分布 $p(T)$，并且所有支持集损失都是在 $K$ 个样本和增强分布上进行平均。\n\n您需要从经验风险最小化和带微分链式法则的梯度优化等核心定义出发，根据以下设计，推导二阶 MAML 的单步内层和外层更新：\n1. 对于任务 $i$ 和支持集索引 $k$，单样本增强训练损失为 $L_{i,k}^{\\mathrm{train}}(\\theta; T) = \\ell\\!\\big(y_{i,k}, f_{\\theta}(T(x_{i,k}))\\big)$，其中 $\\ell$ 是一个可微的分割损失（例如，逐像素交叉熵和软 Dice 分数的加权和），并假定其关于 $\\theta$ 二阶连续可微。\n2. 对于任务 $i$，在适应后的参数 $\\phi$ 上评估的验证损失为 $L_{i}^{\\mathrm{val}}(\\phi) = \\frac{1}{J_{i}} \\sum_{j=1}^{J_{i}} \\ell\\!\\big(y_{i,j}^{\\mathrm{val}}, f_{\\phi}(x_{i,j}^{\\mathrm{val}})\\big)$，同样假定其关于 $\\phi$ 二阶连续可微。\n3. 内循环在增强平均的 $K$-shot 经验风险上执行一个步长为 $\\alpha$ 的单梯度步，从初始值 $\\theta$ 生成任务适应参数 $\\phi_{i}$。\n4. 外循环在一个包含 $N$ 个任务的元批次 (meta-batch) 上执行一个步长为 $\\beta$ 的单元更新，通过关于 $\\theta$ 的梯度下降来最小化验证损失之和 $L_{i}^{\\mathrm{val}}(\\phi_{i})$。\n\n仅使用经验风险最小化、梯度下降和微分链式法则等基本原理，且不作任何舍弃二阶导数的一阶近似，请推导：\n- 以 $\\theta$、$K$、$\\alpha$ 和 $p(T)$ 表示的内循环更新 $\\phi_{i}$。\n- 以 $\\theta$、$N$、$\\beta$、支持集损失关于 $\\theta$ 的 Hessian 矩阵、以及在适应后参数上评估的验证损失关于 $\\phi$ 的梯度表示的精确二阶外循环元更新 $\\theta^{\\mathrm{new}}$。\n\n您的最终答案必须是外循环单步元更新 $\\theta^{\\mathrm{new}}$ 的一个单一闭式解析表达式，该表达式以 $N$、$K$、$\\alpha$、$\\beta$、$p(T)$ 以及指定损失的梯度和 Hessian 矩阵表示，并且内循环的适应过程需要显式地代入该表达式中。不需要进行数值评估。请将最终答案表示为单个解析表达式。",
            "solution": "该问题要求推导模型无关元学习 (MAML) 流程的单步内层更新和二阶外层更新。推导将基于经验风险最小化、梯度下降和微分链式法则的原理。\n\n首先，我们根据问题陈述，形式化定义内循环和外循环的目标函数。\n\n对于给定任务 $i$，其内循环目标是增强平均的 $K$-shot 经验风险。我们将其表示为 $\\mathcal{L}_{i}^{\\mathrm{train}}(\\theta)$。它是单样本增强训练损失在 $K$ 个支持样本和增强分布 $p(T)$ 上的平均值。\n单样本增强训练损失由 $L_{i,k}^{\\mathrm{train}}(\\theta; T) = \\ell\\!\\big(y_{i,k}, f_{\\theta}(T(x_{i,k}))\\big)$ 给出。\n该损失在增强分布上的期望为 $\\mathbb{E}_{T \\sim p(T)}[L_{i,k}^{\\mathrm{train}}(\\theta; T)]$。\n在 $K$ 个支持样本上求平均，任务 $i$ 的内循环目标函数为：\n$$\n\\mathcal{L}_{i}^{\\mathrm{train}}(\\theta) = \\frac{1}{K} \\sum_{k=1}^{K} \\mathbb{E}_{T \\sim p(T)}\\left[ \\ell\\!\\big(y_{i,k}, f_{\\theta}(T(x_{i,k}))\\big) \\right]\n$$\n\n外循环目标是一个包含 $N$ 个任务的元批次 (meta-batch) 上验证损失的总和。任务 $i$ 的验证损失 $L_{i}^{\\mathrm{val}}(\\phi)$ 在任务适应参数 $\\phi_i$ 上进行评估。因此，元目标函数 $\\mathcal{L}^{\\mathrm{meta}}(\\theta)$ 为：\n$$\n\\mathcal{L}^{\\mathrm{meta}}(\\theta) = \\sum_{i=1}^{N} L_{i}^{\\mathrm{val}}(\\phi_i(\\theta))\n$$\n其中 $L_{i}^{\\mathrm{val}}(\\phi_i) = \\frac{1}{J_{i}} \\sum_{j=1}^{J_{i}} \\ell\\!\\big(y_{i,j}^{\\mathrm{val}}, f_{\\phi_i}(x_{i,j}^{\\mathrm{val}})\\big)$。\n\n定义好目标函数后，我们来推导更新规则。\n\n**内循环更新规则**\n内循环更新对 $\\mathcal{L}_{i}^{\\mathrm{train}}(\\theta)$ 执行一个步长为 $\\alpha$ 的单梯度下降步，以获得任务特定参数 $\\phi_i$。\n$$\n\\phi_i = \\theta - \\alpha \\nabla_{\\theta} \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta)\n$$\n为了求得梯度 $\\nabla_{\\theta} \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta)$，我们将内循环损失的表达式对 $\\theta$ 求导。假设梯度和期望算子可以互换（一个标准假设）：\n$$\n\\nabla_{\\theta} \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta) = \\nabla_{\\theta} \\left( \\frac{1}{K} \\sum_{k=1}^{K} \\mathbb{E}_{T \\sim p(T)}\\left[ \\ell\\!\\big(y_{i,k}, f_{\\theta}(T(x_{i,k}))\\big) \\right] \\right) = \\frac{1}{K} \\sum_{k=1}^{K} \\mathbb{E}_{T \\sim p(T)}\\left[ \\nabla_{\\theta} \\ell\\!\\big(y_{i,k}, f_{\\theta}(T(x_{i,k}))\\big) \\right]\n$$\n将此代入更新规则，得到内循环更新的表达式：\n$$\n\\phi_i = \\theta - \\frac{\\alpha}{K} \\sum_{k=1}^{K} \\mathbb{E}_{T \\sim p(T)}\\left[ \\nabla_{\\theta} \\ell\\!\\big(y_{i,k}, f_{\\theta}(T(x_{i,k}))\\big) \\right]\n$$\n该表达式将任务 $i$ 的适应后参数 $\\phi_i$ 定义为元参数 $\\theta$ 的函数。\n\n**外循环更新规则（二阶）**\n外循环元更新是在元目标 $\\mathcal{L}^{\\mathrm{meta}}(\\theta)$ 上执行一个步长为 $\\beta$ 的单梯度下降步：\n$$\n\\theta^{\\mathrm{new}} = \\theta - \\beta \\nabla_{\\theta} \\mathcal{L}^{\\mathrm{meta}}(\\theta)\n$$\n元梯度 $\\nabla_{\\theta} \\mathcal{L}^{\\mathrm{meta}}(\\theta)$ 是元批次中每个任务梯度的总和：\n$$\n\\nabla_{\\theta} \\mathcal{L}^{\\mathrm{meta}}(\\theta) = \\nabla_{\\theta} \\left( \\sum_{i=1}^{N} L_{i}^{\\mathrm{val}}(\\phi_i(\\theta)) \\right) = \\sum_{i=1}^{N} \\nabla_{\\theta} L_{i}^{\\mathrm{val}}(\\phi_i(\\theta))\n$$\n为了计算单个任务的梯度 $\\nabla_{\\theta} L_{i}^{\\mathrm{val}}(\\phi_i(\\theta))$，我们必须应用链式法则，因为 $L_{i}^{\\mathrm{val}}$ 是 $\\phi_i$ 的函数，而 $\\phi_i$ 又是 $\\theta$ 的函数。\n设 $\\theta \\in \\mathbb{R}^d$。梯度 $\\nabla_{\\theta} L_{i}^{\\mathrm{val}}(\\phi_i(\\theta))$ 是一个向量，其分量为 $\\frac{\\partial L_{i}^{\\mathrm{val}}}{\\partial \\theta_j}$。根据多元链式法则：\n$$\n\\nabla_{\\theta} L_{i}^{\\mathrm{val}}(\\phi_i(\\theta)) = \\left(\\frac{\\partial \\phi_i}{\\partial \\theta}\\right)^T \\nabla_{\\phi_i} L_{i}^{\\mathrm{val}}(\\phi_i)\n$$\n其中 $\\frac{\\partial \\phi_i}{\\partial \\theta}$ 是向量函数 $\\phi_i(\\theta)$ 关于向量 $\\theta$ 的雅可比矩阵 (Jacobian matrix)，而 $\\nabla_{\\phi_i} L_{i}^{\\mathrm{val}}(\\phi_i)$ 是标量验证损失关于其输入向量 $\\phi_i$ 的梯度。\n\n我们现在必须计算这个雅可比矩阵。从内循环更新方程开始：\n$$\n\\phi_i(\\theta) = \\theta - \\alpha \\nabla_{\\theta} \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta)\n$$\n雅可比矩阵 $\\frac{\\partial \\phi_i}{\\partial \\theta}$ 为：\n$$\n\\frac{\\partial \\phi_i}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta} \\left( \\theta - \\alpha \\nabla_{\\theta} \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta) \\right) = \\frac{\\partial \\theta}{\\partial \\theta} - \\alpha \\frac{\\partial (\\nabla_{\\theta} \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta))}{\\partial \\theta}\n$$\n向量对自身的导数 $\\frac{\\partial \\theta}{\\partial \\theta}$ 是单位矩阵 $I$。项 $\\frac{\\partial (\\nabla_{\\theta} \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta))}{\\partial \\theta}$ 是标量函数 $\\mathcal{L}_{i}^{\\mathrm{train}}(\\theta)$ 的 Hessian 矩阵（海森矩阵）的定义，记为 $\\nabla_{\\theta}^2 \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta)$。\n所以，雅可比矩阵为：\n$$\n\\frac{\\partial \\phi_i}{\\partial \\theta} = I - \\alpha \\nabla_{\\theta}^2 \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta)\n$$\n由于损失函数 $\\ell$ 假定为二阶连续可微，根据克莱罗定理 (Clairaut's theorem)，Hessian 矩阵 $\\nabla_{\\theta}^2 \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta)$ 是对称的。因此，其转置等于自身：$\\left(\\frac{\\partial \\phi_i}{\\partial \\theta}\\right)^T = I - \\alpha \\nabla_{\\theta}^2 \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta)$。\n\n将此代回单个任务元梯度的链式法则表达式中：\n$$\n\\nabla_{\\theta} L_{i}^{\\mathrm{val}}(\\phi_i(\\theta)) = \\left( I - \\alpha \\nabla_{\\theta}^2 \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta) \\right) \\nabla_{\\phi_i} L_{i}^{\\mathrm{val}}(\\phi_i)\n$$\n这就是精确的二阶梯度。乘积中的第一项 $(I - \\alpha \\nabla_{\\theta}^2 \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta) )$ 涉及训练损失的 Hessian 矩阵。该项解释了训练损失的梯度如何随 $\\theta$ 变化，这对于找到一个对快速适应敏感的初始值 $\\theta$ 至关重要。\n\n最后，我们通过代入所有定义来组装完整的元更新规则。\n内循环损失的 Hessian 矩阵为：\n$$\n\\nabla_{\\theta}^2 \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta) = \\frac{1}{K} \\sum_{k=1}^{K} \\mathbb{E}_{T \\sim p(T)}\\left[ \\nabla_{\\theta}^2 \\ell\\!\\big(y_{i,k}, f_{\\theta}(T(x_{i,k}))\\big) \\right]\n$$\n验证损失关于适应后参数 $\\phi$ 的梯度为：\n$$\n\\nabla_{\\phi} L_{i}^{\\mathrm{val}}(\\phi) = \\frac{1}{J_{i}} \\sum_{j=1}^{J_{i}} \\nabla_{\\phi} \\ell\\!\\big(y_{i,j}^{\\mathrm{val}}, f_{\\phi}(x_{i,j}^{\\mathrm{val}})\\big)\n$$\n该梯度必须在 $\\phi = \\phi_i$ 处进行评估。\n\n综合所有部分，单步外循环更新 $\\theta^{\\mathrm{new}}$ 的完整表达式为：\n$$\n\\theta^{\\mathrm{new}} = \\theta - \\beta \\sum_{i=1}^{N} \\left( I - \\alpha \\nabla_{\\theta}^2 \\mathcal{L}_{i}^{\\mathrm{train}}(\\theta) \\right) \\left. \\nabla_{\\phi} L_{i}^{\\mathrm{val}}(\\phi) \\right|_{\\phi=\\phi_i}\n$$\n将损失和内循环更新的显式形式代入，得到最终表达式，该表达式在最终答案中给出。请注意，在代入的 $\\phi_i$ 表达式中使用了不同的哑索引（$k', T'$）以避免歧义。",
            "answer": "$$\\boxed{\\theta^{\\mathrm{new}} = \\theta - \\beta \\sum_{i=1}^{N} \\left( I - \\frac{\\alpha}{K} \\sum_{k=1}^{K} \\mathbb{E}_{T \\sim p(T)}\\Big[ \\nabla_{\\theta}^2 \\ell\\big(y_{i,k}, f_{\\theta}(T(x_{i,k}))\\big) \\Big] \\right) \\left. \\left( \\frac{1}{J_i} \\sum_{j=1}^{J_i} \\nabla_{\\phi} \\ell\\big(y_{i,j}^{\\mathrm{val}}, f_{\\phi}(x_{i,j}^{\\mathrm{val}})\\big) \\right) \\right|_{\\phi = \\theta - \\frac{\\alpha}{K} \\sum_{k'=1}^{K} \\mathbb{E}_{T' \\sim p(T')}\\left[ \\nabla_{\\theta} \\ell\\big(y_{i,k'}, f_{\\theta}(T'(x_{i,k'}))\\big) \\right]}}$$"
        }
    ]
}