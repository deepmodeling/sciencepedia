{
    "hands_on_practices": [
        {
            "introduction": "在我们能够处理等效性问题之前，我们需要有能力量化地诊断它。本练习将介绍费雪信息矩阵（Fisher Information Matrix, FIM）作为一种强大的局部诊断工具，它通过分析模型对参数变化的敏感性来揭示参数的可识别性。通过计算 FIM 的特征值，我们可以识别参数空间中的“草率”(sloppy) 和“刚性”(stiff) 方向，从而为评估和理解模型解的非唯一性提供坚实的数学基础 。",
            "id": "3810068",
            "problem": "考虑一个用于天底视角双向反射率的风格化、无量纲正向模型，该模型捕捉了随冠层覆盖度增加而产生的饱和效应，通常在遥感和环境建模中用作替代模型。对于已知的无量纲光照或结构驱动因子 $x_i$ 和参数 $\\boldsymbol{\\theta} = (a,b,c)$，模型在样本 $i$ 处预测的反射率为\n$$\ny_i(\\boldsymbol{\\theta}) = a \\left(1 - e^{-b x_i}\\right) + c \\, ,\n$$\n其测量误差为独立同分布的高斯误差，均值为零，方差为 $\\sigma^2$。假设测量算子是无偏的，并且模型在给定参数向量 $\\boldsymbol{\\theta}_0$ 的邻域内线性化是有效的。在这些假设下，$\\boldsymbol{\\theta}_0$ 附近的负对数似然可以由灵敏度（雅可比矩阵）和费雪信息矩阵（FIM）导出的二次型很好地近似。\n\n您的任务纯粹是数学和算法方面的：\n- 使用带有高斯误差的最小二乘法第一性原理，在 $\\boldsymbol{\\theta}_0$ 处定义灵敏度雅可比矩阵 $J \\in \\mathbb{R}^{N \\times 3}$，其中 $N$ 是样本数。然后构建费雪信息矩阵 $F \\in \\mathbb{R}^{3 \\times 3}$ 如下\n$$\nF = J^\\top W J \\, ,\n$$\n其中 $W = \\sigma^{-2} I_N$。\n- 根据 $F$，通过以下度量来量化 $\\boldsymbol{\\theta}_0$ 邻域内的参数“含糊性”（sloppiness）和“异参同效性”（equifinality）：\n    1. 含糊性比率 $r = \\lambda_{\\min}(F)/\\lambda_{\\max}(F)$，其中 $\\lambda_{\\min}$ 和 $\\lambda_{\\max}$ 是 $F$ 的最小和最大特征值。声明一个布尔值 $\\mathrm{is\\_sloppy}$，如果 $r  \\tau$，则其为 $\\mathrm{True}$，否则为 $\\mathrm{False}$，阈值 $\\tau = 10^{-4}$。\n    2. 谱条件数 $\\kappa = \\lambda_{\\max}(F)/\\lambda_{\\min}(F)$。\n    3. 在失配容差 $\\varepsilon > 0$ 下的局部异参同效性指数，由 $(\\Delta \\chi^2 = \\varepsilon)$ 置信椭球体积的高斯线性近似定义：\n$$\nE(\\varepsilon) = \\frac{\\varepsilon^{p/2}}{\\sqrt{\\det(F)}} \\, ,\n$$\n其中 $p = 3$ 是参数的数量。该指数是无量纲的，并且在二次近似下，它与不可区分的参数集体积单调相关。\n\n您必须依赖的基本原理：\n- 具有独立同分布噪声的高斯误差模型意味着最小二乘目标和费雪信息矩阵 $F = J^\\top W J$。\n- 可微模型 $y(\\boldsymbol{\\theta})$ 在 $\\boldsymbol{\\theta}_0$ 附近的线性化得出 $y(\\boldsymbol{\\theta}_0 + \\delta\\boldsymbol{\\theta}) \\approx y(\\boldsymbol{\\theta}_0) + J \\, \\delta\\boldsymbol{\\theta}$。\n- 上面定义的异参同效性指数源于这样一个事实：对于高斯误差和二次近似，置信区域是椭球体，其体积与 $1/\\sqrt{\\det(F)}$ 成正比，并随 $\\varepsilon^{p/2}$ 缩放。\n\n需要实现的模型细节：\n- 雅可比矩阵 $J$ 的条目由 $y_i(\\boldsymbol{\\theta})$ 在 $\\boldsymbol{\\theta}_0$ 处的偏导数计算得出：\n$$\n\\frac{\\partial y_i}{\\partial a} = 1 - e^{-b x_i}, \\quad\n\\frac{\\partial y_i}{\\partial b} = a \\, x_i \\, e^{-b x_i}, \\quad\n\\frac{\\partial y_i}{\\partial c} = 1 \\, .\n$$\n\n测试套件：\n对于下面的每个测试用例，使用指定的输入计算 $\\mathrm{is\\_sloppy}$、$\\kappa$ 和 $E(\\varepsilon)$。所有量都是无量纲的。在每种情况下使用 $N = 20$ 个样本，并将 $x_i$ 定义为所述区间上的线性间隔网格，包括端点。\n\n- 案例1（驱动因子分布良好，低噪声，中等非线性）：\n    - $x_i$ 在 $[0,5]$ 上，$N=20$。\n    - $\\boldsymbol{\\theta}_0 = (a,b,c) = (0.6, 0.8, 0.05)$。\n    - $\\sigma = 0.01$。\n    - $\\varepsilon = 1.0$。\n- 案例2（小曲率参数导致权衡性含糊）：\n    - $x_i$ 在 $[0,1]$ 上，$N=20$。\n    - $\\boldsymbol{\\theta}_0 = (a,b,c) = (0.6, 0.02, 0.05)$。\n    - $\\sigma = 0.01$。\n    - $\\varepsilon = 1.0$。\n- 案例3（高噪声，驱动因子与案例1相同）：\n    - $x_i$ 在 $[0,5]$ 上，$N=20$。\n    - $\\boldsymbol{\\theta}_0 = (a,b,c) = (0.6, 0.8, 0.05)$。\n    - $\\sigma = 0.1$。\n    - $\\varepsilon = 1.0$。\n- 案例4（驱动因子范围窄导致近线性不可区分性）：\n    - $x_i$ 在 $[0,0.1]$ 上，$N=20$。\n    - $\\boldsymbol{\\theta}_0 = (a,b,c) = (0.6, 0.8, 0.05)$。\n    - $\\sigma = 0.01$。\n    - $\\varepsilon = 1.0$。\n\n最终输出规范：\n- 对于每个案例，生成一个列表 $[\\mathrm{is\\_sloppy}, \\kappa, E]$，其中 $\\mathrm{is\\_sloppy}$ 是一个布尔值，两个浮点值四舍五入到六位有效数字。\n- 您的程序应生成单行输出，其中包含四个案例的结果，格式为一个逗号分隔的列表，用方括号括起来，每个案例由其列表表示，没有空格，例如：$[[\\mathrm{True},123.456,0.00123],[\\mathrm{False},\\dots,\\dots],\\dots]$。",
            "solution": "该问题是有效的。这是一个结构良好、有科学依据的练习，涉及基于费雪信息矩阵（FIM）的参数灵敏度分析和不确定性量化。FIM是参数模型统计推断的基石。所有提供的信息都是自洽、一致且数学上精确的。\n\n目标是使用从FIM派生的度量来分析非线性模型的参数可辨识性。该模型将反射率 $y_i$ 描述为环境驱动因子 $x_i$ 和参数向量 $\\boldsymbol{\\theta} = (a, b, c)$ 的函数：\n$$\ny_i(\\boldsymbol{\\theta}) = a \\left(1 - e^{-b x_i}\\right) + c\n$$\n我们假设测量误差是均值为0、方差为 $\\sigma^2$ 的独立同分布高斯变量。在此假设下，FIM提供了围绕点估计 $\\boldsymbol{\\theta}_0$ 的负对数似然函数的二阶近似。\n\n分析按以下步骤进行：\n\n1.  **构建灵敏度（雅可比）矩阵 $J$**。\n    雅可比矩阵 $J$ 包含模型输出相对于每个参数的一阶偏导数，这些偏导数是针对 $N$ 个数据样本在参数向量 $\\boldsymbol{\\theta}_0 = (a_0, b_0, c_0)$ 处计算的。条目 $J_{ik}$ 是 $\\frac{\\partial y_i}{\\partial \\theta_k} |_{\\boldsymbol{\\theta}_0}$。对于给定模型，$N \\times 3$ 的雅可比矩阵的列对应于关于 $a$、$b$ 和 $c$ 的导数：\n    $$\n    J_{i1} = \\frac{\\partial y_i}{\\partial a} \\bigg|_{\\boldsymbol{\\theta}_0} = 1 - e^{-b_0 x_i}\n    $$\n    $$\n    J_{i2} = \\frac{\\partial y_i}{\\partial b} \\bigg|_{\\boldsymbol{\\theta}_0} = a_0 x_i e^{-b_0 x_i}\n    $$\n    $$\n    J_{i3} = \\frac{\\partial y_i}{\\partial c} \\bigg|_{\\boldsymbol{\\theta}_0} = 1\n    $$\n\n2.  **构建费雪信息矩阵 $F$**。\n    FIM定义为 $F = J^\\top W J$。权重矩阵 $W$ 是数据协方差矩阵的逆。对于方差为 $\\sigma^2$ 的独立同分布误差，协方差矩阵为 $\\sigma^2 I_N$，其中 $I_N$ 是 $N \\times N$ 的单位矩阵。因此，$W = (\\sigma^2 I_N)^{-1} = \\sigma^{-2} I_N$。\n    将 $W$ 代入 $F$ 的定义中得到：\n    $$\n    F = J^\\top (\\sigma^{-2} I_N) J = \\frac{1}{\\sigma^2} J^\\top J\n    $$\n    $F$ 是一个 $3 \\times 3$ 的对称半正定矩阵。其特征值 $\\lambda_k$ 量化了模型沿相应特征向量方向（参数不确定性椭球的主轴）对参数变化的敏感度。\n\n3.  **从 $F$ 的特征值计算可辨识性度量**。\n    设 $\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_p$ 为 $F$ 的有序特征值，其中 $p=3$ 是参数的数量。\n    - **含糊性比率 ($r$) 和条件数 ($\\kappa$)**：特征值的大范围分布表明模型是“含糊的”（sloppy）——即在某些方向上对参数变化非常敏感（大特征值），但在其他方向上非常不敏感（小特征值）。这种结构特性由FIM的条件数来量化。该问题定义了两个相关度量：\n        - 含糊性比率 $r = \\lambda_{\\min}(F) / \\lambda_{\\max}(F)$。接近于0的 $r$ 值表示高度含糊。如果 $r  \\tau = 10^{-4}$，我们宣布模型是含糊的。\n        - 谱条件数 $\\kappa = \\lambda_{\\max}(F) / \\lambda_{\\min}(F) = 1/r$。一个大的 $\\kappa$ 值表示一个病态问题，其中数据的微小变化可能导致参数估计的巨大变化，这是可辨识性差的一个标志。\n\n    - **局部异参同效性指数 $E(\\varepsilon)$**：此度量在失配容差 $\\varepsilon$ 下，量化了能产生与 $\\boldsymbol{\\theta}_0$ 处预测在统计上不可区分的模型预测的参数空间体积。对于具有高斯误差的线性化模型，卡方统计量变化 ($\\Delta \\chi^2$) 小于或等于 $\\varepsilon$ 的区域形成一个椭球。该椭球的体积与 $1/\\sqrt{\\det(F)}$ 成正比。给定的指数是这种关系的形式化表达：\n        $$\n        E(\\varepsilon) = \\frac{\\varepsilon^{p/2}}{\\sqrt{\\det(F)}}\n        $$\n        由于行列式是特征值的乘积，$\\det(F) = \\prod_{k=1}^p \\lambda_k$，一个非常小的特征值就会使行列式变小，从而导致一个大的异参同效性指数 $E(\\varepsilon)$。这表明存在一个巨大的“异参同效”参数集，这些参数集对数据的拟合效果几乎同样好。\n\n每个测试用例的算法如下：\na.  在指定区间上生成包含 $N=20$ 个驱动因子 $x_i$ 的向量。\nb.  使用提供的 $\\boldsymbol{\\theta}_0 = (a_0, b_0, c_0)$，构建 $20 \\times 3$ 雅可比矩阵 $J$ 的三列。\nc.  计算 FIM $F = \\frac{1}{\\sigma^2} J^\\top J$。\nd.  计算对称矩阵 $F$ 的特征值，确定 $\\lambda_{\\min}$ 和 $\\lambda_{\\max}$。\ne.  计算 $r = \\lambda_{\\min} / \\lambda_{\\max}$，并通过将 $r$ 与阈值 $\\tau=10^{-4}$ 比较来确定布尔值 $\\mathrm{is\\_sloppy}$。\nf.  计算 $\\kappa = \\lambda_{\\max} / \\lambda_{\\min}$。\ng.  计算行列式 $\\det(F)$，并用它来计算异参同效性指数 $E(\\varepsilon)$，其中 $p=3$ 且 $\\varepsilon$ 为指定值。\nh.  按要求格式化生成的布尔值和两个浮点数。\n\n此过程系统地应用于四个测试用例中的每一个，这些用例旨在探究参数不可辨识性的不同方面：结构性权衡（案例2、4）和测量噪声的影响（案例3）。",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Computes sloppiness and equifinality metrics for a nonlinear model\n    based on the Fisher Information Matrix for four test cases.\n    \"\"\"\n\n    def round_to_sf(x, sf):\n        \"\"\"\n        Rounds a number x to a specified number of significant figures (sf).\n        \"\"\"\n        if x == 0:\n            return 0.0\n        if not np.isfinite(x):\n            return x\n        order = math.floor(math.log10(abs(x)))\n        decimals = sf - 1 - order\n        return round(x, decimals)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: well-spread drivers, low noise, moderate nonlinearity\n        {'x_interval': [0, 5], 'N': 20, 'theta_0': (0.6, 0.8, 0.05), 'sigma': 0.01, 'epsilon': 1.0, 'p': 3},\n        # Case 2: small curvature parameter inducing trade-off sloppiness\n        {'x_interval': [0, 1], 'N': 20, 'theta_0': (0.6, 0.02, 0.05), 'sigma': 0.01, 'epsilon': 1.0, 'p': 3},\n        # Case 3: high noise, same drivers as Case 1\n        {'x_interval': [0, 5], 'N': 20, 'theta_0': (0.6, 0.8, 0.05), 'sigma': 0.1, 'epsilon': 1.0, 'p': 3},\n        # Case 4: narrow driver range causing near-linear indistinguishability\n        {'x_interval': [0, 0.1], 'N': 20, 'theta_0': (0.6, 0.8, 0.05), 'sigma': 0.01, 'epsilon': 1.0, 'p': 3}\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        x_interval = case['x_interval']\n        N = case['N']\n        a0, b0, c0 = case['theta_0']\n        sigma = case['sigma']\n        epsilon = case['epsilon']\n        p = case['p']\n        tau = 1e-4\n\n        # Generate the driver variable grid\n        x = np.linspace(x_interval[0], x_interval[1], N)\n\n        # 1. Construct the Sensitivity (Jacobian) Matrix J\n        # Partial derivative w.r.t. 'a'\n        j_a = 1 - np.exp(-b0 * x)\n        # Partial derivative w.r.t. 'b'\n        j_b = a0 * x * np.exp(-b0 * x)\n        # Partial derivative w.r.t. 'c'\n        j_c = np.ones(N)\n        \n        J = np.stack([j_a, j_b, j_c], axis=1)\n\n        # 2. Construct the Fisher Information Matrix F\n        F = (1 / sigma**2) * (J.T @ J)\n\n        # 3. Compute metrics from eigenvalues of F\n        # Use eigvalsh for symmetric matrices for numerical stability\n        eigenvalues = np.linalg.eigvalsh(F)\n        lambda_min = np.min(eigenvalues)\n        lambda_max = np.max(eigenvalues)\n\n        # Ensure lambda_min is not zero to avoid division errors\n        if lambda_min == 0:\n            # For this problem setup, eigenvalues should be positive,\n            # but this handles potential numerical underflow.\n            # A non-positive min eigenvalue indicates extreme sloppiness.\n            is_sloppy = True\n            kappa = np.inf\n            E_eps = np.inf\n        else:\n            # Sloppiness ratio and boolean\n            r = lambda_min / lambda_max\n            is_sloppy = r  tau\n\n            # Spectral condition number\n            kappa = lambda_max / lambda_min\n\n            # Local equifinality index\n            det_F = np.linalg.det(F)\n            if det_F == 0:\n                E_eps = np.inf\n            else:\n                E_eps = (epsilon**(p / 2)) / np.sqrt(det_F)\n\n        # Format results to 6 significant figures\n        kappa_rounded = round_to_sf(kappa, 6)\n        E_eps_rounded = round_to_sf(E_eps, 6)\n        \n        case_result = [is_sloppy, kappa_rounded, E_eps_rounded]\n        all_results.append(case_result)\n\n    # Format the final output string exactly as specified (list of lists, no spaces)\n    results_str_list = []\n    for res in all_results:\n        # Manually construct the string for each inner list to control spacing\n        s = f\"[{res[0]},{res[1]},{res[2]}]\"\n        results_str_list.append(s)\n        \n    final_output = f\"[{','.join(results_str_list)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "在学会如何诊断等效性之后，本练习旨在探索其在实际应用中的具体后果。我们采用环境建模中常见的校准-验证工作流程，您将通过一个简化的水文模型来体验这一过程。此案例研究将清晰地揭示，一组在校准期间表现同样出色的“等效”参数集，在面对新的验证数据时，其预测结果可能出现显著分歧，这凸显了在模型预测中忽略等效性所带来的风险 。",
            "id": "3810082",
            "problem": "考虑一个单层土壤湿度桶模型，该模型由每日入渗通量驱动，并受到线性蒸散和阈值排水的影响。设状态变量为离散时间 $t$（每日时间步长 $\\Delta t = 1$ 天）下的体积含水量 $S_t$，单位为 $\\mathrm{m^3\\,m^{-3}}$。每日入渗驱动序列为 $P_t$，单位为 $\\mathrm{m^3\\,m^{-3}\\,day^{-1}}$。该模型通过蒸散 $E_t$ 和排水 $Q_t$ 来移除水分，其定义如下：\n$$\nE_t = k_e\\, S_t, \\qquad Q_t = k_q\\, \\max\\!\\left(0,\\, S_t - S_{\\mathrm{fc}}\\right),\n$$\n其中参数 $k_e$ 和 $k_q$ 的单位为 $\\mathrm{day^{-1}}$，$S_{\\mathrm{fc}}$ 的单位为 $\\mathrm{m^3\\,m^{-3}}$。预报更新（采用前向欧拉法并裁剪到物理边界）为：\n$$\nS_{t+1} = \\operatorname{clip}\\!\\left(S_t + P_t - E_t - Q_t,\\, 0,\\, S_{\\max}\\right),\n$$\n其中 $\\operatorname{clip}(x,0,S_{\\max}) = \\min\\!\\left(\\max\\!\\left(0, x\\right), S_{\\max}\\right)$，$S_{\\max}$ 是最大体积含水量。遥感观测算子被视为直接的体积含水量，其测量噪声可忽略不计，即：\n$$\ny_t = S_t.\n$$\n\n此公式体现了等效性（equifinality，模型解的非唯一性），因为当 $S_t$ 在一段时间内小于 $S_{\\mathrm{fc}}$ 时，排水量 $Q_t$ 恒为零，此时 $k_q$ 和 $S_{\\mathrm{fc}}$ 从这些观测中是不可辨识的，因此多种参数组合会产生无法区分的轨迹，这些轨迹都能同样好地拟合率定数据。\n\n您必须实现一个程序，该程序使用参数范围上的网格搜索，在等效性条件下执行率定和验证，计算指定率定容差下的等效集，并量化等效性如何影响验证性能。\n\n需要使用的基本原理和定义：\n- 控制体层面的水量平衡：$dS/dt = P - E - Q$。\n- 通过前向欧拉法进行离散时间近似：$S_{t+1} = S_t + P_t - E_t - Q_t$，然后进行裁剪。\n- 遥感观测算子恒等式：$y_t = S_t$。\n- 均方根误差 (RMSE)：对于 $T$ 个时间步长上的模型预测序列 $\\hat{y}_t$ 和观测序列 $y_t$，RMSE 为：\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{T}\\sum_{t=1}^{T}\\left(\\hat{y}_t - y_t\\right)^2}.\n$$\n\n使用以下物理上一致的常数和序列（除非另有说明，单位均为 $\\mathrm{m^3\\,m^{-3}}$）：\n- 最大体积含水量：$S_{\\max} = 0.45$。\n- 初始条件：$S_0 = 0.15$。\n- 用于生成观测的真实参数：$k_e^\\star = 0.06$, $k_q^\\star = 0.18$, $S_{\\mathrm{fc}}^\\star = 0.32$。\n\n率定驱动序列（长度为 $12$）：\n$$\nP^{\\mathrm{cal}} = [0.015,\\, 0.000,\\, 0.010,\\, 0.000,\\, 0.020,\\, 0.000,\\, 0.015,\\, 0.000,\\, 0.010,\\, 0.000,\\, 0.020,\\, 0.000].\n$$\n\n验证驱动序列（长度为 $12$）：\n$$\nP^{\\mathrm{val}} = [0.050,\\, 0.040,\\, 0.000,\\, 0.030,\\, 0.025,\\, 0.000,\\, 0.060,\\, 0.000,\\, 0.040,\\, 0.030,\\, 0.000,\\, 0.050].\n$$\n\n观测数据是通过使用真实参数在各自的驱动序列上模拟模型生成的，即 $y_t^{\\mathrm{cal}}$ 和 $y_t^{\\mathrm{val}}$ 是在使用 $(k_e^\\star, k_q^\\star, S_{\\mathrm{fc}}^\\star)$、$S_0$ 和 $S_{\\max}$ 的条件下，分别在 $P^{\\mathrm{cal}}$ 和 $P^{\\mathrm{val}}$ 驱动下得到的 $S_t$ 轨迹。\n\n对于下面定义的每个测试用例，执行以下步骤：\n1. 使用每个参数给定的最小值、最大值和数量，为 $k_e$、$k_q$ 和 $S_{\\mathrm{fc}}$ 构建均匀网格。网格点必须包含两个端点并且是线性间隔的。\n2. 对于网格中的每个参数三元组 $(k_e, k_q, S_{\\mathrm{fc}})$，在 $P^{\\mathrm{cal}}$ 上模拟模型以生成 $\\hat{y}_t^{\\mathrm{cal}}$，并根据 $y_t^{\\mathrm{cal}}$ 计算率定 $\\mathrm{RMSE}_{\\mathrm{cal}}$。\n3. 将等效集 $\\mathcal{E}$ 定义为所有其 $\\mathrm{RMSE}_{\\mathrm{cal}}$ 小于或等于测试用例容差 $\\tau$ 的参数三元组。\n4. 对于 $\\mathcal{E}$ 中的每个参数三元组，在 $P^{\\mathrm{val}}$ 上模拟模型以生成 $\\hat{y}_t^{\\mathrm{val}}$，并根据 $y_t^{\\mathrm{val}}$ 计算验证 $\\mathrm{RMSE}_{\\mathrm{val}}$。\n5. 计算该测试用例的以下汇总指标：\n   - 整数基数 $N = |\\mathcal{E}|$。\n   - $\\mathcal{E}$ 上验证 RMSE 值的均值，记为 $\\overline{R}_{\\mathrm{val}}$（一个浮点数，单位为 $\\mathrm{m^3\\,m^{-3}}$）。\n   - $\\mathcal{E}$ 上验证 RMSE 值的方差，记为 $\\mathrm{Var}(R_{\\mathrm{val}})$（一个浮点数，单位为 $(\\mathrm{m^3\\,m^{-3}})^2$）。\n   - 一个指示率定-验证不匹配的布尔诊断指标：令 $(k_e^{\\dagger}, k_q^{\\dagger}, S_{\\mathrm{fc}}^{\\dagger})$ 为在整个网格中实现最小 $\\mathrm{RMSE}_{\\mathrm{cal}}$ 的参数三元组中字典序最前的一个（即，在所有具有最小 $\\mathrm{RMSE}_{\\mathrm{cal}}$ 的三元组中，选择 $k_e$ 最小的，如果相同，则选择 $k_q$ 最小的，如果仍然相同，则选择 $S_{\\mathrm{fc}}$ 最小的）。令 $R_{\\mathrm{val}}^{\\dagger}$ 为其验证 RMSE。如果 $R_{\\mathrm{val}}^{\\dagger}$ 严格大于 $\\mathcal{E}$ 上的最小验证 RMSE，则该诊断指标为 $\\texttt{True}$；否则为 $\\texttt{False}$。\n6. 边界情况处理：如果 $N = 0$，则设置 $\\overline{R}_{\\mathrm{val}} = -1.0$，$\\mathrm{Var}(R_{\\mathrm{val}}) = -1.0$，并且布尔诊断指标为 $\\texttt{False}$。\n\n测试套件（三个测试用例）：\n- 测试用例 1（理想情况下的等效性）：\n  - $k_e$ 网格：最小值 $0.06$，最大值 $0.06$，数量 $1$。\n  - $k_q$ 网格：最小值 $0.00$，最大值 $0.30$，数量 $7$。\n  - $S_{\\mathrm{fc}}$ 网格：最小值 $0.25$，最大值 $0.35$，数量 $6$。\n  - 率定容差：$\\tau = 0.0$。\n- 测试用例 2（边界情况：无等效解）：\n  - $k_e$ 网格：最小值 $0.02$，最大值 $0.055$，数量 $8$。\n  - $k_q$ 网格：最小值 $0.00$，最大值 $0.30$，数量 $7$。\n  - $S_{\\mathrm{fc}}$ 网格：最小值 $0.25$，最大值 $0.35$，数量 $6$。\n  - 率定容差：$\\tau = 0.0$。\n- 测试用例 3（中等容差：多个等效解）：\n  - $k_e$ 网格：最小值 $0.03$，最大值 $0.09$，数量 $7$。\n  - $k_q$ 网格：最小值 $0.00$，最大值 $0.30$，数量 $7$。\n  - $S_{\\mathrm{fc}}$ 网格：最小值 $0.25$，最大值 $0.35$，数量 $6$。\n  - 率定容差：$\\tau = 0.005$。\n\n所需单位：\n- 以 $\\mathrm{m^3\\,m^{-3}}$ 和 $(\\mathrm{m^3\\,m^{-3}})^2$ 分别报告 $\\overline{R}_{\\mathrm{val}}$ 和 $\\mathrm{Var}(R_{\\mathrm{val}})$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。每个测试用例的结果是一个形式为 $[N,\\, \\overline{R}_{\\mathrm{val}},\\, \\mathrm{Var}(R_{\\mathrm{val}}),\\, \\texttt{boolean}]$ 的列表。例如，一个有效的输出格式是 $[[3,0.0042,1.6e-06,True],[0,-1.0,-1.0,False],[12,0.0068,2.1e-06,True]]$。",
            "solution": "该问题要求实现并分析一个单层土壤湿度桶模型，以展示环境建模中的等效性概念。该过程涉及使用网格搜索方法进行参数率定和验证。\n\n模型的核心是在离散的每日时间步长 $t$ 下，体积土壤含水量 $S_t$ 的水量平衡方程。储水量的变化由外部入渗通量 $P_t$ 驱动，并被两个内部过程消耗：蒸散 $E_t$ 和排水 $Q_t$。预报方程是水量平衡微分方程的前向欧拉离散化：\n\n$$\n\\frac{dS}{dt} = P - E - Q\n$$\n\n这被近似为：\n$$\nS_{t+1}^{\\text{raw}} = S_t + (P_t - E_t - Q_t) \\Delta t\n$$\n由于时间步长 $\\Delta t$ 为 1 天，且 $P,E,Q$ 的单位为 $\\mathrm{day^{-1}}$，该方程简化为：\n$$\nS_{t+1}^{\\text{raw}} = S_t + P_t - E_t - Q_t\n$$\n\n各组分通量定义如下：\n1.  蒸散 $E_t = k_e S_t$：当前含水量的线性函数，由速率常数 $k_e$ 参数化。\n2.  排水 $Q_t = k_q \\max(0, S_t - S_{\\mathrm{fc}})$：一个阈值线性函数，当含水量超过田间持水量阈值 $S_{\\mathrm{fc}}$ 时才非零。排水速率由参数 $k_q$ 控制。\n\n为了保持物理真实性，最终的含水量 $S_{t+1}$ 被限制在 0（完全干燥）和最大饱和容量 $S_{\\max}$ 之间：\n$$\nS_{t+1} = \\operatorname{clip}(S_{t+1}^{\\text{raw}}, 0, S_{\\max}) = \\min(\\max(0, S_{t+1}^{\\text{raw}}), S_{\\max})\n$$\n\n总体流程如下：\n首先，我们通过定义一组已知参数 $(k_e^\\star, k_q^\\star, S_{\\mathrm{fc}}^\\star)$ 来建立一个“基准真相”(ground truth)。使用这些真实参数，我们用两个不同的驱动序列 $P^{\\mathrm{cal}}$ 和 $P^{\\mathrm{val}}$ 来模拟模型，以生成合成的观测数据集 $y_t^{\\mathrm{cal}}$ 和 $y_t^{\\mathrm{val}}$。这些数据分别代表我们假设用于率定和验证的数据。\n\n接下来，对于每个测试用例，我们在指定的参数 $k_e$、$k_q$ 和 $S_{\\mathrm{fc}}$ 范围内执行网格搜索。对于网格中的每个参数组合 $(k_e, k_q, S_{\\mathrm{fc}})$：\n1.  我们使用率定驱动 $P^{\\mathrm{cal}}$ 模拟模型，生成预测轨迹 $\\hat{y}_t^{\\mathrm{cal}}$。\n2.  我们通过计算预测值与基准真相观测值之间的均方根误差 (RMSE) 来量化模型性能，$\\mathrm{RMSE}_{\\mathrm{cal}} = \\sqrt{\\frac{1}{T}\\sum_{t=1}^{T}(\\hat{y}_t^{\\mathrm{cal}} - y_t^{\\mathrm{cal}})^2}$。\n\n等效性是这里的核心概念。它指的是多个不同参数集能够产生同样好（或至少可接受地好）地拟合率定数据的模型输出的现象。我们通过定义一个“等效集” $\\mathcal{E}$ 来将其形式化，该集合是所有其 $\\mathrm{RMSE}_{\\mathrm{cal}}$ 低于给定容差 $\\tau$ 的参数三元组的集合。该集合的大小 $N=|\\mathcal{E}|$ 是等效性程度的直接度量。\n\n关键步骤是评估这种等效性对模型预测能力的影响。对于 $\\mathcal{E}$ 内的每个参数集，我们使用独立的驱动序列 $P^{\\mathrm{val}}$ 进行验证运行，并计算验证误差 $\\mathrm{RMSE}_{\\mathrm{val}}$。这些验证误差的分布揭示了我们预测的不确定性。我们计算这些误差的均值 $\\overline{R}_{\\mathrm{val}}$ 和方差 $\\mathrm{Var}(R_{\\mathrm{val}})$。高方差表明，尽管许多参数集都能拟合率定数据，但它们在不同条件下的预测却显著不同，这对可靠的预报构成了挑战。\n\n最后，我们计算一个诊断指标来检查率定-验证不匹配。我们从率定阶段识别出唯一的“最佳”参数集 $(k_e^{\\dagger}, k_q^{\\dagger}, S_{\\mathrm{fc}}^{\\dagger})$，它被定义为实现最小 $\\mathrm{RMSE}_{\\mathrm{cal}}$ 的那个（并采用字典序来解决平局问题）。然后我们检查该参数集是否在验证阶段也表现最佳（即，在 $\\mathcal{E}$ 中所有集合中产生最小的 $\\mathrm{RMSE}_{\\mathrm{val}}$）。如果其验证误差 $R_{\\mathrm{val}}^{\\dagger}$ 严格大于 $\\mathcal{E}$ 中某个成员可能产生的最小验证误差，这就凸显了模型选择中的一个关键问题：率定效果最好的模型不一定是预测能力最好的模型。\n\n测试用例的特定设计旨在突显这些原则。测试用例 1 使用的率定驱动 $P^{\\mathrm{cal}}$ 永远不会导致土壤湿度 $S_t$ 超过田间持水量阈值 $S_{\\mathrm{fc}}$。因此，排水项 $Q_t$ 始终为零，使得参数 $k_q$ 和 $S_{\\mathrm{fc}}$ 不可辨识。这导致了一个大的等效集。验证驱动 $P^{\\mathrm{val}}$ 更强，会激活排水，从而揭示等效参数集之间的性能差异。测试用例 2 使用的参数网格错过了真实参数 $k_e^\\star$，并且容差严格为 $\\tau=0.0$，导致等效集为空。测试用例 3 使用更宽的网格和更宽松的容差，代表了一个更典型的率定场景。\n\n实现将首先定义一个模型模拟函数。然后，对于每个测试用例，我们将生成基准真相，执行网格搜索，识别等效集，计算验证统计数据，并确定布尔诊断指标，严格遵循指定的逻辑。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to perform model calibration and validation under equifinality.\n    \"\"\"\n    # === Fundamental Constants and Forcing Sequences ===\n    S_max = 0.45\n    S0 = 0.15\n    ground_truth_params = (0.06, 0.18, 0.32)\n    P_cal = np.array([0.015, 0.000, 0.010, 0.000, 0.020, 0.000, 0.015, 0.000, 0.010, 0.000, 0.020, 0.000])\n    P_val = np.array([0.050, 0.040, 0.000, 0.030, 0.025, 0.000, 0.060, 0.000, 0.040, 0.030, 0.000, 0.050])\n\n    # === Test Suite Definition ===\n    test_cases = [\n        # Test Case 1: Happy path equifinality\n        {'ke_grid': (0.06, 0.06, 1), 'kq_grid': (0.00, 0.30, 7), 'sfc_grid': (0.25, 0.35, 6), 'tau': 0.0},\n        # Test Case 2: Boundary case, no equifinal solutions\n        {'ke_grid': (0.02, 0.055, 8), 'kq_grid': (0.00, 0.30, 7), 'sfc_grid': (0.25, 0.35, 6), 'tau': 0.0},\n        # Test Case 3: Moderate tolerance, many equifinal solutions\n        {'ke_grid': (0.03, 0.09, 7), 'kq_grid': (0.00, 0.30, 7), 'sfc_grid': (0.25, 0.35, 6), 'tau': 0.005}\n    ]\n\n    # === Helper Functions ===\n    def run_model(params, s0_val, p_seq, s_max_val):\n        \"\"\"Simulates the soil moisture model for a given parameter set and forcing.\"\"\"\n        ke, kq, sfc = params\n        s_t = s0_val\n        s_history = []\n        for p_t in p_seq:\n            e_t = ke * s_t\n            q_t = kq * max(0, s_t - sfc)\n            s_t_plus_1_raw = s_t + p_t - e_t - q_t\n            s_t_plus_1 = np.clip(s_t_plus_1_raw, 0, s_max_val)\n            s_history.append(s_t_plus_1)\n            s_t = s_t_plus_1\n        return np.array(s_history)\n\n    def rmse(y_hat, y_true):\n        \"\"\"Computes the Root Mean Square Error.\"\"\"\n        return np.sqrt(np.mean((y_hat - y_true)**2))\n\n    # === Generate Ground Truth Observations ===\n    y_cal_true = run_model(ground_truth_params, S0, P_cal, S_max)\n    y_val_true = run_model(ground_truth_params, S0, P_val, S_max)\n    \n    final_results = []\n    \n    # === Main Loop over Test Cases ===\n    for case in test_cases:\n        # Step 1: Construct parameter grids\n        ke_grid = np.linspace(case['ke_grid'][0], case['ke_grid'][1], case['ke_grid'][2])\n        kq_grid = np.linspace(case['kq_grid'][0], case['kq_grid'][1], case['kq_grid'][2])\n        sfc_grid = np.linspace(case['sfc_grid'][0], case['sfc_grid'][1], case['sfc_grid'][2])\n        tau = case['tau']\n\n        # Step 2: Grid search and calibration RMSE calculation\n        calibration_results = []\n        for ke in ke_grid:\n            for kq in kq_grid:\n                for sfc in sfc_grid:\n                    params = (ke, kq, sfc)\n                    y_hat_cal = run_model(params, S0, P_cal, S_max)\n                    rmse_cal = rmse(y_hat_cal, y_cal_true)\n                    calibration_results.append({'params': params, 'rmse_cal': rmse_cal})\n\n        # Step 3: Define equifinal set\n        equifinal_set = [res for res in calibration_results if res['rmse_cal'] = tau]\n        \n        # Step 5: Compute cardinality N\n        N = len(equifinal_set)\n\n        # Handle edge case N=0\n        if N == 0:\n            final_results.append([0, -1.0, -1.0, False])\n            continue\n            \n        # Step 4: Compute validation RMSE for equifinal set\n        validation_rmse_values = []\n        for res in equifinal_set:\n            y_hat_val = run_model(res['params'], S0, P_val, S_max)\n            rmse_val = rmse(y_hat_val, y_val_true)\n            res['rmse_val'] = rmse_val  # Augment dict with validation result\n            validation_rmse_values.append(rmse_val)\n        \n        # Step 5: Compute summary metrics\n        validation_rmse_values = np.array(validation_rmse_values)\n        R_val_mean = np.mean(validation_rmse_values)\n        R_val_var = np.var(validation_rmse_values)\n\n        # Boolean diagnostic\n        min_rmse_cal_val = min(res['rmse_cal'] for res in calibration_results)\n        \n        best_cal_params_candidates = [\n            res['params'] for res in calibration_results if np.isclose(res['rmse_cal'], min_rmse_cal_val)\n        ]\n        \n        best_cal_params_candidates.sort()\n        params_dagger = best_cal_params_candidates[0]\n        \n        # Find R_val_dagger, which is the validation RMSE for params_dagger\n        R_val_dagger = -1.0\n        # This parameter set must be in the equifinal set if min_rmse_cal_val = tau\n        for res in equifinal_set:\n            if res['params'] == params_dagger:\n                R_val_dagger = res['rmse_val']\n                break\n        \n        min_R_val_in_E = np.min(validation_rmse_values)\n        \n        diagnostic = R_val_dagger > min_R_val_in_E\n\n        final_results.append([N, R_val_mean, R_val_var, diagnostic])\n\n    # === Final Output Formatting ===\n    # Convert list of lists to the required string format\n    output_str = \"[\"\n    for i, res in enumerate(final_results):\n        N, R_mean, R_var, diag = res\n        # Format floats to reasonable precision for consistent output\n        diag_str = 'True' if diag else 'False'\n        output_str += f\"[{N},{R_mean},{R_var},{diag_str}]\"\n        if i  len(final_results) - 1:\n            output_str += \",\"\n    output_str += \"]\"\n    \n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "本章的最终实践将我们的视角从诊断和后果转向主动的解决方案。如果模型被证实存在等效性，最有效的对策之一便是收集更多或信息量更大的数据。本练习介绍了优化实验设计的概念，特别是 D-最优性准则，并指导您实施一种贪心算法，以主动选择能最大限度约束模型参数、减少非唯一性的观测配置 。",
            "id": "3810094",
            "problem": "您的任务是设计并实现一个完整的、可运行的程序，该程序执行最优实验设计，以减轻线性化遥感正向模型在参数估计中的等效终局性（equifinality）和非唯一性（non-uniqueness）。该程序必须从一个有限的候选观测配置集合中，选择一个子集，该子集在高斯噪声和高斯先验的条件下，能够最大化关于模型参数的信息增益。您的实现必须从第一性原理推导得出，并且不得依赖于本说明中任何预先提供的快捷公式。\n\n考虑一个遥感正向模型，其参数为 $\\boldsymbol{\\theta} \\in \\mathbb{R}^p$。对于单个候选测量配置 $i$，其观测模型为线性化形式\n$$\ny_i \\approx \\mathbf{s}_i^\\top \\boldsymbol{\\theta} + \\varepsilon_i,\n$$\n其中 $\\mathbf{s}_i \\in \\mathbb{R}^p$ 是观测相对于参数的局部灵敏度向量，$\\varepsilon_i$ 是均值为零、方差为 $\\sigma_i^2$ 的高斯噪声。假设不同配置下的测量是相互独立的。高斯先验编码了关于参数的环境知识：$\\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0, \\mathbf{C}_\\text{prior})$，其中 $\\mathbf{C}_\\text{prior} \\in \\mathbb{R}^{p \\times p}$ 是对称正定矩阵。\n\n您的目标是从一个有限的候选集中选择 $m$ 个测量配置，以减少 $\\boldsymbol{\\theta}$ 的后验估计中的等效终局性和非唯一性。等效终局性指的是存在多个不同的参数向量，由于灵敏度方向的对齐或相关性，它们产生难以区分的相似输出，在数学上表现为信息矩阵的近奇异性或病态。为设计选择规则，请从以下基本原理出发：\n\n- 独立测量的高斯似然，\n- 线性高斯模型的费雪信息定义，\n- 通过贝叶斯更新引入高斯先验，\n- 信息矩阵的行列式与置信椭球体积之间的关系。\n\n基于这些原理，推导出一个贪心选择规则，该规则在每一步选择下一个测量，以最大化一个适用于减轻等效终局性的、基于行列式的最优性准则的边际增长。具体而言，使用贝叶斯信息矩阵的行列式最大化，通过将信息分布到参数空间中的独立方向上，来对抗非唯一性。\n\n将最终得到的贪心算法实现为一个函数，该函数接受以下参数：\n- 参数维度 $p$，\n- 先验协方差矩阵 $\\mathbf{C}_\\text{prior}$，\n- 候选灵敏度向量列表 $\\{\\mathbf{s}_i\\}_{i=1}^L$，\n- 对应的噪声方差列表 $\\{\\sigma_i^2\\}_{i=1}^L$，\n- 选择预算 $m$，\n\n并按选择顺序返回所选配置的索引。\n\n您的程序必须解决以下测试套件。每个测试用例被指定为一个元组，包含 $p$、$\\mathbf{C}_\\text{prior}$、候选 $\\mathbf{s}_i$ 列表、$\\sigma_i^2$ 列表和 $m$。所有矩阵和向量的维度都是一致的，且所有噪声方差均为正。\n\n测试套件：\n1. 具有中等先验和混合冗余度的正常路径：\n   - $p = 4$,\n   - $\\mathbf{C}_\\text{prior} = \\operatorname{diag}(10.0, 10.0, 10.0, 10.0)$,\n   - 灵敏度：\n     $\\mathbf{s}_0 = [1.0, 0.0, 0.1, 0.0]$,\n     $\\mathbf{s}_1 = [0.9, 0.1, 0.0, 0.0]$,\n     $\\mathbf{s}_2 = [0.0, 1.0, 0.0, 0.2]$,\n     $\\mathbf{s}_3 = [0.0, 0.0, 1.0, 0.0]$,\n     $\\mathbf{s}_4 = [0.0, 0.0, 0.0, 1.0]$,\n     $\\mathbf{s}_5 = [0.95, 0.05, 0.0, 0.0]$,\n   - 噪声方差：\n     $\\sigma^2 = [0.04, 0.05, 0.04, 0.02, 0.02, 0.05]$,\n   - $m = 3$.\n\n2. 等效终局性严重的情况，其中一个低噪声测量打破了非唯一性：\n   - $p = 3$,\n   - $\\mathbf{C}_\\text{prior} = \\operatorname{diag}(50.0, 50.0, 50.0)$,\n   - 灵敏度：\n     $\\mathbf{s}_0 = [1.0, 0.0, 0.0]$,\n     $\\mathbf{s}_1 = [0.9, 0.1, 0.0]$,\n     $\\mathbf{s}_2 = [0.8, 0.2, 0.0]$,\n     $\\mathbf{s}_3 = [0.0, 1.0, 0.0]$,\n     $\\mathbf{s}_4 = [0.0, 0.0, 1.0]$,\n     $\\mathbf{s}_5 = [0.1, 0.1, 0.0]$,\n   - 噪声方差：\n     $\\sigma^2 = [0.2, 0.2, 0.2, 0.2, 0.05, 0.2]$,\n   - $m = 3$.\n\n3. 单次测量的边界情况：\n   - $p = 3$,\n   - $\\mathbf{C}_\\text{prior} = \\operatorname{diag}(1.0, 1.0, 1.0)$,\n   - 灵敏度：\n     $\\mathbf{s}_0 = [1.0, 0.0, 0.0]$,\n     $\\mathbf{s}_1 = [0.0, 1.0, 0.0]$,\n     $\\mathbf{s}_2 = [0.0, 0.0, 1.0]$,\n     $\\mathbf{s}_3 = [0.5, 0.5, 0.0]$,\n     $\\mathbf{s}_4 = [0.0, 0.5, 0.5]$,\n   - 噪声方差：\n     $\\sigma^2 = [0.1, 0.1, 0.1, 0.1, 0.1]$,\n   - $m = 1$.\n\n4. 先验主导的各向异性，强调一个约束不佳的参数：\n   - $p = 4$,\n   - $\\mathbf{C}_\\text{prior} = \\operatorname{diag}(1.0, 1.0, 1.0, 100.0)$,\n   - 灵敏度：\n     $\\mathbf{s}_0 = [0.0, 0.0, 0.0, 1.0]$,\n     $\\mathbf{s}_1 = [0.1, 0.0, 0.0, 0.9]$,\n     $\\mathbf{s}_2 = [1.0, 0.0, 0.0, 0.0]$,\n     $\\mathbf{s}_3 = [0.0, 1.0, 0.0, 0.0]$,\n     $\\mathbf{s}_4 = [0.0, 0.0, 1.0, 0.0]$,\n   - 噪声方差：\n     $\\sigma^2 = [0.05, 0.05, 0.05, 0.05, 0.05]$,\n   - $m = 2$.\n\n您的程序应生成单行输出，包含所有测试用例的结果，格式为一个用方括号括起来的逗号分隔列表。每个测试用例的结果必须是按选择顺序列出的所选索引列表。例如，最终输出格式必须如下所示\n$$\n[ [i_{1,1}, i_{1,2}, \\dots], [i_{2,1}, i_{2,2}, \\dots], [i_{3,1}, \\dots], [i_{4,1}, i_{4,2}] ].\n$$\n不需要空格；列表必须是包含整数的语法有效的列表。本问题不需要物理单位，因为在数学规范中所有量都是无量纲的。",
            "solution": "用户提供的问题经评估为**有效**。它在科学上基于贝叶斯推断和最优实验设计，问题设定良好，具有明确的目标和约束，并用客观、精确的语言表述。该问题并非无足轻重，需要从第一性原理进行正确推导，下文将提供此推导过程。\n\n### 贪心选择算法的推导\n\n目标是从候选池中选择一个包含 $m$ 个测量的子集，以最大限度地减小参数向量 $\\boldsymbol{\\theta} \\in \\mathbb{R}^p$ 的不确定性。不确定性的减小是通过最大化后验信息矩阵的行列式来量化的，这是一个被称为D-最优性的准则。选择该准则的原因是，$\\boldsymbol{\\theta}$ 的后验可信椭球的体积与后验信息矩阵行列式的平方根成反比。最大化该行列式会积极地缩小与数据和先验一致的参数空间体积，从而减轻等效终局性和非唯一性。\n\n**1. 贝叶斯框架与信息矩阵**\n\n我们方法的基础是贝叶斯定理，对于我们假设为高斯分布的问题，该定理可以方便地用信息矩阵来表示。在给定一组测量 $\\mathcal{S}$ 的条件下，参数 $\\boldsymbol{\\theta}$ 的后验概率分布与似然和先验的乘积成正比：$p(\\boldsymbol{\\theta} | \\{y_j\\}_{j \\in \\mathcal{S}}) \\propto p(\\{y_j\\}_{j \\in \\mathcal{S}} | \\boldsymbol{\\theta}) p(\\boldsymbol{\\theta})$。由于这些分布是高斯分布，它们的指数部分会相加，这意味着它们的信息（精度）矩阵也会相加。\n\n后验信息矩阵 $\\mathbf{I}_\\text{post}$ 是先验信息矩阵 $\\mathbf{I}_\\text{prior}$ 和来自数据的信息矩阵 $\\mathbf{I}_\\text{data}$ 的和：\n$$\n\\mathbf{I}_\\text{post}(\\mathcal{S}) = \\mathbf{I}_\\text{prior} + \\mathbf{I}_\\text{data}(\\mathcal{S})\n$$\n\n**2. 先验信息**\n\n关于参数的先验信念由高斯分布 $\\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0, \\mathbf{C}_\\text{prior})$ 给出。先验信息矩阵是先验协方差矩阵的逆：\n$$\n\\mathbf{I}_\\text{prior} = \\mathbf{C}_\\text{prior}^{-1}\n$$\n该矩阵量化了我们在进行任何新测量之前关于 $\\boldsymbol{\\theta}$ 的知识。\n\n**3. 似然与数据信息（费雪信息）**\n\n单个测量 $i$ 的观测模型为 $y_i \\approx \\mathbf{s}_i^\\top \\boldsymbol{\\theta} + \\varepsilon_i$，其中噪声 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2)$。该测量的对数似然函数为：\n$$\n\\ln p(y_i | \\boldsymbol{\\theta}) = -\\frac{1}{2\\sigma_i^2} (y_i - \\mathbf{s}_i^\\top \\boldsymbol{\\theta})^2 - \\frac{1}{2}\\ln(2\\pi\\sigma_i^2)\n$$\n单个测量的费雪信息矩阵定义为对数似然函数关于 $\\boldsymbol{\\theta}$ 的海森矩阵（二阶导数）的负期望。对于线性高斯模型，这可以简化为关于 $\\boldsymbol{\\theta}$ 的二次项的海森矩阵：\n$$\n\\mathbf{I}_i = -\\mathbb{E}\\left[\\nabla_{\\boldsymbol{\\theta}\\boldsymbol{\\theta}}^\\top \\ln p(y_i | \\boldsymbol{\\theta}) \\right] = \\nabla_{\\boldsymbol{\\theta}\\boldsymbol{\\theta}}^\\top \\left( \\frac{1}{2\\sigma_i^2} (\\mathbf{s}_i^\\top \\boldsymbol{\\theta})^2 \\right) = \\frac{1}{\\sigma_i^2} \\mathbf{s}_i \\mathbf{s}_i^\\top\n$$\n这是一个秩为1的矩阵，代表测量 $i$ 所贡献的信息。由于测量是独立的，来自一组测量 $\\mathcal{S}$ 的总信息是可加的：\n$$\n\\mathbf{I}_\\text{data}(\\mathcal{S}) = \\sum_{j \\in \\mathcal{S}} \\mathbf{I}_j = \\sum_{j \\in \\mathcal{S}} \\frac{1}{\\sigma_j^2} \\mathbf{s}_j \\mathbf{s}_j^\\top\n$$\n\n**4. 贪心选择准则**\n\n我们将迭代地构建所选测量的集合 $\\mathcal{S}$。设 $\\mathcal{S}_{k-1}$ 是已选择的 $k-1$ 个测量的集合，且设 $\\mathbf{I}^{(k-1)} = \\mathbf{I}_\\text{post}(\\mathcal{S}_{k-1})$ 为相应的后验信息矩阵。在第 $k$ 步，我们希望从可用候选集 $\\mathcal{A}_{k-1}$ 中选择下一个测量 $j^*$，该测量能提供信息矩阵行列式的最大边际增长。\n添加测量 $j$ 后的新信息矩阵为：\n$$\n\\mathbf{I}^{(k-1, j)} = \\mathbf{I}^{(k-1)} + \\mathbf{I}_j = \\mathbf{I}^{(k-1)} + \\frac{1}{\\sigma_j^2} \\mathbf{s}_j \\mathbf{s}_j^\\top\n$$\n我们寻求能求解以下问题的测量 $j^*$：\n$$\nj^* = \\arg\\max_{j \\in \\mathcal{A}_{k-1}} \\det(\\mathbf{I}^{(k-1, j)})\n$$\n为了高效地计算，我们使用矩阵行列式引理：$\\det(\\mathbf{A} + \\mathbf{u}\\mathbf{v}^\\top) = (1 + \\mathbf{v}^\\top \\mathbf{A}^{-1}\\mathbf{u})\\det(\\mathbf{A})$。\n令 $\\mathbf{A} = \\mathbf{I}^{(k-1)}$ 且 $\\mathbf{u} = \\mathbf{v} = \\frac{\\mathbf{s}_j}{\\sigma_j}$，我们得到：\n$$\n\\det(\\mathbf{I}^{(k-1, j)}) = \\det(\\mathbf{I}^{(k-1)}) \\left( 1 + \\left(\\frac{\\mathbf{s}_j}{\\sigma_j}\\right)^\\top (\\mathbf{I}^{(k-1)})^{-1} \\left(\\frac{\\mathbf{s}_j}{\\sigma_j}\\right) \\right) = \\det(\\mathbf I^{(k-1)}) \\left( 1 + \\frac{1}{\\sigma_j^2} \\mathbf{s}_j^\\top (\\mathbf{I}^{(k-1)})^{-1} \\mathbf{s}_j \\right)\n$$\n最大化此表达式等价于最大化被加上的项。设 $\\mathbf{C}^{(k-1)} = (\\mathbf{I}^{(k-1)})^{-1}$ 为 $k-1$ 次选择后的后验协方差矩阵。因此，选择规则为：\n$$\nj^* = \\arg\\max_{j \\in \\mathcal{A}_{k-1}} \\frac{\\mathbf{s}_j^\\top \\mathbf{C}^{(k-1)} \\mathbf{s}_j}{\\sigma_j^2}\n$$\n项 $\\mathbf{s}_j^\\top \\mathbf{C}^{(k-1)} \\mathbf{s}_j$ 是当前后验下预测测量值 $y_j = \\mathbf{s}_j^\\top \\boldsymbol{\\theta}$ 的方差。因此，该准则选择最不确定的测量，并用其自身的内禀噪声方差进行归一化。\n\n**5. 算法实现与优化**\n\n一种直接的实现方式是在每一步都重新计算矩阵的逆 $\\mathbf{C}^{(k)} = (\\mathbf{I}^{(k)})^{-1}$，这样做计算成本很高（$O(p^3)$）。一个更高效的方法是使用用于秩1更新求逆的Sherman-Morrison公式，直接将协方差矩阵 $\\mathbf{C}^{(k-1)}$ 更新为 $\\mathbf{C}^{(k)}$：\n$$\n(\\mathbf{A} + \\mathbf{u}\\mathbf{v}^\\top)^{-1} = \\mathbf{A}^{-1} - \\frac{\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{v}^\\top\\mathbf{A}^{-1}}{1 + \\mathbf{v}^\\top\\mathbf{A}^{-1}\\mathbf{u}}\n$$\n将此应用于我们的协方差更新，我们有 $\\mathbf{C}^{(k)} = (\\mathbf{I}^{(k-1)} + \\frac{1}{\\sigma_{j^*}^2}\\mathbf{s}_{j^*}\\mathbf{s}_{j^*}^\\top)^{-1}$。结果为：\n$$\n\\mathbf{C}^{(k)} = \\mathbf{C}^{(k-1)} - \\frac{\\mathbf{C}^{(k-1)} \\mathbf{s}_{j^*} \\mathbf{s}_{j^*}^\\top \\mathbf{C}^{(k-1)}}{\\sigma_{j^*}^2 + \\mathbf{s}_{j^*}^\\top \\mathbf{C}^{(k-1)} \\mathbf{s}_{j^*}}\n$$\n此更新仅需要矩阵-向量乘法和一个外积，将每步更新的复杂度降低到 $O(p^2)$。\n\n最终算法如下：\n1.  初始化 `selected_indices` 为一个空列表，`candidate_indices` 为所有测量索引的集合，以及当前后验协方差 `C_current` 为 `C_prior`。\n2.  对于从 $1$ 到 $m$ 的 $k$：\n    a. 对于 `candidate_indices` 中的每个候选索引 $j$，计算得分 $S_j = (\\mathbf{s}_j^\\top \\mathbf{C}_\\text{current} \\mathbf{s}_j) / \\sigma_j^2$。\n    b. 找到得分最高的索引 $j^*$。如果出现平局，则选择最小的索引。\n    c. 将 $j^*$ 添加到 `selected_indices` 中，并从 `candidate_indices` 中移除。\n    d. 使用 $\\mathbf{s}_{j^*}$ 和 $\\sigma_{j^*}^2$ 通过Sherman-Morrison公式更新 `C_current`。\n3.  返回 `selected_indices` 列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import inv\n\ndef greedy_selection(p, c_prior, sensitivities, variances, m):\n    \"\"\"\n    Performs greedy selection of m measurements to maximize the determinant\n    of the posterior information matrix.\n\n    Args:\n        p (int): The dimension of the parameter space.\n        c_prior (np.ndarray): The prior covariance matrix (p x p).\n        sensitivities (list): A list of candidate sensitivity vectors (numpy arrays).\n        variances (list): A list of corresponding noise variances.\n        m (int): The number of measurements to select.\n\n    Returns:\n        list: A list of indices of the selected measurements.\n    \"\"\"\n    num_candidates = len(sensitivities)\n    candidate_indices = set(range(num_candidates))\n    selected_indices = []\n\n    c_current = c_prior.copy()\n\n    for _ in range(m):\n        if not candidate_indices:\n            break\n\n        best_j = -1\n        max_score = -1.0\n\n        scores = {}\n        # Iterate through candidates in sorted order to ensure deterministic tie-breaking\n        for j in sorted(list(candidate_indices)):\n            s_j = sensitivities[j]\n            sigma_sq_j = variances[j]\n            \n            # Criterion: s_j^T * C_current * s_j / sigma_j^2\n            score = (s_j.T @ c_current @ s_j) / sigma_sq_j\n            \n            if score > max_score:\n                max_score = score\n                best_j = j\n        \n        if best_j == -1: # Should not happen with valid inputs\n            break\n\n        selected_indices.append(best_j)\n        candidate_indices.remove(best_j)\n\n        # Update the covariance matrix using the Sherman-Morrison formula\n        s_best = sensitivities[best_j]\n        sigma_sq_best = variances[best_j]\n\n        v = c_current @ s_best\n        denominator = sigma_sq_best + s_best.T @ v\n        \n        # Numerator is an outer product: v @ v.T\n        # In numpy, this is np.outer(v, v)\n        c_current -= np.outer(v, v) / denominator\n        \n    return selected_indices\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        (\n            4, # p\n            np.diag([10.0, 10.0, 10.0, 10.0]), # C_prior\n            [\n                np.array([1.0, 0.0, 0.1, 0.0]),\n                np.array([0.9, 0.1, 0.0, 0.0]),\n                np.array([0.0, 1.0, 0.0, 0.2]),\n                np.array([0.0, 0.0, 1.0, 0.0]),\n                np.array([0.0, 0.0, 0.0, 1.0]),\n                np.array([0.95, 0.05, 0.0, 0.0]),\n            ], # sensitivities\n            [0.04, 0.05, 0.04, 0.02, 0.02, 0.05], # variances\n            3 # m\n        ),\n        # Test Case 2\n        (\n            3, # p\n            np.diag([50.0, 50.0, 50.0]), # C_prior\n            [\n                np.array([1.0, 0.0, 0.0]),\n                np.array([0.9, 0.1, 0.0]),\n                np.array([0.8, 0.2, 0.0]),\n                np.array([0.0, 1.0, 0.0]),\n                np.array([0.0, 0.0, 1.0]),\n                np.array([0.1, 0.1, 0.0]),\n            ], # sensitivities\n            [0.2, 0.2, 0.2, 0.2, 0.05, 0.2], # variances\n            3 # m\n        ),\n        # Test Case 3\n        (\n            3, # p\n            np.diag([1.0, 1.0, 1.0]), # C_prior\n            [\n                np.array([1.0, 0.0, 0.0]),\n                np.array([0.0, 1.0, 0.0]),\n                np.array([0.0, 0.0, 1.0]),\n                np.array([0.5, 0.5, 0.0]),\n                np.array([0.0, 0.5, 0.5]),\n            ], # sensitivities\n            [0.1, 0.1, 0.1, 0.1, 0.1], # variances\n            1 # m\n        ),\n        # Test Case 4\n        (\n            4, # p\n            np.diag([1.0, 1.0, 1.0, 100.0]), # C_prior\n            [\n                np.array([0.0, 0.0, 0.0, 1.0]),\n                np.array([0.1, 0.0, 0.0, 0.9]),\n                np.array([1.0, 0.0, 0.0, 0.0]),\n                np.array([0.0, 1.0, 0.0, 0.0]),\n                np.array([0.0, 0.0, 1.0, 0.0]),\n            ], # sensitivities\n            [0.05, 0.05, 0.05, 0.05, 0.05], # variances\n            2 # m\n        ),\n    ]\n\n    results = []\n    for case in test_cases:\n        p, c_prior, sensitivities, variances, m = case\n        result = greedy_selection(p, c_prior, sensitivities, variances, m)\n        results.append(result)\n\n    # Format the output string to match the problem specification\n    # e.g., [[3,4,2],[4,0,3],[0],[0,2]]\n    str_results = [str(res).replace(\" \", \"\") for res in results]\n    final_output_string = f\"[{','.join(str_results)}]\"\n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}