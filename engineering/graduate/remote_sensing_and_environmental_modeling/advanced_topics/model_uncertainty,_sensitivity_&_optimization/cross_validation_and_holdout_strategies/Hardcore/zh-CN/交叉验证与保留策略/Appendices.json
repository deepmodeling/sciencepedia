{
    "hands_on_practices": [
        {
            "introduction": "数据泄露是机器学习中一个微妙但至关重要的陷阱，它可能导致模型性能被过度高估。本练习提供了一个具体的、基于代码的模拟，来揭示信息泄露是如何在特征归一化这一看似简单的步骤中发生的 。通过对比正确的“无泄漏”工作流与有缺陷的“泄漏”工作流，您将亲手量化由此产生的性能指标（如 $AUC$）的乐观偏差，从而深刻理解为何严格分离训练与验证数据至关重要。",
            "id": "3804423",
            "problem": "考虑一个遥感领域的二元分类任务，其中每个像素由一个源自辐射波段的多元特征向量表示，目标是从背景中检测出某个目标类别（例如，特定的土地覆盖类型）。您将研究信息泄露对留出法验证性能的影响，重点关注受试者工作特征曲线下面积 (ROC AUC)。此处的泄露发生在验证像素与训练像素共享预处理参数（特征归一化统计量）时，这违反了训练集和验证集之间的独立性假设。\n\n从以下基本概念开始：\n\n- 受试者工作特征曲线下面积 (ROC AUC) 定义为从正类中随机选择的分数超过从负类中随机选择的分数的概率。形式上，如果 $S^{+}$ 和 $S^{-}$ 分别是分类器对一个正类像素和一个负类像素的随机分数，那么 ROC AUC 为\n$$\\mathrm{AUC} = \\mathbb{P}\\left(S^{+}  S^{-}\\right) + \\frac{1}{2}\\mathbb{P}\\left(S^{+} = S^{-}\\right).$$\n- 在留出法策略中，以数据生成过程为条件，训练数据集和验证数据集必须在统计上是独立的。任何使用验证数据估算、并随后在训练或评分过程中应用的预处理参数（例如用于归一化的均值和标准差），都会引入信息泄露，这可能会使性能估计产生偏高的偏差。\n\n您将模拟两个场景：一个训练场景和一个验证场景。像素由一个参数化高斯模型生成，每个场景具有类条件均值和共享协方差。设特征维度为 $d = 2$。对于类别标签 $Y \\in \\{0,1\\}$，训练场景中的原始特征分布定义为\n$$X \\mid (Y=1,\\ \\mathrm{train}) \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}_{1} + \\boldsymbol{b}_{\\mathrm{train}},\\ \\boldsymbol{\\Sigma}_{\\mathrm{train}}\\right),\\quad X \\mid (Y=0,\\ \\mathrm{train}) \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}_{0} + \\boldsymbol{b}_{\\mathrm{train}},\\ \\boldsymbol{\\Sigma}_{\\mathrm{train}}\\right),$$\n在验证场景中则为\n$$X \\mid (Y=1,\\ \\mathrm{val}) \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}_{1} + \\boldsymbol{b}_{\\mathrm{val}},\\ \\boldsymbol{\\Sigma}_{\\mathrm{val}}\\right),\\quad X \\mid (Y=0,\\ \\mathrm{val}) \\sim \\mathcal{N}\\left(\\boldsymbol{\\mu}_{0} + \\boldsymbol{b}_{\\mathrm{val}},\\ \\boldsymbol{\\Sigma}_{\\mathrm{val}}\\right).$$\n此处，$\\boldsymbol{\\mu}_{1}, \\boldsymbol{\\mu}_{0} \\in \\mathbb{R}^{2}$ 是类别均值，$\\boldsymbol{b}_{\\mathrm{train}}, \\boldsymbol{b}_{\\mathrm{val}} \\in \\mathbb{R}^{2}$ 是场景特定偏移量，$\\boldsymbol{\\Sigma}_{\\mathrm{train}}, \\boldsymbol{\\Sigma}_{\\mathrm{val}} \\in \\mathbb{R}^{2\\times 2}$ 是场景特定协方差矩阵，其方差为单位值，相关系数分别为 $\\rho_{\\mathrm{train}}$ 和 $\\rho_{\\mathrm{val}}$。设训练集中各类别的流行度（正类像素的比例）为 $\\pi_{\\mathrm{train}}$，验证集中为 $\\pi_{\\mathrm{val}}$。\n\n预处理包括逐特征的 $z$-score 归一化 $Z = (X - \\boldsymbol{m}) \\oslash \\boldsymbol{s}$，其中 $\\oslash$ 表示逐元素除法，$\\boldsymbol{m}, \\boldsymbol{s} \\in \\mathbb{R}^{2}$ 是从参考池中估算的均值和标准差向量。对比以下两种策略：\n- 无泄露：$\\boldsymbol{m}, \\boldsymbol{s}$ 仅使用训练像素进行估算，训练集和验证集都使用这些仅基于训练集的参数进行归一化。\n- 泄露：$\\boldsymbol{m}, \\boldsymbol{s}$ 使用训练像素和验证像素的并集（共享参数）进行估算，两个集合都使用这些共享参数进行归一化。\n\n在类内协方差相等的假设下，使用线性判别分析 (LDA) 在归一化后的训练数据上训练一个分类器。对于具有归一化特征向量 $\\boldsymbol{z}$ 的像素，其 LDA 评分函数为 $S(\\boldsymbol{z}) = \\boldsymbol{w}^{\\top}\\boldsymbol{z}$，其中\n$$\\boldsymbol{w} = \\boldsymbol{\\Sigma}_{\\text{pooled}}^{-1}\\left(\\boldsymbol{\\hat{\\mu}}_{1} - \\boldsymbol{\\hat{\\mu}}_{0}\\right),$$\n其中 $\\boldsymbol{\\hat{\\mu}}_{1}, \\boldsymbol{\\hat{\\mu}}_{0}$ 是归一化训练集中的经验类别均值，$\\boldsymbol{\\Sigma}_{\\text{pooled}}$ 是从归一化训练集中估算的池化协方差矩阵。由于 ROC AUC 仅依赖于分数的排序，因此可以省略截距。\n\n对每组参数集，执行包含 $R$ 次独立重复实验的蒙特卡洛模拟。在每次重复实验中，根据模型生成 $n_{\\mathrm{train}}$ 个训练像素和 $n_{\\mathrm{val}}$ 个验证像素，在两种策略下分别应用预处理，在训练数据上训练 LDA，在验证数据上计算 ROC AUC，并记录泄露 AUC 与无泄露 AUC 之间的差值。预期的偏高偏差是这 $R$ 次重复实验中差值的经验均值。\n\n您的任务是实现一个程序，针对以下测试套件，输出每种情况下 ROC AUC 的预期偏高偏差：\n\n- 案例 1（中度域偏移，理想路径）：$d=2$，$\\boldsymbol{\\mu}_{1} = [0.5, 0.5]$，$\\boldsymbol{\\mu}_{0} = [-0.5, -0.5]$，$\\rho_{\\mathrm{train}} = 0.3$，$\\rho_{\\mathrm{val}} = 0.3$，$\\boldsymbol{b}_{\\mathrm{train}} = [0.0, 0.0]$，$\\boldsymbol{b}_{\\mathrm{val}} = [1.0, 1.0]$，$\\pi_{\\mathrm{train}} = 0.5$，$\\pi_{\\mathrm{val}} = 0.5$， $n_{\\mathrm{train}} = 600$, $n_{\\mathrm{val}} = 600$, $R = 200$。\n- 案例 2（无域偏移，边界条件）：与案例 1 相同，但 $\\boldsymbol{b}_{\\mathrm{val}} = [0.0, 0.0]$ 且 $\\rho_{\\mathrm{val}} = 0.3$。预期偏差接近 $0$。\n- 案例 3（协方差偏移，边缘情况）：与案例 1 相同，但 $\\rho_{\\mathrm{train}} = 0.0$，$\\rho_{\\mathrm{val}} = 0.8$，$n_{\\mathrm{train}} = 400$, $n_{\\mathrm{val}} = 400$, $R = 200$。\n- 案例 4（流行度偏移，边缘情况）：与案例 1 相同，但 $\\pi_{\\mathrm{train}} = 0.3$，$\\pi_{\\mathrm{val}} = 0.7$，$n_{\\mathrm{train}} = 600$, $n_{\\mathrm{val}} = 600$, $R = 200$。\n\n所有随机抽样必须使用固定种子以保证可复现性。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[r_{1},r_{2},r_{3},r_{4}]$）。每个 $r_{i}$ 必须是一个浮点数，表示相应案例的预期偏高偏差（泄露 AUC 减去无泄露 AUC），并四舍五入到恰好六位小数。此问题不涉及任何物理单位或角度，任何比例或流行度都必须表示为小数。\n\n您的实现必须：\n- 将 $\\boldsymbol{\\Sigma}_{\\mathrm{train}}$ 和 $\\boldsymbol{\\Sigma}_{\\mathrm{val}}$ 构建为 $2\\times 2$ 的协方差矩阵，其方差为单位值，相关系数为指定的 $\\rho$：\n$$\\boldsymbol{\\Sigma}(\\rho) = \\begin{bmatrix}1  \\rho \\\\ \\rho  1\\end{bmatrix}.$$\n- 通过减去经验均值 $\\boldsymbol{m}$ 并除以经验标准差 $\\boldsymbol{s}$ 来执行逐特征归一化，其中 $\\boldsymbol{m}$ 和 $\\boldsymbol{s}$ 在指定的参考池上计算，并在 $\\boldsymbol{s}$ 的每个分量上添加一个小的稳定化常数以避免除以零。\n- 从归一化后的训练数据中训练线性判别分析 (LDA)，使用仅从训练数据中估算的池化协方差。\n- 在归一化的验证数据上，通过其定义 $\\mathrm{AUC} = \\mathbb{P}\\left(S^{+}  S^{-}\\right) + \\frac{1}{2}\\mathbb{P}\\left(S^{+} = S^{-}\\right)$ 计算 ROC AUC，具体方法是通过对已排序的负类分数进行高效搜索来计数比较。\n\n您的最终输出必须是单行，格式严格为 $[r_{1},r_{2},r_{3},r_{4}]$，其中每个 $r_{i}$ 四舍五入到六位小数。",
            "solution": "该问题要求在二元分类任务的留出法验证方案中分析信息泄露，这是遥感领域中的一个常见场景。我们需要量化当特征归一化统计量从包含训练样本和验证样本的数据池中计算时，所产生的受试者工作特征曲线下面积 (AUC) 的乐观偏差。这种做法违反了用于模型训练和模型评估的数据集之间的独立性原则。该分析将通过蒙特卡洛模拟进行。\n\n整体方法论如下：\n1.  针对四个指定案例中的每一个，我们将执行 $R$ 次独立的模拟重复实验。\n2.  在每次重复实验中，我们生成一个大小为 $n_{\\mathrm{train}}$ 的训练数据集和一个大小为 $n_{\\mathrm{val}}$ 的验证数据集。数据点从类条件多元高斯分布中抽取，并根据每个场景（训练和验证）的指定参数进行参数化。\n3.  然后我们模拟两种不同的验证工作流：\n    a. **无泄露工作流**：特征归一化参数（均值 $\\boldsymbol{m}$ 和标准差 $\\boldsymbol{s}$）完全从训练数据中估算。然后使用这些参数对训练数据和验证数据进行归一化。\n    b. **泄露工作流**：归一化参数从所有训练数据和验证数据的组合集中估算。然后使用这些共享参数对两个数据集进行归一化。\n4.  对每个工作流，都在其相应的归一化训练数据上训练一个线性判别分析 (LDA) 分类器。\n5.  然后将训练好的分类器应用于相应的归一化验证数据以获得分类分数。通过计算 ROC AUC 来量化其性能。\n6.  单次重复实验的偏差是差值：$\\mathrm{AUC}_{\\text{leakage}} - \\mathrm{AUC}_{\\text{no-leakage}}$。\n7.  每个案例的最终结果是预期的偏高偏差，通过对所有 $R$ 次重复实验的这些差值求平均值来估算。\n\n让我们将关键计算步骤形式化。\n\n**1. 数据生成**\n对于一个给定的场景（训练或验证），我们生成 $n$ 个样本。正类样本（类别 $Y=1$）的数量是 $n_1 = \\text{round}(n \\cdot \\pi)$，负类样本（类别 $Y=0$）的数量是 $n_0 = n - n_1$。\n每个类别的特征向量从一个 $d=2$ 维的正态分布 $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ 中抽取。\n-   正类特征：$X_1 \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1 + \\boldsymbol{b}, \\boldsymbol{\\Sigma})$\n-   负类特征：$X_0 \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0 + \\boldsymbol{b}, \\boldsymbol{\\Sigma})$\n协方差矩阵 $\\boldsymbol{\\Sigma}$ 基于指定的相关系数 $\\rho$ 构建如下：\n$$\n\\boldsymbol{\\Sigma}(\\rho) = \\begin{bmatrix} 1  \\rho \\\\ \\rho  1 \\end{bmatrix}\n$$\n这个生成过程对训练集和验证集独立执行，使用它们各自的参数（$\\boldsymbol{b}_{\\mathrm{train}}, \\boldsymbol{\\Sigma}_{\\mathrm{train}}, n_{\\mathrm{train}}, \\pi_{\\mathrm{train}}$ 和 $\\boldsymbol{b}_{\\mathrm{val}}, \\boldsymbol{\\Sigma}_{\\mathrm{val}}, n_{\\mathrm{val}}, \\pi_{\\mathrm{val}}$）。\n\n**2. 特征归一化**\n给定一组原始特征向量 $X$ 和一个参考池向量 $X_{\\text{ref}}$，我们应用逐特征的 $z$-score 归一化。均值向量 $\\boldsymbol{m}$ 和标准差向量 $\\boldsymbol{s}$ 从 $X_{\\text{ref}}$ 计算得出：\n$$\n\\boldsymbol{m} = \\mathbb{E}[X_{\\text{ref}}] \\quad \\quad \\boldsymbol{s} = \\sqrt{\\mathrm{Var}(X_{\\text{ref}})}\n$$\n那么对于来自 $X$ 的任何样本 $\\boldsymbol{x}$，其归一化特征 $\\boldsymbol{z}$ 为：\n$$\n\\boldsymbol{z} = (\\boldsymbol{x} - \\boldsymbol{m}) \\oslash (\\boldsymbol{s} + \\epsilon)\n$$\n其中 $\\oslash$ 表示逐元素除法，$\\epsilon$ 是一个小的常数（例如 $10^{-8}$）以防止除以零。\n-   在**无泄露**情况下，$X_{\\text{ref}} = X_{\\mathrm{train}}$。\n-   在**泄露**情况下，$X_{\\text{ref}} = X_{\\mathrm{train}} \\cup X_{\\mathrm{val}}$。\n\n**3. 线性判别分析 (LDA) 训练**\nLDA 分类器学习一个投影向量 $\\boldsymbol{w}$，以最大化类别之间的可分性。给定归一化的训练数据 $Z_{\\mathrm{train}}$ 和相应的标签 $y_{\\mathrm{train}}$，我们计算 $\\boldsymbol{w}$ 如下：\n$$\n\\boldsymbol{w} = \\boldsymbol{\\hat{\\Sigma}}_{\\text{pooled}}^{-1} (\\boldsymbol{\\hat{\\mu}}_1 - \\boldsymbol{\\hat{\\mu}}_0)\n$$\n在这里，$\\boldsymbol{\\hat{\\mu}}_1$ 和 $\\boldsymbol{\\hat{\\mu}}_0$ 分别是训练集中归一化后的正类和负类样本的经验均值。池化协方差矩阵 $\\boldsymbol{\\hat{\\Sigma}}_{\\text{pooled}}$ 是各个类别协方差矩阵的加权平均：\n$$\n\\boldsymbol{\\hat{\\Sigma}}_{\\text{pooled}} = \\frac{(n_1 - 1)\\boldsymbol{\\hat{\\Sigma}}_1 + (n_0 - 1)\\boldsymbol{\\hat{\\Sigma}}_0}{n_1 + n_0 - 2}\n$$\n其中 $n_1, n_0$ 是训练集中正类和负类样本的数量，$\\boldsymbol{\\hat{\\Sigma}}_1, \\boldsymbol{\\hat{\\Sigma}}_0$ 是它们各自的样本协方差矩阵。\n\n**4. ROC AUC 计算**\n对于一个归一化样本 $\\boldsymbol{z}$，其分类分数为 $S(\\boldsymbol{z}) = \\boldsymbol{w}^{\\top}\\boldsymbol{z}$。为了在验证集上计算 AUC，我们首先将分数分为来自正类样本的分数 $\\{S_i^+\\}$ 和来自负类样本的分数 $\\{S_j^-\\}$。AUC 根据其概率定义进行估算：\n$$\n\\mathrm{AUC} = \\frac{1}{N^+ N^-} \\left( \\sum_{i=1}^{N^+} \\sum_{j=1}^{N^-} \\mathbb{I}(S_i^+  S_j^-) + \\frac{1}{2} \\sum_{i=1}^{N^+} \\sum_{j=1}^{N^-} \\mathbb{I}(S_i^+ = S_j^-) \\right)\n$$\n其中 $N^+$ 和 $N^-$ 是验证集中正类和负类样本的数量，$\\mathbb{I}(\\cdot)$ 是指示函数。一种计算上高效的方法是，对负类分数 $\\{S_j^-\\}$ 进行排序，然后对于每个正类分数 $S_i^+$，使用二分搜索来计算小于或等于它的负类分数的数量。\n\n该模拟将使用 Python 的 `NumPy` 库来实现所有数值计算。固定的随机种子将确保结果的可复现性。最终输出是四个指定实验条件下每个案例的平均偏差，四舍五入到六位小数。在案例 2 中，训练数据和验证数据之间没有域偏移，预期的偏差应接近 $0$，这为实现提供了一个健全性检查。对于存在域偏移（在均值、协方差或流行度方面）的其他情况，验证数据统计信息泄露到训练流程中，预计会人为地减少表观的域偏移，从而导致正偏差，即 $\\mathrm{AUC}_{\\text{leakage}}  \\mathrm{AUC}_{\\text{no-leakage}}$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    # A fixed seed ensures that the random sampling is reproducible.\n    np.random.seed(42)\n\n    # Define the parameter sets for the four test cases.\n    # Each tuple contains: (mu1, mu0, rho_train, rho_val, b_train, b_val, \n    #                       pi_train, pi_val, n_train, n_val, R)\n    test_cases = [\n        # Case 1 (moderate domain shift, happy path)\n        (np.array([0.5, 0.5]), np.array([-0.5, -0.5]), 0.3, 0.3, \n         np.array([0.0, 0.0]), np.array([1.0, 1.0]), 0.5, 0.5, 600, 600, 200),\n        # Case 2 (no domain shift, boundary condition)\n        (np.array([0.5, 0.5]), np.array([-0.5, -0.5]), 0.3, 0.3, \n         np.array([0.0, 0.0]), np.array([0.0, 0.0]), 0.5, 0.5, 600, 600, 200),\n        # Case 3 (covariance shift edge case)\n        (np.array([0.5, 0.5]), np.array([-0.5, -0.5]), 0.0, 0.8, \n         np.array([0.0, 0.0]), np.array([1.0, 1.0]), 0.5, 0.5, 400, 400, 200),\n        # Case 4 (prevalence shift edge case)\n        (np.array([0.5, 0.5]), np.array([-0.5, -0.5]), 0.3, 0.3, \n         np.array([0.0, 0.0]), np.array([1.0, 1.0]), 0.3, 0.7, 600, 600, 200),\n    ]\n\n    results = []\n    for case_params in test_cases:\n        expected_bias = run_simulation(*case_params)\n        results.append(expected_bias)\n\n    # Format the final output string as specified.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef generate_data(n, pi, mu1, mu0, b, rho):\n    \"\"\"\n    Generates feature data and labels from a 2D Gaussian mixture model.\n    \"\"\"\n    n_pos = int(round(n * pi))\n    n_neg = n - n_pos\n\n    mean_pos = mu1 + b\n    mean_neg = mu0 + b\n    \n    cov_matrix = np.array([[1, rho], [rho, 1]])\n\n    X_pos = np.random.multivariate_normal(mean_pos, cov_matrix, n_pos)\n    X_neg = np.random.multivariate_normal(mean_neg, cov_matrix, n_neg)\n    \n    if n_pos > 0 and n_neg > 0:\n        X = np.vstack((X_pos, X_neg))\n        y = np.hstack((np.ones(n_pos), np.zeros(n_neg)))\n        # Shuffle to mix positive and negative samples\n        perm = np.random.permutation(n)\n        X, y = X[perm], y[perm]\n    elif n_pos > 0:\n        X, y = X_pos, np.ones(n_pos)\n    else: # n_neg > 0\n        X, y = X_neg, np.zeros(n_neg)\n\n    return X, y\n\ndef train_lda(Z_train, y_train):\n    \"\"\"\n    Trains a Linear Discriminant Analysis classifier.\n    \"\"\"\n    Z1 = Z_train[y_train == 1]\n    Z0 = Z_train[y_train == 0]\n\n    n1, n0 = Z1.shape[0], Z0.shape[0]\n\n    if n1  2 or n0  2:\n        # Handle degenerate cases, though unlikely with problem parameters\n        return np.zeros(Z_train.shape[1])\n\n    mu1_hat = np.mean(Z1, axis=0)\n    mu0_hat = np.mean(Z0, axis=0)\n    \n    S1 = np.cov(Z1, rowvar=False, ddof=1)\n    S0 = np.cov(Z0, rowvar=False, ddof=1)\n    \n    # an edge case can cause S1 or S0 to be a scalar 0.0 if there is one sample\n    if S1.ndim == 0: S1 = np.zeros((Z_train.shape[1], Z_train.shape[1]))\n    if S0.ndim == 0: S0 = np.zeros((Z_train.shape[1], Z_train.shape[1]))\n    \n    Sigma_pooled = ((n1 - 1) * S1 + (n0 - 1) * S0) / (n1 + n0 - 2)\n    \n    try:\n        Sigma_pooled_inv = np.linalg.inv(Sigma_pooled)\n    except np.linalg.LinAlgError:\n         Sigma_pooled_inv = np.linalg.pinv(Sigma_pooled)\n\n    w = Sigma_pooled_inv @ (mu1_hat - mu0_hat)\n    return w\n\ndef calculate_auc(scores, y_val):\n    \"\"\"\n    Calculates the ROC AUC from scores and true labels.\n    \"\"\"\n    scores_pos = scores[y_val == 1]\n    scores_neg = scores[y_val == 0]\n    \n    n_pos = len(scores_pos)\n    n_neg = len(scores_neg)\n\n    if n_pos == 0 or n_neg == 0:\n        return 0.5  # Convention for undefined AUC\n\n    # Sort negative scores for efficient comparison\n    scores_neg_sorted = np.sort(scores_neg)\n    \n    # Use searchsorted for vectorized counting of pairs\n    # Number of S_neg  S_pos\n    num_greater = np.sum(np.searchsorted(scores_neg_sorted, scores_pos, side='left'))\n    # Number of S_neg == S_pos\n    num_equal = np.sum(np.searchsorted(scores_neg_sorted, scores_pos, side='right') - \n                       np.searchsorted(scores_neg_sorted, scores_pos, side='left'))\n\n    auc = (num_greater + 0.5 * num_equal) / (n_pos * n_neg)\n    return auc\n\ndef run_simulation(mu1, mu0, rho_train, rho_val, b_train, b_val, \n                   pi_train, pi_val, n_train, n_val, R):\n    \"\"\"\n    Runs one full Monte Carlo simulation for a given set of parameters.\n    \"\"\"\n    auc_diffs = []\n    STABILIZATION_CONST = 1e-8\n    \n    for _ in range(R):\n        # 1. Generate data\n        X_train, y_train = generate_data(n_train, pi_train, mu1, mu0, b_train, rho_train)\n        X_val, y_val = generate_data(n_val, pi_val, mu1, mu0, b_val, rho_val)\n\n        # --- No-leakage workflow ---\n        # 2a. Normalize using training set stats\n        m_train = np.mean(X_train, axis=0)\n        s_train = np.std(X_train, axis=0) + STABILIZATION_CONST\n        Z_train_nl = (X_train - m_train) / s_train\n        Z_val_nl = (X_val - m_train) / s_train\n\n        # 3a. Train LDA on no-leakage normalized data\n        w_nl = train_lda(Z_train_nl, y_train)\n\n        # 4a. Evaluate on no-leakage validation data\n        scores_nl = Z_val_nl @ w_nl\n        auc_nl = calculate_auc(scores_nl, y_val)\n\n        # --- Leakage workflow ---\n        X_all = np.vstack((X_train, X_val))\n        \n        # 2b. Normalize using combined set stats\n        m_all = np.mean(X_all, axis=0)\n        s_all = np.std(X_all, axis=0) + STABILIZATION_CONST\n        Z_train_l = (X_train - m_all) / s_all\n        Z_val_l = (X_val - m_all) / s_all\n\n        # 3b. Train LDA on leakage normalized data\n        w_l = train_lda(Z_train_l, y_train)\n        \n        # 4b. Evaluate on leakage validation data\n        scores_l = Z_val_l @ w_l\n        auc_l = calculate_auc(scores_l, y_val)\n\n        # 5. Record the difference\n        auc_diffs.append(auc_l - auc_nl)\n\n    # 6. Return the expected bias (mean of differences)\n    return np.mean(auc_diffs)\n\nsolve()\n```"
        },
        {
            "introduction": "在数据泄露这一通用概念的基础上，本练习聚焦于时间序列数据所带来的特定挑战。当对具有时间自相关性的数据使用标准交叉验证时，模型会无意中“看到未来”，从而导致不切实际的性能评估 。此练习将引导您推导一个量化这种时间泄露风险的数学表达式，并阐明为何滚动原点评估 (rolling-origin evaluation) 等方法对于有效的时间序列模型评估至关重要。",
            "id": "3804475",
            "problem": "一位水文学家正在建立一个环境模型，用于在单个代表性地点根据卫星衍生的协变量预测每日地表土壤湿度。令目标序列 $\\{y_{t}\\}_{t=1}^{N}$ 表示土壤湿度异常，该序列是弱平稳的，并且可以很好地由一阶自回归过程（AR(1)）近似，其均值为零，自相关函数为 $\\mathrm{corr}(y_{t},y_{t+h})=\\rho^{|h|}$，其中 $|\\rho|1$。在此设定下，对于每日聚合的异常值，假设 $\\rho \\in [0,1)$。\n\n正在考虑的模型评估方案是随机K折交叉验证（cross-validation (CV)），其中 $K \\ge 2$ 为固定值。该方案的实现方式是：将每个索引 $t \\in \\{1,\\dots,N\\}$ 独立地分配到某一折 $F_{t} \\in \\{1,\\dots,K\\}$，且 $\\mathbb{P}(F_{t}=k)=1/K$，此分配对所有 $t$ 都是独立的。对于任何测试索引 $t$，训练集由所有满足 $s \\neq t$ 和 $F_{s} \\neq F_{t}$ 的索引 $s$ 组成。这种方案可能导致时间泄漏，因为训练数据可能包含来自时间 $st$ 的观测值，而这些观测值与 $y_{t}$ 存在自相关。\n\n将单个随机选择的测试索引 $t$ 的泄漏影响分数定义为\n$$\nL_{K}(\\rho)\\;=\\;\\mathbb{E}\\left[\\sum_{h=1}^{\\infty} \\left|\\mathrm{corr}(y_{t},y_{t+h})\\right| \\cdot \\mathbf{1}\\{t+h \\text{ is in the training set when } t \\text{ is test}\\}\\right],\n$$\n其中期望是针对随机的分折分配以及在内部均匀选择的 $t$ 计算的，因此当 $N \\to \\infty$ 时，边界效应可以忽略不计。将 $L_{K}(\\rho)$ 解释为对于测试点 $t$，进入训练集的相关性加权的未来信息的期望量级。\n\n仅从自相关函数的AR(1)定义、分折分配的独立性和等可能性以及期望的线性性出发，推导出一个关于 $K$ 和 $\\rho$ 的 $L_{K}(\\rho)$ 的闭式解析表达式，该表达式在 $0 \\le \\rho  1$ 和 $N$ 很大时有效。然后，使用基本原理，解释为什么一个滚动原点评估（rolling-origin evaluation (ROE)）方案——即对于测试时间 $t$，仅在索引 $s \\le t-1$ 上进行训练——在此度量下会产生零泄漏影响。\n\n请以 $L_{K}(\\rho)$ 的闭式解析表达式形式提供您的最终答案。不需要数值评估。不陈述单位。最终答案请勿提供不等式或方程式；仅提供闭式表达式。",
            "solution": "该问题是有效的，因为它具有科学依据、提法明确且自成体系。它提出了一个基于时间序列分析和统计模型验证的既定原则的严谨数学推导任务。\n\n主要任务是推导泄漏影响分数 $L_{K}(\\rho)$ 的闭式表达式，其定义为：\n$$\nL_{K}(\\rho) \\;=\\; \\mathbb{E}\\left[\\sum_{h=1}^{\\infty} \\left|\\mathrm{corr}(y_{t},y_{t+h})\\right| \\cdot \\mathbf{1}\\{t+h \\text{ is in the training set when } t \\text{ is test}\\}\\right]\n$$\n期望 $\\mathbb{E}[\\cdot]$ 是对数据点到各折的随机分配计算的。问题指明时间序列 $\\{y_{t}\\}$ 是一个一阶自回归过程（AR($1$)），其自相关函数为 $\\mathrm{corr}(y_{t}, y_{t+h}) = \\rho^{|h|}$。参数 $\\rho$ 被限制在区间 $[0, 1)$ 内，求和是针对未来的滞后 $h \\ge 1$。在这些条件下，$\\left|\\mathrm{corr}(y_{t},y_{t+h})\\right| = |\\rho^h| = \\rho^h$。\n\n令 $I_{h}$ 表示指示函数 $\\mathbf{1}\\{t+h \\text{ 在 } t \\text{ 为测试点时属于训练集}\\}$。$L_{K}(\\rho)$ 的表达式变为：\n$$\nL_{K}(\\rho) = \\mathbb{E}\\left[\\sum_{h=1}^{\\infty} \\rho^h \\cdot I_{h}\\right]\n$$\n由于和中的所有项都是非负的，我们可以应用Fubini-Tonelli定理来交换期望和求和（期望的线性性）：\n$$\nL_{K}(\\rho) = \\sum_{h=1}^{\\infty} \\mathbb{E}\\left[\\rho^h \\cdot I_{h}\\right]\n$$\n项 $\\rho^h$ 相对于随机的分折分配是一个常数。因此，我们可以将其移到期望之外：\n$$\nL_{K}(\\rho) = \\sum_{h=1}^{\\infty} \\rho^h \\cdot \\mathbb{E}[I_{h}]\n$$\n指示函数的期望是其所指示事件的概率。因此，我们需要计算 $\\mathbb{P}(t+h \\text{ 在 } t \\text{ 为测试点时属于训练集})$。\n验证方案是随机K折交叉验证。对于一个测试点 $t$，如果点 $s$ 满足 $s \\neq t$ 且 $s$ 与 $t$ 不在同一折中，则 $s$ 属于训练集。令 $F_t$ 为索引 $t$ 的分折分配。对于 $t+h$（其中 $h \\ge 1$，因此 $t+h \\neq t$）属于训练集的条件是 $F_{t+h} \\neq F_t$。\n因此，我们需要计算概率 $\\mathbb{P}(F_{t+h} \\neq F_t)$。分折分配 $F_t$ 和 $F_{t+h}$ 是独立同分布的随机变量，均匀分布在集合 $\\{1, 2, \\dots, K\\}$ 上。\n两个索引在同一折中的概率是：\n$$\n\\mathbb{P}(F_{t+h} = F_t) = \\sum_{k=1}^{K} \\mathbb{P}(F_{t+h} = k \\text{ and } F_t = k)\n$$\n由于分配的独立性：\n$$\n\\mathbb{P}(F_{t+h} = F_t) = \\sum_{k=1}^{K} \\mathbb{P}(F_{t+h} = k) \\cdot \\mathbb{P}(F_t = k)\n$$\n鉴于等可能的分配，对于任何 $t$ 和 $k$，$\\mathbb{P}(F_t = k) = 1/K$。\n$$\n\\mathbb{P}(F_{t+h} = F_t) = \\sum_{k=1}^{K} \\left(\\frac{1}{K}\\right) \\cdot \\left(\\frac{1}{K}\\right) = \\sum_{k=1}^{K} \\frac{1}{K^2} = K \\cdot \\frac{1}{K^2} = \\frac{1}{K}\n$$\n互补事件，即索引在不同折中的概率是：\n$$\n\\mathbb{P}(F_{t+h} \\neq F_t) = 1 - \\mathbb{P}(F_{t+h} = F_t) = 1 - \\frac{1}{K} = \\frac{K-1}{K}\n$$\n这个概率就是 $\\mathbb{E}[I_{h}]$ 的值，并且对于所有 $h \\ge 1$ 都是常数。将其代入 $L_{K}(\\rho)$ 的表达式中：\n$$\nL_{K}(\\rho) = \\sum_{h=1}^{\\infty} \\rho^h \\cdot \\left(\\frac{K-1}{K}\\right)\n$$\n我们可以将常数项提取出来：\n$$\nL_{K}(\\rho) = \\left(\\frac{K-1}{K}\\right) \\sum_{h=1}^{\\infty} \\rho^h\n$$\n剩余的和是一个标准的几何级数。对于 $|\\rho|  1$，已知其和为：\n$$\n\\sum_{h=1}^{\\infty} \\rho^h = \\frac{\\rho}{1-\\rho}\n$$\n代入这个结果，得到泄漏影响分数的最终闭式表达式：\n$$\nL_{K}(\\rho) = \\frac{K-1}{K} \\frac{\\rho}{1-\\rho}\n$$\n\n问题的第二部分要求解释为什么滚动原点评估（ROE）方案会导致零泄漏影响。在ROE方案中，对于给定的测试时间 $t$，训练集被定义为仅包含索引 $s \\le t-1$ 处的观测值。\n泄漏影响分数 $L(\\rho)$ 被定义为衡量*未来*信息的影响，具体来说是将在时间 $t+h$（其中 $h \\in \\{1, 2, 3, \\dots\\}$）的贡献求和。$L(\\rho)$ 定义中的指示函数变为 $\\mathbf{1}\\{t+h \\text{ 在ROE训练集中}\\}$。根据ROE规则，这要求观测时间 $t+h$ 满足条件 $t+h \\le t-1$。该不等式简化为 $h \\le -1$。然而，$L(\\rho)$ 定义中的求和是针对严格正整数 $h \\ge 1$。对于任何 $h \\ge 1$，条件 $h \\le -1$ 永远无法满足。\n因此，指示函数 $\\mathbf{1}\\{t+h \\text{ 在ROE训练集中}\\}$ 对于求和中的所有项都恒等于零。和变为 $\\sum_{h=1}^{\\infty} \\rho^h \\cdot 0 = 0$。$0$的期望是$0$，所以ROE方案的泄漏影响分数为 $L_{ROE}(\\rho) = 0$。这证实了ROE方案通过其仅使用过去数据进行训练的构造，完全避免了 $L_K(\\rho)$ 度量所捕获的那种未来信息泄漏。",
            "answer": "$$\n\\boxed{\\frac{K-1}{K} \\frac{\\rho}{1-\\rho}}\n$$"
        },
        {
            "introduction": "与时间数据类似，空间数据由于空间自相关性的存在，也给模型验证带来了独特的挑战。本练习将地质统计学理论与稳健验证方案的设计直接联系起来 。您将通过利用经验半变异函数的变程，推导出一个用于在空间块交叉验证 (spatial block cross-validation) 中设定块大小的实用经验法则，从而确保训练集和验证集之间具有充分的独立性。",
            "id": "3804424",
            "problem": "一个遥感团队正在使用一个二阶平稳各向同性高斯随机场 $Z(\\mathbf{s})$（定义在 $\\mathbb{R}^{2}$ 上）来模拟一个空间分布的环境变量。该随机场具有半变异函数 $\\gamma(h)$、协方差函数 $C(h)$ 和相关函数 $\\rho(h) = C(h)/C(0)$。回想一下恒等式 $\\gamma(h) = C(0) - C(h)$ 对所有 $h \\geq 0$ 成立。该团队估计了经验半变异函数 $\\hat{\\gamma}(h)$ 和经验基台值 $\\hat{C}(0)$，并通过条件 $\\hat{\\gamma}(\\hat{r}) = (1 - \\delta)\\,\\hat{C}(0)$ 在容差水平 $\\delta \\in (0,1)$ 上定义了经验有效程长 $\\hat{r}$。\n\n他们计划使用空间块交叉验证进行模型评估：将研究区域密铺成边长为 $b$ 的不重叠方形块，在每一折中，他们选择一个验证块，并移除该验证块周围宽度为 $b$ 的缓冲区内的所有训练点。在这种设计下，任何验证点与任何保留的训练点之间的最小欧几里得距离至少为 $b$。如果任何验证点与任何保留的训练点之间的最大绝对相关性以 $\\delta$ 为界，则该团队称训练和验证是“近似独立的”。\n\n仅使用上述核心定义和各向同性二阶平稳场的半变异函数的单调性，推导出一个关于最小块大小 $b^{\\star}$ 的经验法则。该经验法则应表示为 $\\hat{r}$ 和 $\\delta$ 的闭式函数，并能在所述的带缓冲区的块保留方案下保证近似独立性准则。你的最终答案必须是 $b^{\\star}$ 的单个解析表达式。不需要进行数值舍入。",
            "solution": "在尝试解答之前，对问题进行验证。\n\n### 第 1 步：提取已知条件\n-   模型是一个定义在 $\\mathbb{R}^{2}$ 上的二阶平稳各向同性高斯随机场 $Z(\\mathbf{s})$。\n-   相关函数为半变异函数 $\\gamma(h)$、协方差函数 $C(h)$ 和相关函数 $\\rho(h) = C(h)/C(0)$。\n-   提供了一个恒等式：$\\gamma(h) = C(0) - C(h)$ 对所有 $h \\geq 0$ 成立。\n-   使用了经验估计值：经验半变异函数 $\\hat{\\gamma}(h)$ 和经验基台值 $\\hat{C}(0)$。\n-   对于给定的容差 $\\delta \\in (0,1)$，经验有效程长 $\\hat{r}$ 由条件 $\\hat{\\gamma}(\\hat{r}) = (1 - \\delta)\\,\\hat{C}(0)$ 定义。\n-   模型评估方法是空间块交叉验证，使用边长为 $b$ 的不重叠方形块。\n-   保留方案涉及移除验证块周围宽度为 $b$ 的缓冲区内的所有训练点。\n-   保留方案的一个结果是，任何验证点与任何保留的训练点之间的最小欧几里得距离至少为 $b$。\n-   “近似独立”的准则是任何验证点与任何保留的训练点之间的最大绝对相关性以 $\\delta$ 为界。\n-   目标是推导保证此准则的最小块大小 $b^{\\star}$，作为 $\\hat{r}$ 和 $\\delta$ 的函数。\n-   推导过程仅限于使用所提供的定义和各向同性二阶平稳场的半变异函数的单调性。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题在科学上基于地质统计学和空间数据分析的既定原则。所有术语，如高斯随机场、二阶平稳性、各向同性、半变异函数、协方差和空间块交叉验证，在此背景下都是标准且定义明确的。该问题是适定的，提供了一个明确的目标和充分、一致的信息，可以通过逻辑推导来实现。定义是形式化和客观的。该问题不违反任何科学定律，不基于错误的前提，是可形式化的、完整的，并且不是微不足道的。\n\n### 第 3 步：结论与行动\n问题被判定为 **有效**。将提供解答。\n\n### 解答推导\n\n目标是找到满足“近似独立”准则的最小块大小 $b^{\\star}$。让我们将此准则形式化，并将其与给定的定义联系起来。\n\n近似独立准则指出，任何验证点与任何保留的训练点之间的最大绝对相关性至多为 $\\delta$。设 $\\mathbf{s}_v$ 为任意验证点的位置，$\\mathbf{s}_t$ 为任意保留训练点的位置。它们之间的欧几里得距离是 $h = \\|\\mathbf{s}_v - \\mathbf{s}_t\\|$。这两个位置的随机场值之间的相关性由相关函数 $\\rho(h)$ 给出。该准则可写为：\n$$\n\\max_{\\mathbf{s}_v, \\mathbf{s}_t} |\\rho(h)| \\le \\delta\n$$\n其中最大值取自所有可能的验证点 $\\mathbf{s}_v$ 和保留训练点 $\\mathbf{s}_t$ 对。\n\n根据问题描述，带缓冲区的块保留方案确保了任何此类点对之间的最小距离为 $b$。也就是说，对于任何允许的点对 $(\\mathbf{s}_v, \\mathbf{s}_t)$，它们的距离 $h$ 满足 $h \\ge b$。\n\n对于二阶平稳各向同性随机场，半变异函数 $\\gamma(h)$ 是滞后距离 $h \\ge 0$ 的非递减函数。相关函数 $\\rho(h)$ 和半变异函数 $\\gamma(h)$ 之间的关系由给定的恒等式 $\\gamma(h) = C(0) - C(h)$ 和定义 $\\rho(h) = C(h)/C(0)$ 推导得出：\n$$\n\\rho(h) = \\frac{C(0) - \\gamma(h)}{C(0)} = 1 - \\frac{\\gamma(h)}{C(0)}\n$$\n由于 $\\gamma(h)$ 是 $h$ 的非递减函数，因此 $\\rho(h)$ 是 $h$ 的非递增函数。对于大多数标准半变异函数模型，基台值 $C(0)$ 代表最大半方差，因此 $\\gamma(h) \\le C(0)$，这意味着 $\\rho(h) \\ge 0$。在这种情况下， $|\\rho(h)| = \\rho(h)$。$\\rho(h)$ 的非递增性意味着，对于所有距离 $h \\ge b$，$\\rho(h)$ 的最大值将出现在可能的最小距离处，即 $h=b$。\n\n因此，条件 $\\max_{h \\ge b} |\\rho(h)| \\le \\delta$ 简化为确保在距离 $b$ 处的相关性满足该界限：\n$$\n|\\rho(b)| \\le \\delta\n$$\n按照标准假设 $\\rho(h) \\ge 0$，这变为：\n$$\n\\rho(b) \\le \\delta\n$$\n现在我们用半变异函数来代入 $\\rho(b)$ 的表达式。问题是以经验估计的形式提出的，所以我们将使用 $\\hat{\\gamma}(h)$ 和 $\\hat{C}(0)$。\n$$\n1 - \\frac{\\hat{\\gamma}(b)}{\\hat{C}(0)} \\le \\delta\n$$\n重新整理这个不等式，以求解关于 $\\hat{\\gamma}(b)$ 的条件：\n$$\n1 - \\delta \\le \\frac{\\hat{\\gamma}(b)}{\\hat{C}(0)}\n$$\n$$\n(1 - \\delta)\\hat{C}(0) \\le \\hat{\\gamma}(b)\n$$\n这是块大小 $b$ 为确保近似独立性必须满足的条件。\n\n问题提供了经验有效程长 $\\hat{r}$ 的定义，即经验半变异函数达到基台值特定比例时的距离：\n$$\n\\hat{\\gamma}(\\hat{r}) = (1 - \\delta)\\hat{C}(0)\n$$\n将此定义代入我们的不等式，得到：\n$$\n\\hat{\\gamma}(\\hat{r}) \\le \\hat{\\gamma}(b)\n$$\n问题明确允许使用半变异函数的单调性。由于 $\\hat{\\gamma}(h)$ 是 $h$ 的非递减函数，不等式 $\\hat{\\gamma}(\\hat{r}) \\le \\hat{\\gamma}(b)$ 直接意味着其参数之间的关系：\n$$\n\\hat{r} \\le b\n$$\n这表明，要满足近似独立性准则，块边长 $b$ 必须至少与经验有效程长 $\\hat{r}$（在容差 $\\delta$ 下定义）一样大。问题要求保证该条件的最小块大小 $b^{\\star}$。这个最小值为：\n$$\nb^{\\star} = \\hat{r}\n$$\n这个结果是 $\\hat{r}$ 的函数，而 $\\hat{r}$ 本身通过其定义是 $\\delta$ 的隐函数。这就是所要求的闭式表达式。",
            "answer": "$$\n\\boxed{\\hat{r}}\n$$"
        }
    ]
}