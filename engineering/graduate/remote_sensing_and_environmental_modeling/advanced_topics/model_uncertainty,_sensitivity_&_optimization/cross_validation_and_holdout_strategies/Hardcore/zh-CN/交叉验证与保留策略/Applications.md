## 应用与跨学科连接

在前面的章节中，我们已经探讨了交叉验证 (Cross-Validation, CV) 和留出策略 (Holdout Strategies) 的基本原理与机制。这些技术为评估和选择模型提供了统计上严谨的基础。然而，将这些原理从理想化的教科书情境应用于真实世界的[环境建模](@entry_id:1124562)和遥感分析任务中，会带来一系列独特的挑战。真实世界的数据很少是[独立同分布](@entry_id:169067)的 (i.i.d.)；它们往往表现出复杂的空间、时间或层次依赖性。此外，建模工作流本身可能非常复杂，涉及多阶段的[数据预处理](@entry_id:197920)、[特征工程](@entry_id:174925)和多源[数据融合](@entry_id:141454)，每一个环节都可能成为信息泄露的潜在来源。

本章的目标是展示[交叉验证](@entry_id:164650)的核心原则如何在多样化、跨学科的应用中被扩展、调整和整合。我们不会重复介绍核心概念，而是将重点放在解决由数据内在结构和建模目标复杂性所带来的实际问题上。我们将通过一系列以应用为导向的案例，探索如何设计稳健的验证策略，以应对空间和时间自相关、[数据异质性](@entry_id:918115)、复杂的建模流程以及[模型比较](@entry_id:266577)等挑战。这些案例将揭示，交叉验证并非一个可以盲目套用的“黑箱”工具，而是一种需要根据具体数据结构和科学问题精心设计的强大而灵活的框架。

### 应对空间依赖性

在[环境科学](@entry_id:187998)和遥感中，一个普遍存在的现象是“地理学第一定律”：相近的事物比相远的事物更相关。这种现象，即[空间自相关](@entry_id:177050)，对模型验证构成了根本性挑战。如果随机地将空间数据点分配到[训练集](@entry_id:636396)和[验证集](@entry_id:636445)中（例如，使用标准的 $K$-fold [交叉验证](@entry_id:164650)），那么[验证集](@entry_id:636445)中的某个点很可能与其在空间上非常接近的训练点高度相关。这违反了[交叉验证](@entry_id:164650)所依赖的核心假设，即[训练集](@entry_id:636396)和[验证集](@entry_id:636445)应相互独立。在这种情况下，[模型评估](@entry_id:164873)的将是其在近距离内的插值能力，而非其在全新、未见区域的泛化能力，从而导致对模型性能的过度乐观估计。

#### 空间区组交叉验证

为解决此问题，标准实践是采用**空间区组[交叉验证](@entry_id:164650) (Spatial Block Cross-Validation)**。其核心思想不是[随机抽样](@entry_id:175193)单个数据点，而是将整个研究区域划分为若干个地理上邻接的、互不重叠的“区组”（或瓦片），然后将这些区组作为整体分配到不同的折中。在每一折中，一个或多个区组被作为[验证集](@entry_id:636445)，而所有其余区组则构成[训练集](@entry_id:636396)。这种方法通过在[训练集](@entry_id:636396)和[验证集](@entry_id:636445)之间强制实现空间分离，确保了两者之间的独立性。

然而，一个关键问题随之而来：需要多大的空间分离才足够？答案取决于数据中[空间自相关](@entry_id:177050)的范围。在地统计学中，这个范围可以通过**半变异函数 (Semivariogram)** 来量化，它描述了数据点之间的差异如何随其空间距离的增加而变化。半变异函数模型通常包含一个名为“变程”($a$) 的参数，表示当两点间距超过此距离时，它们之间的空间相关性可以忽略不计。

一个科学上严谨的空间区组交叉验证设计应利用这一信息。一种有效的策略是，在将一个区组作为[验证集](@entry_id:636445)时，不仅要排除该区组本身，还要排除其周围一个缓冲区内的所有训练数据。这个缓冲区的宽度应至少等于[空间自相关](@entry_id:177050)的有效范围（例如，对于指数[协方差模型](@entry_id:165727)，通常取相关性降至 0.05 以下的距离，约为3倍的空间尺度参数 $\phi$）。通过实施这样一个“排他性缓冲区”，我们可以确保[训练集](@entry_id:636396)中的任何一点与[验证集](@entry_id:636445)中的任何一点之间的最小距离都大于自相关的有效范围，从而在统计上保证了训练集和[验证集](@entry_id:636445)的独立性，得到对[泛化误差](@entry_id:637724)的近似无偏估计。 

#### 特征工程中的空间信息泄露

空间依赖性带来的挑战并不仅限于[训练集](@entry_id:636396)和[验证集](@entry_id:636445)的划分。在[特征工程](@entry_id:174925)阶段，一个更微妙的[信息泄露](@entry_id:155485)形式可能已经发生。在遥感[图像分析](@entry_id:914766)中，为了捕捉地物的纹理或上下文信息，通常会使用基于邻域窗口的算子（例如，计算局部均值、方差或[灰度共生矩阵](@entry_id:895073)）。例如，一个像素点的纹理特征是根据其周围一个 $(2r+1) \times (2r+1)$ 窗口内所有像素的光谱值计算得出的。

如果在进行[交叉验证](@entry_id:164650)划分*之前*，就对整幅图像计算这些邻域特征，那么[信息泄露](@entry_id:155485)将不可避免。考虑一个位于训练区组边界附近的像素，其邻域窗口很可能会跨越边界，包含一部分来自验证区组的像素。这意味着，这个训练像素的特征实际上已经“偷看”了[验证集](@entry_id:636445)的光谱信息。反之亦然，验证区组边界附近像素的特征也受到了[训练集](@entry_id:636396)信息的影响。这种跨折的依赖性同样会导致对模型性能的乐观偏差。

为防止此类泄露，必须采用边界感知的特征计算策略。主要有两种严谨的补救措施：
1.  **特征掩膜计算 (Masked Feature Computation)**：在交叉验证的每一折中，为[训练集](@entry_id:636396)和[验证集](@entry_id:636445)分别重新计算特征。当计算一个属于某个集合（[训练集](@entry_id:636396)或[验证集](@entry_id:636445)）的像[素特征](@entry_id:155979)时，其邻域窗口被“掩膜”，即仅使用窗口内同样属于该[集合的像](@entry_id:140317)素进行计算。这确保了特征的计算严格限制在各自的数据折内部。
2.  **缓冲[交叉验证](@entry_id:164650) (Buffered Cross-Validation)**：不改变特征计算方式，而是在分析中排除边界区域的像素。具体来说，对于每个[训练集](@entry_id:636396)和[验证集](@entry_id:636445)，移除那些邻域窗口会跨越边界的像素。通过对训练集和[验证集](@entry_id:636445)进行“腐蚀”操作，可以确保所有保留下来的像素，其邻域窗口完全位于其所属的集合内部。这种方法以牺牲部分样本为代价，保证了特征计算的独立性。

### [处理时间](@entry_id:196496)依赖性与预测任务

与空间自相关类似，[时间序列数据](@entry_id:262935)（如从卫星上获得的月度植被指数NDVI）也表现出时间[自相关](@entry_id:138991)性。在构建预测模型（例如，预测下个月的NDVI）时，验证策略必须严格遵守时间因果性原则：模型只能使用过去的信息来预测未来。任何违反这一原则的做法，例如允许模型在训练时接触到未来数据，都会导致其性能评估完全失效。

标准的 $K$-fold 交叉验证通过随机打乱数据来构建折，这会彻底破坏时间顺序，因此完全不适用于[时间序列预测](@entry_id:1133170)任务。正确的做法是采用一种模拟真实预测流程的验证方案，如**前向链式交叉验证 (Forward-Chaining Cross-Validation)**，也称为滚动原点或扩展窗口验证。

在一个典型的前向链式[交叉验证](@entry_id:164650)方案中，数据被按时间顺序划分为多个连续的训练-验证对。例如，要进行单步预测，其验证分割形式为 $(\\{1, \dots, t\\}, \\{t+1\\})$，其中 $t$ 从一个初始训练期 $t_0$ 逐步推进到数据集的末尾。在第 $t$ 次迭代中，模型使用从时间点 1 到 $t$ 的所有历史数据（一个不断扩展的窗口）进行训练，然后对其在时间点 $t+1$ 的预测能力进行评估。这个过程完美地模拟了现实世界中的预测场景：在任何时间点 $t$，我们只能利用截至 $t$ 的可用信息来预测 $t+1$。

#### 嵌套[时间交叉验证](@entry_id:908161)与特征泄露

当模型包含需要调优的超参数时，情况变得更加复杂，需要使用**[嵌套交叉验证](@entry_id:176273) (Nested Cross-Validation)**。在外循环中，数据被分割以进行性能评估；在内循环中，外循环的[训练集](@entry_id:636396)被进一步分割以进行超参数选择。对于[时间序列数据](@entry_id:262935)，内循环和外循环都必须遵循前向链式结构，以确保因果性。

此外，类似于空间邻域特征，时间序列的[特征工程](@entry_id:174925)也可能引入[信息泄露](@entry_id:155485)。例如，一个在时间点 $t$ 的特征可能是通过一个向后滚动的窗口（如过去 $L$ 天的[移动平均](@entry_id:203766)值）计算的。同时，时间序列中的随机波动可能需要一段时间（称为“混合时间” $\tau_{\text{mix}}$）才会消散。为了确保内循环的[验证集](@entry_id:636445)与训练集在统计上是独立的，并且没有任何特征支持的重叠，必须在训练期的最后一个观测点和验证期的第一个观测点之间引入一个**时间间隔 (Gap)**。

这个间隔的大小需要仔细确定，以同时满足两个条件：(1) 确保[验证集](@entry_id:636445)最早的特征窗口不包含任何训练期的原始观测值；(2) 确保[验证集](@entry_id:636445)最早的特征窗口内的所有原始观测值与训练期最后一个原始观测值之间的时间差大于自相关的[混合时间](@entry_id:262374) $\tau_{\text{mix}}$。综合这两个条件，所需的最小时间间隔 $G_{\text{min}}$ 应为特征窗口长度减一与混合时间之和，即 $G_{\text{min}} = (L-1) + \tau_{\text{mix}}$。在设计嵌套[时间交叉验证](@entry_id:908161)时，在内循环和外循环的每个分割点都强制执行这个时间间隔，是获得[无偏性](@entry_id:902438)能估计的关键。

### 验证模型的泛化性与可移植性

[交叉验证](@entry_id:164650)的一个强大应用是评估模型在当前数据集范围之外的泛化能力，即可移植性 (Transportability)。在环境建模中，我们通常不仅关心模型在已有采样点附近的表现，更关心它能否成功应用于一个全新的、具有不同特征的地理单元（如一个未曾见过的流域）或来自一个全新数据源（如一个不同的卫星传感器）的数据。

#### 泛化到新的空间单元

标准的空间区组交叉验证通过在空间上分离训练集和[验证集](@entry_id:636445)来评估泛化性。然而，我们可以通过将“区组”定义为具有实际意义的实体，来使这一评估更具针对性。例如，在预测河流叶绿素浓度的任务中，数据往往具有层次结构：观测站嵌套在不同的流域中。同一流域内的观测点可能由于共同的水文、地质和气候条件而高度相关，而不同流域之间则相对独立。

在这种情况下，科学目标通常是评估模型在一个全新流域的表现。要模拟这个场景，最合适的验证策略是**留一区组[交叉验证](@entry_id:164650) (Leave-One-Group-Out CV)**，在此即为**留一流域[交叉验证](@entry_id:164650) (Leave-One-Basin-Out CV)**。在每一折中，一个完整的流域被作为[验证集](@entry_id:636445)，模型则使用所有其他流域的数据进行训练和[超参数调优](@entry_id:143653)。这种方法严格遵守了数据的层次结构，确保了训练和验证数据在“流域”这一概念单元上的独立性。其得出的性能评估直接对应于模型迁移到一个具有新水文状况的未见流域时的预期表现。

#### 泛化到新的数据域

在遥感领域，数据通常来自多个不同的传感器（如Sentinel-2, Landsat-8, [MODIS](@entry_id:1128071)）。由于光谱响应函数、空间分辨率和[大气校正](@entry_id:1121189)算法的差异，每个传感器的数据可以被视为来自一个不同的“数据域”。这导致了所谓的“域移位”(Domain Shift) 问题。一个关键的建模目标是开发出对这些传感器差异具有稳健性，并能泛化到新传感器的模型。

为了评估这种跨[域泛化](@entry_id:635092)能力，同样可以采用留一区组[交叉验证](@entry_id:164650)的思路，此时“区组”即为“传感器”。这种**留一传感器交叉验证 (Leave-One-Sensor-Out CV)** 策略在每一外循环折中，将一个完整的传感器数据作为测试集，并使用所有其他传感器的数据进行内循环的[超参数调优](@entry_id:143653)和模型训练。最终的性能是所有外循环折（每个传感器都作为一次测试集）性能的平均值。这个结果提供了模型在面对一个完全未见过的、具有不同系统偏差和噪声特征的数据源时的性能的[无偏估计](@entry_id:756289)。

### 应对复杂建模工作流与数据特性

现代环境建模通常涉及复杂的多步骤工作流和[异构数据](@entry_id:265660)，这给交叉验证的正确实施带来了额外的挑战。

#### “管道”原则：封装整个工作流

一个常见的、严重的错误是在[交叉验证](@entry_id:164650)开始之前，对整个数据集进行预处理。这些[预处理](@entry_id:141204)步骤，即使是“无监督”的（即不使用标签信息），也可能导致[信息泄露](@entry_id:155485)。例如：
-   **[分位数归一化](@entry_id:267331) (Quantile Normalization)**：该方法通过将所有样本的分布强制变为一个“[目标分布](@entry_id:634522)”来消除技术变异。这个[目标分布](@entry_id:634522)通常是根据所有参与归一化的样本计算得出的。如果在划分折之前对整个数据集进行归一化，那么[测试集](@entry_id:637546)样本的统计信息（如分位数）就已经影响了[训练集](@entry_id:636396)样本的变换方式。
-   **主成分分析 (Principal Component Analysis, PCA)**：PCA通过寻找数据方差最大的方向来降维。如果在整个数据集上运行PCA，那么测试集的方差结构就会影响到为训练集所定义的坐标轴。
-   **[批次效应校正](@entry_id:269846) (Batch-Effect Adjustment)**：诸如ComBat之类的[经验贝叶斯方法](@entry_id:169803)通过汇集批次内所有样本的信息来估计和校正[批次效应](@entry_id:265859)。如果训练和测试样本存在于同一批次中并被一同处理，测试样本的信息就会泄露到训练样本的校正过程中。

防止此类泄露的“黄金法则”是：**必须将整个[数据依赖](@entry_id:748197)的建模流程（包括所有[预处理](@entry_id:141204)、[特征选择](@entry_id:177971)和模型拟合步骤）封装在交叉验证的循环之内**。在每一折中，所有用于[转换数](@entry_id:175746)据的参数（如归一化的[目标分布](@entry_id:634522)、PCA的[投影矩阵](@entry_id:154479)、批次效应的参数）都必须*仅*从当前的训练数据中学习，然后将学习到的转换应用到验证数据上。

#### [超参数调优](@entry_id:143653)与[嵌套交叉验证](@entry_id:176273)

当模型包含需要通过数据来选择的超参数时（例如，正则化惩罚项的强度），一次简单的 $K$-fold 交叉验证是不够的。如果我们使用同一套交叉验证分割来选择最佳超参数并报告其性能，那么所报告的性能将是过度乐观的。这是因为我们从多个超参数配置中挑选了在这些特定[验证集](@entry_id:636445)上表现最好的一个，这个选择过程本身就引入了偏差。

正确的做法是采用**[嵌套交叉验证](@entry_id:176273) (Nested Cross-Validation)**。
-   **外循环**用于最终的性能评估。它将数据划分为 $K_{\text{out}}$ 个折。
-   **内循环**用于超参数选择。在每个外循环折中，其训练数据被进一步划分为 $K_{\text{in}}$ 个折。对于每个候选的超参数组合，内循环运行一次完整的[交叉验证](@entry_id:164650)，并计算其平均验证误差。
-   在每个外循环折中，我们选择在内循环中表现最佳的超参数，然后使用这个超参数在*整个*外循环训练集上重新训练模型，并最终在留出的外循环测试集上评估其性能。
-   最终的泛化性能估计是所有外循环折上性能得分的平均值。这个值是对包含超参数选择在内的整个建模*流程*的性能的近似无偏估计。

在实践中，对多个超参数进行[网格搜索](@entry_id:636526)可能计算成本高昂。可以通过采用更智能的搜索策略（如[贝叶斯优化](@entry_id:175791)）和利用优化算法的“热启动”特性来提高效率。此外，为防止对超参数的“过拟合”，可以采用**“一个[标准误](@entry_id:635378)”规则**：不选择验证误差绝对最小的模型，而是选择误差在最小误差一个[标准误](@entry_id:635378)范围内的最简洁（即正则化最强）的模型。

#### 处理多分辨率数据

在遥感中，融合来自不同分辨率传感器的数据（例如，10米分辨率的SAR图像和30米分辨率的光学图像）是一个常见任务。这给验证带来了关于尺度的挑战。假设我们的目标是预测30米分辨率的叶面积指数（LAI），而我们的模型在10米分辨率上进行预测。验证时，我们需要将10米分辨率的预测结果[上采样](@entry_id:275608)到30米，以与30米分辨率的地面[真值](@entry_id:636547)进行比较。

上采样方法的选择会对最终的误差评估产生巨大影响。例如，考虑两种策略：(1) **平均[重采样](@entry_id:142583)**：将一个30米像元内的9个10米预测值取平均；(2) **[最近邻](@entry_id:1128464)重采样**：直接取中心10米像元的预测值。假设地面[真值](@entry_id:636547)本身被定义为9个10米真实LAI值的平均值，那么平均重[采样策略](@entry_id:188482)在数学上与[真值](@entry_id:636547)的定义方式相匹配。

可以从理论上证明，在这种情况下，最近邻重采样会导致均方误差（MSE）显著膨胀。误差的来源有两个：模型本身的预测误差，以及由于真实LAI在30米像元内部的[空间变异性](@entry_id:755146)所导致的[采样误差](@entry_id:182646)。平均[重采样](@entry_id:142583)能够有效地平[滑模](@entry_id:263630)型[预测误差](@entry_id:753692)和内部变异，而最近邻重采样则完全暴露在这两种误差之下。在一个具体的随机场模型假设下，可以计算出两种策略的预期MSE比值，这个比值可能高达4到5倍。这凸显了在多尺度验证中，确保预测值的聚合方式与[真值](@entry_id:636547)的定义方式在物理和统计上保持一致是至关重要的。

### 严谨的[模型评估](@entry_id:164873)与比较

在正确执行了[交叉验证](@entry_id:164650)之后，如何从结果中提炼出可靠的结论是最后一步。这包括如何汇总性能指标，以及如何进行统计上稳健的[模型比较](@entry_id:266577)。

#### 汇总性能指标

-   **回归任务**：在空间区组交叉验证中，由于云、水体等因素的遮挡，每个验证折的有效像元数量可能不同。在这种情况下，简单地将每个折的[均方根误差](@entry_id:170440)（RMSE）取平均是错误的，因为它会给予样本量小的折过高的权重。正确的做法是先将每个折的**平方误差之和 (Sum of Squared Errors, SSE)** 汇总起来，再除以总的验证样本数，最后再开方。这等价于计算各折[均方误差](@entry_id:175403)（MSE）的加权平均（权重为各折的样本量），然后再开方。

-   **[分类任务](@entry_id:635433)**：在处理[类别不平衡](@entry_id:636658)的[分类问题](@entry_id:637153)时（例如，在[土地覆盖](@entry_id:1127047)分类中，水体类别可能只占很小比例），评估指标的汇总方式尤为关键。假设我们为每个类别计算了灵敏度（[真阳性率](@entry_id:637442)）和特异性（真阴性率）。如果我们在每个折内部分别计算这些比率，然后跨折取平均（宏观平均），就会给予每个折同等的权重，而忽略了它们包含的类别[样本量](@entry_id:910360)可能差异很大。更稳健的做法是**微观平均 (micro-averaging)**：首先跨所有折汇总每个类别的[混淆矩阵](@entry_id:1124649)计数（即，总的[真阳性](@entry_id:637126)、假阳性、真阴性、假阴性数量），然后用这些汇总后的计数来计算最终的每个类别的性能指标。这种方法确保了每个样本对最终指标的贡献是均等的，从而真实地反映了模型在整个数据集上的性能，并保留了[类别不平衡](@entry_id:636658)的影响。

#### [类别不平衡](@entry_id:636658)下的分折设计

在使用分层 $K$-fold 交叉验证处理严重[类别不平衡](@entry_id:636658)的数据时（例如，湿地类别流行率仅为1%），一个实际问题是如何确保每个验证折中都包含足够数量的少数类样本以进行有意义的评估。我们可以从[组合学](@entry_id:144343)的角度推导出这一保证的条件。要保证每个验证折至少包含 $m$ 个正例，一个必要且充分的条件是，可用于交叉验证的正例总数 $P$ 必须满足 $P \ge mK$。这反过来也为在给定正例总数 $P$ 和最小样本要求 $m$ 的情况下，可以选择的最大折数 $K$ 设定了上限，即 $K_{\text{max}} = \lfloor P/m \rfloor$。

#### 模型的统计比较

当比较两个模型（例如，模型A和模型B）的性能时，仅仅比较它们的[交叉验证](@entry_id:164650)平均误差是不够的，因为这种差异可能源于随机的[验证集](@entry_id:636445)划分。我们需要进行[统计显著性](@entry_id:147554)检验，例如配对 $t$ 检验，来判断一个模型是否系统性地优于另一个。

然而，将在[交叉验证](@entry_id:164650)中获得的各折误差差异 $\{d_j\}$ 直接输入标准的配对 $t$ 检验是错误的。标准 $t$ 检验假设观测值是独立的，但[交叉验证](@entry_id:164650)产生的各折误差差异并非如此。由于不同折的训练集存在大量重叠，为它们训练出的模型是相关的，因此它们的误差差异也呈正相关。忽略这种相关性会导致对平均误差差异的方差的低估，从而夸大 $t$ 统计量，增加犯[第一类错误](@entry_id:163360)（即错误地拒绝两个模型性能相同的零假设）的风险。

为了解决这个问题，需要使用**修正的配对 $t$ 检验**。该检验在计算[标准误](@entry_id:635378)时，加入了一个修正项，该修正项考虑了由于[训练集](@entry_id:636396)重叠所引起的[方差膨胀](@entry_id:756433)。该修正项与测试集和[训练集](@entry_id:636396)大小的比值 $(n_{\text{test}}/n_{\text{train}})$ 成正比。在 $K$-fold 交叉验证中，这个比值是 $(1/K) / (1-1/K) = 1/(K-1)$。使用这个修正后的检验，可以对两个模型在[交叉验证](@entry_id:164650)下的性能进行更可靠、统计上更严谨的比较。

### [交叉验证](@entry_id:164650)在模型选择中的宏观视角

最后，将交叉验证置于更广阔的模型选择策略背景下进行审视是有益的。除了[交叉验证](@entry_id:164650)，另一类广泛使用的方法是**信息准则 (Information Criteria)**，如**[赤池信息准则](@entry_id:139671) (Akaike Information Criterion, AIC)** 和**贝叶斯信息准则 (Bayesian Information Criterion, BIC)**。这几类方法虽然都用于[模型选择](@entry_id:155601)，但其目标和适用场景有本质区别。

-   **目标差异**：AIC和交叉验证的目标是**预测准确性**。AIC旨在选择在[KL散度](@entry_id:140001)意义下最接近真实数据生成过程的模型，这等价于选择具有最佳预测性能的模型。交叉验证则直接估计模型在样本外的预测误差。相比之下，BIC的目标是**[模型识别](@entry_id:139651)**。它旨在从一组候选模型中识别出“真实”的模型（如果存在的话）。

-   **[渐近性质](@entry_id:177569)**：当样本量 $n \to \infty$ 时，如果真实模型存在于候选集中，BIC具有**一致性 (consistency)**，即它选中真实模型的概率会趋向于1。而AIC不具有一致性，它有一定概率会选择比真实模型更复杂的模型。然而，AIC具有**[渐近有效](@entry_id:167883)性 (asymptotic efficiency)**，即它能选择在预测风险上达到最小化的模型。

-   **适用场景**：
    -   当临床或科学目标是获得一个具有最佳**外部预测能力**的模型时，尤其是在模型可能被错误设定的情况下（即真实模型不在候选集中），[交叉验证](@entry_id:164650)是首选，因为它直接、非参数地估计了预测性能。
    -   当目标是**识别**最能解释数据的“真实”因果或结构模型时，BIC是更合适的选择，因为它倾向于选择更简洁的模型，并能在大样本下保证选出真实模型。
    -   AIC则是在预测和简洁性之间的一种权衡，它在实践中因其简单和与预测的紧密联系而被广泛使用。

因此，在医学等领域的应用中，选择何种策略取决于最终目标：是为了构建一个用于临床预测的“黑箱”工具（此时应优先考虑交叉验证），还是为了理解疾病的潜在机制（此时BIC可能更具优势）。