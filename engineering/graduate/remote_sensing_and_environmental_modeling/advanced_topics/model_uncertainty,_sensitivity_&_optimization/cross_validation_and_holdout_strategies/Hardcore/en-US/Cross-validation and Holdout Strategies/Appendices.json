{
    "hands_on_practices": [
        {
            "introduction": "A common practice in model evaluation is to report the mean performance metric from $K$-fold cross-validation. However, this single number provides no sense of the estimate's stability. This exercise guides you through the process of treating the results from each fold as a sample, allowing you to compute a confidence interval for the model's true performance metric, such as the Root Mean Squared Error (RMSE). By applying the Student's $t$-distribution, you will learn to quantify the uncertainty in your cross-validation estimate, a crucial step towards more rigorous and reliable model assessment .",
            "id": "3804427",
            "problem": "A remote sensing team is modeling Leaf Area Index (LAI) from multispectral satellite reflectance using a regression model that is evaluated by $K$-fold cross-validation. In each fold $k \\in \\{1,\\dots,K\\}$ the model is trained on the remaining $K-1$ folds and evaluated on the held-out fold $k$, producing a fold-specific Root Mean Squared Error (RMSE), denoted $e_{k}$. The RMSE on fold $k$ is defined by $e_{k} = \\sqrt{\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}} r_{k,i}^{2}}$, where $r_{k,i}$ is the prediction residual for test observation $i$ in fold $k$ and $n_{k}$ is the number of test observations in fold $k$. Assume that the fold-wise RMSE values $\\{e_{k}\\}_{k=1}^{K}$ are realizations from an unknown distribution with finite variance and that the folds are designed so that the $e_{k}$ are approximately independent and identically distributed.\n\nStarting from the definitions of the sample mean and sample variance for $\\{e_{k}\\}_{k=1}^{K}$, and using the fact that the Student’s $t$-distribution arises when the population variance is unknown and estimated from the sample, derive a $0.95$ confidence interval for the cross-validated mean RMSE. Explicitly show how the $t$-distribution with $K-1$ degrees of freedom enters the derivation and state the assumptions under which the interval is valid, with particular attention to the independence of folds in a spatially structured remote sensing context.\n\nThen, compute this interval for $K = 5$ with the following fold-wise RMSE values (LAI is dimensionless, so express your answer as decimal fractions with no unit): $e_{1} = 0.82$, $e_{2} = 0.79$, $e_{3} = 0.85$, $e_{4} = 0.88$, $e_{5} = 0.81$. Use the two-sided $t$-critical value $t_{0.975,4} = 2.776$. Round your final interval endpoints to four significant figures.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and internally consistent. It presents a standard statistical task within a realistic remote sensing context and provides all necessary data and definitions for a unique solution. Therefore, the problem is deemed valid. We proceed with the solution.\n\nThe objective is to derive and compute a $0.95$ confidence interval for the true mean cross-validated Root Mean Squared Error (RMSE), denoted $\\mu_e$, based on a sample of $K$ fold-wise RMSE values, $\\{e_k\\}_{k=1}^{K}$.\n\nFirst, we derive the general formula for the confidence interval. Let $\\{e_1, e_2, \\dots, e_K\\}$ be a sample of $K$ independent and identically distributed (i.i.d.) random variables representing the fold-wise RMSE values, drawn from a distribution with mean $\\mu_e$ and finite variance $\\sigma_e^2$.\n\nThe sample mean, $\\bar{e}$, is the point estimator for $\\mu_e$:\n$$\n\\bar{e} = \\frac{1}{K} \\sum_{k=1}^{K} e_k\n$$\nSince the population variance $\\sigma_e^2$ is unknown, we must estimate it from the sample. The unbiased estimator for the population variance is the sample variance, $s_e^2$:\n$$\ns_e^2 = \\frac{1}{K-1} \\sum_{k=1}^{K} (e_k - \\bar{e})^2\n$$\nThe sample standard deviation is $s_e = \\sqrt{s_e^2}$.\n\nThe standard error of the mean (SEM), which is the standard deviation of the sampling distribution of $\\bar{e}$, is estimated by $s_{\\bar{e}}$:\n$$\ns_{\\bar{e}} = \\frac{s_e}{\\sqrt{K}}\n$$\nWhen the population variance is unknown and estimated from a sample of size $K$ drawn from a normal distribution, the standardized test statistic\n$$\nT = \\frac{\\bar{e} - \\mu_e}{s_{\\bar{e}}} = \\frac{\\bar{e} - \\mu_e}{s_e / \\sqrt{K}}\n$$\nfollows a Student's $t$-distribution with $\\nu = K-1$ degrees of freedom. This is the key step where the $t$-distribution enters the derivation.\n\nTo construct a $1-\\alpha$ confidence interval, we find the critical values $\\pm t_{\\alpha/2, K-1}$ from the $t$-distribution that bound the central $1-\\alpha$ area of the distribution. The probability statement is:\n$$\nP\\left(-t_{\\alpha/2, K-1} \\le \\frac{\\bar{e} - \\mu_e}{s_e / \\sqrt{K}} \\le t_{\\alpha/2, K-1}\\right) = 1-\\alpha\n$$\nWe rearrange the inequalities to isolate the population mean $\\mu_e$:\n$$\n-t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}} \\le \\bar{e} - \\mu_e \\le t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}}\n$$\n$$\n-\\bar{e} - t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}} \\le -\\mu_e \\le -\\bar{e} + t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}}\n$$\nMultiplying by $-1$ reverses the inequalities:\n$$\n\\bar{e} - t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}} \\le \\mu_e \\le \\bar{e} + t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}}\n$$\nThus, the $1-\\alpha$ confidence interval for $\\mu_e$ is given by:\n$$\n\\left[ \\bar{e} - t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}}, \\quad \\bar{e} + t_{\\alpha/2, K-1} \\frac{s_e}{\\sqrt{K}} \\right]\n$$\nThis can be written compactly as $\\bar{e} \\pm t_{\\alpha/2, K-1} \\cdot s_{\\bar{e}}$.\n\nThe validity of this interval rests on several key assumptions:\n1.  **Normality**: The derivation assumes the population of fold-wise RMSEs, $\\{e_k\\}$, from which the sample is drawn is normally distributed. For a small sample size like $K=5$, this assumption is important. The $t$-distribution is known to be robust to moderate departures from normality, but strong skewness or heavy tails in the distribution of $e_k$ would compromise the accuracy of the confidence level. For larger $K$, the Central Limit Theorem would ensure that the sampling distribution of $\\bar{e}$ is approximately normal, even if the underlying distribution of $e_k$ is not.\n2.  **Independence**: The derivation assumes that the fold-wise errors $e_k$ are independent. In a remote sensing context involving spatially structured data, this assumption is often violated due to spatial autocorrelation. If data points are geographically close, their prediction residuals may be correlated. If the folds are created without regard to this spatial structure (e.g., simple random sampling of pixels), a test set for one fold may contain points that are spatially close to points in a training set for another fold, which can lead to overly optimistic (narrower) error estimates. The problem states that \"the folds are designed so that the $e_{k}$ are approximately independent,\" which implies a method like spatial blocking or buffered cross-validation was used. Such methods create folds from spatially contiguous blocks of data, ensuring that the training and testing sets in any given fold iteration are spatially separate, thereby reducing the dependency between folds and making the resulting $e_k$ values more independent.\n3.  **Identical Distribution**: The $e_k$ values are assumed to be identically distributed, meaning each fold is an equally representative sample of the overall data landscape. This is typically achieved through stratified sampling on the target variable (LAI) or on geographic strata to ensure that each fold has a similar distribution of environmental conditions.\n\nNow, we compute the $0.95$ confidence interval for the given data.\nThe number of folds is $K=5$. The fold-wise RMSE values are $\\{e_k\\} = \\{0.82, 0.79, 0.85, 0.88, 0.81\\}$.\n\n1.  Calculate the sample mean $\\bar{e}$:\n    $$\n    \\bar{e} = \\frac{1}{5} (0.82 + 0.79 + 0.85 + 0.88 + 0.81) = \\frac{4.15}{5} = 0.83\n    $$\n\n2.  Calculate the sample variance $s_e^2$:\n    $$\n    \\sum_{k=1}^{5} (e_k - \\bar{e})^2 = (0.82-0.83)^2 + (0.79-0.83)^2 + (0.85-0.83)^2 + (0.88-0.83)^2 + (0.81-0.83)^2\n    $$\n    $$\n    = (-0.01)^2 + (-0.04)^2 + (0.02)^2 + (0.05)^2 + (-0.02)^2\n    $$\n    $$\n    = 0.0001 + 0.0016 + 0.0004 + 0.0025 + 0.0004 = 0.0050\n    $$\n    $$\n    s_e^2 = \\frac{1}{K-1} \\sum_{k=1}^{K} (e_k - \\bar{e})^2 = \\frac{0.0050}{5-1} = \\frac{0.0050}{4} = 0.00125\n    $$\n\n3.  Calculate the sample standard deviation $s_e$:\n    $$\n    s_e = \\sqrt{0.00125}\n    $$\n\n4.  Calculate the estimated standard error of the mean $s_{\\bar{e}}$:\n    $$\n    s_{\\bar{e}} = \\frac{s_e}{\\sqrt{K}} = \\frac{\\sqrt{0.00125}}{\\sqrt{5}} = \\sqrt{\\frac{0.00125}{5}} = \\sqrt{0.00025}\n    $$\n    $$\n    s_{\\bar{e}} \\approx 0.015811388...\n    $$\n\n5.  Determine the critical value. For a $0.95$ confidence interval, $\\alpha = 0.05$, so we need the critical value for a two-tailed probability of $\\alpha/2 = 0.025$. The degrees of freedom are $\\nu = K-1 = 4$. The problem provides this value as $t_{0.975,4} = 2.776$.\n\n6.  Calculate the margin of error (ME):\n    $$\n    \\text{ME} = t_{\\alpha/2, K-1} \\cdot s_{\\bar{e}} = 2.776 \\times \\sqrt{0.00025} \\approx 2.776 \\times 0.015811388... \\approx 0.04389439\n    $$\n\n7.  Construct the confidence interval, $\\bar{e} \\pm \\text{ME}$:\n    *   Lower bound: $0.83 - 0.04389439 = 0.78610561$\n    *   Upper bound: $0.83 + 0.04389439 = 0.87389439$\n\nFinally, we round the interval endpoints to four significant figures as requested.\n*   Lower bound rounded: $0.7861$\n*   Upper bound rounded: $0.8739$\n\nThe $0.95$ confidence interval for the cross-validated mean RMSE is $[0.7861, 0.8739]$.",
            "answer": "$$\n\\boxed{[0.7861, 0.8739]}\n$$"
        },
        {
            "introduction": "When working with spatial data, such as satellite imagery or environmental sensor readings, the assumption of independent and identically distributed samples is often violated due to spatial autocorrelation. Naively applying standard cross-validation can lead to information leakage and overly optimistic performance estimates. This practice demonstrates how to design a robust spatial block cross-validation scheme by linking the block size directly to the intrinsic spatial structure of your data . You will derive a rule-of-thumb that uses the effective range of the empirical semivariogram to ensure that training and validation sets are approximately independent, bridging the gap between geostatistical analysis and machine learning best practices.",
            "id": "3804424",
            "problem": "A remote sensing team is modeling a spatially distributed environmental variable using a second-order stationary and isotropic Gaussian random field $Z(\\mathbf{s})$ on $\\mathbb{R}^{2}$ with semivariogram $\\gamma(h)$, covariance function $C(h)$, and correlation function $\\rho(h) = C(h)/C(0)$. Recall the identity $\\gamma(h) = C(0) - C(h)$ for all $h \\geq 0$. The team estimates the empirical semivariogram $\\hat{\\gamma}(h)$ with empirical sill $\\hat{C}(0)$ and defines the empirical effective range $\\hat{r}$ at a tolerance level $\\delta \\in (0,1)$ by the condition $\\hat{\\gamma}(\\hat{r}) = (1 - \\delta)\\,\\hat{C}(0)$.\n\nThey plan to use spatial block cross-validation for model assessment: the domain is tessellated into non-overlapping square blocks of side length $b$, and for each fold they choose one validation block and remove all training points within a buffer of width $b$ around that validation block. Under this design, the minimum Euclidean distance between any validation point and any retained training point is at least $b$. The team will call training and validation “approximately independent” if the maximum absolute correlation between any validation point and any retained training point is bounded by $\\delta$.\n\nUsing only the core definitions above and the monotonicity of the semivariogram for isotropic second-order stationary fields, derive a rule-of-thumb for the minimal block size $b^{\\star}$, expressed as a closed-form function of $\\hat{r}$ and $\\delta$, that guarantees the approximate independence criterion under the described buffered block holdout scheme. Your final answer must be a single analytic expression for $b^{\\star}$. No numerical rounding is required.",
            "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n-   The model is a second-order stationary and isotropic Gaussian random field $Z(\\mathbf{s})$ on $\\mathbb{R}^{2}$.\n-   Associated functions are the semivariogram $\\gamma(h)$, covariance function $C(h)$, and correlation function $\\rho(h) = C(h)/C(0)$.\n-   An identity is provided: $\\gamma(h) = C(0) - C(h)$ for all $h \\geq 0$.\n-   Empirical estimates are used: empirical semivariogram $\\hat{\\gamma}(h)$ and empirical sill $\\hat{C}(0)$.\n-   The empirical effective range $\\hat{r}$ is defined by the condition $\\hat{\\gamma}(\\hat{r}) = (1 - \\delta)\\,\\hat{C}(0)$ for a given tolerance $\\delta \\in (0,1)$.\n-   The model assessment method is spatial block cross-validation with non-overlapping square blocks of side length $b$.\n-   The holdout scheme involves removing all training points within a buffer of width $b$ around the validation block.\n-   A consequence of the holdout scheme is that the minimum Euclidean distance between any validation point and any retained training point is at least $b$.\n-   The criterion for \"approximate independence\" is that the maximum absolute correlation between any validation point and any retained training point is bounded by $\\delta$.\n-   The objective is to derive the minimal block size $b^{\\star}$ as a function of $\\hat{r}$ and $\\delta$ that guarantees this criterion.\n-   The derivation is constrained to using only the provided definitions and the monotonicity of the semivariogram for isotropic second-order stationary fields.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the established principles of geostatistics and spatial data analysis. All terms such as Gaussian random field, second-order stationarity, isotropy, semivariogram, covariance, and spatial block cross-validation are standard and well-defined in this context. The problem is well-posed, providing a clear objective and sufficient, consistent information to achieve it through logical deduction. The definitions are formal and objective. The problem does not violate any scientific laws, is not based on false premises, is formalizable, is complete, and is not trivial.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A solution will be provided.\n\n### Solution Derivation\n\nThe objective is to find the minimal block size $b^{\\star}$ that satisfies the \"approximate independence\" criterion. Let us formalize this criterion and connect it to the given definitions.\n\nThe approximate independence criterion states that the maximum absolute correlation between any validation point and any retained training point is at most $\\delta$. Let $\\mathbf{s}_v$ be the location of an arbitrary validation point and $\\mathbf{s}_t$ be the location of an arbitrary retained training point. The Euclidean distance between them is $h = \\|\\mathbf{s}_v - \\mathbf{s}_t\\|$. The correlation between the values of the random field at these two locations is given by the correlation function $\\rho(h)$. The criterion can be written as:\n$$\n\\max_{\\mathbf{s}_v, \\mathbf{s}_t} |\\rho(h)| \\le \\delta\n$$\nwhere the maximum is taken over all possible pairs of validation points $\\mathbf{s}_v$ and retained training points $\\mathbf{s}_t$.\n\nFrom the problem description, the buffered block holdout scheme ensures that the minimum distance between any such pair of points is $b$. That is, for any allowed pair $(\\mathbf{s}_v, \\mathbf{s}_t)$, their distance $h$ satisfies $h \\ge b$.\n\nFor a second-order stationary and isotropic random field, the semivariogram $\\gamma(h)$ is a non-decreasing function of the lag distance $h \\ge 0$. The relationship between the correlation function $\\rho(h)$ and the semivariogram $\\gamma(h)$ is derived from the given identity $\\gamma(h) = C(0) - C(h)$ and the definition $\\rho(h) = C(h)/C(0)$:\n$$\n\\rho(h) = \\frac{C(0) - \\gamma(h)}{C(0)} = 1 - \\frac{\\gamma(h)}{C(0)}\n$$\nSince $\\gamma(h)$ is a non-decreasing function of $h$, it follows that $\\rho(h)$ is a non-increasing function of $h$. For most standard semivariogram models, the sill $C(0)$ represents the maximum semivariance, so $\\gamma(h) \\le C(0)$, which implies $\\rho(h) \\ge 0$. In this case, $|\\rho(h)| = \\rho(h)$. The non-increasing nature of $\\rho(h)$ means that the maximum value of $\\rho(h)$ for all distances $h \\ge b$ will occur at the minimum possible distance, which is $h=b$.\n\nTherefore, the condition $\\max_{h \\ge b} |\\rho(h)| \\le \\delta$ simplifies to ensuring that the correlation at distance $b$ meets the bound:\n$$\n|\\rho(b)| \\le \\delta\n$$\nAssuming, as is standard, that $\\rho(h) \\ge 0$, this becomes:\n$$\n\\rho(b) \\le \\delta\n$$\nWe now substitute the expression for $\\rho(b)$ in terms of the semivariogram. The problem is posed in terms of empirical estimates, so we will use $\\hat{\\gamma}(h)$ and $\\hat{C}(0)$.\n$$\n1 - \\frac{\\hat{\\gamma}(b)}{\\hat{C}(0)} \\le \\delta\n$$\nRearranging this inequality to solve for a condition on $\\hat{\\gamma}(b)$:\n$$\n1 - \\delta \\le \\frac{\\hat{\\gamma}(b)}{\\hat{C}(0)}\n$$\n$$\n(1 - \\delta)\\hat{C}(0) \\le \\hat{\\gamma}(b)\n$$\nThis is the condition that the block size $b$ must satisfy to ensure approximate independence.\n\nThe problem provides the definition of the empirical effective range, $\\hat{r}$, as the distance at which the empirical semivariogram reaches a specific fraction of the sill:\n$$\n\\hat{\\gamma}(\\hat{r}) = (1 - \\delta)\\hat{C}(0)\n$$\nSubstituting this definition into our inequality gives:\n$$\n\\hat{\\gamma}(\\hat{r}) \\le \\hat{\\gamma}(b)\n$$\nThe problem explicitly allows the use of the monotonicity of the semivariogram. Since $\\hat{\\gamma}(h)$ is a non-decreasing function of $h$, the inequality $\\hat{\\gamma}(\\hat{r}) \\le \\hat{\\gamma}(b)$ directly implies a relationship between their arguments:\n$$\n\\hat{r} \\le b\n$$\nThis shows that to meet the approximate independence criterion, the block side length $b$ must be at least as large as the empirical effective range $\\hat{r}$ (defined at tolerance $\\delta$). The problem asks for the minimal block size, $b^{\\star}$, that guarantees the condition. This minimal value is:\n$$\nb^{\\star} = \\hat{r}\n$$\nThis result is a function of $\\hat{r}$, which itself is implicitly a function of $\\delta$ through its definition. It is the closed-form expression required.",
            "answer": "$$\n\\boxed{\\hat{r}}\n$$"
        },
        {
            "introduction": "A cardinal rule in modeling time-series data is to never use information from the future to predict the past. While this principle is intuitive, standard $K$-fold cross-validation can inadvertently violate it by placing future data points in the training set. This exercise challenges you to move beyond intuition by mathematically quantifying the amount of \"future leakage\" that occurs when using random cross-validation on an autocorrelated time series . By deriving a closed-form expression for this leakage risk, you will gain a deeper appreciation for why chronologically sound methods, such as rolling-origin evaluation, are non-negotiable for robust temporal model assessment.",
            "id": "3804475",
            "problem": "A hydrologist is building an environmental model to predict daily surface soil moisture from satellite-derived covariates at a single representative site. Let the target series $\\{y_{t}\\}_{t=1}^{N}$ denote soil moisture anomalies that are weakly stationary and well-approximated by a first-order autoregressive process (AR(1)), with zero mean and autocorrelation function $\\mathrm{corr}(y_{t},y_{t+h})=\\rho^{|h|}$ for $|\\rho|<1$. For daily aggregated anomalies in this setting, assume $\\rho \\in [0,1)$.\n\nThe model assessment protocol under consideration is random $K$-fold cross-validation (CV) with $K \\ge 2$ fixed, implemented by independently assigning each index $t \\in \\{1,\\dots,N\\}$ to a fold $F_{t} \\in \\{1,\\dots,K\\}$ with $\\mathbb{P}(F_{t}=k)=1/K$, independently across $t$. For any test index $t$, the training set consists of all indices $s \\neq t$ with $F_{s} \\neq F_{t}$. This scheme can induce temporal leakage because training data can include observations from times $s>t$ that are autocorrelated with $y_{t}$.\n\nDefine the leakage influence score for a single randomly chosen test index $t$ as\n$$\nL_{K}(\\rho)\\;=\\;\\mathbb{E}\\left[\\sum_{h=1}^{\\infty} \\left|\\mathrm{corr}(y_{t},y_{t+h})\\right| \\cdot \\mathbf{1}\\{t+h \\text{ is in the training set when } t \\text{ is test}\\}\\right],\n$$\nwhere the expectation is taken over the random fold assignments and over a uniformly chosen $t$ in the interior so that boundary effects are negligible as $N \\to \\infty$. Interpret $L_{K}(\\rho)$ as the expected magnitude of correlation-weighted future information admitted into the training set for the test point $t$.\n\nStarting only from the AR(1) definition of the autocorrelation function, the independence and equiprobability of fold assignments, and linearity of expectation, derive a closed-form analytic expression for $L_{K}(\\rho)$ as a function of $K$ and $\\rho$, valid for $0 \\le \\rho < 1$ and large $N$. Then, using first principles, explain why a rolling-origin evaluation (ROE) protocol that trains only on indices $s \\le t-1$ for test time $t$ yields zero leakage influence in this metric.\n\nProvide your final answer as the analytic expression for $L_{K}(\\rho)$ in closed form. No numerical evaluation is required. State no units. Do not provide inequalities or equations as the final answer; provide only the closed-form expression.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and self-contained. It presents a rigorous mathematical derivation task based on established principles of time series analysis and statistical model validation.\n\nThe primary task is to derive a closed-form expression for the leakage influence score, $L_{K}(\\rho)$, defined as:\n$$\nL_{K}(\\rho) \\;=\\; \\mathbb{E}\\left[\\sum_{h=1}^{\\infty} \\left|\\mathrm{corr}(y_{t},y_{t+h})\\right| \\cdot \\mathbf{1}\\{t+h \\text{ is in the training set when } t \\text{ is test}\\}\\right]\n$$\nThe expectation $\\mathbb{E}[\\cdot]$ is taken over the random assignment of data points to folds. The problem specifies that the time series $\\{y_{t}\\}$ is an autoregressive process of order one (AR($1$)) with autocorrelation function $\\mathrm{corr}(y_{t}, y_{t+h}) = \\rho^{|h|}$. The parameter $\\rho$ is restricted to the interval $[0, 1)$, and the summation is over future lags $h \\ge 1$. For these conditions, $\\left|\\mathrm{corr}(y_{t},y_{t+h})\\right| = |\\rho^h| = \\rho^h$.\n\nLet $I_{h}$ denote the indicator function $\\mathbf{1}\\{t+h \\text{ is in the training set when } t \\text{ is test}\\}$. The expression for $L_{K}(\\rho)$ becomes:\n$$\nL_{K}(\\rho) = \\mathbb{E}\\left[\\sum_{h=1}^{\\infty} \\rho^h \\cdot I_{h}\\right]\n$$\nSince all terms in the sum are non-negative, we can apply the Fubini-Tonelli theorem to interchange the expectation and the summation (linearity of expectation):\n$$\nL_{K}(\\rho) = \\sum_{h=1}^{\\infty} \\mathbb{E}\\left[\\rho^h \\cdot I_{h}\\right]\n$$\nThe term $\\rho^h$ is a constant with respect to the random fold assignments. Therefore, we can move it outside the expectation:\n$$\nL_{K}(\\rho) = \\sum_{h=1}^{\\infty} \\rho^h \\cdot \\mathbb{E}[I_{h}]\n$$\nThe expectation of an indicator function is the probability of the event it indicates. So, we need to calculate $\\mathbb{P}(t+h \\text{ is in the training set when } t \\text{ is test})$.\nThe validation protocol is random $K$-fold cross-validation. A point $s$ is in the training set for a test point $t$ if $s \\neq t$ and $s$ is not in the same fold as $t$. Let $F_t$ be the fold assignment for index $t$. The condition for $t+h$ (where $h \\ge 1$, so $t+h \\neq t$) to be in the training set is $F_{t+h} \\neq F_t$.\nThus, we need to compute the probability $\\mathbb{P}(F_{t+h} \\neq F_t)$. The fold assignments $F_t$ and $F_{t+h}$ are independent and identically distributed random variables, uniformly distributed on the set $\\{1, 2, \\dots, K\\}$.\nThe probability that two indices are in the same fold is:\n$$\n\\mathbb{P}(F_{t+h} = F_t) = \\sum_{k=1}^{K} \\mathbb{P}(F_{t+h} = k \\text{ and } F_t = k)\n$$\nDue to independence of assignments:\n$$\n\\mathbb{P}(F_{t+h} = F_t) = \\sum_{k=1}^{K} \\mathbb{P}(F_{t+h} = k) \\cdot \\mathbb{P}(F_t = k)\n$$\nGiven the equiprobable assignment, $\\mathbb{P}(F_t = k) = 1/K$ for any $t$ and $k$.\n$$\n\\mathbb{P}(F_{t+h} = F_t) = \\sum_{k=1}^{K} \\left(\\frac{1}{K}\\right) \\cdot \\left(\\frac{1}{K}\\right) = \\sum_{k=1}^{K} \\frac{1}{K^2} = K \\cdot \\frac{1}{K^2} = \\frac{1}{K}\n$$\nThe probability of the complementary event, that the indices are in different folds, is:\n$$\n\\mathbb{P}(F_{t+h} \\neq F_t) = 1 - \\mathbb{P}(F_{t+h} = F_t) = 1 - \\frac{1}{K} = \\frac{K-1}{K}\n$$\nThis probability is the value of $\\mathbb{E}[I_{h}]$, and it is constant for all $h \\ge 1$. Substituting this back into the expression for $L_{K}(\\rho)$:\n$$\nL_{K}(\\rho) = \\sum_{h=1}^{\\infty} \\rho^h \\cdot \\left(\\frac{K-1}{K}\\right)\n$$\nWe can factor out the constant term:\n$$\nL_{K}(\\rho) = \\left(\\frac{K-1}{K}\\right) \\sum_{h=1}^{\\infty} \\rho^h\n$$\nThe remaining sum is a standard geometric series. For $|\\rho| < 1$, the sum is known to be:\n$$\n\\sum_{h=1}^{\\infty} \\rho^h = \\frac{\\rho}{1-\\rho}\n$$\nSubstituting this result yields the final closed-form expression for the leakage influence score:\n$$\nL_{K}(\\rho) = \\frac{K-1}{K} \\frac{\\rho}{1-\\rho}\n$$\n\nThe second part of the problem asks to explain why a rolling-origin evaluation (ROE) protocol results in zero leakage influence. In an ROE protocol, for a given test time $t$, the training set is defined to consist only of observations at indices $s \\le t-1$.\nThe leakage influence score $L(\\rho)$ is defined to measure the impact of *future* information, specifically summing contributions from times $t+h$ where $h \\in \\{1, 2, 3, \\dots\\}$. The indicator function in the definition of $L(\\rho)$ becomes $\\mathbf{1}\\{t+h \\text{ is in the ROE training set}\\}$. According to the ROE rule, this requires the observation time $t+h$ to satisfy the condition $t+h \\le t-1$. This inequality simplifies to $h \\le -1$. However, the sum in the definition of $L(\\rho)$ is over strictly positive integers $h \\ge 1$. The condition $h \\le -1$ can never be satisfied for any $h \\ge 1$.\nTherefore, the indicator function $\\mathbf{1}\\{t+h \\text{ is in the ROE training set}\\}$ is identically zero for all terms in the summation. The sum becomes $\\sum_{h=1}^{\\infty} \\rho^h \\cdot 0 = 0$. The expectation of $0$ is $0$, so the leakage influence score for the ROE protocol is $L_{ROE}(\\rho) = 0$. This confirms that the ROE protocol, by its construction of using only past data for training, completely avoids the type of future information leakage captured by the $L_K(\\rho)$ metric.",
            "answer": "$$\n\\boxed{\\frac{K-1}{K} \\frac{\\rho}{1-\\rho}}\n$$"
        }
    ]
}