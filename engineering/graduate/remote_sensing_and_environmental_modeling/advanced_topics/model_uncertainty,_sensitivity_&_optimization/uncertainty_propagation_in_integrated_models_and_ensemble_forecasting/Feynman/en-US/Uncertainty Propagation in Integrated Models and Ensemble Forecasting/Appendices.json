{
    "hands_on_practices": [
        {
            "introduction": "This exercise provides foundational practice in propagating uncertainty through a model using analytical methods. You will apply the first-order Taylor series expansion, also known as the Law of Propagation of Uncertainty, to a simplified remote sensing model. This practice is crucial for understanding how uncertainties in model parameters, especially when they are correlated, combine to determine the uncertainty of a derived scientific product like surface albedo .",
            "id": "3863122",
            "problem": "Consider a parameterized bidirectional reflectance distribution function (BRDF) for a homogeneous land surface, modeled at a single spectral band as $r(\\theta_{s}, \\theta_{v}, \\phi) = a + b \\cos(\\theta_{v}) + c \\cos(\\theta_{s})$, where $r$ is the bidirectional reflectance factor, $\\theta_{s}$ is the solar zenith angle, $\\theta_{v}$ is the view zenith angle, and $\\phi$ is the relative azimuth angle. The directional-hemispherical reflectance (black-sky albedo) at solar zenith $\\theta_{s}$ is defined by the hemispherical integral $A(\\theta_{s}) = \\int_{\\Omega_{v}} r(\\theta_{s}, \\theta_{v}, \\phi) \\cos(\\theta_{v}) \\, \\mathrm{d}\\Omega_{v}$ over the viewing hemisphere, where $\\mathrm{d}\\Omega_{v} = \\sin(\\theta_{v}) \\, \\mathrm{d}\\theta_{v} \\, \\mathrm{d}\\phi$ and the integration domain is $\\theta_{v} \\in [0, \\pi/2]$, $\\phi \\in [0, 2\\pi]$. A remote sensing inversion has produced parameter estimates $a$, $b$, $c$ with joint uncertainty characterized by the covariance matrix $\\Sigma$:\n$$\n\\Sigma = \\begin{pmatrix}\n0.0004 & 0.0001 & -0.00005 \\\\\n0.0001 & 0.0009 & 0.00002 \\\\\n-0.00005 & 0.00002 & 0.00025\n\\end{pmatrix},\n$$\nand mean parameter values $a = 0.12$, $b = 0.08$, $c = 0.05$. The observed solar zenith angle is $\\theta_{s} = 0.7$ and its measurement uncertainty is characterized by a standard deviation $\\sigma_{\\theta} = 0.02$. Assume that the parameter uncertainties and the solar zenith angle uncertainty are statistically independent and that the law of propagation of uncertainty via first-order linearization (Taylor series) around the observed angle applies. Using these data and assumptions, compute the standard uncertainty (one standard deviation) of the black-sky albedo $A(\\theta_{s})$ at the observed solar zenith angle. All angles are in radians, and you may treat $\\pi$ as the circle constant. Express the final uncertainty as a decimal fraction with no unit and round your answer to four significant figures.",
            "solution": "The problem requires the computation of the standard uncertainty of the black-sky albedo, $A(\\theta_{s})$, based on the uncertainties of its input variables. The albedo is a function of the bidirectional reflectance distribution function (BRDF) parameters $a$, $b$, $c$ and the solar zenith angle $\\theta_{s}$. The uncertainty in $A$ will be determined using the law of propagation of uncertainty, which is justified by the problem's statement to use a first-order Taylor series linearization.\n\nFirst, we must derive the analytical expression for the black-sky albedo, $A(\\theta_{s})$. It is defined as the directional-hemispherical reflectance, given by the integral of the BRDF over the viewing hemisphere:\n$$ A(\\theta_{s}) = \\int_{\\Omega_{v}} r(\\theta_{s}, \\theta_{v}, \\phi) \\cos(\\theta_{v}) \\, \\mathrm{d}\\Omega_{v} $$\nThe differential solid angle for the viewing direction is $\\mathrm{d}\\Omega_{v} = \\sin(\\theta_{v}) \\, \\mathrm{d}\\theta_{v} \\, \\mathrm{d}\\phi$, with integration limits for the hemisphere being $\\theta_{v} \\in [0, \\pi/2]$ and $\\phi \\in [0, 2\\pi]$. The given BRDF model is $r(\\theta_{s}, \\theta_{v}, \\phi) = a + b \\cos(\\theta_{v}) + c \\cos(\\theta_{s})$.\n\nWe substitute the BRDF model into the integral for $A(\\theta_s)$:\n$$ A(\\theta_{s}) = \\int_{0}^{2\\pi} \\int_{0}^{\\pi/2} (a + b \\cos(\\theta_{v}) + c \\cos(\\theta_{s})) \\cos(\\theta_{v}) \\sin(\\theta_{v}) \\, \\mathrm{d}\\theta_{v} \\, \\mathrm{d}\\phi $$\nThe integrand does not depend on the relative azimuth angle $\\phi$, so the integration over $\\phi$ from $0$ to $2\\pi$ introduces a factor of $2\\pi$:\n$$ A(\\theta_{s}) = 2\\pi \\int_{0}^{\\pi/2} (a \\cos(\\theta_{v}) \\sin(\\theta_{v}) + b \\cos^2(\\theta_{v}) \\sin(\\theta_{v}) + c \\cos(\\theta_{s}) \\cos(\\theta_{v}) \\sin(\\theta_{v})) \\, \\mathrm{d}\\theta_{v} $$\nTo evaluate the integral over $\\theta_v$, we perform a substitution with $u = \\cos(\\theta_v)$, which implies $\\mathrm{d}u = -\\sin(\\theta_v) \\mathrm{d}\\theta_v$. The integration limits transform accordingly: when $\\theta_v=0$, $u=1$, and when $\\theta_v=\\pi/2$, $u=0$.\n$$ A(\\theta_{s}) = 2\\pi \\int_{1}^{0} (a u + b u^2 + c u \\cos(\\theta_{s})) (-\\mathrm{d}u) = 2\\pi \\int_{0}^{1} (a u + b u^2 + c u \\cos(\\theta_{s})) \\, \\mathrm{d}u $$\nPerforming the polynomial integration yields:\n$$ A(\\theta_{s}) = 2\\pi \\left[ \\frac{a u^2}{2} + \\frac{b u^3}{3} + \\frac{c u^2}{2} \\cos(\\theta_{s}) \\right]_{0}^{1} $$\n$$ A(\\theta_{s}) = 2\\pi \\left( \\frac{a}{2} + \\frac{b}{3} + \\frac{c}{2} \\cos(\\theta_{s}) \\right) $$\nThis simplifies to the final analytical expression for the albedo:\n$$ A(a,b,c,\\theta_s) = \\pi a + \\frac{2\\pi}{3} b + \\pi c \\cos(\\theta_{s}) $$\n\nThe problem states that the uncertainties in the parameters $(a,b,c)$ and the uncertainty in the angle $\\theta_s$ are statistically independent. Therefore, the total variance of $A$, denoted $\\sigma_A^2$, is the sum of the variances contributed by these independent sources:\n$$ \\sigma_A^2 = \\sigma_{A, \\text{params}}^2 + \\sigma_{A, \\theta_s}^2 $$\nThe first term, $\\sigma_{A, \\text{params}}^2$, arises from the parameter uncertainties and is calculated as $J \\Sigma J^T$, where $J$ is the Jacobian row vector of the partial derivatives of $A$ with respect to the parameters $(a,b,c)$, and $\\Sigma$ is their given covariance matrix. The second term, $\\sigma_{A, \\theta_s}^2$, arises from the angle uncertainty and is calculated as $(\\frac{\\partial A}{\\partial \\theta_s})^2 \\sigma_{\\theta}^2$, where $\\sigma_{\\theta}$ is the standard deviation of $\\theta_s$.\n\nWe compute the necessary partial derivatives of $A(a,b,c,\\theta_s)$:\n$$ \\frac{\\partial A}{\\partial a} = \\pi $$\n$$ \\frac{\\partial A}{\\partial b} = \\frac{2\\pi}{3} $$\n$$ \\frac{\\partial A}{\\partial c} = \\pi \\cos(\\theta_{s}) $$\n$$ \\frac{\\partial A}{\\partial \\theta_{s}} = -\\pi c \\sin(\\theta_{s}) $$\n\nThe variance from the parameters is:\n$$ \\sigma_{A, \\text{params}}^2 = \\begin{pmatrix} \\frac{\\partial A}{\\partial a} & \\frac{\\partial A}{\\partial b} & \\frac{\\partial A}{\\partial c} \\end{pmatrix} \\Sigma \\begin{pmatrix} \\frac{\\partial A}{\\partial a} \\\\ \\frac{\\partial A}{\\partial b} \\\\ \\frac{\\partial A}{\\partial c} \\end{pmatrix} $$\nWe evaluate the derivatives at the given value $\\theta_s = 0.7$ radians. The variance expression can be expanded as:\n$$ \\sigma_{A, \\text{params}}^2 = \\left(\\frac{\\partial A}{\\partial a}\\right)^2 \\Sigma_{aa} + \\left(\\frac{\\partial A}{\\partial b}\\right)^2 \\Sigma_{bb} + \\left(\\frac{\\partial A}{\\partial c}\\right)^2 \\Sigma_{cc} + 2\\frac{\\partial A}{\\partial a}\\frac{\\partial A}{\\partial b}\\Sigma_{ab} + 2\\frac{\\partial A}{\\partial a}\\frac{\\partial A}{\\partial c}\\Sigma_{ac} + 2\\frac{\\partial A}{\\partial b}\\frac{\\partial A}{\\partial c}\\Sigma_{bc} $$\nSubstituting the derivatives and the components of $\\Sigma = \\begin{pmatrix} 0.0004 & 0.0001 & -0.00005 \\\\ 0.0001 & 0.0009 & 0.00002 \\\\ -0.00005 & 0.00002 & 0.00025 \\end{pmatrix}$:\n$$ \\sigma_{A, \\text{params}}^2 = \\pi^2 (0.0004) + \\left(\\frac{2\\pi}{3}\\right)^2 (0.0009) + (\\pi\\cos(0.7))^2 (0.00025) + 2(\\pi)\\left(\\frac{2\\pi}{3}\\right)(0.0001) + 2(\\pi)(\\pi\\cos(0.7))(-0.00005) + 2\\left(\\frac{2\\pi}{3}\\right)(\\pi\\cos(0.7))(0.00002) $$\n$$ \\sigma_{A, \\text{params}}^2 = \\pi^2 \\left[ 0.0004 + \\frac{4}{9}(0.0009) + \\cos^2(0.7)(0.00025) + \\frac{4}{3}(0.0001) - 2\\cos(0.7)(0.00005) + \\frac{4}{3}\\cos(0.7)(0.00002) \\right] $$\nUsing $\\theta_s = 0.7$, we find $\\cos(0.7) \\approx 0.764842$:\n$$ \\sigma_{A, \\text{params}}^2 \\approx \\pi^2 [ 0.0004 + 0.0004 + (0.58498)(0.00025) + 0.00013333 - (1.52968)(0.00005) + (1.01979)(0.00002) ] $$\n$$ \\sigma_{A, \\text{params}}^2 \\approx \\pi^2 [ 0.0008 + 0.00014625 + 0.00013333 - 0.00007648 + 0.00002040 ] $$\n$$ \\sigma_{A, \\text{params}}^2 \\approx \\pi^2 [ 0.0010235 ] \\approx 0.0100998 $$\n\nThe variance from the angle uncertainty, with $c=0.05$ and $\\sigma_{\\theta}=0.02$, is:\n$$ \\sigma_{A, \\theta_s}^2 = \\left( \\frac{\\partial A}{\\partial \\theta_s} \\right)^2 \\sigma_{\\theta}^2 = (-\\pi c \\sin(\\theta_s))^2 \\sigma_{\\theta}^2 = \\pi^2 c^2 \\sin^2(\\theta_s) \\sigma_{\\theta}^2 $$\nUsing $\\sin(0.7) \\approx 0.644218$:\n$$ \\sigma_{A, \\theta_s}^2 = \\pi^2 (0.05)^2 \\sin^2(0.7) (0.02)^2 \\approx \\pi^2 (0.0025) (0.644218)^2 (0.0004) $$\n$$ \\sigma_{A, \\theta_s}^2 \\approx \\pi^2 (0.0025) (0.415015) (0.0004) \\approx (9.8696) (4.15015 \\times 10^{-7}) \\approx 0.000004096 $$\n\nThe total variance is the sum of these two components:\n$$ \\sigma_A^2 = \\sigma_{A, \\text{params}}^2 + \\sigma_{A, \\theta_s}^2 \\approx 0.0100998 + 0.000004096 = 0.0101039 $$\nThe standard uncertainty, $\\sigma_A$, is the square root of the total variance:\n$$ \\sigma_A = \\sqrt{\\sigma_A^2} \\approx \\sqrt{0.0101039} \\approx 0.100518 $$\nRounding the result to four significant figures as requested gives $0.1005$.",
            "answer": "$$\\boxed{0.1005}$$"
        },
        {
            "introduction": "While analytical methods are powerful, most complex environmental models are non-linear, making direct analytical propagation of uncertainty intractable. This practice introduces the Monte Carlo method, a versatile and robust numerical technique for uncertainty quantification. You will implement a simulation to propagate uncertainties from several stochastic inputs through a hydrological model and learn how to determine the necessary sample size to achieve a desired level of precision in your results .",
            "id": "3863156",
            "problem": "A hydrological response model is used to map uncertain environmental inputs to a daily mean streamflow prediction. The catchment-integrated daily precipitation is modeled as a lognormal random variable, the daily evapotranspiration is modeled as a truncated normal random variable, the runoff coefficient be $C$, which is dimensionless, and the residence time of a linear reservoir routing scheme is modeled as a lognormal random variable. The mapping from inputs to daily mean discharge is defined as follows. Let daily precipitation be $P$ in $\\mathrm{mm/day}$, daily evapotranspiration be $E$ in $\\mathrm{mm/day}$, runoff coefficient be $C$, and residence time be $k$ in $\\mathrm{days}$. Let the catchment area be $A$ in $\\mathrm{km}^2$. The daily rainfall excess in $\\mathrm{mm/day}$ is $R = C \\max(P - E, 0)$. The daily inflow volume in $\\mathrm{m}^3/\\mathrm{day}$ is $V_{\\mathrm{in}} = A \\times 10^6 \\times R \\times 10^{-3}$. A linear-reservoir routing over a $\\Delta t = 1$ day interval releases a fraction $r = 1 - \\exp(-1/k)$ of the inflow volume during that interval. The daily mean discharge in $\\mathrm{m}^3/\\mathrm{s}$ is the outflow volume divided by the number of seconds per day, i.e., $Q = (V_{\\mathrm{in}} \\, r)/86400$.\n\nThe probability models for the inputs are:\n- Precipitation $P$ is lognormal with mean $\\mu_P$ and coefficient of variation $\\mathrm{cv}_P$. That is, if $Z_P \\sim \\mathcal{N}(\\mu_{\\ln P}, \\sigma_{\\ln P}^2)$ then $P = \\exp(Z_P)$, where $\\sigma_{\\ln P}^2 = \\ln(1 + \\mathrm{cv}_P^2)$ and $\\mu_{\\ln P} = \\ln(\\mu_P) - \\tfrac{1}{2} \\sigma_{\\ln P}^2$.\n- Evapotranspiration $E$ is normal with mean $\\mu_E$ and standard deviation $\\sigma_E$, truncated below at $0$, i.e., $E \\sim \\mathcal{N}(\\mu_E, \\sigma_E^2)$ conditioned on $E \\ge 0$.\n- Runoff coefficient $C$ is beta distributed $C \\sim \\mathrm{Beta}(a_C, b_C)$ on $(0,1)$.\n- Residence time $k$ is lognormal with mean $\\mu_k$ and coefficient of variation $\\mathrm{cv}_k$ in days. If $Z_k \\sim \\mathcal{N}(\\mu_{\\ln k}, \\sigma_{\\ln k}^2)$ then $k = \\exp(Z_k)$, where $\\sigma_{\\ln k}^2 = \\ln(1 + \\mathrm{cv}_k^2)$ and $\\mu_{\\ln k} = \\ln(\\mu_k) - \\tfrac{1}{2} \\sigma_{\\ln k}^2$.\n\nUsing Monte Carlo simulation, propagate the input uncertainties through the mapping above to estimate the expected daily mean discharge $\\mathbb{E}[Q]$ and ensemble forecast quantiles at probabilities $p \\in \\{0.1, 0.5, 0.9\\}$. You must also determine the minimal Monte Carlo sample size $N$ required so that the Monte Carlo standard error of the sample mean estimator of $\\mathbb{E}[Q]$ is no greater than a given absolute tolerance $\\varepsilon$ in $\\mathrm{m}^3/\\mathrm{s}$. The determination of $N$ must be based on a pilot simulation of size $N_0$.\n\nBase your derivation on the following fundamental facts:\n- Independence and identical distribution of Monte Carlo samples.\n- The Law of Large Numbers and the variance of the sample mean of independent and identically distributed random variables.\n- Transformation rules for the lognormal distribution given a mean and a coefficient of variation.\n\nThe algorithmic constraints are:\n- Use a pilot run of size $N_0$ to estimate the variance of $Q$ and then compute the minimal $N$ such that the Monte Carlo standard error of the sample mean is at most $\\varepsilon$. Use the minimal integer $N \\ge 1$ that satisfies the derived inequality.\n- Use random seeds $s_{\\mathrm{pilot}} = 2025$ for the pilot simulation and $s_{\\mathrm{final}} = 2026$ for the final simulation that estimates the mean and quantiles.\n- Evapotranspiration must be sampled from a normal distribution truncated below at $0$.\n- All discharge values must be expressed in $\\mathrm{m}^3/\\mathrm{s}$ and rounded to six decimal places in the final output. The sample size must be an integer.\n\nTest Suite:\nProvide results for each of the following parameter sets. Each set is specified as $(A, \\mu_P, \\mathrm{cv}_P, \\mu_E, \\sigma_E, a_C, b_C, \\mu_k, \\mathrm{cv}_k, \\varepsilon, N_0)$ with units as defined above.\n\n- Case $1$: $(500, 20, 0.5, 4, 1.5, 2, 5, 2, 0.3, 0.2, 2000)$.\n- Case $2$: $(50, 3, 1.0, 2.5, 0.8, 3, 7, 1, 0.5, 0.02, 4000)$.\n- Case $3$: $(2000, 50, 1.5, 5, 2, 1.5, 1.5, 3, 0.8, 2.0, 3000)$.\n- Case $4$: $(500, 20, 0.5, 4, 1.5, 2, 5, 2, 0.3, 0.05, 2000)$.\n- Case $5$: $(10000, 15, 0.6, 3, 1.2, 2.5, 4, 0.5, 0.4, 5.0, 2500)$.\n\nYour program should:\n- For each case, perform a pilot simulation of size $N_0$ using seed $s_{\\mathrm{pilot}}$, estimate the variance of $Q$, compute the minimal $N$ that meets the target Monte Carlo standard error $\\varepsilon$, then perform a final simulation of size $N$ using seed $s_{\\mathrm{final}}$ to estimate the sample mean and the $0.1$, $0.5$, and $0.9$ quantiles.\n- Produce a single line of output containing a comma-separated list enclosed in square brackets, where each element corresponds to one case and is itself a list of five values $[\\hat{\\mu}_Q, \\hat{q}_{0.1}, \\hat{q}_{0.5}, \\hat{q}_{0.9}, N]$. The first four values must be floats rounded to six decimal places in $\\mathrm{m}^3/\\mathrm{s}$, and the last value must be the integer $N$. For example, an output with two cases should look like $[[1.234567,0.123456,0.234567,0.345678,1234],[...]]$.",
            "solution": "The problem requires performing uncertainty propagation for a hydrological model using a two-stage Monte Carlo simulation. The first stage is a pilot simulation to determine the necessary sample size for the main simulation. The second stage uses this sample size to produce estimates of the expected value and quantiles of the output variable, daily mean discharge $Q$.\n\n### **Theoretical Framework**\n\n#### **Model Definition**\nThe model maps four stochastic inputs—precipitation $P$, evapotranspiration $E$, runoff coefficient $C$, and residence time $k$—to the output discharge $Q$, given a fixed catchment area $A$. The mapping is defined by the following sequence of equations:\n1.  Daily rainfall excess, $R$ [$\\mathrm{mm/day}$]: $R = C \\cdot \\max(P - E, 0)$\n2.  Daily inflow volume, $V_{\\mathrm{in}}$ [$\\mathrm{m}^3/\\mathrm{day}$]: The conversion from catchment area in $\\mathrm{km}^2$ and rainfall excess in $\\mathrm{mm/day}$ to volume in $\\mathrm{m}^3/\\mathrm{day}$ is $V_{\\mathrm{in}} = A \\,[\\mathrm{km}^2] \\cdot (10^6 \\, \\mathrm{m}^2/\\mathrm{km}^2) \\cdot R \\,[\\mathrm{mm/day}] \\cdot (10^{-3} \\, \\mathrm{m/mm}) = 1000 \\cdot A \\cdot R$.\n3.  Release fraction, $r$ [dimensionless]: For a linear reservoir with a time step of $\\Delta t = 1$ day, the fraction of inflow volume released is $r = 1 - \\exp(-\\Delta t/k) = 1 - \\exp(-1/k)$.\n4.  Daily mean discharge, $Q$ [$\\mathrm{m}^3/\\mathrm{s}$]: The daily outflow volume is $V_{\\mathrm{out}} = V_{\\mathrm{in}} \\cdot r$. Converting this to a mean rate over one day (which has $86400$ seconds) gives $Q = V_{\\mathrm{out}} / 86400 = (1000 \\cdot A \\cdot R \\cdot r) / 86400$.\n\n#### **Input Probability Models**\nThe inputs are modeled as independent random variables with the following distributions:\n-   $P \\sim \\text{Lognormal}(\\mu_P, \\mathrm{cv}_P)$: If $P = \\exp(Z_P)$ with $Z_P \\sim \\mathcal{N}(\\mu_{\\ln P}, \\sigma_{\\ln P}^2)$, the parameters are derived from the mean $\\mu_P$ and coefficient of variation $\\mathrm{cv}_P$ as $\\sigma_{\\ln P}^2 = \\ln(1 + \\mathrm{cv}_P^2)$ and $\\mu_{\\ln P} = \\ln(\\mu_P) - \\frac{1}{2}\\sigma_{\\ln P}^2$.\n-   $E \\sim \\text{TruncatedNormal}(\\mu_E, \\sigma_E^2, E \\ge 0)$: A normal distribution with mean $\\mu_E$ and variance $\\sigma_E^2$, conditioned on being non-negative.\n-   $C \\sim \\mathrm{Beta}(a_C, b_C)$: A beta distribution on the interval $(0, 1)$.\n-   $k \\sim \\text{Lognormal}(\\mu_k, \\mathrm{cv}_k)$: The parameters $\\mu_{\\ln k}$ and $\\sigma_{\\ln k}^2$ for the underlying normal distribution are found similarly to those for $P$.\n\n#### **Sample Size Determination**\nThe standard error of the Monte Carlo estimator for $\\mathbb{E}[Q]$ (the sample mean $\\hat{\\mu}_Q$) is given by $\\mathrm{SE}(\\hat{\\mu}_Q) = \\sigma_Q / \\sqrt{N}$, where $\\sigma_Q = \\sqrt{\\mathrm{Var}(Q)}$ is the true standard deviation of the discharge and $N$ is the sample size. To ensure the standard error does not exceed a tolerance $\\varepsilon$, we must have $\\sigma_Q / \\sqrt{N} \\le \\varepsilon$. This implies the required sample size is $N \\ge \\sigma_Q^2 / \\varepsilon^2$.\n\nSince $\\sigma_Q^2$ is unknown, we estimate it with the sample variance $\\hat{\\sigma}_{Q, N_0}^2$ from a pilot simulation of size $N_0$:\n$$ \\hat{\\sigma}_{Q, N_0}^2 = \\frac{1}{N_0-1} \\sum_{i=1}^{N_0} (Q_i - \\bar{Q}_{N_0})^2 $$\nThe required sample size $N$ is then the smallest integer greater than or equal to $1$ that satisfies the condition:\n$$ N \\ge \\frac{\\hat{\\sigma}_{Q, N_0}^2}{\\varepsilon^2} \\implies N = \\max\\left(1, \\left\\lceil \\frac{\\hat{\\sigma}_{Q, N_0}^2}{\\varepsilon^2} \\right\\rceil\\right) $$\n\n### **Algorithmic Implementation**\nFor each test case, the following procedure is executed:\n\n1.  **Pilot Simulation**:\n    *   A random number generator is initialized with seed $s_{\\mathrm{pilot}} = 2025$.\n    *   $N_0$ samples of each input variable ($P, E, C, k$) are generated according to their specified distributions. For the truncated normal distribution, `scipy.stats.truncnorm` is used. For the lognormal and beta distributions, `numpy.random.Generator` methods are used.\n    *   The model equations are applied to each of the $N_0$ input sets to produce an ensemble of $N_0$ discharge values, $\\{Q_i\\}_{i=1}^{N_0}$.\n    *   The sample variance $\\hat{\\sigma}_{Q, N_0}^2$ is calculated from this ensemble using a delta degree of freedom of $1$ for an unbiased estimate.\n\n2.  **Sample Size Calculation**:\n    *   The minimum required sample size $N$ for the final simulation is calculated using the formula derived above.\n\n3.  **Final Simulation**:\n    *   The random number generator is re-initialized with seed $s_{\\mathrm{final}} = 2026$ to ensure an independent sample set.\n    *   A new ensemble of $N$ discharge values is generated following the same procedure as the pilot run but with the computed sample size $N$.\n\n4.  **Result Computation**:\n    *   The sample mean $\\hat{\\mu}_Q$ is computed from the final ensemble of $N$ discharge values.\n    *   The sample quantiles at probabilities $p=0.1$, $p=0.5$, and $p=0.9$ (denoted $\\hat{q}_{0.1}, \\hat{q}_{0.5}, \\hat{q}_{0.9}$) are also computed from this final ensemble.\n    *   The calculated mean and quantiles are rounded to six decimal places. The final result for the case is compiled into a list: $[\\hat{\\mu}_Q, \\hat{q}_{0.1}, \\hat{q}_{0.5}, \\hat{q}_{0.9}, N]$.\n\nThe process is repeated for all test cases, and the results are aggregated into a single list of lists for the final output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import truncnorm\n\ndef run_model_simulation(params, N, seed):\n    \"\"\"\n    Runs the hydrological model simulation for N samples.\n    \n    Args:\n        params (tuple): A tuple of model parameters \n                        (A, mu_P, cv_P, mu_E, sigma_E, a_C, b_C, mu_k, cv_k).\n        N (int): The number of Monte Carlo samples to generate.\n        seed (int): The seed for the random number generator.\n    \n    Returns:\n        np.ndarray: An array of N discharge (Q) samples.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    A, mu_P, cv_P, mu_E, sigma_E, a_C, b_C, mu_k, cv_k = params\n\n    # 1. Sample Precipitation (P) - Lognormal\n    if mu_P > 0:\n        sigma_lnP_sq = np.log(1 + cv_P**2)\n        mu_lnP = np.log(mu_P) - 0.5 * sigma_lnP_sq\n        P = rng.lognormal(mean=mu_lnP, sigma=np.sqrt(sigma_lnP_sq), size=N)\n    else:\n        P = np.zeros(N)\n\n    # 2. Sample Evapotranspiration (E) - Truncated Normal\n    if sigma_E > 0:\n        a_trunc = (0 - mu_E) / sigma_E\n        E = truncnorm.rvs(a=a_trunc, b=np.inf, loc=mu_E, scale=sigma_E, size=N, random_state=rng)\n    else:\n        E = np.full(N, max(0, mu_E))\n\n    # 3. Sample Runoff Coefficient (C) - Beta\n    C = rng.beta(a_C, b_C, size=N)\n    \n    # 4. Sample Residence Time (k) - Lognormal\n    if mu_k > 0:\n        sigma_lnk_sq = np.log(1 + cv_k**2)\n        mu_lnk = np.log(mu_k) - 0.5 * sigma_lnk_sq\n        k = rng.lognormal(mean=mu_lnk, sigma=np.sqrt(sigma_lnk_sq), size=N)\n    else:\n        k = np.zeros(N)\n\n    # 5. Calculate Discharge (Q)\n    # Daily rainfall excess in mm/day\n    R = C * np.maximum(P - E, 0)\n    \n    # Daily inflow volume in m^3/day\n    V_in = 1000.0 * A * R\n    \n    # Release fraction (dimensionless)\n    # Add a small epsilon to k to avoid division by zero if k can be 0.\n    r = 1.0 - np.exp(-1.0 / (k + 1e-9))\n    \n    # Daily mean discharge in m^3/s\n    Q = (V_in * r) / 86400.0\n    \n    return Q\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # (A, mu_P, cv_P, mu_E, sigma_E, a_C, b_C, mu_k, cv_k, epsilon, N0)\n        (500.0, 20.0, 0.5, 4.0, 1.5, 2.0, 5.0, 2.0, 0.3, 0.2, 2000),\n        (50.0, 3.0, 1.0, 2.5, 0.8, 3.0, 7.0, 1.0, 0.5, 0.02, 4000),\n        (2000.0, 50.0, 1.5, 5.0, 2.0, 1.5, 1.5, 3.0, 0.8, 2.0, 3000),\n        (500.0, 20.0, 0.5, 4.0, 1.5, 2.0, 5.0, 2.0, 0.3, 0.05, 2000),\n        (10000.0, 15.0, 0.6, 3.0, 1.2, 2.5, 4.0, 0.5, 0.4, 5.0, 2500),\n    ]\n\n    s_pilot = 2025\n    s_final = 2026\n\n    all_results = []\n\n    for case in test_cases:\n        A, mu_P, cv_P, mu_E, sigma_E, a_C, b_C, mu_k, cv_k, eps, N0 = case\n        model_params = (A, mu_P, cv_P, mu_E, sigma_E, a_C, b_C, mu_k, cv_k)\n        \n        # --- Stage 1: Pilot Simulation ---\n        Q_pilot = run_model_simulation(model_params, N0, s_pilot)\n        \n        # Estimate variance of Q from the pilot run\n        var_Q_pilot = np.var(Q_pilot, ddof=1)\n        \n        # --- Calculate N for the final simulation ---\n        # N >= var(Q) / epsilon^2\n        if var_Q_pilot > 0 and eps > 0:\n            N_required = var_Q_pilot / (eps**2)\n            N = int(np.ceil(N_required))\n        else:\n            N = 1\n        N = max(1, N)\n\n        # --- Stage 2: Final Simulation ---\n        Q_final = run_model_simulation(model_params, N, s_final)\n        \n        # --- Calculate final statistics ---\n        mu_Q_hat = np.mean(Q_final)\n        q10, q50, q90 = np.quantile(Q_final, [0.1, 0.5, 0.9])\n        \n        case_result = [\n            round(mu_Q_hat, 6),\n            round(q10, 6),\n            round(q50, 6),\n            round(q90, 6),\n            N\n        ]\n        all_results.append(case_result)\n        \n    # --- Format final output string ---\n    # The string representation of a list in python is already the desired format.\n    output_str = \"[\" + \",\".join(map(str, all_results)) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "In integrated modeling, a key task is to combine information from models and observations, a process known as data assimilation. This exercise explores a critical and subtle aspect of this process: the structure of observation errors. By analytically deriving the impact of neglecting error correlations, you will quantify how such a simplifying assumption can lead to an overconfident (and biased) estimate of the system's state, a crucial lesson for building reliable data assimilation systems .",
            "id": "3863088",
            "problem": "A land surface data assimilation system integrates a thermodynamic land surface model with satellite thermal infrared radiances to estimate a scalar near-surface kinetic temperature $x$ over a homogeneous pixel. The forecast step of the integrated model produces a background (prior) ensemble with mean $x_{b}$ and variance $\\sigma_{b}^{2}$, and the observation operator is linear, $h(x)=x$, as the radiance-to-temperature retrieval has already been performed. Two co-orbital satellite retrievals $y_{1}$ and $y_{2}$ are available for the same pixel within a short time window. Due to common atmospheric correction and shared forward-model components, the retrieval errors are correlated. Let the observation error vector be $\\mathbf{\\varepsilon}=\\begin{pmatrix}\\varepsilon_{1} & \\varepsilon_{2}\\end{{pmatrix}}^{\\top}$ with $\\mathbb{E}[\\varepsilon_{i}]=0$, $\\mathrm{Var}(\\varepsilon_{i})=\\sigma_{o}^{2}$, and $\\mathrm{Corr}(\\varepsilon_{1},\\varepsilon_{2})=\\rho$ with $-1<\\rho<1$. The true observation error covariance is thus $R_{\\mathrm{true}}=\\sigma_{o}^{2}\\begin{pmatrix}1 & \\rho \\\\ \\rho & 1\\end{pmatrix}$.\n\nAssume linear-Gaussian data assimilation and derive the analysis (posterior) variance for $x$ from first principles by applying Bayes’ rule to the Gaussian prior $x\\sim\\mathcal{N}(x_{b},\\sigma_{b}^{2})$ and the Gaussian likelihood $\\mathbf{y}\\mid x \\sim \\mathcal{N}(H x, R)$, where $H=\\begin{pmatrix}1 & 1\\end{pmatrix}^{\\top}$. First, obtain the analysis variance $\\sigma_{a,\\mathrm{true}}^{2}$ using $R=R_{\\mathrm{true}}$. Then, obtain the analysis variance $\\sigma_{a,\\mathrm{diag}}^{2}$ under a diagonal covariance assumption that neglects correlation, i.e., $R_{\\mathrm{diag}}=\\sigma_{o}^{2}I_{2}$.\n\nUsing these results, show how neglecting error correlation inflates perceived observation information content by comparing the observation-induced precision increment terms, and quantify the resulting posterior variance bias. Specifically, provide a closed-form analytic expression for the multiplicative bias factor in the posterior variance,\n$$B=\\frac{\\sigma_{a,\\mathrm{diag}}^{2}}{\\sigma_{a,\\mathrm{true}}^{2}},$$\nin terms of $\\sigma_{b}^{2}$, $\\sigma_{o}^{2}$, and $\\rho$. Your final answer must be a single closed-form analytic expression for $B$. No rounding is required. Because $B$ is dimensionless, do not attach units to your final answer.",
            "solution": "The analysis is grounded in the principles of linear-Gaussian Bayesian inference. The posterior probability distribution for the state variable $x$ given the measurements $\\mathbf{y}$ is proportional to the product of the prior distribution and the likelihood function, $p(x|\\mathbf{y}) \\propto p(\\mathbf{y}|x)p(x)$. Since both the prior and the likelihood are Gaussian, the posterior is also a Gaussian distribution, $x|\\mathbf{y} \\sim \\mathcal{N}(x_{a}, \\sigma_{a}^{2})$. The posterior (analysis) variance, $\\sigma_{a}^{2}$, is determined by the prior (background) variance, $\\sigma_{b}^{2}$, and the observation uncertainty. The general formula for the inverse of the analysis variance, known as the analysis precision, is given by:\n$$(\\sigma_{a}^{2})^{-1} = (\\sigma_{b}^{2})^{-1} + H^{\\top} R^{-1} H$$\nwhere $H$ is the observation operator matrix and $R$ is the observation error covariance matrix. We will apply this formula for the two specified cases for $R$.\n\nFirst, we derive the analysis variance $\\sigma_{a,\\mathrm{true}}^{2}$ using the true observation error covariance matrix, $R_{\\mathrm{true}}$.\nThe given quantities are:\nThe observation operator matrix for the scalar state $x$ and two observations is $H = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\nThe true observation error covariance matrix is $R_{\\mathrm{true}} = \\sigma_{o}^{2}\\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix}$.\n\nTo calculate the term $H^{\\top} R_{\\mathrm{true}}^{-1} H$, we first need the inverse of $R_{\\mathrm{true}}$. The determinant of $R_{\\mathrm{true}}$ is $\\det(R_{\\mathrm{true}}) = (\\sigma_{o}^{2})^{2}(1) - (\\rho\\sigma_{o}^{2})^{2} = \\sigma_{o}^{4}(1-\\rho^{2})$.\nThe inverse is:\n$$R_{\\mathrm{true}}^{-1} = \\frac{1}{\\sigma_{o}^{4}(1-\\rho^{2})} \\begin{pmatrix} \\sigma_{o}^{2} & -\\rho\\sigma_{o}^{2} \\\\ -\\rho\\sigma_{o}^{2} & \\sigma_{o}^{2} \\end{pmatrix} = \\frac{1}{\\sigma_{o}^{2}(1-\\rho^{2})} \\begin{pmatrix} 1 & -\\rho \\\\ -\\rho & 1 \\end{pmatrix}$$\nNow, we compute the observation-induced precision increment, $H^{\\top} R_{\\mathrm{true}}^{-1} H$:\n$$H^{\\top} R_{\\mathrm{true}}^{-1} H = \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\left( \\frac{1}{\\sigma_{o}^{2}(1-\\rho^{2})} \\begin{pmatrix} 1 & -\\rho \\\\ -\\rho & 1 \\end{pmatrix} \\right) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n$$= \\frac{1}{\\sigma_{o}^{2}(1-\\rho^{2})} \\begin{pmatrix} 1-\\rho & 1-\\rho \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n$$= \\frac{1}{\\sigma_{o}^{2}(1-\\rho^{2})} ((1-\\rho) + (1-\\rho)) = \\frac{2(1-\\rho)}{\\sigma_{o}^{2}(1-\\rho)(1+\\rho)} = \\frac{2}{\\sigma_{o}^{2}(1+\\rho)}$$\nThe analysis precision is the sum of the background precision and this observation precision increment:\n$$(\\sigma_{a,\\mathrm{true}}^{2})^{-1} = \\frac{1}{\\sigma_{b}^{2}} + \\frac{2}{\\sigma_{o}^{2}(1+\\rho)} = \\frac{\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2}}{\\sigma_{b}^{2}\\sigma_{o}^{2}(1+\\rho)}$$\nInverting this expression gives the true analysis variance:\n$$\\sigma_{a,\\mathrm{true}}^{2} = \\frac{\\sigma_{b}^{2}\\sigma_{o}^{2}(1+\\rho)}{\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2}}$$\n\nNext, we derive the analysis variance $\\sigma_{a,\\mathrm{diag}}^{2}$ under the incorrect assumption that the observation errors are uncorrelated. This corresponds to using the diagonal covariance matrix $R_{\\mathrm{diag}} = \\sigma_{o}^{2}I_{2}$.\n$$R_{\\mathrm{diag}} = \\sigma_{o}^{2}\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} \\sigma_{o}^{2} & 0 \\\\ 0 & \\sigma_{o}^{2} \\end{pmatrix}$$\nThe inverse is straightforward:\n$$R_{\\mathrm{diag}}^{-1} = \\frac{1}{\\sigma_{o}^{2}}\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$$\nThe perceived observation-induced precision increment is:\n$$H^{\\top} R_{\\mathrm{diag}}^{-1} H = \\begin{pmatrix} 1 & 1 \\end{pmatrix} \\left( \\frac{1}{\\sigma_{o}^{2}}\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\right) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sigma_{o}^{2}}\\begin{pmatrix} 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sigma_{o}^{2}}(1+1) = \\frac{2}{\\sigma_{o}^{2}}$$\nComparing this perceived precision increment, $\\frac{2}{\\sigma_{o}^{2}}$, with the true precision increment, $\\frac{2}{\\sigma_{o}^{2}(1+\\rho)}$, reveals how neglecting correlation affects the perceived information content. If the errors are positively correlated ($\\rho > 0$), then $1+\\rho > 1$, and the true precision increment $\\frac{2}{\\sigma_{o}^{2}(1+\\rho)}$ is smaller than the perceived increment $\\frac{2}{\\sigma_{o}^{2}}$. This means that ignoring positive correlation leads to an overestimation, or inflation, of the information content provided by the observations. The ratio of perceived to true information content is $(\\frac{2}{\\sigma_{o}^{2}}) / (\\frac{2}{\\sigma_{o}^{2}(1+\\rho)}) = 1+\\rho$.\n\nThe analysis precision under the diagonal assumption is:\n$$(\\sigma_{a,\\mathrm{diag}}^{2})^{-1} = \\frac{1}{\\sigma_{b}^{2}} + \\frac{2}{\\sigma_{o}^{2}} = \\frac{\\sigma_{o}^{2} + 2\\sigma_{b}^{2}}{\\sigma_{b}^{2}\\sigma_{o}^{2}}$$\nInverting this expression gives the analysis variance under the diagonal assumption:\n$$\\sigma_{a,\\mathrm{diag}}^{2} = \\frac{\\sigma_{b}^{2}\\sigma_{o}^{2}}{\\sigma_{o}^{2} + 2\\sigma_{b}^{2}}$$\n\nFinally, we compute the multiplicative bias factor $B$ by taking the ratio of the calculated variances:\n$$B = \\frac{\\sigma_{a,\\mathrm{diag}}^{2}}{\\sigma_{a,\\mathrm{true}}^{2}} = \\frac{\\frac{\\sigma_{b}^{2}\\sigma_{o}^{2}}{\\sigma_{o}^{2} + 2\\sigma_{b}^{2}}}{\\frac{\\sigma_{b}^{2}\\sigma_{o}^{2}(1+\\rho)}{\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2}}}$$\nWe can cancel the common term $\\sigma_{b}^{2}\\sigma_{o}^{2}$ from the numerator of both fractions:\n$$B = \\frac{1/(\\sigma_{o}^{2} + 2\\sigma_{b}^{2})}{(1+\\rho)/(\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2})} = \\frac{\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2}}{(\\sigma_{o}^{2} + 2\\sigma_{b}^{2})(1+\\rho)}$$\nThis is the final closed-form analytic expression for the multiplicative bias factor.",
            "answer": "$$\\boxed{\\frac{\\sigma_{o}^{2}(1+\\rho) + 2\\sigma_{b}^{2}}{(\\sigma_{o}^{2} + 2\\sigma_{b}^{2})(1+\\rho)}}$$"
        }
    ]
}