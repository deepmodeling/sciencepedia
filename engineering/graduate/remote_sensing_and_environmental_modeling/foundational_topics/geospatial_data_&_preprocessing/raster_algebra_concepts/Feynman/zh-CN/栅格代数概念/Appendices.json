{
    "hands_on_practices": [
        {
            "introduction": "分区统计是栅格分析中的一项基本操作，它用于概括指定区域（分区）内的像元值，例如计算每个行政区划内的平均植被指数。然而，当处理大量或大型分区时，简单的逐个像元扫描方法会变得非常低效。本实践  旨在解决这一计算效率挑战，您将通过实现并对比两种计算分区直方图的方法——朴素扫描法和基于积分图（Summed-Area Table, SAT）的高效算法，来深入理解算法优化在栅格代数中的重要性。",
            "id": "3840046",
            "problem": "给定一个二维栅格和一组轴对齐的矩形区域。任务是设计并实现一种基于栅格代数概念的算法，该算法使用和面积表（SAT；也称为积分图）高效地计算分区直方图，并评估其相对于朴素扫描的复杂度。栅格是定义在规则网格上的函数，分区直方图为每个矩形区域统计其栅格单元值落入指定分箱的数量。该问题必须通过从离散和与集合运算的基本定义推导方法来解决。\n\n定义与假设：\n- 设栅格是一个函数 $R : \\{0,1,\\dots,H-1\\} \\times \\{0,1,\\dots,W-1\\} \\to \\mathbb{R}$，其高度为 $H$，宽度为 $W$。\n- 设有 $B$ 个直方图分箱，由边界 $\\mathbf{a} = \\big(a_0, a_1, \\dots, a_B\\big)$ 定义，其中 $a_0 < a_1 < \\dots < a_B$。如果 $a_k \\le x < a_{k+1}$，则值 $x$ 属于分箱 $k \\in \\{0,1,\\dots,B-1\\}$；如果 $x = a_B$，则 $x$ 被分配到分箱 $B-1$。\n- 一个矩形区域由其包含性的索引 $(r_0, r_1, c_0, c_1)$ 指定，其中 $0 \\le r_0 \\le r_1 < H$ 且 $0 \\le c_0 \\le c_1 < W$。\n- 可以指定一个可选的 NoData 值 $v_{\\text{nodata}} \\in \\mathbb{R}$；值等于 $v_{\\text{nodata}}$ 的单元格将从所有直方图中排除。\n\n您的程序必须：\n1. 根据分箱边界（不包括 NoData 值）将栅格量化为分箱索引。\n2. 使用两种方法计算分区直方图：\n   - 朴素扫描：对于每个区域，遍历其像素，并为非 NoData 值的单元格增加相应分箱的计数。\n   - 基于和面积表（SAT）的方法：对于每个分箱 $k$，在指示函数 $\\phi_k(r,c) = 1$（如果单元格属于分箱 $k$ 且不是 NoData）和 $\\phi_k(r,c) = 0$（否则）上构建一个积分图。使用容斥原理，通过对每个分箱进行常数时间查询，从 SAT 中计算每个矩形区域的计数。\n3. 在以下标量运算成本模型下评估操作计数：\n   - SAT 构建成本：对于每个分箱，计算两遍累加和（先沿行，再沿列）需要 $2 \\cdot H \\cdot W$ 次加法。对于 $B$ 个分箱，总的 SAT 构建成本为 $2 \\cdot H \\cdot W \\cdot B$ 次加法。\n   - SAT 查询成本：每个分箱的每次矩形查询使用容斥原理，需要 $4$ 次标量运算（三次加法和一次减法）。对于 $Z$ 个区域和 $B$ 个分箱，总的 SAT 查询成本为 $4 \\cdot Z \\cdot B$ 次标量运算。\n   - 朴素扫描成本：对于每个区域，每扫描一个非 NoData 值的像素计为一次标量加法。总成本是所有区域的非 NoData 像素数之和。\n   - 量化成本不计入两种方法中，以确保公平比较，因为两种方法都依赖于相同的预量化步骤。\n4. 验证对于每个测试用例，基于 SAT 的直方图与朴素扫描得到的直方图相匹配。\n\n您必须用 LaTeX表达所有的数学陈述、符号、变量、运算符和数字。程序应生成并处理以下测试套件：\n\n测试用例 1（无 NoData 值的一般情况）：\n- 大小为 $H = 6$, $W = 5$ 的栅格 $R$：\n  $\n  \\begin{bmatrix}\n  12 & 15 & 8 & 7 & 6 \\\\\n  5 & 9 & 11 & 3 & 2 \\\\\n  1 & 4 & 0 & 13 & 10 \\\\\n  8 & 8 & 8 & 14 & 16 \\\\\n  20 & 18 & 17 & 7 & 5 \\\\\n  6 & 6 & 6 & 6 & 6\n  \\end{bmatrix}\n  $\n- 分箱边界 $\\mathbf{a} = (0, 5, 10, 15, 20)$，因此 $B = 4$。\n- 区域：\n  - 区域 $1$：$(r_0, r_1, c_0, c_1) = (0, 2, 1, 3)$。\n  - 区域 $2$：$(r_0, r_1, c_0, c_1) = (3, 5, 0, 4)$。\n  - 区域 $3$：$(r_0, r_1, c_0, c_1) = (0, 5, 0, 4)$。\n- NoData 值：无。\n\n测试用例 2（边界与 NoData 值处理）：\n- 大小为 $H = 3$, $W = 3$ 的栅格 $R$：\n  $\n  \\begin{bmatrix}\n  0 & -9999 & 10 \\\\\n  5 & 5 & 5 \\\\\n  15 & 20 & 20\n  \\end{bmatrix}\n  $\n- 分箱边界 $\\mathbf{a} = (0, 5, 10, 15, 20)$，因此 $B = 4$。\n- 区域：\n  - 区域 $1$：$(r_0, r_1, c_0, c_1) = (0, 0, 0, 0)$。\n  - 区域 $2$：$(r_0, r_1, c_0, c_1) = (0, 0, 1, 1)$。\n  - 区域 $3$：$(r_0, r_1, c_0, c_1) = (1, 1, 0, 2)$。\n  - 区域 $4$：$(r_0, r_1, c_0, c_1) = (0, 2, 0, 2)$。\n- NoData 值：$v_{\\text{nodata}} = -9999$。\n\n测试用例 3（所有值相等的退化栅格）：\n- 大小为 $H = 4$, $W = 4$、所有条目均为 $7$ 的栅格 $R$。\n- 分箱边界 $\\mathbf{a} = (0, 7, 14)$，因此 $B = 2$。\n- 区域：\n  - 区域 $1$：$(r_0, r_1, c_0, c_1) = (0, 3, 0, 3)$。\n- NoData 值：无。\n\n测试用例 4（重复大范围查询的摊销效应）：\n- 大小为 $H = 40$, $W = 40$ 的栅格 $R$，其中 $R(r,c) = r + c$，$r \\in \\{0,1,\\dots,39\\}$ 且 $c \\in \\{0,1,\\dots,39\\}$。\n- 分箱边界 $\\mathbf{a}$ 是从 $0$ 到 $80$ 的 $9$ 个等间距边界，即 $\\mathbf{a} = \\big(0, 10, 20, 30, 40, 50, 60, 70, 80\\big)$，因此 $B = 8$。\n- 区域：$200$ 个覆盖整个栅格的相同区域，即每个区域的 $(r_0, r_1, c_0, c_1) = (0, 39, 0, 39)$。\n- NoData 值：无。\n\n您的程序必须为每个测试用例输出一个列表，其中包含：\n- 一个布尔值，指示基于 SAT 的方法得到的所有分区直方图是否与朴素扫描得到的结果完全匹配。\n- 在指定成本模型下，朴素扫描的总操作计数（整数）。\n- 在指定成本模型下，SAT 方法的总操作计数（整数）。\n- 速度比（朴素扫描操作数除以 SAT 操作数）作为浮点数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为一个由方括号括起来的逗号分隔列表，其中每个测试用例的结果本身也是一个按上述顺序排列的列表。例如：$\\big[\\,[\\text{True},\\,100,\\,48,\\,2.0833333333333335],\\dots\\big]$。",
            "solution": "当前问题要求设计、实现并分析两种用于计算二维栅格上分区直方图的算法的复杂度：一种是朴素扫描法，另一种是基于和面积表（SAT）的更高效方法。解决方案将从离散求和与集合论的基本原理推导得出。\n\n### **1. 形式化问题定义**\n\n设栅格为一个网格函数 $R(r, c)$，定义在离散域 $D = \\{0, 1, \\dots, H-1\\} \\times \\{0, 1, \\dots, W-1\\}$ 上，其中 $H$ 是高度，$W$ 是宽度。每个单元格 $(r,c) \\in D$ 的值为 $R(r,c) \\in \\mathbb{R}$。\n\n一组 $B$ 个直方图分箱由一个包含 $B+1$ 个分箱边界的有序序列 $\\mathbf{a} = \\big(a_0, a_1, \\dots, a_B\\big)$ 定义，满足 $a_0 < a_1 < \\dots < a_B$。一个栅格值 $x$ 根据以下规则分配到分箱 $k \\in \\{0, 1, \\dots, B-1\\}$：\n- 如果 $a_k \\le x < a_{k+1}$，$x$ 属于分箱 $k$。\n- 作为最右边界的特例，如果 $x = a_B$，$x$ 属于分箱 $B-1$。\n带有指定 NoData 值 $v_{\\text{nodata}}$ 的单元格将在所有计算中被忽略。\n\n一个矩形区域 $\\mathcal{Z}$ 由其包含性的行和列索引 $(r_0, r_1, c_0, c_1)$ 定义，其中 $0 \\le r_0 \\le r_1 < H$ 且 $0 \\le c_0 \\le c_1 < W$。\n\n任务是计算每个区域的直方图。一个区域 $\\mathcal{Z}$ 的直方图是一个计数向量 $\\mathbf{h}(\\mathcal{Z}) = \\big(h_0, h_1, \\dots, h_{B-1}\\big)$，其中 $h_k$ 是区域 $\\mathcal{Z}$ 内值 $R(r,c)$ 落入分箱 $k$ 且不等于 $v_{\\text{nodata}}$ 的单元格数量。\n\n### **2. 预处理：栅格量化**\n\n朴素扫描法和基于 SAT 的方法都受益于一个共同的预处理步骤：栅格量化。这涉及到创建一组 $B$ 个二元指示栅格或掩码 $\\Phi = \\{\\phi_0, \\phi_1, \\dots, \\phi_{B-1}\\}$。每个掩码 $\\phi_k(r,c)$ 对应一个分箱 $k$，定义如下：\n$$\n\\phi_k(r,c) = \\begin{cases} 1 & \\text{if } R(r,c) \\text{ is in bin } k \\text{ and } R(r,c) \\ne v_{\\text{nodata}} \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\n利用这些指示函数，区域 $\\mathcal{Z}_{(r_0, r_1, c_0, c_1)}$ 的计数 $h_k$ 可以正式表示为一个离散二维和：\n$$\nh_k(\\mathcal{Z}) = \\sum_{r=r_0}^{r_1} \\sum_{c=c_0}^{c_1} \\phi_k(r,c)\n$$\n此量化步骤的成本被排除在比较分析之外，因为它是两种方法的先决条件。\n\n### **3. 方法 1：朴素扫描**\n\n朴素扫描算法是求和公式的直接实现。对于每个指定的区域 $\\mathcal{Z}$，我们遍历其边界内的每个单元格 $(r,c)$。对于每个单元格，我们获取其值 $R(r,c)$，确定其对应的分箱索引（如果不是 NoData），并在该区域的直方图中增加相应计数器的值。\n\n**算法步骤：**\n1. 对于 $Z$ 个区域集合中的每个区域 $\\mathcal{Z}_i$：\n2. 初始化一个大小为 $B$ 的直方图向量 $\\mathbf{h}(\\mathcal{Z}_i)$，所有元素为零。\n3. 对于从 $(r_{i,0}, c_{i,0})$ 到 $(r_{i,1}, c_{i,1})$ 的每个单元格 $(r,c)$：\n   a. 令 $v = R(r,c)$。\n   b. 如果 $v \\ne v_{\\text{nodata}}$：\n      i. 确定值 $v$ 的分箱索引 $k$。\n      ii. 增加该分箱的计数：$h_k(\\mathcal{Z}_i) \\leftarrow h_k(\\mathcal{Z}_i) + 1$。\n\n**复杂度分析：**\n根据问题的成本模型，处理单个区域 $\\mathcal{Z}$ 的成本是其非 NoData 单元格的数量，我们记为 $N(\\mathcal{Z})$。对于一组 $Z$ 个区域 $\\{\\mathcal{Z}_1, \\dots, \\mathcal{Z}_Z\\}$，总计算成本是每个区域成本的总和：\n$$\nC_{\\text{naive}} = \\sum_{i=1}^{Z} N(\\mathcal{Z}_i)\n$$\n该成本与所有区域扫描的总面积成正比。如果区域重叠，重叠区域中的单元格将被多次处理。\n\n### **4. 方法 2：和面积表（SAT）**\n\n和面积表（SAT），或称积分图，是一种允许快速计算矩形子区域内数值之和的数据结构。其关键思想是以一次性的预计算成本换取极快的查询时间。\n\n**SAT 构建：**\n对于每个分箱 $k$，我们构建一个对应的 SAT，记为 $S_k$。$S_k$ 在任意坐标 $(r,c)$ 的值是从原点 $(0,0)$ 到 $(r,c)$ 的矩形内指示函数值 $\\phi_k(i,j)$ 的总和：\n$$\nS_k(r,c) = \\sum_{i=0}^{r} \\sum_{j=0}^{c} \\phi_k(i,j)\n$$\nSAT 可以使用递推关系在指示掩码 $\\phi_k$ 上通过单次遍历高效计算：\n$$\nS_k(r,c) = \\phi_k(r,c) + S_k(r-1, c) + S_k(r, c-1) - S_k(r-1, c-1)\n$$\n边界条件为当 $r < 0$ 或 $c < 0$ 时 $S_k(r,c) = 0$。这通常实现为两遍算法：首先，沿每行计算累加和，然后对中间结果的每列计算累加和。\n对于一个大小为 $H \\times W$ 的栅格，每遍大约涉及 $H \\times W$ 次加法。因此，构建一个 SAT 的成本是 $2 \\cdot H \\cdot W$ 次加法。对于所有 $B$ 个分箱，总构建成本为：\n$$\nC_{\\text{construct}} = 2 \\cdot H \\cdot W \\cdot B\n$$\n\n**SAT 查询：**\n一旦构建了 SAT $S_0, \\dots, S_{B-1}$，就可以使用容斥原理在常数时间内计算任意矩形 $\\mathcal{Z}_{(r_0, r_1, c_0, c_1)}$ 上 $\\phi_k$ 的和。这个和等于以 $(0,0)$ 为锚点延伸至 $(r_1, c_1)$ 的矩形面积，减去两个重叠的矩形，再加上它们共同的交集。\n$$\nh_k(\\mathcal{Z}) = \\sum_{r=r_0}^{r_1} \\sum_{c=c_0}^{c_1} \\phi_k(r,c) = S_k(r_1, c_1) - S_k(r_1, c_0-1) - S_k(r_0-1, c_1) + S_k(r_0-1, c_0-1)\n$$\n为了简化索引处理，特别是对于触及栅格边界的区域（此时 $r_0-1$ 或 $c_0-1$ 会是负数），通常的做法是用一行和一列零来填充 SAT。对分箱 $k$ 的一次查询需要 4 次查找和 3 次算术运算，问题将其定义为 4 次标量运算。对于 $Z$ 个区域和 $B$ 个分箱，总查询成本为：\n$$\nC_{\\text{query}} = 4 \\cdot Z \\cdot B\n$$\n\n**基于 SAT 的总成本：**\n基于 SAT 方法的总成本是构建成本和查询成本之和：\n$$\nC_{\\text{SAT}} = C_{\\text{construct}} + C_{\\text{query}} = (2 \\cdot H \\cdot W \\cdot B) + (4 \\cdot Z \\cdot B)\n$$\n\n### **5. 对比分析**\n\n选择朴素扫描还是 SAT 方法取决于问题参数：栅格大小 $(H, W)$、分箱数量 $(B)$，以及查询区域的数量 $(Z)$ 和大小。\n\n-   **朴素扫描成本：** $C_{\\text{naive}} \\propto \\sum (\\text{Area of Zone}_i)$\n-   **SAT 成本：** $C_{\\text{SAT}} \\propto (H \\cdot W \\cdot B) + (Z \\cdot B)$\n\nSAT 方法的成本与查询区域的大小无关。它在构建表时有显著的前期成本，但每次查询的成本非常低，为常数时间。朴素方法没有前期成本，但查询成本与区域面积呈线性关系。\n\n当查询数量很大或区域本身很大时，导致朴素方法扫描的总面积超过 SAT 构建成本，SAT 方法就变得比朴素方法更高效。$C_{\\text{construct}}$ 项的成本被摊销到多次查询中。测试用例 4 包含 200 个大区域，旨在展示这种摊销效应，预期 SAT 方法会快得多。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run test cases for zonal histogram calculation.\n    \"\"\"\n    \n    def quantize_raster(raster, bin_edges, nodata_val):\n        \"\"\"\n        Quantizes the raster into B binary indicator masks.\n        \n        A value x is in bin k if bin_edges[k] = x  bin_edges[k+1].\n        If x == bin_edges[-1], it is in the last bin (B-1).\n        \n        Returns a (B, H, W) numpy array of indicator masks.\n        \"\"\"\n        H, W = raster.shape\n        num_bins = len(bin_edges) - 1\n        \n        # Initialize with a sentinel value for pixels outside all bins or nodata\n        bin_indices = np.full(raster.shape, -1, dtype=int)\n        \n        # Assign bin indices based on the rules.\n        # Bins 0 to B-2: a_k = x  a_{k+1}\n        for k in range(num_bins - 1):\n            mask = (raster >= bin_edges[k])  (raster  bin_edges[k+1])\n            bin_indices[mask] = k\n        \n        # Last bin (B-1): a_{B-1} = x = a_B\n        mask_last_bin = (raster >= bin_edges[num_bins - 1])  (raster = bin_edges[num_bins])\n        bin_indices[mask_last_bin] = num_bins - 1\n\n        # Mask out NoData values\n        if nodata_val is not None:\n            bin_indices[raster == nodata_val] = -1\n\n        # Create B indicator masks from the bin indices\n        quantized_masks = np.zeros((num_bins, H, W), dtype=int)\n        for k in range(num_bins):\n            quantized_masks[k, :, :] = (bin_indices == k)\n        \n        return quantized_masks\n\n    def naive_histograms(quantized_masks, zones, original_raster, nodata_val):\n        \"\"\"\n        Computes zonal histograms using naive scanning.\n        \"\"\"\n        histograms = []\n        naive_op_count = 0\n        \n        for r0, r1, c0, c1 in zones:\n            # Calculate operation cost for this zone\n            zone_raster = original_raster[r0:r1+1, c0:c1+1]\n            if nodata_val is not None:\n                naive_op_count += np.sum(zone_raster != nodata_val)\n            else:\n                naive_op_count += zone_raster.size\n\n            # Slice the indicator masks to get the zone\n            zone_masks = quantized_masks[:, r0:r1+1, c0:c1+1]\n            # Sum over the spatial dimensions to get the histogram\n            histogram = np.sum(zone_masks, axis=(1, 2))\n            histograms.append(histogram)\n            \n        return np.array(histograms), naive_op_count\n\n    def sat_histograms(quantized_masks, zones):\n        \"\"\"\n        Computes zonal histograms using Summed-Area Tables.\n        \"\"\"\n        num_bins, H, W = quantized_masks.shape\n        num_zones = len(zones)\n        \n        # --- SAT Construction ---\n        # Cost as per problem statement\n        sat_construction_cost = 2 * H * W * num_bins\n        \n        # Pad SATs with a row and column of zeros for easy querying\n        sats = np.zeros((num_bins, H + 1, W + 1), dtype=int)\n        \n        # Compute cumulative sums twice: once along columns (axis=2), then rows (axis=1)\n        # This is a vectorized implementation of the two-pass algorithm.\n        sats[:, 1:, 1:] = np.cumsum(np.cumsum(quantized_masks, axis=2), axis=1)\n\n        # --- SAT Querying ---\n        # Cost as per problem statement\n        sat_query_cost = 4 * num_zones * num_bins\n        total_sat_cost = sat_construction_cost + sat_query_cost\n\n        histograms = []\n        for r0, r1, c0, c1 in zones:\n            # Adjust indices for padded SAT. The query area corresponds to\n            # corners (r0, c0) and (r1+1, c1+1) in the padded SAT.\n            # D = S(r1, c1), C = S(r1, c0-1), B = S(r0-1, c1), A = S(r0-1, c0-1)\n            # Sum = D - B - C + A\n            # Indices in padded SAT: S(r,c) is accessed at sats[:, r+1, c+1]\n            # So, S(r1,c1) -> sats[:, r1+1, c1+1]\n            # S(r1,c0-1) -> sats[:, r1+1, c0]\n            # S(r0-1,c1) -> sats[:, r0, c1+1]\n            # S(r0-1,c0-1) -> sats[:, r0, c0]\n            # This is vectorized across all bins simultaneously.\n            D = sats[:, r1 + 1, c1 + 1]\n            B_term = sats[:, r1 + 1, c0]\n            C_term = sats[:, r0, c1 + 1]\n            A = sats[:, r0, c0]\n            histogram = D - B_term - C_term + A\n            histograms.append(histogram)\n            \n        return np.array(histograms), total_sat_cost\n\n    test_cases = [\n        # Test Case 1\n        {\n            \"R\": np.array([\n                [12, 15, 8, 7, 6],\n                [5, 9, 11, 3, 2],\n                [1, 4, 0, 13, 10],\n                [8, 8, 8, 14, 16],\n                [20, 18, 17, 7, 5],\n                [6, 6, 6, 6, 6]\n            ]),\n            \"a\": (0, 5, 10, 15, 20),\n            \"zones\": [(0, 2, 1, 3), (3, 5, 0, 4), (0, 5, 0, 4)],\n            \"nodata\": None\n        },\n        # Test Case 2\n        {\n            \"R\": np.array([\n                [0, -9999, 10],\n                [5, 5, 5],\n                [15, 20, 20]\n            ]),\n            \"a\": (0, 5, 10, 15, 20),\n            \"zones\": [(0, 0, 0, 0), (0, 0, 1, 1), (1, 1, 0, 2), (0, 2, 0, 2)],\n            \"nodata\": -9999\n        },\n        # Test Case 3\n        {\n            \"R\": np.full((4, 4), 7),\n            \"a\": (0, 7, 14),\n            \"zones\": [(0, 3, 0, 3)],\n            \"nodata\": None\n        },\n        # Test Case 4\n        {\n            \"R\": np.array([[r + c for c in range(40)] for r in range(40)]),\n            \"a\": tuple(range(0, 81, 10)),\n            \"zones\": [(0, 39, 0, 39)] * 200,\n            \"nodata\": None\n        },\n    ]\n\n    final_results = []\n    for case in test_cases:\n        raster = case[\"R\"]\n        bin_edges = case[\"a\"]\n        zones = case[\"zones\"]\n        nodata_val = case[\"nodata\"]\n\n        # 1. Quantize the raster\n        quantized_masks = quantize_raster(raster, bin_edges, nodata_val)\n\n        # 2a. Compute histograms and cost with naive scanning\n        naive_hists, naive_cost = naive_histograms(quantized_masks, zones, raster, nodata_val)\n\n        # 2b. Compute histograms and cost with SAT\n        sat_hists, sat_cost = sat_histograms(quantized_masks, zones)\n        \n        # 3. Verify results\n        is_match = np.array_equal(naive_hists, sat_hists)\n        \n        # 4. Calculate speed ratio\n        if sat_cost > 0:\n            speed_ratio = naive_cost / sat_cost\n        else: # Should not happen with the given cost models\n            speed_ratio = float('inf') if naive_cost > 0 else 1.0\n            \n        final_results.append([is_match, int(naive_cost), int(sat_cost), speed_ratio])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "与依赖局部或分区信息的操作不同，一些复杂的空间分析需要全局视角，例如在整个地形中寻找成本最低的路径。最小成本路径分析是全局栅格运算的一个典型应用，它将栅格数据从简单的像元集合提升为连接性的网络模型。在本实践中 ，您将学习如何将成本栅格抽象为一个加权图，并应用经典的 Dijkstra 算法来求解最优路径。这个过程将揭示栅格代数与图论之间的深刻联系，这是进行高级空间建模的一项核心技能。",
            "id": "3840074",
            "problem": "您的概念性任务是，在一个空间网格（栅格）上计算最小成本路径，其中每个单元格存储一个非负的单位长度移动摩擦成本；同时，您需要形式化由一个非负加权图模型导出的累积成本栅格与最短路径树之间的关系。本问题中的栅格代数构造必须从第一性原理推导得出，这些原理将空间变化成本场的连续路径积分与栅格网格上的离散图表示联系起来。\n\n从以下基本基础开始：在域 $\\Omega \\subset \\mathbb{R}^2$ 上的一个连续成本场 $c(\\mathbf{x}) \\ge 0$，以及一条总弧长为 $L$、无穷小弧长测度为 $\\mathrm{d}s$ 的连续路径 $\\gamma: [0, L] \\to \\Omega$。遍历路径 $\\gamma$ 的累积成本是路径积分\n$$\nJ[\\gamma] = \\int_{0}^{L} c(\\gamma(s)) \\, \\mathrm{d}s,\n$$\n这是对弧长上的非负摩擦进行积分的空间类比。对于一个具有 $m$ 行和 $n$ 列的栅格，定义成本栅格 $C \\in \\mathbb{R}_{\\ge 0}^{m \\times n}$，使得 $C_{i,j}$ 近似于单元格中心 $\\mathbf{x}_{i,j}$ 处的 $c(\\mathbf{x}_{i,j})$。设顶点集为 $V = \\{(i,j) \\mid i \\in \\{0,\\dots,m-1\\}, j \\in \\{0,\\dots,n-1\\}\\}$，边集 $E$ 在指定的连通性 $\\mathcal{N}$（4-连通或8-连通）下连接每个单元格及其邻居。将每条边 $e = (u,v) \\in E$ 与一个欧几里得步长 $d_{uv} \\in \\{1,\\sqrt{2}\\}$ 相关联，具体取值取决于 $u$ 和 $v$ 是正交邻居还是对角邻居。沿每条边使用一阶精度求积（例如，将梯形法则应用于单元格中心之间的线段），将边权重 $w_{uv}$ 近似为 $c$ 沿该短线段积分的离散类比。这定义了一个非负加权图 $(V,E,w)$，对于该图，从源点集 $S \\subset V$ 到任意顶点 $v \\in V$ 的累积成本是所有从 $S$ 到 $v$ 的离散路径的边权重之和的最小值，并且相应的前驱关系定义了一棵最短路径树（当 $|S| \\ge 2$ 时为森林）。\n\n您的任务是：\n- 实现一个程序，给定 $C$、$\\mathcal{N}$、一个源点集 $S \\subset V$ 和一个目标点 $t \\in V$，该程序能如上所述构建加权图，并使用 Dijkstra 算法在图 $(V,E,w)$ 上计算累积成本栅格 $A \\in \\mathbb{R}_{\\ge 0}^{m \\times n}$ 和前驱栅格 $P \\in \\{-1\\} \\cup \\{0,1,\\dots,mn-1\\}^{m \\times n}$。其中，$A_{v}$ 是从 $S$ 中任意源点到 $v$ 的最小边权重之和，$P_{v}$ 编码了算法在最短路径树中为 $v$ 选择的唯一前驱（对于源点则为 $-1$）。该图必须遵守以下规则：边仅存在于 $\\mathcal{N}$ 下的有效界内邻居之间，并且任何与不可通行单元格（$C_{i,j} = +\\infty$）相邻的边都将被排除。对 $(i,j)$ 坐标使用从零开始的索引约定，并使用扁平索引映射 $f(i,j) = i \\cdot n + j$ 来存储前驱。\n- 通过追踪 $P$ 从目标点 $t$ 回溯到其源点，以重建最小成本路径，计算路径上的步数，并验证重建路径上累积成本栅格的边加性属性：对于路径中的每个连续对 $(u,v)$，在 $10^{-9}$ 的数值容差内检查是否满足 $A_{v} = A_{u} + w_{uv}$，并检查路径上边权重的总和是否在相同容差内等于 $A_{t}$。\n\n单位：所有成本都是无单位的，代表每单位长度的成本单位；步长是无单位的，根据构造，正交移动的步长为 $1$，对角移动的步长为 $\\sqrt{2}$。\n\n角度单位：本问题不使用角度。\n\n百分比：不适用。\n\n测试套件和参数说明：\n定义四个测试用例，每个用例都有一个目标点：\n- 测试用例1（8-连通性和均匀成本的一般情况）：\n    - 栅格大小：$m = 5$, $n = 5$。\n    - 成本栅格：对所有 $(i,j)$，$C_{i,j} = 1$。\n    - 连通性：$\\mathcal{N} = 8$-连通。\n    - 源点：$S = \\{(0,0)\\}$。\n    - 目标点：$t = (4,3)$。\n- 测试用例2（具有不可逾越障碍和4-连通性的边界情况）：\n    - 栅格大小：$m = 5$, $n = 5$。\n    - 成本栅格：对所有 $(i,j)$，$C_{i,j} = 1$，除了 $C_{2,1} = C_{2,2} = C_{2,3} = +\\infty$（不可通行）。\n    - 连通性：$\\mathcal{N} = 4$-连通。\n    - 源点：$S = \\{(0,2)\\}$。\n    - 目标点：$t = (4,2)$。\n- 测试用例3（具有多个源点和8-连通性的非均匀梯度成本）：\n    - 栅格大小：$m = 6$, $n = 6$。\n    - 成本栅格：对于 $i \\in \\{0,\\dots,5\\}, j \\in \\{0,\\dots,5\\}$，$C_{i,j} = 1 + 0.15\\, i + 0.05\\, j$。\n    - 连通性：$\\mathcal{N} = 8$-连通。\n    - 源点：$S = \\{(0,0),(5,5)\\}$。\n    - 目标点：$t = (5,0)$。\n- 测试用例4（具有多个源点和在均匀成本下出现平局的边缘情况）：\n    - 栅格大小：$m = 4$, $n = 4$。\n    - 成本栅格：对所有 $(i,j)$，$C_{i,j} = 1$。\n    - 连通性：$\\mathcal{N} = 8$-连通。\n    - 源点：$S = \\{(0,3),(3,0)\\}$。\n    - 目标点：$t = (3,3)$。\n\n最终输出格式：\n对于每个测试用例，生成一个包含三项的列表：到目标点的累积成本 $A_{t}$（浮点数，保留6位小数）、沿重建的最小成本路径到达源点的步数（整数），以及一个布尔值，指示边加性属性和总路径成本相等性是否在 $10^{-9}$ 的容差内成立。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个元素对应一个测试用例，其本身也是一个形式为 $[A_{t}, \\text{steps}, \\text{valid}]$ 的列表。例如，两个测试用例的输出应如下所示：$[[a_1,s_1,v_1],[a_2,s_2,v_2]]$，并替换为实际值。",
            "solution": "问题陈述已经过仔细审查，并被确定为 **有效**。它在科学上基于应用于空间分析的图论和数值方法原理，特别是栅格上的最小成本路径寻找。该问题是适定的，提供了所有必要的数据、约束和定义，以确保一个唯一且有意义的解。它是客观且无歧义的。任务是基于这些原理实现一个计算解决方案。\n\n解决方案首先将连续的成本路径问题离散化为加权图上的最短路径问题。然后，我们应用 Dijkstra 算法来解决这个离散问题，最后，我们重建并验证所得路径。\n\n**1. 离散化：从连续场到离散图**\n\n其基本概念是将一个连续问题转化为一个适合计算的离散问题。连续的累积成本由路径积分 $J[\\gamma] = \\int_{\\gamma} c(\\mathbf{x}) \\, \\mathrm{d}s$ 给出，其中 $c(\\mathbf{x})$ 是一个空间变化的摩擦成本场。\n\n我们按如下方式进行离散化：\n- 连续域 $\\Omega \\subset \\mathbb{R}^2$ 由一个 $m \\times n$ 单元格的网格表示。每个单元格 $(i,j)$ 成为图 $G = (V, E)$ 中的一个顶点 $v_{i,j}$。\n- 成本场 $c(\\mathbf{x})$ 在每个单元格的中心进行采样，得到成本栅格 $C$，其中 $C_{i,j}$ 是顶点 $v_{i,j}$ 处的成本值。\n- 连续路径 $\\gamma$ 通过连接图中相邻顶点的一系列边来近似。可用边集 $E$ 由指定的连通性确定，可以是 4-连通（正交邻居）或 8-连通（正交和对角邻居）。\n- 沿两个相邻顶点 $u$ 和 $v$ 之间的短路径段的积分 $\\int c(\\mathbf{x}) \\, \\mathrm{d}s$ 通过离散边权重之和 $w_{uv}$ 来近似。\n\n**2. 边权重公式**\n\n问题指定使用一阶精度求积来近似沿连接两个相邻单元格 $u$ 和 $v$ 中心的直线段的成本积分。梯形法则是合适的选择。沿该线段的成本积分近似为端点成本的平均值乘以该线段的长度：\n$$\nw_{uv} \\approx \\frac{C_u + C_v}{2} d_{uv}\n$$\n其中 $C_u$ 和 $C_v$ 分别是单元格 $u$ 和 $v$ 处的成本值，$d_{uv}$ 是它们中心之间的欧几里得距离。按照惯例，对于单位网格间距：\n- 对于正交邻居，$d_{uv} = 1$。\n- 对于对角邻居，$d_{uv} = \\sqrt{2}$。\n\n由于所有成本 $C_{i,j}$ 都是非负的，所有得到的边权重 $w_{uv}$ 也都是非负的。这是 Dijkstra 算法正确性的一个关键先决条件。与不可通行单元格（其中 $C_{i,j} = +\\infty$）相连的边被认为具有无穷大权重，并被有效地从图中排除。\n\n**3. 用于最小成本路径的 Dijkstra 算法**\n\n对于所有边权重 $w$ 均为非负的图 $G = (V,E,w)$，Dijkstra 算法能正确地找到从一组源顶点 $S$ 到所有其他可达顶点的最小累积成本路径。\n\n该算法维护三个关键数据结构：\n- 一个累积成本栅格 $A$，其中 $A_v$ 存储从 $S$ 中任意源点到顶点 $v$ 的当前已知最短路径成本。对所有 $s \\in S$，它被初始化为 $0$，对所有其他顶点，初始化为 $+\\infty$。\n- 一个前驱栅格 $P$，其中 $P_v$ 存储在从 $S$ 出发的最短路径上位于 $v$ 之前的顶点的索引。源顶点具有特殊的前驱值 $-1$。我们为此使用扁平索引映射 $f(i,j) = i \\cdot n + j$。\n- 一个优先队列 `pq`，它存储待访问的顶点，并按其累积成本排列优先级。它用所有源顶点进行初始化。\n\n算法按以下步骤进行：\n1.  如上所述初始化 $A$、$P$ 和 `pq`。\n2.  当优先队列不为空时，提取具有最小累积成本的顶点 $u$。\n3.  对于 $u$ 的每个有效邻居 $v$（由连通性 $\\mathcal{N}$ 和网格边界定义）：\n    a. 计算边权重 $w_{uv} = ((C_u + C_v)/2) \\cdot d_{uv}$。\n    b. 计算通过 $u$ 到达 $v$ 的潜在新成本：$A_u + w_{uv}$。\n    c. 如果这个新成本小于当前成本 $A_v$，则将 $A_v$ 更新为这个新的、更低的成本，将 $P_v$ 设置为 $u$ 的扁平索引，并将 $v$ 及其新成本添加到优先队列中。\n\n算法终止时，$A$ 包含从源点集 $S$ 到每个其他单元格的最终最小成本值，而 $P$ 编码了最短路径树（在有多个不连通分量或多个源点的情况下为森林）。\n\n**4. 路径重建和验证**\n\n给定计算出的前驱栅格 $P$ 和一个目标顶点 $t$，可以通过从 $t$ 开始，迭代地向其前驱回溯，直到到达一个源顶点（其前驱为 $-1$），从而重建最小成本路径。\n\n步数是此重建路径中的边数。\n\n验证涉及两个检查，均在 $10^{-9}$ 的数值容差下执行：\n- **边加性属性**：对于重建路径上的每一对连续顶点 $(u, v)$，其中 $u$ 是 $v$ 的前驱，我们必须验证成本是一致的：$A_v = A_u + w_{uv}$。\n- **总路径成本**：沿整个重建路径的所有边权重 $w_{uv}$ 的总和必须等于目标点的最终累积成本 $A_t$。\n\n如果这两条属性对整个路径都成立，则该实现被认为是有效的。",
            "answer": "```python\nimport numpy as np\nimport heapq\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and orchestrate the solution process.\n    \"\"\"\n\n    def run_least_cost_path(cost_raster, connectivity, sources, target):\n        \"\"\"\n        Computes the least-cost path, reconstructs it, and verifies its properties.\n\n        Args:\n            cost_raster (np.ndarray): The m x n raster of cost values.\n            connectivity (int): The neighborhood connectivity (4 or 8).\n            sources (list of tuples): A list of (row, col) source coordinates.\n            target (tuple): The (row, col) coordinate of the target cell.\n\n        Returns:\n            tuple: A tuple containing:\n                - float: Accumulated cost at the target, rounded.\n                - int: Number of steps in the reconstructed path.\n                - bool: True if the path properties are valid, False otherwise.\n        \"\"\"\n        m, n = cost_raster.shape\n        \n        # Initialize accumulated cost raster A and predecessor raster P\n        costs = np.full((m, n), np.inf, dtype=np.float64)\n        predecessors = np.full((m, n), -1, dtype=np.intp)\n        \n        # Priority queue stores (cost, row, col)\n        pq = []\n\n        for r_s, c_s in sources:\n            if 0 = r_s  m and 0 = c_s  n:\n                costs[r_s, c_s] = 0.0\n                heapq.heappush(pq, (0.0, r_s, c_s))\n\n        # Define neighbor movements and distances\n        if connectivity == 4:\n            neighbors_def = [\n                (0, 1, 1.0), (0, -1, 1.0), (1, 0, 1.0), (-1, 0, 1.0)\n            ]\n        elif connectivity == 8:\n            sqrt2 = np.sqrt(2)\n            neighbors_def = [\n                (0, 1, 1.0), (0, -1, 1.0), (1, 0, 1.0), (-1, 0, 1.0),\n                (1, 1, sqrt2), (1, -1, sqrt2), (-1, 1, sqrt2), (-1, -1, sqrt2)\n            ]\n        else:\n            raise ValueError(\"Connectivity must be 4 or 8.\")\n            \n        # Dijkstra's algorithm\n        while pq:\n            cost, r, c = heapq.heappop(pq)\n            \n            # Skip stale entries\n            if cost > costs[r, c]:\n                continue\n            \n            # Skip impassable cells\n            if np.isinf(cost_raster[r,c]):\n                continue\n\n            for dr, dc, dist in neighbors_def:\n                nr, nc = r + dr, c + dc\n                \n                if 0 = nr  m and 0 = nc  n:\n                    # Skip neighbors that are impassable\n                    if np.isinf(cost_raster[nr, nc]):\n                        continue\n\n                    # Calculate edge weight using trapezoidal rule\n                    edge_weight = (cost_raster[r, c] + cost_raster[nr, nc]) / 2.0 * dist\n                    new_cost = costs[r, c] + edge_weight\n                    \n                    if new_cost  costs[nr, nc]:\n                        costs[nr, nc] = new_cost\n                        predecessors[nr, nc] = r * n + c\n                        heapq.heappush(pq, (new_cost, nr, nc))\n\n        # Path reconstruction and verification\n        target_cost = costs[target]\n        if np.isinf(target_cost):\n            return [np.inf, 0, False]\n\n        path = []\n        curr_r, curr_c = target\n        num_steps = 0\n        \n        if predecessors[curr_r, curr_c] != -1 or (curr_r, curr_c) in sources:\n            while True:\n                path.append((curr_r, curr_c))\n                pred_flat_idx = predecessors[curr_r, curr_c]\n                if pred_flat_idx == -1:\n                    break\n                pred_r, pred_c = divmod(pred_flat_idx, n)\n                curr_r, curr_c = pred_r, pred_c\n                num_steps += 1\n        \n        path.reverse() # Path from source to target\n        \n        # Verification\n        path_is_valid = True\n        total_path_cost_sum = 0.0\n        tolerance = 1e-9\n\n        if num_steps > 0:\n            for i in range(num_steps):\n                u_r, u_c = path[i]\n                v_r, v_c = path[i+1]\n                \n                dr, dc = v_r - u_r, v_c - u_c\n                dist = np.sqrt(dr**2 + dc**2)\n                \n                edge_weight = (cost_raster[u_r, u_c] + cost_raster[v_r, v_c]) / 2.0 * dist\n                total_path_cost_sum += edge_weight\n                \n                # Check edge-additive property\n                if not np.isclose(costs[v_r, v_c], costs[u_r, u_c] + edge_weight, atol=tolerance):\n                    path_is_valid = False\n                    break\n            \n            # Check total path cost property\n            if path_is_valid and not np.isclose(total_path_cost_sum, target_cost, atol=tolerance):\n                path_is_valid = False\n        elif target not in sources:\n             # Target is not a source, but path has 0 steps. This is an invalid state\n             # unless the target is unreachable, which is handled earlier.\n             path_is_valid = False\n\n        return [round(target_cost, 6), num_steps, path_is_valid]\n\n\n    # Test Case 1\n    C1 = np.ones((5, 5), dtype=np.float64)\n    S1 = [(0, 0)]\n    t1 = (4, 3)\n    \n    # Test Case 2\n    C2 = np.ones((5, 5), dtype=np.float64)\n    C2[2, 1] = C2[2, 2] = C2[2, 3] = np.inf\n    S2 = [(0, 2)]\n    t2 = (4, 2)\n    \n    # Test Case 3\n    C3 = np.fromfunction(lambda i, j: 1 + 0.15 * i + 0.05 * j, (6, 6), dtype=np.float64)\n    S3 = [(0, 0), (5, 5)]\n    t3 = (5, 0)\n\n    # Test Case 4\n    C4 = np.ones((4, 4), dtype=np.float64)\n    S4 = [(0, 3), (3, 0)]\n    t4 = (3, 3)\n\n    test_cases = [\n        (C1, 8, S1, t1),\n        (C2, 4, S2, t2),\n        (C3, 8, S3, t3),\n        (C4, 8, S4, t4),\n    ]\n    \n    results = []\n    for C, N_conn, S, t in test_cases:\n        result = run_least_cost_path(C, N_conn, S, t)\n        results.append(result)\n\n    # Convert boolean to string 'True' or 'False' for final printing\n    formatted_results = [f\"[{res[0]}, {res[1]}, {str(res[2])}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "局部运算（或称逐像元运算）是栅格代数的基础，许多遥感指数，如归一化植被指数（NDVI），都基于此类运算。然而，在实际应用中，看似简单的公式可能会遇到数值不稳定的挑战，例如分母接近于零。本实践  将聚焦于此问题，通过引入$\\varepsilon$-正则化技术来增强归一化差异指数的稳健性。您需要从解析上推导该技术引入的偏差，并实现一个数值上更可靠的解决方案，这对于开发稳健的科学计算模型至关重要。",
            "id": "3840049",
            "problem": "给定两个以数组形式表示的单波段反射率栅格，记为 $R_1$ 和 $R_2$。其元素值被限制在区间 $[0,1]$ 内，且无物理单位（无量纲）。目标是实现一个逐像素的归一化差异算子，该算子计算 $R_1$ 和 $R_2$ 之间的差值并按其和进行归一化。实现方式应通过添加一个严格为正的正则化参数 $\\varepsilon$ 来确保在分母中的和很小时数值计算的鲁棒性。然后，量化此正则化引入的偏差，并验证其幅值的上界。\n\n从以下基本依据出发：\n- 栅格代数运算是逐元素定义的。也就是说，对于任何两个形状相同的栅格 $A$ 和 $B$，其加法、减法、乘法和除法运算都是在每个像素上独立执行的。\n- 对于任意 $a,b \\in [0,1]$，它们的和满足 $0 \\le a+b \\le 2$，差满足 $-1 \\le a-b \\le 1$。\n\n在每个和 $S = R_1 + R_2$ 严格为正的像素点上，将理想的、未正则化的指数定义为 $R_1$ 和 $R_2$ 的差值除以它们的和。在每个像素点上，将正则化的指数定义为相同的差值除以加上一个严格为正的常数 $\\varepsilon$ 的和，即分母中的和增加 $\\varepsilon$ 以避免除以非常小的数。正则化指数相对于未正则化指数的逐像素偏差是该像素点上正则化指数与未正则化指数之间的差值。\n\n你的任务：\n1. 根据上述逐元素的定义，通过代数运算推导出一个关于 $R_1$、$R_2$ 和 $\\varepsilon$ 的逐像素偏差的闭式表达式。该表达式在 $R_1 + R_2  0$ 和 $\\varepsilon  0$ 的任意位置均有效。\n2. 证明偏差幅值的一个逐点上界，该上界仅用和 $S = R_1 + R_2$ 和 $\\varepsilon$ 表示，而不涉及差值 $R_1 - R_2$。对于所有 $S  0$ 和 $\\varepsilon  0$，你的界应该是非负且有限的。\n3. 实现一个稳健的、向量化的计算过程，用于计算未正则化和正则化的指数、逐像素偏差，并为每个像素验证任务2中的上界。设置数值容差 $\\delta = 10^{-12}$ 以适应浮点运算。如果一个像素计算出的偏差幅值小于或等于你的上界加上 $\\delta$，则认为该像素的验证成功。\n\n使用以下测试套件。每个测试用例包含两个数组 $R_1$ 和 $R_2$ 以及一个标量 $\\varepsilon$：\n- 测试用例1（和为中等的一般值）：$R_1 = [\\,0.62,\\, 0.18,\\, 0.47,\\, 0.33,\\, 0.70\\,]$，$R_2 = [\\,0.21,\\, 0.35,\\, 0.43,\\, 0.12,\\, 0.40\\,]$，$\\varepsilon = 10^{-3}$。\n- 测试用例2（和接近正则化尺度的较小值）：$R_1 = [\\,10^{-6},\\, 3 \\times 10^{-4},\\, 5 \\times 10^{-3},\\, 2 \\times 10^{-2}\\,]$，$R_2 = [\\,2 \\times 10^{-6},\\, 8 \\times 10^{-4},\\, 5 \\times 10^{-3},\\, 10^{-2}\\,]$，$\\varepsilon = 10^{-3}$。\n- 测试用例3（分子为零，和不为零）：$R_1 = [\\,10^{-6},\\, 10^{-3},\\, 10^{-1},\\, 5 \\times 10^{-1}\\,]$，$R_2 = [\\,10^{-6},\\, 10^{-3},\\, 10^{-1},\\, 5 \\times 10^{-1}\\,]$，$\\varepsilon = 10^{-3}$。\n- 测试用例4（混合极端值）：$R_1 = [\\,1.0,\\, 0.0,\\, 0.9,\\, 2 \\times 10^{-2},\\, 0.6\\,]$，$R_2 = [\\,0.0,\\, 1.0,\\, 0.1,\\, 10^{-2},\\, 0.35\\,]$，$\\varepsilon = 5 \\times 10^{-2}$。\n\n对于每个测试用例，计算并返回以下三个量：\n- 跨像素的最大绝对偏差（一个浮点数）。\n- 跨像素的平均有符号偏差（一个浮点数）。\n- 一个布尔值，指示任务2中的上界是否在容差 $\\delta$ 内对每个像素都满足。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素本身也是一个列表，按指定顺序包含上述三个量。例如，输出的形式应为\n\"[ [max_abs_bias_case1, mean_bias_case1, bound_ok_case1], [max_abs_bias_case2, mean_bias_case2, bound_ok_case2], [max_abs_bias_case3, mean_bias_case3, bound_ok_case3], [max_abs_bias_case4, mean_bias_case4, bound_ok_case4] ]\"。",
            "solution": "该问题要求推导归一化差异指数中正则化项引入的偏差，证明该偏差的上界，并进行数值实现，以计算偏差并为一组给定的测试用例验证该上界。该问题定义明确，具有科学依据，并为获得唯一解提供了所有必要信息。\n\n设两个栅格的逐像素反射率值为 $r_1$ 和 $r_2$，其中 $r_1, r_2 \\in [0, 1]$。正则化参数为 $\\varepsilon  0$。所有栅格操作均按元素执行。\n\n**任务1：推导逐像素偏差的闭式表达式**\n\n对于 $r_1 + r_2  0$ 的情况，未正则化的归一化差异指数 $I_{unreg}$ 定义为：\n$$I_{unreg} = \\frac{r_1 - r_2}{r_1 + r_2}$$\n\n正则化指数 $I_{reg}$ 定义为：\n$$I_{reg} = \\frac{r_1 - r_2}{r_1 + r_2 + \\varepsilon}$$\n\n逐像素偏差 $B$ 是正则化指数和未正则化指数之间的差值：\n$$B = I_{reg} - I_{unreg}$$\n\n代入 $I_{reg}$ 和 $I_{unreg}$ 的定义：\n$$B = \\frac{r_1 - r_2}{r_1 + r_2 + \\varepsilon} - \\frac{r_1 - r_2}{r_1 + r_2}$$\n\n为简化起见，设 $D = r_1 - r_2$ 且 $S = r_1 + r_2$。偏差的表达式变为：\n$$B = \\frac{D}{S + \\varepsilon} - \\frac{D}{S}$$\n\n提出公因子 $D$：\n$$B = D \\left( \\frac{1}{S + \\varepsilon} - \\frac{1}{S} \\right)$$\n\n我们对括号内的项进行通分：\n$$B = D \\left( \\frac{S - (S + \\varepsilon)}{S(S + \\varepsilon)} \\right) = D \\left( \\frac{-\\varepsilon}{S(S + \\varepsilon)} \\right)$$\n\n将 $D = r_1 - r_2$ 和 $S = r_1 + r_2$ 代回，我们得到偏差的闭式表达式：\n$$B = - \\varepsilon \\frac{r_1 - r_2}{(r_1 + r_2)(r_1 + r_2 + \\varepsilon)}$$\n该表达式对所有 $S = r_1 + r_2  0$ 的像素点以及任何 $\\varepsilon  0$ 都有效。\n\n**任务2：证明偏差幅值的逐点上界**\n\n我们寻求偏差幅值 $|B|$ 的一个上界，该上界仅取决于和 $S = r_1 + r_2$ 与正则化参数 $\\varepsilon$。\n\n从推导出的 $B$ 的表达式开始：\n$$|B| = \\left| - \\varepsilon \\frac{r_1 - r_2}{S(S + \\varepsilon)} \\right|$$\n\n由于 $\\varepsilon  0$ 且 $S  0$（根据问题约束），分母 $S(S + \\varepsilon)$ 严格为正。我们可以将幅值简化为：\n$$|B| = \\frac{\\varepsilon |r_1 - r_2|}{S(S + \\varepsilon)}$$\n\n为了建立一个以 $S$ 和 $\\varepsilon$ 表示的上界，我们必须对 $|r_1 - r_2|$ 项进行界定。反射率值为非负，即 $r_1 \\ge 0$ 和 $r_2 \\ge 0$。根据三角不等式，对于任意两个实数 $x$ 和 $y$，有 $|x - y| \\le |x| + |y|$。将此应用于我们的非负反射率：\n$$|r_1 - r_2| \\le |r_1| + |-r_2| = r_1 + r_2 = S$$\n\n这个不等式 $|r_1 - r_2| \\le S$ 允许我们对偏差的幅值进行界定。将其代入 $|B|$ 的表达式中：\n$$|B| \\le \\frac{\\varepsilon \\cdot S}{S(S + \\varepsilon)}$$\n\n对于 $S0$，我们可以消去分子和分母中的 $S$ 项：\n$$|B| \\le \\frac{\\varepsilon}{S + \\varepsilon}$$\n\n这就为偏差的幅值提供了一个有效的上界 $U(S, \\varepsilon) = \\frac{\\varepsilon}{S + \\varepsilon}$。该上界仅用 $S$ 和 $\\varepsilon$ 表示，对于所有 $S  0$ 和 $\\varepsilon  0$ 都是非负且有限的。该界是紧的，意味着当 $|r_1 - r_2| = S$ 时，等式 $|B| = U(S, \\varepsilon)$ 成立，这种情况当且仅当 $r_1$ 或 $r_2$ 中有一个为零时发生。这是一个物理上可实现的情况（例如，$r_1 \\in (0, 1]$ 且 $r_2 = 0$）。\n\n**任务3：向量化计算的算法设计**\n\n实现将使用 `numpy` 库进行向量化，以高效地对栅格数组执行逐元素操作。\n\n对于每个测试用例，包含数组 $R_1$、$R_2$ 和标量 $\\varepsilon$：\n1.  计算逐元素的和 $S = R_1 + R_2$ 与差 $D = R_1 - R_2$。\n2.  使用数值稳定的、已推导的闭式表达式计算偏差数组 $B$：$B = -\\varepsilon D / (S(S + \\varepsilon))$。这可以避免直接计算 $I_{reg} - I_{unreg}$ 时可能出现的相减抵消问题。\n3.  计算偏差幅值数组 $|B| = \\text{abs}(B)$。\n4.  计算上界数组 $U = \\varepsilon / (S + \\varepsilon)$。\n5.  在每个像素点验证上界。使用数值容差 $\\delta = 10^{-12}$，一个像素点验证成功的条件是 $|B| \\le U + \\delta$。通过此比较生成一个布尔数组。\n6.  如果该条件对所有像素都成立，则认为该测试用例的整体上界验证成功。这可以通过对上一步的布尔数组应用全称量词（`np.all`）来确定。\n7.  该测试用例所需的三个输出量是：\n    a. 最大绝对偏差：$\\max(|B|)$。\n    b. 平均有符号偏差：$\\text{mean}(B)$。\n    c. 上界验证的整体布尔结果。\n对每个测试用例重复这些步骤，并将结果汇总以供最终输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the raster algebra problem by calculating bias and verifying bounds.\n    \"\"\"\n    \n    test_cases = [\n        (\n            [0.62, 0.18, 0.47, 0.33, 0.70],\n            [0.21, 0.35, 0.43, 0.12, 0.40],\n            1e-3\n        ),\n        (\n            [1e-6, 3e-4, 5e-3, 2e-2],\n            [2e-6, 8e-4, 5e-3, 1e-2],\n            1e-3\n        ),\n        (\n            [1e-6, 1e-3, 1e-1, 5e-1],\n            [1e-6, 1e-3, 1e-1, 5e-1],\n            1e-3\n        ),\n        (\n            [1.0, 0.0, 0.9, 2e-2, 0.6],\n            [0.0, 1.0, 0.1, 1e-2, 0.35],\n            5e-2\n        )\n    ]\n    \n    delta = 1e-12\n    all_results = []\n    \n    for r1_list, r2_list, epsilon in test_cases:\n        # Convert input lists to numpy arrays for vectorized operations\n        R1 = np.array(r1_list, dtype=float)\n        R2 = np.array(r2_list, dtype=float)\n\n        # Task 1: Compute bias using the derived closed-form expression\n        # This is more numerically stable than subtracting the indices directly.\n        S = R1 + R2  # Element-wise sum\n        D = R1 - R2  # Element-wise difference\n        \n        # Guard against division by zero in the unlikely case S is zero\n        # The problem statement guarantees S > 0 in the test data.\n        # This is for general robustness.\n        # bias = np.divide(-epsilon * D, S * (S + epsilon), where=S>0, out=np.zeros_like(S))\n        bias = -epsilon * D / (S * (S + epsilon))\n        \n        # Task 2: Compute upper bound and verify\n        abs_bias = np.abs(bias)\n        \n        # Bound U(S, epsilon) = epsilon / (S + epsilon)\n        bound = epsilon / (S + epsilon)\n        \n        # Task 3: Verification with tolerance\n        is_bound_satisfied_all_pixels = np.all(abs_bias = bound + delta)\n\n        # Compute required output statistics\n        max_abs_bias = np.max(abs_bias)\n        mean_signed_bias = np.mean(bias)\n        \n        # Append results for the current test case\n        all_results.append([max_abs_bias, mean_signed_bias, bool(is_bound_satisfied_all_pixels)])\n\n    # Format the final output string as a list of lists.\n    # The str() representation of a list of lists matches the required spacing and format.\n    # The problem example shows lowercase booleans, but python's default is capitalized.\n    # We will produce standard Python string representation, which is unambiguous.\n    # The problem prompt is a bit ambiguous on this formatting detail, so we choose\n    # the most direct and standard Python representation.\n    print(str(all_results).replace(\"True\", \"true\").replace(\"False\", \"false\"))\n\nsolve()\n\n```"
        }
    ]
}