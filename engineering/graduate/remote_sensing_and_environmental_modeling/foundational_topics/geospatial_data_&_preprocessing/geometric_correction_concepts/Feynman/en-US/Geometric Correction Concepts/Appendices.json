{
    "hands_on_practices": [
        {
            "introduction": "Understanding geometric distortions is the first step toward correcting them. This exercise focuses on a primary source of error in non-nadir imagery: relief displacement, where an object's height causes its top to appear shifted relative to its base. By deriving the displacement formula from the first principles of central perspective projection, you will gain a fundamental understanding of how terrain and man-made structures are distorted in raw imagery .",
            "id": "3815616",
            "problem": "A frame-imaging satellite acquires a vertical photograph over terrain that can be locally approximated by a horizontal reference plane. Model the imaging as a central perspective (pinhole) camera with focal length $f$ measured in pixel units, and adopt an image coordinate system in which the principal point is at the origin and radial distance from the principal point is measured in pixels. Let the satellite be at height $H$ above the reference plane along the camera’s optical axis. Consider a small, isolated feature of height $h$ above the reference plane. The base of the feature projects in the image at radial distance $r$ from the principal point.\n\nUsing only the central perspective projection relationship that an object point at distance $Z$ from the camera center along the optical axis and lateral ground offset $R$ projects to image radial coordinate $r = f R/Z$, derive from first principles an exact expression for the radial relief displacement in the image, defined as the outward radial shift between the projected positions of the feature’s top and base, in terms of $r$, $f$, $H$, and $h$. Then evaluate this displacement numerically for $h = 50\\,\\mathrm{m}$, $r = 2000\\,\\mathrm{px}$, $H = 600\\,\\mathrm{km}$, and $f = 1000\\,\\mathrm{px}$. Round your final numerical result to four significant figures. Express the answer in pixels.",
            "solution": "The problem asks for the derivation of an expression for radial relief displacement and its numerical evaluation. The problem is physically and mathematically well-defined, based on the principles of central perspective projection, and is therefore valid.\n\nWe begin from first principles. The imaging system is modeled as a pinhole camera, whose geometry is governed by similar triangles. Let the camera's center of projection (the pinhole) be the origin $O$. The optical axis is aligned with the $Z$-axis, and the image plane is parallel to the $XY$-plane at a distance $f$ from the origin. A point in object space with coordinates $(X, Y, Z)$ and a lateral offset from the optical axis $R = \\sqrt{X^2 + Y^2}$ is projected onto the image plane. The problem provides the projection relationship for the radial image coordinate $r$ as $r = f R/Z$, where $Z$ is the distance from the camera center to the object point along the optical axis. This relationship is a direct consequence of the similarity of triangles formed by the object point, the camera center, and their projections on the optical and image planes.\n\nFor a vertical photograph, the camera's optical axis is perpendicular to the reference plane. The satellite is at a height $H$ above this plane. We can set up a coordinate system where the camera center is at an altitude $H$ and the reference plane is at altitude $0$.\n\nLet's locate the base and the top of the feature in this system.\n\n1.  **The Base of the Feature:**\n    The base of the feature rests on the reference plane. Its height above this plane is $0$. The distance from the camera center to the plane containing the feature's base is therefore $Z_{\\text{base}} = H$.\n    Let the lateral ground offset of the feature's base from the axis of nadir be $R$. The problem states that the base projects to a radial distance $r$ in the image. Using the given projection formula:\n    $$r = \\frac{f R}{Z_{\\text{base}}} = \\frac{f R}{H}$$\n    This equation relates the known image coordinate $r$ to the unknown ground offset $R$. We can rearrange it to express $R$ in terms of the given quantities:\n    $$R = \\frac{rH}{f}$$\n\n2.  **The Top of the Feature:**\n    The feature has a height $h$. Assuming it is a vertical feature, its top is directly above its base, so it has the same lateral ground offset $R$. The height of the top above the reference plane is $h$.\n    The distance from the camera center to the plane containing the feature's top is $Z_{\\text{top}} = H - h$.\n    Let the radial distance of the projected top in the image be $r_{\\text{top}}$. Applying the projection formula again:\n    $$r_{\\text{top}} = \\frac{f R}{Z_{\\text{top}}} = \\frac{f R}{H - h}$$\n\n3.  **Derivation of Relief Displacement:**\n    Relief displacement, $\\Delta r$, is defined as the outward radial shift from the projected base to the projected top.\n    $$\\Delta r = r_{\\text{top}} - r$$\n    To express this in terms of the specified variables ($r$, $f$, $H$, and $h$), we substitute the expressions for $r_{\\text{top}}$ and $R$.\n    First, substitute the expression for $R$ from step 1 into the equation for $r_{\\text{top}}$:\n    $$r_{\\text{top}} = \\frac{f}{H - h} \\left( \\frac{rH}{f} \\right) = \\frac{rH}{H - h}$$\n    Note that the focal length $f$ has cancelled out. Now, we can calculate the displacement:\n    $$\\Delta r = \\frac{rH}{H - h} - r$$\n    Factoring out $r$:\n    $$\\Delta r = r \\left( \\frac{H}{H - h} - 1 \\right)$$\n    To simplify the expression in the parenthesis, we find a common denominator:\n    $$\\Delta r = r \\left( \\frac{H - (H - h)}{H - h} \\right) = r \\left( \\frac{H - H + h}{H - h} \\right)$$\n    This yields the final exact expression for the radial relief displacement:\n    $$\\Delta r = \\frac{rh}{H - h}$$\n    Although the problem requests the expression in terms of $r$, $f$, $H$, and $h$, the focal length $f$ is algebraically eliminated when relief displacement is expressed as a function of the image coordinate $r$. The focal length is fundamentally necessary to relate the image and object spaces, but it does not appear in this specific final relationship.\n\n4.  **Numerical Evaluation:**\n    We are given the following values:\n    $h = 50\\,\\mathrm{m}$\n    $r = 2000\\,\\mathrm{px}$\n    $H = 600\\,\\mathrm{km}$\n    $f = 1000\\,\\mathrm{px}$ (This value is not needed for the final calculation).\n\n    For the formula to be dimensionally consistent, $h$ and $H$ must be in the same units. We convert $H$ to meters:\n    $$H = 600\\,\\mathrm{km} = 600 \\times 1000\\,\\mathrm{m} = 600000\\,\\mathrm{m}$$\n    Now, substitute the numerical values into the derived expression for $\\Delta r$:\n    $$\\Delta r = \\frac{(2000\\,\\mathrm{px}) \\times (50\\,\\mathrm{m})}{600000\\,\\mathrm{m} - 50\\,\\mathrm{m}}$$\n    $$\\Delta r = \\frac{100000}{599950}\\,\\mathrm{px}$$\n    Performing the division:\n    $$\\Delta r \\approx 0.16667222\\,\\mathrm{px}$$\n    The problem requires the result to be rounded to four significant figures. The first four significant figures are $1$, $6$, $6$, $6$. The following digit is $7$, so we round up the last digit.\n    $$\\Delta r \\approx 0.1667\\,\\mathrm{px}$$",
            "answer": "$$\\boxed{0.1667}$$"
        },
        {
            "introduction": "Once a geometric correction model is defined, it provides a map from the distorted image grid to a correct georeferenced grid. To create the final corrected image, we must estimate the pixel values at these new grid locations, a process known as resampling. This practice will guide you through bilinear interpolation, a fundamental technique used to calculate new pixel values, ensuring the radiometric integrity of the geometrically corrected product .",
            "id": "3815691",
            "problem": "A spaceborne pushbroom imaging spectrometer acquires a radiometrically calibrated, atmospherically corrected surface reflectance image over a heterogeneous agricultural landscape. During geometric correction, the geodetic coordinates of a field parcel are mapped to the image grid using Rational Polynomial Coefficients (RPCs). For a particular location, the corrected image-plane coordinate is $(u,v)=(10.3,20.7)$, where the reflectance image is sampled on integer grid centers $(i,j)$ with unit spacing along both axes.\n\nAssume the following physically motivated base: the local reconstruction kernel can be modeled as separable along the $u$ and $v$ axes and the scene reflectance field is sufficiently smooth over a single pixel footprint so that linear interpolation along each axis is justified by the linearity of the local Point Spread Function (PSF). Under these assumptions, treat resampling as a two-stage one-dimensional linear interpolation process along $u$ and $v$.\n\nThe four nearest pixel-center reflectances (unitless fractions) are given at the integer coordinates:\n- $(10,20)$ has reflectance $0.12$,\n- $(11,20)$ has reflectance $0.18$,\n- $(10,21)$ has reflectance $0.30$,\n- $(11,21)$ has reflectance $0.42$.\n\nCompute the resampled reflectance at $(u,v)=(10.3,20.7)$ using the separable, locally linear resampling assumption described above. Round your answer to four significant figures. Express the final reflectance as a fraction (unitless).",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded, well-posed, objective, and contains all necessary information to arrive at a unique, meaningful solution. The problem describes a standard image processing task in remote sensing known as resampling, specifically using bilinear interpolation.\n\nThe task is to compute the resampled surface reflectance at an image-plane coordinate $(u, v) = (10.3, 20.7)$. The problem specifies that this can be treated as a two-stage one-dimensional linear interpolation process, which is equivalent to bilinear interpolation. The reflectance values are provided at the four nearest integer grid centers.\n\nLet $R(i, j)$ denote the reflectance at the integer grid coordinate $(i, j)$. The given data are:\n- $R(10, 20) = 0.12$\n- $R(11, 20) = 0.18$\n- $R(10, 21) = 0.30$\n- $R(11, 21) = 0.42$\n\nThe target coordinate is $(u, v) = (10.3, 20.7)$. We can define the integer and fractional parts of these coordinates. Let $i = \\lfloor u \\rfloor = 10$ and $j = \\lfloor v \\rfloor = 20$. The fractional distances from this origin point $(i, j)$ are:\n- $\\Delta u = u - i = 10.3 - 10 = 0.3$\n- $\\Delta v = v - j = 20.7 - 20 = 0.7$\n\nThe separable linear interpolation can be performed in two stages. First, we interpolate along the $u$-axis for the two bracketing integer $v$ coordinates, $j=20$ and $j+1=21$.\n\nStage 1: Linear interpolation along the $u$-axis.\nThe general formula for linear interpolation of a function $f(x)$ between points $(x_1, f(x_1))$ and $(x_2, f(x_2))$ is $f(x) = (1-\\alpha)f(x_1) + \\alpha f(x_2)$, where $\\alpha = \\frac{x-x_1}{x_2-x_1}$. In our case, the grid spacing is unity, so $x_2-x_1=1$ and the weighting factor $\\alpha$ is simply the fractional distance.\n\nFirst, we compute the interpolated reflectance at $(10.3, 20)$ using the values at $(10, 20)$ and $(11, 20)$. The fractional distance is $\\Delta u = 0.3$.\n$$R_{u1} = R(10.3, 20) = (1 - \\Delta u) R(10, 20) + \\Delta u R(11, 20)$$\n$$R_{u1} = (1 - 0.3) \\times 0.12 + 0.3 \\times 0.18$$\n$$R_{u1} = 0.7 \\times 0.12 + 0.3 \\times 0.18 = 0.084 + 0.054 = 0.138$$\n\nNext, we compute the interpolated reflectance at $(10.3, 21)$ using the values at $(10, 21)$ and $(11, 21)$.\n$$R_{u2} = R(10.3, 21) = (1 - \\Delta u) R(10, 21) + \\Delta u R(11, 21)$$\n$$R_{u2} = (1 - 0.3) \\times 0.30 + 0.3 \\times 0.42$$\n$$R_{u2} = 0.7 \\times 0.30 + 0.3 \\times 0.42 = 0.210 + 0.126 = 0.336$$\n\nStage 2: Linear interpolation along the $v$-axis.\nNow, we interpolate vertically between the two intermediate values $R_{u1} = 0.138$ at $(10.3, 20)$ and $R_{u2} = 0.336$ at $(10.3, 21)$ to find the final value at $(10.3, 20.7)$. The fractional distance is $\\Delta v = 0.7$.\n$$R(u, v) = R(10.3, 20.7) = (1 - \\Delta v) R_{u1} + \\Delta v R_{u2}$$\n$$R(10.3, 20.7) = (1 - 0.7) \\times 0.138 + 0.7 \\times 0.336$$\n$$R(10.3, 20.7) = 0.3 \\times 0.138 + 0.7 \\times 0.336$$\n$$R(10.3, 20.7) = 0.0414 + 0.2352 = 0.2766$$\n\nThe bilinearly interpolated reflectance at $(u,v)=(10.3, 20.7)$ is $0.2766$. This value has four significant figures, as requested by the problem statement. The order of interpolation (first along $u$ then $v$, or first along $v$ then $u$) does not affect the final result due to the linear and separable nature of the process. The calculation is complete.",
            "answer": "$$\\boxed{0.2766}$$"
        },
        {
            "introduction": "This comprehensive practice integrates the core task of geometric correction: fitting a mathematical model to relate image coordinates to map coordinates using a set of Ground Control Points (GCPs). You will implement a least squares solution to determine the parameters of an affine transformation, a widely used model for correcting satellite and aerial imagery. The exercise extends beyond simple model fitting to include a critical assessment of the model's quality by comparing predicted and empirical errors, demonstrating how the quality and distribution of GCPs impact the final accuracy .",
            "id": "3815685",
            "problem": "You are given three independent scenarios, each consisting of $12$ Ground Control Points (GCPs) with image coordinates $(x_i,y_i)$ and observed map coordinates $(X_i,Y_i)$. Assume an affine geometric correction model that linearly maps image coordinates to map coordinates. Your task is to:\n\n- Formulate the linear observation model for both axes and derive, from first principles under the classical Gauss–Markov framework, the least squares estimators of the affine parameters for the $X$-axis and $Y$-axis mappings.\n- From the estimator properties, derive the unbiased estimators of the residual variances, and the covariance matrices of the affine parameters for each axis.\n- Using the law of error propagation, predict the Root Mean Square Error (RMSE) of the residuals at the given design points by propagating the parameter covariances to the observation space at the provided $(x_i,y_i)$.\n- Compute the empirical RMSE of the residuals from the fitted model at the GCPs for comparison.\n\nFor each scenario, produce an output list of eight floating-point numbers:\n- The first six values are the affine parameters for the $X$-axis and $Y$-axis mappings, in the order $[a_0,a_1,a_2,b_0,b_1,b_2]$, where the affine models are $X = a_0 + a_1 x + a_2 y$ and $Y = b_0 + b_1 x + b_2 y$.\n- The next two values are the predicted RMSE (from parameter covariance propagation at the design points) and the empirical RMSE (from residuals), in this order.\n\nAll values should be rounded to six decimal places. No physical units are required. Angles do not appear. Percentages do not appear.\n\nFundamental base available for derivation:\n- Linear observation model with independent, homoscedastic errors.\n- Ordinary Least Squares under the Gauss–Markov assumptions.\n- Properties of least squares estimators, including unbiased variance estimation and parameter covariance.\n- Law of error propagation for linear functions.\n\nTest suite data for the three scenarios:\n\n- Scenario $1$ (well-distributed GCPs with small noise):\n    - Image coordinates $(x_i,y_i)$:\n        - $(x,y)$ list: $[(0,0),(100,0),(0,100),(100,100),(50,0),(0,50),(50,50),(150,50),(50,150),(150,150),(200,100),(100,200)]$\n    - Observed map coordinates $(X_i,Y_i)$:\n        - $[(500.8,-301.2),(699.5,-279.1),(551.1,-150.4),(749.3,-129.7),(600.3,-290.6),(524.0,-224.3),(625.2,-215.0),(824.6,-196.5),(675.0,-63.6),(875.6,-45.8),(949.1,-109.5),(800.4,18.9)]$\n\n- Scenario $2$ (near-collinear GCPs; ill-conditioned design):\n    - Image coordinates $(x_i,y_i)$ with $y_i \\approx 0.1 x_i$:\n        - $(x,y)$ list: $[(0,-0.5),(10,1.2),(20,1.9),(30,3.0),(40,4.3),(50,4.6),(60,6.1),(70,6.8),(80,8.5),(90,8.7),(100,10.2),(110,11.0)]$\n    - Observed map coordinates $(X_i,Y_i)$:\n        - $[(1000.35,-501.2),(1009.38,-497.0),(1020.21,-495.5),(1029.5,-492.0),(1039.67,-489.5),(1049.24,-488.1),(1059.39,-485.2),(1069.52,-482.9),(1079.05,-478.7),(1089.63,-478.7),(1098.58,-474.2),(1109.2,-472.3)]$\n\n- Scenario $3$ (well-distributed GCPs with larger noise):\n    - Image coordinates $(x_i,y_i)$:\n        - $(x,y)$ list: $[(0,0),(300,0),(0,300),(300,300),(150,0),(0,150),(150,150),(450,150),(150,450),(450,450),(600,300),(300,600)]$\n    - Observed map coordinates $(X_i,Y_i)$:\n        - $[(-193.5,792.0),(245.8,1015.7),(-286.7,1063.9),(153.0,1289.4),(33.2,900.4),(-250.1,942.3),(-15.3,1036.7),(426.4,1256.6),(-102.9,1304.8),(337.6,1528.8),(615.5,1482.3),(63.2,1560.5)]$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each scenario’s result is itself a comma-separated sublist enclosed in square brackets, and no spaces appear. For example, the structure must be:\n- $[[a_0,a_1,a_2,b_0,b_1,b_2,\\text{predRMSE},\\text{empRMSE}],[\\dots],[\\dots]]$",
            "solution": "The user-provided problem is valid. It is a well-posed, scientifically grounded problem in the field of geomatics and remote sensing, based on the fundamental principles of linear algebra and statistical estimation theory (Ordinary Least Squares). The data provided for all three scenarios are complete and sufficient for a unique solution, and the required derivations and computations are standard procedures in this discipline. The second scenario, while ill-conditioned, is a valid case for demonstrating the effects of poor geometric distribution of control points, a key concept in this domain.\n\n### 1. Theoretical Derivation\n\nThe problem requires performing an affine transformation to map image coordinates $(x,y)$ to map coordinates $(X,Y)$. The transformation is defined by two independent linear equations:\n$$\n\\begin{cases}\nX = a_0 + a_1 x + a_2 y \\\\\nY = b_0 + b_1 x + b_2 y\n\\end{cases}\n$$\nThese two equations can be solved independently using the method of Ordinary Least Squares (OLS). The derivation will be shown for the $X$-coordinate model, and the same logic applies to the $Y$-coordinate model.\n\n**Linear Observation Model for the X-coordinate**\n\nFor $N$ Ground Control Points (GCPs), we have a system of $N$ linear observation equations. For each point $i=1, \\dots, N$:\n$$\nX_i + v_{X,i} = a_0 + a_1 x_i + a_2 y_i\n$$\nwhere $X_i$ is the observed map coordinate and $v_{X,i}$ is the unknown random error or residual. The Gauss-Markov model assumes these errors are uncorrelated and have a constant variance, i.e., $E[v_{X,i}] = 0$ and $E[v_{X,i}^2] = \\sigma_X^2$, and $E[v_{X,i}v_{X,j}] = 0$ for $i \\neq j$.\n\nThis system can be written in matrix form as:\n$$\n\\mathbf{L}_X + \\mathbf{v}_X = \\mathbf{A} \\mathbf{p}_a\n$$\nwhere:\n- $\\mathbf{L}_X = [X_1, X_2, \\dots, X_N]^T$ is the $N \\times 1$ vector of observations.\n- $\\mathbf{v}_X = [v_{X,1}, v_{X,2}, \\dots, v_{X,N}]^T$ is the $N \\times 1$ vector of residuals.\n- $\\mathbf{p}_a = [a_0, a_1, a_2]^T$ is the $3 \\times 1$ vector of unknown affine parameters.\n- $\\mathbf{A}$ is the $N \\times 3$ design matrix, whose elements are the known image coordinates:\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & x_1 & y_1 \\\\\n1 & x_2 & y_2 \\\\\n\\vdots & \\vdots & \\vdots \\\\\n1 & x_N & y_N\n\\end{pmatrix}\n$$\nThe covariance matrix of the observations is $\\boldsymbol{\\Sigma}_{\\mathbf{L}_X \\mathbf{L}_X} = E[\\mathbf{v}_X \\mathbf{v}_X^T] = \\sigma_X^2 \\mathbf{I}$, where $\\mathbf{I}$ is the $N \\times N$ identity matrix.\n\n**Least Squares Estimation of Parameters**\n\nThe OLS principle seeks to find the estimate $\\hat{\\mathbf{p}}_a$ that minimizes the sum of squared residuals, $S = \\mathbf{v}_X^T \\mathbf{v}_X$.\n$$\nS = (\\mathbf{A} \\mathbf{p}_a - \\mathbf{L}_X)^T (\\mathbf{A} \\mathbf{p}_a - \\mathbf{L}_X)\n$$\nTo find the minimum, we differentiate $S$ with respect to $\\mathbf{p}_a$ and set the derivative to zero:\n$$\n\\frac{\\partial S}{\\partial \\mathbf{p}_a} = 2 \\mathbf{A}^T (\\mathbf{A} \\hat{\\mathbf{p}}_a - \\mathbf{L}_X) = \\mathbf{0}\n$$\nThis leads to the **normal equations**:\n$$\n(\\mathbf{A}^T \\mathbf{A}) \\hat{\\mathbf{p}}_a = \\mathbf{A}^T \\mathbf{L}_X\n$$\nAssuming the matrix $\\mathbf{A}^T \\mathbf{A}$ is invertible (which requires the GCPs to not be collinear, i.e., $\\mathbf{A}$ has full column rank $p=3$), the least squares estimator for the parameters is:\n$$\n\\hat{\\mathbf{p}}_a = (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{L}_X\n$$\nSimilarly, for the $Y$-coordinate parameters $\\mathbf{p}_b = [b_0, b_1, b_2]^T$, the estimator is:\n$$\n\\hat{\\mathbf{p}}_b = (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{L}_Y\n$$\nwhere $\\mathbf{L}_Y = [Y_1, Y_2, \\dots, Y_N]^T$.\n\n**Residual Variance and Parameter Covariance**\n\nThe vector of estimated residuals is $\\hat{\\mathbf{v}}_X = \\mathbf{A} \\hat{\\mathbf{p}}_a - \\mathbf{L}_X$. The sum of squared residuals (SSR) is $\\text{SSR}_X = \\hat{\\mathbf{v}}_X^T \\hat{\\mathbf{v}}_X$.\nThe expected value of the SSR is $E[\\text{SSR}_X] = (N-p)\\sigma_X^2$, where $p=3$ is the number of parameters. The quantity $r = N-p$ is the degrees of freedom of the adjustment.\n\nThe **unbiased estimator of the residual variance** $\\sigma_X^2$ is:\n$$\n\\hat{\\sigma}_X^2 = \\frac{\\text{SSR}_X}{N-p}\n$$\nThe **covariance matrix of the estimated parameters** $\\hat{\\mathbf{p}}_a$ is derived using the law of propagation of variances on the estimator equation $\\hat{\\mathbf{p}}_a = (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{L}_X$:\n$$\n\\boldsymbol{\\Sigma}_{\\hat{\\mathbf{p}}_a \\hat{\\mathbf{p}}_a} = \\left[(\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T\\right] \\boldsymbol{\\Sigma}_{\\mathbf{L}_X \\mathbf{L}_X} \\left[(\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T\\right]^T = \\sigma_X^2 (\\mathbf{A}^T \\mathbf{A})^{-1}\n$$\nSince $\\sigma_X^2$ is unknown, we use its estimate $\\hat{\\sigma}_X^2$ to obtain the estimated covariance matrix:\n$$\n\\hat{\\boldsymbol{\\Sigma}}_{\\hat{\\mathbf{p}}_a \\hat{\\mathbf{p}}_a} = \\hat{\\sigma}_X^2 (\\mathbf{A}^T \\mathbf{A})^{-1}\n$$\n\n### 2. RMSE Calculation\n\n**Empirical RMSE**\n\nThe empirical Root Mean Square Error measures the actual misfit of the model to the data points. For each point $i$, the squared residual error is $e_i^2 = \\hat{v}_{X,i}^2 + \\hat{v}_{Y,i}^2$. The empirical RMSE is the square root of the mean of these squared errors over all $N$ points:\n$$\n\\text{RMSE}_{\\text{emp}} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (\\hat{v}_{X,i}^2 + \\hat{v}_{Y,i}^2)} = \\sqrt{\\frac{\\text{SSR}_X + \\text{SSR}_Y}{N}}\n$$\n\n**Predicted RMSE**\n\nThe predicted RMSE is derived by propagating the parameter uncertainties to the observation space. The variance of a single predicted coordinate, e.g., $\\hat{X}_i = \\mathbf{a}_i^T \\hat{\\mathbf{p}}_a$ (where $\\mathbf{a}_i^T = [1, x_i, y_i]$ is the $i$-th row of $\\mathbf{A}$), is given by:\n$$\n\\text{Var}(\\hat{X}_i) = \\mathbf{a}_i^T \\boldsymbol{\\Sigma}_{\\hat{\\mathbf{p}}_a \\hat{\\mathbf{p}}_a} \\mathbf{a}_i = \\sigma_X^2 \\, \\mathbf{a}_i^T (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{a}_i = \\sigma_X^2 h_{ii}\n$$\nwhere $h_{ii}$ is the $i$-th diagonal element of the \"hat\" matrix $\\mathbf{H} = \\mathbf{A}(\\mathbf{A}^T \\mathbf{A})^{-1}\\mathbf{A}^T$. The value $h_{ii}$ is the leverage of the $i$-th observation.\n\nThe predicted RMSE is the root mean square of the standard errors of the fitted values over the design points. The mean predicted variance for a point (summing X and Y components) is:\n$$\n\\frac{1}{N} \\sum_{i=1}^N \\left[ \\text{Var}(\\hat{X}_i) + \\text{Var}(\\hat{Y}_i) \\right] = \\frac{1}{N} \\sum_{i=1}^N \\left[ \\sigma_X^2 h_{ii} + \\sigma_Y^2 h_{ii} \\right] = \\frac{\\sigma_X^2 + \\sigma_Y^2}{N} \\sum_{i=1}^N h_{ii}\n$$\nThe sum of the leverages is the trace of the hat matrix, $\\text{tr}(\\mathbf{H}) = p = 3$. Therefore, the average predicted variance is $\\frac{p}{N}(\\sigma_X^2 + \\sigma_Y^2)$.\nThe predicted RMSE is the square root of this quantity, using the estimates $\\hat{\\sigma}_X^2$ and $\\hat{\\sigma}_Y^2$:\n$$\n\\text{RMSE}_{\\text{pred}} = \\sqrt{\\frac{p}{N}(\\hat{\\sigma}_X^2 + \\hat{\\sigma}_Y^2)} = \\sqrt{\\frac{p}{N} \\left( \\frac{\\text{SSR}_X}{N-p} + \\frac{\\text{SSR}_Y}{N-p} \\right)} = \\sqrt{\\frac{p (\\text{SSR}_X + \\text{SSR}_Y)}{N(N-p)}}\n$$\n\n### 3. Computational Procedure\nFor each scenario:\n1. Set $N=12$ and $p=3$. The degrees of freedom is $df = N-p=9$.\n2. Form the $12 \\times 3$ design matrix $\\mathbf{A}$ from the image coordinates $(x_i, y_i)$.\n3. Form the $12 \\times 1$ observation vectors $\\mathbf{L}_X$ and $\\mathbf{L}_Y$ from the map coordinates $(X_i, Y_i)$.\n4. Compute the normal matrix $\\mathbf{N} = \\mathbf{A}^T \\mathbf{A}$ and the vectors $\\mathbf{c}_X = \\mathbf{A}^T \\mathbf{L}_X$ and $\\mathbf{c}_Y = \\mathbf{A}^T \\mathbf{L}_Y$.\n5. Solve the linear systems $\\mathbf{N} \\hat{\\mathbf{p}}_a = \\mathbf{c}_X$ and $\\mathbf{N} \\hat{\\mathbf{p}}_b = \\mathbf{c}_Y$ to get the parameter vectors $\\hat{\\mathbf{p}}_a = [a_0, a_1, a_2]^T$ and $\\hat{\\mathbf{p}}_b = [b_0, b_1, b_2]^T$.\n6. Compute the residual vectors $\\hat{\\mathbf{v}}_X = \\mathbf{A} \\hat{\\mathbf{p}}_a - \\mathbf{L}_X$ and $\\hat{\\mathbf{v}}_Y = \\mathbf{A} \\hat{\\mathbf{p}}_b - \\mathbf{L}_Y$.\n7. Compute the sums of squared residuals $\\text{SSR}_X = \\hat{\\mathbf{v}}_X^T \\hat{\\mathbf{v}}_X$ and $\\text{SSR}_Y = \\hat{\\mathbf{v}}_Y^T \\hat{\\mathbf{v}}_Y$. Let $\\text{SSR}_{\\text{total}} = \\text{SSR}_X + \\text{SSR}_Y$.\n8. Compute $\\text{RMSE}_{\\text{pred}} = \\sqrt{\\frac{p \\cdot \\text{SSR}_{\\text{total}}}{N \\cdot df}} = \\sqrt{\\frac{3 \\cdot \\text{SSR}_{\\text{total}}}{12 \\cdot 9}} = \\sqrt{\\frac{\\text{SSR}_{\\text{total}}}{36}}$.\n9. Compute $\\text{RMSE}_{\\text{emp}} = \\sqrt{\\frac{\\text{SSR}_{\\text{total}}}{N}} = \\sqrt{\\frac{\\text{SSR}_{\\text{total}}}{12}}$.\n10. Assemble the final list of 8 floating point numbers, rounded to six decimal places.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are permitted, as scipy is not needed for this solution.\n\ndef solve():\n    \"\"\"\n    Solves the affine transformation problem for three scenarios using Ordinary Least Squares.\n    \"\"\"\n\n    test_cases = [\n        # Scenario 1 (well-distributed GCPs with small noise)\n        {\n            \"img_coords\": np.array([\n                [0, 0], [100, 0], [0, 100], [100, 100], [50, 0], [0, 50],\n                [50, 50], [150, 50], [50, 150], [150, 150], [200, 100], [100, 200]\n            ]),\n            \"map_coords\": np.array([\n                [500.8, -301.2], [699.5, -279.1], [551.1, -150.4], [749.3, -129.7],\n                [600.3, -290.6], [524.0, -224.3], [625.2, -215.0], [824.6, -196.5],\n                [675.0, -63.6], [875.6, -45.8], [949.1, -109.5], [800.4, 18.9]\n            ])\n        },\n        # Scenario 2 (near-collinear GCPs; ill-conditioned design)\n        {\n            \"img_coords\": np.array([\n                [0, -0.5], [10, 1.2], [20, 1.9], [30, 3.0], [40, 4.3], [50, 4.6],\n                [60, 6.1], [70, 6.8], [80, 8.5], [90, 8.7], [100, 10.2], [110, 11.0]\n            ]),\n            \"map_coords\": np.array([\n                [1000.35, -501.2], [1009.38, -497.0], [1020.21, -495.5], [1029.5, -492.0],\n                [1039.67, -489.5], [1049.24, -488.1], [1059.39, -485.2], [1069.52, -482.9],\n                [1079.05, -478.7], [1089.63, -478.7], [1098.58, -474.2], [1109.2, -472.3]\n            ])\n        },\n        # Scenario 3 (well-distributed GCPs with larger noise)\n        {\n            \"img_coords\": np.array([\n                [0, 0], [300, 0], [0, 300], [300, 300], [150, 0], [0, 150],\n                [150, 150], [450, 150], [150, 450], [450, 450], [600, 300], [300, 600]\n            ]),\n            \"map_coords\": np.array([\n                [-193.5, 792.0], [245.8, 1015.7], [-286.7, 1063.9], [153.0, 1289.4],\n                [33.2, 900.4], [-250.1, 942.3], [-15.3, 1036.7], [426.4, 1256.6],\n                [-102.9, 1304.8], [337.6, 1528.8], [615.5, 1482.3], [63.2, 1560.5]\n            ])\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        img_coords = case[\"img_coords\"]\n        map_coords = case[\"map_coords\"]\n        \n        N = img_coords.shape[0]  # Number of observations (GCPs)\n        p = 3  # Number of parameters (a0, a1, a2)\n        df = N - p # Degrees of freedom\n\n        # Construct the design matrix A\n        A = np.ones((N, p))\n        A[:, 1] = img_coords[:, 0]  # x coordinates\n        A[:, 2] = img_coords[:, 1]  # y coordinates\n\n        # Construct the observation vectors L_X and L_Y\n        L_X = map_coords[:, 0]\n        L_Y = map_coords[:, 1]\n        \n        # Form the normal equations: (A^T A) p = A^T L\n        N_matrix = A.T @ A\n        c_X = A.T @ L_X\n        c_Y = A.T @ L_Y\n        \n        # Solve for the parameter vectors p_a and p_b\n        try:\n            # np.linalg.solve is numerically more stable than using np.linalg.inv\n            p_a = np.linalg.solve(N_matrix, c_X)\n            p_b = np.linalg.solve(N_matrix, c_Y)\n        except np.linalg.LinAlgError:\n            # Fallback for singular matrix, although not expected with test data\n            inv_N = np.linalg.pinv(N_matrix)\n            p_a = inv_N @ c_X\n            p_b = inv_N @ c_Y\n            \n        a0, a1, a2 = p_a\n        b0, b1, b2 = p_b\n        \n        # Calculate residuals\n        v_X = A @ p_a - L_X\n        v_Y = A @ p_b - L_Y\n        \n        # Calculate Sum of Squared Residuals (SSR)\n        ssr_X = v_X.T @ v_X\n        ssr_Y = v_Y.T @ v_Y\n        ssr_total = ssr_X + ssr_Y\n        \n        # Calculate predicted RMSE from parameter covariance propagation\n        # RMSE_pred = sqrt( (p/N) * (sigma_hat_X^2 + sigma_hat_Y^2) )\n        #           = sqrt( (p/N) * (SSR_X/df + SSR_Y/df) )\n        #           = sqrt( p * (SSR_X + SSR_Y) / (N * df) )\n        if df > 0:\n            rmse_pred = np.sqrt(p * ssr_total / (N * df))\n        else:\n            rmse_pred = 0.0\n\n        # Calculate empirical RMSE from residuals\n        # RMSE_emp = sqrt( (1/N) * sum(v_Xi^2 + v_Yi^2) )\n        #          = sqrt( (SSR_X + SSR_Y) / N )\n        rmse_emp = np.sqrt(ssr_total / N)\n        \n        # Format results\n        scenario_result = [a0, a1, a2, b0, b1, b2, rmse_pred, rmse_emp]\n        rounded_result = [round(val, 6) for val in scenario_result]\n        all_results.append(rounded_result)\n\n    # Format the final output string exactly as required\n    output_str = \"[\"\n    for i, res in enumerate(all_results):\n        output_str += f\"[{','.join(map(str, res))}]\"\n        if i < len(all_results) - 1:\n            output_str += \",\"\n    output_str += \"]\"\n            \n    print(output_str)\n\nsolve()\n```"
        }
    ]
}