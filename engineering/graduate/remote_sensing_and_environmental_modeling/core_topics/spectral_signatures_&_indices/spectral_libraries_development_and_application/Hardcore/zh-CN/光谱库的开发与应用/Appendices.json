{
    "hands_on_practices": [
        {
            "introduction": "在现实世界中，光谱测量总是会受到仪器噪声的干扰，这些噪声可能会掩盖对物质识别至关重要的诊断性吸收特征。虽然像 Savitzky-Golay 这样的平滑滤波器可以有效降噪，但它们也可能扭曲或削弱我们试图研究的光谱特征，这是一个需要权衡的经典问题。 这项动手实践将让您通过编程来量化评估这一权衡，您将构建一个合成光谱，并测试不同滤波器参数对窄吸收特征保留的影响，从而掌握数据预处理中的关键决策技能。",
            "id": "3853543",
            "problem": "您的任务是设计并执行一项定量评估，分析 Savitzky–Golay (SG) 滤波如何影响用于遥感和环境建模的光谱库中的反射光谱的窄吸收特征保留情况。该评估必须在一条科学上合理且基于第一性原理构建的合成光谱上进行。最终程序必须计算指定 SG 滤波器配置下的特征衰减的量化指标，并将结果以单行、机器可读的格式输出。所有波长值必须以纳米 (nm) 为单位处理。所有衰减值必须表示为四舍五入到 $6$ 位小数的小数。\n\n请从以下基础和定义开始：\n\n1. 构建一个波长轴 $\\lambda$，从 $400$ nm 到 $800$ nm 均匀采样，步长为 $1$ nm。将 $\\lambda$ 表示为以纳米为单位的整数网格 $\\{400, 401, \\dots, 800\\}$。\n\n2. 通过以下公式定义一个平滑、缓慢变化的连续统反射率 $R_{\\text{cont}}(\\lambda)$：\n$$\nR_{\\text{cont}}(\\lambda) = 0.3 + 0.0002\\left(\\lambda - 400\\right) + 0.03 \\sin\\left( \\frac{2\\pi}{300} \\left(\\lambda - 400\\right) \\right).\n$$\n这是一个无量纲的反射率模型，包含一个线性斜率和一个宽的正弦分量。\n\n3. 叠加一个中心位于 $\\lambda_0 = 550$ nm 的窄吸收特征，该特征具有高斯形状、小数深度 $A = 0.12$ 和标准差 $\\sigma_\\lambda = 2$ nm，得到特征调制\n$$\nM(\\lambda) = 1 - A \\exp\\left(-\\frac{\\left(\\lambda - \\lambda_0\\right)^2}{2\\sigma_\\lambda^2}\\right).\n$$\n\n4. 将加性仪器噪声 $\\epsilon(\\lambda)$ 建模为均值为零、标准差为 $\\sigma_\\epsilon = 0.005$ 的独立同分布高斯随机变量，即 $\\epsilon(\\lambda) \\sim \\mathcal{N}\\left(0, \\sigma_\\epsilon^2\\right)$。将随机种子固定为 $42$ 以确保可复现性。\n\n5. 观测到的反射光谱定义为\n$$\nR(\\lambda) = R_{\\text{cont}}(\\lambda) \\cdot M(\\lambda) + \\epsilon(\\lambda).\n$$\n\n6. 使用连接 $\\lambda_L = 535$ nm 和 $\\lambda_R = 565$ nm 处两个肩部的线性连续统 $C(\\lambda)$ 来定义特征周围的连续统去除。对于任何信号 $S(\\lambda)$（无论是 $R(\\lambda)$ 还是其滤波版本），构建\n$$\nC_S(\\lambda) = S(\\lambda_L) + \\left(\\lambda - \\lambda_L\\right) \\cdot \\frac{S(\\lambda_R) - S(\\lambda_L)}{\\lambda_R - \\lambda_L}.\n$$\n信号 $S$ 在特征中心的连续统去除深度则为\n$$\nd_S = 1 - \\frac{S(\\lambda_0)}{C_S(\\lambda_0)}.\n$$\n\n7. 窗口长度为 $W$（奇数）和多项式阶数为 $P$ 的 Savitzky–Golay (SG) 滤波器是一种局部最小二乘多项式平滑器：在每个包含 $W$ 个样本的窗口内，找到一个 $P$ 次多项式的系数，使其与数据的平方误差最小化，并使用该多项式在窗口中心的值作为滤波输出。对每个测试用例 $(W,P)$，将 SG 滤波器应用于 $R(\\lambda)$ 以生成 $R_f^{(W,P)}(\\lambda)$。\n\n8. 通过平滑处理导致的特征深度的小数损失来定义每个测试用例 $(W,P)$ 的衰减度量：\n$$\na^{(W,P)} = \\frac{d_{R} - d_{R_f^{(W,P)}}}{d_{R}},\n$$\n其中 $d_R$ 是从原始带噪光谱 $R(\\lambda)$ 计算的深度，而 $d_{R_f^{(W,P)}}$ 是从滤波后光谱 $R_f^{(W,P)}(\\lambda)$ 计算的深度。正值表示特征的衰减（损失）；负值表示由于噪声抑制而产生的明显增强。\n\n您的程序必须实现 $R(\\lambda)$ 的构建，为每个测试用例应用 SG 滤波器，计算 $a^{(W,P)}$，并以确切指定的格式打印结果。不允许任何外部输入。\n\n测试套件：\n- 用例 1：$(W,P) = (7,2)$\n- 用例 2：$(W,P) = (21,2)$\n- 用例 3：$(W,P) = (11,4)$\n- 用例 4：$(W,P) = (5,4)$\n- 用例 5：$(W,P) = (51,3)$\n\n约束条件：\n- $W$ 必须是严格大于 $P$ 的奇数。\n- 所有计算都在以纳米为单位定义的波长网格上进行。\n- 反射率是无量纲的。\n\n答案规格：\n- 对于每个测试用例，计算 $a^{(W,P)}$ 并四舍五入到 $6$ 位小数。\n- 您的程序应生成单行输出，其中包含按测试套件顺序排列的结果，格式为逗号分隔的列表，并用方括号括起来，例如，“[a1,a2,a3,a4,a5]”。",
            "solution": "在尝试求解之前，首先对问题陈述的有效性进行评估。\n\n**问题验证**\n\n1.  **提取已知条件**：\n    -   波长轴：$\\lambda$ 是一个从 $400$ nm 到 $800$ nm 的均匀整数网格，即 $\\lambda \\in \\{400, 401, \\dots, 800\\}$。\n    -   连续统反射率模型：$R_{\\text{cont}}(\\lambda) = 0.3 + 0.0002\\left(\\lambda - 400\\right) + 0.03 \\sin\\left( \\frac{2\\pi}{300} \\left(\\lambda - 400\\right) \\right)$。\n    -   吸收特征调制：$M(\\lambda) = 1 - A \\exp\\left(-\\frac{\\left(\\lambda - \\lambda_0\\right)^2}{2\\sigma_\\lambda^2}\\right)$，中心为 $\\lambda_0 = 550$ nm，小数深度 $A = 0.12$，标准差 $\\sigma_\\lambda = 2$ nm。\n    -   加性噪声模型：$\\epsilon(\\lambda) \\sim \\mathcal{N}\\left(0, \\sigma_\\epsilon^2\\right)$，其中 $\\sigma_\\epsilon = 0.005$。随机种子固定为 $42$。\n    -   观测反射率模型：$R(\\lambda) = R_{\\text{cont}}(\\lambda) \\cdot M(\\lambda) + \\epsilon(\\lambda)$。\n    -   连续统去除：在线性连续统 $C_S(\\lambda)$ 在肩部波长 $\\lambda_L = 535$ nm 和 $\\lambda_R = 565$ nm 之间定义。\n    -   特征深度定义：$d_S = 1 - \\frac{S(\\lambda_0)}{C_S(\\lambda_0)}$。\n    -   Savitzky-Golay (SG) 滤波器应用：将窗口长度为 $W$、多项式阶数为 $P$ 的滤波器应用于 $R(\\lambda)$ 以得到 $R_f^{(W,P)}(\\lambda)$。\n    -   衰减度量：$a^{(W,P)} = \\frac{d_{R} - d_{R_f^{(W,P)}}}{d_{R}}$。\n    -   测试套件：$(W,P)$ 对为 $(7,2)$、$(21,2)$、$(11,4)$、$(5,4)$ 和 $(51,3)$。\n    -   约束条件：$W$ 必须是奇数且 $W > P$。\n\n2.  **使用提取的已知条件进行验证**：\n    -   **科学依据**：该问题在光谱学和信号处理原理方面有充分的依据。通过连续统、吸收特征和噪声构建合成光谱是遥感领域测试算法的标准方法。Savitzky-Golay 滤波器和线性连续统去除是成熟且广泛使用的技术。\n    -   **适定性**：问题被完全指定，提供了所有必要的方程、参数和程序步骤。使用固定的随机种子确保了唯一且可复现的解。\n    -   **客观性**：问题陈述使用精确、数学和客观的语言，不含任何主观因素。\n    -   **完整性与一致性**：定义是自洽的。提供的测试用例，例如 $(W,P) = (5,4)$，满足指定的约束条件（$5$ 是奇数且 $5>4$）。问题是完整的，不包含任何矛盾。\n\n3.  **结论与行动**：\n    -   问题被判定为**有效**。将逐步制定解决方案。\n\n**求解推导**\n\n解决方案需要实现一个计算工作流，以量化 Savitzky-Golay (SG) 滤波如何影响一个窄光谱吸收特征。该过程分解为以下步骤。\n\n**第 1 步：合成光谱生成**\n首先，我们构建合成反射光谱。这为我们的分析提供了一个受控信号。波长轴 $\\lambda$ 被定义为从 $400$ nm 到 $800$ nm 的均匀整数网格。\n$$ \\lambda = \\{400, 401, \\dots, 800\\} $$\n使用指定方程为 $\\lambda$ 中的每个波长计算平滑、缓慢变化的连续统反射率 $R_{\\text{cont}}(\\lambda)$：\n$$ R_{\\text{cont}}(\\lambda) = 0.3 + 0.0002\\left(\\lambda - 400\\right) + 0.03 \\sin\\left( \\frac{2\\pi}{300} \\left(\\lambda - 400\\right) \\right) $$\n在此连续统上叠加一个单一的高斯吸收特征。该特征由一个乘性调制因子 $M(\\lambda)$ 描述，该因子由其中心 $\\lambda_0 = 550$ nm、小数深度 $A = 0.12$ 和标准差 $\\sigma_\\lambda = 2$ nm 决定。\n$$ M(\\lambda) = 1 - A \\exp\\left(-\\frac{\\left(\\lambda - \\lambda_0\\right)^2}{2\\sigma_\\lambda^2}\\right) $$\n为了模拟真实的测量，生成了加性仪器噪声 $\\epsilon(\\lambda)$。为保证可复现性，伪随机数生成器使用值 $42$ 进行播种。每个波长的噪声都是从均值为 $0$、标准差为 $\\sigma_\\epsilon = 0.005$ 的正态分布中独立抽取的。\n最终观测到的反射光谱 $R(\\lambda)$ 是这三个分量的组合：\n$$ R(\\lambda) = R_{\\text{cont}}(\\lambda) \\cdot M(\\lambda) + \\epsilon(\\lambda) $$\n\n**第 2 步：特征深度计算**\n吸收特征的量化需要测量其相对于局部连续统的深度。这是定量光谱学中的一个标准程序。对于任何给定的光谱 $S(\\lambda)$，通过连接两个肩部点 $\\lambda_L = 535$ nm 和 $\\lambda_R = 565$ nm 处的光谱值来建立线性连续统 $C_S(\\lambda)$。\n$$ C_S(\\lambda) = S(\\lambda_L) + \\left(\\lambda - \\lambda_L\\right) \\cdot \\frac{S(\\lambda_R) - S(\\lambda_L)}{\\lambda_R - \\lambda_L} $$\n然后，在特征中心 $\\lambda_0 = 550$ nm 处计算特征的连续统去除深度 $d_S$。其定义为\n$$ d_S = 1 - \\frac{S(\\lambda_0)}{C_S(\\lambda_0)} $$\n该度量提供了特征强度的归一化测量。此计算首先应用于原始带噪光谱 $R(\\lambda)$，以建立基线特征深度 $d_R$。\n\n**第 3 步：应用 Savitzky–Golay 滤波器**\n对于由窗口长度 $W$ 和多项式阶数 $P$ 定义的每个测试用例，将 SG 滤波器应用于整个带噪光谱 $R(\\lambda)$。SG 滤波器是一种局部多项式回归平滑器，能有效减少高频噪声，同时比简单的移动平均更好地保留光谱特征的总体形状。滤波操作会生成一个新的、平滑后的光谱，表示为 $R_f^{(W,P)}(\\lambda)$。\n\n**第 4 步：衰减测量**\n滤波后，使用与第 2 步完全相同的连续统去除和深度计算程序，为平滑后的光谱 $R_f^{(W,P)}(\\lambda)$ 重新计算特征深度。这得到滤波后的深度 $d_{R_f^{(W,P)}}$。\n衰减 $a^{(W,P)}$ 是此问题的关键度量。它量化了由滤波过程导致的特征深度的小数损失。其计算公式为：\n$$ a^{(W,P)} = \\frac{d_{R} - d_{R_f^{(W,P)}}}{d_{R}} $$\n正值表示衰减（特征变浅），这是对一个比滤波器窗口窄的特征应用平滑滤波器时的预期结果。负值则表示特征深度的明显增强。\n\n**第 5 步：执行与格式化**\n执行该过程时，首先计算参考光谱 $R(\\lambda)$ 及其深度 $d_R$。然后，对于测试套件中的每个 $(W,P)$ 对——$(7,2)$、$(21,2)$、$(11,4)$、$(5,4)$ 和 $(51,3)$——生成相应的滤波光谱 $R_f^{(W,P)}(\\lambda)$，计算其深度 $d_{R_f^{(W,P)}}$，并确定衰减 $a^{(W,P)}$。将每个得到的衰减值四舍五入到 $6$ 位小数。最后，将结果列表格式化为指定的单行字符串。",
            "answer": "```python\nimport numpy as np\nfrom scipy.signal import savgol_filter\n\ndef solve():\n    \"\"\"\n    Computes the attenuation of a synthetic spectral feature due to Savitzky-Golay\n    filtering for a set of filter parameters.\n    \"\"\"\n    \n    # Step 1: Define constants and generate the synthetic spectrum\n    \n    # Wavelength grid and feature parameters\n    lambdas = np.arange(400, 801, dtype=np.float64)\n    lambda_0 = 550.0\n    A = 0.12\n    sigma_lambda = 2.0\n    \n    # Noise parameters\n    sigma_eps = 0.005\n    seed = 42\n    \n    # Continuum removal parameters\n    lambda_L = 535.0\n    lambda_R = 565.0\n\n    # Map specific wavelengths to their corresponding array indices\n    # index = wavelength - start_wavelength\n    idx_0 = int(lambda_0 - lambdas[0])\n    idx_L = int(lambda_L - lambdas[0])\n    idx_R = int(lambda_R - lambdas[0])\n\n    # Construct the continuum reflectance\n    R_cont = 0.3 + 0.0002 * (lambdas - 400.0) + 0.03 * np.sin((2 * np.pi / 300.0) * (lambdas - 400.0))\n\n    # Construct the feature modulation\n    M = 1.0 - A * np.exp(-((lambdas - lambda_0)**2) / (2.0 * sigma_lambda**2))\n\n    # Generate reproducible additive noise\n    np.random.seed(seed)\n    epsilon = np.random.normal(0.0, sigma_eps, size=lambdas.shape)\n\n    # Combine components to create the final observed spectrum\n    R = R_cont * M + epsilon\n\n    # Step 2: Define a function for feature depth calculation\n    def calculate_depth(S, l_0, l_L, l_R, i_0, i_L, i_R):\n        \"\"\"\n        Calculates the continuum-removed depth of a feature in a spectrum S.\n        \"\"\"\n        S_L = S[i_L]\n        S_R = S[i_R]\n        S_0 = S[i_0]\n\n        # Calculate the value of the linear continuum at the feature center lambda_0\n        C_S_at_lambda_0 = S_L + (l_0 - l_L) * ((S_R - S_L) / (l_R - l_L))\n        \n        # Calculate the normalized depth\n        d_S = 1.0 - S_0 / C_S_at_lambda_0\n        return d_S\n\n    # Calculate the depth of the feature in the original noisy spectrum\n    d_R = calculate_depth(R, lambda_0, lambda_L, lambda_R, idx_0, idx_L, idx_R)\n\n    # Step 3  4: Apply filters and compute attenuation for each test case\n    test_cases = [\n        (7, 2),   # Case 1\n        (21, 2),  # Case 2\n        (11, 4),  # Case 3\n        (5, 4),   # Case 4\n        (51, 3)   # Case 5\n    ]\n    \n    results = []\n    for W, P in test_cases:\n        # Apply the Savitzky-Golay filter to the original spectrum\n        R_f = savgol_filter(R, window_length=W, polyorder=P)\n        \n        # Calculate the depth of the feature in the filtered spectrum\n        d_Rf = calculate_depth(R_f, lambda_0, lambda_L, lambda_R, idx_0, idx_L, idx_R)\n        \n        # Calculate the attenuation measure\n        attenuation = (d_R - d_Rf) / d_R\n        \n        results.append(round(attenuation, 6))\n\n    # Step 5: Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个有效的光谱库不仅包含单一理想光谱，还应包含同一物质的多个样本以捕捉其自然变异性。要构建一个稳健的分类器，我们必须超越简单的一对一匹配，转而采用统计方法来描述这种类内变异。 本练习将引导您使用多元正态分布、协方差矩阵和马氏距离（Mahalanobis distance）等核心统计概念，为一个矿物类别建立统计模型。通过这种方式，您可以创建一个能够容忍微小光谱变化并能控制错分概率的分类器，这是定量遥感和模式识别中的一项高级且强大的技术。",
            "id": "3853576",
            "problem": "给定一组光谱反射率向量，它们代表了单一矿物类别的光谱库中的条目。每个条目都是在固定波长（单位为纳米，nm）下采样的反射光谱。反射率是无量纲的，其值介于 $0$ 和 $1$ 之间。您的任务是使用类内协方差来量化类内变异性，并在多元正态假设下计算分类器阈值。\n\n从统计模式识别和辐射度学中的核心定义和经过充分检验的公式出发：\n\n- 令 $X \\in \\mathbb{R}^{n \\times p}$ 表示包含 $n$ 个光谱库条目的矩阵，每个条目有 $p$ 个光谱波段（波长）。样本均值向量为 $\\hat{\\mu} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$，样本协方差矩阵为 $\\mathbf{S} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\hat{\\mu})(x_i - \\hat{\\mu})^\\top$。\n- 为确保数值稳定性和模拟仪器噪声，使用 Tikhonov 风格的正则化 $\\boldsymbol{\\Sigma}_\\lambda = \\mathbf{S} + \\lambda \\mathbf{I}_p$，其中 $\\lambda  0$ 是一个标量正则化参数，$\\mathbf{I}_p$ 是 $p \\times p$ 的单位矩阵。\n- 定义一个标量类内变异性度量，即平均每波段方差 $v_{\\text{avg}} = \\frac{\\operatorname{tr}(\\boldsymbol{\\Sigma}_\\lambda)}{p}$，其单位为反射率的平方（无量纲的平方）。\n- 在多元正态假设下，当 $x$ 属于该类别时，马氏距离（Mahalanobis distance）的平方 $D^2(x) = (x - \\hat{\\mu})^\\top \\boldsymbol{\\Sigma}_\\lambda^{-1} (x - \\hat{\\mu})$ 服从自由度为 $p$ 的卡方分布。因此，决策规则 “$D^2(x) \\le \\tau_\\alpha$” 通过设置 $\\tau_\\alpha = \\chi^2_{p, 1-\\alpha}$（即自由度为 $p$ 的卡方分布的 $(1-\\alpha)$ 分位数），可以达到名义上的假阳性率（第一类错误）$\\alpha$。\n\n实现一个程序，对每个给定的测试用例执行以下操作：\n1. 计算 $\\hat{\\mu}$、$\\mathbf{S}$ 和 $\\boldsymbol{\\Sigma}_\\lambda$。\n2. 计算 $v_{\\text{avg}} = \\frac{\\operatorname{tr}(\\boldsymbol{\\Sigma}_\\lambda)}{p}$（一个浮点数）。\n3. 计算马氏距离平方的阈值 $\\tau_\\alpha = \\chi^2_{p, 1-\\alpha}$（一个浮点数）。\n4. 对于每个查询光谱 $q$，计算 $D^2(q)$ 并返回一个布尔决策，指示是否满足 $D^2(q) \\le \\tau_\\alpha$。\n\n作答要求：\n- 反射率是无量纲的；波长单位必须视为给定的纳米（nm），但这不改变反射率的无量纲性质。报告 $v_{\\text{avg}}$ 时，单位为无量纲的反射率平方。报告 $\\tau_\\alpha$ 时，应为一个无量纲的浮点数。将分类决策报告为布尔值。\n- 不涉及角度；不要进行单位转换。\n- 每个测试用例的最终输出必须是一个列表，其中包含 $[v_{\\text{avg}}, \\tau_\\alpha, \\text{decisions}]$，其中 $\\text{decisions}$ 是一个布尔值列表，每个查询光谱对应一个布尔值。\n\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。例如：\"[result1,result2,result3]\"。\n\n使用以下包含三个案例的测试套件，每个案例由 $(\\text{wavelengths in nm}, X, Q, \\alpha, \\lambda)$ 描述：\n\n- 案例 A（常规“理想路径”）：\n  - 波长 (nm): $[450, 550, 650, 850, 1600, 2200]$。\n  - 光谱库 $X$（无量纲反射率）:\n    - $x_1 = [0.08, 0.12, 0.14, 0.18, 0.24, 0.28]$\n    - $x_2 = [0.09, 0.11, 0.15, 0.17, 0.23, 0.27]$\n    - $x_3 = [0.085, 0.115, 0.145, 0.175, 0.235, 0.275]$\n    - $x_4 = [0.082, 0.118, 0.142, 0.182, 0.238, 0.279]$\n    - $x_5 = [0.087, 0.113, 0.147, 0.178, 0.236, 0.276]$\n  - 查询 $Q$（无量纲反射率）:\n    - $q_1 = [0.086, 0.114, 0.146, 0.177, 0.235, 0.276]$\n    - $q_2 = [0.10, 0.12, 0.16, 0.19, 0.25, 0.30]$\n  - 假阳性率 $\\alpha = 0.05$。\n  - 正则化 $\\lambda = 0.00001$。\n\n- 案例 B（边界情况：类内变异性极低，假阳性率更严格）：\n  - 波长 (nm): $[450, 550, 650, 850, 1600, 2200]$。\n  - 光谱库 $X$（无量纲反射率）:\n    - $x_1 = [0.30, 0.28, 0.26, 0.24, 0.22, 0.20]$\n    - $x_2 = [0.3005, 0.2795, 0.2605, 0.2405, 0.2205, 0.2005]$\n    - $x_3 = [0.2995, 0.2805, 0.2595, 0.2395, 0.2195, 0.1995]$\n    - $x_4 = [0.30, 0.28, 0.26, 0.24, 0.22, 0.20]$\n  - 查询 $Q$（无量纲反射率）:\n    - $q_1 = [0.30, 0.28, 0.26, 0.24, 0.22, 0.20]$\n    - $q_2 = [0.31, 0.29, 0.27, 0.25, 0.23, 0.21]$\n  - 假阳性率 $\\alpha = 0.01$。\n  - 正则化 $\\lambda = 0.000001$。\n\n- 案例 C（边缘情况：样本量小，协方差矩阵接近奇异，需要正则化）：\n  - 波长 (nm): $[450, 550, 650, 850, 1600, 2200]$。\n  - 光谱库 $X$（无量纲反射率）:\n    - $x_1 = [0.12, 0.18, 0.25, 0.31, 0.38, 0.44]$\n    - $x_2 = [0.13, 0.195, 0.27, 0.335, 0.41, 0.475]$\n  - 查询 $Q$（无量纲反射率）:\n    - $q_1 = [0.125, 0.1875, 0.2575, 0.3225, 0.395, 0.4575]$\n    - $q_2 = [0.10, 0.22, 0.20, 0.30, 0.45, 0.40]$\n  - 假阳性率 $\\alpha = 0.05$。\n  - 正则化 $\\lambda = 0.0001$。\n\n您的程序必须为每个案例计算指定的量，并生成单行输出：一个顶级列表，其中包含每个案例的一个子列表，每个子列表的形式为 $[v_{\\text{avg}}, \\tau_\\alpha, \\text{decisions}]$。所有值都是无量纲的；请完全按照程序的计算结果报告浮点数和布尔值。",
            "solution": "该问题要求基于多元正态分布和马氏距离，为光谱数据实现一个统计分类器。这包括从已知光谱库中计算关键统计数据，根据指定的假阳性率建立决策阈值，然后对新的查询光谱进行分类。整个过程基于统计模式识别的基本原理。\n\n首先，我们对给定单一类别的数据进行形式化处理。我们得到一组包含 $n$ 个光谱反射率向量的数据集，每个向量都在 $p$ 个不同波长处测量。该数据集可以表示为一个矩阵 $X \\in \\mathbb{R}^{n \\times p}$，其中每一行 $x_i$（对于 $i \\in \\{1, \\dots, n\\}$）都是一个光谱。\n\n第一步是为数据的集中趋势和离散程度建模。假设给定矿物类别的光谱向量是来自一个多元分布的样本，我们可以估计其参数。\n集中趋势通过样本均值向量 $\\hat{\\mu} \\in \\mathbb{R}^p$ 来估计，计算方法为样本向量的平均值：\n$$\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n$$\n光谱波段之间的离散程度和相关性由样本协方差矩阵 $\\mathbf{S} \\in \\mathbb{R}^{p \\times p}$ 捕获。它使用无偏估计量计算：\n$$\n\\mathbf{S} = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\hat{\\mu})(x_i - \\hat{\\mu})^\\top\n$$\n其中 $(x_i - \\hat{\\mu})$ 是一个列向量。除以 $n-1$ 代表了用于无偏估计的 Bessel's 校正。\n\n在实践中，样本协方差矩阵 $\\mathbf{S}$ 可能是病态的或奇异的，特别是当样本数量 $n$ 不显著大于维度数量 $p$ 时。在案例 C 中尤其如此，其中 $n=2$ 且 $p=6$，这确保了 $\\mathbf{S}$ 是秩亏的。为了确保矩阵求逆的数值稳定性，并对光谱库中未捕获的潜在传感器噪声进行建模，应用了 Tikhonov 风格的正则化。正则化协方差矩阵 $\\boldsymbol{\\Sigma}_\\lambda$ 定义为：\n$$\n\\boldsymbol{\\Sigma}_\\lambda = \\mathbf{S} + \\lambda \\mathbf{I}_p\n$$\n其中 $\\lambda  0$ 是一个小的标量正则化参数，$\\mathbf{I}_p$ 是 $p \\times p$ 的单位矩阵。此操作将 $\\lambda$ 加到 $\\mathbf{S}$ 的对角线元素上，有效地将每个波段的方差增加一个很小的值，从而保证 $\\boldsymbol{\\Sigma}_\\lambda$ 是正定的，因此是可逆的。\n\n接下来，我们量化类内变异性。一个简单的标量度量是平均每波段方差 $v_{\\text{avg}}$，其定义为正则化协方差矩阵对角线元素（迹）的均值：\n$$\nv_{\\text{avg}} = \\frac{\\operatorname{tr}(\\boldsymbol{\\Sigma}_\\lambda)}{p}\n$$\n$\\boldsymbol{\\Sigma}_\\lambda$ 的迹是每个光谱波段正则化方差的总和。\n\n分类器的核心是决策规则。我们用一个多元正态分布 $\\mathcal{N}(\\hat{\\mu}, \\boldsymbol{\\Sigma}_\\lambda)$ 来为该类别建模。对于一个查询光谱 $q$，其与该类别分布的“距离”可以通过马氏距离的平方 $D^2(q)$ 来衡量：\n$$\nD^2(q) = (q - \\hat{\\mu})^\\top \\boldsymbol{\\Sigma}_\\lambda^{-1} (q - \\hat{\\mu})\n$$\n这个距离度量在统计上是强大的，因为它考虑了每个波段的方差以及波段间的协方差。它以标准差为单位测量距离，有效地创建了一个与数据云形状相符的椭圆形决策边界。\n\n多元统计学中的一个关键定理指出，如果向量 $x$ 来自均值为 $\\mu$、协方差为 $\\Sigma$ 的 $p$ 元正态分布，那么马氏距离的平方 $(x - \\mu)^\\top \\Sigma^{-1} (x - \\mu)$ 服从自由度为 $p$ 的卡方分布，记为 $\\chi^2_p$。\n\n这一特性使我们能够构建一个具有统计学上可控错误率的决策规则。如果一个查询 $q$ 的马氏距离不是异常大，我们就希望接受它作为该类别的成员。对于一个指定的名义假阳性率（第一类错误）$\\alpha$，我们找到一个阈值 $\\tau_\\alpha$，使得一个真实成员的距离大于该阈值的概率为 $\\alpha$。这个阈值是自由度为 $p$ 的卡方分布的 $(1-\\alpha)$ 分位数：\n$$\nP(D^2(x)  \\tau_\\alpha) = \\alpha \\quad \\implies \\quad \\tau_\\alpha = \\chi^2_{p, 1-\\alpha}\n$$\n决策规则于是为：如果 $D^2(q) \\le \\tau_\\alpha$，则将查询 $q$ 分类为属于该类别。\n\n实现将通过为每个测试用例计算这些量来进行。\n1.  读取输入数据 $(X, Q, \\alpha, \\lambda)$ 并确定维度 $n$ 和 $p$。\n2.  使用 `numpy.mean` 计算 $\\hat{\\mu}$。\n3.  使用 `numpy.cov` 并设置 `ddof=1` 来计算 $\\mathbf{S}$。\n4.  计算 $\\boldsymbol{\\Sigma}_\\lambda = \\mathbf{S} + \\lambda \\mathbf{I}_p$。\n5.  计算 $v_{\\text{avg}} = \\frac{\\operatorname{tr}(\\boldsymbol{\\Sigma}_\\lambda)}{p}$。\n6.  使用 `scipy.stats.chi2` 的百分点函数 (`ppf`)，以 $p$ 为自由度，分位数为 $1-\\alpha$ 来计算 $\\tau_\\alpha$。\n7.  对于每个查询光谱 $q \\in Q$，使用 `numpy.linalg.inv` 找到 $\\boldsymbol{\\Sigma}_\\lambda^{-1}$ 并执行矩阵-向量乘法来计算 $D^2(q)$。\n8.  将每个 $D^2(q)$ 与 $\\tau_\\alpha$ 比较以获得布尔决策。\n9.  为每个案例组装结果 $[v_{\\text{avg}}, \\tau_\\alpha, \\text{decisions}]$ 并将其格式化为指定的最终输出字符串。案例 B 中有一个微小的数据录入错误（$2005$ 而非 $0.2005$），为保持科学有效性已将其纠正，因为反射率的界限是 $[0, 1]$。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Solves the spectral classification problem for all given test cases.\n    \"\"\"\n    \n    # In Case B, the last element of x_2 is given as 2005. This is a clear typo, as reflectance must\n    # be in [0, 1]. The pattern of x_2 = x_1 + [..., 0.0005] suggests the value should be 0.2005.\n    # This correction is made here to ensure the problem is scientifically valid.\n    test_cases = [\n        {\n            \"id\": \"A\",\n            \"X\": np.array([\n                [0.08, 0.12, 0.14, 0.18, 0.24, 0.28],\n                [0.09, 0.11, 0.15, 0.17, 0.23, 0.27],\n                [0.085, 0.115, 0.145, 0.175, 0.235, 0.275],\n                [0.082, 0.118, 0.142, 0.182, 0.238, 0.279],\n                [0.087, 0.113, 0.147, 0.178, 0.236, 0.276]\n            ]),\n            \"Q\": np.array([\n                [0.086, 0.114, 0.146, 0.177, 0.235, 0.276],\n                [0.10, 0.12, 0.16, 0.19, 0.25, 0.30]\n            ]),\n            \"alpha\": 0.05,\n            \"lambda_reg\": 0.00001\n        },\n        {\n            \"id\": \"B\",\n            \"X\": np.array([\n                [0.30, 0.28, 0.26, 0.24, 0.22, 0.20],\n                [0.3005, 0.2795, 0.2605, 0.2405, 0.2205, 0.2005], # Corrected value\n                [0.2995, 0.2805, 0.2595, 0.2395, 0.2195, 0.1995],\n                [0.30, 0.28, 0.26, 0.24, 0.22, 0.20]\n            ]),\n            \"Q\": np.array([\n                [0.30, 0.28, 0.26, 0.24, 0.22, 0.20],\n                [0.31, 0.29, 0.27, 0.25, 0.23, 0.21]\n            ]),\n            \"alpha\": 0.01,\n            \"lambda_reg\": 0.000001\n        },\n        {\n            \"id\": \"C\",\n            \"X\": np.array([\n                [0.12, 0.18, 0.25, 0.31, 0.38, 0.44],\n                [0.13, 0.195, 0.27, 0.335, 0.41, 0.475]\n            ]),\n            \"Q\": np.array([\n                [0.125, 0.1875, 0.2575, 0.3225, 0.395, 0.4575],\n                [0.10, 0.22, 0.20, 0.30, 0.45, 0.40]\n            ]),\n            \"alpha\": 0.05,\n            \"lambda_reg\": 0.0001\n        }\n    ]\n\n    def process_case(X, Q, alpha, lambda_reg):\n        \"\"\"\n        Computes variability, threshold, and classification decisions for a single case.\n        \"\"\"\n        n, p = X.shape\n\n        # 1. Compute mu_hat, S, and Sigma_lambda\n        mu_hat = np.mean(X, axis=0)\n        \n        # In the case of n=1, np.cov returns 0, but the formula requires undefined or NaN.\n        # The problem constraints ensure n > 1 for all cases, so this is safe.\n        S = np.cov(X, rowvar=False, ddof=1)\n        \n        # For a single sample (n=1), S would be an array of NaNs if dimensions are > 1, \n        # or 0 for 1-D data. As n>=2, S is well-defined.\n        # In case p=1 and n > 1, np.cov returns a 0-d array (scalar), need to reshape.\n        if p == 1:\n            S = np.array([[S]])\n\n        I_p = np.identity(p)\n        Sigma_lambda = S + lambda_reg * I_p\n\n        # 2. Compute v_avg\n        v_avg = np.trace(Sigma_lambda) / p\n\n        # 3. Compute tau_alpha\n        tau_alpha = chi2.ppf(1 - alpha, df=p)\n\n        # 4. Compute D^2(q) and decisions for each query\n        try:\n            Sigma_lambda_inv = np.linalg.inv(Sigma_lambda)\n        except np.linalg.LinAlgError:\n            # This should not happen due to regularization\n            return [v_avg, tau_alpha, [False] * len(Q)]\n        \n        decisions = []\n        for q in Q:\n            delta = q - mu_hat\n            # D^2(q) = (q - mu_hat)^T * Sigma_lambda_inv * (q - mu_hat)\n            d2 = delta @ Sigma_lambda_inv @ delta\n            decisions.append(d2 = tau_alpha)\n            \n        return [v_avg, tau_alpha, decisions]\n\n    all_results = []\n    for case in test_cases:\n        result = process_case(case[\"X\"], case[\"Q\"], case[\"alpha\"], case[\"lambda_reg\"])\n        all_results.append(result)\n\n    # Format the final output string to precisely match \"[result1,result2,...]\"\n    # with no spaces.\n    def format_result(item):\n        if isinstance(item, list):\n            return f\"[{','.join(format_result(x) for x in item)}]\"\n        elif isinstance(item, bool):\n            return str(item).lower()  # Python's str(True) is 'True', not 'true'\n        else: # float\n            return str(item)\n\n    # Custom formatting to match the required output style (e.g., [True,False])\n    final_results_str = []\n    for res in all_results:\n        v_avg_str = str(res[0])\n        tau_alpha_str = str(res[1])\n        decisions_str = f\"[{','.join(str(d).lower() for d in res[2])}]\"\n        final_results_str.append(f\"[{v_avg_str},{tau_alpha_str},{decisions_str}]\")\n\n    final_output = f\"[{','.join(final_results_str)}]\"\n    # A final replacement to get rid of spaces around commas, although the f-string approach\n    # should be clean.\n    print(final_output.replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}