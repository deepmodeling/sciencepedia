{
    "hands_on_practices": [
        {
            "introduction": "Understanding Synthetic Aperture Radar (SAR) imagery begins with mastering its unique viewing geometry. Unlike a standard photograph, a SAR image is constructed based on the distance from the sensor to the target, known as slant range. This exercise  provides hands-on practice with the fundamental geometric transformation from the radar's natural slant-range perspective to the more intuitive ground-range or map projection, a crucial first step in SAR data interpretation.",
            "id": "3838457",
            "problem": "A spaceborne Synthetic Aperture Radar (SAR) acquires data over a locally flat terrain. The radar line-of-sight intersects the ground at a point displaced from the nadir point along the ground by the ground range $x$. The slant range $R$ is defined as the length of the line segment from the radar to the ground intersection point along the line-of-sight. The look angle $\\theta_l$ is defined at the sensor as the angle between the local vertical (nadir direction) and the line-of-sight. Assume a flat Earth model so that local verticals are parallel and the ground is a horizontal plane. Using the geometric definitions of projections and trigonometric ratios, derive an expression for the ground range $x$ as a function of the slant range $R$ and the look angle $\\theta_l$. Then, evaluate $x$ for $R=600\\,\\text{km}$ and $\\theta_l=30^\\circ$. Express your numerical result for $x$ in kilometers and round to four significant figures. State angles in degrees.",
            "solution": "The fundamental definitions are as follows. The slant range $R$ is the magnitude of the displacement from the sensor to the target along the line-of-sight. The look angle $\\theta_l$ is measured at the sensor between the local vertical (nadir) and the line-of-sight. Under a flat Earth assumption, the ground is a horizontal plane, and local verticals are parallel. The ground range $x$ is the horizontal displacement along the ground between the nadir point (the point directly below the sensor) and the line-of-sight intersection point.\n\nWe begin from Euclidean vector geometry. Let the sensor be located at position $(0,0,H)$ relative to the ground plane $z=0$, with $H>0$ representing altitude. Let the unit vector along the line-of-sight be denoted by $\\hat{\\ell}$. By the definition of the look angle $\\theta_l$, the component of $\\hat{\\ell}$ along the local vertical (the $z$-axis) is $\\cos \\theta_l$, and the magnitude of the horizontal component in the ground plane (the $xy$-plane) is $\\sin \\theta_l$. Without loss of generality, align the azimuth such that the horizontal component lies along the $x$-axis, so the displacement from the sensor to the target along the line-of-sight of length $R$ has components\n$$\n\\Delta z = R \\cos \\theta_l, \\qquad \\Delta x = R \\sin \\theta_l.\n$$\nThe ground intersection condition is $z=0$, which is satisfied by the chosen geometry when $\\Delta z$ bridges the altitude $H$; however, for the relationship between horizontal and total displacement, the altitude $H$ is not required explicitly because the trigonometric decomposition of the line-of-sight displacement is geometric and independent of $H$. Therefore, the ground range $x$, defined as the horizontal magnitude of the displacement in the ground plane between the nadir and the target, is\n$$\nx = R \\sin \\theta_l.\n$$\n\nThis expression can also be obtained from right-triangle trigonometry. The triangle formed by the altitude $H$ (adjacent to $\\theta_l$), the ground range $x$ (opposite to $\\theta_l$), and the slant range $R$ (hypotenuse) yields $\\sin \\theta_l = x/R$, which rearranges to $x = R \\sin \\theta_l$.\n\nNow evaluate $x$ for $R=600\\,\\text{km}$ and $\\theta_l=30^\\circ$ using degrees:\n$$\nx = R \\sin \\theta_l = 600 \\times \\sin(30^\\circ) = 600 \\times \\frac{1}{2} = 300.\n$$\nExpressing $x$ in kilometers and rounding to four significant figures,\n$$\nx = 3.000 \\times 10^{2}.\n$$",
            "answer": "$$\\boxed{3.000 \\times 10^{2}}$$"
        },
        {
            "introduction": "The relationship between viewing geometry and terrain is not always straightforward and can lead to significant geometric distortions in SAR images. This practice  explores the phenomenon of layover, where steep slopes cause a reversal of the expected range ordering, creating interpretation challenges. By deriving the precise geometric conditions under which layover occurs, you will develop a deeper physical intuition for how terrain interacts with radar signals and affects the final image.",
            "id": "3838545",
            "problem": "An airborne Synthetic Aperture Radar (SAR) images a terrain in a vertical plane aligned with the radar range direction. The radar line-of-sight is characterized by an incidence angle $\\theta_i$, defined as the angle between the radar look vector and the local vertical of a flat reference surface. Consider a planar slope whose dip direction is exactly aligned with the radar range direction, with slope angle $\\alpha$ measured from the horizontal and taken positive when the slope faces the radar.\n\nStarting from first principles, use the definition of incidence angle as the angle between the incoming wave direction and the surface normal to derive the signed local incidence angle on the slope. Then, using the physical interpretation of slant-range ordering and the relationship between signed local incidence angle and range-order reversals, derive the criterion for layover on a slope facing the radar as an inequality solely in terms of $\\alpha$ and $\\theta_i$.\n\nFinally, for a radar viewing a slope with $\\alpha = 40^\\circ$ and $\\theta_i = 35^\\circ$ (angles in degrees), evaluate whether layover occurs by computing the layover indicator\n$$\nL(\\alpha,\\theta_i) = \\begin{cases}\n1 & \\text{if layover occurs},\\\\\n0 & \\text{otherwise},\n\\end{cases}\n$$\nand provide $L(40^\\circ,35^\\circ)$ as the single numerical final answer. No rounding is required.",
            "solution": "The local incidence angle, $\\theta_{loc}$, is the angle between the incoming radar look vector and the normal to the local surface. Let's establish a coordinate system in the vertical plane containing the radar look vector.\n                    \n*   The radar look vector makes an angle $\\theta_i$ with the vertical (by definition of the incidence angle on a flat reference surface).\n*   The terrain slope is $\\alpha$, measured from the horizontal. For a slope facing the radar, its surface normal vector is tilted by an angle $\\alpha$ from the vertical, towards the radar.\n                    \nSince both the look vector and the surface normal are tilted towards the same side of the vertical, the angle between them is the difference of their individual angles from the vertical. We define the signed local incidence angle as:\n$$\n\\theta_{loc} = \\theta_i - \\alpha\n$$\nLayover occurs when terrain features at a farther ground range have a smaller slant range than features at a nearer ground range. This corresponds to a reversal in slant-range ordering, which mathematically means the derivative of slant range $R$ with respect to ground range $x_g$ is negative: $\\frac{dR}{dx_g} < 0$.\n\nThe relationship between the change in slant range and ground range for a slope $\\alpha$ is given by:\n$$\n\\frac{dR}{dx_g} = \\frac{\\sin(\\theta_i - \\alpha)}{\\cos(\\alpha)}\n$$\nFor layover to occur, we need $\\frac{dR}{dx_g} < 0$. In a typical imaging scenario, the slope angle $\\alpha$ is between $0^\\circ$ and $90^\\circ$, so $\\cos(\\alpha) > 0$. The condition for layover thus simplifies to:\n$$\n\\sin(\\theta_i - \\alpha) < 0\n$$\nSince the angles $\\theta_i$ and $\\alpha$ are typically in the range $[0^\\circ, 90^\\circ]$, their difference is in $[-90^\\circ, 90^\\circ]$. In this interval, the sine is negative only when its argument is negative. Therefore, the condition for layover is:\n$$\n\\theta_i - \\alpha < 0 \\quad \\implies \\quad \\alpha > \\theta_i\n$$\nThis means layover occurs when the terrain slope angle is greater than the radar incidence angle on a reference flat surface.\n\nFor the given values, $\\alpha = 40^\\circ$ and $\\theta_i = 35^\\circ$. We check the condition:\n$$\n40^\\circ > 35^\\circ\n$$\nThe condition is true, so layover occurs.\n\nThe layover indicator $L(\\alpha, \\theta_i)$ is 1 if layover occurs. Therefore, for the given case:\n$$\nL(40^\\circ, 35^\\circ) = 1\n$$",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Moving beyond simple geometric distortions, a critical task in quantitative remote sensing is to correct for the effects of viewing geometry on the measured radar brightness, or backscatter. This advanced, code-based exercise  challenges you to implement a standard radiometric normalization technique to convert the local-incidence-angle-dependent backscatter ($\\sigma^0$) to a geometry-normalized value ($\\gamma^0$). By simulating this process and quantifying the residual errors from imperfect assumptions, you will gain practical skills in data processing and a nuanced understanding of the sources of uncertainty in quantitative SAR analysis.",
            "id": "3838468",
            "problem": "A Synthetic Aperture Radar (SAR) instrument measures the Normalized Radar Cross Section, denoted by $\\sigma^0$, which depends on the radar viewing geometry through the local incidence angle. To compare two scenes with differing global incidence angle distributions, one common approach is to convert $\\sigma^0$ to the geometry-normalized quantity $\\gamma^0$ to reduce angular dependence. The foundational base for this problem is the following: (i) the definition of the local incidence angle through the dot product between the unit surface normal and the unit look vector of the sensor, (ii) the planar surface geometry relationship between slope and aspect and the surface normal, and (iii) the Lambertian reflectance law, which implies that energy intercepted by a surface varies with the cosine of the incidence angle. In realistic terrain, slope-induced anisotropy may cause deviations from Lambertian behavior.\n\nYou must design and implement a complete method to compare $\\sigma^0$ across two scenes by normalizing to $\\gamma^0$ and then quantify residual errors attributable to slope-induced anisotropy. Your derivation must begin from the dot product definition for the local incidence angle and the Lambertian base, without relying on pre-given shortcut formulas. Your program must compute the following for each scene:\n- The local incidence angle $\\theta_l$ for each pixel from the global incidence angle $\\theta_g$, terrain slope angle $\\alpha$, slope aspect angle $\\phi_s$, and radar look azimuth angle $\\phi_l$ by using the dot product between the local surface normal and the radar look vector in a planar-slope model.\n- The estimated geometry-normalized backscatter $\\widehat{\\gamma}^0$ by normalizing the measured $\\sigma^0$ according to the Lambertian base.\n- The residual error $\\varepsilon = \\widehat{\\gamma}^0 - \\gamma^0_{\\text{true}}$ under a physically plausible anisotropy model for $\\sigma^0$ given by a power-law dependence with angular exponent $p$ that varies with slope orientation, specifically $p = 1 + c \\tan(\\alpha) \\cos(\\Delta\\phi)$, where $\\Delta\\phi = \\phi_l - \\phi_s$ and $c$ is a small dimensionless anisotropy strength parameter.\n\nYou must assume the following generative model for the measured $\\sigma^0$ in linear (not decibel) units:\n$$\n\\sigma^0_{\\text{true}} = \\gamma^0_{\\text{true}} \\, \\cos^p(\\theta_l),\n$$\nwith $\\gamma^0_{\\text{true}}$ constant for all pixels within a given test case and scene. The local incidence angle $\\theta_l$ must be computed from planar geometry and the dot product definition. In particular, use the exact dot-product-based formula for the local incidence angle on a planar slope:\n$$\n\\cos(\\theta_l) = \\cos(\\theta_g)\\cos(\\alpha) + \\sin(\\theta_g)\\sin(\\alpha)\\cos(\\Delta\\phi),\n$$\nwhere all angles are measured consistently, and $\\Delta\\phi = \\phi_l - \\phi_s$. Pixels for which $\\theta_l \\geq \\pi/2$ (i.e., $\\cos(\\theta_l) \\leq 0$) must be filtered out as non-illuminated or shadowed.\n\nAfter computing $\\widehat{\\gamma}^0$ under the Lambertian assumption, quantify residual errors for each scene by computing:\n- The bias, defined as the mean of $\\varepsilon$ across the valid (illuminated) pixels.\n- The root-mean-square error relative to the true $\\gamma^0$, defined as\n$$\n\\text{RMSE}_{\\text{rel}} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\frac{\\varepsilon_i}{\\gamma^0_{\\text{true}}}\\right)^2},\n$$\nwhere $N$ is the number of valid pixels in the scene.\n\nAngles must be treated in degrees in the input specifications below, but converted to radians internally for all trigonometric operations. The quantities $\\sigma^0$, $\\gamma^0$, $\\widehat{\\gamma}^0$, $\\varepsilon$, and the metrics are unitless floats in linear scale (not decibels). All outputs must be rounded to six decimal places.\n\nImplement your method and evaluate it on the following test suite. For each test case, generate synthetic pixel populations using the specified distributions and a fixed random seed per test case to ensure deterministic outputs. For all uniform distributions, use inclusive bounds and independent sampling for each pixel. When a scalar angle is specified for a scene, use that same value for all pixels in that scene.\n\nTest Suite:\n- Test Case 1 (happy path: moderate slopes, differing look azimuths):\n  - Number of pixels per scene: $N = 2000$.\n  - True geometry-normalized backscatter: $\\gamma^0_{\\text{true}} = 0.15$.\n  - Anisotropy strength: $c = 0.2$.\n  - Scene A:\n    - Global incidence angle $\\theta_g$ uniform in $[30^\\circ,45^\\circ]$.\n    - Radar look azimuth $\\phi_l = 90^\\circ$.\n    - Slope angle $\\alpha$ uniform in $[5^\\circ,20^\\circ]$.\n    - Slope aspect $\\phi_s$ uniform in $[0^\\circ,360^\\circ]$.\n  - Scene B:\n    - Global incidence angle $\\theta_g$ uniform in $[20^\\circ,60^\\circ]$.\n    - Radar look azimuth $\\phi_l = 270^\\circ$.\n    - Slope angle $\\alpha$ uniform in $[5^\\circ,20^\\circ]$.\n    - Slope aspect $\\phi_s$ uniform in $[0^\\circ,360^\\circ]$.\n\n- Test Case 2 (boundary: flat terrain, different global incidence distributions):\n  - Number of pixels per scene: $N = 2000$.\n  - True geometry-normalized backscatter: $\\gamma^0_{\\text{true}} = 0.12$.\n  - Anisotropy strength: $c = 0.3$.\n  - Scene A:\n    - Global incidence angle $\\theta_g$ uniform in $[25^\\circ,35^\\circ]$.\n    - Radar look azimuth $\\phi_l = 0^\\circ$.\n    - Slope angle $\\alpha = 0^\\circ$.\n    - Slope aspect $\\phi_s = 0^\\circ$.\n  - Scene B:\n    - Global incidence angle $\\theta_g$ uniform in $[50^\\circ,55^\\circ]$.\n    - Radar look azimuth $\\phi_l = 180^\\circ$.\n    - Slope angle $\\alpha = 0^\\circ$.\n    - Slope aspect $\\phi_s = 0^\\circ$.\n\n- Test Case 3 (edge: steep slopes facing the radar, contrasting global incidence):\n  - Number of pixels per scene: $N = 2000$.\n  - True geometry-normalized backscatter: $\\gamma^0_{\\text{true}} = 0.10$.\n  - Anisotropy strength: $c = 0.5$.\n  - Scene A:\n    - Global incidence angle $\\theta_g$ uniform in $[40^\\circ,70^\\circ]$.\n    - Radar look azimuth $\\phi_l = 0^\\circ$.\n    - Slope angle $\\alpha$ uniform in $[25^\\circ,40^\\circ]$.\n    - Slope aspect $\\phi_s$ uniform in $[-10^\\circ,10^\\circ]$.\n  - Scene B:\n    - Global incidence angle $\\theta_g$ uniform in $[20^\\circ,50^\\circ]$.\n    - Radar look azimuth $\\phi_l = 180^\\circ$.\n    - Slope angle $\\alpha$ uniform in $[25^\\circ,40^\\circ]$.\n    - Slope aspect $\\phi_s$ uniform in $[170^\\circ,190^\\circ]$.\n\nUse a fixed random seed for each test case: $42$ for Test Case 1, $43$ for Test Case 2, and $44$ for Test Case 3. For each test case and for each scene, compute the bias and the relative root-mean-square error as defined above.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain $12$ floats (unitless), rounded to six decimal places, in the following order:\n$[\\text{bias}_{A,1}, \\text{RMSE}_{\\text{rel},A,1}, \\text{bias}_{B,1}, \\text{RMSE}_{\\text{rel},B,1}, \\text{bias}_{A,2}, \\text{RMSE}_{\\text{rel},A,2}, \\text{bias}_{B,2}, \\text{RMSE}_{\\text{rel},B,2}, \\text{bias}_{A,3}, \\text{RMSE}_{\\text{rel},A,3}, \\text{bias}_{B,3}, \\text{RMSE}_{\\text{rel},B,3}]$.",
            "solution": "The objective is to design and implement a method for quantifying the residual errors that arise when normalizing Synthetic Aperture Radar (SAR) backscatter ($\\sigma^0$) using a simple Lambertian model, given that the true backscatter follows a more complex, slope-dependent anisotropic model. The analysis is performed on two synthetic scenes (A and B) for three distinct test cases. The core of the method involves generating synthetic pixel data, calculating viewing geometry, applying the true and simplified models, and computing error metrics.\n\nThe procedure for each scene within each test case is as follows:\n\n1.  **Synthetic Scene Generation**: For each scene, a population of $N$ pixels is generated. A unique random seed is used for each test case to ensure deterministic results. Each pixel is characterized by a global incidence angle $\\theta_g$, a terrain slope angle $\\alpha$, and a slope aspect angle $\\phi_s$. These are generated from either constant values or uniform distributions as specified in the test case, using a seeded pseudo-random number generator. All angles are initially in degrees and are converted to radians for trigonometric calculations, as this is the standard for scientific computation. Radar look azimuth $\\phi_l$ is constant for all pixels in a scene.\n\n2.  **Local Incidence Angle ($\\theta_l$) Calculation**: The local incidence angle $\\theta_l$ is the angle between the local surface normal vector and the radar look vector. It is the primary geometric factor controlling the backscatter intensity. For a planar surface, its cosine is given by the dot product formulation specified in the problem:\n    $$\n    \\cos(\\theta_l) = \\cos(\\theta_g)\\cos(\\alpha) + \\sin(\\theta_g)\\sin(\\alpha)\\cos(\\Delta\\phi)\n    $$\n    where $\\Delta\\phi = \\phi_l - \\phi_s$ is the difference between the radar look azimuth and the slope aspect. This calculation is performed for every pixel in the scene.\n\n3.  **Filtering of Non-Illuminated Pixels**: A physical surface is only illuminated by the radar if the local incidence angle $\\theta_l < \\pi/2$ radians ($90^\\circ$). If $\\theta_l \\geq \\pi/2$, the surface is in shadow (from the perspective of the radar) or, in extreme cases, exhibits layover. Mathematically, this condition is equivalent to $\\cos(\\theta_l) \\leq 0$. All pixels that do not satisfy $\\cos(\\theta_l) > 0$ must be excluded from further analysis. The number of remaining, valid pixels is denoted $N_{valid}$.\n\n4.  **True Backscatter Generation ($\\sigma^0_{\\text{true}}$)**: The \"measured\" backscatter for each pixel, $\\sigma^0_{\\text{true}}$, is synthesized using the provided physically plausible generative model. This model incorporates slope-induced anisotropy:\n    $$\n    \\sigma^0_{\\text{true}} = \\gamma^0_{\\text{true}} \\, \\cos^p(\\theta_l)\n    $$\n    Here, $\\gamma^0_{\\text{true}}$ is the true geometry-normalized backscatter, a constant for the scene. The exponent $p$ modulates the angular dependency and is itself a function of the terrain orientation relative to the radar look direction:\n    $$\n    p = 1 + c \\tan(\\alpha) \\cos(\\Delta\\phi)\n    $$\n    where $c$ is the anisotropy strength parameter. This model deviates from the simple Lambertian case (where $p=1$) based on slope steepness ($\\tan(\\alpha)$) and whether the slope is facing towards or away from the radar ($\\cos(\\Delta\\phi)$).\n\n5.  **Lambertian Normalization and Estimation of $\\widehat{\\gamma}^0$**: The normalization procedure aims to estimate $\\gamma^0$ from the measured $\\sigma^0$. The standard, simplified approach is to assume a Lambertian scattering law, which corresponds to setting $p=1$. To estimate $\\gamma^0$ under this assumption, one inverts the simplified model:\n    $$\n    \\widehat{\\gamma}^0 = \\frac{\\sigma^0_{\\text{true}}}{\\cos(\\theta_l)}\n    $$\n    Substituting the expression for $\\sigma^0_{\\text{true}}$ from the true generative model yields:\n    $$\n    \\widehat{\\gamma}^0 = \\frac{\\gamma^0_{\\text{true}} \\, \\cos^p(\\theta_l)}{\\cos(\\theta_l)} = \\gamma^0_{\\text{true}} \\, \\cos^{p-1}(\\theta_l)\n    $$\n\n6.  **Residual Error Calculation ($\\varepsilon$)**: The residual error, $\\varepsilon$, is the difference between the estimated geometry-normalized backscatter, $\\widehat{\\gamma}^0$, and its true value, $\\gamma^0_{\\text{true}}$.\n    $$\n    \\varepsilon = \\widehat{\\gamma}^0 - \\gamma^0_{\\text{true}} = \\gamma^0_{\\text{true}} \\, \\cos^{p-1}(\\theta_l) - \\gamma^0_{\\text{true}} = \\gamma^0_{\\text{true}} \\left( \\cos^{p-1}(\\theta_l) - 1 \\right)\n    $$\n    This analytical expression for the error is computed for every valid pixel. It highlights that the error is zero only if $p=1$ (the Lambertian assumption holds) or if $\\theta_l=0$.\n\n7.  **Metric Computation**: To quantify the distribution of residual errors across the scene, two statistical metrics are computed using the set of $\\varepsilon$ values for the $N_{valid}$ pixels:\n    - **Bias**: The mean of the residual errors, which indicates any systematic over- or underestimation of $\\gamma^0$.\n      $$\n      \\text{bias} = \\frac{1}{N_{valid}} \\sum_{i=1}^{N_{valid}} \\varepsilon_i\n      $$\n    - **Relative Root-Mean-Square Error ($\\text{RMSE}_{\\text{rel}}$)**: The root-mean-square of the error relative to the true value, which quantifies the magnitude of the error irrespective of its sign.\n      $$\n      \\text{RMSE}_{\\text{rel}} = \\sqrt{\\frac{1}{N_{valid}}\\sum_{i=1}^{N_{valid}}\\left(\\frac{\\varepsilon_i}{\\gamma^0_{\\text{true}}}\\right)^2}\n      $$\n      Using the derived expression for $\\varepsilon$, the relative error term simplifies to $(\\cos^{p-1}(\\theta_l) - 1)$, making the calculation efficient and independent of $\\gamma^0_{\\text{true}}$.\n\nThis detailed, step-by-step process is implemented for each scene in the test suite to produce the required bias and $\\text{RMSE}_{\\text{rel}}$ values.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef process_scene(N, gamma0_true, c, theta_g_params, phi_l_deg, alpha_params, phi_s_params, rng):\n    \"\"\"\n    Processes a single scene to calculate bias and relative RMSE.\n\n    Args:\n        N (int): Number of pixels to generate.\n        gamma0_true (float): True geometry-normalized backscatter.\n        c (float): Anisotropy strength parameter.\n        theta_g_params (float or tuple): Global incidence angle, constant or (min, max) for uniform dist.\n        phi_l_deg (float): Radar look azimuth in degrees.\n        alpha_params (float or tuple): Slope angle, constant or (min, max) for uniform dist.\n        phi_s_params (float or tuple): Slope aspect, constant or (min, max) for uniform dist.\n        rng (np.random.Generator): Seeded random number generator instance.\n\n    Returns:\n        tuple[float, float]: A tuple containing the calculated bias and relative RMSE.\n    \"\"\"\n    # Step 1: Generate pixel data (angles in degrees).\n    # A helper function to generate data from either a scalar or a uniform distribution range.\n    def generate_data(params, size):\n        if isinstance(params, tuple) and len(params) == 2:\n            return rng.uniform(low=params[0], high=params[1], size=size)\n        else:\n            return np.full(size, params)\n\n    theta_g_deg = generate_data(theta_g_params, N)\n    alpha_deg = generate_data(alpha_params, N)\n    phi_s_deg = generate_data(phi_s_params, N)\n\n    # Step 2: Convert all angles to radians for computation.\n    theta_g = np.deg2rad(theta_g_deg)\n    alpha = np.deg2rad(alpha_deg)\n    phi_s = np.deg2rad(phi_s_deg)\n    phi_l = np.deg2rad(phi_l_deg)\n    \n    # Step 3: Calculate the cosine of the local incidence angle.\n    delta_phi = phi_l - phi_s\n    cos_theta_l = np.cos(theta_g) * np.cos(alpha) + np.sin(theta_g) * np.sin(alpha) * np.cos(delta_phi)\n\n    # Step 4: Filter out non-illuminated pixels (where cos(theta_l) <= 0).\n    valid_mask = cos_theta_l > 0\n    \n    if not np.any(valid_mask):\n        return 0.0, 0.0 # No valid pixels, so no error.\n    \n    # Apply the mask to all pixel-wise arrays.\n    cos_theta_l = cos_theta_l[valid_mask]\n    alpha = alpha[valid_mask]\n    delta_phi = delta_phi[valid_mask]\n    \n    # Step 5: Calculate the anisotropic exponent 'p'.\n    # This is done only for valid pixels.\n    p = 1.0 + c * np.tan(alpha) * np.cos(delta_phi)\n    \n    # Step 6 & 7: Calculate residual error 'epsilon' directly from the analytical formula.\n    # The estimated gamma_hat is gamma0_true * (cos_theta_l ** (p - 1.0))\n    # Epsilon = gamma_hat - gamma0_true\n    epsilon = gamma0_true * (np.power(cos_theta_l, p - 1.0) - 1.0)\n    \n    # Step 8: Calculate metrics.\n    # Bias is the mean of the errors.\n    bias = np.mean(epsilon)\n    \n    # Relative RMSE is calculated from the definition.\n    # The relative error is epsilon / gamma0_true.\n    relative_error = np.power(cos_theta_l, p - 1.0) - 1.0\n    rmse_rel = np.sqrt(np.mean(np.square(relative_error)))\n    \n    return bias, rmse_rel\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the final results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            'seed': 42,\n            'params': {'N': 2000, 'gamma0_true': 0.15, 'c': 0.2},\n            'scene_A': {'theta_g': (30, 45), 'phi_l': 90, 'alpha': (5, 20), 'phi_s': (0, 360)},\n            'scene_B': {'theta_g': (20, 60), 'phi_l': 270, 'alpha': (5, 20), 'phi_s': (0, 360)}\n        },\n        {\n            'seed': 43,\n            'params': {'N': 2000, 'gamma0_true': 0.12, 'c': 0.3},\n            'scene_A': {'theta_g': (25, 35), 'phi_l': 0, 'alpha': 0.0, 'phi_s': 0.0},\n            'scene_B': {'theta_g': (50, 55), 'phi_l': 180, 'alpha': 0.0, 'phi_s': 0.0}\n        },\n        {\n            'seed': 44,\n            'params': {'N': 2000, 'gamma0_true': 0.10, 'c': 0.5},\n            'scene_A': {'theta_g': (40, 70), 'phi_l': 0, 'alpha': (25, 40), 'phi_s': (-10, 10)},\n            'scene_B': {'theta_g': (20, 50), 'phi_l': 180, 'alpha': (25, 40), 'phi_s': (170, 190)}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Use a new seeded generator for each test case for reproducibility.\n        rng = np.random.default_rng(case['seed'])\n        \n        # Process Scene A for the current test case.\n        scene_A_params = case['scene_A']\n        bias_A, rmse_rel_A = process_scene(\n            N=case['params']['N'],\n            gamma0_true=case['params']['gamma0_true'],\n            c=case['params']['c'],\n            theta_g_params=scene_A_params['theta_g'],\n            phi_l_deg=scene_A_params['phi_l'],\n            alpha_params=scene_A_params['alpha'],\n            phi_s_params=scene_A_params['phi_s'],\n            rng=rng\n        )\n        results.extend([bias_A, rmse_rel_A])\n        \n        # Process Scene B for the current test case.\n        scene_B_params = case['scene_B']\n        bias_B, rmse_rel_B = process_scene(\n            N=case['params']['N'],\n            gamma0_true=case['params']['gamma0_true'],\n            c=case['params']['c'],\n            theta_g_params=scene_B_params['theta_g'],\n            phi_l_deg=scene_B_params['phi_l'],\n            alpha_params=scene_B_params['alpha'],\n            phi_s_params=scene_B_params['phi_s'],\n            rng=rng\n        )\n        results.extend([bias_B, rmse_rel_B])\n\n    # Final print statement in the exact required format.\n    # The output values are rounded to six decimal places.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}