{
    "hands_on_practices": [
        {
            "introduction": "原始的遥感测量值，如地表温度，本身可能不足以揭示物种分布的驱动因素。通常，环境胁迫事件（如热浪或寒潮）对物种的生存和繁殖影响更大，而这些事件最好通过偏离正常状况的程度来量化。本实践将指导您如何将一系列历史栅格数据转化为一个标准化的异常预测因子，从而捕捉这些对生态至关重要的极端事件。通过计算每个像素相对于其历史基线的标准化异常$z=(x-\\mu)/\\sigma$，您可以创建一个无量纲的、在空间上可比的指标，用以识别可能影响物种分布的环境胁迫。",
            "id": "3852186",
            "problem": "您将获得代表陆地表面温度 (LST) 的小型合成栅格数据，单位为摄氏度。请将每个栅格视为一个像素值矩阵。目标是通过将目标温度栅格（特定时间点）中的每个像素值 $x$ 与历史栅格堆栈中同一像素的基线分布进行比较，将其转换为一个无量纲的标准化异常栅格。使用以下基本定义：一个像素在 $n$ 个基线栅格中的样本均值 $\\mu$ 是其值的算术平均值，无偏样本标准差 $\\sigma$ 是以 $n-1$ 为分母计算的样本方差的平方根。为避免在 $\\sigma$ 接近零时出现除以零或数值不稳定的情况，请实施一种正则化策略，即通过将基线离散度 $\\sigma$ 与一个与温度具有相同物理单位的微小正数 $\\epsilon$ 相结合，来使用修正标准差 $\\sigma_{\\epsilon}$。标准化异常应为一个无量纲量，它映射了 $x$ 相对于 $\\mu$ 的偏差与 $\\sigma_{\\epsilon}$ 的比值。在计算出标准化异常栅格后，导出一个二元胁迫掩膜，如果某个像素的标准化异常绝对值超过给定阈值，则该像素被标记为处于胁迫状态。\n\n物理单位：温度单位为摄氏度 (°C)。标准化异常是无量纲的。正则化常数的单位必须是 °C。胁迫阈值是无量纲的。\n\n算法要求：\n- 根据基线栅格堆栈，计算每个像素的样本均值 $\\mu$ 和无偏样本标准差 $\\sigma$。\n- 将稳定化离散度定义为 $\\sigma_{\\epsilon} = \\sqrt{\\sigma^2 + \\epsilon^2}$，其中 $\\epsilon = 0.01$ °C。\n- 使用 $\\mu$ 和 $\\sigma_{\\epsilon}$ 将每个目标像素值 $x$ 转换为无量纲的标准化异常。\n- 为每个像素创建一个布尔胁迫掩膜，如果标准化异常的绝对值超过阈值 $t = 2$，则标记为胁迫。\n- 对于每个测试用例，返回三个输出：\n  1. 扁平化的标准化异常栅格（按行主序），为一个浮点数列表，四舍五入到三位小数。\n  2. 扁平化的胁迫掩膜（按行主序），为一个布尔值列表，其中 True 表示 $|z| \\ge t$。\n  3. 胁迫像素的比例，为一个在闭区间 $[0,1]$ 内的浮点数，四舍五入到三位小数。\n\n测试套件：\n使用以下测试用例，每个用例包含一个由 $n=4$ 个栅格组成的基线堆栈和一个目标栅格。所有温度单位均为 °C。每个栅格的大小为 $2 \\times 3$。\n\n- 用例 1 (典型变异性):\n  基线堆栈:\n  $$\n  B_1 = \\begin{bmatrix} 20  21  22 \\\\ 23  24  25 \\end{bmatrix},\\;\n  B_2 = \\begin{bmatrix} 19  21  23 \\\\ 22  24  26 \\end{bmatrix},\\;\n  B_3 = \\begin{bmatrix} 20  22  22 \\\\ 23  25  25 \\end{bmatrix},\\;\n  B_4 = \\begin{bmatrix} 21  21  24 \\\\ 23  24  27 \\end{bmatrix}.\n  $$\n  目标:\n  $$\n  X = \\begin{bmatrix} 22  23  21 \\\\ 24  26  24 \\end{bmatrix}.\n  $$\n\n- 用例 2 (基线中存在零方差像素):\n  基线堆栈:\n  $$\n  B_1 = \\begin{bmatrix} 15  30  5 \\\\ 10  0  12 \\end{bmatrix},\\;\n  B_2 = \\begin{bmatrix} 15  32  5 \\\\ 11  0  12 \\end{bmatrix},\\;\n  B_3 = \\begin{bmatrix} 15  28  5 \\\\ 9  0  12 \\end{bmatrix},\\;\n  B_4 = \\begin{bmatrix} 15  31  5 \\\\ 10  0  12 \\end{bmatrix}.\n  $$\n  目标:\n  $$\n  X = \\begin{bmatrix} 15  33  7 \\\\ 13  0  12 \\end{bmatrix}.\n  $$\n\n- 用例 3 (相对于基线的极端热浪):\n  基线堆栈:\n  $$\n  B_1 = \\begin{bmatrix} 18  18  18 \\\\ 18  18  18 \\end{bmatrix},\\;\n  B_2 = \\begin{bmatrix} 19  19  19 \\\\ 19  19  19 \\end{bmatrix},\\;\n  B_3 = \\begin{bmatrix} 20  20  20 \\\\ 20  20  20 \\end{bmatrix},\\;\n  B_4 = \\begin{bmatrix} 19  19  19 \\\\ 19  19  19 \\end{bmatrix}.\n  $$\n  目标:\n  $$\n  X = \\begin{bmatrix} 35  35  35 \\\\ 35  35  35 \\end{bmatrix}.\n  $$\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须为每个测试用例包含一个条目，并且每个条目必须是包含该用例上述三个输出的列表，顺序需保持一致。例如：\n\"[case1_result,case2_result,case3_result]\"\n其中每个 \"caseX_result\" 本身就是一个包含上述三个输出的列表。",
            "solution": "我们从像素温度的统计特征入手，将其视为一个随机变量 $X$，其基线经验分布源自历史上的陆地表面温度 (LST) 卫星观测数据。对于一个给定的像素，设其基线观测值为 $\\{x_1, x_2, \\dots, x_n\\}$，其中 $n \\ge 2$。样本均值定义为\n$$\n\\mu = \\frac{1}{n} \\sum_{j=1}^{n} x_j,\n$$\n无偏样本方差为\n$$\ns^2 = \\frac{1}{n-1} \\sum_{j=1}^{n} (x_j - \\mu)^2,\n$$\n无偏样本标准差为\n$$\n\\sigma = \\sqrt{s^2}.\n$$\n为了给新的观测值 $x$ 构建一个无量纲的标准化异常，我们用离散度 $\\sigma$ 来缩放偏差 $x - \\mu$。然而，当基线变异性 $\\sigma$ 为零或非常小时（例如，在基线观测值没有变化的像素中），该比率可能未定义或数值不稳定。一种广泛使用的稳定化策略是将 $\\sigma$ 与一个和 $X$ 具有相同物理单位的微小正数 $\\epsilon$ 相结合，以获得一个严格为正的有效离散度\n$$\n\\sigma_{\\epsilon} = \\sqrt{\\sigma^2 + \\epsilon^2}.\n$$\n这类似于 Tikhonov 正则化：它既能防止奇异点的出现，又能保持分母中的单位。标准化异常 $z$ 随后根据基于离散度进行标准化的基本原理导出为\n$$\nz = \\frac{x - \\mu}{\\sigma_{\\epsilon}}.\n$$\n根据其构造，$z$ 是无量纲的：$z = 2$ 的异常值表示，当用 $\\sigma_{\\epsilon}$ 衡量时，$x$ 比基线均值高出两个离散度单位。\n\n与物种分布相关的胁迫事件通常是指超出物种生理或生态耐受范围的环境条件的偶发性偏差。在物种分布模型中，LST 的极端异常可以指示热胁迫或冷胁迫，这些胁迫会改变物种的生存、繁殖、移动或资源可用性。标准化异常 $z$ 以可比较的单位量化了空间上的偏差。$|z|$ 超过阈值 $t$（此处 $t=2$）的像素对应于其幅度相对于典型基线变异性较大的事件。识别此类事件可以提供能够捕捉急性胁迫事件的预测因子，而这些事件仅靠长期气候平均值是无法反映的。例如，通过热红外遥感探测到的异常高的 LST 可能与热浪同时发生，这些热浪会降低栖息地的适宜性或将环境条件推向超出物种特定热生态位的范围。使用 $z$ 既包含了偏差的幅度，也包含了局部变异性的背景，从而实现了跨区域的可比性，这对于在景观到大陆尺度上建模物种分布至关重要。\n\n算法设计：\n1. 对于每个测试用例，使用无偏估计量（分母为 $n-1$）计算基线堆栈中每个像素的 $\\mu$ 和 $\\sigma$。\n2. 设置 $\\epsilon = 0.01$ °C，并为每个像素计算 $\\sigma_{\\epsilon} = \\sqrt{\\sigma^2 + \\epsilon^2}$。\n3. 使用 $z = (x - \\mu)/\\sigma_{\\epsilon}$ 为每个像素计算标准化异常栅格 $z$。\n4. 使用条件 $|z| \\ge t$（其中 $t=2$）为每个像素创建布尔胁迫掩膜。\n5. 计算胁迫像素的比例，即布尔掩膜在所有像素上的平均值，这将得到一个在 $[0, 1]$ 范围内的值。\n6. 将 $z$ 栅格和胁迫掩膜按行主序进行扁平化，将 $z$ 值和胁迫比例四舍五入到三位小数，并按规定汇总每个测试用例的输出。\n\n此程序遵循基本的统计定义，并为量化和检测环境胁迫事件作为物种分布模型中的预测因子提供了一种有原则的方法。由于 $z$ 是无量纲的，它适合与其他标准化预测因子集成，也适合在高级生态位模型（包括广义线性模型、广义相加模型和机器学习框架）中进行基于阈值的特征工程。使用微小的 $\\epsilon$ 可确保数值稳定性，在 $\\sigma$ 足够大时不会实质性地改变 $z$ 值，同时可以防止在基线变异性可忽略的区域（例如，持续均一的表面或粗糙的气候学数据）出现发散。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_standardized_anomaly(baseline_stack, target_raster, epsilon=0.01, threshold=2.0):\n    \"\"\"\n    Compute per-pixel standardized anomaly z and stress mask.\n    baseline_stack: numpy array of shape (n, rows, cols)\n    target_raster: numpy array of shape (rows, cols)\n    epsilon: small positive constant in same units as temperature (°C)\n    threshold: dimensionless threshold for stress detection on |z|\n    Returns:\n        z_flat: list of floats (rounded to 3 decimals), flattened row-major\n        stress_flat: list of booleans, flattened row-major\n        stressed_fraction: float rounded to 3 decimals\n    \"\"\"\n    # Compute per-pixel unbiased sample mean and standard deviation across baseline rasters\n    mu = np.mean(baseline_stack, axis=0)\n    sigma = np.std(baseline_stack, axis=0, ddof=1)\n\n    # Stabilize the denominator using epsilon in °C\n    sigma_eps = np.sqrt(sigma**2 + epsilon**2)\n\n    # Compute standardized anomaly (dimensionless)\n    z = (target_raster - mu) / sigma_eps\n\n    # Stress mask: absolute z exceeding threshold\n    stress_mask = np.abs(z) >= threshold\n\n    # Flatten in row-major order\n    z_flat = np.round(z.flatten(), 3).tolist()\n    stress_flat = stress_mask.flatten().tolist()\n\n    # Fraction of stressed pixels\n    stressed_fraction = np.round(np.mean(stress_mask), 3)\n\n    return z_flat, stress_flat, float(stressed_fraction)\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    # Case 1 (typical variability)\n    B1_1 = np.array([[20,21,22],[23,24,25]], dtype=float)\n    B1_2 = np.array([[19,21,23],[22,24,26]], dtype=float)\n    B1_3 = np.array([[20,22,22],[23,25,25]], dtype=float)\n    B1_4 = np.array([[21,21,24],[23,24,27]], dtype=float)\n    baseline1 = np.stack([B1_1, B1_2, B1_3, B1_4], axis=0)\n    target1 = np.array([[22,23,21],[24,26,24]], dtype=float)\n\n    # Case 2 (zero-variance pixels in baseline)\n    B2_1 = np.array([[15,30,5],[10,0,12]], dtype=float)\n    B2_2 = np.array([[15,32,5],[11,0,12]], dtype=float)\n    B2_3 = np.array([[15,28,5],[9,0,12]], dtype=float)\n    B2_4 = np.array([[15,31,5],[10,0,12]], dtype=float)\n    baseline2 = np.stack([B2_1, B2_2, B2_3, B2_4], axis=0)\n    target2 = np.array([[15,33,7],[13,0,12]], dtype=float)\n\n    # Case 3 (extreme heatwave relative to baseline)\n    B3_1 = np.array([[18,18,18],[18,18,18]], dtype=float)\n    B3_2 = np.array([[19,19,19],[19,19,19]], dtype=float)\n    B3_3 = np.array([[20,20,20],[20,20,20]], dtype=float)\n    B3_4 = np.array([[19,19,19],[19,19,19]], dtype=float)\n    baseline3 = np.stack([B3_1, B3_2, B3_3, B3_4], axis=0)\n    target3 = np.array([[35,35,35],[35,35,35]], dtype=float)\n\n    test_cases = [\n        (baseline1, target1, 0.01, 2.0),\n        (baseline2, target2, 0.01, 2.0),\n        (baseline3, target3, 0.01, 2.0),\n    ]\n\n    results = []\n    for baseline, target, eps, thr in test_cases:\n        z_flat, stress_flat, stressed_fraction = compute_standardized_anomaly(\n            baseline, target, epsilon=eps, threshold=thr\n        )\n        # Each case result is [z_flattened, stress_flattened, stressed_fraction]\n        results.append([z_flat, stress_flat, stressed_fraction])\n\n    # Final print statement in the exact required format.\n    print(f\"{results}\")\n\nsolve()\n```"
        },
        {
            "introduction": "在准备好预测因子之后，下一步是构建物种分布模型。然而，一个关键的决定是选择合适的空间分辨率，因为生态过程在特定尺度上运作，而预测因子与物种响应之间的关系可能随尺度而变。这个综合性实践将引导您在两个不同分辨率下（精细与粗糙）拟合、评估和比较物种分布模型。通过这项练习，您不仅能掌握从模型拟合到性能评估的完整流程，还将学会如何从生态学角度解释尺度差异对模型性能的影响，这是理解和解决“尺度不匹配”问题的核心技能。",
            "id": "3852180",
            "problem": "您需要实现一个完整、可运行的程序，该程序使用出现数据和环境预测因子来评估两种空间分辨率下的物种分布模型。程序必须计算每个分辨率的量化性能指标，然后根据性能差异编码一种解释，这种解释涉及尺度不匹配和生态过程表征。\n\n使用的基本原理包括：用于二元结果的伯努利分布的定义、用于二项式数据的广义线性模型 (GLM) 框架、二项式GLM的规范链接函数、最大似然估计原理，以及接收者操作特征 (ROC) 曲线下面积 (AUC) 和对数损失的运算定义。应使用遥感中的尺度概念，特别是空间分辨率和支持度，来推断预测因子聚合如何影响模型性能，而不依赖任何特定的简化公式。\n\n您的程序必须：\n- 在每个分辨率下，使用带有规范链接和截距项的二项式广义线性模型拟合一个二元响应模型。\n- 通过最大化似然来估计参数，并对除截距外的系数施加一个小的岭（二次）惩罚项，以确保在近可分情况下的数值稳定性。\n- 计算两种分辨率下的ROC曲线下面积和平均对数损失。\n- 根据分辨率之间的性能差异，编码一个整数代码作为解释，以反映关于生态过程尺度和尺度不匹配的假设。\n\n使用的定义：\n- 二元物种出现被建模为 $Y \\sim \\text{Bernoulli}(p)$，其中 $p$ 是出现概率。\n- 二项式GLM的规范链接函数关联了线性预测器和 $p$。\n- 最大似然估计找到使模型下观测到的二元结果的似然最大化的参数值。\n- ROC曲线下面积量化了预测的 $p$ 值在存在和不存在样本之间的排序性能。\n- 对数损失量化了给定预测的 $p$ 值下，每个观测的平均负对数似然。\n\n数据以精细和粗糙两种分辨率的环境预测因子和出现标签的数组形式提供。每个测试用例包含：\n- 精细分辨率预测因子 $X_{\\text{fine}} \\in \\mathbb{R}^{n_f \\times d}$。\n- 精细分辨率标签 $y_{\\text{fine}} \\in \\{0,1\\}^{n_f}$。\n- 粗糙分辨率预测因子 $X_{\\text{coarse}} \\in \\mathbb{R}^{n_c \\times d}$。\n- 粗糙分辨率标签 $y_{\\text{coarse}} \\in \\{0,1\\}^{n_c}$。\n- 预测因子包括植被指数（无单位）和以摄氏度为单位的地表温度。\n\n性能指标：\n- 计算 $AUC_{\\text{fine}}$ 和 $AUC_{\\text{coarse}}$，作为 $[0,1]$ 范围内的浮点数。\n- 计算 $L_{\\text{fine}}$ 和 $L_{\\text{coarse}}$ 作为平均对数损失（浮点数），数值越小表示性能越好。\n\n解释代码：\n- 设 $\\Delta = AUC_{\\text{fine}} - AUC_{\\text{coarse}}$ 且阈值 $\\tau_{\\text{AUC}} = 0.1$。\n- 如果在某个分辨率下，预测的概率实际上是常数（标准差小于 $10^{-12}$）或所有预测因子都是常数（方差为零），则将该分辨率视为退化（degenerate）。\n- 如果两个分辨率都退化或都产生实际上是常数的预测，则将解释代码设置为 $3$（因信息不足而无法确定）。\n- 否则，如果 $\\Delta \\ge \\tau_{\\text{AUC}}$，则将解释代码设置为 $1$（表明在精细分辨率下，更精细尺度的过程得到了更好的表征，而粗糙聚合引入了尺度不匹配）。\n- 否则，如果 $\\Delta \\le -\\tau_{\\text{AUC}}$，则将解释代码设置为 $2$（表明在粗糙分辨率下，大尺度的过程被更好地捕捉，而精细尺度的噪声妨碍了性能）。\n- 否则，将解释代码设置为 $0$（无显著差异；关于尺度不匹配的结论不明确）。\n\n单位：\n- 地表温度预测因子的单位是摄氏度。植被指数无单位。最终输出（AUC和对数损失）是无单位的浮点数。不涉及角度单位。所有小数必须以数字浮点数形式打印，而不是百分比。\n\n您的程序必须无需用户输入即可运行，并生成一行输出，其中包含一个案例结果列表。每个案例结果是一个包含五个值的列表：$[AUC_{\\text{fine}},AUC_{\\text{coarse}},L_{\\text{fine}},L_{\\text{coarse}},\\text{code}]$。在打印输出中，数字必须四舍五入到四位小数。最终输出格式必须为单行：一个用方括号括起来的逗号分隔列表，其中每个案例结果也用方括号括起来，例如 $[[0.8123,0.7431,0.4021,0.5012,1],[\\dots]]$。\n\n测试套件：\n- 案例1（由于精细尺度的植被指数模式，预计精细分辨率性能更好）：\n  - $X_{\\text{fine},1} = [\\,(0.1,15.0),(0.2,16.0),(0.3,17.0),(0.4,18.0),(0.5,19.0),(0.6,20.0),(0.7,21.0),(0.8,22.0),(0.35,15.0),(0.55,19.0),(0.75,23.0),(0.25,16.0)\\,]$\n  - $y_{\\text{fine},1} = [\\,0,0,0,0,1,1,1,1,0,1,1,0\\,]$\n  - $X_{\\text{coarse},1} = [\\,(0.3,17.0),(0.55,20.0),(0.7,22.0),(0.25,16.0)\\,]$\n  - $y_{\\text{coarse},1} = [\\,0,1,1,0\\,]$\n- 案例2（由于大尺度的温度梯度，预计粗糙分辨率性能更好）：\n  - $X_{\\text{fine},2} = [\\,(0.1,10.0),(0.9,10.5),(0.2,11.0),(0.8,11.5),(0.3,12.0),(0.7,12.5),(0.4,13.0),(0.6,13.5),(0.5,14.0),(0.5,10.2)\\,]$\n  - $y_{\\text{fine},2} = [\\,0,0,0,1,0,1,1,1,1,0\\,]$\n  - $X_{\\text{coarse},2} = [\\,(0.45,11.0),(0.65,12.5),(0.5,13.5),(0.6,14.0),(0.3,10.5)\\,]$\n  - $y_{\\text{coarse},2} = [\\,0,1,1,1,0\\,]$\n- 案例3（两种分辨率下都接近线性可分；正则化确保了有限的估计值）：\n  - $X_{\\text{fine},3} = [\\,(0.05,10.0),(0.1,10.0),(0.9,10.0),(0.95,10.0),(0.85,10.0),(0.15,10.0)\\,]$\n  - $y_{\\text{fine},3} = [\\,0,0,1,1,1,0\\,]$\n  - $X_{\\text{coarse},3} = [\\,(0.5,10.0),(0.8,10.0),(0.2,10.0)\\,]$\n  - $y_{\\text{coarse},3} = [\\,1,1,0\\,]$\n- 案例4（退化：预测因子为常数；预计 $AUC \\approx 0.5$ 且解释不确定）：\n  - $X_{\\text{fine},4} = [\\,(0.5,20.0),(0.5,20.0),(0.5,20.0),(0.5,20.0)\\,]$\n  - $y_{\\text{fine},4} = [\\,0,1,0,1\\,]$\n  - $X_{\\text{coarse},4} = [\\,(0.5,20.0),(0.5,20.0)\\,]$\n  - $y_{\\text{coarse},4} = [\\,0,1\\,]$\n\n算法要求：\n- 在GLM中使用截距项，并且不对截距施加惩罚。\n- 在拟合前，将每个分辨率内的预测因子特征标准化为零均值和单位方差，以稳定优化过程；对于方差为零的特征，将其中心化为零而不进行缩放。\n- 为了稳定性，使用一个小的岭惩罚系数 $\\lambda = 10^{-2}$。\n- 在计算对数损失时，将预测概率裁剪到 $[10^{-12}, 1 - 10^{-12}]$ 范围内。\n- 使用能正确处理平局（ties）的方法计算AUC。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试案例的结果是一个包含 $5$ 个值的列表：$[AUC_{\\text{fine}},AUC_{\\text{coarse}},L_{\\text{fine}},L_{\\text{coarse}},\\text{code}]$。在打印输出中，所有数值必须四舍五入到 $4$ 位小数。不得打印任何其他文本。",
            "solution": "该问题要求实现和评估在精细和粗糙两个不同空间分辨率下的物种分布模型。建模框架是用于二元出现数据的广义线性模型 (GLM)，具体来说是逻辑回归模型，通过惩罚最大似然法进行参数估计。任务的核心是拟合这些模型，使用接收者操作特征曲线下面积 ($AUC$) 和对数损失计算它们的性能，并在生态尺度的背景下解释性能差异。\n\n首先，我们对统计模型进行形式化描述。物种在给定位置 $i$ 出现与否，由二元随机变量 $Y_i$ 表示，假定其遵循伯努利分布：\n$$\nY_i \\sim \\text{Bernoulli}(p_i)\n$$\n其中 $p_i$ 是出现概率 ($Y_i=1$)。\n\nGLM通过一个链接函数将响应变量的期望值 $E[Y_i] = p_i$ 与预测变量的线性组合关联起来。对于二项分布族，规范链接函数是logit函数：\n$$\n\\eta_i = g(p_i) = \\log\\left(\\frac{p_i}{1-p_i}\\right)\n$$\n线性预测器 $\\eta_i$ 是该位置预测变量 $\\mathbf{x}_i \\in \\mathbb{R}^d$ 的一个线性函数：\n$$\n\\eta_i = \\beta_0 + \\mathbf{x}_i^T \\boldsymbol{\\beta}\n$$\n这里，$\\beta_0$ 是截距项，$\\boldsymbol{\\beta} \\in \\mathbb{R}^d$ 是 $d$ 个预测因子的系数向量。为了方便矩阵表示，我们可以定义一个增广参数向量 $\\boldsymbol{\\theta} = [\\beta_0, \\beta_1, \\dots, \\beta_d]^T$ 和一个增广预测向量 $\\mathbf{x}_{\\text{aug}, i} = [1, x_{i1}, \\dots, x_{id}]^T$，因此 $\\eta_i = \\mathbf{x}_{\\text{aug}, i}^T \\boldsymbol{\\theta}$。\n\nlogit链接函数的反函数是逻辑S型函数（logistic sigmoid function）$\\sigma(\\eta)$，它使我们能够恢复概率 $p_i$：\n$$\np_i = \\sigma(\\eta_i) = \\frac{1}{1 + e^{-\\eta_i}}\n$$\n\n模型参数 $\\boldsymbol{\\theta}$ 通过最大化观测数据的似然来估计。对于一组 $n$ 个独立观测 $(\\mathbf{y}, \\mathbf{X})$，对数似然函数是：\n$$\n\\ell(\\boldsymbol{\\theta}; \\mathbf{y}, \\mathbf{X}) = \\sum_{i=1}^n \\left[ y_i \\log(p_i) + (1-y_i)\\log(1-p_i) \\right]\n$$\n代入 $p_i = \\sigma(\\mathbf{x}_{\\text{aug}, i}^T \\boldsymbol{\\theta})$，我们得到：\n$$\n\\ell(\\boldsymbol{\\theta}) = \\sum_{i=1}^n \\left[ y_i (\\mathbf{x}_{\\text{aug}, i}^T \\boldsymbol{\\theta}) - \\log(1 + e^{\\mathbf{x}_{\\text{aug}, i}^T \\boldsymbol{\\theta}}) \\right]\n$$\n为确保数值稳定性并防止完全可分性问题，我们向对数似然中添加一个岭 (L2) 惩罚项。惩罚仅适用于斜率系数 $\\boldsymbol{\\beta}$，不适用于截距 $\\beta_0$。需要最大化的惩罚对数似然是：\n$$\n\\ell_p(\\boldsymbol{\\theta}) = \\ell(\\boldsymbol{\\theta}) - \\frac{\\lambda}{2} \\sum_{j=1}^d \\beta_j^2\n$$\n其中 $\\lambda$ 是正则化参数，指定为 $\\lambda=10^{-2}$。由于数值优化程序通常是寻找最小值，我们将最小化负的惩罚对数似然 $- \\ell_p(\\boldsymbol{\\theta})$。这是一个凸优化问题，保证了唯一解。我们使用基于梯度的方法来完成此任务。\n\n在模型拟合之前，每个分辨率下的预测变量 $X$ 被标准化为均值为 $0$、标准差为 $1$。对于均值为 $\\mu_j$、标准差为 $\\sigma_j$ 的特征 $j$，值 $x_{ij}$ 被转换为 $z_{ij} = (x_{ij} - \\mu_j) / \\sigma_j$。如果一个预测因子的方差为零（$\\sigma_j=0$），其标准化值将被设为 $0$。这种标准化将预测因子置于可比较的尺度上，有利于优化算法的稳定性和收敛。\n\n在为精细和粗糙两种分辨率拟合模型并获得最优参数向量（$\\boldsymbol{\\theta}_{\\text{fine}}$ 和 $\\boldsymbol{\\theta}_{\\text{coarse}}$）之后，我们计算性能指标。\n\n1.  **对数损失 (Log Loss)**：该指标量化了预测的平均负对数似然。对于一组 $n$ 个观测，其定义为：\n    $$\n    L = -\\frac{1}{n} \\sum_{i=1}^n \\left[ y_i \\log(\\hat{p}_i) + (1-y_i)\\log(1-\\hat{p}_i) \\right]\n    $$\n    其中 $\\hat{p}_i$ 是模型对观测 $i$ 的预测概率。为避免由 $\\log(0)$ 引起的数值错误，预测概率被裁剪到一个由小 epsilon 界定的区间内，具体为 $[10^{-12}, 1 - 10^{-12}]$。较低的对数损失值表示拟合效果更好。\n\n2.  **ROC曲线下面积 ($AUC$)**: 该指标评估模型区分正例 ($y=1$) 和负例 ($y=0$) 的能力。它等价于模型为一个随机选择的正例分配比一个随机选择的负例更高的预测概率的概率。为了在正确处理预测概率中平局的情况下计算 $AUC$，我们可以将其与 Mann-Whitney U 统计量联系起来。设 $\\mathcal{P} = \\{i | y_i=1\\}$ 为正例索引集，$\\mathcal{A} = \\{i | y_i=0\\}$ 为负例索引集，其中 $n_1 = |\\mathcal{P}|$ 且 $n_0 = |\\mathcal{A}|$。$AUC$ 计算如下：\n    $$\n    AUC = \\frac{1}{n_1 n_0} \\sum_{i \\in \\mathcal{P}} \\sum_{j \\in \\mathcal{A}} \\left( \\mathbf{1}_{\\hat{p}_i > \\hat{p}_j} + 0.5 \\cdot \\mathbf{1}_{\\hat{p}_i = \\hat{p}_j} \\right)\n    $$\n    其中 $\\mathbf{1}$ 是指示函数。$AUC$ 为 $1.0$ 表示完美的分类器，而 $AUC$ 为 $0.5$ 则对应于一个不比随机猜测更好的模型。\n\n最后，根据性能差异分配一个解释代码。我们定义 $\\Delta = AUC_{\\text{fine}} - AUC_{\\text{coarse}}$ 和一个阈值 $\\tau_{AUC} = 0.1$。\n- 如果一个分辨率的所有预测因子都是常数，或者模型产生的概率实际上是常数（标准差  $10^{-12}$），则该分辨率被认为是退化的。如果两个分辨率都退化，则代码为 $3$。\n- 如果 $\\Delta \\ge \\tau_{AUC}$，代码为 $1$，表明精细分辨率模型更好地捕捉了潜在的生态过程。\n- 如果 $\\Delta \\le -\\tau_{AUC}$，代码为 $2$，表明粗糙分辨率模型性能更好，可能是通过滤除精细尺度噪声或更好地匹配主导生态驱动因子的尺度。\n- 否则，代码为 $0$，表示没有显著的性能差异。\n\n整体算法的流程是，对每个测试用例，先对精细分辨率数据，再对粗糙分辨率数据，应用整个序列——预处理、模型拟合、性能评估和解释——然后再比较结果。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to run the species distribution modeling and evaluation for all test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"fine\": (\n                np.array([(0.1, 15.0), (0.2, 16.0), (0.3, 17.0), (0.4, 18.0), (0.5, 19.0), (0.6, 20.0), (0.7, 21.0), (0.8, 22.0), (0.35, 15.0), (0.55, 19.0), (0.75, 23.0), (0.25, 16.0)]),\n                np.array([0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0])\n            ),\n            \"coarse\": (\n                np.array([(0.3, 17.0), (0.55, 20.0), (0.7, 22.0), (0.25, 16.0)]),\n                np.array([0, 1, 1, 0])\n            )\n        },\n        {\n            \"fine\": (\n                np.array([(0.1, 10.0), (0.9, 10.5), (0.2, 11.0), (0.8, 11.5), (0.3, 12.0), (0.7, 12.5), (0.4, 13.0), (0.6, 13.5), (0.5, 14.0), (0.5, 10.2)]),\n                np.array([0, 0, 0, 1, 0, 1, 1, 1, 1, 0])\n            ),\n            \"coarse\": (\n                np.array([(0.45, 11.0), (0.65, 12.5), (0.5, 13.5), (0.6, 14.0), (0.3, 10.5)]),\n                np.array([0, 1, 1, 1, 0])\n            )\n        },\n        {\n            \"fine\": (\n                np.array([(0.05, 10.0), (0.1, 10.0), (0.9, 10.0), (0.95, 10.0), (0.85, 10.0), (0.15, 10.0)]),\n                np.array([0, 0, 1, 1, 1, 0])\n            ),\n            \"coarse\": (\n                np.array([(0.5, 10.0), (0.8, 10.0), (0.2, 10.0)]),\n                np.array([1, 1, 0])\n            )\n        },\n        {\n            \"fine\": (\n                np.array([(0.5, 20.0), (0.5, 20.0), (0.5, 20.0), (0.5, 20.0)]),\n                np.array([0, 1, 0, 1])\n            ),\n            \"coarse\": (\n                np.array([(0.5, 20.0), (0.5, 20.0)]),\n                np.array([0, 1])\n            )\n        }\n    ]\n\n    lambda_penalty = 1e-2\n    prob_clip_val = 1e-12\n    const_prob_std_thresh = 1e-12\n    auc_diff_thresh = 0.1\n\n    def _sigmoid(z):\n        # Clip to avoid overflow\n        z = np.clip(z, -500, 500)\n        return 1 / (1 + np.exp(-z))\n\n    def _compute_auc(y_true, y_pred):\n        pos_preds = y_pred[y_true == 1]\n        neg_preds = y_pred[y_true == 0]\n        \n        n_pos = len(pos_preds)\n        n_neg = len(neg_preds)\n\n        if n_pos == 0 or n_neg == 0:\n            return 0.5 # Return a neutral value if no pairs to compare\n\n        total_pairs = n_pos * n_neg\n        \n        # Broadcasting for efficient pair-wise comparison\n        comparison_matrix = pos_preds[:, np.newaxis]  neg_preds\n        tie_matrix = pos_preds[:, np.newaxis] == neg_preds\n        \n        score = np.sum(comparison_matrix) + 0.5 * np.sum(tie_matrix)\n        \n        return score / total_pairs\n\n    def _compute_log_loss(y_true, y_pred):\n        y_pred_clipped = np.clip(y_pred, prob_clip_val, 1 - prob_clip_val)\n        loss = -np.mean(y_true * np.log(y_pred_clipped) + (1 - y_true) * np.log(1 - y_pred_clipped))\n        return loss\n\n    def fit_and_evaluate(X, y, l2_lambda):\n        n_samples, n_features = X.shape\n        \n        # Standardize predictors\n        mean = np.mean(X, axis=0)\n        std = np.std(X, axis=0)\n        \n        is_degenerate_predictor = np.all(std  1e-9)\n\n        X_std = np.zeros_like(X)\n        non_zero_std_mask = std > 1e-9\n        if np.any(non_zero_std_mask):\n            X_std[:, non_zero_std_mask] = (X[:, non_zero_std_mask] - mean[non_zero_std_mask]) / std[non_zero_std_mask]\n\n        X_aug = np.hstack([np.ones((n_samples, 1)), X_std])\n\n        def neg_penalized_log_likelihood(theta, X_a, y_obs, lmbd):\n            eta = X_a @ theta\n            # Clip eta to avoid overflow in exp\n            eta = np.clip(eta, -500, 500)\n            log_lik = np.sum(y_obs * eta - np.log(1 + np.exp(eta)))\n            penalty = (lmbd / 2) * np.sum(theta[1:]**2) # No penalty on intercept theta[0]\n            return -(log_lik - penalty)\n\n        theta_initial = np.zeros(n_features + 1)\n        res = minimize(neg_penalized_log_likelihood, theta_initial, args=(X_aug, y, l2_lambda), method='BFGS')\n        theta_opt = res.x\n        \n        # Predict probabilities\n        p_hat = _sigmoid(X_aug @ theta_opt)\n        \n        is_degenerate_prediction = np.std(p_hat)  const_prob_std_thresh\n        is_degenerate = is_degenerate_predictor or is_degenerate_prediction\n\n        # Compute metrics\n        auc = _compute_auc(y, p_hat)\n        log_loss = _compute_log_loss(y, p_hat)\n        \n        return auc, log_loss, is_degenerate\n\n    final_results = []\n    for case in test_cases:\n        X_fine, y_fine = case[\"fine\"]\n        X_coarse, y_coarse = case[\"coarse\"]\n\n        auc_fine, ll_fine, deg_fine = fit_and_evaluate(X_fine, y_fine, lambda_penalty)\n        auc_coarse, ll_coarse, deg_coarse = fit_and_evaluate(X_coarse, y_coarse, lambda_penalty)\n\n        # Interpretation code logic\n        if deg_fine and deg_coarse:\n            code = 3\n        else:\n            delta_auc = auc_fine - auc_coarse\n            if delta_auc >= auc_diff_thresh:\n                code = 1\n            elif delta_auc = -auc_diff_thresh:\n                code = 2\n            else:\n                code = 0\n                \n        result_list = [auc_fine, auc_coarse, ll_fine, ll_coarse, code]\n        final_results.append(result_list)\n\n    # Format the final output string\n    formatted_cases = []\n    for res in final_results:\n        # Round all numeric values to 4 decimal places\n        formatted_res = [f\"{val:.4f}\" if isinstance(val, float) else str(val) for val in res]\n        formatted_cases.append(f\"[{','.join(formatted_res)}]\")\n    \n    print(f\"[{','.join(formatted_cases)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当您建立了一个物种分布模型并获得了看似不错的性能指标（如$AUC$）时，一个至关重要的问题是：这个评估结果是否过于乐观？物种分布数据和环境预测因子普遍存在空间自相关性，即邻近位置的观测值并非相互独立，这违背了标准随机交叉验证的基本假设。这个概念性练习将挑战您对模型评估稳健性的理解，阐明为什么随机交叉验证会因“信息泄露”而高估模型的预测能力，以及为什么空间交叉验证对于获得模型在新地理区域的真实泛化性能至关重要。",
            "id": "3852189",
            "problem": "您正在为一个位于位置 $\\mathbf{s} \\in \\mathcal{D} \\subset \\mathbb{R}^{2}$ 的二元存在-缺失响应 $Y(\\mathbf{s}) \\in \\{0,1\\}$ 建立一个物种分布模型（SDM; Species Distribution Model），并使用一组遥感环境变量 $\\mathbf{X}(\\mathbf{s}) \\in \\mathbb{R}^{p}$。假设数据生成结构如下：$Y(\\mathbf{s})$ 的条件均值遵循一个逻辑斯蒂连接，其线性预测器为 $\\eta(\\mathbf{s}) = \\beta_{0} + \\boldsymbol{\\beta}^{\\top} \\mathbf{X}(\\mathbf{s}) + \\varepsilon(\\mathbf{s})$，其中 $\\varepsilon(\\mathbf{s})$ 是一个均值为零的空间随机效应，其协方差函数为 $\\operatorname{Cov}[\\varepsilon(\\mathbf{s}), \\varepsilon(\\mathbf{s}^{\\prime})] = \\sigma^{2} \\rho(\\lVert \\mathbf{s} - \\mathbf{s}^{\\prime} \\rVert)$，相关函数 $\\rho(h)$ 随分离距离 $h$ 单调递减，并满足 $\\rho(0)=1$ 且当 $h \\to \\infty$ 时 $\\rho(h) \\to 0$。您希望估计预期的区域外泛化性能，该性能定义为在与所有训练位置至少相距 $h_{\\star}$ 的测试位置 $\\mathbf{s}_{\\text{test}}$ 进行预测时的期望损失，其中 $h_{\\star}$ 足够大以至于 $\\rho(h_{\\star}) \\approx 0$。考虑使用 $K$ 折的交叉验证程序，并假设 $K \\geq 2$。\n\n在此情景下，关于空间交叉验证和随机交叉验证的以下哪些陈述是正确的？选择所有适用项。\n\nA. 空间交叉验证将观测数据划分到地理上不相交的折中，使得训练集和测试集至少相隔一个距离 $h_{\\star}$（在此距离上 $\\rho(h_{\\star}) \\approx 0$），从而减少了折之间的统计依赖性，与随机交叉验证相比，能够产生对区域外泛化误差偏差较小的估计。\n\nB. 在存在空间自相关的情况下，随机交叉验证仍然是无偏的，因为独立性假设仅适用于模型残差，而不适用于观测对 $\\{Y(\\mathbf{s}), \\mathbf{X}(\\mathbf{s})\\}$，并且残差的独立性由最大似然估计自动保证。\n\nC. 在具有空间结构的物种分布模型中，随机交叉验证倾向于高估预测性能，因为许多测试位置会落在训练位置的空间自相关范围内，因此预测值会通过 $\\rho(h)  0$ 的信息泄露而受益；因此，交叉验证得到的分数反映的是短程插值，而非真正的区域外泛化。\n\nD. 空间交叉验证应始终使用固定大小的棋盘格分块方案，并选择块大小以最小化样本内偏差，因为这能保证对迁移性能作出最优无偏的估计。\n\nE. 如果环境变量 $\\mathbf{X}(\\mathbf{s})$ 被完美测量，且物种分布模型的参数形式正确，那么即使当 $\\rho(h)  0$ 时，随机交叉验证对于区域外性能的估计也是无偏的，因为在以 $\\mathbf{X}(\\mathbf{s})$ 为条件的情况下， $Y(\\mathbf{s})$ 中任何剩余的空间自相关都不能影响测试预测。",
            "solution": "数据生成过程为位置 $\\mathbf{s}$ 处的响应 $Y(\\mathbf{s})$ 指定。物种存在的概率 $p(\\mathbf{s}) = P(Y(\\mathbf{s})=1)$ 由逻辑斯蒂模型给出：\n$$ \\operatorname{logit}(p(\\mathbf{s})) = \\log\\left(\\frac{p(\\mathbf{s})}{1 - p(\\mathbf{s})}\\right) = \\eta(\\mathbf{s}) = \\beta_{0} + \\boldsymbol{\\beta}^{\\top} \\mathbf{X}(\\mathbf{s}) + \\varepsilon(\\mathbf{s}) $$\n关键要素是空间随机效应 $\\varepsilon(\\mathbf{s})$，它在地理上相近的观测值之间引入了相关性。具体来说，对于任意两个位置 $\\mathbf{s}_i$ 和 $\\mathbf{s}_j$，即使以其预测变量 $\\mathbf{X}(\\mathbf{s}_i)$ 和 $\\mathbf{X}(\\mathbf{s}_j)$ 为条件，响应 $Y(\\mathbf{s}_i)$ 和 $Y(\\mathbf{s}_j)$ 也不是独立的。它们的依赖性是由 $\\varepsilon(\\mathbf{s}_i)$ 和 $\\varepsilon(\\mathbf{s}_j)$ 之间的相关性驱动的，只要距离 $h = \\lVert \\mathbf{s}_i - \\mathbf{s}_j \\rVert$ 小于空间自相关的范围，这种相关性就非零。\n\n目标是估计“区域外泛化性能”，即在远离任何训练数据位置 $\\mathbf{s}_{\\text{train}}$ 的测试数据位置 $\\mathbf{s}_{\\text{test}}$ 上的性能。形式上，对于所有训练点，$\\lVert \\mathbf{s}_{\\text{test}} - \\mathbf{s}_{\\text{train}} \\rVert \\ge h_{\\star}$，其中 $\\rho(h_{\\star}) \\approx 0$。这意味着测试位置的随机效应 $\\varepsilon(\\mathbf{s}_{\\text{test}})$ 与所有训练位置的随机效应 $\\varepsilon(\\mathbf{s}_{\\text{train}})$ 不相关。\n\n**随机交叉验证（RCV）**：RCV 将数据点随机分配到各个折中。因此，一个折中的测试点很可能在地理上靠近其他折中的某些训练点。对于这样一个测试点 $\\mathbf{s}_{\\text{test}}$ 和附近的训练点 $\\mathbf{s}_{\\text{train}}$ 对，距离 $h = \\lVert \\mathbf{s}_{\\text{test}} - \\mathbf{s}_{\\text{train}} \\rVert$ 很小，因此 $\\rho(h)  0$。因此，训练数据包含了关于测试位置随机效应 $\\varepsilon(\\mathbf{s}_{\\text{test}})$ 值的信息。一个拟合好的模型可以利用这些信息（例如，通过经验贝叶斯估计或随机效应场的克里金法）来做出更准确的预测。这个预测任务是一种空间*插值*。然而，目标是估计空间*外推*（区域外）的性能，在这种情况下，这些信息是不存在的。因为插值比外推更容易，所以 RCV 会对区域外泛化性能产生一个乐观偏倚的估计（即，它报告的性能会比实际可达到的性能更好）。\n\n**空间交叉验证（SCV）**：SCV 旨在解决这个问题。它根据数据的空间位置将其划分为不同的折，创建地理上连续的块或缓冲区。其核心思想是确保测试折中的任何点与其对应训练集中的任何点之间的最小距离足够大（理想情况下 $\\ge h_{\\star}$），以打破空间依赖性。通过这样做，每个折的测试集与其训练集近似独立，从而模拟了区域外预测的情景。因此，SCV 提供了一个偏差小得多、更现实的区域外泛化性能估计。\n\n现在，让我们基于这一理解来评估每个选项。\n\n**A. 空间交叉验证将观测数据划分到地理上不相交的折中，使得训练集和测试集至少相隔一个距离 $h_{\\star}$（在此距离上 $\\rho(h_{\\star}) \\approx 0$），从而减少了折之间的统计依赖性，与随机交叉验证相比，能够产生对区域外泛化误差偏差较小的估计。**\n这个陈述准确地描述了空间交叉验证的理想实现方式和目的。通过创建地理上不相交的折，它强制在训练集和测试集之间保持一个最小分离距离。这种分离的目的是确保由具有相关性 $\\rho(h)$ 的空间随机效应 $\\varepsilon(\\mathbf{s})$ 产生的统计依赖性被最小化或消除。这使得验证过程能更好地模拟区域外预测的目标任务。因此，与随机交叉验证产生的结果相比，其泛化误差的估计具有较小的乐观偏差。\n**结论：正确。**\n\n**B. 在存在空间自相关的情况下，随机交叉验证仍然是无偏的，因为独立性假设仅适用于模型残差，而不适用于观测对 $\\{Y(\\mathbf{s}), \\mathbf{X}(\\mathbf{s})\\}$，并且残差的独立性由最大似然估计自动保证。**\n这个陈述在几个方面都是错误的。首先，在这种情况下，随机交叉验证在估计区域外性能方面存在明显的（乐观）偏差。其次，交叉验证的有效性依赖于训练集和测试集的独立性，而在这里这一条件被违反了。关于独立性假设“仅适用于模型残差”的说法具有误导性；观测值之间的依赖性正是导致 RCV 对于此目标无效的问题所在。第三，“残差独立性由最大似然估计自动保证”的说法是错误的。最大似然估计（MLE）是一种在*一组给定假设*（可能包括独立性）下寻找最能拟合数据的模型参数的方法；如果底层结构是相关的，并且验证方案没有尊重这一点，它并不能神奇地在数据或残差中创造出独立性。\n**结论：错误。**\n\n**C. 在具有空间结构的物种分布模型中，随机交叉验证倾向于高估预测性能，因为许多测试位置会落在训练位置的空间自相关范围内，因此预测值会通过 $\\rho(h)  0$ 的信息泄露而受益；因此，交叉验证得到的分数反映的是短程插值，而非真正的区域外泛化。**\n这个陈述为随机交叉验证在这种背景下的失败提供了一个极好且准确的解释。“高估预测性能”正确地指出了偏差的方向（例如，AUC 会被夸大，错误率会被低估）。其机制被正确地识别为“信息泄露”，这是由于测试点与训练点距离很近，使得它们相关的随机效应（通过 $\\rho(h)0$ 介导）能够为预测提供信息。正在执行的任务（短程插值）与目标任务（区域外泛化）之间的区别是问题的核心。\n**结论：正确。**\n\n**D. 空间交叉验证应始终使用固定大小的棋盘格分块方案，并选择块大小以最小化样本内偏差，因为这能保证对迁移性能作出最优无偏的估计。**\n这个陈述过于绝对，并包含不正确的信息。虽然棋盘格方案是一种空间交叉验证，但它不是唯一的，也并非“总是”最佳选择。还存在其他方法，如分块交叉验证或带缓冲区的交叉验证。更重要的是，选择块大小的标准是错误的。块大小必须根据数据的空间结构来选择，特别是空间自相关的范围，以确保折之间有足够的分离。目标是使块大小大于自相关范围。“最小化样本内偏差”是一个与最大化训练数据似然相关的模型拟合标准；它不是设计有效交叉验证分区的原则。最后，没有哪种实用方法能“保证”一个“最优无偏”的估计。空间交叉验证旨在做到偏差*更小*，但关于最优性和保证的说法是没有根据的。\n**结论：错误。**\n\n**E. 如果环境变量 $\\mathbf{X}(\\mathbf{s})$ 被完美测量，且物种分布模型的参数形式正确，那么即使当 $\\rho(h)  0$ 时，随机交叉验证对于区域外性能的估计也是无偏的，因为在以 $\\mathbf{X}(\\mathbf{s})$ 为条件的情况下， $Y(\\mathbf{s})$ 中任何剩余的空间自相关都不能影响测试预测。**\n这个陈述是错误的。它错误地假设包含预测变量 $\\mathbf{X}(\\mathbf{s})$ 就消除了空间自相关问题。模型明确包含 $\\varepsilon(\\mathbf{s})$ 项，以解释*未被* $\\mathbf{X}(\\mathbf{s})$ 解释的空间模式。即使模型被完美设定和拟合，对新位置 $\\mathbf{s}_{\\text{test}}$ 的预测仍会涉及对 $\\varepsilon(\\mathbf{s}_{\\text{test}})$ 的估计。在 GLMM 的背景下，这个预测是以整个训练集为条件的，而训练集包含了关于已实现的随机效应场的信息。如果 $\\mathbf{s}_{\\text{test}}$ 靠近某个训练点 $\\mathbf{s}_{\\text{train}}$，那么 $\\varepsilon(\\mathbf{s}_{\\text{test}})$ 和 $\\varepsilon(\\mathbf{s}_{\\text{train}})$ 之间的相关性就会被用来改进预测（这就是克里金法的原理）。因此，由 $\\varepsilon(\\mathbf{s})$ 代表的剩余空间自相关绝对会影响测试预测，随机交叉验证仍然是有偏的。\n**结论：错误。**",
            "answer": "$$\\boxed{AC}$$"
        }
    ]
}