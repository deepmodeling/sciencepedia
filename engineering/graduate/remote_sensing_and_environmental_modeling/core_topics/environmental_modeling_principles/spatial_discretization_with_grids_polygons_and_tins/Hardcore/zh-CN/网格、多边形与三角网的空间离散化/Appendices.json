{
    "hands_on_practices": [
        {
            "introduction": "在环境建模中，我们经常处理不规则区域（如流域或生态区）内的大规模遥感栅格数据。直接使用密集网格存储这些数据会浪费大量内存来表示研究区域外的“无数据”值。本练习旨在通过从第一性原理出发，量化比较密集存储与稀疏存储（如压缩稀疏行格式）的内存占用，从而让您亲身体会为特定空间数据模式选择合适数据结构所带来的显著计算优势。",
            "id": "3850653",
            "problem": "一个环境建模工作流将遥感观测数据整合到流域生物物理场的栅格化表示中。该流域由水文划分产生的一组多边形定义，只有质心落在这些多边形内的网格单元被视为“活动”单元。空间离散化使用一个覆盖多边形域的、由 $N_x$ 列和 $N_y$ 行组成的均匀直线网格。许多单元是“非活动的”（在多边形并集之外），因此活动集是稀疏的。为提高计算效率，数据按波段组织，每个活动单元都包含相同的波段集。\n\n从基本定义出发——密集网格存储每个波段中每个单元的值，而稀疏网格仅存储非零值及其位置——并使用广泛采用的压缩稀疏行 (CSR) 数据结构，从第一性原理推导两种表示的内存占用，然后量化内存节省。在此背景下，CSR 包含：\n- 一个长度为 $N_y + 1$ 的“行指针”数组，使用 $64$ 位整数表示每网格行（行主序）的累积计数，\n- 一个长度等于活动单元数量的“列索引”数组，使用 $32$ 位整数，\n- 以及为每个活动单元存储的各波段值。\n\n假设一个包含四个地球物理场的遥感数据同化的实际配置如下：网格维度为 $N_x = 10000$ 和 $N_y = 12000$，波段数为 $K = 4$，每个波段值的数据类型为 $64$ 位浮点数，活动单元的比例（由于使用共同的多边形掩膜，所有波段的稀疏模式相同）为 $f = 0.07$，并且非活动单元不存储在稀疏表示中。密集表示存储每个网格单元处每个波段的值。稀疏表示存储一套由所有波段共享的索引（行指针和列索引），外加仅在活动单元处的所有波段值。\n\n取 1 兆字节 (MiB) 为 $1$ mebibyte (MiB) $= 2^{20}$ 字节，其中“兆字节 (MiB)”表示二进制信息单位。计算密集与稀疏存储的内存节省，即“密集内存减去稀疏内存”，并以兆字节 (MiB) 表示。将最终答案四舍五入至四位有效数字。将结果表示为单个实数。",
            "solution": "该问题要求对多波段栅格数据集的密集存储与稀疏存储的内存占用进行定量比较。解决方案将从第一性原理出发，通过计算每种表示所需的内存，然后求出它们的差值来推导。本次分析的基本内存单位是字节，其中 $1$ 字节等于 $8$ 比特。\n\n首先，我们定义网格中的总单元数。给定一个有 $N_x$ 列和 $N_y$ 行的网格，总单元数 $N_{total}$ 为：\n$$N_{total} = N_x \\times N_y$$\n\n给定以下参数：\n- 网格列数, $N_x = 10000$\n- 网格行数, $N_y = 12000$\n- 波段数, $K = 4$\n- 活动单元比例, $f = 0.07$\n- $64$ 位浮点数或 $64$ 位整数的大小：$64$ 比特 $= \\frac{64}{8} = 8$ 字节\n- $32$ 位整数的大小：$32$ 比特 $= \\frac{32}{8} = 4$ 字节\n\n总单元数为：\n$$N_{total} = 10000 \\times 12000 = 120,000,000$$\n\n活动单元的数量 $N_{active}$ 是总单元数的一部分，比例为 $f$：\n$$N_{active} = f \\times N_{total} = 0.07 \\times 120,000,000 = 8,400,000$$\n\n**1. 密集内存占用计算**\n\n在密集表示中，每个网格单元的每个波段都存储一个值。总内存 $M_{dense}$ 是总单元数、波段数和每个数据值大小（以字节为单位）的乘积。\n$$M_{dense} = N_{total} \\times K \\times (\\text{一个64位浮点数的大小})$$\n代入数值：\n$$M_{dense} = (120,000,000) \\times 4 \\times 8 \\text{ 字节}$$\n$$M_{dense} = 3,840,000,000 \\text{ 字节}$$\n\n**2. 稀疏内存占用计算**\n\n基于压缩稀疏行 (CSR) 格式的稀疏表示由三个部分组成：行指针数组、列索引数组和活动单元的数据值。\n\na. **行指针数组内存 ($M_{ptr}$)**：此数组长度为 $N_y + 1$，存储 $64$ 位整数。\n$$M_{ptr} = (N_y + 1) \\times (\\text{一个64位整数的大小})$$\n$$M_{ptr} = (12000 + 1) \\times 8 \\text{ 字节} = 12001 \\times 8 \\text{ 字节} = 96,008 \\text{ 字节}$$\n\nb. **列索引数组内存 ($M_{idx}$)**：此数组为每个活动单元存储列索引。其长度为 $N_{active}$，使用 $32$ 位整数。\n$$M_{idx} = N_{active} \\times (\\text{一个32位整数的大小})$$\n$$M_{idx} = 8,400,000 \\times 4 \\text{ 字节} = 33,600,000 \\text{ 字节}$$\n\nc. **数据值内存 ($M_{data}$)**：此部分存储实际的数据值。由于有 $K$ 个波段，且数据仅为活动单元存储，因此值的总数为 $N_{active} \\times K$。每个值都是一个 $64$ 位浮点数。\n$$M_{data} = N_{active} \\times K \\times (\\text{一个64位浮点数的大小})$$\n$$M_{data} = 8,400,000 \\times 4 \\times 8 \\text{ 字节} = 268,800,000 \\text{ 字节}$$\n\n总的稀疏内存占用 $M_{sparse}$ 是这三个部分的总和。问题指明索引结构在所有波段间共享，这已在此公式中考虑。\n$$M_{sparse} = M_{ptr} + M_{idx} + M_{data}$$\n$$M_{sparse} = 96,008 + 33,600,000 + 268,800,000 \\text{ 字节}$$\n$$M_{sparse} = 302,496,008 \\text{ 字节}$$\n\n**3. 内存节省计算**\n\n内存节省量 $\\Delta M$ 是密集内存占用与稀疏内存占用之间的差值。\n$$\\Delta M = M_{dense} - M_{sparse}$$\n$$\\Delta M = 3,840,000,000 \\text{ 字节} - 302,496,008 \\text{ 字节}$$\n$$\\Delta M = 3,537,503,992 \\text{ 字节}$$\n\n**4. 转换为兆字节 (MiB) 并四舍五入**\n\n最后一步是将内存节省量从字节转换为兆字节 (MiB)，并四舍五入到指定的精度。转换因子为 $1 \\text{ MiB} = 2^{20} \\text{ 字节} = 1,048,576 \\text{ 字节}$。\n$$\\Delta M_{\\text{MiB}} = \\frac{\\Delta M}{2^{20}} = \\frac{3,537,503,992}{1,048,576}$$\n$$\\Delta M_{\\text{MiB}} \\approx 3373.659179...$$\n\n问题要求将此结果四舍五入到四位有效数字。前四位有效数字是 $3$、$3$、$7$ 和 $3$。第五位数字是 $6$，大于或等于 $5$，因此我们将第四位数字向上取整。\n$$\\Delta M_{\\text{MiB}} \\approx 3374$$\n\n因此，通过使用稀疏表示实现的内存节省约为 $3374$ MiB。",
            "answer": "$$\\boxed{3374}$$"
        },
        {
            "introduction": "在地理信息科学中，将不同的多边形图层（例如土地利用图与行政区划图）进行叠加是一项核心操作。然而，由于数据来源和配准的微小差异，该操作常会产生被称为“伪多边形”的狭长几何伪影。本练习将指导您设计并实现一个算法，该算法基于几何形态和拓扑邻接规则来识别并消除这些伪多边形，同时通过保持平面图的欧拉特征 $ \\chi $ 不变来确保拓扑一致性。",
            "id": "3850619",
            "problem": "两个多边形图层之间的平面叠置操作会产生一个线状排列，该排列将平面划分为多个面，这些面的边界由输入多边形的线段组成。在遥感和环境建模中，当将土地覆盖多边形与行政单元结合时，此类叠置操作很常见。而由网格、多边形和不规则三角网（TINs）离散化的图层之间的配准误差，常常会产生被称为狭长多边形（sliver polygons）的窄条状伪影。这些伪影的来源可以通过计算几何学的核心定义来理解：当两条长度为 $\\,\\ell\\,$ 的近乎重合的边因一个微小的横向位移 $\\,\\delta\\,$（例如，单位为 $\\,\\mathrm{m}\\,$ 的地理配准误差）而错开时，叠置操作会产生一个面积约为 $\\,A \\approx \\delta \\,\\ell\\,$、由近乎平行的线段所界定的面。这类面的几何形状通常是高度各向异性的，即一个维度远小于另一个维度。\n\n从多边形面积和周长的基本定义以及平面图的拓扑结构出发，推导一个方案，该方案使用阈值来识别和消除狭长多边形，同时保持拓扑一致性。使用不依赖于特定坐标系的形状度量，例如最小宽度 $\\,w_{\\min}\\,$、最大宽度 $\\,w_{\\max}\\,$、面积 $\\,A\\,$ 以及各向异性比 $\\,r = \\dfrac{w_{\\min}}{w_{\\max}}\\,$。阈值谓词的设计必须只选择各向异性的面作为狭长多边形，并且消除操作必须将每个选定的面合并到共享其长边的唯一一个相邻邻居中，以使平面剖分的欧拉示性数 $\\,\\chi = V - E + F\\,$ 保持不变。假设多边形是轴对齐的，因此叠置产生的面是矩形，且邻接关系通过共享边（四邻域）来定义。所有长度单位为 $\\,\\mathrm{m}\\,$，面积单位为 $\\,\\mathrm{m}^2\\,$。\n\n您的程序必须用纯数学术语实现以下算法任务：\n- 从两个输入图层 $\\,L_1\\,$ 和 $\\,L_2\\,$ 构建叠置剖分，每个图层都以一组轴对齐矩形 $\\,[x_{\\min},y_{\\min},x_{\\max},y_{\\max}]\\,$（单位为 $\\,\\mathrm{m}\\,$）的形式给出。具体方法是：计算两个图层中所有矩形边的所有唯一 $\\,x\\,$ 和 $\\,y\\,$ 坐标并排序，然后枚举由连续的 $\\,x\\,$ 和 $\\,y\\,$ 区间形成的每个单元格。如果一个单元格与 $\\,L_1\\,$ 或 $\\,L_2\\,$ 中的至少一个矩形存在正面积的交集，则该单元格属于叠置并集。\n- 对于每个宽度为 $\\,w\\,$、高度为 $\\,h\\,$ 的叠置单元格，定义 $\\,w_{\\min} = \\min(w,h)\\,$、$\\,w_{\\max} = \\max(w,h)\\,$、$\\,r = \\dfrac{w_{\\min}}{w_{\\max}}\\,$ 和 $\\,A = w\\cdot h\\,$。一个单元格是候选狭长多边形的充要条件是 $\\,r \\le \\tau_r\\,$ 且 $\\,(A \\le \\tau_A \\,\\lor\\, w_{\\min} \\le \\tau_w)\\,$，其中 $\\,\\tau_r\\,$ 是一个无量纲的比率阈值，$\\,\\tau_A\\,$ 是一个面积阈值（单位为 $\\,\\mathrm{m}^2\\,$），$\\,\\tau_w\\,$ 是一个宽度阈值（单位为 $\\,\\mathrm{m}\\,$）。\n- 通过要求候选狭长多边形沿其长边恰好只与一个相邻邻居共享边界来强制实现拓扑一致性（即，如果 $\\,h \\ge w\\,$，则它在并集中必须恰好有一个水平邻居；如果 $\\,w  h\\,$，则它在并集中必须恰好有一个垂直邻居）。通过将这样的狭长多边形合并到该唯一邻居中来消除它。证明在该规则下，欧拉示性数的变化量为 $\\,\\Delta \\chi = 0\\,$。\n\n对于下面的每个测试用例，计算该方案将消除多少个叠置单元格。仅报告数量，无需输出几何图形。程序必须生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。\n\n使用以下测试套件（坐标单位为 $\\,\\mathrm{m}\\,$，阈值单位为指定单位）：\n\n- 测试用例 $\\,1\\,$ (理想情况，错位的条带):\n  - $\\,L_1 = \\{[0,0,10,5]\\}\\,$, $\\,L_2 = \\{[0.2,0,10.2,5]\\}\\,$.\n  - 阈值：$\\,\\tau_A = 0.5\\,\\mathrm{m}^2\\,$，$\\,\\tau_r = 0.1\\,$，$\\,\\tau_w = 0.25\\,\\mathrm{m}\\,$。\n\n- 测试用例 $\\,2\\,$ (面积阈值处于边界条件):\n  - $\\,L_1 = \\{[0,0,10,5]\\}\\,$, $\\,L_2 = \\{[0.2,0,10.2,5]\\}\\,$.\n  - 阈值：$\\,\\tau_A = 1.0\\,\\mathrm{m}^2\\,$，$\\,\\tau_r = 1.0\\,$，$\\,\\tau_w = 0.05\\,\\mathrm{m}\\,$。\n\n- 测试用例 $\\,3\\,$ (无配准误差):\n  - $\\,L_1 = \\{[0,0,10,5]\\}\\,$, $\\,L_2 = \\{[0,0,10,5]\\}\\,$.\n  - 阈值：$\\,\\tau_A = 0.1\\,\\mathrm{m}^2\\,$，$\\,\\tau_r = 0.1\\,$，$\\,\\tau_w = 0.1\\,\\mathrm{m}\\,$。\n\n- 测试用例 $\\,4\\,$ (复杂的叠置，双轴均有配准误差，且有一个应保留的内部图斑):\n  - $\\,L_1 = \\{[0,0,10,10]\\}\\,$, $\\,L_2 = \\{[0.1,0.1,10.1,10.1],\\,[2,2,2.3,2.3]\\}\\,$.\n  - 阈值：$\\,\\tau_A = 0.05\\,\\mathrm{m}^2\\,$，$\\,\\tau_r = 0.2\\,$，$\\,\\tau_w = 0.12\\,\\mathrm{m}\\,$。\n\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，$\\,[a,b,c,d]\\,$），其中每个条目是对应测试用例的整数计数。",
            "solution": "该问题要求开发并实现一个方案，用于识别和消除由两个轴对齐矩形图层叠置产生的狭长多边形。消除过程必须保持拓扑一致性，即平面剖分的欧拉示性数保持不变。\n\n### 步骤 1：问题阐述与验证\n该问题是有效的。它在科学上基于计算几何原理及其在地理信息科学（GIS）中的应用。问题陈述清晰，提供了精确的算法、无歧义的定义和一套完整的测试数据。语言客观，约束条件可行。\n\n### 步骤 2：算法方案推导\n该过程分为三个主要任务：构建叠置，基于形状度量识别候选狭长多边形，以及基于拓扑一致性规则消除它们。\n\n#### 2.1. 叠置剖分构建\n给定两个图层 $L_1$ 和 $L_2$（每个图层都是一组轴对齐的矩形），叠置剖分是通过收集所有矩形边界的唯一 $x$ 和 $y$ 坐标来构建网格而成的。设所有唯一 x 坐标的集合为 $X = \\{x_0, x_1, \\dots, x_{n_x}\\}$，所有唯一 y 坐标的集合为 $Y = \\{y_0, y_1, \\dots, y_{n_y}\\}$，两者均已排序。这些坐标定义了一个由基本矩形单元格组成的网格。一个单元格 $C_{ij}$ 由区间 $[x_i, x_{i+1}]$ 和 $[y_j, y_{j+1}]$ 的笛卡尔积定义，其中 $i \\in \\{0, \\dots, n_x-1\\}$ 且 $j \\in \\{0, \\dots, n_y-1\\}$。\n\n如果一个单元格 $C_{ij}$ 与 $L_1 \\cup L_2$ 中的至少一个矩形有正面积的交集，则认为该单元格是叠置并集的一部分。由于网格线是由矩形边界本身定义的，我们可以通过检查单元格的中心点 $p_{ij} = \\left(\\frac{x_i+x_{i+1}}{2}, \\frac{y_j+y_{j+1}}{2}\\right)$ 是否位于 $L_1 \\cup L_2$ 中的任何矩形 $R$ 内来测试其是否被包含。一个点 $(p_x, p_y)$ 位于矩形 $[x_{\\min}, y_{\\min}, x_{\\max}, y_{\\max}]$ 内的条件是 $x_{\\min} \\le p_x \\le x_{\\max}$ 且 $y_{\\min} \\le p_y \\le y_{\\max}$。\n\n#### 2.2. 狭长多边形识别谓词\n对于叠置并集中的每个单元格 $C_{ij}$，我们计算其几何属性。该单元格的宽度为 $w = x_{i+1} - x_i$，高度为 $h = y_{j+1} - y_j$。形状度量定义如下：\n-   面积：$A = w \\cdot h$\n-   最小宽度：$w_{\\min} = \\min(w, h)$\n-   最大宽度：$w_{\\max} = \\max(w, h)$\n-   各向异性比：$r = \\frac{w_{\\min}}{w_{\\max}}$ (如果 $w_{\\max}  0$；否则 $r=1$)\n\n如果一个单元格是高度各向异性的，并且其面积小或非常薄，则它被识别为**候选狭长多边形**。该谓词形式化表述为：\n$$ (\\text{is_candidate}) \\iff (r \\le \\tau_r) \\land (A \\le \\tau_A \\lor w_{\\min} \\le \\tau_w) $$\n其中 $\\tau_r$、$\\tau_A$ 和 $\\tau_w$ 分别是用户定义的各向异性比、面积和最小宽度的阈值。\n\n#### 2.3. 拓扑一致性与消除\n只有当候选狭长多边形满足严格的拓扑标准时，才会被消除，以防止地图拓扑的碎片化。规则是，该狭长多边形必须沿其最长维度“夹在”一个较大的多边形和一个空白区域（或另一个不与之合并的多边形）之间。\n\n设一个候选狭长多边形为单元格 $C_{ij}$。\n-   如果单元格是垂直拉长的（$h \\ge w$，因此其长边是垂直的），我们检查它的水平邻居 $C_{i-1,j}$ 和 $C_{i+1,j}$。当且仅当这两个邻居中**恰好有一个**也位于叠置并集中时，该单元格才被消除。\n-   如果单元格是水平拉长的（$w  h$，因此其长边是水平的），我们检查它的垂直邻居 $C_{i,j-1}$ 和 $C_{i,j+1}$。当且仅当这两个邻居中**恰好有一个**也位于叠置并集中时，该单元格才被消除。\n\n该规则确保狭长多边形有一个唯一的、无歧义的合并对象。操作包括溶解狭长多边形与其沿长边的唯一邻居之间的边界边。\n\n#### 2.4. 欧拉示性数的不变性\n平面图的欧拉示性数由 $\\chi = V - E + F$ 给出，其中 $V$、$E$ 和 $F$ 分别是顶点、边和面的数量。我们必须证明，消除狭长多边形的过程使 $\\chi$ 保持不变，即 $\\Delta \\chi = 0$。\n\n通过将一个狭长面 $f_s$ 合并到相邻的面 $f_n$ 中来消除它，在拓扑上等同于**边收缩**操作。共享的边界边（比如 $e_{sn}$）被收缩。在平面图嵌入中，收缩作为面边界一部分的边会产生以下影响：\n1.  两个面 $f_s$ 和 $f_n$ 合并成一个面。这使面数减少一：$\\Delta F = -1$。\n2.  边 $e_{sn}$ 本身被移除。这使边数减少一：$\\Delta E_{edge} = -1$。\n3.  边 $e_{sn}$ 的两个顶点塌陷成一个顶点。这使顶点数减少一：$\\Delta V = -1$。\n4.  如果收缩导致同一对顶点之间出现多条边，它们会被合并。特定的规则（“沿其长边恰好与一个相邻邻居共享边界”）确保了一种简单的拓扑结构，其中这并非主要影响，但我们必须考虑塌陷顶点的关联边会发生什么。最稳健的看待方式是通过边收缩的一般属性。\n\n拓扑图论中的一个基本定理指出，如果嵌入在曲面 $S$ 上的图 $G$ 的一条边 $e$ 被收缩，新图 $G/e$ 在 $S$ 上存在一个嵌入，且其欧拉示性数是相关的。对于平面图，收缩一条边不会改变曲面（平面）的亏格，并且欧拉示性数得以保留。\n\n让我们通过分步的元素计数来分析这一点。设要移除的边为 $e$。\n- 面的数量减少 $1$：$\\Delta F = -1$。\n- 边 $e$ 被移除，使边数减少 $1$：$\\Delta E = -1$。\n- 边 $e$ 的两个顶点也是其他边的一部分。拓扑规则保证它们不是整个地图的边界顶点。当 $e$ 被移除时，这些顶点仍然存在，但它们的连通性会改变。如果没有顶点被移除，则 $\\Delta V = 0$。\n在这种观点下，欧拉示性数的变化为 $\\Delta \\chi = \\Delta V - \\Delta E + \\Delta F = 0 - (-1) + (-1) = 0$。\n\n一个更严谨的观点承认，合并操作可能会产生度为 $2$ 的顶点，这些顶点随后通常会被移除以保持拓扑的整洁。如果一个度为 $2$ 的顶点 $v$ 被移除，其两条关联边会合并为一条。这意味着移除一个顶点（$\\Delta V = -1$）的同时也移除了一条边（$\\Delta E = -1$）。由于 $\\Delta V - \\Delta E = (-1) - (-1) = 0$，移除任意数量的度为 $2$ 的顶点都不会改变欧拉示性数。\n\n因此，无论将合并操作视为简单的边移除还是带有清理的完全边收缩，它都保留了欧拉示性数 $\\chi$，从而确保了拓扑一致性。\n\n### 步骤 3：实现与测试用例执行\n上述算法使用 Python 实现，并利用 NumPy 库进行高效的网格管理。代码遍历每个测试用例，构建叠置网格，识别候选狭长多边形，应用拓扑检查，并计算最终被消除的单元格数量。\n\n-   **测试用例 1**：$L_1 = \\{[0,0,10,5]\\}$, $L_2 = \\{[0.2,0,10.2,5]\\}$。阈值：$\\tau_A = 0.5$, $\\tau_r = 0.1$, $\\tau_w = 0.25$。这会产生两个垂直的狭长多边形：`[0, 0.2] x [0, 5]` 和 `[10, 10.2] x [0, 5]`。对于两者，$w=0.2, h=5$，因此 $w_{\\min}=0.2, r=0.04, A=1.0$。谓词 $(r \\le 0.1) \\land (A \\le 0.5 \\lor w_{\\min} \\le 0.25)$ 为真，因为 $0.04 \\le 0.1$ 且 $0.2 \\le 0.25$。两者在其长（垂直）边上都恰好有一个邻居。两者均被消除。计数：$2$。\n\n-   **测试用例 2**：几何形状与用例 1 相同。阈值：$\\tau_A = 1.0$, $\\tau_r = 1.0$, $\\tau_w = 0.05$。对于狭长多边形，$A=1.0, w_{\\min}=0.2, r=0.04$。谓词 $(r \\le 1.0) \\land (A \\le 1.0 \\lor w_{\\min} \\le 0.05)$ 为真，因为 $0.04 \\le 1.0$ 且 $1.0 \\le 1.0$。两者均被消除。计数：$2$。\n\n-   **测试用例 3**：$L_1 = L_2 = \\{[0,0,10,5]\\}$。没有配准误差，产生一个单一的叠置单元格 `[0,10] x [0,5]`。这里，$w=10, h=5, w_{\\min}=5, r=0.5$。谓词 $(r \\le 0.1)$ 为假。没有识别出狭长多边形。计数：$0$。\n\n-   **测试用例 4**：复杂的叠置。来自小图斑 `[2,2,2.3,2.3]` 的坐标将较大的狭长区域再分割。沿边界形成狭长多边形：`x in [0, 0.1]`、`x in [10, 10.1]`、`y in [0, 0.1]` 和 `y in [10, 10.1]`。每个狭长条带都被中间坐标分割成 $3$ 个单元格。对于所有这些单元格，最小维度为 $w_{\\min}=0.1$。条件 $w_{\\min} \\le \\tau_w$（$0.1 \\le 0.12$）成立，因此它们都是候选对象。每个也都通过了拓扑检查。这导致 $4$ 个条带 $\\times$ 每个条带 $3$ 个单元格 = $12$ 个被消除的单元格。中心图斑 `[2,2,2.3,2.3]` 本身不是狭长多边形（$r=1.0$），被正确保留。计数：$12$。\n\n最终结果被收集并按要求格式化。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the sliver polygon elimination problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"L1\": np.array([[0, 0, 10, 5]]),\n            \"L2\": np.array([[0.2, 0, 10.2, 5]]),\n            \"thresholds\": {\"tau_A\": 0.5, \"tau_r\": 0.1, \"tau_w\": 0.25},\n        },\n        {\n            \"L1\": np.array([[0, 0, 10, 5]]),\n            \"L2\": np.array([[0.2, 0, 10.2, 5]]),\n            \"thresholds\": {\"tau_A\": 1.0, \"tau_r\": 1.0, \"tau_w\": 0.05},\n        },\n        {\n            \"L1\": np.array([[0, 0, 10, 5]]),\n            \"L2\": np.array([[0, 0, 10, 5]]),\n            \"thresholds\": {\"tau_A\": 0.1, \"tau_r\": 0.1, \"tau_w\": 0.1},\n        },\n        {\n            \"L1\": np.array([[0, 0, 10, 10]]),\n            \"L2\": np.array([[0.1, 0.1, 10.1, 10.1], [2, 2, 2.3, 2.3]]),\n            \"thresholds\": {\"tau_A\": 0.05, \"tau_r\": 0.2, \"tau_w\": 0.12},\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        L1 = case[\"L1\"]\n        L2 = case[\"L2\"]\n        tau_A = case[\"thresholds\"][\"tau_A\"]\n        tau_r = case[\"thresholds\"][\"tau_r\"]\n        tau_w = case[\"thresholds\"][\"tau_w\"]\n\n        # Step 1: Construct the overlay subdivision grid\n        x_coords = set()\n        y_coords = set()\n        all_rects = np.vstack([L1, L2])\n        for rect in all_rects:\n            x_coords.add(rect[0])\n            x_coords.add(rect[2])\n            y_coords.add(rect[1])\n            y_coords.add(rect[3])\n        \n        sorted_x = sorted(list(x_coords))\n        sorted_y = sorted(list(y_coords))\n\n        map_x = {val: i for i, val in enumerate(sorted_x)}\n        map_y = {val: i for i, val in enumerate(sorted_y)}\n        \n        num_x_cells = len(sorted_x) - 1\n        num_y_cells = len(sorted_y) - 1\n\n        if num_x_cells == 0 or num_y_cells == 0:\n            results.append(0)\n            continue\n\n        is_in_union = np.zeros((num_y_cells, num_x_cells), dtype=bool)\n\n        # Determine which cells are in the union of L1 and L2\n        for j in range(num_y_cells):\n            for i in range(num_x_cells):\n                center_x = (sorted_x[i] + sorted_x[i+1]) / 2.0\n                center_y = (sorted_y[j] + sorted_y[j+1]) / 2.0\n                \n                is_covered = False\n                for rect in all_rects:\n                    if (rect[0] = center_x = rect[2]) and \\\n                       (rect[1] = center_y = rect[3]):\n                        is_covered = True\n                        break\n                if is_covered:\n                    is_in_union[j, i] = True\n\n        eliminated_count = 0\n        # Step 2  3: Identify and eliminate slivers\n        for j in range(num_y_cells):\n            for i in range(num_x_cells):\n                if not is_in_union[j, i]:\n                    continue\n\n                w = sorted_x[i+1] - sorted_x[i]\n                h = sorted_y[j+1] - sorted_y[j]\n\n                # Skip degenerate cells\n                if w == 0 or h == 0:\n                    continue\n                \n                # Calculate shape metrics\n                A = w * h\n                w_min = min(w, h)\n                w_max = max(w, h)\n                r = w_min / w_max if w_max > 0 else 1.0\n\n                # Check sliver candidate predicate\n                is_candidate = (r = tau_r) and (A = tau_A or w_min = tau_w)\n\n                if not is_candidate:\n                    continue\n                \n                # Check topological consistency rule\n                is_eliminated = False\n                if h >= w: # Long side is vertical or square\n                    left_neighbor_exists = (i > 0) and is_in_union[j, i-1]\n                    right_neighbor_exists = (i  num_x_cells - 1) and is_in_union[j, i+1]\n                    if left_neighbor_exists != right_neighbor_exists: # XOR\n                        is_eliminated = True\n                else: # Long side is horizontal\n                    bottom_neighbor_exists = (j > 0) and is_in_union[j-1, i]\n                    top_neighbor_exists = (j  num_y_cells - 1) and is_in_union[j+1, i]\n                    if bottom_neighbor_exists != top_neighbor_exists: # XOR\n                        is_eliminated = True\n                \n                if is_eliminated:\n                    eliminated_count += 1\n        \n        results.append(eliminated_count)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "不规则三角网（TIN）是表示地形等连续表面的关键数据结构，对于有限元分析等物理模拟至关重要。这些高级应用要求网格必须是拓扑“水密”的，即每个边都恰好被两个三角形共享。本练习将引导您从基本定义出发，开发一个程序来检测和修复因重复顶点或重复面片而导致的非流形结构，从而确保网格的拓扑完整性，使其适用于严谨的数值模拟。",
            "id": "3850657",
            "problem": "给定一个不规则三角网 (TIN)，定义为一个数对 $(\\mathcal{V}, \\mathcal{F})$，其中 $\\mathcal{V} = \\{ \\mathbf{v}_i \\in \\mathbb{R}^3 \\mid i = 0,1,\\dots,N-1 \\}$ 是一个有限的顶点坐标集合，$\\mathcal{F} = \\{ (i,j,k) \\mid i,j,k \\in \\{0,\\dots,N-1\\}, i \\neq j \\neq k \\}$ 是一个有限的三角面集合，这些三角面引用了 $\\mathcal{V}$ 中的索引。请开发并实现一种方法，以检测和修复非流形边和重复顶点，从而生成一个适用于有限元方法 (FEM) 分析的水密网格。对于嵌入三维空间中的封闭二维流形表面，其水密性定义为每条无向边都恰好与两个面邻接。即，如果 $E$ 表示由 $\\mathcal{F}$ 导出的无向边集合，则对于每条边 $e \\in E$，其边-面邻接计数恰好为 $2$。非流形边是任何邻接计数大于 $2$ 的边，而边界边是任何邻接计数为 $1$ 的边。重复顶点是指坐标在容差 $\\epsilon  0$ 范围内相等的顶点，而重复面是指具有相同顶点索引集合的面（忽略方向）。所期望的修复后网格 $(\\mathcal{V}', \\mathcal{F}')$ 必须没有重复顶点，没有退化面（面积为零或具有重复索引的面），没有重复面，并且根据边-面邻接定义必须是水密的。\n\n从以下基础概念开始：\n- 图论中的网格关联定义：边是从面中提取的顶点索引的无序对，边-面关联是指包含给定无向边的面的数量。\n- $\\mathbb{R}^3$ 中三角形面积的几何定义：对于顶点为 $\\mathbf{v}_i, \\mathbf{v}_j, \\mathbf{v}_k \\in \\mathbb{R}^3$ 的三角形 $(i,j,k)$，其面积为 $\\frac{1}{2}\\|\\left(\\mathbf{v}_j - \\mathbf{v}_i\\right) \\times \\left(\\mathbf{v}_k - \\mathbf{v}_i\\right)\\|_2$。\n- 封闭曲面的水密性拓扑概念：每条无向边恰好与两个三角面邻接。\n\n您的程序必须为每个测试用例，以一种有原则的方式执行以下任务：\n1. 在指定的容差 $\\epsilon$ 内识别并合并重复顶点，生成一个从原始顶点索引到新索引的映射。合并后的顶点簇的代表应在簇内一致地选择（不依赖外部数据）。\n2. 更新面以引用合并后的顶点索引。\n3. 移除退化面，即任何具有重复顶点索引或几何面积小于一个小的阈值 $\\tau$ 的面。\n4. 通过对其顶点索引进行规范集合比较来移除重复面（在确定重复时忽略面的方向）。\n5. 计算无向边-面邻接计数，并确定结果网格是否水密（每条无向边的邻接计数必须恰好为 $2$）。\n\n本任务的假设：专注于这样的网格，其非流形边计数仅由已封闭表面上的重复顶点和重复面引起，因此去重和移除退化面足以恢复水密性。不要创造或添加新的几何形状；修复必须严格按照所述的合并顶点和移除面的方式来完成。\n\n您的程序必须为每个测试用例返回一个包含以下条目的结果列表：\n- 一个布尔值，表示修复后的水密性。\n- 一个整数，表示合并了多少顶点（原始顶点数减去修复后的顶点数）。\n- 一个整数，表示修复过程中移除了多少个面（原始面数减去修复后的面数）。\n- 一个整数，表示最终的顶点数。\n- 一个整数，表示最终的面数。\n\n最终输出必须将所有测试用例的结果汇总为单行，格式为方括号内包含的逗号分隔列表，其中每个元素是一个测试用例的结果列表。例如，输出应类似于 $[[\\text{case1\\_result}], [\\text{case2\\_result}], [\\text{case3\\_result}]]$，不含任何空格。\n\n使用以下测试套件。对于每个用例，所有坐标都是无量纲的，所有索引都是整数。使用顶点合并容差 $\\epsilon = 10^{-8}$ 和面积阈值 $\\tau = 10^{-16}$：\n- 测试用例 A（正常路径；带重复项的闭合四面体）：顶点 $[(0,0,0),(1,0,0),(0,1,0),(0,0,1),(1+10^{-10},0,0)]$，面 $[(0,1,2),(0,1,3),(0,2,3),(1,2,3),(0,4,2),(1,2,3)]$。\n- 测试用例 B（边界条件；已干净）：顶点 $[(0,0,0),(1,0,0),(0,1,0),(0,0,1)]$，面 $[(0,1,2),(0,1,3),(0,2,3),(1,2,3)]$。\n- 测试用例 C（边缘情况；近乎重复的顶点和反转的面方向）：顶点 $[(0,0,0),(1,0,0),(0,1,0),(0,0,1),(0,1,10^{-9})]$，面 $[(0,1,4),(0,1,2),(0,2,3),(1,2,3),(2,1,3),(0,1,3)]$。\n\n您的程序应生成单行输出，其中包含方括号内无空格的逗号分隔列表形式的结果，格式与 $[[b_1,m_1,r_1,V_1,F_1],[b_2,m_2,r_2,V_2,F_2],[b_3,m_3,r_3,V_3,F_3]]$ 完全一致，其中 $b_i$ 是布尔值，$m_i,r_i,V_i,F_i$ 是测试用例 $i$ 的整数。",
            "solution": "该问题陈述是计算几何和网格处理领域一个有效的、适定的问题。它具有科学依据，是客观的，并包含了进行求解所需的所有必要信息。\n\n目标是实现一个程序来修复由顶点集 $\\mathcal{V}$ 和面集 $\\mathcal{F}$ 表示的不规则三角网 (TIN)，以生成一个水密的流形网格。水密网格是指每条边都恰好被两个面共享的网格。修复过程涉及一系列规范化的清理操作：合并重复顶点、重设面索引、移除退化面和重复面。\n\n设初始网格为 $(\\mathcal{V}, \\mathcal{F})$，其中有 $N = |\\mathcal{V}|$ 个顶点和 $M = |\\mathcal{F}|$ 个面。修复过程按以下步骤进行：\n\n1.  **顶点去重与合并**\n    第一步是识别并合并在给定容差 $\\epsilon > 0$ 内几何上重合的顶点。如果顶点 $\\mathbf{v}_i$ 和 $\\mathbf{v}_j$ 之间的欧几里得距离小于 $\\epsilon$，则认为它们是重复的：\n    $$\n    \\|\\mathbf{v}_i - \\mathbf{v}_j\\|_2  \\epsilon\n    $$\n    这种关系将顶点集 $\\mathcal{V}$ 划分为多个重复顶点簇。对于每个簇，选择一个单一的代表顶点。一种用于规范地管理这些簇的稳健方法是使用不相交集并 (DSU) 数据结构。每个顶点索引 $i \\in \\{0, \\dots, N-1\\}$ 最初都属于其自己的集合。我们遍历所有顶点对 $(i, j)$（其中 $i  j$）。如果它们对应的顶点是重复的，我们就合并它们的集合。每个集合的代表被一致地选择，例如，选择集合中索引最小的元素。\n\n    划分后，我们构建一个新的顶点列表 $\\mathcal{V}'$，其中只包含唯一的代表顶点。创建一个映射 $\\phi: \\{0, \\dots, N-1\\} \\to \\{0, \\dots, N'-1\\}$，其中 $N' = |\\mathcal{V}'|$ 是新的顶点数。$\\phi(i)$ 给出原始顶点 $i$ 在 $\\mathcal{V}'$ 中的新索引。合并的顶点数为 $N - N'$。\n\n2.  **面索引重映射**\n    使用上一步中的映射 $\\phi$，我们更新面集 $\\mathcal{F}$。每个原始面 $f = (i, j, k) \\in \\mathcal{F}$ 都被转换为一个新面 $f_{\\text{remap}} = (\\phi(i), \\phi(j), \\phi(k))$。这将产生一个新的面集 $\\mathcal{F}_{\\text{remap}}$。\n\n3.  **退化面移除**\n    如果一个面没有形成一个有效的二维三角形，它就被认为是退化的，必须被移除。这在两种情况下发生：\n    a.  **拓扑退化**：面的重映射顶点索引不唯一。如果 $i'=j'$ 或 $j'=k'$ 或 $k'=i'$，则面 $(i', j', k')$ 是退化的。这样的面已塌缩成一条线或一个点。\n    b.  **几何退化**：面的面积小到可以忽略不计。具有顶点 $(\\mathbf{v}'_{i'}, \\mathbf{v}'_{j'}, \\mathbf{v}'_{k'})$ 的三角形面积由 $A = \\frac{1}{2} \\|\\left(\\mathbf{v}'_{j'} - \\mathbf{v}'_{i'}\\right) \\times \\left(\\mathbf{v}'_{k'} - \\mathbf{v}'_{i'}\\right)\\|_2$ 给出。如果 $A  \\tau$，则移除该面，其中 $\\tau$ 是一个很小的面积阈值。\n    所有来自 $\\mathcal{F}_{\\text{remap}}$ 且非退化的面构成了集合 $\\mathcal{F}_{\\text{degen}}$。\n\n4.  **重复面移除**\n    网格中可能包含同一面的多个实例，可能具有不同的顶点排序（方向）。为了识别这些面，我们为每个面定义一个规范表示。对于一个面 $(i', j', k')$，其规范形式是其索引的排序后元组。例如，面 $(i', j', k')$ 和 $(k', j', i')$ 在方向上不同，但表示相同的几何三角形，因此具有相同的规范形式。我们遍历 $\\mathcal{F}_{\\text{degen}}$，并使用一个集合来跟踪已见过的规范形式，丢弃任何其规范形式已出现过的面。这样就得到了最终的修复面集 $\\mathcal{F}'$。移除的面总数为 $M - |\\mathcal{F}'|$。\n\n5.  **水密性验证**\n    最后一步是验证修复后的网格 $(\\mathcal{V}', \\mathcal{F}')$ 是否水密。根据问题的定义，这意味着网格中的每条无向边必须恰好与两个面邻接。一条无向边可以通过其顶点索引的排序对（例如 $(\\min(i,j), \\max(i,j))$）来进行规范表示。我们通过遍历 $\\mathcal{F}'$ 中的每个面并提取其三条边，来为所有规范边构建一个频率图（字典或哈希表）。一个面 $(i,j,k)$ 贡献了边 $(\\min(i,j), \\max(i,j))$、$(\\min(j,k), \\max(j,k))$ 和 $(\\min(k,i), \\max(k,i))$。计数后，我们检查频率图中的每个计数是否都恰好为 $2$。如果此条件成立，则网格是水密的。结果是一个布尔值。如果没有边（即没有面），则该条件因前提不成立而为真。\n\n最后，对于每个测试用例，我们汇编五个必需的指标：布尔值的水密状态、合并的顶点数 ($N-N'$)、移除的面数 ($M-|\\mathcal{F}'|$)、最终顶点数 ($N'$) 和最终面数 ($|\\mathcal{F}'|$)。",
            "answer": "```python\nimport numpy as np\nimport collections\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n\n    def repair_and_analyze_mesh(vertices, faces, epsilon, tau):\n        \"\"\"\n        Performs the full mesh repair and analysis pipeline for a single test case.\n\n        Args:\n            vertices (list of tuples): Original vertex coordinates.\n            faces (list of tuples): Original face vertex indices.\n            epsilon (float): Tolerance for merging vertices.\n            tau (float): Area threshold for removing degenerate faces.\n\n        Returns:\n            list: A list containing [watertight, vertices_merged, faces_removed, final_vertices, final_faces].\n        \"\"\"\n        v_orig = np.array(vertices, dtype=np.float64)\n        n_orig_vertices = v_orig.shape[0]\n        n_orig_faces = len(faces)\n\n        # Step 1: Identify and merge duplicated vertices\n        parent = list(range(n_orig_vertices))\n        def find_set(v):\n            if v == parent[v]:\n                return v\n            parent[v] = find_set(parent[v])\n            return parent[v]\n\n        def unite_sets(a, b):\n            a_root = find_set(a)\n            b_root = find_set(b)\n            if a_root != b_root:\n                # Make the smaller index the parent for consistency\n                if a_root  b_root:\n                    parent[b_root] = a_root\n                else:\n                    parent[a_root] = b_root\n        \n        if n_orig_vertices > 1:\n            for i in range(n_orig_vertices):\n                for j in range(i + 1, n_orig_vertices):\n                    dist = np.linalg.norm(v_orig[i] - v_orig[j])\n                    if dist  epsilon:\n                        unite_sets(i, j)\n\n        # Create new vertex list and index mapping\n        old_to_new_map = -np.ones(n_orig_vertices, dtype=int)\n        v_new = []\n        new_idx_counter = 0\n        for i in range(n_orig_vertices):\n            root = find_set(i)\n            if old_to_new_map[root] == -1:\n                old_to_new_map[root] = new_idx_counter\n                v_new.append(v_orig[root])\n                new_idx_counter += 1\n        \n        for i in range(n_orig_vertices):\n            old_to_new_map[i] = old_to_new_map[find_set(i)]\n        \n        v_repaired = np.array(v_new, dtype=np.float64)\n        n_repaired_vertices = v_repaired.shape[0]\n        vertices_merged = n_orig_vertices - n_repaired_vertices\n\n        # Step 2: Update faces to reference merged vertex indices\n        faces_remapped = [tuple(old_to_new_map[i] for i in face) for face in faces]\n\n        # Step 3: Remove degenerate faces\n        faces_non_degenerate = []\n        for face in faces_remapped:\n            # Topological degeneracy\n            if len(set(face))  3:\n                continue\n            \n            # Geometric degeneracy\n            p1, p2, p3 = v_repaired[face[0]], v_repaired[face[1]], v_repaired[face[2]]\n            area = 0.5 * np.linalg.norm(np.cross(p2 - p1, p3 - p1))\n            if area  tau:\n                continue\n            \n            faces_non_degenerate.append(face)\n\n        # Step 4: Remove duplicated faces\n        faces_repaired = []\n        seen_canonical_faces = set()\n        for face in faces_non_degenerate:\n            canonical_face = tuple(sorted(face))\n            if canonical_face not in seen_canonical_faces:\n                seen_canonical_faces.add(canonical_face)\n                faces_repaired.append(face)\n        \n        n_repaired_faces = len(faces_repaired)\n        faces_removed = n_orig_faces - n_repaired_faces\n\n        # Step 5: Compute edge-face incidence and check for watertightness\n        edge_counts = collections.defaultdict(int)\n        for face in faces_repaired:\n            i, j, k = face\n            edges = [tuple(sorted((i, j))), tuple(sorted((j, k))), tuple(sorted((k, i)))]\n            for edge in edges:\n                edge_counts[edge] += 1\n        \n        is_watertight = True\n        if not edge_counts: # Vacuously true if no edges/faces\n            is_watertight = True\n        else:\n            for count in edge_counts.values():\n                if count != 2:\n                    is_watertight = False\n                    break\n        \n        return [is_watertight, vertices_merged, faces_removed, n_repaired_vertices, n_repaired_faces]\n\n    # Test suite from the problem statement\n    epsilon = 1e-8\n    tau = 1e-16\n\n    test_cases = [\n        # Test Case A\n        {\n            \"vertices\": [(0,0,0),(1,0,0),(0,1,0),(0,0,1),(1+1e-10,0,0)],\n            \"faces\": [(0,1,2),(0,1,3),(0,2,3),(1,2,3),(0,4,2),(1,2,3)]\n        },\n        # Test Case B\n        {\n            \"vertices\": [(0,0,0),(1,0,0),(0,1,0),(0,0,1)],\n            \"faces\": [(0,1,2),(0,1,3),(0,2,3),(1,2,3)]\n        },\n        # Test Case C\n        {\n            \"vertices\": [(0,0,0),(1,0,0),(0,1,0),(0,0,1),(0,1,1e-9)],\n            \"faces\": [(0,1,4),(0,1,2),(0,2,3),(1,2,3),(2,1,3),(0,1,3)]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = repair_and_analyze_mesh(case[\"vertices\"], case[\"faces\"], epsilon, tau)\n        results.append(result)\n\n    # Final print statement in the exact required format\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}