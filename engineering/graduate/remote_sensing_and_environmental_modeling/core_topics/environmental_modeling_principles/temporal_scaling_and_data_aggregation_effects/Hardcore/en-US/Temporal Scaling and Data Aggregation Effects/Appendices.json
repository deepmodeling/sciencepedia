{
    "hands_on_practices": [
        {
            "introduction": "Any remote sensing time series involves discrete sampling and, often, temporal averaging to create composite data products. These operations are not neutral; they act as filters and can introduce profound artifacts like aliasing, where high-frequency signals (like a daily cycle) are misinterpreted as lower-frequency variations or even a constant value. This exercise provides a foundational analysis of how a combination of temporal averaging and periodic sampling can fundamentally alter or even completely suppress a dominant signal, a critical concept for correctly interpreting aggregated time series data .",
            "id": "3859681",
            "problem": "A geophysical variable $x(t)$ exhibits a dominant narrowband diurnal oscillation with continuous-time frequency $f_{0} = 1\\,\\mathrm{day}^{-1}$. A spaceborne remote sensing mission delivers a time series by producing $3$-day aggregates and reporting one value every $3$ days at times $t_{n} = n T_{s}$ with $T_{s} = 3\\,\\mathrm{days}$. Each reported value is the centered $3$-day average,\n$$\ny[n] \\;=\\; \\frac{1}{T_{w}} \\int_{t_{n}-T_{w}/2}^{t_{n}+T_{w}/2} x(t) \\, dt,\n$$\nwith $T_{w} = 3\\,\\mathrm{days}$. Assume that any other spectral content of $x(t)$ is sufficiently weak and sufficiently far from $f_{0}$ to be neglected for the purpose of determining the apparent frequency in the sampled-and-aggregated record.\n\nStarting from the foundational definition of uniform sampling in continuous time and its effect in the frequency domain (replication of the continuous-time spectrum at integer multiples of the sampling frequency), and using the fact that a centered moving average of duration $T_{w}$ is a linear time-invariant filter with frequency response proportional to the normalized sinc function, determine the single continuous-time frequency $f_{a}$ (in $\\mathrm{day}^{-1}$) that will be observed in the sampled-and-aggregated time series $y[n]$ due to the diurnal component at $f_{0}$. Provide the exact value. Express your final answer in $\\mathrm{day}^{-1}$. No rounding is required.",
            "solution": "The goal is to determine the apparent continuous-time frequency $f_{a}$ in the sampled-and-aggregated output that corresponds to the diurnal component at $f_{0} = 1\\,\\mathrm{day}^{-1}$ when the system samples every $T_{s} = 3\\,\\mathrm{days}$ and uses a centered $3$-day moving average prior to sampling.\n\nWe begin with uniform sampling at interval $T_{s}$, which induces a sampling frequency $f_{s} = \\frac{1}{T_{s}}$. The fundamental relationship from sampling theory states that uniform sampling of a continuous-time signal replicates its spectrum at integer multiples of $f_{s}$ in the frequency domain. If $X(f)$ denotes the Fourier transform of $x(t)$, ideal point sampling produces a sampled spectrum proportional to\n$$\nX_{s}(f) \\;=\\; \\sum_{k \\in \\mathbb{Z}} X\\!\\left(f - k f_{s}\\right),\n$$\nwhere $f_{s} = \\frac{1}{T_{s}}$. A single narrowband component at $f_{0}$ therefore appears at all frequencies $f = f_{0} + k f_{s}$ for $k \\in \\mathbb{Z}$. The discrete-time observation cannot distinguish between these replicas; the baseband component that is seen is the one closest to $0$ in absolute value. Thus, the apparent (aliased) continuous-time frequency carried into the sampled record is\n$$\nf_{a} \\;=\\; \\min_{k \\in \\mathbb{Z}} \\left| f_{0} - k f_{s} \\right|.\n$$\nThis follows from the replication of the spectrum and the identification of the baseband representative by the smallest absolute offset from an integer multiple of $f_{s}$.\n\nNext, we incorporate the centered moving average of duration $T_{w}$. A moving average over $T_{w}$ is a linear time-invariant filter with impulse response\n$$\nh(t) \\;=\\; \\frac{1}{T_{w}} \\,\\mathbf{1}_{[-T_{w}/2,\\,T_{w}/2]}(t),\n$$\nwhere $\\mathbf{1}_{A}$ is the indicator function. Its frequency response is\n$$\nH(f) \\;=\\; \\frac{1}{T_{w}} \\int_{-T_{w}/2}^{T_{w}/2} \\exp\\!\\left(-2\\pi i f t\\right) \\, dt \\;=\\; \\mathrm{sinc}\\!\\left(\\pi f T_{w}\\right),\n$$\nwith the normalized sinc defined as $\\mathrm{sinc}(x) = \\frac{\\sin(x)}{x}$. Therefore, the moving average attenuates the amplitude of a sinusoid at frequency $f$ by the factor $\\mathrm{sinc}\\!\\left(\\pi f T_{w}\\right)$ but does not change its frequency prior to sampling. The overall system is thus a filter $H(f)$ followed by uniform sampling at $f_{s}$, so the frequency mapping that determines aliasing remains governed by the sampling operation, while amplitudes are scaled by $H(f)$.\n\nWe now apply these definitions to the given parameters. The sampling frequency is\n$$\nf_{s} \\;=\\; \\frac{1}{T_{s}} \\;=\\; \\frac{1}{3}\\,\\mathrm{day}^{-1}.\n$$\nWe compute\n$$\nf_{a} \\;=\\; \\min_{k \\in \\mathbb{Z}} \\left| 1 - \\frac{k}{3} \\right|.\n$$\nWe examine integer values of $k$ near the ratio $3 f_{0}$:\n- For $k = 3$, we have $\\left| 1 - \\frac{3}{3} \\right| = \\left| 1 - 1 \\right| = 0$.\n- For $k = 2$, we have $\\left| 1 - \\frac{2}{3} \\right| = \\frac{1}{3}$.\n- For $k = 4$, we have $\\left| 1 - \\frac{4}{3} \\right| = \\frac{1}{3}$.\n- For $k = 1$, we have $\\left| 1 - \\frac{1}{3} \\right| = \\frac{2}{3}$.\n- For $k = 5$, we have $\\left| 1 - \\frac{5}{3} \\right| = \\frac{2}{3}$.\nIt is clear that the minimum is attained at $k = 3$ with value $0$. Therefore,\n$$\nf_{a} \\;=\\; 0\\,\\mathrm{day}^{-1}.\n$$\n\nFor completeness regarding the aggregation effect, the amplitude of the diurnal component after the moving average is multiplied by $H(f_{0}) = \\mathrm{sinc}\\!\\left(\\pi f_{0} T_{w}\\right) = \\mathrm{sinc}\\!\\left(\\pi \\cdot 1 \\cdot 3\\right) = \\mathrm{sinc}(3\\pi) = 0$, since $\\sin(3\\pi) = 0$. Thus, the $3$-day centered average completely suppresses the $1\\,\\mathrm{day}^{-1}$ sinusoid even before sampling, and the sampling maps that component to $f_{a} = 0\\,\\mathrm{day}^{-1}$. The frequency result $f_{a} = 0\\,\\mathrm{day}^{-1}$ is consistent with the intuition that sampling at exactly every $3$ days of a $1$-day period, with an averaging window covering an integer number of cycles, yields a record without apparent oscillation at that frequency.\n\nTherefore, the exact aliased frequency observed in the sampled-and-aggregated record due to the diurnal component is $f_{a} = 0\\,\\mathrm{day}^{-1}$.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "Environmental indices like the Normalized Difference Vegetation Index (NDVI) are inherently nonlinear functions of satellite reflectances. Analysts frequently create temporal composites (e.g., weekly, monthly) from daily observations, which raises a critical question about the order of operations. This practice will guide you through a first-principles derivation to demonstrate that computing an index on averaged reflectances is not equivalent to averaging the index values themselves, leading to a systematic aggregation bias. Understanding this \"ratio of means versus mean of ratios\" problem is essential for accurate long-term trend analysis and vegetation monitoring .",
            "id": "3859636",
            "problem": "A terrestrial vegetation pixel is observed by a multispectral satellite at two distinct times during the growing season. For each time, the instrument records at-sensor reflectance in the near-infrared band and the red band, denoted by $N_1$, $R_1$ at time $t_1$ and $N_2$, $R_2$ at time $t_2$, respectively. The Normalized Difference Vegetation Index (NDVI) is defined as a function of near-infrared reflectance $N$ and red reflectance $R$ by $f(N,R)$, and the temporal aggregation applied by a practitioner is either to average the reflectances first and then compute $f$, or to compute $f$ at each time and then average the index. Within the remote sensing and environmental modeling context, temporal scaling and data aggregation can cause systematic bias in indices due to their nonlinearity.\n\nAssume physically plausible reflectances for a leafy canopy under typical conditions: $N_1 = 0.7$, $R_1 = 0.05$, and $N_2 = 0.2$, $R_2 = 0.18$. Let the time-aggregated reflectances be $\\bar{N} = (N_1 + N_2)/2$ and $\\bar{R} = (R_1 + R_2)/2$. Define the temporal mean of NDVI as the arithmetic mean of $f(N_1,R_1)$ and $f(N_2,R_2)$, and define the aggregated NDVI as $f(\\bar{N},\\bar{R})$.\n\nStarting from the definition of NDVI as a rational function of the reflectances and basic properties of averages, derive from first principles an expression demonstrating how $f(\\bar{N},\\bar{R})$ relates to a weighted average of $f(N_1,R_1)$ and $f(N_2,R_2)$, and use this to explain the direction of the bias when the total reflectance $N_i + R_i$ is larger at the time with larger NDVI. Then, compute the bias\n$$\\Delta = f(\\bar{N},\\bar{R}) - \\frac{f(N_1,R_1) + f(N_2,R_2)}{2}.$$\nExpress the final result as a unitless decimal fraction. Round your answer to $4$ significant figures.",
            "solution": "The Normalized Difference Vegetation Index (NDVI) is defined as a function $f$ of near-infrared reflectance $N$ and red reflectance $R$. This standard index is a rational function given by:\n$$f(N,R) = \\frac{N-R}{N+R}$$\nThe problem considers two temporal aggregation schemes. The first scheme involves computing the NDVI from time-averaged reflectances, a quantity we term the aggregated NDVI:\n$$f(\\bar{N}, \\bar{R})$$\nwhere $\\bar{N} = \\frac{N_1+N_2}{2}$ and $\\bar{R} = \\frac{R_1+R_2}{2}$.\n\nThe second scheme involves averaging the NDVI values computed at each time step, which we term the temporal mean of NDVI:\n$$\\frac{f(N_1,R_1) + f(N_2,R_2)}{2}$$\n\nThe first task is to derive an expression that relates the aggregated NDVI to a weighted average of the individual NDVI values, $f(N_1,R_1)$ and $f(N_2,R_2)$. We begin by substituting the definitions of $\\bar{N}$ and $\\bar{R}$ into the function $f$:\n$$f(\\bar{N},\\bar{R}) = \\frac{\\bar{N}-\\bar{R}}{\\bar{N}+\\bar{R}} = \\frac{\\frac{N_1+N_2}{2} - \\frac{R_1+R_2}{2}}{\\frac{N_1+N_2}{2} + \\frac{R_1+R_2}{2}}$$\nThe factor of $\\frac{1}{2}$ cancels from the numerator and denominator:\n$$f(\\bar{N},\\bar{R}) = \\frac{(N_1-R_1) + (N_2-R_2)}{(N_1+R_1) + (N_2+R_2)}$$\nTo reveal the relationship with the individual NDVI values, let $NDVI_1 = f(N_1,R_1)$ and $NDVI_2 = f(N_2,R_2)$. From the definition of NDVI, we can write the numerator of the index, $N-R$, as a product of the index and its denominator, $N+R$. Thus, $N_1-R_1 = NDVI_1 \\cdot (N_1+R_1)$ and $N_2-R_2 = NDVI_2 \\cdot (N_2+R_2)$. Substituting these into the expression for $f(\\bar{N},\\bar{R})$:\n$$f(\\bar{N},\\bar{R}) = \\frac{NDVI_1 (N_1+R_1) + NDVI_2 (N_2+R_2)}{(N_1+R_1) + (N_2+R_2)}$$\nLet us define the total reflectance at each time step as $S_i = N_i+R_i$ for $i \\in \\{1, 2\\}$. The expression simplifies to:\n$$f(\\bar{N},\\bar{R}) = \\frac{S_1 \\cdot NDVI_1 + S_2 \\cdot NDVI_2}{S_1+S_2}$$\nThis equation can be rewritten as a weighted average:\n$$f(\\bar{N},\\bar{R}) = \\left(\\frac{S_1}{S_1+S_2}\\right) NDVI_1 + \\left(\\frac{S_2}{S_1+S_2}\\right) NDVI_2$$\nThis demonstrates that the aggregated NDVI, $f(\\bar{N},\\bar{R})$, is a weighted average of the individual NDVI values, where the weights are determined by the proportion of the total reflectance sum $S_1+S_2$ contributed by each observation's total reflectance $S_i$.\n\nThe next task is to explain the direction of the bias $\\Delta = f(\\bar{N}, \\bar{R}) - \\frac{NDVI_1 + NDVI_2}{2}$. Using our derived expression for $f(\\bar{N},\\bar{R})$:\n$$\\Delta = \\left(\\frac{S_1}{S_1+S_2} NDVI_1 + \\frac{S_2}{S_1+S_2} NDVI_2 \\right) - \\left(\\frac{1}{2} NDVI_1 + \\frac{1}{2} NDVI_2 \\right)$$\nGrouping terms by $NDVI_1$ and $NDVI_2$:\n$$\\Delta = \\left(\\frac{S_1}{S_1+S_2} - \\frac{1}{2}\\right) NDVI_1 + \\left(\\frac{S_2}{S_1+S_2} - \\frac{1}{2}\\right) NDVI_2$$\nFinding a common denominator for the coefficients:\n$$\\frac{S_1}{S_1+S_2} - \\frac{1}{2} = \\frac{2S_1 - (S_1+S_2)}{2(S_1+S_2)} = \\frac{S_1-S_2}{2(S_1+S_2)}$$\n$$\\frac{S_2}{S_1+S_2} - \\frac{1}{2} = \\frac{2S_2 - (S_1+S_2)}{2(S_1+S_2)} = \\frac{S_2-S_1}{2(S_1+S_2)} = -\\frac{S_1-S_2}{2(S_1+S_2)}$$\nSubstituting these back into the expression for $\\Delta$:\n$$\\Delta = \\left(\\frac{S_1-S_2}{2(S_1+S_2)}\\right) NDVI_1 - \\left(\\frac{S_1-S_2}{2(S_1+S_2)}\\right) NDVI_2$$\nFactoring out the common term yields the final expression for the bias:\n$$\\Delta = \\frac{S_1-S_2}{2(S_1+S_2)} (NDVI_1 - NDVI_2)$$\nThe problem asks to explain the bias direction when the total reflectance $S_i$ is larger at the time with the larger NDVI. Let us assume without loss of generality that $NDVI_1 > NDVI_2$. The condition states that $S_1 > S_2$ as well. In this case, the term $(NDVI_1 - NDVI_2)$ is positive, and the term $(S_1-S_2)$ is also positive. Since reflectances are non-negative, the denominator $2(S_1+S_2)$ is positive. Therefore, the bias $\\Delta$ will be positive. This means that averaging reflectances before computing the index will overestimate the NDVI compared to averaging the indices themselves. This occurs because the weighted average gives more weight to the NDVI value from the observation with the higher total reflectance.\n\nFinally, we compute the numerical value of the bias $\\Delta$ using the provided data:\n$N_1 = 0.7$, $R_1 = 0.05$\n$N_2 = 0.2$, $R_2 = 0.18$\n\nFirst, we compute the individual NDVI values:\n$$NDVI_1 = f(0.7, 0.05) = \\frac{0.7 - 0.05}{0.7 + 0.05} = \\frac{0.65}{0.75} = \\frac{13}{15}$$\n$$NDVI_2 = f(0.2, 0.18) = \\frac{0.2 - 0.18}{0.2 + 0.18} = \\frac{0.02}{0.38} = \\frac{1}{19}$$\nThe temporal mean of NDVI is:\n$$\\frac{NDVI_1 + NDVI_2}{2} = \\frac{1}{2} \\left(\\frac{13}{15} + \\frac{1}{19}\\right) = \\frac{1}{2} \\left(\\frac{13 \\times 19 + 15 \\times 1}{15 \\times 19}\\right) = \\frac{1}{2} \\left(\\frac{247 + 15}{285}\\right) = \\frac{262}{570} = \\frac{131}{285}$$\nNext, we compute the time-averaged reflectances:\n$$\\bar{N} = \\frac{0.7 + 0.2}{2} = 0.45$$\n$$\\bar{R} = \\frac{0.05 + 0.18}{2} = \\frac{0.23}{2} = 0.115$$\nNow, we compute the aggregated NDVI:\n$$f(\\bar{N}, \\bar{R}) = \\frac{0.45 - 0.115}{0.45 + 0.115} = \\frac{0.335}{0.565} = \\frac{335}{565} = \\frac{67}{113}$$\nThe bias $\\Delta$ is the difference between these two values:\n$$\\Delta = f(\\bar{N}, \\bar{R}) - \\frac{NDVI_1 + NDVI_2}{2} = \\frac{67}{113} - \\frac{131}{285}$$\nTo compute the difference, we find a common denominator: $113 \\times 285 = 32205$.\n$$\\Delta = \\frac{67 \\times 285 - 131 \\times 113}{32205} = \\frac{19095 - 14803}{32205} = \\frac{4292}{32205}$$\nConverting this fraction to a decimal:\n$$\\Delta \\approx 0.133271231...$$\nRounding to $4$ significant figures, we obtain $\\Delta \\approx 0.1333$.\nThis positive bias is consistent with our theoretical analysis, as $NDVI_1 \\approx 0.867$ is greater than $NDVI_2 \\approx 0.053$, and the corresponding total reflectance $S_1 = 0.75$ is greater than $S_2 = 0.38$.",
            "answer": "$$\\boxed{0.1333}$$"
        },
        {
            "introduction": "A central challenge in environmental science is that analytical results can be sensitive to the arbitrary choice of temporal resolution, a phenomenon known as the Modifiable Temporal Unit Problem (MTUP). This hands-on coding exercise moves from analytical theory to practical simulation, allowing you to build and observe the MTUP in action. By designing a computational experiment, you will explore how changing the temporal aggregation window affects an estimated relationship—in this case, the time lag—between two environmental variables, developing critical skills for robust modeling and data analysis .",
            "id": "3859639",
            "problem": "You are asked to design and implement a simulation to quantify the Modifiable Temporal Unit Problem (MTUP) in lag estimation between two time series in remote sensing and environmental modeling. The MTUP concerns the sensitivity of estimated relationships to the choice of temporal aggregation windows. You must generate a base daily time series and a lagged counterpart, aggregate both under different bin sizes, and then estimate the lag under each aggregation regime, comparing to the known true lag.\n\nStarting from first principles, use the following mathematical bases:\n\n1. Define a discrete-time daily signal $\\{x_t\\}$ for integer day index $t \\in \\{0,1,\\dots,T-1\\}$, where $T$ is the total number of days. Let $x_t$ be composed of a deterministic seasonal component and stochastic noise, that is\n$$\nx_t = s_t + \\epsilon_t,\n$$\nwhere $s_t$ is a smooth seasonal function and $\\epsilon_t$ is independent and identically distributed (i.i.d.) zero-mean noise with finite variance.\n\n2. Define the lagged signal $\\{y_t\\}$ as a scaled, time-shifted version of $\\{x_t\\}$ with additional noise:\n$$\ny_t = \\gamma \\, x_{t-\\ell} + \\eta_t,\n$$\nwhere $\\gamma > 0$ is a scale factor, $\\ell$ is the true integer lag in days, and $\\eta_t$ is i.i.d. zero-mean noise independent of $\\epsilon_t$. Interpret $x_{t-\\ell}$ as zero when $t-\\ell < 0$ to avoid undefined indices.\n\n3. Define a non-overlapping temporal aggregation operator of width $\\Delta$ days, $A_{\\Delta}(\\cdot)$, that maps daily series to an aggregated series by averaging within bins:\n$$\nA_{\\Delta}(z)_k = \\frac{1}{\\Delta} \\sum_{t=k\\Delta}^{(k+1)\\Delta-1} z_t,\n$$\nfor integer bin index $k \\in \\{0,1,\\dots,K-1\\}$ and $K = \\left\\lfloor \\frac{T}{\\Delta} \\right\\rfloor$.\n\n4. For two aggregated discrete series $\\{u_k\\}$ and $\\{v_k\\}$, define the sample cross-correlation at integer bin lag $h$ as\n$$\n\\widehat{\\rho}_{uv}(h) = \\frac{\\sum_{k} \\left(u_k - \\overline{u}\\right)\\left(v_{k+h} - \\overline{v}\\right)}{\\sqrt{\\sum_{k} \\left(u_k - \\overline{u}\\right)^2} \\, \\sqrt{\\sum_{k} \\left(v_{k+h} - \\overline{v}\\right)^2}},\n$$\nwhere sums are taken over indices $k$ such that both $u_k$ and $v_{k+h}$ are defined, and $\\overline{u}$ and $\\overline{v}$ are sample means over those aligned indices. The estimated lag in bins, $\\hat{h}$, is the argument that maximizes $\\widehat{\\rho}_{uv}(h)$ over a search range $\\{-H,-H+1,\\dots,H\\}$. The estimated lag in days is then $\\widehat{\\ell} = \\Delta \\cdot \\hat{h}$.\n\nScientific realism and constraints:\n\n- Use a seasonal component $s_t$ that is smooth and realistic for environmental signals, such as a sinusoidal annual cycle. Choose $s_t = A \\sin\\left(\\frac{2\\pi t}{P}\\right)$ for amplitude $A$ and period $P$ in days.\n- Use i.i.d. Gaussian noise for $\\epsilon_t$ and $\\eta_t$ with specified standard deviations.\n- Use the aggregation operator described above for bin sizes $\\Delta \\in \\{1,8,30\\}$, corresponding to daily ($\\Delta = 1$), $8$-day, and $30$-day composites. For simplicity and precision, treat a \"monthly\" bin here as a fixed-width $\\Delta = 30$ day window.\n- Estimate lag by maximizing the sample cross-correlation over integer bin lags. The correlation computation must strictly align indices with valid overlap.\n\nYour program must:\n\n- Implement the generation of $\\{x_t\\}$ and $\\{y_t\\}$ for prescribed parameters.\n- Aggregate both series using $A_{\\Delta}$ for $\\Delta \\in \\{1,8,30\\}$.\n- Estimate the lag $\\widehat{\\ell}$ in days under each $\\Delta$ by maximizing $\\widehat{\\rho}_{uv}(h)$ over $h \\in \\{-H,\\dots,H\\}$, where $H$ is a maximum lag in bins chosen to cover a maximum lag magnitude of $H_{\\text{days}}$ days. Use $H_{\\text{days}} = 60$ days.\n- Use a fixed random seed for reproducibility.\n- Return the estimated lags in days as integers.\n\nUnits and output format:\n\n- All lag quantities must be expressed in days, and your final results must be integers in days.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order specified in the test suite below. For each test case, report the estimated lags for $\\Delta = 1$, $\\Delta = 8$, and $\\Delta = 30$, flattened into one list.\n\nTest suite:\n\nUse the following parameter sets to test different aspects (happy path, boundary, edge cases). In all cases, use a sinusoid $s_t = A \\sin\\left(\\frac{2\\pi t}{P}\\right)$ with $A = 1$ and $P = 365$, and $\\gamma = 1$. For each case, specify $(T,\\ell,\\sigma_x,\\sigma_y)$ where $T$ is series length in days, $\\ell$ is the true lag in days, $\\sigma_x$ is the standard deviation of $\\epsilon_t$, and $\\sigma_y$ is the standard deviation of $\\eta_t$:\n\n- Case $1$: $(T = 365, \\ell = 5, \\sigma_x = 0.3, \\sigma_y = 0.3)$.\n- Case $2$: $(T = 365, \\ell = 9, \\sigma_x = 0.5, \\sigma_y = 0.8)$.\n- Case $3$: $(T = 365, \\ell = 29, \\sigma_x = 0.4, \\sigma_y = 0.4)$.\n- Case $4$: $(T = 365, \\ell = 0, \\sigma_x = 0.6, \\sigma_y = 0.6)$.\n- Case $5$: $(T = 120, \\ell = 14, \\sigma_x = 0.8, \\sigma_y = 1.0)$.\n\nSearch range:\n\n- Use $H_{\\text{days}} = 60$ days as the maximum absolute lag in days to search, implying a maximum bin lag $H_{\\Delta} = \\left\\lfloor \\frac{60}{\\Delta} \\right\\rfloor$ for each $\\Delta$.\n\nFinal output specification:\n\n- Your program should produce a single line of output containing the estimated lags (in days, integers) for all test cases in the sequence of cases $1$ through $5$, with the three aggregation regimes per case ordered as $\\Delta = 1$, then $\\Delta = 8$, then $\\Delta = 30$. The final output must be formatted as a single Python list literal, for example, $[\\widehat{\\ell}_{1,1},\\widehat{\\ell}_{1,8},\\widehat{\\ell}_{1,30},\\dots,\\widehat{\\ell}_{5,30}]$, where $\\widehat{\\ell}_{i,\\Delta}$ denotes the estimated lag for case $i$ at bin size $\\Delta$.",
            "solution": "We begin by formalizing the data-generating process and the estimation method, then explain how temporal aggregation induces the Modifiable Temporal Unit Problem (MTUP) in lag estimation.\n\nData generation from fundamental bases:\n\n1. A realistic environmental signal often has a strong seasonal cycle. We define the daily base series $\\{x_t\\}$ as\n$$\nx_t = s_t + \\epsilon_t, \\quad s_t = A \\sin\\left(\\frac{2\\pi t}{P}\\right),\n$$\nwith amplitude $A = 1$ and period $P = 365$ days. The noise term $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma_x^2)$ is independent and identically distributed Gaussian noise. This construction captures a well-tested property of environmental signals: smooth seasonality plus stochastic variability.\n\n2. The paired series $\\{y_t\\}$ is constructed as a scaled, time-shifted version of $\\{x_t\\}$ plus independent noise:\n$$\ny_t = \\gamma \\, x_{t - \\ell} + \\eta_t,\n$$\nwhere $\\gamma = 1$ and $\\eta_t \\sim \\mathcal{N}(0,\\sigma_y^2)$ is independent of $\\epsilon_t$. For indices where $t - \\ell < 0$, we take $x_{t - \\ell} = 0$ to avoid undefined references, which practically introduces a transient edge effect that is small relative to the whole series when $T \\gg \\ell$.\n\nTemporal aggregation as an operator:\n\n3. Aggregation over $\\Delta$-day non-overlapping bins is the operator\n$$\nA_{\\Delta}(z)_k = \\frac{1}{\\Delta} \\sum_{t=k\\Delta}^{(k+1)\\Delta-1} z_t,\n$$\nwhich is equivalent to a discrete convolution with a rectangular kernel (boxcar) of width $\\Delta$ followed by decimation. In signal processing terms, this is a low-pass filtering that attenuates high-frequency components and reduces variance.\n\nLag estimation by cross-correlation:\n\n4. For aggregated series $\\{u_k\\}$ and $\\{v_k\\}$, the sample cross-correlation at bin lag $h$ is\n$$\n\\widehat{\\rho}_{uv}(h) = \\frac{\\sum_{k} \\left(u_k - \\overline{u}\\right)\\left(v_{k+h} - \\overline{v}\\right)}{\\sqrt{\\sum_{k} \\left(u_k - \\overline{u}\\right)^2} \\, \\sqrt{\\sum_{k} \\left(v_{k+h} - \\overline{v}\\right)^2}}.\n$$\nWe estimate the lag by\n$$\n\\hat{h} = \\arg\\max_{h \\in \\{-H,\\dots,H\\}} \\; \\widehat{\\rho}_{uv}(h),\n$$\nand then convert to days $\\widehat{\\ell} = \\Delta \\cdot \\hat{h}$. The search half-width $H$ in bins is chosen via a maximum lag in days $H_{\\text{days}}$, specifically $H = \\left\\lfloor \\frac{H_{\\text{days}}}{\\Delta} \\right\\rfloor$.\n\nHow aggregation affects lag estimation (MTUP):\n\n5. The aggregation operator $A_{\\Delta}$ can be expressed as convolution with a rectangular window $w_{\\Delta}(t)$,\n$$\nw_{\\Delta}(t) = \\begin{cases}\n\\frac{1}{\\Delta}, & t \\in \\{0,1,\\dots,\\Delta-1\\},\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\nThus $A_{\\Delta}(x)$ computed at bin index $k$ is essentially $(x * w_{\\Delta})(t)$ sampled at $t = k\\Delta + (\\Delta - 1)/2$ up to integer rounding. In the correlation domain, the cross-correlation of aggregated signals is related to the cross-correlation of the original signals convolved with the autocorrelation of $w_{\\Delta}$. This smoothing can flatten the correlation peak and, combined with decimation (binning), quantizes the detectable lag to integer multiples of $\\Delta$. When the true lag $\\ell$ is not an integer multiple of $\\Delta$, the estimated lag at the aggregated resolution is typically the nearest multiple $\\Delta \\cdot \\hat{h}$ to $\\ell$, with a quantization error bounded by approximately $\\Delta/2$ days, assuming sufficient signal-to-noise ratio. Higher noise can further perturb the peak location, sometimes biasing toward smaller absolute lags or favoring bins with more overlap.\n\nAlgorithmic design:\n\n6. For each test case $(T,\\ell,\\sigma_x,\\sigma_y)$:\n- Generate $\\{x_t\\}$ for $t = 0,\\dots,T-1$ with $A = 1$ and $P = 365$:\n$$\nx_t = \\sin\\left(\\frac{2\\pi t}{365}\\right) + \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0,\\sigma_x^2).\n$$\n- Generate $\\{y_t\\}$:\n$$\ny_t = x_{t - \\ell} + \\eta_t, \\quad \\eta_t \\sim \\mathcal{N}(0,\\sigma_y^2), \\quad x_{t-\\ell} = 0 \\; \\text{if} \\; t - \\ell < 0.\n$$\n- For each $\\Delta \\in \\{1,8,30\\}$, compute aggregated series $u_k = A_{\\Delta}(x)_k$ and $v_k = A_{\\Delta}(y)_k$ for $k = 0,\\dots,K-1$, where $K = \\left\\lfloor \\frac{T}{\\Delta} \\right\\rfloor$.\n- Estimate $\\hat{h}$ by maximizing $\\widehat{\\rho}_{uv}(h)$ for $h \\in \\{-H,\\dots,H\\}$ with $H = \\left\\lfloor \\frac{60}{\\Delta} \\right\\rfloor$. Align indices properly: for a given $h$, define the overlapping index set so that both $u_k$ and $v_{k+h}$ exist, then compute the correlation using those aligned samples. If either aligned subsequence has zero variance, set the correlation to $0$ for that $h$.\n- Report $\\widehat{\\ell} = \\Delta \\cdot \\hat{h}$ as an integer number of days.\n\nCoverage rationale for the test suite:\n\n- Case $1$ ($\\ell = 5$ days) tests a small lag relative to $\\Delta = 8$ and $\\Delta = 30$, where quantization can induce up to $4$ or $15$ days of error if noise dominates, but with moderate noise it should recover $\\widehat{\\ell} \\approx 5$ for daily and $\\widehat{\\ell} \\approx 8$ for $8$-day bins.\n- Case $2$ ($\\ell = 9$ days) tests a lag near but not equal to $8$ days, to illustrate quantization bias from $\\Delta = 8$ bins and larger bias under $\\Delta = 30$ bins.\n- Case $3$ ($\\ell = 29$ days) probes near-monthly-scale lag where $\\Delta = 30$ bins might report $\\widehat{\\ell} \\approx 30$, showing near-quantization effects.\n- Case $4$ ($\\ell = 0$ days) is a boundary case ensuring the estimator detects zero lag across aggregations despite noise.\n- Case $5$ ($T = 120$, $\\ell = 14$ days, higher noise) is a short, noisy series that stresses the estimator and demonstrates aggregation’s variance reduction versus resolution loss.\n\nImplementation details:\n\n- Use a fixed random seed to ensure reproducibility.\n- Compute aggregation with simple means over non-overlapping windows.\n- Compute sample cross-correlation via explicit alignment and standardized covariance.\n- Convert bin lags to days via multiplication by $\\Delta$ and return integer values.\n\nThe final program will process all five cases and print a single Python list with $15$ integers corresponding to the estimated lags for $\\Delta = 1$, $\\Delta = 8$, and $\\Delta = 30$, in case order.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_series(T, lag_days, sigma_x, sigma_y, A=1.0, P=365, gamma=1.0, rng=None):\n    \"\"\"\n    Generate x_t and y_t daily series.\n    x_t = A * sin(2*pi*t / P) + epsilon_t\n    y_t = gamma * x_{t - lag_days} + eta_t, with x_{t - lag_days} = 0 if t - lag_days < 0\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng(0)\n    t = np.arange(T, dtype=int)\n    seasonal = A * np.sin(2.0 * np.pi * t / P)\n    epsilon = rng.normal(loc=0.0, scale=sigma_x, size=T)\n    x = seasonal + epsilon\n    # Shifted version for y; zero-pad the left side\n    y = np.empty(T, dtype=float)\n    y[:] = 0.0\n    if lag_days >= 0:\n        # y[t] = gamma * x[t - lag_days] + eta[t] if t - lag_days >= 0 else eta[t]\n        eta = rng.normal(loc=0.0, scale=sigma_y, size=T)\n        for tt in range(T):\n            xt_shift = x[tt - lag_days] if (tt - lag_days) >= 0 else 0.0\n            y[tt] = gamma * xt_shift + eta[tt]\n    else:\n        # Negative lag: y leads x, i.e., x is shifted forward\n        # y[t] = gamma * x[t - lag_days] + eta[t], with t - lag_days always >= 0 for lag_days < 0 sufficiently small\n        # Still safe to implement same as above.\n        eta = rng.normal(loc=0.0, scale=sigma_y, size=T)\n        for tt in range(T):\n            xt_shift = x[tt - lag_days] if (tt - lag_days) >= 0 else 0.0\n            y[tt] = gamma * xt_shift + eta[tt]\n    return x, y\n\ndef aggregate_nonoverlapping(z, delta):\n    \"\"\"\n    Aggregate daily series z into non-overlapping windows of size delta via mean.\n    Returns aggregated series u and number of bins K.\n    \"\"\"\n    T = len(z)\n    K = T // delta\n    if K == 0:\n        return np.array([], dtype=float)\n    reshaped = z[:K*delta].reshape(K, delta)\n    return reshaped.mean(axis=1)\n\ndef estimate_lag_days(u, v, delta, H_days):\n    \"\"\"\n    Estimate lag by maximizing sample cross-correlation between aggregated series u and v.\n    u and v are arrays defined on bin indices k.\n    delta is bin size in days. H_days is maximum absolute lag in days.\n    Returns lag estimate in days (integer).\n    \"\"\"\n    # Compute maximum lag in bins\n    H_bins = int(H_days // delta)\n    n = min(len(u), len(v))\n    if n == 0:\n        return 0\n    # For robustness in short series, limit H_bins to n-2\n    H_bins = min(H_bins, max(0, n - 2))\n    best_h = 0\n    best_r = -np.inf\n    # Iterate over integer bin lags h in [-H_bins, H_bins]\n    for h in range(-H_bins, H_bins + 1):\n        if h >= 0:\n            u_sub = u[:n - h]\n            v_sub = v[h:n]\n        else:\n            u_sub = u[-h:n]\n            v_sub = v[:n + h]\n        # Compute Pearson correlation if variances are non-zero\n        if len(u_sub) < 2 or len(v_sub) < 2:\n            r = -np.inf\n        else:\n            u_centered = u_sub - np.mean(u_sub)\n            v_centered = v_sub - np.mean(v_sub)\n            su = np.sqrt(np.sum(u_centered ** 2))\n            sv = np.sqrt(np.sum(v_centered ** 2))\n            if su == 0.0 or sv == 0.0:\n                r = -np.inf\n            else:\n                r = np.sum(u_centered * v_centered) / (su * sv)\n        # Choose the lag with maximum correlation; tie-breaker prefers smaller |h|\n        if r > best_r or (r == best_r and abs(h) < abs(best_h)):\n            best_r = r\n            best_h = h\n    # Convert lag in bins to days\n    return int(best_h * delta)\n\ndef solve():\n    # Fixed RNG seed for reproducibility across all test cases\n    rng = np.random.default_rng(12345)\n\n    # Define the test cases from the problem statement.\n    # Each case: (T, lag_days, sigma_x, sigma_y)\n    test_cases = [\n        (365, 5, 0.3, 0.3),   # Case 1\n        (365, 9, 0.5, 0.8),   # Case 2\n        (365, 29, 0.4, 0.4),  # Case 3\n        (365, 0, 0.6, 0.6),   # Case 4\n        (120, 14, 0.8, 1.0),  # Case 5\n    ]\n\n    deltas = [1, 8, 30]  # daily, 8-day, 30-day bins\n    H_days = 60\n\n    results = []\n    for T, lag_days, sigma_x, sigma_y in test_cases:\n        # Generate series\n        x, y = generate_series(T=T, lag_days=lag_days, sigma_x=sigma_x, sigma_y=sigma_y, rng=rng)\n        # For each aggregation regime, estimate lag\n        for delta in deltas:\n            u = aggregate_nonoverlapping(x, delta)\n            v = aggregate_nonoverlapping(y, delta)\n            est = estimate_lag_days(u, v, delta, H_days)\n            results.append(est)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}