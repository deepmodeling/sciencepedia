{
    "hands_on_practices": [
        {
            "introduction": "遥感影像分类的第一步通常是进行辐射校正，将传感器记录的原始数字信号（或辐射亮度）转换为地表反射率，这是一种不受光照和大气影响的物理属性。本练习  旨在通过一个简化的物理模型，让您亲手实践这一关键过程。您将使用查找表（LUT）方法来插值大气透射率，并计算地表反射率 $\\rho_\\lambda$ 及其对气溶胶厚度变化的敏感性，从而深入理解大气校正的核心机制及其不确定性来源。",
            "id": "3860408",
            "problem": "给定一个在被动光学遥感中针对单个光谱波段的、简化的、物理上一致的大气校正设置。目标是为一个具有已知大气顶层 (TOA) 辐亮度 $L_\\lambda^{TOA}$ 的像素计算波长为 $\\lambda$ 的双向反射因子 $\\rho_\\lambda$。这需要通过从查找表 (LUT) 中插值总大气透射率 $T_\\lambda$ 来实现，然后通过偏导数 $\\partial \\rho_\\lambda / \\partial \\tau_a$ 来量化 $\\rho_\\lambda$ 对气溶胶光学厚度的局部灵敏度。插值必须在气溶胶光学厚度 $\\tau_a$、水汽柱含量 $w$ 和太阳天顶角 $\\theta_s$ 上进行三线性插值。\n\n基本原理：\n- 在朗伯近似下，双向反射因子 $\\rho_\\lambda$ 由辐亮度与辐照度之间的关系定义，\n$$\n\\rho_\\lambda \\equiv \\frac{\\pi\\,L_\\lambda}{E_\\lambda^{d}},\n$$\n其中 $L_\\lambda$ 是离开地表的辐亮度，$E_\\lambda^{d}$ 是地表的下行辐照度。\n- 对于在平面平行大气中、在单次散射和路径辐射可忽略的近似下的 TOA 测量，$L_\\lambda^{TOA}$ 会被上行透射率衰减，而地表辐照度则被下行透射率衰减。用 $T_\\lambda$ 表示下行和上行透射率的乘积，并将地外太阳辐照度 $E_{0,\\lambda}$ 作为大气顶层的辐照度，我们使用经过充分检验的关系式 $E_\\lambda^{d} = E_{0,\\lambda}\\,\\cos\\theta_s\\,T_\\lambda$，并在所述近似下将 $L_\\lambda^{TOA}$ 视为地表出射辐亮度乘以向上透射率的代理。这得到了工作公式\n$$\n\\rho_\\lambda = \\frac{\\pi\\,L_\\lambda^{TOA}}{E_{0,\\lambda}\\,\\cos\\theta_s\\,T_\\lambda}。\n$$\n\n用于LUT合成的大气透射率模型：\n- 总透射率 $T_\\lambda$ 通过带有斜路径大气质量的比尔-朗伯定律建模。令 $m_s \\equiv \\sec\\theta_s$ 为太阳大气质量，$m_v \\equiv \\sec\\theta_v$ 为传感器视角大气质量。考虑一个天底视角，其中 $\\theta_v = 0^\\circ$，因此 $m_v = 1$。那么\n$$\nT_\\lambda(\\tau_a, w, \\theta_s) = \\exp\\left(-m_s\\left(\\alpha_\\lambda\\,\\tau_a + k_{\\lambda,d}\\,w + \\tau_{R,\\lambda,d}\\right) - m_v\\left(\\beta_\\lambda\\,\\tau_a + k_{\\lambda,u}\\,w + \\tau_{R,\\lambda,u}\\right)\\right),\n$$\n其中 $\\alpha_\\lambda$、$\\beta_\\lambda$ 代表下行和上行路径的气溶胶消光权重，$k_{\\lambda,d}$ 和 $k_{\\lambda,u}$ 代表下行和上行路径的有效水汽消光系数，$\\tau_{R,\\lambda,d}$、$\\tau_{R,\\lambda,u}$ 分别代表下行和上行路径的瑞利光学厚度贡献。\n\n给定波段用于LUT合成的常数：\n- $\\alpha_\\lambda = 0.3$, $\\beta_\\lambda = 0.15$,\n- $k_{\\lambda,d} = 0.004$, $k_{\\lambda,u} = 0.002$,\n- $\\tau_{R,\\lambda,d} = 0.02$, $\\tau_{R,\\lambda,u} = 0.01$,\n- $\\theta_v = 0^\\circ$，因此 $m_v = 1$。\n\n定义LUT的网格：\n- 气溶胶光学厚度网格（无量纲）：$\\tau_a \\in \\{\\,0.0,\\,0.2,\\,0.5,\\,1.0\\,\\}$，\n- 水汽柱含量网格（单位：可降水量厘米数）：$w \\in \\{\\,0.5,\\,1.5,\\,3.0,\\,5.0\\,\\}$，\n- 太阳天顶角网格（单位：度）：$\\theta_s \\in \\{\\,0,\\,30,\\,60,\\,75\\,\\}$。\n\n地外太阳辐照度：\n- 使用 $E_{0,\\lambda} = 1850$，单位为 W·m$^{-2}$·µm$^{-1}$。\n\n单位与角度约定：\n- 辐亮度 $L_\\lambda^{TOA}$ 必须以 W·m$^{-2}$·sr$^{-1}$·µm$^{-1}$ 为单位提供。\n- 水汽柱含量 $w$ 必须以可降水量厘米数为单位提供。\n- 气溶胶光学厚度 $\\tau_a$ 是无量纲的。\n- 太阳天顶角 $\\theta_s$ 必须以度为单位指定；内部需要为三角函数转换为弧度。\n- 反射率 $\\rho_\\lambda$ 是无量纲的。\n- 灵敏度 $\\partial \\rho_\\lambda / \\partial \\tau_a$ 是无量纲的，每个单位气溶胶光学厚度。\n- 所有输入角度均以度表示；在计算 $\\cos\\theta_s$ 和 $\\sec\\theta_s$ 时内部使用弧度。\n\n灵敏度定义：\n- 使用链式法则，在给定状态 $(\\tau_a, w, \\theta_s)$ 下的灵敏度为\n$$\n\\frac{\\partial \\rho_\\lambda}{\\partial \\tau_a} = -\\frac{\\pi\\,L_\\lambda^{TOA}}{E_{0,\\lambda}\\,\\cos\\theta_s}\\,\\frac{1}{T_\\lambda(\\tau_a,w,\\theta_s)^2}\\,\\frac{\\partial T_\\lambda}{\\partial \\tau_a},\n$$\n其中 $\\partial T_\\lambda/\\partial \\tau_a$ 的获取必须与LUT插值保持一致。为确保对于LUT构建的通用性，通过对插值函数 $T_\\lambda(\\tau_a,w,\\theta_s)$ 应用有限差分来数值计算 $\\partial T_\\lambda/\\partial \\tau_a$，在 $\\tau_a$ 轴上使用一个小步长 $\\delta\\tau_a$：\n- 如果 $\\tau_a$ 严格位于LUT定义域内部，使用步长为 $\\delta\\tau_a$ 的中心差分：\n$$\n\\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a+\\delta\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a-\\delta\\tau_a,w,\\theta_s)}{2\\,\\delta\\tau_a}。\n$$\n- 如果 $\\tau_a$ 位于下边界，使用前向差分：\n$$\n\\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a+\\delta\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a,w,\\theta_s)}{\\delta\\tau_a}。\n$$\n- 如果 $\\tau_a$ 位于上边界，使用后向差分：\n$$\n\\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a-\\delta\\tau_a,w,\\theta_s)}{\\delta\\tau_a}。\n$$\n选择 $\\delta\\tau_a = 10^{-3}$。\n\n算法要求：\n- 使用提供的常数和比尔-朗伯表达式，在指定的网格上计算 $T_\\lambda(\\tau_a,w,\\theta_s)$ 来合成LUT。在规则网格上使用三线性插值来插值任意 $(\\tau_a,w,\\theta_s)$ 处的 $T_\\lambda$。\n- 对于每个测试用例，使用插值得到的 $T_\\lambda$ 计算 $\\rho_\\lambda$，并如上所述，通过对插值得到的 $T_\\lambda$ 应用关于 $\\tau_a$ 的有限差分来计算 $\\partial \\rho_\\lambda / \\partial \\tau_a$。\n\n测试套件：\n为以下五个测试用例提供结果，每个用例以元组 $(L_\\lambda^{TOA}, \\tau_a, w, \\theta_s)$ 的形式给出，单位和约定如前所述：\n- 用例 1：$(80.0,\\;0.3,\\;2.0,\\;40)$,\n- 用例 2：$(50.0,\\;0.0,\\;1.0,\\;0)$,\n- 用例 3：$(30.0,\\;1.0,\\;5.0,\\;75)$,\n- 用例 4：$(60.0,\\;0.5,\\;4.0,\\;60)$,\n- 用例 5：$(70.0,\\;0.2,\\;1.5,\\;30)$。\n\n最终输出格式：\n- 你的程序应生成单行输出，包含一个列表的列表形式的结果，其中每个内部列表包含两个浮点数 $[\\rho_\\lambda,\\;\\partial \\rho_\\lambda/\\partial \\tau_a]$，对应一个测试用例，顺序与上述指定相同。例如，输出应具有以下形式：\n$$\n\\big[\\, [\\rho_1,\\,d\\rho_1],\\;[\\rho_2,\\,d\\rho_2],\\;[\\rho_3,\\,d\\rho_3],\\;[\\rho_4,\\,d\\rho_4],\\;[\\rho_5,\\,d\\rho_5]\\,\\big],\n$$\n用数值替换符号条目。",
            "solution": "该问题要求针对一组大气和观测条件，计算地表双向反射因子 $\\rho_\\lambda$ 及其对气溶胶光学厚度的灵敏度 $\\partial \\rho_\\lambda / \\partial \\tau_a$。该方法基于一个简化的大气辐射传输模型，其中总大气透射率 $T_\\lambda$ 被预先计算并存储在一个查找表 (LUT) 中。然后，该 LUT 用于对任意条件下的 $T_\\lambda$ 进行快速插值，从而推导出 $\\rho_\\lambda$ 及其导数。该过程概述为以下几个步骤。\n\n**步骤1：透射率查找表 (LUT) 的合成**\n\n该方法的基础是准确高效地计算总大气透射率 $T_\\lambda$。问题提供了一个基于物理的比尔-朗伯定律模型来计算 $T_\\lambda$，该定律描述了光穿过介质时的衰减。总透射率由太阳到地表路径上的透射率和地表到传感器路径上的透射率的乘积给出。它是三个变量的函数：气溶胶光学厚度 ($\\tau_a$)、水汽柱含量 ($w$) 和太阳天顶角 ($\\theta_s$)。\n\n模型表达式为：\n$$\nT_\\lambda(\\tau_a, w, \\theta_s) = \\exp\\left(-m_s\\left(\\alpha_\\lambda\\,\\tau_a + k_{\\lambda,d}\\,w + \\tau_{R,\\lambda,d}\\right) - m_v\\left(\\beta_\\lambda\\,\\tau_a + k_{\\lambda,u}\\,w + \\tau_{R,\\lambda,u}\\right)\\right)\n$$\n其中 $m_s = \\sec\\theta_s$ 是太阳大气质量，$m_v = \\sec\\theta_v$ 是传感器视角大气质量。问题指定了一个天底视角传感器，此时 $\\theta_v = 0^\\circ$，因此 $m_v = 1$。给定光谱波段 $\\lambda$ 的常数为：$\\alpha_\\lambda = 0.3$，$\\beta_\\lambda = 0.15$，$k_{\\lambda,d} = 0.004$，$k_{\\lambda,u} = 0.002$，$\\tau_{R,\\lambda,d} = 0.02$，以及 $\\tau_{R,\\lambda,u} = 0.01$。\n\n代入这些值，要使用的特定透射率函数为：\n$$\nT_\\lambda(\\tau_a, w, \\theta_s) = \\exp\\left( - \\frac{1}{\\cos\\theta_s} \\left(0.3\\,\\tau_a + 0.004\\,w + 0.02\\right) - \\left(0.15\\,\\tau_a + 0.002\\,w + 0.01\\right) \\right)\n$$\n必须注意，三角函数 $\\cos\\theta_s$ 的计算必须使用弧度单位的 $\\theta_s$。\n\nLUT 是通过在三维网格的每个节点上计算该 $T_\\lambda$ 函数来构建的。网格轴由给定的值集定义：\n- 气溶胶光学厚度：$\\tau_a \\in \\{\\,0.0,\\,0.2,\\,0.5,\\,1.0\\,\\}$\n- 水汽柱含量：$w \\in \\{\\,0.5,\\,1.5,\\,3.0,\\,5.0\\,\\}$\n- 太阳天顶角：$\\theta_s \\in \\{\\,0,\\,30,\\,60,\\,75\\,\\}$ 度\n\n这将产生一个存储 $T_\\lambda$ 值的 $4 \\times 4 \\times 4$ 的 LUT。\n\n**步骤2：透射率 $T_\\lambda$ 的三线性插值**\n\n对于一个具有任意参数 $(\\tau_{a,q}, w_q, \\theta_{s,q})$ 的给定测试用例，必须从 LUT 中的离散值插值出相应的透射率 $T_\\lambda$。指定的方法是三线性插值。此方法将查询点视为位于一个由最近的 8 个网格点定义的直线网格单元（一个长方体）内。插值结果是这 8 个角点值的加权平均值，其中权重由该点在长方体内的相对位置确定。\n\n设查询点为 $(x_q, y_q, z_q)$，周围的网格单元由角点 $(x_i, y_j, z_k)$ 和 $(x_{i+1}, y_{j+1}, z_{k+1})$ 定义。首先，我们确定查询点沿每个轴的分数距离：\n$$\nd_x = \\frac{x_q - x_i}{x_{i+1} - x_i}, \\quad d_y = \\frac{y_q - y_j}{y_{j+1} - y_j}, \\quad d_z = \\frac{z_q - z_k}{z_{k+1} - z_k}\n$$\n然后，查询点的值 $V$ 通过一系列线性插值找到。例如，可以先沿着 $x$ 轴在单元格 $y-z$ 平面底部的四个角点处进行插值，然后沿着 $y$ 轴对这四个结果进行插值得到两个值，最后沿着 $z$ 轴对这两个值进行插值。在计算上，即使网格间距不均匀（如此处的情况），这也可以通过配备了规则网格上多元插值功能的库来高效处理。\n\n**步骤3：地表反射率 $\\rho_\\lambda$ 的计算**\n\n一旦获得了插值后的透射率 $T_\\lambda(\\tau_{a,q}, w_q, \\theta_{s,q})$，便使用所提供的简化辐射传输方程计算地表反射率 $\\rho_\\lambda$：\n$$\n\\rho_\\lambda = \\frac{\\pi\\,L_\\lambda^{TOA}}{E_{0,\\lambda}\\,\\cos\\theta_s\\,T_\\lambda}\n$$\n这里，$L_\\lambda^{TOA}$ 是给定像素的实测大气顶层辐亮度，$E_{0,\\lambda}$ 是地外太阳辐照度，给定值为 $1850$ W·m$^{-2}$·µm$^{-1}$。和之前一样，$\\theta_s$ 在余弦函数中必须是弧度。\n\n**步骤4：反射率灵敏度 $\\partial \\rho_\\lambda / \\partial \\tau_a$ 的计算**\n\n最后一步是量化计算出的反射率对气溶胶光学厚度变化的局部灵敏度。这由偏导数 $\\partial \\rho_\\lambda / \\partial \\tau_a$ 给出。对 $\\rho_\\lambda$ 的表达式应用链式法则：\n$$\n\\frac{\\partial \\rho_\\lambda}{\\partial \\tau_a} = \\frac{\\partial}{\\partial \\tau_a} \\left( \\frac{\\pi\\,L_\\lambda^{TOA}}{E_{0,\\lambda}\\,\\cos\\theta_s} \\cdot T_\\lambda^{-1} \\right) = \\frac{\\pi\\,L_\\lambda^{TOA}}{E_{0,\\lambda}\\,\\cos\\theta_s} \\left( -T_\\lambda^{-2} \\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\right)\n$$\n通过代入 $\\rho_\\lambda$ 的定义，这可以更简洁地表示为：\n$$\n\\frac{\\partial \\rho_\\lambda}{\\partial \\tau_a} = -\\frac{\\rho_\\lambda}{T_\\lambda} \\frac{\\partial T_\\lambda}{\\partial \\tau_a}\n$$\n透射率的导数 $\\partial T_\\lambda / \\partial \\tau_a$ 是通过对*插值*的透射率函数应用有限差分格式来数值计算的。格式的选择取决于查询点 $\\tau_{a,q}$ 相对于 $\\tau_a$ 网格边界 $[0.0, 1.0]$ 的位置。使用一个小的扰动 $\\delta\\tau_a = 10^{-3}$。\n\n-   如果 $\\tau_{a,q}$ 是一个内部点 ($0.0  \\tau_{a,q}  1.0$)，使用二阶精度的中心差分：\n    $$\n    \\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a+\\delta\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a-\\delta\\tau_a,w,\\theta_s)}{2\\,\\delta\\tau_a}\n    $$\n-   如果 $\\tau_{a,q}$ 位于下边界 ($\\tau_{a,q} = 0.0$)，需要使用一阶前向差分：\n    $$\n    \\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a+\\delta\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a,w,\\theta_s)}{\\delta\\tau_a}\n    $$\n-   如果 $\\tau_{a,q}$ 位于上边界 ($\\tau_{a,q} = 1.0$)，使用一阶后向差分：\n    $$\n    \\frac{\\partial T_\\lambda}{\\partial \\tau_a} \\approx \\frac{T_\\lambda(\\tau_a,w,\\theta_s) - T_\\lambda(\\tau_a-\\delta\\tau_a,w,\\theta_s)}{\\delta\\tau_a}\n    $$\n这些公式中每一次对 $T_\\lambda$ 的计算都使用步骤2中建立的三线性插值函数来执行。确定了 $\\partial T_\\lambda / \\partial \\tau_a$ 后，最终的灵敏度 $\\partial \\rho_\\lambda / \\partial \\tau_a$ 就可以轻松计算出来。至此完成了整个指定的算法。",
            "answer": "```python\nimport numpy as np\nfrom scipy.interpolate import RegularGridInterpolator\n\ndef solve():\n    \"\"\"\n    Computes surface reflectance and its sensitivity to aerosol optical thickness\n    using a LUT-based atmospheric correction approach.\n    \"\"\"\n\n    # --- Problem Constants ---\n    # Atmospheric model parameters\n    ALPHA_LAMBDA = 0.3\n    BETA_LAMBDA = 0.15\n    K_LAMBDA_D = 0.004\n    K_LAMBDA_U = 0.002\n    TAU_R_LAMBDA_D = 0.02\n    TAU_R_LAMBDA_U = 0.01\n\n    # View geometry\n    THETA_V_DEG = 0.0\n    M_V = 1.0 / np.cos(np.deg2rad(THETA_V_DEG)) # sec(theta_v)\n\n    # Solar irradiance\n    E0_LAMBDA = 1850.0\n\n    # Finite difference step for sensitivity\n    DELTA_TAU_A = 1e-3\n\n    # --- LUT Grid Definition ---\n    TAU_A_GRID = np.array([0.0, 0.2, 0.5, 1.0])\n    W_GRID = np.array([0.5, 1.5, 3.0, 5.0])\n    THETA_S_GRID = np.array([0.0, 30.0, 60.0, 75.0])\n    GRIDS = (TAU_A_GRID, W_GRID, THETA_S_GRID)\n    \n    # --- Test Cases ---\n    test_cases = [\n        # (L_toa, tau_a, w, theta_s)\n        (80.0, 0.3, 2.0, 40.0),\n        (50.0, 0.0, 1.0, 0.0),\n        (30.0, 1.0, 5.0, 75.0),\n        (60.0, 0.5, 4.0, 60.0),\n        (70.0, 0.2, 1.5, 30.0),\n    ]\n\n    def transmittance_model(tau_a, w, theta_s_deg):\n        \"\"\"\n        Calculates atmospheric transmittance based on the provided model.\n        \"\"\"\n        # Convert solar zenith angle to radians for trig functions\n        theta_s_rad = np.deg2rad(theta_s_deg)\n        # Handle the case theta_s = 90 deg, though not in grid\n        cos_theta_s = np.cos(theta_s_rad)\n        if np.isclose(cos_theta_s, 0):\n            # Physical limit, transmittance is zero\n            return 0.0\n        m_s = 1.0 / cos_theta_s  # sec(theta_s)\n        \n        downwelling_exponent = m_s * (ALPHA_LAMBDA * tau_a + K_LAMBDA_D * w + TAU_R_LAMBDA_D)\n        upwelling_exponent = M_V * (BETA_LAMBDA * tau_a + K_LAMBDA_U * w + TAU_R_LAMBDA_U)\n        \n        total_exponent = downwelling_exponent + upwelling_exponent\n        \n        return np.exp(-total_exponent)\n\n    def synthesize_lut(grids):\n        \"\"\"\n        Generates the 3D LUT for transmittance.\n        \"\"\"\n        tau_grid, w_grid, theta_grid = grids\n        lut = np.zeros((len(tau_grid), len(w_grid), len(theta_grid)))\n        \n        for i, tau_a in enumerate(tau_grid):\n            for j, w in enumerate(w_grid):\n                for k, theta_s in enumerate(theta_grid):\n                    lut[i, j, k] = transmittance_model(tau_a, w, theta_s)\n        return lut\n\n    # --- Main Calculation ---\n    \n    # 1. Synthesize the LUT\n    lut_values = synthesize_lut(GRIDS)\n    \n    # 2. Create the trilinear interpolator object\n    interpolator_T = RegularGridInterpolator(GRIDS, lut_values, method='linear')\n\n    results = []\n    for case in test_cases:\n        l_toa, tau_a, w, theta_s = case\n        \n        # 3. Interpolate transmittance T_lambda for the given point\n        query_point = np.array([tau_a, w, theta_s])\n        T_lambda = interpolator_T(query_point)[0]\n\n        # 4. Calculate surface reflectance rho_lambda\n        cos_theta_s = np.cos(np.deg2rad(theta_s))\n        rho_lambda = (np.pi * l_toa) / (E0_LAMBDA * cos_theta_s * T_lambda)\n        \n        # 5. Calculate sensitivity d(rho)/d(tau_a) via numerical derivative of T_lambda\n        if tau_a == TAU_A_GRID[0]:\n            # Forward difference at lower boundary\n            T_plus = interpolator_T([tau_a + DELTA_TAU_A, w, theta_s])[0]\n            T_center = T_lambda\n            dT_dtau = (T_plus - T_center) / DELTA_TAU_A\n        elif tau_a == TAU_A_GRID[-1]:\n            # Backward difference at upper boundary\n            T_minus = interpolator_T([tau_a - DELTA_TAU_A, w, theta_s])[0]\n            T_center = T_lambda\n            dT_dtau = (T_center - T_minus) / DELTA_TAU_A\n        else:\n            # Centered difference for interior points\n            T_plus = interpolator_T([tau_a + DELTA_TAU_A, w, theta_s])[0]\n            T_minus = interpolator_T([tau_a - DELTA_TAU_A, w, theta_s])[0]\n            dT_dtau = (T_plus - T_minus) / (2 * DELTA_TAU_A)\n            \n        drho_dtau = - (rho_lambda / T_lambda) * dT_dtau\n        \n        results.append([rho_lambda, drho_dtau])\n        \n    # --- Final Output ---\n    # Convert list of lists to the required string format\n    # The default string representation of a list of lists matches the desired output format\n    print(str(results).replace(\" \", \"\"))\n\n# We call the main function to execute the logic.\n# The problem template had this structure, but we will call it directly\n# for cleaner scoping according to standard Python practices. The solve()\n# function encapsulates all logic and can be called from the global scope.\n# After further checks, the requested output format is `[[v1,v2],[v3,v4]...]` without spaces\n# `str(results).replace(\" \", \"\")` achieves this robustly.\nsolve()\n```"
        },
        {
            "introduction": "在提取了多种遥感特征（如光谱指数、纹理等）之后，我们常常面临数据维度过高和特征间共线性的问题，这会影响分类器的性能和效率。主成分分析（PCA）是解决这一问题的经典方法，它能将数据转换到一个新的正交坐标系中，并允许我们用少数几个主成分来保留大部分数据方差。本练习  不仅要求您实现PCA降维，更重要的是，它引导您使用Fisher可分性判据 $J$ 来量化降维过程对类别可分性造成的“信息损失” $L$，从而让您学会如何在保留数据方差和保持类别区分度之间做出权衡。",
            "id": "3860432",
            "problem": "给你代表用于土地覆盖图像分类的遥感观测的带标签特征矩阵。你的任务是使用主成分分析 (PCA) 实现图像分类工作流中的降维和重构阶段，然后量化因降维导致的类别可分性信息损失。你必须基于以下基本定义和广泛接受的公式进行推导和算法设计。\n\n基本原理：\n- 主成分分析 (PCA)：给定一个包含 $n$ 个样本和 $d$ 个特征的标准化数据矩阵 $Z \\in \\mathbb{R}^{n \\times d}$，样本协方差矩阵为 $$C = \\frac{1}{n-1} Z^\\top Z.$$ PCA 寻找 $C$ 的标准正交特征向量及其对应的特征值。如果 $C P = P \\Lambda$，其中 $P \\in \\mathbb{R}^{d \\times d}$ 的列是特征向量，$\\Lambda \\in \\mathbb{R}^{d \\times d}$ 是对角线元素为非负特征值的对角矩阵，则第 $i$ 个主成分的解释方差是 $\\Lambda$ 的第 $i$ 个对角元素。前 $k$ 个成分的解释方差比为 $$r_k = \\frac{\\sum_{i=1}^{k} \\lambda_i}{\\sum_{i=1}^{d} \\lambda_i},$$ 其中特征值按非递增顺序排序，$\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_d \\ge 0$。\n- 从顶层成分重构：设 $P_k \\in \\mathbb{R}^{d \\times k}$ 是由前 $k$ 个特征向量组成的矩阵。投影得分为 $$T_k = Z P_k,$$ 在标准化空间中的秩为 $k$ 的重构为 $$\\hat{Z} = T_k P_k^\\top.$$ 如果 $k = 0$，则定义 $P_0$ 为空，$\\hat{Z}$ 为形状为 $n \\times d$ 的零矩阵。\n- Fisher 用于可分性的类别散度比：给定类别标签 $y \\in \\{0, 1, \\dots\\}$，定义总体均值为 $$\\mu = \\frac{1}{n} \\sum_{i=1}^n z_i,$$ 对于每个类别 $c$，其均值为 $$\\mu_c = \\frac{1}{n_c} \\sum_{i \\in \\mathcal{I}_c} z_i,$$ 其中 $\\mathcal{I}_c$ 是类别 $c$ 中样本的索引集，$n_c = |\\mathcal{I}_c|$。定义类内散度迹为 $$\\mathrm{tr}(S_W) = \\sum_{c} \\sum_{i \\in \\mathcal{I}_c} \\| z_i - \\mu_c \\|_2^2,$$ 类间散度迹为 $$\\mathrm{tr}(S_B) = \\sum_{c} n_c \\| \\mu_c - \\mu \\|_2^2.$$ Fisher 可分性判据是 $$J = \\frac{\\mathrm{tr}(S_B)}{\\mathrm{tr}(S_W)}.$$ 如果 $\\mathrm{tr}(S_W) = 0$，为避免除以零，定义 $J = 0$。\n- 因重构导致的信息损失：对于原始标准化特征 $Z$ 和重构后的标准化特征 $\\hat{Z}$，将信息损失定义为 $J$ 的相对下降量：$$L = \\begin{cases} \\max\\left(0, \\dfrac{J(Z) - J(\\hat{Z})}{J(Z)} \\right),  \\text{若 } J(Z) > 0, \\\\ 0,  \\text{若 } J(Z) = 0. \\end{cases}$$\n\n需要实现的工作流：\n1. 标准化输入矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 的每个特征以获得 $Z$，使得每个特征的均值为零，单位无偏标准差为一。使用分母为 $(n-1)$ 的样本标准差（即无偏估计量）进行缩放；如果某个特征的标准差为零，则用 $1$ 代替除数以避免除以零。\n2. 计算 $C$，对 $C$ 进行特征分解，按特征值的非递增顺序对特征对进行排序，并计算累积解释方差比 $r_k$。\n3. 给定一个目标方差比例 $t \\in [0, 1]$（以小数形式表示），选择最小的整数 $k \\in \\{0,1,\\dots,d\\}$ 使得 $r_k \\ge t$（使用 $10^{-12}$ 的数值容差以考虑浮点舍入误差）。如果 $t = 0$，则令 $k = 0$。\n4. 从前 $k$ 个主成分重构 $\\hat{Z}$，计算 $J(Z)$ 和 $J(\\hat{Z})$，然后计算 $L$。\n\n测试套件：\n对于每个测试用例，你将获得 $(X, y, t)$，其中 $X$ 是特征矩阵，$y$ 是类别标签，$t$ 是以小数表示的目标方差比例。\n\n- 测试用例 1（正常路径，中高方差目标）：\n  - $X_1 = \\begin{bmatrix}\n  $0.12$  $0.38$  $0.50$ \\\\\n  $0.10$  $0.35$  $0.48$ \\\\\n  $0.15$  $0.40$  $0.52$ \\\\\n  $0.30$  $0.55$  $0.60$ \\\\\n  $0.28$  $0.50$  $0.58$ \\\\\n  $0.32$  $0.57$  $0.62$\n  \\end{bmatrix}$，\n  $y_1 = [$0$, $0$, $0$, $1$, $1$, $1$],\n  $t_1 = $0.90$。\n- 测试用例 2（边界情况，全方差目标）：\n  - $X_2 = \\begin{bmatrix}\n  $0.05$  $0.20$ \\\\\n  $0.07$  $0.22$ \\\\\n  $0.50$  $0.45$ \\\\\n  $0.48$  $0.40$ \\\\\n  $0.52$  $0.47$\n  \\end{bmatrix}$，\n  $y_2 = [$0$, $0$, $1$, $1$, $1$],\n  $t_2 = $1.00$。\n- 测试用例 3（边缘情况，零方差目标）：\n  - $X_3 = \\begin{bmatrix}\n  $0.20$  $0.30$  $0.25$  $0.35$ \\\\\n  $0.22$  $0.32$  $0.27$  $0.36$ \\\\\n  $0.18$  $0.28$  $0.24$  $0.33$ \\\\\n  $0.21$  $0.31$  $0.26$  $0.34$ \\\\\n  $0.60$  $0.70$  $0.65$  $0.75$ \\\\\n  $0.62$  $0.68$  $0.64$  $0.74$ \\\\\n  $0.58$  $0.72$  $0.66$  $0.76$ \\\\\n  $0.61$  $0.69$  $0.63$  $0.73$\n  \\end{bmatrix}$，\n  $y_3 = [$0$, $0$, $0$, $0$, $1$, $1$, $1$, $1$],\n  $t_3 = $0.00$。\n- 测试用例 4（共线性情况，低目标比例）：\n  - $X_4 = \\begin{bmatrix}\n  $0.10$  $0.20$  $0.30$ \\\\\n  $0.11$  $0.19$  $0.30$ \\\\\n  $0.09$  $0.21$  $0.30$ \\\\\n  $0.40$  $0.50$  $0.90$ \\\\\n  $0.39$  $0.49$  $0.88$ \\\\\n  $0.41$  $0.51$  $0.92$\n  \\end{bmatrix}$，\n  $y_4 = [$0$, $0$, $0$, $1$, $1$, $1$],\n  $t_4 = $0.50$。\n\n所需计算与输出：\n- 对于每个测试用例 $(X, y, t)$，将 $X$ 标准化为 $Z$，计算满足 $r_k \\ge t$ 的最小 $k$ 值，从前 $k$ 个主成分重构 $\\hat{Z}$，计算 $J(Z)$、$J(\\hat{Z})$ 和 $L$。\n- 将所有目标比例表示为小数。本问题不涉及物理单位或角度。\n- 你的程序应生成单行输出，包含所有测试用例的结果，汇总为列表的列表形式。其中每个内层列表为 $[k, r_k, J(Z), J(\\hat{Z}), L]$，浮点值四舍五入到六位小数，$k$ 为整数。最终输出行必须严格遵循以下格式：\n`\"[ [k1,r1,J1,Jhat1,L1],[k2,r2,J2,Jhat2,L2],[k3,r3,J3,Jhat3,L3],[k4,r4,J4,Jhat4,L4] ]\"`，值之间使用逗号分隔，无任何额外文本。",
            "solution": "该问题要求实现一个特定的工作流，该工作流使用主成分分析 (PCA) 对带标签的特征矩阵进行降维，并随后评估关于类别可分性的信息损失。解决方案是通过系统地应用所提供的数据标准化、PCA、数据重构和 Fisher 类别可分性判据的定义来推导的。\n\n对于每个测试用例 $(X, y, t)$ 的总体步骤如下：\n\n1.  **数据标准化**：初始步骤是将原始特征矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 转换为标准化矩阵 $Z \\in \\mathbb{R}^{n \\times d}$，其中 $n$ 是样本数，$d$ 是特征数。$Z$ 的每个特征（列）必须具有零均值和为1的无偏样本标准差。对于每个特征 $j \\in \\{1, \\dots, d\\}$，从 $X$ 的相应列 $X_j$ 计算均值 $\\mu_j$ 和无偏样本标准差 $\\sigma_j$：\n    $$ \\mu_j = \\frac{1}{n} \\sum_{i=1}^{n} X_{ij} $$\n    $$ \\sigma_j = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (X_{ij} - \\mu_j)^2} $$\n    然后，标准化特征 $Z_{ij}$ 计算如下：\n    $$ Z_{ij} = \\frac{X_{ij} - \\mu_j}{\\sigma_j} $$\n    按照规定，如果任何 $\\sigma_j = 0$，则用 $1$ 替换以防止除以零。\n\n2.  **主成分分析 (PCA)**：对标准化数据 $Z$ 执行 PCA。计算样本协方差矩阵 $C \\in \\mathbb{R}^{d \\times d}$：\n    $$ C = \\frac{1}{n-1} Z^\\top Z $$\n    接下来，对对称矩阵 $C$ 进行特征分解，以找到其特征值 $\\lambda_i$ 和对应的特征向量 $p_i$。\n    $$ C p_i = \\lambda_i p_i $$\n    特征向量构成矩阵 $P$ 的列。对特征对 $(\\lambda_i, p_i)$ 进行排序，使特征值呈非递增顺序：$\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_d \\ge 0$。\n\n3.  **成分选择**：要保留的主成分数量 $k$ 由给定的目标方差比例 $t \\in [0, 1]$ 确定。我们计算前 $m$ 个成分的累积解释方差比：\n    $$ r_m = \\frac{\\sum_{i=1}^{m} \\lambda_i}{\\sum_{i=1}^{d} \\lambda_i} $$\n    所选的成分数量 $k$ 是 $\\{0, 1, \\dots, d\\}$ 中满足 $r_k \\ge t$ 的最小整数。对于 $t=0$ 的特殊情况，我们设置 $k=0$。在比较 $r_k \\ge t$ 时使用 $10^{-12}$ 的数值容差，以考虑浮点不精确性。\n\n4.  **数据重构**：原始标准化数据 $Z$ 被投影到 $k$ 维主子空间上，然后重构回原始的 $d$ 维空间。设 $P_k \\in \\mathbb{R}^{d \\times k}$ 是列为前 $k$ 个主特征向量的矩阵。\n    投影得分计算如下：\n    $$ T_k = Z P_k $$\n    接着，重构的标准化数据矩阵 $\\hat{Z}$ 为：\n    $$ \\hat{Z} = T_k P_k^\\top $$\n    如果 $k=0$，重构矩阵 $\\hat{Z}$ 是一个与 $Z$ 维度相同的零矩阵。\n\n5.  **可分性评估**：使用 Fisher 类别可分性判据 $J$ 来量化类别在特征空间中的分离程度。对原始标准化数据 $Z$ 和重构数据 $\\hat{Z}$ 都计算此值。\n    该判据是类间散度迹与类内散度迹的比值：\n    $$ J = \\frac{\\mathrm{tr}(S_B)}{\\mathrm{tr}(S_W)} $$\n    迹的计算方式如下：\n    $$ \\mathrm{tr}(S_B) = \\sum_{c} n_c \\| \\mu_c - \\mu \\|_2^2 $$\n    $$ \\mathrm{tr}(S_W) = \\sum_{c} \\sum_{i \\in \\mathcal{I}_c} \\| z_i - \\mu_c \\|_2^2 $$\n    其中 $\\mu$ 是数据的总体均值，$\\mu_c$ 是类别 $c$ 中数据点的均值，$n_c$ 是类别 $c$ 中的样本数量，$\\mathcal{I}_c$ 是类别 $c$ 中样本的索引集合。如果 $\\mathrm{tr}(S_W)=0$，$J$ 定义为 $0$。\n\n6.  **信息损失量化**：最后，由降维导致的信息损失 $L$被量化为 Fisher 可分性判据 $J$ 的相对下降量。\n    $$ L = \\begin{cases} \\max\\left(0, \\dfrac{J(Z) - J(\\hat{Z})}{J(Z)} \\right),  \\text{若 } J(Z) > 0 \\\\ 0,  \\text{若 } J(Z) = 0 \\end{cases} $$\n    此值表示在 PCA 重构过程中损失的类别可分性信息的比例。\n\n实现将对问题陈述中提供的每个测试用例应用这六个步骤，并按规定格式化最终结果。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by implementing the PCA workflow and calculating\n    the information loss for class separability for each test case.\n    \"\"\"\n    \n    # Test cases defined in the problem statement.\n    test_cases = [\n        (\n            np.array([\n                [0.12, 0.38, 0.50],\n                [0.10, 0.35, 0.48],\n                [0.15, 0.40, 0.52],\n                [0.30, 0.55, 0.60],\n                [0.28, 0.50, 0.58],\n                [0.32, 0.57, 0.62]\n            ]),\n            np.array([0, 0, 0, 1, 1, 1]),\n            0.90\n        ),\n        (\n            np.array([\n                [0.05, 0.20],\n                [0.07, 0.22],\n                [0.50, 0.45],\n                [0.48, 0.40],\n                [0.52, 0.47]\n            ]),\n            np.array([0, 0, 1, 1, 1]),\n            1.00\n        ),\n        (\n            np.array([\n                [0.20, 0.30, 0.25, 0.35],\n                [0.22, 0.32, 0.27, 0.36],\n                [0.18, 0.28, 0.24, 0.33],\n                [0.21, 0.31, 0.26, 0.34],\n                [0.60, 0.70, 0.65, 0.75],\n                [0.62, 0.68, 0.64, 0.74],\n                [0.58, 0.72, 0.66, 0.76],\n                [0.61, 0.69, 0.63, 0.73]\n            ]),\n            np.array([0, 0, 0, 0, 1, 1, 1, 1]),\n            0.00\n        ),\n        (\n            np.array([\n                [0.10, 0.20, 0.30],\n                [0.11, 0.19, 0.30],\n                [0.09, 0.21, 0.30],\n                [0.40, 0.50, 0.90],\n                [0.39, 0.49, 0.88],\n                [0.41, 0.51, 0.92]\n            ]),\n            np.array([0, 0, 0, 1, 1, 1]),\n            0.50\n        )\n    ]\n\n    def compute_j_criterion(data, labels):\n        \"\"\"Computes Fisher's class separability criterion J.\"\"\"\n        n_samples = data.shape[0]\n        if n_samples == 0:\n            return 0.0\n\n        overall_mean = np.mean(data, axis=0)\n        classes = np.unique(labels)\n        \n        tr_S_W = 0.0\n        tr_S_B = 0.0\n\n        for c in classes:\n            class_samples = data[labels == c]\n            n_c = class_samples.shape[0]\n            if n_c == 0:\n                continue\n            \n            class_mean = np.mean(class_samples, axis=0)\n            \n            tr_S_B += n_c * np.sum((class_mean - overall_mean)**2)\n            tr_S_W += np.sum((class_samples - class_mean)**2)\n\n        if tr_S_W  1e-12: # As per problem, if tr(S_W)=0, J=0\n            return 0.0\n        \n        return tr_S_B / tr_S_W\n\n    results = []\n    \n    for X, y, t in test_cases:\n        # Step 1: Standardize the feature matrix\n        n, d = X.shape\n        mean_X = np.mean(X, axis=0)\n        std_X = np.std(X, axis=0, ddof=1)\n        std_X[std_X == 0] = 1.0  # Avoid division by zero\n        Z = (X - mean_X) / std_X\n\n        # Step 2: Perform PCA\n        C = (1 / (n - 1)) * (Z.T @ Z)\n        eigenvalues, eigenvectors = np.linalg.eigh(C)\n\n        # Sort eigenvalues and eigenvectors in descending order\n        sort_indices = np.argsort(eigenvalues)[::-1]\n        sorted_eigenvalues = eigenvalues[sort_indices]\n        sorted_eigenvectors = eigenvectors[:, sort_indices]\n\n        # Step 3: Determine the number of components k\n        total_variance = np.sum(sorted_eigenvalues)\n        if total_variance  1e-12:\n            cumulative_ratios = np.zeros(d)\n        else:\n            cumulative_ratios = np.cumsum(sorted_eigenvalues) / total_variance\n\n        # Select smallest k such that r_k >= t, using a tolerance\n        # and handling the t=0 case.\n        if t = 1e-12:\n            k = 0\n        else:\n            k_indices = np.where(cumulative_ratios >= t - 1e-12)[0]\n            if len(k_indices) == 0:\n                k = d  # Take all components if t=1 but ratio is slightly less\n            else:\n                k = k_indices[0] + 1\n        \n        r_k = 0.0 if k == 0 else cumulative_ratios[k - 1]\n\n        # Step 4: Reconstruct the data\n        if k == 0:\n            hat_Z = np.zeros_like(Z)\n        else:\n            P_k = sorted_eigenvectors[:, :k]\n            T_k = Z @ P_k\n            hat_Z = T_k @ P_k.T\n\n        # Step 5: Compute J for original and reconstructed data\n        J_Z = compute_j_criterion(Z, y)\n        J_hat_Z = compute_j_criterion(hat_Z, y)\n\n        # Step 6: Compute the information loss L\n        if J_Z > 1e-12:\n            L = max(0.0, (J_Z - J_hat_Z) / J_Z)\n        else:\n            L = 0.0\n\n        results.append([k, r_k, J_Z, J_hat_Z, L])\n    \n    # Format the final output string as specified\n    formatted_results = []\n    for res in results:\n        k, r_val, j_z, j_hat, l_val = res\n        # Format floats to 6 decimal places, k is an integer\n        formatted_str = f\"[{k},{r_val:.6f},{j_z:.6f},{j_hat:.6f},{l_val:.6f}]\"\n        formatted_results.append(formatted_str)\n        \n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(f'\"{final_output}\"')\n\nsolve()\n```"
        },
        {
            "introduction": "一个分类模型的优劣最终需要通过在独立验证集上的性能来评判，而混淆矩阵是这一评判过程的基础。然而，在处理类别不平衡（例如，在广阔的非湿地区域中识别小块湿地）的遥感应用中，单一的总体精度指标可能会产生误导。本练习  要求您从一个给定的混淆矩阵出发，推导并计算平衡精度、F1分数和马修斯相关系数（MCC）等多个评估指标，并分析它们在不平衡数据场景下的适用性，这对于客观评估和选择分类模型至关重要。",
            "id": "3860465",
            "problem": "使用多光谱卫星数据对一个滨海湿地复合体进行了监督式土地覆盖分类。工作流程包括辐射定标、大气校正和正射校正，然后是光谱和纹理描述符的特征工程：归一化植被指数 (NDVI)、归一化水体指数 (NDWI)、修正归一化水体指数 (MNDWI)、缨帽变换湿度以及灰度共生矩阵 (GLCM) 纹理度量。一个分类器在这些特征上进行训练，并在一个包含 $12{,}000$ 个像素的分层验证样本上进行评估，其中包括 $800$ 个参考湿地像素（正类）和 $11{,}200$ 个参考非湿地像素（负类）。得到的混淆矩阵（行是参考标签，列是分类器预测）如下：\n$$\n\\begin{array}{c|cc}\n  \\text{Predicted wetland}  \\text{Predicted non-wetland} \\\\\n\\hline\n\\text{Reference wetland}  480  320 \\\\\n\\text{Reference non-wetland}  1200  10000\n\\end{array}\n$$\n仅从列联表计数的核心定义以及统计分类中使用的相关率（例如，敏感性、特异性、精确率、召回率）出发，推导并计算平衡准确率、F1分数和马修斯相关系数 (MCC)。根据它们的数学构造，简要解释在类别不平衡时，这些指标中哪一个最适合总结性能。将每个指标表示为精确的解析形式（如果可以精确化简，则使用分数或根式），并以单行矩阵的形式提供您的最终答案，按顺序包含平衡准确率、F1分数和MCC。不包括单位。不要四舍五入。",
            "solution": "该问题被验证为具有科学依据、问题明确、客观且自洽。所提供的信息对于推导所需的分类性能指标是充分且一致的。\n\n首先，我们必须定义混淆矩阵的组成部分。设“湿地”类为正类，“非湿地”类为负类。矩阵条目为：\n-   真正例 ($TP$)：参考湿地，预测湿地。$TP = 480$。\n-   假负例 ($FN$)：参考湿地，预测非湿地。$FN = 320$。\n-   假正例 ($FP$)：参考非湿地，预测湿地。$FP = 1200$。\n-   真负例 ($TN$)：参考非湿地，预测非湿地。$TN = 10000$。\n\n实际正例（参考湿地）的总数是 $P = TP + FN = 480 + 320 = 800$。\n实际负例（参考非湿地）的总数是 $N = FP + TN = 1200 + 10000 = 11200$。\n总样本量是 $P + N = 800 + 11200 = 12000$。这些值与问题陈述相符。\n\n现在我们推导并计算所需的指标。\n\n**1. 平衡准确率 ($BA$)**\n平衡准确率定义为敏感性和特异性的算术平均值。\n\n敏感性，也称为真正例率 ($TPR$) 或召回率，是实际正例中被正确识别的比例。\n$$TPR = \\frac{TP}{TP + FN}$$\n代入给定值：\n$$TPR = \\frac{480}{480 + 320} = \\frac{480}{800} = \\frac{48}{80} = \\frac{3}{5}$$\n\n特异性，也称为真负例率 ($TNR$)，是实际负例中被正确识别的比例。\n$$TNR = \\frac{TN}{TN + FP}$$\n代入给定值：\n$$TNR = \\frac{10000}{10000 + 1200} = \\frac{10000}{11200} = \\frac{100}{112} = \\frac{25}{28}$$\n\n那么平衡准确率为：\n$$BA = \\frac{TPR + TNR}{2}$$\n$$BA = \\frac{\\frac{3}{5} + \\frac{25}{28}}{2} = \\frac{\\frac{3 \\times 28 + 25 \\times 5}{5 \\times 28}}{2} = \\frac{\\frac{84 + 125}{140}}{2} = \\frac{\\frac{209}{140}}{2} = \\frac{209}{280}$$\n\n**2. F1分数 ($F_1$)**\nF1分数是精确率和召回率（敏感性）的调和平均值。\n\n精确率，也称为正预测值 ($PPV$)，是预测为正例中实际为正例的比例。\n$$PPV = \\frac{TP}{TP + FP}$$\n代入给定值：\n$$PPV = \\frac{480}{480 + 1200} = \\frac{480}{1680} = \\frac{48}{168} = \\frac{2}{7}$$\n\n召回率与敏感性相同，我们已计算出其值为 $TPR = \\frac{3}{5}$。\n\nF1分数的定义为：\n$$F_1 = 2 \\times \\frac{PPV \\times TPR}{PPV + TPR}$$\n$$F_1 = 2 \\times \\frac{\\frac{2}{7} \\times \\frac{3}{5}}{\\frac{2}{7} + \\frac{3}{5}} = 2 \\times \\frac{\\frac{6}{35}}{\\frac{10+21}{35}} = 2 \\times \\frac{\\frac{6}{35}}{\\frac{31}{35}} = 2 \\times \\frac{6}{31} = \\frac{12}{31}$$\n\n或者，使用直接公式：\n$$F_1 = \\frac{2TP}{2TP + FP + FN} = \\frac{2 \\times 480}{2 \\times 480 + 1200 + 320} = \\frac{960}{960 + 1520} = \\frac{960}{2480} = \\frac{96}{248} = \\frac{12}{31}$$\n\n**3. 马修斯相关系数 ($MCC$)**\nMCC是观测分类和预测二元分类之间的相关系数。其定义为：\n$$MCC = \\frac{TP \\times TN - FP \\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$\n\n分子是：\n$$TP \\times TN - FP \\times FN = (480 \\times 10000) - (1200 \\times 320) = 4800000 - 384000 = 4416000$$\n\n分母平方根中的各项是：\n-   $TP+FP = 480 + 1200 = 1680$ (预测正例)\n-   $TP+FN = 480 + 320 = 800$ (实际正例)\n-   $TN+FP = 10000 + 1200 = 11200$ (实际负例)\n-   $TN+FN = 10000 + 320 = 10320$ (预测负例)\n\n分母是：\n$$\\sqrt{1680 \\times 800 \\times 11200 \\times 10320}$$\n为简化计算，我们注意到所有混淆矩阵计数都是 $80$ 的倍数：\n$TP = 6 \\times 80$, $FN = 4 \\times 80$, $FP = 15 \\times 80$, $TN = 125 \\times 80$。\n设 $k=80$。则 $TP = 6k, FN = 4k, FP = 15k, TN = 125k$。\n\nMCC公式可以改写为：\n$$MCC = \\frac{(6k)(125k) - (15k)(4k)}{\\sqrt{((6+15)k)((6+4)k)((125+15)k)((125+4)k)}}$$\n$$MCC = \\frac{750k^2 - 60k^2}{\\sqrt{(21k)(10k)(140k)(129k)}} = \\frac{690k^2}{k^2\\sqrt{21 \\times 10 \\times 140 \\times 129}}$$\n$$MCC = \\frac{690}{\\sqrt{21 \\times 10 \\times (14 \\times 10) \\times 129}} = \\frac{690}{10\\sqrt{21 \\times 14 \\times 129}} = \\frac{69}{\\sqrt{(3 \\times 7) \\times (2 \\times 7) \\times (3 \\times 43)}}$$\n$$MCC = \\frac{69}{\\sqrt{2 \\times 3^2 \\times 7^2 \\times 43}} = \\frac{69}{3 \\times 7 \\sqrt{2 \\times 43}} = \\frac{23}{7\\sqrt{86}}$$\n\n**类别不平衡情况下指标的解释**\n该问题显示出显著的类别不平衡（$800$ vs. $11{,}200$）。在这种情况下，某些指标可能会产生误导。例如，简单准确率为 $\\frac{480+10000}{12000} \\approx 0.87$，这个值看起来很高，但主要反映了分类器在占主导地位的非湿地类别上的成功。\n\n-   **平衡准确率 ($BA$)**：根据其数学构造 $BA = \\frac{1}{2}(TPR + TNR)$，它是各类别准确率的平均值。它给予少数类（$TPR$）和多数类（$TNR$）的性能相同的权重。这使其成为不平衡数据集上性能的稳健指标，因为它不会因多数负类的过高准确率而膨胀。\n\n-   **F1分数 ($F_1$)**：作为精确率和召回率（$TPR$）的调和平均值，F1分数的构造是为了总结在正类上的性能。其公式 $F_1 = \\frac{2TP}{2TP + FP + FN}$ 不包含真负例（$TN$）的计数。虽然在关注重点为正类时很有用，但它完全忽略了正确分类的负实例数量，这意味着它不能捕捉分类器在两个类别上的完整性能图景。\n\n-   **马修斯相关系数 ($MCC$)**：MCC的公式 $MCC = \\frac{TP \\times TN - FP \\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$ 是这三者中唯一一个使用混淆矩阵所有四个值构建的。它是真实类别和预测类别之间的相关系数，产生一个从-1到+1的分数。它是一个对称指标，意味着如果正负类互换，其值不会改变。由于它使用了所有四个计数值，它被广泛认为是一个信息量大且平衡的单分总结，即使在类别大小差异很大时也能提供可靠的质量度量。\n\n基于对其数学构造的分析，**马修斯相关系数 (MCC)** 是总结不平衡类别性能最合适的指标，因为它将分类的所有方面（真正例、假正例、真负例、假负例）合成为一个单一、平衡且稳健的值。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{209}{280}  \\frac{12}{31}  \\frac{23}{7\\sqrt{86}} \\end{pmatrix}}$$"
        }
    ]
}