{
    "hands_on_practices": [
        {
            "introduction": "Before building complex algorithms, we must understand the fundamental properties of our tools. This first practice challenges you to analyze how a simple gradient estimator—the central difference operator—interacts with image noise . By deriving the variance of the gradient estimate, you will gain a core understanding of error propagation in discrete differentiation and appreciate the inherent trade-off between edge localization and noise sensitivity.",
            "id": "3807314",
            "problem": "A satellite pushbroom sensor acquires a two-dimensional raster of top-of-atmosphere reflectance over a coastal environment used for environmental modeling of shoreline change. Let the measured reflectance field be denoted by $Z(i,j)$, where $i$ indexes the along-track direction ($x$-axis) and $j$ indexes the cross-track direction ($y$-axis). Assume the measurement model $Z(i,j) = S(i,j) + N(i,j)$, where $S(i,j)$ is the unknown true reflectance and $N(i,j)$ is Additive White Gaussian Noise (AWGN) with zero mean, variance $\\sigma^{2}$, and spatial independence across pixels. The pixel spacing along the $x$-axis is $\\Delta_{x}$, which is constant over the scene.\n\nTo detect edges aligned with the $y$-axis, an analyst computes the central difference estimate of the $x$-component of the reflectance gradient at pixel $(i,j)$ using\n$$\ng_{x}(i,j) = \\frac{Z(i+1,j) - Z(i-1,j)}{2\\,\\Delta_{x}}.\n$$\nAssume that $S(i,j)$ is deterministic but unknown and focus only on the noise-induced variability of $g_{x}(i,j)$ under the stated AWGN model. Starting from the fundamental definitions of variance and independence for Gaussian random variables, and using only the linearity of expectation and the independence structure of $N(i,j)$ across pixels, derive a closed-form expression for the variance of $g_{x}(i,j)$ due solely to $N(i,j)$.\n\nExpress your final answer as a symbolic expression in terms of $\\sigma$ and $\\Delta_{x}$. Do not substitute any numerical values. No rounding is required.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and contains all necessary information for a unique solution. It is a standard problem in signal processing and error propagation. Therefore, the problem is deemed valid and a solution will be derived.\n\nThe objective is to find the variance of the gradient estimate, $\\text{Var}(g_x(i,j))$, arising solely from the noise component $N(i,j)$. The gradient estimate $g_x(i,j)$ is given by\n$$\ng_{x}(i,j) = \\frac{Z(i+1,j) - Z(i-1,j)}{2\\,\\Delta_{x}}\n$$\nThe measurement model is $Z(i,j) = S(i,j) + N(i,j)$, where $S(i,j)$ is a deterministic true signal and $N(i,j)$ is Additive White Gaussian Noise (AWGN) with the following properties:\n$1$. Zero mean: $E[N(i,j)] = 0$ for all pixel locations $(i,j)$.\n$2$. Constant variance: $\\text{Var}(N(i,j)) = E[N(i,j)^2] - (E[N(i,j)])^2 = E[N(i,j)^2] = \\sigma^2$ for all $(i,j)$.\n$3$. Spatial independence: $N(i_1, j_1)$ and $N(i_2, j_2)$ are statistically independent for $(i_1, j_1) \\neq (i_2, j_2)$. This implies that $E[N(i_1, j_1)N(i_2, j_2)] = E[N(i_1, j_1)]E[N(i_2, j_2)] = 0$.\n\nWe begin by substituting the measurement model into the expression for $g_x(i,j)$:\n$$\ng_{x}(i,j) = \\frac{[S(i+1,j) + N(i+1,j)] - [S(i-1,j) + N(i-1,j)]}{2\\,\\Delta_{x}}\n$$\nWe can separate the terms related to the true signal $S$ and the noise $N$:\n$$\ng_{x}(i,j) = \\frac{S(i+1,j) - S(i-1,j)}{2\\,\\Delta_{x}} + \\frac{N(i+1,j) - N(i-1,j)}{2\\,\\Delta_{x}}\n$$\nThe variance of a random variable $X$ is defined as $\\text{Var}(X) = E[(X - E[X])^2]$. We first compute the expected value of $g_x(i,j)$, denoted as $E[g_x(i,j)]$. Using the linearity of the expectation operator:\n$$\nE[g_{x}(i,j)] = E\\left[\\frac{S(i+1,j) - S(i-1,j)}{2\\,\\Delta_{x}} + \\frac{N(i+1,j) - N(i-1,j)}{2\\,\\Delta_{x}}\\right]\n$$\n$$\nE[g_{x}(i,j)] = E\\left[\\frac{S(i+1,j) - S(i-1,j)}{2\\,\\Delta_{x}}\\right] + E\\left[\\frac{N(i+1,j) - N(i-1,j)}{2\\,\\Delta_{x}}\\right]\n$$\nSince $S(i,j)$ is deterministic, the first term is a constant and its expectation is the term itself. The factor $\\frac{1}{2\\,\\Delta_{x}}$ can be factored out of the expectation in the second term.\n$$\nE[g_{x}(i,j)] = \\frac{S(i+1,j) - S(i-1,j)}{2\\,\\Delta_{x}} + \\frac{1}{2\\,\\Delta_{x}} E[N(i+1,j) - N(i-1,j)]\n$$\nApplying linearity of expectation to the noise term:\n$$\nE[N(i+1,j) - N(i-1,j)] = E[N(i+1,j)] - E[N(i-1,j)]\n$$\nGiven that the noise has zero mean, $E[N(i,j)] = 0$ for any $(i,j)$. Therefore, $E[N(i+1,j)] = 0$ and $E[N(i-1,j)] = 0$. This leads to:\n$$\nE[N(i+1,j) - N(i-1,j)] = 0 - 0 = 0\n$$\nSubstituting this result back, we find the expected value of the gradient estimate:\n$$\nE[g_{x}(i,j)] = \\frac{S(i+1,j) - S(i-1,j)}{2\\,\\Delta_{x}}\n$$\nNow we compute the variance, $\\text{Var}(g_x(i,j))$.\n$$\n\\text{Var}(g_x(i,j)) = E\\left[ (g_x(i,j) - E[g_x(i,j)])^2 \\right]\n$$\nSubstituting the expressions for $g_x(i,j)$ and $E[g_x(i,j)]$:\n$$\ng_x(i,j) - E[g_x(i,j)] = \\left(\\frac{S(i+1,j) - S(i-1,j)}{2\\,\\Delta_{x}} + \\frac{N(i+1,j) - N(i-1,j)}{2\\,\\Delta_{x}}\\right) - \\frac{S(i+1,j) - S(i-1,j)}{2\\,\\Delta_{x}}\n$$\n$$\ng_x(i,j) - E[g_x(i,j)] = \\frac{N(i+1,j) - N(i-1,j)}{2\\,\\Delta_{x}}\n$$\nThus, the variance is:\n$$\n\\text{Var}(g_x(i,j)) = E\\left[ \\left( \\frac{N(i+1,j) - N(i-1,j)}{2\\,\\Delta_{x}} \\right)^2 \\right]\n$$\nThe constant factor can be squared and taken outside the expectation:\n$$\n\\text{Var}(g_x(i,j)) = \\frac{1}{(2\\,\\Delta_{x})^2} E\\left[ (N(i+1,j) - N(i-1,j))^2 \\right] = \\frac{1}{4\\,\\Delta_{x}^2} E\\left[ (N(i+1,j) - N(i-1,j))^2 \\right]\n$$\nWe expand the squared term inside the expectation:\n$$\n(N(i+1,j) - N(i-1,j))^2 = N(i+1,j)^2 - 2N(i+1,j)N(i-1,j) + N(i-1,j)^2\n$$\nUsing the linearity of expectation on this expanded form:\n$$\nE\\left[ (N(i+1,j) - N(i-1,j))^2 \\right] = E[N(i+1,j)^2] - 2E[N(i+1,j)N(i-1,j)] + E[N(i-1,j)^2]\n$$\nWe evaluate each term:\n$1$. From the definition of variance, $\\text{Var}(X) = E[X^2] - (E[X])^2$. Since $E[N(i,j)] = 0$, we have $\\text{Var}(N(i,j)) = E[N(i,j)^2] = \\sigma^2$. Therefore, $E[N(i+1,j)^2] = \\sigma^2$ and $E[N(i-1,j)^2] = \\sigma^2$.\n$2$. For the cross-term $E[N(i+1,j)N(i-1,j)]$, we use the property of spatial independence. The pixels at $(i+1,j)$ and $(i-1,j)$ are distinct. Thus, the noise values $N(i+1,j)$ and $N(i-1,j)$ are independent random variables. For independent variables, the expectation of their product is the product of their expectations:\n$$\nE[N(i+1,j)N(i-1,j)] = E[N(i+1,j)] E[N(i-1,j)] = 0 \\cdot 0 = 0\n$$\nSubstituting these results back into the expanded expectation:\n$$\nE\\left[ (N(i+1,j) - N(i-1,j))^2 \\right] = \\sigma^2 - 2(0) + \\sigma^2 = 2\\sigma^2\n$$\nFinally, we substitute this into our expression for the variance of $g_x(i,j)$:\n$$\n\\text{Var}(g_x(i,j)) = \\frac{1}{4\\,\\Delta_{x}^2} (2\\sigma^2)\n$$\nSimplifying this expression yields the final result:\n$$\n\\text{Var}(g_x(i,j)) = \\frac{2\\sigma^2}{4\\,\\Delta_{x}^2} = \\frac{\\sigma^2}{2\\,\\Delta_{x}^2}\n$$\nThis is the closed-form expression for the variance of the gradient estimate $g_x(i,j)$ due solely to the additive white Gaussian noise.",
            "answer": "$$\n\\boxed{\\frac{\\sigma^{2}}{2\\Delta_{x}^{2}}}\n$$"
        },
        {
            "introduction": "A critical step in refining a raw gradient map into clean, single-pixel-wide contours is Non-Maximum Suppression (NMS). This hands-on coding exercise requires you to implement the NMS pipeline from first principles, including the crucial step of gradient orientation quantization . Through a synthetic experiment, you will quantitatively measure how this quantization affects the continuity of detected edges along curved features, revealing a key source of algorithmic artifacts.",
            "id": "3807300",
            "problem": "Consider a synthetic experiment to quantify how orientation quantization in gradient-based edge operators affects continuity of detected edges with curvature. In remote sensing and environmental modeling, curved edges such as river meanders or circular built structures are common, and edge continuity after orientation quantization can suffer when curvature is high. The objective is to measure the false suppression rate due to Non-Maximum Suppression (NMS) when orientations are quantized into $4$ versus $8$ directions.\n\nFundamental base: Let $I(x,y)$ be a grayscale image defined on a discrete $N \\times N$ grid with unit pixel spacing. The spatial gradient is defined by $\\nabla I = \\left(\\frac{\\partial I}{\\partial x}, \\frac{\\partial I}{\\partial y} \\right)$, the gradient magnitude by $G = \\|\\nabla I\\|_2$, and the gradient orientation by $\\phi = \\operatorname{atan2}\\left(\\frac{\\partial I}{\\partial y},\\frac{\\partial I}{\\partial x}\\right)$. Curvature of a circle of radius $r$ is $\\kappa = \\frac{1}{r}$, implying the edge normal orientation changes along arc length at rate $\\frac{\\mathrm{d}\\phi}{\\mathrm{d}s} = \\kappa$.\n\nTask: You must implement the following steps from these base definitions, without using any specialized edge-detection shortcuts beyond the core definitions.\n\n1. Construct a synthetic image $I(x,y)$ of size $256 \\times 256$, with pixel centers at integer coordinates and image center at $(x_c,y_c)=(128,128)$. Define a binary disk $B(x,y)$ such that $B(x,y) = 1$ if the Euclidean distance $\\rho = \\sqrt{(x-x_c)^2+(y-y_c)^2}$ satisfies $\\rho \\le r$, and $B(x,y) = 0$ otherwise. Convolve $B$ with a Gaussian to emulate sensor blur, obtaining $I = G_\\sigma \\ast B$, where $G_\\sigma$ is an isotropic Gaussian with standard deviation $\\sigma$. Use $\\sigma = 1.0$ pixels. Angles must be in radians throughout this problem.\n\n2. Compute $\\frac{\\partial I}{\\partial x}$ and $\\frac{\\partial I}{\\partial y}$ using second-order accurate central differences on the discrete grid, then compute $G$ and folded orientation $\\phi \\in [0,\\pi)$ where orientations differing by $\\pi$ are identified (because the gradient direction sign does not matter for NMS).\n\n3. Orientation quantization: For a given number of bins $k \\in \\{4,8\\}$, quantize $\\phi$ to the nearest angle in the set $\\{ m \\cdot \\frac{\\pi}{k} \\mid m=0,1,\\dots,k-1\\}$. Denote the quantized orientation by $\\phi_q$.\n\n4. Non-Maximum Suppression (NMS): For each pixel at $(x,y)$, let $\\mathbf{d} = (\\cos\\phi_q, \\sin\\phi_q)$. Sample the gradient magnitude $G$ at subpixel locations $(x,y) + \\mathbf{d}$ and $(x,y) - \\mathbf{d}$ using bilinear interpolation on the grid. Retain the pixel $(x,y)$ if and only if $G(x,y)$ is greater than or equal to both sampled values; otherwise suppress it. This produces a binary mask $M_k$ for the chosen $k$.\n\n5. Ground-truth arc: Parameterize the circle with radius $r$ centered at $(x_c,y_c)$ by $(x(\\theta),y(\\theta)) = (x_c + r\\cos\\theta, y_c + r\\sin\\theta)$. Restrict to an arc with $\\theta \\in [\\theta_0,\\theta_1]$ where $\\theta_0 = \\frac{\\pi}{4}$ and $\\theta_1 = \\frac{3\\pi}{4}$. Sample $\\theta$ uniformly with sufficiently dense sampling to obtain a set of integer pixel coordinates by rounding $(x(\\theta),y(\\theta))$ to nearest integers; deduplicate the set. These pixels form the ground-truth arc set $\\mathcal{A}_r$.\n\n6. False suppression metric: Define the false suppression rate for a given $k$ and $r$ as the fraction of pixels in $\\mathcal{A}_r$ for which there is no retained NMS pixel in their $3\\times 3$ neighborhood in $M_k$. Formally, for each $(x,y) \\in \\mathcal{A}_r$, let $\\mathcal{N}_{3\\times 3}(x,y)$ be all integer coordinates $(u,v)$ with $|u-x| \\le 1$ and $|v-y| \\le 1$; count a false suppression if $\\sum_{(u,v)\\in \\mathcal{N}_{3\\times 3}(x,y)} M_k(u,v) = 0$. The false suppression rate is the number of false suppressions divided by $|\\mathcal{A}_r|$. This rate must be expressed as a decimal in $[0,1]$.\n\nTest suite: Evaluate the false suppression rate for the following parameter sets, which are designed to probe small-radius high-curvature arcs, moderate curvature, and low curvature, for both $k=4$ and $k=8$.\n\n- Case $1$: $r=8$, $k=4$.\n- Case $2$: $r=8$, $k=8$.\n- Case $3$: $r=20$, $k=4$.\n- Case $4$: $r=20$, $k=8$.\n- Case $5$: $r=60$, $k=4$.\n- Case $6$: $r=60$, $k=8$.\n\nAll angles are in radians. There are no physical units beyond pixel counts. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result1,result2,result3]$), where each result corresponds to the false suppression rate for each case in the order listed above, represented as decimal floating point numbers.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of digital image processing and numerical analysis, well-posed with a clear objective and methodology, and internally consistent. It provides a formal specification for a computational experiment to measure the effect of gradient orientation quantization on edge continuity, a relevant topic in remote sensing data analysis.\n\nThe solution proceeds by implementing the six specified steps for each test case.\n\n**1. Synthetic Image Generation**\n\nThe first step is to create a synthetic grayscale image $I(x,y)$ that serves as the input for our analysis. The image is defined on a discrete grid of size $N \\times N$, where $N=256$. The pixel coordinates $(x,y)$ are integers ranging from $0$ to $255$. The center of the geometric features is specified at $(x_c, y_c) = (128, 128)$.\n\nA binary disk $B(x,y)$ is first constructed. For each pixel, its Euclidean distance $\\rho$ from the center $(x_c, y_c)$ is calculated:\n$$\n\\rho(x,y) = \\sqrt{(x-x_c)^2 + (y-y_c)^2}\n$$\nThe binary disk is then defined based on a given radius $r$:\n$$\nB(x,y) = \\begin{cases} 1 & \\text{if } \\rho(x,y) \\le r \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nTo simulate the blur introduced by an optical sensor, this sharp binary disk $B$ is convolved with an isotropic Gaussian kernel $G_\\sigma$. The problem specifies a standard deviation of $\\sigma = 1.0$ pixel. The final image $I$ is obtained from this convolution:\n$$\nI = G_\\sigma \\ast B\n$$\nThis operation is efficiently performed using a Gaussian filter function, which applies the convolution and appropriately handles boundary conditions. The resulting image $I(x,y)$ is a smooth, continuous-tone representation of a disk.\n\n**2. Gradient Field Computation**\n\nThe next step is to compute the spatial gradient of the image $I(x,y)$. The gradient vector $\\nabla I = (\\frac{\\partial I}{\\partial x}, \\frac{\\partial I}{\\partial y})$ indicates the direction and magnitude of the greatest rate of increase in intensity. The partial derivatives are estimated numerically using second-order accurate central differences on the discrete pixel grid.\n\nFrom the partial derivatives, two key quantities are derived:\nThe gradient magnitude $G$, which represents the local edge strength:\n$$\nG = \\lVert \\nabla I \\rVert_2 = \\sqrt{\\left(\\frac{\\partial I}{\\partial x}\\right)^2 + \\left(\\frac{\\partial I}{\\partial y}\\right)^2}\n$$\nThe gradient orientation $\\phi$, which indicates the direction of the gradient:\n$$\n\\phi = \\operatorname{atan2}\\left(\\frac{\\partial I}{\\partial y}, \\frac{\\partial I}{\\partial x}\\right)\n$$\nFor the purpose of non-maximum suppression, the orientation is \"folded\" into the range $[0, \\pi)$ by taking the angle modulo $\\pi$. This identifies orientations that differ by $\\pi$, as they lie along the same line, which is sufficient for defining the direction perpendicular to an edge.\n\n**3. Orientation Quantization**\n\nTo analyze the effect of discretization, the continuous gradient orientation $\\phi$ is quantized into a fixed number of bins, $k$. The problem specifies test cases for $k=4$ and $k=8$. The set of $k$ representative orientations are given by:\n$$\n\\left\\{ m \\cdot \\frac{\\pi}{k} \\;\\middle|\\; m = 0, 1, \\dots, k-1 \\right\\}\n$$\nEach pixel's orientation $\\phi$ is mapped to the nearest angle in this set. This can be achieved by computing an index $m$:\n$$\nm = \\text{round}\\left(\\frac{\\phi \\cdot k}{\\pi}\\right) \\pmod k\n$$\nThe quantized orientation $\\phi_q$ is then:\n$$\n\\phi_q = m \\cdot \\frac{\\pi}{k}\n$$\nThis process groups all continuous orientations into one of $k$ discrete directions.\n\n**4. Non-Maximum Suppression (NMS)**\n\nNMS is an edge thinning technique. It ensures that only pixels with a gradient magnitude that is a local maximum along the gradient direction are retained. This process uses the quantized orientation $\\phi_q$. For each pixel at integer coordinates $(x,y)$, a unit vector $\\mathbf{d}$ is formed along the gradient direction:\n$$\n\\mathbf{d} = (\\cos\\phi_q, \\sin\\phi_q)\n$$\nThe gradient magnitude $G$ is then sampled at two sub-pixel locations along this line: $(x,y) + \\mathbf{d}$ and $(x,y) - \\mathbf{d}$. Since these locations are not on the integer grid, bilinear interpolation is used to estimate their values from the four nearest neighbors in the $G$ field.\n\nA pixel at $(x,y)$ is retained if its gradient magnitude $G(x,y)$ is greater than or equal to the interpolated magnitudes at both neighboring sub-pixel locations. This operation produces a binary mask $M_k$, where $M_k(x,y)=1$ for retained edge pixels and $M_k(x,y)=0$ for suppressed pixels.\n\n**5. Ground-Truth Arc Definition**\n\nTo evaluate the performance of the edge detection, a ground-truth reference is required. This is defined as the set of pixels that lie on the ideal circular arc being detected. The arc corresponds to the upper-left quadrant of the circle of radius $r$, parameterized as:\n$$\n(x(\\theta), y(\\theta)) = (x_c + r\\cos\\theta, y_c + r\\sin\\theta)\n$$\nThe arc is defined by the angular range $\\theta \\in [\\theta_0, \\theta_1]$, where $\\theta_0 = \\frac{\\pi}{4}$ and $\\theta_1 = \\frac{3\\pi}{4}$. To generate the discrete pixel set, $\\theta$ is sampled at a sufficiently high density to ensure that no pixel on the path is missed. A sampling frequency proportional to the radius $r$ guarantees this. The resulting continuous coordinates $(x(\\theta), y(\\theta))$ are rounded to the nearest integer coordinates. The set of unique integer coordinate pairs forms the ground-truth arc set, denoted $\\mathcal{A}_r$.\n\n**6. False Suppression Metric Calculation**\n\nThe final step is to compute the false suppression rate. This metric quantifies discontinuities in the detected edge. For each pixel $(x,y)$ in the ground-truth set $\\mathcal{A}_r$, we examine its $3 \\times 3$ neighborhood in the NMS mask $M_k$. A false suppression is counted if none of the pixels in this neighborhood (including the center pixel) were retained by the NMS procedure. This condition is formally expressed as:\n$$\n\\sum_{(u,v) \\in \\mathcal{N}_{3\\times3}(x,y)} M_k(u,v) = 0\n$$\nwhere $\\mathcal{N}_{3\\times3}(x,y)$ is the set of all integer coordinates $(u,v)$ such that $|u-x| \\le 1$ and $|v-y| \\le 1$.\n\nThe false suppression rate is the total number of such falsely suppressed ground-truth pixels divided by the total number of pixels in the ground-truth set $|\\mathcal{A}_r|$:\n$$\n\\text{Rate} = \\frac{\\text{Number of False Suppressions}}{|\\mathcal{A}_r|}\n$$\nThis rate, a value between $0$ and $1$, provides a quantitative measure of edge fragmentation due to orientation quantization and curvature. This entire procedure is repeated for each $(r,k)$ pair in the test suite.",
            "answer": "```python\nimport numpy as np\nfrom scipy import ndimage\n\ndef compute_fsr(r: int, k: int) -> float:\n    \"\"\"\n    Computes the false suppression rate for a given radius r and quantization level k.\n\n    This function implements the entire pipeline described in the problem statement:\n    1.  Generates a synthetic blurred disk image.\n    2.  Computes the gradient magnitude and orientation.\n    3.  Performs orientation quantization.\n    4.  Applies Non-Maximum Suppression (NMS).\n    5.  Defines the ground-truth arc.\n    6.  Calculates the false suppression rate.\n    \"\"\"\n    # Define image parameters\n    N = 256\n    xc, yc = 128, 128\n    sigma = 1.0\n\n    # Step 1: Construct synthetic image\n    x = np.arange(N)\n    y = np.arange(N)\n    xx, yy = np.meshgrid(x, y)\n    rho = np.sqrt((xx - xc)**2 + (yy - yc)**2)\n    B = (rho <= r).astype(np.float64)\n    I = ndimage.gaussian_filter(B, sigma=sigma)\n\n    # Step 2: Compute gradient field\n    # numpy.gradient uses second-order accurate central differences\n    gy, gx = np.gradient(I)\n    G = np.sqrt(gx**2 + gy**2)\n    phi = np.arctan2(gy, gx)\n    # Fold orientation to [0, pi)\n    phi_folded = phi % np.pi\n\n    # Step 3: Orientation quantization\n    # Quantize phi_folded to the nearest angle in {m * pi/k}\n    quantization_step = np.pi / k\n    indices = np.round(phi_folded / quantization_step) % k\n    phi_q = indices * quantization_step\n\n    # Step 4: Non-Maximum Suppression (NMS)\n    # Get direction vectors for every pixel based on its quantized orientation\n    dy = np.sin(phi_q)\n    dx = np.cos(phi_q)\n\n    # Coordinates of current pixels\n    yy, xx = np.indices(G.shape)\n\n    # Coordinates of neighbors in the gradient direction\n    coords_p1 = np.stack([(yy + dy).ravel(), (xx + dx).ravel()])\n    coords_p2 = np.stack([(yy - dy).ravel(), (xx - dx).ravel()])\n\n    # Interpolate gradient magnitude at neighbor locations\n    # order=1 specifies bilinear interpolation\n    G_p1 = ndimage.map_coordinates(G, coords_p1, order=1).reshape(G.shape)\n    G_p2 = ndimage.map_coordinates(G, coords_p2, order=1).reshape(G.shape)\n    \n    # A pixel is kept if its magnitude is >= its neighbors along the gradient line\n    # Note: Pad G to handle boundary cases where interpolation might be ill-defined,\n    # though map_coordinates handles this. We suppress borders explicitly for robustness.\n    M_k = np.zeros_like(G, dtype=bool)\n    # Suppress 1-pixel border to avoid edge effects from interpolation\n    M_k[1:-1, 1:-1] = (G[1:-1, 1:-1] >= G_p1[1:-1, 1:-1]) & (G[1:-1, 1:-1] >= G_p2[1:-1, 1:-1])\n\n    # Step 5: Ground-truth arc\n    theta_0 = np.pi / 4\n    theta_1 = 3 * np.pi / 4\n    # Sample theta densely enough to capture all pixels on the arc\n    # Sampling rate proportional to radius ensures this.\n    num_samples = int(np.ceil(r * np.pi))\n    theta = np.linspace(theta_0, theta_1, num_samples)\n    \n    x_arc = xc + r * np.cos(theta)\n    y_arc = yc + r * np.sin(theta)\n    \n    # Round to nearest integer pixel coordinates and find unique pixels\n    # Using a set of tuples to automatically handle deduplication\n    arc_pixels = set(zip(np.round(x_arc).astype(int), np.round(y_arc).astype(int)))\n    A_r = list(arc_pixels)\n\n    if not A_r:\n        return 0.0\n\n    # Step 6: False suppression metric\n    # Use a generic filter to sum the 3x3 neighborhood for each pixel in M_k\n    # This is more efficient than looping.\n    M_k_int = M_k.astype(np.int32)\n    neighborhood_sum = ndimage.generic_filter(M_k_int, np.sum, size=3, mode='constant', cval=0)\n\n    # Extract the neighborhood sum values for the ground-truth pixels\n    gt_coords_x = np.array([p[0] for p in A_r])\n    gt_coords_y = np.array([p[1] for p in A_r])\n\n    # Ensure coordinates are within bounds\n    valid_indices = (gt_coords_x >= 0) & (gt_coords_x < N) & \\\n                    (gt_coords_y >= 0) & (gt_coords_y < N)\n    \n    gt_coords_x = gt_coords_x[valid_indices]\n    gt_coords_y = gt_coords_y[valid_indices]\n\n    if len(gt_coords_x) == 0:\n        return 0.0\n\n    # A false suppression occurs where the neighborhood sum is 0\n    sums_at_gt = neighborhood_sum[gt_coords_y, gt_coords_x]\n    false_suppressions = np.sum(sums_at_gt == 0)\n    \n    false_suppression_rate = false_suppressions / len(gt_coords_x)\n    \n    return false_suppression_rate\n\ndef solve():\n    # Test suite from the problem statement\n    test_cases = [\n        # (r, k)\n        (8, 4),\n        (8, 8),\n        (20, 4),\n        (20, 8),\n        (60, 4),\n        (60, 8),\n    ]\n\n    results = []\n    for r, k in test_cases:\n        result = compute_fsr(r, k)\n        results.append(result)\n\n    # Format output as a comma-separated list of floats in brackets\n    print(f\"[{','.join(f'{res:.10f}' for res in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world remote sensing images often lead to fragmented edge maps due to occlusions or low contrast. This final practice moves beyond simple detection to the higher-level task of edge linking . You will first derive a principled linking criterion from geometric and statistical fundamentals, then implement it to bridge gaps between broken edge segments, a common challenge in feature extraction from satellite data.",
            "id": "3807292",
            "problem": "Consider a two-dimensional image intensity field $I(x,y)$ representing a remote sensing scene containing road surfaces. A road edge in such an image is characterized by a locally large change in intensity across the boundary between road and non-road materials. The image gradient, defined by $\\nabla I = \\left(\\frac{\\partial I}{\\partial x}, \\frac{\\partial I}{\\partial y}\\right)$, provides a vector pointing in the direction of maximum increase of intensity. The gradient orientation at a location $(x,y)$ is defined as $\\theta(x,y) = \\operatorname{atan2}\\left(\\frac{\\partial I}{\\partial y}, \\frac{\\partial I}{\\partial x}\\right)$, and the gradient magnitude is defined as $g(x,y) = \\left\\|\\nabla I(x,y)\\right\\|$. In the presence of occlusions (e.g., shadows or vegetation), edge detector outputs can exhibit broken segments: two edge endpoints that should be connected are separated by a gap with missing edge pixels.\n\nStarting from fundamental definitions of the gradient and properties of the dot product and Euclidean geometry, derive a mathematically principled local linking criterion that assigns a dimensionless linking score $S \\in [0,1]$ to a candidate pair of edge endpoints $A$ and $B$ with known positions, gradient orientations, and gradient magnitudes. The criterion must simultaneously account for:\n- Gradient direction alignment at each endpoint with the straight-line direction across the gap.\n- Proximity of the endpoints, favoring shorter gaps.\n- A minimum gradient magnitude requirement at both endpoints.\n\nYour derivation must begin from the definitions of $\\nabla I$, $\\theta$, and $g$, the dot product of unit vectors, and a well-tested proximity weighting based on a Gaussian function of Euclidean distance. You must not assume or cite any pre-existing edge-linking formulas or provide any shortcut formulas; instead, build the criterion from first principles and clearly motivate its mathematical form.\n\nImplementation requirements:\n- Given endpoint coordinates $(x_A,y_A)$ and $(x_B,y_B)$ measured in pixels, gradient orientations $\\theta_A$ and $\\theta_B$ measured in radians, gradient magnitudes $g_A$ and $g_B$ measured in arbitrary intensity units, a proximity scale $\\sigma_d$ measured in pixels, and a minimum gradient magnitude threshold $\\tau_g$ measured in the same units as $g$, compute the linking score $S$ using your derived criterion.\n- Angles must be treated in radians.\n- Distances must be expressed in pixels.\n\nTest suite:\nEvaluate your implementation on the following five cases. For each case, compute the linking score $S$.\n\n- Case $1$ (typical alignment and short gap): $(x_A,y_A)=(10,20)$, $(x_B,y_B)=(13,20)$, $\\theta_A=0$, $\\theta_B=\\pi$, $g_A=2.0$, $g_B=2.5$, $\\sigma_d=4.0$, $\\tau_g=1.0$.\n- Case $2$ (strong misalignment at both ends): $(x_A,y_A)=(10,20)$, $(x_B,y_B)=(13,20)$, $\\theta_A=\\frac{\\pi}{2}$, $\\theta_B=\\frac{\\pi}{2}$, $g_A=2.0$, $g_B=2.5$, $\\sigma_d=4.0$, $\\tau_g=1.0$.\n- Case $3$ (long gap but perfect alignment): $(x_A,y_A)=(0,0)$, $(x_B,y_B)=(50,0)$, $\\theta_A=0$, $\\theta_B=\\pi$, $g_A=3.0$, $g_B=3.0$, $\\sigma_d=10.0$, $\\tau_g=1.0$.\n- Case $4$ (moderate alignment and medium gap): $(x_A,y_A)=(0,0)$, $(x_B,y_B)=(5,0)$, $\\theta_A=\\frac{\\pi}{6}$, $\\theta_B=\\pi-\\frac{\\pi}{6}$, $g_A=2.0$, $g_B=2.0$, $\\sigma_d=5.0$, $\\tau_g=1.0$.\n- Case $5$ (weak gradients below threshold): $(x_A,y_A)=(100,100)$, $(x_B,y_B)=(101,100)$, $\\theta_A=0$, $\\theta_B=\\pi$, $g_A=0.5$, $g_B=0.2$, $\\sigma_d=4.0$, $\\tau_g=1.0$.\n\nFinal output specification:\nYour program should produce a single line of output containing the linking scores as a comma-separated list of floats, each rounded to $6$ decimal places, enclosed in square brackets (e.g., \"[$s_1,s_2,s_3,s_4,s_5$]\"). The scores are dimensionless. No other text should be printed.",
            "solution": "The problem requires the derivation of a mathematically principled local linking score, $S$, for a pair of candidate edge endpoints, $A$ and $B$, in a digital image. The score must be dimensionless, fall within the range $[0,1]$, and simultaneously evaluate three criteria: gradient magnitude, endpoint proximity, and gradient alignment. The derivation will proceed from the fundamental definitions provided, without recourse to pre-existing formulae.\n\nThe overall linking score $S$ will be constructed as a product of three independent factors, each corresponding to one of the required criteria and normalized to the range $[0,1]$. A multiplicative combination ensures that a poor score on any single criterion will penalize the overall score significantly, which is a desirable property for a conservative linking heuristic. The score is thus defined as:\n$$S = S_{mag} \\cdot S_{prox} \\cdot S_{align}$$\nEach component will now be derived from first principles.\n\n1. Gradient Magnitude Score ($S_{mag}$)\nThis component enforces the condition that both endpoints must represent strong edge features, as indicated by a gradient magnitude $g$ exceeding a specified threshold $\\tau_g$. The requirement is binary: if either endpoint fails this test, the pair is not a candidate for linking, and the score should be $0$. If both endpoints pass, this criterion is fully satisfied.\n\nLet $g_A$ and $g_B$ be the gradient magnitudes at endpoints $A$ and $B$, respectively. The minimum gradient magnitude threshold is $\\tau_g$. The score $S_{mag}$ can be formulated as a piecewise function:\n$$\nS_{mag} = \\begin{cases} 1 & \\text{if } g_A \\ge \\tau_g \\text{ and } g_B \\ge \\tau_g \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nThis formulation ensures that $S_{mag} \\in \\{0, 1\\}$ and acts as a gatekeeper for the overall score $S$.\n\n2. Proximity Score ($S_{prox}$)\nThis component must assign a higher score to endpoints that are closer to each other, reflecting the higher probability that they belong to the same broken contour. The problem specifies a weighting based on a Gaussian function of the Euclidean distance between the endpoints.\n\nLet the coordinates of the endpoints be $A(x_A, y_A)$ and $B(x_B, y_B)$. The Euclidean distance $d$ between them is given by:\n$$d = \\left\\| \\vec{p}_B - \\vec{p}_A \\right\\| = \\sqrt{(x_B - x_A)^2 + (y_B - y_A)^2}$$\nwhere $\\vec{p}_A = (x_A, y_A)$ and $\\vec{p}_B = (x_B, y_B)$ are the position vectors of the endpoints.\n\nA standard, unnormalized Gaussian function centered at zero distance is of the form $\\exp\\left(-\\frac{d^2}{2\\sigma^2}\\right)$. We adopt this form, using the provided proximity scale parameter $\\sigma_d$ as the standard deviation $\\sigma$. This yields the proximity score:\n$$S_{prox} = \\exp\\left(-\\frac{d^2}{2\\sigma_d^2}\\right)$$\nThis function correctly maps the distance $d$ to a score in the range $(0, 1]$. When the distance $d=0$, $S_{prox}=1$. As $d \\to \\infty$, $S_{prox} \\to 0$. The rate of decay is controlled by $\\sigma_d$, which sets the characteristic length scale for \"close\" endpoints.\n\n3. Gradient Alignment Score ($S_{align}$)\nThis component quantifies how well the gradient orientations at the endpoints align with the geometry of the gap between them. According to the problem's definition, the gradient vector $\\nabla I$ points in the direction of maximum intensity increase, which is perpendicular to the edge contour itself. The test cases provided imply a geometric configuration where the gradients at the two endpoints point towards each other along the line segment connecting them. This suggests a model not of a single broken edge, but of two edges facing each other across a gap, a common scenario for features like roads. We will formalize this \"mutual alignment\" criterion.\n\nFirst, we define the unit vectors that describe the geometry.\n- The unit vector pointing from $A$ to $B$ is $\\vec{u}_{AB} = \\frac{\\vec{p}_B - \\vec{p}_A}{d}$. This vector represents the direction of the gap.\n- The unit vector in the direction of the gradient at endpoint $A$ is derived from its orientation angle $\\theta_A$: $\\vec{u}_A = (\\cos\\theta_A, \\sin\\theta_A)$.\n- Similarly, the gradient unit vector at endpoint $B$ is $\\vec{u}_B = (\\cos\\theta_B, \\sin\\theta_B)$.\n\nThe alignment at endpoint $A$ is best when its gradient vector $\\vec{u}_A$ is parallel to the gap vector $\\vec{u}_{AB}$. The dot product $\\vec{u}_A \\cdot \\vec{u}_{AB}$ measures the cosine of the angle between these two vectors. This value lies in $[-1, 1]$. To convert this to a score in $[0, 1]$ where $1$ represents perfect alignment (collinear and same direction) and $0$ represents orthogonal or opposing alignment, we can use the function $\\max(0, \\vec{u}_A \\cdot \\vec{u}_{AB})$.\n\nFor endpoint $B$, the gradient $\\vec{u}_B$ should point towards $A$. The direction from $B$ to $A$ is given by the unit vector $\\vec{u}_{BA} = -\\vec{u}_{AB}$. The alignment score for $B$ is therefore similarly defined as $\\max(0, \\vec{u}_B \\cdot \\vec{u}_{BA})$.\n\nTo ensure that strong alignment is required at both endpoints simultaneously, we multiply their individual scores:\n$$S_{align} = \\left[ \\max(0, \\vec{u}_A \\cdot \\vec{u}_{AB}) \\right] \\cdot \\left[ \\max(0, \\vec{u}_B \\cdot \\vec{u}_{BA}) \\right]$$\nSubstituting $\\vec{u}_{BA} = -\\vec{u}_{AB}$, the final expression for the alignment score is:\n$$S_{align} = \\max(0, \\vec{u}_A \\cdot \\vec{u}_{AB}) \\cdot \\max(0, -\\vec{u}_B \\cdot \\vec{u}_{AB})$$\nThis score is guaranteed to be in the range $[0, 1]$.\n\nSummary of the Complete Linking Criterion\nCombining all three components, the final linking score $S$ is given by:\n$$S = \\begin{cases} \\exp\\left(-\\frac{d^2}{2\\sigma_d^2}\\right) \\cdot \\max(0, \\vec{u}_A \\cdot \\vec{u}_{AB}) \\cdot \\max(0, -\\vec{u}_B \\cdot \\vec{u}_{AB}) & \\text{if } g_A \\ge \\tau_g \\text{ and } g_B \\ge \\tau_g \\\\ 0 & \\text{otherwise} \\end{cases}$$\nwhere $d = \\left\\| \\vec{p}_B - \\vec{p}_A \\right\\|$ and the unit vectors are defined as above. This criterion is dimensionless, bounded in $[0,1]$, and constructed entirely from the specified first principles.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_linking_score(p_a, p_b, theta_a, theta_b, g_a, g_b, sigma_d, tau_g):\n    \"\"\"\n    Computes the linking score S for a pair of edge endpoints A and B.\n\n    Args:\n        p_a (np.ndarray): Coordinates of endpoint A, shape (2,).\n        p_b (np.ndarray): Coordinates of endpoint B, shape (2,).\n        theta_a (float): Gradient orientation at A in radians.\n        theta_b (float): Gradient orientation at B in radians.\n        g_a (float): Gradient magnitude at A.\n        g_b (float): Gradient magnitude at B.\n        sigma_d (float): Proximity scale in pixels.\n        tau_g (float): Minimum gradient magnitude threshold.\n\n    Returns:\n        float: The dimensionless linking score S in [0, 1].\n    \"\"\"\n    # 1. Gradient Magnitude Score (S_mag)\n    # This acts as a gateway. If the condition is not met, score is 0.\n    if g_a < tau_g or g_b < tau_g:\n        return 0.0\n    \n    # Calculate vector from A to B and the distance d\n    v_ab = p_b - p_a\n    d = np.linalg.norm(v_ab)\n\n    # Handle the degenerate case where endpoints are at the same location.\n    if d == 0:\n        return 0.0  # Or 1.0 depending on convention, 0.0 makes sense for linking a gap.\n\n    # 2. Proximity Score (S_prox)\n    s_prox = np.exp(-d**2 / (2 * sigma_d**2))\n\n    # 3. Gradient Alignment Score (S_align)\n    # Unit vector in the direction of the gap from A to B\n    u_ab = v_ab / d\n\n    # Unit vector for the gradient at A\n    u_a = np.array([np.cos(theta_a), np.sin(theta_a)])\n\n    # Unit vector for the gradient at B\n    u_b = np.array([np.cos(theta_b), np.sin(theta_b)])\n\n    # Dot product for alignment at A (u_a with u_ab)\n    dot_a = np.dot(u_a, u_ab)\n    \n    # Dot product for alignment at B (u_b with u_ba = -u_ab)\n    dot_b = np.dot(u_b, -u_ab)\n\n    # Individual alignment scores must be non-negative\n    score_align_a = max(0, dot_a)\n    score_align_b = max(0, dot_b)\n\n    s_align = score_align_a * score_align_b\n    \n    # Final score is the product of all components (S_mag is implicitly 1 here)\n    s_final = s_prox * s_align\n    \n    return s_final\n\ndef solve():\n    \"\"\"\n    Drives the solution by evaluating the linking score for the given test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Format: ( (x_A, y_A), (x_B, y_B), theta_A, theta_B, g_A, g_B, sigma_d, tau_g )\n    test_cases = [\n        # Case 1 (typical alignment and short gap)\n        ((10, 20), (13, 20), 0, np.pi, 2.0, 2.5, 4.0, 1.0),\n        # Case 2 (strong misalignment at both ends)\n        ((10, 20), (13, 20), np.pi/2, np.pi/2, 2.0, 2.5, 4.0, 1.0),\n        # Case 3 (long gap but perfect alignment)\n        ((0, 0), (50, 0), 0, np.pi, 3.0, 3.0, 10.0, 1.0),\n        # Case 4 (moderate alignment and medium gap)\n        ((0, 0), (5, 0), np.pi/6, np.pi - np.pi/6, 2.0, 2.0, 5.0, 1.0),\n        # Case 5 (weak gradients below threshold)\n        ((100, 100), (101, 100), 0, np.pi, 0.5, 0.2, 4.0, 1.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        p_a, p_b, theta_a, theta_b, g_a, g_b, sigma_d, tau_g = case\n        p_a_np = np.array(p_a, dtype=float)\n        p_b_np = np.array(p_b, dtype=float)\n        \n        score = calculate_linking_score(\n            p_a_np, p_b_np, theta_a, theta_b, g_a, g_b, sigma_d, tau_g\n        )\n        results.append(score)\n\n    # Final print statement in the exact required format.\n    # The output format requires rounding to 6 decimal places.\n    # Using f-string formatting `{:.6f}` ensures this.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}