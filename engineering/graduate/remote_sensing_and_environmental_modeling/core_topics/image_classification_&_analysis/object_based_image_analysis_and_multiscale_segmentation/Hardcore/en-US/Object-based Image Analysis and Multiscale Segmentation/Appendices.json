{
    "hands_on_practices": [
        {
            "introduction": "This practice delves into the mechanics of a widely used segmentation algorithm, Simple Linear Iterative Clustering (SLIC). By performing a single iteration by hand, you will gain a concrete understanding of how superpixels are formed by balancing spectral similarity and spatial proximity. This exercise  is fundamental for grasping how the choice of parameters like compactness, $m$, and grid size, $S$, directly influences the shape and homogeneity of the initial objects in an OBIA workflow.",
            "id": "3830739",
            "problem": "Consider an object-based image analysis segmentation step using Simple Linear Iterative Clustering (SLIC), applied to a small remote sensing patch. In SLIC, pixels are represented in a joint feature space that concatenates color (in CIE $L^{\\ast}a^{\\ast}b^{\\ast}$ space) and spatial coordinates, and the assignment step minimizes a distance that balances spectral and spatial proximity. Let the patch be a $3 \\times 3$ grid indexed by $(x,y)$ with $x \\in \\{1,2,3\\}$ (column) and $y \\in \\{1,2,3\\}$ (row). The color vectors $[L,a,b]$ at each pixel are given by:\n- At $(x,y)=(1,1)$: $[49,0,0]$,\n- $(2,1)$: $[50,2,1]$,\n- $(3,1)$: $[52,4,2]$,\n- $(1,2)$: $[48,-1,0]$,\n- $(2,2)$: $[51,2,1]$,\n- $(3,2)$: $[54,6,3]$,\n- $(1,3)$: $[47,-2,-1]$,\n- $(2,3)$: $[50,1,1]$,\n- $(3,3)$: $[60,10,10]$.\n\nTwo initial cluster centers are specified as:\n- Cluster $1$: color $[50,0,0]$, position $(x,y)=(1,1)$,\n- Cluster $2$: color $[58,8,8]$, position $(x,y)=(3,3)$.\n\nAssume SLIC uses the standard composite distance defined by\n$$\nD(p,C_{k}) \\;=\\; \\sqrt{d_{c}(p,C_{k})^{2} \\;+\\; \\left(\\frac{m}{S}\\right)^{2} \\, d_{s}(p,C_{k})^{2}},\n$$\nwhere $d_{c}(p,C_{k})$ is the Euclidean distance in CIE $L^{\\ast}a^{\\ast}b^{\\ast}$ color space between pixel $p$ and cluster center $C_{k}$, and $d_{s}(p,C_{k})$ is the Euclidean distance in image coordinates $(x,y)$. Take the SLIC grid interval to be $S=2$ and the compactness parameter to be $m=10$. In the assignment step, evaluate $D$ only within a search window of size $2S \\times 2S$ around each center; for this small patch, all pixels fall within both centers' search windows.\n\nStarting from the above initial centers, perform one full SLIC iteration consisting of:\n1. The assignment step: assign each pixel to the cluster $k \\in \\{1,2\\}$ with the smallest $D(p,C_{k})$.\n2. The update step: from first principles of within-cluster sum-of-squares minimization in the joint feature space, derive the update rule for the cluster centers and compute the updated centers by averaging the features of the pixels assigned in step $1$.\n\nReport the final updated cluster centers as a single row matrix containing the components for cluster $1$ followed by cluster $2$ in the order $[L_{1},a_{1},b_{1},x_{1},y_{1},L_{2},a_{2},b_{2},x_{2},y_{2}]$. Round your reported values to four significant figures. No physical units are required.\n\nAdditionally, in your solution, justify a principled convergence criterion for SLIC under this composite distance in terms of the change in cluster centers between successive iterations. The final numeric answer must be the requested row matrix only.",
            "solution": "The problem is well-posed, scientifically grounded, and contains all necessary information to perform one iteration of the Simple Linear Iterative Clustering (SLIC) algorithm. All provided data and parameters are consistent and sufficient for a unique solution. The task is a direct application of a standard algorithm in image analysis. Therefore, the problem is valid.\n\nThe solution process involves a single iteration of the SLIC algorithm, which consists of two main steps: an assignment step and an update step. We will first perform the assignment step, assigning each of the $9$ pixels to the nearest of the two initial cluster centers. Then, we will derive the general update rule for the cluster centers and apply it to compute the new centers based on the pixel assignments. Finally, a principled convergence criterion will be justified.\n\nThe composite distance $D(p,C_{k})$ used for assignment is given by:\n$$\nD(p,C_{k}) \\;=\\; \\sqrt{d_{c}(p,C_{k})^{2} \\;+\\; \\left(\\frac{m}{S}\\right)^{2} \\, d_{s}(p,C_{k})^{2}}\n$$\nwhere $p$ represents a pixel and $C_k$ is a cluster center. The feature vector for any point (pixel or center) is given in the 5-dimensional space $[L, a, b, x, y]$.\nThe parameters are given as the compactness $m=10$ and the grid interval $S=2$. The scaling factor for the spatial distance is therefore $(\\frac{m}{S})^2 = (\\frac{10}{2})^2 = 5^2 = 25$. Comparing distances $D$ is equivalent to comparing their squares, $D^2$, which simplifies computation by removing the square root. The squared distance is:\n$$\nD(p, C_k)^2 = d_c(p, C_k)^2 + 25 \\, d_s(p, C_k)^2\n$$\nThe color distance $d_c$ and spatial distance $d_s$ are Euclidean:\n$$\nd_c(p, C_k)^2 = (L_p - L_k)^2 + (a_p - a_k)^2 + (b_p - b_k)^2\n$$\n$$\nd_s(p, C_k)^2 = (x_p - x_k)^2 + (y_p - y_k)^2\n$$\nThe initial cluster centers are:\n- $C_1$: features $[L_1, a_1, b_1, x_1, y_1] = [50, 0, 0, 1, 1]$\n- $C_2$: features $[L_2, a_2, b_2, x_2, y_2] = [58, 8, 8, 3, 3]$\n\n**1. Assignment Step**\nWe calculate $D^2(p, C_1)$ and $D^2(p, C_2)$ for each of the $9$ pixels and assign the pixel to the cluster with the smaller distance. Let's denote a pixel at coordinates $(x_p, y_p)$ with color $[L_p, a_p, b_p]$ as $p(x_p, y_p)$.\n\nAs a detailed example, consider the pixel $p(1,1)$ with color $[49, 0, 0]$:\nFor Cluster $1$:\n$$d_c(p, C_1)^2 = (49-50)^2 + (0-0)^2 + (0-0)^2 = (-1)^2 = 1$$\n$$d_s(p, C_1)^2 = (1-1)^2 + (1-1)^2 = 0^2 + 0^2 = 0$$\n$$D(p, C_1)^2 = 1 + 25 \\times 0 = 1$$\nFor Cluster $2$:\n$$d_c(p, C_2)^2 = (49-58)^2 + (0-8)^2 + (0-8)^2 = (-9)^2 + (-8)^2 + (-8)^2 = 81 + 64 + 64 = 209$$\n$$d_s(p, C_2)^2 = (1-3)^2 + (1-3)^2 = (-2)^2 + (-2)^2 = 4 + 4 = 8$$\n$$D(p, C_2)^2 = 209 + 25 \\times 8 = 209 + 200 = 409$$\nSince $1 < 409$, pixel $p(1,1)$ is assigned to Cluster $1$.\n\nRepeating this calculation for all $9$ pixels yields the following squared distances and assignments:\n- $p(1,1): [49,0,0,1,1]$. $D^2(p,C_1)=1$, $D^2(p,C_2)=409$. Assign to $C_1$.\n- $p(2,1): [50,2,1,2,1]$. $D^2(p,C_1)=30$, $D^2(p,C_2)=274$. Assign to $C_1$.\n- $p(3,1): [52,4,2,3,1]$. $D^2(p,C_1)=124$, $D^2(p,C_2)=188$. Assign to $C_1$.\n- $p(1,2): [48,-1,0,1,2]$. $D^2(p,C_1)=30$, $D^2(p,C_2)=370$. Assign to $C_1$.\n- $p(2,2): [51,2,1,2,2]$. $D^2(p,C_1)=56$, $D^2(p,C_2)=184$. Assign to $C_1$.\n- $p(3,2): [54,6,3,3,2]$. $D^2(p,C_1)=186$, $D^2(p,C_2)=70$. Assign to $C_2$.\n- $p(1,3): [47,-2,-1,1,3]$. $D^2(p,C_1)=114$, $D^2(p,C_2)=402$. Assign to $C_1$.\n- $p(2,3): [50,1,1,2,3]$. $D^2(p,C_1)=127$, $D^2(p,C_2)=187$. Assign to $C_1$.\n- $p(3,3): [60,10,10,3,3]$. $D^2(p,C_1)=500$, $D^2(p,C_2)=12$. Assign to $C_2$.\n\nSummary of assignments:\n- Pixels in Cluster $1$ ($\\mathcal{P}_1$): $p(1,1), p(2,1), p(3,1), p(1,2), p(2,2), p(1,3), p(2,3)$. The number of pixels is $N_1 = 7$.\n- Pixels in Cluster $2$ ($\\mathcal{P}_2$): $p(3,2), p(3,3)$. The number of pixels is $N_2 = 2$.\n\n**2. Update Step**\n\nFirst, we derive the update rule. The objective is to find the new center $C_k' = [L_k', a_k', b_k', x_k', y_k']$ that minimizes the sum of squared distances for all pixels $p_i$ in its cluster $\\mathcal{P}_k$. The total error for cluster $k$ is:\n$$ E_k = \\sum_{p_i \\in \\mathcal{P}_k} D(p_i, C_k')^2 = \\sum_{p_i \\in \\mathcal{P}_k} \\left( (L_i - L_k')^2 + (a_i - a_k')^2 + (b_i - b_k')^2 + \\left(\\frac{m}{S}\\right)^2 \\left( (x_i - x_k')^2 + (y_i - y_k')^2 \\right) \\right) $$\nTo find the minimum, we take the partial derivative of $E_k$ with respect to each component of the center $C_k'$ and set it to zero. The five components are independent in this sum. For $L_k'$:\n$$ \\frac{\\partial E_k}{\\partial L_k'} = \\sum_{p_i \\in \\mathcal{P}_k} -2(L_i - L_k') = -2 \\left( \\sum_{p_i \\in \\mathcal{P}_k} L_i - N_k L_k' \\right) = 0 $$\n$$ \\implies N_k L_k' = \\sum_{p_i \\in \\mathcal{P}_k} L_i \\implies L_k' = \\frac{1}{N_k} \\sum_{p_i \\in \\mathcal{P}_k} L_i $$\nThe same logic applies to $a_k'$, $b_k'$, $x_k'$, and $y_k'$. The factor $(m/S)^2$ does not affect the location of the minimum for $x_k'$ and $y_k'$, as it's a positive constant. For example, for $x_k'$:\n$$ \\frac{\\partial E_k}{\\partial x_k'} = \\sum_{p_i \\in \\mathcal{P}_k} \\left(\\frac{m}{S}\\right)^2 (-2(x_i - x_k')) = -2\\left(\\frac{m}{S}\\right)^2 \\left( \\sum_{p_i \\in \\mathcal{P}_k} x_i - N_k x_k' \\right) = 0 $$\n$$ \\implies x_k' = \\frac{1}{N_k} \\sum_{p_i \\in \\mathcal{P}_k} x_i $$\nThus, the updated center is simply the mean of the feature vectors of all pixels assigned to that cluster.\n\nNow we compute the updated centers using this rule.\n\nFor Cluster $1$ ($N_1 = 7$):\n- $\\sum L_i = 49+50+52+48+51+47+50 = 347$\n- $\\sum a_i = 0+2+4+(-1)+2+(-2)+1 = 6$\n- $\\sum b_i = 0+1+2+0+1+(-1)+1 = 4$\n- $\\sum x_i = 1+2+3+1+2+1+2 = 12$\n- $\\sum y_i = 1+1+1+2+2+3+3 = 13$\nThe new center $C_1'$ is:\n$L_1' = \\frac{347}{7} \\approx 49.5714$, $a_1' = \\frac{6}{7} \\approx 0.85714$, $b_1' = \\frac{4}{7} \\approx 0.57142$, $x_1' = \\frac{12}{7} \\approx 1.71428$, $y_1' = \\frac{13}{7} \\approx 1.85714$.\n\nFor Cluster $2$ ($N_2 = 2$):\n- $\\sum L_i = 54+60 = 114$\n- $\\sum a_i = 6+10 = 16$\n- $\\sum b_i = 3+10 = 13$\n- $\\sum x_i = 3+3 = 6$\n- $\\sum y_i = 2+3 = 5$\nThe new center $C_2'$ is:\n$L_2' = \\frac{114}{2} = 57$, $a_2' = \\frac{16}{2} = 8$, $b_2' = \\frac{13}{2} = 6.5$, $x_2' = \\frac{6}{2} = 3$, $y_2' = \\frac{5}{2} = 2.5$.\n\nRounding the components of the new centers to four significant figures:\n- $C_1' = [49.57, 0.8571, 0.5714, 1.714, 1.857]$\n- $C_2' = [57.00, 8.000, 6.500, 3.000, 2.500]$\n\n**3. Convergence Criterion**\nThe SLIC algorithm, like k-means, is an iterative optimization procedure. It seeks to minimize the total sum of squared distances, $E = \\sum_k E_k$. Each full iteration (assignment and update steps) is guaranteed to not increase this total error, ensuring the algorithm converges to a local minimum. A principled convergence criterion should reflect the stability of the model's parameters, which are the cluster centers $C_k = [L_k, a_k, b_k, x_k, y_k]$.\n\nThe algorithm has converged when the cluster centers no longer move significantly between iterations. A robust way to measure this movement is to use a metric consistent with the objective function's distance measure. Let $C_k^{(t)}$ and $C_k^{(t+1)}$ be the center of cluster $k$ at iterations $t$ and $t+1$, respectively. The \"shift\" of a cluster center can be quantified using the SLIC distance metric itself, applied to the old and new center vectors:\n$$ \\Delta C_k = D(C_k^{(t+1)}, C_k^{(t)}) = \\sqrt{d_c(C_k^{(t+1)}, C_k^{(t)})^2 + \\left(\\frac{m}{S}\\right)^2 d_s(C_k^{(t+1)}, C_k^{(t)})^2} $$\nConvergence can be declared when the maximum shift among all cluster centers falls below a predefined small threshold, $\\epsilon$:\n$$ \\max_k (\\Delta C_k) < \\epsilon $$\nThis criterion is principled because it directly measures the change in the parameters being optimized (the cluster centers) using the same scaled distance that defines the clusters themselves. Alternatively, convergence can be detected when the pixel assignments do not change between iterations, which implies the centers will also not change.\n\nThe final required output is the row matrix of the updated cluster centers.\n$$ [L_1', a_1', b_1', x_1', y_1', L_2', a_2', b_2', x_2', y_2'] $$\nUsing the values rounded to four significant figures, this is:\n$[49.57, 0.8571, 0.5714, 1.714, 1.857, 57.00, 8.000, 6.500, 3.000, 2.500]$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n49.57 & 0.8571 & 0.5714 & 1.714 & 1.857 & 57.00 & 8.000 & 6.500 & 3.000 & 2.500\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Once an image is segmented into objects, the next step is to characterize them using descriptive features for classification. This exercise  focuses on calculating texture features from the Gray-Level Co-occurrence Matrix (GLCM), a cornerstone of statistical texture analysis. You will compute contrast and homogeneity for individual objects and then investigate how these feature values change when objects are merged, providing a tangible example of the multiscale behavior of object properties.",
            "id": "3830660",
            "problem": "A remote sensing analyst is conducting Object-Based Image Analysis (OBIA) on a multispectral image quantized to four gray levels $\\{0,1,2,3\\}$. Two adjacent segments (objects) at a fine segmentation scale are represented by the following grayscale matrices, where each entry denotes the quantized radiometric value of a pixel within the object:\n\n$$\nO_{A}=\\begin{pmatrix}\n0 & 1 & 1 \\\\\n0 & 1 & 2 \\\\\n0 & 2 & 2\n\\end{pmatrix},\n\\quad\nO_{B}=\\begin{pmatrix}\n2 & 2 & 3 \\\\\n2 & 3 & 3 \\\\\n1 & 2 & 3\n\\end{pmatrix}.\n$$\n\nThe analyst uses texture features derived from the Gray-Level Co-occurrence Matrix (GLCM), defined for a specified offset as follows. For a given direction $\\theta$ and distance $d$, the GLCM $P(i,j)$ counts the number of times that a pixel with gray level $i$ has a neighbor with gray level $j$ at the given offset; it is then normalized to a probability mass function by dividing by the total number of counted pairs so that $\\sum_{i=0}^{3}\\sum_{j=0}^{3}P(i,j)=1$. In this problem, use the horizontal offset $\\theta=0^{\\circ}$ and $d=1$ so that each pair corresponds to a pixel $(r,c)$ and its neighbor $(r,c+1)$, and count only directed pairs from left to right (do not symmetrize).\n\nFrom the normalized GLCM $P$, define the texture features contrast $C$ and homogeneity $H$ by\n$$\nC=\\sum_{i=0}^{3}\\sum_{j=0}^{3}(i-j)^{2}P(i,j),\n\\quad\nH=\\sum_{i=0}^{3}\\sum_{j=0}^{3}\\frac{P(i,j)}{1+|i-j|}.\n$$\n\nTo study multiscale segmentation, the analyst considers a coarser scale in which the two adjacent segments are merged into a single object $O_{AB}$ by horizontal concatenation of $O_{A}$ (left) and $O_{B}$ (right), producing a $3\\times 6$ object. The same GLCM offset ($\\theta=0^{\\circ}$, $d=1$, directed left-to-right pairs) is used on the merged object.\n\nAn OBIA classifier employs a Linear Discriminant Analysis (LDA) score\n$$\nS=w_{c}C+w_{h}H+b,\n$$\nwith known weights $w_{c}=0.7$ and $w_{h}=0.5$; the bias $b$ is constant across objects. Let $\\Delta S=S_{AB}-S_{A}$ denote the change in the discriminant score when moving from the fine-scale object $O_{A}$ to the coarser-scale merged object $O_{AB}$.\n\nCompute $\\Delta S$ exactly from first principles using the definitions above. Express the final answer as a dimensionless real number and round your answer to four significant figures.",
            "solution": "The objective is to compute the change in the Linear Discriminant Analysis (LDA) score, $\\Delta S$, when moving from a fine-scale object $O_A$ to a coarser-scale merged object $O_{AB}$. The change in the score is defined as $\\Delta S = S_{AB} - S_A$.\n\nThe LDA score $S$ for an object is given by $S = w_{c}C + w_{h}H + b$, where $C$ is the contrast, $H$ is the homogeneity, $w_c$ and $w_h$ are weights, and $b$ is a constant bias.\nThe change $\\Delta S$ can be expressed as:\n$$\n\\Delta S = (w_{c}C_{AB} + w_{h}H_{AB} + b) - (w_{c}C_{A} + w_{h}H_{A} + b)\n$$\n$$\n\\Delta S = w_{c}(C_{AB} - C_A) + w_{h}(H_{AB} - H_A)\n$$\nWe are given the weights $w_{c} = 0.7$ and $w_{h} = 0.5$. To find $\\Delta S$, we must first compute the contrast and homogeneity for objects $O_A$ and $O_{AB}$. This requires constructing their respective Gray-Level Co-occurrence Matrices (GLCMs).\n\nFirst, we analyze object $O_A$:\n$$\nO_{A}=\\begin{pmatrix}\n0 & 1 & 1 \\\\\n0 & 1 & 2 \\\\\n0 & 2 & 2\n\\end{pmatrix}\n$$\nThe GLCM is computed using a horizontal offset with distance $d=1$ (left-to-right pairs). We first count the occurrences of pixel pairs $(i,j)$:\n- Row 1: $(0,1)$, $(1,1)$\n- Row 2: $(0,1)$, $(1,2)$\n- Row 3: $(0,2)$, $(2,2)$\n\nThe total number of pairs is $N_A = 3 \\times (3-1) = 6$. The unnormalized GLCM, which we denote as $G_A$, contains the counts of these pairs. The non-zero entries of $G_A$ for gray levels $\\{0,1,2,3\\}$ are:\n- $G_A(0,1) = 2$\n- $G_A(1,1) = 1$\n- $G_A(1,2) = 1$\n- $G_A(0,2) = 1$\n- $G_A(2,2) = 1$\nAll other entries are $0$. The normalized GLCM is $P_A(i,j) = G_A(i,j) / N_A$.\n\nThe contrast $C_A$ is calculated as:\n$$\nC_A=\\sum_{i=0}^{3}\\sum_{j=0}^{3}(i-j)^{2}P_A(i,j) = \\frac{1}{N_A} \\sum_{i=0}^{3}\\sum_{j=0}^{3}(i-j)^{2}G_A(i,j)\n$$\n$$\nC_A = \\frac{1}{6} \\left[ (0-1)^2 G_A(0,1) + (1-1)^2 G_A(1,1) + (1-2)^2 G_A(1,2) + (0-2)^2 G_A(0,2) + (2-2)^2 G_A(2,2) \\right]\n$$\n$$\nC_A = \\frac{1}{6} \\left[ (1)(2) + (0)(1) + (1)(1) + (4)(1) + (0)(1) \\right] = \\frac{1}{6} (2+0+1+4+0) = \\frac{7}{6}\n$$\nThe homogeneity $H_A$ is calculated as:\n$$\nH_A=\\sum_{i=0}^{3}\\sum_{j=0}^{3}\\frac{P_A(i,j)}{1+|i-j|} = \\frac{1}{N_A} \\sum_{i=0}^{3}\\sum_{j=0}^{3}\\frac{G_A(i,j)}{1+|i-j|}\n$$\n$$\nH_A = \\frac{1}{6} \\left[ \\frac{G_A(0,1)}{1+|0-1|} + \\frac{G_A(1,1)}{1+|1-1|} + \\frac{G_A(1,2)}{1+|1-2|} + \\frac{G_A(0,2)}{1+|0-2|} + \\frac{G_A(2,2)}{1+|2-2|} \\right]\n$$\n$$\nH_A = \\frac{1}{6} \\left[ \\frac{2}{2} + \\frac{1}{1} + \\frac{1}{2} + \\frac{1}{3} + \\frac{1}{1} \\right] = \\frac{1}{6} \\left( 1 + 1 + \\frac{1}{2} + \\frac{1}{3} + 1 \\right) = \\frac{1}{6} \\left( 3 + \\frac{5}{6} \\right) = \\frac{1}{6} \\left( \\frac{23}{6} \\right) = \\frac{23}{36}\n$$\n\nNext, we analyze the merged object $O_{AB}$, formed by horizontally concatenating $O_A$ and $O_B$:\n$$\nO_{AB}=\\begin{pmatrix}\n0 & 1 & 1 & 2 & 2 & 3 \\\\\n0 & 1 & 2 & 2 & 3 & 3 \\\\\n0 & 2 & 2 & 1 & 2 & 3\n\\end{pmatrix}\n$$\nThe total number of pairs for the $3 \\times 6$ matrix is $N_{AB} = 3 \\times (6-1) = 15$. We count the occurrences of all left-to-right pairs:\n- Row 1: $(0,1), (1,1), (1,2), (2,2), (2,3)$\n- Row 2: $(0,1), (1,2), (2,2), (2,3), (3,3)$\n- Row 3: $(0,2), (2,2), (2,1), (1,2), (2,3)$\n\nThe non-zero entries of the unnormalized GLCM $G_{AB}$ are:\n- $G_{AB}(0,1) = 2$\n- $G_{AB}(0,2) = 1$\n- $G_{AB}(1,1) = 1$\n- $G_{AB}(1,2) = 3$\n- $G_{AB}(2,1) = 1$\n- $G_{AB}(2,2) = 3$\n- $G_{AB}(2,3) = 3$\n- $G_{AB}(3,3) = 1$\nThe sum of counts is $2+1+1+3+1+3+3+1=15$, which matches $N_{AB}$.\n\nThe contrast $C_{AB}$ is:\n$$\nC_{AB} = \\frac{1}{15} \\left[ (0-1)^2(2) + (0-2)^2(1) + (1-1)^2(1) + (1-2)^2(3) + (2-1)^2(1) + (2-2)^2(3) + (2-3)^2(3) + (3-3)^2(1) \\right]\n$$\n$$\nC_{AB} = \\frac{1}{15} \\left[ (1)(2) + (4)(1) + (0)(1) + (1)(3) + (1)(1) + (0)(3) + (1)(3) + (0)(1) \\right] = \\frac{1}{15}(2+4+0+3+1+0+3+0) = \\frac{13}{15}\n$$\nThe homogeneity $H_{AB}$ is:\n$$\nH_{AB} = \\frac{1}{15} \\left[ \\frac{2}{1+|0-1|} + \\frac{1}{1+|0-2|} + \\frac{1}{1+|1-1|} + \\frac{3}{1+|1-2|} + \\frac{1}{1+|2-1|} + \\frac{3}{1+|2-2|} + \\frac{3}{1+|2-3|} + \\frac{1}{1+|3-3|} \\right]\n$$\n$$\nH_{AB} = \\frac{1}{15} \\left[ \\frac{2}{2} + \\frac{1}{3} + \\frac{1}{1} + \\frac{3}{2} + \\frac{1}{2} + \\frac{3}{1} + \\frac{3}{2} + \\frac{1}{1} \\right] = \\frac{1}{15} \\left( 1 + \\frac{1}{3} + 1 + \\frac{3}{2} + \\frac{1}{2} + 3 + \\frac{3}{2} + 1 \\right)\n$$\n$$\nH_{AB} = \\frac{1}{15} \\left( 6 + \\frac{1}{3} + \\frac{7}{2} \\right) = \\frac{1}{15} \\left( \\frac{36+2+21}{6} \\right) = \\frac{1}{15} \\left( \\frac{59}{6} \\right) = \\frac{59}{90}\n$$\n\nFinally, we compute $\\Delta S$:\n$$\n\\Delta S = w_c (C_{AB} - C_A) + w_h (H_{AB} - H_A)\n$$\n$$\n\\Delta S = 0.7 \\left( \\frac{13}{15} - \\frac{7}{6} \\right) + 0.5 \\left( \\frac{59}{90} - \\frac{23}{36} \\right)\n$$\nWe find common denominators for the differences:\n$$\nC_{AB} - C_A = \\frac{13 \\times 2}{30} - \\frac{7 \\times 5}{30} = \\frac{26 - 35}{30} = -\\frac{9}{30} = -\\frac{3}{10}\n$$\n$$\nH_{AB} - H_A = \\frac{59 \\times 2}{180} - \\frac{23 \\times 5}{180} = \\frac{118 - 115}{180} = \\frac{3}{180} = \\frac{1}{60}\n$$\nSubstituting these values back into the expression for $\\Delta S$:\n$$\n\\Delta S = \\frac{7}{10} \\left( -\\frac{3}{10} \\right) + \\frac{1}{2} \\left( \\frac{1}{60} \\right) = -\\frac{21}{100} + \\frac{1}{120}\n$$\nUsing a common denominator of $600$:\n$$\n\\Delta S = -\\frac{21 \\times 6}{600} + \\frac{1 \\times 5}{600} = \\frac{-126 + 5}{600} = -\\frac{121}{600}\n$$\nConverting to a decimal value:\n$$\n\\Delta S = -0.201666...\n$$\nRounding to four significant figures, we get $-0.2017$.",
            "answer": "$$\\boxed{-0.2017}$$"
        },
        {
            "introduction": "A key challenge in multiscale OBIA is evaluating whether the generated hierarchy of objects is meaningful. This practice  introduces a powerful quantitative method for this task: the cophenetic correlation coefficient. By comparing the hierarchical structure of a segmentation dendrogram to a ground-truth hierarchy, you will learn how to assess the faithfulness of a multiscale segmentation, a critical skill for validating and comparing different segmentation algorithms.",
            "id": "3830662",
            "problem": "In Object-Based Image Analysis (OBIA) for remote sensing and environmental modeling, multiscale segmentation is often summarized by a hierarchical clustering dendrogram whose merge heights quantify the scale at which objects coalesce. To assess how faithfully such a segmentation preserves ground-truth ecological hierarchies across scales, one can compare the dendrogramâ€™s cophenetic distances to those from a ground-truth hierarchical object assemblage.\n\nConsider five leaf objects labeled $A$, $B$, $C$, $D$, and $E$. A segmentation dendrogram is produced by hierarchical agglomeration with the following merge sequence and heights:\n- Merge $A$ and $B$ at height $0.20$.\n- Merge $C$ and $D$ at height $0.35$.\n- Merge $E$ with the cluster $(C,D)$ at height $0.50$.\n- Merge the cluster $(A,B)$ with the cluster $(C,D,E)$ at height $0.80$.\n\nA ground-truth ecological hierarchy is independently obtained with the following merge sequence and heights:\n- Merge $A$ and $B$ at height $0.15$.\n- Merge $C$ and $E$ at height $0.40$.\n- Merge the cluster $(C,E)$ with $D$ at height $0.45$.\n- Merge the cluster $(A,B)$ with the cluster $(C,D,E)$ at height $0.75$.\n\nUsing the foundational definition that the cophenetic distance between two leaves is the height at which they first become members of the same cluster in a dendrogram, construct the cophenetic distance sets for all unordered pairs from $\\{A,B,C,D,E\\}$ for both the segmentation dendrogram and the ground-truth hierarchy. Then compute the cophenetic correlation coefficient, defined as the Pearson correlation coefficient between these two sets of cophenetic distances taken over all unordered leaf pairs. Round your final numerical answer to four significant figures. Express your answer as a dimensionless number.",
            "solution": "The user wants to compute the cophenetic correlation coefficient between two hierarchical clusterings of five objects. This requires a systematic breakdown into three main steps: first, determining the set of cophenetic distances for all pairs of objects from the segmentation dendrogram; second, doing the same for the ground-truth hierarchy; and third, computing the Pearson correlation coefficient between these two sets of distances.\n\nThe set of five leaf objects is $\\{A, B, C, D, E\\}$. The number of unordered pairs of distinct objects is given by the binomial coefficient $\\binom{5}{2} = \\frac{5 \\times (5-1)}{2} = 10$. The pairs are: $(A,B)$, $(A,C)$, $(A,D)$, $(A,E)$, $(B,C)$, $(B,D)$, $(B,E)$, $(C,D)$, $(C,E)$, and $(D,E)$.\n\n**Step 1: Calculate Cophenetic Distances for the Segmentation Dendrogram**\n\nThe cophenetic distance between two objects is defined as the height of the dendrogram at which they are first merged into the same cluster. Let $d_{seg}(i,j)$ denote the cophenetic distance between objects $i$ and $j$ in the segmentation dendrogram.\n\n1.  Merge $A$ and $B$ at height $0.20$. This directly gives the cophenetic distance:\n    $$d_{seg}(A, B) = 0.20$$\n2.  Merge $C$ and $D$ at height $0.35$.\n    $$d_{seg}(C, D) = 0.35$$\n3.  Merge $E$ with the cluster $(C,D)$ at height $0.50$. This means that $E$ merges with $C$ and $D$ at this height.\n    $$d_{seg}(C, E) = 0.50$$\n    $$d_{seg}(D, E) = 0.50$$\n4.  Merge the cluster $(A,B)$ with the cluster $(C,D,E)$ at height $0.80$. Any object from the first cluster, $\\{A,B\\}$, is first merged with any object from the second cluster, $\\{C,D,E\\}$, at this height.\n    $$d_{seg}(A, C) = d_{seg}(A, D) = d_{seg}(A, E) = 0.80$$\n    $$d_{seg}(B, C) = d_{seg}(B, D) = d_{seg}(B, E) = 0.80$$\n\nLet's denote the set of these $10$ distances as $X$. Ordered by the pairs listed above:\n$X = \\{0.20, 0.80, 0.80, 0.80, 0.80, 0.80, 0.80, 0.35, 0.50, 0.50\\}$\n\n**Step 2: Calculate Cophenetic Distances for the Ground-Truth Hierarchy**\n\nSimilarly, let $d_{gt}(i,j)$ be the cophenetic distance in the ground-truth hierarchy.\n\n1.  Merge $A$ and $B$ at height $0.15$.\n    $$d_{gt}(A, B) = 0.15$$\n2.  Merge $C$ and $E$ at height $0.40$.\n    $$d_{gt}(C, E) = 0.40$$\n3.  Merge the cluster $(C,E)$ with $D$ at height $0.45$.\n    $$d_{gt}(C, D) = 0.45$$\n    $$d_{gt}(E, D) = 0.45$$\n4.  Merge the cluster $(A,B)$ with the cluster $(C,D,E)$ at height $0.75$.\n    $$d_{gt}(A, C) = d_{gt}(A, D) = d_{gt}(A, E) = 0.75$$\n    $$d_{gt}(B, C) = d_{gt}(B, D) = d_{gt}(B, E) = 0.75$$\n\nLet's denote the set of these $10$ distances as $Y$, corresponding to the same ordering of pairs.\n$Y = \\{0.15, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.45, 0.40, 0.45\\}$\n\n**Step 3: Compute the Cophenetic Correlation Coefficient**\n\nThe cophenetic correlation coefficient is the Pearson correlation coefficient, $r$, between the two sets of distances, $X = \\{x_1, ..., x_n\\}$ and $Y = \\{y_1, ..., y_n\\}$, where $n=10$. The formula for $r$ is:\n$$r = \\frac{n \\sum_{i=1}^{n} x_i y_i - (\\sum_{i=1}^{n} x_i)(\\sum_{i=1}^{n} y_i)}{\\sqrt{[n \\sum_{i=1}^{n} x_i^2 - (\\sum_{i=1}^{n} x_i)^2][n \\sum_{i=1}^{n} y_i^2 - (\\sum_{i=1}^{n} y_i)^2]}}$$\n\nFirst, we compute the necessary sums:\n$\\sum x_i = 0.20 + 6(0.80) + 0.35 + 2(0.50) = 0.20 + 4.80 + 0.35 + 1.00 = 6.35$\n$\\sum y_i = 0.15 + 6(0.75) + 0.45 + 0.40 + 0.45 = 0.15 + 4.50 + 0.90 + 0.40 = 5.95$\n\nNext, the sums of squares:\n$\\sum x_i^2 = (0.20)^2 + 6(0.80)^2 + (0.35)^2 + 2(0.50)^2 = 0.04 + 6(0.64) + 0.1225 + 2(0.25) = 0.04 + 3.84 + 0.1225 + 0.50 = 4.5025$\n$\\sum y_i^2 = (0.15)^2 + 6(0.75)^2 + (0.45)^2 + (0.40)^2 + (0.45)^2 = 0.0225 + 6(0.5625) + 0.2025 + 0.16 + 0.2025 = 0.0225 + 3.375 + 0.565 = 3.9625$\n\nNext, the sum of products, $x_i y_i$, for each pair:\n- $(A,B)$: $0.20 \\times 0.15 = 0.03$\n- $6$ pairs with $(A/B, C/D/E)$: $6 \\times (0.80 \\times 0.75) = 6 \\times 0.60 = 3.60$\n- $(C,D)$: $0.35 \\times 0.45 = 0.1575$\n- $(C,E)$: $0.50 \\times 0.40 = 0.20$\n- $(D,E)$: $0.50 \\times 0.45 = 0.225$\n$\\sum x_i y_i = 0.03 + 3.60 + 0.1575 + 0.20 + 0.225 = 4.2125$\n\nNow, substitute these sums into the formula for $r$.\nThe numerator is:\n$n \\sum x_i y_i - (\\sum x_i)(\\sum y_i) = 10(4.2125) - (6.35)(5.95) = 42.125 - 37.7825 = 4.3425$\n\nThe terms in the denominator's square root are:\n$n \\sum x_i^2 - (\\sum x_i)^2 = 10(4.5025) - (6.35)^2 = 45.025 - 40.3225 = 4.7025$\n$n \\sum y_i^2 - (\\sum y_i)^2 = 10(3.9625) - (5.95)^2 = 39.625 - 35.4025 = 4.2225$\n\nThe denominator is:\n$\\sqrt{(4.7025)(4.2225)} = \\sqrt{19.85655625} \\approx 4.4560696$\n\nFinally, the correlation coefficient is:\n$$r \\approx \\frac{4.3425}{4.4560696} \\approx 0.97451319$$\n\nThe problem requires rounding to four significant figures.\n$$r \\approx 0.9745$$\nThis high positive correlation indicates a strong agreement between the segmentation hierarchy and the ground-truth ecological hierarchy.",
            "answer": "$$\\boxed{0.9745}$$"
        }
    ]
}