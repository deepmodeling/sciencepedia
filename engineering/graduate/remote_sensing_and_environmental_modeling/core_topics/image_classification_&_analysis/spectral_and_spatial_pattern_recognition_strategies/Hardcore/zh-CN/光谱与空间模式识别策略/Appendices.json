{
    "hands_on_practices": [
        {
            "introduction": "高光谱影像包含数百个光谱波段，这既带来了丰富的信息，也导致了“维度灾难”问题。主成分分析（PCA）是一种基础且强大的降维技术，它通过将数据投影到一组新的正交基上，将大部分方差集中在前几个主成分中。本练习将带你实践如何根据累积解释方差贡献率，来确定保留主成分的最佳数量，这是高光谱数据预处理中的关键一步。",
            "id": "3852805",
            "problem": "考虑一个高光谱数据立方体，表示为一个二维测量矩阵，包含 $p$ 个空间样本（像素）和 $n$ 个光谱波段，记为 $X \\in \\mathbb{R}^{p \\times n}$。在高光谱成像（HSI）中，$X$ 的每一列对应一个光谱波段，每一行对应一个空间观测。主成分分析（PCA）是遥感和环境建模中一种广泛用于光谱降维的策略，其目标是将数据投影到一个低维子空间上，该子空间由与中心化数据的协方差矩阵相关的标准正交特征向量的子集张成。\n\n从以下基本基础开始：\n- 中心化数据矩阵为 $X_c = X - \\mathbf{1}\\mu^\\top$，其中 $\\mu \\in \\mathbb{R}^{n}$ 是波段均值向量，$\\mathbf{1} \\in \\mathbb{R}^{p}$ 是全1向量。\n- 样本协方差矩阵为 $S = \\frac{1}{p-1} X_c^\\top X_c \\in \\mathbb{R}^{n \\times n}$。\n- 协方差矩阵 $S$ 是对称半正定的，允许进行特征分解 $S = V \\Lambda V^\\top$，其中 $V \\in \\mathbb{R}^{n \\times n}$ 是标准正交的，$\\Lambda = \\operatorname{diag}(\\lambda_1,\\dots,\\lambda_n)$ 包含非负特征值。\n- 第 $i$ 个主成分的方差解释率为 $r_i = \\lambda_i \\big/ \\sum_{j=1}^{n} \\lambda_j$，到 $k$ 个分量的累计方差解释率为 $R_k = \\sum_{i=1}^{k} r_i$。\n\n你的任务是为一个具有 $n = 200$ 个波段的高光谱立方体构建一个基于 PCA 的光谱降维方法，通过选择前 $k$ 个特征向量，使得累计方差解释率 $R_k$ 至少为 $0.95$。你必须直接从一个给定的特征值向量中计算出最小整数 $k$，而无需假设任何先前的排序或归一化。\n\n设计一个程序，给定一组 $n = 200$ 的特征值序列，为每个序列计算使 $R_k \\ge 0.95$ 的最小 $k$ 值。该程序必须：\n- 在计算累计方差解释率之前，将特征值按非增序排序。\n- 稳健地处理零特征值和并列特征值。\n- 如果特征值之和为 $0$，则返回 $k = 0$。\n\n使用以下特征值序列的测试套件（每个序列长度为 $n = 200$）：\n- 测试用例 A（指数光谱能量衰减）：对于 $i = 1,\\dots,200$，$\\lambda_i = \\exp\\!\\big(-\\alpha (i-1)\\big)$，其中 $\\alpha = 0.1$。\n- 测试用例 B（平坦光谱）：对于 $i = 1,\\dots,200$，$\\lambda_i = 1$。\n- 测试用例 C（秩亏，有50个非零分量）：对于 $i \\le 50$，$\\lambda_i = 1$；对于 $i > 50$，$\\lambda_i = 0$。\n- 测试用例 D（尖峰光谱，有5个主导分量）：$\\lambda_1 = 500$，$\\lambda_2 = 400$，$\\lambda_3 = 300$，$\\lambda_4 = 200$，$\\lambda_5 = 100$，对于 $i \\ge 6$，$\\lambda_i = 0.1$。\n- 测试用例 E（在 k=95 处达到精确阈值）：对于 $i \\le 100$，$\\lambda_i = 1$；对于 $i > 100$，$\\lambda_i = 0$。\n- 测试用例 F（未排序输入）：与测试用例 A 相同，但随机排列，即输入特征值顺序是任意的。\n\n对于每个测试用例，答案必须是计算出的最小整数 $k$。此计算不涉及物理单位，也不使用角度。\n\n你的程序应生成单行输出，包含一个方括号内的逗号分隔列表（例如，$[result_1,result_2,\\dots]$）。输出必须按 A、B、C、D、E、F 的顺序汇总这些测试用例的整数 $k$。",
            "solution": "该问题要求设计一种算法，以确定达到至少 $0.95$ 的累计方差解释率所需的最小主成分数，记为 $k$。输入是来自一个具有 $n=200$ 个波段的高光谱数据立方体的光谱协方差矩阵的一系列特征值。\n\n主成分分析（PCA）用于降维的核心原理是将数据投影到一个能捕获最大可能方差的低维子空间上。这个子空间由数据协方差矩阵 $S$ 的特征向量张成。每个特征向量（主成分）所捕获的方差由其对应的特征值 $\\lambda_i$ 给出。数据集中的总方差是协方差矩阵的迹，等同于其所有特征值之和，即 $T = \\operatorname{Tr}(S) = \\sum_{j=1}^{n} \\lambda_j$。\n\n为了用有限的 $k$ 个分量捕获最大方差，必须选择与 $k$ 个最大特征值相关联的特征向量。因此，任何此类过程的第一步都必须是将给定的特征值按非增（降序）顺序排序。设排序后的特征值序列为 $\\lambda'_1 \\ge \\lambda'_2 \\ge \\dots \\ge \\lambda'_n \\ge 0$。\n\n在此排序列表中，第 $i$ 个主成分的方差解释率为 $r'_i = \\lambda'_i / T$。前 $k$ 个分量的累计方差解释率是它们各自比率的总和：\n$$R_k = \\sum_{i=1}^{k} r'_i = \\frac{\\sum_{i=1}^{k} \\lambda'_i}{\\sum_{j=1}^{n} \\lambda'_j}$$\n\n目标是找到最小的整数 $k \\ge 0$，使得 $R_k \\ge \\tau$，其中指定的阈值为 $\\tau = 0.95$。\n\n计算这个最小 $k$ 的算法如下：\n\n1.  **接收输入**：输入是一个包含 $n$ 个非负特征值的序列 $(\\lambda_1, \\lambda_2, \\dots, \\lambda_n)$。\n\n2.  **计算总方差**：计算所有特征值的总和 $T = \\sum_{j=1}^{n} \\lambda_j$。\n\n3.  **处理零方差边界情况**：如果 $T = 0$，会出现一个特殊情况。这意味着所有特征值都为 $0$，表明数据中没有方差（所有空间样本都相同）。在这种情况下，不需要任何分量来解释任何方差。根据问题规范，所需的最小分量数为 $k=0$。\n\n4.  **排序特征值**：如果 $T > 0$，将输入的特征值按非增（降序）顺序排序，得到序列 $\\lambda'_1, \\lambda'_2, \\dots, \\lambda'_n$。这一步至关重要，因为它确保了当我们逐个添加分量时，我们总是包含解释剩余方差最大的那个。这种贪心方法保证了累计方差增长得最快，从而确保了 $k$ 的最小性。\n\n5.  **迭代和累加**：初始化一个累计方差和 $C = 0$ 和一个分量计数器 $k=0$。遍历排序后的特征值 $\\lambda'_i$（$i = 1, 2, \\dots, n$）：\n    a. 增加分量计数器：$k \\leftarrow k + 1$。\n    b. 将当前特征值加到累计和中：$C \\leftarrow C + \\lambda'_i$。\n    c. 检查是否达到累计方差阈值：$C \\ge \\tau \\times T$。在本问题中，$\\tau = 0.95$。\n    d. 如果条件满足，当前的 $k$ 值就是所需的最小分量数。算法终止并返回这个 $k$ 值。\n\n这个迭代过程保证能找到最小的 $k$。例如，如果条件在第 $k=k^*$ 步首次满足，我们知道它在第 $k=k^*-1$ 步没有被满足，因此 $k^*$ 是最小的。由于 $\\sum_{i=1}^{n} \\lambda'_i = T$，假设 $T>0$，当 $k=n$ 时条件总是会满足（因为 $T \\ge 0.95 \\times T$）。\n\n应用于具有 $n=200$ 和 $\\tau=0.95$ 的测试用例：\n\n-   **测试用例 A（指数衰减）**：特征值 $\\lambda_i = \\exp(-0.1(i-1))$ 已经是排序好的。算法将对它们求和，直到累计和达到总和的 $95\\%$。这需要进行数值计算。\n-   **测试用例 B（平坦光谱）**：所有 $\\lambda_i = 1$。总方差为 $T = 200 \\times 1 = 200$。目标方差为 $0.95 \\times 200 = 190$。由于每个分量向总和中增加 $1$，我们需要恰好 $190$ 个分量。因此，$k=190$。\n-   **测试用例 C（秩亏）**：$50$ 个特征值为 $1$，其余为 $0$。总方差 $T = 50 \\times 1 = 50$。目标方差为 $0.95 \\times 50 = 47.5$。排序后，前 $50$ 个特征值为 $1$。为了超过 $47.5$ 的和，我们需要对其中的 $48$ 个求和。因此，$k=48$。\n-   **测试用例 D（尖峰光谱）**：必须首先对特征值进行排序。较大的值（$500, 400, 300, 200, 100$）将位于序列的开头。总方差为 $T = (500+400+300+200+100) + (195 \\times 0.1) = 1500 + 19.5 = 1519.5$。目标方差为 $0.95 \\times 1519.5 = 1443.525$。\n    -   $k=1: C_1 = 500$\n    -   $k=2: C_2 = 900$\n    -   $k=3: C_3 = 1200$\n    -   $k=4: C_4 = 1400$ ($ 1443.525$)\n    -   $k=5: C_5 = 1500$ ($\\ge 1443.525$)\n    所以，最小分量数为 $k=5$。\n-   **测试用例 E（精确阈值）**：$100$ 个特征值为 $1$，其余为 $0$。总方差 $T = 100 \\times 1 = 100$。目标方差为 $0.95 \\times 100 = 95$。我们需要对 $95$ 个单位特征值求和才能恰好达到目标。因此，$k=95$。\n-   **测试用例 F（未排序）**：这些特征值是案例 A 的一个随机排列。算法中的排序步骤使得计算与案例 A 完全相同，因此 $k$ 的结果也将相同。\n\n实现将精确遵循此逻辑，确保对各种特征值分布的稳健性，并遵守所有指定的约束。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_k(eigenvalues: np.ndarray, threshold: float = 0.95) - int:\n    \"\"\"\n    Computes the minimal number of principal components (k) to explain a\n    given cumulative variance threshold.\n\n    Args:\n        eigenvalues: A numpy array of eigenvalues.\n        threshold: The cumulative explained variance ratio to achieve.\n\n    Returns:\n        The minimal integer k.\n    \"\"\"\n    # Calculate total variance\n    total_variance = np.sum(eigenvalues)\n\n    # Handle the edge case where there is no variance in the data.\n    if total_variance == 0:\n        return 0\n\n    # Sort eigenvalues in nonincreasing (descending) order\n    sorted_eigenvalues = np.sort(eigenvalues)[::-1]\n\n    # Calculate the target variance to be explained\n    target_variance = threshold * total_variance\n\n    # Iterate to find the minimal k\n    cumulative_variance = 0.0\n    k = 0\n    for eig_val in sorted_eigenvalues:\n        cumulative_variance += eig_val\n        k += 1\n        if cumulative_variance = target_variance:\n            return k\n    \n    # This part should theoretically not be reached if total_variance  0,\n    # as the loop will always return a k = n.\n    return len(eigenvalues)\n\ndef solve():\n    \"\"\"\n    Defines, runs, and formats the output for all test cases.\n    \"\"\"\n    n = 200\n    \n    # Test case A (exponential spectral energy decay)\n    alpha_A = 0.1\n    i_A = np.arange(n)\n    eig_A = np.exp(-alpha_A * i_A)\n\n    # Test case B (flat spectrum)\n    eig_B = np.ones(n)\n\n    # Test case C (rank-deficient with 50 nonzero components)\n    eig_C = np.zeros(n)\n    eig_C[:50] = 1.0\n\n    # Test case D (spiked spectrum with top 5 dominant components)\n    eig_D = np.full(n, 0.1)\n    eig_D[0] = 500.0\n    eig_D[1] = 400.0\n    eig_D[2] = 300.0\n    eig_D[3] = 200.0\n    eig_D[4] = 100.0\n    \n    # Test case E (exact threshold at k = 95)\n    eig_E = np.zeros(n)\n    eig_E[:100] = 1.0\n\n    # Test case F (unsorted input, same as A but permuted)\n    # Use a fixed seed for reproducibility of the permutation\n    rng = np.random.default_rng(seed=42)\n    eig_F = rng.permutation(eig_A)\n\n    test_cases = [\n        eig_A,\n        eig_B,\n        eig_C,\n        eig_D,\n        eig_E,\n        eig_F,\n    ]\n\n    results = []\n    for case_eigenvalues in test_cases:\n        k = compute_k(case_eigenvalues)\n        results.append(k)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "仅依赖光谱信息的逐像素分类，常常会产生充满噪声的“椒盐”效应图。为了获得更平滑、更真实的分类结果，我们可以引入空间上下文信息，而马尔可夫随机场（MRF）是实现这一目标的经典模型。本练习将通过一个具体的计算，展示如何利用 MRF 的能量最小化框架，特别是 α-扩展算法的一步，来修正初始分类结果，从而体现空间平滑先验的作用。",
            "id": "3852860",
            "problem": "一个多光谱遥感分类器提供了一个跨越植被-裸土过渡区的六个相邻像素一维样带上每个像素的后验类别概率。设两个类别为植被 ($V$) 和裸土 ($B$)。类别平滑度的空间先验被建模为带有 Potts 模型惩罚项的成对马尔可夫随机场 (MRF)。在具有四邻域结构（相邻像素）的链式图上，对于一个标记 $l = (l_{1},\\dots,l_{6})$ 的总体最大后验 (MAP) 能量为\n$$\nE(l) \\;=\\; \\sum_{i=1}^{6} \\Big(-\\ln p_{i}(l_{i})\\Big) \\;+\\; \\lambda \\sum_{(i,j)\\in \\mathcal{N}} \\mathbf{1}\\{l_{i}\\neq l_{j}\\},\n$$\n其中 $p_{i}(c)$ 是像素 $i$ 处类别 $c\\in\\{V,B\\}$ 的后验概率，$\\mathcal{N}$ 包含相邻索引对 $\\{(1,2),(2,3),(3,4),(4,5),(5,6)\\}$，$\\mathbf{1}\\{\\cdot\\}$ 是指示函数，而 $\\lambda$ 是一个非负标量。\n\n给定由光谱分类器产生的以下后验概率：\n- 像素 $1$：$p_{1}(V)=0.65$， $p_{1}(B)=0.35$。\n- 像素 $2$：$p_{2}(V)=0.60$， $p_{2}(B)=0.40$。\n- 像素 $3$：$p_{3}(V)=0.45$， $p_{3}(B)=0.55$。\n- 像素 $4$：$p_{4}(V)=0.40$， $p_{4}(B)=0.60$。\n- 像素 $5$：$p_{5}(V)=0.70$， $p_{5}(B)=0.30$。\n- 像素 $6$：$p_{6}(V)=0.66$， $p_{6}(B)=0.34$。\n\nPotts 模型权重为 $\\lambda=0.40$。初始标记 $l^{(0)}$ 是逐像素分类的结果（即每个像素处 $p_{i}(c)$ 的 argmax）。\n\n从 $l^{(0)}$ 开始，执行一次 $\\alpha=V$（植被）的 $\\alpha$-扩展移动。由于 Potts 项是一个度量，该问题可以通过单次图切割精确求解。计算这次单次 $\\alpha$-扩展移动后标记的能量 $E(l^{(1)})$。使用自然对数 $\\ln$。将最终答案表示为一个无单位的实数，并四舍五入到四位有效数字。",
            "solution": "用户要求我使用 $\\alpha$-扩展算法解决一个马尔可夫随机场 (MRF) 上的最大后验 (MAP) 估计问题。\n\n### 步骤 1：提取已知条件\n-   **类别**：植被 ($V$) 和裸土 ($B$)。\n-   **像素**：一个由 $6$ 个像素组成的一维样带，索引为 $i=1, \\dots, 6$。\n-   **能量函数**：一个标记 $l = (l_1, \\dots, l_6)$ 的最大后验 (MAP) 能量由下式给出\n    $$\n    E(l) \\;=\\; \\sum_{i=1}^{6} \\Big(-\\ln p_{i}(l_{i})\\Big) \\;+\\; \\lambda \\sum_{(i,j)\\in \\mathcal{N}} \\mathbf{1}\\{l_{i}\\neq l_{j}\\},\n    $$\n    其中 $p_i(c)$ 是像素 $i$ 处类别 $c$ 的后验概率，$\\mathcal{N} = \\{(1,2),(2,3),(3,4),(4,5),(5,6)\\}$ 是相邻像素对的集合，$\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n-   **Potts 模型权重**：$\\lambda = 0.40$。\n-   **后验概率**：\n    -   $p_1(V)=0.65$, $p_1(B)=0.35$。\n    -   $p_2(V)=0.60$, $p_2(B)=0.40$。\n    -   $p_3(V)=0.45$, $p_3(B)=0.55$。\n    -   $p_4(V)=0.40$, $p_4(B)=0.60$。\n    -   $p_5(V)=0.70$, $p_5(B)=0.30$。\n    -   $p_6(V)=0.66$, $p_6(B)=0.34$。\n-   **初始条件**：初始标记 $l^{(0)}$ 是逐像素分类，即对每个像素 $i$，有 $l_i^{(0)} = \\arg\\max_{c \\in \\{V, B\\}} p_i(c)$。\n-   **任务**：从 $l^{(0)}$ 开始，执行一次 $\\alpha=V$ 的 $\\alpha$-扩展移动，以获得新的标记 $l^{(1)}$。然后，计算能量 $E(l^{(1)})$ 并将结果四舍五入到四位有效数字。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据。它描述了马尔可夫随机场与 Potts 模型先验在图像分类中的一个标准应用，这在遥感、计算机视觉及相关领域是一项成熟的技术。能量函数是 MAP 估计的常见形式。$\\alpha$-扩展算法是一种标准的、可证明是正确的能量函数最小化方法，适用于平滑项是度量的情况（Potts 模型即是）。该问题是适定的，提供了所有必要的数据和参数。定义清晰明确。问题是客观且可形式化的。\n\n### 步骤 3：结论与行动\n该问题有效。我现在将进行求解。\n\n### 详细解法\n\n解题过程分为四个步骤：\n1.  确定初始标记 $l^{(0)}$。\n2.  为 $\\alpha=V$ 的 $\\alpha$-扩展移动构建能量最小化问题。\n3.  求解最小化问题以找到新的标记 $l^{(1)}$。\n4.  计算最终能量 $E(l^{(1)})$。\n\n**1. 确定初始标记 $l^{(0)}$**\n\n初始标记 $l^{(0)}$ 是通过为每个像素选择具有最高后验概率的类别来获得的。\n\n-   像素 $1$：$p_{1}(V) = 0.65  p_{1}(B)=0.35 \\implies l_{1}^{(0)} = V$。\n-   像素 $2$：$p_{2}(V) = 0.60  p_{2}(B)=0.40 \\implies l_{2}^{(0)} = V$。\n-   像素 $3$：$p_{3}(B) = 0.55  p_{3}(V)=0.45 \\implies l_{3}^{(0)} = B$。\n-   像素 $4$：$p_{4}(B) = 0.60  p_{4}(V)=0.40 \\implies l_{4}^{(0)} = B$。\n-   像素 $5$：$p_{5}(V) = 0.70  p_{5}(B)=0.30 \\implies l_{5}^{(0)} = V$。\n-   像素 $6$：$p_{6}(V) = 0.66  p_{6}(B)=0.34 \\implies l_{6}^{(0)} = V$。\n\n因此，初始标记为 $l^{(0)} = (V, V, B, B, V, V)$。\n\n**2. 构建 $\\alpha$-扩展问题**\n\n我们执行一次 $\\alpha=V$ 的 $\\alpha$-扩展移动。这意味着我们寻求一个新的标记 $l^{(1)}$ 来最小化能量 $E(l)$，其约束条件是：对于每个像素 $i$，其新标记 $l_i^{(1)}$ 要么是其当前标记 $l_i^{(0)}$，要么是扩展标记 $\\alpha=V$。\n\n对于像素 $i \\in \\{1, 2, 5, 6\\}$，初始标记是 $l_i^{(0)} = V$。由于 $\\alpha=V$，唯一可能的新标记是 $V$。因此，它们的标记是固定的：$l_1^{(1)}=V$, $l_2^{(1)}=V$, $l_5^{(1)}=V$, $l_6^{(1)}=V$。\n\n对于像素 $i \\in \\{3, 4\\}$，初始标记是 $l_i^{(0)} = B$。新标记 $l_i^{(1)}$ 可以是 $B$ 或 $V$。我们必须找到像素 $3$ 和 $4$ 的标记组合，以最小化总能量。\n\n对于一个新的标记 $l^{(1)} = (V, V, l_3, l_4, V, V)$，其中 $l_3, l_4 \\in \\{B, V\\}$，总能量为：\n$$\nE(l^{(1)}) = \\sum_{i=1}^{6} \\Big(-\\ln p_{i}(l_i^{(1)})\\Big) + \\lambda \\sum_{(i,j)\\in \\mathcal{N}} \\mathbf{1}\\{l_i^{(1)} \\neq l_j^{(1)}\\}\n$$\n能量可以分解为一个常数部分和一个依赖于 $l_3$ 和 $l_4$ 选择的可变部分。\n我们必须最小化的可变部分是：\n$$\nE_{\\text{sub}}(l_3, l_4) = \\big(-\\ln p_3(l_3)\\big) + \\big(-\\ln p_4(l_4)\\big) + \\lambda \\Big( \\mathbf{1}\\{l_2^{(1)}\\neq l_3\\} + \\mathbf{1}\\{l_3\\neq l_4\\} + \\mathbf{1}\\{l_4\\neq l_5^{(1)}\\} \\Big)\n$$\n代入 $l_2^{(1)}=V$ 和 $l_5^{(1)}=V$，我们得到：\n$$\nE_{\\text{sub}}(l_3, l_4) = -\\ln p_3(l_3) - \\ln p_4(l_4) + \\lambda \\Big( \\mathbf{1}\\{V\\neq l_3\\} + \\mathbf{1}\\{l_3\\neq l_4\\} + \\mathbf{1}\\{l_4\\neq V\\} \\Big)\n$$\n\n**3. 求解最小化问题**\n\n我们对 $(l_3, l_4)$ 的四种可能组合评估 $E_{\\text{sub}}(l_3, l_4)$。我们使用给定的概率和 $\\lambda = 0.40$。数据项为：\n-   $-\\ln p_3(B) = -\\ln(0.55) \\approx 0.5978$\n-   $-\\ln p_3(V) = -\\ln(0.45) \\approx 0.7985$\n-   $-\\ln p_4(B) = -\\ln(0.60) \\approx 0.5108$\n-   $-\\ln p_4(V) = -\\ln(0.40) \\approx 0.9163$\n\n-   **情况 1：** $(l_3, l_4) = (B, B)$\n    $E_{\\text{sub}}(B, B) = -\\ln(0.55) - \\ln(0.60) + 0.40 \\cdot (\\mathbf{1}\\{V\\neq B\\} + \\mathbf{1}\\{B\\neq B\\} + \\mathbf{1}\\{B\\neq V\\})$\n    $E_{\\text{sub}}(B, B) = 0.5978 + 0.5108 + 0.40 \\cdot (1 + 0 + 1) = 1.1086 + 0.8 = 1.9086$\n\n-   **情况 2：** $(l_3, l_4) = (B, V)$\n    $E_{\\text{sub}}(B, V) = -\\ln(0.55) - \\ln(0.40) + 0.40 \\cdot (\\mathbf{1}\\{V\\neq B\\} + \\mathbf{1}\\{B\\neq V\\} + \\mathbf{1}\\{V\\neq V\\})$\n    $E_{\\text{sub}}(B, V) = 0.5978 + 0.9163 + 0.40 \\cdot (1 + 1 + 0) = 1.5141 + 0.8 = 2.3141$\n\n-   **情况 3：** $(l_3, l_4) = (V, B)$\n    $E_{\\text{sub}}(V, B) = -\\ln(0.45) - \\ln(0.60) + 0.40 \\cdot (\\mathbf{1}\\{V\\neq V\\} + \\mathbf{1}\\{V\\neq B\\} + \\mathbf{1}\\{B\\neq V\\})$\n    $E_{\\text{sub}}(V, B) = 0.7985 + 0.5108 + 0.40 \\cdot (0 + 1 + 1) = 1.3093 + 0.8 = 2.1093$\n\n-   **情况 4：** $(l_3, l_4) = (V, V)$\n    $E_{\\text{sub}}(V, V) = -\\ln(0.45) - \\ln(0.40) + 0.40 \\cdot (\\mathbf{1}\\{V\\neq V\\} + \\mathbf{1}\\{V\\neq V\\} + \\mathbf{1}\\{V\\neq V\\})$\n    $E_{\\text{sub}}(V, V) = 0.7985 + 0.9163 + 0.40 \\cdot (0 + 0 + 0) = 1.7148$\n\n比较这四个值，最小能量是 $1.7148$，对应于情况 $(l_3, l_4) = (V, V)$。\n因此，$\\alpha$-扩展移动将像素 $3$ 和 $4$ 的标记更改为 $V$。得到的标记是 $l^{(1)} = (V, V, V, V, V, V)$。\n\n**4. 计算最终能量 $E(l^{(1)})$**\n\n我们现在计算最优标记 $l^{(1)} = (V, V, V, V, V, V)$ 的总能量。\n由于所有标记都相同，平滑项为零，能量得以简化。\n$$\nE(l^{(1)}) = \\sum_{i=1}^{6} \\Big(-\\ln p_{i}(V)\\Big) + \\lambda \\sum_{(i,j)\\in \\mathcal{N}} \\mathbf{1}\\{V\\neq V\\}\n$$\n$$\nE(l^{(1)}) = \\sum_{i=1}^{6} \\Big(-\\ln p_{i}(V)\\Big) + 0\n$$\n$$\nE(l^{(1)}) = \\big(-\\ln p_1(V)\\big) + \\big(-\\ln p_2(V)\\big) + \\big(-\\ln p_3(V)\\big) + \\big(-\\ln p_4(V)\\big) + \\big(-\\ln p_5(V)\\big) + \\big(-\\ln p_6(V)\\big)\n$$\n代入给定的概率：\n$$\nE(l^{(1)}) = \\big(-\\ln(0.65)\\big) + \\big(-\\ln(0.60)\\big) + \\big(-\\ln(0.45)\\big) + \\big(-\\ln(0.40)\\big) + \\big(-\\ln(0.70)\\big) + \\big(-\\ln(0.66)\\big)\n$$\n使用自然对数：\n$$\nE(l^{(1)}) \\approx 0.43078 + 0.51083 + 0.79851 + 0.91629 + 0.35667 + 0.41551\n$$\n$$\nE(l^{(1)}) \\approx 3.42859\n$$\n将结果四舍五入到四位有效数字，我们得到 $3.429$。",
            "answer": "$$\\boxed{3.429}$$"
        },
        {
            "introduction": "分类图制作完成后，必须对其精度进行量化评估，而混淆矩阵是所有精度评估指标的基础。从混淆矩阵中可以派生出总体精度、F1 分数和科恩的卡帕系数（Cohen’s $\\kappa$）等多个指标，它们从不同角度揭示了分类器的性能。本练习旨在通过构建混淆矩阵并计算这些关键指标，让你掌握如何全面分析分类结果的优劣，并理解每个指标背后的统计意义。",
            "id": "3852862",
            "problem": "一个用于多光谱卫星图像的土地覆盖分类器，整合了光谱特征（例如，短波红外、近红外和红光波段的反射率）和空间背景特征（例如，在移动窗口上计算的局部纹理统计量）。该分类器用于绘制四个类别：水体（$W$）、森林（$F$）、城市（$U$）和农业（$A$）。通过在$4$个生态区域进行分层随机抽样，收集了一个包含 $N = 713$ 个像素的独立验证样本，其地面真实情况源自高分辨率航空影像解译。以下汇总结果总结了分类器为每个地面真实类别生成的预测标签，其中计数是具有指定参考标签和预测标签的验证像素数量：\n\n- 地面真实为 $W$：预测为 $W = 140$, $F = 3$, $U = 2$, $A = 5$（行和 $= 150$）。\n- 地面真实为 $F$：预测为 $W = 6$, $F = 180$, $U = 12$, $A = 22$（行和 $= 220$）。\n- 地面真实为 $U$：预测为 $W = 1$, $F = 15$, $U = 110$, $A = 14$（行和 $= 140$）。\n- 地面真实为 $A$：预测为 $W = 2$, $F = 18$, $U = 13$, $A = 170$（行和 $= 203$）。\n\n假设抽样对于测绘区域是设计无偏的，并且验证像素是从潜在的土地覆盖分布中独立抽取的。此外，田野笔记表明，误差在农业河谷（$A$ 和 $F$ 之间的混淆）和城乡结合部混合区域（$U$ 和 $F$ 之间的混淆）表现出空间聚集性，而 $W$ 在光谱上相对独特，但偶尔在海岸线附近会被混淆。\n\n从分类评估中列联表和事件概率的基本定义出发，执行以下操作：\n\n1. 构建类别顺序为 $[W, F, U, A]$ 的 $4 \\times 4$ 混淆矩阵，并计算行和列的边际总数。\n2. 推导并计算总体准确率，即正确分类的比例。\n3. 对于每个类别 $c \\in \\{W, F, U, A\\}$，基于“一对多”的视角定义真阳性、假阳性和假阴性，并使用精确率和召回率的定义推导各类的 F1 分数。\n4. 使用在给定观测边际总数下独立标注的期望一致性定义，推导并计算 Cohen’s $\\kappa$。\n\n简要解释总体准确率、各类别 F1 分数和 Cohen’s $\\kappa$ 如何差异性地反映环境地图中观测到的误差结构和类别流行度，特别是在空间聚集性错分的情况下。\n\n仅报告 Cohen’s $\\kappa$作为最终数值答案。将报告的 $\\kappa$ 四舍五入到四位有效数字，并以小数形式表示。",
            "solution": "问题陈述提供了土地覆盖制图任务的分类结果摘要，并要求使用标准统计指标进行定量评估。该问题具有科学依据、提法明确、客观且内部一致。验证像素总数 $N = 713$ 与提供的地面真实行计数总和（$150 + 220 + 140 + 203 = 713$）相符。尽管有关于空间误差聚集的定性说明，但假设独立抽取的指令允许标准统计指标的应用。因此，该问题是有效的，可以推导出解决方案。\n\n**1. 混淆矩阵和边际总数**\n\n混淆矩阵，记为 $C$，是一个方阵，其中元素 $C_{ij}$ 是已知属于类别 $i$（地面真实）但被预测为类别 $j$ 的观测数量。类别排序为 $[W, F, U, A]$。行代表地面真实标签，列代表预测标签。\n\n使用给定数据构建 $4 \\times 4$ 混淆矩阵：\n$$\nC =\n\\begin{pmatrix}\n140  3  2  5 \\\\\n6  180  12  22 \\\\\n1  15  110  14 \\\\\n2  18  13  170\n\\end{pmatrix}\n$$\n\n行边际总数，代表每个地面真实类别的总像素数，如下所示：\n- $N_{W, \\text{true}} = 140 + 3 + 2 + 5 = 150$\n- $N_{F, \\text{true}} = 6 + 180 + 12 + 22 = 220$\n- $N_{U, \\text{true}} = 1 + 15 + 110 + 14 = 140$\n- $N_{A, \\text{true}} = 2 + 18 + 13 + 170 = 203$\n样本总数为 $N = \\sum_{i} N_{i, \\text{true}} = 150 + 220 + 140 + 203 = 713$。\n\n列边际总数，代表每个类别被预测的总像素数，通过对 $C$ 的列求和计算得出：\n- $N_{W, \\text{pred}} = 140 + 6 + 1 + 2 = 149$\n- $N_{F, \\text{pred}} = 3 + 180 + 15 + 18 = 216$\n- $N_{U, \\text{pred}} = 2 + 12 + 110 + 13 = 137$\n- $N_{A, \\text{pred}} = 5 + 22 + 14 + 170 = 211$\n列边际总数的和也等于样本总数：$149 + 216 + 137 + 211 = 713$。\n\n**2. 总体准确率**\n\n总体准确率（$OA$）是正确分类的验证像素的比例。它通过将正确分类的数量（混淆矩阵的对角线元素）相加，然后除以总像素数 $N$ 来推导。\n$$\nOA = \\frac{\\sum_{i=1}^{k} C_{ii}}{N}\n$$\n其中 $k=4$ 是类别数量。\n正确分类的像素数是 $C$ 的对角线元素之和：\n$$\n\\sum_{i=1}^{4} C_{ii} = 140 + 180 + 110 + 170 = 600\n$$\n因此，总体准确率为：\n$$\nOA = \\frac{600}{713} \\approx 0.8415\n$$\n\n**3. 各类别的 F1 分数**\n\n对于每个类别 $i$，我们采用“一对多”的视角来定义真阳性（$TP_i$）、假阳性（$FP_i$）和假阴性（$FN_i$）。\n- $TP_i$：类别 $i$ 的像素被正确分类为类别 $i$。$TP_i = C_{ii}$。\n- $FP_i$：其他类别的像素被错误分类为类别 $i$。$FP_i = (\\sum_{j=1}^{k} C_{ji}) - C_{ii} = N_{i, \\text{pred}} - C_{ii}$。\n- $FN_i$：类别 $i$ 的像素被错误分类为其他类别。$FN_i = (\\sum_{j=1}^{k} C_{ij}) - C_{ii} = N_{i, \\text{true}} - C_{ii}$。\n\n由此，我们推导出精确率（$P_i$）和召回率（$R_i$）：\n- 精确率（$P_i$）：一个被预测为类别 $i$ 的像素实际上是类别 $i$ 的概率。$P_i = \\frac{TP_i}{TP_i + FP_i} = \\frac{C_{ii}}{N_{i, \\text{pred}}}$。\n- 召回率（$R_i$）：一个类别 $i$ 的像素被正确识别的概率。$R_i = \\frac{TP_i}{TP_i + FN_i} = \\frac{C_{ii}}{N_{i, \\text{true}}}$。\n\nF1 分数是精确率和召回率的调和平均数，提供了一个平衡两者的单一指标：\n$$\nF1_i = 2 \\cdot \\frac{P_i \\cdot R_i}{P_i + R_i}\n$$\n每个类别的计算如下：\n- **水体 (W)**: $TP_W=140, FP_W=9, FN_W=10$。\n  $P_W = \\frac{140}{149}$, $R_W = \\frac{140}{150}$。\n  $F1_W = 2 \\cdot \\frac{\\frac{140}{149} \\cdot \\frac{140}{150}}{\\frac{140}{149} + \\frac{140}{150}} \\approx 0.9364$\n- **森林 (F)**: $TP_F=180, FP_F=36, FN_F=40$。\n  $P_F = \\frac{180}{216}$, $R_F = \\frac{180}{220}$。\n  $F1_F = 2 \\cdot \\frac{\\frac{180}{216} \\cdot \\frac{180}{220}}{\\frac{180}{216} + \\frac{180}{220}} \\approx 0.8257$\n- **城市 (U)**: $TP_U=110, FP_U=27, FN_U=30$。\n  $P_U = \\frac{110}{137}$, $R_U = \\frac{110}{140}$。\n  $F1_U = 2 \\cdot \\frac{\\frac{110}{137} \\cdot \\frac{110}{140}}{\\frac{110}{137} + \\frac{110}{140}} \\approx 0.7942$\n- **农业 (A)**: $TP_A=170, FP_A=41, FN_A=33$。\n  $P_A = \\frac{170}{211}$, $R_A = \\frac{170}{203}$。\n  $F1_A = 2 \\cdot \\frac{\\frac{170}{211} \\cdot \\frac{170}{203}}{\\frac{170}{211} + \\frac{170}{203}} \\approx 0.8212$\n\n**4. Cohen’s Kappa 系数（$\\kappa$）**\n\nCohen's $\\kappa$ 衡量预测标签与真实标签之间的一致性，并对偶然预期的一致性进行了校正。其定义为：\n$$\n\\kappa = \\frac{p_o - p_e}{1 - p_e}\n$$\n这里，$p_o$ 是观测到的一致性概率，也就是总体准确率：\n$$\np_o = OA = \\frac{600}{713}\n$$\n$p_e$ 是偶然一致性的假设概率。它是根据行和列的边际总数计算的。对于每个类别 $i$，一个随机像素属于类别 $i$ 的概率是 $\\frac{N_{i, \\text{true}}}{N}$，一个随机像素被分类为类别 $i$ 的概率是 $\\frac{N_{i, \\text{pred}}}{N}$。这两者偶然达成一致的概率是它们的乘积。对所有类别求和得到 $p_e$：\n$$\np_e = \\sum_{i=1}^{k} \\frac{N_{i, \\text{true}}}{N} \\cdot \\frac{N_{i, \\text{pred}}}{N} = \\frac{1}{N^2} \\sum_{i=1}^{k} (N_{i, \\text{true}} \\cdot N_{i, \\text{pred}})\n$$\n使用之前计算的边际总数（$N=713$）：\n$N_{W, \\text{true}} = 150, N_{F, \\text{true}} = 220, N_{U, \\text{true}} = 140, N_{A, \\text{true}} = 203$。\n$N_{W, \\text{pred}} = 149, N_{F, \\text{pred}} = 216, N_{U, \\text{pred}} = 137, N_{A, \\text{pred}} = 211$。\n\n边际总数乘积的和为：\n$$\n\\sum (\\text{marginals}) = (150 \\times 149) + (220 \\times 216) + (140 \\times 137) + (203 \\times 211)\n$$\n$$\n\\sum (\\text{marginals}) = 22350 + 47520 + 19180 + 42833 = 131883\n$$\n现在，我们计算 $p_e$：\n$$\np_e = \\frac{131883}{713^2} = \\frac{131883}{508369}\n$$\n现在我们可以使用 $p_o$ 和 $p_e$ 的小数形式来精确计算 $\\kappa$：\n$$\np_o \\approx 0.84151473 \\quad \\text{and} \\quad p_e \\approx 0.25942475\n$$\n$$\n\\kappa = \\frac{p_o - p_e}{1 - p_e} = \\frac{0.84151473 - 0.25942475}{1 - 0.25942475} = \\frac{0.58208998}{0.74057525} \\approx 0.785994\n$$\n四舍五入到四位有效数字，Cohen's $\\kappa$ 为 $0.7860$。\n\n**解读**\n\n- **总体准确率（$OA \\approx 0.84$）**：该指标表明分类器性能较高，约有 $84\\%$ 的地景被正确绘制。然而，$OA$ 会受到类别流行度的影响，并且不能揭示误差的性质。\n- **F1 分数**：这些针对特定类别的分数揭示了性能差异。水体的高 F1 分数（$F1_W \\approx 0.94$）证实了其光谱上独特的田野笔记。森林（$F1_F \\approx 0.83$）、城市（$F1_U \\approx 0.79$）和农业（$F1_A \\approx 0.82$）的较低分数凸显了分类的挑战。这些较低的分数是这些类别之间较高混淆率的直接结果，这证实了关于农业河谷（$A-F$）和城乡结合部（$U-F$）误差的田野笔记。混淆矩阵显示了从 $F \\rightarrow A$（$22$）、$A \\rightarrow F$（$18$）、$U \\rightarrow F$（$15$）和 $F \\rightarrow U$（$12$）的显著误差计数。\n- **Cohen’s $\\kappa$（$\\kappa \\approx 0.786$）**：这个值代表了“实质性”或“优秀”的一致性水平。它通过考虑在给定观测到的类别频率（边际总数）下纯粹由偶然性预期的一致性，从而改进了 $OA$。在这种情况下，由于类别相对均衡，$\\kappa$ 值与 $OA$ 没有巨大差异，但它仍然是分类器技能的一个更稳健的指标。关于*空间聚集性*错分的笔记意味着验证样本并非真正独立，这违反了对 $\\kappa$ 进行标准显著性检验的核心假设。尽管在问题明确的独立性假设下，$\\kappa$ 的计算本身在算术上是正确的，但严谨的分析将需要空间统计学来解释这种自相关，这可能导致该指标的置信区间更宽。本质上，$\\kappa$ 量化了超出偶然性的技能，而 F1 分数则诊断了技能在哪些方面有所欠缺，定性的田野笔记表明这些缺陷呈现出空间模式而非随机模式。",
            "answer": "$$\\boxed{0.7860}$$"
        }
    ]
}