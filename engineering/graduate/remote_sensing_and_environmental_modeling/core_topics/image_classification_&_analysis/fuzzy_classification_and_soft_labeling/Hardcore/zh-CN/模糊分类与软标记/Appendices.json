{
    "hands_on_practices": [
        {
            "introduction": "在遥感影像中，单个像素往往不是由单一地物类型构成，而是多种类型的混合体。软标签通过一个概率分布来表示这种混合成分，而我们可以运用信息论中的香农熵来量化这种分类的不确定性。这项实践将熵这一抽象概念与具体的遥感场景相结合，为你提供一个分析分类不确定性的基本工具 。",
            "id": "3814939",
            "problem": "一个沿海湿地场景中的多光谱像素被建模为 $K=3$ 种地表覆盖类别（开阔水域、挺水植被和裸露沉积物）的凸混合。一个监督概率分类器对此像素输出一个软标签向量 $p=(p_{1},p_{2},p_{3})=(0.2,0.5,0.3)$，代表其后验类别隶属概率。在遥感的模糊分类中，一个有效的软标签必须位于概率单纯形内，即每个分量都为非负数，且各分量之和为 $1$。首先，请仅使用有限样本空间上概率测度的核心定义，评估给定的 $p$ 是否满足此归一化性质。\n\n为了量化环境建模中的分类不确定性，采用由 Shannon–Khinchin 公理（连续性、在均匀分布处取最大值、可扩展性和可加性）表征的不确定性泛函。使用自然对数，以奈特（nats）为单位度量不确定性，计算此像素软标签 $p$ 的不确定性。将最终数值结果四舍五入至四位有效数字，并以奈特（nats）为单位表示答案。仅提供数值作为最终答案。",
            "solution": "首先对问题陈述进行严格的验证过程。\n\n给定的条件如下：\n- 一个具有 $K=3$ 个不同地表覆盖类别的系统。\n- 代表后验类别隶属概率的软标签向量：$p=(p_{1},p_{2},p_{3})=(0.2,0.5,0.3)$。\n- 有效软标签的定义：它必须位于概率单纯形内，即对所有 $i$ 都有 $p_i \\ge 0$ 且 $\\sum_i p_i = 1$。\n- 第一个任务是根据概率测度的核心定义，评估给定的向量 $p$ 是否满足此性质。\n- 第二个任务是使用由 Shannon–Khinchin 公理定义的泛函计算分类不确定性。\n- 不确定性以奈特（nats）为单位度量，这意味着使用自然对数。\n- 最终数值结果必须四舍五入至四位有效数字。\n\n该问题具有科学依据，是适定的且客观的。它基于概率论（概率单纯形）和信息论（香农熵，其由 Shannon-Khinchin 公理唯一确定）的既定原则。遥感中的模糊分类是一个标准且现实的应用领域。所提供的数据是完整、一致且足以得出唯一解的。该问题未违反任何指定的无效标准。因此，该问题被认为是有效的，有必要给出完整解答。\n\n根据要求，解答过程分为两部分。\n\n首先，我们验证给定的软标签向量 $p=(0.2, 0.5, 0.3)$。问题要求此验证基于有限样本空间上概率测度的核心定义。设互斥且穷尽的类别集合为 $\\Omega = \\{C_1, C_2, C_3\\}$。分配给每个类别的后验概率为 $p_i = P(C_i)$，其中 $P$ 是一个概率测度。对于有限样本空间，Kolmogorov 概率公理要求：\n1.  非负性：任何事件的概率都是非负的。对于基本事件 $C_i$，这转化为对所有 $i \\in \\{1, 2, 3\\}$ 都有 $p_i \\ge 0$。\n2.  归一化：整个样本空间的概率为 $1$。由于这些类别是穷尽的，这意味着 $P(\\Omega) = P(C_1 \\cup C_2 \\cup C_3) = P(C_1) + P(C_2) + P(C_3) = \\sum_{i=1}^{3} p_i = 1$。\n\n我们对给定的向量 $p$ 检查这两个条件：\n1.  非负性：向量的分量为 $p_1 = 0.2$、$p_2 = 0.5$ 和 $p_3 = 0.3$。这三个值都大于或等于 $0$。此条件满足。\n2.  归一化：分量之和计算如下：\n$$ \\sum_{i=1}^{3} p_i = p_1 + p_2 + p_3 = 0.2 + 0.5 + 0.3 = 1.0 $$\n此条件也满足。\n由于两个公理化要求都已满足，向量 $p$ 是一个有效的概率分布，并且位于 $K=3$ 的概率单纯形内。\n\n其次，我们计算分类不确定性。问题指定使用由 Shannon–Khinchin 公理表征的不确定性泛函。对于离散概率分布 $p = (p_1, p_2, \\dots, p_K)$，此泛函为香农熵 $H(p)$，定义为：\n$$ H(p) = - \\sum_{i=1}^{K} p_i \\log_b(p_i) $$\n其中 $b$ 是对数的底。单位“奈特（nats）”表示必须使用自然对数（底为 $e$）。因此，公式变为：\n$$ H(p) = - \\sum_{i=1}^{K} p_i \\ln(p_i) $$\n如果任何 $p_i$ 为 $0$，则应用 $0 \\ln(0) = 0$ 的约定。\n\n对于给定的概率分布 $p=(0.2, 0.5, 0.3)$ 和 $K=3$，不确定性 $H(p)$ 为：\n$$ H(p) = - \\left( p_1 \\ln(p_1) + p_2 \\ln(p_2) + p_3 \\ln(p_3) \\right) $$\n代入数值：\n$$ H(p) = - \\left( 0.2 \\ln(0.2) + 0.5 \\ln(0.5) + 0.3 \\ln(0.3) \\right) $$\n我们计算自然对数的值：\n$\\ln(0.2) \\approx -1.6094379$\n$\\ln(0.5) \\approx -0.6931472$\n$\\ln(0.3) \\approx -1.2039728$\n\n现在，我们计算和中的每一项：\n$0.2 \\ln(0.2) \\approx 0.2 \\times (-1.6094379) \\approx -0.32188758$\n$0.5 \\ln(0.5) \\approx 0.5 \\times (-0.6931472) \\approx -0.34657360$\n$0.3 \\ln(0.3) \\approx 0.3 \\times (-1.2039728) \\approx -0.36119184$\n\n将这些项相加：\n$$ \\sum_{i=1}^{3} p_i \\ln(p_i) \\approx -0.32188758 - 0.34657360 - 0.36119184 \\approx -1.02965302 $$\n不确定性是此和的负值：\n$$ H(p) \\approx -(-1.02965302) \\approx 1.02965302 \\text{ nats} $$\n问题要求将结果四舍五入到四位有效数字。前四位有效数字是 $1$、$0$、$2$ 和 $9$。第五位有效数字是 $6$，大于或等于 $5$，因此我们将最后一位有效数字向上舍入。因此，$1.02965...$ 四舍五入为 $1.030$。",
            "answer": "$$\\boxed{1.030}$$"
        },
        {
            "introduction": "为了理解更大区域（或“图幅”）的特征，我们常常需要汇总像素级别的信息。贝叶斯推断，特别是狄利克雷-多项式共轭模型，为我们提供了一个严谨的框架，能够结合先验知识与新的观测数据来更新我们对区域地物构成的认知。本练习将向你展示如何为一个地理单元生成统计上稳健的软标签，这是许多环境建模工作流中的关键一步 。",
            "id": "3814923",
            "problem": "一个用于遥感和环境建模的土地覆盖分类工作流，将边长为 $30$ 米的正方形地块内的像素级类别分配，聚合成针对三个土地覆盖类别的地块级软标签。设该地块的未知类别比例向量为 $p=(p_{1},p_{2},p_{3})$，位于 $3$-单纯形上，其狄利克雷先验为 $\\mathrm{Dirichlet}(\\alpha)$，用于捕捉历史上的类别混合情况，其中 $\\alpha=(2,2,2)$。在该地块内，一个大小为 $N$ 的独立像素样本在给定 $p$ 的条件下被建模为一次多项分布抽样，得到的三个类别的观测计数为 $\\mathbf{n}=(n_{1},n_{2},n_{3})=(10,5,3)$。在共轭狄利克雷-多项分布模型下，使用贝叶斯更新方法推导 $p$ 的后验分布，然后计算该地块的后验均值软标签 $\\hat{p}$。\n\n以单行矩阵的形式提供最终答案，该矩阵按顺序包含三个后验狄利克雷参数，以及后验均值软标签的三个分量，即：\n$$\n\\begin{pmatrix}\n\\alpha_{1}^{\\text{post}}  \\alpha_{2}^{\\text{post}}  \\alpha_{3}^{\\text{post}}  \\hat{p}_{1}  \\hat{p}_{2}  \\hat{p}_{3}\n\\end{pmatrix}.\n$$\n将后验均值软标签的分量表示为精确的有理数，不要进行四舍五入。无需单位。",
            "solution": "用户提供了一个在遥感和土地覆盖分类背景下的贝叶斯推断问题。\n\n### 步骤1：提取已知条件\n- **问题领域：** 土地覆盖分类、遥感、环境建模。\n- **空间单元：** 一个边长为 $30$ 米的正方形地块。\n- **类别数量：** $K=3$。\n- **模型参数：** 地块的类别比例向量为 $p = (p_1, p_2, p_3)$，受限于 $3$-单纯形（即对于 $i=1,2,3$，$p_i \\ge 0$ 且 $\\sum_{i=1}^3 p_i = 1$）。\n- **先验分布：** 参数 $p$ 的先验分布是狄利克雷分布，$p \\sim \\mathrm{Dirichlet}(\\alpha)$。\n- **先验超参数：** 先验超参数向量为 $\\alpha = (\\alpha_1, \\alpha_2, \\alpha_3) = (2, 2, 2)$。\n- **数据模型（似然）：** 一个大小为 $N$ 的像素样本被建模为参数为 $p$ 的多项分布抽样。观测计数为 $\\mathbf{n} = (n_1, n_2, n_3)$。\n- **观测数据：** 给定的计数为 $\\mathbf{n} = (10, 5, 3)$。\n- **任务：**\n    1. 推导 $p$ 的后验分布。\n    2. 计算后验均值软标签 $\\hat{p} = E[p | \\mathbf{n}]$。\n- **输出格式：** 一个单行矩阵，包含后验狄利克雷参数 $(\\alpha_1^{\\text{post}}, \\alpha_2^{\\text{post}}, \\alpha_3^{\\text{post}})$，以及后验均值软标签的分量 $(\\hat{p}_1, \\hat{p}_2, \\hat{p}_3)$。$\\hat{p}$ 的分量必须是精确的有理数。\n\n### 步骤2：使用提取的已知条件进行验证\n1.  **科学依据：** 该问题坚实地建立在贝叶斯统计学的基础上。狄利克雷-多项分布模型是推断比例的经典共轭模型。它在土地覆盖分类中应用于软标签是一种在遥感和空间统计学中标准且科学上合理的实践。$30$ 米的地块大小是常见卫星影像（例如 Landsat）的特征，这使得背景非常现实。\n2.  **良态性：** 该问题是良态的。给定狄利克雷先验和多项分布数据，其后验分布已知为狄利克雷分布，其参数可以直接计算。后验均值是狄利克雷分布的一个明确定义的性质。存在唯一解，并且可以通过解析方法推导出来。\n3.  **客观性：** 该问题使用精确、客观的数学语言陈述。所有术语在统计学和机器学习中都是标准的。没有歧义或主观性。\n4.  **完整性：** 该问题是自包含且完整的。它提供了先验分布、其参数、似然模型以及观测数据，这些都是执行贝叶斯更新所需的所有必要组件。\n5.  **一致性：** 所提供的数据和模型在内部是一致的。类别数量与先验参数向量和数据向量的维度相匹配。\n\n### 步骤3：结论与行动\n该问题是有效的。它是使用共轭先验-似然对进行贝叶斯推断的标准应用。该问题定义明确、科学上合理，并提供了所有必要的信息。我现在将开始求解。\n\n### 解题推导\n该问题要求对土地覆盖地块的类别比例向量 $p$ 执行贝叶斯更新。其框架是共轭狄利克雷-多项分布模型。\n\n比例向量 $p = (p_1, p_2, p_3)$ 的先验分布给定为狄利克雷分布，由 $\\alpha = (\\alpha_1, \\alpha_2, \\alpha_3)$ 参数化：\n$$ p \\sim \\mathrm{Dirichlet}(\\alpha) $$\n先验的概率密度函数 (PDF) 是：\n$$ f(p | \\alpha) = \\frac{\\Gamma(\\sum_{i=1}^3 \\alpha_i)}{\\prod_{i=1}^3 \\Gamma(\\alpha_i)} \\prod_{i=1}^3 p_i^{\\alpha_i - 1} $$\n对于我们的问题，$\\alpha = (2, 2, 2)$，所以先验概率密度函数正比于：\n$$ f(p | \\alpha) \\propto p_1^{2-1} p_2^{2-1} p_3^{2-1} = p_1^{1} p_2^{1} p_3^{1} $$\n\n数据由像素计数 $\\mathbf{n} = (n_1, n_2, n_3) = (10, 5, 3)$ 组成。采样的像素总数为 $N = n_1 + n_2 + n_3 = 10 + 5 + 3 = 18$。在给定比例向量 $p$ 的情况下观测到此数据的似然由多项分布描述：\n$$ L(\\mathbf{n} | p) = P(\\mathbf{n} | p, N) = \\frac{N!}{n_1! n_2! n_3!} p_1^{n_1} p_2^{n_2} p_3^{n_3} $$\n作为 $p$ 的函数，似然正比于：\n$$ L(\\mathbf{n} | p) \\propto p_1^{n_1} p_2^{n_2} p_3^{n_3} = p_1^{10} p_2^{5} p_3^{3} $$\n\n根据贝叶斯定理，$p$ 的后验分布正比于先验和似然的乘积：\n$$ f(p | \\mathbf{n}, \\alpha) \\propto L(\\mathbf{n} | p) f(p | \\alpha) $$\n$$ f(p | \\mathbf{n}, \\alpha) \\propto \\left( \\prod_{i=1}^3 p_i^{n_i} \\right) \\left( \\prod_{i=1}^3 p_i^{\\alpha_i - 1} \\right) $$\n$$ f(p | \\mathbf{n}, \\alpha) \\propto \\prod_{i=1}^3 p_i^{n_i + \\alpha_i - 1} $$\n这个得到的函数形式是狄利克雷分布的核。因此，后验分布也是狄利克雷分布，这一性质称为共轭性。后验分布是：\n$$ p | \\mathbf{n} \\sim \\mathrm{Dirichlet}(\\alpha^{\\text{post}}) $$\n其中后验超参数 $\\alpha^{\\text{post}}$ 是通过将观测计数加到先验超参数上得到的：\n$$ \\alpha^{\\text{post}} = \\alpha + \\mathbf{n} = (\\alpha_1 + n_1, \\alpha_2 + n_2, \\alpha_3 + n_3) $$\n\n我们现在可以计算后验参数的具体值：\n$$ \\alpha_1^{\\text{post}} = \\alpha_1 + n_1 = 2 + 10 = 12 $$\n$$ \\alpha_2^{\\text{post}} = \\alpha_2 + n_2 = 2 + 5 = 7 $$\n$$ \\alpha_3^{\\text{post}} = \\alpha_3 + n_3 = 2 + 3 = 5 $$\n因此，后验分布为 $p | \\mathbf{n} \\sim \\mathrm{Dirichlet}(12, 7, 5)$。这些是最终答案的前三个值。\n\n接下来，我们必须计算后验均值软标签 $\\hat{p}$。这是 $p$ 的后验分布的期望值。对于一般的狄利克雷分布 $p \\sim \\mathrm{Dirichlet}(\\beta)$，第 $i$ 个分量的期望值由下式给出：\n$$ E[p_i] = \\frac{\\beta_i}{\\sum_{j=1}^K \\beta_j} $$\n在我们的例子中，参数是后验参数 $\\beta = \\alpha^{\\text{post}}$。令 $\\alpha_0^{\\text{post}}$ 为后验参数之和：\n$$ \\alpha_0^{\\text{post}} = \\sum_{i=1}^3 \\alpha_i^{\\text{post}} = 12 + 7 + 5 = 24 $$\n后验均值向量 $\\hat{p} = (\\hat{p}_1, \\hat{p}_2, \\hat{p}_3)$ 的分量是：\n$$ \\hat{p}_1 = E[p_1 | \\mathbf{n}] = \\frac{\\alpha_1^{\\text{post}}}{\\alpha_0^{\\text{post}}} = \\frac{12}{24} = \\frac{1}{2} $$\n$$ \\hat{p}_2 = E[p_2 | \\mathbf{n}] = \\frac{\\alpha_2^{\\text{post}}}{\\alpha_0^{\\text{post}}} = \\frac{7}{24} $$\n$$ \\hat{p}_3 = E[p_3 | \\mathbf{n}] = \\frac{\\alpha_3^{\\text{post}}}{\\alpha_0^{\\text{post}}} = \\frac{5}{24} $$\n这些是最终答案的后三个值。它们按照要求表示为精确的有理数。\n\n最终答案是结合了后验参数和后验均值分量的行矩阵：\n$$ \\begin{pmatrix} \\alpha_{1}^{\\text{post}}  \\alpha_{2}^{\\text{post}}  \\alpha_{3}^{\\text{post}}  \\hat{p}_{1}  \\hat{p}_{2}  \\hat{p}_{3} \\end{pmatrix} = \\begin{pmatrix} 12  7  5  \\frac{1}{2}  \\frac{7}{24}  \\frac{5}{24} \\end{pmatrix} $$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n12  7  5  \\frac{1}{2}  \\frac{7}{24}  \\frac{5}{24}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "地物覆盖类型通常具有层级结构（例如，“森林”是“植被”的一个子类），一个优秀的分类模型应当尊重这种结构关系。我们可以通过设计一个自定义的损失函数，来惩罚那些违反层级规则的预测，从而将领域的语义结构“教给”模型。这项高级实践将模糊集理论与现代深度学习相结合，展示了如何通过将先验知识直接编码到训练过程中，来构建更智能、更符合物理现实的模型 。",
            "id": "3814912",
            "problem": "考虑一颗卫星图像中的多光谱像素，该图像用于在分层分类体系内进行土地覆盖制图。该像素的类别隶属度被建模为模糊软标签，这与遥感中常见的混合效应一致，即单个像素可能部分属于多个类别。设该分类体系为一棵树，有一个父类 $\\text{Vegetation}$，和两个子类 $\\text{Forest}$ 和 $\\text{Grassland}$。用向量 $y = (y_{\\text{veg}}, y_{\\text{for}}, y_{\\text{gra}}) \\in [0,1]^3$ 表示模型预测的软隶属度，其中 $y_{\\text{veg}}$ 是对 $\\text{Vegetation}$ 的隶属度，$y_{\\text{for}}$ 是对 $\\text{Forest}$ 的隶属度，$y_{\\text{gra}}$ 是对 $\\text{Grassland}$ 的隶属度。假设预测结果来自一个卷积神经网络（CNN），该网络使用从专家标注的亚像素组分中提取的软标签进行训练。\n\n分层模糊集的基本约束要求 $\\text{child} \\leq \\text{parent}$ 的单调性，并且在假设同级类别是其父类下互斥的子类型、覆盖不相交组分的情况下，要求 $\\text{sum of siblings} \\leq \\text{parent}$。从这些原则出发，构建一个结构化损失函数，用于惩罚违反这些分层约束的行为。该惩罚函数应为凸函数，且仅在约束被违反时激活。推导该结构化损失函数相对于软输出 $y$ 的梯度。\n\n然后，对于具体数值案例 $y = (0.55, 0.60, 0.10)$，边惩罚权重 $\\lambda_{\\text{edge}} = 1.2$ 和和惩罚权重 $\\lambda_{\\text{sum}} = 2.5$，计算结构化损失函数相对于 $(y_{\\text{veg}}, y_{\\text{for}}, y_{\\text{gra}})$ 的梯度。\n\n讨论在遥感领域的类别分类体系下进行训练时，这种结构化惩罚如何与基础分类损失相互作用，包括对稳定性、收敛性以及软标签影响的考量。\n\n将计算出的梯度四舍五入到四位有效数字。将最终的梯度向量表示为行矩阵，并且在最终报告的答案中不要包含单位。",
            "solution": "该问题要求构建一个结构化损失函数以在模糊分类设置中强制执行分层一致性，推导其梯度，进行该梯度的具体数值计算，并讨论其影响。\n\n该问题经核实具有科学依据，问题设定良好、客观且一致。它描述了机器学习在遥感应用中的一种标准且重要的技术。\n\n### 第一部分：结构化损失的构建\n\n分层分类体系包含一个父类 Vegetation (veg) 和两个子类 Forest (for) 和 Grassland (gra)。预测的软隶属度由向量 $y = (y_{\\text{veg}}, y_{\\text{for}}, y_{\\text{gra}})$ 给出。\n\n需要强制执行的约束是：\n1.  **子-父单调性**：子类的隶属度不能超过其父类的隶属度。\n    - $y_{\\text{for}} \\leq y_{\\text{veg}}$\n    - $y_{\\text{gra}} \\leq y_{\\text{veg}}$\n2.  **同级和约束**：假设子类代表互斥的子类型，则其隶属度之和不能超过父类的隶属度。\n    - $y_{\\text{for}} + y_{\\text{gra}} \\leq y_{\\text{veg}}$\n\n我们需要构建一个损失函数 $L_{struct}$，用于惩罚违反这些约束的行为。该惩罚必须是凸的，并且仅在约束被违反时激活。一个合适的选择是平方合页损失（squared hinge loss），它既是凸的又是连续可微的。对于一个约束 $g(y) \\leq 0$，平方合页损失的一般形式是 $\\max(0, g(y))^2$。\n\n违规情况可以表示为：\n- $y_{\\text{for}} - y_{\\text{veg}} > 0$\n- $y_{\\text{gra}} - y_{\\text{veg}} > 0$\n- $y_{\\text{for}} + y_{\\text{gra}} - y_{\\text{veg}} > 0$\n\n问题指定了独立的惩罚权重，$\\lambda_{\\text{edge}}$ 用于子-父（边）约束，$\\lambda_{\\text{sum}}$ 用于同级和约束。这意味着我们应该分别惩罚每种类型的违规行为。\n\n结构化损失 $L_{struct}$ 被构建为对每个约束违规的惩罚的加权和：\n$$\nL_{struct}(y) = \\lambda_{\\text{edge}} \\left[ \\max(0, y_{\\text{for}} - y_{\\text{veg}})^2 + \\max(0, y_{\\text{gra}} - y_{\\text{veg}})^2 \\right] + \\lambda_{\\text{sum}} \\max(0, y_{\\text{for}} + y_{\\text{gra}} - y_{\\text{veg}})^2\n$$\n如果所有约束都得到满足，该损失函数为零，并且随着任何违规的幅度呈二次方增长，从而满足了问题的要求。\n\n### 第二部分：梯度的推导\n\n为了推导 $L_{struct}$ 相对于输出向量 $y = (y_{\\text{veg}}, y_{\\text{for}}, y_{\\text{gra}})$ 的梯度，我们需要计算偏导数 $\\frac{\\partial L_{struct}}{\\partial y_{\\text{veg}}}$、$\\frac{\\partial L_{struct}}{\\partial y_{\\text{for}}}$ 和 $\\frac{\\partial L_{struct}}{\\partial y_{\\text{gra}}}$。\n\n我们使用链式法则。$\\max(0, z)^2$ 相对于 $z$ 的导数是 $2 \\cdot \\max(0, z)$。\n\n**关于 $y_{\\text{veg}}$ 的偏导数：**\n$y_{\\text{veg}}$ 出现在所有三个惩罚项中，系数均为 $-1$。\n$$\n\\frac{\\partial L_{struct}}{\\partial y_{\\text{veg}}} = \\lambda_{\\text{edge}} \\left[ 2\\max(0, y_{\\text{for}} - y_{\\text{veg}}) \\cdot (-1) + 2\\max(0, y_{\\text{gra}} - y_{\\text{veg}}) \\cdot (-1) \\right] + \\lambda_{\\text{sum}} \\left[ 2\\max(0, y_{\\text{for}} + y_{\\text{gra}} - y_{\\text{veg}}) \\cdot (-1) \\right]\n$$\n$$\n\\frac{\\partial L_{struct}}{\\partial y_{\\text{veg}}} = -2\\lambda_{\\text{edge}} \\left[ \\max(0, y_{\\text{for}} - y_{\\text{veg}}) + \\max(0, y_{\\text{gra}} - y_{\\text{veg}}) \\right] - 2\\lambda_{\\text{sum}} \\max(0, y_{\\text{for}} + y_{\\text{gra}} - y_{\\text{veg}})\n$$\n\n**关于 $y_{\\text{for}}$ 的偏导数：**\n$y_{\\text{for}}$ 出现在第一个边约束项和和约束项中，系数均为 $+1$。\n$$\n\\frac{\\partial L_{struct}}{\\partial y_{\\text{for}}} = 2\\lambda_{\\text{edge}} \\left[ 2\\max(0, y_{\\text{for}} - y_{\\text{veg}}) \\cdot (1) \\right] + \\lambda_{\\text{sum}} \\left[ 2\\max(0, y_{\\text{for}} + y_{\\text{gra}} - y_{\\text{veg}}) \\cdot (1) \\right]\n$$\n$$\n\\frac{\\partial L_{struct}}{\\partial y_{\\text{for}}} = 2\\lambda_{\\text{edge}} \\max(0, y_{\\text{for}} - y_{\\text{veg}}) + 2\\lambda_{\\text{sum}} \\max(0, y_{\\text{for}} + y_{\\text{gra}} - y_{\\text{veg}})\n$$\n\n**关于 $y_{\\text{gra}}$ 的偏导数：**\n$y_{\\text{gra}}$ 出现在第二个边约束项和和约束项中，系数均为 $+1$。\n$$\n\\frac{\\partial L_{struct}}{\\partial y_{\\text{gra}}} = \\lambda_{\\text{edge}} \\left[ 2\\max(0, y_{\\text{gra}} - y_{\\text{veg}}) \\cdot (1) \\right] + \\lambda_{\\text{sum}} \\left[ 2\\max(0, y_{\\text{for}} + y_{\\text{gra}} - y_{\\text{veg}}) \\cdot (1) \\right]\n$$\n$$\n\\frac{\\partial L_{struct}}{\\partial y_{\\text{gra}}} = 2\\lambda_{\\text{edge}} \\max(0, y_{\\text{gra}} - y_{\\text{veg}}) + 2\\lambda_{\\text{sum}} \\max(0, y_{\\text{for}} + y_{\\text{gra}} - y_{\\text{veg}})\n$$\n\n梯度向量为 $\\nabla_y L_{struct} = \\left( \\frac{\\partial L_{struct}}{\\partial y_{\\text{veg}}}, \\frac{\\partial L_{struct}}{\\partial y_{\\text{for}}}, \\frac{\\partial L_{struct}}{\\partial y_{\\text{gra}}} \\right)$。\n\n### 第三部分：梯度的数值计算\n\n给定具体案例：\n- $y = (y_{\\text{veg}}, y_{\\text{for}}, y_{\\text{gra}}) = (0.55, 0.60, 0.10)$\n- $\\lambda_{\\text{edge}} = 1.2$\n- $\\lambda_{\\text{sum}} = 2.5$\n\n首先，我们通过计算 $\\max$ 函数的参数来检查哪些约束被违反：\n- $y_{\\text{for}} - y_{\\text{veg}} = 0.60 - 0.55 = 0.05$。（违规）\n- $y_{\\text{gra}} - y_{\\text{veg}} = 0.10 - 0.55 = -0.45$。（未违规）\n- $y_{\\text{for}} + y_{\\text{gra}} - y_{\\text{veg}} = 0.60 + 0.10 - 0.55 = 0.70 - 0.55 = 0.15$。（违规）\n\n现在，我们计算在梯度计算中将激活的 $\\max$ 项：\n- $\\max(0, 0.05) = 0.05$\n- $\\max(0, -0.45) = 0$\n- $\\max(0, 0.15) = 0.15$\n\n使用这些值，我们计算梯度的分量：\n- $\\frac{\\partial L_{struct}}{\\partial y_{\\text{veg}}} = -2(1.2)[0.05 + 0] - 2(2.5)(0.15) = -2.4(0.05) - 5.0(0.15) = -0.12 - 0.75 = -0.87$\n- $\\frac{\\partial L_{struct}}{\\partial y_{\\text{for}}} = 2(1.2)(0.05) + 2(2.5)(0.15) = 2.4(0.05) + 5.0(0.15) = 0.12 + 0.75 = 0.87$\n- $\\frac{\\partial L_{struct}}{\\partial y_{\\text{gra}}} = 2(1.2)(0) + 2(2.5)(0.15) = 0 + 5.0(0.15) = 0.75$\n\n梯度向量为 $\\nabla_y L_{struct} = (-0.87, 0.87, 0.75)$。\n将每个分量四舍五入到四位有效数字，得到 $(-0.8700, 0.8700, 0.7500)$。\n\n### 第四部分：讨论\n\n用于训练神经网络的总损失函数是 $L_{total} = L_{base} + L_{struct}$，其中 $L_{base}$ 是一个基础分类损失（例如，对于软标签，使用均方误差或KL散度），它衡量预测值 $y$ 与真实软标签 $t$ 之间的差异。\n\n**与基础损失的相互作用**：$L_{struct}$ 充当一个正则化项。当 $L_{base}$ 驱动模型的输出 $y$ 匹配目标标签 $t$ 时，$L_{struct}$ 惩罚那些与预定义类别层次结构在逻辑上不一致的预测。$L_{total}$ 的梯度是这两项梯度的和。因此，在反向传播过程中对网络权重的更新是来自 $L_{base}$ 的“数据拟合”信号和来自 $L_{struct}$ 的“一致性强制”信号的复合。上面计算的梯度显示了这种一致性信号将如何调整输出：它会推高 $y_{\\text{veg}}$ 并拉低 $y_{\\text{for}}$ 和 $y_{\\text{gra}}$ 以解决违规问题。\n\n**稳定性和收敛性**：添加凸的 $L_{struct}$ 项不会损害损失函数相对于最后一层输出的凸性（假设 $L_{base}$ 是凸的），这是最终优化步骤的一个理想属性。然而，在端到端训练期间，总损失函数相对于网络权重的格局仍然是高度非凸的。惩罚梯度仅在违规时激活，这可能导致稀疏但可能很大的梯度，尤其是在训练早期。惩罚权重 $\\lambda_{\\text{edge}}$ 和 $\\lambda_{\\text{sum}}$ 必须仔细调整，以平衡两个损失分量并确保训练稳定。如果 $\\lambda$ 值过高，它们可能会压倒基础损失，阻碍模型拟合数据的能力。通过编码关于问题结构的强先验知识，该惩罚可以正则化模型，防止过拟合，并引导优化朝向更有意义的解决方案，从而可能加速收敛到实际有用的结果。\n\n**软标签和遥感背景的影响**：在遥感中，真实软标签 $t$ 通常表示土地覆盖类型的亚像素组分。理想情况下，这些标签本身应该是分层一致的（例如，$t_{\\text{for}} + t_{\\text{gra}} \\le t_{\\text{veg}}$）。如果是这样，随着模型学习预测 $y \\approx t$，结构化惩罚 $L_{struct}$ 将自然减小到零。惩罚此时的作用是引导学习过程朝向这个一致的状态。如果真实标签有噪声并包含不一致性，$L_{struct}$ 将与 $L_{base}$ 冲突。模型将找到一个受惩罚项相对强度影响的折衷解决方案。在这种情况下，$L_{struct}$ 实际上执行了一种标签噪声校正，将已知的结构逻辑强加于可能存在缺陷的数据之上。这对于生成物理上和语义上合理的土地覆盖图至关重要，而这正是环境建模中的一个主要目标。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} -0.8700  0.8700  0.7500 \\end{pmatrix}}\n$$"
        }
    ]
}