{
    "hands_on_practices": [
        {
            "introduction": "在构建决策树时，对连续特征进行分裂相对直接，但处理具有多个级别的分类预测变量则带来了组合爆炸的挑战。直接枚举所有可能的二元划分是不可行的。本练习将引导您实践CART算法中用于高效寻找分类特征最佳二元划分的优雅方法，该方法通过计算基尼不纯度下降值来实现，而无需测试每一种组合。",
            "id": "3805106",
            "problem": "一项针对温带流域的土地覆盖分类研究使用多光谱遥感训练数据来构建一个决策树，该决策树根据一个代表有 $5$ 个水平的土壤类型的分类预测变量 $X$ 来预测二元土地覆盖类别 $Y \\in \\{\\text{森林}, \\text{耕地}\\}$。土壤类型的水平为 $\\{S_{1}, S_{2}, S_{3}, S_{4}, S_{5}\\}$。每种土壤类型的训练样本计数如下：\n\n- $S_{1}$：森林 $80$，耕地 $20$，\n- $S_{2}$：森林 $60$，耕地 $40$，\n- $S_{3}$：森林 $40$，耕地 $60$，\n- $S_{4}$：森林 $20$，耕地 $80$，\n- $S_{5}$：森林 $70$，耕地 $30$。\n\n你需要评估一个分类与回归树 (CART) 决策树在根节点上的一次分裂，其中使用 $X$作为分裂变量。使用节点的基尼不纯度的标准定义（根据经验类别比例）和因分裂引起的基尼减少量的标准定义（即父节点不纯度减去两个子节点不纯度的加权平均值，权重为其样本量）。在将 $5$ 个土壤类型水平划分为两个非空、不相交的组的所有二元划分中，确定使基尼减少量最大化的划分。\n\n在你的计算过程中报告实现这一最大值的两组土壤类型水平，并计算此最优划分实现的最大基尼减少量。将最大基尼减少量表示为一个简化的有理数。你提供的最终数值答案必须仅为最大基尼减少量。",
            "solution": "用户提供了一个问题，在尝试解答之前需要进行验证。\n\n### 步骤 1：提取已知条件\n-   **响应变量**：土地覆盖类别 $Y \\in \\{\\text{森林}, \\text{耕地}\\}$。\n-   **预测变量**：土壤类型 $X \\in \\{S_{1}, S_{2}, S_{3}, S_{4}, S_{5}\\}$。\n-   **训练数据计数**：\n    -   $S_{1}$：$80$ 森林，$20$ 耕地。\n    -   $S_{2}$：$60$ 森林，$40$ 耕地。\n    -   $S_{3}$：$40$ 森林，$60$ 耕地。\n    -   $S_{4}$：$20$ 森林，$80$ 耕地。\n    -   $S_{5}$：$70$ 森林，$30$ 耕地。\n-   **算法**：根节点上的分类与回归树 (CART)。\n-   **分裂标准**：基尼减少量，定义为父节点不纯度减去子节点不纯度的加权平均值。\n-   **任务**：找出能最大化基尼减少量的 $5$ 个土壤类型水平的二元划分，并计算该最大值。\n\n### 步骤 2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题是 CART 算法的一个标准应用，这是机器学习和统计建模中的一个基本方法。使用基尼不纯度来分裂分类预测变量是该算法的核心概念。使用遥感数据进行土地覆盖分类的背景是一个常见且有效的应用领域。\n2.  **适定性**：该问题是适定的。$5$ 个类别的可能二元划分数量是有限的（$2^{5-1} - 1 = 15$），这保证了最大基尼减少量的存在。基尼不纯度和基尼减少量的定义是标准且无歧义的。执行计算所需的所有数据都已提供。\n3.  **客观性**：该问题以定量数据和清晰、形式化的定义客观地陈述。它不含主观或基于观点的陈述。\n\n该问题没有表现出任何无效性缺陷。它在科学上是合理的、适定的、客观的、完整的，并且在计算上是可行的。\n\n### 步骤 3：结论与行动\n该问题是有效的。将提供详细的解决方案。\n\n### 解答\n目标是找到预测变量 $X$（土壤类型）在 CART 决策树根节点上的二元划分，以最大化基尼减少量。\n\n首先，我们定义节点 $m$ 的基尼不纯度。设 $p_{mk}$ 为节点 $m$ 中类别 $k$ 的训练实例的比例。对于一组类别 $K$，基尼不纯度为：\n$$G(m) = 1 - \\sum_{k \\in K} p_{mk}^2$$\n对于我们的二元分类问题（$Y \\in \\{\\text{森林}, \\text{耕地}\\}$），这可以简化为：\n$$G(m) = 1 - (p_{m, \\text{森林}}^2 + p_{m, \\text{耕地}}^2)$$\n\n将父节点 $p$ 分裂为两个子节点，一个左节点 $l$ 和一个右节点 $r$ 的基尼减少量由下式给出：\n$$\\Delta G = G(p) - (w_l G(l) + w_r G(r))$$\n其中 $w_l$ 和 $w_r$ 分别是父节点中进入左子节点和右子节点的实例比例（$w_l = N_l / N_p$, $w_r = N_r / N_p$，其中 $N$ 是样本数）。\n\n**1. 计算根（父）节点的基尼不纯度。**\n\n首先，我们计算整个数据集中每个类别的总样本数和计数。\n每种土壤类型的总样本数：$S_1, S_2, S_3, S_4, S_5$ 各有 $100$ 个样本。\n总样本数 $N_p = 5 \\times 100 = 500$。\n\n“森林”类别总样本数：$N_{p, \\text{森林}} = 80 + 60 + 40 + 20 + 70 = 270$。\n“耕地”类别总样本数：$N_{p, \\text{耕地}} = 20 + 40 + 60 + 80 + 30 = 230$。\n检验：$270 + 230 = 500 = N_p$。\n\n根节点的比例为：\n$p_{p, \\text{森林}} = \\frac{270}{500} = \\frac{27}{50}$\n$p_{p, \\text{耕地}} = \\frac{230}{500} = \\frac{23}{50}$\n\n父节点的基尼不纯度为：\n$$G(p) = 1 - \\left( \\left(\\frac{27}{50}\\right)^2 + \\left(\\frac{23}{50}\\right)^2 \\right) = 1 - \\frac{729 + 529}{2500} = 1 - \\frac{1258}{2500} = \\frac{1242}{2500} = \\frac{621}{1250}$$\n\n**2. 确定最优分裂。**\n\n对于具有 $C$ 个水平的分类预测变量和二元结果，寻找最优分裂的过程可以被简化。我们根据某一类别的比例对类别进行排序。最优划分将通过对这个有序类别列表进行分裂来找到。需要检查 $C-1$ 个这样的分裂。\n\n我们来计算每种土壤类型中“森林”类别的比例：\n- $S_1: p_f = \\frac{80}{100} = 0.8$\n- $S_2: p_f = \\frac{60}{100} = 0.6$\n- $S_3: p_f = \\frac{40}{100} = 0.4$\n- $S_4: p_f = \\frac{20}{100} = 0.2$\n- $S_5: p_f = \\frac{70}{100} = 0.7$\n\n按“森林”比例递增排序的土壤类型顺序是：$\\{S_4, S_3, S_2, S_5, S_1\\}$。\n这给了我们 $5-1=4$ 个候选分裂进行评估。\n\n**候选分裂 1：$\\{S_4\\}$ vs. $\\{S_3, S_2, S_5, S_1\\}$**\n- 左节点 ($l_1 = \\{S_4\\}$)：$N_{l_1} = 100$。$N_{l_1,f}=20, N_{l_1,c}=80$。\n$G(l_1) = 1 - ((\\frac{20}{100})^2 + (\\frac{80}{100})^2) = 1 - (0.04 + 0.64) = 0.32 = \\frac{8}{25}$。\n- 右节点 ($r_1 = \\{S_3, S_2, S_5, S_1\\}$)：$N_{r_1} = 400$。$N_{r_1,f}=40+60+70+80=250$, $N_{r_1,c}=60+40+30+20=150$。\n$G(r_1) = 1 - ((\\frac{250}{400})^2 + (\\frac{150}{400})^2) = 1 - ((\\frac{5}{8})^2 + (\\frac{3}{8})^2) = 1 - \\frac{25+9}{64} = 1 - \\frac{34}{64} = \\frac{30}{64} = \\frac{15}{32}$。\n- 基尼减少量：$\\Delta G_1 = G(p) - (\\frac{100}{500}G(l_1) + \\frac{400}{500}G(r_1)) = \\frac{621}{1250} - (\\frac{1}{5}\\frac{8}{25} + \\frac{4}{5}\\frac{15}{32}) = \\frac{621}{1250} - (\\frac{8}{125} + \\frac{3}{8}) = \\frac{621}{1250} - \\frac{64+375}{1000} = \\frac{621}{1250} - \\frac{439}{1000} = \\frac{2484-2195}{5000} = \\frac{289}{5000}$。\n\n**候选分裂 2：$\\{S_4, S_3\\}$ vs. $\\{S_2, S_5, S_1\\}$**\n- 左节点 ($l_2 = \\{S_4, S_3\\}$)：$N_{l_2} = 200$。$N_{l_2,f}=20+40=60$, $N_{l_2,c}=80+60=140$。\n$G(l_2) = 1 - ((\\frac{60}{200})^2 + (\\frac{140}{200})^2) = 1 - ((\\frac{3}{10})^2 + (\\frac{7}{10})^2) = 1 - \\frac{9+49}{100} = \\frac{42}{100} = \\frac{21}{50}$。\n- 右节点 ($r_2 = \\{S_2, S_5, S_1\\}$)：$N_{r_2} = 300$。$N_{r_2,f}=60+70+80=210$, $N_{r_2,c}=40+30+20=90$。\n$G(r_2) = 1 - ((\\frac{210}{300})^2 + (\\frac{90}{300})^2) = 1 - ((\\frac{7}{10})^2 + (\\frac{3}{10})^2) = 1 - \\frac{49+9}{100} = \\frac{42}{100} = \\frac{21}{50}$。\n- 基尼减少量：$\\Delta G_2 = G(p) - (\\frac{200}{500}G(l_2) + \\frac{300}{500}G(r_2)) = \\frac{621}{1250} - (\\frac{2}{5}\\frac{21}{50} + \\frac{3}{5}\\frac{21}{50}) = \\frac{621}{1250} - (\\frac{2+3}{5})\\frac{21}{50} = \\frac{621}{1250} - \\frac{21}{50} = \\frac{621 - 21 \\times 25}{1250} = \\frac{621-525}{1250} = \\frac{96}{1250} = \\frac{48}{625}$。\n\n**候选分裂 3：$\\{S_4, S_3, S_2\\}$ vs. $\\{S_5, S_1\\}$**\n- 左节点 ($l_3 = \\{S_4, S_3, S_2\\}$)：$N_{l_3} = 300$。$N_{l_3,f}=20+40+60=120$, $N_{l_3,c}=80+60+40=180$。\n$G(l_3) = 1 - ((\\frac{120}{300})^2 + (\\frac{180}{300})^2) = 1 - ((\\frac{2}{5})^2 + (\\frac{3}{5})^2) = 1 - \\frac{4+9}{25} = \\frac{12}{25}$。\n- 右节点 ($r_3 = \\{S_5, S_1\\}$)：$N_{r_3} = 200$。$N_{r_3,f}=70+80=150$, $N_{r_3,c}=30+20=50$。\n$G(r_3) = 1 - ((\\frac{150}{200})^2 + (\\frac{50}{200})^2) = 1 - ((\\frac{3}{4})^2 + (\\frac{1}{4})^2) = 1 - \\frac{9+1}{16} = \\frac{6}{16} = \\frac{3}{8}$。\n- 基尼减少量：$\\Delta G_3 = G(p) - (\\frac{3}{5}G(l_3) + \\frac{2}{5}G(r_3)) = \\frac{621}{1250} - (\\frac{3}{5}\\frac{12}{25} + \\frac{2}{5}\\frac{3}{8}) = \\frac{621}{1250} - (\\frac{36}{125} + \\frac{3}{20}) = \\frac{621}{1250} - \\frac{144+75}{500} = \\frac{621}{1250} - \\frac{219}{500} = \\frac{1242-1095}{2500} = \\frac{147}{2500}$。\n\n**候选分裂 4：$\\{S_4, S_3, S_2, S_5\\}$ vs. $\\{S_1\\}$**\n- 左节点 ($l_4 = \\{S_4, S_3, S_2, S_5\\}$)：$N_{l_4} = 400$。$N_{l_4,f}=20+40+60+70=190$, $N_{l_4,c}=80+60+40+30=210$。\n$G(l_4) = 1 - ((\\frac{190}{400})^2 + (\\frac{210}{400})^2) = 1 - ((\\frac{19}{40})^2+(\\frac{21}{40})^2) = 1 - \\frac{361+441}{1600} = \\frac{1600-802}{1600} = \\frac{798}{1600}=\\frac{399}{800}$。\n- 右节点 ($r_4 = \\{S_1\\}$)：$N_{r_4} = 100$。$N_{r_4,f}=80, N_{r_4,c}=20$。\n$G(r_4) = 1 - ((\\frac{80}{100})^2 + (\\frac{20}{100})^2) = 1 - (0.64+0.04) = 0.32 = \\frac{8}{25}$。\n- 基尼减少量：$\\Delta G_4 = G(p) - (\\frac{4}{5}G(l_4) + \\frac{1}{5}G(r_4)) = \\frac{621}{1250} - (\\frac{4}{5}\\frac{399}{800} + \\frac{1}{5}\\frac{8}{25}) = \\frac{621}{1250} - (\\frac{399}{1000} + \\frac{8}{125}) = \\frac{621}{1250} - \\frac{399+64}{1000} = \\frac{621}{1250} - \\frac{463}{1000} = \\frac{2484 - 2315}{5000} = \\frac{169}{5000}$。\n\n**3. 比较基尼减少量。**\n我们比较这四个值：\n- $\\Delta G_1 = \\frac{289}{5000} = 0.0578$\n- $\\Delta G_2 = \\frac{48}{625} = \\frac{384}{5000} = 0.0768$\n- $\\Delta G_3 = \\frac{147}{2500} = \\frac{294}{5000} = 0.0588$\n- $\\Delta G_4 = \\frac{169}{5000} = 0.0338$\n\n最大值是 $\\Delta G_2 = \\frac{48}{625}$。\n这个最大的基尼减少量是通过将土壤类型划分为 $\\{S_4, S_3\\}$ 和 $\\{S_1, S_2, S_5\\}$ 这两组来实现的。\n\n最大基尼减少量是 $\\frac{48}{625}$。",
            "answer": "$$\\boxed{\\frac{48}{625}}$$"
        },
        {
            "introduction": "完全生长的决策树往往会对训练数据产生过拟合，从而降低其在未见数据上的泛化能力。成本复杂度剪枝（Cost-Complexity Pruning）为简化决策树、防止过拟合提供了一种原则性的方法。本练习将带您深入理解这一过程的核心机制，通过计算一系列关键的复杂度惩罚参数 $\\alpha$，您可以确定在不同复杂度与准确度权衡下的最优子树序列。",
            "id": "3805108",
            "problem": "一个土地覆盖分类决策树在一个带标签的卫星像素集上进行了训练，以使用多光谱阈值区分主要类别（城市、植被、水体、裸土）。该方法是分类与回归树（CART）。在此训练中，每个终端叶节点会指定其区域内的多数类别，并产生一个重复代入误分类计数。下面的小树有五个终端叶节点，其重复代入误差为 $\\left(e_{1}, e_{2}, e_{3}, e_{4}, e_{5}\\right)$，还有四个内部节点，其聚合误差（即如果整个节点的区域被单一多数类别标记时的误分类计数）也已给出。\n\n拓扑结构如下：根节点 $U$ 分裂为一个左内部节点 $A$ 和一个右内部节点 $D$；节点 $A$ 分裂为叶节点 $1$ 和 $2$；节点 $D$ 分裂为一个内部节点 $B$ 和叶节点 $5$；节点 $B$ 分裂为叶节点 $3$ 和 $4$。\n\n各叶节点的重复代入误差为\n$$\ne_{1} = 12,\\quad e_{2} = 8,\\quad e_{3} = 15,\\quad e_{4} = 10,\\quad e_{5} = 6.\n$$\n各内部节点的聚合误差（如果每个节点都被剪枝成一个单一叶节点，并用其区域内的多数标签进行标记）为\n$$\nE_{A} = 24,\\quad E_{B} = 28,\\quad E_{D} = 40,\\quad E_{U} = 72.\n$$\n\n假设使用成本复杂度剪枝，复杂度惩罚参数为 $\\alpha \\geq 0$，树的选择通过最小化一个惩罚经验风险来进行，该风险是所有叶节点的重复代入误分类计数之和加上一个与叶节点数量成正比的线性惩罚项。使用源于结构风险最小化的第一性原理推理，通过确定最优子树发生变化时的临界惩罚值序列，以及每个子树成为最优所对应的 $\\alpha$ 区间，来确定剪枝路径。\n\n将临界惩罚值序列按升序报告为一个单行矩阵。给出精确值（不要四舍五入）。",
            "solution": "该问题提法恰当，具有科学依据，并为获得唯一解提供了所有必要信息。数据是内部一致的。因此，将推导出一个解。\n\n该问题要求使用成本复杂度剪枝法确定给定决策树的剪枝路径。该方法是分类与回归树（CART）算法的核心，旨在找到一系列子树，这些子树对于复杂度惩罚参数 $\\alpha$ 的一个连续范围是最优的。\n\n树 $T$ 的成本复杂度定义为：\n$$\nC_{\\alpha}(T) = R(T) + \\alpha |T_{\\text{leaves}}|\n$$\n其中 $R(T)$ 是总重复代入误分类计数，即树 $T$ 中所有终端叶节点的误差之和，而 $|T_{\\text{leaves}}|$ 是 $T$ 中终端叶节点的数量。参数 $\\alpha \\ge 0$ 惩罚树的复杂度，该复杂度由其叶节点数量衡量。\n\n对于树中的任何内部节点 $t$，我们可以考虑以 $t$ 为根的子树 $T_t$。该子树的成本复杂度为 $C_{\\alpha}(T_t) = R(T_t) + \\alpha |(T_t)_{\\text{leaves}}|$。如果我们剪掉这个子树，节点 $t$ 将成为一个终端叶节点。这种剪枝状态的成本复杂度为 $C_{\\alpha}(\\{t\\}) = E_t + \\alpha \\cdot 1$，其中 $E_t$ 是对应于节点 $t$ 区域的聚合误分类计数。\n\n当将节点 $t$ 变为叶节点的成本小于或等于以 $t$ 为根的未剪枝子树的成本时，节点 $t$ 成为剪枝的候选对象：\n$$\nE_t + \\alpha \\le R(T_t) + \\alpha |(T_t)_{\\text{leaves}}|\n$$\n成本相等时的 $\\alpha$ 临界值定义了节点 $t$ 成为树中“最薄弱环节”的点。重新整理该方程，可得到节点 $t$ 的临界复杂度参数：\n$$\n\\alpha_t = \\frac{E_t - R(T_t)}{|(T_t)_{\\text{leaves}}| - 1}\n$$\n成本复杂度剪枝算法是迭代进行的。从完整的树开始，我们为每个内部节点计算 $\\alpha_t$。具有最小 $\\alpha_t$ 值的节点最先被剪枝。这个过程在新剪枝的树上重复进行，直到只剩下根节点。\n\n让我们将初始的完整树表示为 $T_0$。其拓扑结构包括内部节点 $U, A, D, B$ 和终端叶节点 $1, 2, 3, 4, 5$。\n各叶节点的误差给出如下 $e_{1} = 12$, $e_{2} = 8$, $e_{3} = 15$, $e_{4} = 10$, 和 $e_{5} = 6$。\n内部节点的聚合误差为 $E_{A} = 24$, $E_{B} = 28$, $E_{D} = 40$, 和 $E_{U} = 72$。\n\n首先，我们必须为完整树 $T_0$ 中以每个内部节点为根的子树计算重复代入误差 $R(T_t)$ 和叶节点数量 $|(T_t)_{\\text{leaves}}|$。\n\n对于节点 $A$：\n子树 $T_A$ 有叶节点 $1$ 和 $2$。\n$R(T_A) = e_1 + e_2 = 12 + 8 = 20$。\n$|(T_A)_{\\text{leaves}}| = 2$。\n\n对于节点 $B$：\n子树 $T_B$ 有叶节点 $3$ 和 $4$。\n$R(T_B) = e_3 + e_4 = 15 + 10 = 25$。\n$|(T_B)_{\\text{leaves}}| = 2$。\n\n对于节点 $D$：\n子树 $T_D$ 有一个内部节点 $B$ 和一个叶节点 $5$。它的叶节点是 $T_B$ 的叶节点和叶节点 $5$。\n$R(T_D) = R(T_B) + e_5 = 25 + 6 = 31$。\n$|(T_D)_{\\text{leaves}}| = |(T_B)_{\\text{leaves}}| + 1 = 2 + 1 = 3$。\n\n对于根节点 $U$：\n完整树 $T_U = T_0$ 有内部节点 $A$ 和 $D$。它的叶节点是 $T_A$ 和 $T_D$ 叶节点的并集。\n$R(T_U) = R(T_A) + R(T_D) = 20 + 31 = 51$。\n$|(T_U)_{\\text{leaves}}| = |(T_A)_{\\text{leaves}}| + |(T_D)_{\\text{leaves}}| = 2 + 3 = 5$。\n\n现在，我们可以计算 $T_0$ 中所有内部节点的临界 $\\alpha$ 值。\n\n$\\alpha_A = \\frac{E_A - R(T_A)}{|(T_A)_{\\text{leaves}}| - 1} = \\frac{24 - 20}{2 - 1} = \\frac{4}{1} = 4$。\n$\\alpha_B = \\frac{E_B - R(T_B)}{|(T_B)_{\\text{leaves}}| - 1} = \\frac{28 - 25}{2 - 1} = \\frac{3}{1} = 3$。\n$\\alpha_D = \\frac{E_D - R(T_D)}{|(T_D)_{\\text{leaves}}| - 1} = \\frac{40 - 31}{3 - 1} = \\frac{9}{2} = 4.5$。\n$\\alpha_U = \\frac{E_U - R(T_U)}{|(T_U)_{\\text{leaves}}| - 1} = \\frac{72 - 51}{5 - 1} = \\frac{21}{4} = 5.25$。\n\n这些值的最小值是 $\\alpha_B = 3$。因此，第一个临界惩罚值是 $\\alpha_{(1)} = 3$。对于 $\\alpha \\in [0, 3)$，完整树 $T_0$ 是最优子树。在 $\\alpha = 3$ 时，我们剪掉节点 $B$。\n\n设 $T_1$ 是通过剪掉节点 $B$ 得到的树。在 $T_1$ 中，$B$ 成为一个叶节点（我们将其表示为 $B'$），误差为 $R(B') = E_B = 28$。\n$T_1$ 的内部节点是 $A, D, U$。叶节点是 $\\{1, 2, B', 5\\}$。\n我们为 $T_1$ 的内部节点重新计算临界 $\\alpha$ 值。\n\n对于节点 $A$：子树 $T_A$ 未改变，所以 $\\alpha_A = 4$。\n对于节点 $D$：在 $T_1$ 中的子树 $T_D$ 现在有叶节点 $\\{B', 5\\}$。\n$R(T_D \\text{ in } T_1) = R(B') + e_5 = 28 + 6 = 34$。\n$|(T_D \\text{ in } T_1)_{\\text{leaves}}| = 2$。\n$\\alpha_D = \\frac{E_D - R(T_D \\text{ in } T_1)}{|(T_D \\text{ in } T_1)_{\\text{leaves}}| - 1} = \\frac{40 - 34}{2 - 1} = \\frac{6}{1} = 6$。\n对于节点 $U$：树 $T_U$ 现在是 $T_1$。\n$R(T_1) = R(T_A) + R(T_D \\text{ in } T_1) = (e_1+e_2) + (E_B+e_5) = 20 + 34 = 54$。\n$|T_1|_{\\text{leaves}} = 4$。\n$\\alpha_U = \\frac{E_U - R(T_1)}{|T_1|_{\\text{leaves}} - 1} = \\frac{72 - 54}{4 - 1} = \\frac{18}{3} = 6$。\n\n候选临界值集合为 $\\{\\alpha_A, \\alpha_D, \\alpha_U\\} = \\{4, 6, 6\\}$。最小值是 $\\alpha_A = 4$。所以，第二个临界值是 $\\alpha_{(2)} = 4$。对于 $\\alpha \\in [3, 4)$，树 $T_1$ 是最优的。在 $\\alpha=4$ 时，节点 $A$ 被剪枝。\n\n设 $T_2$ 是从 $T_1$ 中剪掉节点 $A$ 得到的树。节点 $A$ 成为一个叶节点 $A'$，误差为 $R(A')=E_A = 24$。\n$T_2$ 的内部节点是 $D, U$。叶节点是 $\\{A', B', 5\\}$。\n我们为 $T_2$ 的内部节点重新计算临界 $\\alpha$ 值。\n\n对于节点 $D$：子树 $T_D$ 不受在 $A$ 处剪枝的影响。它在 $T_2$ 中的结构与在 $T_1$ 中相同。因此，$\\alpha_D = 6$。\n对于节点 $U$：树 $T_U$ 现在是 $T_2$。\n$R(T_2) = R(A') + R(B') + e_5 = 24 + 28 + 6 = 58$。\n$|T_2|_{\\text{leaves}} = 3$。\n$\\alpha_U = \\frac{E_U - R(T_2)}{|T_2|_{\\text{leaves}} - 1} = \\frac{72 - 58}{3 - 1} = \\frac{14}{2} = 7$。\n\n候选值集合为 $\\{\\alpha_D, \\alpha_U\\} = \\{6, 7\\}$。最小值是 $\\alpha_D = 6$。所以，第三个临界值是 $\\alpha_{(3)} = 6$。对于 $\\alpha \\in [4, 6)$，树 $T_2$ 是最优的。在 $\\alpha=6$ 时，节点 $D$ 被剪枝。\n\n设 $T_3$ 是从 $T_2$ 中剪掉节点 $D$ 得到的树。节点 $D$ 成为一个叶节点 $D'$，误差为 $R(D')=E_D = 40$。\n$T_3$ 唯一的内部节点是 $U$。叶节点是 $\\{A', D'\\}$。\n我们为剩下的内部节点 $U$ 计算临界 $\\alpha$ 值。\n\n对于节点 $U$：树 $T_U$ 现在是 $T_3$。\n$R(T_3) = R(A') + R(D') = 24 + 40 = 64$。\n$|T_3|_{\\text{leaves}} = 2$。\n$\\alpha_U = \\frac{E_U - R(T_3)}{|T_3|_{\\text{leaves}} - 1} = \\frac{72 - 64}{2 - 1} = \\frac{8}{1} = 8$。\n\n只有一个内部节点，所以它的 $\\alpha$ 值是下一个临界值，$\\alpha_{(4)} = 8$。对于 $\\alpha \\in [6, 8)$，树 $T_3$ 是最优的。在 $\\alpha=8$ 时，节点 $U$ 被剪枝。\n\n剪掉节点 $U$ 得到只包含根节点的平凡树 $T_4$。这棵树有 1 个叶节点，总误差为 $E_U = 72$。剪枝过程至此完成。对于 $\\alpha \\in [8, \\infty)$，平凡树 $T_4$ 是最优的。\n\n最优子树发生变化的临界惩罚值序列是 $\\alpha_{(1)}, \\alpha_{(2)}, \\alpha_{(3)}, \\alpha_{(4)}$。\n这个序列是 $3, 4, 6, 8$。\n由这些值定义的区间所对应的最优子树序列是 $T_0, T_1, T_2, T_3, T_4$。\n\n临界惩罚值的序列，按升序排列，是 $\\{3, 4, 6, 8\\}$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n3  4  6  8\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "构建分类模型只是工作的一半，我们还必须严格评估其性能。混淆矩阵是进行此类定量评估的基石，它详细记录了模型在验证集上的预测正确与错误的情况。本练习将让您熟练掌握从混淆矩阵中计算关键性能指标的技能，包括精确率（precision）、召回率（recall）和 F1 分数，并特别探讨在遥感等类别不平衡场景中至关重要的宏平均（macro-average）与微平均（micro-average）之间的差异。",
            "id": "3805154",
            "problem": "一个决策树分类器在多光谱卫星观测数据上进行训练，用于将土地覆盖划分为与环境建模相关的三类：森林、耕地和水体。特征包括物理反射率波段和领域标准的波谱指数，例如根据经过大气校正的地表反射率计算的归一化植被指数 (NDVI) 和修正归一化差异水体指数 (MNDWI)。该分类器为每个像素输出一个单一标签。\n\n在一个包含 $N$ 个像素的独立验证集上，得到了以下混淆矩阵 $C$。行对应参考（真实）类别，列对应预测类别：\n$$\nC \\;=\\;\n\\begin{pmatrix}\n420  50  30 \\\\\n60  340  50 \\\\\n5  45  300\n\\end{pmatrix},\n$$\n行和列的类别顺序均为 $\\{\\text{森林}, \\text{耕地}, \\text{水体}\\}$。\n\n使用基于每个类别的真正例、假正例和假负例的逐类精确率、逐类召回率以及调和平均 $\\mathrm{F1}$ 分数的基本定义，计算：\n- 森林、耕地和水体每个类别的精确率、召回率和 $\\mathrm{F1}$ 分数；\n- 三个类别的宏平均精确率、召回率和 $\\mathrm{F1}$ 分数；\n- 三个类别的微平均精确率、召回率和 $\\mathrm{F1}$ 分数。\n\n假设这是一个单标签多分类设置，其中每个像素恰好属于一个参考类别，并接收一个预测类别。请对宏平均和微平均进行定量比较。\n\n将 $F1_{\\mathrm{macro}} - F1_{\\mathrm{micro}}$ 的值以小数形式报告为你的最终答案，并四舍五入到四位有效数字。最终答案中不要包含任何单位或百分号。",
            "solution": "问题陈述已经过验证，被认为是有效的。它在科学上基于机器学习性能评估的原则，提法明确，所有必要数据均已在混淆矩阵中提供，且其表述是客观的。\n\n任务是根据一个三分类器的混淆矩阵 $C$ 计算几个性能指标。类别索引如下：$1$ 代表森林，$2$ 代表耕地，$3$ 代表水体。给定的混淆矩阵为：\n$$\nC \\;=\\;\n\\begin{pmatrix}\nC_{11}  C_{12}  C_{13} \\\\\nC_{21}  C_{22}  C_{23} \\\\\nC_{31}  C_{32}  C_{33}\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n420  50  30 \\\\\n60  340  50 \\\\\n5  45  300\n\\end{pmatrix}\n$$\n其中行代表参考（真实）类别，列代表预测类别。\n\n对于每个类别 $i$，我们定义真正例 ($TP_i$)、假正例 ($FP_i$) 和假负例 ($FN_i$) 的数量：\n- $TP_i = C_{ii}$：类别 $i$ 的像素被正确分类为类别 $i$ 的数量。\n- $FP_i = \\sum_{k \\neq i} C_{ki}$：其他类别的像素被错误分类为类别 $i$ 的数量（第 $i$ 列的总和，不包括对角线元素）。\n- $FN_i = \\sum_{j \\neq i} C_{ij}$：类别 $i$ 的像素被错误分类为其他类别的数量（第 $i$ 行的总和，不包括对角线元素）。\n\n基于这些，我们定义逐类精确率 ($P_i$)、召回率 ($R_i$) 和 $\\mathrm{F1}$ 分数 ($F1_i$)：\n$$ P_i = \\frac{TP_i}{TP_i + FP_i} \\quad , \\quad R_i = \\frac{TP_i}{TP_i + FN_i} \\quad , \\quad F1_i = 2 \\cdot \\frac{P_i \\cdot R_i}{P_i + R_i} = \\frac{2 TP_i}{2 TP_i + FP_i + FN_i} $$\n\n**逐类指标计算**\n\n**类别 1：森林**\n- $TP_1 = C_{11} = 420$\n- $FP_1 = C_{21} + C_{31} = 60 + 5 = 65$\n- $FN_1 = C_{12} + C_{13} = 50 + 30 = 80$\n- $P_1 = \\frac{420}{420 + 65} = \\frac{420}{485} = \\frac{84}{97} \\approx 0.8660$\n- $R_1 = \\frac{420}{420 + 80} = \\frac{420}{500} = \\frac{21}{25} = 0.8400$\n- $F1_1 = \\frac{2 \\cdot 420}{2 \\cdot 420 + 65 + 80} = \\frac{840}{840 + 145} = \\frac{840}{985} = \\frac{168}{197} \\approx 0.8528$\n\n**类别 2：耕地**\n- $TP_2 = C_{22} = 340$\n- $FP_2 = C_{12} + C_{32} = 50 + 45 = 95$\n- $FN_2 = C_{21} + C_{23} = 60 + 50 = 110$\n- $P_2 = \\frac{340}{340 + 95} = \\frac{340}{435} = \\frac{68}{87} \\approx 0.7816$\n- $R_2 = \\frac{340}{340 + 110} = \\frac{340}{450} = \\frac{34}{45} \\approx 0.7556$\n- $F1_2 = \\frac{2 \\cdot 340}{2 \\cdot 340 + 95 + 110} = \\frac{680}{680 + 205} = \\frac{680}{885} = \\frac{136}{177} \\approx 0.7684$\n\n**类别 3：水体**\n- $TP_3 = C_{33} = 300$\n- $FP_3 = C_{13} + C_{23} = 30 + 50 = 80$\n- $FN_3 = C_{31} + C_{32} = 5 + 45 = 50$\n- $P_3 = \\frac{300}{300 + 80} = \\frac{300}{380} = \\frac{15}{19} \\approx 0.7895$\n- $R_3 = \\frac{300}{300 + 50} = \\frac{300}{350} = \\frac{6}{7} \\approx 0.8571$\n- $F1_3 = \\frac{2 \\cdot 300}{2 \\cdot 300 + 80 + 50} = \\frac{600}{600 + 130} = \\frac{600}{730} = \\frac{60}{73} \\approx 0.8219$\n\n**宏平均指标**\n宏平均计算的是逐类指标的未加权平均值。对于 $K=3$ 个类别：\n$$ P_{\\mathrm{macro}} = \\frac{1}{K} \\sum_{i=1}^K P_i \\quad , \\quad R_{\\mathrm{macro}} = \\frac{1}{K} \\sum_{i=1}^K R_i \\quad , \\quad F1_{\\mathrm{macro}} = \\frac{1}{K} \\sum_{i=1}^K F1_i $$\n我们计算 $F1_{\\mathrm{macro}}$：\n$$ F1_{\\mathrm{macro}} = \\frac{1}{3} (F1_1 + F1_2 + F1_3) = \\frac{1}{3} \\left( \\frac{168}{197} + \\frac{136}{177} + \\frac{60}{73} \\right) $$\n使用高精度小数值：\n$$ F1_{\\mathrm{macro}} \\approx \\frac{1}{3} (0.85279188 + 0.76836158 + 0.82191781) = \\frac{1}{3} (2.44307127) \\approx 0.81435709 $$\n\n**微平均指标**\n微平均汇总所有类别的贡献来计算全局指标。我们首先对所有类别的 $TP$、$FP$ 和 $FN$ 计数求和：\n- $\\sum_{i=1}^3 TP_i = TP_1 + TP_2 + TP_3 = 420 + 340 + 300 = 1060$\n- $\\sum_{i=1}^3 FP_i = FP_1 + FP_2 + FP_3 = 65 + 95 + 80 = 240$\n- $\\sum_{i=1}^3 FN_i = FN_1 + FN_2 + FN_3 = 80 + 110 + 50 = 240$\n注意 $\\sum_i FP_i = \\sum_i FN_i$，因为两者都表示混淆矩阵所有非对角线元素之和。\n\n微平均指标为：\n$$ P_{\\mathrm{micro}} = \\frac{\\sum_i TP_i}{\\sum_i TP_i + \\sum_i FP_i} = \\frac{1060}{1060 + 240} = \\frac{1060}{1300} $$\n$$ R_{\\mathrm{micro}} = \\frac{\\sum_i TP_i}{\\sum_i TP_i + \\sum_i FN_i} = \\frac{1060}{1060 + 240} = \\frac{1060}{1300} $$\n由于 $P_{\\mathrm{micro}} = R_{\\mathrm{micro}}$，微平均 $\\mathrm{F1}$ 分数与这两者相等：\n$$ F1_{\\mathrm{micro}} = P_{\\mathrm{micro}} = R_{\\mathrm{micro}} = \\frac{1060}{1300} = \\frac{106}{130} = \\frac{53}{65} $$\n这个值也是分类器的总体准确率。\n$$ F1_{\\mathrm{micro}} = \\frac{53}{65} \\approx 0.81538462 $$\n\n**定量比较与最终答案**\n问题要求进行定量比较，我们将通过计算差值 $F1_{\\mathrm{macro}} - F1_{\\mathrm{micro}}$ 来实现。\n$$ F1_{\\mathrm{macro}} - F1_{\\mathrm{micro}} \\approx 0.81435709 - 0.81538462 = -0.00102753 $$\n负值表示 $F1_{\\mathrm{micro}}  F1_{\\mathrm{macro}}$。微平均对每个样本同等加权，因此样本量更大的类别影响力更大。宏平均对每个类别同等加权。该结果表明，分类器在样本量较多的类别上表现稍好（在此案例中，森林类别的 F1 分数最高，样本数量也最多：$500$），从而相对于宏平均值，将微平均值拉高。\n\n将结果四舍五入到四位有效数字：\n第一个有效数字是万分位上的 $1$。我们保留四位数字：$1, 0, 2, 7$。第五位数字是 $5$，因此我们将最后一位数字进位。\n$$ -0.00102753 \\rightarrow -0.001028 $$",
            "answer": "$$\\boxed{-0.001028}$$"
        }
    ]
}