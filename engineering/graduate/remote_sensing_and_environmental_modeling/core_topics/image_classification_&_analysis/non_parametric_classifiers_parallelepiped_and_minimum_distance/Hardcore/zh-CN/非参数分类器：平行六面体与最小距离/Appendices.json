{
    "hands_on_practices": [
        {
            "introduction": "平行六面体分类器因其直观性而备受青睐，但它们在高维特征空间（在多光谱和高光谱遥感中很常见）中的表现可能与直觉相悖。通过这个练习 ，您将推导并量化这种效应，揭示为何一个体积庞大的接受区域反而可能导致极低的像素接受率。理解这一“维度灾难”现象对于认识该方法的内在局限性至关重要。",
            "id": "3830385",
            "problem": "一台多光谱成像仪器在经过大气校正后，获取地表反射率的 $d$ 维特征向量 $\\mathbf{X} \\in \\mathbb{R}^{d}$。对于一个地物覆盖类别 $C$，平行六面体分类器定义了一个轴对齐的接受区域 $A = \\prod_{j=1}^{d} I_{j}$，其中每个 $I_{j} \\subset \\mathbb{R}$ 是根据训练数据估计的沿波段 $j$ 的闭区间。经过基于主成分分析（PCA）的线性白化变换后，假设变换后的类别条件特征在各波段间是标准化的且统计独立的。类别 $C$ 的 $I_{j}$ 的经验边际覆盖率是 $p_{j} \\in (0,1)$，定义为一个类别 $C$ 的像素在波段 $j$ 上的值落在 $I_{j}$ 内的概率。\n\n仅从积空间上的联合概率定义、变换后波段的独立性以及 $p_{j}$ 作为边际覆盖率的定义出发，推导平行六面体分类器接受的类别 $C$ 像素的期望分数，作为 $\\{p_{j}\\}_{j=1}^{d}$ 的函数。使用几何度量解释为什么增加 $d$ 会同时增大 $A$ 的绝对体积，却又减少了类别分布下的期望联合覆盖率。在覆盖率方面，简要地将其与最小距离分类器（将每个像素分配给最近的类别均值，且不包含拒绝选项）的行为进行对比。\n\n然后，对于一个在 $d = 6$ 个白化波段中的植被类别，其经验测量的边际覆盖率如下\n$$\np_{1} = 0.93,\\quad p_{2} = 0.89,\\quad p_{3} = 0.90,\\quad p_{4} = 0.88,\\quad p_{5} = 0.95,\\quad p_{6} = 0.87,\n$$\n计算平行六面体分类器对类别 $C$ 的期望接受概率。将最终概率四舍五入至 $4$ 位有效数字，并以小数形式表示。",
            "solution": "该问题要求在特征统计独立的假设下，推导平行六面体分类器的期望接受概率，解释该分类器在高维空间中的行为，与最小距离分类器进行简要比较，并进行具体的数值计算。该问题提法清晰，具有科学依据，并为完整解答提供了所有必要信息。\n\n首先，我们推导分类器接受的类别 $C$ 像素的期望分数的一般表达式。设 $\\mathbf{X} = (X_{1}, X_{2}, \\dots, X_{d})$ 是表示属于类别 $C$ 的像素特征的 $d$ 维随机向量。如果一个像素的特征向量落在接受区域 $A$ 内，平行六面体分类器就接受该像素。区域 $A$ 定义为 $d$ 个闭区间的笛卡尔积，$A = \\prod_{j=1}^{d} I_{j}$，其中 $I_{j}$ 是第 $j$ 个波段的接受区间。\n\n一个像素被接受，当且仅当其在所有波段 $j = 1, \\dots, d$ 上的特征值 $X_{j}$ 都落在区间 $I_{j}$ 内。被接受像素的期望分数是这个联合事件的概率，我们记为 $P_{\\text{accept}}$。\n$$\nP_{\\text{accept}} = P(\\mathbf{X} \\in A) = P(X_{1} \\in I_{1} \\text{ and } X_{2} \\in I_{2} \\text{ and } \\dots \\text{ and } X_{d} \\in I_{d})\n$$\n问题陈述指明，经过白化变换后，类别条件特征在各波段间是统计独立的。一组事件统计独立的定义是，它们联合发生的概率是它们各自概率的乘积。因此，我们可以写出：\n$$\nP_{\\text{accept}} = P(X_{1} \\in I_{1}) \\times P(X_{2} \\in I_{2}) \\times \\dots \\times P(X_{d} \\in I_{d})\n$$\n问题将经验边际覆盖率 $p_{j}$ 定义为一个类别 $C$ 的像素在波段 $j$ 上的值落在区间 $I_{j}$ 内的概率。即，$p_{j} = P(X_{j} \\in I_{j})$。将此定义代入 $P_{\\text{accept}}$ 的表达式，我们得到所需结果：\n$$\nP_{\\text{accept}} = \\prod_{j=1}^{d} p_{j}\n$$\n该表达式给出了类别 $C$ 的期望接受概率，作为边际覆盖率 $\\{p_{j}\\}_{j=1}^{d}$ 的函数。\n\n接下来，我们讨论增加维度 $d$ 如何既能增大接受区域 $A$ 的体积，同时又减少期望联合覆盖率 $P_{\\text{accept}}$ 这一看似矛盾的现象。\n轴对齐的平行六面体 $A$ 的几何度量，即体积，是其定义区间长度的乘积：\n$$\n\\text{Vol}(A) = \\prod_{j=1}^{d} \\text{Length}(I_{j})\n$$\n为了使特征标准化，其分布通常具有有限的标准差，例如 $\\sigma_{j}=1$。为了实现高的边际覆盖率 $p_{j}$（例如 $p_{j} = 0.95$），区间 $I_{j}$ 必须跨越一个相当大的范围。例如，如果白化后的特征服从标准正态分布，一个捕获 $p_{j}=0.95$ 概率质量的区间长度必须约为 $3.92$。由于这个长度大于 $1$，体积 $\\text{Vol}(A)$ 将随着维度 $d$ 的增加呈指数级增长，即 $(\\text{长度})^{d}$。这导致接受区域的绝对体积迅速膨胀。\n相反，联合覆盖率，即接受概率，是 $P_{\\text{accept}} = \\prod_{j=1}^{d} p_{j}$。由于每个 $p_{j}$ 都是一个概率，它必须满足 $p_{j} \\in (0, 1)$。多个小于 $1$ 的数相乘会得到一个更小的数。为简单起见，如果我们假设所有边际覆盖率都等于一个常数 $p  1$，那么 $P_{\\text{accept}} = p^{d}$。这个值会随着 $d$ 的增加而指数级地趋近于 $0$。这种现象是“维度灾难”的一种表现：虽然超矩形区域 $A$ 在特征空间中占据了巨大的体积，但这个体积大部分是概率密度小到可以忽略的“空”角落空间。类别分布的实际概率质量变得越来越集中在一个超矩形难以很好近似的区域，而要求一个样本在所有维度上同时“典型”的条件变得极其苛刻。\n\n现在，我们简要对比平行六面体分类器与最小距离分类器的行为。最小距离分类器将整个特征空间 $\\mathbb{R}^{d}$ 划分为决策区域，每个类别一个。具体来说，每个点 $\\mathbf{x} \\in \\mathbb{R}^{d}$ 被分配给其均值向量 $\\boldsymbol{\\mu}_{k}$ 与 $\\mathbf{x}$ 最接近的类别 $C_{k}$。这意味着没有“拒绝”选项；每个像素都会被分类。因此，所有类别的总覆盖率为 $100 \\%$。相比之下，平行六面体分类器为每个类别定义了明确、有界的接受区域。任何落在所有已定义的平行六面体之外的像素都将被拒绝或不予分类。因此，其总覆盖率通常远低于 $100 \\%$。虽然最小距离分类器也受维度灾难的影响（高维空间中的距离可能变得意义不大），但其在覆盖率方面的行为是根本不同的，因为它强制对特征空间进行了完全的剖分。\n\n最后，我们计算给定植被类别的期望接受概率。维度为 $d=6$，边际覆盖率如下：\n$p_{1} = 0.93$\n$p_{2} = 0.89$\n$p_{3} = 0.90$\n$p_{4} = 0.88$\n$p_{5} = 0.95$\n$p_{6} = 0.87$\n\n使用推导出的公式，期望接受概率是这些值的乘积：\n$$\nP_{\\text{accept}} = p_{1} \\times p_{2} \\times p_{3} \\times p_{4} \\times p_{5} \\times p_{6}\n$$\n$$\nP_{\\text{accept}} = 0.93 \\times 0.89 \\times 0.90 \\times 0.88 \\times 0.95 \\times 0.87\n$$\n计算此乘积得到：\n$$\nP_{\\text{accept}} \\approx 0.5418024876\n$$\n问题要求将此值四舍五入至 $4$ 位有效数字。前四位有效数字是 $5$、$4$、$1$ 和 $8$。第五位数字是 $0$，所以我们向下舍入。\n$$\nP_{\\text{accept}} \\approx 0.5418\n$$\n这表明，即使每个波段的边际覆盖率都很高（都接近 $0.90$），一个像素同时满足所有标准的概率也下降到了略高于 $0.54$。",
            "answer": "$$\n\\boxed{0.5418}\n$$"
        },
        {
            "introduction": "在遥感应用中，分类器不仅需要准确，还必须在计算上能够高效处理海量数据集。本练习  将焦点从统计性能转向计算性能。您将分析平行六面体和最小距离分类规则的算法复杂度，并评估现代计算架构下的优化策略，这对于将分析从小规模原型扩展到大规模生产系统至关重要。",
            "id": "3830387",
            "problem": "一名遥感分析师必须将一个包含 $N$ 个像素的大型场景进行分类，每个像素由一个 $d$ 维光谱向量 $\\mathbf{x} \\in \\mathbb{R}^{d}$ 表示，将其归入 $K$ 个土地覆盖类别之一。该分类使用两种在环境建模中常用的非参数决策规则。平行六面体规则假设类别 $k \\in \\{1,\\dots,K\\}$ 由每个波段的下限和上限阈值 $\\{L_{k,i},U_{k,i}\\}_{i=1}^{d}$ 定义，并声明当且仅当对于所有 $i \\in \\{1,\\dots,d\\}$ 都有 $L_{k,i} \\le x_i \\le U_{k,i}$ 时，$\\mathbf{x}$ 与类别 $k$ 一致。最小均值距离规则假设类别均值 $\\{\\boldsymbol{\\mu}_k\\}_{k=1}^{K}$ 在 $\\mathbb{R}^{d}$ 中是已知的，并将 $\\mathbf{x}$ 分配给使欧几里得距离 $\\|\\mathbf{x} - \\boldsymbol{\\mu}_k\\|_{2}$ 最小化的类别。假设在一个标准的单位成本模型中，基本浮点数比较、加法和乘法各自花费常数时间，并使用常规的大O表示法 $\\mathcal{O}(\\cdot)$ 来表示渐进成本。\n\n从第一性原理出发，通过计算每种规则定义所隐含的基本操作数量，推导出单个像素的运行时间如何随 $K$ 和 $d$ 变化的规模关系。然后，考虑在场景尺度（$N$ 很大）下的实现，并探讨改变常数与改变渐进复杂度的各种方法。根据您的推导，以下关于计算复杂度和可扩展实现的陈述中，哪些是正确的？选择所有适用的选项。\n\nA. 对于单个像素，使用平行六面体规则对所有 $K$ 个类别进行测试的最坏情况成本为 $\\mathcal{O}(K d)$ 次基本比较；因为每个波段需要将 $x_i$ 与 $L_{k,i}$ 和 $U_{k,i}$ 两者进行比较，所以每个类别最多有 $2d$ 次比较，并且当边界很紧时，短路拒绝可以降低平均成本。\n\nB. 对于采用最小均值距离规则的单个像素，如果计算欧几里得距离的平方并为所有 $k$ 预先存储 $\\|\\boldsymbol{\\mu}_k\\|_2^2$，则主要计算量减少为 $K$ 次点积 $\\mathbf{x}^{\\top}\\boldsymbol{\\mu}_k$，从而使每个像素的算术运算量为 $\\mathcal{O}(K d)$，并且公共项 $\\|\\mathbf{x}\\|_2^2$ 可以被舍弃而不会改变最小化距离的类别。\n\nC. 在 $K$ 个类别均值上构建空间索引（如 $k$-$d$ 树）可以保证精确最近均值分类的单像素最坏情况时间复杂度低于 $K$ 的线性，而与 $d$ 无关。\n\nD. 对于一个有 $N$ 个像素的场景，将像素排列成包含 $B$ 个像素的图块，并通过一个 $B \\times d$ 的图块矩阵和一个 $d \\times K$ 的均值矩阵之间的密集矩阵-矩阵乘法来计算一个图块的所有类别得分，由于更高的算术强度，这可以在现代图形处理单元（GPU）上显著减少实际运行时间，而渐进算术计数仍为 $\\mathcal{O}(N K d)$。\n\nE. 如果按每个波段对类别边界 $\\{L_{k,i},U_{k,i}\\}$ 进行预排序，平行六面体规则的单像素最坏情况复杂度将恰好变为 $\\mathcal{O}(d \\log K)$，因为可以在每个波段中通过二分搜索找到包含区间，然后对结果求交集。\n\nF. 任何将维度从 $d$ 降至 $d'  d$ 的正交线性变换（例如主成分分析PCA）都能精确保留所有成对的欧几里得距离；因此，最小距离分类结果不变，而每个像素的成本降至 $\\mathcal{O}(K d')$。\n\nG. 一种平行六面体测试的无分支实现，通过使用单指令多数据（SIMD）指令对跨波段和类别的向量化比较来累积布尔掩码，可以在不改变渐进 $\\mathcal{O}(K d)$ 单像素复杂度的情况下提高现代处理器的吞吐量。\n\nH. 在最小均值距离规则中，计算平方根对于避免决策偏差是必要的；省略平方根并比较距离的平方会改变最小化距离的类别，因此每个类别的成本除了 $\\mathcal{O}(d)$ 次乘加运算外，还必须包括一次平方根计算。",
            "solution": "我们从两种规则的定义和基本操作的单位成本模型开始。\n\n平行六面体规则：对于类别 $k$，隶属度测试要求对于所有 $i \\in \\{1,\\dots,d\\}$ 都有 $L_{k,i} \\le x_i \\le U_{k,i}$。对于一个固定的 $k$，在没有提前终止的情况下，这需要每个波段进行 2 次比较（$x_i \\ge L_{k,i}$ 和 $x_i \\le U_{k,i}$），总共需要 $2d$ 次比较。为了确定像素的类别，如果没有类别被提前接受，或者如果实现坚持检查所有类别以检测模糊性，那么必须对所有 $K$ 个类别评估此条件。因此，最坏情况下每个像素的比较次数为 $2 K d$，即 $\\mathcal{O}(K d)$。在实践中，短路评估可以在第一个不满足条件的波段出现后终止对该类别的评估，并且可以在满足接受策略后停止扫描类别，这可能减少平均比较次数，但不会改变最坏情况下的规模关系。\n\n最小均值距离规则：对于类别 $k$，欧几里得距离为 $\\|\\mathbf{x} - \\boldsymbol{\\mu}_k\\|_2 = \\sqrt{\\sum_{i=1}^{d} (x_i - \\mu_{k,i})^2}$。朴素地计算这个距离涉及每个类别 $d$ 次减法、$d$ 次平方（乘法）、$d-1$ 次加法和一次平方根运算。然而，由于平方根函数在 $[0,\\infty)$ 上是严格递增的，$\\|\\mathbf{x} - \\boldsymbol{\\mu}_k\\|_2$ 在 $k$ 上的最小化等同于平方距离 $\\|\\mathbf{x} - \\boldsymbol{\\mu}_k\\|_2^2 = \\sum_{i=1}^{d} (x_i - \\mu_{k,i})^2$ 的最小化。展开可得：\n$$\n\\|\\mathbf{x} - \\boldsymbol{\\mu}_k\\|_2^2 \\;=\\; \\mathbf{x}^{\\top}\\mathbf{x} - 2\\,\\boldsymbol{\\mu}_k^{\\top}\\mathbf{x} + \\boldsymbol{\\mu}_k^{\\top}\\boldsymbol{\\mu}_k.\n$$\n项 $\\mathbf{x}^{\\top}\\mathbf{x}$ 与 $k$ 无关，因此不影响对 $k$ 的 argmin（最小化参数）运算。如果我们为所有 $k$ 预先计算并存储 $\\boldsymbol{\\mu}_k^{\\top}\\boldsymbol{\\mu}_k$，则每个类别的计算就简化为评估点积 $\\boldsymbol{\\mu}_k^{\\top}\\mathbf{x}$（成本为 $\\mathcal{O}(d)$）和常数数量的标量运算。因此，每个像素的主要算术运算是 $K$ 次点积，总计为 $\\mathcal{O}(K d)$。\n\n扩展到包含 $N$ 个像素的场景：一个直接的逐像素循环对于最小距离规则会产生 $\\mathcal{O}(N K d)$ 次基本操作，对于平行六面体规则在最坏情况下会产生 $\\mathcal{O}(N K d)$ 次比较。改善内存局部性和向量化的实现策略可以减少常数并改善实际运行时间，同时保持渐进算术计数不变。例如，将像素分批成大小为 $B$ 的图块，并计算一个 $B \\times d$ 图块矩阵和 $d \\times K$ 类别均值矩阵之间的密集矩阵-矩阵乘积，可以以高算术强度和高效的缓存复用计算所有 $B \\cdot K$ 个点积，这非常适合图形处理单元（GPU）架构，但每个图块仍然执行 $\\Theta(B K d)$ 次乘加运算，保持了整体 $\\mathcal{O}(N K d)$ 的复杂度。\n\n我们现在逐一分析每个选项：\n\nA. 上述论证得出，在没有提前退出的情况下，每个类别需要 $2d$ 次比较，最多 $K$ 个类别，最坏情况为 $2 K d$ 次比较，即 $\\mathcal{O}(K d)$。短路拒绝是一种影响平均情况的有效常数因子优化。结论 — 正确。\n\nB. 通过展开欧几里得距离的平方，舍去常数项 $\\mathbf{x}^{\\top}\\mathbf{x}$，并预计算 $\\|\\boldsymbol{\\mu}_k\\|_2^2$，我们将每个类别的工作量减少为计算 $\\boldsymbol{\\mu}_k^{\\top}\\mathbf{x}$ 和少数几次标量运算，即每个类别 $\\mathcal{O}(d)$，每个像素 $\\mathcal{O}(K d)$。由于平方根函数是单调的，省略平方根不会改变最小化者的身份。结论 — 正确。\n\nC. 空间分割数据结构（如 $k$-$d$ 树）可以在低维空间为最近邻查询提供平均情况下的亚线性行为，但它们不能保证精确搜索的最坏情况时间是亚线性的；事实上，最坏情况下的查询会退化为访问 $\\Theta(K)$ 个节点，尤其是在 $d$ 增长时。因此，并不存在“与 $d$ 无关”的最坏情况亚线性保证。结论 — 错误。\n\nD. 将 $B$ 个像素块的计算转化为一个 $B \\times d$ 图块矩阵和一个 $d \\times K$ 均值矩阵之间的密集矩阵-矩阵乘法，这会执行恰好 $2 B K d$ 次浮点运算（计算乘加操作），并利用图形处理单元（GPU）上的高性能内核，通常能大幅减少实际运行时间。然而，算术计数仍然与 $N K d$ 成正比。结论 — 正确。\n\nE. 按每个波段预排序区间允许通过二分搜索在每个波段以 $\\mathcal{O}(\\log K)$ 的时间识别出包含 $x_i$ 的候选类别，但最终决策需要对 $d$ 个波段的候选集合求交集。在最坏情况下，每个波段之后可能仍有许多或所有类别是候选者（例如，如果大多数区间都很宽），这会迫使进行 $\\Theta(K d)$ 次检查。因此，无法保证 $\\mathcal{O}(d \\log K)$ 的最坏情况界限。结论 — 错误。\n\nF. 除非所有感兴趣的向量都位于该 $d'$ 维子空间内，否则将维度降至 $d'  d$ 的正交变换无法精确保留所有欧几里得距离。主成分分析（PCA）在截断时只能近似保留距离。因此，降维会改变最小距离决策的结果，尽管每个像素的成本会降至 $\\mathcal{O}(K d')$。结论 — 错误。\n\nG. 以无分支、向量化的方式实现平行六面体测试——例如，使用单指令多数据（SIMD）并行评估多个波段和类别的比较，并通过位运算组合结果——可以通过减少分支预测失误和增加数据级并行性来提高吞吐量。这种优化不会改变渐进的 $\\mathcal{O}(K d)$ 比较计数。结论 — 正确。\n\nH. 因为平方根在非负实数上是严格递增的，所以 $\\|\\mathbf{x} - \\boldsymbol{\\mu}_k\\|_2$ 的最小化者与 $\\|\\mathbf{x} - \\boldsymbol{\\mu}_k\\|_2^2$ 的最小化者相同。因此，对于分类决策而言，计算平方根是不必要的，只会增加开销。结论 — 错误。\n\n正确的选项是 A、B、D 和 G。",
            "answer": "$$\\boxed{ABDG}$$"
        }
    ]
}