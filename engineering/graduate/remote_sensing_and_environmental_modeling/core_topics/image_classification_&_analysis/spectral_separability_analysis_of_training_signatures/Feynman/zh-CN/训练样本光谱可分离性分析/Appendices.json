{
    "hands_on_practices": [
        {
            "introduction": "在分析光谱可分离性之前，我们必须首先从训练数据中估计每个地物类别的统计特性。该练习  提供了一个基础实践，用于推导作为类别模型基本构建块的均值向量和协方差矩阵的最大似然估计。它还引导我们直面遥感领域的一个关键问题：当训练数据稀缺时，这些估计的可靠性。",
            "id": "3853753",
            "problem": "在用于环境建模的多光谱遥感中，光谱可分性分析依赖于从已标记像素估计的类条件训练特征。考虑一个索引为 $i$ 的特定地物类别，您拥有 $N_i$ 个已标记的 $d$ 维光谱向量 $\\{\\mathbf{x}_n\\}_{n=1}^{N_i}$，这些向量假定独立同分布于一个均值为 $\\boldsymbol{\\mu}_i \\in \\mathbb{R}^d$、协方差矩阵为正定矩阵 $\\boldsymbol{\\Sigma}_i \\in \\mathbb{R}^{d \\times d}$ 的 $d$ 维正态（高斯）分布。多元正态概率密度函数为\n$$\np(\\mathbf{x}\\mid \\boldsymbol{\\mu}_i,\\boldsymbol{\\Sigma}_i)=\\frac{1}{(2\\pi)^{d/2}|\\boldsymbol{\\Sigma}_i|^{1/2}}\\exp\\!\\left(-\\frac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu}_i)^{\\top}\\boldsymbol{\\Sigma}_i^{-1}(\\mathbf{x}-\\boldsymbol{\\mu}_i)\\right).\n$$\n从最大似然原理和上述密度函数出发，仅使用已标记样本 $\\{\\mathbf{x}_n\\}_{n=1}^{N_i}$ 来推导 $\\boldsymbol{\\mu}_i$ 和 $\\boldsymbol{\\Sigma}_i$ 的最大似然估计。然后，利用多元正态分布和 Wishart 分布的性质，分析在 $N_i$ 有限的情况下协方差估计的偏差，并阐述一个在正态性假设下的偏差校正估计量，评论当 $N_i$ 相对于 $d$ 较小时其行为以及对光谱可分性分析的影响。\n\n您的最终答案必须是 $\\boldsymbol{\\mu}_i$ 和 $\\boldsymbol{\\Sigma}_i$ 的最大似然估计的闭式解析表达式对，按此顺序以单个行向量的两个条目形式呈现。不要包含任何解释性文字，并且在最终答案中不要包含等号。无需四舍五入。",
            "solution": "该问题具有科学依据、是适定的，并包含推导最大似然估计及其性质分析所需的所有信息。这是多元统计学中的一个标准问题，在遥感领域有直接且重要的应用。因此，该问题是有效的，下面给出完整解法。\n\n目标是根据 $N_i$ 个独立同分布 (i.i.d.) 的样本 $\\{\\mathbf{x}_n\\}_{n=1}^{N_i}$，求出 $d$ 维正态分布的均值向量 $\\boldsymbol{\\mu}_i$ 和协方差矩阵 $\\boldsymbol{\\Sigma}_i$ 的最大似然估计 (MLE)。\n\n首先，我们构建似然函数。由于样本是独立同分布的，似然函数是每个样本的概率密度函数的乘积：\n$$\nL(\\boldsymbol{\\mu}_i, \\boldsymbol{\\Sigma}_i \\mid \\{\\mathbf{x}_n\\}) = \\prod_{n=1}^{N_i} p(\\mathbf{x}_n\\mid \\boldsymbol{\\mu}_i,\\boldsymbol{\\Sigma}_i) = \\prod_{n=1}^{N_i} \\frac{1}{(2\\pi)^{d/2}|\\boldsymbol{\\Sigma}_i|^{1/2}}\\exp\\!\\left(-\\frac{1}{2}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)^{\\top}\\boldsymbol{\\Sigma}_i^{-1}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)\\right)\n$$\n最大化似然函数等价于最大化其自然对数，即对数似然函数 $\\ell = \\ln L$。取对数将乘积简化为求和：\n$$\n\\ell(\\boldsymbol{\\mu}_i, \\boldsymbol{\\Sigma}_i) = \\ln \\left( \\prod_{n=1}^{N_i} \\left[ (2\\pi)^{-d/2}|\\boldsymbol{\\Sigma}_i|^{-1/2} \\exp\\!\\left(-\\frac{1}{2}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)^{\\top}\\boldsymbol{\\Sigma}_i^{-1}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)\\right) \\right] \\right)\n$$\n$$\n\\ell(\\boldsymbol{\\mu}_i, \\boldsymbol{\\Sigma}_i) = \\sum_{n=1}^{N_i} \\left( -\\frac{d}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\boldsymbol{\\Sigma}_i| - \\frac{1}{2}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)^{\\top}\\boldsymbol{\\Sigma}_i^{-1}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i) \\right)\n$$\n$$\n\\ell(\\boldsymbol{\\mu}_i, \\boldsymbol{\\Sigma}_i) = -\\frac{N_i d}{2}\\ln(2\\pi) - \\frac{N_i}{2}\\ln|\\boldsymbol{\\Sigma}_i| - \\frac{1}{2}\\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)^{\\top}\\boldsymbol{\\Sigma}_i^{-1}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)\n$$\n为了求得最大似然估计，我们对 $\\ell$ 分别关于 $\\boldsymbol{\\mu}_i$ 和 $\\boldsymbol{\\Sigma}_i$ 求偏导数，并令其为零。\n\n**均值 $\\boldsymbol{\\mu}_i$ 的最大似然估计**\n\n我们计算 $\\ell$ 关于 $\\boldsymbol{\\mu}_i$ 的梯度。只有求和项依赖于 $\\boldsymbol{\\mu}_i$。对于对称矩阵 $\\mathbf{A}$，使用标准矩阵微积分恒等式 $\\frac{\\partial}{\\partial\\mathbf{v}} (\\mathbf{x}-\\mathbf{v})^{\\top}\\mathbf{A}(\\mathbf{x}-\\mathbf{v}) = -2\\mathbf{A}(\\mathbf{x}-\\mathbf{v})$：\n$$\n\\frac{\\partial \\ell}{\\partial \\boldsymbol{\\mu}_i} = -\\frac{1}{2}\\sum_{n=1}^{N_i} \\frac{\\partial}{\\partial \\boldsymbol{\\mu}_i}\\left( (\\mathbf{x}_n-\\boldsymbol{\\mu}_i)^{\\top}\\boldsymbol{\\Sigma}_i^{-1}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i) \\right) = -\\frac{1}{2}\\sum_{n=1}^{N_i} \\left( -2\\boldsymbol{\\Sigma}_i^{-1}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i) \\right) = \\boldsymbol{\\Sigma}_i^{-1} \\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)\n$$\n将梯度设为零向量：\n$$\n\\boldsymbol{\\Sigma}_i^{-1} \\left( \\sum_{n=1}^{N_i}\\mathbf{x}_n - N_i\\boldsymbol{\\mu}_i \\right) = \\mathbf{0}\n$$\n由于 $\\boldsymbol{\\Sigma}_i$ 是正定的，其逆矩阵 $\\boldsymbol{\\Sigma}_i^{-1}$ 存在且也是正定的，因此是可逆的。我们可以两边乘以 $\\boldsymbol{\\Sigma}_i$ 得到：\n$$\n\\sum_{n=1}^{N_i}\\mathbf{x}_n - N_i\\boldsymbol{\\mu}_i = \\mathbf{0} \\implies N_i\\boldsymbol{\\mu}_i = \\sum_{n=1}^{N_i}\\mathbf{x}_n\n$$\n均值的最大似然估计，记作 $\\hat{\\boldsymbol{\\mu}}_i$，即为样本均值：\n$$\n\\hat{\\boldsymbol{\\mu}}_i = \\frac{1}{N_i}\\sum_{n=1}^{N_i}\\mathbf{x}_n\n$$\n\n**协方差矩阵 $\\boldsymbol{\\Sigma}_i$ 的最大似然估计**\n\n接下来，我们对 $\\ell$ 关于 $\\boldsymbol{\\Sigma}_i$ 求导。更方便的做法是关于逆协方差矩阵（或精度矩阵）$\\mathbf{\\Lambda}_i = \\boldsymbol{\\Sigma}_i^{-1}$ 求导。我们使用 $\\ln|\\boldsymbol{\\Sigma}_i| = -\\ln|\\mathbf{\\Lambda}_i|$ 和迹的循环性质 $(\\mathbf{v}^\\top\\mathbf{A}\\mathbf{v} = \\text{tr}(\\mathbf{A}\\mathbf{v}\\mathbf{v}^\\top))$ 重写对数似然函数：\n$$\n\\ell(\\hat{\\boldsymbol{\\mu}}_i, \\mathbf{\\Lambda}_i) = C + \\frac{N_i}{2}\\ln|\\mathbf{\\Lambda}_i| - \\frac{1}{2}\\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)^{\\top}\\mathbf{\\Lambda}_i(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)\n$$\n$$\n\\ell(\\hat{\\boldsymbol{\\mu}}_i, \\mathbf{\\Lambda}_i) = C + \\frac{N_i}{2}\\ln|\\mathbf{\\Lambda}_i| - \\frac{1}{2}\\text{tr}\\left( \\mathbf{\\Lambda}_i \\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)^{\\top} \\right)\n$$\n我们定义散布矩阵 $\\mathbf{S} = \\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)^{\\top}$。\n使用恒等式 $\\frac{\\partial \\ln|\\mathbf{A}|}{\\partial \\mathbf{A}} = (\\mathbf{A}^{-1})^\\top$ 和 $\\frac{\\partial \\text{tr}(\\mathbf{A}\\mathbf{B})}{\\partial \\mathbf{A}} = \\mathbf{B}^\\top$：\n$$\n\\frac{\\partial \\ell}{\\partial \\mathbf{\\Lambda}_i} = \\frac{N_i}{2}(\\mathbf{\\Lambda}_i^{-1})^\\top - \\frac{1}{2}\\mathbf{S}^\\top\n$$\n由于 $\\mathbf{\\Lambda}_i$ 和 $\\mathbf{S}$ 都是对称的，我们有：\n$$\n\\frac{\\partial \\ell}{\\partial \\mathbf{\\Lambda}_i} = \\frac{N_i}{2}\\mathbf{\\Lambda}_i^{-1} - \\frac{1}{2}\\mathbf{S}\n$$\n设为零矩阵并回顾 $\\mathbf{\\Lambda}_i^{-1} = \\boldsymbol{\\Sigma}_i$：\n$$\n\\frac{N_i}{2}\\boldsymbol{\\Sigma}_i - \\frac{1}{2}\\mathbf{S} = \\mathbf{0} \\implies \\boldsymbol{\\Sigma}_i = \\frac{1}{N_i}\\mathbf{S}\n$$\n协方差矩阵的最大似然估计，记作 $\\hat{\\boldsymbol{\\Sigma}}_i$，为：\n$$\n\\hat{\\boldsymbol{\\Sigma}}_i = \\frac{1}{N_i}\\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)^{\\top}\n$$\n\n**协方差估计量的偏差分析**\n\n为分析 $\\hat{\\boldsymbol{\\Sigma}}_i$ 的偏差，我们计算其期望值。设真实（但未知）的参数为 $\\boldsymbol{\\mu}_i$ 和 $\\boldsymbol{\\Sigma}_i$。\n$$\nE[\\hat{\\boldsymbol{\\Sigma}}_i] = E\\left[\\frac{1}{N_i}\\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)^{\\top}\\right]\n$$\n我们代入 $\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i = (\\mathbf{x}_n-\\boldsymbol{\\mu}_i) - (\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)$：\n$$\n\\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)^{\\top} = \\sum_{n=1}^{N_i} \\left[ (\\mathbf{x}_n-\\boldsymbol{\\mu}_i)(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)^\\top - (\\mathbf{x}_n-\\boldsymbol{\\mu}_i)(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)^\\top - (\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)^\\top + (\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)^\\top \\right]\n$$\n对各项求和并使用 $\\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i) = N_i(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)$：\n$$\n= \\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)^\\top - N_i(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)^\\top - N_i(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)^\\top + N_i(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)^\\top\n$$\n$$\n= \\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)^\\top - N_i(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)^\\top\n$$\n现在我们取期望。第一项的期望为 $\\sum_{n=1}^{N_i} E[(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)(\\mathbf{x}_n-\\boldsymbol{\\mu}_i)^\\top] = \\sum_{n=1}^{N_i} \\boldsymbol{\\Sigma}_i = N_i \\boldsymbol{\\Sigma}_i$。\n第二项的期望涉及样本均值的协方差：$E[(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)^\\top] = \\text{Cov}(\\hat{\\boldsymbol{\\mu}}_i) = \\text{Cov}(\\frac{1}{N_i}\\sum \\mathbf{x}_n) = \\frac{1}{N_i^2}\\sum\\text{Cov}(\\mathbf{x}_n) = \\frac{N_i}{N_i^2}\\boldsymbol{\\Sigma}_i = \\frac{1}{N_i}\\boldsymbol{\\Sigma}_i$。\n因此，$E[N_i(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)(\\hat{\\boldsymbol{\\mu}}_i-\\boldsymbol{\\mu}_i)^\\top] = N_i (\\frac{1}{N_i}\\boldsymbol{\\Sigma}_i) = \\boldsymbol{\\Sigma}_i$。\n将它们放在一起：\n$$\nE[N_i \\hat{\\boldsymbol{\\Sigma}}_i] = N_i \\boldsymbol{\\Sigma}_i - \\boldsymbol{\\Sigma}_i = (N_i-1)\\boldsymbol{\\Sigma}_i\n$$\n$$\nE[\\hat{\\boldsymbol{\\Sigma}}_i] = \\frac{N_i-1}{N_i}\\boldsymbol{\\Sigma}_i\n$$\n这表明协方差的最大似然估计是有偏的。偏差为 $E[\\hat{\\boldsymbol{\\Sigma}}_i] - \\boldsymbol{\\Sigma}_i = -\\frac{1}{N_i}\\boldsymbol{\\Sigma}_i$。该估计量系统地低估了真实的协方差。\n\n**偏差校正估计量及其影响**\n\n根据偏差的计算，我们可以通过将最大似然估计乘以一个因子 $\\frac{N_i}{N_i-1}$ 来构造一个无偏估计量。这就得到了我们熟悉的样本协方差矩阵，我们称之为 $\\mathbf{S}_i$：\n$$\n\\mathbf{S}_i = \\frac{N_i}{N_i-1}\\hat{\\boldsymbol{\\Sigma}}_i = \\frac{1}{N_i-1}\\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)^{\\top}\n$$\n这个估计量是无偏的，即 $E[\\mathbf{S}_i] = \\boldsymbol{\\Sigma}_i$。\n\n当样本数量 $N_i$ 相对于维度 $d$ 较小时，我们会遇到一个关键问题。散布矩阵 $\\mathbf{S} = \\sum_{n=1}^{N_i}(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)(\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i)^{\\top}$ 是 $N_i$ 个矩阵的和，每个矩阵的秩最多为1。此外，向量集 $\\{\\mathbf{x}_n-\\hat{\\boldsymbol{\\mu}}_i\\}_{n=1}^{N_i}$ 是线性相关的，因为它们的和为零向量，因此张成一个维度最多为 $N_i-1$ 的子空间。因此，散布矩阵的秩（以及 $\\hat{\\boldsymbol{\\Sigma}}_i$ 和 $\\mathbf{S}_i$ 的秩）最多为 $\\min(d, N_i-1)$。\n如果 $N_i-1  d$（或更一般地 $N_i \\le d$），估计的协方差矩阵 $\\mathbf{S}_i$ 将是奇异的（秩亏的）。\n\n这对光谱可分性分析有严重的影响：\n1.  **可逆性失效**：许多分类器（例如，二次判别分析）和可分性度量（例如，Mahalanobis 距离、Bhattacharyya 距离）需要计算协方差矩阵的逆 $\\boldsymbol{\\Sigma}_i^{-1}$。一个奇异的估计 $\\mathbf{S}_i$ 没有逆矩阵，导致这些方法完全失效。\n2.  **退化模型**：奇异的协方差矩阵意味着估计的高斯分布是退化的，其概率质量集中在 $\\mathbb{R}^d$ 的一个低维子空间上。这是数据不足造成的人为结果，而不是底层地物类别的真实属性。\n3.  **高方差**：即使当 $N_i$ 略大于 $d$ 时，估计 $\\mathbf{S}_i$ 通常也是数值上病态的（接近奇异），其元素具有非常高的方差。这使得估计的类别特征不可靠，并导致分类器的泛化性能不佳。\n\n这是“维度灾难”在高维小样本场景下的一种体现，也是遥感中的一个常见问题。为了缓解这个问题，必须采用诸如正则化（例如，收缩）、降维或使用更简单的协方差模型（例如，对角协方差或汇集协方差）等技术。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{N_i} \\sum_{n=1}^{N_i} \\mathbf{x}_n  \\frac{1}{N_i} \\sum_{n=1}^{N_i} \\left(\\mathbf{x}_n - \\frac{1}{N_i}\\sum_{m=1}^{N_i} \\mathbf{x}_m\\right)\\left(\\mathbf{x}_n - \\frac{1}{N_i}\\sum_{m=1}^{N_i} \\mathbf{x}_m\\right)^{\\top} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "一旦我们为各个类别建立了统计模型，下一步就是量化它们在光谱空间中的“可分离”程度。该实践  介绍了一种强大的可分离性度量——巴氏 (Bhattacharyya) 距离。你将为一个常见场景推导其闭合形式表达式，并将其应用于一个数值示例，从而对类别方差和协方差结构如何影响可分离性获得更深刻的几何理解。",
            "id": "3853814",
            "problem": "在用于监督土地覆盖制图的光谱可分性分析中，两个类别的训练光谱特征通常被建模为跨越 $d$ 个光谱波段的多元高斯分布。考虑两个土地覆盖类别：季节性淹没草地 (SFG) 和灌溉稻田 (IRP)，每个类别由一个 $d$ 维多元正态密度 $p_{i}(\\mathbf{x})$ 表示，其均值为 $\\boldsymbol{\\mu}_{i} \\in \\mathbb{R}^{d}$，协方差为 $\\boldsymbol{\\Sigma}_{i} \\in \\mathbb{R}^{d \\times d}$，其中 $i \\in \\{1,2\\}$。一种广泛使用的可分性度量是巴氏 (Bhattacharyya) 距离 (B)，它由巴氏系数 (Bhattacharyya coefficient) $\\mathrm{BC}$ 定义为 $B = -\\ln(\\mathrm{BC})$，其中巴氏系数由重叠积分 $\\mathrm{BC} = \\int_{\\mathbb{R}^{d}} \\sqrt{p_{1}(\\mathbf{x}) p_{2}(\\mathbf{x})} \\, d\\mathbf{x}$ 给出。\n\n从这些定义和多元正态密度的标准形式出发，在等协方差假设 $\\boldsymbol{\\Sigma}_{1} = \\boldsymbol{\\Sigma}_{2} = \\boldsymbol{\\Sigma}$ 下，推导 $B$ 的闭式表达式。然后，利用 $\\boldsymbol{\\Sigma}$ 的特征分解，分析 $\\boldsymbol{\\Sigma}$ 中的各向异性如何影响沿不同光谱方向的可分性。\n\n最后，对以下三波段反射率特征（波段依次为绿光、红光和近红外）进行 $B$ 的数值计算：$\\boldsymbol{\\mu}_{1} = \\begin{pmatrix} 0.08 \\\\ 0.06 \\\\ 0.32 \\end{pmatrix}$，$\\boldsymbol{\\mu}_{2} = \\begin{pmatrix} 0.10 \\\\ 0.05 \\\\ 0.36 \\end{pmatrix}$，以及 $\\boldsymbol{\\Sigma} = \\operatorname{diag}\\!\\big(0.01, 0.02, 0.09\\big)$。将您最终的 $B$ 数值答案表示为一个无量纲实数，并四舍五入到四位有效数字。",
            "solution": "所述问题需经过验证过程，以确保其科学性和逻辑的严谨性。\n\n### 第1步：提取已知条件\n-   两个土地覆盖类别被建模为 $d$ 维多元正态密度 $p_{i}(\\mathbf{x})$，其中 $i \\in \\{1,2\\}$。\n-   类别 $i$ 的概率密度函数为 $p_{i}(\\mathbf{x}) \\sim \\mathcal{N}(\\boldsymbol{\\mu}_{i}, \\boldsymbol{\\Sigma}_{i})$，其中 $\\boldsymbol{\\mu}_{i} \\in \\mathbb{R}^{d}$ 是均值向量，$\\boldsymbol{\\Sigma}_{i} \\in \\mathbb{R}^{d \\times d}$ 是协方差矩阵。\n-   Bhattacharyya 距离 $B$ 定义为 $B = -\\ln(\\mathrm{BC})$。\n-   Bhattacharyya 系数 $\\mathrm{BC}$ 由积分 $\\mathrm{BC} = \\int_{\\mathbb{R}^{d}} \\sqrt{p_{1}(\\mathbf{x}) p_{2}(\\mathbf{x})} \\, d\\mathbf{x}$ 定义。\n-   假设协方差相等：$\\boldsymbol{\\Sigma}_{1} = \\boldsymbol{\\Sigma}_{2} = \\boldsymbol{\\Sigma}$。\n-   任务1：在等协方差假设下，推导 $B$ 的闭式表达式。\n-   任务2：利用 $\\boldsymbol{\\Sigma}$ 的特征分解，分析 $\\boldsymbol{\\Sigma}$ 中的各向异性如何影响可分性。\n-   任务3：针对特定情况进行 $B$ 的数值计算：\n    -   波段数 $d=3$。\n    -   均值向量：$\\boldsymbol{\\mu}_{1} = \\begin{pmatrix} 0.08 \\\\ 0.06 \\\\ 0.32 \\end{pmatrix}$ 和 $\\boldsymbol{\\mu}_{2} = \\begin{pmatrix} 0.10 \\\\ 0.05 \\\\ 0.36 \\end{pmatrix}$。\n    -   协方差矩阵：$\\boldsymbol{\\Sigma} = \\operatorname{diag}\\!\\big(0.01, 0.02, 0.09\\big)$。\n    -   最终的 $B$ 数值答案应为一个无量纲实数，并四舍五入到四位有效数字。\n\n### 第2步：使用提取的已知条件进行验证\n根据既定标准对问题进行评估：\n-   **科学依据充分：** 该问题牢固地植根于统计模式识别及其在遥感中的应用，这是环境科学和地理学中的标准实践。使用多元正态分布对光谱特征进行建模，以及使用Bhattacharyya距离作为可分性度量，都是公认的成熟方法。\n-   **适定性：** 该问题提供了推导所求表达式、进行分析和计算数值结果所需的所有必要定义、数据和约束。问题清晰明确，能够导出一个唯一、稳定且有意义的解。\n-   **客观性：** 问题采用精确、形式化的数学和科学语言陈述，没有任何主观性或偏见。\n\n### 第3步：结论与行动\n该问题被判定为**有效**。它具有科学合理性、适定性和客观性，不包含任何逻辑矛盾、信息缺失或不科学的前提。因此，可以继续进行求解过程。\n\n### Bhattacharyya 距离的推导\n\n类别 $i$ 的 $d$ 维多元正态分布的概率密度函数由下式给出：\n$$\np_{i}(\\mathbf{x}) = \\frac{1}{(2\\pi)^{d/2} |\\boldsymbol{\\Sigma}_i|^{1/2}} \\exp\\left( -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu}_i)^T \\boldsymbol{\\Sigma}_i^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_i) \\right)\n$$\n在协方差矩阵相等，即 $\\boldsymbol{\\Sigma}_1 = \\boldsymbol{\\Sigma}_2 = \\boldsymbol{\\Sigma}$ 的假设下，密度函数为：\n$$\np_{1}(\\mathbf{x}) = \\frac{1}{(2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}} \\exp\\left( -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu}_1)^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_1) \\right)\n$$\n$$\np_{2}(\\mathbf{x}) = \\frac{1}{(2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}} \\exp\\left( -\\frac{1}{2} (\\mathbf{x} - \\boldsymbol{\\mu}_2)^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_2) \\right)\n$$\nBhattacharyya 系数 $\\mathrm{BC}$ 需要计算几何平均值 $\\sqrt{p_{1}(\\mathbf{x}) p_{2}(\\mathbf{x})}$：\n$$\n\\sqrt{p_{1}(\\mathbf{x}) p_{2}(\\mathbf{x})} = \\frac{1}{(2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}} \\exp\\left( -\\frac{1}{4} \\left[ (\\mathbf{x} - \\boldsymbol{\\mu}_1)^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_1) + (\\mathbf{x} - \\boldsymbol{\\mu}_2)^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_2) \\right] \\right)\n$$\n让我们分析指数中的项。令 $Q(\\mathbf{x}) = (\\mathbf{x} - \\boldsymbol{\\mu}_1)^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_1) + (\\mathbf{x} - \\boldsymbol{\\mu}_2)^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_2)$。展开并合并关于 $\\mathbf{x}$ 的项得到：\n$$\nQ(\\mathbf{x}) = 2\\mathbf{x}^T \\boldsymbol{\\Sigma}^{-1} \\mathbf{x} - 2\\mathbf{x}^T \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_1 + \\boldsymbol{\\mu}_2) + \\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_1 + \\boldsymbol{\\mu}_2^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_2\n$$\n我们对包含 $\\mathbf{x}$ 的项进行配方。令 $\\boldsymbol{\\mu}' = \\frac{\\boldsymbol{\\mu}_1 + \\boldsymbol{\\mu}_2}{2}$。二次型可以表示为：\n$$\n2(\\mathbf{x} - \\boldsymbol{\\mu}')^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}') = 2\\mathbf{x}^T \\boldsymbol{\\Sigma}^{-1} \\mathbf{x} - 2\\mathbf{x}^T \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_1+\\boldsymbol{\\mu}_2) + 2(\\boldsymbol{\\mu}')^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}'\n$$\n将此代入 $Q(\\mathbf{x})$ 的表达式中：\n$$\nQ(\\mathbf{x}) = 2(\\mathbf{x} - \\boldsymbol{\\mu}')^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}') + \\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_1 + \\boldsymbol{\\mu}_2^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_2 - 2(\\boldsymbol{\\mu}')^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}'\n$$\n常数项简化为：\n$$\n\\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_1 + \\boldsymbol{\\mu}_2^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_2 - 2\\left(\\frac{\\boldsymbol{\\mu}_1 + \\boldsymbol{\\mu}_2}{2}\\right)^T \\boldsymbol{\\Sigma}^{-1} \\left(\\frac{\\boldsymbol{\\mu}_1 + \\boldsymbol{\\mu}_2}{2}\\right)\n= \\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_1 + \\boldsymbol{\\mu}_2^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_2 - \\frac{1}{2}(\\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_1 + 2\\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_2 + \\boldsymbol{\\mu}_2^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_2)\n$$\n$$\n= \\frac{1}{2}(\\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_1 - 2\\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_2 + \\boldsymbol{\\mu}_2^T \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_2) = \\frac{1}{2}(\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)^T \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)\n$$\n几何平均值中的指数变为：\n$$\n-\\frac{1}{4}Q(\\mathbf{x}) = -\\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu}')^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}') - \\frac{1}{8}(\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)^T \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)\n$$\n因此，Bhattacharyya 系数的积分为：\n$$\n\\mathrm{BC} = \\int_{\\mathbb{R}^{d}} \\frac{1}{(2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}} \\exp\\left(-\\frac{1}{8}(\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)^T \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)\\right) \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu}')^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}')\\right) d\\mathbf{x}\n$$\n常数项可以从积分中提出：\n$$\n\\mathrm{BC} = \\exp\\left(-\\frac{1}{8}(\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)^T \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)\\right) \\int_{\\mathbb{R}^{d}} \\frac{1}{(2\\pi)^{d/2} |\\boldsymbol{\\Sigma}|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu}')^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}')\\right) d\\mathbf{x}\n$$\n剩余的积分是一个多元正态概率密度 $\\mathcal{N}(\\boldsymbol{\\mu}', \\boldsymbol{\\Sigma})$ 在其整个定义域 $\\mathbb{R}^d$ 上的积分，其值等于 $1$。因此：\n$$\n\\mathrm{BC} = \\exp\\left(-\\frac{1}{8}(\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)^T \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)\\right)\n$$\n于是，Bhattacharyya 距离 $B = -\\ln(\\mathrm{BC})$ 为：\n$$\nB = \\frac{1}{8}(\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)^T \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2)\n$$\n该表达式是两个均值向量 $\\boldsymbol{\\mu}_1$ 和 $\\boldsymbol{\\mu}_2$ 之间马氏距离 (Mahalanobis distance) 平方的 $\\frac{1}{8}$。\n\n### 各向异性分析\n为分析 $\\boldsymbol{\\Sigma}$ 中的各向异性如何影响可分性，我们对对称正定协方差矩阵 $\\boldsymbol{\\Sigma}$ 进行特征分解：\n$$\n\\boldsymbol{\\Sigma} = \\mathbf{V} \\mathbf{\\Lambda} \\mathbf{V}^T\n$$\n其中 $\\mathbf{V}$ 是一个正交矩阵，其列是 $\\boldsymbol{\\Sigma}$ 的特征向量 $\\mathbf{v}_j$，$\\mathbf{\\Lambda}$ 是由相应正特征值 $\\lambda_j$ 构成的对角矩阵。其逆矩阵为 $\\boldsymbol{\\Sigma}^{-1} = \\mathbf{V} \\mathbf{\\Lambda}^{-1} \\mathbf{V}^T$。令 $\\Delta\\boldsymbol{\\mu} = \\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2$。将该分解代入 $B$ 的表达式中：\n$$\nB = \\frac{1}{8}(\\Delta\\boldsymbol{\\mu})^T (\\mathbf{V} \\mathbf{\\Lambda}^{-1} \\mathbf{V}^T) (\\Delta\\boldsymbol{\\mu}) = \\frac{1}{8} (\\mathbf{V}^T \\Delta\\boldsymbol{\\mu})^T \\mathbf{\\Lambda}^{-1} (\\mathbf{V}^T \\Delta\\boldsymbol{\\mu})\n$$\n令 $\\mathbf{c} = \\mathbf{V}^T \\Delta\\boldsymbol{\\mu}$。$\\mathbf{c}$ 的分量为 $c_j = \\mathbf{v}_j^T \\Delta\\boldsymbol{\\mu}$，表示均值差向量 $\\Delta\\boldsymbol{\\mu}$ 在每个特征向量 $\\mathbf{v}_j$ 上的投影。$B$ 的表达式变为：\n$$\nB = \\frac{1}{8} \\mathbf{c}^T \\mathbf{\\Lambda}^{-1} \\mathbf{c} = \\frac{1}{8} \\sum_{j=1}^{d} \\frac{c_j^2}{\\lambda_j}\n$$\n这种形式揭示了各向异性（不均匀的特征值）如何影响可分性：\n-   总可分性 $B$ 是均值差向量的平方分量的加权和，这些分量是沿着协方差结构的主轴（特征向量）定义的。\n-   每个分量的权重是相应特征值的倒数，$1/\\lambda_j$。特征值 $\\lambda_j$ 表示数据沿轴 $\\mathbf{v}_j$ 的方差。\n-   较小的特征值 $\\lambda_j$ 意味着沿方向 $\\mathbf{v}_j$ 的方差较小（即数据簇在该方向上“较窄”）。其倒数 $1/\\lambda_j$ 较大。因此，沿此方向的均值分离（$c_j \\neq 0$）对总可分性 $B$ 的贡献很大。\n-   相反，较大的特征值 $\\lambda_k$ 意味着沿方向 $\\mathbf{v}_k$ 的方差较大（数据簇在该方向上“较宽”）。其倒数 $1/\\lambda_k$ 较小。沿此高方差方向的均值分离对 $B$ 的贡献极小。\n-   因此，$\\boldsymbol{\\Sigma}$ 中的各向异性使得可分性高度依赖于方向。方差最低的光谱方向对于区分不同类别最为关键。\n\n### 数值计算\n\n给定 $d=3$，$\\boldsymbol{\\mu}_{1} = \\begin{pmatrix} 0.08 \\\\ 0.06 \\\\ 0.32 \\end{pmatrix}$，$\\boldsymbol{\\mu}_{2} = \\begin{pmatrix} 0.10 \\\\ 0.05 \\\\ 0.36 \\end{pmatrix}$，以及 $\\boldsymbol{\\Sigma} = \\operatorname{diag}\\!\\big(0.01, 0.02, 0.09\\big)$。\n\n首先，我们计算均值向量之差 $\\Delta\\boldsymbol{\\mu}$：\n$$\n\\Delta\\boldsymbol{\\mu} = \\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{2} = \\begin{pmatrix} 0.08 - 0.10 \\\\ 0.06 - 0.05 \\\\ 0.32 - 0.36 \\end{pmatrix} = \\begin{pmatrix} -0.02 \\\\ 0.01 \\\\ -0.04 \\end{pmatrix}\n$$\n接下来，我们求协方差矩阵的逆矩阵 $\\boldsymbol{\\Sigma}^{-1}$。由于 $\\boldsymbol{\\Sigma}$ 是对角矩阵，其逆矩阵是对角线上元素取倒数后形成的对角矩阵：\n$$\n\\boldsymbol{\\Sigma}^{-1} = \\operatorname{diag}\\!\\left(\\frac{1}{0.01}, \\frac{1}{0.02}, \\frac{1}{0.09}\\right) = \\operatorname{diag}\\!\\left(100, 50, \\frac{100}{9}\\right)\n$$\n现在，我们计算二次型 $(\\Delta\\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\Delta\\boldsymbol{\\mu})$：\n$$\n(\\Delta\\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma}^{-1} (\\Delta\\boldsymbol{\\mu}) = \\begin{pmatrix} -0.02  0.01  -0.04 \\end{pmatrix} \\begin{pmatrix} 100  0  0 \\\\ 0  50  0 \\\\ 0  0  \\frac{100}{9} \\end{pmatrix} \\begin{pmatrix} -0.02 \\\\ 0.01 \\\\ -0.04 \\end{pmatrix}\n$$\n$$\n= (-0.02)(100)(-0.02) + (0.01)(50)(0.01) + (-0.04)\\left(\\frac{100}{9}\\right)(-0.04)\n$$\n$$\n= \\frac{(-0.02)^2}{0.01} + \\frac{(0.01)^2}{0.02} + \\frac{(-0.04)^2}{0.09}\n$$\n$$\n= \\frac{0.0004}{0.01} + \\frac{0.0001}{0.02} + \\frac{0.0016}{0.09}\n$$\n$$\n= 0.04 + 0.005 + \\frac{16}{900} = 0.045 + \\frac{4}{225}\n$$\n数值上，$\\frac{4}{225} \\approx 0.01777...$。所以二次型为：\n$$\n0.045 + 0.01777... = 0.062777...\n$$\n最后，我们计算Bhattacharyya距离 $B$：\n$$\nB = \\frac{1}{8} \\times (0.062777...) = 0.007847222...\n$$\n四舍五入到四位有效数字，我们得到 $0.007847$。用标准科学记数法表示，即为 $7.847 \\times 10^{-3}$。",
            "answer": "$$\\boxed{7.847 \\times 10^{-3}}$$"
        },
        {
            "introduction": "理论和简洁的数值示例为我们提供了坚实的基础，但真实世界的光谱数据常常带来挑战，可能会破坏我们的分析。最后一个练习  聚焦于一个关键的实际问题：由光谱波段之间高度相关性引起的病态协方差矩阵。通过分析一个具体案例，你将学会识别不良条件的症状和后果，并理解为何它对许多常用的可分离性度量构成挑战。",
            "id": "3853723",
            "problem": "在多光谱遥感分类场景中，考虑在 $p=2$ 个光谱波段中测量的两个地物覆盖类别的训练样本。对于类别 $i$，用 $\\boldsymbol{\\mu}_i$ 表示样本均值向量，用 $\\boldsymbol{\\Sigma}_i$ 表示样本协方差矩阵。协方差矩阵是从 $n_i$ 个独立的训练像素估计的。假设有以下经验估计量：\n- 类别 1：$n_1 = 12$，$\\boldsymbol{\\mu}_1 = \\begin{bmatrix} 0.20 \\\\ 0.20 \\end{bmatrix}$，$\\boldsymbol{\\Sigma}_1 = \\begin{bmatrix} 0.090  0.089 \\\\ 0.089  0.089 \\end{bmatrix}$。\n- 类别 2：$n_2 = 50$，$\\boldsymbol{\\mu}_2 = \\begin{bmatrix} 0.22 \\\\ 0.18 \\end{bmatrix}$，$\\boldsymbol{\\Sigma}_2 = \\begin{bmatrix} 0.090  0 \\\\ 0  0.090 \\end{bmatrix}$。\n\n假设要使用基于距离的度量来评估可分性，这些度量假设类别条件密度为多元高斯分布，并且通过包含 $\\boldsymbol{\\Sigma}_i^{-1}$ 和 $\\det(\\boldsymbol{\\Sigma}_i)$ 的项来依赖于 $\\boldsymbol{\\Sigma}_i$（例如，巴氏 (Bhattacharyya) 距离和杰氏-马氏 (Jeffries-Matusita, JM) 距离，其中杰氏-马氏距离是巴氏距离的单调变换）。\n\n从多元统计中协方差和相关性的基本定义以及多元正态分布的对数似然函数出发，解释协方差矩阵如何编码光谱波段相关性，以及这种编码如何影响可分性分析中使用的距离的几何形状。然后，利用 $\\boldsymbol{\\Sigma}_1$ 的特征分解，论证为什么病态的 $\\boldsymbol{\\Sigma}_i$ 会使需要 $\\boldsymbol{\\Sigma}_i^{-1}$ 或 $\\ln \\det(\\boldsymbol{\\Sigma}_i)$ 的可分性度量的数值计算变得复杂。特别地，请参考由条件数 $\\kappa(\\boldsymbol{\\Sigma}_i)$ 量化的矩阵求逆对扰动的敏感性。\n\n在此背景下，选择所有正确的陈述：\n\nA. 光谱波段之间的高度正相关表现为 $\\boldsymbol{\\Sigma}_i$ 中较大的正非对角线元素，这会旋转协方差椭圆的主轴；一个非常小的特征值会产生一个狭窄的短轴，而由 $\\boldsymbol{\\Sigma}_i^{-1}$ 加权的距离项会沿着该短轴变得高度敏感。\n\nB. 如果 $\\boldsymbol{\\Sigma}_i$ 是病态的，使用 $\\boldsymbol{\\Sigma}_i^{-1}$ 的度量在数值上是不稳定的，因为 $\\boldsymbol{\\Sigma}_i$ 中的小的相对扰动可能导致 $\\boldsymbol{\\Sigma}_i^{-1}$ 中与条件数成比例的大的相对变化；添加一个小的岭项 $\\lambda \\mathbf{I}$（其中 $\\lambda > 0$）可以减少这种不稳定性。\n\nC. 对于两个均值相同但协方差不同的多元高斯类，Bhattacharyya 距离为零，因此在这种情况下，协方差结构和波段相关性对可分性没有贡献。\n\nD. 在 Bhattacharyya 距离中，一个小的 $\\det(\\boldsymbol{\\Sigma}_1)$ 会减小对数项的量级，从而提高数值稳定性并减少病态条件的影响。\n\nE. 基于 $\\boldsymbol{\\Sigma}_i$ 的白化变换（通过 $\\boldsymbol{\\Sigma}_i^{-1/2}$ 去相关）可以减轻相关效应，但如果 $\\boldsymbol{\\Sigma}_i$ 是病态的，白化变换本身会变得不稳定，并可能放大与小特征值相关的方向上的测量噪声。\n\nF. 当 $n_i$ 较小时，高斯训练样本的 $\\boldsymbol{\\Sigma}_i$ 的最大似然估计是无偏的，因此条件差完全归因于波段间相关性，而不是有限的样本量。",
            "solution": "基础知识包括以下标准定义和属性：\n- 随机变量 $X_j$ 和 $X_k$ 之间的协方差是 $\\operatorname{Cov}(X_j, X_k) = \\mathbb{E}\\!\\left[(X_j - \\mu_j)(X_k - \\mu_k)\\right]$，相关系数是 $\\rho_{jk} = \\frac{\\operatorname{Cov}(X_j, X_k)}{\\sqrt{\\operatorname{Var}(X_j)\\operatorname{Var}(X_k)}}$。\n- 对于 $p$ 维的多元正态（高斯）类别条件密度，观测值 $\\boldsymbol{x}$ 在类别 $i$ 下的对数似然函数是 $\\log f_i(\\boldsymbol{x}) = -\\frac{1}{2}\\left[ (\\boldsymbol{x} - \\boldsymbol{\\mu}_i)^\\top \\boldsymbol{\\Sigma}_i^{-1} (\\boldsymbol{x} - \\boldsymbol{\\mu}_i) + \\ln \\det(\\boldsymbol{\\Sigma}_i) + p \\ln(2\\pi) \\right]$。\n- 协方差矩阵 $\\boldsymbol{\\Sigma}_i$ 是对称正定的（对于非退化类别的总体而言），它允许进行特征分解 $\\boldsymbol{\\Sigma}_i = \\boldsymbol{Q}\\boldsymbol{\\Lambda}\\boldsymbol{Q}^\\top$，其中 $\\boldsymbol{Q}$ 是标准正交的，$\\boldsymbol{\\Lambda} = \\operatorname{diag}(\\lambda_1,\\ldots,\\lambda_p)$ 是对角的，并且 $\\boldsymbol{\\Sigma}_i^{-1} = \\boldsymbol{Q}\\boldsymbol{\\Lambda}^{-1}\\boldsymbol{Q}^\\top$。\n- 对称正定矩阵的 $2$-范数条件数是 $\\kappa_2(\\boldsymbol{\\Sigma}_i) = \\frac{\\lambda_{\\max}(\\boldsymbol{\\Sigma}_i)}{\\lambda_{\\min}(\\boldsymbol{\\Sigma}_i)}$。\n- 矩阵求逆敏感性：对于足够小的扰动 $\\Delta \\boldsymbol{\\Sigma}$，且满足 $\\|\\boldsymbol{\\Sigma}^{-1}\\| \\|\\Delta \\boldsymbol{\\Sigma}\\|  1$，Neumann 级数给出 $(\\boldsymbol{\\Sigma} + \\Delta \\boldsymbol{\\Sigma})^{-1} = \\boldsymbol{\\Sigma}^{-1}\\sum_{k=0}^{\\infty}(-\\Delta \\boldsymbol{\\Sigma}\\,\\boldsymbol{\\Sigma}^{-1})^k$，一个标准的界限意味着 $\\frac{\\|(\\boldsymbol{\\Sigma} + \\Delta \\boldsymbol{\\Sigma})^{-1} - \\boldsymbol{\\Sigma}^{-1}\\|}{\\|\\boldsymbol{\\Sigma}^{-1}\\|} \\lesssim \\kappa(\\boldsymbol{\\Sigma}) \\frac{\\|\\Delta \\boldsymbol{\\Sigma}\\|}{\\|\\boldsymbol{\\Sigma}\\|}$，其中 $\\kappa(\\boldsymbol{\\Sigma})$ 是基于范数的条件数。\n\n$\\boldsymbol{\\Sigma}_i$ 如何编码光谱波段相关性：\n- 在给定的 $\\boldsymbol{\\Sigma}_1 = \\begin{bmatrix} 0.090  0.089 \\\\ 0.089  0.089 \\end{bmatrix}$ 中，非对角线元素 $0.089$ 几乎与方差的几何平均值 $\\sqrt{0.090 \\cdot 0.089}$ 一样大。这意味着相关性为\n$$\n\\rho = \\frac{0.089}{\\sqrt{0.090 \\cdot 0.089}} = \\frac{0.089}{\\sqrt{0.00801}} \\approx \\frac{0.089}{0.08949} \\approx 0.995,\n$$\n表明两个波段之间存在极高的正相关性。\n- 这种相关性将协方差椭圆的主轴旋转至直线 $x_1 \\approx x_2$ 方向（第一主成分方向），导致沿 $[1,\\,1]^\\top$ 方向的方差很大，而沿正交的 $[1,\\,-1]^\\top$ 方向的方差非常小。\n\n$\\boldsymbol{\\Sigma}_1$ 的特征结构和条件：\n- 迹为 $\\operatorname{tr}(\\boldsymbol{\\Sigma}_1) = 0.090 + 0.089 = 0.179$。\n- 行列式为 $\\det(\\boldsymbol{\\Sigma}_1) = (0.090)(0.089) - (0.089)^2 = 0.00801 - 0.007921 = 0.000089$。\n- 在 $p=2$ 时，特征值满足 $\\lambda_1 + \\lambda_2 = 0.179$ 和 $\\lambda_1 \\lambda_2 = 0.000089$，得出大约\n$$\n\\lambda_{\\max} \\approx 0.1785, \\quad \\lambda_{\\min} \\approx 0.0005.\n$$\n- 因此，$2$-范数条件数为\n$$\n\\kappa_2(\\boldsymbol{\\Sigma}_1) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} \\approx \\frac{0.1785}{0.0005} \\approx 357.\n$$\n这个大的条件数表明求逆是高度敏感的。在特征基下，$\\boldsymbol{\\Sigma}_1^{-1}$ 沿着短轴按 $1/\\lambda_{\\min} \\approx 2000$ 缩放，沿着长轴按 $1/\\lambda_{\\max} \\approx 5.6$ 缩放。任何涉及 $(\\boldsymbol{x} - \\boldsymbol{\\mu}_i)^\\top \\boldsymbol{\\Sigma}_i^{-1} (\\boldsymbol{x} - \\boldsymbol{\\mu}_i)$ 的距离项都会严重加权沿短轴的偏差，可能放大噪声和估计误差。\n\n基于距离的可分性度量：\n- 多元正态对数似然函数表明，从中导出的分类规则和可分性度量固有地依赖于 $\\boldsymbol{\\Sigma}_i^{-1}$ 和 $\\ln \\det(\\boldsymbol{\\Sigma}_i)$ 两者。对于两个类别，Bhattacharyya 距离包含一个关于均值差的二次项（由逆协方差加权）和一个涉及相关协方差行列式的对数的项。因此，即使均值相等或仅有轻微差异，协方差结构和相关性也直接影响可分性。\n- 当 $\\det(\\boldsymbol{\\Sigma}_i)$ 非常小（由于接近奇异）时，$\\ln \\det(\\boldsymbol{\\Sigma}_i)$ 变成一个很大的负数，使得涉及行列式比率或平均值的项的量级变大。在数值上，对非常小的行列式取对数可能会遭受浮点数下溢或放大行列式估计中的相对误差。\n\n对扰动的敏感性：\n- 对于一个相对扰动 $\\frac{\\|\\Delta \\boldsymbol{\\Sigma}_1\\|}{\\|\\boldsymbol{\\Sigma}_1\\|} = \\delta$，界限\n$$\n\\frac{\\|(\\boldsymbol{\\Sigma}_1 + \\Delta \\boldsymbol{\\Sigma}_1)^{-1} - \\boldsymbol{\\Sigma}_1^{-1}\\|}{\\|\\boldsymbol{\\Sigma}_1^{-1}\\|} \\lesssim \\kappa(\\boldsymbol{\\Sigma}_1)\\,\\delta\n$$\n意味着即使是适度的 $\\delta = 0.01$（$1\\%$）也可能在 $\\boldsymbol{\\Sigma}_1^{-1}$ 中产生大约 $3.6$ 量级的相对变化。由于可分性度量中的马氏距离型项由 $\\boldsymbol{\\Sigma}_1^{-1}$ 加权，当 $\\kappa$ 很大时，它们的值在小的估计噪声下可能会有很大变化。此外，通过 $\\boldsymbol{\\Sigma}_1^{-1/2}$ 进行白化使用特征值的 $-1/2$ 次方，这仍然会大幅放大与小特征值对应的分量，从而有放大噪声和数值不稳定的风险。\n\n逐项分析：\n- 选项 A：正确。大的正非对角线协方差元素编码了强正相关，旋转了主轴。小的 $\\lambda_{\\min}$ 导致逆矩阵沿短轴急剧增大，使得逆加权距离在该方向上高度敏感。这正是协方差及其逆矩阵中相关性的几何效应。\n\n- 选项 B：正确。病态（大的 $\\kappa$）意味着求逆对扰动高度敏感。Neumann 级数和条件数界限明确指出，$\\boldsymbol{\\Sigma}_i$ 的微小变化可能导致 $\\boldsymbol{\\Sigma}_i^{-1}$ 的巨大相对变化。岭正则化 $\\boldsymbol{\\Sigma}_i + \\lambda \\mathbf{I}$ 将最小特征值增加到至少为 $\\lambda$，从而减小 $\\kappa$ 并稳定求逆和行列式计算。\n\n- 选项 C：不正确。对于均值相同但协方差不同的多元高斯类，Bhattacharyya 距离非零，因为它包含一个涉及行列式对数和协方差平均值的项。因此，即使均值重合，协方差结构和相关性也会影响可分性。\n\n- 选项 D：不正确。一个小的 $\\det(\\boldsymbol{\\Sigma}_1)$ 不会减小对数项的量级；相反，由于对小数取对数，它可能使该项的量级变大，可能恶化数值稳定性。在可分性公式中，如果一个行列式非常小，诸如 $\\frac{\\det(\\boldsymbol{\\Sigma}_\\text{avg})}{\\sqrt{\\det(\\boldsymbol{\\Sigma}_1)\\det(\\boldsymbol{\\Sigma}_2)}}$之类的比率将有一个很大的对数。\n\n- 选项 E：正确。通过 $\\boldsymbol{\\Sigma}_i^{-1/2}$ 进行白化在原理上去除相关性并使方差相等，但当 $\\boldsymbol{\\Sigma}_i$ 是病态时，该变换会极大地放大与小特征值相关的分量，导致不稳定性和噪声放大。因此，虽然白化可以减轻相关性，但在病态设置中若无正则化则可能不可靠。\n\n- 选项 F：不正确。当 $n_i$ 较小时，高斯数据的 $\\boldsymbol{\\Sigma}_i$ 的最大似然估计使用 $1/n_i$ 因子并且是有偏的（无偏估计使用 $1/(n_i - 1)$）。有限的样本量也会导致条件差：当 $n_i$相对于 $p$ 较小时，样本协方差是有噪声的并且可能接近秩亏，这会加剧病态，其影响超出了真实相关性本身。\n\n因此，正确的陈述是 A、B 和 E。",
            "answer": "$$\\boxed{ABE}$$"
        }
    ]
}