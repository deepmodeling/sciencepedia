{
    "hands_on_practices": [
        {
            "introduction": "To accurately model random dopant fluctuation, we must first understand the statistical nature of the active dopant population. This foundational exercise  explores a two-stage random process: the initial Poisson-distributed count of implanted dopants and the subsequent binomial activation of each dopant. By deriving the statistics of the final active dopant count from first principles, you will demonstrate a fundamental property known as the thinning of a Poisson process, a key building block for more complex variability models.",
            "id": "4159307",
            "problem": "In a nanoscale Metal-Oxide-Semiconductor Field-Effect Transistor (MOSFET), random dopant fluctuation arises due to the discreteness of implanted dopant atoms and stochastic activation during post-implant annealing. Consider an electrically active device volume into which dopants are implanted. Let the total number of implanted dopants within this volume be the random variable $N$, and let each implanted dopant independently become electrically active after annealing with probability $p \\in (0,1)$. Define the random variable $K$ as the number of electrically active dopants within the volume.\n\nStarting only from the following foundational elements:\n- The definition of a Bernoulli random variable and the binomial distribution as the sum of independent and identically distributed Bernoulli random variables.\n- The definition of the Poisson distribution and its use to model counts of independent, rare events in a fixed region.\n- Basic conditioning identities from probability (e.g., iterated expectation and variance), without invoking any pre-packaged “thinning” theorems.\n\nPerform the following:\n1. Condition on a fixed implanted-dopant count $N=n$, and derive an expression for $\\operatorname{Var}[K \\mid N=n]$ in terms of $n$ and $p$.\n2. Now model the implanted-dopant count as Poisson, $N \\sim \\operatorname{Poisson}(\\lambda)$, where $\\lambda>0$ is the mean implanted count in the volume. Using only first principles and conditioning, derive a closed-form expression for $\\operatorname{Var}[K]$ in terms of $p$ and $\\lambda$. In the course of your derivation, explicitly show that the unconditional distribution of $K$ is Poisson with mean $p\\lambda$, thereby demonstrating the equivalence to independent thinning of a Poisson process.\n3. State your final answer as a single closed-form analytic expression for $\\operatorname{Var}[K]$ under the Poisson-implanted, independent-activation model.\n\nExpress the final answer as a single analytic expression. No units are required.",
            "solution": "The problem requires a three-part derivation concerning the number of electrically active dopants, $K$, in a semiconductor device volume. The derivation must proceed from first principles, starting from the foundational definitions of probability distributions and using basic conditioning identities.\n\n**Part 1: Derivation of Conditional Variance, $\\operatorname{Var}[K \\mid N=n]$**\n\nLet us first consider the case where the total number of implanted dopants is a fixed integer, $N=n$. Each of these $n$ dopants has a probability $p$ of becoming electrically active, independently of the others.\n\nWe can model the activation of each dopant $i$ (for $i=1, 2, \\dots, n$) with a Bernoulli random variable, $X_i$.\nLet $X_i = 1$ if the $i$-th dopant is active (with probability $p$) and $X_i = 0$ if it is not (with probability $1-p$).\n$$\nP(X_i = 1) = p\n$$\n$$\nP(X_i = 0) = 1-p\n$$\nThe number of active dopants, $K$, given that there are $n$ implanted dopants, is the sum of these independent and identically distributed (i.i.d.) Bernoulli random variables:\n$$\nK \\mid (N=n) = \\sum_{i=1}^{n} X_i\n$$\nBy definition, the sum of $n$ i.i.d. Bernoulli($p$) random variables follows a binomial distribution, so $(K \\mid N=n) \\sim \\operatorname{Binomial}(n, p)$.\n\nWe are asked to find the variance of this conditional distribution, $\\operatorname{Var}[K \\mid N=n]$. We derive this from the properties of the constituent Bernoulli variables. First, we find the expectation and variance of a single Bernoulli variable $X_i$.\n\nThe expectation of $X_i$ is:\n$$\nE[X_i] = (1 \\cdot p) + (0 \\cdot (1-p)) = p\n$$\nTo find the variance, we first compute $E[X_i^2]$:\n$$\nE[X_i^2] = (1^2 \\cdot p) + (0^2 \\cdot (1-p)) = p\n$$\nThe variance of $X_i$ is then given by:\n$$\n\\operatorname{Var}[X_i] = E[X_i^2] - (E[X_i])^2 = p - p^2 = p(1-p)\n$$\nSince the $X_i$ variables are independent, the variance of their sum is the sum of their variances:\n$$\n\\operatorname{Var}[K \\mid N=n] = \\operatorname{Var}\\left[\\sum_{i=1}^{n} X_i\\right] = \\sum_{i=1}^{n} \\operatorname{Var}[X_i]\n$$\nSubstituting the variance of a single Bernoulli variable, we get:\n$$\n\\operatorname{Var}[K \\mid N=n] = \\sum_{i=1}^{n} p(1-p) = n p(1-p)\n$$\nThis is the well-known variance of a $\\operatorname{Binomial}(n,p)$ distribution, derived from first principles as required.\n\n**Part 2: Unconditional Variance $\\operatorname{Var}[K]$ and Distribution of $K$**\n\nNow we consider the number of implanted dopants $N$ to be a random variable following a Poisson distribution with mean $\\lambda > 0$, i.e., $N \\sim \\operatorname{Poisson}(\\lambda)$. We must derive the unconditional variance $\\operatorname{Var}[K]$. We will use the law of total variance, which states:\n$$\n\\operatorname{Var}[K] = E[\\operatorname{Var}[K \\mid N]] + \\operatorname{Var}[E[K \\mid N]]\n$$\nWe need to find the two terms on the right-hand side.\n\nFrom Part 1, we have the conditional variance as a function of $n$: $\\operatorname{Var}[K \\mid N=n] = np(1-p)$. This implies that the conditional variance as a function of the random variable $N$ is:\n$$\n\\operatorname{Var}[K \\mid N] = Np(1-p)\n$$\nThe first term in the law of total variance is the expectation of this quantity:\n$$\nE[\\operatorname{Var}[K \\mid N]] = E[Np(1-p)]\n$$\nSince $p$ is a constant, we can factor it out of the expectation:\n$$\nE[\\operatorname{Var}[K \\mid N]] = p(1-p)E[N]\n$$\nFor a Poisson distribution $N \\sim \\operatorname{Poisson}(\\lambda)$, the expectation is $E[N] = \\lambda$. Therefore:\n$$\nE[\\operatorname{Var}[K \\mid N]] = p(1-p)\\lambda\n$$\nNext, we find the second term, $\\operatorname{Var}[E[K \\mid N]]$. First, we compute the conditional expectation $E[K \\mid N]$. As established, $(K \\mid N=n) \\sim \\operatorname{Binomial}(n,p)$, whose expectation is $np$. Thus, as a function of the random variable $N$:\n$$\nE[K \\mid N] = Np\n$$\nNow, we compute the variance of this quantity:\n$$\n\\operatorname{Var}[E[K \\mid N]] = \\operatorname{Var}[Np]\n$$\nUsing the property $\\operatorname{Var}[cX] = c^2\\operatorname{Var}[X]$ for a constant $c$, we have:\n$$\n\\operatorname{Var}[E[K \\mid N]] = p^2\\operatorname{Var}[N]\n$$\nFor a Poisson distribution $N \\sim \\operatorname{Poisson}(\\lambda)$, the variance is $\\operatorname{Var}[N] = \\lambda$. Therefore:\n$$\n\\operatorname{Var}[E[K \\mid N]] = p^2\\lambda\n$$\nFinally, we substitute both terms back into the law of total variance:\n$$\n\\operatorname{Var}[K] = E[\\operatorname{Var}[K \\mid N]] + \\operatorname{Var}[E[K \\mid N]] = p(1-p)\\lambda + p^2\\lambda\n$$\n$$\n\\operatorname{Var}[K] = (p\\lambda - p^2\\lambda) + p^2\\lambda = p\\lambda\n$$\nAs part of this derivation, the problem asks to explicitly show that the unconditional distribution of $K$ is Poisson with mean $p\\lambda$. This provides a consistency check, as the variance of a Poisson($p\\lambda$) distribution is indeed $p\\lambda$.\n\nTo find the probability mass function (PMF) of $K$, $P(K=k)$, we use the law of total probability, conditioning on the value of $N$:\n$$\nP(K=k) = \\sum_{n=0}^{\\infty} P(K=k \\mid N=n) P(N=n)\n$$\nWe have the two PMFs:\n- $P(K=k \\mid N=n) = \\binom{n}{k} p^k (1-p)^{n-k}$, for $0 \\le k \\le n$. This term is $0$ if $k > n$.\n- $P(N=n) = \\frac{\\exp(-\\lambda)\\lambda^n}{n!}$ for $n \\ge 0$.\n\nSubstituting these into the sum, and noting that the sum only needs to run from $n=k$ since $P(K=k \\mid N=n)=0$ for $n<k$:\n$$\nP(K=k) = \\sum_{n=k}^{\\infty} \\left( \\binom{n}{k} p^k (1-p)^{n-k} \\right) \\left( \\frac{\\exp(-\\lambda)\\lambda^n}{n!} \\right)\n$$\nLet's rearrange the terms:\n$$\nP(K=k) = \\sum_{n=k}^{\\infty} \\frac{n!}{k!(n-k)!} p^k (1-p)^{n-k} \\frac{\\exp(-\\lambda)\\lambda^n}{n!}\n$$\nCancel the $n!$ terms and pull out factors that do not depend on the summation index $n$:\n$$\nP(K=k) = \\frac{\\exp(-\\lambda) p^k}{k!} \\sum_{n=k}^{\\infty} \\frac{(1-p)^{n-k} \\lambda^n}{(n-k)!}\n$$\nTo simplify the sum, let $j = n-k$, which implies $n = j+k$. When $n=k$, $j=0$. The sum becomes:\n$$\nP(K=k) = \\frac{\\exp(-\\lambda) p^k}{k!} \\sum_{j=0}^{\\infty} \\frac{(1-p)^j \\lambda^{j+k}}{j!}\n$$\nFactor out $\\lambda^k$ from the sum:\n$$\nP(K=k) = \\frac{\\exp(-\\lambda) (p\\lambda)^k}{k!} \\sum_{j=0}^{\\infty} \\frac{((1-p)\\lambda)^j}{j!}\n$$\nThe summation is the Taylor series expansion for the exponential function, $\\sum_{j=0}^{\\infty} \\frac{x^j}{j!} = \\exp(x)$, with $x = (1-p)\\lambda$.\n$$\n\\sum_{j=0}^{\\infty} \\frac{((1-p)\\lambda)^j}{j!} = \\exp((1-p)\\lambda)\n$$\nSubstituting this back into the expression for $P(K=k)$:\n$$\nP(K=k) = \\frac{\\exp(-\\lambda) (p\\lambda)^k}{k!} \\exp((1-p)\\lambda)\n$$\nCombining the exponential terms:\n$$\nP(K=k) = \\frac{(p\\lambda)^k}{k!} \\exp(-\\lambda + (1-p)\\lambda) = \\frac{(p\\lambda)^k}{k!} \\exp(-\\lambda + \\lambda - p\\lambda)\n$$\n$$\nP(K=k) = \\frac{(p\\lambda)^k}{k!} \\exp(-p\\lambda)\n$$\nThis is the PMF of a Poisson distribution with parameter $p\\lambda$. Thus, we have shown that $K \\sim \\operatorname{Poisson}(p\\lambda)$. This process is known as the thinning of a Poisson process. The mean and variance of this distribution are both equal to its parameter, $p\\lambda$. This confirms our earlier result for $\\operatorname{Var}[K]$.\n\n**Part 3: Final Answer**\n\nThe final answer is the closed-form expression for the unconditional variance, $\\operatorname{Var}[K]$, derived under the model where the implanted dopant count $N$ is Poisson-distributed and activation is an independent Bernoulli trial for each dopant. Based on the derivation in Part 2, this is:\n$$\n\\operatorname{Var}[K] = p\\lambda\n$$",
            "answer": "$$\n\\boxed{p\\lambda}\n$$"
        },
        {
            "introduction": "The impact of a dopant on device performance critically depends on its location. This practice  moves from simple dopant counts to a more physical model by incorporating a spatial sensitivity function that weights each dopant's contribution to the threshold voltage ($V_T$). Your task is to apply principles of stochastic processes to derive the variance of $V_T$ fluctuations and connect it to the renowned Pelgrom parameter, bridging the gap between microscopic randomness and macroscopic device scaling laws.",
            "id": "4159288",
            "problem": "Consider an $n$-channel Metal–Oxide–Semiconductor Field-Effect Transistor (MOSFET) with gate width $W$, gate length $L$, and a uniformly doped body within a depletion depth $T$ below the oxide–semiconductor interface. The discrete acceptor dopants in the body are modeled as a spatial Poisson point process with constant intensity (mean volumetric density) $\\rho$ over the volume $\\Omega = [0,L] \\times [0,W] \\times [0,T]$. Each dopant carries elementary charge $q$, and the oxide capacitance per unit area is $C_{ox}$. Assume linear electrostatic coupling from each discrete charge to the gate, so that the total threshold voltage shift is the sum of the contributions from individual dopants. Let the spatial sensitivity function be $w(\\mathbf{r}) = \\exp(-z/\\lambda)$, where $z$ is the vertical coordinate measured into the semiconductor, and $\\lambda$ is a positive screening length. Assume negligible lateral variation of the sensitivity, i.e., $w(\\mathbf{r})$ depends only on $z$.\n\nStarting from first principles appropriate to discrete dopant modeling and random dopant fluctuation, use the following foundations:\n- For the MOS electrostatics in the small-signal limit, the threshold voltage shift caused by an areal gate charge density $Q'$ is $\\Delta V_T = Q'/C_{ox}$, and a discrete charge $q$ located at depth $z$ couples to the gate with effective areal weight $w(z)/(W L)$.\n- For a spatial Poisson point process, the dopant count in any subvolume has variance equal to its mean, and the variance of a sum of independent contributions is the sum of variances.\n\nDefine the generalized Pelgrom parameter $A_{V_T}$ by the relation $\\sigma_{\\Delta V_T} = A_{V_T}/\\sqrt{W L}$, where $\\sigma_{\\Delta V_T}$ is the standard deviation of the threshold voltage fluctuation due to random dopants. Derive, in closed form, the expression for $A_{V_T}$ in terms of $q$, $C_{ox}$, $\\rho$, $T$, and $\\lambda$ for the given sensitivity $w(\\mathbf{r}) = \\exp(-z/\\lambda)$. Your final answer must be a single analytic expression. Do not use numerical values.",
            "solution": "The problem requires the derivation of an expression for the generalized Pelgrom parameter, $A_{V_T}$, which characterizes the standard deviation of threshold voltage fluctuations, $\\sigma_{\\Delta V_T}$, due to random discrete dopants in a MOSFET.\n\n### Step 1: Problem Validation\n\n**1.1. Extract Givens**\n- **Device Geometry and Doping:** An $n$-channel MOSFET with gate width $W$, gate length $L$, and a uniformly doped body within a depletion depth $T$. The volume of interest is $\\Omega = [0,L] \\times [0,W] \\times [0,T]$.\n- **Dopant Model:** Discrete acceptor dopants are modeled as a spatial Poisson point process with a constant mean volumetric density $\\rho$ over $\\Omega$.\n- **Charge:** Each dopant carries elementary charge $q$.\n- **Capacitance:** The oxide capacitance per unit area is $C_{ox}$.\n- **Electrostatic Coupling:**\n    - The threshold voltage shift $\\Delta V_T$ due to an areal gate charge density $Q'$ is given by $\\Delta V_T = Q'/C_{ox}$.\n    - A single discrete charge $q$ at depth $z$ contributes an effective areal weight of $w(z)/(W L)$ to the gate charge.\n    - The total $\\Delta V_T$ is the sum of contributions from individual dopants (linear superposition).\n- **Spatial Sensitivity Function:** The sensitivity function is given by $w(\\mathbf{r}) = \\exp(-z/\\lambda)$, where $z$ is the depth and $\\lambda > 0$ is a screening length. It is assumed to be independent of lateral position $(x, y)$.\n- **Statistical Property:** For a spatial Poisson point process, the variance of the dopant count in a volume equals its mean. The variance of a sum of independent contributions is the sum of their variances.\n- **Definition of $A_{V_T}$:** The parameter $A_{V_T}$ is defined by the relation $\\sigma_{\\Delta V_T} = A_{V_T}/\\sqrt{W L}$.\n\n**1.2. Validate Using Extracted Givens**\n- **Scientific Grounding:** The problem is firmly grounded in the established physics of semiconductor devices. The modeling of random dopant fluctuation (RDF) using a Poisson process is a standard and well-accepted technique. The use of a sensitivity function (related to the device's Green's function) to model the electrostatic coupling of discrete charges to the channel is also a mainstream approach. The exponential decay form of the sensitivity function is a physically plausible approximation for electrostatic screening in the semiconductor body.\n- **Well-Posedness:** The problem is well-posed. It provides all necessary parameters ($W$, $L$, $T$, $\\rho$, $q$, $C_{ox}$, $\\lambda$) and functional forms ($w(z)$) to derive a unique, closed-form expression for $A_{V_T}$. The assumptions of uniform doping density and linear superposition make the problem analytically tractable.\n- **Objectivity:** The problem statement is objective, using precise, quantitative, and unbiased technical language.\n\n**1.3. Verdict and Action**\nThe problem is scientifically sound, self-contained, and well-posed. It presents a standard, non-trivial problem in the field of semiconductor device modeling. Therefore, the problem is **valid**. We proceed to the solution.\n\n### Step 2: Derivation of the Expression for $A_{V_T}$\n\nThe total threshold voltage fluctuation, $\\Delta V_T$, is the sum of the contributions from all individual dopant charges within the volume $\\Omega$. Let's first determine the contribution of a single dopant.\n\nA single dopant with charge $q$ located at a position $\\mathbf{r} = (x, y, z)$ induces an effective areal charge density at the gate. According to the problem statement, the effective areal weight is $w(z)/(W L)$. Thus, the effective areal gate charge density $Q'$ due to this single dopant is:\n$$ Q' = \\frac{q \\cdot w(z)}{W L} $$\nThe resulting shift in threshold voltage, $\\Delta V_{T, \\text{single}}$, from this single dopant is given by:\n$$ \\Delta V_{T, \\text{single}}(z) = \\frac{Q'}{C_{ox}} = \\frac{q \\cdot w(z)}{C_{ox} W L} $$\nGiven $w(z) = \\exp(-z/\\lambda)$, this becomes:\n$$ \\Delta V_{T, \\text{single}}(z) = \\frac{q}{C_{ox} W L} \\exp(-z/\\lambda) $$\n\nThe total threshold voltage shift, $\\Delta V_T$, is the a sum over all dopants present in the volume $\\Omega$:\n$$ \\Delta V_T = \\sum_{i=1}^{N} \\Delta V_{T, \\text{single}}(z_i) $$\nwhere $N$ is the random number of dopants in $\\Omega$, and $z_i$ is the depth of the $i$-th dopant.\n\nWe need to find the variance of $\\Delta V_T$, denoted by $\\sigma^2_{\\Delta V_T}$. Since the dopants are distributed according to a spatial Poisson point process with intensity $\\rho$, the variance of the sum of functions evaluated at the points of the process can be calculated using Campbell's Theorem for shot noise processes. The theorem states that for a process $X = \\sum_{i} h(\\mathbf{r}_i)$, where the points $\\mathbf{r}_i$ are from a Poisson process with intensity $\\rho$, the variance of $X$ is given by:\n$$ \\text{Var}[X] = \\rho \\int_{\\Omega} [h(\\mathbf{r})]^2 dV $$\nIn our case, the function $h(\\mathbf{r})$ is the contribution from a single dopant, $h(\\mathbf{r}) = \\Delta V_{T, \\text{single}}(z)$. The integration volume is $\\Omega = [0,L] \\times [0,W] \\times [0,T]$ and the volume element is $dV = dx \\, dy \\, dz$.\n\nApplying this theorem, the variance of the threshold voltage fluctuation is:\n$$ \\sigma^2_{\\Delta V_T} = \\text{Var}[\\Delta V_T] = \\rho \\int_{0}^{T} \\int_{0}^{W} \\int_{0}^{L} \\left( \\frac{q}{C_{ox} W L} \\exp(-z/\\lambda) \\right)^2 dx \\, dy \\, dz $$\n\nWe can separate the constants and the integrals:\n$$ \\sigma^2_{\\Delta V_T} = \\rho \\left( \\frac{q}{C_{ox} W L} \\right)^2 \\int_{0}^{T} \\int_{0}^{W} \\int_{0}^{L} \\exp(-2z/\\lambda) \\, dx \\, dy \\, dz $$\nThe integrand does not depend on $x$ or $y$, so the integrals over these coordinates are straightforward:\n$$ \\int_{0}^{L} dx = L $$\n$$ \\int_{0}^{W} dy = W $$\nSubstituting these results into the expression for the variance:\n$$ \\sigma^2_{\\Delta V_T} = \\rho \\frac{q^2}{C_{ox}^2 (W L)^2} (W L) \\int_{0}^{T} \\exp(-2z/\\lambda) \\, dz $$\nSimplifying the pre-integral factor:\n$$ \\sigma^2_{\\Delta V_T} = \\frac{\\rho q^2}{C_{ox}^2 W L} \\int_{0}^{T} \\exp(-2z/\\lambda) \\, dz $$\nNow, we evaluate the remaining integral with respect to $z$:\n$$ \\int_{0}^{T} \\exp(-2z/\\lambda) \\, dz = \\left[ \\frac{\\exp(-2z/\\lambda)}{-2/\\lambda} \\right]_{0}^{T} = -\\frac{\\lambda}{2} \\left( \\exp(-2T/\\lambda) - \\exp(0) \\right) $$\n$$ = -\\frac{\\lambda}{2} \\left( \\exp(-2T/\\lambda) - 1 \\right) = \\frac{\\lambda}{2} \\left( 1 - \\exp(-2T/\\lambda) \\right) $$\nSubstituting this result back into the expression for $\\sigma^2_{\\Delta V_T}$:\n$$ \\sigma^2_{\\Delta V_T} = \\frac{\\rho q^2}{C_{ox}^2 W L} \\left[ \\frac{\\lambda}{2} (1 - \\exp(-2T/\\lambda)) \\right] $$\nThe problem defines the Pelgrom parameter $A_{V_T}$ via the relation $\\sigma_{\\Delta V_T} = A_{V_T}/\\sqrt{W L}$. Squaring both sides gives:\n$$ \\sigma^2_{\\Delta V_T} = \\frac{A_{V_T}^2}{W L} $$\nBy equating our derived expression for $\\sigma^2_{\\Delta V_T}$ with its definition in terms of $A_{V_T}$, we can solve for $A_{V_T}^2$:\n$$ \\frac{A_{V_T}^2}{W L} = \\frac{\\rho q^2 \\lambda}{2 C_{ox}^2 W L} (1 - \\exp(-2T/\\lambda)) $$\nThe term $W L$ cancels from both sides of the equation:\n$$ A_{V_T}^2 = \\frac{\\rho q^2 \\lambda}{2 C_{ox}^2} (1 - \\exp(-2T/\\lambda)) $$\nFinally, taking the positive square root to find $A_{V_T}$:\n$$ A_{V_T} = \\sqrt{\\frac{\\rho q^2 \\lambda}{2 C_{ox}^2} (1 - \\exp(-2T/\\lambda))} $$\nWe can simplify this expression by factoring out terms from under the square root:\n$$ A_{V_T} = \\frac{q}{C_{ox}} \\sqrt{\\frac{\\rho \\lambda}{2} (1 - \\exp(-2T/\\lambda))} $$\nThis is the final closed-form expression for the generalized Pelgrom parameter $A_{V_T}$ based on the provided model.",
            "answer": "$$ \\boxed{\\frac{q}{C_{ox}} \\sqrt{\\frac{\\rho \\lambda}{2} \\left(1 - \\exp\\left(-\\frac{2T}{\\lambda}\\right)\\right)}} $$"
        },
        {
            "introduction": "While variance quantifies the spread of the threshold voltage distribution, it doesn't tell the whole story, especially in highly scaled devices where distributions are often non-Gaussian. This advanced problem  challenges you to go beyond variance and calculate the skewness of the $V_T$ distribution, a measure of its asymmetry. By modeling the total $V_T$ shift as a compound Poisson process, you will gain insight into the conditions under which a simple Gaussian approximation fails and a more detailed statistical characterization is necessary.",
            "id": "4159359",
            "problem": "Consider a Metal-Oxide-Semiconductor Field-Effect Transistor (MOSFET) in which the threshold voltage $V_T$ is influenced by Random Dopant Fluctuation (RDF) due to discrete ionized dopants in the channel. Model the threshold voltage as $V_T = V_{T,0} + S$, where $V_{T,0}$ is a deterministic reference threshold voltage and $S$ is a random sum of individual dopant contributions. Assume the following physically realistic model:\n\n- The number of dopants $N$ in the electrically sensitive region is a Poisson random variable with mean $\\lambda$, i.e., $N \\sim \\mathrm{Poisson}(\\lambda)$.\n- Conditional on $N$, dopant positions $\\{x_i\\}_{i=1}^{N}$ are independent and identically distributed with probability density function $p(x)$ along the depth coordinate $x \\geq 0$ into the semiconductor.\n- Each dopant at depth $x$ contributes an incremental threshold shift $\\Delta V_T(x)$ that depends on its position via the electrostatic weighting $w(x)$, so that $\\Delta V_T(x) = A\\,w(x)$, where $A$ is a positive constant aggregating charge and capacitance factors and $w(x)$ is strictly positive and decays with $x$.\n\nLet $p(x) = \\frac{1}{\\beta}\\exp\\!\\left(-\\frac{x}{\\beta}\\right)$ for $x \\geq 0$ represent a physically plausible implanted dopant depth profile with characteristic length $\\beta > 0$, and let the electrostatic weighting be $w(x) = \\exp\\!\\left(-\\frac{x}{\\ell}\\right)$ with characteristic screening length $\\ell > 0$. Thus, each dopant contributes $Y = \\Delta V_T(X) = A \\exp\\!\\left(-\\frac{X}{\\ell}\\right)$ where $X \\sim p(x)$ independently for each dopant. The total shift is $S = \\sum_{i=1}^{N} Y_i$.\n\nStarting from fundamental definitions of moments, cumulants, and the compound Poisson construction (obtained by conditioning on $N$ and using independence), derive an exact closed-form expression for the skewness $\\gamma_1$ of the $V_T$ distribution in terms of $\\lambda$, $\\beta$, and $\\ell$. Then, evaluate $\\gamma_1$ numerically for $\\ell = 1\\,\\mathrm{nm}$, $\\beta = 2\\,\\mathrm{nm}$, and $\\lambda = 50$.\n\nA Gaussian approximation to the distribution of $V_T$ is considered adequate when the absolute skewness satisfies $|\\gamma_1| < \\varepsilon$. Using the derived expression for $\\gamma_1$, determine the minimal expected dopant count $\\lambda_{\\min}$ such that the Gaussian approximation is adequate for $\\varepsilon = 0.10$, given the same $\\ell$ and $\\beta$.\n\nRound both numerical results to four significant figures. Both quantities are dimensionless; report them without units.",
            "solution": "## PROBLEM VALIDATION\n\n### Step 1: Extract Givens\n\n-   Threshold voltage model: $V_T = V_{T,0} + S$, where $V_{T,0}$ is a deterministic reference threshold voltage.\n-   Total random shift: $S = \\sum_{i=1}^{N} Y_i$.\n-   Number of dopants $N$ is a Poisson random variable: $N \\sim \\mathrm{Poisson}(\\lambda)$, where $\\lambda$ is the mean.\n-   Incremental threshold shift from a single dopant at depth $x$: $\\Delta V_T(x) = A\\,w(x)$, where $A$ is a positive constant.\n-   Random variable for individual contribution: $Y = \\Delta V_T(X) = A \\exp(-X/\\ell)$, where $X$ is a random variable representing dopant depth.\n-   The position $X$ has a probability density function (PDF): $p(x) = \\frac{1}{\\beta}\\exp(-x/\\beta)$ for $x \\geq 0$.\n-   The electrostatic weighting function is: $w(x) = \\exp(-x/\\ell)$.\n-   The characteristic length of the depth profile is $\\beta > 0$.\n-   The characteristic screening length is $\\ell > 0$.\n-   The individual contributions $\\{Y_i\\}_{i=1}^{N}$ are independent and identically distributed (i.i.d.).\n-   Skewness is denoted by $\\gamma_1$.\n-   Numerical values for the first calculation: $\\ell = 1\\,\\mathrm{nm}$, $\\beta = 2\\,\\mathrm{nm}$, $\\lambda = 50$.\n-   Condition for Gaussian approximation: $|\\gamma_1| < \\varepsilon$.\n-   Numerical values for the second calculation: $\\varepsilon = 0.10$, $\\ell = 1\\,\\mathrm{nm}$, $\\beta = 2\\,\\mathrm{nm}$.\n-   Required output: an exact closed-form expression for $\\gamma_1$, its numerical value for the first set of parameters, and the minimal expected dopant count $\\lambda_{\\min}$ for the second set of parameters. Both numerical results should be rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n\n-   **Scientifically Grounded**: The problem is well-grounded in the physics of semiconductor devices, specifically addressing the phenomenon of Random Dopant Fluctuation (RDF), a critical issue in modern nano-scale transistors. The use of a Poisson distribution for the number of discrete dopants, an exponential distribution for their depth profile (a common approximation for ion implantation tails), and an exponential decay for electrostatic influence are standard and physically plausible models in this field.\n-   **Well-Posed**: The problem is clearly stated, providing all necessary mathematical models, distributions, and parameters to derive a unique solution. The objectives are specific and quantifiable.\n-   **Objective**: The language is precise and technical, free of subjective or ambiguous terminology.\n-   **Self-Contained and Consistent**: All required information is provided within the problem statement. The models and parameters are consistent with each other. For example, the PDFs are properly normalized, and the physical parameters ($\\beta, \\ell, \\lambda, A$) are defined with positive values as physically required.\n-   **No Flaws**: The problem does not violate any of the invalidity criteria. It is a formalizable, non-trivial, and scientifically relevant problem in semiconductor process modeling.\n\n### Step 3: Verdict and Action\n\nThe problem is valid. A complete solution will be provided.\n\n## SOLUTION\n\nThe threshold voltage $V_T$ is given by $V_T = V_{T,0} + S$, where $V_{T,0}$ is a deterministic constant. The statistical properties of $V_T$, such as variance and skewness, are identical to those of the random variable $S$. The total shift $S$ is a sum of a random number of i.i.d. random variables, $S = \\sum_{i=1}^{N} Y_i$, where $N \\sim \\mathrm{Poisson}(\\lambda)$. This construction defines a compound Poisson process.\n\nThe skewness, $\\gamma_1$, is defined in terms of the cumulants $\\kappa_k$ of the distribution as $\\gamma_1 = \\frac{\\kappa_3}{\\kappa_2^{3/2}}$. For a compound Poisson process, the $k$-th cumulant of the sum $S$ is related to the moments of the individual term $Y$ by the law of total cumulance:\n$$ \\kappa_k[S] = \\lambda E[Y^k] $$\nTherefore, the second and third cumulants of $S$ are $\\kappa_2[S] = \\lambda E[Y^2]$ and $\\kappa_3[S] = \\lambda E[Y^3]$. The skewness of $S$ (and hence of $V_T$) is:\n$$ \\gamma_1 = \\frac{\\lambda E[Y^3]}{(\\lambda E[Y^2])^{3/2}} = \\frac{E[Y^3]}{\\sqrt{\\lambda} (E[Y^2])^{3/2}} $$\nTo proceed, we must compute the moments of the individual dopant contribution, $Y = A \\exp(-X/\\ell)$, where the random variable $X$ has the probability density function $p(x) = \\frac{1}{\\beta}\\exp(-x/\\beta)$ for $x \\geq 0$.\n\nThe $k$-th moment of $Y$ is given by:\n$$ E[Y^k] = E\\left[\\left(A \\exp\\left(-\\frac{X}{\\ell}\\right)\\right)^k\\right] = E\\left[A^k \\exp\\left(-\\frac{kX}{\\ell}\\right)\\right] = A^k E\\left[\\exp\\left(-\\frac{kX}{\\ell}\\right)\\right] $$\nWe calculate the expectation by integrating over the distribution of $X$:\n$$ E\\left[\\exp\\left(-\\frac{kX}{\\ell}\\right)\\right] = \\int_0^\\infty \\exp\\left(-\\frac{kx}{\\ell}\\right) p(x) \\, dx = \\int_0^\\infty \\exp\\left(-\\frac{kx}{\\ell}\\right) \\frac{1}{\\beta}\\exp\\left(-\\frac{x}{\\beta}\\right) \\, dx $$\n$$ = \\frac{1}{\\beta} \\int_0^\\infty \\exp\\left(-x\\left(\\frac{k}{\\ell} + \\frac{1}{\\beta}\\right)\\right) \\, dx = \\frac{1}{\\beta} \\int_0^\\infty \\exp\\left(-x\\frac{k\\beta + \\ell}{\\ell\\beta}\\right) \\, dx $$\nThis is a standard exponential integral:\n$$ = \\frac{1}{\\beta} \\left[ -\\frac{\\ell\\beta}{k\\beta + \\ell} \\exp\\left(-x\\frac{k\\beta + \\ell}{\\ell\\beta}\\right) \\right]_0^\\infty = \\frac{1}{\\beta} \\left(0 - \\left(-\\frac{\\ell\\beta}{k\\beta + \\ell}\\right)\\right) = \\frac{\\ell}{k\\beta + \\ell} $$\nThus, the $k$-th moment of $Y$ is:\n$$ E[Y^k] = A^k \\frac{\\ell}{k\\beta + \\ell} $$\nWe need the second ($k=2$) and third ($k=3$) moments:\n$$ E[Y^2] = A^2 \\frac{\\ell}{2\\beta + \\ell} $$\n$$ E[Y^3] = A^3 \\frac{\\ell}{3\\beta + \\ell} $$\nNow we substitute these into the expression for skewness. The constant $A$ cancels out:\n$$ \\gamma_1 = \\frac{A^3 \\frac{\\ell}{3\\beta + \\ell}}{\\sqrt{\\lambda} \\left(A^2 \\frac{\\ell}{2\\beta + \\ell}\\right)^{3/2}} = \\frac{A^3 \\ell (3\\beta + \\ell)^{-1}}{\\sqrt{\\lambda} A^3 \\ell^{3/2} (2\\beta + \\ell)^{-3/2}} $$\n$$ \\gamma_1 = \\frac{1}{\\sqrt{\\lambda} \\sqrt{\\ell}} \\frac{(2\\beta + \\ell)^{3/2}}{3\\beta + \\ell} $$\nThis is the required closed-form expression for the skewness $\\gamma_1$.\n\nNext, we evaluate $\\gamma_1$ numerically for $\\ell = 1\\,\\mathrm{nm}$, $\\beta = 2\\,\\mathrm{nm}$, and $\\lambda = 50$.\n$$ \\gamma_1 = \\frac{1}{\\sqrt{50}\\sqrt{1}} \\frac{(2(2) + 1)^{3/2}}{3(2) + 1} = \\frac{1}{\\sqrt{50}} \\frac{5^{3/2}}{7} = \\frac{5\\sqrt{5}}{7 \\cdot 5\\sqrt{2}} = \\frac{\\sqrt{5}}{7\\sqrt{2}} = \\frac{\\sqrt{10}}{14} $$\nNumerically, this value is:\n$$ \\gamma_1 \\approx \\frac{3.16227766}{14} \\approx 0.22587697... $$\nRounding to four significant figures, we get $\\gamma_1 \\approx 0.2259$.\n\nFinally, we determine the minimal expected dopant count $\\lambda_{\\min}$ such that the Gaussian approximation is adequate, i.e., $|\\gamma_1| < \\varepsilon$ for $\\varepsilon = 0.10$. Since all parameters are positive, $\\gamma_1 > 0$, so the condition is $\\gamma_1 < \\varepsilon$. As $\\gamma_1$ is a decreasing function of $\\lambda$, the minimal count $\\lambda_{\\min}$ occurs at the boundary $\\gamma_1 = \\varepsilon$.\n$$ \\varepsilon = \\frac{1}{\\sqrt{\\lambda_{\\min}} \\sqrt{\\ell}} \\frac{(2\\beta + \\ell)^{3/2}}{3\\beta + \\ell} $$\nSolving for $\\lambda_{\\min}$:\n$$ \\sqrt{\\lambda_{\\min}} = \\frac{1}{\\varepsilon \\sqrt{\\ell}} \\frac{(2\\beta + \\ell)^{3/2}}{3\\beta + \\ell} $$\n$$ \\lambda_{\\min} = \\frac{1}{\\varepsilon^2 \\ell} \\frac{(2\\beta + \\ell)^3}{(3\\beta + \\ell)^2} $$\nWe substitute the given values $\\varepsilon = 0.10$, $\\ell = 1\\,\\mathrm{nm}$, and $\\beta = 2\\,\\mathrm{nm}$:\n$$ \\lambda_{\\min} = \\frac{1}{(0.10)^2 (1)} \\frac{(2(2) + 1)^3}{(3(2) + 1)^2} = \\frac{1}{0.01} \\frac{5^3}{7^2} = 100 \\times \\frac{125}{49} = \\frac{12500}{49} $$\nNumerically, this value is:\n$$ \\lambda_{\\min} \\approx 255.10204... $$\nRounding to four significant figures, we get $\\lambda_{\\min} \\approx 255.1$.\n\nThe two numerical results are the skewness $\\gamma_1$ and the minimal expected dopant count $\\lambda_{\\min}$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.2259 & 255.1\n\\end{pmatrix}\n}\n$$"
        }
    ]
}