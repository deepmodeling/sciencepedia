{
    "hands_on_practices": [
        {
            "introduction": "A fundamental skill in process control is predicting how small, random fluctuations in process inputs propagate to the final manufactured output. Since the underlying physical models are often complex and non-linear, a powerful and common technique is to linearize the model around a nominal operating point. This exercise provides direct practice in using a first-order Taylor expansion to approximate a lithography process model, allowing you to calculate the resulting variance in a critical dimension (CD) based on the known variability of focus and dose settings . This is the cornerstone of sensitivity analysis and process window characterization.",
            "id": "4157337",
            "problem": "In optical lithography for semiconductor manufacturing, the line Critical Dimension (CD) depends on exposure focus $F$ (in $\\mathrm{nm}$ of defocus) and exposure dose $D$ (in $\\mathrm{mJ}\\cdot \\mathrm{cm}^{-2}$). Consider a single spatial frequency line-space feature whose CD can be modeled near a nominal operating point $(F_0,D_0)$ by a differentiable function $C(F,D)$ that encodes aerial image slope and resist threshold effects. Assume the nominal operating point is $(F_0,D_0) = (0, 20)$, and the CD function is\n$$\nC(F,D) = C_{\\mathrm{target}} + A \\arctan(\\alpha F) - B \\ln\\!\\left(\\frac{D}{D_0}\\right) + C F \\left(\\frac{D}{D_0} - 1\\right),\n$$\nwith $C_{\\mathrm{target}} = 28$, $A = 5$, $\\alpha = 0.015$, $B = 12$, and $C = 0.03$. All quantities inside $C(F,D)$ are in $\\mathrm{nm}$ except $D$ which uses $\\mathrm{mJ}\\cdot \\mathrm{cm}^{-2}$; the function $C(F,D)$ outputs CD in $\\mathrm{nm}$. The final interaction term captures first-order coupling between focus $F$ and normalized dose deviation $\\frac{D}{D_0} - 1$.\n\nStarting from the first-order Taylor expansion for a differentiable scalar field and the definitions of variance and covariance, perform the following:\n\n1. Derive the linearized mapping from the deviations $\\Delta F = F - F_0$ and $\\Delta D = D - D_0$ to the deviation in CD, $\\Delta \\mathrm{CD} = C(F,D) - C(F_0,D_0)$, at $(F_0, D_0)$. Express the result as an explicit affine function with numerical coefficients evaluated at $(F_0,D_0)$.\n\n2. Suppose the joint variability of $(\\Delta F, \\Delta D)$ is zero-mean and characterized by the covariance matrix\n$$\n\\Sigma = \\begin{pmatrix}\n36  -0.9 \\\\\n-0.9  0.25\n\\end{pmatrix},\n$$\nwhere the first row and column correspond to $\\Delta F$ (in $\\mathrm{nm}$) and the second to $\\Delta D$ (in $\\mathrm{mJ}\\cdot \\mathrm{cm}^{-2}$). Compute the variance of the CD under the linearized mapping, $\\mathrm{Var}(\\mathrm{CD})$, in $\\mathrm{nm}^2$.\n\nRound your final numerical value for $\\mathrm{Var}(\\mathrm{CD})$ to four significant figures and express it in $\\mathrm{nm}^2$.",
            "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. There is a minor ambiguity in the phrasing regarding the units of the constant $C$, but dimensional analysis of the provided equation for $C(F,D)$ uniquely determines that $C$ must be a dimensionless quantity for the equation to be consistent. With this clarification, the problem is solvable.\n\nThe problem requires a two-step analysis: first, deriving a linearized model for the Critical Dimension (CD) deviation, and second, using this model to compute the variance of the CD based on the given process variability.\n\n**Part 1: Derivation of the Linearized Mapping**\n\nThe relationship between the deviation in CD, $\\Delta \\mathrm{CD} = C(F,D) - C(F_0,D_0)$, and the deviations in focus, $\\Delta F = F - F_0$, and dose, $\\Delta D = D - D_0$, can be approximated by a first-order Taylor expansion of the function $C(F,D)$ around the nominal operating point $(F_0,D_0)$.\nFor a differentiable scalar field $C(F,D)$, this expansion is given by:\n$$\n\\Delta \\mathrm{CD} \\approx \\left. \\frac{\\partial C}{\\partial F} \\right|_{(F_0,D_0)} (F - F_0) + \\left. \\frac{\\partial C}{\\partial D} \\right|_{(F_0,D_0)} (D - D_0)\n$$\nThis can be written more compactly as:\n$$\n\\Delta \\mathrm{CD} \\approx S_F \\Delta F + S_D \\Delta D\n$$\nwhere $S_F$ and $S_D$ are the sensitivities of the CD to focus and dose, respectively, evaluated at the nominal point.\n\nThe CD function is given as:\n$$\nC(F,D) = C_{\\mathrm{target}} + A \\arctan(\\alpha F) - B \\ln\\!\\left(\\frac{D}{D_0}\\right) + C F \\left(\\frac{D}{D_0} - 1\\right)\n$$\nFirst, we compute the partial derivative with respect to focus, $F$:\n$$\n\\frac{\\partial C}{\\partial F} = \\frac{\\partial}{\\partial F} \\left[ C_{\\mathrm{target}} + A \\arctan(\\alpha F) - B \\ln\\!\\left(\\frac{D}{D_0}\\right) + C F \\left(\\frac{D}{D_0} - 1\\right) \\right] = A \\frac{\\alpha}{1 + (\\alpha F)^2} + C \\left(\\frac{D}{D_0} - 1\\right)\n$$\nNext, we compute the partial derivative with respect to dose, $D$:\n$$\n\\frac{\\partial C}{\\partial D} = \\frac{\\partial}{\\partial D} \\left[ C_{\\mathrm{target}} + A \\arctan(\\alpha F) - B \\ln\\!\\left(\\frac{D}{D_0}\\right) + C F \\left(\\frac{D}{D_0} - 1\\right) \\right] = -B \\frac{1}{D/D_0} \\cdot \\frac{1}{D_0} + C F \\frac{1}{D_0} = -\\frac{B}{D} + \\frac{C F}{D_0}\n$$\nNow, we evaluate these sensitivities at the nominal operating point $(F_0, D_0) = (0, 20)$.\n$$\nS_F = \\left. \\frac{\\partial C}{\\partial F} \\right|_{(0,20)} = A \\frac{\\alpha}{1 + (\\alpha \\cdot 0)^2} + C \\left(\\frac{20}{20} - 1\\right) = A\\alpha + C(0) = A\\alpha\n$$\n$$\nS_D = \\left. \\frac{\\partial C}{\\partial D} \\right|_{(0,20)} = -\\frac{B}{20} + \\frac{C \\cdot 0}{20} = -\\frac{B}{D_0}\n$$\nSubstituting the given numerical values for the parameters: $A = 5$, $\\alpha = 0.015$, $B = 12$, and $D_0 = 20$.\n$$\nS_F = 5 \\cdot 0.015 = 0.075\n$$\nThe units of $S_F$ are nm/nm, making it a dimensionless quantity.\n$$\nS_D = -\\frac{12}{20} = -0.6\n$$\nThe units of $S_D$ are $\\mathrm{nm} / (\\mathrm{mJ}\\cdot \\mathrm{cm}^{-2})$.\n\nTherefore, the linearized mapping from the deviations $(\\Delta F, \\Delta D)$ to the CD deviation $\\Delta \\mathrm{CD}$ is:\n$$\n\\Delta \\mathrm{CD} \\approx 0.075 \\Delta F - 0.6 \\Delta D\n$$\n\n**Part 2: Calculation of CD Variance**\n\nThe variance of a linear combination of two correlated random variables, $Y = aX_1 + bX_2$, is given by the formula:\n$$\n\\mathrm{Var}(Y) = a^2 \\mathrm{Var}(X_1) + b^2 \\mathrm{Var}(X_2) + 2ab \\mathrm{Cov}(X_1, X_2)\n$$\nIn our case, the CD deviation $\\Delta \\mathrm{CD}$ is approximated by a linear function of the random variables $\\Delta F$ and $\\Delta D$. Thus, we have:\n$Y = \\Delta \\mathrm{CD}$, $X_1 = \\Delta F$, $X_2 = \\Delta D$, $a = S_F = 0.075$, and $b = S_D = -0.6$.\n\nThe variances and covariance are given by the covariance matrix $\\Sigma$:\n$$\n\\Sigma = \\begin{pmatrix} \\mathrm{Var}(\\Delta F)  \\mathrm{Cov}(\\Delta F, \\Delta D) \\\\ \\mathrm{Cov}(\\Delta D, \\Delta F)  \\mathrm{Var}(\\Delta D) \\end{pmatrix} = \\begin{pmatrix} 36  -0.9 \\\\ -0.9  0.25 \\end{pmatrix}\n$$\nFrom the matrix, we extract the required statistical moments:\n$\\mathrm{Var}(\\Delta F) = \\sigma_F^2 = 36$ $\\mathrm{nm}^2$\n$\\mathrm{Var}(\\Delta D) = \\sigma_D^2 = 0.25$ $(\\mathrm{mJ}\\cdot \\mathrm{cm}^{-2})^2$\n$\\mathrm{Cov}(\\Delta F, \\Delta D) = -0.9$ $\\mathrm{nm} \\cdot \\mathrm{mJ}\\cdot \\mathrm{cm}^{-2}$\n\nWe can now compute the variance of the CD, $\\mathrm{Var}(\\mathrm{CD})$, which is approximately equal to the variance of the linearized deviation, $\\mathrm{Var}(\\Delta \\mathrm{CD})$.\n$$\n\\mathrm{Var}(\\mathrm{CD}) \\approx \\mathrm{Var}(\\Delta \\mathrm{CD}) = S_F^2 \\mathrm{Var}(\\Delta F) + S_D^2 \\mathrm{Var}(\\Delta D) + 2 S_F S_D \\mathrm{Cov}(\\Delta F, \\Delta D)\n$$\nSubstituting the numerical values:\n$$\n\\mathrm{Var}(\\mathrm{CD}) \\approx (0.075)^2 (36) + (-0.6)^2 (0.25) + 2(0.075)(-0.6)(-0.9)\n$$\nLet's compute each term separately:\nThe first term:\n$$\n(0.075)^2 \\cdot 36 = 0.005625 \\cdot 36 = 0.2025 \\,\\,\\mathrm{nm^2}\n$$\nThe second term:\n$$\n(-0.6)^2 \\cdot 0.25 = 0.36 \\cdot 0.25 = 0.09 \\,\\,\\mathrm{nm^2}\n$$\nThe third term (covariance term):\n$$\n2(0.075)(-0.6)(-0.9) = 2(0.075)(0.54) = 0.15 \\cdot 0.54 = 0.081 \\,\\,\\mathrm{nm^2}\n$$\nSumming the terms gives the total variance:\n$$\n\\mathrm{Var}(\\mathrm{CD}) \\approx 0.2025 + 0.09 + 0.081 = 0.3735 \\,\\,\\mathrm{nm^2}\n$$\nThe problem requests the result rounded to four significant figures. The calculated value $0.3735$ already has four significant figures.\nThus, the variance of the CD is $0.3735$ $\\mathrm{nm}^2$.",
            "answer": "$$\n\\boxed{0.3735}\n$$"
        },
        {
            "introduction": "While the previous exercise focused on propagating known input variances, engineers often face the inverse problem: decomposing measured output variability to identify its root causes. This practice introduces the rigorous statistical framework of Analysis of Variance (ANOVA) for a nested random-effects model, a common scenario in a hierarchical manufacturing environment. By partitioning the total variance into contributions from different sources—such as chamber, wafer, and die—you can perform a formal hypothesis test to pinpoint the most significant drivers of process instability and prioritize improvement efforts .",
            "id": "4157299",
            "problem": "A lithography module in a high-volume semiconductor fabrication plant operates with $a$ identical process chambers. In a scheduled run, each chamber processes $b$ nominally identical wafers, and each wafer has $n$ die-level measurements of a critical dimension (CD) recorded. The manufacturing engineering team seeks to determine whether chamber-to-chamber variability is statistically significant relative to wafer-to-wafer variability, under an Analysis of Variance (ANOVA) framework. Assume a balanced nested random-effects model $y_{jk\\ell} = \\mu + C_{j} + W_{k(j)} + \\varepsilon_{jk\\ell}$, where $y_{jk\\ell}$ is the CD of die $\\ell$ on wafer $k$ processed in chamber $j$, $C_{j}$ is the chamber random effect, $W_{k(j)}$ is the wafer random effect nested in chamber $j$, and $\\varepsilon_{jk\\ell}$ is the within-wafer residual. Assume $C_{j}$, $W_{k(j)}$, and $\\varepsilon_{jk\\ell}$ are mutually independent, each has zero mean, and follows a normal distribution.\n\nIn a balanced experiment with $a=4$ chambers, $b=5$ wafers per chamber, and $n=12$ dies per wafer, the following aggregated statistics were computed from the measured data (units are nanometers for CD, but the test statistic is unitless):\n\n- The grand mean is $\\bar{y}_{\\cdot\\cdot\\cdot} = 32.50$.\n- The chamber means are $\\bar{y}_{1\\cdot\\cdot} = 32.40$, $\\bar{y}_{2\\cdot\\cdot} = 32.65$, $\\bar{y}_{3\\cdot\\cdot} = 32.45$, and $\\bar{y}_{4\\cdot\\cdot} = 32.50$.\n- For each chamber $j \\in \\{1,2,3,4\\}$, the sum of squared deviations of wafer means from the corresponding chamber mean is\n  $\\sum_{k=1}^{b}\\left(\\bar{y}_{jk\\cdot} - \\bar{y}_{j\\cdot\\cdot}\\right)^{2}$ equal to $0.06$ for $j=1$, $0.05$ for $j=2$, $0.07$ for $j=3$, and $0.06$ for $j=4$.\n- The within-wafer sum of squares based on die-level variability, $\\sum_{j=1}^{a}\\sum_{k=1}^{b}\\sum_{\\ell=1}^{n}\\left(y_{jk\\ell} - \\bar{y}_{jk\\cdot}\\right)^{2}$, equals $8.80$.\n\nUsing the balanced nested random-effects framework and the standard ANOVA decomposition for the model above, formulate the null and alternative hypotheses to test whether the chamber variance component is zero. Then, construct the appropriate $F$-statistic that compares chamber-to-chamber variability relative to wafer-to-wafer variability, and compute its numerical value from the provided aggregated statistics.\n\nRound your final reported $F$-statistic to four significant figures. Express the final answer as a unitless number.",
            "solution": "The problem statement has been validated and is deemed sound. It is a well-posed statistical problem based on standard principles of Analysis of Variance (ANOVA) applied to a nested random-effects model, which is a scientifically grounded method for analyzing sources of variability in hierarchical manufacturing processes. All necessary data are provided, and the problem is free of contradictions or ambiguities.\n\nThe problem requires us to test for the significance of chamber-to-chamber variability in a semiconductor manufacturing process. This is framed within a balanced nested random-effects model given by:\n$$\ny_{jk\\ell} = \\mu + C_{j} + W_{k(j)} + \\varepsilon_{jk\\ell}\n$$\nwhere $y_{jk\\ell}$ is the measurement for die $\\ell$ on wafer $k$ from chamber $j$. The terms $C_{j}$, $W_{k(j)}$, and $\\varepsilon_{jk\\ell}$ are independent random effects.\n- $C_j \\sim N(0, \\sigma_C^2)$ represents the random effect of chamber $j$.\n- $W_{k(j)} \\sim N(0, \\sigma_W^2)$ represents the random effect of wafer $k$ nested within chamber $j$.\n- $\\varepsilon_{jk\\ell} \\sim N(0, \\sigma^2)$ represents the random error for die $\\ell$ on wafer $k$ in chamber $j$.\n\nThe number of levels for each factor are given as:\n- Number of chambers, $a = 4$.\n- Number of wafers per chamber, $b = 5$.\n- Number of dies per wafer, $n = 12$.\n\nThe objective is to determine if the chamber variance component, $\\sigma_C^2$, is statistically significant. This translates to testing the following null and alternative hypotheses:\n- Null hypothesis, $H_0: \\sigma_C^2 = 0$. This hypothesis states that there is no variability between the process chambers.\n- Alternative hypothesis, $H_1: \\sigma_C^2  0$. This hypothesis states that there is significant variability between the chambers. The test is one-sided as variance cannot be negative.\n\nTo test these hypotheses, we use an ANOVA F-test. This requires decomposing the total sum of squares into components corresponding to each source of variation in the model. The primary sources are Chambers (C), Wafers within Chambers (W(C)), and Error (within-wafer, E).\n\nFirst, we calculate the degrees of freedom (df) associated with each source of variation:\n- Chambers: $df_C = a - 1 = 4 - 1 = 3$.\n- Wafers within Chambers: $df_{W(C)} = a(b-1) = 4(5-1) = 4(4) = 16$.\n- Error: $df_E = ab(n-1) = 4 \\times 5 \\times (12-1) = 20 \\times 11 = 220$.\n\nNext, we compute the Sum of Squares (SS) for each source using the provided statistics.\n\nThe Sum of Squares for Chambers ($SSC$) measures the variability between chamber means ($\\bar{y}_{j\\cdot\\cdot}$) and the grand mean ($\\bar{y}_{\\cdot\\cdot\\cdot}$).\n$$\nSSC = bn \\sum_{j=1}^{a} (\\bar{y}_{j\\cdot\\cdot} - \\bar{y}_{\\cdot\\cdot\\cdot})^2\n$$\nThe givens are $b=5$, $n=12$, $\\bar{y}_{\\cdot\\cdot\\cdot} = 32.50$, and the chamber means $\\bar{y}_{1\\cdot\\cdot} = 32.40$, $\\bar{y}_{2\\cdot\\cdot} = 32.65$, $\\bar{y}_{3\\cdot\\cdot} = 32.45$, and $\\bar{y}_{4\\cdot\\cdot} = 32.50$.\nThe sum of squared deviations is:\n$$\n\\sum_{j=1}^{4} (\\bar{y}_{j\\cdot\\cdot} - \\bar{y}_{\\cdot\\cdot\\cdot})^2 = (32.40 - 32.50)^2 + (32.65 - 32.50)^2 + (32.45 - 32.50)^2 + (32.50 - 32.50)^2\n$$\n$$\n= (-0.10)^2 + (0.15)^2 + (-0.05)^2 + (0)^2 = 0.0100 + 0.0225 + 0.0025 + 0 = 0.0350\n$$\nTherefore, $SSC$ is:\n$$\nSSC = (5)(12) \\times 0.0350 = 60 \\times 0.0350 = 2.10\n$$\n\nThe Sum of Squares for Wafers within Chambers ($SSW$) measures the variability of wafer means ($\\bar{y}_{jk\\cdot}$) around their respective chamber means ($\\bar{y}_{j\\cdot\\cdot}$).\n$$\nSSW = n \\sum_{j=1}^{a} \\sum_{k=1}^{b} (\\bar{y}_{jk\\cdot} - \\bar{y}_{j\\cdot\\cdot})^2\n$$\nThe problem provides the sum of squared deviations for each chamber, $\\sum_{k=1}^{b}(\\bar{y}_{jk\\cdot} - \\bar{y}_{j\\cdot\\cdot})^{2}$. We sum these values across all chambers:\n$$\n\\sum_{j=1}^{4} \\left[ \\sum_{k=1}^{5} (\\bar{y}_{jk\\cdot} - \\bar{y}_{j\\cdot\\cdot})^2 \\right] = 0.06 + 0.05 + 0.07 + 0.06 = 0.24\n$$\nThus, $SSW$ is:\n$$\nSSW = 12 \\times 0.24 = 2.88\n$$\nThe Sum of Squares for Error ($SSE$), representing the within-wafer (die-to-die) variability, is given directly as $SSE = 8.80$.\n\nWith the SS and df values, we can calculate the Mean Squares (MS), which are the average sums of squares.\n- Mean Square for Chambers: $MSC = \\frac{SSC}{df_C} = \\frac{2.10}{3} = 0.70$.\n- Mean Square for Wafers within Chambers: $MSW = \\frac{SSW}{df_{W(C)}} = \\frac{2.88}{16} = 0.18$.\n- Mean Square for Error: $MSE = \\frac{SSE}{df_E} = \\frac{8.80}{220} = 0.04$.\n\nTo construct the correct F-statistic for testing $H_0: \\sigma_C^2 = 0$, we must examine the Expected Mean Squares (EMS) for this model. For a balanced nested random-effects model, the EMS are:\n- $E(MSE) = \\sigma^2$\n- $E(MSW) = \\sigma^2 + n\\sigma_W^2$\n- $E(MSC) = \\sigma^2 + n\\sigma_W^2 + bn\\sigma_C^2$\n\nThe F-statistic is a ratio of two mean squares whose expected values are identical under the null hypothesis. We wish to test $H_0: \\sigma_C^2 = 0$.\nIf $H_0$ is true, then $E(MSC) = \\sigma^2 + n\\sigma_W^2 + bn(0) = \\sigma^2 + n\\sigma_W^2$.\nThis is identical to $E(MSW)$. Therefore, the appropriate F-statistic is the ratio of $MSC$ to $MSW$. This directly addresses the problem's requirement to compare chamber-to-chamber variability ($MSC$) to wafer-to-wafer variability ($MSW$).\n$$\nF = \\frac{MSC}{MSW}\n$$\nUnder $H_0$, this statistic follows an F-distribution with $df_C=3$ and $df_{W(C)}=16$ degrees of freedom.\n\nSubstituting the calculated numerical values:\n$$\nF = \\frac{0.70}{0.18} = \\frac{70}{18} = \\frac{35}{9} \\approx 3.8888...\n$$\n\nThe problem requires rounding the final value to four significant figures.\n$$\nF \\approx 3.889\n$$\nThis value would then be compared to the critical value from the $F_{3,16}$ distribution at a chosen significance level to decide whether to reject the null hypothesis. The computed F-statistic itself is the quantity requested.",
            "answer": "$$\n\\boxed{3.889}\n$$"
        },
        {
            "introduction": "Process variations rarely affect different device features in isolation; instead, they often induce correlated patterns across multiple measurements. This final practice moves from analyzing individual variance components to a multivariate approach for uncovering these systematic relationships. You will use the principles of eigen-decomposition—the mathematical foundation of Principal Component Analysis (PCA)—to deconstruct a covariance matrix into its dominant modes of variation. This powerful technique allows you to connect the abstract statistical modes back to underlying physical mechanisms, such as global process drifts or pattern-dependent effects, providing a much deeper insight into the process behavior .",
            "id": "4157327",
            "problem": "A single-wafer metrology experiment measures post-etch critical dimension offsets across three layout categories: dense lines ($D$), semi-dense lines ($S$), and isolated lines ($I$). For each wafer, the measurement vector is modeled as $x = [\\Delta \\mathrm{CD}_{D}, \\Delta \\mathrm{CD}_{S}, \\Delta \\mathrm{CD}_{I}]^{\\top}$. Assume the following physically motivated, statistically independent sources of variability contribute additively to $x$:\n\n- A global chamber drift mode that shifts all categories similarly, represented by a unit signature vector $u = \\frac{1}{\\sqrt{3}}[1, 1, 1]^{\\top}$, with source variance $\\sigma_{c}^{2}$.\n- A microloading pattern-density mode that shifts dense and semi-dense in opposite directions while leaving isolated approximately unchanged, represented by a unit signature vector $v = \\frac{1}{\\sqrt{2}}[1, -1, 0]^{\\top}$, with source variance $\\sigma_{p}^{2}$.\n- Independent category-specific noise (tool measurement and local stochastic effects) that contributes isotropically, modeled as white noise with variance $\\sigma_{i}^{2}$ per layout category.\n\nUnder the assumptions of independence and linear superposition of sources, the covariance of $x$ is\n$$\n\\Sigma = \\sigma_{c}^{2} \\, u u^{\\top} + \\sigma_{p}^{2} \\, v v^{\\top} + \\sigma_{i}^{2} \\, I_{3},\n$$\nwhere $I_{3}$ is the $3 \\times 3$ identity matrix. Suppose for a given stable process, the source variances have been estimated as $\\sigma_{c}^{2} = 4.0$, $\\sigma_{p}^{2} = 1.0$, and $\\sigma_{i}^{2} = 0.25$ (each in the same squared units of critical dimension).\n\nStarting from the definitions of covariance for independent sources and the spectral theorem for symmetric positive semi-definite matrices, derive the eigen-decomposition of $\\Sigma$ by identifying its eigenvalues and orthonormal eigenvectors. Explain how each eigenvector corresponds to a physical mode of variation in the process and justify the association. Then, using your decomposition, compute the fraction of total variance explained by the dominant principal component (the one associated with the largest eigenvalue), expressed as a decimal number. Use the linear algebra notion of Principal Component Analysis (PCA) only after deriving the eigen-decomposition from first principles. Round your final decimal to $4$ significant figures. Express the final fraction without a percent sign.",
            "solution": "The problem requires the eigen-decomposition of a given covariance matrix $\\Sigma$ and the calculation of the fraction of total variance attributable to the dominant principal component. The covariance matrix is defined as a linear combination of rank-one matrices derived from physically motivated source vectors and an isotropic noise term.\n\nThe given measurement vector is $x = [\\Delta \\mathrm{CD}_{D}, \\Delta \\mathrm{CD}_{S}, \\Delta \\mathrm{CD}_{I}]^{\\top}$. The covariance matrix of $x$ is given by the model:\n$$\n\\Sigma = \\sigma_{c}^{2} \\, u u^{\\top} + \\sigma_{p}^{2} \\, v v^{\\top} + \\sigma_{i}^{2} \\, I_{3}\n$$\nwhere $I_3$ is the $3 \\times 3$ identity matrix. The given source variances are $\\sigma_{c}^{2} = 4.0$, $\\sigma_{p}^{2} = 1.0$, and $\\sigma_{i}^{2} = 0.25$. The signature vectors are:\n$$\nu = \\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad v = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}\n$$\n\nThe first step is to derive the eigen-decomposition of $\\Sigma$. An eigenvector $q$ and its corresponding eigenvalue $\\lambda$ of a matrix $\\Sigma$ satisfy the equation $\\Sigma q = \\lambda q$. The matrix $\\Sigma$ is symmetric since $(u u^{\\top})^{\\top} = u u^{\\top}$, $(v v^{\\top})^{\\top} = v v^{\\top}$, and $I_3^{\\top} = I_3$. Therefore, it must have three real eigenvalues and a set of three mutually orthogonal eigenvectors.\n\nA key insight can be gained by examining the structure of $\\Sigma$. It is constructed from matrices $u u^{\\top}$ and $v v^{\\top}$. Let's investigate the properties of the vectors $u$ and $v$. They are given as unit vectors:\n$u^{\\top}u = \\frac{1}{3}(1^2 + 1^2 + 1^2) = 1$.\n$v^{\\top}v = \\frac{1}{2}(1^2 + (-1)^2 + 0^2) = 1$.\n\nLet's check their orthogonality:\n$$\nu^{\\top}v = \\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1  1  1 \\end{pmatrix} \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{6}}(1 \\cdot 1 + 1 \\cdot (-1) + 1 \\cdot 0) = 0\n$$\nSince $u$ and $v$ are orthogonal, this suggests that they may be eigenvectors of $\\Sigma$. Let's test this hypothesis.\n\nConsider the action of $\\Sigma$ on the vector $u$:\n$$\n\\Sigma u = (\\sigma_{c}^{2} u u^{\\top} + \\sigma_{p}^{2} v v^{\\top} + \\sigma_{i}^{2} I_{3}) u\n$$\nUsing the distributive property of matrix multiplication:\n$$\n\\Sigma u = \\sigma_{c}^{2} u (u^{\\top}u) + \\sigma_{p}^{2} v (v^{\\top}u) + \\sigma_{i}^{2} (I_{3} u)\n$$\nSince $u^{\\top}u=1$ and $v^{\\top}u = (u^{\\top}v)^{\\top}=0$:\n$$\n\\Sigma u = \\sigma_{c}^{2} u (1) + \\sigma_{p}^{2} v (0) + \\sigma_{i}^{2} u = (\\sigma_{c}^{2} + \\sigma_{i}^{2})u\n$$\nThis is of the form $\\Sigma u = \\lambda_1 u$. Thus, $q_1 = u$ is an eigenvector of $\\Sigma$ with the corresponding eigenvalue $\\lambda_1 = \\sigma_{c}^{2} + \\sigma_{i}^{2}$.\n\nNext, consider the action of $\\Sigma$ on the vector $v$:\n$$\n\\Sigma v = (\\sigma_{c}^{2} u u^{\\top} + \\sigma_{p}^{2} v v^{\\top} + \\sigma_{i}^{2} I_{3}) v\n$$\n$$\n\\Sigma v = \\sigma_{c}^{2} u (u^{\\top}v) + \\sigma_{p}^{2} v (v^{\\top}v) + \\sigma_{i}^{2} (I_{3} v)\n$$\nSince $u^{\\top}v=0$ and $v^{\\top}v=1$:\n$$\n\\Sigma v = \\sigma_{c}^{2} u (0) + \\sigma_{p}^{2} v (1) + \\sigma_{i}^{2} v = (\\sigma_{p}^{2} + \\sigma_{i}^{2})v\n$$\nThis is of the form $\\Sigma v = \\lambda_2 v$. Thus, $q_2 = v$ is an eigenvector of $\\Sigma$ with the corresponding eigenvalue $\\lambda_2 = \\sigma_{p}^{2} + \\sigma_{i}^{2}$.\n\nSince $\\Sigma$ is a $3 \\times 3$ symmetric matrix, it has a third eigenvector, $q_3$, which must be orthogonal to both $q_1=u$ and $q_2=v$. We can find a vector $w'$ orthogonal to the components of $u$ and $v$, which are proportional to $(1,1,1)$ and $(1,-1,0)$. Let $w' = (w_x, w_y, w_z)$.\n$w' \\cdot (1,1,1) = w_x + w_y + w_z = 0$\n$w' \\cdot (1,-1,0) = w_x - w_y = 0 \\implies w_x = w_y$.\nSubstituting the second equation into the first gives $w_x + w_x + w_z = 0 \\implies w_z = -2w_x$.\nChoosing $w_x=1$, we get the vector $w' = (1,1,-2)$. To obtain the unit eigenvector $q_3$, we normalize $w'$:\n$$\nq_3 = \\frac{w'}{||w'||} = \\frac{1}{\\sqrt{1^2+1^2+(-2)^2}}\\begin{pmatrix} 1 \\\\ 1 \\\\ -2 \\end{pmatrix} = \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1 \\\\ 1 \\\\ -2 \\end{pmatrix}\n$$\nNow, consider the action of $\\Sigma$ on $q_3$:\n$$\n\\Sigma q_3 = (\\sigma_{c}^{2} u u^{\\top} + \\sigma_{p}^{2} v v^{\\top} + \\sigma_{i}^{2} I_{3}) q_3\n$$\n$$\n\\Sigma q_3 = \\sigma_{c}^{2} u (u^{\\top}q_3) + \\sigma_{p}^{2} v (v^{\\top}q_3) + \\sigma_{i}^{2} (I_{3} q_3)\n$$\nBy construction, $q_3$ is orthogonal to $u$ and $v$, so $u^{\\top}q_3 = 0$ and $v^{\\top}q_3 = 0$.\n$$\n\\Sigma q_3 = \\sigma_{c}^{2} u (0) + \\sigma_{p}^{2} v (0) + \\sigma_{i}^{2} q_3 = \\sigma_{i}^{2}q_3\n$$\nThus, $q_3$ is an eigenvector of $\\Sigma$ with the corresponding eigenvalue $\\lambda_3 = \\sigma_{i}^{2}$.\n\nThe eigen-decomposition has yielded the following orthonormal eigenvectors and eigenvalues:\n- $q_1 = u = \\frac{1}{\\sqrt{3}}[1, 1, 1]^{\\top}$ with eigenvalue $\\lambda_1 = \\sigma_{c}^{2} + \\sigma_{i}^{2}$. This eigenvector represents the global chamber drift mode, where all CD offsets shift together in the same direction. The eigenvalue represents the total variance along this direction, composed of the chamber source variance and the isotropic noise variance.\n- $q_2 = v = \\frac{1}{\\sqrt{2}}[1, -1, 0]^{\\top}$ with eigenvalue $\\lambda_2 = \\sigma_{p}^{2} + \\sigma_{i}^{2}$. This eigenvector represents the microloading pattern density mode, where dense and semi-dense CD offsets shift in opposite directions, and the isolated CD is unaffected. The variance along this direction is the sum of the microloading source variance and the isotropic noise variance.\n- $q_3 = \\frac{1}{\\sqrt{6}}[1, 1, -2]^{\\top}$ with eigenvalue $\\lambda_3 = \\sigma_{i}^{2}$. This eigenvector represents a residual mode of variation after accounting for the two primary physical modes. It captures a contrast between the average of dense/semi-dense CDs and the isolated CD. The variance along this direction is solely due to the isotropic category-specific noise. This is the Principal Component Analysis (PCA) interpretation of the eigen-decomposition.\n\nNow, we compute the numerical values of the eigenvalues using the provided variances: $\\sigma_{c}^{2} = 4.0$, $\\sigma_{p}^{2} = 1.0$, and $\\sigma_{i}^{2} = 0.25$.\n$$\n\\lambda_1 = 4.0 + 0.25 = 4.25\n$$\n$$\n\\lambda_2 = 1.0 + 0.25 = 1.25\n$$\n$$\n\\lambda_3 = 0.25\n$$\nThe principal components are the eigenvectors $q_1, q_2, q_3$. The dominant principal component is the one associated with the largest eigenvalue. Here, the largest eigenvalue is $\\lambda_1 = 4.25$.\n\nThe total variance of the process, $V_{total}$, is the trace of the covariance matrix, $\\text{Tr}(\\Sigma)$. The trace is also equal to the sum of the eigenvalues.\n$$\nV_{total} = \\lambda_1 + \\lambda_2 + \\lambda_3 = 4.25 + 1.25 + 0.25 = 5.75\n$$\nThe fraction of total variance explained by the dominant principal component (associated with $\\lambda_1$) is the ratio of its eigenvalue to the total variance:\n$$\n\\text{Fraction} = \\frac{\\lambda_1}{V_{total}} = \\frac{4.25}{5.75}\n$$\nTo compute the decimal value, we can simplify the fraction:\n$$\n\\frac{4.25}{5.75} = \\frac{425}{575} = \\frac{17 \\times 25}{23 \\times 25} = \\frac{17}{23}\n$$\nPerforming the division:\n$$\n\\frac{17}{23} \\approx 0.73913043...\n$$\nRounding to $4$ significant figures, we get $0.7391$.",
            "answer": "$$\n\\boxed{0.7391}\n$$"
        }
    ]
}