{
    "hands_on_practices": [
        {
            "introduction": "A predictive model is useless if its parameters cannot be uniquely determined from experimental data. This fundamental property, known as identifiability, is a critical prerequisite in process modeling. This exercise guides you through selecting an efficient experimental design that guarantees identifiability for a linearized lithography model, using the Fisher information matrix as the mathematical tool to assess the information content of your chosen measurements. ",
            "id": "4157910",
            "problem": "A critical dimension response model in semiconductor lithography is linearized within a small process window around a nominal condition as follows: for exposure $j$, the measured critical dimension $y_{j}$ is modeled by\n$$\ny_{j} \\;=\\; \\theta_{0} \\;+\\; \\theta_{E}\\,\\delta E_{j} \\;+\\; \\theta_{F}\\,\\delta F_{j} \\;+\\; \\varepsilon_{j},\n$$\nwhere $\\theta_{0}$ is the mask bias offset, $\\theta_{E}$ is the dose sensitivity, $\\theta_{F}$ is the focus sensitivity, and $\\varepsilon_{j}$ are independent and identically distributed measurement errors assumed Gaussian with zero mean and variance $\\sigma^{2}$. These parameters are central to Design-Technology Co-Optimization (DTCO) and process window optimization because they quantify how patterning outcomes respond to dose and focus. The process window corner exposures are available as a candidate set:\n$$\n(\\delta E, \\delta F) \\in \\{(-1,-1),\\,(-1,1),\\,(1,-1),\\,(1,1)\\}.\n$$\nAssume all exposures produce independent measurements with the same $\\sigma$, and that the linearization is valid in the given window. From the standpoint of Bayesian inverse modeling with Gaussian noise, the Fisher information encapsulates the curvature of the log-likelihood and determines local identifiability.\n\nStarting from the Gaussian noise model and the definition of Fisher information as the expectation of the negative Hessian of the log-likelihood with respect to $(\\theta_{0}, \\theta_{E}, \\theta_{F})$, do the following:\n\n- Select a minimal subset of exposures from the candidate set that ensures the parameter vector $(\\theta_{0}, \\theta_{E}, \\theta_{F})$ is identifiable.\n- Compute the Fisher information matrix for your selected minimal subset in terms of $\\sigma$.\n- Report the determinant of this Fisher information matrix as a closed-form analytic expression in $\\sigma$.\n\nExpress the final determinant as a function of $\\sigma$. No rounding is needed and no physical units are required in the final reported value.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, objective, and internally consistent.\n\nThe given linear response model for the measured critical dimension $y_j$ is:\n$$y_j = \\theta_0 + \\theta_E \\delta E_j + \\theta_F \\delta F_j + \\varepsilon_j$$\nwhere $\\varepsilon_j \\sim \\mathcal{N}(0, \\sigma^2)$ are independent and identically distributed Gaussian errors. This is a standard linear regression model. For a set of $n$ measurements, this relationship can be expressed in matrix form as:\n$$\\mathbf{y} = X\\boldsymbol{\\theta} + \\boldsymbol{\\varepsilon}$$\nwhere $\\mathbf{y} = (y_1, ..., y_n)^T$ is the vector of measurements, $\\boldsymbol{\\theta} = (\\theta_0, \\theta_E, \\theta_F)^T$ is the $3 \\times 1$ vector of parameters to be identified, $\\boldsymbol{\\varepsilon}$ is the vector of noise terms, and $X$ is the $n \\times 3$ design matrix. Each row of $X$ corresponds to an exposure condition and is of the form $(1, \\delta E_j, \\delta F_j)$.\n\nThe parameter vector $\\boldsymbol{\\theta}$ is identifiable if and only if the design matrix $X$ has full column rank, which is rank $3$. For an $n \\times 3$ matrix to have rank $3$, it is necessary that $n \\ge 3$. Therefore, the minimal number of exposures required to ensure identifiability is $n=3$.\n\nThe first task is to select a minimal subset of exposures from the candidate set $\\{(-1,-1), (-1,1), (1,-1), (1,1)\\}$ that ensures identifiability. We must select $n=3$ exposure conditions such that the resulting $3 \\times 3$ design matrix $X$ is invertible (i.e., has rank $3$). Let us choose the following subset of three exposures:\n$$ \\{(\\delta E_1, \\delta F_1), (\\delta E_2, \\delta F_2), (\\delta E_3, \\delta F_3)\\} = \\{(-1,-1), (-1,1), (1,-1)\\} $$\nThe corresponding design matrix $X$ is:\n$$ X = \\begin{pmatrix} 1  \\delta E_1  \\delta F_1 \\\\ 1  \\delta E_2  \\delta F_2 \\\\ 1  \\delta E_3  \\delta F_3 \\end{pmatrix} = \\begin{pmatrix} 1  -1  -1 \\\\ 1  -1  1 \\\\ 1  1  -1 \\end{pmatrix} $$\nTo confirm that this choice allows for parameter identification, we check if $X$ is invertible by computing its determinant:\n$$ \\det(X) = 1((-1)(-1) - (1)(1)) - (-1)((1)(-1) - (1)(1)) + (-1)((1)(1) - (-1)(1)) $$\n$$ \\det(X) = 1(1-1) + 1(-1-1) - 1(1+1) = 0 - 2 - 2 = -4 $$\nSince $\\det(X) = -4 \\neq 0$, the matrix $X$ is invertible, and the parameter vector $\\boldsymbol{\\theta}$ is identifiable with this minimal set of $3$ exposures.\n\nThe second task is to compute the Fisher information matrix (FIM), $I(\\boldsymbol{\\theta})$. The FIM is defined as the negative expectation of the Hessian of the log-likelihood function $\\ln \\mathcal{L}(\\boldsymbol{\\theta}|\\mathbf{y})$. For the given linear model with i.i.d. Gaussian noise, the log-likelihood is:\n$$ \\ln \\mathcal{L}(\\boldsymbol{\\theta}|\\mathbf{y}) = -\\frac{n}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{j=1}^n (y_j - (\\theta_0 + \\theta_E \\delta E_j + \\theta_F \\delta F_j))^2 $$\nThe Hessian matrix $H(\\boldsymbol{\\theta}) = \\frac{\\partial^2 \\ln \\mathcal{L}}{\\partial \\boldsymbol{\\theta} \\partial \\boldsymbol{\\theta}^T}$ can be shown to be:\n$$ H(\\boldsymbol{\\theta}) = -\\frac{1}{\\sigma^2} X^T X $$\nSince the Hessian matrix does not depend on the measurements $\\mathbf{y}$, its expectation is simply itself, $E[H(\\boldsymbol{\\theta})] = H(\\boldsymbol{\\theta})$. The Fisher Information Matrix is therefore:\n$$ I(\\boldsymbol{\\theta}) = -E[H(\\boldsymbol{\\theta})] = -H(\\boldsymbol{\\theta}) = \\frac{1}{\\sigma^2} X^T X $$\nNow we compute $X^T X$ for our chosen design matrix $X$:\n$$ X^T X = \\begin{pmatrix} 1  1  1 \\\\ -1  -1  1 \\\\ -1  1  -1 \\end{pmatrix} \\begin{pmatrix} 1  -1  -1 \\\\ 1  -1  1 \\\\ 1  1  -1 \\end{pmatrix} = \\begin{pmatrix} 3  -1  -1 \\\\ -1  3  -1 \\\\ -1  -1  3 \\end{pmatrix} $$\nThe Fisher Information Matrix for this minimal design is:\n$$ I(\\boldsymbol{\\theta}) = \\frac{1}{\\sigma^2} \\begin{pmatrix} 3  -1  -1 \\\\ -1  3  -1 \\\\ -1  -1  3 \\end{pmatrix} $$\n\nThe final task is to compute the determinant of this FIM. Using the property $\\det(cA) = c^k \\det(A)$ for a $k \\times k$ matrix $A$ and a scalar $c$, we have:\n$$ \\det(I(\\boldsymbol{\\theta})) = \\det\\left(\\frac{1}{\\sigma^2} X^T X\\right) = \\left(\\frac{1}{\\sigma^2}\\right)^3 \\det(X^T X) $$\nThe determinant of $X^T X$ can be calculated directly or by using the property $\\det(X^T X) = (\\det(X))^2$. We already found $\\det(X) = -4$.\n$$ \\det(X^T X) = (\\det(X))^2 = (-4)^2 = 16 $$\nAlternatively, computing the determinant of the $3 \\times 3$ matrix directly:\n$$ \\det \\begin{pmatrix} 3  -1  -1 \\\\ -1  3  -1 \\\\ -1  -1  3 \\end{pmatrix} = 3(3 \\cdot 3 - (-1)(-1)) - (-1)(-1 \\cdot 3 - (-1)(-1)) + (-1)(-1 \\cdot (-1) - 3 \\cdot (-1)) $$\n$$ = 3(9-1) + 1(-3-1) - 1(1+3) = 3(8) - 4 - 4 = 24 - 8 = 16 $$\nSubstituting this result into the expression for $\\det(I(\\boldsymbol{\\theta}))$:\n$$ \\det(I(\\boldsymbol{\\theta})) = \\frac{1}{(\\sigma^2)^3} \\cdot 16 = \\frac{16}{\\sigma^6} $$\nThis is the determinant of the Fisher information matrix for the selected minimal subset of exposures.",
            "answer": "$$\\boxed{\\frac{16}{\\sigma^{6}}}$$"
        },
        {
            "introduction": "With a well-designed experiment, the next challenge is to estimate the model's parameters from the resulting measurements. This practice demystifies the engine behind many Bayesian inverse modeling tasks by guiding you through the derivation and application of the Metropolis-Hastings algorithm. By performing a step-by-step calculation, you will gain a concrete understanding of how Markov Chain Monte Carlo (MCMC) methods explore the parameter space to approximate the posterior distribution. ",
            "id": "4157871",
            "problem": "In Design-Technology Co-Optimization (DTCO) for semiconductor manufacturing, process window optimization requires calibrated predictive models of critical dimension (CD). Consider a simple local linearized CD observation model near the nominal process point, where a single measured CD $y$ is modeled as $y=\\theta+\\epsilon$, with $\\epsilon\\sim\\mathcal{N}(0,\\sigma^{2})$ and $\\theta$ an unknown CD setting parameter in nanometers. In Bayesian inverse modeling, a prior $\\theta\\sim\\mathcal{N}(\\mu_{0},\\tau^{2})$ is used, and the posterior is sampled by Markov Chain Monte Carlo (MCMC), specifically the Metropolis-Hastings algorithm (MH). \n\nTask 1: Using Bayesâ€™s theorem and the detailed balance principle for Markov chains, derive the Metropolis-Hastings acceptance probability for a generic proposal distribution $q(\\theta'|\\theta)$ that guarantees the posterior $p(\\theta|y)$ is invariant.\n\nTask 2: Now specialize to a symmetric Gaussian proposal $q(\\theta'|\\theta)=\\mathcal{N}(\\theta,s^{2})$. Suppose the following process-calibration scenario: the measured CD is $y=34$ nanometers, the known metrology noise standard deviation is $\\sigma=1.2$ nanometers, the prior mean is $\\mu_{0}=32$ nanometers, the prior standard deviation is $\\tau=3$ nanometers, the current Markov chain state is $\\theta=33$ nanometers, and a proposal draw yields $\\theta'=34.5$ nanometers. Using the derived acceptance probability and these values, compute the numerical acceptance probability for the MH step. Round your final numerical answer for the acceptance probability to four significant figures. No physical units are required for the acceptance probability.",
            "solution": "The problem is divided into two tasks. The first is a theoretical derivation of the Metropolis-Hastings acceptance probability. The second is a numerical calculation of this probability for a specific scenario in semiconductor process modeling.\n\n**Task 1: Derivation of the Metropolis-Hastings Acceptance Probability**\n\nThe goal of a Markov Chain Monte Carlo (MCMC) method is to construct a Markov chain whose stationary distribution is the desired target distribution, which in this problem is the posterior probability distribution $p(\\theta|y)$. For a Markov chain to converge to a stationary distribution $\\pi(\\theta)$, it is a sufficient condition that the transition kernel $T(\\theta'|\\theta)$ (the probability of moving from state $\\theta$ to $\\theta'$) satisfies the detailed balance equation:\n$$\n\\pi(\\theta) T(\\theta'|\\theta) = \\pi(\\theta') T(\\theta|\\theta')\n$$\nIn our case, the target distribution is the posterior, so we write $\\pi(\\theta) = p(\\theta|y)$.\n\nThe Metropolis-Hastings algorithm defines the transition as a two-step process:\n1.  **Proposal:** A new candidate state $\\theta'$ is drawn from a proposal distribution $q(\\theta'|\\theta)$.\n2.  **Acceptance/Rejection:** The proposed state $\\theta'$ is accepted with a probability $\\alpha(\\theta'|\\theta)$. If it is not accepted, the chain remains at the current state $\\theta$.\n\nThe transition probability for $\\theta' \\neq \\theta$ is therefore the product of the proposal probability and the acceptance probability:\n$$\nT(\\theta'|\\theta) = q(\\theta'|\\theta) \\alpha(\\theta'|\\theta)\n$$\nSubstituting this into the detailed balance equation gives:\n$$\np(\\theta|y) q(\\theta'|\\theta) \\alpha(\\theta'|\\theta) = p(\\theta'|y) q(\\theta|\\theta') \\alpha(\\theta|\\theta')\n$$\nThis can be rearranged to express the ratio of the acceptance probabilities:\n$$\n\\frac{\\alpha(\\theta'|\\theta)}{\\alpha(\\theta|\\theta')} = \\frac{p(\\theta'|y) q(\\theta|\\theta')}{p(\\theta|y) q(\\theta'|\\theta)}\n$$\nThe Metropolis-Hastings algorithm selects the acceptance probability to satisfy this ratio while maximizing the acceptance rate to ensure efficient exploration of the state space. This is achieved by setting:\n$$\n\\alpha(\\theta'|\\theta) = \\min \\left( 1, \\frac{p(\\theta'|y) q(\\theta|\\theta')}{p(\\theta|y) q(\\theta'|\\theta)} \\right)\n$$\nThis choice satisfies the detailed balance condition.\n\nNext, we use Bayes's theorem, which states that the posterior is proportional to the product of the likelihood $p(y|\\theta)$ and the prior $p(\\theta)$:\n$$\np(\\theta|y) = \\frac{p(y|\\theta) p(\\theta)}{p(y)}\n$$\nwhere $p(y)$ is the marginal likelihood or evidence. When we substitute this into the acceptance probability ratio, the evidence term $p(y)$ appears in both the numerator and the denominator and thus cancels out:\n$$\n\\frac{p(\\theta'|y)}{p(\\theta|y)} = \\frac{p(y|\\theta')p(\\theta')/p(y)}{p(y|\\theta)p(\\theta)/p(y)} = \\frac{p(y|\\theta')p(\\theta')}{p(y|\\theta)p(\\theta)}\n$$\nTherefore, the final expression for the Metropolis-Hastings acceptance probability is:\n$$\n\\alpha(\\theta'|\\theta) = \\min \\left( 1, \\frac{p(y|\\theta') p(\\theta') q(\\theta|\\theta')}{p(y|\\theta) p(\\theta) q(\\theta'|\\theta)} \\right)\n$$\nThis expression guarantees that the chain will sample from the posterior distribution $p(\\theta|y)$ in the long run.\n\n**Task 2: Numerical Calculation of the Acceptance Probability**\n\nFor the second task, we must compute the numerical value of $\\alpha(\\theta'|\\theta)$ given a specific scenario.\nThe proposal distribution is a symmetric Gaussian, $q(\\theta'|\\theta) = \\mathcal{N}(\\theta, s^2)$. A distribution is symmetric if $q(\\theta'|\\theta) = q(\\theta|\\theta')$. For the Gaussian proposal, we have:\n$$\nq(\\theta'|\\theta) = \\frac{1}{\\sqrt{2\\pi s^2}} \\exp\\left(-\\frac{(\\theta'-\\theta)^2}{2s^2}\\right)\n$$\n$$\nq(\\theta|\\theta') = \\frac{1}{\\sqrt{2\\pi s^2}} \\exp\\left(-\\frac{(\\theta-\\theta')^2}{2s^2}\\right)\n$$\nSince $(\\theta'-\\theta)^2 = (\\theta-\\theta')^2$, it is clear that $q(\\theta'|\\theta)=q(\\theta|\\theta')$. The proposal terms in the acceptance probability formula cancel out, simplifying the expression to the form used in the original Metropolis algorithm:\n$$\n\\alpha(\\theta'|\\theta) = \\min \\left( 1, \\frac{p(y|\\theta') p(\\theta')}{p(y|\\theta) p(\\theta)} \\right)\n$$\nThe problem provides the models for the likelihood and the prior:\nLikelihood: $p(y|\\theta) = \\mathcal{N}(y|\\theta, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp\\left(-\\frac{(y-\\theta)^2}{2\\sigma^2}\\right)$\nPrior: $p(\\theta) = \\mathcal{N}(\\theta|\\mu_0, \\tau^2) = \\frac{1}{\\sqrt{2\\pi \\tau^2}}\\exp\\left(-\\frac{(\\theta-\\mu_0)^2}{2\\tau^2}\\right)$\n\nThe ratio of the unnormalized posterior densities is:\n$$\nR = \\frac{p(y|\\theta') p(\\theta')}{p(y|\\theta) p(\\theta)} = \\frac{\\exp\\left(-\\frac{(y-\\theta')^2}{2\\sigma^2}\\right) \\exp\\left(-\\frac{(\\theta'-\\mu_0)^2}{2\\tau^2}\\right)}{\\exp\\left(-\\frac{(y-\\theta)^2}{2\\sigma^2}\\right) \\exp\\left(-\\frac{(\\theta-\\mu_0)^2}{2\\tau^2}\\right)}\n$$\nThe normalization constants from the Gaussian PDFs cancel. To avoid manipulating small numbers, it is numerically more stable to work with the logarithm of this ratio:\n$$\n\\ln(R) = \\left[ -\\frac{(y-\\theta')^2}{2\\sigma^2} - \\frac{(\\theta'-\\mu_0)^2}{2\\tau^2} \\right] - \\left[ -\\frac{(y-\\theta)^2}{2\\sigma^2} - \\frac{(\\theta-\\mu_0)^2}{2\\tau^2} \\right]\n$$\n$$\n\\ln(R) = \\frac{1}{2\\sigma^2} \\left[ (y-\\theta)^2 - (y-\\theta')^2 \\right] + \\frac{1}{2\\tau^2} \\left[ (\\theta-\\mu_0)^2 - (\\theta'-\\mu_0)^2 \\right]\n$$\nWe are given the following numerical values:\n-   Measured CD: $y = 34$\n-   Noise standard deviation: $\\sigma = 1.2$, so $\\sigma^2 = 1.44$\n-   Prior mean: $\\mu_0 = 32$\n-   Prior standard deviation: $\\tau = 3$, so $\\tau^2 = 9$\n-   Current state: $\\theta = 33$\n-   Proposed state: $\\theta' = 34.5$\n\nSubstituting these values into the expression for $\\ln(R)$:\n$$\n\\ln(R) = \\frac{1}{2(1.44)} \\left[ (34-33)^2 - (34-34.5)^2 \\right] + \\frac{1}{2(9)} \\left[ (33-32)^2 - (34.5-32)^2 \\right]\n$$\n$$\n\\ln(R) = \\frac{1}{2.88} \\left[ 1^2 - (-0.5)^2 \\right] + \\frac{1}{18} \\left[ 1^2 - (2.5)^2 \\right]\n$$\n$$\n\\ln(R) = \\frac{1}{2.88} \\left[ 1 - 0.25 \\right] + \\frac{1}{18} \\left[ 1 - 6.25 \\right]\n$$\n$$\n\\ln(R) = \\frac{0.75}{2.88} + \\frac{-5.25}{18}\n$$\nWe can compute this using fractions for precision:\n$\\frac{0.75}{2.88} = \\frac{75}{288} = \\frac{25 \\times 3}{96 \\times 3} = \\frac{25}{96}$\n$\\frac{-5.25}{18} = \\frac{-525}{1800} = \\frac{-21 \\times 25}{72 \\times 25} = \\frac{-21}{72} = \\frac{-7 \\times 3}{24 \\times 3} = -\\frac{7}{24}$\nSo,\n$$\n\\ln(R) = \\frac{25}{96} - \\frac{7}{24} = \\frac{25}{96} - \\frac{7 \\times 4}{24 \\times 4} = \\frac{25}{96} - \\frac{28}{96} = -\\frac{3}{96} = -\\frac{1}{32}\n$$\nThus, $\\ln(R) = -1/32 = -0.03125$. The ratio $R$ is:\n$$\nR = \\exp\\left(-\\frac{1}{32}\\right) = \\exp(-0.03125) \\approx 0.96924298\n$$\nThe acceptance probability is $\\alpha(\\theta'|\\theta) = \\min(1, R)$. Since $R  1$, the probability is equal to $R$.\n$$\n\\alpha(34.5 | 33) = 0.96924298\n$$\nRounding this to four significant figures gives $0.9692$.",
            "answer": "$$\n\\boxed{0.9692}\n$$"
        },
        {
            "introduction": "The ultimate goal of process modeling is to enable better decision-making and control on the factory floor. This final exercise bridges the gap between a calibrated statistical model and practical process window optimization. You will use the model's sensitivities and the uncertainty in its parameters to determine how much a process must be tightened to meet a critical manufacturing quality target, defined by the process capability index, $C_{pk}$. ",
            "id": "4157852",
            "problem": "A lithography critical dimension $CD$ in a $7~\\mathrm{nm}$ technology node is controlled through Design-Technology Co-Optimization (DTCO) and Bayesian inverse modeling of scanner state variables. The $CD$ specification is two-sided with lower specification limit $LSL = 19~\\mathrm{nm}$ and upper specification limit $USL = 21~\\mathrm{nm}$. Advanced Process Control (APC) keeps the mean $CD$ centered at $20~\\mathrm{nm}$ so that the two specification margins are equal. The fab sets a target process capability index $C_{pk}^{*} = 1.33$ for $CD$.\n\nA DTCO first-order local model around the centered operating point approximates $CD$ variation by a linearization in exposure dose $E$ and focus $F$,\n$$\n\\Delta CD \\approx s_{E}\\,\\Delta E + s_{F}\\,\\Delta F,\n$$\nwith sensitivities $s_{E} = 0.8~\\mathrm{nm}/(\\mathrm{mJ}/\\mathrm{cm}^{2})$ and $s_{F} = 1.5~\\mathrm{nm}/\\mathrm{nm}$. Bayesian inverse modeling using inline metrology produces a joint posterior for $(E,F)$ with posterior standard deviations $\\sigma_{E}^{\\mathrm{post}} = 0.5~\\mathrm{mJ}/\\mathrm{cm}^{2}$ and $\\sigma_{F}^{\\mathrm{post}} = 0.8~\\mathrm{nm}$, and correlation coefficient $\\rho = 0.3$.\n\nAssume APC uniformly tightens the process by scaling the posterior covariance of $(E,F)$ so that the posterior standard deviations are both multiplied by a common factor $\\gamma$, while $\\rho$ remains unchanged. Using only first principles and the given data:\n- Compute the required reduction factor $\\gamma$ such that the resulting $CD$ process achieves the target $C_{pk}^{*}$ while keeping $\\mu$ centered.\n- Translate this $\\gamma$ into symmetric $\\pm 3\\sigma$ control limits on $E$ and $F$.\n\nExpress the control limits for $E$ in $\\mathrm{mJ}/\\mathrm{cm}^{2}$ and for $F$ in $\\mathrm{nm}$. Round your final numerical values to four significant figures. Your final answer must be a single row vector containing, in order, the reduction factor $\\gamma$, the half-width of the $\\pm 3\\sigma$ control limit for $E$, and the half-width of the $\\pm 3\\sigma$ control limit for $F$.",
            "solution": "The user wants me to solve a problem related to semiconductor manufacturing process control, specifically finding a process tightening factor and the resulting control limits.\n\n### Step 1: Problem Validation\n\nI must first validate the problem statement.\n\n#### Extracted Givens:\n- **Process Variable**: Critical Dimension, $CD$.\n- **Technology Node**: $7~\\mathrm{nm}$.\n- **CD Specification**: Lower Specification Limit $LSL = 19~\\mathrm{nm}$, Upper Specification Limit $USL = 21~\\mathrm{nm}$.\n- **Process Mean**: $\\mu_{CD} = 20~\\mathrm{nm}$ (centered).\n- **Target Process Capability**: $C_{pk}^{*} = 1.33$.\n- **First-Order Model**: $\\Delta CD \\approx s_{E}\\,\\Delta E + s_{F}\\,\\Delta F$.\n- **Model Sensitivities**: $s_{E} = 0.8~\\mathrm{nm}/(\\mathrm{mJ}/\\mathrm{cm}^{2})$, $s_{F} = 1.5~\\mathrm{nm}/\\mathrm{nm}$.\n- **Initial Process Variation (Posterior)**:\n    - Standard deviation of exposure dose $E$: $\\sigma_{E}^{\\mathrm{post}} = 0.5~\\mathrm{mJ}/\\mathrm{cm}^{2}$.\n    - Standard deviation of focus $F$: $\\sigma_{F}^{\\mathrm{post}} = 0.8~\\mathrm{nm}$.\n    - Correlation coefficient between $E$ and $F$: $\\rho = 0.3$.\n- **Process Control Action**:\n    - The posterior standard deviations are scaled by a common factor $\\gamma$: $\\sigma_{E}^{\\mathrm{new}} = \\gamma \\sigma_{E}^{\\mathrm{post}}$ and $\\sigma_{F}^{\\mathrm{new}} = \\gamma \\sigma_{F}^{\\mathrm{post}}$.\n    - The correlation coefficient $\\rho$ is unchanged.\n- **Required Outputs**:\n    1. The reduction factor $\\gamma$.\n    2. The half-widths of the symmetric $\\pm 3\\sigma$ control limits for $E$ and $F$ after scaling.\n- **Formatting**: Final numerical values rounded to four significant figures.\n\n#### Validation Verdict:\nThe problem is scientifically grounded, well-posed, and objective. It is based on standard principles of statistical process control ($C_{pk}$), linear error propagation for correlated variables, and common models used in semiconductor lithography. All necessary data are provided, and there are no internal contradictions or ambiguities. The terminology (DTCO, APC, Bayesian inverse modeling) is standard in the field. The provided values are physically plausible. The problem is therefore deemed **valid** and a solution can be derived.\n\n### Step 2: Solution Derivation\n\nThe solution will be derived in three parts:\n1.  Calculate the target standard deviation of the critical dimension, $\\sigma_{CD}^{\\mathrm{target}}$, required to meet the $C_{pk}^{*}$ target.\n2.  Calculate the initial standard deviation of the critical dimension, $\\sigma_{CD}^{\\mathrm{initial}}$, based on the given process variations, and then relate it to the target standard deviation via the reduction factor $\\gamma$.\n3.  Solve for $\\gamma$ and use it to compute the new control limits for the scanner state variables $E$ and $F$.\n\n#### Part 1: Target CD Standard Deviation from $C_{pk}$\n\nThe process capability index, $C_{pk}$, is defined as:\n$$\nC_{pk} = \\min\\left( \\frac{USL - \\mu}{3\\sigma}, \\frac{\\mu - LSL}{3\\sigma} \\right)\n$$\nIn this problem, the variable is the critical dimension $CD$, so $\\mu = \\mu_{CD}$ and $\\sigma = \\sigma_{CD}$. The given values are $LSL = 19~\\mathrm{nm}$, $USL = 21~\\mathrm{nm}$, and the process is centered at $\\mu_{CD} = 20~\\mathrm{nm}$.\n\nThe distances from the mean to the specification limits are:\n$$\nUSL - \\mu_{CD} = 21~\\mathrm{nm} - 20~\\mathrm{nm} = 1~\\mathrm{nm}\n$$\n$$\n\\mu_{CD} - LSL = 20~\\mathrm{nm} - 19~\\mathrm{nm} = 1~\\mathrm{nm}\n$$\nSince the process is centered, the two terms in the $C_{pk}$ definition are equal. We can set the target $C_{pk}^{*}$ equal to this common value, where $\\sigma_{CD}^{\\mathrm{target}}$ is the required standard deviation of the $CD$ process.\n$$\nC_{pk}^{*} = \\frac{USL - \\mu_{CD}}{3\\sigma_{CD}^{\\mathrm{target}}} = \\frac{1~\\mathrm{nm}}{3\\sigma_{CD}^{\\mathrm{target}}}\n$$\nThe target $C_{pk}^{*}$ is given as $1.33$. We can now solve for $\\sigma_{CD}^{\\mathrm{target}}$:\n$$\n1.33 = \\frac{1}{3\\sigma_{CD}^{\\mathrm{target}}}\n$$\n$$\n\\sigma_{CD}^{\\mathrm{target}} = \\frac{1}{3 \\times 1.33} = \\frac{1}{3.99}~\\mathrm{nm}\n$$\n\n#### Part 2: Initial CD Standard Deviation and Relation to $\\gamma$\n\nThe variation in the critical dimension, $\\Delta CD$, is given by the first-order model:\n$$\n\\Delta CD \\approx s_{E}\\,\\Delta E + s_{F}\\,\\Delta F\n$$\nThe variance of $\\Delta CD$, which is the variance of $CD$ since the process is centered ($\\mathbb{E}[\\Delta CD]=0$), is found using the formula for the variance of a linear combination of two correlated random variables, $\\Delta E$ and $\\Delta F$:\n$$\n\\mathrm{Var}(\\Delta CD) = s_{E}^{2} \\mathrm{Var}(\\Delta E) + s_{F}^{2} \\mathrm{Var}(\\Delta F) + 2 s_{E} s_{F} \\mathrm{Cov}(\\Delta E, \\Delta F)\n$$\nThe variances of $\\Delta E$ and $\\Delta F$ are the squares of their standard deviations, and the covariance is given by $\\mathrm{Cov}(\\Delta E, \\Delta F) = \\rho \\sigma_{E} \\sigma_{F}$. Substituting these, the initial variance of $CD$ is:\n$$\n(\\sigma_{CD}^{\\mathrm{initial}})^{2} = s_{E}^{2} (\\sigma_{E}^{\\mathrm{post}})^{2} + s_{F}^{2} (\\sigma_{F}^{\\mathrm{post}})^{2} + 2 s_{E} s_{F} \\rho \\sigma_{E}^{\\mathrm{post}} \\sigma_{F}^{\\mathrm{post}}\n$$\nSubstituting the given initial values: $s_{E} = 0.8$, $s_{F} = 1.5$, $\\sigma_{E}^{\\mathrm{post}} = 0.5$, $\\sigma_{F}^{\\mathrm{post}} = 0.8$, and $\\rho = 0.3$:\n$$\n(\\sigma_{CD}^{\\mathrm{initial}})^{2} = (0.8)^{2} (0.5)^{2} + (1.5)^{2} (0.8)^{2} + 2 (0.8) (1.5) (0.3) (0.5) (0.8)\n$$\n$$\n(\\sigma_{CD}^{\\mathrm{initial}})^{2} = (0.64)(0.25) + (2.25)(0.64) + 0.288\n$$\n$$\n(\\sigma_{CD}^{\\mathrm{initial}})^{2} = 0.16 + 1.44 + 0.288 = 1.888~\\mathrm{nm}^{2}\n$$\nThe initial standard deviation is:\n$$\n\\sigma_{CD}^{\\mathrm{initial}} = \\sqrt{1.888}~\\mathrm{nm}\n$$\nAdvanced Process Control (APC) tightens the process by multiplying the standard deviations of $E$ and $F$ by a factor $\\gamma$. The new standard deviations are $\\sigma_{E}^{\\mathrm{new}} = \\gamma\\sigma_{E}^{\\mathrm{post}}$ and $\\sigma_{F}^{\\mathrm{new}} = \\gamma\\sigma_{F}^{\\mathrm{post}}$. The variance of the tightened process, $(\\sigma_{CD}^{\\mathrm{target}})^{2}$, is:\n$$\n(\\sigma_{CD}^{\\mathrm{target}})^{2} = s_{E}^{2} (\\gamma\\sigma_{E}^{\\mathrm{post}})^{2} + s_{F}^{2} (\\gamma\\sigma_{F}^{\\mathrm{post}})^{2} + 2 s_{E} s_{F} \\rho (\\gamma\\sigma_{E}^{\\mathrm{post}})(\\gamma\\sigma_{F}^{\\mathrm{post}})\n$$\nFactoring out $\\gamma^{2}$:\n$$\n(\\sigma_{CD}^{\\mathrm{target}})^{2} = \\gamma^{2} \\left[ s_{E}^{2} (\\sigma_{E}^{\\mathrm{post}})^{2} + s_{F}^{2} (\\sigma_{F}^{\\mathrm{post}})^{2} + 2 s_{E} s_{F} \\rho \\sigma_{E}^{\\mathrm{post}} \\sigma_{F}^{\\mathrm{post}} \\right]\n$$\n$$\n(\\sigma_{CD}^{\\mathrm{target}})^{2} = \\gamma^{2} (\\sigma_{CD}^{\\mathrm{initial}})^{2}\n$$\nTaking the square root of both sides gives a direct relationship between the standard deviations:\n$$\n\\sigma_{CD}^{\\mathrm{target}} = \\gamma \\sigma_{CD}^{\\mathrm{initial}}\n$$\n\n#### Part 3: Calculation of $\\gamma$ and Control Limits\n\nWe can now solve for the reduction factor $\\gamma$:\n$$\n\\gamma = \\frac{\\sigma_{CD}^{\\mathrm{target}}}{\\sigma_{CD}^{\\mathrm{initial}}} = \\frac{1/(3.99)}{\\sqrt{1.888}}\n$$\n$$\n\\gamma \\approx \\frac{0.25062657}{1.37404512} \\approx 0.18240005\n$$\nRounding to four significant figures, the reduction factor is $\\gamma = 0.1824$.\n\nNext, we compute the new standard deviations for $E$ and $F$:\n$$\n\\sigma_{E}^{\\mathrm{new}} = \\gamma \\sigma_{E}^{\\mathrm{post}} \\approx 0.18240005 \\times 0.5~\\mathrm{mJ}/\\mathrm{cm}^{2} \\approx 0.091200025~\\mathrm{mJ}/\\mathrm{cm}^{2}\n$$\n$$\n\\sigma_{F}^{\\mathrm{new}} = \\gamma \\sigma_{F}^{\\mathrm{post}} \\approx 0.18240005 \\times 0.8~\\mathrm{nm} \\approx 0.14592004~\\mathrm{nm}\n$$\nThe problem asks for the symmetric $\\pm 3\\sigma$ control limits. This corresponds to the half-width of the control band, which is $3\\sigma^{\\mathrm{new}}$.\nFor the exposure dose $E$, the half-width is:\n$$\n3\\sigma_{E}^{\\mathrm{new}} \\approx 3 \\times 0.091200025~\\mathrm{mJ}/\\mathrm{cm}^{2} \\approx 0.273600075~\\mathrm{mJ}/\\mathrm{cm}^{2}\n$$\nRounding to four significant figures, the half-width for $E$ is $0.2736~\\mathrm{mJ}/\\mathrm{cm}^{2}$.\n\nFor the focus $F$, the half-width is:\n$$\n3\\sigma_{F}^{\\mathrm{new}} \\approx 3 \\times 0.14592004~\\mathrm{nm} \\approx 0.43776012~\\mathrm{nm}\n$$\nRounding to four significant figures, the half-width for $F$ is $0.4378~\\mathrm{nm}$.\n\nThe final answer consists of these three computed values: $\\gamma$, the half-width for $E$, and the half-width for $F$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.1824  0.2736  0.4378\n\\end{pmatrix}\n}\n$$"
        }
    ]
}