## 应用与交叉学科联系

在前面的章节中，我们已经详细介绍了[高斯过程](@entry_id:182192)（GP）回归和多项式混沌展开（PCE）的数学原理与核心机制。这些方法不仅仅是抽象的数学工具，更是在现代科学与工程领域中解决复杂问题的强大引擎。它们构成了所谓的“代理模型”或“替代模型”技术的核心，其主旨在于用计算成本低廉的统计模型来近似模拟那些计算成本高昂的物理仿真或实验。本章的目标是展示这些核心原理在多样化、跨学科的真实世界应用中的具体实践。

我们将不再重复基本概念，而是通过一系列以应用为导向的场景，探索这些原理如何被扩展、组合和应用，以解决从[实验设计](@entry_id:142447)、不确定性量化到优化决策的各种挑战。我们将看到，无论是[半导体制造](@entry_id:187383)、聚变能源科学还是电池工程，GP和PCE都为理解和操控复杂系统提供了不可或缺的视角。

### 高效的计算[实验设计](@entry_id:142447)与[模型评估](@entry_id:164873)

构建任何代理模型的第一步都是[数据采集](@entry_id:273490)。对于计算成本高昂的仿真模型，我们无法详尽地探索整个输入空间。因此，如何以最少的仿真次数获取信息最丰富的训练数据，以及如何客观地评估最终得到的代理模型，是至关重要的问题。

#### [实验设计](@entry_id:142447)：为代理模型奠定坚实基础

与旨在最小化方差的传统物理[实验设计](@entry_id:142447)不同，计算机实验的目标是尽可能均匀地探索整个设计空间，以捕捉函数（即仿真模型）的整体行为。为此，[空间填充设计](@entry_id:755078)（Space-Filling Designs）应运而生，其中最著名的是拉丁超立方采样（Latin Hypercube Sampling, LHS）。LHS确保在每个输入维度上，投影点都均匀地分布在预设的“分层”中，避免了点在任何一个维度上的聚集。

一个好的[空间填充设计](@entry_id:755078)对于GP和PCE的性能至关重要。为了进一步提升设计质量，通常会采用诸如“最大最小距离”（maximin）之类的准则对LHS设计进行优化。该准则旨在最大化[设计点](@entry_id:748327)集中任意两点之间的最小欧氏距离。这样做的好处是双重的：

1.  对于[高斯过程回归](@entry_id:276025)，如果训练点过于接近，会导致[协方差核](@entry_id:266561)矩阵的行或列变得近似[线性相关](@entry_id:185830)。这会使核矩阵变得病态（ill-conditioned）甚至奇异，从而在模型训练（例如，通过最大化[边际似然](@entry_id:636856)来优化超参数）和预测所需的[矩阵求逆](@entry_id:636005)过程中引发严重的数值不稳定性。最大化点间距可确保核矩阵具有更好的条件数，从而构建出更稳定、更可靠的GP模型。

2.  对于[多项式混沌展开](@entry_id:162793)（尤其是基于回归的方法），如果输入变量之间存在高[度相关性](@entry_id:1123507)（即点在输入空间中呈现出线性或其他结构性聚集），则会导致PCE基函数之间出现严重的[多重共线性](@entry_id:141597)（multicollinearity）。例如，如果[设计点](@entry_id:748327)都落在一条直线上，那么区分不同输入变量对输出的影响就变得不可能。这会使求解PCE系数的[最小二乘回归](@entry_id:262382)问题变得病态或无解。一个良好散布的[空间填充设计](@entry_id:755078)能够最小化这种[多重共线性](@entry_id:141597)，从而确保PCE系数的估计稳定而准确。

因此，在半导体等离子体刻蚀等工艺的建模项目中，选择一个经过优化的、满足最大最小距离准则的LHS设计，是构建高质量GP或PCE代理模型的关键第一步。

#### 物理启发的变量变换

许多物理和工程系统的行为在原始输入变量空间中是高度[非线性](@entry_id:637147)的。直接用多项式或具有固定平滑度的[核函数](@entry_id:145324)来拟合这种行为，效率低下且需要大量数据。一个强大的策略是利用已知的基本物理定律来指导输入和输出变量的变换，从而使代理模型需要学习的函数关系变得更简单。

以[聚变反应堆材料](@entry_id:749669)中的[氚渗透](@entry_id:756182)问题为例。在扩散主导的机制下，[稳态](@entry_id:139253)渗透通量$J$与温度$T$、上游分压$p$和膜厚度$L$的关系可以由物理定律近似描述为：
$$
J(T,p,L) \propto \frac{p^{1/2}}{L} \exp\left(-\frac{E_{\Phi}}{RT}\right)
$$
其中$E_{\Phi}$是渗透活化能，$R$是气体常数。这个关系式在$(T, p, L)$空间中是强[非线性](@entry_id:637147)的。然而，通过[对数变换](@entry_id:267035)，我们可以得到一个线性关系：
$$
\ln J = \text{常数} - \frac{E_{\Phi}}{R} \left(\frac{1}{T}\right) + \frac{1}{2} \ln p - \ln L
$$
这表明，如果我们选择对数通量$\ln J$作为输出，并使用变换后的输入变量$(1/T, \ln p, \ln L)$，那么底层的函数关系就变成了线性的。即使真实的、高保真的仿真模型包含更复杂的物理效应，这种变换也极大地简化了代理模型需要捕捉的主要趋势。无论是PCE还是GP，拟合一个接近线性的函数都远比拟合一个指数与幂律混合的函数要容易得多，从而可以用更少的数据达到更高的精度。这种基于物理洞察的预处理是代理建模实践中的一个重要技巧。

#### 代理[模型评估](@entry_id:164873)与验证

构建模型后，必须通过一系列量化指标来严格评估其性能。这些指标不仅衡量预测的准确性，还应评估其[不确定性量化](@entry_id:138597)的质量。

最常用的准确性指标是**[均方根误差](@entry_id:170440)（Root Mean Squared Error, RMSE）**和**平均[绝对误差](@entry_id:139354)（Mean Absolute Error, MAE）**。对于一个包含$n$个测试点的[验证集](@entry_id:636445)，它们的定义如下：
$$
\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
$$
$$
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
$$
其中$y_i$是真实观测值，$\hat{y}_i$是代理模型的点预测值（对于GP，通常是其[后验均值](@entry_id:173826)）。这两个指标都与输出变量$y$具有相同的单位，便于直观解释。由于RMSE对误差进行平方，它比MAE对大的误差（离群点）更为敏感。

然而，RMSE和MAE只评估点预测的准确性，完全忽略了模型提供的不确定性信息。对于UQ任务，我们需要能够评估整个预测分布的指标。**负对数预测密度（Negative Log Predictive Density, NLPD）**正是为此而生。它衡量了真实观测值在模型预测概率分布下的似然程度。对于第$i$个测试点，如果GP给出的[预测分布](@entry_id:165741)是均值为$\mu_i$、方差为$\sigma_i^2$的正态分布，其NLPD贡献为：
$$
-\ln p(y_i|x_i) = \frac{1}{2}\ln(2\pi\sigma_i^2) + \frac{(y_i - \mu_i)^2}{2\sigma_i^2}
$$
NLPD对模型进行双重惩罚：一方面，如果预测均值$\mu_i$偏离真实值$y_i$（准确性差），第二项会变大；另一方面，如果模型对其错误的预测过于自信（即$\sigma_i^2$过小），第二项会急剧增大；或者如果模型过于不确定（$\sigma_i^2$过大），第一项也会变大。因此，NLPD同时评估了模型的准确性和其[不确定性估计](@entry_id:191096)的“校准”水平。

对于像PCE这样的确定性代理模型，它本身不提供预测方差。为了计算NLPD，可以采用一种标准方法：假设一个高斯误差模型，其均值为PCE的预测值$\hat{y}_i$，方差$\sigma^2_{\text{const}}$则通过在[验证集](@entry_id:636445)上的残差进行校准得到。这使得我们可以在一个统一的概率框架下比较不同类型代理模型的性能。

### 代理模型在[不确定性量化](@entry_id:138597)中的核心应用

GP和PCE不仅能提供快速预测，更强大的能力在于它们能够对输入不确定性如何传播到输出进行深入分析，即不确定性量化（UQ）。

#### 全局敏感性分析

在多输入系统中，一个核心问题是：哪些输入参数对输出的不确定性贡献最大？[全局敏感性分析](@entry_id:171355)（Global Sensitivity Analysis, GSA）旨在解答这一问题，而PCE为此提供了极其高效的计算途径。

基于方差的[敏感性分析](@entry_id:147555)，特别是[Sobol指数](@entry_id:156558)，是GSA的黄金标准。一阶[Sobol指数](@entry_id:156558)$S_i$衡量了输入变量$X_i$单独对总输出方差的贡献。总[Sobol指数](@entry_id:156558)$S_{T_i}$则衡量了$X_i$单独以及它与其他变量所有[交互作用](@entry_id:164533)对总方差的贡献。

当一个函数被表示为正交的PCE形式时，其总方差可以被精确地分解为与各个多项式基函数相关的方差之和。假设PCE为$Y = \sum_{\alpha} c_{\alpha} \Psi_{\alpha}(X)$，其中$\Psi_{\alpha}$是正交（但不一定归一）的基函数。总方差可以表示为：
$$
\operatorname{Var}(Y) = \sum_{\alpha \neq \mathbf{0}} c_{\alpha}^2 \mathbb{E}[\Psi_{\alpha}^2]
$$
基于此方差分解，一阶[Sobol指数](@entry_id:156558)$S_i$可以通过汇总所有仅依赖于变量$X_i$的基函数的方差贡献来计算：
$$
S_{i} = \frac{\sum_{\alpha: \alpha_i > 0, \forall k \neq i, \alpha_k=0} c_{\alpha}^2 \mathbb{E}[\Psi_{\alpha}^2]}{\operatorname{Var}(Y)}
$$
这个公式使得我们一旦获得了PCE系数，便可以几乎无额外成本地“解析地”计算出一阶敏感性。

类似地，总[Sobol指数](@entry_id:156558)$S_{T_i}$可以通过汇总所有与变量$X_i$相关的项（即多项式索引$\alpha$中第$i$个分量$\alpha_i > 0$的项）的方差贡献来得到。对于使用标准正态输入和归一化[Hermite多项式](@entry_id:153594)基的PCE（此时$\mathbb{E}[\Psi_{\alpha}^2]=1$），计算变得尤为简洁：
$$
S_{T_i} = \frac{\sum_{\alpha: \alpha_i > 0} c_{\alpha}^2}{\sum_{\alpha \neq \mathbf{0}} c_{\alpha}^2}
$$
这个强大的后处理能力使PCE成为识别关键参数的理想工具，例如在[薄膜沉积](@entry_id:1133096)工艺中，工程师可以通过计算$S_{T_i}$来判断是沉积温度、腔室压力还是反应物比例对最终的[薄膜应力](@entry_id:1133097)变异性影响最大，从而指导工艺优化和控制策略。

#### 降维：[活性子空间](@entry_id:1120750)

传统的[敏感性分析](@entry_id:147555)关注单个输入变量的重要性。然而，在许多高维问题中，真正重要的是输入变量的特定[线性组合](@entry_id:154743)。[活性子空间](@entry_id:1120750)（Active Subspaces）方法旨在发现这些能主导函数变化的低维方向。

该方法的核心是分析函数梯度的统计特性，其关键对象是一个[对称半正定矩阵](@entry_id:163376)$C$，它是在输入参数的概率分布下，函数梯度$\nabla_x f(x)$外[积的期望](@entry_id:190023)：
$$
C = \mathbb{E}_{x} \left[ \nabla_x f(x) (\nabla_x f(x))^{\top} \right]
$$
这个矩阵的谱结构（即其特征值和[特征向量](@entry_id:151813)）揭示了函数的平均敏感性方向。具体来说，$C$的[特征向量](@entry_id:151813)$w_i$定义了输入空间中的一个方向，而对应的特征值$\lambda_i$则是在该方向上函数变化的平均平方速率。

一个大的特征值$\lambda_1$意味着函数沿着其对应的[特征向量](@entry_id:151813)$w_1$方向变化最为剧烈。相反，小的特征值则对应着函数几乎不发生变化的方向。如果特征值呈现出明显的“[谱隙](@entry_id:144877)”（即少数几个特征值远大于其他特征值），则表明函数的变化主要被一个由大特征值对应的[特征向量](@entry_id:151813)所张成的低维“[活性子空间](@entry_id:1120750)”所控制。

PCE代理模型再次为此提供了便利。由于PCE是多项式形式，其梯度可以解析地计算。结合输入变量的统计矩，可以推导出矩阵$C$的解析表达式，而无需昂贵的[蒙特卡洛采样](@entry_id:752171)。例如，对于一个关于标准化正态输入的二阶PC[E模](@entry_id:160271)型，矩阵$C$的元素可以表示为PCE系数的函数。通过对该矩阵进行特征分解，工程师就能识别出影响如化学机械平坦化（CMP）工艺中去除速率的关键参数组合，从而实现有效的降维和更具洞察力的工艺优化。

### 代理模型驱动的优化与决策

代理模型的另一个核心价值在于它们能够作为“廉价的[评价函数](@entry_id:173036)”，嵌入到优化和决策流程中，以解决那些直接对原始仿真或实验进行优化不可行的问题。

#### [贝叶斯优化](@entry_id:175791)

当目标是寻找一个昂贵黑盒函数的全局最优值时，[贝叶斯优化](@entry_id:175791)（Bayesian Optimization）是一种非常高效的策略。其核心是使用GP来拟合目标函数。GP的优越性在于，它不仅提供对函数值的预测（后验均值），还提供了关于该预测的不确定性（后验方差）。

贝叶斯优化的流程是一个迭代循环：
1.  根据现有[数据拟合](@entry_id:149007)一个GP模型。
2.  使用一个“[采集函数](@entry_id:168889)”（Acquisition Function）来评估在输入空间中哪个点最有希望成为下一个评估点。
3.  在选定的新点上运行昂贵的仿真或实验，并将新的数据点加入训练集。
4.  返回第一步，更新GP模型。

最常用的采集函数之一是**[期望提升](@entry_id:749168)（Expected Improvement, EI）**。假设我们正在最大化一个目标（如晶圆良率），当前已知的最佳值为$y_{\star}$。在某个候选点$x_c$，GP给出的预测是一个均值为$\mu(x_c)$、标准差为$\sigma(x_c)$的正态分布。EI计算的是在该点进行评估，其结果超过当前最优值$y_{\star}$的期望。其[闭式](@entry_id:271343)解为：
$$
\operatorname{EI}(x_c) = (\mu(x_c) - y_{\star}) \Phi\left(\frac{\mu(x_c) - y_{\star}}{\sigma(x_c)}\right) + \sigma(x_c) \phi\left(\frac{\mu(x_c) - y_{\star}}{\sigma(x_c)}\right)
$$
其中$\Phi$和$\phi$分别是[标准正态分布](@entry_id:184509)的[累积分布函数](@entry_id:143135)（CDF）和概率密度函数（PDF）。EI巧妙地平衡了“利用”（exploitation，在预测均值高的区域搜索）和“探索”（exploration，在不确定性大的区域搜索）。这种智能的搜索策略使得[贝叶斯优化](@entry_id:175791)能够以极少的样本数找到全局最优解，非常适用于昂贵的半导体工艺优化问题。

#### [鲁棒优化](@entry_id:163807)

在许多工程应用中，我们的目标不仅是达到某个性能指标，还要确保该性能对环境中不可控的“扰动”不敏感。[鲁棒优化](@entry_id:163807)（Robust Optimization）旨在寻找在存在不确定性的情况下性能最稳健的控制参数。

代理模型可以极大地简化[鲁棒优化](@entry_id:163807)问题。考虑一个光刻工艺，其关键尺寸（CD）由控制参数（如曝光剂量$u$）和一组无法精确控制的扰动参数$\boldsymbol{\theta}$（如[焦距](@entry_id:164489)偏移、抗蚀剂厚度变化）共同决定。假设扰动$\boldsymbol{\theta}$在一个已知的[有界集](@entry_id:157754)合（例如，$\|\boldsymbol{\theta}\|_{\infty} \le \rho$）内变化。一个鲁棒的优化目标是，最小化在最坏情况下的扰动下，CD与目标值$C^{\star}$的偏差。这可以表示为一个“最小-最大”（minimax）问题：
$$
\min_{u} \max_{\|\boldsymbol{\theta}\|_{\infty} \le \rho} |f(u, \boldsymbol{\theta}) - C^{\star}|
$$
如果我们用一个代理模型来近似$f(u, \boldsymbol{\theta})$，问题就可以被解析地处理。例如，一个结合了GP均值（描述对$u$的依赖）和一阶PCE（描述对$\boldsymbol{\theta}$的线性敏感度）的混合模型$f(u, \boldsymbol{\theta}) \approx m(u) + \mathbf{c}^{\top}\boldsymbol{\theta}$，可以将上述问题转化为：
$$
\min_{u} \left( |m(u) - C^{\star}| + \rho \|\mathbf{c}\|_1 \right)
$$
这里的内层最大化问题利用了范数的对偶性被解析地求解。这个转化后的[目标函数](@entry_id:267263)通常是凸的，因此可以被高效地求解，从而得到能使工艺在面对扰动时表现最稳定的最优控制参数$u^{\star}$。

#### 工艺窗口探索

在[半导体制造](@entry_id:187383)中，工艺窗口（Process Window）是指所有控制参数的设置组合，在这些设置下，所有产品的性能指标（如CD、线边缘粗糙度LER）都能满足其规格要求。识别并最大化这个窗口是工艺开发的核心任务。

代理模型为这项任务提供了一个完整的、基于不确定性的解决方案。一个典型的[科学工作流](@entry_id:1131303)程如下：
1.  **[数据采集](@entry_id:273490)**：使用[空间填充设计](@entry_id:755078)（如LHS）在工艺参数空间中进行初步采样。在部分点上进行[重复测量](@entry_id:896842)，以估计纯粹的测量噪声方差。
2.  **模型训练**：为每个性能指标（如CD和LER）分别训练代理模型（GP或PCE）。GP因其在小数据集上的灵活性和天生的UQ能力而常被首选。
3.  **不确定性量化**：利用训练好的模型，不仅可以预测在任意参数设置下的性能指标均值，还可以得到其[置信区间](@entry_id:142297)。
4.  **模型充分性决策**：通过在独立的[验证集](@entry_id:636445)上检查预测[置信区间](@entry_id:142297)的覆盖率（coverage）是否与预设的[置信水平](@entry_id:182309)（如95%）相符，来判断模型的[不确定性估计](@entry_id:191096)是否校准良好。同时，可以设定一个全局不确定性阈值（如，整个参数空间上的平均预测方差），当模型整体足够“确信”时，可以停止进一步的数据采集。
5.  **主动学习**：如果模型被认为尚不充分，则需要采集更多数据。最高效的策略是“[主动学习](@entry_id:157812)”：在最能帮助我们决策的区域采集新数据点。对于工艺窗口探索，这些区域通常是靠近规格边界的地方，因为在这些地方，模型的不确定性直接影响我们对一个点是否“合格”的判断。因此，可以在这些边界附近、模型预测不确定性最大的地方增加新的采样点。

通过迭代这个循环，工程师可以高效地、以最少的实验次数精确地描绘出合格的工艺窗口，从而做出稳健的工艺决策。

### 先进代理模型：集成与约束

GP和PCE的基本形式非常强大，但它们的真正潜力在于能够通过各种方式进行扩展和组合，以整合更多的物理知识和数据源。

#### [模型校准](@entry_id:146456)与[数据融合](@entry_id:141454)

物理仿真模型通常包含一些无法从第一性原理确定的“校准参数”（如材料的某个经验系数）。这些参数必须通过与真实世界的实验数据进行比较来推断。这个过程称为模型校准。

代理模型在此过程中扮演着“仿真器”（emulator）的角色。由于物理仿真模型本身可能很慢，我们首先为其构建一个快速的代理模型（GP或PCE），该代理模型将控制参数和校准参数都作为输入。然后，在贝叶斯框架下，我们可以将这个代理模型与稀疏的实验数据进行比较。

在一个典型的[贝叶斯校准](@entry_id:746704)问题中，我们有实验观测$\mathbf{y}$，它被认为是仿真器在真实参数$\theta_{\text{true}}$下的输出加上[测量噪声](@entry_id:275238)$\boldsymbol{\varepsilon}$。通过[贝叶斯定理](@entry_id:897366)，我们可以推断出校准参数$\theta$的后验分布：
$$
p(\theta | \mathbf{y}) \propto p(\mathbf{y} | \theta) p(\theta)
$$
其中，$p(\mathbf{y} | \theta)$是[似然函数](@entry_id:921601)（由代理模型和噪声模型定义），$p(\theta)$是我们对该参数的先验信念。对于[线性高斯模型](@entry_id:268963)，[后验分布](@entry_id:145605)可以解析地求出。对于更一般的情况，则需要使用[马尔可夫链蒙特卡洛](@entry_id:138779)（MCMC）等采样方法。在这个流程中，代理模型使得在[贝叶斯推断](@entry_id:146958)中进行成千上万次模型评估成为可能。

更进一步，有时我们知道物理仿真模型本身就是不完美的，它与现实世界之间存在一个系统的、结构性的偏差。这被称为“模型差异”（model discrepancy）。著名的[Kennedy and O'Hagan框架](@entry_id:1126890)提出，用另一个GP来明确地为这个未知的差异函数$\delta(x)$建模。观测模型变为：
$$
y(x) = f(x, \theta) + \delta(x) + \varepsilon
$$
其中$f(x,\theta)$是仿真模型（或其代理）。在这个[分层贝叶斯模型](@entry_id:169496)中，我们可以同时推断校准参数$\theta$和差异函数$\delta(x)$，从而避免将模型的系统性误差错误地归因于校准参数，得到更稳健的推断结果。

#### 物理约束的代理模型

纯粹数据驱动的代理模型可能会做出违反基本物理定律的预测。例如，一个GP模型可能预测刻蚀速率随偏置电压增加而下降，即使我们从物理上知道它应该是单调递增的。

我们可以通过引入“虚拟观测”将这些物理约束直接编码到GP模型中。如果已知函数$f(V)$关于变量$V$是单调递增的，这意味着其导数$f'(V)$必须为正。我们可以通过在一些选定的“虚拟点”上添加$f'(V_i) > 0$的约束来强制GP满足这一属性。从技术上讲，这需要所选的[协方差核](@entry_id:266561)函数是可微的，并且需要计算函数值与函数导数值之间的互协方差。例如，对于一个[平方指数核](@entry_id:191141)$k(V,V')$，其互协方差为：
$$
\operatorname{cov}(f(V), f'(V')) = \frac{\partial}{\partial V'} k(V,V')
$$
$$
\operatorname{cov}(f'(V), f'(V')) = \frac{\partial^2}{\partial V \partial V'} k(V,V')
$$
通过将这些导数观测（及其协方差）整合到GP的条件更新公式中，我们便可以得到一个既能拟[合数](@entry_id:263553)据、又能尊重已知物理约束的后验GP。这种方法使得模型在数据稀疏区域的泛化能力大大增强。

#### 多输出与[多保真度模型](@entry_id:752241)

许多系统具有多个相互关联的输出，例如，[薄膜沉积](@entry_id:1133096)工艺同时产生厚度和应力两个输出。分别对每个输出建立独立的代理模型会忽略它们之间的相关性，从而损失信息。

多输出GP（也称Co-Kriging）旨在联合建模这些相关的输出。线性核区化模型（Linear Model of Coregionalization, LMC）是一种构建多输出[协方差核](@entry_id:266561)的流行方法。其核心思想是，假设所有$P$个观测输出$y_p(x)$都是由一组$Q$个共享的、独立的潜在（latent）GP $f_q(x)$[线性组合](@entry_id:154743)而成：
$$
y_p(x) = \sum_{q=1}^{Q} a_{pq} f_q(x)
$$
其中$a_{pq}$是所谓的“核区化矩阵”的元素。基于这个构造，任意两个输出$y_p(x)$和$y_r(x')$之间的互协方差可以被推导出来：
$$
\operatorname{Cov}(y_p(x), y_r(x')) = \sum_{q=1}^{Q} a_{pq} a_{rq} k_q(x,x')
$$
其中$k_q$是第$q$个潜在GP的核函数。这个公式优雅地展示了输出间的相关性是如何通过共享的潜在过程和核区化系数被建立起来的。通过联合拟合所有输出的数据，模型可以利用一个输出的信息来改善对另一个输出的预测。

#### [混合模型](@entry_id:266571)：PC-Kriging

PCE和GP各有优劣：PCE擅长捕捉光滑的全局趋势，而GP擅长拟合局部变化。PC-Kriging（也称作带有多项式趋势的[泛克里金法](@entry_id:1133613)）是一种将两者优点结合起来的混合模型。

其模型结构如下：
$$
f(x) = \mu_{\text{PCE}}(x) + Z_{\text{GP}}(x)
$$
这里，函数$f(x)$被分解为一个由PCE表示的确定性全局趋势项$\mu_{\text{PCE}}(x)$和一个由零均值GP $Z_{\text{GP}}(x)$表示的局部随机波动项。
$$
\mu_{\text{PCE}}(x) = \sum_{\alpha} c_{\alpha} \Psi_{\alpha}(x)
$$
这种分解非常符合许多工程问题的结构，其中函数行为由一个主导的、可用低阶多项式描述的全局趋势和一些更复杂的局部偏差组成。模型的训练需要联合估计PCE的系数$c_{\alpha}$和GP的核超参数，这通常通过最大化集中（profiled）[似然函数](@entry_id:921601)来实现。该方法能够让数据自动“决定”函数的多大变异性应归因于全局趋势，多大应归因于局部相关波动，从而避免了“双重计算方差”的问题。

PC-Kriging模型存在两个有趣的极限情况：如果GP部分的方差趋于零，模型就退化为一个纯粹的PCE[回归模型](@entry_id:1130806)；反之，如果PCE部分只包含一个常数项，模型就退化为标准的“[普通克里金法](@entry_id:1129196)”（Ordinary Kriging）。

### 方法比较与选择

通过以上应用，我们看到GP和PCE并非相互排斥，而是各具特色，有时甚至可以协同工作。选择哪种方法取决于具体问题的特点和建模目标。

**[高斯过程回归](@entry_id:276025)（GPR）的优势在于：**
*   **数据高效性**：作为一种非参数贝叶斯方法，它在小数据集上通常表现出色。
*   **不确定性量化**：它自然地提供预测的[后验分布](@entry_id:145605)，量化了由于数据有限而产生的认知不确定性（epistemic uncertainty），这对于[主动学习](@entry_id:157812)和[贝叶斯优化](@entry_id:175791)至关重要。
*   **灵活性**：通过选择不同的[核函数](@entry_id:145324)（如Matérn核），可以对被建[模函数](@entry_id:155728)的平滑度做出灵活的假设，从而能有效处理带有“[尖点](@entry_id:636792)”或不光滑特征的函数。
*   **输入无关性**：它对输入变量的分布没有特定要求，并且能自然地处理相关的输入变量。

**[多项式混沌展开](@entry_id:162793)（PCE）的优势在于：**
*   **评估速度**：一旦系数被确定，PCE就是一个简单的多项式，评估速度极快。
*   **全局敏感性分析**：它能够以极低的计算成本，解析地提供精确的Sobol敏感性指数，对于理解输入输出关系非常有价值。
*   **平滑函数的高效性**：如果目标函数在某些变换后的变量空间中是光滑且低阶的，PCE可以用极少的基函数实现非常高的精度。

**两种方法也各有其局限性：**
*   GPR的训练成本随样本量$N$的增加而以$O(N^3)$的速率增长，使其不适用于非常大的数据集。此外，核函数的选择对性能至关重要。
*   标准PCE需要了解输入变量的概率分布，并且其性能在面对[非光滑函数](@entry_id:175189)时会严重下降（[吉布斯现象](@entry_id:138701)）。此外，标准PCE不直接提供认知不确定性，且处理相关输入需要额外的变换步骤。

总而言之，GP和PCE是现代计算科学与工程中一对相辅相成的强大工具。GP更像是一把灵活的、适用于各种局部细节的“瑞士军刀”，而PCE则更像是一台用于捕捉系统全局动态的、高效的“[频谱分析仪](@entry_id:184248)”。理解它们的特性、优势和局限性，并根据手头的具体问题——无论是[样本量](@entry_id:910360)、函数光滑度、不确定性量化的需求还是输入结构——来做出明智的选择，是成功应用代理模型的关键所在。