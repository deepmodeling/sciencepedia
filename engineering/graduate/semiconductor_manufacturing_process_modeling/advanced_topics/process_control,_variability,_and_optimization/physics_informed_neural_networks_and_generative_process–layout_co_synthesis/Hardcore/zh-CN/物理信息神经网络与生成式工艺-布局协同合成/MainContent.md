## 引言
随着半导体技术节点不断缩小，工艺与版图之间的相互作用日益复杂，传统的序贯设计方法已难以为继。技术协同优化（TCO），即在设计阶段同时考虑制造工艺的影响，已成为延续摩尔定律的关键。然而，这一范式面临着一个核心挑战：传统基于物理的工艺仿真（TCAD）虽然精确，但计算成本高昂，无法被整合到需要海量迭代的自动化版图设计循环中。本文旨在介绍一种前沿解决方案：一个基于物理-信息神经网络（PINN）的生成式工艺-版图协同综合框架，它通过将物理定律与深度学习相结合，填补了快速、可微的物理模型在设计自动化领域的空白。通过学习本文，读者将掌握一种强大的、端到端优化的新方法，以应对下一代半导体设计的挑战。

在接下来的章节中，我们将首先深入“原理与机制”，阐明PINN如何作为[可微物理](@entry_id:634068)代理，并构建起整个协同综合框架。随后，在“应用与跨学科连接”部分，我们将展示该框架在光刻、刻蚀等核心工艺中的具体应用，并揭示其与优化理论、强化学习等领域的深刻联系。最后，通过“动手实践”环节，读者将有机会将理论付诸实践，巩固对这一变革性技术的理解。

## 原理与机制

本章旨在阐述物理-信息神经网络（PINN）作为可微代理模型的核心原理，并详细介绍其在半导体工艺-版图协同综合问题中的关键机制。我们将从基本概念出发，逐步深入到高级训练策略、可扩展性以及最终的生成式协同优化框架。

### 物理-信息神经网络（PINN）：一种可微的物理代理

物理-信息神经网络（Physics-Informed Neural Network, PINN）的核心思想是利用神经网络的强大[函数逼近](@entry_id:141329)能力来表示一个物理系统的解，例如一个由[偏微分](@entry_id:194612)方程（PDE）描述的场量 $u(\mathbf{x}, t)$。我们将解近似为一个以时空坐标 $(\mathbf{x}, t)$ 为输入、由可训练参数 $\theta$ 定义的神经网络 $u_{\theta}(\mathbf{x}, t)$。

这种方法的真正威力源于现代深度学习框架中内置的**[自动微分](@entry_id:144512)（Automatic Differentiation, AD）**机制。AD 是一种计算程序导数的技术，它使我们能够精确且高效地计算神经网络输出关于其任何输入的导数（例如时间导数 $\partial u_{\theta} / \partial t$ 和空间导数 $\nabla u_{\theta}$、$\nabla^{2} u_{\theta}$），以及关于其可训练参数 $\theta$ 的梯度（$\partial u_{\theta} / \partial \theta$）。这种能力是 PINN 的基石，因为它允许我们将物理定律——以[微分](@entry_id:158422)方程的形式——直接编码到网络的训练过程中。

例如，在半导体[热退火](@entry_id:203792)过程中，掺杂剂的扩散通常由一个[二阶偏微分方程](@entry_id:175326)描述。为了在 PINN 框架中求解此问题，我们需要计算解的[拉普拉斯算子](@entry_id:146319) $\nabla^{2} u_{\theta}$。AD 能够通过对网络输出 $u_{\theta}$ 相对于其空间输入（例如 $x$ 和 $y$）应用两[次微分](@entry_id:175641)来精确计算这个二阶导数 。然而，这种能力并非没有代价。

从计算和数值角度看，[高阶导数](@entry_id:140882)（尤其是二阶及以上）的引入带来了显著挑战 。
*   **计算成本**：与仅需一次反向传播即可计算一阶梯度（$\nabla_{\theta} u_{\theta}$）相比，计算[高阶导数](@entry_id:140882)（如 $\nabla^{2} u_{\theta}$）或涉及[高阶导数](@entry_id:140882)的梯度（如 $\nabla_{\theta}(\nabla^{2} u_{\theta})$）需要更复杂的 AD 运算（例如，多次应用反向或前向模式），这极大地增加了每次训练迭代的计算时间和内存消耗。
*   **[数值精度](@entry_id:146137)**：[高阶导数](@entry_id:140882)对数值误差更为敏感。常用的激活函数（如[双曲正切](@entry_id:636446) $\tanh$）在其饱和区域的一阶导数趋近于零，其二阶导数则会更快地“消失”。这种“二阶导数消失”现象使得网络很难学习到具有显著曲率的解，尤其是在半导体工艺中常见的、具有尖锐梯度和高曲率的掺杂分布区域。此外，在有限精度[浮点数](@entry_id:173316)上进行的 AD 计算会累积和放大舍入误差，对[高阶导数](@entry_id:140882)的计算稳定性构成挑战。

### 构建物理-信息[损失函数](@entry_id:634569)

PINN 的训练核心是**[残差最小化](@entry_id:754272)原理**。我们将描述物理系统的所有方程（PDE、边界条件、初值条件等）都转化为残差形式，即把方程所有项移到一侧，使其等于零。然后，我们构建一个复合损失函数，该函数是这些残差在时空域中一系列[配置点](@entry_id:169000)（collocation points）上平方值的加权和。通过最小化这个[损失函数](@entry_id:634569)，我们驱使神经网络 $u_{\theta}$ 的行为逼近真实物理。

一个全面的 PINN 损失函数通常由以下几个部分组成，其结构可由一个复杂的工艺-版图协同综合问题中的[损失函数](@entry_id:634569)来阐明 ：

1.  **PDE 残差损失 ($\mathcal{L}_{\mathrm{pde}}$)**：这是最核心的损失项，它惩罚网络解在求解域内部对主导 PDE 的偏离。对于一个由残差 $r_{\mathrm{pde}}$ 定义的 PDE，该损失项通常是其在大量[配置点](@entry_id:169000)上的[均方误差](@entry_id:175403)：$\mathcal{L}_{\mathrm{pde}} = \mathbb{E}[r_{\mathrm{pde}}^2]$。

2.  **边界条件损失 ($\mathcal{L}_{\mathrm{BC}}$)**：此项强制网络解满足在求解域边界上规定的条件。这包括：
    *   **狄利克雷（Dirichlet）边界条件**：例如，在边界上规定了浓度值 $c(\mathbf{x}, t) = c_b$。损失项将是 $\mathcal{L}_{D} = \mathbb{E}[ (u_{\theta} - c_b)^2 ]$。
    *   **诺伊曼（Neumann）边界条件**：例如，在对称边界上规定了零通量 $\mathbf{n} \cdot \nabla c = 0$。损失项将是 $\mathcal{L}_{N} = \mathbb{E}[ (\mathbf{n} \cdot \nabla u_{\theta})^2 ]$。

3.  **初始条件损失 ($\mathcal{L}_{\mathrm{IC}}$)**：此项确保网络解在初始时刻 $t=0$ 与给定的初始状态 $u_0(\mathbf{x})$ 一致。在协同综合问题中，初始条件 $u_0(\mathbf{x})$ 本身可能由一个[生成模型](@entry_id:177561) $G(\mathbf{z})$ 产生，因此该损失项 $\mathcal{L}_{\mathrm{IC}} = \mathbb{E}[ (u_{\theta}(\mathbf{x}, 0) - u_0(\mathbf{x}; \mathbf{z}))^2 ]$ 将神经网络解与生成模型联系起来。

4.  **数据保真度损失 ($\mathcal{L}_{\mathrm{data}}$)**：当存在实验测量数据时（例如，[二次离子质谱法](@entry_id:201118) SIMS 测得的掺杂浓度），可以加入此项来使网络解与真实数据对齐。对于[高斯噪声](@entry_id:260752)测量，该损失项对应于[负对数似然](@entry_id:637801)，形式为 $\mathcal{L}_{\mathrm{data}} = \sum_{i} (u_{\theta}(\mathbf{x}_i, t_i) - y_i)^2 / \sigma_i^2$。

5.  **物理约束损失**：除了上述标准项，还可以加入其他已知的物理守恒定律作为软约束。例如，在版图生成中，可以要求初始[掺杂分布](@entry_id:1123928)的总剂量守恒，即 $\int_{\Omega} u(\mathbf{x}, 0) d\mathbf{x} = Q_{\text{target}}$。相应的损失项可以是 $(\int_{\Omega} u_{\theta}(\mathbf{x}, 0) d\mathbf{x} - Q_{\text{target}})^2$ 。

#### 处理非均匀介质与界面

在许多实际半导体工艺模型中，材料属性并非处处相同。例如，扩散系数可能随空间位置变化，甚至在不同材料的界面处发生跳变。对于形如 $\nabla \cdot (k(\mathbf{x}) \nabla u) = f$ 的方程，其中扩散系数 $k(\mathbf{x})$ 是分片光滑的，简单的残差形式 $k(\mathbf{x}) \Delta u_{\theta} - f$ 是不正确的，因为它忽略了 $\nabla k \cdot \nabla u$ 这一项。

正确的强形式残差必须基于完整的[散度形式](@entry_id:748608) $r_{\mathrm{int}} = \nabla \cdot (k(\mathbf{x}) \nabla u_{\theta}) - f$。利用 AD，这可以通过先计算[梯度场](@entry_id:264143) $\nabla u_{\theta}$，再乘以 $k(\mathbf{x})$ 形成通量场，最后计算通量场的散度来实现 。

更重要的是，在 $k(\mathbf{x})$ 的不连续界面 $\Gamma$ 上，强形式残差是无定义的。物理上，我们需要在此处强制执行通量连续性条件，即 $[k \nabla u \cdot \mathbf{n}]_{\Gamma} = 0$，其中 $[\cdot]_{\Gamma}$ 表示跨界面的跃变。这需要在 PINN 损失函数中引入一个额外的**界面残差损失项**，并在界面上专门采样[配置点](@entry_id:169000)来强制该条件 。

#### 无量纲化的重要性

上述不同损失项的量级和物理单位可能迥然不同。例如，PDE 残差的单位可能是 $(\text{浓度}/\text{时间})^2$，而边界残差的单位可能是 $(\text{浓度})^2$。直接将它们相加并用固定的权重进行优化是极其困难的。

**[无量纲化](@entry_id:136704)**是解决此问题的关键步骤。通过引入特征长度 $L$，特征时间 $\tau$ 和特征浓度 $C_{\text{ref}}$，我们可以将原始的有量纲方程和变量转化为无量纲形式。这个过程不仅使得所有损失项的量级具有可比性，还自然地揭示了控制系统行为的关键**[无量纲数](@entry_id:260863)** 。例如，在掺杂-缺陷耦合[扩散模型](@entry_id:142185)中，[无量纲化](@entry_id:136704)可以导出：
*   **毕渥数 (Biot number, Bi)**：$hL/D_0$，表示界面传质速率与体内扩散速率之比。
*   **达姆科勒数 (Damköhler number, $\Lambda$)**：$k_r L^2/D_0$，表示扩散特征时间与反应特征时间之比。
*   **扩散系数比 ($\chi$)**：$D_s/D_0$，比较两种物质的扩散快慢。

这些[无量纲数](@entry_id:260863)不仅有助于平衡损失项，其本身也为工艺-版图协同综合提供了重要的物理洞察和优化目标。

### 高级架构与训练策略

为了提高 PINN 的训练效率、稳定性和[可扩展性](@entry_id:636611)，研究人员发展了多种高级策略。

#### 硬约束与软[约束编码](@entry_id:197822)

标准的 PINN [损失函数](@entry_id:634569)通过“软”惩罚项来强制执行[初始和边界条件](@entry_id:750648)。另一种更强有力的方法是“硬”编码，即通过特殊设计的[网络架构](@entry_id:268981)来确保条件被精确满足。例如，为了强制执行初始条件 $u(\mathbf{x}, 0) = u_0(\mathbf{x})$，我们可以构造如下形式的网络 ：
$$
u_{\theta}(\mathbf{x}, t) = u_0(\mathbf{x}) + t \cdot \tilde{u}_{\theta}(\mathbf{x}, t)
$$
其中 $\tilde{u}_{\theta}(\mathbf{x}, t)$ 是一个标准的无约束神经网络。显然，当 $t=0$ 时，该表达式自动满足 $u_{\theta}(\mathbf{x}, 0) = u_0(\mathbf{x})$，无论参数 $\theta$ 为何值。这种方法消除了对初始条件损失项的需求。

更有趣的是，这种架构对训练动态产生了积极影响。将此形式代入 PDE 残差，会发现与待训练网络 $\tilde{u}_{\theta}$ 的空间导数相关的项都乘以了一个因子 $t$。这意味着在训练初期（$t \approx 0$），优化过程将主要集中于拟合与时间导数相关的项，而将空间演化的学习“推迟”到稍后的时间。这形成了一种**自然[课程学习](@entry_id:1123314)（natural curriculum learning）**，可以[解耦](@entry_id:160890)初始时刻一致性与空间保真度的学习，从而改善优化的稳定性和收敛性 。

#### 耦合系统的自适应权重

对于包含多个耦合 PDE 的复杂系统（例如，[热传导](@entry_id:143509)与质量扩散耦合），不同物理过程的特征时间和尺度可能差异巨大，导致各残差项的梯度大小相差悬殊。使用固定的损失权重 $\lambda_i$ 往往会导致训练过程被梯度最大的那个损失项所主导，而其他物理过程则得不到充分学习。

一个更具原则性的方法是采用**自适应权重**方案。其核心思想是动态调整权重，以平衡每个损失项对参数更新的贡献。一种有效策略是使每个加权损失项的梯度范数 $\lVert \lambda_i \nabla_{\theta} \mathcal{L}_i \rVert$ 保持大致相等。这可以通过在训练过程中周期性地计算每个损失项的梯度范数 $g_i = \lVert \nabla_{\theta} \mathcal{L}_i \rVert$，然后根据 $g_i$ 的大小反向调整相应的权重 $\lambda_i$ 来实现。例如，可以采用类似 GradNorm 的更新规则 ：
$$
\lambda_{i} \leftarrow \lambda_{i} \cdot \left(\frac{g_{\text{ref}}}{g_{i}+\epsilon}\right)^{\alpha}
$$
其中 $g_{\text{ref}}$ 是一个目标梯度范数（例如，所有梯度范数的平均值）。该策略能有效防止梯度“爆炸”或“消失”的损失项主导训练，确保所有相关的物理约束都被[协同学](@entry_id:1132788)习。

#### 高级[采样策略](@entry_id:188482)

[配置点](@entry_id:169000)的选择对 PINN 的性能至关重要。简单的均匀[随机采样](@entry_id:175193)效率低下。更高级的策略包括 ：
*   **重要性采样**：在解的梯度较大或物理属性变化剧烈的区域（例如，[材料界面](@entry_id:751731)附近）放置更多的点。
*   **自适应重采样**：在训练过程中，周期性地评估 PDE 残差的大小，并在残差较大的区域增加采样密度。这使得网络能够集中“精力”去修正当前误差最大的地方。
*   **[准随机序列](@entry_id:142160)（[低差异序列](@entry_id:139452)）**：使用 Sobol 或 Halton 序列代替[伪随机数生成器](@entry_id:145648)，可以更均匀地覆盖求解域，避免出现采样“空洞”。

#### 可扩展性与[区域分解](@entry_id:165934)（XPINN）

传统 PINN 的一个主要局限性是[可扩展性](@entry_id:636611)差。对于大型或复杂的求解域，单个大型神经网络的训练变得非常困难。**扩展物理-信息神经网络（Extended Physics-Informed Neural Networks, XPINN）**通过区域分解来解决这个问题 。

XPINN 的思想是将整个求解域分解为多个非重叠的子域，并为每个子域分配一个独立的、较小的神经网络。子域之间的物理连续性通过在它们共享的内部界面上强制执行连续性条件（例如，温度连续和热通量连续）来保证。这些界面条件同样作为残差项加入到总[损失函数](@entry_id:634569)中。

这种方法允许在[分布式计算](@entry_id:264044)系统上进行[数据并行](@entry_id:172541)训练（例如，每个处理器负责一个子域），从而显著提高了可扩展性。然而，这也引入了新的权衡：[并行计算](@entry_id:139241)带来的加速与[子域](@entry_id:155812)间交换数据和梯度（用于计算界面损失）所需的通信开销之间的平衡。通过对计算时间和通信开销进行建模，可以分析并确定一个最优的子域数量 $N^{\star}$，以在满足精度要求的前提下最小化总训练时间 。

### 生成式工艺-版图协同综合

将上述 PINN 技术整合到一个更大的框架中，我们就来到了生成式工艺-版图协同综合的核心。这里的目标不再是为给定的工艺和版图求解物理方程，而是反过来，**利用可微的物理模型来指导工艺参数和版图自身的优化设计**。

#### 可微的端到端优化流程

协同综合的实现依赖于一个从设计参数到最终性能指标的完全可微的[计算图](@entry_id:636350)。这个流程通常包括：
1.  **生成模型**：一个可微的生成网络（例如，基于参数 $\mathbf{p}$ 或[隐变量](@entry_id:150146) $\mathbf{z}$ 的生成器 $G_{\phi}$）产生一个候选的版图设计或工艺参数 。
2.  **物理场建模**：生成的版图和工艺参数被输入到一个物理模型中，以确定空间变化的物理属性，例如光刻中的光强分布 $I(\mathbf{x}; \mathbf{p})$ 或热模型中的热导率 $k(\mathbf{x})$ [@problem_id:4151978, @problem_id:4152008]。这一步也必须是可微的，例如，[光刻](@entry_id:158096)成像模型可以通过[傅里叶光学](@entry_id:192627)（涉及可微的 FFT 变换）来构建。
3.  **PINN 求解器**：PINN 作为一个可微的代理模型，接收上一步生成的物理场，并快速求解相应的 PDE，得到系统状态（如抗蚀剂状态场）。
4.  **性能评估**：从 PINN 的解中提取出关键的性能指标（KPI），例如边缘放置误差 $J_1$ 和[线边缘粗糙度](@entry_id:1127249) $J_2$。这些指标也必须是可微的函数。

整个流程从输入的设计参数 $\mathbf{p}$ 一直到最终的损失 $J$，形成了一个巨大的、端到端的[计算图](@entry_id:636350)。通过 AD，我们可以计算出性能指标关于最前端设计参数的梯度 $\partial J / \partial \mathbf{p}$。这些梯度随后被用于[梯度下降](@entry_id:145942)等[优化算法](@entry_id:147840)，以迭代地改进版图和[工艺设计](@entry_id:196705)。这个流程的成功关键在于**每一环节都必须是可微的**。例如，版图的栅格化步骤不能使用不可微的硬[阈值函数](@entry_id:272436)，而必须采用其平滑、可微的近似（如 Sigmoid 函数）。

#### [多目标优化](@entry_id:637420)与帕累托平稳点

协同综合本质上是一个多目标优化问题。我们希望同时优化多个（通常是相互冲突的）性能指标，同时还要满足物理定律的约束。一种常见的方法是**[标量化](@entry_id:634761)**，即构建一个加权和的[目标函数](@entry_id:267263) ：
$$
S(\mathbf{p}; \alpha, \gamma) = \alpha J_{1}(\mathbf{p}) + (1 - \alpha) J_{2}(\mathbf{p}) + \gamma R(\mathbf{p})
$$
其中 $J_1$ 和 $J_2$ 是性能指标，$\alpha$ 是平衡它们的权重，$R(\mathbf{p})$ 是 PINN 的物理残差损失，而 $\gamma$ 是一个惩罚系数，用于确保物理约束得到满足。

优化的目标是找到一个**帕累托平稳点 (Pareto-stationary point)** $\mathbf{p}^*$，在该点处，[标量化](@entry_id:634761)目标函数的梯度为零：
$$
\nabla_{\mathbf{p}} S(\mathbf{p}^*) = \alpha \nabla_{\mathbf{p}} J_1 + (1-\alpha) \nabla_{\mathbf{p}} J_2 + \gamma \nabla_{\mathbf{p}} R = \mathbf{0}
$$
这个条件意味着在这一点，各个目标（性能指标和物理约束）的梯度形成了一种平衡状态。通过调整权重 $\alpha$，我们可以在帕累托前沿上探索不同的设计权衡，找到满足特定需求的最佳设计。

#### 逆问题与可识别性

协同综合的另一个重要方面是**逆问题**：利用有限的实验观测数据来推断未知的物理参数。例如，我们可能需要根据测量的酸浓度演化来确定抗蚀剂中的扩散系数 $D$ 和淬灭速率 $k$。

然而，一个至关重要的概念是**[结构可识别性](@entry_id:182904) (structural identifiability)**。它指的是，在一个给定的模型结构和观测方案下，我们是否能够从理想的、无噪声的数据中唯一地确定模型参数。答案并不总是肯定的。

考虑一个一维反应-扩散系统，其初始条件为一个余弦函数，而我们只能观测到该初始分布加权的浓度积分随时间的变化 。通过对此系统的解析求解可以发现，观测量的演化由一个指数衰减项 $\exp(-\lambda t)$ 控制，其中衰减率 $\lambda = D(\pi/L)^2 + k$。这意味着，无论我们的测量多么精确，我们都只能唯一地确定 $D(\pi/L)^2 + k$ 这个**组合**，而无法单独分离出 $D$ 和 $k$。

这个例子深刻地揭示了模型驱动的机器学习的一个基本限制：我们能从数据中学到的东西，受限于我们所选择的模型结构和观测方式。在进行[参数推断](@entry_id:753157)或逆向设计时，理解和分析参数的可识别性是不可或缺的一步。