{
    "hands_on_practices": [
        {
            "introduction": "Before building complex simulations, a modeler must understand the inherent artifacts of discretizing continuous physical laws onto a lattice. This analytical exercise explores how the choice of a discrete Laplacian operator—a fundamental building block for modeling diffusion and curvature—introduces an artificial directional bias. By deriving the leading-order anisotropy for the common von Neumann and Moore neighborhood stencils, you will gain a foundational understanding of the trade-offs between computational simplicity and physical fidelity in cellular automata models .",
            "id": "4113119",
            "problem": "In curvature-driven microstructure evolution used in semiconductor manufacturing process modeling, a two-dimensional interface moves with normal velocity proportional to its mean curvature. Consider a Cellular Automaton (CA) discretization on a square lattice of spacing $a$ in which the interface is represented implicitly by the signed distance function $\\phi(x,y) = \\sqrt{x^{2}+y^{2}} - R$ for a circular inclusion of radius $R$. The continuous normal velocity law is $V_{n} = M \\gamma \\kappa$, where $M$ is the mobility and $\\gamma$ is the isotropic interfacial free energy per unit length. The curvature $\\kappa$ at the interface can be obtained from the Laplacian of the signed distance field in two dimensions.\n\nModel the discrete curvature by applying a discrete Laplacian to $\\phi$ evaluated on the lattice sites closest to the interface. Define two neighborhood stencils:\n- The von Neumann neighborhood (four-neighbor, five-point stencil) discrete Laplacian,\n$$\\Delta_{\\mathrm{VN}} \\phi(i,j) \\equiv \\frac{1}{a^{2}}\\Big(\\phi_{i+1,j} + \\phi_{i-1,j} + \\phi_{i,j+1} + \\phi_{i,j-1} - 4\\phi_{i,j}\\Big).$$\n- The Moore neighborhood (eight-neighbor, nine-point stencil) discrete Laplacian chosen to improve angular isotropy to leading order,\n$$\\Delta_{\\mathrm{M}} \\phi(i,j) \\equiv \\frac{1}{6 a^{2}}\\Big(4\\big[\\phi_{i+1,j} + \\phi_{i-1,j} + \\phi_{i,j+1} + \\phi_{i,j-1}\\big] + \\big[\\phi_{i+1,j+1} + \\phi_{i+1,j-1} + \\phi_{i-1,j+1} + \\phi_{i-1,j-1}\\big] - 20\\phi_{i,j}\\Big).$$\n\nAssume $a/R \\ll 1$ and use a local angular parametrization of the interface point $(x,y) = (R \\cos\\theta, R \\sin\\theta)$, where $\\theta$ is the polar angle measured from the $x$-axis. Starting from foundational definitions of curvature in two dimensions and consistent Taylor expansions of the discrete Laplacians, derive the leading-order angular dependence of the interface normal-velocity bias introduced by lattice anisotropy. Define the curvature-dependent interface velocity bias at angle $\\theta$ for stencil $S \\in \\{\\mathrm{VN}, \\mathrm{M}\\}$ as\n$$B_{S}(\\theta) \\equiv V_{n,S}(\\theta) - \\langle V_{n,S} \\rangle_{\\theta},$$\nwhere $V_{n,S}(\\theta) = M \\gamma\\, \\kappa_{S}(\\theta)$ and $\\langle \\cdot \\rangle_{\\theta}$ denotes the azimuthal average over $\\theta \\in [0,2\\pi)$.\n\nProvide a single closed-form analytical expression for the difference in the leading-order curvature-dependent interface velocity bias between the von Neumann and Moore stencils, $B_{\\mathrm{VN}}(\\theta) - B_{\\mathrm{M}}(\\theta)$, as a function of $M$, $\\gamma$, $a$, $R$, and $\\theta$. No numerical evaluation or rounding is required. Express your final answer as a symbolic expression.",
            "solution": "The user wants to find the difference in the leading-order, curvature-dependent interface velocity bias between the von Neumann and Moore stencils, denoted as $B_{\\mathrm{VN}}(\\theta) - B_{\\mathrm{M}}(\\theta)$.\n\nFirst, we establish the definitions provided. The interface velocity for a stencil $S$ is given by $V_{n,S}(\\theta) = M \\gamma \\kappa_{S}(\\theta)$, where $M$ is the mobility, $\\gamma$ is the interfacial free energy, and $\\kappa_{S}(\\theta)$ is the discrete curvature at a polar angle $\\theta$. The discrete curvature is approximated by the discrete Laplacian of the signed distance function, $\\kappa_{S}(\\theta) \\approx \\Delta_{S} \\phi$.\n\nThe velocity bias for a stencil $S$ is defined as the deviation from its azimuthal average:\n$$B_{S}(\\theta) \\equiv V_{n,S}(\\theta) - \\langle V_{n,S}(\\theta) \\rangle_{\\theta}$$\nwhere $\\langle \\cdot \\rangle_{\\theta}$ denotes the average over $\\theta \\in [0, 2\\pi)$.\nSubstituting the expression for $V_{n,S}(\\theta)$, we get:\n$$B_{S}(\\theta) = M \\gamma \\left( \\kappa_{S}(\\theta) - \\langle \\kappa_{S}(\\theta) \\rangle_{\\theta} \\right)$$\nThe quantity we need to compute is:\n$$B_{\\mathrm{VN}}(\\theta) - B_{\\mathrm{M}}(\\theta) = M \\gamma \\left[ \\left( \\kappa_{\\mathrm{VN}}(\\theta) - \\langle \\kappa_{\\mathrm{VN}}(\\theta) \\rangle_{\\theta} \\right) - \\left( \\kappa_{\\mathrm{M}}(\\theta) - \\langle \\kappa_{\\mathrm{M}}(\\theta) \\rangle_{\\theta} \\right) \\right]$$\n$$B_{\\mathrm{VN}}(\\theta) - B_{\\mathrm{M}}(\\theta) = M \\gamma \\left[ (\\kappa_{\\mathrm{VN}}(\\theta) - \\kappa_{\\mathrm{M}}(\\theta)) - \\langle \\kappa_{\\mathrm{VN}}(\\theta) - \\kappa_{\\mathrm{M}}(\\theta) \\rangle_{\\theta} \\right]$$\n\nTo find the discrete curvatures $\\kappa_{\\mathrm{VN}}(\\theta)$ and $\\kappa_{\\mathrm{M}}(\\theta)$, we perform a Taylor series expansion of the discrete Laplacian operators, $\\Delta_{\\mathrm{VN}}$ and $\\Delta_{\\mathrm{M}}$, around a point $(x,y)$ on the interface. The Taylor expansion of a function $f(x+h, y+k)$ is\n$$f(x+h, y+k) = \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left( h \\frac{\\partial}{\\partial x} + k \\frac{\\partial}{\\partial y} \\right)^n f(x,y)$$\nApplying this to the von Neumann stencil terms on a lattice with spacing $a$:\n$$\\phi(x\\pm a, y) = \\phi \\pm a \\phi_x + \\frac{a^2}{2} \\phi_{xx} \\pm \\frac{a^3}{6} \\phi_{xxx} + \\frac{a^4}{24} \\phi_{xxxx} + O(a^5)$$\n$$\\phi(x, y\\pm a) = \\phi \\pm a \\phi_y + \\frac{a^2}{2} \\phi_{yy} \\pm \\frac{a^3}{6} \\phi_{yyy} + \\frac{a^4}{24} \\phi_{yyyy} + O(a^5)$$\nSumming the neighbor terms for the von Neumann stencil:\n$$\\phi_{i+1,j} + \\phi_{i-1,j} + \\phi_{i,j+1} + \\phi_{i,j-1} = 4\\phi + a^2(\\phi_{xx} + \\phi_{yy}) + \\frac{a^4}{12}(\\phi_{xxxx} + \\phi_{yyyy}) + O(a^6)$$\nThe discrete Laplacian for the von Neumann stencil is thus:\n$$\\kappa_{\\mathrm{VN}} \\equiv \\Delta_{\\mathrm{VN}}\\phi = \\frac{1}{a^2} \\left[ 4\\phi + a^2 \\Delta\\phi + \\frac{a^4}{12}(\\phi_{xxxx} + \\phi_{yyyy}) - 4\\phi \\right] + O(a^4) = \\Delta\\phi + \\frac{a^2}{12}(\\phi_{xxxx} + \\phi_{yyyy}) + O(a^4)$$\nwhere $\\Delta\\phi = \\phi_{xx} + \\phi_{yy}$ is the continuous Laplacian.\n\nFor the Moore stencil, we also need the diagonal terms, e.g., $\\phi(x+a, y+a)$. Summing all four diagonal neighbors, odd-order derivative terms cancel, and we find:\n$$\\sum_{\\text{diag}} \\phi_k = 4\\phi + 2a^2 \\Delta\\phi + \\frac{a^4}{6} (\\phi_{xxxx} + 6\\phi_{xxyy} + \\phi_{yyyy}) + O(a^6)$$\nThe Moore discrete Laplacian is:\n$$\\kappa_{\\mathrm{M}} \\equiv \\Delta_{\\mathrm{M}}\\phi = \\frac{1}{6a^2} \\left[ 4 \\left( \\sum_{\\text{v-n}} \\phi_k \\right) + \\left( \\sum_{\\text{diag}} \\phi_k \\right) - 20\\phi \\right]$$\nwhere the sums are over non-central neighbors.\n$$\\kappa_{\\mathrm{M}} = \\frac{1}{6a^2} \\left[ 4\\left(4\\phi + a^2 \\Delta\\phi + \\frac{a^4}{12}(\\phi_{xxxx} + \\phi_{yyyy})\\right) + \\left(4\\phi + 2a^2 \\Delta\\phi + \\frac{a^4}{6}(\\phi_{xxxx} + 6\\phi_{xxyy} + \\phi_{yyyy})\\right) - 20\\phi \\right] + O(a^4)$$\n$$\\kappa_{\\mathrm{M}} = \\frac{1}{6a^2} \\left[ 6a^2 \\Delta\\phi + \\frac{a^4}{2}(\\phi_{xxxx} + \\phi_{yyyy}) + a^4 \\phi_{xxyy} \\right] + O(a^4)$$\n$$\\kappa_{\\mathrm{M}} = \\Delta\\phi + \\frac{a^2}{12}(\\phi_{xxxx} + 2\\phi_{xxyy} + \\phi_{yyyy}) + O(a^4) = \\Delta\\phi + \\frac{a^2}{12}\\Delta^2\\phi + O(a^4)$$\n\nThe difference in the discrete curvatures to leading order in $a$ is:\n$$\\kappa_{\\mathrm{VN}} - \\kappa_{\\mathrm{M}} = \\left( \\Delta\\phi + \\frac{a^2}{12}(\\phi_{xxxx} + \\phi_{yyyy}) \\right) - \\left( \\Delta\\phi + \\frac{a^2}{12}(\\phi_{xxxx} + 2\\phi_{xxyy} + \\phi_{yyyy}) \\right) + O(a^4)$$\n$$\\kappa_{\\mathrm{VN}} - \\kappa_{\\mathrm{M}} = -\\frac{a^2}{6}\\phi_{xxyy} + O(a^4)$$\nNow, we must evaluate $\\phi_{xxyy}$ for the signed distance function $\\phi(x,y) = \\sqrt{x^2+y^2} - R$ on the interface where $x=R\\cos\\theta$ and $y=R\\sin\\theta$. Let $r = \\sqrt{x^2+y^2}$.\nThe required partial derivatives are:\n$\\phi_x = \\frac{x}{r}$\n$\\phi_{xx} = \\frac{y^2}{r^3}$\n$\\phi_{xxy} = \\frac{\\partial}{\\partial y} \\left( y^2 r^{-3} \\right) = 2yr^{-3} - 3y^3 r^{-5} = \\frac{2yr^2 - 3y^3}{r^5} = \\frac{2yx^2 - y^3}{r^5}$\n$\\phi_{xxyy} = \\frac{\\partial}{\\partial y} \\left( (2yx^2 - y^3)r^{-5} \\right) = (2x^2 - 3y^2)r^{-5} - 5y(2yx^2 - y^3)r^{-7}$\n$= \\frac{(2x^2-3y^2)r^2 - 10y^2x^2 + 5y^4}{r^7} = \\frac{(2x^2-3y^2)(x^2+y^2) - 10y^2x^2 + 5y^4}{r^7} = \\frac{2x^4 - 11x^2y^2 + 2y^4}{r^7}$\nOn the interface, $r=R$, $x=R\\cos\\theta$, and $y=R\\sin\\theta$:\n$$\\phi_{xxyy} = \\frac{R^4(2\\cos^4\\theta - 11\\cos^2\\theta\\sin^2\\theta + 2\\sin^4\\theta)}{R^7} = \\frac{1}{R^3}(2\\cos^4\\theta - 11\\cos^2\\theta\\sin^2\\theta + 2\\sin^4\\theta)$$\nWe simplify the trigonometric expression using double-angle and power-reduction identities:\n$$2\\cos^4\\theta - 11\\cos^2\\theta\\sin^2\\theta + 2\\sin^4\\theta = 2(\\cos^4\\theta + \\sin^4\\theta) - 11\\cos^2\\theta\\sin^2\\theta$$\n$$= 2( (1 - 2\\cos^2\\theta\\sin^2\\theta) ) - 11\\cos^2\\theta\\sin^2\\theta = 2 - 15\\cos^2\\theta\\sin^2\\theta$$\n$$= 2 - 15 \\left( \\frac{\\sin(2\\theta)}{2} \\right)^2 = 2 - \\frac{15}{4}\\sin^2(2\\theta) = 2 - \\frac{15}{4} \\left( \\frac{1-\\cos(4\\theta)}{2} \\right)$$\n$$= 2 - \\frac{15}{8} + \\frac{15}{8}\\cos(4\\theta) = \\frac{1}{8} + \\frac{15}{8}\\cos(4\\theta) = \\frac{1}{8}(1 + 15\\cos(4\\theta))$$\nThus, the fourth derivative on the interface is:\n$$\\phi_{xxyy}(\\theta) = \\frac{1}{8R^3}(1 + 15\\cos(4\\theta))$$\nSubstituting this into the expression for the curvature difference:\n$$\\kappa_{\\mathrm{VN}}(\\theta) - \\kappa_{\\mathrm{M}}(\\theta) = -\\frac{a^2}{6} \\left[ \\frac{1}{8R^3}(1 + 15\\cos(4\\theta)) \\right] = -\\frac{a^2}{48R^3}(1 + 15\\cos(4\\theta))$$\nNext, we compute the azimuthal average of this difference. The integral of $\\cos(4\\theta)$ over $[0, 2\\pi)$ is $0$.\n$$\\langle \\kappa_{\\mathrm{VN}} - \\kappa_{\\mathrm{M}} \\rangle_{\\theta} = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} -\\frac{a^2}{48R^3}(1 + 15\\cos(4\\theta)) \\,d\\theta = -\\frac{a^2}{48R^3}$$\nFinally, we substitute these results back into the expression for the bias difference:\n$$B_{\\mathrm{VN}}(\\theta) - B_{\\mathrm{M}}(\\theta) = M \\gamma \\left[ (\\kappa_{\\mathrm{VN}}(\\theta) - \\kappa_{\\mathrm{M}}(\\theta)) - \\langle \\kappa_{\\mathrm{VN}}(\\theta) - \\kappa_{\\mathrm{M}}(\\theta) \\rangle_{\\theta} \\right]$$\n$$B_{\\mathrm{VN}}(\\theta) - B_{\\mathrm{M}}(\\theta) = M \\gamma \\left[ \\left(-\\frac{a^2}{48R^3}(1 + 15\\cos(4\\theta))\\right) - \\left(-\\frac{a^2}{48R^3}\\right) \\right]$$\n$$B_{\\mathrm{VN}}(\\theta) - B_{\\mathrm{M}}(\\theta) = M \\gamma \\left[ -\\frac{a^2}{48R^3} - \\frac{15a^2}{48R^3}\\cos(4\\theta) + \\frac{a^2}{48R^3} \\right]$$\n$$B_{\\mathrm{VN}}(\\theta) - B_{\\mathrm{M}}(\\theta) = -M \\gamma \\frac{15a^2}{48R^3}\\cos(4\\theta)$$\nSimplifying the fraction $\\frac{15}{48} = \\frac{5}{16}$, we obtain the final expression.\n$$B_{\\mathrm{VN}}(\\theta) - B_{\\mathrm{M}}(\\theta) = -M \\gamma \\frac{5a^2}{16R^3}\\cos(4\\theta)$$\nThis result shows that to leading order $O(a^2)$, the Moore stencil introduces no angular bias ($B_{\\mathrm{M}}(\\theta)=0$), and the entire difference is due to the four-fold symmetric bias of the von Neumann stencil.",
            "answer": "$$\\boxed{- \\frac{5 M \\gamma a^{2}}{16 R^{3}} \\cos(4\\theta)}$$"
        },
        {
            "introduction": "Having examined the underlying structure of the lattice, we now turn to the dynamics that unfold upon it. This practice asks you to implement a simple, deterministic cellular automaton based on an energy-minimization principle analogous to a zero-temperature Ising model. You will investigate fundamental concepts of dynamical systems, including the identification of stable microstructures (fixed points), their robustness to parameter changes, and their basins of attraction within a defined state space . This exercise provides direct experience with the core concepts of stability and predictability in pattern-forming systems.",
            "id": "4113048",
            "problem": "You will implement a deterministic two-dimensional binary cellular automaton to model microstructure evolution in a simplified setting relevant to semiconductor manufacturing process modeling. The automaton is defined on a periodic square lattice and uses an update rule derived from minimizing a local interaction energy that favors alignment with nearest neighbors and a uniform bias field. You will analyze stability of specified fixed microstructural configurations under perturbations to the local rule and characterize basins of attraction in terms of Hamming distance neighborhoods.\n\nFundamental base and definitions:\n- Let the lattice be $\\Omega = \\{0,1,\\dots,N-1\\} \\times \\{0,1,\\dots,N-1\\}$ with periodic boundary conditions. Each site $(i,j) \\in \\Omega$ carries a spin $s_{i,j} \\in \\{-1,+1\\}$ representing two microstructural phases.\n- The neighborhood is the eight-neighbor set $\\mathcal{N}_{8}(i,j)$ consisting of the sites at offsets $(\\Delta i,\\Delta j) \\in \\{(-1,0),(+1,0),(0,-1),(0,+1),(-1,-1),(-1,+1),(+1,-1),(+1,+1)\\}$, interpreted with periodic wrapping.\n- The local field at site $(i,j)$ is\n$$\nF_{i,j} = J \\sum_{(p,q)\\in\\mathcal{N}_{8}(i,j)} s_{p,q} + h,\n$$\nwhere $J \\in \\mathbb{R}$ is the nearest-neighbor coupling strength and $h \\in \\mathbb{R}$ is a uniform bias field representing an external driving preference.\n- The deterministic synchronous update rule for time $t \\mapsto t+1$ is\n$$\ns_{i,j}^{t+1} =\n\\begin{cases}\ns_{i,j}^{t}, & \\text{if } F_{i,j}^{t} = 0,\\\\\n\\mathrm{sign}\\!\\left(F_{i,j}^{t}\\right), & \\text{if } F_{i,j}^{t} \\neq 0,\n\\end{cases}\n$$\nwhere $\\mathrm{sign}(x)=+1$ if $x>0$ and $\\mathrm{sign}(x)=-1$ if $x<0$. Ties ($F_{i,j}^{t}=0$) keep the current spin.\n- A configuration $s^\\star = \\{s_{i,j}^\\star\\}$ is a fixed configuration under parameters $(J,h)$ if and only if applying the synchronous update produces no changes, i.e., $s_{i,j}^{t+1}=s_{i,j}^{t}=s_{i,j}^\\star$ for all $(i,j)$.\n- Stability under perturbations: Given a finite set of parameter perturbations $\\{(\\Delta J_k,\\Delta h_k)\\}_{k=1}^{K}$, the configuration $s^\\star$ is said to be stable under these perturbations if it remains a fixed configuration for each perturbed parameter pair $(J+\\Delta J_k,h+\\Delta h_k)$.\n- Basin of attraction within Hamming radius: For a target fixed configuration $s^\\star$, define the Hamming distance $d_H(x,s^\\star)$ between configurations $x$ and $s^\\star$ as the number of sites on which they disagree. For a radius $R \\in \\mathbb{N}$ and a maximum iteration budget $M \\in \\mathbb{N}$, the radius-$R$ basin $\\mathcal{B}_R$ is the set of all configurations $x$ with $d_H(x,s^\\star) \\le R$ such that iterative application of the synchronous update under baseline parameters $(J,h)$ reaches $s^\\star$ within at most $M$ steps. If a trajectory enters a cycle that does not include $s^\\star$ or does not reach $s^\\star$ within $M$ steps, it does not belong to $\\mathcal{B}_R$.\n\nTasks to implement:\n1. For each test case below, compute the boolean $b_0$ indicating whether $s^\\star$ is a fixed configuration under the baseline $(J,h)$.\n2. For each test case, compute the boolean $b_1$ indicating whether $s^\\star$ is a fixed configuration under all perturbations $(J+\\Delta J_k,h+\\Delta h_k)$ in the provided list.\n3. For each test case, compute the integer $B = |\\mathcal{B}_R|$, the size of the basin of attraction within Hamming radius $R$ under the baseline parameters.\n4. For each test case, compute the float $\\bar{T}$, the mean number of update steps required for configurations in $\\mathcal{B}_R$ to reach $s^\\star$, rounded to three decimals. If $|\\mathcal{B}_R|=0$, return $\\bar{T}=0.0$.\n\nScientific basis:\n- Start from the local interaction energy for the Ising-like model $E = -J \\sum_{\\langle (i,j),(p,q)\\rangle} s_{i,j} s_{p,q} - h \\sum_{(i,j)} s_{i,j}$, where $\\langle \\cdot,\\cdot \\rangle$ denotes nearest neighbors. In the zero-temperature deterministic limit, local updates align spins with the sign of the local field $F_{i,j}$, yielding the rule above. Ties correspond to locally neutral energy differences and are kept unchanged, consistent with non-increasing energy dynamics.\n\nBoundary conditions and computational details:\n- Use periodic boundary conditions on the $N \\times N$ lattice.\n- The neighborhood sum is over the eight nearest neighbors as specified.\n- Equality to zero in the tie condition should be treated robustly in floating-point arithmetic, considering a small tolerance, but since all sums here are integer multiples of $J$ plus $h$, exact comparisons are acceptable if implemented carefully.\n- The Hamming neighborhood enumeration must include all configurations differing from $s^\\star$ by exactly $k$ spins for $k \\in \\{0,1,\\dots,R\\}$.\n\nTest suite:\n- Use lattice size $N=4$, radius $R=3$, and maximum iteration budget $M=50$ for all cases. For each case, define $s^\\star$, $(J,h)$, and the perturbations $\\{(\\Delta J_k,\\Delta h_k)\\}$ as follows.\n  - Case $1$ (uniform positive phase):\n    - $s^\\star$ is the uniform configuration with $s_{i,j}^\\star=+1$ for all $(i,j)$.\n    - Baseline parameters $(J,h)=(1.0,0.0)$.\n    - Perturbations: $\\{(-0.1,0.0),(0.0,0.2),(0.05,-0.3)\\}$.\n  - Case $2$ (checkerboard):\n    - $s^\\star$ is the checkerboard configuration $s_{i,j}^\\star = (-1)^{i+j}$ mapped to $\\{-1,+1\\}$, i.e., $s_{i,j}^\\star=+1$ if $i+j$ is even and $s_{i,j}^\\star=-1$ if $i+j$ is odd.\n    - Baseline parameters $(J,h)=(1.0,0.0)$.\n    - Perturbations: $\\{(0.0,0.1),(0.0,-0.1),(-0.1,0.05)\\}$.\n  - Case $3$ (uniform negative phase):\n    - $s^\\star$ is the uniform configuration with $s_{i,j}^\\star=-1$ for all $(i,j)$.\n    - Baseline parameters $(J,h)=(1.0,0.0)$.\n    - Perturbations: $\\{(0.0,-0.2),(-0.5,3.9),(-0.95,0.5)\\}$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s result must be a bracketed list $[b_0,b_1,B,\\bar{T}]$ in that order, where $b_0$ and $b_1$ are booleans, $B$ is an integer, and $\\bar{T}$ is a float rounded to three decimals. For example, a valid output for three test cases would look like $[[\\mathrm{True},\\mathrm{False},12,3.000],[\\mathrm{True},\\mathrm{True},8,1.250],[\\mathrm{False},\\mathrm{False},0,0.000]]$.",
            "solution": "### Model Formalization\n\nThe system is defined on a two-dimensional square lattice $\\Omega$ of size $N \\times N$ with periodic boundary conditions. Each site $(i,j)$ on the lattice is in one of two states, represented by a spin variable $s_{i,j} \\in \\{-1, +1\\}$. The evolution of the system is governed by a synchronous update rule that deterministically minimizes a local energy functional. This rule depends on the local field, $F_{i,j}$, at each site, which is defined as:\n$$\nF_{i,j} = J \\sum_{(p,q)\\in\\mathcal{N}_{8}(i,j)} s_{p,q} + h\n$$\nHere, $J$ is the coupling constant that dictates the strength of interaction between a spin and its neighbors, $h$ is an external bias field that favors one spin state over the other, and $\\mathcal{N}_{8}(i,j)$ is the set of the $8$ nearest neighbors of site $(i,j)$. This formulation is analogous to the zero-temperature dynamics of an Ising model where spins align to lower the local energy.\n\nThe synchronous update rule for all sites $(i,j)$ from time $t$ to $t+1$ is given by:\n$$\ns_{i,j}^{t+1} =\n\\begin{cases}\ns_{i,j}^{t}, & \\text{if } F_{i,j}^{t} = 0,\\\\\n\\mathrm{sign}\\!\\left(F_{i,j}^{t}\\right), & \\text{if } F_{i,j}^{t} \\neq 0,\n\\end{cases}\n$$\nwhere the sign function is defined as $\\mathrm{sign}(x) = +1$ for $x > 0$ and $\\mathrm{sign}(x) = -1$ for $x < 0$. If the local field $F_{i,j}^{t}$ is exactly zero, the spin at that site remains unchanged, representing a state of neutral stability.\n\n### Algorithmic Implementation\n\nAn efficient implementation requires careful design, particularly for the neighborhood sum calculation and the basin of attraction analysis.\n\n**1. Fixed Point and Stability Analysis (Tasks 1 & 2)**\n\nA configuration $s^\\star = \\{s_{i,j}^\\star\\}$ is a fixed point if, for every site $(i,j)$, the update rule yields no change: $s_{i,j}^{t+1} = s_{i,j}^\\star$. This is equivalent to the condition that for every site, either the local field $F_{i,j}$ is zero, or its sign matches the spin at that site, i.e., $s_{i,j}^\\star \\cdot F_{i,j} > 0$.\n\nTo implement the check for $b_0$ (whether $s^\\star$ is a fixed point under baseline parameters $(J,h)$), we perform one full synchronous update on $s^\\star$ and verify if the resulting configuration is identical to $s^\\star$.\n\nThe stability analysis for $b_1$ extends this procedure. The configuration $s^\\star$ is stable under a set of perturbations $\\{(\\Delta J_k, \\Delta h_k)\\}$ if it remains a fixed point for all perturbed parameters $(J_k', h_k') = (J+\\Delta J_k, h+\\Delta h_k)$. The algorithm iterates through each perturbation, applies the fixed-point check, and returns `True` only if the condition holds for all of them.\n\nThe crucial calculation of the neighbor sum, $\\sum s_{p,q}$, for all sites simultaneously is efficiently performed using a 2D convolution. The lattice configuration is convolved with a $3 \\times 3$ kernel of ones with a zero at the center. The use of periodic boundary conditions (`wrap` mode in `scipy.signal.convolve2d`) correctly handles the lattice topology.\n\n**2. Basin of Attraction Analysis (Tasks 3 & 4)**\n\nThis analysis is performed only if the target configuration $s^\\star$ is a valid fixed point under the baseline parameters $(J,h)$. The goal is to find the size $B = |\\mathcal{B}_R|$ of the basin of attraction and the mean convergence time $\\bar{T}$.\n\nThe algorithm proceeds as follows:\n- **Enumerate Hamming Neighborhood**: We must test every configuration $s$ whose Hamming distance from $s^\\star$ is less than or equal to the radius $R$. This is done by generating all combinations of $k$ distinct sites to flip from their state in $s^\\star$, for each $k \\in \\{0, 1, \\dots, R\\}$. The `itertools.combinations` function is used for this combinatorial generation.\n- **Simulate Trajectories**: For each initial configuration generated:\n    1. A simulation is run for a maximum of $M$ steps.\n    2. At each step, the configuration is updated using the synchronous rule.\n    3. The trajectory is checked for convergence, which occurs if the configuration becomes identical to $s^\\star$. If it converges at step $\\tau$, this configuration is added to the basin $\\mathcal{B}_R$, and the step count $\\tau$ is recorded.\n    4. To detect non-converging cycles, a history of all visited configurations in the current trajectory is maintained. If a configuration repeats before reaching $s^\\star$, a cycle has been found, and the trajectory is marked as non-converging.\n    5. If a trajectory does not converge to $s^\\star$ within the budget of $M$ steps, it is also considered non-converging.\n- **Compute Statistics**: After testing all initial configurations in the Hamming ball, the basin size $B$ is the total count of converging trajectories. The total number of steps for all converging trajectories is summed, and the mean convergence time $\\bar{T}$ is calculated as this sum divided by $B$. If $B=0$, $\\bar{T}$ is defined as $0.0$. The initial state $s^\\star$ itself contributes to the basin with a convergence time of $0$ steps.\n\nThis comprehensive approach ensures that the properties of the automaton's dynamics near the specified fixed points are correctly characterized according to the problem statement. The use of `numpy` for array operations, `scipy` for convolution, and standard library tools for combinatorics provides an efficient and robust solution.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import convolve2d\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and generate the final output.\n    \"\"\"\n    \n    # Define a helper function to create the s_star configurations.\n    def create_s_star(n_size, config_type):\n        if config_type == 'uniform_pos':\n            # All spins are +1\n            return np.ones((n_size, n_size), dtype=np.int8)\n        elif config_type == 'uniform_neg':\n            # All spins are -1\n            return -np.ones((n_size, n_size), dtype=np.int8)\n        elif config_type == 'checkerboard':\n            # s_ij = (-1)^(i+j)\n            # Create a grid where value is (i+j)\n            idx_grid = np.fromfunction(lambda i, j: i + j, (n_size, n_size), dtype=np.int8)\n            # Map even to +1, odd to -1\n            return 1 - 2 * (idx_grid % 2)\n        return None\n\n    # Define test cases as specified in the problem statement.\n    N_val = 4\n    test_cases = [\n        {\n            \"s_star\": create_s_star(N_val, 'uniform_pos'),\n            \"J\": 1.0, \"h\": 0.0,\n            \"perturbations\": [(-0.1, 0.0), (0.0, 0.2), (0.05, -0.3)],\n            \"N\": N_val, \"R\": 3, \"M\": 50\n        },\n        {\n            \"s_star\": create_s_star(N_val, 'checkerboard'),\n            \"J\": 1.0, \"h\": 0.0,\n            \"perturbations\": [(0.0, 0.1), (0.0, -0.1), (-0.1, 0.05)],\n            \"N\": N_val, \"R\": 3, \"M\": 50\n        },\n        {\n            \"s_star\": create_s_star(N_val, 'uniform_neg'),\n            \"J\": 1.0, \"h\": 0.0,\n            \"perturbations\": [(0.0, -0.2), (-0.5, 3.9), (-0.95, 0.5)],\n            \"N\": N_val, \"R\": 3, \"M\": 50\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_case(\n            case[\"s_star\"], case[\"J\"], case[\"h\"], case[\"perturbations\"],\n            case[\"N\"], case[\"R\"], case[\"M\"]\n        )\n        results.append(result)\n\n    # Format the results into the required single-line string format.\n    str_results = []\n    for res in results:\n        b0_str = str(res[0])\n        b1_str = str(res[1])\n        b_str = str(res[2])\n        t_bar_str = f\"{res[3]:.3f}\"\n        str_results.append(f\"[{b0_str},{b1_str},{b_str},{t_bar_str}]\")\n        \n    print(f\"[{','.join(str_results)}]\")\n\ndef update_step(config, J, h):\n    \"\"\"\n    Performs a single synchronous update of the entire lattice.\n    \"\"\"\n    # Kernel for summing the 8-neighbor Moore neighborhood.\n    kernel = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=np.int8)\n    # Use 2D convolution with periodic boundary conditions.\n    neighbor_sum = convolve2d(config, kernel, mode='same', boundary='wrap')\n    \n    # Calculate the local field F for all sites.\n    F = J * neighbor_sum + h\n    \n    # Apply the update rule.\n    next_config = config.copy()\n    next_config[F > 0] = 1\n    next_config[F < 0] = -1\n    # Where F=0, the spin remains unchanged from the copied config.\n    \n    return next_config\n\ndef is_fixed_point(config, J, h):\n    \"\"\"\n    Checks if a given configuration is a fixed point for the given parameters.\n    \"\"\"\n    next_config = update_step(config, J, h)\n    return np.array_equal(config, next_config)\n\ndef analyze_basin(s_star, J, h, N, R, M):\n    \"\"\"\n    Analyzes the basin of attraction within Hamming radius R.\n    Returns the size of the basin (B) and the mean convergence time (T_bar).\n    \"\"\"\n    basin_size = 0\n    total_steps = 0\n    \n    num_sites = N * N\n    site_indices = np.arange(num_sites)\n\n    # Iterate through all Hamming distances from 0 to R.\n    for k in range(R + 1):\n        # Generate all combinations of k sites to flip.\n        for flip_indices_1d in combinations(site_indices, k):\n            # Create the initial configuration by flipping spins in s_star.\n            initial_config = s_star.copy()\n            if k > 0:\n                # Convert 1D indices to 2D for array indexing.\n                flip_indices_2d = np.unravel_index(list(flip_indices_1d), (N, N))\n                initial_config[flip_indices_2d] *= -1\n\n            # Simulate the trajectory for this initial configuration.\n            current_config = initial_config\n            # Use a set of byte-representations for efficient history tracking (cycle detection).\n            history = {current_config.tobytes()}\n            \n            # Check for convergence within M steps.\n            for step in range(M + 1):\n                if np.array_equal(current_config, s_star):\n                    basin_size += 1\n                    total_steps += step\n                    break\n                \n                # If we've reached the step limit M without converging, stop.\n                if step == M:\n                    break\n\n                current_config = update_step(current_config, J, h)\n                config_bytes = current_config.tobytes()\n                if config_bytes in history:\n                    # Cycle detected, trajectory does not converge to s_star.\n                    break\n                history.add(config_bytes)\n    \n    if basin_size == 0:\n        return 0, 0.0\n    \n    mean_steps = total_steps / basin_size\n    return basin_size, mean_steps\n\ndef process_case(s_star, J, h, perturbations, N, R, M):\n    \"\"\"\n    Processes a single test case to compute b0, b1, B, and T_bar.\n    \"\"\"\n    # Task 1: Check if s_star is a fixed configuration under baseline parameters.\n    b0 = is_fixed_point(s_star, J, h)\n    \n    # Task 2: Check if s_star is stable under all perturbations.\n    if not b0:\n        b1 = False\n    else:\n        b1 = True\n        for dJ, dh in perturbations:\n            if not is_fixed_point(s_star, J + dJ, h + dh):\n                b1 = False\n                break\n    \n    # Tasks 3 & 4: Analyze basin of attraction.\n    # If s_star is not a fixed point, its basin of attraction is considered empty.\n    if not b0:\n        B = 0\n        T_bar = 0.0\n    else:\n        B, T_bar = analyze_basin(s_star, J, h, N, R, M)\n        \n    return [b0, b1, B, T_bar]\n\n# Run the solver.\nsolve()\n```"
        },
        {
            "introduction": "This final practice synthesizes our understanding of lattice effects and automaton dynamics into a sophisticated application: modeling a physical pattern-forming phenomenon. You will develop a cellular automaton to simulate the Mullins-Sekerka instability, a process where a smooth solidification front becomes unstable and develops a cellular pattern, which is critical in semiconductor crystal growth. The challenge lies not only in implementing the model based on diffusion and interface kinetics but also in quantitatively comparing your numerical results against the predictions of an analytical linear stability analysis . This is a capstone exercise in validating a computational model against established physical theory.",
            "id": "4113123",
            "problem": "Design and implement a two-dimensional Cellular Automaton (CA) model for directional solidification relevant to semiconductor manufacturing process modeling that captures the competition between a planar solidification front and the emergence of cellular patterns. The model must be grounded on the following foundational base and assumptions, and all quantities are to be dimensionless:\n\n1. Base physical law: use Fick's second law of diffusion for a scalar field interpreted as an undercooling or supersaturation field, expressed as the partial differential equation $$\\frac{\\partial u}{\\partial t} = D \\nabla^2 u,$$ where $u$ is the scalar field, $t$ is time, $D$ is a positive diffusion coefficient, and $\\nabla^2$ is the Laplacian operator. Implement a discrete version on a uniform square lattice with spacing $\\Delta x = 1$ and explicit time stepping $\\Delta t = 1$ using the standard five-point stencil for the Laplacian.\n\n2. Interface kinetics: approximate normal interface velocity by a linear kinetic law combining local drive and curvature penalty, $$v_n \\propto \\alpha u_{\\mathrm{int}} - \\beta \\kappa,$$ where $\\alpha > 0$ is an interface mobility coefficient, $\\beta \\ge 0$ is an effective capillarity coefficient, $u_{\\mathrm{int}}$ is the local scalar field immediately ahead of the interface, and $\\kappa$ is the local interface curvature. Model the interface as the top boundary of a solid region; curvature may be approximated by a discrete second difference in the interface height.\n\n3. Boundary conditions: impose a fixed scalar field at the top and bottom boundaries that drives a linear background gradient with magnitude proportional to a control parameter $G$. Use periodic boundary conditions in the horizontal direction.\n\n4. Initialization: initialize a planar interface with a small sinusoidal height perturbation of amplitude $A_0$ and wavenumber $k = \\frac{2\\pi m}{N_x}$, where $m$ is an integer mode index and $N_x$ is the horizontal grid size. The solid occupies the region below the interface. Initialize the scalar field to a linear profile consistent with the boundary conditions.\n\n5. Empirical stability assessment: numerically estimate the temporal growth rate of the sinusoidal amplitude by $$\\sigma_{\\mathrm{emp}}(k) = \\frac{1}{T_{\\mathrm{eff}}} \\ln\\left(\\frac{A(T_{\\mathrm{eff}})}{A(0)}\\right),$$ where $A(t)$ is the amplitude of the selected Fourier mode of the interface height at time $t$, extracted from a discrete Fourier transform of the height field, and $T_{\\mathrm{eff}}$ is the number of time steps actually simulated (to account for early termination if the interface reaches the domain boundary). The empirical critical gradient $G_{\\mathrm{c,CA}}(k)$ is the value of $G$ at which $\\sigma_{\\mathrm{emp}}(k)$ changes sign, estimated by scanning $G$ over a range and selecting the value closest to zero growth rate.\n\n6. Analytical comparison: starting from Fick's second law and the linear kinetic law for the interface, perform a linear stability analysis in the discrete setting to obtain a dispersion relation of the form $$\\sigma(k;G) = \\alpha G - \\mathcal{D}(k) - \\beta k^2,$$ where $\\mathcal{D}(k)$ is the discrete diffusion contribution. For the five-point stencil on a square lattice with spacing $\\Delta x = 1$, the plane-wave response yields $$\\mathcal{D}(k) = 2D\\left(1 - \\cos(k)\\right),$$ for perturbations periodic in the horizontal direction. The analytical critical gradient is then $$G_{\\mathrm{c,an}}(k) = \\frac{\\mathcal{D}(k) + \\beta k^2}{\\alpha}.$$\n\n7. Output quantity: for each test case, compute the difference $$\\Delta G(k) = G_{\\mathrm{c,CA}}(k) - G_{\\mathrm{c,an}}(k).$$\n\nThe CA update must adhere to the following steps per time step:\n- Diffuse the scalar field $u$ using the discrete Laplacian with diffusion coefficient $D$ and enforce Dirichlet boundary conditions at the top $(y=0)$ and bottom $(y=N_y-1)$ consistent with a vertical gradient controlled by $G$. Use periodic boundary conditions in $x$.\n- Compute the discrete interface curvature $\\kappa$ using second differences of the interface height.\n- Advance the interface upward by one lattice site at columns where the interface drive is positive according to the rule: a liquid cell just above the interface solidifies if $\\alpha u_{\\mathrm{int}} - \\beta \\kappa > 0$. Reduce $u$ locally at newly solidified sites by a small consumption amount to mimic latent heat or solute uptake. The solid region is updated accordingly.\n- Measure the interface amplitude $A(t)$ for the specified mode $m$ using the magnitude of the corresponding discrete Fourier coefficient of the interface height deviation from its mean.\n\nTest suite and specifications:\n- Use a uniform grid with $N_x = 64$ and $N_y = 64$, spacing $\\Delta x = 1$ and time step $\\Delta t = 1$.\n- Use the following three test cases, each specified by $(m, D, \\alpha, \\beta, A_0, T)$:\n    1. $(m=2, D=0.2, \\alpha=0.7, \\beta=0.05, A_0=2.0, T=180)$\n    2. $(m=2, D=0.01, \\alpha=0.5, \\beta=0.0, A_0=2.0, T=180)$\n    3. $(m=4, D=0.15, \\alpha=0.9, \\beta=0.25, A_0=2.0, T=180)$\n- For each test case, determine $G_{\\mathrm{c,CA}}(k)$ by scanning $G$ over a suitable range centered around $G_{\\mathrm{c,an}}(k)$ and selecting the $G$ giving $\\sigma_{\\mathrm{emp}}(k)$ closest to zero.\n- The final program output must be a single line containing a comma-separated list enclosed in square brackets with the three values $[\\Delta G_1,\\Delta G_2,\\Delta G_3]$ for the test cases in the given order. Values must be decimals in dimensionless units.\n\nThe program must be self-contained and must not require any user input. It must implement the CA, perform the empirical stability analysis, compute the analytical predictions, and print the final single-line output in the specified format. No other output is permitted.",
            "solution": "The solution proceeds in two main stages for each test case: first, calculating the analytical critical gradient $G_{\\mathrm{c,an}}(k)$, and second, numerically determining the empirical critical gradient $G_{\\mathrm{c,CA}}(k)$ via direct simulation. The final result is the difference $\\Delta G(k) = G_{\\mathrm{c,CA}}(k) - G_{\\mathrm{c,an}}(k)$.\n\n### Analytical Critical Gradient, $G_{\\mathrm{c,an}}(k)$\n\nThe problem provides the analytical dispersion relation for the growth rate $\\sigma$ of a sinusoidal perturbation with wavenumber $k$ under an imposed gradient $G$:\n$$\n\\sigma(k;G) = \\alpha G - \\mathcal{D}(k) - \\beta k^2\n$$\nHere, $\\alpha G$ is the destabilizing term from the constitutional undercooling/supersaturation gradient. $\\mathcal{D}(k)$ is a stabilizing term due to diffusion, and $\\beta k^2$ is a stabilizing term due to capillarity (interface energy). The critical condition for stability is when the growth rate is zero, $\\sigma(k;G) = 0$. Solving for the gradient $G$ at this threshold gives the analytical critical gradient, $G_{\\mathrm{c,an}}(k)$.\n\nGiven the discrete diffusion term for a five-point stencil on a lattice with spacing $\\Delta x = 1$:\n$$\n\\mathcal{D}(k) = 2D(1 - \\cos(k))\n$$\nThe analytical critical gradient is found by setting $\\sigma(k;G) = 0$:\n$$\n\\alpha G_{\\mathrm{c,an}}(k) - 2D(1 - \\cos(k)) - \\beta k^2 = 0\n$$\n$$\nG_{\\mathrm{c,an}}(k) = \\frac{2D(1 - \\cos(k)) + \\beta k^2}{\\alpha}\n$$\nFor each test case, the wavenumber $k$ is determined by the mode index $m$ and the horizontal grid size $N_x = 64$:\n$$\nk = \\frac{2\\pi m}{N_x}\n$$\nThis formula is used to compute the reference critical gradient for each set of parameters $(m, D, \\alpha, \\beta)$.\n\n### Numerical Critical Gradient, $G_{\\mathrm{c,CA}}(k)$\n\nThe empirical critical gradient, $G_{\\mathrm{c,CA}}(k)$, is determined by performing a series of CA simulations over a range of candidate gradients $G$ and identifying the value for which the perturbation's growth rate is closest to zero.\n\n**1. Simulation Setup**\n\nFor each simulation, a two-dimensional grid of size $N_x = 64 \\times N_y = 64$ is initialized. The coordinate system is defined with $y=0$ at the top and $y=N_y-1$ at the bottom.\n\n- **Scalar Field $u$**: The scalar field $u$, representing supersaturation, is initialized with a linear profile consistent with the imposed gradient $G$. Boundary conditions are fixed (Dirichlet) at the top and bottom: $u(x, y=0) = G(N_y-1)$ and $u(x, y=N_y-1) = 0$. The initial field is thus $u(x, y) = G \\cdot (N_y - 1 - y)$.\n- **Interface**: The interface is represented by an integer array of heights $h(x)$, where $h(x)$ is the y-coordinate of the solid-liquid boundary in column $x$. The solid phase exists for $y \\ge h(x)$. The interface is initialized near the bottom of the domain (at a mean height of $N_y - 20$) with a sinusoidal perturbation of amplitude $A_0$ and wavenumber $k$:\n  $$\n  h(x, t=0) = \\text{round}\\left( (N_y - 20) - A_0 \\cos(kx) \\right)\n  $$\n- **Phase Field**: A phase field $\\phi(x,y)$ is used to distinguish between liquid ($\\phi=0$) and solid ($\\phi=1$) cells.\n\n**2. CA Time Evolution**\n\nThe system evolves over a maximum of $T$ time steps, with $\\Delta t=1$. Each step consists of the following sequential updates:\n\n- **Diffusion of $u$**: The scalar field $u$ evolves according to the explicit finite-difference form of Fick's second law, $\\frac{\\partial u}{\\partial t} = D \\nabla^2 u$. The Laplacian $\\nabla^2 u$ is computed using a five-point stencil with periodic boundary conditions in the $x$-direction.\n  $$\n  u(x,y,t+\\Delta t) = u(x,y,t) + D \\Delta t \\left[ u(x+1,y,t) + u(x-1,y,t) + u(x,y+1,t) + u(x,y-1,t) - 4u(x,y,t) \\right]\n  $$\n  After the diffusion update, the fixed boundary conditions at $y=0$ and $y=N_y-1$ are re-imposed. Furthermore, the supersaturation within the solid region is set to zero, $u(x,y) = 0$ for all cells where $\\phi(x,y)=1$.\n\n- **Interface Advancement**: The interface motion is governed by a discrete rule based on the local driving force.\n    - The local supersaturation at the interface is $u_{\\mathrm{int}}(x) = u(x, h(x)-1, t+\\Delta t)$.\n    - The local interface curvature $\\kappa(x)$ is approximated by the central second difference of the height profile: $\\kappa(x) = h(x+1) + h(x-1) - 2h(x)$.\n    - The driving force is $F_{\\text{drive}}(x) = \\alpha u_{\\mathrm{int}}(x) - \\beta \\kappa(x)$.\n    - For each column $x$ where $F_{\\text{drive}}(x) > 0$, the interface advances upward by one lattice site: $h(x) \\to h(x) - 1$. This threshold-based, discrete advancement is a key distinction from the continuous velocity law assumed in the analytical model.\n\n- **Post-advancement Update**: Following interface advancement, any newly solidified cells have their local supersaturation consumed by setting $u=0$ at their locations.\n\n**3. Growth Rate Measurement**\n\nThe amplitude of the perturbation, $A(t)$, is measured at each time step. The mean height is subtracted from the interface profile, $h'(x,t) = h(x,t) - \\langle h \\rangle_x$, and a Discrete Fourier Transform (DFT) is performed on $h'(x,t)$. The amplitude of the mode $m$ is extracted using the standard definition for real signals:\n$$\nA(t) = \\frac{2}{N_x} |\\hat{h}'(m,t)|\n$$\nwhere $\\hat{h}'(m,t)$ is the $m$-th complex coefficient from the DFT. The initial amplitude $A(0)$ is measured from the discretized initial interface, and the final amplitude $A(T_{\\mathrm{eff}})$ is measured at the end of the simulation. The effective simulation time, $T_{\\mathrm{eff}}$, is the number of steps completed before the simulation terminates, which may be less than the maximum time $T$ if the interface reaches a domain boundary.\n\nThe empirical growth rate is then computed as:\n$$\n\\sigma_{\\mathrm{emp}}(k) = \\frac{1}{T_{\\mathrm{eff}}} \\ln\\left(\\frac{A(T_{\\mathrm{eff}})}{A(0)}\\right)\n$$\n\n**4. Finding $G_{\\mathrm{c,CA}}(k)$**\n\nFor each test case, a one-dimensional search is conducted over a range of candidate $G$ values centered on the analytical prediction $G_{\\mathrm{c,an}}(k)$. For each $G_{\\text{test}}$, a full CA simulation is run to compute $\\sigma_{\\mathrm{emp}}(k)$. The value of $G_{\\text{test}}$ that yields a growth rate closest to zero is selected as the numerical critical gradient $G_{\\mathrm{c,CA}}(k)$.\n\nThis procedure systematically determines the numerical stability threshold, allowing for a direct comparison with the analytical prediction and the calculation of $\\Delta G(k)$. The primary sources of discrepancy $\\Delta G(k)$ include the CA's discrete, thresholded interface advancement rule versus the continuous velocity law of the analytical model, and the use of the continuous curvature approximation $\\beta k^2$ in the analytical formula instead of the discrete representation.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the complete analysis for all test cases.\n    \"\"\"\n    test_cases = [\n        # (m, D, alpha, beta, A0, T)\n        (2, 0.2, 0.7, 0.05, 2.0, 180),\n        (2, 0.01, 0.5, 0.0, 2.0, 180),\n        (4, 0.15, 0.9, 0.25, 2.0, 180),\n    ]\n\n    delta_g_results = []\n\n    for m, D, alpha, beta, A0, T in test_cases:\n        params = {\n            'm': m, 'D': D, 'alpha': alpha, 'beta': beta,\n            'A0': A0, 'T': T,\n            'Nx': 64, 'Ny': 64\n        }\n        \n        # 1. Calculate analytical critical gradient\n        k = 2 * np.pi * m / params['Nx']\n        D_k = 2 * D * (1 - np.cos(k))\n        g_c_analytical = (D_k + beta * k**2) / alpha\n        \n        # 2. Find numerical critical gradient by scanning G\n        g_c_numerical = find_g_crit_ca(params, g_c_analytical)\n        \n        # 3. Compute and store the difference\n        delta_g = g_c_numerical - g_c_analytical\n        delta_g_results.append(delta_g)\n\n    print(f\"[{','.join(f'{g:.6f}' for g in delta_g_results)}]\")\n\ndef find_g_crit_ca(params, g_an_estimate):\n    \"\"\"\n    Scans a range of G values around an estimate to find the numerical critical gradient.\n    \"\"\"\n    if g_an_estimate == 0:\n        # Handle cases where analytical G is zero or very small\n        g_range = np.linspace(-0.01, 0.01, 21)\n    else:\n        # Scan a range from 50% to 150% of the analytical value\n        g_range = np.linspace(g_an_estimate * 0.5, g_an_estimate * 1.5, 21)\n    \n    sigmas = []\n    for g_test in g_range:\n        current_params = params.copy()\n        current_params['G'] = g_test\n        sigma = run_ca_simulation(current_params)\n        sigmas.append(sigma)\n    \n    sigmas = np.array(sigmas)\n    # Find the G that results in sigma closest to 0\n    closest_idx = np.argmin(np.abs(sigmas))\n    \n    return g_range[closest_idx]\n\ndef run_ca_simulation(params):\n    \"\"\"\n    Runs a single Cellular Automaton simulation for a given set of parameters.\n    \"\"\"\n    # Unpack parameters\n    m, D, alpha, beta, A0, T = params['m'], params['D'], params['alpha'], params['beta'], params['A0'], params['T']\n    Nx, Ny, G = params['Nx'], params['Ny'], params['G']\n\n    k = 2 * np.pi * m / Nx\n    x_coords = np.arange(Nx)\n    \n    # Initialization\n    # Scalar field u\n    y_coords = np.arange(Ny).reshape(-1, 1)\n    u = G * (Ny - 1 - y_coords)\n    u = np.broadcast_to(u, (Ny, Nx)).copy()\n    \n    # Interface height h\n    h_mean = Ny - 20\n    h_initial = np.round(h_mean - A0 * np.cos(k * x_coords)).astype(int)\n    h = h_initial.copy()\n    \n    # Phase field (1 for solid, 0 for liquid)\n    y_grid, _ = np.mgrid[0:Ny, 0:Nx]\n    phase_mask = y_grid >= h\n    u[phase_mask] = 0.0\n\n    # Measure initial amplitude\n    h_dev_initial = h_initial - np.mean(h_initial)\n    fft_initial = np.fft.fft(h_dev_initial)\n    A_initial = (2 / Nx) * np.abs(fft_initial[m])\n\n    if A_initial == 0:\n        return np.inf  # Undefined growth\n\n    T_eff = T\n    for t in range(1, T + 1):\n        # Diffusion Step\n        lap_u = (np.roll(u, 1, axis=1) + np.roll(u, -1, axis=1) +\n                 np.roll(u, 1, axis=0) + np.roll(u, -1, axis=0) - 4.0 * u)\n        u += D * lap_u\n\n        # Set u=0 in the solid region\n        solid_mask = y_grid >= h\n        u[solid_mask] = 0.0\n\n        # Enforce Dirichlet BCs\n        u[0, :] = G * (Ny - 1)\n        u[Ny-1, :] = 0.0\n        \n        # Interface Advancement Step\n        # Check for boundary collision\n        if np.any(h <= 1) or np.any(h >= Ny - 2):\n            T_eff = t - 1\n            break\n\n        # Get u just above the interface\n        u_interface = u[h - 1, x_coords]\n        \n        # Calculate curvature\n        kappa = np.roll(h, 1) + np.roll(h, -1) - 2 * h\n        \n        # Calculate drive and advance interface\n        drive = alpha * u_interface - beta * kappa\n        to_advance = drive > 0\n        \n        h_old = h.copy()\n        h[to_advance] -= 1\n        \n        # Consume supersaturation at newly solidified cells\n        newly_solidified_mask_x = h < h_old\n        if np.any(newly_solidified_mask_x):\n            new_solid_y_coords = h[newly_solidified_mask_x]\n            new_solid_x_coords = x_coords[newly_solidified_mask_x]\n            u[new_solid_y_coords, new_solid_x_coords] = 0.0\n    \n    if T_eff <= 0:\n        return np.inf # Simulation ended immediately\n\n    # Measure final amplitude\n    h_dev_final = h - np.mean(h)\n    fft_final = np.fft.fft(h_dev_final)\n    A_final = (2 / Nx) * np.abs(fft_final[m])\n\n    if A_final == 0:\n        return -np.inf # Perturbation died out completely\n\n    # Calculate empirical growth rate\n    sigma_emp = (1 / T_eff) * np.log(A_final / A_initial)\n    \n    return sigma_emp\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}