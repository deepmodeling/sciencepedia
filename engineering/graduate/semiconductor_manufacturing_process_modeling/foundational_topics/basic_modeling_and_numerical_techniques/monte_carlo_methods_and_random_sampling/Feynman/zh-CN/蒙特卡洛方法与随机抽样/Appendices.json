{
    "hands_on_practices": [
        {
            "introduction": "在启动大规模蒙特卡洛模拟之前，一个关键的初始步骤是估算所需的样本数量。这项练习将引导您推导达到期望相对误差所需的样本量公式，将“需要运行多少次？”这个实际问题置于中心极限定理的理论基础之上。理解样本量、方差和精度之间的关系 ，对于设计高效且有效的计算实验至关重要。",
            "id": "4143286",
            "problem": "在一个用于极紫外光刻过程中随机缺陷预测的半导体制造过程建模任务中，令一个高维随机向量 $\\mathbf{X} \\in \\mathbb{R}^{d}$ 编码晶圆级的工艺变化（线边缘粗糙度参数、光刻胶模糊、随机光子散粒噪声替代物、刻蚀偏差参数），并令标量响应 $Y = g(\\mathbf{X})$ 表示每单位面积上预测的随机微桥数量。您使用普通蒙特卡罗（MC）方法，通过来自 $N$ 个独立同分布实现的样本均值 $\\bar{Y}_{N}$ 来估计均值 $\\mu = \\mathbb{E}[Y]$。假设 $Y$ 具有有限方差 $\\sigma^{2} = \\operatorname{Var}(Y)$，并且一项初步的引导性研究为 $\\sigma^{2}$ 提供了一个可靠的规划值。您需要为 $\\mu$ 构建一个置信水平为 $1-\\alpha$ 的双侧置信区间，其半宽最多为预设的相对容差 $\\varepsilon \\mu$，其中给定 $\\varepsilon \\in (0,1)$ 和 $\\alpha \\in (0,1)$。\n\n从中心极限定理（CLT）和基于正态分位数的样本均值置信区间出发，推导最小样本量 $N$（忽略整数约束）的显式封闭形式表达式，该表达式应使用上 $\\alpha/2$ 标准正态分位数 $z_{\\alpha/2}$、方差代理 $\\sigma^{2}$、相对容差 $\\varepsilon$ 和真实均值 $\\mu$ 来表示。将您的最终答案表示为单个简化的解析表达式。无需单位。\n\n最后，在不进行数值计算的情况下，讨论在半导体工艺模型校准中常见的高维参数空间（大 $d$）中校准 $g$ 时，这一要求的实用性，包括当 $|\\mu|$ 很小时的影响，以及方差缩减技术如何改变所需的 $N$。\n\n您最终报告的结果必须是 $N$ 的单一封闭形式表达式。不要对该表达式进行四舍五入或近似。",
            "solution": "该问题要求推导出一个封闭形式的表达式，用于计算普通蒙特卡罗方法估计均值 $\\mu = \\mathbb{E}[Y]$ 以达到指定相对精度所需的最小样本量 $N$。\n\n首先对问题陈述进行验证。\n步骤1：提取给定条件。\n- 随机向量为 $\\mathbf{X} \\in \\mathbb{R}^{d}$。\n- 标量响应为 $Y = g(\\mathbf{X})$。\n- 待估计量为均值 $\\mu = \\mathbb{E}[Y]$。\n- 估计量为来自 $N$ 个独立同分布实现的样本均值 $\\bar{Y}_{N}$。\n- 响应的方差为 $\\sigma^{2} = \\operatorname{Var}(Y)$，其值为有限且有一个已知的规划值。\n- 需要为 $\\mu$ 构建一个双侧置信区间。\n- 置信水平为 $1-\\alpha$，其中 $\\alpha \\in (0,1)$。\n- 置信区间的半宽，记为 $H$，必须最多为 $\\varepsilon \\mu$。\n- 相对容差为 $\\varepsilon \\in (0,1)$。\n- 推导需从中心极限定理（CLT）和基于正态分位数的置信区间开始。\n- 推导出的 $N$ 的表达式应使用上 $\\alpha/2$ 标准正态分位数 $z_{\\alpha/2}$、$\\sigma^{2}$、$\\varepsilon$ 和 $\\mu$ 来表示。\n- $N$ 的整数约束将被忽略。\n\n步骤2：使用提取的给定条件进行验证。\n该问题具有科学依据，因为它是将统计理论（中心极限定理、置信区间、样本量计算）应用于计算科学与工程领域一个明确定义的问题（用于过程建模的蒙特卡罗模拟）的标准应用。该问题是适定的，提供了推导所需表达式的所有必要信息。其陈述客观，不包含矛盾或不完整的信息。该问题是指定领域内一个可形式化且相关的练习。因此，该问题被视为有效。\n\n步骤3：结论与行动。\n问题有效。现在开始推导解答。\n\n根据中心极限定理，对于足够大的样本量 $N$，样本均值 $\\bar{Y}_{N} = \\frac{1}{N} \\sum_{i=1}^{N} Y_i$ 的分布近似于正态分布。具体来说，给定单个样本 $Y_i$ 是独立同分布的，其均值为 $\\mu$、方差为 $\\sigma^2$，则样本均值 $\\bar{Y}_{N}$ 近似服从以下分布：\n$$\n\\bar{Y}_{N} \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{N}\\right)\n$$\n为了构建 $\\mu$ 的置信区间，我们将随机变量 $\\bar{Y}_{N}$ 标准化，以获得一个标准正态变量 $Z$：\n$$\nZ = \\frac{\\bar{Y}_{N} - \\mu}{\\sigma / \\sqrt{N}} \\sim \\mathcal{N}(0, 1)\n$$\n一个置信水平为 $1-\\alpha$ 的双侧置信区间被定义为以 $1-\\alpha$ 的概率包含真实均值 $\\mu$ 的区间。使用标准正态分布，这可以表示为：\n$$\nP\\left(-z_{\\alpha/2} \\le Z \\le z_{\\alpha/2}\\right) = 1-\\alpha\n$$\n其中 $z_{\\alpha/2}$ 是来自标准正态分布的临界值，使得 $P(Z > z_{\\alpha/2}) = \\alpha/2$。代入 $Z$ 的表达式：\n$$\nP\\left(-z_{\\alpha/2} \\le \\frac{\\bar{Y}_{N} - \\mu}{\\sigma / \\sqrt{N}} \\le z_{\\alpha/2}\\right) = 1-\\alpha\n$$\n整理不等式以分离出 $\\mu$：\n$$\nP\\left(\\bar{Y}_{N} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} \\le \\mu \\le \\bar{Y}_{N} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{N}}\\right) = 1-\\alpha\n$$\n这给出了 $\\mu$ 的近似 $100(1-\\alpha)\\%$ 置信区间为 $[\\bar{Y}_{N} - H, \\bar{Y}_{N} + H]$，其中半宽 $H$ 为：\n$$\nH = z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{N}}\n$$\n问题指定该半宽必须最多为预设的相对容差 $\\varepsilon \\mu$。这施加了以下约束：\n$$\nH \\le \\varepsilon \\mu\n$$\n将 $H$ 的表达式代入约束条件中，得到：\n$$\nz_{\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} \\le \\varepsilon \\mu\n$$\n为了找到满足此条件的最小样本量 $N$，我们对相应的等式求解 $N$：\n$$\nz_{\\alpha/2} \\frac{\\sigma}{\\sqrt{N}} = \\varepsilon \\mu\n$$\n我们重新整理方程以求解 $N$。首先，我们分离出 $\\sqrt{N}$：\n$$\n\\sqrt{N} = \\frac{z_{\\alpha/2} \\sigma}{\\varepsilon \\mu}\n$$\n对两边取平方，得到最小样本量 $N$ 的表达式，按要求忽略整数约束：\n$$\nN = \\left(\\frac{z_{\\alpha/2} \\sigma}{\\varepsilon \\mu}\\right)^2\n$$\n这可以写成其最终的简化形式：\n$$\nN = \\frac{z_{\\alpha/2}^2 \\sigma^2}{\\varepsilon^2 \\mu^2}\n$$\n这就是所要求的 $N$ 的封闭形式表达式。\n\n关于实用性的讨论如下：\n推导出的公式揭示了一个实际困难：$N$ 依赖于 $\\mu$ 和 $\\sigma^2$，而这些正是我们希望估计的未知总体参数。在实践中，$\\sigma^2$ 通常被来自引导性研究的规划值或来自数据的样本方差估计 $s^2_N$ 所取代，而 $\\mu$ 则被样本均值 $\\bar{Y}_N$ 取代。后者引入了循环依赖，但对于样本量规划，通常使用来自引导性运行的 $\\mu$ 的粗略估计。\n\n在高维参数空间（大 $d$）中，函数 $g(\\mathbf{X})$ 可能很复杂且计算成本高昂。更重要的是，高维性通常会导致函数具有较大的方差 $\\sigma^2$，这是一种与维度灾难相关的现象。由于 $N \\propto \\sigma^2$，大方差需要非常大的蒙特卡罗样本数量，再加上每次评估的高成本，可能使估计在计算上变得不可行。\n\n$N \\propto 1/\\mu^2$ 的依赖关系凸显了当 $|\\mu|$ 很小时的一个关键问题。对于固定的相对容差 $\\varepsilon$，当均值接近零时，所需的样本量 $N$ 趋于无穷大。这使得以高*相对*精度估计一个接近零的量变得极其困难。例如，在预测一个非常低的缺陷数时，相对误差标准通常是不切实际的。在这种情况下，采用*绝对*误差容差 $H \\le \\delta$ 会更合适，这将导致 $N = (z_{\\alpha/2} \\sigma / \\delta)^2$，这是一个与 $\\mu$ 无关的要求。\n\n方差缩减技术直接解决了普通蒙特卡罗方法的低效率问题。如果一个更先进的估计量（例如，使用控制变量法、重要性抽样）的方差为 $\\sigma_{\\text{new}}^2  \\sigma^2$，那么所需的样本量就变为 $N_{\\text{new}} = N \\cdot (\\sigma_{\\text{new}}^2 / \\sigma^2)$。样本量的减少与方差的减少成正比。对于 $\\sigma^2$ 很大的高维问题，实现显著的方差缩减通常是在合理计算预算内获得可靠估计的唯一可行方法。",
            "answer": "$$\n\\boxed{\\frac{z_{\\alpha/2}^2 \\sigma^2}{\\varepsilon^2 \\mu^2}}\n$$"
        },
        {
            "introduction": "当使用马尔可夫链蒙特卡洛（MCMC）等高级采样方法来探索复杂的后验分布时，确保模拟已收敛是至关重要的。本动手练习涉及推导和实现Gelman-Rubin诊断（$\\hat{R}$），这是一种通过比较多个MCMC链的链内方差和链间方差来评估收敛性的标准工具 。掌握这项技术对于建立贝叶斯推断和其他基于MCMC模型结果的可信度至关重要。",
            "id": "4143285",
            "problem": "一个半导体制造团队正在对一个代表有效等离子体刻蚀速率（单位：纳米/分钟，nm/min）的单一潜过程参数 $\\theta$ 的后验分布进行建模。该后验分布通过多个独立的马尔可夫链蒙特卡洛 (MCMC) 链进行探索，每条链都生成样本 $\\{\\theta_{ij}\\}$，其中 $i$ 为链的索引，$j$ 为链内迭代的索引。目标是构建一个 Gelman-Rubin 潜在尺度缩减诊断量 $\\hat{R}$，以评估这些链是否已收敛到同一个平稳分布。\n\n从基本定义和定律出发，您必须为 Gelman-Rubin 潜在尺度缩减因子 $\\hat{R}$ 推导出一个可计算的表达式：\n- 使用任意有限样本 $\\{x_{j}\\}$ 的样本均值 $\\bar{x} = \\frac{1}{n}\\sum_{j=1}^{n} x_{j}$ 和无偏样本方差 $s^{2} = \\frac{1}{n-1}\\sum_{j=1}^{n} (x_{j}-\\bar{x})^{2}$ 的定义。\n- 使用全方差定律，该定律指出，对于任意随机变量 $X$ 和 $Y$，$\\mathrm{Var}(X) = \\mathrm{E}[\\mathrm{Var}(X|Y)] + \\mathrm{Var}(\\mathrm{E}[X|Y])$。\n- 定义估算跨链边际后验方差估计与平均链内方差之间的目标比率所需的所有量，并由此比率定义一个潜在尺度缩减因子 $\\hat{R}$，该因子量化了如果采样无限期地继续下去可以预期的尺度缩减程度。\n\n一旦您为 $\\hat{R}$ 推导出正确的表达式，就实现一个程序，该程序：\n1. 在指定的正态分布下，为 $\\theta$ 生成多个后验样本合成链，以模拟 MCMC 输出。使用带有固定种子的独立伪随机数生成器以确保可复现性。\n2. 使用您推导的表达式为每个测试用例计算 $\\hat{R}$。\n3. 将 $\\hat{R}$ 与选定的阈值 $T$ 进行比较，以生成一个指示收敛性的布尔标志。为便于解释，较小的 $\\hat{R}$ 值表示更好的跨链一致性；您必须通过检查 $\\hat{R}  T$ 来确定收敛性。\n\n使用以下测试套件以确保覆盖不同方面：\n- 具有收敛链的基线案例。\n- 具有一个未收敛链的案例。\n- 链长度较短的案例，由于采样变异性较高，可能导致 $\\hat{R}$ 值膨胀。\n- 具有一个轻微偏离链的案例，用于测试诊断的敏感性。\n\n您的程序必须使用Python 3在指定的执行环境中运行。所有计算必须在`solve`函数内部执行，并且只能输出最终结果的单行字符串。\n\n对于所有测试用例，使用以下固定参数：\n- 测试用例1：`m=4, n=1000, means=[50, 50, 50, 50], std_dev=2, seeds=[101, 102, 103, 104], T=1.1`\n- 测试用例2：`m=3, n=800, means=[50, 50, 53], std_dev=2, seeds=[201, 202, 203], T=1.1`\n- 测试用例3：`m=4, n=25, means=[50, 50, 50, 50], std_dev=2, seeds=[301, 302, 303, 304], T=1.1`\n- 测试用例4：`m=4, n=500, means=[50, 50, 50, 51], std_dev=2, seeds=[401, 402, 403, 404], T=1.1`\n\n您的程序应生成一个单行输出，其中包含一个用方括号括起来的、逗号分隔的列表形式的列表。输出必须遵循以下格式：`[[r1,b1],[r2,b2],[r3,b3],[r4,b4]]`，其中`r`是四舍五入到四位小数的$\\hat{R}$值，`b`是表示收敛性的布尔标志（`True`/`False`）。",
            "solution": "目标是推导并实现 Gelman-Rubin 潜在尺度缩减因子（记为 $\\hat{R}$），以评估多个马尔可夫链蒙特卡洛 (MCMC) 链的收敛性。该推导将基于基本统计学原理，包括全方差定律和样本矩的定义。\n\n设存在 $m$ 条独立的 MCMC 链，每条链的长度为 $n$。令 $\\theta_{ij}$ 表示第 $i$ 条链的第 $j$ 个样本，其中 $i=1, \\dots, m$ 且 $j=1, \\dots, n$。这些是参数 $\\theta$ 的后验分布的样本。\n\n推导过程分几步进行：\n\n1.  **计算链内方差和链间方差**\n\n    首先，对于每个单独的链 $i$，我们计算其样本均值 $\\bar{\\theta}_{i.}$ 和其无偏样本方差 $s_i^2$。\n    \n    第 $i$ 条链的样本均值为：\n    $$ \\bar{\\theta}_{i.} = \\frac{1}{n} \\sum_{j=1}^{n} \\theta_{ij} $$\n    \n    第 $i$ 条链的无偏样本方差为：\n    $$ s_i^2 = \\frac{1}{n-1} \\sum_{j=1}^{n} (\\theta_{ij} - \\bar{\\theta}_{i.})^2 $$\n\n    **平均链内方差** $W$ 是这些单个链方差的均值。假设链已达到平稳状态，$W$ 可作为任何给定链内期望方差的估计。\n    $$ W = \\frac{1}{m} \\sum_{i=1}^{m} s_i^2 $$\n\n    接下来，我们量化链*之间*的变异。这通过链均值围绕所有样本的总均值的方差来体现。总均值 $\\bar{\\theta}_{..}$ 是链均值的平均值：\n    $$ \\bar{\\theta}_{..} = \\frac{1}{m} \\sum_{i=1}^{m} \\bar{\\theta}_{i.} $$\n\n    **链间方差** $B$ 定义为链均值的样本方差，并按链长 $n$ 进行缩放。\n    $$ B = \\frac{n}{m-1} \\sum_{i=1}^{m} (\\bar{\\theta}_{i.} - \\bar{\\theta}_{..})^2 $$\n    因子 $n$ 至关重要。量 $\\frac{B}{n}$ 是链均值的方差。由于大小为 $n$ 的样本均值的方差大约是基础分布方差的 $\\frac{1}{n}$，我们通过乘以 $n$ 进行缩放，使得 $B$ 与 $W$ 估计的是同一个方差。\n\n2.  **估计边际后验方差**\n\n    全方差定律指出，一个随机变量的总方差可以分解为条件方差的期望和条件期望的方差之和。对于我们的参数 $\\theta$，以链索引 $I$ 为条件，我们有：\n    $$ \\mathrm{Var}(\\theta) = \\mathrm{E}[\\mathrm{Var}(\\theta|I)] + \\mathrm{Var}(\\mathrm{E}[\\theta|I]) $$\n    如果链已收敛，它们都从相同的平稳后验分布中抽样。在这种理想情况下，$W$ 是 $\\mathrm{Var}(\\theta)$ 的一个估计量。然而，对于有限长度的链，$W$ 倾向于低估真实的后验方差，因为每个单独的链可能尚未完全探索整个参数空间。\n\n    Gelman 和 Rubin 提出了一个边际后验方差的估计量 $\\widehat{\\mathrm{Var}}^+(\\theta|y)$，它结合了链内和链间信息。该估计量旨在高估真实方差，使其成为一种保守的诊断度量。它是 $W$ 和 $B$ 的加权平均：\n    $$ \\widehat{\\mathrm{Var}}^+(\\theta|y) = \\frac{n-1}{n} W + \\frac{1}{n} B $$\n    这个混合方差估计考虑了对于有限 $n$，$W$ 是一个低估值的事实，并引入链间变异 $B$ 作为修正。如果链是平稳的，该估计量是后验方差的无偏估计。如果链不是平稳的（例如，它们从相距很远的位置开始且尚未完全混合），$B$ 将会偏大，导致 $\\widehat{\\mathrm{Var}}^+(\\theta|y)$ 也偏大。\n\n3.  **定义潜在尺度缩减因子 ($\\hat{R}$)**\n\n    该诊断的核心思想是将混合方差估计 $\\widehat{\\mathrm{Var}}^+(\\theta|y)$ 与平均链内方差 $W$ 进行比较。如果链已收敛到目标分布，这两个量应该彼此接近。一个大的差异表明，与链内方差相比，链间方差相当大，这预示着尚未收敛。\n\n    潜在尺度缩减因子 $\\hat{R}$ 定义为这两个方差估计值之比的平方根：\n    $$ \\hat{R} = \\sqrt{\\frac{\\widehat{\\mathrm{Var}}^+(\\theta|y)}{W}} $$\n    代入 $\\widehat{\\mathrm{Var}}^+(\\theta|y)$ 的表达式，我们得到最终的可计算公式：\n    $$ \\hat{R} = \\sqrt{\\frac{\\frac{n-1}{n} W + \\frac{1}{n} B}{W}} = \\sqrt{\\frac{n-1}{n} + \\frac{B}{nW}} $$\n    随着链运行时间增长（$n \\to \\infty$）并收敛，各链的均值 $\\bar{\\theta}_{i.}$ 将趋向一个共同值，导致 $B$ 相对于 $nW$ 变得很小。因此，$\\hat{R}$ 将趋近于 1。一个显著大于 1 的 $\\hat{R}$ 值表明，通过延长链的运行时间以改善混合，方差可以被显著减小，从而暗示了不收敛。一个常用的启发式方法是要求所有参数的 $\\hat{R}  1.1$，作为收敛的一个必要（但非充分）条件。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Gelman-Rubin diagnostic problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"m\": 4, \"n\": 1000, \"means\": [50, 50, 50, 50],\n            \"std_dev\": 2, \"seeds\": [101, 102, 103, 104], \"T\": 1.1\n        },\n        {\n            \"m\": 3, \"n\": 800, \"means\": [50, 50, 53],\n            \"std_dev\": 2, \"seeds\": [201, 202, 203], \"T\": 1.1\n        },\n        {\n            \"m\": 4, \"n\": 25, \"means\": [50, 50, 50, 50],\n            \"std_dev\": 2, \"seeds\": [301, 302, 303, 304], \"T\": 1.1\n        },\n        {\n            \"m\": 4, \"n\": 500, \"means\": [50, 50, 50, 51],\n            \"std_dev\": 2, \"seeds\": [401, 402, 403, 404], \"T\": 1.1\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        m = case[\"m\"]\n        n = case[\"n\"]\n        means = case[\"means\"]\n        std_dev = case[\"std_dev\"]\n        seeds = case[\"seeds\"]\n        T = case[\"T\"]\n\n        # 1. Generate synthetic chains\n        chains = []\n        for i in range(m):\n            rng = np.random.default_rng(seeds[i])\n            chain = rng.normal(loc=means[i], scale=std_dev, size=n)\n            chains.append(chain)\n        \n        # Convert list of arrays to a 2D numpy array for efficient computation\n        chains_array = np.array(chains)\n\n        # 2. Compute R-hat\n        r_hat = calculate_r_hat(chains_array, m, n)\n        \n        # 3. Round R-hat and determine convergence\n        r_hat_rounded = round(r_hat, 4)\n        converged = r_hat_rounded  T\n        \n        results.append([r_hat_rounded, converged])\n\n    # 4. Format and print the final output\n    # The output format [[r1,b1],[r2,b2]] requires custom string formatting\n    # to avoid spaces and use capital True/False.\n    output_parts = [f\"[{r},{str(c)}]\" for r, c in results]\n    final_output = f\"[{','.join(output_parts)}]\"\n    print(final_output)\n\ndef calculate_r_hat(chains: np.ndarray, m: int, n: int) -> float:\n    \"\"\"\n    Computes the Gelman-Rubin potential scale reduction factor (R-hat).\n\n    Args:\n        chains: A numpy array of shape (m, n) containing the MCMC samples.\n        m: The number of chains.\n        n: The length of each chain.\n\n    Returns:\n        The calculated R-hat value.\n    \"\"\"\n    if m == 1:\n        raise ValueError(\"R-hat requires at least 2 chains.\")\n    if n == 1:\n        raise ValueError(\"Chains must have length > 1 to compute variance.\")\n\n    # Calculate chain means (shape: (m,))\n    chain_means = np.mean(chains, axis=1)\n\n    # Calculate unbiased chain variances (shape: (m,))\n    # ddof=1 for unbiased sample variance (n-1 denominator)\n    chain_variances = np.var(chains, axis=1, ddof=1)\n\n    # Calculate W: average of the within-chain variances\n    W = np.mean(chain_variances)\n\n    # If W is zero, all chains are constant.\n    # If means are same, B=0, converged, R=sqrt((n-1)/n) ~ 1.\n    # If means are different, B>0, not converged, R=inf.\n    if W == 0:\n        is_converged = np.all(np.isclose(chain_means, chain_means[0]))\n        return np.sqrt((n - 1) / n) if is_converged else np.inf\n\n    # Calculate B: scaled variance of the chain means\n    overall_mean = np.mean(chain_means)\n    B = (n / (m - 1)) * np.sum((chain_means - overall_mean)**2)\n\n    # Calculate R-hat using the derived formula\n    r_hat = np.sqrt(((n - 1) / n) + (B / (n * W)))\n\n    return r_hat\n\nsolve()\n```"
        },
        {
            "introduction": "虽然标准蒙特卡洛方法使用伪随机数，但通过使用更均匀的点集可以提高其性能。这项练习通过计算星偏差（star-discrepancy）来探索准蒙特卡洛（QMC）方法，星偏差是衡量均匀性的一个指标。您将为伪随机点集和低偏差Sobol点集计算该指标 。通过实现基于网格的近似计算，您将具体了解QMC如何在建模光刻剂量均匀性等应用中带来更准确的估计。",
            "id": "4143268",
            "problem": "考虑一个半导体制造过程中的光刻剂量均匀性模型，其中在单位正方形 $[0,1]^2$ 上规划了等权重的曝光，并评估任何以原点为锚点的轴对齐矩形 $[0,t_1)\\times[0,t_2)$ 内的累积剂量与理想均匀目标的符合程度。点集的均匀性由星偏差（star-discrepancy）量化，对于一个包含$N$个点 $\\{x_i\\}_{i=1}^N \\subset [0,1]^2$ 的集合，其定义为在$t\\in[0,1]^2$上，经验分布函数与均匀分布之间偏差的上确界：\n$$\nD_N^* \\equiv \\sup_{t=(t_1,t_2)\\in[0,1]^2} \\left| \\frac{1}{N} \\sum_{i=1}^N \\mathbf{1}\\{x_i^{(1)}  t_1,\\, x_i^{(2)}  t_2\\} - t_1 t_2 \\right|.\n$$\n该量是无量纲的，并且可以直接解释为在以原点为锚点的矩形上最坏情况下的相对累积剂量误差，前提是假设每次曝光剂量相等，且目标剂量与面积成正比。在用于过程建模的蒙特卡洛和拟蒙特卡洛（QMC）采样中，已知像Sobol点这样的低偏差序列相对于伪随机点能改善均匀性。\n\n您的任务是实现星偏差的基于网格的经验近似，方法是用在有限网格 $\\mathcal{G}_m \\equiv \\{(i/m,j/m) : i,j \\in \\{1,2,\\dots,m\\}\\}$ 上的上确界来替代在 $[0,1]^2$ 上的上确界，其中$m\\ge 1$是给定的整数分辨率。对于每个网格节点 $(i/m,j/m)$，计算在 $[0,i/m)\\times[0,j/m)$ 内的经验累积计数，及其与面积 $(i/m)\\cdot(j/m)$ 的偏差（用$N$进行归一化），然后取遍布 $\\mathcal{G}_m$ 的最大绝对偏差。这定义了基于网格的经验星偏差近似值\n$$\n\\widehat{D}_{N,m}^* \\equiv \\max_{1\\le i,j\\le m} \\left| \\frac{1}{N}\\sum_{k=1}^N \\mathbf{1}\\left\\{x_k^{(1)}  \\frac{i}{m},\\, x_k^{(2)}  \\frac{j}{m}\\right\\} - \\frac{i}{m}\\cdot\\frac{j}{m} \\right|.\n$$\n\n从蒙特卡洛采样的基础和星偏差的定义出发，并且不使用任何快捷公式，实现以下内容：\n\n- 在 $[0,1)^2$ 中生成 $N=256$ 个二维Sobol点（非加扰）。\n- 对于三个独立的种子，分别在 $[0,1)^2$ 中生成 $N=256$ 个二维伪随机点，并通过计算三个基于网格的经验星偏差的算术平均值来汇总比较。\n- 对于每个指定的网格分辨率 $m$，计算Sobol点集的基于网格的经验星偏差 $\\widehat{D}_{N,m}^*$ 以及三个伪随机点集的平均经验星偏差。\n- 根据上述等剂量曝光光刻模型，将每个偏差解释为无量纲的最坏情况下的相对累积剂量误差。\n\n本任务中不需要物理单位，因为偏差及其解释都是无量纲的。不要使用百分号表示任何结果；所有输出必须是纯小数。\n\n使用以下测试套件以确保覆盖不同方面：\n- 粗糙网格分辨率 $m=4$（基于网格的上确界的边界条件）。\n- 中等精细分辨率 $m=16$（常规路径）。\n- 精细分辨率 $m=64$（提高保真度）。\n- 极精细分辨率 $m=128$（考验计算效率的边界情况）。\n\n对于所有测试用例，使用相同的三个伪随机种子 $s\\in\\{101,202,303\\}$。在所有情况下，维度均为 $2$，点数为 $N=256$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于按顺序排列的四个网格分辨率 $m\\in[4,16,64,128]$，按以下顺序输出八个浮点数：\n$$\n[\\widehat{D}_{N,4}^{*,\\mathrm{Sobol}},\\, \\overline{\\widehat{D}_{N,4}^{*,\\mathrm{PRNG}}},\\, \\widehat{D}_{N,16}^{*,\\mathrm{Sobol}},\\, \\overline{\\widehat{D}_{N,16}^{*,\\mathrm{PRNG}}},\\, \\widehat{D}_{N,64}^{*,\\mathrm{Sobol}},\\, \\overline{\\widehat{D}_{N,64}^{*,\\mathrm{PRNG}}},\\, \\widehat{D}_{N,128}^{*,\\mathrm{Sobol}},\\, \\overline{\\widehat{D}_{N,128}^{*,\\mathrm{PRNG}}}],\n$$\n其中 $\\overline{\\widehat{D}_{N,m}^{*,\\mathrm{PRNG}}}$ 表示对三个伪随机种子的算术平均值。最终输出是无量纲的小数，表示在每个 $m$ 值下，Sobol点的基于网格的经验星偏差值以及伪随机点的平均值。",
            "solution": "所提出的问题是有效的。它在数值分析和统计计算领域有科学依据，特别涉及蒙特卡洛和拟蒙特卡洛方法。问题定义明确，所有必要的参数、常数和定义都已提供，以确保唯一且可验证的解。半导体光刻的背景为星偏差概念提供了一个现实且可形式化的应用场景。\n\n任务是为二维点集计算星偏差的基于网格的经验近似值 $\\widehat{D}_{N,m}^*$。该度量是均匀分布理论及其应用的一块基石，用于量化单位超立方体内点分布的均匀性。对于 $[0,1]^2$ 中的一个包含$N$个点 $\\{x_k\\}_{k=1}^N$ 的集合，星偏差 $D_N^*$ 是在所有以原点为锚点的矩形测试集上，经验分布与均匀分布之间的最坏情况偏差。其定义是：\n$$\nD_N^* \\equiv \\sup_{t=(t_1,t_2)\\in[0,1]^2} \\left| \\frac{N([0,t_1)\\times[0,t_2))}{N} - t_1 t_2 \\right|\n$$\n其中 $N([0,t_1)\\times[0,t_2))$是落入矩形 $[0,t_1)\\times[0,t_2)$ 内的点 $x_k$ 的数量，而项 $t_1 t_2$ 是该矩形的面积，代表在均匀分布下点的预期分数。\n\n问题要求实现的不是计算上困难的真实上确界，而是一个易于处理的近似值 $\\widehat{D}_{N,m}^*$。这是通过将测试矩形限制在给定分辨率 $m$ 的有限网格 $\\mathcal{G}_m = \\{(i/m, j/m) : i,j \\in \\{1, 2, \\dots, m\\}\\}$ 上来实现的。需要计算的公式是：\n$$\n\\widehat{D}_{N,m}^* \\equiv \\max_{1\\le i,j\\le m} \\left| \\frac{1}{N}\\sum_{k=1}^N \\mathbf{1}\\left\\{x_k^{(1)}  \\frac{i}{m},\\, x_k^{(2)}  \\frac{j}{m}\\right\\} - \\frac{i}{m}\\cdot\\frac{j}{m} \\right|\n$$\n在此，$\\mathbf{1}\\{\\cdot\\}$ 是指示函数。项 $\\frac{1}{N}\\sum_{k=1}^N \\mathbf{1}\\{\\cdot\\}$ 是在网格点 $(\\frac{i}{m}, \\frac{j}{m})$ 处评估的经验累积分布函数（ECDF），而 $\\frac{i}{m}\\cdot\\frac{j}{m}$ 是均匀分布的理论累积分布函数（CDF）。\n\n一种直接、朴素的计算方法是遍历所有 $m^2$ 个网格节点，并对每个节点遍历所有 $N$ 个点，其时间复杂度为 $O(N \\cdot m^2)$。对于指定的最大分辨率 $m=128$，这在计算上是可行的，但效率不高。我们采用了一种更高效的算法，其复杂度为 $O(N + m^2)$。该算法按以下步骤进行：\n\n1.  **点集生成**：首先，生成所需的点集。对于拟蒙特卡洛（QMC）情况，生成 $N=256$ 个非加扰的二维Sobol点。对于蒙特卡洛（MC）情况，使用种子101、202和303的标准生成器生成三组独立的 $N=256$ 个伪随机点，以保证可复现性。\n\n2.  **分箱**：对于给定的点集和网格分辨率 $m$，将 $[0,1)^2$ 中的 $N$ 个点分入一个 $m \\times m$ 的网格单元中。构建一个二维直方图，其中每个条目 $(i,j)$ 存储落入单元格 $[\\frac{i}{m}, \\frac{i+1}{m}) \\times [\\frac{j}{m}, \\frac{j+1}{m})$ 中的点的数量。此步骤的复杂度为 $O(N)$。\n\n3.  **累积求和**：对直方图计算二维前缀和（或累积和）。得到的 $m \\times m$ 累积计数矩阵（我们称之为 $\\mathbf{C}$）的元素 $\\mathbf{C}_{i-1,j-1}$ 包含矩形 $[0, \\frac{i}{m}) \\times [0, \\frac{j}{m})$ 内点的总数。此操作的复杂度为 $O(m^2)$。\n\n4.  **偏差计算**：将矩阵 $\\mathbf{C}$ 除以 $N$ 进行归一化，得到ECDF值 $\\mathbf{F}_N = \\mathbf{C}/N$。同样，构建一个相应的 $m \\times m$ 理论面积矩阵 $\\mathbf{A}$，其中 $\\mathbf{A}_{i-1,j-1} = (\\frac{i}{m}) \\cdot (\\frac{j}{m})$。然后通过取元素级绝对差的最大值来找到基于网格的偏差：$\\widehat{D}_{N,m}^* = \\max |\\mathbf{F}_N - \\mathbf{A}|$。\n\n对每个网格分辨率 $m \\in \\{4, 16, 64, 128\\}$ 重复此过程。对于伪随机点，每个 $m$ 的最终报告值是根据三个独立集合计算出的偏差的算术平均值。然后将Sobol偏差和平均伪随机偏差的结果进行整理。正如低偏差序列理论所预期的那样，Sobol点应表现出比伪随机点系统性更低的偏差，从而具有更好的均匀性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import qmc\n\ndef calculate_grid_discrepancy(points: np.ndarray, m: int) - float:\n    \"\"\"\n    Calculates the grid-based empirical star-discrepancy for a set of 2D points.\n\n    Args:\n        points: An array of shape (N, 2) of points in the unit square [0,1)^2.\n        m: The resolution of the grid.\n\n    Returns:\n        The empirical grid-based star-discrepancy.\n    \"\"\"\n    N = points.shape[0]\n    if N == 0:\n        # If there are no points, the empirical measure is 0. The max discrepancy\n        # will be at i=m, j=m, where the area is 1.\n        return 1.0\n\n    # Step 1: Create a 2D histogram of the points.\n    # `hist[i, j]` counts points in [i/m, (i+1)/m) x [j/m, (j+1)/m).\n    # The range is [0,1) for both axes.\n    # Note: numpy.histogram2d returns a histogram where the first dimension corresponds\n    # to the first input array (x-coordinates) and the second to the y-coordinates.\n    # We treat x as dimension 0 and y as dimension 1.\n    hist, _, _ = np.histogram2d(\n        points[:, 0], points[:, 1], bins=m, range=[[0, 1], [0, 1]]\n    )\n\n    # Step 2: Compute the 2D cumulative sum to get counts for rectangles [0, i/m)x[0,j/m).\n    # `cumulative_counts[i-1, j-1]` will hold the count of points in the\n    # rectangle [0, i/m) x [0, j/m).\n    cumulative_counts = hist.cumsum(axis=0).cumsum(axis=1)\n\n    # Step 3: Normalize by N to get the empirical CDF values on the grid.\n    empirical_cdf = cumulative_counts / N\n\n    # Step 4: Create a grid of theoretical probabilities (areas).\n    # The test points are (i/m, j/m) for i,j in {1, ..., m}.\n    i_indices = np.arange(1, m + 1)\n    # Create m x m grids for i and j indices, with 'ij' indexing to match\n    # matrix row/column conventions.\n    grid_i, grid_j = np.meshgrid(i_indices, i_indices, indexing='ij')\n    areas = (grid_i / m) * (grid_j / m)\n\n    # Step 5: Calculate the element-wise absolute difference and find the maximum.\n    # The indices of `empirical_cdf` are 0..m-1, corresponding to i,j = 1..m.\n    # `empirical_cdf[i-1, j-1]` corresponds to the test point (i/m, j/m).\n    # `areas[i-1, j-1]` corresponds to the area (i/m * j/m).\n    discrepancy_matrix = np.abs(empirical_cdf - areas)\n    \n    return np.max(discrepancy_matrix)\n\ndef solve():\n    # Define the problem parameters.\n    N_POINTS = 256\n    DIMENSION = 2\n    PRNG_SEEDS = [101, 202, 303]\n    test_cases_m = [4, 16, 64, 128]\n\n    # Generate Sobol points once, as they are deterministic.\n    # `scramble=False` for unscrambled points as specified.\n    sobol_sampler = qmc.Sobol(d=DIMENSION, scramble=False)\n    # For N=256, which is 2^8, the sequence is optimal.\n    sobol_points = sobol_sampler.random(n=N_POINTS)\n\n    results = []\n    # Iterate through each grid resolution m.\n    for m in test_cases_m:\n        # Calculate and store the discrepancy for the Sobol set.\n        d_sobol = calculate_grid_discrepancy(sobol_points, m)\n        results.append(d_sobol)\n\n        # Calculate discrepancy for each pseudorandom set and average the results.\n        prng_discrepancies = []\n        for seed in PRNG_SEEDS:\n            rng = np.random.default_rng(seed=seed)\n            prng_points = rng.random(size=(N_POINTS, DIMENSION))\n            d_prng = calculate_grid_discrepancy(prng_points, m)\n            prng_discrepancies.append(d_prng)\n        \n        d_prng_mean = np.mean(prng_discrepancies)\n        results.append(d_prng_mean)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}