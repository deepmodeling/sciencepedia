{
    "hands_on_practices": [
        {
            "introduction": "The journey into numerical modeling often begins with the simplest schemes, which provide invaluable insight into the interplay between discretization choices and simulation stability. This first practice explores the Forward Time, Centered Space (FTCS) method applied to the one-dimensional diffusion equation, a cornerstone model in semiconductor process simulation. By performing a von Neumann stability analysis, you will uncover the critical relationship between the time step $\\Delta t$, the spatial grid spacing $h$, and the physical diffusivity $D$, and confront the practical limitations imposed by the stability constraint of explicit methods .",
            "id": "4126438",
            "problem": "In semiconductor manufacturing process modeling, the redistribution of dopants during a high-temperature furnace anneal is commonly described by Fick’s second law of diffusion for a one-dimensional concentration field. For a constant diffusivity and a uniform grid, consider the one-dimensional Partial Differential Equation (PDE)\n$$\n\\frac{\\partial C(x,t)}{\\partial t} = D \\frac{\\partial^{2} C(x,t)}{\\partial x^{2}},\n$$\nwhere $C(x,t)$ denotes the dopant concentration, $D$ is the constant diffusion coefficient, $x$ is the spatial coordinate, and $t$ is time. Using a uniform spatial grid with spacing $h$ and a Forward Time, Centered Space (FTCS) explicit time-stepping scheme, perform a von Neumann stability analysis to determine the largest stable time step $\\Delta t_{\\max}$ as a function of $D$ and $h$. Then, evaluate the largest stable time step for $D = 10^{-13}\\,\\mathrm{m^{2}/s}$ and $h = 10^{-6}\\,\\mathrm{m}$. Finally, within the context of furnace anneals of duration on the order of tens of minutes to hours, discuss whether this explicit stability constraint is practical for process simulation and why, referring to the scaling of the stability bound with $h$.\n\nRound your computed time step to three significant figures. Express the final time step in seconds.",
            "solution": "The problem requires a three-part analysis of the Forward Time, Centered Space (FTCS) discretization of the one-dimensional diffusion equation. First, a von Neumann stability analysis to derive the maximum stable time step, $\\Delta t_{\\max}$. Second, a numerical evaluation of $\\Delta t_{\\max}$ for given parameters. Third, a discussion of the practical implications of this stability constraint in the context of semiconductor process simulation.\n\nThe governing Partial Differential Equation (PDE) is Fick's second law of diffusion:\n$$\n\\frac{\\partial C(x,t)}{\\partial t} = D \\frac{\\partial^{2} C(x,t)}{\\partial x^{2}}\n$$\nwhere $C(x,t)$ is the concentration, $D$ is the constant diffusivity, $x$ is the spatial coordinate, and $t$ is time.\n\nFirst, we discretize this PDE using the FTCS scheme. Let the spatial domain be discretized with a uniform grid spacing $h$, such that $x_j = j h$, and the time domain with uniform time steps $\\Delta t$, such that $t_n = n \\Delta t$. The concentration at the grid point $(x_j, t_n)$ is denoted by $C_j^n = C(j h, n \\Delta t)$.\n\nThe time derivative $\\frac{\\partial C}{\\partial t}$ is approximated using a forward difference at time $t_n$:\n$$\n\\frac{\\partial C}{\\partial t} \\bigg|_{j,n} \\approx \\frac{C_j^{n+1} - C_j^n}{\\Delta t}\n$$\n\nThe spatial second derivative $\\frac{\\partial^2 C}{\\partial x^2}$ is approximated using a centered difference at position $x_j$:\n$$\n\\frac{\\partial^2 C}{\\partial x^2} \\bigg|_{j,n} \\approx \\frac{C_{j+1}^n - 2C_j^n + C_{j-1}^n}{h^2}\n$$\n\nSubstituting these approximations into the PDE yields the FTCS finite difference equation:\n$$\n\\frac{C_j^{n+1} - C_j^n}{\\Delta t} = D \\frac{C_{j+1}^n - 2C_j^n + C_{j-1}^n}{h^2}\n$$\n\nRearranging the terms to solve for $C_j^{n+1}$, we obtain the explicit update formula:\n$$\nC_j^{n+1} = C_j^n + \\frac{D \\Delta t}{h^2} (C_{j+1}^n - 2C_j^n + C_{j-1}^n)\n$$\nLet's define the dimensionless diffusion number, $\\alpha = \\frac{D \\Delta t}{h^2}$. The equation becomes:\n$$\nC_j^{n+1} = C_j^n + \\alpha (C_{j+1}^n - 2C_j^n + C_{j-1}^n) = \\alpha C_{j-1}^n + (1 - 2\\alpha)C_j^n + \\alpha C_{j+1}^n\n$$\n\nTo perform the von Neumann stability analysis, we consider the propagation of a single Fourier mode of the solution, represented as:\n$$\nC_j^n = G^n e^{i k x_j} = G^n e^{i k j h}\n$$\nwhere $G$ is the amplification factor per time step, $k$ is the wave number, and $i = \\sqrt{-1}$. For a stable scheme, the magnitude of the amplification factor must not exceed unity for any wave number $k$, i.e., $|G| \\le 1$. If $|G| > 1$, errors will be amplified and grow unboundedly.\n\nSubstituting the Fourier mode into the discretized equation:\n$$\nG^{n+1} e^{i k j h} = \\alpha G^n e^{i k (j-1) h} + (1 - 2\\alpha) G^n e^{i k j h} + \\alpha G^n e^{i k (j+1) h}\n$$\nDividing by the common term $G^n e^{i k j h}$ gives the expression for the amplification factor $G$:\n$$\nG = \\alpha e^{-i k h} + (1 - 2\\alpha) + \\alpha e^{i k h}\n$$\nUsing Euler's identity, $e^{i\\theta} + e^{-i\\theta} = 2\\cos(\\theta)$, we simplify the expression for $G$:\n$$\nG = 1 - 2\\alpha + \\alpha(e^{i k h} + e^{-i k h}) = 1 - 2\\alpha + 2\\alpha\\cos(k h)\n$$\nFactoring out $2\\alpha$:\n$$\nG = 1 - 2\\alpha(1 - \\cos(k h))\n$$\nUsing the trigonometric half-angle identity, $1 - \\cos(k h) = 2\\sin^2(\\frac{k h}{2})$:\n$$\nG = 1 - 4\\alpha\\sin^2\\left(\\frac{k h}{2}\\right)\n$$\nThe stability condition is $|G| \\le 1$, which is equivalent to $-1 \\le G \\le 1$.\nThe term $\\sin^2(\\frac{k h}{2})$ varies between $0$ and $1$ for all possible values of $k$.\nThe upper bound, $G \\le 1$, becomes $1 - 4\\alpha\\sin^2(\\frac{k h}{2}) \\le 1$, which implies $-4\\alpha\\sin^2(\\frac{k h}{2}) \\le 0$. Since $\\alpha = \\frac{D \\Delta t}{h^2}$ is non-negative and $\\sin^2(\\frac{k h}{2})$ is non-negative, this condition is always satisfied.\nThe lower bound, $G \\ge -1$, is the crucial constraint:\n$$\n1 - 4\\alpha\\sin^2\\left(\\frac{k h}{2}\\right) \\ge -1\n$$\n$$\n2 \\ge 4\\alpha\\sin^2\\left(\\frac{k h}{2}\\right)\n$$\n$$\n\\frac{1}{2} \\ge \\alpha\\sin^2\\left(\\frac{k h}{2}\\right)\n$$\nThis inequality must hold for all $k$. The \"worst case\" occurs when $\\sin^2(\\frac{k h}{2})$ reaches its maximum value of $1$ (for high-frequency spatial modes where $k h = \\pi$). Therefore, the stability condition simplifies to:\n$$\n\\alpha \\le \\frac{1}{2}\n$$\nSubstituting back the definition of $\\alpha$:\n$$\n\\frac{D \\Delta t}{h^2} \\le \\frac{1}{2}\n$$\nFrom this, we find the constraint on the time step $\\Delta t$:\n$$\n\\Delta t \\le \\frac{h^2}{2D}\n$$\nThe largest stable time step, $\\Delta t_{\\max}$, is therefore:\n$$\n\\Delta t_{\\max} = \\frac{h^2}{2D}\n$$\nThis completes the first part of the problem.\n\nFor the second part, we evaluate $\\Delta t_{\\max}$ using the given values $D = 10^{-13}\\,\\mathrm{m^{2}/s}$ and $h = 10^{-6}\\,\\mathrm{m}$.\n$$\n\\Delta t_{\\max} = \\frac{(10^{-6}\\,\\mathrm{m})^2}{2(10^{-13}\\,\\mathrm{m^{2}/s})} = \\frac{10^{-12}\\,\\mathrm{m^2}}{2 \\times 10^{-13}\\,\\mathrm{m^2/s}} = \\frac{10}{2}\\,\\mathrm{s} = 5\\,\\mathrm{s}\n$$\nRounding to three significant figures, the result is $5.00\\,\\mathrm{s}$.\n\nFor the third part, we discuss the practicality of this stability constraint.\nA furnace anneal process can last for tens of minutes to hours, e.g., from $1800\\,\\mathrm{s}$ ($30$ minutes) to $3600\\,\\mathrm{s}$ ($1$ hour) or more. With a maximum stable time step of $\\Delta t_{\\max} = 5.00\\,\\mathrm{s}$, simulating a $30$-minute anneal would require a minimum of $\\frac{1800\\,\\mathrm{s}}{5\\,\\mathrm{s}} = 360$ time steps. For a $1$-hour anneal, it would be $\\frac{3600\\,\\mathrm{s}}{5\\,\\mathrm{s}} = 720$ time steps. For modern computers, this number of steps is computationally inexpensive and perfectly practical.\n\nHowever, the critical issue is the scaling of the stability bound with the grid spacing $h$: $\\Delta t_{\\max} \\propto h^2$. This quadratic dependence makes the explicit FTCS scheme impractical for simulations requiring high spatial resolution. In semiconductor process modeling, it is often necessary to resolve very sharp dopant profiles or small features, which require a much finer grid (smaller $h$). For example, if we needed to refine the grid by a factor of $10$ to $h = 10^{-7}\\,\\mathrm{m}$ for better accuracy, the stability constraint would force us to reduce the time step by a factor of $10^2 = 100$:\n$$\n\\Delta t'_{\\max} = \\frac{(10^{-7}\\,\\mathrm{m})^2}{2(10^{-13}\\,\\mathrm{m^{2}/s})} = 0.05\\,\\mathrm{s}\n$$\nSimulating a $30$-minute anneal would then require $\\frac{1800\\,\\mathrm{s}}{0.05\\,\\mathrm{s}} = 36000$ time steps. Further grid refinement would rapidly increase the computational cost to prohibitive levels. For instance, halving $h$ again would quadruple the number of steps.\n\nIn conclusion, while the FTCS scheme is simple to implement, its conditional stability, and specifically the severe restriction that $\\Delta t \\le \\frac{h^2}{2D}$, renders it impractical for many realistic process simulations where fine spatial grids are essential for accuracy. The computational cost becomes excessive as $h$ is reduced. For this reason, unconditionally stable implicit methods, such as the Crank-Nicolson scheme, are generally preferred in professional process simulators despite their higher computational complexity per time step (they require solving a system of linear equations at each step). The ability to choose $\\Delta t$ based on accuracy requirements alone, rather than being constrained by stability, is a decisive advantage.",
            "answer": "$$\n\\boxed{5.00}\n$$"
        },
        {
            "introduction": "A stable numerical solution is a necessary but not sufficient condition for a successful simulation; the solution must also be accurate. This exercise provides a hands-on method for quantifying accuracy by comparing a numerical approximation against a known analytical solution, a cornerstone of code verification. You will first derive the exact temperature profile for a steady-state heat conduction problem with internal generation and Robin boundary conditions, and then use this exact solution as a benchmark to compute the $L^2$ error norm of a given numerical result . This practice demonstrates how to move from a qualitative sense of error to a rigorous, quantitative assessment.",
            "id": "4126486",
            "problem": "A high-temperature rapid thermal processing step in semiconductor manufacturing heats a silicon wafer of thickness $L$ by radiation, leading to a spatially uniform volumetric heat generation rate $q'''$ within the wafer. The wafer is cooled on both faces by a surrounding gas at ambient temperature $T_{\\infty}$ through convective heat transfer with film coefficient $h$. Assume one-dimensional, steady-state heat conduction through the wafer thickness, constant thermal conductivity $k$, and no axial variations along the wafer plane. The temperature field $T(x)$ for $x\\in[0,L]$ is governed by conservation of energy and Fourier’s law, and the boundaries obey Newton’s law of cooling. The temperature field is used to assess discretization error norms that arise in Finite Element Method (FEM) and Finite Difference Method (FDM) computations.\n\nUsing this physical model:\n- Start from the steady one-dimensional energy balance with uniform volumetric generation and Fourier’s law to derive the governing differential equation for $T(x)$ and the appropriate Robin (convective) boundary conditions at $x=0$ and $x=L$ based on outward normals.\n- Solve analytically for $T(x)$.\n- Using the following parameters that are representative of silicon wafer processing, evaluate the exact nodal temperatures on a uniform mesh with $N=5$ uniform subintervals (six nodes): $x_i = i \\Delta x$ for $i=0,1,2,3,4,5$, with $\\Delta x = L/5$:\n  - $L = 5\\times 10^{-3}\\,\\mathrm{m}$,\n  - $k = 100\\,\\mathrm{W}\\,\\mathrm{m}^{-1}\\,\\mathrm{K}^{-1}$,\n  - $h = 500\\,\\mathrm{W}\\,\\mathrm{m}^{-2}\\,\\mathrm{K}^{-1}$,\n  - $q''' = 2.0\\times 10^{7}\\,\\mathrm{W}\\,\\mathrm{m}^{-3}$,\n  - $T_{\\infty} = 300\\,\\mathrm{K}$.\n- A student has computed an approximate nodal solution on this mesh using a second-order central finite difference scheme with a one-sided boundary closure. The resulting nodal temperatures (in Kelvin) are:\n  - $T_0^{\\mathrm{num}} = 399.8$,\n  - $T_1^{\\mathrm{num}} = 400.3$,\n  - $T_2^{\\mathrm{num}} = 400.65$,\n  - $T_3^{\\mathrm{num}} = 400.55$,\n  - $T_4^{\\mathrm{num}} = 400.45$,\n  - $T_5^{\\mathrm{num}} = 399.9$.\n- Let the nodal error be $e_i = T(x_i) - T_i^{\\mathrm{num}}$. Define the root-mean-square $L^2$ error norm as\n  $$\\|e\\|_{L^2,\\mathrm{RMS}} \\equiv \\sqrt{\\frac{1}{L}\\int_{0}^{L} e(x)^2\\,\\mathrm{d}x}.$$\n  Approximate this integral with the composite trapezoidal rule using the nodal errors:\n  $$\\|e\\|_{L^2,\\mathrm{RMS}} \\approx \\sqrt{\\frac{1}{L}\\sum_{i=0}^{5} w_i e_i^2},\\quad w_0=w_5=\\frac{\\Delta x}{2},\\quad w_i=\\Delta x\\ \\text{for}\\ i=1,2,3,4.$$\n\nCompute this approximate $\\|e\\|_{L^2,\\mathrm{RMS}}$ for the given data. Express your final answer in Kelvin and round your answer to four significant figures.",
            "solution": "The problem is first validated against the specified criteria.\n\n### Step 1: Extract Givens\n-   **Physical Model**: One-dimensional, steady-state heat conduction in a wafer of thickness $L$.\n-   **Volumetric Heat Generation**: Uniform rate, $q'''$.\n-   **Thermal Conductivity**: Constant, $k$.\n-   **Boundary Conditions**: Convective cooling on both faces ($x=0$ and $x=L$) to a gas at ambient temperature $T_{\\infty}$ with a film coefficient $h$. The boundaries are governed by Robin conditions based on outward normals.\n-   **Mesh**: Uniform grid with $N=5$ subintervals, creating six nodes $x_i = i \\Delta x$ for $i=0,1,2,3,4,5$, where $\\Delta x = L/N$.\n-   **Numerical Parameters**:\n    -   $L = 5\\times 10^{-3}\\,\\mathrm{m}$\n    -   $k = 100\\,\\mathrm{W}\\,\\mathrm{m}^{-1}\\,\\mathrm{K}^{-1}$\n    -   $h = 500\\,\\mathrm{W}\\,\\mathrm{m}^{-2}\\,\\mathrm{K}^{-1}$\n    -   $q''' = 2.0\\times 10^{7}\\,\\mathrm{W}\\,\\mathrm{m}^{-3}$\n    -   $T_{\\infty} = 300\\,\\mathrm{K}$\n-   **Approximate Nodal Solution ($T_i^{\\mathrm{num}}$)**:\n    -   $T_0^{\\mathrm{num}} = 399.8\\,\\mathrm{K}$\n    -   $T_1^{\\mathrm{num}} = 400.3\\,\\mathrm{K}$\n    -   $T_2^{\\mathrm{num}} = 400.65\\,\\mathrm{K}$\n    -   $T_3^{\\mathrm{num}} = 400.55\\,\\mathrm{K}$\n    -   $T_4^{\\mathrm{num}} = 400.45\\,\\mathrm{K}$\n    -   $T_5^{\\mathrm{num}} = 399.9\\,\\mathrm{K}$\n-   **Error Definition**: Nodal error is $e_i = T(x_i) - T_i^{\\mathrm{num}}$.\n-   **Error Norm**: The root-mean-square $L^2$ error norm is defined as $\\|e\\|_{L^2,\\mathrm{RMS}} \\equiv \\sqrt{\\frac{1}{L}\\int_{0}^{L} e(x)^2\\,\\mathrm{d}x}$.\n-   **Approximation Method**: The integral for the norm is approximated by the composite trapezoidal rule:\n    $\\|e\\|_{L^2,\\mathrm{RMS}} \\approx \\sqrt{\\frac{1}{L}\\sum_{i=0}^{5} w_i e_i^2}$, with weights $w_0=w_5=\\frac{\\Delta x}{2}$ and $w_i=\\Delta x$ for $i=1,2,3,4$.\n-   **Task**: Compute the approximate $\\|e\\|_{L^2,\\mathrm{RMS}}$ and round to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is a standard, canonical problem in heat transfer, based on Fourier's law and the conservation of energy. The physical setup and parameters are realistic for semiconductor processing. It is scientifically sound.\n-   **Well-Posed**: The problem requires deriving and solving a second-order linear ordinary differential equation with two boundary conditions (one at each boundary). This constitutes a well-posed boundary value problem, which is expected to have a unique and stable solution.\n-   **Objective**: The problem is stated in precise, quantitative, and unbiased terms. All data and definitions are clear.\n-   **Conclusion**: The problem is free of scientific flaws, ambiguity, and contradictions. It is a complete and solvable problem.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution Derivation\n\n**1. Governing Equation and Boundary Conditions**\nThe one-dimensional, steady-state heat conduction equation with uniform volumetric heat generation is derived from an energy balance on a differential control volume $A \\cdot dx$, where $A$ is the cross-sectional area.\n$$q_x - q_{x+dx} + q'''(A\\,dx) = 0$$\nUsing Fourier's law, $q_x = -kA\\frac{dT}{dx}$, and expanding $q_{x+dx}$ in a Taylor series, we get:\n$$(-kA\\frac{dT}{dx}) - (-kA\\frac{dT}{dx} - kA\\frac{d^2T}{dx^2}dx) + q'''A\\,dx = 0$$\n$$kA\\frac{d^2T}{dx^2}dx + q'''A\\,dx = 0$$\nDividing by $kA\\,dx$ gives the governing differential equation:\n$$\\frac{d^2T}{dx^2} + \\frac{q'''}{k} = 0$$\nThe boundary conditions are derived from an energy balance at the surfaces $x=0$ and $x=L$. The heat flux conducted to the surface must be equal to the heat flux convected away from the surface. The heat flux vector is $\\vec{q}'' = -k\\frac{dT}{dx}\\hat{i}$. The convective flux is $h(T - T_\\infty)$.\n\nAt $x=0$, the outward normal is $-\\hat{i}$. The outward heat flux is $\\vec{q}'' \\cdot (-\\hat{i}) = k\\frac{dT}{dx}$. So the boundary condition is:\n$$k\\frac{dT}{dx}\\bigg|_{x=0} = h(T(0) - T_{\\infty})$$\nAt $x=L$, the outward normal is $+\\hat{i}$. The outward heat flux is $\\vec{q}'' \\cdot (+\\hat{i}) = -k\\frac{dT}{dx}$. So the boundary condition is:\n$$-k\\frac{dT}{dx}\\bigg|_{x=L} = h(T(L) - T_{\\infty})$$\n\n**2. Analytical Solution for $T(x)$**\nIntegrating the governing equation twice gives the general solution for the temperature field:\n$$T'(x) = -\\frac{q'''}{k}x + C_1$$\n$$T(x) = -\\frac{q'''}{2k}x^2 + C_1x + C_2$$\nThe physical problem is symmetric. The geometry, heat generation, and boundary cooling are identical on both sides. Therefore, the temperature profile must be symmetric about the centerline $x = L/2$. This implies that the temperature gradient at the centerline is zero, i.e., $T'(L/2) = 0$.\n$$T'\\left(\\frac{L}{2}\\right) = -\\frac{q'''}{k}\\left(\\frac{L}{2}\\right) + C_1 = 0 \\implies C_1 = \\frac{q'''L}{2k}$$\nNow we use the boundary condition at $x=0$ to find $C_2$:\n$$k \\cdot T'(0) = h(T(0) - T_{\\infty})$$\n$$k \\cdot C_1 = h(C_2 - T_{\\infty})$$\nSubstituting the expression for $C_1$:\n$$k \\left(\\frac{q'''L}{2k}\\right) = h(C_2 - T_{\\infty})$$\n$$\\frac{q'''L}{2} = h(C_2 - T_{\\infty}) \\implies C_2 = T_{\\infty} + \\frac{q'''L}{2h}$$\nSubstituting $C_1$ and $C_2$ back into the general solution for $T(x)$:\n$$T(x) = -\\frac{q'''}{2k}x^2 + \\frac{q'''L}{2k}x + T_{\\infty} + \\frac{q'''L}{2h}$$\nThis can be rearranged to:\n$$T(x) = T_{\\infty} + \\frac{q'''}{2k}(Lx - x^2) + \\frac{q'''L}{2h}$$\n\n**3. Evaluation of Exact Nodal Temperatures**\nFirst, we substitute the given parameter values into the analytical solution:\n$$T(x) = 300 + \\frac{2.0\\times 10^{7}}{2(100)}((5\\times 10^{-3})x - x^2) + \\frac{(2.0\\times 10^{7})(5\\times 10^{-3})}{2(500)}$$\n$$T(x) = 300 + 10^5((5\\times 10^{-3})x - x^2) + \\frac{10^5}{1000}$$\n$$T(x) = 300 + 500x - 10^5 x^2 + 100$$\n$$T(x) = 400 + 500x - 10^5 x^2$$\nThe mesh has $N=5$ intervals, so the step size is $\\Delta x = L/5 = (5\\times 10^{-3}\\,\\mathrm{m})/5 = 1\\times 10^{-3}\\,\\mathrm{m}$. The nodes are at $x_i = i \\cdot \\Delta x$ for $i=0, \\dots, 5$.\n\n$T(x_0 = 0) = 400 + 500(0) - 10^5(0)^2 = 400.0\\,\\mathrm{K}$\n$T(x_1 = 10^{-3}) = 400 + 500(10^{-3}) - 10^5(10^{-3})^2 = 400 + 0.5 - 0.1 = 400.4\\,\\mathrm{K}$\n$T(x_2 = 2\\times 10^{-3}) = 400 + 500(2\\times 10^{-3}) - 10^5(2\\times 10^{-3})^2 = 400 + 1.0 - 0.4 = 400.6\\,\\mathrm{K}$\n$T(x_3 = 3\\times 10^{-3}) = 400 + 500(3\\times 10^{-3}) - 10^5(3\\times 10^{-3})^2 = 400 + 1.5 - 0.9 = 400.6\\,\\mathrm{K}$\n$T(x_4 = 4\\times 10^{-3}) = 400 + 500(4\\times 10^{-3}) - 10^5(4\\times 10^{-3})^2 = 400 + 2.0 - 1.6 = 400.4\\,\\mathrm{K}$\n$T(x_5 = 5\\times 10^{-3}) = 400 + 500(5\\times 10^{-3}) - 10^5(5\\times 10^{-3})^2 = 400 + 2.5 - 2.5 = 400.0\\,\\mathrm{K}$\n\n**4. Calculation of Nodal Errors**\nThe nodal errors are $e_i = T(x_i) - T_i^{\\mathrm{num}}$.\n$e_0 = 400.0 - 399.8 = 0.2$\n$e_1 = 400.4 - 400.3 = 0.1$\n$e_2 = 400.6 - 400.65 = -0.05$\n$e_3 = 400.6 - 400.55 = 0.05$\n$e_4 = 400.4 - 400.45 = -0.05$\n$e_5 = 400.0 - 399.9 = 0.1$\n\n**5. Computation of the Approximate Error Norm**\nThe approximate $\\|e\\|_{L^2,\\mathrm{RMS}}$ is computed using the composite trapezoidal rule:\n$$\\|e\\|_{L^2,\\mathrm{RMS}}^2 \\approx \\frac{1}{L}\\sum_{i=0}^{5} w_i e_i^2 = \\frac{1}{L}\\left[ \\frac{\\Delta x}{2}(e_0^2 + e_5^2) + \\Delta x(e_1^2 + e_2^2 + e_3^2 + e_4^2) \\right]$$\nWe have $L=5\\times 10^{-3}\\,\\mathrm{m}$ and $\\Delta x=1\\times 10^{-3}\\,\\mathrm{m}$.\nThe sum of weighted squared errors is:\n$\\sum w_i e_i^2 = \\frac{10^{-3}}{2}(0.2^2 + 0.1^2) + 10^{-3}(0.1^2 + (-0.05)^2 + 0.05^2 + (-0.05)^2)$\n$\\sum w_i e_i^2 = 0.5 \\times 10^{-3}(0.04 + 0.01) + 10^{-3}(0.01 + 0.0025 + 0.0025 + 0.0025)$\n$\\sum w_i e_i^2 = 0.5 \\times 10^{-3}(0.05) + 10^{-3}(0.01 + 0.0075)$\n$\\sum w_i e_i^2 = 0.025 \\times 10^{-3} + 10^{-3}(0.0175)$\n$\\sum w_i e_i^2 = (0.025 + 0.0175) \\times 10^{-3} = 0.0425 \\times 10^{-3}\\,\\mathrm{K}^2\\mathrm{m}$\n\nNow, we compute the squared norm:\n$$\\|e\\|_{L^2,\\mathrm{RMS}}^2 \\approx \\frac{1}{5\\times 10^{-3}\\,\\mathrm{m}} (0.0425 \\times 10^{-3}\\,\\mathrm{K}^2\\mathrm{m}) = \\frac{0.0425}{5}\\,\\mathrm{K}^2 = 0.0085\\,\\mathrm{K}^2$$\nFinally, we take the square root to find the norm:\n$$\\|e\\|_{L^2,\\mathrm{RMS}} \\approx \\sqrt{0.0085}\\,\\mathrm{K} \\approx 0.09219544\\,\\mathrm{K}$$\nRounding to four significant figures, the result is $0.09220\\,\\mathrm{K}$.",
            "answer": "$$\n\\boxed{0.09220}\n$$"
        },
        {
            "introduction": "The previous practices highlight a fundamental challenge in numerical modeling: achieving high accuracy often requires fine grids, which can be computationally prohibitive, especially for problems with localized features or moving fronts. This final practice introduces a powerful solution: adaptive mesh refinement (AMR), where the grid dynamically adapts to the solution's behavior. You will implement an algorithm that uses a gradient-based error indicator to automatically refine the mesh near a moving interface and coarsen it in quiescent regions, optimizing computational resources . This exercise provides direct experience with the logic and implementation of the sophisticated h-adaptive strategies that enable modern, efficient simulations.",
            "id": "4126493",
            "problem": "You are modeling a one-dimensional through-thickness cross-section of a semiconductor thin film growing on a substrate during chemical vapor deposition. The spatial domain is the closed interval $\\left[0, L\\right]$ with coordinate $y \\in \\left[0, L\\right]$, where $y = 0$ is the substrate and $y = L$ is the gas boundary. The film surface is represented by a scalar height $s(t)$ measured from the substrate into the gas. During deposition, the surface advances according to a kinematic law of the form $\\dfrac{ds}{dt} = v\\!\\left(s, t\\right)$, where $v$ is the normal growth velocity. To focus solely on adaptive mesh refinement, adopt a proxy scalar field $c(y; s)$ that mimics a steep interfacial layer at the film surface:\n$$\nc(y; s) = \\exp\\!\\left(-\\left(\\dfrac{y - s}{w}\\right)^2\\right),\n$$\nwhere $w > 0$ is a user-specified interfacial width parameter. Use the forward Euler time discretization for the kinematics with a constant deposition coefficient $v_0 > 0$:\n$$\ns^{n+1} = \\min\\!\\left(L,\\, s^n + v_0\\, c\\!\\left(s^n; s^n\\right)\\, \\Delta t\\right),\n$$\nand initialize with $s^0 = s_0$. Because $c\\!\\left(s; s\\right) = 1$, the above reduces to $s^{n+1} = \\min\\!\\left(L,\\, s^n + v_0\\, \\Delta t\\right)$. This proxy advances the interface at a constant rate and is intended only to provide a moving target for refinement; the final output is dimensionless, so no physical unit conversion is required.\n\nDiscretize the domain with a one-dimensional, conforming, piecewise-linear Finite Element (FE) mesh defined by nodes $\\{ y_i \\}_{i=0}^{N}$ with $0 = y_0 < y_1 < \\cdots < y_N = L$. For each element $K_i = \\left[y_i, y_{i+1}\\right]$, define an element-wise gradient indicator based on the FE constant gradient in $K_i$:\n$$\n\\eta_i = \\left| \\dfrac{c\\!\\left(y_{i+1}; s\\right) - c\\!\\left(y_i; s\\right)}{y_{i+1} - y_i} \\right|.\n$$\nThis indicator is equivalent in one dimension to a centered Finite Difference (FD) slope on each element and targets high gradients of $c$ occurring near $y \\approx s$.\n\nConstruct an adaptive refinement and coarsening scheme to evolve the mesh after each time step:\n\n- Refinement rule: Let $\\eta_{\\max} = \\max_i \\eta_i$. For a user-specified threshold $\\theta_{\\mathrm{ref}} \\in \\left(0, 1\\right)$ and minimum element size $h_{\\min} > 0$, bisect any element $K_i$ with $\\eta_i > \\theta_{\\mathrm{ref}}\\, \\eta_{\\max}$ provided $\\left|K_i\\right| > h_{\\min}$, where $\\left|K_i\\right| = y_{i+1} - y_i$.\n\n- Coarsening rule: For a user-specified threshold $\\theta_{\\mathrm{coarse}} \\in \\left(0, 1\\right)$ and maximum element size $h_{\\max} > 0$, attempt to merge two adjacent elements $K_i$ and $K_{i+1}$ into a single element $K^\\star$ if both satisfy $\\eta_i < \\theta_{\\mathrm{coarse}}\\, \\eta_{\\max}$ and $\\eta_{i+1} < \\theta_{\\mathrm{coarse}}\\, \\eta_{\\max}$, and if $\\left|K^\\star\\right| = \\left|K_i\\right| + \\left|K_{i+1}\\right| \\le h_{\\max}$. Do not violate conformity or boundary alignment; merging removes the shared node between $K_i$ and $K_{i+1}$.\n\n- Apply refinement first, then recompute indicators on the refined mesh, then apply coarsening.\n\nInitialize the mesh as uniform with nodal spacing $h_0 > 0$, i.e., $y_i = i\\, h_0$ for $i = 0, 1, \\dots, \\lfloor L/h_0 \\rfloor$ and $y_N = L$. At each time step, update $s^n \\mapsto s^{n+1}$, evaluate $c(y; s^{n+1})$ at current mesh nodes, compute $\\eta_i$, and adapt the mesh as above.\n\nAssessment metric. After $N_{\\mathrm{steps}}$ time steps, compute the final near-surface mean element size and the bulk mean element size as follows. Let element centers be $m_i = \\dfrac{y_i + y_{i+1}}{2}$. Define a near-surface window half-width $\\delta = \\kappa\\, w$ with $\\kappa > 0$. The near-surface set is all elements with $\\left| m_i - s^{N_{\\mathrm{steps}}} \\right| \\le \\delta$. The bulk set is all elements with $\\left| m_i - s^{N_{\\mathrm{steps}}} \\right| \\ge 3\\, \\delta$. Let $\\overline{h}_{\\mathrm{near}}$ be the mean $\\left|K_i\\right|$ over the near-surface set and $\\overline{h}_{\\mathrm{bulk}}$ be the mean $\\left|K_i\\right|$ over the bulk set. If either set is empty, define its mean to be the global mean element size $\\overline{h}_{\\mathrm{global}} = \\dfrac{1}{N}\\sum_{i=0}^{N-1} \\left|K_i\\right|$. The final scalar outcome for each test case is the dimensionless ratio\n$$\nR = \\dfrac{\\overline{h}_{\\mathrm{bulk}}}{\\overline{h}_{\\mathrm{near}}}.\n$$\n\nImplement the above algorithm exactly and produce the results for the following test suite. In all cases, use forward Euler time stepping, refinement followed by coarsening at each time step, and the given parameters. All real numbers below are in a consistent nondimensionalization, and the requested output is dimensionless.\n\nTest suite:\n- Case A (baseline deposition, sharp interface): $L = 1.0$, $s_0 = 0.2$, $v_0 = 0.2$, $w = 0.05$, $h_0 = 0.02$, $h_{\\min} = 0.001$, $h_{\\max} = 0.1$, $\\theta_{\\mathrm{ref}} = 0.4$, $\\theta_{\\mathrm{coarse}} = 0.1$, $\\Delta t = 0.01$, $N_{\\mathrm{steps}} = 50$, $\\kappa = 2.0$.\n- Case B (no deposition, sharp interface): $L = 1.0$, $s_0 = 0.2$, $v_0 = 0.0$, $w = 0.05$, $h_0 = 0.02$, $h_{\\min} = 0.001$, $h_{\\max} = 0.1$, $\\theta_{\\mathrm{ref}} = 0.4$, $\\theta_{\\mathrm{coarse}} = 0.1$, $\\Delta t = 0.01$, $N_{\\mathrm{steps}} = 50$, $\\kappa = 2.0$.\n- Case C (baseline deposition, gentle interface): $L = 1.0$, $s_0 = 0.2$, $v_0 = 0.05$, $w = 0.3$, $h_0 = 0.02$, $h_{\\min} = 0.001$, $h_{\\max} = 0.1$, $\\theta_{\\mathrm{ref}} = 0.4$, $\\theta_{\\mathrm{coarse}} = 0.1$, $\\Delta t = 0.01$, $N_{\\mathrm{steps}} = 50$, $\\kappa = 2.0$.\n- Case D (baseline deposition, conservative thresholds): $L = 1.0$, $s_0 = 0.2$, $v_0 = 0.2$, $w = 0.05$, $h_0 = 0.02$, $h_{\\min} = 0.001$, $h_{\\max} = 0.1$, $\\theta_{\\mathrm{ref}} = 0.9$, $\\theta_{\\mathrm{coarse}} = 0.8$, $\\Delta t = 0.01$, $N_{\\mathrm{steps}} = 50$, $\\kappa = 2.0$.\n\nYour program must produce a single line of output containing the four values of $R$ for Cases A–D, in this order, as a comma-separated list enclosed in square brackets, with each value rounded to six digits after the decimal point. For example, the output format must be like $\\left[\\text{result\\_A},\\text{result\\_B},\\text{result\\_C},\\text{result\\_D}\\right]$. The final output is dimensionless, so no physical unit is required, and angles are not involved. The only acceptable data types in the list are floating-point numbers.",
            "solution": "The user has provided a well-defined computational problem to simulate an adaptive meshing algorithm for a moving interface. The problem is valid as it is scientifically grounded in numerical analysis principles, self-contained, and algorithmically specified. I will now construct a solution by first outlining the methodology and then providing a complete implementation.\n\nThe core of the problem is to implement a time-dependent simulation that involves two main components at each time step: updating the position of a moving interface and adapting a one-dimensional finite element mesh to resolve the features around this interface.\n\n**1. System State and Initialization**\n\nThe state of the system at any time step $n$ is defined by the surface height $s^n$ and the nodal positions $\\{y_i^n\\}_{i=0}^{N_n}$ of the computational mesh.\n\n-   **Surface Position**: The simulation begins with an initial surface height $s^0 = s_0$.\n-   **Computational Mesh**: The domain $[0, L]$ is initially discretized into a uniform mesh with nodal spacing $h_0$. The nodal coordinates are given by $y_i^0 = i \\cdot h_0$ for $i = 0, 1, \\dots, N_0-1$, where $N_0 = \\lfloor L/h_0 \\rfloor$, and the final node is at $y_{N_0}^0=L$. For the given test cases, $L/h_0$ is an integer, so the initial mesh is perfectly uniform with $N_0 = L/h_0$ elements of size $h_0$. The nodes are located at $y_i^0 = i \\cdot (L/N_0)$.\n\n**2. Time Evolution**\n\nThe simulation proceeds for a total of $N_{\\mathrm{steps}}$ time steps. Within each time step, from $t^n$ to $t^{n+1} = t^n + \\Delta t$, the following sequence of operations is performed.\n\n-   **Update Surface Position**: The surface height $s$ is advanced using a forward Euler scheme. The problem specifies the simplified update rule:\n    $$\n    s^{n+1} = \\min(L, s^n + v_0 \\Delta t)\n    $$\n    This models a constant velocity interface progression, capped at the domain boundary $y=L$.\n\n-   **Adaptive Meshing**: After updating the surface to $s^{n+1}$, the mesh $\\{y_i^n\\}$ is adapted to create a new mesh $\\{y_i^{n+1}\\}$ that better resolves the proxy field $c(y; s^{n+1})$ near the new surface position. The proxy field is a Gaussian pulse centered at $y=s^{n+1}$:\n    $$\n    c(y; s^{n+1}) = \\exp\\left(-\\left(\\frac{y - s^{n+1}}{w}\\right)^2\\right)\n    $$\n    The adaptation process consists of two stages: refinement followed by coarsening.\n\n    -   **a. Refinement**:\n        1.  First, an error indicator $\\eta_i$ is computed for each element $K_i = [y_i^n, y_{i+1}^n]$ in the current mesh. This indicator approximates the magnitude of the gradient of $c(y; s^{n+1})$ within the element:\n            $$\n            \\eta_i = \\left| \\frac{c(y_{i+1}^n; s^{n+1}) - c(y_i^n; s^{n+1})}{y_{i+1}^n - y_i^n} \\right|\n            $$\n        2.  The maximum indicator value $\\eta_{\\max} = \\max_i \\eta_i$ is found.\n        3.  An element $K_i$ is flagged for refinement if its indicator $\\eta_i$ is greater than a fraction of the maximum, i.e., $\\eta_i > \\theta_{\\mathrm{ref}} \\eta_{\\max}$, and if its size $|K_i| = y_{i+1}^n - y_i^n$ is larger than a minimum allowed size, $|K_i| > h_{\\min}$.\n        4.  Each flagged element is bisected by inserting a new node at its midpoint. This process generates an intermediate, refined mesh.\n\n    -   **b. Coarsening**:\n        1.  On the newly refined mesh, the element indicators $\\eta_i$ are recomputed.\n        2.  The new maximum indicator $\\eta_{\\max}$ is determined.\n        3.  The algorithm then attempts to merge adjacent elements. A pair of adjacent elements, $K_i$ and $K_{i+1}$, are merged into a single larger element if both elements have small indicators ($\\eta_i < \\theta_{\\mathrm{coarse}} \\eta_{\\max}$ and $\\eta_{i+1} < \\theta_{\\mathrm{coarse}} \\eta_{\\max}$) and their combined size does not exceed the maximum allowed element size, $|K_i| + |K_{i+1}| \\le h_{\\max}$.\n        4.  Merging is accomplished by removing the node shared between the two elements. To ensure a deterministic and robust procedure, a single pass is made over the elements to identify mergeable pairs. If a pair $(K_i, K_{i+1})$ is merged, the algorithm continues its search from the element following the newly formed block to avoid overlapping merge operations. This yields the final mesh $\\{y_i^{n+1}\\}$ for the next time step.\n\n**3. Final Assessment**\n\nAfter completing all $N_{\\mathrm{steps}}$, the final mesh is analyzed to compute the assessment metric $R$.\n\n-   **Element Classification**: The final surface position is $s^{\\mathrm{final}} = s^{N_{\\mathrm{steps}}}$. A near-surface region is defined by the interval $[s^{\\mathrm{final}} - \\delta, s^{\\mathrm{final}} + \\delta]$, where $\\delta = \\kappa w$. A bulk region is defined as the area outside a wider interval, specifically where $|y - s^{\\mathrm{final}}| \\ge 3 \\delta$. Each element in the final mesh is classified based on the position of its center, $m_i = (y_i + y_{i+1})/2$.\n    -   An element is in the \"near-surface\" set if $|m_i - s^{\\mathrm{final}}| \\le \\delta$.\n    -   An element is in the \"bulk\" set if $|m_i - s^{\\mathrm{final}}| \\ge 3 \\delta$.\n\n-   **Metric Calculation**:\n    1.  The average element size is computed for both the near-surface set ($\\overline{h}_{\\mathrm{near}}$) and the bulk set ($\\overline{h}_{\\mathrm{bulk}}$).\n    2.  If either set is empty, its average size is defined to be the global average element size, $\\overline{h}_{\\mathrm{global}}$.\n    3.  The final metric is the ratio of these average sizes:\n        $$\n        R = \\frac{\\overline{h}_{\\mathrm{bulk}}}{\\overline{h}_{\\mathrm{near}}}\n        $$\nThis ratio quantifies the effectiveness of the adaptive meshing: a high value of $R$ indicates that the mesh has been successfully refined near the interface (small $\\overline{h}_{\\mathrm{near}}$) and coarsened away from it (large $\\overline{h}_{\\mathrm{bulk}}$).\n\nThe implementation will execute this entire procedure for each of the four test cases provided, producing a value of $R$ for each.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_case(L, s0, v0, w, h0, h_min, h_max, theta_ref, theta_coarse, dt, N_steps, kappa):\n    \"\"\"\n    Executes one full simulation case for the adaptive meshing problem.\n    \"\"\"\n\n    def c_field(y, s_val, w_val):\n        \"\"\"Computes the proxy scalar field c(y; s).\"\"\"\n        return np.exp(-((y - s_val) / w_val)**2)\n\n    def compute_indicators(nodes, s_val, w_val):\n        \"\"\"Computes the gradient indicators eta_i for each element.\"\"\"\n        if len(nodes) < 2:\n            return np.array([])\n        \n        y_vals = np.array(nodes)\n        c_vals = c_field(y_vals, s_val, w_val)\n        \n        # Element-wise gradient indicators\n        # Denominator can't be zero since h_min > 0 and nodes are sorted.\n        dy = y_vals[1:] - y_vals[:-1]\n        dc = c_vals[1:] - c_vals[:-1]\n        \n        # Check for dy being close to zero to avoid division issues, although problem constraints should prevent this.\n        # h_min > 0 so dy should always be > h_min after first step.\n        etas = np.abs(dc / dy)\n        return etas\n\n    # 1. Initialization\n    s = s0\n    # Initial mesh generation as per problem statement\n    # For L=1.0, h0=0.02, L/h0 is integer, so linspace is perfect.\n    num_points = int(round(L / h0)) + 1\n    nodes = list(np.linspace(0, L, num_points))\n\n    # 2. Time Evolution\n    for _ in range(N_steps):\n        # Update surface position\n        s = min(L, s + v0 * dt)\n        \n        # --- Refinement Pass ---\n        etas = compute_indicators(nodes, s, w)\n        if etas.size > 0:\n            eta_max = np.max(etas)\n            if eta_max > 0: # Avoid refinement if field is flat\n                ref_threshold_val = theta_ref * eta_max\n                # Iterate backwards over elements to safely insert into the list\n                for i in range(len(nodes) - 2, -1, -1):\n                    element_size = nodes[i+1] - nodes[i]\n                    if etas[i] > ref_threshold_val and element_size > h_min:\n                        new_node = (nodes[i] + nodes[i+1]) / 2.0\n                        nodes.insert(i + 1, new_node)\n\n        # --- Coarsening Pass ---\n        # Recompute indicators on the refined mesh\n        etas_refined = compute_indicators(nodes, s, w)\n        if etas_refined.size > 0:\n            eta_max_refined = np.max(etas_refined)\n            if eta_max_refined > 0:\n                coarse_threshold_val = theta_coarse * eta_max_refined\n                \n                nodes_to_keep = [True] * len(nodes)\n                i = 0  # Element index\n                num_elements = len(nodes) - 1\n                while i < num_elements - 1:\n                    # Attempt to merge elements K_i and K_{i+1} by removing node i+1\n                    # This requires checking element i+1, so we need i+2 to be a valid node index\n                    \n                    mergeable = etas_refined[i] < coarse_threshold_val and etas_refined[i+1] < coarse_threshold_val\n                    if mergeable:\n                        merged_size = nodes[i+2] - nodes[i]\n                        if merged_size <= h_max:\n                            # Mark node i+1 for removal.\n                            nodes_to_keep[i+1] = False\n                            # Skip element i+1 as it is now part of the merged block\n                            i += 2\n                        else:\n                            i += 1\n                    else:\n                        i += 1\n                \n                nodes = [node for j, node in enumerate(nodes) if nodes_to_keep[j]]\n\n    # 3. Final Assessment\n    s_final = s\n    delta = kappa * w\n    \n    node_arr = np.array(nodes)\n    element_sizes = node_arr[1:] - node_arr[:-1]\n    element_centers = (node_arr[1:] + node_arr[:-1]) / 2.0\n    \n    dist_from_surface = np.abs(element_centers - s_final)\n    \n    near_surface_mask = dist_from_surface <= delta\n    bulk_mask = dist_from_surface >= 3 * delta\n    \n    near_surface_sizes = element_sizes[near_surface_mask]\n    bulk_sizes = element_sizes[bulk_mask]\n    \n    h_global_mean = np.mean(element_sizes) if element_sizes.size > 0 else 0.0\n\n    h_near_mean = np.mean(near_surface_sizes) if near_surface_sizes.size > 0 else h_global_mean\n    h_bulk_mean = np.mean(bulk_sizes) if bulk_sizes.size > 0 else h_global_mean\n    \n    if h_near_mean == 0:\n        # This can happen if all elements are coarsened into one, etc.\n        # Fallback to avoid division by zero. A ratio of 1.0 is neutral.\n        return 1.0\n\n    R = h_bulk_mean / h_near_mean\n    return R\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (baseline deposition, sharp interface)\n        dict(L=1.0, s0=0.2, v0=0.2, w=0.05, h0=0.02, h_min=0.001, h_max=0.1, theta_ref=0.4, theta_coarse=0.1, dt=0.01, N_steps=50, kappa=2.0),\n        # Case B (no deposition, sharp interface)\n        dict(L=1.0, s0=0.2, v0=0.0, w=0.05, h0=0.02, h_min=0.001, h_max=0.1, theta_ref=0.4, theta_coarse=0.1, dt=0.01, N_steps=50, kappa=2.0),\n        # Case C (baseline deposition, gentle interface)\n        dict(L=1.0, s0=0.2, v0=0.05, w=0.3, h0=0.02, h_min=0.001, h_max=0.1, theta_ref=0.4, theta_coarse=0.1, dt=0.01, N_steps=50, kappa=2.0),\n        # Case D (baseline deposition, conservative thresholds)\n        dict(L=1.0, s0=0.2, v0=0.2, w=0.05, h0=0.02, h_min=0.001, h_max=0.1, theta_ref=0.9, theta_coarse=0.8, dt=0.01, N_steps=50, kappa=2.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(**case)\n        results.append(f\"{result:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}