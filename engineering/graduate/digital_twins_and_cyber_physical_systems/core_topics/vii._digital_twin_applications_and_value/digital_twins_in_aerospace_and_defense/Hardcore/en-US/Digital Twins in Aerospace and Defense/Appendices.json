{
    "hands_on_practices": [
        {
            "introduction": "This practice tackles one of the most critical predictive tasks in aerospace engineering: determining the flutter speed of a lifting surface. You will construct an aeroelastic digital twin from first principles, coupling structural dynamics with aerodynamic forces to form a state-space model. This exercise  demonstrates how digital twins can be used in the design and certification phase to predict complex, emergent behaviors and assess model credibility by comparing predictions against flight test data.",
            "id": "4216584",
            "problem": "Aerospace and defense digital twins for aeroelasticity seek to credibly predict flutter speed by coupling a structural model with an aerodynamic model and analyzing stability through an eigenvalue problem. Consider a two-degree-of-freedom typical section representing plunge and pitch of a lifting surface per unit span. Let the generalized coordinates be $q(t) = [h(t), \\alpha(t)]^\\top$, where $h$ is plunge in $\\mathrm{m}$ and $\\alpha$ is pitch in $\\mathrm{rad}$. The coupled linearized equations of motion can be written as\n$$\n\\mathbf{M} \\ddot{q}(t) + \\left(\\mathbf{C}_0 + q(U)\\,\\mathbf{C}_1\\right)\\dot{q}(t) + \\left(\\mathbf{K}_0 + q(U)\\,\\mathbf{K}_1\\right) q(t) = \\mathbf{0},\n$$\nwhere $\\mathbf{M} \\in \\mathbb{R}^{2\\times 2}$ is the symmetric positive definite structural mass matrix, $\\mathbf{C}_0 \\in \\mathbb{R}^{2\\times 2}$ is the structural damping matrix, $\\mathbf{K}_0 \\in \\mathbb{R}^{2\\times 2}$ is the structural stiffness matrix, and $\\mathbf{C}_1, \\mathbf{K}_1 \\in \\mathbb{R}^{2\\times 2}$ are aerodynamic influence matrices that scale linearly with the dynamic pressure $q(U)$. The dynamic pressure is given by the well-tested formula\n$$\nq(U) = \\tfrac{1}{2}\\,\\rho\\,U^2,\n$$\nwhere $\\rho$ is the air density in $\\mathrm{kg/m^3}$ and $U$ is the airspeed in $\\mathrm{m/s}$.\n\nDefine the first-order state vector $x(t) = [q(t)^\\top, \\dot{q}(t)^\\top]^\\top \\in \\mathbb{R}^{4}$, and construct the state matrix $\\mathbf{A}(U) \\in \\mathbb{R}^{4\\times 4}$ by\n$$\n\\mathbf{A}(U) = \n\\begin{bmatrix}\n\\mathbf{0}_{2\\times 2}  \\mathbf{I}_{2\\times 2} \\\\\n-\\mathbf{M}^{-1}\\left(\\mathbf{K}_0 + q(U)\\,\\mathbf{K}_1\\right)  -\\mathbf{M}^{-1}\\left(\\mathbf{C}_0 + q(U)\\,\\mathbf{C}_1\\right)\n\\end{bmatrix}.\n$$\nFor a given $U$, the eigenvalues $\\{\\lambda_i(U)\\}_{i=1}^4$ of $\\mathbf{A}(U)$ characterize the stability. Let\n$$\n\\sigma(U) = \\max_{\\{i:\\ \\mathrm{Im}(\\lambda_i(U)) \\neq 0\\}} \\mathrm{Re}\\left(\\lambda_i(U)\\right)\n$$\nbe the maximum real part among the oscillatory (nonzero imaginary part) eigenvalues. Define the flutter speed $U_f$ on an interval $[U_{\\min}, U_{\\max}]$ as the smallest $U$ in this interval for which $\\sigma(U)$ crosses zero from negative to nonnegative, that is, the least $U$ such that $\\sigma(U) = 0$ with $\\sigma(U^-)0$ and $\\sigma(U^+)\\ge 0$ and $\\mathrm{Im}(\\lambda_i(U)) \\neq 0$ for the controlling pair. If no such $U$ exists in the interval, report $U_f = -1.0$.\n\nUsing this principle-based definition, implement a numerical procedure that:\n- For each test case, constructs $\\mathbf{A}(U)$, computes $\\sigma(U)$, finds a bracket for the root of $\\sigma(U)$ on the specified interval by scanning $U$, and refines the flutter speed $U_f$ via bisection until the absolute bracket width is less than $10^{-3}\\ \\mathrm{m/s}$.\n- Compares the computed $U_f$ against flight test data to assess model credibility of the digital twin.\n\nCredibility assessment rule per test case:\n- If the flight test provides a measured flutter speed $U_{\\text{meas}}$ (flag $f=1$), declare the model credible if $U_f \\neq -1.0$ and $|U_f - U_{\\text{meas}}| \\le \\Delta_U$, where $\\Delta_U$ is a tolerance in $\\mathrm{m/s}$.\n- If the flight test indicates no flutter up to $U_{\\text{env}}$ (flag $f=0$), declare the model credible if $U_f = -1.0$ or $U_f  U_{\\text{env}}$.\n\nScientific base and units:\n- Use $q(U) = \\tfrac{1}{2}\\rho U^2$ with $\\rho = 1.225\\ \\mathrm{kg/m^3}$.\n- All speeds must be expressed in $\\mathrm{m/s}$.\n- Angles are in $\\mathrm{rad}$.\n- The returned flutter speeds must be rounded to three decimal places, and if no flutter is detected within the search interval, return $-1.0$.\n\nTest suite. For all cases, $q(U)$ scales the aerodynamic matrices linearly as shown above. Use the following structural and aerodynamic parameters and flight test metadata:\n\nBase structural and aerodynamic matrices (common to all cases):\n- $\\mathbf{M} = \\begin{bmatrix} 70.0  12.0 \\\\ 12.0  900.0 \\end{bmatrix}$.\n- $\\mathbf{K}_0 = \\begin{bmatrix} 1.6\\times 10^{6}  0.0 \\\\ 0.0  1.2\\times 10^{5} \\end{bmatrix}$.\n- $\\mathbf{C}_0 = \\beta\\,\\mathbf{M} + \\alpha\\,\\mathbf{K}_0$ with $\\beta = 20.0$ and $\\alpha = 2.0\\times 10^{-3}$.\n- Aerodynamic bases $\\mathbf{K}_1^{\\text{base}} = \\begin{bmatrix} -150.0  -800.0 \\\\ -800.0  -16000.0 \\end{bmatrix}$, $\\mathbf{C}_1^{\\text{base}} = \\begin{bmatrix} 200.0  1200.0 \\\\ 1200.0  30000.0 \\end{bmatrix}$.\n- For each case, set $\\mathbf{K}_1 = s\\cdot \\mathbf{K}_1^{\\text{base}}$ and $\\mathbf{C}_1 = s\\cdot \\mathbf{C}_1^{\\text{base}}$ with scale $s$ specified per case.\n\nCases:\n1. Case A (nominal flexibility):\n   - Scale $s = 1.0$.\n   - Search interval $[U_{\\min}, U_{\\max}] = [40.0, 220.0]\\ \\mathrm{m/s}$.\n   - Flight test flag $f=1$, measured flutter speed $U_{\\text{meas}} = 165.0\\ \\mathrm{m/s}$.\n   - Credibility tolerance $\\Delta_U = 15.0\\ \\mathrm{m/s}$.\n\n2. Case B (stiffened wing, extended envelope):\n   - Scale $s = 0.1$.\n   - Search interval $[U_{\\min}, U_{\\max}] = [40.0, 220.0]\\ \\mathrm{m/s}$.\n   - Flight test flag $f=0$, no flutter up to $U_{\\text{env}} = 220.0\\ \\mathrm{m/s}$.\n   - Credibility tolerance $\\Delta_U$ unused for this case.\n\n3. Case C (soft wing, low-speed susceptibility):\n   - Scale $s = 2.0$.\n   - Search interval $[U_{\\min}, U_{\\max}] = [20.0, 120.0]\\ \\mathrm{m/s}$.\n   - Flight test flag $f=1$, measured flutter speed $U_{\\text{meas}} = 60.0\\ \\mathrm{m/s}$.\n   - Credibility tolerance $\\Delta_U = 15.0\\ \\mathrm{m/s}$.\n\nAlgorithmic requirements:\n- Construct $\\mathbf{A}(U)$ exactly as defined.\n- Use a dense scan of $U$ across the interval to locate a sign change in $\\sigma(U)$, then apply bisection on the bracket to solve $\\sigma(U)=0$ to the specified tolerance.\n- When computing $\\sigma(U)$, only consider eigenvalues with nonzero imaginary parts; if at a given $U$ all eigenvalues have zero imaginary parts, treat $\\sigma(U)$ as $-\\infty$ for bracketing purposes.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets: $[U_f^{A}, \\text{cred}^{A}, U_f^{B}, \\text{cred}^{B}, U_f^{C}, \\text{cred}^{C}]$.\n- Each $U_f^{(\\cdot)}$ must be in $\\mathrm{m/s}$, rounded to three decimal places; report $-1.0$ if no flutter is found in the specified interval for that case.\n- Each $\\text{cred}^{(\\cdot)}$ must be a boolean as defined above.\n\nNo external input is permitted; all parameters are embedded as constants in the program.",
            "solution": "The problem presented is a well-posed and scientifically grounded exercise in computational aeroelasticity, a core discipline within aerospace engineering. It requires the determination of the flutter speed for a two-degree-of-freedom typical section model and the subsequent credibility assessment of this digital twin prediction against supplied flight-test data. The problem is valid as it is self-contained, logically consistent, and based on established principles of structural dynamics and aerodynamics.\n\nThe solution methodology proceeds in four principal stages: system modeling, stability analysis, numerical root-finding, and credibility assessment.\n\nFirst, the system's governing equations are formulated in state-space form. The provided second-order linear ordinary differential equation is:\n$$\n\\mathbf{M} \\ddot{q}(t) + \\left(\\mathbf{C}_0 + q(U)\\,\\mathbf{C}_1\\right)\\dot{q}(t) + \\left(\\mathbf{K}_0 + q(U)\\,\\mathbf{K}_1\\right) q(t) = \\mathbf{0}\n$$\nwhere $q(t) = [h(t), \\alpha(t)]^\\top$ represents the plunge and pitch degrees of freedom. This is transformed into a first-order system $\\dot{x}(t) = \\mathbf{A}(U) x(t)$ by defining the state vector $x(t) = [q(t)^\\top, \\dot{q}(t)^\\top]^\\top$. This leads to the state matrix $\\mathbf{A}(U)$ given by:\n$$\n\\mathbf{A}(U) = \n\\begin{bmatrix}\n\\mathbf{0}_{2\\times 2}  \\mathbf{I}_{2\\times 2} \\\\\n-\\mathbf{M}^{-1}\\left(\\mathbf{K}_0 + q(U)\\,\\mathbf{K}_1\\right)  -\\mathbf{M}^{-1}\\left(\\mathbf{C}_0 + q(U)\\,\\mathbf{C}_1\\right)\n\\end{bmatrix}\n$$\nThe matrices $\\mathbf{K}_0$, $\\mathbf{C}_0$, and $\\mathbf{M}$ are constant structural properties. The aerodynamic matrices $\\mathbf{K}_1$ and $\\mathbf{C}_1$ are scaled by the dynamic pressure $q(U) = \\frac{1}{2}\\rho U^2$, where $\\rho = 1.225\\ \\mathrm{kg/m^3}$ and $U$ is the airspeed.\n\nThe constant matrices are constructed first. The structural mass matrix $\\mathbf{M}$ and stiffness matrix $\\mathbf{K}_0$ are given. The structural damping matrix $\\mathbf{C}_0$ is defined as a Rayleigh damping model: $\\mathbf{C}_0 = \\beta\\mathbf{M} + \\alpha\\mathbf{K}_0$, with specified constants $\\beta = 20.0$ and $\\alpha = 2.0\\times 10^{-3}$. The inverse of the mass matrix, $\\mathbf{M}^{-1}$, is computed once and stored, as it is constant for all speeds and cases.\n\nFor each test case, the aerodynamic matrices $\\mathbf{K}_1 = s \\cdot \\mathbf{K}_1^{\\text{base}}$ and $\\mathbf{C}_1 = s \\cdot \\mathbf{C}_1^{\\text{base}}$ are determined using the case-specific scale factor $s$.\n\nSecond, the stability of the system is assessed by analyzing the eigenvalues $\\{\\lambda_i(U)\\}_{i=1}^4$ of the state matrix $\\mathbf{A}(U)$. Flutter, a dynamic instability, occurs when an oscillatory mode becomes undamped. The stability metric $\\sigma(U)$ is defined as the maximum real part of all eigenvalues that have a non-zero imaginary part:\n$$\n\\sigma(U) = \\max_{\\{i:\\ \\mathrm{Im}(\\lambda_i(U)) \\neq 0\\}} \\mathrm{Re}\\left(\\lambda_i(U)\\right)\n$$\nThe system is stable if $\\sigma(U)  0$, marginally stable at the flutter boundary if $\\sigma(U) = 0$, and unstable if $\\sigma(U)  0$. If, at a given airspeed $U$, all eigenvalues are purely real (non-oscillatory divergence), we consider $\\sigma(U) = -\\infty$ for bracketing purposes, as these modes are not associated with flutter.\n\nThird, the flutter speed $U_f$ is found numerically. $U_f$ is defined as the smallest airspeed $U$ in the specified search interval $[U_{\\min}, U_{\\max}]$ where $\\sigma(U)$ crosses from negative to non-negative. This corresponds to finding the smallest root of the equation $\\sigma(U) = 0$. The numerical procedure is a two-step process:\n1.  **Bracketing**: The interval $[U_{\\min}, U_{\\max}]$ is scanned with a fine mesh of discrete airspeeds, $U_j$. For each $U_j$, the function $\\sigma(U_j)$ is evaluated. The first pair of consecutive points $(U_j, U_{j+1})$ for which $\\sigma(U_j)  0$ and $\\sigma(U_{j+1}) \\ge 0$ forms a bracket $[U_j, U_{j+1}]$ that contains the root $U_f$. If no such sign change is identified across the entire interval, we conclude that no flutter occurs, and $U_f$ is set to $-1.0$. A scan resolution of $200$ points is selected to ensure a robust bracket is found.\n2.  **Refinement**: Once a bracket $[a, b]$ is located, the bisection method is employed to refine the root. This iterative algorithm repeatedly halves the interval while ensuring the root remains bracketed. The process continues until the interval width $|b - a|$ is less than the required tolerance of $10^{-3}\\ \\mathrm{m/s}$. The flutter speed $U_f$ is then taken as the midpoint of the final, refined interval.\n\nFourth, for each case, the computed flutter speed $U_f$ is used to assess the credibility of the digital twin model against the provided flight test data. The rules are applied as follows:\n-   If the test indicates flutter at a measured speed $U_{\\text{meas}}$ (flag $f=1$), the model is credible if a flutter speed was found ($U_f \\neq -1.0$) and it is within a tolerance $\\Delta_U$ of the measured value, i.e., $|U_f - U_{\\text{meas}}| \\le \\Delta_U$.\n-   If the test indicates no flutter up to an explored airspeed $U_{\\text{env}}$ (flag $f=0$), the model is credible if it predicts no flutter in the interval ($U_f = -1.0$) or predicts flutter at a speed higher than the explored envelope ($U_f  U_{\\text{env}}$).\n\nThe final results, comprising the rounded flutter speed $U_f$ (or $-1.0$) and the boolean credibility assessment for each of the three test cases, are compiled into a single list as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the aeroelastic flutter problem for three test cases, assesses model\n    credibility, and prints the results in the specified format.\n    \"\"\"\n\n    # Scientific base constants and units\n    RHO = 1.225  # Air density in kg/m^3\n\n    # Base structural and aerodynamic matrices\n    M = np.array([[70.0, 12.0], [12.0, 900.0]])\n    K0 = np.array([[1.6e6, 0.0], [0.0, 1.2e5]])\n    \n    # Rayleigh damping parameters\n    BETA = 20.0\n    ALPHA = 2.0e-3\n    C0 = BETA * M + ALPHA * K0\n    \n    # Aerodynamic base matrices\n    K1_base = np.array([[-150.0, -800.0], [-800.0, -16000.0]])\n    C1_base = np.array([[200.0, 1200.0], [1200.0, 30000.0]])\n    \n    # Pre-compute constant matrix inverse and identity/zero blocks for efficiency\n    M_inv = np.linalg.inv(M)\n    I2 = np.identity(2)\n    Z2 = np.zeros((2, 2))\n    \n    # Numerical procedure constants\n    BISECTION_TOLERANCE = 1e-3\n    SCAN_POINTS = 200\n\n    def compute_sigma(U, K1, C1):\n        \"\"\"\n        Computes the stability metric sigma(U) for a given airspeed U.\n        \n        Args:\n            U (float): Airspeed in m/s.\n            K1 (np.ndarray): Aerodynamic stiffness matrix.\n            C1 (np.ndarray): Aerodynamic damping matrix.\n        \n        Returns:\n            float: The maximum real part of the oscillatory eigenvalues of A(U),\n                   or -inf if no oscillatory eigenvalues exist.\n        \"\"\"\n        if U  0:\n            return -np.inf # Physically meaningless, treated as stable.\n        \n        q_U = 0.5 * RHO * U**2\n        \n        K_U = K0 + q_U * K1\n        C_U = C0 + q_U * C1\n        \n        A_bottom_left = -M_inv @ K_U\n        A_bottom_right = -M_inv @ C_U\n        A = np.block([[Z2, I2], [A_bottom_left, A_bottom_right]])\n        \n        eigenvalues = np.linalg.eigvals(A)\n        \n        # Filter for oscillatory eigenvalues (non-zero imaginary part)\n        # Using a small tolerance for floating point comparisons\n        oscillatory_eigs = eigenvalues[np.abs(np.imag(eigenvalues))  1e-9]\n        \n        if oscillatory_eigs.size == 0:\n            return -np.inf\n            \n        return np.max(np.real(oscillatory_eigs))\n\n    def find_flutter_speed(U_min, U_max, K1, C1):\n        \"\"\"\n        Finds the flutter speed using scanning for bracketing and bisection for refinement.\n        \n        Returns:\n            float: The flutter speed U_f in m/s, or -1.0 if no flutter is found.\n        \"\"\"\n        # Step 1: Bracketing by scanning the interval\n        U_scan = np.linspace(U_min, U_max, SCAN_POINTS)\n        sigma_scan = np.array([compute_sigma(U, K1, C1) for U in U_scan])\n        \n        bracket = None\n        for i in range(len(U_scan) - 1):\n            if sigma_scan[i]  0 and sigma_scan[i+1] = 0:\n                bracket = [U_scan[i], U_scan[i+1]]\n                break\n        \n        if bracket is None:\n            return -1.0\n\n        # Step 2: Refinement using bisection\n        a, b = bracket\n        max_iter = 100 # Safety break for bisection loop\n        for _ in range(max_iter):\n            if (b - a)  BISECTION_TOLERANCE:\n                break\n            mid = (a + b) / 2.0\n            sigma_mid = compute_sigma(mid, K1, C1)\n            \n            if sigma_mid  0:\n                a = mid\n            else:\n                b = mid\n        \n        U_f = (a + b) / 2.0\n        return U_f\n\n    def assess_credibility(U_f, flight_test_data):\n        \"\"\"\n        Assesses model credibility based on the computed U_f and flight test data.\n        \n        Returns:\n            bool: True if the model is credible, False otherwise.\n        \"\"\"\n        f_flag, test_speed, delta_U = flight_test_data\n        \n        if f_flag == 1:  # Measured flutter speed U_meas\n            U_meas = test_speed\n            return U_f != -1.0 and abs(U_f - U_meas) = delta_U\n        elif f_flag == 0:  # No flutter up to envelope speed U_env\n            U_env = test_speed\n            return U_f == -1.0 or U_f  U_env\n        return False\n\n    # Define test cases from the problem statement\n    test_cases = [\n        # Case A: Nominal flexibility\n        {'s': 1.0, 'U_interval': [40.0, 220.0], 'flight_data': (1, 165.0, 15.0)},\n        # Case B: Stiffened wing\n        {'s': 0.1, 'U_interval': [40.0, 220.0], 'flight_data': (0, 220.0, None)},\n        # Case C: Soft wing\n        {'s': 2.0, 'U_interval': [20.0, 120.0], 'flight_data': (1, 60.0, 15.0)},\n    ]\n\n    final_results = []\n    for case in test_cases:\n        s = case['s']\n        U_min, U_max = case['U_interval']\n        \n        # Construct case-specific aerodynamic matrices\n        K1 = s * K1_base\n        C1 = s * C1_base\n        \n        # Compute flutter speed\n        U_f = find_flutter_speed(U_min, U_max, K1, C1)\n        \n        # Assess credibility\n        credibility = assess_credibility(U_f, case['flight_data'])\n        \n        # Append results, rounding U_f to 3 decimal places\n        final_results.append(round(U_f, 3) if U_f != -1.0 else -1.0)\n        final_results.append(credibility)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "A digital twin's fidelity depends on its ability to accurately reflect its physical counterpart, which requires calibrating model parameters using real-world data. This practice focuses on a grey-box modeling approach for a turbofan engine, where you will derive an identifiable regression model from physical laws and use operational data to estimate its parameters. This hands-on exercise  is fundamental to creating adaptive digital twins that learn and improve over the asset's lifecycle.",
            "id": "4216540",
            "problem": "In the setting of a Digital Twin (DT) for a turbofan engine in Aerospace and Defense (AD), consider a grey-box, physics-informed identification task built from first principles. Begin from the spool dynamics balance, which follows Newton's second law for rotation: the rotor's angular momentum changes due to the difference between fuel torque and aerodynamic load. After linearization about an operating point and discrete-time sampling with period $\\Delta t$, one obtains the first-order discrete dynamics for the spool speed deviation $n_k$ and a static affine mapping to thrust deviation $T_k$:\n- State update: $n_{k+1} = a\\,n_k + b\\,u_k + w_k$,\n- Measurement: $T_k = \\gamma\\,n_k + \\eta\\,u_k + v_k$,\nwhere $u_k$ is the commanded fuel flow deviation (dimensionless), $a$ and $b$ are discrete-time coefficients reflecting rotor inertia and aerodynamic damping, $\\gamma$ and $\\eta$ parameterize how thrust depends on spool speed and fuel flow, and $w_k$ and $v_k$ are zero-mean process and measurement noises. The thrust $T_k$ is measured in Newtons (N). The process and measurement noises are modeled as Gaussian with known, possibly heterogeneous standard deviations for the measurements.\n\nStarting from these fundamental definitions, derive an identifiable regression that depends only on observable quantities $T_k$ and $u_k$ by eliminating the unmeasured state $n_k$. Then, treat the measurement noise as heteroscedastic, with known standard deviations $\\sigma_k$ for $T_k$. Use the principle that, under Gaussian noise, the Maximum Likelihood Estimator (MLE) coincides with Generalized Least Squares (GLS) to calibrate the parameters of this observable regression using the provided operational datasets. To ensure numerical stability and handle potential near-singular normal equations, use Tikhonov regularization with a small hyperparameter $\\lambda = 10^{-6}$ added to the parameter normal matrix. In all computations, interpret $b'$ and $\\eta$ in Newtons (N) and $a$ as dimensionless, but print only numeric values without units.\n\nResiduals must be whitened by the known standard deviations to assess goodness of fit. Quantify the goodness of fit using:\n- The mean of squared whitened residuals, defined as $\\frac{1}{N}\\sum_{k} \\left(\\frac{r_k}{\\sigma_k}\\right)^2$, where $r_k$ are the residuals at the thrust samples corresponding to the regression output.\n- The Akaike Information Criterion (AIC) under heteroscedastic Gaussian noise with known variances, defined by $AIC = 2p - 2\\log L$, where $p$ is the number of calibrated parameters and $\\log L = -\\frac{1}{2}\\sum_k \\left[\\log(2\\pi \\sigma_k^2) + \\frac{r_k^2}{\\sigma_k^2}\\right]$ is the log-likelihood.\n\nImplement a program that performs the following steps:\n1. From the fundamental laws and definitions above, derive the observable linear regression in terms of $T_{k+1}$, $T_k$, $u_k$, and $u_{k+1}$ that is implied by the model after eliminating $n_k$. Calibrate its parameters using GLS with ridge regularization $\\lambda = 10^{-6}$.\n2. Compute the residuals at each output sample, whiten by the provided standard deviations, compute the mean of squared whitened residuals, and compute $AIC$ using the heteroscedastic Gaussian likelihood.\n\nUse the following test suite of three operational datasets. Each dataset provides input command sequences $u_k$ (dimensionless), measured thrust $T_k$ in Newtons (N), and measurement standard deviations $\\sigma_k$ in Newtons (N). All sequences are time-aligned and uniformly sampled; you must form regression samples over consecutive indices $k$ where $T_{k+1}$ is predicted from $(T_k, u_k, u_{k+1})$. In each dataset, use the samples $k=0,1,\\dots, K-2$ when the arrays have length $K$.\n\nDataset 1 (typical excitation, moderate noise):\n- $u^{(1)} = [0.20, 0.20, 0.25, 0.25, 0.35, 0.35, 0.30, 0.40, 0.50, 0.50, 0.45, 0.55, 0.60]$\n- $T^{(1)} = [150.0, 152.5, 165.0, 170.0, 230.0, 235.0, 225.0, 275.0, 340.0, 345.0, 335.0, 390.0, 420.0]$ in N\n- $\\sigma^{(1)} = [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]$ in N\n\nDataset 2 (near-marginal stability, slow response, lower noise):\n- $u^{(2)} = [0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41]$\n- $T^{(2)} = [240.0, 242.0, 244.5, 247.0, 249.0, 251.5, 254.0, 256.0, 258.5, 261.0, 263.0, 265.5]$ in N\n- $\\sigma^{(2)} = [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]$ in N\n\nDataset 3 (low excitation, nearly constant input, small noise):\n- $u^{(3)} = [0.40, 0.40, 0.40, 0.41, 0.39, 0.40, 0.40, 0.41, 0.39, 0.40]$\n- $T^{(3)} = [300.0, 301.0, 300.5, 302.0, 299.0, 300.5, 300.0, 302.0, 298.5, 300.0]$ in N\n- $\\sigma^{(3)} = [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]$ in N\n\nFor each dataset $i \\in \\{1,2,3\\}$, compute:\n- The calibrated regression parameters $[\\,a^{(i)}, b^{\\prime (i)}, \\eta^{(i)}\\,]$, where $a$ is dimensionless and both $b'$ and $\\eta$ are in N,\n- The mean of squared whitened residuals,\n- The Akaike Information Criterion.\n\nFinal output format: Your program should produce a single line of output containing a list of three sublists, one per dataset, each sublist in the order $[\\,a, b', \\eta, \\text{MSWR}, \\text{AIC}\\,]$. Print each float in standard decimal form. For example, the output must look like\n$[\\,[a_1,b'_1,\\eta_1,mswr_1,aic_1],[a_2,b'_2,\\eta_2,mswr_2,aic_2],[a_3,b'_3,\\eta_3,mswr_3,aic_3]\\,]$.",
            "solution": "The problem requires the identification of parameters for a simplified turbofan engine model using operational data. This is a grey-box identification task, starting from a physics-informed state-space model and deriving an observable regression form.\n\n### Step 1: Derivation of the Observable Regression Model\n\nThe provided discrete-time, linearized model of the turbofan engine dynamics is given by a state-space representation:\n1.  State update equation for spool speed deviation $n_k$:\n    $$n_{k+1} = a\\,n_k + b\\,u_k + w_k \\quad (*)$$\n2.  Measurement equation for thrust deviation $T_k$:\n    $$T_k = \\gamma\\,n_k + \\eta\\,u_k + v_k \\quad (**)$$\n\nHere, $n_k$ is the unmeasured state variable (spool speed), while $T_k$ (thrust) and $u_k$ (fuel flow command) are observable quantities. The terms $w_k$ and $v_k$ represent zero-mean, Gaussian process and measurement noise, respectively. The measurement noise $v_k$ associated with $T_k$ is heteroscedastic with a known standard deviation $\\sigma_k$.\n\nThe objective is to derive an equation that relates only the observable variables. This is achieved by algebraically eliminating the unobserved state $n_k$. From the measurement equation $(**)$, we can express $n_k$ as:\n$$\\gamma\\,n_k = T_k - \\eta\\,u_k - v_k$$\nAssuming $\\gamma \\neq 0$ (a physical necessity, as spool speed must influence thrust), we have:\n$$n_k = \\frac{1}{\\gamma}(T_k - \\eta\\,u_k - v_k)$$\n\nTo substitute this into the state update equation $(*)$, we also need an expression for $n_{k+1}$. Advancing the time index from $k$ to $k+1$ in the expression for $n_k$ yields:\n$$n_{k+1} = \\frac{1}{\\gamma}(T_{k+1} - \\eta\\,u_{k+1} - v_{k+1})$$\n\nNow, substitute the expressions for $n_k$ and $n_{k+1}$ into the state equation $(*)$:\n$$\\frac{1}{\\gamma}(T_{k+1} - \\eta\\,u_{k+1} - v_{k+1}) = a\\left[\\frac{1}{\\gamma}(T_k - \\eta\\,u_k - v_k)\\right] + b\\,u_k + w_k$$\n\nTo simplify, we multiply the entire equation by $\\gamma$:\n$$T_{k+1} - \\eta\\,u_{k+1} - v_{k+1} = a(T_k - \\eta\\,u_k - v_k) + \\gamma b\\,u_k + \\gamma w_k$$\n\nWe rearrange this equation to group observable terms on one side and noise terms on the other. We seek a model that predicts the next thrust measurement, $T_{k+1}$:\n$$T_{k+1} = a\\,T_k - a\\eta\\,u_k + \\gamma b\\,u_k + \\eta\\,u_{k+1} + (v_{k+1} - a\\,v_k + \\gamma w_k)$$\n\nGrouping the coefficients of the input $u_k$, we get:\n$$T_{k+1} = a\\,T_k + (\\gamma b - a\\eta)\\,u_k + \\eta\\,u_{k+1} + \\epsilon_{k+1}$$\nwhere $\\epsilon_{k+1} = v_{k+1} - a\\,v_k + \\gamma w_k$ is a composite, colored noise term.\n\nThis equation is in a standard linear regression form, specifically an AutoRegressive with eXogenous inputs (ARX) model. The parameters to be identified are the coefficients of the observable terms. Let us define new parameters for our regression:\n- $\\theta_1 = a$\n- $\\theta_2 = b' = \\gamma b - a\\eta$\n- $\\theta_3 = \\eta$\n\nThe problem specifies that $a$ is dimensionless, while $b'$ and $\\eta$ are in Newtons ($N$), which is consistent with the derived equation where $T_k$ is in $N$ and $u_k$ is dimensionless. The identifiable regression model is thus:\n$$T_{k+1} = a\\,T_k + b'\\,u_k + \\eta\\,u_{k+1} + \\epsilon_{k+1} \\quad (***)$$\n\n### Step 2: Parameter Estimation using Generalized Least Squares (GLS) with Regularization\n\nThe error term $\\epsilon_{k+1}$ is a moving average of noise sources, making it serially correlated. However, a common and effective simplification in equation-error methods is to assume the error is dominated by the most recent measurement noise, $\\epsilon_{k+1} \\approx v_{k+1}$. Under this assumption, the errors are approximately uncorrelated but retain the heteroscedasticity of the measurement noise, i.e., $\\text{Var}(\\epsilon_{k+1}) \\approx \\text{Var}(v_{k+1}) = \\sigma_{k+1}^2$.\n\nThis heteroscedasticity motivates the use of Generalized Least Squares (GLS). For Gaussian noise, GLS is equivalent to the Maximum Likelihood Estimator (MLE). GLS standardizes each regression equation by dividing by the standard deviation of its error term. For equation $(***)$, the standard deviation is $\\sigma_{k+1}$. This process, known as whitening, yields:\n$$\\frac{T_{k+1}}{\\sigma_{k+1}} = a\\left(\\frac{T_k}{\\sigma_{k+1}}\\right) + b'\\left(\\frac{u_k}{\\sigma_{k+1}}\\right) + \\eta\\left(\\frac{u_{k+1}}{\\sigma_{k+1}}\\right) + \\frac{\\epsilon_{k+1}}{\\sigma_{k+1}}$$\nThe new error term has a variance of approximately $1$, making the problem amenable to Ordinary Least Squares (OLS) on the transformed variables.\n\nFor a dataset of length $K$, we can construct $N = K-1$ such equations for $k \\in \\{0, 1, \\dots, K-2\\}$. We can express this in matrix form $\\tilde{\\mathbf{Y}} = \\tilde{\\mathbf{X}}\\theta$, where $\\theta = [a, b', \\eta]^T$.\n- The whitened response vector is $\\tilde{\\mathbf{Y}} \\in \\mathbb{R}^{N}$:\n  $$\\tilde{\\mathbf{Y}} = \\begin{bmatrix} T_1 / \\sigma_1 \\\\ T_2 / \\sigma_2 \\\\ \\vdots \\\\ T_{K-1} / \\sigma_{K-1} \\end{bmatrix}$$\n- The whitened regressor matrix is $\\tilde{\\mathbf{X}} \\in \\mathbb{R}^{N \\times 3}$:\n  $$\\tilde{\\mathbf{X}} = \\begin{bmatrix}\n  T_0 / \\sigma_1  u_0 / \\sigma_1  u_1 / \\sigma_1 \\\\\n  T_1 / \\sigma_2  u_1 / \\sigma_2  u_2 / \\sigma_2 \\\\\n  \\vdots  \\vdots  \\vdots \\\\\n  T_{K-2} / \\sigma_{K-1}  u_{K-2} / \\sigma_{K-1}  u_{K-1} / \\sigma_{K-1}\n  \\end{bmatrix}$$\n\nThe problem requires Tikhonov regularization (ridge regression) to ensure numerical stability. The parameter vector $\\theta$ is found by minimizing the regularized squared error:\n$$\\min_{\\theta} ||\\tilde{\\mathbf{Y}} - \\tilde{\\mathbf{X}}\\theta||_2^2 + \\lambda ||\\theta||_2^2$$\nwhere $\\lambda = 10^{-6}$ is the regularization hyperparameter. The solution to this problem is given by the regularized normal equations:\n$$\\hat{\\theta} = (\\tilde{\\mathbf{X}}^T\\tilde{\\mathbf{X}} + \\lambda\\mathbf{I})^{-1}\\tilde{\\mathbf{X}}^T\\tilde{\\mathbf{Y}}$$\nwhere $\\mathbf{I}$ is the $3 \\times 3$ identity matrix.\n\n### Step 3: Goodness-of-Fit Assessment\n\nOnce the parameter vector $\\hat{\\theta} = [\\hat{a}, \\hat{b}', \\hat{\\eta}]^T$ is estimated, we evaluate the model's performance.\n\nFirst, we compute the model's predictions $\\hat{T}_{k+1}$ and the corresponding residuals $r_{k+1}$ for the output samples $k=1, \\dots, K-1$:\n$$\\hat{T}_{k+1} = \\hat{a}\\,T_k + \\hat{b}'\\,u_k + \\hat{\\eta}\\,u_{k+1}$$\n$$r_{k+1} = T_{k+1} - \\hat{T}_{k+1}$$\n\nThe **Mean of Squared Whitened Residuals (MSWR)** measures the average squared error in units of noise variance:\n$$\\text{MSWR} = \\frac{1}{N}\\sum_{k=1}^{K-1} \\left(\\frac{r_k}{\\sigma_k}\\right)^2$$\nwhere $N = K-1$ is the number of fitted data points.\n\nThe **Akaike Information Criterion (AIC)** provides a measure of model quality that penalizes complexity. For a model with $p$ parameters and heteroscedastic Gaussian noise with known variances $\\sigma_k^2$, the AIC is defined as $AIC = 2p - 2\\log L$. The log-likelihood $L$ is:\n$$\\log L = -\\frac{1}{2}\\sum_{k=1}^{K-1} \\left[\\log(2\\pi \\sigma_k^2) + \\frac{r_k^2}{\\sigma_k^2}\\right]$$\nHere, $p=3$ (for $a, b', \\eta$). The sum is over the $N=K-1$ output samples. This can be rewritten for computation as:\n$$\\text{AIC} = 2p + \\sum_{k=1}^{N} \\left[\\log(2\\pi\\sigma_{k, \\text{out}}^2) + \\left(\\frac{r_{k, \\text{out}}}{\\sigma_{k, \\text{out}}}\\right)^2\\right] = 2p + N\\log(2\\pi) + 2\\sum_{k=1}^{N}\\log(\\sigma_{k, \\text{out}}) + N \\cdot \\text{MSWR}$$\nwhere the sums and quantities are indexed over the $N$ output samples.\n\nThis comprehensive procedure allows for robust calibration of the engine model and a quantitative assessment of its predictive accuracy and statistical validity.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process datasets and print the final results.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Dataset 1\n        {\n            \"u\": np.array([0.20, 0.20, 0.25, 0.25, 0.35, 0.35, 0.30, 0.40, 0.50, 0.50, 0.45, 0.55, 0.60]),\n            \"T\": np.array([150.0, 152.5, 165.0, 170.0, 230.0, 235.0, 225.0, 275.0, 340.0, 345.0, 335.0, 390.0, 420.0]),\n            \"sigma\": np.array([5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]),\n        },\n        # Dataset 2\n        {\n            \"u\": np.array([0.30, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.40, 0.41]),\n            \"T\": np.array([240.0, 242.0, 244.5, 247.0, 249.0, 251.5, 254.0, 256.0, 258.5, 261.0, 263.0, 265.5]),\n            \"sigma\": np.array([3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0]),\n        },\n        # Dataset 3\n        {\n            \"u\": np.array([0.40, 0.40, 0.40, 0.41, 0.39, 0.40, 0.40, 0.41, 0.39, 0.40]),\n            \"T\": np.array([300.0, 301.0, 300.5, 302.0, 299.0, 300.5, 300.0, 302.0, 298.5, 300.0]),\n            \"sigma\": np.array([2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]),\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_dataset(case[\"u\"], case[\"T\"], case[\"sigma\"])\n        results.append(result)\n\n    # Format the final output string manually to match the required format without spaces.\n    sublist_strs = []\n    for sublist in results:\n        # Each float is converted to its standard string representation.\n        sublist_strs.append(f\"[{','.join(map(str, sublist))}]\")\n    \n    final_output = f\"[{','.join(sublist_strs)}]\"\n    print(final_output)\n\ndef process_dataset(u, T, sigma):\n    \"\"\"\n    Performs GLS regression with regularization and calculates goodness-of-fit metrics.\n\n    Args:\n        u (np.array): Input command sequence.\n        T (np.array): Measured thrust sequence.\n        sigma (np.array): Measurement standard deviation sequence.\n\n    Returns:\n        list: A list containing [a, b', eta, MSWR, AIC].\n    \"\"\"\n    lambda_reg = 1e-6\n    \n    # 1. Prepare data for regression\n    # The regression predicts T_{k+1} from (T_k, u_k, u_{k+1}).\n    # For a dataset of length K, we form N = K-1 regression samples.\n    K = len(T)\n    N = K - 1\n\n    # Output samples (T_1, ..., T_{K-1})\n    T_out = T[1:]\n    sigma_out = sigma[1:]\n\n    # Regressor samples (T_0, ..., T_{K-2}), (u_0, ..., u_{K-2}), (u_1, ..., u_{K-1})\n    T_reg = T[:-1]\n    u_reg = u[:-1]\n    u_reg_p1 = u[1:]\n\n    # 2. Formulate whitened (GLS) problem\n    # Divide each regression equation by the corresponding sigma of the output.\n    Y_tilde = T_out / sigma_out\n\n    X_tilde_col1 = T_reg / sigma_out\n    X_tilde_col2 = u_reg / sigma_out\n    X_tilde_col3 = u_reg_p1 / sigma_out\n    \n    X_tilde = np.stack([X_tilde_col1, X_tilde_col2, X_tilde_col3], axis=1)\n\n    # 3. Solve for parameters using regularized least squares\n    num_params = X_tilde.shape[1]\n    I = np.identity(num_params)\n    \n    # Normal matrix H = X_tilde^T * X_tilde + lambda * I\n    H = X_tilde.T @ X_tilde + lambda_reg * I\n    # Right-hand side g = X_tilde^T * Y_tilde\n    g = X_tilde.T @ Y_tilde\n    \n    # Solve H * theta = g for theta\n    theta = np.linalg.solve(H, g)\n    a, b_prime, eta = theta\n\n    # 4. Calculate goodness-of-fit metrics\n    # Predict thrust using the obtained parameters\n    T_pred = a * T_reg + b_prime * u_reg + eta * u_reg_p1\n    \n    # Calculate residuals\n    residuals = T_out - T_pred\n    \n    # Calculate whitened residuals\n    whitened_residuals = residuals / sigma_out\n    \n    # Mean of Squared Whitened Residuals (MSWR)\n    mswr = np.mean(whitened_residuals**2)\n    \n    # Akaike Information Criterion (AIC)\n    p = num_params\n    # logL = -0.5 * sum(log(2*pi*sigma_k^2) + (r_k/sigma_k)^2)\n    # AIC = 2*p - 2*logL\n    logL = -0.5 * np.sum(np.log(2 * np.pi * sigma_out**2) + whitened_residuals**2)\n    aic = 2 * p - 2 * logL\n    \n    return [a, b_prime, eta, mswr, aic]\n\n\nsolve()\n\n```"
        },
        {
            "introduction": "For a digital twin to be effective in real-time operations, it must accurately track the state of its physical asset by continuously fusing noisy sensor data. This exercise  puts you in the role of designing the estimation core of a tracking digital twin, implementing and comparing the Extended Kalman Filter (EKF) and the Unscented Kalman Filter (UKF). By evaluating their performance in various scenarios, you will gain practical insight into the trade-offs of different nonlinear filtering techniques used in aerospace applications.",
            "id": "4216505",
            "problem": "Aerospace tracking digital twins in defense contexts must fuse nonlinear radar measurements to estimate kinematic states in real time. Consider a planar ground-based tracking digital twin for an aerial target, modeled as a discrete-time nonlinear system. The target state at time step $k$ is $x_k = [p_{x,k}, p_{y,k}, v_k, \\psi_k]^\\top$, where $p_{x,k}$ and $p_{y,k}$ are planar Cartesian position components in meters, $v_k$ is speed in meters per second, and $\\psi_k$ is heading in radians. The control input is a known constant turn rate $\\omega$ in radians per second. The dynamics follow first principles of kinematics:\n$$\np_{x,k+1} = p_{x,k} + \\Delta t \\, v_k \\cos(\\psi_k), \\quad\np_{y,k+1} = p_{y,k} + \\Delta t \\, v_k \\sin(\\psi_k),\n$$\n$$\nv_{k+1} = v_k, \\quad\n\\psi_{k+1} = \\psi_k + \\omega \\Delta t,\n$$\nwith additive zero-mean Gaussian process noise $w_k \\sim \\mathcal{N}(0, Q)$, where $Q$ is a $4 \\times 4$ covariance matrix. A stationary ground-based radar located at the origin provides measurements $z_k = [r_k, \\theta_k]^\\top$, where\n$$\nr_k = \\sqrt{p_{x,k}^2 + p_{y,k}^2}, \\quad\n\\theta_k = \\operatorname{atan2}(p_{y,k}, p_{x,k}),\n$$\nwith additive zero-mean Gaussian measurement noise $v_k \\sim \\mathcal{N}(0, R)$, where $R$ is a $2 \\times 2$ covariance matrix. Angles must be handled in radians and normalized to the interval $(-\\pi, \\pi]$ when forming differences or averages.\n\nImplement both the Extended Kalman Filter (EKF) and the Unscented Kalman Filter (UKF) to compute posterior state estimates and posterior covariance matrices over a given sequence of measurements. The EKF must be derived via first-order linearization of the nonlinear dynamics and measurement functions around the current estimates. The UKF must be derived via the unscented transform with a deterministic set of sigma points and appropriate weights. Use the same simulated truth and measurements for both filters to enable a fair comparison of performance under nonlinearity.\n\nFundamental base and assumptions:\n- The discrete-time state-space system obeys $x_{k+1} = f(x_k) + w_k$ and $z_k = h(x_k) + v_k$ with $w_k$ and $v_k$ mutually independent, zero-mean, Gaussian noise.\n- The ground-truth trajectory is generated by the noise-free dynamics $x_{k+1}^{\\text{true}} = f(x_k^{\\text{true}})$, then measurements are formed as $z_k = h(x_k^{\\text{true}}) + v_k$.\n- Use a fixed pseudo-random seed $42$ for reproducible measurement noise generation.\n\nInitial conditions for filtering (common to all test cases):\n- Initial true state $x_0^{\\text{true}} = [p_{x,0}, p_{y,0}, v_0, \\psi_0]^\\top$ is case-dependent (specified below).\n- Initial state estimate $x_0 = x_0^{\\text{true}} + [\\delta p_x, \\delta p_y, \\delta v, \\delta \\psi]^\\top$, with $\\delta p_x = 50 \\,\\text{m}$, $\\delta p_y = -50 \\,\\text{m}$, $\\delta v = -20 \\,\\text{m/s}$, and $\\delta \\psi = 5^\\circ$ converted to radians.\n- Initial covariance $P_0 = \\operatorname{diag}([\\sigma_{p_x}^2, \\sigma_{p_y}^2, \\sigma_v^2, \\sigma_\\psi^2])$ with $\\sigma_{p_x} = 100 \\,\\text{m}$, $\\sigma_{p_y} = 100 \\,\\text{m}$, $\\sigma_v = 25 \\,\\text{m/s}$, and $\\sigma_\\psi = 10^\\circ$ converted to radians.\n- Process noise covariance $Q = \\operatorname{diag}([\\sigma_{q,p_x}^2, \\sigma_{q,p_y}^2, \\sigma_{q,v}^2, \\sigma_{q,\\psi}^2])$, case-dependent (specified below).\n\nEKF specification:\n- Use first-order Taylor linearization for $f(\\cdot)$ and $h(\\cdot)$ to derive the state transition Jacobian $F_k = \\left.\\frac{\\partial f}{\\partial x}\\right|_{x=x_k}$ and measurement Jacobian $H_k = \\left.\\frac{\\partial h}{\\partial x}\\right|_{x=\\hat{x}_{k|k-1}}$.\n- Prediction: $\\hat{x}_{k|k-1} = f(\\hat{x}_{k-1|k-1})$, $P_{k|k-1} = F_{k-1} P_{k-1|k-1} F_{k-1}^\\top + Q$.\n- Update: $S_k = H_k P_{k|k-1} H_k^\\top + R$, $K_k = P_{k|k-1} H_k^\\top S_k^{-1}$, innovation $\\nu_k = z_k - h(\\hat{x}_{k|k-1})$ with angular component normalized, posterior $\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k \\nu_k$, $P_{k|k} = (I - K_k H_k) P_{k|k-1}$.\n\nUKF specification:\n- Use unscented transform with parameters $\\alpha$, $\\beta$, and $\\kappa$. Let $n = 4$ be the state dimension and $\\lambda = \\alpha^2 (n + \\kappa) - n$. Generate $2n+1$ sigma points around $\\hat{x}_{k-1|k-1}$ using the Cholesky factor of $(n + \\lambda) P_{k-1|k-1}$. Use corresponding weights $W^{(m)}$ and $W^{(c)}$ for mean and covariance. Propagate sigma points through $f(\\cdot)$ and $h(\\cdot)$, applying angle-aware averaging for angular components and angle normalization for differences. Add $Q$ and $R$ in the prediction and measurement covariance steps, respectively. Perform the standard UKF update with cross-covariance and Kalman gain.\n\nPerformance metric:\n- Compute the Root Mean Square Error (RMSE) of position over the entire sequence for each filter:\n$$\n\\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{k=1}^N \\left[(\\hat{p}_{x,k} - p_{x,k}^{\\text{true}})^2 + (\\hat{p}_{y,k} - p_{y,k}^{\\text{true}})^2\\right]},\n$$\nin meters. Express all RMSE values in meters, as decimal numbers (no units in the printed output, but the values must correspond to meters). Also compute the ratio $\\rho = \\text{RMSE}_{\\text{UKF}} / \\text{RMSE}_{\\text{EKF}}$ (dimensionless).\n\nTest suite and parameters:\n- Case $1$ (general case, mild nonlinearity):\n  - $\\Delta t = 1 \\,\\text{s}$, $N = 20$, $\\omega = 0.05 \\,\\text{rad/s}$, $v_0 = 250 \\,\\text{m/s}$, $x_0^{\\text{true}} = [1000 \\,\\text{m}, 0 \\,\\text{m}, v_0, 0 \\,\\text{rad}]^\\top$.\n  - Measurement noise: $\\sigma_r = 30 \\,\\text{m}$, $\\sigma_\\theta = 0.5^\\circ$ converted to radians; $R = \\operatorname{diag}([\\sigma_r^2, \\sigma_\\theta^2])$.\n  - Process noise: $\\sigma_{q,p_x} = 5 \\,\\text{m}$, $\\sigma_{q,p_y} = 5 \\,\\text{m}$, $\\sigma_{q,v} = 1 \\,\\text{m/s}$, $\\sigma_{q,\\psi} = 0.1^\\circ$ converted to radians.\n- Case $2$ (higher nonlinearity, tighter turns and closer range):\n  - $\\Delta t = 0.5 \\,\\text{s}$, $N = 40$, $\\omega = 0.2 \\,\\text{rad/s}$, $v_0 = 200 \\,\\text{m/s}$, $x_0^{\\text{true}} = [500 \\,\\text{m}, 200 \\,\\text{m}, v_0, \\frac{\\pi}{6} \\,\\text{rad}]^\\top$.\n  - Measurement noise: $\\sigma_r = 20 \\,\\text{m}$, $\\sigma_\\theta = 0.3^\\circ$ converted to radians; $R = \\operatorname{diag}([\\sigma_r^2, \\sigma_\\theta^2])$.\n  - Process noise: $\\sigma_{q,p_x} = 3 \\,\\text{m}$, $\\sigma_{q,p_y} = 3 \\,\\text{m}$, $\\sigma_{q,v} = 2 \\,\\text{m/s}$, $\\sigma_{q,\\psi} = 0.2^\\circ$ converted to radians.\n- Case $3$ (very noisy measurements):\n  - $\\Delta t = 1 \\,\\text{s}$, $N = 30$, $\\omega = 0.1 \\,\\text{rad/s}$, $v_0 = 220 \\,\\text{m/s}$, $x_0^{\\text{true}} = [1500 \\,\\text{m}, -300 \\,\\text{m}, v_0, \\frac{\\pi}{4} \\,\\text{rad}]^\\top$.\n  - Measurement noise: $\\sigma_r = 100 \\,\\text{m}$, $\\sigma_\\theta = 1.5^\\circ$ converted to radians; $R = \\operatorname{diag}([\\sigma_r^2, \\sigma_\\theta^2])$.\n  - Process noise: $\\sigma_{q,p_x} = 10 \\,\\text{m}$, $\\sigma_{q,p_y} = 10 \\,\\text{m}$, $\\sigma_{q,v} = 5 \\,\\text{m/s}$, $\\sigma_{q,\\psi} = 0.5^\\circ$ converted to radians.\n- Case $4$ (near-origin geometry increasing Jacobian sensitivity):\n  - $\\Delta t = 0.5 \\,\\text{s}$, $N = 25$, $\\omega = 0.15 \\,\\text{rad/s}$, $v_0 = 180 \\,\\text{m/s}$, $x_0^{\\text{true}} = [50 \\,\\text{m}, 50 \\,\\text{m}, v_0, -\\frac{\\pi}{3} \\,\\text{rad}]^\\top$.\n  - Measurement noise: $\\sigma_r = 10 \\,\\text{m}$, $\\sigma_\\theta = 0.8^\\circ$ converted to radians; $R = \\operatorname{diag}([\\sigma_r^2, \\sigma_\\theta^2])$.\n  - Process noise: $\\sigma_{q,p_x} = 2 \\,\\text{m}$, $\\sigma_{q,p_y} = 2 \\,\\text{m}$, $\\sigma_{q,v} = 1 \\,\\text{m/s}$, $\\sigma_{q,\\psi} = 0.3^\\circ$ converted to radians.\n\nUKF parameters (use for all cases): $\\alpha = 10^{-3}$, $\\beta = 2$, $\\kappa = 0$.\n\nYour program must:\n- Simulate the truth trajectory and measurement sequence using the specified $x_0^{\\text{true}}$, $\\Delta t$, $N$, and $\\omega$, with noise drawn using seed $42$ for the measurement noise.\n- Run EKF and UKF to compute posterior estimates $\\hat{x}_{k|k}$ and posterior covariances $P_{k|k}$ for $k = 1, \\ldots, N$.\n- Compute position RMSE for EKF and UKF in meters for each case, and the ratio $\\rho$ (dimensionless).\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must be flat and ordered as $[\\text{RMSE}_{\\text{EKF},1}, \\text{RMSE}_{\\text{UKF},1}, \\rho_1, \\text{RMSE}_{\\text{EKF},2}, \\text{RMSE}_{\\text{UKF},2}, \\rho_2, \\text{RMSE}_{\\text{EKF},3}, \\text{RMSE}_{\\text{UKF},3}, \\rho_3, \\text{RMSE}_{\\text{EKF},4}, \\text{RMSE}_{\\text{UKF},4}, \\rho_4]$.\n\nAngles must be in radians throughout. Express all RMSE values in meters as decimal numbers. The ratio must be expressed as a decimal number.",
            "solution": "The user has provided a well-defined problem in the domain of nonlinear state estimation for an aerospace tracking application. The task is to implement, compare, and evaluate the performance of an Extended Kalman Filter (EKF) and an Unscented Kalman Filter (UKF). The problem statement is validated to be scientifically sound, self-contained, and objective. It provides all necessary models, parameters, and initial conditions to proceed with a solution.\n\nThe solution requires the implementation of the following components:\n1.  A simulation environment to generate the ground-truth trajectory of an aerial target and the corresponding noisy radar measurements.\n2.  The Extended Kalman Filter algorithm, which linearizes the nonlinear system and measurement models at each time step.\n3.  The Unscented Kalman Filter algorithm, which uses a deterministic set of sample points (sigma points) to capture the mean and covariance of the state distribution, providing a generally more accurate approximation for nonlinear systems than the EKF's linearization.\n4.  A routine to calculate the Root Mean Square Error (RMSE) of the position estimate for both filters against the ground truth.\n\nThe state of the target at time step $k$ is represented by the vector $x_k = [p_{x,k}, p_{y,k}, v_k, \\psi_k]^\\top$, where $(p_{x,k}, p_{y,k})$ is the Cartesian position, $v_k$ is the speed, and $\\psi_k$ is the heading angle. The measurement from the radar is $z_k = [r_k, \\theta_k]^\\top$, comprising range and bearing. All angular quantities are handled in radians, with special care for normalization to the interval $(-\\pi, \\pi]$.\n\nFirst, we define the nonlinear state transition function $f(\\cdot)$ and measurement function $h(\\cdot)$:\nThe state transition function $x_{k+1} = f(x_k, u_k)$, where the control input $u_k$ includes the turn rate $\\omega$ and time step $\\Delta t$, is given by:\n$$f(x_k) = \\begin{bmatrix} p_{x,k} + \\Delta t \\, v_k \\cos(\\psi_k) \\\\ p_{y,k} + \\Delta t \\, v_k \\sin(\\psi_k) \\\\ v_k \\\\ \\psi_k + \\omega \\Delta t \\end{bmatrix}$$\nThe measurement function $z_k = h(x_k)$ is:\n$$h(x_k) = \\begin{bmatrix} \\sqrt{p_{x,k}^2 + p_{y,k}^2} \\\\ \\operatorname{atan2}(p_{y,k}, p_{x,k}) \\end{bmatrix}$$\n\nA helper function, `normalize_angle`, is essential for correctly handling circular quantities. It wraps any given angle to the interval $(-\\pi, \\pi]$. This is critical when calculating innovations or averaging angles.\n\nFor the EKF, we must derive the Jacobians of $f$ and $h$. The state transition Jacobian $F_k = \\frac{\\partial f}{\\partial x}|_{\\hat{x}_{k-1|k-1}}$ is:\n$$F_k = \\begin{bmatrix} 1  0  \\Delta t \\cos(\\hat{\\psi}_{k-1|k-1})  -\\Delta t \\hat{v}_{k-1|k-1} \\sin(\\hat{\\psi}_{k-1|k-1}) \\\\ 0  1  \\Delta t \\sin(\\hat{\\psi}_{k-1|k-1})  \\Delta t \\hat{v}_{k-1|k-1} \\cos(\\hat{\\psi}_{k-1|k-1}) \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\end{bmatrix}$$\nThe measurement Jacobian $H_k = \\frac{\\partial h}{\\partial x}|_{\\hat{x}_{k|k-1}}$ is:\n$$H_k = \\begin{bmatrix} \\frac{\\hat{p}_{x,k|k-1}}{\\sqrt{\\hat{p}_{x,k|k-1}^2 + \\hat{p}_{y,k|k-1}^2}}  \\frac{\\hat{p}_{y,k|k-1}}{\\sqrt{\\hat{p}_{x,k|k-1}^2 + \\hat{p}_{y,k|k-1}^2}}  0  0 \\\\ -\\frac{\\hat{p}_{y,k|k-1}}{\\hat{p}_{x,k|k-1}^2 + \\hat{p}_{y,k|k-1}^2}  \\frac{\\hat{p}_{x,k|k-1}}{\\hat{p}_{x,k|k-1}^2 + \\hat{p}_{y,k|k-1}^2}  0  0 \\end{bmatrix}$$\nThe EKF then proceeds with its standard two-step cycle: predict and update, using these Jacobians to propagate the covariance matrix. The innovation for the angle `theta` must be normalized.\n\nFor the UKF, we employ the unscented transform. Given the state dimension $n=4$ and the specified parameters $\\alpha=10^{-3}$, $\\beta=2$, $\\kappa=0$, we first compute the scaling parameter $\\lambda = \\alpha^2(n+\\kappa)-n$. We then generate a set of $2n+1=9$ sigma points around the current state estimate using the Cholesky decomposition of the scaled covariance matrix $(n+\\lambda)P$. These sigma points are propagated through the nonlinear functions $f$ and $h$. The predicted state, predicted measurement, and their respective covariances are then reconstituted from the transformed sigma points using a set of carefully chosen weights. A crucial implementation detail is the handling of angles: the mean of angular sigma points (for $\\psi$ and $\\theta$) must be calculated by taking the `atan2` of the weighted sum of their sines and cosines. Similarly, differences involving angles must be normalized.\n\nThe main program logic will iterate through four distinct test cases. For each case:\n1.  The specific parameters ($\\Delta t$, $N$, $\\omega$, noise covariances, initial true state) are set.\n2.  The initial filter state and covariance are derived from the true initial state as specified.\n3.  The ground-truth trajectory is generated deterministically using the function $f$.\n4.  Noisy measurements are generated from the ground truth using a pseudo-random number generator initialized with the specified seed of $42$.\n5.  The EKF and UKF are executed over the sequence of $N$ time steps, each processing the same measurement data.\n6.  The position RMSE for both filters and their ratio $\\rho$ are computed and stored.\n\nFinally, the collected results from all four cases are formatted into a single string as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy  # Allowed, though not strictly necessary for this implementation\n\ndef solve():\n    \"\"\"\n    Implements and compares EKF and UKF for a nonlinear tracking problem\n    across four test cases.\n    \"\"\"\n\n    def normalize_angle(angle):\n        \"\"\"Normalize an angle to the range [-pi, pi].\"\"\"\n        return (angle + np.pi) % (2 * np.pi) - np.pi\n\n    def state_transition_function(x, dt, omega):\n        \"\"\"\n        Computes the state transition for the constant turn rate model.\n        x = [px, py, v, psi]\n        \"\"\"\n        px, py, v, psi = x\n        px_new = px + dt * v * np.cos(psi)\n        py_new = py + dt * v * np.sin(psi)\n        v_new = v\n        psi_new = psi + omega * dt # Normalization applied after in filters\n        return np.array([px_new, py_new, v_new, psi_new])\n\n    def measurement_function(x):\n        \"\"\"\n        Computes the measurement [range, bearing] from the state.\n        \"\"\"\n        px, py, _, _ = x\n        r = np.sqrt(px**2 + py**2)\n        theta = np.arctan2(py, px)\n        return np.array([r, theta])\n\n    def state_jacobian(x, dt):\n        \"\"\"\n        Computes the Jacobian of the state transition function (F).\n        The omega term is part of the model, not the state.\n        \"\"\"\n        _, _, v, psi = x\n        F = np.eye(4)\n        F[0, 2] = dt * np.cos(psi)\n        F[0, 3] = -dt * v * np.sin(psi)\n        F[1, 2] = dt * np.sin(psi)\n        F[1, 3] = dt * v * np.cos(psi)\n        return F\n\n    def measurement_jacobian(x):\n        \"\"\"\n        Computes the Jacobian of the measurement function (H).\n        \"\"\"\n        px, py, _, _ = x\n        r_sq = px**2 + py**2\n        if r_sq  1e-9:  # Avoid division by zero\n            r_sq = 1e-9\n        r = np.sqrt(r_sq)\n        H = np.zeros((2, 4))\n        H[0, 0] = px / r\n        H[0, 1] = py / r\n        H[1, 0] = -py / r_sq\n        H[1, 1] = px / r_sq\n        return H\n\n    def run_ekf(measurements, x0, P0, Q, R, dt, omega, N):\n        \"\"\"Runs the Extended Kalman Filter simulation.\"\"\"\n        x_est = x0.copy()\n        P_est = P0.copy()\n        est_history = np.zeros((N, 4))\n\n        for k in range(N):\n            # Predict\n            F = state_jacobian(x_est, dt)\n            x_pred = state_transition_function(x_est, dt, omega)\n            x_pred[3] = normalize_angle(x_pred[3])\n            P_pred = F @ P_est @ F.T + Q\n\n            # Update\n            H = measurement_jacobian(x_pred)\n            z_pred = measurement_function(x_pred)\n            \n            y = measurements[k] - z_pred\n            y[1] = normalize_angle(y[1]) # Normalize angle innovation\n\n            S = H @ P_pred @ H.T + R\n            K = P_pred @ H.T @ np.linalg.inv(S)\n            \n            x_est = x_pred + K @ y\n            x_est[3] = normalize_angle(x_est[3]) # Normalize heading\n            P_est = (np.eye(4) - K @ H) @ P_pred\n\n            est_history[k] = x_est\n\n        return est_history\n\n    def run_ukf(measurements, x0, P0, Q, R, dt, omega, N):\n        \"\"\"Runs the Unscented Kalman Filter simulation.\"\"\"\n        n = 4  # State dimension\n        alpha = 1e-3\n        beta = 2.0\n        kappa = 0.0\n        \n        lambda_ = alpha**2 * (n + kappa) - n\n        \n        # Weights for mean\n        Wm = np.full(2 * n + 1, 1 / (2 * (n + lambda_)))\n        Wm[0] = lambda_ / (n + lambda_)\n        \n        # Weights for covariance\n        Wc = np.full(2 * n + 1, 1 / (2 * (n + lambda_)))\n        Wc[0] = lambda_ / (n + lambda_) + (1 - alpha**2 + beta)\n\n        x_est = x0.copy()\n        P_est = P0.copy()\n        est_history = np.zeros((N, 4))\n\n        for k in range(N):\n            # --- PREDICT ---\n            \n            # 1. Generate sigma points\n            L = np.linalg.cholesky((n + lambda_) * P_est)\n            sigmas = np.zeros((2 * n + 1, n))\n            sigmas[0] = x_est\n            for i in range(n):\n                sigmas[i + 1] = x_est + L[:, i]\n                sigmas[i + 1 + n] = x_est - L[:, i]\n            \n            # 2. Propagate sigma points through dynamics\n            sigmas_pred = np.array([state_transition_function(s, dt, omega) for s in sigmas])\n            \n            # 3. Calculate predicted mean\n            x_pred = np.zeros(n)\n            # Linear components\n            x_pred[:3] = np.sum(Wm[:, np.newaxis] * sigmas_pred[:, :3], axis=0)\n            # Angular component (psi)\n            sum_sin = np.sum(Wm * np.sin(sigmas_pred[:, 3]))\n            sum_cos = np.sum(Wm * np.cos(sigmas_pred[:, 3]))\n            x_pred[3] = np.arctan2(sum_sin, sum_cos)\n\n            # 4. Calculate predicted covariance\n            P_pred = np.zeros((n, n))\n            for i in range(2 * n + 1):\n                diff = sigmas_pred[i] - x_pred\n                diff[3] = normalize_angle(diff[3])\n                P_pred += Wc[i] * np.outer(diff, diff)\n            P_pred += Q\n            \n            # --- UPDATE ---\n\n            # 5. Propagate predicted sigma points through measurement model\n            Z_sigmas = np.array([measurement_function(s) for s in sigmas_pred])\n            \n            # 6. Calculate predicted measurement\n            z_pred = np.zeros(2)\n            # Linear component (r)\n            z_pred[0] = np.sum(Wm * Z_sigmas[:, 0])\n            # Angular component (theta)\n            sum_sin = np.sum(Wm * np.sin(Z_sigmas[:, 1]))\n            sum_cos = np.sum(Wm * np.cos(Z_sigmas[:, 1]))\n            z_pred[1] = np.arctan2(sum_sin, sum_cos)\n            \n            # 7. Calculate innovation covariance (S) and cross-covariance (T)\n            S = np.zeros((2, 2))\n            T = np.zeros((n, 2))\n            for i in range(2 * n + 1):\n                # Measurement residual\n                z_diff = Z_sigmas[i] - z_pred\n                z_diff[1] = normalize_angle(z_diff[1])\n                S += Wc[i] * np.outer(z_diff, z_diff)\n                \n                # State residual\n                x_diff = sigmas_pred[i] - x_pred\n                x_diff[3] = normalize_angle(x_diff[3])\n                T += Wc[i] * np.outer(x_diff, z_diff)\n            S += R\n            \n            # 8. Calculate Kalman gain and update state/covariance\n            K = T @ np.linalg.inv(S)\n            y = measurements[k] - z_pred\n            y[1] = normalize_angle(y[1])\n            \n            x_est = x_pred + K @ y\n            x_est[3] = normalize_angle(x_est[3])\n            P_est = P_pred - K @ S @ K.T\n            \n            est_history[k] = x_est\n\n        return est_history\n\n    def calculate_rmse(estimates, truth):\n        \"\"\"Calculates position RMSE.\"\"\"\n        pos_errors = estimates[:, :2] - truth[:, :2]\n        squared_errors = np.sum(pos_errors**2, axis=1)\n        return np.sqrt(np.mean(squared_errors))\n\n    test_cases = [\n        # Case 1\n        {\n            'dt': 1.0, 'N': 20, 'omega': 0.05, 'v0': 250.0,\n            'x0_true': np.array([1000.0, 0.0, 250.0, 0.0]),\n            'sigma_r': 30.0, 'sigma_theta_deg': 0.5,\n            'sigma_q_p': 5.0, 'sigma_q_v': 1.0, 'sigma_q_psi_deg': 0.1\n        },\n        # Case 2\n        {\n            'dt': 0.5, 'N': 40, 'omega': 0.2, 'v0': 200.0,\n            'x0_true': np.array([500.0, 200.0, 200.0, np.pi/6]),\n            'sigma_r': 20.0, 'sigma_theta_deg': 0.3,\n            'sigma_q_p': 3.0, 'sigma_q_v': 2.0, 'sigma_q_psi_deg': 0.2\n        },\n        # Case 3\n        {\n            'dt': 1.0, 'N': 30, 'omega': 0.1, 'v0': 220.0,\n            'x0_true': np.array([1500.0, -300.0, 220.0, np.pi/4]),\n            'sigma_r': 100.0, 'sigma_theta_deg': 1.5,\n            'sigma_q_p': 10.0, 'sigma_q_v': 5.0, 'sigma_q_psi_deg': 0.5\n        },\n        # Case 4\n        {\n            'dt': 0.5, 'N': 25, 'omega': 0.15, 'v0': 180.0,\n            'x0_true': np.array([50.0, 50.0, 180.0, -np.pi/3]),\n            'sigma_r': 10.0, 'sigma_theta_deg': 0.8,\n            'sigma_q_p': 2.0, 'sigma_q_v': 1.0, 'sigma_q_psi_deg': 0.3\n        }\n    ]\n\n    all_results = []\n    \n    # Common initial estimate perturbations\n    delta_x = np.array([50.0, -50.0, -20.0, np.deg2rad(5)])\n    P0_diag = np.array([100.0**2, 100.0**2, 25.0**2, np.deg2rad(10.0)**2])\n    P0 = np.diag(P0_diag)\n\n    for case in test_cases:\n        # Setup case parameters\n        dt, N, omega = case['dt'], case['N'], case['omega']\n        x0_true = case['x0_true']\n\n        # Initial conditions for filters\n        x0 = x0_true + delta_x\n        x0[3] = normalize_angle(x0[3])\n        \n        # Process Noise Covariance Q\n        Q_diag = np.array([\n            case['sigma_q_p']**2, \n            case['sigma_q_p']**2, \n            case['sigma_q_v']**2, \n            np.deg2rad(case['sigma_q_psi_deg'])**2\n        ])\n        Q = np.diag(Q_diag)\n\n        # Measurement Noise Covariance R\n        R_diag = np.array([\n            case['sigma_r']**2, \n            np.deg2rad(case['sigma_theta_deg'])**2\n        ])\n        R = np.diag(R_diag)\n        \n        # Generate data\n        rng = np.random.default_rng(42)\n        truth_history = np.zeros((N, 4))\n        measurements = np.zeros((N, 2))\n        \n        x_true = x0_true.copy()\n        for k in range(N):\n            # The problem states to use the true state from the previous step k to generate z_k\n            # and the true state for k+1. Let's start with x0_true for z_0, then evolve.\n            # But the problem asks for posterior for k=1..N, so we need N measurements starting from x1_true.\n            # So, we first evolve the state from x0_true to x1_true, then generate z1, and so on.\n            x_true = state_transition_function(x_true, dt, omega)\n            x_true[3] = normalize_angle(x_true[3])\n            truth_history[k] = x_true\n\n            # Generate noisy measurement\n            z_true = measurement_function(x_true)\n            v_k = rng.multivariate_normal([0, 0], R)\n            measurements[k] = z_true + v_k\n            measurements[k, 1] = normalize_angle(measurements[k, 1])\n\n        # Run filters\n        ekf_history = run_ekf(measurements, x0, P0, Q, R, dt, omega, N)\n        ukf_history = run_ukf(measurements, x0, P0, Q, R, dt, omega, N)\n        \n        # Calculate performance metrics\n        rmse_ekf = calculate_rmse(ekf_history, truth_history)\n        rmse_ukf = calculate_rmse(ukf_history, truth_history)\n        rho = rmse_ukf / rmse_ekf if rmse_ekf != 0 else float('inf')\n        \n        all_results.extend([rmse_ekf, rmse_ukf, rho])\n\n    # Final print statement\n    print(f\"[{','.join(f'{x:.6f}' for x in all_results)}]\")\n\nsolve()\n```"
        }
    ]
}