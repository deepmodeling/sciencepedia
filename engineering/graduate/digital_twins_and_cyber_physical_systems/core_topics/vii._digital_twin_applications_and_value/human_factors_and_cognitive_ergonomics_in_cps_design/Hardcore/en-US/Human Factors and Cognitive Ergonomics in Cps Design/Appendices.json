{
    "hands_on_practices": [
        {
            "introduction": "The design of effective human-machine interfaces is a cornerstone of cognitive ergonomics. This practice grounds your understanding of interface design in the quantitative principles of human motor control using Fitts's Law. By applying this foundational model, you will predict how changes to the size of an interactive element, like a button on a touchscreen, affect the time it takes for an operator to select it, providing a crucial tool for designing efficient and user-friendly supervisory control panels. ",
            "id": "4226397",
            "problem": "A human factors team is engineering a supervisory control interface for a Digital Twin (DT) of a Cyber-Physical System (CPS) that supports high-stakes, time-critical selections on a touchscreen. To predict operator motor performance in this Human-Computer Interaction (HCI) context, the team uses the well-tested Fitts’ law model from empirically grounded motor control research. For a given operator-device combination in the target environment, the calibrated Shannon-form Fitts’ law for movement time is\n$$\nMT \\;=\\; a \\;+\\; b \\,\\log_{2}\\!\\left(\\frac{2A}{W}\\right),\n$$\nwhere $MT$ is movement time, $A$ is the movement amplitude, and $W$ is the effective target width.\n\nIn a representative task, the amplitude is $A = 200$ pixels (px) and the button width is $W = 20$ px. The measured intercept and slope are $a = 50$ milliseconds (ms) and $b = 100$ ms. Assume the operator and device remain unchanged across conditions and that the Shannon formulation and the properties of logarithms apply.\n\nTasks:\n1) Starting from the stated Fitts’ law and using properties of the logarithm, derive a closed-form symbolic expression for the change in movement time when the target width $W$ is scaled by a positive factor $s$ (that is, when $W$ is replaced by $sW$), holding $A$, $a$, and $b$ constant.\n2) Using your expression, evaluate the absolute reduction in movement time when the width doubles from $W = 20$ px to $W' = 40$ px in this interface, with $A = 200$ px, $a = 50$ ms, and $b = 100$ ms.\n\nReport only the absolute reduction in movement time for the doubling of $W$ in milliseconds. Round your answer to four significant figures. Express the final result in ms.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in Fitts' law, a foundational model in human-computer interaction and motor control. The problem is well-posed, providing a clear objective, all necessary parameters, and a consistent mathematical framework. There are no contradictions, ambiguities, or factual inaccuracies.\n\nThe solution proceeds in two parts as requested.\n\nPart 1: Derivation of the symbolic expression for the change in movement time ($\\Delta MT$).\n\nLet the initial movement time be $MT_1$ for a target of width $W$. According to the given Shannon-form of Fitts' law:\n$$\nMT_1 = a + b \\log_{2}\\left(\\frac{2A}{W}\\right)\n$$\nWhen the target width $W$ is scaled by a positive factor $s$, the new width is $sW$. The new movement time, $MT_2$, is given by:\n$$\nMT_2 = a + b \\log_{2}\\left(\\frac{2A}{sW}\\right)\n$$\nThe change in movement time, $\\Delta MT$, is the difference between the new movement time and the initial movement time:\n$$\n\\Delta MT = MT_2 - MT_1\n$$\nSubstituting the expressions for $MT_1$ and $MT_2$:\n$$\n\\Delta MT = \\left[a + b \\log_{2}\\left(\\frac{2A}{sW}\\right)\\right] - \\left[a + b \\log_{2}\\left(\\frac{2A}{W}\\right)\\right]\n$$\nThe intercept term $a$ cancels out:\n$$\n\\Delta MT = b \\log_{2}\\left(\\frac{2A}{sW}\\right) - b \\log_{2}\\left(\\frac{2A}{W}\\right)\n$$\nFactoring out the slope term $b$:\n$$\n\\Delta MT = b \\left[ \\log_{2}\\left(\\frac{2A}{sW}\\right) - \\log_{2}\\left(\\frac{2A}{W}\\right) \\right]\n$$\nUsing the property of logarithms, $\\log_{c}(x) - \\log_{c}(y) = \\log_{c}\\left(\\frac{x}{y}\\right)$, we can combine the two logarithmic terms:\n$$\n\\Delta MT = b \\log_{2}\\left( \\frac{\\frac{2A}{sW}}{\\frac{2A}{W}} \\right)\n$$\nSimplifying the fraction inside the logarithm:\n$$\n\\frac{\\frac{2A}{sW}}{\\frac{2A}{W}} = \\frac{2A}{sW} \\cdot \\frac{W}{2A} = \\frac{1}{s}\n$$\nSubstituting this back into the expression for $\\Delta MT$:\n$$\n\\Delta MT = b \\log_{2}\\left(\\frac{1}{s}\\right)\n$$\nUsing another property of logarithms, $\\log_{c}\\left(\\frac{1}{x}\\right) = -\\log_{c}(x)$, we arrive at the final closed-form symbolic expression for the change in movement time:\n$$\n\\Delta MT = -b \\log_{2}(s)\n$$\n\nPart 2: Evaluation of the absolute reduction in movement time.\n\nThe problem states that the target width doubles from $W = 20$ px to $W' = 40$ px. The scaling factor $s$ is the ratio of the new width to the initial width:\n$$\ns = \\frac{W'}{W} = \\frac{40}{20} = 2\n$$\nThe given value for the slope coefficient is $b = 100$ ms. We can now substitute these values into the derived expression for $\\Delta MT$:\n$$\n\\Delta MT = -(100) \\log_{2}(2)\n$$\nBy the definition of the base-$2$ logarithm, $\\log_{2}(2) = 1$. Therefore:\n$$\n\\Delta MT = -(100) \\times 1 = -100 \\text{ ms}\n$$\nThe negative sign indicates that the movement time has decreased, which is a reduction. The problem asks for the absolute reduction in movement time, which is the magnitude of this change:\n$$\n|\\Delta MT| = |-100| = 100 \\text{ ms}\n$$\nThe problem requires the answer to be rounded to four significant figures. To express the exact integer $100$ with four significant figures, we write it as $100.0$.\nThe absolute reduction in movement time is therefore $100.0$ ms. Note that this result depends only on the scaling factor $s$ and the coefficient $b$, and is independent of the amplitude $A$ and the initial width $W$, as demonstrated by the symbolic derivation.",
            "answer": "$$\\boxed{100.0}$$"
        },
        {
            "introduction": "A central challenge in designing cyber-physical systems is determining the optimal allocation of control between the human operator and automation. This exercise introduces a formal approach to this problem using risk analysis and optimization, balancing the reliability of automation against the potential for rare but catastrophic failures. You will construct an expected harm model and use it to find the ideal level of automation, a critical skill in the design of safety-critical systems. ",
            "id": "4226414",
            "problem": "A supervisory control decision must be made for a safety-critical Cyber-Physical System (CPS) supported by a Digital Twin (DT). The system must execute a repetitive task where human operators and automated controllers can share control. Let the stage of automation be represented by a continuous allocation variable $a \\in [0,1]$, where $a$ denotes the fraction of control authority assigned to automation and $1-a$ denotes the fraction of control authority assigned to the human operator. The following empirically observed rates apply when either agent has full control: the human’s non-catastrophic task error probability is $p_{h} = 0.05$, and the automation’s non-catastrophic task error probability is $p_{a} = 0.02$. In addition, when automation is engaged, there exists a small probability of catastrophic automation failure per task, $p_{\\mathrm{cat}} = 0.005$.\n\nAssume the following scientifically standard modeling assumptions grounded in risk and expected value:\n1. The per-task expected non-catastrophic error probability under shared control is the convex combination $p_{\\mathrm{nc}}(a) = (1-a)p_{h} + a p_{a}$, reflecting proportional influence of each agent’s contribution to control.\n2. Catastrophic automation failures are only possible when automation is engaged. Due to socio-technical coupling and mode-dependence in highly automated CPS, model the engagement-dependent catastrophic failure probability as $p_{\\mathrm{cat}}(a) = p_{\\mathrm{cat}}a^{2}$, capturing a superlinear increase in catastrophic risk with increasing automation engagement.\n3. Let the harm of a non-catastrophic error be normalized to $s_{e} = 1$ harm unit, and let the harm of a catastrophic failure be $s_{c} = 100$ harm units, reflecting an order-of-magnitude difference in consequence severity commonly used in safety engineering.\n\nUsing the fundamental definition of expected harm per task $E[H(a)] = \\sum (\\text{probability}) \\times (\\text{consequence})$, construct $E[H(a)]$ from these components and determine the value $a^{\\star} \\in [0,1]$ that minimizes $E[H(a)]$. Express $a^{\\star}$ as a dimensionless fraction. Round your final answer to three significant figures.",
            "solution": "The problem statement is first subjected to validation.\n\n### Step 1: Extract Givens\n- Control allocation variable: $a \\in [0,1]$, where $a$ is the fraction of automation control and $1-a$ is the fraction of human control.\n- Human non-catastrophic error probability (full control): $p_{h} = 0.05$.\n- Automation non-catastrophic error probability (full control): $p_{a} = 0.02$.\n- Base catastrophic automation failure probability: $p_{\\mathrm{cat}} = 0.005$.\n- Non-catastrophic error probability under shared control: $p_{\\mathrm{nc}}(a) = (1-a)p_{h} + a p_{a}$.\n- Catastrophic failure probability under shared control: $p_{\\mathrm{cat}}(a) = p_{\\mathrm{cat}}a^{2}$.\n- Harm of a non-catastrophic error: $s_{e} = 1$.\n- Harm of a catastrophic failure: $s_{c} = 100$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It is based on the standard principles of risk assessment and optimization used in safety engineering and human-factors engineering.\n- The use of expected harm, $E[H] = \\sum P(\\text{event}) \\times C(\\text{event})$, is a fundamental concept in decision theory and risk analysis.\n- The model for non-catastrophic error, $p_{\\mathrm{nc}}(a)$, as a convex combination of human and automation error rates is a standard and simple model for shared control.\n- The model for catastrophic risk, $p_{\\mathrm{cat}}(a) = p_{\\mathrm{cat}} a^{2}$, is a plausible phenomenological model representing the superlinear increase in risk that can accompany increasing levels of automation complexity and coupling in socio-technical systems.\n- The problem is self-contained, providing all necessary data and relationships. All terms are defined quantitatively and unambiguously. It is a well-posed optimization problem of finding the minimum of a continuous function on a compact set.\nThe problem does not violate any of the invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be derived.\n\nThe objective is to find the value of the automation allocation variable $a$, denoted $a^{\\star}$, within the interval $[0,1]$ that minimizes the total expected harm per task, $E[H(a)]$.\n\nThe total expected harm per task is the sum of the expected harm from non-catastrophic errors and the expected harm from catastrophic failures. Following the principle of expected value, this is given by:\n$$E[H(a)] = p_{\\mathrm{nc}}(a) s_{e} + p_{\\mathrm{cat}}(a) s_{c}$$\nSubstituting the given models for the probabilities:\n$$E[H(a)] = \\left( (1-a)p_{h} + a p_{a} \\right) s_{e} + (p_{\\mathrm{cat}} a^{2}) s_{c}$$\nThis is the objective function to be minimized. We can expand and rearrange this expression as a quadratic function of $a$:\n$$E[H(a)] = (p_{h} - a p_{h} + a p_{a}) s_{e} + p_{\\mathrm{cat}} s_{c} a^{2}$$\n$$E[H(a)] = (p_{\\mathrm{cat}} s_{c}) a^{2} + (p_{a} - p_{h}) s_{e} a + p_{h} s_{e}$$\nThis is a standard quadratic function of the form $f(a) = A a^{2} + B a + C$, where $A = p_{\\mathrm{cat}} s_{c}$, $B = (p_{a} - p_{h}) s_{e}$, and $C = p_{h} s_{e}$.\n\nTo find the value of $a$ that minimizes this function, we employ differential calculus. We take the first derivative of $E[H(a)]$ with respect to $a$ and set it to zero to find the critical points.\n$$\\frac{dE[H(a)]}{da} = \\frac{d}{da} \\left( (p_{\\mathrm{cat}} s_{c}) a^{2} + (p_{a} - p_{h}) s_{e} a + p_{h} s_{e} \\right)$$\n$$\\frac{dE[H(a)]}{da} = 2 (p_{\\mathrm{cat}} s_{c}) a + (p_{a} - p_{h}) s_{e}$$\nSetting the derivative to zero gives the critical point, which we denote as $a_{\\mathrm{crit}}$:\n$$2 (p_{\\mathrm{cat}} s_{c}) a_{\\mathrm{crit}} + (p_{a} - p_{h}) s_{e} = 0$$\nSolving for $a_{\\mathrm{crit}}$:\n$$a_{\\mathrm{crit}} = - \\frac{(p_{a} - p_{h}) s_{e}}{2 p_{\\mathrm{cat}} s_{c}} = \\frac{(p_{h} - p_{a}) s_{e}}{2 p_{\\mathrm{cat}} s_{c}}$$\nTo confirm that this critical point corresponds to a minimum, we evaluate the second derivative:\n$$\\frac{d^{2}E[H(a)]}{da^{2}} = 2 p_{\\mathrm{cat}} s_{c}$$\nGiven that $p_{\\mathrm{cat}} = 0.005 > 0$ and $s_{c} = 100 > 0$, the second derivative is positive. This confirms that $E[H(a)]$ is a convex function (an upward-opening parabola), and thus $a_{\\mathrm{crit}}$ is the global minimum of the function.\n\nThe optimal allocation level, $a^{\\star}$, must lie within the specified domain $[0,1]$. We must check if $a_{\\mathrm{crit}}$ falls within this interval.\n$$a_{\\mathrm{crit}} = \\frac{(p_{h} - p_{a}) s_{e}}{2 p_{\\mathrm{cat}} s_{c}}$$\nGiven $p_{h} > p_{a}$, the numerator is positive. The denominator is also positive. Thus, $a_{\\mathrm{crit}} > 0$. The minimum of $E[H(a)]$ on the interval $[0,1]$ is at $a^{\\star}$, where:\n- $a^{\\star} = 0$ if $a_{\\mathrm{crit}} \\le 0$.\n- $a^{\\star} = a_{\\mathrm{crit}}$ if $0  a_{\\mathrm{crit}}  1$.\n- $a^{\\star} = 1$ if $a_{\\mathrm{crit}} \\ge 1$.\n\nNow, we substitute the provided numerical values into the expression for $a_{\\mathrm{crit}}$:\n$p_{h} = 0.05$\n$p_{a} = 0.02$\n$p_{\\mathrm{cat}} = 0.005$\n$s_{e} = 1$\n$s_{c} = 100$\n\n$$a_{\\mathrm{crit}} = \\frac{(0.05 - 0.02) \\times 1}{2 \\times 0.005 \\times 100}$$\n$$a_{\\mathrm{crit}} = \\frac{0.03}{2 \\times 0.5}$$\n$$a_{\\mathrm{crit}} = \\frac{0.03}{1}$$\n$$a_{\\mathrm{crit}} = 0.03$$\nThe calculated value $a_{\\mathrm{crit}} = 0.03$ is within the interval $[0,1]$. Therefore, the optimal level of automation that minimizes expected harm is $a^{\\star} = 0.03$.\n\nThe problem requires the answer to be rounded to three significant figures. The number $0.03$ has one significant figure. To express this value with three significant figures, we write it as $0.0300$.",
            "answer": "$$\n\\boxed{0.0300}\n$$"
        },
        {
            "introduction": "Beyond performance and safety, a critical metric for any CPS design is the cognitive workload it imposes on the human operator. This practice provides hands-on experience with the NASA Task Load Index (NASA-TLX), a gold-standard psychometric tool for assessing subjective workload. By calculating a weighted workload score from operator ratings, you will learn how to quantify this crucial human factor and analyze the system's sensitivity to different sources of cognitive demand. ",
            "id": "4226354",
            "problem": "A human operator supervises a Cyber-Physical System (CPS) that controls a multi-robot assembly cell through a Digital Twin interface. To quantify cognitive ergonomics and human factors under this supervisory control, the operator completes the NASA Task Load Index (NASA-TLX), consisting of six subscales: Mental Demand, Physical Demand, Temporal Demand, Performance, Effort, and Frustration. Each subscale receives a raw rating on a $0$ to $100$ continuum and a weight derived from pairwise comparisons, where the weights reflect the relative contribution of each subscale to perceived workload. Assume that the pairwise-comparison weights sum to the total number of pairwise judgments, which for six subscales is $15$, and that the Performance rating scale is interpreted such that higher values indicate poorer performance and therefore increased workload contribution.\n\nThe operator’s raw ratings and pairwise-comparison weights are:\n- Mental Demand: rating $= 68$, weight $= 5$.\n- Physical Demand: rating $= 30$, weight $= 1$.\n- Temporal Demand: rating $= 55$, weight $= 4$.\n- Performance: rating $= 45$, weight $= 2$.\n- Effort: rating $= 70$, weight $= 2$.\n- Frustration: rating $= 40$, weight $= 1$.\n\nStarting from first principles of multi-attribute aggregation in psychometrics and decision science, where a composite score is formed by a normalized linear combination of the attributes proportional to their weights, derive the expression for the overall workload score consistent with NASA-TLX’s weighted methodology, compute its value for the given data, and justify the role of normalization. Then, treating the overall workload as a differentiable function of the Temporal Demand rating while holding all other subscale ratings and weights fixed, interpret the sensitivity to a $10\\%$ increase in Temporal Demand in terms of its first-order effect, and compute the new overall workload score after this $10\\%$ increase in the Temporal Demand rating.\n\nRound the reported new overall workload score to four significant figures. Express the final workload score as a unitless number.",
            "solution": "The problem is well-posed and scientifically grounded within the domain of psychometrics and human factors engineering. All necessary data are provided, and the methodology described is consistent with the standard procedure for calculating the NASA Task Load Index (NASA-TLX) weighted score. Therefore, a solution can be derived.\n\nLet the set of six NASA-TLX subscales be indexed by $i$, where $i \\in \\{\\text{MD, PD, TD, P, E, F}\\}$. For each subscale $i$, we are given a raw rating, $R_i$, on a continuum from $0$ to $100$, and a pairwise-comparison weight, $w_i$. The problem states that the sum of the weights is equal to the total number of pairwise judgments for six subscales, which is $\\binom{6}{2} = \\frac{6 \\times (6-1)}{2} = 15$. We can verify the sum of the given weights: $w_{\\text{MD}} + w_{\\text{PD}} + w_{\\text{TD}} + w_{\\text{P}} + w_{\\text{E}} + w_{\\text{F}} = 5 + 1 + 4 + 2 + 2 + 1 = 15$.\n\nThe first principle of multi-attribute aggregation, as stated in the problem, is to form a composite score via a normalized linear combination of the attributes, proportional to their weights. This corresponds to a weighted average. The overall workload score, which we denote as $W$, is calculated by first multiplying each subscale rating $R_i$ by its corresponding weight $w_i$, summing these products, and then normalizing this sum.\n\nThe expression for the overall workload score $W$ is:\n$$ W = \\frac{\\sum_{i} R_i w_i}{\\sum_{i} w_i} $$\nThe role of normalization, achieved by dividing by the sum of the weights $\\sum_i w_i$, is crucial. It transforms the aggregated score (which would otherwise be in the range of $0$ to $100 \\times 15 = 1500$) into an average. This brings the final score back to a scale that is conceptually aligned with the original $0$ to $100$ rating scale, making it more interpretable. Normalization ensures that the score represents the average weighted rating, independent of the total number of pairwise comparisons used to generate the weights.\n\nWe now compute the initial overall workload score, $W_{\\text{initial}}$, using the provided data:\n- Mental Demand: $R_{\\text{MD}} = 68$, $w_{\\text{MD}} = 5$.\n- Physical Demand: $R_{\\text{PD}} = 30$, $w_{\\text{PD}} = 1$.\n- Temporal Demand: $R_{\\text{TD}} = 55$, $w_{\\text{TD}} = 4$.\n- Performance: $R_{\\text{P}} = 45$, $w_{\\text{P}} = 2$.\n- Effort: $R_{\\text{E}} = 70$, $w_{\\text{E}} = 2$.\n- Frustration: $R_{\\text{F}} = 40$, $w_{\\text{F}} = 1$.\n\nThe sum of the products $R_i w_i$ is:\n$$ \\sum_{i} R_i w_i = (68)(5) + (30)(1) + (55)(4) + (45)(2) + (70)(2) + (40)(1) $$\n$$ \\sum_{i} R_i w_i = 340 + 30 + 220 + 90 + 140 + 40 = 860 $$\nThe sum of the weights is $\\sum_i w_i = 15$.\nTherefore, the initial workload score is:\n$$ W_{\\text{initial}} = \\frac{860}{15} = \\frac{172}{3} \\approx 57.333... $$\n\nNext, we analyze the sensitivity of the workload score $W$ to a change in the Temporal Demand rating, $R_{\\text{TD}}$, while all other ratings and all weights are held constant. We can express $W$ as a function of $R_{\\text{TD}}$:\n$$ W(R_{\\text{TD}}) = \\frac{ (R_{\\text{MD}}w_{\\text{MD}} + R_{\\text{PD}}w_{\\text{PD}} + R_{\\text{P}}w_{\\text{P}} + R_{\\text{E}}w_{\\text{E}} + R_{\\text{F}}w_{\\text{F}}) + R_{\\text{TD}}w_{\\text{TD}} }{\\sum_i w_i} $$\nLet $C = R_{\\text{MD}}w_{\\text{MD}} + R_{\\text{PD}}w_{\\text{PD}} + R_{\\text{P}}w_{\\text{P}} + R_{\\text{E}}w_{\\text{E}} + R_{\\text{F}}w_{\\text{F}}$ be the constant part of the numerator.\n$$ W(R_{\\text{TD}}) = \\frac{C + R_{\\text{TD}}w_{\\text{TD}}}{\\sum_i w_i} $$\nTo find the sensitivity, we compute the partial derivative of $W$ with respect to $R_{\\text{TD}}$:\n$$ \\frac{\\partial W}{\\partial R_{\\text{TD}}} = \\frac{d}{d R_{\\text{TD}}} \\left( \\frac{C}{\\sum_i w_i} + \\frac{w_{\\text{TD}}}{\\sum_i w_i} R_{\\text{TD}} \\right) = \\frac{w_{\\text{TD}}}{\\sum_i w_i} $$\nSubstituting the values $w_{\\text{TD}} = 4$ and $\\sum_i w_i = 15$:\n$$ \\frac{\\partial W}{\\partial R_{\\text{TD}}} = \\frac{4}{15} $$\nThis derivative represents the rate of change of the overall workload score with respect to the Temporal Demand rating. It indicates that for every 1-point increase in $R_{\\text{TD}}$, the overall workload score $W$ increases by exactly $\\frac{4}{15}$ points.\n\nWe are asked to interpret the first-order effect of a $10\\%$ increase in Temporal Demand. The initial rating is $R_{\\text{TD}} = 55$. The increase is:\n$$ \\Delta R_{\\text{TD}} = 0.10 \\times 55 = 5.5 $$\nThe first-order approximation for the change in the workload score, $\\Delta W$, is given by:\n$$ \\Delta W \\approx \\frac{\\partial W}{\\partial R_{\\text{TD}}} \\Delta R_{\\text{TD}} $$\n$$ \\Delta W \\approx \\frac{4}{15} \\times 5.5 = \\frac{4}{15} \\times \\frac{11}{2} = \\frac{22}{15} $$\nBecause the function $W(R_{\\text{TD}})$ is linear in $R_{\\text{TD}}$, this first-order effect is not an approximation but the exact change. The interpretation is that a $10\\%$ increase in the Temporal Demand rating (from $55$ to $60.5$) will cause the overall workload score to increase by exactly $\\frac{22}{15} \\approx 1.47$ points.\n\nFinally, we compute the new overall workload score, $W_{\\text{new}}$, after this increase. The new Temporal Demand rating is:\n$$ R_{\\text{TD, new}} = R_{\\text{TD, initial}} + \\Delta R_{\\text{TD}} = 55 + 5.5 = 60.5 $$\nWe can calculate the new score by either adding the change $\\Delta W$ to the initial score $W_{\\text{initial}}$ or by re-evaluating the formula with the new rating $R_{\\text{TD, new}}$. The latter is more direct.\nThe new sum of products is the original sum plus the change caused by the increase in $R_{\\text{TD}}$:\n$$ \\sum_{i} R_i w_i \\big|_{\\text{new}} = \\sum_{i} R_i w_i \\big|_{\\text{initial}} + (\\Delta R_{\\text{TD}}) \\times w_{\\text{TD}} = 860 + (5.5)(4) = 860 + 22 = 882 $$\nThe new overall workload score is:\n$$ W_{\\text{new}} = \\frac{882}{15} = \\frac{294}{5} = 58.8 $$\nThe problem requires this value to be rounded to four significant figures.\n$$ W_{\\text{new}} = 58.80 $$\nThis score is a unitless number, as it represents a normalized rating.",
            "answer": "$$ \\boxed{58.80} $$"
        }
    ]
}