{
    "hands_on_practices": [
        {
            "introduction": "The first and most fundamental step in creating a compelling Augmented Reality experience is registering virtual content with the physical world. This practice guides you through the cornerstone algorithm for this task: point set registration. By deriving the optimal rigid-body transformation ($T_{\\mathcal{W}\\mathcal{T}}$) that aligns a digital twin's model to physical landmarks from first principles, you will master a crucial technique used across robotics and computer vision. This exercise builds the mathematical foundation for all subsequent alignment and tracking tasks by solving the least-squares problem using Singular Value Decomposition (SVD) .",
            "id": "4206803",
            "problem": "In an Augmented Reality (AR) and Virtual Reality (VR) interface for a digital twin, a headset tracks physical fiducial markers in the world coordinate frame $\\mathcal{W}$ and renders a virtual mesh in the twin coordinate frame $\\mathcal{T}$. To overlay the twin accurately onto the physical scene, one estimates a rigid body transformation $T_{\\mathcal{W}\\mathcal{T}} \\in \\mathrm{SE}(3)$ that maps points from $\\mathcal{T}$ to $\\mathcal{W}$. Suppose you are given $n \\geq 3$ known correspondences $\\{(x_i^{\\mathcal{W}}, x_i^{\\mathcal{T}})\\}_{i=1}^{n}$, where each $x_i^{\\mathcal{W}} \\in \\mathbb{R}^{3}$ is a fiducial location measured in $\\mathcal{W}$ and each $x_i^{\\mathcal{T}} \\in \\mathbb{R}^{3}$ is the location of the corresponding vertex in the twin’s mesh in $\\mathcal{T}$. The measurement model is $x_i^{\\mathcal{W}} = R x_i^{\\mathcal{T}} + t + \\varepsilon_i$, where $R \\in \\mathrm{SO}(3)$, $t \\in \\mathbb{R}^{3}$, and the noise $\\varepsilon_i$ is zero-mean with finite second moment, independent across $i$, and independent of $x_i^{\\mathcal{T}}$. You may assume the correspondences are correct and fixed.\n\nStarting from the constrained least-squares formulation built on the Euclidean norm and the rigid-body constraints, derive, from first principles, a closed-form analytic expression for the least-squares estimator $\\hat{T}_{\\mathcal{W}\\mathcal{T}}$ in terms of the given correspondences. You must:\n- Begin from the definitions of a rigid transformation, the Euclidean norm, and basic matrix identities, and proceed by logically eliminating the translation and reducing the rotation subproblem to an optimization over $\\mathrm{SO}(3)$ that can be solved using singular value decomposition.\n- Clearly show the derivation steps that lead to the final analytic form of the estimator.\n- State the minimal assumptions required for identifiability and uniqueness of the solution in $\\mathrm{SE}(3)$.\n\nExpress your final answer as a single closed-form analytic expression for $\\hat{T}_{\\mathcal{W}\\mathcal{T}}$ using $4 \\times 4$ homogeneous coordinates. No numerical rounding is required.",
            "solution": "The problem requires the derivation of the closed-form least-squares estimator for a rigid body transformation $T_{\\mathcal{W}\\mathcal{T}} \\in \\mathrm{SE}(3)$ between two sets of $n$ corresponding $3$D points, $\\{(x_i^{\\mathcal{W}}, x_i^{\\mathcal{T}})\\}_{i=1}^{n}$. The transformation maps points from the twin coordinate frame $\\mathcal{T}$ to the world coordinate frame $\\mathcal{W}$.\n\nA rigid body transformation is composed of a rotation $R \\in \\mathrm{SO}(3)$ and a translation $t \\in \\mathbb{R}^{3}$. A point $x^{\\mathcal{T}}$ is mapped to $x^{\\mathcal{W}}$ by the rule $x^{\\mathcal{W}} = R x^{\\mathcal{T}} + t$. Given the measurement model $x_i^{\\mathcal{W}} = R x_i^{\\mathcal{T}} + t + \\varepsilon_i$, the least-squares estimation problem seeks to find the transformation $(\\hat{R}, \\hat{t})$ that minimizes the sum of squared Euclidean norms of the residuals. The objective function $E(R, t)$ is:\n$$E(R, t) = \\sum_{i=1}^{n} \\| x_i^{\\mathcal{W}} - (R x_i^{\\mathcal{T}} + t) \\|^2$$\nThis optimization is constrained by the condition that $R$ must be a proper rotation matrix, i.e., $R \\in \\mathrm{SO}(3)$, which means $R^T R = I$ and $\\det(R) = +1$, where $I$ is the $3 \\times 3$ identity matrix.\n\nThe derivation proceeds in two main stages: first, we solve for the translation $t$, and second, we solve for the rotation $R$.\n\nFirst, we find the optimal translation $\\hat{t}$ by minimizing $E(R, t)$ with respect to $t$ for a fixed $R$. We compute the partial derivative of $E(R, t)$ with respect to $t$ and set it to zero.\n$$ \\frac{\\partial E}{\\partial t} = \\frac{\\partial}{\\partial t} \\sum_{i=1}^{n} (x_i^{\\mathcal{W}} - R x_i^{\\mathcal{T}} - t)^T (x_i^{\\mathcal{W}} - R x_i^{\\mathcal{T}} - t) = 0 $$\n$$ \\sum_{i=1}^{n} -2(x_i^{\\mathcal{W}} - R x_i^{\\mathcal{T}} - t) = 0 $$\n$$ \\sum_{i=1}^{n} t = \\sum_{i=1}^{n} (x_i^{\\mathcal{W}} - R x_i^{\\mathcal{T}}) $$\n$$ n t = \\sum_{i=1}^{n} x_i^{\\mathcal{W}} - R \\sum_{i=1}^{n} x_i^{\\mathcal{T}} $$\nLet us define the centroids of the two point sets as $\\bar{x}^{\\mathcal{W}} = \\frac{1}{n}\\sum_{i=1}^{n} x_i^{\\mathcal{W}}$ and $\\bar{x}^{\\mathcal{T}} = \\frac{1}{n}\\sum_{i=1}^{n} x_i^{\\mathcal{T}}$. The optimal translation $\\hat{t}$ can then be expressed as a function of the rotation $R$:\n$$ \\hat{t} = \\bar{x}^{\\mathcal{W}} - R \\bar{x}^{\\mathcal{T}} $$\nThis result shows that the centroid of the transformed points $R x_i^{\\mathcal{T}}$ plus the translation must align with the centroid of the measured points $x_i^{\\mathcal{W}}$.\n\nNext, we substitute this expression for $\\hat{t}$ back into the objective function to obtain a problem that depends only on $R$.\n$$ x_i^{\\mathcal{W}} - (R x_i^{\\mathcal{T}} + \\hat{t}) = x_i^{\\mathcal{W}} - (R x_i^{\\mathcal{T}} + \\bar{x}^{\\mathcal{W}} - R \\bar{x}^{\\mathcal{T}}) $$\n$$ = (x_i^{\\mathcal{W}} - \\bar{x}^{\\mathcal{W}}) - R(x_i^{\\mathcal{T}} - \\bar{x}^{\\mathcal{T}}) $$\nLet us define the centered coordinates for each point set: $y'_i = x_i^{\\mathcal{W}} - \\bar{x}^{\\mathcal{W}}$ and $x'_i = x_i^{\\mathcal{T}} - \\bar{x}^{\\mathcal{T}}$. The objective function becomes:\n$$ E(R) = \\sum_{i=1}^{n} \\| y'_i - R x'_i \\|^2 $$\nWe must find the rotation $\\hat{R}$ that minimizes this new objective function. Let's expand the squared norm:\n$$ E(R) = \\sum_{i=1}^{n} (y'_i - R x'_i)^T (y'_i - R x'_i) $$\n$$ = \\sum_{i=1}^{n} ((y'_i)^T y'_i - (y'_i)^T R x'_i - (R x'_i)^T y'_i + (R x'_i)^T R x'_i) $$\nSince $(y'_i)^T R x'_i$ is a scalar, it is equal to its transpose $(R x'_i)^T y'_i$. Also, since $R \\in \\mathrm{SO}(3)$, we have $R^T R = I$, so $(R x'_i)^T R x'_i = (x'_i)^T R^T R x'_i = (x'_i)^T I x'_i = (x'_i)^T x'_i$. The expression simplifies to:\n$$ E(R) = \\sum_{i=1}^{n} (\\|y'_i\\|^2 + \\|x'_i\\|^2 - 2 (y'_i)^T R x'_i) $$\nThe terms $\\sum_{i=1}^{n} \\|y'_i\\|^2$ and $\\sum_{i=1}^{n} \\|x'_i\\|^2$ do not depend on $R$. Therefore, minimizing $E(R)$ is equivalent to maximizing the term $\\sum_{i=1}^{n} (y'_i)^T R x'_i$.\nUsing the trace operator, and its cyclic property $\\mathrm{Tr}(ABC) = \\mathrm{Tr}(BCA)$, we can rewrite the objective. Since $(y'_i)^T R x'_i$ is a scalar ($1 \\times 1$ matrix), it is equal to its own trace.\n$$ \\sum_{i=1}^{n} (y'_i)^T R x'_i = \\sum_{i=1}^{n} \\mathrm{Tr}((y'_i)^T R x'_i) = \\sum_{i=1}^{n} \\mathrm{Tr}(R x'_i (y'_i)^T) $$\nBy linearity of the trace, this is:\n$$ \\mathrm{Tr} \\left( R \\sum_{i=1}^{n} x'_i (y'_i)^T \\right) $$\nLet us define the $3 \\times 3$ covariance matrix $H = \\sum_{i=1}^{n} x'_i (y'_i)^T$. The rotation estimation problem is now reduced to:\n$$ \\hat{R} = \\arg\\max_{R \\in \\mathrm{SO}(3)} \\mathrm{Tr}(R H) $$\nTo solve this maximization, we use the Singular Value Decomposition (SVD) of $H$. Let $H = U \\Sigma V^T$, where $U, V \\in \\mathrm{O}(3)$ are orthogonal matrices and $\\Sigma = \\mathrm{diag}(\\sigma_1, \\sigma_2, \\sigma_3)$ is a diagonal matrix of non-negative singular values, ordered $\\sigma_1 \\geq \\sigma_2 \\geq \\sigma_3 \\geq 0$.\nSubstituting the SVD of $H$ into the trace expression:\n$$ \\mathrm{Tr}(R H) = \\mathrm{Tr}(R U \\Sigma V^T) $$\nUsing the cyclic property of the trace again:\n$$ \\mathrm{Tr}(R U \\Sigma V^T) = \\mathrm{Tr}(\\Sigma V^T R U) $$\nLet $M = V^T R U$. Since $V^T$, $R$, and $U$ are orthogonal matrices, their product $M$ is also an orthogonal matrix ($M \\in \\mathrm{O}(3)$). The problem is to maximize $\\mathrm{Tr}(\\Sigma M) = \\sum_{j=1}^{3} \\sigma_j M_{jj}$. Since $M$ is orthogonal, its column vectors are unit vectors, which implies that its elements satisfy $|M_{jk}| \\leq 1$. To maximize this sum with non-negative $\\sigma_j$, we need to make the diagonal elements $M_{jj}$ as large as possible. The largest possible value for each $M_{jj}$ is $1$, which occurs if $M$ is the identity matrix, $M = I$.\nIf $M = I$, then $V^T \\hat{R} U = I$, which gives a candidate solution for the rotation:\n$$ \\hat{R} = V I U^T = V U^T $$\nHowever, we must satisfy the constraint that $\\hat{R} \\in \\mathrm{SO}(3)$, which requires $\\det(\\hat{R}) = +1$. The SVD matrices $U$ and $V$ are in $\\mathrm{O}(3)$, so their determinants can be either $+1$ or $-1$.\nWe have $\\det(\\hat{R}) = \\det(V U^T) = \\det(V) \\det(U^T) = \\det(V) \\det(U)$.\nIf $\\det(V)\\det(U) = +1$, then $\\hat{R} = V U^T$ is a valid rotation and is the optimal solution.\nIf $\\det(V)\\det(U) = -1$, then $\\det(\\hat{R}) = -1$. This solution represents a reflection, not a proper rotation. The true maximum over $\\mathrm{SO}(3)$ must be found. In this case, the maximum of $\\mathrm{Tr}(\\Sigma M)$ subject to $\\det(M) = -1$ is achieved when $M = \\mathrm{diag}(1, 1, -1)$, which makes the term with the smallest singular value $\\sigma_3$ negative. The trace becomes $\\sigma_1 + \\sigma_2 - \\sigma_3$, which is the maximum possible value under the reflection constraint.\nThis gives $V^T \\hat{R} U = \\mathrm{diag}(1, 1, -1)$. The corrected rotation is:\n$$ \\hat{R} = V \\, \\mathrm{diag}(1, 1, -1) \\, U^T $$\nWe can unify both cases into a single expression. Let $S = \\mathrm{diag}(1, 1, \\det(V U^T))$. Then the optimal rotation is always given by $\\hat{R} = V S U^T$.\n\nThe minimal assumptions for identifiability and uniqueness of the solution $\\hat{T}_{\\mathcal{W}\\mathcal{T}} \\in \\mathrm{SE}(3)$ are:\n$1$. The number of correspondences must be $n \\geq 3$.\n$2$. The corresponding points $\\{x_i^\\mathcal{T}\\}_{i=1}^n$ must not be collinear. If they are collinear, the covariance matrix $H$ has rank at most $1$, and the rotation cannot be determined uniquely (there is an ambiguity in rotation around the axis of collinearity). If the points are non-collinear, the transformation is unique. For a robust solution where all rotational degrees of freedom are well-constrained by the data, the points should be non-coplanar, which ensures that $H$ is full rank (rank $3$).\n\nIn summary, the closed-form solution is found via the following steps:\n$1$. Compute the centroids $\\bar{x}^{\\mathcal{T}}$ and $\\bar{x}^{\\mathcal{W}}$.\n$2$. Compute the covariance matrix $H = \\sum_{i=1}^{n} (x_i^{\\mathcal{T}} - \\bar{x}^{\\mathcal{T}})(x_i^{\\mathcal{W}} - \\bar{x}^{\\mathcal{W}})^T$.\n$3$. Perform SVD on $H$ to get $H=U \\Sigma V^T$.\n$4$. Calculate the optimal rotation $\\hat{R} = V \\, \\mathrm{diag}(1, 1, \\det(V U^T)) \\, U^T$.\n$5$. Calculate the optimal translation $\\hat{t} = \\bar{x}^{\\mathcal{W}} - \\hat{R} \\bar{x}^{\\mathcal{T}}$.\n$6$. Assemble the homogeneous transformation matrix $\\hat{T}_{\\mathcal{W}\\mathcal{T}}$.\n\nThe final expression for $\\hat{T}_{\\mathcal{W}\\mathcal{T}}$ combines these results. Let the following quantities be defined based on the input correspondences $\\{(x_i^{\\mathcal{W}}, x_i^{\\mathcal{T}})\\}_{i=1}^{n}$:\n- The centroids: $\\bar{x}^{\\mathcal{T}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i^{\\mathcal{T}}$ and $\\bar{x}^{\\mathcal{W}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i^{\\mathcal{W}}$.\n- The covariance matrix: $H = \\sum_{i=1}^{n} (x_i^{\\mathcal{T}} - \\bar{x}^{\\mathcal{T}}) (x_i^{\\mathcal{W}} - \\bar{x}^{\\mathcal{W}})^T$.\n- The SVD of $H$: $H = U \\Sigma V^T$.\n- The correction matrix for reflections: $S = \\mathrm{diag}(1, 1, \\det(V U^T))$.\n\nWith these definitions, the optimal rotation and translation are given by $\\hat{R} = V S U^T$ and $\\hat{t} = \\bar{x}^{\\mathcal{W}} - \\hat{R} \\bar{x}^{\\mathcal{T}}$, respectively.\nThe final transformation in homogeneous coordinates is:\n$$ \\hat{T}_{\\mathcal{W}\\mathcal{T}} = \\begin{pmatrix} \\hat{R} & \\hat{t} \\\\ \\mathbf{0}^T & 1 \\end{pmatrix} = \\begin{pmatrix} V S U^T & \\bar{x}^{\\mathcal{W}} - (V S U^T) \\bar{x}^{\\mathcal{T}} \\\\ \\mathbf{0}^T & 1 \\end{pmatrix} $$\nwhere $\\mathbf{0}^T$ is a $1 \\times 3$ row vector of zeros.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix} V \\mathrm{diag}(1, 1, \\det(V U^T)) U^T & \\frac{1}{n}\\sum_{i=1}^{n} x_i^{\\mathcal{W}} - (V \\mathrm{diag}(1, 1, \\det(V U^T)) U^T) \\frac{1}{n}\\sum_{i=1}^{n} x_i^{\\mathcal{T}} \\\\ \\mathbf{0}^T & 1 \\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While initial registration is essential, maintaining alignment during user motion is a dynamic challenge, especially when using tracking systems like monocular SLAM which are prone to drift. This practice addresses the critical issue of scale ambiguity in monocular vision, where the perceived size of the virtual world can slowly diverge from reality. You will analyze this common failure mode and learn to use the metrically accurate Digital Twin as a ground-truth reference to estimate and correct for this scale drift, a vital skill for ensuring the long-term stability and fidelity of an AR overlay .",
            "id": "4206827",
            "problem": "An augmented reality headset with a monocular camera is used to overlay a Digital Twin of a robotic cell onto the physical environment. The headset runs a monocular Simultaneous Localization and Mapping (SLAM) system that provides camera poses and a sparse map, both defined up to an unknown global similarity transform. The Digital Twin includes a Computer-Aided Design (CAD) model with metrically accurate dimensions. The overlay is produced by aligning the SLAM map to the CAD model. \n\nUse the following base facts and definitions:\n- In the projective camera model, image coordinates $x$ of a world point $X$ satisfy $x \\sim K [R \\mid t] X$, where $K$ is the intrinsic matrix, $R \\in \\mathrm{SO}(3)$ is a rotation, and $t \\in \\mathbb{R}^3$ is a translation. \n- For a monocular system, structure and motion recovered from images are determined up to an unknown global similarity transform, namely a triplet $\\{ s, R_0, t_0 \\}$ with $s \\in \\mathbb{R}^+$, $R_0 \\in \\mathrm{SO}(3)$, and $t_0 \\in \\mathbb{R}^3$; in particular, the absolute metric scale $s$ is unobservable from a single monocular sequence without metric priors. \n- Scale drift denotes gradual error in the estimated global scale $s$ due to accumulated estimation noise over time in a monocular SLAM pipeline.\n\nSuppose the headset must maintain sub-centimeter overlay accuracy over a workspace of diameter $D$ meters, and the CAD model provides metrically accurate baselines between identifiable features. In a given session, $M = 3$ feature pairs are matched between the SLAM map points and CAD features, providing metric baselines from CAD and their corresponding distances in the current SLAM map coordinates. The known CAD baseline lengths (in meters) are $L_1 = 1.200$, $L_2 = 2.500$, $L_3 = 3.000$, and the corresponding distances between the matched map points in current SLAM units are $\\hat{d}_1 = 1.18$, $\\hat{d}_2 = 2.42$, $\\hat{d}_3 = 2.87$. Assume equal confidence for the three correspondences. Additionally, at the time of overlay, the instantaneous scale factor of the SLAM trajectory relative to true metric scale has drifted to $s' = 0.96$ (that is, true translations are $s$ times the SLAM translations, but the system is still using an outdated scale equal to $1$ when mapping to the CAD frame).\n\nWhich option best explains, from first principles, why scale drift in a monocular SLAM undermines Digital Twin overlay fidelity, and proposes a principled correction using the known baseline(s) from the CAD model, including the correct numerical estimate of the scale from the given baselines and how to apply it to the SLAM state? Also state the expected magnitude of positional overlay error at a point $R = 5.0$ meters from the origin before correction, given $s' = 0.96$.\n\nA. Because monocular reconstruction is defined only up to a similarity, the absolute scale $s$ is unobservable and can drift. An overlay error arises because rendering uses a mismatched similarity between the SLAM map and the CAD model, producing position errors that grow approximately linearly with scene extent. A principled correction is to estimate the global scale $s$ by minimizing the sum of squared residuals between scaled SLAM distances and metric CAD baselines, namely $s^* = \\arg\\min_s \\sum_{m=1}^M ( s \\hat{d}_m - L_m )^2$, which yields $s^* = \\left( \\sum_m \\hat{d}_m L_m \\right) / \\left( \\sum_m \\hat{d}_m^2 \\right)$. For the provided data, $s^* \\approx 1.038$. Apply the correction by scaling all SLAM translations and map point positions by $s^*$ while leaving rotations on $\\mathrm{SO}(3)$ unchanged, and add a similarity edge (scale prior) in the pose graph to arrest future drift. The pre-correction overlay position error at range $R$ under $s' = 0.96$ is approximately $|1 - s'| R \\approx 0.20$ meters.\n\nB. Scale drift does not affect overlay if the camera intrinsics $K$ are calibrated because $K$ fixes the metric scale. A correction is to adjust the field of view to match the CAD at each frame. The scale can be estimated by the arithmetic mean $s = \\frac{1}{M} \\sum_m \\frac{L_m}{\\hat{d}_m}$ and then applied uniformly to both the translations and rotations, i.e., set $R' = s R$ and $t' = s t$. The pre-correction overlay error is zero if $K$ is known.\n\nC. Scale drift only changes the internal map but not the perceived overlay if the renderer uses the current pose; thus, no global similarity is required. If a correction is desired, add a constant offset along the camera’s optical axis. The scale can be estimated as $s = \\frac{\\sum_m L_m}{\\sum_m \\hat{d}_m}$ and applied only to camera translations without changing map points. The pre-correction overlay position error is approximately $0.04$ meters irrespective of $R$.\n\nD. Scale drift is due to incorrect pixel-to-metric conversion, so enforce that the pixel distance between two matched image features equals the CAD baseline: set $s = \\frac{L}{\\|\\hat{u}_i - \\hat{u}_j\\|}$ from any single image, then update the focal length $f$ accordingly. Rotations must be scaled as $R' = s R$ to maintain consistency. The pre-correction overlay error is eliminated per-frame by this update.",
            "solution": "## PROBLEM VALIDATION\n\n### Step 1: Extract Givens\n\n- **System**: An augmented reality headset with a monocular camera using a monocular Simultaneous Localization and Mapping (SLAM) system.\n- **Application**: Overlaying a Digital Twin (DT) of a robotic cell, which includes a metrically accurate Computer-Aided Design (CAD) model.\n- **Camera Model**: Projective camera, where image coordinates $x$ of a world point $X$ satisfy $x \\sim K [R \\mid t] X$, with $K$ as the intrinsic matrix, $R \\in \\mathrm{SO}(3)$ as rotation, and $t \\in \\mathbb{R}^3$ as translation.\n- **SLAM Ambiguity**: The recovered structure and motion are determined up to an unknown global similarity transform $\\{ s, R_0, t_0 \\}$, where $s \\in \\mathbb{R}^+$ is the scale, $R_0 \\in \\mathrm{SO}(3)$ is a global rotation, and $t_0 \\in \\mathbb{R}^3$ is a global translation. The absolute metric scale $s$ is unobservable from a single monocular sequence without metric priors.\n- **Scale Drift Definition**: Gradual error in the estimated global scale $s$ due to accumulated estimation noise over time.\n- **Performance Requirement**: Sub-centimeter overlay accuracy over a workspace of diameter $D$ meters.\n- **Provided Data for Scale Estimation**:\n    - Number of matched feature pairs: $M = 3$.\n    - Known CAD baseline lengths (in meters): $L_1 = 1.200$, $L_2 = 2.500$, $L_3 = 3.000$.\n    - Corresponding SLAM map distances (in SLAM units): $\\hat{d}_1 = 1.18$, $\\hat{d}_2 = 2.42$, $\\hat{d}_3 = 2.87$.\n    - Assumption: Equal confidence for the three correspondences.\n- **Scenario for Error Calculation**:\n    - At the time of overlay, the instantaneous scale factor has drifted to $s' = 0.96$. This means the true metric distance is $s'$ times the corresponding distance in the SLAM map's units.\n    - The system is using an outdated scale equal to $1$ for mapping to the CAD frame.\n    - An overlay error is to be calculated for a point at a distance $R = 5.0$ meters from the origin.\n\n### Step 2: Validate Using Extracted Givens\n\n- **Scientifically Grounded**: The problem statement is firmly rooted in the principles of 3D computer vision and robotics, specifically monocular SLAM. The concepts of the projective camera model, the similarity ambiguity of monocular reconstruction (including unobservable scale), scale drift, and the use of metric priors (CAD baselines) for scale correction are all standard and well-established in the field.\n- **Well-Posed**: The problem is well-posed. It provides sufficient numerical data ($M=3$ pairs of corresponding distances) to uniquely determine an estimate for the scale factor $s$. The question asks for a specific derivation, a numerical calculation, and an analysis of a given scenario, all of which are solvable with the provided information.\n- **Objective**: The problem is stated using precise, objective, and technical language. All key terms are either defined or are standard in the field. The data is quantitative. There are no subjective or opinion-based statements.\n\nThe problem does not exhibit any of the invalidity flaws:\n1.  **Scientific Unsoundness**: No violations of scientific or mathematical principles.\n2.  **Irrelevance**: The problem is directly relevant to the specified topic.\n3.  **Incompleteness/Contradiction**: The setup is self-contained and consistent. The provision of data for estimating a scale factor and a separate, drifted scale factor for an error-analysis scenario is a standard problem structure, not a contradiction.\n4.  **Unfeasibility**: All numerical values are physically realistic for a typical robotic work cell.\n5.  **Ill-Posedness**: The problem admits a unique and meaningful solution.\n6.  **Triviality**: The problem requires substantive knowledge of SLAM principles and least-squares estimation.\n7.  **Unverifiability**: All claims and calculations are mathematically verifiable.\n\n### Step 3: Verdict and Action\nThe problem statement is **VALID**. The solution process will now proceed.\n\n## SOLUTION DERIVATION\n\nThe problem requires a three-part answer:\n1.  An explanation of why scale drift affects overlay fidelity.\n2.  A principled method to correct the scale using the given data, including a numerical estimate.\n3.  A calculation of the pre-correction overlay error for the given scenario.\n\n### Part 1: Explanation of Scale Drift and Overlay Error\n\nThe core of monocular SLAM is the reconstruction of 3D structure and camera motion from a 2D video stream. Due to the nature of projective geometry, this reconstruction is only possible up to an unknown similarity transformation. This means that if $\\{ \\mathcal{P}, \\mathcal{T} \\}$ is a valid 3D map (points $\\mathcal{P}$) and camera trajectory (poses $\\mathcal{T}$), then for any scale $s > 0$, rotation $R_0 \\in \\mathrm{SO}(3)$, and translation $t_0 \\in \\mathbb{R}^3$, the transformed reconstruction $\\{ s R_0 \\mathcal{P} + t_0, (R_0 R_i, s R_0 t_i + t_0) \\in \\mathcal{T} \\}$ is also a valid reconstruction that produces the exact same image observations. The scale factor $s$ is unobservable from monocular vision alone.\n\nA Digital Twin overlay requires aligning the SLAM map coordinate system with the real-world metric system, represented by the CAD model. This is done by finding the specific similarity transform $\\{s, R_0, t_0\\}$ that maps SLAM coordinates to CAD coordinates. Initially, this can be computed. However, in a real-time SLAM system, small errors in frame-to-frame motion estimation accumulate. This accumulation causes the parameters of the similarity transform to drift over time. Most notably, the scale $s$ can drift, meaning the ratio of a true meter to a SLAM map unit is not constant.\n\nLet the true scale factor at a given time be $s'$. A true distance $L_{true}$ in the world is represented as a distance $d_{slam}$ in the SLAM map, where $L_{true} = s' \\cdot d_{slam}$. The AR system must use a scale factor, let's call it $s_{sys}$, to render the Digital Twin overlay. If $s_{sys} \\neq s'$, a misalignment occurs. The system calculates the metric position of a SLAM point $p_{slam}$ as $p_{est} = s_{sys} \\cdot p_{slam}$. The true metric position is $p_{true} = s' \\cdot p_{slam}$. The vector error is $e = p_{true} - p_{est} = (s' - s_{sys}) p_{slam}$. The magnitude of the error is proportional to the distance of the point from the origin of the SLAM frame, $\\|e\\| = |s' - s_{sys}| \\|p_{slam}\\|$. This demonstrates that overlay errors due to scale drift grow linearly with the distance from the SLAM origin.\n\n### Part 2: Scale Correction and Estimation\n\nTo correct the scale, we must estimate the true current scale factor $s'$ by comparing distances in the SLAM map to known metric distances from the CAD model. We are given $M=3$ pairs of distances: metric CAD baselines $\\{L_m\\}_{m=1}^3$ and their corresponding SLAM map counterparts $\\{\\hat{d}_m\\}_{m=1}^3$. The ideal relationship is $L_m = s \\cdot \\hat{d}_m$. Due to measurement noise in the SLAM positions, this will not be exact. A principled method to find the best estimate for $s$ is to minimize the sum of squared errors between the known metric baselines and the scaled SLAM distances.\n\nWe define the objective function $E(s)$ as the sum of squared residuals:\n$$ E(s) = \\sum_{m=1}^{M} (s \\hat{d}_m - L_m)^2 $$\nTo find the optimal scale $s^*$ that minimizes this error, we take the derivative of $E(s)$ with respect to $s$ and set it to zero:\n$$ \\frac{dE}{ds} = \\sum_{m=1}^{M} \\frac{d}{ds} (s \\hat{d}_m - L_m)^2 = \\sum_{m=1}^{M} 2(s \\hat{d}_m - L_m)(\\hat{d}_m) = 0 $$\n$$ \\sum_{m=1}^{M} (s \\hat{d}_m^2 - L_m \\hat{d}_m) = 0 $$\n$$ s \\sum_{m=1}^{M} \\hat{d}_m^2 = \\sum_{m=1}^{M} L_m \\hat{d}_m $$\nThis yields the least-squares estimator for the scale:\n$$ s^* = \\frac{\\sum_{m=1}^{M} L_m \\hat{d}_m}{\\sum_{m=1}^{M} \\hat{d}_m^2} $$\nUsing the provided data:\n$L_1 = 1.200, L_2 = 2.500, L_3 = 3.000$\n$\\hat{d}_1 = 1.18, \\hat{d}_2 = 2.42, \\hat{d}_3 = 2.87$\n\nNumerator:\n$$ \\sum L_m \\hat{d}_m = (1.200)(1.18) + (2.500)(2.42) + (3.000)(2.87) = 1.416 + 6.050 + 8.610 = 16.076 $$\nDenominator:\n$$ \\sum \\hat{d}_m^2 = (1.18)^2 + (2.42)^2 + (2.87)^2 = 1.3924 + 5.8564 + 8.2369 = 15.4857 $$\nScale estimate:\n$$ s^* = \\frac{16.076}{15.4857} \\approx 1.038118 $$\nThis estimated scale $s^* \\approx 1.038$ should be applied to the SLAM map. The correction involves multiplicatively scaling all translational components of the map. This means every map point position $\\vec{p}$ becomes $s^* \\vec{p}$, and every camera translation vector $\\vec{t}$ in the trajectory becomes $s^* \\vec{t}$. The rotation matrices $R \\in \\mathrm{SO}(3)$ must remain unchanged, as scaling would violate their defining property of orthonormality and corrupt the rotational geometry.\n\n### Part 3: Pre-Correction Error Calculation\n\nWe are given a scenario where the true instantaneous scale factor has drifted to $s' = 0.96$. A point is located at a true metric distance of $R = 5.0$ meters from the origin.\nThe SLAM system would reconstruct this point at a distance $d_{slam}$ in its own arbitrary units, where $R = s' \\cdot d_{slam}$. Thus, $d_{slam} = R/s'$.\n$$ d_{slam} = \\frac{5.0}{0.96} \\approx 5.2083 \\text{ SLAM units} $$\nThe problem states that the system is using an outdated scale factor of $s_{sys} = 1$ to render the overlay onto the CAD frame. Therefore, the system believes the metric distance to the point is:\n$$ R_{est} = s_{sys} \\cdot d_{slam} = 1 \\cdot \\frac{5.0}{0.96} \\approx 5.2083 \\text{ meters} $$\nThe true distance is $R = 5.0$ meters. The magnitude of the positional overlay error is the difference between the true and estimated metric distances:\n$$ \\text{Error} = |R - R_{est}| = \\left|5.0 - \\frac{5.0}{0.96}\\right| = 5.0 \\left|1 - \\frac{1}{0.96}\\right| = 5.0 \\left|\\frac{0.96 - 1}{0.96}\\right| = 5.0 \\left(\\frac{0.04}{0.96}\\right) = 5.0 \\cdot \\frac{1}{24} = \\frac{5}{24} \\approx 0.2083 \\text{ meters} $$\nA common first-order approximation for this error, valid when $s' \\approx 1$, is $|1 - s'| R$.\n$$ |1 - s'| R = |1 - 0.96| \\times 5.0 = 0.04 \\times 5.0 = 0.20 \\text{ meters} $$\nThis approximation is close to the exact value.\n\n## OPTION-BY-OPTION ANALYSIS\n\n- **A. Because monocular reconstruction is defined only up to a similarity, the absolute scale $s$ is unobservable and can drift. An overlay error arises because rendering uses a mismatched similarity between the SLAM map and the CAD model, producing position errors that grow approximately linearly with scene extent. A principled correction is to estimate the global scale $s$ by minimizing the sum of squared residuals between scaled SLAM distances and metric CAD baselines, namely $s^* = \\arg\\min_s \\sum_{m=1}^M ( s \\hat{d}_m - L_m )^2$, which yields $s^* = \\left( \\sum_m \\hat{d}_m L_m \\right) / \\left( \\sum_m \\hat{d}_m^2 \\right)$. For the provided data, $s^* \\approx 1.038$. Apply the correction by scaling all SLAM translations and map point positions by $s^*$ while leaving rotations on $\\mathrm{SO}(3)$ unchanged, and add a similarity edge (scale prior) in the pose graph to arrest future drift. The pre-correction overlay position error at range $R$ under $s' = 0.96$ is approximately $|1 - s'| R \\approx 0.20$ meters.**\n  - **Verdict:** **Correct**. This option provides a correct theoretical explanation. It uses the correct and principled least-squares formulation for scale estimation. The numerical calculation $s^* \\approx 1.038$ is correct based on my derivation. The method for applying the correction (scaling translations and points but not rotations) is correct. The suggestion of adding a similarity edge is an advanced and correct technique. Finally, the error calculation is a valid and numerically close approximation.\n\n- **B. Scale drift does not affect overlay if the camera intrinsics $K$ are calibrated because $K$ fixes the metric scale. A correction is to adjust the field of view to match the CAD at each frame. The scale can be estimated by the arithmetic mean $s = \\frac{1}{M} \\sum_m \\frac{L_m}{\\hat{d}_m}$ and then applied uniformly to both the translations and rotations, i.e., set $R' = s R$ and $t' = s t$. The pre-correction overlay error is zero if $K$ is known.**\n  - **Verdict:** **Incorrect**. The premise that a calibrated intrinsic matrix $K$ fixes the metric scale is fundamentally false. The scale ambiguity of monocular vision is geometric and persists even with a known $K$. Applying a scale factor to a rotation matrix ($R' = sR$) is a nonsensical operation that would take it out of $\\mathrm{SO}(3)$.\n\n- **C. Scale drift only changes the internal map but not the perceived overlay if the renderer uses the current pose; thus, no global similarity is required. If a correction is desired, add a constant offset along the camera’s optical axis. The scale can be estimated as $s = \\frac{\\sum_m L_m}{\\sum_m \\hat{d}_m}$ and applied only to camera translations without changing map points. The pre-correction overlay position error is approximately $0.04$ meters irrespective of $R$.**\n  - **Verdict:** **Incorrect**. Scale drift absolutely affects the perceived overlay, as the \"current pose\" has a translation component that is incorrectly scaled. A constant offset is the wrong model for a multiplicative scale error. Applying scale correction only to translations while leaving map points unchanged would destroy the consistency of the map. The claim that the error is constant and independent of range $R$ is also fundamentally incorrect; scale error is multiplicative.\n\n- **D. Scale drift is due to incorrect pixel-to-metric conversion, so enforce that the pixel distance between two matched image features equals the CAD baseline: set $s = \\frac{L}{\\|\\hat{u}_i - \\hat{u}_j\\|}$ from any single image, then update the focal length $f$ accordingly. Rotations must be scaled as $R' = s R$ to maintain consistency. The pre-correction overlay error is eliminated per-frame by this update.**\n  - **Verdict:** **Incorrect**. This option conflates 2D image-space pixel distances with 3D world-space metric distances, which is a grave error. The relationship is governed by projective geometry, not a simple ratio. Modifying the focal length $f$ to correct a 3D world scale drift is incorrect. As with option B, scaling rotation matrices ($R' = sR$) is wrong.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "A successful AR interface must be both geometrically accurate and highly responsive, which requires careful management of computational resources. This practice moves beyond geometry to system-level optimization, tackling the problem of how to distribute a demanding processing pipeline between a local AR device (the edge) and remote servers (the cloud). You will formulate a cost function based on queuing theory and network models to find the optimal partition that minimizes end-to-end latency. This exercise provides hands-on experience in system design and performance engineering, essential for building scalable and interactive digital twin applications .",
            "id": "4206841",
            "problem": "Consider an interactive Augmented Reality (AR) and Virtual Reality (VR) interface to a Digital Twin (DT), where each incoming frame must be processed through a sequence of $n$ ordered tasks $\\{ \\tau_1, \\tau_2, \\ldots, \\tau_n \\}$ before the result is rendered to the user. The processing pipeline can be partitioned at an index $k \\in \\{0,1,\\ldots,n\\}$, where tasks $\\tau_1,\\ldots,\\tau_k$ run at the edge device (for example, a headset) and tasks $\\tau_{k+1},\\ldots,\\tau_n$ run in the cloud. The goal is to choose $k$ to minimize end-to-end latency while satisfying compute constraints at the edge and cloud, and to justify the placement using a principled cost function.\n\nYou must derive a cost function based on fundamental principles and implement an algorithm that selects the partition index $k$ minimizing this cost. Use only the models and definitions specified below; do not introduce ad hoc formulas.\n\nFundamental base and definitions:\n- Let the compute demand of task $\\tau_i$ be $c_i$ in Giga-Operations (GOp) per frame. If the processor has a nominal compute rate $r$ in GOp/s, the service time per frame for a set of tasks with total compute $C$ is $S = C / r$ seconds.\n- Define the service rate for a processing stage with deterministic average service time $S$ as $\\mu = 1 / S$ frames per second.\n- Assume frames arrive at rate $\\lambda$ frames per second. Model each compute stage as a Markovian arrival, Markovian service, single server (M/M/1) queue in steady state, where the expected time in system (including waiting and service) for a stable stage is $T = 1 / (\\mu - \\lambda)$ seconds with stability condition $\\lambda < \\mu$. Define utilization as $\\rho = \\lambda / \\mu$ and impose an additional engineering constraint $\\rho \\le u_{\\max}$ for each stage, where $u_{\\max} \\in (0,1)$ reflects a maximum allowable utilization.\n- The network between edge and cloud introduces a deterministic latency per frame. If the payload size sent uplink after the edge stage is $s_{\\text{up}}$ megabits and the return payload size from cloud to edge is $s_{\\text{down}}$ megabits, with uplink bandwidth $B_{\\text{up}}$ megabits per second, downlink bandwidth $B_{\\text{down}}$ megabits per second, and one-way propagation delay $d_{\\text{prop}}$ seconds, the total network latency per frame is\n$$\nN = \\frac{s_{\\text{up}}}{B_{\\text{up}}} + \\frac{s_{\\text{down}}}{B_{\\text{down}}} + 2 d_{\\text{prop}}.\n$$\n- The payload $s_{\\text{up}}$ depends on $k$. Let $s_{\\text{after}}[k]$ denote the uplink payload after tasks $\\tau_1,\\ldots,\\tau_k$. By definition, $s_{\\text{after}}[0]$ is the raw uplink payload with no edge tasks, and $s_{\\text{after}}[n]$ is the uplink payload after all tasks (which may be $0$ if no cloud processing is needed).\n\nCost function design:\n- For a given $k$, define the edge service time per frame as $S_{\\text{edge}}(k) = \\left(\\sum_{i=1}^{k} c_i\\right) / r_{\\text{edge}}$ and cloud service time per frame as $S_{\\text{cloud}}(k) = \\left(\\sum_{i=k+1}^{n} c_i\\right) / r_{\\text{cloud}}$. Their service rates are $\\mu_{\\text{edge}}(k) = 1 / S_{\\text{edge}}(k)$ (with the convention $S_{\\text{edge}}(0) = 0$ leading to $\\mu_{\\text{edge}}(0) = +\\infty$) and $\\mu_{\\text{cloud}}(k) = 1 / S_{\\text{cloud}}(k)$ (with the convention $S_{\\text{cloud}}(n) = 0$ leading to $\\mu_{\\text{cloud}}(n) = +\\infty$).\n- The expected time in system at each stage, for stable operation, is $T_{\\text{edge}}(k) = 1 / (\\mu_{\\text{edge}}(k) - \\lambda)$ and $T_{\\text{cloud}}(k) = 1 / (\\mu_{\\text{cloud}}(k) - \\lambda)$. If $\\mu_{\\text{edge}}(k) \\le \\lambda$ or $\\mu_{\\text{cloud}}(k) \\le \\lambda$, the stage is unstable and the expected time diverges in an M/M/1 model; the cost function must penalize such $k$ heavily.\n- Define the deterministic network latency $N(k) = s_{\\text{after}}[k] / B_{\\text{up}} + s_{\\text{down}} / B_{\\text{down}} + 2 d_{\\text{prop}}$.\n- Let $u_{\\max,\\text{edge}}$ and $u_{\\max,\\text{cloud}}$ be the maximum allowable utilizations for edge and cloud. To unify latency minimization with constraint satisfaction, define the cost for partition index $k$ as\n$$\nJ(k) = T_{\\text{edge}}(k) + N(k) + T_{\\text{cloud}}(k) + \\alpha \\left[\\max\\!\\left(0,\\ \\lambda - u_{\\max,\\text{edge}}\\,\\mu_{\\text{edge}}(k)\\right)\\, \\frac{1}{\\mu_{\\text{edge}}(k)} + \\max\\!\\left(0,\\ \\lambda - u_{\\max,\\text{cloud}}\\,\\mu_{\\text{cloud}}(k)\\right)\\, \\frac{1}{\\mu_{\\text{cloud}}(k)}\\right] + \\beta \\left[\\max\\!\\left(0,\\ \\lambda - \\mu_{\\text{edge}}(k)\\right)\\, \\frac{1}{\\mu_{\\text{edge}}(k)} + \\max\\!\\left(0,\\ \\lambda - \\mu_{\\text{cloud}}(k)\\right)\\, \\frac{1}{\\mu_{\\text{cloud}}(k)}\\right],\n$$\nwith the conventions that terms containing $\\frac{1}{\\mu}$ are treated as $0$ when $\\mu = +\\infty$. Here $\\alpha$ and $\\beta$ are penalty coefficients with units that produce seconds in the penalty terms. The first penalty bracket enforces the utilization constraints $\\rho \\le u_{\\max}$, and the second bracket penalizes instability $\\lambda \\ge \\mu$ (which would otherwise produce infinite expected time). The total latency to be minimized is $J(k)$, and the optimal partition index is $k^\\star = \\arg\\min_{k \\in \\{0,\\ldots,n\\}} J(k)$. A partition is feasible if both utilization constraints are satisfied: $\\lambda \\le u_{\\max,\\text{edge}}\\,\\mu_{\\text{edge}}(k^\\star)$ and $\\lambda \\le u_{\\max,\\text{cloud}}\\,\\mu_{\\text{cloud}}(k^\\star)$.\n\nUnits and output specification:\n- All times must be expressed in seconds.\n- All bandwidths are in megabits per second.\n- All payloads are in megabits.\n- All compute rates are in Giga-Operations per second.\n- All compute demands are in Giga-Operations per frame.\n- The frame arrival rate $\\lambda$ is in frames per second.\n\nYour program must compute $k^\\star$, the minimized cost $J(k^\\star)$ in seconds, and a feasibility indicator for each test case. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a list of the form $[k^\\star, J(k^\\star), \\text{feasible}]$. The minimized cost $J(k^\\star)$ must be rounded to $6$ decimal places. Example output format: $[[0,0.123456,True],[2,0.234567,False]]$.\n\nTest suite:\n- Case $1$ (happy path):\n    - $n = 4$\n    - $c = [3.0, 2.0, 1.0, 1.0]$ (GOp/frame)\n    - $r_{\\text{edge}} = 200.0$ (GOp/s), $r_{\\text{cloud}} = 600.0$ (GOp/s)\n    - $s_{\\text{after}} = [80.0, 40.0, 20.0, 10.0, 5.0]$ (megabits)\n    - $s_{\\text{down}} = 10.0$ (megabits)\n    - $B_{\\text{up}} = 160.0$ (megabits/s), $B_{\\text{down}} = 200.0$ (megabits/s)\n    - $d_{\\text{prop}} = 0.01$ (seconds)\n    - $\\lambda = 20.0$ (frames/s)\n    - $u_{\\max,\\text{edge}} = 0.85$, $u_{\\max,\\text{cloud}} = 0.95$\n- Case $2$ (boundary utilization at edge):\n    - $n = 4$\n    - $c = [1.5, 1.0, 0.8, 0.5]$ (GOp/frame)\n    - $r_{\\text{edge}} = 100.0$ (GOp/s), $r_{\\text{cloud}} = 400.0$ (GOp/s)\n    - $s_{\\text{after}} = [100.0, 50.0, 25.0, 12.5, 6.0]$ (megabits)\n    - $s_{\\text{down}} = 8.0$ (megabits)\n    - $B_{\\text{up}} = 120.0$ (megabits/s), $B_{\\text{down}} = 150.0$ (megabits/s)\n    - $d_{\\text{prop}} = 0.02$ (seconds)\n    - $\\lambda = 16.0$ (frames/s)\n    - $u_{\\max,\\text{edge}} = 0.80$, $u_{\\max,\\text{cloud}} = 0.90$\n- Case $3$ (network bottleneck, low bandwidth):\n    - $n = 5$\n    - $c = [0.8, 0.6, 0.6, 0.5, 0.4]$ (GOp/frame)\n    - $r_{\\text{edge}} = 180.0$ (GOp/s), $r_{\\text{cloud}} = 500.0$ (GOp/s)\n    - $s_{\\text{after}} = [200.0, 160.0, 120.0, 80.0, 40.0, 10.0]$ (megabits)\n    - $s_{\\text{down}} = 5.0$ (megabits)\n    - $B_{\\text{up}} = 40.0$ (megabits/s), $B_{\\text{down}} = 50.0$ (megabits/s)\n    - $d_{\\text{prop}} = 0.025$ (seconds)\n    - $\\lambda = 18.0$ (frames/s)\n    - $u_{\\max,\\text{edge}} = 0.90$, $u_{\\max,\\text{cloud}} = 0.95$\n- Case $4$ (cloud compute bottleneck):\n    - $n = 3$\n    - $c = [1.2, 1.1, 1.0]$ (GOp/frame)\n    - $r_{\\text{edge}} = 220.0$ (GOp/s), $r_{\\text{cloud}} = 150.0$ (GOp/s)\n    - $s_{\\text{after}} = [60.0, 30.0, 15.0, 7.0]$ (megabits)\n    - $s_{\\text{down}} = 6.0$ (megabits)\n    - $B_{\\text{up}} = 180.0$ (megabits/s), $B_{\\text{down}} = 180.0$ (megabits/s)\n    - $d_{\\text{prop}} = 0.015$ (seconds)\n    - $\\lambda = 22.0$ (frames/s)\n    - $u_{\\max,\\text{edge}} = 0.85$, $u_{\\max,\\text{cloud}} = 0.85$\n- Case $5$ (high frame rate, near-infeasible):\n    - $n = 4$\n    - $c = [2.0, 1.5, 1.0, 1.0]$ (GOp/frame)\n    - $r_{\\text{edge}} = 210.0$ (GOp/s), $r_{\\text{cloud}} = 300.0$ (GOp/s)\n    - $s_{\\text{after}} = [120.0, 80.0, 55.0, 35.0, 20.0]$ (megabits)\n    - $s_{\\text{down}} = 12.0$ (megabits)\n    - $B_{\\text{up}} = 140.0$ (megabits/s), $B_{\\text{down}} = 160.0$ (megabits/s)\n    - $d_{\\text{prop}} = 0.02$ (seconds)\n    - $\\lambda = 50.0$ (frames/s)\n    - $u_{\\max,\\text{edge}} = 0.90$, $u_{\\max,\\text{cloud}} = 0.90$\n\nIn all cases, set penalty coefficients $\\alpha = 100.0$ and $\\beta = 1000.0$ (chosen to dominate small latency differences when constraints are violated). Your program must evaluate $J(k)$ for all $k \\in \\{0,\\ldots,n\\}$, choose $k^\\star$, compute $J(k^\\star)$ in seconds rounded to $6$ decimal places, and return whether the utilization constraints are satisfied at $k^\\star$.",
            "solution": "The problem asks us to find the optimal partition index $k^\\star$ for a sequence of $n$ computational tasks, distributed between an edge device and a cloud server. The optimal partition is the one that minimizes a total cost function $J(k)$, which represents the end-to-end latency for processing a single frame, augmented with penalty terms for violating operational constraints. The index $k$ ranges from $0$ (all tasks in the cloud) to $n$ (all tasks at the edge).\n\nThe core of the solution is to systematically evaluate the cost function $J(k)$ for each possible partition $k \\in \\{0, 1, \\ldots, n\\}$ and identify the index $k^\\star$ that yields the minimum cost.\n\nFirst, we establish the computational load for each stage. For a given partition $k$, the total compute demand at the edge is the sum of the demands of the first $k$ tasks, and the cloud handles the rest. Let $c_i$ be the compute demand for task $\\tau_i$.\nEdge compute load: $C_{\\text{edge}}(k) = \\sum_{i=1}^{k} c_i$.\nCloud compute load: $C_{\\text{cloud}}(k) = \\sum_{i=k+1}^{n} c_i$.\nTo facilitate this calculation, we can pre-compute the cumulative sum of task demands. Let $\\text{csum}[j] = \\sum_{i=1}^{j} c_i$, with $\\text{csum}[0]=0$. Then, $C_{\\text{edge}}(k) = \\text{csum}[k]$ and $C_{\\text{cloud}}(k) = \\text{csum}[n] - \\text{csum}[k]$.\n\nNext, we model the performance of each stage. Given the processor compute rates $r_{\\text{edge}}$ and $r_{\\text{cloud}}$, the service times per frame are:\n$S_{\\text{edge}}(k) = C_{\\text{edge}}(k) / r_{\\text{edge}}$\n$S_{\\text{cloud}}(k) = C_{\\text{cloud}}(k) / r_{\\text{cloud}}$\nThe corresponding service rates, in frames per second, are the reciprocals of the service times:\n$\\mu_{\\text{edge}}(k) = 1 / S_{\\text{edge}}(k)$\n$\\mu_{\\text{cloud}}(k) = 1 / S_{\\text{cloud}}(k)$\nSpecial cases are $k=0$ (no edge processing) and $k=n$ (no cloud processing). For $k=0$, $C_{\\text{edge}}(0)=0$, so $S_{\\text{edge}}(0)=0$ and we define $\\mu_{\\text{edge}}(0) = +\\infty$. Symmetrically, for $k=n$, $C_{\\text{cloud}}(n)=0$, so $S_{\\text{cloud}}(n)=0$ and $\\mu_{\\text{cloud}}(n) = +\\infty$.\n\nThe problem models each stage as an M/M/1 queue. The expected time in system $T$ (queuing delay plus service time) for a stable stage (where arrival rate $\\lambda$ is less than service rate $\\mu$) is:\n$T = 1 / (\\mu - \\lambda)$.\nThis formula is only valid for stable queues, i.e., $\\lambda < \\mu$. The provided cost function $J(k)$ accounts for instability by adding large penalty terms. We calculate the latency contribution $T(k)$ as $1/(\\mu(k)-\\lambda)$ if $\\mu(k) > \\lambda$ and as $0$ otherwise, letting the penalty terms dominate the cost for unstable partitions.\n\nThe network latency, $N(k)$, depends on the partition $k$ through the uplink payload size $s_{\\text{after}}[k]$:\n$N(k) = s_{\\text{after}}[k] / B_{\\text{up}} + s_{\\text{down}} / B_{\\text{down}} + 2 d_{\\text{prop}}$.\n\nThe total cost function $J(k)$ is the sum of the latencies and penalties:\n$J(k) = T_{\\text{edge}}(k) + T_{\\text{cloud}}(k) + N(k) + \\text{Penalty}_{\\alpha}(k) + \\text{Penalty}_{\\beta}(k)$.\nThe penalty terms are defined as:\n$\\text{Penalty}_{\\alpha}(k) = \\alpha \\left[\\max\\!\\left(0,\\ \\lambda - u_{\\max,\\text{edge}}\\,\\mu_{\\text{edge}}(k)\\right)\\,S_{\\text{edge}}(k) + \\max\\!\\left(0,\\ \\lambda - u_{\\max,\\text{cloud}}\\,\\mu_{\\text{cloud}}(k)\\right)\\,S_{\\text{cloud}}(k)\\right]$\n$\\text{Penalty}_{\\beta}(k) = \\beta \\left[\\max\\!\\left(0,\\ \\lambda - \\mu_{\\text{edge}}(k)\\right)\\,S_{\\text{edge}}(k) + \\max\\!\\left(0,\\ \\lambda - \\mu_{\\text{cloud}}(k)\\right)\\,S_{\\text{cloud}}(k)\\right]$\nHere, we have substituted $S(k)$ for $1/\\mu(k)$. The conventions for $\\mu=\\infty$ ensure that the penalty terms for an idle stage are zero since its service time $S$ is zero. The $\\alpha$-penalty enforces the maximum utilization constraint $\\rho_j = \\lambda/\\mu_j \\le u_{\\max,j}$, while the $\\beta$-penalty penalizes fundamental instability $\\lambda \\ge \\mu_j$.\n\nThe algorithm proceeds as follows for each test case:\n1. Initialize `min_cost` to infinity and `k_star` to an invalid value.\n2. For each possible partition index $k$ from $0$ to $n$:\n   a. Calculate $C_{\\text{edge}}(k)$ and $C_{\\text{cloud}}(k)$.\n   b. Determine $S_{\\text{edge}}(k)$, $\\mu_{\\text{edge}}(k)$, and $T_{\\text{edge}}(k)$ (if stable).\n   c. Determine $S_{\\text{cloud}}(k)$, $\\mu_{\\text{cloud}}(k)$, and $T_{\\text{cloud}}(k)$ (if stable).\n   d. Calculate the network latency $N(k)$.\n   e. Calculate the $\\alpha$ and $\\beta$ penalty terms for both edge and cloud stages.\n   f. Sum all components to find the total cost $J(k)$.\n   g. If $J(k)$ is less than the current `min_cost`, update `min_cost` to $J(k)$ and `k_star` to $k$.\n3. After checking all $k$, the optimal partition $k^\\star$ and its associated minimum cost $J(k^\\star)$ are found.\n4. Finally, determine the feasibility of the solution at $k^\\star$. A solution is feasible if the utilization constraints are met for both stages: $\\lambda \\le u_{\\max,\\text{edge}}\\,\\mu_{\\text{edge}}(k^\\star)$ and $\\lambda \\le u_{\\max,\\text{cloud}}\\,\\mu_{\\text{cloud}}(k^\\star)$. This check must correctly handle the infinite service rate of idle stages.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the task partitioning problem for a series of test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1 (happy path)\n        {\n            \"n\": 4, \"c\": [3.0, 2.0, 1.0, 1.0], \"r_edge\": 200.0, \"r_cloud\": 600.0,\n            \"s_after\": [80.0, 40.0, 20.0, 10.0, 5.0], \"s_down\": 10.0,\n            \"B_up\": 160.0, \"B_down\": 200.0, \"d_prop\": 0.01,\n            \"lambda\": 20.0, \"u_max_edge\": 0.85, \"u_max_cloud\": 0.95,\n        },\n        # Case 2 (boundary utilization at edge)\n        {\n            \"n\": 4, \"c\": [1.5, 1.0, 0.8, 0.5], \"r_edge\": 100.0, \"r_cloud\": 400.0,\n            \"s_after\": [100.0, 50.0, 25.0, 12.5, 6.0], \"s_down\": 8.0,\n            \"B_up\": 120.0, \"B_down\": 150.0, \"d_prop\": 0.02,\n            \"lambda\": 16.0, \"u_max_edge\": 0.80, \"u_max_cloud\": 0.90,\n        },\n        # Case 3 (network bottleneck, low bandwidth)\n        {\n            \"n\": 5, \"c\": [0.8, 0.6, 0.6, 0.5, 0.4], \"r_edge\": 180.0, \"r_cloud\": 500.0,\n            \"s_after\": [200.0, 160.0, 120.0, 80.0, 40.0, 10.0], \"s_down\": 5.0,\n            \"B_up\": 40.0, \"B_down\": 50.0, \"d_prop\": 0.025,\n            \"lambda\": 18.0, \"u_max_edge\": 0.90, \"u_max_cloud\": 0.95,\n        },\n        # Case 4 (cloud compute bottleneck)\n        {\n            \"n\": 3, \"c\": [1.2, 1.1, 1.0], \"r_edge\": 220.0, \"r_cloud\": 150.0,\n            \"s_after\": [60.0, 30.0, 15.0, 7.0], \"s_down\": 6.0,\n            \"B_up\": 180.0, \"B_down\": 180.0, \"d_prop\": 0.015,\n            \"lambda\": 22.0, \"u_max_edge\": 0.85, \"u_max_cloud\": 0.85,\n        },\n        # Case 5 (high frame rate, near-infeasible)\n        {\n            \"n\": 4, \"c\": [2.0, 1.5, 1.0, 1.0], \"r_edge\": 210.0, \"r_cloud\": 300.0,\n            \"s_after\": [120.0, 80.0, 55.0, 35.0, 20.0], \"s_down\": 12.0,\n            \"B_up\": 140.0, \"B_down\": 160.0, \"d_prop\": 0.02,\n            \"lambda\": 50.0, \"u_max_edge\": 0.90, \"u_max_cloud\": 0.90,\n        }\n    ]\n    \n    alpha = 100.0\n    beta = 1000.0\n    \n    results = []\n\n    for case in test_cases:\n        n = case[\"n\"]\n        c = np.array(case[\"c\"])\n        r_edge, r_cloud = case[\"r_edge\"], case[\"r_cloud\"]\n        s_after = np.array(case[\"s_after\"])\n        s_down = case[\"s_down\"]\n        B_up, B_down = case[\"B_up\"], case[\"B_down\"]\n        d_prop = case[\"d_prop\"]\n        lambda_rate = case[\"lambda\"]\n        u_max_edge, u_max_cloud = case[\"u_max_edge\"], case[\"u_max_cloud\"]\n\n        c_cumulative = np.insert(np.cumsum(c), 0, 0)\n        c_total = c_cumulative[n]\n\n        min_cost = float('inf')\n        k_star = -1\n\n        for k in range(n + 1):\n            # Edge stage calculation\n            C_edge = c_cumulative[k]\n            T_edge, penalty_alpha_edge, penalty_beta_edge = 0, 0, 0\n            S_edge, mu_edge = 0, float('inf')\n            \n            if C_edge > 0:\n                S_edge = C_edge / r_edge\n                mu_edge = 1.0 / S_edge\n                if mu_edge > lambda_rate:\n                    T_edge = 1.0 / (mu_edge - lambda_rate)\n                \n                penalty_alpha_edge = alpha * max(0, lambda_rate - u_max_edge * mu_edge) * S_edge\n                penalty_beta_edge = beta * max(0, lambda_rate - mu_edge) * S_edge\n\n            # Cloud stage calculation\n            C_cloud = c_total - C_edge\n            T_cloud, penalty_alpha_cloud, penalty_beta_cloud = 0, 0, 0\n            S_cloud, mu_cloud = 0, float('inf')\n            \n            if C_cloud > 0:\n                S_cloud = C_cloud / r_cloud\n                mu_cloud = 1.0 / S_cloud\n                if mu_cloud > lambda_rate:\n                    T_cloud = 1.0 / (mu_cloud - lambda_rate)\n            \n                penalty_alpha_cloud = alpha * max(0, lambda_rate - u_max_cloud * mu_cloud) * S_cloud\n                penalty_beta_cloud = beta * max(0, lambda_rate - mu_cloud) * S_cloud\n\n            # Network latency\n            N_k = s_after[k] / B_up + s_down / B_down + 2 * d_prop\n\n            # Total cost J(k)\n            J_k = (T_edge + T_cloud + N_k + \n                   penalty_alpha_edge + penalty_beta_edge + \n                   penalty_alpha_cloud + penalty_beta_cloud)\n\n            if J_k  min_cost:\n                min_cost = J_k\n                k_star = k\n        \n        # Feasibility check for the optimal partition k_star\n        C_edge_star = c_cumulative[k_star]\n        mu_edge_star = float('inf')\n        if C_edge_star > 0:\n            mu_edge_star = 1.0 / (C_edge_star / r_edge)\n\n        C_cloud_star = c_total - C_edge_star\n        mu_cloud_star = float('inf')\n        if C_cloud_star > 0:\n            mu_cloud_star = 1.0 / (C_cloud_star / r_cloud)\n            \n        is_feasible_edge = (mu_edge_star == float('inf')) or (lambda_rate = u_max_edge * mu_edge_star)\n        is_feasible_cloud = (mu_cloud_star == float('inf')) or (lambda_rate = u_max_cloud * mu_cloud_star)\n        is_feasible = is_feasible_edge and is_feasible_cloud\n\n        results.append([k_star, min_cost, is_feasible])\n    \n    # Format the output as specified\n    output_str = \"[\" + \",\".join([f\"[{r[0]},{r[1]:.6f},{r[2]}]\" for r in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}