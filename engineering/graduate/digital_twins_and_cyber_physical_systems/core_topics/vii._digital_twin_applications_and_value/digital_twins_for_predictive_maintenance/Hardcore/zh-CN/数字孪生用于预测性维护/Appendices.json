{
    "hands_on_practices": [
        {
            "introduction": "预测性维护的核心是理解和量化设备何时可能发生故障。本练习将探讨威布尔分布，这是可靠性工程中用于描述部件寿命的基石模型。通过推导可靠性函数 $R(t)$ 和风险函数 $h(t)$，您将掌握如何评估一个部件在特定时间点后仍然正常工作的概率，以及其瞬时故障率。这项实践旨在培养将统计模型应用于维护决策的基本技能，并学会解读风险函数（递增、递减或恒定）如何揭示部件的老化特性，从而指导维护策略的制定 。",
            "id": "4216187",
            "problem": "信息物理系统（CPS）中的一个旋转资产由一个数字孪生监控，该数字孪生通过根据资产推断的失效时间分布来估计瞬时失效风险，从而执行预测性维护。假设失效时间随机变量 $T$ 服从威布尔分布，其形状参数为 $k>0$，尺度参数为 $\\lambda>0$，在 $t \\ge 0$ 上的概率密度函数 $f(t)$ 由下式给出：\n$$\nf(t) = \\frac{k}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{k-1}\\exp\\!\\left(-\\left(\\frac{t}{\\lambda}\\right)^{k}\\right).\n$$\n数字孪生使用可靠性和风险率的基本定义：\n- 可靠性 $R(t)$ 为 $R(t) = \\mathbb{P}(T>t)$。\n- 风险率 $h(t)$ 为 $h(t) = \\frac{f(t)}{R(t)}$。\n\n系统采用风险阈值策略：当瞬时风险率首次等于给定阈值 $\\eta>0$（单位：事件数/小时）时，在时间 $t_{\\eta}$ 触发预防性更换。系统时间单位为小时。\n\n任务：\n1. 从上述 $f(t)$ 以及定义 $R(t) = \\mathbb{P}(T>t)$ 和 $h(t) = \\frac{f(t)}{R(t)}$ 出发，为所有 $t \\ge 0$ 推导 $R(t)$ 和 $h(t)$ 的闭式表达式。\n2. 对于 $k \\ne 1$ 的情况，求解 $h(t_{\\eta}) = \\eta$ 以得到 $t_{\\eta}$，并将 $t_{\\eta}$（以小时为单位）表示为关于 $k$、$\\lambda$ 和 $\\eta$ 的闭式符号表达式。然后，计算 $R(t_{\\eta})$，并将其表示为关于 $k$、$\\lambda$ 和 $\\eta$ 的闭式符号表达式。\n3. 在维护策略设计的背景下，简要解释当 $k<1$、$k=1$ 和 $k>1$ 时，风险率 $h(t)$ 如何随时间演变，以及这对于安排检查和更换意味着什么，阐述这些情况的定性含义。\n\n将您的最终答案以包含 $t_{\\eta}$ 和 $R(t_{\\eta})$（按此顺序）的单一复合表达式形式报告，使用最简化的闭式形式。将 $t_{\\eta}$ 以小时表示。无需进行数值四舍五入。最终答案必须是实值符号表达式，且不得包含单位。",
            "solution": "问题陈述经评估有效。它在科学上基于可靠性工程和统计建模的原理，使用了威布尔分布、可靠性函数和风险率函数的标准定义。该问题是适定的，提供了推导唯一、有意义解所需的所有必要信息和定义。它没有歧义、矛盾和事实错误。\n\n任务将按顺序解决。\n\n任务1：推导可靠性函数 $R(t)$ 和风险率函数 $h(t)$。\n\n可靠性函数 $R(t)$ 定义为失效时间 $T$ 大于某个时间 $t$ 的概率。它是累积分布函数（CDF）$F(t) = \\mathbb{P}(T \\le t)$ 的补集。因此，$R(t) = 1 - F(t) = \\int_t^\\infty f(u) \\, du$。\n给定威布尔分布的概率密度函数（PDF）$f(t)$：\n$$\nf(t) = \\frac{k}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{k-1}\\exp\\!\\left(-\\left(\\frac{t}{\\lambda}\\right)^{k}\\right) \\quad \\text{for } t \\ge 0\n$$\n我们计算 $R(t)$ 的积分：\n$$\nR(t) = \\int_t^\\infty \\frac{k}{\\lambda}\\left(\\frac{u}{\\lambda}\\right)^{k-1}\\exp\\!\\left(-\\left(\\frac{u}{\\lambda}\\right)^{k}\\right) du\n$$\n为了解此积分，我们使用换元法。令 $x = \\left(\\frac{u}{\\lambda}\\right)^{k}$。则其微分为 $dx = k\\left(\\frac{u}{\\lambda}\\right)^{k-1} \\cdot \\frac{1}{\\lambda} \\, du$。我们还必须改变积分限。当 $u \\to t$ 时，下限变为 $x = (t/\\lambda)^{k}$。当 $u \\to \\infty$ 时，上限变为 $x \\to \\infty$。\n代入积分中：\n$$\nR(t) = \\int_{(t/\\lambda)^{k}}^{\\infty} \\exp(-x) \\, dx\n$$\n这是一个标准的指数积分：\n$$\nR(t) = \\left[ -\\exp(-x) \\right]_{(t/\\lambda)^{k}}^{\\infty} = \\lim_{b \\to \\infty} (-\\exp(-b)) - (-\\exp(-(t/\\lambda)^{k}))\n$$\n由于 $\\lim_{b \\to \\infty} \\exp(-b) = 0$，上式可简化为：\n$$\nR(t) = \\exp\\!\\left(-\\left(\\frac{t}{\\lambda}\\right)^{k}\\right)\n$$\n这就是 $t \\ge 0$ 时可靠性函数的闭式表达式。\n\n接下来，我们推导风险率函数 $h(t)$，其定义为 $h(t) = \\frac{f(t)}{R(t)}$。\n使用给定的 $f(t)$ 表达式和推导出的 $R(t)$ 表达式：\n$$\nh(t) = \\frac{\\frac{k}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{k-1}\\exp\\!\\left(-\\left(\\frac{t}{\\lambda}\\right)^{k}\\right)}{\\exp\\!\\left(-\\left(\\frac{t}{\\lambda}\\right)^{k}\\right)}\n$$\n分子和分母中的指数项相互抵消，得到：\n$$\nh(t) = \\frac{k}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{k-1}\n$$\n这就是 $t \\ge 0$ 时瞬时风险率函数的闭式表达式。\n\n任务2：对于 $k \\ne 1$ 的情况，求解更换时间 $t_{\\eta}$ 及此时的可靠性 $R(t_{\\eta})$。\n\n更换时间 $t_{\\eta}$ 由条件 $h(t_{\\eta}) = \\eta$ 定义，其中 $\\eta > 0$ 是一个恒定的风险阈值。\n$$\n\\frac{k}{\\lambda}\\left(\\frac{t_{\\eta}}{\\lambda}\\right)^{k-1} = \\eta\n$$\n我们求解此方程以得到 $t_{\\eta}$。首先，分离含有 $t_{\\eta}$ 的项：\n$$\n\\left(\\frac{t_{\\eta}}{\\lambda}\\right)^{k-1} = \\frac{\\eta \\lambda}{k}\n$$\n由于题目规定 $k \\ne 1$，指数 $(k-1)$ 非零，我们可以对两边取 $(1/(k-1))$ 次幂：\n$$\n\\frac{t_{\\eta}}{\\lambda} = \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{1}{k-1}}\n$$\n乘以 $\\lambda$ 得到 $t_{\\eta}$ 的最终表达式（以小时为单位）：\n$$\nt_{\\eta} = \\lambda \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{1}{k-1}}\n$$\n接下来，我们计算这个特定时间的可靠性 $R(t_{\\eta})$。我们使用推导出的 $R(t)$ 表达式：\n$$\nR(t_{\\eta}) = \\exp\\!\\left(-\\left(\\frac{t_{\\eta}}{\\lambda}\\right)^{k}\\right)\n$$\n从上一步中，我们得到了 $t_{\\eta}/\\lambda$ 项的表达式：\n$$\n\\frac{t_{\\eta}}{\\lambda} = \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{1}{k-1}}\n$$\n我们将此表达式进行 $k$ 次幂运算：\n$$\n\\left(\\frac{t_{\\eta}}{\\lambda}\\right)^{k} = \\left[ \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{1}{k-1}} \\right]^k = \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{k}{k-1}}\n$$\n将此结果代回可靠性函数：\n$$\nR(t_{\\eta}) = \\exp\\!\\left( - \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{k}{k-1}} \\right)\n$$\n这提供了 $t_{\\eta}$ 和 $R(t_{\\eta})$ 的闭式符号表达式。\n\n任务3：形状参数 $k$ 的解释。\n\n风险率函数 $h(t) = \\frac{k}{\\lambda}(\\frac{t}{\\lambda})^{k-1}$ 的行为由指数 $k-1$ 的符号决定。\n- 情况 $k  1$：在这种情况下，指数 $k-1$ 为负。因此，对于 $t  0$，$h(t)$ 是时间 $t$ 的递减函数。这模拟了“早期失效”或“早期寿命失效”。失效风险在开始时最高，并随着部件的运行而降低。这意味着如果一个资产度过了其初始阶段，它会变得更加可靠。对于维护策略而言，这表明基于役龄的预防性更换是适得其反的；一个“老化磨合”期可能是有益的，而其他维护策略（例如，故障后修复性维护）更为合适。\n- 情况 $k = 1$：指数 $k-1$ 为零。风险率函数变为常数：$h(t) = \\frac{1}{\\lambda}(\\frac{t}{\\lambda})^{0} = \\frac{1}{\\lambda}$。这对应于指数分布。失效风险不随时间变化，表明失效是随机且无记忆性的。就失效风险而言，该资产不会“老化”。对于维护策略而言，这意味着在固定役龄进行预防性更换与在故障时更换相比没有优势，因为一个旧部件在下一小时内发生故障的可能性并不比一个新部件高。\n- 情况 $k  1$：指数 $k-1$ 为正。因此，$h(t)$ 是时间 $t$ 的递增函数。这模拟了由老化和磨损引起的失效，这在机械部件中很常见。失效风险随着运行时间的增加而增加。对于维护策略而言，这是预测性和预防性维护最有效的经典场景。风险阈值策略是合理的，因为它允许在失效风险变得不可接受地高之前更换部件，从而优化了在充分利用部件寿命和避免昂贵的在役失效之间的权衡。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\lambda \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{1}{k-1}} \\\\\n\\exp\\left( - \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{k}{k-1}} \\right)\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "数字孪生的一个关键功能是从充满噪声的传感器数据中实时追踪一个不可直接测量的“健康指数”。本练习聚焦于卡尔曼滤波器，这是实现这一功能的核心算法。您将为一个简化的健康退化过程推导稳态卡尔曼增益 $K$，该增益决定了在模型预测和新的传感器测量之间应如何权衡。这项实践让您深入了解许多数字孪生内部的“大脑”——状态估计算法，通过推导其核心逻辑来理解模型与数据融合的精髓 。",
            "id": "4216218",
            "problem": "用于预测性维护的数字孪生估计一个因逐渐磨损而漂移的标量健康指数。健康动态和传感被建模为一个线性高斯状态空间系统：潜在健康状态 $x_{t} \\in \\mathbb{R}$ 根据 $x_{t+1} = x_{t} + w_{t}$ 演化，传感器产生 $y_{t} = x_{t} + v_{t}$，其中过程噪声 $w_{t} \\sim \\mathcal{N}(0,Q)$ 和测量噪声 $v_{t} \\sim \\mathcal{N}(0,R)$ 相互独立、随时间独立，并且与初始状态无关，其中 $Q  0$ 和 $R  0$ 是已知的。在数字孪生的稳态运行中，要求估计器在这些假设下达到最优线性最小均方误差性能。\n\n从线性估计器的预测和更新误差协方差的基本定义以及标量线性高斯情况下的均方误差最优性条件出发，推导与基于新息的线性更新相关的稳态误差协方差，然后推导稳态卡尔曼增益 $K$。假设误差协方差的稳态极限存在且有限，并且除了正性之外，不要对 $Q$ 或 $R$ 的任何特定值做假设。\n\n以 $Q$ 和 $R$ 的闭式解析表达式形式提供最终的稳态卡尔曼增益 $K$。不需要进行数值评估，也不需要单位。最终答案必须是单个解析表达式。",
            "solution": "首先根据指定标准验证问题。\n\n**步骤 1：提取已知条件**\n- 潜在健康状态 $x_t \\in \\mathbb{R}$ 根据过程模型演化：$x_{t+1} = x_{t} + w_{t}$。\n- 传感器测量值 $y_t$ 由测量模型给出：$y_{t} = x_{t} + v_{t}$。\n- 过程噪声是零均值高斯随机变量：$w_{t} \\sim \\mathcal{N}(0,Q)$，其方差为 $Q  0$。\n- 测量噪声是零均值高斯随机变量：$v_{t} \\sim \\mathcal{N}(0,R)$，其方差为 $R  0$。\n- 噪声过程 $w_t$ 和 $v_t$ 相互独立、随时间独立，并且与初始状态无关。\n- 目标是找到稳态下的最优线性最小均方误差估计器。\n- 假设误差协方差的稳态极限存在且有限。\n- 任务是推导稳态卡尔曼增益 $K$，并将其表示为关于 $Q$ 和 $R$ 的闭式解析表达式。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题描述了一个标量线性高斯状态空间模型，这是估计理论和控制系统中的一个基本构造。稳态卡尔曼滤波器的推导是一个标准的、成熟的过程，基于严格的概率和优化数学原理。用于预测性维护的数字孪生这一应用背景是这类模型的现代且科学上有效的用途。该问题在科学上是合理的。\n- **适定性：** 该问题是适定的。系统由一个带有噪声测量的标准随机游走过程描述。对于这样一个过程噪声协方差 $Q$ 和测量噪声协方差 $R$ 均为正的系统，与卡尔曼滤波器相关的离散时间代数Riccati方程有一个唯一的、正定（在此标量情况下为正）的稳定解。问题明确假设这个稳态极限存在，从而确保可以找到唯一解。\n- **客观性：** 该问题以精确、客观、无歧义的数学语言陈述。术语如“线性最小均方误差”、“误差协方差”和“卡尔曼增益”在该领域有精确的定义。\n\n**步骤 3：结论与行动**\n该问题是有效的。它具有科学依据、适定且客观，并为唯一解提供了所有必要信息。可以进行推导过程。\n\n**稳态卡尔曼增益的推导**\n\n该系统是一个线性时不变状态空间模型：\n$$x_{t+1} = F x_{t} + w_{t}$$\n$$y_{t} = H x_{t} + v_{t}$$\n根据问题陈述，我们有一个标量系统，其中状态转移矩阵为 $F=1$，观测矩阵为 $H=1$。噪声协方差是标量 $Q$ 和 $R$。\n\n卡尔曼滤波器通过一个两步过程递归地计算状态估计：预测和更新。与这些步骤相关的误差协方差是滤波器性能的核心。设 $P_{t|t-1}$ 为预测（先验）误差协方差， $P_{t|t}$ 为更新（后验）误差协方差。\n\n误差协方差的标准卡尔曼滤波器方程为：\n1.  **预测：** $P_{t|t-1} = F P_{t-1|t-1} F^T + Q$\n2.  **更新：** $P_{t|t} = (I - K_t H) P_{t|t-1}$\n\n选择卡尔曼增益 $K_t$ 以最小化均方误差，其公式为：\n$$K_t = P_{t|t-1} H^T (H P_{t|t-1} H^T + R)^{-1}$$\n\n对于我们特定的标量情况（$F=1$, $H=1$），这些方程简化为：\n1.  **预测：** $P_{t|t-1} = P_{t-1|t-1} + Q$\n2.  **卡尔曼增益：** $K_t = P_{t|t-1} (P_{t|t-1} + R)^{-1} = \\frac{P_{t|t-1}}{P_{t|t-1} + R}$\n3.  **更新：** $P_{t|t} = (1 - K_t) P_{t|t-1}$\n\n我们可以将这些结合起来推导离散时间Riccati方程，该方程描述了误差协方差的传播。将 $K_t$ 的表达式代入 $P_{t|t}$ 的更新方程中：\n$$P_{t|t} = \\left(1 - \\frac{P_{t|t-1}}{P_{t|t-1} + R}\\right) P_{t|t-1} = \\left(\\frac{P_{t|t-1} + R - P_{t|t-1}}{P_{t|t-1} + R}\\right) P_{t|t-1} = \\frac{R P_{t|t-1}}{P_{t|t-1} + R}$$\n现在，我们将预测方程 $P_{t|t-1} = P_{t-1|t-1} + Q$ 代入此结果：\n$$P_{t|t} = \\frac{R (P_{t-1|t-1} + Q)}{P_{t-1|t-1} + Q + R}$$\n这是后验误差协方差的递归关系。\n\n在稳态下，误差协方差变为常数。我们定义稳态后验误差协方差为 $P = \\lim_{t \\to \\infty} P_{t|t}$。因此，在极限情况下，$P_{t|t} = P_{t-1|t-1} = P$。Riccati方程变为离散时间代数Riccati方程（DARE）：\n$$P = \\frac{R (P + Q)}{P + Q + R}$$\n为了求解 $P$，我们整理这个代数方程：\n$$P(P + Q + R) = R(P + Q)$$\n$$P^2 + PQ + PR = RP + RQ$$\n$$P^2 + PQ - RQ = 0$$\n这是一个关于 $P$ 的二次方程，形式为 $aP^2 + bP + c = 0$，其中 $a=1$，$b=Q$，$c=-RQ$。使用二次公式 $P = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$：\n$$P = \\frac{-Q \\pm \\sqrt{Q^2 - 4(1)(-RQ)}}{2} = \\frac{-Q \\pm \\sqrt{Q^2 + 4QR}}{2}$$\n由于 $P$ 代表方差，它必须是非负的（$P \\ge 0$）。鉴于 $Q  0$ 和 $R  0$，我们有 $\\sqrt{Q^2 + 4QR}  \\sqrt{Q^2} = Q$。因此，带有负号的根 $-Q - \\sqrt{Q^2 + 4QR}$ 是负的，必须作为非物理根舍弃。唯一有效的解是：\n$$P = \\frac{-Q + \\sqrt{Q^2 + 4QR}}{2}$$\n现在我们必须找到稳态卡尔曼增益 $K = \\lim_{t \\to \\infty} K_t$。我们可以使用前面推导的关系。一个巧妙的方法是首先建立 $P$ 和 $K$ 之间的直接联系。\n从增益方程 $K_t = \\frac{P_{t|t-1}}{P_{t|t-1} + R}$，我们得到 $K_t(P_{t|t-1} + R) = P_{t|t-1}$，整理后得 $P_{t|t-1}(1 - K_t) = K_t R$。\n从更新方程，$P_{t|t} = (1 - K_t)P_{t|t-1}$。\n比较这两个表达式，我们发现一个简单的关系：\n$$P_{t|t} = K_t R$$\n在稳态下，这变为 $P = KR$。\n\n我们现在可以将 $P = KR$ 代入我们找到的关于 $P$ 的二次方程中：\n$$P^2 + QP - RQ = 0$$\n$$(KR)^2 + Q(KR) - RQ = 0$$\n$$K^2 R^2 + KQR - QR = 0$$\n由于 $R  0$，我们可以将整个方程除以 $R$：\n$$R K^2 + Q K - Q = 0$$\n这是一个关于稳态增益 $K$ 的二次方程。我们使用二次公式求解 $K$，其中 $a=R$, $b=Q$, $c=-Q$：\n$$K = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} = \\frac{-Q \\pm \\sqrt{Q^2 - 4(R)(-Q)}}{2R}$$\n$$K = \\frac{-Q \\pm \\sqrt{Q^2 + 4QR}}{2R}$$\n卡尔曼增益 $K_t$ 必须在范围 $[0, 1]$ 内。在我们的情况下，由于 $P_{t|t-1}  0$ 且 $R  0$， $K_t = \\frac{P_{t|t-1}}{P_{t|t-1} + R}$ 严格在 $(0, 1)$ 区间内，因此稳态增益 $K$ 也必须是正的。和之前一样，项 $\\sqrt{Q^2 + 4QR}$ 大于 $Q$，所以负根会得到一个负的 $K$ 值，这在物理上是无效的。因此，我们必须选择正根：\n$$K = \\frac{-Q + \\sqrt{Q^2 + 4QR}}{2R}$$\n这个关于 $K$ 的表达式就是所要求的以 $Q$ 和 $R$ 表示的闭式解。",
            "answer": "$$\\boxed{\\frac{-Q + \\sqrt{Q^{2} + 4QR}}{2R}}$$"
        },
        {
            "introduction": "在真实场景中，我们不仅要估计系统的健康状态，还常常面临模型参数（如退化速率、噪声水平）未知以及传感器数据缺失的挑战。本练习将引导您应用期望最大化（EM）算法来解决这一复杂的联合估计问题。EM算法通过在两个步骤之间迭代来解决这个问题：E步（期望步）使用卡尔曼平滑器在给定当前参数的情况下推断隐藏状态，M步（最大化步）则更新参数以最好地解释这些推断出的状态。作为一个综合性练习，它要求您实现一个能够在数据不完整的情况下进行自校准和鲁棒健康追踪的复杂算法，从而弥合了理论与实际应用之间的鸿沟 。",
            "id": "4216256",
            "problem": "用于预测性维护的数字孪生对一个隐藏的标量健康状态进行建模，该状态随离散时间演化，并且由于传感器读数缺失而只能被部分观测。考虑以下针对单个资产在 $T$ 个时间步长上的线性高斯状态空间模型 (LGSSM)，其中隐藏的健康状态表示为 $x_t$，观测值表示为 $y_t$：\n$$\nx_1 \\sim \\mathcal{N}(\\mu_0, P_0), \\quad x_{t+1} = a x_t + u + w_t, \\quad w_t \\sim \\mathcal{N}(0,q), \\quad t = 1,\\dots,T-1,\n$$\n$$\ny_t = x_t + v_t, \\quad v_t \\sim \\mathcal{N}(0,r), \\quad t = 1,\\dots,T.\n$$\n一些 $y_t$ 值根据已知的二元掩码 $m_t \\in \\{0,1\\}$ 缺失，其中 $m_t=1$ 表示 $y_t$ 被观测到，而 $m_t=0$ 表示观测值缺失。目标是使用期望最大化 (EM) 算法进行联合状态与参数估计，即在推断状态后验分布的同时，估计参数向量 $\\theta = (a,u,q,r,\\mu_0,P_0)$。\n\n您必须：\n- 从第一性原理出发，推导该模型的期望步骤 (E-step) 和最大化步骤 (M-step)，推导应始于完全数据对数似然和高斯分布的贝叶斯法则。您的推导必须从高斯密度和线性状态空间传播的基本定义开始，并可以利用“线性高斯模型的后验分布是高斯分布”这一经过充分检验的原理。您不得在没有论证的情况下引用现成的快捷公式；相反，应展示充分统计量如何从线性高斯结构中产生，以及如何通过卡尔曼滤波和 Rauch-Tung-Striebel 平滑计算它们。\n- 实现一个完整的、可运行的程序，在下面定义的合成数据集上执行具有固定迭代次数 $I$ 的 EM 算法，并在卡尔曼更新中严格处理缺失的观测值。使用数值稳定的操作，并通过一个小的 $\\epsilon$ 设置下界来确保 $q  0$、$r  0$、$P_0  0$。\n\n实施要求：\n- 使用 $I=50$ 次 EM 迭代，无额外停止准则。\n- 用 $(a^{(0)},u^{(0)},q^{(0)},r^{(0)},\\mu_0^{(0)},P_0^{(0)}) = (0.5,0.0,0.1,0.1,0.0,1.0)$ 初始化参数。\n- 在 E-step 中，通过结合前向卡尔曼滤波器和后向 Rauch-Tung-Striebel 平滑器，计算平滑后的一阶矩 $E[x_t \\mid y_{1:T}]$、二阶矩 $E[x_t^2 \\mid y_{1:T}]$ 以及 $E[x_t x_{t+1} \\mid y_{1:T}]$（对于 $t=1,\\dots,T-1$），并正确处理缺失的观测值（$m_t=0$ 意味着在时间 $t$ 没有测量更新）。\n- 在 M-step 中，关于 $\\theta$ 最大化期望完全数据对数似然，并用 E-step 中计算的充分统计量来表示更新。您必须确保更新公式是通过最小化高斯模型所隐含的期望二次型推导出来的。\n- 在 $I$ 次迭代后，为每个测试案例输出最终的参数估计值 $(\\hat a,\\hat u,\\hat q,\\hat r,\\hat \\mu_0,\\hat P_0)$，并将每个值四舍五入到恰好 $6$ 位小数。\n\n数据生成和测试套件：\n- 对于每个测试案例，使用真实参数从 LGSSM 中采样生成一条轨迹，并使用指定的随机种子来设置伪随机数生成器。缺失掩码要么是具有指定率的随机伯努利分布，要么是按规定是确定性的。使用以下三个测试案例：\n    1. 测试 A（具有中等噪声的轻度稳定退化）：$T = 50$，真实参数 $(a,u,q,r,\\mu_0,P_0) = (0.98,0.05,0.01,0.04,0.0,0.5)$，缺失掩码 $m_t \\sim \\text{Bernoulli}(0.8)$，每个时间步独立，过程噪声、观测噪声以及缺失生成的种子均为 $7$。\n    2. 测试 B（带有漂移和低过程噪声的随机游走，高缺失率）：$T = 80$，真实参数 $(a,u,q,r,\\mu_0,P_0) = (1.0,0.02,0.001,0.01,-0.5,1.0)$，缺失掩码 $m_t \\sim \\text{Bernoulli}(0.5)$，种子为 $11$。\n    3. 测试 C（无漂移的健康衰减，结构化缺失）：$T = 40$，真实参数 $(a,u,q,r,\\mu_0,P_0) = (0.90,0.0,0.05,0.02,1.0,0.2)$，缺失掩码由 $m_t = 1$（对于奇数 $t$）和 $m_t = 0$（对于偶数 $t$）给出（确定性），过程噪声和观测噪声的种子为 $13$。\n\n要求的最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。每个元素都是一个包含六个浮点数的列表，对应一个测试案例的 $(\\hat a,\\hat u,\\hat q,\\hat r,\\hat \\mu_0,\\hat P_0)$，顺序为测试 A、测试 B、测试 C。例如，输出必须具有以下形式\n\"[[a_A,u_A,q_A,r_A,mu0_A,P0_A],[a_B,u_B,q_B,r_B,mu0_B,P0_B],[a_C,u_C,q_C,r_C,mu0_C,P0_C]]\"\n每个浮点数四舍五入到恰好 $6$ 位小数。",
            "solution": "该问题要求推导并实现期望最大化 (EM) 算法，以估计一个带有缺失观测值的标量线性高斯状态空间模型 (LGSSM) 的参数 $\\theta = (a, u, q, r, \\mu_0, P_0)$。\n\n模型定义如下：\n- 初始状态：$x_1 \\sim \\mathcal{N}(\\mu_0, P_0)$\n- 状态转移：$x_{t+1} = a x_t + u + w_t$，其中 $w_t \\sim \\mathcal{N}(0, q)$，对于 $t = 1, \\dots, T-1$\n- 观测：$y_t = x_t + v_t$，其中 $v_t \\sim \\mathcal{N}(0, r)$，对于 $t = 1, \\dots, T$\n- 缺失性：二元掩码 $m_t \\in \\{0, 1\\}$ 指示 $y_t$ 是被观测到 ($m_t=1$) 还是缺失 ($m_t=0$)。\n\nEM 算法是一种在具有潜变量的模型中寻找最大似然估计的迭代过程。它在期望 (E) 步骤和最大化 (M) 步骤之间交替进行。\n\n令 $X = \\{x_1, \\dots, x_T\\}$ 为潜状态，$Y_{obs} = \\{y_t \\mid m_t=1, t=1, \\dots, T\\}$ 为观测数据。目标是最大化边际对数似然 $\\log p(Y_{obs} | \\theta)$，这通常是难以直接处理的。EM 算法通过最大化期望完全数据对数似然 $Q(\\theta | \\theta^{(k)}) = E_{X|Y_{obs}, \\theta^{(k)}}[\\log p(X, Y_{obs} | \\theta)]$ 来实现，其中 $\\theta^{(k)}$ 是第 $k$ 次迭代时的参数估计值。\n\n**1. 完全数据对数似然**\n\n完全数据 $(X, Y_{obs})$ 的联合概率由模型各组成部分概率的乘积给出：\n$$p(X, Y_{obs} | \\theta) = p(x_1 | \\mu_0, P_0) \\left( \\prod_{t=1}^{T-1} p(x_{t+1} | x_t, a, u, q) \\right) \\left( \\prod_{t=1, m_t=1}^{T} p(y_t | x_t, r) \\right)$$\n相应的对数似然 $\\mathcal{L}_c(\\theta) = \\log p(X, Y_{obs} | \\theta)$ 是：\n$$ \\mathcal{L}_c(\\theta) = \\log p(x_1 | \\mu_0, P_0) + \\sum_{t=1}^{T-1} \\log p(x_{t+1} | x_t, a, u, q) + \\sum_{t=1}^{T} m_t \\log p(y_t | x_t, r) $$\n代入高斯概率密度函数 $p(z | \\mu, \\sigma^2) = (2\\pi\\sigma^2)^{-1/2} \\exp(-\\frac{(z-\\mu)^2}{2\\sigma^2})$，我们得到：\n$$ \\mathcal{L}_c(\\theta) = -\\frac{1}{2}\\log(2\\pi P_0) - \\frac{(x_1 - \\mu_0)^2}{2 P_0} - \\sum_{t=1}^{T-1} \\left( \\frac{1}{2}\\log(2\\pi q) + \\frac{(x_{t+1} - a x_t - u)^2}{2q} \\right) - \\sum_{t=1}^{T} m_t \\left( \\frac{1}{2}\\log(2\\pi r) + \\frac{(y_t - x_t)^2}{2r} \\right) $$\n这可以通过分离与参数相关的项来重新整理：\n$$ \\mathcal{L}_c(\\theta) = -\\frac{1}{2}\\log P_0 - \\frac{(x_1 - \\mu_0)^2}{2 P_0} - \\frac{T-1}{2}\\log q - \\frac{1}{2q}\\sum_{t=1}^{T-1}(x_{t+1} - a x_t - u)^2 - \\frac{\\sum m_t}{2}\\log r - \\frac{1}{2r}\\sum_{t=1}^{T} m_t (y_t - x_t)^2 + C $$\n其中 $C$ 是一个与参数 $\\theta$ 无关的常数。\n\n**2. E-步骤：计算充分统计量**\n\nE-步骤计算 $\\mathcal{L}_c(\\theta)$ 关于潜状态后验分布 $p(X | Y_{obs}, \\theta^{(k)})$ 的期望。我们将这个期望表示为 $E_k[\\cdot]$。$E_k[\\mathcal{L}_c(\\theta)]$ 中的相关项涉及潜状态 $x_t$ 函数的期望。这些是 M-步骤所需的充分统计量。\n让我们定义以下平滑期望，它们以所有观测值 $Y_{obs}$ 和当前参数集 $\\theta^{(k)}$ 为条件：\n- $\\hat{x}_{t|T} = E_k[x_t]$\n- $E_k[x_t^2] = \\text{Var}_k(x_t) + (E_k[x_t])^2 = P_{t|T} + \\hat{x}_{t|T}^2$\n- $E_k[x_t x_{t+1}] = \\text{Cov}_k(x_t, x_{t+1}) + E_k[x_t]E_k[x_{t+1}] = P_{t+1,t|T} + \\hat{x}_{t+1|T}\\hat{x}_{t|T}$\n\n对于 LGSSM，后验分布 $p(X | Y_{obs}, \\theta^{(k)})$ 是高斯分布。其矩可以通过一个双遍算法高效计算，该算法包括一个前向卡尔曼滤波器和一个后向 Rauch-Tung-Striebel (RTS) 平滑器。这些方程中的所有参数 $(a, u, q, r, \\mu_0, P_0)$ 都取自当前的估计值 $\\theta^{(k)}$。\n\n**卡尔曼滤波 (前向遍):**\n滤波器迭代地计算滤波分布 $p(x_t|y_{1:t}, \\theta^{(k)}) = \\mathcal{N}(x_t | \\hat{x}_{t|t}, P_{t|t})$。\n- **初始化 ($t=1$)：**\n  - 预测：$\\hat{x}_{1|0} = \\mu_0$， $P_{1|0} = P_0$。\n- **对于 $t=1, \\dots, T$：**\n  - **预测步骤 (如果 $t1$)：**\n    - $\\hat{x}_{t|t-1} = a \\hat{x}_{t-1|t-1} + u$\n    - $P_{t|t-1} = a^2 P_{t-1|t-1} + q$\n  - **更新步骤：**\n    - 如果观测值 $y_t$ 可用 ($m_t = 1$)：\n      - 残差：$\\tilde{y}_t = y_t - \\hat{x}_{t|t-1}$\n      - 残差协方差：$S_t = P_{t|t-1} + r$\n      - 卡尔曼增益：$K_t = P_{t|t-1} / S_t$\n      - 更新后的均值：$\\hat{x}_{t|t} = \\hat{x}_{t|t-1} + K_t \\tilde{y}_t$\n      - 更新后的协方差：$P_{t|t} = (1 - K_t) P_{t|t-1}$\n    - 如果观测值 $y_t$ 缺失 ($m_t = 0$)：\n      - $\\hat{x}_{t|t} = \\hat{x}_{t|t-1}$\n      - $P_{t|t} = P_{t|t-1}$\n\n**RTS 平滑器 (后向遍):**\n平滑器计算平滑分布 $p(x_t|Y_{obs}, \\theta^{(k)}) = \\mathcal{N}(x_t | \\hat{x}_{t|T}, P_{t|T})$ 和滞后一阶交叉协方差 $P_{t+1,t|T}$。\n- **初始化 ($t=T$)：**\n  - $\\hat{x}_{T|T}$ 和 $P_{T|T}$ 取自卡尔曼滤波的最后一步。\n- **对于 $t = T-1, \\dots, 1$：**\n  - 平滑器增益：$J_t = P_{t|t} a / P_{t+1|t}$\n  - 平滑后的均值：$\\hat{x}_{t|T} = \\hat{x}_{t|t} + J_t (\\hat{x}_{t+1|T} - \\hat{x}_{t+1|t})$\n  - 平滑后的协方差：$P_{t|T} = P_{t|t} + J_t^2 (P_{t+1|T} - P_{t+1|t})$\n- **滞后一阶协方差平滑器：** 在对均值和方差进行后向遍处理后，我们计算平滑后的滞后一阶协方差。\n- **对于 $t = 1, \\dots, T-1$：**\n  - $P_{t+1,t|T} = P_{t+1|T} J_t$\n\nE-步骤通过使用这些平滑矩来计算充分统计量而结束。\n\n**3. M-步骤：参数最大化**\n\nM-步骤通过关于 $\\theta$ 最大化 $Q(\\theta | \\theta^{(k)}) = E_k[\\mathcal{L}_c(\\theta)]$ 来更新参数 $\\theta^{(k+1)}$。\n\n- **$(\\mu_0, P_0)$ 的更新：**\n$Q$ 的相关部分是 $E_k[-\\frac{1}{2}\\log P_0 - \\frac{(x_1 - \\mu_0)^2}{2 P_0}]$。\n令 $\\frac{\\partial Q}{\\partial \\mu_0} = \\frac{1}{P_0}(E_k[x_1] - \\mu_0) = 0$ 可得 $\\mu_0^{(k+1)} = E_k[x_1] = \\hat{x}_{1|T}$。\n令 $\\frac{\\partial Q}{\\partial P_0} = -\\frac{1}{2P_0} + \\frac{E_k[(x_1 - \\mu_0)^2]}{2P_0^2} = 0$，并代入新的 $\\mu_0^{(k+1)}$，我们得到 $P_0^{(k+1)} = E_k[(x_1 - \\hat{x}_{1|T})^2] = P_{1|T}$。\n\n- **$(a, u)$ 的更新：**\n$Q$ 的相关部分涉及 $-\\frac{1}{2q}\\sum_{t=1}^{T-1}E_k[(x_{t+1} - a x_t - u)^2]$。最大化这一项等价于最小化平方和 $J(a,u) = \\sum_{t=1}^{T-1}E_k[(x_{t+1} - a x_t - u)^2]$。\n对 $a$ 和 $u$ 求导并令其为零，得到一个线性系统：\n$ \\frac{\\partial J}{\\partial u} = -2\\sum_{t=1}^{T-1}(E_k[x_{t+1}] - a E_k[x_t] - u) = 0 $\n$ \\frac{\\partial J}{\\partial a} = -2\\sum_{t=1}^{T-1}E_k[x_t(x_{t+1} - a x_t - u)] = 0 $\n这导出了正规方程组：\n$ \\begin{pmatrix} \\sum E_k[x_t^2]  \\sum E_k[x_t] \\\\ \\sum E_k[x_t]  \\sum 1 \\end{pmatrix} \\begin{pmatrix} a \\\\ u \\end{pmatrix} = \\begin{pmatrix} \\sum E_k[x_{t+1}x_t] \\\\ \\sum E_k[x_{t+1}] \\end{pmatrix} $\n其中求和范围为 $t=1$ 到 $T-1$。解这个 $2 \\times 2$ 的方程组可以得到更新后的 $a^{(k+1)}$ 和 $u^{(k+1)}$。\n\n- **$q$ 的更新：**\n$Q$ 的相关部分是 $-\\frac{T-1}{2}\\log q - \\frac{1}{2q}\\sum_{t=1}^{T-1}E_k[(x_{t+1} - a x_t - u)^2]$。\n令 $\\frac{\\partial Q}{\\partial q} = -\\frac{T-1}{2q} + \\frac{1}{2q^2}\\sum E_k[\\dots]^2 = 0$ 可得：\n$ q^{(k+1)} = \\frac{1}{T-1} \\sum_{t=1}^{T-1} E_k[(x_{t+1} - a^{(k+1)} x_t - u^{(k+1)})^2] $\n该期望可以使用充分统计量和新计算出的 $a^{(k+1)}, u^{(k+1)}$ 来展开。\n\n- **$r$ 的更新：**\n令 $N_{obs} = \\sum_{t=1}^T m_t$。$Q$ 的相关部分是 $-\\frac{N_{obs}}{2}\\log r - \\frac{1}{2r}\\sum_{t=1}^{T}m_t E_k[(y_t - x_t)^2]$。\n令 $\\frac{\\partial Q}{\\partial r} = -\\frac{N_{obs}}{2r} + \\frac{1}{2r^2}\\sum m_t E_k[(y_t-x_t)^2] = 0$ 可得：\n$ r^{(k+1)} = \\frac{1}{N_{obs}} \\sum_{t=1}^{T} m_t E_k[(y_t - x_t)^2] = \\frac{1}{N_{obs}} \\sum_{t=1}^{T} m_t ( (y_t - \\hat{x}_{t|T})^2 + P_{t|T} ) $\n\n该算法通过对 E 和 M 步骤进行固定次数的迭代来进行，并通过强制施加一个小的正下界 $\\epsilon$ 来确保方差参数 $q, r, P_0$ 保持为正。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    \n    # Small epsilon to enforce positivity of variance parameters\n    EPSILON = 1e-9\n    \n    # Test case definitions\n    test_cases = [\n        {\n            'name': 'Test A',\n            'T': 50,\n            'true_params': {'a': 0.98, 'u': 0.05, 'q': 0.01, 'r': 0.04, 'mu0': 0.0, 'P0': 0.5},\n            'mask_spec': ('bernoulli', 0.8),\n            'seed': 7\n        },\n        {\n            'name': 'Test B',\n            'T': 80,\n            'true_params': {'a': 1.0, 'u': 0.02, 'q': 0.001, 'r': 0.01, 'mu0': -0.5, 'P0': 1.0},\n            'mask_spec': ('bernoulli', 0.5),\n            'seed': 11\n        },\n        {\n            'name': 'Test C',\n            'T': 40,\n            'true_params': {'a': 0.90, 'u': 0.0, 'q': 0.05, 'r': 0.02, 'mu0': 1.0, 'P0': 0.2},\n            'mask_spec': ('deterministic_alt',),\n            'seed': 13\n        }\n    ]\n\n    # Shared settings\n    iterations = 50\n    initial_params = {'a': 0.5, 'u': 0.0, 'q': 0.1, 'r': 0.1, 'mu0': 0.0, 'P0': 1.0}\n    \n    final_results = []\n    \n    def generate_data(T, true_params, mask_spec, seed):\n        \"\"\"Generates synthetic data from the LGSSM.\"\"\"\n        rng = np.random.default_rng(seed)\n        \n        a, u, q, r, mu0, P0 = true_params.values()\n        \n        x = np.zeros(T)\n        y = np.zeros(T)\n        \n        # Generate states\n        x[0] = rng.normal(mu0, np.sqrt(P0))\n        for t in range(T - 1):\n            x[t+1] = a * x[t] + u + rng.normal(0, np.sqrt(q))\n            \n        # Generate observations\n        y = x + rng.normal(0, np.sqrt(r), size=T)\n        \n        # Generate mask\n        mask_type = mask_spec[0]\n        if mask_type == 'bernoulli':\n            p = mask_spec[1]\n            m = rng.binomial(1, p, size=T)\n        elif mask_type == 'deterministic_alt':\n            m = np.zeros(T)\n            m[::2] = 1 # odd t (1, 3, ...) corresponds to index 0, 2, ...\n        \n        y[m == 0] = np.nan # Mark missing values\n        \n        return y, m\n\n    def kalman_filter(y, m, params, T):\n        \"\"\"Performs the forward Kalman filter pass.\"\"\"\n        a, u, q, r, mu0, P0 = params['a'], params['u'], params['q'], params['r'], params['mu0'], params['P0']\n\n\n        x_pred = np.zeros(T)\n        P_pred = np.zeros(T)\n        x_filt = np.zeros(T)\n        P_filt = np.zeros(T)\n\n        # Time t=1 (index 0)\n        x_pred[0] = mu0\n        P_pred[0] = P0\n        \n        if m[0] == 1:\n            S = P_pred[0] + r\n            K = P_pred[0] / S if S > 0 else 0.0\n            x_filt[0] = x_pred[0] + K * (y[0] - x_pred[0])\n            P_filt[0] = (1 - K) * P_pred[0]\n        else:\n            x_filt[0] = x_pred[0]\n            P_filt[0] = P_pred[0]\n\n        # Time t=2...T (index 1...T-1)\n        for t in range(1, T):\n            # Prediction\n            x_pred[t] = a * x_filt[t-1] + u\n            P_pred[t] = a**2 * P_filt[t-1] + q\n            \n            # Update\n            if m[t] == 1:\n                S = P_pred[t] + r\n                K = P_pred[t] / S if S > 0 else 0.0\n                x_filt[t] = x_pred[t] + K * (y[t] - x_pred[t])\n                P_filt[t] = (1 - K) * P_pred[t]\n            else:\n                x_filt[t] = x_pred[t]\n                P_filt[t] = P_pred[t]\n                \n        return {\n            'x_pred': x_pred, 'P_pred': P_pred,\n            'x_filt': x_filt, 'P_filt': P_filt\n        }\n\n    def rts_smoother(filter_results, params, T):\n        \"\"\"Performs the backward RTS smoother pass.\"\"\"\n        a = params['a']\n        x_pred, P_pred = filter_results['x_pred'], filter_results['P_pred']\n        x_filt, P_filt = filter_results['x_filt'], filter_results['P_filt']\n\n        x_smooth = np.zeros(T)\n        P_smooth = np.zeros(T)\n        P_cov_smooth = np.zeros(T - 1)\n\n        x_smooth[T-1] = x_filt[T-1]\n        P_smooth[T-1] = P_filt[T-1]\n\n        for t in range(T - 2, -1, -1):\n            J = P_filt[t] * a / P_pred[t+1] if P_pred[t+1] > 0 else 0.0\n            x_smooth[t] = x_filt[t] + J * (x_smooth[t+1] - x_pred[t+1])\n            P_smooth[t] = P_filt[t] + J**2 * (P_smooth[t+1] - P_pred[t+1])\n        \n        # This covariance is P_{t,t-1|T}, not P_{t+1,t|T} as might be expected by index.\n        # But we compute P_{t+1,t|T} as P_cov_smooth[t].\n        J_prev = P_filt[:-1] * a / P_pred[1:]\n        J_prev[P_pred[1:] = 0] = 0.0\n        P_cov_smooth = P_smooth[1:] * J_prev\n\n\n        return {'x_smooth': x_smooth, 'P_smooth': P_smooth, 'P_cov_smooth': P_cov_smooth}\n\n    def e_step(y, m, params, T):\n        \"\"\"Performs the E-step.\"\"\"\n        filter_results = kalman_filter(y, m, params, T)\n        smoother_results = rts_smoother(filter_results, params, T)\n        \n        x_s = smoother_results['x_smooth']\n        P_s = smoother_results['P_smooth']\n        P_cov_s = smoother_results['P_cov_smooth']\n        \n        Ex = x_s\n        Ex2 = P_s + x_s**2\n        Exx_pair = P_cov_s + x_s[1:] * x_s[:-1]\n\n        return {'Ex': Ex, 'Ex2': Ex2, 'Exx_pair': Exx_pair, 'P_s': P_s}\n\n    def m_step(y, m, stats, T, params):\n        \"\"\"Performs the M-step.\"\"\"\n        Ex, Ex2, Exx_pair, P_s = stats['Ex'], stats['Ex2'], stats['Exx_pair'], stats['P_s']\n        \n        new_mu0 = Ex[0]\n        new_P0 = P_s[0]\n        \n        S_xx = np.sum(Ex2[:-1])\n        S_x = np.sum(Ex[:-1])\n        S_x_prime_x = np.sum(Exx_pair)\n        S_x_prime = np.sum(Ex[1:])\n        \n        T_minus_1 = T - 1\n        denom = T_minus_1 * S_xx - S_x**2\n        if np.abs(denom)  EPSILON:\n            new_a = params['a']\n            new_u = params['u']\n        else:\n            new_a = (T_minus_1 * S_x_prime_x - S_x * S_x_prime) / denom\n            new_u = (S_x_prime * S_xx - S_x * S_x_prime_x) / denom\n        \n        S_x_prime_x_prime = np.sum(Ex2[1:])\n        term1 = S_x_prime_x_prime\n        term2 = -2 * new_a * S_x_prime_x\n        term3 = -2 * new_u * S_x_prime\n        term4 = new_a**2 * S_xx\n        term5 = 2 * new_a * new_u * S_x\n        term6 = T_minus_1 * new_u**2\n        new_q = (term1 + term2 + term3 + term4 + term5 + term6) / T_minus_1\n        \n        N_obs = np.sum(m)\n        sum_r = 0\n        y_obs = y[m==1]\n        Ex_obs = Ex[m==1]\n        Ex2_obs = Ex2[m==1]\n        sum_r = np.sum(y_obs**2 - 2 * y_obs * Ex_obs + Ex2_obs)\n\n        if N_obs > 0:\n            new_r = sum_r / N_obs\n        else:\n            new_r = params['r']\n            \n        return {\n            'a': new_a, 'u': new_u, \n            'q': np.maximum(new_q, EPSILON), \n            'r': np.maximum(new_r, EPSILON),\n            'mu0': new_mu0, \n            'P0': np.maximum(new_P0, EPSILON)\n        }\n        \n    for case in test_cases:\n        y, m = generate_data(case['T'], case['true_params'], case['mask_spec'], case['seed'])\n        current_params = initial_params.copy()\n        \n        for _ in range(iterations):\n            sufficient_stats = e_step(y, m, current_params, case['T'])\n            current_params = m_step(y, m, sufficient_stats, case['T'], current_params)\n            \n        final_params = list(current_params.values())\n        rounded_params = [f\"{p:.6f}\" for p in final_params]\n        final_results.append(f\"[{','.join(rounded_params)}]\")\n\n    print(f\"[[{final_results[0][1:-1]}],[{final_results[1][1:-1]}],[{final_results[2][1:-1]}]]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}