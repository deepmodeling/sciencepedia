{
    "hands_on_practices": [
        {
            "introduction": "预测性维护的核心在于准确量化设备随时间变化的失效风险。本练习将带您深入探讨威布尔分布，这是一个在可靠性工程中广泛用于描述部件寿命的强大统计模型。通过亲手推导其可靠性与风险函数，您将理解如何将抽象的数学概念转化为指导维护策略（例如，何时进行预防性更换）的具体依据，并揭示不同失效模式（早期失效、随机失效或老化失效）对决策的深远影响。",
            "id": "4216187",
            "problem": "一个信息物理系统 (CPS) 中的旋转资产由一个数字孪生进行监控，该数字孪生通过估算资产推断的故障时间分布来执行预测性维护，从而估算瞬时故障风险。假设故障时间随机变量 $T$ 服从威布尔分布，其形状参数为 $k0$，尺度参数为 $\\lambda0$，在 $t \\ge 0$ 上的概率密度函数 $f(t)$ 由下式给出：\n$$\nf(t) = \\frac{k}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{k-1}\\exp\\!\\left(-\\left(\\frac{t}{\\lambda}\\right)^{k}\\right).\n$$\n数字孪生使用可靠性和风险率的基本定义：\n- 可靠性 $R(t)$ 为 $R(t) = \\mathbb{P}(Tt)$。\n- 风险率 $h(t)$ 为 $h(t) = \\frac{f(t)}{R(t)}$。\n\n采用风险阈值策略：当瞬时风险率首次等于给定阈值 $\\eta0$（单位为事件/小时）时，在时间 $t_{\\eta}$ 触发预防性更换。系统时间单位为小时。\n\n任务：\n1. 从上述 $f(t)$ 以及定义 $R(t) = \\mathbb{P}(Tt)$ 和 $h(t) = \\frac{f(t)}{R(t)}$ 出发，推导 $R(t)$ 和 $h(t)$ 在所有 $t \\ge 0$ 上的闭式表达式。\n2. 对于 $k \\ne 1$ 的情况，求解 $h(t_{\\eta}) = \\eta$ 得到 $t_{\\eta}$，并将其表示为以 $k$、$\\lambda$ 和 $\\eta$ 表示的闭式符号表达式（单位为小时）。然后，计算 $R(t_{\\eta})$，并将其表示为以 $k$、$\\lambda$ 和 $\\eta$ 表示的闭式符号表达式。\n3. 在维护策略设计的背景下，简要解释 $k1$、$k=1$ 和 $k1$ 这三种情况的定性含义，说明风险率 $h(t)$ 如何随时间演变，以及这对安排检查和更换有何启示。\n\n将您的最终答案以包含 $t_{\\eta}$ 和 $R(t_{\\eta})$（按此顺序）的单一复合表达式形式报告，使用最简化的闭式形式。将 $t_{\\eta}$ 以小时为单位表示。无需数值四舍五入。最终答案必须是实值符号表达式，且不得包含单位。",
            "solution": "问题陈述经评估有效。它在科学上基于可靠性工程和统计建模的原理，使用了威布尔分布、可靠性函数和风险率函数的标准定义。问题提法恰当，提供了所有必要的信息和定义以推导出唯一且有意义的解。它没有歧义、矛盾和事实错误。\n\n任务将按顺序解决。\n\n任务1：推导可靠性函数 $R(t)$ 和风险率函数 $h(t)$。\n\n可靠性函数 $R(t)$ 定义为故障时间 $T$ 大于某个时间 $t$ 的概率。它是累积分布函数 (CDF) $F(t) = \\mathbb{P}(T \\le t)$ 的补集。因此，$R(t) = 1 - F(t) = \\int_t^\\infty f(u) \\, du$。\n给定威布尔分布的概率密度函数 (PDF) $f(t)$：\n$$\nf(t) = \\frac{k}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{k-1}\\exp\\!\\left(-\\left(\\frac{t}{\\lambda}\\right)^{k}\\right) \\quad \\text{for } t \\ge 0\n$$\n我们计算 $R(t)$ 的积分：\n$$\nR(t) = \\int_t^\\infty \\frac{k}{\\lambda}\\left(\\frac{u}{\\lambda}\\right)^{k-1}\\exp\\!\\left(-\\left(\\frac{u}{\\lambda}\\right)^{k}\\right) du\n$$\n为求解此积分，我们使用换元法。令 $x = \\left(\\frac{u}{\\lambda}\\right)^{k}$。则其微分为 $dx = k\\left(\\frac{u}{\\lambda}\\right)^{k-1} \\cdot \\frac{1}{\\lambda} \\, du$。我们还必须更改积分上下限。当 $u \\to t$ 时，下限变为 $x = (t/\\lambda)^{k}$。当 $u \\to \\infty$ 时，上限变为 $x \\to \\infty$。\n代入积分中：\n$$\nR(t) = \\int_{(t/\\lambda)^{k}}^{\\infty} \\exp(-x) \\, dx\n$$\n这是一个标准的指数积分：\n$$\nR(t) = \\left[ -\\exp(-x) \\right]_{(t/\\lambda)^{k}}^{\\infty} = \\lim_{b \\to \\infty} (-\\exp(-b)) - (-\\exp(-(t/\\lambda)^{k}))\n$$\n由于 $\\lim_{b \\to \\infty} \\exp(-b) = 0$，上式简化为：\n$$\nR(t) = \\exp\\!\\left(-\\left(\\frac{t}{\\lambda}\\right)^{k}\\right)\n$$\n这就是可靠性函数在 $t \\ge 0$ 上的闭式表达式。\n\n接下来，我们推导风险率函数 $h(t)$，其定义为 $h(t) = \\frac{f(t)}{R(t)}$。\n使用给定的 $f(t)$ 表达式和推导出的 $R(t)$ 表达式：\n$$\nh(t) = \\frac{\\frac{k}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{k-1}\\exp\\!\\left(-\\left(\\frac{t}{\\lambda}\\right)^{k}\\right)}{\\exp\\!\\left(-\\left(\\frac{t}{\\lambda}\\right)^{k}\\right)}\n$$\n分子和分母中的指数项相互抵消，得到：\n$$\nh(t) = \\frac{k}{\\lambda}\\left(\\frac{t}{\\lambda}\\right)^{k-1}\n$$\n这就是瞬时风险率函数在 $t \\ge 0$ 上的闭式表达式。\n\n任务2：对于 $k \\ne 1$ 的情况，求解更换时间 $t_{\\eta}$ 及其在该时间的可靠性 $R(t_{\\eta})$。\n\n更换时间 $t_{\\eta}$ 由条件 $h(t_{\\eta}) = \\eta$ 定义，其中 $\\eta  0$ 是一个恒定的风险阈值。\n$$\n\\frac{k}{\\lambda}\\left(\\frac{t_{\\eta}}{\\lambda}\\right)^{k-1} = \\eta\n$$\n我们求解此方程以得到 $t_{\\eta}$。首先，分离出包含 $t_{\\eta}$ 的项：\n$$\n\\left(\\frac{t_{\\eta}}{\\lambda}\\right)^{k-1} = \\frac{\\eta \\lambda}{k}\n$$\n由于问题指定 $k \\ne 1$，指数 $(k-1)$ 非零，我们可以对两边取 $(1/(k-1))$ 次方：\n$$\n\\frac{t_{\\eta}}{\\lambda} = \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{1}{k-1}}\n$$\n乘以 $\\lambda$ 得到 $t_{\\eta}$ 的最终表达式（单位为小时）：\n$$\nt_{\\eta} = \\lambda \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{1}{k-1}}\n$$\n接下来，我们计算在这个特定时间的可靠性 $R(t_{\\eta})$。我们使用推导出的 $R(t)$ 表达式：\n$$\nR(t_{\\eta}) = \\exp\\!\\left(-\\left(\\frac{t_{\\eta}}{\\lambda}\\right)^{k}\\right)\n$$\n从上一步中，我们得到了项 $t_{\\eta}/\\lambda$ 的表达式：\n$$\n\\frac{t_{\\eta}}{\\lambda} = \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{1}{k-1}}\n$$\n我们将此表达式取 $k$ 次方：\n$$\n\\left(\\frac{t_{\\eta}}{\\lambda}\\right)^{k} = \\left[ \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{1}{k-1}} \\right]^k = \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{k}{k-1}}\n$$\n将此代回可靠性函数：\n$$\nR(t_{\\eta}) = \\exp\\!\\left( - \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{k}{k-1}} \\right)\n$$\n这就提供了 $t_{\\eta}$ 和 $R(t_{\\eta})$ 的闭式符号表达式。\n\n任务3：对形状参数 $k$ 的解释。\n\n风险率函数 $h(t) = \\frac{k}{\\lambda}(\\frac{t}{\\lambda})^{k-1}$ 的行为由指数 $k-1$ 的符号决定。\n- 情况 $k  1$：在这种情况下，指数 $k-1$ 为负。因此，对于 $t  0$，$h(t)$ 是时间 $t$ 的递减函数。这模拟了“早期失效”或早期故障。故障风险在开始时最高，并随着部件的运行而降低。这意味着如果一个资产度过了其初始阶段，它会变得更可靠。对于维护策略，这表明基于年龄的预防性更换会适得其反；一个磨合期可能是有益的，而其他维护策略（例如，故障后进行纠正性维护）更为合适。\n- 情况 $k = 1$：指数 $k-1$ 为零。风险率函数变为常数：$h(t) = \\frac{1}{\\lambda}(\\frac{t}{\\lambda})^{0} = \\frac{1}{\\lambda}$。这对应于指数分布。故障风险随时间恒定，表明故障是随机且无记忆性的。就故障风险而言，资产不会“老化”。对于维护策略，这意味着在固定年龄进行预防性更换相比于故障后更换没有任何优势，因为一个旧部件在下一小时内发生故障的可能性不比一个新部件高。\n- 情况 $k  1$：指数 $k-1$ 为正。因此，$h(t)$ 是时间 $t$ 的递增函数。这模拟了由老化和磨损引起的故障，这在机械部件中很常见。故障风险随运行年龄的增加而增加。对于维护策略，这是预测性和预防性维护最有效的典型场景。采用风险阈值策略是合理的，因为它允许在故障风险变得不可接受之高以前更换部件，从而在充分利用部件寿命和避免代价高昂的运行中故障之间进行优化权衡。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\lambda \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{1}{k-1}} \\\\ \\exp\\left( - \\left(\\frac{\\eta \\lambda}{k}\\right)^{\\frac{k}{k-1}} \\right)\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "数字孪生通过分析传感器数据来推断设备内部不可见的健康状态，但我们如何确保这些关键状态能够被“观测”到？本练习将引导您探索可观测性这一基本概念，它是判断能否从外部测量中唯一确定系统内部状态的理论基石。您将从第一性原理出发，推导线性系统的可观测性条件，并将其应用于一个具体的动态系统，从而深刻理解系统动力学和传感器配置如何共同决定了预测性维护模型的有效性。",
            "id": "4216200",
            "problem": "一个用于信息物理系统（CPS）中旋转机械的数字孪生（DT）使用一个线性时不变连续时间子系统来估计潜在健康状态，以进行预测性维护。考虑由状态空间方程 $\\dot{x}(t) = A x(t) + B u(t)$ 和输出 $y(t) = C x(t)$ 定义的子系统，其中 $x(t) \\in \\mathbb{R}^{n}$，$u(t) \\in \\mathbb{R}^{m}$，$y(t) \\in \\mathbb{R}^{p}$。潜在状态 $x(t)$ 包含一个健康变量，其准确估计对维护决策至关重要。从线性时不变系统的可观测性基本定义出发：对于在有限区间 $[0,T]$ 上的已知输入 $u(t)$，初始状态 $x(0)$ 由在 $[0,T]$ 上测量的输出 $y(t)$ 唯一确定。仅使用此定义，通过将 $t=0$ 时的输出及其逐次时间导数与初始状态 $x(0)$ 相关联，推导出系统对 $(A,C)$ 可观测的充分必要条件。解释该条件如何确保从 $x(0)$ 到输出特征的映射的单射性，并阐明其在预测性维护背景下的解释，特别是关于健康状态是否可以从测量输出中推断出来。\n\n然后，对于下面给出的具体数字孪生线性化模型，计算在 $t=0$ 时由输出的直至 $n-1$ 阶（其中 $n=4$）的逐次时间导数构成的堆叠灵敏度算子的秩。使用此秩来评估该子系统的可观测性，并将结论与健康可估性联系起来：\n\n$$\nA = \\begin{pmatrix}\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1 \\\\\n-0.8  -0.5  -0.3  -0.1\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n0 \\\\\n0\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1  0  0  0\n\\end{pmatrix}.\n$$\n\n将您的最终答案表示为该算子的整数秩。无需四舍五入。以无单位的纯整数形式提供最终答案。",
            "solution": "该问题被评估为有效，因为它在科学上基于线性系统理论，是适定的、客观的，并包含唯一解所需的所有必要信息。它要求从第一性原理推导可观测性条件，并将其应用于一个具体系统，这是控制工程中一个标准且有意义的练习。\n\n我们首先建立线性时不变（LTI）系统可观测性的充分必要条件。该系统由状态空间方程描述：\n$$ \\dot{x}(t) = A x(t) + B u(t) $$\n$$ y(t) = C x(t) $$\n其中 $x(t) \\in \\mathbb{R}^{n}$ 是状态向量，$u(t) \\in \\mathbb{R}^{m}$ 是输入向量，$y(t) \\in \\mathbb{R}^{p}$ 是输出向量。矩阵 $A$、$B$ 和 $C$ 是具有适当维度的常数矩阵。\n\n可观测性的定义指出，如果对于在有限时间区间 $[0,T]$ 上的任何已知输入 $u(t)$，初始状态 $x(0)$ 可以从同一区间上的输出历史 $y(t)$ 中唯一确定，则系统是可观测的。\n\n状态方程的解由常数变易法公式给出：\n$$ x(t) = e^{At} x(0) + \\int_{0}^{t} e^{A(t-\\tau)} B u(\\tau) d\\tau $$\n将其代入输出方程得到：\n$$ y(t) = C e^{At} x(0) + C \\int_{0}^{t} e^{A(t-\\tau)} B u(\\tau) d\\tau $$\n为了确定初始状态 $x(0)$，我们可以重新排列这个方程：\n$$ y(t) - C \\int_{0}^{t} e^{A(t-\\tau)} B u(\\tau) d\\tau = C e^{At} x(0) $$\n由于输入 $u(t)$ 是已知的，左侧的积分项是一个已知的时间函数。让我们将左侧表示为 $\\tilde{y}(t)$。从 $y(t)$ 和 $u(t)$ 确定 $x(0)$ 的问题等价于从 $\\tilde{y}(t)$ 确定 $x(0)$，其中 $\\tilde{y}(t) = C e^{At} x(0)$。这是输入为零时系统的响应。因此，系统对 $(A,C)$ 的可观测性仅取决于矩阵 $A$ 和 $C$，而与矩阵 $B$ 无关。\n\n问题指导我们使用 $t=0$ 时输出的逐次时间导数。为了确定 $x(0)$，我们不妨考虑 $u(t)=0$ 的系统。\n输出为 $y(t) = C x(t)$。\n输出的一阶时间导数为：\n$$ \\dot{y}(t) = \\frac{d}{dt}(C x(t)) = C \\dot{x}(t) = C (A x(t)) = C A x(t) $$\n二阶时间导数为：\n$$ \\ddot{y}(t) = \\frac{d}{dt}(C A x(t)) = C A \\dot{x}(t) = C A (A x(t)) = C A^2 x(t) $$\n继续这个过程，输出的 $k$ 阶导数为：\n$$ y^{(k)}(t) = C A^k x(t) $$\n现在，我们在初始时间 $t=0$ 评估这些导数：\n$$ y(0) = C x(0) $$\n$$ \\dot{y}(0) = C A x(0) $$\n$$ \\ddot{y}(0) = C A^2 x(0) $$\n$$ \\vdots $$\n$$ y^{(n-1)}(0) = C A^{n-1} x(0) $$\n我们考虑直到 $n-1$ 阶的导数，其中 $n$ 是状态空间的维度。根据 Cayley-Hamilton 定理，$A$ 的任何 $n$ 次或更高次幂都可以表示为 $A$ 的 $0$ 次到 $n-1$ 次幂的线性组合。因此，$n$ 阶或更高阶的导数不会提供关于 $x(0)$ 的新的线性无关信息。\n\n我们可以将这 $n$ 个向量方程堆叠成一个单一的矩阵方程：\n$$ \\begin{pmatrix} y(0) \\\\ \\dot{y}(0) \\\\ \\ddot{y}(0) \\\\ \\vdots \\\\ y^{(n-1)}(0) \\end{pmatrix} = \\begin{pmatrix} C \\\\ CA \\\\ CA^2 \\\\ \\vdots \\\\ CA^{n-1} \\end{pmatrix} x(0) $$\n令 $Y_0$ 为左侧堆叠的输出导数的列向量，令 $\\mathcal{O}$ 为右侧的矩阵，称为可观测性矩阵。这就是问题中提到的“堆叠灵敏度算子”，因为它将初始状态 $x(0)$ 与输出特征 $Y_0$ 联系起来。\n方程为 $Y_0 = \\mathcal{O} x(0)$。\n\n为了从向量 $Y_0$ 中唯一确定初始状态 $x(0)$，由矩阵 $\\mathcal{O}$ 表示的线性映射必须是单射的。一个单射线性映射的零空间（或核）只包含零向量。这意味着如果 $\\mathcal{O}z = 0$，则必须有 $z=0$。对于一个矩阵，此属性等价于其列是线性无关的。矩阵 $\\mathcal{O}$ 的维度是 $(np) \\times n$。为了使其列线性无关，矩阵必须具有满列秩。因此，可观测性的充分必要条件是：\n$$ \\text{rank}(\\mathcal{O}) = n $$\n其中 $\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\\\ \\vdots \\\\ CA^{n-1} \\end{pmatrix}$。这就是卡尔曼可观测性秩条件。\n\n在旋转机械的预测性维护背景下，状态向量 $x(t)$ 代表机器的物理状态，包括位置、速度等变量，以及重要的潜在健康指标（例如，轴承磨损、轴不平衡）。输出向量 $y(t)$ 代表传感器测量值（例如，振动、温度）。条件 $\\text{rank}(\\mathcal{O}) = n$ 确保状态向量的每个分量，包括不可测量的健康变量，都对测量输出序列产生唯一的影响。如果系统是可观测的，数字孪生原则上可以从传感器数据特征中完美地重建初始健康状态 $x(0)$，并进而重建整个状态轨迹 $x(t)$。如果系统不可观测，某些健康退化模式对传感器来说将是“不可见”的，从而阻止数字孪生做出准确的维护预测。\n\n现在，我们将此条件应用于给定的具体系统。\n状态维度为 $n=4$。矩阵为：\n$$ A = \\begin{pmatrix} 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\\\ -0.8  -0.5  -0.3  -0.1 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 1  0  0  0 \\end{pmatrix} $$\n我们必须计算可观测性矩阵 $\\mathcal{O}$ 及其秩。\n$$ \\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\\\ CA^2 \\\\ CA^3 \\end{pmatrix} $$\n各分量计算如下：\n$C = \\begin{pmatrix} 1  0  0  0 \\end{pmatrix}$\n$CA = \\begin{pmatrix} 1  0  0  0 \\end{pmatrix} A = \\begin{pmatrix} 0  1  0  0 \\end{pmatrix}$ (这是 $A$ 的第一行)\n$CA^2 = (CA)A = \\begin{pmatrix} 0  1  0  0 \\end{pmatrix} A = \\begin{pmatrix} 0  0  1  0 \\end{pmatrix}$ (这是 $A$ 的第二行)\n$CA^3 = (CA^2)A = \\begin{pmatrix} 0  0  1  0 \\end{pmatrix} A = \\begin{pmatrix} 0  0  0  1 \\end{pmatrix}$ (这是 $A$ 的第三行)\n\n组合可观测性矩阵 $\\mathcal{O}$：\n$$ \\mathcal{O} = \\begin{pmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\end{pmatrix} $$\n这是 $4 \\times 4$ 的单位矩阵，$I_4$。\n矩阵的秩是线性无关的行或列的数量。单位矩阵 $I_4$ 有 4 个线性无关的列。\n因此，可观测性矩阵的秩为：\n$$ \\text{rank}(\\mathcal{O}) = \\text{rank}(I_4) = 4 $$\n由于 $\\mathcal{O}$ 的秩为 4，等于状态维度 $n=4$，因此该系统是完全可观测的。\n\n关于健康可估性的结论：因为系统是可观测的，所以可以从测量值中唯一确定初始状态向量 $x(0)$。这意味着所有潜在状态，包括任何代表机器健康状况的状态，都可以从传感器输出中推断出来。基于此线性化模型的数字孪生将能够成功估计旋转机械的健康状况，为预测性维护策略奠定有效的基础。",
            "answer": "$$\n\\boxed{4}\n$$"
        },
        {
            "introduction": "在真实工业场景中，我们不仅需要估计设备的健康状态，还常常面临模型参数未知和传感器数据缺失的双重挑战。本练习将指导您实现期望最大化（EM）算法，这是一种强大的迭代方法，能够同时学习模型参数并推断隐藏的系统状态。通过结合用于状态推断的卡尔曼平滑（E步）和用于参数更新的最大似然估计（M步），您将构建一个能够从不完整数据中自适应学习的数字孪生，这是迈向高级预测性维护系统的关键一步。",
            "id": "4216256",
            "problem": "用于预测性维护的数字孪生模型对一个隐藏的标量健康状态进行建模，该状态随离散时间演化，并且由于传感器读数缺失而只能被部分观测到。考虑以下针对单个资产在 $T$ 个时间步长上的线性高斯状态空间模型（LGSSM），其中隐藏的健康状态表示为 $x_t$，观测值表示为 $y_t$：\n$$\nx_1 \\sim \\mathcal{N}(\\mu_0, P_0), \\quad x_{t+1} = a x_t + u + w_t, \\quad w_t \\sim \\mathcal{N}(0,q), \\quad t = 1,\\dots,T-1,\n$$\n$$\ny_t = x_t + v_t, \\quad v_t \\sim \\mathcal{N}(0,r), \\quad t = 1,\\dots,T.\n$$\n部分 $y_t$ 值根据一个已知的二进制掩码 $m_t \\in \\{0,1\\}$ 缺失，其中 $m_t = 1$ 表示 $y_t$ 被观测到，而 $m_t = 0$ 表示观测值缺失。目标是使用期望最大化（EM）算法进行联合状态和参数估计，即在推断状态后验分布的同时，估计参数向量 $\\theta = (a,u,q,r,\\mu_0,P_0)$。\n\n您必须：\n- 从第一性原理出发，推导该模型的期望步骤（E-step）和最大化步骤（M-step），推导应从完整数据对数似然和高斯分布的贝叶斯法则开始。您的推导必须从高斯密度和线性状态空间传播的基本定义开始，并可以利用线性高斯模型的后验分布是高斯的这一经过充分验证的原理。您不能未经论证就引用现成的快捷公式；相反，您必须展示充分统计量如何从线性高斯结构中产生，以及如何通过卡尔曼滤波和 Rauch-Tung-Striebel 平滑计算它们。\n- 实现一个完整的、可运行的程序，在下面定义的合成数据集上执行具有固定迭代次数 $I$ 的EM算法，并在卡尔曼更新中严格处理缺失的观测值。请使用数值稳定的操作，并通过一个小的 $\\epsilon$ 设置下界来强制 $q  0$、$r  0$、$P_0  0$。\n\n实现要求：\n- 使用 $I=50$ 次EM迭代，无额外停止准则。\n- 用 $(a^{(0)},u^{(0)},q^{(0)},r^{(0)},\\mu_0^{(0)},P_0^{(0)}) = (0.5,0.0,0.1,0.1,0.0,1.0)$ 初始化参数。\n- 在E-step中，通过结合前向卡尔曼滤波器和后向Rauch-Tung-Striebel平滑器，计算平滑后的一阶和二阶矩 $E[x_t \\mid y_{1:T}]$、$E[x_t^2 \\mid y_{1:T}]$ 以及 $E[x_t x_{t+1} \\mid y_{1:T}]$（对于 $t=1,\\dots,T-1$），并正确处理缺失的观测值（$m_t=0$ 意味着在时间 $t$ 没有测量更新）。\n- 在M-step中，相对于 $\\theta$ 最大化期望的完整数据对数似然，用E-step中计算出的充分统计量来表示更新。您必须确保更新公式是通过最小化高斯模型所蕴含的期望二次型推导出来的。\n- 在 $I$ 次迭代后，为每个测试用例输出最终的参数估计值 $(\\hat a,\\hat u,\\hat q,\\hat r,\\hat \\mu_0,\\hat P_0)$，每个值四舍五入到恰好 $6$ 位小数。\n\n数据生成和测试套件：\n- 对于每个测试用例，使用真实参数从LGSSM中采样生成一条轨迹，并使用指定的随机种子来设置伪随机数生成器。缺失掩码可以是指定比率的随机伯努利分布，也可以是指定的确定性模式。使用以下三个测试用例：\n    1. 测试A（轻度稳定退化与中等噪声）：$T = 50$，真实参数 $(a,u,q,r,\\mu_0,P_0) = (0.98,0.05,0.01,0.04,0.0,0.5)$，缺失掩码 $m_t \\sim \\text{Bernoulli}(0.8)$，每个时间步独立生成，过程噪声、观测噪声以及缺失掩码生成的种子均为 $7$。\n    2. 测试B（带漂移的随机游走与低过程噪声，高缺失率）：$T = 80$，真实参数 $(a,u,q,r,\\mu_0,P_0) = (1.0,0.02,0.001,0.01,-0.5,1.0)$，缺失掩码 $m_t \\sim \\text{Bernoulli}(0.5)$，种子为 $11$。\n    3. 测试C（无漂移的健康衰减，结构化缺失）：$T = 40$，真实参数 $(a,u,q,r,\\mu_0,P_0) = (0.90,0.0,0.05,0.02,1.0,0.2)$，缺失掩码由 $m_t = 1$（当 $t$ 为奇数时）和 $m_t = 0$（当 $t$ 为偶数时）给出（确定性），过程噪声和观测噪声的种子为 $13$。\n\n要求的最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。每个元素都是一个包含六个浮点数的列表，对应于一个测试用例的 $(\\hat a,\\hat u,\\hat q,\\hat r,\\hat \\mu_0,\\hat P_0)$，顺序为测试A、测试B、测试C。例如，输出必须具有以下形式\n\"[[a_A,u_A,q_A,r_A,mu0_A,P0_A],[a_B,u_B,q_B,r_B,mu0_B,P0_B],[a_C,u_C,q_C,r_C,mu0_C,P0_C]]\"\n每个浮点数四舍五入到恰好 $6$ 位小数。",
            "solution": "该问题要求推导和实现期望最大化（EM）算法，以估计带有缺失观测值的标量线性高斯状态空间模型（LGSSM）的参数 $\\theta = (a, u, q, r, \\mu_0, P_0)$。\n\n该模型定义如下：\n- 初始状态：$x_1 \\sim \\mathcal{N}(\\mu_0, P_0)$\n- 状态转移：$x_{t+1} = a x_t + u + w_t$，其中 $w_t \\sim \\mathcal{N}(0, q)$，对于 $t = 1, \\dots, T-1$\n- 观测：$y_t = x_t + v_t$，其中 $v_t \\sim \\mathcal{N}(0, r)$，对于 $t = 1, \\dots, T$\n- 缺失性：一个二进制掩码 $m_t \\in \\{0, 1\\}$ 指示 $y_t$ 是被观测到的（$m_t=1$）还是缺失的（$m_t=0$）。\n\nEM算法是在含有潜变量的模型中寻找最大似然估计的一种迭代过程。它在期望（E）步骤和最大化（M）步骤之间交替进行。\n\n令 $X = \\{x_1, \\dots, x_T\\}$ 为潜状态，$Y_{obs} = \\{y_t \\mid m_t=1, t=1, \\dots, T\\}$ 为观测数据。目标是最大化边际对数似然 $\\log p(Y_{obs} | \\theta)$，这通常是难以直接处理的。EM算法通过最大化期望的完整数据对数似然 $Q(\\theta | \\theta^{(k)}) = E_{X|Y_{obs}, \\theta^{(k)}}[\\log p(X, Y_{obs} | \\theta)]$ 来实现，其中 $\\theta^{(k)}$ 是在第 $k$ 次迭代时的参数估计值。\n\n**1. 完整数据对数似然**\n\n完整数据 $(X, Y_{obs})$ 的联合概率由模型各组成部分的概率之积给出：\n$$p(X, Y_{obs} | \\theta) = p(x_1 | \\mu_0, P_0) \\left( \\prod_{t=1}^{T-1} p(x_{t+1} | x_t, a, u, q) \\right) \\left( \\prod_{t=1, m_t=1}^{T} p(y_t | x_t, r) \\right)$$\n相应的对数似然 $\\mathcal{L}_c(\\theta) = \\log p(X, Y_{obs} | \\theta)$ 为：\n$$ \\mathcal{L}_c(\\theta) = \\log p(x_1 | \\mu_0, P_0) + \\sum_{t=1}^{T-1} \\log p(x_{t+1} | x_t, a, u, q) + \\sum_{t=1}^{T} m_t \\log p(y_t | x_t, r) $$\n代入高斯概率密度函数 $p(z | \\mu, \\sigma^2) = (2\\pi\\sigma^2)^{-1/2} \\exp(-\\frac{(z-\\mu)^2}{2\\sigma^2})$，我们得到：\n$$ \\mathcal{L}_c(\\theta) = -\\frac{1}{2}\\log(2\\pi P_0) - \\frac{(x_1 - \\mu_0)^2}{2 P_0} - \\sum_{t=1}^{T-1} \\left( \\frac{1}{2}\\log(2\\pi q) + \\frac{(x_{t+1} - a x_t - u)^2}{2q} \\right) - \\sum_{t=1}^{T} m_t \\left( \\frac{1}{2}\\log(2\\pi r) + \\frac{(y_t - x_t)^2}{2r} \\right) $$\n这可以通过分离依赖于参数的项来重新整理：\n$$ \\mathcal{L}_c(\\theta) = -\\frac{1}{2}\\log P_0 - \\frac{(x_1 - \\mu_0)^2}{2 P_0} - \\frac{T-1}{2}\\log q - \\frac{1}{2q}\\sum_{t=1}^{T-1}(x_{t+1} - a x_t - u)^2 - \\frac{\\sum m_t}{2}\\log r - \\frac{1}{2r}\\sum_{t=1}^{T} m_t (y_t - x_t)^2 + C $$\n其中 $C$ 是一个与参数 $\\theta$ 无关的常数。\n\n**2. E-Step：计算充分统计量**\n\nE-step计算 $\\mathcal{L}_c(\\theta)$ 关于潜状态后验分布 $p(X | Y_{obs}, \\theta^{(k)})$ 的期望。我们将此期望表示为 $E_k[\\cdot]$。$E_k[\\mathcal{L}_c(\\theta)]$ 中的相关项涉及潜状态 $x_t$ 函数的期望。这些是M-step所需的充分统计量。\n让我们定义以下平滑期望，它们以所有观测值 $Y_{obs}$ 和当前参数集 $\\theta^{(k)}$ 为条件：\n- $\\hat{x}_{t|T} = E_k[x_t]$\n- $E_k[x_t^2] = \\text{Var}_k(x_t) + (E_k[x_t])^2 = P_{t|T} + \\hat{x}_{t|T}^2$\n- $E_k[x_t x_{t+1}] = \\text{Cov}_k(x_t, x_{t+1}) + E_k[x_t]E_k[x_{t+1}] = P_{t+1,t|T} + \\hat{x}_{t+1|T}\\hat{x}_{t|T}$\n\n对于LGSSM，后验分布 $p(X | Y_{obs}, \\theta^{(k)})$ 是高斯分布。其矩可以通过一个两遍算法高效计算，该算法包括一个前向卡尔曼滤波器和一个后向 Rauch-Tung-Striebel（RTS）平滑器。这些方程中的所有参数 $(a, u, q, r, \\mu_0, P_0)$ 都取自当前的估计值 $\\theta^{(k)}$。\n\n**卡尔曼滤波器（前向传递）：**\n该滤波器迭代计算滤波分布 $p(x_t|y_{1:t}, \\theta^{(k)}) = \\mathcal{N}(x_t | \\hat{x}_{t|t}, P_{t|t})$。\n- **初始化 ($t=1$):**\n  - 预测：$\\hat{x}_{1|0} = \\mu_0$，$P_{1|0} = P_0$。\n- **对于 $t=1, \\dots, T$:**\n  - **预测步骤 (如果 $t1$):**\n    - $\\hat{x}_{t|t-1} = a \\hat{x}_{t-1|t-1} + u$\n    - $P_{t|t-1} = a^2 P_{t-1|t-1} + q$\n  - **更新步骤：**\n    - 如果观测值 $y_t$ 可用 ($m_t = 1$):\n      - 残差：$\\tilde{y}_t = y_t - \\hat{x}_{t|t-1}$\n      - 残差协方差：$S_t = P_{t|t-1} + r$\n      - 卡尔曼增益：$K_t = P_{t|t-1} / S_t$\n      - 更新后均值：$\\hat{x}_{t|t} = \\hat{x}_{t|t-1} + K_t \\tilde{y}_t$\n      - 更新后协方差：$P_{t|t} = (1 - K_t) P_{t|t-1}$\n    - 如果观测值 $y_t$ 缺失 ($m_t = 0$):\n      - $\\hat{x}_{t|t} = \\hat{x}_{t|t-1}$\n      - $P_{t|t} = P_{t|t-1}$\n\n**RTS平滑器（后向传递）：**\n平滑器计算平滑分布 $p(x_t|Y_{obs}, \\theta^{(k)}) = \\mathcal{N}(x_t | \\hat{x}_{t|T}, P_{t|T})$ 和滞后一阶的互协方差 $P_{t+1,t|T}$。\n- **初始化 ($t=T$):**\n  - $\\hat{x}_{T|T}$ 和 $P_{T|T}$ 取自卡尔曼滤波器的最后一步。\n- **对于 $t = T-1, \\dots, 1$:**\n  - 平滑器增益：$J_t = P_{t|t} a / P_{t+1|t}$\n  - 平滑后均值：$\\hat{x}_{t|T} = \\hat{x}_{t|t} + J_t (\\hat{x}_{t+1|T} - \\hat{x}_{t+1|t})$\n  - 平滑后协方差：$P_{t|T} = P_{t|t} + J_t^2 (P_{t+1|T} - P_{t+1|t})$\n- **滞后一阶协方差平滑器：** 在对均值和方差进行后向传递之后，我们计算平滑后的滞后一阶协方差。\n- **对于 $t = 1, \\dots, T-1$:**\n  - $P_{t+1,t|T} = P_{t+1|T} J_t$\n\nE-step通过使用这些平滑矩计算充分统计量来结束。\n\n**3. M-Step：参数最大化**\n\nM-step通过相对于 $\\theta$ 最大化 $Q(\\theta | \\theta^{(k)}) = E_k[\\mathcal{L}_c(\\theta)]$ 来更新参数 $\\theta^{(k+1)}$。\n\n- **$(\\mu_0, P_0)$ 的更新：**\n$Q$ 的相关部分是 $E_k[-\\frac{1}{2}\\log P_0 - \\frac{(x_1 - \\mu_0)^2}{2 P_0}]$。\n令 $\\frac{\\partial Q}{\\partial \\mu_0} = \\frac{1}{P_0}(E_k[x_1] - \\mu_0) = 0$ 得到 $\\mu_0^{(k+1)} = E_k[x_1] = \\hat{x}_{1|T}$。\n令 $\\frac{\\partial Q}{\\partial P_0} = -\\frac{1}{2P_0} + \\frac{E_k[(x_1 - \\mu_0)^2]}{2P_0^2} = 0$，并代入新的 $\\mu_0^{(k+1)}$，我们得到 $P_0^{(k+1)} = E_k[(x_1 - \\hat{x}_{1|T})^2] = P_{1|T}$。\n\n- **$(a, u)$ 的更新：**\n$Q$ 的相关部分涉及 $-\\frac{1}{2q}\\sum_{t=1}^{T-1}E_k[(x_{t+1} - a x_t - u)^2]$。最大化这一项等价于最小化平方和 $J(a,u) = \\sum_{t=1}^{T-1}E_k[(x_{t+1} - a x_t - u)^2]$。\n对 $a$ 和 $u$ 求导并令其为零，得到一个线性系统：\n$ \\frac{\\partial J}{\\partial u} = -2\\sum_{t=1}^{T-1}(E_k[x_{t+1}] - a E_k[x_t] - u) = 0 $\n$ \\frac{\\partial J}{\\partial a} = -2\\sum_{t=1}^{T-1}E_k[x_t(x_{t+1} - a x_t - u)] = 0 $\n这导出了正规方程：\n$ \\begin{pmatrix} \\sum E_k[x_t^2]  \\sum E_k[x_t] \\\\ \\sum E_k[x_t]  \\sum 1 \\end{pmatrix} \\begin{pmatrix} a \\\\ u \\end{pmatrix} = \\begin{pmatrix} \\sum E_k[x_{t+1}x_t] \\\\ \\sum E_k[x_{t+1}] \\end{pmatrix} $\n其中求和范围是从 $t=1$ 到 $T-1$。求解这个 $2 \\times 2$ 系统可以得到更新后的 $a^{(k+1)}$ 和 $u^{(k+1)}$。\n\n- **$q$ 的更新：**\n$Q$ 的相关部分是 $-\\frac{T-1}{2}\\log q - \\frac{1}{2q}\\sum_{t=1}^{T-1}E_k[(x_{t+1} - a x_t - u)^2]$。\n令 $\\frac{\\partial Q}{\\partial q} = -\\frac{T-1}{2q} + \\frac{1}{2q^2}\\sum E_k[\\dots]^2 = 0$ 得到：\n$ q^{(k+1)} = \\frac{1}{T-1} \\sum_{t=1}^{T-1} E_k[(x_{t+1} - a^{(k+1)} x_t - u^{(k+1)})^2] $\n该期望可以使用充分统计量和新计算出的 $a^{(k+1)}, u^{(k+1)}$ 进行展开。\n\n- **$r$ 的更新：**\n令 $N_{obs} = \\sum_{t=1}^T m_t$。$Q$ 的相关部分是 $-\\frac{N_{obs}}{2}\\log r - \\frac{1}{2r}\\sum_{t=1}^{T}m_t E_k[(y_t - x_t)^2]$。\n令 $\\frac{\\partial Q}{\\partial r} = -\\frac{N_{obs}}{2r} + \\frac{1}{2r^2}\\sum m_t E_k[(y_t-x_t)^2] = 0$ 得到：\n$ r^{(k+1)} = \\frac{1}{N_{obs}} \\sum_{t=1}^{T} m_t E_k[(y_t - x_t)^2] = \\frac{1}{N_{obs}} \\sum_{t=1}^{T} m_t ( (y_t - \\hat{x}_{t|T})^2 + P_{t|T} ) $\n\n算法通过对这些E和M步骤进行固定次数的迭代来进行，并通过强制设置一个小的正下界 $\\epsilon$ 来确保方差参数 $q, r, P_0$ 保持为正。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    \n    # Small epsilon to enforce positivity of variance parameters\n    EPSILON = 1e-9\n    \n    # Test case definitions\n    test_cases = [\n        {\n            'name': 'Test A',\n            'T': 50,\n            'true_params': {'a': 0.98, 'u': 0.05, 'q': 0.01, 'r': 0.04, 'mu0': 0.0, 'P0': 0.5},\n            'mask_spec': ('bernoulli', 0.8),\n            'seed': 7\n        },\n        {\n            'name': 'Test B',\n            'T': 80,\n            'true_params': {'a': 1.0, 'u': 0.02, 'q': 0.001, 'r': 0.01, 'mu0': -0.5, 'P0': 1.0},\n            'mask_spec': ('bernoulli', 0.5),\n            'seed': 11\n        },\n        {\n            'name': 'Test C',\n            'T': 40,\n            'true_params': {'a': 0.90, 'u': 0.0, 'q': 0.05, 'r': 0.02, 'mu0': 1.0, 'P0': 0.2},\n            'mask_spec': ('deterministic_alt',),\n            'seed': 13\n        }\n    ]\n\n    # Shared settings\n    iterations = 50\n    initial_params = {'a': 0.5, 'u': 0.0, 'q': 0.1, 'r': 0.1, 'mu0': 0.0, 'P0': 1.0}\n    \n    final_results = []\n    \n    def generate_data(T, true_params, mask_spec, seed):\n        \"\"\"Generates synthetic data from the LGSSM.\"\"\"\n        rng = np.random.default_rng(seed)\n        \n        a, u, q, r, mu0, P0 = true_params.values()\n        \n        x = np.zeros(T)\n        y = np.zeros(T)\n        \n        # Generate states\n        x[0] = rng.normal(mu0, np.sqrt(P0))\n        for t in range(T - 1):\n            x[t+1] = a * x[t] + u + rng.normal(0, np.sqrt(q))\n            \n        # Generate observations\n        y = x + rng.normal(0, np.sqrt(r), size=T)\n        \n        # Generate mask\n        mask_type = mask_spec[0]\n        if mask_type == 'bernoulli':\n            p = mask_spec[1]\n            m = rng.binomial(1, p, size=T)\n        elif mask_type == 'deterministic_alt':\n            m = np.zeros(T)\n            m[::2] = 1 # odd t (1, 3, ...) corresponds to index 0, 2, ...\n        \n        y[m == 0] = np.nan # Mark missing values\n        \n        return y, m\n\n    def kalman_filter(y, m, params, T):\n        \"\"\"Performs the forward Kalman filter pass.\"\"\"\n        a, u, q, r, mu0, P0 = params.values()\n\n        x_pred = np.zeros(T)\n        P_pred = np.zeros(T)\n        x_filt = np.zeros(T)\n        P_filt = np.zeros(T)\n\n        # Time t=1 (index 0)\n        x_pred[0] = mu0\n        P_pred[0] = P0\n        \n        if m[0] == 1:\n            K = P_pred[0] / (P_pred[0] + r)\n            x_filt[0] = x_pred[0] + K * (y[0] - x_pred[0])\n            P_filt[0] = (1 - K) * P_pred[0]\n        else:\n            x_filt[0] = x_pred[0]\n            P_filt[0] = P_pred[0]\n\n        # Time t=2...T (index 1...T-1)\n        for t in range(1, T):\n            # Prediction\n            x_pred[t] = a * x_filt[t-1] + u\n            P_pred[t] = a**2 * P_filt[t-1] + q\n            \n            # Update\n            if m[t] == 1:\n                S = P_pred[t] + r\n                if S > 0:\n                   K = P_pred[t] / S\n                else:\n                   K = 0.0 # handle potential numerical issues\n                x_filt[t] = x_pred[t] + K * (y[t] - x_pred[t])\n                P_filt[t] = (1 - K) * P_pred[t]\n            else:\n                x_filt[t] = x_pred[t]\n                P_filt[t] = P_pred[t]\n                \n        return {\n            'x_pred': x_pred, 'P_pred': P_pred,\n            'x_filt': x_filt, 'P_filt': P_filt\n        }\n\n    def rts_smoother(filter_results, params, T):\n        \"\"\"Performs the backward RTS smoother pass.\"\"\"\n        a, q = params['a'], params['q']\n        x_pred, P_pred = filter_results['x_pred'], filter_results['P_pred']\n        x_filt, P_filt = filter_results['x_filt'], filter_results['P_filt']\n\n        x_smooth = np.zeros(T)\n        P_smooth = np.zeros(T)\n        P_cov_smooth = np.zeros(T - 1)\n\n        x_smooth[T-1] = x_filt[T-1]\n        P_smooth[T-1] = P_filt[T-1]\n\n        for t in range(T - 2, -1, -1):\n            if P_pred[t+1] > 0:\n                J = P_filt[t] * a / P_pred[t+1]\n            else:\n                J = 0.0 # handle potential numerical issues\n\n            x_smooth[t] = x_filt[t] + J * (x_smooth[t+1] - x_pred[t+1])\n            P_smooth[t] = P_filt[t] + J**2 * (P_smooth[t+1] - P_pred[t+1])\n\n        # Lag-one covariance smoother pass\n        # P_t,t-1|T = P_t|T * J_{t-1}\n        for t in range(T - 1, 0, -1):\n            if P_pred[t] > 0:\n                 J_prev = P_filt[t-1] * a / P_pred[t]\n            else:\n                 J_prev = 0.0\n            P_cov_smooth[t-1] = P_smooth[t] * J_prev\n\n        return {'x_smooth': x_smooth, 'P_smooth': P_smooth, 'P_cov_smooth': P_cov_smooth}\n\n    def e_step(y, m, params, T):\n        \"\"\"Performs the E-step.\"\"\"\n        filter_results = kalman_filter(y, m, params, T)\n        smoother_results = rts_smoother(filter_results, params, T)\n        \n        x_s = smoother_results['x_smooth']\n        P_s = smoother_results['P_smooth']\n        P_cov_s = smoother_results['P_cov_smooth']\n        \n        Ex = x_s\n        Ex2 = x_s**2 + P_s\n        Exx = np.zeros(T - 1)\n        for t in range(T-1):\n            Exx[t] = x_s[t] * x_s[t+1] + P_cov_s[t]\n\n        return {'Ex': Ex, 'Ex2': Ex2, 'Exx_pair': Exx}\n\n    def m_step(y, m, stats, T, params):\n        \"\"\"Performs the M-step.\"\"\"\n        Ex, Ex2, Exx_pair = stats['Ex'], stats['Ex2'], stats['Exx_pair']\n        \n        # Update mu0, P0\n        new_mu0 = Ex[0]\n        new_P0 = Ex2[0] - Ex[0]**2\n        \n        # Prepare sums for a, u updates\n        S_xx = np.sum(Ex2[:-1])\n        S_x = np.sum(Ex[:-1])\n        S_x_prime_x = np.sum(Exx_pair)\n        S_x_prime = np.sum(Ex[1:])\n        \n        # Update a, u\n        T_minus_1 = T - 1\n        denom = T_minus_1 * S_xx - S_x**2\n        if np.abs(denom)  EPSILON: # Avoid division by zero if states are constant\n            new_a = params['a']\n            new_u = params['u']\n        else:\n            new_a = (T_minus_1 * S_x_prime_x - S_x * S_x_prime) / denom\n            new_u = (S_x_prime * S_xx - S_x * S_x_prime_x) / denom\n        \n        # Update q\n        S_x_prime_x_prime = np.sum(Ex2[1:])\n        term1 = S_x_prime_x_prime\n        term2 = -2 * new_a * S_x_prime_x\n        term3 = -2 * new_u * S_x_prime\n        term4 = new_a**2 * S_xx\n        term5 = 2 * new_a * new_u * S_x\n        term6 = T_minus_1 * new_u**2\n        new_q = (term1 + term2 + term3 + term4 + term5 + term6) / T_minus_1\n        \n        # Update r\n        N_obs = np.sum(m)\n        sum_r = 0\n        for t in range(T):\n            if m[t] == 1:\n                sum_r += y[t]**2 - 2 * y[t] * Ex[t] + Ex2[t]\n        \n        if N_obs > 0:\n            new_r = sum_r / N_obs\n        else:\n            new_r = params['r'] # Keep old r if no observations\n            \n        return {\n            'a': new_a, 'u': new_u, \n            'q': np.maximum(new_q, EPSILON), \n            'r': np.maximum(new_r, EPSILON),\n            'mu0': new_mu0, \n            'P0': np.maximum(new_P0, EPSILON)\n        }\n        \n    for case in test_cases:\n        y, m = generate_data(case['T'], case['true_params'], case['mask_spec'], case['seed'])\n        \n        current_params = initial_params.copy()\n        \n        for _ in range(iterations):\n            sufficient_stats = e_step(y, m, current_params, case['T'])\n            current_params = m_step(y, m, sufficient_stats, case['T'], current_params)\n            \n        final_params = list(current_params.values())\n        rounded_params = [f\"{p:.6f}\" for p in final_params]\n        final_results.append(f\"[{','.join(rounded_params)}]\")\n\n    print(f\"[{','.join(final_results)}]\")\n\nsolve()\n```"
        }
    ]
}