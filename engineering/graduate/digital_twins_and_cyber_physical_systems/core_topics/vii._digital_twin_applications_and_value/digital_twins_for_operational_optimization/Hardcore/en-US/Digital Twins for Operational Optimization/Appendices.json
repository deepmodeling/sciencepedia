{
    "hands_on_practices": [
        {
            "introduction": "At the heart of operational optimization lies the challenge of maximizing performance within physical or budgetary limits. This exercise provides foundational practice in solving such problems using the Karush-Kuhn-Tucker (KKT) conditions, a cornerstone of constrained nonlinear optimization. By working through a realistic production scenario, you will not only find the optimal operational setpoints but also interpret the resulting Lagrange multipliers as \"shadow prices,\" which quantify the marginal economic value of each resource constraint—a critical insight for strategic decision-making. ",
            "id": "4215652",
            "problem": "A cyber-physical production cell is operated using a Digital Twin (DT) to optimize two parallel machine setpoints, modeled as decision variables $x_1$ and $x_2$ in units per hour. The DT’s operational objective is to maximize hourly profit with diminishing returns, subject to resource budgets modeled from sensor telemetry: electrical power and thermal dissipation capacity. The profit model is concave and given by\n$$\nf(x_1,x_2) = a_1 x_1 - \\frac{b_1}{2} x_1^2 + a_2 x_2 - \\frac{b_2}{2} x_2^2,\n$$\nwith resource constraints\n$$\ne_1 x_1 + e_2 x_2 \\leq E_{\\max}, \\qquad t_1 x_1 + t_2 x_2 \\leq T_{\\max}, \\qquad x_1 \\geq 0, \\qquad x_2 \\geq 0.\n$$\nHere $a_i$ are unit revenues in dollars per unit, $b_i$ parameterize diminishing returns in dollars per $(\\text{unit}/\\text{hour})^2$, $e_i$ are electrical power intensities in $\\text{kW}$ per $(\\text{unit}/\\text{hour})$, $t_i$ are thermal load intensities in $\\text{kW}$ per $(\\text{unit}/\\text{hour})$, $E_{\\max}$ is the available electrical power capacity in $\\text{kW}$, and $T_{\\max}$ is the available thermal dissipation capacity in $\\text{kW}$. For this DT instance, the parameters are\n$$\na_1 = \\$\\,100, \\quad b_1 = \\$\\,2, \\quad a_2 = \\$\\,80, \\quad b_2 = \\$\\,1, \\quad e_1 = 3, \\quad e_2 = 2, \\quad t_1 = 1, \\quad t_2 = 3, \\quad E_{\\max} = 100, \\quad T_{\\max} = 90.\n$$\nStarting from the fundamental definitions of constrained optimization, Lagrangian duality, and the Karush-Kuhn-Tucker (KKT) conditions (Karush-Kuhn-Tucker), derive the KKT optimality conditions for this operational optimization and interpret each Lagrange multiplier as a physical shadow price that quantifies a marginal resource trade-off. Then, for the given numerical parameters, compute the numerical value of the electrical power shadow price, namely the Lagrange multiplier associated with the electrical power budget $e_1 x_1 + e_2 x_2 \\leq E_{\\max}$ at the optimum. Express your final answer in dollars per kilowatt ($\\$/\\text{kW}$) and round your answer to four significant figures.",
            "solution": "The problem is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\nThe problem provides the following data and definitions:\n- **Decision Variables**: Machine setpoints $x_1$ and $x_2$ in units per hour.\n- **Objective Function (Profit)**: $f(x_1,x_2) = a_1 x_1 - \\frac{b_1}{2} x_1^2 + a_2 x_2 - \\frac{b_2}{2} x_2^2$, to be maximized.\n- **Resource Constraints**:\n  - Electrical Power: $e_1 x_1 + e_2 x_2 \\leq E_{\\max}$\n  - Thermal Dissipation: $t_1 x_1 + t_2 x_2 \\leq T_{\\max}$\n  - Non-negativity: $x_1 \\geq 0$, $x_2 \\geq 0$\n- **Parameter Definitions and Units**:\n  - $a_i$: unit revenues in dollars per unit.\n  - $b_i$: diminishing returns parameters in dollars per $(\\text{unit}/\\text{hour})^2$.\n  - $e_i$: electrical power intensities in $\\text{kW}$ per $(\\text{unit}/\\text{hour})$.\n  - $t_i$: thermal load intensities in $\\text{kW}$ per $(\\text{unit}/\\text{hour})$.\n  - $E_{\\max}$: available electrical power capacity in $\\text{kW}$.\n  - $T_{\\max}$: available thermal dissipation capacity in $\\text{kW}$.\n- **Numerical Values**:\n  - $a_1 = 100$\n  - $b_1 = 2$\n  - $a_2 = 80$\n  - $b_2 = 1$\n  - $e_1 = 3$\n  - $e_2 = 2$\n  - $t_1 = 1$\n  - $t_2 = 3$\n  - $E_{\\max} = 100$\n  - $T_{\\max} = 90$\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is a standard instance of a constrained optimization problem, specifically quadratic programming. The physical context of optimizing a production process with resource constraints (power, thermal load) is a well-established and realistic application in engineering and operations research. The model of diminishing returns via a concave quadratic profit function is also a standard economic principle. The problem is free of pseudoscience and relies on fundamental mathematical and engineering principles.\n- **Well-Posed**: The objective function is strictly concave, and the constraints are linear, defining a convex and non-empty feasible set. Maximizing a strictly concave function over a convex set is a convex optimization problem that is guaranteed to have a unique solution. The problem provides all necessary parameters and defines a clear objective.\n- **Objective**: The problem statement uses precise, unambiguous mathematical and technical language. It is free of subjective claims.\n- **Other criteria**: The problem is self-contained, its data are dimensionally consistent, and it is not trivial or circular.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\nThe task is to solve a constrained optimization problem. The problem is to maximize the profit function $f(x_1, x_2)$ subject to a set of linear inequality constraints.\nThe profit function is\n$$f(x_1,x_2) = a_1 x_1 - \\frac{b_1}{2} x_1^2 + a_2 x_2 - \\frac{b_2}{2} x_2^2$$\nThe Hessian matrix of $f(x_1, x_2)$ is $\\nabla^2 f = \\begin{pmatrix} -b_1 & 0 \\\\ 0 & -b_2 \\end{pmatrix}$. Given $b_1=2$ and $b_2=1$, both are positive, so the Hessian is negative definite. This confirms that $f(x_1, x_2)$ is a strictly concave function. The feasible region is defined by linear inequalities, which form a convex set. The maximization of a concave function over a convex set is a convex optimization problem, for which the Karush-Kuhn-Tucker (KKT) conditions are both necessary and sufficient for a global optimum.\n\nWe define the Lagrangian function, $\\mathcal{L}$, to incorporate the constraints. For a maximization problem, the standard form of the constraints is $g_i(\\mathbf{x}) \\leq 0$. The constraints are:\n$g_1(x_1, x_2) = e_1 x_1 + e_2 x_2 - E_{\\max} \\leq 0$\n$g_2(x_1, x_2) = t_1 x_1 + t_2 x_2 - T_{\\max} \\leq 0$\n$g_3(x_1, x_2) = -x_1 \\leq 0$\n$g_4(x_1, x_2) = -x_2 \\leq 0$\n\nLet $\\lambda_E, \\lambda_T, \\mu_1, \\mu_2$ be the non-negative Lagrange multipliers associated with constraints $g_1, g_2, g_3, g_4$ respectively. The Lagrangian is:\n$$\\mathcal{L}(x_1, x_2, \\lambda_E, \\lambda_T, \\mu_1, \\mu_2) = f(x_1, x_2) - \\lambda_E(e_1 x_1 + e_2 x_2 - E_{\\max}) - \\lambda_T(t_1 x_1 + t_2 x_2 - T_{\\max}) - \\mu_1(-x_1) - \\mu_2(-x_2)$$\n\nThe KKT conditions are as follows:\n1.  **Stationarity**: The gradient of the Lagrangian with respect to the decision variables must be zero.\n    $$ \\frac{\\partial \\mathcal{L}}{\\partial x_1} = a_1 - b_1 x_1 - e_1 \\lambda_E - t_1 \\lambda_T + \\mu_1 = 0 $$\n    $$ \\frac{\\partial \\mathcal{L}}{\\partial x_2} = a_2 - b_2 x_2 - e_2 \\lambda_E - t_2 \\lambda_T + \\mu_2 = 0 $$\n\n2.  **Primal Feasibility**: The original constraints must be satisfied.\n    $$ e_1 x_1 + e_2 x_2 \\leq E_{\\max} $$\n    $$ t_1 x_1 + t_2 x_2 \\leq T_{\\max} $$\n    $$ x_1 \\geq 0, \\quad x_2 \\geq 0 $$\n\n3.  **Dual Feasibility**: The Lagrange multipliers for the inequality constraints must be non-negative.\n    $$ \\lambda_E \\geq 0, \\quad \\lambda_T \\geq 0, \\quad \\mu_1 \\geq 0, \\quad \\mu_2 \\geq 0 $$\n\n4.  **Complementary Slackness**: The product of each Lagrange multiplier and its corresponding constraint (in the form $g_i(\\mathbf{x})=0$) must be zero.\n    $$ \\lambda_E (e_1 x_1 + e_2 x_2 - E_{\\max}) = 0 $$\n    $$ \\lambda_T (t_1 x_1 + t_2 x_2 - T_{\\max}) = 0 $$\n    $$ \\mu_1 x_1 = 0 $$\n    $$ \\mu_2 x_2 = 0 $$\n\n### Interpretation of Lagrange Multipliers (Shadow Prices)\nIn the context of this problem, the Lagrange multipliers $\\lambda_E$ and $\\lambda_T$ have a direct physical and economic interpretation. They are known as shadow prices. Let $f^*$ be the optimal profit, which is a function of the resource budgets, i.e., $f^*(E_{\\max}, T_{\\max})$.\n- The multiplier $\\lambda_E$ represents the marginal value of the electrical power resource, given by $\\lambda_E = \\frac{\\partial f^*}{\\partial E_{\\max}}$. It quantifies the rate at which the maximum possible profit would increase if the electrical power capacity $E_{\\max}$ were increased by one unit (one $\\text{kW}$). Its unit is dollars per kilowatt ($\\$/\\text{kW}$).\n- Similarly, $\\lambda_T = \\frac{\\partial f^*}{\\partial T_{\\max}}$ represents the marginal value of the thermal dissipation capacity. It is the rate at which the maximum profit would increase for a one-unit increase in $T_{\\max}$, and its unit is also dollars per kilowatt ($\\$/\\text{kW}$).\nIf a constraint is not active (i.e., the resource is not fully used), its corresponding Lagrange multiplier is zero, indicating that having slightly more of that resource would not improve the profit.\n\n### Numerical Solution\nWe now substitute the given numerical parameters into the KKT conditions.\n$a_1 = 100, b_1 = 2, a_2 = 80, b_2 = 1, e_1 = 3, e_2 = 2, t_1 = 1, t_2 = 3, E_{\\max} = 100, T_{\\max} = 90$.\n\nThe KKT system becomes:\n1.  **Stationarity**:\n    (i) $100 - 2x_1 - 3\\lambda_E - \\lambda_T + \\mu_1 = 0$\n    (ii) $80 - x_2 - 2\\lambda_E - 3\\lambda_T + \\mu_2 = 0$\n2.  **Primal Feasibility**:\n    (iii) $3x_1 + 2x_2 \\leq 100$\n    (iv) $x_1 + 3x_2 \\leq 90$\n    (v) $x_1 \\geq 0, x_2 \\geq 0$\n3.  **Dual Feasibility**:\n    (vi) $\\lambda_E \\geq 0, \\lambda_T \\geq 0, \\mu_1 \\geq 0, \\mu_2 \\geq 0$\n4.  **Complementary Slackness**:\n    (vii) $\\lambda_E(3x_1 + 2x_2 - 100) = 0$\n    (viii) $\\lambda_T(x_1 + 3x_2 - 90) = 0$\n    (ix) $\\mu_1 x_1 = 0$\n    (x) $\\mu_2 x_2 = 0$\n\nWe solve this system by considering cases for which constraints are active. We can reasonably assume $x_1 > 0$ and $x_2 > 0$ since the unconstrained optimum ($x_1=50, x_2=80$) is far from the origin. This implies $\\mu_1 = 0$ and $\\mu_2 = 0$.\n\n**Case 1**: Both main constraints (iii) and (iv) are inactive.\nThis would imply $\\lambda_E = 0$ and $\\lambda_T = 0$. Stationarity equations become $100 - 2x_1 = 0 \\Rightarrow x_1=50$ and $80-x_2=0 \\Rightarrow x_2=80$. Checking feasibility: $3(50) + 2(80) = 150+160=310$, which violates $310 \\leq 100$. This case is not the solution.\n\n**Case 2**: Electrical constraint (iii) is active, thermal constraint (iv) is inactive.\nSo, $3x_1 + 2x_2 = 100$, and $\\lambda_T = 0$. The stationarity equations become:\n$100 - 2x_1 - 3\\lambda_E = 0 \\Rightarrow x_1 = 50 - \\frac{3}{2}\\lambda_E$\n$80 - x_2 - 2\\lambda_E = 0 \\Rightarrow x_2 = 80 - 2\\lambda_E$\nSubstituting into the active constraint:\n$3(50 - \\frac{3}{2}\\lambda_E) + 2(80 - 2\\lambda_E) = 100$\n$150 - \\frac{9}{2}\\lambda_E + 160 - 4\\lambda_E = 100 \\Rightarrow 310 - \\frac{17}{2}\\lambda_E = 100 \\Rightarrow \\frac{17}{2}\\lambda_E = 210 \\Rightarrow \\lambda_E = \\frac{420}{17} > 0$.\n$x_1 = 50 - \\frac{3}{2}(\\frac{420}{17}) = \\frac{850-630}{17} = \\frac{220}{17} > 0$.\n$x_2 = 80 - 2(\\frac{420}{17}) = \\frac{1360-840}{17} = \\frac{520}{17} > 0$.\nCheck the inactive constraint (iv): $x_1 + 3x_2 = \\frac{220}{17} + 3(\\frac{520}{17}) = \\frac{220+1560}{17} = \\frac{1780}{17} \\approx 104.7$. This violates $x_1+3x_2 \\leq 90$. This case is not the solution.\n\n**Case 3**: Thermal constraint (iv) is active, electrical constraint (iii) is inactive.\nSo, $x_1 + 3x_2 = 90$, and $\\lambda_E = 0$. The stationarity equations become:\n$100 - 2x_1 - \\lambda_T = 0 \\Rightarrow x_1 = 50 - \\frac{1}{2}\\lambda_T$\n$80 - x_2 - 3\\lambda_T = 0 \\Rightarrow x_2 = 80 - 3\\lambda_T$\nSubstituting into the active constraint:\n$(50 - \\frac{1}{2}\\lambda_T) + 3(80 - 3\\lambda_T) = 90$\n$50 - \\frac{1}{2}\\lambda_T + 240 - 9\\lambda_T = 90 \\Rightarrow 290 - \\frac{19}{2}\\lambda_T = 90 \\Rightarrow \\frac{19}{2}\\lambda_T = 200 \\Rightarrow \\lambda_T = \\frac{400}{19} > 0$.\n$x_1 = 50 - \\frac{1}{2}(\\frac{400}{19}) = \\frac{950-200}{19} = \\frac{750}{19} > 0$.\n$x_2 = 80 - 3(\\frac{400}{19}) = \\frac{1520-1200}{19} = \\frac{320}{19} > 0$.\nCheck the inactive constraint (iii): $3x_1 + 2x_2 = 3(\\frac{750}{19}) + 2(\\frac{320}{19}) = \\frac{2250+640}{19} = \\frac{2890}{19} \\approx 152.1$. This violates $3x_1+2x_2 \\leq 100$. This case is not the solution.\n\n**Case 4**: Both constraints (iii) and (iv) are active.\nThis means $\\lambda_E > 0$ and $\\lambda_T > 0$. The optimum $(x_1, x_2)$ is the intersection of the two constraint lines:\n$3x_1 + 2x_2 = 100$\n$x_1 + 3x_2 = 90$\nFrom the second equation, $x_1 = 90 - 3x_2$. Substitute into the first:\n$3(90 - 3x_2) + 2x_2 = 100 \\Rightarrow 270 - 9x_2 + 2x_2 = 100 \\Rightarrow 170 = 7x_2 \\Rightarrow x_2 = \\frac{170}{7}$.\nThen $x_1 = 90 - 3(\\frac{170}{7}) = \\frac{630-510}{7} = \\frac{120}{7}$.\nBoth $x_1$ and $x_2$ are positive, so $\\mu_1 = 0, \\mu_2 = 0$ is consistent.\nWe now solve for $\\lambda_E$ and $\\lambda_T$ using the stationarity equations (i) and (ii):\n$100 - 2(\\frac{120}{7}) - 3\\lambda_E - \\lambda_T = 0 \\Rightarrow 3\\lambda_E + \\lambda_T = 100 - \\frac{240}{7} = \\frac{460}{7}$\n$80 - \\frac{170}{7} - 2\\lambda_E - 3\\lambda_T = 0 \\Rightarrow 2\\lambda_E + 3\\lambda_T = 80 - \\frac{170}{7} = \\frac{390}{7}$\nWe have a system of two linear equations for $\\lambda_E, \\lambda_T$:\n(A) $3\\lambda_E + \\lambda_T = \\frac{460}{7}$\n(B) $2\\lambda_E + 3\\lambda_T = \\frac{390}{7}$\nFrom (A), $\\lambda_T = \\frac{460}{7} - 3\\lambda_E$. Substitute into (B):\n$2\\lambda_E + 3(\\frac{460}{7} - 3\\lambda_E) = \\frac{390}{7}$\n$2\\lambda_E + \\frac{1380}{7} - 9\\lambda_E = \\frac{390}{7}$\n$-7\\lambda_E = \\frac{390 - 1380}{7} = \\frac{-990}{7}$\n$\\lambda_E = \\frac{990}{49}$\nNow find $\\lambda_T$:\n$\\lambda_T = \\frac{460}{7} - 3(\\frac{990}{49}) = \\frac{460 \\times 7}{49} - \\frac{2970}{49} = \\frac{3220 - 2970}{49} = \\frac{250}{49}$\nBoth $\\lambda_E = \\frac{990}{49} > 0$ and $\\lambda_T = \\frac{250}{49} > 0$. Since all KKT conditions are met, this is the unique global optimum.\n\nThe problem asks for the numerical value of the electrical power shadow price, which is $\\lambda_E$.\n$\\lambda_E = \\frac{990}{49} \\approx 20.2040816...$\nRounding to four significant figures gives $20.20$. The units are dollars per kilowatt ($\\$/\\text{kW}$).",
            "answer": "$$\\boxed{20.20}$$"
        },
        {
            "introduction": "Digital twins must often operate under uncertainty, such as unpredictable renewable energy generation or fluctuating market demand. This practice moves beyond deterministic models to address this challenge using chance-constrained programming. You will learn to translate a probabilistic requirement—like ensuring a power feeder does not overload with 99% certainty—into a deterministic mathematical constraint that can be incorporated into a standard optimization problem, a powerful technique for making robust decisions in stochastic environments. ",
            "id": "4215614",
            "problem": "A Digital Twin (DT) of a campus microgrid is used to optimize a single-period battery discharge decision that mitigates feeder overload under uncertain renewable forecast error. The DT models the feeder power flow as a function of the decision and uncertainty as follows. Let the net feeder flow be $F(x,\\xi) = d - x + \\xi$, where $x$ is the battery discharge decision (positive values reduce the feeder flow), $d$ is the net baseline demand without the battery, and $\\xi$ is the forecast error in renewable generation modeled as a Gaussian random variable with mean $\\mu$ and standard deviation $\\sigma$. The feeder has a thermal limit $c$ that must be respected with high probability.\n\nThe operator seeks to minimize a convex quadratic operating cost while guaranteeing probabilistic satisfaction of the feeder limit. The optimization problem is\nminimize over $x$ the cost $J(x) = \\tfrac{1}{2} q x^{2} + r x$\nsubject to the chance constraint $\\mathbb{P}\\big(F(x,\\xi) \\le c\\big) \\ge 1 - \\alpha$\nand the actuator bounds $0 \\le x \\le x_{\\max}$.\n\nStarting only from foundational probability definitions and well-tested facts about Gaussian random variables and their cumulative distribution function, first derive a deterministic equivalent inequality in $x$ for the chance constraint of the form $\\mathbb{P}\\big(F(x,\\xi) \\le c\\big) \\ge 1 - \\alpha$. Then compute the optimal decision $x^{\\star}$ that minimizes the cost subject to the equivalent deterministic constraints for the following DT-identified parameters:\n- $d = 12$ megawatts (MW),\n- $c = 10$ MW,\n- $\\mu = 1$ MW,\n- $\\sigma = 0.8$ MW,\n- $\\alpha = 0.01$,\n- $q = 1$,\n- $r = -3$,\n- $x_{\\max} = 8$ MW.\n\nAssume that the Gaussian modeling assumption for $\\xi$ is valid for this period and that the quadratic cost encodes relevant degradation and energy opportunity costs. Round your answer to $4$ significant figures. Express your final decision in megawatts (MW). The final numerical answer must be a single real number.",
            "solution": "The problem requires the derivation of a deterministic equivalent for a chance constraint and the solution of the resulting convex optimization problem.\n\n**Problem Validation**\n\nFirst, the problem statement is validated against the required criteria.\n\n**Step 1: Extract Givens**\n- Net feeder flow model: $F(x,\\xi) = d - x + \\xi$\n- Decision variable: $x$ (battery discharge)\n- Baseline demand: $d$\n- Random forecast error: $\\xi \\sim \\mathcal{N}(\\mu, \\sigma^2)$\n- Mean of error: $\\mu$\n- Standard deviation of error: $\\sigma$\n- Feeder thermal limit: $c$\n- Cost function: $J(x) = \\tfrac{1}{2} q x^{2} + r x$\n- Chance constraint: $\\mathbb{P}\\big(F(x,\\xi) \\le c\\big) \\ge 1 - \\alpha$\n- Actuator bounds: $0 \\le x \\le x_{\\max}$\n- Specific parameters:\n  - $d = 12$\n  - $c = 10$\n  - $\\mu = 1$\n  - $\\sigma = 0.8$\n  - $\\alpha = 0.01$\n  - $q = 1$\n  - $r = -3$\n  - $x_{\\max} = 8$\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem uses a standard formulation for chance-constrained quadratic programming, a widely accepted technique in stochastic optimization for engineering systems, including power grids. The model is based on established principles of probability theory and optimization. It is scientifically sound.\n- **Well-posed:** The objective function $J(x)$ is strictly convex, as the coefficient of the quadratic term, $q=1$, is positive. The constraint set, formed by the deterministic equivalent of the chance constraint and the box constraints, is a convex set. The minimization of a strictly convex function over a non-empty, closed, convex set has a unique solution. The problem is well-posed.\n- **Objective and Complete:** The problem is stated using precise mathematical definitions and objective, clearly defined parameters. All data required for a solution are provided.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid as it is scientifically grounded, well-posed, objective, and complete. A solution will be derived.\n\n**Solution Derivation**\n\nThe solution procedure consists of two main parts: converting the probabilistic chance constraint into a deterministic inequality, and then solving the resulting deterministic optimization problem.\n\n**Part 1: Derivation of the Deterministic Equivalent Constraint**\n\nThe chance constraint is given by:\n$$ \\mathbb{P}\\big(F(x,\\xi) \\le c\\big) \\ge 1 - \\alpha $$\nSubstitute the definition of the feeder flow, $F(x,\\xi) = d - x + \\xi$:\n$$ \\mathbb{P}\\big(d - x + \\xi \\le c\\big) \\ge 1 - \\alpha $$\nTo analyze this probability, we isolate the random variable $\\xi$:\n$$ \\mathbb{P}\\big(\\xi \\le c - d + x\\big) \\ge 1 - \\alpha $$\nThe problem states that $\\xi$ is a Gaussian random variable with mean $\\mu$ and standard deviation $\\sigma$, i.e., $\\xi \\sim \\mathcal{N}(\\mu, \\sigma^2)$. To proceed, we standardize the variable $\\xi$. Let $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$, defined by the transformation $Z = \\frac{\\xi - \\mu}{\\sigma}$.\nWe apply this transformation to the inequality within the probability statement:\n$$ \\mathbb{P}\\left(\\frac{\\xi - \\mu}{\\sigma} \\le \\frac{c - d + x - \\mu}{\\sigma}\\right) \\ge 1 - \\alpha $$\nThis is equivalent to:\n$$ \\mathbb{P}\\left(Z \\le \\frac{c - d + x - \\mu}{\\sigma}\\right) \\ge 1 - \\alpha $$\nLet $\\Phi(z)$ denote the cumulative distribution function (CDF) of the standard normal random variable $Z$, where $\\Phi(z) = \\mathbb{P}(Z \\le z)$. The inequality can be expressed using the CDF:\n$$ \\Phi\\left(\\frac{c - d + x - \\mu}{\\sigma}\\right) \\ge 1 - \\alpha $$\nSince the CDF $\\Phi(\\cdot)$ is a strictly increasing function, its inverse, $\\Phi^{-1}(\\cdot)$, is also strictly increasing. We apply $\\Phi^{-1}(\\cdot)$ to both sides of the inequality, preserving its direction:\n$$ \\frac{c - d + x - \\mu}{\\sigma} \\ge \\Phi^{-1}(1 - \\alpha) $$\nThe term $\\Phi^{-1}(1 - \\alpha)$ is the $(1 - \\alpha)$-quantile of the standard normal distribution. We denote this critical value as $z_{\\alpha} = \\Phi^{-1}(1 - \\alpha)$.\nThe inequality becomes:\n$$ \\frac{c - d + x - \\mu}{\\sigma} \\ge z_{\\alpha} $$\nSolving for the decision variable $x$ yields the deterministic equivalent of the chance constraint, which is a linear inequality:\n$$ x \\ge d - c + \\mu + \\sigma z_{\\alpha} $$\n\n**Part 2: Solving the Deterministic Optimization Problem**\n\nThe original problem is now transformed into a deterministic quadratic program:\n$$ \\text{minimize} \\quad J(x) = \\tfrac{1}{2} q x^{2} + r x $$\n$$ \\text{subject to} \\quad x \\ge d - c + \\mu + \\sigma z_{\\alpha} $$\n$$ 0 \\le x \\le x_{\\max} $$\nLet's define the lower bound from the chance constraint as $x_{\\min}^{\\text{cc}} = d - c + \\mu + \\sigma z_{\\alpha}$. The complete feasible region for $x$ is the interval $[L, U]$, where:\n$$ L = \\max(0, x_{\\min}^{\\text{cc}}) $$\n$$ U = x_{\\max} $$\nThe objective function $J(x)$ is a convex parabola opening upwards, as $q=1 > 0$. Its unconstrained minimum, $x_{\\text{unc}}$, occurs where its derivative is zero:\n$$ \\frac{dJ}{dx} = qx + r = 0 \\implies x_{\\text{unc}} = -\\frac{r}{q} $$\nThe optimal solution to the constrained problem, $x^{\\star}$, is the projection of $x_{\\text{unc}}$ onto the feasible interval $[L, U]$. This can be written as:\n$$ x^{\\star} = \\max(L, \\min(U, x_{\\text{unc}})) $$\n\n**Part 3: Numerical Computation**\n\nWe substitute the given parameter values: $d = 12$, $c = 10$, $\\mu = 1$, $\\sigma = 0.8$, $\\alpha = 0.01$, $q = 1$, $r = -3$, and $x_{\\max} = 8$.\n\nFirst, we find the value of $z_{\\alpha} = \\Phi^{-1}(1 - \\alpha)$:\n$$ z_{0.01} = \\Phi^{-1}(1 - 0.01) = \\Phi^{-1}(0.99) $$\nFrom standard normal distribution tables or a computational tool, this value is $z_{0.01} \\approx 2.3263$.\n\nNext, we compute the lower bound $x_{\\min}^{\\text{cc}}$:\n$$ x_{\\min}^{\\text{cc}} = d - c + \\mu + \\sigma z_{0.01} \\approx 12 - 10 + 1 + (0.8)(2.3263) $$\n$$ x_{\\min}^{\\text{cc}} \\approx 2 + 1 + 1.86104 = 4.86104 $$\n\nNow, we define the feasible interval $[L, U]$:\n$$ L = \\max(0, 4.86104) = 4.86104 $$\n$$ U = x_{\\max} = 8 $$\nThe feasible region for $x$ is the interval $[4.86104, 8]$.\n\nThen, we compute the unconstrained minimizer $x_{\\text{unc}}$:\n$$ x_{\\text{unc}} = -\\frac{r}{q} = -\\frac{-3}{1} = 3 $$\n\nFinally, we find the optimal solution $x^{\\star}$ by projecting $x_{\\text{unc}}$ onto the feasible interval $[4.86104, 8]$.\nSince $x_{\\text{unc}} = 3$ is less than the lower bound of the feasible interval, $L = 4.86104$, the minimum of the cost function $J(x)$ over the feasible set occurs at the lower boundary, $L$.\n$$ x^{\\star} = L = 4.86104 $$\nThe problem requires the answer to be rounded to $4$ significant figures.\n$$ x^{\\star} \\approx 4.861 $$\nThe units of the decision are megawatts (MW), as inherited from the problem parameters.",
            "answer": "$$\\boxed{4.861}$$"
        },
        {
            "introduction": "The reliability of a digital twin's predictions is only as good as the accuracy of its underlying model parameters. This exercise focuses on a crucial aspect of model validation: uncertainty propagation. You will use first-order sensitivity analysis to derive how small uncertainties in model parameters affect the variance of a key performance indicator (KPI), providing a quantitative measure of confidence in the twin's outputs and identifying which parameters have the greatest impact on performance predictions. ",
            "id": "4215665",
            "problem": "A digital twin of a single-zone Heating, Ventilation and Air Conditioning (HVAC) system is used for operational optimization of electrical power consumption. The twin enforces steady-state constraints described by a residual map $f(x,p)=0$, where $x \\in \\mathbb{R}^{2}$ is the vector of steady-state states and $p \\in \\mathbb{R}^{2}$ is a vector of uncertain model parameters. The Key Performance Indicator (KPI) is the steady-state electrical power $g(x)$ in kilowatts, modeled as a quadratic form\n$$\ng(x) = \\frac{1}{2} x^{\\top} H x + c^{\\top} x,\n$$\nwith $H \\in \\mathbb{R}^{2 \\times 2}$ symmetric and $c \\in \\mathbb{R}^{2}$. The parameters $p$ have a nominal value $p^{\\star}$ and small, zero-mean uncertainty $\\delta p = p - p^{\\star}$ with covariance matrix $\\Sigma_{p} = \\mathbb{E}[\\delta p \\, \\delta p^{\\top}]$. The steady state $x$ depends on $p$ implicitly through $f(x,p)=0$. At the nominal operating point $(x^{\\star},p^{\\star})$, define the Jacobians $A = \\left.\\frac{\\partial f}{\\partial x}\\right|_{(x^{\\star},p^{\\star})}$ and $B = \\left.\\frac{\\partial f}{\\partial p}\\right|_{(x^{\\star},p^{\\star})}$.\n\nStarting from first principles, use a first-order Taylor expansion, the implicit function theorem linearization of the steady-state constraint, and the definitions of expectation and variance for linear transformations of random variables to derive a first-order expression for the variance of $g(x(p))$ under parameter uncertainty. Then, evaluate the resulting expression numerically for the following data, all given at $(x^{\\star},p^{\\star})$:\n$$\nA = \\begin{pmatrix} -2 & 0.5 \\\\ 1 & -3 \\end{pmatrix}, \\quad\nB = \\begin{pmatrix} 1 & 2 \\\\ -1 & 1 \\end{pmatrix}, \\quad\nH = \\begin{pmatrix} 2 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad\nc = \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}, \\quad\nx^{\\star} = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix},\n$$\nand\n$$\n\\Sigma_{p} = \\begin{pmatrix} 0.04 & 0.01 \\\\ 0.01 & 0.09 \\end{pmatrix}.\n$$\n\nExpress the final variance of $g(x(p))$ in $(\\text{kW})^{2}$ and round your answer to four significant figures. The final answer must be a single real number.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in standard principles of engineering mathematics, specifically uncertainty propagation and sensitivity analysis. The problem is well-posed, with all necessary data and definitions provided, and the constraints are consistent. The language is objective and precise.\n\nThe goal is to derive a first-order expression for the variance of the Key Performance Indicator (KPI), $g(x(p))$, due to uncertainty in the parameters $p$, and then to evaluate this expression numerically. The KPI is given by $g(x) = \\frac{1}{2} x^{\\top} H x + c^{\\top} x$, and the state $x$ is related to the parameters $p$ via the implicit steady-state constraint $f(x,p)=0$.\n\nFirst, we linearize the system dynamics around the nominal operating point $(x^{\\star}, p^{\\star})$. The perturbations are defined as $\\delta x = x - x^{\\star}$ and $\\delta p = p - p^{\\star}$. A first-order Taylor expansion of the constraint $f(x, p) = 0$ around $(x^{\\star}, p^{\\star})$ gives:\n$$ f(x, p) \\approx f(x^{\\star}, p^{\\star}) + \\left.\\frac{\\partial f}{\\partial x}\\right|_{(x^{\\star},p^{\\star})} (x - x^{\\star}) + \\left.\\frac{\\partial f}{\\partial p}\\right|_{(x^{\\star},p^{\\star})} (p - p^{\\star}) $$\nGiven that $f(x,p)=0$ and $f(x^{\\star}, p^{\\star})=0$, and using the provided Jacobian definitions $A = \\left.\\frac{\\partial f}{\\partial x}\\right|_{(x^{\\star},p^{\\star})}$ and $B = \\left.\\frac{\\partial f}{\\partial p}\\right|_{(x^{\\star},p^{\\star})}$, the linearized relationship is:\n$$ 0 \\approx A \\delta x + B \\delta p $$\nThe implicit function theorem implies that if $A$ is invertible, we can express the state perturbation $\\delta x$ as a function of the parameter perturbation $\\delta p$:\n$$ \\delta x \\approx -A^{-1}B \\delta p $$\nLet us define the sensitivity matrix $S = \\frac{dx}{dp} = -A^{-1}B$. Then, $\\delta x \\approx S \\delta p$.\n\nNext, we find a first-order approximation for the change in the KPI, $\\delta g = g(x) - g(x^{\\star})$. We perform a Taylor expansion of $g(x)$ around $x^{\\star}$:\n$$ g(x) \\approx g(x^{\\star}) + \\nabla_x g(x^{\\star})^{\\top} (x - x^{\\star}) $$\nThus, $\\delta g \\approx \\nabla_x g(x^{\\star})^{\\top} \\delta x$. The gradient of the KPI, $\\nabla_x g(x)$, is:\n$$ \\nabla_x g(x) = \\nabla_x \\left(\\frac{1}{2} x^{\\top} H x + c^{\\top} x\\right) = Hx + c $$\nwhere we have used the fact that $H$ is symmetric. At the nominal point $x^{\\star}$, the gradient is $g_x = \\nabla_x g(x^{\\star}) = Hx^{\\star} + c$.\nSubstituting this and the expression for $\\delta x$ into the approximation for $\\delta g$:\n$$ \\delta g \\approx g_x^{\\top} (S \\delta p) = (g_x^{\\top} S) \\delta p $$\n\nWe are asked to find the variance of $g(x(p))$, which to a first order is the variance of $\\delta g$. The variance is defined as $\\text{Var}(g) \\approx \\text{Var}(\\delta g) = \\mathbb{E}[(\\delta g - \\mathbb{E}[\\delta g])^2]$.\nFirst, we compute the expected value of $\\delta g$:\n$$ \\mathbb{E}[\\delta g] \\approx \\mathbb{E}[g_x^{\\top} S \\delta p] = g_x^{\\top} S \\mathbb{E}[\\delta p] $$\nSince the parameter uncertainty $\\delta p$ is given to be zero-mean, $\\mathbb{E}[\\delta p] = 0$. Therefore, $\\mathbb{E}[\\delta g] \\approx 0$.\nThe variance is then:\n$$ \\text{Var}(g) \\approx \\mathbb{E}[(\\delta g)^2] $$\nThe term inside the expectation is a scalar, so it can be written as its own transpose. Let $W = g_x^{\\top} S$. Then $\\delta g \\approx W \\delta p$.\n$$ \\text{Var}(g) \\approx \\mathbb{E}[(W \\delta p)(W \\delta p)^{\\top}] = \\mathbb{E}[W \\delta p (\\delta p)^{\\top} W^{\\top}] $$\nSince $W$ is a constant matrix (a row vector in this case), we can pull it out of the expectation:\n$$ \\text{Var}(g) \\approx W \\mathbb{E}[\\delta p (\\delta p)^{\\top}] W^{\\top} $$\nBy definition, the covariance matrix of the parameters is $\\Sigma_p = \\mathbb{E}[\\delta p (\\delta p)^{\\top}]$. Substituting this and the expressions for $W$ and $S$ yields the final symbolic formula for the variance:\n$$ \\text{Var}(g(x(p))) \\approx (g_x^{\\top}S) \\Sigma_p (S^{\\top}g_x) $$\n\nNow, we evaluate this expression numerically using the provided data:\n$$ A = \\begin{pmatrix} -2 & 0.5 \\\\ 1 & -3 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 1 & 2 \\\\ -1 & 1 \\end{pmatrix}, \\quad H = \\begin{pmatrix} 2 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad c = \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}, \\quad x^{\\star} = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}, \\quad \\Sigma_{p} = \\begin{pmatrix} 0.04 & 0.01 \\\\ 0.01 & 0.09 \\end{pmatrix} $$\n\n1.  Calculate the inverse of $A$:\n    $\\det(A) = (-2)(-3) - (0.5)(1) = 6 - 0.5 = 5.5$.\n    $$ A^{-1} = \\frac{1}{5.5} \\begin{pmatrix} -3 & -0.5 \\\\ -1 & -2 \\end{pmatrix} = \\frac{2}{11} \\begin{pmatrix} -3 & -0.5 \\\\ -1 & -2 \\end{pmatrix} = \\frac{1}{11} \\begin{pmatrix} -6 & -1 \\\\ -2 & -4 \\end{pmatrix} $$\n\n2.  Calculate the sensitivity matrix $S = -A^{-1}B$:\n    $$ S = - \\frac{1}{11} \\begin{pmatrix} -6 & -1 \\\\ -2 & -4 \\end{pmatrix} \\begin{pmatrix} 1 & 2 \\\\ -1 & 1 \\end{pmatrix} = -\\frac{1}{11} \\begin{pmatrix} (-6)(1) + (-1)(-1) & (-6)(2) + (-1)(1) \\\\ (-2)(1) + (-4)(-1) & (-2)(2) + (-4)(1) \\end{pmatrix} $$\n    $$ S = -\\frac{1}{11} \\begin{pmatrix} -5 & -13 \\\\ 2 & -8 \\end{pmatrix} = \\frac{1}{11} \\begin{pmatrix} 5 & 13 \\\\ -2 & 8 \\end{pmatrix} $$\n\n3.  Calculate the nominal gradient of the KPI, $g_x = Hx^{\\star} + c$:\n    $$ g_x = \\begin{pmatrix} 2 & 1 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 2(2) + 1(-1) \\\\ 1(2) + 0(-1) \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 2 \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 5 \\end{pmatrix} $$\n\n4.  To simplify the final calculation, we first compute the vector $v = S^{\\top}g_x$:\n    $$ v = \\left(\\frac{1}{11} \\begin{pmatrix} 5 & 13 \\\\ -2 & 8 \\end{pmatrix}\\right)^{\\top} \\begin{pmatrix} 4 \\\\ 5 \\end{pmatrix} = \\frac{1}{11} \\begin{pmatrix} 5 & -2 \\\\ 13 & 8 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 5 \\end{pmatrix} = \\frac{1}{11} \\begin{pmatrix} 5(4) - 2(5) \\\\ 13(4) + 8(5) \\end{pmatrix} = \\frac{1}{11} \\begin{pmatrix} 20 - 10 \\\\ 52 + 40 \\end{pmatrix} = \\frac{1}{11} \\begin{pmatrix} 10 \\\\ 92 \\end{pmatrix} $$\n\n5.  Finally, calculate the variance $\\text{Var}(g) \\approx v^{\\top} \\Sigma_p v$:\n    $$ \\text{Var}(g) \\approx \\left(\\frac{1}{11} \\begin{pmatrix} 10 \\\\ 92 \\end{pmatrix}\\right)^{\\top} \\begin{pmatrix} 0.04 & 0.01 \\\\ 0.01 & 0.09 \\end{pmatrix} \\left(\\frac{1}{11} \\begin{pmatrix} 10 \\\\ 92 \\end{pmatrix}\\right) $$\n    $$ \\text{Var}(g) \\approx \\frac{1}{121} \\begin{pmatrix} 10 & 92 \\end{pmatrix} \\begin{pmatrix} 0.04 & 0.01 \\\\ 0.01 & 0.09 \\end{pmatrix} \\begin{pmatrix} 10 \\\\ 92 \\end{pmatrix} $$\n    First, we compute the product of the matrix and the rightmost vector:\n    $$ \\begin{pmatrix} 0.04 & 0.01 \\\\ 0.01 & 0.09 \\end{pmatrix} \\begin{pmatrix} 10 \\\\ 92 \\end{pmatrix} = \\begin{pmatrix} 0.04(10) + 0.01(92) \\\\ 0.01(10) + 0.09(92) \\end{pmatrix} = \\begin{pmatrix} 0.4 + 0.92 \\\\ 0.1 + 8.28 \\end{pmatrix} = \\begin{pmatrix} 1.32 \\\\ 8.38 \\end{pmatrix} $$\n    Now, we compute the final dot product:\n    $$ \\text{Var}(g) \\approx \\frac{1}{121} \\begin{pmatrix} 10 & 92 \\end{pmatrix} \\begin{pmatrix} 1.32 \\\\ 8.38 \\end{pmatrix} = \\frac{1}{121} (10 \\times 1.32 + 92 \\times 8.38) $$\n    $$ \\text{Var}(g) \\approx \\frac{1}{121} (13.2 + 770.96) = \\frac{784.16}{121} \\approx 6.480661157... $$\nRounding the result to four significant figures, we get $6.481$. The unit of variance is the square of the unit of the KPI, which is $(\\text{kW})^2$.",
            "answer": "$$\\boxed{6.481}$$"
        }
    ]
}