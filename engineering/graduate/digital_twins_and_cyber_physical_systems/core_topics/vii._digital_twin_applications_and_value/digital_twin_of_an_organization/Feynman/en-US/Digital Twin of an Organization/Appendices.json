{
    "hands_on_practices": [
        {
            "introduction": "A digital twin's power lies in its ability to reflect the true state of its physical counterpart. This practice explores the fundamental concept of observability, a cornerstone of control theory, to determine if the internal states of an organizational model can be fully inferred from its output KPIs . By calculating the rank of the observability matrix for a linearized model, you will gain a rigorous method for assessing the adequacy of a monitoring strategy for a Digital Twin of an Organization (DTO), directly addressing the critical question: \"Are we measuring the right things?\"",
            "id": "4214840",
            "problem": "A digital twin of an organization near an operating point is modeled as a continuous-time, linear time-invariant state-space system with state vector $x \\in \\mathbb{R}^{4}$, where $x_{1}$ represents order backlog deviations, $x_{2}$ represents work-in-progress throughput deviations, $x_{3}$ represents resource capacity imbalance, and $x_{4}$ represents a latent compliance risk propensity. The output vector $y \\in \\mathbb{R}^{2}$ collects key monitoring indicators: a filtered backlog measure and a composite compliance incident signal. The linearization around the operating point yields the pair $(A,C)$:\n$$\nA \\;=\\; \\begin{bmatrix}\n-0.3 & 1 & 0 & 0 \\\\\n0 & -0.5 & 1 & 0 \\\\\n0 & 0 & -0.1 & 0 \\\\\n0 & 0 & 0 & -0.2\n\\end{bmatrix}, \n\\qquad\nC \\;=\\; \\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 1 & 0\n\\end{bmatrix}.\n$$\nStarting from the definition of observability for linear time-invariant systems and without using any pre-given shortcut formulas, determine the rank of the observability matrix associated with $(A,C)$ and interpret what this rank implies for the monitoring design of the digital twin (for example, which latent organizational dynamics can or cannot be inferred from the available indicators). Provide the rank as your final numerical answer. No rounding is necessary, and no physical units are required for the rank.",
            "solution": "The problem requires us to determine the observability of a linear time-invariant (LTI) system described by the state-space representation $\\dot{x} = Ax, y = Cx$ and interpret the findings in the context of a digital twin of an organization. The core of the task is to compute the rank of the system's observability matrix, starting from the fundamental definition of observability.\n\nAn LTI system is said to be observable if, for any unknown initial state $x(0) = x_0$, there exists a finite time $t_f > 0$ such that knowledge of the input $u(t)$ and the output $y(t)$ over the interval $[0, t_f]$ is sufficient to uniquely determine $x_0$. For a system with no input ($u(t)=0$), the state trajectory is given by $x(t) = \\exp(At)x_0$, and the output is $y(t) = C x(t) = C \\exp(At) x_0$.\n\nA state $x_0$ is unobservable if and only if, for that initial state, the output is identically zero for all time $t \\ge 0$. That is, $y(t) = C \\exp(At) x_0 = \\mathbf{0}$ for all $t \\ge 0$. To derive a testable condition from this definition, we can repeatedly differentiate the output equation with respect to time and evaluate at $t=0$:\n$y(0) = C x_0 = \\mathbf{0}$\n$\\dot{y}(t) = \\frac{d}{dt}(C \\exp(At) x_0) = C A \\exp(At) x_0 \\implies \\dot{y}(0) = C A x_0 = \\mathbf{0}$\n$\\ddot{y}(t) = \\frac{d^2}{dt^2}(C \\exp(At) x_0) = C A^2 \\exp(At) x_0 \\implies \\ddot{y}(0) = C A^2 x_0 = \\mathbf{0}$\n...\n$y^{(k)}(t) = \\frac{d^k}{dt^k}(C \\exp(At) x_0) = C A^k \\exp(At) x_0 \\implies y^{(k)}(0) = C A^k x_0 = \\mathbf{0}$\n\nTherefore, an initial state $x_0$ is unobservable if and only if $C A^k x_0 = \\mathbf{0}$ for all non-negative integers $k$. According to the Cayley-Hamilton theorem, any matrix power $A^k$ for $k \\ge n$ (where $n$ is the dimension of the state vector) can be expressed as a linear combination of the powers $\\{A^0, A^1, \\dots, A^{n-1}\\}$. Thus, the condition simplifies to checking only the first $n$ such equations. This set of linear equations can be written in matrix form:\n$$\n\\begin{bmatrix}\nC \\\\\nCA \\\\\nCA^2 \\\\\n\\vdots \\\\\nCA^{n-1}\n\\end{bmatrix}\nx_0 = \\mathbf{0}\n$$\nThe matrix in this equation is the observability matrix, denoted by $\\mathcal{O}$. A non-zero state $x_0$ is unobservable if it lies in the null space of $\\mathcal{O}$. The system is fully observable if the only solution to $\\mathcal{O} x_0 = \\mathbf{0}$ is the trivial solution $x_0 = \\mathbf{0}$. This is equivalent to the condition that the observability matrix $\\mathcal{O}$ has full column rank, i.e., $\\text{rank}(\\mathcal{O}) = n$.\n\nThe state dimension is $n=4$. The observability matrix is $\\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\\\ CA^2 \\\\ CA^3 \\end{bmatrix}$. We are given:\n$$\nA = \\begin{bmatrix}\n-0.3 & 1 & 0 & 0 \\\\\n0 & -0.5 & 1 & 0 \\\\\n0 & 0 & -0.1 & 0 \\\\\n0 & 0 & 0 & -0.2\n\\end{bmatrix}, \n\\qquad\nC = \\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 1 & 0\n\\end{bmatrix}\n$$\nThe rows of $\\mathcal{O}$ are the rows of $C, CA, CA^2,$ and $CA^3$.\nFirst, we compute the matrix products:\n$C = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\end{bmatrix}$\n\n$CA = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\end{bmatrix} \\begin{bmatrix} -0.3 & 1 & 0 & 0 \\\\ 0 & -0.5 & 1 & 0 \\\\ 0 & 0 & -0.1 & 0 \\\\ 0 & 0 & 0 & -0.2 \\end{bmatrix} = \\begin{bmatrix} -0.3 & 1 & 0 & 0 \\\\ 0 & -0.5 & 0.9 & 0 \\end{bmatrix}$\n\nTo compute $CA^2$, we first find $A^2$:\n$A^2 = A \\cdot A = \\begin{bmatrix} -0.3 & 1 & 0 & 0 \\\\ 0 & -0.5 & 1 & 0 \\\\ 0 & 0 & -0.1 & 0 \\\\ 0 & 0 & 0 & -0.2 \\end{bmatrix}^2 = \\begin{bmatrix} 0.09 & -0.8 & 1 & 0 \\\\ 0 & 0.25 & -0.6 & 0 \\\\ 0 & 0 & 0.01 & 0 \\\\ 0 & 0 & 0 & 0.04 \\end{bmatrix}$\nThen, $CA^2 = C \\cdot A^2 = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\end{bmatrix} \\begin{bmatrix} 0.09 & -0.8 & 1 & 0 \\\\ 0 & 0.25 & -0.6 & 0 \\\\ 0 & 0 & 0.01 & 0 \\\\ 0 & 0 & 0 & 0.04 \\end{bmatrix} = \\begin{bmatrix} 0.09 & -0.8 & 1 & 0 \\\\ 0 & 0.25 & -0.59 & 0 \\end{bmatrix}$\n\nTo compute $CA^3$, we first find $A^3$:\n$A^3 = A \\cdot A^2 = \\begin{bmatrix} -0.3 & 1 & 0 & 0 \\\\ 0 & -0.5 & 1 & 0 \\\\ 0 & 0 & -0.1 & 0 \\\\ 0 & 0 & 0 & -0.2 \\end{bmatrix} \\begin{bmatrix} 0.09 & -0.8 & 1 & 0 \\\\ 0 & 0.25 & -0.6 & 0 \\\\ 0 & 0 & 0.01 & 0 \\\\ 0 & 0 & 0 & 0.04 \\end{bmatrix} = \\begin{bmatrix} -0.027 & 0.49 & -0.9 & 0 \\\\ 0 & -0.125 & 0.31 & 0 \\\\ 0 & 0 & -0.001 & 0 \\\\ 0 & 0 & 0 & -0.008 \\end{bmatrix}$\nThen, $CA^3 = C \\cdot A^3 = \\begin{bmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\end{bmatrix} \\begin{bmatrix} -0.027 & 0.49 & -0.9 & 0 \\\\ 0 & -0.125 & 0.31 & 0 \\\\ 0 & 0 & -0.001 & 0 \\\\ 0 & 0 & 0 & -0.008 \\end{bmatrix} = \\begin{bmatrix} -0.027 & 0.49 & -0.9 & 0 \\\\ 0 & -0.125 & 0.309 & 0 \\end{bmatrix}$\n\nNow we assemble the full observability matrix $\\mathcal{O}$:\n$$\n\\mathcal{O} = \\begin{bmatrix}\nC \\\\\nCA \\\\\nCA^2 \\\\\nCA^3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 1 & 0 \\\\\n-0.3 & 1 & 0 & 0 \\\\\n0 & -0.5 & 0.9 & 0 \\\\\n0.09 & -0.8 & 1 & 0 \\\\\n0 & 0.25 & -0.59 & 0 \\\\\n-0.027 & 0.49 & -0.9 & 0 \\\\\n0 & -0.125 & 0.309 & 0\n\\end{bmatrix}\n$$\nTo determine the rank of this $8 \\times 4$ matrix, we analyze its columns. The fourth column consists entirely of zeros. This immediately implies that the columns are not linearly independent. Specifically, the vector $v = [0, 0, 0, \\alpha]^T$ for any non-zero scalar $\\alpha$ will satisfy $\\mathcal{O}v = \\mathbf{0}$. This means the null space of $\\mathcal{O}$ has a dimension of at least $1$, and consequently, the rank of $\\mathcal{O}$ is at most $4-1=3$.\n\nTo determine if the rank is exactly $3$, we must check if the first three columns are linearly independent. We can do this by finding a $3 \\times 3$ submatrix with a non-zero determinant. Let's form a submatrix using the first three rows and first three columns of $\\mathcal{O}$:\n$$\n M = \\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 1 \\\\\n-0.3 & 1 & 0\n\\end{bmatrix}\n$$\nThe determinant of this submatrix is:\n$$\n\\det(M) = 1 \\cdot \\det\\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\end{pmatrix} - 0 + 0 = 1 \\cdot (1 \\cdot 0 - 1 \\cdot 1) = -1\n$$\nSince $\\det(M) \\neq 0$, the first three columns of $\\mathcal{O}$ are linearly independent. Therefore, the rank of the observability matrix $\\mathcal{O}$ is exactly $3$.\n\nInterpretation:\nThe rank of the observability matrix is $3$, which is less than the state dimension $n=4$. The difference, $n - \\text{rank}(\\mathcal{O}) = 4 - 3 = 1$, indicates that there is a one-dimensional unobservable subspace. Any state vector within this subspace cannot be determined from the output measurements.\n\nAs shown by the calculation, the null space of $\\mathcal{O}$ is spanned by the vector $[0, 0, 0, 1]^T$. This vector corresponds to the fourth state variable, $x_4$, which is the \"latent compliance risk propensity\". This means that the dynamics of $x_4$ are completely decoupled from the outputs $y$. An initial value or any subsequent change in $x_4$ has no effect on the measured \"filtered backlog measure\" and \"composite compliance incident signal\".\n\nIn the context of the digital twin monitoring design, this result implies a critical flaw: the current set of key monitoring indicators is insufficient to track or infer the organization's latent compliance risk. The dynamics associated with backlog ($x_1$), throughput ($x_2$), and resource imbalance ($x_3$) can be fully reconstructed from the output data (as their corresponding columns in $\\mathcal{O}$ are linearly independent). However, the propensity for compliance risk ($x_4$) remains hidden. To make this state observable, the monitoring strategy must be augmented with new indicators that are explicitly or implicitly dependent on $x_4$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "Beyond merely monitoring, a sophisticated DTO can recommend optimal actions under uncertainty. This exercise transitions from observation to control by framing an organizational decision problem as a Markov Decision Process (MDP) . By implementing the value iteration algorithm, you will compute an optimal policy for resource allocation in a dynamic environment, providing a concrete example of how DTOs can power prescriptive analytics and automate strategic decision-making.",
            "id": "4214863",
            "problem": "A digital twin of an organization models decision-making over coarse-grained backlog states under uncertainty. Consider a finite Markov Decision Process (MDP) with discounted infinite-horizon returns, where the state space is $S=\\{0,1,2\\}$, representing organizational backlog levels: $0$ (low), $1$ (medium), and $2$ (high). The action space is $A=\\{0,1,2\\}$, representing $0$ (allocate resources to reduce backlog), $1$ (hold steady), and $2$ (shift resources to innovation). Immediate rewards are defined by $R(s,a)=r_a + p_s$, where $r_a$ is the action-dependent immediate reward and $p_s$ is the backlog-dependent penalty. Assume $r_0=-1$, $r_1=0$, $r_2=2$, and $p_0=0$, $p_1=-2$, $p_2=-5$.\n\nTransitions are specified by one of two kernels, $\\mathsf{P}^{(1)}$ and $\\mathsf{P}^{(2)}$, both mapping $S \\times A$ to distributions over $S$. For $\\mathsf{P}^{(1)}$ (stochastic operational dynamics):\n- For action $0$ (allocate resources to reduce backlog):\n  - From $s=0$: to $s'=0$ with probability $0.7$, to $s'=1$ with probability $0.3$, to $s'=2$ with probability $0.0$.\n  - From $s=1$: to $s'=0$ with probability $0.6$, to $s'=1$ with probability $0.3$, to $s'=2$ with probability $0.1$.\n  - From $s=2$: to $s'=0$ with probability $0.0$, to $s'=1$ with probability $0.6$, to $s'=2$ with probability $0.4$.\n- For action $1$ (hold steady):\n  - From $s=0$: to $s'=0$ with probability $0.5$, to $s'=1$ with probability $0.5$, to $s'=2$ with probability $0.0$.\n  - From $s=1$: to $s'=0$ with probability $0.0$, to $s'=1$ with probability $0.6$, to $s'=2$ with probability $0.4$.\n  - From $s=2$: to $s'=0$ with probability $0.0$, to $s'=1$ with probability $0.2$, to $s'=2$ with probability $0.8$.\n- For action $2$ (shift resources to innovation):\n  - From $s=0$: to $s'=0$ with probability $0.3$, to $s'=1$ with probability $0.7$, to $s'=2$ with probability $0.0$.\n  - From $s=1$: to $s'=0$ with probability $0.0$, to $s'=1$ with probability $0.3$, to $s'=2$ with probability $0.7$.\n  - From $s=2$: to $s'=0$ with probability $0.0$, to $s'=1$ with probability $0.1$, to $s'=2$ with probability $0.9$.\n\nFor $\\mathsf{P}^{(2)}$ (deterministic policy effects):\n- For action $0$ (allocate resources to reduce backlog): from $s=0$ to $s'=0$ with probability $1.0$, from $s=1$ to $s'=0$ with probability $1.0$, from $s=2$ to $s'=1$ with probability $1.0$.\n- For action $1$ (hold steady): from $s=0$ to $s'=0$ with probability $1.0$, from $s=1$ to $s'=1$ with probability $1.0$, from $s=2$ to $s'=2$ with probability $1.0$.\n- For action $2$ (shift resources to innovation): from $s=0$ to $s'=1$ with probability $1.0$, from $s=1$ to $s'=2$ with probability $1.0$, from $s=2$ to $s'=2$ with probability $1.0$.\n\nCompute an optimal policy via value iteration under a discount factor $\\gamma \\in [0,1)$, using the decision rule that ties in the maximization must be broken by choosing the smallest action index. Let the stopping threshold be $\\varepsilon>0$ in the supremum norm on state values, and the maximum iteration cap be $N_{\\max} \\in \\mathbb{N}$. If $\\gamma \\ge 1$, detect non-contraction and, instead of running value iteration, output the myopic policy that maximizes $R(s,a)$ independently in each state, set the iteration count to $0$, and set the convergence flag to boolean false. If $\\gamma \\in [0,1)$ but the algorithm does not meet the stopping threshold by $N_{\\max}$ iterations, output the greedy policy with respect to the last iterate, the actual number of iterations performed, and a boolean false convergence flag.\n\nYour program must implement the above and evaluate the following test suite of parameter values, each specified as $(\\text{kernel}, \\gamma, \\varepsilon, N_{\\max})$:\n- Case $1$: $\\left(\\mathsf{P}^{(1)},\\, 0.9,\\, 10^{-8},\\, 10000\\right)$.\n- Case $2$: $\\left(\\mathsf{P}^{(1)},\\, 0.999,\\, 10^{-12},\\, 20000\\right)$.\n- Case $3$: $\\left(\\mathsf{P}^{(1)},\\, 0.0,\\, 10^{-8},\\, 10000\\right)$.\n- Case $4$: $\\left(\\mathsf{P}^{(2)},\\, 0.95,\\, 10^{-8},\\, 10000\\right)$.\n- Case $5$: $\\left(\\mathsf{P}^{(1)},\\, 1.0,\\, 10^{-8},\\, 10000\\right)$.\n\nFor each case, produce a result list $\\left[a_0,a_1,a_2,n,c\\right]$, where $a_0,a_1,a_2 \\in \\{0,1,2\\}$ are the chosen actions for states $s=0,1,2$, $n \\in \\mathbb{N}$ is the number of iterations actually performed by your procedure (with $n=0$ in the $\\gamma \\ge 1$ myopic case), and $c \\in \\{\\text{True},\\text{False}\\}$ indicates whether your procedure declared convergence according to the stopping criterion. \n\nFinal output format specification: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the per-case result list, for example, $\\left[\\left[a_0,a_1,a_2,n,c\\right],\\left[\\cdots\\right],\\ldots\\right]$.",
            "solution": "The user-provided problem is assessed to be **valid** after a thorough validation process. The problem describes a set of standard, finite-state Markov Decision Processes (MDPs) and requests the computation of optimal policies using the well-established value iteration algorithm. The problem statement is self-contained, scientifically grounded in the theory of stochastic optimal control, and mathematically well-posed. All parameters, including state and action spaces, reward functions, transition kernels, discount factors, and stopping criteria, are defined precisely. The problem also specifies clear procedures for handling special cases, such as non-contractive discount factors ($\\gamma \\ge 1$) and non-convergence within a given iteration limit, ensuring a unique and well-defined output for all specified test cases.\n\nThe solution proceeds as follows:\n\nFirst, we formalize the components of the MDP. The state space is $S=\\{0, 1, 2\\}$, the action space is $A=\\{0, 1, 2\\}$, and the discount factor is $\\gamma$. The immediate reward for taking action $a$ in state $s$ is given by $R(s, a) = r_a + p_s$. We can pre-compute this into a $3 \\times 3$ reward matrix $\\mathbf{R}$:\n$$\n\\mathbf{R}_{s,a} = \\begin{pmatrix} r_0+p_0 & r_1+p_0 & r_2+p_0 \\\\ r_0+p_1 & r_1+p_1 & r_2+p_1 \\\\ r_0+p_2 & r_1+p_2 & r_2+p_2 \\end{pmatrix} = \\begin{pmatrix} -1+0 & 0+0 & 2+0 \\\\ -1-2 & 0-2 & 2-2 \\\\ -1-5 & 0-5 & 2-5 \\end{pmatrix} = \\begin{pmatrix} -1 & 0 & 2 \\\\ -3 & -2 & 0 \\\\ -6 & -5 & -3 \\end{pmatrix}\n$$\nThe transition dynamics are given by probability kernels $\\mathsf{P}(s'|s,a)$, which we represent as a $3 \\times 3 \\times 3$ tensor $\\mathbf{P}$ where $\\mathbf{P}_{s,a,s'} = \\mathsf{P}(s'|s,a)$. Two such tensors, $\\mathbf{P}^{(1)}$ and $\\mathbf{P}^{(2)}$, are constructed based on the problem description.\n\nThe core of the solution is the value iteration algorithm, which finds the optimal value function $V^*(s)$ for an infinite-horizon discounted MDP. The value function represents the maximum expected cumulative discounted reward starting from state $s$. Value iteration is based on the Bellman optimality equation:\n$$\nV^*(s) = \\max_{a \\in A} \\left( R(s, a) + \\gamma \\sum_{s' \\in S} \\mathsf{P}(s'|s,a) V^*(s') \\right)\n$$\nThe algorithm iteratively improves an estimate of the value function, starting with an initial guess $V_0(s)$ (e.g., $V_0(s)=0$ for all $s$). The update rule for iteration $k+1$ is:\n$$\nV_{k+1}(s) = \\max_{a \\in A} \\left( R(s, a) + \\gamma \\sum_{s' \\in S} \\mathsf{P}(s'|s,a) V_k(s') \\right)\n$$\nThis can be expressed more compactly by defining the state-action value function, or Q-function, as $Q_k(s, a) = R(s, a) + \\gamma \\sum_{s' \\in S} \\mathsf{P}(s'|s,a) V_k(s')$. Then, the update becomes $V_{k+1}(s) = \\max_{a \\in A} Q_k(s, a)$.\n\nThe iteration continues until the value function converges, which is determined by checking if the supremum norm of the difference between successive value function iterates is below a given threshold $\\varepsilon$:\n$$\n\\max_{s \\in S} |V_{k+1}(s) - V_k(s)| < \\varepsilon\n$$\nThis condition is guaranteed to be met for $\\gamma \\in [0,1)$ because the Bellman operator is a contraction mapping with modulus $\\gamma$.\n\nIf the algorithm is provided with a discount factor $\\gamma \\ge 1$, the Bellman operator is no longer a contraction, and value iteration may not converge. As stipulated, in this case, we do not run the iteration. Instead, we compute a myopic policy $\\pi(s) = \\arg\\max_a R(s,a)$ for each state, set the iteration count to $0$, and report that convergence was not achieved.\n\nIf the algorithm for $\\gamma \\in [0,1)$ fails to converge within the maximum number of iterations $N_{\\max}$, it terminates. The final policy is then the greedy policy with respect to the last computed value function, $V_{N_{\\max}}$.\n\nOnce the value function $V$ has converged (or the iteration limit is reached), the optimal policy $\\pi^*(s)$ is extracted by finding the action that maximizes the Q-function for each state:\n$$\n\\pi^*(s) = \\arg\\max_{a \\in A} \\left( R(s, a) + \\gamma \\sum_{s' \\in S} \\mathsfP(s'|s,a) V(s') \\right)\n$$\nThe problem specifies that any ties during this maximization must be broken by choosing the action with the smallest index.\n\nThe implementation will use `NumPy` arrays for efficient vectorized computation. The rewards $\\mathbf{R}$ will be a $3 \\times 3$ matrix. The transition kernels $\\mathbf{P}^{(1)}$ and $\\mathbf{P}^{(2)}$ will be $3 \\times 3 \\times 3$ tensors. The value function $V$ will be a vector of size $3$. The term $\\sum_{s'} \\mathsf{P}(s'|s,a) V(s')$ is computed efficiently for all states and actions simultaneously using `numpy.einsum`. The `numpy.argmax` function is used for the maximization steps, as it inherently breaks ties by returning the index of the first occurrence of the maximum value, satisfying the tie-breaking rule. The procedure is applied to each test case, and the results are formatted into a single-line string as specified.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of Markov Decision Process problems using value iteration.\n    \"\"\"\n    \n    # Define MDP components\n    num_states = 3\n    num_actions = 3\n    r = np.array([-1, 0, 2])\n    p = np.array([0, -2, -5])\n    R = r.reshape(1, num_actions) + p.reshape(num_states, 1)\n\n    # Transition Kernel P1 (stochastic)\n    P1 = np.zeros((num_states, num_actions, num_states))\n    # Action 0: reduce backlog\n    P1[0, 0, :] = [0.7, 0.3, 0.0]\n    P1[1, 0, :] = [0.6, 0.3, 0.1]\n    P1[2, 0, :] = [0.0, 0.6, 0.4]\n    # Action 1: hold steady\n    P1[0, 1, :] = [0.5, 0.5, 0.0]\n    P1[1, 1, :] = [0.0, 0.6, 0.4]\n    P1[2, 1, :] = [0.0, 0.2, 0.8]\n    # Action 2: innovate\n    P1[0, 2, :] = [0.3, 0.7, 0.0]\n    P1[1, 2, :] = [0.0, 0.3, 0.7]\n    P1[2, 2, :] = [0.0, 0.1, 0.9]\n\n    # Transition Kernel P2 (deterministic)\n    P2 = np.zeros((num_states, num_actions, num_states))\n    # Action 0: reduce backlog\n    P2[0, 0, 0] = 1.0\n    P2[1, 0, 0] = 1.0\n    P2[2, 0, 1] = 1.0\n    # Action 1: hold steady\n    P2[0, 1, 0] = 1.0\n    P2[1, 1, 1] = 1.0\n    P2[2, 1, 2] = 1.0\n    # Action 2: innovate\n    P2[0, 2, 1] = 1.0\n    P2[1, 2, 2] = 1.0\n    P2[2, 2, 2] = 1.0\n    \n    kernels = {'P1': P1, 'P2': P2}\n\n    test_cases = [\n        ('P1', 0.9, 1e-8, 10000),\n        ('P1', 0.999, 1e-12, 20000),\n        ('P1', 0.0, 1e-8, 10000),\n        ('P2', 0.95, 1e-8, 10000),\n        ('P1', 1.0, 1e-8, 10000),\n    ]\n\n    def solve_mdp(P, gamma, epsilon, n_max):\n        \"\"\"\n        Implements value iteration for a given MDP.\n        \"\"\"\n        # Case: gamma >= 1, non-contraction\n        if gamma >= 1:\n            policy = np.argmax(R, axis=1)\n            return [int(policy[0]), int(policy[1]), int(policy[2]), 0, False]\n\n        # Case: gamma  1, value iteration\n        V = np.zeros(num_states)\n        for n in range(1, n_max + 1):\n            V_old = V.copy()\n            Q = R + gamma * np.einsum('ijk,k-ij', P, V_old)\n            V = np.max(Q, axis=1)\n            \n            # Check for convergence\n            if np.max(np.abs(V - V_old))  epsilon:\n                policy = np.argmax(Q, axis=1)\n                return [int(policy[0]), int(policy[1]), int(policy[2]), n, True]\n\n        # Case: did not converge within n_max iterations\n        Q = R + gamma * np.einsum('ijk,k-ij', P, V)\n        policy = np.argmax(Q, axis=1)\n        return [int(policy[0]), int(policy[1]), int(policy[2]), n_max, False]\n\n    all_results = []\n    for kernel_name, gamma, epsilon, n_max in test_cases:\n        P = kernels[kernel_name]\n        result_list = solve_mdp(P, gamma, epsilon, n_max)\n        all_results.append(result_list)\n        \n    # Format the final output string to match the required format without spaces\n    string_results = []\n    for res_list in all_results:\n        inner_str = f\"[{','.join(map(str, res_list))}]\"\n        string_results.append(inner_str)\n    \n    final_output = f\"[{','.join(string_results)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "The theoretical models of a DTO must be supported by a high-performance computational infrastructure to be effective in real-time operations. This practice focuses on the systems engineering aspect, requiring you to build a discrete-event simulator to evaluate different parallelization strategies for a DTO's processing pipeline . By comparing the throughput and latency of various architectures, you will develop critical skills in performance modeling and capacity planning for complex cyber-physical systems.",
            "id": "4214864",
            "problem": "An organization deploys a Digital Twin of an Organization (DTO) that continuously runs internal simulation tasks and downstream analytics tasks. The simulation tasks create state updates that the analytics tasks consume. The objective is to design and evaluate parallelization strategies for the two-stage processing pipeline comprising a simulation stage and an analytics stage. The evaluation must quantify the throughput and end-to-end latency under scientifically sound assumptions and constraints, using a programmatic, reproducible experiment.\n\nThe fundamental base for modeling the DTO pipeline is the following:\n- A Poisson process for arrivals, where inter-arrival times are independent and exponentially distributed with rate parameter $\\lambda$ arrivals per second.\n- Exponential service times with specified means, consistent with First-Come First-Served (FCFS) queuing and independent servers.\n- Little's Law, stated as $L = \\lambda W$, relating steady-state average number $L$ in the system, arrival rate $\\lambda$, and average time $W$ in the system, which conceptually underpins the relationship between throughput and latency even if we compute by simulation rather than closed form.\n\nThe pipeline comprises two stages:\n- Stage $1$ (simulation): Each arriving job has a service time that is exponentially distributed with mean $s_{\\text{sim}}$ seconds. Stage $1$ has $c_1$ identical parallel servers.\n- Stage $2$ (analytics): Each job has a core service time exponentially distributed with mean $s_{\\text{ana,core}}$ seconds and a per-item overhead $o$ seconds, unless micro-batching is used. Stage $2$ has $c_2$ identical parallel servers unless micro-batching dictates otherwise.\n\nThe four parallelization strategies to evaluate are defined precisely:\n- Strategy $0$ (baseline serial per stage): $c_1 = 1$, $c_2 = 1$, FCFS, no batching. Each analytics job takes $o + X$, where $X \\sim \\text{Exp}(\\text{mean}=s_{\\text{ana,core}})$.\n- Strategy $1$ (analytics data-parallel): $c_1 = 1$, $c_2 = k$, FCFS across Stage $2$, no batching. Each analytics job takes $o + X$, same $X$ distribution as above.\n- Strategy $2$ (data-parallel both stages): $c_1 = m$, $c_2 = k$, FCFS at each stage, no batching. Each analytics job takes $o + X$, same $X$ distribution.\n- Strategy $3$ (analytics micro-batching): $c_1 = 1$, $c_2 = 1$, Stage $2$ processes jobs in batches of size up to $b$ according to FCFS with greedy batch formation at the server's availability time. The per-batch service time is $o + \\sum_{i=1}^{n_b} X_i$, where $n_b \\leq b$ is the number of items available at batch start and $X_i \\sim \\text{Exp}(\\text{mean}=s_{\\text{ana,core}})$ are independent. All items in a batch complete together at the batch completion time.\n\nScheduling discipline:\n- At each stage, the scheduling is FCFS. For stages with $c$ parallel servers, each arrival is assigned to the server that becomes available earliest; the job's service begins at the maximum of its arrival time and that server's availability time. This is a classical multi-server FCFS discipline under independent service times.\n\nPerformance metrics:\n- Throughput is defined as the total number of completed jobs divided by the elapsed time from the first arrival at Stage $1$ to the last completion at Stage $2$, in jobs per second.\n- End-to-end latency for each job is defined as completion time at Stage $2$ minus its initial arrival time at Stage $1$, in seconds. We report the mean over all jobs.\n\nModeling constraints:\n- Inter-arrival times to Stage $1$ are independent and exponentially distributed with mean $1/\\lambda$ seconds.\n- Stage $1$ service times per job are independent and exponentially distributed with mean $s_{\\text{sim}}$ seconds.\n- Stage $2$ core service times per job are independent and exponentially distributed with mean $s_{\\text{ana,core}}$ seconds. The per-item overhead $o$ applies once per job for strategies without micro-batching and once per batch for strategy $3$.\n\nYour program must:\n- Implement a discrete-event simulation respecting the above assumptions for each strategy and test case.\n- Use the same random draws across strategies within a test case to isolate the effect of the parallelization strategy. Specifically, pre-generate and reuse the sequence of Stage $1$ service times, Stage $2$ core service times, and inter-arrival times for all strategies in a given test case.\n- For analytics micro-batching, form batches greedily at the time the single analytics server becomes available: include up to $b$ jobs that have already arrived to Stage $2$ by that time; do not delay the server to wait for future arrivals to fill a batch beyond what is currently available.\n- Express throughput in jobs per second and latency in seconds.\n\nTest suite with parameter sets:\n- Case $1$: $N=500$, $\\lambda=5$, $s_{\\text{sim}}=0.1$, $s_{\\text{ana,core}}=0.15$, $o=0.02$, $k=4$, $m=2$, $b=8$, random seed $42$.\n- Case $2$: $N=1000$, $\\lambda=20$, $s_{\\text{sim}}=0.08$, $s_{\\text{ana,core}}=0.12$, $o=0.04$, $k=6$, $m=4$, $b=16$, random seed $43$.\n- Case $3$: $N=400$, $\\lambda=8$, $s_{\\text{sim}}=0.05$, $s_{\\text{ana,core}}=0.3$, $o=0.1$, $k=8$, $m=2$, $b=32$, random seed $44$.\n- Case $4$: $N=200$, $\\lambda=1$, $s_{\\text{sim}}=0.2$, $s_{\\text{ana,core}}=0.2$, $o=0.02$, $k=4$, $m=2$, $b=8$, random seed $45$.\n\nOutput specification:\n- For each case in ascending order $(1,2,3,4)$ and for strategies $s \\in \\{0,1,2,3\\}$ in ascending order, compute two floats: throughput and mean latency.\n- Aggregate the results into a single line of output containing a comma-separated list enclosed in square brackets.\n- The list ordering must be: for Case $1$, $(\\text{throughput}_0,\\text{latency}_0,\\text{throughput}_1,\\text{latency}_1,\\text{throughput}_2,\\text{latency}_2,\\text{throughput}_3,\\text{latency}_3)$, then Case $2$ in the same pattern, then Case $3$, then Case $4$.\n\nUnits:\n- Report throughput in jobs per second and latency in seconds.\n\nAngle units:\n- No angles are used; this is not applicable.\n\nPercentages:\n- No percentages are used; this is not applicable.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\dots]$).",
            "solution": "The user has provided a problem that requires the design and implementation of a discrete-event simulation to evaluate four different parallelization strategies for a two-stage processing pipeline. The problem is rooted in queuing theory and is well-defined, scientifically sound, and computationally verifiable.\n\n### Step 1: Extract Givens\n\nThe problem provides the following data, definitions, and constraints:\n- **Arrival Process**: A Poisson process with rate $\\lambda$ arrivals per second. Inter-arrival times are independent and exponentially distributed with mean $1/\\lambda$.\n- **Scheduling Discipline**: First-Come First-Served (FCFS) at each stage. For multi-server stages, arrivals a-re assigned to the server that becomes available earliest.\n- **Stage 1 (Simulation)**: $c_1$ identical parallel servers. Service times are independent and exponentially distributed with mean $s_{\\text{sim}}$ seconds.\n- **Stage 2 (Analytics)**: $c_2$ identical parallel servers. Core service times are independent and exponentially distributed with mean $s_{\\text{ana,core}}$ seconds. There is a per-item or per-batch overhead $o$ seconds.\n- **Strategy 0 (Baseline)**: $c_1 = 1$, $c_2 = 1$. No batching. Stage 2 service time per job is $o + X$, where $X \\sim \\text{Exp}(\\text{mean}=s_{\\text{ana,core}})$.\n- **Strategy 1 (Analytics Data-Parallel)**: $c_1 = 1$, $c_2 = k$. No batching. Stage 2 service time is the same as Strategy 0.\n- **Strategy 2 (Data-Parallel Both Stages)**: $c_1 = m$, $c_2 = k$. No batching. Stage 2 service time is the same as Strategy 0.\n- **Strategy 3 (Analytics Micro-Batching)**: $c_1 = 1$, $c_2 = 1$. Stage 2 processes jobs in batches of size up to $b$. The per-batch service time is $o + \\sum_{i=1}^{n_b} X_i$, where $n_b \\leq b$ is the batch size and $X_i$ are independent Exp($s_{\\text{ana,core}}$) variables. Batches are formed greedily when the server becomes available.\n- **Performance Metrics**:\n    - **Throughput**: Total completed jobs / (last completion time - first arrival time).\n    - **Mean End-to-End Latency**: Average of (Stage 2 completion time - Stage 1 arrival time) over all jobs.\n- **Simulation Constraint**: For each test case, the same sequence of random draws for inter-arrival times, Stage 1 service times, and Stage 2 core service times must be used across all four strategies.\n- **Test Cases**:\n    - Case 1: $N=500$, $\\lambda=5$, $s_{\\text{sim}}=0.1$, $s_{\\text{ana,core}}=0.15$, $o=0.02$, $k=4$, $m=2$, $b=8$, seed=42.\n    - Case 2: $N=1000$, $\\lambda=20$, $s_{\\text{sim}}=0.08$, $s_{\\text{ana,core}}=0.12$, $o=0.04$, $k=6$, $m=4$, $b=16$, seed=43.\n    - Case 3: $N=400$, $\\lambda=8$, $s_{\\text{sim}}=0.05$, $s_{\\text{ana,core}}=0.3$, $o=0.1$, $k=8$, $m=2$, $b=32$, seed=44.\n    - Case 4: $N=200$, $\\lambda=1$, $s_{\\text{sim}}=0.2$, $s_{\\text{ana,core}}=0.2$, $o=0.02$, $k=4$, $m=2$, $b=8$, seed=45.\n- **Output Format**: A single line containing a comma-separated list of floats (throughput, latency for each strategy and each case) enclosed in square brackets.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is subjected to rigorous validation.\n- **Scientifically Grounded**: The problem is based on fundamental concepts of queuing theory ($M/M/c$ queues, Poisson processes, exponential distributions) and discrete-event simulation, which are standard and well-established in operations research, computer science, and engineering. The use of Little's Law as a conceptual underpinning is appropriate. The model is scientifically sound.\n- **Well-Posed**: The problem is well-posed. It requires the computation of specific performance metrics for clearly defined system configurations. All necessary parameters are provided, and the use of a random seed ensures that the simulation is deterministic and reproducible, leading to a unique solution. The simulation is guaranteed to terminate as it processes a fixed number of jobs, $N$.\n- **Objective**: The problem is stated using precise mathematical and algorithmic language. All strategies, metrics, and assumptions are defined objectively and without ambiguity.\n- **Completeness and Consistency**: The problem statement is self-contained and provides all necessary data ($N$, $\\lambda$, service time means, overhead, server counts, batch size, and random seeds). The constraints, such as reusing random variates, are consistent with sound experimental design for comparing systems. There are no contradictions.\n- **Unrealistic or Infeasible**: The parameters are physically plausible for modeling computational tasks. The model is a simplification, but not an unrealistic or impossible one.\n- **Ill-Posed or Poorly Structured**: The problem is well-structured, guiding the user to implement a discrete-event simulation. The solution is unique and stable given the fixed random seed.\n- **Pseudo-Profound or Trivial**: The implementation of a discrete-event simulation for four different queuing configurations, especially the micro-batching strategy, is a non-trivial programming and modeling task. It is a substantive problem.\n- **Outside Scientific Verifiability**: The results are verifiable by implementing the specified simulation with the given parameters and seed.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a well-defined, scientifically grounded problem in simulation modeling. I will now proceed to provide a complete solution.\n\n### Principle-Based Design of the Solution\n\nThe solution will be a discrete-event simulation model implemented in Python. The core principle is to track the progression of each of the $N$ jobs through the two-stage pipeline, calculating their arrival and completion timestamps at each stage according to the rules of the specified strategy.\n\n**1. Random Variate Generation:**\nTo ensure a fair comparison between strategies as mandated, we first pre-generate all random numbers for a given test case. A `NumPy` random number generator is initialized with the specified seed. We generate $N$ values for:\n- Inter-arrival times at Stage 1, from an exponential distribution with mean $1/\\lambda$.\n- Service times for Stage 1, from an exponential distribution with mean $s_{\\text{sim}}$.\n- Core service times for Stage 2, from an exponential distribution with mean $s_{\\text{ana,core}}$.\nThese three arrays of random variates will be reused for each of the four strategies within a test case.\n\n**2. Simulation of a Multi-Server Stage (M/M/c-like queue):**\nThis logic is common to Stage 1 and to Stage 2 for Strategies 0, 1, and 2. A stage with $c$ servers is modeled by maintaining the time at which each server becomes available. A min-heap is the ideal data structure for this, allowing $O(1)$ access to the earliest available server time. For each job arriving at the stage at time $t_{\\text{arrival}}$:\n- The earliest available server is found, available at time $t_{\\text{server\\_avail}}$.\n- The job's service starts at $t_{\\text{start}} = \\max(t_{\\text{arrival}}, t_{\\text{server\\_avail}})$.\n- The job's service completes at $t_{\\text{complete}} = t_{\\text{start}} + t_{\\text{service}}$.\n- The server's availability time is updated to $t_{\\text{complete}}$.\n\n**3. Simulation of Stage 1:**\nWe first calculate the absolute arrival times of all $N$ jobs at Stage 1 by taking the cumulative sum of the pre-generated inter-arrival times. Then, using the multi-server logic described above with $c_1$ servers, we compute the completion time of each job from Stage 1. These completion times become the arrival times for Stage 2.\n\n**4. Simulation of Stage 2:**\nThe jobs must be processed at Stage 2 in the order they arrive from Stage 1. Therefore, we sort the jobs based on their Stage 1 completion times before simulating Stage 2. Each job carries its pre-generated Stage 2 core service time and its original Stage 1 arrival time (to calculate end-to-end latency).\n\n- **Strategies 0, 1, 2 (Non-Batching):** We apply the same multi-server simulation logic. The number of servers is $c_2$. The service time for each job is its pre-generated core service time plus the overhead $o$.\n\n- **Strategy 3 (Micro-Batching):** This requires special logic for its single server ($c_2=1$). We maintain the server's availability time. The simulation proceeds in steps, driven by the server becoming available.\n    - When the server is available at time $t_{\\text{current}}$, it greedily forms a batch from all jobs that are waiting in its queue (i.e., have completed Stage 1 by $t_{\\text{current}}$). The batch size is capped at $b$.\n    - If the server is available but the queue is empty, time is advanced to the arrival time of the next job from Stage 1. This job then forms a batch of size 1.\n    - The total service time for the batch is the single overhead $o$ plus the sum of the core service times of all jobs in the batch.\n    - All jobs in the batch share the same completion time: $t_{\\text{batch\\_complete}} = t_{\\text{current}} + t_{\\text{batch\\_service}}$.\n    - The server's next availability time is updated to $t_{\\text{batch\\_complete}}$.\n\n**5. Metrics Calculation:**\nAfter simulating all $N$ jobs through both stages, we have the initial arrival time and final completion time for every job.\n- **End-to-End Latency**: For each job, this is its final completion time minus its initial arrival time. The mean of these values is calculated.\n- **Throughput**: This is $N$ divided by the total simulation span, which is the time of the last job's completion minus the time of the first job's arrival.\n\nBy encapsulating this logic into functions, we can systematically run the simulation for each test case and each strategy, collecting the results for final output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\nfrom collections import deque\n\ndef simulate_stage1(c1, s1_arrival_times, s1_service_times):\n    \"\"\"Simulates a multi-server stage 1 and returns job completion times.\"\"\"\n    num_jobs = len(s1_arrival_times)\n    s1_completion_times = np.zeros(num_jobs)\n    server_availability = [0.0] * c1\n    heapq.heapify(server_availability)\n\n    for i in range(num_jobs):\n        arrival_time = s1_arrival_times[i]\n        service_time = s1_service_times[i]\n        \n        earliest_server_avail = heapq.heappop(server_availability)\n        start_time = max(arrival_time, earliest_server_avail)\n        completion_time = start_time + service_time\n        \n        s1_completion_times[i] = completion_time\n        heapq.heappush(server_availability, completion_time)\n        \n    return s1_completion_times\n\ndef simulate_stage2_non_batching(c2, o, jobs_for_s2):\n    \"\"\"Simulates a non-batching multi-server stage 2.\"\"\"\n    server_availability = [0.0] * c2\n    heapq.heapify(server_availability)\n    completion_times_dict = {}\n\n    for s2_arrival_time, s2_core_service_time, s1_initial_arrival_time in jobs_for_s2:\n        service_time = o + s2_core_service_time\n        \n        earliest_server_avail = heapq.heappop(server_availability)\n        start_time = max(s2_arrival_time, earliest_server_avail)\n        completion_time = start_time + service_time\n        \n        completion_times_dict[s1_initial_arrival_time] = completion_time\n        heapq.heappush(server_availability, completion_time)\n        \n    return completion_times_dict\n\ndef simulate_stage2_batching(b, o, jobs_for_s2):\n    \"\"\"Simulates a single-server batching stage 2.\"\"\"\n    num_jobs = len(jobs_for_s2)\n    s2_queue = deque()\n    job_idx = 0\n    server_avail_time = 0.0\n    completion_times_dict = {}\n    processed_count = 0\n\n    while processed_count  num_jobs:\n        # If server is idle and no jobs are waiting, fast-forward to the next arrival.\n        if not s2_queue and server_avail_time  jobs_for_s2[job_idx][0]:\n            current_time = jobs_for_s2[job_idx][0]\n        else:\n            current_time = server_avail_time\n\n        # Add all jobs that have arrived by current_time to the queue.\n        while job_idx  num_jobs and jobs_for_s2[job_idx][0] = current_time:\n            s2_queue.append(jobs_for_s2[job_idx])\n            job_idx += 1\n        \n        # Form a batch from the available jobs in the queue.\n        batch_size = min(len(s2_queue), b)\n        if batch_size == 0:\n            # Should not happen if loop logic is correct, but as a safeguard.\n            if job_idx  num_jobs:\n                current_time = jobs_for_s2[job_idx][0]\n                continue\n            else:\n                break\n        \n        batch = [s2_queue.popleft() for _ in range(batch_size)]\n        \n        # Calculate batch service and completion time.\n        batch_core_service = sum(job[1] for job in batch)\n        batch_total_service = o + batch_core_service\n        batch_completion_time = current_time + batch_total_service\n        \n        server_avail_time = batch_completion_time\n\n        for job in batch:\n            s1_initial_arrival_time = job[2]\n            completion_times_dict[s1_initial_arrival_time] = batch_completion_time\n        \n        processed_count += batch_size\n        \n    return completion_times_dict\n\ndef run_simulation(params, strategy_params, random_variates):\n    \"\"\"Runs a single simulation for a given strategy.\"\"\"\n    N, o = params['N'], params['o']\n    c1, c2, b, is_batching = strategy_params\n    s1_arrival_times, s1_service_times, s2_core_service_times = random_variates\n\n    s1_completion_times = simulate_stage1(c1, s1_arrival_times, s1_service_times)\n    \n    # Jobs must be processed by stage 2 in their arrival order to that stage.\n    jobs_for_s2 = sorted(zip(s1_completion_times, s2_core_service_times, s1_arrival_times))\n\n    if is_batching:\n        s2_completion_dict = simulate_stage2_batching(b, o, jobs_for_s2)\n    else:\n        s2_completion_dict = simulate_stage2_non_batching(c2, o, jobs_for_s2)\n\n    s2_final_completions = np.array([s2_completion_dict[t] for t in s1_arrival_times])\n\n    first_arrival = s1_arrival_times[0]\n    last_completion = np.max(s2_final_completions)\n    total_time = last_completion - first_completion\n    \n    throughput = N / total_time if total_time  0 else 0.0\n    \n    latencies = s2_final_completions - s1_arrival_times\n    mean_latency = np.mean(latencies)\n    \n    return throughput, mean_latency\n\n\ndef solve():\n    test_cases = [\n        {'N': 500, 'lambda': 5, 's_sim': 0.1, 's_ana_core': 0.15, 'o': 0.02, 'k': 4, 'm': 2, 'b': 8, 'seed': 42},\n        {'N': 1000, 'lambda': 20, 's_sim': 0.08, 's_ana_core': 0.12, 'o': 0.04, 'k': 6, 'm': 4, 'b': 16, 'seed': 43},\n        {'N': 400, 'lambda': 8, 's_sim': 0.05, 's_ana_core': 0.3, 'o': 0.1, 'k': 8, 'm': 2, 'b': 32, 'seed': 44},\n        {'N': 200, 'lambda': 1, 's_sim': 0.2, 's_ana_core': 0.2, 'o': 0.02, 'k': 4, 'm': 2, 'b': 8, 'seed': 45},\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        N, lambda_, s_sim, s_ana_core = case['N'], case['lambda'], case['s_sim'], case['s_ana_core']\n        k, m, b, seed = case['k'], case['m'], case['b'], case['seed']\n        \n        # Pre-generate random variates for the test case\n        rng = np.random.default_rng(seed)\n        # Add a small value to inter-arrival times to avoid zero, which cumsum handles poorly for unique keys.\n        inter_arrival_times = rng.exponential(1.0 / lambda_, N) + 1e-12 \n        s1_service_times = rng.exponential(s_sim, N)\n        s2_core_service_times = rng.exponential(s_ana_core, N)\n        s1_arrival_times = np.cumsum(inter_arrival_times)\n        \n        random_variates = (s1_arrival_times, s1_service_times, s2_core_service_times)\n        \n        strategies = {\n            0: (1, 1, b, False),       # c1, c2, b, is_batching\n            1: (1, k, b, False),\n            2: (m, k, b, False),\n            3: (1, 1, b, True)\n        }\n        \n        case_results = []\n        for i in range(4):\n            strategy_params = strategies[i]\n            throughput, mean_latency = run_simulation(case, strategy_params, random_variates)\n            case_results.extend([throughput, mean_latency])\n        \n        all_results.extend(case_results)\n\n    # Format output as a comma-separated list of floats inside brackets\n    print(f\"[{','.join(f'{x:.6f}' for x in all_results)}]\")\n\nsolve()\n```"
        }
    ]
}