{
    "hands_on_practices": [
        {
            "introduction": "A primary objective of any Prognostics and Health Management (PHM) program is to maximize the operational availability of a system. This first exercise provides a hands-on look at the fundamental trade-off that governs availability. By modeling a simple repairable system as a two-state Markov chain, you will derive the classic formula for steady-state availability, gaining a clear, quantitative understanding of how failure rates ($\\lambda$) and repair rates ($\\mu$) dictate system performance .",
            "id": "4236511",
            "problem": "A predictive Digital Twin (DT) of a Cyber-Physical System (CPS) monitors a single repairable subsystem operating in one of two states: operational ($\\text{Up}$) and failed ($\\text{Down}$). Failures occur according to a memoryless mechanism with constant failure rate $\\lambda$ (per unit time), and repairs are performed by a maintenance team with a memoryless mechanism and constant repair rate $\\mu$ (per unit time). Assume that the process is well modeled as a continuous-time Markov chain with two states and that the system operates indefinitely. Using only the definitions of stationary distributions for continuous-time Markov chains and the interpretation of steady-state availability as the long-run fraction of time the subsystem is operational, derive the steady-state availability $A$ of the subsystem in terms of $\\lambda$ and $\\mu$. Express your final answer as a single closed-form analytic expression in terms of $\\lambda$ and $\\mu$. Additionally, briefly interpret your result in the context of Prognostics and Health Management (PHM) for how changes in $\\mu$ (enabled by PHM-driven maintenance optimization via the DT) influence $A$. The final reported quantity must be the analytic expression for $A$; do not provide any numerical evaluation.",
            "solution": "The subsystem evolves as a two-state continuous-time Markov chain with states $\\text{Up}$ and $\\text{Down}$. By the memoryless assumptions, the failure transition from $\\text{Up}$ to $\\text{Down}$ occurs at rate $\\lambda$, and the repair transition from $\\text{Down}$ to $\\text{Up}$ occurs at rate $\\mu$. The infinitesimal generator matrix $\\mathbf{Q}$ for the chain, with state order $(\\text{Up}, \\text{Down})$, is\n$$\n\\mathbf{Q} \\;=\\;\n\\begin{pmatrix}\n-\\lambda  \\lambda \\\\\n\\mu  -\\mu\n\\end{pmatrix}.\n$$\nThe steady-state (stationary) distribution $\\boldsymbol{\\pi} = (\\pi_{\\text{Up}}, \\pi_{\\text{Down}})$ satisfies the global balance equations $\\boldsymbol{\\pi}\\,\\mathbf{Q} = \\mathbf{0}$ together with the normalization constraint $\\pi_{\\text{Up}} + \\pi_{\\text{Down}} = 1$. Writing out the balance equations,\n$$\n\\pi_{\\text{Up}}(-\\lambda) + \\pi_{\\text{Down}}\\mu = 0,\n$$\nand\n$$\n\\pi_{\\text{Up}}\\lambda + \\pi_{\\text{Down}}(-\\mu) = 0,\n$$\nwhich are redundant given normalization. Rearranging the first gives\n$$\n\\pi_{\\text{Down}}\\mu = \\pi_{\\text{Up}}\\lambda \\quad \\Rightarrow \\quad \\pi_{\\text{Down}} = \\pi_{\\text{Up}} \\frac{\\lambda}{\\mu}.\n$$\nUsing $\\pi_{\\text{Up}} + \\pi_{\\text{Down}} = 1$,\n$$\n\\pi_{\\text{Up}} + \\pi_{\\text{Up}} \\frac{\\lambda}{\\mu} = 1\n\\quad \\Rightarrow \\quad\n\\pi_{\\text{Up}} \\left(1 + \\frac{\\lambda}{\\mu}\\right) = 1\n\\quad \\Rightarrow \\quad\n\\pi_{\\text{Up}} = \\frac{1}{1 + \\frac{\\lambda}{\\mu}} = \\frac{\\mu}{\\lambda + \\mu}.\n$$\nBy definition, the steady-state availability $A$ is the long-run fraction of time the subsystem is operational, which equals the stationary probability of the $\\text{Up}$ state. Therefore,\n$$\nA = \\pi_{\\text{Up}} = \\frac{\\mu}{\\lambda + \\mu}.\n$$\n\nAn equivalent derivation from renewal theory uses the long-run time-average fraction in $\\text{Up}$ given by the ratio of the mean up-time to the mean cycle time. With exponential failure of rate $\\lambda$, the mean up-time is $1/\\lambda$, and with exponential repair of rate $\\mu$, the mean down-time is $1/\\mu$. Thus the mean cycle time is $(1/\\lambda) + (1/\\mu)$, and the fraction of time up is\n$$\nA = \\frac{\\frac{1}{\\lambda}}{\\frac{1}{\\lambda} + \\frac{1}{\\mu}} = \\frac{\\mu}{\\lambda + \\mu},\n$$\nconsistent with the Markov-chain stationary analysis.\n\nInterpretation in Prognostics and Health Management (PHM): PHM-enabled maintenance optimization via the DT primarily acts to increase $\\mu$ by reducing repair delays (e.g., through better spare logistics, scheduling, and fault isolation). Since\n$$\nA(\\lambda,\\mu) = \\frac{\\mu}{\\lambda + \\mu},\n$$\nits sensitivity to $\\mu$ satisfies\n$$\n\\frac{\\partial A}{\\partial \\mu} = \\frac{\\lambda}{(\\lambda + \\mu)^{2}} > 0,\n$$\nso increasing $\\mu$ strictly increases $A$; however, the marginal gain diminishes as $\\mu$ grows because $\\frac{\\partial A}{\\partial \\mu}$ decreases with increasing $\\mu$. Conversely, reducing $\\lambda$ via improved prognostics and condition-based interventions also increases $A$, with sensitivity\n$$\n\\frac{\\partial A}{\\partial \\lambda} = -\\frac{\\mu}{(\\lambda + \\mu)^{2}}  0.\n$$\nThus, PHM strategies that jointly reduce $\\lambda$ and increase $\\mu$ provide complementary improvements in steady-state availability, which the DT can quantify and trade off for optimal maintenance planning.",
            "answer": "$$\\boxed{\\frac{\\mu}{\\lambda+\\mu}}$$"
        },
        {
            "introduction": "To effectively manage system availability, a digital twin must accurately track the health degradation of critical components, which is often not directly observable. This practice introduces the Kalman filter, a cornerstone algorithm in PHM for estimating a hidden state from a sequence of noisy measurements. By working through the predict-update cycle for a simple random walk model, you will gain fundamental insight into how a system's belief about its health state is recursively updated as new data becomes available .",
            "id": "4236615",
            "problem": "A digital twin used for Prognostics and Health Management (PHM) of a Cyber-Physical System (CPS) tracks a scalar health indicator $x_k$ that evolves as a random walk and is measured directly with additive noise. The discrete-time state-space model is given by the process equation $x_k = A x_{k-1} + w_{k-1}$ and the measurement equation $y_k = C x_k + v_k$, where $w_{k-1} \\sim \\mathcal{N}(0,Q)$ and $v_k \\sim \\mathcal{N}(0,R)$ are independent, zero-mean Gaussian noises. The prior at $k=0$ is Gaussian with mean $x_0$ and variance $P_0$. At each step, the digital twin performs a one-step predict and update cycle to assimilate measurements into its belief over $x_k$.\n\nAssume the scalar case with $A=1$, $C=1$, $Q=0.01$, $R=0.04$, prior mean $x_0=0$, prior variance $P_0=1$, and two sequential measurements $y_1=0.2$ and $y_2=0.3$. Starting from the fundamental Bayesian filtering framework for linear Gaussian models, and performing exactly one predict and one update at each time step, compute the posterior state estimates (posterior means) after assimilating $y_1$ and $y_2$, denoted $x_1$ and $x_2$, respectively.\n\nExpress your final answer as exact rational numbers and provide it as a single row matrix $\\begin{pmatrix}x_1  x_2\\end{pmatrix}$. No rounding is required. There are no physical units associated with $x_k$ in this scenario.",
            "solution": "The state-space model is given by:\nProcess model: $x_k = A x_{k-1} + w_{k-1}$, with $w_{k-1} \\sim \\mathcal{N}(0, Q)$\nMeasurement model: $y_k = C x_k + v_k$, with $v_k \\sim \\mathcal{N}(0, R)$\n\nThe posterior probability distribution of the state $x_k$ conditioned on all measurements up to time $k$, denoted $p(x_k | y_{1:k})$, is a Gaussian distribution $\\mathcal{N}(\\hat{x}_{k|k}, P_{k|k})$. We are asked to find the posterior means $\\hat{x}_{1|1}$ and $\\hat{x}_{2|2}$, which will be denoted as $x_1$ and $x_2$ in the final answer.\n\nThe given parameters are:\n$A = 1$\n$C = 1$\n$Q = 0.01 = \\frac{1}{100}$\n$R = 0.04 = \\frac{4}{100} = \\frac{1}{25}$\n\nThe prior distribution at time $k=0$ is given by its mean and variance:\n$\\hat{x}_{0|0} = 0$\n$P_{0|0} = 1$\n\nThe measurements are:\n$y_1 = 0.2 = \\frac{1}{5}$\n$y_2 = 0.3 = \\frac{3}{10}$\n\nThe Kalman filter recursions for a scalar system are as follows.\n\n**Predict Step:**\nThe prior distribution for step $k$ is predicted from the posterior at step $k-1$.\nPredicted state mean: $\\hat{x}_{k|k-1} = A \\hat{x}_{k-1|k-1}$\nPredicted state variance: $P_{k|k-1} = A^2 P_{k-1|k-1} + Q$\n\n**Update Step:**\nThe predicted distribution is updated using the measurement $y_k$.\nInnovation (measurement residual): $\\tilde{y}_k = y_k - C \\hat{x}_{k|k-1}$\nInnovation variance: $S_k = C^2 P_{k|k-1} + R$\nKalman gain: $K_k = \\frac{P_{k|k-1} C}{S_k} = \\frac{P_{k|k-1} C}{C^2 P_{k|k-1} + R}$\nUpdated state mean: $\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k \\tilde{y}_k$\nUpdated state variance: $P_{k|k} = (1 - K_k C) P_{k|k-1}$\n\nWe now apply these equations for $k=1$ and $k=2$.\n\n**Time Step $k=1$**\n\n**Predict:**\nUsing the prior at $k=0$ ($\\hat{x}_{0|0}=0$, $P_{0|0}=1$):\n$\\hat{x}_{1|0} = A \\hat{x}_{0|0} = 1 \\cdot 0 = 0$\n$P_{1|0} = A^2 P_{0|0} + Q = 1^2 \\cdot 1 + \\frac{1}{100} = 1 + \\frac{1}{100} = \\frac{101}{100}$\n\n**Update:**\nUsing the measurement $y_1 = \\frac{1}{5}$:\nInnovation: $\\tilde{y}_1 = y_1 - C \\hat{x}_{1|0} = \\frac{1}{5} - 1 \\cdot 0 = \\frac{1}{5}$\nInnovation variance: $S_1 = C^2 P_{1|0} + R = 1^2 \\cdot \\frac{101}{100} + \\frac{1}{25} = \\frac{101}{100} + \\frac{4}{100} = \\frac{105}{100} = \\frac{21}{20}$\nKalman gain: $K_1 = \\frac{P_{1|0} C}{S_1} = \\frac{\\frac{101}{100} \\cdot 1}{\\frac{21}{20}} = \\frac{101}{100} \\cdot \\frac{20}{21} = \\frac{101}{5 \\cdot 21} = \\frac{101}{105}$\nUpdated state mean (posterior mean for $k=1$):\n$\\hat{x}_{1|1} = \\hat{x}_{1|0} + K_1 \\tilde{y}_1 = 0 + \\frac{101}{105} \\cdot \\frac{1}{5} = \\frac{101}{525}$\n\nWe also compute the updated variance, which will be the prior for the next step:\nUpdated state variance: $P_{1|1} = (1 - K_1 C) P_{1|0} = (1 - \\frac{101}{105} \\cdot 1) \\frac{101}{100} = (\\frac{105 - 101}{105}) \\frac{101}{100} = \\frac{4}{105} \\cdot \\frac{101}{100} = \\frac{101}{105 \\cdot 25} = \\frac{101}{2625}$\n\nThe posterior distribution after assimilating $y_1$ is $\\mathcal{N}(\\frac{101}{525}, \\frac{101}{2625})$.\n\n**Time Step $k=2$**\n\n**Predict:**\nUsing the posterior from $k=1$ ($\\hat{x}_{1|1}=\\frac{101}{525}$, $P_{1|1}=\\frac{101}{2625}$):\n$\\hat{x}_{2|1} = A \\hat{x}_{1|1} = 1 \\cdot \\frac{101}{525} = \\frac{101}{525}$\n$P_{2|1} = A^2 P_{1|1} + Q = 1^2 \\cdot \\frac{101}{2625} + \\frac{1}{100} = \\frac{101 \\cdot 4}{10500} + \\frac{1 \\cdot 105}{10500} = \\frac{404 + 105}{10500} = \\frac{509}{10500}$\n\n**Update:**\nUsing the measurement $y_2 = \\frac{3}{10}$:\nInnovation: $\\tilde{y}_2 = y_2 - C \\hat{x}_{2|1} = \\frac{3}{10} - 1 \\cdot \\frac{101}{525} = \\frac{3 \\cdot 105}{1050} - \\frac{101 \\cdot 2}{1050} = \\frac{315 - 202}{1050} = \\frac{113}{1050}$\nInnovation variance: $S_2 = C^2 P_{2|1} + R = 1^2 \\cdot \\frac{509}{10500} + \\frac{1}{25} = \\frac{509}{10500} + \\frac{420}{10500} = \\frac{929}{10500}$\nKalman gain: $K_2 = \\frac{P_{2|1} C}{S_2} = \\frac{\\frac{509}{10500} \\cdot 1}{\\frac{929}{10500}} = \\frac{509}{929}$\nUpdated state mean (posterior mean for $k=2$):\n$\\hat{x}_{2|2} = \\hat{x}_{2|1} + K_2 \\tilde{y}_2 = \\frac{101}{525} + \\frac{509}{929} \\cdot \\frac{113}{1050}$\nTo perform the addition, we find a common denominator:\n$\\hat{x}_{2|2} = \\frac{101 \\cdot 2}{1050} + \\frac{509 \\cdot 113}{929 \\cdot 1050} = \\frac{202 \\cdot 929 + 57517}{975450} = \\frac{187658 + 57517}{975450} = \\frac{245175}{975450}$\nThis fraction can be simplified. We can divide the numerator and denominator by their greatest common divisor.\n$\\frac{245175}{975450} = \\frac{25 \\cdot 9807}{25 \\cdot 39018} = \\frac{9807}{39018} = \\frac{3 \\cdot 3269}{3 \\cdot 13006} = \\frac{3269}{13006} = \\frac{7 \\cdot 467}{7 \\cdot 1858} = \\frac{467}{1858}$\n\nThe posterior state estimates are $x_1 = \\hat{x}_{1|1} = \\frac{101}{525}$ and $x_2 = \\hat{x}_{2|2} = \\frac{467}{1858}$.\nThe final answer is presented as a row matrix as requested.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{101}{525}  \\frac{467}{1858}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The true power of prognostics is realized when predictions are used to drive intelligent, cost-effective decisions. This final practice moves from estimation to action, tackling the problem of optimal maintenance scheduling under uncertainty. You will use the principles of Bayes risk minimization to derive a decision rule that balances the known cost of planned maintenance against the potential cost of an in-service failure, based on a probabilistic Remaining Useful Life (RUL) forecast .",
            "id": "4236673",
            "problem": "A cyber-physical system (CPS) asset is monitored by a Digital Twin that performs Prognostics and Health Management (PHM). The Digital Twin maintains a posterior probability distribution for the Remaining Useful Life (RUL) $T$ of a component, conditioned on the latest data $\\mathcal{D}$. At discrete inspection times spaced by $\\Delta t$ hours, a binary decision is made: either perform planned maintenance immediately or continue operating until the next inspection. Let the cost of planned maintenance be $C_m$ dollars and the cost incurred if a failure occurs before the next inspection be $C_f$ dollars.\n\nStarting from first principles of expected cost and decision-making under uncertainty (Bayes risk minimization), derive a threshold-based stopping rule that depends only on the posterior probability that failure occurs before the next inspection, namely the probability $\\mathbb{P}(T \\le \\Delta t \\mid \\mathcal{D})$. Implement this rule to decide, for each test case, whether to stop now for maintenance (decision is true) or continue for one more interval (decision is false). Explicitly compute the posterior probability $\\mathbb{P}(T \\le \\Delta t \\mid \\mathcal{D})$ using the cumulative distribution function of the specified posterior distribution.\n\nThe posterior $T \\mid \\mathcal{D}$ is specified as either:\n- A Weibull distribution with shape parameter $k$ and scale parameter $\\lambda$ hours; or\n- A Lognormal distribution with parameters $\\mu$ (log-location) and $\\sigma$ (log-scale), so that $\\ln T \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n\nTime quantities must be handled in hours. Costs are in dollars. Output probabilities must be unitless and rounded to six decimal places. For each test case, you must output a three-element list $[d, p, \\tau]$ where:\n- $d$ is a boolean indicating the decision to stop ($\\text{True}$) or to continue ($\\text{False}$),\n- $p$ is the computed probability $\\mathbb{P}(T \\le \\Delta t \\mid \\mathcal{D})$ rounded to six decimal places,\n- $\\tau$ is the decision threshold on $\\mathbb{P}(T \\le \\Delta t \\mid \\mathcal{D})$ derived from the Bayes risk minimization, rounded to six decimal places.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets with no spaces, where each element corresponds to one test case and is itself a three-element list of the form described above (for example, \"[[True,0.123456,0.200000],[False,0.050000,0.250000]]\").\n\nUse the following test suite of posterior distributions and decision parameters:\n- Test case $1$: Posterior is Weibull with $k=2.0$, $\\lambda=100.0$ hours; $\\Delta t=10.0$ hours; $C_m=2000.0$ dollars; $C_f=10000.0$ dollars.\n- Test case $2$: Posterior is Lognormal with $\\mu=3.5$, $\\sigma=0.6$; $\\Delta t=24.0$ hours; $C_m=500.0$ dollars; $C_f=2000.0$ dollars.\n- Test case $3$ (boundary condition): Posterior is Weibull with $k=2.0$, $\\lambda=21.18$ hours; $\\Delta t=10.0$ hours; $C_m=1000.0$ dollars; $C_f=5000.0$ dollars.\n- Test case $4$ (edge case with high maintenance cost): Posterior is Weibull with $k=1.5$, $\\lambda=50.0$ hours; $\\Delta t=15.0$ hours; $C_m=15000.0$ dollars; $C_f=10000.0$ dollars.\n- Test case $5$ (edge case with very high failure cost): Posterior is Weibull with $k=2.0$, $\\lambda=100.0$ hours; $\\Delta t=10.0$ hours; $C_m=500.0$ dollars; $C_f=100000.0$ dollars.\n\nThe final output format must be a single line:\n- A single list whose elements are the per-test-case lists, with no spaces anywhere in the line.\n- Each float rounded to six decimal places.",
            "solution": "The problem requires the derivation and implementation of a threshold-based stopping rule for planned maintenance of a cyber-physical system component. The decision is made under uncertainty, guided by the principle of Bayes risk minimization, using a posterior probability distribution for the component's Remaining Useful Life (RUL).\n\nFirst, we formalize the decision-making problem. At a given inspection point, we must choose between two actions:\n1.  **Stop**: Perform planned maintenance immediately.\n2.  **Continue**: Defer maintenance and continue operating for another interval of duration $\\Delta t$.\n\nThe decision will be based on minimizing the expected cost over the next interval $[0, \\Delta t]$. Let $T$ be the random variable representing the RUL, with a posterior probability distribution conditioned on available data $\\mathcal{D}$. The key quantity for our decision is the probability of failure within the next interval, which we denote as $p$:\n$$ p = \\mathbb{P}(T \\le \\Delta t \\mid \\mathcal{D}) $$\n\nNext, we define the cost associated with each action.\nThe cost of the **Stop** action, let's call it $J(\\text{Stop})$, is the deterministic cost of planned maintenance, $C_m$.\n$$ J(\\text{Stop}) = C_m $$\n\nThe cost of the **Continue** action is stochastic. If the component fails within the interval (i.e., $T \\le \\Delta t$), a cost of $C_f$ is incurred. If the component survives the interval (i.e., $T  \\Delta t$), no cost is incurred in this one-step lookahead model. The expected cost of the **Continue** action, $J(\\text{Continue})$, is the probability-weighted sum of these outcomes:\n$$ J(\\text{Continue}) = \\mathbb{E}[\\text{Cost} \\mid \\text{Continue}] = C_f \\cdot \\mathbb{P}(T \\le \\Delta t \\mid \\mathcal{D}) + 0 \\cdot \\mathbb{P}(T  \\Delta t \\mid \\mathcal{D}) $$\nSubstituting $p = \\mathbb{P}(T \\le \\Delta t \\mid \\mathcal{D})$, this simplifies to:\n$$ J(\\text{Continue}) = C_f \\cdot p $$\n\nAccording to the principle of Bayes risk minimization, we should choose the action with the lower expected cost. We should decide to **Stop** if the cost of stopping is less than the expected cost of continuing:\n$$ J(\\text{Stop})  J(\\text{Continue}) $$\n$$ C_m  C_f \\cdot p $$\n\nBy rearranging this inequality, we can express the decision rule in terms of the failure probability $p$:\n$$ p  \\frac{C_m}{C_f} $$\n\nThis inequality defines the threshold-based stopping rule. We will perform maintenance if the posterior probability of failure in the next interval, $p$, exceeds a critical threshold, $\\tau$. This threshold is the ratio of the maintenance cost to the failure cost:\n$$ \\tau = \\frac{C_m}{C_f} $$\nThe decision rule is therefore: **Stop** if $p  \\tau$, and **Continue** if $p \\le \\tau$. The decision variable $d$ is $\\text{True}$ for stopping, so $d = (p  \\tau)$.\n\nTo apply this rule, we must calculate the probability $p = \\mathbb{P}(T \\le \\Delta t \\mid \\mathcal{D})$ using the cumulative distribution function (CDF) of the given posterior distribution for $T$, evaluated at $T = \\Delta t$.\n\nIf the posterior for $T$ is a **Weibull distribution** with shape parameter $k$ and scale parameter $\\lambda$, its CDF is:\n$$ F_T(t; k, \\lambda) = 1 - \\exp\\left(-\\left(\\frac{t}{\\lambda}\\right)^k\\right) \\quad \\text{for } t \\ge 0 $$\nThe probability of failure is:\n$$ p = F_T(\\Delta t; k, \\lambda) = 1 - \\exp\\left(-\\left(\\frac{\\Delta t}{\\lambda}\\right)^k\\right) $$\n\nIf the posterior for $T$ is a **Lognormal distribution** with parameters $\\mu$ and $\\sigma$ (such that $\\ln T \\sim \\mathcal{N}(\\mu, \\sigma^2)$), its CDF is given in terms of the standard normal CDF, $\\Phi(\\cdot)$:\n$$ F_T(t; \\mu, \\sigma) = \\Phi\\left(\\frac{\\ln(t) - \\mu}{\\sigma}\\right) $$\nThe probability of failure is:\n$$ p = F_T(\\Delta t; \\mu, \\sigma) = \\Phi\\left(\\frac{\\ln(\\Delta t) - \\mu}{\\sigma}\\right) $$\nThe standard normal CDF can be calculated using the error function, $\\text{erf}(\\cdot)$, as $\\Phi(z) = \\frac{1}{2}\\left[1 + \\text{erf}\\left(\\frac{z}{\\sqrt{2}}\\right)\\right]$.\n\nWith these formulas, we can compute $p$ and $\\tau$ for each test case and determine the optimal maintenance decision $d$.",
            "answer": "[[False,0.009950,0.200000],[True,0.295791,0.250000],[False,0.200000,0.200000],[False,0.151431,1.500000],[True,0.009950,0.005000]]"
        }
    ]
}