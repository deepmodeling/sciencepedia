{
    "hands_on_practices": [
        {
            "introduction": "The most direct approach to prognostics involves observing a degradation trend and extrapolating it into the future. This practice embodies that fundamental concept, guiding you to estimate the Remaining Useful Life (RUL) by fitting a linear model to recent sensor data. You will work with common vibration features like Root Mean Square (RMS) and kurtosis, learning to handle multiple indicators of failure and making a final prediction based on the most critical one.",
            "id": "4240301",
            "problem": "You are building a Remaining Useful Life (RUL) estimator for a rotating machine within a digital twin of a Cyber-Physical System. The digital twin maintains recent measurements of two fault-sensitive features extracted from vibration: the Root Mean Square (RMS) of acceleration and the kurtosis of the vibration signal. Over a short horizon, assume the degradation process can be locally approximated as linear in time due to slow variation relative to the sampling period. Failure is defined to occur when either feature reaches its respective failure threshold. Your task is to estimate the linear degradation rates from recent data and compute the RUL as the earliest predicted time to reach any threshold.\n\nFundamental base:\n- The Root Mean Square (RMS) of an acceleration segment of length $N$ samples is defined by $\\mathrm{RMS} = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N} a_i^2}$, where $a_i$ are the acceleration samples; its trend over time can be represented as a discrete-time series $r_i$ sampled at times $t_i$.\n- The kurtosis of a signal segment is defined by $\\mathrm{Kurtosis} = \\frac{\\frac{1}{N}\\sum_{i=1}^{N} (x_i - \\mu)^4}{\\left(\\frac{1}{N}\\sum_{i=1}^{N} (x_i - \\mu)^2\\right)^2}$, where $x_i$ are the samples and $\\mu$ is the mean; its trend over time can be represented as a discrete-time series $k_i$ sampled at times $t_i$.\n- Over a short time window, linearization of the feature evolution is valid: $r(t) \\approx m_r t + b_r$ and $k(t) \\approx m_k t + b_k$.\n\nDefinitions:\n- Let $\\Delta t$ be the sampling interval in hours.\n- Let $r_i$ and $k_i$ be the last $N$ observed values of RMS and kurtosis at times $t_i = i \\Delta t$ for $i = 0, 1, \\dots, N-1$.\n- Let $r_{\\mathrm{th}}$ and $k_{\\mathrm{th}}$ be the respective failure thresholds for RMS and kurtosis.\n- Remaining Useful Life (RUL) is the smallest nonnegative time $\\tau$ from the current time $t_{N-1}$ until either $r(t)$ or $k(t)$ reaches its threshold. If either feature has already reached or exceeded its threshold at $t_{N-1}$, RUL is $0$. If the inferred degradation rate for a feature is nonpositive and its current value is below threshold, the crossing time for that feature is considered infinite.\n\nInstructions:\n1. Infer the linear degradation rate for each feature from the recent data window by fitting a straight line to $(t_i, r_i)$ and $(t_i, k_i)$ using ordinary least squares over the last $N$ samples.\n2. Compute the predicted crossing times $t_r^\\star$ and $t_k^\\star$ when $r(t)$ and $k(t)$ reach $r_{\\mathrm{th}}$ and $k_{\\mathrm{th}}$, respectively.\n3. Compute the RUL in hours as $\\min\\left(\\max(0, t_r^\\star - t_{N-1}), \\max(0, t_k^\\star - t_{N-1})\\right)$ with the conventions: if the slope for a feature is nonpositive and its current value is below threshold, its crossing time contribution is infinite; if its current value is already at or above threshold, its RUL contribution is $0$.\n4. Express the final RUL in hours, rounded to three decimals. Infinite values should be represented as $\\infty$.\n\nTest suite:\nImplement your program for the following parameter sets. For each set, use the given arrays as $r_i$ and $k_i$, the given $\\Delta t$ as the sampling interval in hours, and the given thresholds $r_{\\mathrm{th}}$ and $k_{\\mathrm{th}}$.\n\n- Case $1$ (general increasing trends):\n  - $\\Delta t = 0.5$\n  - $r_i = [1.20, 1.25, 1.28, 1.36, 1.45, 1.52, 1.62, 1.75]$\n  - $k_i = [3.20, 3.25, 3.30, 3.35, 3.45, 3.55, 3.68, 3.82]$\n  - $r_{\\mathrm{th}} = 2.20$\n  - $k_{\\mathrm{th}} = 5.00$\n- Case $2$ (kurtosis near threshold, RMS nearly flat):\n  - $\\Delta t = 1.0$\n  - $r_i = [1.00, 0.98, 1.01, 1.02, 1.03, 1.05]$\n  - $k_i = [4.80, 4.85, 4.88, 4.92, 4.95, 5.00, 5.05, 5.10]$\n  - $r_{\\mathrm{th}} = 1.50$\n  - $k_{\\mathrm{th}} = 5.20$\n- Case $3$ (RMS already above threshold):\n  - $\\Delta t = 0.25$\n  - $r_i = [1.40, 1.50, 1.65, 1.90]$\n  - $k_i = [3.60, 3.70, 3.75, 3.80]$\n  - $r_{\\mathrm{th}} = 1.80$\n  - $k_{\\mathrm{th}} = 6.00$\n- Case $4$ (RMS decreasing due to maintenance, kurtosis increasing):\n  - $\\Delta t = 2.0$\n  - $r_i = [2.00, 1.95, 1.90, 1.85, 1.80]$\n  - $k_i = [3.50, 3.60, 3.80, 4.10, 4.50]$\n  - $r_{\\mathrm{th}} = 2.30$\n  - $k_{\\mathrm{th}} = 5.00$\n- Case $5$ (both features flat, no degradation evident):\n  - $\\Delta t = 1.0$\n  - $r_i = [1.20, 1.20, 1.20, 1.20, 1.20]$\n  - $k_i = [3.20, 3.20, 3.20, 3.20, 3.20]$\n  - $r_{\\mathrm{th}} = 2.00$\n  - $k_{\\mathrm{th}} = 6.00$\n\nFinal output format:\nYour program should produce a single line of output containing the RUL results for the five cases as a comma-separated list enclosed in square brackets in hours, rounded to three decimals (with infinite values represented as the literal $\\mathrm{inf}$), for example $[r_1, r_2, r_3, r_4, r_5]$ where each $r_j$ is the RUL for case $j$ in hours.",
            "solution": "The solution to this problem involves three main steps for each feature (RMS and kurtosis): linear model fitting, time-to-threshold calculation, and RUL computation. The final system RUL is the minimum of the RULs calculated for each feature.\n\n**1. Linear Degradation Model Fitting**\nFor each feature (e.g., RMS, denoted by the series $r_i$), we have $N$ observations at times $t_i = i \\Delta t$ for $i=0, \\dots, N-1$. We fit a linear model $r(t) = m_r t + b_r$ using ordinary least squares (OLS). OLS finds the slope ($m_r$) and intercept ($b_r$) that minimize the sum of squared differences between the observed data and the fitted line. The standard formulas for OLS are:\n$$ m_r = \\frac{N \\sum t_i r_i - (\\sum t_i)(\\sum r_i)}{N \\sum t_i^2 - (\\sum t_i)^2} $$\n$$ b_r = \\frac{\\sum r_i - m_r \\sum t_i}{N} = \\bar{r} - m_r \\bar{t} $$\nA similar process is followed for the kurtosis data $k_i$ to find its slope $m_k$ and intercept $b_k$. In practice, this can be implemented using a library function for linear regression.\n\n**2. Time-to-Threshold Calculation**\nOnce the linear model is determined, the time $t_r^\\star$ at which the feature is predicted to cross its failure threshold $r_{\\mathrm{th}}$ is found by solving the line equation for $t$:\n$$ r_{\\mathrm{th}} = m_r t_r^\\star + b_r \\implies t_r^\\star = \\frac{r_{\\mathrm{th}} - b_r}{m_r} $$\nThis calculation is meaningful only if the degradation rate (slope) $m_r$ is positive. If $m_r \\le 0$, the feature is not trending towards failure, and its time-to-threshold is considered infinite.\n\n**3. Remaining Useful Life (RUL) Computation**\nThe RUL for a single feature is the time remaining from the last measurement until the predicted crossing time. The last measurement was taken at time $t_{N-1} = (N-1)\\Delta t$. The RUL for the RMS feature is therefore:\n$$ \\text{RUL}_r = t_r^\\star - t_{N-1} $$\nThis value must be non-negative. If the last observed value $r_{N-1}$ is already at or above the threshold $r_{\\mathrm{th}}$, the RUL is immediately 0. Otherwise, if the calculated RUL is negative (meaning the crossing time is in the past), it is also capped at 0. Combining these rules, the RUL for the feature is $\\max(0, t_r^\\star - t_{N-1})$.\n\n**4. System RUL**\nFailure is defined as the first threshold crossing. Therefore, the overall system RUL is the minimum of the RULs computed for each individual feature:\n$$ \\text{RUL}_{\\text{system}} = \\min(\\text{RUL}_r, \\text{RUL}_k) $$\nwhere $\\text{RUL}_k$ is calculated for kurtosis in the same manner. This provides the final estimate, which is then rounded as specified.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the RUL estimation problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1: general increasing trends\n        {\n            \"delta_t\": 0.5,\n            \"r_i\": [1.20, 1.25, 1.28, 1.36, 1.45, 1.52, 1.62, 1.75],\n            \"k_i\": [3.20, 3.25, 3.30, 3.35, 3.45, 3.55, 3.68, 3.82],\n            \"r_th\": 2.20,\n            \"k_th\": 5.00,\n        },\n        # Case 2: kurtosis near threshold, RMS nearly flat\n        {\n            \"delta_t\": 1.0,\n            \"r_i\": [1.00, 0.98, 1.01, 1.02, 1.03, 1.05],\n            \"k_i\": [4.80, 4.85, 4.88, 4.92, 4.95, 5.00, 5.05, 5.10],\n            \"r_th\": 1.50,\n            \"k_th\": 5.20,\n        },\n        # Case 3: RMS already above threshold\n        {\n            \"delta_t\": 0.25,\n            \"r_i\": [1.40, 1.50, 1.65, 1.90],\n            \"k_i\": [3.60, 3.70, 3.75, 3.80],\n            \"r_th\": 1.80,\n            \"k_th\": 6.00,\n        },\n        # Case 4: RMS decreasing, kurtosis increasing\n        {\n            \"delta_t\": 2.0,\n            \"r_i\": [2.00, 1.95, 1.90, 1.85, 1.80],\n            \"k_i\": [3.50, 3.60, 3.80, 4.10, 4.50],\n            \"r_th\": 2.30,\n            \"k_th\": 5.00,\n        },\n        # Case 5: both features flat\n        {\n            \"delta_t\": 1.0,\n            \"r_i\": [1.20, 1.20, 1.20, 1.20, 1.20],\n            \"k_i\": [3.20, 3.20, 3.20, 3.20, 3.20],\n            \"r_th\": 2.00,\n            \"k_th\": 6.00,\n        },\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        rul_r = calculate_feature_rul(case[\"r_i\"], case[\"delta_t\"], case[\"r_th\"])\n        rul_k = calculate_feature_rul(case[\"k_i\"], case[\"delta_t\"], case[\"k_th\"])\n        \n        final_rul = min(rul_r, rul_k)\n        \n        if final_rul == float('inf'):\n            results.append(\"inf\")\n        else:\n            results.append(f\"{final_rul:.3f}\")\n            \n    print(f\"[{','.join(results)}]\")\n\ndef calculate_feature_rul(feature_values, delta_t, threshold):\n    \"\"\"\n    Calculates the RUL for a single feature.\n\n    Args:\n        feature_values (list): The list of recent feature measurements.\n        delta_t (float): The sampling interval in hours.\n        threshold (float): The failure threshold for the feature.\n\n    Returns:\n        float: The calculated RUL for the feature, which can be 0, a positive\n               number, or float('inf').\n    \"\"\"\n    N = len(feature_values)\n    \n    # If there's insufficient data to fit a line, we can't make a prediction.\n    # The problem implies N >= 2, but this is a robust check.\n    if N  2:\n        return float('inf')\n\n    last_value = feature_values[-1]\n    \n    # If already at or above threshold, RUL is 0.\n    if last_value >= threshold:\n        return 0.0\n\n    time_vector = np.arange(N) * delta_t\n    \n    # Perform ordinary least squares linear regression to get slope (m) and intercept (b).\n    # np.polyfit returns [m, b] for a degree 1 polynomial.\n    m, b = np.polyfit(time_vector, feature_values, 1)\n\n    # If slope is non-positive, the feature is not degrading towards the threshold.\n    # Per the problem, its RUL contribution is infinite.\n    if m = 0:\n        return float('inf')\n\n    # Calculate the time (t_star) at which the linear model crosses the threshold.\n    # y(t) = m*t + b => t_star = (threshold - b) / m\n    t_star = (threshold - b) / m\n    \n    # RUL is the time from the last measurement to the crossing time.\n    time_of_last_measurement = time_vector[-1]\n    rul = t_star - time_of_last_measurement\n    \n    # RUL must be non-negative. If t_star is in the past, RUL is 0.\n    return max(0.0, rul)\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world degradation processes are rarely deterministic; they are subject to inherent randomness and are observed through imperfect, noisy sensors. This practice introduces a cornerstone of modern prognostics: the Kalman filter. You will model degradation as a drifted Brownian motion—a standard stochastic process—and implement the Kalman filter to track the true health state of a component, providing a robust RUL estimate that explicitly accounts for these uncertainties.",
            "id": "4240318",
            "problem": "You are tasked with formalizing a degradation-tracking digital twin model and implementing a computational routine for Remaining Useful Life (RUL) estimation in a Cyber-Physical System (CPS). The underlying degradation is modeled as a drifted Brownian motion observed through noisy measurements. Formally, the latent degradation state $x_k$ evolves in discrete time steps of size $\\Delta t$ according to a linear Gaussian state-space representation derived from a Wiener process with drift. The latent state $x_k$ is only observable through a measurement $y_k$ corrupted by additive Gaussian noise, and the initial state is uncertain.\n\nStarting from fundamental principles, construct the linear Gaussian state-space model using the following base:\n\n- The continuous-time Wiener process (Brownian motion) $W_t$ has independent increments with $W_{t+\\Delta t} - W_t \\sim \\mathcal{N}(0, \\Delta t)$.\n- A drifted Brownian degradation process $X_t$ obeys $X_{t+\\Delta t} = X_t + \\mu \\Delta t + \\sqrt{q}\\,(W_{t+\\Delta t} - W_t)$, where $\\mu$ is a deterministic drift rate (units of degradation per unit time) and $q$ is a nonnegative diffusion coefficient (units of degradation squared per unit time).\n- At discrete times indexed by $k \\in \\{1,2,\\ldots,N\\}$, we define $x_k = X_{k \\Delta t}$. Measurements obey $y_k = x_k + v_k$ where $v_k \\sim \\mathcal{N}(0, r)$ are independent and identically distributed measurement noises with variance $r$ (units of degradation squared). The initial state $x_0$ has a Gaussian prior $x_0 \\sim \\mathcal{N}(m_0, P_0)$.\n\nYour program must implement the filtering distribution computation via Kalman recursion to obtain the posterior mean $m_{N\\mid N}$ and variance $P_{N\\mid N}$ of $x_N$ given measurements $\\{y_k\\}_{k=1}^N$ for each test case. Based on the filtered posterior mean, compute the expected Remaining Useful Life (RUL) to an upper failure threshold $L$ (units of degradation) under the drifted Brownian model. You must express the expected RUL in hours. Adopt the following rules for expected RUL:\n- If $m_{N\\mid N} \\ge L$, the expected RUL is $0$ hours.\n- If $m_{N\\mid N}  L$ and $\\mu \\le 0$, the expected RUL is $+\\infty$ hours.\n- If $m_{N\\mid N}  L$ and $\\mu  0$, the expected RUL is $\\dfrac{L - m_{N\\mid N}}{\\mu}$ hours.\n\nDo not use any specialized \"shortcut\" formulas for Kalman filtering in your problem statement; you must derive and implement the recursion based on linear-Gaussian state-space principles in your solution. All mathematical symbols, variables, functions, operators, and numbers must be written in LaTeX.\n\nPhysical units: report RUL in hours. Do not use percentages. No angles are involved. The final program must output a single line containing a comma-separated list enclosed in square brackets with the expected RUL values for each test case as decimal floats. When the expected RUL is infinite, print the Python floating-point representation of $+\\infty$.\n\nImplement your program for the following test suite of parameter sets, chosen to exercise different scenarios including a typical case, already-failed detection, small positive drift, negative drift, and zero drift. Each test case specifies $(\\Delta t, \\mu, q, r, m_0, P_0, L, \\{y_k\\}_{k=1}^N)$:\n\n- Test Case A (typical positive drift):\n  - $\\Delta t = 1.0$ hours,\n  - $\\mu = 0.5$ degradation per hour,\n  - $q = 0.2$ degradation squared per hour,\n  - $r = 0.5$ degradation squared,\n  - $m_0 = 0.0$ degradation,\n  - $P_0 = 1.0$ degradation squared,\n  - $L = 10.0$ degradation,\n  - Measurements $\\{y_k\\} = [0.2, 0.7, 1.3, 2.0, 2.4, 3.1, 3.9, 4.4, 5.2, 5.7]$ (degradation units).\n- Test Case B (already failed after filtering):\n  - $\\Delta t = 1.0$ hours,\n  - $\\mu = 0.6$ degradation per hour,\n  - $q = 0.1$ degradation squared per hour,\n  - $r = 0.05$ degradation squared,\n  - $m_0 = 2.5$ degradation,\n  - $P_0 = 0.2$ degradation squared,\n  - $L = 4.0$ degradation,\n  - Measurements $\\{y_k\\} = [3.0, 3.8, 4.4]$ (degradation units).\n- Test Case C (small positive drift):\n  - $\\Delta t = 0.5$ hours,\n  - $\\mu = 0.05$ degradation per hour,\n  - $q = 0.1$ degradation squared per hour,\n  - $r = 0.1$ degradation squared,\n  - $m_0 = -0.2$ degradation,\n  - $P_0 = 0.5$ degradation squared,\n  - $L = 1.0$ degradation,\n  - Measurements $\\{y_k\\} = [-0.1, 0.0, 0.1, 0.2, 0.25]$ (degradation units).\n- Test Case D (negative drift):\n  - $\\Delta t = 1.0$ hours,\n  - $\\mu = -0.1$ degradation per hour,\n  - $q = 0.3$ degradation squared per hour,\n  - $r = 0.2$ degradation squared,\n  - $m_0 = 2.0$ degradation,\n  - $P_0 = 1.0$ degradation squared,\n  - $L = 5.0$ degradation,\n  - Measurements $\\{y_k\\} = [2.1, 2.0, 1.9, 1.8, 1.7]$ (degradation units).\n- Test Case E (zero drift):\n  - $\\Delta t = 1.0$ hours,\n  - $\\mu = 0.0$ degradation per hour,\n  - $q = 0.3$ degradation squared per hour,\n  - $r = 0.5$ degradation squared,\n  - $m_0 = 1.0$ degradation,\n  - $P_0 = 0.5$ degradation squared,\n  - $L = 3.0$ degradation,\n  - Measurements $\\{y_k\\} = [1.1, 1.2, 1.25]$ (degradation units).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$), where each $r_i$ is the expected RUL in hours for the corresponding test case computed from the filtered posterior mean $m_{N\\mid N}$ and the above rules.",
            "solution": "The problem requires the formulation of a linear Gaussian state-space model for a degradation process and the implementation of a Kalman filter to estimate the system's state and subsequently its Remaining Useful Life (RUL). The solution is presented in three stages: first, the derivation of the discrete-time state-space model from the given continuous-time process; second, the step-by-step derivation of the Kalman filter recursion from fundamental principles; and third, the application of the RUL estimation rule.\n\n**1. State-Space Model Formulation**\n\nThe degradation process is described by a drifted Brownian motion in continuous time $t$. The latent degradation state $X_t$ evolves according to:\n$$X_{t+\\Delta t} = X_t + \\mu \\Delta t + \\sqrt{q}\\,(W_{t+\\Delta t} - W_t)$$\nwhere $\\mu$ is the drift rate, $q$ is the diffusion coefficient, and $W_t$ is a standard Wiener process whose increments are Gaussian: $W_{t+\\Delta t} - W_t \\sim \\mathcal{N}(0, \\Delta t)$.\n\nWe discretize this process by considering time points $t_k = k \\Delta t$ for $k \\in \\{0, 1, 2, \\ldots\\}$. Let the discrete-time state be $x_k = X_{t_k}$. The state evolution equation can be written as:\n$$x_k = x_{k-1} + \\mu \\Delta t + \\sqrt{q}\\,(W_{k\\Delta t} - W_{(k-1)\\Delta t})$$\nLet us define a process noise term $w_{k-1} = \\sqrt{q}\\,(W_{k\\Delta t} - W_{(k-1)\\Delta t})$. Since the Wiener increment is a random variable with mean $0$ and variance $\\Delta t$, the process noise $w_{k-1}$ is also a Gaussian random variable. Its mean is $E[w_{k-1}] = \\sqrt{q} E[W_{k\\Delta t} - W_{(k-1)\\Delta t}] = 0$. Its variance, which we denote as $Q$, is $\\text{Var}(w_{k-1}) = E[w_{k-1}^2] = q \\cdot E[(W_{k\\Delta t} - W_{(k-1)\\Delta t})^2] = q \\Delta t$. Thus, $w_{k-1} \\sim \\mathcal{N}(0, Q)$, where $Q = q \\Delta t$.\n\nThe state transition equation is therefore:\n$$x_k = x_{k-1} + \\mu \\Delta t + w_{k-1}$$\nThis equation is in the standard linear state-space form $x_k = A x_{k-1} + B u_{k-1} + w_{k-1}$. For this scalar system, the state transition matrix is $A=1$. The term $\\mu \\Delta t$ is a deterministic drift, which can be modeled as a control input $u_{k-1} = \\mu \\Delta t$ with a corresponding control matrix $B=1$.\n\nThe measurement model is given as $y_k = x_k + v_k$, where the measurement noise $v_k$ is drawn from a Gaussian distribution, $v_k \\sim \\mathcal{N}(0, r)$. This directly corresponds to the standard measurement equation $y_k = H x_k + v_k$. For this scalar system, the observation matrix is $H=1$, and the measurement noise variance is $R=r$.\n\nIn summary, the linear Gaussian state-space model is defined by:\n- State equation: $x_k = 1 \\cdot x_{k-1} + 1 \\cdot (\\mu \\Delta t) + w_{k-1}$, with $w_{k-1} \\sim \\mathcal{N}(0, q \\Delta t)$\n- Measurement equation: $y_k = 1 \\cdot x_k + v_k$, with $v_k \\sim \\mathcal{N}(0, r)$\n- Initial condition: $p(x_0) = \\mathcal{N}(x_0; m_0, P_0)$\n\n**2. Kalman Filter Recursion**\n\nThe Kalman filter provides an optimal recursive algorithm for estimating the state $x_k$ given all measurements up to time $k$, denoted by $y_{1:k} = \\{y_1, y_2, \\ldots, y_k\\}$. The filter computes the posterior probability distribution $p(x_k | y_{1:k})$, which for a linear Gaussian model is itself Gaussian: $p(x_k | y_{1:k}) = \\mathcal{N}(x_k; m_{k|k}, P_{k|k})$. The recursion proceeds in two steps for each time increment: prediction and update.\n\nWe start with the filtered estimate from the previous step, $p(x_{k-1} | y_{1:k-1}) = \\mathcal{N}(x_{k-1}; m_{k-1|k-1}, P_{k-1|k-1})$. The initial state is $m_{0|0} = m_0$ and $P_{0|0} = P_0$.\n\n**Prediction Step (Time Update):**\nThis step predicts the state at time $k$ using the model, before accounting for the new measurement $y_k$. We compute the predictive distribution $p(x_k | y_{1:k-1}) = \\mathcal{N}(x_k; m_{k|k-1}, P_{k|k-1})$.\nThe predicted mean $m_{k|k-1}$ is the expectation of the state $x_k$ conditioned on previous data:\n$$m_{k|k-1} = E[x_k | y_{1:k-1}] = E[A x_{k-1} + B u_{k-1} + w_{k-1} | y_{1:k-1}]$$\n$$m_{k|k-1} = A E[x_{k-1} | y_{1:k-1}] + B u_{k-1} = A m_{k-1|k-1} + B u_{k-1}$$\nThe predicted covariance $P_{k|k-1}$ is the variance of this prediction:\n$$P_{k|k-1} = \\text{Var}(x_k | y_{1:k-1}) = \\text{Var}(A x_{k-1} + w_{k-1} | y_{1:k-1})$$\n$$P_{k|k-1} = A \\text{Var}(x_{k-1} | y_{1:k-1}) A^T + \\text{Var}(w_{k-1}) = A P_{k-1|k-1} A^T + Q$$\n\nFor our specific scalar model, with $A=1$, $B=1$, $u_{k-1} = \\mu \\Delta t$, and $Q = q \\Delta t$:\n$$m_{k|k-1} = m_{k-1|k-1} + \\mu \\Delta t$$\n$$P_{k|k-1} = P_{k-1|k-1} + q \\Delta t$$\n\n**Update Step (Measurement Update):**\nThis step updates the predicted state and covariance using the new measurement $y_k$. We combine the predictive distribution (our prior for this step) with the likelihood of the measurement $p(y_k | x_k) = \\mathcal{N}(y_k; H x_k, R)$ via Bayes' rule to obtain the posterior $p(x_k | y_{1:k}) = \\mathcal{N}(x_k; m_{k|k}, P_{k|k})$. The update equations are:\n\n1.  Innovation (or measurement residual): $\\tilde{y}_k = y_k - E[y_k | y_{1:k-1}] = y_k - H m_{k|k-1}$. This is the difference between the actual measurement and its prediction.\n2.  Innovation covariance: $S_k = \\text{Var}(\\tilde{y}_k) = H P_{k|k-1} H^T + R$. This represents the uncertainty in the innovation.\n3.  Kalman gain: $K_k = P_{k|k-1} H^T S_k^{-1}$. The gain determines how much the prediction is corrected by the innovation. A high gain weights the measurement more, while a low gain weights the prediction more.\n4.  Updated mean: $m_{k|k} = m_{k|k-1} + K_k \\tilde{y}_k$. The predicted mean is adjusted by the weighted innovation.\n5.  Updated covariance: $P_{k|k} = (I - K_k H) P_{k|k-1}$. The prediction uncertainty is reduced by the information gained from the measurement.\n\nFor our scalar model with $H=1$ and $R=r$:\n$$\\tilde{y}_k = y_k - m_{k|k-1}$$\n$$S_k = P_{k|k-1} + r$$\n$$K_k = P_{k|k-1} (S_k)^{-1} = \\frac{P_{k|k-1}}{P_{k|k-1} + r}$$\n$$m_{k|k} = m_{k|k-1} + K_k (y_k - m_{k|k-1})$$\n$$P_{k|k} = (1 - K_k) P_{k|k-1}$$\n\nThis recursion is performed for $k=1, \\ldots, N$, yielding the final filtered estimate $(m_{N|N}, P_{N|N})$.\n\n**3. RUL Estimation**\n\nThe expected RUL is calculated from the final filtered state mean, $m_{N|N}$, which is our best estimate of the current degradation level. The future expected degradation path is assumed to follow the drift $\\mu$. The time to reach the failure threshold $L$ from the current state is calculated based on the following rules:\n\n- If $m_{N|N} \\ge L$: The estimated degradation has already reached or exceeded the failure threshold. The expected RUL is $0$ hours.\n- If $m_{N|N}  L$ and $\\mu \\le 0$: The degradation is not expected to increase (it may decrease or stay constant on average). Therefore, the threshold $L$ is not expected to be reached. The expected RUL is considered infinite, $+\\infty$ hours.\n- If $m_{N|N}  L$ and $\\mu  0$: The degradation is expected to increase at a rate of $\\mu$ units per hour. The remaining amount of degradation until failure is $\\Delta_L = L - m_{N|N}$. The expected time to cover this amount is:\n$$ \\text{RUL} = \\frac{\\Delta_L}{\\mu} = \\frac{L - m_{N|N}}{\\mu} \\text{ hours} $$\n\nThe implementation will apply these state-space, Kalman filter, and RUL equations to each test case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Remaining Useful Life (RUL) estimation problem for a series of test cases.\n    \"\"\"\n\n    # Each test case is a dictionary specifying the parameters for the degradation model and Kalman filter.\n    # The format is: (delta_t, mu, q, r, m0, P0, L, measurements) in SI-like units.\n    test_cases = [\n        # Test Case A (typical positive drift)\n        {\n            \"delta_t\": 1.0,  # hours\n            \"mu\": 0.5,      # degradation per hour\n            \"q\": 0.2,       # degradation^2 per hour\n            \"r\": 0.5,       # degradation^2\n            \"m0\": 0.0,      # degradation\n            \"P0\": 1.0,      # degradation^2\n            \"L\": 10.0,      # degradation\n            \"y\": [0.2, 0.7, 1.3, 2.0, 2.4, 3.1, 3.9, 4.4, 5.2, 5.7]  # degradation\n        },\n        # Test Case B (already failed after filtering)\n        {\n            \"delta_t\": 1.0,\n            \"mu\": 0.6,\n            \"q\": 0.1,\n            \"r\": 0.05,\n            \"m0\": 2.5,\n            \"P0\": 0.2,\n            \"L\": 4.0,\n            \"y\": [3.0, 3.8, 4.4]\n        },\n        # Test Case C (small positive drift)\n        {\n            \"delta_t\": 0.5,\n            \"mu\": 0.05,\n            \"q\": 0.1,\n            \"r\": 0.1,\n            \"m0\": -0.2,\n            \"P0\": 0.5,\n            \"L\": 1.0,\n            \"y\": [-0.1, 0.0, 0.1, 0.2, 0.25]\n        },\n        # Test Case D (negative drift)\n        {\n            \"delta_t\": 1.0,\n            \"mu\": -0.1,\n            \"q\": 0.3,\n            \"r\": 0.2,\n            \"m0\": 2.0,\n            \"P0\": 1.0,\n            \"L\": 5.0,\n            \"y\": [2.1, 2.0, 1.9, 1.8, 1.7]\n        },\n        # Test Case E (zero drift)\n        {\n            \"delta_t\": 1.0,\n            \"mu\": 0.0,\n            \"q\": 0.3,\n            \"r\": 0.5,\n            \"m0\": 1.0,\n            \"P0\": 0.5,\n            \"L\": 3.0,\n            \"y\": [1.1, 1.2, 1.25]\n        },\n    ]\n\n    results = []\n    for params in test_cases:\n        rul = calculate_rul_with_kalman_filter(params)\n        results.append(rul)\n\n    # Format the final output as a comma-separated list in brackets.\n    # The map(str, ...) ensures that infinity is printed as 'inf'.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef calculate_rul_with_kalman_filter(params):\n    \"\"\"\n    Computes the filtered state and RUL for a single degradation process.\n\n    Args:\n        params (dict): A dictionary containing all model parameters.\n\n    Returns:\n        float: The estimated Remaining Useful Life in hours.\n    \"\"\"\n    # Extract parameters for clarity\n    delta_t = params[\"delta_t\"]\n    mu = params[\"mu\"]\n    q = params[\"q\"]\n    r = params[\"r\"]\n    m_current = params[\"m0\"]\n    P_current = params[\"P0\"]\n    L = params[\"L\"]\n    measurements = params[\"y\"]\n\n    # --- State-Space Model Parameters for the scalar case ---\n    # According to the derivation: x_k = A*x_{k-1} + B*u_{k-1} + w_{k-1}\n    # A = 1 (State transition matrix)\n    # B = 1 (Control input matrix)\n    # u = mu * delta_t (Control input, deterministic drift part)\n    # Q = q * delta_t (Process noise variance)\n    # According to the derivation: y_k = H*x_k + v_k\n    # H = 1 (Observation matrix)\n    # R = r (Measurement noise variance)\n    u_input = mu * delta_t\n    Q_noise_var = q * delta_t\n\n    # --- Kalman Filter Recursion ---\n    for y_k in measurements:\n        # 1. Prediction (Time Update)\n        m_predicted = m_current + u_input\n        P_predicted = P_current + Q_noise_var\n\n        # 2. Update (Measurement Update)\n        # Innovation (residual)\n        y_tilde = y_k - m_predicted\n        # Innovation covariance\n        S = P_predicted + r\n        # Kalman gain\n        K = P_predicted / S\n        # Updated state mean\n        m_current = m_predicted + K * y_tilde\n        # Updated state covariance\n        P_current = (1 - K) * P_predicted\n    \n    # Final filtered mean is m_current, which is m_{N|N}\n    m_N_N = m_current\n\n    # --- RUL Calculation ---\n    if m_N_N >= L:\n        # Already failed\n        return 0.0\n    elif m_N_N  L and mu = 0:\n        # Degradation is not expected to increase, will not reach threshold\n        return float('inf')\n    else:  # m_N_N  L and mu > 0\n        # Expected time to reach threshold L with positive drift mu\n        return (L - m_N_N) / mu\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Creating a prognostic model is only half the battle; we must also rigorously evaluate its performance to trust its predictions for making critical decisions. This exercise focuses on the essential task of scoring RUL predictions against ground-truth data. You will derive and implement two key types of metrics from first principles: an accuracy metric based on the average Euclidean error, and a timeliness metric that captures the asymmetric costs of predicting failure too early versus too late.",
            "id": "4240256",
            "problem": "A digital twin for a cyber-physical asset streams a discrete-time sequence of Remaining Useful Life (RUL) predictions. Let the ground-truth RUL at discrete instants indexed by $k \\in \\{0,1,\\dots, K-1\\}$ be denoted by $r_k$ (in $\\mathrm{h}$), and the digital twin prediction by $\\hat{r}_k$ (in $\\mathrm{h}$). Define the prediction error as $e_k = \\hat{r}_k - r_k$ (in $\\mathrm{h}$). The goal is to compute two performance metrics and an operational decision flag, purely from first principles, using only foundational constructs of empirical risk and cost-sensitive decision making:\n- The first metric should be derived by starting from the Euclidean norm in $\\mathbb{R}^K$ and the principle of averaging over $K$ samples to quantify the typical magnitude of error in hours.\n- The second metric should be derived by starting from a per-step cost with the following axioms: zero penalty at zero error, monotonicity in the magnitude of error, convexity, positive homogeneity, translation invariance of increments, and asymmetric unit costs for overestimation and underestimation. Overestimation (predicting larger RUL than reality, $e_k  0$) should incur a per-hour unit cost $c_{+}$ (in $\\mathrm{CU}/\\mathrm{h}$), and underestimation (predicting smaller RUL than reality, $e_k  0$) should incur a per-hour unit cost $c_{-}$ (in $\\mathrm{CU}/\\mathrm{h}$), with $c_{+}$ and $c_{-}$ given. Aggregate this per-step penalty across time by the empirical mean to obtain a timeliness metric in cost units (in $\\mathrm{CU}$).\n- The operational decision flag is defined for given procurement lead time $L$ (in $\\mathrm{h}$) and a planning buffer $B$ (in $\\mathrm{h}$). A maintenance order is placed at the first index $k$ such that $\\hat{r}_k \\le L + B$. Declare scheduling success if there exists any such index $k$ with $r_k \\ge L$; otherwise declare failure. This encodes the rule: the system should trigger when the predicted RUL falls to at most $L + B$, but the true RUL at that trigger must be at least $L$ to allow the order to arrive before failure.\n\nYou must:\n- Derive both metrics from the above bases without appealing to any pre-given shortcut formulas, and implement them.\n- For each test case, compute:\n  $1)$ the first metric in $\\mathrm{h}$,\n  $2)$ the second metric in $\\mathrm{CU}$,\n  $3)$ the scheduling success boolean.\n\nExpress all RUL quantities in $\\mathrm{h}$ and costs in $\\mathrm{CU}$, and round all floating-point outputs to $4$ decimal places.\n\nTest suite:\n- Test case $1$:\n  - $r_k$ in $\\mathrm{h}$: $\\{50, 40, 30, 20, 10, 0\\}$\n  - $\\hat{r}_k$ in $\\mathrm{h}$: $\\{52, 41, 28, 18, 9, 0\\}$\n  - $c_{+} = 2$ (in $\\mathrm{CU}/\\mathrm{h}$), $c_{-} = 1$ (in $\\mathrm{CU}/\\mathrm{h}$)\n  - $L = 12$ (in $\\mathrm{h}$), $B = 4$ (in $\\mathrm{h}$)\n- Test case $2$:\n  - $r_k$ in $\\mathrm{h}$: $\\{40, 30, 20, 10, 0\\}$\n  - $\\hat{r}_k$ in $\\mathrm{h}$: $\\{35, 25, 15, 5, 0\\}$\n  - $c_{+} = 2$ (in $\\mathrm{CU}/\\mathrm{h}$), $c_{-} = 1$ (in $\\mathrm{CU}/\\mathrm{h}$)\n  - $L = 10$ (in $\\mathrm{h}$), $B = 2$ (in $\\mathrm{h}$)\n- Test case $3$:\n  - $r_k$ in $\\mathrm{h}$: $\\{12, 8, 4, 0\\}$\n  - $\\hat{r}_k$ in $\\mathrm{h}$: $\\{12, 8, 4, 0\\}$\n  - $c_{+} = 3$ (in $\\mathrm{CU}/\\mathrm{h}$), $c_{-} = 1$ (in $\\mathrm{CU}/\\mathrm{h}$)\n  - $L = 6$ (in $\\mathrm{h}$), $B = 0$ (in $\\mathrm{h}$)\n- Test case $4$:\n  - $r_k$ in $\\mathrm{h}$: $\\{24, 16, 8, 0\\}$\n  - $\\hat{r}_k$ in $\\mathrm{h}$: $\\{34, 22, 10, 0\\}$\n  - $c_{+} = 3$ (in $\\mathrm{CU}/\\mathrm{h}$), $c_{-} = 0.5$ (in $\\mathrm{CU}/\\mathrm{h}$)\n  - $L = 8$ (in $\\mathrm{h}$), $B = 4$ (in $\\mathrm{h}$)\n\nFinal output format:\nYour program should produce a single line of output containing a list of per-test-case triplets in the form\n$[ [m_1, t_1, s_1], [m_2, t_2, s_2], \\dots ]$\nwhere $m_i$ is the first metric in $\\mathrm{h}$ (rounded to $4$ decimals), $t_i$ is the timeliness metric in $\\mathrm{CU}$ (rounded to $4$ decimals), and $s_i$ is the boolean scheduling success for test case $i$. The printed list must contain no spaces, and numbers must be rendered in standard decimal notation as floats or integers as appropriate, with the specified rounding. For example: $[[m_1,t_1,s_1],[m_2,t_2,s_2],\\dots]$.",
            "solution": "The problem requires the derivation and computation of two performance metrics and one operational decision flag from first principles.\n\n**Metric 1: Error Magnitude Metric (Root Mean Square Error)**\n\nThe goal is to quantify the typical magnitude of the prediction error, $e_k = \\hat{r}_k - r_k$, in hours. The derivation starts from the concept of the Euclidean norm for the error vector $\\mathbf{e} = [e_0, e_1, \\dots, e_{K-1}]^T$ in $\\mathbb{R}^K$.\n\n1.  The squared Euclidean norm, $\\|\\mathbf{e}\\|_2^2 = \\sum_{k=0}^{K-1} e_k^2$, gives the total squared error.\n2.  To find a \"typical\" or average value over the $K$ samples, we compute the mean of the squared errors: $\\frac{1}{K} \\sum_{k=0}^{K-1} e_k^2$. This is the Mean Squared Error (MSE), which has units of hours squared.\n3.  To return to the original units of hours, we take the square root of the MSE.\n\nThis yields the Root Mean Square Error (RMSE), which we denote as $m_1$:\n$$ m_1 = \\sqrt{\\frac{1}{K} \\sum_{k=0}^{K-1} (\\hat{r}_k - r_k)^2} $$\n\n**Metric 2: Timeliness Metric (Asymmetric Cost)**\n\nThis metric is derived from an asymmetric, per-step cost function, $C(e_k)$, which is then averaged over all time steps. The axioms lead to a linear penalty that depends on the sign of the error.\n\n1.  For overestimation ($e_k > 0$), the penalty is proportional to the error magnitude, with a cost of $c_{+}$ per hour: $c_{+} \\cdot e_k$. This penalizes being overly optimistic, which can lead to unexpected failures.\n2.  For underestimation ($e_k  0$), the penalty is proportional to the error magnitude $|e_k| = -e_k$, with a cost of $c_{-}$ per hour: $c_{-} \\cdot (-e_k)$. This penalizes being overly pessimistic, which can lead to premature maintenance and unnecessary costs.\n3.  For zero error ($e_k = 0$), the cost is zero.\n\nThe per-step cost function can be written as:\n$$ C(e_k) = \\begin{cases} c_{+} \\cdot e_k  \\text{if } e_k > 0 \\\\ c_{-} \\cdot (-e_k)  \\text{if } e_k  0 \\\\ 0  \\text{if } e_k = 0 \\end{cases} $$\nThe total timeliness metric, $t_1$, is the empirical mean of this cost across all $K$ samples:\n$$ t_1 = \\frac{1}{K} \\sum_{k=0}^{K-1} C(e_k) = \\frac{1}{K} \\sum_{k=0}^{K-1} \\left[ c_{+} \\max(0, \\hat{r}_k - r_k) + c_{-} \\max(0, r_k - \\hat{r}_k) \\right] $$\nThis metric is in units of Cost Units (CU).\n\n**Operational Decision Flag**\n\nThis flag, $s_1$, evaluates the practical success of the prognostic model in a scheduling context.\n\n1.  A maintenance order is triggered at the first time index $k^*$ where the prediction $\\hat{r}_{k^*}$ falls below a defined threshold, $T = L + B$. $L$ is the lead time for parts/personnel, and $B$ is a safety buffer.\n    $$ k^* = \\min \\{k \\mid \\hat{r}_k \\le L + B \\} $$\n2.  If no such trigger occurs within the observation window, the maintenance is never scheduled, which is considered a scheduling failure ($s_1 = \\text{False}$).\n3.  If a trigger occurs at $k^*$, the scheduling is considered a success ($s_1 = \\text{True}$) if and only if the ground-truth RUL at that moment, $r_{k^*}$, is at least as long as the lead time $L$. This ensures that the component will not fail before maintenance can be performed. The condition is:\n    $$ r_{k^*} \\ge L $$\nIf this condition is not met, the maintenance call was made too late, resulting in scheduling failure ($s_1 = \\text{False}$).",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the RUL performance evaluation problem for a given set of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"r\": np.array([50, 40, 30, 20, 10, 0]),\n            \"r_hat\": np.array([52, 41, 28, 18, 9, 0]),\n            \"c_plus\": 2.0,\n            \"c_minus\": 1.0,\n            \"L\": 12.0,\n            \"B\": 4.0,\n        },\n        {\n            \"r\": np.array([40, 30, 20, 10, 0]),\n            \"r_hat\": np.array([35, 25, 15, 5, 0]),\n            \"c_plus\": 2.0,\n            \"c_minus\": 1.0,\n            \"L\": 10.0,\n            \"B\": 2.0,\n        },\n        {\n            \"r\": np.array([12, 8, 4, 0]),\n            \"r_hat\": np.array([12, 8, 4, 0]),\n            \"c_plus\": 3.0,\n            \"c_minus\": 1.0,\n            \"L\": 6.0,\n            \"B\": 0.0,\n        },\n        {\n            \"r\": np.array([24, 16, 8, 0]),\n            \"r_hat\": np.array([34, 22, 10, 0]),\n            \"c_plus\": 3.0,\n            \"c_minus\": 0.5,\n            \"L\": 8.0,\n            \"B\": 4.0,\n        },\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        r = case[\"r\"]\n        r_hat = case[\"r_hat\"]\n        c_plus = case[\"c_plus\"]\n        c_minus = case[\"c_minus\"]\n        L = case[\"L\"]\n        B = case[\"B\"]\n        \n        # Calculate error vector\n        e = r_hat - r\n        \n        # Metric 1: Root Mean Square Error (RMSE)\n        # m1 = sqrt( (1/K) * sum(e_k^2) )\n        m1 = np.sqrt(np.mean(e**2))\n        \n        # Metric 2: Timeliness Metric (Asymmetric Cost)\n        # t1 = (1/K) * sum( C(e_k) )\n        # C(e_k) = c_plus * max(0, e_k) + c_minus * max(0, -e_k)\n        overestimation_cost = c_plus * np.maximum(0, e)\n        underestimation_cost = c_minus * np.maximum(0, -e)\n        t1 = np.mean(overestimation_cost + underestimation_cost)\n        \n        # Operational Decision Flag\n        # s1 = success/failure boolean\n        trigger_threshold = L + B\n        trigger_indices = np.where(r_hat = trigger_threshold)[0]\n        \n        s1 = False # Default to failure\n        if trigger_indices.size > 0:\n            first_trigger_index = trigger_indices[0]\n            true_rul_at_trigger = r[first_trigger_index]\n            if true_rul_at_trigger >= L:\n                s1 = True\n\n        # Round floats to 4 decimal places for the result list\n        m1_rounded = round(m1, 4)\n        t1_rounded = round(t1, 4)\n        \n        all_results.append([m1_rounded, t1_rounded, s1])\n        \n    # Format the final output string to remove spaces\n    # Example: '[[1.5275, 1.8333, False], ...]' becomes '[[1.5275,1.8333,False],...]'\n    output_string = str(all_results).replace(\" \", \"\")\n    print(output_string)\n\nsolve()\n```"
        }
    ]
}