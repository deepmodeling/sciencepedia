{
    "hands_on_practices": [
        {
            "introduction": "对于复杂的物理系统，数字孪生必须具备高效的计算能力才能实现实时应用。本次实践介绍一种强大的数据驱动技术——本征正交分解（Proper Orthogonal Decomposition, POD），用于创建能捕捉高保真系统核心动态的降阶模型（Reduced-Order Models, ROMs）。通过本练习，您将学习构建数据驱动ROM的完整流程，从生成仿真数据到将系统动力学投影到低维基上，这是构建实用数字孪生的一项基本技能。",
            "id": "4215940",
            "problem": "您正在为一个线性时不变 (LTI) 系统设计一个用于性能监测的数据驱动降阶数字孪生。该系统在已知激励下生成状态快照。请基于线性代数和动力系统的基本原理，实现本征正交分解 (POD)，并推导截断基误差界，以保证在指定的能量捕获阈值下快照的重构质量。\n\n给定一个连续时间 LTI 状态空间模型，其状态向量维度为 $n$，输入维度为 $1$，输出维度为 $2$：\n$$\n\\dot{x}(t) = A x(t) + B u(t), \\quad y(t) = C x(t),\n$$\n其数值数据如下：\n$$\nA = \\begin{bmatrix}\n-0.8  0.2  0.0  0.0  0.0\\\\\n-0.1  -1.0  0.3  0.0  0.0\\\\\n0.0  -0.2  -1.2  0.4  0.0\\\\\n0.0  0.0  -0.3  -1.5  0.5\\\\\n0.0  0.0  0.0  -0.4  -1.8\n\\end{bmatrix}, \\quad\nB = \\begin{bmatrix}\n1.0\\\\\n0.5\\\\\n0.2\\\\\n0.1\\\\\n0.05\n\\end{bmatrix}, \\quad\nC = \\begin{bmatrix}\n1.0  0.0  0.0  0.0  0.0\\\\\n0.0  0.0  1.0  0.0  0.0\n\\end{bmatrix}.\n$$\n设状态维度 $n=5$。使用步长为 $\\Delta t = 0.05$ 的离散时间前向 Euler 积分器，从初始条件\n$$\nx(0) = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\n$$\n在确定性输入序列\n$$\nu_k = \\sin(0.15 k) + 0.5 \\sin(0.03 k), \\quad k = 0,1,\\dots,m-1,\n$$\n下生成 $m=200$ 个快照，其中 $x_{k+1} = x_k + \\Delta t \\left( A x_k + B u_k \\right)$，每个快照列为 $x_k$。构建快照矩阵 $X \\in \\mathbb{R}^{n \\times m}$，其第 $k$ 列为 $x_k$。\n\n需要执行的任务：\n\n1) 使用标准线性代数定义计算快照矩阵 $X$ 的奇异值分解 (SVD)。根据奇异值定义 POD 能量谱，并对于每个能量捕获阈值 $\\eta \\in (0,1]$，选择最小的降阶维度 $r$，使得前 $r$ 个模态捕获的 POD 能量至少为 $\\eta$。\n\n2) 从前导左奇异向量构建 POD 降阶基 $V_r \\in \\mathbb{R}^{n \\times r}$。构建 Galerkin 降阶模型 (ROM)\n$$\n\\dot{z}(t) = A_r z(t) + B_r u(t), \\quad \\hat{x}(t) = V_r z(t), \\quad y_r(t) = C \\hat{x}(t),\n$$\n其中 $A_r = V_r^\\top A V_r$ 且 $B_r = V_r^\\top B$，并初始化 $z(0) = V_r^\\top x(0)$。使用相同的前向 Euler 方法和输入序列对 ROM 进行仿真，以在相同的时间范围内生成 $y_r$。\n\n3) 利用正交投影的基本原理和经典矩阵近似结果所蕴含的截断最优性，推导出一个关于使用 $r$ 个模态时快照重构误差的、非增的 Frobenius 范数截断基误差界。该界应完全用 $X$ 的奇异值表示，并为每个选定的 $r$ 进行数值量化。在推导过程中，请勿假设或使用任何未经证明的简化公式。\n\n4) 对于每个阈值 $\\eta$，计算：\n- 所选的降阶维度 $r$，\n- 捕获的能量分数，为一个在 $\\left[0,1\\right]$ 区间内的实数，\n- 快照重构误差 $\\|X - V_r V_r^\\top X\\|_F$，\n- 推导出的 Frobenius 范数截断基误差界的值，\n- 在所有时间步和两个输出上，$y$ 和 $y_r$ 之间的均方根误差 (RMSE)，\n- 一个布尔值，指示快照重构误差是否在微小的数值容差内小于或等于其界。\n\n所有值均为无量纲；实数以小数形式报告。\n\n测试组：\n- 使用能量捕获阈值 $\\eta \\in \\{0.5, 0.9, 0.99, 1.0\\}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果。每个元素对应一个测试用例（按上述阈值的顺序排列），并且其本身必须是遵循以下顺序的列表：\n$$\n[r,\\ \\text{captured\\_energy},\\ \\text{reconstruction\\_error\\_F},\\ \\text{bound\\_F},\\ \\text{output\\_RMSE},\\ \\text{is\\_within\\_bound}]\n$$\n例如，一个使用占位符数字的有效输出是：\n$$\n[[2,0.95,0.123,0.123,0.045,\\text{True}],[\\dots],[\\dots],[\\dots]].\n$$\n您的实现必须是完全确定性的，并且不需要任何输入。最终的打印输出必须只包含这一行。",
            "solution": "该问题提法明确，具有科学依据，并提供了进行求解所需的所有必要信息。目标是为一个给定的线性时不变 (LTI) 系统设计并分析一个基于本征正交分解 (POD) 的降阶模型 (ROM)。这涉及生成状态快照，执行奇异值分解 (SVD) 以获得 POD 基，构建一个 Galerkin 降阶模型，推导并量化重构误差界，最后评估一系列能量捕获阈值的性能。\n\n连续时间 LTI 系统由以下方程描述\n$$\n\\dot{x}(t) = A x(t) + B u(t), \\quad y(t) = C x(t)\n$$\n状态维度为 $n=5$，输入维度为 $1$，输出维度为 $p=2$。系统矩阵 $A$、$B$ 和 $C$ 均已给定。\n\n**第 1 步：快照生成**\n我们首先通过仿真全阶模型 (FOM) 生成一组状态快照。连续时间动态系统通过时间步长为 $\\Delta t = 0.05$ 的前向 Euler 方法进行离散化。离散时间的状态更新方程为：\n$$\nx_{k+1} = x_k + \\Delta t (A x_k + B u_k) = (I_n + \\Delta t A) x_k + (\\Delta t B) u_k\n$$\n其中 $I_n$ 是 $n \\times n$ 的单位矩阵，且 $x_k \\approx x(k \\Delta t)$。仿真从初始条件 $x_0 = \\mathbf{0}$ 开始，运行 $m=200$ 步，从 $k=0$ 到 $k=199$。每一步的输入由 $u_k = \\sin(0.15 k) + 0.5 \\sin(0.03 k)$ 给出。生成的状态 $\\{x_0, x_1, \\dots, x_{m-1}\\}$ 被组装成快照矩阵 $X \\in \\mathbb{R}^{n \\times m}$ 的列：\n$$\nX = [x_0 | x_1 | \\dots | x_{m-1}]\n$$\n同时，计算并存储全阶输出序列 $y_k = C x_k$，以供后续与 ROM 输出进行比较。\n\n**第 2 步：本征正交分解 (POD)**\nPOD 提供了一种寻找最优低维基来表示快照数据的方法。这是通过计算快照矩阵 $X$ 的奇异值分解 (SVD) 来实现的：\n$$\nX = U \\Sigma V^T\n$$\n这里，$U \\in \\mathbb{R}^{n \\times n}$ 是左奇异向量（POD 模态）矩阵，$\\Sigma \\in \\mathbb{R}^{n \\times m}$ 是一个包含奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_{\\min(n,m)} \\ge 0$ 的矩形对角矩阵，$V \\in \\mathbb{R}^{m \\times m}$ 是右奇异向量矩阵。$U$ 的列，记为 $u_i$，构成了 $\\mathbb{R}^n$ 的一个标准正交基。\n\n快照的“能量”是根据奇异值定义的。总能量是 $X$ 的 Frobenius 范数的平方，它等于奇异值的平方和：\n$$\nE_{\\text{total}} = \\|X\\|_F^2 = \\sum_{i=1}^{\\min(n,m)} \\sigma_i^2\n$$\n对于给定的能量捕获阈值 $\\eta \\in (0, 1]$，我们选择最小的模态数 $r$，使得前 $r$ 个模态捕获的能量至少是总能量的 $\\eta$ 倍：\n$$\nr = \\min \\left\\{ k \\in \\mathbb{N} \\;\\middle|\\; \\frac{\\sum_{i=1}^{k} \\sigma_i^2}{\\sum_{i=1}^{\\min(n,m)} \\sigma_i^2} \\ge \\eta \\right\\}\n$$\n\n**第 3 步：Galerkin 降阶模型构建与仿真**\n通过选取前 $r$ 个 POD 模态（左奇异向量）来构建降阶基。根据问题的符号表示，我们将这个基矩阵记为 $V_r \\in \\mathbb{R}^{n \\times r}$：\n$$\nV_r = [u_1 | u_2 | \\dots | u_r]\n$$\nFOM 的状态向量 $x(t)$ 通过这些基向量的线性组合来近似：$\\hat{x}(t) = V_r z(t)$，其中 $z(t) \\in \\mathbb{R}^r$ 是降阶坐标向量。\n\n使用 Galerkin 投影来推导 ROM 的动态方程。我们将近似值 $\\hat{x}(t)$ 代入原始状态空间方程，并将结果投影到由 $V_r$ 的列所张成的子空间上：\n$$\nV_r^\\top (\\frac{d}{dt} (V_r z(t))) = V_r^\\top (A (V_r z(t)) + B u(t))\n$$\n由于基向量是常数，并利用正交性 $V_r^\\top V_r = I_r$（$r \\times r$ 单位矩阵），我们得到降阶动态方程：\n$$\n\\dot{z}(t) = A_r z(t) + B_r u(t)\n$$\n其中降阶系统矩阵为 $A_r = V_r^\\top A V_r \\in \\mathbb{R}^{r \\times r}$ 和 $B_r = V_r^\\top B \\in \\mathbb{R}^{r \\times 1}$。降阶输出由 $y_r(t) = C \\hat{x}(t) = C V_r z(t)$ 给出。\n\n这个连续时间 ROM 使用相同的步长为 $\\Delta t$ 的前向 Euler 格式进行仿真：\n$$\nz_{k+1} = z_k + \\Delta t (A_r z_k + B_r u_k)\n$$\n降阶状态的初始条件是 FOM 初始条件的投影：$z_0 = V_r^\\top x_0$。由于 $x_0 = \\mathbf{0}$，我们有 $z_0 = \\mathbf{0}$。每一步的降阶输出为 $y_{r,k} = (C V_r) z_k$。\n\n**第 4 步：截断基误差界的推导**\n问题要求推导快照重构误差 $\\|X - V_r V_r^\\top X\\|_F$ 的界。这个量表示将原始快照投影到 $r$ 维 POD 子空间上所产生的误差。矩阵 $V_r V_r^\\top$ 是到由前 $r$ 个 POD 模态张成的子空间上的正交投影算子。\n\n设 $X$ 的 SVD 为 $X = U \\Sigma V^T = \\sum_{i=1}^{\\min(n,m)} \\sigma_i u_i v_i^T$。基 $V_r$ 由 $U$ 的前 $r$ 列组成，所以 $V_r = U_r = [u_1, \\dots, u_r]$。$X$ 的投影为：\n$$\nV_r V_r^\\top X = (U_r U_r^\\top) X = \\left(\\sum_{i=1}^r u_i u_i^T\\right) \\left(\\sum_{j=1}^{\\min(n,m)} \\sigma_j u_j v_j^T\\right)\n$$\n由于基向量的正交性（$u_i^\\top u_j = \\delta_{ij}$），乘积简化为：\n$$\nV_r V_r^\\top X = \\sum_{i=1}^r \\sum_{j=1}^{\\min(n,m)} \\sigma_j (u_i u_i^T u_j) v_j^T = \\sum_{i=1}^r \\sigma_i u_i v_i^T\n$$\n这个投影矩阵 $V_r V_r^\\top X$ 是 $X$ 在 Frobenius 范数意义下、位于 $V_r$ 列空间中的最佳逼近。重构误差矩阵为：\n$$\nE_{\\text{recon}} = X - V_r V_r^\\top X = \\sum_{i=1}^{\\min(n,m)} \\sigma_i u_i v_i^T - \\sum_{i=1}^r \\sigma_i u_i v_i^T = \\sum_{i=r+1}^{\\min(n,m)} \\sigma_i u_i v_i^T\n$$\n一个矩阵的 Frobenius 范数是其奇异值平方和的平方根。矩阵 $E_{\\text{recon}}$ 的奇异值为 $\\{\\sigma_{r+1}, \\sigma_{r+2}, \\dots, \\sigma_{\\min(n,m)}\\}$。因此，其 Frobenius 范数的平方是：\n$$\n\\|E_{\\text{recon}}\\|_F^2 = \\|X - V_r V_r^\\top X\\|_F^2 = \\sum_{i=r+1}^{\\min(n,m)} \\sigma_i^2\n$$\n重构误差恰好由该表达式给出。这是 Eckart-Young-Mirsky 定理的直接推论，该定理指出 $\\sum_{i=1}^r \\sigma_i u_i v_i^T$ 是 $X$ 的最佳秩-$r$ 逼近。因此，值\n$$\n\\text{Bound}_F = \\sqrt{\\sum_{i=r+1}^{\\min(n,m)} \\sigma_i^2}\n$$\n是误差的精确表达式，而不仅仅是一个上界。该值随 $r$ 的增加而非增，符合要求。我们将计算实际的重构误差 $\\|X - V_r V_r^\\top X\\|_F$ 和这个理论值，在数值精度范围内它们应该是相等的。\n\n**第 5 步：数值评估**\n对于每个能量阈值 $\\eta \\in \\{0.5, 0.9, 0.99, 1.0\\}$，我们计算以下指标：\n1.  降阶维度 $r$。\n2.  实际捕获的能量分数：$(\\sum_{i=1}^{r} \\sigma_i^2) / (\\sum_{i=1}^{\\min(n,m)} \\sigma_i^2)$。\n3.  快照重构误差：$\\|X - V_r V_r^\\top X\\|_F$。\n4.  推导的误差界值：$\\sqrt{\\sum_{i=r+1}^{\\min(n,m)} \\sigma_i^2}$。\n5.  全阶模型输出 $Y=[y_0, \\dots, y_{m-1}]$ 与降阶模型输出 $Y_r=[y_{r,0}, \\dots, y_{r,m-1}]$ 之间的均方根误差 (RMSE)，定义为 $\\text{RMSE} = \\sqrt{\\frac{1}{m \\cdot p} \\|Y - Y_r\\|_F^2}$。\n6.  一个布尔值检查，验证计算出的重构误差是否小于或等于计算出的界。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are permitted.\n\ndef solve():\n    \"\"\"\n    Implements and evaluates a POD-based reduced-order model for a given LTI system.\n    \"\"\"\n    #\n    # Step 0: Define the LTI system and simulation parameters\n    #\n    A = np.array([\n        [-0.8, 0.2, 0.0, 0.0, 0.0],\n        [-0.1, -1.0, 0.3, 0.0, 0.0],\n        [0.0, -0.2, -1.2, 0.4, 0.0],\n        [0.0, 0.0, -0.3, -1.5, 0.5],\n        [0.0, 0.0, 0.0, -0.4, -1.8]\n    ])\n    B = np.array([[1.0], [0.5], [0.2], [0.1], [0.05]])\n    C = np.array([\n        [1.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 1.0, 0.0, 0.0]\n    ])\n    \n    n = 5\n    m = 200\n    p = 2\n    dt = 0.05\n    x0 = np.zeros((n, 1))\n\n    # Test suite thresholds\n    eta_values = [0.5, 0.9, 0.99, 1.0]\n    \n    #\n    # Step 1: Generate Snapshots from the Full-Order Model (FOM)\n    #\n    X = np.zeros((n, m))\n    Y_fom = np.zeros((p, m))\n    x_k = x0.copy()\n    \n    # B is (n, 1), need to make it a flat array for single-u_k multiplication, then reshape\n    B_flat = B.flatten()\n\n    for k in range(m):\n        u_k = np.sin(0.15 * k) + 0.5 * np.sin(0.03 * k)\n        \n        # Store current state and output\n        X[:, k] = x_k.flatten()\n        Y_fom[:, k] = (C @ x_k).flatten()\n        \n        # Update state using Forward Euler\n        x_k = x_k + dt * (A @ x_k + B * u_k)\n\n    #\n    # Step 2: Perform POD via SVD\n    #\n    # Using full_matrices=False is more efficient as we only need the first min(n,m) modes\n    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n    \n    # Calculate energy spectrum\n    s_sq = s**2\n    total_energy = np.sum(s_sq)\n    \n    # Handle the case where total_energy is zero\n    if total_energy > 1e-15:\n        cumulative_energy = np.cumsum(s_sq) / total_energy\n    else:\n        # Trivial case: all snapshots are zero.\n        cumulative_energy = np.zeros_like(s)\n    \n    all_results = []\n    \n    # Loop over each energy capture threshold\n    for eta in eta_values:\n        \n        #\n        # Step 3: Determine reduced dimension r\n        #\n        # Find the smallest r such that cumulative_energy fraction is >= eta\n        # np.searchsorted finds the index where eta would be inserted to maintain order.\n        # side='left' gives the first such index. Add 1 for the count.\n        r = np.searchsorted(cumulative_energy, eta, side='left') + 1\n        \n        # Ensure r is not greater than the number of singular values\n        r = min(r, len(s))\n        \n        #\n        # Step 4: Construct and Simulate the ROM\n        #\n        captured_energy = cumulative_energy[r - 1] if r > 0 else 0.0\n\n        # Basis from leading left singular vectors (POD modes)\n        Vr = U[:, :r]\n        \n        # Galerkin projection\n        Ar = Vr.T @ A @ Vr\n        Br = Vr.T @ B\n        Cr = C @ Vr\n        \n        # Simulate the ROM\n        z_k = Vr.T @ x0  # Initial reduced state\n        Y_rom = np.zeros((p, m))\n\n        for k in range(m):\n            u_k = np.sin(0.15 * k) + 0.5 * np.sin(0.03 * k)\n            \n            # Store reduced output\n            Y_rom[:, k] = (Cr @ z_k).flatten()\n            \n            # Update reduced state\n            z_k = z_k + dt * (Ar @ z_k + Br * u_k)\n\n        #\n        # Step 5: Compute Error Metrics\n        #\n        # Snapshot reconstruction error\n        X_reconstructed = Vr @ (Vr.T @ X)\n        reconstruction_error_F = np.linalg.norm(X - X_reconstructed, 'fro')\n        \n        # Derived Frobenius-norm truncated-basis bound\n        # This is the square root of the sum of the squares of the truncated singular values\n        bound_F = np.sqrt(np.sum(s_sq[r:]))\n        \n        # Root-Mean-Square Error (RMSE) for the output\n        output_rmse = np.sqrt(np.mean((Y_fom - Y_rom)**2))\n        \n        # Check if the error is within the bound (should be equal up to floating-point error)\n        is_within_bound = reconstruction_error_F = bound_F + 1e-9\n\n        # Store results for this threshold\n        all_results.append([\n            r,\n            captured_energy,\n            reconstruction_error_F,\n            bound_F,\n            output_rmse,\n            is_within_bound\n        ])\n\n    # Final print statement in the exact required format\n    # Using list comprehensions and f-string formatting to match the output style\n    inner_lists = [f\"[{r},{e:.15f},{err_f:.15f},{b_f:.15f},{rmse:.15f},{is_wb}]\"\n                   for r, e, err_f, b_f, rmse, is_wb in all_results]\n    print(f\"[{','.join(inner_lists)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "数字孪生模型必须用真实世界的数据进行校准，但我们能得到的参数估计精度有多高？本次实践探讨了估计的理论极限，即克拉默-拉奥下界（Cramér-Rao Lower Bound, CRLB），它为任何无偏估计量的最佳性能提供了基准。通过本练习，您将学习推导和解释CRLB，这对于理解数据中包含了多少关于系统性能的信息，以及为数字孪生的准确性设定切合实际的期望至关重要。",
            "id": "4215921",
            "problem": "一个信息物理生产单元由一个数字孪生监控，其传感器输出向量的测量模型由 $y_k = h_{\\theta}(x_k, u_k) + v_k$ 给出，其中 $y_k \\in \\mathbb{R}^{m}$ 是在时间索引 $k$ 处的测量输出，$x_k \\in \\mathbb{R}^{n}$ 是已知状态，$u_k \\in \\mathbb{R}^{p}$ 是已知控制输入，而 $h_{\\theta} : \\mathbb{R}^{n} \\times \\mathbb{R}^{p} \\to \\mathbb{R}^{m}$ 是一个由 $\\theta \\in \\mathbb{R}^{d}$ 参数化的可微输出映射。噪声序列 $v_k$ 在 $k$ 上是独立的，其中 $v_k \\sim \\mathcal{N}(0, R)$，$R \\in \\mathbb{R}^{m \\times m}$ 是一个已知的正定协方差矩阵，且 $R$ 不依赖于 $\\theta$。数据集 $\\{(x_k, u_k, y_k)\\}_{k=1}^{K}$ 是可用的。\n\n该生产单元的性能由一个在特定工作条件 $(x_{\\mathrm{op}}, u_{\\mathrm{op}})$ 下定义的标量输出 $g(\\theta) = a^{\\top} h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})$ 概括，其中 $a \\in \\mathbb{R}^{m}$ 是一个已知的权重向量。假设标准的正则性条件对于基于似然的推断成立，并假设通过参数估计然后在 $(x_{\\mathrm{op}}, u_{\\mathrm{op}})$ 处求值来构建 $g(\\theta)$ 的一个无偏估计量。\n\n从独立高斯测量噪声的似然的基本定义和最大似然估计量 (MLE) 的定义出发，推导对数似然的形式以及 $\\theta$ 的相应估计量。然后，利用 Fisher 信息矩阵 (FIM) 和 Cramér–Rao 下界 (CRLB) 的定义，推导在真实参数值 $\\theta^{\\star}$ 处评估的 $g(\\theta)$ 的任何无偏估计量的方差的 CRLB 的一个闭式解析表达式。你的最终答案必须是单个闭式解析表达式。不要提供数值。你的最终答案必须用雅可比矩阵 $\\frac{\\partial h_{\\theta}(x_k, u_k)}{\\partial \\theta}$ 和 $\\frac{\\partial h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})}{\\partial \\theta}$、协方差 $R$ 和权重向量 $a$ 明确表示。",
            "solution": "问题要求计算性能标量 $g(\\theta) = a^{\\top} h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})$ 的无偏估计量方差的 Cramér–Rao 下界 (CRLB)。推导过程首先定义统计模型及其对数似然，然后计算 Fisher 信息矩阵 (FIM)，最后对估计参数的函数应用 CRLB 定理。\n\n测量模型由 $y_k = h_{\\theta}(x_k, u_k) + v_k$ 给出，其中噪声项 $v_k$ 服从独立同分布的高斯分布，$v_k \\sim \\mathcal{N}(0, R)$。这意味着在给定状态 $x_k$、输入 $u_k$ 和参数向量 $\\theta$ 的条件下，单个测量向量 $y_k$ 的条件概率分布也是高斯的：\n$$y_k | x_k, u_k, \\theta \\sim \\mathcal{N}(h_{\\theta}(x_k, u_k), R)$$\n因此，单个观测值 $y_k$ 的概率密度函数 (PDF) 为：\n$$p(y_k | \\theta) = \\frac{1}{(2\\pi)^{m/2} \\sqrt{\\det(R)}} \\exp\\left(-\\frac{1}{2} (y_k - h_{\\theta}(x_k, u_k))^{\\top} R^{-1} (y_k - h_{\\theta}(x_k, u_k))\\right)$$\n由于噪声项 $v_k$ 在时间索引 $k$ 上是独立的，整个数据集 $Y = \\{y_k\\}_{k=1}^{K}$ 的似然是各个 PDF 的乘积：\n$$L(\\theta | Y) = \\prod_{k=1}^{K} p(y_k | \\theta)$$\n对数似然函数 $\\mathcal{L}(\\theta) = \\ln(L(\\theta|Y))$ 是各个对数 PDF 的和：\n$$\\mathcal{L}(\\theta) = \\sum_{k=1}^{K} \\left[ -\\frac{m}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln(\\det(R)) - \\frac{1}{2}(y_k - h_{\\theta}(x_k, u_k))^{\\top} R^{-1} (y_k - h_{\\theta}(x_k, u_k)) \\right]$$\n$\\theta$ 的最大似然估计量 (MLE)，记为 $\\hat{\\theta}_{MLE}$，是使 $\\mathcal{L}(\\theta)$ 最大化的 $\\theta$ 值。由于和中的前两项相对于 $\\theta$ 是常数，这等价于最小化加权残差平方和：\n$$\\hat{\\theta}_{MLE} = \\arg\\min_{\\theta} \\sum_{k=1}^{K} (y_k - h_{\\theta}(x_k, u_k))^{\\top} R^{-1} (y_k - h_{\\theta}(x_k, u_k))$$\n\nFisher 信息矩阵 (FIM) $I(\\theta)$ 提供了一种度量，衡量可观测数据 $Y$ 携带的关于未知参数 $\\theta$ 的信息量。在标准正则性条件下，它被定义为在真实参数值 $\\theta^{\\star}$ 处求值的对数似然函数的 Hessian 矩阵的负期望：\n$$I(\\theta^{\\star}) = -E\\left[ \\left. \\frac{\\partial^2 \\mathcal{L}(\\theta)}{\\partial \\theta \\partial \\theta^{\\top}} \\right|_{\\theta=\\theta^{\\star}} \\right]$$\n让我们首先计算对数似然的梯度（得分函数）。令 $J_k(\\theta) = \\frac{\\partial h_{\\theta}(x_k, u_k)}{\\partial \\theta}$ 为 $h_{\\theta}$ 关于 $\\theta$ 的 $m \\times d$ 雅可比矩阵。使用向量微积分恒等式，$\\mathcal{L}(\\theta)$ 的梯度为：\n$$\\frac{\\partial \\mathcal{L}(\\theta)}{\\partial \\theta} = \\sum_{k=1}^{K} J_k(\\theta)^{\\top} R^{-1} (y_k - h_{\\theta}(x_k, u_k))$$\nHessian 矩阵是得分函数关于 $\\theta^{\\top}$ 的导数：\n$$\\frac{\\partial^2 \\mathcal{L}(\\theta)}{\\partial \\theta \\partial \\theta^{\\top}} = \\sum_{k=1}^{K} \\frac{\\partial}{\\partial \\theta^{\\top}} \\left[ J_k(\\theta)^{\\top} R^{-1} (y_k - h_{\\theta}(x_k, u_k)) \\right]$$\n应用微分的乘法法则可得：\n$$\\frac{\\partial^2 \\mathcal{L}(\\theta)}{\\partial \\theta \\partial \\theta^{\\top}} = \\sum_{k=1}^{K} \\left[ \\left(\\frac{\\partial (J_k(\\theta)^{\\top} R^{-1})}{\\partial \\theta^{\\top}}\\right) (y_k - h_{\\theta}(x_k, u_k)) - J_k(\\theta)^{\\top} R^{-1} J_k(\\theta) \\right]$$\n期望是关于数据分布计算的，其中 $E[y_k] = h_{\\theta^{\\star}}(x_k, u_k)$。因此，在真实参数值 $\\theta^{\\star}$ 处，我们有 $E[y_k - h_{\\theta^{\\star}}(x_k, u_k)] = E[v_k] = 0$。Hessian 矩阵中第一项的期望为零：\n$$E\\left[ \\left. \\frac{\\partial^2 \\mathcal{L}(\\theta)}{\\partial \\theta \\partial \\theta^{\\top}} \\right|_{\\theta=\\theta^{\\star}} \\right] = - \\sum_{k=1}^{K} J_k(\\theta^{\\star})^{\\top} R^{-1} J_k(\\theta^{\\star})$$\n因此，在 $\\theta^{\\star}$ 处的 FIM 为：\n$$I(\\theta^{\\star}) = \\sum_{k=1}^{K} J_k(\\theta^{\\star})^{\\top} R^{-1} J_k(\\theta^{\\star}) = \\sum_{k=1}^{K} \\left(\\frac{\\partial h_{\\theta}(x_k, u_k)}{\\partial \\theta}\\right)_{\\theta=\\theta^{\\star}}^{\\top} R^{-1} \\left(\\frac{\\partial h_{\\theta}(x_k, u_k)}{\\partial \\theta}\\right)_{\\theta=\\theta^{\\star}}$$\nCramér–Rao 下界定理指出，对于 $\\theta$ 的任何无偏估计量 $\\hat{\\theta}$，其协方差矩阵的下界为 FIM 的逆矩阵：$\\mathrm{Cov}(\\hat{\\theta}) \\ge I(\\theta^{\\star})^{-1}$。\n\n我们需要标量函数 $g(\\theta) = a^{\\top} h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})$ 的估计量的 CRLB。对于参数的函数，CRLB 由 delta 方法（或不确定性传播）给出：\n$$\\mathrm{CRLB}(g(\\theta^{\\star})) = (\\nabla_{\\theta} g(\\theta^{\\star}))^{\\top} I(\\theta^{\\star})^{-1} (\\nabla_{\\theta} g(\\theta^{\\star}))$$\n其中 $\\nabla_{\\theta} g(\\theta^{\\star})$ 是在 $\\theta^{\\star}$ 处求值的 $g(\\theta)$ 的梯度。让我们计算这个梯度。令 $J_{\\mathrm{op}}(\\theta) = \\frac{\\partial h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})}{\\partial \\theta}$ 为在工作点处输出映射的 $m \\times d$ 雅可比矩阵。\n$$g(\\theta) = a^{\\top} h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})$$\n关于 $\\theta$ 的梯度是一个 $d \\times 1$ 的列向量：\n$$\\nabla_{\\theta} g(\\theta) = \\left(\\frac{\\partial h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})}{\\partial \\theta}\\right)^{\\top} a = J_{\\mathrm{op}}(\\theta)^{\\top} a$$\n该梯度的转置是 $(\\nabla_{\\theta} g(\\theta))^{\\top} = a^{\\top} J_{\\mathrm{op}}(\\theta)$。\n将梯度和 FIM 代入 CRLB 公式，我们得到在真实参数 $\\theta^{\\star}$ 处求值的 $g(\\theta)$ 的任何无偏估计量的方差下界：\n$$\\mathrm{CRLB}(g(\\theta^{\\star})) = (a^{\\top} J_{\\mathrm{op}}(\\theta^{\\star})) I(\\theta^{\\star})^{-1} (J_{\\mathrm{op}}(\\theta^{\\star})^{\\top} a)$$\n代入 $I(\\theta^{\\star})^{-1}$ 的完整表达式：\n$$\\mathrm{CRLB}(g(\\theta^{\\star})) = a^{\\top} J_{\\mathrm{op}}(\\theta^{\\star}) \\left[ \\sum_{k=1}^{K} J_k(\\theta^{\\star})^{\\top} R^{-1} J_k(\\theta^{\\star}) \\right]^{-1} J_{\\mathrm{op}}(\\theta^{\\star})^{\\top} a$$\n按照要求，我们用指定的雅可比矩阵来表示最终答案，为使符号清晰，省略了在 $\\theta^{\\star}$ 处的显式求值，因为这在问题上下文中是隐含的。\n$$\\mathrm{CRLB}(g) = a^{\\top} \\left(\\frac{\\partial h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})}{\\partial \\theta}\\right) \\left[ \\sum_{k=1}^{K} \\left(\\frac{\\partial h_{\\theta}(x_k, u_k)}{\\partial \\theta}\\right)^{\\top} R^{-1} \\left(\\frac{\\partial h_{\\theta}(x_k, u_k)}{\\partial \\theta}\\right) \\right]^{-1} \\left(\\frac{\\partial h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})}{\\partial \\theta}\\right)^{\\top} a$$\n该表达式表示基于所提供的数据和模型结构，对性能指标 $g(\\theta)$ 的任何无偏估计量可达到的最小方差。",
            "answer": "$$\n\\boxed{\na^{\\top} \\left(\\frac{\\partial h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})}{\\partial \\theta}\\right) \\left[ \\sum_{k=1}^{K} \\left(\\frac{\\partial h_{\\theta}(x_k, u_k)}{\\partial \\theta}\\right)^{\\top} R^{-1} \\left(\\frac{\\partial h_{\\theta}(x_k, u_k)}{\\partial \\theta}\\right) \\right]^{-1} \\left(\\frac{\\partial h_{\\theta}(x_{\\mathrm{op}}, u_{\\mathrm{op}})}{\\partial \\theta}\\right)^{\\top} a\n}\n$$"
        },
        {
            "introduction": "物理系统的状态永远无法被完美地知晓，它总是一个带有不确定性的估计值。本次实践演示了数字孪生如何利用这种状态不确定性来计算衍生的关键性能指标（Key Performance Indicator, KPI）的相应不确定性。通过这个练习，您将掌握“不确定性量化”的核心概念，学习如何通过一阶泰勒级数展开，将系统状态的不确定性转化为高层性能指标的不确定性，这对于风险评估和决策至关重要。",
            "id": "4215971",
            "problem": "一个信息物理系统 (CPS) 的数字孪生 (DT) 监控着一个加工单元的循环时间，并将其作为一个关键性能指标。循环时间 $K$ 通过函数从状态向量 $x = (u, b, T)^\\top$ 建模：\n$$\nK = \\phi(x) = \\frac{\\eta}{1 - u} \\left( 1 + \\gamma b \\right) \\exp\\!\\left( \\beta \\left( T - T_{\\mathrm{ref}} \\right) \\right),\n$$\n其中 $u$ 是利用率（无量纲，以分数表示），$b$ 是归一化缓冲占有率（无量纲，以分数表示），$T$ 是温度（单位：摄氏度），$T_{\\mathrm{ref}}$ 是参考温度（单位：摄氏度）。常数分别为 $\\eta = 0.8$（秒），$\\gamma = 0.1$（无量纲），$\\beta = 0.02$（每摄氏度），以及 $T_{\\mathrm{ref}} = 35$（摄氏度）。该数字孪生 (DT) 维持一个对状态的高斯估计，其均值（工作点）为\n$$\n\\mu_x = \\begin{pmatrix} u_0 \\\\ b_0 \\\\ T_0 \\end{pmatrix} = \\begin{pmatrix} 0.75 \\\\ 0.30 \\\\ 40 \\end{pmatrix},\n$$\n协方差为\n$$\n\\Sigma_x = \\begin{pmatrix}\n0.0004  0.0003  0.01 \\\\\n0.0003  0.0025  0.02 \\\\\n0.01  0.02  2.25\n\\end{pmatrix}.\n$$\n从方差、协方差和一阶泰勒展开的基本定义出发，推导 $K$ 关于 $\\mu_x$ 的方差的一阶近似。然后，使用所给的数值参数，计算 $K$ 的近似方差，单位为平方秒。假设 $\\mu_x$ 周围的噪声足够小，使得一阶近似有效。将最终数值答案四舍五入到四位有效数字。以 $\\mathrm{s}^2$ 表示最终方差。",
            "solution": "题目要求计算循环时间 $K$ 的方差的一阶近似，其中 $K$ 是状态向量 $x = (u, b, T)^\\top$ 的函数。状态向量 $x$ 是一个随机变量，具有给定的均值 $\\mu_x$ 和协方差矩阵 $\\Sigma_x$。\n\n函数由下式给出：\n$$\nK = \\phi(x) = \\frac{\\eta}{1 - u} \\left( 1 + \\gamma b \\right) \\exp\\!\\left( \\beta \\left( T - T_{\\mathrm{ref}} \\right) \\right)\n$$\n该状态由一个均值为 $\\mu_x$、协方差为 $\\Sigma_x$ 的高斯分布来表征。\n函数 $K = \\phi(x)$ 在均值状态 $\\mu_x$ 附近的一阶泰勒级数展开为：\n$$\n\\phi(x) \\approx \\phi(\\mu_x) + \\nabla \\phi(\\mu_x)^\\top (x - \\mu_x)\n$$\n其中 $\\nabla \\phi(\\mu_x)$ 是 $\\phi$ 在 $\\mu_x$ 处计算的梯度。我们将此梯度记为 $J$。\n\n$K$ 的期望值近似为：\n$$\nE[K] = E[\\phi(x)] \\approx E[\\phi(\\mu_x) + J^\\top (x - \\mu_x)] = \\phi(\\mu_x) + J^\\top E[x - \\mu_x]\n$$\n由于 $E[x - \\mu_x] = E[x] - \\mu_x = \\mu_x - \\mu_x = 0$，均值的一阶近似为 $E[K] \\approx \\phi(\\mu_x)$。\n\n$K$ 的方差定义为 $\\mathrm{Var}(K) = E[(K - E[K])^2]$。对 $K$ 和 $E[K]$ 使用一阶近似：\n$$\n\\mathrm{Var}(K) \\approx E\\left[ \\left( (\\phi(\\mu_x) + J^\\top (x - \\mu_x)) - \\phi(\\mu_x) \\right)^2 \\right]\n$$\n$$\n\\mathrm{Var}(K) \\approx E\\left[ \\left( J^\\top (x - \\mu_x) \\right)^2 \\right]\n$$\n平方项可以写成矩阵乘积的形式：\n$$\n\\mathrm{Var}(K) \\approx E\\left[ \\left( J^\\top (x - \\mu_x) \\right) \\left( (x - \\mu_x)^\\top J \\right) \\right]\n$$\n由于 $J$ 是一个常数向量（在常数均值 $\\mu_x$ 处计算），我们可以将其移到期望符号之外：\n$$\n\\mathrm{Var}(K) \\approx J^\\top E\\left[ (x - \\mu_x) (x - \\mu_x)^\\top \\right] J\n$$\n期望内的项是状态向量 $x$ 的协方差矩阵的定义，即 $\\Sigma_x = E\\left[ (x - \\mu_x) (x - \\mu_x)^\\top \\right]$。\n因此，$K$ 的方差的一阶近似为：\n$$\n\\mathrm{Var}(K) \\approx J^\\top \\Sigma_x J\n$$\n这是向量函数不确定性传播的通用公式，此处特化为标量输出。\n\n为了应用此公式，我们首先需要计算梯度向量 $J = \\nabla \\phi(x)$，并在平均工作点 $\\mu_x = (u_0, b_0, T_0)^\\top$ 处对其进行求值。梯度的分量是关于 $u$、$b$ 和 $T$ 的偏导数。\n\n1.  关于 $u$ 的偏导数：\n    $$\n    \\frac{\\partial K}{\\partial u} = \\frac{\\partial}{\\partial u} \\left[ \\frac{\\eta}{1 - u} \\left( 1 + \\gamma b \\right) \\exp\\left( \\beta (T - T_{\\mathrm{ref}}) \\right) \\right] = \\frac{\\eta}{(1-u)^2} \\left( 1 + \\gamma b \\right) \\exp\\left( \\beta (T - T_{\\mathrm{ref}}) \\right)\n    $$\n    这可以用 $K$ 本身更简单地表示：\n    $$\n    \\frac{\\partial K}{\\partial u} = K \\cdot \\frac{1}{1-u}\n    $$\n\n2.  关于 $b$ 的偏导数：\n    $$\n    \\frac{\\partial K}{\\partial b} = \\frac{\\eta}{1 - u} \\left[ \\frac{\\partial}{\\partial b} (1 + \\gamma b) \\right] \\exp\\left( \\beta (T - T_{\\mathrm{ref}}) \\right) = \\frac{\\eta}{1 - u} \\gamma \\exp\\left( \\beta (T - T_{\\mathrm{ref}}) \\right)\n    $$\n    用 $K$ 表示：\n    $$\n    \\frac{\\partial K}{\\partial b} = K \\cdot \\frac{\\gamma}{1+\\gamma b}\n    $$\n\n3.  关于 $T$ 的偏导数：\n    $$\n    \\frac{\\partial K}{\\partial T} = \\frac{\\eta}{1 - u} (1 + \\gamma b) \\left[ \\frac{\\partial}{\\partial T} \\exp\\left( \\beta (T - T_{\\mathrm{ref}}) \\right) \\right] = \\frac{\\eta}{1 - u} (1 + \\gamma b) \\exp\\left( \\beta (T - T_{\\mathrm{ref}}) \\right) \\cdot \\beta\n    $$\n    用 $K$ 表示：\n    $$\n    \\frac{\\partial K}{\\partial T} = K \\cdot \\beta\n    $$\n\n接下来，我们在平均工作点 $\\mu_x$ 处计算这些导数，其中 $u_0 = 0.75$，$b_0 = 0.30$，$T_0 = 40$。我们还使用给定的常数：$\\eta = 0.8$，$\\gamma = 0.1$，$\\beta = 0.02$ 和 $T_{\\mathrm{ref}} = 35$。\n\n首先，我们计算在均值点处的 $K$ 值，即 $K_0 = \\phi(\\mu_x)$：\n$$\nK_0 = \\frac{0.8}{1 - 0.75} (1 + 0.1 \\cdot 0.30) \\exp(0.02(40 - 35))\n$$\n$$\nK_0 = \\frac{0.8}{0.25} (1 + 0.03) \\exp(0.02 \\cdot 5) = 3.2 \\cdot 1.03 \\cdot \\exp(0.1) = 3.296 \\exp(0.1)\n$$\n使用 $\\exp(0.1)$ 的数值，我们得到 $K_0 \\approx 3.296 \\cdot 1.1051709 = 3.6426633$ s。\n\n现在我们在 $\\mu_x$ 处计算雅可比（梯度）向量 $J = (J_u, J_b, J_T)^\\top$ 的分量：\n$$\nJ_u = \\frac{\\partial K}{\\partial u} \\bigg|_{\\mu_x} = \\frac{K_0}{1 - u_0} = \\frac{K_0}{1 - 0.75} = \\frac{K_0}{0.25} = 4 K_0 \\approx 4 \\cdot 3.6426633 = 14.570653\n$$\n$$\nJ_b = \\frac{\\partial K}{\\partial b} \\bigg|_{\\mu_x} = \\frac{K_0 \\gamma}{1 + \\gamma b_0} = \\frac{K_0 \\cdot 0.1}{1 + 0.1 \\cdot 0.30} = \\frac{0.1 K_0}{1.03} \\approx 0.097087 \\cdot K_0 \\approx 0.353686\n$$\n$$\nJ_T = \\frac{\\partial K}{\\partial T} \\bigg|_{\\mu_x} = K_0 \\beta = 0.02 K_0 \\approx 0.02 \\cdot 3.6426633 = 0.072853\n$$\n所以，梯度向量为 $J \\approx (14.570653, 0.353686, 0.072853)^\\top$。\n\n最后，我们使用 $\\mathrm{Var}(K) \\approx J^\\top \\Sigma_x J$ 计算方差。协方差矩阵给出如下：\n$$\n\\Sigma_x = \\begin{pmatrix}\n0.0004  0.0003  0.01 \\\\\n0.0003  0.0025  0.02 \\\\\n0.01  0.02  2.25\n\\end{pmatrix}\n$$\n方差由二次型给出：\n$$\n\\mathrm{Var}(K) \\approx J_u^2 \\sigma_{uu}^2 + J_b^2 \\sigma_{bb}^2 + J_T^2 \\sigma_{TT}^2 + 2(J_u J_b \\sigma_{ub} + J_u J_T \\sigma_{uT} + J_b J_T \\sigma_{bT})\n$$\n其中 $\\sigma_{ij}$ 是 $\\Sigma_x$ 的元素。\n\n我们来计算每一项：\n-   来自 $u$ 的方差贡献：$J_u^2 \\sigma_{uu}^2 = (14.570653)^2 \\cdot 0.0004 \\approx 0.0849215$\n-   来自 $b$ 的方差贡献：$J_b^2 \\sigma_{bb}^2 = (0.353686)^2 \\cdot 0.0025 \\approx 0.0003127$\n-   来自 $T$ 的方差贡献：$J_T^2 \\sigma_{TT}^2 = (0.072853)^2 \\cdot 2.25 \\approx 0.0119421$\n-   来自 $u, b$ 的协方差贡献：$2 J_u J_b \\sigma_{ub} = 2 \\cdot 14.570653 \\cdot 0.353686 \\cdot 0.0003 \\approx 0.0030930$\n-   来自 $u, T$ 的协方差贡献：$2 J_u J_T \\sigma_{uT} = 2 \\cdot 14.570653 \\cdot 0.072853 \\cdot 0.01 \\approx 0.0212318$\n-   来自 $b, T$ 的协方差贡献：$2 J_b J_T \\sigma_{bT} = 2 \\cdot 0.353686 \\cdot 0.072853 \\cdot 0.02 \\approx 0.0010308$\n\n将这些贡献相加：\n$$\n\\mathrm{Var}(K) \\approx 0.0849215 + 0.0003127 + 0.0119421 + 0.0030930 + 0.0212318 + 0.0010308\n$$\n$$\n\\mathrm{Var}(K) \\approx 0.1225319 \\;\\mathrm{s}^2\n$$\n题目要求将最终答案四舍五入到四位有效数字。\n$$\n\\mathrm{Var}(K) \\approx 0.1225 \\;\\mathrm{s}^2\n$$",
            "answer": "$$\n\\boxed{0.1225}\n$$"
        }
    ]
}