## 引言
在构建如[数字孪生](@entry_id:171650)和信息物理系统这类复杂系统的征程中，我们常常面临一个核心挑战：如何在有限的计算资源下实现对物理世界既精确又迅速的模拟。高保真度模型虽准，但其高昂的计算成本往往令人望而却步；而低保真度模型虽快，却可能因过度简化而导致预测失真。[多保真度建模](@entry_id:752240)策略应运而生，它并非简单地在两者间取其一，而是旨在通过智慧地融合不同层级的模型，以实现计算成本与预测精度之间的最优平衡。本文旨在为读者构建一个关于[多保真度建模](@entry_id:752240)的完整知识体系。我们将首先在“原理与机制”一章中，深入剖析支撑这一策略的理论基石，解构“保真度”的内涵，并介绍多种核心的融合技术。随后，在“应用与跨学科连接”一章中，我们将展示这些理论如何在航空航天、能源系统、生物医学乃至因果推断等多元领域中落地生根，解决实际工程与科学问题。最后，通过“动手实践”部分，读者将有机会亲手应用所学知识，将理论转化为实践能力。让我们从最根本的原理开始，探索[多保真度建模](@entry_id:752240)的精髓。

## 原理与机制

在[数字孪生](@entry_id:171650)和信息物理系统的构建中，[多保真度建模](@entry_id:752240)是一种核心策略，旨在以可控的计算成本实现对复杂现象的精确预测和深刻理解。本章旨在深入阐述支撑多保真度策略的基本原理以及融合与管理不同保真度水平的关键机制。我们将从“保真度”这一概念本身出发，解构其多维度的内涵，进而探讨驱动[多保真度方法](@entry_id:1128261)的核心经济学原理——成本与精度之间的权衡。随后，本章将系统地介绍几种主流的保真度融合技术，包括基于[高斯过程](@entry_id:182192)的修正方法、用于不确定性量化的[多层蒙特卡洛方法](@entry_id:752291)，以及结合了物理知识的现代[深度学习](@entry_id:142022)框架。最后，我们将这些原理和机制置于实际应用的背景下，讨论它们如何在优化、系统行为分析以及模型可信度评估（即验证、确认和不确定性量化）等关键任务中发挥作用。

### 解构模型保真度

在探讨如何“混合”不同模型之前，我们必须首先精确定义**模型保真度 (model fidelity)**。直观上，保真度衡量了一个模型对其所代表的真实物理系统或现象的逼真程度。一个高保真度模型能够以高精度复现真实系统的行为，而低保真度模型则可能在某些方面做出简化或抽象，从而牺牲一部分精度以换取计算效率。

从形式上看，若真实物理系统可被一个理想的因果映射 $f_{\star}$ 所描述，它将输入（如外部扰动、负载、控制设定等）映射到系统输出（如温度、压力、功率等），那么一个模型 $f_{M}$ 的保真度可以被量化为它与真实系统在任务相关场景分布上的近似程度。这通常通过一个由输入空间的测度 $\mu$ 诱导的[误差范数](@entry_id:176398)来衡量，即 $\|f_{M} - f_{\star}\|_{\mu}$ 。一个高保真度的模型意味着在所有关心的场景中，这个[误差范数](@entry_id:176398)都足够小。

然而，保真度并非一个单一的标量属性。它是一个多维度的概念，其变化源于模型构建过程中的不同选择。我们可以将模型 $f_{M}$ 的构建过程分解为三个基本组成部分：$f_{M} = \mathcal{D}_{h,\varepsilon}\big(f_{\mathcal{H}}(\cdot;\theta)\big)$。这为我们提供了一个解构保真度的系统性框架 ：

1.  **结构保真度 (Structural Fidelity)**：这与模型类 $\mathcal{H}$ 的选择有关，即模型所包含的**物理定律**和**拓扑结构**。它决定了模型“骨架”的复杂性和完整性。例如，在为一个建筑的暖通空调（HVAC）系统建立数字孪生时，选择将一个房间区域表示为单一的、充分混合的温容节点，还是一个能够捕捉垂直温度分层的多节点网络，这是一个结构保真度的选择。同样，是否在模型中明确包含由[压降](@entry_id:199916)关系和风机特性决定的风道网络，或者是否考虑湿度的动态变化及其与显热的耦合，都属于改变模型结构保真度的范畴 。

2.  **参数保真度 (Parametric Fidelity)**：在给定的模型结构 $\mathcal{H}$ 下，这与模型参数 $\theta$ 的**准确性**有关。这些参数是模型方程中的具体数值，如材料属性、设备[性能曲线](@entry_id:183861)的系数等。在HVAC的例子中，通过实验数据校准建筑围护结构的热阻 $R$、区域的热容 $C$、盘管的[总传热系数](@entry_id:151629)-面积乘积 $UA$、风机[性能曲线](@entry_id:183861)的[多项式系数](@entry_id:262287) $(a_{0},a_{1},a_{2})$ 等，就是在[提升模型](@entry_id:909156)的参数保真度 。

3.  **数值保真度 (Numerical Fidelity)**：这与求解模型方程的数值方案 $\mathcal{D}_{h,\varepsilon}$ 有关，它决定了从连续的数学模型到离散的计算机解的过程中引入的**近似误差**。这包括由有限步长（如时间步长 $\Delta t$、空间网格尺寸 $h$）导致的**离散误差**，以及由迭代求解器的[收敛判据](@entry_id:158093)（如容差 $\varepsilon$）导致的**迭代误差**。在HVAC模型中，减小[数值积分](@entry_id:136578)的时间步长 $\Delta t$、加密[计算流体动力学](@entry_id:142614)（CFD）网格、提高积分阶数（如从一阶显式格式变为二阶[隐式格式](@entry_id:166484)），或收紧非线性方程组求解器的[收敛容差](@entry_id:635614)，都是提高数值保真度的手段 。

这三个维度——结构、参数和数值——共同定义了模型的“保真度空间”。例如，在一个[流固耦合](@entry_id:1125339)（FSI）问题中，我们可以在**物理**维度（如选择[直接数值模拟](@entry_id:149543)DNS、[大涡模拟](@entry_id:153702)LES或雷诺平均法RANS来处理[湍流](@entry_id:151300)）、**空间**维度（如选择网格尺寸 $h$ 或单元阶次 $p_s$）和**时间**维度（如选择时间积分阶次 $p_t$）上调整保真度。这些维度构成了近似正交的保真度坐标轴，尽管改变一个轴（如物理模型）通常会对其他轴的最优选择（如所需的分辨率）产生影响 。

### 根本权衡：成本与精度

[多保真度建模](@entry_id:752240)的根本动机在于一个经济学原理：**高保真度通常意味着高昂的计算成本**。反之，低保真度模型虽然计算廉价，但其预测可能存在显著的偏差或不确定性。多保真度策略的核心目标，正是在这个由成本和精度构成的二维空间中，寻找最佳的平衡点。

为了形式化这一权衡，我们可以考虑一个简单的场景：一个复合预测器 $\hat{y}(x)$ 通过线性混合一个低保真度模型输出 $y_L$ 和一个高保真度模型输出 $y_H$ 来估计真实值 $y^{\star}$：
$$
\hat{y}(x) = x y_{H} + (1-x) y_{L}
$$
其中混合参数 $x \in [0,1]$。假设高、低保真度模型的单次评估成本分别为 $c_H$ 和 $c_L$ ($c_H > c_L > 0$)，且复合预测器的成本也呈线性关系 $C(x) = c_H x + c_L (1-x)$。模型的[预测误差](@entry_id:753692)定义为 $e_H = y_H - y^{\star}$ 和 $e_L = y_L - y^{\star}$。那么，复合预测器的期望平方误差 $E(x) = \mathbb{E}[(\hat{y}(x) - y^{\star})^2]$ 可以表示为 $x$ 的二次函数 ：
$$
E(x) = (M_{H} + M_{L} - 2K)x^{2} + (2K - 2M_{L})x + M_{L}
$$
其中 $M_H = \mathbb{E}[e_H^2]$，$M_L = \mathbb{E}[e_L^2]$，$K = \mathbb{E}[e_H e_L]$ 分别是误差的二阶矩和交叉矩。

通过求解 $x$ 关于 $C$ 的表达式 $x = (C - c_L)/(c_H - c_L)$，并将其代入 $E(x)$，我们可以得到期望误差作为成本的函数 $E(C)$，这便定义了成本-误差空间中的**帕累托前沿 (Pareto Frontier)**。一个关键的结论是，这个函数 $E(C)$ 是[凸函数](@entry_id:143075)。其二阶导数 $\frac{d^2E}{dC^2}$ 正比于 $\mathbb{E}[(e_H - e_L)^2]$，而后者恒为非负 。

$E(C)$ 的**[凸性](@entry_id:138568)**是[多保真度方法](@entry_id:1128261)有效性的根本数学保证。它意味着，通过巧妙地组合高、低保真度模型，我们可能得到一个比单纯使用任一模型更优的“性价比”方案。也就是说，存在某个混合比例 $x \in (0,1)$，使得其成本-误差组合 $(C(x), E(x))$ 位于连接纯低保真度点 $(c_L, M_L)$ 和纯高保真度点 $(c_H, M_H)$ 的直线段下方。

为了更深入地理解“误差”，我们可以将其分解。对于一个基于训练数据 $\mathcal{D}$ 构建的低保真度预测器 $\hat{y}_L(x)$，其对带有测量噪声 $\varepsilon$ 的真实观测值 $y_{\text{obs}}(x) = y(x) + \varepsilon(x)$ 的期望平方[预测误差](@entry_id:753692)，可以被精确地分解为三个部分 ：
$$
\mathbb{E}_{\mathcal{D},\varepsilon}[(\hat{y}_{L}(x) - y_{\text{obs}}(x))^{2}] = \underbrace{(\mathbb{E}_{\mathcal{D}}[\hat{y}_{L}(x)] - y(x))^{2}}_{\text{平方偏差 (Squared Bias)}} + \underbrace{\operatorname{Var}_{\mathcal{D}}[\hat{y}_{L}(x)]}_{\text{方差 (Variance)}} + \underbrace{\sigma_{\varepsilon}^{2}}_{\text{噪声 (Noise)}}
$$
这个**偏差-方差-噪声分解**告诉我们，预测误差来源于三个方面：
*   **偏差**：模型系统性的、固有的缺陷，即使在拥有无限训练数据的情况下也无法消除。
*   **方差**：模型对训练数据中有限样本的敏感性，反映了因数据局限性导致的不确定性。
*   **噪声**：物理测量的固有随机性，是任何模型都无法消除的误差下限。

多保真度策略的精髓，就在于利用高保真度信息来修正低保真度模型的偏差，同时结合多种数据源来降低预测的方差。

### 保真度融合的关键机制

[多保真度建模](@entry_id:752240)的核心在于“如何”有效地融合不同保真度的信息。根据应用目标和模型特性的不同，发展出了多种融合机制。

#### 基于修正的融合：协克里金与[高斯过程](@entry_id:182192)

这类方法的基本思想是将高保真度函数 $f_H(x)$ 建模为低保真度函数 $f_L(x)$ 的一个[线性变换](@entry_id:149133)，外加一个修正项或“差异项” $\delta(x)$。

**Kennedy–O'Hagan (KOH) 框架**为这一思想提供了坚实的统计基础 。它将真实物理过程 $y(x)$ 与一个（通常是确定性的）低保真度计算机代码输出 $y_L(x)$ 联系起来：
$$
y(x) = \rho \, y_L(x) + \delta(x)
$$
这里，$\rho$ 是一个回归参数，用于捕捉高、低保真度模型之间的线性相关性。而**模型差异函数 (model discrepancy function)** $\delta(x)$ 则代表了低保真度模型在经过最佳[线性缩放](@entry_id:197235)后仍然存在的系统性误差。KOH框架的创新之处在于，它不把 $\delta(x)$ 当作一个固定的未知函数，而是将其形式化为一个**[随机过程](@entry_id:268487)**，通常是**高斯过程 (Gaussian Process, GP)**，即 $\delta(x) \sim \text{GP}(0, k_{\delta}(x,x'))$。这允许我们以概率的方式对模型本身的结构性缺陷进行建模和量化。完整的观测模型还包括测量噪声 $\varepsilon(x)$：
$$
y_{\text{obs}}(x) = y(x) + \varepsilon(x) = \rho \, y_L(x) + \delta(x) + \varepsilon(x)
$$
为了保证模型的相[干性](@entry_id:900268)和参数的可识别性，该框架依赖于关键的独立性假设：$\delta(x)$、 $y_L(x)$ 和 $\varepsilon(x)$ 三者相互独立 。

**自回归协克里金模型 (Auto-regressive Co-Kriging)** 是这一思想在代理建模中的一个具体实现 。该模型同样采用 $f_H(x) = \rho f_L(x) + \delta(x)$ 的形式，并将 $f_L(x)$ 和 $\delta(x)$ 都建模为高斯过程。为了从有限的观测数据 $y_L(x_i)$ 和 $y_H(x_j)$ 中唯一地辨识出模型参数（如 $\rho$ 和 $\delta(x)$ 的协方差函数 $k_{\delta}$），[实验设计](@entry_id:142447)必须满足一些条件：
1.  **共置输入 (Co-located inputs)**：需要在一些相同的输入点 $x$ 上同时拥有高、低保真度的观测值。这为估计交叉协方差 $\operatorname{Cov}(y_H, y_L) = \rho k_L$ 提供了最强的信息，从而能够辨识 $\rho$。
2.  **低保真度重复观测 (Replication)**：当低保真度观测本身也含有噪声时（$y_L = f_L + \varepsilon_L$），需要对某些输入进行重复观测，以将信号本身的方差（由 $k_L$ 决定）与噪声方差 $\sigma_L^2$ 分离开来。
3.  **独立性假设**：差异过程 $\delta(x)$ 与低保真度过程 $f_L(x)$ 必须假设为相互独立。这是分解高保真度模型总方差、识别出 $k_{\delta}$ 的理论基石。

#### 基于聚合的融合：[多层蒙特卡洛方法](@entry_id:752291) (MLMC)

当目标是估计某个不确定性输入下的期望输出（即进行[不确定性量化](@entry_id:138597)，UQ）时，[多层蒙特卡洛方法](@entry_id:752291)提供了一种极其高效的融合策略。

MLMC的核心是**伸缩求和恒等式 (telescoping identity)** 。假设我们有一个模型层级 $Q_0, Q_1, \dots, Q_L$，其保真度和成本逐级递增。我们想要估计最高保真度模型 $Q_L$ 的期望 $\mathbb{E}[Q_L]$。该恒等式将这个期望分解为：
$$
\mathbb{E}[Q_L] = \mathbb{E}[Q_0] + \sum_{\ell=1}^{L} \mathbb{E}[Q_\ell - Q_{\ell-1}]
$$
MLMC估计器 $\hat{Q}$ 通过对上式右边的每一项进行独立的[蒙特卡洛估计](@entry_id:637986)来构造：
$$
\hat{Q} = \hat{Y}_0 + \sum_{\ell=1}^{L} \hat{Y}_\ell = \frac{1}{N_0}\sum_{i=1}^{N_0} Q_0^{(i)} + \sum_{\ell=1}^{L} \frac{1}{N_\ell}\sum_{i=1}^{N_\ell} (Q_\ell^{(i)} - Q_{\ell-1}^{(i)})
$$
MLMC的“魔力”在于，用于计算差异项 $(Q_\ell^{(i)} - Q_{\ell-1}^{(i)})$ 的每一对样本 $(Q_\ell^{(i)}, Q_{\ell-1}^{(i)})$ 都使用**相同的随机输入**生成。这种**强耦合**使得当 $Q_\ell$ 和 $Q_{\ell-1}$ 都收敛到同一个真实解时，它们的差值 $Q_\ell - Q_{\ell-1}$ 的方差会趋于零。

这一特性带来了巨大的计算优势。为了达到[均方根误差](@entry_id:170440) $\epsilon$ 的目标，标准蒙特卡洛方法在最高保真度级别 $L$ 上的总成本为 $\mathcal{O}(\epsilon^{-2} C_L)$，其中 $C_L$ 是单次高保真度样本的成本。而MLMC的总成本可以被证明为 ：
*   当差异项的方差衰减速度快于每层成本的增长速度时（即 $\mathbb{V}[Q_\ell - Q_{\ell-1}] \sim h_\ell^\beta$ 且 $C_\ell \sim h_\ell^{-\gamma}$，其中 $\beta > \gamma$），总成本仅为 $\mathcal{O}(\epsilon^{-2})$。
*   在临界情况 $\beta = \gamma$ 时，成本为 $\mathcal{O}(\epsilon^{-2}(\log\epsilon)^2)$。

在许多实际问题中，$\beta > \gamma$ 的条件是满足的，这意味着MLMC能够以与最粗糙模型 $\mathcal{O}(\epsilon^{-2} C_0)$ 相当的计算复杂度（除了常数因子），达到最高保真度模型的精度。

#### 现代融合方法：多保真度物理知识通知神经网络 (MF-PINN)

随着[深度学习](@entry_id:142022)的发展，多保真度思想也被融入到神经网络代理模型中，特别是物理知识通知神经网络（PINN）。

MF-PINN的目标是训练一个高保真度的神经网络代理 $u_H(x,t)$，其训练过程受到一个预训练的低保真度代理 $u_L(x,t)$ 的引导，同时严格遵守物理定律 。这通过精巧的架构设计和[损失函数](@entry_id:634569)设计来实现。

*   **架构融合**：一种有效的方式是通过特征传递。例如，可以将低保真度网络 $u_L$ 的一个固定编码器 $E_L$ 提取的中间层特征 $\phi_L(x,t)$，与输入 $(x,t)$ 拼接在一起，共同作为高保真度网络 $G_\theta$ 的输入，即 $u_H(x,t) = G_\theta(x, t, \phi_L(x,t))$。

*   **[损失函数](@entry_id:634569)融合**：这是MF-PINN的核心。一个鲁棒的MF-[PINN损失函数](@entry_id:137288) $\mathcal{L}$ 通常包含以下几部分：
    $$
    \mathcal{L} = \mathcal{L}_{\mathrm{phys}} + \mathcal{L}_{\mathrm{data}} + \lambda_{\mathrm{bc}}\mathcal{L}_{\mathrm{bc}} + \lambda_{\mathrm{ic}}\mathcal{L}_{\mathrm{ic}} + \eta\mathcal{L}_{\mathrm{res\_align}} + \mu\mathcal{L}_{\mathrm{feat\_align}}
    $$
    -   $\mathcal{L}_{\mathrm{phys}} = \mathbb{E}[|R[u_H]|^2]$：这是标准的PINN物理损失，其中 $R[u]$ 是[偏微分](@entry_id:194612)方程（PDE）的残差算子。它驱动 $u_H$ 满足高保真度的物理定律。
    -   $\mathcal{L}_{\mathrm{data}}$, $\mathcal{L}_{\mathrm{bc}}$, $\mathcal{L}_{\mathrm{ic}}$：分别对应于拟合高保真度传感器数据、边界条件和初始条件。
    -   $\mathcal{L}_{\mathrm{res\_align}} = \mathbb{E}[w(x,t) |R[u_H] - R[u_L]|^2]$：这是关键的**多保真度残差对齐项**。它鼓励高保真度模型的PDE残差与低保真度模型的残差保持一致。至关重要的是，权重函数 $w(x,t) = (1+|R[u_L]|^2)^{-1}$ 会在低保真度模型物理上不准确（即 $|R[u_L]|$ 很大）的区域**降低**这种引导的强度。这是一种非常智能和鲁棒的知识迁移方式，避免了“坏”知识对高保真度模型的污染 。
    -   $\mathcal{L}_{\mathrm{feat\_align}}$：鼓励高、低保真度网络在中间[特征空间](@entry_id:638014)上对齐，是另一种有效的知识传递方式。

### 应用与背景

[多保真度建模](@entry_id:752240)的原理和机制在[数字孪生](@entry_id:171650)的生命周期中扮演着多种角色，从[系统优化](@entry_id:262181)到行为分析，再到可信度评估。

#### 用于优化的[多保真度模型](@entry_id:752241)

在工程设计和控制中，一个常见的任务是优化一个由昂贵的高保真度模拟 $f(x)$ 定义的[目标函数](@entry_id:267263)。直接对 $f(x)$ 进行优化可能成本高得无法接受。多保真度代理模型为此提供了解决方案。

**信任域模型管理 (Trust-Region Model Management)** 是一种成熟的优化策略 。在每次迭代 $k$ 中，该方法的核心思想是：
1.  在一个以当前点 $x_k$ 为中心、半径为 $\Delta_k$ 的**信任域**内，构建一个廉价的代理模型 $m_k(x)$。
2.  这个代理模型 $m_k(x)$ 不是直接使用有偏的低保真度模型 $g(x)$，而是通过一个**修正**过程，强制它在当前点 $x_k$ 与高保真度模型 $f(x)$ 满足**一阶或更高阶的吻合条件**，例如 $m_k(x_k)=f(x_k)$ 和 $\nabla m_k(x_k)=\nabla f(x_k)$。
3.  在信任域内优化 $m_k(x)$ 得到一个试验步长 $s_k$。
4.  根据 $m_k(x)$ 的预测下降量与 $f(x)$ 的实际下降量之间的一致性，来决定是否接受该步长并更新信任域半径 $\Delta_k$。

只要保证代理模型序列是“充分线性”的（即模型误差和梯度误差随信任域半径的缩小而高阶衰减），并且步长能提供足够的预测下降，同时半径更新机制合理，该方法就能被证明[全局收敛](@entry_id:635436)到一个一阶[稳定点](@entry_id:136617)（即 $\liminf_{k\to\infty}\|\nabla f(x_k)\|=0$）。

#### 用于理解系统行为的[多保真度模型](@entry_id:752241)

保真度的不同维度直接影响着仿真的数值特性，为[多保真度方法](@entry_id:1128261)的必要性提供了具体物理解释。考虑一个[化学反应器](@entry_id:204463)中的一维[平流-扩散-反应](@entry_id:746316)过程，其[半离散化](@entry_id:163562)（空间离散，时间连续）后得到一个[常微分方程组](@entry_id:907499)（ODE）$\frac{d\mathbf{c}}{dt} = A\mathbf{c} + \mathbf{b}$ 。

系统的**刚性 (stiffness)** 由[雅可比矩阵](@entry_id:178326) $A$ 的[特征值谱](@entry_id:1124216)决定。特征值的实部大小反映了系统动态的时间尺度。对于这个系统：
*   扩散项（二阶导数）在离散化后，其贡献的特征值大小尺度为 $\mathcal{O}(h^{-2})$。
*   平流项（[一阶导数](@entry_id:749425)）在离散化后，其贡献的特征值大小尺度为 $\mathcal{O}(h^{-1})$。

当提高空间保真度，即加密网格、减小 $h$ 时，扩散项导致的特征值模长会急剧增大。这使得[ODE系统](@entry_id:907499)变得非常**刚性**，对[显式时间积分](@entry_id:165797)格式的稳定性步长 $\Delta t$ 提出了极其苛刻的限制（通常 $\Delta t \propto h^2$）。例如，若网格密度增加一倍（$\alpha=2$），则[稳定时间步长](@entry_id:755325)需要缩减为原来的四分之一 [@problem_id:4232529, @problem_id:4232529]。这使得纯高保真度的瞬态仿真变得极为昂贵，从而凸显了使用计算成本较低的粗网格模型进行加速的价值。同时，这也揭示了粗糙模型本质上是一个**[谱滤波](@entry_id:755173)器**，它只保留了系统的低频（平滑）动态模式，而滤除了高频（振荡）模式 。

#### 确保可信度：验证、确认与[不确定性量化](@entry_id:138597) (VVUQ)

一个多保真度[数字孪生](@entry_id:171650)，无论其数学上多么精巧，若其预测结果不可信，则毫无用处。**验证（Verification）、确认（Validation）和[不确定性量化](@entry_id:138597)（UQ）**，合称 **VVUQ**，是建立模型可信度的系统性过程 。

在一个多保真度框架下，VVUQ的任务也相应地分层和扩展：

*   **验证 (Verification)**：回答“我们是否正确地求解了方程？”。这主要针对高保真度数值求解器。活动包括：
    -   **代码验证**：使用**制造解方法 (Method of Manufactured Solutions)** 检查代码实现是否与控制方程一致。
    -   **解验证**：通过网格和时间步精化研究（如[理查森外推法](@entry_id:137237)）来估计**[收敛阶](@entry_id:146394)**，确认[数值误差](@entry_id:635587)的行为符合理论预期。
    -   **不变量保持**：检查数值格式是否遵守由物理定律蕴含的守恒律（如质量、能量守恒）。
    -   在多保真度语境下，还包括验证代理模型的构建过程，例如检查协克里金模型在训练点上的拟合残差。

*   **确认 (Validation)**：回答“我们是否求解了正确的方程？”。这必须将模型预测与真实世界的物理实验数据进行比较。关键在于：
    -   使用**未用于模型训练或校准**的**预留验证数据集**。
    -   对于概率性预测模型（如基于GP的协克里金或[贝叶斯神经网络](@entry_id:746725)），确认不仅要评估中心预测的准确性（如[均方根误差](@entry_id:170440)），还必须评估其**[不确定性区间](@entry_id:269091)的可信度**（如通过计算预测区间的**经验覆盖率**是否与名义覆盖率相符）。

*   **[不确定性量化 (UQ)](@entry_id:756296)**：回答“我们对预测的[置信度](@entry_id:267904)有多高，以及它如何影响决策？”。这涉及：
    -   将所有相关的不确定性来源（参数不确定性、[模型结构不确定性](@entry_id:1128051)/差异 $\delta(x)$、数值误差等）通过模型进行**[前向传播](@entry_id:193086)**。
    -   使用高效的采样方法（如MLMC）得到关心的输出量（QoI）的概率分布。
    -   评估UQ计算本身的数值误差（如[蒙特卡洛](@entry_id:144354)[标准误](@entry_id:635378) $\sigma_{MC}$）是否在可接受范围内。
    -   最终，利用得到的概率信息来支持**基于风险的决策**，例如，计算某个关键指标超过安全阈值的概率是否小于规定的风险容忍度 $\alpha$，即 $\mathbb{P}(Q \ge q_{\mathrm{thr}}) \le \alpha$ 。

综上所述，[多保真度建模](@entry_id:752240)是一个涵盖了从模型定义、[成本效益分析](@entry_id:200072)、算法机制到应用与评估的完整体系。通过深刻理解其背后的原理和机制，研究人员和工程师能够为复杂的物理系统构建出既精确又高效的数字孪生，从而实现更优的设计、更智能的控制和更可靠的决策。