{
    "hands_on_practices": [
        {
            "introduction": "A primary goal of Processor-in-the-Loop simulation is to verify that a control algorithm can execute within its specified time constraints on the target hardware. Before conducting a full simulation, a foundational step is to analyze the system's schedulability. This practice  provides a concrete scenario for calculating the available processor time, or \"slack,\" within a control loop, accounting for the task's worst-case execution time ($C$), context-switching overhead ($S$), and preemption by I/O interrupts ($I$). Mastering this type of timing budget analysis is a fundamental skill for ensuring the temporal correctness of any real-time embedded system.",
            "id": "4236201",
            "problem": "In a processor-in-the-loop (PIL) experiment for a sampled-data control loop in a cyber-physical system, a single periodic control task is executed at the sampling period $T_{s}$. The task runs on the target processor with preemptive fixed-priority scheduling and is the only periodic task in the system during the experiment. The following conditions hold.\n\n- The control task has a worst-case execution time (WCET) $C$ on the target processor.\n- A context switch incurs a fixed overhead $S$ per switch, incurred once at task dispatch and once at task completion.\n- During each sampling period, an asynchronous input/output (I/O) interrupt arrives and preempts the processor for a worst-case duration $I$; assume worst-case phasing so that exactly one such preemption occurs during each sampling period.\n- Actuation is performed at the end of the control computation and is followed immediately by an optional post-actuation diagnostic routine with execution time $D$ that must also complete before the end of the same sampling period if it is to be included.\n- There is no overlap or parallelism; all execution and overheads consume the same single-core processor resource.\n\nStarting from first principles of real-time scheduling for a single periodic task, define the available slack within each sampling period as the time remaining after accounting for the control taskâ€™s WCET, the two context switches per period, and the single worst-case I/O interrupt preemption. Then derive the remaining slack margin after allocating the post-actuation diagnostic routine within the same sampling period.\n\nGiven the numerical values $T_{s}=1\\ \\text{ms}$, $C=0.6\\ \\text{ms}$, $S=0.05\\ \\text{ms}$, $I=0.1\\ \\text{ms}$, and $D=0.2\\ \\text{ms}$, compute the remaining slack margin. State whether the slack suffices for the diagnostic routine based on the sign of the remaining margin. Express the final remaining slack margin in milliseconds. Do not round the result.",
            "solution": "The user wants me to solve a real-time scheduling problem related to a processor-in-the-loop (PIL) experiment.\n\nHere's my plan:\n1.  **Validate the Problem**: I will meticulously check the problem statement against my validation criteria.\n    *   **Step 1: Extract Givens**: List all the provided variables and values verbatim.\n        *   $T_s$: sampling period.\n        *   $C$: worst-case execution time (WCET) of the control task.\n        *   $S$: context switch overhead per switch.\n        *   $I$: worst-case duration of an asynchronous I/O interrupt.\n        *   $D$: execution time of an optional post-actuation diagnostic routine.\n        *   The control task is periodic with period $T_s$.\n        *   It's a single periodic task system with preemptive fixed-priority scheduling.\n        *   Two context switches occur per period (dispatch and completion).\n        *   Exactly one I/O interrupt preemption of duration $I$ occurs per period.\n        *   All execution and overheads are on a single-core processor.\n        *   The diagnostic routine, if included, must complete within the sampling period.\n        *   Numerical values: $T_s=1\\ \\text{ms}$, $C=0.6\\ \\text{ms}$, $S=0.05\\ \\text{ms}$, $I=0.1\\ \\text{ms}$, $D=0.2\\ \\text{ms}$.\n\n    *   **Step 2: Validate Using Extracted Givens**:\n        *   **Scientifically Grounded?**: Yes. The problem uses standard concepts from real-time systems and embedded control, such as WCET, sampling periods, context switch overhead, and preemptive scheduling. These are fundamental topics in computer engineering and cyber-physical systems.\n        *   **Well-Posed?**: Yes. The question asks for a specific derivation (available slack, remaining slack margin) and a numerical calculation based on given data. There appears to be enough information to arrive at a unique solution.\n        *   **Objective?**: Yes. The language is precise and technical. No subjective or opinion-based statements are present.\n        *   **Flaw Check**:\n            1.  **Scientific Unsoundness?**: No. The model is a simplification (e.g., fixed overheads, worst-case phasing), but these are standard assumptions in introductory real-time systems analysis. It doesn't violate any fundamental principles.\n            2.  **Non-Formalizable/Irrelevant?**: No. The problem is directly related to processor-in-the-loop simulation, a key technique in developing cyber-physical systems. It's perfectly formalizable.\n            3.  **Incomplete/Contradictory?**: No. The setup seems complete and consistent. We have all the necessary components of time consumption within a period and the total available time.\n            4.  **Unrealistic/Infeasible?**: No. The numerical values are plausible for a microcontroller-based control system. $T_s=1\\ \\text{ms}$ is a $1\\ \\text{kHz}$ control loop, which is common. Execution times and overheads are in the microsecond range, which is also realistic. All units are consistent (milliseconds).\n            5.  **Ill-Posed?**: No. The problem defines \"available slack\" and \"remaining slack margin\" clearly, guiding the solution process. The solution should be unique and stable.\n            6.  **Pseudo-Profound/Trivial?**: No. It's a straightforward application of scheduling principles, but it requires careful accounting of all time components. It's a valid introductory-level problem.\n            7.  **Unverifiable?**: No. The derivation and calculation are mathematically verifiable.\n\n    *   **Step 3: Verdict**: The problem is **valid**.\n\n2.  **Solve the Problem**: Now I will proceed with the solution.\n\n    *   **Principle**: The core principle is that for a real-time task to be schedulable (i.e., meet its deadline), its total worst-case response time must be less than or equal to its deadline. In this case, the deadline is the end of the sampling period, $T_s$. The total time consumed by all activities within one period must not exceed $T_s$.\n\n    *   **Step A: Define Total Processor Demand within one period (without the diagnostic routine)**\n        *   The total time available in one sampling period is $T_s$.\n        *   The processor is busy with several activities. I need to sum their worst-case durations.\n        *   **Control Task Execution**: This is given as the WCET, $C$.\n        *   **Context Switch Overhead**: The problem states a fixed overhead $S$ is incurred *once at task dispatch and once at task completion*. So, the total context switch overhead per period is $2S$.\n        *   **I/O Interrupt Preemption**: The problem states that exactly one interrupt of worst-case duration $I$ preempts the task. This time is also consumed by the processor and must be accounted for.\n        *   **Total Demand (without diagnostics)**, let's call it $T_{demand}$:\n            $T_{demand} = C + 2S + I$. This is the total time the processor is busy executing the control task, handling its context switches, and servicing the I/O interrupt.\n\n    *   **Step B: Define and Calculate Available Slack**\n        *   The problem defines \"available slack\" as the time remaining after accounting for the control task's WCET, the two context switches, and the I/O interrupt.\n        *   Let the available slack be $\\sigma_{avail}$.\n        *   From first principles, the slack is the total available time minus the total time consumed.\n        *   $\\sigma_{avail} = T_s - T_{demand}$\n        *   $\\sigma_{avail} = T_s - (C + 2S + I)$\n\n    *   **Step C: Define and Calculate Remaining Slack Margin**\n        *   The problem then asks to derive the \"remaining slack margin\" after allocating the post-actuation diagnostic routine with execution time $D$.\n        *   This routine consumes additional processor time. The remaining slack is the available slack minus the time needed for this new routine.\n        *   Let the remaining slack margin be $\\sigma_{rem}$.\n        *   $\\sigma_{rem} = \\sigma_{avail} - D$\n        *   Substituting the expression for $\\sigma_{avail}$:\n            $\\sigma_{rem} = (T_s - C - 2S - I) - D$\n        *   So, $\\sigma_{rem} = T_s - C - 2S - I - D$.\n\n    *   **Step D: Numerical Calculation**\n        *   Now, I will substitute the given numerical values into the derived formula for $\\sigma_{rem}$.\n        *   $T_s = 1\\ \\text{ms}$\n        *   $C = 0.6\\ \\text{ms}$\n        *   $S = 0.05\\ \\text{ms}$\n        *   $I = 0.1\\ \\text{ms}$\n        *   $D = 0.2\\ \\text{ms}$\n        *   $\\sigma_{rem} = 1 - 0.6 - 2(0.05) - 0.1 - 0.2$\n        *   $\\sigma_{rem} = 1 - 0.6 - 0.1 - 0.1 - 0.2$\n        *   $\\sigma_{rem} = 1 - (0.6 + 0.1 + 0.1 + 0.2)$\n        *   $\\sigma_{rem} = 1 - 1.0$\n        *   $\\sigma_{rem} = 0\\ \\text{ms}$\n\n    *   **Step E: Interpretation**\n        *   The problem asks to state whether the slack suffices for the diagnostic routine based on the sign of the remaining margin.\n        *   A non-negative remaining slack margin ($\\sigma_{rem} \\ge 0$) means that all tasks, including the diagnostic routine, can complete within the deadline $T_s$ in the worst-case scenario.\n        *   A negative remaining slack margin ($\\sigma_{rem}  0$) means that the total required execution time exceeds the available time, and thus the system is not schedulable (the deadline will be missed).\n        *   In this case, $\\sigma_{rem} = 0$. This means the total worst-case a-priori utilization equals the available time exactly. The system is schedulable, but there is zero margin. The slack is exactly sufficient, not more, not less.\n\n    *   **Final Answer Formulation**:\n        *   The final numerical answer is $0$.\n        *   The question asks to \"Express the final remaining slack margin in milliseconds.\"\n        *   The result is $0$.\n        *   The final answer must be enclosed in `$$\\boxed{...}$$`.\n        *   So, the final answer will be `$$\\boxed{0}$$`.\n\nThis seems correct and follows all instructions. I will double-check the calculations and reasoning.\n$T_s = 1$\n$C = 0.6$\n$2S = 2 \\times 0.05 = 0.1$\n$I = 0.1$\n$D = 0.2$\nTotal time consumed with diagnostic: $C + 2S + I + D = 0.6 + 0.1 + 0.1 + 0.2 = 1.0$.\nAvailable time = $T_s = 1.0$.\nRemaining slack = Available time - Total time consumed = $1.0 - 1.0 = 0$.\nThe logic is sound. The interpretation of the result is also correct. The system is schedulable, but critically so. The question asks whether the slack *suffices*, which it does if the margin is non-negative. $0$ is non-negative, so it suffices. My full explanation will include this point. The final answer box, however, only contains the numerical result.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "Processor-in-the-Loop simulation is essential for uncovering subtle yet critical bugs that arise from discrepancies between the development (host) and deployment (target) environments. This exercise  focuses on a particularly insidious source of divergence: the \"undefined behavior\" of signed integer overflow. You will explore a classic case where a simple comparison, $x+1  x$, is optimized to always be true by a Software-in-the-Loop (SIL) compiler but fails on the hardware due to arithmetic wrap-around. This hands-on practice demonstrates why on-target testing is non-negotiable for developing robust and safe cyber-physical systems.",
            "id": "4236240",
            "problem": "Consider a digital twin of a simple decision logic used in a cyber-physical controller. The digital twin is evaluated in a Software-in-the-Loop (SIL) environment using unbounded mathematical integers, while the actual processor is evaluated in a Processor-in-the-Loop (PIL) environment using fixed-width two's-complement signed integers. Let the logic be: return $1$ if $x+1  x$, else return $0$. In mathematical integers, the strict total order guarantees that for any integer $x$, the relation $x+1  x$ holds. In two's-complement $n$-bit signed integers, $x$ is representable only if $x \\in [-(2^{n-1}), 2^{n-1}-1]$, and addition is performed modulo $2^n$ followed by two's-complement interpretation. In the C programming language, signed integer overflow is undefined behavior, allowing compilers in SIL builds to assume that $x+1$ cannot overflow and to optimize conditionals such as $x+1  x$ as always true, while on actual hardware in PIL the wrap-around arithmetic may make $x+1  x$ false at the upper boundary $x = 2^{n-1}-1$. This can produce divergent outputs between SIL and PIL.\n\nYour task is to implement a program that:\n- Models the SIL decision using mathematical integers, that is, evaluates whether $x+1  x$ over $\\mathbb{Z}$ and outputs $1$ if true and $0$ otherwise.\n- Models the PIL decision using $n$-bit two's-complement signed integers, that is, computes $x+1$ with wrap-around modulo $2^n$, interprets both $x$ and $x+1$ as signed values, and then evaluates whether the signed $x+1$ is greater than $x$, outputting $1$ if true and $0$ otherwise.\n- Computes a divergence flag showing whether the SIL and PIL outputs differ for the given $(n,x)$ pair.\n- Computes a static analysis safety predicate that forbids undefined behavior for the expression $x+1$ in $n$-bit two's-complement signed arithmetic, expressed as the condition $x \\in [-(2^{n-1}), (2^{n-1}-1) - 1]$, which ensures $x+1$ is representable without overflow. Output this predicate as a boolean.\n\nUse the following test suite of $(n,x)$ pairs to exercise normal operation, boundary conditions, and different bit-widths:\n- $(n,x) = (32, 0)$\n- $(n,x) = (32, 2^{31}-1)$\n- $(n,x) = (32, -1)$\n- $(n,x) = (16, 2^{15}-1)$\n- $(n,x) = (16, -2^{15})$\n\nFor each test case, produce a four-element list $[s, p, d, q]$ where:\n- $s$ is the SIL output as an integer ($1$ or $0$).\n- $p$ is the PIL output as an integer ($1$ or $0$).\n- $d$ is a boolean indicating whether the outputs diverge, i.e., whether $s \\neq p$.\n- $q$ is a boolean indicating whether the static analysis safety predicate holds for $x+1$ under $n$-bit signed arithmetic.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The required format is a list of lists, in the order of the test suite, for example, $[[s_1,p_1,d_1,q_1],[s_2,p_2,d_2,q_2],\\dots]$ with no extra whitespace or text. There are no physical units or angle units involved in this problem, and all outputs are dimensionless integers and booleans.",
            "solution": "The problem requires an analysis of the divergence between a mathematical model (Software-in-the-Loop, SIL) and a hardware-specific model (Processor-in-the-Loop, PIL) for a simple control logic. The logic is to return $1$ if $x+1  x$ and $0$ otherwise. The divergence arises from the differing properties of unbounded mathematical integers versus fixed-width two's-complement signed integers. The task is to compute four values for given pairs of bit-width $n$ and integer $x$: the SIL output $s$, the PIL output $p$, a divergence flag $d$, and a static analysis safety predicate $q$.\n\nThe solution is developed by modeling each of these four components based on their formal definitions.\n\n1.  **SIL Model Output ($s$)**\n\nThe SIL environment is defined as using unbounded mathematical integers, denoted by the set $\\mathbb{Z}$. In this system, the ordering of integers is a strict total order. For any integer $x \\in \\mathbb{Z}$, the successor of $x$, which is $x+1$, is axiomatically greater than $x$. Therefore, the condition $x+1  x$ is a tautology; it is always true. The SIL model output $s$, which evaluates this condition, will consequently always be $1$.\n\n$s = 1 \\quad \\forall x \\in \\mathbb{Z}$\n\n2.  **Static Analysis Safety Predicate ($q$)**\n\nThe static analysis predicate a-priori checks if an operation might lead to undefined behavior. In C, signed integer overflow is undefined behavior. To prevent overflow for the expression $x+1$ using $n$-bit signed integers, the result $x+1$ must also be representable within the valid range $[-(2^{n-1}), 2^{n-1}-1]$. Given that the input $x$ is already within this range, we only need to ensure that adding $1$ does not exceed the maximum value.\n\nThe maximum representable value is $x_{max} = 2^{n-1}-1$. If $x = x_{max}$, then $x+1 = 2^{n-1}$, which is outside the representable range, causing an overflow. For any $x  x_{max}$, $x+1$ will be less than or equal to $x_{max}$ and thus will not overflow. The safety predicate is therefore the condition that $x$ is strictly less than the maximum possible value.\n\n$q = (x  2^{n-1}-1)$\n\nThe problem statement defines the predicate as $x \\in [-(2^{n-1}), (2^{n-1}-1) - 1]$. Since $x$ is given to be in the representable range $[-(2^{n-1}), 2^{n-1}-1]$, the lower bound check is implicitly satisfied. The upper bound check is $x \\leq (2^{n-1}-1) - 1$, which is equivalent to $x  2^{n-1}-1$. The predicate $q$ is a boolean that is true if this condition holds.\n\n3.  **PIL Model Output ($p$)**\n\nThe PIL environment models a physical processor using $n$-bit two's-complement signed integer arithmetic. In this system, addition is performed modulo $2^n$. The range of representable numbers is $[x_{min}, x_{max}]$, where $x_{min} = -(2^{n-1})$ and $x_{max} = 2^{n-1}-1$.\n\nFor most values of $x$, the computed value of $x+1$ in this system matches the mathematical result, and thus $x+1  x$ holds true. However, there is a critical exception at the upper boundary.\n\nWhen $x = x_{max} = 2^{n-1}-1$, the operation $x+1$ results in an overflow. In two's-complement arithmetic, the bit pattern for $x_{max}$ is a $0$ followed by $n-1$ ones ($011...1$). Adding $1$ to this pattern yields a $1$ followed by $n-1$ zeros ($100...0$), which is the representation of the minimum value, $x_{min} = -(2^{n-1})$.\n\nSo, for $x = 2^{n-1}-1$, the PIL evaluates:\n$(x+1)_{PIL} = -(2^{n-1})$\n\nThe comparison then becomes:\n$-(2^{n-1})  2^{n-1}-1$\n\nThis inequality is false. Thus, for $x = 2^{n-1}-1$, the PIL output is $p=0$. For all other representable values of $x$ (i.e., $x \\in [-(2^{n-1}), 2^{n-1}-2]$), the result of $x+1$ does not wrap around in this manner, and the comparison $x+1  x$ remains true, yielding $p=1$.\n\nThe implementation of this model can be achieved efficiently by utilizing the fixed-width integer types provided by the `numpy` library (e.g., `numpy.int32` for $n=32$), which naturally handle the wrap-around arithmetic characteristic of hardware processors.\n\n4.  **Divergence Flag ($d$)**\n\nThe divergence flag $d$ simply indicates whether the SIL and PIL models produce different outputs. It is a boolean value computed by the logical inequality $s \\neq p$. Based on the analysis above, divergence will occur if and only if $x = 2^{n-1}-1$, which is precisely the case where the static analysis predicate $q$ is false.\n\n$d = (s \\neq p)$\n\nThe program will iterate through the provided test cases. For each pair $(n, x)$, it will:\n- Set $s=1$.\n- Calculate $p$ by performing the addition and comparison using `numpy`'s fixed-width integer types corresponding to the bit-width $n$.\n- Calculate $d$ by comparing $s$ and $p$.\n- Calculate $q$ by comparing $x$ to the computed threshold $2^{n-1}-1$.\nThe final result is a list of these four-element lists.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are used.\n\ndef solve():\n    \"\"\"\n    Analyzes divergence between SIL and PIL models for the logic x+1  x.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (32, 0),\n        (32, 2**31 - 1),\n        (32, -1),\n        (16, 2**15 - 1),\n        (16, -2**15),\n    ]\n\n    results = []\n    for n, x in test_cases:\n        # 1. Calculate s: SIL (Software-in-the-Loop) output\n        # In mathematical integers, x+1  x is always true.\n        s = 1\n\n        # 2. Calculate p: PIL (Processor-in-the-Loop) output\n        # Model n-bit two's-complement signed integer arithmetic.\n        # numpy's fixed-width integers model hardware overflow correctly.\n        if n == 16:\n            dtype = np.int16\n        elif n == 32:\n            dtype = np.int32\n        else:\n            # As per problem constraints, only n=16 and n=32 are used.\n            # This is a fallback that would raise an error for other n.\n            raise ValueError(f\"Unsupported bit-width: {n}\")\n        \n        x_pil = dtype(x)\n        one_pil = dtype(1)\n        x_plus_1_pil = x_pil + one_pil\n        \n        # Perform the comparison in the PIL model.\n        if x_plus_1_pil  x_pil:\n            p = 1\n        else:\n            p = 0\n            \n        # 3. Calculate d: Divergence flag\n        # True if SIL and PIL outputs differ.\n        d = (s != p)\n        \n        # 4. Calculate q: Static analysis safety predicate\n        # Checks if x+1 would overflow in signed n-bit arithmetic.\n        # The condition is x  2**(n-1) - 1.\n        max_val = 2**(n - 1) - 1\n        q = (x  max_val)\n\n        results.append([s, p, d, q])\n\n    # Format the output string as a list of lists with no extra whitespace.\n    inner_strings = []\n    for res_list in results:\n        # Convert each element in the sublist to a string\n        # and join with commas.\n        inner_str = ','.join(map(str, res_list))\n        inner_strings.append(f\"[{inner_str}]\")\n    \n    # Join the inner list strings with commas and enclose in brackets.\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond simple verification, the PIL environment serves as a powerful platform for designing and validating advanced control strategies. This practice explores how a digital twin can be used proactively within a co-simulation scheme to actively compensate for inherent system latencies, such as processor computation delay. In this advanced exercise , you will implement a controller that leverages a digital twin to predict the future state of a plant, thereby enabling the control action to counteract the delay. By performing an optimization to find the ideal prediction horizon $h^{\\star}$, you will engage with a state-of-the-art technique for enhancing the performance of cyber-physical systems.",
            "id": "4236198",
            "problem": "Consider a single-input, single-output continuous-time Linear Time-Invariant (LTI) plant defined by the state equation $\\dot{x}(t) = a \\, x(t) + b \\, u(t)$ and the output $y(t) = x(t)$. A Digital Twin (DT), defined as a physics-based computational replica of the plant, is used within a Processor-in-the-Loop (PIL) simulation to predict future plant states in order to compensate for processor computation delay. The actuator command is updated at discrete sampling times $t_k = k \\, T_s$, where $T_s$ is the sampling period, via a Zero-Order Hold (ZOH). The processor imposes a computation delay of $\\tau_p$ seconds, which is strictly less than the sampling period $T_s$, i.e., $0 \\le \\tau_p  T_s$. At each sampling instant $t_k$, the controller computes a control input using a state-feedback law applied to a DT-predicted state at horizon $h \\in [0, \\tau_p]$; the newly computed control will be applied to the plant at time $t_k + \\tau_p$ due to the delay. The reference signal is a step $r(t) = r_0$ for all $t \\ge 0$.\n\nDesign a co-simulation scheme in which:\n- The plant is integrated continuously with piecewise-constant input under ZOH and delayed control application.\n- At each sampling time $t_k$, the DT predicts the plant state at future time $t_k + h$ assuming the input over $[t_k, t_k + h)$ remains equal to the currently applied plant input.\n- The controller computes $u_k$ using proportional state feedback on the DT-predicted state with gain $K$, and schedules $u_k$ to be applied at $t_k + \\tau_p$.\n- The tracking error is $e(t) = r_0 - y(t) = r_0 - x(t)$.\n\nFor a fixed set of parameters $(a,b,K,T_s,\\tau_p,r_0)$, define the performance index\n$$\nJ(h) = \\int_{0}^{T_{\\text{end}}} e(t)^2 \\, dt,\n$$\nwhere $T_{\\text{end}}$ is a finite horizon of interest. Your task is to compute, for each test case, the prediction horizon $h^\\star \\in [0, \\tau_p]$ that minimizes $J(h)$ subject to the constraint that the closed-loop response remains stable throughout $[0, T_{\\text{end}}]$ under the chosen co-simulation scheme. Declare the response unstable if the state magnitude $|x(t)|$ exceeds a large finite threshold at any time in $[0, T_{\\text{end}}]$.\n\nYou must implement the described co-simulation in a complete, runnable program that performs a grid search over $h \\in [0, \\tau_p]$ to approximate $h^\\star$ and returns the minimizing value among the stable cases. If no $h \\in [0, \\tau_p]$ yields a stable response, return a Not-a-Number indicator. All time quantities, including the returned $h^\\star$, must be expressed in seconds. The final reported horizons must be rounded to three decimal places.\n\nUse the following test suite, with all quantities in International System of Units (SI units):\n1. Case $1$ (happy path): $a = -2.0$, $b = 1.0$, $K = 3.0$, $T_s = 0.02$, $\\tau_p = 0.006$, $r_0 = 1.0$, $T_{\\text{end}} = 2.0$.\n2. Case $2$ (boundary delay): $a = -1.0$, $b = 1.0$, $K = 2.0$, $T_s = 0.01$, $\\tau_p = 0.0$, $r_0 = 1.0$, $T_{\\text{end}} = 1.0$.\n3. Case $3$ (near-sampling delay): $a = -1.5$, $b = 1.0$, $K = 2.5$, $T_s = 0.02$, $\\tau_p = 0.018$, $r_0 = 1.0$, $T_{\\text{end}} = 2.0$.\n4. Case $4$ (slow plant): $a = -0.5$, $b = 1.0$, $K = 1.0$, $T_s = 0.05$, $\\tau_p = 0.01$, $r_0 = 1.0$, $T_{\\text{end}} = 4.0$.\n\nAngle units are not applicable. Percentages are not applicable. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[h_1^\\star,h_2^\\star,h_3^\\star,h_4^\\star]$), where each $h_i^\\star$ is the minimizing prediction horizon for the corresponding case in seconds, rounded to three decimal places. If a case has no stable horizon, the corresponding entry must be a Not-a-Number indicator written as $\\text{nan}$.",
            "solution": "The problem is well-posed and scientifically grounded. It describes a standard Processor-In-the-Loop (PIL) co-simulation scenario for a digital control system with computational delay. The components, including the Linear Time-Invariant (LTI) plant, Zero-Order Hold (ZOH), state prediction for delay compensation, and performance index, are all standard concepts in control theory and cyber-physical systems. The task is to find an optimal prediction horizon $h$ that minimizes a quadratic error cost, subject to a stability constraint. This can be solved numerically through the specified co-simulation and grid search approach.\n\nThe control law is described as \"proportional state feedback on the DT-predicted state with gain $K$\". In a reference tracking context with error $e(t) = r_0 - x(t)$, this is interpreted as a proportional controller acting on the predicted tracking error. The control input $u_k$ computed at sampling time $t_k$ is therefore defined as:\n$$\nu_k = K(r_0 - x_{\\text{pred}}(t_k+h))\n$$\nwhere $x_{\\text{pred}}(t_k+h)$ is the Digital Twin's prediction of the plant state at time $t_k+h$. This form ensures the controller attempts to drive the plant state $x$ towards the reference $r_0$.\n\nThe solution approach is to implement a detailed co-simulation that accurately models the timing of events and then use this simulation to evaluate the performance index $J(h)$ for a grid of $h$ values. The optimal $h^\\star$ is the value that yields the minimum cost among all stable simulations.\n\n**1. Plant Dynamics and Exact Solution**\n\nThe plant is a first-order LTI system described by the state equation:\n$$\n\\dot{x}(t) = a \\, x(t) + b \\, u(t)\n$$\nGiven that the control input $u(t)$ is piecewise-constant due to the ZOH and delayed application, we can find an exact solution for the state evolution over any interval $[t_i, t_f]$ where the input is a constant $u_{\\text{const}}$. The solution is:\n$$\nx(t_f) = e^{a(t_f-t_i)} x(t_i) + \\int_{t_i}^{t_f} e^{a(t_f-\\tau)} b \\, u_{\\text{const}} \\, d\\tau\n$$\nEvaluating the integral, we obtain the state update equation for a time step $\\Delta t = t_f - t_i$. For $a \\neq 0$:\n$$\nx(t_i + \\Delta t) = e^{a \\Delta t} x(t_i) + \\frac{b}{a} (e^{a \\Delta t} - 1) u_{\\text{const}}\n$$\nThis formula will be used to propagate the plant state between events, avoiding numerical integration errors.\n\n**2. Co-Simulation Algorithm**\n\nThe simulation must capture the precise sequence of events within each sampling period $T_s$. Let $t_k = k T_s$ for $k = 0, 1, 2, \\dots$. The state at time $t_k$ is $x(t_k)$. Let $u_{k-1}$ be the control value computed at $t_{k-1}$ and applied to the plant from $t_{k-1}+\\tau_p$ onwards.\n\nThe simulation proceeds iteratively for each sampling interval $[t_k, t_{k+1})$:\n\n- **Step A: Controller Action at $t_k$**\n  1.  **DT Prediction**: The controller predicts the plant state at the future time $t_k+h$. The problem specifies that this prediction uses the state at time $t_k$, which is $x(t_k)$, and assumes the input over the horizon $[t_k, t_k+h)$ is the one currently being applied to the plant. At time $t_k$, the active plant input is $u_{k-1}$. The predicted state is therefore:\n      $$\n      x_{\\text{pred}}(t_k+h) = e^{ah} x(t_k) + \\frac{b}{a} (e^{ah} - 1) u_{k-1}\n      $$\n  2.  **Control Computation**: A new control value, $u_k$, is computed using the proportional feedback law on the predicted error:\n      $$\n      u_k = K(r_0 - x_{\\text{pred}}(t_k+h))\n      $$\n      This value $u_k$ is scheduled for application at time $t_k + \\tau_p$.\n\n- **Step B: Plant Evolution over $[t_k, t_{k+1})$**\n  The plant state evolves over two distinct sub-intervals due to the delayed control application.\n  1.  **Interval $[t_k, t_k + \\tau_p)$**: The input to the plant remains $u_{k-1}$. The state evolves from $x(t_k)$ to $x(t_k + \\tau_p)$:\n      $$\n      x(t_k + \\tau_p) = e^{a\\tau_p} x(t_k) + \\frac{b}{a} (e^{a\\tau_p} - 1) u_{k-1}\n      $$\n  2.  **Interval $[t_k + \\tau_p, t_{k+1})$**: At time $t_k + \\tau_p$, the actuator applies the new control $u_k$. The plant evolves under this new input for a duration of $T_s - \\tau_p$. The state at the next sampling instant, $x(t_{k+1})$, is:\n      $$\n      x(t_{k+1}) = e^{a(T_s - \\tau_p)} x(t_k + \\tau_p) + \\frac{b}{a} (e^{a(T_s - \\tau_p)} - 1) u_k\n      $$\n\nThe simulation starts at $t=0$ with $x(0)=0$ and an initial control input of $u_{-1}=0$. The loop continues until $t$ reaches $T_{\\text{end}}$.\n\n**3. Performance Index Calculation**\n\nThe performance index is the integrated squared error:\n$$\nJ(h) = \\int_{0}^{T_{\\text{end}}} e(t)^2 \\, dt = \\int_{0}^{T_{\\text{end}}} (r_0 - x(t))^2 \\, dt\n$$\nTo compute this integral accurately, we sum the contributions from each sub-interval where the control input $u$ is constant. Over an interval of duration $\\Delta t$ starting at time $t_i$ with initial state $x(t_i)$ and constant input $u_{\\text{const}}$, the state trajectory is $x(t) = (x(t_i) - x_{ss}) e^{a(t-t_i)} + x_{ss}$, where $x_{ss} = -b/a \\cdot u_{\\text{const}}$ is the steady-state value for that input.\n\nLet $\\tau = t - t_i$. The error is $e(\\tau) = r_0 - x(\\tau) = (r_0 - x_{ss}) - (x(t_i) - x_{ss})e^{a\\tau}$. Let $C_A = r_0 - x_{ss}$ and $C_B = -(x(t_i) - x_{ss})$. The integral of the squared error over $[0, \\Delta t]$ is:\n$$\n\\int_{0}^{\\Delta t} (C_A + C_B e^{a\\tau})^2 \\, d\\tau = \\int_{0}^{\\Delta t} (C_A^2 + 2C_A C_B e^{a\\tau} + C_B^2 e^{2a\\tau}) \\, d\\tau\n$$\nFor $a \\neq 0$, the exact value of this definite integral is:\n$$\n\\left[ C_A^2 \\tau + \\frac{2C_A C_B}{a} e^{a\\tau} + \\frac{C_B^2}{2a} e^{2a\\tau} \\right]_0^{\\Delta t} = C_A^2 \\Delta t + \\frac{2C_A C_B}{a} (e^{a\\Delta t} - 1) + \\frac{C_B^2}{2a} (e^{2a\\Delta t} - 1)\n$$\nThe total cost $J(h)$ is the sum of these integrals calculated for each sub-interval in the simulation from $t=0$ to $t=T_{\\text{end}}$.\n\n**4. Optimization and Stability**\n\nTo find the optimal prediction horizon $h^\\star$, a grid search is performed over the interval $h \\in [0, \\tau_p]$. For each value of $h$ in the grid:\n- A full co-simulation is run from $t=0$ to $t=T_{\\text{end}}$.\n- During the simulation, the magnitude of the state, $|x(t)|$, is monitored. If it exceeds a large predefined threshold (e.g., $10^6$), the system is declared unstable for that $h$, and the cost is considered infinite.\n- If the simulation completes without instability, the total cost $J(h)$ is computed.\n\nAfter evaluating all $h$ values, the one corresponding to the minimum finite cost is chosen as the optimal horizon $h^\\star$. If all simulations are unstable, no solution exists for the given parameters, and the result is Not-a-Number (nan).",
            "answer": "```python\nimport numpy as np\n\ndef state_update(x_start, u, a, b, dt):\n    \"\"\"\n    Calculates the exact state of the LTI system after a time step dt\n    with constant input u.\n    \"\"\"\n    if dt = 0:\n        return x_start\n    \n    # Handle the case where a is close to zero to avoid division errors.\n    if abs(a)  1e-9:\n        return x_start + b * u * dt\n    else:\n        eadt = np.exp(a * dt)\n        return eadt * x_start + (b / a) * (eadt - 1) * u\n\ndef cost_integral(t_start, t_end, x_start, u, a, b, r0):\n    \"\"\"\n    Calculates the exact integral of the squared error (r0 - x(t))^2\n    over the interval [t_start, t_end].\n    \"\"\"\n    dt = t_end - t_start\n    if dt = 0:\n        return 0.0\n\n    if abs(a)  1e-9:\n        # e(t) = r0 - (x_start + b*u*(t-t_start))\n        # Let tau = t-t_start. e(tau) = (r0 - x_start) - b*u*tau\n        # Integrate (C1 - C2*tau)^2 dtau from 0 to dt\n        c1 = r0 - x_start\n        c2 = b * u\n        term1 = c1**2 * dt\n        term2 = -c1 * c2 * dt**2\n        term3 = (c2**2 / 3.0) * dt**3\n        return term1 + term2 + term3\n    else:\n        x_ss = -b * u / a\n        c_a = r0 - x_ss\n        c_b = -(x_start - x_ss)\n\n        eadt = np.exp(a * dt)\n        \n        term1 = c_a**2 * dt\n        term2 = (2 * c_a * c_b / a) * (eadt - 1)\n        \n        # Handle the case where a is close to zero for the 2a term.\n        # This case is already handled by the outer if, but for robustness:\n        if abs(2 * a)  1e-9:\n             # Taylor expansion of (exp(2*a*dt)-1)/(2a) - dt\n             term3 = c_b**2 * dt\n        else:\n             e2adt = np.exp(2 * a * dt)\n             term3 = (c_b**2 / (2 * a)) * (e2adt - 1)\n        \n        return term1 + term2 + term3\n\ndef run_simulation(a, b, K, Ts, tau_p, r0, Tend, h):\n    \"\"\"\n    Runs the co-simulation for a given set of parameters and prediction horizon h.\n    \"\"\"\n    instability_threshold = 1e6\n    \n    t = 0.0\n    x = 0.0\n    total_cost = 0.0\n    \n    # u_prev_period represents u_{k-1}. Initially, control before t=0 was 0.\n    u_prev_period = 0.0\n    \n    k = 0\n    while t  Tend:\n        t_k = k * Ts\n        \n        # --- Controller action at t_k ---\n        # 1. Prediction: predict x(t_k + h) using state x(t_k) and input u_{k-1}.\n        x_pred = state_update(x, u_prev_period, a, b, h)\n        \n        # 2. Control computation: compute u_k = K(r0 - x_pred).\n        u_k = K * (r0 - x_pred)\n        \n        # --- Plant evolution over [t_k, t_{k+1}) ---\n        \n        # Sub-interval 1: [t_k, t_k + tau_p). Plant input is u_{k-1}.\n        t_start1 = t_k\n        t_end1 = min(t_k + tau_p, Tend)\n        dt1 = t_end1 - t_start1\n        \n        if dt1  1e-12: # Check for non-zero interval\n            total_cost += cost_integral(t_start1, t_end1, x, u_prev_period, a, b, r0)\n            x = state_update(x, u_prev_period, a, b, dt1)\n            t = t_end1\n            \n            if abs(x)  instability_threshold:\n                return np.inf\n            if t = Tend:\n                break\n                \n        # Sub-interval 2: [t_k + tau_p, t_{k+1}). Plant input is u_k.\n        t_start2 = t_k + tau_p\n        t_end2 = min(t_k + Ts, Tend)\n        dt2 = t_end2 - t_start2\n\n        if dt2  1e-12: # Check for non-zero interval\n            total_cost += cost_integral(t_start2, t_end2, x, u_k, a, b, r0)\n            x = state_update(x, u_k, a, b, dt2)\n            t = t_end2\n\n            if abs(x)  instability_threshold:\n                return np.inf\n            if t = Tend:\n                break\n        \n        # Prepare for next iteration\n        u_prev_period = u_k\n        k += 1\n            \n    return total_cost\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    # Test cases: (a, b, K, Ts, tau_p, r0, Tend)\n    test_cases = [\n        (-2.0, 1.0, 3.0, 0.02, 0.006, 1.0, 2.0),\n        (-1.0, 1.0, 2.0, 0.01, 0.0, 1.0, 1.0),\n        (-1.5, 1.0, 2.5, 0.02, 0.018, 1.0, 2.0),\n        (-0.5, 1.0, 1.0, 0.05, 0.01, 1.0, 4.0),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        a, b, K, Ts, tau_p, r0, Tend = case\n        \n        # Create a grid of h values to search over.\n        # Use 101 points for adequate resolution.\n        if tau_p == 0.0:\n            h_values = np.array([0.0])\n        else:\n            h_values = np.linspace(0.0, tau_p, 101)\n        \n        costs = []\n        stable_h = []\n\n        for h in h_values:\n            cost = run_simulation(a, b, K, Ts, tau_p, r0, Tend, h)\n            if not np.isinf(cost):\n                costs.append(cost)\n                stable_h.append(h)\n        \n        if not stable_h:\n            results.append('nan')\n        else:\n            min_cost_idx = np.argmin(costs)\n            h_star = stable_h[min_cost_idx]\n            # Format to 3 decimal places. f-string formatting handles rounding.\n            results.append(f\"{h_star:.3f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}