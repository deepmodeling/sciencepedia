{
    "hands_on_practices": [
        {
            "introduction": "在我们信任卡尔曼 (Kalman) 滤波器的估计结果之前，必须确保滤波器本身是稳定的。一个不稳定的滤波器不仅无法提供有用的信息，其内部状态（如误差协方差）甚至可能增长到无穷大。本练习通过编程仿真，引导您探索“可检测性” (detectability) 这一核心概念，并亲眼见证一个未被观测到的不稳定系统状态如何导致估计器发生灾难性的发散 。",
            "id": "4228697",
            "problem": "一个离散时间线性时不变信息物理估计问题涉及一个系统，其状态向量 $x_k \\in \\mathbb{R}^n$ 演化为 $x_{k+1} = A x_k + w_k$，输出为 $y_k = C x_k + v_k$，其中 $A \\in \\mathbb{R}^{n \\times n}$，$C \\in \\mathbb{R}^{p \\times n}$，$w_k$ 和 $v_k$ 是零均值高斯白噪声，其协方差分别为 $Q \\succ 0$ 和 $R \\succ 0$。考虑在信息物理系统的数字孪生中使用卡尔曼滤波器 (KF) 进行状态估计。如果每个不可观测模态都是稳定的，则称系统对 $(A,C)$ 是可检测的，这等价于 $A$ 的每个满足 $|\\lambda| \\ge 1$ 的特征值 $\\lambda$ 都是可被 $C$ 观测的。当因为存在一个不稳定的不可观测模态导致 $(A,C)$ 不可检测时，与 KF 相关的协方差递归可能会发散。\n\n你的任务是通过直接仿真和验证，严格地证明当一个不稳定模态不可观测时，协方差里卡提递归会发散；而当所有不稳定模态都可观测，或者当不可观测模态是稳定时，该递归会保持有界。你必须为给定的参数集实现离散时间卡尔曼协方差递归，并自动评估其发散性。这里不提供公式；你的程序必须依赖第一性原理和经过充分检验的事实来构建正确的递归。\n\n实现一个程序，该程序：\n- 用给定的协方差 $P_0 \\succeq 0$ 初始化，并对离散时间卡尔曼协方差递归进行 $N$ 步迭代。\n- 如果在任何迭代 $k \\in \\{1,\\dots,N\\}$ 中，协方差 $P_k$ 的最大特征值超过了预设阈值 $\\tau$，或者 $P_k$ 失去有限性（例如，包含 $\\infty$ 或 $\\text{NaN}$），则声明为发散。\n- 为每个测试用例返回一个布尔值，表示发散 (true) 或有界 (false)。\n\n使用以下测试套件，其中状态数 $n=2$，标量输出 $p=1$，并具有共同的噪声协方差和初始协方差：\n- $Q = \\operatorname{diag}(q_1, q_2)$，其中 $q_1 = 0.01$，$q_2 = 0.01$。\n- $R = [r]$，其中 $r = 0.1$。\n- $P_0 = I_2$。\n- $N = 200$ 次迭代。\n- 发散阈值 $\\tau = 10^{12}$。\n\n测试用例：\n1. 不可检测，具有一个不稳定的不可观测模态：\n   - $A = \\begin{bmatrix} 1.2  0.0 \\\\ 0.0  0.9 \\end{bmatrix}$，$C = \\begin{bmatrix} 0.0  1.0 \\end{bmatrix}$。\n   - 特征值为 $1.2$ 的不稳定模态是不可观测的，因为它完全位于与测量正交的子空间中。\n2. 可检测，具有一个不稳定的可观测模态：\n   - $A = \\begin{bmatrix} 1.2  0.0 \\\\ 0.0  0.9 \\end{bmatrix}$，$C = \\begin{bmatrix} 1.0  0.0 \\end{bmatrix}$。\n   - 特征值为 $1.2$ 的不稳定模态是可观测的。\n3. 不可观测但稳定的模态：\n   - $A = \\begin{bmatrix} 0.95  0.0 \\\\ 0.0  0.7 \\end{bmatrix}$，$C = \\begin{bmatrix} 1.0  0.0 \\end{bmatrix}$。\n   - 所有模态都是稳定的；第二个模态是不可观测的，但没有违反可检测性。\n\n你的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[result_1,result_2,result_3]$），其中每个 $result_i$ 是一个用小写字母表示的布尔值，指示相应的测试用例是发散 (true) 还是保持有界 (false)。此任务不涉及物理单位或角度，答案应如上所述为布尔值。你的实现必须是自包含的，不需要任何输入，并遵守指定的运行时环境。",
            "solution": "该问题要求通过直接仿真来证明卡尔曼滤波的一个基本原理：滤波器误差协方差矩阵的有界性取决于系统的可检测性。我们将首先建立理论基础，然后描述用于验证的算法实现。\n\n一个离散时间线性时不变系统由状态方程和测量方程定义：\n$$\nx_{k+1} = A x_k + w_k\n$$\n$$\ny_k = C x_k + v_k\n$$\n其中 $x_k \\in \\mathbb{R}^n$ 是状态向量，$y_k \\in \\mathbb{R}^p$ 是测量向量，$A \\in \\mathbb{R}^{n \\times n}$ 是状态转移矩阵，$C \\in \\mathbb{R}^{p \\times n}$ 是测量矩阵。过程噪声 $w_k$ 和测量噪声 $v_k$ 是零均值高斯白过程，其协方差矩阵分别为 $Q \\succ 0$ 和 $R \\succ 0$。\n\n卡尔曼滤波器提供对状态 $x_k$ 的最优估计。滤波器的性能由误差协方差矩阵 $P_k = E[(x_k - \\hat{x}_{k|k})(x_k - \\hat{x}_{k|k})^T]$ 来表征，其中 $\\hat{x}_{k|k}$ 是在时间 $k$ 的后验状态估计。$P_k$ 的演化由离散时间矩阵里卡提递归控制。从一个初始协方差 $P_0$ 开始，对于 $k=1, 2, \\dots, N$ 的递归是一个两步过程：\n\n1.  **时间更新（预测）：** 误差协方差随时间向前传播。先验协方差 $P_{k|k-1}$ 是根据上一步的后验协方差 $P_{k-1|k-1}$ 计算得出的。\n    $$\n    P_{k|k-1} = A P_{k-1|k-1} A^T + Q\n    $$\n\n2.  **测量更新（校正）：** 使用来自测量 $y_k$ 的信息来校正先验协方差。得到的后验协方差 $P_{k|k}$ 由以下公式给出：\n    $$\n    P_{k|k} = P_{k|k-1} - P_{k|k-1} C^T (C P_{k|k-1} C^T + R)^{-1} C P_{k|k-1}\n    $$\n这种形式等价于 Joseph 形式 $P_{k|k} = (I - K_k C)P_{k|k-1}$，其中 $K_k$ 是卡尔曼增益，并且在精确算术下，它能保持协方差矩阵的对称性和半正定性。\n\n估计理论中的一个基石定理指出，误差协方差递归 $P_k$ 收敛到一个唯一的、有限的、半正定的稳态解 $P_\\infty$ 的充分必要条件是系统对 $(A, C)$ 是可检测的，且系统对 $(A, Q^{1/2})$ 是可镇定的。如果 $A$ 的每个不可观测模态都是稳定的，则系统 $(A, C)$ 是可检测的。一个与 $A$ 的特征值 $\\lambda$ 对应的模态，如果 $|\\lambda|  1$ 则是稳定的，如果 $|\\lambda| \\ge 1$ 则是不稳定的。一个与 $\\lambda$ 相关的特征向量 $v$ 如果位于测量矩阵的零空间中，即 $C v = 0$，则对应一个不可观测的模态。\n\n在所有提供的测试用例中，过程噪声协方差 $Q$ 是一个具有严格正元素的对角矩阵，这意味着 $Q \\succ 0$。这确保了系统对 $(A, Q^{1/2})$ 是可控的（一个比可镇定更强的条件）。因此，里卡提递归的收敛性和有界性仅取决于系统对 $(A, C)$ 的可检测性。\n\n任务是针对三种特定情况仿真此递归过程，并验证理论预测。发散被定义为 $P_k$ 的最大特征值超过阈值 $\\tau = 10^{12}$ 或 $P_k$ 包含非有限值。\n\n**测试用例分析：**\n共同参数为 $n=2$, $p=1$, $Q = \\operatorname{diag}(0.01, 0.01)$, $R = [0.1]$, $P_0 = I_2$, $N=200$, 以及 $\\tau = 10^{12}$。\n\n**情况 1：** $A = \\begin{bmatrix} 1.2  0.0 \\\\ 0.0  0.9 \\end{bmatrix}$，$C = \\begin{bmatrix} 0.0  1.0 \\end{bmatrix}$。\n$A$ 的特征值为 $\\lambda_1 = 1.2$ 和 $\\lambda_2 = 0.9$。与 $\\lambda_1 = 1.2$ 相关的模态是不稳定的。对应的特征向量是 $v_1 = [1.0, 0.0]^T$。我们测试其可观测性：\n$$\nC v_1 = \\begin{bmatrix} 0.0  1.0 \\end{bmatrix} \\begin{bmatrix} 1.0 \\\\ 0.0 \\end{bmatrix} = 0.0\n$$\n由于 $C v_1 = 0$，该不稳定模态是不可观测的。系统是不可检测的。根据理论，误差协方差 $P_k$ 预计会发散。未被观测且不稳定的状态的方差将无界增长。仿真结果应为 `true`。\n\n**情况 2：** $A = \\begin{bmatrix} 1.2  0.0 \\\\ 0.0  0.9 \\end{bmatrix}$，$C = \\begin{bmatrix} 1.0  0.0 \\end{bmatrix}$。\n不稳定的模态同样在 $\\lambda_1 = 1.2$ 处，其特征向量为 $v_1 = [1.0, 0.0]^T$。我们测试其可观测性：\n$$\nC v_1 = \\begin{bmatrix} 1.0  0.0 \\end{bmatrix} \\begin{bmatrix} 1.0 \\\\ 0.0 \\end{bmatrix} = 1.0 \\neq 0.0\n$$\n该不稳定模态是可观测的。另一个模态 $\\lambda_2=0.9$ 是稳定的。由于所有不稳定的模态都是可观测的，系统是可检测的。理论预测 $P_k$ 将收敛到一个有限的稳态值。仿真结果应为 `false`。\n\n**情况 3：** $A = \\begin{bmatrix} 0.95  0.0 \\\\ 0.0  0.7 \\end{bmatrix}$，$C = \\begin{bmatrix} 1.0  0.0 \\end{bmatrix}$。\n$A$ 的特征值为 $\\lambda_1 = 0.95$ 和 $\\lambda_2 = 0.7$。由于 $|\\lambda_i|  1$，两个模态都是稳定的。对应于 $\\lambda_2 = 0.7$ 的特征向量是 $v_2 = [0.0, 1.0]^T$。我们测试其可观测性：\n$$\nC v_2 = \\begin{bmatrix} 1.0  0.0 \\end{bmatrix} \\begin{bmatrix} 0.0 \\\\ 1.0 \\end{bmatrix} = 0.0\n$$\n与 $\\lambda_2=0.7$ 相关的模态是不可观测的。然而，由于这个不可观测的模态是稳定的，可检测性的条件得到了满足。系统是可检测的。因此，误差协方差 $P_k$ 将保持有界并收敛。仿真结果应为 `false`。\n\n程序将实现协方差递归，并在所有三种情况下对 $N=200$ 次迭代中的每一步测试发散条件。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not used as per the specified environment\n\ndef solve():\n    \"\"\"\n    Simulates the discrete-time Kalman covariance recursion for three test cases\n    to demonstrate the effect of system detectability on filter stability.\n    \"\"\"\n    \n    # Common parameters for all test cases\n    Q = np.diag([0.01, 0.01])\n    R = np.array([[0.1]])\n    P0 = np.identity(2)\n    N = 200\n    tau = 1.0e12\n\n    # Test cases defined by the problem statement\n    test_cases = [\n        {\n            \"name\": \"Not detectable with an unstable unobservable mode\",\n            \"A\": np.array([[1.2, 0.0], [0.0, 0.9]]),\n            \"C\": np.array([[0.0, 1.0]]),\n        },\n        {\n            \"name\": \"Detectable with an unstable observable mode\",\n            \"A\": np.array([[1.2, 0.0], [0.0, 0.9]]),\n            \"C\": np.array([[1.0, 0.0]]),\n        },\n        {\n            \"name\": \"Unobservable but stable mode\",\n            \"A\": np.array([[0.95, 0.0], [0.0, 0.7]]),\n            \"C\": np.array([[1.0, 0.0]]),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        A = case[\"A\"]\n        C = case[\"C\"]\n        \n        # Initialize the posteriori covariance\n        P = P0.copy()\n        \n        diverged = False\n        for _ in range(N):\n            # 1. Time Update (Prediction)\n            P_predict = A @ P @ A.T + Q\n            \n            # 2. Measurement Update (Correction)\n            # Innovation covariance\n            S = C @ P_predict @ C.T + R\n            \n            # Check for non-invertibility, though R > 0 should prevent this\n            if np.linalg.det(S) == 0:\n                diverged = True\n                break\n\n            # Kalman Gain\n            K = P_predict @ C.T @ np.linalg.inv(S)\n\n            # Update posteriori covariance using the standard form (I - KC)P_predict\n            # This is computationally efficient and sufficient here.\n            # Joseph form P = (I - K@C)@P_predict@(I - K@C).T + K@R@K.T could be used\n            # for better numerical stability in general, but is not necessary for this problem.\n            I = np.identity(P.shape[0])\n            P = (I - K @ C) @ P_predict\n            \n            # 3. Check for divergence\n            # Check for non-finite values (inf or nan)\n            if not np.all(np.isfinite(P)):\n                diverged = True\n                break\n                \n            # Check if the largest eigenvalue exceeds the threshold.\n            # Use eigvalsh for real symmetric matrices. P should be symmetric.\n            try:\n                # Add a small stabilization term to ensure P remains symmetric under floating-point arithmetic\n                P = (P + P.T) / 2.0\n                eigenvalues = np.linalg.eigvalsh(P)\n                if np.max(eigenvalues) > tau:\n                    diverged = True\n                    break\n            except np.linalg.LinAlgError:\n                # This can happen if P becomes non-finite or badly scaled\n                diverged = True\n                break\n\n        # Append the boolean result (True for divergence, False for boundedness)\n        results.append(str(diverged).lower())\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "理解了滤波器稳定性的前提条件后，让我们深入探究测量更新步骤的“魔力”所在。本练习将剖析一个新的测量值如何降低系统状态的不确定性，并通过编程实践证明这种不确定性的“缩减”仅发生在状态空间的“可观测” (observable) 子空间内。此外，本练习还将这一概念推广到非线性系统，通过实现扩展卡尔曼滤波器 (Extended Kalman Filter, EKF) 的更新步骤，展示如何处理实际工程中更常见的非线性模型 。",
            "id": "4228745",
            "problem": "考虑一个离散时间、线性、时不变的高斯状态空间模型，该模型构成了信息物理系统数字孪生的典型基础。该模型由状态动力学和测量方程定义\n$$\nx_{k+1} = A x_k + w_k,\\quad y_k = C x_k + v_k,\n$$\n其中 $x_k \\in \\mathbb{R}^n$ 是状态，$y_k \\in \\mathbb{R}^m$ 是测量值，$w_k \\sim \\mathcal{N}(0,Q)$ 是过程噪声，$v_k \\sim \\mathcal{N}(0,R)$ 是测量噪声。假设 $A \\in \\mathbb{R}^{n \\times n}$，$C \\in \\mathbb{R}^{m \\times n}$，$Q \\in \\mathbb{R}^{n \\times n}$，$R \\in \\mathbb{R}^{m \\times m}$，并且先验协方差 $P^- \\in \\mathbb{R}^{n \\times n}$ 是已知的。Kalman 滤波器更新必须基于高斯条件化的第一性原理进行构建，不得使用问题陈述中任何预先引用的公式。\n\n将在一个测量步骤中的瞬时可观测子空间定义为 $\\mathbb{R}^n$ 中 $C^\\top$ 的列空间。令 $V \\in \\mathbb{R}^{n \\times n}$ 为通过对 $C$ 进行奇异值分解得到的标准正交基，并令 $r$ 为 $C$ 的秩。用 $V_r \\in \\mathbb{R}^{n \\times r}$ 表示 $V$ 的前 $r$ 列，它们张成了可观测子空间，并将到可观测和不可观测子空间的正交投影定义为\n$$\n\\Pi_{\\mathrm{obs}} = V_r V_r^\\top,\\quad \\Pi_{\\mathrm{unobs}} = I_n - \\Pi_{\\mathrm{obs}}.\n$$\n对于单步测量更新，令 $P^+$ 表示在给定时间步长并入测量值后的后验误差协方差。将总协方差收缩以及限制在可观测和不可观测子空间上的收缩定义为\n$$\n\\Delta_{\\mathrm{tot}} = \\operatorname{tr}(P^-) - \\operatorname{tr}(P^+),\n$$\n$$\n\\Delta_{\\mathrm{obs}} = \\operatorname{tr}\\!\\big(\\Pi_{\\mathrm{obs}} P^- \\Pi_{\\mathrm{obs}}\\big) - \\operatorname{tr}\\!\\big(\\Pi_{\\mathrm{obs}} P^+ \\Pi_{\\mathrm{obs}}\\big),\\quad\n\\Delta_{\\mathrm{unobs}} = \\operatorname{tr}\\!\\big(\\Pi_{\\mathrm{unobs}} P^- \\Pi_{\\mathrm{unobs}}\\big) - \\operatorname{tr}\\!\\big(\\Pi_{\\mathrm{unobs}} P^+ \\Pi_{\\mathrm{unobs}}\\big).\n$$\n将在可观测子空间上集中的收缩分数定义为\n$$\ns_{\\mathrm{obs}} = \n\\begin{cases}\n\\dfrac{\\Delta_{\\mathrm{obs}}}{\\Delta_{\\mathrm{tot}}},  \\text{if } \\Delta_{\\mathrm{tot}}  \\varepsilon,\\\\\n0,  \\text{otherwise},\n\\end{cases}\n$$\n其中 $\\varepsilon  0$ 是一个很小的数值容差，并类似地将 $s_{\\mathrm{unobs}}$ 定义为不可观测子空间的分数。\n\n您的任务是基于第一性原理实现以下内容：\n1. 源自高斯条件化的单步线性 Kalman 滤波器协方差更新。\n2. 使用 $C$ 的奇异值分解（或对于非线性测量使用雅可比矩阵）构建 $\\Pi_{\\mathrm{obs}}$ 和 $\\Pi_{\\mathrm{unobs}}$。\n3. 计算下面每个指定测试用例的 $s_{\\mathrm{obs}}$。\n\n此外，为了处理与现实世界信息物理系统数字孪生一致的非线性变体，考虑一个非线性测量 $y_k = h(x_k) + v_k$。通过在指定的线性化点 $x^\\ast$ 对 $h$ 进行线性化以获得其雅可比矩阵 $H(x^\\ast)$，然后将 $H(x^\\ast)$ 视为协方差更新中的测量矩阵，来实现扩展 Kalman 滤波器 (EKF) 的单步协方差更新。使用 $H(x^\\ast)$ 的奇异值分解来构建 $\\Pi_{\\mathrm{obs}}$。\n\n使用以下测试套件，其中所有矩阵和向量均以数值方式指定。在所有情况下，计算单步后验协方差 $P^+$，构建 $\\Pi_{\\mathrm{obs}}$，并以浮点数形式返回 $s_{\\mathrm{obs}}$。\n\n测试用例：\n- 用例 1 (理想情况，块对角，部分可观测，线性)：\n  - $n=4$, $m=2$。\n  - $C = \\begin{bmatrix}1  0  0  0\\\\ 0  1  0  0\\end{bmatrix}$。\n  - $P^- = \\operatorname{diag}(1,1,1,1)$。\n  - $R = 0.05 I_2$。\n- 用例 2 (跨子空间的相关先验，线性)：\n  - $n=4$, $m=2$。\n  - $C = \\begin{bmatrix}1  0  0  0\\\\ 0  1  0  0\\end{bmatrix}$。\n  - 构建 $S \\in \\mathbb{R}^{4 \\times 4}$ 为\n    $S = \\begin{bmatrix}\n    1  0.2  0.1  0.1\\\\\n    0  1.0  0.2  0.1\\\\\n    0  0  1.0  0.3\\\\\n    0  0  0  1.0\n    \\end{bmatrix}$，\n    并设置 $P^- = S S^\\top$。\n  - $R = 0.10 I_2$。\n- 用例 3 (极度嘈杂的测量，线性，边界情况)：\n  - $n=4$, $m=2$。\n  - $C = \\begin{bmatrix}1  0  0  0\\\\ 0  1  0  0\\end{bmatrix}$。\n  - $P^- = \\operatorname{diag}(1,1,1,1)$。\n  - $R = 1000 I_2$。\n- 用例 4 (使用扩展 Kalman 滤波器的非线性测量，秩亏雅可比矩阵)：\n  - $n=3$, $m=2$。\n  - $h(x) = \\begin{bmatrix}\\sin(x_1)\\\\ \\sin(x_1)\\end{bmatrix}$。\n  - 在 $x^\\ast = \\begin{bmatrix}0\\\\ 0\\\\ 0\\end{bmatrix}$ 处线性化以获得 $H(x^\\ast)$。\n  - $P^- = \\operatorname{diag}(1,1,1)$。\n  - $R = 0.05 I_2$。\n\n角度单位不适用。无需物理单位。所有计算输出均为无量纲浮点数。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，\\\"[result1,result2,result3,result4]\\\"），其中每个条目是相应测试用例的 $s_{\\mathrm{obs}}$，四舍五入到六位小数。在确定 $s_{\\mathrm{obs}}$ 定义中的分母条件时，使用数值容差 $\\varepsilon = 10^{-12}$。",
            "solution": "该问题要求从高斯条件化的第一性原理出发，推导单步 Kalman 滤波器协方差更新，并应用它来分析状态空间模型的可观测和不可观测子空间之间的协方差收缩分布。该分析将针对线性模型和通过扩展 Kalman 滤波器 (EKF) 框架的非线性模型进行。\n\n首先，我们推导后验协方差更新。我们考虑一个状态 $x \\in \\mathbb{R}^n$ 和一个测量值 $y \\in \\mathbb{R}^m$。关于状态的先验信念由高斯分布 $x \\sim \\mathcal{N}(\\hat{x}^-, P^-)$ 建模，其中 $\\hat{x}^-$ 是先验均值， $P^-$ 是先验误差协方差。测量值通过线性模型 $y = C x + v$ 与状态相关联，其中测量噪声 $v \\sim \\mathcal{N}(0, R)$ 是一个均值为零、协方差为 $R$ 的高斯随机变量，并假设其与状态 $x$ 独立。\n\n贝叶斯更新的核心是找到在给定 $y$ 的观测值时 $x$ 的条件分布。为此，我们构造一个增广随机向量 $z = [x^\\top, y^\\top]^\\top$。由于 $x$ 和 $v$ 是联合高斯分布（因为它们是独立的），并且 $y$ 是它们的线性变换，所以增广向量 $z$ 也是高斯分布的。我们接下来求其均值和协方差。\n\n增广向量的均值为：\n$$\n\\mathbb{E}[z] = \n\\begin{bmatrix}\n\\mathbb{E}[x] \\\\\n\\mathbb{E}[y]\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\hat{x}^- \\\\\n\\mathbb{E}[C x + v]\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\hat{x}^- \\\\\nC \\mathbb{E}[x] + \\mathbb{E}[v]\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\hat{x}^- \\\\\nC \\hat{x}^-\n\\end{bmatrix}\n$$\n\n增广向量的协方差为：\n$$\n\\operatorname{Cov}(z) = \\Sigma_z =\n\\begin{bmatrix}\n\\operatorname{Cov}(x, x)  \\operatorname{Cov}(x, y) \\\\\n\\operatorname{Cov}(y, x)  \\operatorname{Cov}(y, y)\n\\end{bmatrix}\n$$\n这些块的计算如下：\n- $\\operatorname{Cov}(x, x) = P^-$ (先验协方差)。\n- $\\operatorname{Cov}(x, y) = \\operatorname{Cov}(x, C x + v) = \\operatorname{Cov}(x, C x) + \\operatorname{Cov}(x, v)$。由于 $x$ 和 $v$ 是独立的，$\\operatorname{Cov}(x, v) = 0$。因此，$\\operatorname{Cov}(x, y) = \\operatorname{Cov}(x, x) C^\\top = P^- C^\\top$。\n- $\\operatorname{Cov}(y, x) = (\\operatorname{Cov}(x, y))^\\top = C P^-$。\n- $\\operatorname{Cov}(y, y) = \\operatorname{Cov}(C x + v, C x + v) = \\operatorname{Cov}(C x, C x) + \\operatorname{Cov}(v, v) = C \\operatorname{Cov}(x, x) C^\\top + R = C P^- C^\\top + R$。此项被称为新息协方差，通常表示为 $S_k$。\n\n所以，联合分布为 $z \\sim \\mathcal{N}\\left(\n\\begin{bmatrix} \\hat{x}^- \\\\ C \\hat{x}^- \\end{bmatrix}, \n\\begin{bmatrix} P^-  P^- C^\\top \\\\ C P^-  C P^- C^\\top + R \\end{bmatrix}\n\\right)$。\n\n对于一个一般的已分块高斯向量 $z = [z_a^\\top, z_b^\\top]^\\top$，其协方差为 $\\Sigma = \\begin{bmatrix} \\Sigma_{aa}  \\Sigma_{ab} \\\\ \\Sigma_{ba}  \\Sigma_{bb} \\end{bmatrix}$，给定 $z_b$ 时 $z_a$ 的条件协方差由 $\\Sigma$ 中 $\\Sigma_{bb}$ 的舒尔补给出：\n$$\n\\operatorname{Cov}(z_a | z_b) = \\Sigma_{aa} - \\Sigma_{ab} \\Sigma_{bb}^{-1} \\Sigma_{ba}\n$$\n将此公式应用于我们的问题，我们确定 $z_a \\equiv x$ 和 $z_b \\equiv y$。因此，后验协方差 $P^+$，即在对测量值 $y$ 进行条件化之后的状态 $x$ 的协方差为：\n$$\nP^+ = P^- - (P^- C^\\top) (C P^- C^\\top + R)^{-1} (C P^-)\n$$\n这个方程是著名的 Kalman 滤波器协方差更新的 Joseph 形式。将 Kalman 增益定义为 $K = P^- C^\\top (C P^- C^\\top + R)^{-1}$，更新可以更紧凑地写为 $P^+ = P^- - K C P^-$。这就是我们将要实现的方程。\n\n问题进一步要求分析此更新如何影响不同状态子空间中的不确定性。测量步骤中的瞬时可观测子空间被定义为 $C^\\top$ 的列空间，这等价于 $C$ 的行空间。这是直接影响测量值 $y$ 的状态子空间。其正交补是不可观测子空间。\n为了构建这些子空间的标准正交基，我们使用测量矩阵 $C$ 的奇异值分解 (SVD)：$C = U \\Sigma_s V^\\top$。$V \\in \\mathbb{R}^{n \\times n}$ 的列构成了状态空间 $\\mathbb{R}^n$ 的一个标准正交基。如果 $C$ 的秩为 $r$，则 $V$ 的前 $r$ 列（表示为 $V_r \\in \\mathbb{R}^{n \\times r}$）张成 $C$ 的行空间（可观测子空间）。剩下的 $n-r$ 列张成 $C$ 的零空间（不可观测子空间）。到这些子空间上的正交投影矩阵是 $\\Pi_{\\mathrm{obs}} = V_r V_r^\\top$ 和 $\\Pi_{\\mathrm{unobs}} = I_n - \\Pi_{\\mathrm{obs}}$。\n\n不确定性的总减少量，即协方差收缩，是协方差矩阵迹的减少量：$\\Delta_{\\mathrm{tot}} = \\operatorname{tr}(P^-) - \\operatorname{tr}(P^+)$。我们希望将这个总收缩分解到位于可观测和不可观测子空间中的分量。投影协方差是 $\\Pi_{\\mathrm{obs}} P \\Pi_{\\mathrm{obs}}$ 和 $\\Pi_{\\mathrm{unobs}} P \\Pi_{\\mathrm{unobs}}$。每个子空间中的收缩为：\n$$\n\\Delta_{\\mathrm{obs}} = \\operatorname{tr}(\\Pi_{\\mathrm{obs}} P^- \\Pi_{\\mathrm{obs}}) - \\operatorname{tr}(\\Pi_{\\mathrm{obs}} P^+ \\Pi_{\\mathrm{obs}})\n$$\n$$\n\\Delta_{\\mathrm{unobs}} = \\operatorname{tr}(\\Pi_{\\mathrm{unobs}} P^- \\Pi_{\\mathrm{unobs}}) - \\operatorname{tr}(\\Pi_{\\mathrm{unobs}} P^+ \\Pi_{\\mathrm{unobs}})\n$$\n利用迹的循环性质（$\\operatorname{tr}(AB) = \\operatorname{tr}(BA)$）和投影算子的幂等性质（$\\Pi^2 = \\Pi$），我们可以简化迹项：$\\operatorname{tr}(\\Pi P \\Pi) = \\operatorname{tr}(P \\Pi \\Pi) = \\operatorname{tr}(P \\Pi)$。这产生了一种计算上更高效的形式：\n$$\n\\Delta_{\\mathrm{obs}} = \\operatorname{tr}((P^- - P^+) \\Pi_{\\mathrm{obs}})\n$$\n可观测子空间上的收缩分数 $s_{\\mathrm{obs}}$ 则是比率 $\\Delta_{\\mathrm{obs}} / \\Delta_{\\mathrm{tot}}$，并带有一个检查以防止除以一个非常小的数。\n\n对于非线性测量模型 $y_k = h(x_k) + v_k$，扩展 Kalman 滤波器 (EKF) 使用围绕当前状态估计（或给定的线性化点 $x^\\ast$）的一阶泰勒级数展开来近似测量函数。这产生了一个线性近似 $y_k \\approx h(x^\\ast) + H(x^\\ast)(x_k - x^\\ast) + v_k$，其中 $H(x^\\ast) = \\left. \\frac{\\partial h}{\\partial x} \\right|_{x=x^\\ast}$ 是雅可比矩阵。然后应用线性协方差更新公式，用这个雅可比矩阵 $H$ 替换 $C$。可观测子空间也相应地由 $H$ 的 SVD 构建。\n\n下面的实现基于这些原理为所提供的测试用例计算后验协方差 $P^+$ 和收缩分数 $s_{\\mathrm{obs}}$。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_s_obs(P_minus, C, R, epsilon=1e-12):\n    \"\"\"\n    Calculates the one-step posterior covariance and the observable shrinkage fraction.\n\n    Args:\n        P_minus (np.ndarray): Prior covariance matrix (n x n).\n        C (np.ndarray): Measurement matrix (m x n).\n        R (np.ndarray): Measurement noise covariance matrix (m x m).\n        epsilon (float): Numerical tolerance for division.\n\n    Returns:\n        float: The fraction of covariance shrinkage on the observable subspace, s_obs.\n    \"\"\"\n    n, _ = P_minus.shape\n\n    # 1. Kalman Filter Covariance Update\n    # Innovation covariance: S = C * P_minus * C.T + R\n    S = C @ P_minus @ C.T + R\n    \n    # Kalman gain: K = P_minus * C.T * inv(S)\n    # Using np.linalg.solve for better numerical stability than inv()\n    # We solve S.T @ K.T = C @ P_minus.T for K.T, then transpose. Since S is symmetric, S.T=S.\n    # K.T = solve(S, C @ P_minus.T)\n    # K = solve(S, C @ P_minus.T).T is equivalent to K = P_minus @ C.T @ inv(S)\n    K = P_minus @ C.T @ np.linalg.inv(S)\n\n    # Posterior covariance: P_plus = P_minus - K * C * P_minus\n    P_plus = P_minus - K @ C @ P_minus\n\n    # 2. Construct Projection Matrix\n    # SVD of C to find the basis for the observable subspace\n    # The columns of vh.T are the right singular vectors of C\n    _, _, vh = np.linalg.svd(C, full_matrices=True)\n    V = vh.T\n    \n    # Rank of C determines the dimension of the observable subspace\n    r = np.linalg.matrix_rank(C)\n    \n    # V_r contains the first r columns of V, spanning the observable subspace\n    V_r = V[:, :r]\n    \n    # Projection matrix onto the observable subspace: Pi_obs = V_r * V_r.T\n    Pi_obs = V_r @ V_r.T\n\n    # 3. Calculate Shrinkage Values\n    # Total covariance shrinkage\n    Delta_P = P_minus - P_plus\n    Delta_tot = np.trace(Delta_P)\n\n    # Use cyclic property of trace: tr(Pi*P*Pi) = tr(P*Pi)\n    Delta_obs = np.trace(Delta_P @ Pi_obs)\n    \n    # 4. Calculate Shrinkage Fraction\n    if Delta_tot > epsilon:\n        s_obs = Delta_obs / Delta_tot\n    else:\n        s_obs = 0.0\n\n    return s_obs\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the results.\n    \"\"\"\n    results = []\n\n    # Case 1: Happy path, block-diagonal, partially observable, linear\n    n1, m1 = 4, 2\n    C1 = np.array([[1.0, 0, 0, 0], [0, 1.0, 0, 0]])\n    P_minus1 = np.diag([1.0, 1.0, 1.0, 1.0])\n    R1 = 0.05 * np.eye(m1)\n    results.append(calculate_s_obs(P_minus1, C1, R1))\n\n    # Case 2: Correlated prior across subspaces, linear\n    n2, m2 = 4, 2\n    C2 = np.array([[1.0, 0, 0, 0], [0, 1.0, 0, 0]])\n    S_mat = np.array([\n        [1.0, 0.2, 0.1, 0.1],\n        [0.0, 1.0, 0.2, 0.1],\n        [0.0, 0.0, 1.0, 0.3],\n        [0.0, 0.0, 0.0, 1.0]\n    ])\n    P_minus2 = S_mat @ S_mat.T\n    R2 = 0.10 * np.eye(m2)\n    results.append(calculate_s_obs(P_minus2, C2, R2))\n\n    # Case 3: Extremely noisy measurements, linear, boundary\n    n3, m3 = 4, 2\n    C3 = np.array([[1.0, 0, 0, 0], [0, 1.0, 0, 0]])\n    P_minus3 = np.diag([1.0, 1.0, 1.0, 1.0])\n    R3 = 1000.0 * np.eye(m3)\n    results.append(calculate_s_obs(P_minus3, C3, R3))\n\n    # Case 4: Nonlinear measurement with EKF, rank-deficient Jacobian\n    n4, m4 = 3, 2\n    # Nonlinear function h(x) = [sin(x1), sin(x1)]\n    # Linearization point x_star = [0, 0, 0]\n    # Jacobian H = [[cos(x1), 0, 0], [cos(x1), 0, 0]]\n    # At x_star, cos(0) = 1, so H = [[1,0,0], [1,0,0]]\n    H4 = np.array([[1.0, 0, 0], [1.0, 0, 0]])\n    P_minus4 = np.diag([1.0, 1.0, 1.0])\n    R4 = 0.05 * np.eye(m4)\n    results.append(calculate_s_obs(P_minus4, H4, R4))\n\n    # Format output\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "一个调校精良的卡尔曼滤波器不仅能估计状态，更是系统监控的强大工具。滤波器的“创新” (innovation)——即预测测量与实际测量之间的差异——在系统正常运行时应表现为零均值的白噪声。本练习将演示如何利用创新的统计特性，构建一个基于卡方 (Chi-Squared, $\\chi^2$) 检验的异常检测器，这是确保信息物理系统健康与安全的关键功能 。",
            "id": "4228746",
            "problem": "您的任务是为信息物理系统 (CPS) 中的数字孪生设计、论证并实现一个基于创新的异常检测器。该估计器是 Kalman 滤波家族的一员，可能是线性 Kalman 滤波器 (KF)、扩展 Kalman 滤波器 (EKF) 或无迹 Kalman 滤波器 (UKF)。在正确的建模假设下，离散时间索引 $k$ 处的新息（也称残差），记为 $e_k$，是一个协方差矩阵为 $S_k$ 的随机向量。假设测量噪声服从零均值高斯分布，并且估计器从其预测和更新步骤中一致地计算出 $e_k$ 和 $S_k$。\n\n您的任务是：\n- 从第一性原理推导，为何在新息的高斯性假设下，标量检验统计量 $e_k^\\top S_k^{-1} e_k$ 服从自由度等于测量维度的卡方 (Chi-Squared) 分布。\n- 实现一个数值稳定的检测器，对于每个提供的测试用例，该检测器计算统计量 $e_k^\\top S_k^{-1} e_k$ 而不显式求 $S_k$ 的逆，将该值与指定显著性水平 $\\alpha$ 和测量维度 $m$ 的卡方临界值进行比较，并且当且仅当该统计量严格大于临界值时，输出一个布尔值指示异常。\n\n通过 Cholesky 分解求解三角系统来使用一种数值稳定的方法。如果 Cholesky 分解因 $S_k$ 近乎奇异而失败，则添加一个小的对角抖动 $\\epsilon I$（其中 $\\epsilon = 10^{-9}$，$I$ 是适当维度的单位矩阵）并重试。\n\n此问题不涉及物理单位；将所有量视为无量纲。不涉及角度。将所有最终输出表示为布尔值。\n\n测试套件由五个独立的案例组成，每个案例由测量维度 $m$、对称正定协方差 $S_k$、新息向量 $e_k$ 和显著性水平 $\\alpha$ 指定：\n\n- 案例 1 (一般的良态二维情况):\n  - $m = 2$\n  - $S_k = \\begin{bmatrix} 1.0  0.1 \\\\ 0.1  1.5 \\end{bmatrix}$\n  - $e_k = \\begin{bmatrix} 0.2 \\\\ -0.1 \\end{bmatrix}$\n  - $\\alpha = 0.05$\n\n- 案例 2 (边界情况，对于 $m=2$ 和 $\\alpha=0.05$ 以及单位协方差，其值恰好在临界值上):\n  - $m = 2$\n  - $S_k = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}$\n  - $e_k = \\begin{bmatrix} \\sqrt{5.991464547107982} \\\\ 0.0 \\end{bmatrix}$\n  - $\\alpha = 0.05$\n\n- 案例 3 (明显的三维异常):\n  - $m = 3$\n  - $S_k = \\operatorname{diag}(0.5, 0.5, 2.0)$\n  - $e_k = \\begin{bmatrix} 3.0 \\\\ -3.0 \\\\ 0.0 \\end{bmatrix}$\n  - $\\alpha = 0.01$\n\n- 案例 4 (小方差的标量测量):\n  - $m = 1$\n  - $S_k = \\begin{bmatrix} 0.01 \\end{bmatrix}$\n  - $e_k = \\begin{bmatrix} 0.2 \\end{bmatrix}$\n  - $\\alpha = 0.10$\n\n- 案例 5 (二维近奇异协方差):\n  - $m = 2$\n  - $S_k = \\operatorname{diag}(10^{-6}, 10.0)$\n  - $e_k = \\begin{bmatrix} 10^{-3} \\\\ 0.0 \\end{bmatrix}$\n  - $\\alpha = 0.05$\n\n对于每个案例，通过基于 Cholesky 的白化计算统计量 $t_k = e_k^\\top S_k^{-1} e_k$，并将其与卡方临界值 $c_{\\alpha} = F_{\\chi^2(m)}^{-1}(1 - \\alpha)$ 进行比较，其中 $F_{\\chi^2(m)}^{-1}$ 表示具有 $m$ 个自由度的卡方分布的逆累积分布函数（分位数函数）。检测器当且仅当 $t_k  c_{\\alpha}$ 时应标记异常。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果（例如，$[result_1,result_2,result_3,result_4,result_5]$），其中每个 $result_i$ 是一个布尔值，按上面列出的顺序对应于每个案例。",
            "solution": "此问题根据指定标准进行验证。\n\n### 步骤 1：提取已知条件\n- **系统模型**：系统状态由 Kalman 滤波器变体（KF、EKF 或 UKF）估计。\n- **新息**：离散时间索引 $k$ 处的新息向量是 $e_k$。\n- **新息协方差**：新息的协方差矩阵是 $S_k$。\n- **假设**：测量噪声是零均值高斯分布。估计器正确计算 $e_k$ 和 $S_k$。在零假设（无异常）下，新息是一个零均值高斯随机向量，即 $e_k \\sim \\mathcal{N}(0, S_k)$。\n- **检验统计量**：异常检测检验统计量定义为 $t_k = e_k^\\top S_k^{-1} e_k$。\n- **任务 1 (推导)**：推导 $t_k$ 服从具有 $m$ 个自由度的卡方分布，其中 $m$ 是测量向量（因此也是 $e_k$）的维度。\n- **任务 2 (实现)**：实现一个检测器，该检测器使用 Cholesky 分解计算 $t_k$ 而无需显式矩阵求逆。如果分解失败，检测器必须通过添加对角抖动 $\\epsilon I$（其中 $\\epsilon = 10^{-9}$）来处理潜在的近奇异 $S_k$。如果 $t_k$ 严格大于临界值 $c_{\\alpha} = F_{\\chi^2(m)}^{-1}(1 - \\alpha)$，则标记异常，其中 $F_{\\chi^2(m)}^{-1}$ 是具有 $m$ 个自由度的卡方分布的分位数函数，$\\alpha$ 是显著性水平。\n- **测试用例**：\n  - 案例 1: $m = 2$, $S_k = \\begin{bmatrix} 1.0  0.1 \\\\ 0.1  1.5 \\end{bmatrix}$, $e_k = \\begin{bmatrix} 0.2 \\\\ -0.1 \\end{bmatrix}$, $\\alpha = 0.05$。\n  - 案例 2: $m = 2$, $S_k = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix}$, $e_k = \\begin{bmatrix} \\sqrt{5.991464547107982} \\\\ 0.0 \\end{bmatrix}$, $\\alpha = 0.05$。\n  - 案例 3: $m = 3$, $S_k = \\operatorname{diag}(0.5, 0.5, 2.0)$, $e_k = \\begin{bmatrix} 3.0 \\\\ -3.0 \\\\ 0.0 \\end{bmatrix}$, $\\alpha = 0.01$。\n  - 案例 4: $m = 1$, $S_k = \\begin{bmatrix} 0.01 \\end{bmatrix}$, $e_k = \\begin{bmatrix} 0.2 \\end{bmatrix}$, $\\alpha = 0.10$。\n  - 案例 5: $m = 2$, $S_k = \\operatorname{diag}(10^{-6}, 10.0)$, $e_k = \\begin{bmatrix} 10^{-3} \\\\ 0.0 \\end{bmatrix}$, $\\alpha = 0.05$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，因为它基于应用于状态估计的标准统计理论，而状态估计是控制理论和信号处理中的一个核心概念。卡方检验统计量的推导是多元统计学中的一个基本结果。该问题是适定的，为理论推导和数值实现提供了所有必要的数据和清晰、明确的目标。其中没有矛盾，并且指定的数值方法（Cholesky 分解、三角求解、用于稳定性的抖动）是标准的最佳实践。该问题与 Kalman 滤波主题及其在 CPS 和数字孪生中用于异常检测的应用直接相关。这个问题不简单，因为它既需要理论上的理解，也需要细致的数值实现。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。将提供完整的解决方案。\n\n### 基于原理的解决方案\n\n解决方案按要求分为两部分呈现：首先是理论推导，其次是数值实现的解释。\n\n#### 第 1 部分：检验统计量分布的推导\n\n目标是证明检验统计量 $t_k = e_k^\\top S_k^{-1} e_k$ 服从具有 $m$ 个自由度的卡方 ($\\chi^2$) 分布。\n\n推导始于这样一个前提：在正常操作条件下（零假设），新息向量 $e_k$ 是一个服从多元高斯分布的随机变量，其均值向量为 $0$，协方差矩阵为 $S_k$。$e_k$ 的维度是 $m$。这可以正式表述为：\n$$\ne_k \\sim \\mathcal{N}(0, S_k)\n$$\n其中 $e_k \\in \\mathbb{R}^m$ 且 $S_k \\in \\mathbb{R}^{m \\times m}$。\n\n由于 $S_k$ 是一个协方差矩阵，所以它是对称且半正定的。对于一个具有可观测系统的正常工作的滤波器，$S_k$ 是严格正定的。一个正定矩阵 $S_k$ 可以通过 Cholesky 分解唯一地分解为一个下三角矩阵 $L_k$ 与其转置 $L_k^\\top$ 的乘积：\n$$\nS_k = L_k L_k^\\top\n$$\n那么 $S_k$ 的逆可以表示为：\n$$\nS_k^{-1} = (L_k L_k^\\top)^{-1} = (L_k^\\top)^{-1} L_k^{-1}\n$$\n\n下一步是“白化”新息向量 $e_k$。白化是一种线性变换，它将具有已知协方差矩阵的随机向量转换为具有单位协方差矩阵（和零均值）的新随机向量。我们定义白化新息向量 $z_k$ 为：\n$$\nz_k = L_k^{-1} e_k\n$$\n现在我们分析 $z_k$ 的统计特性。$z_k$ 的期望值为：\n$$\n\\mathbb{E}[z_k] = \\mathbb{E}[L_k^{-1} e_k] = L_k^{-1} \\mathbb{E}[e_k] = L_k^{-1} \\cdot 0 = 0\n$$\n$z_k$ 的协方差矩阵计算如下：\n$$\n\\operatorname{Cov}(z_k) = \\mathbb{E}[ (z_k - \\mathbb{E}[z_k]) (z_k - \\mathbb{E}[z_k])^\\top ] = \\mathbb{E}[z_k z_k^\\top]\n$$\n代入 $z_k$ 的定义：\n$$\n\\operatorname{Cov}(z_k) = \\mathbb{E}[ (L_k^{-1} e_k) (L_k^{-1} e_k)^\\top ] = \\mathbb{E}[ L_k^{-1} e_k e_k^\\top (L_k^{-1})^\\top ]\n$$\n利用期望算子的线性性质：\n$$\n\\operatorname{Cov}(z_k) = L_k^{-1} \\mathbb{E}[e_k e_k^\\top] (L_k^\\top)^{-1}\n$$\n根据定义，$\\mathbb{E}[e_k e_k^\\top]$ 是 $e_k$ 的协方差矩阵，即 $S_k$。\n$$\n\\operatorname{Cov}(z_k) = L_k^{-1} S_k (L_k^\\top)^{-1}\n$$\n现在，代入 Cholesky 分解 $S_k = L_k L_k^\\top$：\n$$\n\\operatorname{Cov}(z_k) = L_k^{-1} (L_k L_k^\\top) (L_k^\\top)^{-1} = (L_k^{-1} L_k) (L_k^\\top (L_k^\\top)^{-1}) = I_m \\cdot I_m = I_m\n$$\n其中 $I_m$ 是 $m \\times m$ 的单位矩阵。\n\n由于 $e_k$ 是一个高斯随机向量，而 $z_k$ 是 $e_k$ 的线性变换，因此 $z_k$ 也是一个高斯随机向量。我们已经证明了它的均值为 $0$，协方差为 $I_m$。因此，$z_k$ 服从标准多元正态分布：\n$$\nz_k \\sim \\mathcal{N}(0, I_m)\n$$\n这意味着 $z_k$ 的分量，记为 $z_{k,i}$ (其中 $i=1, \\dots, m$)，是独立同分布 (i.i.d.) 的标准正态随机变量，即 $z_{k,i} \\sim \\mathcal{N}(0, 1)$。\n\n现在，我们可以用白化向量 $z_k$ 来重新表示检验统计量 $t_k$：\n$$\nt_k = e_k^\\top S_k^{-1} e_k = e_k^\\top (L_k^\\top)^{-1} L_k^{-1} e_k\n$$\n使用属性 $(AB)^\\top = B^\\top A^\\top$，我们可以将其写为：\n$$\nt_k = (L_k^{-1} e_k)^\\top (L_k^{-1} e_k) = z_k^\\top z_k\n$$\n量 $z_k^\\top z_k$ 是 $z_k$ 各分量的平方和：\n$$\nt_k = \\sum_{i=1}^{m} z_{k,i}^2\n$$\n根据卡方分布的定义， $m$ 个独立标准正态随机变量的平方和服从自由度为 $m$ 的卡方分布。\n\n因此，我们已经证明了检验统计量 $t_k = e_k^\\top S_k^{-1} e_k$ 服从 $\\chi^2(m)$ 分布。推导至此完成。\n\n#### 第 2 部分：数值稳定的实现\n\n异常检测器的实现是基于从推导中获得的见解。目标是计算 $t_k = e_k^\\top S_k^{-1} e_k$ 并将其与临界值进行比较，而不执行 $S_k$ 的显式矩阵求逆，因为这种求逆在数值上不稳定且计算效率低下。\n\n算法步骤如下：\n\n1.  **Cholesky 分解**：给定新息协方差矩阵 $S_k$，计算其下三角 Cholesky 因子 $L_k$ 使得 $S_k = L_k L_k^\\top$。一个鲁棒的实现必须能处理 $S_k$ 在数值上非正定的情况（例如，由于浮点误差或模型病态）。按照规定，如果初始分解失败，则向 $S_k$ 添加一个小的正则化项或“抖动”$\\epsilon I_m$，其中 $\\epsilon = 10^{-9}$。然后在正则化后的矩阵 $S_k' = S_k + \\epsilon I_m$ 上重新尝试分解。\n\n2.  **通过三角求解进行白化**：我们不通过对 $L_k$ 求逆来计算 $z_k = L_k^{-1} e_k$，而是求解等价的线性系统 $L_k z_k = e_k$ 来得到向量 $z_k$。由于 $L_k$ 是下三角矩阵，该系统可以使用前向替换法高效且稳定地求解。\n\n3.  **统计量计算**：一旦获得白化向量 $z_k$，检验统计量 $t_k$ 就简单地计算为 $z_k$ 的欧几里得范数的平方：$t_k = z_k^\\top z_k$。这在计算上非常简单，在数值上也是良性的。\n\n4.  **假设检验**：\n    - 临界值 $c_{\\alpha}$ 是根据具有 $m$ 个自由度的卡方分布的逆累积分布函数 (CDF) 确定的。具体来说，对于显著性水平 $\\alpha$，临界值是 $\\chi^2(m)$ 分布上的一个点，使得其右侧曲线下的面积为 $\\alpha$。这对应于 $1 - \\alpha$ 的累积概率。因此，$c_{\\alpha} = F_{\\chi^2(m)}^{-1}(1-\\alpha)$，其中 $F^{-1}$ 是分位数函数（或百分点函数）。\n    - 当且仅当计算出的统计量 $t_k$ 严格大于临界值 $c_{\\alpha}$ 时，才声明存在异常。每个案例的输出是一个布尔值：如果 $t_k  c_{\\alpha}$ 则为 `True`，否则为 `False`。\n\n这种方法完全避免了矩阵求逆，而是依赖于稳定得多的 Cholesky 分解和三角系统求解操作。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import cholesky, solve_triangular, LinAlgError\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Solves the anomaly detection problem for all specified test cases.\n    \"\"\"\n\n    # Define the test cases as per the problem statement.\n    test_cases = [\n        {\n            \"m\": 2,\n            \"S_k\": np.array([[1.0, 0.1], \n                             [0.1, 1.5]]),\n            \"e_k\": np.array([0.2, -0.1]),\n            \"alpha\": 0.05,\n        },\n        {\n            \"m\": 2,\n            \"S_k\": np.array([[1.0, 0.0], \n                             [0.0, 1.0]]),\n            \"e_k\": np.array([np.sqrt(5.991464547107982), 0.0]),\n            \"alpha\": 0.05,\n        },\n        {\n            \"m\": 3,\n            \"S_k\": np.diag([0.5, 0.5, 2.0]),\n            \"e_k\": np.array([3.0, -3.0, 0.0]),\n            \"alpha\": 0.01,\n        },\n        {\n            \"m\": 1,\n            \"S_k\": np.array([[0.01]]),\n            \"e_k\": np.array([0.2]),\n            \"alpha\": 0.10,\n        },\n        {\n            \"m\": 2,\n            \"S_k\": np.diag([1e-6, 10.0]),\n            \"e_k\": np.array([1e-3, 0.0]),\n            \"alpha\": 0.05,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        is_anomaly = detect_anomaly(\n            case[\"m\"], case[\"S_k\"], case[\"e_k\"], case[\"alpha\"]\n        )\n        results.append(is_anomaly)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results)).lower()}]\")\n\ndef detect_anomaly(m, S_k, e_k, alpha):\n    \"\"\"\n    Performs innovation-based anomaly detection for a single time step.\n\n    Args:\n        m (int): The dimension of the measurement space.\n        S_k (np.ndarray): The innovation covariance matrix (m x m).\n        e_k (np.ndarray): The innovation vector (m,).\n        alpha (float): The significance level for the Chi-Squared test.\n\n    Returns:\n        bool: True if an anomaly is detected, False otherwise.\n    \"\"\"\n    epsilon = 1e-9  # Jitter for near-singular matrices\n\n    try:\n        # Perform Cholesky factorization: S_k = L * L.T\n        # 'lower=True' ensures L is lower-triangular.\n        L = cholesky(S_k, lower=True)\n    except LinAlgError:\n        # If S_k is not positive definite, add jitter and retry.\n        S_k_jittered = S_k + epsilon * np.identity(m)\n        L = cholesky(S_k_jittered, lower=True)\n\n    # Whiten the innovation vector by solving the triangular system L * z_k = e_k.\n    # This is numerically superior to computing z_k = inv(L) * e_k.\n    z_k = solve_triangular(L, e_k, lower=True)\n\n    # Compute the test statistic t_k = z_k.T * z_k\n    t_k = np.dot(z_k, z_k)\n\n    # Compute the critical value from the Chi-Squared distribution's\n    # percent point function (inverse CDF).\n    critical_value = chi2.ppf(1 - alpha, df=m)\n\n    # An anomaly is detected if the statistic is strictly greater than the threshold.\n    return t_k > critical_value\n\nsolve()\n```"
        }
    ]
}