{
    "hands_on_practices": [
        {
            "introduction": "A core challenge in disturbance observer design is balancing the need to accurately track real disturbances while not amplifying measurement noise. This practice guides you through a foundational optimization problem where you will derive the optimal cutoff frequency for a $Q$-filter by minimizing the mean-square estimation error. Completing this exercise  provides a rigorous understanding of the trade-off that governs the performance of all disturbance observers.",
            "id": "4218779",
            "problem": "A cyber-physical system is monitored by a Digital Twin (DT) that implements a Disturbance Observer (DO) to estimate an additive output disturbance. The physical plant is linear time-invariant (LTI) and, over the operating region, the DT provides an exact nominal model, so the actual plant equals the nominal plant. The nominal plant is given by $P_{n}(s)=\\frac{1}{s+1}$. The DO uses the standard residual $y(s)-P_{n}(s)u(s)$, where $y(s)$ is the measured output, $u(s)$ is the control input, and the measurement is corrupted by additive sensor noise. The DO estimate is formed by filtering this residual with a first-order low-pass $Q$-filter, $Q(s)=\\frac{\\omega_{c}}{s+\\omega_{c}}$, where $\\omega_{c}0$ is the cutoff angular frequency to be chosen.\n\nAssume the following signal structure and models:\n- The true output is $y(s)=P_{n}(s)u(s)+d(s)+n(s)$, where $d(s)$ is the additive output disturbance and $n(s)$ is additive sensor noise.\n- Because the DT provides exact nominal matching, $P(s)=P_{n}(s)$, so there is no model mismatch term.\n- The additive disturbance $d(t)$ is a wide-sense stationary process with one-sided Power Spectral Density (PSD) $S_{d}(\\omega)$ that is constant and equal to $S_{d0}$ over $0\\leq \\omega\\leq \\omega_{d}$ and zero for $\\omega\\omega_{d}$.\n- The sensor noise $n(t)$ is white with one-sided PSD $S_{n}(\\omega)=S_{n0}$ for all $\\omega\\geq 0$.\n- All processes are mutually uncorrelated.\n\nStarting from the fundamental LTI input-output relations in the frequency domain and the definition of mean-square error via one-sided PSDs, derive the frequency-domain disturbance estimation error due to $d(t)$ and $n(t)$ for the DO estimate $\\hat{d}(s)=Q(s)\\big(y(s)-P_{n}(s)u(s)\\big)$. Then, by integrating the error spectra over frequency, obtain a scalar cost $J(\\omega_{c})$ equal to the one-sided mean-square estimation error as a function of $\\omega_{c}$. Finally, determine the cutoff angular frequency $\\omega_{c}^{\\star}$ that minimizes $J(\\omega_{c})$ for the numerical values $S_{d0}=2\\pi$, $S_{n0}=\\pi-2$, and $\\omega_{d}=10$.\n\nExpress the final optimal cutoff angular frequency in radians per second. No rounding is required; provide the exact value.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n- **Nominal Plant Model**: $P_{n}(s)=\\frac{1}{s+1}$.\n- **Plant-Model Relationship**: The nominal model is exact, $P(s)=P_{n}(s)$.\n- **Output Equation**: $y(s)=P_{n}(s)u(s)+d(s)+n(s)$, where $d(s)$ is the disturbance and $n(s)$ is the sensor noise.\n- **Disturbance Observer (DO) Estimate**: $\\hat{d}(s)=Q(s)\\big(y(s)-P_{n}(s)u(s)\\big)$.\n- **Q-filter**: $Q(s)=\\frac{\\omega_{c}}{s+\\omega_{c}}$ with $\\omega_{c}0$.\n- **Disturbance PSD**: The one-sided Power Spectral Density (PSD) of $d(t)$ is $S_{d}(\\omega) = S_{d0}$ for $0\\leq \\omega\\leq \\omega_{d}$ and $S_{d}(\\omega)=0$ for $\\omega\\omega_{d}$.\n- **Noise PSD**: The one-sided PSD of $n(t)$ is $S_{n}(\\omega)=S_{n0}$ for all $\\omega\\geq 0$.\n- **Signal Properties**: The processes $d(t)$ and $n(t)$ are wide-sense stationary and mutually uncorrelated.\n- **Numerical Values**: $S_{d0}=2\\pi$, $S_{n0}=\\pi-2$, and $\\omega_{d}=10$.\n- **Objective**: Find the optimal cutoff angular frequency $\\omega_c^{\\star}$ that minimizes the mean-square estimation error, $J(\\omega_c)$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem uses standard principles of Linear Time-Invariant (LTI) systems, stochastic processes (PSDs), and optimization within the established field of control theory and disturbance observer design. All concepts are valid.\n- **Well-Posed**: The problem is fully specified. All necessary models, signal characteristics, and numerical values are provided to formulate and solve the optimization problem. The physical constraint $\\omega_c0$ is given. The PSD values $S_{d0}=2\\pi  0$ and $S_{n0}=\\pi-2  0$ are physically meaningful.\n- **Objective**: The problem statement is precise, quantitative, and free of subjective elements.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A complete solution will be provided.\n\n### Derivation of the Mean-Square Estimation Error\n\nThe disturbance estimation error in the Laplace domain is $\\tilde{d}(s) = d(s) - \\hat{d}(s)$.\nThe disturbance estimate is given by $\\hat{d}(s)=Q(s)\\big(y(s)-P_{n}(s)u(s)\\big)$.\nSubstituting the expression for the output $y(s)$, we get:\n$$y(s)-P_{n}(s)u(s) = \\big(P_{n}(s)u(s)+d(s)+n(s)\\big) - P_{n}(s)u(s) = d(s) + n(s)$$\nThus, the disturbance estimate is $\\hat{d}(s) = Q(s) \\big(d(s) + n(s)\\big)$.\nThe estimation error is then:\n$$\\tilde{d}(s) = d(s) - Q(s)\\big(d(s) + n(s)\\big) = \\big(1 - Q(s)\\big)d(s) - Q(s)n(s)$$\nThe error signal $\\tilde{d}(t)$ is the output of an LTI system with two inputs, $d(t)$ and $n(t)$. The transfer function from $d(t)$ to $\\tilde{d}(t)$ is $T_{d\\tilde{d}}(s) = 1 - Q(s)$, and from $n(t)$ to $\\tilde{d}(t)$ is $T_{n\\tilde{d}}(s) = -Q(s)$.\nSince $d(t)$ and $n(t)$ are uncorrelated, the one-sided PSD of the estimation error, $S_{\\tilde{d}}(\\omega)$, is the sum of the individual output PSDs:\n$$S_{\\tilde{d}}(\\omega) = |T_{d\\tilde{d}}(j\\omega)|^2 S_{d}(\\omega) + |T_{n\\tilde{d}}(j\\omega)|^2 S_{n}(\\omega) = |1 - Q(j\\omega)|^2 S_{d}(\\omega) + |Q(j\\omega)|^2 S_{n}(\\omega)$$\nWe evaluate the frequency response magnitudes for the given $Q$-filter $Q(s) = \\frac{\\omega_c}{s+\\omega_c}$:\n$$Q(j\\omega) = \\frac{\\omega_c}{j\\omega + \\omega_c} \\implies |Q(j\\omega)|^2 = Q(j\\omega)Q(-j\\omega) = \\frac{\\omega_c^2}{\\omega^2 + \\omega_c^2}$$\n$$1 - Q(j\\omega) = 1 - \\frac{\\omega_c}{j\\omega + \\omega_c} = \\frac{j\\omega}{j\\omega + \\omega_c} \\implies |1 - Q(j\\omega)|^2 = \\frac{\\omega^2}{\\omega^2 + \\omega_c^2}$$\nSubstituting these into the expression for $S_{\\tilde{d}}(\\omega)$:\n$$S_{\\tilde{d}}(\\omega) = \\frac{\\omega^2}{\\omega^2 + \\omega_c^2} S_{d}(\\omega) + \\frac{\\omega_c^2}{\\omega^2 + \\omega_c^2} S_{n}(\\omega)$$\nThe scalar cost $J(\\omega_c)$ is the mean-square estimation error, which is obtained by integrating the one-sided error PSD over all frequencies:\n$$J(\\omega_c) = E[\\tilde{d}^2(t)] = \\frac{1}{2\\pi} \\int_0^\\infty S_{\\tilde{d}}(\\omega) d\\omega$$\nWe can split the cost into a component due to the disturbance, $J_d(\\omega_c)$, and a component due to noise, $J_n(\\omega_c)$.\n$$J(\\omega_c) = J_d(\\omega_c) + J_n(\\omega_c)$$\nUsing the given PSD for the disturbance, the first component is:\n$$J_d(\\omega_c) = \\frac{1}{2\\pi} \\int_0^\\infty \\frac{\\omega^2}{\\omega^2 + \\omega_c^2} S_{d}(\\omega) d\\omega = \\frac{S_{d0}}{2\\pi} \\int_0^{\\omega_d} \\frac{\\omega^2}{\\omega^2 + \\omega_c^2} d\\omega$$\n$$J_d(\\omega_c) = \\frac{S_{d0}}{2\\pi} \\int_0^{\\omega_d} \\left(1 - \\frac{\\omega_c^2}{\\omega^2 + \\omega_c^2}\\right) d\\omega = \\frac{S_{d0}}{2\\pi} \\left[ \\omega - \\omega_c \\arctan\\left(\\frac{\\omega}{\\omega_c}\\right) \\right]_0^{\\omega_d}$$\n$$J_d(\\omega_c) = \\frac{S_{d0}}{2\\pi} \\left( \\omega_d - \\omega_c \\arctan\\left(\\frac{\\omega_d}{\\omega_c}\\right) \\right)$$\nUsing the given PSD for the noise, the second component is:\n$$J_n(\\omega_c) = \\frac{1}{2\\pi} \\int_0^\\infty \\frac{\\omega_c^2}{\\omega^2 + \\omega_c^2} S_{n}(\\omega) d\\omega = \\frac{S_{n0}\\omega_c^2}{2\\pi} \\int_0^\\infty \\frac{1}{\\omega^2 + \\omega_c^2} d\\omega$$\nThe integral evaluates to $\\int_0^\\infty \\frac{1}{\\omega^2 + \\omega_c^2} d\\omega = \\left[ \\frac{1}{\\omega_c} \\arctan\\left(\\frac{\\omega}{\\omega_c}\\right) \\right]_0^\\infty = \\frac{1}{\\omega_c}\\left(\\frac{\\pi}{2} - 0\\right) = \\frac{\\pi}{2\\omega_c}$.\n$$J_n(\\omega_c) = \\frac{S_{n0}\\omega_c^2}{2\\pi} \\left( \\frac{\\pi}{2\\omega_c} \\right) = \\frac{S_{n0}\\omega_c}{4}$$\nThe total cost function is:\n$$J(\\omega_c) = \\frac{S_{d0}}{2\\pi} \\left( \\omega_d - \\omega_c \\arctan\\left(\\frac{\\omega_d}{\\omega_c}\\right) \\right) + \\frac{S_{n0}\\omega_c}{4}$$\n\n### Optimization of the Cutoff Frequency\n\nTo find the optimal cutoff frequency $\\omega_c^{\\star}$ that minimizes $J(\\omega_c)$, we set its derivative with respect to $\\omega_c$ to zero.\n$$\\frac{dJ}{d\\omega_c} = \\frac{d}{d\\omega_c} \\left[ \\frac{S_{d0}}{2\\pi} \\left( \\omega_d - \\omega_c \\arctan\\left(\\frac{\\omega_d}{\\omega_c}\\right) \\right) + \\frac{S_{n0}\\omega_c}{4} \\right] = 0$$\nLet's compute the derivatives of the terms:\n$$\\frac{d}{d\\omega_c} \\left( \\frac{S_{n0}\\omega_c}{4} \\right) = \\frac{S_{n0}}{4}$$\n$$\\frac{d}{d\\omega_c} \\left( \\omega_c \\arctan\\left(\\frac{\\omega_d}{\\omega_c}\\right) \\right) = \\arctan\\left(\\frac{\\omega_d}{\\omega_c}\\right) + \\omega_c \\left( \\frac{1}{1+(\\omega_d/\\omega_c)^2} \\cdot \\left(-\\frac{\\omega_d}{\\omega_c^2}\\right) \\right) = \\arctan\\left(\\frac{\\omega_d}{\\omega_c}\\right) - \\frac{\\omega_c\\omega_d}{\\omega_c^2 + \\omega_d^2}$$\nSo, the total derivative is:\n$$\\frac{dJ}{d\\omega_c} = \\frac{S_{d0}}{2\\pi} \\left( -\\left[ \\arctan\\left(\\frac{\\omega_d}{\\omega_c}\\right) - \\frac{\\omega_c\\omega_d}{\\omega_c^2 + \\omega_d^2} \\right] \\right) + \\frac{S_{n0}}{4} = 0$$\nRearranging the terms gives the optimality condition:\n$$\\frac{S_{n0}}{4} = \\frac{S_{d0}}{2\\pi} \\left( \\arctan\\left(\\frac{\\omega_d}{\\omega_c}\\right) - \\frac{\\omega_c\\omega_d}{\\omega_c^2 + \\omega_d^2} \\right)$$\nNow we substitute the given numerical values: $S_{d0}=2\\pi$, $S_{n0}=\\pi-2$, and $\\omega_d=10$.\n$$\\frac{\\pi-2}{4} = \\frac{2\\pi}{2\\pi} \\left( \\arctan\\left(\\frac{10}{\\omega_c}\\right) - \\frac{10\\omega_c}{\\omega_c^2 + 10^2} \\right)$$\n$$\\frac{\\pi-2}{4} = \\arctan\\left(\\frac{10}{\\omega_c}\\right) - \\frac{10\\omega_c}{\\omega_c^2 + 100}$$\nWe need to solve this transcendental equation for $\\omega_c$. Let us test the a potential solution of $\\omega_c = \\omega_d = 10$.\nSubstituting $\\omega_c=10$ into the right-hand side of the equation:\n$$\\text{RHS} = \\arctan\\left(\\frac{10}{10}\\right) - \\frac{10(10)}{10^2 + 100} = \\arctan(1) - \\frac{100}{200} = \\frac{\\pi}{4} - \\frac{1}{2}$$\nSimplifying the right-hand side gives:\n$$\\frac{\\pi}{4} - \\frac{2}{4} = \\frac{\\pi-2}{4}$$\nThis is identical to the left-hand side of the equation. Therefore, $\\omega_c^{\\star} = 10$ is the solution that satisfies the optimality condition. The second derivative of $J(\\omega_c)$ can be shown to be positive, confirming this stationary point is a minimum.\nThe optimal cutoff angular frequency is $10$ radians per second.",
            "answer": "$$\n\\boxed{10}\n$$"
        },
        {
            "introduction": "While a high-bandwidth disturbance observer offers better performance in theory, it can lead to instability when the system model is not perfectly accurate. This practice explores this critical issue of robust stability by introducing multiplicative uncertainty, particularly unmodeled flexible dynamics. By applying the small-gain theorem , you will derive a formal condition for stability and see firsthand why an overly aggressive design can be dangerous, a crucial lesson for real-world cyber-physical systems.",
            "id": "4218791",
            "problem": "Consider a linear time-invariant cyber-physical system equipped with a digital twin model used for disturbance compensation via a Disturbance Observer (DOB). Let the true plant input-output relationship in the Laplace domain be $Y(s) = P(s) U(s) + D(s)$, where $P(s)$ is the true plant, $U(s)$ is the commanded input, and $D(s)$ is an external disturbance. The digital twin uses a nominal model $P_n(s)$ and forms a disturbance estimate through a stable, strictly proper low-pass filter $Q(s)$ and the nominal inverse $P_n^{-1}(s)$, as part of a standard DOB architecture. Assume multiplicative model uncertainty written as $P(s) = P_n(s) \\left( 1 + W_m(s) \\Delta(s) \\right)$, where $W_m(s)$ is a known frequency-dependent weighting that captures uncertainty (with lightly damped flexible mode behavior) and $\\Delta(s)$ is any stable bounded perturbation satisfying $\\left\\| \\Delta(j\\omega) \\right\\|_\\infty \\leq 1$. Frequencies must be treated in radians per second.\n\nStarting only from the definitions of linear time-invariant systems, convolution, the Laplace transform, and the small-gain theorem for feedback interconnections, derive a mathematically rigorous condition that guarantees internal stability of the DOB compensation in the presence of multiplicative uncertainty. Your derivation must make explicit the feedback interconnection map between the uncertainty input and output in the DOB inner loop and must quantify how the bandwidth of the $Q(s)$ filter influences the robustness of this interconnection. Then, construct a counterexample using a lightly damped flexible mode in the uncertainty weighting, and provide a logically sound argument explaining why making the $Q(s)$ bandwidth too aggressive degrades robustness.\n\nFor concreteness and numerical verification, use the following parameterizations for the low-pass filter and the multiplicative uncertainty weighting:\n- $Q(s) = \\dfrac{\\omega_q}{s + \\omega_q}$ with bandwidth parameter $\\omega_q  0$ expressed in radians per second.\n- $W_m(s) = k_w \\dfrac{\\omega_f^2}{s^2 + 2 \\zeta_f \\omega_f s + \\omega_f^2}$, where $\\omega_f  0$ is the flexible mode natural frequency in radians per second, $\\zeta_f \\in (0, 1)$ is its damping ratio, and $k_w  0$ is a dimensionless uncertainty scale factor.\n\nAfter deriving the condition, implement a program that, for any given set of parameters $(\\omega_q,\\omega_f,\\zeta_f,k_w)$, numerically evaluates the supremum over frequency $\\omega \\in [10^{-1}, 10^{4}]$ radians per second of the magnitude of the loop-gain from the uncertainty to itself in the DOB inner loop implied by your derivation. Based on this supremum, return a boolean indicating whether robust stability is guaranteed under all admissible $\\Delta(s)$ consistent with the multiplicative uncertainty model. The program must treat angles in radians and frequencies in radians per second. No other physical units are needed in the output.\n\nTest Suite:\nUse the following four parameter sets to demonstrate coverage, including a general case, an aggressive bandwidth case that breaks robustness, a case with increased damping that restores robustness, and a boundary case close to loss of robustness:\n1. $(\\omega_q,\\omega_f,\\zeta_f,k_w) = (30,\\ 200,\\ 0.02,\\ 0.1)$ in radians per second for $\\omega_q$ and $\\omega_f$.\n2. $(\\omega_q,\\omega_f,\\zeta_f,k_w) = (400,\\ 200,\\ 0.02,\\ 0.1)$ in radians per second for $\\omega_q$ and $\\omega_f$.\n3. $(\\omega_q,\\omega_f,\\zeta_f,k_w) = (400,\\ 200,\\ 0.10,\\ 0.1)$ in radians per second for $\\omega_q$ and $\\omega_f$.\n4. $(\\omega_q,\\omega_f,\\zeta_f,k_w) = (90,\\ 200,\\ 0.02,\\ 0.1)$ in radians per second for $\\omega_q$ and $\\omega_f$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the robustness results as a comma-separated list of booleans enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$). Each $result_i$ is $True$ if robust stability is guaranteed by your derived condition for the $i$-th test case, and $False$ otherwise.",
            "solution": "The problem statement is critically evaluated according to the specified validation procedure.\n\n### Step 1: Extract Givens\n- Plant input-output relationship: $Y(s) = P(s) U(s) + D(s)$, where $Y(s)$ is the output, $P(s)$ is the true plant, $U(s)$ is the commanded input, and $D(s)$ is an external disturbance.\n- Nominal plant model: $P_n(s)$.\n- Disturbance observer filter: $Q(s)$, a stable, strictly proper low-pass filter.\n- Nominal plant inverse: $P_n^{-1}(s)$.\n- Multiplicative uncertainty model: $P(s) = P_n(s) \\left( 1 + W_m(s) \\Delta(s) \\right)$.\n- Uncertainty weighting function: $W_m(s)$.\n- Perturbation block: $\\Delta(s)$, any stable system satisfying $\\left\\| \\Delta(j\\omega) \\right\\|_\\infty \\leq 1$.\n- Frequency units: radians per second.\n- $Q$-filter parameterization: $Q(s) = \\dfrac{\\omega_q}{s + \\omega_q}$ with bandwidth $\\omega_q  0$.\n- Uncertainty weighting parameterization: $W_m(s) = k_w \\dfrac{\\omega_f^2}{s^2 + 2 \\zeta_f \\omega_f s + \\omega_f^2}$, with flexible mode frequency $\\omega_f  0$, damping ratio $\\zeta_f \\in (0, 1)$, and uncertainty scale factor $k_w  0$.\n- Numerical evaluation range: $\\omega \\in [10^{-1}, 10^{4}]$ radians per second.\n- Test Cases:\n  1. $(\\omega_q, \\omega_f, \\zeta_f, k_w) = (30, 200, 0.02, 0.1)$\n  2. $(\\omega_q, \\omega_f, \\zeta_f, k_w) = (400, 200, 0.02, 0.1)$\n  3. $(\\omega_q, \\omega_f, \\zeta_f, k_w) = (400, 200, 0.10, 0.1)$\n  4. $(\\omega_q, \\omega_f, \\zeta_f, k_w) = (90, 200, 0.02, 0.1)$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity:\n- **Scientifically Grounded:** The problem is firmly rooted in the principles of modern control theory, specifically robust control and observer design. The concepts of disturbance observers (DOB), multiplicative uncertainty modeling, the small-gain theorem, and frequency-domain analysis are canonical within this discipline. The setup is scientifically and mathematically sound.\n- **Well-Posed:** The problem is well-posed. It requests the derivation of a standard robust stability condition and its numerical evaluation given specific parameterizations. The requested output is uniquely determined by the provided data and established theory.\n- **Objective:** The problem statement is written in precise, formal, and objective language, free from ambiguity or subjective claims.\n- **Completeness and Consistency:** The problem provides all necessary definitions, models, and parameters to derive the condition and perform the numerical computation. There are no internal contradictions.\n- **Realism:** The models for the filter and uncertainty weighting, particularly the representation of a lightly damped flexible mode, are standard and realistic in the context of controlling mechanical systems, a common application for cyber-physical systems and digital twins.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution is provided below.\n\n### Principle-Based Design and Derivation\n\nThe primary objective is to derive a condition for the internal stability of the closed-loop system formed by the plant and the Disturbance Observer (DOB). We begin by formalizing the structure of the DOB as described. A standard DOB estimates a lumped disturbance and injects a compensating signal into the control input. The estimate is formed by comparing the plant output with the output of a nominal model.\n\nLet $U_r(s)$ be the external reference command. The actual input to the plant, $U(s)$, is the sum of this reference and a cancellation signal, $U_{comp}(s)$. The DOB formulation described implies that the cancellation signal is an estimate of the disturbance, referred to the input. We construct this estimate as follows.\n\nAn intermediate signal, which we may call the \"measured disturbance\", $d_m(s)$, is formed by differencing the plant input $U(s)$ and the input that would have produced the output $Y(s)$ if the plant were nominal, i.e., $P_n^{-1}(s)Y(s)$.\n$$d_m(s) = P_n^{-1}(s)Y(s) - U(s)$$\nThis signal is then passed through the low-pass filter $Q(s)$ to generate the estimated disturbance, which serves as the compensation signal:\n$$U_{comp}(s) = -Q(s)d_m(s)$$\nThe negative sign indicates that this signal is subtracted from the reference command. The total input to the plant is therefore:\n$$U(s) = U_r(s) + U_{comp}(s) = U_r(s) - Q(s)d_m(s)$$\nSubstituting the expression for $d_m(s)$:\n$$U(s) = U_r(s) - Q(s) \\left( P_n^{-1}(s)Y(s) - U(s) \\right)$$\nTo analyze the stability of the inner DOB loop, we must understand how it interacts with modeling uncertainty. We substitute the plant and uncertainty models, $Y(s) = P(s)U(s) + D(s)$ and $P(s) = P_n(s)(1+W_m(s)\\Delta(s))$, into the equation for $U(s)$.\n$$U(s) = U_r(s) - Q(s) \\left( P_n^{-1}(s)\\left[ P_n(s)(1+W_m(s)\\Delta(s))U(s) + D(s) \\right] - U(s) \\right)$$\nSimplifying the term inside the parenthesis:\n$$P_n^{-1}(s)P_n(s)(1+W_m(s)\\Delta(s))U(s) - U(s) = (1+W_m(s)\\Delta(s))U(s) - U(s) = W_m(s)\\Delta(s)U(s)$$\nThus, the equation for $U(s)$ becomes:\n$$U(s) = U_r(s) - Q(s) \\left( W_m(s)\\Delta(s)U(s) + P_n^{-1}(s)D(s) \\right)$$\nTo analyze internal stability, we consider the homogeneous system by setting all external inputs to zero, i.e., $U_r(s) = 0$ and $D(s) = 0$.\n$$U(s) = -Q(s)W_m(s)\\Delta(s)U(s)$$\nThis equation reveals the feedback structure that governs internal stability. We can rearrange it as:\n$$U(s) + Q(s)W_m(s)\\Delta(s)U(s) = 0$$\n$$\\left[ 1 + Q(s)W_m(s)\\Delta(s) \\right] U(s) = 0$$\nFor a non-trivial solution $U(s) \\neq 0$, the characteristic equation for this loop is $1 + Q(s)W_m(s)\\Delta(s) = 0$. The system is internally stable if and only if this equation has no roots in the closed right-half of the complex plane for all admissible perturbations $\\Delta(s)$.\n\nThe feedback interconnection is now explicit. We can model the system as a negative feedback loop where the forward path is $\\Delta(s)$ and the feedback path is $M(s) = Q(s)W_m(s)$. The stability of such a connection with a family of uncertain but stable blocks $\\Delta(s)$ is guaranteed by the small-gain theorem.\n\nThe small-gain theorem states that a feedback interconnection of two stable systems, $M$ and $\\Delta$, is stable if the product of their gains is less than $1$. The gain is defined as the $H_\\infty$-norm, i.e., $\\|G\\|_\\infty = \\sup_{\\omega} |G(j\\omega)|$.\nThe condition for robust stability is:\n$$\\| M(s) \\|_\\infty \\cdot \\| \\Delta(s) \\|_\\infty  1$$\nWe are given that $\\Delta(s)$ is any stable transfer function satisfying $\\| \\Delta(s) \\|_\\infty \\leq 1$. To guarantee stability for the worst-case $\\Delta(s)$ (where its norm is $1$), we must impose the following strict condition on our nominal system:\n$$\\| M(s) \\|_\\infty  1$$\nSubstituting $M(s) = Q(s)W_m(s)$, the rigorous condition for robust internal stability is:\n$$\\| Q(s)W_m(s) \\|_\\infty  1$$\nThis is equivalent to:\n$$\\sup_{\\omega \\ge 0} \\left| Q(j\\omega)W_m(j\\omega) \\right|  1$$\n\nNow, we will analyze how the bandwidth of the $Q(s)$ filter, $\\omega_q$, affects robustness, and construct a counterexample. The uncertainty weighting $W_m(s)$ represents a lightly damped flexible mode. Its magnitude response, $|W_m(j\\omega)| = \\left| k_w \\frac{\\omega_f^2}{-\\omega^2 + 2j\\zeta_f \\omega_f \\omega + \\omega_f^2} \\right|$, exhibits a sharp resonant peak at the natural frequency $\\omega \\approx \\omega_f$. The approximate peak magnitude is $|W_m(j\\omega_f)| \\approx \\frac{k_w}{2\\zeta_f}$. For small damping $\\zeta_f$, this peak can be significantly greater than $1$.\n\nThe filter $Q(s)$ has a magnitude response $|Q(j\\omega)| = \\frac{\\omega_q}{\\sqrt{\\omega^2 + \\omega_q^2}}$, which is characteristic of a first-order low-pass filter. Its gain is approximately $1$ for frequencies $\\omega \\ll \\omega_q$ and rolls off for frequencies $\\omega \\gg \\omega_q$.\n\nThe robust stability condition $\\sup_{\\omega} |Q(j\\omega)W_m(j\\omega)|  1$ must hold for all frequencies. The most challenging frequency is near the resonant peak of $W_m(s)$, i.e., $\\omega \\approx \\omega_f$. At this frequency, we must satisfy $|Q(j\\omega_f)||W_m(j\\omega_f)|  1$. Since $|W_m(j\\omega_f)|$ is large, this requires that $|Q(j\\omega_f)|$ must be sufficiently small. For $|Q(j\\omega_f)| = \\frac{\\omega_q}{\\sqrt{\\omega_f^2 + \\omega_q^2}}$ to be small, the filter bandwidth $\\omega_q$ must be chosen significantly smaller than the flexible mode frequency $\\omega_f$.\n\nThis illustrates the fundamental trade-off in DOB design. A high-bandwidth filter (large $\\omega_q$) is desirable for rejecting a wide range of disturbances. However, an overly aggressive (high) bandwidth extends the DOB's action to high frequencies where the model is inaccurate, as captured by the large magnitude of $W_m(s)$. This can lead to the DOB amplifying measurement noise and, more critically, destabilizing the system by positively feeding back into the unmodeled dynamics.\n\nA counterexample is constructed by comparing two cases.\n1. A conservative design with $\\omega_q \\ll \\omega_f$ (e.g., Test Case $1$ with $\\omega_q=30$, $\\omega_f=200$). Here, at $\\omega_f=200$, the $Q$-filter heavily attenuates the signal, ensuring $|Q(j\\omega_f)W_m(j\\omega_f)|  1$.\n2. An aggressive design with $\\omega_q \\ge \\omega_f$ (e.g., Test Case $2$ with $\\omega_q=400$, $\\omega_f=200$). Here, at $\\omega_f=200$, the $Q$-filter has a gain close to $1$. The product $|Q(j\\omega_f)W_m(j\\omega_f)|$ will be approximately $|W_m(j\\omega_f)| \\approx \\frac{k_w}{2\\zeta_f}$, which can easily exceed $1$, thus violating the stability condition.\n\nThe numerical implementation will evaluate $\\sup_{\\omega \\in [10^{-1}, 10^{4}]} |Q(j\\omega)W_m(j\\omega)|$ for each parameter set and return `True` if this supremum is less than $1$ and `False` otherwise.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and numerically validates the robust stability condition for a\n    Disturbance Observer (DOB) in the presence of multiplicative uncertainty.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (omega_q, omega_f, zeta_f, k_w)\n    test_cases = [\n        (30.0, 200.0, 0.02, 0.1),\n        (400.0, 200.0, 0.02, 0.1),\n        (400.0, 200.0, 0.10, 0.1),\n        (90.0, 200.0, 0.02, 0.1),\n    ]\n\n    results = []\n\n    # Define the frequency range for numerical evaluation of the H-infinity norm.\n    # A logarithmic space is used to cover the wide range efficiently.\n    # 20000 points ensure an accurate capture of the resonant peak.\n    omega = np.logspace(-1, 4, 20000) # Frequencies in rad/s\n\n    for case in test_cases:\n        omega_q, omega_f, zeta_f, k_w = case\n\n        # The complex frequency variable s = j*omega\n        s = 1j * omega\n\n        # Calculate the frequency response of the Q(s) filter.\n        # Q(s) = omega_q / (s + omega_q)\n        q_s_freq_response = omega_q / (s + omega_q)\n\n        # Calculate the frequency response of the uncertainty weighting W_m(s).\n        # W_m(s) = k_w * omega_f^2 / (s^2 + 2*zeta_f*omega_f*s + omega_f^2)\n        wm_s_freq_response = (k_w * omega_f**2) / (s**2 + 2 * zeta_f * omega_f * s + omega_f**2)\n\n        # The transfer function from the uncertainty output to its input is T(s) = Q(s) * W_m(s).\n        t_s_freq_response = q_s_freq_response * wm_s_freq_response\n\n        # According to the small-gain theorem, for robust stability, the H_infinity norm\n        # of T(s) must be less than 1. The H_infinity norm is the supremum of the\n        # magnitude of the frequency response.\n        h_inf_norm_approx = np.max(np.abs(t_s_freq_response))\n\n        # Check the robust stability condition.\n        is_robustly_stable = h_inf_norm_approx  1.0\n        results.append(is_robustly_stable)\n\n    # Final print statement in the exact required format.\n    # The output is a list of booleans indicating robust stability for each case.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond the frequency-domain $Q$-filter approach, disturbance estimation can be framed as an optimal state estimation problem using the Kalman Filter. In this practice, you will augment the system's state with a model of the disturbance and apply the principles of Kalman filtering to compute the optimal steady-state observer gain. This exercise  not only introduces a powerful and widely used alternative but also delves into the practical sensitivity of the estimator to its tuning parameters, the noise covariances.",
            "id": "4218744",
            "problem": "Consider a discrete-time linear time-invariant cyber-physical system (CPS) with a Digital Twin (DT) model whose plant state is affected by an unknown, slowly varying disturbance. The disturbance observer is constructed by augmenting the plant state with the disturbance to enable joint estimation via an optimal linear estimator. The goal is to compute the steady-state gain of the Kalman Filter (KF) used for disturbance estimation and to analyze the sensitivity of that gain to mis-specification of the noise covariances.\n\nThe plant dynamics are modeled as follows. Let the augmented state be $z_k \\in \\mathbb{R}^3$ defined by $z_k = \\begin{bmatrix} x_{p,k} \\\\ x_{v,k} \\\\ d_k \\end{bmatrix}$, where $x_{p,k}$ is position, $x_{v,k}$ is velocity, and $d_k$ is a scalar disturbance that acts as an unknown acceleration and follows a random walk. The discrete-time augmented dynamics are\n$$\nz_{k+1} = A z_k + w_k,\\quad y_k = C z_k + v_k,\n$$\nwith sampling interval $0.1$ seconds, where\n$$\nA = \\begin{bmatrix}\n1  0.1  0 \\\\\n0  1  0.1 \\\\\n0  0  1\n\\end{bmatrix},\\quad\nC = \\begin{bmatrix}\n1  0  0\n\\end{bmatrix}.\n$$\nThe process noise $w_k \\in \\mathbb{R}^3$ and measurement noise $v_k \\in \\mathbb{R}$ are independent, zero-mean Gaussian random variables with covariances\n$$\n\\mathbb{E}[w_k w_k^\\top] = Q_w \\in \\mathbb{R}^{3 \\times 3},\\quad \\mathbb{E}[v_k^2] = R_v \\in \\mathbb{R}_{0}.\n$$\nAll matrices $Q_w$ and $R_v$ are symmetric positive (semi)definite as appropriate.\n\nStarting from the foundational principles of linear Gaussian estimation and the definitions of error covariance propagation and innovation, the steady-state Kalman Filter gain $K_\\infty \\in \\mathbb{R}^{3 \\times 1}$ for the augmented system exists under standard detectability conditions and is obtained by solving the discrete-time algebraic Riccati equation for the steady-state estimation error covariance and forming the corresponding optimal gain expression. You must compute $K_\\infty$ numerically for the given test cases. To assess sensitivity to covariance mis-specification, define the sensitivity index\n$$\nS := \\frac{\\|K_\\infty(Q_w', R_v') - K_\\infty(Q_w, R_v)\\|_F}{\\|K_\\infty(Q_w, R_v)\\|_F},\n$$\nwhere $\\|\\cdot\\|_F$ denotes the Frobenius norm, $K_\\infty(Q_w, R_v)$ is the steady-state gain computed using the baseline covariances, and $K_\\infty(Q_w', R_v')$ is the steady-state gain computed using mis-specified covariances $Q_w' = s_Q Q_w$ and $R_v' = s_R R_v$ for positive scalars $s_Q$ and $s_R$.\n\nYou must implement a program that, for each provided test case, computes:\n- The Frobenius norm $\\|K_\\infty(Q_w, R_v)\\|_F$ of the baseline steady-state gain, and\n- The sensitivity index $S$ for the specified $(s_Q, s_R)$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a two-element list as $[\\|K_\\infty\\|_F, S]$ with both values given as floating-point numbers. For example, the output should look like $[[a,b],[c,d],\\ldots]$ with no spaces.\n\nTest Suite:\nUse the fixed matrices $A$ and $C$ above and the following baseline covariances and mis-specification scalings. For each test case, $Q_w$ is diagonal with the given diagonal entries and $R_v$ is scalar.\n\n- Test case $1$ (balanced baseline, moderate measurement noise):\n  - $Q_w = \\mathrm{diag}(1\\times 10^{-4},\\, 1\\times 10^{-3},\\, 1\\times 10^{-2})$,\n  - $R_v = 1\\times 10^{-2}$,\n  - $s_Q = 10$, $s_R = 0.1$.\n\n- Test case $2$ (very small disturbance variance, moderate measurement noise):\n  - $Q_w = \\mathrm{diag}(1\\times 10^{-5},\\, 1\\times 10^{-5},\\, 1\\times 10^{-6})$,\n  - $R_v = 1\\times 10^{-2}$,\n  - $s_Q = 100$, $s_R = 1$.\n\n- Test case $3$ (large process noise, very small measurement noise):\n  - $Q_w = \\mathrm{diag}(1\\times 10^{-2},\\, 1\\times 10^{-2},\\, 1\\times 10^{-1})$,\n  - $R_v = 1\\times 10^{-4}$,\n  - $s_Q = 0.1$, $s_R = 10$.\n\n- Test case $4$ (moderate process noise, large measurement noise):\n  - $Q_w = \\mathrm{diag}(1\\times 10^{-4},\\, 1\\times 10^{-3},\\, 1\\times 10^{-2})$,\n  - $R_v = 1$,\n  - $s_Q = 1$, $s_R = 100$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[[r_1,s_1],[r_2,s_2],[r_3,s_3],[r_4,s_4]]$), where $r_i$ is the Frobenius norm of the baseline steady-state Kalman gain for test case $i$, and $s_i$ is the corresponding sensitivity index. No units are required, and all quantities must be expressed as floating-point numbers.",
            "solution": "The problem requires the computation of the steady-state Kalman filter gain for a discrete-time linear augmented system and the analysis of its sensitivity to mis-specifications in the noise covariance matrices. The system describes the dynamics of a plant affected by a slowly varying disturbance, a common scenario in cyber-physical systems and control engineering.\n\nThe foundation of the solution lies in the theory of optimal linear estimation for state-space models. The given system is a discrete-time linear time-invariant (LTI) system described by the following state-space equations:\n$$\nz_{k+1} = A z_k + w_k\n$$\n$$\ny_k = C z_k + v_k\n$$\nwhere $z_k \\in \\mathbb{R}^3$ is the augmented state vector, $y_k \\in \\mathbb{R}$ is the measurement, $A \\in \\mathbb{R}^{3 \\times 3}$ is the state transition matrix, and $C \\in \\mathbb{R}^{1 \\times 3}$ is the measurement matrix. The terms $w_k \\in \\mathbb{R}^3$ and $v_k \\in \\mathbb{R}$ represent zero-mean, independent Gaussian process and measurement noise, with covariance matrices $Q_w = \\mathbb{E}[w_k w_k^\\top]$ and $R_v = \\mathbb{E}[v_k^2]$, respectively.\n\nThe Kalman filter is an optimal estimator for the state $z_k$. It operates in two steps: prediction and update. The steady-state behavior of the filter is of interest, where the filter gain converges to a constant value, $K_\\infty$. This occurs when the estimation error covariance reaches a steady state. The steady-state a priori error covariance, denoted as $P_\\infty$, is the unique, symmetric, positive semi-definite solution to the Discrete-time Algebraic Riccati Equation (DARE):\n$$\nP_\\infty = A P_\\infty A^\\top - A P_\\infty C^\\top (C P_\\infty C^\\top + R_v)^{-1} C P_\\infty A^\\top + Q_w\n$$\nFor a unique, stabilizing solution to exist, certain conditions of stabilizability and detectability must be met. The pair $(A, C)$ must be detectable, and the pair $(A, \\sqrt{Q_w})$ must be stabilizable. For the given system matrices $A$ and $C$, the pair $(A, C)$ is observable (a stronger condition than detectability), and for the given positive definite $Q_w$ matrices, the pair $(A, \\sqrt{Q_w})$ is controllable (a stronger condition than stabilizability). Thus, a unique solution $P_\\infty$ is guaranteed to exist.\n\nThe DARE for filtering is not typically solved directly. Standard numerical solvers are designed for the LQR control DARE. Due to the principle of duality, we can use an LQR DARE solver. The control DARE is $X = \\mathcal{A}^\\top X \\mathcal{A} - (\\mathcal{A}^\\top X \\mathcal{B})(\\mathcal{R} + \\mathcal{B}^\\top X \\mathcal{B})^{-1}(\\mathcal{B}^\\top X \\mathcal{A}) + \\mathcal{Q}$. By setting $\\mathcal{A}=A^\\top$, $\\mathcal{B}=C^\\top$, $\\mathcal{Q}=Q_w$, and $\\mathcal{R}=R_v$, solving for $X$ provides the desired filtering covariance matrix $P_\\infty$.\n\nOnce the steady-state covariance $P_\\infty$ is found, the steady-state Kalman gain $K_\\infty$ is computed as:\n$$\nK_\\infty = P_\\infty C^\\top (C P_\\infty C^\\top + R_v)^{-1}\n$$\n\nThe first objective is to compute the Frobenius norm of this baseline gain, $\\|K_\\infty(Q_w, R_v)\\|_F$.\n\nThe second objective is to assess the sensitivity of this gain to changes in the noise covariances. The mis-specified covariances are defined as $Q_w' = s_Q Q_w$ and $R_v' = s_R R_v$. A new steady-state gain, $K_\\infty(Q_w', R_v')$, is calculated by solving the DARE with these new covariances. The sensitivity index, $S$, is then calculated as the relative change in the Frobenius norm:\n$$\nS := \\frac{\\|K_\\infty(Q_w', R_v') - K_\\infty(Q_w, R_v)\\|_F}{\\|K_\\infty(Q_w, R_v)\\|_F}\n$$\n\nThe overall algorithm for each test case is as follows:\n1.  Define the system matrices $A$, $C$, and the baseline noise covariances $Q_w$ and $R_v$.\n2.  Solve the DARE using the baseline covariances to obtain the steady-state error covariance $P_\\infty$.\n3.  Compute the baseline steady-state Kalman gain $K_\\infty(Q_w, R_v)$ and its Frobenius norm.\n4.  Define the mis-specified noise covariances $Q_w' = s_Q Q_w$ and $R_v' = s_R R_v$ using the given scaling factors $s_Q$ and $s_R$.\n5.  Solve the DARE again using the mis-specified covariances to obtain $P'_\\infty$.\n6.  Compute the new steady-state Kalman gain $K_\\infty(Q_w', R_v')$.\n7.  Calculate the sensitivity index $S$.\n8.  Collect the pair of results: $[\\|K_\\infty(Q_w, R_v)\\|_F, S]$.\n\nThis procedure is implemented for each of the four test cases provided.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_discrete_are\n\ndef compute_gain_and_sensitivity(A, C, Qw, Rv, sQ, sR):\n    \"\"\"\n    Computes the steady-state Kalman gain and its sensitivity to covariance mis-specification.\n    \n    Args:\n        A (np.ndarray): State transition matrix.\n        C (np.ndarray): Measurement matrix.\n        Qw (np.ndarray): Process noise covariance matrix.\n        Rv (float): Measurement noise variance.\n        sQ (float): Scaling factor for Qw.\n        sR (float): Scaling factor for Rv.\n        \n    Returns:\n        tuple[float, float]: A tuple containing the Frobenius norm of the baseline\n                             steady-state gain and the sensitivity index S.\n    \"\"\"\n    \n    # 1. Compute baseline steady-state Kalman gain\n    # The DARE for filtering P = A*P*A' - A*P*C'*(C*P*C' + R)^-1*C*P*A' + Q\n    # is solved using the dual LQR DARE solver solve_discrete_are by passing\n    # A.T, C.T, Qw, and Rv.\n    P_inf = solve_discrete_are(A.T, C.T, Qw, np.array([[Rv]]))\n    \n    # K_inf = P_inf * C' * inv(C * P_inf * C' + R)\n    K_inf = P_inf @ C.T @ np.linalg.inv(C @ P_inf @ C.T + Rv)\n    \n    # Compute the Frobenius norm of the baseline gain\n    norm_K_inf = np.linalg.norm(K_inf, 'fro')\n    \n    # 2. Compute gain with mis-specified covariances\n    Qw_prime = sQ * Qw\n    Rv_prime = sR * Rv\n    \n    P_inf_prime = solve_discrete_are(A.T, C.T, Qw_prime, np.array([[Rv_prime]]))\n    K_inf_prime = P_inf_prime @ C.T @ np.linalg.inv(C @ P_inf_prime @ C.T + Rv_prime)\n    \n    # 3. Compute the sensitivity index S\n    norm_diff = np.linalg.norm(K_inf_prime - K_inf, 'fro')\n    \n    # Avoid division by zero if the baseline gain happens to be zero.\n    if norm_K_inf == 0:\n        sensitivity = np.inf if norm_diff  0 else 0.0\n    else:\n        sensitivity = norm_diff / norm_K_inf\n        \n    return norm_K_inf, sensitivity\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    \n    # Fixed system matrices\n    T = 0.1  # Sampling interval of 0.1 seconds\n    A = np.array([\n        [1.0, T, 0.0],\n        [0.0, 1.0, T],\n        [0.0, 0.0, 1.0]\n    ])\n    C = np.array([[1.0, 0.0, 0.0]])\n    \n    # Test Suite\n    test_cases = [\n        # Test case 1\n        {'Qw_diag': [1e-4, 1e-3, 1e-2], 'Rv': 1e-2, 'sQ': 10.0, 'sR': 0.1},\n        # Test case 2\n        {'Qw_diag': [1e-5, 1e-5, 1e-6], 'Rv': 1e-2, 'sQ': 100.0, 'sR': 1.0},\n        # Test case 3\n        {'Qw_diag': [1e-2, 1e-2, 1e-1], 'Rv': 1e-4, 'sQ': 0.1, 'sR': 10.0},\n        # Test case 4\n        {'Qw_diag': [1e-4, 1e-3, 1e-2], 'Rv': 1.0, 'sQ': 1.0, 'sR': 100.0},\n    ]\n    \n    results = []\n    \n    for case in test_cases:\n        Qw = np.diag(case['Qw_diag'])\n        Rv = case['Rv']\n        sQ = case['sQ']\n        sR = case['sR']\n        \n        norm_k, sensitivity = compute_gain_and_sensitivity(A, C, Qw, Rv, sQ, sR)\n        results.append([norm_k, sensitivity])\n\n    # Format the final output string as [[r1,s1],[r2,s2],...] with no spaces.\n    inner_strings = [f\"[{r},{s}]\" for r, s in results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}