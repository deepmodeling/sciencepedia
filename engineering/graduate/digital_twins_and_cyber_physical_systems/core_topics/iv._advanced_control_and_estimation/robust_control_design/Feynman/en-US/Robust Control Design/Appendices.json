{
    "hands_on_practices": [
        {
            "introduction": "This first exercise establishes a crucial connection between the frequency-domain definition of a system's gain and its state-space representation. You will start by analytically calculating the $\\mathcal{H}_{\\infty}$ norm, which represents the peak gain across all frequencies, for a simple yet fundamental first-order system. Then, you will verify this result by applying the Bounded Real Lemma, a cornerstone of modern control theory, demonstrating how a state-space approach using Lyapunov stability concepts certifies the same property .",
            "id": "4241440",
            "problem": "A digital twin of a networked sensor in a cyber-physical system is modeled by a Single-Input Single-Output (SISO) continuous-time transfer function $G(s) = \\dfrac{k}{s+a}$, where $a0$ and $k \\in \\mathbb{R}$. The robustness requirement is posed in the frequency domain: the attenuation of disturbance across the communication channel must be certified by the $\\mathcal{H}_{\\infty}$ norm of $G(s)$. Starting from the definition of the $\\mathcal{H}_{\\infty}$ norm as the supremum of the maximum singular value of $G(j\\omega)$ over all real frequencies, compute $\\|G\\|_{\\infty}$ analytically in terms of $a$ and $k$.\n\nThen, model $G(s)$ in minimal state-space form with zero feedthrough and use the continuous-time Bounded Real Lemma (BRL) as a foundational fact from robust control. Without using any pre-derived formulas beyond the BRL statement itself, verify that the BRL inequality is satisfied with the exact $\\gamma$ equal to the $\\mathcal{H}_{\\infty}$ norm you computed, by constructing a suitable scalar Lyapunov certificate.\n\nExpress the final $\\mathcal{H}_{\\infty}$ norm as a single closed-form analytic expression in terms of $a$ and $k$. No numerical approximation is required.",
            "solution": "The problem is first validated to ensure it is well-posed, scientifically grounded, and self-contained. Upon confirmation of its validity, a two-part solution is provided. First, the $\\mathcal{H}_{\\infty}$ norm of the given transfer function is computed analytically from its definition. Second, this result is verified using the Bounded Real Lemma.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- System transfer function: $G(s) = \\dfrac{k}{s+a}$\n- System type: Single-Input Single-Output (SISO), continuous-time.\n- Parameter constraints: $a  0$ and $k \\in \\mathbb{R}$.\n- Definition of $\\mathcal{H}_{\\infty}$ norm: $\\|G\\|_{\\infty} = \\sup_{\\omega \\in \\mathbb{R}} \\sigma_{\\max}(G(j\\omega))$.\n- Task 1: Analytically compute $\\|G\\|_{\\infty}$ in terms of $a$ and $k$.\n- Task 2: Model $G(s)$ in a minimal state-space form with zero feedthrough ($D=0$).\n- Task 3: Verify the result from Task 1 using the continuous-time Bounded Real Lemma (BRL) by constructing a suitable scalar Lyapunov certificate.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is set in the context of robust control theory, a core discipline in engineering. It uses standard concepts like transfer functions, state-space models, the $\\mathcal{H}_{\\infty}$ norm, and the Bounded Real Lemma, all of which are fundamental and well-established. The system model $G(s)$ represents a stable first-order low-pass filter, which is a physically realistic and common model.\n- **Well-Posed**: The problem is clearly defined. The constraint $a0$ ensures the system's pole is in the left-half complex plane, making the system stable. A stable system is a prerequisite for having a finite $\\mathcal{H}_{\\infty}$ norm. The objectives are specific and lead to a unique analytical solution.\n- **Objective**: The problem is stated using precise mathematical language and contains no subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is scientifically sound, well-posed, and objective. A complete solution will be provided.\n\n### Part 1: Analytical Computation of the $\\mathcal{H}_{\\infty}$ Norm\n\nThe $\\mathcal{H}_{\\infty}$ norm of a transfer function matrix $G(s)$ is defined as the supremum of its largest singular value over all frequencies $\\omega$. For a Single-Input Single-Output (SISO) system, the transfer function $G(s)$ is a scalar. The singular value of a scalar is simply its magnitude. Therefore, the definition simplifies to:\n$$\n\\|G\\|_{\\infty} = \\sup_{\\omega \\in \\mathbb{R}} |G(j\\omega)|\n$$\nThe given transfer function is $G(s) = \\dfrac{k}{s+a}$. To find the frequency response, we substitute $s=j\\omega$, where $j$ is the imaginary unit and $\\omega$ is the angular frequency.\n$$\nG(j\\omega) = \\frac{k}{j\\omega + a} = \\frac{k}{a + j\\omega}\n$$\nThe magnitude of this complex number is:\n$$\n|G(j\\omega)| = \\left| \\frac{k}{a + j\\omega} \\right| = \\frac{|k|}{|a + j\\omega|}\n$$\nThe magnitude of the denominator is $|a + j\\omega| = \\sqrt{a^2 + \\omega^2}$. Thus, the magnitude of the frequency response is:\n$$\n|G(j\\omega)| = \\frac{|k|}{\\sqrt{a^2 + \\omega^2}}\n$$\nWe need to find the supremum of this function for $\\omega \\in \\mathbb{R}$. The numerator $|k|$ is a non-negative constant. The function $|G(j\\omega)|$ is maximized when its denominator, $\\sqrt{a^2 + \\omega^2}$, is minimized. The term inside the square root, $a^2 + \\omega^2$, is minimized when $\\omega^2$ is minimized. Since $\\omega \\in \\mathbb{R}$, the minimum value of $\\omega^2$ is $0$, which occurs at $\\omega=0$.\n\nAt $\\omega=0$, the denominator has its minimum value:\n$$\n\\min_{\\omega \\in \\mathbb{R}} \\sqrt{a^2 + \\omega^2} = \\sqrt{a^2 + 0^2} = \\sqrt{a^2} = a\n$$\nWe use $a$ instead of $|a|$ because the problem states $a0$.\n\nThe maximum value of $|G(j\\omega)|$ is therefore:\n$$\n\\sup_{\\omega \\in \\mathbb{R}} |G(j\\omega)| = \\frac{|k|}{a}\n$$\nThus, the $\\mathcal{H}_{\\infty}$ norm of the system is:\n$$\n\\|G\\|_{\\infty} = \\frac{|k|}{a}\n$$\n\n### Part 2: Verification using the Bounded Real Lemma\n\nFirst, we represent $G(s)$ in a minimal state-space form $(\\mathbf{A}, \\mathbf{B}, \\mathbf{C}, \\mathbf{D})$ with zero feedthrough ($\\mathbf{D}=0$).\n$$\n\\dot{\\mathbf{x}} = \\mathbf{A}\\mathbf{x} + \\mathbf{B}u\n$$\n$$\ny = \\mathbf{C}\\mathbf{x} + \\mathbf{D}u\n$$\nFor the first-order system $G(s) = \\dfrac{k}{s+a}$, we can define a scalar state $x(t)$ such that its Laplace transform $X(s)$ relates to the input $U(s)$ by $X(s) = \\frac{1}{s+a}U(s)$. This corresponds to the differential equation $\\dot{x}(t) + ax(t) = u(t)$. The output is $Y(s) = kX(s)$, or $y(t)=kx(t)$. This gives the following state-space realization:\n$$\n\\mathbf{A} = [-a], \\quad \\mathbf{B} = [1], \\quad \\mathbf{C} = [k], \\quad \\mathbf{D} = [0]\n$$\nThis realization is minimal because it is both controllable (the controllability matrix is just $\\mathbf{B}=[1]$, which has full rank) and observable (the observability matrix is just $\\mathbf{C}=[k]$, which has full rank, assuming $k \\neq 0$. If $k=0$, the system is trivial and the norm is $0$).\n\nThe continuous-time Bounded Real Lemma (non-strict version) states that for a stable system with state-space realization $(\\mathbf{A}, \\mathbf{B}, \\mathbf{C}, \\mathbf{D})$, its $\\mathcal{H}_{\\infty}$ norm satisfies $\\|G\\|_{\\infty} \\le \\gamma$ if and only if there exists a symmetric positive semi-definite matrix $\\mathbf{P}$ ($\\mathbf{P} = \\mathbf{P}^T \\ge 0$) solving the following Linear Matrix Inequality (LMI):\n$$\n\\begin{pmatrix}\n\\mathbf{A}^T \\mathbf{P} + \\mathbf{P} \\mathbf{A}  \\mathbf{P} \\mathbf{B}  \\mathbf{C}^T \\\\\n\\mathbf{B}^T \\mathbf{P}  -\\gamma \\mathbf{I}  \\mathbf{D}^T \\\\\n\\mathbf{C}  \\mathbf{D}  -\\gamma \\mathbf{I}\n\\end{pmatrix} \\le 0\n$$\nWe need to verify this condition holds for $\\gamma = \\|G\\|_{\\infty} = \\frac{|k|}{a}$. Since the system is SISO, the Lyapunov certificate $\\mathbf{P}$ is a scalar, which we denote as $p$. For a non-trivial certificate, we require $p0$, which corresponds to $\\mathbf{P}0$.\n\nSubstituting the state-space matrices and $\\mathbf{D}=0$ into the LMI, we get:\n$$\n\\mathbf{M} = \\begin{pmatrix}\n(-a)p + p(-a)  p(1)  k \\\\\n(1)p  -\\gamma  0 \\\\\nk  0  -\\gamma\n\\end{pmatrix} = \\begin{pmatrix}\n-2ap  p  k \\\\\np  -\\gamma  0 \\\\\nk  0  -\\gamma\n\\end{pmatrix} \\le 0\n$$\nFor this matrix $\\mathbf{M}$ to be negative semi-definite, all of its principal minors of order $m$ must have sign $(-1)^m$ or be zero.\n1. The diagonal elements (minors of order $1$) must be non-positive:\n   - $-2ap \\le 0$. Since $a0$ and we seek $p0$, this is satisfied.\n   - $-\\gamma \\le 0$. Since $\\gamma = \\frac{|k|}{a}$, with $|k| \\ge 0$ and $a0$, this is also satisfied.\n\n2. The principal minors of order $2$ must be non-negative:\n   - $\\det \\begin{pmatrix} -2ap  p \\\\ p  -\\gamma \\end{pmatrix} = (-2ap)(-\\gamma) - p^2 = 2ap\\gamma - p^2 \\ge 0$.\n   - $\\det \\begin{pmatrix} -2ap  k \\\\ k  -\\gamma \\end{pmatrix} = (-2ap)(-\\gamma) - k^2 = 2ap\\gamma - k^2 \\ge 0$.\n   - $\\det \\begin{pmatrix} -\\gamma  0 \\\\ 0  -\\gamma \\end{pmatrix} = \\gamma^2 \\ge 0$. This is always true.\n\n3. The determinant of $\\mathbf{M}$ (minor of order $3$) must be non-positive:\n   $$\n   \\det(\\mathbf{M}) = -2ap(\\gamma^2) - p(-p\\gamma) + k(k\\gamma) = \\gamma(-2ap\\gamma + p^2 + k^2) \\le 0\n   $$\nSince $\\gamma \\ge 0$, this requires $p^2 - 2ap\\gamma + k^2 \\le 0$.\n\nNow, we substitute $\\gamma = \\frac{|k|}{a}$ and construct the certificate $p$. The condition from the determinant becomes:\n$$\np^2 - 2a\\left(\\frac{|k|}{a}\\right)p + k^2 \\le 0\n$$\n$$\np^2 - 2|k|p + k^2 \\le 0\n$$\nSince $k^2 = |k|^2$, we have:\n$$\np^2 - 2|k|p + |k|^2 \\le 0\n$$\n$$\n(p - |k|)^2 \\le 0\n$$\nA squared real number cannot be negative. The only way this inequality can be satisfied is if the term is exactly zero:\n$$\n(p - |k|)^2 = 0 \\implies p = |k|\n$$\nThis gives us our candidate for the scalar Lyapunov certificate, $p = |k|$. If $k \\neq 0$, then $p  0$ as required. If $k=0$, then $p=0$, and the LMI holds trivially as the zero matrix.\n\nLet's check if $p=|k|$ satisfies the remaining conditions derived from the principal minors of order 2, with $\\gamma = |k|/a$.\n- $2ap\\gamma - p^2 = 2a(|k|)\\left(\\frac{|k|}{a}\\right) - (|k|)^2 = 2|k|^2 - |k|^2 = |k|^2 \\ge 0$. This holds.\n- $2ap\\gamma - k^2 = 2a(|k|)\\left(\\frac{|k|}{a}\\right) - k^2 = 2|k|^2 - k^2 = 2|k|^2 - |k|^2 = |k|^2 \\ge 0$. This also holds.\n\nSince all conditions are met with the choice $p = |k|$, we have successfully constructed a suitable Lyapunov certificate. This confirms that for $\\gamma = \\frac{|k|}{a}$, the BRL inequality is satisfied (as an equality, $\\det(\\mathbf{M})=0$), verifying that the $\\mathcal{H}_{\\infty}$ norm is indeed $\\frac{|k|}{a}$.",
            "answer": "$$\n\\boxed{\\frac{|k|}{a}}\n$$"
        },
        {
            "introduction": "Control system design often involves navigating critical trade-offs, and this practice explores one of the most important: the balance between performance and robustness. We will analyze a scenario where a high-gain controller, intended to improve system performance, inadvertently makes the closed-loop system fragile and sensitive to modeling errors. By calculating the $\\mathcal{H}_{\\infty}$ norm of the sensitivity function, you will quantify this lack of robustness and gain insight into why the small-gain theorem is a vital tool for certifying stability .",
            "id": "4241449",
            "problem": "A cyber-physical servo system is operated with a Digital Twin (DT) model that is used for controller tuning. The DTâ€™s nominal plant is a unit-normalized second-order compliant actuator modeled as $P_{0}(s) = \\frac{1}{s^{2} + 2 \\zeta s + 1}$ with damping ratio $\\zeta = 0.1$. A proportional controller $K(s) = k$ with gain $k = 20$ is deployed to achieve high low-frequency loop gain. The actual plant differs from $P_{0}(s)$ by an additive uncertainty $\\Delta_{a}(s)$ that is bounded in the Hardy space $\\mathcal{H}_{\\infty}$ sense by a constant weight $W(s) = w_{0}$ with $w_{0} = 0.1$, that is, $|\\Delta_{a}(j\\omega)| \\leq w_{0}$ for all real $\\omega$. The closed loop with the DT model is nominally stable for the chosen parameters.\n\nStarting from fundamental definitions of the loop transfer function $L(s) = P_{0}(s) K(s)$ and the sensitivity function $S(s) = \\frac{1}{1 + L(s)}$, use first principles to derive the frequency response $|S(j\\omega)|$ and determine its supremum over $\\omega \\in [0,\\infty)$. Provide the single number equal to $\\|S\\|_{\\infty} = \\sup_{\\omega \\geq 0} |S(j\\omega)|$. Express your final answer as a dimensionless scalar and round your answer to four significant figures.\n\nYour construction should show how a nominally stable, high loop-gain design can violate the small-gain robust stability bound for additive uncertainty, and how this violation manifests as a peak in the sensitivity function. No shortcut formulas are permitted; base your reasoning on core definitions and calculus.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n- Nominal plant model: $P_{0}(s) = \\frac{1}{s^{2} + 2 \\zeta s + 1}$\n- Damping ratio: $\\zeta = 0.1$\n- Controller: $K(s) = k$\n- Controller gain: $k = 20$\n- Additive uncertainty bound: $|\\Delta_{a}(j\\omega)| \\leq |W(s)| = w_{0}$\n- Uncertainty weight: $w_{0} = 0.1$\n- Loop transfer function definition: $L(s) = P_{0}(s) K(s)$\n- Sensitivity function definition: $S(s) = \\frac{1}{1 + L(s)}$\n- Objective: Determine $\\|S\\|_{\\infty} = \\sup_{\\omega \\geq 0} |S(j\\omega)|$ and round to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is based on fundamental principles of linear control theory, specifically robust control. It uses standard definitions for the plant, controller, loop transfer function, sensitivity function, and $\\mathcal{H}_{\\infty}$ norm. All parameters are provided, making the problem self-contained and mathematically well-posed. The language is precise and objective. The values are physically plausible for a model of a servo system. The premise that a high-gain controller can lead to a large sensitivity peak, indicating poor robustness, is a cornerstone concept in control design. The problem is therefore deemed valid.\n\n### Step 3: Verdict and Action\nThe problem is valid and a full solution will be provided.\n\n### Solution Derivation\n\nThe nominal plant is given by $P_{0}(s) = \\frac{1}{s^{2} + 2 \\zeta s + 1}$, with a damping ratio $\\zeta = 0.1$. The proportional controller is $K(s) = k = 20$.\n\nThe loop transfer function, $L(s)$, is the product of the controller and the nominal plant:\n$$L(s) = K(s) P_{0}(s) = 20 \\cdot \\frac{1}{s^{2} + 2(0.1)s + 1} = \\frac{20}{s^{2} + 0.2s + 1}$$\n\nThe sensitivity function, $S(s)$, is defined as:\n$$S(s) = \\frac{1}{1 + L(s)}$$\nSubstituting the expression for $L(s)$:\n$$S(s) = \\frac{1}{1 + \\frac{20}{s^{2} + 0.2s + 1}} = \\frac{s^{2} + 0.2s + 1}{(s^{2} + 0.2s + 1) + 20} = \\frac{s^{2} + 0.2s + 1}{s^{2} + 0.2s + 21}$$\nTo find the $\\mathcal{H}_{\\infty}$ norm, we analyze the magnitude of the frequency response, $|S(j\\omega)|$. We substitute $s = j\\omega$:\n$$S(j\\omega) = \\frac{(j\\omega)^{2} + 0.2(j\\omega) + 1}{(j\\omega)^{2} + 0.2(j\\omega) + 21} = \\frac{-\\omega^{2} + 0.2j\\omega + 1}{-\\omega^{2} + 0.2j\\omega + 21} = \\frac{(1 - \\omega^{2}) + j(0.2\\omega)}{(21 - \\omega^{2}) + j(0.2\\omega)}$$\nThe squared magnitude of the frequency response is:\n$$|S(j\\omega)|^{2} = \\frac{|(1 - \\omega^{2}) + j(0.2\\omega)|^{2}}{|(21 - \\omega^{2}) + j(0.2\\omega)|^{2}} = \\frac{(1 - \\omega^{2})^{2} + (0.2\\omega)^{2}}{(21 - \\omega^{2})^{2} + (0.2\\omega)^{2}}$$\nExpanding the terms:\n$$|S(j\\omega)|^{2} = \\frac{1 - 2\\omega^{2} + \\omega^{4} + 0.04\\omega^{2}}{441 - 42\\omega^{2} + \\omega^{4} + 0.04\\omega^{2}} = \\frac{\\omega^{4} - 1.96\\omega^{2} + 1}{\\omega^{4} - 41.96\\omega^{2} + 441}$$\nWe seek to find the maximum value of this function for $\\omega \\in [0, \\infty)$. This is equivalent to maximizing the function with respect to $\\omega^{2}$. Let $x = \\omega^{2}$, where $x \\geq 0$. We define the function $f(x)$:\n$$f(x) = \\frac{x^{2} - 1.96x + 1}{x^{2} - 41.96x + 441}$$\nTo find the extrema, we compute the derivative $f'(x)$ and set it to zero. Using the quotient rule, $\\frac{d}{dx}\\left(\\frac{u}{v}\\right) = \\frac{u'v - uv'}{v^{2}}$, with $u(x) = x^{2} - 1.96x + 1$ and $v(x) = x^{2} - 41.96x + 441$:\n$$u'(x) = 2x - 1.96$$\n$$v'(x) = 2x - 41.96$$\nSetting the numerator of the derivative to zero:\n$$u'v - uv' = (2x - 1.96)(x^{2} - 41.96x + 441) - (x^{2} - 1.96x + 1)(2x - 41.96) = 0$$\nExpanding and combining like terms:\n$$(-85.88 + 45.88)x^2 + (964.2416 - 84.2416)x + (-864.36 + 41.96) = 0$$\n$$-40x^{2} + 880x - 822.4 = 0$$\nDividing by $-40$:\n$$x^{2} - 22x + 20.56 = 0$$\nWe solve this quadratic equation for $x$ using the quadratic formula $x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n$$x = \\frac{22 \\pm \\sqrt{(-22)^{2} - 4(1)(20.56)}}{2(1)} = \\frac{22 \\pm \\sqrt{484 - 82.24}}{2} = \\frac{22 \\pm \\sqrt{401.76}}{2}$$\nThe two solutions for $x = \\omega^{2}$ are:\n$$x_{1} = \\frac{22 - \\sqrt{401.76}}{2} \\approx \\frac{22 - 20.04395}{2} \\approx 0.978025$$\n$$x_{2} = \\frac{22 + \\sqrt{401.76}}{2} \\approx \\frac{22 + 20.04395}{2} \\approx 21.021975$$\nWe must determine which of these critical points corresponds to a maximum. We check the function value at the endpoints ($x=0$ and as $x \\to \\infty$) and at the critical points.\n- At $x=0$ ($\\omega=0$): $f(0) = \\frac{1}{441} \\approx 0.00227$.\n- As $x \\to \\infty$ ($\\omega \\to \\infty$): $\\lim_{x \\to \\infty} f(x) = 1$.\n- At $x_{1} \\approx 0.978025$: $f(0.978025) \\approx \\frac{(0.978025)^2 - 1.96(0.978025) + 1}{(0.978025)^2 - 41.96(0.978025) + 441} \\approx \\frac{0.0396}{400.9} \\approx 9.88 \\times 10^{-5}$. This is a minimum.\n- At $x_{2} \\approx 21.021975$:\n$$f(21.021975) \\approx \\frac{(21.021975)^{2} - 1.96(21.021975) + 1}{(21.021975)^{2} - 41.96(21.021975) + 441}$$\n$$f(21.021975) \\approx \\frac{441.9234 - 41.2031 + 1}{441.9234 - 882.0421 + 441} = \\frac{401.7203}{0.8813} \\approx 455.83$$\nThis value is the maximum of $f(x)$. Thus, the peak squared magnitude of the sensitivity function is $\\|S\\|_{\\infty}^{2} \\approx 455.83$.\nThe $\\mathcal{H}_{\\infty}$ norm is the supremum of the magnitude, which is the square root of this value:\n$$\\|S\\|_{\\infty} = \\sup_{\\omega \\geq 0} |S(j\\omega)| = \\sqrt{f(x_{2})} \\approx \\sqrt{455.83} \\approx 21.3502$$\nThe robust stability condition for additive uncertainty requires $w_0 k \\|S\\|_{\\infty}  1$, which implies $\\|S\\|_{\\infty}  1/(w_0 k) = 1/(0.1 \\cdot 20) = 0.5$. Our calculated peak of approximately $21.35$ massively violates this condition, demonstrating how the high-gain design created a system with very poor robustness to this class of uncertainty.\n\nRounding the result to four significant figures yields $21.35$.",
            "answer": "$$\\boxed{21.35}$$"
        },
        {
            "introduction": "Moving beyond the norm-based uncertainties of the previous exercises, this practice tackles structured parametric uncertainty, where a system's physical parameters are known to vary within a given range. You will investigate a \"polytopic\" system model, common in digital twins, where the uncertainty is captured by a set of vertex systems. The challenge is to derive the conditions for a single, fixed controller to robustly stabilize every possible plant in this family and then to implement a computational search for such a controller, illustrating the power of Lyapunov methods in computational robust control design .",
            "id": "4241443",
            "problem": "Consider a continuous-time, linear time-invariant cyber-physical system modeled within a Digital Twin as an uncertain plant whose state-space matrices vary affinely over a convex polytope. The uncertainty set is represented by a finite set of vertices $\\{(A_i,B_i)\\}_{i=1}^{N}$ with $A_i \\in \\mathbb{R}^{n \\times n}$ and $B_i \\in \\mathbb{R}^{n \\times m}$, and the actual plant matrices $(A(\\theta),B(\\theta))$ are any convex combination of the vertices, i.e., $A(\\theta) = \\sum_{i=1}^{N} \\theta_i A_i$, $B(\\theta) = \\sum_{i=1}^{N} \\theta_i B_i$ where $\\theta_i \\ge 0$ and $\\sum_{i=1}^{N} \\theta_i = 1$. You are tasked to ensure robust stabilization using static state feedback $u(t) = K x(t)$ that is valid for all convex combinations of the vertices. Begin from the fundamental Lyapunov stability principle for linear systems and the definition of convexity, and derive conditions that guarantee the existence of a common symmetric positive definite matrix $P \\succ 0$ certifying robust exponential stability for all vertices simultaneously under a single constant feedback matrix $K$. The conditions must be expressible as linear matrix inequalities in appropriately chosen decision variables, derived without assuming any specialized solver.\n\nThen, design an algorithm that searches for a feasible pair $(K,P)$ satisfying these conditions for given vertices. Your algorithm must be correct in the sense that, if it finds a certificate $(K,P)$, the derived inequalities are satisfied for all provided vertices. For numerical robustness, require strict inequalities by enforcing a margin $S_i \\preceq -\\varepsilon I_n$ with a fixed small constant $\\varepsilon  0$ at each vertex $i$, where $S_i$ is the symmetric part specified by your derived conditions and $I_n$ is the identity matrix of dimension $n$. Your algorithm may employ a structured search over a restricted family of matrices $P$ and gains $K$ provided that this restriction is explicitly stated and justified; it must check the derived inequalities exactly for each candidate.\n\nYour program must implement this algorithm and evaluate the following test suite, which covers a general case, a boundary case where no control action is needed, and an infeasible case:\n\n- Test Case 1 (Robustly stabilizable mass-spring-damper Digital Twin with stiffness uncertainty):\n  - Dimension: $n=2$, $m=1$.\n  - Vertices: $A_1 = \\begin{bmatrix} 0  1 \\\\ -1.0  -0.4 \\end{bmatrix}$, $A_2 = \\begin{bmatrix} 0  1 \\\\ -2.0  -0.4 \\end{bmatrix}$, and $B_1 = B_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$.\n- Test Case 2 (Open-loop stable polytopic plant; feedback $K=0$ suffices):\n  - Dimension: $n=2$, $m=1$.\n  - Vertices: $A_1 = \\begin{bmatrix} -1.0  0 \\\\ 0  -2.0 \\end{bmatrix}$, $A_2 = \\begin{bmatrix} -1.5  0 \\\\ 0  -1.0 \\end{bmatrix}$, and $B_1 = B_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$.\n- Test Case 3 (Infeasible due to an uncontrollable unstable vertex):\n  - Dimension: $n=2$, $m=1$.\n  - Vertices: $(A_1,B_1)$ with $A_1 = \\begin{bmatrix} 0  1 \\\\ 0  0 \\end{bmatrix}$ and $B_1 = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$, and $(A_2,B_2)$ with $A_2 = \\begin{bmatrix} -1  1 \\\\ -1  -1 \\end{bmatrix}$ and $B_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$.\n\nImplementation requirements:\n- Use a fixed margin $\\varepsilon = 10^{-5}$ when checking strict negative definiteness in the inequalities.\n- Restrict the Lyapunov matrix to be diagonal, i.e., $P = \\mathrm{diag}(p_1,\\dots,p_n)$ with $p_j  0$, and search over a finite set of positive values for each $p_j$. Restrict the feedback to be static state feedback $K \\in \\mathbb{R}^{m \\times n}$, and search over a finite grid for its entries.\n- For each candidate pair $(K,P)$, form the symmetric matrices $S_i$ implied by your derived conditions at each vertex $i$, and accept $(K,P)$ if and only if all $S_i \\preceq -\\varepsilon I_n$ hold.\n- The program should return, for each test case in the order listed above, the Boolean value $ \\mathrm{True}$ if such a pair $(K,P)$ is found, and $ \\mathrm{False}$ otherwise.\n\nYour program should produce a single line of output containing the results as a comma-separated Python-style list of Booleans enclosed in square brackets (e.g., \"[True,False,True]\"). No physical units, angles, or percentages are involved in this problem. All numerical quantities are real numbers with standard floating-point interpretation.",
            "solution": "The problem requires the derivation of stability conditions for a polytopic uncertain system and the implementation of a search algorithm to find a robust static state-feedback controller.\n\n### Step 1: Derivation of Robust Stability Conditions\n\nThe system under consideration is a continuous-time linear time-invariant (LTI) plant described by the state-space equations:\n$$ \\dot{x}(t) = A(\\theta)x(t) + B(\\theta)u(t) $$\nwhere $x(t) \\in \\mathbb{R}^n$ is the state vector, and $u(t) \\in \\mathbb{R}^m$ is the control input. The system matrices $(A(\\theta), B(\\theta))$ are uncertain and belong to a convex polytope defined by a finite set of $N$ vertices $\\{(A_i, B_i)\\}_{i=1}^{N}$. Any plant realization is a convex combination of these vertices:\n$$ A(\\theta) = \\sum_{i=1}^{N} \\theta_i A_i, \\quad B(\\theta) = \\sum_{i=1}^{N} \\theta_i B_i $$\nwith parameters $\\theta_i \\ge 0$ and $\\sum_{i=1}^{N} \\theta_i = 1$.\n\nWe are to design a static state-feedback controller $u(t) = K x(t)$, where $K \\in \\mathbb{R}^{m \\times n}$ is a constant gain matrix. The resulting closed-loop system is:\n$$ \\dot{x}(t) = (A(\\theta) + B(\\theta)K)x(t) $$\n\nAccording to the Lyapunov stability theory for linear systems, the closed-loop system is exponentially stable if and only if there exists a symmetric positive definite matrix $P \\succ 0$ (i.e., $P=P^T$ and $x^T P x  0$ for all $x \\neq 0$) such that the following inequality holds:\n$$ (A(\\theta) + B(\\theta)K)^T P + P (A(\\theta) + B(\\theta)K) \\prec 0 $$\nThis inequality is known as the Lyapunov inequality.\n\nTo ensure robust stability for all possible plant realizations within the polytope, we must find a single, *common* Lyapunov matrix $P \\succ 0$ and a single gain matrix $K$ that satisfy the Lyapunov inequality for all admissible $\\theta$.\n\nSubstituting the polytopic definitions of $A(\\theta)$ and $B(\\theta)$ into the inequality:\n$$ \\left(\\sum_{i=1}^{N} \\theta_i A_i + \\left(\\sum_{i=1}^{N} \\theta_i B_i\\right)K\\right)^T P + P \\left(\\sum_{i=1}^{N} \\theta_i A_i + \\left(\\sum_{i=1}^{N} \\theta_i B_i\\right)K\\right) \\prec 0 $$\nUsing the linearity of matrix operations, this can be rewritten as:\n$$ \\sum_{i=1}^{N} \\theta_i \\left[ (A_i + B_i K)^T P + P (A_i + B_i K) \\right] \\prec 0 $$\nLet us define the matrix $S_i(P, K) = (A_i + B_i K)^T P + P (A_i + B_i K)$. The condition becomes:\n$$ \\sum_{i=1}^{N} \\theta_i S_i(P, K) \\prec 0 $$\nThis expression represents a convex combination of the matrices $S_i$. A key property of convex sets is that if a condition holds for all vertices, it holds for any point within their convex hull. Therefore, if we can guarantee that $S_i(P, K) \\prec 0$ for each vertex $i=1, \\dots, N$, then the sum, being a convex combination of negative definite matrices (with $\\theta_i \\ge 0$, not all zero), will also be negative definite.\n\nThus, the condition for robust stability simplifies to finding a common symmetric matrix $P \\succ 0$ and a gain matrix $K$ such that the following set of matrix inequalities holds simultaneously for all vertices $i = 1, \\dots, N$:\n$$ (A_i + B_i K)^T P + P (A_i + B_i K) \\prec 0 $$\n\nThese inequalities are not linear in the decision variables $P$ and $K$ due to product terms like $K^T P$ and $P K$. They are Bilinear Matrix Inequalities (BMIs). To convert them to Linear Matrix Inequalities (LMIs), a standard change of variables is to let $X = P^{-1}$ and $Y = K P^{-1} = K X$. Then $P = X^{-1}$ and $K = Y X^{-1}$. Pre- and post-multiplying the BMI by $X$ yields:\n$$ X(A_i + B_i K)^T P X + X P (A_i + B_i K) X \\prec 0 $$\n$$ (A_i X + B_i Y)^T + (A_i X + B_i Y) \\prec 0 $$\n$$ A_i X + X A_i^T + B_i Y + Y^T B_i^T \\prec 0 $$\nThis, along with $X \\succ 0$, is a set of LMIs in the variables $X$ and $Y$, which can be solved efficiently. However, the problem specifies a direct search over $(K, P)$.\n\n### Step 2: Algorithm Design\n\nThe problem instructs us to design an algorithm that searches for a feasible pair $(K,P)$ under specific restrictions, rather than solving the general LMI formulation.\n\n1.  **Define Search Space**:\n    *   The Lyapunov matrix $P$ is restricted to be diagonal: $P = \\mathrm{diag}(p_1, \\dots, p_n)$ with $p_j  0$. We will search over a pre-defined finite set of positive values for each $p_j$.\n    *   The feedback gain matrix $K \\in \\mathbb{R}^{m \\times n}$ entries are searched over a pre-defined finite grid of real numbers.\n\n2.  **Iterative Search**:\n    The algorithm performs a systematic, brute-force search over the discrete candidate sets for $P$ and $K$.\n    *   An outer loop iterates through all possible diagonal matrices $P$ from its defined search space. By construction, these candidates are symmetric and positive definite.\n    *   An inner loop iterates through all possible gain matrices $K$ from its defined grid.\n\n3.  **Verification**:\n    For each candidate pair $(P, K)$, the algorithm verifies if it constitutes a valid certificate of robust stability.\n    *   For each vertex $i = 1, \\dots, N$, the matrix $S_i = (A_i + B_i K)^T P + P (A_i + B_i K)$ is computed.\n    *   For numerical robustness, we must check for strict negative definiteness with a margin $\\varepsilon = 10^{-5}$. The condition to be verified is $S_i \\preceq -\\varepsilon I_n$, where $I_n$ is the $n \\times n$ identity matrix.\n    *   A symmetric matrix $M$ satisfies $M \\preceq c I$ if and only if its maximum eigenvalue, $\\lambda_{\\max}(M)$, satisfies $\\lambda_{\\max}(M) \\le c$. Thus, the check is equivalent to verifying $\\lambda_{\\max}(S_i) \\le -\\varepsilon$ for all $i=1, \\dots, N$.\n    *   The eigenvalues are computed for the symmetric matrix $S_i$. If for any vertex $i$, this condition is violated, the current pair $(P, K)$ is discarded, and the search continues.\n\n4.  **Termination**:\n    *   If a pair $(P, K)$ is found that satisfies the inequalities for all vertices simultaneously, the algorithm has found a valid certificate. For the corresponding test case, the result is `True`, and the search for that case terminates.\n    *   If the loops complete without finding any such pair, the search space has been exhausted. The algorithm concludes that no solution was found under the given restrictions, and the result for that test case is `False`.\n\nIt is crucial to note that this algorithm's success depends on the chosen search spaces for $P$ and $K$ and the restriction that $P$ must be diagonal. As shown by analysis of Test Case 1, a system in controllable canonical form cannot be proven stable using a diagonal Lyapunov matrix, as the $(1,1)$ element of the resulting Lyapunov matrix equation will always be zero, violating the strict negative definiteness requirement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import product\n\ndef find_stabilizer(case_data):\n    \"\"\"\n    Searches for a robustly stabilizing state-feedback controller K and\n    a diagonal Lyapunov matrix P for a given polytopic uncertain system.\n    \"\"\"\n    A_verts, B_verts, n, m, epsilon = case_data\n\n    # Define a discrete search space for the diagonal entries of P.\n    # P must be positive definite, so we choose positive values.\n    p_values = [0.1, 0.5, 1.0, 5.0, 10.0]\n\n    # Define a discrete grid for the entries of the feedback gain matrix K.\n    # The range is chosen to be reasonably broad.\n    k_values = np.linspace(-10.0, 10.0, num=9)  # 9 values from -10 to 10\n\n    # Iterate through all candidate P matrices (diagonal)\n    p_diagonals = product(p_values, repeat=n)\n    for p_diag_tuple in p_diagonals:\n        P = np.diag(p_diag_tuple)\n        \n        # Iterate through all candidate K matrices\n        k_entries = product(k_values, repeat=m * n)\n        for k_flat_tuple in k_entries:\n            K = np.array(k_flat_tuple).reshape((m, n))\n            \n            # For the current (P, K) pair, check the stability condition at each vertex.\n            is_pair_valid = True\n            for i in range(len(A_verts)):\n                Ai = A_verts[i]\n                Bi = B_verts[i]\n                \n                # Closed-loop matrix for vertex i\n                A_cl = Ai + Bi @ K\n                \n                # Form the matrix S_i from the Lyapunov inequality\n                S_i = A_cl.T @ P + P @ A_cl\n                \n                # Check for strict negative definiteness: S_i = -epsilon * I\n                # This is equivalent to max(eigenvalues(S_i)) = -epsilon.\n                # Use eigvalsh for symmetric matrices for numerical stability and efficiency.\n                try:\n                    eigenvalues = np.linalg.eigvalsh(S_i)\n                    if np.max(eigenvalues)  -epsilon:\n                        is_pair_valid = False\n                        break  # This (P, K) pair is invalid, try next one.\n                except np.linalg.LinAlgError:\n                    # If eigenvalue computation fails, the matrix is likely ill-conditioned.\n                    # We treat this as a failure for this candidate pair.\n                    is_pair_valid = False\n                    break\n\n            if is_pair_valid:\n                # A valid (P, K) certificate was found for all vertices.\n                return True\n\n    # If the loops complete, no suitable (P, K) was found in the search space.\n    return False\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the search algorithm.\n    \"\"\"\n    epsilon = 1e-5\n\n    # Test Case 1: Robustly stabilizable mass-spring-damper, but not with a diagonal P.\n    case1_A1 = np.array([[0.0, 1.0], [-1.0, -0.4]])\n    case1_A2 = np.array([[0.0, 1.0], [-2.0, -0.4]])\n    case1_B = np.array([[0.0], [1.0]])\n    case1 = ([case1_A1, case1_A2], [case1_B, case1_B], 2, 1, epsilon)\n\n    # Test Case 2: Open-loop stable system where K=0 is a valid solution.\n    case2_A1 = np.array([[-1.0, 0.0], [0.0, -2.0]])\n    case2_A2 = np.array([[-1.5, 0.0], [0.0, -1.0]])\n    case2_B = np.array([[0.0], [1.0]])\n    case2 = ([case2_A1, case2_A2], [case2_B, case2_B], 2, 1, epsilon)\n\n    # Test Case 3: Infeasible due to an uncontrollable unstable vertex.\n    case3_A1 = np.array([[0.0, 1.0], [0.0, 0.0]])\n    case3_B1 = np.array([[0.0], [0.0]])\n    case3_A2 = np.array([[-1.0, 1.0], [-1.0, -1.0]])\n    case3_B2 = np.array([[0.0], [1.0]])\n    case3 = ([case3_A1, case3_A2], [case3_B1, case3_B2], 2, 1, epsilon)\n    \n    test_cases = [\n        case1,\n        case2,\n        case3,\n    ]\n\n    results = []\n    for case in test_cases:\n        result = find_stabilizer(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}