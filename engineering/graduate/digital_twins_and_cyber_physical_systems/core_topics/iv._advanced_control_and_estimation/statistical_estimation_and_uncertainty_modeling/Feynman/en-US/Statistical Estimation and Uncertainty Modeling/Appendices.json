{
    "hands_on_practices": [
        {
            "introduction": "A primary task in developing a digital twin is to estimate the unknown parameters of its underlying model from sensor data. This first practice introduces the principle of Maximum Likelihood Estimation (MLE), a cornerstone of statistical inference that asks: what parameter value makes our observed data most probable? By deriving the MLE for the arrival rate in a hypothetical cyber-physical system network , you will build foundational skills in constructing likelihood functions and using calculus to find optimal parameter estimates.",
            "id": "4247293",
            "problem": "A digital twin of a cyber-physical system (CPS) network monitors packet arrivals on a backbone link. Over $n$ disjoint, equal-duration observation windows, it records counts $y_{1},\\dots,y_{n}$ of arrivals. The system architect posits a homogeneous Poisson arrival model across windows, in which each $y_{i}$ is modeled as an independent draw from a Poisson distribution with unknown mean parameter $\\lambda>0$, representing the expected number of arrivals per window. Using only the foundational definition of maximum likelihood estimation and basic properties of independent samples, perform the following:\n\n- Derive from first principles a closed-form maximum likelihood estimator $\\hat{\\lambda}$ for $\\lambda$.\n- From the law of large numbers and standard regularity considerations for identically distributed samples, state explicit sampling conditions under which $\\hat{\\lambda}$ is consistent for the true parameter $\\lambda_{0}$.\n\nExpress your final answer as a single symbolic expression for $\\hat{\\lambda}$ in terms of $y_{1},\\dots,y_{n}$. No rounding is required. Do not include units in your final answer. You may assume that all windows are of equal duration so that stationarity across windows is well-defined, and that the data-generating process is time-homogeneous during the collection period.",
            "solution": "The problem is first validated against the specified criteria.\n\n**Step 1: Extract Givens**\n- Data: A set of $n$ counts, $y_{1}, \\dots, y_{n}$, representing packet arrivals in $n$ disjoint, equal-duration observation windows.\n- Model: Each count $y_{i}$ is an independent draw from a Poisson distribution with an unknown mean parameter $\\lambda > 0$. This implies the random variables $Y_{1}, \\dots, Y_{n}$ corresponding to the counts are independent and identically distributed (IID) as $Y_{i} \\sim \\text{Poisson}(\\lambda)$.\n- Objective 1: Derive the maximum likelihood estimator (MLE), denoted $\\hat{\\lambda}$, for the parameter $\\lambda$ from first principles.\n- Objective 2: State the conditions under which $\\hat{\\lambda}$ is a consistent estimator for the true parameter, $\\lambda_{0}$, by invoking the law of large numbers.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective.\n- **Scientific Soundness**: The problem utilizes the Poisson distribution and the principle of maximum likelihood estimation, which are foundational concepts in probability theory and statistical inference. The application to modeling packet arrivals is a standard and valid use case in network engineering and queuing theory.\n- **Well-Posedness**: The problem is self-contained and provides all necessary information to derive the estimator and analyze its consistency. The goal is clearly defined, and the assumptions (IID Poisson samples) lead to a unique and meaningful solution.\n- **Objectivity**: The language is precise and uses standard mathematical and statistical terminology. There are no subjective or ambiguous statements.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A solution will be derived.\n\n**Part 1: Derivation of the Maximum Likelihood Estimator $\\hat{\\lambda}$**\n\nThe derivation proceeds from the foundational definition of likelihood. The probability mass function (PMF) for a single observation $y_{i}$ from a Poisson distribution with mean $\\lambda$ is given by:\n$$ P(Y=y_{i} | \\lambda) = \\frac{\\lambda^{y_{i}} \\exp(-\\lambda)}{y_{i}!} $$\nwhere $y_{i} \\in \\{0, 1, 2, \\dots\\}$.\n\nGiven that the $n$ observations $y_{1}, \\dots, y_{n}$ are independent, the joint probability of observing this specific dataset is the product of the individual probabilities. This joint probability, when viewed as a function of the parameter $\\lambda$ for a fixed set of data, is the likelihood function $L(\\lambda)$.\n$$ L(\\lambda | y_{1}, \\dots, y_{n}) = \\prod_{i=1}^{n} P(Y=y_{i} | \\lambda) = \\prod_{i=1}^{n} \\frac{\\lambda^{y_{i}} \\exp(-\\lambda)}{y_{i}!} $$\nThis expression can be simplified by combining terms:\n$$ L(\\lambda) = \\frac{\\left(\\prod_{i=1}^{n} \\lambda^{y_{i}}\\right) \\left(\\prod_{i=1}^{n} \\exp(-\\lambda)\\right)}{\\prod_{i=1}^{n} y_{i}!} = \\frac{\\lambda^{\\sum_{i=1}^{n} y_{i}} \\exp(-n\\lambda)}{\\prod_{i=1}^{n} y_{i}!} $$\nTo find the value of $\\lambda$ that maximizes $L(\\lambda)$, it is mathematically more convenient to maximize the natural logarithm of the likelihood function, known as the log-likelihood function, $\\ell(\\lambda) = \\ln(L(\\lambda))$. Since the logarithm is a monotonically increasing function, maximizing $\\ell(\\lambda)$ is equivalent to maximizing $L(\\lambda)$.\n$$ \\ell(\\lambda) = \\ln\\left(\\frac{\\lambda^{\\sum_{i=1}^{n} y_{i}} \\exp(-n\\lambda)}{\\prod_{i=1}^{n} y_{i}!}\\right) $$\nUsing the properties of logarithms, we can separate the terms:\n$$ \\ell(\\lambda) = \\ln\\left(\\lambda^{\\sum_{i=1}^{n} y_{i}}\\right) + \\ln(\\exp(-n\\lambda)) - \\ln\\left(\\prod_{i=1}^{n} y_{i}!\\right) $$\n$$ \\ell(\\lambda) = \\left(\\sum_{i=1}^{n} y_{i}\\right) \\ln(\\lambda) - n\\lambda - \\sum_{i=1}^{n} \\ln(y_{i}!) $$\nTo find the maximum, we compute the first derivative of $\\ell(\\lambda)$ with respect to $\\lambda$ and set it to zero. The term $\\sum_{i=1}^{n} \\ln(y_{i}!)$ is a constant with respect to $\\lambda$ and its derivative is zero.\n$$ \\frac{d\\ell}{d\\lambda} = \\frac{d}{d\\lambda}\\left[ \\left(\\sum_{i=1}^{n} y_{i}\\right) \\ln(\\lambda) - n\\lambda \\right] = \\left(\\sum_{i=1}^{n} y_{i}\\right) \\frac{1}{\\lambda} - n $$\nSetting the derivative to zero to find the critical point:\n$$ \\frac{1}{\\lambda} \\sum_{i=1}^{n} y_{i} - n = 0 $$\n$$ \\frac{1}{\\lambda} \\sum_{i=1}^{n} y_{i} = n $$\nSolving for $\\lambda$ gives the maximum likelihood estimator, $\\hat{\\lambda}$:\n$$ \\hat{\\lambda} = \\frac{1}{n} \\sum_{i=1}^{n} y_{i} $$\nThis result shows that the MLE for the Poisson parameter is the sample mean of the observations.\n\nTo confirm that this critical point corresponds to a maximum, we examine the second derivative of the log-likelihood function:\n$$ \\frac{d^{2}\\ell}{d\\lambda^{2}} = \\frac{d}{d\\lambda}\\left[ \\left(\\sum_{i=1}^{n} y_{i}\\right) \\lambda^{-1} - n \\right] = - \\left(\\sum_{i=1}^{n} y_{i}\\right) \\lambda^{-2} = -\\frac{\\sum_{i=1}^{n} y_{i}}{\\lambda^{2}} $$\nSince $\\lambda > 0$, $\\lambda^{2}$ is positive. The counts $y_{i}$ are non-negative, so their sum $\\sum_{i=1}^{n} y_{i}$ is also non-negative. As long as at least one observation $y_{i}$ is positive, the sum is strictly positive, and the second derivative $\\frac{d^{2}\\ell}{d\\lambda^{2}}$ is strictly negative. This confirms that $\\hat{\\lambda}$ is indeed a local maximum. If all $y_{i}=0$, then $\\hat{\\lambda}=0$, and the likelihood function $L(\\lambda) = \\exp(-n\\lambda)$ is a strictly decreasing function for $\\lambda > 0$, so its maximum over the domain $\\lambda \\ge 0$ occurs at $\\lambda = 0$. Thus, the derived estimator is correct in all cases.\n\n**Part 2: Consistency of the Estimator $\\hat{\\lambda}$**\n\nAn estimator $\\hat{\\lambda}_{n}$ (where the subscript $n$ denotes its dependence on the sample size) is consistent for a true parameter $\\lambda_{0}$ if it converges in probability to $\\lambda_{0}$ as the sample size $n$ approaches infinity. This is written as:\n$$ \\hat{\\lambda}_{n} \\xrightarrow{p} \\lambda_{0} \\quad \\text{as } n \\to \\infty $$\nThe estimator we derived is the sample mean of the observations:\n$$ \\hat{\\lambda}_{n} = \\frac{1}{n} \\sum_{i=1}^{n} Y_{i} $$\nHere, we use $Y_{i}$ to denote the random variable for the $i$-th observation, which is drawn from a $\\text{Poisson}(\\lambda_{0})$ distribution. The problem states that the observations are IID. The Weak Law of Large Numbers (WLLN) states that for a sequence of IID random variables $Y_{1}, Y_{2}, \\dots$ with a finite expected value $E[Y_{i}] = \\mu$, the sample mean converges in probability to $\\mu$.\n\nFor a Poisson-distributed random variable $Y_{i} \\sim \\text{Poisson}(\\lambda_{0})$, the expected value is:\n$$ E[Y_{i}] = \\lambda_{0} $$\nThis expectation is finite for any valid Poisson process ($\\lambda_0 > 0$).\nAccording to the WLLN, we can directly state:\n$$ \\hat{\\lambda}_{n} = \\frac{1}{n} \\sum_{i=1}^{n} Y_{i} \\xrightarrow{p} E[Y_{i}] = \\lambda_{0} \\quad \\text{as } n \\to \\infty $$\nTherefore, $\\hat{\\lambda}$ is a consistent estimator for $\\lambda_{0}$.\n\nThe explicit sampling condition required for this conclusion, based on the law of large numbers, is that the number of independent and identically distributed observation windows, $n$, can be increased without bound (i.e., $n \\to \\infty$). The model's premise that the samples $y_i$ are IID from a distribution with a finite mean ($\\text{Poisson}(\\lambda_0)$) inherently satisfies the necessary prerequisites for the WLLN to apply. The standard regularity conditions for the consistency of MLEs are also met by the Poisson distribution, further ensuring this property.",
            "answer": "$$\n\\boxed{\\frac{1}{n} \\sum_{i=1}^{n} y_{i}}\n$$"
        },
        {
            "introduction": "While MLE relies solely on current data, digital twins often benefit from incorporating prior knowledge gained from historical operations or engineering specifications. This exercise introduces Maximum A Posteriori (MAP) estimation, a Bayesian approach that elegantly combines the data likelihood with a prior distribution over the parameter . Through this practice, you will discover the concept of 'shrinkage,' where the final estimate is a principled compromise between the data-driven evidence and our prior beliefs, a crucial technique for robust calibration in noisy environments.",
            "id": "4247342",
            "problem": "A Cyber-Physical System (CPS) digital twin is used to continuously calibrate a latent operating parameter, the mean vibration amplitude, denoted by $\\mu$, of a rotating component. At calibration cycle $t$, the digital twin collects $n$ sensor observations $\\{y_i\\}_{i=1}^{n}$ subject to additive sensor noise that is modeled as independent and identically distributed Gaussian with known variance $\\sigma^{2}$, so that $y_i \\sim \\mathcal{N}(\\mu,\\sigma^{2})$ for $i=1,\\dots,n$. Prior engineering knowledge from previous operating cycles is represented as a Gaussian prior $\\mu \\sim \\mathcal{N}(\\mu_{0},\\tau^{2})$ with known hyperparameters $\\mu_{0}$ and $\\tau^{2}$.\n\nStarting from first principles of Bayesian inference and the Maximum A Posteriori (MAP) definition, derive the closed-form MAP estimator for $\\mu$ under these assumptions. Your derivation must begin from the definition of the likelihood, the prior, and Bayes’ rule, and proceed by optimizing the posterior density with respect to $\\mu$. In your explanation, articulate the statistical mechanism by which the estimator exhibits shrinkage, including how the estimator balances the sample mean toward the prior mean as a function of $n$, $\\sigma^{2}$, and $\\tau^{2}$, and discuss the limiting behavior when $\\tau^{2} \\to \\infty$ and when $\\tau^{2} \\to 0$.\n\nProvide the final estimator as a single closed-form analytical expression in terms of $n$, $\\sigma^{2}$, $\\tau^{2}$, $\\mu_{0}$, and the sample mean $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i$. No numerical rounding is required, and no units are to be included in the final expression.",
            "solution": "The user wants to solve the problem.\nThe problem is valid. I will proceed with the solution.\n\nThe objective is to derive the Maximum A Posteriori (MAP) estimator for the mean vibration amplitude $\\mu$ of a rotating component, given a set of sensor observations and prior knowledge about the parameter.\n\nThe problem provides the following:\n1.  A set of $n$ sensor observations $\\{y_i\\}_{i=1}^{n}$.\n2.  A likelihood model for each observation: $y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$, where the observations are independent and identically distributed (i.i.d.) and the variance $\\sigma^2$ is known.\n3.  A prior distribution for the parameter $\\mu$: $\\mu \\sim \\mathcal{N}(\\mu_0, \\tau^2)$, where the hyperparameters $\\mu_0$ and $\\tau^2$ are known.\n\nThe derivation will proceed from the first principles of Bayesian inference.\n\nAccording to Bayes' rule, the posterior probability density of the parameter $\\mu$ given the data $\\{y_i\\}$ is proportional to the product of the likelihood of the data given the parameter and the prior probability density of the parameter.\n$$\np(\\mu | y_1, \\dots, y_n) \\propto p(y_1, \\dots, y_n | \\mu) \\, p(\\mu)\n$$\nwhere $p(\\mu | y_1, \\dots, y_n)$ is the posterior, $p(y_1, \\dots, y_n | \\mu)$ is the likelihood, and $p(\\mu)$ is the prior.\n\nFirst, we define the likelihood function, $L(\\mu) = p(y_1, \\dots, y_n | \\mu)$. Since the observations $\\{y_i\\}$ are i.i.d., the joint likelihood is the product of the individual probability densities:\n$$\nL(\\mu) = \\prod_{i=1}^{n} p(y_i | \\mu)\n$$\nGiven the Gaussian model $y_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$, the probability density function for a single observation is:\n$$\np(y_i | \\mu) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right)\n$$\nThe full likelihood function is therefore:\n$$\nL(\\mu) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(y_i - \\mu)^2}{2\\sigma^2} \\right) = (2\\pi\\sigma^2)^{-n/2} \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2 \\right)\n$$\n\nNext, we define the prior distribution for $\\mu$, which is given as $\\mu \\sim \\mathcal{N}(\\mu_0, \\tau^2)$:\n$$\np(\\mu) = \\frac{1}{\\sqrt{2\\pi\\tau^2}} \\exp\\left( -\\frac{(\\mu - \\mu_0)^2}{2\\tau^2} \\right)\n$$\n\nNow, we construct the posterior density by multiplying the likelihood and the prior. We can ignore the normalization constants as they do not depend on $\\mu$:\n$$\np(\\mu | \\{y_i\\}) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2 \\right) \\exp\\left( -\\frac{(\\mu - \\mu_0)^2}{2\\tau^2} \\right)\n$$\nCombining the exponents, we get:\n$$\np(\\mu | \\{y_i\\}) \\propto \\exp\\left( - \\left[ \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2 + \\frac{(\\mu - \\mu_0)^2}{2\\tau^2} \\right] \\right)\n$$\n\nThe MAP estimator, denoted $\\hat{\\mu}_{\\text{MAP}}$, is the value of $\\mu$ that maximizes this posterior probability density. It is computationally more convenient to maximize the natural logarithm of the posterior, as the logarithm is a monotonic function. Let $\\mathcal{L}(\\mu) = \\ln(p(\\mu | \\{y_i\\}))$.\n$$\n\\mathcal{L}(\\mu) = C - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu)^2 - \\frac{(\\mu - \\mu_0)^2}{2\\tau^2}\n$$\nwhere $C$ is a constant term that does not depend on $\\mu$. To find the maximum, we take the derivative of $\\mathcal{L}(\\mu)$ with respect to $\\mu$ and set it to zero:\n$$\n\\frac{d\\mathcal{L}}{d\\mu} = -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} 2(y_i - \\mu)(-1) - \\frac{1}{2\\tau^2} 2(\\mu - \\mu_0)(1) = 0\n$$\n$$\n\\frac{1}{\\sigma^2} \\sum_{i=1}^{n} (y_i - \\mu) - \\frac{1}{\\tau^2}(\\mu - \\mu_0) = 0\n$$\nRecognizing that $\\sum_{i=1}^{n} y_i = n\\bar{y}$, where $\\bar{y}$ is the sample mean, we have:\n$$\n\\frac{1}{\\sigma^2} (n\\bar{y} - n\\mu) - \\frac{1}{\\tau^2}(\\mu - \\mu_0) = 0\n$$\nNow, we solve for $\\mu$:\n$$\n\\frac{n\\bar{y}}{\\sigma^2} - \\frac{n\\mu}{\\sigma^2} - \\frac{\\mu}{\\tau^2} + \\frac{\\mu_0}{\\tau^2} = 0\n$$\n$$\n\\frac{n\\bar{y}}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2} = \\mu \\left( \\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2} \\right)\n$$\n$$\n\\hat{\\mu}_{\\text{MAP}} = \\mu = \\frac{\\frac{n\\bar{y}}{\\sigma^2} + \\frac{\\mu_0}{\\tau^2}}{\\frac{n}{\\sigma^2} + \\frac{1}{\\tau^2}}\n$$\nTo obtain the expression in the required form, we multiply the numerator and denominator by $\\sigma^2\\tau^2$:\n$$\n\\hat{\\mu}_{\\text{MAP}} = \\frac{n\\tau^2\\bar{y} + \\sigma^2\\mu_0}{n\\tau^2 + \\sigma^2}\n$$\n\nThis closed-form solution for $\\hat{\\mu}_{\\text{MAP}}$ can be rewritten as a weighted average of the sample mean $\\bar{y}$ and the prior mean $\\mu_0$:\n$$\n\\hat{\\mu}_{\\text{MAP}} = \\left(\\frac{n\\tau^2}{n\\tau^2 + \\sigma^2}\\right) \\bar{y} + \\left(\\frac{\\sigma^2}{n\\tau^2 + \\sigma^2}\\right) \\mu_0\n$$\n\nThis form clearly illustrates the statistical mechanism of shrinkage. The MAP estimate is a convex combination of the maximum likelihood estimate (which for a Gaussian is the sample mean $\\bar{y}$) and the prior mean $\\mu_0$. The data-driven estimate $\\bar{y}$ is \"shrunk\" toward the prior belief $\\mu_0$. The degree of shrinkage is determined by the weights, which depend on the sample size $n$, the sensor noise variance $\\sigma^2$, and the prior variance $\\tau^2$.\n-   A larger sample size $n$ increases the weight on $\\bar{y}$, meaning the estimate relies more on the data.\n-   A larger sensor noise variance $\\sigma^2$ increases the weight on $\\mu_0$, signifying that noisy data are less trustworthy, so the estimate relies more on the prior.\n-   A larger prior variance $\\tau^2$ (a less certain prior) increases the weight on $\\bar{y}$, as the prior information is considered less reliable.\n\nWe now analyze the limiting behavior of the estimator.\n\nCase 1: Uninformative prior, $\\tau^2 \\to \\infty$. This represents a scenario with very weak prior knowledge.\n$$\n\\lim_{\\tau^2 \\to \\infty} \\hat{\\mu}_{\\text{MAP}} = \\lim_{\\tau^2 \\to \\infty} \\frac{n\\tau^2\\bar{y} + \\sigma^2\\mu_0}{n\\tau^2 + \\sigma^2}\n$$\nDividing the numerator and denominator by $\\tau^2$:\n$$\n\\lim_{\\tau^2 \\to \\infty} \\frac{n\\bar{y} + \\frac{\\sigma^2}{\\tau^2}\\mu_0}{n + \\frac{\\sigma^2}{\\tau^2}} = \\frac{n\\bar{y} + 0}{n + 0} = \\bar{y}\n$$\nIn this limit, the MAP estimator converges to the sample mean $\\bar{y}$, which is the Maximum Likelihood Estimate (MLE). The prior's influence vanishes.\n\nCase 2: Infinitely strong prior, $\\tau^2 \\to 0$. This represents absolute certainty that $\\mu = \\mu_0$.\n$$\n\\lim_{\\tau^2 \\to 0} \\hat{\\mu}_{\\text{MAP}} = \\lim_{\\tau^2 \\to 0} \\frac{n\\tau^2\\bar{y} + \\sigma^2\\mu_0}{n\\tau^2 + \\sigma^2}\n$$\nAs $\\tau^2 \\to 0$, the terms involving $\\tau^2$ vanish:\n$$\n\\lim_{\\tau^2 \\to 0} \\frac{n(0)\\bar{y} + \\sigma^2\\mu_0}{n(0) + \\sigma^2} = \\frac{\\sigma^2\\mu_0}{\\sigma^2} = \\mu_0\n$$\nIn this limit, the MAP estimator discards the data entirely and is fixed at the prior mean $\\mu_0$. The prior belief is so strong that no amount of data can alter it.",
            "answer": "$$\n\\boxed{\\frac{n\\tau^2\\bar{y} + \\sigma^2\\mu_0}{n\\tau^2 + \\sigma^2}}\n$$"
        },
        {
            "introduction": "Real-world cyber-physical systems are rarely linear and static. This advanced, hands-on coding practice tackles the challenge of tracking a hidden state in a nonlinear dynamic system, a task where analytical solutions fail . By implementing a bootstrap particle filter, you will gain practical experience with a powerful computational tool for state estimation, learning to manage challenges like sample degeneracy through monitoring the effective sample size and applying resampling techniques.",
            "id": "4247459",
            "problem": "You are given a scalar Cyber-Physical System (CPS) governed by a nonlinear discrete-time state-space model with process and measurement uncertainties. The latent state is denoted by $x_k \\in \\mathbb{R}$ at discrete time index $k \\in \\{0, 1, 2, \\dots\\}$, the process noise by $w_k \\in \\mathbb{R}$, and the measurement noise by $v_k \\in \\mathbb{R}$. The model is\n- State transition: $x_{k+1} = x_k^2 + w_k$,\n- Measurement: $y_k = x_k + v_k$,\nwith independent Gaussian uncertainties $w_k \\sim \\mathcal{N}(0, q)$ and $v_k \\sim \\mathcal{N}(0, r)$, and a Gaussian prior $x_0 \\sim \\mathcal{N}(m_0, P_0)$, where $q > 0$, $r > 0$, $P_0 > 0$.\n\nTask: Implement a bootstrap particle filter that performs sequential Bayesian estimation using $N$ particles with the proposal equal to the state transition density. At each time step $k$, before any resampling, compute the Effective Sample Size (ESS) defined by\n$$\nN_{\\text{eff}}(k) = \\frac{1}{\\sum_{i=1}^{N} \\tilde{w}_{k}^{(i)\\,2}},\n$$\nwhere $\\tilde{w}_{k}^{(i)}$ are the normalized importance weights at time $k$. Use systematic resampling only when the pre-resampling ESS satisfies $N_{\\text{eff}}(k) < N/2$. The particle filtering recursion at time $k$ should be:\n- For $k = 0$: draw $x_0^{(i)} \\sim \\mathcal{N}(m_0, P_0)$, compute weights proportional to the likelihood $p(y_0 \\mid x_0^{(i)})$, normalize the weights, compute $N_{\\text{eff}}(0)$, and if $N_{\\text{eff}}(0) < N/2$ then resample and reset the weights to uniform.\n- For $k \\ge 1$: propagate $x_k^{(i)} = \\left(x_{k-1}^{(i)}\\right)^2 + w_{k-1}^{(i)}$ with $w_{k-1}^{(i)} \\sim \\mathcal{N}(0, q)$, update weights proportional to $p(y_k \\mid x_k^{(i)})$ multiplied by the previous weights, normalize the weights, compute $N_{\\text{eff}}(k)$, and if $N_{\\text{eff}}(k) < N/2$ then resample and reset the weights to uniform.\n\nImplementation constraints and requirements:\n- Use a fixed pseudorandom number generator seed $s = 12345$ for reproducibility. If multiple test cases are evaluated in one program run, use seeds $s, s+1, s+2, \\dots$ for successive cases in the order listed below to ensure deterministic and distinct randomness across test cases.\n- Use numerically stable computations for weights by working in the logarithmic domain to avoid underflow, and normalize via a log-sum-exp stabilization.\n- The output for each test case is a single real number equal to the minimum pre-resampling $N_{\\text{eff}}(k)$ over all time indices $k \\in \\{0, \\dots, T-1\\}$, where $T$ is the length of the measurement sequence in that test case.\n- Express the final numerical answers rounded to exactly $4$ decimal places.\n\nTest suite:\nEvaluate your bootstrap particle filter on the following three test cases. In every case, the measurement sequence length is $T = 6$ with observations $y_0, y_1, y_2, y_3, y_4, y_5$.\n\n- Test case $1$ (happy path):\n  - Number of particles: $N = 5000$.\n  - Process noise variance: $q = 0.05$.\n  - Measurement noise variance: $r = 0.2$.\n  - Prior mean and variance: $m_0 = 0.3$, $P_0 = 0.4$.\n  - Measurements: $y = [0.25, 0.11, 0.15, 0.05, 0.10, 0.18]$.\n\n- Test case $2$ (boundary with small $N$ and higher noise):\n  - Number of particles: $N = 200$.\n  - Process noise variance: $q = 0.2$.\n  - Measurement noise variance: $r = 0.8$.\n  - Prior mean and variance: $m_0 = 0.0$, $P_0 = 1.0$.\n  - Measurements: $y = [0.2, -0.1, 0.0, 0.05, -0.2, 0.1]$.\n\n- Test case $3$ (edge case with strong nonlinearity and low noise):\n  - Number of particles: $N = 3000$.\n  - Process noise variance: $q = 0.01$.\n  - Measurement noise variance: $r = 0.05$.\n  - Prior mean and variance: $m_0 = -1.0$, $P_0 = 0.1$.\n  - Measurements: $y = [-0.90, 0.85, 0.70, 0.55, 0.36, 0.14]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- Specifically, the output must be a single line of the form\n  $$\n  [\\text{res}_1,\\text{res}_2,\\text{res}_3],\n  $$\n  where $\\text{res}_j$ is the minimum pre-resampling effective sample size for test case $j$ rounded to exactly $4$ decimal places (no units).\n\nAngle units and physical units:\n- No angular quantities appear; no angle units are required.\n- The effective sample size is dimensionless; no physical units are required.\n\nYour implementation must be a complete, runnable program that uses only the standard library and the specified numerical libraries, reads no input, and prints exactly one line in the specified format.",
            "solution": "The user has provided a well-defined problem in the domain of statistical estimation for nonlinear dynamical systems. The problem is scientifically grounded, self-contained, and algorithmically specific. It requires the implementation of a bootstrap particle filter, a standard Monte Carlo method for solving state estimation problems. All parameters, system dynamics, and evaluation criteria are provided unambiguously. Therefore, the problem is valid.\n\nThe core of the problem is to perform sequential Bayesian estimation for a scalar state $x_k$ at discrete time $k$, governed by the nonlinear state-space model:\n$$\n\\text{State transition: } x_{k+1} = x_k^2 + w_k, \\quad w_k \\sim \\mathcal{N}(0, q)\n$$\n$$\n\\text{Measurement: } y_k = x_k + v_k, \\quad v_k \\sim \\mathcal{N}(0, r)\n$$\nThe estimation is based on a sequence of measurements $y_0, y_1, \\dots, y_{T-1}$. The particle filter approximates the posterior probability density function $p(x_k | y_{0:k})$ with a set of $N$ weighted samples or \"particles\" $\\{(x_k^{(i)}, \\tilde{w}_k^{(i)})\\}_{i=1}^N$. The solution proceeds by implementing the specified bootstrap particle filter algorithm.\n\nThe bootstrap filter is a specific type of Sequential Importance Resampling (SIR) filter where the proposal distribution for generating particles at the next time step is chosen to be the state transition distribution, $p(x_k | x_{k-1})$. This choice simplifies the weight update equation. The algorithm proceeds recursively as follows:\n\n**Step 1: Initialization ($k=0$)**\nWe begin by drawing $N$ initial particles from the prior distribution of the state. The problem specifies a Gaussian prior $x_0 \\sim \\mathcal{N}(m_0, P_0)$.\n$$\nx_0^{(i)} \\sim \\mathcal{N}(m_0, P_0) \\quad \\text{for } i=1, \\dots, N\n$$\nThe initial weights are uniform, which is equivalent to assuming no prior information before the first measurement. We then incorporate the first measurement, $y_0$, by updating a set of unnormalized weights, $w_0^{(i)}$, to be proportional to the likelihood of observing $y_0$ given the particle's state $x_0^{(i)}$.\n$$\nw_0^{(i)} \\propto p(y_0 | x_0^{(i)})\n$$\nSince the measurement noise $v_0 = y_0 - x_0$ is Gaussian with variance $r$, the likelihood function is the probability density function (PDF) of a Gaussian distribution $\\mathcal{N}(x_0^{(i)}, r)$ evaluated at $y_0$. For numerical stability, we work with log-weights. The unnormalized log-weight is:\n$$\n\\log w_0^{(i)} = \\log p(y_0 | x_0^{(i)}) = -\\frac{1}{2}\\log(2\\pi r) - \\frac{(y_0 - x_0^{(i)})^2}{2r}\n$$\n\n**Step 2: Propagation (for $k \\ge 1$)**\nFor subsequent time steps, we first predict the next state of each particle using the state transition model. This is the \"bootstrap\" step, where we sample from the dynamics. A particle $x_{k-1}^{(i)}$ from the previous step is propagated forward to time $k$:\n$$\nx_k^{(i)} = (x_{k-1}^{(i)})^2 + w_{k-1}^{(i)}, \\quad \\text{where } w_{k-1}^{(i)} \\sim \\mathcal{N}(0, q)\n$$\nThis generates a new set of particles $\\{x_k^{(i)}\\}_{i=1}^N$ that represents an empirical approximation of the predictive density $p(x_k|y_{0:k-1})$.\n\n**Step 3: Weight Update (for $k \\ge 1$)**\nUpon receiving a new measurement $y_k$, the weights are updated to reflect how well each propagated particle $x_k^{(i)}$ agrees with this measurement. The update rule for a general particle filter is $w_k^{(i)} \\propto \\tilde{w}_{k-1}^{(i)} \\frac{p(y_k|x_k^{(i)})p(x_k^{(i)}|x_{k-1}^{(i)})}{q(x_k^{(i)}|x_{k-1}^{(i)})}$, where $\\tilde{w}_{k-1}^{(i)}$ is the normalized weight from the previous step and $q(\\cdot)$ is the proposal distribution. In a bootstrap filter, the proposal is the prior, $q(x_k^{(i)}|x_{k-1}^{(i)}) = p(x_k^{(i)}|x_{k-1}^{(i)})$, so the fraction cancels. The update simplifies to:\n$$\nw_k^{(i)} \\propto \\tilde{w}_{k-1}^{(i)} p(y_k | x_k^{(i)})\n$$\nIn the logarithmic domain, this becomes an additive update:\n$$\n\\log w_k^{(i)} = \\log \\tilde{w}_{k-1}^{(i)} + \\log p(y_k | x_k^{(i)})\n$$\n\n**Step 4: Normalization and Effective Sample Size (ESS) Calculation**\nThe unnormalized log-weights $\\log w_k^{(i)}$ are normalized to yield weights $\\tilde{w}_k^{(i)}$ that sum to $1$. To avoid numerical underflow/overflow, this is done using the log-sum-exp trick:\n$$\nS_k = \\log\\left(\\sum_{i=1}^N \\exp(\\log w_k^{(i)})\\right)\n$$\nThe normalized log-weights are $\\log \\tilde{w}_k^{(i)} = \\log w_k^{(i)} - S_k$, and the normalized weights are $\\tilde{w}_k^{(i)} = \\exp(\\log \\tilde{w}_k^{(i)})$.\n\nBefore any resampling, we compute the Effective Sample Size (ESS) to measure particle degeneracy. A low ESS indicates that a few particles have very high weights, making the approximation of the posterior poor. The formula is:\n$$\nN_{\\text{eff}}(k) = \\frac{1}{\\sum_{i=1}^{N} (\\tilde{w}_{k}^{(i)})^2}\n$$\nThis value is computed and stored for each time step $k \\in \\{0, \\dots, T-1\\}$ to find the minimum as required by the problem.\n\n**Step 5: Resampling**\nIf the particle set is degenerate, as indicated by $N_{\\text{eff}}(k) < N/2$, a resampling step is performed. We will implement systematic resampling, a low-variance method. This step creates a new set of particles by drawing $N$ times from the current particle set $\\{x_k^{(i)}\\}$ with probabilities given by their weights $\\{\\tilde{w}_k^{(i)}\\}$. High-weight particles are likely to be duplicated, while low-weight particles are likely to be eliminated. After resampling, the particles are replaced by the new set, and their weights are reset to be uniform: $\\tilde{w}_k^{(i)} = 1/N$ for all $i$. In the log domain, this means $\\log \\tilde{w}_k^{(i)} = -\\log N$. If no resampling occurs, the normalized weights $\\tilde{w}_k^{(i)}$ (or their logs) are carried forward to the next time step.\n\nThis entire sequence—propagation, weighting, normalization, ESS calculation, and conditional resampling—is repeated for each time step from $k=0$ to $k=T-1$. The final output for each test case is the minimum of the pre-resampling $N_{\\text{eff}}(k)$ values recorded over this interval. The implementation will use a fixed random seed for each test case to ensure reproducibility.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef run_particle_filter(N, q, r, m0, P0, y_seq, seed):\n    \"\"\"\n    Implements a bootstrap particle filter for a nonlinear state-space model.\n\n    Args:\n        N (int): Number of particles.\n        q (float): Process noise variance.\n        r (float): Measurement noise variance.\n        m0 (float): Prior mean.\n        P0 (float): Prior variance.\n        y_seq (list or np.ndarray): Sequence of measurements.\n        seed (int): Seed for the pseudorandom number generator.\n\n    Returns:\n        float: The minimum pre-resampling effective sample size (ESS).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    T = len(y_seq)\n    \n    # Standard deviations for noise generation\n    std_q = np.sqrt(q)\n    std_r = np.sqrt(r)\n\n    # --- Step 1: Initialization (k=0) ---\n    # Draw initial particles from the prior distribution\n    # These represent the particle set for time k=0, i.e., {x_0^(i)}\n    particles = rng.normal(loc=m0, scale=np.sqrt(P0), size=N)\n    \n    # Initialize log weights to be uniform. These represent log(w_tilde_{-1}),\n    # which are implicitly uniform before the first measurement.\n    log_weights = np.full(N, -np.log(N))\n    \n    all_ess_values = []\n\n    # --- Main Loop (k = 0 to T-1) ---\n    for k in range(T):\n        # At the start of loop k, `particles` holds {x_{k-1}^{(i)}} and `log_weights` holds log(w_tilde_{k-1}).\n        # For k=0, `particles` holds {x_0^{(i)}} and there is no propagation.\n        \n        # --- Step 2: Propagation (for k >= 1) ---\n        if k > 0:\n            process_noise = rng.normal(loc=0.0, scale=std_q, size=N)\n            particles = particles**2 + process_noise\n        \n        # `particles` now holds the set {x_k^(i)}\n\n        # --- Step 3: Weight Update ---\n        # Calculate log-likelihood log p(y_k | x_k^(i))\n        log_likelihood = norm.logpdf(y_seq[k], loc=particles, scale=std_r)\n        \n        # Update log-weights: log(w_k) = log(w_tilde_{k-1}) + log p(y_k | x_k)\n        unnormalized_log_weights = log_weights + log_likelihood\n\n        # --- Step 4: Normalization and ESS Calculation ---\n        # Normalize weights using log-sum-exp trick for numerical stability\n        max_log = np.max(unnormalized_log_weights)\n        if np.isneginf(max_log): # All weights are -inf, numerically unstable\n            # This can happen if all particles are extremely unlikely.\n            # We can reset to uniform weights to recover, but for this problem,\n            # this indicates a serious filter divergence.\n            # To avoid division by zero, we set weights to uniform.\n            normalized_weights = np.full(N, 1.0/N)\n            log_weights = np.log(normalized_weights)\n        else:\n            temp_weights = np.exp(unnormalized_log_weights - max_log)\n            sum_of_weights = np.sum(temp_weights)\n            log_sum = max_log + np.log(sum_of_weights)\n            normalized_weights = temp_weights / sum_of_weights\n            log_weights = unnormalized_log_weights - log_sum\n        \n        # Calculate pre-resampling Effective Sample Size (ESS)\n        ess = 1.0 / np.sum(normalized_weights**2)\n        all_ess_values.append(ess)\n\n        # --- Step 5: Resampling ---\n        if ess < N / 2.0:\n            # Systematic resampling\n            positions = (np.arange(N) + rng.random()) / N\n            cumulative_sum = np.cumsum(normalized_weights)\n            indices = np.searchsorted(cumulative_sum, positions, side='left')\n            \n            # Ensure indices are within bounds (can happen with numerical precision issues)\n            indices = np.clip(indices, 0, N - 1)\n\n            particles = particles[indices]\n            log_weights = np.full(N, -np.log(N)) # Reset weights to uniform\n\n    return min(all_ess_values)\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the particle filter, and print results.\n    \"\"\"\n    base_seed = 12345\n\n    test_cases = [\n        {\n            \"N\": 5000, \"q\": 0.05, \"r\": 0.2, \"m0\": 0.3, \"P0\": 0.4,\n            \"y\": [0.25, 0.11, 0.15, 0.05, 0.10, 0.18]\n        },\n        {\n            \"N\": 200, \"q\": 0.2, \"r\": 0.8, \"m0\": 0.0, \"P0\": 1.0,\n            \"y\": [0.2, -0.1, 0.0, 0.05, -0.2, 0.1]\n        },\n        {\n            \"N\": 3000, \"q\": 0.01, \"r\": 0.05, \"m0\": -1.0, \"P0\": 0.1,\n            \"y\": [-0.90, 0.85, 0.70, 0.55, 0.36, 0.14]\n        }\n    ]\n\n    results = []\n    for i, case in enumerate(test_cases):\n        min_ess = run_particle_filter(\n            N=case[\"N\"],\n            q=case[\"q\"],\n            r=case[\"r\"],\n            m0=case[\"m0\"],\n            P0=case[\"P0\"],\n            y_seq=case[\"y\"],\n            seed=base_seed + i\n        )\n        results.append(f\"{min_ess:.4f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}