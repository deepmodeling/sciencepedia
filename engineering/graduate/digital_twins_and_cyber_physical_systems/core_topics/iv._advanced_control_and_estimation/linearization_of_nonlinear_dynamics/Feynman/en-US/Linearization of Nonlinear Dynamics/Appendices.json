{
    "hands_on_practices": [
        {
            "introduction": "In digital control and simulation, continuous-time dynamics must be translated into discrete-time models that a computer can process. This practice bridges that fundamental gap, guiding you through the process of obtaining a discrete-time representation from a continuous-time linearized system using the explicit Euler method. More importantly, it challenges you to quantify the approximation error introduced during this discretization , providing a concrete understanding of how the system's inherent dynamics ($A$) and the chosen sampling interval ($\\Delta t$) influence the accuracy of your digital model.",
            "id": "4230043",
            "problem": "A Digital Twin (DT) of a Cyber-Physical System (CPS) maintains a discrete-time model of a continuous-time plant with nonlinear dynamics given by $\\dot{x}(t)=f(x(t),u(t))$, where $x \\in \\mathbb{R}^{n}$ and $u \\in \\mathbb{R}^{m}$. At an equilibrium $(\\bar{x},\\bar{u})$ with $f(\\bar{x},\\bar{u})=0$, define the deviation variables $\\tilde{x}(t)=x(t)-\\bar{x}$ and $\\tilde{u}(t)=u(t)-\\bar{u}$. Assume $f$ is continuously differentiable in a neighborhood of $(\\bar{x},\\bar{u})$, and denote by $A=\\left.\\frac{\\partial f}{\\partial x}\\right|_{(\\bar{x},\\bar{u})}$ and $B=\\left.\\frac{\\partial f}{\\partial u}\\right|_{(\\bar{x},\\bar{u})}$ the Jacobians. Consider a sample period $\\Delta t>0$ and a Zero-Order Hold (ZOH) input over $[k\\Delta t,(k+1)\\Delta t)$, i.e., $\\tilde{u}(t)=\\tilde{u}_{k}$ for $t \\in [k\\Delta t,(k+1)\\Delta t)$.\n\nStarting from the fundamental definitions of linearization via first-order Taylor expansion and the exact solution for linear time-invariant systems, derive the first-order explicit Euler discrete-time approximation of the linearized dynamics, and identify the corresponding discrete-time state transition and input matrices. Then, using operator-norm arguments for matrix exponentials and consistent subordinate norms, derive closed-form analytic expressions that upper bound the local discretization errors of the Euler approximation for both the state transition and input matrices, expressed solely as functions of $\\|A\\|$, $\\|B\\|$, and $\\Delta t$.\n\nProvide the final answer as a single row matrix containing: the discrete-time state transition matrix expression, the discrete-time input matrix expression, the norm-based upper-bound expression for the state-transition discretization error, and the norm-based upper-bound expression for the input discretization error. No numerical rounding is required. No physical units are required.",
            "solution": "The user has provided a problem requiring the derivation of discrete-time matrix representations for a linearized system and the corresponding error bounds.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- Nonlinear continuous-time plant dynamics: $\\dot{x}(t)=f(x(t),u(t))$, where $x \\in \\mathbb{R}^{n}$ and $u \\in \\mathbb{R}^{m}$.\n- Equilibrium point: $(\\bar{x},\\bar{u})$ such that $f(\\bar{x},\\bar{u})=0$.\n- Deviation variables: $\\tilde{x}(t)=x(t)-\\bar{x}$ and $\\tilde{u}(t)=u(t)-\\bar{u}$.\n- Smoothness assumption: $f$ is continuously differentiable in a neighborhood of $(\\bar{x},\\bar{u})$.\n- Jacobian matrices: $A=\\left.\\frac{\\partial f}{\\partial x}\\right|_{(\\bar{x},\\bar{u})}$ and $B=\\left.\\frac{\\partial f}{\\partial u}\\right|_{(\\bar{x},\\bar{u})}$.\n- Sample period: $\\Delta t > 0$.\n- Input model: Zero-Order Hold (ZOH), $\\tilde{u}(t)=\\tilde{u}_{k}$ for $t \\in [k\\Delta t,(k+1)\\Delta t)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, as it deals with fundamental concepts of control theory: linearization of nonlinear systems and their discretization for digital implementation. These are core topics in the study of Cyber-Physical Systems and Digital Twins. The problem is well-posed, providing all necessary definitions and constraints to derive the requested expressions. The language is objective and mathematically precise. The problem does not violate any of the invalidity criteria.\n\n**Step 3: Verdict and Action**\nThe problem is valid. The solution process will proceed.\n\n### Derivation\n\n**1. Linearization of Dynamics**\nThe dynamics are given by $\\dot{x}(t)=f(x(t),u(t))$. We define deviation variables $\\tilde{x}(t) = x(t) - \\bar{x}$ and $\\tilde{u}(t) = u(t) - \\bar{u}$. The derivative of the state deviation is $\\dot{\\tilde{x}}(t) = \\dot{x}(t)$. Substituting the definitions, we have:\n$$\n\\dot{\\tilde{x}}(t) = f(\\bar{x} + \\tilde{x}(t), \\bar{u} + \\tilde{u}(t))\n$$\nA first-order Taylor series expansion of $f$ around the equilibrium point $(\\bar{x}, \\bar{u})$ yields:\n$$\nf(\\bar{x} + \\tilde{x}, \\bar{u} + \\tilde{u}) \\approx f(\\bar{x}, \\bar{u}) + \\left.\\frac{\\partial f}{\\partial x}\\right|_{(\\bar{x},\\bar{u})} \\tilde{x} + \\left.\\frac{\\partial f}{\\partial u}\\right|_{(\\bar{x},\\bar{u})} \\tilde{u}\n$$\nUsing the provided definitions $f(\\bar{x},\\bar{u})=0$, $A=\\left.\\frac{\\partial f}{\\partial x}\\right|_{(\\bar{x},\\bar{u})}$, and $B=\\left.\\frac{\\partial f}{\\partial u}\\right|_{(\\bar{x},\\bar{u})}$, the linearized continuous-time system is:\n$$\n\\dot{\\tilde{x}}(t) = A \\tilde{x}(t) + B \\tilde{u}(t)\n$$\n\n**2. First-Order Explicit Euler Discretization**\nThe explicit Euler method approximates the derivative $\\dot{\\tilde{x}}(t)$ at time $t_k = k \\Delta t$ as $\\dot{\\tilde{x}}(t_k) \\approx \\frac{\\tilde{x}(t_{k+1}) - \\tilde{x}(t_k)}{\\Delta t}$. Let $\\tilde{x}_k = \\tilde{x}(t_k)$. Applying this to the linearized system gives:\n$$\n\\frac{\\tilde{x}_{k+1} - \\tilde{x}_k}{\\Delta t} = A \\tilde{x}_k + B \\tilde{u}_k\n$$\nwhere $\\tilde{u}_k$ is the constant input over the interval $[t_k, t_{k+1})$. Rearranging for $\\tilde{x}_{k+1}$, we obtain the discrete-time model:\n$$\n\\tilde{x}_{k+1} = \\tilde{x}_k + \\Delta t (A \\tilde{x}_k + B \\tilde{u}_k) = (I + A \\Delta t) \\tilde{x}_k + (B \\Delta t) \\tilde{u}_k\n$$\nFrom this form, we identify the Euler-approximated discrete-time state transition and input matrices, which we denote as $A_{_E}$ and $B_{_E}$ respectively.\n$$\nA_{_E} = I + A \\Delta t\n$$\n$$\nB_{_E} = B \\Delta t\n$$\n\n**3. Exact Discretization**\nThe exact solution to the linear time-invariant (LTI) system $\\dot{\\tilde{x}}(t) = A \\tilde{x}(t) + B \\tilde{u}(t)$ over one sample period $\\Delta t$ starting from $\\tilde{x}_k$ is given by the variation of constants formula:\n$$\n\\tilde{x}_{k+1} = \\exp(A \\Delta t) \\tilde{x}_k + \\int_{k\\Delta t}^{(k+1)\\Delta t} \\exp(A((k+1)\\Delta t - \\tau)) B \\tilde{u}(\\tau) d\\tau\n$$\nWith the Zero-Order Hold (ZOH) assumption, $\\tilde{u}(\\tau) = \\tilde{u}_k$ is constant over the interval. The integral becomes:\n$$\n\\left( \\int_{0}^{\\Delta t} \\exp(As) ds \\right) B \\tilde{u}_k\n$$\nThis gives the exact discrete-time system $\\tilde{x}_{k+1} = A_d \\tilde{x}_k + B_d \\tilde{u}_k$, with the exact matrices:\n$$\nA_d = \\exp(A \\Delta t)\n$$\n$$\nB_d = \\left( \\int_{0}^{\\Delta t} \\exp(As) ds \\right) B\n$$\n\n**4. Discretization Error Bounds**\nThe local discretization error is the difference between the exact and approximated matrices. We derive upper bounds for the norms of these error matrices.\n\n**State Transition Matrix Error:**\nThe error matrix is $E_A = A_d - A_{_E} = \\exp(A \\Delta t) - (I + A \\Delta t)$. Using the Taylor series expansion of the matrix exponential, $\\exp(X) = \\sum_{j=0}^{\\infty} \\frac{X^j}{j!}$:\n$$\nE_A = \\left( \\sum_{j=0}^{\\infty} \\frac{(A \\Delta t)^j}{j!} \\right) - (I + A \\Delta t) = \\left( I + A \\Delta t + \\sum_{j=2}^{\\infty} \\frac{(A \\Delta t)^j}{j!} \\right) - (I + A \\Delta t) = \\sum_{j=2}^{\\infty} \\frac{(A \\Delta t)^j}{j!}\n$$\nTaking the operator norm and applying the triangle inequality and submultiplicativity ($\\|XY\\| \\le \\|X\\|\\|Y\\|$) for consistent norms:\n$$\n\\|E_A\\| = \\left\\| \\sum_{j=2}^{\\infty} \\frac{(A \\Delta t)^j}{j!} \\right\\| \\le \\sum_{j=2}^{\\infty} \\frac{\\|A \\Delta t\\|^j}{j!} = \\sum_{j=2}^{\\infty} \\frac{(\\|A\\| \\Delta t)^j}{j!}\n$$\nThe resulting scalar series is the tail of the Taylor series for $\\exp(z)$ where $z = \\|A\\| \\Delta t$.\n$$\n\\sum_{j=2}^{\\infty} \\frac{z^j}{j!} = \\exp(z) - 1 - z\n$$\nThus, the upper bound for the state transition matrix error norm is:\n$$\n\\|E_A\\| \\le \\exp(\\|A\\| \\Delta t) - 1 - \\|A\\| \\Delta t\n$$\n\n**Input Matrix Error:**\nThe error matrix is $E_B = B_d - B_{_E}$. First, we expand the integral term in $B_d$:\n$$\n\\int_{0}^{\\Delta t} \\exp(As) ds = \\int_{0}^{\\Delta t} \\left( \\sum_{j=0}^{\\infty} \\frac{(As)^j}{j!} \\right) ds = \\sum_{j=0}^{\\infty} \\frac{A^j}{j!} \\int_{0}^{\\Delta t} s^j ds = \\sum_{j=0}^{\\infty} \\frac{A^j (\\Delta t)^{j+1}}{(j+1)!}\n$$\nSo, $B_d = \\left( \\sum_{j=0}^{\\infty} \\frac{A^j (\\Delta t)^{j+1}}{(j+1)!} \\right) B$. The error is:\n$$\nE_B = \\left( \\left(\\sum_{j=0}^{\\infty} \\frac{A^j (\\Delta t)^{j+1}}{(j+1)!}\\right) - I \\Delta t \\right) B\n$$\nThe $j=0$ term of the summation is $\\frac{A^0 (\\Delta t)^1}{1!} = I \\Delta t$. We can separate this term:\n$$\nE_B = \\left( I \\Delta t + \\sum_{j=1}^{\\infty} \\frac{A^j (\\Delta t)^{j+1}}{(j+1)!} - I \\Delta t \\right) B = \\left( \\sum_{j=1}^{\\infty} \\frac{A^j (\\Delta t)^{j+1}}{(j+1)!} \\right) B\n$$\nTaking the norm gives $\\|E_B\\| \\le \\left\\| \\sum_{j=1}^{\\infty} \\frac{A^j (\\Delta t)^{j+1}}{(j+1)!} \\right\\| \\|B\\|$. We bound the norm of the sum:\n$$\n\\left\\| \\sum_{j=1}^{\\infty} \\frac{A^j (\\Delta t)^{j+1}}{(j+1)!} \\right\\| \\le \\sum_{j=1}^{\\infty} \\frac{\\|A\\|^j (\\Delta t)^{j+1}}{(j+1)!}\n$$\nAssuming $\\|A\\| \\ne 0$, we can factor out $\\frac{1}{\\|A\\|}$:\n$$\n\\frac{1}{\\|A\\|} \\sum_{j=1}^{\\infty} \\frac{(\\|A\\| \\Delta t)^{j+1}}{(j+1)!} = \\frac{1}{\\|A\\|} \\sum_{k=2}^{\\infty} \\frac{(\\|A\\| \\Delta t)^{k}}{k!} = \\frac{\\exp(\\|A\\| \\Delta t) - 1 - \\|A\\| \\Delta t}{\\|A\\|}\n$$\nwhere we substituted $k=j+1$. This expression is also well-defined for $\\|A\\| \\to 0$ and evaluates to $0$. The final bound on the input matrix error norm is:\n$$\n\\|E_B\\| \\le \\frac{\\exp(\\|A\\| \\Delta t) - 1 - \\|A\\| \\Delta t}{\\|A\\|} \\|B\\|\n$$\n\n**Summary of Results**\n1.  Euler discrete-time state transition matrix: $A_{_E} = I + A \\Delta t$.\n2.  Euler discrete-time input matrix: $B_{_E} = B \\Delta t$.\n3.  Upper bound for state transition error norm: $\\exp(\\|A\\| \\Delta t) - 1 - \\|A\\| \\Delta t$.\n4.  Upper bound for input matrix error norm: $\\frac{\\exp(\\|A\\| \\Delta t) - 1 - \\|A\\| \\Delta t}{\\|A\\|} \\|B\\|$.\nThese four expressions constitute the final answer.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nI + A \\Delta t & B \\Delta t & \\exp(\\|A\\| \\Delta t) - 1 - \\|A\\| \\Delta t & \\frac{\\exp(\\|A\\| \\Delta t) - 1 - \\|A\\| \\Delta t}{\\|A\\|} \\|B\\|\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A linear approximation is, by definition, only valid \"locally\" around the point of linearization. But how large is this local neighborhood? This exercise moves beyond qualitative statements and provides a rigorous method to define this region of validity by deriving a confidence ellipsoid . Using bounds on the system's second-order behavior (its curvature, represented by the Hessian matrix), you will learn to mathematically delineate a region where the linearization error is guaranteed to remain below a specified tolerance, a vital skill for ensuring the safety and reliability of model-based predictions in cyber-physical systems.",
            "id": "4229982",
            "problem": "A supervisory controller in a Digital Twin (DT)-enabled Cyber-Physical System (CPS) uses a linearized surrogate of a scalar one-step performance map for real-time prediction. Let $h:\\mathbb{R}^{n} \\to \\mathbb{R}$ be twice continuously differentiable on a convex neighborhood $\\mathcal{N}$ of an operating point $z_{0} \\in \\mathcal{N}$. The DT returns, from its statistical estimation pipeline, a symmetric positive definite matrix $\\mathcal{B}_{\\alpha} \\in \\mathbb{R}^{n \\times n}$ such that, with confidence level at least $1-\\alpha$, the Hessian of $h$ satisfies the uniform operator bound\n$$\n-\\mathcal{B}_{\\alpha} \\preceq \\nabla^{2} h(\\zeta) \\preceq \\mathcal{B}_{\\alpha} \\quad \\text{for all } \\zeta \\in \\mathcal{N}.\n$$\nThe controller linearizes $h$ at $z_{0}$ and uses the affine predictor $h(z_{0}) + \\nabla h(z_{0})^{\\top} \\delta$ for $\\delta := z - z_{0}$, where $z \\in \\mathcal{N}$. Given a specified absolute error tolerance $\\epsilon > 0$, define the “confidence region” in the perturbation space as the set of all $\\delta \\in \\mathbb{R}^{n}$ for which the linearization error satisfies $\\left|h(z_{0}+\\delta) - \\left(h(z_{0}) + \\nabla h(z_{0})^{\\top} \\delta\\right)\\right| \\le \\epsilon$ with probability at least $1-\\alpha$.\n\nStarting from the fundamental Taylor expansion with integral remainder and the given uniform bound on the Hessian, derive a closed-form expression, as an explicit ellipsoidal set in $\\mathbb{R}^{n}$ centered at the origin of the $\\delta$-space, for a confidence ellipsoid guaranteed to lie within the confidence region above. Your final expression must be written solely in terms of $\\epsilon$ and $\\mathcal{B}_{\\alpha}$. Provide the ellipsoid as a set in $\\mathbb{R}^{n}$. The final answer must be a single closed-form analytic expression. No numerical rounding is required.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in multivariable calculus and linear algebra, well-posed, objective, and contains sufficient information for a rigorous derivation. No flaws are identified.\n\nThe objective is to find a guaranteed confidence ellipsoid for the perturbation vector $\\delta$ such that the linearization error is bounded by a given tolerance $\\epsilon > 0$. The linearization error is defined as the absolute difference between the true function value $h(z_0 + \\delta)$ and its affine approximation at $z_0$, which is $h(z_0) + \\nabla h(z_0)^{\\top} \\delta$.\n\nLet the linearization error be denoted by $E(\\delta)$:\n$$\nE(\\delta) = \\left|h(z_{0}+\\delta) - \\left(h(z_{0}) + \\nabla h(z_{0})^{\\top} \\delta\\right)\\right|\n$$\nThe term inside the absolute value is the remainder of the first-order Taylor expansion of $h$ around $z_0$ evaluated at $z_0 + \\delta$. Since $h$ is given to be twice continuously differentiable ($C^2$) on the convex neighborhood $\\mathcal{N}$, we can express this remainder term using Taylor's theorem with the integral form:\n$$\nh(z_{0}+\\delta) - h(z_{0}) - \\nabla h(z_{0})^{\\top} \\delta = \\int_{0}^{1} (1-t) \\delta^{\\top} \\nabla^{2} h(z_{0}+t\\delta) \\delta \\, dt\n$$\nThe points $z_0+t\\delta$ for $t \\in [0, 1]$ form the line segment connecting $z_0$ and $z_0+\\delta = z$. Since $\\mathcal{N}$ is a convex set and $z_0, z \\in \\mathcal{N}$, this entire line segment lies within $\\mathcal{N}$. Therefore, the Hessian $\\nabla^{2} h(z_{0}+t\\delta)$ is well-defined and the given bound applies for all $t$ in the interval of integration.\n\nThe error is the absolute value of this integral:\n$$\nE(\\delta) = \\left| \\int_{0}^{1} (1-t) \\delta^{\\top} \\nabla^{2} h(z_{0}+t\\delta) \\delta \\, dt \\right|\n$$\nBy applying the triangle inequality for integrals (or Jensen's inequality), we can move the absolute value inside the integral:\n$$\nE(\\delta) \\le \\int_{0}^{1} \\left| (1-t) \\delta^{\\top} \\nabla^{2} h(z_{0}+t\\delta) \\delta \\right| \\, dt\n$$\nSince $t \\in [0, 1]$, the term $(1-t)$ is non-negative, so it can be moved outside the absolute value:\n$$\nE(\\delta) \\le \\int_{0}^{1} (1-t) \\left| \\delta^{\\top} \\nabla^{2} h(z_{0}+t\\delta) \\delta \\right| \\, dt\n$$\nThe problem states that the Hessian $\\nabla^{2} h(\\zeta)$ is bounded for all $\\zeta \\in \\mathcal{N}$ by the symmetric positive definite matrix $\\mathcal{B}_{\\alpha}$, with confidence level at least $1-\\alpha$. The bound is given in terms of the Loewner order as:\n$$\n-\\mathcal{B}_{\\alpha} \\preceq \\nabla^{2} h(\\zeta) \\preceq \\mathcal{B}_{\\alpha}\n$$\nFor any vector $\\delta \\in \\mathbb{R}^n$, this operator inequality implies the following inequality for the corresponding quadratic forms:\n$$\n\\delta^{\\top} (-\\mathcal{B}_{\\alpha}) \\delta \\le \\delta^{\\top} \\nabla^{2} h(\\zeta) \\delta \\le \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta\n$$\nThis is equivalent to:\n$$\n-\\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta \\le \\delta^{\\top} \\nabla^{2} h(\\zeta) \\delta \\le \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta\n$$\nThis precisely means that the absolute value of the quadratic form involving the Hessian is bounded:\n$$\n\\left| \\delta^{\\top} \\nabla^{2} h(\\zeta) \\delta \\right| \\le \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta\n$$\nThis bound holds for all $\\zeta \\in \\mathcal{N}$. Since $z_0+t\\delta \\in \\mathcal{N}$ for $t \\in [0,1]$, we can substitute this upper bound into our integral for the error $E(\\delta)$:\n$$\nE(\\delta) \\le \\int_{0}^{1} (1-t) (\\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta) \\, dt\n$$\nThe term $\\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta$ is a scalar that is constant with respect to the integration variable $t$, so it can be factored out of the integral:\n$$\nE(\\delta) \\le (\\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta) \\int_{0}^{1} (1-t) \\, dt\n$$\nEvaluating the elementary integral:\n$$\n\\int_{0}^{1} (1-t) \\, dt = \\left[t - \\frac{t^2}{2}\\right]_{0}^{1} = \\left(1 - \\frac{1}{2}\\right) - (0) = \\frac{1}{2}\n$$\nSubstituting this result back gives a deterministic upper bound on the linearization error:\n$$\nE(\\delta) \\le \\frac{1}{2} \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta\n$$\nThe derivation of this inequality is contingent on the Hessian bound, which holds with a confidence of at least $1-\\alpha$. Therefore, this error bound also holds with a confidence of at least $1-\\alpha$.\n\nWe are looking for a region of $\\delta$ where the linearization error is guaranteed to be no more than $\\epsilon$. That is, we require $E(\\delta) \\le \\epsilon$. A sufficient condition to ensure this is to require that our derived upper bound on the error be less than or equal to $\\epsilon$:\n$$\n\\frac{1}{2} \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta \\le \\epsilon\n$$\nThis inequality defines a set of vectors $\\delta$ for which the error tolerance is guaranteed to be met (with the specified confidence). Rearranging the inequality, we get:\n$$\n\\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta \\le 2\\epsilon\n$$\nSince $\\mathcal{B}_{\\alpha}$ is a symmetric positive definite matrix and $2\\epsilon > 0$, this inequality defines a closed, solid ellipsoid centered at the origin ($\\delta=0$) in the space $\\mathbb{R}^n$. Any $\\delta$ within this ellipsoid will satisfy the error tolerance condition.\n\nThe final expression for the confidence ellipsoid, as a set in $\\mathbb{R}^n$, is therefore:\n$$\n\\{ \\delta \\in \\mathbb{R}^{n} \\mid \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta \\le 2\\epsilon \\}\n$$\nThis is the closed-form expression for a confidence ellipsoid guaranteed to lie within the specified confidence region.",
            "answer": "$$\\boxed{\\{ \\delta \\in \\mathbb{R}^{n} \\mid \\delta^{\\top} \\mathcal{B}_{\\alpha} \\delta \\le 2\\epsilon \\}}$$"
        },
        {
            "introduction": "Linearization is a powerful simplification, but its power comes with a critical caveat: it can sometimes obscure essential features of the original nonlinear system. This practice presents a classic cautionary tale where a linearized model suggests a system is fully controllable, yet the true nonlinear system is not, due to a simple physical constraint on an actuator. By analyzing this intuitive example , you will develop a crucial instinct for the limitations of linear analysis and learn to critically assess when a linear model's predictions might diverge from physical reality.",
            "id": "4230034",
            "problem": "A cyber-physical system (CPS) has a digital twin that uses linearization to design controllers for a planar vehicle subject to a unidirectional thrust actuator. The physical plant is modeled by the nonlinear state equations\n$$\n\\dot{x}_{1} = x_{2}, \\qquad\n\\dot{x}_{2} = -\\beta\\, x_{2}\\,|x_{2}| + u,\n$$\nwhere $x_{1}$ is position, $x_{2}$ is velocity, $\\beta > 0$ is a known constant representing quadratic drag, and $u$ is the actuator input constrained by a hardware uni-directionality requirement $u \\in [0, u_{\\max}]$ with $u_{\\max} > 0$. The digital twin, however, uses the unconstrained linearization around the equilibrium $(x^{\\star},u^{\\star}) = (0,0)$ to assess controllability and design feedback.\n\nStarting only from the definitions of linearization via Jacobians and standard controllability concepts for linear systems, and without invoking any shortcut formulas, do the following:\n\n1. Identify the Jacobian matrices that define the linearization of the nonlinear plant around $(x^{\\star},u^{\\star}) = (0,0)$, obtaining a linear system $\\dot{\\delta x} = A\\,\\delta x + B\\,\\delta u$.\n\n2. For the $2 \\times 2$ pair $(A,B)$, form the controllability matrix with columns $B$ and $AB$, and compute its determinant. This determinant certifies whether the linearized pair is controllable by the usual rank test.\n\n3. Using first principles (variation of constants and sign arguments grounded in the given dynamics and constraints), explain why the nonlinear plant with the unilateral input constraint $u \\in [0,u_{\\max}]$ fails to be locally controllable at $(x^{\\star},u^{\\star}) = (0,0)$, even though the linearized pair $(A,B)$ is controllable in the unconstrained sense. In particular, show that for sufficiently small time horizons, the reachable set from $x^{\\star}$ cannot contain states with $x_{2} < 0$.\n\nYour final reported quantity should be the determinant from Part 2. Express the final answer as an exact real number. No rounding is required and no units should be included in the final answer box.",
            "solution": "The problem asks for a three-part analysis of a nonlinear control system: linearization, a controllability test on the linearized system, and an explanation for why the nonlinear system is not locally controllable.\n\nLet the state vector be $x = \\begin{pmatrix} x_{1} \\\\ x_{2} \\end{pmatrix}$. The nonlinear dynamics are given by $\\dot{x} = f(x, u)$, where the function $f: \\mathbb{R}^2 \\times \\mathbb{R} \\to \\mathbb{R}^2$ is defined as:\n$$\nf(x, u) = \\begin{pmatrix} f_{1}(x, u) \\\\ f_{2}(x, u) \\end{pmatrix} = \\begin{pmatrix} x_{2} \\\\ -\\beta\\, x_{2}\\,|x_{2}| + u \\end{pmatrix}\n$$\nThe system is to be analyzed at the equilibrium point $(x^{\\star}, u^{\\star})$, where $x^{\\star} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ and $u^{\\star} = 0$.\n\n**Part 1: Linearization**\n\nThe linearization of the nonlinear system around the equilibrium point $(x^{\\star}, u^{\\star})$ results in a linear time-invariant system of the form $\\dot{\\delta x} = A\\,\\delta x + B\\,\\delta u$, where $\\delta x = x - x^{\\star}$ and $\\delta u = u - u^{\\star}$. The matrices $A$ and $B$ are the Jacobians of $f$ with respect to $x$ and $u$, evaluated at the equilibrium point.\n\nThe Jacobian matrix $A$ is given by:\n$$\nA = \\frac{\\partial f}{\\partial x}\\bigg|_{(x^{\\star}, u^{\\star})} = \\begin{pmatrix} \\frac{\\partial f_{1}}{\\partial x_{1}} & \\frac{\\partial f_{1}}{\\partial x_{2}} \\\\ \\frac{\\partial f_{2}}{\\partial x_{1}} & \\frac{\\partial f_{2}}{\\partial x_{2}} \\end{pmatrix}\\bigg|_{(x^{\\star}, u^{\\star})}\n$$\nWe compute the partial derivatives:\n$\\frac{\\partial f_{1}}{\\partial x_{1}} = \\frac{\\partial}{\\partial x_{1}}(x_{2}) = 0$\n$\\frac{\\partial f_{1}}{\\partial x_{2}} = \\frac{\\partial}{\\partial x_{2}}(x_{2}) = 1$\n$\\frac{\\partial f_{2}}{\\partial x_{1}} = \\frac{\\partial}{\\partial x_{1}}(-\\beta\\, x_{2}\\,|x_{2}| + u) = 0$\n\nFor the derivative $\\frac{\\partial f_{2}}{\\partial x_{2}}$, we must differentiate the term $-\\beta\\, x_{2}\\,|x_{2}|$. The function $g(x_{2}) = x_{2}\\,|x_{2}|$ is $x_{2}^{2}$ for $x_{2} \\ge 0$ and $-x_{2}^{2}$ for $x_{2} < 0$. Its derivative is $\\frac{dg}{dx_{2}} = 2x_{2}$ for $x_{2} > 0$ and $\\frac{dg}{dx_{2}} = -2x_{2}$ for $x_{2} < 0$. This can be written compactly as $\\frac{d}{dx_{2}}(x_{2}\\,|x_{2}|) = 2|x_{2}|$. At $x_{2}=0$, the derivative is $0$.\nTherefore, $\\frac{\\partial f_{2}}{\\partial x_{2}} = \\frac{\\partial}{\\partial x_{2}}(-\\beta\\, x_{2}\\,|x_{2}| + u) = -2\\beta\\,|x_{2}|$.\n\nEvaluating the Jacobian matrix at the equilibrium state $x^{\\star} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$:\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ 0 & -2\\beta\\,|x_{2}| \\end{pmatrix}\\bigg|_{x_{2}=0} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}\n$$\nThe Jacobian matrix $B$ is given by:\n$$\nB = \\frac{\\partial f}{\\partial u}\\bigg|_{(x^{\\star}, u^{\\star})} = \\begin{pmatrix} \\frac{\\partial f_{1}}{\\partial u} \\\\ \\frac{\\partial f_{2}}{\\partial u} \\end{pmatrix}\\bigg|_{(x^{\\star}, u^{\\star})}\n$$\nWe compute the partial derivatives:\n$\\frac{\\partial f_{1}}{\\partial u} = \\frac{\\partial}{\\partial u}(x_{2}) = 0$\n$\\frac{\\partial f_{2}}{\\partial u} = \\frac{\\partial}{\\partial u}(-\\beta\\, x_{2}\\,|x_{2}| + u) = 1$\nThe resulting matrix $B$ is constant:\n$$\nB = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nThe linearized system is $\\dot{\\delta x} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\delta x + \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\delta u$.\n\n**Part 2: Controllability of the Linearized System**\n\nThe controllability of the linear pair $(A, B)$ is determined by the rank of the controllability matrix $\\mathcal{C} = [B \\mid AB \\mid \\dots \\mid A^{n-1}B]$. For a $2$-dimensional system ($n=2$), the matrix is $\\mathcal{C} = [B \\mid AB]$.\n\nWe have $A = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$ and $B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\nFirst, calculate the product $AB$:\n$$\nAB = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} (0)(0) + (1)(1) \\\\ (0)(0) + (0)(1) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\nNow, form the controllability matrix $\\mathcal{C}$:\n$$\n\\mathcal{C} = [B \\mid AB] = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}\n$$\nThe determinant of this matrix is:\n$$\n\\det(\\mathcal{C}) = (0)(0) - (1)(1) = -1\n$$\nSince $\\det(\\mathcal{C}) = -1 \\neq 0$, the rank of $\\mathcal{C}$ is $2$, which is equal to the dimension of the state space. Therefore, the linearized system $(A, B)$ is controllable.\n\n**Part 3: Local Uncontrollability of the Nonlinear System**\n\nDespite the controllability of its linearization, the original nonlinear system is not locally controllable at the origin due to the unilateral input constraint $u \\in [0, u_{\\max}]$. Local controllability at an equilibrium point $x^{\\star}$ requires that, for any neighborhood of $x^{\\star}$, the set of states reachable from $x^{\\star}$ in arbitrarily small time contains a neighborhood of $x^{\\star}$. We will show that from the origin $x(0) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, it is impossible to reach any state with a negative velocity, i.e., $x_{2} < 0$.\n\nThe dynamics of the velocity state $x_{2}$ are governed by:\n$$\n\\dot{x}_{2} = -\\beta\\, x_{2}\\,|x_{2}| + u(t)\n$$\nWe start at $x(0) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, so $x_{2}(0) = 0$. The input is constrained such that $u(t) \\ge 0$ for all $t \\ge 0$.\n\nLet us assume, for the sake of contradiction, that there exists a control input $u(t)$ and a time $T > 0$ such that the system reaches a state where $x_{2}(T) < 0$. Since the state trajectory $x(t)$ is continuous and $x_{2}(0) = 0$, there must be a first time $t_{0} \\in [0, T)$ where the velocity either becomes negative or is about to. Let $t_{0} = \\inf\\{t > 0 \\mid x_{2}(t) < 0\\}$. By the continuity of $x_{2}(t)$, we must have $x_{2}(t_{0}) = 0$. For any small $\\epsilon > 0$, there exists a time $t' \\in (t_{0}, t_{0}+\\epsilon)$ such that $x_{2}(t') < 0$.\n\nNow, let us examine the dynamics for any time $t > t_{0}$ where $x_{2}(t) < 0$. In this case, $|x_{2}(t)| = -x_{2}(t)$. The velocity dynamics become:\n$$\n\\dot{x}_{2}(t) = -\\beta\\, x_{2}(t) (-x_{2}(t)) + u(t) = \\beta\\,x_{2}(t)^{2} + u(t)\n$$\nSince $\\beta > 0$, the term $\\beta\\,x_{2}(t)^{2}$ is always non-negative. The input constraint specifies that $u(t)$ is also non-negative. Therefore, for any time $t$ where $x_{2}(t) < 0$, the time derivative of the velocity must be non-negative:\n$$\n\\dot{x}_{2}(t) \\ge 0\n$$\nThis implies that whenever the velocity $x_{2}$ is negative, it can only be non-decreasing.\n\nLet's return to the time $t_{0}$. We have $x_{2}(t_{0}) = 0$. For times $t$ in an interval $(t_{0}, t_{0}+\\delta)$ immediately following $t_{0}$, we have assumed $x_{2}(t) < 0$. However, according to our analysis, $\\dot{x}_{2}(t) \\ge 0$ for all $t$ in this interval. This means that $x_{2}(t)$ is a non-decreasing function on $(t_{0}, t_{0}+\\delta)$. A non-decreasing function starting from $x_{2}(t_{0})=0$ cannot take on negative values for $t>t_{0}$. That is, $x_{2}(t) \\ge x_{2}(t_{0}) = 0$ must hold. This creates a direct contradiction with our assumption that $x_{2}(t) < 0$ for $t \\in (t_{0}, t_{0}+\\delta)$.\n\nThe assumption that a state with $x_{2} < 0$ is reachable must be false. The reachable set from the origin is confined to the half-plane where $x_{2} \\ge 0$. Since any open neighborhood of the origin in $\\mathbb{R}^{2}$ contains points with $x_{2} < 0$, the reachable set cannot contain any such neighborhood. Thus, the nonlinear system is not locally controllable at the origin.\n\nThe linearization is misleading because it represents the system's behavior for infinitesimal perturbations $\\delta u$ around $u^{\\star}=0$ that can be both positive and negative. A negative $\\delta u$ (i.e., a negative total input $u$) would be required to generate a negative acceleration $\\dot{x}_{2}$ starting from rest. The physical constraint $u \\ge 0$ prohibits this, a critical detail that the linearization process discards.",
            "answer": "$$\\boxed{-1}$$"
        }
    ]
}