{
    "hands_on_practices": [
        {
            "introduction": "The core of Model Predictive Control is its ability to \"predict\" the future behavior of a system. This exercise takes you back to first principles to construct the very foundation of an MPC controller: the prediction model . By iteratively applying the state-update equation, you will derive an explicit expression for the future state, revealing its direct dependence on the initial state and the sequence of control actions.",
            "id": "2884328",
            "problem": "In the context of designing a finite-horizon Model Predictive Control (MPC) law for a discrete-time, linear time-invariant state-space model arising from signal processing and systems modeling, consider the state-update equation given by the fundamental state-evolution law\n$$x_{k+1}=A x_{k} + B u_{k},$$\nwhere the state is $x_{k} \\in \\mathbb{R}^{2}$ and the control input is $u_{k} \\in \\mathbb{R}$. The prediction model used in MPC is obtained by repeatedly applying this fundamental law forward in time from the current measured state $x_{0}$. You are given\n$$A=\\begin{bmatrix}0.9  0 \\\\ 0.1  0.95\\end{bmatrix}, \\quad B=\\begin{bmatrix}1 \\\\ 0\\end{bmatrix}.$$\nUsing only the fundamental recursion $x_{k+1}=A x_{k} + B u_{k}$ and first principles (no pre-condensed prediction formulas), derive the three-step-ahead predicted state $x_{3}$ as a closed-form analytic expression that depends only on $x_{0}$ and the input moves $u_{0}, u_{1}, u_{2}$. Express your final answer as a single closed-form analytic expression. No rounding is required and no units are associated with the variables.",
            "solution": "The problem statement is scientifically grounded, well-posed, objective, and self-contained. It presents a standard task in linear systems theory, fundamental to the field of Model Predictive Control. The problem is valid.\n\nThe objective is to derive the expression for the state vector $x_{3}$ three time steps into the future, based on the initial state $x_{0}$ and a sequence of control inputs $u_{0}$, $u_{1}$, and $u_{2}$. The derivation must proceed from first principles, using the fundamental state-evolution law for a discrete-time linear time-invariant system.\n\nThe state-update equation is given as:\n$$x_{k+1} = A x_{k} + B u_{k}$$\nwhere $k$ is the discrete time index. The initial state at $k=0$ is $x_{0}$. We will derive the state at successive time steps by recurrent substitution.\n\nFor $k=0$, the state at the next time step, $x_{1}$, is:\n$$x_{1} = A x_{0} + B u_{0}$$\n\nFor $k=1$, the state $x_{2}$ is found by applying the evolution law to $x_{1}$:\n$$x_{2} = A x_{1} + B u_{1}$$\nSubstituting the expression for $x_{1}$ into this equation gives:\n$$x_{2} = A (A x_{0} + B u_{0}) + B u_{1}$$\nBy the distributive property of matrix multiplication, this becomes:\n$$x_{2} = A^{2} x_{0} + A B u_{0} + B u_{1}$$\n\nFor $k=2$, the state $x_{3}$ is found by applying the law to $x_{2}$:\n$$x_{3} = A x_{2} + B u_{2}$$\nSubstituting the expression for $x_{2}$ yields:\n$$x_{3} = A (A^{2} x_{0} + A B u_{0} + B u_{1}) + B u_{2}$$\nDistributing the matrix $A$ results in the general closed-form expression for the three-step-ahead prediction:\n$$x_{3} = A^{3} x_{0} + A^{2} B u_{0} + A B u_{1} + B u_{2}$$\n\nThe problem requires a specific analytical expression for the given system matrices:\n$$A = \\begin{bmatrix} 0.9  0 \\\\ 0.1  0.95 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$$\nTo obtain the final expression, we must compute the matrix powers $A^{2}$, $A^{3}$ and the products $A B$, $A^{2} B$.\n\nFirst, we compute the powers of matrix $A$:\n$$A^{2} = A A = \\begin{bmatrix} 0.9  0 \\\\ 0.1  0.95 \\end{bmatrix} \\begin{bmatrix} 0.9  0 \\\\ 0.1  0.95 \\end{bmatrix} = \\begin{bmatrix} (0.9)(0.9) + (0)(0.1)  (0.9)(0) + (0)(0.95) \\\\ (0.1)(0.9) + (0.95)(0.1)  (0.1)(0) + (0.95)(0.95) \\end{bmatrix} = \\begin{bmatrix} 0.81  0 \\\\ 0.185  0.9025 \\end{bmatrix}$$\n$$A^{3} = A A^{2} = \\begin{bmatrix} 0.9  0 \\\\ 0.1  0.95 \\end{bmatrix} \\begin{bmatrix} 0.81  0 \\\\ 0.185  0.9025 \\end{bmatrix} = \\begin{bmatrix} (0.9)(0.81) + (0)(0.185)  (0.9)(0) + (0)(0.9025) \\\\ (0.1)(0.81) + (0.95)(0.185)  (0.1)(0) + (0.95)(0.9025) \\end{bmatrix} = \\begin{bmatrix} 0.729  0 \\\\ 0.25675  0.857375 \\end{bmatrix}$$\n\nNext, we compute the matrix-vector products involving $B$:\n$$A B = \\begin{bmatrix} 0.9  0 \\\\ 0.1  0.95 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0.9 \\\\ 0.1 \\end{bmatrix}$$\n$$A^{2} B = A (A B) = \\begin{bmatrix} 0.9  0 \\\\ 0.1  0.95 \\end{bmatrix} \\begin{bmatrix} 0.9 \\\\ 0.1 \\end{bmatrix} = \\begin{bmatrix} (0.9)(0.9) + (0)(0.1) \\\\ (0.1)(0.9) + (0.95)(0.1) \\end{bmatrix} = \\begin{bmatrix} 0.81 \\\\ 0.185 \\end{bmatrix}$$\n\nSubstituting these computed matrices into the general expression for $x_{3}$:\n$$x_{3} = \\begin{bmatrix} 0.729  0 \\\\ 0.25675  0.857375 \\end{bmatrix} x_{0} + \\begin{bmatrix} 0.81 \\\\ 0.185 \\end{bmatrix} u_{0} + \\begin{bmatrix} 0.9 \\\\ 0.1 \\end{bmatrix} u_{1} + \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} u_{2}$$\n\nThis expression can be written more compactly by grouping the terms dependent on the control input sequence $U = \\begin{bmatrix} u_{0} \\\\ u_{1} \\\\ u_{2} \\end{bmatrix}$:\n$$x_{3} = \\begin{bmatrix} 0.729  0 \\\\ 0.25675  0.857375 \\end{bmatrix} x_{0} + \\begin{bmatrix} 0.81  0.9  1 \\\\ 0.185  0.1  0 \\end{bmatrix} \\begin{bmatrix} u_{0} \\\\ u_{1} \\\\ u_{2} \\end{bmatrix}$$\nThis is the required single closed-form analytic expression for the three-step-ahead predicted state $x_{3}$.",
            "answer": "$$\n\\boxed{\n\\begin{bmatrix}\n0.729  0 \\\\\n0.25675  0.857375\n\\end{bmatrix}\nx_{0} + \n\\begin{bmatrix}\n0.81  0.9  1 \\\\\n0.185  0.1  0\n\\end{bmatrix}\n\\begin{bmatrix}\nu_{0} \\\\\nu_{1} \\\\\nu_{2}\n\\end{bmatrix}\n}\n$$"
        },
        {
            "introduction": "Once we can predict the system's future trajectory, the next step in MPC is to find the optimal sequence of control inputs that minimizes a certain cost. This optimization problem is typically formulated as a Quadratic Program (QP), and this exercise focuses on constructing its key components . You will learn how the system dynamics and cost function weights are condensed into the Hessian matrix, which defines the curvature of the optimization landscape.",
            "id": "2884304",
            "problem": "Consider a discrete-time, linear time-invariant scalar system in the standard Model Predictive Control (MPC) setup:\n$$x_{k+1} = A x_{k} + B u_{k},$$\nwith given parameters $A = 0.8$ and $B = 1$. Let the finite-horizon cost of length $N = 3$ be\n$$J = \\sum_{k=0}^{N-1} \\left( x_{k}^{\\top} Q x_{k} + u_{k}^{\\top} R u_{k} \\right),$$\nwith $Q = 1$ and $R = 0.1$. There is no terminal-state penalty, that is, the terminal weight is zero. Introduce the stacked input vector\n$$U = \\begin{pmatrix} u_{0} \\\\ u_{1} \\\\ u_{2} \\end{pmatrix},$$\nand write the cost in the canonical Quadratic Program (QP) form\n$$J(U) = \\frac{1}{2} U^{\\top} H U + f^{\\top} U + c,$$\nwhere $H$ is the condensed Hessian that depends only on the system matrices and cost weights, $f$ depends on the initial condition $x_{0}$, and $c$ is a constant independent of $U$. Starting only from the state update equation and the finite-horizon cost definition, form the prediction model for the stacked states over the horizon and derive the condensed Hessian $H$ explicitly for the given numerical values. Compute $H$ as a numeric $3 \\times 3$ matrix. No rounding is required; report exact decimal values. The final answer must be the explicit matrix $H$.",
            "solution": "The problem presented is a standard formulation in Model Predictive Control (MPC) and is scientifically grounded, well-posed, and objective. It contains all necessary information for a unique solution. Therefore, the problem is deemed valid and a full solution is provided below.\n\nThe objective is to derive the condensed Hessian matrix $H$ for the given discrete-time system and quadratic cost function. The cost function $J$ must be expressed in the quadratic program (QP) form $J(U) = \\frac{1}{2} U^{\\top} H U + f^{\\top} U + c$, where $U$ is the stacked vector of control inputs over the prediction horizon.\n\nThe system dynamics are given by:\n$$x_{k+1} = A x_{k} + B u_{k}$$\nwith scalar parameters $A = 0.8$ and $B = 1$. The state $x_k$ and control input $u_k$ are also scalars.\n\nThe finite-horizon cost is defined over a horizon $N=3$:\n$$J = \\sum_{k=0}^{N-1} \\left( x_{k}^{\\top} Q x_{k} + u_{k}^{\\top} R u_{k} \\right) = \\sum_{k=0}^{2} \\left( x_{k}^{2} Q + u_{k}^{2} R \\right)$$\nwith weights $Q = 1$ and $R = 0.1$. The terminal weight is zero.\n\nThe control input vector to be optimized is:\n$$U = \\begin{pmatrix} u_{0} \\\\ u_{1} \\\\ u_{2} \\end{pmatrix}$$\nThe states that contribute to the cost are $x_0$, $x_1$, and $x_2$. We must express these states in terms of the initial state $x_0$ and the control inputs $u_0, u_1, u_2$.\nThe state evolution is as follows:\n$x_0$ is the initial condition.\n$$x_{1} = A x_{0} + B u_{0}$$\n$$x_{2} = A x_{1} + B u_{1} = A (A x_{0} + B u_{0}) + B u_{1} = A^2 x_{0} + A B u_{0} + B u_{1}$$\n\nWe can express the sequence of states relevant to the cost, $\\mathbf{X}_{\\text{cost}} = \\begin{pmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{pmatrix}$, in a stacked matrix form:\n$$\\begin{pmatrix} x_{0} \\\\ x_{1} \\\\ x_{2} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ A \\\\ A^2 \\end{pmatrix} x_{0} + \\begin{pmatrix} 0  0  0 \\\\ B  0  0 \\\\ AB  B  0 \\end{pmatrix} \\begin{pmatrix} u_{0} \\\\ u_{1} \\\\ u_{2} \\end{pmatrix}$$\nLet's denote these matrices as $\\mathbf{S}_{x}$ and $\\mathbf{S}_{u}$, so that $\\mathbf{X}_{\\text{cost}} = \\mathbf{S}_{x} x_{0} + \\mathbf{S}_{u} U$.\n\nThe cost function can be written in matrix form as:\n$$J = \\mathbf{X}_{\\text{cost}}^{\\top} \\bar{Q} \\mathbf{X}_{\\text{cost}} + U^{\\top} \\bar{R} U$$\nwhere $\\bar{Q}$ and $\\bar{R}$ are block-diagonal matrices of weights:\n$$\\bar{Q} = \\begin{pmatrix} Q  0  0 \\\\ 0  Q  0 \\\\ 0  0  Q \\end{pmatrix}, \\quad \\bar{R} = \\begin{pmatrix} R  0  0 \\\\ 0  R  0 \\\\ 0  0  R \\end{pmatrix}$$\nSubstituting the expression for $\\mathbf{X}_{\\text{cost}}$ into the cost function $J$:\n$$J = (\\mathbf{S}_{x} x_{0} + \\mathbf{S}_{u} U)^{\\top} \\bar{Q} (\\mathbf{S}_{x} x_{0} + \\mathbf{S}_{u} U) + U^{\\top} \\bar{R} U$$\nExpanding this expression:\n$$J = x_{0}^{\\top} \\mathbf{S}_{x}^{\\top} \\bar{Q} \\mathbf{S}_{x} x_{0} + 2 x_{0}^{\\top} \\mathbf{S}_{x}^{\\top} \\bar{Q} \\mathbf{S}_{u} U + U^{\\top} \\mathbf{S}_{u}^{\\top} \\bar{Q} \\mathbf{S}_{u} U + U^{\\top} \\bar{R} U$$\nThis expression matches the QP form $J(U) = c + f^{\\top} U + \\frac{1}{2} U^{\\top} H U$.\nThe term quadratic in $U$ is $U^{\\top} (\\mathbf{S}_{u}^{\\top} \\bar{Q} \\mathbf{S}_{u} + \\bar{R}) U$.\nBy comparison with $\\frac{1}{2} U^{\\top} H U$, we identify the condensed Hessian matrix $H$ as:\n$$H = 2 \\left( \\mathbf{S}_{u}^{\\top} \\bar{Q} \\mathbf{S}_{u} + \\bar{R} \\right)$$\nNow, we substitute the given numerical values: $A = 0.8$, $B = 1$, $Q = 1$, $R = 0.1$.\nThe matrices $\\mathbf{S}_u$, $\\bar{Q}$, and $\\bar{R}$ become:\n$$\\mathbf{S}_{u} = \\begin{pmatrix} 0  0  0 \\\\ 1  0  0 \\\\ (0.8)(1)  1  0 \\end{pmatrix} = \\begin{pmatrix} 0  0  0 \\\\ 1  0  0 \\\\ 0.8  1  0 \\end{pmatrix}$$\n$$\\bar{Q} = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} = I_{3}$$\n$$\\bar{R} = \\begin{pmatrix} 0.1  0  0 \\\\ 0  0.1  0 \\\\ 0  0  0.1 \\end{pmatrix}$$\nSince $\\bar{Q}$ is the identity matrix, $\\mathbf{S}_{u}^{\\top} \\bar{Q} \\mathbf{S}_{u} = \\mathbf{S}_{u}^{\\top} \\mathbf{S}_{u}$.\nFirst, we compute $\\mathbf{S}_{u}^{\\top} \\mathbf{S}_{u}$:\n$$\\mathbf{S}_{u}^{\\top} \\mathbf{S}_{u} = \\begin{pmatrix} 0  1  0.8 \\\\ 0  0  1 \\\\ 0  0  0 \\end{pmatrix} \\begin{pmatrix} 0  0  0 \\\\ 1  0  0 \\\\ 0.8  1  0 \\end{pmatrix} = \\begin{pmatrix} (1)(1)+(0.8)(0.8)  (0.8)(1)  0 \\\\ (1)(0.8)  (1)(1)  0 \\\\ 0  0  0 \\end{pmatrix} = \\begin{pmatrix} 1.64  0.8  0 \\\\ 0.8  1  0 \\\\ 0  0  0 \\end{pmatrix}$$\nNext, we add $\\bar{R}$:\n$$\\mathbf{S}_{u}^{\\top} \\bar{Q} \\mathbf{S}_{u} + \\bar{R} = \\begin{pmatrix} 1.64  0.8  0 \\\\ 0.8  1  0 \\\\ 0  0  0 \\end{pmatrix} + \\begin{pmatrix} 0.1  0  0 \\\\ 0  0.1  0 \\\\ 0  0  0.1 \\end{pmatrix} = \\begin{pmatrix} 1.74  0.8  0 \\\\ 0.8  1.1  0 \\\\ 0  0  0.1 \\end{pmatrix}$$\nFinally, we compute $H$ by multiplying by $2$:\n$$H = 2 \\begin{pmatrix} 1.74  0.8  0 \\\\ 0.8  1.1  0 \\\\ 0  0  0.1 \\end{pmatrix} = \\begin{pmatrix} 3.48  1.6  0 \\\\ 1.6  2.2  0 \\\\ 0  0  0.2 \\end{pmatrix}$$\nThis is the condensed Hessian matrix for the given MPC problem.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n3.48  1.6  0 \\\\\n1.6  2.2  0 \\\\\n0  0  0.2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "In practical applications for cyber-physical systems, the models we use are never perfect, and measurements are subject to noise. This practice introduces a fundamental technique from robust MPC to guarantee safety and stability despite such uncertainties . You will use the concept of the Minkowski set difference to systematically \"tighten\" state constraints, ensuring that the true system state remains within its admissible region for any possible error.",
            "id": "4231525",
            "problem": "Consider a robust Model Predictive Control (MPC) design for a digital twin in cyber-physical systems (CPS), where state predictions are subject to bounded additive estimation errors. Let the nominal state be $x \\in \\mathbb{R}^{2}$ and the admissible state set be the half-space $\\mathcal{X} = \\{ x \\in \\mathbb{R}^{2} \\mid h^{\\top} x \\leq k \\}$, with $h \\in \\mathbb{R}^{2}$ and $k \\in \\mathbb{R}$. The estimation error $e \\in \\mathbb{R}^{2}$ lies in a known convex polyhedral set $\\mathcal{E}$. To guarantee that the actual state $x + e$ satisfies $\\mathcal{X}$ for all $e \\in \\mathcal{E}$, one enforces the tightened constraint $x \\in \\mathcal{X} \\ominus \\mathcal{E}$, where the Pontryagin (Minkowski) difference is defined by $\\mathcal{X} \\ominus \\mathcal{E} = \\{ x \\in \\mathbb{R}^{2} \\mid x + \\mathcal{E} \\subseteq \\mathcal{X} \\}$.\n\nStarting only from the definitions of the Pontryagin difference and the support function $h_{\\mathcal{S}}(v) = \\sup_{s \\in \\mathcal{S}} v^{\\top} s$ of a convex set $\\mathcal{S}$, derive a scalar inequality of the form $h^{\\top} x \\leq \\text{(tightened bound)}$ that ensures $x \\in \\mathcal{X} \\ominus \\mathcal{E}$, and express the tightened bound in terms of $h_{\\mathcal{E}}(h)$.\n\nThen, compute this tightened bound numerically in the specific case where $h = \\begin{pmatrix} 3 \\\\ -4 \\end{pmatrix}$, $k = 2$, and $\\mathcal{E}$ is the axis-aligned hyperrectangle\n$$\n\\mathcal{E} = \\{ e \\in \\mathbb{R}^{2} \\mid |e_{1}| \\leq 0.05,\\ |e_{2}| \\leq 0.02 \\}.\n$$\nProvide your final answer as a single real number. No rounding is necessary.",
            "solution": "The problem requires the derivation of a tightened constraint for a robust Model Predictive Control (MPC) problem and its subsequent numerical evaluation.\n\n### Step 1: Problem Validation\n\n**1. Extraction of Givens:**\n- Nominal state: $x \\in \\mathbb{R}^{2}$\n- Admissible state set: $\\mathcal{X} = \\{ x \\in \\mathbb{R}^{2} \\mid h^{\\top} x \\leq k \\}$, where $h \\in \\mathbb{R}^{2}$ and $k \\in \\mathbb{R}$.\n- Estimation error: $e \\in \\mathbb{R}^{2}$, belonging to a known convex polyhedral set $\\mathcal{E}$.\n- Robustness condition: The actual state $x + e$ must remain in $\\mathcal{X}$ for all possible errors $e \\in \\mathcal{E}$.\n- Tightened constraint set: $x \\in \\mathcal{X} \\ominus \\mathcal{E}$.\n- Pontryagin (Minkowski) difference: $\\mathcal{X} \\ominus \\mathcal{E} = \\{ x \\in \\mathbb{R}^{2} \\mid x + \\mathcal{E} \\subseteq \\mathcal{X} \\}$.\n- Support function of a convex set $\\mathcal{S}$: $h_{\\mathcal{S}}(v) = \\sup_{s \\in \\mathcal{S}} v^{\\top} s$.\n- Task 1: Derive a scalar inequality $h^{\\top} x \\leq \\text{(tightened bound)}$ equivalent to $x \\in \\mathcal{X} \\ominus \\mathcal{E}$, with the bound expressed in terms of $h_{\\mathcal{E}}(h)$.\n- Task 2: Compute the tightened bound for the specific case: $h = \\begin{pmatrix} 3 \\\\ -4 \\end{pmatrix}$, $k = 2$, and $\\mathcal{E} = \\{ e \\in \\mathbb{R}^{2} \\mid |e_{1}| \\leq 0.05,\\ |e_{2}| \\leq 0.02 \\}$.\n\n**2. Validation:**\n- **Scientific Grounding:** The problem is based on established principles of robust control theory, specifically set-based methods for handling uncertainty. The concepts of Pontryagin difference and support functions are standard tools in this domain. The problem is scientifically sound.\n- **Well-Posedness:** The problem provides all necessary definitions and data to derive a unique analytical expression and then compute a unique numerical result. It is well-posed.\n- **Objectivity:** The problem is stated in precise, formal mathematical language, free of ambiguity or subjective claims.\n\n**3. Verdict:**\nThe problem is valid.\n\n### Step 2: Derivation of the Tightened Constraint\n\nThe starting point is the condition for the nominal state $x$ to be in the tightened set $\\mathcal{X} \\ominus \\mathcal{E}$. By the definition of the Pontryagin difference provided:\n$$\nx \\in \\mathcal{X} \\ominus \\mathcal{E} \\iff x + \\mathcal{E} \\subseteq \\mathcal{X}\n$$\nThe condition $x + \\mathcal{E} \\subseteq \\mathcal{X}$ means that every element in the set $x + \\mathcal{E}$ must also be an element of the set $\\mathcal{X}$. An element of $x + \\mathcal{E}$ has the form $x + e$ for some $e \\in \\mathcal{E}$.\nThe set $\\mathcal{X}$ is defined by the linear inequality $h^{\\top} z \\leq k$ for any $z \\in \\mathcal{X}$.\nTherefore, for $x + \\mathcal{E}$ to be a subset of $\\mathcal{X}$, the inequality must hold for all points $z = x + e$, where $e \\in \\mathcal{E}$. This gives the condition:\n$$\nh^{\\top}(x + e) \\leq k, \\quad \\forall e \\in \\mathcal{E}\n$$\nUsing the linearity of the inner product, we can expand the left-hand side:\n$$\nh^{\\top}x + h^{\\top}e \\leq k, \\quad \\forall e \\in \\mathcal{E}\n$$\nTo ensure this inequality holds for all $e \\in \\mathcal{E}$, the term $h^{\\top}x$ must be small enough to compensate for the largest possible value of $h^{\\top}e$. We can rearrange the inequality as:\n$$\nh^{\\top}x \\leq k - h^{\\top}e, \\quad \\forall e \\in \\mathcal{E}\n$$\nThis is equivalent to requiring that $h^{\\top}x$ be less than or equal to the minimum value of the right-hand side over all $e \\in \\mathcal{E}$:\n$$\nh^{\\top}x \\leq \\min_{e \\in \\mathcal{E}} (k - h^{\\top}e)\n$$\nSince $k$ is a constant, minimizing $k - h^{\\top}e$ is equivalent to maximizing $h^{\\top}e$:\n$$\nh^{\\top}x \\leq k - \\max_{e \\in \\mathcal{E}} (h^{\\top}e)\n$$\nThe problem defines the support function of a convex set $\\mathcal{S}$ as $h_{\\mathcal{S}}(v) = \\sup_{s \\in \\mathcal{S}} v^{\\top} s$. For a compact set, the supremum is equivalent to the maximum. Applying this definition to our expression with $\\mathcal{S} = \\mathcal{E}$ and $v = h$, we get:\n$$\n\\max_{e \\in \\mathcal{E}} (h^{\\top}e) = h_{\\mathcal{E}}(h)\n$$\nSubstituting this into our inequality yields the final form of the tightened constraint:\n$$\nh^{\\top}x \\leq k - h_{\\mathcal{E}}(h)\n$$\nThis is the required scalar inequality. The tightened bound is the right-hand side of this expression, $k - h_{\\mathcal{E}}(h)$.\n\n### Step 3: Numerical Computation\n\nWe are now asked to compute this tightened bound for the specific case where:\n- $h = \\begin{pmatrix} 3 \\\\ -4 \\end{pmatrix}$\n- $k = 2$\n- $\\mathcal{E} = \\{ e = \\begin{pmatrix} e_1 \\\\ e_2 \\end{pmatrix} \\in \\mathbb{R}^{2} \\mid |e_{1}| \\leq 0.05,\\ |e_{2}| \\leq 0.02 \\}$\n\nThe tightened bound is $k - h_{\\mathcal{E}}(h)$. First, we must calculate the value of the support function $h_{\\mathcal{E}}(h)$.\n$$\nh_{\\mathcal{E}}(h) = \\sup_{e \\in \\mathcal{E}} (h^{\\top}e)\n$$\nSubstituting the given values for $h$ and $e$:\n$$\nh^{\\top}e = \\begin{pmatrix} 3  -4 \\end{pmatrix} \\begin{pmatrix} e_1 \\\\ e_2 \\end{pmatrix} = 3e_1 - 4e_2\n$$\nThe domain $\\mathcal{E}$ is an axis-aligned rectangle defined by the constraints:\n$$\n-0.05 \\leq e_1 \\leq 0.05\n$$\n$$\n-0.02 \\leq e_2 \\leq 0.02\n$$\nWe need to find the supremum of the linear function $3e_1 - 4e_2$ over this rectangular domain. To maximize this expression, we must:\n1.  Maximize the term $3e_1$. Since the coefficient $3$ is positive, we choose the maximum possible value for $e_1$, which is $e_1 = 0.05$.\n2.  Maximize the term $-4e_2$. Since the coefficient $-4$ is negative, we choose the minimum possible value for $e_2$, which is $e_2 = -0.02$.\n\nThis is because the terms $3e_1$ and $-4e_2$ are independent. The supremum is thus:\n$$\nh_{\\mathcal{E}}(h) = 3(0.05) - 4(-0.02) = 0.15 + 0.08 = 0.23\n$$\nNow we can compute the tightened bound, $k - h_{\\mathcal{E}}(h)$:\n$$\n\\text{Tightened bound} = 2 - 0.23 = 1.77\n$$\nThe tightened constraint for the nominal state $x$ is thus $\\begin{pmatrix} 3  -4 \\end{pmatrix} x \\leq 1.77$. The problem asks for the numerical value of the tightened bound.",
            "answer": "$$\n\\boxed{1.77}\n$$"
        }
    ]
}