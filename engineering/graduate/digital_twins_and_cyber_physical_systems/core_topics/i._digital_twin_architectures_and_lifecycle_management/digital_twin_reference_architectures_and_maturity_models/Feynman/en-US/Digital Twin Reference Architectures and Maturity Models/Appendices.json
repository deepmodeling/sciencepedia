{
    "hands_on_practices": [
        {
            "introduction": "A core function of a Digital Twin is to accurately mirror the state of its physical counterpart. Before a twin can be used for prediction or control, we must ensure that it can, in principle, determine the complete internal state of the asset based on the available sensor outputs. This fundamental requirement is captured by the control-theoretic concept of observability, which serves as a critical gateway to achieving a \"synchronized\" maturity level. This exercise  provides a direct application of the Kalman observability criterion to verify if a twin's model is capable of full state reconstruction.",
            "id": "4215314",
            "problem": "A Digital Twin (DT) of a Cyber-Physical System (CPS) is engineered following a layered reference architecture in which the model layer exposes a continuous-time Linear Time-Invariant (LTI) state-space representation derived from the asset dynamics and instrumentation layout. At the “synchronized” stage of a widely used Digital Twin Maturity Model, the DT must support exact model-based state reconstruction (ignoring noise) from measured outputs, which requires that the pair $(A, C)$ be observable in the linearized regime.\n\nConsider the LTI model of the asset-twin system linearized about an operating point:\n$$\n\\dot{x}(t) = A\\,x(t), \\qquad y(t) = C\\,x(t),\n$$\nwhere the state is $x(t) \\in \\mathbb{R}^{3}$ and the output is $y(t) \\in \\mathbb{R}$. The matrices $A \\in \\mathbb{R}^{3 \\times 3}$ and $C \\in \\mathbb{R}^{1 \\times 3}$ are given by\n$$\nA = \\begin{pmatrix}\n0 & 1 & 0 \\\\\n0 & 0 & 1 \\\\\n-6 & -11 & -6\n\\end{pmatrix}, \n\\qquad\nC = \\begin{pmatrix}\n1 & 0 & 1\n\\end{pmatrix}.\n$$\nUsing fundamental principles of observability for Linear Time-Invariant systems and without invoking any unproven shortcuts, construct the observability matrix built from $A$ and $C$, compute its rank, and conclude whether exact state reconstruction is feasible for the DT at the synchronized maturity stage when measurement noise is neglected. Provide the rank as an integer. No rounding is necessary.",
            "solution": "The problem statement is evaluated to be valid as it is scientifically grounded in the principles of linear systems and control theory, is well-posed with all necessary information provided, and is articulated in precise, objective language. There are no contradictions, ambiguities, or factual inaccuracies.\n\nThe problem requires an analysis of the observability of a continuous-time Linear Time-Invariant (LTI) system. An LTI system described by the state-space equations\n$$\n\\dot{x}(t) = A\\,x(t) + B\\,u(t)\n$$\n$$\ny(t) = C\\,x(t) + D\\,u(t)\n$$\nis said to be observable if, for any unknown initial state $x(t_0)$, it is possible to determine this state from the history of system outputs $y(t)$ and inputs $u(t)$ over a finite time interval $[t_0, t_f]$. For the given system, which is autonomous ($u(t)=0$) and has no direct feedthrough ($D=0$), the condition simplifies. The system is described by:\n$$\n\\dot{x}(t) = A\\,x(t), \\qquad y(t) = C\\,x(t)\n$$\nThe state vector is $x(t) \\in \\mathbb{R}^n$, where the dimension of the state space is $n=3$. The matrices $A$ and $C$ are given as:\n$$\nA = \\begin{pmatrix}\n0 & 1 & 0 \\\\\n0 & 0 & 1 \\\\\n-6 & -11 & -6\n\\end{pmatrix} \\in \\mathbb{R}^{3 \\times 3}, \n\\qquad\nC = \\begin{pmatrix}\n1 & 0 & 1\n\\end{pmatrix} \\in \\mathbb{R}^{1 \\times 3}.\n$$\nAccording to the Kalman observability criterion, the pair $(A, C)$ is observable if and only if the observability matrix, denoted by $\\mathcal{O}$, has full column rank. For a system with state dimension $n$, the observability matrix is constructed as:\n$$\n\\mathcal{O} = \\begin{pmatrix}\nC \\\\\nCA \\\\\nCA^2 \\\\\n\\vdots \\\\\nCA^{n-1}\n\\end{pmatrix}\n$$\nIn this problem, the state dimension is $n=3$, so the observability matrix is a $3 \\times 3$ matrix given by:\n$$\n\\mathcal{O} = \\begin{pmatrix}\nC \\\\\nCA \\\\\nCA^2\n\\end{pmatrix}\n$$\nTo construct this matrix, we must compute the products $CA$ and $CA^2$.\n\nFirst, we compute the product $CA$:\n$$\nCA = \\begin{pmatrix} 1 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ -6 & -11 & -6 \\end{pmatrix}\n$$\n$$\nCA = \\begin{pmatrix} 1(0) + 0(0) + 1(-6) & 1(1) + 0(0) + 1(-11) & 1(0) + 0(1) + 1(-6) \\end{pmatrix}\n$$\n$$\nCA = \\begin{pmatrix} -6 & -10 & -6 \\end{pmatrix}\n$$\nNext, we compute $CA^2$. We can do this by first computing $A^2$ and then left-multiplying by $C$.\n$$\nA^2 = A \\cdot A = \\begin{pmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ -6 & -11 & -6 \\end{pmatrix} \\begin{pmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ -6 & -11 & -6 \\end{pmatrix}\n$$\n$$\nA^2 = \\begin{pmatrix}\n0(0)+1(0)+0(-6) & 0(1)+1(0)+0(-11) & 0(0)+1(1)+0(-6) \\\\\n0(0)+0(0)+1(-6) & 0(1)+0(0)+1(-11) & 0(0)+0(1)+1(-6) \\\\\n-6(0)-11(0)-6(-6) & -6(1)-11(0)-6(-11) & -6(0)-11(1)-6(-6)\n\\end{pmatrix}\n$$\n$$\nA^2 = \\begin{pmatrix} 0 & 0 & 1 \\\\ -6 & -11 & -6 \\\\ 36 & 60 & 25 \\end{pmatrix}\n$$\nNow, we compute $CA^2$:\n$$\nCA^2 = \\begin{pmatrix} 1 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 & 1 \\\\ -6 & -11 & -6 \\\\ 36 & 60 & 25 \\end{pmatrix}\n$$\n$$\nCA^2 = \\begin{pmatrix} 1(0)+0(-6)+1(36) & 1(0)+0(-11)+1(60) & 1(1)+0(-6)+1(25) \\end{pmatrix}\n$$\n$$\nCA^2 = \\begin{pmatrix} 36 & 60 & 26 \\end{pmatrix}\n$$\nWe can now assemble the observability matrix $\\mathcal{O}$:\n$$\n\\mathcal{O} = \\begin{pmatrix}\nC \\\\\nCA \\\\\nCA^2\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 0 & 1 \\\\\n-6 & -10 & -6 \\\\\n36 & 60 & 26\n\\end{pmatrix}\n$$\nFor the system to be observable, the rank of $\\mathcal{O}$ must be equal to the state dimension, $n=3$. For a square matrix, having full rank is equivalent to having a non-zero determinant. We compute the determinant of $\\mathcal{O}$:\n$$\n\\det(\\mathcal{O}) = 1 \\cdot \\det\\begin{pmatrix} -10 & -6 \\\\ 60 & 26 \\end{pmatrix} - 0 \\cdot \\det\\begin{pmatrix} -6 & -6 \\\\ 36 & 26 \\end{pmatrix} + 1 \\cdot \\det\\begin{pmatrix} -6 & -10 \\\\ 36 & 60 \\end{pmatrix}\n$$\n$$\n\\det(\\mathcal{O}) = 1 \\cdot ((-10)(26) - (-6)(60)) - 0 + 1 \\cdot ((-6)(60) - (-10)(36))\n$$\n$$\n\\det(\\mathcal{O}) = (-260 + 360) + (-360 + 360)\n$$\n$$\n\\det(\\mathcal{O}) = 100 + 0 = 100\n$$\nSince $\\det(\\mathcal{O}) = 100 \\neq 0$, the matrix $\\mathcal{O}$ is non-singular and has full rank. The rank of the observability matrix is therefore:\n$$\n\\text{rank}(\\mathcal{O}) = 3\n$$\nBecause the rank of the observability matrix, $3$, is equal to the dimension of the state space, $n=3$, the system is completely observable. This confirms that, in the idealized case where measurement noise is neglected, it is theoretically possible to uniquely reconstruct the full state vector $x(t)$ from the measurements of the output $y(t)$. Thus, the condition for the \"synchronized\" maturity stage is met. The question asks for the rank of the observability matrix as an integer.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "For a Digital Twin to be effective in real-time control applications, its response time is paramount. The end-to-end latency—the time from sensing an event in the physical world to actuating a response—is a critical performance metric dictated by the underlying reference architecture. This practice  challenges you to deconstruct a layered architecture, calculate its worst-case latency budget by identifying the critical path, and then connect this delay to a fundamental constraint on the twin's ability to stabilize and control the physical system.",
            "id": "4215319",
            "problem": "In the context of a layered Digital Twin reference architecture consistent with the Industrial Internet Reference Architecture (IIRA) and the Reference Architecture Model for Industrie 4.0 (RAMI 4.0), consider an end-to-end closed-loop path that spans the following layers: physical device sensing, communication uplink, edge pre-processing, platform ingestion, analytics, fusion, application decision logic, communication downlink, and actuation. The analytics layer comprises two branches that execute concurrently: a physics-based model and a data-driven model accelerated by a Graphics Processing Unit (GPU). The platform layer employs an event-stream micro-batcher that releases frames at fixed intervals. Assume that each layer exhibits deterministic service time and that the event stream is always backlogged such that the worst-case waiting time due to micro-batching must be included in the end-to-end latency budget. The fusion stage waits for both analytics branches to complete before proceeding.\n\nThe following per-layer deterministic delays are given, expressed as service or enforced waiting times in milliseconds: device sensing delay $t_{\\text{sense}} = 2$, uplink communication delay $t_{\\text{up}} = 5$, edge pre-processing delay $t_{\\text{edge}} = 3$, platform micro-batch interval (worst-case waiting time) $T_{\\text{batch}} = 10$, platform ingestion delay $t_{\\text{plat}} = 4$, physics-based analytics branch delay $t_{\\text{phys}} = 7$, data-driven analytics branch delay $t_{\\text{ml}} = 11$, fusion delay $t_{\\text{fuse}} = 2$, application decision logic delay $t_{\\text{app}} = 1.5$, downlink communication delay $t_{\\text{down}} = 5$, and actuation delay $t_{\\text{act}} = 2.5$.\n\nStarting from core definitions in real-time systems and feedback control, treat the end-to-end latency budget $L$ as the worst-case time from sensing to actuation along the critical path, accounting for pipeline parallelism by modeling the analytics stage as a fork-join where its effective service time equals the maximum of the branch service times. Then, derive how the computed $L$ constrains the achievable closed-loop bandwidth when the twin is used for real-time feedback. Specifically, for a required phase margin $\\phi_{m} = \\pi/4$ and a loop where the dominant additional phase lag is the transport-delay induced by $L$, determine the maximal crossover angular frequency $\\omega_{c}^{\\max}$ in radians per second that is conservatively admissible such that the delay does not consume the entire phase margin.\n\nCompute the worst-case end-to-end latency $L$ in milliseconds, and the maximal admissible crossover angular frequency $\\omega_{c}^{\\max}$ in radians per second. Express $L$ in milliseconds. Express $\\omega_{c}^{\\max}$ in radians per second and round your answer for $\\omega_{c}^{\\max}$ to four significant figures. Provide your final answer as a two-entry row, with the first entry being $L$ (in milliseconds) and the second entry being $\\omega_{c}^{\\max}$ (in radians per second).",
            "solution": "The user wants to solve a two-part problem related to the real-time performance of a Digital Twin.\n\n**Part 1: Calculation of Worst-Case End-to-End Latency ($L$)**\n\nThe problem defines the end-to-end closed-loop path as a series of stages with deterministic delays. The total latency, $L$, is the worst-case time from sensing to actuation. This corresponds to the sum of delays along the critical path. The architecture specifies that the analytics layer consists of two parallel branches, and the subsequent fusion stage must wait for both to complete. This is a classic \"fork-join\" parallelism model. The effective delay of such a parallel stage is determined by the longest-running branch (the critical path).\n\nThe delays of the two analytics branches are given as:\n- Physics-based analytics branch delay: $t_{\\text{phys}} = 7$ ms\n- Data-driven analytics branch delay: $t_{\\text{ml}} = 11$ ms\n\nThe effective service time of the analytics stage, denoted as $t_{\\text{analytics}}$, is the maximum of these two values:\n$$t_{\\text{analytics}} = \\max(t_{\\text{phys}}, t_{\\text{ml}}) = \\max(7, 11) = 11 \\text{ ms}$$\n\nThe total end-to-end latency $L$ is the sum of the delays of all stages in sequence. The critical path includes the longer of the two analytics branches. The stages are: device sensing ($t_{\\text{sense}}$), uplink communication ($t_{\\text{up}}$), edge pre-processing ($t_{\\text{edge}}$), platform micro-batch waiting time ($T_{\\text{batch}}$), platform ingestion ($t_{\\text{plat}}$), analytics ($t_{\\text{analytics}}$), fusion ($t_{\\text{fuse}}$), application decision logic ($t_{\\text{app}}$), downlink communication ($t_{\\text{down}}$), and actuation ($t_{\\text{act}}$).\n\nThe total latency $L$ is therefore:\n$$L = t_{\\text{sense}} + t_{\\text{up}} + t_{\\text{edge}} + T_{\\text{batch}} + t_{\\text{plat}} + t_{\\text{analytics}} + t_{\\text{fuse}} + t_{\\text{app}} + t_{\\text{down}} + t_{\\text{act}}$$\n\nSubstituting the given values in milliseconds:\n$$L = 2 + 5 + 3 + 10 + 4 + 11 + 2 + 1.5 + 5 + 2.5$$\n$$L = 46 \\text{ ms}$$\n\n**Part 2: Calculation of Maximal Admissible Crossover Angular Frequency ($\\omega_{c}^{\\max}$)**\n\nThe second part of the problem relates the total latency $L$ to the stability of a real-time feedback control loop. The latency $L$ is modeled as a pure transport delay. In the Laplace domain, a transport delay has the transfer function $G_d(s) = \\exp(-sL)$.\n\nTo analyze the effect on stability in the frequency domain, we substitute $s = j\\omega$, where $j$ is the imaginary unit and $\\omega$ is the angular frequency.\n$$G_d(j\\omega) = \\exp(-j\\omega L)$$\n\nAccording to Euler's formula, $\\exp(-j\\theta) = \\cos(\\theta) - j\\sin(\\theta)$, which has a magnitude of $1$ and a phase angle of $-\\theta$. Therefore, the transport delay introduces a frequency-dependent phase lag, $\\Delta\\phi(\\omega)$, given by:\n$$\\Delta\\phi(\\omega) = -\\omega L$$\n\nThe phase margin, $\\phi_m$, is a measure of a system's stability, defined at the gain crossover frequency, $\\omega_c$ (where the open-loop gain is unity). The problem requires a phase margin of at least $\\phi_m = \\pi/4$ radians. The problem states that the phase lag from the transport delay is the dominant additional lag and should not consume the entire phase margin. This establishes a conservative limit for stable operation. The phase lag induced by the delay at the crossover frequency, $|\\Delta\\phi(\\omega_c)| = \\omega_c L$, must be less than or equal to the required phase margin $\\phi_m$.\n$$\\omega_c L \\le \\phi_m$$\n\nTo find the maximal admissible crossover frequency, $\\omega_{c}^{\\max}$, we solve for the equality condition:\n$$\\omega_{c}^{\\max} L = \\phi_m$$\n$$\\omega_{c}^{\\max} = \\frac{\\phi_m}{L}$$\n\nWe must use consistent units. The latency $L$ was calculated in milliseconds, so it must be converted to seconds for this calculation. The phase margin $\\phi_m$ is already given in radians, and the resulting frequency $\\omega_c^{\\max}$ will be in radians per second.\n- $L = 46 \\text{ ms} = 46 \\times 10^{-3} \\text{ s}$\n- $\\phi_m = \\frac{\\pi}{4}$ radians\n\nSubstituting these values into the equation:\n$$\\omega_{c}^{\\max} = \\frac{\\frac{\\pi}{4}}{46 \\times 10^{-3}} = \\frac{\\pi}{4 \\times 46 \\times 10^{-3}} = \\frac{\\pi}{184 \\times 10^{-3}} = \\frac{1000\\pi}{184}$$\n$$\\omega_{c}^{\\max} = \\frac{125\\pi}{23} \\text{ rad/s}$$\n\nNow, we compute the numerical value and round to four significant figures as requested.\n$$\\omega_{c}^{\\max} \\approx \\frac{125 \\times 3.14159265}{23} \\approx 17.07387... \\text{ rad/s}$$\n\nRounding to four significant figures, we get:\n$$\\omega_{c}^{\\max} \\approx 17.07 \\text{ rad/s}$$\n\nThe two computed values are $L=46$ ms and $\\omega_{c}^{\\max} \\approx 17.07$ rad/s.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n46 & 17.07\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Assessing the overall capability of a Digital Twin program requires evaluating multiple, disparate dimensions, from model fidelity to data governance. A quantitative maturity model provides a structured way to perform this assessment, but it requires a scientifically sound method to aggregate heterogeneous metrics into a single, meaningful score. This final practice  walks you through the essential steps of normalization and weighted aggregation, demonstrating how to transform raw performance data from various architectural layers into a defensible, unified maturity score.",
            "id": "4215324",
            "problem": "A systems engineering team is evaluating the maturity of a Digital Twin (DT) program for a complex Cyber-Physical System (CPS) against a reference architecture that partitions capability into eight dimensions. To construct a quantitative maturity model, the team must use an additive, weighted rubric that is scientifically defensible from the standpoint of multi-attribute measurement. The team collects raw architectural metrics for each dimension, each with physically meaningful units or bounded scores, and will convert these raw metrics into dimensionless, normalized scores before aggregation. The evaluation context and data are as follows.\n\nDimensions and raw metrics:\n- Data interoperability coverage: fraction of canonical model mappings implemented, raw value $x_{1}=0.78$, bounded on $[0,1]$, larger is better.\n- Model fidelity: root-mean-square error (RMSE) of state estimates in millimeters, raw value $x_{2}=3.2$ with target range $[0,10]$ millimeters, where smaller is better.\n- Synchronization latency: median DT-to-physical synchronization latency in milliseconds, raw value $x_{3}=55$ with target range $[0,200]$ milliseconds, where smaller is better.\n- Security and governance: compliance score on a $0$ to $5$ audit scale, raw value $x_{4}=4.0$, larger is better.\n- Lifecycle integration: number of supported lifecycle stages out of $8$ defined stages, raw value $x_{5}=6$, larger is better; the range is $[0,8]$ stages.\n- Analytics and decision support: predictive model quality measured as an $\\mathrm{F1}$ score on $[0,1]$, raw value $x_{6}=0.67$, larger is better.\n- Scalability: throughput ratio at $10\\times$ load relative to baseline, raw value $x_{7}=7.5$, bounded on $[0,10]$, larger is better.\n- Standards compliance coverage: ratio of applicable standards requirements satisfied, raw value $x_{8}=0.62$, bounded on $[0,1]$, larger is better.\n\nWeights for the rubric are assigned by architecture-criticality and sum to one:\n$$\nw_{1}=0.18,\\quad\nw_{2}=0.14,\\quad\nw_{3}=0.12,\\quad\nw_{4}=0.16,\\quad\nw_{5}=0.12,\\quad\nw_{6}=0.10,\\quad\nw_{7}=0.10,\\quad\nw_{8}=0.08.\n$$\n\nTasks:\n1. Using a scientifically grounded normalization that produces dimensionless scores $s_{i}\\in[0,1]$ and preserves the monotonicity of each metric with respect to maturity (that is, larger raw values should map to larger $s_{i}$ when larger is better, and larger raw values should map to smaller $s_{i}$ when smaller is better), construct $s_{i}$ for all eight dimensions from the given $x_{i}$ and their ranges.\n2. Aggregate the normalized scores using a principled weighted additive model consistent with the requirements of multi-attribute utility for commensurate scales to produce a single overall maturity score $M$.\n3. Briefly explain, from first principles of measurement, how normalization affects comparability across heterogeneous units and scales in this maturity assessment, and why the chosen normalization is appropriate in this context.\n\nRound the final overall maturity score to four significant figures. Express the final answer as a unitless decimal without a percentage sign.",
            "solution": "The problem is deemed valid as it is scientifically grounded in multi-attribute measurement theory, well-posed with all necessary data provided, and objective in its formulation. All data and constraints are self-contained and consistent.\n\nThe solution is divided into three parts as requested by the problem statement.\n\n### 1. Construction of Normalized Scores\n\nTo create a scientifically defensible rubric, the raw metrics $x_i$, which possess heterogeneous units and scales, must be transformed into dimensionless scores $s_i$ on a commensurate scale. The most direct and objective method, given the problem's constraints, is linear min-max normalization. This method maps each raw value to a score on the interval $[0, 1]$, where $s_i = 0$ represents the worst possible outcome and $s_i = 1$ represents the best possible outcome.\n\nThere are two cases for this transformation, depending on whether a larger or smaller raw value is preferable.\n\nCase A: For \"larger is better\" metrics, the normalized score $s_i$ is calculated as:\n$$s_i = \\frac{x_i - x_{i, \\text{min}}}{x_{i, \\text{max}} - x_{i, \\text{min}}}$$\nwhere $x_i$ is the raw value, and $x_{i, \\text{min}}$ and $x_{i, \\text{max}}$ are the minimum and maximum values of the metric's defined range, respectively.\n\nCase B: For \"smaller is better\" metrics, the relationship is inverted to ensure $s_i=1$ corresponds to the best outcome (the minimum raw value). The normalized score $s_i$ is calculated as:\n$$s_i = \\frac{x_{i, \\text{max}} - x_i}{x_{i, \\text{max}} - x_{i, \\text{min}}}$$\n\nWe apply these formulae to each of the eight dimensions:\n\n- **Dimension 1 (Data interoperability):** $x_1 = 0.78$, range $[0, 1]$, larger is better.\n$$s_1 = \\frac{0.78 - 0}{1 - 0} = 0.78$$\n\n- **Dimension 2 (Model fidelity):** $x_2 = 3.2$ mm, range $[0, 10]$ mm, smaller is better.\n$$s_2 = \\frac{10 - 3.2}{10 - 0} = \\frac{6.8}{10} = 0.68$$\n\n- **Dimension 3 (Synchronization latency):** $x_3 = 55$ ms, range $[0, 200]$ ms, smaller is better.\n$$s_3 = \\frac{200 - 55}{200 - 0} = \\frac{145}{200} = 0.725$$\n\n- **Dimension 4 (Security and governance):** $x_4 = 4.0$, range $[0, 5]$, larger is better.\n$$s_4 = \\frac{4.0 - 0}{5.0 - 0} = 0.8$$\n\n- **Dimension 5 (Lifecycle integration):** $x_5 = 6$, range $[0, 8]$, larger is better.\n$$s_5 = \\frac{6 - 0}{8 - 0} = 0.75$$\n\n- **Dimension 6 (Analytics and decision support):** $x_6 = 0.67$, range $[0, 1]$, larger is better.\n$$s_6 = \\frac{0.67 - 0}{1 - 0} = 0.67$$\n\n- **Dimension 7 (Scalability):** $x_7 = 7.5$, range $[0, 10]$, larger is better.\n$$s_7 = \\frac{7.5 - 0}{10 - 0} = 0.75$$\n\n- **Dimension 8 (Standards compliance):** $x_8 = 0.62$, range $[0, 1]$, larger is better.\n$$s_8 = \\frac{0.62 - 0}{1 - 0} = 0.62$$\n\n### 2. Aggregation into a Single Maturity Score\n\nThe problem specifies a principled weighted additive model, which is a standard method in Multi-Attribute Utility Theory (MAUT). The overall maturity score, $M$, is the weighted sum of the individual normalized scores $s_i$. The weights $w_i$ represent the relative importance of each dimension, and their sum is $\\sum_{i=1}^{8} w_i = 1$.\n\nThe formula for the overall maturity score $M$ is:\n$$M = \\sum_{i=1}^{8} w_i s_i$$\n\nSubstituting the given weights and the calculated normalized scores:\n$$M = w_1 s_1 + w_2 s_2 + w_3 s_3 + w_4 s_4 + w_5 s_5 + w_6 s_6 + w_7 s_7 + w_8 s_8$$\n$$M = (0.18)(0.78) + (0.14)(0.68) + (0.12)(0.725) + (0.16)(0.8) + (0.12)(0.75) + (0.10)(0.67) + (0.10)(0.75) + (0.08)(0.62)$$\n$$M = 0.1404 + 0.0952 + 0.0870 + 0.1280 + 0.0900 + 0.0670 + 0.0750 + 0.0496$$\n$$M = 0.7322$$\n\nThe problem requires the final score to be rounded to four significant figures. The calculated value $0.7322$ already has four significant figures.\n\n### 3. Explanation of Normalization in Measurement\n\nFrom the first principles of measurement, aggregating quantities requires them to be dimensionally homogeneous. The raw architectural metrics ($x_i$) are dimensionally heterogeneous, possessing different units (e.g., millimeters, milliseconds, audit points) and scales (e.g., $[0, 10]$ vs. $[0, 200]$). Directly summing these quantities, even with weighting, is mathematically and physically meaningless—it is akin to adding length and time. The result would be numerically dominated by metrics with a large range magnitude (e.g., latency) regardless of their assigned importance, violating the principle of a weighted rubric.\n\nNormalization addresses this fundamental problem by transforming each raw measurement into a dimensionless value on a common, commensurate scale, here $[0, 1]$. This new scale represents the degree of achievement or \"utility\" for each dimension, where $0$ is the worst performance and $1$ is the ideal goal. By making the scales commensurate, the weighted sum becomes a valid mathematical operation. The weights $w_i$ can now be correctly interpreted as the relative importance of achieving maximal utility in each dimension.\n\nThe chosen linear min-max normalization method is appropriate in this context for several reasons. First, it is a simple, transparent, and deterministic transformation. Second, it correctly preserves the monotonicity of each metric with respect to maturity, handling both \"larger is better\" and \"smaller is better\" cases. Third, it assumes a linear relationship between the raw metric and its utility. In the absence of evidence for non-linear preferences (such as diminishing returns), assuming linearity is the most parsimonious and objective approach, consistent with the requirements for a scientifically defensible model. This normalization step is the essential precondition that makes the additive aggregation of scores a valid and meaningful procedure.",
            "answer": "$$ \\boxed{0.7322} $$"
        }
    ]
}