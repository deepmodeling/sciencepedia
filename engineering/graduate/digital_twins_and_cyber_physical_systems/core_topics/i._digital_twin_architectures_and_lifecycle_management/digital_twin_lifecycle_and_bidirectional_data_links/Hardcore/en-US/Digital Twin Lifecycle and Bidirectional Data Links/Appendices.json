{
    "hands_on_practices": [
        {
            "introduction": "A critical first step in designing a digital twin architecture is ensuring the data link can handle the volume of telemetry from physical assets. This exercise  provides hands-on practice in calculating the maximum data rate by applying first principles of information flow, accounting for data aggregation from multiple sources and the effects of edge compression. Mastering this type of capacity planning is a fundamental skill for designing robust and scalable cyber-physical systems.",
            "id": "4214308",
            "problem": "A cyber-physical production line is mirrored by a cloud-hosted digital twin. During the operation and maintenance phases of the digital twin lifecycle, each physical asset streams telemetry to the edge, which pre-processes and compresses the data before forwarding it to the cloud. Consider a deployment with $N=100$ identical assets. Each asset emits a raw telemetry stream at a constant rate $r$ kilobits per second. The edge performs lossless compression with a compression ratio of $4:1$, meaning the compressed bit rate equals the uncompressed bit rate divided by $4$. The edge-to-cloud uplink has a fixed bottleneck capacity of $B_{\\uparrow}=5\\,\\mathrm{Mbps}$ dedicated to compressed telemetry, while the cloud-to-edge downlink has capacity $B_{\\downarrow}=10\\,\\mathrm{Mbps}$ used for control and model updates, which are negligible for the capacity budget in this scenario. Assume long-run flow conservation, no protocol overhead, and that all assets are scheduled fairly so that the per-asset rate is equal in steady state.\n\nStarting from first principles (conservation of information rate across the compression and link layers and the definition of compression ratio), derive the maximum feasible raw telemetry rate per asset, $r_{\\max}$, consistent with the uplink constraint. Then evaluate $r_{\\max}$ numerically for the given parameters. Express your final answer in kilobits per second (kbps). No rounding is required beyond exact arithmetic.",
            "solution": "The problem is deemed valid as it is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. The derivation proceeds from first principles.\n\nLet $N$ be the number of identical assets, $r$ be the raw telemetry rate per asset in kilobits per second (kbps), and $C$ be the compression factor. The problem states there are $N=100$ assets.\n\nThe first principle is the definition of the compression ratio. A compression ratio of $4:1$ implies that the size of the compressed data is $1/4$ the size of the uncompressed data. For data rates, this means the compressed bit rate is $1/4$ of the raw bit rate. The compression factor is therefore $C=4$. The compressed telemetry rate for a single asset, denoted $r_c$, is given by:\n$$r_c = \\frac{r}{C}$$\n\nThe second principle is the aggregation of data streams. Assuming fair scheduling, all assets contribute equally to the total data stream. The total compressed telemetry rate from all $N$ assets, denoted $R_{c, total}$, is the sum of the individual compressed rates:\n$$R_{c, total} = \\sum_{i=1}^{N} r_{c,i} = N \\times r_c$$\nSubstituting the expression for $r_c$:\n$$R_{c, total} = N \\times \\frac{r}{C}$$\n\nThe third principle is the capacity constraint, which is an application of the principle of flow conservation. For the system to operate without data loss or unbounded queuing delays, the total aggregated rate of data sent to the cloud must not exceed the capacity of the uplink. Let $B_{\\uparrow}$ be the uplink capacity. The constraint is:\n$$R_{c, total} \\le B_{\\uparrow}$$\n\nThe problem asks for the maximum feasible raw telemetry rate per asset, $r_{\\max}$. This maximum rate is achieved when the system fully utilizes the available uplink capacity, which corresponds to the case where the inequality becomes an equality:\n$$N \\times \\frac{r_{\\max}}{C} = B_{\\uparrow}$$\n\nWe can now solve this equation for $r_{\\max}$ to obtain a general symbolic expression:\n$$r_{\\max} = \\frac{B_{\\uparrow} \\times C}{N}$$\n\nNext, we evaluate this expression numerically using the given parameters. The parameters are:\n- Number of assets, $N = 100$.\n- Compression factor, $C = 4$.\n- Uplink capacity, $B_{\\uparrow} = 5\\,\\mathrm{Mbps}$.\n\nA critical step is to ensure unit consistency. The desired unit for $r_{\\max}$ is kilobits per second (kbps). The uplink capacity $B_{\\uparrow}$ is given in megabits per second (Mbps). We use the conversion $1\\,\\mathrm{Mbps} = 1000\\,\\mathrm{kbps}$.\n$$B_{\\uparrow} = 5\\,\\mathrm{Mbps} = 5 \\times 1000\\,\\mathrm{kbps} = 5000\\,\\mathrm{kbps}$$\n\nNow, we substitute the numerical values into the derived expression for $r_{\\max}$:\n$$r_{\\max} = \\frac{(5000\\,\\mathrm{kbps}) \\times 4}{100}$$\n$$r_{\\max} = \\frac{20000}{100}\\,\\mathrm{kbps}$$\n$$r_{\\max} = 200\\,\\mathrm{kbps}$$\n\nThe maximum feasible raw telemetry rate per asset is $200$ kbps. The information about the downlink capacity, $B_{\\downarrow}=10\\,\\mathrm{Mbps}$, is extraneous to this calculation, as the problem states that its usage is negligible for the capacity budget.",
            "answer": "$$\\boxed{200}$$"
        },
        {
            "introduction": "Beyond sheer data volume, the timeliness of data exchange is paramount, especially when the digital twin participates in a closed control loop. This problem  guides you through a statistical analysis of network latency, a key performance indicator for the bidirectional data link. By modeling latency as a random variable and evaluating its quantiles against a Service Level Objective (SLO), you will practice a standard and essential method for guaranteeing system responsiveness and safety during the operational phase.",
            "id": "4214327",
            "problem": "A cyber-physical production cell exposes its operational state to a high-fidelity Digital Twin via a bidirectional data link. In the operational phase of the digital twin lifecycle, the closed-loop controller in the twin issues control commands and receives acknowledgments and sensor frames from the physical asset, with end-to-end round-trip latency defined as the time between command emission and acknowledgment receipt. To guarantee safe supervisory control, the system owner specifies a Service Level Objective (SLO) such that the $0.99$-quantile of round-trip latency must not exceed $30$ ms.\n\nAfter deployment stabilization, an instrumentation campaign produces latency samples whose distribution is well-modeled as a Gaussian (normal) random variable with mean $15$ ms and standard deviation $5$ ms, reflecting the aggregate effects of serialization delay, propagation delay, and queuing jitter under the current load.\n\nUsing foundational definitions of quantiles and the cumulative distribution function, and assuming the latency $X$ is normal with parameters $\\mu$ and $\\sigma$, determine the $0.99$-quantile of $X$ and compute the SLO margin $\\Delta = L_{\\mathrm{SLO}} - q_{0.99}$, where $L_{\\mathrm{SLO}}$ is the SLO threshold and $q_{0.99}$ is the $0.99$-quantile. Interpret $\\Delta > 0$ as meeting the SLO and $\\Delta  0$ as violating the SLO.\n\nRound your final value of $\\Delta$ to four significant figures. Express the final value in milliseconds.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n-   System: A cyber-physical production cell with a Digital Twin.\n-   Data link type: Bidirectional.\n-   Digital TwinLifecycle Phase: Operational phase.\n-   Latency Definition: End-to-end round-trip latency, defined as the time between command emission and acknowledgment receipt.\n-   Service Level Objective (SLO): The $0.99$-quantile of round-trip latency must not exceed $30$ ms. This defines the SLO threshold, $L_{\\mathrm{SLO}} = 30$ ms.\n-   Latency Distribution: The latency, denoted as a random variable $X$, is modeled as a Gaussian (normal) distribution.\n-   Distribution Parameters: Mean $\\mu = 15$ ms and standard deviation $\\sigma = 5$ ms. So, $X \\sim \\mathcal{N}(15, 5^2)$.\n-   Objective 1: Determine the $0.99$-quantile of $X$, denoted as $q_{0.99}$.\n-   Objective 2: Compute the SLO margin $\\Delta = L_{\\mathrm{SLO}} - q_{0.99}$.\n-   Interpretation: $\\Delta > 0$ implies the SLO is met; $\\Delta  0$ implies the SLO is violated.\n-   Final Answer Specification: Round the final value of $\\Delta$ to four significant figures and express it in milliseconds.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is based on standard principles of probability theory and statistics, specifically the properties of the normal distribution and the definition of quantiles. Applying these concepts to model system latency and evaluate against a Service Level Objective is a standard and valid practice in systems engineering and computer science.\n-   **Well-Posed**: The problem is clearly defined with all necessary parameters ($\\mu$, $\\sigma$, $L_{\\mathrm{SLO}}$, and the quantile level $0.99$) provided. The objective is unambiguous, leading to a unique, stable, and meaningful solution.\n-   **Objective**: The problem uses precise, standard terminology from statistics and engineering without any subjective or opinion-based statements.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, missing information, or unrealistic assumptions. The provided values for mean and standard deviation of latency are plausible for an industrial control network.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A complete, reasoned solution will be provided.\n\n### Solution\nLet the round-trip latency be a random variable $X$. According to the problem statement, $X$ follows a normal (Gaussian) distribution with mean $\\mu = 15$ ms and standard deviation $\\sigma = 5$ ms. We can write this as $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, where $\\mu = 15$ and $\\sigma = 5$.\n\nThe primary goal is to find the $0.99$-quantile of this distribution, which we denote as $q_{0.99}$. By definition, the $p$-quantile of a continuous random variable is the value $x_p$ such that the probability of the variable being less than or equal to $x_p$ is $p$. Mathematically, this is expressed using the cumulative distribution function (CDF), $F_X(x)$, as $F_X(x_p) = P(X \\le x_p) = p$.\n\nFor our problem, we need to find the value $q_{0.99}$ such that:\n$$P(X \\le q_{0.99}) = 0.99$$\nTo solve this for a general normal distribution, we first standardize the random variable $X$. We define a new random variable $Z$ as:\n$$Z = \\frac{X - \\mu}{\\sigma}$$\n$Z$ follows the standard normal distribution, $Z \\sim \\mathcal{N}(0, 1)$. The CDF of $Z$ is typically denoted by $\\Phi(z)$.\n\nWe can rewrite the probability expression in terms of $Z$:\n$$P\\left(\\frac{X - \\mu}{\\sigma} \\le \\frac{q_{0.99} - \\mu}{\\sigma}\\right) = 0.99$$\n$$P\\left(Z \\le \\frac{q_{0.99} - \\mu}{\\sigma}\\right) = 0.99$$\nLet $z_{0.99}$ be the $0.99$-quantile of the standard normal distribution. This is the value such that $P(Z \\le z_{0.99}) = \\Phi(z_{0.99}) = 0.99$. The value $z_{0.99}$ can be found from standard statistical tables or by using the inverse CDF of the standard normal distribution, $z_{0.99} = \\Phi^{-1}(0.99)$.\nFrom the equation above, we have:\n$$\\frac{q_{0.99} - \\mu}{\\sigma} = z_{0.99}$$\nSolving for $q_{0.99}$, we obtain the expression:\n$$q_{0.99} = \\mu + z_{0.99} \\sigma$$\nThe value of $z_{0.99}$ is a standard constant in statistics, approximately $z_{0.99} \\approx 2.326348$. Now, we can substitute the given values for $\\mu$ and $\\sigma$:\n$$\\mu = 15$$\n$$\\sigma = 5$$\n$$q_{0.99} \\approx 15 + (2.326348)(5)$$\n$$q_{0.99} \\approx 15 + 11.63174$$\n$$q_{0.99} \\approx 26.63174 \\text{ ms}$$\nThis value represents the latency that is exceeded only $1\\%$ of the time.\n\nThe next step is to compute the SLO margin, $\\Delta$, which is defined as the difference between the SLO threshold, $L_{\\mathrm{SLO}}$, and the calculated $0.99$-quantile, $q_{0.99}$:\n$$\\Delta = L_{\\mathrm{SLO}} - q_{0.99}$$\nThe problem states that the SLO threshold is $L_{\\mathrm{SLO}} = 30$ ms.\n$$\\Delta \\approx 30 - 26.63174$$\n$$\\Delta \\approx 3.36826 \\text{ ms}$$\nSince $\\Delta > 0$, the system is meeting its Service Level Objective.\n\nFinally, the problem requires rounding the value of $\\Delta$ to four significant figures. The calculated value is $3.36826\\dots$.\nThe first four significant figures are $3$, $3$, $6$, and $8$. The fifth significant figure is $2$. Since $2  5$, we round down, which means we keep the fourth significant digit as it is.\nTherefore, the rounded value of $\\Delta$ is $3.368$.",
            "answer": "$$\n\\boxed{3.368}\n$$"
        },
        {
            "introduction": "Once data flows reliably between the physical asset and its digital twin, the twin can perform sophisticated analysis to monitor the system's health. This advanced practice  involves implementing a data-driven anomaly detection system using Principal Component Analysis (PCA), a powerful technique for modeling complex operational behavior. You will learn to compute and apply statistically-grounded monitoring statistics (Hotelling’s $T^2$ and Squared Prediction Error) to flag deviations, a core function enabling predictive maintenance and intelligent operational oversight.",
            "id": "4214271",
            "problem": "A Digital Twin (DT) of a Cyber-Physical System (CPS) uses Principal Component Analysis (PCA) to monitor normal operation via a bidirectional data link, and flags anomalies when new data deviate from the learned latent structure. Assume the training data are independent and identically distributed samples from a multivariate normal distribution with mean vector $\\mu$ and covariance matrix $\\Sigma$. The learned PCA model is obtained by the eigen-decomposition of the sample covariance matrix computed from training data. For a new centered sample $x_c = x - \\hat{\\mu}$, two monitoring statistics are defined: the Hotelling’s $T^2$ statistic in the retained principal subspace and the Squared Prediction Error (SPE, also called the $Q$-statistic) in the residual subspace. Using well-tested formulas, define both limits at the $99\\%$ level and determine whether the new sample is anomalous with respect to each statistic.\n\nFundamental base:\n- The training data matrix $X \\in \\mathbb{R}^{N \\times p}$ is modeled as samples from a multivariate normal $\\mathcal{N}(\\mu, \\Sigma)$.\n- The sample mean is $\\hat{\\mu} = \\frac{1}{N} \\sum_{i=1}^{N} x_i$.\n- The unbiased sample covariance matrix is $S = \\frac{1}{N - 1} \\sum_{i=1}^{N} (x_i - \\hat{\\mu})(x_i - \\hat{\\mu})^\\top$.\n- The eigen-decomposition of $S$ is $S = P \\Lambda P^\\top$, where $P \\in \\mathbb{R}^{p \\times p}$ is orthonormal and $\\Lambda = \\operatorname{diag}(\\lambda_1, \\dots, \\lambda_p)$ with $\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_p \\ge 0$.\n- For a retained dimension $A$ with $A  p$, define $P_A \\in \\mathbb{R}^{p \\times A}$ and $\\Lambda_A = \\operatorname{diag}(\\lambda_1, \\dots, \\lambda_A)$, and the residual eigenvalues $\\{\\lambda_{A+1}, \\dots, \\lambda_p\\}$.\n\nMonitoring statistics:\n- The score vector in the retained subspace is $t = P_A^\\top x_c$. The Hotelling’s $T^2$ statistic is\n$$\nT^2 = t^\\top \\Lambda_A^{-1} t = \\sum_{a=1}^A \\frac{t_a^2}{\\lambda_a}.\n$$\n- The reconstruction error is $e = x_c - P_A P_A^\\top x_c$. The Squared Prediction Error is\n$$\n\\mathrm{SPE} = \\|e\\|_2^2 = e^\\top e.\n$$\n\nControl limits at the $99\\%$ level:\n- Under the finite-sample setting with unknown covariance estimated from $N$ training samples, the Hotelling’s $T^2$ control limit uses the $F$-distribution, given by\n$$\nT^2_{\\text{lim}}(0.99) = \\frac{A(N - 1)}{N - A} F_{A,\\, N - A}(0.99),\n$$\nwhere $F_{A, N - A}(0.99)$ is the $0.99$ quantile of the $F$-distribution with degrees of freedom $A$ and $N - A$.\n- The Squared Prediction Error limit uses the Jackson–Mudholkar approximation. Let\n$$\n\\theta_1 = \\sum_{i=A+1}^{p} \\lambda_i,\\quad\n\\theta_2 = \\sum_{i=A+1}^{p} \\lambda_i^2,\\quad\n\\theta_3 = \\sum_{i=A+1}^{p} \\lambda_i^3,\n$$\nand \n$$\nh_0 = 1 - \\frac{2\\theta_1 \\theta_3}{3 \\theta_2^2}.\n$$\nIf $\\theta_2  0$, the $99\\%$ limit is\n$$\nQ_{\\text{lim}}(0.99) = \\theta_1 \\left( \\frac{z_{0.99}\\, \\sqrt{2 \\theta_2}\\, h_0}{\\theta_1} + 1 + \\frac{\\theta_2 h_0 (h_0 - 1)}{\\theta_1^2} \\right)^{1/h_0},\n$$\nwhere $z_{0.99}$ is the $0.99$ quantile of the standard normal distribution.\n\nYour task:\n- Implement a complete program that, for each test case, computes the PCA model from the provided training data matrix, evaluates the Hotelling’s $T^2$ and $\\mathrm{SPE}$ statistics for the given new data sample, compares them to the $99\\%$ limits, and outputs anomaly flags: $T^2  T^2_{\\text{lim}}(0.99)$ and $\\mathrm{SPE}  Q_{\\text{lim}}(0.99)$.\n- The final outputs for each test case must be booleans. No physical units are needed.\n- The program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case yields a two-element list $[T2\\_flag, SPE\\_flag]$, and the overall output collects these lists in order. For example: $[[\\text{True},\\text{False}],[\\text{False},\\text{False}]]$.\n\nTest suite:\n- Test case $1$ (happy path): $N = 12$, $p = 3$, $A = 2$. Training data matrix\n$$\nX_1 = \\begin{bmatrix}\n1.0  0.5  1.3\\\\\n0.8  0.7  1.1\\\\\n1.1  0.6  1.4\\\\\n0.9  0.4  1.2\\\\\n1.2  0.9  1.7\\\\\n1.0  0.8  1.5\\\\\n0.7  0.5  1.0\\\\\n1.3  0.7  1.8\\\\\n0.9  0.6  1.2\\\\\n1.1  0.5  1.4\\\\\n0.8  0.4  1.0\\\\\n1.2  0.8  1.6\n\\end{bmatrix},\\quad\nx^{\\text{new}}_1 = \\begin{bmatrix} 1.8  0.2  2.5 \\end{bmatrix}.\n$$\n- Test case $2$ (boundary on retained dimension): $N = 10$, $p = 4$, $A = 1$. Training data matrix\n$$\nX_2 = \\begin{bmatrix}\n10.0  9.8  0.2  0.1\\\\\n9.7  9.6  0.1  0.2\\\\\n10.2  10.0  0.3  0.2\\\\\n9.9  9.7  0.2  0.3\\\\\n10.1  9.9  0.2  0.1\\\\\n9.8  9.7  0.1  0.2\\\\\n10.0  9.8  0.3  0.2\\\\\n9.9  9.6  0.2  0.3\\\\\n10.2  10.1  0.3  0.1\\\\\n9.7  9.6  0.1  0.2\n\\end{bmatrix},\\quad\nx^{\\text{new}}_2 = \\begin{bmatrix} 10.8  10.7  0.5  0.4 \\end{bmatrix}.\n$$\n- Test case $3$ (small-sample edge): $N = 6$, $p = 5$, $A = 2$. Training data matrix\n$$\nX_3 = \\begin{bmatrix}\n2.0  1.0  3.0  0.5  1.5\\\\\n1.8  1.1  2.9  0.6  1.4\\\\\n2.1  0.9  3.1  0.4  1.6\\\\\n1.9  1.0  3.0  0.5  1.6\\\\\n2.0  1.2  3.2  0.6  1.7\\\\\n1.8  0.8  2.8  0.4  1.4\n\\end{bmatrix},\\quad\nx^{\\text{new}}_3 = \\begin{bmatrix} 2.5  0.5  3.7  0.2  2.0 \\end{bmatrix}.\n$$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the exact format\n$$\n[[T2\\_1,SPE\\_1],[T2\\_2,SPE\\_2],[T2\\_3,SPE\\_3]],\n$$\nwhere each entry is either $\\text{True}$ or $\\text{False}$ as a boolean literal.",
            "solution": "We begin with the assumption that the training data matrix $X \\in \\mathbb{R}^{N \\times p}$ arises from a stable operating regime of the Digital Twin (DT) connected to its Cyber-Physical System (CPS) via a bidirectional data link. This assumption implies that the training data are samples drawn from a multivariate normal distribution $\\mathcal{N}(\\mu, \\Sigma)$, which is a standard foundation for Principal Component Analysis (PCA)-based monitoring. We compute the sample mean $\\hat{\\mu}$ and unbiased sample covariance $S$:\n$$\n\\hat{\\mu} = \\frac{1}{N} \\sum_{i=1}^{N} x_i,\\quad\nS = \\frac{1}{N - 1} \\sum_{i=1}^{N} (x_i - \\hat{\\mu})(x_i - \\hat{\\mu})^\\top.\n$$\nThe PCA model is obtained via eigen-decomposition of $S$:\n$$\nS = P \\Lambda P^\\top,\n$$\nwhere $P \\in \\mathbb{R}^{p \\times p}$ is orthonormal ($P^\\top P = I$), and $\\Lambda = \\operatorname{diag}(\\lambda_1,\\dots,\\lambda_p)$ contains eigenvalues ordered $\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_p \\ge 0$. We select the first $A$ principal components, denoted by $P_A$ and $\\Lambda_A$.\n\nFor any new observation $x$, we center it using the training mean: $x_c = x - \\hat{\\mu}$. The projection (score) on the retained subspace is\n$$\nt = P_A^\\top x_c,\n$$\nand the Hotelling’s $T^2$ statistic is the quadratic form\n$$\nT^2 = t^\\top \\Lambda_A^{-1} t = \\sum_{a=1}^{A} \\frac{t_a^2}{\\lambda_a}.\n$$\nThis arises from standardizing the scores by the variance captured by each principal component. The reconstruction of $x_c$ from the retained subspace is $P_A P_A^\\top x_c$, and the residual error is\n$$\ne = x_c - P_A P_A^\\top x_c.\n$$\nThe Squared Prediction Error (SPE or $Q$-statistic) is the squared norm of the residual:\n$$\n\\mathrm{SPE} = \\|e\\|_2^2 = e^\\top e.\n$$\nThese two statistics align with the latent-structure deviation ($T^2$) and the off-subspace deviation ($\\mathrm{SPE}$) in PCA-based monitoring.\n\nTo determine anomaly flags at the $99\\%$ level, we need control limits. For Hotelling’s $T^2$, one begins with the classical result that if the covariance were known, then $T^2$ would be distributed as a chi-square with $A$ degrees of freedom. However, because $\\Sigma$ is unknown and estimated from $N$ samples, the appropriate Phase I or Phase II limit uses the $F$-distribution:\n$$\nT^2_{\\text{lim}}(0.99) = \\frac{A(N - 1)}{N - A} F_{A,\\, N - A}(0.99),\n$$\nwhere $F_{A, N - A}(0.99)$ is the $0.99$ quantile of the $F$ distribution with $A$ and $N - A$ degrees of freedom. This incorporates the uncertainty from estimating $\\Sigma$ and yields a more accurate finite-sample bound.\n\nFor the SPE limit, we rely on the Jackson–Mudholkar approximation, which uses the moments of the residual eigenvalues $\\lambda_{A+1}, \\dots, \\lambda_p$:\n$$\n\\theta_1 = \\sum_{i=A+1}^{p} \\lambda_i,\\quad\n\\theta_2 = \\sum_{i=A+1}^{p} \\lambda_i^2,\\quad\n\\theta_3 = \\sum_{i=A+1}^{p} \\lambda_i^3.\n$$\nDefine\n$$\nh_0 = 1 - \\frac{2\\theta_1 \\theta_3}{3 \\theta_2^2}.\n$$\nWhen $\\theta_20$, the $99\\%$ control limit for the SPE is\n$$\nQ_{\\text{lim}}(0.99) = \\theta_1 \\left( \\frac{z_{0.99}\\, \\sqrt{2 \\theta_2}\\, h_0}{\\theta_1} + 1 + \\frac{\\theta_2 h_0 (h_0 - 1)}{\\theta_1^2} \\right)^{1/h_0},\n$$\nwhere $z_{0.99}$ is the standard normal $0.99$ quantile. This approximation is well-tested and widely used in PCA monitoring literature for residual-space detection.\n\nAlgorithmic steps that integrate these principles:\n1. Compute $\\hat{\\mu}$ and $S$ from each training matrix $X$ using the unbiased estimator.\n2. Perform eigen-decomposition $S = P \\Lambda P^\\top$ and sort eigenvalues and eigenvectors in descending order.\n3. Select $P_A$ and $\\Lambda_A$, and compute the centered new sample $x_c$.\n4. Compute scores $t = P_A^\\top x_c$ and Hotelling’s $T^2 = \\sum_{a=1}^A t_a^2/\\lambda_a$.\n5. Compute residual error $e = x_c - P_A P_A^\\top x_c$ and $\\mathrm{SPE} = e^\\top e$.\n6. Compute $T^2_{\\text{lim}}(0.99)$ using the $F$-distribution quantile with degrees of freedom $A$ and $N - A$:\n$$\nT^2_{\\text{lim}} = \\frac{A(N - 1)}{N - A} F_{A,\\,N - A}(0.99).\n$$\n7. Compute $Q_{\\text{lim}}(0.99)$ using $\\theta_1, \\theta_2, \\theta_3$, $h_0$, and $z_{0.99}$ as above. If $\\theta_2 = 0$, set $Q_{\\text{lim}}(0) = 0$ since the residual subspace has zero variance.\n8. Determine boolean anomaly flags:\n$$\n\\text{T2\\_flag} = [T^2  T^2_{\\text{lim}}(0.99)],\\quad\n\\text{SPE\\_flag} = [\\mathrm{SPE}  Q_{\\text{lim}}(0.99)].\n$$\n\nEdge-case considerations:\n- If $A = 0$, then $T^2 = 0$ and the limit is undefined; however, the test suite avoids $A=0$.\n- If $N \\le A$, the $F$-based limit cannot be computed due to degrees of freedom; the test suite maintains $N  A$.\n- If numerical small negative eigenvalues appear due to rounding, clip to a small non-negative value before using in denominators.\n\nImplementation:\n- Use the provided matrices $X_1$, $X_2$, $X_3$, their respective $A$, and new samples $x^{\\text{new}}_1$, $x^{\\text{new}}_2$, $x^{\\text{new}}_3$.\n- Compute and aggregate the boolean flags for each test case into the single-line output in the exact required format.\n\nThis approach grounds anomaly detection in PCA on statistically justified thresholds, suitable for advanced-graduate level analysis of digital twin lifecycle monitoring and bidirectional data links in cyber-physical systems.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import f, norm\n\ndef pca_anomaly_flags(X_train, x_new, A, alpha=0.99):\n    \"\"\"\n    Compute PCA from training data, evaluate Hotelling's T^2 and SPE for x_new,\n    and return boolean anomaly flags at the given alpha level.\n    \"\"\"\n    X = np.array(X_train, dtype=float)\n    x = np.array(x_new, dtype=float)\n    N, p = X.shape\n\n    # Compute sample mean and unbiased covariance\n    mu = X.mean(axis=0)\n    Xc = X - mu\n    # Unbiased sample covariance: (1/(N-1)) Xc^T Xc\n    S = np.cov(X, rowvar=False, bias=False)\n\n    # Eigen-decomposition (S is symmetric). eigh returns ascending eigenvalues.\n    evals, evecs = np.linalg.eigh(S)\n    order = np.argsort(evals)[::-1]  # descending order\n    evals = evals[order]\n    evecs = evecs[:, order]\n\n    # Clip tiny negative eigenvalues due to numerical errors\n    evals = np.clip(evals, 1e-12, None)\n\n    # Retained subspace\n    if A > 0:\n        P_A = evecs[:, :A]\n        lamA = evals[:A]\n    else:\n        # Not used in tests, but for completeness\n        P_A = np.zeros((p, 0))\n        lamA = np.array([])\n\n    # Residual eigenvalues\n    lam_resid = evals[A:] if A  p else np.array([])\n\n    # Center new sample\n    x_c = x - mu\n\n    # Scores and T^2\n    if A > 0:\n        t = x_c @ P_A\n        T2 = np.sum((t ** 2) / lamA)\n    else:\n        T2 = 0.0\n\n    # T^2 limit using F-distribution\n    if A > 0 and (N - A) > 0:\n        Fcrit = f.ppf(alpha, A, N - A)\n        T2_limit = (A * (N - 1) / (N - A)) * Fcrit\n    else:\n        # Degenerate case; mark limit as infinity to avoid false alarms\n        T2_limit = np.inf\n\n    # Residual and SPE\n    if A > 0:\n        e = x_c - P_A @ (P_A.T @ x_c)\n    else:\n        e = x_c.copy()\n    SPE = float(np.dot(e, e))\n\n    # SPE limit via Jackson–Mudholkar approximation\n    theta1 = float(np.sum(lam_resid))\n    theta2 = float(np.sum(lam_resid ** 2))\n    theta3 = float(np.sum(lam_resid ** 3))\n\n    if theta2 > 0 and theta1 > 0:\n        h0 = 1.0 - (2.0 * theta1 * theta3) / (3.0 * (theta2 ** 2))\n        z = norm.ppf(alpha)\n        Q_limit = theta1 * (\n            (z * np.sqrt(2.0 * theta2) * h0) / theta1\n            + 1.0\n            + (theta2 * h0 * (h0 - 1.0)) / (theta1 ** 2)\n        ) ** (1.0 / h0)\n        Q_limit = max(Q_limit, 0.0)\n    else:\n        # No residual variance -> residual space is zero -> limit zero\n        Q_limit = 0.0\n\n    # Flags\n    t2_flag = bool(T2 > T2_limit)\n    spe_flag = bool(SPE > Q_limit)\n\n    return t2_flag, spe_flag\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        (\n            [\n                [1.0, 0.5, 1.3],\n                [0.8, 0.7, 1.1],\n                [1.1, 0.6, 1.4],\n                [0.9, 0.4, 1.2],\n                [1.2, 0.9, 1.7],\n                [1.0, 0.8, 1.5],\n                [0.7, 0.5, 1.0],\n                [1.3, 0.7, 1.8],\n                [0.9, 0.6, 1.2],\n                [1.1, 0.5, 1.4],\n                [0.8, 0.4, 1.0],\n                [1.2, 0.8, 1.6],\n            ],\n            [1.8, 0.2, 2.5],\n            2,\n        ),\n        # Test case 2\n        (\n            [\n                [10.0, 9.8, 0.2, 0.1],\n                [9.7, 9.6, 0.1, 0.2],\n                [10.2, 10.0, 0.3, 0.2],\n                [9.9, 9.7, 0.2, 0.3],\n                [10.1, 9.9, 0.2, 0.1],\n                [9.8, 9.7, 0.1, 0.2],\n                [10.0, 9.8, 0.3, 0.2],\n                [9.9, 9.6, 0.2, 0.3],\n                [10.2, 10.1, 0.3, 0.1],\n                [9.7, 9.6, 0.1, 0.2],\n            ],\n            [10.8, 10.7, 0.5, 0.4],\n            1,\n        ),\n        # Test case 3\n        (\n            [\n                [2.0, 1.0, 3.0, 0.5, 1.5],\n                [1.8, 1.1, 2.9, 0.6, 1.4],\n                [2.1, 0.9, 3.1, 0.4, 1.6],\n                [1.9, 1.0, 3.0, 0.5, 1.6],\n                [2.0, 1.2, 3.2, 0.6, 1.7],\n                [1.8, 0.8, 2.8, 0.4, 1.4],\n            ],\n            [2.5, 0.5, 3.7, 0.2, 2.0],\n            2,\n        ),\n    ]\n\n    results = []\n    for X_train, x_new, A in test_cases:\n        t2_flag, spe_flag = pca_anomaly_flags(X_train, x_new, A, alpha=0.99)\n        results.append([t2_flag, spe_flag])\n\n    # Format output exactly as required: no spaces, boolean literals.\n    def format_bool(b):\n        return \"True\" if b else \"False\"\n\n    formatted = \"[\" + \",\".join(\"[\" + \",\".join(format_bool(b) for b in pair) + \"]\" for pair in results) + \"]\"\n    print(formatted)\n\nsolve()\n```"
        }
    ]
}