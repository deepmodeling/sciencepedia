## 引言
随着信息物理系统（Cyber-Physical Systems, CPS）及其数字孪生在关键基础设施、[智能制造](@entry_id:1131785)和[自动驾驶](@entry_id:270800)等领域的广泛应用，保障其硬件与软件供应链的安全已成为一项至关重要的挑战。系统的复杂性、全球化的采购以及开源组件的广泛使用，使得供应链的每一环都可能成为攻击者渗透的切入点，从设计阶段的恶意植入到部署后的漏洞利用，其后果可能直接延伸至物理世界，造成灾难性影响。

本文旨在系统性地解决这一知识鸿沟，为理解和应对硬件与软件供应链中的复杂威胁提供一个全面的框架。我们将超越零散的安全措施，深入探讨一套相互关联的原理、机制和量化方法，帮助读者构建一个端到端的、可信的[供应链安全](@entry_id:1132659)体系。

在接下来的章节中，读者将踏上一段从理论到实践的深度学习之旅。在“原理与机制”一章，我们将解构建立信任的技术基石，包括用于追踪来源的物料清单（BOM）、用于硬件身份认证的[物理不可克隆函数](@entry_id:753421)（PUF）以及用于验证[系统完整性](@entry_id:755778)的[远程证明](@entry_id:754241)。随后，在“应用与跨学科关联”一章，我们将展示这些原理如何应用于工业控制、汽车、医疗等关键行业，并与风险管理、经济学和认证框架产生深刻的联系。最后，“动手实践”部分将通过一系列精心设计的问题，帮助读者巩固和应用所学到的量化分析技能。

通过本文的学习，读者将能够全面掌握保障现代CPS与数字孪生[供应链安全](@entry_id:1132659)所需的核心知识体系，为设计、构建和维护下一代可信系统奠定坚实的基础。

## 原理与机制

本章深入探讨保障硬件和[软件供应链安全](@entry_id:755014)所需的核心原理与关键机制。在上一章介绍背景之后，我们将系统性地剖析用于建立信任、识别威胁、验证组件以及量化管理风险的技术和方法论框架。这些原理与机制共同构成了保护现代信息物理系统（CPS）及其数字孪生免受供应链攻击的基石。

### 基础：来源与完整性

[供应链安全](@entry_id:1132659)的基石是建立对系统中每个组件来源（**provenance**）和完整性（**integrity**）的可信度。来源是指一个组件从起源到部署的完整历史记录，而完整性则保证了该组件在整个生命周期中未被未授权篡改。若无法确信一个组件的来源和完整性，那么所有后续的安全措施都将建立在不确定的基础之上。

#### 物料清单：追踪硬件与软件的基因

为了系统地追踪来源和完整性，业界开发了“物料清单”（Bill of Materials, BOM）的概念。物料清单详细列出构成一个产品的所有组件、库和依赖项，如同一个产品的“成分表”。在信息物理系统的背景下，我们主要关注两种BOM：软件物料清单（**Software Bill of Materials, SBOM**）和硬件物料清单（**Hardware Bill of Materials, HBOM**）。

一个有效的BOM不仅仅是一份组件列表，它必须包含一组精确的[元数据](@entry_id:275500)，以支持端到端的来源保证。考虑一个用于远程诊断和更新的[数字孪生](@entry_id:171650)，它需要对其镜像的嵌入式控制器拥有可审计的来源链。为了实现这一点，SBOM和HBOM必须包含以下关键字段：

1.  **身份标识（Identity）**: 包括组件名称和版本号（例如，软件的版本标识符或硬件的部件号及修订版）。这为每个组件提供了独一无二、可供人读的身份，是实施[访问控制](@entry_id:746212)和降级攻击防护策略的基础。

2.  **[密码学哈希](@entry_id:1123262)（Cryptographic Hash）**: 例如，使用SHA-256算法计算出的哈希值 $h$。这个哈希值是组件确切位级（bit-level）内容的“数字指纹”。通过将元数据与这个哈希值绑定，我们可以验证组件的**完整性**，即确保我们使用的组件与供应商声称的完全一致，未被篡改。

3.  **供应商信息（Supplier Identity）**: 明确指出组件的来源，包括供应商的法律实体和可用于密码学验证的密钥标识符。这为信任链提供了一个锚点，支持签名验证和在发现问题时进行撤销。

4.  **许可证信息（License）**: 如SPDX许可证标识符。这定义了组件的使用、分发和修改的法律约束，是**策略来源（policy provenance）**的重要组成部分。在CPS的整个生命周期中，许可证合规性直接影响到风险和法律义务。

5.  **构建/制造环境描述符（Build/Manufacturing Environment Descriptor）**: 对于软件，这可能包括编译器版本、构建脚本哈希或容器镜像摘要。对于硬件，则可能包括工艺流程标识符和运行批次。这个字段至关重要，因为它支持**可复现性（reproducibility）**验证。一个确定性的构建过程可以建模为一个函数 $a = f(x, b)$，其中 $a$ 是输出的构件，$x$ 是源代码，$b$ 是构建环境。只有同时掌握 $x$ 和 $b$，我们才能独立地重现构建过程并验证其输出的哈希值，从而检测出构建环境是否被恶意篡改。

6.  **硬件特定标识符（Hardware-Specific Identifiers）**: 对于HBOM，还需要批次号或[序列号](@entry_id:165652)。这使得我们可以将现场部署的物理单元追溯到特定的生产运行过程，对于定位和召回受伪造或制造缺陷影响的特定批次产品至关重要。

缺少上述任何一个字段都会在来源保证链中留下缺口，可能被攻击者利用。例如，仅依赖供应商签名而不使用[密码学哈希](@entry_id:1123262)，攻击者可以替换内容但保持签名有效（若签名的是弱校验和）；忽略构建环境则无法检测到受感染的编译器。因此，一个完备的BOM是实现真正端到端[供应链安全](@entry_id:1132659)的第一步。

#### 来源图与完整性度量

单个BOM描述了一个组件的直接依赖，但现代系统的供应链是一个复杂的依赖网络。为了全面理解和管理这种复杂性，我们可以将整个系统的来源信息建模为一个**[有向无环图](@entry_id:164045)（Directed Acyclic Graph, DAG）** 。

在这个**来源图（provenance graph）**中，节点代表供应链中的各种构件，如源代码仓库、构建流水线、第三方库和最终的软件产品。有向边则表示它们之间的关系，例如“依赖于”、“由...构建”或“包含”。例如，一个[数字孪生](@entry_id:171650)核心模块 $M$ 的构建过程可以表示为从其源代码仓库 $R_M$ 到构建流水线 $P_M$ 再到最终构件 $M$ 的边：$R_M \rightarrow P_M \rightarrow M$。如果 $M$ 依赖于一个模拟器库 $S$ 和一个外部库 $L_1$，则图中会有相应的依赖边：$M \rightarrow S$ 和 $M \rightarrow L_1$。

这个图的价值在于，它不仅清晰地展示了所有声明的依赖关系和构建流程，还为我们提供了一个量化评估[供应链安全](@entry_id:1132659)状况的框架。我们可以定义一个**来源完整性（provenance completeness）**度量 $C$，即已获得密码学证据（如签名或证明记录）支持的“已追溯边”数量与图中所有“已声明边”总数的比率：
$$ C = \frac{|E_{\text{traced}}|}{|E_{\text{declared}}|} $$
这里的“已声明边”来自SBOM和构建清单，而“已追溯边”则来自诸如符合SLSA（Supply-chain Levels for Software Artifacts）框架的in-toto证明等[密码学](@entry_id:139166)证据。

例如，假设一个数字孪生软件栈共有26条声明的依赖和构建边。通过审计发现，其中有16条边可以由[密码学](@entry_id:139166)证明来支持（例如，部分组件的构建过程有签名证明，部分组件有包含依赖项哈希的签名SBOM）。那么，该系统的来源完整性就是 $C = \frac{16}{26} \approx 0.615$。这个指标为安全团队提供了一个明确、可操作的改进目标：通过加强对缺失证据环节（如未签名的第三方库或缺乏构建证明的内部组件）的验证，逐步提升 $C$ 值，从而系统性地增强整个供应链的可信度。

### 硬件安全：身份、威胁与验证

与软件不同，硬件一旦制造完成便难以修改，这使得其[供应链安全](@entry_id:1132659)尤为重要。[硬件安全](@entry_id:169931)的核心挑战在于两个方面：一是在没有可信第三方的情况下确认一个物理芯片的真实身份；二是检测在设计或制造过程中被植入的恶意电路。

#### 建立可信硬件身份：[物理不可克隆函数](@entry_id:753421)

传统的身份验证方法依赖于在芯片的[非易失性存储器](@entry_id:191738)中存储一个秘密密钥。然而，这种方法存在密钥被物理提取或窃取的风险。**[物理不可克隆函数](@entry_id:753421)（Physical Unclonable Function, PUF）**提供了一种创新的解决方案，它利用了芯片制造过程中不可避免的、微观级别的随机物理差异来生成一个独一无二的“物理指纹”。

PUF可以被看作一个物理上的[单向函数](@entry_id:267542)，它将一个输入的“挑战（challenge）” $c$ 映射到一个输出的“响应（response）” $R$。对于同一个芯片，每次施加相同的挑战 $c$，其响应 $R'$ 都会非常接近原始注册的响应 $R$，但由于环境噪声和电路老化，会存在一些随机的位翻转。而对于另一个不同的芯片，即便是同一型号，其对挑战 $c$ 的响应也与 $R$ 大相径庭，几乎是完全随机的。

这种特性使PUF具备了两个关键的统计属性：
1.  **可靠性（Reliability）**: 同一设备多次响应之间的[汉明距离](@entry_id:157657)（Hamming Distance），即**设备内距离（intra-distance）**，应该很小。这个距离通常遵循一个均值较低的[二项分布](@entry_id:141181)，例如 $D_{intra} \sim \mathrm{Binomial}(n, p)$，其中 $n$ 是响应的位数，$p$ 是单个位的翻转概率（通常很小）。
2.  **唯一性（Uniqueness）**: 不同设备响应之间的[汉明距离](@entry_id:157657)，即**设备间距离（inter-distance）**，应该很大。这个距离近似遵循一个均值为 $n/2$ 的[二项分布](@entry_id:141181)，即 $D_{inter} \sim \mathrm{Binomial}(n, 1/2)$。

基于PUF的认证系统（如[数字孪生](@entry_id:171650)对现场设备的远程验证）通过设定一个门限值 $t$ 来工作：如果现场设备返回的响应 $R'$ 与注册响应 $R$ 的[汉明距离](@entry_id:157657)小于等于 $t$，则认证通过。为了避免在设备或验证器（数字孪生）中存储任何秘密，通常采用**[模糊提取器](@entry_id:1125425)（fuzzy extractor）**方案。在注册阶段，系统生成一个随机密钥 $K$，并利用 $R$ 和[纠错码](@entry_id:153794)生成一个公开的“辅助数据（helper data）” $W$。在验证阶段，设备使用现场响应 $R'$ 和公开的 $W$ 来恢复密钥 $K$。只要 $R'$ 和 $R$ 之间的差异（即位翻转数）在[纠错码](@entry_id:153794)的能力范围内（即小于等于 $t$），密钥 $K$ 就能被完美恢复。

门限值 $t$ 的选择是一个关键的权衡。过低的 $t$ 会导致合法的设备因噪声而被拒绝（高**错误拒绝率, False Reject Rate, FRR**），而过高的 $t$ 则可能让伪造的设备蒙混过关（高**错误接受率, False Accept Rate, FAR**）。假设我们要求 $P_{\mathrm{FRR}} \le \alpha$ 且 $P_{\mathrm{FAR}} \le \beta$，我们可以通过[正态近似](@entry_id:261668)求解 $t$ 必须满足的不等式。例如，对于一个响应位数为 $n=256$，位翻转概率为 $p=0.08$ 的PUF，要达到 $\alpha=10^{-6}$ 和 $\beta=10^{-9}$ 的严苛安全要求，计算得出认证门限 $t$ 必须设置为41。这意味着，为了保证可靠的认证，其配套的[模糊提取器](@entry_id:1125425)必须能够纠正多达41个位的错误。

#### 恶意篡改的威胁：[硬件木马](@entry_id:1125920)

**[硬件木马](@entry_id:1125920)（Hardware Trojan）**是在[硬件设计](@entry_id:170759)或制造过程的某个环节中，被恶意植入到电路中的一小部分逻辑。这些木马在正常情况下处于休眠状态，不会影响芯片的常规功能测试，但当满足特定的触发条件时，它们会被激活并执行恶意负载。

[硬件木马](@entry_id:1125920)可以根据其**触发器（trigger）**和**有效负载（payload）**进行分类：
-   **触发器类型**:
    -   **[组合逻辑](@entry_id:265083)触发**: 由一个非常罕见的输入模式或内部状态激活。
    -   **时序逻辑触发**: 由一个特定的事件序列激活，例如通过一个内部计数器或[状态机](@entry_id:171352)，在系统运行特定次数或特定时间后触发。
    -   **物理/模拟触发**: 由外部环境或电路参数的变化触发，如特定的温度、电压或由电路老化引起的参数漂移。
-   **有效负载类型**:
    -   **功能改变**: 修改电路的正常逻辑功能，如添加后门、实现[权限提升](@entry_id:753756)或直接导致功能错误。
    -   **[信息泄露](@entry_id:155485)**: 通过旁道（如功耗或[电磁辐射](@entry_id:152916)）建立隐蔽信道，窃取芯片内部的敏感数据（如密钥）。
    -   **参数退化/拒绝服务**: 降低芯片的性能，如增加[关键路径延迟](@entry_id:748059)导致时序错误，或通过增加功耗来缩短电池寿命，甚至使芯片失效。

由于硬件木马的[隐蔽](@entry_id:196364)性，传统的基于功能的测试很难发现它们。一种更有效的方法是利用**旁道分析（side-channel analysis）**，通过测量芯片的物理特性（如功耗、时序）来检测异常。[数字孪生](@entry_id:171650)可以为这种检测提供高精度的基线模型。

例如，我们可以同时监测一条[关键路径](@entry_id:265231)的**路径延迟（path delay）**和芯片在特定测试序列下的**动态功耗（dynamic power）**。一个硬件木马，哪怕只是几个额外的[逻辑门](@entry_id:178011)，也会给它所在的路径增加微小的电容负载 $\Delta C$，从而导致路径延迟的增加，其增量 $\Delta t \approx R_{\mathrm{on}}\Delta C$（其中 $R_{\mathrm{on}}$ 是驱动门电路的[等效电阻](@entry_id:264704)）。同时，如果木马电路在测试序列下发生翻转，也会增加芯片的动态功耗，其增量 $\Delta P \approx \alpha_{T} f V^{2} \Delta C$（其中 $\alpha_T$ 是木马电路的翻转活动因子， $f$ 是时钟频率，$V$ 是电源电压）。

通过建立[统计假设检验](@entry_id:274987)模型，我们可以计算出每种方法的[检测灵敏度](@entry_id:176035)。假设路径延迟的测量[抖动](@entry_id:200248)标准差为 $5\,\mathrm{ps}$，功耗[测量噪声](@entry_id:275238)标准差为 $1.5\,\mathrm{mW}$，经过100次平均后，并考虑数字孪生模型的残余不确定性，在严格的误报和漏报概率下（例如，$\alpha_{\mathrm{FA}}=1\%, \beta=5\%$），我们可以计算出最小可检测的电容增量。

分析表明，对于具有低活动因子（例如 $\alpha_T = 10^{-2}$）的“隐形”时序木马，路径延迟检测的灵敏度可能远高于功耗检测。例如，路径延迟可能检测到约 $28\,\mathrm{fF}$ 的电容负载（相当于几个小[逻辑门](@entry_id:178011)），而功耗检测则需要高达约 $99\,\mathrm{pF}$ 的翻转电容才能达到相同的[置信度](@entry_id:267904)，这对于一个[隐蔽](@entry_id:196364)的木马来说是不现实的。这揭示了一个重要原理：针对不同类型的硬件木马，需要采用不同的、具有相应灵敏度的检测策略，而功耗分析更适合检测那些活动频繁或始终开启的木马。

### 软件与系统安全：证明与漏洞管理

对于由众多软件组件构成的复杂系统，确保其安全性需要两个层面的努力：一是在系统启动和运行时，验证其状态是否符合预期的可信配置；二是在整个生命周期中，持续管理和修复新发现的软件漏洞。

#### 验证[系统完整性](@entry_id:755778)：[远程证明](@entry_id:754241)

**[远程证明](@entry_id:754241)（Remote Attestation）**是一种允许远端验证者（如[数字孪生](@entry_id:171650)平台）安全地检验一个设备（如CPS中的控制器）当前软件状态完整性的协议。其核心硬件基础是**[可信平台模块](@entry_id:756204)（Trusted Platform Module, TPM）**，这是一种内置于主板上的安全芯片。

TPM内部包含一组称为**平台配置寄存器（Platform Configuration Registers, PCRs）**的特殊寄存器。这些寄存器的独特之处在于它们只能通过“扩展（extend）**”操作来更新。一次扩展操作会将PCR的当前值与一个新测量值的哈希拼接起来，再对此结果进行哈希，并将此新哈希值作为PCR的新值。即：
$$ p_{i} \leftarrow H(p_{i-1} \,\|\, H(m_{i})) $$
其中 $p_{i-1}$ 是PCR的旧值，$m_i$ 是新的测量值（如固件、引导加载程序或操作系统的代码），$H$ 是一个[密码学哈希函数](@entry_id:274006)。这个过程是单向的，无法伪造或回滚。从系统启动开始，BIOS、引导加载程序、[操作系统内核](@entry_id:752950)等一系列软件组件在加载前都会被依次“测量”，其哈希值被扩展到PCR中。最终，PCR的值 $p_k$ 成为了整个启动链状态的唯一、可信的摘要。

[远程证明](@entry_id:754241)协议利用PCR来防止攻击者谎报系统状态 。其流程如下：
1.  **挑战（Challenge）**: 验证者（数字孪生编排器）生成一个足够长的、随机的、一次性的** nonce **（随机数）$n$，并将其发送给待验证的设备。
2.  **引用（Quote）**: 设备中的TPM接收到 nonce $n$ 后，会生成一个包含当前PCR值 $p$ 和 nonce $n$ 的“引用（quote）”。这个引用由[TPM](@entry_id:170576)内部独有的、不可导出的**证明密钥（Attestation Key, AK）**进行签名：$\sigma = \mathrm{Sign}_{\mathrm{AK}}(n \,\|\, p)$。
3.  **验证（Verification）**: 设备将签名后的引用 $\sigma$ 和相关的PCR值日志发回给验证者。验证者使用之前已安全获取的AK公钥来验证签名。

这个协议的安全性关键在于** nonce **。由于每次证明会话都使用一个全新的、不可预测的 nonce，攻击者即使截获了过去一次合法的引用 $\sigma_j = \mathrm{Sign}_{\mathrm{AK}}(n_j \,\|\, p^{\star})$，也无法在新的会话中重放它。因为新会话的 nonce 是 $n \neq n_j$，验证者会发现签名中的 nonce 与其发出的不匹配，从而拒绝该证明。

攻击者成功的总概率 $P(S)$ 可以通过 union bound 进行上限估计，它包括了[重放攻击](@entry_id:1130869)、伪造签名和破坏[哈希函数](@entry_id:636237)等多种途径：
$$ P(S) \le \frac{M}{2^L} + 2^{-r} + 2^{-h} $$
其中 $L$ 是 nonce 的比特长度，$M$ 是攻击者拥有的历史引用数量，$r$ 是签名方案的安全比特强度，$h$ 是[哈希函数](@entry_id:636237)的输出比特长度。在实际应用中，$2^{-r}$ 和 $2^{-h}$ 的值极小（例如，$r=128, h=256$），因此主要风险来自 nonce 碰撞。为了将攻击成功率控制在极低的水平（例如 $\epsilon = 10^{-9}$），我们需要选择足够大的 $L$。例如，在攻击者已记录 $M = 10^6$ 次会话的场景下，通过求解 $10^6 / 2^L \le 10^{-9}$，我们得出 $L$ 至少需要50比特。这说明，通过使用足够长的、密码学安全的随机 nonce，[远程证明](@entry_id:754241)可以非常有效地抵御[重放攻击](@entry_id:1130869)，确保验证者获得的是设备当前实时的可信状态。

#### 管理软件漏洞：从信息技术到物理空间的挑战

软件供应链的另一个核心任务是管理其中存在的漏洞。为此，业界建立了一套[标准化](@entry_id:637219)的工具和系统，包括：
-   **通用漏洞披露（Common Vulnerabilities and Exposures, CVE）**: 为每个[公开披露](@entry_id:915266)的漏洞提供一个唯一的[标准化](@entry_id:637219)ID，作为全球统一的参考标识。
-   **通用漏洞评分系统（Common Vulnerability Scoring System, C[VSS](@entry_id:635952)）**: 提供一个0到10的评分，用于评估漏洞的内在技术严重性。它基于攻击向量、复杂度、所需权限以及对[机密性、完整性、可用性](@entry_id:1122869)的影响等指标进行计算。
-   **漏洞利用预测评分系统（Exploit Prediction Scoring System, EPSS）**: 基于历史数据和外部信号，预测一个特定的CVE在短期内（如未来30天）被“在野”利用的概率。

这些工具在传统I[T环](@entry_id:170218)境中非常有效，但在CPS和[数字孪生](@entry_id:171650)的背景下，它们的应用存在显著的局限性。风险通常被概念化为期望损失，即 $R \propto p \cdot I$，其中 $p$ 是利用概率，$I$ 是影响或后果。CPS的特殊性在于其影响 $I$ 通常是物理的，而非纯粹的信息层面。

1.  **CVSS的局限性**：CVSS的“影响”指标衡量的是对受影响**组件本身**的机密性（C）、完整性（I）、可用性（A）的破坏程度。它完全不考虑该组件在整个物理系统中的角色和上下文。一个在非关键传感器上导致远程代码执行的漏洞（CVSS评分可能高达9.8），其物理影响 $I_{\text{phys}}$ 可能接近于零。相反，一个导致关键过程控制器短暂失灵的漏洞（C[VSS](@entry_id:635952)评分可能为中等），却可能引发灾难性的物理后果（$I_{\text{phys}}$ 极大）。因此，**高CVSS分数不等于高物理风险**，直接使用C[VSS](@entry_id:635952)分数来为CPS漏洞修复排定优先级是危险且具有误导性的。

2.  **EPSS的局限性**：EPSS的预测能力依赖于大规模、公开可观测的漏洞利用数据。这使其非常适合预测广泛传播的、机会主义的攻击。然而，关键基础设施和重要的CPS系统往往是高能力、有动机的**高级持续性威胁（Advanced Persistent Threats, APTs）**的目标。这些攻击是高度定向的、低调的，并且可能利用全新的、尚无历史数据的漏洞。此外，许多CPS部署在隔离网络中，导致可供EPSS模型学习的“在野”利用[遥测](@entry_id:199548)数据非常稀疏。因此，对于一个特定CPS系统，即使其某个漏洞的EPSS概率分很低，一个专注的攻击者利用它的条件概率（即威胁模型中的 $p$）可能非常高。

一个更严谨的CPS[供应链风险管理](@entry_id:1132658)工作流应该将这些工具整合起来，并用领域知识加以增强：
-   使用**CVE**进行漏洞的唯一识别和追踪。
-   使用**CVSS**作为对漏洞技术内在严重性的初步评估。
-   使用**EPSS**作为对机会主义攻击可能性的数据驱动输入。
-   最关键的是，必须**增强**这些通用指标，引入一个由**数字孪生驱动的物理后果模型 $I_{\text{phys}}$**。通过在[数字孪生](@entry_id:171650)中模拟漏洞被利用后的控制行为和过程动态，可以量化地评估出从经济损失到安全事故等各种物理影响。

通过这种[混合方法](@entry_id:163463)，将通用的漏洞评分与特定于系统的物理影响模型相结合，才能对CPS供应链中的软件风险做出准确的、有意义的评估和排序。

### 供应链的量化[风险管理](@entry_id:141282)

有效的[供应链安全](@entry_id:1132659)策略不仅仅是实施一系列技术控制，更需要一个能够量化评估风险、比较不同策略效益[并指](@entry_id:276731)导资源投入的系统性框架。本节将介绍几种量化风险管理的方法，从整体[风险建模](@entry_id:1125939)到对特定失效后果的精细分析。

#### 风险评估与[威胁建模](@entry_id:924842)框架

一个全面的风险评估模型需要考虑攻击的全链条，从供应商的初始妥协到最终的业务影响。我们可以构建一个形式化的风险模型，来评估上游完整性风险（即恶意修改在被接受之前进入系统的风险）。借鉴NIST SP 800-161等框架的思想，我们可以将风险表示为：
$$ R^{(j)} \approx \left(\sum_{i} \alpha_{i}^{(j)} p_{i}\right) \left(1 - d^{(j)}\right) m^{(j)} I $$
这个公式中的每个部分都代表了[风险管理](@entry_id:141282)的一个关键环节：
-   $I$: 基础影响，即一个未被检测到的妥协进入运营后造成的最大潜在损失。
-   $p_i$: 供应商 $i$ 的基线妥协概率，代表了其固有的安全水平。
-   $\alpha_{i}^{(j)} \in [0,1]$: 在实施控制措施组合 $j$ 后，应用于供应商 $i$ 妥协概率的**缩减因子**。这代表了通过加强供应商安全要求和审查来“预防”问题的效果。
-   $d^{(j)} \in [0,1]$: 在实施控制措施组合 $j$ 后，在接收前**检测**到恶意修改的概率。这代表了通过验收测试和验证来“过滤”问题的能力。
-   $m^{(j)} \in (0,1]$: 在实施控制措施组合 $j$ 后，对最终影响的**缓解因子**。这代表了通过[运行时监控](@entry_id:1131150)和安全设计来“遏制”问题后果的能力。

通过为不同的控制策略（如加强来源证明、强化验收测试、部署[运行时监控](@entry_id:1131150)）赋予相应的 $(\alpha, d, m)$ 参数值，决策者可以量化地比较不同投资策略的风险降低效益。例如，一个强调来源证明和可复现构建的策略（如Bundle A）会显著降低 $\alpha_i$ 并提高 $d$，从而大幅降低上游完整性风险。相比之下，一个只关注运行时控制的策略（如Bundle B）对 $\alpha_i$ 和 $d$ 的改善有限，因此在阻止恶意组件流入方面效果较差。

为了使风险评估更具针对性，我们还必须进行**威胁建模**。不同的攻击者拥有不同的能力和机会。我们可以将供应链抽象为一系列阶段（如需求、设计、IP集成、制造、测试、部署），并为不同类型的攻击者（如**内部人员、承包商、国家级行为体**）定义其可访问的阶段集合 $X_A$ 和能力参数 $c_A$ 。同时，每个阶段 $S_i$ 都有一个固有的“隐藏难度” $b_i$。一次攻击是可行的，当且仅当该阶段在攻击者的可访问集合内，且攻击者的能力足以克服该阶段的隐藏难度（即 $b_i \le \rho_A c_A$，其中 $\rho_A$ 是风险容忍度）。

通过实施阶段性的[安全控制](@entry_id:1131181)（如形式化验证、IP来源证明、安全启动），我们可以针对性地增加特定阶段的隐藏难度（$b_i' = m_i b_i$）。这使得我们可以分析不同控制措施如何改变不同攻击者的**可行攻击集（feasible set）** $F_A$。例如，对[RTL设计](@entry_id:174303)阶段进行形式化验证会使 $b_2$ 大幅增加，可能将该阶段移出内部人员的可行攻击集；而对第三方IP集成进行来源证明则会使 $b_3$ 增加，主要影响承包商和国家级行为体的攻击选择。这种模型化的方法使得防御者能够基于对特定威胁的担忧，系统地、有针对性地部署和评估其防御策略。

#### 失效后果建模：从传感器到[数字孪生](@entry_id:171650)

量化风险的一个关键步骤是精确评估[供应链安全](@entry_id:1132659)失效所带来的后果。对于CPS及其[数字孪生](@entry_id:171650)而言，这种后果常常表现为系统性能和可信度的下降。

考虑一个通过融合 $m$ 个冗余传感器读数来估计物理状态 $\theta$ 的[数字孪生](@entry_id:171650)。其估计器为简单的算术平均 $\hat{\theta} = \frac{1}{m}\sum_{i=1}^{m} y_i$。在理想情况下，传感器读数 $y_i = \theta + v_i$，其中 $v_i$ 是零均值高斯噪声。然而，由于硬件或软件供应链的妥协，假设有比例为 $f$ 的传感器被植入了恶意逻辑，导致其读数产生一个恒定的对抗性偏置 $\beta$，即 $y_i = \theta + v_i + \beta$。[数字孪生](@entry_id:171650)在运行时并不知道哪些传感器被感染，因此仍然对所有读数一视同仁。

这种上游传感器的**[数据完整性](@entry_id:167528)**问题——即数据从采集到消费过程中被篡改——直接影响了[数字孪生](@entry_id:171650)的可信度。我们可以通过分析估计器的**[均方误差](@entry_id:175403)（Mean Squared Error, MSE）**来量化这种影响。MSE定义为 $\mathrm{MSE} = \mathbb{E}[(\hat{\theta}-\theta)^2] = \mathrm{Bias}(\hat{\theta})^2 + \mathrm{Var}(\hat{\theta})$。

通过推导可以发现，[状态估计器](@entry_id:272846)的偏置为 $\mathrm{Bias}(\hat{\theta}) = f\beta$，而其方差为 $\mathrm{Var}(\hat{\theta}) = \frac{(1-f)\sigma_u^2 + f\sigma_c^2}{m}$（其中 $\sigma_u^2$ 和 $\sigma_c^2$ 分别是未受感染和受感染传感器的噪声方差）。因此，总的[均方误差](@entry_id:175403)为：
$$ \mathrm{MSE}(f) = (f\beta)^2 + \frac{(1-f)\sigma_u^2 + f\sigma_c^2}{m} $$
这个公式清晰地揭示了供应链失效的后果：
-   **系统性偏差**: MSE中包含一个 $(f\beta)^2$ 项。这意味着即使只有一小部分传感器被感染（$f > 0$），整个系统的状态估计也会产生一个系统性的、与感染比例 $f$ 的平方成正比的偏差。这会严重误导基于[数字孪生](@entry_id:171650)的决策。
-   **噪声增加**: 受感染传感器的噪声特性 $\sigma_c^2$ 也可能被攻击者操纵，从而影响方差项。
-   **来源的重要性**: 这个模型有力地说明了**数据来源（data provenance）**为何至关重要。如果数字孪生能够通过[供应链安全](@entry_id:1132659)机制（如PUF或[远程证明](@entry_id:754241)）获知每个传感器的可信度，它就可以采用加权平均或其他鲁棒的估计算法，降低或剔除来自不可信来源的数据，从而显著减小MSE。

#### 高级主题：关联风险与系统性风险

在对多个供应商或组件的风险进行汇总时，一个常见的错误是假设它们的失效是相互独立的。在现实中，许多风险是**关联（correlated）**的，因为它们可能源于共同的根本原因，例如共享同一个有漏洞的子级供应商、共同的物流渠道或被同一个被盗的签名密钥所影响。

一种建模这种关联性的方法是使用**[协方差矩阵](@entry_id:139155)（covariance matrix）** 。假设我们有4个一级供应商，其交付功能偏离预期的[随机变量](@entry_id:195330)为 $\mathbf{X}=(X_{1},X_{2},X_{3},X_{4})^{\top}$。由于共享子供应商，它们的表现可能是相关的，这种关系可以用一个 $4 \times 4$ 的[协方差矩阵](@entry_id:139155) $\mathbf{\Sigma}$ 来描述。$\mathbf{\Sigma}$ 的对角[线元](@entry_id:196833)素 $\Sigma_{ii} = \sigma_i^2$ 是每个供应商各自的方差，而非对角线元素 $\Sigma_{ij} = C_{ij}\sigma_i\sigma_j$ 则是它们之间的协方差（其中 $C_{ij}$ 是相关系数）。如果整个CPS的性能是这些供应商贡献的加权和 $Y = \mathbf{w}^{\top}\mathbf{X}$（其中 $\mathbf{w}$ 是关键性权重向量），那么系统级的总体风险（方差）就由以下二次型给出：
$$ \mathrm{Var}(Y) = \mathbf{w}^{\top}\mathbf{\Sigma}\mathbf{w} $$
这个模型（类似于金融中的投资组合理论）的重要性在于它表明，即使每个供应商的个体风险 $\sigma_i^2$ 很小，但如果它们之间存在正相关（$\Sigma_{ij} > 0$），总风险也可能被显著放大。忽略这种相关性将导致对系统总体风险的严重低估。

然而，对于由供应链共同原因（如一个被盗的供应商密钥）引发的极端事件或“黑天鹅”事件，简单的线性相关模型可能还不够。这类事件往往表现出**尾部依赖（tail dependence）**，即一个组件发生极端损失时，另一个组件也发生极端损失的概率远高于独立假设下的情况。

为了更精确地对这种系统性风险进行建模，我们可以使用**[Copula理论](@entry_id:142319)** 。Copula是一个[多变量函数](@entry_id:145643)，它将多个[随机变量](@entry_id:195330)的边缘分布连接起来，形成一个[联合分布](@entry_id:263960)，从而专门用于描述它们之间的依赖结构。

考虑三个不同的损失来源 $L_1, L_2, L_3$（例如，固件、软件包和ICS更新），它们都可能受到同一个被盗供应商密钥的影响。假设每个损失都服从[重尾](@entry_id:274276)的[帕累托分布](@entry_id:271483)。我们可以比较两种情况下的总损失 $S = L_1 + L_2 + L_3$ 的**在险价值（Value-at-Risk, [VaR](@entry_id:140792)）**，一个衡量极端损失的常用指标：
1.  **独立情景**: 假设三个损失[相互独立](@entry_id:273670)。对于重尾分布，总损失的VaR近似等于单个损失[VaR](@entry_id:140792)的 $n^{1/\alpha}$ 倍（其中 $n=3$, $\alpha$ 是[帕累托分布](@entry_id:271483)的[形状参数](@entry_id:270600)）。
2.  **依赖情景**: 使用一个能够捕捉上尾部依赖的**Gumbel Copula**来建模。这种依赖结构可以用**上尾部依赖系数 $\lambda_U \in [0,1]$** 来量化，它表示在给定一个损失超过其极高分位数时，另一个损失也超过其相同高分位数的条件概率。

计算结果显示，依赖性对风险的放大效应是惊人的。例如，在99%[置信水平](@entry_id:182309)下，独立假设下的总损失[VaR](@entry_id:140792)可能约为980万美元。而在完全依赖（共单调, comonotonic）的极端情况下，VaR将是三个独立[VaR](@entry_id:140792)之和，约为1890万美元。在由Gumbel Copula（参数 $\theta=2$）建模的中等强度尾部依赖下，[VaR](@entry_id:140792)将严格处于这两者之间，且其上尾部依赖系数 $\lambda_U \approx 0.586$，远大于零。这清晰地表明，由共同根本原因（如被盗密钥）驱动的供应链风险具有系统性特征，其造成的极端损失可能数倍于独立风险的总和。在进行供应链[风险评估](@entry_id:170894)时，识别并正确建模这种依赖结构是至关重要的。