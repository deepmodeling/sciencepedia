{
    "hands_on_practices": [
        {
            "introduction": "The most common way to visualize resilience is through a system's performance curve over time following a disruption. This exercise asks you to derive the total resilience loss for a system exhibiting a classic first-order exponential recovery. This practice  reinforces the fundamental definition of resilience as an integral of performance shortfall and reveals a simple yet powerful relationship between the initial impact and the speed of recovery.",
            "id": "4240950",
            "problem": "A cyber-physical system (CPS) is monitored by a digital twin that computes a dimensionless performance index $Q(t)$, normalized so that the pre-disturbance steady-state performance is $Q(t)=1$. At time $t=0$, a step disturbance instantaneously reduces the performance, after which the closed-loop recovery follows first-order stable dynamics given by $$Q(t)=1-\\alpha \\exp(-\\beta t), \\quad t\\ge 0,$$ where $\\alpha\\in(0,1)$ quantifies the immediate loss in performance and $\\beta0$ is the recovery rate. Under the standard resilience metric that defines the resilience triangle $A$ as the area of the performance shortfall relative to the pre-disturbance baseline over the interval $[0,\\infty)$, derive the analytic expression for $A$ as a function of $\\alpha$ and $\\beta$. Express the final result in seconds, assuming $t$ is measured in seconds. Your final answer must be a single closed-form expression in $\\alpha$ and $\\beta$, with no rounding required.",
            "solution": "The problem asks for the derivation of an analytic expression for the resilience triangle area, denoted by $A$. This area is defined as the integral of the performance shortfall over the time interval $[0, \\infty)$.\n\nFirst, we must define the performance shortfall. The pre-disturbance steady-state performance is given as a constant baseline value, which we can denote as $Q_{baseline}$. From the problem statement, this is $Q_{baseline} = 1$. The performance of the system for $t \\ge 0$ is given by the function $Q(t)$:\n$$Q(t) = 1 - \\alpha \\exp(-\\beta t)$$\nThe performance shortfall at any time $t$, let's call it $\\Delta Q(t)$, is the difference between the baseline performance and the actual performance:\n$$\\Delta Q(t) = Q_{baseline} - Q(t)$$\nSubstituting the given expressions, we get:\n$$\\Delta Q(t) = 1 - \\left(1 - \\alpha \\exp(-\\beta t)\\right)$$\nSimplifying this expression yields the magnitude of the performance shortfall at time $t$:\n$$\\Delta Q(t) = \\alpha \\exp(-\\beta t)$$\nThe resilience triangle area $A$ is the total performance loss, which is calculated by integrating the shortfall function $\\Delta Q(t)$ from the time of the disturbance, $t=0$, to infinity, $t \\to \\infty$. This is represented by the improper integral:\n$$A = \\int_{0}^{\\infty} \\Delta Q(t) \\, dt$$\nSubstituting the expression for $\\Delta Q(t)$ into the integral:\n$$A = \\int_{0}^{\\infty} \\alpha \\exp(-\\beta t) \\, dt$$\nSince $\\alpha$ is a constant, it can be factored out of the integral:\n$$A = \\alpha \\int_{0}^{\\infty} \\exp(-\\beta t) \\, dt$$\nTo evaluate this integral, we find the antiderivative of $\\exp(-\\beta t)$ with respect to $t$. The antiderivative is $-\\frac{1}{\\beta}\\exp(-\\beta t)$. We then evaluate this at the limits of integration:\n$$A = \\alpha \\left[ -\\frac{1}{\\beta} \\exp(-\\beta t) \\right]_{0}^{\\infty}$$\nThis is shorthand for the limit definition of an improper integral:\n$$A = \\alpha \\lim_{b \\to \\infty} \\left[ -\\frac{1}{\\beta} \\exp(-\\beta t) \\right]_{0}^{b} = \\alpha \\lim_{b \\to \\infty} \\left( \\left(-\\frac{1}{\\beta} \\exp(-\\beta b)\\right) - \\left(-\\frac{1}{\\beta} \\exp(-\\beta \\cdot 0)\\right) \\right)$$\nWe evaluate the two terms inside the limit. For the first term, we use the condition that $\\beta > 0$. As $b \\to \\infty$, the term $-\\beta b \\to -\\infty$. Therefore, $\\exp(-\\beta b) \\to 0$.\n$$\\lim_{b \\to \\infty} \\left(-\\frac{1}{\\beta} \\exp(-\\beta b)\\right) = 0$$\nFor the second term, we have $\\exp(-\\beta \\cdot 0) = \\exp(0) = 1$.\n$$\\left(-\\frac{1}{\\beta} \\exp(0)\\right) = -\\frac{1}{\\beta}$$\nSubstituting these results back into the expression for $A$:\n$$A = \\alpha \\left( 0 - \\left(-\\frac{1}{\\beta}\\right) \\right)$$\n$$A = \\alpha \\left(\\frac{1}{\\beta}\\right)$$\nThe final expression for the resilience triangle area is:\n$$A = \\frac{\\alpha}{\\beta}$$\nThe problem asks for the result to be expressed in seconds. We can verify the units. The performance index $Q(t)$ is dimensionless, which implies that the parameter $\\alpha$ is also dimensionless. The variable $t$ is in seconds. For the argument of the exponential function, $-\\beta t$, to be dimensionless, the parameter $\\beta$ must have units of inverse time, i.e., $s^{-1}$. Therefore, the units of $A = \\frac{\\alpha}{\\beta}$ are $\\frac{\\text{dimensionless}}{s^{-1}} = s$. This is consistent with the problem's requirement.",
            "answer": "$$\n\\boxed{\\frac{\\alpha}{\\beta}}\n$$"
        },
        {
            "introduction": "Beyond temporal performance, the resilience of a cyber-physical system often depends on the robustness of its underlying network structure. In this practice, you will use the algebraic connectivity of a graph, a powerful metric from spectral graph theory, to quantify a communication network's resilience to node failures. By implementing this analysis in code, you will gain practical experience in evaluating how structural vulnerabilities impact overall system robustness .",
            "id": "4240958",
            "problem": "A digital twin of a Cyber-Physical System (CPS) uses algebraic connectivity as a resilience indicator for its communication network. Consider an undirected, weighted ring network with $n=10$ nodes, indexed as $0,1,\\dots,9$, whose connectivity is represented by a symmetric adjacency matrix $A \\in \\mathbb{R}^{10 \\times 10}$. Each edge $(i,(i+1) \\bmod 10)$ has a nonnegative weight $w_i$, and there are no other edges. Let the degree matrix $D$ be defined by $D_{ii} = \\sum_{j=0}^{9} A_{ij}$ and let the combinatorial graph Laplacian be $L = D - A$. The algebraic connectivity is the second-smallest eigenvalue $\\lambda_2$ of $L$, also known as the Fiedler value. Removing a node $k$ from the network yields a new adjacency matrix $A'$ formed by deleting row $k$ and column $k$ from $A$, and the corresponding Laplacian $L' = D' - A'$ on the remaining $n-1$ nodes.\n\nFundamental base definitions:\n- For a weighted undirected graph with symmetric adjacency $A$, the degree matrix $D$ satisfies $D_{ii} = \\sum_{j} A_{ij}$ and the combinatorial Laplacian is $L = D - A$.\n- For symmetric $L$, the eigenvalues are real and can be ordered as $0 = \\lambda_1 \\le \\lambda_2 \\le \\dots \\le \\lambda_n$. The algebraic connectivity $\\lambda_2$ quantifies how well connected the graph is in the sense of diffusion or consensus dynamics governed by $\\dot{x} = -L x$.\n- Node removal $k$ corresponds to deleting the associated row and column in $A$ and recomputing $L'$ and its spectrum.\n\nDefine the resilience metric as the change in algebraic connectivity and its normalized residual:\n- $\\Delta = \\lambda_2^{\\text{post}} - \\lambda_2^{\\text{pre}}$,\n- $r = \\lambda_2^{\\text{post}} / \\lambda_2^{\\text{pre}}$,\nwhere $\\lambda_2^{\\text{pre}}$ is computed before node removal and $\\lambda_2^{\\text{post}}$ after removing node $k$. Interpret $r$ as the fraction of connectivity retained; lower $r$ indicates lower resilience.\n\nTasks to implement:\n1. Construct $A$ for each test case from the specified weights $w_i$ for edges $(i,(i+1) \\bmod 10)$, with $A_{i,(i+1) \\bmod 10} = A_{(i+1) \\bmod 10,i} = w_i$ and all other entries zero. Compute $L = D - A$ and $\\lambda_2^{\\text{pre}}$.\n2. Remove node $k$ to obtain $A'$ by deleting row $k$ and column $k$, compute $L' = D' - A'$, and $\\lambda_2^{\\text{post}}$.\n3. Compute $\\Delta$ and $r$ as defined above.\n\nTest suite with parameter values:\n- Case $1$ (happy path): $n=10$, $w_i=1$ for all $i \\in \\{0,\\dots,9\\}$, remove node $k=0$.\n- Case $2$ (asymmetry and local weakness): $n=10$, $w_0=0.2$ and $w_i=1$ for $i \\in \\{1,\\dots,9\\}$, remove node $k=0$.\n- Case $3$ (near-critical weak link): $n=10$, $w_4=0.001$ and $w_i=1$ for $i \\in \\{0,1,2,3,5,6,7,8,9\\}$, remove node $k=7$.\n\nAnswer specification:\n- For each case, output the list $[\\lambda_2^{\\text{pre}}, \\lambda_2^{\\text{post}}, \\Delta, r]$ with each float rounded to six decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list of these per-case lists, enclosed in square brackets, for example $[[a,b,c,d],[e,f,g,h],[p,q,r,s]]$.\n- No physical units are involved; all outputs are pure dimensionless floats. Do not use a percentage sign; express $r$ as a decimal.\n\nYour program must be self-contained and must not require any user input. It must implement the above computations exactly as described and produce the final aggregated results in the specified single-line format.",
            "solution": "We derive the computation and metrics from core graph-theoretic and dynamical-system definitions. For an undirected weighted graph with symmetric adjacency matrix $A$, the degree of node $i$ is $d_i = \\sum_{j=0}^{n-1} A_{ij}$ and the degree matrix is $D = \\mathrm{diag}(d_0,\\dots,d_{n-1})$. The combinatorial Laplacian is $L = D - A$. This $L$ is symmetric and positive semidefinite, implying a real spectrum $0 = \\lambda_1 \\le \\lambda_2 \\le \\dots \\le \\lambda_n$, where $\\lambda_1 = 0$ corresponds to the eigenvector of all ones. The algebraic connectivity $\\lambda_2$ is the second-smallest eigenvalue and is a fundamental measure of connectivity: it can be characterized by the Rayleigh quotient minimization subject to orthogonality to the all-ones vector, namely\n$$\n\\lambda_2 = \\min_{\\substack{x \\in \\mathbb{R}^n \\\\ x \\perp \\mathbf{1},\\, x \\ne 0}} \\frac{x^\\top L x}{x^\\top x}.\n$$\nThis characterization relates $\\lambda_2$ to the \"tightest bottleneck\" in the graph in terms of diffusion or consensus dynamics $\\dot{x}(t) = -L x(t)$, since larger $\\lambda_2$ implies faster convergence to consensus and stronger robustness to link or node perturbations.\n\nThe ring network is defined by edges $(i,(i+1) \\bmod n)$ for $i \\in \\{0,\\dots,n-1\\}$ with weights $w_i \\ge 0$. The adjacency matrix entries satisfy $A_{i,(i+1) \\bmod n} = A_{(i+1) \\bmod n,i} = w_i$ and all other entries are zero. From $A$, we compute $D$ and then $L = D - A$. The second-smallest eigenvalue $\\lambda_2$ is obtained by computing the eigenvalues of $L$ and ordering them increasingly.\n\nNode removal is a structural change: removing node $k$ deletes row $k$ and column $k$ from $A$, producing $A' \\in \\mathbb{R}^{(n-1)\\times(n-1)}$. We then compute $D'$ and $L' = D' - A'$, and obtain $\\lambda_2^{\\text{post}}$ analogously. In a ring, removing a single node breaks the cycle and yields a path on the remaining $n-1$ nodes, which remains connected provided all remaining edge weights are nonzero. Hence, $\\lambda_2^{\\text{post}}$ will be strictly positive but generally smaller than $\\lambda_2^{\\text{pre}}$, reflecting reduced connectivity.\n\nThe resilience metric is defined as both the absolute change $\\Delta = \\lambda_2^{\\text{post}} - \\lambda_2^{\\text{pre}}$ and the normalized residual $r = \\lambda_2^{\\text{post}}/\\lambda_2^{\\text{pre}}$. The interpretation is:\n- If $\\Delta  0$ and $0  r  1$, connectivity has degraded. Smaller $r$ indicates that less connectivity has been retained, implying lower resilience to the node removal.\n- If $r$ is closer to $1$, the network is more robust to that removal.\n\nAlgorithmic steps implemented in the program:\n1. For each test case, construct the adjacency matrix $A$ by setting $A_{i,(i+1)\\bmod n} = A_{(i+1)\\bmod n,i} = w_i$ and zero otherwise.\n2. Compute the degree matrix $D$ via $d_i = \\sum_j A_{ij}$ and form $L = D - A$.\n3. Compute the eigenvalues of $L$ using a symmetric-eigenvalue routine and extract $\\lambda_2^{\\text{pre}}$ as the second-smallest eigenvalue.\n4. Remove node $k$ by deleting row and column $k$ from $A$ to get $A'$, compute $D'$ and $L'$, and extract $\\lambda_2^{\\text{post}}$.\n5. Compute $\\Delta$ and $r$ and round each to six decimal places for reporting.\n6. Aggregate the per-case results into a single list of lists and print in the required single-line format.\n\nCoverage rationale for the test suite:\n- Case $1$ is the symmetric \"happy path\" where all $w_i=1$ and the removal $k=0$ yields a uniform path, illustrating the canonical drop in connectivity when a cycle becomes a path.\n- Case $2$ introduces local weakness ($w_0=0.2$) and removes node $k=0$, eliminating the weak edge and yielding a uniform path; this tests how pre-removal asymmetry affects $\\lambda_2^{\\text{pre}}$ and the retained fraction $r$.\n- Case $3$ sets a near-critical weak link ($w_4=0.001$) and removes node $k=7$, resulting in a path that retains the weak link. This edge case demonstrates a substantial decrease in algebraic connectivity and the sensitivity of the resilience metric to extreme local degradations.\n\nThe outputs are dimensionless floats rounded to six decimals and aggregated as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_ring_adjacency(n: int, weights: np.ndarray) - np.ndarray:\n    \"\"\"\n    Build the adjacency matrix for a weighted undirected ring.\n    Nodes are 0..n-1. Edge (i, (i+1)%n) has weight weights[i].\n    \"\"\"\n    A = np.zeros((n, n), dtype=float)\n    for i in range(n):\n        j = (i + 1) % n\n        w = weights[i]\n        # Symmetric adjacency for undirected graph\n        A[i, j] = w\n        A[j, i] = w\n    return A\n\ndef laplacian_from_adjacency(A: np.ndarray) - np.ndarray:\n    \"\"\"\n    Compute the combinatorial Laplacian L = D - A,\n    where D is the diagonal degree matrix with D_ii = sum_j A_ij.\n    \"\"\"\n    degrees = np.sum(A, axis=1)\n    D = np.diag(degrees)\n    L = D - A\n    return L\n\ndef algebraic_connectivity(L: np.ndarray) - float:\n    \"\"\"\n    Compute the second-smallest eigenvalue (algebraic connectivity) of symmetric Laplacian L.\n    \"\"\"\n    # Use eigvalsh for symmetric/hermitian matrices to get sorted eigenvalues\n    evals = np.linalg.eigvalsh(L)\n    # Numerical guard: ensure ordering and non-negativity within tolerance\n    evals_sorted = np.sort(evals)\n    # Second-smallest eigenvalue\n    lam2 = float(evals_sorted[1])\n    # Clip tiny negatives due to round-off\n    if lam2  0 and lam2  -1e-12:\n        lam2 = 0.0\n    return lam2\n\ndef remove_node_adjacency(A: np.ndarray, k: int) - np.ndarray:\n    \"\"\"\n    Remove node k from adjacency matrix A by deleting row k and column k.\n    \"\"\"\n    mask = np.ones(A.shape[0], dtype=bool)\n    mask[k] = False\n    A_reduced = A[np.ix_(mask, mask)]\n    return A_reduced\n\ndef compute_metrics(n: int, weights_list, remove_idx: int):\n    \"\"\"\n    For a given ring configuration and node removal index, compute:\n    lambda2_pre, lambda2_post, delta, ratio\n    \"\"\"\n    weights = np.array(weights_list, dtype=float)\n    A = build_ring_adjacency(n, weights)\n    L = laplacian_from_adjacency(A)\n    lam2_pre = algebraic_connectivity(L)\n\n    A_post = remove_node_adjacency(A, remove_idx)\n    L_post = laplacian_from_adjacency(A_post)\n    lam2_post = algebraic_connectivity(L_post)\n\n    delta = lam2_post - lam2_pre\n    ratio = lam2_post / lam2_pre if lam2_pre  0 else float('nan')\n    return lam2_pre, lam2_post, delta, ratio\n\ndef format_result_tuple(tup):\n    \"\"\"\n    Format a 4-tuple of floats to six decimal places inside a list representation.\n    \"\"\"\n    return \"[\" + \",\".join(f\"{x:.6f}\" for x in tup) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Case 1: n=10, all weights 1, remove node 0\n    n1 = 10\n    weights1 = [1.0] * n1\n    remove_idx1 = 0\n\n    # Case 2: n=10, w0=0.2, others 1.0, remove node 0\n    n2 = 10\n    weights2 = [1.0] * n2\n    weights2[0] = 0.2\n    remove_idx2 = 0\n\n    # Case 3: n=10, w4=0.001, others 1.0, remove node 7\n    n3 = 10\n    weights3 = [1.0] * n3\n    weights3[4] = 0.001\n    remove_idx3 = 7\n\n    test_cases = [\n        (n1, weights1, remove_idx1),\n        (n2, weights2, remove_idx2),\n        (n3, weights3, remove_idx3),\n    ]\n\n    results = []\n    for n, weights, remove_idx in test_cases:\n        lam2_pre, lam2_post, delta, ratio = compute_metrics(n, weights, remove_idx)\n        results.append((lam2_pre, lam2_post, delta, ratio))\n\n    # Final print statement in the exact required format: list of per-case lists.\n    formatted = \"[\" + \",\".join(format_result_tuple(r) for r in results) + \"]\"\n    print(formatted)\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world recovery planning is rarely about optimizing a single metric; it involves balancing conflicting objectives such as speed, cost, and quality of restoration. This final exercise places you in the role of a decision-maker using a Digital Twin to evaluate different recovery options. You will apply core principles like Pareto dominance and weighted-sum utility to make a rational, data-driven choice, demonstrating how quantitative metrics inform strategic planning in complex, multi-faceted scenarios .",
            "id": "4240929",
            "problem": "A utility operator maintains a Digital Twin (DT) of a power-grid Cyber-Physical System (CPS) to plan recovery after a cyber-induced physical disruption. The system-wide service level is described by a normalized quality trajectory $Q(t) \\in [0,1]$, where $Q(t)$ decreases at the disruption onset and is later restored by recovery actions. Resilience assessment in this context prioritizes recovery speed, extent of service restoration, and resource expenditure. Two candidate recovery options $R_1$ and $R_2$ are simulated in the DT and evaluated by three metrics measured at the planning stage:\n- Recovery acceleration $A$ in units of $\\mathrm{h}^{-1}$, representing the characteristic rate parameter of first-order recovery toward a target service level.\n- Recovery expenditure $c$ in millions of dollars, representing the total additional cost attributable to the chosen recovery option.\n- Maximum incremental restoration $\\Delta Q_{\\max}$, a dimensionless fraction in $[0,1]$ representing the peak increase in normalized service level achievable by the option beyond the disrupted baseline.\n\nThe DT provides the following metric values:\n- For $R_1$: $A_1 = 0.8\\,\\mathrm{h}^{-1}$, $c_1 = 12$, $\\Delta Q_{\\max,1} = 0.35$.\n- For $R_2$: $A_2 = 0.5\\,\\mathrm{h}^{-1}$, $c_2 = 9$, $\\Delta Q_{\\max,2} = 0.45$.\n\nStakeholders (regulators, operators, and customers) have negotiated an aggregate weight vector over the three dimensions: $w_A = 0.5$, $w_c = 0.2$, $w_Q = 0.3$. To compare heterogeneous metrics, the planning team will normalize each metric to a dimensionless utility on $[0,1]$ using reference values that reflect aspirational targets and budget caps agreed in policy:\n- Reference acceleration $A_{\\mathrm{ref}} = 1.0\\,\\mathrm{h}^{-1}$.\n- Reference cost cap $c_{\\mathrm{ref}} = 15$ (millions of dollars).\n- Reference service restoration $\\Delta Q_{\\mathrm{ref}} = 0.5$.\n\nAssume the following decision principles:\n1. Use Pareto dominance with correct objective directions to eliminate any dominated option: recovery acceleration $A$ and maximum incremental restoration $\\Delta Q_{\\max}$ are objectives to be maximized, whereas cost $c$ is an objective to be minimized.\n2. If neither option is Pareto dominated, derive a dimensionless weighted-sum utility consistent with the stakeholder weights by mapping each metric to a $[0,1]$ utility via normalization with the provided reference values and aligning directions so that $1$ denotes ideal performance for each dimension.\n\nDecide between $R_1$ and $R_2$ accordingly, and report the weighted-sum utility of the selected option as a single number. Round your answer to four significant figures. Express the final value as a dimensionless number.",
            "solution": "We begin from fundamental multi-objective decision principles relevant to resilience planning in Cyber-Physical Systems (CPS). The normalized service level $Q(t)$ captures the system performance over time, while resilience-oriented metrics quantify recovery speed, restoration extent, and resource expenditure. The decision requires comparing two options $R_1$ and $R_2$ across three objectives with heterogeneous units. \n\nFirst, we apply Pareto dominance. An option $X$ Pareto dominates option $Y$ if, for all objectives, $X$ is at least as good as $Y$ in the correct direction and strictly better in at least one. Here:\n- Recovery acceleration $A$ is to be maximized.\n- Maximum incremental restoration $\\Delta Q_{\\max}$ is to be maximized.\n- Cost $c$ is to be minimized.\n\nWe list the metrics:\n- $R_1$: $A_1 = 0.8$, $c_1 = 12$, $\\Delta Q_{\\max,1} = 0.35$.\n- $R_2$: $A_2 = 0.5$, $c_2 = 9$, $\\Delta Q_{\\max,2} = 0.45$.\n\nComparisons:\n- For $A$: $A_1 = 0.8  0.5 = A_2$, so $R_1$ is better on $A$.\n- For $c$: $c_1 = 12  9 = c_2$, but since lower cost is better, $R_2$ is better on $c$.\n- For $\\Delta Q_{\\max}$: $\\Delta Q_{\\max,1} = 0.35  0.45 = \\Delta Q_{\\max,2}$, so $R_2$ is better on $\\Delta Q_{\\max}$.\n\nSince $R_1$ is better in $A$ but worse in both $c$ and $\\Delta Q_{\\max}$, and $R_2$ is better in two objectives but worse in one, neither option is at least as good in all objectives compared to the other. Therefore, neither $R_1$ nor $R_2$ Pareto dominates the other. Both lie on the Pareto front with respect to the two options.\n\nGiven no dominance, we proceed to construct a weighted-sum utility that is dimensionless and aligns objective directions. We normalize each metric to $[0,1]$ using the provided references:\n- For acceleration, higher is better; a natural normalization is the ratio to the reference:\n  $$u_A = \\frac{A}{A_{\\mathrm{ref}}}.$$\n- For cost, lower is better; we invert relative to the reference cap so that $0$ corresponds to hitting the cap and $1$ to zero cost:\n  $$u_c = 1 - \\frac{c}{c_{\\mathrm{ref}}}.$$\n- For restoration, higher is better; use the ratio to the target:\n  $$u_Q = \\frac{\\Delta Q_{\\max}}{\\Delta Q_{\\mathrm{ref}}}.$$\n\nThese utilities are in $[0,1]$ provided $A \\in [0, A_{\\mathrm{ref}}]$, $c \\in [0, c_{\\mathrm{ref}}]$, and $\\Delta Q_{\\max} \\in [0, \\Delta Q_{\\mathrm{ref}}]$, matching the planning references. We then combine them with stakeholder weights $w_A$, $w_c$, and $w_Q$ to form the overall utility:\n$$U = w_A\\,u_A + w_c\\,u_c + w_Q\\,u_Q,$$\nwhere $w_A = 0.5$, $w_c = 0.2$, and $w_Q = 0.3$.\n\nCompute the utilities for each option.\n\nFor $R_1$:\n- $$u_{A,1} = \\frac{A_1}{A_{\\mathrm{ref}}} = \\frac{0.8}{1.0} = 0.8.$$\n- $$u_{c,1} = 1 - \\frac{c_1}{c_{\\mathrm{ref}}} = 1 - \\frac{12}{15} = 1 - 0.8 = 0.2.$$\n- $$u_{Q,1} = \\frac{\\Delta Q_{\\max,1}}{\\Delta Q_{\\mathrm{ref}}} = \\frac{0.35}{0.5} = 0.7.$$\nThus,\n$$U_1 = (0.5)(0.8) + (0.2)(0.2) + (0.3)(0.7) = 0.4 + 0.04 + 0.21 = 0.65.$$\n\nFor $R_2$:\n- $$u_{A,2} = \\frac{A_2}{A_{\\mathrm{ref}}} = \\frac{0.5}{1.0} = 0.5.$$\n- $$u_{c,2} = 1 - \\frac{c_2}{c_{\\mathrm{ref}}} = 1 - \\frac{9}{15} = 1 - 0.6 = 0.4.$$\n- $$u_{Q,2} = \\frac{\\Delta Q_{\\max,2}}{\\Delta Q_{\\mathrm{ref}}} = \\frac{0.45}{0.5} = 0.9.$$\nThus,\n$$U_2 = (0.5)(0.5) + (0.2)(0.4) + (0.3)(0.9) = 0.25 + 0.08 + 0.27 = 0.60.$$\n\nTherefore, the weighted-sum utility favors $R_1$ with $U_1 = 0.65$ over $R_2$ with $U_2 = 0.60$. The decision is $R_1$. The requested output is the weighted-sum utility of the selected option, rounded to four significant figures. Rounding $0.65$ to four significant figures yields $0.6500$, expressed as a dimensionless number.",
            "answer": "$$\\boxed{0.6500}$$"
        }
    ]
}