{
    "hands_on_practices": [
        {
            "introduction": "The power of the Web Ontology Language (OWL) lies in its ability to create formal, machine-readable definitions for the concepts in a domain. A critical skill for a knowledge engineer is to translate these formal semantics into practical verification algorithms. This exercise, , tasks you with implementing a checker for a common and important type of definition: a qualified cardinality restriction. By verifying that a `SensingDevice` has at least one `Measurement` output, you will bridge the gap between abstract model theory and the concrete code needed to validate instances in your knowledge graph.",
            "id": "4228925",
            "problem": "You are working within the domain of knowledge graphs and semantic representations for Cyber-Physical Systems (CPS), targeting the Web Ontology Language (OWL) class modeling of devices and their outputs. The fundamental base for this problem is the model-theoretic semantics of Description Logic (DL) underlying OWL, where classes are interpreted as sets and properties as binary relations over a universe of discourse. Specifically, rely on the following fundamentals:\n- An interpretation assigns to each class symbol a subset of a domain and to each property symbol a binary relation over the domain.\n- A cardinality restriction on a property counts the number of distinct successors satisfying a given class membership under that property, aligned with set-theoretic counting and relational composition.\n\nObjective: Construct the OWL class expression for a SensingDevice that must have at least one Measurement output and demonstrate how this requirement is captured using an OWL restriction with minimum cardinality. Then, implement an algorithm that, given a finite knowledge graph consisting of individual types and property edges, decides for each test instance whether it satisfies the qualified minimum cardinality requirement.\n\nDefinitions to use:\n- Let $\\Delta^{I}$ denote the universe of interpretation.\n- Let $P^{I} \\subseteq \\Delta^{I} \\times \\Delta^{I}$ denote the interpretation of a property.\n- Let $C^{I} \\subseteq \\Delta^{I}$ denote the interpretation of a class.\n- A qualified minimum cardinality restriction is satisfied by an individual $x \\in \\Delta^{I}$ if the number of distinct $P^{I}$-successors of $x$ that are in $C^{I}$ is at least $n$, for some integer $n \\ge 0$.\n\nTask details:\n1. Formulate the class expression for “SensingDevice with at least one Measurement output” using a qualified minimum cardinality restriction on the property “hasOutput” relative to the class “Measurement,” with the minimum count $n = 1$. Do not present the target formula directly in the problem statement; instead, your algorithmic solution must derive it from the aforementioned fundamentals of interpretation and cardinality.\n2. Implement a program that:\n   - Represents a small knowledge graph with individuals, their types, and a property adjacency structure for “hasOutput.”\n   - For each test case device, computes whether it satisfies the qualified minimum cardinality requirement “hasOutput at least $1$ Measurement” by counting distinct successors typed as Measurement.\n   - Returns a boolean for each test case indicating satisfaction.\n\nAssumptions:\n- Counting is over distinct successors, that is, if there are repeated edges to the same individual, they contribute only once to the cardinality.\n- An edge $(x,y)$ contributes to the count only if $y$ is typed as Measurement.\n- Absence of a property edge yields a count of $0$.\n\nTest suite:\nUse the following six test cases. Each case is a self-contained configuration of types and property edges for a single device identifier. The property of interest is “hasOutput,” the target class is “Measurement,” and the minimum qualified cardinality is $1$.\n\n- Case A (happy path): Device $s_1$ has one output $m_1$; $m_1$ is typed Measurement.\n  - Types: $s_1 \\mapsto \\{\\text{SensingDevice}\\}$, $m_1 \\mapsto \\{\\text{Measurement}\\}$\n  - Edges: $(s_1, \\text{hasOutput}, m_1)$\n  - Expected boolean: True\n\n- Case B (boundary: duplicates do not inflate cardinality): Device $s_2$ has two edges to the same output $m_1$; $m_1$ is typed Measurement; distinct count is $1$.\n  - Types: $s_2 \\mapsto \\{\\text{SensingDevice}\\}$, $m_1 \\mapsto \\{\\text{Measurement}\\}$\n  - Edges: $(s_2, \\text{hasOutput}, m_1)$ twice\n  - Expected boolean: True\n\n- Case C (edge case: zero outputs): Device $s_3$ has no outputs.\n  - Types: $s_3 \\mapsto \\{\\text{SensingDevice}\\}$\n  - Edges: none\n  - Expected boolean: False\n\n- Case D (failure: non-measurement output only): Device $s_4$ has one output $nm_1$; $nm_1$ is typed NonMeasurement.\n  - Types: $s_4 \\mapsto \\{\\text{SensingDevice}\\}$, $nm_1 \\mapsto \\{\\text{NonMeasurement}\\}$\n  - Edges: $(s_4, \\text{hasOutput}, nm_1)$\n  - Expected boolean: False\n\n- Case E (mixed outputs): Device $s_5$ has outputs $m_2$ and $nm_1$; $m_2$ is typed Measurement; $nm_1$ is typed NonMeasurement; distinct Measurement count is $1$.\n  - Types: $s_5 \\mapsto \\{\\text{SensingDevice}\\}$, $m_2 \\mapsto \\{\\text{Measurement}\\}$, $nm_1 \\mapsto \\{\\text{NonMeasurement}\\}$\n  - Edges: $(s_5, \\text{hasOutput}, m_2)$ and $(s_5, \\text{hasOutput}, nm_1)$\n  - Expected boolean: True\n\n- Case F (multiple distinct measurement outputs): Device $s_6$ has outputs $m_1$ and $m_2$; both typed Measurement; distinct count is $2 \\ge 1$.\n  - Types: $s_6 \\mapsto \\{\\text{SensingDevice}\\}$, $m_1 \\mapsto \\{\\text{Measurement}\\}$, $m_2 \\mapsto \\{\\text{Measurement}\\}$\n  - Edges: $(s_6, \\text{hasOutput}, m_1)$ and $(s_6, \\text{hasOutput}, m_2)$\n  - Expected boolean: True\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, “[result1,result2,...]”), where each result is a boolean corresponding to the cases A through F in order.",
            "solution": "The problem is valid. It is scientifically grounded in the formal model-theoretic semantics of Description Logics (DL), which form the basis for the Web Ontology Language (OWL). The problem is well-posed, providing a clear objective, complete definitions, and a set of unambiguous test cases. It correctly tasks the user with applying the formal definition of a qualified cardinality restriction to a practical verification algorithm.\n\nThe core of this problem is to formalize and verify a statement about a class of objects within a knowledge graph. The statement is: “a `SensingDevice` that has at least one output which is a `Measurement`.” This is a common modeling pattern in designing ontologies for Cyber-Physical Systems (CPS), where ensuring data integrity and proper system composition is critical.\n\nWe begin by formalizing the statement using the concepts of Description Logic. Let the base class be $SensingDevice$, the property be $hasOutput$, and the qualifying class for the output be $Measurement$. The requirement can be expressed as a complex class definition, which is the intersection (conjunction) of the base class and a restriction on its property.\n\nThe restriction is a qualified minimum cardinality restriction. In DL syntax, it is written as $(\\ge n \\ P.C)$, where $n$ is the minimum number of connections, $P$ is the property, and $C$ is the qualifying class for the objects connected via $P$. For our specific case, the property $P$ is $hasOutput$, the qualifying class $C$ is $Measurement$, and the minimum number of connections $n$ is $1$. The restriction is therefore $(\\ge 1 \\ hasOutput.Measurement)$.\n\nThe complete class expression for a “SensingDevice with at least one Measurement output” is the intersection of the base class and this restriction:\n$$\nSensingDevice \\sqcap (\\ge 1 \\ hasOutput.Measurement)\n$$\nwhere $\\sqcap$ denotes the class intersection operator.\n\nTo understand how this formal expression is verified, we turn to the model-theoretic semantics provided. An interpretation $\\mathcal{I} = (\\Delta^{\\mathcal{I}}, \\cdot^{\\mathcal{I}})$ consists of a non-empty domain of individuals $\\Delta^{\\mathcal{I}}$ and an interpretation function $\\cdot^{\\mathcal{I}}$ that maps class names to subsets of $\\Delta^{\\mathcal{I}}$ and property names to binary relations on $\\Delta^{\\mathcal{I}}$.\n\nAn individual $x \\in \\Delta^{\\mathcal{I}}$ is an instance of the class expression $SensingDevice \\sqcap (\\ge 1 \\ hasOutput.Measurement)$ if and only if it satisfies both parts of the conjunction:\n$1$. $x \\in (SensingDevice)^{\\mathcal{I}}$\n$2$. $x \\in (\\ge 1 \\ hasOutput.Measurement)^{\\mathcal{I}}$\n\nThe first condition simply means that the individual $x$ must be of type $SensingDevice$. The second condition is defined by the semantics of qualified minimum cardinality restrictions. An individual $x$ satisfies this condition if the cardinality of the set of its distinct successors via the $hasOutput$ property, which are also members of the $Measurement$ class, is greater than or equal to $1$. Formally:\n$$\n|\\{ y \\in \\Delta^{\\mathcal{I}} \\mid (x, y) \\in (hasOutput)^{\\mathcal{I}} \\land y \\in (Measurement)^{\\mathcal{I}} \\}| \\ge 1\n$$\nHere, $(hasOutput)^{\\mathcal{I}}$ is the set of all pairs $(u,v)$ related by the $hasOutput$ property, and $(Measurement)^{\\mathcal{I}}$ is the set of all individuals of type $Measurement$. The set $\\{ y \\in \\Delta^{\\mathcal{I}} \\mid \\dots \\}$ collects all distinct individuals $y$ that are connected to $x$ via $hasOutput$ and are typed as $Measurement$. The operator $|\\cdot|$ calculates the size of this set.\n\nThe algorithm to verify this condition for a given device in a finite knowledge graph directly implements this semantic definition.\n$1$. **Identify the device ($x$)** to be checked from the test case.\n$2$. **Retrieve all successors ($y$)** of $x$ connected by the $hasOutput$ property. This corresponds to finding all $y$ such that the edge $(x, \\text{hasOutput}, y)$ exists in the graph. The problem specifies that absence of an edge results in a count of $0$, which happens naturally if this set is empty.\n$3$. **Ensure distinctness**. The semantic definition counts elements of a set, so any duplicate successors must be counted only once. This is achieved by creating a set of the successor individuals.\n$4$. **Filter by type**. For each distinct successor $y$, we check if it is an instance of the $Measurement$ class. This corresponds to checking if $y \\in (Measurement)^{\\mathcal{I}}$.\n$5$. **Count and compare**. We count the number of distinct successors that meet the type requirement. Let this count be $c$. The condition is satisfied if $c \\ge 1$.\n\nThis step-by-step procedure is implemented for each of the six test cases provided, yielding a boolean result indicating whether the device in each case is a member of the defined class. For instance, in Case E, device $s_5$ has two distinct successors, $m_2$ and $nm_1$. Of these, only $m_2$ is of type $Measurement$. The count of qualified successors is therefore $1$. Since $1 \\ge 1$, the condition is met and the result is True. In Case D, device $s_4$ has one successor, $nm_1$, which is not of type $Measurement$. The count is $0$. Since $0 < 1$, the condition is not met and the result is False. This logic is applied consistently across all cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Validates devices against a qualified minimum cardinality restriction.\n    \n    The problem asks to implement a check for the Description Logic class expression:\n    SensingDevice ⊓ (≥ 1 hasOutput.Measurement)\n    \n    This means for a device to be valid, it must have at least one distinct\n    successor via the 'hasOutput' property that is of type 'Measurement'.\n    \"\"\"\n\n    # Test suite definition. Each case represents a small knowledge graph\n    # configuration for a single device under test.\n    # Structure: (device_id_to_check, types_dictionary, edges_dictionary)\n    # - types_dictionary: maps individual IDs to a set of their class types.\n    # - edges_dictionary: maps a source ID to a list of target IDs for the\n    #   'hasOutput' property.\n    test_cases = [\n        # Case A: Happy path. s1 has one Measurement output.\n        (\n            's1',\n            {'s1': {'SensingDevice'}, 'm1': {'Measurement'}},\n            {'s1': ['m1']}\n        ),\n        # Case B: Boundary. Duplicate edges to the same output count as one.\n        (\n            's2',\n            {'s2': {'SensingDevice'}, 'm1': {'Measurement'}},\n            {'s2': ['m1', 'm1']}\n        ),\n        # Case C: Edge case. s3 has no outputs.\n        (\n            's3',\n            {'s3': {'SensingDevice'}},\n            {} # No edges for s3\n        ),\n        # Case D: Failure. s4's only output is not a Measurement.\n        (\n            's4',\n            {'s4': {'SensingDevice'}, 'nm1': {'NonMeasurement'}},\n            {'s4': ['nm1']}\n        ),\n        # Case E: Mixed outputs. s5 has one Measurement and one non-Measurement.\n        (\n            's5',\n            {'s5': {'SensingDevice'}, 'm2': {'Measurement'}, 'nm1': {'NonMeasurement'}},\n            {'s5': ['m2', 'nm1']}\n        ),\n        # Case F: Multiple distinct Measurement outputs.\n        (\n            's6',\n            {'s6': {'SensingDevice'}, 'm1': {'Measurement'}, 'm2': {'Measurement'}},\n            {'s6': ['m1', 'm2']}\n        ),\n    ]\n\n    results = []\n    # Parameters for the qualified cardinality restriction\n    target_class = 'Measurement'\n    min_cardinality = 1\n\n    for device_id, types, edges in test_cases:\n        # Retrieve the list of successors for the device via 'hasOutput'.\n        # If the device has no outgoing edges, .get() returns an empty list.\n        successors = edges.get(device_id, [])\n\n        # The semantics require counting *distinct* successors. A set handles this.\n        distinct_successors = set(successors)\n\n        # Count the number of distinct successors that are of the target class.\n        qualified_count = 0\n        for successor_id in distinct_successors:\n            # Get the types of the successor. Default to an empty set if not found.\n            successor_types = types.get(successor_id, set())\n            if target_class in successor_types:\n                qualified_count += 1\n        \n        # Check if the count meets the minimum cardinality requirement.\n        is_satisfied = qualified_count >= min_cardinality\n        results.append(is_satisfied)\n\n    # Format the final output as a comma-separated list of booleans in brackets.\n    # The map(str, ...) converts each boolean (True/False) to its string representation.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While OWL is used to define the conceptual schema and logical axioms of your domain, the Shapes Constraint Language (SHACL) serves the complementary role of ensuring the quality and structure of the instance data within your knowledge graph. For Cyber-Physical Systems, where data reliability is paramount, validating a graph against a set of SHACL shapes is a non-negotiable step in the data lifecycle. In this practice, , you will implement a simplified SHACL validator, giving you first-hand experience in enforcing constraints on cardinalities, datatypes, and value ranges to maintain a high-fidelity digital twin.",
            "id": "4228930",
            "problem": "Consider a simplified validation task over a Knowledge Graph (KG) in the context of Cyber-Physical Systems (CPS), using the Shapes Constraint Language (SHACL). The KG is modeled as a finite Resource Description Framework (RDF) graph with nodes, properties, and typed values. You are to implement a validator that, given a KG snippet and a set of SHACL shapes, computes the total number of violations and the set of nodes causing at least one violation. The task demands a precise implementation based on formal definitions and constraints.\n\nFundamental base:\n- Resource Description Framework (RDF) defines triples as $$(s,p,o) \\in N \\times P \\times (N \\cup L),$$ where $N$ is the set of Internationalized Resource Identifiers (IRIs), $P$ is the set of properties (IRIs), and $L$ is the set of typed literals. A typed literal is a pair $(v, d)$ with $v$ a value and $d$ a datatype.\n- Shapes Constraint Language (SHACL) defines constraints on nodes through shapes. A shape $S$ associates a target class $C$ (identified by an IRI) to a set of property shapes that restrict the values reachable via a property path (IRI). A property shape may constrain: minimum count ($\\text{minCount}$), maximum count ($\\text{maxCount}$), node kind (IRI or literal), datatype (e.g., integer, float, string), and numeric bounds (minimum inclusive, maximum inclusive, or minimum exclusive). A closed shape may also restrict the set of allowed properties.\n\nValidator semantics to implement:\n- A node $n \\in N$ is validated against a shape $S$ if $n$ has an RDF type triple $(n, \\text{rdf:type}, C)$ where $C$ is the target class of $S$.\n- For each property shape with path $p$:\n  - Count constraint: if the number of values for $p$ at $n$ is less than $\\text{minCount}$, or exceeds $\\text{maxCount}$, one violation is recorded for the property shape.\n  - Node kind constraint: for each value of $p$, if a value is not of the expected kind (IRI or literal), one violation is recorded per offending value.\n  - Datatype constraint: for each literal value of $p$, if its datatype does not match the expected datatype, one violation is recorded per offending value.\n  - Numeric bounds: for each numeric literal value (integer or float as appropriate), if it violates a bound (less than $\\text{minInclusive}$, greater than $\\text{maxInclusive}$, or not strictly greater than $\\text{minExclusive}$), one violation is recorded per offending value.\n- For a closed shape, if a node has any property not in the allowed set, one violation is recorded per extraneous property (regardless of its cardinality).\n- The total number of violations is the sum of all recorded violations across all shapes and nodes. A node is considered \"causing\" violations if it has at least one recorded violation under any applicable shape.\n\nAcronyms:\n- Knowledge Graph (KG)\n- Resource Description Framework (RDF)\n- Shapes Constraint Language (SHACL)\n- Cyber-Physical Systems (CPS)\n\nShapes used in all test cases:\n- Sensor shape targeting class IRI \"ex:Sensor\":\n  - Property \"ex:hasSamplingPeriod\": node kind Literal, datatype integer, with $\\text{minCount} = 1$, $\\text{minInclusive} = 1$, $\\text{maxInclusive} = 60$.\n  - Property \"ex:connectedTo\": node kind IRI, with $\\text{minCount} = 1$.\n- Actuator shape targeting class IRI \"ex:Actuator\":\n  - Property \"ex:hasPowerRating\": node kind Literal, datatype float, with $\\text{minExclusive} = 0$.\n  - Property \"ex:controlledBy\": node kind IRI, with $\\text{minCount} = 1$, $\\text{maxCount} = 1$.\n- Controller shape targeting class IRI \"ex:Controller\":\n  - Property \"ex:controls\": node kind IRI, with $\\text{minCount} = 2$.\n  - Closed shape: only properties in the allowed set $\\{\\text{ex:controls}\\}$ are permitted, in addition to $\\{\\text{rdf:type}\\}$ which is always permitted.\n\nKG representation:\n- Each node is a mapping from property IRIs to lists of values.\n- A value is either an IRI or a literal. A literal is represented with a Python value and a datatype IRI. Numeric literals use Python integers or floats appropriately.\n\nYour task:\n- Implement the validator according to the above semantics.\n- Apply it to the test suite below.\n- For each test case, output a pair consisting of the total number of violations and the sorted list of node IRIs that cause at least one violation.\n\nTest suite:\n- Test Case $1$ (general case):\n  - Nodes:\n    - \"ex:S1\": \n      - \"rdf:type\": [\"ex:Sensor\"]\n      - \"ex:hasSamplingPeriod\": integer literal with value $0$\n      - \"ex:connectedTo\": not present\n    - \"ex:S2\":\n      - \"rdf:type\": [\"ex:Sensor\"]\n      - \"ex:hasSamplingPeriod\": integer literal with value $10$\n      - \"ex:connectedTo\": [\"ex:A1\"]\n    - \"ex:A1\":\n      - \"rdf:type\": [\"ex:Actuator\"]\n      - \"ex:hasPowerRating\": float literal with value $-5.0$\n      - \"ex:controlledBy\": [\"ex:C1\"]\n    - \"ex:C1\":\n      - \"rdf:type\": [\"ex:Controller\"]\n      - \"ex:controls\": [\"ex:S2\", \"ex:A1\"]\n      - \"ex:hasExtraProperty\": string literal \"foo\"\n    - \"ex:U1\":\n      - \"rdf:type\": [\"ex:Unknown\"]\n      - \"ex:random\": string literal \"bar\"\n- Test Case $2$ (boundary conditions satisfied except one strict bound):\n  - Nodes:\n    - \"ex:S3\":\n      - \"rdf:type\": [\"ex:Sensor\"]\n      - \"ex:hasSamplingPeriod\": integer literal with value $60$\n      - \"ex:connectedTo\": [\"ex:A2\"]\n    - \"ex:A2\":\n      - \"rdf:type\": [\"ex:Actuator\"]\n      - \"ex:hasPowerRating\": float literal with value $0.0$\n      - \"ex:controlledBy\": [\"ex:C2\"]\n    - \"ex:C2\":\n      - \"rdf:type\": [\"ex:Controller\"]\n      - \"ex:controls\": [\"ex:S3\", \"ex:A2\"]\n- Test Case $3$ (edge cases with datatype and node kind mismatches, and count violations):\n  - Nodes:\n    - \"ex:S4\":\n      - \"rdf:type\": [\"ex:Sensor\"]\n      - \"ex:hasSamplingPeriod\": string literal \"ten\"\n      - \"ex:connectedTo\": string literal \"ex:C3\"\n    - \"ex:A3\":\n      - \"rdf:type\": [\"ex:Actuator\"]\n      - \"ex:hasPowerRating\": float literal with value $10.0$\n      - \"ex:controlledBy\": [\"ex:C3\", \"ex:C4\"]\n    - \"ex:C3\":\n      - \"rdf:type\": [\"ex:Controller\"]\n      - \"ex:controls\": []\n    - \"ex:C4\":\n      - \"rdf:type\": [\"ex:Controller\"]\n      - \"ex:controls\": [\"ex:S4\"]\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each result is of the form $[v, L]$ with $v$ an integer violation count and $L$ a sorted list of node IRIs that cause violations. For example, the output should look like: $$[[v_1, L_1],[v_2, L_2],[v_3, L_3]]$$ with no spaces except those inherent to list formatting. The node IRIs should be sorted in ascending lexicographic order within each $L$.",
            "solution": "The user has provided a problem that requires the implementation of a validator for a Knowledge Graph (KG) based on a subset of the Shapes Constraint Language (SHACL). The problem is well-defined, scientifically grounded in the principles of RDF and SHACL, and provides a clear set of rules and test cases. Therefore, the problem is deemed valid.\n\nThe solution will be implemented by first modeling the KG and the SHACL shapes using Python data structures, and then creating a validation function that systematically applies the specified rules.\n\n**1. Data Representation**\n\n*   **Knowledge Graph (KG):** A KG will be represented as a dictionary mapping node IRIs (strings) to their properties. Each property is, in turn, a dictionary mapping property IRIs (strings) to a list of values.\n*   **Values:** A value can be an Internationalized Resource Identifier (IRI) or a literal.\n    *   An IRI is represented by a Python `str`.\n    *   A literal is represented by a Python `tuple` of the form `(value, datatype_iri)`, where `value` is the literal's value (e.g., an `int`, `float`, or `str`) and `datatype_iri` is a `str` identifying the datatype (e.g., `\"integer\"`, `\"float\"`).\n*   **SHACL Shapes:** The set of shapes will be represented as a dictionary where keys are the target class IRIs (strings). Each value is a dictionary defining the constraints for that shape, including property shapes and whether the shape is closed.\n\n**2. Validator Design**\n\nThe core of the solution is a `validate_kg` function that takes a KG and the shapes definition as input. It will return the total number of violations and a set of nodes that caused at least one violation.\n\nThe validation process proceeds as follows for each node in the KG:\n1.  **Identify Applicable Shapes:** The validator inspects the `rdf:type` property of the node. For each type that matches a target class in the shapes definition, the corresponding shape's constraints are applied to the node.\n2.  **Initialize Violation Count:** A local counter for the current node's violations is initialized to $0$.\n3.  **Apply Shape Constraints:** For each applicable shape, the following checks are performed:\n    *   **Closed Shape Constraint:** If the shape is defined as closed (`closed: true`), the validator iterates through all properties of the node. For each property that is not in the set of allowed properties for the shape, a violation is counted. The property `rdf:type` is implicitly allowed.\n    *   **Property Shape Constraints:** The validator iterates through each property shape defined within the main shape. For each property shape, it applies the following constraints to the values of the corresponding property on the node:\n        *   **Cardinality Constraints (`minCount`, `maxCount`):** The number of values for the property is counted. If this count is less than `minCount` or greater than `maxCount`, a single violation is recorded for the cardinality constraint.\n        *   **Value-level Constraints:** The validator then iterates through each individual value of the property and applies further checks:\n            *   **Node Kind Constraint (`nodeKind`):** It verifies if the value is of the expected kind (IRI or Literal). A violation is recorded for each value that does not match the required kind. If the kind is incorrect, further checks on this value (datatype, numeric bounds) are skipped as they are not applicable.\n            *   **Datatype Constraint (`datatype`):** For literal values, it checks if the literal's datatype IRI matches the one specified in the property shape. A violation is recorded for each mismatch. If the datatype is incorrect, subsequent numeric bound checks are skipped.\n            *   **Numeric Bound Constraints (`minInclusive`, `maxInclusive`, `minExclusive`):** For numeric literals with the correct datatype, the validator checks if the value respects the given bounds. A violation is recorded for each bound that is not satisfied.\n\n4.  **Aggregate Results:** After all applicable shapes have been checked for a node, if the node's local violation counter is greater than $0$, this count is added to the global total violation counter, and the node's IRI is added to a set of violating nodes.\n\n5.  **Final Output:** Once all nodes in the KG have been processed, the function returns the total violation count and the set of violating node IRIs. The main program then sorts the list of violating nodes lexicographically as required.\n\nThis systematic application of the rules ensures that all constraints are checked correctly and that the violation counts are aggregated as specified in the problem statement.\n\nThe implementation will translate these steps into Python code. Helper functions `is_iri` and `is_literal` will be used to distinguish between the two types of values based on their Python representation (`str` vs. `tuple`). The test cases provided in the problem statement will be encoded using these data structures and passed to the validator to generate the final results.\n\nLet's trace `Test Case 1`, Node `ex:C1` as an example:\n*   **Node:** `ex:C1` has `rdf:type` `ex:Controller`.\n*   **Applicable Shape:** The `ex:Controller` shape.\n*   **Validation:**\n    1.  **Closed Shape Constraint:** The shape is closed, with allowed properties being `{\"ex:controls\", \"rdf:type\"}`. The node has a property `ex:hasExtraProperty`, which is not in the allowed set. This generates $1$ violation.\n    2.  **Property Shape `ex:controls`:** The shape requires `minCount = 2` and `nodeKind = IRI`.\n        *   **Cardinality:** The node has two values for `ex:controls`: `[\"ex:S2\", \"ex:A1\"]`. The count is $2$, which satisfies `minCount = 2`. No violation.\n        *   **Value-level:** Both `\"ex:S2\"` and `\"ex:A1\"` are strings, thus correctly identified as IRIs. No violations.\n*   **Total for `ex:C1`:** The node has $1$ violation. It is added to the list of violating nodes.\n\nThis detailed, rule-based process will be implemented for all nodes and all test cases to produce the required output.",
            "answer": "```python\nimport numpy as np\n# No other libraries are permitted, as per the rules.\n\ndef solve():\n    \"\"\"\n    Main function to define shapes, test cases, run validation, and print results.\n    \"\"\"\n\n    # SHACL shapes definition as per the problem statement.\n    # The datatypes 'integer', 'float', 'string' are used as simplified IRIs.\n    shapes = {\n        \"ex:Sensor\": {\n            \"properties\": {\n                \"ex:hasSamplingPeriod\": {\n                    \"nodeKind\": \"Literal\",\n                    \"datatype\": \"integer\",\n                    \"minCount\": 1,\n                    \"minInclusive\": 1,\n                    \"maxInclusive\": 60,\n                },\n                \"ex:connectedTo\": {\n                    \"nodeKind\": \"IRI\",\n                    \"minCount\": 1,\n                },\n            },\n            \"closed\": False,\n        },\n        \"ex:Actuator\": {\n            \"properties\": {\n                \"ex:hasPowerRating\": {\n                    \"nodeKind\": \"Literal\",\n                    \"datatype\": \"float\",\n                    \"minExclusive\": 0.0,\n                },\n                \"ex:controlledBy\": {\n                    \"nodeKind\": \"IRI\",\n                    \"minCount\": 1,\n                    \"maxCount\": 1,\n                },\n            },\n            \"closed\": False,\n        },\n        \"ex:Controller\": {\n            \"properties\": {\n                \"ex:controls\": {\n                    \"nodeKind\": \"IRI\",\n                    \"minCount\": 2,\n                },\n            },\n            \"closed\": True,\n            \"allowedProperties\": {\"rdf:type\", \"ex:controls\"},\n        },\n    }\n\n    # Test suite definition. Literals are represented as (value, datatype_iri) tuples.\n    # IRIs are represented as strings.\n    test_cases = [\n        # Test Case 1\n        {\n            \"ex:S1\": {\n                \"rdf:type\": [\"ex:Sensor\"],\n                \"ex:hasSamplingPeriod\": [(0, \"integer\")],\n            },\n            \"ex:S2\": {\n                \"rdf:type\": [\"ex:Sensor\"],\n                \"ex:hasSamplingPeriod\": [(10, \"integer\")],\n                \"ex:connectedTo\": [\"ex:A1\"],\n            },\n            \"ex:A1\": {\n                \"rdf:type\": [\"ex:Actuator\"],\n                \"ex:hasPowerRating\": [(-5.0, \"float\")],\n                \"ex:controlledBy\": [\"ex:C1\"],\n            },\n            \"ex:C1\": {\n                \"rdf:type\": [\"ex:Controller\"],\n                \"ex:controls\": [\"ex:S2\", \"ex:A1\"],\n                \"ex:hasExtraProperty\": [(\"foo\", \"string\")],\n            },\n            \"ex:U1\": {\n                \"rdf:type\": [\"ex:Unknown\"],\n                \"ex:random\": [(\"bar\", \"string\")],\n            },\n        },\n        # Test Case 2\n        {\n            \"ex:S3\": {\n                \"rdf:type\": [\"ex:Sensor\"],\n                \"ex:hasSamplingPeriod\": [(60, \"integer\")],\n                \"ex:connectedTo\": [\"ex:A2\"],\n            },\n            \"ex:A2\": {\n                \"rdf:type\": [\"ex:Actuator\"],\n                \"ex:hasPowerRating\": [(0.0, \"float\")],\n                \"ex:controlledBy\": [\"ex:C2\"],\n            },\n            \"ex:C2\": {\n                \"rdf:type\": [\"ex:Controller\"],\n                \"ex:controls\": [\"ex:S3\", \"ex:A2\"],\n            },\n        },\n        # Test Case 3\n        {\n            \"ex:S4\": {\n                \"rdf:type\": [\"ex:Sensor\"],\n                \"ex:hasSamplingPeriod\": [(\"ten\", \"string\")],\n                \"ex:connectedTo\": [(\"ex:C3\", \"string\")],\n            },\n            \"ex:A3\": {\n                \"rdf:type\": [\"ex:Actuator\"],\n                \"ex:hasPowerRating\": [(10.0, \"float\")],\n                \"ex:controlledBy\": [\"ex:C3\", \"ex:C4\"],\n            },\n            \"ex:C3\": {\n                \"rdf:type\": [\"ex:Controller\"],\n                \"ex:controls\": [],\n            },\n            \"ex:C4\": {\n                \"rdf:type\": [\"ex:Controller\"],\n                \"ex:controls\": [\"ex:S4\"],\n            },\n        },\n    ]\n\n    results = []\n    for kg in test_cases:\n        total_violations, violating_nodes = validate_kg(kg, shapes)\n        results.append([total_violations, sorted(list(violating_nodes))])\n        \n    # Format the final output string precisely as required.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef is_iri(value):\n    \"\"\"Checks if a value represents an IRI (is a string).\"\"\"\n    return isinstance(value, str)\n\ndef is_literal(value):\n    \"\"\"Checks if a value represents a Literal (is a (value, type) tuple).\"\"\"\n    return isinstance(value, tuple) and len(value) == 2 and isinstance(value[1], str)\n\ndef validate_kg(kg, shapes):\n    \"\"\"\n    Validates a Knowledge Graph against a set of SHACL shapes.\n    \n    Args:\n        kg (dict): The Knowledge Graph to validate.\n        shapes (dict): The SHACL shapes definition.\n        \n    Returns:\n        tuple: A pair (total_violations, violating_nodes_set).\n    \"\"\"\n    total_violations = 0\n    violating_nodes = set()\n\n    for node_iri, node_data in kg.items():\n        node_violations = 0\n        node_types = node_data.get(\"rdf:type\", [])\n        \n        for node_type in node_types:\n            if node_type not in shapes:\n                continue\n            \n            shape = shapes[node_type]\n            \n            # --- Closed Shape Validation ---\n            if shape.get(\"closed\", False):\n                allowed_props = shape.get(\"allowedProperties\", set())\n                for prop in node_data.keys():\n                    if prop not in allowed_props:\n                        node_violations += 1\n\n            # --- Property Shape Validation ---\n            for prop_iri, prop_shape in shape.get(\"properties\", {}).items():\n                values = node_data.get(prop_iri, [])\n                num_values = len(values)\n\n                # Count Constraints\n                if \"minCount\" in prop_shape and num_values < prop_shape[\"minCount\"]:\n                    node_violations += 1\n                if \"maxCount\" in prop_shape and num_values > prop_shape[\"maxCount\"]:\n                    node_violations += 1\n                \n                # Value-level Constraints\n                for value in values:\n                    # Node Kind Constraint\n                    if \"nodeKind\" in prop_shape:\n                        kind = prop_shape[\"nodeKind\"]\n                        if kind == \"IRI\" and not is_iri(value):\n                            node_violations += 1\n                            continue\n                        if kind == \"Literal\" and not is_literal(value):\n                            node_violations += 1\n                            continue\n                    \n                    if is_literal(value):\n                        lit_val, lit_type = value\n                        \n                        # Datatype Constraint\n                        if \"datatype\" in prop_shape and lit_type != prop_shape[\"datatype\"]:\n                            node_violations += 1\n                            continue\n                        \n                        # Numeric Bounds Constraints (only for numeric Python types)\n                        if isinstance(lit_val, (int, float)):\n                            if \"minInclusive\" in prop_shape and lit_val < prop_shape[\"minInclusive\"]:\n                                node_violations += 1\n                            if \"maxInclusive\" in prop_shape and lit_val > prop_shape[\"maxInclusive\"]:\n                                node_violations += 1\n                            if \"minExclusive\" in prop_shape and lit_val <= prop_shape[\"minExclusive\"]:\n                                node_violations += 1\n\n        if node_violations > 0:\n            total_violations += node_violations\n            violating_nodes.add(node_iri)\n            \n    return total_violations, violating_nodes\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "Real-world knowledge graphs are often built by integrating data from multiple, heterogeneous sources, which inevitably leads to a fundamental challenge: entity resolution. Deciding whether two different descriptions or nodes actually refer to the same physical asset is a crucial step in creating a clean, non-redundant digital twin. This advanced practice, , guides you through implementing a sophisticated, multi-criteria workflow for this very task. By combining evidence from string similarity, property constraints, and data provenance, you will learn to build a robust decision-making engine that mirrors the complex logic required for practical data integration.",
            "id": "4228994",
            "problem": "In a Knowledge Graph (KG) for Cyber-Physical Systems (CPS), entity resolution must decide whether two nodes represent the same physical component. Construct a mathematically grounded workflow that uses string similarity, property constraints, and provenance to decide identity merges. Implement a program that, for a given test suite of candidate pairs, outputs whether each pair should be merged. The workflow should be derived from first principles of equivalence relations and multi-criteria decision rules.\n\nFundamental base and definitions:\n- An identity merge must satisfy the logic of an equivalence relation: reflexivity, symmetry, and transitivity. In practice, the decision rule must be symmetric with respect to the two entities and grounded in observable properties and provenance.\n- Let $A$ and $B$ denote two entities with attributes. Define a token-based string similarity $s_{\\text{name}} \\in [0,1]$ as the Jaccard similarity between token sets extracted from names. Tokenization must convert to lowercase and split on any non-alphanumeric character, discarding empty tokens. For tokens $T_A$ and $T_B$, let\n$$\ns_{\\text{name}} = \\frac{|T_A \\cap T_B|}{|T_A \\cup T_B|}.\n$$\n- Define a three-dimensional Euclidean location distance $d$ between coordinates $(x_A,y_A,z_A)$ and $(x_B,y_B,z_B)$, with\n$$\nd = \\sqrt{(x_A - x_B)^2 + (y_A - y_B)^2 + (z_A - z_B)^2},\n$$\nexpressed in $\\mathrm{m}$ (meters).\n- Define a location closeness score $s_{\\text{loc}} \\in [0,1]$ by\n$$\ns_{\\text{loc}} = \\max\\left(0, 1 - \\frac{d}{D_{\\text{max}}}\\right),\n$$\nwith $D_{\\text{max}} = 10 \\ \\mathrm{m}$.\n- Let indicator signals be defined for properties that contribute to similarity when they are available on both entities:\n  - Serial number indicator $I_{\\text{serial}} = 1$ if both serial numbers exist and are equal; otherwise undefined if one or both are missing; it is never $0$ because differing serials are handled as a hard constraint failure below.\n  - Manufacturer indicator $I_{\\text{manuf}} = 1$ if both manufacturers exist and are equal, and $0$ if both exist and differ; undefined if one or both are missing.\n- Define a property similarity $s_{\\text{prop}} \\in [0,1]$ as the mean of all defined signals among $\\{s_{\\text{loc}}, I_{\\text{serial}}, I_{\\text{manuf}}\\}$. If none are defined, set $s_{\\text{prop}} = 0$.\n- Define a convex combination\n$$\n\\sigma = w_s \\, s_{\\text{name}} + w_p \\, s_{\\text{prop}},\n$$\nwith weights $w_s = 0.6$ and $w_p = 0.4$, satisfying $w_s + w_p = 1$.\n- Let provenance trust values $t_A \\in [0,1]$ and $t_B \\in [0,1]$ be assigned to entities $A$ and $B$. Define the pairwise trust dampening\n$$\n\\tau = \\min(t_A, t_B),\n$$\nand the damped combined score\n$$\n\\sigma' = \\tau \\, \\sigma.\n$$\n- Define hard constraints that must hold prior to scoring:\n  1. If both serial numbers exist and are different, then do not merge.\n  2. If both types exist and are different, then do not merge.\n  3. If both units exist and are different, then do not merge.\n  4. If $d > D_{\\text{hard}}$ with $D_{\\text{hard}} = 10 \\ \\mathrm{m}$, then do not merge.\n- Define a serial override consistent with physical identity: if both serial numbers exist and are equal, and none of the hard constraints are violated, then merge regardless of $\\sigma'$.\n- Otherwise, adopt the decision rule: merge if and only if $\\sigma' \\ge \\theta$ with threshold $\\theta = 0.5$.\n\nYour task is to implement this workflow in a program. Physical units to use for distance are $\\mathrm{m}$ (meters). No angle units are involved. The output for each candidate pair must be a boolean.\n\nTest suite:\nUse the following eight candidate pairs as inputs. Each entity is specified as a dictionary of attributes: name (string), type (string or None), unit (string or None), manufacturer (string or None), serial (string or None), location (triplet of floats in $\\mathrm{m}$), trust (float in $[0,1]$).\n\n1. Happy path with serial equality and close location:\n   - $A$: name \"Temp Sensor A\", type \"sensor\", unit \"Celsius\", manufacturer \"Acme\", serial \"SN-001\", location $(0,0,0)$ $\\mathrm{m}$, trust $0.9$.\n   - $B$: name \"Temperature Sensor A\", type \"sensor\", unit \"Celsius\", manufacturer \"Acme\", serial \"SN-001\", location $(3,0,0)$ $\\mathrm{m}$, trust $0.8$.\n2. Boundary location case at $10 \\ \\mathrm{m}$ with serial equality:\n   - $A$: name \"Pump-01\", type \"actuator\", unit \"L/s\", manufacturer \"Globex\", serial \"P01X\", location $(100,50,0)$ $\\mathrm{m}$, trust $0.7$.\n   - $B$: name \"Pump01\", type \"actuator\", unit \"L/s\", manufacturer \"Globex\", serial \"P01X\", location $(110,50,0)$ $\\mathrm{m}$, trust $0.7$.\n3. Unit mismatch case:\n   - $A$: name \"Room Temp Sensor\", type \"sensor\", unit \"Celsius\", manufacturer \"Acme\", serial \"SN-777\", location $(10,10,2)$ $\\mathrm{m}$, trust $0.95$.\n   - $B$: name \"Room Temperature Sensor\", type \"sensor\", unit \"Kelvin\", manufacturer \"Acme\", serial \"SN-778\", location $(11,11,2)$ $\\mathrm{m}$, trust $0.9$.\n4. Type mismatch case:\n   - $A$: name \"Valve Position Unit 7\", type \"sensor\", unit \"position\", manufacturer \"Initech\", serial \"VP-007\", location $(25,0,0)$ $\\mathrm{m}$, trust $0.85$.\n   - $B$: name \"Valve Controller 7\", type \"actuator\", unit \"position\", manufacturer \"Initech\", serial \"VC-007\", location $(25.5,0,0)$ $\\mathrm{m}$, trust $0.9$.\n5. High similarity but low provenance trust:\n   - $A$: name \"Motor RPM Sensor\", type \"sensor\", unit \"RPM\", manufacturer \"Acme\", serial None, location $(200,75,0)$ $\\mathrm{m}$, trust $0.3$.\n   - $B$: name \"Motor Rotation Sensor\", type \"sensor\", unit \"RPM\", manufacturer \"Acme\", serial None, location $(202,77,0)$ $\\mathrm{m}$, trust $0.4$.\n6. Different names but equal serial numbers:\n   - $A$: name \"Building B Floor 2 Zone 3 Thermistor\", type \"sensor\", unit \"Celsius\", manufacturer \"ThermoCorp\", serial \"TH-2203\", location $(500,200,5)$ $\\mathrm{m}$, trust $0.9$.\n   - $B$: name \"Z3-B2 Temperature Probe\", type \"sensor\", unit \"Celsius\", manufacturer \"ThermoCorp\", serial \"TH-2203\", location $(503,201,5)$ $\\mathrm{m}$, trust $0.85$.\n7. Missing unit on one entity:\n   - $A$: name \"Humidity Sensor East\", type \"sensor\", unit None, manufacturer \"EnviroSys\", serial None, location $(0,50,0)$ $\\mathrm{m}$, trust $0.95$.\n   - $B$: name \"East Humidity Sensor\", type \"sensor\", unit \"percent\", manufacturer \"EnviroSys\", serial None, location $(0.5,50.2,0)$ $\\mathrm{m}$, trust $0.9$.\n8. Location just above the hard threshold:\n   - $A$: name \"Pressure Sensor North\", type \"sensor\", unit \"bar\", manufacturer \"Acme\", serial \"PSN-100\", location $(0,0,0)$ $\\mathrm{m}$, trust $0.9$.\n   - $B$: name \"North Pressure Sensor\", type \"sensor\", unit \"bar\", manufacturer \"Acme\", serial \"PSN-101\", location $(0,10.0001,0)$ $\\mathrm{m}$, trust $0.9$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,...]\"). Each result must be a boolean corresponding to the merge decision for the respective test case in the order given. The physical distance must be computed in $\\mathrm{m}$, and booleans must be printed as either \"True\" or \"False\".",
            "solution": "The problem requires the construction and implementation of a rigorous, mathematically-grounded workflow for entity resolution in a Knowledge Graph for Cyber-Physical Systems (CPS). The workflow must decide whether two entities, $A$ and $B$, represent the same physical component. The provided specification is self-contained, logically consistent, and scientifically sound, forming a valid basis for a solution. The core of the solution is a multi-stage decision process derived from first principles of evidence fusion and rule-based logic.\n\nThe logical foundation of the decision process is designed to approximate an equivalence relation. The decision rule for a pair $(A, B)$ is symmetric, as all calculations (Jaccard similarity, Euclidean distance, minimum of trust scores) are symmetric with respect to the order of $A$ and $B$. This ensures that the decision for $(A, B)$ is identical to the decision for $(B, A)$.\n\nThe workflow is structured as a hierarchical application of rules, proceeding from definitive evidence to probabilistic scoring:\n\nStep 1: Hard Constraint Evaluation\nThis initial step serves as a set of inviolable falsification rules. If any of these conditions are met, the hypothesis that $A$ and $B$ are identical is immediately rejected. These constraints represent strong negative evidence that is sufficient to terminate the process.\nLet $d$ be the Euclidean distance in meters ($\\mathrm{m}$) between the locations of entities $A$ and $B$. The hard constraints are:\n1.  If both entities have serial numbers and they are different, they cannot be the same component.\n2.  If both entities have types and they are different (e.g., 'sensor' vs. 'actuator'), they are functionally distinct and thus not identical.\n3.  If both entities have specified units and they are different (e.g., 'Celsius' vs. 'Kelvin'), they measure different physical properties or use incompatible scales, implying they are not the same component.\n4.  If the physical distance $d$ exceeds a hard threshold, $D_{\\text{hard}} = 10 \\ \\mathrm{m}$, the entities are considered too far apart to be the same component. The rule is to not merge if $d > 10$.\n\nStep 2: Serial Number Override\nThis step represents a form of strong positive evidence. A serial number is typically a unique identifier for a physical device.\nThe rule is as follows: if both entities have serial numbers, they are identical, and none of the hard constraints from Step 1 are violated, the entities are merged. This decision is made regardless of any other similarity scores, as the matching serial numbers provide overwhelming evidence of identity.\n\nStep 3: Probabilistic Scoring and Thresholding\nIf the decision is not resolved by the definitive rules in Steps 1 and 2, a scoring mechanism is employed to weigh the combined evidence. This applies when information is incomplete (e.g., missing serial numbers) or conflicting.\n\nFirst, two primary similarity scores are calculated:\n    - String Similarity, $s_{\\text{name}}$: The Jaccard similarity of name tokens, $s_{\\text{name}} = \\frac{|T_A \\cap T_B|}{|T_A \\cup T_B|}$, where $T_A$ and $T_B$ are the sets of alphanumeric tokens from the lowercase names of the entities. This measures semantic overlap in their descriptions.\n    - Property Similarity, $s_{\\text{prop}}$: This score aggregates similarity across various physical and logical attributes. It is the arithmetic mean of the defined indicator signals from the set $\\{s_{\\text{loc}}, I_{\\text{serial}}, I_{\\text{manuf}}\\}$.\n        - Location Closeness, $s_{\\text{loc}} = \\max\\left(0, 1 - \\frac{d}{D_{\\text{max}}}\\right)$ with $D_{\\text{max}} = 10 \\ \\mathrm{m}$. This score is $1$ for co-located entities and decays linearly to $0$ as the distance $d$ approaches $10 \\ \\mathrm{m}$.\n        - Serial Number Indicator, $I_{\\text{serial}}$: This is $1$ if serial numbers match. However, due to the logic flow (Step 1 and 2), this signal is never defined at Step 3. If serials matched, the override would have triggered; if they differed, a hard constraint would have failed. This step only runs if at least one serial is missing.\n        - Manufacturer Indicator, $I_{\\text{manuf}}$: This is $1$ if manufacturers match and $0$ if they differ (assuming both are known).\n\nNext, these scores are combined into a single score, $\\sigma$, using a convex combination: $\\sigma = w_s s_{\\text{name}} + w_p s_{\\text{prop}}$, with weights $w_s = 0.6$ and $w_p = 0.4$. This reflects a greater emphasis on name similarity.\n\nFinally, the score is dampened by a provenance trust factor. Data sources in a real-world KG have varying reliability. The pairwise trust dampening, $\\tau = \\min(t_A, t_B)$, ensures that a match is only as trustworthy as the least trusted source. The damped score is $\\sigma' = \\tau \\sigma$.\n\nThe final decision is made by comparing this damped score to a threshold $\\theta = 0.5$. A merge is performed if and only if $\\sigma' \\ge 0.5$.\n\nApplying this workflow to the test suite:\n\nCase 1: $A($ `...serial=\"SN-001\"`$, ...)$, $B($ `...serial=\"SN-001\"`$, ...)$.\n- Hard constraints: All pass.\n- Serial override: Serials exist and are equal. Rule applies. Decision: **True**.\n\nCase 2: $A($ `...serial=\"P01X\"`$, loc=(100,50,0))$, $B($ `...serial=\"P01X\"`$, loc=(110,50,0))$.\n- Distance $d = 10.0 \\ \\mathrm{m}$. Hard constraint $d > 10$ is not met. All other hard constraints pass.\n- Serial override: Serials exist and are equal. Rule applies. Decision: **True**.\n\nCase 3: $A($ `...unit=\"Celsius\", serial=\"SN-777\"`$), B($ `...unit=\"Kelvin\", serial=\"SN-778\"`$)$.\n- Hard constraint: Units exist and are different. Rule applies. Decision: **False**.\n- Hard constraint: Serials exist and are different. Rule also applies. Decision: **False**.\n\nCase 4: $A($ `...type=\"sensor\", serial=\"VP-007\"`$), B($ `...type=\"actuator\", serial=\"VC-007\"`$)$.\n- Hard constraint: Types exist and are different. Rule applies. Decision: **False**.\n- Hard constraint: Serials exist and are different. Rule also applies. Decision: **False**.\n\nCase 5: $A($ `...trust=0.3`$), B($ `...trust=0.4`$)$. No serials.\n- Hard constraints: All pass. Serial override: Not applicable.\n- Scoring:\n    - $s_{\\text{name}}$ for names \"Motor RPM Sensor\" and \"Motor Rotation Sensor\" is $2/4 = 0.5$.\n    - $d = \\sqrt{(202-200)^2 + (77-75)^2} = \\sqrt{8} \\approx 2.828 \\ \\mathrm{m}$.\n    - $s_{\\text{loc}} = 1 - \\sqrt{8}/10 \\approx 0.717$. $I_{\\text{manuf}} = 1$ (both \"Acme\"). $I_{\\text{serial}}$ is undefined.\n    - $s_{\\text{prop}} = (0.717 + 1)/2 = 0.8585$.\n    - $\\sigma = 0.6 \\times 0.5 + 0.4 \\times 0.8585 = 0.3 + 0.3434 = 0.6434$.\n    - $\\tau = \\min(0.3, 0.4) = 0.3$.\n    - $\\sigma' = 0.3 \\times 0.6434 = 0.193$.\n- Decision: $0.193 < 0.5$. **False**.\n\nCase 6: $A($ `...name=\"Building B...\", serial=\"TH-2203\"`$), B($ `...name=\"Z3-B2...\", serial=\"TH-2203\"`$)$.\n- Hard constraints: All pass.\n- Serial override: Serials exist and are equal. Rule applies. Decision: **True**.\n\nCase 7: $A($ `...unit=None`$), B($ `...unit=\"percent\"`$)$. No serials.\n- Hard constraints: All pass (unit constraint requires *both* to exist). Serial override: Not applicable.\n- Scoring:\n    - $s_{\\text{name}}$ for \"Humidity Sensor East\" and \"East Humidity Sensor\" is $3/3 = 1.0$.\n    - $d = \\sqrt{0.5^2 + 0.2^2} = \\sqrt{0.29} \\approx 0.539 \\ \\mathrm{m}$.\n    - $s_{\\text{loc}} = 1 - \\sqrt{0.29}/10 \\approx 0.946$. $I_{\\text{manuf}} = 1$.\n    - $s_{\\text{prop}} = (0.946 + 1)/2 = 0.973$.\n    - $\\sigma = 0.6 \\times 1.0 + 0.4 \\times 0.973 = 0.6 + 0.3892 = 0.9892$.\n    - $\\tau = \\min(0.95, 0.9) = 0.9$.\n    - $\\sigma' = 0.9 \\times 0.9892 \\approx 0.89$.\n- Decision: $0.89 \\ge 0.5$. **True**.\n\nCase 8: $A($ `loc=(0,0,0)`$), B($ `loc=(0,10.0001,0)`$)$. Serials differ.\n- Distance $d = 10.0001 \\ \\mathrm{m}$.\n- Hard constraint: Serials exist and are different. Rule applies. Decision: **False**.\n- Hard constraint: $d = 10.0001 > 10$. Rule also applies. Decision: **False**.",
            "answer": "```python\nimport numpy as np\nimport re\n\ndef solve():\n    \"\"\"\n    Main function to run the entity resolution workflow on a test suite.\n    \"\"\"\n    \n    # Define constants from the problem statement.\n    D_MAX = 10.0\n    D_HARD = 10.0\n    W_S = 0.6\n    W_P = 0.4\n    THETA = 0.5\n\n    test_cases = [\n        # Case 1\n        (\n            {\"name\": \"Temp Sensor A\", \"type\": \"sensor\", \"unit\": \"Celsius\", \"manufacturer\": \"Acme\", \"serial\": \"SN-001\", \"location\": (0, 0, 0), \"trust\": 0.9},\n            {\"name\": \"Temperature Sensor A\", \"type\": \"sensor\", \"unit\": \"Celsius\", \"manufacturer\": \"Acme\", \"serial\": \"SN-001\", \"location\": (3, 0, 0), \"trust\": 0.8},\n        ),\n        # Case 2\n        (\n            {\"name\": \"Pump-01\", \"type\": \"actuator\", \"unit\": \"L/s\", \"manufacturer\": \"Globex\", \"serial\": \"P01X\", \"location\": (100, 50, 0), \"trust\": 0.7},\n            {\"name\": \"Pump01\", \"type\": \"actuator\", \"unit\": \"L/s\", \"manufacturer\": \"Globex\", \"serial\": \"P01X\", \"location\": (110, 50, 0), \"trust\": 0.7},\n        ),\n        # Case 3\n        (\n            {\"name\": \"Room Temp Sensor\", \"type\": \"sensor\", \"unit\": \"Celsius\", \"manufacturer\": \"Acme\", \"serial\": \"SN-777\", \"location\": (10, 10, 2), \"trust\": 0.95},\n            {\"name\": \"Room Temperature Sensor\", \"type\": \"sensor\", \"unit\": \"Kelvin\", \"manufacturer\": \"Acme\", \"serial\": \"SN-778\", \"location\": (11, 11, 2), \"trust\": 0.9},\n        ),\n        # Case 4\n        (\n            {\"name\": \"Valve Position Unit 7\", \"type\": \"sensor\", \"unit\": \"position\", \"manufacturer\": \"Initech\", \"serial\": \"VP-007\", \"location\": (25, 0, 0), \"trust\": 0.85},\n            {\"name\": \"Valve Controller 7\", \"type\": \"actuator\", \"unit\": \"position\", \"manufacturer\": \"Initech\", \"serial\": \"VC-007\", \"location\": (25.5, 0, 0), \"trust\": 0.9},\n        ),\n        # Case 5\n        (\n            {\"name\": \"Motor RPM Sensor\", \"type\": \"sensor\", \"unit\": \"RPM\", \"manufacturer\": \"Acme\", \"serial\": None, \"location\": (200, 75, 0), \"trust\": 0.3},\n            {\"name\": \"Motor Rotation Sensor\", \"type\": \"sensor\", \"unit\": \"RPM\", \"manufacturer\": \"Acme\", \"serial\": None, \"location\": (202, 77, 0), \"trust\": 0.4},\n        ),\n        # Case 6\n        (\n            {\"name\": \"Building B Floor 2 Zone 3 Thermistor\", \"type\": \"sensor\", \"unit\": \"Celsius\", \"manufacturer\": \"ThermoCorp\", \"serial\": \"TH-2203\", \"location\": (500, 200, 5), \"trust\": 0.9},\n            {\"name\": \"Z3-B2 Temperature Probe\", \"type\": \"sensor\", \"unit\": \"Celsius\", \"manufacturer\": \"ThermoCorp\", \"serial\": \"TH-2203\", \"location\": (503, 201, 5), \"trust\": 0.85},\n        ),\n        # Case 7\n        (\n            {\"name\": \"Humidity Sensor East\", \"type\": \"sensor\", \"unit\": None, \"manufacturer\": \"EnviroSys\", \"serial\": None, \"location\": (0, 50, 0), \"trust\": 0.95},\n            {\"name\": \"East Humidity Sensor\", \"type\": \"sensor\", \"unit\": \"percent\", \"manufacturer\": \"EnviroSys\", \"serial\": None, \"location\": (0.5, 50.2, 0), \"trust\": 0.9},\n        ),\n        # Case 8\n        (\n            {\"name\": \"Pressure Sensor North\", \"type\": \"sensor\", \"unit\": \"bar\", \"manufacturer\": \"Acme\", \"serial\": \"PSN-100\", \"location\": (0, 0, 0), \"trust\": 0.9},\n            {\"name\": \"North Pressure Sensor\", \"type\": \"sensor\", \"unit\": \"bar\", \"manufacturer\": \"Acme\", \"serial\": \"PSN-101\", \"location\": (0, 10.0001, 0), \"trust\": 0.9},\n        ),\n    ]\n\n    def tokenize(name_str):\n        \"\"\"Converts a name string to a set of lowercase alphanumeric tokens.\"\"\"\n        if not name_str:\n            return set()\n        # Split on any sequence of one or more non-alphanumeric characters\n        tokens = re.split(r'[^a-zA-Z0-9]+', name_str.lower())\n        # Filter out empty strings that result from splitting\n        return {token for token in tokens if token}\n\n    def decide_merge(entity_a, entity_b):\n        \"\"\"\n        Implements the complete decision workflow for a pair of entities.\n        \"\"\"\n        # Step 1: Calculate distance and check hard constraints\n        loc_a, loc_b = np.array(entity_a['location']), np.array(entity_b['location'])\n        distance = np.linalg.norm(loc_a - loc_b)\n\n        if distance > D_HARD:\n            return False\n        \n        serial_a, serial_b = entity_a['serial'], entity_b['serial']\n        if serial_a is not None and serial_b is not None and serial_a != serial_b:\n            return False\n\n        type_a, type_b = entity_a['type'], entity_b['type']\n        if type_a is not None and type_b is not None and type_a != type_b:\n            return False\n\n        unit_a, unit_b = entity_a['unit'], entity_b['unit']\n        if unit_a is not None and unit_b is not None and unit_a != unit_b:\n            return False\n\n        # Step 2: Serial number override\n        if serial_a is not None and serial_a == serial_b:\n            return True\n\n        # Step 3: Probabilistic scoring and thresholding\n        \n        # String similarity\n        tokens_a = tokenize(entity_a['name'])\n        tokens_b = tokenize(entity_b['name'])\n        intersection_size = len(tokens_a.intersection(tokens_b))\n        union_size = len(tokens_a.union(tokens_b))\n        s_name = intersection_size / union_size if union_size > 0 else 0\n\n        # Property similarity\n        prop_signals = []\n        \n        # Location closeness\n        s_loc = max(0, 1 - (distance / D_MAX))\n        prop_signals.append(s_loc)\n        \n        # Manufacturer indicator\n        manuf_a, manuf_b = entity_a['manufacturer'], entity_b['manufacturer']\n        if manuf_a is not None and manuf_b is not None:\n            i_manuf = 1.0 if manuf_a == manuf_b else 0.0\n            prop_signals.append(i_manuf)\n            \n        # Serial indicator is never defined at this stage, per the problem logic\n\n        s_prop = np.mean(prop_signals) if prop_signals else 0\n\n        # Combined score\n        sigma = W_S * s_name + W_P * s_prop\n\n        # Provenance damping\n        tau = min(entity_a['trust'], entity_b['trust'])\n        sigma_prime = tau * sigma\n\n        # Final decision\n        return sigma_prime >= THETA\n\n    results = []\n    for case in test_cases:\n        entity_a, entity_b = case\n        result = decide_merge(entity_a, entity_b)\n        results.append(result)\n\n    # Format the final output as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}