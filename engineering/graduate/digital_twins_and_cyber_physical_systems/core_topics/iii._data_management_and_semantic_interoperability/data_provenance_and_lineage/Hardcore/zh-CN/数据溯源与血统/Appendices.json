{
    "hands_on_practices": [
        {
            "introduction": "在任何溯源系统中，每个数据工件都需要一个唯一的标识符。加密哈希是实现此目的的常用方法，但在大规模系统中，“哈希碰撞”（即两个不同的工件获得相同的ID）的风险成为一个现实的威胁。本练习  提供了一个使用“生日问题”来动手计算这种风险的机会，阐明了为什么选择足够大的哈希值大小对于维护数据血缘的基本完整性至关重要。",
            "id": "4212518",
            "problem": "一个用于国家级信息物理系统（CPS）的数字孪生（DT）来源账本，为每个传感器事件记录了不可变的谱系构件。每个构件由一个加密哈希函数的截断输出进行标识，该函数被建模为一个向大小为 $2^{k}$ 的有限集进行的均匀随机映射，且每次抽取都是独立的。为提高存储效率，系统将安全哈希算法256（SHA-256）的输出截断为 $k = 64$ 位。在一个 $8$ 小时的摄取窗口期内， $200{,}000$ 个传感器每个每分钟发出 $10$ 条谱系记录，每条记录都成为账本中的一个构件。\n\n仅从对有限集进行均匀独立抽样的定义和概率论的基本法则出发，推导在 $n$ 个构件被哈希到 $2^{k}$ 个可能的输出中，至少发生一次碰撞的概率的近似表达式。然后，针对所述的摄取窗口，对此近似值进行数值计算。\n\n将最终概率以小数形式表示，并四舍五入到四位有效数字。\n\n最后，在所述的建模假设下，解释此概率对此类数字孪生来源账本中谱系完整性的影响。",
            "solution": "该问题提法明确且有科学依据。它展示了计算机科学和密码学中的一个经典场景，即“生日问题”，并将其应用于信息物理系统中的数据来源背景。我们可以进行形式化分析。\n\n首先，我们必须确定在指定时间窗口内生成并哈希的构件总数 $n$。\n\n给定参数如下：\n- 传感器数量，$S = 200{,}000 = 2 \\times 10^5$。\n- 每个传感器的记录发出速率，$R = 10 \\text{ 条记录}/\\text{分钟}$。\n- 摄取窗口持续时间，$T = 8 \\text{ 小时}$。\n\n为计算 $n$，我们首先将持续时间 $T$ 转换为分钟：\n$$T = 8 \\text{ hours} \\times \\frac{60 \\text{ minutes}}{1 \\text{ hour}} = 480 \\text{ minutes}$$\n\n构件总数 $n$ 是传感器数量、发出速率和以分钟为单位的时间持续时间的乘积：\n$$n = S \\times R \\times T = (2 \\times 10^5) \\times 10 \\times 480 = 960 \\times 10^6 = 9.6 \\times 10^8$$\n\n哈希函数将输出截断为 $k=64$ 位。可能的哈希输出集合的大小为 $M$，其中：\n$$M = 2^k = 2^{64}$$\n\n问题将哈希函数建模为具有独立抽样的均匀随机映射。这意味着对于 $n$ 个构件中的每一个，其产生的哈希值都是从 $M$ 个可能的输出中均匀且独立地选择的。$n$ 个哈希值的可能序列总数为 $M^n$。\n\n我们要求的是至少发生一次碰撞的概率，记为 $P_c$。更直接的方法是先计算其互补事件的概率：即没有碰撞发生。设此概率为 $P_{nc}$。那么，$P_c = 1 - P_{nc}$。\n\n为使没有碰撞发生，所有 $n$ 个哈希值必须互不相同。从 $M$ 个可能性中不放回地选择 $n$ 个不同哈希值的方法数由降阶乘 $P(M, n)$ 给出：\n$$P(M, n) = M(M-1)(M-2)\\cdots(M-n+1) = \\frac{M!}{(M-n)!}$$\n一个特定的包含 $n$ 个不同哈希值的序列的概率是 $1/M^n$。因此，获得任何没有碰撞的序列的概率是：\n$$P_{nc} = \\frac{M(M-1)\\cdots(M-n+1)}{M^n} = \\frac{M}{M} \\cdot \\frac{M-1}{M} \\cdot \\frac{M-2}{M} \\cdots \\frac{M-n+1}{M}$$\n这可以表示为乘积形式：\n$$P_{nc} = \\prod_{i=0}^{n-1} \\left(1 - \\frac{i}{M}\\right)$$\n\n对于本问题中 $n$ 和 $M$ 的巨大数值，精确计算是不可行的。我们必须使用一个近似，并按要求从基本原理推导。指数函数在 $x=0$ 附近的泰勒级数展开为 $\\exp(x) \\approx 1+x$（对于小的 $x$）。这意味着对于一个小的项 $\\epsilon_i = i/M$，我们可以近似为 $1-\\epsilon_i \\approx \\exp(-\\epsilon_i)$。这个近似是稳健的。\n\n将此近似应用于 $P_{nc}$ 乘积中的每一项：\n$$P_{nc} \\approx \\prod_{i=0}^{n-1} \\exp\\left(-\\frac{i}{M}\\right) = \\exp\\left(-\\sum_{i=0}^{n-1} \\frac{i}{M}\\right)$$\n这个求和是一个等差级数：$\\sum_{i=0}^{n-1} i = \\frac{(n-1)n}{2}$。将此代入指数中：\n$$P_{nc} \\approx \\exp\\left(-\\frac{n(n-1)}{2M}\\right)$$\n对于非常大的 $n$，$n(n-1) \\approx n^2$，这导出了常用近似 $P_{nc} \\approx \\exp(-n^2/(2M))$。我们将保留稍微更精确的 $n(n-1)$ 形式。\n\n因此，至少发生一次碰撞的概率 $P_c$ 是：\n$$P_c = 1 - P_{nc} \\approx 1 - \\exp\\left(-\\frac{n(n-1)}{2M}\\right)$$\n这就是所求的近似表达式。\n\n现在，我们用给定的数值对这个表达式进行数值计算：\n- $n = 9.6 \\times 10^8$\n- $M = 2^{64}$\n\n设 $\\lambda$ 为指数函数中指数的参数：\n$$\\lambda = \\frac{n(n-1)}{2M} = \\frac{(9.6 \\times 10^8)(9.6 \\times 10^8 - 1)}{2 \\times 2^{64}}$$\n由于在此计算中 $n-1$ 与 $n$ 的差异可以忽略不计，我们可以近似 $n(n-1) \\approx n^2$：\n$$\\lambda \\approx \\frac{n^2}{2M} = \\frac{(9.6 \\times 10^8)^2}{2 \\times 2^{64}} = \\frac{9.216 \\times 10^{17}}{2^{65}}$$\n为计算此值，我们使用 $2^{64} \\approx 1.844674 \\times 10^{19}$。\n$$\\lambda \\approx \\frac{9.216 \\times 10^{17}}{2 \\times (1.844674 \\times 10^{19})} = \\frac{9.216 \\times 10^{17}}{3.689348 \\times 10^{19}} \\approx 0.024979$$\n现在我们计算碰撞概率：\n$$P_c \\approx 1 - \\exp(-\\lambda) \\approx 1 - \\exp(-0.024979)$$\n使用计算器计算指数项：\n$$\\exp(-0.024979) \\approx 0.975328$$\n$$P_c \\approx 1 - 0.975328 = 0.024672$$\n四舍五入到四位有效数字，我们得到：\n$$P_c \\approx 0.02467$$\n\n最后，我们解释这一结果的含义。\n对于一个谱系完整性至关重要的系统来说，单单一个 $8$ 小时窗口内约 $2.467\\%$ 的碰撞概率是相当高的。哈希碰撞意味着两个不同的谱系记录被分配了相同的唯一标识符。这从根本上破坏了来源链，使得明确追溯数据历史变得不可能。审计员或自动化分析工具将无法区分这两个发生碰撞的记录，这可能导致对系统状态、故障传播或安全事件得出错误的结论。对于一个连续运行的系统，几天之内发生碰撞几乎是必然的。在一天（三个 $8$ 小时窗口）内不发生碰撞的概率是 $(1-P_c)^3 \\approx (0.97533)^3 \\approx 0.9275$，这意味着每日的碰撞风险超过 $7\\%$。在一个月（$90$ 个窗口）内，避免碰撞的概率是 $(1-P_c)^{90} \\approx 0.103$，意味着至少发生一次碰撞的几率为 $89.7\\%$。假设哈希函数是均匀随机的，这是一种乐观的建模假设；现实世界中的哈希函数可能存在偏差，从而增加碰撞概率。因此，计算出的风险应被视为一个下界。这明确地意味着，一个 $64$ 位的哈希空间不足以在这种规模下确保谱系完整性。该系统需要更大的哈希输出，例如 $128$ 位或完整的 SHA-256 的 $256$ 位，以将碰撞概率降低到密码学上可以忽略的水平。",
            "answer": "$$\\boxed{0.02467}$$"
        },
        {
            "introduction": "一旦建立了一个完整且一致的血缘图，它就成为系统分析（尤其是安全与审计）的强大工具。攻击者可能会试图通过破坏血缘路径中的某些节点来隐藏恶意转换。本练习  将这一安全挑战构建为一个图论问题：找出需要破坏的最小节点数，以切断从某个转换到下游监控器的所有路径。通过应用最大流最小割定理，您将学习如何量化系统的“攻击面”，并从数据溯源的角度识别其最关键的脆弱点。",
            "id": "4212528",
            "problem": "一个信息物理系统 (CPS) 的数字孪生可以由一个有向无环图 (DAG) 表示，其中每个顶点表示一个谱系节点（例如，一个数据源、一个转换或一个存储事件），每条有向边表示从一个上游节点到一个下游节点的谱系依赖。设该 DAG 表示为 $G = (V, E)$，其中顶点集为 $V$，边集为 $E \\subseteq V \\times V$。对于一个固定的转换节点 $t \\in V$ 和一组在下游记录证据的监控节点 $M \\subseteq V$，考虑这样一个问题：确定一个最小的谱系节点集合，攻破这些节点将能对 $M$ 中的每个监控节点隐藏转换 $t$ 的所有证据。攻破被建模为将这些节点从证据传播中移除，从而使得从 $t$ 到任何 $m \\in M$ 的每条路径都被至少一个被攻破的节点阻断。\n\n使用的基本定义：\n- 在 $G$ 中的一条有向路径是一个顶点序列 $(v_0, v_1, \\dots, v_k)$，满足对于所有 $i \\in \\{0, 1, \\dots, k-1\\}$ 都有 $(v_i, v_{i+1}) \\in E$。\n- 对于给定的 $t \\in V$ 和 $M \\subseteq V$，一个顶点割（或 $t$-$M$ 分割集）是一个集合 $S \\subseteq V \\setminus (\\{t\\} \\cup M)$，使得从 $t$ 到任何 $m \\in M$ 的每条有向路径都至少包含 $S$ 中的一个顶点。\n- 一个（按基数）最小顶点割 $S^{\\star}$ 是在所有顶点割中基数最小的顶点割。\n- 相对于监控节点 $M$，转换 $t$ 的攻击面度量定义为 $\\mathcal{A}(t, M) = |S^{\\star}|$，即攻击者要对所有监控节点隐藏 $t$ 所必须攻破的最少谱系节点数量。\n- 假设除 $t$ 和监控节点 $M$ 外，所有顶点都是可被攻破的。节点 $t$ 和 $M$ 被视为受保护的，不能被攻破。\n\n你的任务是编写一个完整的、可运行的程序，对于给定的 DAG、$t$ 和 $M$，计算整数 $\\mathcal{A}(t, M) = |S^{\\star}|$。你必须基于以上定义和经过充分验证的事实（例如，图论中的流与割），从基本原理推导出你的算法，而不能使用或假设未由基本原理阐释的捷径公式。程序不应要求任何输入；它必须在代码中嵌入的测试套件上运行。\n\n测试套件规范（每个测试用例是一个三元组 $(G, t, M)$；顶点由整数标记，边以有序对列出，并保证 $G$ 是一个有向无环图）：\n\n- 测试用例 1（通用分支，两条不相交路径）：\n  - $V = \\{0, 1, 2, 3, 4, 5\\}$\n  - $E = \\{(0, 1), (0, 2), (1, 3), (2, 4), (3, 5), (4, 5)\\}$\n  - $t = 0$, $M = \\{5\\}$\n\n- 测试用例 2（单一路径）：\n  - $V = \\{0, 1, 2\\}$\n  - $E = \\{(0, 1), (1, 2)\\}$\n  - $t = 0$, $M = \\{2\\}$\n\n- 测试用例 3（从 t 到监控节点无路径）：\n  - $V = \\{0, 1, 2, 3\\}$\n  - $E = \\{(0, 1), (2, 3)\\}$\n  - $t = 0$, $M = \\{3\\}$\n\n- 测试用例 4（多个监控节点前的共享瓶颈）：\n  - $V = \\{0, 1, 2, 3, 4\\}$\n  - $E = \\{(0, 1), (1, 2), (2, 3), (2, 4)\\}$\n  - $t = 0$, $M = \\{3, 4\\}$\n\n- 测试用例 5（三个不相交分支汇合于单个监控节点）：\n  - $V = \\{0, 1, 2, 3, 4, 5, 6, 7\\}$\n  - $E = \\{(0, 1), (1, 4), (4, 7), (0, 2), (2, 5), (5, 7), (0, 3), (3, 6), (6, 7)\\}$\n  - $t = 0$, $M = \\{7\\}$\n\n你的程序应该生成单行输出，其中包含按测试用例 1 到 5 的确切顺序排列的结果，结果为用方括号括起来的逗号分隔列表。每个结果必须是该测试用例的整数值 $\\mathcal{A}(t, M)$。例如，最终打印的输出必须形如 $[a_1,a_2,a_3,a_4,a_5]$，其中每个 $a_i$ 是一个整数。",
            "solution": "该问题要求在一个有向无环图 (DAG) $G = (V, E)$ 中，计算一个转换节点 $t$ 和一组监控节点 $M$ 的攻击面度量 $\\mathcal{A}(t, M)$。该度量被定义为最小顶点割 $S^{\\star}$ 的基数，其中 $S^{\\star} \\subseteq V \\setminus (\\{t\\} \\cup M)$，它将 $t$ 与 $M$ 中的所有节点分离。如果从 $t$ 到任何节点 $m \\in M$ 的每条有向路径都至少包含 $S$ 中的一个顶点，则集合 $S$ 是一个 $t$-$M$ 分割集。\n\n这个问题是在有向图中寻找一个源顶点和一组目标顶点之间的最小顶点割的经典实例。解决这个问题的理论基础是 Menger 定理及其推广，即最大流最小割定理。Menger 定理将两个顶点之间的最小顶点分割集的大小与它们之间的顶点不相交路径的最大数量关联起来。最大流最小割定理为计算这个数量提供了一个强大的算法框架。\n\n为了应用通常针对边割陈述的最大流最小割定理，我们必须首先将原始图 $G$ 及其顶点割问题转换为一个等价的、带边割的网络流问题。这可以通过标准的顶点分裂构造法来实现。我们构造一个新的有容量的有向图，称之为 $G_f = (V_f, E_f)$，如下所示：\n\n$1$. **顶点分裂**：对于原始图 $G$ 中的每个顶点 $v$，我们在 $G_f$ 中创建两个节点：一个“入节点” $v_{in}$ 和一个“出节点” $v_{out}$。我们在 $G_f$ 中添加一条从 $v_{in}$ 到 $v_{out}$ 的有向边。这条边代表顶点 $v$ 本身，其容量将用于建模该顶点是否可被攻破。\n    - 如果顶点 $v$ 是一个普通的谱系节点，即 $v \\in V \\setminus (\\{t\\} \\cup M)$，攻破它等同于被“切割”。我们为其对应的边分配容量 1：$c(v_{in}, v_{out}) = 1$。\n    - 如果顶点 $v$ 是受保护的转换节点 $t$ 或受保护的监控节点 $m \\in M$ 之一，它不能被攻破。我们通过为其对应的边分配无穷大容量来建模此特性：对于所有 $m \\in M$，有 $c(t_{in}, t_{out}) = \\infty$ 和 $c(m_{in}, m_{out}) = \\infty$。\n\n$2$. **边的表示**：对于原始图 $G$ 中的每条有向边 $(u, v) \\in E$，我们在 $G_f$ 中添加一条从 $u$ 的出节点到 $v$ 的入节点的有向边。这条新边 $(u_{out}, v_{in})$ 代表原始的依赖路径。由于我们只关心切割顶点（由顶点分裂边表示），这些代表路径的边不能成为最小割的一部分。我们通过为其分配无穷大容量来确保这一点：$c(u_{out}, v_{in}) = \\infty$。\n\n$3$. **处理多个汇点**：问题指定了一组作为汇点的监控节点 $M$。为了在标准的最大流算法中处理多个汇点，我们在 $G_f$ 中引入一个单一的“超级汇点”节点，称之为 $T_{super}$。对于每个监控节点 $m \\in M$，我们添加一条从其出节点 $m_{out}$ 到超级汇点 $T_{super}$ 的有向边，同样具有无穷大容量：$c(m_{out}, T_{super}) = \\infty$。\n\n在这个构造的网络中，流的源点将是转换节点 $t$ 的入节点 $t_{in}$。在 $G$ 中寻找最小顶点割的问题现在被转换为在流网络 $G_f$ 中寻找从源点 $S_f = t_{in}$ 到汇点 $T_f = T_{super}$ 的最大流问题。\n\n根据最大流最小割定理，网络中从源点到汇点的最大流值等于一个 $S_f$-$T_f$ 割的最小容量。一个 $S_f$-$T_f$ 割是 $G_f$ 中顶点的一个划分，该划分将顶点分为两个集合，一个包含 $S_f$，另一个包含 $T_f$。割的容量是从源点侧集合到汇点侧集合的所有边的容量之和。在我们构造的图 $G_f$ 中，唯一具有有限容量的边是对应于可被攻破节点的顶点分裂边，这些边的容量都为 1。因此，任何最小割都将完全由这些边组成。这样一个割的总容量就是这些边的数量，这直接对应于原始图 $G$ 中被攻破的顶点数量。\n\n因此，最小顶点割的基数 $\\mathcal{A}(t, M) = |S^{\\star}|$ 精确地等于 $G_f$ 中从 $t_{in}$ 到 $T_{super}$ 的最大流值。\n\n为了计算最大流，我们可以使用 Edmonds-Karp 算法。该算法在残留图上运行，残留图表示剩余的可用流容量。它使用广度优先搜索 (BFS) 重复地寻找从源点到汇点的增广路径。增广路径是残留图中的一条简单路径，其上所有边的可用容量都大于 0。这些可用容量的最小值是该路径的瓶颈容量。这个瓶颈容量被加到总流量中，并且路径上的残留容量会被更新（正向边的容量减少，相应反向边的容量增加）。当再也找不到增广路径时，算法终止。所有找到的增广路径的瓶颈容量之和就是最大流。",
            "answer": "```python\nimport numpy as np\nfrom collections import deque\n\ndef solve():\n    \"\"\"\n    Solves the problem for the entire suite of test cases.\n    \"\"\"\n    \n    # Test case 1: general branching, two disjoint paths\n    test_case_1 = {\n        \"V\": {0, 1, 2, 3, 4, 5},\n        \"E\": [(0, 1), (0, 2), (1, 3), (2, 4), (3, 5), (4, 5)],\n        \"t\": 0,\n        \"M\": {5}\n    }\n    \n    # Test case 2: single path\n    test_case_2 = {\n        \"V\": {0, 1, 2},\n        \"E\": [(0, 1), (1, 2)],\n        \"t\": 0,\n        \"M\": {2}\n    }\n\n    # Test case 3: no path from t to monitors\n    test_case_3 = {\n        \"V\": {0, 1, 2, 3},\n        \"E\": [(0, 1), (2, 3)],\n        \"t\": 0,\n        \"M\": {3}\n    }\n\n    # Test case 4: shared bottleneck before multiple monitors\n    test_case_4 = {\n        \"V\": {0, 1, 2, 3, 4},\n        \"E\": [(0, 1), (1, 2), (2, 3), (2, 4)],\n        \"t\": 0,\n        \"M\": {3, 4}\n    }\n\n    # Test case 5: three disjoint branches merging at a single monitor\n    test_case_5 = {\n        \"V\": {0, 1, 2, 3, 4, 5, 6, 7},\n        \"E\": [(0, 1), (1, 4), (4, 7), (0, 2), (2, 5), (5, 7), (0, 3), (3, 6), (6, 7)],\n        \"t\": 0,\n        \"M\": {7}\n    }\n    \n    test_cases = [test_case_1, test_case_2, test_case_3, test_case_4, test_case_5]\n\n    results = []\n    for case in test_cases:\n        result = compute_attack_surface(case[\"V\"], case[\"E\"], case[\"t\"], case[\"M\"])\n        results.append(result)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef bfs(graph, s, t, parent):\n    \"\"\"\n    Breadth-First Search to find an augmenting path in the residual graph.\n    \n    Args:\n        graph (np.ndarray): The residual capacity graph.\n        s (int): The source node index.\n        t (int): The sink node index.\n        parent (list): A list to store the path.\n        \n    Returns:\n        bool: True if a path is found, False otherwise.\n    \"\"\"\n    visited = [False] * len(graph)\n    queue = deque()\n    \n    queue.append(s)\n    visited[s] = True\n    parent[s] = -1\n    \n    while queue:\n        u = queue.popleft()\n        for v in range(len(graph)):\n            if not visited[v] and graph[u, v] > 0:\n                queue.append(v)\n                visited[v] = True\n                parent[v] = u\n                if v == t:\n                    return True\n    return False\n\ndef compute_attack_surface(V, E, t, M):\n    \"\"\"\n    Computes the attack surface measure A(t, M) using max-flow min-cut.\n\n    Args:\n        V (set): Set of vertices in the original graph.\n        E (list): List of edges (u, v) in the original graph.\n        t (int): The transformation node.\n        M (set): The set of monitor nodes.\n\n    Returns:\n        int: The cardinality of the minimal vertex cut, A(t, M).\n    \"\"\"\n    if not V:\n        return 0\n    max_node_label = max(V)\n    num_orig_vertices = max_node_label + 1\n\n    # The flow network has 2*num_orig_vertices nodes for vertex splitting,\n    # plus one super-sink.\n    # Node v_in -> v\n    # Node v_out -> v + num_orig_vertices\n    # Super-sink -> 2 * num_orig_vertices\n    num_flow_nodes = 2 * num_orig_vertices + 1\n    \n    source = t\n    sink = 2 * num_orig_vertices\n    \n    capacity = np.zeros((num_flow_nodes, num_flow_nodes), dtype=int)\n    inf_capacity = num_orig_vertices + 1  # A value larger than any possible flow\n\n    # 1. Build vertex-capacity edges (v_in -> v_out)\n    for v in range(num_orig_vertices):\n        v_in = v\n        v_out = v + num_orig_vertices\n        if v == t or v in M:\n            capacity[v_in, v_out] = inf_capacity\n        else:\n            # Compromisable node\n            capacity[v_in, v_out] = 1\n\n    # 2. Build original graph edges (u_out -> v_in)\n    for u, v in E:\n        u_out = u + num_orig_vertices\n        v_in = v\n        capacity[u_out, v_in] = inf_capacity\n\n    # 3. Build monitor-to-super-sink edges (m_out -> T_super)\n    for m in M:\n        m_out = m + num_orig_vertices\n        capacity[m_out, sink] = inf_capacity\n\n    # Edmonds-Karp Algorithm\n    residual_graph = np.copy(capacity)\n    parent = [0] * num_flow_nodes\n    max_flow = 0\n    \n    while bfs(residual_graph, source, sink, parent):\n        path_flow = inf_capacity\n        v = sink\n        while v != source:\n            u = parent[v]\n            path_flow = min(path_flow, residual_graph[u, v])\n            v = u\n        \n        max_flow += path_flow\n        \n        v = sink\n        while v != source:\n            u = parent[v]\n            residual_graph[u, v] -= path_flow\n            residual_graph[v, u] += path_flow\n            v = u\n            \n    return max_flow\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}