{
    "hands_on_practices": [
        {
            "introduction": "Effective data governance begins with robust privacy protection, especially when releasing datasets for collaborative analysis. While techniques like $k$-anonymity are foundational, they can be vulnerable to homogeneity and background knowledge attacks. This practice  challenges you to work with more advanced privacy-preserving principles, $l$-diversity and $t$-closeness, which provide stronger guarantees against attribute disclosure. You will evaluate whether a dataset from a manufacturing digital twin meets these standards and propose concrete, governance-preserving adjustments to achieve compliance.",
            "id": "4212228",
            "problem": "A manufacturing Digital Twin (DT) deployed within a Cyber-Physical System (CPS) aggregates operational records and releases an anonymized dataset for collaborative analytics under strict data governance. The dataset uses quasi-identifiers to form equivalence classes and retains a single sensitive attribute, incident severity, with categories Minor, Moderate, and Critical. The data owner wishes to evaluate compliance with two anonymization criteria: distinctness $l$-diversity with $l=3$ and $t$-closeness with threshold $t=0.2$, under a categorical distance defined as the total variation distance. Use the following foundational definitions.\n\nDefinitions:\n- An equivalence class is the set of records identical on the chosen quasi-identifiers.\n- Distinctness $l$-diversity requires that each equivalence class contains at least $l$ distinct sensitive attribute values present.\n- $t$-closeness requires that for every equivalence class, the distance between the class-level sensitive attribute distribution and the global sensitive attribute distribution is bounded above by $t$. For a categorical sensitive attribute, use the total variation distance defined by $d(P,Q) = \\frac{1}{2}\\sum_{i} |P(i) - Q(i)|$, where $P$ and $Q$ are probability mass functions over the sensitive categories.\n\nThe anonymized dataset comprises four equivalence classes $\\mathcal{E}_1,\\mathcal{E}_2,\\mathcal{E}_3,\\mathcal{E}_4$, each containing $25$ records. The sensitive attribute counts within each class are:\n- $\\mathcal{E}_1$: Minor $20$, Moderate $5$, Critical $0$.\n- $\\mathcal{E}_2$: Minor $10$, Moderate $10$, Critical $5$.\n- $\\mathcal{E}_3$: Minor $15$, Moderate $7$, Critical $3$.\n- $\\mathcal{E}_4$: Minor $15$, Moderate $8$, Critical $2$.\n\nThe global sensitive attribute counts across the $100$ records are Minor $60$, Moderate $30$, Critical $10$.\n\nTask:\n1. Starting from the definitions above, derive the achieved distinctness $l$-diversity (i.e., the minimum number of distinct sensitive categories present in any equivalence class).\n2. Compute, for each equivalence class, the total variation distance between its sensitive attribute distribution and the global distribution, and identify the largest such distance.\n3. Evaluate whether the dataset satisfies distinctness $l$-diversity with $l=3$ and $t$-closeness with $t=0.2$.\n4. If any criterion fails, propose a minimal adjustment grounded in governance-preserving operations (e.g., microaggregation, swapping records between classes while preserving class sizes and global totals) to achieve compliance, and justify why the adjustment addresses the failure.\n\nExpress your final numeric outputs as the ordered pair consisting of the achieved distinctness $l$-diversity and the maximal total variation distance across classes. Provide exact values; no rounding is required. The outputs are dimensionless.",
            "solution": "The problem statement has been critically examined and found to be valid. It is scientifically grounded in the principles of data anonymization, well-posed with a complete and consistent set of data and definitions, and objective in its formulation. The total counts of sensitive attributes across the equivalence classes sum to the specified global counts, ensuring internal consistency.\nTotal Minor: $20+10+15+15 = 60$.\nTotal Moderate: $5+10+7+8 = 30$.\nTotal Critical: $0+5+3+2 = 10$.\nTotal Records: $4 \\times 25 = 100$.\nThe data is consistent and sufficient for a rigorous solution. We proceed with the analysis.\n\nThe problem requires a four-part analysis: evaluating distinctness $l$-diversity, computing the maximum $t$-closeness distance, assessing compliance with the given criteria, and proposing a minimal adjustment for any identified failures.\n\n**1. Derivation of Achieved Distinctness $l$-diversity**\n\nDistinctness $l$-diversity requires that each equivalence class contains at least $l$ distinct values for the sensitive attribute. We must find the minimum number of distinct sensitive attribute categories present in any single equivalence class. The sensitive attribute categories are Minor, Moderate, and Critical.\n\n-   For equivalence class $\\mathcal{E}_1$ with counts (Minor $20$, Moderate $5$, Critical $0$), there are $2$ distinct categories present: {Minor, Moderate}.\n-   For equivalence class $\\mathcal{E}_2$ with counts (Minor $10$, Moderate $10$, Critical $5$), there are $3$ distinct categories present: {Minor, Moderate, Critical}.\n-   For equivalence class $\\mathcal{E}_3$ with counts (Minor $15$, Moderate $7$, Critical $3$), there are $3$ distinct categories present: {Minor, Moderate, Critical}.\n-   For equivalence class $\\mathcal{E}_4$ with counts (Minor $15$, Moderate $8$, Critical $2$), there are $3$ distinct categories present: {Minor, Moderate, Critical}.\n\nThe achieved distinctness $l$-diversity is the minimum of these counts:\n$$l_{\\text{achieved}} = \\min(\\{2, 3, 3, 3\\}) = 2$$\n\n**2. Computation of Total Variation Distance**\n\nThe $t$-closeness criterion is evaluated using the total variation distance, $d(P, Q) = \\frac{1}{2}\\sum_{i} |P(i) - Q(i)|$, where $Q$ is the global distribution and $P$ is the class-level distribution of the sensitive attribute.\n\nFirst, we establish the global probability mass function, $Q$, over the categories $S = \\{\\text{Minor, Moderate, Critical}\\}$. The total number of records is $N=100$, with global counts of $60$ (Minor), $30$ (Moderate), and $10$ (Critical).\n$$Q(\\text{Minor}) = \\frac{60}{100} = 0.6$$\n$$Q(\\text{Moderate}) = \\frac{30}{100} = 0.3$$\n$$Q(\\text{Critical}) = \\frac{10}{100} = 0.1$$\nThus, the global distribution is $Q = (0.6, 0.3, 0.1)$.\n\nNext, we compute the probability mass function $P_k$ for each equivalence class $\\mathcal{E}_k$, each of which contains $N_k=25$ records.\n\nFor $\\mathcal{E}_1$: Counts are $(20, 5, 0)$.\n$$P_1 = \\left(\\frac{20}{25}, \\frac{5}{25}, \\frac{0}{25}\\right) = (0.8, 0.2, 0.0)$$\nThe total variation distance is:\n$$d(\\mathcal{E}_1, Q) = \\frac{1}{2} \\left( |0.8 - 0.6| + |0.2 - 0.3| + |0.0 - 0.1| \\right) = \\frac{1}{2} (0.2 + 0.1 + 0.1) = \\frac{1}{2} (0.4) = 0.2$$\n\nFor $\\mathcal{E}_2$: Counts are $(10, 10, 5)$.\n$$P_2 = \\left(\\frac{10}{25}, \\frac{10}{25}, \\frac{5}{25}\\right) = (0.4, 0.4, 0.2)$$\nThe total variation distance is:\n$$d(\\mathcal{E}_2, Q) = \\frac{1}{2} \\left( |0.4 - 0.6| + |0.4 - 0.3| + |0.2 - 0.1| \\right) = \\frac{1}{2} (0.2 + 0.1 + 0.1) = \\frac{1}{2} (0.4) = 0.2$$\n\nFor $\\mathcal{E}_3$: Counts are $(15, 7, 3)$.\n$$P_3 = \\left(\\frac{15}{25}, \\frac{7}{25}, \\frac{3}{25}\\right) = (0.6, 0.28, 0.12)$$\nThe total variation distance is:\n$$d(\\mathcal{E}_3, Q) = \\frac{1}{2} \\left( |0.6 - 0.6| + |0.28 - 0.3| + |0.12 - 0.1| \\right) = \\frac{1}{2} (0.0 + 0.02 + 0.02) = \\frac{1}{2} (0.04) = 0.02$$\n\nFor $\\mathcal{E}_4$: Counts are $(15, 8, 2)$.\n$$P_4 = \\left(\\frac{15}{25}, \\frac{8}{25}, \\frac{2}{25}\\right) = (0.6, 0.32, 0.08)$$\nThe total variation distance is:\n$$d(\\mathcal{E}_4, Q) = \\frac{1}{2} \\left( |0.6 - 0.6| + |0.32 - 0.3| + |0.08 - 0.1| \\right) = \\frac{1}{2} (0.0 + 0.02 + 0.02) = \\frac{1}{2} (0.04) = 0.02$$\n\nThe set of computed distances is $\\{0.2, 0.2, 0.02, 0.02\\}$. The largest such distance is:\n$$d_{\\max} = \\max(\\{0.2, 0.2, 0.02, 0.02\\}) = 0.2$$\n\n**3. Compliance Evaluation**\n\n-   **Distinctness $l$-diversity:** The requirement is $l=3$. The achieved level is $l_{\\text{achieved}}=2$. Since $2  3$, the dataset **fails** to satisfy distinctness $l$-diversity with $l=3$. The failure is in equivalence class $\\mathcal{E}_1$.\n-   **$t$-closeness:** The requirement is that the distance for every class must be bounded above by $t=0.2$. This means $d(\\mathcal{E}_k, Q) \\le 0.2$ for all $k \\in \\{1,2,3,4\\}$. The maximum computed distance is $d_{\\max}=0.2$. Since $0.2 \\le 0.2$, the condition holds for all equivalence classes. Therefore, the dataset **satisfies** $t$-closeness with $t=0.2$.\n\n**4. Minimal Adjustment Proposal**\n\nThe dataset fails the $l=3$ diversity criterion because $\\mathcal{E}_1$ lacks a 'Critical' incident record. A minimal adjustment to correct this is to introduce at least one 'Critical' record into $\\mathcal{E}_1$. This can be achieved via a record swap with another equivalence class to preserve class sizes and global distributions, as mandated by governance-preserving operations.\n\nWe can swap one 'Minor' record from $\\mathcal{E}_1$ with one 'Critical' record from any class that can spare one, for instance, $\\mathcal{E}_2$.\n-   Initial $\\mathcal{E}_1$: (Minor $20$, Moderate $5$, Critical $0$)\n-   Initial $\\mathcal{E}_2$: (Minor $10$, Moderate $10$, Critical $5$)\n\nThe proposed swap is: move one 'Critical' record from $\\mathcal{E}_2$ to $\\mathcal{E}_1$, and move one 'Minor' record from $\\mathcal{E}_1$ to $\\mathcal{E}_2$.\n\n-   Adjusted $\\mathcal{E}'_1$: (Minor $19$, Moderate $5$, Critical $1$)\n-   Adjusted $\\mathcal{E}'_2$: (Minor $11$, Moderate $10$, Critical $4$)\n\nLet us verify the effect of this adjustment.\n-   **$l$-diversity compliance:** After adjustment, $\\mathcal{E}'_1$ contains $3$ distinct categories. All other classes already had $3$. The minimum count is now $3$, so the dataset is compliant with $l=3$ diversity.\n-   **$t$-closeness compliance:** We must re-calculate the total variation distance for the modified classes, $\\mathcal{E}'_1$ and $\\mathcal{E}'_2$, to ensure they still meet the $t \\le 0.2$ threshold.\n    -   $P'_1 = \\left(\\frac{19}{25}, \\frac{5}{25}, \\frac{1}{25}\\right) = (0.76, 0.2, 0.04)$.\n    -   $d(\\mathcal{E}'_1, Q) = \\frac{1}{2} \\left( |0.76 - 0.6| + |0.2 - 0.3| + |0.04 - 0.1| \\right) = \\frac{1}{2} (0.16 + 0.1 + 0.06) = 0.16$.\n    -   $P'_2 = \\left(\\frac{11}{25}, \\frac{10}{25}, \\frac{4}{25}\\right) = (0.44, 0.4, 0.16)$.\n    -   $d(\\mathcal{E}'_2, Q) = \\frac{1}{2} \\left( |0.44 - 0.6| + |0.4 - 0.3| + |0.16 - 0.1| \\right) = \\frac{1}{2} (0.16 + 0.1 + 0.06) = 0.16$.\nSince $0.16 \\le 0.2$, both adjusted classes remain compliant with the $t$-closeness criterion. The other classes were unaffected and remain compliant. This minimal swap successfully rectifies the $l$-diversity failure while preserving all constraints and overall compliance.\n\nThe final numeric outputs requested are the achieved distinctness $l$-diversity and the maximal total variation distance for the original, unadjusted dataset.\nAchieved $l$-diversity: $2$.\nMaximal total variation distance: $0.2$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  0.2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Beyond protecting data at rest, a comprehensive governance framework must also audit the fairness of the algorithms that use it. In complex cyber-physical systems, automated decisions can have significant real-world consequences, making it crucial to ensure they do not create or amplify societal biases. This exercise  puts you in the role of a data steward, tasking you with auditing a digital twin's allocation model for fairness using the disparate impact ($DI$) metric. By working with the statistical properties of the model, you will quantify its fairness level and assess it against predefined governance thresholds.",
            "id": "4212236",
            "problem": "A Digital Twin (DT) of a city-wide Cyber-Physical System (CPS) for adaptive electric vehicle charging allocates limited fast-charge slots based on a group-blind decision rule applied to a privacy-preserving score. To comply with cross-jurisdictional data sovereignty, the system must use a single global threshold $t$ for all users, and cannot transmit raw identifiers or counts across jurisdictions. The fairness metric mandated by the data stewardship board is disparate impact (DI), defined as $DI=\\frac{p_{\\text{protected}}}{p_{\\text{unprotected}}}$, where $p_{\\text{protected}}$ and $p_{\\text{unprotected}}$ are the allocation rates for the protected and unprotected groups, respectively.\n\nAssume the following well-tested modeling facts are applicable:\n- For each group $g \\in \\{\\text{protected}, \\text{unprotected}\\}$, the privacy-preserving score $S_{g}$ is standardized and well-approximated by a Normal distribution with mean $\\mu_{g}$ and common variance $\\sigma^{2}$.\n- The allocation rule is a threshold: allocate if and only if $S_{g} \\ge t$.\n- By definition of a Normal random variable $X \\sim \\mathcal{N}(\\mu,\\sigma^{2})$ and the standard Normal cumulative distribution function $\\Phi(\\cdot)$, the tail probability is $\\mathbb{P}(X \\ge t)=1-\\Phi\\!\\left(\\frac{t-\\mu}{\\sigma}\\right)$.\n\nIn the current batch, a capacity-constrained and sovereignty-compliant control plane has published a signed attestation that the unique global threshold is $t=0.5$. The distributional parameters, learned from federated, differentially private training, are $\\mu_{\\text{protected}}=0.2$, $\\mu_{\\text{unprotected}}=0.5$, and $\\sigma=1$.\n\nThe governance policy defines two action thresholds for $DI$: a soft-audit trigger at $\\alpha_{\\text{soft}}=0.8$ and a hard-stop trigger at $\\alpha_{\\text{hard}}=0.7$. Define the maximum governance action threshold $\\alpha^{\\star}$ to be the supremum of all $\\alpha \\in (0,1]$ such that the observed $DI$ satisfies $DI \\ge \\alpha$ for this batch.\n\nStarting from the core definitions above and without using any raw counts, compute the value of $\\alpha^{\\star}$ implied by the attested threshold and the given distributional parameters. Express your final answer as a decimal rounded to four significant figures. No units are required.",
            "solution": "The problem is subjected to validation against the established criteria.\n\n### Step 1: Extract Givens\n- **System context**: A Digital Twin (DT) for a Cyber-Physical System (CPS) allocating electric vehicle fast-charge slots.\n- **Fairness metric**: Disparate impact, $DI=\\frac{p_{\\text{protected}}}{p_{\\text{unprotected}}}$.\n- **Definitions**: $p_{\\text{protected}}$ is the allocation rate for the protected group; $p_{\\text{unprotected}}$ is the allocation rate for the unprotected group.\n- **Score distribution**: For each group $g$, the score $S_{g}$ is modeled by a Normal distribution, $S_{g} \\sim \\mathcal{N}(\\mu_{g}, \\sigma^{2})$.\n- **Allocation rule**: A slot is allocated if and only if the score $S_{g} \\ge t$.\n- **Tail probability formula**: For a random variable $X \\sim \\mathcal{N}(\\mu,\\sigma^{2})$, the probability $\\mathbb{P}(X \\ge t)$ is given by $1-\\Phi\\!\\left(\\frac{t-\\mu}{\\sigma}\\right)$, where $\\Phi(\\cdot)$ is the standard Normal cumulative distribution function (CDF).\n- **Attested global threshold**: $t=0.5$.\n- **Distributional parameters**:\n    - Mean for protected group: $\\mu_{\\text{protected}}=0.2$.\n    - Mean for unprotected group: $\\mu_{\\text{unprotected}}=0.5$.\n    - Common standard deviation: $\\sigma=1$. (The variance $\\sigma^2$ is $1^2=1$).\n- **Governance thresholds**: Soft-audit at $\\alpha_{\\text{soft}}=0.8$, hard-stop at $\\alpha_{\\text{hard}}=0.7$.\n- **Quantity to be computed**: $\\alpha^{\\star} = \\sup\\{\\alpha \\in (0,1] \\mid DI \\ge \\alpha\\}$.\n- **Required precision**: The final answer must be a decimal rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined and scientifically sound.\n- **Scientifically Grounded**: The problem uses standard concepts from probability theory (Normal distribution, CDF) and the established field of algorithmic fairness (disparate impact). The application to a CPS is a modern, realistic context. The premises are factually and mathematically correct.\n- **Well-Posed**: All necessary data ($\\mu_{\\text{protected}}$, $\\mu_{\\text{unprotected}}$, $\\sigma$, $t$) and definitions are provided to compute the disparate impact, $DI$. The definition of $\\alpha^{\\star}$ as the supremum of a set is mathematically precise and unambiguously implies that $\\alpha^{\\star}$ is the computed value of $DI$. A unique solution exists.\n- **Objective**: The problem is stated in precise, quantitative, and unbiased language.\n- The problem is self-contained, consistent, and does not violate any of the invalidity criteria. The governance thresholds $\\alpha_{\\text{soft}}$ and $\\alpha_{\\text{hard}}$ provide context but are not used in the calculation of $\\alpha^{\\star}$, which does not create a contradiction.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be derived.\n\n### Derivation of Solution\nThe objective is to compute $\\alpha^{\\star}$, which is defined as the supremum of all values $\\alpha$ in the interval $(0,1]$ such that the observed disparate impact, $DI$, is greater than or equal to $\\alpha$. This is a formal definition which simplifies to finding the value of $DI$ itself. Thus, we have $\\alpha^{\\star} = DI$.\n\nThe disparate impact is defined as the ratio of the allocation rates for the protected and unprotected groups:\n$$\nDI = \\frac{p_{\\text{protected}}}{p_{\\text unprotected}}\n$$\nAn allocation is made if a user's score $S_g$ meets or exceeds the global threshold $t$. Therefore, the allocation rate for a group $g$, denoted $p_g$, is the probability $\\mathbb{P}(S_g \\ge t)$. The problem states that the scores for each group $g$ follow a Normal distribution, $S_g \\sim \\mathcal{N}(\\mu_g, \\sigma^2)$, and provides the formula for the tail probability:\n$$\np_g = \\mathbb{P}(S_g \\ge t) = 1 - \\Phi\\left(\\frac{t-\\mu_g}{\\sigma}\\right)\n$$\nwhere $\\Phi$ is the CDF of the standard Normal distribution, $\\mathcal{N}(0, 1)$.\n\nWe are given the following parameter values:\n-   Threshold: $t = 0.5$\n-   Protected group mean: $\\mu_{\\text{protected}} = 0.2$\n-   Unprotected group mean: $\\mu_{\\text{unprotected}} = 0.5$\n-   Common standard deviation: $\\sigma = 1$\n\nFirst, we compute the allocation rate for the unprotected group, $p_{\\text{unprotected}}$.\n$$\np_{\\text{unprotected}} = \\mathbb{P}(S_{\\text{unprotected}} \\ge 0.5) = 1 - \\Phi\\left(\\frac{t - \\mu_{\\text{unprotected}}}{\\sigma}\\right)\n$$\nSubstituting the given values:\n$$\np_{\\text{unprotected}} = 1 - \\Phi\\left(\\frac{0.5 - 0.5}{1}\\right) = 1 - \\Phi(0)\n$$\nThe CDF of the standard Normal distribution at $z=0$ is exactly $0.5$, i.e., $\\Phi(0) = 0.5$.\n$$\np_{\\text{unprotected}} = 1 - 0.5 = 0.5\n$$\nNext, we compute the allocation rate for the protected group, $p_{\\text{protected}}$.\n$$\np_{\\text{protected}} = \\mathbb{P}(S_{\\text{protected}} \\ge 0.5) = 1 - \\Phi\\left(\\frac{t - \\mu_{\\text{protected}}}{\\sigma}\\right)\n$$\nSubstituting the given values:\n$$\np_{\\text{protected}} = 1 - \\Phi\\left(\\frac{0.5 - 0.2}{1}\\right) = 1 - \\Phi(0.3)\n$$\nTo find the value of $p_{\\text{protected}}$, we must evaluate $\\Phi(0.3)$. Using standard statistical tables or a computational tool, an accurate value for $\\Phi(0.3)$ is approximately $0.6179114$.\n$$\np_{\\text{protected}} \\approx 1 - 0.6179114 = 0.3820886\n$$\nNow, we can compute the disparate impact, $DI$.\n$$\nDI = \\frac{p_{\\text{protected}}}{p_{\\text{unprotected}}} \\approx \\frac{0.3820886}{0.5} = 0.7641772\n$$\nAs established, $\\alpha^{\\star} = DI$. Therefore, $\\alpha^{\\star} \\approx 0.7641772$.\n\nThe problem requires the final answer to be rounded to four significant figures. The first four significant figures are $7$, $6$, $4$, and $1$. The fifth significant figure is $7$, which is $5$ or greater, so we round up the fourth significant figure.\n$$\n\\alpha^{\\star} \\approx 0.7642\n$$\nThis value of $\\alpha^{\\star}$ falls between the hard-stop trigger $\\alpha_{\\text{hard}}=0.7$ and the soft-audit trigger $\\alpha_{\\text{soft}}=0.8$, which is a consistent and meaningful result in the context of the problem's narrative.",
            "answer": "$$\\boxed{0.7642}$$"
        },
        {
            "introduction": "Modern digital twins are often collaborative ecosystems, built on data federated from multiple sovereign owners. This raises a critical governance question: how can the value generated by the collective model be fairly attributed to each individual contributor? This practice  introduces a rigorous, axiom-based method to solve this challenge using the Shapley value from cooperative game theory. You will calculate the fair contribution of a data owner to a model's accuracy, connecting abstract fairness principles like symmetry and efficiency to a tangible, quantitative valuation.",
            "id": "4212234",
            "problem": "A Cyber-Physical Systems (CPS) operator is constructing a Digital Twin (DT) model of a production line by federating data from three sovereign data owners, labeled $A$, $B$, and $C$. Each owner’s data may be included or excluded according to their data governance choices, subject to legal constraints such as consent and purpose limitation under the General Data Protection Regulation (GDPR). For any coalition $S \\subseteq \\{A,B,C\\}$, let $v(S)$ denote the DT’s validated out-of-sample accuracy (unitless fraction) when the model is trained exclusively on the data contributed by the owners in $S$, using a common pipeline and fixed hyperparameters to ensure comparability. Assume $v(\\varnothing) = 0$ and the following empirically obtained values:\n- $v(\\{A\\}) = 0.70$, $v(\\{B\\}) = 0.68$, $v(\\{C\\}) = 0.66$,\n- $v(\\{A,B\\}) = 0.78$, $v(\\{A,C\\}) = 0.77$, $v(\\{B,C\\}) = 0.75$,\n- $v(\\{A,B,C\\}) = 0.82$.\n\nTreating the owners as players in a cooperative game with characteristic function $v(\\cdot)$ and interpreting “fair contribution” as an allocation determined solely by coalition-dependent accuracy increments (subject to data governance constraints that determine admissible coalitions), do the following:\n\n1. Starting from the foundational fairness axioms of cooperative value allocation—symmetry (indistinguishable players receive equal allocation), efficiency (allocations sum to the grand coalition value), and the null player property (any player whose addition does not change any coalition’s value receives zero allocation)—derive a closed-form expression for the fair contribution of a player in terms of marginal improvements across all coalitions consistent with data governance orderings. Your derivation must establish why the resulting allocation depends on expectations over player orderings and why the axioms above constrain the allocation uniquely to that form.\n\n2. In the context of sovereign data ownership and governance, provide a justification for why each axiom is appropriate for attributing DT accuracy: symmetry when two owners’ data are functionally indistinguishable for model performance, efficiency to ensure no accuracy “surplus” or “deficit” remains unassigned, and the null player property when an owner’s data are either legally unusable (e.g., lack of valid consent) or statistically uninformative for the DT.\n\n3. Using your derived expression, compute the fair contribution for owner $A$ based on the values above. Round your final numeric answer to four significant figures and express it as a unitless decimal (no percentage sign).",
            "solution": "The problem asks for the derivation of a fair value allocation scheme based on specified axioms, a justification of these axioms in the context of data governance for Digital Twins, and the computation of this value for a specific data owner. The problem describes a cooperative game, where the players are the data owners $N = \\{A, B, C\\}$, and the value of any coalition $S \\subseteq N$ is given by the characteristic function $v(S)$, representing the accuracy of a Digital Twin model. The problem is valid as it is scientifically grounded in cooperative game theory and its application to data valuation, is well-posed with all necessary information provided, and is formulated objectively.\n\nThe fair allocation scheme sought is the Shapley value, which is uniquely determined by the axioms of symmetry, efficiency, and the null player property, along with linearity.\n\n1. Derivation of the Fair Contribution Expression (Shapley Value)\n\nLet $N$ be the set of players, in this case, the data owners $\\{A, B, C\\}$. A cooperative game is defined by the characteristic function $v: 2^N \\to \\mathbb{R}$, which assigns a value $v(S)$ to each coalition (subset) $S \\subseteq N$, with $v(\\varnothing)=0$. We seek an allocation vector $\\phi(v)$ with components $\\phi_i(v)$ for each player $i \\in N$, representing the fair contribution of player $i$ to the total value. This allocation must satisfy the following axioms:\n\n-   **Symmetry**: If two players $i$ and $j$ are interchangeable (i.e., for every coalition $S \\subseteq N \\setminus \\{i, j\\}$, it holds that $v(S \\cup \\{i\\}) = v(S \\cup \\{j\\})$), then their allocations must be equal: $\\phi_i(v) = \\phi_j(v)$.\n-   **Efficiency**: The sum of the individual allocations must equal the value of the grand coalition $N$: $\\sum_{i \\in N} \\phi_i(v) = v(N)$.\n-   **Null Player Property**: If a player $i$ contributes nothing to any coalition (i.e., for every coalition $S \\subseteq N$, $v(S \\cup \\{i\\}) = v(S)$), then their allocation is zero: $\\phi_i(v) = 0$.\n\nTo derive the expression for $\\phi_i(v)$, we consider the value player $i$ adds when joining a coalition of existing players. A fair way to account for all possibilities is to imagine the players arriving in a random sequential order. Let $\\pi$ be a permutation of the player set $N$, representing one such arrival ordering. Let $P_i(\\pi)$ be the set of players who precede player $i$ in the ordering $\\pi$. When player $i$ arrives, they join the coalition $P_i(\\pi)$ and create the new coalition $P_i(\\pi) \\cup \\{i\\}$. The marginal contribution of player $i$ for this specific ordering $\\pi$ is the value they add:\n$$\n\\text{MC}_i(\\pi) = v(P_i(\\pi) \\cup \\{i\\}) - v(P_i(\\pi))\n$$\nThe core idea of the Shapley value is that a player's fair contribution is their expected marginal contribution, averaged over all possible arrival orderings. Assuming each of the $|N|!$ permutations is equally likely (with probability $1/|N|!$), the fair contribution for player $i$, $\\phi_i(v)$, is the expectation of $\\text{MC}_i(\\pi)$:\n$$\n\\phi_i(v) = \\frac{1}{|N|!} \\sum_{\\pi \\in \\Pi_N} \\left[ v(P_i(\\pi) \\cup \\{i\\}) - v(P_i(\\pi)) \\right]\n$$\nwhere $\\Pi_N$ is the set of all permutations of $N$. This formulation establishes why the allocation depends on expectations over player orderings.\n\nTo obtain the closed-form expression in terms of marginal improvements across coalitions, we can group permutations based on the set of predecessors $P_i(\\pi)$. For any given coalition $S \\subseteq N \\setminus \\{i\\}$, let's count the number of permutations where $P_i(\\pi) = S$. For such a permutation, the players in $S$ must come first, followed by player $i$, followed by the remaining players in $N \\setminus (S \\cup \\{i\\})$.\n-   There are $|S|!$ ways to order the players within $S$.\n-   Player $i$ is in a fixed position after all players in $S$.\n-   There are $(|N| - |S| - 1)!$ ways to order the remaining players.\nThus, there are $|S|! (|N| - |S| - 1)!$ permutations for which player $i$ is preceded by precisely the coalition $S$. The marginal contribution for all these permutations is the same: $v(S \\cup \\{i\\}) - v(S)$.\n\nBy summing the contributions over all possible predecessor coalitions $S$, we can rewrite the expectation as:\n$$\n\\phi_i(v) = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|! (|N| - |S| - 1)!}{|N|!} \\left[ v(S \\cup \\{i\\}) - v(S) \\right]\n$$\nThis is the closed-form expression for the fair contribution of player $i$ in terms of their marginal improvements to every possible coalition they can join. It can be proven that this is the *unique* allocation that satisfies the three stated axioms, as well as a fourth axiom called additivity ($\\phi(v+w) = \\phi(v) + \\phi(w)$). The uniqueness proof relies on showing that any game $v$ can be uniquely represented as a linear combination of simpler \"unanimity games\", and that the Shapley value is the only linear operator satisfying the axioms for these basis games.\n\n2. Justification of Axioms for Digital Twin Accuracy Attribution\n\n-   **Symmetry**: This axiom is appropriate because it embodies the principle of substitutability. If two data owners, $A$ and $B$, provide data that is functionally indistinguishable for the DT model (e.g., data from identical sensors on parallel production lines under identical conditions), such that replacing $A$'s data with $B$'s data in any data combination yields the same model accuracy, then their contribution to the model's performance is identical. It is therefore fair and logical that their attributed value be equal. The symmetry axiom formalizes this intuition, ensuring the allocation reflects functional equivalence, not arbitrary labels.\n\n-   **Efficiency**: This axiom ensures a rational and complete accounting of the total value created. The grand coalition's value, $v(N)$, represents the maximum achievable accuracy with the available data. The efficiency axiom, $\\sum_{i \\in N} \\phi_i(v) = v(N)$, mandates that the sum of the attributed contributions of all owners must precisely equal this total value. This prevents any accuracy \"surplus\" or \"deficit\" from being unassigned, ensuring that the allocation scheme provides a closed-loop decomposition of the total performance gain. It reflects the collaborative nature of the enterprise: all the value generated by the group must be distributed among its members.\n\n-   **Null Player Property**: This axiom is crucial for handling cases where data is unusable or uninformative, which are common concerns under data governance frameworks like GDPR. An owner might be a null player for two primary reasons. First, legal constraints, such as a lack of valid consent for a specific processing purpose required by the DT, may render their data legally unusable. In this scenario, they cannot contribute to any coalition, and their marginal value is correctly assessed as zero. Second, their data might be statistically uninformative—for example, it could be pure noise, completely redundant with data already provided by another owner, or irrelevant to the physical process being modeled. In this case, adding their data provides no improvement to the DT's accuracy. The null player axiom ensures that owners are rewarded for providing useful, legally compliant information, not simply for possessing data.\n\n3. Computation of Fair Contribution for Owner A\n\nWe apply the derived Shapley value formula to compute the fair contribution for owner $A$, denoted $\\phi_A(v)$. The set of players is $N = \\{A, B, C\\}$, so $|N| = 3$. The formula is:\n$$\n\\phi_A(v) = \\sum_{S \\subseteq \\{B, C\\}} \\frac{|S|! (3 - |S| - 1)!}{3!} \\left[ v(S \\cup \\{A\\}) - v(S) \\right]\n$$\nWe evaluate the term for each subset $S$ of $\\{B, C\\}$:\n\n-   For $S = \\varnothing$:\n    The weight is $\\frac{0! (2)!}{3!} = \\frac{1 \\times 2}{6} = \\frac{1}{3}$.\n    The marginal contribution is $v(\\{A\\}) - v(\\varnothing) = 0.70 - 0 = 0.70$.\n    The term is $\\frac{1}{3} \\times 0.70$.\n\n-   For $S = \\{B\\}$:\n    The weight is $\\frac{1! (1)!}{3!} = \\frac{1 \\times 1}{6} = \\frac{1}{6}$.\n    The marginal contribution is $v(\\{A, B\\}) - v(\\{B\\}) = 0.78 - 0.68 = 0.10$.\n    The term is $\\frac{1}{6} \\times 0.10$.\n\n-   For $S = \\{C\\}$:\n    The weight is $\\frac{1! (1)!}{3!} = \\frac{1 \\times 1}{6} = \\frac{1}{6}$.\n    The marginal contribution is $v(\\{A, C\\}) - v(\\{C\\}) = 0.77 - 0.66 = 0.11$.\n    The term is $\\frac{1}{6} \\times 0.11$.\n\n-   For $S = \\{B, C\\}$:\n    The weight is $\\frac{2! (0)!}{3!} = \\frac{2 \\times 1}{6} = \\frac{1}{3}$.\n    The marginal contribution is $v(\\{A, B, C\\}) - v(\\{B, C\\}) = 0.82 - 0.75 = 0.07$.\n    The term is $\\frac{1}{3} \\times 0.07$.\n\nSumming these terms gives the Shapley value for owner $A$:\n$$\n\\phi_A(v) = \\left(\\frac{1}{3} \\times 0.70\\right) + \\left(\\frac{1}{6} \\times 0.10\\right) + \\left(\\frac{1}{6} \\times 0.11\\right) + \\left(\\frac{1}{3} \\times 0.07\\right)\n$$\n$$\n\\phi_A(v) = \\frac{0.70}{3} + \\frac{0.10}{6} + \\frac{0.11}{6} + \\frac{0.07}{3}\n$$\n$$\n\\phi_A(v) = \\frac{2 \\times 0.70}{6} + \\frac{0.10}{6} + \\frac{0.11}{6} + \\frac{2 \\times 0.07}{6}\n$$\n$$\n\\phi_A(v) = \\frac{1.40 + 0.10 + 0.11 + 0.14}{6} = \\frac{1.75}{6}\n$$\n$$\n\\phi_A(v) \\approx 0.291666...\n$$\nRounding to four significant figures, the fair contribution for owner $A$ is $0.2917$.",
            "answer": "$$\\boxed{0.2917}$$"
        }
    ]
}