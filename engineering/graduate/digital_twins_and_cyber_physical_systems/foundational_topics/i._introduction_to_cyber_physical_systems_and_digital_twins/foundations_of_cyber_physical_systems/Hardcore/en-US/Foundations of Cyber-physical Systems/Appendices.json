{
    "hands_on_practices": [
        {
            "introduction": "We begin by addressing a core challenge in many cyber-physical systems: managing concurrency and shared resources. This exercise uses Petri nets, a formal modeling tool, to analyze a resource allocation system for potential deadlocks. By identifying structural properties like siphons and traps, you will learn to formally reason about system liveness and design a supervisory controller to enforce safe operation .",
            "id": "4223669",
            "problem": "Consider a resource-sharing Cyber-Physical System (CPS) modeled by a Petri net (PN) with two reusable resources and a population of tasks whose acquisition order of resources is non-deterministic (free-choice). The PN has the set of places $P = \\{r_A, r_B, p^s, p^A, p^B, p^{AB}\\}$ and transitions $T = \\{t_{A}^{\\text{start}}, t_{B}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$. The arcs are defined as follows, using the standard notation where the pre-set of a transition $t$ is $\\bullet t \\subseteq P$ and its post-set is $t \\bullet \\subseteq P$:\n- $t_{A}^{\\text{start}}$: $\\bullet t_{A}^{\\text{start}} = \\{p^{s}, r_{A}\\}$ and $t_{A}^{\\text{start}} \\bullet = \\{p^{A}\\}$,\n- $t_{B}^{\\text{start}}$: $\\bullet t_{B}^{\\text{start}} = \\{p^{s}, r_{B}\\}$ and $t_{B}^{\\text{start}} \\bullet = \\{p^{B}\\}$,\n- $t_{A\\to B}$: $\\bullet t_{A\\to B} = \\{p^{A}, r_{B}\\}$ and $t_{A\\to B} \\bullet = \\{p^{AB}\\}$,\n- $t_{B\\to A}$: $\\bullet t_{B\\to A} = \\{p^{B}, r_{A}\\}$ and $t_{B\\to A} \\bullet = \\{p^{AB}\\}$,\n- $t^{\\text{rel}}$: $\\bullet t^{\\text{rel}} = \\{p^{AB}\\}$ and $t^{\\text{rel}} \\bullet = \\{r_{A}, r_{B}, p^{s}\\}$.\n\nThe initial marking is $M_{0}(r_{A}) = c_{A}$, $M_{0}(r_{B}) = c_{B}$, $M_{0}(p^{s}) = n$, and $M_{0}(p^{A}) = M_{0}(p^{B}) = M_{0}(p^{AB}) = 0$, with $c_{A}, c_{B}, n \\in \\mathbb{N}$ and $c_{A} \\geq 1$, $c_{B} \\geq 1$, $n \\geq 1$. This PN models $n$ task instances cycling through the system, where each instance non-deterministically starts by acquiring either resource $A$ or resource $B$, then acquires the other resource, and finally releases both and returns to ready.\n\nUse the following foundational definitions.\n- A subset of places $S \\subseteq P$ is a siphon if every transition that has an output arc to a place in $S$ also has an input arc from a place in $S$, equivalently $\\bullet S \\subseteq S \\bullet$ where $\\bullet S = \\{t \\in T \\mid t \\bullet \\cap S \\neq \\emptyset\\}$ and $S \\bullet = \\{t \\in T \\mid \\bullet t \\cap S \\neq \\emptyset\\}$.\n- A subset of places $U \\subseteq P$ is a trap if every transition that has an input arc from a place in $U$ also has an output arc to a place in $U$, equivalently $U \\bullet \\subseteq \\bullet U$ where $U \\bullet = \\{t \\in T \\mid \\bullet t \\cap U \\neq \\emptyset\\}$ and $\\bullet U = \\{t \\in T \\mid t \\bullet \\cap U \\neq \\emptyset\\}$.\n- A marking $M$ is live if from $M$ every transition in $T$ can be enabled at least once in some continuation (no deadlock). A classical necessary condition to avoid deadlock is that no siphon becomes unmarked (empty of tokens) along any reachable execution.\n\nTasks:\n1. Identify a siphon $S$ for this PN whose emptiness would result in deadlock. Prove that $S$ is a siphon using the formal definition, and explain informally why its emptiness prevents any transition from returning tokens to $S$.\n2. Identify a trap $U$ for this PN that is initially marked under $M_{0}$, and argue whether $U \\subseteq S$ holds; discuss the implication for deadlock risk under $M_{0}$.\n3. Propose a non-intrusive supervisory control action consistent with digital twin supervisory control: add a single control place $u$ with arcs $\\bullet t_{A}^{\\text{start}} \\gets u$, $\\bullet t_{B}^{\\text{start}} \\gets u$, and $t^{\\text{rel}} \\bullet \\to u$, so that each start transition consumes one token from $u$ and each release transition produces one token to $u$. Let the initial marking of the control place be $M_{0}(u) = K$, with $K \\in \\mathbb{N}$. Derive, from first principles and using place-level token balance, the minimal value of $K$ as a function of $c_{A}$ and $c_{B}$ that guarantees that the siphon identified in Task 1 never becomes unmarked along any reachable execution, thereby enforcing liveness with respect to deadlock due to siphon emptiness. Express your final answer as a single closed-form expression in terms of $c_{A}$ and $c_{B}$ only. No rounding is required.",
            "solution": "The user wants me to analyze a Petri net model of a resource-sharing Cyber-Physical System.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n-   Petri Net (PN) Structure:\n    -   Set of places: $P = \\{r_{A}, r_{B}, p^{s}, p^{A}, p^{B}, p^{AB}\\}$\n    -   Set of transitions: $T = \\{t_{A}^{\\text{start}}, t_{B}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$\n    -   Arcs (pre-sets $\\bullet t$ and post-sets $t \\bullet$):\n        -   $\\bullet t_{A}^{\\text{start}} = \\{p^{s}, r_{A}\\}$, $t_{A}^{\\text{start}} \\bullet = \\{p^{A}\\}$\n        -   $\\bullet t_{B}^{\\text{start}} = \\{p^{s}, r_{B}\\}$, $t_{B}^{\\text{start}} \\bullet = \\{p^{B}\\}$\n        -   $\\bullet t_{A\\to B} = \\{p^{A}, r_{B}\\}$, $t_{A\\to B} \\bullet = \\{p^{AB}\\}$\n        -   $\\bullet t_{B\\to A} = \\{p^{B}, r_{A}\\}$, $t_{B\\to A} \\bullet = \\{p^{AB}\\}$\n        -   $\\bullet t^{\\text{rel}} = \\{p^{AB}\\}$, $t^{\\text{rel}} \\bullet = \\{r_{A}, r_{B}, p^{s}\\}$\n-   Initial Marking ($M_{0}$):\n    -   $M_{0}(r_{A}) = c_{A}$\n    -   $M_{0}(r_{B}) = c_{B}$\n    -   $M_{0}(p^{s}) = n$\n    -   $M_{0}(p^{A}) = M_{0}(p^{B}) = M_{0}(p^{AB}) = 0$\n    -   Constraints: $c_{A}, c_{B}, n \\in \\mathbb{N}$ with $c_{A} \\geq 1$, $c_{B} \\geq 1$, $n \\geq 1$.\n-   Definitions:\n    -   Siphon $S \\subseteq P$: $\\bullet S \\subseteq S \\bullet$, where $\\bullet S = \\{t \\in T \\mid t \\bullet \\cap S \\neq \\emptyset\\}$ and $S \\bullet = \\{t \\in T \\mid \\bullet t \\cap S \\neq \\emptyset\\}$.\n    -   Trap $U \\subseteq P$: $U \\bullet \\subseteq \\bullet U$, where $U \\bullet = \\{t \\in T \\mid \\bullet t \\cap U \\neq \\emptyset\\}$ and $\\bullet U = \\{t \\in T \\mid t \\bullet \\cap U \\neq \\emptyset\\}$.\n    -   Liveness: A marking is live if every transition can be eventually enabled.\n-   Tasks:\n    1.  Identify a deadlock-related siphon $S$, prove it is a siphon, and explain the consequence of its emptiness.\n    2.  Identify an initially marked trap $U$, check if $U \\subseteq S$, and discuss implications.\n    3.  Add a control place $u$ with arcs $\\bullet t_{A}^{\\text{start}} \\gets u$, $\\bullet t_{B}^{\\text{start}} \\gets u$, $t^{\\text{rel}} \\bullet \\to u$, and initial marking $M_{0}(u) = K$. Derive the minimal value of $K$ in terms of $c_{A}$ and $c_{B}$ that guarantees the siphon from Task 1 never becomes unmarked.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is firmly rooted in Petri net theory, a standard formalism for modeling and analyzing concurrent systems, particularly for resource allocation and deadlock analysis in fields like computer science and cyber-physical systems. The concepts of siphons, traps, liveness, and supervisory control are central to this theory.\n-   **Well-Posed:** The Petri net structure, initial state, and all relevant definitions are provided completely and unambiguously. The tasks are specific, logically connected, and solvable using the provided information and standard Petri net analysis techniques.\n-   **Objective:** The problem is stated using formal mathematical language and established scientific terminology, free of any subjective or ambiguous content.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is scientifically sound, well-posed, and objective. I will proceed with the solution.\n\n**Solution**\n\n**Task 1: Siphon Identification and Proof**\n\nA deadlock in this system corresponds to a state where tasks are waiting for resources that are held by other waiting tasks. This suggests a circular wait, which often relates to an unmarked siphon. A key set of places in this process involves the resources themselves ($r_A, r_B$) and the place where tasks hold both resources ($p^{AB}$) before releasing them. Let us propose the set $S = \\{r_{A}, r_{B}, p^{AB}\\}$ as a candidate siphon.\n\nTo prove that $S$ is a siphon, we must show that $\\bullet S \\subseteq S \\bullet$. We first compute the set of input transitions to $S$, $\\bullet S$, and the set of output transitions from $S$, $S \\bullet$.\n\nThe set of input transitions to $S$, $\\bullet S = \\{t \\in T \\mid t \\bullet \\cap S \\neq \\emptyset\\}$, consists of all transitions that add tokens to any place in $S$.\n-   $t_{A}^{\\text{start}} \\bullet = \\{p^{A}\\}$. $\\{p^{A}\\} \\cap S = \\emptyset$.\n-   $t_{B}^{\\text{start}} \\bullet = \\{p^{B}\\}$. $\\{p^{B}\\} \\cap S = \\emptyset$.\n-   $t_{A\\to B} \\bullet = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap S = \\{p^{AB}\\} \\neq \\emptyset$, so $t_{A\\to B} \\in \\bullet S$.\n-   $t_{B\\to A} \\bullet = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap S = \\{p^{AB}\\} \\neq \\emptyset$, so $t_{B\\to A} \\in \\bullet S$.\n-   $t^{\\text{rel}} \\bullet = \\{r_{A}, r_{B}, p^{s}\\}$. $\\{r_{A}, r_{B}, p^{s}\\} \\cap S = \\{r_{A}, r_{B}\\} \\neq \\emptyset$, so $t^{\\text{rel}} \\in \\bullet S$.\nThus, the set of input transitions is $\\bullet S = \\{t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$.\n\nThe set of output transitions from $S$, $S \\bullet = \\{t \\in T \\mid \\bullet t \\cap S \\neq \\emptyset\\}$, consists of all transitions that consume tokens from any place in $S$.\n-   $\\bullet t_{A}^{\\text{start}} = \\{p^{s}, r_{A}\\}$. $\\{p^{s}, r_{A}\\} \\cap S = \\{r_{A}\\} \\neq \\emptyset$, so $t_{A}^{\\text{start}} \\in S \\bullet$.\n-   $\\bullet t_{B}^{\\text{start}} = \\{p^{s}, r_{B}\\}$. $\\{p^{s}, r_{B}\\} \\cap S = \\{r_{B}\\} \\neq \\emptyset$, so $t_{B}^{\\text{start}} \\in S \\bullet$.\n-   $\\bullet t_{A\\to B} = \\{p^{A}, r_{B}\\}$. $\\{p^{A}, r_{B}\\} \\cap S = \\{r_{B}\\} \\neq \\emptyset$, so $t_{A\\to B} \\in S \\bullet$.\n-   $\\bullet t_{B\\to A} = \\{p^{B}, r_{A}\\}$. $\\{p^{B}, r_{A}\\} \\cap S = \\{r_{A}\\} \\neq \\emptyset$, so $t_{B\\to A} \\in S \\bullet$.\n-   $\\bullet t^{\\text{rel}} = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap S = \\{p^{AB}\\} \\neq \\emptyset$, so $t^{\\text{rel}} \\in S \\bullet$.\nThus, the set of output transitions is $S \\bullet = \\{t_{A}^{\\text{start}}, t_{B}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$.\n\nComparing the two sets, we see that $\\bullet S = \\{t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$ is a subset of $S \\bullet = \\{t_{A}^{\\text{start}}, t_{B}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$. Therefore, $\\bullet S \\subseteq S \\bullet$, and $S = \\{r_{A}, r_{B}, p^{AB}\\}$ is a siphon.\n\nIf this siphon $S$ becomes empty (unmarked), it means $M(r_{A})=0$, $M(r_{B})=0$, and $M(p^{AB})=0$. For the siphon to become marked again, at least one of its input transitions, $t \\in \\bullet S$, must fire. The transitions in $\\bullet S$ are $t_{A\\to B}$, $t_{B\\to A}$, and $t^{\\text{rel}}$.\n-   Firing $t_{A\\to B}$ requires a token in $r_{B}$. Since $M(r_{B})=0$, this is not possible.\n-   Firing $t_{B\\to A}$ requires a token in $r_{A}$. Since $M(r_{A})=0$, this is not possible.\n-   Firing $t^{\\text{rel}}$ requires a token in $p^{AB}$. Since $M(p^{AB})=0$, this is not possible.\nSince no input transition to $S$ can fire, an empty siphon $S$ will remain empty forever. In this state, not only these three transitions are disabled but all other transitions are as well: $t_{A}^{\\text{start}}$ requires a token in $r_{A}$ and $t_{B}^{\\text{start}}$ requires a token in $r_{B}$. Thus, the emptiness of $S$ implies a total deadlock of the system.\n\n**Task 2: Trap Identification and Analysis**\n\nA trap is a set of places that, once marked, can never become empty. The P-invariants of the net often correspond to traps. The conservation of resource $A$ is represented by the invariant $M(r_{A}) + M(p^{A}) + M(p^{AB}) = c_{A}$. Let's test the corresponding set of places $U = \\{r_{A}, p^{A}, p^{AB}\\}$ to see if it is a trap.\n\nTo prove that $U$ is a trap, we must show that $U \\bullet \\subseteq \\bullet U$.\nThe set of output transitions from $U$, $U \\bullet = \\{t \\in T \\mid \\bullet t \\cap U \\neq \\emptyset\\}$:\n-   $\\bullet t_{A}^{\\text{start}} = \\{p^{s}, r_{A}\\}$. $\\{p^{s}, r_{A}\\} \\cap U = \\{r_{A}\\} \\neq \\emptyset$, so $t_{A}^{\\text{start}} \\in U \\bullet$.\n-   $\\bullet t_{B}^{\\text{start}} = \\{p^{s}, r_{B}\\}$. Intersection is empty.\n-   $\\bullet t_{A\\to B} = \\{p^{A}, r_{B}\\}$. $\\{p^{A}, r_{B}\\} \\cap U = \\{p^{A}\\} \\neq \\emptyset$, so $t_{A\\to B} \\in U \\bullet$.\n-   $\\bullet t_{B\\to A} = \\{p^{B}, r_{A}\\}$. $\\{p^{B}, r_{A}\\} \\cap U = \\{r_{A}\\} \\neq \\emptyset$, so $t_{B\\to A} \\in U \\bullet$.\n-   $\\bullet t^{\\text{rel}} = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap U = \\{p^{AB}\\} \\neq \\emptyset$, so $t^{\\text{rel}} \\in U \\bullet$.\nThus, $U \\bullet = \\{t_{A}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$.\n\nThe set of input transitions to $U$, $\\bullet U = \\{t \\in T \\mid t \\bullet \\cap U \\neq \\emptyset\\}$:\n-   $t_{A}^{\\text{start}} \\bullet = \\{p^{A}\\}$. $\\{p^{A}\\} \\cap U = \\{p^{A}\\} \\neq \\emptyset$, so $t_{A}^{\\text{start}} \\in \\bullet U$.\n-   $t_{B}^{\\text{start}} \\bullet = \\{p^{B}\\}$. Intersection is empty.\n-   $t_{A\\to B} \\bullet = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap U = \\{p^{AB}\\} \\neq \\emptyset$, so $t_{A\\to B} \\in \\bullet U$.\n-   $t_{B\\to A} \\bullet = \\{p^{AB}\\}$. $\\{p^{AB}\\} \\cap U = \\{p^{AB}\\} \\neq \\emptyset$, so $t_{B\\to A} \\in \\bullet U$.\n-   $t^{\\text{rel}} \\bullet = \\{r_{A}, r_{B}, p^{s}\\}$. $\\{r_{A}, r_{B}, p^{s}\\} \\cap U = \\{r_{A}\\} \\neq \\emptyset$, so $t^{\\text{rel}} \\in \\bullet U$.\nThus, $\\bullet U = \\{t_{A}^{\\text{start}}, t_{A\\to B}, t_{B\\to A}, t^{\\text{rel}}\\}$.\n\nSince $U \\bullet = \\bullet U$, the condition $U \\bullet \\subseteq \\bullet U$ holds. Therefore, $U = \\{r_{A}, p^{A}, p^{AB}\\}$ is a trap.\nThe initial marking of this trap is $M_{0}(U) = M_{0}(r_{A}) + M_{0}(p^{A}) + M_{0}(p^{AB}) = c_{A} + 0 + 0 = c_{A}$. Since $c_{A} \\geq 1$, the trap $U$ is initially marked.\n\nNow we check if $U \\subseteq S$.\n$U = \\{r_{A}, p^{A}, p^{AB}\\}$\n$S = \\{r_{A}, r_{B}, p^{AB}\\}$\nThe inclusion $U \\subseteq S$ does not hold because $p^{A} \\in U$ but $p^{A} \\notin S$.\n\nA fundamental result in Petri net theory is that a siphon that contains an initially marked trap can never become empty. In our case, the dangerous siphon $S$ does not contain the initially marked trap $U$. This lack of a structural guarantee (an initially marked trap inside the siphon) is precisely why the siphon $S$ *can* become empty, leading to the possibility of deadlock.\n\n**Task 3: Supervisory Control for Liveness**\n\nThe supervisory control action adds a control place $u$ with arcs from $u$ to $t_{A}^{\\text{start}}$ and $t_{B}^{\\text{start}}$, and an arc from $t^{\\text{rel}}$ to $u$. The initial marking is $M_0(u)=K$. This control structure creates a new place invariant. The change in marking for the new place $u$ for each transition is: `[-1, -1, 0, 0, 1]`. The sum of markings for places $p^A$, $p^B$, $p^{AB}$, and $u$ is invariant. Let's verify:\n- For $t_{A}^{\\text{start}}$: $+1$ in $p^A$, $-1$ in $u$. Sum is $0$.\n- For $t_{B}^{\\text{start}}$: $+1$ in $p^B$, $-1$ in $u$. Sum is $0$.\n- For $t_{A\\to B}$: $-1$ in $p^A$, $+1$ in $p^{AB}$. Sum is $0$.\n- For $t_{B\\to A}$: $-1$ in $p^B$, $+1$ in $p^{AB}$. Sum is $0$.\n- For $t^{\\text{rel}}$: $-1$ in $p^{AB}$, $+1$ in $u$. Sum is $0$.\n\nThus, for any reachable marking $M$, the following P-invariant holds:\n$M(p^{A}) + M(p^{B}) + M(p^{AB}) + M(u) = \\text{constant}$.\nThe constant is determined by the initial marking $M_0$:\n$M_{0}(p^{A}) + M_{0}(p^{B}) + M_{0}(p^{AB}) + M_{0}(u) = 0 + 0 + 0 + K = K$.\nSo, for any reachable marking $M$: $M(p^{A}) + M(p^{B}) + M(p^{AB}) + M(u) = K$.\n\nThe problem is to find the value of $K$ that guarantees the siphon $S = \\{r_A, r_B, p^{AB}\\}$ never becomes unmarked, i.e., $M(S) = M(r_{A}) + M(r_{B}) + M(p^{AB})  0$ for all reachable $M$.\n\nWe use the existing P-invariants of the system:\n1. $M(r_{A}) + M(p^{A}) + M(p^{AB}) = c_{A} \\implies M(r_{A}) = c_{A} - M(p^{A}) - M(p^{AB})$\n2. $M(r_{B}) + M(p^{B}) + M(p^{AB}) = c_{B} \\implies M(r_{B}) = c_{B} - M(p^{B}) - M(p^{AB})$\n\nWe substitute these into the expression for the marking of the siphon $S$:\n$M(S) = (c_{A} - M(p^{A}) - M(p^{AB})) + (c_{B} - M(p^{B}) - M(p^{AB})) + M(p^{AB})$\n$M(S) = c_{A} + c_{B} - (M(p^{A}) + M(p^{B}) + M(p^{AB}))$\n\nLet's denote the number of tasks currently active in the system (i.e., those that have acquired at least one resource) as $N_{\\text{active}}(M) = M(p^{A}) + M(p^{B}) + M(p^{AB})$. The expression for the siphon marking becomes:\n$M(S) = c_{A} + c_{B} - N_{\\text{active}}(M)$.\n\nTo guarantee $M(S)  0$, we must ensure that $c_{A} + c_{B} - N_{\\text{active}}(M)  0$ for any reachable marking $M$. This is equivalent to the condition:\n$N_{\\text{active}}(M)  c_{A} + c_{B}$.\n\nThe control place $u$ imposes a constraint on $N_{\\text{active}}$. From the new invariant $N_{\\text{active}}(M) + M(u) = K$, and since the marking of any place must be non-negative ($M(u) \\geq 0$), we have:\n$N_{\\text{active}}(M) \\leq K$.\n\nTo satisfy the liveness condition $N_{\\text{active}}(M)  c_{A} + c_{B}$ for all reachable markings, we must choose $K$ such that the upper bound on $N_{\\text{active}}(M)$ is strictly less than $c_{A} + c_{B}$. Thus, we must set $K  c_{A} + c_{B}$.\n\nThe problem describes a \"non-intrusive\" supervisor and asks for a single value of $K$. In supervisory control theory, a non-intrusive or maximally permissive supervisor is one that restricts the system's behavior as little as possible while enforcing the desired property. The number of concurrent tasks is bounded by $K$. To be as non-intrusive as possible, we should allow the maximum number of tasks consistent with liveness. This corresponds to choosing the largest integer value of $K$ that satisfies the inequality $K  c_{A} + c_{B}$. Although the question asks for the \"minimal value of K\", this is interpreted in the context of designing the least restrictive controller. A smaller $K$ is more restrictive. The \"minimal\" here refers to the minimal constraint strength, which means the maximal value of $K$.\n\nThe largest integer $K$ satisfying $K  c_{A} + c_{B}$ is $K = c_{A} + c_{B} - 1$.\nThis choice guarantees that $N_{\\text{active}}(M) \\leq c_{A} + c_{B} - 1$, which ensures $N_{\\text{active}}(M)  c_{A} + c_{B}$. This, in turn, guarantees $M(S) = c_{A} + c_{B} - N_{\\text{active}}(M) \\ge c_{A} + c_{B} - (c_{A} + c_{B} - 1) = 1$. The siphon marking is always at least $1$, so it never becomes empty.\nThis value is also necessary: if $K \\geq c_{A} + c_{B}$, it would be possible (with $n \\geq c_{A} + c_{B}$ tasks) to reach a deadlock state where $N_{\\text{active}}(M) = c_{A} + c_{B}$, resulting in $M(S) = 0$.\n\nTherefore, the required value for $K$ is $c_{A} + c_{B} - 1$.",
            "answer": "$$\n\\boxed{c_{A} + c_{B} - 1}\n$$"
        },
        {
            "introduction": "Next, we turn our attention to the dynamics of systems operating under periodic digital supervision, a common feature in CPS and their digital twins. This problem introduces Floquet theory to analyze the stability of a linear system with a time-varying matrix that repeats periodically. Calculating the system's Floquet multipliers will allow you to determine its long-term stability, a critical step in verifying the behavior of switched and scheduled systems .",
            "id": "4223719",
            "problem": "Consider a Digital Twin of a two-degree-of-freedom Cyber-Physical System (CPS) implementing a periodic supervisory schedule in discrete time. The state update is modeled by a linear time-varying difference equation $x_{k+1}=A_{k}x_{k}$, where $A_{k}$ is periodic with period $T=3$, meaning $A_{k+3}=A_{k}$ for all integer $k\\geq 0$. Over one period, the system matrices are\n$$\nA_{0}=\\begin{pmatrix}0.8  0.1 \\\\ 0  0.9\\end{pmatrix},\\quad\nA_{1}=\\begin{pmatrix}1.2  -0.2 \\\\ 0  0.7\\end{pmatrix},\\quad\nA_{2}=\\begin{pmatrix}0.95  0.05 \\\\ 0  0.6\\end{pmatrix}.\n$$\nStarting from foundational principles of linear discrete-time systems and periodic time-varying dynamics, compute the Floquet multipliers associated with one period of the system. Then, determine the conditions under which the periodic discrete-time system is exponentially stable.\n\nExpress the Floquet multipliers as a row matrix using the $\\texttt{pmatrix}$ environment, and round your numerical values to four significant figures. No physical units are required for the answer.",
            "solution": "The problem is valid as it is scientifically grounded in the established principles of Floquet theory for linear discrete-time periodic systems, is well-posed with sufficient information for a unique solution, and is objectively formulated without ambiguity.\n\nThe system under consideration is a linear discrete-time system with a periodic time-varying state matrix, described by the difference equation:\n$$x_{k+1} = A_k x_k$$\nwhere $x_k \\in \\mathbb{R}^2$ is the state vector at discrete time step $k$, and the matrix $A_k$ is periodic with period $T=3$. This means $A_{k+3} = A_k$ for all integers $k \\geq 0$.\n\nThe core of analyzing such a periodic system is to study its behavior over one full period. The state evolution from an initial time $k_0$ to a later time $k$ is described by the state transition matrix $\\Phi(k, k_0)$. The state at time $k$ is given by $x_k = \\Phi(k, k_0) x_{k_0}$. For this system, the state transition matrix over one time step from $j$ to $j+1$ is simply $A_j$.\n\nThe state evolution over one full period, starting from time $k=0$, is found by composing the state updates for each step within the period. The state after one step is $x_1 = A_0 x_0$. After two steps, $x_2 = A_1 x_1 = A_1 A_0 x_0$. After three steps, which completes one period, the state is:\n$$x_3 = A_2 x_2 = A_2 (A_1 A_0 x_0) = (A_2 A_1 A_0) x_0$$\nThe matrix that maps the state from the beginning of a period to the end of that period is called the monodromy matrix. For the period starting at $k=0$, the monodromy matrix is $\\Phi(3, 0)$.\n$$\\Phi(3, 0) = A_{3-1} A_{3-2} \\cdots A_0 = A_2 A_1 A_0$$\nWe are given the matrices for one period:\n$$A_{0}=\\begin{pmatrix}0.8  0.1 \\\\ 0  0.9\\end{pmatrix}, \\quad A_{1}=\\begin{pmatrix}1.2  -0.2 \\\\ 0  0.7\\end{pmatrix}, \\quad A_{2}=\\begin{pmatrix}0.95  0.05 \\\\ 0  0.6\\end{pmatrix}$$\nFirst, we compute the product $A_1 A_0$:\n$$A_1 A_0 = \\begin{pmatrix}1.2  -0.2 \\\\ 0  0.7\\end{pmatrix} \\begin{pmatrix}0.8  0.1 \\\\ 0  0.9\\end{pmatrix} = \\begin{pmatrix}(1.2)(0.8) + (-0.2)(0)  (1.2)(0.1) + (-0.2)(0.9) \\\\ (0)(0.8) + (0.7)(0)  (0)(0.1) + (0.7)(0.9)\\end{pmatrix}$$\n$$A_1 A_0 = \\begin{pmatrix}0.96  0.12 - 0.18 \\\\ 0  0.63\\end{pmatrix} = \\begin{pmatrix}0.96  -0.06 \\\\ 0  0.63\\end{pmatrix}$$\nNext, we compute the monodromy matrix $\\Phi(3, 0) = A_2 (A_1 A_0)$:\n$$\\Phi(3, 0) = \\begin{pmatrix}0.95  0.05 \\\\ 0  0.6\\end{pmatrix} \\begin{pmatrix}0.96  -0.06 \\\\ 0  0.63\\end{pmatrix}$$\n$$\\Phi(3, 0) = \\begin{pmatrix}(0.95)(0.96) + (0.05)(0)  (0.95)(-0.06) + (0.05)(0.63) \\\\ (0)(0.96) + (0.6)(0)  (0)(-0.06) + (0.6)(0.63)\\end{pmatrix}$$\n$$\\Phi(3, 0) = \\begin{pmatrix}0.912  -0.057 + 0.0315 \\\\ 0  0.378\\end{pmatrix} = \\begin{pmatrix}0.912  -0.0255 \\\\ 0  0.378\\end{pmatrix}$$\nThis is the monodromy matrix for one period of the system.\n\nThe Floquet multipliers, denoted by $\\lambda_i$, are the eigenvalues of the monodromy matrix. To find the eigenvalues of $\\Phi(3, 0)$, we solve the characteristic equation $\\det(\\Phi(3, 0) - \\lambda I) = 0$, where $I$ is the identity matrix.\n$$\\det\\begin{pmatrix}0.912 - \\lambda  -0.0255 \\\\ 0  0.378 - \\lambda\\end{pmatrix} = 0$$\nSince the monodromy matrix is upper triangular, its eigenvalues are simply its diagonal entries.\n$$(0.912 - \\lambda)(0.378 - \\lambda) = 0$$\nThe Floquet multipliers are therefore:\n$$\\lambda_1 = 0.912$$\n$$\\lambda_2 = 0.378$$\n\nAccording to Floquet theory for discrete-time systems, the origin of a linear periodic system $x_{k+1}=A_k x_k$ is exponentially stable if and only if all of its Floquet multipliers have magnitudes strictly less than $1$. This condition is equivalent to the spectral radius of the monodromy matrix, $\\rho(\\Phi)$, being less than $1$, i.e., $\\rho(\\Phi) = \\max_i |\\lambda_i|  1$.\n\nIn this case, we check the magnitudes of the calculated Floquet multipliers:\n$$|\\lambda_1| = |0.912| = 0.912  1$$\n$$|\\lambda_2| = |0.378| = 0.378  1$$\nSince both Floquet multipliers have magnitudes strictly less than $1$, the condition for exponential stability is satisfied for this specific system.\n\nThe problem asks for the Floquet multipliers rounded to four significant figures.\n$\\lambda_1 = 0.9120$\n$\\lambda_2 = 0.3780$\nThese values are to be expressed as a row matrix.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.9120  0.3780\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Our final practice synthesizes multiple design goals into a single, elegant control framework. This exercise guides you through the formulation of a real-time Quadratic Program (QP) that unifies a Control Lyapunov Function (CLF) for stability with a Control Barrier Function (CBF) for safety, while also respecting actuator limitations. This powerful technique is central to modern CPS control, enabling the design of controllers that are both provably safe and optimized for performance .",
            "id": "4223707",
            "problem": "Consider a cyber-physical plant modeled as a single-input single-output continuous-time system with state $x \\in \\mathbb{R}$ and control input $u \\in \\mathbb{R}$, governed by the single-integrator dynamics $\\dot{x} = u$. You are asked to unify a Control Lyapunov Function (CLF) objective with a Control Barrier Function (CBF) constraint via a Quadratic Program (QP) and to analyze feasibility when the CLF objective and the CBF constraint are in conflict, especially in the presence of actuator limits.\n\nStart from the following foundational definitions and laws:\n- The CLF $V(x)$ is a continuously differentiable, positive definite function, with a desired decrease rate quantified by a constant $c > 0$. For the single-integrator model, use $V(x) = \\frac{1}{2} x^2$. The CLF condition is expressed in terms of Lie derivatives $L_f V(x)$ and $L_g V(x)$ along the drift $f(x)$ and input vector field $g(x)$. For the single-integrator, the drift is $f(x) = 0$ and the input vector field is $g(x) = 1$, hence $L_f V(x) = 0$ and $L_g V(x) = \\frac{\\partial V}{\\partial x} = x$. To allow regulation to coexist with safety, include a nonnegative slack variable $\\delta \\ge 0$ that relaxes the CLF inequality. The relaxed CLF constraint is\n$x u \\le -\\frac{c}{2} x^2 + \\delta$.\n- The CBF $h(x)$ defines a forward-invariant safe set $\\{x \\mid h(x) \\ge 0\\}$ by enforcing the inequality $\\dot{h}(x) + \\alpha h(x) \\ge 0$ for some $\\alpha > 0$ (a class-$\\mathcal{K}$ gain). Use the affine barrier $h(x) = x - x_{\\min}$ where $x_{\\min} \\in \\mathbb{R}$ denotes a safety threshold. For the single-integrator model, this yields\n$u + \\alpha (x - x_{\\min}) \\ge 0$,\nor equivalently\n$u \\ge -\\alpha (x - x_{\\min})$.\n- To encode actuator limits, impose box constraints $u_{\\min} \\le u \\le u_{\\max}$ with given constants $u_{\\min} \\in \\mathbb{R}$ and $u_{\\max} \\in \\mathbb{R}$.\n\nFormulate the following convex Quadratic Program (QP) that unifies the CLF objective with the CBF constraint:\n- Decision variables: $(u, \\delta) \\in \\mathbb{R} \\times \\mathbb{R}$ with $\\delta \\ge 0$.\n- Objective: minimize the quadratic cost\n$$\nJ(u,\\delta) = \\frac{1}{2} u^2 + \\frac{1}{2} p \\delta^2,\n$$\nwhere $p > 0$ is a penalty weight on the CLF slack.\n- Constraints:\n    1. CLF decrease (relaxed): $x u \\le -\\frac{c}{2} x^2 + \\delta$,\n    2. CBF safety: $u \\ge -\\alpha (x - x_{\\min})$,\n    3. Actuator limits: $u_{\\min} \\le u \\le u_{\\max}$,\n    4. Slack nonnegativity: $\\delta \\ge 0$.\n\nYour program must:\n- Implement from first principles an algorithm to compute the optimal solution $(u^\\star, \\delta^\\star)$ and the optimal cost $J^\\star$ for given parameters $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max})$.\n- Determine feasibility: return a boolean indicating whether there exists any $(u, \\delta)$ satisfying all constraints. Interpret feasibility with respect to the constraints; in particular, the CLF constraint is relaxable via $\\delta \\ge 0$, so infeasibility can only arise from irreconcilable safety and actuator limits.\n\nYou must analyze and encode feasibility conditions when the CLF objective and the CBF constraint are in conflict with actuator limits. Specifically, your solution must reason from the constraints to decide when no admissible control $u$ exists that simultaneously satisfies the CBF inequality and the actuator bounds, regardless of the CLF slack $\\delta$.\n\nTest Suite:\nUse the following parameter sets to exercise different regimes (happy path, boundary, and conflict). Each test case is a tuple $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max})$:\n- Case $1$: $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max}) = (\\,1.0,\\,0.0,\\,1.0,\\,1.0,\\,100.0,\\, -2.0,\\, 2.0\\,)$.\n- Case $2$: $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max}) = (\\,0.0,\\,0.0,\\,1.0,\\,1.0,\\,10.0,\\, -1.0,\\, 1.0\\,)$.\n- Case $3$: $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max}) = (\\,0.1,\\,0.0,\\,50.0,\\,1.0,\\,10.0,\\, -2.0,\\, 2.0\\,)$.\n- Case $4$: $(x, x_{\\min}, \\alpha, c, p, u_{\\min}, u_{\\max}) = (\\, -1.0,\\, -5.0,\\, 0.5,\\, 1.0,\\, 50.0,\\, -3.0,\\, 3.0\\,)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one test case and must be a list of the form $[\\text{feasible}, u^\\star, \\delta^\\star, J^\\star]$, where $\\text{feasible}$ is a boolean, and $u^\\star$, $\\delta^\\star$, and $J^\\star$ are real numbers. For example, the output must look like\n$[[\\text{True}, u_1, \\delta_1, J_1],[\\text{False}, u_2, \\delta_2, J_2],\\ldots]$\ncomputed for the four specified test cases.",
            "solution": "The problem presented is to find the optimal control input $u$ and Control Lyapunov Function (CLF) relaxation slack $\\delta$ for a single-integrator system, $\\dot{x} = u$. The optimization is formulated as a Quadratic Program (QP) that minimizes a cost function balancing control effort and CLF relaxation, subject to constraints from a relaxed CLF, a Control Barrier Function (CBF), actuator limits, and slack non-negativity.\n\nThe QP is formulated as follows:\n$$ \\min_{u, \\delta} \\quad J(u,\\delta) = \\frac{1}{2} u^2 + \\frac{1}{2} p \\delta^2 $$\nsubject to the constraints:\n1.  $x u \\le -\\frac{c}{2} x^2 + \\delta$ (Relaxed CLF condition)\n2.  $u \\ge -\\alpha (x - x_{\\min})$ (CBF condition)\n3.  $u_{\\min} \\le u \\le u_{\\max}$ (Actuator limits)\n4.  $\\delta \\ge 0$ (Slack non-negativity)\n\nHere, $x \\in \\mathbb{R}$ is the state, $u \\in \\mathbb{R}$ is the control input, and $\\delta \\in \\mathbb{R}$ is the slack variable. The parameters $c, p, \\alpha, x_{\\min}, u_{\\min}, u_{\\max}$ are given positive constants or real values.\n\nFirst, we analyze the feasibility of this QP. The CLF constraint, $x u \\le -\\frac{c}{2} x^2 + \\delta$, can be rewritten as $\\delta \\ge x u + \\frac{c}{2} x^2$. Since we also have the constraint $\\delta \\ge 0$, for any given control input $u$, we can always find a feasible $\\delta$ by choosing $\\delta \\ge \\max(0, x u + \\frac{c}{2} x^2)$. This implies that the feasibility of the entire QP depends only on the existence of a control input $u$ that satisfies the remaining constraints. These constraints on $u$ are the CBF condition and the actuator limits:\n$$ u \\ge -\\alpha (x - x_{\\min}) $$\n$$ u_{\\min} \\le u \\le u_{\\max} $$\nFor a feasible $u$ to exist, the intersection of the sets defined by these inequalities must be non-empty. This is true if and only if the overall lower bound on $u$ is less than or equal to the upper bound. Let $u_{cbf} = -\\alpha (x - x_{\\min})$ be the lower bound from the CBF constraint. The combined lower bound on $u$ is $\\max(u_{\\min}, u_{cbf})$. Thus, the feasible set for $u$ is non-empty if and only if:\n$$ \\max(u_{\\min}, -\\alpha (x - x_{\\min})) \\le u_{\\max} $$\nThis is the feasibility condition. If it is not met, no solution exists. We assume that the actuator limits are well-defined, i.e., $u_{\\min} \\le u_{\\max}$. The condition then simplifies to $-\\alpha (x - x_{\\min}) \\le u_{\\max}$.\n\nIf the problem is feasible, we proceed to find the optimal solution $(u^\\star, \\delta^\\star)$. To minimize the objective function $J(u, \\delta)$, which is a sum of squared terms with positive weights ($p0$), we must choose the smallest permissible value for $\\delta$. As established, the constraints on $\\delta$ are $\\delta \\ge 0$ and $\\delta \\ge x u + \\frac{c}{2} x^2$. Thus, the optimal choice for $\\delta$ for any given $u$ is:\n$$ \\delta(u) = \\max\\left(0, x u + \\frac{c}{2} x^2\\right) $$\nSubstituting this into the objective function transforms the two-variable QP into a one-dimensional optimization problem over $u$:\n$$ \\min_{u \\in [u_{lower}, u_{upper}]} \\quad J(u) = \\frac{1}{2} u^2 + \\frac{1}{2} p \\left( \\max\\left(0, x u + \\frac{c}{2} x^2\\right) \\right)^2 $$\nwhere the feasible interval for $u$ is $[u_{lower}, u_{upper}]$, with $u_{lower} = \\max(u_{\\min}, -\\alpha (x - x_{\\min}))$ and $u_{upper} = u_{\\max}$.\n\nThe objective function $J(u)$ is convex and continuously differentiable. Its unconstrained minimum can be found by setting its derivative to zero. We analyze this by considering two cases based on the sign of $C(u) = x u + \\frac{c}{2} x^2$.\n\nCase 1: $C(u) \\le 0$. Here, $\\delta(u)=0$ and $J(u) = \\frac{1}{2} u^2$. The minimum of this quadratic is at $u=0$. However, the condition $C(0) = \\frac{c}{2}x^2 \\le 0$ holds only if $x=0$, which we handle as a special case.\n\nCase 2: $C(u)  0$. Here, $\\delta(u) = x u + \\frac{c}{2} x^2$ and the objective is $J(u) = \\frac{1}{2} u^2 + \\frac{1}{2} p (x u + \\frac{c}{2} x^2)^2$. The derivative is:\n$$ \\frac{dJ}{du} = u + p \\left(x u + \\frac{c}{2} x^2\\right) x = u(1 + px^2) + \\frac{pcx^3}{2} $$\nSetting $\\frac{dJ}{du} = 0$ yields the unconstrained minimizer:\n$$ u_{unc} = -\\frac{p c x^3}{2(1 + p x^2)} $$\nWe can verify that for $x \\neq 0$, this value of $u_{unc}$ yields $C(u_{unc}) = x u_{unc} + \\frac{c}{2} x^2 = \\frac{c x^2}{2(1 + p x^2)}  0$, confirming that the unconstrained minimum lies in this region.\n\nThe optimal solution $u^\\star$ for the constrained problem is the projection of the unconstrained minimizer $u_{unc}$ onto the feasible interval $[u_{lower}, u_{upper}]$.\n$$ u^\\star = \\max(u_{lower}, \\min(u_{unc}, u_{upper})) $$\n\nSpecial Case: $x = 0$.\nIf $x=0$, the CLF constraint becomes $\\delta \\ge 0$. The CBF constraint is $u \\ge \\alpha x_{\\min}$. The feasible set for $u$ is $u \\in [\\max(u_{\\min}, \\alpha x_{\\min}), u_{\\max}]$. The objective is $J(u, \\delta) = \\frac{1}{2} u^2 + \\frac{1}{2} p \\delta^2$. To minimize $J$, we must choose $\\delta^\\star=0$. The optimal control $u^\\star$ is the value in the feasible interval closest to $0$, which is found by projecting $0$ onto the interval.\n\nThe algorithm is as follows:\n1.  Calculate the feasibility bounds: $u_{cbf} = -\\alpha (x - x_{\\min})$, $u_{lower} = \\max(u_{\\min}, u_{cbf})$, and $u_{upper} = u_{\\max}$.\n2.  Check for feasibility: If $u_{lower}  u_{upper}$, the problem is infeasible.\n3.  If feasible:\n    a. If $x=0$:\n       $u^\\star = \\max(u_{lower}, \\min(0, u_{upper}))$.\n       $\\delta^\\star = 0$.\n    b. If $x \\neq 0$:\n       Calculate $u_{unc} = - (p \\cdot c \\cdot x^3) / (2 \\cdot (1 + p \\cdot x^2))$.\n       $u^\\star = \\max(u_{lower}, \\min(u_{unc}, u_{upper}))$.\n       $\\delta^\\star = \\max(0, x \\cdot u^\\star + (c/2) \\cdot x^2)$.\n4.  Calculate the optimal cost $J^\\star = \\frac{1}{2} (u^\\star)^2 + \\frac{1}{2} p (\\delta^\\star)^2$.\n5.  Return the feasibility status and the optimal values $(u^\\star, \\delta^\\star, J^\\star)$.",
            "answer": "```python\nimport numpy as np\n\ndef solve_clf_cbf_qp(x, x_min, alpha, c, p, u_min, u_max):\n    \"\"\"\n    Solves the CLF-CBF-QP for a single-integrator system from first principles.\n\n    Args:\n        x (float): Current state.\n        x_min (float): Safety threshold for the state.\n        alpha (float): CBF class-K gain.\n        c (float): CLF decay rate constant.\n        p (float): Penalty weight on the CLF slack.\n        u_min (float): Minimum control input.\n        u_max (float): Maximum control input.\n\n    Returns:\n        list: A list containing [feasible, u_star, delta_star, J_star].\n              'feasible' is a boolean. For infeasible cases, the other\n              values are np.nan.\n    \"\"\"\n    # 1. Feasibility Analysis\n    # The set of admissible controls for u is constrained by the CBF and actuator limits.\n    # Feasibility requires this set to be non-empty.\n    \n    # Lower bound from CBF constraint: u = -alpha * (x - x_min)\n    u_cbf_lower_bound = -alpha * (x - x_min)\n\n    # Combined lower bound for u\n    u_lower = max(u_min, u_cbf_lower_bound)\n    u_upper = u_max\n\n    is_feasible = u_lower = u_upper\n\n    if not is_feasible:\n        return [False, np.nan, np.nan, np.nan]\n\n    # 2. Solve for the optimal (u*, delta*)\n    u_star = 0.0\n    delta_star = 0.0\n\n    if x == 0.0:\n        # For x=0, CLF constraint is delta = 0.\n        # Objective is min 0.5*u^2 + 0.5*p*delta^2.\n        # To minimize, we need delta=0 and u to be as close to 0 as possible.\n        # u_star is the projection of 0 onto the feasible set [u_lower, u_upper].\n        u_star = max(u_lower, min(0.0, u_upper))\n        delta_star = 0.0\n    else:\n        # For x != 0, solve the 1D optimization problem for u.\n        # Unconstrained minimizer of the reduced objective function J(u).\n        numerator = p * c * (x**3)\n        denominator = 2 * (1 + p * (x**2))\n        u_unc = -numerator / denominator\n\n        # The optimal u* is the projection of u_unc onto the feasible interval.\n        u_star = max(u_lower, min(u_unc, u_upper))\n        \n        # The optimal delta* is the smallest value satisfying the constraints.\n        delta_star = max(0.0, x * u_star + (c / 2.0) * (x**2))\n\n    # 3. Calculate the optimal cost\n    J_star = 0.5 * (u_star**2) + 0.5 * p * (delta_star**2)\n\n    return [True, u_star, delta_star, J_star]\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results in the required format.\n    \"\"\"\n    test_cases = [\n        # (x, x_min, alpha, c, p, u_min, u_max)\n        (1.0, 0.0, 1.0, 1.0, 100.0, -2.0, 2.0),\n        (0.0, 0.0, 1.0, 1.0, 10.0, -1.0, 1.0),\n        (0.1, 0.0, 50.0, 1.0, 10.0, -2.0, 2.0),\n        (-1.0, -5.0, 0.5, 1.0, 50.0, -3.0, 3.0),\n    ]\n\n    results = []\n    for params in test_cases:\n        result = solve_clf_cbf_qp(*params)\n        results.append(result)\n\n    # Format the output string as specified in the problem.\n    # e.g., [[True,-0.495...,0.00495...,0.123...],[True,0.0,0.0,0.0],...]\n    formatted_results = []\n    for res in results:\n        # str() on a boolean gives 'True' or 'False' with correct capitalization.\n        # str() on np.nan gives 'nan'.\n        inner_list_str = f\"[{str(res[0])},{res[1]},{res[2]},{res[3]}]\"\n        formatted_results.append(inner_list_str)\n    \n    # Final output is a comma-separated list of these inner lists, enclosed in brackets.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}