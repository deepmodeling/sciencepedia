{
    "hands_on_practices": [
        {
            "introduction": "This first practice delves into the fundamental solution of a linear time-invariant (LTI) state-space model, a cornerstone for simulating and predicting the behavior of cyber-physical systems. By working through this problem , you will compute a system's complete output by decomposing it into its two constituent parts: the homogeneous response, which describes the system's evolution from its initial state, and the forced response, which captures its reaction to external inputs. This exercise is crucial for developing an intuitive grasp of how a system's dynamics are shaped by both its internal energy and external stimuli.",
            "id": "4229606",
            "problem": "A Digital Twin (DT) of a simple actuator-sensor loop within a Cyber-Physical System (CPS) is modeled by a continuous-time Linear Time-Invariant (LTI) state-space representation with a state vector of dimension $2$, a single input, and a single output. The governing equations are\n$$\\dot{x}(t) = A x(t) + B u(t), \\quad y(t) = C x(t) + D u(t),$$\nwhere\n$$A = \\begin{pmatrix} -1  1 \\\\ 0  -1 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 1  1 \\end{pmatrix}, \\quad D = 2,$$\nthe input is\n$$u(t) = \\exp(-t),$$\nand the initial condition is\n$$x(0) = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}.$$\nStarting from the fundamental definitions of the LTI state-space model and the principle of superposition, derive the output $y(t)$ for $t \\geq 0$ by decomposing the response into homogeneous and forced components. Explain the conceptual roles of the homogeneous response (due to the initial condition) and the forced response (due to the input and direct feedthrough) in the context of the DT-CPS representation, ensuring scientific realism in the interpretation.\n\nProvide your final result as a single closed-form analytic expression for $y(t)$. No rounding is required; express your answer exactly without units.",
            "solution": "The problem statement is evaluated and found to be valid. It is a well-posed problem in linear systems theory, providing all necessary information (system matrices $A$, $B$, $C$, $D$, initial condition $x(0)$, and input function $u(t)$) to derive a unique, meaningful solution for the output $y(t)$. The problem is scientifically grounded, objective, and its request for an interpretation of the response components aligns with the pedagogical goals of understanding system dynamics in a cyber-physical context.\n\nThe governing equations for the continuous-time Linear Time-Invariant (LTI) system are:\n$$\n\\dot{x}(t) = A x(t) + B u(t)\n$$\n$$\ny(t) = C x(t) + D u(t)\n$$\nwith matrices and vectors given as:\n$$\nA = \\begin{pmatrix} -1  1 \\\\ 0  -1 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 1  1 \\end{pmatrix}, \\quad D = 2, \\quad x(0) = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nand input:\n$$\nu(t) = \\exp(-t) \\quad \\text{for } t \\geq 0\n$$\n\nThe total response of an LTI system can be decomposed by the principle of superposition into two components: the homogeneous response (also known as the zero-input response), which is due to the initial conditions of the system, and the forced response (also known as the zero-state response), which is due to the external input.\n\nThe total output is thus $y(t) = y_h(t) + y_f(t)$.\n\n1.  **Homogeneous Response ($y_h(t)$)**\n\nThe homogeneous response is the solution to the system with the input set to zero, driven only by the initial state $x(0)$.\nThe state evolves according to $\\dot{x}_h(t) = A x_h(t)$ with the initial condition $x_h(0) = x(0)$. The solution is given by $x_h(t) = e^{At} x(0)$, where $e^{At}$ is the state-transition matrix. The corresponding output is $y_h(t) = C x_h(t) = C e^{At} x(0)$.\n\nTo compute the matrix exponential $e^{At}$, we decompose the matrix $A$ into simpler components. Let $A = -I + N$, where $I$ is the $2 \\times 2$ identity matrix and $N = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}$. Since the identity matrix $I$ commutes with any matrix, we can write $e^{At} = e^{(-I+N)t} = e^{-It}e^{Nt}$.\n\nThe matrix $e^{-It}$ is simply $e^{-t}I = \\begin{pmatrix} e^{-t}  0 \\\\ 0  e^{-t} \\end{pmatrix}$.\nThe matrix $N$ is nilpotent, as $N^2 = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}$. All higher powers are also the zero matrix.\nThe Taylor series for $e^{Nt}$ truncates:\n$$\ne^{Nt} = I + Nt + \\frac{(Nt)^2}{2!} + \\dots = I + Nt = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 0  t \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 1  t \\\\ 0  1 \\end{pmatrix}\n$$\nCombining these results, the state-transition matrix is:\n$$\ne^{At} = e^{-t}I (I + Nt) = e^{-t} \\begin{pmatrix} 1  t \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} e^{-t}  t \\exp(-t) \\\\ 0  e^{-t} \\end{pmatrix}\n$$\nNow, we can find the homogeneous state response:\n$$\nx_h(t) = e^{At} x(0) = \\begin{pmatrix} e^{-t}  t \\exp(-t) \\\\ 0  e^{-t} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} t \\exp(-t) \\\\ e^{-t} \\end{pmatrix}\n$$\nAnd the homogeneous output response:\n$$\ny_h(t) = C x_h(t) = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} t \\exp(-t) \\\\ e^{-t} \\end{pmatrix} = t \\exp(-t) + e^{-t} = (t+1)\\exp(-t)\n$$\n\nConceptually, this homogeneous response represents the natural dynamics of the Digital Twin's model. It shows how the actuator-sensor loop's state evolves from its non-zero initial condition ($x(0)$) if no external command ($u(t)=0$) is applied. The terms $e^{-t}$ and $t \\exp(-t)$ are the system's natural modes, dictated by the repeated eigenvalue of $A$ at $-1$. The decay to zero confirms the system is stable, meaning any initial energy or displacement in the system will naturally dissipate over time.\n\n2.  **Forced Response ($y_f(t)$)**\n\nThe forced response is the solution to the system with zero initial state ($x(0)=0$), driven only by the input $u(t)$. The state equation is $\\dot{x}_f(t) = A x_f(t) + B u(t)$ with $x_f(0)=0$. The solution is given by the convolution integral:\n$$\nx_f(t) = \\int_{0}^{t} e^{A(t-\\tau)} B u(\\tau) \\,d\\tau\n$$\nThe corresponding output is $y_f(t) = C x_f(t) + D u(t)$.\n\nFirst, we compute the integrand:\n$$\ne^{A(t-\\tau)} B u(\\tau) = \\begin{pmatrix} e^{-(t-\\tau)}  (t-\\tau)\\exp(-(t-\\tau)) \\\\ 0  e^{-(t-\\tau)} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\exp(-\\tau)\n$$\n$$\n= \\begin{pmatrix} (t-\\tau)\\exp(-(t-\\tau)) \\\\ \\exp(-(t-\\tau)) \\end{pmatrix} \\exp(-\\tau) = \\begin{pmatrix} (t-\\tau)\\exp(-t) \\\\ \\exp(-t) \\end{pmatrix}\n$$\nNow, we perform the integration to find the forced state response:\n$$\nx_f(t) = \\int_{0}^{t} \\begin{pmatrix} (t-\\tau)\\exp(-t) \\\\ \\exp(-t) \\end{pmatrix} \\,d\\tau = \\exp(-t) \\int_{0}^{t} \\begin{pmatrix} t-\\tau \\\\ 1 \\end{pmatrix} \\,d\\tau\n$$\n$$\nx_f(t) = \\exp(-t) \\begin{pmatrix} \\left[t\\tau - \\frac{\\tau^2}{2}\\right]_{0}^{t} \\\\ \\left[\\tau\\right]_{0}^{t} \\end{pmatrix} = \\exp(-t) \\begin{pmatrix} t^2 - \\frac{t^2}{2} \\\\ t \\end{pmatrix} = \\begin{pmatrix} \\frac{t^2}{2}\\exp(-t) \\\\ t\\exp(-t) \\end{pmatrix}\n$$\nThe forced output response is then:\n$$\ny_f(t) = C x_f(t) + D u(t) = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} \\frac{t^2}{2}\\exp(-t) \\\\ t\\exp(-t) \\end{pmatrix} + 2\\exp(-t)\n$$\n$$\ny_f(t) = \\left(\\frac{t^2}{2} + t\\right)\\exp(-t) + 2\\exp(-t) = \\left(\\frac{t^2}{2} + t + 2\\right)\\exp(-t)\n$$\n\nConceptually, this forced response describes how the CPS model reacts to the external command $u(t)$. It has two parts. The first part, $C x_f(t)$, represents the dynamic response, where the input excites the system's internal states which then evolve over time and contribute to the output. The second part, $D u(t)$, is the feedthrough term, representing an instantaneous, non-dynamic path from input to output. In the context of the actuator-sensor loop, this means the output is a combination of the system's dynamic reaction to the command signal and a direct, proportional feed-forward of the command signal itself ($2 u(t)$).\n\n3.  **Total Response ($y(t)$)**\n\nThe total output is the sum of the homogeneous and forced responses:\n$$\ny(t) = y_h(t) + y_f(t) = (t+1)\\exp(-t) + \\left(\\frac{t^2}{2} + t + 2\\right)\\exp(-t)\n$$\n$$\ny(t) = \\left(t + 1 + \\frac{t^2}{2} + t + 2\\right)\\exp(-t)\n$$\n$$\ny(t) = \\left(\\frac{t^2}{2} + 2t + 3\\right)\\exp(-t)\n$$\nThis final expression represents the complete behavior of the system's output for $t \\geq 0$, combining the effects of its initial state and the external input.",
            "answer": "$$\n\\boxed{\\left(\\frac{t^2}{2} + 2t + 3\\right)\\exp(-t)}\n$$"
        },
        {
            "introduction": "While the first exercise focused on a model's dynamic behavior, this practice examines the efficiency and validity of the model's structure itself. We will investigate the fundamental properties of controllability and observability for a given state-space realization . These concepts determine whether it is possible to steer the system to any desired state and to deduce the internal state from output measurements, respectively, allowing us to ascertain if the model is a minimal realization—a critical quality for building parsimonious and effective digital twins.",
            "id": "4229641",
            "problem": "A Digital Twin (DT) of a Cyber-Physical System (CPS) is used to model a three-state subsystem describing the linearized vertical channel of an aerial vehicle around a steady operating point. The subsystem is represented by a continuous-time Linear Time-Invariant (LTI) model with state vector $x \\in \\mathbb{R}^{3}$, input $u \\in \\mathbb{R}$, and output $y \\in \\mathbb{R}$, given by $\\dot{x} = A x + B u$ and $y = C x$. The matrices are\n$$\nA = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  1 \\\\\n-4  -5  -2\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n1\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1  0  2\n\\end{pmatrix}.\n$$\nUsing foundational definitions of reachability and output distinguishability for LTI systems, compute the controllability matrix $\\mathcal{C}$ and the observability matrix $\\mathcal{O}$, verify their ranks, and determine whether the given realization is minimal. Finally, report the McMillan degree $n_{\\min}$ of the minimal realization as a single integer. No rounding is required and no physical units are to be reported in the answer.",
            "solution": "The problem asks for an analysis of a continuous-time Linear Time-Invariant (LTI) system to determine if its given state-space realization is minimal, and to find its McMillan degree. The system is described by the state-space equations $\\dot{x} = A x + B u$ and $y = C x$, with state vector $x \\in \\mathbb{R}^{3}$, input $u \\in \\mathbb{R}$, and output $y \\in \\mathbb{R}$. The dimension of the state space is $n=3$.\n\nThe given matrices are:\n$$\nA = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  1 \\\\\n-4  -5  -2\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n1\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1  0  2\n\\end{pmatrix}.\n$$\n\nA state-space realization is considered minimal if it is both completely controllable and completely observable. The order of a minimal realization of a system is a unique number called the McMillan degree, denoted by $n_{\\min}$.\n\nFirst, we must verify the controllability of the system. A system is completely controllable if and only if its controllability matrix $\\mathcal{C}$ has full rank, i.e., $\\text{rank}(\\mathcal{C}) = n$. For a system of order $n=3$, the controllability matrix is given by:\n$$\n\\mathcal{C} = \\begin{pmatrix} B  AB  A^2B \\end{pmatrix}\n$$\nWe compute the necessary components:\nThe first column is the matrix $B$ itself:\n$$\nB = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\nThe second column is the product $AB$:\n$$\nAB = \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\\\ -4  -5  -2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\cdot 0 + 1 \\cdot 1 + 0 \\cdot 1 \\\\ 0 \\cdot 0 + 0 \\cdot 1 + 1 \\cdot 1 \\\\ -4 \\cdot 0 - 5 \\cdot 1 - 2 \\cdot 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ -7 \\end{pmatrix}\n$$\nThe third column is the product $A^2B = A(AB)$:\n$$\nA^2B = \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\\\ -4  -5  -2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ -7 \\end{pmatrix} = \\begin{pmatrix} 0 \\cdot 1 + 1 \\cdot 1 + 0 \\cdot (-7) \\\\ 0 \\cdot 1 + 0 \\cdot 1 + 1 \\cdot (-7) \\\\ -4 \\cdot 1 - 5 \\cdot 1 - 2 \\cdot (-7) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -7 \\\\ -4 - 5 + 14 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -7 \\\\ 5 \\end{pmatrix}\n$$\nNow, we assemble the controllability matrix $\\mathcal{C}$:\n$$\n\\mathcal{C} = \\begin{pmatrix} 0  1  1 \\\\ 1  1  -7 \\\\ 1  -7  5 \\end{pmatrix}\n$$\nTo determine the rank of $\\mathcal{C}$, we compute its determinant. A non-zero determinant for a square matrix implies that it is of full rank.\n$$\n\\det(\\mathcal{C}) = 0 \\cdot \\det\\begin{pmatrix} 1  -7 \\\\ -7  5 \\end{pmatrix} - 1 \\cdot \\det\\begin{pmatrix} 1  -7 \\\\ 1  5 \\end{pmatrix} + 1 \\cdot \\det\\begin{pmatrix} 1  1 \\\\ 1  -7 \\end{pmatrix}\n$$\n$$\n\\det(\\mathcal{C}) = 0 - 1 \\cdot (1 \\cdot 5 - (-7) \\cdot 1) + 1 \\cdot (1 \\cdot (-7) - 1 \\cdot 1)\n$$\n$$\n\\det(\\mathcal{C}) = -(5+7) + (-7-1) = -12 - 8 = -20\n$$\nSince $\\det(\\mathcal{C}) = -20 \\neq 0$, the matrix $\\mathcal{C}$ has full rank, which is $\\text{rank}(\\mathcal{C}) = 3$. As this equals the state dimension $n=3$, the system is completely controllable.\n\nNext, we verify the observability of the system. A system is completely observable if and only if its observability matrix $\\mathcal{O}$ has full rank, i.e., $\\text{rank}(\\mathcal{O}) = n$. For a system of order $n=3$, the observability matrix is given by:\n$$\n\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\\\ CA^2 \\end{pmatrix}\n$$\nWe compute the necessary components:\nThe first row is the matrix $C$ itself:\n$$\nC = \\begin{pmatrix} 1  0  2 \\end{pmatrix}\n$$\nThe second row is the product $CA$:\n$$\nCA = \\begin{pmatrix} 1  0  2 \\end{pmatrix} \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\\\ -4  -5  -2 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot 0 + 0 \\cdot 0 + 2 \\cdot (-4)  1 \\cdot 1 + 0 \\cdot 0 + 2 \\cdot (-5)  1 \\cdot 0 + 0 \\cdot 1 + 2 \\cdot (-2) \\end{pmatrix} = \\begin{pmatrix} -8  -9  -4 \\end{pmatrix}\n$$\nThe third row is the product $CA^2 = (CA)A$:\n$$\nCA^2 = \\begin{pmatrix} -8  -9  -4 \\end{pmatrix} \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\\\ -4  -5  -2 \\end{pmatrix} = \\begin{pmatrix} (-8) \\cdot 0 + (-9) \\cdot 0 + (-4) \\cdot (-4)  (-8) \\cdot 1 + (-9) \\cdot 0 + (-4) \\cdot (-5)  (-8) \\cdot 0 + (-9) \\cdot 1 + (-4) \\cdot (-2) \\end{pmatrix} = \\begin{pmatrix} 16  12  -1 \\end{pmatrix}\n$$\nNow, we assemble the observability matrix $\\mathcal{O}$:\n$$\n\\mathcal{O} = \\begin{pmatrix} 1  0  2 \\\\ -8  -9  -4 \\\\ 16  12  -1 \\end{pmatrix}\n$$\nTo determine the rank of $\\mathcal{O}$, we compute its determinant:\n$$\n\\det(\\mathcal{O}) = 1 \\cdot \\det\\begin{pmatrix} -9  -4 \\\\ 12  -1 \\end{pmatrix} - 0 \\cdot \\det\\begin{pmatrix} -8  -4 \\\\ 16  -1 \\end{pmatrix} + 2 \\cdot \\det\\begin{pmatrix} -8  -9 \\\\ 16  12 \\end{pmatrix}\n$$\n$$\n\\det(\\mathcal{O}) = 1 \\cdot ((-9)(-1) - (-4)(12)) + 2 \\cdot ((-8)(12) - (-9)(16))\n$$\n$$\n\\det(\\mathcal{O}) = (9 + 48) + 2(-96 + 144) = 57 + 2(48) = 57 + 96 = 153\n$$\nSince $\\det(\\mathcal{O}) = 153 \\neq 0$, the matrix $\\mathcal{O}$ has full rank, which is $\\text{rank}(\\mathcal{O}) = 3$. As this equals the state dimension $n=3$, the system is completely observable.\n\nSince the system is both completely controllable and completely observable, the given state-space realization $(A, B, C)$ is minimal.\nThe McMillan degree, $n_{\\min}$, is defined as the order of a minimal realization. Because the given realization is minimal, its order is the McMillan degree. The state vector is $x \\in \\mathbb{R}^3$, so the order of the system is $n=3$.\nTherefore, the McMillan degree is $n_{\\min} = 3$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "In practical applications, the complete state of a physical system is often not directly measurable. This final hands-on practice addresses this challenge by guiding you through the design and analysis of a state observer, a key algorithm in a digital twin's toolkit. By deriving the error dynamics and simulating a discrete-time observer , you will learn how to use a system model to estimate hidden states from available input-output data and evaluate the stability and performance of your estimation scheme.",
            "id": "4229638",
            "problem": "Consider a discrete-time, linear, time-invariant state-space model appropriate for cyber-physical systems and their digital twins, with state $x_k \\in \\mathbb{R}^n$, input $u_k \\in \\mathbb{R}^m$, and measured output $y_k \\in \\mathbb{R}^p$ defined by the laws $x_{k+1} = A x_k + B u_k$ and $y_k = C x_k$, where $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times m}$, and $C \\in \\mathbb{R}^{p \\times n}$ are constant matrices. An observer is used to produce state estimates $\\hat{x}_k \\in \\mathbb{R}^n$ driven by the same input and the measured output through the standard observer update law. From these, define the estimation error $e_k := x_k - \\hat{x}_k$. Using only the provided system and observer structures as the fundamental base, derive the linear estimation error dynamics, and determine the associated transition characteristics that govern the evolution of $e_k$.\n\nImplement a program that, for a fixed plant and measurement model, simulates both the true system and the observer over $K$ discrete time steps and computes:\n1. The spectral radius of the linear error-propagation operator derived from the system matrices and the observer gain (denote this as $\\rho$).\n2. The two-norm of the final estimation error $\\lVert e_K \\rVert_2$.\n3. The maximum two-norm residual of the one-step error recursion over the simulated horizon, defined as $\\max_{k \\in \\{1,\\dots,K\\}} \\lVert e_k - \\text{(predicted one-step error propagation from } e_{k-1}\\text{)} \\rVert_2$.\n\nAll quantities are dimensionless in this problem and therefore do not require physical units or angle units.\n\nUse the following fixed plant, measurement, and simulation parameters shared by all test cases:\n- State dimension $n = 2$, input dimension $m = 1$, and output dimension $p = 1$.\n- System matrices $A = \\begin{bmatrix} 0.8  0.1 \\\\ 0.0  0.9 \\end{bmatrix}$, $B = \\begin{bmatrix} 0.1 \\\\ 0.05 \\end{bmatrix}$, $C = \\begin{bmatrix} 1.0  0.0 \\end{bmatrix}$.\n- Simulation horizon $K = 20$.\n- Initial true state $x_0 = \\begin{bmatrix} 1.0 \\\\ -1.0 \\end{bmatrix}$ and initial observer state $\\hat{x}_0 = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$.\n- Deterministic input sequence $u_k = 0.1 k$ for $k \\in \\{0,1,2,\\dots,K-1\\}$.\n\nDefine a test suite of four observer gains to probe different regimes of the error dynamics:\n- Case $1$ (nominal stable): $L^{(1)} = \\begin{bmatrix} 0.3 \\\\ 0.2 \\end{bmatrix}$.\n- Case $2$ (marginal boundary): $L^{(2)} = \\begin{bmatrix} -0.2 \\\\ 0.0 \\end{bmatrix}$.\n- Case $3$ (unstable): $L^{(3)} = \\begin{bmatrix} -0.5 \\\\ 0.0 \\end{bmatrix}$.\n- Case $4$ (no correction): $L^{(4)} = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$.\n\nFor each case, run the plant-observer simulation over the shared horizon and compute the three quantities in the order described above. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list of three floats in the order $[\\rho,\\lVert e_K \\rVert_2,\\text{max residual}]$. For example, the output format must be $[[\\rho_1,\\lVert e_K \\rVert_{2,1},r^{\\max}_1],[\\rho_2,\\lVert e_K \\rVert_{2,2},r^{\\max}_2],[\\rho_3,\\lVert e_K \\rVert_{2,3},r^{\\max}_3],[\\rho_4,\\lVert e_K \\rVert_{2,4},r^{\\max}_4]]$. Express all floats rounded to six decimal places.",
            "solution": "The problem is well-posed, scientifically grounded, and contains all necessary information for a unique solution. It is therefore deemed valid. The solution proceeds by first deriving the theoretical error dynamics and then implementing a simulation to compute the required quantities.\n\nThe system is a discrete-time, linear, time-invariant (LTI) model given by:\nState evolution: $x_{k+1} = A x_k + B u_k$\nMeasurement: $y_k = C x_k$\n\nA standard Luenberger observer is employed to estimate the state $x_k$. The observer's state estimate, $\\hat{x}_k$, evolves according to:\nObserver evolution: $\\hat{x}_{k+1} = A \\hat{x}_k + B u_k + L(y_k - \\hat{y}_k)$\nwhere $L$ is the observer gain matrix, and $\\hat{y}_k$ is the estimated output, defined as:\nEstimated measurement: $\\hat{y}_k = C \\hat{x}_k$\n\nThe estimation error is defined as $e_k := x_k - \\hat{x}_k$.\n\n**1. Derivation of the Linear Estimation Error Dynamics**\n\nWe seek to find an expression for the evolution of the error, $e_{k+1}$, in terms of the previous error, $e_k$. We start from the definition of $e_{k+1}$:\n$$\ne_{k+1} = x_{k+1} - \\hat{x}_{k+1}\n$$\nSubstitute the equations for the state and observer evolution:\n$$\ne_{k+1} = (A x_k + B u_k) - (A \\hat{x}_k + B u_k + L(y_k - \\hat{y}_k))\n$$\nThe terms involving the input, $B u_k$, cancel out. This is a crucial feature of this observer design, making the error dynamics independent of the system's input $u_k$.\n$$\ne_{k+1} = A x_k - A \\hat{x}_k - L(y_k - \\hat{y}_k)\n$$\nFactor out the matrix $A$ from the first two terms:\n$$\ne_{k+1} = A(x_k - \\hat{x}_k) - L(y_k - \\hat{y}_k)\n$$\nSubstitute the definitions for the measurement $y_k$ and estimated measurement $\\hat{y}_k$:\n$$\ne_{k+1} = A(x_k - \\hat{x}_k) - L(C x_k - C \\hat{x}_k)\n$$\nFactor out the matrix $C$ inside the parenthesis:\n$$\ne_{k+1} = A(x_k - \\hat{x}_k) - L C (x_k - \\hat{x}_k)\n$$\nRecognize that the term $(x_k - \\hat{x}_k)$ is the definition of the error $e_k$:\n$$\ne_{k+1} = A e_k - L C e_k\n$$\nFinally, factor out the error vector $e_k$ to obtain the linear estimation error dynamics:\n$$\ne_{k+1} = (A - LC) e_k\n$$\nThis is a linear, homogeneous difference equation. The matrix $A_e := (A - LC)$ is the **linear error-propagation operator**. The evolution of the estimation error from any initial condition $e_0$ is given by $e_k = (A_e)^k e_0$.\n\nThe transition characteristics of the error are determined by the eigenvalues of the matrix $A_e$. The error $e_k$ will converge to zero as $k \\to \\infty$ if and only if all eigenvalues of $A_e$ have a magnitude less than $1$. This condition is equivalent to stating that the spectral radius of $A_e$, denoted $\\rho(A_e)$, must be less than $1$. The spectral radius is defined as $\\rho(A_e) = \\max_i |\\lambda_i|$, where $\\lambda_i$ are the eigenvalues of $A_e$.\n\n**2. Simulation and Computation Plan**\n\nThe program will implement the following logic for each of the four specified observer gains $L^{(j)}$:\n\n**Quantity 1: Spectral Radius $\\rho$**\nFor each gain $L$, form the error-propagation operator $A_e = A - LC$. Then, compute its eigenvalues $\\lambda_i$. The spectral radius is $\\rho = \\max_i |\\lambda_i|$. This value is computed once per case, before the simulation begins.\n\n**Quantity 2  3: Simulation for $\\lVert e_K \\rVert_2$ and Maximum Residual**\nA simulation is run for $K=20$ time steps.\n- **Initialization**: Set the initial true state $x_0 = \\begin{bmatrix} 1.0 \\\\ -1.0 \\end{bmatrix}$ and initial observer state $\\hat{x}_0 = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$. The initial error is $e_0 = x_0 - \\hat{x}_0 = \\begin{bmatrix} 1.0 \\\\ -1.0 \\end{bmatrix}$. A variable `max_residual_norm` is initialized to $0.0$.\n- **Iteration**: A loop runs for $k$ from $0$ to $K-1 = 19$. In each step:\n    a. The current error is $e_k = x_k - \\hat{x}_k$.\n    b. The next-step error is predicted using the derived dynamics: $e_{k+1}^{\\text{pred}} = A_e e_k$.\n    c. The system and observer are propagated one step forward using their respective update laws with input $u_k = 0.1k$:\n       $x_{k+1} = A x_k + B u_k$\n       $\\hat{x}_{k+1} = A \\hat{x}_k + B u_k + L(C x_k - C \\hat{x}_k)$\n    d. The actual next-step error is computed from the simulated states: $e_{k+1}^{\\text{sim}} = x_{k+1} - \\hat{x}_{k+1}$.\n    e. The one-step error recursion residual is the difference between the simulated error and the predicted error: $\\text{residual}_k = e_{k+1}^{\\text{sim}} - e_{k+1}^{\\text{pred}}$.\n    f. The two-norm of this residual, $\\lVert \\text{residual}_k \\rVert_2$, is computed and compared with `max_residual_norm`, which is updated if the new norm is larger.\n- **Finalization**: After the loop completes (at $k=19$), the final states are $x_{20}$ and $\\hat{x}_{20}$.\n    a. The final estimation error is $e_K = e_{20} = x_{20} - \\hat{x}_{20}$. Its two-norm, $\\lVert e_K \\rVert_2$, is computed.\n    b. The maximum residual norm recorded over the horizon, $\\max_{k \\in \\{1,\\dots,K\\}} \\lVert \\text{residual}_{k-1} \\rVert_2$, is the third required quantity. Based on the derivation, this value should be numerically zero, subject to floating-point precision limitations, verifying the correctness of the error dynamics $e_{k+1} = (A-LC)e_k$.\n\nThe three computed quantities—$\\rho$, $\\lVert e_K \\rVert_2$, and the maximum residual—are collected for each of the four test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the observer simulation problem for four different observer gains.\n    \"\"\"\n    # Fixed plant, measurement, and simulation parameters\n    n = 2  # state dimension\n    m = 1  # input dimension\n    p = 1  # output dimension\n    \n    A = np.array([[0.8, 0.1], [0.0, 0.9]])\n    B = np.array([[0.1], [0.05]])\n    C = np.array([[1.0, 0.0]])\n    \n    K = 20  # Simulation horizon\n    x0 = np.array([[1.0], [-1.0]])\n    x_hat0 = np.array([[0.0], [0.0]])\n\n    # Test suite of four observer gains\n    test_cases = [\n        # Case 1 (nominal stable)\n        np.array([[0.3], [0.2]]),\n        # Case 2 (marginal boundary)\n        np.array([[-0.2], [0.0]]),\n        # Case 3 (unstable)\n        np.array([[-0.5], [0.0]]),\n        # Case 4 (no correction)\n        np.array([[0.0], [0.0]]),\n    ]\n\n    all_results = []\n    \n    for L in test_cases:\n        # 1. Compute the spectral radius of the error-propagation operator\n        A_e = A - L @ C\n        eigenvalues = np.linalg.eigvals(A_e)\n        rho = np.max(np.abs(eigenvalues))\n        \n        # Initialize simulation variables\n        x_k = x0.copy()\n        x_hat_k = x_hat0.copy()\n        max_residual_norm = 0.0\n        \n        # 2.  3. Simulate system and observer and compute error metrics\n        for k in range(K):\n            # Current error (e_k)\n            e_k = x_k - x_hat_k\n            \n            # Predict next error using the derived dynamics\n            # e_{k+1}^{pred} = (A - LC) * e_k\n            e_k_plus_1_pred = A_e @ e_k\n            \n            # Define input for the current step\n            u_k = 0.1 * k\n            \n            # System and observer updates\n            y_k = C @ x_k\n            \n            x_k_plus_1 = A @ x_k + B * u_k\n            x_hat_k_plus_1 = A @ x_hat_k + B * u_k + L @ (y_k - C @ x_hat_k)\n            \n            # Compute the actual error at the next step from simulation\n            e_k_plus_1_sim = x_k_plus_1 - x_hat_k_plus_1\n            \n            # Compute the residual of the one-step error recursion\n            residual = e_k_plus_1_sim - e_k_plus_1_pred\n            residual_norm = np.linalg.norm(residual)\n            \n            if residual_norm > max_residual_norm:\n                max_residual_norm = residual_norm\n            \n            # Update states for the next iteration\n            x_k = x_k_plus_1\n            x_hat_k = x_hat_k_plus_1\n            \n        # After the loop, k = K-1, and states are x_K, x_hat_K\n        # Compute final estimation error norm\n        e_K = x_k - x_hat_k\n        norm_e_K = np.linalg.norm(e_K)\n        \n        # Store results for the current case\n        case_results = [rho, norm_e_K, max_residual_norm]\n        all_results.append(case_results)\n\n    # Format the final output string as specified\n    formatted_results = []\n    for res in all_results:\n        rho_str = f\"{res[0]:.6f}\"\n        norm_eK_str = f\"{res[1]:.6f}\"\n        max_res_str = f\"{res[2]:.6f}\"\n        formatted_results.append(f\"[{rho_str},{norm_eK_str},{max_res_str}]\")\n    \n    final_output_str = f\"[{','.join(formatted_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}