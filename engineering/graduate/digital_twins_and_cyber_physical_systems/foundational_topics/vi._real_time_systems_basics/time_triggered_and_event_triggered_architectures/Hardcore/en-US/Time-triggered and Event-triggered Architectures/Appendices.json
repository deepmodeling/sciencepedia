{
    "hands_on_practices": [
        {
            "introduction": "The core of time-triggered (TT) design is achieving absolute predictability through a pre-computed schedule. This exercise grounds the abstract concept of a TT schedule in a concrete construction task. By manually calculating the hyperperiod and allocating tasks to specific time slots, you will gain a fundamental understanding of how determinism is achieved in static, non-preemptive systems .",
            "id": "4251650",
            "problem": "A Cyber-Physical System (CPS) with an embedded Digital Twin (DT) executes a statically time-triggered schedule on a single-core processor. The time base is a synchronous global clock with tick $\\Delta t = 0.5\\,\\mathrm{ms}$, and all tasks are released synchronously at time $t=0$. The DT’s computational pipeline consists of three periodic tasks $\\tau_1$, $\\tau_2$, and $\\tau_3$ with harmonic periods. Each task $\\tau_k$ is characterized by period $T_k$, worst-case execution time $C_k$, release offset $O_k$, and implicit deadline $D_k = T_k$. The parameters are:\n- $\\tau_1$: $T_1 = 5\\,\\mathrm{ms}$, $C_1 = 1\\,\\mathrm{ms}$, $O_1 = 0\\,\\mathrm{ms}$.\n- $\\tau_2$: $T_2 = 10\\,\\mathrm{ms}$, $C_2 = 1.5\\,\\mathrm{ms}$, $O_2 = 0\\,\\mathrm{ms}$.\n- $\\tau_3$: $T_3 = 20\\,\\mathrm{ms}$, $C_3 = 2\\,\\mathrm{ms}$, $O_3 = 0\\,\\mathrm{ms}$.\n\nAssume non-preemptive execution, a single processor, and that every schedule slot start and end aligns to the clock tick $\\Delta t$. All jobs must start no earlier than their release time and complete no later than their implicit deadline. Over one hyperperiod, construct a deterministic time-triggered schedule table using the following policy: at each release time, schedule all newly released ready jobs in order of strictly decreasing period $T_k$ (with ties broken by increasing task index), assigning each job the earliest start time that does not overlap any already scheduled slots and respects non-preemption. Jobs cannot be moved earlier than their release time.\n\nStarting from first principles of periodic task systems and well-tested definitions of harmonicity and hyperperiod, determine:\n1. The hyperperiod $H$.\n2. The ordered slot allocation over $[0,H)$ as triplets $(i,s,e)$ where $i \\in \\{1,2,3\\}$ is the task index and $s$ and $e$ are the slot start and end times in $\\mathrm{ms}$.\n3. The total slack time $S$ within $[0,H)$.\n\nExpress all times in $\\mathrm{ms}$. Provide the final answer as a single row matrix containing, in order: $H$, then the sequence of all $(i,s,e)$ triplets sorted by increasing $s$, and finally $S$. No rounding is required. The matrix must contain numbers only; do not include units inside the matrix.",
            "solution": "The user-provided problem is a well-defined real-time scheduling problem. It is scientifically grounded in the principles of time-triggered systems, is self-contained with all necessary parameters, and is free of contradictions or ambiguities. The problem is therefore deemed valid and a solution can be constructed.\n\nThe solution is derived in three parts as requested: determining the hyperperiod, constructing the schedule, and calculating the total slack time.\n\n**Part 1: Hyperperiod $H$**\n\nThe hyperperiod $H$ of a set of periodic tasks is the least common multiple (LCM) of their periods. It represents the time interval after which the pattern of job releases repeats. The tasks are $\\tau_1$, $\\tau_2$, and $\\tau_3$ with periods $T_1 = 5\\,\\mathrm{ms}$, $T_2 = 10\\,\\mathrm{ms}$, and $T_3 = 20\\,\\mathrm{ms}$, respectively.\n\nThe problem states that the periods are harmonic. This means that for any two tasks $\\tau_i$ and $\\tau_j$, if $T_i < T_j$, then $T_j$ is an integer multiple of $T_i$. We can verify this: $T_2 = 2 \\times T_1$ and $T_3 = 2 \\times T_2$. For a harmonic set of periods, the LCM is simply the largest period.\n\nTherefore, the hyperperiod $H$ is:\n$$H = \\mathrm{lcm}(T_1, T_2, T_3) = \\mathrm{lcm}(5, 10, 20) = 20\\,\\mathrm{ms}$$\n\nThe schedule will be constructed over the time interval $[0, H)$, which is $[0, 20)$.\n\n**Part 2: Time-Triggered Schedule Construction**\n\nThe schedule is constructed by considering events at each distinct release time within the hyperperiod. All tasks have an offset $O_k=0$, so they are released synchronously. The release times for each task $\\tau_k$ are $n \\times T_k$ for non-negative integers $n$ such that $n \\times T_k < H$.\n- $\\tau_1$ ($T_1=5$): releases at $t=0, 5, 10, 15$.\n- $\\tau_2$ ($T_2=10$): releases at $t=0, 10$.\n- $\\tau_3$ ($T_3=20$): releases at $t=0$.\n\nThe distinct release times are $t=0, 5, 10, 15$. We build the schedule chronologically. Let the schedule be a set of occupied time intervals.\n\n**Time $t=0\\,\\mathrm{ms}$:**\nJobs from all three tasks ($\\tau_1, \\tau_2, \\tau_3$) are released. Let's denote the $j$-th job of task $\\tau_i$ as $\\tau_{i,j}$. The released jobs are $\\tau_{1,1}$, $\\tau_{2,1}$, and $\\tau_{3,1}$.\nThe scheduling policy requires ordering them by strictly decreasing period $T_k$.\nThe order is: $\\tau_{3,1}$ ($T_3=20$), then $\\tau_{2,1}$ ($T_2=10$), then $\\tau_{1,1}$ ($T_1=5$).\n\n1.  **Schedule $\\tau_{3,1}$ ($C_3 = 2\\,\\mathrm{ms}$):**\n    The earliest available start time $s \\ge 0$ is $s=0$. The slot is $[0, 2)$.\n    - Allocation: $(i=3, s=0, e=2)$.\n    - Deadline for $\\tau_{3,1}$ is $D_3=20$. Completion at $t=2 \\le 20$. Met.\n\n2.  **Schedule $\\tau_{2,1}$ ($C_2 = 1.5\\,\\mathrm{ms}$):**\n    The earliest available start time $s \\ge 0$ not overlapping with $[0, 2)$ is $s=2$. The slot is $[2, 3.5)$.\n    - Allocation: $(i=2, s=2, e=3.5)$.\n    - Deadline for $\\tau_{2,1}$ is $D_2=10$. Completion at $t=3.5 \\le 10$. Met.\n\n3.  **Schedule $\\tau_{1,1}$ ($C_1 = 1\\,\\mathrm{ms}$):**\n    The earliest available start time $s \\ge 0$ not overlapping with $[0, 2)$ or $[2, 3.5)$ is $s=3.5$. The slot is $[3.5, 4.5)$.\n    - Allocation: $(i=1, s=3.5, e=4.5)$.\n    - Deadline for $\\tau_{1,1}$ is $D_1=5$. Completion at $t=4.5 \\le 5$. Met.\n\n**Time $t=5\\,\\mathrm{ms}$:**\nA new job $\\tau_{1,2}$ is released. It is the only new job.\n1.  **Schedule $\\tau_{1,2}$ ($C_1 = 1\\,\\mathrm{ms}$):**\n    The earliest available start time $s \\ge 5$ not overlapping existing slots is $s=5$. The slot is $[5, 6)$.\n    - Allocation: $(i=1, s=5, e=6)$.\n    - Deadline for $\\tau_{1,2}$ is $5+D_1=10$. Completion at $t=6 \\le 10$. Met.\n\n**Time $t=10\\,\\mathrm{ms}$:**\nNew jobs $\\tau_{1,3}$ and $\\tau_{2,2}$ are released.\nThe scheduling order (decreasing period) is $\\tau_{2,2}$ ($T_2=10$), then $\\tau_{1,3}$ ($T_1=5$).\n\n1.  **Schedule $\\tau_{2,2}$ ($C_2 = 1.5\\,\\mathrm{ms}$):**\n    The earliest available start time $s \\ge 10$ is $s=10$. The slot is $[10, 11.5)$.\n    - Allocation: $(i=2, s=10, e=11.5)$.\n    - Deadline for $\\tau_{2,2}$ is $10+D_2=20$. Completion at $t=11.5 \\le 20$. Met.\n\n2.  **Schedule $\\tau_{1,3}$ ($C_1 = 1\\,\\mathrm{ms}$):**\n    The earliest available start time $s \\ge 10$ not overlapping $[10, 11.5)$ is $s=11.5$. The slot is $[11.5, 12.5)$.\n    - Allocation: $(i=1, s=11.5, e=12.5)$.\n    - Deadline for $\\tau_{1,3}$ is $10+D_1=15$. Completion at $t=12.5 \\le 15$. Met.\n\n**Time $t=15\\,\\mathrm{ms}$:**\nA new job $\\tau_{1,4}$ is released. It is the only new job.\n1.  **Schedule $\\tau_{1,4}$ ($C_1 = 1\\,\\mathrm{ms}$):**\n    The earliest available start time $s \\ge 15$ is $s=15$. The slot is $[15, 16)$.\n    - Allocation: $(i=1, s=15, e=16)$.\n    - Deadline for $\\tau_{1,4}$ is $15+D_1=20$. Completion at $t=16 \\le 20$. Met.\n\nThis completes the scheduling for the hyperperiod $[0, 20)$. All slot start ($s$) and end ($e$) times are multiples of the clock tick $\\Delta t = 0.5\\,\\mathrm{ms}$, as required.\n\nThe final ordered slot allocation, as a list of triplets $(i,s,e)$ sorted by increasing start time $s$, is:\n1.  $(3, 0, 2)$\n2.  $(2, 2, 3.5)$\n3.  $(1, 3.5, 4.5)$\n4.  $(1, 5, 6)$\n5.  $(2, 10, 11.5)$\n6.  $(1, 11.5, 12.5)$\n7.  $(1, 15, 16)$\n\n**Part 3: Total Slack Time $S$**\n\nThe total slack time $S$ is the total time the processor is idle within one hyperperiod. This can be calculated by subtracting the total execution time of all jobs in the hyperperiod from the hyperperiod duration $H$.\n\nFirst, we determine the number of jobs, $N_k$, for each task $\\tau_k$ within $[0, H)$:\n- $N_1 = H / T_1 = 20 / 5 = 4$\n- $N_2 = H / T_2 = 20 / 10 = 2$\n- $N_3 = H / T_3 = 20 / 20 = 1$\n\nThe total execution time, $C_{\\text{total}}$, is the sum of the execution times of all these jobs:\n$$C_{\\text{total}} = N_1 C_1 + N_2 C_2 + N_3 C_3$$\n$$C_{\\text{total}} = (4 \\times 1\\,\\mathrm{ms}) + (2 \\times 1.5\\,\\mathrm{ms}) + (1 \\times 2\\,\\mathrm{ms})$$\n$$C_{\\text{total}} = 4 + 3 + 2 = 9\\,\\mathrm{ms}$$\nThis is also equivalent to the total utilization $U$ multiplied by the hyperperiod $H$:\n$$U = \\sum_{k=1}^3 \\frac{C_k}{T_k} = \\frac{1}{5} + \\frac{1.5}{10} + \\frac{2}{20} = 0.2 + 0.15 + 0.1 = 0.45$$\n$$C_{\\text{total}} = U \\times H = 0.45 \\times 20 = 9\\,\\mathrm{ms}$$\n\nThe total slack time $S$ is:\n$$S = H - C_{\\text{total}} = 20\\,\\mathrm{ms} - 9\\,\\mathrm{ms} = 11\\,\\mathrm{ms}$$\n\nThe final answer combines $H$, the sequence of schedule triplets $(i,s,e)$, and $S$ into a single structure.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n20 & 3 & 0 & 2 & 2 & 2 & 3.5 & 1 & 3.5 & 4.5 & 1 & 5 & 6 & 2 & 10 & 11.5 & 1 & 11.5 & 12.5 & 1 & 15 & 16 & 11\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While event-triggered (ET) systems offer superior responsiveness, their dynamic, priority-driven nature can lead to subtle but critical failure modes. This practice explores priority inversion, a classic hazard where a high-priority task is unduly delayed by a lower-priority one, potentially causing deadline misses. Analyzing the provided scenario will help you diagnose the conditions that cause this dangerous phenomenon and understand the mechanism of standard solutions like priority inheritance protocols .",
            "id": "4251617",
            "problem": "An event-triggered (ET) controller in a cyber-physical system is implemented with fixed-priority preemptive scheduling and a shared mutex protecting resource $R$. There is no resource-access protocol in the kernel (no priority inheritance or ceiling). Three periodic tasks are deployed, and releases are driven by external events at the stated times. Task parameters are as follows (deadlines are relative to release times):\n- High-priority task $\\tau_H$: period $T_H = 10$ ms, deadline $D_H = 10$ ms, worst-case execution time $C_H = 2$ ms, with a critical section on resource $R$ of length $\\ell_H = 1$ ms inside its execution.\n- Medium-priority task $\\tau_M$: period $T_M = 15$ ms, deadline $D_M = 15$ ms, worst-case execution time $C_M = 6$ ms, no use of $R$.\n- Low-priority task $\\tau_L$: period $T_L = 50$ ms, deadline $D_L = 50$ ms, worst-case execution time $C_L = 8$ ms, with a critical section on $R$ of length $\\ell_L = 3$ ms that begins $1$ ms after $\\tau_L$ starts executing.\n\nAssume the first releases are at $t=0$ for $\\tau_L$, and at $t=2$ for both $\\tau_H$ and $\\tau_M$. The ET scheduler dispatches the ready task with the highest static priority, and tasks are preemptive except when a task holds a mutex (preemptions are still allowed in this kernel when holding the mutex, since no protocol is implemented).\n\nA model of this system in a timed-automata model checker encodes deadlines as clocks and verifies the safety property $A\\,\\Box(\\text{no\\_deadline\\_miss})$, meaning “on all paths, always no deadline is missed.”\n\nUsing only foundational definitions from fixed-priority schedulability theory and mutual exclusion in real-time systems, select the option that both:\n- gives a concrete counterexample execution trace in which $\\tau_H$ misses its deadline due to priority inversion, and\n- proposes a minimal fix, and justifies—by appeal to worst-case response-time reasoning and to a re-run of the same model checking—that the fix eliminates the violation under the same workload.\n\nOptions:\nA. Counterexample trace: At $t=2$, $\\tau_M$ preempts $\\tau_L$ and blocks $\\tau_H$ directly because of priority inversion on resource $R$, causing $\\tau_H$ to miss its deadline at $t=12$. Fix: switch to a non-preemptive kernel so lower-priority tasks run to completion, which removes all inversions; model checking then shows no deadline miss.\n\nB. Counterexample trace: $\\tau_L$ starts at $t=0$; it acquires $R$ at $t=1$ and would hold it for $\\ell_L = 3$ ms if uninterrupted. At $t=2$, both $\\tau_H$ and $\\tau_M$ are released. $\\tau_H$ attempts to lock $R$ and blocks behind $\\tau_L$. The kernel does not raise $\\tau_L$’s priority, so $\\tau_M$ preempts $\\tau_L$ from $t=2$ to $t=8$ for its $C_M = 6$ ms. $\\tau_L$ then resumes, completes its critical section at $t=11$, and releases $R$. $\\tau_H$ acquires $R$ and completes by $t=13$, missing its deadline at $t=12$. Fix: enable priority inheritance on $R$. Then the maximum blocking for $\\tau_H$ is $B_H = \\ell_L = 3$ ms, and since there are no higher-priority tasks than $\\tau_H$, its worst-case response time satisfies $R_H = C_H + B_H = 2 + 3 = 5 < D_H = 10$. Re-running the same model checking with priority inheritance yields $A\\,\\Box(\\text{no\\_deadline\\_miss})$ as true, with no counterexample.\n\nC. Counterexample trace: $\\tau_L$ never overlaps with $\\tau_H$’s use of $R$, yet $\\tau_H$ still misses its deadline because it busy-waits on $R$ from $t=2$ to $t=5$. Fix: adopt the priority ceiling protocol; the new worst-case response time is $R_H = C_H + \\ell_H = 2 + 1 = 3 < 10$, so deadlines hold, and model checking confirms the property.\n\nD. Counterexample trace: $\\tau_H$ can miss its deadline if it releases at $t=9$ while $\\tau_L$ is executing; the system is unstable because of jitter. Fix: convert the system to a time-triggered static table with slots of $2$ ms for $\\tau_H$, $6$ ms for $\\tau_M$, and $8$ ms for $\\tau_L$; the fixed table removes interference, so deadlines hold, and model checking remains unchanged.\n\nWhich option is correct?",
            "solution": "The user wants me to validate and solve a problem concerning real-time scheduling in a cyber-physical system.\n\n### Step 1: Extract Givens\n\n- **System:** Event-triggered (ET) controller with fixed-priority preemptive scheduling.\n- **Resource Management:** A shared mutex protects resource $R$. No resource-access protocol (e.g., priority inheritance, priority ceiling) is implemented in the kernel.\n- **Preemption Rule:** Preemption is allowed even when a task holds a mutex.\n- **Task Set:**\n    - **$\\tau_H$ (High Priority):** Period $T_H = 10$ ms, Deadline $D_H = 10$ ms, Worst-Case Execution Time (WCET) $C_H = 2$ ms. It has a critical section on $R$ of length $\\ell_H = 1$ ms.\n    - **$\\tau_M$ (Medium Priority):** Period $T_M = 15$ ms, Deadline $D_M = 15$ ms, WCET $C_M = 6$ ms. It does not use resource $R$.\n    - **$\\tau_L$ (Low Priority):** Period $T_L = 50$ ms, Deadline $D_L = 50$ ms, WCET $C_L = 8$ ms. It has a critical section on $R$ of length $\\ell_L = 3$ ms, which begins $1$ ms after $\\tau_L$ starts executing.\n- **Initial Release Times:**\n    - $\\tau_L$ is released at $t=0$ ms.\n    - $\\tau_H$ and $\\tau_M$ are released at $t=2$ ms.\n- **Verification Context:** A timed-automata model checker is used to verify the property $A\\,\\Box(\\text{no\\_deadline\\_miss})$, which asserts that no deadlines are ever missed on any execution path.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement is scientifically grounded in established real-time systems theory, covering concepts like fixed-priority preemptive scheduling, mutual exclusion, and priority inversion. The parameters are well-defined and numerically consistent. The scenario described—a high-priority task blocked by a low-priority task, which is then preempted by a medium-priority task—is the classic case used to illustrate unbounded priority inversion.\n\nThe problem asks for a counterexample trace where $\\tau_H$ misses its deadline. For this to be a well-posed question, such a miss must occur under the given conditions. Let us analyze the timeline. A deadline miss can be defined strictly (completion time $T_c \\geq T_{deadline}$) or non-strictly ($T_c > T_{deadline}$). We will assume the strict definition common in safety-critical systems, where completion at the deadline instant constitutes a miss. The absolute deadline for the first instance of $\\tau_H$ is $t = 2 \\text{ ms} + 10 \\text{ ms} = 12 \\text{ ms}$.\n\nAn analysis of the execution trace (derived in the next section) shows that $\\tau_H$ completes at $t=12$ ms. Under the strict deadline definition, this is a miss. Thus, the premise of the question—that a deadline miss occurs—is valid. The problem is therefore scientifically sound, objective, well-posed, and contains sufficient information for a rigorous analysis.\n\n**Verdict:** The problem is **valid**.\n\n### Step 3: Derivation of the Counterexample and Solution\n\nWe will construct an execution trace (Gantt chart) to demonstrate the deadline miss for $\\tau_H$. The priorities are $\\tau_H > \\tau_M > \\tau_L$.\n\n1.  **Interval $[0 \\text{ ms}, 1 \\text{ ms})$:** At $t=0$, $\\tau_L$ is released. As it is the only ready task, it begins execution. It runs for $1$ ms.\n2.  **At $t=1$ ms:** Having executed for $1$ ms, $\\tau_L$ enters its critical section and acquires the mutex for resource $R$.\n3.  **Interval $[1 \\text{ ms}, 2 \\text{ ms})$:** $\\tau_L$ continues executing, now inside its critical section. It runs for another $1$ ms. At $t=2$ ms, it has completed $1$ ms of its $3$ ms critical section.\n4.  **At $t=2$ ms:** Tasks $\\tau_H$ and $\\tau_M$ are released. The scheduler evaluates the ready tasks.\n    - $\\tau_H$ has the highest priority. We assume the worst case where it immediately requires resource $R$. Since $R$ is held by $\\tau_L$, $\\tau_H$ blocks.\n    - The scheduler then considers the next highest priority ready task, which is $\\tau_M$. Because the kernel has no resource-access protocol, $\\tau_L$'s priority is not elevated. Thus, $\\tau_M$ preempts $\\tau_L$.\n5.  **Interval $[2 \\text{ ms}, 8 \\text{ ms})$:** $\\tau_M$ executes for its full WCET of $C_M = 6$ ms. During this entire interval, $\\tau_H$ is blocked waiting for $\\tau_L$, and $\\tau_L$ is preempted by $\\tau_M$. This is the classic **priority inversion** scenario: a medium-priority task is delaying a high-priority task.\n6.  **At $t=8$ ms:** $\\tau_M$ completes. The scheduler finds that $\\tau_H$ is still blocked. The highest priority runnable task is now $\\tau_L$.\n7.  **Interval $[8 \\text{ ms}, 10 \\text{ ms})$:** $\\tau_L$ resumes execution. It needs to complete the remaining $\\ell_L - 1 \\text{ ms} = 3 - 1 = 2$ ms of its critical section. It runs for these $2$ ms.\n8.  **At $t=10$ ms:** $\\tau_L$ completes its critical section and releases the mutex for $R$. This action unblocks $\\tau_H$.\n9.  **At $t=10$ ms (scheduler action):** $\\tau_H$ becomes ready and, as the highest priority task, immediately preempts $\\tau_L$.\n10. **Interval $[10 \\text{ ms}, 12 \\text{ ms})$:** $\\tau_H$ executes for its WCET of $C_H = 2$ ms.\n11. **At $t=12$ ms:** $\\tau_H$ completes its execution.\n\n**Deadline Analysis for $\\tau_H$:**\n- Release time: $t_{release} = 2$ ms.\n- Relative deadline: $D_H = 10$ ms.\n- Absolute deadline: $t_{deadline} = 2 + 10 = 12$ ms.\n- Completion time: $t_{completion} = 12$ ms.\n\nSince the completion time is equal to the absolute deadline, under a strict deadline definition ($t_{completion} < t_{deadline}$ for success), the deadline is missed. Even under a non-strict definition ($t_{completion} \\le t_{deadline}$), this scenario represents a critical failure with zero slack time, directly caused by priority inversion. The duration of the priority inversion blocking suffered by $\\tau_H$ was the execution time of $\\tau_M$, totaling $6$ ms.\n\n### Evaluation of Options\n\nLet's evaluate each option based on this analysis.\n\n**A. Counterexample trace: At $t=2$, $\\tau_M$ preempts $\\tau_L$ and blocks $\\tau_H$ directly because of priority inversion on resource $R$, causing $\\tau_H$ to miss its deadline at $t=12$. Fix: switch to a non-preemptive kernel so lower-priority tasks run to completion, which removes all inversions; model checking then shows no deadline miss.**\n\n- **Counterexample Analysis:** The statement that \"$\\tau_M$... blocks $\\tau_H$ directly\" is imprecise. $\\tau_L$ directly blocks $\\tau_H$ by holding the mutex. $\\tau_M$ causes the inversion, prolonging the block.\n- **Fix Analysis:** Switching to a non-preemptive kernel is a drastic change, not a minimal fix. It replaces preemptive interference and priority inversion with potentially large non-preemptive blocking. While it might work for this specific scenario, the claim that it \"removes all inversions\" is false; it simply replaces one type of blocking with another. For example, $\\tau_H$ would be blocked for the entire remaining execution of $\\tau_L$ if it arrived just after $\\tau_L$ started.\n- **Verdict:** **Incorrect**. The reasoning is imprecise and the justification for the fix is flawed.\n\n**B. Counterexample trace: $\\tau_L$ starts at $t=0$; it acquires $R$ at $t=1$ and would hold it for $\\ell_L = 3$ ms if uninterrupted. At $t=2$, both $\\tau_H$ and $\\tau_M$ are released. $\\tau_H$ attempts to lock $R$ and blocks behind $\\tau_L$. The kernel does not raise $\\tau_L$’s priority, so $\\tau_M$ preempts $\\tau_L$ from $t=2$ to $t=8$ for its $C_M = 6$ ms. $\\tau_L$ then resumes, completes its critical section at $t=11$, and releases $R$. $\\tau_H$ acquires $R$ and completes by $t=13$, missing its deadline at $t=12$. Fix: enable priority inheritance on $R$. Then the maximum blocking for $\\tau_H$ is $B_H = \\ell_L = 3$ ms, and since there are no higher-priority tasks than $\\tau_H$, its worst-case response time satisfies $R_H = C_H + B_H = 2 + 3 = 5 < D_H = 10$. Re-running the same model checking with priority inheritance yields $A\\,\\Box(\\text{no\\_deadline\\_miss})$ as true, with no counterexample.**\n\n- **Counterexample Analysis:** The description of the events leading to the priority inversion is entirely correct. However, there is a minor numerical error in the trace: my analysis shows $\\tau_L$ resumes at $t=8$ and runs for its remaining $2$ ms of critical section, releasing the lock at $t=10$. This option states it releases the lock at $t=11$. Consequently, it claims $\\tau_H$ completes at $t=13$ instead of $t=12$. Despite this arithmetic slip, the core qualitative description of the priority inversion phenomenon and the conclusion that a deadline is missed are correct.\n- **Fix Analysis:** The proposed fix, Priority Inheritance (PI), is the standard minimal solution to this problem. When $\\tau_H$ blocks on $\\tau_L$, PI would elevate $\\tau_L$'s priority to that of $\\tau_H$, preventing $\\tau_M$ from preempting it. This would bound the blocking time.\n- **Justification Analysis:** The appeal to worst-case response-time analysis (RTA) is correct. For the highest priority task $\\tau_H$, its response time is $R_H = C_H + B_H$. With PI, the maximum blocking $B_H$ is bounded by the longest critical section of any lower-priority task, which is $\\ell_L = 3$ ms. Therefore, the worst-case response time becomes $R_H = 2 \\text{ ms} + 3 \\text{ ms} = 5 \\text{ ms}$. Since $5 \\text{ ms} < D_H = 10 \\text{ ms}$, the deadline is guaranteed to be met. The conclusion about the model checker result is also logical and correct.\n- **Verdict:** **Correct**. Despite a minor numerical error in the trace timeline, this option correctly identifies the phenomenon (priority inversion), proposes the standard minimal fix (priority inheritance), and provides a sound, theoretically correct justification using response-time analysis.\n\n**C. Counterexample trace: $\\tau_L$ never overlaps with $\\tau_H$’s use of $R$, yet $\\tau_H$ still misses its deadline because it busy-waits on $R$ from $t=2$ to $t=5$. Fix: adopt the priority ceiling protocol; the new worst-case response time is $R_H = C_H + \\ell_H = 2 + 1 = 3 < 10$, so deadlines hold, and model checking confirms the property.**\n\n- **Counterexample Analysis:** The premise \"$\\tau_L$ never overlaps with $\\tau_H$’s use of $R$\" is factually incorrect for the given scenario. At $t=2$, $\\tau_L$ holds the lock on $R$ when $\\tau_H$ is released.\n- **Fix Analysis:** The Priority Ceiling Protocol (PCP) is indeed a valid and often superior fix.\n- **Justification Analysis:** The response time calculation is wrong. Under PCP, the blocking term $B_H$ is the duration of the longest critical section of any lower-priority task using a resource with a ceiling relevant to $\\tau_H$. Here, that would be $\\ell_L = 3$ ms, not $\\ell_H = 1$ ms. The correct RTA would be $R_H = C_H + \\ell_L = 2 + 3 = 5$ ms.\n- **Verdict:** **Incorrect**. The counterexample is based on a false premise, and the justification contains an incorrect formula for response-time analysis.\n\n**D. Counterexample trace: $\\tau_H$ can miss its deadline if it releases at $t=9$ while $\\tau_L$ is executing; the system is unstable because of jitter. Fix: convert the system to a time-triggered static table with slots of $2$ ms for $\\tau_H$, $6$ ms for $\\tau_M$, and $8$ ms for $\\tau_L$; the fixed table removes interference, so deadlines hold, and model checking remains unchanged.**\n\n- **Counterexample Analysis:** This option ignores the specified release times ($t=0, t=2$) and invents a new scenario. The problem asks for an analysis of the given workload, not a hypothetical one. The term \"jitter\" is introduced without basis from the problem statement.\n- **Fix Analysis:** Converting to a time-triggered (TT) architecture is a fundamental system redesign, not a \"minimal fix.\" The description of the fix is incomplete as it only gives slot sizes, not the actual schedule.\n- **Justification Analysis:** The claim that \"model checking remains unchanged\" is false. A TT system has a completely different state-space model than an event-triggered, priority-preemptive system.\n- **Verdict:** **Incorrect**. It fails to analyze the given problem, proposes a non-minimal fix, and contains flawed justifications.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Modern cyber-physical systems often require a blend of TT predictability and ET responsiveness, leading to sophisticated hybrid architectures. This exercise delves into the trade-off between preserving the temporal determinism of TT tasks (by bounding their jitter) and minimizing the latency of ET tasks that run in the available slack time. By solving this optimization problem, you will learn how to quantitatively manage the allocation of system resources to balance competing performance goals—a key skill in advanced CPS design .",
            "id": "4251626",
            "problem": "A digital twin orchestrates a mixed-criticality cyber-physical controller that runs a cyclic time-triggered (TT) schedule of period $T = 100\\,\\mathrm{ms}$ and admits event-triggered (ET) jobs only inside explicitly allocated slack windows. There are two TT activities per cycle: activity $\\mathcal{A}$ with baseline start time $t_{\\mathcal{A}} = 20\\,\\mathrm{ms}$ and activity $\\mathcal{B}$ with baseline start time $t_{\\mathcal{B}} = 60\\,\\mathrm{ms}$. To avoid violating temporal determinism, TT activity start-time jitter is bounded: the slack window placed immediately before $\\mathcal{A}$ must have length $s_1$ satisfying $0 \\le s_1 \\le J_{\\mathcal{A}}$ with $J_{\\mathcal{A}} = 8\\,\\mathrm{ms}$, and the slack window placed immediately before $\\mathcal{B}$ must have length $s_2$ satisfying $0 \\le s_2 \\le J_{\\mathcal{B}}$ with $J_{\\mathcal{B}} = 12\\,\\mathrm{ms}$. The total slack budget per cycle is fixed and must be fully allocated, i.e., $s_1 + s_2 = S$ with $S = 15\\,\\mathrm{ms}$.\n\nAssume ET job arrivals are a homogeneous Poisson process with rate $\\lambda$ sufficiently small that, on average, queueing due to backlog within slack windows is negligible relative to the gating delay induced by TT-only intervals. Assume ET jobs can begin service only at the start of the next slack window following arrival and that entering during a slack window yields zero gating delay. Under these assumptions, model the average ET job latency as the expected forward time from a uniformly random arrival epoch within the cycle to the start of the next slack window. Using first principles (uniform sampling of arrival phase in a renewal cycle and the definition of jitter as slack-induced delay of TT starts), derive the analytic expression for this expected latency as a function of $s_1$ and $s_2$, then solve the constrained optimization problem to find the slack allocation $(s_1, s_2)$ that minimizes average ET job latency while preserving the TT jitter bounds.\n\nIn your derivation, start from fundamental definitions of uniform arrival phase in a periodic schedule and forward recurrence time in gaps between service windows. Demonstrate the trade-off quantitatively by showing how the optimal allocation relates to the jitter bounds and the geometry of the TT schedule.\n\nReport the optimal $(s_1, s_2)$ as a single row vector in milliseconds. No rounding is required; express exact values in $\\mathrm{ms}$.",
            "solution": "The problem is evaluated as valid. It is scientifically grounded in the principles of real-time scheduling for cyber-physical systems, well-posed as a constrained optimization problem, and objectively defined with no ambiguity.\n\nThe objective is to find the slack allocation $(s_1, s_2)$ that minimizes the average latency for event-triggered (ET) jobs, subject to several constraints. The system has a time-triggered (TT) schedule with a period of $T = 100\\,\\mathrm{ms}$.\n\nFirst, we define the structure of the schedule within one cycle, which spans the interval $[0, T)$. There are two TT activities, $\\mathcal{A}$ and $\\mathcal{B}$, with baseline start times $t_{\\mathcal{A}} = 20\\,\\mathrm{ms}$ and $t_{\\mathcal{B}} = 60\\,\\mathrm{ms}$. Two slack windows, of durations $s_1$ and $s_2$, are allocated for ET jobs immediately before these activities.\nThe first slack window, $I_1$, has duration $s_1$ and is located in the time interval $[t_{\\mathcal{A}} - s_1, t_{\\mathcal{A}}]$, which is $[20 - s_1, 20]$.\nThe second slack window, $I_2$, has duration $s_2$ and is located in the time interval $[t_{\\mathcal{B}} - s_2, t_{\\mathcal{B}}]$, which is $[60 - s_2, 60]$.\n\nET jobs are serviced at the beginning of these slack windows. An arrival during a slack window is assumed to have zero latency. An arrival during a TT-only interval must wait until the start of the next available slack window. The average latency is defined as the expected forward time from a uniformly random arrival epoch to the start of the next service opportunity.\n\nLet $\\tau$ be the arrival time of an ET job, which is assumed to be a random variable uniformly distributed over the interval $[0, T)$. The probability density function of $\\tau$ is $f(\\tau) = \\frac{1}{T}$. The latency for an arrival at time $\\tau$ is denoted by $W(\\tau)$. The average latency, $L$, is the expected value of $W(\\tau)$:\n$$L = E[W(\\tau)] = \\int_0^T W(\\tau) f(\\tau) d\\tau = \\frac{1}{T} \\int_0^T W(\\tau) d\\tau$$\n\nThe schedule consists of the two slack windows, $I_1$ and $I_2$, and the TT-only intervals (gaps) between them.\nThe interval between the end of $I_1$ and the start of $I_2$ is the first gap, $G_1 = [20, 60 - s_2]$. The length of this gap is $l_1 = (60 - s_2) - 20 = 40 - s_2$.\nThe interval between the end of $I_2$ and the start of the next cycle's $I_1$ is the second gap, $G_2$. This gap spans the cycle boundary, covering $[60, 100)$ and $[0, 20-s_1)$. Its total length is $l_2 = (100 - 60) + (20 - s_1) = 60 - s_1$.\n\nFor an arrival at time $\\tau$ within a gap of length $l$ that ends at time $t_{end}$, the waiting time is $W(\\tau) = t_{end} - \\tau$. The integral of the waiting time over this gap is a standard result for the mean forward recurrence time in a uniform process, given by $\\frac{l^2}{2}$.\nThus, the total integrated waiting time across all gaps is the sum of the contributions from each gap:\n$$\\int_0^T W(\\tau) d\\tau = \\int_{G_1} W(\\tau) d\\tau + \\int_{G_2} W(\\tau) d\\tau = \\frac{l_1^2}{2} + \\frac{l_2^2}{2}$$\nSubstituting the expressions for $l_1$ and $l_2$:\n$$\\int_0^T W(\\tau) d\\tau = \\frac{(40 - s_2)^2}{2} + \\frac{(60 - s_1)^2}{2}$$\nThe average latency $L$ is therefore:\n$$L(s_1, s_2) = \\frac{1}{T} \\left( \\frac{(40 - s_2)^2}{2} + \\frac{(60 - s_1)^2}{2} \\right) = \\frac{1}{200} \\left( (40 - s_2)^2 + (60 - s_1)^2 \\right)$$\n\nWe must minimize this function subject to the given constraints:\n1. Total slack budget: $s_1 + s_2 = S = 15$\n2. Jitter bounds: $0 \\le s_1 \\le J_{\\mathcal{A}} = 8$ and $0 \\le s_2 \\le J_{\\mathcal{B}} = 12$\n\nWe can reduce the problem to a single variable by substituting $s_2 = 15 - s_1$ into the objective function:\n$$L(s_1) = \\frac{1}{200} \\left( (40 - (15 - s_1))^2 + (60 - s_1)^2 \\right)$$\n$$L(s_1) = \\frac{1}{200} \\left( (25 + s_1)^2 + (60 - s_1)^2 \\right)$$\n\nNext, we define the feasible range for $s_1$. The explicit constraint is $0 \\le s_1 \\le 8$. The constraint on $s_2$ also implies a constraint on $s_1$:\n$$0 \\le s_2 \\le 12 \\implies 0 \\le 15 - s_1 \\le 12$$\nThe inequality $15 - s_1 \\ge 0$ implies $s_1 \\le 15$.\nThe inequality $15 - s_1 \\le 12$ implies $s_1 \\ge 3$.\nCombining all constraints on $s_1$, we have $s_1 \\in [0, 8]$ and $s_1 \\in [3, 15]$. The intersection gives the final feasible domain for $s_1$ as the closed interval $[3, 8]$.\n\nTo find the minimum of $L(s_1)$, we can analyze the quadratic function inside the parentheses, let's call it $f(s_1) = (25 + s_1)^2 + (60 - s_1)^2$. Minimizing $L(s_1)$ is equivalent to minimizing $f(s_1)$. We find the derivative with respect to $s_1$:\n$$f'(s_1) = \\frac{d}{ds_1} \\left( (25 + s_1)^2 + (60 - s_1)^2 \\right) = 2(25 + s_1) - 2(60 - s_1) = 50 + 2s_1 - 120 + 2s_1 = 4s_1 - 70$$\nSetting the derivative to zero to find the unconstrained minimum:\n$$4s_1 - 70 = 0 \\implies s_1 = \\frac{70}{4} = 17.5$$\nThe second derivative is $f''(s_1) = 4 > 0$, confirming that $f(s_1)$ is a convex parabola with a minimum at $s_1 = 17.5$.\n\nThis unconstrained minimum $s_1 = 17.5$ lies outside the feasible interval $[3, 8]$. Since the function is a parabola with its minimum at $s_1=17.5$, the function $f(s_1)$ is strictly decreasing for all $s_1 < 17.5$. Consequently, it is strictly decreasing over the entire feasible interval $[3, 8]$.\nTherefore, the minimum value of $f(s_1)$ on this interval must occur at the rightmost boundary point, which is $s_1 = 8$.\n\nThe optimal allocation for $s_1$ is $s_1^* = 8\\,\\mathrm{ms}$.\nThe corresponding optimal value for $s_2$ is found from the budget constraint:\n$$s_2^* = 15 - s_1^* = 15 - 8 = 7\\,\\mathrm{ms}$$\nThe optimal allocation is $(s_1^*, s_2^*) = (8, 7)$. This solution is valid as it satisfies all constraints: $s_1^* = 8 \\in [3, 8]$ and $s_2^* = 7$, which satisfies $0 \\le 7 \\le 12$.\n\nThe trade-off is evident here. The average latency is minimized when the sum of the squares of the gap lengths, $l_1^2 + l_2^2$, is minimal. For a fixed sum $l_1+l_2 = (40-s_2) + (60-s_1) = 100-S = 85$, the sum of squares is minimized when the lengths are equal: $l_1=l_2=42.5$. This would require $60-s_1=42.5 \\implies s_1=17.5$. However, the jitter bound for activity $\\mathcal{A}$ imposes the constraint $s_1 \\le 8$. Since the objective function decreases as $s_1$ approaches the unconstrained optimum of $17.5$, the constrained optimum is found by making $s_1$ as large as possible, which is $s_1 = 8$. The system's desire to balance the long TT-only intervals is limited by the temporal determinism requirement of TT task $\\mathcal{A}$.\nThe optimal solution fully utilizes the allowed jitter for the TT task $\\mathcal{A}$, allocating the maximum possible slack $s_1 = J_{\\mathcal{A}} = 8\\,\\mathrm{ms}$, with the remaining slack budget assigned to $s_2$.\nThe optimal slack allocation in milliseconds is $(s_1, s_2) = (8, 7)$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 8 & 7 \\end{pmatrix}}$$"
        }
    ]
}