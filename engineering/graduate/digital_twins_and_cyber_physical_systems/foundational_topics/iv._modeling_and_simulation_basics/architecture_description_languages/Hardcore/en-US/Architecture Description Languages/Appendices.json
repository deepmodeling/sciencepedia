{
    "hands_on_practices": [
        {
            "introduction": "The full power of an Architecture Description Language (ADL) lies in its ability to formally model not just components and connectors, but their dynamic interactions and resource sharing policies. In real-time cyber-physical systems, these interactions can lead to subtle but catastrophic failure modes, such as priority inversion, where a high-priority task is unexpectedly blocked by a low-priority one. This exercise  guides you through using an ADL model to reason about concurrency, identify the conditions for unbounded priority inversion, and evaluate architectural mitigations that ensure schedulability and correctness.",
            "id": "4205715",
            "problem": "An Architecture Description Language (ADL) model, expressed in Architecture Analysis and Design Language (AADL), specifies a cyber-physical system and its Digital Twin that share a single-core processor under a Real-Time Operating System (RTOS) using fixed-priority, fully preemptive scheduling. The ADL declares three threads bound to the same processor and a shared memory component DataBuffer with a mutual-exclusion lock. The ADL sets the lock policy to a first-in-first-out mutex with no priority inheritance by default. The three threads are declared with priorities and timing parameters as follows: ActuatorControl thread ($T_H$) with priority $p_H = 90$, period $T_H = 10$ ms, relative deadline $D_H = 10$ ms, and worst-case execution time $C_H = 2$ ms including a critical section on DataBuffer of duration $1$ ms; SensorFusion thread ($T_M$) with priority $p_M = 60$, period $T_M = 15$ ms, relative deadline $D_M = 15$ ms, and worst-case execution time $C_M = 9$ ms, which does not access DataBuffer; Logger thread ($T_L$) with priority $p_L = 10$, period $T_L = 50$ ms, relative deadline $D_L = 50$ ms, and worst-case execution time $C_L = 5$ ms including a critical section on DataBuffer of duration $3$ ms. The ADL deployment binds the shared DataBuffer and all three threads to the same processor and the same memory with the default mutex policy described above. Releases in the worst-case pattern occur with offsets: $O_L = 0$ ms, $O_H = 1$ ms, $O_M = 1.5$ ms. All execution-time and critical-section durations are feasible and consistent with the hardware.\n\nUsing only fundamental definitions of fixed-priority preemptive scheduling, mutual exclusion, and blocking (no specialized protocol formulas), reason about whether the declared configuration can produce priority inversion for $T_H$ and whether the inversion can cause a deadline miss for $T_H$. Then, consider architectural mitigations that the ADL could express (e.g., by property changes or component redesign) to eliminate unbounded inversion while preserving bounded latency. Select all options that correctly identify the condition under which priority inversion occurs in this deployment and propose an effective architectural mitigation that is expressible at the ADL level and correct under the given assumptions.\n\nA. Priority inversion occurs when $T_L$ holds the DataBuffer mutex, $T_H$ requests the same mutex and is blocked, and $T_M$ preempts $T_L$ before it can release the mutex; a mitigation is to enable priority inheritance on the DataBuffer mutex in the ADL so that when $T_H$ is blocked, $T_L$ temporarily executes at priority $p_H$, preventing preemption by $T_M$ and bounding $T_H$’s blocking by the longest lower-priority critical section using the resource.\n\nB. Priority inversion in this deployment can only occur if $T_M$ also uses DataBuffer; a mitigation is to replace the mutex with a read-write lock, designating $T_L$ as a writer and $T_H$ as a reader, which prevents blocking between them.\n\nC. Priority inversion necessarily occurs in any single-core fixed-priority system whenever any lower-priority thread accesses any shared resource; a mitigation is to make all mutexes non-preemptible at the kernel level, which eliminates priority inversion without impacting schedulability of higher-priority threads.\n\nD. Priority inversion occurs because the shared resource is bound via ADL to a non-deterministic bus with variable arbitration, and a mitigation is to migrate $T_H$ to a higher-priority core where bus access is prioritized, eliminating the blocking.\n\nE. Priority inversion occurs when $T_L$ holds the DataBuffer mutex, $T_H$ requests the mutex and is blocked, and $T_M$—despite not using DataBuffer—preempts $T_L$; a mitigation is to redesign DataBuffer as a lock-free Single-Producer Single-Consumer (SPSC) ring buffer with bounded atomic operations and appropriate memory fences, declared in the ADL as a lock-free synchronization kind, under the condition that $T_L$ is the unique producer and $T_H$ is the unique consumer and the buffer capacity $N$ is sized to avoid producer-induced blocking.",
            "solution": "The problem statement is a valid exercise in real-time systems analysis. It provides a complete and consistent set of parameters for three threads scheduled on a single-core processor under a fixed-priority preemptive policy, including their timing properties, priorities, and interaction via a shared resource protected by a standard mutex without priority inheritance. The scenario is scientifically grounded in established scheduling theory and is well-posed for analyzing the phenomena of priority inversion and its consequences on system schedulability.\n\nThe central task is to analyze the potential for priority inversion affecting the highest-priority thread, $T_H$, and to evaluate proposed architectural mitigations.\n\n**1. Analysis of Priority Inversion Condition**\n\nPriority inversion occurs when a high-priority thread is forced to wait for a lower-priority thread. The problem becomes severe, leading to \"unbounded\" priority inversion, when the duration of this waiting is not determined solely by the time the lower-priority thread spends in its critical section, but is prolonged by the execution of medium-priority threads.\n\nThe given system is a textbook case for this phenomenon:\n-   $T_H$ has the highest priority ($p_H=90$).\n-   $T_M$ has a medium priority ($p_M=60$).\n-   $T_L$ has the lowest priority ($p_L=10$).\n-   $T_H$ and $T_L$ share a resource, `DataBuffer`, protected by a mutex.\n-   $T_M$ does not use the resource but can preempt $T_L$.\n-   The mutex policy does not include priority inheritance.\n\nA worst-case scenario unfolds as follows:\n1.  The low-priority thread, $T_L$, starts execution and acquires the mutex for `DataBuffer`.\n2.  The high-priority thread, $T_H$, is released. It preempts $T_L$ and begins executing.\n3.  $T_H$ attempts to acquire the mutex for `DataBuffer`, finds it locked by $T_L$, and blocks (is moved from the \"Running\" state to the \"Blocked\" state).\n4.  The scheduler must now run the highest-priority ready thread. Since $T_H$ is blocked, the scheduler considers $T_M$ and $T_L$.\n5.  The medium-priority thread, $T_M$, which is ready to run, has a higher priority than $T_L$ ($p_M > p_L$). Therefore, $T_M$ preempts $T_L$.\n6.  $T_M$ runs. During this entire time, $T_H$ remains blocked, waiting for $T_L$ to release the mutex. However, $T_L$ cannot run to release the mutex because it is being preempted by $T_M$.\n\nThe duration of blocking experienced by $T_H$ is the sum of the remaining critical section time of $T_L$ and the entire execution time of $T_M$. This is the classic unbounded priority inversion problem.\n\n**2. Analysis of Deadline Miss for $T_H$**\n\nWe will construct a timeline based on the worst-case parameters to determine if $T_H$ can miss its deadline.\n-   Offsets: $O_L = 0$ ms, $O_H = 1$ ms, $O_M = 1.5$ ms.\n-   At time $t=0$ ms, $T_L$ is released. Let's assume it starts executing and immediately enters its critical section, which has a worst-case duration of $3$ ms.\n-   At time $t=1$ ms, $T_H$ is released. Since $p_H > p_L$, $T_H$ preempts $T_L$. $T_L$ has executed for $1$ ms inside its critical section.\n-   At time $t=1.5$ ms, $T_M$ is released. However, $T_H$ is still running ($p_H > p_M$), so $T_M$ is placed in the ready queue.\n-   The WCET of $T_H$ is $C_H = 2$ ms, which includes a $1$ ms critical section. Let's assume the worst case for blocking, where $T_H$ executes its non-critical part first. This takes $C_H - (\\text{CS duration}) = 2 - 1 = 1$ ms. So, $T_H$ runs from $t=1$ ms to $t=2$ ms.\n-   At time $t=2$ ms, $T_H$ attempts to lock the mutex. It finds the mutex held by $T_L$ and blocks.\n-   The scheduler now dispatches the highest-priority ready thread. This is $T_M$ (priority $60$), which was released at $t=1.5$ ms.\n-   $T_M$ begins execution at $t=2$ ms. It runs for its full WCET, $C_M=9$ ms.\n-   $T_M$ completes its execution at $t = 2 + 9 = 11$ ms.\n-   At time $t=11$ ms, the highest-priority ready thread is $T_L$ (priority $10$). $T_H$ is still blocked.\n-   $T_L$ resumes execution to complete its critical section. It had already run for $1$ ms, so it needs $3 - 1 = 2$ more ms. It runs from $t=11$ ms to $t=13$ ms.\n-   At time $t=13$ ms, $T_L$ releases the mutex.\n-   Immediately upon the mutex release, $T_H$ becomes unblocked and ready. As it has the highest priority, it preempts $T_L$ and begins executing its critical section.\n-   $T_H$ runs for its critical section duration of $1$ ms, from $t=13$ ms to $t=14$ ms.\n-   At time $t=14$ ms, the first job of $T_H$ completes.\n-   The deadline for this job of $T_H$ is its release time plus its relative deadline: $D_{H,abs} = O_H + D_H = 1 + 10 = 11$ ms.\n-   Since the job finishes at $14$ ms, which is later than its deadline of $11$ ms, the thread $T_H$ misses its deadline.\nThe analysis confirms that the specified configuration can produce priority inversion, and this inversion can directly cause a deadline miss for the high-priority thread.\n\n**3. Evaluation of Options**\n\n**Option A:** Priority inversion occurs when $T_L$ holds the DataBuffer mutex, $T_H$ requests the same mutex and is blocked, and $T_M$ preempts $T_L$ before it can release the mutex; a mitigation is to enable priority inheritance on the DataBuffer mutex in the ADL so that when $T_H$ is blocked, $T_L$ temporarily executes at priority $p_H$, preventing preemption by $T_M$ and bounding $T_H$’s blocking by the longest lower-priority critical section using the resource.\n-   **Analysis**: This option provides a perfectly accurate description of the unbounded priority inversion scenario identified in our analysis. The proposed mitigation, enabling priority inheritance, is the standard solution. When $T_L$ holds the lock and blocks $T_H$, $T_L$ would inherit the priority of $T_H$, becoming $p_L' = p_H = 90$. Consequently, $T_M$ (with $p_M=60$) would not be able to preempt $T_L$. $T_L$ would finish its critical section ($3$ ms max), release the lock, and then $T_H$ could proceed. This bounds the blocking time of $T_H$ to the duration of $T_L$'s critical section ($3$ ms), preventing the deadline miss (new response time would be at most $C_H + \\text{blocking} = 2+3=5$ ms, which is less than $D_H=10$ ms). Such a policy is a standard feature in RTOSes and is configurable in ADLs like AADL.\n-   **Verdict**: **Correct**.\n\n**Option B:** Priority inversion in this deployment can only occur if $T_M$ also uses DataBuffer; a mitigation is to replace the mutex with a read-write lock, designating $T_L$ as a writer and $T_H$ as a reader, which prevents blocking between them.\n-   **Analysis**: The premise is false. The severe priority inversion problem occurs precisely because $T_M$ *does not* use the mutex and is free to preempt $T_L$. The proposed mitigation is also flawed. A read-write lock does not allow a reader ($T_H$) to proceed if a writer ($T_L$) holds the lock. Exclusive access is required for writers. Thus, $T_H$ would still block on $T_L$, and the priority inversion scenario with preemption by $T_M$ would remain unchanged.\n-   **Verdict**: **Incorrect**.\n\n**Option C:** Priority inversion necessarily occurs in any single-core fixed-priority system whenever any lower-priority thread accesses any shared resource; a mitigation is to make all mutexes non-preemptible at the kernel level, which eliminates priority inversion without impacting schedulability of higher-priority threads.\n-   **Analysis**: The initial premise is an overgeneralization. While blocking of a high-priority thread by a low-priority thread is technically a priority inversion, it is not always \"unbounded\" or problematic. The severe case requires the specific three-priority-level interaction. The proposed mitigation, using non-preemptible critical sections, does prevent the inversion scenario. However, the claim that this is achieved \"without impacting schedulability of higher-priority threads\" is false. A non-preemptible section executed by a low-priority thread will block any higher-priority thread from running for its duration, even if the higher-priority thread does not use the shared resource. This introduces a separate form of blocking that can negatively impact schedulability.\n-   **Verdict**: **Incorrect**.\n\n**Option D:** Priority inversion occurs because the shared resource is bound via ADL to a non-deterministic bus with variable arbitration, and a mitigation is to migrate $T_H$ to a higher-priority core where bus access is prioritized, eliminating the blocking.\n-   **Analysis**: This option introduces facts not in evidence. The problem statement specifies a \"single-core processor\" and attributes the issue to scheduling and locking policies. There is no mention of a bus architecture. The proposed mitigation is impossible as the system only has a single core. The reasoning is entirely disconnected from the provided problem description.\n-   **Verdict**: **Incorrect**.\n\n**Option E:** Priority inversion occurs when $T_L$ holds the DataBuffer mutex, $T_H$ requests the mutex and is blocked, and $T_M$—despite not using DataBuffer—preempts $T_L$; a mitigation is to redesign DataBuffer as a lock-free Single-Producer Single-Consumer (SPSC) ring buffer with bounded atomic operations and appropriate memory fences, declared in the ADL as a lock-free synchronization kind, under the condition that $T_L$ is the unique producer and $T_H$ is the unique consumer and the buffer capacity $N$ is sized to avoid producer-induced blocking.\n-   **Analysis**: The description of the priority inversion condition is identical to Option A's and is correct. The proposed mitigation involves a fundamental architectural redesign of the shared component to use a lock-free algorithm. An SPSC queue is a classic example of a lock-free data structure that avoids mutexes entirely, thereby eliminating the possibility of blocking due to mutual exclusion and the associated priority inversion. This is a valid and effective advanced mitigation strategy. The option correctly notes the necessary preconditions (single producer/consumer roles) for this specific design pattern. Such an architectural pattern is expressible in an ADL, representing a change in the component's design and synchronization properties.\n-   **Verdict**: **Correct**.",
            "answer": "$$\\boxed{AE}$$"
        },
        {
            "introduction": "Once the logical correctness of task interactions is established, a critical step is to quantify the system's end-to-end performance against its requirements. This practice  focuses on the communication network, which is often a key performance bottleneck in distributed systems. By analyzing a network specified with a time-triggered protocol, you will learn to derive fundamental metrics such as bus utilization, worst-case latency, and jitter, which are crucial for the stability and performance of closed-loop control applications.",
            "id": "4205739",
            "problem": "A networked Cyber-Physical System (CPS) is specified using the Architecture Analysis and Design Language (AADL). The AADL model declares a single shared communication resource modeled as an AADL bus with the dispatch protocol set to time-triggered and a uniform Time Division Multiple Access (TDMA) major cycle of length $C$. The bus line rate is $B$ bits per second, and all messages use fixed-size frames with serialization delay equal to the frame size divided by the line rate. Assume negligible propagation, switching, and queuing delays except for waiting to the start of the assigned TDMA slot.\n\nThe AADL model includes three periodic flows mapped to this bus, each described by a frame size $S_i$ (in bits) and a period $T_i$ (in seconds):\n- Flow $1$: $S_1 = 800$ bits, $T_1 = 5 \\times 10^{-3}$ s.\n- Flow $2$: $S_2 = 1200$ bits, $T_2 = 1.0 \\times 10^{-2}$ s.\n- Flow $3$: $S_3 = 400$ bits, $T_3 = 2 \\times 10^{-3}$ s.\n\nThe bus has a line rate of $B = 1.0 \\times 10^{7}$ bits/s, and the TDMA major cycle is $C = 6.0 \\times 10^{-4}$ s. The control loop under consideration is the periodic flow $1$. The control loop’s end-to-end network latency requirement is $L_{\\mathrm{req}} = 1.0 \\times 10^{-3}$ s, and its network delay jitter requirement (defined as the maximum variation in network delay across successive releases) is $J_{\\mathrm{req}} = 7.0 \\times 10^{-4}$ s. The AADL schedule assigns a dedicated slot for flow $1$ every TDMA cycle, and flow $1$ is eligible for transmission only during its assigned slot. The release time of flow $1$ within a cycle is not phase-aligned to the slot boundary.\n\nUsing only first principles that relate throughput, utilization, and time-triggered scheduling semantics, do the following:\n1. Determine the bus utilization $U$ as a dimensionless fraction due to the three periodic flows.\n2. Determine whether the bus meets both the control loop’s latency and jitter requirements by computing the joint feasibility margin $m$ in milliseconds, defined as $m = \\min\\{L_{\\mathrm{req}} - L_{\\max},\\; J_{\\mathrm{req}} - J_{\\max}\\}$, where $L_{\\max}$ is the worst-case network latency of flow $1$ and $J_{\\max}$ is the worst-case network delay jitter of flow $1$ induced solely by the TDMA schedule.\n\nExpress $U$ as a dimensionless fraction and $m$ in milliseconds. Round both reported values to four significant figures. The final answer must be the ordered pair $\\left(U, m\\right)$.",
            "solution": "The problem requires the evaluation of a networked Cyber-Physical System's communication bus performance. The analysis is divided into two parts: first, the calculation of the bus utilization, and second, the schedulability analysis of a specific control loop (flow $1$) in terms of its latency and jitter requirements.\n\n**Part 1: Bus Utilization ($U$)**\n\nThe bus utilization, $U$, is a dimensionless quantity representing the fraction of the total bus capacity that is used by the data flows. It is calculated as the ratio of the total required data rate to the bus line rate (capacity).\n\nThe required data rate for each periodic flow $i$, denoted as $R_i$, is the frame size $S_i$ divided by the flow's period $T_i$.\n$$R_i = \\frac{S_i}{T_i}$$\n\nThe total required data rate, $R_{\\text{total}}$, is the sum of the individual data rates for all three flows:\n$$R_{\\text{total}} = R_1 + R_2 + R_3 = \\frac{S_1}{T_1} + \\frac{S_2}{T_2} + \\frac{S_3}{T_3}$$\n\nThe bus utilization $U$ is then given by:\n$$U = \\frac{R_{\\text{total}}}{B}$$\nwhere $B$ is the bus line rate.\n\nSubstituting the given values:\n- Flow $1$: $S_1 = 800$ bits, $T_1 = 5 \\times 10^{-3}$ s.\n- Flow $2$: $S_2 = 1200$ bits, $T_2 = 1.0 \\times 10^{-2}$ s.\n- Flow $3$: $S_3 = 400$ bits, $T_3 = 2 \\times 10^{-3}$ s.\n- Bus line rate: $B = 1.0 \\times 10^{7}$ bits/s.\n\nThe individual data rates are:\n$$R_1 = \\frac{800}{5 \\times 10^{-3}} = 160000 \\text{ bits/s} = 1.6 \\times 10^5 \\text{ bits/s}$$\n$$R_2 = \\frac{1200}{1.0 \\times 10^{-2}} = 120000 \\text{ bits/s} = 1.2 \\times 10^5 \\text{ bits/s}$$\n$$R_3 = \\frac{400}{2 \\times 10^{-3}} = 200000 \\text{ bits/s} = 2.0 \\times 10^5 \\text{ bits/s}$$\n\nThe total data rate is:\n$$R_{\\text{total}} = (1.6 + 1.2 + 2.0) \\times 10^5 = 4.8 \\times 10^5 \\text{ bits/s}$$\n\nThe bus utilization is:\n$$U = \\frac{4.8 \\times 10^5}{1.0 \\times 10^7} = 0.048$$\n\nRounding to four significant figures, the utilization is $0.04800$.\n\n**Part 2: Joint Feasibility Margin ($m$)**\n\nThe joint feasibility margin $m$ for flow $1$ is defined as $m = \\min\\{L_{\\mathrm{req}} - L_{\\max},\\; J_{\\mathrm{req}} - J_{\\max}\\}$. This requires calculating the worst-case network latency ($L_{\\max}$) and worst-case network delay jitter ($J_{\\max}$) for flow $1$.\n\nThe system uses a Time Division Multiple Access (TDMA) schedule with a major cycle of $C = 6.0 \\times 10^{-4}$ s. Flow $1$ is assigned a dedicated slot in every TDMA cycle. This means the transmission of flow $1$ is temporally isolated from flows $2$ and $3$. Therefore, the latency and jitter analysis for flow $1$ depends only on its own parameters and the TDMA cycle characteristics.\n\nThe network latency of a message is the total time from its release to the completion of its transmission. It is the sum of the waiting time for the assigned slot and the serialization (transmission) delay.\n\nThe serialization delay for flow $1$, $d_{\\text{ser},1}$, is:\n$$d_{\\text{ser},1} = \\frac{S_1}{B} = \\frac{800 \\text{ bits}}{1.0 \\times 10^7 \\text{ bits/s}} = 8.0 \\times 10^{-5} \\text{ s}$$\n\nThe problem states that the release of a flow $1$ message is not phase-aligned with the TDMA cycle. This means a message can be released at any time relative to its assigned slot.\n\nThe worst-case network latency, $L_{\\max}$, occurs when a message becomes ready for transmission just after its assigned slot has begun. In this scenario, the message must wait for the slot in the next TDMA cycle. The maximum waiting time is thus the duration of one full TDMA cycle, $C$.\nThe total worst-case latency is the sum of this maximum waiting time and the serialization delay:\n$$L_{\\max} = C + d_{\\text{ser},1}$$\n$$L_{\\max} = 6.0 \\times 10^{-4} \\text{ s} + 8.0 \\times 10^{-5} \\text{ s} = 6.0 \\times 10^{-4} \\text{ s} + 0.8 \\times 10^{-4} \\text{ s} = 6.8 \\times 10^{-4} \\text{ s}$$\n\nThe best-case network latency, $L_{\\min}$, occurs when a message is released just before its slot begins. The waiting time is effectively zero, and the latency is only the serialization delay.\n$$L_{\\min} = d_{\\text{ser},1} = 8.0 \\times 10^{-5} \\text{ s}$$\n\nThe network delay jitter, $J_{\\max}$, is defined as the maximum variation in network delay. This is the difference between the worst-case and best-case latencies.\n$$J_{\\max} = L_{\\max} - L_{\\min} = (C + d_{\\text{ser},1}) - d_{\\text{ser},1} = C$$\n$$J_{\\max} = 6.0 \\times 10^{-4} \\text{ s}$$\n\nNow, we can compute the feasibility margin using the given requirements for flow $1$:\n- Latency requirement: $L_{\\mathrm{req}} = 1.0 \\times 10^{-3}$ s.\n- Jitter requirement: $J_{\\mathrm{req}} = 7.0 \\times 10^{-4}$ s.\n\nThe latency margin is:\n$$L_{\\mathrm{req}} - L_{\\max} = 1.0 \\times 10^{-3} - 6.8 \\times 10^{-4} = 10.0 \\times 10^{-4} - 6.8 \\times 10^{-4} = 3.2 \\times 10^{-4} \\text{ s}$$\n\nThe jitter margin is:\n$$J_{\\mathrm{req}} - J_{\\max} = 7.0 \\times 10^{-4} - 6.0 \\times 10^{-4} = 1.0 \\times 10^{-4} \\text{ s}$$\n\nThe joint feasibility margin $m$ is the minimum of these two values:\n$$m = \\min\\{3.2 \\times 10^{-4} \\text{ s}, 1.0 \\times 10^{-4} \\text{ s}\\} = 1.0 \\times 10^{-4} \\text{ s}$$\n\nThe problem requires $m$ to be expressed in milliseconds.\n$$m = 1.0 \\times 10^{-4} \\text{ s} \\times \\frac{1000 \\text{ ms}}{1 \\text{ s}} = 0.1 \\text{ ms}$$\n\nRounding to four significant figures, the margin is $0.1000$ ms.\n\nIn summary, the calculated values are:\n- Bus utilization $U = 0.04800$.\n- Joint feasibility margin $m = 0.1000$ ms.\nThe final answer is the ordered pair $(U, m)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.04800  0.1000\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Beyond analyzing a single, fixed design, ADLs enable a paradigm shift towards automated Design Space Exploration (DSE), where a vast landscape of architectural possibilities can be systematically evaluated. This capstone exercise  frames system design as a constrained optimization problem: finding the optimal allocation of software components to hardware resources to minimize latency while respecting all resource constraints. This practice demonstrates how ADL models serve as the foundation for building analysis tools that can automatically discover high-performance and efficient system architectures.",
            "id": "4205704",
            "problem": "Consider an Architecture Description Language (ADL) model of a cyber-physical system consisting of processors, a shared bus, memories, and a linear pipeline of software components. The objective is to determine an allocation of each software component to a processor and to a memory that minimizes the end-to-end latency of one pipeline execution, subject to processor schedulability, memory capacity, and bus capacity constraints. The allocation must be derived from first principles of performance modeling and scheduling theory and implemented as a complete runnable program.\n\nDefinitions and fundamental base:\n- Architecture Description Language (ADL) provides a structural model of components and connectors. We consider sets of processors, a single shared bus, memories, and software components with fixed attributes.\n- Millions of Instructions Per Second (MIPS) is the processor speed metric. If a component requires $w_i$ million instructions and executes on a processor of speed $S_p$ MIPS, then its compute time is $C_{i,p} = \\frac{w_i}{S_p}$ seconds.\n- Megabytes per second (MB/s) is the capacity metric for bus bandwidth and memory throughput. If a component requires $d_i$ megabytes per period for memory access and executes with period $T_i$ seconds, then its memory data rate is $\\frac{d_i}{T_i}$ MB/s.\n- Schedulability under Earliest Deadline First (EDF): For a single processor, a sufficient and necessary schedulability condition is the utilization inequality $\\sum_{i \\in \\mathcal{A}(p)} \\frac{C_{i,p}}{T_i} \\leq 1$, where $\\mathcal{A}(p)$ is the set of components assigned to processor $p$, $C_{i,p}$ is the compute time on that processor, and $T_i$ is the component period.\n- Memory throughput capacity: For each memory $m$ with throughput capacity $W_m$ MB/s, the aggregate assigned data rates must satisfy $\\sum_{i \\in \\mathcal{A}(m)} \\frac{d_i}{T_i} \\leq W_m$.\n- Shared bus capacity: For a single shared bus of bandwidth $R_b$ MB/s and per-transfer arbitration overhead $\\tau_b$ seconds, the sum of rates of all bus-using flows must satisfy $\\sum_{\\text{flows}} \\text{rate} \\leq R_b$. The flows are: (a) remote memory accesses where a component’s assigned memory is not the processor’s local memory, with rate $\\frac{d_i}{T_i}$ for component $i$, and (b) inter-component message flows between adjacent components in the pipeline when they reside on different processors. For a message of size $s_j$ MB between components $j$ and $j+1$, the bus rate contribution is $\\frac{s_j}{\\max(T_j, T_{j+1})}$ MB/s.\n- End-to-end latency model: For a pipeline of $N$ components with assignments $p(i)$ to processors and $m(i)$ to memories, the end-to-end latency $L_{\\text{end}}$ of one execution equals the sum of compute times, memory access times, and inter-component communication latencies:\n  $$L_{\\text{end}} = \\sum_{i=1}^{N} \\left( \\frac{w_i}{S_{p(i)}} + \\left( \\frac{d_i}{W_{m(i)}} + \\lambda_{m(i)} \\right) + \\Delta^{\\text{mem}}_{i} \\right) + \\sum_{i=1}^{N-1} \\Delta^{\\text{msg}}_{i,i+1},$$\n  where $\\lambda_{m(i)}$ is the base memory latency of memory $m(i)$, and the additional bus terms are\n  $$\\Delta^{\\text{mem}}_{i} = \\begin{cases}\n  \\frac{d_i}{R_b} + \\tau_b  \\text{if } m(i) \\neq L_{p(i)},\\\\\n  0  \\text{otherwise,}\n  \\end{cases} \\quad\n  \\Delta^{\\text{msg}}_{i,i+1} = \\begin{cases}\n  \\frac{s_i}{R_b} + \\tau_b  \\text{if } p(i) \\neq p(i+1),\\\\\n  0  \\text{otherwise,}\n  \\end{cases}$$\n  with $L_{p(i)}$ denoting the local memory identifier of processor $p(i)$.\n\nAllocation decision variables:\n- For each component $i \\in \\{1,\\dots,N\\}$, choose a processor $p(i)$ from the processor set and a memory $m(i)$ from the memory set.\n\nConstraints:\n- Processor schedulability (EDF) for each processor $p$: $$\\sum_{i : p(i) = p} \\frac{\\frac{w_i}{S_p}}{T_i} \\leq 1.$$\n- Memory throughput for each memory $m$: $$\\sum_{i : m(i) = m} \\frac{d_i}{T_i} \\leq W_m.$$\n- Bus capacity: $$\\sum_{i : m(i) \\neq L_{p(i)}} \\frac{d_i}{T_i} + \\sum_{j=1}^{N-1 : p(j) \\neq p(j+1)} \\frac{s_j}{\\max(T_j, T_{j+1})} \\leq R_b.$$\n\nObjective:\n- Minimize $L_{\\text{end}}$ subject to the constraints.\n\nYour task:\n- Implement a complete program that enumerates all allocations and returns the minimal feasible end-to-end latency $L_{\\text{end}}$ for each provided test case. The answer must be expressed in seconds, rounded to $6$ decimal places.\n\nTest suite:\n- All test cases share a pipeline length $N = 3$ with adjacent message sizes $s_1$ and $s_2$ and component memory data per period $d_1$, $d_2$, $d_3$.\n- Test Case $1$ (general case):\n  - Processors: $p_1$ with speed $S_{p_1} = 100$ MIPS and local memory $L_{p_1} = m_1$; $p_2$ with speed $S_{p_2} = 50$ MIPS and local memory $L_{p_2} = m_2$.\n  - Bus: bandwidth $R_b = 100$ MB/s, arbitration overhead $\\tau_b = 0.0005$ s.\n  - Memories: $m_1$ with throughput $W_{m_1} = 60$ MB/s and base latency $\\lambda_{m_1} = 0.001$ s; $m_2$ with throughput $W_{m_2} = 40$ MB/s and base latency $\\lambda_{m_2} = 0.002$ s.\n  - Components: $(w_1,w_2,w_3) = (2, 1.5, 1)$ million instructions, $(T_1,T_2,T_3) = (0.05, 0.05, 0.05)$ s, $(d_1,d_2,d_3) = (1, 0.5, 0.2)$ MB, and adjacent message sizes $(s_1,s_2) = (2, 1)$ MB.\n- Test Case $2$ (bus-constrained boundary case):\n  - Processors: identical to Test Case $1$.\n  - Bus: bandwidth $R_b = 60$ MB/s, arbitration overhead $\\tau_b = 0.0005$ s.\n  - Memories: $m_1$ with throughput $W_{m_1} = 60$ MB/s and base latency $\\lambda_{m_1} = 0.001$ s; $m_2$ with throughput $W_{m_2} = 60$ MB/s and base latency $\\lambda_{m_2} = 0.0015$ s.\n  - Components: identical to Test Case $1$.\n- Test Case $3$ (memory-throughput edge case):\n  - Processors: $p_1$ with speed $S_{p_1} = 100$ MIPS and local memory $L_{p_1} = m_1$; $p_2$ with speed $S_{p_2} = 80$ MIPS and local memory $L_{p_2} = m_2$.\n  - Bus: bandwidth $R_b = 200$ MB/s, arbitration overhead $\\tau_b = 0.0005$ s.\n  - Memories: $m_1$ with throughput $W_{m_1} = 25$ MB/s and base latency $\\lambda_{m_1} = 0.001$ s; $m_2$ with throughput $W_{m_2} = 25$ MB/s and base latency $\\lambda_{m_2} = 0.001$ s.\n  - Components: $(w_1,w_2,w_3) = (2, 1.5, 1)$ million instructions, $(T_1,T_2,T_3) = (0.05, 0.05, 0.05)$ s, $(d_1,d_2,d_3) = (1, 0.5, 0.2)$ MB, and adjacent message sizes $(s_1,s_2) = (2, 1)$ MB.\n\nFinal output format:\n- Your program should produce a single line of output containing the minimal end-to-end latencies for the three test cases, as a comma-separated list enclosed in square brackets (e.g., \"[0.123456,0.234567,0.345678]\"), with each latency in seconds, rounded to $6$ decimal places.",
            "solution": "The problem presented is a constrained combinatorial optimization task. The objective is to find an allocation of software components to hardware resources (processors and memories) in a cyber-physical system, described by an Architecture Description Language (ADL) model, that minimizes the end-to-end latency of a software pipeline. This allocation must satisfy a set of performance and capacity constraints.\n\nThe problem is well-posed and all parameters, constraints, and the objective function are explicitly defined. The proposed solution methodology is based on an exhaustive search of all possible allocations, which is computationally feasible given the small dimensions of the problem instance ($N=3$ components, $2$ processors, $2$ memories).\n\nAn allocation is defined by a pair of assignment vectors, $(\\vec{p}, \\vec{m})$, where for each software component $i \\in \\{1, \\dots, N\\}$, $p(i)$ specifies its assigned processor and $m(i)$ specifies its assigned memory. With $|P|$ processors and $|M|$ memories, there are $(|P| \\cdot |M|)^N$ total possible allocations. For each test case, we have $N=3$, $|P|=2$, and $|M|=2$, resulting in $(2 \\cdot 2)^3 = 64$ unique allocations to evaluate.\n\nThe solution algorithm proceeds as follows:\n1.  Initialize a variable for the minimum latency, $L_{\\text{min}}$, to infinity.\n2.  Iterate through each of the $64$ possible allocations $(\\vec{p}, \\vec{m})$.\n3.  For each allocation, perform a feasibility check by verifying all system constraints. An allocation is deemed feasible only if it satisfies all three of the following conditions:\n\n    a.  **Processor Schedulability Constraint**: For each processor $p$ in the system, the total utilization must not exceed its capacity. The utilization for a set of components $\\mathcal{A}(p)$ assigned to processor $p$ is calculated based on the Earliest Deadline First (EDF) schedulability condition. With component $i$ having workload $w_i$ (million instructions), period $T_i$ (seconds), and processor $p$ having speed $S_p$ (MIPS), the compute time is $C_{i,p} = w_i/S_p$. The constraint is:\n    $$\\sum_{i : p(i)=p} \\frac{C_{i,p}}{T_i} = \\sum_{i : p(i)=p} \\frac{w_i}{S_p \\cdot T_i} \\leq 1$$\n\n    b.  **Memory Throughput Constraint**: For each memory $m$ with throughput capacity $W_m$ (MB/s), the sum of data rates from all components assigned to it must not exceed its capacity. A component $i$ requiring $d_i$ MB of data per period $T_i$ has a data rate of $d_i/T_i$. The constraint is:\n    $$\\sum_{i : m(i)=m} \\frac{d_i}{T_i} \\leq W_m$$\n\n    c.  **Bus Capacity Constraint**: The total bandwidth consumed on the single shared bus must not exceed its capacity $R_b$ (MB/s). Bus traffic originates from two sources: (i) remote memory accesses, when a component's assigned memory $m(i)$ is not the local memory $L_{p(i)}$ of its assigned processor $p(i)$, and (ii) inter-processor communication, when adjacent components in the pipeline are assigned to different processors. The constraint is:\n    $$\\sum_{i : m(i) \\neq L_{p(i)}} \\frac{d_i}{T_i} + \\sum_{j=1}^{N-1 : p(j) \\neq p(j+1)} \\frac{s_j}{\\max(T_j, T_{j+1})} \\leq R_b$$\n    where $s_j$ is the message size between components $j$ and $j+1$.\n\n4.  If an allocation is found to be feasible (i.e., it satisfies all three constraints), its end-to-end latency, $L_{\\text{end}}$, is calculated using the formula provided:\n    $$L_{\\text{end}} = \\sum_{i=1}^{N} \\left( \\frac{w_i}{S_{p(i)}} + \\frac{d_i}{W_{m(i)}} + \\lambda_{m(i)} + \\Delta^{\\text{mem}}_{i} \\right) + \\sum_{i=1}^{N-1} \\Delta^{\\text{msg}}_{i,i+1}$$\n    The terms $\\Delta^{\\text{mem}}_{i}$ and $\\Delta^{\\text{msg}}_{i,i+1}$ represent the additional latency due to bus usage for remote memory access and inter-processor communication, respectively. They are non-zero only if the bus is used:\n    $$\\Delta^{\\text{mem}}_{i} = \\begin{cases} \\frac{d_i}{R_b} + \\tau_b  \\text{if } m(i) \\neq L_{p(i)} \\\\ 0  \\text{otherwise} \\end{cases}$$\n    $$\\Delta^{\\text{msg}}_{i,i+1} = \\begin{cases} \\frac{s_i}{R_b} + \\tau_b  \\text{if } p(i) \\neq p(i+1) \\\\ 0  \\text{otherwise} \\end{cases}$$\n    where $R_b$ is the bus bandwidth and $\\tau_b$ is the bus arbitration overhead.\n\n5.  The calculated $L_{\\text{end}}$ is compared with the current minimum latency, $L_{\\text{min}}$, and $L_{\\text{min}}$ is updated if the new latency is lower: $L_{\\text{min}} = \\min(L_{\\text{min}}, L_{\\text{end}})$.\n\n6.  After evaluating all $64$ allocations, the final value of $L_{\\text{min}}$ represents the minimal feasible end-to-end latency. This entire procedure is applied to each of the three test cases provided. The final result for each case is rounded to $6$ decimal places as required.",
            "answer": "```python\nimport numpy as np\nimport itertools\n\ndef solve_case(procs, mems, bus, comps):\n    \"\"\"\n    Solves for the minimum end-to-end latency for a single test case.\n\n    This function enumerates all possible processor and memory allocations\n    for the software components. For each allocation, it checks feasibility\n    against processor, memory, and bus constraints. If feasible, it calculates\n    the end-to-end latency. The minimum latency across all feasible\n    allocations is returned.\n    \"\"\"\n    w, T, d, s = comps['w'], comps['T'], comps['d'], comps['s']\n    N = len(w)\n    num_procs = len(procs)\n    num_mems = len(mems)\n\n    p_indices = range(num_procs)\n    m_indices = range(num_mems)\n\n    # Generate all possible allocations using itertools.product\n    proc_allocations = list(itertools.product(p_indices, repeat=N))\n    mem_allocations = list(itertools.product(m_indices, repeat=N))\n\n    min_latency = float('inf')\n\n    for p_alloc in proc_allocations:\n        for m_alloc in mem_allocations:\n            # 1. Check processor schedulability (EDF utilization)\n            proc_util = [0.0] * num_procs\n            for i in range(N):\n                p_idx = p_alloc[i]\n                proc_util[p_idx] += (w[i] / procs[p_idx]['S']) / T[i]\n            \n            if any(u > 1.0 for u in proc_util):\n                continue\n\n            # 2. Check memory throughput capacity\n            mem_thru = [0.0] * num_mems\n            for i in range(N):\n                m_idx = m_alloc[i]\n                mem_thru[m_idx] += d[i] / T[i]\n\n            if any(mem_thru[j] > mems[j]['W'] for j in range(num_mems)):\n                continue\n\n            # 3. Check shared bus capacity\n            bus_rate = 0.0\n            # a) Remote memory access flows\n            for i in range(N):\n                p_idx = p_alloc[i]\n                m_idx = m_alloc[i]\n                if m_idx != procs[p_idx]['L_mem_idx']:\n                    bus_rate += d[i] / T[i]\n            \n            # b) Inter-component message flows\n            for i in range(N - 1):\n                if p_alloc[i] != p_alloc[i+1]:\n                    bus_rate += s[i] / max(T[i], T[i+1])\n\n            if bus_rate > bus['R_b']:\n                continue\n\n            # If all constraints are met, the allocation is feasible.\n            # Calculate its end-to-end latency.\n            current_latency = 0.0\n            \n            # Sum of component-level latencies\n            for i in range(N):\n                p_idx = p_alloc[i]\n                m_idx = m_alloc[i]\n                \n                # Compute time\n                current_latency += w[i] / procs[p_idx]['S']\n                \n                # Memory access time (base part)\n                current_latency += d[i] / mems[m_idx]['W'] + mems[m_idx]['lambda']\n                \n                # Additional bus latency for remote memory access\n                if m_idx != procs[p_idx]['L_mem_idx']:\n                    current_latency += d[i] / bus['R_b'] + bus['tau_b']\n\n            # Sum of inter-component communication latencies\n            for i in range(N - 1):\n                if p_alloc[i] != p_alloc[i+1]:\n                    current_latency += s[i] / bus['R_b'] + bus['tau_b']\n            \n            min_latency = min(min_latency, current_latency)\n\n    return min_latency\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and generate the final output.\n    \"\"\"\n    # Common component data for all test cases\n    components = {\n        'w': [2.0, 1.5, 1.0],      # million instructions\n        'T': [0.05, 0.05, 0.05],  # seconds\n        'd': [1.0, 0.5, 0.2],    # MB\n        's': [2.0, 1.0]          # MB\n    }\n\n    test_cases = [\n        # Test Case 1: General case\n        {\n            'procs': [{'S': 100.0, 'L_mem_idx': 0}, {'S': 50.0, 'L_mem_idx': 1}],\n            'bus': {'R_b': 100.0, 'tau_b': 0.0005},\n            'mems': [{'W': 60.0, 'lambda': 0.001}, {'W': 40.0, 'lambda': 0.002}]\n        },\n        # Test Case 2: Bus-constrained boundary case\n        {\n            'procs': [{'S': 100.0, 'L_mem_idx': 0}, {'S': 50.0, 'L_mem_idx': 1}],\n            'bus': {'R_b': 60.0, 'tau_b': 0.0005},\n            'mems': [{'W': 60.0, 'lambda': 0.001}, {'W': 60.0, 'lambda': 0.0015}]\n        },\n        # Test Case 3: Memory-throughput edge case\n        {\n            'procs': [{'S': 100.0, 'L_mem_idx': 0}, {'S': 80.0, 'L_mem_idx': 1}],\n            'bus': {'R_b': 200.0, 'tau_b': 0.0005},\n            'mems': [{'W': 25.0, 'lambda': 0.001}, {'W': 25.0, 'lambda': 0.001}]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(case['procs'], case['mems'], case['bus'], components)\n        results.append(result)\n\n    # Format the output as specified: list of latencies, 6 decimal places.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}