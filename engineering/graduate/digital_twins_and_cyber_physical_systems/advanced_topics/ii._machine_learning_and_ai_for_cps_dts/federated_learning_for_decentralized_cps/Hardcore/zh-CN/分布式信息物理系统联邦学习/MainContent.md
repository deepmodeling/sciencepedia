## 引言
在日益互联的世界中，信息物理系统（CPS）正将计算智能深度嵌入到我们的物理环境中，从[智能制造](@entry_id:1131785)到[自动驾驶](@entry_id:270800)，再到智慧城市。这些系统由大量分布式设备组成，它们持续不断地生成海量数据。传统上，利用这些数据训练强大的机器学习模型需要将它们全部汇集到一个中央服务器。然而，在CPS的现实场景中，由于严格的[数据隐私](@entry_id:263533)法规、有限的通信带宽以及[数据主权](@entry_id:902387)问题，这种中心化的方法往往是不可行或不被允许的。这就造成了一个关键的知识鸿沟：我们如何能够在不直接访问分布式原始数据的情况下，协同利用集体数据来构建一个共享的全局智能？

[联邦学习](@entry_id:637118)（Federated Learning, FL）正是为应对这一挑战而生的一种革命性[机器学习范式](@entry_id:637731)。它主张“数据不动，模型动”，允许部署在各处的设备（客户端）在本地利用其私有数据进行模型训练，然后仅将非敏感的模型更新发送至一个中央协调器进行聚合，从而共同训练出一个更强大、更具泛化能力的全局模型。通过这种方式，联邦学习在保护[数据隐私](@entry_id:263533)和安全的前提下，实现了知识的共享与协作。

本文将系统性地引导您深入了解面向去中心化信息物理系统的联邦学习。在“原理与机制”一章中，我们将剖析联邦学习与其他分布式学习范式的区别，阐明其核心算法（如[联邦平均](@entry_id:1124886)）的工作原理，并分析在CPS中部署时所面临的统计异构性、系统异构性、通信、安全与隐私等关键挑战。接着，在“应用与跨学科连接”一章中，我们将跳出理论框架，通过[数字孪生](@entry_id:171650)、状态估计、自主控制以及医疗健康等具体应用场景，展示[联邦学习](@entry_id:637118)如何作为一项使能技术，解决现实世界中的复杂问题。最后，“动手实践”部分将提供一系列计算练习，让您能够将所学理论付诸实践。让我们首先从理解联邦学习的基础原理开始。

## 原理与机制

本章旨在深入探讨在去中心化信息物理系统（CPS）中应用联邦学习（FL）的核心原理和基础机制。我们将从多种分布式学习范式的基本区别入手，详细阐述联邦学习的具体工作流程，并分析在真实CPS环境中部署时所面临的关键挑战，包括统计异构性、系统异构性、通信瓶颈、隐私泄露和恶意攻击等。最后，我们将介绍为应对这些挑战而设计的先进机制与架构。

### 分布式系统中的基本学习范式

在深入[联邦学习](@entry_id:637118)之前，有必要将其置于更广泛的分布式机器学习范畴内进行理解和定位。根据[数据局部性](@entry_id:638066)、通信拓扑和协调原语的不同，我们可以区分三种主要的学习范式。

**中心化学习（Centralized Learning）** 是最传统的方法。其核心假设是所有数据都可以被汇集到一个中央数据中心。在这种模式下，来自各个子系统 $k$ 的本地数据集 $\mathcal{D}_k$ 被传输并合并成一个单一的、巨大的联合数据集 $\mathcal{D} = \bigcup_k \mathcal{D}_k$。随后，一个标准的优化算法（如[随机梯度下降](@entry_id:139134)）在这个聚合数据集上运行，以训练一个全局模型。边缘子系统在此过程中仅作为被动的数据源，不参与训练计算。这种方法虽然能够利用所有数据，但在CPS应用中通常是不可行的，因为它违反了[数据隐私](@entry_id:263533)、主权和带宽限制等核心约束 。

**联邦学习（Federated Learning, FL）** 专为解决[数据局部性](@entry_id:638066)问题而设计。其决定性原则是：**原始数据永不离开本地设备**。在典型的[联邦学习](@entry_id:637118)设置中，例如[联邦平均](@entry_id:1124886)（Federated Averaging, [FedAvg](@entry_id:634153)），系统采用星型拓扑结构，包含一个中央协调器（或称参数服务器）和大量的客户端（如CPS设备或其[数字孪生](@entry_id:171650)）。训练过程以迭代轮次的方式进行：
1.  **广播**：协调器将当前的全局模型参数 $w$ 广播给一部分被选中的客户端。
2.  **本地计算**：每个被选中的客户端使用其本地数据 $\mathcal{D}_k$ 对接收到的模型进行多步本地更新（例如，执行若干轮次的SGD），从而得到一个本地更新后的模型 $w_k$。
3.  **上传**：客户端将更新信息（如更新后的模型参数 $w_k$ 或模型参数的变化量 $\Delta_k = w_k - w$）发送回协调器。关键在于，传输的是模型层面的信息，而非原始数据。
4.  **聚合**：协调器收集来自客户端的更新，并通过某种聚合规则（如加权平均）来计算新的全局模型，然后开始下一轮迭代。

这种模式天然地支持数据非[独立同分布](@entry_id:169067)（non-IID）、数据量不均衡以及部分客户端参与等真实场景，并通过本地计算减少了通信频率 。

**完全[去中心化学习](@entry_id:1123450)（Fully Decentralized Learning）**，或称**共识学习（Consensus-based Learning）**，则更进一步，完全摒弃了中央协调器。在这种范式下，数据同样保留在本地。各个节点（子系统）通过一个点对点（peer-to-peer）的通信网络（可用图 $G=(V,E)$ 表示）连接。每个节点 $k$ 维护其自身的模型副本 $w_k$，并仅与图 $G$ 中的邻居节点交换信息。优化的目标通常被构建为一个[共识问题](@entry_id:637652)：通过迭代式的本地计算和邻居间的信息融合（或称“混合”），所有节点协同工作，在最小化全局[目标函数](@entry_id:267263)的同时，确保它们的本地模型最终收敛到一个共同的值，即 $w_k \to w^*$ 对所有 $k$ 成立。这种架构消除了中央服务器带来的[单点故障](@entry_id:267509)风险和通信瓶颈，使其在鲁棒性方面具有显著优势 。

### [联邦平均](@entry_id:1124886)（[FedAvg](@entry_id:634153)）机制

[联邦平均](@entry_id:1124886)（[FedAvg](@entry_id:634153)）是联邦学习中最具代表性的算法。其核心思想是通过在客户端进行多步本地更新来减少与服务器的通信次数。让我们从第一性原理出发，构建其数学形式。

假设我们有 $m$ 个客户端，每个客户端 $i$ 拥有一个本地数据集 $\mathcal{D}_i$，其样本数量为 $n_i$。所有客户端的总样本数为 $n = \sum_{i=1}^{m} n_i$。全局[经验风险](@entry_id:633993) $F(w)$ 定义为所有设备上所有样本损失的平均值：
$$
F(w) = \frac{1}{n} \sum_{i=1}^{m} \sum_{j=1}^{n_i} \ell(w; x_{ij}, y_{ij})
$$
其中 $w \in \mathbb{R}^{d}$ 是共享的模型参数，$\ell$ 是单个样本的[损失函数](@entry_id:634569)。

自然地，我们可以为每个客户端 $i$ 定义一个**本地目标函数** $F_i(w)$，即其本地数据的平均损失：
$$
F_i(w) = \frac{1}{n_i} \sum_{j=1}^{n_i} \ell(w; x_{ij}, y_{ij})
$$
通过这个定义，全局目标函数可以被重写为所有本地[目标函数](@entry_id:267263)的加权平均：
$$
F(w) = \sum_{i=1}^{m} \frac{n_i}{n} F_i(w)
$$
这个表达式是[FedAvg](@entry_id:634153)聚合规则的理论基础。权重 $\frac{n_i}{n}$ 反映了每个客户端数据量在总数据量中的占比，确保聚合过程与最小化全局[经验风险](@entry_id:633993)的目标保持一致 。

在第 $t$ 个通信轮次，[FedAvg](@entry_id:634153)的流程如下：
1.  服务器将当前全局模型 $w^t$ 分发给所有参与的客户端。
2.  每个客户端 $i$ 将其本地模型初始化为 $w_i^{t,0} = w^t$。
3.  客户端 $i$ 在其本地数据上执行 $\tau$ 步[随机梯度下降](@entry_id:139134)（SGD），其迭代过程为：
    $$
    w_{i}^{t,s+1} = w_{i}^{t,s} - \eta_s g_i(w_{i}^{t,s}; \xi_{i}^{t,s}), \quad s \in \{0,\dots,\tau-1\}
    $$
    其中 $\eta_s$ 是本地学习率，$g_i$ 是从本地数据集 $\mathcal{D}_i$ 中采样的小批量数据 $\xi_{i}^{t,s}$ 计算出的随机梯度，它是 $\nabla F_i$ 的一个无偏估计。
4.  $\tau$ 步本地更新后，客户端 $i$ 得到本地模型 $w_{i}^{t,\tau}$，并将其发送给服务器。
5.  服务器通过对接收到的本地模型进行加权平均来更新全局模型：
    $$
    w^{t+1} = \sum_{i=1}^{m} \frac{n_i}{n} w_{i}^{t,\tau}
    $$
我们可以将这个聚合规则表示得更明确。将本地SGD的迭代过程展开，客户端 $i$ 在本地更新结束后的模型为：
$$
w_{i}^{t,\tau} = w_i^{t,0} - \sum_{s=0}^{\tau-1} \eta_s g_i(w_{i}^{t,s}; \xi_{i}^{t,s}) = w^{t} - \sum_{s=0}^{\tau-1} \eta_s g_i(w_{i}^{t,s}; \xi_{i}^{t,s})
$$
代入全局聚合公式，我们得到：
$$
w^{t+1} = \sum_{i=1}^{m} \frac{n_i}{n} \left( w^{t} - \sum_{s=0}^{\tau-1} \eta_s g_i(w_{i}^{t,s}; \xi_{i}^{t,s}) \right) = w^{t} - \sum_{i=1}^{m} \frac{n_i}{n} \sum_{s=0}^{\tau-1} \eta_s g_i(w_{i}^{t,s}; \xi_{i}^{t,s})
$$
这个表达式清晰地表明，新的全局模型是通过从当前模型中减去所有客户端累积本地更新的[加权平均值](@entry_id:894528)而得到的。这可以被看作是对一个虚拟的、聚合后的全局梯度方向的一次移动 。

### 联邦学习在CPS中的关键挑战

将联邦学习应用于信息物理系统（CPS）时，理论上的理想模型会遇到源于数据和物理系统本身的严峻挑战。

#### 统计异构性：[客户端漂移](@entry_id:634167)问题

[联邦学习](@entry_id:637118)的一个核心挑战是客户端之间的数据分布通常是**非[独立同分布](@entry_id:169067)（non-IID）**的。在CPS中，这意味着每个设备（例如，部署在不同地理位置的传感器）由于其独特的运行环境和经历，其本地数据分布 $P_k$ 会与全局数据分布 $P = \sum_k p_k P_k$ 以及其他设备的分布显著不同。

这种数据异构性会导致一个被称为**[客户端漂移](@entry_id:634167)（Client Drift）** 的现象。其根本原因在于，每个客户端的本地梯度 $\nabla F_k(\theta)$ 是其本地目标 $F_k$ 的无偏估计，但却是全局目标 $F$ 的**有偏估计**。也就是说，$\mathbb{E}_{x \sim P_k}[\nabla \ell(\theta; x)] = \nabla F_k(\theta) \neq \nabla F(\theta)$。

当一个客户端执行单步本地更新时，它会朝着其本地最优解的方向移动，这个方向与[全局最优解](@entry_id:175747)的方向存在偏差。如果进行多步（$E > 1$）本地更新，这种偏差会累积。本地模型会沿着其自身的优化路径向其本地最优解 $\theta_k^* = \arg\min F_k(\theta)$ “漂移”，从而可能远离[全局最优解](@entry_id:175747) $\theta^* = \arg\min F(\theta)$。当服务器聚合这些已经“漂移”的本地模型时，可能会减慢[收敛速度](@entry_id:636873)，甚至导致模型发散。这种由数据异构性和多步本地更新共同引起的本地模型轨迹与全局优化轨迹的偏离，正是[客户端漂移](@entry_id:634167)的本质 。

#### 系统异构性与同步问题

CPS设备在计算能力、网络连接和[可用能](@entry_id:268430)量等方面存在巨大差异，这构成了**系统异构性**。这种异构性对同步FL协议构成了严重挑战。

在**同步FL**中，服务器必须等待所有被选中的客户端完成本地计算并上传更新后，才能进行聚合。这导致整个系统的效率受限于最慢的客户端，即所谓的**“掉队者”问题（Straggler Problem）**。在CPS的实时环境中，这个问题尤为突出。一个CPS客户端通常需要运行高优先级的实时控制任务。用于FL训练的计算只能在控制周期的空闲时间窗口内进行。这个窗口的大小受到传感器[采样周期](@entry_id:265475)、致动器延迟、操作系统开销和时序[抖动](@entry_id:200248)等多种因素的限制。

例如，对于客户端 $i$，其每个控制周期 $T_{c,i}$ 内可用于训练的最小空闲时间为 $b_{i}^{\min}$。若该轮本地训练总计算量为 $W_i$，则完成计算至少需要 $\lceil W_i / b_{i}^{\min} \rceil$ 个控制周期，总耗时为 $T_{\text{comp}, i} = \lceil W_i / b_{i}^{\min} \rceil T_{c,i}$。考虑到最坏情况下的通信延迟 $\ell_{i}^{\max}$，该客户端完成一轮任务的总时间为 $T_{\text{total}, i}^{\max} = T_{\text{comp}, i} + \ell_{i}^{\max}$。如果对于任何一个参与的客户端 $i$，其最长完成时间超过了服务器设定的全局轮次截止时间 $D$（即 $T_{\text{total}, i}^{\max} > D$），那么同步聚合就是不可行的 。

为了应对“掉队者”问题，**异步[联邦学习](@entry_id:637118)（Asynchronous FL, AFL）**应运而生。在AFL中，服务器在收到任何一个客户端的更新后，会立即用它来更新全局模型，而无需等待其他客户端。这种非阻塞的方式显著提高了系统的[吞吐量](@entry_id:271802)和资源利用率。然而，异步性也引入了新的问题，即**陈旧更新（Stale Updates）**。

一个陈旧更新指的是，客户端 $k$ 在较早的时间点 $t_k$ 基于当时的全局模型 $\boldsymbol{\theta}^{(t_k)}$ 计算了更新，但当这个更新在稍晚的时间点 $t_s$ 到达并被服务器应用时，服务器的全局模型已经因为吸收了其他更快客户端的更新而演变成了 $\boldsymbol{\theta}^{(t_s)}$。服务器实际上是将一个针对旧模型 $\boldsymbol{\theta}^{(t_k)}$ 计算的梯度 $g_k(\boldsymbol{\theta}^{(t_k)})$ 应用到了新模型 $\boldsymbol{\theta}^{(t_s)}$ 上。这种不匹配引入了一个误差项 $g_k(\boldsymbol{\theta}^{(t_s)}) - g_k(\boldsymbol{\theta}^{(t_k)})$，如果梯度是 $L$-[Lipschitz连续的](@entry_id:267396)，这个误差的范数可以被 $L \|\boldsymbol{\theta}^{(t_s)} - \boldsymbol{\theta}^{(t_k)}\|$ 界定。陈旧性会给梯度方向带来偏差，如果陈旧程度（即模型版本的差异）过大，可能会损害收敛性。

需要区分的是**延迟聚合（Delayed Aggregation）**，这是指服务器的一种调度策略，即在收到更新后，有意等待一段时间（例如为了批量处理），再将其应用到全局模型上。这主要影响了模型更新的“挂钟时间”新鲜度，但更新内容本身（即基于哪个旧版本模型计算的）并未改变 。

### 先进机制与架构

为了克服上述挑战，研究界已经发展出多种先进的机制和替代性架构。

#### 去中心化（共识）学习架构

如前所述，完全去中心化的架构通过消除中央服务器，从根本上解决了与之相关的瓶颈和单点故障问题。在这种点对点网络中，鲁棒性和[可扩展性](@entry_id:636611)得到增强。然而，其性能高度依赖于通信网络的拓扑结构。

信息在去中心化网络中的传播和混合速度，直接影响了共识达成的效率，进而影响整体学习的[收敛速度](@entry_id:636873)。这个速度可以通过图的光谱（eigenvalue spectrum）特性来量化。对于一个由[图拉普拉斯矩阵](@entry_id:275190) $L = D - A$（其中 $D$ 是度矩阵，$A$ 是邻接矩阵）描述的无向[连通图](@entry_id:264785)，其第二个最小的特征值 $\lambda_2(L)$ 被称为**[代数连通度](@entry_id:152762)（Algebraic Connectivity）**。

代数连通度 $\lambda_2(L)$ 量化了图的“连接紧密程度”。在一个基于拉普拉斯的[共识算法](@entry_id:164644)（如 $x^{t+1} = x^t - \gamma L x^t$）中，$\lambda_2(L)$ 决定了非共识部分（即节点间差异）收敛到零的最慢速率。一个更大的 $\lambda_2(L)$ 意味着网络混合得更快，节点间的模型差异能够更快地被消除。在去中心化[联邦学习](@entry_id:637118)中，更快的混合速度有助于抑制由数据异构性（non-IID）引起的本地模型分歧，从而减少共识误差，并最终以更少的通信轮次达到目标精度 。

与中心化的参数服务器模型相比，去中心化模型在同步模式（本地屏障而非全局屏障）、故障容忍度（无单点故障）和[通信开销](@entry_id:636355)（每轮通信量与边数 $|E|$ 成正比，而非节点数 $|V|$）等方面都表现出截然不同的特性 。

#### 通信效率：梯度压缩

在许多CPS应用中，无线信道的带宽有限，对[通信开销](@entry_id:636355)有严格的预算。为了在这种约束下进行联邦学习，**梯度压缩**成为一项关键技术。其目标是在向服务器上传更新（如梯度或模型增量）之前，对其进行[有损压缩](@entry_id:267247)，以减少传输的数据量。两种主流的压缩技术是**量化**和**稀疏化**。

-   **梯度量化（Gradient Quantization）**：降低表示[梯度向量](@entry_id:141180)中每个坐标值的精度。例如，将一个32位浮点数映射到一个4位或8位的离散值集合中的一个。
-   **梯度稀疏化（Gradient Sparsification）**：只传输[梯度向量](@entry_id:141180)中“最重要”的一部分坐标，而将其余坐标置为零。例如，只发送绝对值最大的前 $k$ 个梯度值及其索引。

从[统计估计](@entry_id:270031)的角度看，压缩过程可以被视为用一个压缩后的梯度 $\widehat{\mathbf{g}}_i$ 来估计真实的本地梯度 $\mathbf{g}_i$。压缩器的性能可以通过其引入的偏差（bias）和方差（variance）来评估。

-   **确定性量化器（Deterministic Quantizers）**：这类量化器对给定的输入应用一个固定的映射规则，如“四舍五入”到最近的量化层级。对于一个确定的输入 $\mathbf{g}_i$，其输出 $\widehat{\mathbf{g}}_i$ 也是确定的。因此，在压缩操作本身这个层面上，它引入的**方差为零**。然而，由于[舍入误差](@entry_id:162651)的存在，除非输入恰好落在量化层级上，否则 $\mathbb{E}[\widehat{\mathbf{g}}_i] = \widehat{\mathbf{g}}_i \neq \mathbf{g}_i$，即它是**有偏**的。

-   **随机量化器（Stochastic Quantizers）**：这类量化器在映射过程中引入随机性。例如，一个值如果落在两个量化层级之间，它会以一定概率被映射到其中一个层级。这些概率经过精心设计，以确保输出的[期望值](@entry_id:150961)等于原始输入值，即 $\mathbb{E}[\widehat{\mathbf{g}}_i] = \mathbf{g}_i$。因此，这类量化器是**无偏**的。然而，引入随机性来消除偏差的代价是，压缩操作本身会给估计带来**非零的方差** 。

选择哪种压缩策略，需要在偏差对收敛的影响与方差对收敛的影响之间进行权衡。

#### 安全性：抵御拜占庭攻击

[联邦学习](@entry_id:637118)的分布式特性使其容易受到恶意参与者的攻击。在分布式计算中，最恶劣的[故障模型](@entry_id:1124860)是**[拜占庭故障](@entry_id:1121966)模型**，其中**拜占庭客户端**可以完全偏离协议，发送任意构造的、旨在破坏学习过程的恶意信息。在CPS中，这类攻击可能导致严重的物理后果。

在联邦学习中，拜占庭攻击主要分为两类：

-   **投毒攻击（Poisoning Attacks）**：攻击者的目标是降低全局模型的整体性能。他们通过发送精心构造的恶意更新，使聚合后的梯度方向偏离正确的风险最小化方向。例如，在[传感器校准](@entry_id:1131484)任务中，拜占庭客户端可以持续报告一个带有固定偏差的更新，这将污染全局模型，导致所有使用该模型的设备产生系统性测量误差。在控制器调优任务中，攻击者可以提交导致控制器在所有常规工况下性能下降（如超调量增大、振荡加剧）的参数更新 。

-   **后门攻击（Backdoor Attacks）**：攻击者的目标更为[隐蔽](@entry_id:196364)和险恶。他们希望在不影响模型在正常数据上表现的同时，植入一个“后门”。这个后门是一个由攻击者定义的特定触发器（trigger），当输入数据中包含该触发器时，模型会产生攻击者预设的恶意行为。在[传感器校准](@entry_id:1131484)中，后门攻击可以是在传感器读数中出现某种特定（且罕见）的[频谱](@entry_id:276824)模式或元数据标签时，才报告一个巨大的错误读数，而在其他时候表现正常。在控制器调优中，后门可能是在接收到某个特定的设定值序列时，故意让系统失稳或执行危险动作，而在正常操作下控制器性能良好。后门攻击因其[隐蔽](@entry_id:196364)性而尤其危险 。

开发能够抵御拜占庭攻击的鲁棒聚合规则是[联邦学习](@entry_id:637118)安全领域的一个核心研究方向。

#### 隐私性：[差分隐私](@entry_id:261539)

尽管联邦学习通过将[数据保留](@entry_id:174352)在本地提供了基本的隐私保护，但它并不能完全防止隐私泄露。攻击者仍然可能通过分析客户端上传的模型更新来推断其本地数据信息。为了提供更强的、可量化的隐私保证，**差分隐私（Differential Privacy, DP）**被引入到联邦学习中。

一个[随机化](@entry_id:198186)机制 $\mathcal{M}$ 被认为是满足 **$(\epsilon, \delta)$-[差分隐私](@entry_id:261539)** 的，如果对于任何两个仅相差一个个体数据的相邻数据集 $D$ 和 $D'$，以及任何可能的输出集合 $S$，都有 $\Pr[\mathcal{M}(D) \in S] \le e^{\epsilon} \Pr[\mathcal{M}(D') \in S] + \delta$ 成立。这里的“个体”在[联邦学习](@entry_id:637118)的客户端级别隐私中，指的是一个客户端的全部数据。这个定义直观地意味着，从机制的输出中，攻击者几乎无法判断某个特定客户端是否参与了计算。

在联邦学习中有两种主要的DP部署模式：

-   **中心差分隐私（Central DP）**：在这种模式下，服务器被认为是**可信的**。客户端发送未经扰动的更新给服务器。服务器在聚合了所有更新之后，对聚合结果应用一个[随机化](@entry_id:198186)机制（例如，添加高斯噪声），然后再发布或使用这个结果。这种方法保护了数据免受外部观察者的攻击，但不能防御恶意的或“好奇的”服务器。

-   **[本地差分隐私](@entry_id:1127394)（Local DP, LDP）**：在这种模式下，服务器被认为是**不可信的**。每个客户端在将其更新发送给服务器之前，必须在本地应用随机化机制。这样，原始的、未受保护的更新信息就永远不会离开客户端设备，从而提供了针对包括服务器在内的所有外部方的隐私保护。

这两种模式在隐私保证强度和模型效用之间存在着根本性的权衡。LDP提供了更强的隐私保证，但代价是模型精度的显著下降。其原因是，为了达到相同的隐私水平，每个客户端都需要添加大量的噪声。当服务器对这些充满噪声的更新进行平均时，虽然信号部分被平均，但噪声的方差也累积起来。

具体来说，如果使用[高斯机制](@entry_id:909372)并对客户端更新进行范数裁剪（clipping），在中心DP中，添加到聚合结果上的噪声方差在最终平均值中的贡献尺度为 $O(1/n^2)$（其中 $n$ 是参与客户端数量）。而在本地DP中，由于每个客户端都加噪，最终平均值中的噪声方差贡献尺度为 $O(1/n)$。这意味着随着客户端数量 $n$ 的增加，中心DP的精度会迅速提高，而本地DP的精度提升则缓慢得多。因此，在能够信任服务器的场景下，中心DP通常是实现隐私保护FL的首选方案 。