{
    "hands_on_practices": [
        {
            "introduction": "构建一个可靠的数字孪生，首先需要一个精确的物理系统动力学模型。本练习将演示如何运用联邦学习，在不共享敏感原始数据的情况下，从分布式数据中估计这些动态（即系统矩阵 $A$ 和 $B$）。通过此实践，您将学习如何构建一个融合先验物理知识的损失函数，并推导出一种通过聚合充分统计量来保护数据本地性的联邦估计算法。",
            "id": "4222039",
            "problem": "考虑一个由 $K$ 个分布式客户端组成的去中心化信息物理系统 (CPS)，每个客户端维护一个数字孪生，其局部动态可通过线性时不变 (LTI) 模型很好地近似。对于客户端 $k \\in \\{1,\\dots,K\\}$，其局部状态和输入时间序列满足离散时间动力学 $x_{t+1}^{(k)} = A x_{t}^{(k)} + B u_{t}^{(k)} + \\epsilon_{t}^{(k)}$，其中 $x_{t}^{(k)} \\in \\mathbb{R}^{n}$，$u_{t}^{(k)} \\in \\mathbb{R}^{m}$，而 $\\epsilon_{t}^{(k)} \\in \\mathbb{R}^{n}$ 是模型失配和过程噪声。假设存在一个基于物理的先验模型 $(A_{0}, B_{0})$，该模型通过第一性原理建模和线性化得到，其级联参数矩阵定义为 $\\Theta_{0} \\triangleq [A_{0}\\;B_{0}] \\in \\mathbb{R}^{n \\times (n+m)}$，并定义级联回归量 $z_{t}^{(k)} \\triangleq \\begin{pmatrix} x_{t}^{(k)} \\\\ u_{t}^{(k)} \\end{pmatrix} \\in \\mathbb{R}^{n+m}$。每个客户端都有一条长度为 $T_{k}$ 的局部轨迹，样本索引为 $t \\in \\{0,\\dots,T_{k}-1\\}$。\n\n您的任务是设计一种物理信息损失，该损失惩罚对 LTI 动力学的违反，并构建一个对 $(A,B)$ 的联邦估计器，该估计器在所有客户端之间保持一致，同时保护数据局部性。该物理信息损失必须基于以下科学基础：\n- LTI 系统的定义及其残差 $r_{t}^{(k)} \\triangleq x_{t+1}^{(k)} - A x_{t}^{(k)} - B u_{t}^{(k)}$。\n- 一个经过充分检验的假设，即 $\\epsilon_{t}^{(k)}$ 是独立同分布的，且服从 $\\epsilon_{t}^{(k)} \\sim \\mathcal{N}(0,\\sigma^{2} I_{n})$，其中标量 $\\sigma^{2} > 0$ 已知。\n- 需要使用正则化强度为 $\\lambda > 0$ 的 Tikhonov 惩罚，将估计器向基于物理的先验 $\\Theta_{0}$ 进行正则化。\n\n请正式推导一个对客户端和时间可加的目标函数，该函数惩罚动态残差并向 $\\Theta_{0}$ 正则化，并证明在 $\\Theta \\triangleq [A\\;B] \\in \\mathbb{R}^{n \\times (n+m)}$ 上最小化此目标函数会得到一个以客户端局部充分统计量表示的闭式解，这些统计量可以在不共享原始数据的情况下进行聚合。请将您的最终估计器完全用以下跨客户端的聚合量来表示：\n- $S_{ZZ} \\triangleq \\sum_{k=1}^{K} \\sum_{t=0}^{T_{k}-1} z_{t}^{(k)} z_{t}^{(k)\\top} \\in \\mathbb{R}^{(n+m) \\times (n+m)}$，\n- $S_{XZ} \\triangleq \\sum_{k=1}^{K} \\sum_{t=0}^{T_{k}-1} x_{t+1}^{(k)} z_{t}^{(k)\\top} \\in \\mathbb{R}^{n \\times (n+m)}$。\n\n您的推导必须仅依赖于上述基础，且不得引入未经检验的简化公式。最终答案必须是关于 $\\Theta$ 的全局联邦估计的单一闭式解析表达式，写成 $S_{ZZ}$、$S_{XZ}$、$\\lambda$、$\\sigma^{2}$ 和 $\\Theta_{0}$ 的函数。不要包含任何数值，也不要提供不等式。最终答案中不要包含任何单位。",
            "solution": "此问题已经过验证。\n\n### 步骤 1：提取已知条件\n- **系统**：一个拥有 $K$ 个客户端的去中心化信息物理系统 (CPS)。\n- **客户端动力学**：客户端 $k \\in \\{1, \\dots, K\\}$ 的离散时间线性时不变 (LTI) 模型：$x_{t+1}^{(k)} = A x_{t}^{(k)} + B u_{t}^{(k)} + \\epsilon_{t}^{(k)}$。\n- **状态向量**：$x_{t}^{(k)} \\in \\mathbb{R}^{n}$。\n- **输入向量**：$u_{t}^{(k)} \\in \\mathbb{R}^{m}$。\n- **噪声项**：$\\epsilon_{t}^{(k)} \\in \\mathbb{R}^{n}$。\n- **基于物理的先验**：$(A_{0}, B_{0})$。\n- **级联先验矩阵**：$\\Theta_{0} \\triangleq [A_{0}\\;B_{0}] \\in \\mathbb{R}^{n \\times (n+m)}$。\n- **级联回归量**：$z_{t}^{(k)} \\triangleq \\begin{pmatrix} x_{t}^{(k)} \\\\ u_{t}^{(k)} \\end{pmatrix} \\in \\mathbb{R}^{n+m}$。\n- **数据轨迹**：对于每个客户端 $k$，一条长度为 $T_{k}$ 的轨迹，时间索引为 $t \\in \\{0, \\dots, T_{k}-1\\}$。\n- **残差定义**：$r_{t}^{(k)} \\triangleq x_{t+1}^{(k)} - A x_{t}^{(k)} - B u_{t}^{(k)}$。\n- **噪声模型**：$\\epsilon_{t}^{(k)}$ 是独立同分布 (i.i.d.) 的，服从高斯分布 $\\mathcal{N}(0,\\sigma^{2} I_{n})$，其中 $\\sigma^{2} > 0$ 是一个已知标量。\n- **正则化**：朝向 $\\Theta_{0}$ 的 Tikhonov 惩罚，正则化强度为 $\\lambda > 0$。\n- **待估计参数矩阵**：$\\Theta \\triangleq [A\\;B] \\in \\mathbb{R}^{n \\times (n+m)}$。\n- **聚合充分统计量**：\n  - $S_{ZZ} \\triangleq \\sum_{k=1}^{K} \\sum_{t=0}^{T_{k}-1} z_{t}^{(k)} z_{t}^{(k)\\top} \\in \\mathbb{R}^{(n+m) \\times (n+m)}$。\n  - $S_{XZ} \\triangleq \\sum_{k=1}^{K} \\sum_{t=0}^{T_{k}-1} x_{t+1}^{(k)} z_{t}^{(k)\\top} \\in \\mathbb{R}^{n \\times (n+m)}$。\n- **目标**：以闭式解的形式推导 $\\Theta$ 的联邦估计器，表示为 $S_{ZZ}$、$S_{XZ}$、$\\lambda$、$\\sigma^{2}$ 和 $\\Theta_{0}$ 的函数。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据、适定且客观。\n1.  **科学依据**：该问题植根于系统辨识、统计估计和控制理论的基本原理。LTI 模型、高斯噪声假设、最大似然估计和 Tikhonov 正则化的使用是工程学和统计学中标准且经过严格验证的技术。联邦学习环境是这些原理的一个现代且有效的应用领域。\n2.  **适定性**：该问题要求推导一个目标函数的最小化器。该目标函数结合了平方和项（来自高斯似然）和二次正则化惩罚项，是凸函数。这保证了解的存在性和唯一性。即使数据矩阵之和 $S_{ZZ}$ 不是满秩的，Tikhonov 正则化也能确保问题保持良态。\n3.  **客观性与完整性**：该问题使用精确的数学语言和符号进行陈述。制定目标函数并推导其最小化器所需的所有必要组件均已提供。定义是自洽且一致的。\n\n该问题没有表现出任何诸如科学上不健全、信息缺失或模糊不清等缺陷。\n\n### 步骤 3：结论与行动\n问题有效。将提供一个合理的解决方案。\n\n任务是通过最小化一个物理信息损失函数，来推导参数矩阵 $\\Theta = [A\\;B]$ 的联邦估计器。该损失函数必须根据所提供的科学基础来构建：惩罚动态残差并朝先验模型 $\\Theta_0$ 进行正则化。这种表述等同于寻找 $\\Theta$ 的最大后验 (MAP) 估计。\n\n我们寻求相对于 $\\Theta$ 最小化的总目标函数，是数据保真项和正则化项的和。\n\n数据保真项源自观测数据的负对数似然。给定独立同分布 (i.i.d.) 的高斯噪声模型 $\\epsilon_{t}^{(k)} \\sim \\mathcal{N}(0, \\sigma^2 I_n)$，在给定回归量 $z_t^{(k)}$ 和参数 $\\Theta$ 的条件下，观测到状态 $x_{t+1}^{(k)}$ 的似然函数为：\n$$p(x_{t+1}^{(k)} | z_t^{(k)}, \\Theta) = \\frac{1}{(2\\pi\\sigma^2)^{n/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} \\|x_{t+1}^{(k)} - \\Theta z_t^{(k)}\\|_2^2\\right)$$\n由于所有样本都是独立的，总对数似然是各个对数似然的和。忽略常数项，负对数似然与残差平方和成正比，并由噪声方差进行缩放：\n$$-\\ln \\mathcal{L}(\\Theta) \\propto \\frac{1}{2\\sigma^2} \\sum_{k=1}^{K} \\sum_{t=0}^{T_k-1} \\|x_{t+1}^{(k)} - \\Theta z_t^{(k)}\\|_2^2$$\n\n正则化项被指定为强度为 $\\lambda$ 的 Tikhonov 惩罚：\n$$\\mathcal{R}(\\Theta) = \\frac{\\lambda}{2} \\|\\Theta - \\Theta_0\\|_F^2$$\n其中 $\\|\\cdot\\|_F$ 表示 Frobenius 范数。包含因子 $1/2$ 是为了方便求导。\n\n要最小化的总目标函数是负对数似然项和正则化项的和，代表负对数后验：\n$$\\mathcal{J}(\\Theta) = \\frac{1}{2\\sigma^2} \\sum_{k=1}^{K} \\sum_{t=0}^{T_k-1} \\|x_{t+1}^{(k)} - \\Theta z_t^{(k)}\\|_2^2 + \\frac{\\lambda}{2} \\|\\Theta - \\Theta_0\\|_F^2$$\n该目标在客户端和时间上是可加的，这对于联邦方法至关重要。我们可以使用矩阵迹表示法重写目标函数，注意到对于向量 $v$，$\\|v\\|_2^2 = v^\\top v = \\text{tr}(vv^\\top)$，对于矩阵 $M$，$\\|M\\|_F^2 = \\text{tr}(MM^\\top)$。\n\n让我们展开目标函数中的各项：\n$$\\sum_{k,t} \\|x_{t+1}^{(k)} - \\Theta z_t^{(k)}\\|_2^2 = \\sum_{k,t} \\text{tr}\\left((x_{t+1}^{(k)} - \\Theta z_t^{(k)})(x_{t+1}^{(k)} - \\Theta z_t^{(k)})^\\top\\right)$$\n$$= \\sum_{k,t} \\text{tr}\\left(x_{t+1}^{(k)}(x_{t+1}^{(k)})^\\top - x_{t+1}^{(k)}(z_t^{(k)})^\\top\\Theta^\\top - \\Theta z_t^{(k)}(x_{t+1}^{(k)})^\\top + \\Theta z_t^{(k)}(z_t^{(k)})^\\top\\Theta^\\top\\right)$$\n利用迹和求和算子的线性性质，可得：\n$$= \\text{tr}\\left(\\sum_{k,t} x_{t+1}^{(k)}(x_{t+1}^{(k)})^\\top\\right) - \\text{tr}\\left(\\left(\\sum_{k,t} x_{t+1}^{(k)}(z_t^{(k)})^\\top\\right)\\Theta^\\top\\right) - \\text{tr}\\left(\\Theta \\left(\\sum_{k,t} z_t^{(k)}(x_{t+1}^{(k)})^\\top\\right)\\right) + \\text{tr}\\left(\\Theta \\left(\\sum_{k,t} z_t^{(k)}(z_t^{(k)})^\\top\\right) \\Theta^\\top\\right)$$\n使用 $S_{XZ}$ 和 $S_{ZZ}$ 的给定定义以及属性 $\\text{tr}(A) = \\text{tr}(A^\\top)$：\n$$= C - 2\\text{tr}(S_{XZ} \\Theta^\\top) + \\text{tr}(\\Theta S_{ZZ} \\Theta^\\top)$$\n其中 $C$ 是一个与 $\\Theta$无关的常数。\n\n正则化项为：\n$$\\|\\Theta - \\Theta_0\\|_F^2 = \\text{tr}((\\Theta-\\Theta_0)(\\Theta-\\Theta_0)^\\top) = \\text{tr}(\\Theta\\Theta^\\top - \\Theta\\Theta_0^\\top - \\Theta_0\\Theta^\\top + \\Theta_0\\Theta_0^\\top)$$\n$$= \\text{tr}(\\Theta\\Theta^\\top) - 2\\text{tr}(\\Theta_0\\Theta^\\top) + \\text{const}$$\n\n将这些代回目标函数 $\\mathcal{J}(\\Theta)$：\n$$\\mathcal{J}(\\Theta) = \\frac{1}{2\\sigma^2}\\left(-2\\text{tr}(S_{XZ}\\Theta^\\top) + \\text{tr}(\\Theta S_{ZZ} \\Theta^\\top)\\right) + \\frac{\\lambda}{2}\\left(\\text{tr}(\\Theta\\Theta^\\top) - 2\\text{tr}(\\Theta_0\\Theta^\\top)\\right) + \\text{const}$$\n该目标是关于 $\\Theta$ 的二次函数，并且是凸函数。通过将其关于 $\\Theta$ 的梯度设为零来找到最小值。我们使用矩阵微积分恒等式 $\\nabla_X \\text{tr}(AX^\\top) = A$ 和 $\\nabla_X \\text{tr}(X B X^\\top) = X(B+B^\\top)$。\n$$\\nabla_\\Theta \\mathcal{J}(\\Theta) = \\frac{1}{2\\sigma^2}\\left(-2S_{XZ} + \\Theta(S_{ZZ} + S_{ZZ}^\\top)\\right) + \\frac{\\lambda}{2}\\left(2\\Theta - 2\\Theta_0\\right)$$\n由于 $S_{ZZ}$根据定义是对称的 ($S_{ZZ} = S_{ZZ}^\\top$)，上式简化为：\n$$\\nabla_\\Theta \\mathcal{J}(\\Theta) = \\frac{1}{\\sigma^2}(-S_{XZ} + \\Theta S_{ZZ}) + \\lambda(\\Theta - \\Theta_0)$$\n将梯度设为零以找到最优的 $\\hat{\\Theta}$：\n$$\\frac{1}{\\sigma^2}(-S_{XZ} + \\hat{\\Theta} S_{ZZ}) + \\lambda(\\hat{\\Theta} - \\Theta_0) = 0$$\n现在我们求解 $\\hat{\\Theta}$。两边乘以 $\\sigma^2$：\n$$-S_{XZ} + \\hat{\\Theta} S_{ZZ} + \\lambda\\sigma^2(\\hat{\\Theta} - \\Theta_0) = 0$$\n$$\\hat{\\Theta} S_{ZZ} + \\lambda\\sigma^2 \\hat{\\Theta} = S_{XZ} + \\lambda\\sigma^2 \\Theta_0$$\n提出因子 $\\hat{\\Theta}$：\n$$\\hat{\\Theta}(S_{ZZ} + \\lambda\\sigma^2 I) = S_{XZ} + \\lambda\\sigma^2 \\Theta_0$$\n其中 $I$ 是大小为 $(n+m) \\times (n+m)$ 的单位矩阵。\n联邦估计 $\\hat{\\Theta}$ 的闭式解可以通过右乘 $(S_{ZZ} + \\lambda\\sigma^2 I)$ 的逆矩阵得到。对于 $\\lambda > 0$ 和 $\\sigma^2 > 0$，该矩阵是可逆的，因为 $S_{ZZ}$ 是半正定的，而 $\\lambda\\sigma^2 I$ 是正定的，使其和为正定矩阵，因此可逆。\n$$\\hat{\\Theta} = (S_{XZ} + \\lambda\\sigma^2 \\Theta_0)(S_{ZZ} + \\lambda\\sigma^2 I)^{-1}$$\n此解符合联邦学习的设定。每个客户端 $k$ 计算其局部统计量 $\\sum_{t} z_{t}^{(k)} z_{t}^{(k)\\top}$ 和 $\\sum_{t} x_{t+1}^{(k)} z_{t}^{(k)\\top}$，然后这些统计量在中央服务器上聚合以形成 $S_{ZZ}$ 和 $S_{XZ}$，而无需共享原始数据 $\\{x_t^{(k)}, u_t^{(k)}\\}$。然后，服务器使用推导出的公式计算最终估计值。",
            "answer": "$$\n\\boxed{(S_{XZ} + \\lambda\\sigma^{2}\\Theta_{0})(S_{ZZ} + \\lambda\\sigma^{2}I)^{-1}}\n$$"
        },
        {
            "introduction": "在为系统建立模型之后，下一步通常是利用实时传感器数据来估计其当前状态。本练习探讨了在联邦设置中如何最优地融合来自多个异构传感器的测量数据。您将推导出一个联邦卡尔曼式滤波器的稳态性能，并理解为何根据传感器的可靠性（即噪声方差的倒数）进行加权至关重要。",
            "id": "4222026",
            "problem": "考虑一个去中心化的信息物理系统 (Cyber-Physical System, CPS)，其数字孪生 (Digital Twin, DT) 正在运行一个联邦学习 (Federated Learning, FL) 估计过程，用于估计一个标量潜状态。该物理过程根据离散时间线性时不变模型 $x_{k+1} = a x_k + w_k$ 演化，其中 $x_k \\in \\mathbb{R}$，$a \\in \\mathbb{R}$ 且为保证稳定性有 $|a| < 1$，过程噪声 $w_k$ 是零均值高斯分布，方差为 $Q > 0$。有 $m \\in \\mathbb{N}$ 个地理上分布的传感器；传感器 $i \\in \\{1,\\dots,m\\}$ 提供测量值 $y_{i,k} = x_k + v_{i,k}$，其中 $v_{i,k}$ 是零均值高斯分布，方差为 $R_i > 0$，在传感器之间和时间上独立，并且与 $w_k$ 独立。\n\nDT 使用联邦聚合来维护一个 Kalman 风格的估计器。在联邦设置中，原始测量数据不进行集中化处理；相反，本地站点发送信息形式更新所需的必要统计数据。聚合器构建的测量更新等效于（在线性高斯意义上）用每个传感器噪声协方差的逆 $R_i^{-1}$ 对其贡献进行加权。设测量更新后的后验误差协方差表示为 $P_k^{+}$，测量更新前的先验误差协方差表示为 $P_k^{-}$。时间更新遵循 $P_{k+1}^{-} = a^2 P_k^{+} + Q$。\n\n从线性高斯模型的基本贝叶斯估计原理和传感器噪声的独立性出发，推导在逆协方差联邦聚合下的稳态后验误差协方差 $P^{\\star}$，并将其表示为关于 $a$、 $Q$ 和 $\\{R_i\\}_{i=1}^{m}$ 的闭式解。然后，使用第一性原理，解释在稳态误差协方差方面，逆协方差加权与对测量值进行朴素均匀平均 $ \\bar{y}_k = \\frac{1}{m} \\sum_{i=1}^{m} y_{i,k}$ 相比如何，且不依赖任何快捷公式。\n\n您的最终答案必须是 $P^{\\star}$ 的单一闭式解析表达式，并且不得包含任何不等式或方程比较。不需要四舍五入，也不需要单位。",
            "solution": "所述问题具有科学依据，提法恰当，客观且自洽。它描述了一个标准的离散时间线性状态空间模型，并提出了一个关于在联邦传感场景下相关 Kalman 滤波器误差协方差 Riccati 方程的稳态解的问题。其模型和假设在估计理论和控制系统中是标准的。因此，该问题被认为是有效的。\n\n物理过程由线性时不变 (LTI) 模型描述：\n$$x_{k+1} = a x_k + w_k, \\quad w_k \\sim \\mathcal{N}(0, Q)$$\n其中 $x_k \\in \\mathbb{R}$ 是标量状态，稳定性条件 $|a| < 1$ 成立，$w_k$ 是过程噪声。\n有 $m$ 个传感器，第 $i$ 个传感器提供测量值：\n$$y_{i,k} = x_k + v_{i,k}, \\quad v_{i,k} \\sim \\mathcal{N}(0, R_i)$$\n测量噪声 $v_{i,k}$ 相互独立，且与 $w_k$ 独立。\n\n所描述的联邦聚合方案的核心是信息融合原理。对于独立的高斯测量，关于状态的总信息是每个来源提供的信息之和。在此，Kalman 滤波器的信息形式最为自然。误差协方差矩阵（在本例中为标量 $P_k^{+}$）的信息更新由下式给出：\n$$(P_k^{+})^{-1} = (P_k^{-})^{-1} + \\sum_{i=1}^{m} H_i^T R_i^{-1} H_i$$\n在我们的例子中，每个传感器的测量矩阵 $H_i$ 就是标量 $1$。因此，后验误差协方差的更新方程变为：\n$$(P_k^{+})^{-1} = (P_k^{-})^{-1} + \\sum_{i=1}^{m} R_i^{-1}$$\n我们将总测量精度 $S$ 定义为各个传感器精度的总和：\n$$S = \\sum_{i=1}^{m} R_i^{-1}$$\n测量更新方程则为 $(P_k^{+})^{-1} = (P_k^{-})^{-1} + S$。量 $S^{-1}$ 可以被解释为一个等效传感器的有效测量噪声方差 $R_{eff}$，该传感器最优地融合了所有 $m$ 个传感器的信息。\n\n误差协方差的时间更新如下：\n$$P_{k+1}^{-} = a^2 P_k^{+} + Q$$\n\n我们寻求稳态后验误差协方差，记为 $P^{\\star}$。在稳态下，协方差不再随时间变化，因此 $P_k^{+} = P_{k+1}^{+} = P^{\\star}$ 且 $P_k^{-} = P_{k+1}^{-} = P^{-}$。稳态方程为：\n1. $(P^{\\star})^{-1} = (P^{-})^{-1} + S$\n2. $P^{-} = a^2 P^{\\star} + Q$\n\n我们可以求解这个由两个方程组成的方程组，以求得单一未知数 $P^{\\star}$。从方程(1)中，我们可以用 $P^{\\star}$ 表示 $P^{-}$：\n$$(P^{-})^{-1} = (P^{\\star})^{-1} - S = \\frac{1 - S P^{\\star}}{P^{\\star}} \\implies P^{-} = \\frac{P^{\\star}}{1 - S P^{\\star}}$$\n将此代入方程(2)：\n$$\\frac{P^{\\star}}{1 - S P^{\\star}} = a^2 P^{\\star} + Q$$\n这种方法会导致代数上的困难。一个更直接的代入方法是将方程(2)代入方程(1)：\n$$(P^{\\star})^{-1} = (a^2 P^{\\star} + Q)^{-1} + S$$\n$$\\frac{1}{P^{\\star}} = \\frac{1}{a^2 P^{\\star} + Q} + S$$\n为了消去分数，我们将整个方程乘以 $P^{\\star}(a^2 P^{\\star} + Q)$:\n$$a^2 P^{\\star} + Q = P^{\\star} + S P^{\\star}(a^2 P^{\\star} + Q)$$\n$$a^2 P^{\\star} + Q = P^{\\star} + a^2 S (P^{\\star})^2 + Q S P^{\\star}$$\n重新整理各项，得到关于 $P^{\\star}$ 的二次方程：\n$$a^2 S (P^{\\star})^2 + (1 + QS - a^2) P^{\\star} - Q = 0$$\n这是一个标准形式为 $A x^2 + B x + C = 0$ 的二次方程，其中 $x = P^{\\star}$，$A = a^2 S$，$B = 1-a^2+QS$，$C = -Q$。解由二次公式给出：\n$$P^{\\star} = \\frac{-B \\pm \\sqrt{B^2 - 4AC}}{2A}$$\n代入我们的系数：\n$$P^{\\star} = \\frac{-(1-a^2+QS) \\pm \\sqrt{(1-a^2+QS)^2 - 4(a^2 S)(-Q)}}{2 a^2 S}$$\n$$P^{\\star} = \\frac{-(1-a^2+QS) \\pm \\sqrt{(1-a^2+QS)^2 + 4 a^2 Q S}}{2 a^2 S}$$\n由于 $P^{\\star}$ 代表误差方差，它必须是一个正实数。分母 $2a^2S$ 是正的（假设 $a \\neq 0$，这很典型，并且我们知道 $S > 0$）。让我们分析分子。平方根下的项是严格正的。平方根项 $\\sqrt{(1-a^2+QS)^2 + 4 a^2 Q S}$ 严格大于 $\\sqrt{(1-a^2+QS)^2} = |1-a^2+QS|$。由于 $|a| < 1$，$Q>0$ 且 $S>0$，项 $1-a^2+QS$ 是正的。因此，平方根大于 $1-a^2+QS$。为了确保 $P^{\\star}$ 为正值，我们必须在分子中选择 `+` 号：\n$$P^{\\star} = \\frac{-(1-a^2+QS) + \\sqrt{(1-a^2+QS)^2 + 4 a^2 Q S}}{2 a^2 S}$$\n这就是在逆协方差联邦聚合下的稳态后验误差协方差的闭式表达式，其中 $S = \\sum_{i=1}^{m} R_i^{-1}$。\n\n接下来，我们将这种最优融合与对测量值进行朴素均匀平均进行比较。平均后的测量值为：\n$$\\bar{y}_k = \\frac{1}{m} \\sum_{i=1}^{m} y_{i,k} = \\frac{1}{m} \\sum_{i=1}^{m} (x_k + v_{i,k}) = x_k + \\frac{1}{m} \\sum_{i=1}^{m} v_{i,k}$$\n这对应于一个有效的测量模型 $\\bar{y}_k = x_k + \\bar{v}_k$，其中有效的测量噪声是 $\\bar{v}_k = \\frac{1}{m} \\sum_{i=1}^{m} v_{i,k}$。由于噪声 $v_{i,k}$ 是独立的，它们和的方差是它们方差的和。有效噪声的方差为：\n$$R_{avg} = \\text{Var}(\\bar{v}_k) = \\text{Var}\\left(\\frac{1}{m} \\sum_{i=1}^{m} v_{i,k}\\right) = \\frac{1}{m^2} \\sum_{i=1}^{m} \\text{Var}(v_{i,k}) = \\frac{1}{m^2} \\sum_{i=1}^{m} R_i$$\n最优逆协方差加权的有效测量噪声方差为：\n$$R_{eff} = S^{-1} = \\left(\\sum_{i=1}^{m} R_i^{-1}\\right)^{-1}$$\n根据数学的第一性原理，特别是一组正数 $\\{R_i\\}$ 的算术平均数和调和平均数不等式，我们有：\n$$\\frac{\\sum_{i=1}^{m} R_i}{m} \\ge \\frac{m}{\\sum_{i=1}^{m} R_i^{-1}}$$\n两边同乘以 $1/m$ 得到：\n$$\\frac{1}{m^2}\\sum_{i=1}^{m} R_i \\ge \\frac{1}{\\sum_{i=1}^{m} R_i^{-1}}$$\n这直接转化为：\n$$R_{avg} \\ge R_{eff}$$\n当且仅当所有测量噪声方差相等时，即 $R_1=R_2=\\dots=R_m$ 时，等号成立。\n\n根据估计的第一性原理，后验误差协方差是测量噪声方差的单调递增函数。较大的测量噪声方差意味着测量提供的关于状态的信息可靠性较低。因此，滤波器会减少对测量的权重，而更多地依赖模型预测，从而导致最终状态估计具有更大的不确定性（误差协方差）。因此，由于 $R_{avg} \\ge R_{eff}$，由朴素平均产生的稳态后验误差协方差 $P_{avg}^{\\star}$ 将大于或等于由最优逆协方差加权得到的协方差 $P^{\\star}$。除非所有传感器的精度完全相同，否则朴素均匀平均是次优的。",
            "answer": "$$ \\boxed{ \\frac{-(1-a^2+Q\\sum_{i=1}^{m} R_i^{-1}) + \\sqrt{(1-a^2+Q\\sum_{i=1}^{m} R_i^{-1})^2 + 4 a^2 Q (\\sum_{i=1}^{m} R_i^{-1})}}{2 a^2 (\\sum_{i=1}^{m} R_i^{-1})} } $$"
        },
        {
            "introduction": "在去中心化系统中，一个关键挑战是确保全局模型对所有子系统都公平有效，而不仅仅是“平均”或数据最丰富的子系统。本计算练习将理论付诸实践，让您能够量化全局模型准确性（总体风险）与公平性（不同客户端群体间性能差异）之间的权衡。您将通过编程探索不同的聚合策略如何影响这一关键平衡。",
            "id": "4222080",
            "problem": "考虑一个使用数字孪生建模的去中心化网络物理系统（CPS）环境，其中联邦学习（FL）聚合客户端模型而无需集中原始数据。设有 $K$ 个客户端，索引为 $i \\in \\{1,2,\\dots,K\\}$，每个客户端都有一个定义在共享参数向量 $w \\in \\mathbb{R}^d$ 上的局部经验风险函数。假设采用经验风险最小化（ERM）和二次可微的凸损失函数，并将每个客户端在其局部最小值点 $w_i^\\star$ 附近的经验风险建模为一个正定二次近似：\n$$\nL_i(w) = (w - w_i^\\star)^\\top H_i (w - w_i^\\star) + c_i,\n$$\n其中 $H_i \\in \\mathbb{R}^{d \\times d}$ 是对称正定矩阵，$c_i \\in \\mathbb{R}$ 是一个常数偏移量。令联邦聚合器通过局部最小值点的凸组合形成一个全局参数，\n$$\nw(\\alpha) = \\sum_{i=1}^K \\alpha_i w_i^\\star,\n$$\n其中 $\\alpha_i \\ge 0$ 且 $\\sum_{i=1}^K \\alpha_i = 1$。令 $p_i \\ge 0$ 且 $\\sum_{i=1}^K p_i = 1$ 表示标准化的客户端数据量权重，它们将总体风险定义为\n$$\nR(w) = \\sum_{i=1}^K p_i L_i(w).\n$$\n假设这 $K$ 个客户端被划分为两个不相交的组 $G_1$ 和 $G_2$，覆盖所有客户端。通过对每个组内的客户端风险进行平均来定义组风险，\n$$\nR_{G_1}(w) = \\frac{1}{|G_1|} \\sum_{i \\in G_1} L_i(w), \\quad R_{G_2}(w) = \\frac{1}{|G_2|} \\sum_{i \\in G_2} L_i(w),\n$$\n并定义公平性差异\n$$\nD(w) = \\left| R_{G_1}(w) - R_{G_2}(w) \\right|.\n$$\n通过评估在不同聚合权重 $\\alpha$ 下，$D(w(\\alpha))$ 和 $R(w(\\alpha))$ 如何协同变化来评估公平性-准确性权衡。\n\n从 ERM 和凸二次损失近似的基础出发，编写一个完整的程序，根据给定的以下测试套件，为每个指定的聚合权重向量计算由总体风险 $R(w(\\alpha))$、公平性差异 $D(w(\\alpha))$ 以及相对于指定基线 $\\alpha^{\\mathrm{base}}$ 的边际公平性-准确性斜率组成的三元组，\n$$\nS(\\alpha) = \n\\begin{cases}\n\\frac{D(w(\\alpha)) - D(w(\\alpha^{\\mathrm{base}}))}{R(w(\\alpha)) - R(w(\\alpha^{\\mathrm{base}}))},  \\text{如果 } R(w(\\alpha)) \\ne R(w(\\alpha^{\\mathrm{base}})), \\\\\n0,  \\text{其他情况}.\n\\end{cases}\n$$\n\n使用以下参数，这些参数在一个 CPS 联邦优化场景中是科学上合理且自洽的。\n\n- 维度 $d = 2$，客户端数量 $K = 4$。\n- 客户端二次近似：\n  - $H_1 = \\begin{bmatrix} 2.0  0.3 \\\\ 0.3  1.0 \\end{bmatrix}$, $w_1^\\star = \\begin{bmatrix} 1.0 \\\\ -0.5 \\end{bmatrix}$, $c_1 = 0$。\n  - $H_2 = \\begin{bmatrix} 1.5  0.1 \\\\ 0.1  1.2 \\end{bmatrix}$, $w_2^\\star = \\begin{bmatrix} -0.8 \\\\ 0.3 \\end{bmatrix}$, $c_2 = 0$。\n  - $H_3 = \\begin{bmatrix} 2.2  -0.2 \\\\ -0.2  0.8 \\end{bmatrix}$, $w_3^\\star = \\begin{bmatrix} 0.5 \\\\ 1.2 \\end{bmatrix}$, $c_3 = 0$。\n  - $H_4 = \\begin{bmatrix} 0.9  0.0 \\\\ 0.0  1.8 \\end{bmatrix}$, $w_4^\\star = \\begin{bmatrix} -1.3 \\\\ -0.7 \\end{bmatrix}$, $c_4 = 0$。\n- 数据量权重 $p = [0.4, 0.1, 0.3, 0.2]$。\n- 组划分 $G_1 = \\{1, 2\\}$ 和 $G_2 = \\{3, 4\\}$。\n- 基线聚合权重 $\\alpha^{\\mathrm{base}} = [0.25, 0.25, 0.25, 0.25]$。\n- 待评估的聚合权重测试套件：\n  - 情况 1：$\\alpha = [0.25, 0.25, 0.25, 0.25]$ (统一基线)。\n  - 情况 2：$\\alpha = [0.45, 0.45, 0.05, 0.05]$ (强调组 $G_1$)。\n  - 情况 3：$\\alpha = [0.05, 0.05, 0.45, 0.45]$ (强调组 $G_2$)。\n  - 情况 4：$\\alpha = [0.4, 0.1, 0.3, 0.2]$ (按数据量加权)。\n  - 情况 5：$\\alpha = [0.97, 0.01, 0.01, 0.01]$ (极端偏向客户端 1)。\n\n您的程序必须：\n- 为每种情况计算 $w(\\alpha)$。\n- 为所有客户端 $i$ 计算 $L_i(w(\\alpha))$。\n- 按定义计算 $R(w(\\alpha))$、$R_{G_1}(w(\\alpha))$、$R_{G_2}(w(\\alpha))$、$D(w(\\alpha))$ 和 $S(\\alpha)$。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素是对应测试用例的三个浮点数列表 $[R, D, S]$，并按给定顺序排列。例如：$[[r_1,d_1,s_1],[r_2,d_2,s_2],\\dots]$。\n\n无需外部输入，不涉及物理单位、角度或百分比。所有数值输出必须是实值浮点数。",
            "solution": "在尝试解决方案之前，问题陈述经过了严格的验证过程。\n\n### 步骤 1：提取给定信息\n\n问题陈述中明确提供了以下数据和定义：\n- **模型背景**：一个去中心化的网络物理系统（CPS）环境，其中有 $K$ 个客户端使用联邦学习（FL）。客户端模型被聚合而无需集中原始数据。分析基于经验风险最小化（ERM）。\n- **客户端风险函数**：每个客户端 $i \\in \\{1, 2, \\dots, K\\}$ 都有一个局部经验风险函数 $L_i(w)$，该函数在其局部最小值点 $w_i^\\star \\in \\mathbb{R}^d$ 附近被一个正定二次形式近似：\n$$L_i(w) = (w - w_i^\\star)^\\top H_i (w - w_i^\\star) + c_i$$\n其中 $H_i \\in \\mathbb{R}^{d \\times d}$ 是一个对称正定矩阵，$c_i \\in \\mathbb{R}$ 是一个常数。\n- **聚合参数向量**：全局参数向量 $w(\\alpha)$ 是局部最小值点的凸组合：\n$$w(\\alpha) = \\sum_{i=1}^K \\alpha_i w_i^\\star, \\quad \\text{其中 } \\alpha_i \\ge 0 \\text{ 且 } \\sum_{i=1}^K \\alpha_i = 1$$\n- **总体风险函数**：总体风险 $R(w)$ 是客户端风险的加权平均：\n$$R(w) = \\sum_{i=1}^K p_i L_i(w), \\quad \\text{其中 } p_i \\ge 0 \\text{ 且 } \\sum_{i=1}^K p_i = 1$$\n- **组风险与公平性**：客户端被划分为两个不相交的组 $G_1$ 和 $G_2$。\n  - 组风险：$R_{G_1}(w) = \\frac{1}{|G_1|} \\sum_{i \\in G_1} L_i(w)$ 和 $R_{G_2}(w) = \\frac{1}{|G_2|} \\sum_{i \\in G_2} L_i(w)$。\n  - 公平性差异：$D(w) = |R_{G_1}(w) - R_{G_2}(w)|$。\n- **公平性-准确性斜率**：相对于基线 $\\alpha^{\\mathrm{base}}$ 的边际权衡斜率为：\n$$S(\\alpha) = \\begin{cases} \\frac{D(w(\\alpha)) - D(w(\\alpha^{\\mathrm{base}}))}{R(w(\\alpha)) - R(w(\\alpha^{\\mathrm{base}}))},  \\text{如果 } R(w(\\alpha)) \\ne R(w(\\alpha^{\\mathrm{base}})) \\\\ 0,  \\text{其他情况} \\end{cases}$$\n- **具体参数**：\n  - 维度 $d = 2$，客户端数量 $K = 4$。\n  - 客户端 1：$H_1 = \\begin{bmatrix} 2.0  0.3 \\\\ 0.3  1.0 \\end{bmatrix}$，$w_1^\\star = \\begin{bmatrix} 1.0 \\\\ -0.5 \\end{bmatrix}$，$c_1 = 0$。\n  - 客户端 2：$H_2 = \\begin{bmatrix} 1.5  0.1 \\\\ 0.1  1.2 \\end{bmatrix}$，$w_2^\\star = \\begin{bmatrix} -0.8 \\\\ 0.3 \\end{bmatrix}$，$c_2 = 0$。\n  - 客户端 3：$H_3 = \\begin{bmatrix} 2.2  -0.2 \\\\ -0.2  0.8 \\end{bmatrix}$，$w_3^\\star = \\begin{bmatrix} 0.5 \\\\ 1.2 \\end{bmatrix}$，$c_3 = 0$。\n  - 客户端 4：$H_4 = \\begin{bmatrix} 0.9  0.0 \\\\ 0.0  1.8 \\end{bmatrix}$，$w_4^\\star = \\begin{bmatrix} -1.3 \\\\ -0.7 \\end{bmatrix}$，$c_4 = 0$。\n  - 数据量权重：$p = [0.4, 0.1, 0.3, 0.2]$。\n  - 组划分：$G_1 = \\{1, 2\\}$，$G_2 = \\{3, 4\\}$。\n  - 基线聚合权重：$\\alpha^{\\mathrm{base}} = [0.25, 0.25, 0.25, 0.25]$。\n- **任务**：对于一个 $\\alpha$ 向量的测试套件，计算三元组 $(R(w(\\alpha)), D(w(\\alpha)), S(\\alpha))$。\n- **测试套件**：\n  - 情况 1：$\\alpha = [0.25, 0.25, 0.25, 0.25]$\n  - 情况 2：$\\alpha = [0.45, 0.45, 0.05, 0.05]$\n  - 情况 3：$\\alpha = [0.05, 0.05, 0.45, 0.45]$\n  - 情况 4：$\\alpha = [0.4, 0.1, 0.3, 0.2]$\n  - 情况 5：$\\alpha = [0.97, 0.01, 0.01, 0.01]$\n\n### 步骤 2：使用提取的给定信息进行验证\n\n根据既定标准对问题进行评估：\n- **科学依据**：该问题在优化和机器学习原理方面有充分的依据。使用二次近似来逼近损失函数是一种标准技术，源自于围绕最小值点的二阶泰勒展开。联邦平均、经验风险以及公平性-准确性权衡等概念是当前分布式机器学习研究的核心。该框架是一个用于分析联邦学习算法行为的有效且常见的简化模型。\n- **适定且一致**：该问题在数学上是适定的。所有量都由明确的公式定义。给定输入参数，输出通过确定性的计算过程唯一确定。参数是自洽的：\n  - 数据量权重的总和为 $\\sum_{i=1}^4 p_i = 0.4 + 0.1 + 0.3 + 0.2 = 1.0$。\n  - 对于每个测试用例，聚合权重的总和为 1：例如，对于情况 2，$\\sum_{i=1}^4 \\alpha_i = 0.45 + 0.45 + 0.05 + 0.05 = 1.0$。所有 $\\alpha_i$ 均为非负值。\n  - Hessian 矩阵 $H_i$ 被指定为对称正定。通过检查它们的主子式来验证这一点。对于一个 $2 \\times 2$ 矩阵，这要求左上角元素和行列式为正。\n    - $H_1$：$2.0 > 0$，$\\det(H_1) = (2.0)(1.0) - (0.3)^2 = 1.91 > 0$。\n    - $H_2$：$1.5 > 0$，$\\det(H_2) = (1.5)(1.2) - (0.1)^2 = 1.79 > 0$。\n    - $H_3$：$2.2 > 0$，$\\det(H_3) = (2.2)(0.8) - (-0.2)^2 = 1.72 > 0$。\n    - $H_4$：$0.9 > 0$，$\\det(H_4) = (0.9)(1.8) - (0.0)^2 = 1.62 > 0$。\n  所有矩阵确实都是正定的。\n  - $S(\\alpha)$ 的定义明确处理了分母为零的情况，防止了不确定性。\n- **客观且可形式化**：该问题使用精确的数学语言陈述，没有主观性或歧义。它可以直接形式化为一个计算算法。CPS 和数字孪生的背景为这个抽象的数学问题提供了科学上相关的动机。\n\n该问题没有表现出任何已定义的缺陷（例如，科学上不健全、不完整、矛盾或不适定）。\n\n### 步骤 3：结论与行动\n\n该问题是**有效的**。将推导并实现一个解决方案。\n\n### 解决方案的推导\n\n目标是为测试套件中每个指定的聚合权重向量 $\\alpha$ 计算三元组 $(R(w(\\alpha)), D(w(\\alpha)), S(\\alpha))$。这需要系统地应用所提供的定义。步骤如下：\n\n**步骤 1：基线计算**\n首先，我们使用基线聚合权重 $\\alpha^{\\mathrm{base}} = [0.25, 0.25, 0.25, 0.25]$ 来计算基线总体风险 $R^{\\mathrm{base}}$ 和公平性差异 $D^{\\mathrm{base}}$。这些值对于计算所有测试用例的斜率 $S(\\alpha)$ 是必需的。\n\n**步骤 2：遍历测试用例**\n对于由向量 $\\alpha$ 定义的每个测试用例，我们执行以下计算：\n\n**2.1. 计算聚合参数向量 $w(\\alpha)$**\n全局参数向量是局部最小值点的凸组合：\n$$w(\\alpha) = \\sum_{i=1}^{4} \\alpha_i w_i^\\star$$\n这是一个向量和，其中每个局部最小值向量 $w_i^\\star$ 都按其相应的权重 $\\alpha_i$进行缩放。\n\n**2.2. 计算客户端特定损失 $L_i(w(\\alpha))$**\n对于每个客户端 $i \\in \\{1, 2, 3, 4\\}$，计算其在聚合参数 $w(\\alpha)$ 处的局部损失。鉴于所有客户端的 $c_i = 0$：\n$$L_i(w(\\alpha)) = (w(\\alpha) - w_i^\\star)^\\top H_i (w(\\alpha) - w_i^\\star)$$\n令 $\\Delta w_i(\\alpha) = w(\\alpha) - w_i^\\star$。损失计算为二次型 $L_i(w(\\alpha)) = (\\Delta w_i(\\alpha))^\\top H_i (\\Delta w_i(\\alpha))$。\n\n**2.3. 计算总体风险 $R(w(\\alpha))$**\n总体风险是客户端特定损失的加权平均，使用数据量权重 $p_i$：\n$$R(w(\\alpha)) = \\sum_{i=1}^{4} p_i L_i(w(\\alpha))$$\n其中 $p = [0.4, 0.1, 0.3, 0.2]$。\n\n**2.4. 计算组风险和公平性差异 $D(w(\\alpha))$**\n客户端被划分为 $G_1 = \\{1, 2\\}$ 和 $G_2 = \\{3, 4\\}$。组风险是每个组内损失的平均值。由于 $|G_1| = 2$ 和 $|G_2| = 2$：\n$$R_{G_1}(w(\\alpha)) = \\frac{1}{2} (L_1(w(\\alpha)) + L_2(w(\\alpha)))$$\n$$R_{G_2}(w(\\alpha)) = \\frac{1}{2} (L_3(w(\\alpha)) + L_4(w(\\alpha)))$$\n公平性差异是这两个组风险之间的绝对差值：\n$$D(w(\\alpha)) = |R_{G_1}(w(\\alpha)) - R_{G_2}(w(\\alpha))|$$\n\n**2.5. 计算边际公平性-准确性斜率 $S(\\alpha)$**\n使用预先计算的基线值 $R^{\\mathrm{base}} = R(w(\\alpha^{\\mathrm{base}}))$ 和 $D^{\\mathrm{base}} = D(w(\\alpha^{\\mathrm{base}}))$，斜率计算如下：\n$$S(\\alpha) = \\frac{D(w(\\alpha)) - D^{\\mathrm{base}}}{R(w(\\alpha)) - R^{\\mathrm{base}}}$$\n如果分母 $R(w(\\alpha)) - R^{\\mathrm{base}}$ 为零（这发生在情况 1 中，其中 $\\alpha = \\alpha^{\\mathrm{base}}$），则斜率定义为 $S(\\alpha) = 0$。\n\n这个多步骤过程将应用于所提供的 5 个测试用例中的每一个。最终输出是所得 $(R, D, S)$ 三元组的集合。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the federated learning fairness-accuracy trade-off problem.\n    \"\"\"\n    \n    # Define the problem parameters as specified.\n    # Dimension d=2, number of clients K=4.\n    \n    # Client Hessian matrices H_i\n    H_mats = [\n        np.array([[2.0, 0.3], [0.3, 1.0]]),\n        np.array([[1.5, 0.1], [0.1, 1.2]]),\n        np.array([[2.2, -0.2], [-0.2, 0.8]]),\n        np.array([[0.9, 0.0], [0.0, 1.8]])\n    ]\n\n    # Client local minimizers w_i^*\n    w_stars = [\n        np.array([1.0, -0.5]),\n        np.array([-0.8, 0.3]),\n        np.array([0.5, 1.2]),\n        np.array([-1.3, -0.7])\n    ]\n\n    # Constant offsets c_i (all zero)\n    c_vals = np.array([0.0, 0.0, 0.0, 0.0])\n\n    # Data-size weights p_i\n    p_vec = np.array([0.4, 0.1, 0.3, 0.2])\n\n    # Group partition G1={1, 2}, G2={3, 4}\n    # Indices are 0-based in the code, so G1={0, 1}, G2={2, 3}\n    G1_indices = [0, 1]\n    G2_indices = [2, 3]\n\n    # Baseline aggregation weights alpha_base\n    alpha_base = np.array([0.25, 0.25, 0.25, 0.25])\n\n    # Test suite of aggregation weights alpha\n    test_cases = [\n        np.array([0.25, 0.25, 0.25, 0.25]),  # Case 1 (uniform baseline)\n        np.array([0.45, 0.45, 0.05, 0.05]),  # Case 2 (emphasize G1)\n        np.array([0.05, 0.05, 0.45, 0.45]),  # Case 3 (emphasize G2)\n        np.array([0.4, 0.1, 0.3, 0.2]),       # Case 4 (data-size weighted)\n        np.array([0.97, 0.01, 0.01, 0.01])   # Case 5 (skewed to client 1)\n    ]\n\n    def compute_all_metrics(alpha_vec, H, w_s, c, p):\n        \"\"\"\n        Computes all required metrics for a given alpha vector.\n        \"\"\"\n        # Step 1: Compute global parameter w(alpha)\n        w_alpha = np.sum([alpha_vec[i] * w_s[i] for i in range(len(w_s))], axis=0)\n\n        # Step 2: Compute client-specific losses L_i(w(alpha))\n        losses = []\n        for i in range(len(w_s)):\n            delta_w = w_alpha - w_s[i]\n            loss = delta_w.T @ H[i] @ delta_w + c[i]\n            losses.append(loss)\n        \n        # Step 3: Compute overall risk R(w(alpha))\n        R = np.sum(p * losses)\n\n        # Step 4: Compute group risks and fairness disparity D(w(alpha))\n        R_G1 = np.mean([losses[i] for i in G1_indices])\n        R_G2 = np.mean([losses[i] for i in G2_indices])\n        D = np.abs(R_G1 - R_G2)\n\n        return R, D\n\n    # Compute baseline risk and disparity\n    R_base, D_base = compute_all_metrics(alpha_base, H_mats, w_stars, c_vals, p_vec)\n\n    results = []\n    for alpha_test in test_cases:\n        # Compute metrics for the current test case\n        R_test, D_test = compute_all_metrics(alpha_test, H_mats, w_stars, c_vals, p_vec)\n\n        # Step 5: Compute marginal fairness-accuracy slope S(alpha)\n        delta_R = R_test - R_base\n        if np.isclose(delta_R, 0):\n            S = 0.0\n        else:\n            delta_D = D_test - D_base\n            S = delta_D / delta_R\n        \n        # Append the triplet [R, D, S] to results\n        # Represent 'str(a_list).replace(' ', '')' would remove spaces but the default is fine.\n        results.append([R_test, D_test, S])\n\n    # Final print statement in the exact required format.\n    # map(str, results) will create strings like '[r, d, s]'\n    # ','.join will produce '[r1,d1,s1],[r2,d2,s2]'\n    # The f-string adds the outer brackets.\n    output_str = ','.join([str(res) for res in results])\n    print(f\"[{output_str}]\")\n\nsolve()\n\n```"
        }
    ]
}