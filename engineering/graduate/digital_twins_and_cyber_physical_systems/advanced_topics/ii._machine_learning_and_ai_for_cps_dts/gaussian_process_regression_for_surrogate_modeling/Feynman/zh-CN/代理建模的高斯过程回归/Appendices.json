{
    "hands_on_practices": [
        {
            "introduction": "本实践旨在从第一性原理出发，动手实现高斯过程回归的预测方程。通过为具有马特恩（Matérn）核的GP模型计算预测均值和方差，您将深入理解高斯过程回归的核心机制，并掌握将理论公式转化为数值稳定代码的关键技能。这项练习是后续更高级应用的基础。",
            "id": "4224416",
            "problem": "考虑一个针对信息物理系统 (CPS) 的数字孪生的代理建模任务，其中潜系统响应被建模为高斯过程 (GP)。高斯过程 (GP) 定义为一族随机变量的集合，其中任何有限子集都服从多元高斯分布。设潜函数表示为 $f(\\cdot)$，观测输出为 $y$，其中 $y$ 是 $f(\\cdot)$ 的带噪声观测，噪声为加性独立高斯噪声。\n\n假设先验为零均值 $m(x)=0$，协方差函数为具有已知超参数的 Matérn 协方差函数。观测模型为 $y_i = f(x_i) + \\epsilon_i$，其中对于 $i \\in \\{1,\\dots,n\\}$，$\\epsilon_i \\sim \\mathcal{N}(0,\\sigma_n^2)$ 独立同分布。Matérn 核函数 $k_\\nu(\\cdot,\\cdot)$ 通过欧几里得距离 $r = \\lVert x - x' \\rVert_2$ 定义如下：\n$$\nk_\\nu(r) \\;=\\; \\sigma_f^2 \\cdot \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\left( \\frac{\\sqrt{2\\nu}\\, r}{\\ell} \\right)^\\nu K_\\nu \\!\\left( \\frac{\\sqrt{2\\nu}\\, r}{\\ell} \\right),\n$$\n其中 $\\sigma_f^2$ 是信号方差，$\\ell$ 是长度尺度，$\\nu$ 是平滑度参数，$\\Gamma(\\cdot)$ 是伽马函数，而 $K_\\nu(\\cdot)$ 是第二类修正贝塞尔函数。该核函数满足 $k_\\nu(0) = \\sigma_f^2$。\n\n从高斯过程先验和线性高斯观测模型的定义出发，推导在新输入点 $x_*$ 处潜函数 $f(x_*)$ 的预测分布。实现一个程序，使用数值稳定的线性代数方法计算在 $x_*$ 处的预测均值和方差。\n\n您的实现必须：\n- 使用给定的 Matérn 核函数构建 Gram 矩阵 $K$，并将其对角线元素加上观测噪声方差 $\\sigma_n^2$。\n- 使用数值稳定的求解器（例如，基于 Cholesky 的方法）以避免显式矩阵求逆。\n- 计算潜函数 $f(x_*)$ 的预测均值和方差。\n\n不需要物理单位；所有量均为无量纲实数。不涉及角度。不涉及百分比。\n\n测试套件：\n使用以下测试用例。每个用例指定了 $X \\in \\mathbb{R}^{n \\times d}$，$y \\in \\mathbb{R}^n$，超参数 $(\\sigma_f,\\ell,\\nu,\\sigma_n)$ 和一个查询点 $x_* \\in \\mathbb{R}^d$。所有数值均为实数。\n\n- 用例 1 (通用二维，中等长度尺度):\n  $$\n  X^{(1)} = \\begin{bmatrix}\n  0.0  & 0.0\\\\\n  0.5  & -0.2\\\\\n  1.0  & 0.3\\\\\n  1.5  & -0.5\\\\\n  2.0  & 0.0\n  \\end{bmatrix},\\quad\n  y^{(1)} = \\begin{bmatrix}\n  0.0\\\\\n  0.329418342\\\\\n  0.807356092\\\\\n  0.782039086\\\\\n  0.999573603\n  \\end{bmatrix},\n  $$\n  $$\n  (\\sigma_f^{(1)},\\ell^{(1)},\\nu^{(1)},\\sigma_n^{(1)}) = (1.2,\\,0.7,\\,1.5,\\,0.1),\\quad\n  x_*^{(1)} = \\begin{bmatrix} 1.2\\\\ 0.1 \\end{bmatrix}.\n  $$\n\n- 用例 2 (边界情况：查询点等于一个训练输入):\n  $$\n  X^{(2)} = X^{(1)},\\quad y^{(2)} = y^{(1)},\\quad\n  (\\sigma_f^{(2)},\\ell^{(2)},\\nu^{(2)},\\sigma_n^{(2)}) = (1.2,\\,0.7,\\,1.5,\\,0.1),\\quad\n  x_*^{(2)} = \\begin{bmatrix} 1.0\\\\ 0.3 \\end{bmatrix}.\n  $$\n\n- 用例 3 (边界：极小长度尺度，强局部性):\n  $$\n  X^{(3)} = X^{(1)},\\quad y^{(3)} = y^{(1)},\\quad\n  (\\sigma_f^{(3)},\\ell^{(3)},\\nu^{(3)},\\sigma_n^{(3)}) = (1.2,\\,0.05,\\,1.5,\\,0.05),\\quad\n  x_*^{(3)} = \\begin{bmatrix} 1.1\\\\ 0.25 \\end{bmatrix}.\n  $$\n\n- 用例 4 (边界：极大长度尺度，近似恒定的行为):\n  $$\n  X^{(4)} = X^{(1)},\\quad y^{(4)} = y^{(1)},\\quad\n  (\\sigma_f^{(4)},\\ell^{(4)},\\nu^{(4)},\\sigma_n^{(4)}) = (1.2,\\,50.0,\\,1.5,\\,0.1),\\quad\n  x_*^{(4)} = \\begin{bmatrix} 10.0\\\\ -10.0 \\end{bmatrix}.\n  $$\n\n- 用例 5 (一维输入，不同平滑度):\n  $$\n  X^{(5)} = \\begin{bmatrix}\n  0.0\\\\ 1.0\\\\ 2.0\\\\ 3.0\n  \\end{bmatrix},\\quad\n  y^{(5)} = \\begin{bmatrix}\n  1.0\\\\ 0.540302306\\\\ -0.416146837\\\\ -0.989992497\n  \\end{bmatrix},\n  $$\n  $$\n  (\\sigma_f^{(5)},\\ell^{(5)},\\nu^{(5)},\\sigma_n^{(5)}) = (1.0,\\,1.0,\\,2.5,\\,0.01),\\quad\n  x_*^{(5)} = \\begin{bmatrix} 1.5 \\end{bmatrix}.\n  $$\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个测试用例结果是一个双元素列表 $[\\mu, s^2]$，包含对应 $x_*$ 的预测均值 $\\mu$ 和方差 $s^2$。具体而言，输出必须是\n$$\n\\big[ [\\mu^{(1)}, s^{2,(1)}], [\\mu^{(2)}, s^{2,(2)}], [\\mu^{(3)}, s^{2,(3)}], [\\mu^{(4)}, s^{2,(4)}], [\\mu^{(5)}, s^{2,(5)}] \\big].\n$$",
            "solution": "用户提供了一个统计机器学习领域中明确定义的问题。任务是推导并实现高斯过程 (GP) 回归的预测方程。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n\n- **模型**：使用高斯过程对潜函数 $f(\\cdot)$ 进行建模。\n- **先验**：GP 具有零均值先验，$m(x)=0$。\n- **协方差**：协方差函数是具有已知超参数 $\\sigma_f^2$（信号方差）、$\\ell$（长度尺度）和 $\\nu$（平滑度）的 Matérn 核函数 $k_\\nu(\\cdot,\\cdot)$。该核函数定义如下：\n$$\nk_\\nu(r) \\;=\\; \\sigma_f^2 \\cdot \\frac{2^{1-\\nu}}{\\Gamma(\\nu)} \\left( \\frac{\\sqrt{2\\nu}\\, r}{\\ell} \\right)^\\nu K_\\nu \\!\\left( \\frac{\\sqrt{2\\nu}\\, r}{\\ell} \\right)\n$$\n其中 $r = \\lVert x - x' \\rVert_2$，$\\Gamma(\\cdot)$ 是伽马函数，$K_\\nu(\\cdot)$ 是第二类修正贝塞尔函数。给定性质 $k_\\nu(0) = \\sigma_f^2$。\n- **观测模型**：观测值 $y_i$ 是潜函数的带噪声版本，$y_i = f(x_i) + \\epsilon_i$，其中噪声 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2)$ 独立同分布。\n- **目标**：推导在新输入点 $x_*$ 处潜函数值 $f(x_*)$ 的预测分布。\n- **实现约束**：\n    1.  构建 Gram 矩阵 $K$。\n    2.  将观测噪声方差 $\\sigma_n^2$ 加到对角线上。\n    3.  使用像 Cholesky 分解这样的数值稳定方法来避免显式矩阵求逆。\n    4.  计算 $f(x_*)$ 的预测均值和方差。\n- **数据**：提供了五个测试用例，每个用例都包含训练输入 $X$、训练输出 $y$、超参数 $(\\sigma_f, \\ell, \\nu, \\sigma_n)$ 和一个测试输入 $x_*$。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n- **科学依据**：该问题是高斯过程贝叶斯推断的标准应用，这是现代机器学习和统计学的基石。所有定义和公式在该领域都是正确且标准的。\n- **适定性**：问题是适定的。给定模型、数据和超参数，后验预测分布是唯一确定的。要求使用数值稳定的求解器，是承认并解决了协方差矩阵可能存在的病态问题，从而确保可以计算出稳定的解。\n- **目标**：问题以精确的数学语言陈述，没有歧义，并为唯一解提供了所有必要的数值数据。\n- **完整性和一致性**：问题是自洽的。它提供了完整的模型规范（先验、似然、核函数）和计算所需的所有数据。没有矛盾之处。\n- **现实性**：该任务是代理建模的一个典型例子，这是数字孪生和信息物理系统中的一个关键功能。数值对于此类问题是现实的。\n\n**步骤 3：结论和行动**\n\n该问题是**有效的**，因为它是科学合理的、适定的和完整的。我现在将着手推导和实现解决方案。\n\n### 预测分布的推导\n\n高斯过程回归的核心原理是，任何有限的函数值集合都服从联合高斯分布。我们感兴趣的是，在给定训练数据 $D = \\{X, \\mathbf{y}\\}$ 的条件下，测试点 $x_*$ 处潜函数值 $f_* = f(x_*)$ 的条件分布，其中 $X = \\{x_1, \\dots, x_n\\}$ 是训练输入集，$\\mathbf{y} = [y_1, \\dots, y_n]^T$ 是相应带噪声观测值的向量。\n\n1.  **联合先验分布**：根据 GP 先验，训练点处的潜函数值向量 $\\mathbf{f} = [f(x_1), \\dots, f(x_n)]^T$ 和测试点处的值 $f_*$ 服从联合高斯分布。在零均值先验下，该分布为：\n    $$\n    \\begin{bmatrix} \\mathbf{f} \\\\ f_* \\end{bmatrix} \\sim \\mathcal{N} \\left( \\begin{bmatrix} \\mathbf{0} \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} K(X, X) & K(X, x_*) \\\\ K(x_*, X) & K(x_*, x_*) \\end{bmatrix} \\right)\n    $$\n    让我们用更简洁的符号来表示分块协方差矩阵：$K = K(X, X)$（$n \\times n$ 的 Gram 矩阵），$k_* = K(X, x_*)$（训练点与测试点之间的协方差向量，$n \\times 1$），以及 $k_{**} = K(x_*, x_*)$（测试点处的先验方差）。因此，协方差矩阵为 $\\begin{bmatrix} K & k_* \\\\ k_*^T & k_{**} \\end{bmatrix}$。\n\n2.  **观测值与潜测试值的联合分布**：观测模型为 $\\mathbf{y} = \\mathbf{f} + \\boldsymbol{\\epsilon}$，其中噪声向量 $\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_n^2 I_n)$。由于 $\\mathbf{f}$ 和 $\\boldsymbol{\\epsilon}$ 是独立的，它们的和 $\\mathbf{y}$ 也是一个高斯随机变量。观测数据 $\\mathbf{y}$ 和潜值 $f_*$ 的联合分布为：\n    $$\n    \\begin{bmatrix} \\mathbf{y} \\\\ f_* \\end{bmatrix} \\sim \\mathcal{N} \\left( \\begin{bmatrix} \\mathbf{0} \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} K + \\sigma_n^2 I_n & k_* \\\\ k_*^T & k_{**} \\end{bmatrix} \\right)\n    $$\n    此处，$\\mathbf{y}$ 和 $f_*$ 之间的协方差为 $\\text{Cov}(\\mathbf{f} + \\boldsymbol{\\epsilon}, f_*) = \\text{Cov}(\\mathbf{f}, f_*) + \\text{Cov}(\\boldsymbol{\\epsilon}, f_*) = k_* + \\mathbf{0} = k_*$。$\\mathbf{y}$ 的方差为 $\\text{Var}(\\mathbf{f} + \\boldsymbol{\\epsilon}) = \\text{Var}(\\mathbf{f}) + \\text{Var}(\\boldsymbol{\\epsilon}) = K + \\sigma_n^2 I_n$。\n\n3.  **条件（后验）分布**：我们寻求分布 $p(f_* | \\mathbf{y}, X, x_*)$。使用多元高斯分布的条件分布标准公式，对于一个联合分布 $\\begin{pmatrix} \\mathbf{a} \\\\ \\mathbf{b} \\end{pmatrix} \\sim \\mathcal{N} \\left( \\begin{pmatrix} \\boldsymbol{\\mu}_a \\\\ \\boldsymbol{\\mu}_b \\end{pmatrix}, \\begin{pmatrix} \\Sigma_{aa} & \\Sigma_{ab} \\\\ \\Sigma_{ba} & \\Sigma_{bb} \\end{pmatrix} \\right)$，条件分布 $p(\\mathbf{b}|\\mathbf{a})$ 是一个高斯分布，其均值为 $\\boldsymbol{\\mu}_{b|a} = \\boldsymbol{\\mu}_b + \\Sigma_{ba} \\Sigma_{aa}^{-1} (\\mathbf{a} - \\boldsymbol{\\mu}_a)$，协方差为 $\\Sigma_{b|a} = \\Sigma_{bb} - \\Sigma_{ba} \\Sigma_{aa}^{-1} \\Sigma_{ab}$。\n\n    通过代入我们的项（$\\mathbf{a} \\to \\mathbf{y}$，$\\mathbf{b} \\to f_*$，零均值，以及推导出的协方差结构），我们得到 $f_*$ 的预测分布：\n    -   **预测均值** $\\mu_*(x_*)$：\n        $$\n        \\mu_*(x_*) = \\mathbf{0} + k_*^T (K + \\sigma_n^2 I_n)^{-1} (\\mathbf{y} - \\mathbf{0}) = k_*^T (K + \\sigma_n^2 I_n)^{-1} \\mathbf{y}\n        $$\n    -   **预测方差** $s^2_*(x_*)$：\n        $$\n        s^2_*(x_*) = k_{**} - k_*^T (K + \\sigma_n^2 I_n)^{-1} k_*\n        $$\n\n### 数值稳定的实现\n\n直接计算矩阵逆 $(K + \\sigma_n^2 I_n)^{-1}$ 在数值上是不稳定且低效的。一个更好的方法是使用 Cholesky 分解。设 $K_{yy} = K + \\sigma_n^2 I_n$。由于 $K$ 是对称半正定矩阵，且 $\\sigma_n^2 > 0$，因此 $K_{yy}$ 是对称正定矩阵。因此，它有唯一的 Cholesky 分解 $K_{yy} = LL^T$，其中 $L$ 是一个下三角矩阵。\n\n然后，预测均值和方差可以按如下方式计算：\n\n1.  为计算均值 $\\mu_*(x_*) = k_*^T \\boldsymbol{\\alpha}$，其中 $\\boldsymbol{\\alpha} = K_{yy}^{-1}\\mathbf{y}$，我们求解线性系统 $K_{yy}\\boldsymbol{\\alpha} = \\mathbf{y}$。使用分解，这变为 $LL^T\\boldsymbol{\\alpha} = \\mathbf{y}$。我们使用代入法分两步求解：\n    a. 求解 $L\\mathbf{v} = \\mathbf{y}$ 得到 $\\mathbf{v}$（前向代入）。\n    b. 求解 $L^T\\boldsymbol{\\alpha} = \\mathbf{v}$ 得到 $\\boldsymbol{\\alpha}$（后向代入）。\n\n2.  为计算方差 $s^2_*(x_*) = k_{**} - k_*^T K_{yy}^{-1} k_*$，我们计算其二次型。设 $\\mathbf{z} = L^{-1}k_*$。我们可以通过前向代入求解 $L\\mathbf{z} = k_*$ 来找到 $\\mathbf{z}$。然后二次型可以写成：\n    $$\n    k_*^T K_{yy}^{-1} k_* = k_*^T (LL^T)^{-1} k_* = k_*^T (L^T)^{-1}L^{-1} k_* = (L^{-1}k_*)^T (L^{-1}k_*) = \\mathbf{z}^T\\mathbf{z} = \\lVert \\mathbf{z} \\rVert_2^2\n    $$\n    因此，预测方差为 $s^2_*(x_*) = k_{**} - \\mathbf{z}^T\\mathbf{z}$。这种方法避免了第二次三角求解，并且在数值上是稳健的。\n\n### Matérn 核函数计算\n\nMatérn 核函数需要计算伽马函数 $\\Gamma(\\nu)$ 和第二类修正贝塞尔函数 $K_\\nu(z)$。这些函数在 `scipy.special` 中可用。一个关键细节是 $r=0$ 处的行为。此时，贝塞尔函数的参数为零，而当 $z \\to 0$ 时 $K_\\nu(z)$ 发散。然而，乘积 $z^\\nu K_\\nu(z)$ 有一个有限极限 $2^{\\nu-1}\\Gamma(\\nu)$。将此代入核函数公式可以证实给定的性质 $k_\\nu(0) = \\sigma_f^2$。实现时必须单独处理 $r=0$ 的情况，以避免出现类似 $0 \\times \\infty$ 的数值错误。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gamma, kv\nfrom scipy.linalg import cholesky, solve_triangular\n\ndef solve():\n    \"\"\"\n    Solves for the predictive mean and variance for a series of Gaussian Process\n    regression test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"X\": np.array([\n                [0.0, 0.0], [0.5, -0.2], [1.0, 0.3], [1.5, -0.5], [2.0, 0.0]\n            ]),\n            \"y\": np.array([0.0, 0.329418342, 0.807356092, 0.782039086, 0.999573603]),\n            \"params\": (1.2, 0.7, 1.5, 0.1),\n            \"x_star\": np.array([1.2, 0.1])\n        },\n        {\n            \"X\": np.array([\n                [0.0, 0.0], [0.5, -0.2], [1.0, 0.3], [1.5, -0.5], [2.0, 0.0]\n            ]),\n            \"y\": np.array([0.0, 0.329418342, 0.807356092, 0.782039086, 0.999573603]),\n            \"params\": (1.2, 0.7, 1.5, 0.1),\n            \"x_star\": np.array([1.0, 0.3])\n        },\n        {\n            \"X\": np.array([\n                [0.0, 0.0], [0.5, -0.2], [1.0, 0.3], [1.5, -0.5], [2.0, 0.0]\n            ]),\n            \"y\": np.array([0.0, 0.329418342, 0.807356092, 0.782039086, 0.999573603]),\n            \"params\": (1.2, 0.05, 1.5, 0.05),\n            \"x_star\": np.array([1.1, 0.25])\n        },\n        {\n            \"X\": np.array([\n                [0.0, 0.0], [0.5, -0.2], [1.0, 0.3], [1.5, -0.5], [2.0, 0.0]\n            ]),\n            \"y\": np.array([0.0, 0.329418342, 0.807356092, 0.782039086, 0.999573603]),\n            \"params\": (1.2, 50.0, 1.5, 0.1),\n            \"x_star\": np.array([10.0, -10.0])\n        },\n        {\n            \"X\": np.array([\n                [0.0], [1.0], [2.0], [3.0]\n            ]),\n            \"y\": np.array([1.0, 0.540302306, -0.416146837, -0.989992497]),\n            \"params\": (1.0, 1.0, 2.5, 0.01),\n            \"x_star\": np.array([1.5])\n        }\n    ]\n\n    def matern_kernel(X1, X2, sigma_f, l, nu):\n        \"\"\"\n        Computes the Matérn covariance matrix between two sets of points.\n        \"\"\"\n        # Compute squared Euclidean distance matrix\n        # dist_sq = sum_i( (X1_i - X2_i)^2 )\n        dist_sq = np.sum(X1**2, axis=1)[:, np.newaxis] + np.sum(X2**2, axis=1) - 2 * np.dot(X1, X2.T)\n        # Numerical stability for small negative values from floating point errors\n        dist_sq = np.maximum(dist_sq, 0)\n        r = np.sqrt(dist_sq)\n\n        # Handle the r=0 special case\n        # For r > 0, we use the standard formula. For r=0, the kernel value is sigma_f^2\n        # A small epsilon is used for numerical stability\n        eps = 1e-9\n        r_is_zero = r  eps\n        \n        # Pre-compute constants\n        const_factor = (2**(1 - nu)) / gamma(nu)\n        sigma_f_sq = sigma_f**2\n\n        # Create a result matrix filled with the r=0 case\n        K = np.full(r.shape, sigma_f_sq)\n\n        # Compute arguments for the non-zero distance case\n        r_nz = r[~r_is_zero]\n        arg = (np.sqrt(2 * nu) * r_nz) / l\n        \n        # Calculate kernel values for r > 0\n        K[~r_is_zero] = sigma_f_sq * const_factor * (arg**nu) * kv(nu, arg)\n        \n        return K\n\n    results = []\n    for case in test_cases:\n        X, y = case[\"X\"], case[\"y\"]\n        sigma_f, l, nu, sigma_n = case[\"params\"]\n        x_star = case[\"x_star\"].reshape(1, -1) # Ensure x_star is 2D\n        n = X.shape[0]\n\n        # 1. Construct the Gram matrix K(X, X) and add noise\n        K = matern_kernel(X, X, sigma_f, l, nu)\n        K_yy = K + (sigma_n**2) * np.eye(n)\n\n        # 2. Compute the Cholesky decomposition of K_yy\n        # L L^T = K_yy\n        try:\n            L = cholesky(K_yy, lower=True)\n        except np.linalg.LinAlgError:\n            # Fallback for numerically challenging matrices\n            # Add a small jitter to the diagonal\n            jitter = 1e-6\n            L = cholesky(K_yy + jitter * np.eye(n), lower=True)\n\n\n        # 3. Compute the cross-covariance vector k_* = K(X, x_*)\n        k_star = matern_kernel(X, x_star, sigma_f, l, nu)\n\n        # 4. Compute the predictive mean\n        # Solve L v = y, then L^T alpha = v\n        v = solve_triangular(L, y, lower=True)\n        alpha = solve_triangular(L.T, v, lower=False)\n        mu_star = np.dot(k_star.T, alpha)\n\n        # 5. Compute the predictive variance\n        # Solve L z = k_*, then var = k_** - z^T z\n        z = solve_triangular(L, k_star, lower=True)\n        k_star_star = sigma_f**2 # k(x_*, x_*) where r=0\n        s2_star = k_star_star - np.dot(z.T, z)\n\n        # Ensure results are scalar floats\n        mu_val = float(mu_star)\n        s2_val = float(s2_star)\n        results.append([mu_val, s2_val])\n\n    # Format the final output string exactly as required\n    output_parts = [f\"[{mu},{s2}]\" for mu, s2 in results]\n    print(f\"[{','.join(output_parts)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个强大的代理模型始于一个恰当的先验假设，在高斯过程中，这体现在核函数的设计上。本练习将探讨如何通过组合不同的核函数来为一个表现出周期性振荡和缓慢趋势的复杂物理系统建模。通过分析加性核的原理，您将学会如何让模型结构反映潜在的物理过程，这是高斯过程建模中的一项核心高级技能。",
            "id": "4224393",
            "problem": "在数字孪生中，一个信息物理系统展现出一个可观测输出 $y(t)$，该输出在一个已知的驱动频率下呈现持续振荡，并因热量积累而产生缓慢漂移的基线。您的目标是为 $y(t)$ 建立一个高斯过程回归代理模型，以支持预测和在线异常检测。您设定潜函数 $f(t)$ 分解为一个周期性分量和一个缓慢变化趋势的加性叠加，并受到独立测量噪声的干扰。因此，您采用一个具有复合协方差的高斯过程先验\n$$\nk(t,t') \\;=\\; k_{\\text{periodic}}(t,t') \\;+\\; k_{\\text{RBF}}(t,t') \\;+\\; \\sigma_n^2 \\,\\delta(t,t')\\,,\n$$\n其中，$k_{\\text{periodic}}$ 编码周期为 $p$ 的周期性相关性，$k_{\\text{RBF}}$ 编码在某个特征长度尺度上的平滑相关性，而 $\\sigma_n^2 \\delta(t,t')$ 是观测噪声协方差。您将通过边缘似然，并结合具有物理意义的弱先验来训练超参数。\n\n仅从以下基本事实出发：(i) 高斯过程是随机变量的集合，其任何有限子集都服从联合高斯分布；(ii) 如果 $f_1 \\sim \\mathcal{GP}(0,k_1)$ 和 $f_2 \\sim \\mathcal{GP}(0,k_2)$ 是独立的，那么 $f_1 + f_2 \\sim \\mathcal{GP}(0,k_1 + k_2)$；(iii) 对联合高斯分布进行条件化是线性的，并产生高斯后验分布；以及 (iv) 对于平稳核，功率谱密度是协方差的傅里叶变换，且傅里叶变换是线性的。请基于这些事实，判断以下哪些陈述正确地论证和描述了针对此信息物理系统的建模选择 $k = k_{\\text{periodic}} + k_{\\text{RBF}}$。\n\n选择所有适用项。\n\nA. 加性核编码了先验假设 $f(t) = f_{\\text{per}}(t) + f_{\\text{tr}}(t)$，其中 $f_{\\text{per}} \\sim \\mathcal{GP}(0,k_{\\text{periodic}})$ 和 $f_{\\text{tr}} \\sim \\mathcal{GP}(0,k_{\\text{RBF}})$ 在先验上是独立的。在高斯条件化下，后验均值可加性地分解为两个潜分量后验均值的和；对于平稳分量， $f$ 的边缘功率谱密度是各分量谱密度的和，这反映了窄带周期性谱线和宽带低频凸起的叠加。\n\nB. 对于此任务，乘积核 $k(t,t') = k_{\\text{periodic}}(t,t') \\, k_{\\text{RBF}}(t,t')$ 在本质上更优，因为它强制周期性振荡和缓慢趋势在潜函数中以加性方式组合，而和（sum）无法表示物理上的加性叠加。\n\nC. 因为 $f_{\\text{per}}$ 和 $f_{\\text{tr}}$ 在先验上被建模为独立的，所以在对数据进行条件化之后它们仍然保持独立，因此 $f_{\\text{per}}$ 和 $f_{\\text{tr}}$ 之间的后验互协方差在所有输入上恒为 $0$。\n\nD. 如果没有与物理学一致的、对超参数的信息性先验结构，当观测窗口跨越少于大约 $2$ 个周期时，最大边缘似然可能会混淆 $k_{\\text{periodic}}$ 和 $k_{\\text{RBF}}$。施加先验或约束，以鼓励 $\\ell_{\\text{RBF}}  p$ 并且周期性相长度尺度在相空间中较短，可以提高加性分解的可辨识性。\n\nE. 使用加性核，任何测试输入点的预测方差等于各个分量预测方差之和再加上噪声方差，并且无论训练输入的位置如何，此等式都成立。",
            "solution": "问题陈述描述了高斯过程（GP）回归在时间序列建模中的一个标准且有效的应用。其目标是为输出 $y(t)$ 建模，该输出是周期信号、缓慢漂移以及噪声的叠加。所提出的模型是一个具有加性核结构的高斯过程。该问题具有科学依据，提法恰当且客观。我们可以开始解答。\n\n该建模选择的核心是将潜函数 $f(t)$ 表示为两个独立过程的和：一个周期性分量 $f_{\\text{per}}(t)$ 和一个趋势分量 $f_{\\text{tr}}(t)$。\n$$f(t) = f_{\\text{per}}(t) + f_{\\text{tr}}(t)$$\n周期性分量的先验为 $f_{\\text{per}} \\sim \\mathcal{GP}(0, k_{\\text{periodic}})$，趋势分量的先验为 $f_{\\text{tr}} \\sim \\mathcal{GP}(0, k_{\\text{RBF}})$。根据基本事实(ii)，如果这两个过程是独立的，它们的和 $f = f_{\\text{per}} + f_{\\text{tr}}$ 也是一个高斯过程，其先验为 $f \\sim \\mathcal{GP}(0, k)$，其中核函数 $k$ 是各分量核的和：\n$$k(t,t') = k_{\\text{periodic}}(t,t') + k_{\\text{RBF}}(t,t')$$\n观测值由 $y(t) = f(t) + \\epsilon$ 给出，其中 $\\epsilon$ 代表方差为 $\\sigma_n^2$ 的独立同分布高斯噪声，对应于噪声协方差项 $\\sigma_n^2 \\delta(t,t')$。设训练数据为 $\\mathcal{D} = \\{(\\mathbf{t}, \\mathbf{y})\\}$。我们现在来评估每个陈述。\n\n**选项A评估**\n该陈述对加性模型提出了三个论点。\n1.  **加性分解：** “加性核编码了先验假设 $f(t) = f_{\\text{per}}(t) + f_{\\text{tr}}(t)$，其中 $f_{\\text{per}} \\sim \\mathcal{GP}(0,k_{\\text{periodic}})$ 和 $f_{\\text{tr}} \\sim \\mathcal{GP}(0,k_{\\text{RBF}})$ 在先验上是独立的。” 这是对基本事实(ii)的直接且正确的解释。核的和精确地对应于一个模型假设，即潜函数是从各分量先验中抽取的独立高斯过程样本的和。\n2.  **后验均值分解：** “在高斯条件化下，后验均值可加性地分解为两个潜分量后验均值的和……” 在一个测试点 $t_*$ 处，总函数 $f$ 的后验均值为 $\\mathbb{E}[f(t_*) | \\mathcal{D}]$。根据期望的线性性质，这是 $\\mathbb{E}[f_{\\text{per}}(t_*) + f_{\\text{tr}}(t_*) | \\mathcal{D}] = \\mathbb{E}[f_{\\text{per}}(t_*) | \\mathcal{D}] + \\mathbb{E}[f_{\\text{tr}}(t_*) | \\mathcal{D}]$。这个数学恒等式成立。因此，和的后验均值是各分量后验均值的和，其中所有均值都是以相同的观测数据 $\\mathcal{D}$ 为条件。\n3.  **功率谱密度（PSD）分解：** “……对于平稳分量， $f$ 的边缘功率谱密度是各分量谱密度的和，这反映了窄带周期性谱线和宽带低频凸起的叠加。” 根据基本事实(iv)，功率谱密度 $S(\\omega)$ 是协方差函数 $k(\\tau)$ 的傅里叶变换，其中 $\\tau = t-t'$。傅里叶变换是一个线性算子。因此，对于总协方差 $k = k_{\\text{periodic}} + k_{\\text{RBF}}$，其功率谱密度为 $S(\\omega) = \\mathcal{F}[k_{\\text{periodic}}](\\omega) + \\mathcal{F}[k_{\\text{RBF}}](\\omega) = S_{\\text{periodic}}(\\omega) + S_{\\text{RBF}}(\\omega)$。其描述也是正确的：周期核的功率谱密度在基频的谐波处有尖锐的峰值，而RBF核的功率谱密度是在零频率处的一个宽阔的、类似高斯分布的峰（一个低频凸起）。\n陈述A的所有部分都是正确的，并且可以从所提供的基本事实中推导出来。\n\n对选项A的判断：**正确**。\n\n**选项B评估**\n该陈述声称乘积核 $k(t,t') = k_{\\text{periodic}}(t,t') \\, k_{\\text{RBF}}(t,t')$ 更优，因为它强制潜函数进行加性组合。这在根本上是错误的。正如基本事实(ii)所确立的，是核的和对应于独立潜函数的和。核的乘积并不对应于一个加性模型；相反，它可以用来为交互作用建模，例如一个振幅被平滑非周期函数调制的周期函数。陈述中“和（sum）无法表示物理上的加性叠加”的说法与正确原理完全相反。\n\n对选项B的判断：**错误**。\n\n**选项C评估**\n该陈述声称，由于先验分量 $f_{\\text{per}}$ 和 $f_{\\text{tr}}$ 是独立的，它们在对数据 $\\mathcal{D}$ 进行条件化后的后验分布中仍然保持独立。这是一个常见的谬误。对和 $f(t_i) = f_{\\text{per}}(t_i) + f_{\\text{tr}}(t_i)$ 的观测值 $y_i$ 进行条件化，会在这两个分量之间引入依赖关系。这种现象被称为“解释消除”（explaining away）：如果我们观测到一个值 $y_i$，并随后推断出分量 $f_{\\text{per}}(t_i)$ 有一个大的正值，那么为了解释同一个观测值，分量 $f_{\\text{tr}}(t_i)$ 有一个较小的值就变得更有可能。这意味着在后验中存在负相关性。联合后验分布 $p(f_{\\text{per}}, f_{\\text{tr}} | \\mathcal{D})$ 是高斯的，但其协方差矩阵包含非零的非对角块，代表后验互协方差 $\\text{Cov}(f_{\\text{per}}, f_{\\text{tr}} | \\mathcal{D})$。由于这个互协方差不恒为零，因此后验分量不是独立的。\n\n对选项C的判断：**错误**。\n\n**选项D评估**\n该陈述解决了在模型拟合中使用最大边缘似然时超参数可辨识性的实际问题，正如问题设置中提到的。边缘似然的景观可能条件很差，尤其是在数据有限的情况下。如果观测窗口很短（例如，如建议的，少于大约2个周期），周期函数的一段可以被一个平滑的非周期函数很好地近似。在这种情况下，优化器可能难以区分周期核 $k_{\\text{periodic}}$ 和RBF核 $k_{\\text{RBF}}$ 的贡献。这是一个真实的混淆问题。该陈述正确地提出，对超参数施加具有物理意义的先验或约束可以解决这种模糊性。例如，将RBF的长度尺度 $\\ell_{\\text{RBF}}$ 约束为大于已知周期 $p$ （$\\ell_{\\text{RBF}}  p$），可以强制其仅用于建模*缓慢漂移*的基线，从而将其功能与周期核区分开来。这改善了加性分解的可辨识性。这个陈述正确地描述了成功应用所选模型的一个关键方面。\n\n对选项D的判断：**正确**。\n\n**选项E评估**\n该陈述声称预测方差是可加的。在测试点 $t_*$ 处，总函数 $f$ 的预测方差为 $\\text{var}[f(t_*) | \\mathcal{D}]$。由于 $f(t_*) = f_{\\text{per}}(t_*) + f_{\\text{tr}}(t_*)$，和的方差由下式给出：\n$$\\text{var}[f(t_*) | \\mathcal{D}] = \\text{var}[f_{\\text{per}}(t_*) | \\mathcal{D}] + \\text{var}[f_{\\text{tr}}(t_*) | \\mathcal{D}] + 2\\,\\text{cov}[f_{\\text{per}}(t_*), f_{\\text{tr}}(t_*) | \\mathcal{D}]$$\n正如在选项C的分析中所确立的，后验互协方差项 $\\text{cov}[f_{\\text{per}}(t_*), f_{\\text{tr}}(t_*) | \\mathcal{D}]$ 通常不为零。该陈述错误地忽略了这个交叉项。声称这种加性等式“无论训练输入的位置如何”都成立的说法也是错误的，因为整个后验分布，包括所有的方差和协方差，都严重依赖于训练数据。方差可加的唯一情况是在先验中（条件化之前），即 $\\text{var}[f(t_*)] = k(t_*, t_*) = k_{\\text{periodic}}(t_*, t_*) + k_{\\text{RBF}}(t_*, t_*)$。预测方差作为一个后验量，是不可加的。该陈述还提到加上噪声方差 $\\sigma_n^2$，这与预测新观测值 $y_*$ 相关，而不是潜函数 $f_*$。即使对于 $y_*$，其潜在的潜函数分量的方差也不是可加的。\n\n对选项E的判断：**错误**。",
            "answer": "$$\\boxed{AD}$$"
        },
        {
            "introduction": "高斯过程回归的主要优势之一是其能够提供有量化不确定性的预测。本实践将展示如何利用这一特性，将功率消耗代理模型的不确定性传播到对总能耗的估计中。通过为一个操作周期计算总能量的可信区间（credible interval），您将掌握不确定性传播的关键技术，这对于在数字孪生和信息物理系统中进行风险评估和鲁棒决策至关重要。",
            "id": "4224377",
            "problem": "考虑一个信息物理系统 (CPS) 的数字孪生 (DT)，该数字孪生使用高斯过程回归 (GPR) 作为代理模型，来预测在固定工作模式下瞬时功耗 $f(t)$（单位：瓦特）随时间 $t$（单位：秒）的变化。目标是通过严格传播代理模型的不确定性，计算一个工作周期内总消耗能量的不确定性边界。所有涉及物理单位的量都必须以一致的单位报告：时间单位为秒，能量单位为焦耳。\n\n现提供以下训练数据和建模假设：\n\n- 训练输入（时间样本，单位：秒）：$[0,2,4,6,8]$。\n- 训练输出（测得功率，单位：瓦特，与上述时间对应）：$[120.0,135.0,128.0,140.0,132.0]$。\n- 核函数选择：平方指数协方差核函数，其幅度参数为 $\\sigma_f^2$，长度尺度为 $\\ell$，由下式给出\n$$\nk(t,t') = \\sigma_f^2 \\exp\\left(-\\frac{(t-t')^2}{2\\ell^2}\\right).\n$$\n- 超参数：$\\sigma_f^2 = 900.0$（瓦特平方），$\\ell = 2.5$（秒），以及独立高斯测量噪声方差 $\\sigma_n^2 = 9.0$（瓦特平方）。\n\n假设工作周期由一组有限的查询时间 $t_i$（单位：秒）指定，每个时间点代表在均匀时间间隔 $\\Delta t$（单位：秒）下对代理模型 $f(t)$ 的一次瞬时采样。总能量通过黎曼和 $\\sum_i f(t_i)\\,\\Delta t$ 近似计算，并且必须以焦耳为单位报告。由于代理模型的预测是不确定的，需要传播 GPR 的后验不确定性，以获得总能量在 $0.95$ 水平上的双边中心置信区间的下界和上界。所有边界都以焦耳为单位，报告为实值小数。\n\n实现一个程序，该程序：\n- 针对每个工作周期案例，使用提供的训练数据和超参数，在指定的查询时间点上构建 $f(t)$ 的 GPR 后验。\n- 通过黎曼和传播代理模型的后验不确定性，以获得总能量（单位：焦耳）在 $0.95$ 水平上的中心置信区间。\n- 生成单行输出，包含每个案例的边界。每个案例的结果是一个包含两个元素的列表 $[L,U]$，分别代表 $0.95$ 置信区间的下界 $L$ 和上界 $U$。\n\n使用以下工作周期的测试套件：\n1. 正常路径：查询时间为 $[1,2,3,4,5,6,7,8,9]$，均匀间隔 $\\Delta t = 1.0$ 秒。\n2. 边界情况：查询时间为空 $[]$，$\\Delta t = 1.0$ 秒（这代表零长度周期，应产生零能量和零不确定性）。\n3. 单样本边缘情况：查询时间为 $[5.0]$，$\\Delta t = 2.0$ 秒。\n4. 密集采样边缘情况：查询时间为 $[0.0,0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0,5.5,6.0,6.5,7.0,7.5,8.0]$，$\\Delta t = 0.5$ 秒。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，格式如下\n$$\n[[L_1,U_1],[L_2,U_2],[L_3,U_3],[L_4,U_4]],\n$$\n其中每个 $L_i$ 和 $U_i$ 都是实数，代表上述列表中第 $i$ 个案例的 $0.95$ 置信区间的下界和上界（单位：焦耳）。",
            "solution": "该问题是有效的，因为它具有科学依据、客观、适定，并包含得出唯一解所需的所有信息。任务是将高斯过程回归 (GPR) 功耗代理模型的不确定性，传播到总能耗的估计中。\n\n解决方案包括三个主要阶段：\n1.  基于提供的训练数据，为功率函数 $f(t)$ 构建 GPR 后验分布。\n2.  将此后验分布的均值和协方差通过计算总能量的线性算子（即黎曼和）进行传播。\n3.  使用得到的总能量分布来计算 $0.95$ 中心置信区间的边界。\n\n**1. 高斯过程回归模型**\n\n高斯过程 (GP) 定义了函数上的概率分布。我们将未知的功耗函数 $f(t)$ 建模为从一个 GP 中的抽样：\n$$\nf(t) \\sim \\mathcal{GP}(\\mu(t), k(t, t'))\n$$\n其中 $\\mu(t)$ 是均值函数，$k(t, t')$ 是协方差（或核）函数。按照标准实践，我们假设一个零均值先验，即 $\\mu(t) = 0$。问题指定了平方指数核函数：\n$$\nk(t, t') = \\sigma_f^2 \\exp\\left(-\\frac{(t-t')^2}{2\\ell^2}\\right)\n$$\n其超参数为 $\\sigma_f^2 = 900.0 \\, \\text{W}^2$（幅度）和 $\\ell = 2.5 \\, \\text{s}$（长度尺度）。\n\n训练数据包含 $N=5$ 个带噪声的功率测量值。训练输入是时间点 $X = [0, 2, 4, 6, 8]^T$（秒），对应的训练输出是功率测量值 $Y = [120.0, 135.0, 128.0, 140.0, 132.0]^T$（瓦特）。观测模型为 $y_i = f(t_i) + \\epsilon_i$，其中测量噪声 $\\epsilon_i$ 假设为独立同分布的高斯噪声，$\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2)$，噪声方差为 $\\sigma_n^2 = 9.0 \\, \\text{W}^2$。\n\n给定训练数据 $(X, Y)$ 和一组 $N_*$ 个查询时间点 $X_* = [t_{*1}, \\dots, t_{*N_*}]^T$，GPR 框架给出了函数值 $\\mathbf{f}_* = [f(t_{*1}), \\dots, f(t_{*N_*})]^T$ 的后验分布。该后验是一个多元高斯分布，$p(\\mathbf{f}_* | X, Y, X_*) = \\mathcal{N}(\\boldsymbol{\\mu}_*, \\boldsymbol{\\Sigma}_*)$，其均值向量为 $\\boldsymbol{\\mu}_*$，协方差矩阵为 $\\boldsymbol{\\Sigma}_*$。\n\n后验均值和协方差由以下公式给出：\n$$\n\\boldsymbol{\\mu}_* = K(X_*, X) [K(X, X) + \\sigma_n^2 I_N]^{-1} Y\n$$\n$$\n\\boldsymbol{\\Sigma}_* = K(X_*, X_*) - K(X_*, X) [K(X, X) + \\sigma_n^2 I_N]^{-1} K(X, X_*)\n$$\n其中：\n- $I_N$ 是 $N \\times N$ 的单位矩阵。\n- $K(X, X)$ 是训练输入的 $N \\times N$ 协方差矩阵，其元素为 $[K(X, X)]_{ij} = k(t_i, t_j)$。\n- $K(X, X_*)$ 是训练输入和查询输入之间的 $N \\times N_*$ 互协方差矩阵，其元素为 $[K(X, X_*)]_{ij} = k(t_i, t_{*j})$。\n- $K(X_*, X) = K(X, X_*)^T$。\n- $K(X_*, X_*)$ 是查询输入的 $N_* \\times N_*$ 协方差矩阵，其元素为 $[K(X_*, X_*)]_{ij} = k(t_{*i}, t_{*j})$。\n\n**2. 总能量的不确定性传播**\n\n在工作周期内消耗的总能量 $E$（单位：焦耳）通过黎曼和近似计算：\n$$\nE = \\sum_{j=1}^{N_*} f(t_{*j}) \\Delta t\n$$\n其中 $\\Delta t$ 是均匀时间间隔（单位：秒）。这是对函数值向量 $\\mathbf{f}_*$ 的一个线性变换：\n$$\nE = \\mathbf{w}^T \\mathbf{f}_* \\quad \\text{其中} \\quad \\mathbf{w} = [\\Delta t, \\Delta t, \\dots, \\Delta t]^T\n$$\n由于 $\\mathbf{f}_*$ 服从多元高斯分布，能量 $E$ 作为其分量的线性组合，也服从单变量高斯分布：$E \\sim \\mathcal{N}(\\mu_E, \\sigma_E^2)$。\n\n能量的均值和方差是利用随机变量线性变换的性质推导出来的：\n- **能量均值**：$\\mu_E = \\mathbb{E}[E] = \\mathbb{E}[\\mathbf{w}^T \\mathbf{f}_*] = \\mathbf{w}^T \\mathbb{E}[\\mathbf{f}_*] = \\mathbf{w}^T \\boldsymbol{\\mu}_*$。\n- **能量方差**：$\\sigma_E^2 = \\text{Var}(E) = \\text{Var}(\\mathbf{w}^T \\mathbf{f}_*) = \\mathbf{w}^T \\text{Var}(\\mathbf{f}_*) \\mathbf{w} = \\mathbf{w}^T \\boldsymbol{\\Sigma}_* \\mathbf{w}$。\n\n将 $\\boldsymbol{\\mu}_*$ 和 $\\boldsymbol{\\Sigma}_*$ 的表达式代入，我们就可以计算出总能量的均值和方差。\n\n**3. 置信区间计算**\n\n对于高斯随机变量 $E \\sim \\mathcal{N}(\\mu_E, \\sigma_E^2)$，其在水平 $1-\\alpha$ 上的双边中心置信区间由下式给出：\n$$\n[L, U] = [\\mu_E - z_{\\alpha/2} \\sigma_E, \\mu_E + z_{\\alpha/2} \\sigma_E]\n$$\n其中 $\\sigma_E = \\sqrt{\\sigma_E^2}$ 是标准差，$z_{\\alpha/2}$ 是标准正态分布的上 $\\alpha/2$ 临界值。对于指定的 $0.95$ 水平，我们有 $1-\\alpha = 0.95$，因此 $\\alpha = 0.05$。所需的临界值是 $z_{0.025}$，即标准正态分布的 $0.975$ 分位数，$z_{0.025} \\approx 1.95996$。\n\n因此，总能量 $E$ 的 $0.95$ 置信区间的下界 $L$ 和上界 $U$ 为：\n$$\nL = \\mu_E - z_{0.025} \\sigma_E\n$$\n$$\nU = \\mu_E + z_{0.025} \\sigma_E\n$$\n\n每个测试案例的计算流程如下：\n1.  定义训练数据 $X, Y$ 和超参数 $\\sigma_f^2, \\ell, \\sigma_n^2$。\n2.  预计算矩阵 $K_y = K(X, X) + \\sigma_n^2 I_N$ 和向量 $\\boldsymbol{\\alpha} = K_y^{-1} Y$。为了数值稳定性，通过求解线性系统 $K_y \\boldsymbol{\\alpha} = Y$ 来找到 $\\boldsymbol{\\alpha}$。\n3.  对于每个工作周期（由查询时间 $X_*$ 和时间步长 $\\Delta t$ 定义）：\n    a. 如果 $X_*$ 是空集，则能量 $E$ 为 $0$ 且不确定性为零，因此 $L=U=0$。\n    b. 否则，构建矩阵 $K(X, X_*)$ 和 $K(X_*, X_*)$。\n    c. 计算后验均值功率向量：$\\boldsymbol{\\mu}_* = K(X_*, X) \\boldsymbol{\\alpha}$。\n    d. 计算后验协方差功率矩阵：$\\boldsymbol{\\Sigma}_* = K(X_*, X_*) - K(X_*, X) K_y^{-1} K(X, X_*)$。为避免直接求逆，这也通过求解线性系统来计算。\n    e. 计算能量均值 $\\mu_E = \\Delta t \\sum_{j} (\\boldsymbol{\\mu}_*)_j$。\n    f. 计算能量方差 $\\sigma_E^2 = (\\Delta t)^2 \\sum_{i,j} (\\boldsymbol{\\Sigma}_*)_{ij}$。\n    g. 使用标准差 $\\sigma_E = \\sqrt{\\sigma_E^2}$ 和 $z_{0.025}$ 计算边界 $L$ 和 $U$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes the 95% credible interval for total energy consumption based on a\n    Gaussian Process Regression surrogate model of power.\n    \"\"\"\n    \n    # 1. Define GPR model parameters and training data\n    # Training inputs (time in seconds)\n    X_train = np.array([0., 2., 4., 6., 8.]).reshape(-1, 1)\n    \n    # Training outputs (power in Watts)\n    y_train = np.array([120.0, 135.0, 128.0, 140.0, 132.0]).reshape(-1, 1)\n    \n    # Hyperparameters\n    sigma_f_sq = 900.0  # Amplitude variance (Watts^2)\n    ell = 2.5          # Length-scale (seconds)\n    sigma_n_sq = 9.0   # Noise variance (Watts^2)\n    \n    # Test suite of operating cycles\n    test_cases = [\n        # Case 1: Happy path\n        (np.array([1., 2., 3., 4., 5., 6., 7., 8., 9.]), 1.0),\n        # Case 2: Boundary case (empty)\n        (np.array([]), 1.0),\n        # Case 3: Single-sample edge\n        (np.array([5.0]), 2.0),\n        # Case 4: Dense sampling edge\n        (np.arange(0.0, 8.01, 0.5), 0.5)\n    ]\n\n    def squared_exponential_kernel(xa, xb, sigma_f_sq_val, ell_val):\n        \"\"\"\n        Computes the squared-exponential kernel matrix between two sets of points.\n        Vectorized implementation for 1D inputs.\n        \"\"\"\n        # Broadcasting creates a matrix of pairwise differences (xa_i - xb_j)\n        # and then squares them.\n        sqdist = (xa - xb.T)**2\n        return sigma_f_sq_val * np.exp(-0.5 / ell_val**2 * sqdist)\n\n    # 2. Pre-computation for GPR posterior\n    # This part is independent of the query points and can be done once.\n    N = X_train.shape[0]\n    Ky = squared_exponential_kernel(X_train, X_train, sigma_f_sq, ell) + sigma_n_sq * np.eye(N)\n    \n    # For numerical stability, solve the linear system K_y * alpha = y_train\n    # instead of computing the inverse of K_y directly.\n    alpha = np.linalg.solve(Ky, y_train)\n\n    # 3. Process each test case\n    results = []\n    \n    # Get the z-score for the 95% confidence interval once.\n    # z such that P(-z  Z  z) = 0.95 for Z ~ N(0,1)\n    z_score = norm.ppf(0.975)\n\n    for X_query_vals, dt in test_cases:\n        # Handle the boundary case of an empty set of query times\n        if X_query_vals.size == 0:\n            results.append([0.0, 0.0])\n            continue\n\n        X_query = X_query_vals.reshape(-1, 1)\n        \n        # 4. GPR prediction at query points\n        K_star = squared_exponential_kernel(X_train, X_query, sigma_f_sq, ell)\n        K_star_star = squared_exponential_kernel(X_query, X_query, sigma_f_sq, ell)\n        \n        # Posterior mean of power at query points\n        mu_star = K_star.T @ alpha\n        \n        # Posterior covariance of power at query points\n        # Solve K_y * v = K_star to get v = (K_y^-1) * K_star\n        v = np.linalg.solve(Ky, K_star)\n        Sigma_star = K_star_star - K_star.T @ v\n\n        # 5. Uncertainty propagation for total energy\n        # Mean energy (Joules)\n        # E = sum(f(t_i) * dt) -> mu_E = sum(mu_star_i * dt)\n        mu_E = dt * np.sum(mu_star)\n\n        # Variance of energy (Joules^2)\n        # Var(E) = w^T * Sigma_star * w, where w is a vector of dt\n        # This simplifies to dt^2 * sum(all elements of Sigma_star)\n        var_E = dt**2 * np.sum(Sigma_star)\n        \n        # Handle potential small negative variance from numerical precision errors\n        if var_E  0:\n            var_E = 0.0\n        \n        sigma_E = np.sqrt(var_E)\n\n        # 6. Calculate the 95% credible interval\n        lower_bound = mu_E - z_score * sigma_E\n        upper_bound = mu_E + z_score * sigma_E\n        \n        results.append([lower_bound, upper_bound])\n\n    # 7. Format the final output string as specified\n    final_output_str = f\"[{','.join(map(str, results))}]\"\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}