{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any ethical Cyber-Physical System (CPS) is its safety and reliability. This practice explores how to quantify the risk of system failure, a critical step in adhering to principles like As Low As Reasonably Practicable (ALARP). By working through this problem , you will use the Beta-factor model to analyze how correlations in failure modes, known as Common Cause Failures, can undermine redundant designs and significantly impact overall system safety.",
            "id": "4220283",
            "problem": "A hospital deploys a Cyber-Physical System (CPS) for closed-loop drug delivery, with a Digital Twin continuously auditing sensor reliability for ethical risk management under the As Low As Reasonably Practicable (ALARP) principle. The CPS uses a dual-redundant sensing architecture where either sensor can provide the necessary measurement. Each sensor has a single-sensor failure probability over the mission time modeled as $p$. Audits of software updates and environmental stressors report the presence of Common Cause Failures (CCF), summarized by a common-cause factor $\\beta$, defined as the fraction of the single-sensor failure probability attributable to mechanisms that simultaneously incapacitate both redundant sensors. The remainder $(1 - \\beta)$ of $p$ is attributed to idiosyncratic, sensor-specific failure mechanisms.\n\nAssume:\n- The two sensors are statistically independent conditional on the absence of common-cause mechanisms.\n- Common-cause mechanisms and idiosyncratic mechanisms are mutually exclusive routes to failure over the mission time.\n- The mission-time failure probability $p$ is small enough that second-order terms can be treated as arising from independent idiosyncratic mechanisms without reweighting the single-sensor marginal beyond the leading-order decomposition described above.\n\nStarting from the law of total probability and the definitions above, derive the mixture expression for the system-level failure probability $P_f$ of the dual-redundant sensor network over the mission time, in terms of $\\beta$ and $p$, emphasizing how the common-cause and independent routes contribute. Then, for $p = 1.1 \\times 10^{-4}$ and $\\beta = 0.30$, compute the numerical value of $P_f$. Express the final probability as a decimal and round your answer to four significant figures. No units are required.",
            "solution": "The problem statement is first validated to ensure it is scientifically grounded, well-posed, objective, and complete.\n\n### Step 1: Extract Givens\n-   System architecture: Dual-redundant sensing, where either sensor is sufficient for operation. The system fails if and only if both sensors fail.\n-   Single-sensor failure probability: $p$.\n-   Common-cause factor: $\\beta$, defined as the fraction of $p$ attributable to mechanisms that simultaneously incapacitate both sensors.\n-   Idiosyncratic failure contribution: The fraction $(1 - \\beta)$ of $p$ is attributed to sensor-specific failure mechanisms.\n-   Assumption 1: The two sensors are statistically independent conditional on the absence of common-cause mechanisms.\n-   Assumption 2: Common-cause mechanisms and idiosyncratic mechanisms are mutually exclusive routes to failure.\n-   Assumption 3: $p$ is small, allowing second-order terms to be treated as arising from independent mechanisms without further correction.\n-   Numerical values: $p = 1.1 \\times 10^{-4}$ and $\\beta = 0.30$.\n-   Required output: Derive the expression for the system-level failure probability $P_f$ and compute its numerical value, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is valid. It employs the Beta-factor model, a standard and well-established method in reliability engineering for analyzing Common Cause Failures (CCF) in redundant systems. The context is scientifically appropriate, the terms are precisely defined, and the provided data and assumptions are self-contained and consistent. No scientific, logical, or structural flaws are present.\n\n### Step 3: Derivation and Solution\n\nLet $S_1$ and $S_2$ be the events that sensor $1$ and sensor $2$ fail over the mission time, respectively. The single-sensor failure probability is given as $P(S_1) = P(S_2) = p$. The system is dual-redundant, meaning it fails only if both sensors fail. The system-level failure event is therefore the intersection $S_1 \\cap S_2$, and its probability is $P_f = P(S_1 \\cap S_2)$.\n\nThe problem states that sensor failures can arise from two mutually exclusive routes: common-cause failures (CCF) and idiosyncratic, sensor-specific failures. We can therefore decompose the system failure probability based on these routes.\n\nLet $p_{cc}$ be the portion of the single-sensor failure probability attributable to common causes, and $p_{id}$ be the portion attributable to idiosyncratic causes. According to the problem's definition of $\\beta$:\n-   The probability that a single sensor fails due to a common cause is $p_{cc} = \\beta p$.\n-   The probability that a single sensor fails due to an idiosyncratic cause is $p_{id} = (1 - \\beta)p$.\n\nThe total failure probability of a single sensor is conserved: $p = p_{cc} + p_{id} = \\beta p + (1-\\beta)p$.\n\nThe total system failure probability, $P_f$, is the sum of the probabilities of system failure through the two mutually exclusive routes:\n1.  System failure due to a common-cause event.\n2.  System failure due to the simultaneous occurrence of independent idiosyncratic failures in both sensors.\n\nLet's analyze each route:\n\n**Route 1: Common-Cause Failure (CCF)**\nThe problem defines $\\beta$ with respect to \"mechanisms that simultaneously incapacitate both redundant sensors\". A common-cause failure event, by this definition, compromises the entire redundant pair. The probability of such an event occurring and causing a single sensor to fail is given as $\\beta p$. Since this event incapacitates both sensors, the probability of the system failing due to a common cause is precisely this value.\n$$P_{\\text{system failure | CCF}} = \\beta p$$\n\n**Route 2: Independent Idiosyncratic Failures (IDF)**\nFor the system to fail via this route, both sensors must fail due to their own independent, specific causes. The probability for a single sensor to fail idiosyncratically is $p_{id} = (1-\\beta)p$.\nGiven the assumption that these failures are statistically independent, the probability that *both* sensors fail idiosyncratically is the product of their individual idiosyncratic failure probabilities:\n$$P_{\\text{system failure | IDF}} = P(\\text{S1 fails idio.}) \\times P(\\text{S2 fails idio.})$$\n$$P_{\\text{system failure | IDF}} = p_{id} \\times p_{id} = ((1-\\beta)p)^2 = (1-\\beta)^2 p^2$$\n\nSince these two failure routes are mutually exclusive, the total system-level failure probability $P_f$ is the sum of their probabilities:\n$$P_f = P_{\\text{system failure | CCF}} + P_{\\text{system failure | IDF}}$$\n$$P_f = \\beta p + (1-\\beta)^2 p^2$$\nThis is the derived mixture expression for the system-level failure probability, emphasizing the linear contribution from common-cause failures and the quadratic contribution from independent failures.\n\nNow, we compute the numerical value of $P_f$ for the given parameters: $p = 1.1 \\times 10^{-4}$ and $\\beta = 0.30$.\n\nFirst, substitute the values into the derived expression:\n$$P_f = (0.30) \\times (1.1 \\times 10^{-4}) + (1 - 0.30)^2 \\times (1.1 \\times 10^{-4})^2$$\n\nCalculate the contribution from each term:\nThe common-cause failure term is:\n$$P_{\\text{CCF}} = 0.30 \\times 1.1 \\times 10^{-4} = 0.33 \\times 10^{-4} = 3.3 \\times 10^{-5}$$\n\nThe independent failure term is:\n$$(1 - 0.30)^2 = (0.70)^2 = 0.49$$\n$$(1.1 \\times 10^{-4})^2 = 1.21 \\times 10^{-8}$$\n$$P_{\\text{IDF}} = 0.49 \\times (1.21 \\times 10^{-8}) = 0.5929 \\times 10^{-8} = 5.929 \\times 10^{-9}$$\n\nSum the two contributions to find the total system failure probability:\n$$P_f = 3.3 \\times 10^{-5} + 5.929 \\times 10^{-9}$$\nTo add these, we can express them with the same power of $10$:\n$$P_f = 3.3 \\times 10^{-5} + 0.005929 \\times 10^{-5}$$\n$$P_f = (3.3 + 0.005929) \\times 10^{-5}$$\n$$P_f = 3.305929 \\times 10^{-5}$$\n\nThe problem requires the final answer to be expressed as a decimal rounded to four significant figures. The number is $3.305929 \\times 10^{-5}$. The first four significant figures are $3$, $3$, $0$, and $5$. The fifth significant digit is $9$, which is $5$ or greater, so we round up the fourth significant digit. The fourth digit, $5$, rounds up to $6$.\nThe rounded value is $3.306 \\times 10^{-5}$.\n\nExpressed as a decimal, this is:\n$$P_f \\approx 0.00003306$$",
            "answer": "$$\\boxed{0.00003306}$$"
        },
        {
            "introduction": "Beyond functioning correctly, a CPS must operate fairly, especially when it governs the allocation of critical resources. This exercise shifts our focus from system reliability to social impact, introducing a standard method for auditing algorithmic bias. This practice  provides a hands-on application of the disparate impact ratio, allowing you to translate raw operational data into a quantitative measure of fairness and assess compliance with well-established heuristics like the four-fifths rule.",
            "id": "4220340",
            "problem": "A city operates a Cyber-Physical System (CPS) for critical energy resilience that uses a Digital Twin (DT) to allocate real-time battery backup service tokens to households during grid stress events. To evaluate ethical fairness in service allocation, the city applies the disparate impact assessment drawn from the Equal Employment Opportunity Commission (EEOC) four-fifths rule, generalized to non-employment CPS resource provisioning.\n\nData aggregated over a stable operational window show two demographic groups: an unprivileged group $U$ and a privileged group $P$. The CPS processed $N_U$ applications from group $U$ and allocated tokens to $A_U$ applicants; it processed $N_P$ applications from group $P$ and allocated tokens to $A_P$ applicants. Over the period, the counts were $N_U = 950$, $A_U = 171$, $N_P = 800$, and $A_P = 184$.\n\nStarting from the frequentist interpretation of probability, the selection rate for any group is the ratio of allocated outcomes to total applicants. The disparate impact ratio is defined as the unprivileged group’s selection rate divided by the highest selection rate among the compared groups. Using this definition and the four-fifths ($0.8$) rule as the compliance heuristic, compute the disparate impact ratio from the provided counts and determine whether the allocation is compliant with the $0.8$ rule under this data.\n\nExpress your final answer as the disparate impact ratio in decimal form, rounded to four significant figures. Do not include any units. Provide no intermediate quantities in your final answer; only the disparate impact ratio itself should be reported.",
            "solution": "We begin from the frequentist interpretation of probability, where empirical rates are computed as counts of outcomes divided by counts of trials. For any group $G$, the selection rate $r_G$ is defined as the ratio of allocated cases to applicants:\n$r_G = \\frac{A_G}{N_G}.$\nUnder the disparate impact framework, the disparate impact ratio is defined as the unprivileged group’s selection rate divided by the highest selection rate among the compared groups. Let the unprivileged group be $U$ with selection rate $r_U$, and the privileged group be $P$ with selection rate $r_P$. Let\n$r_{\\max} = \\max\\{r_U, r_P\\}.$\nThen the disparate impact ratio $\\rho$ is\n$\\rho = \\frac{r_U}{r_{\\max}}.$\n\nWe first compute the selection rates using the given counts. For the unprivileged group $U$,\n$r_U = \\frac{A_U}{N_U} = \\frac{171}{950}.$\nWe check whether this fraction simplifies to a terminating decimal. Since $950 = 2 \\times 5^{2} \\times 19$, we can directly compute:\n$\\frac{171}{950} = 0.18.$\nFor the privileged group $P$,\n$r_P = \\frac{A_P}{N_P} = \\frac{184}{800}.$\nSince $800 = 2^{5} \\times 5^{2}$, we compute:\n$\\frac{184}{800} = 0.23.$\n\nNow we compute $r_{\\max}$:\n$r_{\\max} = \\max\\{0.18, 0.23\\} = 0.23.$\nTherefore,\n$\\rho = \\frac{r_U}{r_{\\max}} = \\frac{0.18}{0.23}.$\nWe express this ratio as an exact fraction first. Note that $0.18 = \\frac{18}{100}$ and $0.23 = \\frac{23}{100}$, so\n$\\rho = \\frac{\\frac{18}{100}}{\\frac{23}{100}} = \\frac{18}{23}.$\nCompute the decimal expansion:\n$\\frac{18}{23} \\approx 0.7826086956\\ldots$\nRounding $\\rho$ to four significant figures yields:\n$\\rho \\approx 0.7826.$\n\nTo test compliance with the four-fifths rule, compare $\\rho$ with $0.8$:\n$0.7826  0.8,$\nwhich indicates non-compliance under the $0.8$ rule for these counts. The problem requests the final answer to be the disparate impact ratio only, rounded to four significant figures. Hence, we report $0.7826$.",
            "answer": "$$\\boxed{0.7826}$$"
        },
        {
            "introduction": "A reliable and fair CPS can still be compromised if it is not secure, making security a cornerstone of trustworthiness. This final practice addresses the threat of malicious attacks by focusing on formal verification of system resilience against a common vulnerability: the replay attack. In this exercise , you will derive a precise, mathematical criterion that guarantees security, learning how to connect design parameters like nonce cache sizes and timing windows to a provable security property.",
            "id": "4220309",
            "problem": "You are given a formal security model for a cyber-physical system command channel as used in a digital twin controlling a physical actuator. Commands are issued by a trusted controller and received by an actuator. Each command carries a timestamp $t_s$ (in $\\mathrm{ms}$) and a unique nonce $n$ generated uniformly at random and never reused by the controller. The actuator maintains a finite cache of the most recently seen nonces of capacity $M$ entries, evicting the oldest nonce upon overflow using First-In-First-Out (FIFO). The actuator’s acceptance logic uses three checks: secure timestamping, nonce freshness, and control-delay safety.\n\nThe environment assumptions are:\n\n- Bounded delay: the one-way network delay is bounded above by $\\Delta_{\\max}$ (in $\\mathrm{ms}$). The attacker can replay any previously observed packet but cannot modify its fields. The attacker is constrained by the same network bound.\n- Bounded clock skew: the difference between the receiver’s local clock and the sender’s clock is bounded by $|\\epsilon| \\le \\Sigma$ (in $\\mathrm{ms}$), guaranteed by secure time synchronization.\n- Command rate: legitimate commands are issued at a constant rate $r$ (in $\\mathrm{messages}/\\mathrm{ms}$), each with a fresh nonce.\n\nThe actuator executes a command if and only if all of the following hold at receipt time:\n\n- Timestamp freshness: $t_{\\text{now,local}} - t_s \\le W$, where $W$ (in $\\mathrm{ms}$) is the configured freshness window.\n- Nonce freshness: $n$ is not in the nonce cache.\n- Control-delay safety: to guarantee real-time safety despite skew, the actuator enforces $t_{\\text{now,local}} - t_s \\le D_{\\text{safe}} - \\Sigma$, where $D_{\\text{safe}}$ (in $\\mathrm{ms}$) is the maximum allowable real delay for safe control action.\n\nA replay attack succeeds if a previously accepted command is executed again upon replay. To analyze worst-case acceptance under skew, use the well-tested fact that if $|\\epsilon| \\le \\Sigma$, then acceptance based on the local condition $t_{\\text{now,local}} - t_s \\le W$ implies the real age satisfies $t_{\\text{now,real}} - t_{s,\\text{real}} \\le W + \\Sigma$.\n\nStarting only from the above fundamental definitions and facts, derive a criterion that is both necessary and sufficient under these assumptions to prevent any replayed command from being executed. Your derivation must be expressed in terms of the parameters $W$, $\\Sigma$, $D_{\\text{safe}}$, $r$, and $M$, all in consistent units as specified. Then, implement a program that, for each parameter set in the test suite, decides whether the system is replay-resilient (output $True$) or not (output $False$) according to your derived criterion.\n\nUse the following test suite. All times are in $\\mathrm{ms}$, and $r$ is in $\\mathrm{messages}/\\mathrm{ms}$:\n\n- Test $1$ (happy path): $(W, \\Sigma, D_{\\text{safe}}, r, M) = (100, 5, 80, 0.1, 10)$.\n- Test $2$ (boundary equality): $(W, \\Sigma, D_{\\text{safe}}, r, M) = (100, 5, 80, 0.1, 8)$.\n- Test $3$ (long window, insufficient cache): $(W, \\Sigma, D_{\\text{safe}}, r, M) = (1000, 10, 900, 0.2, 128)$.\n- Test $4$ (small control horizon clamps window): $(W, \\Sigma, D_{\\text{safe}}, r, M) = (1000, 10, 50, 0.2, 11)$.\n- Test $5$ (large skew, edge capacity): $(W, \\Sigma, D_{\\text{safe}}, r, M) = (30, 30, 100, 0.05, 3)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[True,False,True,False,True]$).\n\nNote: The one-way network delay bound $\\Delta_{\\max}$ is part of the environment description but does not appear as an input parameter in the test suite, because the acceptance logic above already internalizes a worst-case margin for skew and delay via $W$ and $D_{\\text{safe}}$. Express all intermediate reasoning in $\\mathrm{ms}$ and $\\mathrm{messages}/\\mathrm{ms}$ and ensure dimensional consistency.",
            "solution": "The objective is to derive a necessary and sufficient criterion to prevent a replayed command from being executed by the actuator. A replay attack succeeds if a command packet, having been accepted once, is accepted a second time upon being replayed by an adversary. The system is replay-resilient if and only if for any command packet that has been accepted, every subsequent replay of that same packet is rejected.\n\nA command packet is defined by its timestamp $t_s$ and nonce $n$. For a packet to be accepted at a local time $t_{\\text{now,local}}$, it must simultaneously satisfy three conditions:\n1.  Timestamp freshness: $t_{\\text{now,local}} - t_s \\le W$\n2.  Nonce freshness: the nonce $n$ is not in the actuator's cache.\n3.  Control-delay safety: $t_{\\text{now,local}} - t_s \\le D_{\\text{safe}} - \\Sigma$\n\nCombining the first and third conditions, a packet is accepted only if the observed time difference $t_{\\text{now,local}} - t_s$ is less than or equal to both $W$ and $D_{\\text{safe}} - \\Sigma$. We can define an effective acceptance window, $W_{\\text{eff}}$, that captures the most restrictive of these two a priori constraints:\n$$\nW_{\\text{eff}} = \\min(W, D_{\\text{safe}} - \\Sigma)\n$$\nThus, the time-based acceptance condition simplifies to $t_{\\text{now,local}} - t_s \\le W_{\\text{eff}}$.\n\nA replay attack involves two acceptance events for the same packet $(t_s, n)$. Let the first, legitimate acceptance occur at real time $T_1$ and the second, replayed acceptance occur at real time $T_2$, where $T_2 > T_1$. For the attack to succeed, the packet must pass all checks at both times. Specifically, at $T_2$, the timestamp check must pass, but the nonce check must fail for the attacker. That is, at $T_2$, the nonce $n$ (which was added to the cache at $T_1$) must no longer be in the cache.\n\nTo analyze the timing, we must work in a common frame of reference, which is real time. The problem provides a critical bridge between the local clock check and real time: an acceptance based on $t_{\\text{now,local}} - t_s \\le W_{\\text{eff}}$ implies that the real age of the packet, $T_{\\text{accept}} - T_s$, satisfies $T_{\\text{accept}} - T_s \\le W_{\\text{eff}} + \\Sigma$, where $T_s$ is the real time of sending.\n\nThis defines a real-time window of vulnerability. A packet sent at real time $T_s$ can be accepted at any real time $T_{\\text{accept}}$ such that $T_s \\le T_{\\text{accept}} \\le T_s + W_{\\text{eff}} + \\Sigma$. The lower bound $T_s$ is due to causality (the packet cannot arrive before it is sent), and the upper bound is derived from the acceptance logic. The total duration of this real-time vulnerability window, $T_{\\text{vulnerable}}$, is the difference between the latest and earliest possible acceptance times:\n$$\nT_{\\text{vulnerable}} = (T_s + W_{\\text{eff}} + \\Sigma) - T_s = W_{\\text{eff}} + \\Sigma\n$$\nAn attacker can succeed only if they can find two acceptance times, $T_1$ and $T_2$, within this window such that the nonce has been evicted by time $T_2$.\n\nThe defense against replay is the nonce cache. When a command is accepted at time $T_1$, its nonce $n$ is added to the FIFO cache of size $M$. This nonce will be evicted once $M$ new, legitimate commands have been accepted. Since legitimate commands are issued at a constant rate of $r$ messages per millisecond, the real time required to issue (and subsequently accept) $M$ new commands is $M/r$. This duration is the real-time residency of the nonce in the cache, $T_{\\text{cache}}$:\n$$\nT_{\\text{cache}} = \\frac{M}{r}\n$$\n\nFor the system to be resilient, the nonce must be guaranteed to remain in the cache throughout the entire real-time window of vulnerability. If an attacker replays the packet at any time $T_2$ within the window, the nonce check ($n$ is not in cache) must fail. This is guaranteed if and only if the cache residency time is strictly greater than the duration of the vulnerability window. If they were equal, an attacker could time the replay to arrive at the exact moment the nonce is evicted, and the check \"is not in the cache\" would pass.\n\nTherefore, the necessary and sufficient condition for replay resilience is:\n$$\nT_{\\text{cache}}  T_{\\text{vulnerable}}\n$$\nSubstituting the expressions for these durations, we get:\n$$\n\\frac{M}{r}  W_{\\text{eff}} + \\Sigma\n$$\nSubstituting the definition of $W_{\\text{eff}}$ gives the final criterion in terms of the input parameters:\n$$\n\\frac{M}{r}  \\min(W, D_{\\text{safe}} - \\Sigma) + \\Sigma\n$$\nThis inequality is equivalent to $M  r \\cdot (\\min(W, D_{\\text{safe}} - \\Sigma) + \\Sigma)$. The system is considered replay-resilient if and only if this condition holds. If $D_{\\text{safe}} - \\Sigma \\le 0$, the effective window $W_{\\text{eff}}$ may be non-positive, but the logic remains sound. A non-positive $W_{\\text{eff}}$ severely restricts or prevents acceptance, but the formal criterion still correctly determines resilience.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not used.\n\ndef solve():\n    \"\"\"\n    Solves the cyber-physical system replay resilience problem for a suite of test cases.\n    \"\"\"\n    \n    # Test suite from the problem statement.\n    # Each tuple is (W, Sigma, D_safe, r, M).\n    test_cases = [\n        (100, 5, 80, 0.1, 10),      # Test 1\n        (100, 5, 80, 0.1, 8),       # Test 2\n        (1000, 10, 900, 0.2, 128),   # Test 3\n        (1000, 10, 50, 0.2, 11),     # Test 4\n        (30, 30, 100, 0.05, 3),      # Test 5\n    ]\n\n    results = []\n    for case in test_cases:\n        W, Sigma, D_safe, r, M = case\n\n        # The system is replay-resilient if and only if the following strict inequality holds:\n        # M  r * (min(W, D_safe - Sigma) + Sigma)\n        #\n        # Derivation:\n        # 1. The effective acceptance window based on local clock checks is\n        #    W_eff = min(W, D_safe - Sigma).\n        # 2. Based on the problem's fact about clock skew, the real-time vulnerability\n        #    window duration is T_vulnerable = W_eff + Sigma. This is the maximum\n        #    real-time span between the earliest and latest possible acceptance of a packet.\n        # 3. The real-time residency of a nonce in the FIFO cache of size M, with a\n        #    command rate of r, is T_cache = M / r.\n        # 4. For security, the nonce must remain in the cache longer than the packet is\n        #    vulnerable to acceptance. This requires a strict inequality to prevent\n        #    attacks at the boundary moment of eviction.\n        #    T_cache  T_vulnerable  =  M / r  W_eff + Sigma.\n        #    This is equivalent to M  r * (W_eff + Sigma).\n        \n        # Calculate the effective acceptance window in ms.\n        w_eff = min(W, D_safe - Sigma)\n        \n        # Calculate the right-hand side of the inequality. This represents the minimum\n        # number of cache slots required to outlast the vulnerability window.\n        required_cache_slots = r * (w_eff + Sigma)\n        \n        # Check if the available cache capacity M is strictly greater than the required capacity.\n        is_resilient = M  required_cache_slots\n        \n        results.append(is_resilient)\n\n    # Format the final output as a comma-separated list in brackets.\n    # The boolean values True/False must be capitalized as per Python's str() conversion.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}