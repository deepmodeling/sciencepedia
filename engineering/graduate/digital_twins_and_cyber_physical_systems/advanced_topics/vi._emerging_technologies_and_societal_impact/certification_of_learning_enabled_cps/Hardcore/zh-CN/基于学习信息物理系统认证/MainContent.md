## 引言
随着机器学习技术，特别是深度学习的崛起，含学习组件的信息物理系统（LE-CPS）正被广泛应用于自动驾驶、智能机器人和医疗设备等安全关键领域。这些系统通过与物理世界交互并从中学习，展现出前所未有的性能与适应性。然而，其核心学习组件的复杂性、[非线性](@entry_id:637147)和[数据依赖](@entry_id:748197)性也带来了巨大的挑战：我们如何才能信任这些系统，并权威地证明它们在所有操作条件下都是安全的？传统的软件认证方法难以应对这种动态和不确定性，亟需一个专为LE-CPS设计的、严谨的保证与认证框架。

本文旨在系统性地阐述为LE-CPS建立置信度的核心理论与实践。我们将引导读者穿越从形式化理论到工程应用的完整路径，构建一个关于如何认证这些复杂智能系统的全面理解。

*   在 **“原理与机制”** 一章中，我们将奠定理论基石，介绍如何用数学语言精确定义“安全”，并探讨一系列用于在设计时和运行时提供安全保证的核心技术，如[控制屏障函数](@entry_id:177928)与运行时保证架构。
*   接下来，在 **“应用与交叉学科联系”** 一章中，我们将展示这些理论如何在控制理论、形式化方法和机器学习等多个学科的交叉点上，解决自动驾驶和机器人技术等领域的实际问题。
*   最后，通过 **“动手实践”** 部分，读者将有机会亲手应用关键的验证与分析技术，将理论知识转化为可操作的技能。

通过本次学习，您将掌握为下一代智能系统构建可信[安全保证](@entry_id:1131169)的关键方法论。让我们从理解LE-[CPS认证](@entry_id:1122213)的基本原理开始。

## 原理与机制

本章旨在阐述为含学习组件的信息物理系统（LE-CPS）建立[置信度](@entry_id:267904)的核心原理与关键机制。我们将从系统的形式化定义出发，探讨如何精确描述安全需求，并介绍一系列用于在设计时和运行时提供[安全保证](@entry_id:1131169)的先进技术。这些机制共同构成了 LE-CPS 认证的基石。

### LE-CPS 的保证问题：定义与核心概念

为 LE-CPS 设计认证框架的第一步，是建立一个能够精确描述其混合动态特性的数学模型。一个典型的 LE-CPS 包含连续演化的物理对象和离散决策的计算组件。

我们可以将物理对象（或称**被控对象**）的动态行为建模为一个常微分方程。设物理状态为 $x(t) \in \mathbb{R}^{n}$，控制输入为 $u(t) \in \mathbb{R}^{m}$，同时系统受到来自外部环境的扰动信号 $w(t) \in \mathbb{R}^{p}$。一个常见的模型是**[控制仿射系统](@entry_id:168741)**：
$$
\dot{x}(t) = f(x(t)) + B u(t) + w(t)
$$
其中，$f: \mathbb{R}^{n} \to \mathbb{R}^{n}$ 描述了系统的内部动态，$B \in \mathbb{R}^{n \times m}$ 是控制输入矩阵。系统的可测量输出 $y(t) \in \mathbb{R}^{\ell}$ 通过观测函数 $y(t) = h(x(t))$ 获得。

与之交互的计算组件（或称**赛博组件**）通常以离散时间的方式运行。在采样时刻 $t_k = k T_s$（其中 $T_s$ 是采样周期），控制器根据其内部状态 $x_c(k)$、系统测量输出 $y(t_k)$ 以及任务参考 $r(t_k)$ 来更新其状态和决策。当引入学习模块时，其参数 $\theta(k) \in \mathbb{R}^{d}$ 也会在这些时刻进行在线更新。例如，参数更新可能遵循[梯度下降](@entry_id:145942)规则：
$$
\theta(k+1) = \theta(k) - \alpha \nabla_{\theta} \mathcal{L}(\theta(k); \mathcal{D}_{k})
$$
其中 $\mathcal{L}$ 是一个损失函数，$\mathcal{D}_{k}$ 是用于更新的数据集。在两个采样时刻之间，即 $t \in [t_k, t_{k+1})$，控制输入 $u(t)$ 通常由[零阶保持器](@entry_id:264751)保持恒定，其值由当前周期的决策决定：$u(t) = g(x_{c}(k), y(t), r(t), \theta(k))$。

这种连续动态（“流”）与离散更新（“跳”）的相互作用，是典型的**混合系统**（Hybrid System）模型。系统与环境的所有交互都受到**接口规约**（Interface Contract） $\mathcal{I}$ 的约束，该规约定义了信号的允许范围、时序限制和不确定性边界（例如，传感器噪声界、[执行器饱和](@entry_id:274581)、通信延迟等）。此外，一个高保真的**[数字孪生](@entry_id:171650)**（Digital Twin）模型通常被用于仿真、[数据增强](@entry_id:266029)和支持学习过程 。

在此模型基础上，对 LE-CPS 的保证活动可以分为三个既有区别又相互关联的核心过程：

1.  **验证（Verification）**：回答“我们是否正确地构建了系统？”（Are we building the system right?）。这是一个数学和逻辑过程，旨在严格证明一个系统实现或模型 $M$ 在给定的假设（例如接口规约 $\mathcal{I}$）下，满足其形式化规约 $\varphi$，记为 $M \models \varphi$。验证所依赖的证据是分析性的，例如[数学证明](@entry_id:137161)、[模型检测](@entry_id:150498)、[静态分析](@entry_id:755368)和[形式逻辑](@entry_id:263078)。

2.  **确认（Validation）**：回答“我们是否构建了正确的系统？”（Are we building the right system?）。这是一个经验和实验过程，旨在评估系统及其模型是否适用于其在真实操作环境中的预期用途。确认通过将模型预测与物理世界的测量数据进行比较，量化模型保真度和系统性能来实现。其证据是经验性的，包括物理实验、统计分析和与[数字孪生](@entry_id:171650)的交叉检验。

3.  **认证（Certification）**：这是一个权威性的符合性评定过程。它通常由一个独立第三方机构进行，[证明系统](@entry_id:156272)满足其应用领域（如航空、医疗设备）的所有适用标准、法规和法律要求。认证的依据是一套完整的**保证证据包**（Assurance Case），它必须系统地整合验证证据、确认结果、[危害与风险](@entry_id:926564)分析、以及对标准的符合性评估报告 。

### 形式化规约：定义“安全”

为实现严格的认证，系统的期望行为，特别是安全需求，必须被转化为无歧义的**形式化规约**（Formal Specifications）。这些规约定义了系统在任何时候都不能违反的规则。

最基本的属性类型是**安全属性**（Safety Properties）和**活性属性**（Liveness Properties）。

-   **安全属性**断言“坏事永远不会发生”（nothing bad ever happens）。任何违反安全属性的行为都可以通过一个有限的执行轨迹来发现。例如，对于一个[自动驾驶](@entry_id:270800)车辆的换道辅助系统，一个关键的安全属性是车辆永远不会偏离其所在车道。更精确地说，车辆的横向位置 $y(t)$ 与车道中心线 $y_c(t)$ 之间的偏差，在任何时候都必须小于车道半宽 $w$ 减去一个安全裕度 $\delta$，即 $|y(t) - y_c(t)| \le w - \delta$。

-   **活性属性**断言“好事最终会发生”（something good eventually happens）。活性属性的违反只有在无限长的执行中才能被确定（即系统永远不进入“好”状态）。对于上述换道辅助系统，一个典型的活性属性是车辆最终会回到靠近车道中心线的位置。一个更强的、适用于持续运行系统的活性属性是，车辆会**无限次地**回到中心线附近。

这些属性可以使用**时序逻辑**（Temporal Logics）进行精确表述。例如，**线性[时序逻辑](@entry_id:181558)（LTL）** 使用 $\mathbf{G}$（总是）和 $\mathbf{F}$（最终）等算子。对于处理连续信号的 CPS，**[信号时序逻辑](@entry_id:1131627)（STL）** 更为适合，它允许在逻辑公式中加入对时间和信号值的量化约束。

以前述换道[辅助系统](@entry_id:142219)为例，使用原子命题 $p_{\mathrm{in}}(t) : |y(t)-y_c(t)| \le w - \delta$（在安全裕度内）和 $p_{\mathrm{goal}}(t) : |y(t)-y_c(t)| \le \epsilon$（在目标容差内），我们可以形式化地表达属性：

-   **安全性（[不变性](@entry_id:140168)）**：车辆始终保持在车道安全裕度内。
    -   LTL: $\mathbf{G}(p_{\mathrm{in}})$
    -   STL: $\mathbf{G}_{[0, \infty)}(|y(t) - y_c(t)| \le w - \delta)$

-   **活性（循环到达）**：车辆总是能在有限时间（如 $\tau$ 秒）内回到目标区域。
    -   LTL: $\mathbf{G}\mathbf{F}(p_{\mathrm{goal}})$
    -   STL: $\mathbf{G}_{[0, \infty)} \mathbf{F}_{[0, \tau]} (|y(t) - y_c(t)| \le \epsilon)$

除了这些基本属性，更复杂的**到达-规避**（Reach-Avoid）属性在 CPS 中也很常见。它要求系统在到达一个目标区域的同时，必须始终规避一个不安全区域。例如，要求车辆在回到车道中心（到达 $p_{\mathrm{goal}}$）的过程中，始终不能越过车道边界（规避 $|y(t)-y_c(t)| \ge w$）。在 LTL 中，这可以用“Until”算子 $\mathbf{U}$ 表达为 $(\neg p_{\mathrm{bad}}) \mathbf{U} (p_{\mathrm{goal}})$ 。

### 定义操作环境：ODD 与覆盖率

LE-CPS 的[安全保证](@entry_id:1131169)通常不是无条件的，而是限定在一个明确的操作范围内。这个范围被称为**操作设计域**（Operational Design Domain, ODD）。ODD 详细说明了系统设计意图在其中安全运行的各种条件，例如天气状况、光照水平、道路类型、交通密度等。

为了进行系统化的测试和验证，ODD 需要被形式化为一个场景空间。这个空间通常是混合的，包含离散和连续的因素。例如，天气可以被建模为一个[离散集](@entry_id:146023)合 $\mathcal{D} = \{\text{晴天, 雨天, 雪天}\}$，而对于每一种天气 $d \in \mathcal{D}$，相关的连续因素（如车速、道路曲率）则构成一个连续子空间 $\mathcal{C}_d \subseteq \mathbb{R}^m$。整个场景空间可以表示为 $\mathcal{X} = \bigcup_{d \in \mathcal{D}} ( \{d\} \times \mathcal{C}_d )$。

在[数字孪生](@entry_id:171650)中生成测试场景时，一个关键问题是如何衡量测试集对 ODD 的**覆盖率**。一个严谨的覆盖率度量需要能够同时处理离散和连续的维度。我们可以基于[测度论](@entry_id:139744)来构建这样一个度量。首先，为每个离散类别 $d \in \mathcal{D}$ 分配一个非负权重 $w(d)$，反映其重要性或发生频率。然后，对于每个类别内的连续空间 $\mathcal{C}_d$，我们使用**[勒贝格测度](@entry_id:139781)**（Lebesgue measure）$\lambda$ 来衡量其“体积”。

给定一个测试集 $\mathcal{T} \subseteq \text{ODD}$ 和一个分辨[率参数](@entry_id:265473) $r > 0$，我们可以定义覆盖率为：
$$
\text{Cov}(\mathcal{T}, r) = \frac{\sum_{d \in \mathcal{D}} w(d) \cdot \lambda \left( \left( \bigcup_{x \in \mathcal{T}_d} B_r(x) \right) \cap \text{ODD}_d \right)}{\sum_{d \in \mathcal{D}} w(d) \cdot \lambda(\text{ODD}_d)}
$$
这里，$\mathcal{T}_d$ 是[测试集](@entry_id:637546)中属于类别 $d$ 的所有连续向量的集合，$\text{ODD}_d$ 是 ODD 中属于类别 $d$ 的连续子空间，$B_r(x)$ 是以测试点 $x$ 为中心、半径为 $r$ 的球。这个度量的直观含义是：它计算了测试点周围 $r$-邻域所覆盖的 ODD 体积，并根据离散类别的权重进行加权平均。这种度量是归一化的（在 $[0,1]$ 区间内）、单调的，并且对离散和连续因素都敏感，为评估测试的完备性提供了量化依据 。

### 保证策略：架构与方法论

为 LE-CPS 提供安全保证，可以采取多种策略，这些策略在实施时间（设计时 vs. 运行时）和[系统架构](@entry_id:1132820)上有所不同。

#### 设计时保证 vs. 运行时保证

从实施时间的角度，保证活动可分为**离线验证**（Offline Verification）和**[运行时监控](@entry_id:1131150)**（Runtime Monitoring）。

-   **离线验证**在系统部署前于设计阶段进行，通常利用系统的形式化模型（如[数字孪生](@entry_id:171650)）。通过**[可达性](@entry_id:271693)分析**等技术，对模型在所有可能的不确定性（参数 $\Theta$）下进行**穷尽式**的分析。如果采用**稳健的过近似**（Sound Over-approximation）方法，即计算出的[可达集](@entry_id:276191)总是包含真实系统的所有可能轨迹，那么离线验证可以提供极强的[安全保证](@entry_id:1131169)：如果模型被验证为安全，那么真实系统也是安全的。这意味着其**[假阴性率](@entry_id:911094)**（False Negative Rate, $\beta$），即系统不安全但被误报为安全的概率，理想情况下为零。然而，过近似可能导致**假阳性**（False Positives, $\alpha$），即一个本身安全的系统因为近似过于保守而被报告为不安全。

-   **[运行时监控](@entry_id:1131150)**在系统实际运行时进行，直接观测系统行为。它通过传感器获取数据，并检查其是否符合安全规约。由于传感器存在噪声、模型存在[未建模动态](@entry_id:264781)（如突发阵风），[运行时监控](@entry_id:1131150)不可避免地会面临错误决策的风险。它可能因为噪声而发出虚警（增加 $\alpha$），也可能因为观测不全面或响应延迟而错过真正的违规（导致 $\beta > 0$）。

这两种方法并非相互竞争，而是高度互补的。离线验证为系统在 ODD 内的行为提供了坚实的设计时保证，构成了安全认证的核心证据。[运行时监控](@entry_id:1131150)则作为一道重要的防线，用于处理模型未覆盖的**残余风险**和超出 ODD 的**分布外**（Out-of-Distribution）事件，提供关键的[运行时保障](@entry_id:1131148) 。

#### 架构选择：模块化 vs. 端到端

从[系统架构](@entry_id:1132820)的角度，LE-CPS 的设计对可认证性有深远影响。主要有两种范式：**模块化架构**和**端到端架构**。

-   **模块化架构**将复杂的感知到控制流程分解为多个独立的模块，例如一个感知模块和一个控制模块。这种分解允许我们定义清晰的**接口规约**，并采用**组合式验证**（Compositional Verification）的策略。例如，我们可以为感知模块提供一个认证，保证其输出的[估计误差](@entry_id:263890)在 $\epsilon$ 界限内。然后，我们可以独立地为控制模块提供认证，证明其在输入误差小于 $\epsilon$ 的**假设**下能够保证系统安全。当这两个模块组合时，感知模块的**保证**满足了控制模块的**假设**，从而可以通过“分而治之”的方式推导出整个系统的[安全保证](@entry_id:1131169)。这种基于**假设-保证**（Assume-Guarantee）的推理是认证复杂系统的强大工具 , 。

-   **端到端架构**则使用一个单一的、通常是大型神经网络的策略 $\pi$，直接将原始传感器[数据映射](@entry_id:895128)到控制指令。这种架构可能在性能上表现更优，但其内部缺乏明确的[中间表示](@entry_id:750746)，使得组合式验证变得困难。它的“黑箱”特性给形式化分析带来了巨大挑战。

尽管[端到端模型](@entry_id:167365)难以进行组合式分析，但我们仍有方法为其提供安全保证。例如，可以采用基于**增益分析**的[鲁棒控制](@entry_id:260994)方法。如果系统的开环动态具有良好的稳定性（如增量输入到状态稳定，$\delta$-ISS），并且我们能知道端到端策略的**[利普希茨常数](@entry_id:146583)**（Lipschitz constant），那么就有可能推导出从[传感器噪声](@entry_id:1131486)到系统状态偏差的[闭环增益](@entry_id:275610)界。通过证明在最坏情况下，噪声引起的偏差也不会使系统离开安[全集](@entry_id:264200)，我们依然可以获得形式化的安全证书 。

在进行组合式验证时，必须确保对学习组件不确定性行为的建模是**过近似**的。如果接口规约**低估**了学习组件可能产生的行为（即是一个**欠近似**），那么即使每个模块在各自的（错误的）假设下都被验证为安全，组合后的整个系统也可能因为那些未被考虑的行为而变得不安全，导致整个验证过程的**不健全性**（Unsoundness）。

### 关键保证机制

本节将深入探讨几种实现 LE-CPS [安全保证](@entry_id:1131169)的关键技术机制，涵盖设计时分析、运行时干预和数据驱动方法。

#### 设计时验证机制

设计时验证的核心目标是在系统部署前，通过数学方法证明其在模型层面上的安全性。

**[控制屏障函数](@entry_id:177928) (Control Barrier Functions, CBF)**

CBF 是一种功能强大的工具，用于设计和验证能确保系统状态**[前向不变性](@entry_id:170094)**（Forward Invariance）的控制器，即一旦系统进入一个安全集 $S$，它将永远不会离开。

考虑一个由 $S = \{ x \in \mathbb{R}^n : B(x) \ge 0 \}$ 定义的安[全集](@entry_id:264200)，其中 $B(x)$ 是一个连续可微的函数。$B(x)$ 被称为一个**[控制屏障函数](@entry_id:177928)**，如果存在一个扩展类 $\mathcal{K}$ 函数 $\alpha$（即 $\alpha$ 是连续、严格递增且 $\alpha(0)=0$ 的函数），使得对于安[全集](@entry_id:264200) $S$ 内的所有状态 $x$，都存在一个允许的控制输入 $u \in U$，满足以下条件：
$$
\dot{B}(x) + \alpha(B(x)) \ge 0
$$
其中 $\dot{B}(x) = \nabla B(x)^\top \dot{x} = L_f B(x) + L_g B(x) u$ 是 $B(x)$ 沿着系统轨线的[李导数](@entry_id:171745)。这个条件直观地意味着：
-   在安[全集](@entry_id:264200)的边界上（$B(x)=0$），$\dot{B}(x) \ge 0$，即系统的[速度矢量](@entry_id:269648)必须指向安全集的内部或与其相切，从而阻止状态穿越边界。
-   在安[全集](@entry_id:264200)的内部（$B(x)>0$），该条件允许 $B(x)$ 在一定程度上减小，但其减小的速率受到了 $-\alpha(B(x))$ 的限制。

只要存在一个 CBF，我们就可以通过求解一个二次规划（QP）来实时合成一个既能保证安全、又尽可能接近期望性能输入的控制器。CBF 为模型驱动的安全性设计与验证提供了一个可操作的框架 。

**反向可达性分析 (Backward Reachability Analysis)**

当系统面临来自环境或[模型不确定性](@entry_id:265539)的[对抗性扰动](@entry_id:746324)时，我们需要一个更强大的工具来回答：“是否存在一个控制策略，能在**所有**可能的扰动下都保证安全？”**反向可达性分析**，特别是源于**[微分](@entry_id:158422)对策**（Differential Games）理论的方法，为此提供了答案。

其核心思想是，从一个不安全的目标集 $U$ 出发，反向计算所有可能在未来某个时刻被**不可避免地**驱动进入 $U$ 的状态集合。这个集合被称为不安[全集](@entry_id:264200) $U$ 的**反向[可达集](@entry_id:276191)**（Backward Reachable Set）。

形式上，对于一个时间范围 $[0, T]$，反向[可达集](@entry_id:276191) $B_T(U)$ 定义为：
$$
B_T(U) := \left\{ x_0 \mid \forall \text{控制策略 } u(\cdot), \exists \text{扰动 } w(\cdot) \text{ 使得轨迹在 } t \in [0,T] \text{ 的某时刻进入 } U \right\}
$$
这个[集合的补集](@entry_id:146296) $\mathbb{R}^n \setminus B_T(U)$ 则是由所有“可保安全”的状态组成的。对于任何一个从该[补集](@entry_id:161099)出发的初始状态，都存在一个“获胜”的控制策略，能够确保系统在 $[0, T]$ 时间内始终规避不安[全集](@entry_id:264200) $U$，无论扰动如何。

将时间范围扩展到无限，我们可以定义无限时间的反向[可达集](@entry_id:276191) $B_\infty(U) = \bigcup_{T>0} B_T(U)$。其[补集](@entry_id:161099) $\mathbb{R}^n \setminus B_\infty(U)$ 是**最大的鲁棒受控不变子集**（Largest Robust Controlled-Invariant Subset），即在该集合内，存在一个控制策略可以永远保证系统的安全 。反向[可达性](@entry_id:271693)分析为最坏情况下的安全综合与验证提供了理论基础。

#### 运行时保证机制

运行时保证机制通过在系统运行时进行监控和干预，作为最后一道安全防线。

**运行时保证架构 (Runtime Assurance, RTA)**

RTA 架构，有时也称为 **Simplex 架构**，是一种经典的运行时安全机制。它包含两个控制器：
-   一个高性能、可能基于学习的**先进控制器 (AC)**，负责优化系统性能。
-   一个经过形式化验证、可能性能较差但安全性有保障的**基线控制器 (BC)**。

其核心思想是在每个决策时刻，预测性地判断 AC 的行为是否安全。如果不安全，则切换到 BC。一个基于**[集合论](@entry_id:137783)可达性**的切换逻辑如下：

1.  在当前状态 $x_k$，计算在 AC 控制下，考虑所有不确定性（如扰动、模型误差）后，系统下一步可能到达的所有状态的**过近似集合** $\mathcal{R}_{\mathrm{ad}}(x_k)$。
2.  检查这个[可达集](@entry_id:276191)是否完全包含在一个已知的安全恢复集 $\mathcal{R}$ 内，即 $\mathcal{R}_{\mathrm{ad}}(x_k) \subseteq \mathcal{R}$。恢复集 $\mathcal{R}$ 被预先验证为在 BC 控制下是鲁棒正不变的。
3.  如果包含关系成立，则放心使用 AC。
4.  如果关系不成立，则立即切换到 BC。由于当前状态 $x_k$ 仍在安[全集](@entry_id:264200) $\mathcal{R}$ 内，且 $\mathcal{R}$ 在 BC 控制下是不变的，因此系统安全得以保证。

这种**预测性**的切换逻辑确保了安全干预发生在违规**之前**，而不是之后，从而为系统提供了强有力的安全保障 。

**安全滤波器 (Safety Filters)**

另一种运行时干预方法是**安全滤波器**。它不是在两个控制器之间切换，而是修改先进控制器提出的指令，以确保其安全性。一个常见的实现是使用前述的**[控制屏障函数](@entry_id:177928) (CBF)**。AC 产生一个名义上的、以性能为目标的控制指令 $u_{\text{nom}}$。这个指令不直接发送给执行器，而是作为实时求解的二次规划（QP）的[目标函数](@entry_id:267263)：
$$
u^* = \arg\min_{u \in U} \|u - u_{\text{nom}}\|^2 \quad \text{s.t.} \quad \dot{B}(x, u) + \alpha(B(x)) \ge 0
$$
QP 的解 $u^*$ 是在所有满足 CBF 安全条件的控制输入中，与 $u_{\text{nom}}$ 最接近的一个。这样，安全滤波器在保证安全的同时，最大限度地保留了 AC 的性能。这种方法巧妙地将设计时的模型知识（CBF）应用于运行时，为端到端策略等难以直接验证的组件提供了安全“[外包](@entry_id:262441)装”。

#### 数据驱动的保证机制

当 LE-CPS 的某些部分（如感知模块）完全由数据驱动时，我们需要能够量化其不确定性的方法。

**置信预测 (Conformal Prediction)**

对于一个基于学习的[回归模型](@entry_id:1130806)（例如，一个用于估计障碍物距离的神经网络），我们如何为其预测提供一个严格的置信度？**置信预测**提供了一种与分布无关的方法来构建具有统计保证的**[预测区间](@entry_id:635786)**。

其核心思想是利用一个与训练数据独立的**校准数据集**。对于校准集中的每个样本 $(x_i, y_i)$，我们计算一个**非符合性分数**，例如模型预测值与真实值之间的[绝对误差](@entry_id:139354) $s_i = |y_i - \hat{f}(x_i)|$。然后，对于一个新的输入 $x_{new}$，我们希望构建一个区间 $C(x_{new})$，使得真实值 $y_{new}$ 以至少 $1-\alpha$ 的概率落入其中（$\alpha$ 是预先设定的[显著性水平](@entry_id:902699)）。

通过计算校准分数集 $\{s_i\}$ 的 $\lceil (1-\alpha)(m+1) \rceil$-th 分位数 $q$（其中 $m$ 是校准集大小），我们可以构建[预测区间](@entry_id:635786)为 $[\hat{f}(x_{new}) - q, \hat{f}(x_{new}) + q]$。置信预测理论保证，在数据是**可交换的**（Exchangeable）这一基本假设下，这个区间将以不低于 $1-\alpha$ 的概率覆盖真实值。这种**边际覆盖保证**为学习组件的输出提供了一个可操作的、有理论依据的置信度度量 。

**数据统计假设的挑战**

然而，在将数据驱动方法应用于闭环 CPS 时，必须极其谨慎地审视其底层的统计假设。机器学习中常用的**[独立同分布](@entry_id:169067)**（i.i.d.）假设在闭环系统中通常是**不成立**的。

-   **独立性失效**：由于系统的动态演化，当前状态 $x_t$ 直接依赖于前一时刻的状态 $x_{t-1}$。这种固有的**时间相关性**破坏了样本间的独立性。
-   **同分布失效**：如果学习控制器在线自适应（即参数 $\theta_t$ 随时间变化），系统的闭环动态就是非平稳的，导致数据分布随时间变化。即使控制器参数固定，系统从初始状态到稳定状态的暂态过程中的数据分布也并非恒定。

更深层次的问题是**反馈引起的[协变量偏移](@entry_id:636196)**（Feedback-Induced Covariate Shift）。控制器通过其输出的控制指令，主动地影响着系统未来的状态，从而改变了它自己未来将要观测到的输入数据的分布。这意味着训练或验证时所使用的数据分布 $P_{\text{train}}(x)$，与系统在实际部署时遇到的数据分布 $P_{\text{oper}}(x)$ 可能会有显著差异。当部署策略与训练时不同，或者控制器在线更新时，这种[分布偏移](@entry_id:915633)几乎是必然的。任何基于训练数据得出的性能或[安全保证](@entry_id:1131169)，在面临这种[协变量偏移](@entry_id:636196)时都可能失效。因此，对 LE-CPS 的认证必须明确地识别并处理这一根本性挑战 。