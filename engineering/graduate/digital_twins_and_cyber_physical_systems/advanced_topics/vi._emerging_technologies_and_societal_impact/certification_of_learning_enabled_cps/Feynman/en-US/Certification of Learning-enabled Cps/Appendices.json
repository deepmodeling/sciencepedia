{
    "hands_on_practices": [
        {
            "introduction": "Certifying a system with a neural network controller requires a rigorous understanding of the network's input-output behavior. This exercise introduces Interval Bound Propagation (IBP), a foundational formal verification technique used to compute a guaranteed over-approximation of a network's outputs for a given range of inputs. By deriving these bounds from first principles for an affine layer followed by a ReLU activation, you will see how we can \"box in\" the behavior of a learning-enabled component. ",
            "id": "4207720",
            "problem": "A Cyber-Physical System (CPS) controller is implemented as a single feedforward neural network layer followed by a Rectified Linear Unit (ReLU). For certification against input uncertainty originating from a Digital Twin, the controller must be shown to map any input within a specified hyperrectangle to outputs lying within a sound over-approximation. Consider an input vector $x \\in \\mathbb{R}^{3}$ constrained elementwise to the intervals $x_{1} \\in [\\,1,\\,2\\,]$, $x_{2} \\in [\\,-1,\\,0.5\\,]$, and $x_{3} \\in [\\,0,\\,3\\,]$. The layer computes the affine map $z = W x + b$, where\n$$\nW \\;=\\; \\begin{pmatrix}\n2 & -1 & 0.5 \\\\\n-3 & 4 & 1\n\\end{pmatrix},\n\\qquad\nb \\;=\\; \\begin{pmatrix}\n0.2 \\\\\n-0.1\n\\end{pmatrix},\n$$\nand then applies the coordinatewise ReLU nonlinearity $y = \\max\\{0, z\\}$, where the maximum is applied elementwise.\n\nStarting only from (i) the definition of an affine map $z = W x + b$, (ii) the definition and monotonicity of the Rectified Linear Unit (ReLU), and (iii) the order properties of real intervals together with interval arithmetic, derive the tightest elementwise interval over-approximation, known as Interval Bound Propagation (IBP), of the reachable set of $z$ given the input hyperrectangle, and then of $y$ after the ReLU. Your derivation must justify why the extrema of each scalar component $z_{i}$ over the input hyperrectangle occur at the vertices of the hyperrectangle, and must express the resulting bounds in terms of $W$, $b$, and the input interval endpoints.\n\nAfter completing the derivation, apply it to the concrete data above to compute the upper interval bound of the first output coordinate $y_1$ after the ReLU. Express your final answer as a real number with no units. Do not round.",
            "solution": "The problem is valid. It is scientifically grounded in the mathematics of neural networks and interval arithmetic, is well-posed with all necessary information provided, and is expressed in objective, formal language. The dimensions of the matrices and vectors are consistent. We may proceed with the solution.\n\nThe problem requires the derivation of interval bounds for the output of a single neural network layer, first for the affine part and then for the post-activation output. This process is known as Interval Bound Propagation (IBP).\n\nLet the input vector be $x \\in \\mathbb{R}^{n}$ and the input hyperrectangle be defined by elementwise bounds $x_j \\in [l_j, u_j]$ for $j = 1, \\dots, n$. Let this set of all possible inputs be denoted by $\\mathcal{X}$. The controller first computes an affine map $z = W x + b$, where $W \\in \\mathbb{R}^{m \\times n}$ and $b \\in \\mathbb{R}^{m}$. We want to find the tightest elementwise interval bounds for $z$, denoted as $[\\underline{z}_i, \\overline{z}_i]$ for each component $z_i$, where $i = 1, \\dots, m$.\n\nThe $i$-th component of the output $z$ is given by the scalar function:\n$$\nz_i(x) = \\sum_{j=1}^{n} W_{ij} x_j + b_i\n$$\nwhere $W_{ij}$ is the element in the $i$-th row and $j$-th column of $W$. We seek the minimum and maximum values of this function over the domain $\\mathcal{X}$.\n\nThe function $z_i(x)$ is a linear function of the vector $x$. The domain $\\mathcal{X}$ is a hyperrectangle, which is a convex and compact set (specifically, a convex polytope). A fundamental result from optimization theory states that the extrema (minimum and maximum) of a linear function over a convex polytope are always attained at one of its vertices. The vertices of the hyperrectangle $\\mathcal{X}$ are the points where each component $x_j$ is equal to either its lower bound $l_j$ or its upper bound $u_j$.\n\nTo find the upper bound $\\overline{z}_i = \\max_{x \\in \\mathcal{X}} z_i(x)$, we can maximize each term in the sum independently, as the choices for each $x_j$ are independent.\n$$\n\\overline{z}_i = \\max_{x \\in \\mathcal{X}} \\left( \\sum_{j=1}^{n} W_{ij} x_j + b_i \\right) = b_i + \\sum_{j=1}^{n} \\max_{x_j \\in [l_j, u_j]} (W_{ij} x_j)\n$$\nThe maximization of each term $W_{ij} x_j$ depends on the sign of the constant $W_{ij}$.\n- If $W_{ij} \\ge 0$, the term $W_{ij} x_j$ is maximized when $x_j$ is at its maximum value, $u_j$.\n- If $W_{ij} < 0$, the term $W_{ij} x_j$ is maximized when $x_j$ is at its minimum value, $l_j$.\n\nTherefore, the upper bound $\\overline{z}_i$ can be written as:\n$$\n\\overline{z}_i = b_i + \\sum_{j=1, W_{ij} \\ge 0}^{n} W_{ij} u_j + \\sum_{j=1, W_{ij} < 0}^{n} W_{ij} l_j\n$$\nBy a symmetric argument, the lower bound $\\underline{z}_i = \\min_{x \\in \\mathcal{X}} z_i(x)$ is obtained by minimizing each term:\n$$\n\\underline{z}_i = b_i + \\sum_{j=1, W_{ij} \\ge 0}^{n} W_{ij} l_j + \\sum_{j=1, W_{ij} < 0}^{n} W_{ij} u_j\n$$\nThis completes the derivation of the tightest interval bounds for the affine transformation $z$.\n\nNext, we consider the coordinatewise Rectified Linear Unit (ReLU) activation, $y = \\max\\{0, z\\}$, which means $y_i = \\max\\{0, z_i\\}$. The function $f(v) = \\max\\{0, v\\}$ is a monotonically non-decreasing function. This means that if $v_1 \\le v_2$, then $f(v_1) \\le f(v_2)$.\nGiven that we have found the tightest interval for $z_i$ to be $[\\underline{z}_i, \\overline{z}_i]$, meaning $\\underline{z}_i \\le z_i \\le \\overline{z}_i$, we can apply the monotonic ReLU function to these bounds to find the bounds for $y_i$.\nThe lower bound for $y_i$ is $\\underline{y}_i = \\max\\{0, \\underline{z}_i\\}$.\nThe upper bound for $y_i$ is $\\overline{y}_i = \\max\\{0, \\overline{z}_i\\}$.\nThus, the tightest interval over-approximation for the output $y_i$ is $[\\max\\{0, \\underline{z}_i\\}, \\max\\{0, \\overline{z}_i\\}]$.\n\nNow, we apply this derivation to the specific problem data to find the upper interval bound of the first output coordinate, $y_1$. We need to compute $\\overline{y}_1$.\nFrom the general derivation, $\\overline{y}_1 = \\max\\{0, \\overline{z}_1\\}$. First, we compute $\\overline{z}_1$.\n\nThe input vector is $x \\in \\mathbb{R}^{3}$. The input intervals are:\n- $x_{1} \\in [\\,1,\\,2\\,]$, so $l_1 = 1$ and $u_1 = 2$.\n- $x_{2} \\in [\\,-1,\\,0.5\\,]$, so $l_2 = -1$ and $u_2 = 0.5$.\n- $x_{3} \\in [\\,0,\\,3\\,]$, so $l_3 = 0$ and $u_3 = 3$.\n\nThe weight matrix and bias vector are:\n$$\nW \\;=\\; \\begin{pmatrix}\n2 & -1 & 0.5 \\\\\n-3 & 4 & 1\n\\end{pmatrix},\n\\qquad\nb \\;=\\; \\begin{pmatrix}\n0.2 \\\\\n-0.1\n\\end{pmatrix}\n$$\nWe are interested in the first component, so we use the first row of $W$, $W_{1,:} = (W_{11}, W_{12}, W_{13}) = (2, -1, 0.5)$, and the first component of $b$, $b_1 = 0.2$.\n\nUsing the derived formula for $\\overline{z}_i$:\n$$\n\\overline{z}_1 = b_1 + \\sum_{j=1, W_{1j} \\ge 0}^{3} W_{1j} u_j + \\sum_{j=1, W_{1j} < 0}^{3} W_{1j} l_j\n$$\nWe identify the terms based on the signs of $W_{1j}$:\n- $W_{11} = 2 > 0$: this term contributes $W_{11} u_1$.\n- $W_{12} = -1 < 0$: this term contributes $W_{12} l_2$.\n- $W_{13} = 0.5 > 0$: this term contributes $W_{13} u_3$.\n\nSubstituting the values:\n$$\n\\overline{z}_1 = b_1 + W_{11} u_1 + W_{13} u_3 + W_{12} l_2\n$$\n$$\n\\overline{z}_1 = 0.2 + (2)(2) + (0.5)(3) + (-1)(-1)\n$$\n$$\n\\overline{z}_1 = 0.2 + 4 + 1.5 + 1\n$$\n$$\n\\overline{z}_1 = 6.7\n$$\nNow, we can find the upper bound for $y_1$:\n$$\n\\overline{y}_1 = \\max\\{0, \\overline{z}_1\\} = \\max\\{0, 6.7\\} = 6.7\n$$\nThe upper interval bound of the first output coordinate $y_1$ is $6.7$.",
            "answer": "$$\\boxed{6.7}$$"
        },
        {
            "introduction": "A certified property of a learning component, such as an error bound, is most valuable when it can be used to guarantee the safety of the entire system. This practice problem explores how to formally integrate such a guarantee, specifically propagating a perception module's error bound into a controller designed with Control Barrier Functions (CBFs). You will derive the necessary \"tightening\" of the safety condition to provably compensate for worst-case error, ensuring the true state of the system remains safe. ",
            "id": "4207704",
            "problem": "A longitudinal collision-avoidance subsystem in a learning-enabled Cyber-Physical System (CPS) uses a learning-based perception module to estimate the gap $y$ between an ego vehicle and a lead obstacle. The perception output is $\\hat{y} = y + e$, where the perception error $e$ is unknown but bounded. A Digital Twin (DT) recalibration updates the certified error bound from a previous value to a new value $\\varepsilon_{\\text{new}}$, such that $|e| \\le \\varepsilon_{\\text{new}}$.\n\nThe safety controller is designed via a Control Barrier Function (CBF), with barrier $h(x) = y - d_{\\text{safe}}(v)$, where $v$ is the ego vehicle speed and $d_{\\text{safe}}(v)$ is the physically required stopping distance under a fixed actuation and computation reaction time $T_{\\mathrm{r}}$ and a constant worst-case braking deceleration $a_{\\max}$. The controller is implemented on the measured quantity, enforcing the inequality $\\hat{h}(x) \\ge 0$, where $\\hat{h}(x) = \\hat{y} - d_{\\text{safe}}(v)$.\n\nStarting from first principles in kinematics and Newtonian dynamics, derive the tightened certified condition that must be enforced on $\\hat{h}(x)$ so that the true barrier $h(x)$ remains nonnegative for all errors $e$ satisfying $|e| \\le \\varepsilon_{\\text{new}}$. Then, propagate this tightening to compute the maximum certified ego speed $v_{\\max}^{\\text{new}}$ at a snapshot where the measured gap is $\\hat{y} = 28\\,\\mathrm{m}$, the updated perception error bound is $\\varepsilon_{\\text{new}} = 0.7\\,\\mathrm{m}$, the reaction time is $T_{\\mathrm{r}} = 0.35\\,\\mathrm{s}$, and the maximum available deceleration is $a_{\\max} = 7.5\\,\\mathrm{m\\,s^{-2}}$.\n\nUse only well-established physical laws and algebraic reasoning. Round your final numerical answer to four significant figures. Express the final result for $v_{\\max}^{\\text{new}}$ in $\\mathrm{m\\,s^{-1}}$.",
            "solution": "The problem requires a two-part solution: first, to derive a certified safety condition for a collision-avoidance system that accounts for perception error, and second, to calculate the maximum permissible speed based on this condition and given parameters. The validation of the problem statement must precede any attempt at a solution.\n\n### Step 1: Problem Validation\n\nFirst, I will extract the givens as stated in the problem.\n- Perception model: $\\hat{y} = y + e$, where $y$ is the true gap, $\\hat{y}$ is the measured gap, and $e$ is the perception error.\n- Perception error bound: $|e| \\le \\varepsilon_{\\text{new}}$.\n- True safety barrier: $h(x) = y - d_{\\text{safe}}(v)$.\n- Safe stopping distance: $d_{\\text{safe}}(v)$, determined by reaction time $T_{\\mathrm{r}}$ and constant deceleration $a_{\\max}$.\n- Implemented controller condition: $\\hat{h}(x) \\ge 0$, where $\\hat{h}(x) = \\hat{y} - d_{\\text{safe}}(v)$.\n- Required true safety condition: $h(x) \\ge 0$.\n- Numerical values for speed calculation:\n  - Measured gap: $\\hat{y} = 28\\,\\mathrm{m}$.\n  - Updated perception error bound: $\\varepsilon_{\\text{new}} = 0.7\\,\\mathrm{m}$.\n  - Reaction time: $T_{\\mathrm{r}} = 0.35\\,\\mathrm{s}$.\n  - Maximum available deceleration: $a_{\\max} = 7.5\\,\\mathrm{m\\,s^{-2}}$.\n\nThe problem is scientifically grounded in Newtonian kinematics and control theory (specifically, the concept of Control Barrier Functions). The model of a learning-based perception system with bounded error is a standard and valid representation in the field of cyber-physical systems. The numerical values provided are physically realistic for an automotive application. The problem is well-posed, with a clear objective and sufficient information to derive a unique solution. There are no contradictions, ambiguities, or reliance on pseudoscience. Therefore, the problem is deemed valid and a solution can be formulated.\n\n### Step 2: Derivation of the Certified Safety Condition\n\nThe fundamental requirement for safety is that the true barrier function $h(x)$ must remain non-negative.\n$$h(x) \\ge 0$$\nUsing the definition of $h(x)$, this means the true gap $y$ must be greater than or equal to the safe stopping distance $d_{\\text{safe}}(v)$.\n$$y - d_{\\text{safe}}(v) \\ge 0 \\implies y \\ge d_{\\text{safe}}(v)$$\nThe controller does not have access to the true gap $y$, but only to the measured gap $\\hat{y}$. The relationship is given by $\\hat{y} = y + e$, which can be rearranged to express the true gap as $y = \\hat{y} - e$. Substituting this into the safety requirement yields:\n$$(\\hat{y} - e) - d_{\\text{safe}}(v) \\ge 0$$\nThis inequality must hold for all possible values of the perception error $e$ within its certified bound, $|e| \\le \\varepsilon_{\\text{new}}$. To guarantee safety, we must ensure the condition holds for the worst-case scenario. Rearranging the inequality to isolate the terms accessible to the controller:\n$$\\hat{y} - d_{\\text{safe}}(v) \\ge e$$\nThe worst-case scenario corresponds to the value of $e$ that makes this condition hardest to satisfy, which is the maximum possible value of $e$. Given $|e| \\le \\varepsilon_{\\text{new}}$, the maximum value of $e$ is $\\varepsilon_{\\text{new}}$. Therefore, to guarantee safety for all possible errors, the controller must enforce the following tightened condition:\n$$\\hat{y} - d_{\\text{safe}}(v) \\ge \\varepsilon_{\\text{new}}$$\nRecognizing that the measured barrier function is defined as $\\hat{h}(x) = \\hat{y} - d_{\\text{safe}}(v)$, the tightened certified condition that must be enforced is:\n$$\\hat{h}(x) \\ge \\varepsilon_{\\text{new}}$$\nThis is the first part of the required derivation. It demonstrates that the naive condition $\\hat{h}(x) \\ge 0$ is insufficient; the measured barrier must be maintained above the maximum possible perception error.\n\n### Step 3: Derivation of the Safe Stopping Distance\n\nNext, we derive the expression for the safe stopping distance $d_{\\text{safe}}(v)$ from first principles. The stopping process consists of two distinct phases:\n1.  **Reaction phase:** The vehicle continues to travel at its initial speed $v$ for the duration of the reaction time $T_{\\mathrm{r}}$. The distance covered during this phase is $d_1 = v T_{\\mathrm{r}}$.\n2.  **Braking phase:** The vehicle decelerates with a constant acceleration of magnitude $a_{\\max}$ from speed $v$ to a final speed of $0$. We use the time-independent kinematic equation $v_f^2 = v_i^2 + 2 a \\Delta x$. Here, $v_f=0$, $v_i=v$, $a=-a_{\\max}$, and $\\Delta x = d_2$ is the braking distance.\n$$0^2 = v^2 + 2(-a_{\\max})d_2$$\nSolving for the braking distance $d_2$:\n$$2 a_{\\max} d_2 = v^2 \\implies d_2 = \\frac{v^2}{2 a_{\\max}}$$\nThe total safe stopping distance $d_{\\text{safe}}(v)$ is the sum of the distances from both phases:\n$$d_{\\text{safe}}(v) = d_1 + d_2 = v T_{\\mathrm{r}} + \\frac{v^2}{2 a_{\\max}}$$\n\n### Step 4: Calculation of the Maximum Certified Speed\n\nThe maximum certified speed, $v_{\\max}^{\\text{new}}$, is the highest speed $v$ for which the tightened safety condition can be met at the given measured gap $\\hat{y}$. This occurs when the inequality becomes an equality:\n$$\\hat{y} - d_{\\text{safe}}(v_{\\max}^{\\text{new}}) = \\varepsilon_{\\text{new}}$$\nSubstituting the expression for $d_{\\text{safe}}(v)$:\n$$\\hat{y} - \\left( (v_{\\max}^{\\text{new}}) T_{\\mathrm{r}} + \\frac{(v_{\\max}^{\\text{new}})^2}{2 a_{\\max}} \\right) = \\varepsilon_{\\text{new}}$$\nTo solve for $v_{\\max}^{\\text{new}}$, we rearrange this into a standard quadratic equation of the form $Av^2 + Bv + C = 0$:\n$$\\frac{1}{2 a_{\\max}} (v_{\\max}^{\\text{new}})^2 + T_{\\mathrm{r}} (v_{\\max}^{\\text{new}}) + (\\varepsilon_{\\text{new}} - \\hat{y}) = 0$$\nWe solve for $v_{\\max}^{\\text{new}}$ using the quadratic formula, $v = \\frac{-B \\pm \\sqrt{B^2 - 4AC}}{2A}$, with coefficients $A = \\frac{1}{2 a_{\\max}}$, $B = T_{\\mathrm{r}}$, and $C = \\varepsilon_{\\text{new}} - \\hat{y}$.\n$$v_{\\max}^{\\text{new}} = \\frac{-T_{\\mathrm{r}} \\pm \\sqrt{T_{\\mathrm{r}}^2 - 4 \\left( \\frac{1}{2 a_{\\max}} \\right) (\\varepsilon_{\\text{new}} - \\hat{y})}}{2 \\left( \\frac{1}{2 a_{\\max}} \\right)}$$\nSimplifying the expression:\n$$v_{\\max}^{\\text{new}} = \\frac{-T_{\\mathrm{r}} \\pm \\sqrt{T_{\\mathrm{r}}^2 + \\frac{2}{a_{\\max}} (\\hat{y} - \\varepsilon_{\\text{new}})}}{\\frac{1}{a_{\\max}}}$$\n$$v_{\\max}^{\\text{new}} = a_{\\max} \\left( -T_{\\mathrm{r}} \\pm \\sqrt{T_{\\mathrm{r}}^2 + \\frac{2}{a_{\\max}} (\\hat{y} - \\varepsilon_{\\text{new}})} \\right)$$\nSince speed $v$ must be a positive physical quantity, we select the positive root. The term $\\sqrt{T_{\\mathrm{r}}^2 + \\dots}$ is strictly greater than $T_{\\mathrm{r}}$ (as $\\hat{y} > \\varepsilon_{\\text{new}}$), so choosing the 'plus' sign ensures a positive result for the speed.\n$$v_{\\max}^{\\text{new}} = a_{\\max} \\left( -T_{\\mathrm{r}} + \\sqrt{T_{\\mathrm{r}}^2 + \\frac{2(\\hat{y} - \\varepsilon_{\\text{new}})}{a_{\\max}}} \\right)$$\nNow, we substitute the provided numerical values: $\\hat{y} = 28\\,\\mathrm{m}$, $\\varepsilon_{\\text{new}} = 0.7\\,\\mathrm{m}$, $T_{\\mathrm{r}} = 0.35\\,\\mathrm{s}$, and $a_{\\max} = 7.5\\,\\mathrm{m\\,s^{-2}}$.\n$$v_{\\max}^{\\text{new}} = 7.5 \\left( -0.35 + \\sqrt{(0.35)^2 + \\frac{2(28 - 0.7)}{7.5}} \\right)$$\n$$v_{\\max}^{\\text{new}} = 7.5 \\left( -0.35 + \\sqrt{0.1225 + \\frac{2(27.3)}{7.5}} \\right)$$\n$$v_{\\max}^{\\text{new}} = 7.5 \\left( -0.35 + \\sqrt{0.1225 + 7.28} \\right)$$\n$$v_{\\max}^{\\text{new}} = 7.5 \\left( -0.35 + \\sqrt{7.4025} \\right)$$\n$$v_{\\max}^{\\text{new}} = 7.5 \\left( -0.35 + 2.72075357...\\right)$$\n$$v_{\\max}^{\\text{new}} = 7.5 \\left( 2.37075357... \\right)$$\n$$v_{\\max}^{\\text{new}} = 17.7806517... \\,\\mathrm{m\\,s^{-1}}$$\nRounding the final answer to four significant figures as requested gives $17.78\\,\\mathrm{m\\,s^{-1}}$.",
            "answer": "$$\\boxed{17.78}$$"
        },
        {
            "introduction": "For highly complex learning-enabled systems where formal verification is intractable, rigorous statistical testing provides a practical path to certification. This exercise delves into the foundational \"zero-failure\" testing scenario, where you will derive the minimum number of simulation runs required to claim a low probability of failure ($p \\le \\varepsilon$) with high statistical confidence ($1-\\alpha$). Mastering this calculation is essential for making sound, evidence-based safety arguments from empirical data gathered via a Digital Twin. ",
            "id": "4207711",
            "problem": "A certification authority is using a Digital Twin (DT) to assess the safety of a learning-enabled Cyber-Physical System (CPS), specifically a quadrotor stabilized by an Artificial Neural Network (ANN) controller. The DT samples initial conditions and environmental parameters independently from an Operational Design Domain (ODD) distribution and executes closed-loop simulations to detect a binary safety violation event $E$ on each run. Let $X_i \\in \\{0,1\\}$ denote the indicator of failure on the $i$-th run, with $X_i = 1$ if $E$ occurs and $X_i = 0$ otherwise. Assume the $X_i$ are independent and identically distributed Bernoulli random variables with unknown failure probability $p = \\mathbb{P}(E)$ under the ODD distribution.\n\nA certification claim requires demonstrating, at confidence level $1-\\alpha$ with $0<\\alpha<1$, that the true failure probability satisfies $p \\le \\varepsilon$ for a prescribed risk threshold $0<\\varepsilon<1$. The authority will run $n$ independent DT experiments and proceed only if zero failures are observed, that is, $\\sum_{i=1}^{n} X_i = 0$. The authority adopts the exact one-sided Clopper–Pearson construction for a $(1-\\alpha)$ upper confidence bound on $p$ based on the Binomial model.\n\nDerive, from first principles of the Bernoulli and Binomial models together with the coverage definition of a one-sided $(1-\\alpha)$ Clopper–Pearson bound, a closed-form expression for the minimal integer sample size $n^{\\star}$ such that, if zero failures are observed, it is valid to assert at confidence level $1-\\alpha$ that $p \\le \\varepsilon$. Express your final answer as a single closed-form analytic expression in terms of $\\alpha$ and $\\varepsilon$. Do not provide an inequality; provide the minimal $n^{\\star}$ as a single expression. No numerical substitution is required.",
            "solution": "We model each experiment as a Bernoulli trial. Let $X_i \\sim \\text{Bernoulli}(p)$ denote the indicator of failure on the $i$-th run, with $X_1,\\dots,X_n$ independent and identically distributed. Define $S_n = \\sum_{i=1}^{n} X_i \\sim \\text{Binomial}(n,p)$. The probability of observing zero failures given $p$ is\n$$\n\\mathbb{P}(S_n=0 \\mid p) = (1-p)^{n}.\n$$\n\nA one-sided $(1-\\alpha)$ Clopper–Pearson (exact) upper confidence bound $p_u$ for $p$ is defined by inverting the cumulative Binomial distribution so that, for the observed count $S_n=s$, the bound $p_u$ satisfies\n$$\n\\mathbb{P}_{p=p_u}(S_n \\le s) = \\alpha,\n$$\nwhich ensures coverage at level $1-\\alpha$ for all $p$. For the special case $s=0$, we have $\\mathbb{P}_{p}(S_n \\le 0) = \\mathbb{P}_{p}(S_n=0) = (1-p)^{n}$. Thus the one-sided exact upper bound $p_u$ when zero failures are observed is obtained by solving\n$$\n(1-p_u)^{n} = \\alpha,\n$$\nwhich yields\n$$\np_u = 1 - \\alpha^{1/n}.\n$$\n\nTo certify that $p \\le \\varepsilon$ at confidence level $1-\\alpha$ after observing zero failures, it is necessary and sufficient that the upper bound satisfy $p_u \\le \\varepsilon$. Therefore we require\n$$\n1 - \\alpha^{1/n} \\le \\varepsilon.\n$$\nRearranging,\n$$\n\\alpha^{1/n} \\ge 1 - \\varepsilon.\n$$\nTaking natural logarithms (noting that for $0\\alpha1$ and $0\\varepsilon1$, we have $\\ln(\\alpha)  0$ and $\\ln(1-\\varepsilon)  0$),\n$$\n\\frac{1}{n} \\ln(\\alpha) \\ge \\ln(1-\\varepsilon).\n$$\nMultiplying both sides by $n>0$ and dividing by $\\ln(1-\\varepsilon)  0$ reverses the inequality, giving\n$$\nn \\ge \\frac{\\ln(\\alpha)}{\\ln(1-\\varepsilon)}.\n$$\n\nSince $n$ must be an integer number of experiments, the minimal integer sample size that satisfies the requirement is the ceiling of the right-hand side:\n$$\nn^{\\star} = \\left\\lceil \\frac{\\ln(\\alpha)}{\\ln(1-\\varepsilon)} \\right\\rceil.\n$$\nThis expression is positive because both $\\ln(\\alpha)$ and $\\ln(1-\\varepsilon)$ are negative, making their ratio positive. This $n^{\\star}$ ensures that, upon observing zero failures, the one-sided Clopper–Pearson $(1-\\alpha)$ upper bound on $p$ is at most $\\varepsilon$, thereby justifying the certification claim $p \\le \\varepsilon$ at confidence level $1-\\alpha$ under the stated Binomial model and independence assumptions.",
            "answer": "$$\\boxed{\\left\\lceil \\frac{\\ln(\\alpha)}{\\ln(1-\\varepsilon)} \\right\\rceil}$$"
        }
    ]
}