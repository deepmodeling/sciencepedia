{
    "hands_on_practices": [
        {
            "introduction": "The first step in evaluating an autonomous system for bias is often a post-deployment audit of its real-world performance. This exercise places you in the role of an auditor for a vehicle safety system, using raw performance data summarized in confusion matrices for different demographic groups. By calculating the True Positive and False Positive Rates for each group, you will quantify the system's adherence to the Equalized Odds fairness criterion, a foundational concept ensuring that a model's predictive power is independent of group membership, conditional on the true outcome. ",
            "id": "4205289",
            "problem": "An autonomous emergency intervention module in a cyber-physical system (CPS) is deployed in a fleet of vehicles and mirrored in a high-fidelity digital twin environment. The module is a binary classifier that predicts imminent high-risk events, where a positive prediction triggers a preparatory braking action. For post-deployment auditing of algorithmic bias, the development team evaluates the classifier on two disjoint demographic groups, indexed by $g \\in \\{0,1\\}$, using replayed digital twin logs aligned to ground-truth outcomes. For each group $g$, the confusion matrix entries are recorded as true positives $\\text{TP}_g$, false positives $\\text{FP}_g$, false negatives $\\text{FN}_g$, and true negatives $\\text{TN}_g$. The observed counts are:\n- Group $g=0$: $\\text{TP}_0=80$, $\\text{FP}_0=20$, $\\text{FN}_0=40$, $\\text{TN}_0=60$.\n- Group $g=1$: $\\text{TP}_1=50$, $\\text{FP}_1=10$, $\\text{FN}_1=50$, $\\text{TN}_1=90$.\n\nStarting from the fundamental probabilistic definitions of true positive rate and false positive rate for a binary classifier, namely $\\text{TPR}_g = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1, G=g)$ and $\\text{FPR}_g = \\mathbb{P}(\\hat{Y}=1 \\mid Y=0, G=g)$, and using the standard identification of their empirical estimators from the confusion matrix, compute $\\text{TPR}_g$ and $\\text{FPR}_g$ for each group $g \\in \\{0,1\\}$. Then, evaluate the violation of the equalized odds criterion, defined here as the single-number gap\n$$\nd_{\\text{EO}} \\;=\\; \\max\\!\\big(|\\text{TPR}_0-\\text{TPR}_1|,\\;|\\text{FPR}_0-\\text{FPR}_1|\\big).\n$$\nReport only the value of $d_{\\text{EO}}$ as a decimal fraction. Round your answer to four significant figures.",
            "solution": "The problem asks for the evaluation of the equalized odds fairness criterion violation, denoted by $d_{\\text{EO}}$, for a binary classifier based on its performance on two demographic groups, $g \\in \\{0, 1\\}$. The solution proceeds by first calculating the empirical true positive rates ($\\text{TPR}_g$) and false positive rates ($\\text{FPR}_g$) for each group and then computing the maximum absolute difference between these rates across the groups.\n\nThe fundamental probabilistic definitions for the true positive rate and false positive rate for a specific group $g$ are given as:\n$$\n\\text{TPR}_g = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1, G=g)\n$$\n$$\n\\text{FPR}_g = \\mathbb{P}(\\hat{Y}=1 \\mid Y=0, G=g)\n$$\nwhere $\\hat{Y}$ is the predicted label, $Y$ is the true label, and $G$ is the group identifier.\n\nThe standard empirical estimators for these probabilities are calculated from the confusion matrix entries: true positives ($\\text{TP}_g$), false positives ($\\text{FP}_g$), false negatives ($\\text{FN}_g$), and true negatives ($\\text{TN}_g$). The total number of actual positive instances for group $g$ is $P_g = \\text{TP}_g + \\text{FN}_g$. The total number of actual negative instances is $N_g = \\text{FP}_g + \\text{TN}_g$.\n\nThe empirical estimators are thus:\n$$\n\\text{TPR}_g = \\frac{\\text{TP}_g}{\\text{TP}_g + \\text{FN}_g}\n$$\n$$\n\\text{FPR}_g = \\frac{\\text{FP}_g}{\\text{FP}_g + \\text{TN}_g}\n$$\n\nWe are given the confusion matrix counts for two groups.\n\nFor group $g=0$:\n$\\text{TP}_0=80$, $\\text{FP}_0=20$, $\\text{FN}_0=40$, $\\text{TN}_0=60$.\n\nFirst, we calculate the total number of actual positives and negatives for group $g=0$:\nThe total number of actual positives is $P_0 = \\text{TP}_0 + \\text{FN}_0 = 80 + 40 = 120$.\nThe total number of actual negatives is $N_0 = \\text{FP}_0 + \\text{TN}_0 = 20 + 60 = 80$.\n\nNow, we compute $\\text{TPR}_0$ and $\\text{FPR}_0$:\n$$\n\\text{TPR}_0 = \\frac{\\text{TP}_0}{P_0} = \\frac{80}{120} = \\frac{2}{3}\n$$\n$$\n\\text{FPR}_0 = \\frac{\\text{FP}_0}{N_0} = \\frac{20}{80} = \\frac{1}{4} = 0.25\n$$\n\nFor group $g=1$:\n$\\text{TP}_1=50$, $\\text{FP}_1=10$, $\\text{FN}_1=50$, $\\text{TN}_1=90$.\n\nSimilarly, we calculate the total number of actual positives and negatives for group $g=1$:\nThe total number of actual positives is $P_1 = \\text{TP}_1 + \\text{FN}_1 = 50 + 50 = 100$.\nThe total number of actual negatives is $N_1 = \\text{FP}_1 + \\text{TN}_1 = 10 + 90 = 100$.\n\nNow, we compute $\\text{TPR}_1$ and $\\text{FPR}_1$:\n$$\n\\text{TPR}_1 = \\frac{\\text{TP}_1}{P_1} = \\frac{50}{100} = \\frac{1}{2} = 0.5\n$$\n$$\n\\text{FPR}_1 = \\frac{\\text{FP}_1}{N_1} = \\frac{10}{100} = \\frac{1}{10} = 0.1\n$$\n\nThe next step is to evaluate the violation of the equalized odds criterion, defined as $d_{\\text{EO}} = \\max\\!\\big(|\\text{TPR}_0-\\text{TPR}_1|,\\;|\\text{FPR}_0-\\text{FPR}_1|\\big)$.\n\nWe calculate the absolute differences:\n$$\n|\\text{TPR}_0-\\text{TPR}_1| = \\left|\\frac{2}{3} - \\frac{1}{2}\\right| = \\left|\\frac{4}{6} - \\frac{3}{6}\\right| = \\frac{1}{6}\n$$\n$$\n|\\text{FPR}_0-\\text{FPR}_1| = \\left|\\frac{1}{4} - \\frac{1}{10}\\right| = \\left|0.25 - 0.1\\right| = 0.15 = \\frac{15}{100} = \\frac{3}{20}\n$$\n\nTo find the maximum, we compare the two values. It is helpful to express them as decimals:\n$|\\text{TPR}_0-\\text{TPR}_1| = \\frac{1}{6} \\approx 0.1666...$\n$|\\text{FPR}_0-\\text{FPR}_1| = 0.15$\n\nComparing these, we find that $\\frac{1}{6}$ is greater than $0.15$.\nTherefore,\n$$\nd_{\\text{EO}} = \\max\\left(\\frac{1}{6}, \\frac{3}{20}\\right) = \\frac{1}{6}\n$$\n\nThe problem requires the answer as a decimal fraction rounded to four significant figures.\n$$\nd_{\\text{EO}} = \\frac{1}{6} \\approx 0.166666...\n$$\nRounding to four significant figures gives $0.1667$.",
            "answer": "$$\n\\boxed{0.1667}\n$$"
        },
        {
            "introduction": "While metrics like Equalized Odds are powerful, a deep understanding of fairness requires recognizing that different intuitive notions of fairness can be mutually exclusive. This practice explores the fundamental tension between group calibration, where a risk score has a consistent meaning across groups, and predictive parity, which demands equal precision (Positive Predictive Value) for all groups. Through a guided theoretical derivation based on a hypothetical digital twin model, you will prove how a system can satisfy one of these criteria while simultaneously violating the other, a crucial insight for designing and critiquing fair systems. ",
            "id": "4205284",
            "problem": "Consider an autonomous decision support component in a Digital Twin (DT) of a Cyber-Physical System (CPS) that outputs a continuous risk score $S \\in [0,1]$ for each agent, used to decide whether to trigger an intervention. Agents belong to one of two demographic groups $G \\in \\{A, B\\}$. Let the ground-truth event $Y \\in \\{0,1\\}$ indicate whether the intervention is truly needed. Assume the following data-generating process consistent with the DT model: conditional on the true risk $R$, the event $Y$ is generated as $Y \\sim \\text{Bernoulli}(R)$, and the risk score equals the true risk, $S = R$. Thus, the score $S$ is group-calibrated by construction, meaning that for each group $g \\in \\{A,B\\}$ and each score value $s \\in [0,1]$, $\\Pr(Y = 1 \\mid S = s, G = g) = s$.\n\nSuppose the distribution of true risk $R$ differs by group due to environmental and sensor heterogeneity modeled in the DT: for group $A$, $R \\sim \\text{Beta}(1,1)$ (uniform on $[0,1]$), and for group $B$, $R \\sim \\text{Beta}(2,1)$ (density $f_{B}(r) = 2r$ on $[0,1]$). A binary classifier is formed by applying a common threshold $t \\in (0,1)$ to the score: $\\hat{Y} = \\mathbb{1}\\{S \\ge t\\}$, where $\\mathbb{1}\\{\\cdot\\}$ denotes the indicator function. Define predictive parity for group $g$ at threshold $t$ by the positive predictive value $\\text{PPV}_{g}(t) = \\Pr(Y = 1 \\mid \\hat{Y} = 1, G = g)$.\n\nStarting only from the given definitions and the specified risk distributions, construct the classifier and derive an exact closed-form analytic expression for the predictive parity gap\n$$D(t) = \\text{PPV}_{B}(t) - \\text{PPV}_{A}(t),$$\nas a function of $t \\in (0,1)$. Explain, based on the derivation, the mechanism by which predictive parity is violated despite group calibration. Express your final answer as a single closed-form analytic expression in $t$. No rounding is required and no units are to be reported.",
            "solution": "The problem asks for the derivation of the predictive parity gap, $D(t) = \\text{PPV}_{B}(t) - \\text{PPV}_{A}(t)$, between two groups, $A$ and $B$, as a function of a classification threshold $t$. We must also explain the mechanism for this gap despite the system being group-calibrated.\n\nFirst, we formalize the expression for the Positive Predictive Value (PPV) for a generic group $g$, denoted as $\\text{PPV}_{g}(t)$. By definition, $\\text{PPV}_{g}(t) = \\Pr(Y = 1 \\mid \\hat{Y} = 1, G = g)$. Using the definition of conditional probability, we have:\n$$ \\text{PPV}_{g}(t) = \\frac{\\Pr(Y = 1, \\hat{Y} = 1 \\mid G = g)}{\\Pr(\\hat{Y} = 1 \\mid G = g)} $$\n\nThe classifier is defined as $\\hat{Y} = \\mathbb{1}\\{S \\ge t\\}$, which means $\\hat{Y}=1$ is equivalent to the condition $S \\ge t$. The problem states that the risk score $S$ is equal to the true risk $R$, so $\\hat{Y}=1$ is equivalent to $R \\ge t$. Let $f_g(r)$ be the probability density function (PDF) of the true risk $R$ for group $g$.\n\nThe denominator, $\\Pr(\\hat{Y} = 1 \\mid G = g)$, is the probability that an individual from group $g$ is classified as positive. This is $\\Pr(R \\ge t \\mid G=g)$, which can be computed by integrating the PDF of $R$ for group $g$ from $t$ to $1$:\n$$ \\Pr(\\hat{Y} = 1 \\mid G = g) = \\int_t^1 f_g(r) \\, dr $$\n\nThe numerator, $\\Pr(Y = 1, \\hat{Y} = 1 \\mid G = g)$, can be found using the law of total probability by conditioning on the true risk $R=r$:\n$$ \\Pr(Y = 1, \\hat{Y} = 1 \\mid G = g) = \\int_0^1 \\Pr(Y = 1, \\hat{Y} = 1 \\mid R=r, G=g) f_g(r) \\, dr $$\nThe events $Y=1$ and $\\hat{Y}=1$ are conditionally independent given $R=r$. The condition $\\hat{Y}=1$ is fully determined by $r$ (it's true if $r \\ge t$), and is thus represented by an indicator function $\\mathbb{1}\\{r \\ge t\\}$. The problem states that $Y \\sim \\text{Bernoulli}(R)$, which means $\\Pr(Y=1 \\mid R=r, G=g) = r$.\nTherefore, the integrand is $\\Pr(Y=1 \\mid R=r, G=g) \\cdot \\mathbb{1}\\{r \\ge t\\} \\cdot f_g(r) = r \\cdot \\mathbb{1}\\{r \\ge t\\} \\cdot f_g(r)$.\nThe integral becomes:\n$$ \\Pr(Y = 1, \\hat{Y} = 1 \\mid G = g) = \\int_0^1 r \\cdot \\mathbb{1}\\{r \\ge t\\} \\cdot f_g(r) \\, dr = \\int_t^1 r f_g(r) \\, dr $$\n\nCombining the numerator and denominator, we obtain the general expression for $\\text{PPV}_{g}(t)$:\n$$ \\text{PPV}_{g}(t) = \\frac{\\int_t^1 r f_g(r) \\, dr}{\\int_t^1 f_g(r) \\, dr} $$\nThis expression represents the expected true risk, $E[R]$, conditional on the risk being above the threshold $t$ for group $g$.\n\nNow, we apply this formula to groups $A$ and $B$ using their respective risk distributions.\n\nFor group $A$, the risk is distributed as $R \\sim \\text{Beta}(1,1)$, which is a uniform distribution on $[0,1]$. The PDF is $f_A(r) = 1$ for $r \\in [0,1]$.\nThe denominator is:\n$$ \\Pr(\\hat{Y} = 1 \\mid G = A) = \\int_t^1 1 \\, dr = [r]_t^1 = 1 - t $$\nThe numerator is:\n$$ \\int_t^1 r \\cdot 1 \\, dr = \\left[ \\frac{1}{2}r^2 \\right]_t^1 = \\frac{1}{2}(1^2 - t^2) = \\frac{1-t^2}{2} $$\nSo, the PPV for group $A$ is:\n$$ \\text{PPV}_{A}(t) = \\frac{\\frac{1-t^2}{2}}{1-t} = \\frac{(1-t)(1+t)}{2(1-t)} = \\frac{1+t}{2} $$\n\nFor group $B$, the risk is distributed as $R \\sim \\text{Beta}(2,1)$. The PDF is $f_B(r) = 2r$ for $r \\in [0,1]$.\nThe denominator is:\n$$ \\Pr(\\hat{Y} = 1 \\mid G = B) = \\int_t^1 2r \\, dr = [r^2]_t^1 = 1 - t^2 $$\nThe numerator is:\n$$ \\int_t^1 r \\cdot (2r) \\, dr = \\int_t^1 2r^2 \\, dr = \\left[ \\frac{2}{3}r^3 \\right]_t^1 = \\frac{2}{3}(1^3 - t^3) = \\frac{2(1-t^3)}{3} $$\nSo, the PPV for group $B$ is:\n$$ \\text{PPV}_{B}(t) = \\frac{\\frac{2(1-t^3)}{3}}{1-t^2} = \\frac{2(1-t)(1+t+t^2)}{3(1-t)(1+t)} = \\frac{2(1+t+t^2)}{3(1+t)} $$\n\nFinally, we compute the predictive parity gap, $D(t) = \\text{PPV}_{B}(t) - \\text{PPV}_{A}(t)$:\n$$ D(t) = \\frac{2(1+t+t^2)}{3(1+t)} - \\frac{1+t}{2} $$\nTo subtract these fractions, we find a common denominator, which is $6(1+t)$:\n$$ D(t) = \\frac{2 \\cdot 2(1+t+t^2) - 3 \\cdot (1+t)(1+t)}{6(1+t)} = \\frac{4(1+t+t^2) - 3(1+2t+t^2)}{6(1+t)} $$\nExpanding the terms in the numerator:\n$$ D(t) = \\frac{(4+4t+4t^2) - (3+6t+3t^2)}{6(1+t)} = \\frac{(4-3) + (4t-6t) + (4t^2-3t^2)}{6(1+t)} $$\n$$ D(t) = \\frac{1 - 2t + t^2}{6(1+t)} $$\nThe numerator is a perfect square, $(1-t)^2$. Thus, the final expression for the gap is:\n$$ D(t) = \\frac{(1-t)^2}{6(1+t)} $$\n\nThe mechanism by which predictive parity is violated, despite group calibration, is evident from the derivation. The score is group-calibrated, meaning $\\Pr(Y=1|S=s, G=g)=s$. This is a *pointwise* property: a score $s$ means the same level of risk regardless of group. However, predictive parity, $\\text{PPV}_g(t)$, is a property of the *aggregate* of individuals whose scores are above the threshold $t$. As derived, $\\text{PPV}_g(t)$ is the expected risk for those with $S \\ge t$, which depends on the underlying risk distribution $f_g(r)$. Because the distributions $f_A(r)$ (uniform) and $f_B(r)$ (skewed towards higher risk) are different, the composition of the populations with $S \\ge t$ differs between the groups. Group $B$ has a higher proportion of high-risk individuals overall. Consequently, the sub-population of group $B$ with scores above $t$ has a higher average risk than the corresponding sub-population of group $A$. This difference in the base-rate distributions of risk, $f_A$ and $f_B$, directly causes the PPV values to diverge, violating predictive parity. It is a fundamental result in fairness literature that calibration and predictive parity cannot both be satisfied simultaneously when base rates (or, in this case, risk distributions) differ across groups.",
            "answer": "$$\\boxed{\\frac{(1-t)^{2}}{6(1+t)}}$$"
        },
        {
            "introduction": "Real-world fairness challenges are rarely confined to a single attribute or static conditions. This advanced practice moves from simple audits to proactive simulation within a digital twin, a powerful methodology for stress-testing autonomous systems. You will implement a model that evaluates an autonomous perception module's fairness across multiple intersectional subgroups, which are defined by the combination of age, gender, and race. By programming this simulation, you will analyze how Equalized Odds and Demographic Parity violations evolve as environmental conditions, such as visibility, change, providing a richer, more dynamic picture of algorithmic bias. ",
            "id": "4205313",
            "problem": "Consider a Digital Twin (DT) simulation for an autonomous perception module in a Cyber-Physical System (CPS) that must decide whether a true event is present from a noisy sensor measurement. The true event indicator is denoted by $y \\in \\{0,1\\}$ and the predicted decision by $\\hat{y} \\in \\{0,1\\}$. The sensor produces a scalar measurement $x \\in \\mathbb{R}$, which is thresholded at level $\\tau$ so that $\\hat{y} = 1$ if and only if $x \\ge \\tau$. The environment is summarized by a dimensionless visibility index $c \\ge 0$.\n\nIntersectional protected attributes are modeled by the Cartesian product of Age $A \\in \\{\\text{Y},\\text{S}\\}$, Gender $G \\in \\{\\text{F},\\text{M}\\}$, and Race $R \\in \\{\\text{R0},\\text{R1}\\}$. Each intersectional subgroup $g = (A,G,R)$ affects the signal and background through group-dependent parameters. The DT specifies the conditional measurement distributions as Gaussian:\n$$\nx \\mid (y=1, g, c) \\sim \\mathcal{N}\\!\\big(\\mu_g(c), \\sigma^2(c)\\big), \\quad\nx \\mid (y=0, g, c) \\sim \\mathcal{N}\\!\\big(\\nu_g(c), \\sigma^2(c)\\big),\n$$\nwith visibility-dependent noise standard deviation $\\sigma(c) = \\frac{\\sigma_0}{c+\\epsilon}$, positive constants $\\sigma_0 > 0$, $\\epsilon > 0$, and group-dependent means\n$$\n\\mu_g(c) = r_g \\, c, \\quad \\nu_g(c) = b_g \\, c,\n$$\nwhere $r_g$ and $b_g$ are group-specific response coefficients. The prevalence of the true event in subgroup $g$ is $p_g = \\mathbb{P}(y=1 \\mid g)$.\n\nFrom probability theory and the Gaussian Cumulative Distribution Function (CDF) $\\Phi(\\cdot)$, the True Positive Rate (TPR) and False Positive Rate (FPR) for subgroup $g$ at visibility $c$ are\n$$\n\\mathrm{TPR}_g(c) = \\mathbb{P}(\\hat{y}=1 \\mid y=1,g,c) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_g(c)}{\\sigma(c)}\\right),\n$$\n$$\n\\mathrm{FPR}_g(c) = \\mathbb{P}(\\hat{y}=1 \\mid y=0,g,c) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\nu_g(c)}{\\sigma(c)}\\right).\n$$\nThe selection rate for subgroup $g$ is\n$$\ns_g(c) = \\mathbb{P}(\\hat{y}=1 \\mid g,c) = p_g \\,\\mathrm{TPR}_g(c) + (1-p_g)\\,\\mathrm{FPR}_g(c).\n$$\n\nFairness across intersectional subgroups is evaluated by two metrics:\n1. Equalized Odds (EO) violation at visibility $c$, defined as the maximum of the ranges of subgroup TPRs and FPRs:\n$$\n\\mathrm{EO}(c) = \\max\\!\\left\\{ \\big(\\max_g \\mathrm{TPR}_g(c) - \\min_g \\mathrm{TPR}_g(c)\\big), \\big(\\max_g \\mathrm{FPR}_g(c) - \\min_g \\mathrm{FPR}_g(c)\\big) \\right\\}.\n$$\n2. Demographic Parity (DP) violation at visibility $c$, defined as the range of subgroup selection rates:\n$$\n\\mathrm{DP}(c) = \\max_g s_g(c) - \\min_g s_g(c).\n$$\n\nYour task is to implement a program that, for a specified test suite of visibility conditions and digital twin parameters, computes $\\mathrm{EO}(c)$ and $\\mathrm{DP}(c)$ across all intersectional subgroups. Return each metric as a float rounded to six decimal places.\n\nUse the following DT parameterization:\n- Threshold: $\\tau = 1.0$.\n- Noise parameters: $\\sigma_0 = 0.5$, $\\epsilon = 0.1$.\n- Group response coefficients $r_g$ and $b_g$ are additive across attributes:\n  - Base response: $r_{\\text{base}} = 1.2$, $b_{\\text{base}} = 0.05$.\n  - Age contributions: $r_{\\text{Y}} = 0.00$, $r_{\\text{S}} = -0.10$; $b_{\\text{Y}} = 0.01$, $b_{\\text{S}} = 0.02$.\n  - Gender contributions: $r_{\\text{F}} = 0.00$, $r_{\\text{M}} = 0.00$; $b_{\\text{F}} = -0.005$, $b_{\\text{M}} = 0.00$.\n  - Race contributions: $r_{\\text{R0}} = 0.00$, $r_{\\text{R1}} = -0.15$; $b_{\\text{R0}} = 0.00$, $b_{\\text{R1}} = 0.02$.\n  Thus $r_g = r_{\\text{base}} + r_A + r_G + r_R$ and $b_g = b_{\\text{base}} + b_A + b_G + b_R$.\n- Event prevalence is additive then clipped to $[0,1]$:\n  - Base prevalence: $p_{\\text{base}} = 0.20$.\n  - Age contributions: $p_{\\text{Y}} = -0.02$, $p_{\\text{S}} = +0.05$.\n  - Gender contributions: $p_{\\text{F}} = 0.00$, $p_{\\text{M}} = 0.00$.\n  - Race contributions: $p_{\\text{R0}} = 0.00$, $p_{\\text{R1}} = 0.00$.\n  Thus $p_g = \\min\\{1,\\max\\{0, p_{\\text{base}} + p_A + p_G + p_R\\}\\}$.\n\nTest suite of visibility indices:\n- Poor visibility: $c = 0.00$.\n- Foggy: $c = 0.20$.\n- Overcast: $c = 0.50$.\n- Clear: $c = 0.90$.\n- Exceptional clarity: $c = 1.30$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list should contain, in this order, for each visibility $c$ in the test suite, the Equalized Odds violation value $\\mathrm{EO}(c)$ followed by the Demographic Parity violation value $\\mathrm{DP}(c)$, each rounded to six decimals. For example, the output format must be $[\\mathrm{EO}(c_1),\\mathrm{DP}(c_1),\\mathrm{EO}(c_2),\\mathrm{DP}(c_2),\\ldots,\\mathrm{EO}(c_5),\\mathrm{DP}(c_5)]$.",
            "solution": "The problem furnishes a complete and mathematically coherent model for evaluating algorithmic bias in an autonomous perception module. The validation process confirms that the problem is well-posed, scientifically grounded, and contains all necessary data for a unique solution. We may therefore proceed with the derivation and computation.\n\nThe objective is to compute the Equalized Odds (EO) and Demographic Parity (DP) violation metrics for a set of visibility conditions. The core of the task involves calculating performance rates for eight distinct intersectional subgroups and then measuring the disparity across these subgroups.\n\nFirst, we must establish the parameters for each intersectional subgroup $g=(A,G,R)$, where the attributes are Age $A \\in \\{\\text{Y},\\text{S}\\}$, Gender $G \\in \\{\\text{F},\\text{M}\\}$, and Race $R \\in \\{\\text{R0},\\text{R1}\\}$. The group-dependent response coefficients, $r_g$ and $b_g$, and the event prevalence, $p_g$, are defined by additive models.\n\nThe response coefficient $r_g$ is given by $r_g = r_{\\text{base}} + r_A + r_G + r_R$. Using the provided values: $r_{\\text{base}} = 1.2$, $r_{\\text{Y}} = 0.0$, $r_{\\text{S}} = -0.1$, $r_{\\text{F}} = 0.0$, $r_{\\text{M}} = 0.0$, $r_{\\text{R0}} = 0.0$, and $r_{\\text{R1}} = -0.15$.\n\nThe response coefficient $b_g$ is given by $b_g = b_{\\text{base}} + b_A + b_G + b_R$. Using the provided values: $b_{\\text{base}} = 0.05$, $b_{\\text{Y}} = 0.01$, $b_{\\text{S}} = 0.02$, $b_{\\text{F}} = -0.005$, $b_{\\text{M}} = 0.0$, $b_{\\text{R0}} = 0.0$, and $b_{\\text{R1}} = 0.02$.\n\nThe event prevalence $p_g$ is given by $p_g = \\min\\{1,\\max\\{0, p_{\\text{base}} + p_A + p_G + p_R\\}\\}$. Using the provided values: $p_{\\text{base}} = 0.20$, $p_{\\text{Y}} = -0.02$, $p_{\\text{S}} = 0.05$, with zero contributions from Gender and Race.\n\nSystematically calculating these for all $2 \\times 2 \\times 2 = 8$ subgroups yields the following parameter table:\n| Subgroup $g$ & Attributes (A,G,R) & $r_g$ | $b_g$  | $p_g$  |\n| :------------ | :----------------- | :----: | :----: | :----: |\n| $g_1$         | (Y, F, R0)         | $1.20$ | $0.055$ | $0.18$ |\n| $g_2$         | (Y, F, R1)         | $1.05$ | $0.075$ | $0.18$ |\n| $g_3$         | (Y, M, R0)         | $1.20$ | $0.060$ | $0.18$ |\n| $g_4$         | (Y, M, R1)         | $1.05$ | $0.080$ | $0.18$ |\n| $g_5$         | (S, F, R0)         | $1.10$ | $0.065$ | $0.25$ |\n| $g_6$         | (S, F, R1)         | $0.95$ | $0.085$ | $0.25$ |\n| $g_7$         | (S, M, R0)         | $1.10$ | $0.070$ | $0.25$ |\n| $g_8$         | (S, M, R1)         | $0.95$ | $0.090$ | $0.25$ |\n\nWith these group-specific parameters established, we can now evaluate the fairness metrics for each visibility index $c$ in the test suite $\\{0.00, 0.20, 0.50, 0.90, 1.30\\}$. For each $c$, the following sequence of calculations is performed.\n\nThe visibility-dependent noise standard deviation is $\\sigma(c) = \\frac{\\sigma_0}{c+\\epsilon} = \\frac{0.5}{c+0.1}$.\nThe group- and visibility-dependent means for signal ($y=1$) and background ($y=0$) are $\\mu_g(c) = r_g \\cdot c$ and $\\nu_g(c) = b_g \\cdot c$, respectively.\n\nThe True Positive Rate (TPR) and False Positive Rate (FPR) for subgroup $g$ are determined by the probability of the sensor measurement $x$ exceeding the threshold $\\tau=1.0$. Given the Gaussian conditional distributions, these are computed using the standard normal cumulative distribution function (CDF), $\\Phi(\\cdot)$.\n$\\mathrm{TPR}_g(c) = \\mathbb{P}(x \\ge \\tau \\mid y=1,g,c) = 1 - \\Phi\\left(\\frac{\\tau - \\mu_g(c)}{\\sigma(c)}\\right)$.\n$\\mathrm{FPR}_g(c) = \\mathbb{P}(x \\ge \\tau \\mid y=0,g,c) = 1 - \\Phi\\left(\\frac{\\tau - \\nu_g(c)}{\\sigma(c)}\\right)$.\nA useful identity is $1 - \\Phi(z) = \\Phi(-z)$. Thus, we can write:\n$\\mathrm{TPR}_g(c) = \\Phi\\left(\\frac{\\mu_g(c) - \\tau}{\\sigma(c)}\\right)$\n$\\mathrm{FPR}_g(c) = \\Phi\\left(\\frac{\\nu_g(c) - \\tau}{\\sigma(c)}\\right)$\n\nThe selection rate for subgroup $g$, $s_g(c)$, is the weighted average of its TPR and FPR, with weights given by the event prevalence $p_g$:\n$s_g(c) = p_g \\cdot \\mathrm{TPR}_g(c) + (1-p_g) \\cdot \\mathrm{FPR}_g(c)$.\n\nAfter computing $\\mathrm{TPR}_g(c)$, $\\mathrm{FPR}_g(c)$, and $s_g(c)$ for all eight subgroups, the fairness violation metrics are calculated.\nThe Equalized Odds violation, $\\mathrm{EO}(c)$, is the maximum of the ranges of subgroup TPRs and FPRs:\n$\\mathrm{EO}(c) = \\max\\left\\{ \\left(\\max_g \\mathrm{TPR}_g(c) - \\min_g \\mathrm{TPR}_g(c)\\right), \\left(\\max_g \\mathrm{FPR}_g(c) - \\min_g \\mathrm{FPR}_g(c)\\right) \\right\\}$.\nThe Demographic Parity violation, $\\mathrm{DP}(c)$, is the range of subgroup selection rates:\n$\\mathrm{DP}(c) = \\max_g s_g(c) - \\min_g s_g(c)$.\n\nA special case occurs at $c=0.0$. Here, $\\mu_g(0) = 0$ and $\\nu_g(0) = 0$ for all groups $g$. The standard deviation is $\\sigma(0) = 0.5/0.1 = 5.0$. Consequently, $\\mathrm{TPR}_g(0) = \\Phi(-1.0/5.0)$ and $\\mathrm{FPR}_g(0) = \\Phi(-1.0/5.0)$ are identical for all subgroups. This immediately implies that their ranges are zero, so $\\mathrm{EO}(0)=0$. Furthermore, since $s_g(0) = p_g \\mathrm{TPR}_g(0) + (1-p_g) \\mathrm{FPR}_g(0)$ and $\\mathrm{TPR}_g(0) = \\mathrm{FPR}_g(0)$, the selection rate simplifies to $s_g(0) = \\mathrm{TPR}_g(0)$, which is also constant across all groups. Therefore, $\\mathrm{DP}(0)=0$ as well.\n\nFor all other values of $c > 0$, the group-dependent parameters $r_g$ and $b_g$ lead to different values for $\\mu_g(c)$ and $\\nu_g(c)$, resulting in non-zero fairness violations. The algorithm proceeds by iterating through each $c$ value, computing the rates for all eight subgroups, and then determining the max-min differences to find the required metrics. The final numerical results are rounded to six decimal places as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes Equalized Odds (EO) and Demographic Parity (DP) violation\n    metrics for a Digital Twin simulation of an autonomous perception module.\n    \"\"\"\n\n    # --- Problem Givens ---\n    tau = 1.0\n    sigma_0 = 0.5\n    epsilon = 0.1\n\n    # Group attribute definitions\n    attributes = {\n        'A': {'Y', 'S'},\n        'G': {'F', 'M'},\n        'R': {'R0', 'R1'}\n    }\n\n    # Additive contributions for parameters\n    r_contrib = {'base': 1.2, 'Y': 0.00, 'S': -0.10, 'F': 0.00, 'M': 0.00, 'R0': 0.00, 'R1': -0.15}\n    b_contrib = {'base': 0.05, 'Y': 0.01, 'S': 0.02, 'F': -0.005, 'M': 0.00, 'R0': 0.00, 'R1': 0.02}\n    p_contrib = {'base': 0.20, 'Y': -0.02, 'S': 0.05, 'F': 0.00, 'M': 0.00, 'R0': 0.00, 'R1': 0.00}\n    \n    # Test suite of visibility indices\n    test_cases = [0.00, 0.20, 0.50, 0.90, 1.30]\n\n    # --- Subgroup Parameter Calculation ---\n    subgroups = []\n    for age in attributes['A']:\n        for gender in attributes['G']:\n            for race in attributes['R']:\n                subgroups.append((age, gender, race))\n\n    group_params = []\n    for group in subgroups:\n        age, gender, race = group\n        # Calculate r_g\n        r_g = r_contrib['base'] + r_contrib[age] + r_contrib[gender] + r_contrib[race]\n        # Calculate b_g\n        b_g = b_contrib['base'] + b_contrib[age] + b_contrib[gender] + b_contrib[race]\n        # Calculate p_g with clipping\n        p_raw = p_contrib['base'] + p_contrib[age] + p_contrib[gender] + p_contrib[race]\n        p_g = min(1.0, max(0.0, p_raw))\n        \n        group_params.append({'r': r_g, 'b': b_g, 'p': p_g})\n\n    # --- Main Calculation Loop ---\n    results = []\n    for c in test_cases:\n        # Special case c=0 where metrics are analytically zero\n        if c == 0.0:\n            results.extend([0.0, 0.0])\n            continue\n            \n        tpr_g_list = []\n        fpr_g_list = []\n        s_g_list = []\n\n        sigma_c = sigma_0 / (c + epsilon)\n\n        for params in group_params:\n            r_g, b_g, p_g = params['r'], params['b'], params['p']\n\n            mu_g = r_g * c\n            nu_g = b_g * c\n\n            # TPR = P(x >= tau | y=1) = Phi((mu - tau)/sigma)\n            tpr = norm.cdf((mu_g - tau) / sigma_c)\n            tpr_g_list.append(tpr)\n\n            # FPR = P(x >= tau | y=0) = Phi((nu - tau)/sigma)\n            fpr = norm.cdf((nu_g - tau) / sigma_c)\n            fpr_g_list.append(fpr)\n\n            # Selection Rate s_g = p_g*TPR + (1-p_g)*FPR\n            s_g = p_g * tpr + (1.0 - p_g) * fpr\n            s_g_list.append(s_g)\n\n        # Calculate EO violation\n        tpr_range = max(tpr_g_list) - min(tpr_g_list)\n        fpr_range = max(fpr_g_list) - min(fpr_g_list)\n        eo_violation = max(tpr_range, fpr_range)\n\n        # Calculate DP violation\n        dp_violation = max(s_g_list) - min(s_g_list)\n\n        results.extend([round(eo_violation, 6), round(dp_violation, 6)])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, [f'{r:.6f}' for r in results]))}]\")\n\nsolve()\n```"
        }
    ]
}