{
    "hands_on_practices": [
        {
            "introduction": "Understanding the collective behavior of a federated system begins with analyzing its composite dynamics. This practice guides you through the fundamental process of combining two linear time-invariant subsystems into a single, larger state-space model. By determining the equilibrium point of this composite system, you will practice a core skill in systems analysis and gain insight into the steady-state behavior of interconnected digital twins. ",
            "id": "4209278",
            "problem": "A composite Digital Twin (DT) of a federated Cyber-Physical System (CPS) is formed by interconnecting two linear time-invariant subsystem twins. Subsystem $1$ has state $x_1 \\in \\mathbb{R}^{2}$, input $u_1 \\in \\mathbb{R}^{2}$, and output $y_1 \\in \\mathbb{R}^{2}$ with dynamics\n$$\n\\dot{x}_1 = A_1 x_1 + B_1 u_1, \\quad y_1 = C_1 x_1 + D_1 u_1,\n$$\nand subsystem $2$ has state $x_2 \\in \\mathbb{R}^{2}$, input $u_2 \\in \\mathbb{R}^{2}$, and output $y_2 \\in \\mathbb{R}^{2}$ with dynamics\n$$\n\\dot{x}_2 = A_2 x_2 + B_2 u_2, \\quad y_2 = C_2 x_2 + D_2 u_2.\n$$\nIn this federated composite DT, the interconnection is defined by\n$$\nu_1 = C_2 x_2, \\qquad u_2 = C_1 x_1,\n$$\nthat is, each subsystem’s input is the state-based output of the other (no direct feedthrough is used in the interconnection). The subsystem parameter matrices are\n$$\nA_1=\\begin{pmatrix}-1 & 2\\\\ -3 & -4\\end{pmatrix},\\quad B_1=\\begin{pmatrix}1 & 0\\\\ 0 & 1\\end{pmatrix},\\quad C_1=\\begin{pmatrix} \\tfrac{1}{2} & 0\\\\ 0 & -1\\end{pmatrix},\\quad D_1=\\begin{pmatrix}0 & 0\\\\ 0 & 0\\end{pmatrix},\n$$\n$$\nA_2=\\begin{pmatrix}-2 & 1\\\\ 1 & -3\\end{pmatrix},\\quad B_2=\\begin{pmatrix}2 & 0\\\\ 0 & 1\\end{pmatrix},\\quad C_2=\\begin{pmatrix}1 & 1\\\\ 0 & 2\\end{pmatrix},\\quad D_2=\\begin{pmatrix}0 & 0\\\\ 0 & 0\\end{pmatrix}.\n$$\nUsing only fundamental state-space modeling principles for linear time-invariant systems and the definition of equilibrium for autonomous systems, determine the equilibrium point $(x_1^{\\star},x_2^{\\star})$ of the composite federated DT under the given interconnection. Express your final answer as a single row vector\n$$\n\\begin{pmatrix} x_{1,1}^{\\star} & x_{1,2}^{\\star} & x_{2,1}^{\\star} & x_{2,2}^{\\star} \\end{pmatrix}\n$$\nwith no units. No rounding is required; provide the exact values.",
            "solution": "The problem requires the determination of the equilibrium point $(x_1^{\\star}, x_2^{\\star})$ for a composite federated digital twin. The system is described by two interconnected linear time-invariant (LTI) subsystems.\n\nFirst, we establish the mathematical model for the overall composite system. The state of the composite system is the concatenation of the individual subsystem states, defined as $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$, where $x \\in \\mathbb{R}^{4}$.\n\nThe dynamics of the individual subsystems are given by:\n$$\n\\dot{x}_1 = A_1 x_1 + B_1 u_1\n$$\n$$\n\\dot{x}_2 = A_2 x_2 + B_2 u_2\n$$\nThe interconnection between the subsystems is defined by the coupling equations:\n$$\nu_1 = C_2 x_2\n$$\n$$\nu_2 = C_1 x_1\n$$\nSubstituting these interconnection laws into the subsystem dynamics yields the dynamics of the composite system as a function of its own state, making it an autonomous system:\n$$\n\\dot{x}_1 = A_1 x_1 + B_1 (C_2 x_2) = A_1 x_1 + (B_1 C_2) x_2\n$$\n$$\n\\dot{x}_2 = A_2 x_2 + B_2 (C_1 x_1) = (B_2 C_1) x_1 + A_2 x_2\n$$\nThis can be expressed in a standard state-space form for the composite system, $\\dot{x} = A_{comp} x$:\n$$\n\\begin{pmatrix} \\dot{x}_1 \\\\ \\dot{x}_2 \\end{pmatrix} = \\begin{pmatrix} A_1 & B_1 C_2 \\\\ B_2 C_1 & A_2 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}\n$$\nHere, $A_{comp} = \\begin{pmatrix} A_1 & B_1 C_2 \\\\ B_2 C_1 & A_2 \\end{pmatrix}$ is the state matrix of the composite system.\n\nAn equilibrium point $x^{\\star}$ of an autonomous system $\\dot{x} = f(x)$ is a state at which the system remains indefinitely. This occurs when the state derivatives are zero, i.e., $\\dot{x} = 0$. For our linear system, the equilibrium condition is $\\dot{x}^{\\star} = A_{comp} x^{\\star} = 0$. This is a system of homogeneous linear equations.\n\nTo find the equilibrium point(s), we must first construct the matrix $A_{comp}$ using the provided parameter matrices.\nThe given matrices are:\n$$\nA_1=\\begin{pmatrix}-1 & 2\\\\ -3 & -4\\end{pmatrix}, B_1=\\begin{pmatrix}1 & 0\\\\ 0 & 1\\end{pmatrix}, C_1=\\begin{pmatrix} \\frac{1}{2} & 0\\\\ 0 & -1\\end{pmatrix}\n$$\n$$\nA_2=\\begin{pmatrix}-2 & 1\\\\ 1 & -3\\end{pmatrix}, B_2=\\begin{pmatrix}2 & 0\\\\ 0 & 1\\end{pmatrix}, C_2=\\begin{pmatrix}1 & 1\\\\ 0 & 2\\end{pmatrix}\n$$\nWe compute the off-diagonal block matrices $B_1 C_2$ and $B_2 C_1$:\n$$\nB_1 C_2 = \\begin{pmatrix}1 & 0\\\\ 0 & 1\\end{pmatrix} \\begin{pmatrix}1 & 1\\\\ 0 & 2\\end{pmatrix} = \\begin{pmatrix}1 & 1\\\\ 0 & 2\\end{pmatrix}\n$$\n$$\nB_2 C_1 = \\begin{pmatrix}2 & 0\\\\ 0 & 1\\end{pmatrix} \\begin{pmatrix} \\frac{1}{2} & 0\\\\ 0 & -1\\end{pmatrix} = \\begin{pmatrix}(2)(\\frac{1}{2})+(0)(0) & (2)(0)+(0)(-1)\\\\ (0)(\\frac{1}{2})+(1)(0) & (0)(0)+(1)(-1)\\end{pmatrix} = \\begin{pmatrix}1 & 0\\\\ 0 & -1\\end{pmatrix}\n$$\nNow, we assemble the composite state matrix $A_{comp}$:\n$$\nA_{comp} = \\begin{pmatrix} A_1 & B_1 C_2 \\\\ B_2 C_1 & A_2 \\end{pmatrix} = \\left(\\begin{array}{cc|cc} -1 & 2 & 1 & 1 \\\\ -3 & -4 & 0 & 2 \\\\ \\hline 1 & 0 & -2 & 1 \\\\ 0 & -1 & 1 & -3 \\end{array}\\right)\n$$\nThe equilibrium points $x^{\\star}$ are the solutions to the equation $A_{comp} x^{\\star} = 0$. A non-trivial solution (i.e., $x^{\\star} \\neq 0$) exists if and only if the matrix $A_{comp}$ is singular, which means its determinant is zero ($\\det(A_{comp}) = 0$). If the matrix is non-singular ($\\det(A_{comp}) \\neq 0$), the only solution is the trivial solution $x^{\\star} = 0$.\n\nWe proceed to calculate the determinant of $A_{comp}$. We use the method of Laplace expansion. Expanding along the third row is advantageous due to the presence of a zero element.\n$$\n\\det(A_{comp}) = (1) \\cdot C_{31} + (0) \\cdot C_{32} + (-2) \\cdot C_{33} + (1) \\cdot C_{34}\n$$\nwhere $C_{ij}$ is the cofactor of the element in the $i$-th row and $j$-th column.\n$$\n\\det(A_{comp}) = (1) \\cdot (-1)^{3+1} \\det\\begin{pmatrix} 2 & 1 & 1 \\\\ -4 & 0 & 2 \\\\ -1 & 1 & -3 \\end{pmatrix} + (-2) \\cdot (-1)^{3+3} \\det\\begin{pmatrix} -1 & 2 & 1 \\\\ -3 & -4 & 2 \\\\ 0 & -1 & -3 \\end{pmatrix} + (1) \\cdot (-1)^{3+4} \\det\\begin{pmatrix} -1 & 2 & 1 \\\\ -3 & -4 & 0 \\\\ 0 & -1 & 1 \\end{pmatrix}\n$$\nWe calculate the three required $3 \\times 3$ determinants:\n$M_{31} = \\det\\begin{pmatrix} 2 & 1 & 1 \\\\ -4 & 0 & 2 \\\\ -1 & 1 & -3 \\end{pmatrix} = 2(0-2) - 1(12-(-2)) + 1(-4-0) = -4 - 14 - 4 = -22$.\n$M_{33} = \\det\\begin{pmatrix} -1 & 2 & 1 \\\\ -3 & -4 & 2 \\\\ 0 & -1 & -3 \\end{pmatrix} = -1(12-(-2)) - 2(9-0) + 1(3-0) = -14 - 18 + 3 = -29$.\n$M_{34} = \\det\\begin{pmatrix} -1 & 2 & 1 \\\\ -3 & -4 & 0 \\\\ 0 & -1 & 1 \\end{pmatrix} = -1(-4-0) - 2(-3-0) + 1(3-0) = 4 + 6 + 3 = 13$.\n\nSubstituting these values back into the expression for $\\det(A_{comp})$:\n$$\n\\det(A_{comp}) = (1)(1)(-22) + (-2)(1)(-29) + (1)(-1)(13)\n$$\n$$\n\\det(A_{comp}) = -22 + 58 - 13\n$$\n$$\n\\det(A_{comp}) = 36 - 13 = 23\n$$\nSince $\\det(A_{comp}) = 23 \\neq 0$, the matrix $A_{comp}$ is non-singular (invertible). Therefore, the homogeneous system of linear equations $A_{comp} x^{\\star} = 0$ has only one solution, which is the trivial solution $x^{\\star} = 0$.\n\nThe equilibrium state is $x^{\\star} = \\begin{pmatrix} x_1^{\\star} \\\\ x_2^{\\star} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$. This corresponds to both subsystems resting at their respective origins.\nIn the requested row vector format, the equilibrium point is $\\begin{pmatrix} x_{1,1}^{\\star} & x_{1,2}^{\\star} & x_{2,1}^{\\star} & x_{2,2}^{\\star} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 0 & 0 \\end{pmatrix}$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0 & 0 & 0 & 0 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Moving from pure modeling to practical implementation, co-simulating coupled digital twins introduces significant numerical challenges, especially when direct feedthrough creates algebraic loops. This exercise delves into the stability of such co-simulations by applying the Banach fixed-point theorem to a Gauss-Seidel iterative scheme. By deriving the convergence condition and the maximum allowable macro-step size, you will gain critical insight into how to ensure a co-simulation framework is both robust and efficient. ",
            "id": "4209299",
            "problem": "Consider two coupled Functional Mock-up Units (FMUs), where Functional Mock-up Unit (FMU) denotes a standardized black-box model with well-defined input-output behavior. Each FMU is a single-input single-output linear time-invariant system with direct feedthrough and continuous-time state dynamics. For FMU $i \\in \\{1,2\\}$, the continuous-time dynamics and output are given by\n$$\n\\dot{x}_{i}(t) = a_{i}\\,x_{i}(t) + b_{i}\\,u_{i}(t), \\quad y_{i}(t) = c_{i}\\,x_{i}(t) + d_{i}\\,u_{i}(t),\n$$\nwhere $a_{i}, b_{i}, c_{i}, d_{i}$ are nonnegative real scalars, $x_{i}(t)$ is the state, $u_{i}(t)$ is the input, and $y_{i}(t)$ is the output. The FMUs are coupled in a co-simulation setting with macro-step size $h > 0$ using Gauss–Seidel sequencing at each macro-step $t_{n} \\mapsto t_{n+1} = t_{n} + h$ under the algebraic coupling\n$$\nu_{1}(t_{n+1}) = y_{2}(t_{n+1}), \\quad u_{2}(t_{n+1}) = y_{1}(t_{n+1}).\n$$\nAssume the one-step numerical integration within each FMU uses the forward Euler method and that the direct feedthrough terms are such that $d_{1} d_{2} < 1$.\n\nStarting from the forward Euler discretization principle and the definitions of Lipschitz continuity and the Banach fixed-point theorem (contraction mapping principle), perform the following tasks:\n\n1. Derive the Gauss–Seidel fixed-point iteration that updates the coupling variable $y_{2}(t_{n+1})$ using the most recent value of $y_{1}(t_{n+1})$ and the previous iterate of $y_{2}(t_{n+1})$ at macro-step $t_{n+1}$. Express this iteration explicitly as an affine map in $y_{2}(t_{n+1})$.\n\n2. Using the Lipschitz constants that follow from the forward Euler discretization and the given system structure, derive a sufficient condition for convergence of the Gauss–Seidel iteration. Reduce this condition to a single inequality of the form\n$$\n\\left(d_{1} + h\\,c_{1} b_{1}\\right)\\left(d_{2} + h\\,c_{2} b_{2}\\right) < 1.\n$$\n\n3. Determine the exact closed-form expression for the largest admissible macro-step size $h_{\\max}$ that guarantees convergence of the Gauss–Seidel co-simulation fixed-point iteration, expressed only in terms of $a_{i}, b_{i}, c_{i}, d_{i}$ for $i \\in \\{1,2\\}$ and satisfying the condition derived in Task 2. Provide $h_{\\max}$ as a single analytic expression.\n\nNo numerical rounding is required, and no units should be included in your final expression.",
            "solution": "The problem requires an analysis of a Gauss-Seidel co-simulation scheme for two coupled linear time-invariant (LTI) systems, represented as Functional Mock-up Units (FMUs). The analysis proceeds in three steps: derivation of the fixed-point iteration, establishment of a convergence condition, and determination of the maximum allowable step size $h_{\\max}$.\n\nThe continuous-time dynamics for each FMU $i \\in \\{1,2\\}$ are given by:\n$$\n\\dot{x}_{i}(t) = a_{i}\\,x_{i}(t) + b_{i}\\,u_{i}(t)\n$$\n$$\ny_{i}(t) = c_{i}\\,x_{i}(t) + d_{i}\\,u_{i}(t)\n$$\nAll parameters $a_{i}, b_{i}, c_{i}, d_{i}$ are nonnegative real scalars. The coupling at each macro-step $t_{n+1} = t_{n}+h$ is algebraic:\n$$\nu_{1}(t_{n+1}) = y_{2}(t_{n+1}), \\quad u_{2}(t_{n+1}) = y_{1}(t_{n+1})\n$$\nThis defines a system of algebraic equations for the coupling variables at $t_{n+1}$ which must be solved iteratively. The problem specifies a Gauss-Seidel iterative scheme.\n\nTo derive a convergence condition that depends on the step size $h$, we must first establish how the output $y_{i}(t_{n+1})$ depends on the input $u_{i}(t_{n+1})$. This dependency is created by the numerical integration scheme. The problem states that a forward Euler method is used. In the context of co-simulation with implicit coupling, this is standardly interpreted as a semi-implicit or explicit-integrator-implicit-coupling scheme. The state derivative is evaluated at $t_n$, but it is a function of the input at $t_{n+1}$ during the algebraic loop. A more precise discretization of the state equation is thus:\n$$\n\\frac{x_{i}(t_{n+1}) - x_{i}(t_{n})}{h} = a_{i}\\,x_{i}(t_{n}) + b_{i}\\,u_{i}(t_{n+1})\n$$\nThis is a forward-Euler-like update where the state-dependent part of the derivative is evaluated at $t_n$, while the input is taken at $t_{n+1}$ to form the implicit algebraic constraint. Rearranging for $x_{i}(t_{n+1})$:\n$$\nx_{i}(t_{n+1}) = x_{i}(t_{n}) + h \\left( a_{i}\\,x_{i}(t_{n}) + b_{i}\\,u_{i}(t_{n+1}) \\right) = (1+ha_{i})x_{i}(t_{n}) + h b_{i} u_{i}(t_{n+1})\n$$\nNow, we substitute this into the output equation for $y_{i}(t_{n+1})$:\n$$\ny_{i}(t_{n+1}) = c_{i}x_{i}(t_{n+1}) + d_{i}u_{i}(t_{n+1}) = c_{i}\\left( (1+ha_{i})x_{i}(t_{n}) + h b_{i} u_{i}(t_{n+1}) \\right) + d_{i}u_{i}(t_{n+1})\n$$\n$$\ny_{i}(t_{n+1}) = c_{i}(1+ha_{i})x_{i}(t_{n}) + (d_{i} + h c_{i} b_{i})u_{i}(t_{n+1})\n$$\nThis equation defines an affine map from the input $u_{i}(t_{n+1})$ to the output $y_{i}(t_{n+1})$. Let's define the constant part, which depends only on the state at the previous step $t_n$, as $z_{i,n} = c_{i}(1+ha_{i})x_{i}(t_{n})$, and the gain as $L_{i}(h) = d_{i} + h c_{i} b_{i}$. The input-output relationship at step $t_{n+1}$ is:\n$$\ny_{i}(t_{n+1}) = z_{i,n} + L_{i}(h)u_{i}(t_{n+1})\n$$\nNow we can analyze the iterative solution of the coupled system. For brevity, let $y_i = y_i(t_{n+1})$ and $u_i = u_i(t_{n+1})$. The system to be solved is:\n$$\ny_{1} = z_{1,n} + L_{1}(h)u_{1}\n$$\n$$\ny_{2} = z_{2,n} + L_{2}(h)u_{2}\n$$\nwith coupling constraints $u_{1} = y_{2}$ and $u_{2} = y_{1}$. Substituting these constraints yields:\n$$\ny_{1} = z_{1,n} + L_{1}(h)y_{2}\n$$\n$$\ny_{2} = z_{2,n} + L_{2}(h)y_{1}\n$$\n\n**1. Derivation of the Gauss–Seidel Fixed-Point Iteration**\n\nThe problem specifies a Gauss-Seidel sequencing that updates $y_{2}(t_{n+1})$ using the most recent value of $y_{1}(t_{n+1})$. This implies an evaluation order of FMU $1 \\to$ FMU $2$ within each iteration. Let $y_i^{(k)}$ denote the $k$-th iterate for $y_i$. The iterative scheme is:\n$$\ny_{1}^{(k+1)} = z_{1,n} + L_{1}(h)y_{2}^{(k)}\n$$\n$$\ny_{2}^{(k+1)} = z_{2,n} + L_{2}(h)y_{1}^{(k+1)}\n$$\nTo find the iteration for $y_2$ as an affine map of its previous value, we substitute the expression for $y_{1}^{(k+1)}$ into the second equation:\n$$\ny_{2}^{(k+1)} = z_{2,n} + L_{2}(h) \\left( z_{1,n} + L_{1}(h)y_{2}^{(k)} \\right)\n$$\n$$\ny_{2}^{(k+1)} = (z_{2,n} + L_{2}(h)z_{1,n}) + (L_{1}(h)L_{2}(h)) y_{2}^{(k)}\n$$\nThis is the required affine map. Let's write it explicitly in terms of the original parameters. Let $y_{2,n+1}^{(k)}$ be the $k$-th iterate for $y_{2}(t_{n+1})$.\n$$\ny_{2,n+1}^{(k+1)} = \\left( c_{2}(1+ha_{2})x_{2}(t_{n}) + (d_{2} + h c_{2} b_{2})c_{1}(1+ha_{1})x_{1}(t_{n}) \\right) + \\left( (d_{1} + h c_{1} b_{1})(d_{2} + h c_{2} b_{2}) \\right) y_{2,n+1}^{(k)}\n$$\nThis is an iteration of the form $y^{(k+1)} = C + K y^{(k)}$, which is an affine map.\n\n**2. Derivation of the Convergence Condition**\n\nAccording to the Banach fixed-point theorem (contraction mapping principle), the iteration $y_2^{(k+1)} = F(y_2^{(k)})$ converges to a unique fixed point for any initial guess if the function $F$ is a contraction mapping. For an affine map $F(y) = C + Ky$, this condition is equivalent to its Lipschitz constant being less than $1$. The Lipschitz constant is $|K|$.\nIn our case, the slope of the affine map is $K = L_{1}(h)L_{2}(h)$. The convergence condition is therefore:\n$$\n|L_{1}(h)L_{2}(h)| < 1\n$$\nLet's substitute the expressions for $L_1(h)$ and $L_2(h)$:\n$$\n|(d_{1} + h c_{1} b_{1})(d_{2} + h c_{2} b_{2})| < 1\n$$\nThe problem states that $a_i, b_i, c_i, d_i$ are all nonnegative real scalars, and $h > 0$. Consequently, the terms $c_1 b_1 \\ge 0$ and $c_2 b_2 \\ge 0$. This implies that $d_{1} + h c_{1} b_{1} \\ge 0$ and $d_{2} + h c_{2} b_{2} \\ge 0$. The product of these two terms is therefore nonnegative, and the absolute value can be removed. The sufficient condition for convergence becomes:\n$$\n(d_{1} + h c_{1} b_{1})(d_{2} + h c_{2} b_{2}) < 1\n$$\nThis matches the inequality given in Task 2.\n\n**3. Determination of the Maximum Step Size $h_{\\max}$**\n\nWe must find the largest $h > 0$ that satisfies the convergence condition. Expanding the inequality:\n$$\nd_{1}d_{2} + h d_1 c_2 b_2 + h d_2 c_1 b_1 + h^2 (c_1 b_1)(c_2 b_2) < 1\n$$\nThis is a quadratic inequality in $h$. Let's rearrange it into the standard form $Ph^2 + Qh + R < 0$:\n$$\n(c_{1}b_{1}c_{2}b_{2})h^2 + (d_{1}c_{2}b_{2} + d_{2}c_{1}b_{1})h + (d_{1}d_{2} - 1) < 0\n$$\nLet us identify the coefficients:\n$P = c_{1}b_{1}c_{2}b_{2}$\n$Q = d_{1}c_{2}b_{2} + d_{2}c_{1}b_{1}$\n$R = d_{1}d_{2} - 1$\n\nFrom the problem statement, all base parameters are nonnegative, so $P \\ge 0$ and $Q \\ge 0$. The given condition $d_{1}d_{2} < 1$ implies $R < 0$.\nThe quadratic function $f(h) = Ph^2 + Qh + R$ represents a parabola opening upwards (or a line if $P=0$). At $h=0$, $f(0) = R < 0$. The inequality is satisfied for small positive $h$. To find the upper bound for $h$, we need to find the positive root of the equation $Ph^2 + Qh + R = 0$.\nThe roots are given by $h = \\frac{-Q \\pm \\sqrt{Q^2 - 4PR}}{2P}$. Since $P \\ge 0$, $Q \\ge 0$, and $R < 0$, the discriminant $\\Delta = Q^2 - 4PR$ is always nonnegative, guaranteeing real roots. The root with the minus sign, $\\frac{-Q - \\sqrt{\\Delta}}{2P}$, is non-positive. The positive root, which defines $h_{\\max}$, is $h_{\\max} = \\frac{-Q + \\sqrt{Q^2 - 4PR}}{2P}$.\n\nA more numerically stable and general form for this root, which also gracefully handles the case $P=0$, is obtained by multiplying the numerator and denominator by the conjugate of the numerator:\n$$\nh_{\\max} = \\frac{-Q + \\sqrt{Q^2 - 4PR}}{2P} \\times \\frac{-Q - \\sqrt{Q^2 - 4PR}}{-Q - \\sqrt{Q^2 - 4PR}} = \\frac{Q^2 - (Q^2 - 4PR)}{2P(-Q - \\sqrt{Q^2 - 4PR})} = \\frac{4PR}{2P(-Q - \\sqrt{\\Delta})} = \\frac{2R}{-Q - \\sqrt{\\Delta}}\n$$\nThis form avoids catastrophic cancellation when $P$ is small and is well-behaved as $P \\to 0$. Substituting $P, Q, R$ and $\\Delta = Q^2 - 4PR$:\n$$\nh_{\\max} = \\frac{2(d_{1}d_{2} - 1)}{-(d_{1}c_{2}b_{2} + d_{2}c_{1}b_{1}) - \\sqrt{(d_{1}c_{2}b_{2} + d_{2}c_{1}b_{1})^2 - 4(c_{1}b_{1}c_{2}b_{2})(d_{1}d_{2} - 1)}}\n$$\nSince $d_1 d_2 - 1 < 0$, we can flip the signs of both numerator and denominator:\n$$\nh_{\\max} = \\frac{2(1 - d_{1}d_{2})}{d_{1}c_{2}b_{2} + d_{2}c_{1}b_{1} + \\sqrt{(d_{1}c_{2}b_{2} + d_{2}c_{1}b_{1})^2 + 4c_{1}b_{1}c_{2}b_{2}(1 - d_{1}d_{2})}}\n$$\nThe term under the square root can be expanded and simplified:\n$(d_{1}c_{2}b_{2} + d_{2}c_{1}b_{1})^2 + 4c_{1}b_{1}c_{2}b_{2}(1 - d_{1}d_{2}) = (d_{1}c_{2}b_{2})^2 + 2d_1d_2c_1b_1c_2b_2 + (d_{2}c_{1}b_{1})^2 + 4c_1b_1c_2b_2 - 4d_1d_2c_1b_1c_2b_2$\n$= (d_{1}c_{2}b_{2})^2 - 2d_1d_2c_1b_1c_2b_2 + (d_{2}c_{1}b_{1})^2 + 4c_1b_1c_2b_2 = (d_{1}c_{2}b_{2} - d_{2}c_{1}b_{1})^2 + 4c_{1}b_{1}c_{2}b_{2}$\nSo the final expression for $h_{\\max}$ is:\n$$\nh_{\\max} = \\frac{2(1-d_1d_2)}{d_1c_2b_2 + d_2c_1b_1 + \\sqrt{(d_1c_2b_2 - d_2c_1b_1)^2 + 4c_1b_1c_2b_2}}\n$$\nThis single analytic expression is valid for all nonnegative parameter values, correctly yielding a finite positive value if $c_1b_1c_2b_2 > 0$, a different finite positive value if $c_1b_1c_2b_2 = 0$ but $d_1c_2b_2+d_2c_1b_1 > 0$, and $h_{\\max} \\to \\infty$ if both the quadratic and linear terms vanish, as all terms in the denominator are nonnegative and can only be zero simultaneously. The parameters $a_1$ and $a_2$ do not influence the convergence condition.",
            "answer": "$$\n\\boxed{\\frac{2(1-d_{1}d_{2})}{d_{1}c_{2}b_{2} + d_{2}c_{1}b_{1} + \\sqrt{(d_{1}c_{2}b_{2} - d_{2}c_{1}b_{1})^{2} + 4c_{1}b_{1}c_{2}b_{2}}}}\n$$"
        },
        {
            "introduction": "Beyond analyzing and simulating a given composite system, a key challenge is designing the federation architecture itself. This exercise frames this complex design problem as a hypergraph partitioning task, a powerful abstraction for optimizing system decomposition. By finding a minimal cut that respects architectural constraints, you will practice a quantitative approach to deciding where to draw the boundaries between federated digital twins, balancing modularity with interaction costs. ",
            "id": "4209250",
            "problem": "You are given a hypergraph partitioning problem that formalizes boundary optimization for composite and federated digital twins (FDT). A hypergraph models subsystem interactions: vertices are subsystems, and hyperedges are multi-way interactions. The goal is to choose a binary partition of subsystems into two federated groups such that a prescribed set of interactions are preserved entirely within a single group while the sum of weights of the remaining interactions that are severed by the partition is minimized.\n\nFundamental base and definitions:\n- A hypergraph is a pair $H = (V, E)$ where $V$ is a finite set of vertices (subsystems) and $E$ is a finite multiset of hyperedges with each hyperedge $e \\in E$ being a subset $e \\subseteq V$. Each hyperedge $e$ has a nonnegative weight $w_e \\in \\mathbb{R}_{\\ge 0}$.\n- A binary partition of $V$ is an ordered pair $(A, B)$ such that $A \\subseteq V$, $B = V \\setminus A$, and $A \\cap B = \\emptyset$.\n- A hyperedge $e$ is said to be cut by $(A, B)$ if $e \\cap A \\ne \\emptyset$ and $e \\cap B \\ne \\emptyset$.\n- A set $R \\subseteq \\{0,1,\\dots, |E|-1\\}$ indexes the hyperedges that are required-preserved interactions which must not be cut.\n- Two disjoint seed sets $S_A \\subseteq V$ and $S_B \\subseteq V$ specify subsystems that must be placed in $A$ and $B$ respectively.\n\nObjective and constraints:\n- Among all partitions $(A, B)$ satisfying $S_A \\subseteq A$, $S_B \\subseteq B$, and for every index $r \\in R$ the corresponding hyperedge $e_r$ must be entirely contained in either $A$ or $B$, minimize the cut cost\n$$\nJ(A) = \\sum_{\\substack{e \\in E \\\\ \\text{index}(e) \\notin R}} w_e \\, \\mathbf{1}\\big[(e \\cap A \\ne \\emptyset) \\wedge (e \\cap B \\ne \\emptyset)\\big],\n$$\nwhere $\\mathbf{1}[\\cdot]$ is the indicator function and $B = V \\setminus A$.\n\nFeasibility:\n- If the required-preserved constraint is impossible to satisfy (for example, there exists a required-preserved hyperedge $e_r$ that contains at least one vertex from $S_A$ and at least one from $S_B$), then the problem is infeasible and the output for that case must be $-1$.\n\nReturn value and units:\n- There are no physical units in this problem. For each test case, return the minimal cut cost as a nonnegative integer if feasible, or $-1$ if infeasible.\n\nYour task:\n- Implement a program that, for each provided test case, computes the minimal cut cost subject to the constraints above. Your method must be correct for the given test sizes. You may use any algorithmic approach; an exhaustive but pruned search that respects the constraints is acceptable given the small sizes.\n\nAngle units are not applicable. Percentages are not applicable.\n\nTest suite:\nFor each test case below, the input is given by a tuple consisting of:\n- number of vertices $n$,\n- a list of hyperedges $E$ as vertex index sets,\n- a list of nonnegative integer weights $(w_e)$ aligned with $E$ by index,\n- the set of required-preserved hyperedge indices $R$,\n- the seed sets $S_A$ and $S_B$.\n\nInterpretation: Vertices are indexed from $0$ to $n-1$. A hyperedge at position $i$ in the list has weight given at position $i$ in the weights list.\n\nProvide outputs for these test cases, in order:\n\n- Test case $1$ (happy path, mixed sizes and a required-preserved pair):\n  - $n = 5$,\n  - $E = [\\{0,1,2\\}, \\{2,3\\}, \\{3,4\\}, \\{1,4\\}]$,\n  - weights $[3, 2, 4, 1]$,\n  - $R = \\{1\\}$,\n  - $S_A = \\{0\\}$, $S_B = \\{4\\}$.\n- Test case $2$ (infeasible because a required-preserved interaction spans conflicting seeds):\n  - $n = 3$,\n  - $E = [\\{0,1\\}, \\{1,2\\}]$,\n  - weights $[5, 1]$,\n  - $R = \\{0\\}$,\n  - $S_A = \\{0\\}$, $S_B = \\{1\\}$.\n- Test case $3$ (zero-cost feasible partition, includes a singleton hyperedge that can never be cut):\n  - $n = 4$,\n  - $E = [\\{0,1\\}, \\{1\\}, \\{2,3\\}]$,\n  - weights $[2, 10, 3]$,\n  - $R = \\emptyset$,\n  - $S_A = \\{0\\}$, $S_B = \\{3\\}$.\n- Test case $4$ (forced cut of a low-weight large hyperedge versus avoiding higher-weight pairwise cuts, with a required-preserved pair):\n  - $n = 6$,\n  - $E = [\\{0,1,2,3\\}, \\{1,4\\}, \\{2,5\\}, \\{4,5\\}]$,\n  - weights $[1, 5, 5, 2]$,\n  - $R = \\{3\\}$,\n  - $S_A = \\{0\\}$, $S_B = \\{3\\}$.\n- Test case $5$ (required-preserved hyperedge of size greater than two):\n  - $n = 5$,\n  - $E = [\\{0,1,2\\}, \\{2,3,4\\}, \\{0,4\\}]$,\n  - weights $[7, 2, 3]$,\n  - $R = \\{0\\}$,\n  - $S_A = \\{0\\}$, $S_B = \\{3\\}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the test cases, in order, as a comma-separated list enclosed in square brackets, for example, $[x_1,x_2,x_3,x_4,x_5]$, where each $x_i$ is an integer. No spaces are allowed in the output line.",
            "solution": "This problem asks for the minimum cost partition of a hypergraph under several constraints. Since the number of vertices is small in all test cases, the problem can be solved by an exhaustive search over all possible valid partitions. We can prune the search space by considering the fixed assignments from the seed sets and the grouping constraints from the required-preserved hyperedges. We will walk through Test Case 1 to illustrate the method.\n\n**Test Case 1 Data:**\n-   Vertices $V = \\{0, 1, 2, 3, 4\\}$\n-   Hyperedges and weights: $e_0=\\{0,1,2\\}, w_0=3$; $e_1=\\{2,3\\}, w_1=2$; $e_2=\\{3,4\\}, w_2=4$; $e_3=\\{1,4\\}, w_3=1$.\n-   Required-preserved: $R = \\{1\\}$, so hyperedge $e_1=\\{2,3\\}$ must not be cut.\n-   Seed sets: $S_A = \\{0\\}$, $S_B = \\{4\\}$.\n\n**1. Initial Constraints Analysis:**\n-   The seed sets require vertex $0$ to be in partition $A$ and vertex $4$ to be in partition $B$.\n-   The required-preserved constraint on $e_1=\\{2,3\\}$ means vertices $2$ and $3$ must be in the same partition. We can treat them as a single block $\\{2,3\\}$.\n-   The free vertices whose assignments we must decide are $V \\setminus (S_A \\cup S_B) = \\{1, 2, 3\\}$.\n\n**2. Enumerate Valid Partitions:**\nWe need to decide the partition for vertex $1$ and the block $\\{2,3\\}$. There are $2^2=4$ possibilities to check.\n\n-   **Case A: $\\{1\\} \\to A$ and $\\{2,3\\} \\to A$.**\n    -   The partition is $A = \\{0, 1, 2, 3\\}$, $B = \\{4\\}$.\n    -   This is a valid partition since $e_1=\\{2,3\\}$ is fully contained in $A$.\n    -   **Cost:** We check hyperedges with indices not in $R$ (i.e., 0, 2, 3).\n        -   $e_0=\\{0,1,2\\}$: Not cut (all in $A$).\n        -   $e_2=\\{3,4\\}$: Cut. Adds $w_2 = 4$ to cost.\n        -   $e_3=\\{1,4\\}$: Cut. Adds $w_3 = 1$ to cost.\n    -   Total Cost = $4 + 1 = 5$.\n\n-   **Case B: $\\{1\\} \\to B$ and $\\{2,3\\} \\to A$.**\n    -   The partition is $A = \\{0, 2, 3\\}$, $B = \\{1, 4\\}$.\n    -   This is valid since $e_1=\\{2,3\\}$ is in $A$.\n    -   **Cost:**\n        -   $e_0=\\{0,1,2\\}$: Cut. Adds $w_0 = 3$.\n        -   $e_2=\\{3,4\\}$: Cut. Adds $w_2 = 4$.\n        -   $e_3=\\{1,4\\}$: Not cut (all in $B$).\n    -   Total Cost = $3 + 4 = 7$.\n\n-   **Case C: $\\{1\\} \\to A$ and $\\{2,3\\} \\to B$.**\n    -   The partition is $A = \\{0, 1\\}$, $B = \\{2, 3, 4\\}$.\n    -   This is valid since $e_1=\\{2,3\\}$ is in $B$.\n    -   **Cost:**\n        -   $e_0=\\{0,1,2\\}$: Cut. Adds $w_0 = 3$.\n        -   $e_2=\\{3,4\\}$: Not cut (all in $B$).\n        -   $e_3=\\{1,4\\}$: Cut. Adds $w_3 = 1$.\n    -   Total Cost = $3 + 1 = 4$.\n\n-   **Case D: $\\{1\\} \\to B$ and $\\{2,3\\} \\to B$.**\n    -   The partition is $A = \\{0\\}$, $B = \\{1, 2, 3, 4\\}$.\n    -   This is valid since $e_1=\\{2,3\\}$ is in $B$.\n    -   **Cost:**\n        -   $e_0=\\{0,1,2\\}$: Cut. Adds $w_0 = 3$.\n        -   $e_2=\\{3,4\\}$: Not cut (all in $B$).\n        -   $e_3=\\{1,4\\}$: Not cut (all in $B$).\n    -   Total Cost = 3.\n\n**3. Conclusion:**\nComparing the costs from all valid partitions (5, 7, 4, 3), the minimum cost is 3. This same procedure is applied to all test cases to obtain the final results.",
            "answer": "[3,-1,0,1,2]"
        }
    ]
}