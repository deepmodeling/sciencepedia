{
    "hands_on_practices": [
        {
            "introduction": "A common task in time-series analysis is publishing aggregate statistics like a rolling window sum. This first exercise provides a fundamental hands-on experience in applying the Laplace mechanism, a cornerstone of differential privacy. You will learn how to calculate the sensitivity of a query under a specific data model and use it to calibrate the exact amount of noise needed to satisfy a given privacy budget, directly linking theoretical principles to practical implementation and its impact on data utility. ",
            "id": "4213204",
            "problem": "A digital twin (DT) of a cyber-physical system (CPS) maintains a time series of scalar sensor readings $\\{x_t\\}_{t=1}^{T}$, each bounded in the interval $[0,1]$. At each time index $t \\geq w$, the analytics pipeline releases a rolling window sum defined by $f_t(D) = \\sum_{i=t-w+1}^{t} x_i$, where $w \\in \\mathbb{N}$ is the fixed window length and $D$ denotes the dataset comprising the time series. The DT requires an event-level privacy guarantee, where two datasets $D$ and $D'$ are adjacent if they differ in exactly one index $k$ by an arbitrary change within $[0,1]$. For each release $t$, the mechanism outputs $\\tilde{f}_t = f_t(D) + Z_t$ with $Z_t$ drawn independently from a zero-mean Laplace distribution with unknown scale $b > 0$. The requirement is that each single release at time $t$ must satisfy $\\epsilon$-differential privacy for a fixed $\\epsilon > 0$.\n\nStarting from the definition of $\\epsilon$-differential privacy and the properties of the Laplace distribution, derive the appropriate scale $b$ that ensures the release at time $t$ is $\\epsilon$-differentially private under event-level adjacency. Then, compute the expected mean squared error per release $\\mathbb{E}\\!\\left[(\\tilde{f}_t - f_t(D))^2\\right]$ as a function of $\\epsilon$. Express the final answer as a single row matrix containing the calibrated $b$ and the expected mean squared error per release, in that order. No rounding is required and no units should be included in the final expression.",
            "solution": "The user has provided a problem statement that requires validation before a solution is attempted.\n\n### Step 1: Extract Givens\n-   Time series of scalar sensor readings: $\\{x_t\\}_{t=1}^{T}$.\n-   Bound on readings: $x_t \\in [0,1]$ for all $t$.\n-   Rolling window sum function at time $t \\geq w$: $f_t(D) = \\sum_{i=t-w+1}^{t} x_i$.\n-   Window length: $w \\in \\mathbb{N}$, fixed.\n-   Dataset: $D$ denotes the time series $\\{x_t\\}_{t=1}^{T}$.\n-   Adjacency definition (event-level privacy): Two datasets $D$ and $D'$ are adjacent if they differ in exactly one index $k$ by an arbitrary change within $[0,1]$. That is, $D' = \\{x_1, \\dots, x_k', \\dots, x_T\\}$ where $x_k \\neq x_k'$ and $x_i = x_i'$ for all $i \\neq k$. Both $x_k, x_k' \\in [0,1]$.\n-   Mechanism output at time $t$: $\\tilde{f}_t = f_t(D) + Z_t$.\n-   Noise distribution: $Z_t$ is drawn independently from a zero-mean Laplace distribution with scale $b > 0$. The probability density function is $p(z|b) = \\frac{1}{2b}\\exp\\left(-\\frac{|z|}{b}\\right)$.\n-   Privacy requirement: Each release $\\tilde{f}_t$ must satisfy $\\epsilon$-differential privacy for a fixed $\\epsilon > 0$.\n-   Objective 1: Derive the appropriate scale $b$.\n-   Objective 2: Compute the expected mean squared error per release, $\\mathbb{E}\\!\\left[(\\tilde{f}_t - f_t(D))^2\\right]$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the established theory of differential privacy and probability theory. All terms such as $\\epsilon$-differential privacy, Laplace mechanism, and mean squared error are standard and well-defined. The problem is self-contained, providing all necessary definitions (e.g., function, adjacency) to proceed. The setup is a canonical example of applying differential privacy to time-series analysis, which is a relevant and non-trivial topic in computer science and engineering. The problem is objective, mathematically precise, and contains no contradictions or ambiguities. It is well-posed, and a unique, meaningful solution can be derived.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A solution will now be provided.\n\nThe core principle for calibrating the noise in the Laplace mechanism is to match the scale of the noise to the sensitivity of the query function. We will first derive the sensitivity, then use it to find the noise scale $b$, and finally compute the resulting mean squared error.\n\nA randomized mechanism $\\mathcal{M}$ satisfies $\\epsilon$-differential privacy if for any two adjacent datasets $D$ and $D'$, and for any set of possible outputs $S$, the following inequality holds:\n$$\n\\text{Pr}[\\mathcal{M}(D) \\in S] \\leq \\exp(\\epsilon) \\cdot \\text{Pr}[\\mathcal{M}(D') \\in S]\n$$\nFor a real-valued function $f$, the Laplace mechanism, which outputs $\\mathcal{M}(D) = f(D) + Z$ where $Z$ is drawn from a Laplace distribution with mean $0$ and scale $b$, is known to satisfy $\\epsilon$-differential privacy if the scale $b$ is set as:\n$$\nb = \\frac{\\Delta f}{\\epsilon}\n$$\nHere, $\\Delta f$ is the $L_1$-sensitivity of the function $f$, defined as the maximum possible change in the function's output for any pair of adjacent datasets:\n$$\n\\Delta f = \\sup_{D, D' \\text{ adjacent}} \\|f(D) - f(D')\\|_1\n$$\nIn our case, the function $f_t(D)$ is scalar-valued, so the $L_1$-norm is simply the absolute value. The sensitivity of the rolling window sum $f_t$ is:\n$$\n\\Delta f_t = \\sup_{D, D' \\text{ adjacent}} |f_t(D) - f_t(D')|\n$$\nLet $D = \\{x_1, \\dots, x_k, \\dots, x_T\\}$ and $D' = \\{x_1, \\dots, x_k', \\dots, x_T\\}$ be two adjacent datasets, where $x_k, x_k' \\in [0,1]$ and $x_i = x_i'$ for all $i \\neq k$. The difference in the function output is:\n$$\nf_t(D) - f_t(D') = \\left(\\sum_{i=t-w+1}^{t} x_i\\right) - \\left(\\sum_{i=t-w+1}^{t} x'_i\\right)\n$$\nSince $x_i = x'_i$ for all indices except $k$, this sum simplifies.\nThere are two cases for the index $k$:\n1.  The changed index $k$ is outside the query window: $k < t-w+1$ or $k > t$. In this case, for all $i \\in [t-w+1, t]$, we have $x_i = x'_i$. Therefore, $f_t(D) - f_t(D') = 0$.\n2.  The changed index $k$ is inside the query window: $t-w+1 \\leq k \\leq t$. In this case, the sums cancel for all terms where $i \\neq k$, leaving only the term for index $k$.\n    $$\n    f_t(D) - f_t(D') = x_k - x'_k\n    $$\nThe sensitivity $\\Delta f_t$ is the supremum of the absolute value of this difference over all possible adjacent datasets. This corresponds to the maximum possible value of $|x_k - x'_k|$ for $x_k, x_k' \\in [0,1]$, which occurs when one value is $0$ and the other is $1$.\n$$\n\\Delta f_t = \\sup_{x_k, x'_k \\in [0,1]} |x_k - x'_k| = |1 - 0| = 1\n$$\nTherefore, the $L_1$-sensitivity of the rolling sum query $f_t$ under the given event-level adjacency is $1$.\n\nNow, we can determine the required scale $b$ for the Laplace noise to ensure $\\epsilon$-differential privacy.\n$$\nb = \\frac{\\Delta f_t}{\\epsilon} = \\frac{1}{\\epsilon}\n$$\nThis is the first part of the answer.\n\nNext, we compute the expected mean squared error (MSE) per release. The error at time $t$ is the difference between the noisy output $\\tilde{f}_t$ and the true value $f_t(D)$.\n$$\n\\text{Error}_t = \\tilde{f}_t - f_t(D) = (f_t(D) + Z_t) - f_t(D) = Z_t\n$$\nThe mean squared error is the expected value of the squared error:\n$$\n\\text{MSE} = \\mathbb{E}[(\\text{Error}_t)^2] = \\mathbb{E}[Z_t^2]\n$$\nThe random variable $Z_t$ is drawn from a Laplace distribution with mean $\\mu = 0$ and scale $b$. The variance of a random variable $X$ is given by $\\text{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$. For $Z_t$, we have $\\mathbb{E}[Z_t] = \\mu = 0$.\nThus, the MSE is equal to the variance of the noise variable $Z_t$:\n$$\n\\text{MSE} = \\mathbb{E}[Z_t^2] - (\\mathbb{E}[Z_t])^2 = \\mathbb{E}[Z_t^2] - 0^2 = \\text{Var}(Z_t)\n$$\nThe variance of a Laplace distribution with scale parameter $b$ is known to be $2b^2$.\n$$\n\\text{Var}(Z_t) = 2b^2\n$$\nSubstituting the expression for $b$ that we derived:\n$$\n\\text{MSE} = 2 \\left(\\frac{1}{\\epsilon}\\right)^2 = \\frac{2}{\\epsilon^2}\n$$\nThis is the second part of the answer.\n\nThe problem requires the answer to be a single row matrix containing the calibrated $b$ and the expected mean squared error. The two values are $b = \\frac{1}{\\epsilon}$ and $\\text{MSE} = \\frac{2}{\\epsilon^2}$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{\\epsilon} & \\frac{2}{\\epsilon^2} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Real-world cyber-physical systems and digital twins don't just release data once; they do so continuously. This practice delves into the critical concept of privacy composition, which governs how privacy guarantees degrade over a sequence of data releases. By comparing the bounds from basic and advanced composition theorems, you will gain an essential understanding of how to manage a privacy budget over time, a crucial skill for designing any practical, long-term privacy-preserving system. ",
            "id": "4213357",
            "problem": "A cyber-physical digital twin for a smart manufacturing line releases, at each discrete time step, a time-series statistic computed from raw sensor streams. At each time step, the mechanism is the Gaussian mechanism applied to a function with bounded squared-sensitivity, that is, the function has the same global $\\ell_{2}$-sensitivity $\\Delta_{2}$ at every time step. The noise standard deviation is calibrated per release so that each single-time-step release is $(\\epsilon, \\delta)$-Differentially Private (DP) with $\\epsilon = 0.5$ and $\\delta = 10^{-6}$. Assume the releases are produced adaptively over $T$ time steps.\n\nStarting from the definition of Differential Privacy and the standard composition theorems regarded as well-tested facts, derive the total privacy parameters under:\n- Basic composition, and\n- Advanced composition (choose an auxiliary parameter $\\delta' = 10^{-6}$).\n\nExpress each total privacy guarantee as a pair $(\\epsilon_{\\mathrm{tot}}, \\delta_{\\mathrm{tot}})$ as a function of $T$. Your final answer must be a single closed-form analytic expression presented as a row matrix containing, in order,\n- $\\epsilon_{\\mathrm{basic}}(T)$,\n- $\\epsilon_{\\mathrm{advanced}}(T)$,\n- $\\delta_{\\mathrm{basic}}(T)$,\n- $\\delta_{\\mathrm{advanced}}(T)$.\n\nNo numerical rounding is required. Do not include units in your final expression.",
            "solution": "The problem is valid as it is scientifically grounded in the theory of differential privacy, is well-posed with all necessary information provided, and is expressed in objective, formal language. We can therefore proceed with the derivation.\n\nThe problem describes a sequence of $T$ adaptive mechanisms, where the $i$-th mechanism $M_i$ for each time step $i \\in \\{1, 2, \\dots, T\\}$ is $(\\epsilon, \\delta)$-differentially private. The privacy parameters for each release are given as $\\epsilon = 0.5$ and $\\delta = 10^{-6}$. We are asked to derive the total privacy cost $(\\epsilon_{\\mathrm{tot}}, \\delta_{\\mathrm{tot}})$ for the sequence of $T$ releases under two different composition rules: basic composition and advanced composition.\n\nFirst, let us recall the definition of $(\\epsilon, \\delta)$-Differential Privacy (DP). A randomized mechanism $M$ is $(\\epsilon, \\delta)$-DP if for all adjacent datasets $D_1$ and $D_2$ (differing in one individual's data), and for all subsets of outputs $S \\subseteq \\mathrm{Range}(M)$, the following inequality holds:\n$$P(M(D_1) \\in S) \\le \\exp(\\epsilon) P(M(D_2) \\in S) + \\delta$$\n\nWe will now apply the standard composition theorems to the sequence of $T$ mechanisms, where each mechanism $M_i$ is $(\\epsilon, \\delta)$-DP with $\\epsilon = 0.5$ and $\\delta = 10^{-6}$.\n\n**1. Basic Composition**\n\nThe basic composition theorem states that if a sequence of $T$ mechanisms $M_1, \\dots, M_T$ are respectively $(\\epsilon_1, \\delta_1), \\dots, (\\epsilon_T, \\delta_T)$-differentially private, their adaptive composition provides $(\\sum_{i=1}^T \\epsilon_i, \\sum_{i=1}^T \\delta_i)$-differential privacy.\n\nIn this problem, each of the $T$ mechanisms has the same privacy parameters $\\epsilon_i = \\epsilon = 0.5$ and $\\delta_i = \\delta = 10^{-6}$. Therefore, the total privacy parameters under basic composition, denoted $(\\epsilon_{\\mathrm{basic}}(T), \\delta_{\\mathrm{basic}}(T))$, are:\n$$\n\\epsilon_{\\mathrm{basic}}(T) = \\sum_{i=1}^T \\epsilon = T \\epsilon = T \\times 0.5 = 0.5T\n$$\n$$\n\\delta_{\\mathrm{basic}}(T) = \\sum_{i=1}^T \\delta = T \\delta = T \\times 10^{-6}\n$$\n\n**2. Advanced Composition**\n\nThe advanced composition theorem provides a tighter bound on the privacy loss for a sequence of mechanisms. A standard formulation of the theorem states that for any $\\epsilon, \\delta, \\delta' \\ge 0$, the $T$-fold adaptive composition of $(\\epsilon, \\delta)$-DP mechanisms is $(\\epsilon_{\\mathrm{tot}}, \\delta_{\\mathrm{tot}})$-DP, where:\n$$\n\\epsilon_{\\mathrm{tot}} = \\sqrt{2T \\ln(1/\\delta')} \\epsilon + T\\epsilon(\\exp(\\epsilon)-1)\n$$\n$$\n\\delta_{\\mathrm{tot}} = T\\delta + \\delta'\n$$\nThe problem specifies the per-step parameters $\\epsilon = 0.5$ and $\\delta = 10^{-6}$, and directs us to use an auxiliary parameter $\\delta' = 10^{-6}$. We will substitute these values into the theorem to find the total privacy parameters $(\\epsilon_{\\mathrm{advanced}}(T), \\delta_{\\mathrm{advanced}}(T))$.\n\nFirst, we compute the total delta parameter, $\\delta_{\\mathrm{advanced}}(T)$:\n$$\n\\delta_{\\mathrm{advanced}}(T) = T\\delta + \\delta' = T \\times 10^{-6} + 10^{-6} = (T+1) \\times 10^{-6}\n$$\n\nNext, we compute the total epsilon parameter, $\\epsilon_{\\mathrm{advanced}}(T)$:\n$$\n\\epsilon_{\\mathrm{advanced}}(T) = \\sqrt{2T \\ln(1/\\delta')} \\epsilon + T\\epsilon(\\exp(\\epsilon)-1)\n$$\nSubstituting the values $\\epsilon = 0.5$ and $\\delta' = 10^{-6}$:\n$$\n\\epsilon_{\\mathrm{advanced}}(T) = \\sqrt{2T \\ln(1/10^{-6})} \\times 0.5 + T \\times 0.5 \\times (\\exp(0.5)-1)\n$$\nWe can simplify the logarithmic term:\n$$\n\\ln(1/10^{-6}) = \\ln(10^6) = 6 \\ln(10)\n$$\nSubstituting this back into the expression for $\\epsilon_{\\mathrm{advanced}}(T)$:\n$$\n\\epsilon_{\\mathrm{advanced}}(T) = \\sqrt{2T \\cdot 6 \\ln(10)} \\times 0.5 + 0.5T(\\exp(0.5)-1)\n$$\n$$\n\\epsilon_{\\mathrm{advanced}}(T) = \\sqrt{12T \\ln(10)} \\times 0.5 + 0.5T(\\exp(0.5)-1)\n$$\nWe can simplify the square root term $\\sqrt{12} = \\sqrt{4 \\times 3} = 2\\sqrt{3}$:\n$$\n\\epsilon_{\\mathrm{advanced}}(T) = (2\\sqrt{3T \\ln(10)}) \\times 0.5 + 0.5T(\\exp(0.5)-1)\n$$\n$$\n\\epsilon_{\\mathrm{advanced}}(T) = \\sqrt{3T \\ln(10)} + 0.5T(\\exp(0.5)-1)\n$$\nThe problem does not require numerical evaluation, so we leave the expression in its exact analytical form.\n\nIn summary, the four requested quantities as functions of $T$ are:\n- $\\epsilon_{\\mathrm{basic}}(T) = 0.5T$\n- $\\epsilon_{\\mathrm{advanced}}(T) = \\sqrt{3T \\ln(10)} + 0.5T(\\exp(0.5) - 1)$\n- $\\delta_{\\mathrm{basic}}(T) = T \\times 10^{-6}$\n- $\\delta_{\\mathrm{advanced}}(T) = (T+1) \\times 10^{-6}$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.5T & \\sqrt{3T \\ln(10)} + 0.5T(\\exp(0.5) - 1) & T \\times 10^{-6} & (T+1) \\times 10^{-6} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Beyond releasing simple statistics, a key application of time-series data is training predictive models. This advanced practice introduces the moments accountant, a state-of-the-art technique for tracking privacy loss in iterative algorithms like Differentially Private Stochastic Gradient Descent (DP-SGD). By implementing this method, you will engage with the sophisticated interplay between subsampling, noise addition, and composition, revealing how tight privacy bounds are computed for modern machine learning applications. ",
            "id": "4213347",
            "problem": "A cyber-physical system digital twin ingests multivariate time-series sensor data to train a forecasting model using Differentially Private Stochastic Gradient Descent (DP-SGD). The training procedure at each iteration applies per-example gradient clipping at norm $C$ and adds independent Gaussian noise with standard deviation $\\sigma C$ to the aggregated gradient. Minibatches are formed by subsampling the dataset with sampling probability $q$, where $q = B/N$ for dataset size $N$ and batch size $B$. The objective is to bound the cumulative privacy loss across training iterations using the moments accountant technique and to compute an example privacy curve (privacy loss $\\epsilon$ as a function of epochs) under fixed batch size and sampling rate.\n\nStart from the fundamental definitions:\n- Differential Privacy (DP): A randomized mechanism $\\mathcal{M}$ is $(\\epsilon,\\delta)$-DP if, for all neighboring datasets $D$ and $D'$ differing by one record and all measurable subsets $S$ of outputs, $\\Pr[\\mathcal{M}(D) \\in S] \\leq e^{\\epsilon} \\Pr[\\mathcal{M}(D') \\in S] + \\delta$.\n- Rényi Differential Privacy (RDP): For $\\alpha > 1$, a mechanism satisfies $(\\alpha,\\epsilon_{\\mathrm{RDP}})$-RDP if, for all neighboring $D,D'$, the Rényi divergence of order $\\alpha$ between output distributions is at most $\\epsilon_{\\mathrm{RDP}}$. Composition is additive in the RDP parameter, and any $(\\alpha,\\epsilon_{\\mathrm{RDP}})$-RDP mechanism implies $(\\epsilon,\\delta)$-DP for any $\\delta \\in (0,1)$ via $\\epsilon = \\epsilon_{\\mathrm{RDP}} + \\frac{\\log(1/\\delta)}{\\alpha - 1}$.\n\nTasks:\n1. Using the moments accountant viewpoint that tracks the log-moment (or equivalently Rényi divergence) of the privacy loss random variable, derive the leading-order behavior of the per-iteration Rényi differential privacy for the subsampled Gaussian mechanism in the small-sampling-rate regime $q \\ll 1$. Show how the additive composition over $T$ iterations provides a bound on the total Rényi differential privacy parameter $\\epsilon_{\\mathrm{RDP}}(\\alpha)$ for a given order $\\alpha$, and then convert this bound to $(\\epsilon,\\delta)$-DP using the relation $\\epsilon(\\alpha,\\delta) = \\epsilon_{\\mathrm{RDP}}(\\alpha) + \\frac{\\log(1/\\delta)}{\\alpha - 1}$.\n2. Implement a program that, given $N$, $B$, $\\sigma$, $\\delta$, and a list of epoch counts $\\{E_1,\\dots,E_m\\}$, computes the privacy curve $\\{\\epsilon(E_1),\\dots,\\epsilon(E_m)\\}$ by:\n   - Computing $q = B/N$.\n   - Computing the number of iterations per epoch $S = \\lceil N/B \\rceil$ and total iterations $T = S \\cdot E$ for each epoch $E$.\n   - For a fixed set of integer orders $\\alpha \\in \\{2,3,\\dots,64\\}$, computing the per-iteration Rényi differential privacy $\\epsilon_{\\mathrm{RDP,step}}(\\alpha)$ under the small-$q$ leading-order approximation, summing over $T$ iterations to get $\\epsilon_{\\mathrm{RDP,total}}(\\alpha) = T \\cdot \\epsilon_{\\mathrm{RDP,step}}(\\alpha)$, converting to $(\\epsilon,\\delta)$-DP via $\\epsilon(\\alpha,\\delta)$, and finally taking the minimum over $\\alpha$ to obtain the tightest bound $\\epsilon(E)$.\n   - Returning the list $\\{\\epsilon(E_1),\\dots,\\epsilon(E_m)\\}$ as floating-point numbers.\n3. Design and run the following test suite. For each parameter set, compute the privacy curve with the specified epochs. No physical units apply, and all outputs should be dimensionless floats.\n   - Test Case $1$ (happy path): $N = 60000$, $B = 256$, $\\sigma = 1.1$, $\\delta = 10^{-5}$, epochs $\\{0,1,5,10\\}$.\n   - Test Case $2$ (moderate sampling, lower noise): $N = 10000$, $B = 64$, $\\sigma = 0.8$, $\\delta = 10^{-6}$, epochs $\\{1,2,5\\}$.\n   - Test Case $3$ (very small sampling, long training): $N = 200000$, $B = 128$, $\\sigma = 1.0$, $\\delta = 10^{-6}$, epochs $\\{10,20,50\\}$.\n   - Test Case $4$ (very small sampling, high noise): $N = 50000$, $B = 32$, $\\sigma = 2.0$, $\\delta = 10^{-5}$, epochs $\\{1,5,20\\}$.\n4. Final Output Format: Your program should produce a single line of output containing the results as a comma-separated list of lists enclosed in square brackets, with no spaces. Each inner list corresponds to one test case and contains the computed $\\epsilon$ values for its epochs in the given order. For example, an output with two test cases and two epochs each should look like \"[[e11,e12],[e21,e22]]\".\n\nYour program must be self-contained, require no input, and run deterministically. All numerical calculations should use natural logarithms. Ensure numerically stable handling for the boundary case $E = 0$ by returning $\\epsilon = 0$ exactly.",
            "solution": "The user-provided problem is valid. It is scientifically grounded in the established principles of differential privacy, specifically the moments accountant and Rényi Differential Privacy (RDP) for analyzing the privacy loss of the subsampled Gaussian mechanism used in DP-SGD. The problem is well-posed, providing all necessary parameters and definitions for a unique, computable solution. The language is objective and unambiguous.\n\n### Step 1: Theoretical Derivation and Algorithmic Design\n\nThe problem requires us to determine the privacy loss, quantified by $(\\epsilon, \\delta)$-Differential Privacy (DP), for a model trained using Differentially Private Stochastic Gradient Descent (DP-SGD). The analysis will be conducted using the moments accountant framework, which is equivalent to tracking Rényi Differential Privacy (RDP) parameters.\n\nThe DP-SGD algorithm at each step involves three key operations:\n1.  Computing per-example gradients for a minibatch of data.\n2.  Clipping the $L_2$ norm of each per-example gradient to a maximum value $C$.\n3.  Aggregating the clipped gradients and adding Gaussian noise scaled by $\\sigma C$.\n\nThe privacy analysis centers on the **subsampled Gaussian mechanism**. A minibatch is formed by sampling $B$ examples from a dataset of size $N$ without replacement, corresponding to a sampling probability of $q = B/N$. The mechanism then adds zero-mean Gaussian noise with standard deviation $\\sigma C$ to the sum of the clipped gradients. The clipping ensures that the sensitivity of this sum is bounded by $C$.\n\n**Task 1: Derivation of the Privacy Bound**\n\nWe are asked to find the leading-order behavior of the per-iteration RDP parameter for the subsampled Gaussian mechanism in the small-sampling-rate regime ($q \\ll 1$) and compose it over multiple iterations.\n\nA mechanism is $(\\alpha, \\epsilon_{\\mathrm{RDP}})$-RDP if the Rényi divergence of order $\\alpha$ between its output distributions on any two neighboring datasets is at most $\\epsilon_{\\mathrm{RDP}}$. For the Gaussian mechanism (without subsampling) that adds noise $\\mathcal{N}(0, s^2)$ to a function with $L_2$ sensitivity $\\Delta$, the RDP parameter is $\\epsilon_{\\mathrm{RDP,Gauss}}(\\alpha) = \\frac{\\alpha \\Delta^2}{2s^2}$. In our case, the sensitivity after clipping is $C$ and the noise standard deviation is $\\sigma C$, so $\\Delta=C$ and $s=\\sigma C$. Thus, for the pure (non-subsampled) Gaussian mechanism, $\\epsilon_{\\mathrm{RDP,Gauss}}(\\alpha) = \\frac{\\alpha C^2}{2(\\sigma C)^2} = \\frac{\\alpha}{2\\sigma^2}$.\n\nThe analysis of the *subsampled* Gaussian mechanism is more complex. While a simple analysis using Poisson subsampling (a common approximation for sampling without replacement) yields a privacy cost of order $O(q)$, a tighter analysis specific to sampling without replacement reveals that for small $q$, the privacy cost is of order $O(q^2)$. This is a key result from the moments accountant literature. The leading-order approximation for the per-iteration RDP parameter, which we denote $\\epsilon_{\\mathrm{RDP,step}}(\\alpha)$, is given by:\n$$\n\\epsilon_{\\mathrm{RDP,step}}(\\alpha) \\approx \\frac{q^2 \\alpha}{2\\sigma^2}\n$$\nThis approximation is valid when $q\\alpha/\\sigma$ is small, a condition generally met in typical DP-SGD settings.\n\nRDP features a convenient composition property: the RDP parameters are additive over independent applications of a mechanism. If training proceeds for $T$ iterations, the total RDP cost, $\\epsilon_{\\mathrm{RDP,total}}(\\alpha)$, is simply the sum of the per-iteration costs:\n$$\n\\epsilon_{\\mathrm{RDP,total}}(\\alpha) = T \\cdot \\epsilon_{\\mathrm{RDP,step}}(\\alpha) = T \\frac{q^2 \\alpha}{2\\sigma^2}\n$$\n\nFinally, we convert this $(\\alpha, \\epsilon_{\\mathrm{RDP}})$-RDP guarantee into the more standard $(\\epsilon, \\delta)$-DP guarantee. The conversion formula is provided:\n$$\n\\epsilon(\\alpha, \\delta) = \\epsilon_{\\mathrm{RDP,total}}(\\alpha) + \\frac{\\log(1/\\delta)}{\\alpha - 1}\n$$\nSubstituting our expression for the total RDP gives:\n$$\n\\epsilon(\\alpha, \\delta) = T \\frac{q^2 \\alpha}{2\\sigma^2} + \\frac{\\log(1/\\delta)}{\\alpha - 1}\n$$\nThis expression gives a valid upper bound on $\\epsilon$ for any choice of order $\\alpha > 1$. To obtain the tightest possible bound, we must find the value of $\\alpha$ that minimizes this expression. The problem simplifies this optimization by restricting the search to a discrete set of integer orders.\n$$\n\\epsilon = \\min_{\\alpha \\in \\{2, 3, \\dots, 64\\}} \\left( T \\frac{q^2 \\alpha}{2\\sigma^2} + \\frac{\\log(1/\\delta)}{\\alpha - 1} \\right)\n$$\n\n**Task 2: Algorithm Implementation**\n\nThe algorithm to compute the privacy curve $\\{\\epsilon(E_1), \\dots, \\epsilon(E_m)\\}$ for a given set of epochs $\\{E_1, \\dots, E_m\\}$ proceeds as follows:\n\nFor each epoch count $E$ in the input list:\n1.  Handle the boundary case: if $E=0$, the privacy loss is $\\epsilon=0$ as no data has been processed.\n2.  Calculate the sampling probability $q = B/N$.\n3.  Calculate the number of training steps (iterations) per epoch, $S$. Since minibatches are sampled, one epoch corresponds to processing approximately $N$ records. This requires $N/B$ minibatches. We use the ceiling to ensure all data is seen at least once on average over many epochs: $S = \\lceil N/B \\rceil$. This can be computed with integer arithmetic as $(N + B - 1) // B$.\n4.  Calculate the total number of iterations $T = S \\cdot E$.\n5.  Initialize a variable `min_epsilon` to a very large number (infinity).\n6.  Iterate through the specified integer orders $\\alpha$ from $2$ to $64$.\n    a. For each $\\alpha$, calculate the $(\\epsilon, \\delta)$-DP bound:\n       $\\epsilon_\\alpha = T \\frac{q^2 \\alpha}{2\\sigma^2} + \\frac{\\log(1/\\delta)}{\\alpha - 1}$.\n    b. Update the minimum: `min_epsilon = min(min_epsilon, epsilon_alpha)`.\n7.  The result for epoch $E$ is the final `min_epsilon`.\n\nThis process is repeated for all specified epoch counts to generate the privacy curve. The final output is structured as a list of these curves, one for each test case. All logarithms are natural logarithms (base $e$).",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the differential privacy problem for the given test cases.\n    It computes the privacy curves (epsilon vs. epochs) for DP-SGD training\n    using the moments accountant method with a leading-order approximation.\n    \"\"\"\n\n    def compute_epsilon_curve(N, B, sigma, delta, epochs):\n        \"\"\"\n        Computes the privacy curve for a single parameter set.\n\n        Args:\n            N (int): Total number of data points in the dataset.\n            B (int): Batch size.\n            sigma (float): Noise multiplier.\n            delta (float): Target delta for (epsilon, delta)-DP.\n            epochs (list of int): A list of epoch counts to compute epsilon for.\n\n        Returns:\n            list of float: A list of computed epsilon values corresponding to the input epochs.\n        \"\"\"\n        results_for_case = []\n        q = B / N  # Sampling probability\n        if N == 0 or B == 0:\n            # Avoid division by zero, although not expected in test cases.\n            # If no data or no batches, no processing occurs.\n            return [0.0] * len(epochs)\n\n        # Number of steps per epoch, calculated using integer ceiling division\n        steps_per_epoch = (N + B - 1) // B\n\n        # Orders for Rényi DP, as specified in the problem\n        alphas = list(range(2, 65))\n        log_1_over_delta = np.log(1 / delta)\n\n        for E in epochs:\n            # Handle the boundary case E=0, where no training has occurred\n            if E == 0:\n                results_for_case.append(0.0)\n                continue\n\n            total_steps = steps_per_epoch * E\n            min_epsilon = float('inf')\n\n            # The leading-order approximation for RDP of the subsampled Gaussian mechanism\n            # is O(q^2). The per-step RDP is approx. (q^2 * alpha) / (2 * sigma^2).\n            # This is constant for a given alpha, so we can pre-calculate it.\n            rdp_const_factor = total_steps * (q**2) / (2 * sigma**2)\n\n            for alpha in alphas:\n                # Total RDP after T steps (additive composition)\n                total_rdp = rdp_const_factor * alpha\n                \n                # Convert from (alpha, epsilon_RDP)-RDP to (epsilon, delta)-DP\n                current_epsilon = total_rdp + log_1_over_delta / (alpha - 1)\n                \n                # Update the tightest bound\n                min_epsilon = min(min_epsilon, current_epsilon)\n            \n            results_for_case.append(min_epsilon)\n            \n        return results_for_case\n\n    # Test cases as defined in the problem statement\n    test_cases = [\n        # (N, B, sigma, delta, epochs list)\n        (60000, 256, 1.1, 1e-5, [0, 1, 5, 10]),\n        (10000, 64, 0.8, 1e-6, [1, 2, 5]),\n        (200000, 128, 1.0, 1e-6, [10, 20, 50]),\n        (50000, 32, 2.0, 1e-5, [1, 5, 20]),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        N, B, sigma, delta, epochs = case\n        result_curve = compute_epsilon_curve(N, B, sigma, delta, epochs)\n        all_results.append(result_curve)\n\n    # Format the final output string as specified: [[e11,e12],[e21,e22]]\n    inner_strings = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}