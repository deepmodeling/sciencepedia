## 引言
随着人工智能和控制技术的发展，自主系统正变得日益复杂和强大。然而，这些系统，尤其是那些采用深度学习等先进但难以形式化验证技术的系统，其行为的不可预测性也带来了前所未有的安全挑战。如何确保一辆自动驾驶汽车或一架自主无人机在追求最优性能的同时，绝不逾越安全的红线？这便是当前自主系统领域面临的核心知识鸿沟。[运行时保障](@entry_id:1131148)（Runtime Assurance, RA）范式正是为了解决这一难题而生，它通过在系统运行时进行持续的在线监控和干预，为复杂的自主系统提供了一道动态的安全防线。

本文将系统性地引导您深入理解[运行时保障](@entry_id:1131148)的世界。您将学习到：

- **原理与机制**：我们将剖析[运行时保障](@entry_id:1131148)系统的核心架构，深入探讨其背后的数学原理，如[控制屏障函数](@entry_id:177928)（CBF）和可行性理论，并探讨如何应对不确定性、混合系统以及学习型组件带来的挑战。
- **应用与跨学科连接**：我们将展示这些理论如何在[安全关键控制](@entry_id:174428)、模型预测控制等领域得到应用，并探讨如何弥合理论与实践之间的差距，同时揭示其与形式化方法、[网络安全](@entry_id:262820)及人机交互等领域的深刻联系。
- **动手实践**：最后，您将通过一系列精心设计的练习，亲手实现Simplex架构、基于CBF的安全滤波器，并分析其实时性约束，将理论知识转化为实践能力。

现在，让我们从构成一个可靠的[运行时保障](@entry_id:1131148)系统的基本原理与机制开始。

## 原理与机制

本章深入探讨[运行时保障](@entry_id:1131148)（Runtime Assurance, RA）的核心科学原理和关键实现机制。我们将从构成一个RA系统的基本架构入手，逐步解析其用于强制执行安全性的形式化方法，并探讨在面对不确定性、复杂系统模型及机器学习组件时所需的先进技术。最后，我们将讨论模块化设计、性能评估以及实时性约束等实际工程考量。

### [运行时保障](@entry_id:1131148)的核心架构与理念

一个典型的[运行时保障](@entry_id:1131148)系统建立在一个核心理念之上：允许一个高性能、但可能未经完全验证的先进控制器（advanced controller）在大部分时间主导系统，同时通过一个在线**安全监视器（safety monitor）**来保障系统的安全性。当且仅当监视器预测到先进控制器的行为可能导致危险时，控制权才会被一个权威性的**切换仲裁器（switching arbiter）**切换到一个预先验证过的、行为可预测的**基线安全控制器（baseline safe controller）**。

这个架构包含四个最小组成部分 ：
1.  **先进控制器 ($\pi_{\mathrm{adv}}$)**：一个以追求高性能（如效率、速度、任务完成度）为目标的控制器。它可能基于复杂的、难以形式化验证的技术，例如[深度神经网络](@entry_id:636170)。
2.  **基线安全控制器 ($\pi_{\mathrm{safe}}$)**：一个经过形式化验证的控制器，其唯一但关键的任务是确保系统在任何情况下都能维持在[安全状态](@entry_id:754485)。它的性能通常较为保守。
3.  **安全监视器**：一个在线模块，利用系统的状态估计 $\hat{x}(t)$ 和一个高精度的预测模型（通常称为**[数字孪生](@entry_id:171650)（Digital Twin, DT）**）来评估先进控制器 $\pi_{\mathrm{adv}}$ 的指令是否会在未来导致安全违规。
4.  **切换仲裁器**：一个拥有最终执行器控制权的决策模块。它根据监视器的判断，决定是将 $\pi_{\mathrm{adv}}$ 的指令传递给执行器，还是将其覆盖，转而执行 $\pi_{\mathrm{safe}}$ 的安全指令。

这种架构与另外两种常见的保障范式有着本质区别。**离线验证（Offline verification）**试图在系统运行前，基于模型假设来证明 $\pi_{\mathrm{adv}}$ 的安全性，但这对于[模型误差](@entry_id:175815)和未预见的环境扰动非常脆弱。**在线自适应（Online adaptation）**在运行时调整 $\pi_{\mathrm{adv}}$ 的参数以优化性能，但其本身并不提供严格的安全保证。[运行时保障](@entry_id:1131148)则通过在线监视和干预，为系统提供了一道动态的安全防线。

### 安全性的形式化：监视器的角色

要设计一个安全监视器，我们首先必须精确定义“安全”。在控制理论中，安全性通常被形式化为**状态[不变性](@entry_id:140168)（state invariance）**。

给定一个系统，其状态 $x(t)$ 在[状态空间](@entry_id:160914) $X \subseteq \mathbb{R}^n$ 中演化。一个**安[全集](@entry_id:264200)（safe set）** $S \subseteq X$ 定义了所有可接受的系统状态。安全目标就是确保系统的状态轨迹始终保持在 $S$ 内部，即对于所有 $t \ge 0$，都有 $x(t) \in S$。如果对于从集合 $C \subseteq S$ 内任意初始状态出发的所有轨迹，在某个控制策略下都能永远保持在 $C$ 内，那么这个集合 $C$ 就被称为**受控[不变集](@entry_id:275226)（controlled invariant set）**。

基于这个目标，监视器的角色可以从两个互补的视角来理解 ：

- **基于状态的监视器**：这是控制理论中的经典视角。监视器在每个时刻 $t$ 评估先进控制器提出的控制输入 $u_t$。它利用系统的动态模型 $x_{t+1} = f(x_t, u_t, w_t)$（其中 $w_t$ 是外部扰动）来预测，在所有可能的扰动下，下一个状态 $x_{t+1}$ 是否仍会保持在一个已知的受控[不变集](@entry_id:275226) $C$ 内。如果预测结果显示存在脱离 $C$ 的风险，监视器将拒绝 $u_t$，并用来自安全控制器 $\pi_{\mathrm{safe}}$ 的安全输入 $u_t^{\mathrm{safe}}$ 进行**替换（replacement）**。这种监视器强制执行的是与系统动态模型紧密相关的状态不变性属性。

- **基于迹的防护（Shielding）**：这是源于形式化方法和计算机科学的视角。它将系统行为看作是输入/输出的交互序列或“迹”（trace）。安全属性被定义为一组允许的迹，其特征是任何违规行为都可以通过一个有限的“坏前缀”（bad prefix）来识别。一个**防护（shield）**模块会在线检查控制器将要产生的输出是否会形成一个坏前缀。如果会，它会通过最小化修改来**编辑（editing）**该输出，以避免违规，而不是完全替换控制器。这种机制能够强制执行所有可通过确定性安全自动机识别的前缀封闭类安全属性。

尽管两种视角在术语和侧重点上有所不同，但其核心思想是相通的：通过在线预测和干预来阻止系统进入[不安全状态](@entry_id:756344)。在接下来的讨论中，我们主要聚焦于基于状态的监视器，因为它与自主系统的物理动态紧密相关。

### 基于状态的安全监视机制

一个现代安全监视器的核心是其预测和决策的数学机制。[控制屏障函数](@entry_id:177928)（Control Barrier Functions）为此提供了一个强大而实用的框架。

#### [控制屏障函数](@entry_id:177928)（Control Barrier Functions, CBFs）

考虑一个由[控制仿射系统](@entry_id:168741)描述的自主系统，其动态方程为 $\dot{x} = f(x) + g(x)u$，其中 $x$ 是状态， $u$ 是控制输入。我们可以使用一个连续可微的函数 $h: \mathbb{R}^n \to \mathbb{R}$ 来定义安[全集](@entry_id:264200)，即 $S = \{x \in \mathbb{R}^n : h(x) \ge 0\}$。该[集合的边界](@entry_id:144240)是 $\partial S = \{x \in \mathbb{R}^n : h(x) = 0\}$。为了使集合 $S$ 成为**前向[不变集](@entry_id:275226)（forward invariant set）**，即轨迹一旦进入就不会离开，我们必须确保每当状态 $x$ 接近边界时，其运动方向不会指向集合的外部。

$h(x)$ 的值可以被看作是“安全裕度”。当 $h(x) \gt 0$ 时，系统是安全的；当 $h(x) = 0$ 时，系统处于安全边界；当 $h(x) \lt 0$ 时，系统处于[不安全状态](@entry_id:756344)。为了保持安全，我们必须防止 $h(x)$ 从正值变为负值。一个直观的要求是，当 $h(x)$ 趋近于0时，它的时间导数 $\dot{h}(x)$ 应该是非负的。

通过链式法则，我们可以计算 $\dot{h}(x)$：
$$
\dot{h}(x) = \frac{\partial h}{\partial x} \dot{x} = \nabla h(x) \cdot (f(x) + g(x)u)
$$
使用**[李导数](@entry_id:171745)（Lie derivative）**的记法，即 $L_f h(x) = \nabla h(x) \cdot f(x)$ 和 $L_g h(x) = \nabla h(x) \cdot g(x)$，上式可以写为：
$$
\dot{h}(x) = L_f h(x) + L_g h(x)u
$$
**[控制屏障函数](@entry_id:177928)（CBF）**为我们提供了一个确保[前向不变性](@entry_id:170094)的充分条件 。如果存在一个扩展$\mathcal{K}$[类函数](@entry_id:146970) $\alpha$（即 $\alpha$ 是连续、严格递增且 $\alpha(0)=0$ 的函数），使得对于任何状态 $x$，我们总能找到一个控制输入 $u$，满足以下不等式：
$$
L_f h(x) + L_g h(x)u + \alpha(h(x)) \ge 0
$$
那么，任何强制执行此不等式的控制器都能确保集合 $S$ 是前向不变的。这个不等式被称为 **CBF约束（CBF constraint）**。它定义了一个状态依赖的安全控制输入集合 $K_{cbf}(x) = \{u \in U \mid L_f h(x) + L_g h(x)u + \alpha(h(x)) \ge 0\}$。

在[运行时保障](@entry_id:1131148)中，监视器可以在每个时间点求解一个**二次规划（Quadratic Program, QP）**问题，来从先进控制器 $\pi_{\mathrm{adv}}$ 提出的指令 $u_{\mathrm{adv}}$ 中找到一个既安全又与之最接近的实际控制指令 $u^\star$：
$$
\begin{aligned}
u^\star(x) = \arg\min_{u \in U}  \quad \|u - u_{\mathrm{adv}}(x)\|^2 \\
\text{s.t.}  \quad L_f h(x) + L_g h(x)u + \alpha(h(x)) \ge 0
\end{aligned}
$$
这种基于QP的监视器能够以最小的干预代价来确保安全，是当前[运行时保障](@entry_id:1131148)领域最主流的实现方式之一。

#### 应对不确定性的鲁棒监视

真实世界的系统总是伴随着不确定性。一个鲁棒的[运行时保障](@entry_id:1131148)系统必须能在存在不确定性的情况下提供安全保证。这些不确定性主要分为两类 ：
- **[参数不确定性](@entry_id:264387)（Parametric Uncertainty）**：系统模型结构已知，但其中某些参数的真实值 $\theta^\star$ 未知，仅知道其位于一个已知的[紧集](@entry_id:147575) $\Theta$ 内。
- **未建模不确定性（Unmodeled Uncertainty）**：由模型简化、高频动态或外部扰动引起的、未被包含在基本模型中的附加项 $w(x,u,t)$，通常我们只知道其范数[上界](@entry_id:274738)，例如 $\|w\| \le \Delta(x,u)$。

假设一个系统的真实动态为 $\dot{x} = f(x,u,\theta^\star) + w(x,u,t)$。为了保证安全，CBF约束必须在所有可能的不确定性实现下都成立。这意味着监视器必须考虑最坏情况。最坏情况是指不确定性 $(\theta, w)$ 的组合会最大限度地减小 $\dot{h}(x)$ 的值，从而最有力地将系统推向不安全区域。

鲁棒的CBF约束要求对于任意状态 $x$，存在一个控制 $u$，使得对于**所有**可能的 $\theta \in \Theta$ 和 **所有**可能的 $w \in \mathcal{W}(x,u)$，$\dot{h}(x) + \alpha(h(x)) \ge 0$ 都成立。这等价于：
$$
\inf_{\theta \in \Theta, w \in \mathcal{W}(x,u)} \left[ \nabla h(x) \cdot (f(x,u,\theta) + w) \right] + \alpha(h(x)) \ge 0
$$
这个最坏情况的表达式可以分解为对参数不确定性和未建模不确定性的分别处理：
$$
\inf_{\theta \in \Theta} \left[ \nabla h(x) \cdot f(x,u,\theta) \right] + \inf_{w \in \mathcal{W}(x,u)} \left[ \nabla h(x) \cdot w \right] + \alpha(h(x)) \ge 0
$$
对于未建模不确定性项，如果 $w$ 的范数有界 $\|w\| \le \Delta(x,u)$，那么根据广义柯西-[施瓦茨不等式](@entry_id:202153)，其最坏影响为 $\inf_{w} [\nabla h(x) \cdot w] = -\|\nabla h(x)\|_\star \Delta(x,u)$，其中 $\|\cdot\|_\star$ 是 $\|\cdot\|$ 的[对偶范数](@entry_id:200340)。

因此，一个鲁棒的监视器需要强制执行的CBF约束变为：
$$
\inf_{\theta \in \Theta} \left[ \nabla h(x) \cdot f(x,u,\theta) \right] - \|\nabla h(x)\|_\star \Delta(x,u) + \alpha(h(x)) \ge 0
$$
这个不等式将不确定性的最坏影响直接内嵌到了安全条件中，从而为系统提供了可靠的鲁棒安全保证。

#### 应对学习型组件的挑战

现代自主系统越来越多地采用**学习型组件（Learning-Enabled Components, LECs）**，例如基于[深度学习](@entry_id:142022)的策略网络 $\pi_\theta$。这些组件为[运行时保障](@entry_id:1131148)带来了新的挑战 ：
1.  **不[确定性与随机性](@entry_id:636235)**：LECs的输出可能是随机的（例如，从一个策略分布中采样得到动作），或者在面对训练分布之外的数据（distribution shift）时表现出不可预测的[非确定性](@entry_id:273591)行为。
2.  **缺乏形式化证书**：与传统的控制器不同，为复杂的LECs（如大型神经网络）提供关于其行为的绝对形式化保证（即证书）是极其困难的。

这些特性意味着，在LECs采取行动之前，监视器无法确切知道它将产生哪个具体的控制指令。相反，监视器只能认为LECs可能从一个动作集合 $\mathcal{U}_{LEC}(x)$ 中选择一个动作。

为了在这种情况下保证安全，监视器必须采取**[最坏情况分析](@entry_id:168192)**。它必须验证，对于从 $\mathcal{U}_{LEC}(x)$ 中**任何可能**被选择的动作 $u$，系统的下一个状态都将是安全的。也就是说，监视器需要检查集合包含关系 $f(x, \mathcal{U}_{LEC}(x)) \subseteq S$ 是否成立。如果这个条件不满足，或者如果监视器无法在运行时有效地计算出一个可靠的 $\mathcal{U}_{LEC}(x)$ 的[上界](@entry_id:274738)，那么它就必须拒绝LECs的控制权，并切换到安全的基线控制器 $\mu(x)$ 。这种保守但必要的方法是确保含有学习型组件的系统安全的关键。

### 理论基础与先进系统模型

为了更深刻地理解和应用[运行时保障](@entry_id:1131148)，我们需要探索其背后的理论基础，并将其扩展到更复杂的系统模型。

#### 可行性理论（Viability Theory）

可行性理论为长期[安全保证](@entry_id:1131169)提供了坚实的数学基础。它关注的核心问题是：从哪些初始状态出发，系统有可能通过选择合适的控制策略来永远保持在安[全集](@entry_id:264200) $S$ 内？

这个问题的答案是**可行性核（Viability Kernel）**，记为 $\mathrm{Viab}(S)$ 。它被定义为安全集 $S$ 中所有初始状态 $x_0$ 的集合，对于其中每一个状态，都**存在**一个[控制函数](@entry_id:183140) $u(\cdot)$，使得系统的轨迹 $x(t; x_0, u)$ 对于所有未来时间 $t \ge 0$ 都保持在 $S$ 内。
$$
\mathrm{Viab}(S) = \left\{ x_0 \in S \mid \exists u(\cdot) \text{ s.t. } x(t; x_0, u) \in S \ \forall t \ge 0 \right\}
$$
可行性核是 $S$ 的**最大受控不变子集**。它是所有包含在 $S$ 内的受控不变集的并集。

可行性核的实践意义是巨大的：它精确地划分了“可挽救”和“不可避免地失败”的状态。只要系统的状态 $x(t)$ 保持在 $\mathrm{Viab}(S)$ 内，就总有办法维持安全。一旦状态脱离了 $\mathrm{Viab}(S)$，无论后续采取何种控制措施，轨迹最终都将离开安全集 $S$。因此，一个理想的安全监视器的根本任务，就是确保闭环系统的状态轨迹永远不会离开可行性核 。

另一个相关概念是**后向[可达集](@entry_id:276191)（Backward Reachable Set）**。不安全集 $S^c$ 在时间 $[0, \tau]$ 内的后向[可达集](@entry_id:276191) $\mathcal{R}_{\tau}^{-}(S^c)$ 是所有能够在 $\tau$ 时间内被某个控制策略驱动到 $S^c$ 的初始状态的集合。这些集合的计算对于离线分析安全边界和设计监视器策略非常有价值。

#### [混合系统](@entry_id:271183)（Hybrid Systems）

许多自主系统，如[自动驾驶](@entry_id:270800)汽车，其行为不能仅用连续动态来描述，它们还包含离散的模式切换。这类系统被称为**[混合系统](@entry_id:271183)（Hybrid Systems）**。一个混合系统模型通常包括 ：
- **模式（Modes）** $Q$：系统的离散状态，如车辆的“巡航”、“刹车”、“紧急制动”模式。
- **连续动态** $f_q(x,u)$：在每个模式 $q \in Q$ 下，系统的连续状态 $x$ 的演化规律。
- **[不变集](@entry_id:275226)（Invariants）** $\mathrm{Inv}(q)$：在模式 $q$ 下，连续状态 $x$ 必须满足的约束。例如，巡航模式下的速度上限。
- **守卫（Guards）** $\mathrm{Guard}(q,q')$：一个状态子集，当 $x$ 进入该子集时，从模式 $q$ 到 $q'$ 的转换被触发。例如，与前车距离小于某个阈值时，触发从“巡航”到“刹车”的转换。
- **重置映射（Reset Maps）** $R_{q,q'}$：在发生转换时，对连续状态进行瞬时更新的规则。

为混合系统设计安全监视器，其任务变得更加复杂。监视器不仅要保证连续演化（流，flow）的安全性，还要保证离散切换（跳，jump）的安全性：
1.  **流安全**：在任何模式 $q$ 下，监视器必须确保在先进控制器的指令下，系统的预测轨迹不会违反该模式的[不变集](@entry_id:275226) $\mathrm{Inv}(q)$。
2.  **跳安全**：当监视器预测到系统的轨迹将要触发一个守卫 $\mathrm{Guard}(q,q')$ 时，它必须验证经过重置映射 $R_{q,q'}$ 后的新状态是否位于目标模式 $q'$ 的[不变集](@entry_id:275226) $\mathrm{Inv}(q')$ 内部。

在存在不确定性的情况下，监视器需要计算**前向可达管（forward reachable tube）**——即未来所有可能状态的集合——并验证该管集是否满足上述流安全和跳安全条件 。如果任一条件可能被违反，监视器必须立即介入，例如强制切换到一个经过验证的安全模式。

### 模块化设计与监视器性能

在复杂的系统中，组件的模块化设计和性能评估至关重要。

#### [假设-保证合约](@entry_id:1121149)（Assume-Guarantee Contracts）

当一个大型系统由多个组件构成时，为整个系统进行整体验证可能非常困难。**[假设-保证合约](@entry_id:1121149)（Assume-Guarantee Contracts）**提供了一种模块化的验证方法 。一个合约 $(A,G)$ 指定：如果组件所处的环境满足假设（Assumption） $A$，那么该组件承诺满足保证（Guarantee） $G$。

形式上，对于一个组件 $\mathcal{M}$，它满足合约 $(A,G)$ 是指：对于其所有可能的行为迹 $\sigma$，如果该迹的输入部分 $\sigma_I$ 满足 $A$（记为 $\sigma_I \models A$），那么整个行为迹 $\sigma$ 必须满足 $G$（记为 $\sigma \models G$）。
$$
\forall \sigma \in \mathcal{B}(\mathcal{M}), \quad (\sigma_I \models A) \implies (\sigma \models G)
$$
运行时监视器可以用来强制执行这类合约。监视器会在线观察系统的输入迹。只要输入迹没有违反假设 $A$，监视器就会强制执行保证 $G$（对于安全属性，这意味着阻止坏前缀的发生）。如果环境违反了假设 $A$，那么组件的保证义务就被解除，监视器可以切换到其他安全策略，但从合约的角度看，系统并未违规。

#### 监视器的正确性：[可靠性与完备性](@entry_id:148267)

一个监视器的性能可以用两个关键指标来衡量：**可靠性（Soundness）**和**完备性（Completeness）** 。假设安全违规是由一系列“坏前缀” $B$ 来定义的。
- **可靠性**：如果一个监视器是可靠的，那么它的每一次警报都是真实的。也就是说，如果监视器对某个前缀 $w$ 发出警报，那么 $w$ 必须是一个真正的坏前缀（$w \in B$）。一个不可靠的监视器会产生**[假阳性](@entry_id:197064)（false positives）**，即“狼来了”的假警报。这会降低系统的性能，因为不必要的安全干预会被触发。
- **完备性**：如果一个监视器是完备的，那么它绝不会错过任何一次安全违规。也就是说，对于任何最终会违规的[系统轨迹](@entry_id:1132840)，监视器总能在其某个前缀处发出警报。一个不完备的监视器会产生**假阴性（false negatives）**，即未能检测到已经发生的危险。这对于安全关键系统是极其危险的。

在实践中，尤其是在存在不确定性的情况下，可靠性和完备性之间常常存在权衡。例如，一个基于[可达集](@entry_id:276191)计算的监视器，如果它使用真实可达集的**过近似（over-approximation）**进行预测，它将是完备的（不会错过任何危险），但可能会产生[假阳性](@entry_id:197064)（因为近似集可能触及危险区域，而真实集没有）。相反，如果它使用**欠近似（under-approximation）**，它将是可靠的（任何警报都是真实的），但可能会错过某些危险，因而是不完备的 。

#### 实时性约束

最后，安全监视器本身是一个在嵌入式处理器上运行的软件任务。它的计算必须在一个控制周期内完成，否则其决策将是过时的，可能导致安全失效。因此，监视器必须满足**实时性约束（real-time constraints）** 。

**最坏情况执行时间（Worst-Case Execution Time, WCET）**是一个关键度量，它指的是一个任务在特定硬件上无中断执行所可能需要的最大时间。这必须通过[静态分析](@entry_id:755368)或严谨的测量来确定，而不能使用平均执行时间，因为后者无法提供确定性保证。

在[运行时保障](@entry_id:1131148)架构中，安全监视器 ($\tau_m$)、控制器 ($\tau_c$) 以及[数字孪生](@entry_id:171650)预测器 ($\tau_d$) 等都是周期性任务，它们共同竞争处理器资源。[实时调度](@entry_id:754136)理论，如**最早截止期优先（Earliest Deadline First, EDF）**或**[速率单调调度](@entry_id:754083)（Rate Monotonic Scheduling, RMS）**，被用来分析整个任务集是否“可调度”，即是否所有任务都能在各自的截止日期前完成。例如，对于一组独立的、可抢占的周期任务，如果总的处理器利用率 $\sum_i C_i/T_i$（其中 $C_i$ 是WCET，$T_i$ 是周期）不超过1，那么该任务集在EDF下是可调度的 。确保包括监视器在内的所有关键任务满足实时性要求，是构建一个可信赖的[运行时保障](@entry_id:1131148)系统的最后但同样重要的一环。