{
    "hands_on_practices": [
        {
            "introduction": "数字孪生的一个核心功能是实时追踪物理系统的状态。由于过程噪声和模型不确定性的存在，我们不仅需要估计状态本身，还必须量化其不确定性。本练习  演示了如何通过对非线性动态模型进行线性化，来推导和计算状态不确定性（以协方差矩阵表示）在一个时间步长内的传播，这是扩展卡尔曼滤波器等高级估计算法的基石。",
            "id": "4253077",
            "problem": "一个信息物理系统（CPS）部署了一个单连杆旋转元件的数字孪生，其离散时间状态 $x_t$ 由角度 $\\theta_t$ 和角速度 $\\omega_t$ 组成，记为 $x_t = \\begin{pmatrix} \\theta_t \\\\ \\omega_t \\end{pmatrix}$。该数字孪生在一个带有加性过程噪声的非线性离散时间动态模型下演化，\n$$\nx_{t+1} = f(x_t) + w_t,\n$$\n其中 $w_t$ 是一个零均值高斯随机向量，其协方差矩阵为 $Q$，且与 $x_t$ 无关。动力学由下式给出\n$$\nf(x_t) = \n\\begin{pmatrix}\n\\theta_t + \\Delta t \\,\\omega_t \\\\\n\\omega_t + \\Delta t \\left( -\\alpha \\,\\sin(\\theta_t) - \\beta \\,\\omega_t \\right)\n\\end{pmatrix},\n$$\n其中采样间隔为 $\\Delta t$，类重力系数为 $\\alpha$，粘性阻尼系数为 $\\beta$。假设角度单位为弧度。\n\n在时间 $t$，数字孪生的置信度（先验）是一个高斯分布，其均值为\n$$\n\\mu_t = \\begin{pmatrix} 0.3 \\\\ 0.1 \\end{pmatrix},\n$$\n协方差为\n$$\nP_t = \\begin{pmatrix} 0.01  & 0.002 \\\\ 0.002  & 0.04 \\end{pmatrix}.\n$$\n过程噪声的协方差为\n$$\nQ = \\begin{pmatrix} 1 \\times 10^{-5}  & 0 \\\\ 0  & 2 \\times 10^{-5} \\end{pmatrix}.\n$$\n已知的物理参数为 $\\Delta t = 0.05$，$\\alpha = 3.0$ 和 $\\beta = 0.4$。\n\n仅从协方差的定义出发，\n$$\n\\mathrm{Cov}(y) = \\mathbb{E}\\left[ (y - \\mathbb{E}[y]) (y - \\mathbb{E}[y])^{\\top} \\right],\n$$\n结合 $w_t$ 与 $x_t$ 的独立性，以及 $f(x_t)$ 在均值 $\\mu_t$ 附近的一阶泰勒线性化，推导 $x_{t+1}$ 的一阶协方差传播，并计算时间 $t+1$ 时预测协方差矩阵的行列式。使用在 $\\mu_t$ 处有效的线性化，并对所有需要的量进行数值计算。将最终答案四舍五入至五位有效数字。使用弧度作为角度单位、弧度/秒作为角速度单位，以基本单位表示该行列式。只需给出最终的数值（在您报告的最终值中不要包含单位）。作为背景，此设置是用于信息物理系统（CPS）数字孪生中的扩展卡尔曼滤波器（EKF）的典型配置，但您必须从前述基本定义出发，而不能使用任何现成的传播公式。",
            "solution": "本题要求推导一个离散时间非线性系统的一阶协方差传播，并计算在时间 $t+1$ 的预测协方差矩阵的行列式。推导必须从协方差的基本定义开始。\n\n在时间 $t$，系统的状态是随机向量 $x_t = \\begin{pmatrix} \\theta_t \\\\ \\omega_t \\end{pmatrix}$。其分布近似为均值为 $\\mu_t$、协方差为 $P_t$ 的高斯分布。系统根据以下方程演化：\n$$\nx_{t+1} = f(x_t) + w_t\n$$\n其中 $w_t$ 是一个零均值高斯噪声向量，其协方差为 $Q$，且与 $x_t$ 无关。\n\n在时间 $t+1$ 的预测状态协方差，记作 $P_{t+1}$，定义为：\n$$\nP_{t+1} = \\mathrm{Cov}(x_{t+1}) = \\mathbb{E}\\left[ (x_{t+1} - \\mathbb{E}[x_{t+1}]) (x_{t+1} - \\mathbb{E}[x_{t+1}])^{\\top} \\right]\n$$\n\n首先，我们近似预测均值 $\\mu_{t+1} = \\mathbb{E}[x_{t+1}]$。\n$$\n\\mu_{t+1} = \\mathbb{E}[f(x_t) + w_t] = \\mathbb{E}[f(x_t)] + \\mathbb{E}[w_t]\n$$\n由于 $w_t$ 是零均值的，所以 $\\mathbb{E}[w_t] = 0$。对于项 $\\mathbb{E}[f(x_t)]$，我们使用 $f(x_t)$ 在均值 $\\mu_t$ 附近的一阶泰勒级数展开：\n$$\nf(x_t) \\approx f(\\mu_t) + F_t (x_t - \\mu_t)\n$$\n其中 $F_t$ 是 $f(x_t)$ 在 $\\mu_t$ 处求值的雅可比矩阵，即 $F_t = \\frac{\\partial f}{\\partial x_t} \\Big|_{x_t = \\mu_t}$。\n取期望，我们得到：\n$$\n\\mathbb{E}[f(x_t)] \\approx \\mathbb{E}[f(\\mu_t) + F_t (x_t - \\mu_t)] = f(\\mu_t) + F_t (\\mathbb{E}[x_t] - \\mu_t)\n$$\n由于 $\\mathbb{E}[x_t] = \\mu_t$，第二项变为零，从而得到近似式 $\\mathbb{E}[f(x_t)] \\approx f(\\mu_t)$。\n因此，预测均值为 $\\mu_{t+1} \\approx f(\\mu_t)$。\n\n接下来，我们推导预测协方差 $P_{t+1}$ 的表达式。我们将 $x_{t+1}$ 的线性化表达式和 $\\mu_{t+1}$ 的近似值代入协方差定义中：\n$$\nx_{t+1} - \\mu_{t+1} \\approx \\left( f(\\mu_t) + F_t(x_t - \\mu_t) + w_t \\right) - f(\\mu_t) = F_t(x_t - \\mu_t) + w_t\n$$\n所以，$P_{t+1}$ 可以写作：\n$$\nP_{t+1} \\approx \\mathbb{E}\\left[ \\left( F_t(x_t - \\mu_t) + w_t \\right) \\left( F_t(x_t - \\mu_t) + w_t \\right)^{\\top} \\right]\n$$\n展开期望内的乘积：\n$$\nP_{t+1} \\approx \\mathbb{E}\\left[ F_t(x_t - \\mu_t)(x_t - \\mu_t)^{\\top}F_t^{\\top} + F_t(x_t - \\mu_t)w_t^{\\top} + w_t(x_t - \\mu_t)^{\\top}F_t^{\\top} + w_t w_t^{\\top} \\right]\n$$\n利用期望的线性性质：\n$$\nP_{t+1} \\approx \\mathbb{E}[F_t(x_t - \\mu_t)(x_t - \\mu_t)^{\\top}F_t^{\\top}] + \\mathbb{E}[F_t(x_t - \\mu_t)w_t^{\\top}] + \\mathbb{E}[w_t(x_t - \\mu_t)^{\\top}F_t^{\\top}] + \\mathbb{E}[w_t w_t^{\\top}]\n$$\n我们对每一项进行求值：\n1.  $\\mathbb{E}[F_t(x_t - \\mu_t)(x_t - \\mu_t)^{\\top}F_t^{\\top}] = F_t \\mathbb{E}[(x_t - \\mu_t)(x_t - \\mu_t)^{\\top}] F_t^{\\top} = F_t P_t F_t^{\\top}$，因为 $P_t = \\mathrm{Cov}(x_t)$。\n2.  $\\mathbb{E}[F_t(x_t - \\mu_t)w_t^{\\top}] = F_t \\mathbb{E}[(x_t - \\mu_t)w_t^{\\top}]$。由于 $x_t$ 和 $w_t$ 是独立的，$\\mathbb{E}[(x_t - \\mu_t)w_t^{\\top}] = \\mathbb{E}[x_t - \\mu_t]\\mathbb{E}[w_t^{\\top}] = (\\mu_t - \\mu_t) \\cdot 0^{\\top} = 0$。\n3.  第三项是第二项的转置，因此也为零。\n4.  $\\mathbb{E}[w_t w_t^{\\top}]$。由于 $\\mathbb{E}[w_t]=0$，根据定义，这是 $w_t$ 的协方差，即 $Q$。\n\n综合这些结果，我们得到一阶协方差传播公式：\n$$\nP_{t+1} \\approx F_t P_t F_t^{\\top} + Q\n$$\n\n现在，我们进行数值计算。\n首先，我们求雅可比矩阵 $F_t$。函数 $f(x_t)$ 为：\n$$\nf(x_t) = \n\\begin{pmatrix}\nf_1(\\theta_t, \\omega_t) \\\\\nf_2(\\theta_t, \\omega_t)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\theta_t + \\Delta t \\,\\omega_t \\\\\n\\omega_t + \\Delta t \\left( -\\alpha \\,\\sin(\\theta_t) - \\beta \\,\\omega_t \\right)\n\\end{pmatrix}\n$$\n雅可比矩阵为 $F_t = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial \\theta_t} & \\frac{\\partial f_1}{\\partial \\omega_t} \\\\ \\frac{\\partial f_2}{\\partial \\theta_t} & \\frac{\\partial f_2}{\\partial \\omega_t} \\end{pmatrix}$。偏导数是：\n$$\n\\frac{\\partial f_1}{\\partial \\theta_t} = 1 \\quad\\quad \\frac{\\partial f_1}{\\partial \\omega_t} = \\Delta t\n$$\n$$\n\\frac{\\partial f_2}{\\partial \\theta_t} = -\\alpha \\Delta t \\cos(\\theta_t) \\quad\\quad \\frac{\\partial f_2}{\\partial \\omega_t} = 1 - \\beta \\Delta t\n$$\n给定 $\\Delta t = 0.05$，$\\alpha = 3.0$ 和 $\\beta = 0.4$。我们在 $\\mu_t = \\begin{pmatrix} 0.3 \\\\ 0.1 \\end{pmatrix}$ 处计算雅可比矩阵，所以我们使用 $\\theta_t = 0.3$：\n$$\nF_t = \\begin{pmatrix}\n1 & 0.05 \\\\\n-3.0 \\times 0.05 \\cos(0.3) & 1 - 0.4 \\times 0.05\n\\end{pmatrix}\n= \\begin{pmatrix}\n1 & 0.05 \\\\\n-0.15 \\cos(0.3) & 0.98\n\\end{pmatrix}\n$$\n使用 $\\cos(0.3) \\approx 0.95533649$，我们有：\n$$\nF_t \\approx \\begin{pmatrix}\n1 & 0.05 \\\\\n-0.14330047 & 0.98\n\\end{pmatrix}\n$$\n给定的协方差矩阵是 $P_t = \\begin{pmatrix} 0.01 & 0.002 \\\\ 0.002 & 0.04 \\end{pmatrix}$ 和 $Q = \\begin{pmatrix} 10^{-5} & 0 \\\\ 0 & 2 \\times 10^{-5} \\end{pmatrix}$。\n\n我们计算 $F_t P_t F_t^{\\top}$：\n$$\nF_t P_t \\approx \\begin{pmatrix} 1 & 0.05 \\\\ -0.14330047 & 0.98 \\end{pmatrix} \\begin{pmatrix} 0.01 & 0.002 \\\\ 0.002 & 0.04 \\end{pmatrix} = \\begin{pmatrix} 0.0101 & 0.004 \\\\ 0.000526995 & 0.03891340 \\end{pmatrix}\n$$\n$$\nF_t P_t F_t^{\\top} \\approx \\begin{pmatrix} 0.0101 & 0.004 \\\\ 0.000526995 & 0.03891340 \\end{pmatrix} \\begin{pmatrix} 1 & -0.14330047 \\\\ 0.05 & 0.98 \\end{pmatrix}\n$$\n$$\nF_t P_t F_t^{\\top} \\approx \\begin{pmatrix} 0.0103 & 0.002472665 \\\\ 0.002472665 & 0.03805961 \\end{pmatrix}\n$$\n现在，我们计算 $P_{t+1} = F_t P_t F_t^{\\top} + Q$：\n$$\nP_{t+1} \\approx \\begin{pmatrix} 0.0103 & 0.002472665 \\\\ 0.002472665 & 0.03805961 \\end{pmatrix} + \\begin{pmatrix} 0.00001 & 0 \\\\ 0 & 0.00002 \\end{pmatrix}\n$$\n$$\nP_{t+1} \\approx \\begin{pmatrix} 0.01031 & 0.002472665 \\\\ 0.002472665 & 0.03807961 \\end{pmatrix}\n$$\n最后，我们计算 $P_{t+1}$ 的行列式：\n$$\n\\det(P_{t+1}) \\approx (0.01031)(0.03807961) - (0.002472665)^2\n$$\n$$\n\\det(P_{t+1}) \\approx 0.00039260078 - 0.00000611410\n$$\n$$\n\\det(P_{t+1}) \\approx 0.00038648668\n$$\n四舍五入到五位有效数字，结果是 $0.00038649$。",
            "answer": "$$\n\\boxed{3.8649 \\times 10^{-4}}\n$$"
        },
        {
            "introduction": "除了状态不确定性，数字孪生模型中的物理参数（如控制增益或材料属性）本身也常常是不确定的。本练习  探讨了如何使用贝叶斯推断，根据一次测量数据来校准一个不确定参数。更重要的是，它引导我们分析后验估计结果对先验假设的敏感性，这是进行稳健不确定性量化分析的关键一步。",
            "id": "4253100",
            "problem": "一个信息物理系统 (Cyber-Physical System, CPS) 的数字孪生 (Digital Twin, DT) 被用于从测量数据中校准一个标量控制增益参数 $\\theta$。该数字孪生采用带有加性高斯噪声的线性测量模型：观测到的标量 $y$ 满足 $y = x \\theta + \\varepsilon$，其中 $\\varepsilon$ 是均值为零、方差为 $\\sigma^{2}$ 的高斯噪声，而 $x$ 是一个已知的标量输入。在 $\\theta$ 上设置了均值为 $\\mu_{0}$、精度（方差的倒数）为 $\\lambda_{0}$ 的高斯先验，即 $\\theta \\sim \\mathcal{N}(\\mu_{0}, 1/\\lambda_{0})$。\n\n作为不确定性量化分析的一部分，考虑后验均值对先验精度的敏感性。具体来说，假设先验精度被扰动为 $\\lambda = \\lambda_{0} + \\delta\\lambda$，其中 $|\\delta\\lambda|$ 很小。仅从贝叶斯定理以及高斯似然和高斯先验的定义出发，推导后验均值 $m(\\lambda)$ 作为 $\\lambda$ 的函数形式，然后计算由该扰动引起的后验均值的一阶变化 $\\Delta m$，其由线性近似 $\\Delta m \\approx \\left.\\frac{d m}{d \\lambda}\\right|_{\\lambda=\\lambda_{0}} \\delta\\lambda$ 定义。\n\n使用以下代表在线数字孪生校准步骤的数值指定场景：\n$x = 3$，$y = 2$，$\\sigma^{2} = 1.5$，$\\mu_{0} = 0.5$，$\\lambda_{0} = 4$，以及 $\\delta\\lambda = 0.1$。\n\n报告从一阶近似中获得的单个实数值 $\\Delta m$。将您的答案四舍五入到 $5$ 位有效数字。以小数或标准科学记数法表示答案。",
            "solution": "本题要求我们推导后验均值 $m(\\lambda)$ 作为先验精度 $\\lambda$ 的函数，然后计算其关于 $\\lambda$ 的一阶变化。\n\n**第 1 部分：推导后验均值 $m(\\lambda)$**\n\n我们从贝叶斯定理开始，后验概率密度 $p(\\theta | y)$ 正比于似然函数 $p(y | \\theta)$ 和先验分布 $p(\\theta)$ 的乘积：\n$$p(\\theta | y) \\propto p(y | \\theta) p(\\theta)$$\n\n似然函数 $p(y|\\theta)$ 由测量模型 $y = x\\theta + \\varepsilon$ 给出，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$。这意味着 $y \\sim \\mathcal{N}(x\\theta, \\sigma^2)$，因此似然函数为：\n$$p(y|\\theta) \\propto \\exp\\left( -\\frac{(y - x\\theta)^2}{2\\sigma^2} \\right)$$\n\n先验分布 $p(\\theta)$ 是均值为 $\\mu_0$、精度为 $\\lambda$ 的高斯分布，即 $p(\\theta) = \\mathcal{N}(\\theta | \\mu_0, \\lambda^{-1})$：\n$$p(\\theta) \\propto \\exp\\left( -\\frac{\\lambda(\\theta - \\mu_0)^2}{2} \\right)$$\n\n将它们代入贝叶斯定理，后验概率与两个指数函数的乘积成正比：\n$$p(\\theta | y) \\propto \\exp\\left( -\\frac{(y - x\\theta)^2}{2\\sigma^2} - \\frac{\\lambda(\\theta - \\mu_0)^2}{2} \\right)$$\n\n为了找到后验分布的形式，我们展开指数部分，并按 $\\theta$ 的幂次进行整理。指数项为：\n$$\n-\\frac{1}{2\\sigma^2}(y^2 - 2yx\\theta + x^2\\theta^2) - \\frac{\\lambda}{2}(\\theta^2 - 2\\mu_0\\theta + \\mu_0^2)\n$$\n$$\n= \\theta^2 \\left(-\\frac{x^2}{2\\sigma^2} - \\frac{\\lambda}{2}\\right) + \\theta \\left(\\frac{yx}{\\sigma^2} + \\lambda\\mu_0\\right) + C\n$$\n其中 $C$ 是不含 $\\theta$ 的项。这个关于 $\\theta$ 的二次型表明后验分布也是一个高斯分布，记为 $p(\\theta|y) = \\mathcal{N}(\\theta|m(\\lambda), \\lambda_{\\text{post}}^{-1})$。\n通过比较 $\\theta^2$ 和 $\\theta$ 的系数，我们可以确定后验精度 $\\lambda_{\\text{post}}$ 和后验均值 $m(\\lambda)$。\n从 $\\theta^2$ 的系数可得后验精度：\n$$\\lambda_{\\text{post}} = \\frac{x^2}{\\sigma^2} + \\lambda$$\n从 $\\theta$ 的系数可得：\n$$\\lambda_{\\text{post}}m(\\lambda) = \\frac{yx}{\\sigma^2} + \\lambda\\mu_0$$\n因此，后验均值 $m(\\lambda)$ 为：\n$$m(\\lambda) = \\frac{\\frac{yx}{\\sigma^2} + \\lambda\\mu_0}{\\frac{x^2}{\\sigma^2} + \\lambda}$$\n\n**第 2 部分：后验均值的微分**\n\n现在我们计算导数 $\\frac{dm}{d\\lambda}$。使用商法则 $\\left(\\frac{u}{v}\\right)' = \\frac{u'v - uv'}{v^2}$，其中 $u(\\lambda) = \\frac{yx}{\\sigma^2} + \\lambda\\mu_0$ 且 $v(\\lambda) = \\frac{x^2}{\\sigma^2} + \\lambda$：\n$u'(\\lambda) = \\mu_0$ 和 $v'(\\lambda) = 1$。\n于是：\n$$\n\\frac{dm}{d\\lambda} = \\frac{\\mu_0\\left(\\frac{x^2}{\\sigma^2} + \\lambda\\right) - \\left(\\frac{yx}{\\sigma^2} + \\lambda\\mu_0\\right) \\cdot 1}{\\left(\\frac{x^2}{\\sigma^2} + \\lambda\\right)^2}\n= \\frac{\\frac{\\mu_0 x^2}{\\sigma^2} + \\mu_0 \\lambda - \\frac{yx}{\\sigma^2} - \\lambda\\mu_0}{\\left(\\frac{x^2}{\\sigma^2} + \\lambda\\right)^2}\n$$\n$$\n\\frac{dm}{d\\lambda} = \\frac{\\frac{\\mu_0 x^2 - yx}{\\sigma^2}}{\\left(\\frac{x^2}{\\sigma^2} + \\lambda\\right)^2} = \\frac{x(\\mu_0 x - y)}{\\sigma^2 \\left(\\frac{x^2}{\\sigma^2} + \\lambda\\right)^2} = - \\frac{x(y - \\mu_0 x)}{\\sigma^2 \\left(\\frac{x^2}{\\sigma^2} + \\lambda\\right)^2}\n$$\n\n**第 3 部分：计算一阶变化 $\\Delta m$**\n\n一阶变化由线性近似给出：$\\Delta m \\approx \\left.\\frac{d m}{d \\lambda}\\right|_{\\lambda=\\lambda_{0}} \\delta\\lambda$。\n我们代入给定的数值：$x = 3$，$y = 2$，$\\sigma^{2} = 1.5$，$\\mu_{0} = 0.5$，$\\lambda_{0} = 4$，以及 $\\delta\\lambda = 0.1$。\n\n首先，计算表达式中的各项：\n-   分子项: $x(y - \\mu_0 x) = 3 \\times (2 - 0.5 \\times 3) = 3 \\times (2 - 1.5) = 3 \\times 0.5 = 1.5$。\n-   分母括号中的项: $\\lambda_0 + \\frac{x^2}{\\sigma^2} = 4 + \\frac{3^2}{1.5} = 4 + \\frac{9}{1.5} = 4 + 6 = 10$。\n-   完整的导数在 $\\lambda_0$ 处的值:\n    $$ \\left.\\frac{d m}{d \\lambda}\\right|_{\\lambda=\\lambda_{0}} = - \\frac{1.5}{1.5 \\times (10)^2} = - \\frac{1.5}{150} = -0.01 $$\n现在，计算 $\\Delta m$:\n$$ \\Delta m \\approx -0.01 \\times \\delta\\lambda = -0.01 \\times 0.1 = -0.001 $$\n问题要求答案四舍五入到 5 位有效数字，即 $-1.0000 \\times 10^{-3}$。",
            "answer": "$$\\boxed{-1.0000 \\times 10^{-3}}$$"
        },
        {
            "introduction": "现实世界中的数字孪生模型可能包含大量不确定参数，逐一分析其影响是不现实的。本练习  介绍了一种高效的全局敏感性分析方法——莫里斯筛选法（Morris screening）。通过设计并执行一个计算实验，你将学习如何从高维参数空间中识别出对模型输出影响最大的“关键少数”参数，从而为模型校准和优化指明方向。",
            "id": "4253088",
            "problem": "您的任务是设计并执行一次一变量（One-At-a-Time）莫里斯（Morris）筛选实验，以识别参数不确定性下的高维数字孪生模型中的影响性输入。您的设计和实现必须严格遵循有限差分基础，并且是自包含的。所有输入均归一化到单位超立方体 $[0,1]^d$ 内，所有三角函数参数均以弧度为单位，所有输出均无单位。该实验必须实现为一个完整、可运行的程序。\n\n您必须使用的基本原理如下：\n- 输入 $i$ 的基本效应（elementary effect）是一个基于一维扰动的有限差分商，其中所有其他坐标保持不变。如果 $f$ 是模型，$x \\in [0,1]^d$ 是一个基点，$\\delta \\in (0,1)$ 是一个网格对齐的步长，那么在 $x$ 点输入 $i$ 的效应定义为仅将第 $i$ 个坐标移动 $\\pm \\delta$ 所引起的变化，并按步长大小进行缩放。每个输入 $i$ 的聚合莫里斯统计量是通过在输入空间中重复采样轨迹来计算的。\n- 实验设计必须在每个维度具有 $p$ 个水平的均匀网格上，使用长度为 $d$ 的轴对齐一次一变量轨迹。网格为 $\\{0, \\frac{1}{p-1}, \\ldots, 1\\}$，步长 $\\delta$ 必须等于 $\\frac{p}{2(p-1)}$，这样当 $p$ 为偶数时，每一步都停留在网格上并保持在单位超立方体内。\n\n您必须实现以下精确步骤：\n1. 对于每个维度为 $d$、水平数 $p$（偶数）和轨迹数 $r$ 的测试用例，定义每个坐标上有 $p$ 个均匀间隔水平的网格，以及步长 $\\delta = \\frac{p}{2(p-1)}$。\n2. 对于每条轨迹 $k \\in \\{1,\\ldots,r\\}$：\n   - 采样一个方向向量 $s \\in \\{-1,+1\\}^d$，其元素为独立同分布的 Rademacher 项。\n   - 对于每个坐标 $i \\in \\{1,\\ldots,d\\}$，选择一个网格对齐的基准索引，以确保单步移动 $x_i \\mapsto x_i + s_i \\delta$ 保持在 $[0,1]$ 区间内。形式上，如果 $s_i=+1$，从集合 $\\{0,\\frac{1}{p-1},\\ldots,1-\\delta\\}$ 中选择 $x_i$；如果 $s_i=-1$，从集合 $\\{\\delta,\\delta+\\frac{1}{p-1},\\ldots,1\\}$ 中选择 $x_i$。这些值均在 $[0,1]$ 区间内。\n   - 独立于 $s$ 和之前的轨迹，对 $\\{1,\\ldots,d\\}$ 进行随机排列，得到 $\\pi$。\n   - 从基点开始，根据排列 $\\pi$ 的顺序和向量 $s$ 的符号，每次顺序移动一个坐标，构建一条包含 $d+1$ 个点的轨迹。\n   - 在轨迹的每个点上评估模型 $f$，产生 $d+1$ 个输出。对于轨迹上对应于输入 $i$ 的每一步，使用有限差分商计算输入 $i$ 的一个基本效应样本\n     $$\\mathrm{EE}_{i} = \\frac{f(x^{\\text{after}}) - f(x^{\\text{before}})}{s_{i}\\,\\delta}.$$\n3. 对于每个输入 $i$，将其在 $r$ 条轨迹中得到的 $r$ 个基本效应进行聚合，并计算：\n   - 绝对均值\n     $$\\mu^{\\star}_i = \\frac{1}{r}\\sum_{k=1}^{r} \\left|\\mathrm{EE}_{i}^{(k)}\\right|.$$\n   - 标准差（总体版本）\n     $$\\sigma_i = \\sqrt{\\frac{1}{r}\\sum_{k=1}^{r} \\left(\\mathrm{EE}_{i}^{(k)} - \\bar{\\mathrm{EE}}_i\\right)^2}, \\quad \\text{其中 } \\bar{\\mathrm{EE}}_i = \\frac{1}{r}\\sum_{k=1}^{r} \\mathrm{EE}_{i}^{(k)}.$$\n\n随机性控制：\n- 使用一个以整数 $42$ 为种子的全局伪随机数生成器，并按照给定顺序为所有测试用例的所有随机抽样使用该生成器，以确保输出是完全可复现的。\n\n测试套件：\n在以下三个测试用例上实现并评估莫里斯筛选。在所有情况下，模型输入为 $x=(x_1,\\ldots,x_d)\\in[0,1]^d$。\n\n- 测试用例 A（中等维度，包含交互作用和曲率）：\n  - 参数：$d=6$，$p=6$，$r=12$。\n  - 模型：\n    $$f_{\\mathrm{A}}(x) = 5\\,x_1 + 0.5\\,x_2^2 + 20\\,x_3^2 + 3\\,x_4 x_5 + 0.5\\,\\sin(2\\pi x_6).$$\n    角度以弧度为单位。\n\n- 测试用例 B（更高维度，包含稀疏的强效应和弱干扰项）：\n  - 参数：$d=12$，$p=8$，$r=10$。\n  - 模型：\n    $$f_{\\mathrm{B}}(x) = 8\\,x_1 + 4\\,x_2^2 + 0.5\\,x_3 + 10\\,x_4 x_5 + 0.1\\,x_6 + 0.05\\,x_7 + 9\\,x_8^2 + 2\\,x_9 x_{10} + 0.2\\,\\sin(2\\pi x_{11}) + 0.01\\,x_{12}.$$\n    角度以弧度为单位。\n\n- 测试用例 C（含不连续性的边界情况，用于探究效应的分布）：\n  - 参数：$d=4$，$p=4$，$r=8$。\n  - 包含亥维赛阶跃的模型：\n    $$H(z) = \\begin{cases}0, & z  0,\\\\ 1,  z \\ge 0,\\end{cases} \\quad f_{\\mathrm{C}}(x) = 3\\,x_1 + 2\\,H(x_2 - 0.5) + 5\\,x_3^2 + 0.1\\,x_4.$$\n\n要求的最终输出格式：\n- 对每个测试用例，首先输出 $d$ 个值 $\\mu^{\\star}_1,\\ldots,\\mu^{\\star}_d$，然后输出 $d$ 个值 $\\sigma_1,\\ldots,\\sigma_d$，均按输入索引递增的顺序排列。\n- 将测试用例 A、B、C 的结果按此精确顺序连接起来，形成每个测试用例包含 $2d$ 个数值的单个扁平列表，并最终组合成一个包含所有测试用例结果的列表。\n- 您的程序应生成单行输出，其中包含这个组合列表，形式为用单对方括号括起来的逗号分隔序列，每个数字精确到 $6$ 位小数，且无多余空格。例如：$[\\ldots]$。\n\n所有算术均为实数运算。不涉及物理单位。所有三角函数参数均以弧度为单位。三角函数内的角度和值不得转换为度。程序不得读取任何输入，并且在给定种子 $42$ 的情况下必须是完全确定性的。",
            "solution": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to execute the Morris screening for all test cases and print the results.\n    \"\"\"\n\n    # --- Model Functions ---\n    def f_A(x):\n        \"\"\"Model for Test Case A with d=6.\"\"\"\n        return (5 * x[0] + 0.5 * x[1]**2 + 20 * x[2]**2 +\n                3 * x[3] * x[4] + 0.5 * np.sin(2 * np.pi * x[5]))\n\n    def f_B(x):\n        \"\"\"Model for Test Case B with d=12.\"\"\"\n        return (8 * x[0] + 4 * x[1]**2 + 0.5 * x[2] + 10 * x[3] * x[4] +\n                0.1 * x[5] + 0.05 * x[6] + 9 * x[7]**2 + 2 * x[8] * x[9] +\n                0.2 * np.sin(2 * np.pi * x[10]) + 0.01 * x[11])\n\n    def H(z):\n        \"\"\"Heaviside step function.\"\"\"\n        return 1.0 if z = 0.0 else 0.0\n\n    def f_C(x):\n        \"\"\"Model for Test Case C with d=4.\"\"\"\n        return 3 * x[0] + 2 * H(x[1] - 0.5) + 5 * x[2]**2 + 0.1 * x[3]\n\n    # --- Core Morris Screening Logic ---\n    def morris_screening(model, d, p, r, rng):\n        \"\"\"\n        Performs the Morris screening experiment.\n\n        Args:\n            model (callable): The model function to evaluate.\n            d (int): Number of input dimensions.\n            p (int): Number of grid levels (must be even).\n            r (int): Number of trajectories.\n            rng (np.random.Generator): The random number generator instance.\n\n        Returns:\n            tuple: A tuple containing two numpy arrays (mu_star, sigma).\n        \"\"\"\n        delta = p / (2 * (p - 1))\n        grid = np.linspace(0, 1, p)\n        tol = 1e-9  # Tolerance for floating point comparisons\n\n        elementary_effects = [[] for _ in range(d)]\n\n        for _ in range(r):\n            # 1. Sample orientation vector s\n            s = rng.choice([-1, 1], size=d)\n\n            # 2. Sample grid-aligned base point x0\n            x0 = np.zeros(d)\n            for i in range(d):\n                if s[i] == 1:\n                    possible_values = grid[grid  (1 - delta + tol)]\n                else:  # s[i] == -1\n                    possible_values = grid[grid  (delta - tol)]\n                x0[i] = rng.choice(possible_values)\n\n            # 3. Sample random permutation pi\n            pi = rng.permutation(d)\n\n            # 4. Construct trajectory and compute EEs\n            x_before = x0.copy()\n            y_before = model(x_before)\n\n            for j in range(d):\n                input_idx = pi[j]\n\n                x_after = x_before.copy()\n                x_after[input_idx] += s[input_idx] * delta\n                y_after = model(x_after)\n                \n                ee = (y_after - y_before) / (s[input_idx] * delta)\n                elementary_effects[input_idx].append(ee)\n\n                # Update state for the next step in the trajectory\n                x_before = x_after\n                y_before = y_after\n\n        # 5. Aggregate statistics\n        mu_star = np.zeros(d)\n        sigma = np.zeros(d)\n\n        for i in range(d):\n            ees_i = np.array(elementary_effects[i])\n            mu_star[i] = np.mean(np.abs(ees_i))\n            # Population standard deviation (ddof=0 is default)\n            sigma[i] = np.std(ees_i)\n\n        return mu_star, sigma\n\n    # --- Main Execution Logic ---\n    # Single global RNG seeded as required for reproducibility\n    rng = np.random.default_rng(42)\n\n    test_cases = [\n        {'d': 6, 'p': 6, 'r': 12, 'model': f_A},\n        {'d': 12, 'p': 8, 'r': 10, 'model': f_B},\n        {'d': 4, 'p': 4, 'r': 8, 'model': f_C},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        mu_star, sigma = morris_screening(\n            case['model'], case['d'], case['p'], case['r'], rng\n        )\n        # Per problem spec: concatenate mu* then sigma for each case\n        all_results.extend(mu_star)\n        all_results.extend(sigma)\n\n    # Format the final list for printing as a single line\n    formatted_results = [f\"{x:.6f}\" for x in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```",
            "answer": "[5.000000,0.600000,10.000000,0.666667,0.708333,3.141593,0.000000,0.200000,6.000000,0.608581,0.590290,0.000000,8.000000,3.111111,0.500000,4.642857,4.428571,0.100000,0.050000,5.857143,0.914286,0.857143,1.256637,0.010000,0.000000,1.383284,0.000000,3.013742,2.946394,0.000000,0.000000,3.314286,0.666667,0.666667,0.000000,0.000000,3.000000,2.666667,5.000000,0.100000,0.000000,0.942809,2.886751,0.000000]"
        }
    ]
}