{
    "hands_on_practices": [
        {
            "introduction": "在投入资源进行实验设计和参数校准之前，一个关键的先决步骤是评估模型的结构可辨识性。如果一个模型的不同参数组合能够产生完全相同的输出，那么仅凭输出数据就不可能唯一地确定这些参数。本练习  通过一个简单的线性时不变系统，要求您构建一个反例，以揭示这种不可辨识性问题，从而强调了在校准前进行模型分析的重要性。",
            "id": "4214597",
            "problem": "考虑一个单自由度信息物理执行器-传感器链的数字孪生，其模型为线性时不变（LTI）系统。物理执行器将指令输入 $u(t)$ 应用于一个建模为纯积分器的对象，传感器以未知的增益测量其状态。该数字孪生使用以下参数模型：\n$$\n\\dot{x}(t) = g_{a}\\,u(t), \\qquad y(t) = g_{s}\\,x(t),\n$$\n初始条件为 $x(0) = 0$，其中执行器增益 $g_{a} \\in \\mathbb{R}$ 和传感器增益 $g_{s} \\in \\mathbb{R}$ 未知但非零。假设在某个有限时间域 $T > 0$ 内，允许的输入信号 $u(t)$ 属于集合 $L^{2}([0,T])$。\n\n从一阶线性微分方程解的基本定义和线性时不变（LTI）系统的叠加原理出发，分析由该模型导出的映射 $\\theta = (g_{a}, g_{s}) \\mapsto y(\\cdot)$，并确定对于所有允许的输入，仅使用在 $t \\in [0,T]$ 上的输出测量值 $y(t)$ 进行校准是否足以唯一地辨识 $\\theta$。如果不足以唯一辨识，请构造一个与 $\\theta$ 不同但对于所有允许的输入 $u(t)$ 和指定的初始条件都能产生相同输出 $y(t)$ 的备选参数矢量 $\\theta' = (g_{a}', g_{s}')$ 的闭式通用表达式。\n\n将您的最终答案表示为关于 $\\theta$ 和一个自由非零标量的单一解析表达式。不需要数值四舍五入。不需要单位。",
            "solution": "我们得到以下线性时不变（LTI）模型：\n$$\n\\dot{x}(t) = g_{a}\\,u(t), \\qquad y(t) = g_{s}\\,x(t),\n$$\n其中 $x(0)=0$，允许的输入 $u \\in L^{2}([0,T])$。\n\n我们从一阶线性常微分方程的基本解开始。对于给定的系统，\n$$\n\\dot{x}(t) = g_{a}\\,u(t),\n$$\n在 $x(0)=0$ 的条件下，其解可以通过对两边关于时间积分得到：\n$$\nx(t) = x(0) + \\int_{0}^{t} g_{a}\\,u(\\tau)\\,d\\tau = g_{a}\\,\\int_{0}^{t} u(\\tau)\\,d\\tau.\n$$\n这对于 $u \\in L^{2}([0,T])$ 是有效的，因为在有限区间上，$L^{2}([0,T]) \\subset L^{1}([0,T])$，因此积分 $\\int_{0}^{t} u(\\tau)\\,d\\tau$ 对于所有 $t \\in [0,T]$ 都存在。\n\n输出由测量方程给出：\n$$\ny(t) = g_{s}\\,x(t) = g_{s}\\,g_{a}\\,\\int_{0}^{t} u(\\tau)\\,d\\tau.\n$$\n因此，该系统的输入-输出映射可以写为：\n$$\nu(\\cdot) \\mapsto y(t) = \\left(g_{a}\\,g_{s}\\right)\\,\\int_{0}^{t} u(\\tau)\\,d\\tau.\n$$\n这表明输出对参数矢量 $\\theta = (g_{a}, g_{s})$ 的依赖仅通过乘积 $g_{a}\\,g_{s}$，而不是单独依赖于 $g_{a}$ 和 $g_{s}$。因此，从 $t \\in [0,T]$ 上的仅输出测量值 $y(t)$ 和任意允许的输入 $u$，最多只能辨识标量 $g_{a}\\,g_{s}$，而不能辨识 $g_{a}$ 和 $g_{s}$ 的各自值。\n\n为了构造一组对于所有允许的输入都能产生相同输出的不同参数矢量，我们需要两个参数对 $(g_{a}, g_{s})$ 和 $(g_{a}', g_{s}')$ 满足：\n$$\ng_{a}\\,g_{s} = g_{a}'\\,g_{s}'.\n$$\n参数化所有此类不同参数对的一种通用方法是引入一个自由非零标量 $\\alpha \\in \\mathbb{R}\\setminus\\{0\\}$ 并定义：\n$$\ng_{a}' = \\alpha\\,g_{a}, \\qquad g_{s}' = \\frac{g_{s}}{\\alpha}.\n$$\n那么，\n$$\ng_{a}'\\,g_{s}' = \\left(\\alpha\\,g_{a}\\right)\\left(\\frac{g_{s}}{\\alpha}\\right) = g_{a}\\,g_{s},\n$$\n这意味着对于所有允许的 $u(\\cdot)$ 和所有 $t \\in [0,T]$，都有 $y'(t) = g_{a}'\\,g_{s}'\\int_{0}^{t}u(\\tau)\\,d\\tau = y(t)$。对于任何 $\\alpha \\neq 1$，参数对 $(g_{a}', g_{s}')$ 都与 $(g_{a}, g_{s})$ 不同，这证明了不可辨识性。所有观测上无法区分的参数矢量的等价类由以下单参数族给出：\n$$\n\\theta'(\\alpha) = \\left(\\alpha\\,g_{a}, \\frac{g_{s}}{\\alpha}\\right), \\quad \\alpha \\in \\mathbb{R}\\setminus\\{0\\}.\n$$\n这就完成了一个反例的构造，其中两个不同的参数矢量对所有允许的输入都产生相同的输出，从而说明了该数字孪生模型校准中的不可辨识性问题。",
            "answer": "$$\\boxed{\\begin{pmatrix}\\alpha\\,g_{a}  \\dfrac{g_{s}}{\\alpha}\\end{pmatrix}}$$"
        },
        {
            "introduction": "一旦确认模型是可辨识的，下一步就是利用观测数据进行校准。贝叶斯推断为此提供了一个强大的框架，它不仅能更新我们对参数的估计，还能量化估计的不确定性。本练习  将指导您通过编程实践，在一个线性模型中执行贝叶斯校准，并系统地分析先验分布的选择如何影响最终的后验结果，从而加深对数据与先验知识之间相互作用的理解。",
            "id": "4214490",
            "problem": "考虑在信息物理系统（Cyber-Physical Systems, CPS）的数字孪生（Digital Twin, DT）开发背景下的一个校准任务，其中，物理系统内部的一个信息物理传感器产生的测量值，可以通过一个已知输入和一个未知增益参数之间的简单线性关系来建模。数字孪生必须使用观测数据来校准这个未知的增益参数，并验证校准结果对先验分布假设的敏感性。假设模型如下：测量值由关系式 $y_i = \\theta x_i + \\varepsilon_i$ 描述，其中 $i \\in \\{1, \\dots, n\\}$，误差 $\\varepsilon_i$ 是独立同分布的，服从 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$，未知增益参数 $\\theta$ 的先验分布为 $\\theta \\sim \\mathcal{N}(\\mu_0, \\tau_0^2)$。校准应使用贝叶斯推断（Bayesian inference）原理进行。\n\n您的任务是编写一个完整的、可运行的程序。该程序在给定一个固定的数据集 $(x_i, y_i)$、一个固定的先验均值 $\\mu_0$ 和一个固定的噪声方差 $\\sigma^2$ 的情况下，计算在几种不同的先验方差 $\\tau_0^2$ 选择下，参数 $\\theta$ 的后验均值以及一个置信水平为 $0.95$ 的对称可信区间。该可信区间的端点必须与 $\\theta$ 的单位相同（在此设置中为无单位），并且必须对应于后验分布的 $(\\alpha/2)$ 和 $(1-\\alpha/2)$ 分位数，其中 $\\alpha = 0.05$。这里假设共轭性导致后验分布为高斯分布。\n\n使用的基本原理：连续随机变量的贝叶斯定理、线性模型下的高斯似然函数定义，以及高斯先验与高斯似然函数在线性模型中的共轭性。所有的推导和计算都应遵循这些原理，从似然和先验的定义开始，通过标准操作（例如，配方法和识别高斯核）推导出后验分布。\n\n使用以下数据集和固定的超参数：\n- 输入：$x = [\\,0.5,\\,1.0,\\,1.6,\\,2.1,\\,2.8\\,]$。\n- 观测值：$y = [\\,1.13,\\,2.15,\\,3.64,\\,4.54,\\,6.17\\,]$。\n- 先验均值：$\\mu_0 = 2.0$。\n- 噪声方差：$\\sigma^2 = 0.04$（因此噪声标准差为 $\\sigma = 0.2$）。\n- 可信水平：$0.95$（因此补集为 $\\alpha = 0.05$）。\n\n通过在以下测试套件上改变先验方差 $\\tau_0^2$ 来分析先验敏感性：\n- 先验方差的测试用例集：$[\\,0.0001,\\,0.01,\\,0.1,\\,1.0,\\,100.0\\,]$。\n  - $\\tau_0^2 = 0.0001$ 的情况代表一个信息量极大的先验。\n  - $\\tau_0^2 = 0.01$ 的情况代表一个信息量很大的先验。\n  - $\\tau_0^2 = 0.1$ 的情况代表一个信息量适中的先验。\n  - $\\tau_0^2 = 1.0$ 的情况代表一个弱信息先验。\n  - $\\tau_0^2 = 100.0$ 的情况代表一个非常分散的先验，接近于数据主导的状态。\n\n对于测试套件中的每个 $\\tau_0^2$ 值，您的程序必须计算：\n- $\\theta$ 的后验均值（无单位）。\n- 对称 $0.95$ 可信区间的下端点（无单位）。\n- 对称 $0.95$ 可信区间的上端点（无单位）。\n\n您的程序应该生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果必须表示为一个包含三个小数的列表，四舍五入到六位小数，顺序为 $[\\,\\text{posterior\\_mean},\\,\\text{lower\\_endpoint},\\,\\text{upper\\_endpoint}\\,]$。将所有测试用例聚合到一个外部列表中。例如，输出必须具有 $[\\,[m_1,\\ell_1,u_1],[m_2,\\ell_2,u_2],\\dots]\\,$ 的形式，其中每个 $m_j$、$\\ell_j$ 和 $u_j$ 都四舍五入到六位小数。所有输出都是无单位的小数，并且必须精确打印到小数点后六位。",
            "solution": "该问题要求在数字孪生模型中校准传感器的增益参数 $\\theta$。所采用的方法是贝叶斯推断。我们给定了一个用于测量值 $y_i$ 的线性模型、一个高斯噪声模型以及 $\\theta$ 的一个高斯先验。任务是针对先验方差 $\\tau_0^2$ 的几种不同选择，计算 $\\theta$ 的后验均值和一个 $0.95$ 可信区间，以分析后验分布对先验信息量的敏感性。\n\n首先，我们将概率模型形式化。测量模型由 $y_i = \\theta x_i + \\varepsilon_i$ 给出，其中 $i = 1, \\dots, n$。误差 $\\varepsilon_i$ 是独立同分布的，服从均值为 $0$、方差为 $\\sigma^2$ 的正态分布，即 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。这意味着在给定输入 $x_i$ 和参数 $\\theta$ 的条件下，观测值 $y_i$ 的条件分布也是正态的：$y_i | \\theta, x_i \\sim \\mathcal{N}(\\theta x_i, \\sigma^2)$。\n\n似然函数，即在给定 $\\theta$ 和输入 $\\mathbf{x} = \\{x_1, \\dots, x_n\\}$ 的条件下观测到整个数据集 $\\mathbf{y} = \\{y_1, \\dots, y_n\\}$ 的概率，是由于测量的独立性而得出的各个概率密度的乘积：\n$$ p(\\mathbf{y} | \\theta, \\mathbf{x}, \\sigma^2) = \\prod_{i=1}^{n} p(y_i | \\theta, x_i, \\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\theta x_i)^2}{2\\sigma^2}\\right) $$\n作为 $\\theta$ 的函数，似然函数正比于：\n$$ p(\\mathbf{y} | \\theta, \\mathbf{x}, \\sigma^2) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(y_i - \\theta x_i)^2\\right) $$\n\n参数 $\\theta$ 的先验分布被指定为正态分布，$\\theta \\sim \\mathcal{N}(\\mu_0, \\tau_0^2)$。其先验概率密度函数为：\n$$ p(\\theta | \\mu_0, \\tau_0^2) = \\frac{1}{\\sqrt{2\\pi\\tau_0^2}} \\exp\\left(-\\frac{(\\theta - \\mu_0)^2}{2\\tau_0^2}\\right) $$\n\n根据贝叶斯定理，$\\theta$ 的后验分布正比于似然函数和先验分布的乘积：\n$$ p(\\theta | \\mathbf{y}, \\mathbf{x}, \\sigma^2, \\mu_0, \\tau_0^2) \\propto p(\\mathbf{y} | \\theta, \\mathbf{x}, \\sigma^2) \\cdot p(\\theta | \\mu_0, \\tau_0^2) $$\n代入似然函数和先验的表达式，我们得到：\n$$ p(\\theta | \\dots) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(y_i - \\theta x_i)^2\\right) \\cdot \\exp\\left(-\\frac{(\\theta - \\mu_0)^2}{2\\tau_0^2}\\right) $$\n$$ p(\\theta | \\dots) \\propto \\exp\\left( -\\frac{1}{2} \\left[ \\frac{\\sum_{i=1}^{n}(y_i - \\theta x_i)^2}{\\sigma^2} + \\frac{(\\theta - \\mu_0)^2}{\\tau_0^2} \\right] \\right) $$\n为了确定后验分布的形式，我们通过展开平方项并收集包含 $\\theta$ 的项来分析指数部分：\n$$ \\frac{1}{\\sigma^2}\\sum(y_i^2 - 2\\theta x_i y_i + \\theta^2 x_i^2) + \\frac{1}{\\tau_0^2}(\\theta^2 - 2\\theta \\mu_0 + \\mu_0^2) $$\n$$ = \\theta^2 \\left( \\frac{\\sum x_i^2}{\\sigma^2} + \\frac{1}{\\tau_0^2} \\right) - 2\\theta \\left( \\frac{\\sum x_i y_i}{\\sigma^2} + \\frac{\\mu_0}{\\tau_0^2} \\right) + C $$\n其中 $C$ 包含不依赖于 $\\theta$ 的项。指数部分中关于 $\\theta$ 的这种二次形式表明，后验分布也是一个正态分布。设后验分布为 $\\theta | \\dots \\sim \\mathcal{N}(\\mu_n, \\tau_n^2)$。其密度函数的指数部分正比于 $-\\frac{1}{2\\tau_n^2}(\\theta - \\mu_n)^2$，展开后为：\n$$ -\\frac{1}{2} \\left( \\frac{1}{\\tau_n^2}\\theta^2 - \\frac{2\\mu_n}{\\tau_n^2}\\theta + \\frac{\\mu_n^2}{\\tau_n^2} \\right) $$\n通过匹配指数部分两种形式中 $\\theta^2$ 和 $\\theta$ 的系数，我们推导出后验参数 $\\mu_n$ 和 $\\tau_n^2$。\n$\\theta^2$ 的系数给出了后验精度（$1/\\tau_n^2$）：\n$$ \\frac{1}{\\tau_n^2} = \\frac{1}{\\tau_0^2} + \\frac{\\sum_{i=1}^{n} x_i^2}{\\sigma^2} $$\n$\\theta$ 的系数给出了后验均值 $\\mu_n$：\n$$ \\frac{\\mu_n}{\\tau_n^2} = \\frac{\\mu_0}{\\tau_0^2} + \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sigma^2} \\implies \\mu_n = \\tau_n^2 \\left( \\frac{\\mu_0}{\\tau_0^2} + \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sigma^2} \\right) $$\n这些公式展示了贝叶斯更新的原理：后验精度是先验精度和数据精度的和，而后验均值是先验均值和由数据导出的均值的精度加权平均。\n\n为了计算所需的量，我们使用所提供的数据：\n- 输入：$\\mathbf{x} = [\\,0.5,\\,1.0,\\,1.6,\\,2.1,\\,2.8\\,]$\n- 观测值：$\\mathbf{y} = [\\,1.13,\\,2.15,\\,3.64,\\,4.54,\\,6.17\\,]$\n- 先验均值：$\\mu_0 = 2.0$\n- 噪声方差：$\\sigma^2 = 0.04$\n首先，我们从数据中计算汇总统计量：\n$$ \\sum_{i=1}^{n} x_i^2 = (0.5)^2 + (1.0)^2 + (1.6)^2 + (2.1)^2 + (2.8)^2 = 16.06 $$\n$$ \\sum_{i=1}^{n} x_i y_i = (0.5)(1.13) + (1.0)(2.15) + (1.6)(3.64) + (2.1)(4.54) + (2.8)(6.17) = 35.349 $$\n\n对于集合 $[\\,0.0001,\\,0.01,\\,0.1,\\,1.0,\\,100.0\\,]$ 中给定的每个先验方差 $\\tau_0^2$，我们计算后验均值 $\\mu_n$ 和后验方差 $\\tau_n^2$。\n\n对于一个服从正态分布 $\\theta \\sim \\mathcal{N}(\\mu_n, \\tau_n^2)$ 的参数，其水平为 $1-\\alpha$ 的对称可信区间由 $[\\mu_n - z_{1-\\alpha/2} \\tau_n, \\mu_n + z_{1-\\alpha/2} \\tau_n]$ 给出，其中 $\\tau_n = \\sqrt{\\tau_n^2}$ 是后验标准差，而 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$-分位数。对于一个 $0.95$ 的可信区间，$\\alpha=0.05$，所以我们需要 $z_{0.975}$ 分位数，其值约为 $1.96$。\n\n程序将实现这些公式，遍历每个指定的 $\\tau_0^2$ 值，以计算后验均值 $\\mu_n$ 以及 $0.95$ 可信区间的下端点和上端点。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes the posterior mean and a 0.95 credible interval for a sensor gain\n    parameter theta using Bayesian linear regression for different prior variances.\n    \"\"\"\n    #\n    # Step 1: Define givens from the problem statement.\n    #\n\n    # Dataset\n    x = np.array([0.5, 1.0, 1.6, 2.1, 2.8])\n    y = np.array([1.13, 2.15, 3.64, 4.54, 6.17])\n\n    # Fixed hyperparameters\n    mu_0 = 2.0\n    sigma_sq = 0.04\n\n    # Test cases for prior variance\n    tau_0_sq_cases = [0.0001, 0.01, 0.1, 1.0, 100.0]\n\n    # Credible interval level\n    confidence_level = 0.95\n    alpha = 1 - confidence_level\n\n    #\n    # Step 2: Pre-compute data-dependent summary statistics.\n    #\n    sum_x_sq = np.sum(x**2)\n    sum_xy = np.sum(x * y)\n\n    #\n    # Step 3: Pre-compute the z-score for the credible interval.\n    #\n    # For a symmetric 95% credible interval, we need the quantile for\n    # 1 - alpha/2 = 1 - 0.05/2 = 0.975.\n    z_score = norm.ppf(1 - alpha / 2)\n\n    #\n    # Step 4: Iterate through test cases and perform Bayesian updates.\n    #\n    all_results = []\n    for tau_0_sq in tau_0_sq_cases:\n        #\n        # Step 4a: Calculate posterior precision and variance.\n        # Posterior precision = Prior precision + Data precision\n        #\n        prior_precision = 1 / tau_0_sq\n        data_precision = sum_x_sq / sigma_sq\n        posterior_precision = prior_precision + data_precision\n        tau_n_sq = 1 / posterior_precision\n\n        #\n        # Step 4b: Calculate posterior mean.\n        # The posterior mean is a precision-weighted average of the prior mean and\n        # a data-driven estimate.\n        #\n        mu_n = tau_n_sq * ((mu_0 / tau_0_sq) + (sum_xy / sigma_sq))\n\n        #\n        # Step 4c: Calculate the credible interval.\n        # The interval is [mean - z*stdev, mean + z*stdev].\n        #\n        tau_n = np.sqrt(tau_n_sq)\n        margin_of_error = z_score * tau_n\n        lower_endpoint = mu_n - margin_of_error\n        upper_endpoint = mu_n + margin_of_error\n\n        all_results.append([mu_n, lower_endpoint, upper_endpoint])\n\n    #\n    # Step 5: Format the results for the final output.\n    #\n    output_parts = []\n    for result_triple in all_results:\n        # Format each number to exactly six decimal places.\n        formatted_nums = [f\"{num:.6f}\" for num in result_triple]\n        # Create the inner list string, e.g., \"[2.007624,1.988407,2.026842]\".\n        output_parts.append(f\"[{','.join(formatted_nums)}]\")\n\n    # Join all test case results into the final output string.\n    final_output = f\"[{','.join(output_parts)}]\"\n    print(final_output)\n\nsolve()\n\n```"
        },
        {
            "introduction": "数字孪生的校准并非一劳永逸；由于物理系统的磨损、老化或环境变化，模型会逐渐失配。因此，持续的验证和及时的再校准至关重要。本练习  将带您从单纯的统计验证进入到实际的运维决策层面，要求您基于贝叶斯决策理论，构建一个风险感知的决策规则，以决定何时应该触发成本高昂的再校准过程。",
            "id": "4214546",
            "problem": "您正在为信息物理系统（CPS）环境中的数字孪生设计一种风险感知的重校准决策规则。该数字孪生预测一个可测量的输出，而验证子系统在每个验证步骤中，在一个大小为 $n$ 的固定窗口内收集残差验证误差 $e_i$。当数字孪生校准良好时，残差在统计上集中在零附近；当孪生与物理系统不匹配时，残差会产生偏差且更为分散。重校准可以立即将孪生恢复到校准良好的状态，但会产生有限的成本；而选择不重校准则会面临性能损失的风险，直到下一个验证步骤。\n\n基本基础。假设残差误差模型如下：\n- 在校准良好的状态 $H_0$ 下，残差是独立同分布的，服从 $e_i \\sim \\mathcal{N}(0,\\sigma_0^2)$。\n- 在不匹配的状态 $H_1$ 下，残差是独立同分布的，服从 $e_i \\sim \\mathcal{N}(\\mu,\\sigma_1^2)$。\n观测到的验证指标是平方和 $S = \\sum_{i=1}^{n} e_i^2$。设观测到 $S$ 之前的不匹配先验概率为 $p_1 \\in (0,1)$。损失模型为：\n- 无论处于何种状态，重校准决策都会产生成本 $C  0$。\n- 在 $H_1$ 状态下，不重校准决策会产生单位时间为 $L  0$ 的性能损失率，该损失会在一个有限的决策时域 $H  0$ 内累积，直到下一次验证。\n\n任务。仅从上述基本定义以及关于高斯模型和贝叶斯决策理论的公认事实出发，推导出一个能在验证步骤中最小化预期后验损失的原则性决策规则。您的规则必须能根据观测值 $S$、先验概率 $p_1$ 以及参数 $n$、$\\sigma_0$、$\\sigma_1$、$\\mu$、$H$、$L$ 和 $C$ 进行显式计算。您必须：\n- 使用贝叶斯定理计算在给定 $S$ 的情况下的不匹配后验概率。\n- 使用给定的损失模型，在“重校准”和“不重校准”两个行动之间做出决策，以最小化预期损失。\n- 在一个程序中实现该决策规则，为每个测试用例返回一个布尔值，指示是否应进行重校准（$\\text{True}$）或不重校准（$\\text{False}$）。\n\n统计建模事实。在 $H_0$ 下，$S$ 的分布源于独立高斯变量的平方和，并与中心卡方分布相关。在 $H_1$ 下，由于非零均值 $\\mu$，它与非中心卡方分布相关。使用这些经过充分检验的事实，不要为最终决策规则假设或使用任何快捷公式。\n\n测试套件。使用以下测试用例。对于每个案例，考虑所提供的残差序列 $\\{e_i\\}_{i=1}^{n}$，计算 $S = \\sum_{i=1}^{n} e_i^2$，并应用您的决策规则。本问题不涉及物理单位，概率必须用小数表示。不涉及角度。\n\n- 案例 A（一般情况）：\n  - $n = 20$, $\\sigma_0 = 0.5$, $\\sigma_1 = 0.7$, $\\mu = 0.3$, $p_1 = 0.2$, $H = 10$, $L = 1.0$, $C = 4.0$。\n  - 残差：$[0.21, -0.38, 0.45, 0.50, -0.12, 0.33, 0.62, -0.15, 0.27, 0.41, 0.35, -0.07, 0.58, 0.29, -0.24, 0.48, 0.26, -0.11, 0.54, 0.31]$。\n\n- 案例 B（边界条件 $H \\cdot L = C$）：\n  - $n = 10$, $\\sigma_0 = 0.3$, $\\sigma_1 = 0.5$, $\\mu = 0.1$, $p_1 = 0.3$, $H = 5$, $L = 1.0$, $C = 5.0$。\n  - 残差：$[-0.05, 0.02, -0.01, 0.03, -0.04, 0.01, 0.00, -0.02, 0.04, -0.03]$。\n\n- 案例 C（小窗口，强偏差）：\n  - $n = 1$, $\\sigma_0 = 0.4$, $\\sigma_1 = 0.5$, $\\mu = 0.8$, $p_1 = 0.1$, $H = 12$, $L = 1.0$, $C = 2.0$。\n  - 残差：$[1.20]$。\n\n- 案例 D（高先验不匹配，轻微误差）：\n  - $n = 5$, $\\sigma_0 = 0.4$, $\\sigma_1 = 0.6$, $\\mu = 0.3$, $p_1 = 0.8$, $H = 3$, $L = 1.5$, $C = 2.0$。\n  - 残差：$[0.05, -0.02, 0.10, -0.08, 0.06]$。\n\n- 案例 E（方差相等，小偏差）：\n  - $n = 8$, $\\sigma_0 = 0.5$, $\\sigma_1 = 0.5$, $\\mu = 0.15$, $p_1 = 0.25$, $H = 4$, $L = 1.0$, $C = 3.0$。\n  - 残差：$[0.20, -0.12, 0.18, 0.05, -0.07, 0.22, -0.03, 0.10]$。\n\n最终输出格式。您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[resultA,resultB,resultC,resultD,resultE]”），其中每个条目都是一个布尔值，指示是否建议对相应案例进行重校准。",
            "solution": "用户希望我推导并实现一个用于重校准数字孪生的风险感知决策规则。\n\n### **问题验证**\n\n**1. 提取已知条件：**\n-   **残差 $e_i$ 的假设**：\n    -   $H_0$（校准良好）：$e_i \\sim \\mathcal{N}(0, \\sigma_0^2)$，对于 $i=1, \\dots, n$ 独立同分布。\n    -   $H_1$（不匹配）：$e_i \\sim \\mathcal{N}(\\mu, \\sigma_1^2)$，对于 $i=1, \\dots, n$ 独立同分布。\n-   **观测统计量**：$S = \\sum_{i=1}^{n} e_i^2$。\n-   **不匹配的先验概率**：$P(H_1) = p_1 \\in (0,1)$。\n-   **行动**：‘重校准’（$A_R$）和‘不重校准’（$A_{NR}$）。\n-   **损失模型**：\n    -   行动 $A_R$ 的损失：$C  0$，无论真实状态是 $H_0$ 还是 $H_1$。\n    -   行动 $A_{NR}$ 的损失：如果状态是 $H_0$，损失为 $0$；如果状态是 $H_1$，损失为 $L \\cdot H$。\n-   **模型参数**：窗口大小 $n$、方差 $\\sigma_0^2$ 和 $\\sigma_1^2$、均值偏差 $\\mu$、先验概率 $p_1$、损失率 $L$、决策时域 $H$ 和重校准成本 $C$。\n-   **任务**：推导一个最小化预期后验损失的决策规则，并为给定的测试用例实现它。\n\n**2. 验证：**\n-   **科学依据**：该问题在贝叶斯决策理论和统计假设检验方面有充分的依据，使用了标准分布（正态分布、卡方分布、非中心卡方分布）。这些是进行此类分析的标准且正确的工具。该问题在科学上是合理的。\n-   **适定性**：目标定义清晰（最小化预期后验损失）。模型已完全指定，包含所有必要参数。可以从给定信息中推导出唯一的决策规则。该问题是适定的。\n-   **客观性**：该问题使用精确、定量和客观的数学语言陈述。没有主观因素。\n-   **完整性**：为测试用例提供了所有必需的数据和参数。该问题是自包含的。\n-   **一致性与可行性**：问题陈述中没有矛盾之处。所要求的计算基于成熟的统计分布，并且在计算上是可行的。\n\n**3. 结论：**\n该问题被认为是**有效的**，因为其科学合理、适定、客观且完整。\n\n### **决策规则的推导**\n\n目标是选择行动——重校准（$A_R$）或不重校准（$A_{NR}$），以最小化在观测数据 $S$ 条件下的预期损失。这是一个贝叶斯决策问题。\n\n每个行动的预期后验损失是各种可能损失乘以其后验概率的总和。设 $P(H_0|S)$ 和 $P(H_1|S)$ 分别为在给定观测值 $S$ 的情况下，系统处于状态 $H_0$ 和 $H_1$ 的后验概率。\n\n**重校准的预期损失，$E[\\text{Loss}|A_R, S]$**\n重校准的成本为 $C$，与系统的真实状态无关。\n$$ E[\\text{Loss}|A_R, S] = C \\cdot P(H_0|S) + C \\cdot P(H_1|S) = C \\cdot (P(H_0|S) + P(H_1|S)) = C $$\n\n**不重校准的预期损失，$E[\\text{Loss}|A_{NR}, S]$**\n只有当系统处于不匹配状态 $H_1$ 时才会产生损失。损失为 $H \\cdot L$。\n$$ E[\\text{Loss}|A_{NR}, S] = 0 \\cdot P(H_0|S) + (H \\cdot L) \\cdot P(H_1|S) = (H \\cdot L) \\cdot P(H_1|S) $$\n\n**决策规则**\n当且仅当重校准的预期损失小于不重校准的预期损失时，最优决策是进行重校准。\n$$ E[\\text{Loss}|A_R, S]  E[\\text{Loss}|A_{NR}, S] $$\n$$ C  (H \\cdot L) \\cdot P(H_1|S) $$\n这个不等式定义了我们的决策规则。通过重新整理，我们发现如果失配的后验概率超过某个阈值 $\\tau$，我们应该进行重校准：\n$$ P(H_1|S)  \\frac{C}{H \\cdot L} \\equiv \\tau $$\n如果 $P(H_1|S)$ 等于阈值，我们处于无差异状态；按照惯例，我们选择成本较低的行动，即不重校准。\n\n**后验概率的计算**\n为了计算 $P(H_1|S)$，我们使用贝叶斯定理：\n$$ P(H_1|S) = \\frac{f(S|H_1) P(H_1)}{f(S|H_0) P(H_0) + f(S|H_1) P(H_1)} $$\n其中 $f(S|H_k)$ 是在给定假设 $H_k$ 的情况下观测到 $S$ 的似然， $P(H_1) = p_1$ 是给定的先验概率，而 $P(H_0) = 1 - p_1$。我们需要推导似然函数 $f(S|H_0)$ 和 $f(S|H_1)$。\n\n**$H_0$ 下的似然函数**\n在 $H_0$ 下，每个残差 $e_i \\sim \\mathcal{N}(0, \\sigma_0^2)$。如果我们将残差标准化为 $z_i = e_i/\\sigma_0$，那么 $z_i \\sim \\mathcal{N}(0, 1)$。统计量 $S$ 与这些标准正态变量的平方和有关：\n$$ S = \\sum_{i=1}^n e_i^2 = \\sigma_0^2 \\sum_{i=1}^n \\left(\\frac{e_i}{\\sigma_0}\\right)^2 = \\sigma_0^2 \\sum_{i=1}^n z_i^2 $$\n和 $\\sum z_i^2$ 服从自由度为 $n$ 的中心卡方分布，即 $\\chi^2_n$。\n这意味着变量 $Y = S/\\sigma_0^2$ 服从 $\\chi^2_n$ 分布。通过变量替换可以找到 $S$ 的概率密度函数（PDF）。结果是 $S$ 服从形状参数为 $k = n/2$、尺度参数为 $\\theta = 2\\sigma_0^2$ 的伽马分布。似然是在观测到的 $S$ 值处评估该分布的概率密度函数：\n$$ f(S|H_0) = \\text{GammaPDF}(S; k=n/2, \\theta=2\\sigma_0^2) $$\n\n**$H_1$ 下的似然函数**\n在 $H_1$ 下，每个残差 $e_i \\sim \\mathcal{N}(\\mu, \\sigma_1^2)$。如果标准化为 $z_i = e_i/\\sigma_1$，那么 $z_i \\sim \\mathcal{N}(\\mu/\\sigma_1, 1)$。统计量 $S$ 为：\n$$ S = \\sum_{i=1}^n e_i^2 = \\sigma_1^2 \\sum_{i=1}^n \\left(\\frac{e_i}{\\sigma_1}\\right)^2 = \\sigma_1^2 \\sum_{i=1}^n z_i^2 $$\n和 $\\sum z_i^2$ 服从非中心卡方分布，记为 $\\chi'^2_n(\\lambda)$，其自由度为 $n$，非中心参数为 $\\lambda = \\sum_{i=1}^n (\\text{mean of } z_i)^2$。\n在这种情况下，非中心参数为：\n$$ \\lambda = n \\left(\\frac{\\mu}{\\sigma_1}\\right)^2 $$\n变量 $W = S/\\sigma_1^2$ 服从 $\\chi'^2_n(\\lambda)$ 分布。通过变量替换，似然 $f(S|H_1)$ 为：\n$$ f(S|H_1) = \\frac{1}{\\sigma_1^2} \\cdot \\text{ncChi2PDF}(S/\\sigma_1^2; \\text{df}=n, \\text{nc}=\\lambda) $$\n其中 $\\text{ncChi2PDF}$ 是非中心卡方分布的概率密度函数。\n\n**最终算法**\n对于每个测试用例，流程如下：\n1.  根据提供的残差计算 $S = \\sum_{i=1}^{n} e_i^2$。\n2.  使用参数为 $k=n/2$ 和 $\\theta=2\\sigma_0^2$ 的伽马概率密度函数计算似然 $L_0 = f(S|H_0)$。\n3.  使用如上所述的非中心卡方概率密度函数计算似然 $L_1 = f(S|H_1)$。\n4.  计算后验概率 $P(H_1|S) = \\frac{L_1 p_1}{L_1 p_1 + L_0 (1-p_1)}$。\n5.  计算决策阈值 $\\tau = C/(H \\cdot L)$。\n6.  如果 $P(H_1|S)  \\tau$，决策为重校准（True）。否则，决策为不重校准（False）。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import gamma, ncx2\n\ndef solve():\n    \"\"\"\n    Solves the digital twin recalibration problem for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"n\": 20, \"sigma0\": 0.5, \"sigma1\": 0.7, \"mu\": 0.3, \"p1\": 0.2,\n            \"H\": 10, \"L\": 1.0, \"C\": 4.0,\n            \"residuals\": [0.21, -0.38, 0.45, 0.50, -0.12, 0.33, 0.62, -0.15,\n                          0.27, 0.41, 0.35, -0.07, 0.58, 0.29, -0.24, 0.48,\n                          0.26, -0.11, 0.54, 0.31]\n        },\n        {\n            \"name\": \"Case B\",\n            \"n\": 10, \"sigma0\": 0.3, \"sigma1\": 0.5, \"mu\": 0.1, \"p1\": 0.3,\n            \"H\": 5, \"L\": 1.0, \"C\": 5.0,\n            \"residuals\": [-0.05, 0.02, -0.01, 0.03, -0.04, 0.01, 0.00,\n                          -0.02, 0.04, -0.03]\n        },\n        {\n            \"name\": \"Case C\",\n            \"n\": 1, \"sigma0\": 0.4, \"sigma1\": 0.5, \"mu\": 0.8, \"p1\": 0.1,\n            \"H\": 12, \"L\": 1.0, \"C\": 2.0,\n            \"residuals\": [1.20]\n        },\n        {\n            \"name\": \"Case D\",\n            \"n\": 5, \"sigma0\": 0.4, \"sigma1\": 0.6, \"mu\": 0.3, \"p1\": 0.8,\n            \"H\": 3, \"L\": 1.5, \"C\": 2.0,\n            \"residuals\": [0.05, -0.02, 0.10, -0.08, 0.06]\n        },\n        {\n            \"name\": \"Case E\",\n            \"n\": 8, \"sigma0\": 0.5, \"sigma1\": 0.5, \"mu\": 0.15, \"p1\": 0.25,\n            \"H\": 4, \"L\": 1.0, \"C\": 3.0,\n            \"residuals\": [0.20, -0.12, 0.18, 0.05, -0.07, 0.22, -0.03, 0.10]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        decision = should_recalibrate(\n            case[\"n\"], case[\"sigma0\"], case[\"sigma1\"], case[\"mu\"], case[\"p1\"],\n            case[\"H\"], case[\"L\"], case[\"C\"], np.array(case[\"residuals\"])\n        )\n        results.append(str(decision))\n\n    print(f\"[{','.join(results)}]\")\n\ndef should_recalibrate(n, sigma0, sigma1, mu, p1, H, L, C, residuals):\n    \"\"\"\n    Applies the derived Bayesian decision rule to recommend recalibration.\n\n    Args:\n        n (int): Number of residual samples.\n        sigma0 (float): Standard deviation under hypothesis H0.\n        sigma1 (float): Standard deviation under hypothesis H1.\n        mu (float): Mean bias under hypothesis H1.\n        p1 (float): Prior probability of H1.\n        H (float): Decision horizon.\n        L (float): Performance loss rate.\n        C (float): Recalibration cost.\n        residuals (np.ndarray): Array of observed residuals.\n\n    Returns:\n        bool: True if recalibration is recommended, False otherwise.\n    \"\"\"\n    # Step 1: Compute the observed statistic S (sum of squares)\n    S = np.sum(residuals**2)\n\n    # Step 2: Calculate the likelihood under H0 (well-calibrated)\n    # The distribution of S under H0 is Gamma(k=n/2, theta=2*sigma0^2).\n    # In scipy, shape `a` corresponds to k, and `scale` corresponds to theta.\n    k_H0 = n / 2.0\n    theta_H0 = 2 * sigma0**2\n    L0 = gamma.pdf(S, a=k_H0, scale=theta_H0)\n\n    # Step 3: Calculate the likelihood under H1 (mismatched)\n    # The distribution of S/sigma1^2 under H1 is non-central chi-squared.\n    # Degrees of freedom `df` = n.\n    # Non-centrality parameter `nc` = n * (mu/sigma1)^2.\n    df_H1 = n\n    nc_H1 = n * (mu / sigma1)**2\n    # The PDF of S is derived by change of variables from the ncx2 PDF.\n    # L1 = (1/sigma1^2) * PDF_ncx2(S/sigma1^2, df=df_H1, nc=nc_H1)\n    L1 = ncx2.pdf(S / sigma1**2, df=df_H1, nc=nc_H1) / sigma1**2\n\n    # Step 4: Calculate the posterior probability of mismatch, P(H1|S)\n    p0 = 1.0 - p1\n    \n    # Check for non-finite likelihoods to prevent division by zero, although\n    # PDFs should be non-negative. A zero denominator occurs if both likelihoods are zero.\n    denominator = (L1 * p1) + (L0 * p0)\n    if denominator == 0.0:\n        # If both likelihoods are zero, the evidence is impossible under the model.\n        # The posterior is undefined. A conservative choice is not to act.\n        # Alternatively, if one prior is 0 or 1, the result is trivial.\n        # p1 is in (0,1), so we can infer based on which likelihood is non-zero.\n        # If L1>0 and L0=0, P(H1|S) = 1. If L0>0 and L1=0, P(H1|S) = 0.\n        # Here we assume this edge case means posterior does not support action.\n        posterior_p1 = 0.0\n    else:\n        posterior_p1 = (L1 * p1) / denominator\n\n    # Step 5: Calculate the decision threshold\n    # The product H*L cannot be zero as H > 0 and L > 0\n    threshold = C / (H * L)\n\n    # Step 6: Make the decision\n    # Recalibrate if the posterior probability of mismatch exceeds the threshold.\n    return posterior_p1 > threshold\n\nsolve()\n```"
        }
    ]
}