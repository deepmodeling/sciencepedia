{
    "hands_on_practices": [
        {
            "introduction": "A core function of a digital twin is to continuously monitor a system and detect when its behavior deviates from the model's predictions. This first practice grounds you in the fundamentals of sequential change-point detection by deriving the classic Cumulative Sum (CUSUM) algorithm from first principles. By working through the derivation, you will understand how to use log-likelihood ratios to optimally accumulate evidence of a shift and how to characterize the detector's performance using the Average Run Length .",
            "id": "4231270",
            "problem": "A digital twin for a cyber-physical system executes a one-step-ahead predictor and monitors the innovation residuals $\\{r_t\\}_{t \\geq 1}$. Under a correctly specified model (no drift), assume $\\{r_t\\}$ are independent and identically distributed as Gaussian with zero mean and known variance, that is, $r_t \\sim \\mathcal{N}(0,\\sigma^2)$ with known $\\sigma^2$. A model drift corresponding to a constant additive bias causes a shift in the mean to a known design value $\\mu > 0$, so that post-change residuals follow $r_t \\sim \\mathcal{N}(\\mu,\\sigma^2)$ while the variance remains $\\sigma^2$. You will use a one-sided Cumulative Sum (CUSUM) procedure to detect this shift in the positive direction.\n\nStarting only from the probability density function of the Gaussian distribution and the definition of a likelihood ratio, perform the following:\n\n1. Derive the single-sample log-likelihood ratio $\\ell(r_t)$ for testing the null hypothesis $H_0: r_t \\sim \\mathcal{N}(0,\\sigma^2)$ versus the alternative hypothesis $H_1: r_t \\sim \\mathcal{N}(\\mu,\\sigma^2)$, expressed explicitly as a function of $r_t$, $\\mu$, and $\\sigma^2$ using the natural logarithm.\n\n2. Using the principle of sequential change detection and reflection at zero, derive the one-sided CUSUM recursion that accumulates $\\ell(r_t)$ and resets to zero when the partial sum becomes negative. Define the stopping time $T_h$ as the first index $t$ at which the CUSUM statistic exceeds a fixed threshold $h$ (measured in natural logarithm units).\n\n3. Using Wald-type approximations grounded in the moment generating function and ignoring overshoot corrections, compute the in-control Average Run Length $\\mathrm{ARL}_0 \\triangleq \\mathbb{E}_0[T_h]$ for the derived CUSUM, where the subscript $0$ denotes expectation under $H_0$. For the purposes of this computation, take the design parameters $\\mu = 0.5$, $\\sigma = 1$, and threshold $h = 8$. Round your final numerical answer for $\\mathrm{ARL}_0$ to four significant figures and express it in samples.",
            "solution": "The problem requires a three-part analysis of a one-sided Cumulative Sum (CUSUM) procedure for detecting a shift in the mean of a Gaussian process. The analysis will proceed by first validating the problem statement, which has been found to be scientifically sound, well-posed, and objective. We will now derive the necessary components and compute the required quantity.\n\nFirst, we derive the single-sample log-likelihood ratio, $\\ell(r_t)$, for testing the null hypothesis $H_0$ against the alternative $H_1$. The probability density function (PDF) of a Gaussian distribution with mean $\\theta$ and variance $\\sigma^2$ is given by\n$$f(x; \\theta, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\theta)^2}{2\\sigma^2}\\right)$$\nUnder the null hypothesis $H_0$, the residuals $r_t$ are distributed as $r_t \\sim \\mathcal{N}(0, \\sigma^2)$, so their PDF is\n$$f_0(r_t) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{r_t^2}{2\\sigma^2}\\right)$$\nUnder the alternative hypothesis $H_1$, the residuals $r_t$ are distributed as $r_t \\sim \\mathcal{N}(\\mu, \\sigma^2)$, with the PDF\n$$f_1(r_t) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(r_t - \\mu)^2}{2\\sigma^2}\\right)$$\nThe likelihood ratio $L(r_t)$ is the ratio of these two densities:\n$$L(r_t) = \\frac{f_1(r_t)}{f_0(r_t)} = \\frac{\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(r_t - \\mu)^2}{2\\sigma^2}\\right)}{\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{r_t^2}{2\\sigma^2}\\right)} = \\exp\\left(\\frac{r_t^2 - (r_t - \\mu)^2}{2\\sigma^2}\\right)$$\nThe exponent can be simplified:\n$$r_t^2 - (r_t - \\mu)^2 = r_t^2 - (r_t^2 - 2\\mu r_t + \\mu^2) = 2\\mu r_t - \\mu^2$$\nSubstituting this back into the expression for $L(r_t)$ gives\n$$L(r_t) = \\exp\\left(\\frac{2\\mu r_t - \\mu^2}{2\\sigma^2}\\right)$$\nThe single-sample log-likelihood ratio, $\\ell(r_t)$, is the natural logarithm of $L(r_t)$:\n$$\\ell(r_t) = \\ln(L(r_t)) = \\frac{2\\mu r_t - \\mu^2}{2\\sigma^2} = \\frac{\\mu}{\\sigma^2}r_t - \\frac{\\mu^2}{2\\sigma^2}$$\nThis is the required expression for the log-likelihood ratio increment.\n\nSecond, we define the one-sided CUSUM recursion and the associated stopping time. The CUSUM statistic, denoted by $S_t$, accumulates the log-likelihood ratio increments $\\ell(r_t)$ over time. The \"reflection at zero\" principle means the cumulative sum is not allowed to become negative; if it does, it is reset to zero. This is captured by the following recursion:\n$$S_0 = 0$$\n$$S_t = \\max(0, S_{t-1} + \\ell(r_t)) \\quad \\text{for } t \\geq 1$$\nThe detection of a change occurs when the statistic $S_t$ first exceeds a predefined threshold $h$. The stopping time, $T_h$, is formally defined as:\n$$T_h \\triangleq \\inf\\{t \\geq 1 : S_t > h\\}$$\n\nThird, we compute the in-control Average Run Length, $\\mathrm{ARL}_0 = \\mathbb{E}_0[T_h]$, using a Wald-type approximation. This approximation is based on large deviation theory and renewal arguments. Under the in-control hypothesis $H_0$, the expected value of the increment $\\ell(r_t)$ is negative:\n$$\\mathbb{E}_0[\\ell(r_t)] = \\mathbb{E}_0\\left[\\frac{\\mu}{\\sigma^2}r_t - \\frac{\\mu^2}{2\\sigma^2}\\right] = \\frac{\\mu}{\\sigma^2}\\mathbb{E}_0[r_t] - \\frac{\\mu^2}{2\\sigma^2} = \\frac{\\mu}{\\sigma^2}(0) - \\frac{\\mu^2}{2\\sigma^2} = -\\frac{\\mu^2}{2\\sigma^2}$$\nDue to this negative drift, the statistic $S_t$ will frequently reset to $0$. The process of reaching the threshold $h$ can be viewed as a sequence of renewal cycles, where each cycle has a small probability $p$ of resulting in a false alarm (i.e., crossing $h$). The number of samples until this event, $T_h$, is approximately geometrically distributed with mean $1/p$. Thus, $\\mathrm{ARL}_0 \\approx 1/p$.\n\nThe probability $p$ that the process, starting from $0$, ever crosses the boundary $h$ can be approximated using a result related to Wald's identity and Cramér's theorem. The approximation is $p \\approx \\exp(-\\theta^* h)$, where $\\theta^*$ is the non-zero solution to the equation $\\mathbb{E}_0[\\exp(\\theta \\ell(r_t))] = 1$. Let us find this $\\theta^*$.\nThe moment generating function (MGF) of $\\ell(r_t)$ under $H_0$ is:\n$$\\psi_0(\\theta) = \\mathbb{E}_0[\\exp(\\theta \\ell(r_t))] = \\mathbb{E}_0\\left[\\exp\\left(\\theta \\left(\\frac{\\mu r_t}{\\sigma^2} - \\frac{\\mu^2}{2\\sigma^2}\\right)\\right)\\right] = \\exp\\left(-\\frac{\\theta \\mu^2}{2\\sigma^2}\\right) \\mathbb{E}_0\\left[\\exp\\left(\\frac{\\theta \\mu}{\\sigma^2}r_t\\right)\\right]$$\nThe term inside the expectation is the MGF of a normal random variable $r_t \\sim \\mathcal{N}(0, \\sigma^2)$ evaluated at the point $k = \\frac{\\theta \\mu}{\\sigma^2}$. The MGF of $\\mathcal{N}(m, s^2)$ is $\\exp(mk + s^2k^2/2)$. For our case, $m=0$ and $s^2=\\sigma^2$, so:\n$$\\mathbb{E}_0\\left[\\exp\\left(\\frac{\\theta \\mu}{\\sigma^2}r_t\\right)\\right] = \\exp\\left(0 \\cdot \\frac{\\theta \\mu}{\\sigma^2} + \\frac{\\sigma^2}{2}\\left(\\frac{\\theta \\mu}{\\sigma^2}\\right)^2\\right) = \\exp\\left(\\frac{\\sigma^2 \\theta^2 \\mu^2}{2\\sigma^4}\\right) = \\exp\\left(\\frac{\\theta^2 \\mu^2}{2\\sigma^2}\\right)$$\nSubstituting this back into the expression for $\\psi_0(\\theta)$:\n$$\\psi_0(\\theta) = \\exp\\left(-\\frac{\\theta \\mu^2}{2\\sigma^2}\\right) \\exp\\left(\\frac{\\theta^2 \\mu^2}{2\\sigma^2}\\right) = \\exp\\left(\\frac{\\mu^2}{2\\sigma^2}(\\theta^2 - \\theta)\\right)$$\nWe seek the non-zero $\\theta^*$ that solves $\\psi_0(\\theta^*) = 1$. This implies the exponent must be zero:\n$$\\frac{\\mu^2}{2\\sigma^2}((\\theta^*)^2 - \\theta^*) = 0$$\nSince $\\mu > 0$ and $\\sigma^2 > 0$, this simplifies to $(\\theta^*)^2 - \\theta^* = 0$, or $\\theta^*(\\theta^* - 1) = 0$. The non-zero solution is $\\theta^* = 1$.\nWith $\\theta^* = 1$, the probability of a false alarm in a cycle is $p \\approx \\exp(-1 \\cdot h) = \\exp(-h)$.\nThe resulting approximation for the in-control Average Run Length is:\n$$\\mathrm{ARL}_0 \\approx \\frac{1}{p} \\approx \\frac{1}{\\exp(-h)} = \\exp(h)$$\nThis approximation is valid for large $h$ and when overshoot is ignored. The specific values $\\mu = 0.5$ and $\\sigma=1$ were not required for this general derivation, as $\\theta^*$ is independent of them.\nNow, we use the given threshold $h=8$ to compute the numerical value:\n$$\\mathrm{ARL}_0 \\approx \\exp(8)$$\nCalculating the value of $\\exp(8)$:\n$$\\exp(8) \\approx 2980.957987...$$\nRounding this to four significant figures yields $2981$. The result is expressed in units of samples.",
            "answer": "$$\\boxed{2981}$$"
        },
        {
            "introduction": "Once a drift is detected or suspected, the next step is often adaptation. This exercise introduces a common and important drift scenario known as label shift, where the underlying frequency of different classes changes over time. You will derive the Black Box Shift Estimator (BBSE), an elegant and direct analytical method for estimating these new class frequencies, demonstrating how a well-posed assumption can lead to a highly efficient adaptation strategy .",
            "id": "4231216",
            "problem": "A digital twin of a manufacturing Cyber-Physical System (CPS) monitors a multi-class process state using a fixed classifier with $K$ classes. The digital twin is deployed under a source environment with joint distribution $P_{s}(x, y)$ and later receives unlabeled data from a target environment with joint distribution $P_{t}(x, y)$. Assume the following formal label shift condition: $P_{t}(x \\mid y) = P_{s}(x \\mid y)$ for all classes $y \\in \\{1, \\dots, K\\}$, but $P_{t}(y)$ may differ from $P_{s}(y)$. Let the classifier’s predicted label be $\\hat{y} \\in \\{1, \\dots, K\\}$, produced by a fixed mapping from $x$ that does not change between source and target.\n\nThe source environment provides access to labeled data to estimate the classifier’s confusion matrix $C \\in \\mathbb{R}^{K \\times K}$ with entries $C_{ij} = P_{s}(\\hat{y} = i \\mid y = j)$. The target environment provides only unlabeled data, from which the digital twin can estimate the prediction marginal vector $\\boldsymbol{q}_{t} \\in \\mathbb{R}^{K}$ with entries $[\\boldsymbol{q}_{t}]_{i} = P_{t}(\\hat{y} = i)$. Define the source class prior vector $\\boldsymbol{\\mu}_{s} \\in \\mathbb{R}^{K}$ with entries $[\\boldsymbol{\\mu}_{s}]_{j} = P_{s}(y = j)$, and the target class prior vector $\\boldsymbol{\\mu}_{t} \\in \\mathbb{R}^{K}$ with entries $[\\boldsymbol{\\mu}_{t}]_{j} = P_{t}(y = j)$.\n\nStarting from the law of total probability and the formal definition of label shift, derive the Black Box Shift Estimator (BBSE) that expresses the target class prior vector $\\boldsymbol{\\mu}_{t}$ as a function of the confusion matrix $C$ and the target prediction marginal vector $\\boldsymbol{q}_{t}$. Then, state the necessary and sufficient identifiability conditions under which $\\boldsymbol{\\mu}_{t}$ is uniquely determined by $C$ and $\\boldsymbol{q}_{t}$ in this CPS digital twin setting. Your final answer must be a single closed-form analytic expression for $\\boldsymbol{\\mu}_{t}$ in terms of $C$ and $\\boldsymbol{q}_{t}$. No numerical computation is required, and no rounding is needed. Express the final answer as a symbolic expression without units.",
            "solution": "The objective is to derive an expression for the target class prior vector, $\\boldsymbol{\\mu}_{t}$, in terms of the source confusion matrix, $C$, and the target prediction marginal vector, $\\boldsymbol{q}_{t}$, under the label shift assumption. We will also state the conditions under which this estimation is uniquely possible.\n\nLet's begin with the law of total probability for the marginal probability of a prediction $\\hat{y} = i$ in the target domain. This is given by summing over all possible true classes $y=j$:\n$$\nP_{t}(\\hat{y} = i) = \\sum_{j=1}^{K} P_{t}(\\hat{y} = i, y = j)\n$$\nUsing the definition of conditional probability, $P(A, B) = P(A \\mid B) P(B)$, we can rewrite this as:\n$$\nP_{t}(\\hat{y} = i) = \\sum_{j=1}^{K} P_{t}(\\hat{y} = i \\mid y = j) P_{t}(y = j)\n$$\nNow, we will substitute the terms defined in the problem statement into this equation.\nThe $i$-th entry of the target prediction marginal vector $\\boldsymbol{q}_{t}$ is $[\\boldsymbol{q}_{t}]_{i} = P_{t}(\\hat{y} = i)$.\nThe $j$-th entry of the target class prior vector $\\boldsymbol{\\mu}_{t}$ is $[\\boldsymbol{\\mu}_{t}]_{j} = P_{t}(y = j)$.\nSubstituting these into our equation yields:\n$$\n[\\boldsymbol{q}_{t}]_{i} = \\sum_{j=1}^{K} P_{t}(\\hat{y} = i \\mid y = j) [\\boldsymbol{\\mu}_{t}]_{j}\n$$\nThe next step is to evaluate the term $P_{t}(\\hat{y} = i \\mid y = j)$. The problem states the formal label shift condition, $P_{t}(x \\mid y) = P_{s}(x \\mid y)$, and that the classifier is a fixed mapping from the feature space $x$ to a predicted label $\\hat{y}$. Let this mapping be denoted by the function $h$, so $\\hat{y}=h(x)$. The conditional probability of a prediction $\\hat{y}=i$ given a true label $y=j$ is the probability that a feature vector $x$ drawn from the distribution $P(x \\mid y=j)$ is mapped to $i$ by the classifier. This can be expressed as an integral over the subset of the feature space where $h(x)=i$:\n$$\nP(\\hat{y}=i \\mid y=j) = \\int_{\\{x \\mid h(x)=i\\}} P(x \\mid y=j) dx\n$$\nSince the function $h(x)$ is fixed and the conditional feature distribution is invariant between the source and target domains ($P_{t}(x \\mid y=j) = P_{s}(x \\mid y=j)$), it follows directly that the conditional prediction distribution is also invariant:\n$$\nP_{t}(\\hat{y} = i \\mid y = j) = P_{s}(\\hat{y} = i \\mid y = j)\n$$\nThe problem defines the source confusion matrix $C$ to have entries $C_{ij} = P_{s}(\\hat{y} = i \\mid y = j)$. Therefore, we have:\n$$\nP_{t}(\\hat{y} = i \\mid y = j) = C_{ij}\n$$\nSubstituting this back into our equation for $[\\boldsymbol{q}_{t}]_{i}$:\n$$\n[\\boldsymbol{q}_{t}]_{i} = \\sum_{j=1}^{K} C_{ij} [\\boldsymbol{\\mu}_{t}]_{j}\n$$\nThis equation holds for each prediction class $i \\in \\{1, \\dots, K\\}$. This system of $K$ linear equations can be expressed concisely in matrix-vector form. The right-hand side is the definition of the matrix-vector product $C \\boldsymbol{\\mu}_{t}$. Thus, we have:\n$$\n\\boldsymbol{q}_{t} = C \\boldsymbol{\\mu}_{t}\n$$\nTo solve for the unknown target class prior vector $\\boldsymbol{\\mu}_{t}$, we need to isolate it. If the confusion matrix $C$ is invertible, we can left-multiply both sides by its inverse, $C^{-1}$:\n$$\nC^{-1} \\boldsymbol{q}_{t} = C^{-1} C \\boldsymbol{\\mu}_{t}\n$$\n$$\nC^{-1} \\boldsymbol{q}_{t} = I \\boldsymbol{\\mu}_{t}\n$$\n$$\n\\boldsymbol{\\mu}_{t} = C^{-1} \\boldsymbol{q}_{t}\n$$\nThis expression is the Black Box Shift Estimator (BBSE).\n\nThe second part of the task is to state the necessary and sufficient identifiability conditions. The target class prior vector $\\boldsymbol{\\mu}_{t}$ is uniquely determined by $C$ and $\\boldsymbol{q}_{t}$ if and only if the system of linear equations $\\boldsymbol{q}_{t} = C \\boldsymbol{\\mu}_{t}$ has a unique solution for $\\boldsymbol{\\mu}_{t}$. From linear algebra, a unique solution exists if and only if the matrix $C$ is invertible (or non-singular). An invertible matrix has a non-zero determinant, $\\det(C) \\neq 0$, and its column vectors (and row vectors) are linearly independent.\n\nIn the context of this problem, the $j$-th column of $C$ is the vector of conditional probabilities of classifier predictions given the true class is $j$. If the columns of $C$ are not linearly independent, it implies that the classifier's responses to different true classes are statistically confounded, making it impossible to uniquely disentangle the contributions of each true class to the observed prediction marginals $\\boldsymbol{q}_{t}$. Therefore, the necessary and sufficient condition for the identifiability of $\\boldsymbol{\\mu}_{t}$ is the invertibility of the confusion matrix $C$.",
            "answer": "$$\\boxed{C^{-1} \\boldsymbol{q}_{t}}$$"
        },
        {
            "introduction": "Building on the concept of label shift adaptation, this practice explores a more powerful and general iterative method: the Expectation-Maximization (EM) algorithm. Unlike the direct analytical solution in the previous exercise , the EM algorithm allows for adaptation in more complex scenarios using only the classifier's outputs and is a foundational technique for problems with latent variables. This hands-on derivation and implementation will equip you with a key computational tool for advanced model adaptation .",
            "id": "4231223",
            "problem": "Consider a digital twin of a cyber-physical system that continuously classifies operational states into $K$ discrete categories using a calibrated classifier trained on source-domain data. Let the source-domain class prior be $\\pi^{s} \\in \\mathbb{R}^{K}$ with entries $\\pi^{s}_{k} \\in (0,1)$ satisfying $\\sum_{k=1}^{K} \\pi^{s}_{k} = 1$. In the target domain, model drift occurs in the form of label shift: the conditional distribution of features given the label is invariant, but class priors change. Formally, the label shift assumption is $p_{t}(x \\mid y=k) = p_{s}(x \\mid y=k)$ for all $k \\in \\{1,\\dots,K\\}$, while $p_{t}(y=k) = \\pi_{k}$ may differ from $\\pi^{s}_{k}$. The digital twin collects target-domain feature instances $x_{i}$ for $i \\in \\{1,\\dots,n\\}$ with reliability weights $w_{i}  0$, and the source classifier provides calibrated posteriors $q_{ik} = p_{s}(y=k \\mid x_{i})$ satisfying $\\sum_{k=1}^{K} q_{ik} = 1$ for each $i$. Under the label shift model and Bayes rule, the target-domain weighted log-likelihood of the observed features, as a function of the unknown target prior $\\pi \\in \\Delta^{K-1}$ where $\\Delta^{K-1} = \\{ \\pi \\in \\mathbb{R}^{K} \\mid \\pi_{k} \\ge 0, \\sum_{k=1}^{K} \\pi_{k} = 1 \\}$, is\n$$\n\\mathcal{L}_{w}(\\pi) = \\sum_{i=1}^{n} w_{i} \\log \\left( \\sum_{k=1}^{K} \\frac{q_{ik}}{\\pi^{s}_{k}} \\, \\pi_{k} \\right),\n$$\nwhere the factor $a_{ik} = \\frac{q_{ik}}{\\pi^{s}_{k}}$ arises from the identity $p_{s}(x \\mid y=k) = \\frac{p_{s}(y=k \\mid x) \\, p_{s}(x)}{\\pi^{s}_{k}}$ and $p_{s}(x)$ does not depend on $\\pi$. Your task is twofold:\n\n1. Derive from first principles an Expectation-Maximization (EM) procedure for maximizing $\\mathcal{L}_{w}(\\pi)$ under the label shift model, starting from the following base:\n   - Bayes theorem $p(y \\mid x) = \\frac{p(x \\mid y) p(y)}{p(x)}$,\n   - The definition of weighted log-likelihood $\\mathcal{L}_{w}(\\pi)$ for independent observations with weights $w_{i}$,\n   - The Expectation-Maximization (EM) method defined as alternating maximization of a Jensen lower bound on $\\mathcal{L}_{w}(\\pi)$ using latent variables,\n   - Jensen's inequality for the concavity of the logarithm function.\n   Your derivation must specify the E-step responsibilities and the M-step update for $\\pi$, and must prove that each EM iteration monotonically increases (or leaves unchanged) $\\mathcal{L}_{w}(\\pi)$, thus ensuring convergence to at least a local maximum.\n\n2. Implement a complete, runnable program that:\n   - Accepts no external input and uses internal test cases,\n   - Computes the EM sequence $\\{\\pi^{(t)}\\}_{t=0}^{T}$ and the corresponding sequence $\\{\\mathcal{L}_{w}(\\pi^{(t)})\\}_{t=0}^{T}$ for each test case,\n   - Verifies monotone non-decrease in $\\mathcal{L}_{w}(\\pi^{(t)})$ across iterations within numerical tolerance,\n   - Returns for each test case a boolean indicating monotone improvement and the final estimate $\\pi^{(\\text{final})}$.\n\nUse the following test suite with all quantities expressed as unitless decimals:\n- Test Case A (general case): $K=3$, $n=8$, $\\pi^{s} = [0.5, 0.3, 0.2]$, $q$ rows are\n  $[0.7, 0.2, 0.1]$, $[0.6, 0.25, 0.15]$, $[0.2, 0.7, 0.1]$, $[0.1, 0.2, 0.7]$, $[0.5, 0.3, 0.2]$, $[0.55, 0.3, 0.15]$, $[0.4, 0.4, 0.2]$, $[0.3, 0.3, 0.4]$, and weights $w = [1.0, 0.8, 1.2, 1.5, 0.9, 1.1, 1.0, 0.7]$.\n- Test Case B (information-poor boundary): $K=3$, $n=6$, $\\pi^{s} = [0.5, 0.3, 0.2]$, $q$ rows are all $[0.5, 0.3, 0.2]$, and weights $w = [1.0, 2.0, 0.5, 1.5, 0.75, 1.25]$.\n- Test Case C (edge case with zeros): $K=4$, $n=6$, $\\pi^{s} = [0.4, 0.25, 0.2, 0.15]$, $q$ rows are $[0.95, 0.05, 0.0, 0.0]$, $[0.0, 0.9, 0.1, 0.0]$, $[0.0, 0.0, 1.0, 0.0]$, $[0.1, 0.0, 0.0, 0.9]$, $[0.5, 0.5, 0.0, 0.0]$, $[0.2, 0.3, 0.5, 0.0]$, and weights $w = [2.0, 1.0, 1.5, 3.0, 1.2, 0.8]$.\n\nInitialization must use $\\pi^{(0)} = \\pi^{s}$ for each test case. For numerical stability, ensure that all iterates satisfy $\\pi^{(t)}_{k} \\in (0,1)$ and $\\sum_{k=1}^{K} \\pi^{(t)}_{k} = 1$, and use a tolerance of $10^{-10}$ for convergence and for checking monotonic non-decrease.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must be of the form $[\\text{monotone},[\\pi_{1}^{(\\text{final})},\\dots,\\pi_{K}^{(\\text{final})}]]$, where $\\text{monotone}$ is a boolean and the $\\pi_{k}^{(\\text{final})}$ are decimals. For example, the overall output should be of the form $[[\\text{True},[0.4,0.4,0.2]],[\\text{True},[0.5,0.3,0.2]],[\\text{True},[0.45,0.25,0.2,0.1]]]$ (the numeric values shown here are illustrative only).",
            "solution": "The user-provided problem statement has been analyzed and is deemed valid. It is scientifically grounded in statistical machine learning, well-posed as a convex optimization problem, and contains a complete and consistent set of givens.\n\nHerein, a complete solution is provided, starting with a first-principles derivation of the Expectation-Maximization (EM) algorithm for the specified problem, followed by the implementation details.\n\n### Part 1: Derivation of the Expectation-Maximization (EM) Algorithm\n\nThe objective is to find the target-domain class prior $\\pi \\in \\Delta^{K-1}$ that maximizes the weighted log-likelihood of the observed target-domain features $\\{x_i\\}_{i=1}^n$. The set $\\Delta^{K-1}$ is the $(K-1)$-dimensional probability simplex, defined as $\\Delta^{K-1} = \\{ \\pi \\in \\mathbb{R}^{K} \\mid \\pi_{k} \\ge 0, \\sum_{k=1}^{K} \\pi_{k} = 1 \\}$.\n\n**1. Observed-Data Log-Likelihood**\n\nThe probability of observing a single feature vector $x_i$ in the target domain, $p_t(x_i)$, is obtained by marginalizing over the unknown class labels $y=k$ for $k \\in \\{1, \\dots, K\\}$:\n$$p_t(x_i; \\pi) = \\sum_{k=1}^{K} p_t(x_i, y=k; \\pi) = \\sum_{k=1}^{K} p_t(x_i \\mid y=k) p_t(y=k; \\pi)$$\nThe model is defined by two key assumptions:\n- The target-domain class prior is $p_t(y=k; \\pi) = \\pi_k$.\n- The label shift assumption states that the class-conditional feature distribution is invariant: $p_t(x \\mid y=k) = p_s(x \\mid y=k)$.\n\nSubstituting these into the expression for $p_t(x_i; \\pi)$:\n$$p_t(x_i; \\pi) = \\sum_{k=1}^{K} p_s(x_i \\mid y=k) \\pi_k$$\nUsing Bayes' theorem for the source domain, we can express $p_s(x_i \\mid y=k)$ in terms of the given quantities: the source classifier's posterior $q_{ik} = p_s(y=k \\mid x_i)$ and the source prior $\\pi^s_k = p_s(y=k)$.\n$$p_s(x_i \\mid y=k) = \\frac{p_s(y=k \\mid x_i) p_s(x_i)}{p_s(y=k)} = \\frac{q_{ik} p_s(x_i)}{\\pi^s_k}$$\nSubstituting this back into the expression for $p_t(x_i; \\pi)$:\n$$p_t(x_i; \\pi) = \\sum_{k=1}^{K} \\frac{q_{ik} p_s(x_i)}{\\pi^s_k} \\pi_k = p_s(x_i) \\sum_{k=1}^{K} \\frac{q_{ik}}{\\pi^s_k} \\pi_k$$\nThe weighted log-likelihood for $n$ independent observations $\\{x_i\\}$, each with weight $w_i > 0$, is:\n$$ \\mathcal{L}_w(\\pi) = \\sum_{i=1}^{n} w_i \\log p_t(x_i; \\pi) = \\sum_{i=1}^{n} w_i \\log \\left( p_s(x_i) \\sum_{k=1}^{K} \\frac{q_{ik}}{\\pi^s_k} \\pi_k \\right) $$\n$$ \\mathcal{L}_w(\\pi) = \\sum_{i=1}^{n} w_i \\log p_s(x_i) + \\sum_{i=1}^{n} w_i \\log \\left( \\sum_{k=1}^{K} \\frac{q_{ik}}{\\pi^s_k} \\pi_k \\right) $$\nWhen maximizing with respect to $\\pi$, the term $\\sum_{i=1}^{n} w_i \\log p_s(x_i)$ is a constant and can be disregarded. Thus, we aim to maximize the objective function provided in the problem statement:\n$$ \\mathcal{L}_{w}(\\pi) = \\sum_{i=1}^{n} w_{i} \\log \\left( \\sum_{k=1}^{K} \\frac{q_{ik}}{\\pi^{s}_{k}} \\, \\pi_{k} \\right) $$\nThe sum inside the logarithm makes direct maximization difficult. This structure is canonical for the application of the Expectation-Maximization (EM) algorithm.\n\n**2. The EM Framework with Latent Variables**\n\nWe introduce latent variables $Z = \\{z_{ik}\\}_{i=1, k=1}^{n, K}$, where $z_{ik}=1$ if the true label of observation $x_i$ is $k$, and $z_{ik}=0$ otherwise. For each $i$, $\\{z_{i1}, \\dots, z_{iK}\\}$ is a one-hot vector.\n\nThe complete-data, which includes both observed data $X=\\{x_i\\}$ and latent data $Z$, has a simpler likelihood. The joint probability of $(x_i, z_i)$ where $z_i$ represents the one-hot vector for observation $i$ is:\n$$ p_t(x_i, z_i; \\pi) = \\prod_{k=1}^{K} (p_t(x_i, y=k; \\pi))^{z_{ik}} = \\prod_{k=1}^{K} (p_s(x_i \\mid y=k) \\pi_k)^{z_{ik}} $$\nThe complete-data weighted log-likelihood $\\mathcal{L}_c(\\pi; X, Z)$ is:\n$$ \\mathcal{L}_c(\\pi; X, Z) = \\sum_{i=1}^{n} w_i \\log p_t(x_i, z_i; \\pi) = \\sum_{i=1}^{n} w_i \\sum_{k=1}^K z_{ik} \\log(p_s(x_i|y=k)\\pi_k) $$\nThe EM algorithm iteratively finds a parameter estimate $\\pi^{(t+1)}$ that increases the log-likelihood by maximizing the expectation of $\\mathcal{L}_c$ taken over the latent variables $Z$, conditional on the observed data $X$ and the current parameter estimate $\\pi^{(t)}$. This expectation is the Q-function:\n$$ Q(\\pi, \\pi^{(t)}) = E_{Z \\mid X, \\pi^{(t)}}[\\mathcal{L}_c(\\pi; X, Z)] $$\n\n**3. E-Step: Computing Responsibilities**\n\nThe E-step involves calculating the Q-function. By linearity of expectation:\n$$ Q(\\pi, \\pi^{(t)}) = \\sum_{i=1}^{n} w_i \\sum_{k=1}^{K} E[z_{ik} \\mid x_i, \\pi^{(t)}] \\log(p_s(x_i|y=k)\\pi_k) $$\nThe expectation $E[z_{ik} \\mid x_i, \\pi^{(t)}]$ is the posterior probability that the true label for $x_i$ is $k$, given the data $x_i$ and the current estimate $\\pi^{(t)}$. This is called the \"responsibility\" of class $k$ for observation $i$, denoted by $\\gamma_{ik}^{(t)}$:\n$$ \\gamma_{ik}^{(t)} = P(y=k \\mid x_i; \\pi^{(t)})_t = \\frac{p_t(x_i \\mid y=k) p_t(y=k; \\pi^{(t)})}{p_t(x_i; \\pi^{(t)})} = \\frac{p_s(x_i \\mid y=k) \\pi_k^{(t)}}{\\sum_{j=1}^K p_s(x_i \\mid y=j) \\pi_j^{(t)}} $$\nSubstituting $p_s(x_i \\mid y=j) = q_{ij}p_s(x_i)/\\pi^s_j$:\n$$ \\gamma_{ik}^{(t)} = \\frac{\\frac{q_{ik} p_s(x_i)}{\\pi^s_k} \\pi_k^{(t)}}{\\sum_{j=1}^K \\frac{q_{ij} p_s(x_i)}{\\pi^s_j} \\pi_j^{(t)}} = \\frac{\\frac{q_{ik}}{\\pi^s_k} \\pi_k^{(t)}}{\\sum_{j=1}^K \\frac{q_{ij}}{\\pi^s_j} \\pi_j^{(t)}} $$\nThis is the final expression for the responsibilities computed in the E-step.\n\n**4. M-Step: Maximizing the Q-Function**\n\nThe M-step updates the parameters by maximizing $Q(\\pi, \\pi^{(t)})$ with respect to $\\pi$:\n$$ \\pi^{(t+1)} = \\arg\\max_{\\pi \\in \\Delta^{K-1}} Q(\\pi, \\pi^{(t)}) $$\nWe can split the Q-function into two parts:\n$$ Q(\\pi, \\pi^{(t)}) = \\sum_{i=1}^{n} \\sum_{k=1}^{K} w_i \\gamma_{ik}^{(t)} \\log p_s(x_i|y=k) + \\sum_{i=1}^{n} \\sum_{k=1}^{K} w_i \\gamma_{ik}^{(t)} \\log \\pi_k $$\nThe first term does not depend on $\\pi$, so we only need to maximize the second term subject to the constraint $\\sum_{k=1}^K \\pi_k = 1$. Let's define the function to maximize as:\n$$ F(\\pi) = \\sum_{k=1}^K \\left( \\sum_{i=1}^n w_i \\gamma_{ik}^{(t)} \\right) \\log \\pi_k $$\nWe use a Lagrange multiplier $\\lambda$ for the sum constraint:\n$$ \\mathcal{J}(\\pi, \\lambda) = \\sum_{k=1}^K \\left( \\sum_{i=1}^n w_i \\gamma_{ik}^{(t)} \\right) \\log \\pi_k + \\lambda \\left(1 - \\sum_{k=1}^K \\pi_k \\right) $$\nTaking the derivative with respect to $\\pi_j$ and setting it to $0$:\n$$ \\frac{\\partial \\mathcal{J}}{\\partial \\pi_j} = \\frac{1}{\\pi_j} \\sum_{i=1}^n w_i \\gamma_{ij}^{(t)} - \\lambda = 0 \\implies \\sum_{i=1}^n w_i \\gamma_{ij}^{(t)} = \\lambda \\pi_j $$\nSumming over all classes $j=1, \\dots, K$:\n$$ \\sum_{j=1}^K \\sum_{i=1}^n w_i \\gamma_{ij}^{(t)} = \\sum_{j=1}^K \\lambda \\pi_j = \\lambda \\sum_{j=1}^K \\pi_j = \\lambda $$\nSince $\\sum_{j=1}^K \\gamma_{ij}^{(t)} = 1$ for any $i$, we can simplify the left side:\n$$ \\lambda = \\sum_{i=1}^n w_i \\sum_{j=1}^K \\gamma_{ij}^{(t)} = \\sum_{i=1}^n w_i (1) = \\sum_{i=1}^n w_i $$\nLet $W = \\sum_{i=1}^n w_i$. Substituting $\\lambda=W$ back, we find the update rule for $\\pi_k$:\n$$ \\pi_k^{(t+1)} = \\frac{1}{\\lambda} \\sum_{i=1}^n w_i \\gamma_{ik}^{(t)} = \\frac{\\sum_{i=1}^n w_i \\gamma_{ik}^{(t)}}{\\sum_{j=1}^n w_j} $$\nThis is the M-step update rule. It holds that $\\pi_k^{(t+1)} \\ge 0$ since $w_i > 0$ and $\\gamma_{ik}^{(t)} \\ge 0$. It also holds that $\\sum_k \\pi_k^{(t+1)} = 1$.\n\n**5. Proof of Monotonic Convergence**\nThe EM algorithm is guaranteed to find a local maximum of the likelihood function because each iteration monotonically increases (or leaves unchanged) the value of $\\mathcal{L}_w(\\pi)$.\nFor any distribution $\\{c_{ik}\\}$ over the latent labels (i.e., $c_{ik} \\ge 0, \\sum_k c_{ik} = 1$), Jensen's inequality for the concave $\\log$ function provides a lower bound on the log-likelihood:\n$$ \\mathcal{L}_w(\\pi) = \\sum_{i=1}^n w_i \\log \\left( \\sum_{k=1}^K p_t(x_i, y=k; \\pi) \\right) = \\sum_{i=1}^n w_i \\log \\left( \\sum_{k=1}^K c_{ik} \\frac{p_t(x_i, y=k; \\pi)}{c_{ik}} \\right) \\ge \\sum_{i=1}^n w_i \\sum_{k=1}^K c_{ik} \\log \\frac{p_t(x_i, y=k; \\pi)}{c_{ik}} $$\nLet this lower bound be $\\mathcal{F}(c, \\pi)$. The EM algorithm can be viewed as coordinate ascent on $\\mathcal{F}$.\n- **E-Step**: Given $\\pi^{(t)}$, we maximize $\\mathcal{F}(c, \\pi^{(t)})$ with respect to $c$. The bound becomes tight ($\\mathcal{L}_w(\\pi^{(t)}) = \\mathcal{F}(c, \\pi^{(t)})$) when we choose $c_{ik} = P(y=k \\mid x_i; \\pi^{(t)})_t = \\gamma_{ik}^{(t)}$.\n- **M-Step**: Given $c = \\gamma^{(t)}$, we maximize $\\mathcal{F}(\\gamma^{(t)}, \\pi)$ with respect to $\\pi$. This maximization yields $\\pi^{(t+1)}$. Note that maximizing $\\mathcal{F}(\\gamma^{(t)}, \\pi)$ is equivalent to maximizing $Q(\\pi, \\pi^{(t)})$, as the terms involving $\\log c_{ik}$ do not depend on $\\pi$.\nSo we have the sequence of relations:\n$$ \\mathcal{L}_w(\\pi^{(t+1)}) \\ge \\mathcal{F}(\\gamma^{(t)}, \\pi^{(t+1)}) \\quad (\\text{Jensen's inequality}) $$\n$$ \\mathcal{F}(\\gamma^{(t)}, \\pi^{(t+1)}) \\ge \\mathcal{F}(\\gamma^{(t)}, \\pi^{(t)}) \\quad (\\text{M-step maximizes } \\mathcal{F}) $$\n$$ \\mathcal{F}(\\gamma^{(t)}, \\pi^{(t)}) = \\mathcal{L}_w(\\pi^{(t)}) \\quad (\\text{E-step choice makes bound tight}) $$\nCombining these proves that $\\mathcal{L}_w(\\pi^{(t+1)}) \\ge \\mathcal{L}_w(\\pi^{(t)})$, ensuring monotonic non-decrease of the objective function.\n\n### Summary of Algorithm\n1.  **Initialization**: Set $t=0$ and initialize $\\pi^{(0)} = \\pi^s$.\n2.  **Iteration**: Repeat until convergence (e.g., $|\\pi^{(t+1)} - \\pi^{(t)}|  \\epsilon$):\n    a. **E-Step**: For each $i \\in \\{1,...,n\\}$ and $k \\in \\{1,...,K\\}$, compute:\n       $$ \\gamma_{ik}^{(t)} = \\frac{ (q_{ik}/\\pi^s_k) \\pi_k^{(t)} }{ \\sum_{j=1}^K (q_{ij}/\\pi^s_j) \\pi_j^{(t)} } $$\n    b. **M-Step**: Update the estimate for $\\pi$:\n       $$ \\pi_k^{(t+1)} = \\frac{\\sum_{i=1}^n w_i \\gamma_{ik}^{(t)}}{\\sum_{i=1}^n w_i} $$\n    c. Increment $t \\to t+1$.\n3.  **Return** the final estimate $\\pi^{(\\text{final})}$.\nThis completes the derivation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the label shift estimation problem using the EM algorithm for the given test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Test Case A (general)\",\n            \"pi_s\": np.array([0.5, 0.3, 0.2]),\n            \"q\": np.array([\n                [0.7, 0.2, 0.1], [0.6, 0.25, 0.15], [0.2, 0.7, 0.1],\n                [0.1, 0.2, 0.7], [0.5, 0.3, 0.2], [0.55, 0.3, 0.15],\n                [0.4, 0.4, 0.2], [0.3, 0.3, 0.4]\n            ]),\n            \"w\": np.array([1.0, 0.8, 1.2, 1.5, 0.9, 1.1, 1.0, 0.7])\n        },\n        {\n            \"name\": \"Test Case B (information-poor)\",\n            \"pi_s\": np.array([0.5, 0.3, 0.2]),\n            \"q\": np.array([\n                [0.5, 0.3, 0.2], [0.5, 0.3, 0.2], [0.5, 0.3, 0.2],\n                [0.5, 0.3, 0.2], [0.5, 0.3, 0.2], [0.5, 0.3, 0.2]\n            ]),\n            \"w\": np.array([1.0, 2.0, 0.5, 1.5, 0.75, 1.25])\n        },\n        {\n            \"name\": \"Test Case C (edge case)\",\n            \"pi_s\": np.array([0.4, 0.25, 0.2, 0.15]),\n            \"q\": np.array([\n                [0.95, 0.05, 0.0, 0.0], [0.0, 0.9, 0.1, 0.0],\n                [0.0, 0.0, 1.0, 0.0], [0.1, 0.0, 0.0, 0.9],\n                [0.5, 0.5, 0.0, 0.0], [0.2, 0.3, 0.5, 0.0]\n            ]),\n            \"w\": np.array([2.0, 1.0, 1.5, 3.0, 1.2, 0.8])\n        }\n    ]\n\n    results = []\n    \n    # Parameters for the EM algorithm\n    max_iter = 1000\n    tolerance = 1e-10\n\n    for case in test_cases:\n        pi_s = case[\"pi_s\"]\n        q = case[\"q\"]\n        w = case[\"w\"]\n\n        # Initialize pi_t with pi_s\n        pi_t = np.copy(pi_s)\n        \n        # Pre-compute the ratio a_ik = q_ik / pi_s_k\n        # Handle division by zero in pi_s if it occurs, though problem states pi_s_k > 0\n        with np.errstate(divide='ignore', invalid='ignore'):\n            A = q / pi_s\n            A[np.isnan(A)] = 0\n            A[np.isinf(A)] = 0\n        \n        total_weight = np.sum(w)\n        \n        likelihoods = []\n        is_monotonic = True\n\n        for t in range(max_iter):\n            # Calculate log-likelihood for the current pi_t\n            # Denominator terms of the gamma calculation are the same as likelihood inner terms\n            likelihood_inner_sum = A @ pi_t\n            \n            # Add a small epsilon for numerical stability of log\n            log_likelihood = np.sum(w * np.log(likelihood_inner_sum + 1e-15))\n            likelihoods.append(log_likelihood)\n            \n            # Check for monotonic non-decrease\n            if t > 0:\n                if likelihoods[t]  likelihoods[t-1] - tolerance:\n                    is_monotonic = False\n            \n            # E-step: Compute responsibilities (gamma)\n            # Denominator for gamma is the likelihood_inner_sum\n            gamma_num = A * pi_t  # Broadcasting\n            with np.errstate(divide='ignore', invalid='ignore'):\n                gamma = gamma_num / likelihood_inner_sum[:, np.newaxis]\n                gamma[np.isnan(gamma)] = 0\n\n            # M-step: Update pi_t\n            pi_t_new_num = np.sum(w[:, np.newaxis] * gamma, axis=0)\n            pi_t_new = pi_t_new_num / total_weight\n            \n            # Check for convergence\n            if np.linalg.norm(pi_t_new - pi_t)  tolerance:\n                pi_t = pi_t_new\n                break\n            \n            pi_t = pi_t_new\n\n        # Format final pi for output\n        pi_final_list = [f\"{x:.15f}\".rstrip('0').rstrip('.') for x in pi_t]\n        pi_str = f\"[{','.join(pi_final_list)}]\"\n        \n        # Format final result string\n        result_str = f\"[{'True' if is_monotonic else 'False'},{pi_str}]\"\n        results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\n# The problem requires this function to be called to produce output.\nsolve()\n```"
        }
    ]
}