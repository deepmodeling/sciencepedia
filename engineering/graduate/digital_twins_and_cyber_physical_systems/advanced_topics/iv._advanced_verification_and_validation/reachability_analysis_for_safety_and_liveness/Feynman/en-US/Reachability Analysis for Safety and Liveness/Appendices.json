{
    "hands_on_practices": [
        {
            "introduction": "The choice of geometric representation for reachable sets is a cornerstone of set-based analysis. In this first exercise, we compare two of the most prevalent families: zonotopes and ellipsoids. By analyzing how efficiently these shapes over-approximate reachable sets generated from different input constraints, you will develop a crucial intuition for selecting the most suitable representation for a given system, a key step in designing efficient verification algorithms .",
            "id": "4238580",
            "problem": "A two-dimensional discrete-time Linear Time-Invariant (LTI) system in a Digital Twin (DT) and Cyber-Physical System (CPS) context is given by $x_{k+1} = A x_{k} + B u_{k}$, where $x_{k} \\in \\mathbb{R}^{2}$, $u_{k} \\in \\mathbb{R}^{2}$, $A \\in \\mathbb{R}^{2 \\times 2}$, and $B \\in \\mathbb{R}^{2 \\times 2}$ is invertible. A DT uses reachability analysis for safety and liveness by constructing over-approximations of one-step input-induced reachable sets. Two bounded-input models are considered:\n- An $L_{\\infty}$-bounded input set $U_{\\infty} = \\{ u \\in \\mathbb{R}^{2} : \\|u\\|_{\\infty} \\leq 1 \\}$,\n- An $L_{2}$-bounded input set $U_{2} = \\{ u \\in \\mathbb{R}^{2} : \\|u\\|_{2} \\leq 1 \\}$.\n\nThe one-step input-induced reachable sets are $S_{\\infty} = B U_{\\infty}$ and $S_{2} = B U_{2}$. Consider two over-approximation families:\n- Zonotopic over-approximations with two generators aligned with the columns of $B$, i.e., the set $Z = B([-1,1]^{2})$.\n- Ellipsoidal over-approximations using the minimum-volume enclosing ellipsoid (Löwner ellipsoid).\n\nFor the $L_{\\infty}$ case, compare the minimum-volume enclosing ellipsoid of $S_{\\infty}$ to the zonotope $Z$, and for the $L_{2}$ case, compare the zonotope $Z$ to the minimum-volume enclosing ellipsoid of $S_{2}$. Using only foundational geometric and linear-algebraic facts about linear transformations, convex bodies, and volumes, derive the exact ratios\n$$r_{\\infty} = \\frac{\\operatorname{area}(\\text{minimum-volume ellipsoid containing } S_{\\infty})}{\\operatorname{area}(Z)} \\quad \\text{and} \\quad r_{2} = \\frac{\\operatorname{area}(Z)}{\\operatorname{area}(\\text{minimum-volume ellipsoid containing } S_{2})}.$$\n\nProvide the final answer as a single row matrix containing $r_{\\infty}$ and $r_{2}$, in exact analytic form. No rounding is required and no units should be used. The comparison must be based on the one-step input-induced reachable sets and must not assume any special structure of $A$ beyond dimensional consistency.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. The concepts presented are standard in the fields of control theory, convex optimization, and reachability analysis for cyber-physical systems. Therefore, the problem is valid, and a full solution is warranted.\n\nThe problem asks for the computation of two ratios, $r_{\\infty}$ and $r_{2}$, which quantify the tightness of different set-based over-approximations for one-step reachable sets of a discrete-time LTI system.\n\nThe system is given by $x_{k+1} = A x_{k} + B u_{k}$. The one-step input-induced reachable sets from the origin are of the form $B U$, where $U$ is the set of admissible inputs. The matrix $B \\in \\mathbb{R}^{2 \\times 2}$ is invertible, which implies $\\det(B) \\neq 0$. A key property of linear transformations is that for a measurable set $K \\subset \\mathbb{R}^{2}$, the area of its image under the transformation $B$ is given by $\\operatorname{area}(B(K)) = |\\det(B)| \\operatorname{area}(K)$.\n\nLet us first analyze the sets involved:\n1.  The input set $U_{\\infty} = \\{ u \\in \\mathbb{R}^{2} : \\|u\\|_{\\infty} \\leq 1 \\}$ is the square $[-1,1] \\times [-1,1]$ in $\\mathbb{R}^{2}$. Its area is $\\operatorname{area}(U_{\\infty}) = (1 - (-1)) \\times (1 - (-1)) = 2 \\times 2 = 4$.\n2.  The input set $U_{2} = \\{ u \\in \\mathbb{R}^{2} : \\|u\\|_{2} \\leq 1 \\}$ is the unit disk centered at the origin. Its area is $\\operatorname{area}(U_{2}) = \\pi (1)^{2} = \\pi$.\n3.  The reachable set $S_{\\infty} = B U_{\\infty}$ is the image of the square $U_{\\infty}$ under the linear map $B$. Since $B$ is a linear transformation, $S_{\\infty}$ is a parallelogram centered at the origin. Its area is $\\operatorname{area}(S_{\\infty}) = |\\det(B)| \\operatorname{area}(U_{\\infty}) = 4|\\det(B)|$.\n4.  The reachable set $S_{2} = B U_{2}$ is the image of the unit disk $U_{2}$ under the linear map $B$. The image of an ellipse (a circle is a special case) under a linear transformation is another ellipse. Thus, $S_{2}$ is an ellipse centered at the origin. Its area is $\\operatorname{area}(S_{2}) = |\\det(B)| \\operatorname{area}(U_{2}) = \\pi|\\det(B)|$.\n5.  The zonotope $Z = B([-1,1]^{2})$ is, by definition, the same set as $S_{\\infty}$. Thus, $Z = S_{\\infty}$.\n\nWe now compute the two required ratios.\n\n**Calculation of $r_{\\infty}$**\n\nThe ratio $r_{\\infty}$ is defined as:\n$$r_{\\infty} = \\frac{\\operatorname{area}(\\text{minimum-volume ellipsoid containing } S_{\\infty})}{\\operatorname{area}(Z)}$$\nAs established, $Z = S_{\\infty}$. Let $E_{\\text{out}}(K)$ denote the minimum-volume enclosing ellipsoid (also known as the Löwner-John ellipsoid) of a convex body $K$. The expression for $r_{\\infty}$ simplifies to:\n$$r_{\\infty} = \\frac{\\operatorname{area}(E_{\\text{out}}(S_{\\infty}))}{\\operatorname{area}(S_{\\infty})}$$\nA fundamental property of the Löwner-John ellipsoid is that the ratio of the volume of $E_{\\text{out}}(K)$ to the volume of $K$ is invariant under non-singular affine transformations. Since $S_{\\infty} = B(U_{\\infty})$ and $B$ is invertible, we have $E_{\\text{out}}(S_{\\infty}) = E_{\\text{out}}(B(U_{\\infty})) = B(E_{\\text{out}}(U_{\\infty}))$. Therefore, the ratio can be computed using the base set $U_{\\infty}$:\n$$r_{\\infty} = \\frac{\\operatorname{area}(E_{\\text{out}}(B(U_{\\infty})))}{\\operatorname{area}(B(U_{\\infty}))} = \\frac{\\operatorname{area}(B(E_{\\text{out}}(U_{\\infty})))}{\\operatorname{area}(B(U_{\\infty}))} = \\frac{|\\det(B)| \\operatorname{area}(E_{\\text{out}}(U_{\\infty}))}{|\\det(B)| \\operatorname{area}(U_{\\infty})} = \\frac{\\operatorname{area}(E_{\\text{out}}(U_{\\infty}))}{\\operatorname{area}(U_{\\infty})}$$\nWe need to find the minimum-area ellipse enclosing the square $U_{\\infty} = [-1,1]^2$. By symmetry, the minimum-area enclosing ellipse is the circumscribed circle of the square. The vertices of the square are $(\\pm 1, \\pm 1)$. The distance from the origin to any vertex is $\\sqrt{1^2 + 1^2} = \\sqrt{2}$. Thus, the circumscribed circle is centered at the origin and has a radius $R = \\sqrt{2}$.\nThe area of this enclosing circle (which is an ellipse) is $\\operatorname{area}(E_{\\text{out}}(U_{\\infty})) = \\pi R^2 = \\pi (\\sqrt{2})^2 = 2\\pi$.\nThe area of the square $U_{\\infty}$ is $4$.\nThe ratio is therefore:\n$$r_{\\infty} = \\frac{2\\pi}{4} = \\frac{\\pi}{2}$$\nThis is the classic John's theorem result for a parallelogram in $\\mathbb{R}^2$.\n\n**Calculation of $r_{2}$**\n\nThe ratio $r_{2}$ is defined as:\n$$r_{2} = \\frac{\\operatorname{area}(Z)}{\\operatorname{area}(\\text{minimum-volume ellipsoid containing } S_{2})}$$\nLet us compute the areas of the numerator and the denominator.\nThe numerator is $\\operatorname{area}(Z)$. As determined earlier, $Z = S_{\\infty} = B(U_{\\infty})$, so its area is:\n$$\\operatorname{area}(Z) = \\operatorname{area}(B(U_{\\infty})) = |\\det(B)| \\operatorname{area}(U_{\\infty}) = 4|\\det(B)|$$\nThe denominator is the area of the minimum-volume ellipsoid containing $S_{2}$, which is $\\operatorname{area}(E_{\\text{out}}(S_{2}))$. The set $S_{2} = B(U_{2})$ is the image of the unit disk $U_{2}$ under the transformation $B$. As the linear image of an ellipse, $S_{2}$ is itself an ellipse. The minimum-volume enclosing ellipsoid of an ellipse is the ellipse itself. Hence, $E_{\\text{out}}(S_{2}) = S_{2}$.\nThe area of the denominator is therefore $\\operatorname{area}(S_2)$:\n$$\\operatorname{area}(S_{2}) = \\operatorname{area}(B(U_{2})) = |\\det(B)| \\operatorname{area}(U_{2}) = |\\det(B)| \\pi$$\nNow we can compute the ratio $r_{2}$:\n$$r_{2} = \\frac{\\operatorname{area}(Z)}{\\operatorname{area}(S_{2})} = \\frac{4|\\det(B)|}{\\pi|\\det(B)|}$$\nSince $B$ is invertible, $\\det(B) \\neq 0$, so we can cancel the term $|\\det(B)|$:\n$$r_{2} = \\frac{4}{\\pi}$$\nThe two requested ratios are $r_{\\infty} = \\frac{\\pi}{2}$ and $r_{2} = \\frac{4}{\\pi}$. They are fundamental constants that do not depend on the specific choice of the invertible matrix $B$.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\pi}{2} & \\frac{4}{\\pi} \\end{pmatrix}}$$"
        },
        {
            "introduction": "While over-approximations are necessary for scalability, their value depends on how tightly they bound the true reachable set. This practice moves from geometric intuition to rigorous analysis, tasking you with deriving an exact analytical bound on the approximation error. Using the powerful formalism of support functions, you will quantify the directed Hausdorff distance between a complex, multi-step reachable set and its simpler polyhedral over-approximation, providing a formal guarantee on the quality of your analysis .",
            "id": "4238593",
            "problem": "A Digital Twin for a Cyber-Physical System (CPS) monitors a discrete-time linear surrogate model with state $x \\in \\mathbb{R}^{2}$ governed by the set-valued update\n$$\nx^{+} \\in A x \\oplus B U,\n$$\nwhere $\\oplus$ denotes the Minkowski sum, $A = \\mathrm{diag}(\\alpha,\\beta)$ with $0 < \\alpha < 1$ and $0 < \\beta < 1$, $B = I_{2}$ is the identity matrix, and the input set is the polyhedral diamond\n$$\nU = \\{ u \\in \\mathbb{R}^{2} : |u_{1}| + |u_{2}| \\leq 1 \\}.\n$$\nAssume the initial state set is $X_{0} = \\{0\\}$.\n\nUsing only foundational definitions and properties of Minkowski sums, linear images of convex sets, and support functions, carry out the following tasks:\n\n1. Derive the exact $k$-step reachable set $R_{k}$.\n2. Construct a polyhedral over-approximation $P_{k}$ of $R_{k}$ that is an $\\ell_{1}$-ball (diamond) centered at the origin, with the smallest possible radius $\\rho_{k}$ ensuring $R_{k} \\subseteq P_{k}$.\n3. Using the support-function characterization of the directed Hausdorff distance between convex sets, derive a closed-form upper bound on the over-approximation error $\\delta_{k}$ defined as the directed Hausdorff distance from $P_{k}$ to $R_{k}$.\n\nExpress your final bound $\\delta_{k}$ as a single closed-form analytic expression in terms of $\\alpha$, $\\beta$, and $k$. No numerical approximation is required, and no units apply to the final answer. The final expression must be a single analytic expression, not an inequality or equation to be solved.",
            "solution": "The problem is evaluated as valid. It is a well-posed, scientifically grounded problem in the field of reachability analysis for linear systems, a core topic within cyber-physical systems theory. All definitions are standard, and the setup is internally consistent and complete.\n\nThe task is to analyze the reachable set of a discrete-time linear system, find a specific polyhedral over-approximation, and compute the approximation error.\n\nThe system dynamics are given by the set-valued recurrence relation:\n$$\nx^{+} \\in A x \\oplus B U\n$$\nwith initial state set $X_0 = \\{0\\}$. The matrices are $A = \\mathrm{diag}(\\alpha, \\beta)$ and $B=I_2$, where $0 < \\alpha < 1$ and $0 < \\beta < 1$. The input set is the unit $\\ell_1$-ball $U = \\{ u \\in \\mathbb{R}^{2} : |u_1| + |u_2| \\leq 1 \\}$. The symbol $\\oplus$ denotes the Minkowski sum.\n\n**1. Derivation of the exact $k$-step reachable set $R_k$**\n\nThe reachable set $R_k$ at step $k$ is the set of all possible states starting from $X_0$. We can find it by unrolling the recursion.\nFor $k=0$, the reachable set is the initial set: $R_0 = X_0 = \\{0\\}$.\nFor $k=1$:\n$$\nR_1 = A R_0 \\oplus B U = A\\{0\\} \\oplus I_2 U = \\{0\\} \\oplus U = U\n$$\nFor $k=2$:\n$$\nR_2 = A R_1 \\oplus B U = A U \\oplus U\n$$\nFor $k=3$:\n$$\nR_3 = A R_2 \\oplus B U = A (A U \\oplus U) \\oplus U = A^2 U \\oplus A U \\oplus U\n$$\nBy induction, the state $x(k)$ after $k$ steps is a sum of transformed inputs $u(0), \\dots, u(k-1)$ where each $u(i) \\in U$:\n$$\nx(k) = A^{k-1} B u(0) + A^{k-2} B u(1) + \\dots + A^0 B u(k-1)\n$$\nThe set of all such states $x(k)$ is the reachable set $R_k$. Since $B=I_2$, this is the Minkowski sum of the transformed input sets:\n$$\nR_k = \\bigoplus_{i=0}^{k-1} A^i U\n$$\nThe matrix $A$ is diagonal, so $A^i = \\mathrm{diag}(\\alpha^i, \\beta^i)$. A set $A^i U$ is the linear image of $U$ under $A^i$. For any point $v \\in A^i U$, there exists a $u \\in U$ such that $v = A^i u$, which means $v_1 = \\alpha^i u_1$ and $v_2 = \\beta^i u_2$. Since $|u_1| + |u_2| \\leq 1$, the points $v$ in $A^i U$ satisfy:\n$$\n\\left|\\frac{v_1}{\\alpha^i}\\right| + \\left|\\frac{v_2}{\\beta^i}\\right| \\leq 1\n$$\nEach set $A^i U$ is a zonotope (specifically, a diamond shape scaled anisotropically). The Minkowski sum of zonotopes is a zonotope. Thus, $R_k = \\bigoplus_{i=0}^{k-1} A^i U$ is the exact characterization of the $k$-step reachable set.\n\n**2. Construction of the over-approximating $\\ell_1$-ball $P_k$**\n\nWe seek the smallest radius $\\rho_k$ such that $R_k \\subseteq P_k$, where $P_k = \\{x \\in \\mathbb{R}^2 : |x_1| + |x_2| \\leq \\rho_k\\}$. The set $P_k$ is an $\\ell_1$-ball of radius $\\rho_k$, which can be written as $P_k = \\rho_k U$.\nThe smallest such $\\rho_k$ is the maximum value of the $\\ell_1$-norm over the set $R_k$:\n$$\n\\rho_k = \\max_{x \\in R_k} ||x||_1 = \\max_{x \\in R_k} (|x_1|+|x_2|)\n$$\nAny point $x \\in R_k$ has the form $x = \\sum_{i=0}^{k-1} x^{(i)}$ where $x^{(i)} \\in A^i U$. Therefore, $x = \\sum_{i=0}^{k-1} A^i u^{(i)}$ for some choice of $u^{(i)} \\in U$.\nThe $\\ell_1$-norm of $x$ is:\n$$\n||x||_1 = \\left|\\sum_{i=0}^{k-1} \\alpha^i u_1^{(i)}\\right| + \\left|\\sum_{i=0}^{k-1} \\beta^i u_2^{(i)}\\right|\n$$\nBy the triangle inequality, and since $\\alpha^i > 0$ and $\\beta^i > 0$:\n$$\n||x||_1 \\leq \\sum_{i=0}^{k-1} \\left|\\alpha^i u_1^{(i)}\\right| + \\sum_{i=0}^{k-1} \\left|\\beta^i u_2^{(i)}\\right| = \\sum_{i=0}^{k-1} \\left(\\alpha^i |u_1^{(i)}| + \\beta^i |u_2^{(i)}|\\right)\n$$\nTo find the maximum of $||x||_1$, we can maximize the right-hand side. This involves, for each $i$, maximizing the expression $\\alpha^i |u_1| + \\beta^i |u_2|$ subject to $|u_1|+|u_2| \\leq 1$. This is a linear function of $|u_1|$ and $|u_2|$ over a simplex, so the maximum is achieved at a vertex. The vertices of the domain for $(|u_1|, |u_2|)$ are $(0,0)$, $(1,0)$, and $(0,1)$. The maximum value is $\\max(\\alpha^i, \\beta^i)$.\nThus, an upper bound for $||x||_1$ is $\\sum_{i=0}^{k-1} \\max(\\alpha^i, \\beta^i)$. This bound is tight, as it can be achieved by choosing the sequence of inputs $u^{(i)}$ to align and maximize the terms. For example, if $\\alpha > \\beta$, then $\\alpha^i > \\beta^i$ for all $i \\ge 1$. We can choose $u^{(i)} = (1,0)$ for all $i$. Then $||x||_1 = |\\sum \\alpha^i| + 0 = \\sum \\alpha^i$.\nSo, $\\rho_k$ is given by:\n$$\n\\rho_k = \\sum_{i=0}^{k-1} \\max(\\alpha^i, \\beta^i)\n$$\nSince $\\alpha, \\beta \\in (0,1)$, if $\\alpha \\ne \\beta$, the term $\\max(\\alpha, \\beta)$ determines which is larger for all powers $i \\ge 1$. Thus, $\\max(\\alpha^i, \\beta^i) = (\\max(\\alpha, \\beta))^i$. The case $i=0$ is $\\max(1,1)=1$. So the formula holds.\nUsing the formula for a geometric series:\n$$\n\\rho_k = \\sum_{i=0}^{k-1} (\\max(\\alpha, \\beta))^i = \\frac{1 - (\\max(\\alpha, \\beta))^k}{1 - \\max(\\alpha, \\beta)}\n$$\nThe over-approximating set is $P_k = \\{x : ||x||_1 \\leq \\rho_k\\}$.\n\n**3. Derivation of the error bound $\\delta_k$**\n\nThe over-approximation error $\\delta_k$ is the directed Hausdorff distance from $P_k$ to $R_k$. For convex sets $X, Y$, this is given by $d(X, Y) = \\sup_{||l||_*=1}(h_X(l)-h_Y(l))$, expressed via support functions. Assuming the standard Euclidean norm for distance, the dual norm for $l$ is also the Euclidean norm, so we take the supremum over $||l||_2=1$.\n$$\n\\delta_k = d(P_k, R_k) = \\sup_{||l||_2=1} (h_{P_k}(l) - h_{R_k}(l))\n$$\nFirst, we find the support functions. The support function of the base set $U$ is $h_U(l) = \\sup_{u \\in U} l^T u = ||l||_\\infty = \\max(|l_1|, |l_2|)$.\nThe support function of $R_k = \\bigoplus_{i=0}^{k-1} A^i U$ is:\n$$\nh_{R_k}(l) = \\sum_{i=0}^{k-1} h_{A^i U}(l) = \\sum_{i=0}^{k-1} h_U((A^i)^T l) = \\sum_{i=0}^{k-1} \\max(|\\alpha^i l_1|, |\\beta^i l_2|)\n$$\nThe support function of $P_k = \\rho_k U$ is:\n$$\nh_{P_k}(l) = \\rho_k h_U(l) = \\rho_k \\max(|l_1|, |l_2|)\n$$\nSubstituting $\\rho_k = \\sum_{i=0}^{k-1} \\max(\\alpha^i, \\beta^i)$, the difference is:\n$$\nh_{P_k}(l) - h_{R_k}(l) = \\left(\\sum_{i=0}^{k-1} \\max(\\alpha^i, \\beta^i)\\right)\\max(|l_1|, |l_2|) - \\sum_{i=0}^{k-1} \\max(\\alpha^i|l_1|, \\beta^i|l_2|)\n$$\nThis can be written as a sum:\n$$\nh_{P_k}(l) - h_{R_k}(l) = \\sum_{i=0}^{k-1} \\left[ \\max(\\alpha^i, \\beta^i)\\max(|l_1|, |l_2|) - \\max(\\alpha^i|l_1|, \\beta^i|l_2|) \\right]\n$$\nLet's analyze the $i$-th term, $C_i(l)$. For $i=0$, $\\alpha^0=\\beta^0=1$, so $C_0(l) = \\max(1,1)\\max(|l_1|,|l_2|) - \\max(|l_1|,|l_2|) = 0$. So the sum effectively starts at $i=1$.\nConsider $i \\ge 1$. Without loss of generality, assume $\\alpha > \\beta$. Then $\\alpha^i > \\beta^i$ and $\\max(\\alpha^i, \\beta^i) = \\alpha^i$.\n$$\nC_i(l) = \\alpha^i \\max(|l_1|, |l_2|) - \\max(\\alpha^i|l_1|, \\beta^i|l_2|)\n$$\nIf $|l_1| \\ge |l_2|$, then $\\max(|l_1|,|l_2|)=|l_1|$. Also $\\alpha^i|l_1| > \\beta^i|l_1| \\ge \\beta^i|l_2|$, so $\\max(\\alpha^i|l_1|, \\beta^i|l_2|) = \\alpha^i|l_1|$. Thus, $C_i(l) = \\alpha^i|l_1| - \\alpha^i|l_1| = 0$.\nIf $|l_1| < |l_2|$, then $\\max(|l_1|,|l_2|)=|l_2|$. The term becomes:\n$$\nC_i(l) = \\alpha^i|l_2| - \\max(\\alpha^i|l_1|, \\beta^i|l_2|)\n$$\nSince $\\max(a,b) \\ge b$, we have $\\max(\\alpha^i|l_1|, \\beta^i|l_2|) \\ge \\beta^i|l_2|$. Therefore,\n$$\nC_i(l) \\le (\\alpha^i - \\beta^i)|l_2|\n$$\nSince we are maximizing over $||l||_2=1$, we have $|l_2| \\le 1$. This implies $C_i(l) \\le \\alpha^i - \\beta^i$.\nThis upper bound is achieved when $|l_2|=1$ (so $l_1=0$, and $l=(0, \\pm 1)$) and the inequality above holds with equality. At $l=(0, 1)$, $|l_2|=1$ and $\\max(\\alpha^i|l_1|, \\beta^i|l_2|) = \\max(0, \\beta^i) = \\beta^i|l_2|$. So equality holds.\nThe maximum value of $C_i(l)$ is $\\alpha^i - \\beta^i$, achieved at $l=(0, \\pm 1)$.\n\nThe total error is $\\delta_k = \\sup_{||l||_2=1} \\sum_{i=1}^{k-1} C_i(l)$. Since each function $C_i(l)$ for $i \\in \\{1,\\dots,k-1\\}$ is maximized by the same vector $l$ (e.g., $l=(0,1)$ if $\\alpha>\\beta$), the supremum of the sum is the sum of the suprema:\n$$\n\\delta_k = \\sum_{i=1}^{k-1} \\sup_{||l||_2=1} C_i(l)\n$$\nIf $\\alpha > \\beta$, $\\delta_k = \\sum_{i=1}^{k-1} (\\alpha^i - \\beta^i)$.\nIf $\\beta > \\alpha$, a symmetric argument starting with maximizing directions $l=(\\pm 1, 0)$ gives $\\delta_k = \\sum_{i=1}^{k-1} (\\beta^i - \\alpha^i)$.\nIn general, $\\delta_k = \\sum_{i=1}^{k-1} |\\alpha^i - \\beta^i|$. Since the sign of $\\alpha^i - \\beta^i$ is constant for all $i \\ge 1$, we can write:\n$$\n\\delta_k = \\left| \\sum_{i=1}^{k-1} (\\alpha^i - \\beta^i) \\right| = \\left| \\sum_{i=1}^{k-1} \\alpha^i - \\sum_{i=1}^{k-1} \\beta^i \\right|\n$$\nUsing the sum of a geometric series for $k-1$ terms starting from index $1$:\n$$\n\\sum_{i=1}^{k-1} \\alpha^i = \\alpha \\frac{1-\\alpha^{k-1}}{1-\\alpha} = \\frac{\\alpha-\\alpha^k}{1-\\alpha}\n$$\nAnd similarly for $\\beta$. Therefore, the error bound is:\n$$\n\\delta_k = \\left| \\frac{\\alpha - \\alpha^k}{1-\\alpha} - \\frac{\\beta - \\beta^k}{1-\\beta} \\right|\n$$\nThis expression is the exact directed Hausdorff distance $d(P_k, R_k)$, and as such, it is the tightest possible upper bound for the error.",
            "answer": "$$\\boxed{\\left| \\frac{\\alpha - \\alpha^k}{1-\\alpha} - \\frac{\\beta - \\beta^k}{1-\\beta} \\right|}$$"
        },
        {
            "introduction": "The ultimate test of understanding is the ability to translate theory into practice. This final exercise challenges you to implement a complete algorithm for reachability analysis of continuous-time linear systems from first principles. You will code the propagation of reachable sets by computing the evolution of their support functions, handling various set representations and numerically approximating the integral contribution from system inputs. This practice solidifies the connection between the underlying mathematics of convex sets and a functional computational tool for safety and liveness verification .",
            "id": "4238587",
            "problem": "You are given a linear time-invariant continuous-time system in the context of Digital Twin (DT) models of Cyber-Physical Systems (CPS). The state evolves according to the ordinary differential equation $\\dot{x} = A x + B u$, where $x \\in \\mathbb{R}^n$ is the state, $u \\in \\mathbb{R}^m$ is the control input taking values in a compact convex set $U \\subset \\mathbb{R}^m$, $A \\in \\mathbb{R}^{n \\times n}$, and $B \\in \\mathbb{R}^{n \\times m}$. The initial state belongs to a compact convex set $X_0 \\subset \\mathbb{R}^n$. The goal is to compute the support function of the reachable set at a fixed time $t$, in a given direction $l \\in \\mathbb{R}^n$, using a principled construction derived from fundamental facts without shortcuts.\n\nThe fundamental base you must use is limited to the following:\n- The variation-of-constants solution of linear ordinary differential equations: for any $t \\ge 0$, the solution satisfies $x(t) = e^{A t} x(0) + \\int_0^t e^{A (t - \\tau)} B u(\\tau)\\, d\\tau$.\n- The definition of the support function of a compact convex set: for any compact convex set $S \\subset \\mathbb{R}^k$, the support function in direction $l \\in \\mathbb{R}^k$ is $h_S(l) = \\sup_{s \\in S} \\langle l, s \\rangle$.\n- The Minkowski sum of sets and its basic properties.\n\nYou must implement a method that, given $(A,B)$, $X_0$, $U$, $t$, and $l$, returns a numerical approximation of the support function of the convex reachable set in direction $l$ at time $t$ based on the principle that convex set images under linear operators and Minkowski integrals are handled via their support functions. Your algorithm must rely solely on these principles and the definition of the support function. You must not invoke any shortcut formulas or pre-provided results beyond these fundamentals.\n\nIn your implementation, you must handle input sets $U$ specified as any of the following convex representations:\n- A box specified by lower and upper bounds $[u_{\\min}, u_{\\max}] \\subset \\mathbb{R}^m$, where $u_{\\min}, u_{\\max} \\in \\mathbb{R}^m$ with $u_{\\min} \\le u_{\\max}$ componentwise.\n- An Euclidean ball centered at the origin with radius $r \\in \\mathbb{R}_{\\ge 0}$, that is $\\{u \\in \\mathbb{R}^m : \\|u\\|_2 \\le r\\}$.\n- A convex polytope specified by a finite set of vertices $\\{v_i\\}_{i=1}^N \\subset \\mathbb{R}^m$ whose convex hull is $U$.\n\nYou must also handle initial sets $X_0$ specified as any of the following convex representations:\n- A box specified by lower and upper bounds $[x_{\\min}, x_{\\max}] \\subset \\mathbb{R}^n$.\n- An Euclidean ball centered at the origin with radius $r_0 \\in \\mathbb{R}_{\\ge 0}$.\n- A convex polytope specified by a finite set of vertices in $\\mathbb{R}^n$.\n\nYour numerical method should use a principled quadrature rule to approximate the time integral that arises from the contribution of $U$ to the reachable set. Angles are not involved in this problem, and no physical units are required because the problem is purely mathematical. The output for each test case must be a single real number (a float), which is the support function value in the prescribed direction.\n\nTest suite:\nFor each test case, compute the support function in the specified direction $l$ at time $t$ for the given $(A,B)$, $X_0$, and $U$. Use the following five test cases:\n\n- Test case $1$ (happy path, two-dimensional stable system, non-symmetric box input):\n  - $A = \\begin{bmatrix} -0.5 & 0.2 \\\\ -0.1 & -0.3 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$,\n  - $X_0$ is a box with $x_{\\min} = \\begin{bmatrix} -0.5 \\\\ -0.5 \\end{bmatrix}$ and $x_{\\max} = \\begin{bmatrix} 0.5 \\\\ 0.5 \\end{bmatrix}$,\n  - $U$ is a box with $u_{\\min} = \\begin{bmatrix} -1.0 \\\\ -0.5 \\end{bmatrix}$ and $u_{\\max} = \\begin{bmatrix} 1.0 \\\\ 0.5 \\end{bmatrix}$,\n  - $t = 1.0$,\n  - $l = \\begin{bmatrix} 1.0 \\\\ -0.5 \\end{bmatrix}$.\n\n- Test case $2$ (boundary case: zero input set, propagation of initial set only):\n  - $A = \\begin{bmatrix} -0.5 & 0.2 \\\\ -0.1 & -0.3 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$,\n  - $X_0$ is a box with $x_{\\min} = \\begin{bmatrix} -1.0 \\\\ -1.0 \\end{bmatrix}$ and $x_{\\max} = \\begin{bmatrix} 1.0 \\\\ 1.0 \\end{bmatrix}$,\n  - $U$ is the singleton $\\{0\\}$ represented as a box with $u_{\\min} = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$ and $u_{\\max} = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$,\n  - $t = 2.0$,\n  - $l = \\begin{bmatrix} 0.3 \\\\ 0.4 \\end{bmatrix}$.\n\n- Test case $3$ (edge case: two-dimensional unstable system, ball input, zero initial set):\n  - $A = \\begin{bmatrix} 0.4 & 0.6 \\\\ 0.0 & 0.2 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$,\n  - $X_0$ is the singleton $\\{0\\}$ represented as a box with $x_{\\min} = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$ and $x_{\\max} = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}$,\n  - $U$ is an Euclidean ball in $\\mathbb{R}^2$ of radius $r = 0.2$ centered at the origin,\n  - $t = 0.5$,\n  - $l = \\begin{bmatrix} 1.0 \\\\ 1.0 \\end{bmatrix}$.\n\n- Test case $4$ (one-dimensional system, interval input, zero initial set):\n  - $A = \\begin{bmatrix} -1.0 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1.0 \\end{bmatrix}$,\n  - $X_0$ is the singleton $\\{0\\}$ represented as a box with $x_{\\min} = \\begin{bmatrix} 0.0 \\end{bmatrix}$ and $x_{\\max} = \\begin{bmatrix} 0.0 \\end{bmatrix}$,\n  - $U$ is a box (interval) with $u_{\\min} = \\begin{bmatrix} 0.0 \\end{bmatrix}$ and $u_{\\max} = \\begin{bmatrix} 1.0 \\end{bmatrix}$,\n  - $t = 1.5$,\n  - $l = \\begin{bmatrix} 1.0 \\end{bmatrix}$.\n\n- Test case $5$ (three-dimensional stable system, ball initial set, polytope input):\n  - $A = \\begin{bmatrix} -0.2 & 0.1 & 0.0 \\\\ 0.0 & -0.3 & 0.2 \\\\ 0.0 & 0.0 & -0.1 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 1.0 \\\\ 0.5 & 0.5 \\end{bmatrix}$,\n  - $X_0$ is an Euclidean ball in $\\mathbb{R}^3$ of radius $r_0 = 0.1$ centered at the origin,\n  - $U$ is a convex polytope in $\\mathbb{R}^2$ with vertices $\\{ \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ -1 \\end{bmatrix} \\}$,\n  - $t = 2.0$,\n  - $l = \\begin{bmatrix} 0.5 \\\\ -0.5 \\\\ 1.0 \\end{bmatrix}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For the above five test cases, the expected output format is $[r_1, r_2, r_3, r_4, r_5]$, where each $r_i$ is the computed support function value (a float) for test case $i$ in the specified direction at the specified time. No other text should be printed.",
            "solution": "The problem is subjected to validation prior to any attempt at a solution.\n\n### Step 1: Extract Givens\n- **System Dynamics**: A linear time-invariant continuous-time system described by the ordinary differential equation (ODE) $\\dot{x} = A x + B u$.\n- **State and Input**: The state is $x \\in \\mathbb{R}^n$, and the control input is $u \\in \\mathbb{R}^m$.\n- **State and Input Sets**: The initial state $x(0)$ is in a compact convex set $X_0 \\subset \\mathbb{R}^n$. The control input $u(\\tau)$ for $\\tau \\ge 0$ takes values in a compact convex set $U \\subset \\mathbb{R}^m$.\n- **System Matrices**: $A \\in \\mathbb{R}^{n \\times n}$ and $B \\in \\mathbb{R}^{n \\times m}$.\n- **Fundamental Principles**:\n    1.  **Variation-of-Constants Solution**: For any $t \\ge 0$, the solution to the ODE is $x(t) = e^{A t} x(0) + \\int_0^t e^{A (t - \\tau)} B u(\\tau)\\, d\\tau$.\n    2.  **Support Function Definition**: For a compact convex set $S \\subset \\mathbb{R}^k$, its support function in a direction $l \\in \\mathbb{R}^k$ is $h_S(l) = \\sup_{s \\in S} \\langle l, s \\rangle$.\n    3.  **Minkowski Sum**: The problem requires knowledge of the Minkowski sum of sets and its basic properties.\n- **Goal**: Compute the support function of the reachable set at a fixed time $t$ in a given direction $l \\in \\mathbb{R}^n$.\n- **Set Representations**:\n    - $X_0$ and $U$ can be a box (hyperrectangle), an Euclidean ball at the origin, or a convex polytope defined by its vertices.\n- **Numerical Method**: The implementation must use a principled quadrature rule to approximate the time integral.\n- **Test Cases**: Five specific test cases are provided with matrices $A, B$, set definitions for $X_0$ and $U$, time $t$, and direction $l$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific or Factual Unsoundness**: The problem is scientifically and mathematically sound. It is based on fundamental concepts of linear systems theory and convex analysis. The variation-of-constants formula is the correct solution for linear ODEs. The definition of the support function and the concept of a reachable set are standard in control theory and computational geometry. All principles are factually correct.\n2.  **Non-Formalizable or Irrelevant**: The problem is highly formal and directly relevant to the field of reachability analysis for cyber-physical systems, which is a core topic in the specified domain.\n3.  **Incomplete or Contradictory Setup**: The problem is self-contained. For each test case, it provides all necessary components: the system matrices ($A, B$), the definitions of the initial and input sets ($X_0, U$), the time horizon ($t$), and the direction vector ($l$). The specifications for the sets are complete and unambiguous.\n4.  **Unrealistic or Infeasible**: The provided matrices and set parameters are mathematically well-defined and do not represent physically impossible or inconsistent scenarios within the abstract mathematical framework of the problem.\n5.  **Ill-Posed or Poorly Structured**: The problem is well-posed. For an LTI system with compact and convex initial and input sets, the reachable set at any time $t$ is also compact and convex. The support function of a compact set is well-defined and unique for any given direction.\n6.  **Pseudo-Profound, Trivial, or Tautological**: The problem is not trivial. It requires deriving the solution from first principles, combining concepts from linear algebra, differential equations, and convex analysis. It necessitates a non-trivial numerical implementation. Test cases cover a range of scenarios (stable/unstable, different set types, degenerate cases) that test the robustness of the derived method.\n7.  **Outside Scientific Verifiability**: The problem is entirely mathematical, and the results can be verified through analytical calculations (for simple cases like Test Case 4) or comparison with established numerical reachability tools.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is scientifically sound, well-posed, and all necessary information is provided. A solution will be constructed based on the stipulated first principles.\n\n### Solution Derivation\nThe objective is to compute the support function of the reachable set at time $t$, denoted $R(t)$, in a given direction $l \\in \\mathbb{R}^n$. The value to be computed is $h_{R(t)}(l)$.\n\nThe reachable set $R(t)$ is the set of all states $x(t)$ that are solutions to the ODE $\\dot{x} = A x + B u$ with an initial state $x(0) \\in X_0$ and a measurable control input function $u(\\cdot)$ such that $u(\\tau) \\in U$ for all $\\tau \\in [0, t]$.\n\nUsing the provided variation-of-constants formula, any such state $x(t)$ can be written as:\n$$x(t) = e^{A t} x(0) + \\int_0^t e^{A (t - \\tau)} B u(\\tau)\\, d\\tau$$\n\nThe set of all such points $x(t)$ can be expressed using set-theoretic operations. The first term, $e^{A t} x(0)$, corresponds to the linear transformation of the initial set $X_0$. We denote this transformed set by $e^{A t} X_0 = \\{e^{A t} x_0 \\mid x_0 \\in X_0\\}$.\n\nThe second term, the integral, represents the contribution from the control input. The set of all possible values for this integral, considering all admissible control functions $u(\\cdot)$, is the Minkowski integral of the time-varying set $e^{A(t-\\tau)}BU$. This is written as $\\int_0^t e^{A (t - \\tau)} B U \\, d\\tau$.\n\nThe total reachable set $R(t)$ is the Minkowski sum of these two sets:\n$$R(t) = e^{A t} X_0 \\oplus \\int_0^t e^{A (t - \\tau)} B U \\, d\\tau$$\nwhere $\\oplus$ denotes the Minkowski sum, $S_1 \\oplus S_2 = \\{s_1 + s_2 \\mid s_1 \\in S_1, s_2 \\in S_2\\}$.\n\nA fundamental property of support functions is their additivity over the Minkowski sum: $h_{S_1 \\oplus S_2}(l) = h_{S_1}(l) + h_{S_2}(l)$. Applying this property to the expression for $R(t)$:\n$$h_{R(t)}(l) = h_{e^{A t} X_0}(l) + h_{\\int_0^t e^{A (t - \\tau)} B U \\, d\\tau}(l)$$\n\nWe now analyze each term separately based on the provided first principles.\n\n**Term 1: Contribution from the initial set $X_0$**\nThe first term is the support function of a linear transformation of the set $X_0$. For any linear map $M$ and compact convex set $S$, the support function satisfies $h_{M S}(l) = h_S(M^T l)$. In our case, the linear map is $M = e^{A t}$. Its transpose is $M^T = (e^{A t})^T = e^{A^T t}$.\nTherefore, the first term becomes:\n$$h_{e^{A t} X_0}(l) = h_{X_0}((e^{A t})^T l)$$\n\n**Term 2: Contribution from the input set $U$**\nThe second term is the support function of a Minkowski integral. For a time-varying compact convex set $K(\\tau)$, the support function of its Minkowski integral is the integral of its support function: $h_{\\int_0^t K(\\tau) d\\tau}(l) = \\int_0^t h_{K(\\tau)}(l) d\\tau$.\nIn our case, $K(\\tau) = e^{A (t - \\tau)} B U$. The support function of this set is given by:\n$$h_{K(\\tau)}(l) = h_{e^{A (t - \\tau)} B U}(l)$$\nUsing the property for linear transformations again, with $M = e^{A (t - \\tau)} B$, we have:\n$$h_{e^{A (t - \\tau)} B U}(l) = h_U((e^{A (t - \\tau)} B)^T l) = h_U(B^T (e^{A (t-\\tau)})^T l) = h_U(B^T e^{A^T (t-\\tau)} l)$$\nIntegrating this expression from $\\tau=0$ to $t$ gives the second term:\n$$h_{\\int_0^t e^{A (t - \\tau)} B U \\, d\\tau}(l) = \\int_0^t h_U(B^T e^{A^T (t-\\tau)} l) \\, d\\tau$$\n\n**Final Formula and Numerical Implementation**\nCombining both terms, we obtain the exact formula for the support function of the reachable set:\n$$h_{R(t)}(l) = h_{X_0}((e^{A t})^T l) + \\int_0^t h_U(B^T e^{A^T (t-\\tau)} l) \\, d\\tau$$\n\nFor numerical computation, the integral is simplified by a change of variables. Let $s = t - \\tau$. Then $ds = -d\\tau$. The integration limits change from $\\tau \\in [0, t]$ to $s \\in [t, 0]$.\n$$\\int_0^t h_U(B^T e^{A^T (t-\\tau)} l) \\, d\\tau = \\int_t^0 h_U(B^T e^{A^T s} l) \\, (-ds) = \\int_0^t h_U(B^T e^{A^T s} l) \\, ds$$\n\nThe integral is approximated using the trapezoidal rule. We discretize the interval $[0, t]$ into $N_{steps}$ segments of width $\\Delta s = t / N_{steps}$. The grid points are $s_k = k \\Delta s$ for $k = 0, 1, \\dots, N_{steps}$. The integral is approximated as:\n$$\\int_0^t g(s) ds \\approx \\Delta s \\left( \\frac{g(s_0) + g(s_{N_{steps}})}{2} + \\sum_{k=1}^{N_{steps}-1} g(s_k) \\right)$$\nwhere the integrand is $g(s) = h_U(B^T e^{A^T s} l)$.\n\n**Support Function Implementations for Specific Sets**\n\nThe computation requires evaluating the support functions $h_{X_0}$ and $h_U$ for the specific set representations. Let $S$ be a generic compact convex set and $v$ be a direction vector.\n\n1.  **Box**: $S = \\{s \\mid s_{\\min} \\le s \\le s_{\\max}\\}$, where vector inequalities are component-wise.\n    $h_S(v) = \\sup_{s \\in S} \\langle v, s \\rangle = \\sup_{s_{\\min} \\le s \\le s_{\\max}} \\sum_i v_i s_i$. The supremum is achieved by choosing $s_i = s_{i, \\max}$ if $v_i \\ge 0$ and $s_i = s_{i, \\min}$ if $v_i < 0$.\n    $$h_S(v) = \\sum_{i:v_i \\ge 0} v_i s_{i, \\max} + \\sum_{i:v_i < 0} v_i s_{i, \\min}$$\n\n2.  **Euclidean Ball**: $S = \\{s \\in \\mathbb{R}^k : \\|s\\|_2 \\le r\\}$.\n    $h_S(v) = \\sup_{\\|s\\|_2 \\le r} \\langle v, s \\rangle$. By the Cauchy-Schwarz inequality, this supremum is $r \\|v\\|_2$, achieved when $s$ is parallel to $v$.\n    $$h_S(v) = r \\|v\\|_2$$\n\n3.  **Convex Polytope**: $S = \\text{conv}(\\{p_1, \\dots, p_N\\})$, the convex hull of a finite set of vertices.\n    A linear function over a convex polytope attains its maximum at one of the vertices.\n    $$h_S(v) = \\max_{i \\in \\{1, \\dots, N\\}} \\langle v, p_i \\rangle$$\n\nThe algorithm proceeds by computing the term for $X_0$ and then numerically computing the integral for the $U$ term, summing the results. This principled approach adheres strictly to the problem's constraints.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef solve():\n    \"\"\"\n    Solves the reachability problem for the five test cases.\n    \"\"\"\n\n    def support_function(set_spec, direction):\n        \"\"\"\n        Computes the support function for a given set and direction.\n\n        Args:\n            set_spec: A tuple (type, params) describing the set.\n            direction: The direction vector l.\n\n        Returns:\n            The value of the support function.\n        \"\"\"\n        set_type, params = set_spec\n        \n        if direction.ndim == 0:\n            direction = np.array([direction])\n\n        if set_type == 'box':\n            min_bounds, max_bounds = params\n            # s_i is max_bounds_i if direction_i >= 0, else min_bounds_i\n            s_star = np.where(direction >= 0, max_bounds, min_bounds)\n            return np.dot(direction, s_star)\n        \n        elif set_type == 'ball':\n            radius = params\n            norm_direction = np.linalg.norm(direction)\n            if norm_direction == 0:\n                return 0.0\n            return radius * norm_direction\n\n        elif set_type == 'polytope':\n            vertices = params\n            if not vertices:\n                return 0.0\n            # sup over s in Conv(V) is max over v in V\n            return max(np.dot(v, direction) for v in vertices)\n        \n        else:\n            raise ValueError(f\"Unknown set type: {set_type}\")\n\n    def compute_reachable_set_support_function(A, B, X0_spec, U_spec, t, l, n_steps=2000):\n        \"\"\"\n        Computes the support function of the reachable set R(t) in direction l.\n\n        Args:\n            A, B: System matrices.\n            X0_spec: Specification for the initial set X0.\n            U_spec: Specification for the input set U.\n            t: Time horizon.\n            l: Direction vector.\n            n_steps: Number of steps for numerical integration.\n\n        Returns:\n            The value h_R(t)(l).\n        \"\"\"\n        # Term 1: Contribution from the initial set X0\n        # h_{exp(At)X0}(l) = h_{X0}(exp(A.T*t) @ l)\n        exp_At_T = expm(A.T * t)\n        l_prime_x0 = exp_At_T @ l\n        h_x0_term = support_function(X0_spec, l_prime_x0)\n        \n        # Term 2: Contribution from the input set U (integral term)\n        # integral from 0 to t of h_U(B.T @ exp(A.T*s) @ l) ds\n        # Use trapezoidal rule for numerical integration.\n        # Change of variables s = t - tau makes it integral from 0 to t.\n        \n        h_u_integral = 0.0\n        if t > 0:\n            ds = t / n_steps\n            integrand_values = []\n            \n            for k in range(n_steps + 1):\n                s = k * ds\n                exp_As_T = expm(A.T * s)\n                l_prime_u = B.T @ exp_As_T @ l\n                integrand_value = support_function(U_spec, l_prime_u)\n                integrand_values.append(integrand_value)\n            \n            # Trapezoidal rule: ds * ( (f(0)+f(t))/2 + sum(f(s_k)) for k=1..n-1 )\n            h_u_integral = ds * ( (integrand_values[0] + integrand_values[-1]) / 2.0 + sum(integrand_values[1:-1]) )\n\n        return h_x0_term + h_u_integral\n\n    test_cases = [\n        { # Test case 1\n            \"A\": np.array([[-0.5, 0.2], [-0.1, -0.3]]),\n            \"B\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"X0_spec\": ('box', (np.array([-0.5, -0.5]), np.array([0.5, 0.5]))),\n            \"U_spec\": ('box', (np.array([-1.0, -0.5]), np.array([1.0, 0.5]))),\n            \"t\": 1.0,\n            \"l\": np.array([1.0, -0.5])\n        },\n        { # Test case 2\n            \"A\": np.array([[-0.5, 0.2], [-0.1, -0.3]]),\n            \"B\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"X0_spec\": ('box', (np.array([-1.0, -1.0]), np.array([1.0, 1.0]))),\n            \"U_spec\": ('box', (np.array([0.0, 0.0]), np.array([0.0, 0.0]))),\n            \"t\": 2.0,\n            \"l\": np.array([0.3, 0.4])\n        },\n        { # Test case 3\n            \"A\": np.array([[0.4, 0.6], [0.0, 0.2]]),\n            \"B\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"X0_spec\": ('box', (np.array([0.0, 0.0]), np.array([0.0, 0.0]))),\n            \"U_spec\": ('ball', 0.2),  # radius 0.2\n            \"t\": 0.5,\n            \"l\": np.array([1.0, 1.0])\n        },\n        { # Test case 4\n            \"A\": np.array([[-1.0]]),\n            \"B\": np.array([[1.0]]),\n            \"X0_spec\": ('box', (np.array([0.0]), np.array([0.0]))),\n            \"U_spec\": ('box', (np.array([0.0]), np.array([1.0]))),\n            \"t\": 1.5,\n            \"l\": np.array([1.0])\n        },\n        { # Test case 5\n            \"A\": np.array([[-0.2, 0.1, 0.0], [0.0, -0.3, 0.2], [0.0, 0.0, -0.1]]),\n            \"B\": np.array([[1.0, 0.0], [0.0, 1.0], [0.5, 0.5]]),\n            \"X0_spec\": ('ball', 0.1), # radius 0.1\n            \"U_spec\": ('polytope', [\n                np.array([1.0, 0.0]), np.array([0.0, 1.0]),\n                np.array([-1.0, 0.0]), np.array([0.0, -1.0])\n            ]),\n            \"t\": 2.0,\n            \"l\": np.array([0.5, -0.5, 1.0])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_reachable_set_support_function(\n            case[\"A\"], case[\"B\"], case[\"X0_spec\"], case[\"U_spec\"], case[\"t\"], case[\"l\"]\n        )\n        results.append(f\"{result:.7f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}