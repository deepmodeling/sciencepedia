{
    "hands_on_practices": [
        {
            "introduction": "A fundamental strategy for accelerating carry propagation is to introduce hierarchy, as seen in the Block Carry-Lookahead Adder (CLA). This architecture partitions the adder into smaller, manageable blocks, but introduces a critical design trade-off: larger blocks have slower internal logic, while smaller blocks create a longer inter-block carry chain. This exercise  challenges you to find the optimal balance by analytically deriving the block size that minimizes total delay, a classic optimization problem in digital design.",
            "id": "4255521",
            "problem": "Consider an $n$-bit two-level block Carry Lookahead Adder (CLA), organized into $n/b$ contiguous blocks of size $b$. The CLA is designed under a standard Electronic Design Automation (EDA) timing model in which the delay of a logic gate with fan-in $k \\geq 2$ is given by $t_{2} + (k-2)\\Delta$, where $t_{2}$ is the delay of a two-input gate and $\\Delta$ is the incremental delay per additional input beyond two. The adder employs bit-level propagate and generate signals defined by $p_{i} = a_{i} \\oplus b_{i}$ and $g_{i} = a_{i} \\wedge b_{i}$, respectively, for bit index $i \\in \\{0,1,\\dots,n-1\\}$. Within each block $j$, the group propagate is $P_{j} = \\bigwedge_{i \\in \\text{block } j} p_{i}$ and the group generate $G_{j}$ is formed by a sum-of-products lookahead network from the $\\{p_{i},g_{i}\\}$ of the block. Assume that the precomputation needed to feed the final wide $b$-input $\\vee$ gate for $G_{j}$, built from only two-input primitives, has a fixed depth and thus contributes a constant delay independent of $b$.\n\nInter-block carry computation follows the carry recurrence $C_{j+1} = G_{j} \\vee (P_{j} \\wedge C_{j})$ and is implemented as a chain of per-block two-input gates, one $\\wedge$ followed by one $\\vee$ per block along the carry path. Assume $p_{i}$ and $g_{i}$ are available after a constant head delay (from the adder inputs) that does not depend on $b$, and that the dominant $b$-dependent delays inside a block are the single $b$-input $\\wedge$ for $P_{j}$ and the single $b$-input $\\vee$ for $G_{j}$.\n\nUsing only the fundamental carry definitions $C_{i+1} = g_{i} \\vee (p_{i} \\wedge C_{i})$, the block group definitions for $P_{j}$ and $G_{j}$ stated above, and the specified gate delay model $t(k) = t_{2} + (k-2)\\Delta$, derive the block size $b$ that minimizes the worst-case carry-out delay of the adder as a function of $n$, $t_{2}$, and $\\Delta$. Express your final result for the optimal $b$ as a single closed-form analytical expression. No numerical evaluation is required.",
            "solution": "The starting point is the carry recurrence at the bit level, $C_{i+1} = g_{i} \\vee (p_{i} \\wedge C_{i})$, which generalizes at the block level to $C_{j+1} = G_{j} \\vee \\left(P_{j} \\wedge C_{j}\\right)$ once block group propagate and generate signals $P_{j}$ and $G_{j}$ have been formed. The critical-path delay to the adder carry-out must account for three components: the time to form bit-level signals $\\{p_{i},g_{i}\\}$, the time to form the block-level signals $\\{P_{j},G_{j}\\}$, and the time to propagate through the chain of $n/b$ blocks via the recurrence $C_{j+1} = G_{j} \\vee (P_{j} \\wedge C_{j})$.\n\nUnder the given gate delay model, any $k$-input gate has delay $t(k) = t_{2} + (k-2)\\Delta$. Let the constant delay required from the adder inputs to the availability of all $\\{p_{i},g_{i}\\}$ be denoted by $T_{\\text{head}}$, which may include the delays of $\\oplus$ and $\\wedge$ operations and any local buffering, and does not depend on $b$. Inside a block of size $b$, the group propagate $P_{j}$ is formed by a single $b$-input $\\wedge$, incurring delay $t_{P}(b) = t_{2} + (b-2)\\Delta$ beyond the availability of $\\{p_{i}\\}$. The group generate $G_{j}$ is assumed to be formed by a final $b$-input $\\vee$ whose inputs are precomputed by a fixed-depth network of two-input gates; let the fixed precomputation delay be $T_{\\text{pre}}$. Therefore, the dominant $b$-dependent portion for $G_{j}$ is the $b$-input $\\vee$ with delay $t_{G}(b) = t_{2} + (b-2)\\Delta$ beyond the precomputation. The earliest time at which both $P_{j}$ and $G_{j}$ are available for all blocks is thus\n$$\nT_{\\text{blk}}(b) = T_{\\text{head}} + T_{\\text{pre}} + \\left[t_{2} + (b-2)\\Delta\\right],\n$$\nwhere the bracketed term captures the $b$-dependent wide-gate delay and the sum $T_{\\text{head}} + T_{\\text{pre}}$ is independent of $b$.\n\nAcross blocks, the carry recurrence $C_{j+1} = G_{j} \\vee (P_{j} \\wedge C_{j})$ is implemented per block by one two-input $\\wedge$ followed by one two-input $\\vee$, so each block along the carry chain contributes a delay of $2 t_{2}$. For $n/b$ blocks, the inter-block carry propagation delay is\n$$\nT_{\\text{chain}}(b) = 2 t_{2} \\cdot \\frac{n}{b}.\n$$\nNeglecting constant terms independent of $b$ when searching for the minimizing $b$, the total worst-case carry-out delay can be written as\n$$\nD(b) = \\underbrace{T_{\\text{head}} + T_{\\text{pre}}}_{\\text{independent of } b} + \\left[t_{2} + (b-2)\\Delta\\right] + 2 t_{2} \\cdot \\frac{n}{b}.\n$$\nDefine $K = T_{\\text{head}} + T_{\\text{pre}} + t_{2} - 2\\Delta$, which is independent of $b$. Then\n$$\nD(b) = K + \\Delta b + 2 t_{2} \\cdot \\frac{n}{b}.\n$$\nTo minimize $D(b)$ with respect to continuous $b > 0$, differentiate and set the derivative to zero:\n$$\n\\frac{dD}{db} = \\Delta - 2 t_{2} \\cdot \\frac{n}{b^{2}} = 0.\n$$\nSolving for $b$ gives\n$$\n\\Delta = 2 t_{2} \\cdot \\frac{n}{b^{2}} \\quad \\Rightarrow \\quad b^{2} = \\frac{2 t_{2} n}{\\Delta} \\quad \\Rightarrow \\quad b^{\\star} = \\sqrt{\\frac{2 t_{2} n}{\\Delta}}.\n$$\nA second derivative check confirms convexity:\n$$\n\\frac{d^{2}D}{db^{2}} = 4 t_{2} \\cdot \\frac{n}{b^{3}} > 0 \\quad \\text{for} \\quad b > 0,\n$$\nso the stationary point is indeed a global minimum. The constants $T_{\\text{head}}$ and $T_{\\text{pre}}$ do not affect the optimal $b$, as they do not depend on $b$. Therefore, the optimal block size that minimizes the worst-case carry-out delay under the specified model is\n$$\nb^{\\star} = \\sqrt{\\frac{2 t_{2} n}{\\Delta}}.\n$$\nIf an integer block size is required in implementation, one would choose the nearest integer to $b^{\\star}$, but the closed-form analytical minimizer as requested is as above.",
            "answer": "$$\\boxed{\\sqrt{\\frac{2 t_{2} n}{\\Delta}}}$$"
        },
        {
            "introduction": "Moving to more advanced parallel prefix architectures, the design of the elementary prefix cell becomes paramount. A subtle change in the definition of the 'propagate' signal can have profound implications for the entire carry network's complexity and speed. In this practice , you will explore the replacement of the conventional $p_i = a_i \\oplus b_i$ signal with the 'propagate-when-one' variant $p_i' = a_i \\lor b_i$, analyzing its effect on the logic's monotonicity and its suitability for high-speed dynamic circuit families.",
            "id": "4255496",
            "problem": "Consider a family of parallel-prefix adders in Integrated Circuit design and Electronic Design Automation (EDA). At bit position $i$, let the operand bits be $a_i$ and $b_i$, and let the incoming carry be $c_i$. Define the one-bit addition from first principles as the modulo-$2$ sum and the carry-out according to Boolean addition: the sum bit is $s_i = a_i \\oplus b_i \\oplus c_i$, and the carry-out $c_{i+1}$ is the Boolean function that is $1$ exactly when at least two of $\\{a_i,b_i,c_i\\}$ are $1$. Introduce the standard generate signal $g_i = a_i \\land b_i$ and the conventional propagate signal $p_i = a_i \\oplus b_i$. In prefix architectures, bitwise pairs $(g_i,p_i)$ are combined into group pairs $(G_{k:j},P_{k:j})$ over ranges $[j,k]$ using an associative binary operator built from $\\land$ and $\\lor$ so that carry-lookahead can be realized without ripple.\n\nNow consider replacing the conventional propagate $p_i$ with the \"propagate-when-one\" signal $p_i' = a_i \\lor b_i$ while keeping $g_i = a_i \\land b_i$. Starting from the above fundamental base (Boolean definitions of sum, majority carry, and generate), and without assuming any adder-specific shortcut identities, derive the exact forms of $c_{i+1}$ and $s_i$ when expressed in terms of $g_i$, $p_i'$, and $c_i$. Then, reason about how the group propagate and generate should be formed over a block $[j,k]$ using only $\\land$ and $\\lor$, and whether the associative prefix-combine operator on $(G,P)$ pairs persists under the replacement $p_i \\mapsto p_i'$. Finally, analyze implications of this replacement for gate complexity in the carry tree and for susceptibility to logic hazards in static Complementary Metal–Oxide–Semiconductor (CMOS) and dynamic Domino realizations.\n\nSelect the option(s) that are correct based on your derivations and analysis:\n\nA. With $p_i'$, the carry-out remains $c_{i+1} = g_i \\lor (p_i' \\land c_i)$, and the sum can be formed directly as $s_i = p_i' \\oplus c_i$; because $g_i$ and $p_i'$ are disjoint, this replacement decreases hazard susceptibility.\n\nB. With $p_i'$, the bit-level sum must be written $s_i = (p_i' \\oplus g_i) \\oplus c_i$, the carry-out is $c_{i+1} = g_i \\lor (p_i' \\land c_i)$, and the prefix algebra on pairs $(G,P)$ retains the associative form $(G,P)\\circ(G',P') = (G \\lor (P \\land G'),\\, P \\land P')$; the carry network becomes monotone (only $\\land,\\lor$ on $(G,P)$), which is favorable to dynamic Domino CMOS, and it reduces gate complexity in the carry tree relative to $\\oplus$-propagate.\n\nC. With $p_i'$, the correct group propagate over $[j,k]$ is $P_{k:j}' = p_k' \\lor p_{k-1}' \\lor \\cdots \\lor p_j'$, which shortens the tree depth but increases fan-in; the associative prefix operator fails for $(G,P')$ unless the tree is strictly balanced.\n\nD. Using $p_i'$ invalidates carry-lookahead because the combine operator on $(G,P')$ pairs is non-associative; thus, parallel-prefix architectures cannot be constructed with $p_i'$.\n\nE. Replacing $p_i$ by $p_i'$ reduces gate count in the carry tree, but the sum path requires an additional level to form $p_i' \\oplus g_i$ before the final $\\oplus c_i$, so the sum-path logical depth can increase by $1$ relative to directly using $p_i = a_i \\oplus b_i$; the adder’s critical path impact depends on whether the carry or sum path dominates.",
            "solution": "The problem asks for a complete analysis of replacing the conventional propagate signal $p_i = a_i \\oplus b_i$ with $p_i' = a_i \\lor b_i$. We will derive the required expressions and analyze their implications.\n\n**1. Derivation of Bit-Level Sum ($s_i$) and Carry ($c_{i+1}$)**\nThe fundamental definitions are:\n- Sum: $s_i = a_i \\oplus b_i \\oplus c_i$\n- Carry-out: $c_{i+1} = \\text{MAJ}(a_i, b_i, c_i) = (a_i \\land b_i) \\lor (a_i \\land c_i) \\lor (b_i \\land c_i)$\n\nThe proposed signals are:\n- Generate: $g_i = a_i \\land b_i$\n- Propagate-when-one: $p_i' = a_i \\lor b_i$\n\nFirst, let's express $c_{i+1}$ using $g_i$ and $p_i'$. By factoring the majority function:\n$$c_{i+1} = (a_i \\land b_i) \\lor (c_i \\land (a_i \\lor b_i))$$\nSubstituting the definitions of $g_i$ and $p_i'$ directly yields:\n$$c_{i+1} = g_i \\lor (p_i' \\land c_i)$$\nThis is the standard carry recurrence relation, valid under the $p_i'$ definition.\n\nNext, let's express $s_i$ using $g_i$, $p_i'$, and $c_i$. The sum is $s_i = (a_i \\oplus b_i) \\oplus c_i$. We must express the half-sum $a_i \\oplus b_i$ in terms of $g_i$ and $p_i'$. We use the Boolean identity $X \\oplus Y = (X \\lor Y) \\oplus (X \\land Y)$. Let $X=a_i$ and $Y=b_i$.\n$$a_i \\oplus b_i = (a_i \\lor b_i) \\oplus (a_i \\land b_i) = p_i' \\oplus g_i$$\nTherefore, the full sum expression is:\n$$s_i = (p_i' \\oplus g_i) \\oplus c_i$$\n\n**2. Derivation of Group Generate/Propagate and Associativity**\nA parallel-prefix adder computes carries for groups of bits. Let's find the group generate $G_{k:j}$ and group propagate $P_{k:j}'$ for a block of bits from index $j$ to $k$ ($k>j$). The carry-out of this block, $c_{k+1}$, must satisfy $c_{k+1} = G_{k:j} \\lor (P_{k:j}' \\land c_j)$.\nLet's combine two adjacent blocks: a block from $j$ to $m-1$ and a block from $m$ to $k$. We use the operator symbol $\\circ$ for this combination. Let $(G_2, P_2')$ represent the block $[m, k]$ and $(G_1, P_1')$ represent the block $[j, m-1]$.\nThe carry into the second block, $c_m$, is the output of the first block:\n$$c_m = G_1 \\lor (P_1' \\land c_j)$$\nThe carry-out of the second block, $c_{k+1}$, is:\n$$c_{k+1} = G_2 \\lor (P_2' \\land c_m)$$\nSubstituting the expression for $c_m$:\n$$c_{k+1} = G_2 \\lor (P_2' \\land (G_1 \\lor (P_1' \\land c_j)))$$\n$$c_{k+1} = G_2 \\lor (P_2' \\land G_1) \\lor (P_2' \\land P_1' \\land c_j)$$\nBy comparing this to the target form $c_{k+1} = G_{k:j} \\lor (P_{k:j}' \\land c_j)$, we identify the combined group signals:\n$$G_{k:j} = G_2 \\lor (P_2' \\land G_1)$$\n$$P_{k:j}' = P_2' \\land P_1'$$\nSo, the prefix-combine operator on pairs $(G, P')$ is:\n$$(G_2, P_2') \\circ (G_1, P_1') = (G_2 \\lor (P_2' \\land G_1), P_2' \\land P_1')$$\nThis operator is associative. This can be proven by testing $(A \\circ B) \\circ C = A \\circ (B \\circ C)$, which holds true. This means parallel-prefix architectures can be constructed with this logic.\n\n**3. Analysis of Implications**\n*   **Gate Complexity  Monotonicity**: The initial signals $g_i = a_i \\land b_i$ and $p_i' = a_i \\lor b_i$ are simpler to compute than the conventional $p_i = a_i \\oplus b_i$. Furthermore, both $g_i$ and $p_i'$ are monotonic functions of the inputs. Since the prefix operator only uses $\\land$ and $\\lor$, the entire carry network becomes monotonic, which is highly advantageous for single-rail dynamic logic families like Domino CMOS.\n*   **Sum Path Delay**: The sum calculation $s_i = (p_i' \\oplus g_i) \\oplus c_i$ requires an extra logic level (the $p_i' \\oplus g_i$ term) compared to the conventional $s_i = p_i \\oplus c_i$. This can increase the delay of the sum-computation path.\n*   **Critical Path**: The overall adder speed depends on the maximum of the carry-path delay and the sum-path delay. This change makes the carry pre-computation simpler but the sum computation more complex, representing a classic design trade-off.\n\n**4. Evaluation of Options**\n*   **A**: Incorrect sum formula and incorrect claim that $g_i$ and $p_i'$ are disjoint.\n*   **B**: All claims are correct as per our derivation: correct sum and carry formulas, correct associative operator form, and correct analysis of monotonicity and complexity.\n*   **C**: Incorrect group propagate formula and incorrect claim about associativity.\n*   **D**: Incorrect claim about associativity.\n*   **E**: Correctly identifies the reduced complexity of the carry path logic, the increased logical depth of the sum path, and the resulting critical path trade-off.\n\nBoth options B and E are correct.",
            "answer": "$$\\boxed{BE}$$"
        },
        {
            "introduction": "The final step in high-performance design is translating an optimized logic architecture into a physically fast circuit by sizing transistors appropriately. After selecting an architecture and cell logic, as explored in the previous exercises, we must ensure the gates can drive their loads with minimal delay. This problem  provides hands-on practice with the method of logical effort, a powerful technique for optimizing path delay, by asking you to calculate the performance of a critical path composed of prefix cells and determine the optimal sizing for maximum speed.",
            "id": "4255542",
            "problem": "A parallel-prefix carry network uses black prefix cells to accelerate carries in a $64$-bit adder. Along the critical generate path, there are $N=6$ identical black prefix cells in series. Each black cell is implemented as a static Complementary Metal-Oxide-Semiconductor (CMOS) complex gate of the And-Or-Invert (AOI) or Or-And-Invert (OAI) type with fan-in $4$ (functionally equivalent to an $\\text{AOI22}$ or its dual $\\text{OAI22}$). Use the method of logical effort to model delay, with the following normalization and physical assumptions:\n\n- The minimum inverter used for normalization has $n$-channel width $1$ and $p$-channel width $2$ (chosen to equalize pull-up and pull-down resistances). Its input capacitance is denoted $C_{\\text{inv}}$ and is proportional to the sum of its device widths. Gate input capacitance is proportional to the sum of the widths of the transistors driven by that input.\n- Series devices in a pull-up or pull-down conduction path are upsized so that the worst-case path resistance equals that of the minimum inverter.\n- The parasitic delay of a gate is proportional to the total diffusion capacitance connected to its output and is normalized to the inverter’s parasitic; assume the diffusion contribution per device at the output sums linearly.\n- There is no branching along this path (branching effort equal to $1$).\n\nThe path must drive a final load of $C_{L} = 256\\,C_{\\text{inv}}$. The source that drives the first black cell cannot be upsized and constrains the input capacitance seen by the first black cell to be at most $4\\,C_{\\text{inv}}$. You may assume the first black cell is sized to exactly meet this input capacitance budget. Measure delay in the logical-effort delay unit $\\tau$.\n\nTasks:\n1. Derive the logical effort $g$ and the parasitic delay $p$ of the $\\text{AOI22}$/$\\text{OAI22}$ black cell under the sizing rule stated above.\n2. Using the method of logical effort and the given load and input-capacitance constraint, determine the optimal per-stage effort and the corresponding sizing progression along the path (expressed as the input capacitance of each stage in multiples of $C_{\\text{inv}}$).\n3. Compute the minimum path delay $D_{\\min}$ in units of $\\tau$.\n\nReport only the numerical value of $D_{\\min}$ in units of $\\tau$ as your final answer. No rounding is required.",
            "solution": "The solution proceeds in three parts as requested by the problem statement:\n1.  Derive the logical effort $g$ and parasitic delay $p$ of the black prefix cell.\n2.  Determine the optimal per-stage effort.\n3.  Compute the minimum path delay $D_{\\min}$.\n\n**1. Logical Effort and Parasitic Delay of the AOI22 Cell**\n\nThe black prefix cell is an AOI22 gate, with the Boolean function $F = \\overline{(A \\cdot B) + (C \\cdot D)}$. We must first determine the transistor sizes required to give this gate the same drive strength as the reference inverter. The reference inverter has an $n$-channel transistor of width $1$ and a $p$-channel transistor of width $2$. This sizing equalizes the pull-up and pull-down resistances, which we denote as $R_{\\text{inv}}$. The input capacitance of this inverter is proportional to the sum of its gate widths, $1+2=3$.\n\n**Sizing the AOI22 Gate:**\n- **Pull-Down Network (PDN):** The PDN consists of two parallel branches, where each branch has two $n$-channel transistors in series (e.g., A in series with B). The worst-case pull-down resistance occurs when only one branch is active. This path consists of two series $n$-channel transistors. To make the total resistance equal to $R_{\\text{inv}}$, each of these transistors must have a resistance of $R_{\\text{inv}}/2$. Since resistance is inversely proportional to width, their width must be twice that of the reference $n$-channel transistor. Thus, all $n$-channel transistors must have a width of $2 \\times 1 = 2$.\n- **Pull-Up Network (PUN):** The PUN is the dual of the PDN. It consists of two series blocks, each containing two parallel $p$-channel transistors (e.g., A in parallel with C). The worst-case pull-up resistance occurs when a path is formed through one transistor in each of the series blocks. This path consists of two series $p$-channel transistors. To make their total resistance equal to $R_{\\text{inv}}$, each must have a resistance of $R_{\\text{inv}}/2$. The reference $p$-channel transistor has width $2$ and resistance $R_{\\text{inv}}$. Therefore, to achieve half the resistance, the width must be doubled. Thus, all $p$-channel transistors must have a width of $2 \\times 2 = 4$.\n\n**Logical Effort ($g$):**\nThe logical effort of a gate is the ratio of its input capacitance to that of an inverter with the same output drive strength.\n- The input capacitance of the AOI22 gate at any input (e.g., A) is proportional to the sum of the widths of the transistors it drives (one $n$-channel, one $p$-channel): $C_{\\text{in,AOI22}} \\propto W_n + W_p = 2 + 4 = 6$.\n- The input capacitance of the reference inverter is proportional to $W_{n,\\text{inv}} + W_{p,\\text{inv}} = 1 + 2 = 3$.\n- The logical effort $g$ is the ratio of these capacitances:\n$$g = \\frac{6}{3} = 2$$\nThe analysis for an OAI22 gate yields the same result.\n\n**Parasitic Delay ($p$):**\nThe parasitic delay is the ratio of the gate's output diffusion capacitance to that of the reference inverter. Diffusion capacitance is proportional to the total width of the transistor drains connected to the output node.\n- **AOI22 Output Node:** The output is connected to the drains of all transistors in the pull-down network and all transistors in the pull-up network. The total diffusion width at the output of the AOI22 is the sum of the widths of these transistors: $W_{\\text{diff,AOI22}} = 4 \\cdot W_n + 4 \\cdot W_p = 4 \\cdot 2 + 4 \\cdot 4 = 8 + 16 = 24$. Wait, this is not correct. The total diffusion width at the output is the sum of the widths of the transistors whose drains are connected to the output. In an AOI22, the output node connects to the two parallel series n-FET chains, and the two series parallel p-FET chains. In the PDN, only the drains of the top transistors (A and C) connect to the output Y. The internal nodes connect B to A and D to C. So only 2 nFET drains are at the output. In the PUN, the structure is dual. So 2 pFET drains are at the output.\nLet's re-calculate.\nFor the PDN: Two branches in parallel. Each branch has 2 nMOS in series. The drains of the top nMOS transistors (one from each branch) are connected to the output. The total n-type diffusion width at the output is $2 \\times W_n = 2 \\times 2 = 4$.\nFor the PUN: Two blocks in series. Each block has 2 pMOS in parallel. The drains of all pMOS in the bottom block are connected to the output. The total p-type diffusion width at the output is $2 \\times W_p = 2 \\times 4 = 8$.\nTotal diffusion width at output of AOI22: $4 + 8 = 12$.\n- **Inverter Output Node:** The output is connected to the drain of one $n$-channel and one $p$-channel transistor. The total diffusion width is: $W_{\\text{diff,inv}} = W_{n,\\text{inv}} + W_{p,\\text{inv}} = 1 + 2 = 3$.\n- The parasitic delay $p$ is the ratio of these diffusion widths (assuming $p_{\\text{inv}}=1$ by normalization):\n$$p = \\frac{W_{\\text{diff,AOI22}}}{W_{\\text{diff,inv}}} = \\frac{12}{3} = 4$$\n\n**2. Optimal Stage Effort and Path Parameters**\n\nThe path consists of $N=6$ identical stages. The delay of a path is minimized when the effort of each stage is the same. The stage effort is $f_i = g_i h_i$, where $g_i$ is the logical effort and $h_i$ is the electrical effort.\n- Path logical effort: $G = \\prod_{i=1}^{N} g_i = g^N = 2^6 = 64$.\n- Path electrical effort: $H = \\frac{C_L}{C_{\\text{in},1}}$, where $C_L$ is the final load and $C_{\\text{in},1}$ is the input capacitance of the first stage.\n$$H = \\frac{256\\,C_{\\text{inv}}}{4\\,C_{\\text{inv}}} = 64$$\n- Total path effort: $F = GBH$. Since the branching effort $B=1$, $F=GH$.\n$$F = 64 \\times 64 = 4096$$\nThe optimal stage effort, $f_{\\text{opt}}$, is the $N$-th root of the total path effort:\n$$f_{\\text{opt}} = F^{1/N} = (4096)^{1/6} = (2^{12})^{1/6} = 2^{12/6} = 2^2 = 4$$\n\n**3. Minimum Path Delay ($D_{\\min}$)**\n\nThe total path delay, $D$, is the sum of the individual stage delays, $d_i = f_i + p_i$. When minimized, all stage efforts are equal to $f_{\\text{opt}}$.\nThe minimum path delay is given by the formula:\n$$D_{\\min} = N \\cdot f_{\\text{opt}} + P_{\\text{path}}$$\nwhere $P_{\\text{path}}$ is the sum of the parasitic delays of all stages in the path.\n- Path parasitic delay: $P_{\\text{path}} = \\sum_{i=1}^{N} p_i = N \\cdot p = 6 \\times 4 = 24$.\nSubstituting the values for $N$, $f_{\\text{opt}}$, and $P_{\\text{path}}$:\n$$D_{\\min} = (6 \\times 4) + 24 = 24 + 24 = 48$$\nThe delay is measured in units of $\\tau$, the fundamental delay unit of the logical effort methodology.\nThe sizing of the stages would be such that the electrical effort of each stage is $h_i = f_{\\text{opt}} / g = 4 / 2 = 2$.\nThis leads to a sequence of input capacitances: $C_{\\text{in},1} = 4\\,C_{\\text{inv}}$, $C_{\\text{in},2} = 8\\,C_{\\text{inv}}$, ..., $C_{\\text{in},6} = 128\\,C_{\\text{inv}}$. The output of the last stage is $h_6 \\cdot C_{\\text{in},6} = 2 \\cdot 128\\,C_{\\text{inv}} = 256\\,C_{\\text{inv}}$, which correctly matches the load $C_L$.\nThe minimum delay is therefore $48\\,\\tau$.",
            "answer": "$$\\boxed{48}$$"
        }
    ]
}