{
    "hands_on_practices": [
        {
            "introduction": "The Voltage-Controlled Oscillator (VCO) is the core component of any clock recovery system, responsible for generating the recovered clock. This practice  builds your analytical skills by having you derive two of its most critical performance metrics—the VCO gain ($K_{vco}$) and the phase noise ($L(\\Delta f)$)—from fundamental circuit principles. Understanding how device-level properties and noise sources translate into these system-level parameters is a foundational step in designing and analyzing high-performance CDR loops.",
            "id": "4259653",
            "problem": "A clock and data recovery architecture employs a ring Voltage-Controlled Oscillator (VCO) comprising $N$ identical, current-starved delay stages. Each stage drives an effective load capacitance $C_{L}$ and exhibits a full-swing voltage excursion $V_{s}$ over each transition. The bias network sets the per-stage bias current $I$ through a control voltage $V_{b}$, with small-signal transconductance $\\alpha = \\partial I / \\partial V_{b}$ that is approximately constant over the operating range of interest. Assume the propagation delay per stage arises from charging or discharging the load capacitance at approximately constant current, so that the delay follows directly from the capacitor current law.\n\nThe oscillator runs at a fundamental frequency set by the loop propagation around the ring. You may treat the stages as identical and the waveform as periodic and stationary in the absence of noise, with sufficiently large amplitude regulation that amplitude perturbations do not significantly couple into phase at the offsets considered.\n\nIn addition to bias control, the oscillator experiences device noise in each stage. Model the dominant device noise contributions at the output nodes of the $N$ stages as zero-mean, wide-sense stationary current noise sources $i_{n,k}(t)$, $k=1,\\dots,N$, each with a one-sided power spectral density $S_{i,k}(\\Delta f)$ in $\\mathrm{A^{2}/Hz}$ evaluated at offset frequency $\\Delta f$ from the carrier. Let the Impulse Sensitivity Function (ISF) $\\Gamma_{k}(\\varphi)$ quantify the normalized phase sensitivity of the oscillator to an infinitesimal charge impulse injected at node $k$ when the oscillator is at phase $\\varphi$, over one period. Define the root-mean-square (rms) value of each ISF over a period $T$ by $\\Gamma_{k,\\mathrm{rms}} = \\sqrt{\\frac{1}{T}\\int_{0}^{T}\\Gamma_{k}^{2}(\\varphi(t))\\,\\mathrm{d}t}$.\n\nStarting from fundamental capacitor charging and delay concepts and the definition of phase from time shift, derive:\n\n1. The VCO gain $K_{vco} = \\partial f_{\\mathrm{osc}} / \\partial V_{b}$ as a function of the bias transconductance $\\alpha$, the number of stages $N$, the load capacitance $C_{L}$, and the voltage swing $V_{s}$.\n\n2. The single-sideband phase noise $L(\\Delta f)$ in linear units per Hertz (dimensionless ratio per Hz), at an offset $\\Delta f$ from the carrier, due to the $N$ device noise sources acting through their ISFs. Express $L(\\Delta f)$ in terms of $\\Gamma_{k,\\mathrm{rms}}$, $S_{i,k}(\\Delta f)$, $C_{L}$, $V_{s}$, and $\\Delta f$, assuming identical $C_{L}$ and $V_{s}$ at all $N$ nodes.\n\nYour final answers must be closed-form analytical expressions. For $K_{vco}$, express your result in $\\mathrm{Hz/V}$. For $L(\\Delta f)$, express your result in linear scale per Hertz (do not use decibels). No numerical evaluation is required.",
            "solution": "The problem is found to be valid as it is scientifically grounded, well-posed, and objective. It presents a standard model of a ring oscillator VCO and asks for the derivation of its gain and phase noise based on fundamental principles and established theoretical frameworks (specifically, the Impulse Sensitivity Function model). All necessary parameters and definitions are provided.\n\nThe solution is presented in two parts as requested.\n\n### Part 1: Derivation of VCO Gain ($K_{vco}$)\n\nThe analysis begins by determining the propagation delay, $t_{pd}$, of a single delay stage. The problem states that this delay arises from charging or discharging the load capacitance, $C_{L}$, with a constant bias current, $I$, over the full voltage swing, $V_{s}$. Based on the fundamental capacitor current-voltage relationship $I = C \\frac{dV}{dt}$, for a constant current $I$, the time $\\Delta t$ required for a voltage change $\\Delta V$ across a capacitor $C$ is $\\Delta t = C \\frac{\\Delta V}{I}$. Applying this to a single stage, the propagation delay is:\n$$t_{pd} = \\frac{C_{L} V_{s}}{I}$$\n\nA ring oscillator's period of oscillation, $T_{osc}$, is determined by the total time it takes for a signal edge to propagate around the loop and for the cycle to complete. For a standard $N$-stage ring oscillator, the period is twice the total propagation delay of the $N$ stages.\n$$T_{osc} = 2 N t_{pd}$$\n\nSubstituting the expression for $t_{pd}$ gives the oscillation period in terms of the circuit parameters:\n$$T_{osc} = 2 N \\frac{C_{L} V_{s}}{I}$$\n\nThe fundamental frequency of oscillation, $f_{osc}$, is the reciprocal of the period:\n$$f_{osc} = \\frac{1}{T_{osc}} = \\frac{I}{2 N C_{L} V_{s}}$$\n\nThe VCO gain, $K_{vco}$, is defined as the sensitivity of the oscillation frequency to changes in the control voltage, $V_{b}$. We calculate this by taking the partial derivative of $f_{osc}$ with respect to $V_{b}$:\n$$K_{vco} = \\frac{\\partial f_{osc}}{\\partial V_{b}} = \\frac{\\partial}{\\partial V_{b}} \\left( \\frac{I}{2 N C_{L} V_{s}} \\right)$$\n\nThe parameters $N$, $C_{L}$, and $V_{s}$ are constants with respect to $V_{b}$. The bias current $I$ is a function of $V_{b}$. Therefore, we apply the chain rule:\n$$K_{vco} = \\frac{1}{2 N C_{L} V_{s}} \\frac{\\partial I}{\\partial V_{b}}$$\n\nThe problem defines the bias network's small-signal transconductance as $\\alpha = \\frac{\\partial I}{\\partial V_{b}}$. Substituting this definition into the expression for $K_{vco}$ yields the final result:\n$$K_{vco} = \\frac{\\alpha}{2 N C_{L} V_{s}}$$\n\n### Part 2: Derivation of Single-Sideband Phase Noise ($L(\\Delta f)$)\n\nThe phase noise is derived using the Impulse Sensitivity Function (ISF) framework. In this model, the phase deviation $\\phi(t)$ of the oscillator is the result of perturbations from noise sources. A noise current $i_{n,k}(t)$ injected at node $k$ causes a phase deviation governed by the ISF for that node, $\\Gamma_{k}(\\varphi)$. The resulting total phase deviation $\\phi(t)$ is the time-integrated effect of all noise currents, weighted by their respective ISFs and normalized by the maximum charge $q_{max}$ displaced across the node capacitance during a swing. For a swing of $V_{s}$ across a capacitance $C_{L}$, this charge is $q_{max} = C_{L} V_{s}$.\n\nThe phase evolution is described by:\n$$\\phi(t) = \\sum_{k=1}^{N} \\int_{-\\infty}^{t} \\frac{\\Gamma_{k}(\\omega_{osc} \\tau)}{C_{L} V_{s}} i_{n,k}(\\tau) d\\tau$$\nwhere $\\omega_{osc} = 2 \\pi f_{osc}$ is the angular frequency of oscillation. This equation shows that the phase $\\phi(t)$ is the output of a linear system whose input is the process $x(t) = \\sum_{k=1}^{N} \\frac{\\Gamma_{k}(\\omega_{osc}t)}{C_{L} V_{s}} i_{n,k}(t)$ and whose impulse response is that of an ideal integrator, $h(t) = u(t)$, which has a frequency response $H(\\Delta f) = \\frac{1}{j 2 \\pi \\Delta f}$.\n\nThe power spectral density (PSD) of the output is related to the PSD of the input by $S_{\\phi}(\\Delta f) = |H(\\Delta f)|^{2} S_{x}(\\Delta f)$. This relationship holds for the one-sided PSDs:\n$$S_{\\phi, \\text{one-sided}}(\\Delta f) = \\frac{1}{(2 \\pi \\Delta f)^{2}} S_{x, \\text{one-sided}}(\\Delta f)$$\n\nNext, we find the one-sided PSD of the input process, $S_{x, \\text{one-sided}}(\\Delta f)$. The noise sources $i_{n,k}(t)$ are assumed to be wide-sense stationary and uncorrelated. Therefore, the PSD of the sum is the sum of the PSDs of the individual terms:\n$$S_{x, \\text{one-sided}}(\\Delta f) = \\sum_{k=1}^{N} \\text{PSD}\\left[\\frac{\\Gamma_{k}(\\omega_{osc}t)}{C_{L} V_{s}} i_{n,k}(t)\\right]$$\n\nEach term is the product of a stationary random process $i_{n,k}(t)$ and a deterministic periodic function $\\frac{\\Gamma_{k}(\\omega_{osc}t)}{C_{L} V_{s}}$. The resulting process is cyclostationary. For offset frequencies $\\Delta f$ that are small compared to $f_{osc}$, the time-averaged PSD of this product is approximately the PSD of the noise scaled by the mean-square value of the periodic function. The mean-square value of $\\frac{\\Gamma_{k}(\\omega_{osc}t)}{C_{L} V_{s}}$ over one period $T$ is:\n$$\\left\\langle \\left(\\frac{\\Gamma_{k}(\\omega_{osc}t)}{C_{L} V_{s}}\\right)^{2} \\right\\rangle = \\frac{1}{(C_{L} V_{s})^{2}} \\frac{1}{T} \\int_{0}^{T} \\Gamma_{k}^{2}(\\varphi(t)) dt$$\nThe problem defines the rms value of the ISF as $\\Gamma_{k,\\mathrm{rms}} = \\sqrt{\\frac{1}{T}\\int_{0}^{T}\\Gamma_{k}^{2}(\\varphi(t)) dt}$, so $\\Gamma_{k,\\mathrm{rms}}^{2} = \\frac{1}{T}\\int_{0}^{T}\\Gamma_{k}^{2}(\\varphi(t)) dt$. Thus, the scaling factor is $\\frac{\\Gamma_{k,\\mathrm{rms}}^{2}}{(C_{L} V_{s})^{2}}$.\n\nThe PSD of the sum $x(t)$ becomes:\n$$S_{x, \\text{one-sided}}(\\Delta f) = \\sum_{k=1}^{N} \\frac{\\Gamma_{k,\\mathrm{rms}}^{2}}{(C_{L} V_{s})^{2}} S_{i,k}(\\Delta f)$$\nwhere $S_{i,k}(\\Delta f)$ is the given one-sided PSD of the current noise source at node $k$.\n\nSubstituting this into the expression for the phase PSD gives:\n$$S_{\\phi, \\text{one-sided}}(\\Delta f) = \\frac{1}{(2 \\pi \\Delta f)^{2}} \\frac{1}{(C_{L} V_{s})^{2}} \\sum_{k=1}^{N} \\Gamma_{k,\\mathrm{rms}}^{2} S_{i,k}(\\Delta f)$$\n\nThe single-sideband phase noise, $L(\\Delta f)$, is defined as half of the one-sided spectral density of the phase fluctuations:\n$$L(\\Delta f) = \\frac{1}{2} S_{\\phi, \\text{one-sided}}(\\Delta f)$$\n\nSubstituting the expression for $S_{\\phi, \\text{one-sided}}(\\Delta f)$ yields the final result for the phase noise:\n$$L(\\Delta f) = \\frac{1}{2} \\cdot \\frac{1}{4 \\pi^{2} (\\Delta f)^{2} (C_{L} V_{s})^{2}} \\sum_{k=1}^{N} \\Gamma_{k,\\mathrm{rms}}^{2} S_{i,k}(\\Delta f)$$\n$$L(\\Delta f) = \\frac{1}{8 \\pi^{2} (\\Delta f)^{2} (C_{L} V_{s})^{2}} \\sum_{k=1}^{N} \\Gamma_{k,\\mathrm{rms}}^{2} S_{i,k}(\\Delta f)$$",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\alpha}{2 N C_{L} V_{s}}  \\frac{1}{8 \\pi^{2} (\\Delta f)^{2} (C_{L} V_{s})^{2}} \\sum_{k=1}^{N} \\Gamma_{k,\\mathrm{rms}}^{2} S_{i,k}(\\Delta f) \\end{pmatrix}}$$"
        },
        {
            "introduction": "While control loops are often designed using continuous-time theory, modern CDRs implement the loop filter in the digital domain for flexibility and scalability. This exercise  tackles the crucial translation between these two worlds. You will use the bilinear transform to map a continuous-time proportional-integral (PI) controller to its digital equivalent and analyze the resulting \"mapping error,\" providing practical insight into the non-idealities of sampled-data control systems.",
            "id": "4259696",
            "problem": "Consider a linearized clock and data recovery loop in which the phase-domain model consists of a phase detector with gain $K_{d}$ (output in a normalized control unit per radian), a digital proportional–integral (PI) filter $F(z)=K_{p}+K_{i}\\frac{z}{z-1}$ running with update period $T_{u}$, a digitally controlled oscillator (DCO) modeled as an integrator with gain $K_{v}$ (radian per second per normalized control unit), and a feedback divider of ratio $N$. Assume small-signal linear behavior and unity phase feedback.\n\nStarting from the bilinear (Tustin) transform definition $s=\\frac{2}{T_{u}}\\frac{z-1}{z+1}$, derive the equivalent continuous-time loop filter $F_{\\mathrm{eq}}(s)$ that matches the discrete-time PI $F(z)$ under the bilinear mapping. Using the continuous-time loop consisting of the phase detector, the equivalent PI loop filter, and the DCO, write the closed-loop characteristic equation in $s$ and identify the natural frequency $\\omega_{n}$ and damping ratio $\\zeta$ in terms of the loop gains. Proceed from first principles by:\n- Mapping $\\frac{z}{z-1}$ to the $s$-domain using the bilinear relation without invoking any shortcut formulas beyond the bilinear definition.\n- Modeling the DCO as a continuous-time integrator $\\frac{K_{v}/N}{s}$, and forming the unity-feedback closed-loop characteristic equation.\n- Matching the polynomial to the standard second-order form $s^{2}+2\\zeta\\omega_{n}s+\\omega_{n}^{2}$, and solving for $\\omega_{n}$ and $\\zeta$ symbolically.\n\nDefine the mapping error as the Euclidean norm of the relative error vector between the achieved $(\\omega_{n},\\zeta)$ and target continuous-time specifications $(\\omega_{n0},\\zeta_{0})$:\n$$E=\\sqrt{\\left(\\frac{\\omega_{n}-\\omega_{n0}}{\\omega_{n0}}\\right)^{2}+\\left(\\frac{\\zeta-\\zeta_{0}}{\\zeta_{0}}\\right)^{2}}.$$\nUse the following numerical values, representative of a multi-gigabit per second clock and data recovery loop:\n- $K_{d}=0.5$,\n- $K_{v}=2\\pi\\times 5\\times 10^{8}$,\n- $N=1$,\n- $T_{u}=1.0\\times 10^{-10}$,\n- $K_{p}=5.0\\times 10^{-3}$,\n- $K_{i}=1.6\\times 10^{-6}$,\n- $\\omega_{n0}=5.0\\times 10^{6}$ (radians per second),\n- $\\zeta_{0}=0.8$.\n\nCompute $E$ and express your final result as a single real number. Round your answer to four significant figures. The mapping error $E$ is dimensionless; no physical units are required for the final answer.",
            "solution": "The discrete-time PI filter is given by $F(z)=K_{p}+K_{i}\\frac{z}{z-1}$. Under the bilinear (Tustin) transform, the relation between $s$ and $z$ is\n$$\ns=\\frac{2}{T_{u}}\\frac{z-1}{z+1}.\n$$\nSolving this for $z$ gives\n$$\n\\frac{sT_{u}}{2}=\\frac{z-1}{z+1}\\quad\\Rightarrow\\quad z-1=\\frac{sT_{u}}{2}(z+1)\\quad\\Rightarrow\\quad z\\left(1-\\frac{sT_{u}}{2}\\right)=1+\\frac{sT_{u}}{2},\n$$\nand hence\n$$\nz=\\frac{1+\\frac{sT_{u}}{2}}{1-\\frac{sT_{u}}{2}}.\n$$\nWe map the discrete integrator term $\\frac{z}{z-1}$ to the $s$-domain using this expression. First compute $z-1$:\n$$\nz-1=\\frac{1+\\frac{sT_{u}}{2}}{1-\\frac{sT_{u}}{2}}-1=\\frac{\\left(1+\\frac{sT_{u}}{2}\\right)-\\left(1-\\frac{sT_{u}}{2}\\right)}{1-\\frac{sT_{u}}{2}}=\\frac{sT_{u}}{1-\\frac{sT_{u}}{2}}.\n$$\nTherefore,\n$$\n\\frac{z}{z-1}=\\frac{\\frac{1+\\frac{sT_{u}}{2}}{1-\\frac{sT_{u}}{2}}}{\\frac{sT_{u}}{1-\\frac{sT_{u}}{2}}}=\\frac{1+\\frac{sT_{u}}{2}}{sT_{u}}.\n$$\nSubstituting back into $F(z)$ yields the equivalent continuous-time loop filter under bilinear mapping:\n$$\nF_{\\mathrm{eq}}(s)=K_{p}+K_{i}\\frac{1+\\frac{sT_{u}}{2}}{sT_{u}}=K_{p}+\\frac{K_{i}}{sT_{u}}+\\frac{K_{i}}{2}.\n$$\nWe can group terms to interpret $F_{\\mathrm{eq}}(s)$ as a continuous-time PI:\n$$\nF_{\\mathrm{eq}}(s)=K_{p}^{\\prime}+\\frac{K_{i}^{\\prime}}{s},\\quad\\text{where}\\quad K_{p}^{\\prime}=K_{p}+\\frac{K_{i}}{2},\\quad K_{i}^{\\prime}=\\frac{K_{i}}{T_{u}}.\n$$\nNext, we form the loop dynamics. The DCO is modeled as an integrator with gain $\\frac{K_{v}}{N}$, thus its transfer function is $\\frac{K_{v}/N}{s}$. The open-loop transfer function from phase error to output phase is\n$$\nL(s)=K_{d}\\,F_{\\mathrm{eq}}(s)\\,\\frac{K_{v}/N}{s}=K_{d}\\left(K_{p}^{\\prime}+\\frac{K_{i}^{\\prime}}{s}\\right)\\frac{K_{v}/N}{s}.\n$$\nUnder unity phase feedback, the closed-loop characteristic equation is\n$$\n1+L(s)=0\\quad\\Rightarrow\\quad 1+K_{d}\\left(K_{p}^{\\prime}+\\frac{K_{i}^{\\prime}}{s}\\right)\\frac{K_{v}/N}{s}=0.\n$$\nMultiplying through by $s^2$ and rearranging to a monic polynomial yields\n$$\ns^2+s\\,K_{d}\\frac{K_{v}}{N}\\left(K_{p}^{\\prime}+\\frac{K_{i}^{\\prime}}{s}\\right) = 0\\quad\\Rightarrow\\quad s^{2}+s\\,K_{d}\\frac{K_{v}}{N}K_{p}^{\\prime}+K_{d}\\frac{K_{v}}{N}K_{i}^{\\prime}=0.\n$$\nComparing to the standard second-order form\n$$\ns^{2}+2\\zeta\\omega_{n}s+\\omega_{n}^{2}=0\n$$\ngives the identifications\n$$\n\\omega_{n}^{2}=K_{d}\\frac{K_{v}}{N}K_{i}^{\\prime}=K_{d}\\frac{K_{v}}{N}\\frac{K_{i}}{T_{u}},\\quad 2\\zeta\\omega_{n}=K_{d}\\frac{K_{v}}{N}K_{p}^{\\prime}=K_{d}\\frac{K_{v}}{N}\\left(K_{p}+\\frac{K_{i}}{2}\\right).\n$$\nSolving for $\\omega_{n}$ and $\\zeta$,\n$$\n\\omega_{n}=\\sqrt{K_{d}\\frac{K_{v}}{N}\\frac{K_{i}}{T_{u}}},\\quad \\zeta=\\frac{K_{d}\\frac{K_{v}}{N}\\left(K_{p}+\\frac{K_{i}}{2}\\right)}{2\\sqrt{K_{d}\\frac{K_{v}}{N}\\frac{K_{i}}{T_{u}}}}.\n$$\nThese are the continuous-time second-order parameters equivalent to the given digital PI filter under bilinear mapping.\n\nWe now compute the numerical values using the provided parameters:\n- $K_{d}=0.5$,\n- $K_{v}=2\\pi\\times 5\\times 10^{8}$,\n- $N=1$,\n- $T_{u}=1.0\\times 10^{-10}$,\n- $K_{p}=5.0\\times 10^{-3}$,\n- $K_{i}=1.6\\times 10^{-6}$,\n- $\\omega_{n0}=5.0\\times 10^{6}$,\n- $\\zeta_{0}=0.8$.\n\nCompute auxiliary quantities:\n$$\nK_{p}^{\\prime}=K_{p}+\\frac{K_{i}}{2}=5.0\\times 10^{-3}+0.8\\times 10^{-6}=5.0008\\times 10^{-3},\n$$\n$$\nK_{i}^{\\prime}=\\frac{K_{i}}{T_{u}}=\\frac{1.6\\times 10^{-6}}{1.0\\times 10^{-10}}=1.6\\times 10^{4},\n$$\nand\n$$\nP=K_{d}\\frac{K_{v}}{N}=0.5\\times \\left(2\\pi\\times 5\\times 10^{8}\\right)=0.5\\times 3.141592653589793\\times 10^{9}=1.5707963267948965\\times 10^{9}.\n$$\nThen\n$$\n\\omega_{n}=\\sqrt{P\\,K_{i}^{\\prime}}=\\sqrt{1.5707963267948965\\times 10^{9}\\times 1.6\\times 10^{4}}=\\sqrt{2.513274122871834\\times 10^{13}}\\approx 5.0132565\\times 10^{6},\n$$\nand\n$$\n\\zeta=\\frac{P\\,K_{p}^{\\prime}}{2\\,\\omega_{n}}=\\frac{1.5707963267948965\\times 10^{9}\\times 5.0008\\times 10^{-3}}{2\\times 5.0132565\\times 10^{6}}\\approx \\frac{7.85523827\\times 10^{6}}{1.00265130\\times 10^{7}}\\approx 0.78345.\n$$\nFinally, compute the mapping error\n$$\nE=\\sqrt{\\left(\\frac{\\omega_{n}-\\omega_{n0}}{\\omega_{n0}}\\right)^{2}+\\left(\\frac{\\zeta-\\zeta_{0}}{\\zeta_{0}}\\right)^{2}}.\n$$\nThe relative errors are\n$$\n\\frac{\\omega_{n}-\\omega_{n0}}{\\omega_{n0}}=\\frac{5.0132565\\times 10^{6}-5.0\\times 10^{6}}{5.0\\times 10^{6}}\\approx 2.6513\\times 10^{-3},\n$$\n$$\n\\frac{\\zeta-\\zeta_{0}}{\\zeta_{0}}=\\frac{0.78345-0.8}{0.8}\\approx -2.0691\\times 10^{-2}.\n$$\nThus\n$$\nE\\approx \\sqrt{\\left(2.6513\\times 10^{-3}\\right)^{2}+\\left(-2.0691\\times 10^{-2}\\right)^{2}}\\approx \\sqrt{7.03\\times 10^{-6}+4.28\\times 10^{-4}}\\approx \\sqrt{4.35\\times 10^{-4}}\\approx 2.086\\times 10^{-2}.\n$$\nRounded to four significant figures, the mapping error is\n$$\nE\\approx 0.02086.\n$$",
            "answer": "$$\\boxed{0.02086}$$"
        },
        {
            "introduction": "In All-Digital Phase-Locked Loops (ADPLLs), the analog phase detector and charge pump are replaced by a Time-to-Digital Converter (TDC), but this block suffers from its own set of manufacturing-induced non-idealities. This hands-on coding practice  challenges you to design a robust statistical calibration algorithm for a TDC. By deriving sample complexity requirements and implementing a noise-aware estimation procedure, you will gain experience with the practical data-driven techniques essential for modern digital and mixed-signal IC design.",
            "id": "4259687",
            "problem": "You are designing a calibration procedure for the Time-to-Digital Converter (TDC) gain in an All-Digital Phase-Locked Loop (ADPLL) within a clock and data recovery architecture. The TDC quantizes a time difference input $ \\tau \\in [0,T_{\\mathrm{ref}}) $ into one of $ N $ integer codes by a set of monotonic thresholds, yielding $ N $ bins with widths $ w_k $ in seconds for $ k \\in \\{0,\\dots,N-1\\} $ that satisfy $ \\sum_{k=0}^{N-1} w_k = T_{\\mathrm{ref}} $. The TDC exhibits differential nonlinearity that causes the $ w_k $ to deviate from the ideal uniform width. An on-chip dithering source excites the TDC input uniformly over $ [0,T_{\\mathrm{ref}}) $, and additive timing noise of zero mean with standard deviation $ \\sigma_t $ perturbs the input. Your task is to formulate and implement a robust histogram-based TDC gain calibration, a sample complexity computation for a target accuracy, and a noise-aware procedure.\n\nStarting from fundamental definitions of probability, quantization, and concentration inequalities, you must:\n\n1. Formulate a histogram-based estimator for the bin widths $ w_k $ and the per-code gain $ g_k \\triangleq 1/w_k $, based on $ M $ independent samples of the quantized codes under a uniform excitation over $ [0,T_{\\mathrm{ref}}) $ in seconds and additive noise with standard deviation $ \\sigma_t $ in seconds. The estimator must be robust to outliers and zero counts under quantization and noise. Your estimator must be expressible in algorithmic form without relying on pre-derived shortcut formulas.\n\n2. Derive a finite-sample requirement $ M_{\\min} $ using a valid concentration inequality and a union bound argument that guarantees, with confidence $ 1-\\alpha $, that the maximum absolute estimation error of all bin widths satisfies $ \\max_k | \\widehat{w}_k - w_k | \\le \\varepsilon_{\\mathrm{abs}} $ in seconds. The derivation must begin from a well-tested inequality for bounded independent random variables as the foundational base and proceed step-by-step to a computable $ M_{\\min} $.\n\n3. Design a robust calibration procedure that, in addition to the histogram estimator, uses a median-of-means strategy across groups of samples and smoothing to handle noise and quantization edge cases while preserving unbiasedness under uniform excitation. Provide a clear rationale for its robustness.\n\nYour program must implement the derived procedure and produce results for the following test suite. For each test case below, you will:\n- Compute $ M_{\\min} $ in samples.\n- Simulate $ M_{\\min} $ samples under the specified conditions, estimate $ \\widehat{w}_k $, and report the achieved maximum absolute error $ \\max_k | \\widehat{w}_k - w_k | $ in seconds.\n- Output a boolean indicating whether the achieved error is less than or equal to the target bound $ \\varepsilon_{\\mathrm{abs}} $.\n\nUse the following test suite parameters:\n- Test Case $ 1 $ (general case): $ N = 64 $, $ T_{\\mathrm{ref}} = 1\\times 10^{-9}\\,\\text{s} $, $ \\sigma_t = 1\\times 10^{-11}\\,\\text{s} $, differential nonlinearity level specified as a dimensionless root-mean-square fraction of the ideal least significant bit $ \\mathrm{DNL}_{\\mathrm{rms}} = 0.05 $, confidence parameter $ \\alpha = 0.01 $, target absolute error $ \\varepsilon_{\\mathrm{abs}} = 1\\times 10^{-11}\\,\\text{s} $.\n- Test Case $ 2 $ (boundary condition with higher mismatch at lower $ N $): $ N = 8 $, $ T_{\\mathrm{ref}} = 5\\times 10^{-10}\\,\\text{s} $, $ \\sigma_t = 5\\times 10^{-11}\\,\\text{s} $, $ \\mathrm{DNL}_{\\mathrm{rms}} = 0.10 $, $ \\alpha = 0.05 $, $ \\varepsilon_{\\mathrm{abs}} = 5\\times 10^{-12}\\,\\text{s} $.\n- Test Case $ 3 $ (edge case with large $ N $): $ N = 256 $, $ T_{\\mathrm{ref}} = 2\\times 10^{-9}\\,\\text{s} $, $ \\sigma_t = 2\\times 10^{-11}\\,\\text{s} $, $ \\mathrm{DNL}_{\\mathrm{rms}} = 0.10 $, $ \\alpha = 0.01 $, $ \\varepsilon_{\\mathrm{abs}} = 2\\times 10^{-11}\\,\\text{s} $.\n\nAngle units are not applicable; all quantities are in seconds or dimensionless.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each of the three test cases, output a list of three elements in the order $ [M_{\\min}, \\mathrm{achieved\\_error\\_in\\_s}, \\mathrm{success}] $, where $ M_{\\min} $ is an integer, $ \\mathrm{achieved\\_error\\_in\\_s} $ is a float in seconds, and $ \\mathrm{success} $ is a boolean. The final program output must thus be a single list of three lists, for example $ [[m_1,e_1,s_1],[m_2,e_2,s_2],[m_3,e_3,s_3]] $ with all numbers and booleans instantiated.",
            "solution": "The problem of calibrating a Time-to-Digital Converter (TDC) gain profile is a problem of statistical estimation. The problem as stated is scientifically grounded, well-posed, and contains sufficient information to formulate a solution. The parameters provided are realistic for contemporary integrated circuit design. We will proceed with a three-part solution, addressing each task laid out in the problem statement.\n\n### 1. Histogram-Based Estimator Formulation\n\nThe core of the calibration procedure is to estimate the width $w_k$ of each of the $N$ quantization bins for $k \\in \\{0, \\dots, N-1\\}$. The TDC operation maps a continuous time input $\\tau \\in [0, T_{\\mathrm{ref}})$ to a discrete code $k$ if $\\tau$ falls within the $k$-th bin.\n\n**Ideal Model and Basic Estimator**\n\nLet us first consider an idealized scenario with a uniform dither signal and no additive noise. The dither source provides an input $\\tau$ that is a random variable uniformly distributed over the interval $[0, T_{\\mathrm{ref}})$. The probability density function (PDF) is $f_{\\tau}(t) = 1/T_{\\mathrm{ref}}$ for $t \\in [0, T_{\\mathrm{ref}})$ and $0$ otherwise. The probability, $p_k$, that the input $\\tau$ falls into the $k$-th bin, which spans the interval $[T_{k-1}, T_k)$ with width $w_k = T_k - T_{k-1}$, is given by:\n$$\np_k = P(\\tau \\in [T_{k-1}, T_k)) = \\int_{T_{k-1}}^{T_k} f_{\\tau}(t) dt = \\int_{T_{k-1}}^{T_k} \\frac{1}{T_{\\mathrm{ref}}} dt = \\frac{w_k}{T_{\\mathrm{ref}}}\n$$\nThis establishes a direct proportionality between the bin width $w_k$ and the probability $p_k$ of observing the code $k$.\n\nTo estimate $p_k$ from data, we collect $M$ independent samples. Let $C_k$ be the number of times the output code is $k$ (the count for bin $k$). The empirical probability is the relative frequency:\n$$\n\\widehat{p}_k = \\frac{C_k}{M}\n$$\nThis is the maximum likelihood estimator for the parameter of a multinomial distribution. Using the relationship $w_k = p_k T_{\\mathrm{ref}}$, we can formulate a simple estimator for the bin width:\n$$\n\\widehat{w}_k = \\widehat{p}_k T_{\\mathrm{ref}} = \\frac{C_k}{M} T_{\\mathrm{ref}}\n$$\nCorrespondingly, the estimator for the per-code gain $g_k = 1/w_k$ is $\\widehat{g}_k = 1/\\widehat{w}_k$.\n\n**Effect of Additive Noise**\n\nThe problem states that the input is perturbed by additive timing noise with zero mean and standard deviation $\\sigma_t$. We assume this noise follows a Gaussian distribution, a standard assumption for aggregated noise sources in physical systems. The actual input to the quantizer is $\\tau' = \\tau + \\delta$, where $\\tau \\sim U(0, T_{\\mathrm{ref}})$ and $\\delta \\sim \\mathcal{N}(0, \\sigma_t^2)$.\n\nThe PDF of $\\tau'$, $f_{\\tau'}(t)$, is the convolution of the uniform and Gaussian PDFs. This PDF is no longer perfectly uniform. However, for regions sufficiently far from the boundaries at $0$ and $T_{\\mathrm{ref}}$, the \"blurring\" effect of the convolution results in a nearly flat PDF. The integral of the noise-convolved PDF over a bin width $w_k$ is still approximately proportional to $w_k$. More formally, the expectation of the count $C_k$ remains $E[C_k] = M p_k$, where $p_k = \\int_{T_{k-1}}^{T_k} f_{\\tau'}(t) dt$. For $\\sigma_t \\ll w_k$ and bins not at the edges of the range, $p_k \\approx w_k/T_{\\mathrm{ref}}$. Therefore, the estimator $\\widehat{w}_k = (C_k/M) T_{\\mathrm{ref}}$ remains approximately unbiased.\n\n**Estimator Robustness Considerations**\n\nThis basic estimator suffers from two main issues. First, if a bin width $w_k$ is very small, it is possible that for a finite number of samples $M$, the count $C_k$ could be zero. This leads to an estimate $\\widehat{w}_k = 0$ and an undefined gain $\\widehat{g}_k$. Second, the estimator is not robust to outliers or burst noise events that might corrupt a segment of the collected data. These limitations motivate the more advanced procedure discussed in part $3$.\n\n### 2. Sample Complexity Derivation\n\nWe seek the minimum number of samples, $M_{\\min}$, required to guarantee that the maximum absolute error across all bin width estimates is bounded by a target value $\\varepsilon_{\\mathrm{abs}}$, with a specified confidence $1-\\alpha$.\n$$\nP\\left(\\max_{k \\in \\{0, \\dots, N-1\\}} |\\widehat{w}_k - w_k| \\le \\varepsilon_{\\mathrm{abs}}\\right) \\ge 1-\\alpha\n$$\nThis can be rewritten in terms of probabilities $\\widehat{p}_k = \\widehat{w}_k/T_{\\mathrm{ref}}$ and $p_k = w_k/T_{\\mathrm{ref}}$:\n$$\nP\\left(\\max_{k} |T_{\\mathrm{ref}}\\widehat{p}_k - T_{\\mathrm{ref}}p_k| \\le \\varepsilon_{\\mathrm{abs}}\\right) = P\\left(\\max_{k} |\\widehat{p}_k - p_k| \\le \\frac{\\varepsilon_{\\mathrm{abs}}}{T_{\\mathrm{ref}}}\\right) \\ge 1-\\alpha\n$$\nLet $\\varepsilon' = \\varepsilon_{\\mathrm{abs}}/T_{\\mathrm{ref}}$. The condition for failure is that for at least one bin $k$, the estimation error exceeds this threshold: $\\max_k |\\widehat{p}_k - p_k|  \\varepsilon'$. We can bound the probability of this event using the **union bound**:\n$$\nP\\left(\\max_{k} |\\widehat{p}_k - p_k|  \\varepsilon'\\right) = P\\left(\\bigcup_{k=0}^{N-1} \\{|\\widehat{p}_k - p_k|  \\varepsilon'\\}\\right) \\le \\sum_{k=0}^{N-1} P\\left(|\\widehat{p}_k - p_k|  \\varepsilon'\\right)\n$$\nWe want this total failure probability to be no more than $\\alpha$. A sufficient condition is to bound the failure probability for each individual bin by $\\alpha/N$:\n$$\n\\forall k: P\\left(|\\widehat{p}_k - p_k|  \\varepsilon'\\right) \\le \\frac{\\alpha}{N}\n$$\nThe estimate $\\widehat{p}_k = C_k/M$ is the sample mean of $M$ independent and identically distributed Bernoulli random variables, each with mean $p_k$. Such a sum is tightly concentrated around its mean. We use **Hoeffding's inequality** for a sum of bounded random variables. For $M$ i.i.d. random variables $X_i$ bounded in $[a,b]$, the inequality states:\n$$\nP\\left(\\left|\\frac{1}{M}\\sum_{i=1}^{M} X_i - E\\left[\\frac{1}{M}\\sum_{i=1}^{M} X_i\\right]\\right| \\ge t\\right) \\le 2e^{-\\frac{2Mt^2}{(b-a)^2}}\n$$\nIn our case, the variables are Bernoulli indicators for bin $k$, which are bounded in $[0, 1]$. Thus, $a=0$, $b=1$, and the sample mean is $\\widehat{p}_k$. Setting $t = \\varepsilon'$, we have:\n$$\nP\\left(|\\widehat{p}_k - p_k| \\ge \\varepsilon'\\right) \\le 2e^{-2M(\\varepsilon')^2}\n$$\nTo satisfy the per-bin error probability bound, we require:\n$$\n2e^{-2M(\\varepsilon')^2} \\le \\frac{\\alpha}{N}\n$$\nWe now solve for $M$:\n$$\ne^{-2M(\\varepsilon')^2} \\le \\frac{\\alpha}{2N}\n$$\n$$\n-2M(\\varepsilon')^2 \\le \\ln\\left(\\frac{\\alpha}{2N}\\right)\n$$\n$$\n2M(\\varepsilon')^2 \\ge -\\ln\\left(\\frac{\\alpha}{2N}\\right) = \\ln\\left(\\frac{2N}{\\alpha}\\right)\n$$\n$$\nM \\ge \\frac{\\ln(2N/\\alpha)}{2(\\varepsilon')^2}\n$$\nSubstituting back $\\varepsilon' = \\varepsilon_{\\mathrm{abs}}/T_{\\mathrm{ref}}$, we obtain the formula for the minimum required number of samples:\n$$\nM_{\\min} = \\left\\lceil \\frac{T_{\\mathrm{ref}}^2 \\ln(2N/\\alpha)}{2\\varepsilon_{\\mathrm{abs}}^2} \\right\\rceil\n$$\nThis derivation begins from a foundational concentration inequality and uses a standard union bound argument, fulfilling the problem requirements.\n\n### 3. Robust Calibration Procedure Design\n\nTo address the shortcomings of the basic estimator, we design a procedure incorporating a median-of-means strategy and a normalization step that acts as a form of global smoothing.\n\n**Rationale for Robustness**\n\n*   **Median-of-Means (MoM):** This technique provides robustness against outliers. By dividing the data into multiple batches and computing an estimate from each, the final estimate is the median of these batch estimates. The median is a robust statistic; it is insensitive to arbitrarily large errors in up to half of the batches. This protects the final estimate from being skewed by transient noise events or other data corruption that might affect a portion of the total samples.\n*   **Normalization:** The estimates $\\widehat{w}_k$ are subject to random statistical error, and their sum $\\sum_k \\widehat{w}_k$ will generally not equal $T_{\\mathrm{ref}}$. Enforcing this physical constraint via normalization, $\\widehat{w}_k^{\\text{final}} = \\widehat{w}_k \\cdot (T_{\\mathrm{ref}} / \\sum_j \\widehat{w}_j)$, is a form of constraint-based smoothing. It adjusts all bin widths by a common factor, preserving their relative proportions while ensuring they are physically consistent. This reduces the total estimation error and improves overall accuracy without introducing the local bias characteristic of moving-average filters.\n\n**Algorithmic Procedure**\n\nGiven the total number of samples $M$ (determined as $M_{\\min}$), a number of bins $N$, and the total time range $T_{\\mathrm{ref}}$:\n\n1.  **Partition Data:** Divide the $M$ collected TDC output codes into $B$ batches of equal size $S = \\lfloor M/B \\rfloor$. A good choice for $B$ is a small odd integer, e.g., $B=11$, to ensure a unique median and sufficient batches for the median to be effective. Let the total samples used be $M_{eff} = S \\times B$.\n\n2.  **Batch-wise Estimation:** For each batch $j \\in \\{1, \\dots, B\\}$:\n    a. Compute a histogram of the $S$ codes in the batch. Let $C_{k,j}$ be the count for bin $k$ in batch $j$.\n    b. Calculate a local estimate of the bin width for each bin $k$:\n       $$\n       \\widehat{w}_{k,j} = \\frac{C_{k,j}}{S} T_{\\mathrm{ref}}\n       $$\n\n3.  **Median Application:** For each bin $k$, assemble the $B$ batch-wise estimates $\\{\\widehat{w}_{k,1}, \\widehat{w}_{k,2}, \\dots, \\widehat{w}_{k,B}\\}$. The median-of-means estimate is then:\n    $$\n    \\widehat{w}_{k}^{\\text{MoM}} = \\text{median}(\\{\\widehat{w}_{k,j}\\}_{j=1}^B)\n    $$\n    With a large batch size $S$, the probability of a zero count for non-zero width bins is very low, making the MoM estimate inherently robust to the zero-count problem for all but pathologically narrow bins.\n\n4.  **Normalization:** Compute the sum of the MoM estimates: $W_{\\text{total}} = \\sum_{k=0}^{N-1} \\widehat{w}_{k}^{\\text{MoM}}$. The final, robustly calibrated bin width estimates are:\n    $$\n    \\widehat{w}_{k} = \\widehat{w}_{k}^{\\text{MoM}} \\cdot \\frac{T_{\\mathrm{ref}}}{W_{\\text{total}}}\n    $$\nThis procedure is robust, algorithmically well-defined, and relies on sound statistical principles to estimate the TDC bin widths accurately in the presence of noise and potential data outliers.",
            "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to run the TDC calibration simulation for all test cases.\n    \"\"\"\n    np.random.seed(0)  # for reproducibility\n\n    test_cases = [\n        # Case 1: General case\n        {\"N\": 64, \"T_ref\": 1e-9, \"sigma_t\": 1e-11, \"DNL_rms\": 0.05, \"alpha\": 0.01, \"eps_abs\": 1e-11},\n        # Case 2: Boundary condition with higher mismatch at lower N\n        {\"N\": 8, \"T_ref\": 5e-10, \"sigma_t\": 5e-11, \"DNL_rms\": 0.10, \"alpha\": 0.05, \"eps_abs\": 5e-12},\n        # Case 3: Edge case with large N and high noise\n        {\"N\": 256, \"T_ref\": 2e-9, \"sigma_t\": 2e-11, \"DNL_rms\": 0.10, \"alpha\": 0.01, \"eps_abs\": 2e-11},\n    ]\n\n    final_results = []\n    for params in test_cases:\n        result = run_test_case(**params)\n        final_results.append(result)\n    \n    # Format the output exactly as specified.\n    # The output should be a list of lists, so we construct the string manually.\n    output_str = \"[\"\n    for i, res in enumerate(final_results):\n        m_min, err, succ = res\n        output_str += f\"[{m_min},{err:.5e},{str(succ).lower()}]\"\n        if i  len(final_results) - 1:\n            output_str += \",\"\n    output_str += \"]\"\n    print(output_str)\n\n\ndef run_test_case(N, T_ref, sigma_t, DNL_rms, alpha, eps_abs):\n    \"\"\"\n    Executes the full simulation and estimation for a single test case.\n    \n    Returns:\n        list: [M_min, achieved_error_in_s, success_boolean]\n    \"\"\"\n    \n    # 1. Derive the finite-sample requirement M_min\n    m_min_float = (T_ref**2 * math.log(2 * N / alpha)) / (2 * eps_abs**2)\n    M_min = math.ceil(m_min_float)\n\n    # 2. Generate true bin widths (w_k) with specified DNL\n    w_ideal = T_ref / N\n    \n    # To achieve the target RMS DNL after mean-centering, scale the initial variance.\n    # Var(d_k) = Var(d'_k - mean(d')) = Var(d'_k) * (N-1)/N\n    # So, Var(d'_k) = TargetVar * N/(N-1)\n    if N  1:\n        initial_sigma_d = DNL_rms * math.sqrt(N / (N - 1))\n    else:\n        initial_sigma_d = DNL_rms\n\n    w_k_true = []\n    while True:\n        dnl_raw = np.random.normal(0, initial_sigma_d, N)\n        dnl_centered = dnl_raw - np.mean(dnl_raw)  # Ensure sum(d_k) = 0\n        w_k_candidate = w_ideal * (1 + dnl_centered)\n        if np.all(w_k_candidate  0):\n            w_k_true = w_k_candidate\n            break\n            \n    # Re-normalize to exactly match T_ref in case of floating point inaccuracies\n    w_k_true = w_k_true * (T_ref / np.sum(w_k_true))\n    \n    # 3. Simulate M_min samples\n    # Generate dithered and noisy input times\n    tau_dither = np.random.uniform(0, T_ref, M_min)\n    noise = np.random.normal(0, sigma_t, M_min)\n    tau_input = tau_dither + noise\n    \n    # Apply modulo behavior for inputs outside [0, T_ref)\n    tau_input_wrapped = np.mod(tau_input, T_ref)\n\n    # 4. Quantize samples to get TDC codes\n    thresholds = np.cumsum(w_k_true)\n    # The last threshold is T_ref, which we don't need in searchsorted.\n    # searchsorted finds the index i where to insert item x to maintain order.\n    # 'right' side means bins are [T_k-1, T_k).\n    tdc_codes = np.searchsorted(thresholds[:-1], tau_input_wrapped, side='right')\n\n    # 5. Apply the robust calibration procedure (Median-of-Means)\n    B = 11  # Number of batches, should be an odd integer\n    if M_min  B:\n        B=1 # Not enough samples for batching\n    S = M_min // B  # Samples per batch\n    M_eff = S * B  # Effective number of samples used\n    \n    if M_eff == 0:\n        # Failsafe for extremely small M_min\n        achieved_error = float('inf')\n        return [M_min, achieved_error, False]\n\n    codes_reshaped = tdc_codes[:M_eff].reshape((B, S))\n    \n    batch_width_estimates = np.zeros((N, B))\n\n    for j in range(B):\n        batch_codes = codes_reshaped[j, :]\n        counts = np.bincount(batch_codes, minlength=N)\n        batch_width_estimates[:, j] = (counts / S) * T_ref\n        \n    w_k_mom = np.median(batch_width_estimates, axis=1)\n    \n    # Handle case where all estimates for a bin are zero - sum is zero\n    sum_w_k_mom = np.sum(w_k_mom)\n    if sum_w_k_mom  0:\n        w_k_estimated = w_k_mom * (T_ref / sum_w_k_mom)\n    else: # All estimates were zero, a failure case\n        w_k_estimated = w_k_mom\n\n    # 6. Compute final error and success metric\n    achieved_error = np.max(np.abs(w_k_estimated - w_k_true))\n    success = achieved_error = eps_abs\n    \n    return [M_min, achieved_error, success]\n\n\nif __name__ == '__main__':\n    solve()\n\n```"
        }
    ]
}