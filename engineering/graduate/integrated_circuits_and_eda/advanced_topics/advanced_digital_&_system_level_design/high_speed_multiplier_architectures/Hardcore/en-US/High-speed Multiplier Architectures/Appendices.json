{
    "hands_on_practices": [
        {
            "introduction": "The power of high-speed multipliers stems from avoiding slow carry propagation. Carry-save arithmetic is the key, where sums and carries are kept separate. This first practice  challenges you to design and analyze the most common operation within a compressor tree: the reduction of four input bits in a column back into a carry-save format, a process known as 4:2 compression. Mastering this building block is essential for understanding the delay and structure of the entire multiplier.",
            "id": "4275921",
            "problem": "Consider two carry-save encoded unsigned $n$-bit integers, represented as pairs $(S_{1}, C_{1})$ and $(S_{2}, C_{2})$, where each pair denotes the integer $N = \\sum_{i=0}^{n-1} S[i] 2^{i} + \\sum_{i=0}^{n-1} C[i] 2^{i+1}$. The task is to accumulate these two carry-save pairs into a single carry-save result $(S_{\\mathrm{out}}, C_{\\mathrm{out}})$ using only $3{:}2$ compressors. A $3{:}2$ compressor is a full adder that maps three input bits of equal weight to a sum bit of the same weight and a carry bit of the next higher weight. The network is purely combinational and is organized in levels; a carry output produced at a given level cannot be consumed by any compressor within the same level. The depth of the network is defined as the number of such compressor levels from inputs to outputs.\n\nAssume $n \\geq 2$, no sign extension, and that the boundary columns outside the range $[0, n]$ contain zeros. Design a minimal-depth network that reduces the initial per-column bit-heights arising from $(S_{1}, C_{1})$ and $(S_{2}, C_{2})$ to at most two bits per column everywhere (thereby yielding a single carry-save pair), under the constraint that only $3{:}2$ compressors are permitted. Then, calculate the minimal possible depth as a function of $n$.\n\nProvide the final minimal depth as an exact integer. No rounding is required and no physical units are involved. Your answer must be a single number.",
            "solution": "The problem requires finding the minimal depth of a combinational network composed of $3{:}2$ compressors to add two carry-save encoded numbers, $(S_1, C_1)$ and $(S_2, C_2)$, and produce a single carry-save result, $(S_{\\mathrm{out}}, C_{\\mathrm{out}})$. The depth is defined as the number of levels of compressors. A carry-save result is one where each bit-column has a height of at most $2$.\n\nFirst, we must determine the initial number of bits, or \"height,\" in each columnar position. The value of a carry-save number $(S, C)$ is given by $N = \\sum_{i=0}^{n-1} S[i] 2^{i} + \\sum_{i=0}^{n-1} C[i] 2^{i+1}$. This means that for each position $i$, we have a sum bit $S[i]$ at weight $2^i$ and a carry bit $C[i]$ at weight $2^{i+1}$. The latter is equivalent to a bit $C[i]$ from position $i$ being shifted to position $i+1$.\n\nWe are tasked with computing the sum of two such numbers, $N_1$ and $N_2$:\n$N_1 + N_2 = \\left(\\sum_{i=0}^{n-1} S_1[i] 2^{i} + \\sum_{i=0}^{n-1} C_1[i] 2^{i+1}\\right) + \\left(\\sum_{i=0}^{n-1} S_2[i] 2^{i} + \\sum_{i=0}^{n-1} C_2[i] 2^{i+1}\\right)$\nLet's analyze the height of each column $k$, which corresponds to bits with weight $2^k$. We denote this initial height as $h_k^{(1)}$.\n- For column $k=0$: The contributors are $S_1[0]$ and $S_2[0]$. Thus, $h_0^{(1)} = 2$.\n- For columns $1 \\le k \\le n-1$: The contributors are $S_1[k]$, $S_2[k]$ (from the sum terms) and $C_1[k-1]$, $C_2[k-1]$ (from the carry terms, which are shifted from column $k-1$). Thus, $h_k^{(1)} = 4$.\n- For column $k=n$: The contributors are $C_1[n-1]$ and $C_2[n-1]$. Thus, $h_n^{(1)} = 2$.\n- For columns $k > n$: The boundary conditions state these columns contain zeros, so $h_k^{(1)} = 0$.\n\nThe initial height profile before the first level of compression is:\n$h_k^{(1)} = \\begin{cases} 2  \\text{if } k=0 \\text{ or } k=n \\\\ 4  \\text{if } 1 \\le k \\le n-1 \\\\ 0  \\text{otherwise} \\end{cases}$\n\nA $3{:}2$ compressor, or full adder, takes $3$ bits of weight $2^k$ and outputs $1$ sum bit of weight $2^k$ and $1$ carry bit of weight $2^{k+1}$. The constraint that a carry cannot be used in the same level means we can model the reduction process in discrete levels.\nLet $h_k^{(L)}$ be the height of column $k$ at the input of level $L$.\nThe number of compressors used in column $k$ at level $L$ is $c_k^{(L)} = \\lfloor h_k^{(L)}/3 \\rfloor$.\nThese compressors produce $c_k^{(L)}$ sum bits, which remain in column $k$, and $c_k^{(L)}$ carry bits, which move to column $k+1$. The number of uncompressed bits in column $k$ is $h_k^{(L)} \\pmod 3$.\nThe number of bits in column $k$ that are passed to the next level is $s_k^{(L)} = (h_k^{(L)} \\pmod 3) + c_k^{(L)}$.\nThe height of column $k$ at the input of the next level, $L+1$, is the sum of bits passed from column $k$ and carries generated in column $k-1$:\n$h_k^{(L+1)} = s_k^{(L)} + c_{k-1}^{(L)}$\n\nLet's apply this process, starting with $L=1$.\n**Level 1 Compression:**\nFirst, we calculate the number of carries $c_k^{(1)}$ and remaining sum bits $s_k^{(1)}$ from the initial heights $h_k^{(1)}$.\n$c_k^{(1)} = \\lfloor h_k^{(1)}/3 \\rfloor = \\begin{cases} 1  \\text{if } 1 \\le k \\le n-1 \\\\ 0  \\text{otherwise} \\end{cases}$\n$s_k^{(1)} = (h_k^{(1)} \\pmod 3) + c_k^{(1)} = \\begin{cases} (2 \\pmod 3) + 0 = 2  \\text{if } k=0 \\text{ or } k=n \\\\ (4 \\pmod 3) + 1 = 2  \\text{if } 1 \\le k \\le n-1 \\\\ 0  \\text{otherwise} \\end{cases}$\n\nNow, we compute the height profile for the input to Level 2, $h_k^{(2)}$.\n$h_k^{(2)} = s_k^{(1)} + c_{k-1}^{(1)}$\n- $h_0^{(2)} = s_0^{(1)} + c_{-1}^{(1)} = 2 + 0 = 2$\n- $h_1^{(2)} = s_1^{(1)} + c_0^{(1)} = 2 + 0 = 2$\n- For $2 \\le k \\le n-1$: $h_k^{(2)} = s_k^{(1)} + c_{k-1}^{(1)} = 2 + 1 = 3$. This holds for $n \\ge 3$. If $n=2$, this range is empty.\n- $h_n^{(2)} = s_n^{(1)} + c_{n-1}^{(1)} = 2 + 1 = 3$.\n- $h_{n+1}^{(2)} = s_{n+1}^{(1)} + c_{n}^{(1)} = 0 + 0 = 0$.\n\nThe height profile at the input of Level 2, $h_k^{(2)}$, is:\n$h_k^{(2)} = \\begin{cases} 2  \\text{if } k=0, 1 \\\\ 3  \\text{if } 2 \\le k \\le n \\\\ 0  \\text{otherwise} \\end{cases}$\nThis is valid for all $n \\ge 2$. For $n=2$, the range $2 \\le k \\le n$ is just $k=2$, so $h_k^{(2)}$ is $\\{2, 2, 3, 0, \\ldots\\}$.\nSince $\\max(h_k^{(2)}) = 3$, which is greater than $2$, the reduction is not complete. At least one more level is required. Thus, the minimal depth is greater than $1$.\n\n**Level 2 Compression:**\nWe now reduce the height profile $h_k^{(2)}$.\n$c_k^{(2)} = \\lfloor h_k^{(2)}/3 \\rfloor = \\begin{cases} 1  \\text{if } 2 \\le k \\le n \\\\ 0  \\text{otherwise} \\end{cases}$\n$s_k^{(2)} = (h_k^{(2)} \\pmod 3) + c_k^{(2)} = \\begin{cases} 2  \\text{if } k=0, 1 \\\\ 1  \\text{if } 2 \\le k \\le n \\\\ 0  \\text{otherwise} \\end{cases}$\n\nNow, we compute the height profile for the input to Level 3, $h_k^{(3)}$.\n$h_k^{(3)} = s_k^{(2)} + c_{k-1}^{(2)}$\n- $h_0^{(3)} = s_0^{(2)} + c_{-1}^{(2)} = 2 + 0 = 2$\n- $h_1^{(3)} = s_1^{(2)} + c_0^{(2)} = 2 + 0 = 2$\n- $h_2^{(3)} = s_2^{(2)} + c_1^{(2)} = 1 + 0 = 1$\n- For $3 \\le k \\le n$: $h_k^{(3)} = s_k^{(2)} + c_{k-1}^{(2)} = 1 + 1 = 2$. This range is non-empty for $n \\ge 3$.\n- $h_{n+1}^{(3)} = s_{n+1}^{(2)} + c_n^{(2)} = 0 + 1 = 1$.\n- For $k \\ge n+2$: $h_k^{(3)} = s_k^{(2)} + c_{k-1}^{(2)} = 0 + 0 = 0$.\n\nThe resulting height profile after Level 2, $h_k^{(3)}$, is:\n$h_k^{(3)} = \\begin{cases} 2  \\text{if } k=0, 1 \\\\ 1  \\text{if } k=2 \\\\ 2  \\text{if } 3 \\le k \\le n \\\\ 1  \\text{if } k=n+1 \\\\ 0  \\text{otherwise} \\end{cases}$\nFor all values of $k$, $h_k^{(3)} \\le 2$. This means the output is in carry-save format, and no further compression is needed.\n\nSince one level of compression is insufficient and two levels are sufficient, the minimal depth of the network is $2$. This result holds for any $n \\ge 2$.",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "Once we understand the basic compression cells, the next step is to organize them into an efficient reduction tree. This exercise  dives into the architectural trade-offs by comparing two seminal approaches: the Wallace scheme, which aggressively reduces column heights for maximum speed, and the Dadda scheme, which uses the minimum necessary hardware at each stage. By synthesizing a reduction level for both, you will gain a concrete appreciation for their distinct design philosophies and resulting hardware costs.",
            "id": "4275975",
            "problem": "Consider a signed multiplication unit implementing a $24 \\times 24$ bit product using a parallel partial product array and a compression tree in the context of high-speed multiplier architectures for integrated circuits and Electronic Design Automation (EDA). The partial product columns are indexed by $k \\in \\{0,1,\\dots,46\\}$, with column-height profile given by $h_k = \\min(k+1, 47-k)$, corresponding to the triangular distribution of partial products for a square multiplier.\n\nTwo column compression strategies are considered for the first reduction level:\n- A Wallace approach that greedily applies $3{:}2$ compressors (full adders) within each column as much as possible in the first level, without using any $2{:}1$ compressors (half adders) in that level. The $3{:}2$ compressor maps three input bits in the same column into one sum bit in the same column and one carry bit in the next more significant column.\n- A Dadda approach that computes the first-stage maximum column height bound $d$ using the Dadda sequence and then minimally applies $3{:}2$ and $2{:}1$ compressors to ensure that, after this first level, the height in every column does not exceed $d$. In the Dadda reduction, a $3{:}2$ compressor reduces the current-column height by $2$ and produces one carry to the next column, while a $2{:}1$ compressor reduces the current-column height by $1$ and produces one carry to the next column. Carries produced within the level must be accounted for sequentially from the least significant column to the most significant column when determining how many compressors are needed in each column.\n\nSynthesize exactly one reduction level under each approach and compute the total number of $3{:}2$ and $2{:}1$ reductions required in that level. Express the final answer as four numbers in a single row matrix, ordered as $\\left(N_{3{:}2}^{\\text{Wallace}}, N_{2{:}1}^{\\text{Wallace}}, N_{3{:}2}^{\\text{Dadda}}, N_{2{:}1}^{\\text{Dadda}}\\right)$. No rounding is required. No units are required.",
            "solution": "The problem requires the calculation of the number of $3{:}2$ and $2{:}1$ compressors used in the first reduction level for a $24 \\times 24$ multiplier, according to two different strategies: a Wallace-like approach and a Dadda approach.\n\nThe initial column-height profile of the partial product array is given by $h_k = \\min(k+1, 47-k)$ for column indices $k \\in \\{0, 1, \\dots, 46\\}$. The maximum height of this array occurs at $k=23$, where $h_{23} = \\min(23+1, 47-23) = 24$.\n\nA $3{:}2$ compressor (full adder) takes $3$ input bits from a column $k$, and produces one sum bit in column $k$ and one carry bit in column $k+1$. This reduces the height of column $k$ by $2$ and increases the height of column $k+1$ by $1$.\nA $2{:}1$ compressor (half adder) takes $2$ input bits from a column $k$, and produces one sum bit in column $k$ and one carry bit in column $k+1$. This reduces the height of column $k$ by $1$ and increases the height of column $k+1$ by $1$.\n\nFirst, we analyze the Wallace approach.\nThe Wallace strategy specified is to greedily apply $3{:}2$ compressors in each column to achieve maximum reduction in a single level, without using any $2{:}1$ compressors in that level.\nFor a column $k$ with initial height $h_k$, the number of $3{:}2$ compressors that can be applied is $n_{3{:}2, k}^{\\text{Wallace}} = \\lfloor h_k / 3 \\rfloor$.\nThe problem states that no $2{:}1$ compressors are used, so $N_{2{:}1}^{\\text{Wallace}} = 0$.\nThe total number of $3{:}2$ compressors, $N_{3{:}2}^{\\text{Wallace}}$, is the sum over all columns:\n$$N_{3{:}2}^{\\text{Wallace}} = \\sum_{k=0}^{46} n_{3{:}2, k}^{\\text{Wallace}} = \\sum_{k=0}^{46} \\left\\lfloor \\frac{h_k}{3} \\right\\rfloor$$\nThe height profile $h_k$ is symmetric. We can split the sum:\n$$N_{3{:}2}^{\\text{Wallace}} = \\sum_{k=0}^{23} \\left\\lfloor \\frac{k+1}{3} \\right\\rfloor + \\sum_{k=24}^{46} \\left\\lfloor \\frac{47-k}{3} \\right\\rfloor$$\nLet $j=k+1$ in the first sum. When $k=0, j=1$; when $k=23, j=24$. The sum becomes $\\sum_{j=1}^{24} \\lfloor j/3 \\rfloor$.\nThis sum can be computed as $3 \\times (1+2+3+4+5+6+7) + 8 = 3 \\times 28 + 8 = 84 + 8 = 92$.\nLet $j=47-k$ in the second sum. When $k=24, j=23$; when $k=46, j=1$. The sum becomes $\\sum_{j=1}^{23} \\lfloor j/3 \\rfloor$.\nThis sum is $3 \\times (1+2+3+4+5+6+7) = 3 \\times 28 = 84$.\nTherefore, the total number of $3{:}2$ compressors is:\n$$N_{3{:}2}^{\\text{Wallace}} = 92 + 84 = 176$$\nThe number of $2{:}1$ compressors is:\n$$N_{2{:}1}^{\\text{Wallace}} = 0$$\n\nNext, we analyze the Dadda approach.\nThe Dadda strategy requires reducing the column heights to not exceed a specific value $d$, determined by the Dadda sequence. The sequence is defined by $d_0 = 2$ and $d_{j+1} = \\lfloor 1.5 d_j \\rfloor$.\nThe sequence is $d_0=2$, $d_1=3$, $d_2=4$, $d_3=6$, $d_4=9$, $d_5=13$, $d_6=19$, $d_7=28$, ...\nThe maximum initial height is $h_{\\max} = 24$. The first-stage height limit $d$ is the largest member of the Dadda sequence that is less than $h_{\\max}$. Thus, we have $d=19$.\nThe goal is to minimally apply compressors such that for each column $k$, the final height after reduction is at most $19$. The process is performed sequentially from the least significant column ($k=0$) to the most significant ($k=46$), accounting for carries generated from the previous column.\nLet $h_k$ be the initial height of column $k$, and $c_k$ be the number of carry-in bits from column $k-1$. The total height to be considered for column $k$ is $H_k = h_k + c_k$.\nIf $H_k > 19$, we must apply compressors. To do this minimally, we use $n_{3{:}2,k}$ full adders and $n_{2{:}1,k}$ half adders, where $n_{3{:}2,k} = \\lfloor (H_k - 19)/2 \\rfloor$ and $n_{2{:}1,k} = (H_k - 19) \\pmod 2$. The number of carries generated to column $k+1$ is $c_{k+1} = n_{3{:}2,k} + n_{2{:}1,k}$.\n\nWe now proceed with the column-by-column calculation, starting with $c_0=0$.\nFor $k \\in \\{0, \\dots, 18\\}$, $h_k = k+1 \\le 19$. Since $c_k=0$ for these columns, $H_k \\le 19$. No reduction is needed. $n_{3{:}2,k}=0, n_{2{:}1,k}=0, c_{k+1}=0$.\nFor $k=19$: $h_{19}=20, c_{19}=0 \\implies H_{19}=20$. $H_{19}-19 = 1$. $n_{3{:}2,19}=\\lfloor 1/2 \\rfloor = 0$, $n_{2{:}1,19}=1 \\pmod 2 = 1$. $c_{20}=0+1=1$.\nFor $k=20$: $h_{20}=21, c_{20}=1 \\implies H_{20}=22$. $H_{20}-19 = 3$. $n_{3{:}2,20}=\\lfloor 3/2 \\rfloor = 1$, $n_{2{:}1,20}=3 \\pmod 2 = 1$. $c_{21}=1+1=2$.\nFor $k=21$: $h_{21}=22, c_{21}=2 \\implies H_{21}=24$. $H_{21}-19 = 5$. $n_{3{:}2,21}=\\lfloor 5/2 \\rfloor = 2$, $n_{2{:}1,21}=5 \\pmod 2 = 1$. $c_{22}=2+1=3$.\nFor $k=22$: $h_{22}=23, c_{22}=3 \\implies H_{22}=26$. $H_{22}-19 = 7$. $n_{3{:}2,22}=\\lfloor 7/2 \\rfloor = 3$, $n_{2{:}1,22}=7 \\pmod 2 = 1$. $c_{23}=3+1=4$.\nFor $k=23$: $h_{23}=24, c_{23}=4 \\implies H_{23}=28$. $H_{23}-19 = 9$. $n_{3{:}2,23}=\\lfloor 9/2 \\rfloor = 4$, $n_{2{:}1,23}=9 \\pmod 2 = 1$. $c_{24}=4+1=5$.\nFor $k=24$: $h_{24}=23, c_{24}=5 \\implies H_{24}=28$. $H_{24}-19 = 9$. $n_{3{:}2,24}=\\lfloor 9/2 \\rfloor = 4$, $n_{2{:}1,24}=9 \\pmod 2 = 1$. $c_{25}=4+1=5$.\nFor $k=25$: $h_{25}=22, c_{25}=5 \\implies H_{25}=27$. $H_{25}-19 = 8$. $n_{3{:}2,25}=\\lfloor 8/2 \\rfloor = 4$, $n_{2{:}1,25}=8 \\pmod 2 = 0$. $c_{26}=4+0=4$.\nFor $k=26$: $h_{26}=21, c_{26}=4 \\implies H_{26}=25$. $H_{26}-19 = 6$. $n_{3{:}2,26}=\\lfloor 6/2 \\rfloor = 3$, $n_{2{:}1,26}=6 \\pmod 2 = 0$. $c_{27}=3+0=3$.\nFor $k=27$: $h_{27}=20, c_{27}=3 \\implies H_{27}=23$. $H_{27}-19 = 4$. $n_{3{:}2,27}=\\lfloor 4/2 \\rfloor = 2$, $n_{2{:}1,27}=4 \\pmod 2 = 0$. $c_{28}=2+0=2$.\nFor $k=28$: $h_{28}=19, c_{28}=2 \\implies H_{28}=21$. $H_{28}-19 = 2$. $n_{3{:}2,28}=\\lfloor 2/2 \\rfloor = 1$, $n_{2{:}1,28}=2 \\pmod 2 = 0$. $c_{29}=1+0=1$.\nFor $k=29$: $h_{29}=18, c_{29}=1 \\implies H_{29}=19$. Since $H_{29} \\le 19$, no reduction is needed. $n_{3{:}2,29}=0, n_{2{:}1,29}=0, c_{30}=0$.\nFor all subsequent columns $k29$, $h_k  19$ and $c_k = 0$, so no further reductions occur in this stage.\n\nTotal compressors for the Dadda approach:\n$N_{3{:}2}^{\\text{Dadda}} = \\sum_{k=0}^{46} n_{3{:}2,k} = 0+1+2+3+4+4+4+3+2+1 = 24$.\n$N_{2{:}1}^{\\text{Dadda}} = \\sum_{k=0}^{46} n_{2{:}1,k} = 1+1+1+1+1+1+0+0+0+0 = 6$.\n\nThe four required numbers are $\\left(N_{3{:}2}^{\\text{Wallace}}, N_{2{:}1}^{\\text{Wallace}}, N_{3{:}2}^{\\text{Dadda}}, N_{2{:}1}^{\\text`Dadda`}\\right)$.\n$N_{3{:}2}^{\\text{Wallace}} = 176$.\n$N_{2{:}1}^{\\text{Wallace}} = 0$.\n$N_{3{:}2}^{\\text`Dadda`} = 24$.\n$N_{2{:}1}^{\\text`Dadda`} = 6$.\nThe result is $(176, 0, 24, 6)$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 176  0  24  6 \\end{pmatrix}}$$"
        },
        {
            "introduction": "A multiplier's output is often wider than the datapath of the surrounding system, necessitating truncation or rounding. This final practice  addresses this critical, real-world issue by examining the errors introduced when a full-precision product is shortened. You will quantitatively analyze the statistical properties of different schemes, from simple truncation to more sophisticated rounding methods, learning how to manage the trade-off between hardware complexity and numerical accuracy.",
            "id": "4275952",
            "problem": "Consider an unsigned $32 \\times 32$ parallel multiplier implemented using a high-speed partial-product compression network (for example, a Wallace tree), producing an exact $64$-bit product $P$. To reduce critical-path delay and power, the design truncates the $k=8$ least significant bits (LSBs) of the product prior to the final carry-propagate adder, delivering a $56$-bit truncated product. The error due to truncation is defined as $e = \\hat{P} - P$, where $\\hat{P}$ is the delivered (approximate) product. Assume operands are uniformly distributed over their $32$-bit range so that the discarded remainder is well modeled as uniformly distributed and independent of the retained bits.\n\nAnalyze three schemes:\n- Pure truncation: no correction.\n- Bias compensation: add a constant offset equal to half of the truncation quantum before truncation.\n- Unbiased rounding-to-nearest with ties to even: resolve the half-quantum boundary so the expected error at ties is zero.\n\nUse the following definitions of error metrics over the ensemble of discarded $8$-bit remainders:\n- Mean error $\\mu = \\mathbb{E}[e]$.\n- Mean absolute error $\\eta = \\mathbb{E}[|e|]$.\n- Worst-case error magnitude $\\epsilon_{\\max} = \\max |e|$.\n\nModel the $64$-bit exact product as $P = 256 M + d$ where $M \\in \\mathbb{Z}$ is the retained $56$-bit part and $d \\in \\{0,1,\\dots,255\\}$ is the discarded remainder. For bias compensation, add the constant $C = 128$ in the pre-truncation path. For unbiased rounding with ties to even, assume that parity of $M$ is equally likely so that the tie case contributes zero mean error.\n\nCompute $\\mu$, $\\eta$, and $\\epsilon_{\\max}$ for each scheme as exact values in integer units of the original product (i.e., counts of the least significant bit of $P$). Express your final answer as nine numbers in the order: pure truncation $(\\mu, \\eta, \\epsilon_{\\max})$, bias compensation $(\\mu, \\eta, \\epsilon_{\\max})$, unbiased rounding $(\\mu, \\eta, \\epsilon_{\\max})$. No rounding is required.",
            "solution": "The problem requires an analysis of the error characteristics of three different fixed-point product truncation schemes. The exact $64$-bit product $P$ is modeled as $P = 256M + d$, where $M$ is the upper $56$-bit part to be retained, and $d$ is the lower $8$-bit remainder to be discarded. The value of $d$ is an integer in the set $\\{0, 1, 2, \\dots, 255\\}$. Based on the problem statement, we model $d$ as a discrete random variable uniformly distributed over this set. The probability mass function is $p(d) = \\frac{1}{256}$ for any $d$ in its domain. The error is defined as $e = \\hat{P} - P$, where $\\hat{P}$ is the approximate, truncated product. All error metrics are calculated in units of the least significant bit (LSB) of the original product $P$, which has a weight of $1$.\n\nThe expectation of any function $f(d)$ of the remainder is given by the sum over all possible values of $d$:\n$$ \\mathbb{E}[f(d)] = \\sum_{d=0}^{255} f(d) p(d) = \\frac{1}{256} \\sum_{d=0}^{255} f(d) $$\nWe will make use of the formula for the sum of the first $n$ integers: $\\sum_{i=1}^{n} i = \\frac{n(n+1)}{2}$. The sum of the possible remainder values is:\n$$ \\sum_{d=0}^{255} d = \\frac{255(255+1)}{2} = \\frac{255 \\times 256}{2} = 32640 $$\n\nWe analyze each scheme in turn to find the mean error $\\mu = \\mathbb{E}[e]$, mean absolute error $\\eta = \\mathbb{E}[|e|]$, and worst-case error magnitude $\\epsilon_{\\max} = \\max|e|$.\n\n**Scheme 1: Pure Truncation**\nIn pure truncation, the $8$ LSBs are simply discarded. This is equivalent to taking the floor of the product divided by $2^8 = 256$. The retained part is $M$.\nThe approximate product is $\\hat{P} = 256M$.\nThe error $e$ is therefore:\n$$ e = \\hat{P} - P = 256M - (256M + d) = -d $$\nWe can now compute the error metrics:\n- **Mean Error ($\\mu_1$)**:\n$$ \\mu_1 = \\mathbb{E}[e] = \\mathbb{E}[-d] = -\\mathbb{E}[d] = -\\frac{1}{256} \\sum_{d=0}^{255} d = -\\frac{32640}{256} = -127.5 $$\n- **Mean Absolute Error ($\\eta_1$)**: Since $d \\ge 0$, $|e| = |-d| = d$.\n$$ \\eta_1 = \\mathbb{E}[|e|] = \\mathbb{E}[d] = \\frac{1}{256} \\sum_{d=0}^{255} d = 127.5 $$\n- **Worst-case Error Magnitude ($\\epsilon_{\\max, 1}$)**:\n$$ \\epsilon_{\\max, 1} = \\max_{d \\in \\{0, \\dots, 255\\}} |e| = \\max_{d} |-d| = \\max_{d} d = 255 $$\n\n**Scheme 2: Bias Compensation**\nA constant offset $C=128$ is added to the product before truncation. The value to be processed is $P' = P + 128 = 256M + d + 128$.\nThe approximate product is $\\hat{P} = 256 \\times \\lfloor \\frac{P'}{256} \\rfloor = 256 \\times \\lfloor \\frac{256M + d + 128}{256} \\rfloor = 256 \\times \\lfloor M + \\frac{d+128}{256} \\rfloor$.\nThe floor function's behavior depends on $d$:\n- If $0 \\le d \\le 127$, then $0.5 \\le \\frac{d+128}{256}  1$. Thus, $\\lfloor M + \\frac{d+128}{256} \\rfloor = M$.\n  $\\hat{P} = 256M$, and the error is $e = 256M - (256M+d) = -d$.\n- If $128 \\le d \\le 255$, then $1 \\le \\frac{d+128}{256}  1.5$. Thus, $\\lfloor M + \\frac{d+128}{256} \\rfloor = M+1$.\n  $\\hat{P} = 256(M+1)$, and the error is $e = 256(M+1) - (256M+d) = 256-d$.\nWe compute the metrics by summing over these two ranges for $d$:\n- **Mean Error ($\\mu_2$)**:\n$$ \\mu_2 = \\frac{1}{256} \\left( \\sum_{d=0}^{127} (-d) + \\sum_{d=128}^{255} (256-d) \\right) $$\nThe first sum is $\\sum_{d=0}^{127} (-d) = -\\frac{127 \\times 128}{2} = -8128$.\nLet $j=256-d$. For the second sum, as $d$ goes from $128$ to $255$, $j$ goes from $128$ to $1$. So $\\sum_{d=128}^{255} (256-d) = \\sum_{j=1}^{128} j = \\frac{128 \\times 129}{2} = 8256$.\n$$ \\mu_2 = \\frac{1}{256} (-8128 + 8256) = \\frac{128}{256} = 0.5 $$\n- **Mean Absolute Error ($\\eta_2$)**:\n$$ \\eta_2 = \\frac{1}{256} \\left( \\sum_{d=0}^{127} |-d| + \\sum_{d=128}^{255} |256-d| \\right) = \\frac{1}{256} \\left( \\sum_{d=0}^{127} d + \\sum_{d=128}^{255} (256-d) \\right) $$\nThe first sum is $\\frac{127 \\times 128}{2} = 8128$. The second sum is $8256$.\n$$ \\eta_2 = \\frac{1}{256} (8128 + 8256) = \\frac{16384}{256} = 64 $$\n- **Worst-case Error Magnitude ($\\epsilon_{\\max, 2}$)**:\nThe magnitude of the error is $|e|=d$ for $d \\in \\{0, \\dots, 127\\}$, whose maximum is $127$.\nThe magnitude is $|e|=256-d$ for $d \\in \\{128, \\dots, 255\\}$, whose maximum is $256-128 = 128$.\n$$ \\epsilon_{\\max, 2} = \\max(127, 128) = 128 $$\n\n**Scheme 3: Unbiased Rounding-to-Nearest with Ties to Even**\nThis scheme rounds $P/256 = M + d/256$ to the nearest integer, with a special rule for ties.\n- If $d/256  0.5$ (i.e., $0 \\le d \\le 127$), we round down. $\\hat{P} = 256M$, so $e = -d$.\n- If $d/256  0.5$ (i.e., $129 \\le d \\le 255$), we round up. $\\hat{P} = 256(M+1)$, so $e = 256-d$.\n- If $d/256 = 0.5$ (i.e., $d=128$), it's a tie. We round to the nearest even integer.\n  - If $M$ is even, we round down to $M$. $\\hat{P}=256M$, so $e = -128$.\n  - If $M$ is odd, we round up to $M+1$. $\\hat{P}=256(M+1)$, so $e = 256-128 = 128$.\nWe are given that $M$ is equally likely to be even or odd, so $P(M \\text{ is even}) = P(M \\text{ is odd}) = 0.5$.\n- **Mean Error ($\\mu_3$)**: The error now depends on $M$ for the case $d=128$. We compute the expectation over both $d$ and $M$.\n$$ \\mu_3 = \\mathbb{E}_{d,M}[e] = \\frac{1}{256} \\left( \\sum_{d=0, d \\neq 128}^{255} e(d) + \\mathbb{E}_M[e(d=128, M)] \\right) $$\n$\\mathbb{E}_M[e(d=128, M)] = (-128) P(M \\text{ is even}) + (128) P(M \\text{ is odd}) = -128(0.5) + 128(0.5) = 0$.\nThe sum is $\\sum_{d=0}^{127} (-d) + \\sum_{d=129}^{255} (256-d)$.\nThe first part is $-8128$. For the second part, let $j=256-d$. As $d$ goes from $129$ to $255$, $j$ goes from $127$ to $1$. So $\\sum_{j=1}^{127} j = \\frac{127 \\times 128}{2} = 8128$.\n$$ \\mu_3 = \\frac{1}{256} (-8128 + 0 + 8128) = 0 $$\n- **Mean Absolute Error ($\\eta_3$)**:\n$$ \\eta_3 = \\frac{1}{256} \\left( \\sum_{d=0, d \\neq 128}^{255} |e(d)| + \\mathbb{E}_M[|e(d=128, M)|] \\right) $$\n$\\mathbb{E}_M[|e(d=128, M)|] = |-128| P(M \\text{ is even}) + |128| P(M \\text{ is odd}) = 128(0.5) + 128(0.5) = 128$.\nThe sum is $\\sum_{d=0}^{127} d + \\sum_{d=129}^{255} (256-d) = 8128 + 8128 = 16256$.\n$$ \\eta_3 = \\frac{1}{256} (16256 + 128) = \\frac{16384}{256} = 64 $$\n- **Worst-case Error Magnitude ($\\epsilon_{\\max, 3}$)**:\nThe error magnitudes are $|e|=d$ for $d \\in \\{0, \\dots, 127\\}$ (max $127$), $|e|=256-d$ for $d \\in \\{129, \\dots, 255\\}$ (max $127$), and $|e|=128$ for $d=128$.\n$$ \\epsilon_{\\max, 3} = \\max(127, 128) = 128 $$\n\nSummary of results:\n- Pure truncation: $(\\mu_1, \\eta_1, \\epsilon_{\\max, 1}) = (-127.5, 127.5, 255)$.\n- Bias compensation: $(\\mu_2, \\eta_2, \\epsilon_{\\max, 2}) = (0.5, 64, 128)$.\n- Unbiased rounding: $(\\mu_3, \\eta_3, \\epsilon_{\\max, 3}) = (0, 64, 128)$.\nThese nine values form the final answer.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} -127.5  127.5  255  0.5  64  128  0  64  128 \\end{pmatrix} } $$"
        }
    ]
}