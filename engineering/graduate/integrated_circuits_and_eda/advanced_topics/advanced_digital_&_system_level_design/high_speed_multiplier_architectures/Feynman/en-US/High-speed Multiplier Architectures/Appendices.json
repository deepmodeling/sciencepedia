{
    "hands_on_practices": [
        {
            "introduction": "The primary motivation for exploring complex multiplier architectures is the demand for higher performance. While a simple array multiplier is structurally regular, its speed is limited by the ripple-carry effect through its rows of adders. This exercise provides a concrete performance comparison between the traditional array structure and a high-speed Wallace tree multiplier. By calculating the critical path delay for both, you will quantify the substantial speedup achieved by the Wallace tree's parallel partial product reduction, justifying its use in high-performance computing and DSP applications .",
            "id": "1977497",
            "problem": "In the design of a high-speed digital signal processing chip, an engineer is tasked with evaluating two competing architectures for a hardware multiplier that computes the product of two $N$-bit unsigned integers. The performance of each architecture is determined by its critical path delay, which is measured in units of a fundamental gate delay, $t_{gate}$.\n\nThe following component delays are universal to both designs:\n- The delay of a 2-input AND gate used for generating partial products is $t_{AND} = t_{gate}$.\n- The delay through a single Full Adder (FA), from any input to any output, is $t_{FA} = 2.5 t_{gate}$.\n\n**Architecture A: Array Multiplier**\nThis is a straightforward, regular structure composed of a grid of Full Adders. The partial products are generated and then summed row by row. It is known that the critical path delay for an $N \\times N$ Array Multiplier can be modeled as:\n$$T_{Array} = t_{AND} + (2N-2)t_{FA}$$\n\n**Architecture B: Wallace Tree Multiplier**\nThis architecture prioritizes speed by using a more complex, parallel approach. It consists of two main phases:\n1.  **Reduction Stage:** The $N$ rows of partial products are compressed into just two rows. This is achieved through successive layers of Carry-Save Adders (CSAs). A CSA is a bank of parallel Full Adders, so the delay of one layer of reduction is simply $t_{FA}$. The number of rows is reduced in each layer according to the formula $N_{i+1} = 2 \\cdot \\lfloor \\frac{N_i}{3} \\rfloor + (N_i \\pmod 3)$, where $N_i$ is the number of rows at the input of layer $i$. The reduction phase starts with $N_0 = N$ rows and continues for $k$ layers until the number of output rows, $N_k$, is 2. The total delay for this stage is $k \\times t_{FA}$.\n2.  **Final Adder Stage:** The two rows resulting from the reduction stage are summed using a high-speed $(2N)$-bit Carry-Lookahead Adder (CLA). The delay of an $M$-bit CLA is given by the formula:\n    $$T_{CLA}(M) = (2 \\log_{4}(M) + 2) t_{gate}$$\nThe total delay of the Wallace Tree Multiplier, $T_{Wallace}$, is the sum of the partial product generation delay, the total reduction stage delay, and the final adder stage delay.\n\nFor a specific implementation where $N=12$, calculate the speedup factor of the Wallace Tree Multiplier relative to the Array Multiplier. The speedup factor is defined as the ratio of the total delay of the slower architecture to the total delay of the faster one. Round your final answer to three significant figures.",
            "solution": "The problem asks for the speedup factor of a Wallace Tree Multiplier compared to an Array Multiplier for the case of $N=12$. The speedup factor is defined as the ratio of the longer delay to the shorter delay. We must first calculate the total delay for each architecture.\n\n**Step 1: Calculate the delay of the Array Multiplier ($T_{Array}$)**\n\nThe delay for the Array Multiplier is given by the formula $T_{Array} = t_{AND} + (2N-2)t_{FA}$.\nWe are given the parameters:\n$N=12$\n$t_{AND} = t_{gate}$\n$t_{FA} = 2.5 t_{gate}$\n\nSubstitute these values into the formula:\n$$T_{Array} = t_{gate} + (2 \\cdot 12 - 2) \\cdot (2.5 t_{gate})$$\n$$T_{Array} = t_{gate} + (24 - 2) \\cdot (2.5 t_{gate})$$\n$$T_{Array} = t_{gate} + (22) \\cdot (2.5 t_{gate})$$\n$$T_{Array} = t_{gate} + 55 t_{gate}$$\n$$T_{Array} = 56 t_{gate}$$\n\n**Step 2: Calculate the delay of the Wallace Tree Multiplier ($T_{Wallace}$)**\n\nThe total delay for the Wallace Tree Multiplier is the sum of three components: the partial product generation delay, the reduction stage delay, and the final adder stage delay.\n$$T_{Wallace} = T_{PPgen} + T_{reduction} + T_{final\\_add}$$\n\n**Part 2a: Partial Product Generation Delay ($T_{PPgen}$)**\nThe partial products are generated by AND gates. The delay is given as:\n$$T_{PPgen} = t_{AND} = t_{gate}$$\n\n**Part 2b: Reduction Stage Delay ($T_{reduction}$)**\nWe need to find the number of reduction layers, $k$, required to reduce $N=12$ rows down to 2. We use the given recurrence relation $N_{i+1} = 2 \\cdot \\lfloor \\frac{N_i}{3} \\rfloor + (N_i \\pmod 3)$, starting with $N_0 = 12$.\n\n-   **Layer 1:** Input is $N_0 = 12$ rows.\n    $N_1 = 2 \\cdot \\lfloor \\frac{12}{3} \\rfloor + (12 \\pmod 3) = 2 \\cdot 4 + 0 = 8$ rows.\n-   **Layer 2:** Input is $N_1 = 8$ rows.\n    $N_2 = 2 \\cdot \\lfloor \\frac{8}{3} \\rfloor + (8 \\pmod 3) = 2 \\cdot 2 + 2 = 6$ rows.\n-   **Layer 3:** Input is $N_2 = 6$ rows.\n    $N_3 = 2 \\cdot \\lfloor \\frac{6}{3} \\rfloor + (6 \\pmod 3) = 2 \\cdot 2 + 0 = 4$ rows.\n-   **Layer 4:** Input is $N_3 = 4$ rows.\n    $N_4 = 2 \\cdot \\lfloor \\frac{4}{3} \\rfloor + (4 \\pmod 3) = 2 \\cdot 1 + 1 = 3$ rows.\n-   **Layer 5:** Input is $N_4 = 3$ rows.\n    $N_5 = 2 \\cdot \\lfloor \\frac{3}{3} \\rfloor + (3 \\pmod 3) = 2 \\cdot 1 + 0 = 2$ rows.\n\nThe reduction stops when we have 2 rows, which occurs after 5 layers. Thus, $k=5$.\nThe total delay for the reduction stage is $k$ times the delay of a single layer ($t_{FA}$).\n$$T_{reduction} = k \\cdot t_{FA} = 5 \\cdot (2.5 t_{gate}) = 12.5 t_{gate}$$\n\n**Part 2c: Final Adder Stage Delay ($T_{final\\_add}$)**\nThe final adder is a $(2N)$-bit Carry-Lookahead Adder (CLA). For $N=12$, the adder size is $M = 2 \\cdot 12 = 24$ bits.\nThe delay is given by the formula $T_{CLA}(M) = (2 \\log_{4}(M) + 2) t_{gate}$.\nSubstitute $M=24$:\n$$T_{final\\_add} = (2 \\log_{4}(24) + 2) t_{gate}$$\nTo evaluate $\\log_{4}(24)$, we can use the change of base formula: $\\log_{b}(x) = \\frac{\\ln(x)}{\\ln(b)}$.\n$$\\log_{4}(24) = \\frac{\\ln(24)}{\\ln(4)} \\approx \\frac{3.17805}{1.38629} \\approx 2.2925$$\nNow, substitute this value back into the delay formula:\n$$T_{final\\_add} \\approx (2 \\cdot 2.2925 + 2) t_{gate} = (4.585 + 2) t_{gate} = 6.585 t_{gate}$$\n\n**Part 2d: Total Wallace Tree Delay**\nNow, sum the delays of the three parts:\n$$T_{Wallace} = T_{PPgen} + T_{reduction} + T_{final\\_add}$$\n$$T_{Wallace} \\approx (1 + 12.5 + 6.585) t_{gate} = 20.085 t_{gate}$$\n\n**Step 3: Calculate the Speedup Factor**\n\nWe compare the two total delays:\n$T_{Array} = 56 t_{gate}$\n$T_{Wallace} \\approx 20.085 t_{gate}$\n\nSince $T_{Array} > T_{Wallace}$, the Array Multiplier is the slower architecture and the Wallace Tree Multiplier is the faster one. The speedup factor is the ratio of the slower delay to the faster delay.\n$$\\text{Speedup Factor} = \\frac{T_{Array}}{T_{Wallace}} \\approx \\frac{56 t_{gate}}{20.085 t_{gate}} \\approx 2.78815$$\n\nThe problem asks to round the final answer to three significant figures.\n$$\\text{Speedup Factor} \\approx 2.79$$",
            "answer": "$$\\boxed{2.79}$$"
        },
        {
            "introduction": "Having established the performance advantage of compressor trees, we now delve into the specific algorithms that govern their construction. The goal of the reduction stage is to compress the matrix of partial products into just two rows as efficiently as possible. This practice problem challenges you to synthesize the first reduction level using two canonical strategies: the greedy Wallace approach and the more structured Dadda method. This hands-on comparison will illuminate the trade-offs between these schemes and deepen your understanding of the automated logic synthesis process for these critical components .",
            "id": "4275975",
            "problem": "Consider a signed multiplication unit implementing a $24 \\times 24$ bit product using a parallel partial product array and a compression tree in the context of high-speed multiplier architectures for integrated circuits and Electronic Design Automation (EDA). The partial product columns are indexed by $k \\in \\{0, 1, \\dots, 46\\}$, with column-height profile given by $h_k = \\min(k+1, 47-k)$, corresponding to the triangular distribution of partial products for a square multiplier.\n\nTwo column compression strategies are considered for the first reduction level:\n- A Wallace approach that greedily applies $3{:}2$ compressors (full adders) within each column as much as possible in the first level, without using any $2{:}1$ compressors (half adders) in that level. The $3{:}2$ compressor maps three input bits in the same column into one sum bit in the same column and one carry bit in the next more significant column.\n- A Dadda approach that computes the first-stage maximum column height bound $d$ using the Dadda sequence and then minimally applies $3{:}2$ and $2{:}1$ compressors to ensure that, after this first level, the height in every column does not exceed $d$. In the Dadda reduction, a $3{:}2$ compressor reduces the current-column height by $2$ and produces one carry to the next column, while a $2{:}1$ compressor reduces the current-column height by $1$ and produces one carry to the next column. Carries produced within the level must be accounted for sequentially from the least significant column to the most significant column when determining how many compressors are needed in each column.\n\nSynthesize exactly one reduction level under each approach and compute the total number of $3{:}2$ and $2{:}1$ reductions required in that level. Express the final answer as four numbers in a single row matrix, ordered as $\\left(N_{3{:}2}^{\\text{Wallace}}, N_{2{:}1}^{\\text{Wallace}}, N_{3{:}2}^{\\text{Dadda}}, N_{2{:}1}^{\\text{Dadda}}\\right)$. No rounding is required. No units are required.",
            "solution": "The problem requires the calculation of the number of $3{:}2$ and $2{:}1$ compressors used in the first reduction level for a $24 \\times 24$ multiplier, according to two different strategies: a Wallace-like approach and a Dadda approach.\n\nThe initial column-height profile of the partial product array is given by $h_k = \\min(k+1, 47-k)$ for column indices $k \\in \\{0, 1, \\dots, 46\\}$. The maximum height of this array occurs at $k=23$, where $h_{23} = \\min(23+1, 47-23) = 24$.\n\nA $3{:}2$ compressor (full adder) takes $3$ input bits from a column $k$, and produces one sum bit in column $k$ and one carry bit in column $k+1$. This reduces the height of column $k$ by $2$ and increases the height of column $k+1$ by $1$.\nA $2{:}1$ compressor (half adder) takes $2$ input bits from a column $k$, and produces one sum bit in column $k$ and one carry bit in column $k+1$. This reduces the height of column $k$ by $1$ and increases the height of column $k+1$ by $1$.\n\nFirst, we analyze the Wallace approach.\nThe Wallace strategy specified is to greedily apply $3{:}2$ compressors in each column to achieve maximum reduction in a single level, without using any $2{:}1$ compressors in that level.\nFor a column $k$ with initial height $h_k$, the number of $3{:}2$ compressors that can be applied is $n_{3{:}2, k}^{\\text{Wallace}} = \\lfloor h_k / 3 \\rfloor$.\nThe problem states that no $2{:}1$ compressors are used, so $N_{2{:}1}^{\\text{Wallace}} = 0$.\nThe total number of $3{:}2$ compressors, $N_{3{:}2}^{\\text{Wallace}}$, is the sum over all columns:\n$$N_{3{:}2}^{\\text{Wallace}} = \\sum_{k=0}^{46} n_{3{:}2, k}^{\\text{Wallace}} = \\sum_{k=0}^{46} \\left\\lfloor \\frac{h_k}{3} \\right\\rfloor$$\nThe height profile $h_k$ is symmetric. We can split the sum:\n$$N_{3{:}2}^{\\text{Wallace}} = \\sum_{k=0}^{23} \\left\\lfloor \\frac{k+1}{3} \\right\\rfloor + \\sum_{k=24}^{46} \\left\\lfloor \\frac{47-k}{3} \\right\\rfloor$$\nLet $j=k+1$ in the first sum. When $k=0, j=1$; when $k=23, j=24$. The sum becomes $\\sum_{j=1}^{24} \\lfloor j/3 \\rfloor$.\nThis sum can be computed as $3 \\times (1+2+3+4+5+6+7) + \\lfloor 24/3 \\rfloor = 3 \\times \\frac{7 \\times 8}{2} + 8 = 3 \\times 28 + 8 = 84 + 8 = 92$.\nLet $j=47-k$ in the second sum. When $k=24, j=23$; when $k=46, j=1$. The sum becomes $\\sum_{j=1}^{23} \\lfloor j/3 \\rfloor$.\nThis sum is $3 \\times (1+2+3+4+5+6+7) = 3 \\times 28 = 84$.\nTherefore, the total number of $3{:}2$ compressors is:\n$$N_{3{:}2}^{\\text{Wallace}} = 92 + 84 = 176$$\nThe number of $2{:}1$ compressors is:\n$$N_{2{:}1}^{\\text{Wallace}} = 0$$\n\nNext, we analyze the Dadda approach.\nThe Dadda strategy requires reducing the column heights to not exceed a specific value $d$, determined by the Dadda sequence. The sequence is defined by $d_0 = 2$ and $d_{j+1} = \\lfloor 1.5 d_j \\rfloor$.\nThe sequence is $d_0=2$, $d_1=3$, $d_2=4$, $d_3=6$, $d_4=9$, $d_5=13$, $d_6=19$, $d_7=28$, ...\nThe maximum initial height is $h_{\\max} = 24$. The first-stage height limit $d$ is the largest member of the Dadda sequence that is less than $h_{\\max}$. Thus, we have $d=19$.\nThe goal is to minimally apply compressors such that for each column $k$, the final height after reduction is at most $19$. The process is performed sequentially from the least significant column ($k=0$) to the most significant ($k=46$), accounting for carries generated from the previous column.\nLet $h_k$ be the initial height of column $k$, and $c_k$ be the number of carry-in bits from column $k-1$. The total height to be considered for column $k$ is $H_k = h_k + c_k$.\nIf $H_k > 19$, we must apply compressors. To do this minimally, we use $n_{3{:}2,k}$ full adders and $n_{2{:}1,k}$ half adders, where $n_{3{:}2,k} = \\lfloor (H_k - 19)/2 \\rfloor$ and $n_{2{:}1,k} = (H_k - 19) \\pmod 2$. The number of carries generated to column $k+1$ is $c_{k+1} = n_{3{:}2,k} + n_{2{:}1,k}$.\n\nWe now proceed with the column-by-column calculation, starting with $c_0=0$.\nFor $k \\in \\{0, \\dots, 18\\}$, $h_k = k+1 \\le 19$. Since $c_k=0$ for these columns, $H_k \\le 19$. No reduction is needed. $n_{3{:}2,k}=0, n_{2{:}1,k}=0, c_{k+1}=0$.\nFor $k=19$: $h_{19}=20, c_{19}=0 \\implies H_{19}=20$. $H_{19}-19 = 1$. $n_{3{:}2,19}=\\lfloor 1/2 \\rfloor = 0$, $n_{2{:}1,19}=1 \\pmod 2 = 1$. $c_{20}=0+1=1$.\nFor $k=20$: $h_{20}=21, c_{20}=1 \\implies H_{20}=22$. $H_{20}-19 = 3$. $n_{3{:}2,20}=\\lfloor 3/2 \\rfloor = 1$, $n_{2{:}1,20}=3 \\pmod 2 = 1$. $c_{21}=1+1=2$.\nFor $k=21$: $h_{21}=22, c_{21}=2 \\implies H_{21}=24$. $H_{21}-19 = 5$. $n_{3{:}2,21}=\\lfloor 5/2 \\rfloor = 2$, $n_{2{:}1,21}=5 \\pmod 2 = 1$. $c_{22}=2+1=3$.\nFor $k=22$: $h_{22}=23, c_{22}=3 \\implies H_{22}=26$. $H_{22}-19 = 7$. $n_{3{:}2,22}=\\lfloor 7/2 \\rfloor = 3$, $n_{2{:}1,22}=7 \\pmod 2 = 1$. $c_{23}=3+1=4$.\nFor $k=23$: $h_{23}=24, c_{23}=4 \\implies H_{23}=28$. $H_{23}-19 = 9$. $n_{3{:}2,23}=\\lfloor 9/2 \\rfloor = 4$, $n_{2{:}1,23}=9 \\pmod 2 = 1$. $c_{24}=4+1=5$.\nFor $k=24$: $h_{24}=23, c_{24}=5 \\implies H_{24}=28$. $H_{24}-19 = 9$. $n_{3{:}2,24}=\\lfloor 9/2 \\rfloor = 4$, $n_{2{:}1,24}=9 \\pmod 2 = 1$. $c_{25}=4+1=5$.\nFor $k=25$: $h_{25}=22, c_{25}=5 \\implies H_{25}=27$. $H_{25}-19 = 8$. $n_{3{:}2,25}=\\lfloor 8/2 \\rfloor = 4$, $n_{2{:}1,25}=8 \\pmod 2 = 0$. $c_{26}=4+0=4$.\nFor $k=26$: $h_{26}=21, c_{26}=4 \\implies H_{26}=25$. $H_{26}-19 = 6$. $n_{3{:}2,26}=\\lfloor 6/2 \\rfloor = 3$, $n_{2{:}1,26}=6 \\pmod 2 = 0$. $c_{27}=3+0=3$.\nFor $k=27$: $h_{27}=20, c_{27}=3 \\implies H_{27}=23$. $H_{27}-19 = 4$. $n_{3{:}2,27}=\\lfloor 4/2 \\rfloor = 2$, $n_{2{:}1,27}=4 \\pmod 2 = 0$. $c_{28}=2+0=2$.\nFor $k=28$: $h_{28}=19, c_{28}=2 \\implies H_{28}=21$. $H_{28}-19 = 2$. $n_{3{:}2,28}=\\lfloor 2/2 \\rfloor = 1$, $n_{2{:}1,28}=2 \\pmod 2 = 0$. $c_{29}=1+0=1$.\nFor $k=29$: $h_{29}=18, c_{29}=1 \\implies H_{29}=19$. Since $H_{29} \\le 19$, no reduction is needed. $n_{3{:}2,29}=0, n_{2{:}1,29}=0, c_{30}=0$.\nFor all subsequent columns $k>29$, $h_k < 19$ and $c_k = 0$, so no further reductions occur in this stage.\n\nTotal compressors for the Dadda approach:\n$N_{3{:}2}^{\\text{Dadda}} = \\sum_{k=0}^{46} n_{3{:}2,k} = 0+1+2+3+4+4+4+3+2+1 = 24$.\n$N_{2{:}1}^{\\text{Dadda}} = \\sum_{k=0}^{46} n_{2{:}1,k} = 1+1+1+1+1+1+0+0+0+0 = 6$.\n\nThe four required numbers are $\\left(N_{3{:}2}^{\\text{Wallace}}, N_{2{:}1}^{\\text{Wallace}}, N_{3{:}2}^{\\text{Dadda}}, N_{2{:}1}^{\\text{Dadda}}\\right)$.\n$N_{3{:}2}^{\\text{Wallace}} = 176$.\n$N_{2{:}1}^{\\text{Wallace}} = 0$.\n$N_{3{:}2}^{\\text{Dadda}} = 24$.\n$N_{2{:}1}^{\\text{Dadda}} = 6$.\nThe result is $(176, 0, 24, 6)$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 176 & 0 & 24 & 6 \\end{pmatrix}}$$"
        },
        {
            "introduction": "In real-world systems, the pursuit of speed and area efficiency often leads to compromises in numerical precision. Full-width products are a luxury that many applications, particularly in fixed-point digital signal processing, cannot afford. This exercise addresses the practical challenge of product truncation, where the least significant bits are discarded to reduce the size and delay of the final adder. You will analyze and quantify the errors introduced by simple truncation and explore how techniques like bias compensation and unbiased rounding can mitigate these errors, providing a crucial lesson in managing the trade-off between hardware cost and numerical fidelity .",
            "id": "4275952",
            "problem": "Consider an unsigned $32 \\times 32$ parallel multiplier implemented using a high-speed partial-product compression network (for example, a Wallace tree), producing an exact $64$-bit product $P$. To reduce critical-path delay and power, the design truncates the $k=8$ least significant bits (LSBs) of the product prior to the final carry-propagate adder, delivering a $56$-bit truncated product. The error due to truncation is defined as $e = \\hat{P} - P$, where $\\hat{P}$ is the delivered (approximate) product. Assume operands are uniformly distributed over their $32$-bit range so that the discarded remainder is well modeled as uniformly distributed and independent of the retained bits.\n\nAnalyze three schemes:\n- Pure truncation: no correction.\n- Bias compensation: add a constant offset equal to half of the truncation quantum before truncation.\n- Unbiased rounding-to-nearest with ties to even: resolve the half-quantum boundary so the expected error at ties is zero.\n\nUse the following definitions of error metrics over the ensemble of discarded $8$-bit remainders:\n- Mean error $\\mu = \\mathbb{E}[e]$.\n- Mean absolute error $\\eta = \\mathbb{E}[|e|]$.\n- Worst-case error magnitude $\\epsilon_{\\max} = \\max |e|$.\n\nModel the $64$-bit exact product as $P = 256 M + d$ where $M \\in \\mathbb{Z}$ is the retained $56$-bit part and $d \\in \\{0, 1, \\dots, 255\\}$ is the discarded remainder. For bias compensation, add the constant $C = 128$ in the pre-truncation path. For unbiased rounding with ties to even, assume that parity of $M$ is equally likely so that the tie case contributes zero mean error.\n\nCompute $\\mu$, $\\eta$, and $\\epsilon_{\\max}$ for each scheme as exact values in integer units of the original product (i.e., counts of the least significant bit of $P$). Express your final answer as nine numbers in the order: pure truncation $(\\mu, \\eta, \\epsilon_{\\max})$, bias compensation $(\\mu, \\eta, \\epsilon_{\\max})$, unbiased rounding $(\\mu, \\eta, \\epsilon_{\\max})$. No rounding is required.",
            "solution": "The problem requires an analysis of the error characteristics of three different fixed-point product truncation schemes. The exact $64$-bit product $P$ is modeled as $P = 256M + d$, where $M$ is the upper $56$-bit part to be retained, and $d$ is the lower $8$-bit remainder to be discarded. The value of $d$ is an integer in the set $\\{0, 1, 2, \\dots, 255\\}$. Based on the problem statement, we model $d$ as a discrete random variable uniformly distributed over this set. The probability mass function is $p(d) = \\frac{1}{256}$ for any $d$ in its domain. The error is defined as $e = \\hat{P} - P$, where $\\hat{P}$ is the approximate, truncated product. All error metrics are calculated in units of the least significant bit (LSB) of the original product $P$, which has a weight of $1$.\n\nThe expectation of any function $f(d)$ of the remainder is given by the sum over all possible values of $d$:\n$$ \\mathbb{E}[f(d)] = \\sum_{d=0}^{255} f(d) p(d) = \\frac{1}{256} \\sum_{d=0}^{255} f(d) $$\nWe will make use of the formula for the sum of the first $n$ integers: $\\sum_{i=1}^{n} i = \\frac{n(n+1)}{2}$. The sum of the possible remainder values is:\n$$ \\sum_{d=0}^{255} d = \\frac{255(255+1)}{2} = \\frac{255 \\times 256}{2} = 32640 $$\n\nWe analyze each scheme in turn to find the mean error $\\mu = \\mathbb{E}[e]$, mean absolute error $\\eta = \\mathbb{E}[|e|]$, and worst-case error magnitude $\\epsilon_{\\max} = \\max|e|$.\n\n**Scheme 1: Pure Truncation**\nIn pure truncation, the $8$ LSBs are simply discarded. This is equivalent to taking the floor of the product divided by $2^8 = 256$. The retained part is $M$.\nThe approximate product is $\\hat{P} = 256M$.\nThe error $e$ is therefore:\n$$ e = \\hat{P} - P = 256M - (256M + d) = -d $$\nWe can now compute the error metrics:\n- **Mean Error ($\\mu_1$)**:\n$$ \\mu_1 = \\mathbb{E}[e] = \\mathbb{E}[-d] = -\\mathbb{E}[d] = -\\frac{1}{256} \\sum_{d=0}^{255} d = -\\frac{32640}{256} = -127.5 $$\n- **Mean Absolute Error ($\\eta_1$)**: Since $d \\ge 0$, $|e| = |-d| = d$.\n$$ \\eta_1 = \\mathbb{E}[|e|] = \\mathbb{E}[d] = \\frac{1}{256} \\sum_{d=0}^{255} d = 127.5 $$\n- **Worst-case Error Magnitude ($\\epsilon_{\\max, 1}$)**:\n$$ \\epsilon_{\\max, 1} = \\max_{d \\in \\{0, \\dots, 255\\}} |e| = \\max_{d} |-d| = \\max_{d} d = 255 $$\n\n**Scheme 2: Bias Compensation**\nA constant offset $C=128$ is added to the product before truncation. The value to be processed is $P' = P + 128 = 256M + d + 128$.\nThe approximate product is $\\hat{P} = 256 \\times \\lfloor \\frac{P'}{256} \\rfloor = 256 \\times \\lfloor \\frac{256M + d + 128}{256} \\rfloor = 256 \\times \\lfloor M + \\frac{d+128}{256} \\rfloor$.\nThe floor function's behavior depends on $d$:\n- If $0 \\le d \\le 127$, then $0.5 \\le \\frac{d+128}{256} < 1$. Thus, $\\lfloor M + \\frac{d+128}{256} \\rfloor = M$.\n  $\\hat{P} = 256M$, and the error is $e = 256M - (256M+d) = -d$.\n- If $128 \\le d \\le 255$, then $1 \\le \\frac{d+128}{256} < 1.5$. Thus, $\\lfloor M + \\frac{d+128}{256} \\rfloor = M+1$.\n  $\\hat{P} = 256(M+1)$, and the error is $e = 256(M+1) - (256M+d) = 256-d$.\nWe compute the metrics by summing over these two ranges for $d$:\n- **Mean Error ($\\mu_2$)**:\n$$ \\mu_2 = \\frac{1}{256} \\left( \\sum_{d=0}^{127} (-d) + \\sum_{d=128}^{255} (256-d) \\right) $$\nThe first sum is $\\sum_{d=0}^{127} (-d) = -\\frac{127 \\times 128}{2} = -8128$.\nLet $j=256-d$. For the second sum, as $d$ goes from $128$ to $255$, $j$ goes from $128$ to $1$. So $\\sum_{d=128}^{255} (256-d) = \\sum_{j=1}^{128} j = \\frac{128 \\times 129}{2} = 8256$.\n$$ \\mu_2 = \\frac{1}{256} (-8128 + 8256) = \\frac{128}{256} = 0.5 $$\n- **Mean Absolute Error ($\\eta_2$)**:\n$$ \\eta_2 = \\frac{1}{256} \\left( \\sum_{d=0}^{127} |-d| + \\sum_{d=128}^{255} |256-d| \\right) = \\frac{1}{256} \\left( \\sum_{d=0}^{127} d + \\sum_{d=128}^{255} (256-d) \\right) $$\nThe first sum is $\\frac{127 \\times 128}{2} = 8128$. The second sum is $8256$.\n$$ \\eta_2 = \\frac{1}{256} (8128 + 8256) = \\frac{16384}{256} = 64 $$\n- **Worst-case Error Magnitude ($\\epsilon_{\\max, 2}$)**:\nThe magnitude of the error is $|e|=d$ for $d \\in \\{0, \\dots, 127\\}$, whose maximum is $127$.\nThe magnitude is $|e|=256-d$ for $d \\in \\{128, \\dots, 255\\}$, whose maximum is $256-128 = 128$.\n$$ \\epsilon_{\\max, 2} = \\max(127, 128) = 128 $$\n\n**Scheme 3: Unbiased Rounding-to-Nearest with Ties to Even**\nThis scheme rounds $P/256 = M + d/256$ to the nearest integer, with a special rule for ties.\n- If $d/256 < 0.5$ (i.e., $0 \\le d \\le 127$), we round down. $\\hat{P} = 256M$, so $e = -d$.\n- If $d/256 > 0.5$ (i.e., $129 \\le d \\le 255$), we round up. $\\hat{P} = 256(M+1)$, so $e = 256-d$.\n- If $d/256 = 0.5$ (i.e., $d=128$), it's a tie. We round to the nearest even integer.\n  - If $M$ is even, we round down to $M$. $\\hat{P}=256M$, so $e = -128$.\n  - If $M$ is odd, we round up to $M+1$. $\\hat{P}=256(M+1)$, so $e = 256-128 = 128$.\nWe are given that $M$ is equally likely to be even or odd, so $P(M \\text{ is even}) = P(M \\text{ is odd}) = 0.5$.\n- **Mean Error ($\\mu_3$)**: The error now depends on $M$ for the case $d=128$. We compute the expectation over both $d$ and $M$.\n$$ \\mu_3 = \\mathbb{E}_{d,M}[e] = \\frac{1}{256} \\left( \\sum_{d=0, d \\neq 128}^{255} e(d) + \\mathbb{E}_M[e(d=128, M)] \\right) $$\n$\\mathbb{E}_M[e(d=128, M)] = (-128) P(M \\text{ is even}) + (128) P(M \\text{ is odd}) = -128(0.5) + 128(0.5) = 0$.\nThe sum is $\\sum_{d=0}^{127} (-d) + \\sum_{d=129}^{255} (256-d)$.\nThe first part is $-8128$. For the second part, let $j=256-d$. As $d$ goes from $129$ to $255$, $j$ goes from $127$ to $1$. So $\\sum_{j=1}^{127} j = \\frac{127 \\times 128}{2} = 8128$.\n$$ \\mu_3 = \\frac{1}{256} (-8128 + 0 + 8128) = 0 $$\n- **Mean Absolute Error ($\\eta_3$)**:\n$$ \\eta_3 = \\frac{1}{256} \\left( \\sum_{d=0, d \\neq 128}^{255} |e(d)| + \\mathbb{E}_M[|e(d=128, M)|] \\right) $$\n$\\mathbb{E}_M[|e(d=128, M)|] = |-128| P(M \\text{ is even}) + |128| P(M \\text{ is odd}) = 128(0.5) + 128(0.5) = 128$.\nThe sum is $\\sum_{d=0}^{127} d + \\sum_{d=129}^{255} (256-d) = 8128 + 8128 = 16256$.\n$$ \\eta_3 = \\frac{1}{256} (16256 + 128) = \\frac{16384}{256} = 64 $$\n- **Worst-case Error Magnitude ($\\epsilon_{\\max, 3}$)**:\nThe error magnitudes are $|e|=d$ for $d \\in \\{0, \\dots, 127\\}$ (max $127$), $|e|=256-d$ for $d \\in \\{129, \\dots, 255\\}$ (max $127$), and $|e|=128$ for $d=128$.\n$$ \\epsilon_{\\max, 3} = \\max(127, 128) = 128 $$\n\nSummary of results:\n- Pure truncation: $(\\mu_1, \\eta_1, \\epsilon_{\\max, 1}) = (-127.5, 127.5, 255)$.\n- Bias compensation: $(\\mu_2, \\eta_2, \\epsilon_{\\max, 2}) = (0.5, 64, 128)$.\n- Unbiased rounding: $(\\mu_3, \\eta_3, \\epsilon_{\\max, 3}) = (0, 64, 128)$.\nThese nine values form the final answer.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} -127.5 & 127.5 & 255 & 0.5 & 64 & 128 & 0 & 64 & 128 \\end{pmatrix} } $$"
        }
    ]
}