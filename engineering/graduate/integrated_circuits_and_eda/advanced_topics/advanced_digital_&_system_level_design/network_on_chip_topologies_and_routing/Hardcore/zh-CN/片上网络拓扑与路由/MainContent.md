## 引言
随着摩尔定律的演进，单颗芯片上集成的处理器核心数量呈指数级增长，使得[片上系统](@entry_id:1131845)（SoC）变得日益复杂。传统的[共享总线](@entry_id:177993)或交叉开关等互连架构在[可扩展性](@entry_id:636611)、带宽和功耗方面面临严峻挑战，已无法满足众核时代的通信需求。[片上网络](@entry_id:1128532)（NoC）作为一种可扩展、高性能的片上通信范式应运而生，已成为现代高性能处理器和专用[加速器设计](@entry_id:746209)的基石。然而，设计一个高效且可靠的NoC是一个复杂的[多目标优化](@entry_id:637420)问题，涉及网络拓扑、[路由算法](@entry_id:1131127)、流控机制以及物理实现等多个层面的深刻权衡。本文旨在系统性地梳理NoC设计的核心知识体系，填补理论与实践之间的鸿沟。

在接下来的内容中，我们将分三步深入探索NoC的世界。首先，在“原理与机制”一章中，我们将奠定理论基础，学习如何使用图论对网络进行建模，分析关键拓扑属性，并深入探讨[路由算法](@entry_id:1131127)、流控机制以及确保网络正确运行的[死锁](@entry_id:748237)与[活锁](@entry_id:751367)避免策略。其次，在“应用与跨学科连接”一章中，我们将把理论应用于现实，探讨NoC设计如何与电子设计自动化（EDA）、计算机体系结构以及神经形态计算等领域交叉，揭示在物理约束和系统性能需求下的设计权衡。最后，通过“动手实践”部分的精选习题，您将有机会将所学知识付诸实践，加深对[网络性能](@entry_id:268688)分析与[算法设计](@entry_id:634229)的理解。

## 原理与机制

在介绍性章节对片上网络（NoC）的基本背景和意义进行概述之后，本章将深入探讨其核心技术原理与实现机制。我们将 NoC 建模为数学图，并在此基础上分析其拓扑特性如何决定性能边界。随后，我们将阐述数据包如何在网络中导航的[路由算法](@entry_id:1131127)，管理网络资源的流控机制，以及确保网络正确运行、避免[死锁](@entry_id:748237)与[活锁](@entry_id:751367)的关键策略。最后，我们将介绍一些高级机制，如虚拟通道和虚拟网络，它们是实现高性能和多业务[服务质量](@entry_id:753918)（QoS）保证的基石。

### 将[网络表示](@entry_id:752440)为[图论](@entry_id:140799)模型

为了对[片上网络](@entry_id:1128532)进行严谨的分析与设计，我们首先需要一个形式化的数学模型。最常用且最强大的方法是将 NoC 抽象为一个**图**（Graph）$G=(V, E)$。在这个模型中：

-   **顶点集 $V$** (Vertices) 代表了网络中的处理单元或路由节点。在 NoC 的语境下，一个顶点通常对应一个“瓦片”（tile），它可能包含一个处理器核心、一个缓存片、一个[内存控制器](@entry_id:167560)或其他[知识产权](@entry_id:908926)（IP）核，以及一个与之相关联的路由器。

-   **[边集](@entry_id:267160) $E$** (Edges) 代表了连接这些节点的物理通信链路。在大多数 NoC 中，这些链路是双向的，允许数据在两个方向上同时传输。因此，我们通常将物理链路建模为图中的一条无向边，或者一对方向相反的有向边，具体取决于分析的需要。

这种图论模型使我们能够运用[图论](@entry_id:140799)中成熟的工具和概念来量化和比较不同的[网络设计](@entry_id:267673)。例如，从一个节点到另一个节点的[消息传递](@entry_id:751915)过程可以被看作是在图上寻找一条路径。接下来，我们将探讨一些基于此模型的关键拓扑属性及其对[网络性能](@entry_id:268688)的深远影响。

### 关键拓扑属性及其性能启示

网络拓扑的几何结构直接制约了其通信性能的上限。通过分析一些基本的图度量，我们可以对一个网络的成本和性能潜力有一个初步而深刻的理解。我们将以一个常见的二维网格（2D Mesh）拓扑为例来说明这些概念。

#### 节点度

节点的**度**（Degree）定义为与其相连的物理链路的数量。在 NoC 中，一个路由器的度决定了其端口数量，这直接关系到路由器的复杂性、面积和功耗。

-   **[最大度](@entry_id:265573)**（Maximum Degree）决定了网络中最复杂路由器的设计要求。
-   **平均度**（Average Degree）则反映了整个网络的平均连接成本。

考虑一个 $k \times k$ 的二维[网格拓扑](@entry_id:750070)，其中节点位于整数坐标 $(i,j)$ 上，且 $1 \le i, j \le k$。一个典型的内部节点，如 $(2,2)$，连接着它的东、南、西、北四个邻居，因此其度为 $4$。而位于角落的节点，如 $(1,1)$，只连接着两个邻居，度为 $2$。位于边缘（但非角落）的节点则有 $3$ 个邻居，度为 $3$。

因此，对于一个没有环绕链路的 $k \times k$ 网格：
-   最大节点度为 $4$。
-   通过计算所有节点的度并求平均，可以得出平均[节点度](@entry_id:1128744)为 $4 - \frac{4}{k}$。当 $k$ 趋向于无穷大时，[平均度](@entry_id:261638)接近 $4$ 。

一个网络的度分布揭示了其规整性。像网格或环面（Torus）这样的**规整拓扑**（Regular Topology），其所有节点的度都相同，这有助于简化设计和实现。

#### 直径与平均跳数

在网络中，一个数据包从源节点到目的节点所经过的链路数被称为**路径长度**或**跳数**（Hop Count）。在所有可能的路径中，跳数最少的路径被称为**最短路径**（Shortest Path）。

网络的**直径**（Diameter）被定义为网络中任意两个节点之间[最短路径长度](@entry_id:902643)的最大值。它代表了在最坏情况下，一个数据包在网络中需要穿越的最小跳数。

直径是衡量最坏情况通信延迟的一个关键指标。假设网络采用**[最短路径路由](@entry_id:1131594)**（Minimal Routing），并且数据包穿越每一跳（包括链路传输和路由器转发）的延迟是一个统一的常量 $\tau$。在这种理想情况下（即没有拥塞和排队），从源节点 $u$ 到目的节点 $v$ 的端到端延迟就是 $d(u,v) \times \tau$，其中 $d(u,v)$ 是它们之间的[最短路径距离](@entry_id:754797)。因此，网络中的最坏情况通信延迟 $L_{\max}$ 直接由其直径 $D$ 决定 ：
$L_{\max} = D \times \tau$

例如，在一个 $k \times k$ 的二维网格中，[最短路径距离](@entry_id:754797)由**[曼哈顿距离](@entry_id:141126)**（Manhattan Distance）给出：$d((i_1,j_1), (i_2,j_2)) = |i_1 - i_2| + |j_1 - j_2|$。距离最远的两个节点是位于对角的两个角落，例如 $(1,1)$ 和 $(k,k)$。它们之间的距离为 $(k-1) + (k-1) = 2(k-1)$。因此，该网络的直径为 $D = 2(k-1)$ 。

虽然直径反映了最坏情况，但网络的平均性能通常由**平均[最短路径长度](@entry_id:902643)**（Average Shortest Path Length）或**平均跳数**来衡量。这是在所有节点对之间随机选择一对源和目的时，它们之间[最短路径长度](@entry_id:902643)的[期望值](@entry_id:150961)。对于一个 $k \times k$ 网格，可以证明平均[最短路径长度](@entry_id:902643)与 $k$ 呈线性关系，即 $\Theta(k)$ 。这个指标直接影响了在均匀[随机流](@entry_id:197438)量模式下网络的平均通信延迟。

#### 对剖带宽

**对剖带宽**（Bisection Bandwidth）是衡量网络全局吞吐能力的一个核心指标。它反映了网络在最拥挤的通信模式下的瓶颈。一个网络的对剖是指将其顶点集 $V$ 分割成两个大小相等（或最多相差一个）的子集 $S$ 和 $V \setminus S$。跨越这两个子集的所有链路构成的集合被称为一个**对剖割**（Bisection Cut）。对剖带宽被定义为在所有可能的对剖割中，横跨割集的链路总容量的最小值。

这个指标的重要性源于**[最大流](@entry_id:178209)-[最小割](@entry_id:1127910)定理**（Max-Flow Min-Cut Theorem）的一个直观推论：任何跨越一个割集的通信流量总量，都不能超过该割集的总容量。对剖带宽代表了网络最窄的“腰部”，因此它限制了需要大量全局通信的流量模式的整体吞吐率。

考虑一个场景，网络中的每个节点都需要以相同的速率 $r$ 向其他所有节点发送数据，这被称为**全局对全通信**（All-to-All Communication）。我们可以通过对剖带宽来估算这个最大可能速率 $r$ 的上限。在一个包含 $n$ 个节点的网络中，考虑一个最小对剖割，它将网络分为两个大小为 $n/2$ 的子集。从一个子集到另一个子集的所有通信都必须穿越这个割集。在全员对全通信模式下，一个子集中的 $n/2$ 个节点中的每一个都需要向另一个子集中的 $n/2$ 个节点发送数据。因此，总共有 $(n/2) \times (n/2) = n^2/4$ 条流向一个方向，同样数量的流向相反方向。总的跨越割集的流量需求为 $2 \times (n^2/4) \times r = (n^2/2)r$。这个流量必须小于等于对剖带宽 $B(G)$。因此，我们得到了单个流速率 $r$ 的一个严格上限 ：
$r \le \frac{2 B(G)}{n^2}$

对于一个 $k \times k$ 的二维网格（其中 $k$ 为偶数），一个最小对剖割可以通过沿中心线切开网络得到，这条[割线](@entry_id:178768)会切断 $k$ 条物理链路。如果每条物理链路在每个方向上的容量为 $C$，那么对剖带宽就是 $k \times 2C = 2Ck$ 。这个值直接限制了该[网格拓扑](@entry_id:750070)所能支持的全局通信强度。

### [路由算法](@entry_id:1131127)：在拓扑中导航

有了[网络拓扑结构](@entry_id:141407)，我们还需要定义数据包如何从源节点找到通往目的节点的路径。这就是**[路由算法](@entry_id:1131127)**（Routing Algorithm）的任务。[路由算法](@entry_id:1131127)的选择对[网络性能](@entry_id:268688)、成本和正确性都有着至关重要的影响。

#### 路由范式：最小、非最小、自适应与确定性

[路由算法](@entry_id:1131127)可以根据其路径选择的灵活性和路径长度进行分类。

-   **最小路由**（Minimal Routing）：算法选择的路径总是最短路径之一。这保证了最低的跳数，从而在无拥塞情况下实现最低延迟。

-   **非最小路由**（Non-minimal Routing）：算法被允许选择比最短路径更长的路径。虽然这会增加单个数据包的延迟，但通过绕开拥塞区域，它可能提高整个网络的总[吞吐量](@entry_id:271802)。一个经典的非最小[路由算法](@entry_id:1131127)是 **Valiant 随机路由**。在该算法中，一个数据包从源节点 $S$ 发送到一个随机选择的中间节点 $I$，然后再从 $I$ 发送到最终的目的节点 $T$。尽管这几乎肯定会使路径变长（在均匀[随机流](@entry_id:197438)量下，[平均路径长度](@entry_id:141072)大约会翻倍），但它通过将所有流量“[随机化](@entry_id:198186)”来极大地改善了[负载均衡](@entry_id:264055)，能够有效地应对非均匀或对抗性的流量模式，从而保证高吞吐率 。

-   **确定性路由**（Deterministic Routing）：对于给定的源-目的对，[路由算法](@entry_id:1131127)总是选择完全相同的路径，而不考虑当前的网络状态（如拥塞）。一个典型的例子是二维网格中的**维度顺序路由**（Dimension-Order Routing, DOR），例如 XY 路由。在 XY 路由中，数据包首先在 X 维度上移动，直到其 X 坐标与目的地对齐，然后再在 Y 维度上移动。这种算法简单、易于实现，但由于其路径选择僵化，容易在特定流量模式下造成拥塞热点 。

-   **[自适应路由](@entry_id:1120782)**（Adaptive Routing）：[路由算法](@entry_id:1131127)可以根据网络状态（如邻近路由器的队列长度）来动态选择路径。在一个拓扑中，源和目的地之间可能存在多条不同的最短路径。例如，在一个二维网格中，从 $(x_s, y_s)$ 到 $(x_d, y_d)$ 的任何一条由 $\Delta x = |x_d - x_s|$ 次水平移动和 $\Delta y = |y_d - y_s|$ 次垂直移动组成的路径都是[最短路径](@entry_id:157568)。这样的路径总共有 $\binom{\Delta x + \Delta y}{\Delta x}$ 条。**自适应最小路由**（Adaptive Minimal Routing）可以在这组最短路径中进行选择，试图绕开局部拥塞点，从而在不增加跳数的情况下降低排队延迟 。

#### 路由实现：源路由与分布式路由

路由决策的计算可以在网络中的不同位置进行，这导致了两种主要的实现方式。

-   **分布式路由**（Distributed Routing）：这是最常见的方法。每个路由器都包含路由逻辑。当一个数据包到达路由器时，路由器检查其头部携带的目的地址，并根据本地存储的路由表或一个固定的[路由算法](@entry_id:1131127)（如DOR）来决定下一跳应该发往哪个输出端口。这种方式下，数据包的头部开销较小，只需要携带最终目的地址。

-   **源路由**（Source Routing）：在这种模式下，整个路径在数据包被注入网络之前，由源节点的网络接口（Network Interface）计算好。然后，完整的[路径信息](@entry_id:169683)（例如，一个由要经过的路由器坐标或输出端口组成的序列）被编码在数据包的头部。沿途的每个路由器不再需要进行复杂的路由计算；它只需读取头部信息中的下一跳指令并照此转发即可。这简化了路由器的设计，但代价是显著增加了数据包的**头部开销**（Header Overhead）。

源路由的头部开销与路径长度成正比。在最坏的情况下，这个开销可能非常大。例如，在一个 $k \times k$ 的网格中，如果每个节点的坐标 $(x,y)$ 需要 $2 \log_2 k$ 位来表示，而最长的最短路径（即[网络直径](@entry_id:752428)）为 $2(k-1)$ 跳，那么在最坏情况下，编码整个路径所需的头部开销将是 $2(k-1) \times 2\log_2 k = 4(k-1)\log_2 k$ 位 。这个开销会随着网络规模 $k$ 的增大而迅速增长。

### 流控机制：管理网络资源

除了确定路径，网络还必须有一种机制来管理对链路和缓冲区这些有限资源的访问。这就是**流控**（Flow Control）的作用。它决定了一个数据包（或其一部分）何时可以被转发到下一跳。

#### 缓冲流控：[虫洞](@entry_id:158887)机制

**[虫洞](@entry_id:158887)流控**（Wormhole Flow Control）是现代 NoC 中最普遍的缓冲流控方案。其核心思想是将一个数据包分解成多个更小的固定大小的单元，称为**流片**（flits）。

-   **头流片**（Head Flit）负责进行路由决策，并在沿途的路由器中为数据包预留输出通道。
-   **体流片**（Body Flits）和**尾流片**（Tail Flit）紧随其后，像一条“蠕虫”一样在网络中以流水线方式前进。
-   数据包的流片可以在网络中跨越多个路由器，只有头流片需要等待路由和通道分配。一旦通道被分配，它就会被整个数据包占据，直到尾流片通过。

为了防止下游路由器[缓冲区溢出](@entry_id:747009)，[虫洞](@entry_id:158887)流控通常与**基于信用的[背压](@entry_id:746637)机制**（Credit-based Backpressure）相结合。下游路由器会向上游路由器发送“信用”（credits），每个信用代表其输入缓冲区中有一个空闲的流片位置。上游路由器只有在拥有信用时才能发送流片，从而保证了不会有数据丢失。

[虫洞](@entry_id:158887)流控在低负载下延迟非常低，因为只有头流片会经历路由延迟。然而，当网络负载增加时，其性能会因两种现象而下降 ：
1.  **排队延迟**：当多个数据包争用同一个输出端口时，失败的数据包必须在输入缓冲区中等待，导致排队延迟。随着负载接近饱和点，这种延迟会呈超[线性增长](@entry_id:157553)。
2.  **队头阻塞**（Head-of-Line Blocking, HOL Blocking）：一个被阻塞的数据包（例如，其头流片正在等待一个繁忙的输出端口）会占据其所在的输入通道和缓冲区，阻止其后方即使前往不同、空闲输出端口的数据包前进。

#### 无缓冲流控：偏转路由

与依赖缓冲区的[虫洞](@entry_id:158887)流控相反，**无缓冲流控**（Bufferless Flow Control）或**偏转路由**（Deflection Routing）采取了一种截然不同的策略。在这种方案中，路由器几乎没有或完全没有输入缓冲区。

当多个流片在同一周期到达一个路由器并请求同一个输出端口时，会发生争用。路由器通过一个仲裁机制（Arbitration）选择一个“获胜者”发往所请求的端口。而所有“失败者”不会被存储，而是立即被“偏转”（deflected）到一个或多个当前空闲的输出端口，即使这些端口是非优选的（即不会使它们更接近目的地）。

偏转路由的延迟特性与[虫洞](@entry_id:158887)流控有根本的不同 ：
-   **无排队延迟**：由于没有缓冲区，流片永远不会等待，因此没有排队延迟。
-   **因偏转增加的延迟**：延迟的增加主要来自于因偏转而导致的额外跳数。一个被偏转的流片走了一条更长的非最小路径，因此其总传输时间增加。

偏转路由的主要优点是路由器的设计极其简单，面积和功耗都很低。然而，它的性能行为可能更难预测，并且在高负载下，频繁的偏转会消耗大量网络带宽，导致[吞吐量](@entry_id:271802)饱和。

### 路由的正确性：避免死锁与[活锁](@entry_id:751367)

一个功能完备的路由网络不仅要高效，更要保证**正确性**，即每个注入网络的数据包最终都能到达其目的地。两个主要的正确性问题是死锁和[活锁](@entry_id:751367)。

#### 死锁：毁灭的循环

**[死锁](@entry_id:748237)**（Deadlock）是一种致命的网络状态，其中一组数据包因为循环地等待彼此占有的资源而无法继续前进。在采用[虫洞](@entry_id:158887)流控的网络中，这些资源就是路由器中的通道（channel）。

我们可以使用**通道依赖图**（Channel Dependency Graph, CDG）来形式化地分析死锁。CDG 的顶点是网络中所有的（有向）通道。如果一个数据包在路由过程中可能在持有通道 $c_1$ 的同时请求通道 $c_2$，那么在 CDG 中就存在一条从 $c_1$ 到 $c_2$ 的有向边。[死锁的必要条件](@entry_id:752389)是 CDG 中存在一个**环**（Cycle）。如果这个环上的所有通道同时被不同的数据包持有，并且每个数据包都在请求环上的下一个通道，那么死锁就发生了。由于每个数据包都遵循“[持有并等待](@entry_id:750367)”（hold-and-wait）的原则（它必须持有当前通道直到获得下一个通道），这个[循环等待](@entry_id:747359)将永远无法打破。

在具有环绕链路的拓扑（如环面/Torus）上，使用简单的[自适应路由](@entry_id:1120782)策略很容易产生[死锁](@entry_id:748237)。例如，在一个 $4 \times 4$ 的环面上，考虑四个数据包形成一个“死亡之环” ：
-   $P_0$: 从 (3,0) 到 (0,1)，持有向东的通道 $E_{3,0}$，请求向北的通道 $N_{0,0}$。
-   $P_1$: 从 (0,0) 到 (3,1)，持有向北的通道 $N_{0,0}$，请求向西的通道 $W_{0,1}$。
-   $P_2$: 从 (0,1) 到 (3,0)，持有向西的通道 $W_{0,1}$，请求向南的通道 $S_{3,1}$。
-   $P_3$: 从 (3,1) 到 (0,0)，持有向南的通道 $S_{3,1}$，请求向东的通道 $E_{3,0}$。

在这个场景中，$P_0$ 等待 $P_1$，$P_1$ 等待 $P_2$，$P_2$ 等待 $P_3$，而 $P_3$ 又在等待 $P_0$。一个无法解开的[循环等待](@entry_id:747359)就此形成，导致这四个数据包永久停滞。

#### [活锁](@entry_id:751367)：无尽的奔波

**[活锁](@entry_id:751367)**（Livelock）是另一种违反网络正确性的状态，它与[死锁](@entry_id:748237)不同。在[活锁](@entry_id:751367)中，数据包仍然在网络中移动，消耗着网络资源，但它们永远无法到达目的地。这是一个**活性**（Liveness）问题（“好的事情最终会发生”），而非**安全性**（Safety）问题（“坏的事情永不发生”）如死锁。

[活锁](@entry_id:751367)是无缓冲偏转路由中一个特别需要关注的问题。由于数据包在争用失败时会被偏转，一个“不幸”的数据包可能会被持续地偏转，在网络中无休止地兜圈子，而从不向其目的地取得实质性进展。一个设计不当的、具有固定偏见的本地仲裁策略就可能导致[活锁](@entry_id:751367)。例如，一个总是优先处理来自特定方向（如“顺时针”）的数据包的策略，就可能被利用来系统性地使某些数据包持续被偏转，形成循环路径 。

为了防止[活锁](@entry_id:751367)，仲裁策略必须包含一种机制来保证每个数据包最终都能获得其所需的路径。一个有效且广泛使用的方案是**基于年龄的优先级**（Age-based Priority），也称为“长者优先”（Oldest-first）。
-   每个数据包在注入网络时被赋予一个年龄（或时间戳），每经过一跳，其年龄就增加。
-   当发生端口争用时，年龄最大的数据包获得最高优先级，并被保证获得其所请求的（最小路径）输出端口，绝不被偏转。

这个方案之所以能保证无[活锁](@entry_id:751367)，是因为一个数据包的年龄会随时间单调增长。在有限的网络中，一个数据包最终会成为“最老”的那个。一旦它成为最老的数据包，它就不会再被偏转，而是沿着一条确定的[最短路径](@entry_id:157568)前进，并将在有限的步数内到达目的地。这就从根本上杜绝了任何数据包被无限期滞留在网络中的可能性 。

### [服务质量](@entry_id:753918)与正确性的高级机制

为了解决上述问题并提供更高级的功能，现代 NoC 设计引入了虚拟通道和虚拟网络等强大机制。

#### 虚拟通道：NoC 设计的瑞士军刀

一个**虚拟通道**（Virtual Channel, VC）是在单个物理链路上复用出的多个逻辑通道，每个 VC 都有自己独立的、基于信用流控的缓冲区。VC 是一个极其强大的工具，主要用于解决死锁问题和改善性能。

VC 的核心作用是**[解耦](@entry_id:160890)资源依赖**，从而打破 CDG 中的环。以[环面拓扑](@entry_id:265595)上的[死锁](@entry_id:748237)为例，死锁的根源在于环绕链路导致了资源依赖环。我们可以通过使用多个 VC 来打破这个环。一种经典的方案（基于 Duato 的理论）是使用两个 VC 类别：
1.  一个 VC 用于在环上“正常”行进。
2.  另一个 VC 专门用于跨越环绕链路（即“数据线”）。
通过规定数据包只能从第一类 VC 切换到第二类 VC，而绝不允许反向切换，我们就在 CDG 中切断了环路，从而避免了[死锁](@entry_id:748237)。

为了在[二维环面](@entry_id:265991)拓扑上实现完全自适应的最小路由，同时保证无死锁，我们需要一个更复杂的 VC 分配方案。我们需要一个**逃生虚拟网络**（Escape Virtual Network），它本身是无[死锁](@entry_id:748237)的，而其他 VC 则可以用于[自适应路由](@entry_id:1120782)。一个无[死锁](@entry_id:748237)的逃生网络本身就需要 VC 来打破维度内的环路。在[二维环面](@entry_id:265991)上，使用维度顺序路由（DOR）作为逃生路径，每个维度（环）需要至少 2 个 VC 来打破环绕依赖。此外，我们至少需要 1 个额外的 VC 用于[自适应路由](@entry_id:1120782)。因此，要在[二维环面](@entry_id:265991)上支持无[死锁](@entry_id:748237)的[自适应路由](@entry_id:1120782)，每个物理通道至少需要 $2+1=3$ 个 VC 。

此外，VC 也能有效缓解队头阻塞（HOL Blocking）。如果一个数据包在一个 VC 中被阻塞，其他数据包仍然可以使用同一物理链路上的其他空闲 VC，从而提高了物理带宽的利用率。

#### 虚拟网络：隔离流量以保证[服务质量](@entry_id:753918)

**虚拟网络**（Virtual Network, VN）是比 VC 更高一层的抽象。一个 VN 是由一组 VC 构成的完全独立的逻辑网络，拥有自己独立的缓冲区资源和仲裁域。不同 VN 中的数据包永远不会共享缓冲区，也不会在同一个仲裁域中竞争。

VN 的主要用途是提供**[服务质量](@entry_id:753918)（QoS）隔离**。在复杂的片上系统中，不同应用可能产生不同性质的流量。例如，实时视频流是**延迟敏感**（Latency-Critical, LC）的，而后台数据同步任务则是**尽力而为**（Best-Effort, BE）的。如果这两类流量在同一个网络中竞争，BE 流量的突发可能会阻塞 LC 流量，导致其延迟急剧增加，违反其 QoS 要求。

通过将 LC 和 BE 流量分配到不同的 VN 中，我们可以实现它们之间的完全隔离。例如，我们可以创建一个 $\mathrm{VN}_{\mathrm{LC}}$ 和一个 $\mathrm{VN}_{\mathrm{BE}}$。通过在路由器仲裁时给予 $\mathrm{VN}_{\mathrm{LC}}$ 绝对的静态优先级，我们能确保 LC 数据包永远不会因为 BE 数据包的存在而等待，从而为其提供了有保障的低延迟服务。

更有趣的是，VN 还可以与逃生通道的概念相结合，同时解决 QoS 和死锁问题。考虑一个系统，它需要隔离 LC 和 BE 流量，并且 LC 流量使用可能产生死锁的[自适应路由](@entry_id:1120782)。我们可以设计一个包含三个 VN 的系统 ：
1.  **$\mathrm{VN}_{\mathrm{LC}}$**: 一个高优先级的 VN，专用于 LC 流量，采用[自适应路由](@entry_id:1120782)以降低平均延迟。
2.  **$\mathrm{VN}_{\mathrm{BE}}$**: 一个低优先级的 VN，用于 BE 流量。
3.  **$\mathrm{VN}_{\mathrm{esc}}$**: 一个所有数据包（无论是 LC 还是 BE）都可访问的、实现无[死锁](@entry_id:748237)确定性路由（如 DOR）的逃生 VN。

在这个架构中，通过 $\mathrm{VN}_{\mathrm{LC}}$ 和 $\mathrm{VN}_{\mathrm{BE}}$ 的分离实现了 QoS 保证，而通过共享的 $\mathrm{VN}_{\mathrm{esc}}$ 保证了整个系统的无[死锁](@entry_id:748237)运行。这清晰地展示了如何通过分层的逻辑抽象（VN 和 VC）来系统性地解决 NoC 设计中的复杂挑战。