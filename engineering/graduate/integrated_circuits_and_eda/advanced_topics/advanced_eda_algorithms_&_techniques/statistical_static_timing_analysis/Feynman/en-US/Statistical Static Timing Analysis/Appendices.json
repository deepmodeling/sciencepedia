{
    "hands_on_practices": [
        {
            "introduction": "The foundation of Statistical Static Timing Analysis lies in accurately modeling how variations in physical parameters affect circuit delay. This first exercise provides practice with this core skill by using the classic Elmore delay model for an RC interconnect. You will derive the statistical properties of the delay by propagating parameterized variations in resistance and capacitance, constructing the fundamental canonical linear form that is used throughout SSTA. ",
            "id": "4301862",
            "problem": "Consider a resistive-capacitive interconnect tree driven by a source and observed at a designated sink node. Let the path from the source to the sink be denoted by the ordered edge set $\\mathcal{P}$, indexed by $k \\in \\{1,2,\\dots, m\\}$, where each edge $k$ has resistance $R_{k}$, and let the capacitive loads be associated to nodes, indexed by $j \\in \\{1,2,\\dots, n\\}$, with capacitances $C_{j}$. For each edge $k$ along $\\mathcal{P}$, define the downstream set $\\mathcal{D}(k, S)$ as the set of indices of capacitances whose charging current flows through edge $k$ on the way to the sink $S$.\n\nFor Statistical Static Timing Analysis (SSTA), suppose parameterized process variation induces multiplicative perturbations on both resistances and capacitances, modeled as\n$$\nR_{k} \\;=\\; R_{k,0}\\left(1 + \\alpha_{k} G + \\sum_{p=1}^{P_{r}} \\gamma_{k,p} X_{p}\\right), \\quad k \\in \\mathcal{P},\n$$\n$$\nC_{j} \\;=\\; C_{j,0}\\left(1 + \\beta_{j} G + \\sum_{q=1}^{P_{c}} \\delta_{j,q} Y_{q}\\right), \\quad j \\in \\{1,\\dots,n\\},\n$$\nwhere $R_{k,0} > 0$ and $C_{j,0} > 0$ are nominal values, $G \\sim \\mathcal{N}(0,\\sigma_{G}^{2})$ is a global zero-mean Gaussian source common to both resistances and capacitances, and $\\{X_{p}\\}_{p=1}^{P_{r}}$ and $\\{Y_{q}\\}_{q=1}^{P_{c}}$ are mutually independent, zero-mean Gaussian local sources with variances $\\sigma_{X_{p}}^{2}$ and $\\sigma_{Y_{q}}^{2}$, respectively. Assume $G$, all $X_{p}$, and all $Y_{q}$ are mutually independent, and that the perturbations are sufficiently small to justify a first-order linearization in the random sources (i.e., products of random sources are neglected).\n\nUsing the standard definition of Elmore delay for an interconnect resistive-capacitive tree, construct the random variable for the Elmore delay $T_{S}$ to the sink $S$ in a canonical linear form with respect to the sources $G$, $\\{X_{p}\\}$, and $\\{Y_{q}\\}$. Then, derive closed-form expressions for the mean $\\mathbb{E}[T_{S}]$ and the variance $\\mathrm{Var}(T_S)$ in terms of the nominal parameters $\\{R_{k,0}\\}$, $\\{C_{j,0}\\}$, the path $\\mathcal{P}$, the downstream sets $\\{\\mathcal{D}(k,S)\\}$, and the sensitivity coefficients $\\{\\alpha_{k}\\}$, $\\{\\beta_{j}\\}$, $\\{\\gamma_{k,p}\\}$, and $\\{\\delta_{j,q}\\}$, as well as the source variances $\\sigma_{G}^{2}$, $\\{\\sigma_{X_{p}}^{2}\\}$, and $\\{\\sigma_{Y_{q}}^{2}\\}$.\n\nExpress the mean in seconds and the variance in square seconds. Provide your final answer as a two-entry row matrix containing $\\mathbb{E}[T_S]$ and $\\mathrm{Var}(T_S)$, respectively, in a single closed-form analytic expression.",
            "solution": "The user wants to find the mean and variance of the Elmore delay for a specified sink node in an RC interconnect tree, where the resistances and capacitances are subject to statistical variations.\n\n### Step 1: Problem Validation\n\n**1. Extract Givens:**\n- An RC interconnect tree with a source and a sink node $S$.\n- The path from source to sink is an ordered edge set $\\mathcal{P}$, with edges indexed by $k \\in \\{1, 2, \\dots, m\\}$.\n- Edge resistances $R_k$ and nodal capacitances $C_j$ for $j \\in \\{1, 2, \\dots, n\\}$.\n- The downstream set for an edge $k \\in \\mathcal{P}$ is $\\mathcal{D}(k, S)$, the set of indices of capacitances whose charging current flows through edge $k$.\n- The statistical model for resistance $R_k$ is $R_{k} = R_{k,0}(1 + \\alpha_{k} G + \\sum_{p=1}^{P_{r}} \\gamma_{k,p} X_{p})$, where $R_{k,0} > 0$ is the nominal resistance.\n- The statistical model for capacitance $C_j$ is $C_{j} = C_{j,0}(1 + \\beta_{j} G + \\sum_{q=1}^{P_{c}} \\delta_{j,q} Y_{q})$, where $C_{j,0} > 0$ is the nominal capacitance.\n- $G \\sim \\mathcal{N}(0,\\sigma_{G}^{2})$ is a global zero-mean Gaussian random source.\n- $\\{X_{p}\\}_{p=1}^{P_{r}}$ are mutually independent, zero-mean Gaussian random sources with variances $\\sigma_{X_{p}}^{2}$.\n- $\\{Y_{q}\\}_{q=1}^{P_{c}}$ are mutually independent, zero-mean Gaussian random sources with variances $\\sigma_{Y_{q}}^{2}$.\n- All random sources ($G$, $\\{X_p\\}$, $\\{Y_q\\}$) are mutually independent.\n- A first-order linearization is assumed, meaning products of random sources are neglected.\n\n**2. Validate Using Extracted Givens:**\n- **Scientifically Grounded:** The problem is a standard exercise in Statistical Static Timing Analysis (SSTA) for integrated circuits. The Elmore delay is a well-established and fundamental first-order approximation for signal delay in RC networks. The linear canonical model for process variations is a cornerstone of many SSTA methodologies. The problem is firmly rooted in electrical engineering and applied statistics.\n- **Well-Posed:** All necessary parameters, models, and assumptions (Elmore delay definition, statistical models for R and C, independence of random sources, linearization) are explicitly provided to derive a unique solution for the mean and variance.\n- **Objective:** The problem is stated in precise, formal mathematical and engineering terms, free of any subjectivity or ambiguity.\n\n**3. Verdict and Action:**\nThe problem is valid. It is scientifically sound, well-posed, and objective. I will proceed with the derivation of the solution.\n\n### Step 2: Solution Derivation\n\nThe Elmore delay $T_S$ at a sink node $S$ is defined as the sum of $RC$ products over the path from the source to the sink. Specifically, for each resistance $R_k$ on the path $\\mathcal{P}$, it is multiplied by the total capacitance downstream of it.\nThe formula for the Elmore delay $T_S$ is:\n$$\nT_{S} = \\sum_{k \\in \\mathcal{P}} R_{k} \\left( \\sum_{j \\in \\mathcal{D}(k,S)} C_{j} \\right)\n$$\nGiven the indexing $k \\in \\{1, 2, \\dots, m\\}$ for the path $\\mathcal{P}$, we can write this as:\n$$\nT_{S} = \\sum_{k=1}^{m} R_{k} \\left( \\sum_{j \\in \\mathcal{D}(k,S)} C_{j} \\right)\n$$\nThe problem specifies statistical models for $R_k$ and $C_j$. We substitute these into the Elmore delay formula:\n$$\nT_{S} = \\sum_{k=1}^{m} \\left[ R_{k,0}\\left(1 + \\alpha_{k} G + \\sum_{p=1}^{P_{r}} \\gamma_{k,p} X_{p}\\right) \\right] \\left[ \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0}\\left(1 + \\beta_{j} G + \\sum_{q=1}^{P_{c}} \\delta_{j,q} Y_{q}\\right) \\right]\n$$\nThe problem states that we must use a first-order linearization, which means we neglect terms involving products of the random sources (e.g., $G^2$, $GX_p$, $X_p Y_q$, etc.). Let's expand the expression for $T_S$ and keep only the constant and first-order terms in the random variables $G$, $\\{X_p\\}$, and $\\{Y_q\\}$.\nThe product within the summation is of the form $(A_0 + \\Delta A)(B_0 + \\Delta B)$, where $A_0$ and $B_0$ are nominal values and $\\Delta A, \\Delta B$ are linear combinations of the random sources. The first-order approximation is $A_0 B_0 + A_0 \\Delta B + B_0 \\Delta A$.\nFor each term $k$ in the summation:\n- The nominal resistance part is $R_{k,0}$.\n- The nominal downstream capacitance part is $C_{down,0}(k) = \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0}$.\n- The variation in resistance is $\\Delta R_k = R_{k,0} \\left( \\alpha_k G + \\sum_{p=1}^{P_r} \\gamma_{k,p} X_p \\right)$.\n- The variation in downstream capacitance is $\\Delta C_{down}(k) = \\sum_{j \\in \\mathcal{D}(k,S)} \\Delta C_j = \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0} \\left( \\beta_j G + \\sum_{q=1}^{P_c} \\delta_{j,q} Y_q \\right)$.\n\nApplying the first-order approximation to the delay expression:\n$$\nT_S \\approx \\sum_{k=1}^{m} \\left( R_{k,0} C_{down,0}(k) + R_{k,0} \\Delta C_{down}(k) + C_{down,0}(k) \\Delta R_k \\right)\n$$\nSubstituting the expressions for the variations:\n$$\nT_S \\approx \\sum_{k=1}^{m} R_{k,0} C_{down,0}(k) + \\sum_{k=1}^{m} \\left( R_{k,0} \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0} \\left( \\beta_j G + \\sum_{q=1}^{P_c} \\delta_{j,q} Y_q \\right) + C_{down,0}(k) R_{k,0} \\left( \\alpha_k G + \\sum_{p=1}^{P_r} \\gamma_{k,p} X_p \\right) \\right)\n$$\nLet's group the terms by the random sources to obtain the canonical linear form $T_S \\approx T_{S,0} + S_G G + \\sum_{p=1}^{P_r} S_{X_p} X_p + \\sum_{q=1}^{P_c} S_{Y_q} Y_q$.\n\nThe nominal delay, $T_{S,0}$, is the term with no random variables:\n$$\nT_{S,0} = \\sum_{k=1}^{m} R_{k,0} C_{down,0}(k) = \\sum_{k=1}^{m} R_{k,0} \\left( \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0} \\right)\n$$\nThe sensitivity coefficient for the global source $G$, $S_G$, is the coefficient of $G$:\n$$\nS_G = \\sum_{k=1}^{m} \\left( R_{k,0} \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0} \\beta_j + C_{down,0}(k) R_{k,0} \\alpha_k \\right) = \\sum_{k=1}^{m} \\left( \\alpha_k R_{k,0} \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0} + R_{k,0} \\sum_{j \\in \\mathcal{D}(k,S)} \\beta_j C_{j,0} \\right)\n$$\n$$\nS_G = \\sum_{k=1}^{m} \\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0} C_{j,0} (\\alpha_k + \\beta_j)\n$$\nThe sensitivity coefficient for the local resistance source $X_p$, $S_{X_p}$, is the coefficient of $X_p$:\n$$\nS_{X_p} = \\sum_{k=1}^{m} C_{down,0}(k) R_{k,0} \\gamma_{k,p} = \\sum_{k=1}^{m} \\gamma_{k,p} R_{k,0} \\left( \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0} \\right) = \\sum_{k=1}^{m} \\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0} C_{j,0} \\gamma_{k,p}\n$$\nThe sensitivity coefficient for the local capacitance source $Y_q$, $S_{Y_q}$, is the coefficient of $Y_q$:\n$$\nS_{Y_q} = \\sum_{k=1}^{m} R_{k,0} \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0} \\delta_{j,q} = \\sum_{k=1}^{m} \\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0} C_{j,0} \\delta_{j,q}\n$$\n\n**Derivation of the Mean $\\mathbb{E}[T_S]$**\nThe mean of the delay is found by taking the expectation of the linearized expression for $T_S$. By the linearity of expectation:\n$$\n\\mathbb{E}[T_S] \\approx \\mathbb{E}[T_{S,0}] + S_G \\mathbb{E}[G] + \\sum_{p=1}^{P_r} S_{X_p} \\mathbb{E}[X_p] + \\sum_{q=1}^{P_c} S_{Y_q} \\mathbb{E}[Y_q]\n$$\nSince all random sources are defined to be zero-mean ($\\mathbb{E}[G]=0$, $\\mathbb{E}[X_p]=0$, $\\mathbb{E}[Y_q]=0$), the expression simplifies to:\n$$\n\\mathbb{E}[T_S] = T_{S,0} = \\sum_{k=1}^{m} R_{k,0} \\left( \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0} \\right)\n$$\n\n**Derivation of the Variance $\\mathrm{Var}(T_S)$**\nThe variance of a sum of independent random variables is the sum of their variances. Since $G$, $\\{X_p\\}$, and $\\{Y_q\\}$ are mutually independent:\n$$\n\\mathrm{Var}(T_S) \\approx \\mathrm{Var}(T_{S,0} + S_G G + \\sum_{p=1}^{P_r} S_{X_p} X_p + \\sum_{q=1}^{P_c} S_{Y_q} Y_q)\n$$\nThe nominal term $T_{S,0}$ is a constant, so its variance is zero.\n$$\n\\mathrm{Var}(T_S) = \\mathrm{Var}(S_G G) + \\sum_{p=1}^{P_r} \\mathrm{Var}(S_{X_p} X_p) + \\sum_{q=1}^{P_c} \\mathrm{Var}(S_{Y_q} Y_q)\n$$\nUsing the property $\\mathrm{Var}(aZ) = a^2 \\mathrm{Var}(Z)$:\n$$\n\\mathrm{Var}(T_S) = S_G^2 \\mathrm{Var}(G) + \\sum_{p=1}^{P_r} S_{X_p}^2 \\mathrm{Var}(X_p) + \\sum_{q=1}^{P_c} S_{Y_q}^2 \\mathrm{Var}(Y_q)\n$$\nSubstituting the given variances ($\\sigma_G^2$, $\\sigma_{X_p}^2$, $\\sigma_{Y_q}^2$) and the expressions for the sensitivity coefficients:\n$$\n\\mathrm{Var}(T_S) = \\sigma_G^2 S_G^2 + \\sum_{p=1}^{P_r} \\sigma_{X_p}^2 S_{X_p}^2 + \\sum_{q=1}^{P_c} \\sigma_{Y_q}^2 S_{Y_q}^2\n$$\n$$\n\\mathrm{Var}(T_S) = \\sigma_G^2 \\left( \\sum_{k=1}^m \\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0} C_{j,0} (\\alpha_k + \\beta_j) \\right)^2 + \\sum_{p=1}^{P_r} \\sigma_{X_p}^2 \\left( \\sum_{k=1}^m \\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0} C_{j,0} \\gamma_{k,p} \\right)^2 + \\sum_{q=1}^{P_c} \\sigma_{Y_q}^2 \\left( \\sum_{k=1}^m \\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0} C_{j,0} \\delta_{j,q} \\right)^2\n$$\nThe problem asks for the mean in seconds and the variance in square seconds. Since $R_{k,0}$ and $C_{j,0}$ have units of resistance and capacitance respectively, their product $R_{k,0}C_{j,0}$ has units of time (e.g., Ohms $\\times$ Farads = seconds). The sensitivity coefficients $\\alpha, \\beta, \\gamma, \\delta$ and the random sources are dimensionless. Thus, the derived expression for the mean has units of time, and the variance (which involves squared sensitivities and dimensionless source variances) has units of time squared, as required.\n\nFinal expressions for mean and variance are:\n$$\n\\mathbb{E}[T_S] = \\sum_{k=1}^{m} R_{k,0} \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0}\n$$\n$$\n\\mathrm{Var}(T_S) = \\sigma_{G}^{2} \\left[ \\sum_{k=1}^{m}\\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0}C_{j,0}(\\alpha_k + \\beta_j) \\right]^{2} + \\sum_{p=1}^{P_r} \\sigma_{X_{p}}^{2} \\left[ \\sum_{k=1}^{m} \\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0}C_{j,0} \\gamma_{k,p} \\right]^{2} + \\sum_{q=1}^{P_c} \\sigma_{Y_{q}}^{2} \\left[ \\sum_{k=1}^{m} \\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0}C_{j,0} \\delta_{j,q} \\right]^{2}\n$$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\displaystyle\\sum_{k=1}^{m} R_{k,0} \\sum_{j \\in \\mathcal{D}(k,S)} C_{j,0} & \\sigma_{G}^{2} \\left( \\sum_{k=1}^{m}\\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0}C_{j,0}(\\alpha_k + \\beta_j) \\right)^{2} + \\sum_{p=1}^{P_r} \\sigma_{X_{p}}^{2} \\left( \\sum_{k=1}^{m} \\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0}C_{j,0} \\gamma_{k,p} \\right)^{2} + \\sum_{q=1}^{P_c} \\sigma_{Y_{q}}^{2} \\left( \\sum_{k=1}^{m} \\sum_{j \\in \\mathcal{D}(k,S)} R_{k,0}C_{j,0} \\delta_{j,q} \\right)^{2} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "A key advantage of SSTA is its ability to handle correlations between different timing paths, which avoids the excessive pessimism of traditional methods. This practice focuses on the origin of this correlation, demonstrating how shared sources of variation create statistical dependencies between two different arrival times. By deriving the correlation coefficient directly from the sensitivity coefficients of the underlying linear models, you will gain a concrete understanding of this crucial concept. ",
            "id": "4301807",
            "problem": "In Statistical Static Timing Analysis (SSTA) within Electronic Design Automation (EDA), path arrival times are modeled as affine functions of independent random sources representing process, environment, and noise variations. Consider two node arrival times, $T_{A}$ and $T_{B}$, in a synchronous digital integrated circuit. Each arrival time is modeled as an affine transformation of a common set of independent standard normal basis variables that encode global and local variation modes, plus node-specific independent noise.\n\nLet the global variation modes be $X_{1}$ and $X_{2}$ (each $X_{i} \\sim \\mathcal{N}(0,1)$), and two spatial local variation modes be $X_{3}$ (region $R$) and $X_{4}$ (region $S$), each $X_{i} \\sim \\mathcal{N}(0,1)$ and mutually independent. Additionally, node-specific independent noise terms are modeled as $Z_{A} \\sim \\mathcal{N}(0,1)$ and $Z_{B} \\sim \\mathcal{N}(0,1)$, independent of all $X_{i}$ and of each other. The arrival times are given by\n$$\nT_{A} = \\mu_{A} + a_{1} X_{1} + a_{2} X_{2} + a_{3} X_{3} + s_{A} Z_{A},\n$$\n$$\nT_{B} = \\mu_{B} + b_{1} X_{1} + b_{2} X_{2} + b_{4} X_{4} + s_{B} Z_{B},\n$$\nwhere $\\mu_{A}$ and $\\mu_{B}$ are deterministic means, and the coefficients $a_{i}$, $b_{i}$, $s_{A}$, and $s_{B}$ are deterministic sensitivity coefficients with respect to the corresponding standard normal modes. The local mode $X_{3}$ influences node $A$ only (region $R$), and $X_{4}$ influences node $B$ only (region $S$). All random variables listed are mutually independent except for the shared global modes $X_{1}$ and $X_{2}$.\n\nSuppose the sensitivity coefficients are\n$$\na_{1} = 0.8,\\quad a_{2} = 0.5,\\quad a_{3} = 0.4,\\quad s_{A} = 0.3,\n$$\n$$\nb_{1} = 0.7,\\quad b_{2} = 0.6,\\quad b_{4} = 0.5,\\quad s_{B} = 0.2.\n$$\n\nStarting from the definitions of covariance, variance, and the Pearson correlation coefficient for jointly modeled random variables, derive an expression for the correlation coefficient between $T_{A}$ and $T_{B}$ in terms of the sensitivity coefficients and the independence of the basis variables. Then compute the numerical value of the correlation coefficient between $T_{A}$ and $T_{B}$ for the given sensitivity coefficients. Express your final answer as a pure number and round your answer to four significant figures.",
            "solution": "The problem as stated is subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n-   The arrival times $T_{A}$ and $T_{B}$ are modeled as affine functions of independent random sources.\n-   Global variation modes: $X_{1} \\sim \\mathcal{N}(0,1)$, $X_{2} \\sim \\mathcal{N}(0,1)$.\n-   Local variation modes: $X_{3} \\sim \\mathcal{N}(0,1)$, $X_{4} \\sim \\mathcal{N}(0,1)$.\n-   Node-specific independent noise: $Z_{A} \\sim \\mathcal{N}(0,1)$, $Z_{B} \\sim \\mathcal{N}(0,1)$.\n-   All basis random variables ($X_{1}$, $X_{2}$, $X_{3}$, $X_{4}$, $Z_{A}$, $Z_{B}$) are mutually independent.\n-   Arrival time for node A: $T_{A} = \\mu_{A} + a_{1} X_{1} + a_{2} X_{2} + a_{3} X_{3} + s_{A} Z_{A}$.\n-   Arrival time for node B: $T_{B} = \\mu_{B} + b_{1} X_{1} + b_{2} X_{2} + b_{4} X_{4} + s_{B} Z_{B}$.\n-   Coefficients for $T_A$: $a_{1} = 0.8$, $a_{2} = 0.5$, $a_{3} = 0.4$, $s_{A} = 0.3$.\n-   Coefficients for $T_B$: $b_{1} = 0.7$, $b_{2} = 0.6$, $b_{4} = 0.5$, $s_{B} = 0.2$.\n-   The task is to derive the correlation coefficient between $T_{A}$ and $T_{B}$ and then compute its numerical value, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is well-grounded in the theory of statistical static timing analysis (SSTA) for integrated circuits. The use of affine models based on independent Gaussian random variables to represent process variations is a standard and well-established technique in this field. The statistical concepts used (variance, covariance, correlation) are fundamental and correctly applied.\n-   **Well-Posed**: The problem is clearly defined and provides all necessary information (functional forms, distributions of all random variables, and all coefficient values) to derive a unique numerical solution.\n-   **Objective**: The problem is stated using precise mathematical language, free of ambiguity, subjectivity, or opinion-based claims.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. It is scientifically sound, well-posed, and objective. There are no contradictions, missing information, or violations of physical or mathematical principles. I will now proceed with the solution.\n\nThe Pearson correlation coefficient, $\\rho(T_{A}, T_{B})$, between two random variables $T_{A}$ and $T_{B}$ is defined as:\n$$\n\\rho(T_{A}, T_{B}) = \\frac{\\text{Cov}(T_{A}, T_{B})}{\\sqrt{\\text{Var}(T_{A}) \\text{Var}(T_{B})}}\n$$\nwhere $\\text{Var}(\\cdot)$ denotes the variance and $\\text{Cov}(\\cdot, \\cdot)$ denotes the covariance. We must compute the variance of $T_{A}$ and $T_{B}$, and their covariance.\n\nFirst, we determine the expected values of $T_{A}$ and $T_{B}$. The basis random variables $X_{i}$ and $Z_{j}$ are standard normal, so their expected value is $0$.\n$$\nE[T_{A}] = E[\\mu_{A} + a_{1} X_{1} + a_{2} X_{2} + a_{3} X_{3} + s_{A} Z_{A}]\n$$\nBy linearity of expectation:\n$$\nE[T_{A}] = \\mu_{A} + a_{1} E[X_{1}] + a_{2} E[X_{2}] + a_{3} E[X_{3}] + s_{A} E[Z_{A}] = \\mu_{A} + 0 = \\mu_{A}\n$$\nSimilarly, for $T_{B}$:\n$$\nE[T_{B}] = E[\\mu_{B} + b_{1} X_{1} + b_{2} X_{2} + b_{4} X_{4} + s_{B} Z_{B}] = \\mu_{B}\n$$\n\nNext, we compute the variance of $T_{A}$. The variance of a sum of independent random variables is the sum of their variances. Since $\\mu_A$ is a constant, it does not contribute to the variance. The variables $X_{1}$, $X_{2}$, $X_{3}$, and $Z_{A}$ are mutually independent.\n$$\n\\text{Var}(T_{A}) = \\text{Var}(a_{1} X_{1} + a_{2} X_{2} + a_{3} X_{3} + s_{A} Z_{A})\n$$\nUsing the property $\\text{Var}(cY) = c^2 \\text{Var}(Y)$ and the independence of the variables:\n$$\n\\text{Var}(T_{A}) = a_{1}^2 \\text{Var}(X_{1}) + a_{2}^2 \\text{Var}(X_{2}) + a_{3}^2 \\text{Var}(X_{3}) + s_{A}^2 \\text{Var}(Z_{A})\n$$\nSince all basis variables are standard normal, their variance is $1$.\n$$\n\\text{Var}(T_{A}) = a_{1}^2(1) + a_{2}^2(1) + a_{3}^2(1) + s_{A}^2(1) = a_{1}^2 + a_{2}^2 + a_{3}^2 + s_{A}^2\n$$\nBy the same reasoning, the variance of $T_{B}$ is:\n$$\n\\text{Var}(T_{B}) = \\text{Var}(b_{1} X_{1} + b_{2} X_{2} + b_{4} X_{4} + s_{B} Z_{B}) = b_{1}^2 \\text{Var}(X_{1}) + b_{2}^2 \\text{Var}(X_{2}) + b_{4}^2 \\text{Var}(X_{4}) + s_{B}^2 \\text{Var}(Z_{B})\n$$\n$$\n\\text{Var}(T_{B}) = b_{1}^2 + b_{2}^2 + b_{4}^2 + s_{B}^2\n$$\n\nNow, we compute the covariance of $T_{A}$ and $T_{B}$.\n$$\n\\text{Cov}(T_{A}, T_{B}) = E[(T_{A} - E[T_{A}])(T_{B} - E[T_{B}])]\n$$\n$$\n\\text{Cov}(T_{A}, T_{B}) = E[(a_{1} X_{1} + a_{2} X_{2} + a_{3} X_{3} + s_{A} Z_{A})(b_{1} X_{1} + b_{2} X_{2} + b_{4} X_{4} + s_{B} Z_{B})]\n$$\nExpanding the product and applying the linearity of expectation, we get a sum of terms like $E[c_{i}d_{j}V_{i}W_{j}]$, where $V_i$ and $W_j$ are basis random variables. Since all basis variables are independent and have zero mean, the expectation of any cross-product of different variables is zero. For example, $E[X_{1}X_{2}] = E[X_{1}]E[X_{2}] = 0 \\times 0 = 0$. The only non-zero terms arise from the products of a variable with itself. The shared variables between the expressions for $T_A$ and $T_B$ are $X_1$ and $X_2$.\n$$\n\\text{Cov}(T_{A}, T_{B}) = E[a_{1}b_{1} X_{1}^2 + a_{2}b_{2} X_{2}^2 + \\text{other cross-product terms}]\n$$\n$$\n\\text{Cov}(T_{A}, T_{B}) = a_{1}b_{1}E[X_{1}^2] + a_{2}b_{2}E[X_{2}^2]\n$$\nFor a standard normal variable $X$, $\\text{Var}(X) = E[X^2] - (E[X])^2$. With $\\text{Var}(X) = 1$ and $E[X] = 0$, we have $E[X^2] = 1$.\nTherefore, the covariance is:\n$$\n\\text{Cov}(T_{A}, T_{B}) = a_{1}b_{1} + a_{2}b_{2}\n$$\nNow we can write the general expression for the correlation coefficient:\n$$\n\\rho(T_{A}, T_{B}) = \\frac{a_{1}b_{1} + a_{2}b_{2}}{\\sqrt{(a_{1}^2 + a_{2}^2 + a_{3}^2 + s_{A}^2)(b_{1}^2 + b_{2}^2 + b_{4}^2 + s_{B}^2)}}\n$$\nWe now substitute the given numerical values for the sensitivity coefficients:\n$a_{1} = 0.8$, $a_{2} = 0.5$, $a_{3} = 0.4$, $s_{A} = 0.3$\n$b_{1} = 0.7$, $b_{2} = 0.6$, $b_{4} = 0.5$, $s_{B} = 0.2$\n\nCalculate the covariance:\n$$\n\\text{Cov}(T_{A}, T_{B}) = (0.8)(0.7) + (0.5)(0.6) = 0.56 + 0.30 = 0.86\n$$\nCalculate the variance of $T_A$:\n$$\n\\text{Var}(T_{A}) = (0.8)^2 + (0.5)^2 + (0.4)^2 + (0.3)^2 = 0.64 + 0.25 + 0.16 + 0.09 = 1.14\n$$\nCalculate the variance of $T_B$:\n$$\n\\text{Var}(T_{B}) = (0.7)^2 + (0.6)^2 + (0.5)^2 + (0.2)^2 = 0.49 + 0.36 + 0.25 + 0.04 = 1.14\n$$\nNow, compute the correlation coefficient:\n$$\n\\rho(T_{A}, T_{B}) = \\frac{0.86}{\\sqrt{(1.14)(1.14)}} = \\frac{0.86}{1.14}\n$$\n$$\n\\rho(T_{A}, T_{B}) \\approx 0.75438596...\n$$\nRounding the result to four significant figures gives $0.7544$.",
            "answer": "$$\n\\boxed{0.7544}\n$$"
        },
        {
            "introduction": "With models for individual delays and their correlations, the next step is to propagate these statistical distributions through the circuit graph. This exercise simulates the fundamental computational step at a logic gate's fan-in, where the latest arrival time must be determined from multiple correlated input signals. You will practice applying both the statistical `sum` (for path delays) and the non-trivial `max` operators to see how a new statistical arrival time is computed, completing the core analysis loop of SSTA. ",
            "id": "4301929",
            "problem": "Consider Statistical Static Timing Analysis (SSTA) on a two-fanin timing graph where random delays are modeled by Canonical Linear Forms (CLFs). In a CLF, a random delay is represented as $X = \\mu + \\sum_i \\alpha_i Z_i$, where $\\mu$ is a deterministic mean, each $\\alpha_i$ is a deterministic sensitivity, and each $Z_i$ is an independent standard normal random variable $Z_i \\sim \\mathcal{N}(0,1)$. Arrival times at a node are computed by repeated application of the sum over edge delays and the maximum over fan-in arrivals, while consistently tracking correlations by maintaining a common basis of shared $Z_i$ across the graph.\n\nYou are given two source nodes, $\\text{A}$ and $\\text{B}$, that feed a sink node $\\text{S}$ through edges $\\text{A}\\to \\text{S}$ and $\\text{B}\\to \\text{S}$. All randomness is decomposed into a single global process component $Z_g$ shared by all elements, and independent local components per node and per edge. All $Z$’s that are not $Z_g$ are mutually independent and independent of $Z_g$.\n\nSource arrivals:\n- At node $\\text{A}$: $T_{\\text{A}} = 120 + 10 Z_g + 8 Z_{\\text{A}}$ (picoseconds).\n- At node $\\text{B}$: $T_{\\text{B}} = 118 + 10 Z_g + 10 Z_{\\text{B}}$ (picoseconds).\n\nEdge delays:\n- On $\\text{A}\\to \\text{S}$: $D_{\\text{AS}} = 30 + 5 Z_g + 7 Z_{\\text{AS}}$ (picoseconds).\n- On $\\text{B}\\to \\text{S}$: $D_{\\text{BS}} = 35 + 5 Z_g + 6 Z_{\\text{BS}}$ (picoseconds).\n\nAssume the algorithm computes for each node its arrival time CLF by:\n- Summing CLFs along an edge to form path arrival CLFs, thereby preserving the common $Z_g$ and independent local $Z$’s.\n- Taking the maximum of fan-in arrival CLFs at a node, approximating the maximum of two correlated Gaussian random variables by moment-matching of its mean and variance, and constructing a new CLF that preserves correlation to upstream sources by blending the coefficient vectors with a dominance probability and adding, if needed, a new independent standard normal residual to match the total variance.\n\nLet $X = T_{\\text{A}} + D_{\\text{AS}}$ and $Y = T_{\\text{B}} + D_{\\text{BS}}$ denote the two path arrival CLFs into $\\text{S}$. Among the algorithmic outputs below, which CLF is the correct arrival time at node $\\text{S}$ produced by such a correlation-tracking SSTA algorithm?\n\nA. $T_{\\text{S}} = 157.911 + 15 Z_g + 3.4 Z_{\\text{A}} + 2.975 Z_{\\text{AS}} + 5.75 Z_{\\text{B}} + 3.45 Z_{\\text{BS}} + 4.683 Z_{\\text{R}}$ (picoseconds).\n\nB. $T_{\\text{S}} = 157.911 + 15 Z_g + 3.4 Z_{\\text{A}} + 2.975 Z_{\\text{AS}} + 5.75 Z_{\\text{B}} + 3.45 Z_{\\text{BS}}$ (picoseconds).\n\nC. $T_{\\text{S}} = 153 + 15 Z_g + 10 Z_{\\text{B}} + 6 Z_{\\text{BS}}$ (picoseconds).\n\nD. $T_{\\text{S}} = 151.725 + 15 Z_g + 3.4 Z_{\\text{A}} + 2.975 Z_{\\text{AS}} + 5.75 Z_{\\text{B}} + 3.45 Z_{\\text{BS}}$ (picoseconds).\n\nNotes:\n- Each coefficient multiplies the indicated standard normal $Z$.\n- $Z_{\\text{R}}$ (if present) denotes a new independent standard normal that is not used elsewhere.\n- All numerical values are rounded to three decimal places where applicable.",
            "solution": "The user wants me to solve a problem related to statistical static timing analysis (SSTA).\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem statement provides the following information:\n-   **Model**: Statistical delays are represented by Canonical Linear Forms (CLFs) of the type $X = \\mu + \\sum_i \\alpha_i Z_i$, where $Z_i \\sim \\mathcal{N}(0,1)$ are independent standard normal random variables.\n-   **Graph**: A sink node $\\text{S}$ is fed by two source nodes, $\\text{A}$ and $\\text{B}$, through edges $\\text{A}\\to \\text{S}$ and $\\text{B}\\to \\text{S}$.\n-   **Random Sources**:\n    -   $Z_g$: A single global random variable.\n    -   $Z_{\\text{A}}, Z_{\\text{B}}, Z_{\\text{AS}}, Z_{\\text{BS}}$: Local random variables, mutually independent and independent of $Z_g$.\n-   **Source Arrival Times (CLFs)**:\n    -   $T_{\\text{A}} = 120 + 10 Z_g + 8 Z_{\\text{A}}$ (picoseconds).\n    -   $T_{\\text{B}} = 118 + 10 Z_g + 10 Z_{\\text{B}}$ (picoseconds).\n-   **Edge Delays (CLFs)**:\n    -   $D_{\\text{AS}} = 30 + 5 Z_g + 7 Z_{\\text{AS}}$ (picoseconds).\n    -   $D_{\\text{BS}} = 35 + 5 Z_g + 6 Z_{\\text{BS}}$ (picoseconds).\n-   **Path Arrival Times**:\n    -   $X = T_{\\text{A}} + D_{\\text{AS}}$\n    -   $Y = T_{\\text{B}} + D_{\\text{BS}}$\n-   **Sink Arrival Time**: The arrival time at node $\\text{S}$ is $T_{\\text{S}} = \\max(X, Y)$.\n-   **Algorithm for `max` operation**: The maximum of two correlated Gaussian random variables is approximated by a new CLF. This new CLF is constructed by:\n    1.  Matching the mean and variance of the exact distribution of $\\max(X, Y)$.\n    2.  Blending the coefficient vectors of the input CLFs based on a dominance probability.\n    3.  Adding a new independent residual random variable, $Z_{\\text{R}}$, if necessary, to match the target variance.\n\n**Step 2: Validate Using Extracted Givens**\n\n-   **Scientifically Grounded**: The problem is well-grounded in the field of Electronic Design Automation (EDA), specifically SSTA. The use of CLFs, decomposition into global and local variations, and moment-matching for the `max` operator are standard, established techniques (e.g., the methods proposed by Visweswariah et al.).\n-   **Well-Posed**: The problem provides all necessary inputs (CLFs for sources and edges) and a clear description of the algorithms (summation and `max` approximation) required to find a unique solution.\n-   **Objective**: The problem is stated using precise mathematical and engineering terminology, with no subjective or ambiguous language.\n-   **Completeness and Consistency**: The setup is complete and internally consistent. No information is missing or contradictory.\n-   **Realism**: The numerical values for delays and sensitivities are plausible for integrated circuit timing analysis.\n-   **Structure**: The problem is well-structured and non-trivial, requiring multi-step calculations involving statistical properties of Gaussian variables.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It is a standard, well-defined problem in SSTA. The solution derivation can proceed.\n\n### Solution Derivation\n\nThe solution requires calculating the CLF for $T_{\\text{S}} = \\max(X, Y)$, where $X$ and $Y$ are correlated Gaussian random variables.\n\n**1. Calculate Path Arrival Time CLFs, $X$ and $Y$**\n\nThe arrival time along a path is the sum of the source arrival time and the edge delay.\n-   For path $\\text{A}\\to \\text{S}$:\n    $X = T_{\\text{A}} + D_{\\text{AS}} = (120 + 10 Z_g + 8 Z_{\\text{A}}) + (30 + 5 Z_g + 7 Z_{\\text{AS}})$\n    $$X = 150 + 15 Z_g + 8 Z_{\\text{A}} + 7 Z_{\\text{AS}}$$\n-   For path $\\text{B}\\to \\text{S}$:\n    $Y = T_{\\text{B}} + D_{\\text{BS}} = (118 + 10 Z_g + 10 Z_{\\text{B}}) + (35 + 5 Z_g + 6 Z_{\\text{BS}})$\n    $$Y = 153 + 15 Z_g + 10 Z_{\\text{B}} + 6 Z_{\\text{BS}}$$\n\n**2. Characterize $X$ and $Y$ as Correlated Gaussian Random Variables**\n\nSince $X$ and $Y$ are linear combinations of independent Gaussian random variables, they are themselves Gaussian, $X \\sim \\mathcal{N}(\\mu_X, \\sigma_X^2)$ and $Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y^2)$.\n-   **Means**:\n    $\\mu_X = E[X] = 150$ ps.\n    $\\mu_Y = E[Y] = 153$ ps.\n-   **Variances**: The variance of a CLF is the sum of the squares of its sensitivities, as $Z_i$ are independent and have variance $1$.\n    $\\sigma_X^2 = \\text{Var}(X) = 15^2 + 8^2 + 7^2 = 225 + 64 + 49 = 338 \\, \\text{ps}^2$.\n    $\\sigma_Y^2 = \\text{Var}(Y) = 15^2 + 10^2 + 6^2 = 225 + 100 + 36 = 361 \\, \\text{ps}^2$.\n-   **Covariance**: The covariance is due to the shared random variable $Z_g$.\n    $\\text{Cov}(X, Y) = E[(X-\\mu_X)(Y-\\mu_Y)] = E[(15 Z_g + 8 Z_{\\text{A}} + 7 Z_{\\text{AS}})(15 Z_g + 10 Z_{\\text{B}} + 6 Z_{\\text{BS}})]$.\n    Since all $Z_i$ except $Z_g$ are independent, all cross-terms like $E[Z_g Z_A]$ are $0$.\n    $\\text{Cov}(X, Y) = E[15 Z_g \\cdot 15 Z_g] = 225 \\cdot E[Z_g^2] = 225 \\cdot 1 = 225 \\, \\text{ps}^2$.\n\n**3. Calculate Moments of $T_{\\text{S}} = \\max(X, Y)$**\n\nThe standard formulas for the moments of the maximum of two correlated Gaussian variables are used. Let $W = X - Y$. Then $W \\sim \\mathcal{N}(\\mu_W, \\sigma_W^2)$.\n-   $\\mu_W = \\mu_X - \\mu_Y = 150 - 153 = -3$ ps.\n-   $\\sigma_W^2 = \\text{Var}(X-Y) = \\sigma_X^2 + \\sigma_Y^2 - 2 \\text{Cov}(X, Y) = 338 + 361 - 2(225) = 699 - 450 = 249 \\, \\text{ps}^2$.\n-   $\\sigma_W = \\sqrt{249} \\approx 15.7797$ ps.\n\nLet $\\alpha = \\frac{\\mu_W}{\\sigma_W} = \\frac{-3}{\\sqrt{249}} \\approx -0.190117$.\nWe use the standard normal CDF $\\Phi(z)$ and PDF $\\phi(z)$. The dominance probability of $X$ over $Y$ is $p_d = P(X>Y) = P(W>0) = \\Phi(\\alpha)$.\n-   $p_d = \\Phi(-0.190117) \\approx 0.4246$. The problem states rounding to 3 decimal places, which yields $p_d \\approx 0.425$. The coefficients in the options confirm this rounded value is used for blending.\n-   $\\phi(\\alpha) = \\phi(-0.190117) \\approx 0.39176$.\n\nThe mean and variance of $T_\\text{S}$ are:\n-   $\\mu_{T_S} = E[\\max(X, Y)] = \\mu_X p_d + \\mu_Y (1-p_d) + \\sigma_W \\phi(\\alpha)$.\n    Using the likely intended $p_d=0.425$ and the corresponding $\\alpha = \\Phi^{-1}(0.425) \\approx -0.1893$ and $\\phi(-0.1893) \\approx 0.39185$:\n    $\\mu_{T_S} \\approx 150(0.425) + 153(0.575) + \\sqrt{249}(0.39185) = 63.75 + 87.975 + 6.1837 = 157.9087$ ps.\n    This value is extremely close to the $157.911$ ps given in options A and B. The small difference is attributable to rounding conventions.\n-   $\\sigma^2_{T_S} = \\text{Var}[\\max(X, Y)] = (\\mu_X^2 + \\sigma_X^2)p_d + (\\mu_Y^2 + \\sigma_Y^2)(1-p_d) + (\\mu_X+\\mu_Y)\\sigma_W\\phi(\\alpha) - \\mu_{T_S}^2$.\n    Using $p_d=0.425$, its corresponding $\\phi(\\alpha)$, and our calculated $\\mu_{T_S}$:\n    $\\sigma^2_{T_S} \\approx (150^2+338)(0.425) + (153^2+361)(0.575) + (150+153)\\sqrt{249}(0.39185) - (157.9087)^2$\n    $\\sigma^2_{T_S} \\approx (22838)(0.425) + (23770)(0.575) + (303)(6.1837) - 24935.15$\n    $\\sigma^2_{T_S} \\approx 9706.15 + 13667.75 + 1873.66 - 24935.15 = 312.41 \\, \\text{ps}^2$.\n\n**4. Construct the Final CLF for $T_{\\text{S}}$**\n\nThe final CLF has the form $T_S = \\mu_{T_S} + \\sum \\beta_i Z_i + \\beta_R Z_R$.\n-   **Mean**: $\\mu_{T_S} \\approx 157.909$ ps, consistent with the options' $157.911$ ps.\n-   **Blended Sensitivities**: The sensitivities $\\beta_i$ are a blend of the sensitivities of $X$ ($\\vec{\\alpha}_X$) and $Y$ ($\\vec{\\alpha}_Y$) using the dominance probabilities. Let $p_d=0.425$ and $1-p_d=0.575$.\n    $\\vec{\\alpha}_X = (15, 8, 7, 0, 0)$ for $(Z_g, Z_A, Z_{AS}, Z_B, Z_{BS})$.\n    $\\vec{\\alpha}_Y = (15, 0, 0, 10, 6)$ for $(Z_g, Z_A, Z_{AS}, Z_B, Z_{BS})$.\n    $\\beta_g = p_d(15) + (1-p_d)(15) = 15$.\n    $\\beta_{\\text{A}} = p_d(8) + (1-p_d)(0) = 0.425 \\times 8 = 3.4$.\n    $\\beta_{\\text{AS}} = p_d(7) + (1-p_d)(0) = 0.425 \\times 7 = 2.975$.\n    $\\beta_{\\text{B}} = p_d(0) + (1-p_d)(10) = 0.575 \\times 10 = 5.75$.\n    $\\beta_{\\text{BS}} = p_d(0) + (1-p_d)(6) = 0.575 \\times 6 = 3.45$.\n    The CLF constructed from this blending, $T_{S, \\text{blend}} = \\mu_{T_S} + 15Z_g + 3.4Z_{\\text{A}} + 2.975Z_{\\text{AS}} + 5.75Z_{\\text{B}} + 3.45Z_{\\text{BS}}$, has a variance of:\n    $\\sigma^2_{T_{S, \\text{blend}}} = 15^2 + 3.4^2 + 2.975^2 + 5.75^2 + 3.45^2 = 225 + 11.56 + 8.850625 + 33.0625 + 11.9025 = 290.375625 \\, \\text{ps}^2$.\n-   **Residual Term**: The variance of the blended CLF ($290.38 \\, \\text{ps}^2$) is less than the target variance of the true maximum ($312.41 \\, \\text{ps}^2$). A residual term is needed to match the variance.\n    $\\sigma_R^2 = \\sigma^2_{T_S} - \\sigma^2_{T_{S, \\text{blend}}} = 312.41 - 290.38 = 22.03 \\, \\text{ps}^2$.\n    The coefficient for the new independent random variable $Z_R$ is $\\beta_R$.\n    $\\beta_R = \\sqrt{\\sigma_R^2} = \\sqrt{22.03} \\approx 4.694$ ps.\n    This is very close to the value $4.683$ given in option A. Squaring the option's value gives $\\beta_R^2 = 4.683^2 \\approx 21.93 \\, \\text{ps}^2$, which is also very close to our calculated residual variance.\n\n**5. Assembled CLF and Option Evaluation**\n\nOur derived CLF is approximately:\n$T_S \\approx 157.909 + 15 Z_g + 3.4 Z_{\\text{A}} + 2.975 Z_{\\text{AS}} + 5.75 Z_{\\text{B}} + 3.45 Z_{\\text{BS}} + 4.694 Z_{\\text{R}}$.\nThis result aligns very closely with Option A. The minor numerical differences are inconsequential and are expected from rounding in intermediate steps or function approximations.\n\n**A. $T_{\\text{S}} = 157.911 + 15 Z_g + 3.4 Z_{\\text{A}} + 2.975 Z_{\\text{AS}} + 5.75 Z_{\\text{B}} + 3.45 Z_{\\text{BS}} + 4.683 Z_{\\text{R}}$ (picoseconds).**\nThis option correctly identifies the mean of the maximum distribution (within rounding tolerance), correctly calculates the blended sensitivities based on the dominance probability, and correctly includes a residual term to match the variance of the true maximum. The numerical values match our derivation very closely.\n**Verdict: Correct.**\n\n**B. $T_{\\text{S}} = 157.911 + 15 Z_g + 3.4 Z_{\\text{A}} + 2.975 Z_{\\text{AS}} + 5.75 Z_{\\text{B}} + 3.45 Z_{\\text{BS}}$ (picoseconds).**\nThis option has the correct mean and blended sensitivities but incorrectly omits the residual random variable $Z_R$. As calculated, the variance of this blended-only CLF ($290.38 \\, \\text{ps}^2$) does not match the target variance of $\\max(X, Y)$ (approx. $312.4 \\, \\text{ps}^2$). The algorithm explicitly states a residual should be added if needed.\n**Verdict: Incorrect.**\n\n**C. $T_{\\text{S}} = 153 + 15 Z_g + 10 Z_{\\text{B}} + 6 Z_{\\text{BS}}$ (picoseconds).**\nThis is the CLF for path $Y$ ($T_Y$). This choice would be equivalent to a deterministic analysis where the path with the larger mean delay is chosen as the result. This approach completely ignores the statistical nature of the `max` operation and the contribution from path $X$.\n**Verdict: Incorrect.**\n\n**D. $T_{\\text{S}} = 151.725 + 15 Z_g + 3.4 Z_{\\text{A}} + 2.975 Z_{\\text{AS}} + 5.75 Z_{\\text{B}} + 3.45 Z_{\\text{BS}}$ (picoseconds).**\nThis option uses the correct blended sensitivities. However, its mean, $\\mu=151.725$ ps, is the simple linear blend of the input means: $\\mu_X p_d + \\mu_Y (1-p_d) = 150(0.425) + 153(0.575) = 151.725$. This is not the correct mean of $\\max(X, Y)$; it is missing the positive term $\\sigma_W \\phi(\\alpha)$, which accounts for the variability. The mean of the maximum is always greater than or equal to the maximum of the means.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}