{
    "hands_on_practices": [
        {
            "introduction": "The fidelity of pattern transfer begins with the optical aerial image. This exercise addresses a fundamental challenge in photolithography: ensuring that features print consistently regardless of their proximity to other patterns. You will implement a Fourier optics-based imaging simulator to find the optimal size and placement of Sub-Resolution Assist Features (SRAFs), providing a foundational, hands-on understanding of how Optical Proximity Correction (OPC) techniques engineer the aerial image to improve pattern fidelity. ",
            "id": "4288223",
            "problem": "An isolated line on a binary optical mask often exhibits an aerial image environment different from that of a line embedded in a dense periodic pattern under partially coherent illumination. Sub-Resolution Assist Features (SRAF) can be added near the isolated line to adjust its aerial image environment. Consider one-dimensional scalar imaging consistent with the Hopkins formulation of partially coherent imaging. Use the following fundamental base: the pupil cutoff spatial frequency is $f_{\\mathrm{c}} = \\mathrm{NA}/\\lambda$, the partially coherent source is modeled as a uniform one-dimensional distribution of point sources each with spatial frequency shift $k_{\\mathrm{s}} \\in [-\\sigma f_{\\mathrm{c}}, \\sigma f_{\\mathrm{c}}]$, and the partially coherent aerial image is the incoherent average of coherent images from each source point. For a single source point, the coherent image amplitude is the inverse Fourier transform of the product of the pupil function and the object spectrum shifted by $k_{\\mathrm{s}}$, where a spatial modulation by $\\exp\\left(i 2\\pi k_{\\mathrm{s}} x\\right)$ in real space implements the spectrum shift.\n\nModel the mask transmittance $t(x)$ as a binary function in one dimension. For the dense pattern, construct a periodic line-space mask with line width $W$ and pitch $P$ centered so that a line is at $x=0$. For the isolated pattern with SRAF, construct an isolated main line of width $W$ centered at $x=0$, and two identical SRAF lines of width $w$ placed symmetrically at centers $x = \\pm \\left(\\frac{W}{2} + d + \\frac{w}{2}\\right)$, where $d$ is the gap between the main line edge and the nearest SRAF edge. Use a scalar imaging model with a real, circular pupil in one dimension given by $P(f) = 1$ for $|f| \\le f_{\\mathrm{c}}$ and $P(f) = 0$ otherwise. For each source point $k_{\\mathrm{s}}$, form the modulated object field $u(x) = t(x)\\exp\\left(i 2\\pi k_{\\mathrm{s}} x\\right)$, take the Fourier transform $U(f)$, apply the pupil $U(f)P(f)$, and inverse transform to get the coherent amplitude $a_{k_{\\mathrm{s}}}(x)$. The partially coherent aerial image is $I(x) = \\frac{1}{N_{\\mathrm{s}}}\\sum_{k_{\\mathrm{s}}} \\left|a_{k_{\\mathrm{s}}}(x)\\right|^{2}$ for $N_{\\mathrm{s}}$ uniformly spaced source samples.\n\nDefine the environment-equality objective as the mean squared difference between the normalized aerial images of the isolated-with-SRAF and dense masks inside a symmetric window $[-L_{\\mathrm{w}}, L_{\\mathrm{w}}]$ about $x=0$, where normalization divides each image by its maximum inside the window. Impose a non-printing constraint by requiring the normalized intensity at each SRAF center to be strictly less than a threshold $I_{\\mathrm{th}}$; otherwise, add a large penalty to the objective. Search over a discrete grid of candidate SRAF widths $w$ and offsets $d$ and select the pair $(d^{\\star}, w^{\\star})$ that minimizes the penalized objective.\n\nUse the following scientifically realistic parameters and units, and express all mask dimensions and outputs in nanometers (nm). Angles are not used. The computational spatial sampling step must be $dx = 1$ nm, and the domain length must be $N \\cdot dx$ with $N = 2048$ samples. The pupil cutoff frequency is in cycles per nanometer. Use $N_{\\mathrm{s}} = 11$ equally spaced source samples spanning $[-\\sigma f_{\\mathrm{c}}, \\sigma f_{\\mathrm{c}}]$. Use a penalty of $J_{\\text{pen}} = 1000$ added to the objective if the non-printing constraint is violated. The dense mask is periodic with pitch $P$, implemented across the entire computational domain. The isolated mask contains only the main line and the two SRAF lines.\n\nTest Suite:\n- Case 1: Wavelength $\\lambda = 193$ nm, Numerical Aperture (NA) $\\text{NA} = 0.85$, partial coherence $\\sigma = 0.30$, main line width $W = 90$ nm, dense pitch $P = 220$ nm, window half-width $L_{\\mathrm{w}} = 400$ nm, SRAF width candidates $w \\in \\{12, 16, 20, 24, 28\\}$ nm, SRAF offset candidates $d \\in \\{60, 70, 80, 90, 100, 110, 120, 130, 140, 150\\}$ nm, non-printing threshold $I_{\\text{th}} = 0.35$.\n- Case 2: $\\lambda = 193$ nm, $\\text{NA} = 0.85$, $\\sigma = 0.60$, $W = 90$ nm, $P = 220$ nm, $L_{\\mathrm{w}} = 400$ nm, $w \\in \\{12, 16, 20, 24, 28\\}$ nm, $d \\in \\{60, 70, 80, 90, 100, 110, 120, 130, 140, 150\\}$ nm, $I_{\\text{th}} = 0.35$.\n- Case 3: $\\lambda = 193$ nm, $\\text{NA} = 0.85$, $\\sigma = 0.20$, $W = 70$ nm, $P = 200$ nm, $L_{\\mathrm{w}} = 400$ nm, $w \\in \\{12, 16, 20, 24, 28\\}$ nm, $d \\in \\{60, 70, 80, 90, 100, 110, 120, 130, 140, 150\\}$ nm, $I_{\\text{th}} = 0.35$.\n- Case 4: $\\lambda = 193$ nm, $\\text{NA} = 0.85$, $\\sigma = 0.80$, $W = 100$ nm, $P = 240$ nm, $L_{\\mathrm{w}} = 400$ nm, $w \\in \\{12, 16, 20, 24, 28\\}$ nm, $d \\in \\{60, 70, 80, 90, 100, 110, 120, 130, 140, 150\\}$ nm, $I_{\\text{th}} = 0.35$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each result is a two-element list $[d^{\\star}, w^{\\star}]$ for the corresponding test case, expressed in nanometers as floating-point numbers. For example, the output format is $[[d_1,w_1],[d_2,w_2],[d_3,w_3],[d_4,w_4]]$ with no additional text.\n\nAll calculations must adhere to the stated model and units. Round each reported $d^{\\star}$ and $w^{\\star}$ to one decimal place before output.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of Fourier optics and partially coherent imaging, specifically the Hopkins formulation, which is a standard model in photolithography simulation. The problem is well-posed, providing a clear objective function, a defined search space, and all necessary physical and computational parameters. The terminology is precise, and the setup is self-contained and free of contradictions. The given parameters are realistic for modern semiconductor manufacturing processes.\n\nThe solution proceeds by first constructing a computational model of the one-dimensional scalar imaging system. This involves defining the spatial and frequency domains, the optical pupil, and the partially coherent light source. Subsequently, we simulate the aerial images for two types of masks: a reference dense pattern and an isolated pattern augmented with Sub-Resolution Assist Features (SRAFs). The goal is to find the SRAF geometry (width $w$ and placement $d$) that makes the aerial image of the isolated line most closely match that of the dense line, subject to the constraint that the SRAFs themselves do not print.\n\nThe core of the solution is the calculation of the partially coherent aerial image $I(x)$, which is based on the Hopkins model. The source is discretized into $N_{\\mathrm{s}}$ point sources, each indexed by its spatial frequency shift $k_{\\mathrm{s}}$. For each source point, a coherent imaging calculation is performed, and the final partially coherent image is the sum of the intensities from all source points.\n\nThe procedure is as follows:\n\n1.  **System Setup**:\n    A one-dimensional spatial domain is established with coordinate $x$, consisting of $N = 2048$ samples with a step size of $dx = 1$ nm. This spans from $-1024$ nm to $1023$ nm. The corresponding frequency domain, with coordinate $f$, is determined using the properties of the Discrete Fourier Transform. The pupil cutoff frequency is calculated as $f_{\\mathrm{c}} = \\mathrm{NA}/\\lambda$. The pupil function $P(f)$ is defined as a binary filter, being $1$ for $|f| \\le f_{\\mathrm{c}}$ and $0$ otherwise. The partially coherent source is modeled as $N_{\\mathrm{s}} = 11$ discrete point sources uniformly distributed in the frequency range $[-\\sigma f_{\\mathrm{c}}, \\sigma f_{\\mathrm{c}}]$.\n\n2.  **Mask Transmittance Functions**:\n    The mask patterns are represented by binary transmittance functions, $t(x)$, where $t(x)=1$ for transmissive areas (clear) and $t(x)=0$ for opaque areas.\n    -   **Dense Mask** ($t_{\\mathrm{dense}}(x)$): A periodic line-space pattern with pitch $P$ and line width $W$ is created across the entire computational domain. A line is centered at $x=0$.\n    -   **Isolated-SRAF Mask** ($t_{\\mathrm{iso}}(x)$): For each pair of SRAF parameters $(d, w)$ from the candidate grids, a mask is constructed. It consists of a central main feature of width $W$ and two SRAFs of width $w$. The SRAFs are placed symmetrically about the origin at center positions $x_{\\mathrm{sraf}} = \\pm \\left(\\frac{W}{2} + d + \\frac{w}{2}\\right)$.\n\n3.  **Aerial Image Calculation**:\n    A function is implemented to calculate the aerial image $I(x)$ for a given mask transmittance $t(x)$.\n    - The process iterates through each source point $k_{\\mathrm{s}}$.\n    - For each $k_{\\mathrm{s}}$, the object field is modulated by the off-axis illumination phase factor: $u_{k_{\\mathrm{s}}}(x) = t(x) \\exp(i 2\\pi k_{\\mathrm{s}} x)$.\n    - The Fourier Transform of this modulated field, $U_{k_{\\mathrm{s}}}(f) = \\mathcal{F}\\{u_{k_{\\mathrm{s}}}(x)\\}$, is computed. This is equivalent to shifting the object spectrum, $\\mathcal{F}\\{t(x)\\}$, by $k_{\\mathrm{s}}$.\n    - The spectrum is then filtered by the pupil function: $U_{\\mathrm{filtered}}(f) = U_{k_{\\mathrm{s}}}(f) \\cdot P(f)$.\n    - The Inverse Fourier Transform of the filtered spectrum yields the coherent image amplitude: $a_{k_{\\mathrm{s}}}(x) = \\mathcal{F}^{-1}\\{U_{\\mathrm{filtered}}(f)\\}$.\n    - The intensity $|a_{k_{\\mathrm{s}}}(x)|^2$ from this source point is added to a running total.\n    - After summing contributions from all source points, the total intensity is averaged: $I(x) = \\frac{1}{N_{\\mathrm{s}}} \\sum_{k_{\\mathrm{s}}} |a_{k_{\\mathrm{s}}}(x)|^2$.\n    The Fast Fourier Transform (FFT) algorithm is used for numerical computation, with appropriate shifting (`fftshift`, `ifftshift`) to handle centered coordinate systems.\n\n4.  **Optimization via Grid Search**:\n    The optimal SRAF parameters ($d^{\\star}, w^{\\star}$) are determined by minimizing a penalized objective function over the provided discrete grid of $(d, w)$ values.\n    - First, the aerial image for the dense pattern, $I_{\\mathrm{dense}}(x)$, is calculated and serves as the target.\n    - The optimization loop iterates through each candidate pair $(d, w)$.\n    - For each pair, the corresponding isolated-SRAF mask $t_{\\mathrm{iso}}(x)$ is generated, and its aerial image $I_{\\mathrm{iso}}(x)$ is calculated.\n    - Both $I_{\\mathrm{dense}}(x)$ and $I_{\\mathrm{iso}}(x)$ are normalized by dividing each by its own maximum value within the evaluation window $[-L_{\\mathrm{w}}, L_{\\mathrm{w}}]$. Let these be $I_{\\mathrm{dense,norm}}(x)$ and $I_{\\mathrm{iso,norm}}(x)$.\n    - **Non-Printing Constraint**: The normalized intensity of the SRAF, evaluated at its center, $I_{\\mathrm{iso,norm}}(x_{\\mathrm{sraf}})$, must be less than the threshold $I_{\\mathrm{th}} = 0.35$.\n    - **Objective Function**: The primary objective is the mean squared error (MSE) between the two normalized images within the window:\n      $$ \\text{MSE} = \\frac{1}{M} \\sum_{x_j \\in [-L_{\\mathrm{w}}, L_{\\mathrm{w}}]} \\left( I_{\\mathrm{iso,norm}}(x_j) - I_{\\mathrm{dense,norm}}(x_j) \\right)^2 $$\n      where $M$ is the number of sample points in the window.\n    - A large penalty, $J_{\\mathrm{pen}} = 1000$, is added to the MSE if the non-printing constraint is violated.\n    - The pair $(d, w)$ that yields the minimum penalized objective is selected as the optimal solution $(d^{\\star}, w^{\\star})$ for the given test case.\n\nThis procedure is repeated for each of the four test cases specified, and the resulting optimal pairs are collected and formatted for the final output.",
            "answer": "```python\nimport numpy as np\nfrom scipy import fft\n\ndef calculate_aerial_image(t, x, f_shifted, pupil, ks_list):\n    \"\"\"\n    Calculates the partially coherent aerial image using the Hopkins model.\n    \"\"\"\n    N = len(x)\n    total_intensity = np.zeros(N, dtype=np.float64)\n\n    for ks in ks_list:\n        # 1. Modulate object field by the source\n        illumination_phase = np.exp(1j * 2 * np.pi * ks * x)\n        u_ks = t * illumination_phase\n\n        # 2. Compute object spectrum (FFT)\n        # Use ifftshift before FFT for centered spatial input\n        U_ks = fft.fftshift(fft.fft(fft.ifftshift(u_ks)))\n\n        # 3. Apply pupil filter\n        U_filtered = U_ks * pupil\n\n        # 4. Compute coherent image amplitude (IFFT)\n        # Use ifftshift before IFFT for centered spectral input\n        a_ks = fft.fftshift(fft.ifft(fft.ifftshift(U_filtered)))\n        \n        # 5. Accumulate intensity\n        total_intensity += np.abs(a_ks)**2\n        \n    # 6. Average intensity over all source points\n    return total_intensity / len(ks_list)\n\ndef solve():\n    \"\"\"\n    Main function to solve the SRAF optimization problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        {'lambda': 193.0, 'NA': 0.85, 'sigma': 0.30, 'W': 90.0, 'P': 220.0, 'Lw': 400.0,\n         'w_cand': [12.0, 16.0, 20.0, 24.0, 28.0],\n         'd_cand': [60.0, 70.0, 80.0, 90.0, 100.0, 110.0, 120.0, 130.0, 140.0, 150.0],\n         'I_th': 0.35},\n        # Case 2\n        {'lambda': 193.0, 'NA': 0.85, 'sigma': 0.60, 'W': 90.0, 'P': 220.0, 'Lw': 400.0,\n         'w_cand': [12.0, 16.0, 20.0, 24.0, 28.0],\n         'd_cand': [60.0, 70.0, 80.0, 90.0, 100.0, 110.0, 120.0, 130.0, 140.0, 150.0],\n         'I_th': 0.35},\n        # Case 3\n        {'lambda': 193.0, 'NA': 0.85, 'sigma': 0.20, 'W': 70.0, 'P': 200.0, 'Lw': 400.0,\n         'w_cand': [12.0, 16.0, 20.0, 24.0, 28.0],\n         'd_cand': [60.0, 70.0, 80.0, 90.0, 100.0, 110.0, 120.0, 130.0, 140.0, 150.0],\n         'I_th': 0.35},\n        # Case 4\n        {'lambda': 193.0, 'NA': 0.85, 'sigma': 0.80, 'W': 100.0, 'P': 240.0, 'Lw': 400.0,\n         'w_cand': [12.0, 16.0, 20.0, 24.0, 28.0],\n         'd_cand': [60.0, 70.0, 80.0, 90.0, 100.0, 110.0, 120.0, 130.0, 140.0, 150.0],\n         'I_th': 0.35}\n    ]\n\n    # Global computational parameters\n    N = 2048\n    dx = 1.0\n    Ns = 11\n    J_pen = 1000.0\n\n    # Spatial and frequency coordinates\n    x = (np.arange(N) - N / 2) * dx\n    f = fft.fftfreq(N, d=dx)\n    f_shifted = fft.fftshift(f)\n\n    all_results = []\n\n    for case in test_cases:\n        # Unpack parameters\n        lambda_ = case['lambda']\n        NA = case['NA']\n        sigma = case['sigma']\n        W = case['W']\n        P = case['P']\n        Lw = case['Lw']\n        w_cand = case['w_cand']\n        d_cand = case['d_cand']\n        I_th = case['I_th']\n\n        # System parameters\n        f_c = NA / lambda_\n        ks_list = np.linspace(-sigma * f_c, sigma * f_c, Ns)\n        \n        # Pupil function\n        pupil = np.zeros(N, dtype=np.float64)\n        pupil[np.abs(f_shifted) <= f_c] = 1.0\n\n        # Create and simulate dense (target) mask\n        t_dense = (np.abs((x + P / 2) % P - P / 2) <= W / 2).astype(np.float64)\n        I_dense = calculate_aerial_image(t_dense, x, f_shifted, pupil, ks_list)\n        \n        # Normalize target image\n        window_mask = np.abs(x) <= Lw\n        max_I_dense = np.max(I_dense[window_mask])\n        I_dense_norm = I_dense / max_I_dense if max_I_dense > 0 else I_dense\n\n        min_objective = float('inf')\n        best_d, best_w = None, None\n\n        # Grid search for optimal d and w\n        for w in w_cand:\n            for d in d_cand:\n                # Create isolated-SRAF mask\n                t_iso = np.zeros_like(x)\n                t_iso[np.abs(x) <= W / 2] = 1.0\n                sraf_center = W / 2 + d + w / 2\n                t_iso[np.abs(x - sraf_center) <= w / 2] = 1.0\n                t_iso[np.abs(x + sraf_center) <= w / 2] = 1.0\n                \n                # Calculate aerial image\n                I_iso = calculate_aerial_image(t_iso, x, f_shifted, pupil, ks_list)\n                \n                # Normalize and check constraint\n                max_I_iso = np.max(I_iso[window_mask])\n                I_iso_norm = I_iso / max_I_iso if max_I_iso > 0 else I_iso\n\n                sraf_center_idx = np.argmin(np.abs(x - sraf_center))\n                I_sraf = I_iso_norm[sraf_center_idx]\n                \n                is_printing = I_sraf >= I_th\n                \n                # Calculate objective function\n                mse = np.mean((I_iso_norm[window_mask] - I_dense_norm[window_mask])**2)\n                objective = mse + J_pen if is_printing else mse\n\n                # Update best parameters\n                if objective < min_objective:\n                    min_objective = objective\n                    best_d, best_w = d, w\n        \n        all_results.append([round(best_d, 1), round(best_w, 1)])\n\n    # Format and print the final results\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "Once the aerial image is projected onto the wafer, its energy must be transduced into a physical pattern in the photoresist. This practice focuses on modeling this critical step by fitting a widely used sigmoidal function to simulated experimental data, connecting exposure dose to the resulting critical dimension (CD). You will extract key physical parameters like resist contrast ($\\gamma$) and threshold dose ($E_T$) and diagnose the challenge of parameter identifiability when non-ideal effects like stray light (flare) are present. ",
            "id": "4288243",
            "problem": "A resist-based pattern transfer in photolithography converts optical exposure dose into developed feature size. In dense-line regimes with a nearly uniform aerial image inside the line opening, the line Central Dose (dose per unit area) controls a switching nonlinearity of the resist. Begin from the following fundamental bases:\n\n- The effective energy density that drives solubility change is the time-integrated intensity, called the exposure dose, denoted by $E$ in $\\mathrm{mJ/cm^2}$.\n- Stray light (flare) from lens scatter and wafer topography adds a spatially nearly uniform background, which is well modeled to first order as an additive, dose-equivalent constant $F$ in $\\mathrm{mJ/cm^2}$, so that the effective dose is $E_{\\mathrm{eff}} = E + F$.\n- Positive chemically amplified resist clearing is monotonic in $E_{\\mathrm{eff}}$ and exhibits a finite transition width set by the resist contrast (slope), denoted by $\\gamma$, and a characteristic threshold dose $E_T$ in $\\mathrm{mJ/cm^2}$.\n- For a line feature whose nominal mask opening is constant across the dose sweep, the post-development critical dimension can be normalized to a dimensionless fraction $y \\in [0,1]$ that increases monotonically with $E_{\\mathrm{eff}}$ and has a sigmoidal shape when plotted versus $\\log E_{\\mathrm{eff}}$.\n\nDerive, from these bases and standard monotonicity and dimensional-consistency arguments, a sigmoidal response model for the normalized critical dimension $y$ that depends only on the dimensionless ratio $E_{\\mathrm{eff}} / E_T$ and the contrast $\\gamma$, and is consistent with the limits $y \\to 0$ as $E_{\\mathrm{eff}} \\ll E_T$ and $y \\to 1$ as $E_{\\mathrm{eff}} \\gg E_T$. Use this model to perform nonlinear least-squares fitting to extract $\\gamma$ and $E_T$ from noiseless datasets. Then assess parameter identifiability when the flare $F$ is unknown and must be co-estimated. Use the Jacobian-based local identifiability diagnostic: the sensitivity matrix (Jacobian) with respect to the fitted parameters must have a well-conditioned Gram matrix; declare parameters as poorly identifiable if the condition number of the Jacobian exceeds a fixed threshold.\n\nImplement a program that performs the following tasks on the specified test suite. In all items below, doses are in $\\mathrm{mJ/cm^2}$ and angles do not appear. Report any fitted $E_T$ in $\\mathrm{mJ/cm^2}$, and report $\\gamma$ as dimensionless. When a boolean is requested, output either the literal True or False. All floating-point outputs must be rounded to six decimal places.\n\n- Test case A (no flare, fit $\\gamma$ and $E_T$ with known $F$): Use true parameters $\\gamma = 3.0$, $E_T = 20.0$, $F = 0.0$. Use dose samples $E \\in \\left[ 5, 10, 15, 20, 25, 30, 40, 60 \\right]$. Generate the corresponding noiseless normalized critical dimension data $y$ from your derived sigmoidal model and fit only $\\gamma$ and $E_T$ while holding $F$ fixed to the known value. Output the fitted $\\gamma$ and fitted $E_T$ for this case as two floats.\n\n- Test case B (known flare, fit $\\gamma$ and $E_T$): Use true parameters $\\gamma = 2.0$, $E_T = 30.0$, $F = 5.0$. Use dose samples $E \\in \\left[ 0, 5, 10, 15, 20, 30, 50 \\right]$. Generate noiseless $y$ and fit only $\\gamma$ and $E_T$ while holding $F$ fixed to the known value. Output the fitted $\\gamma$ and fitted $E_T$ for this case as two floats.\n\n- Test case C (unknown flare on high-dose-only data, identifiability check): Use true parameters $\\gamma = 2.0$, $E_T = 30.0$, $F = 5.0$. Use high-dose samples $E \\in \\left[ 50, 100, 150, 200 \\right]$. Generate noiseless $y$ and fit the parameter triplet $\\left( \\gamma, E_T, F \\right)$ simultaneously. Compute the Jacobian of the model residuals with respect to the fitted parameters evaluated at the solution, and compute its condition number as the ratio of its largest to smallest singular values. Declare the triplet poorly identifiable if this Jacobian condition number exceeds $10^8$. Output a single boolean for this case: True if poorly identifiable, False otherwise.\n\n- Test case D (unknown flare with low doses included, identifiability check): Use true parameters $\\gamma = 2.0$, $E_T = 30.0$, $F = 5.0$. Use doses $E \\in \\left[ 0, 2, 4, 6, 8, 10, 20, 40 \\right]$. Generate noiseless $y$ and fit the parameter triplet $\\left( \\gamma, E_T, F \\right)$. Compute the Jacobian condition number as above and declare poor identifiability if it exceeds $10^8$. Output a single boolean for this case.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order\n$\\left[ \\widehat{\\gamma}_A, \\widehat{E_T}_A, \\widehat{\\gamma}_B, \\widehat{E_T}_B, \\mathrm{poorID}_C, \\mathrm{poorID}_D \\right]$,\nwhere $\\widehat{\\gamma}_A$ and $\\widehat{E_T}_A$ are the fitted values for Test case A, $\\widehat{\\gamma}_B$ and $\\widehat{E_T}_B$ are the fitted values for Test case B, and $\\mathrm{poorID}_C$, $\\mathrm{poorID}_D$ are the booleans for Test cases C and D respectively. Express any $E_T$ in $\\mathrm{mJ/cm^2}$ in the printed float values, rounded to six decimal places. No other text must be printed.",
            "solution": "The mapping from dose to normalized critical dimension is rooted in resist clearing physics. First, the effective exposure dose that controls deprotection is the time integral of intensity, and stray light contributes a nearly uniform constant to this dose. Hence, the effective dose is $E_{\\mathrm{eff}} = E + F$, where $E$ is the programmed dose and $F$ is the flare background, both in $\\mathrm{mJ/cm^2}$.\n\nSecond, positive chemically amplified resists show a sigmoidal transition in clearing fraction versus $\\log E_{\\mathrm{eff}}$ due to stochastic deprotection, quencher consumption, and development kinetics. The resist contrast $\\gamma$ characterizes the steepness of this transition, while a characteristic threshold dose $E_T$ sets the scale at which clearing occurs. Dimensional consistency and monotonicity require that the normalized response $y$ be a function of the dimensionless combination $E_{\\mathrm{eff}} / E_T$ and that $y \\to 0$ as $E_{\\mathrm{eff}} / E_T \\to 0$ and $y \\to 1$ as $E_{\\mathrm{eff}} / E_T \\to \\infty$.\n\nA minimal model satisfying these requirements and widely used in practice is a Hill-type sigmoid written in terms of the ratio $E_{\\mathrm{eff}} / E_T$ and contrast $\\gamma$:\n$$\ny(E; \\gamma, E_T, F) \\;=\\; \\frac{1}{1 + \\left( \\frac{E_T}{E + F} \\right)^{\\gamma}},\n$$\nwith $0 < y < 1$ for finite $E + F > 0$, $y \\to 0$ as $E + F \\ll E_T$, and $y \\to 1$ as $E + F \\gg E_T$. This model captures the essential physics: $y$ increases monotonically with $E_{\\mathrm{eff}}$, the scale of the transition is controlled by $E_T$, and the steepness by $\\gamma$.\n\nFor parameter estimation, one sets up a nonlinear least-squares problem. Given doses $\\{ E_i \\}_{i=1}^N$ and observations $\\{ y_i \\}_{i=1}^N$, define the residuals\n$$\nr_i(\\boldsymbol{\\theta}) = y(E_i; \\boldsymbol{\\theta}) - y_i,\n$$\nwhere $\\boldsymbol{\\theta}$ is either $\\boldsymbol{\\theta} = (\\gamma, E_T)$ when $F$ is known, or $\\boldsymbol{\\theta} = (\\gamma, E_T, F)$ when $F$ is unknown. The least-squares estimate minimizes $\\frac{1}{2} \\sum_{i=1}^N r_i(\\boldsymbol{\\theta})^2$ subject to positivity constraints $\\gamma > 0$, $E_T > 0$, and $F \\ge 0$.\n\nTo assess local identifiability when fitting all three parameters, examine the Jacobian matrix $J \\in \\mathbb{R}^{N \\times p}$, with elements $J_{i,j} = \\partial r_i / \\partial \\theta_j$ at the solution, where $p$ is the number of parameters. Because $r_i = y_i(\\boldsymbol{\\theta}) - y_i^{\\text{obs}}$ and $y_i^{\\text{obs}}$ is constant, $J_{i,j} = \\partial y(E_i; \\boldsymbol{\\theta}) / \\partial \\theta_j$. Using the Hill model above, introduce $E_{\\mathrm{eff},i} = E_i + F$ and $r_i^\\star = \\left(\\frac{E_T}{E_{\\mathrm{eff},i}}\\right)^\\gamma$. Then\n$$\ny_i = \\frac{1}{1 + r_i^\\star}, \\quad \\frac{\\partial y_i}{\\partial \\gamma} = - \\frac{r_i^\\star \\ln\\left(\\frac{E_T}{E_{\\mathrm{eff},i}}\\right)}{(1 + r_i^\\star)^2}, \\quad \\frac{\\partial y_i}{\\partial E_T} = - \\frac{\\gamma \\, r_i^\\star}{E_T \\, (1 + r_i^\\star)^2}, \\quad \\frac{\\partial y_i}{\\partial F} = \\frac{\\gamma \\, r_i^\\star}{E_{\\mathrm{eff},i} \\, (1 + r_i^\\star)^2}.\n$$\nThe Fisher Information Matrix for homoscedastic Gaussian noise is proportional to $J^\\top J$, so a necessary condition for local identifiability is that $J$ be full column rank with a moderate condition number. We diagnose poor identifiability by computing the singular values $\\sigma_{\\max} \\ge \\cdots \\ge \\sigma_{\\min} > 0$ of $J$ and forming the condition number $\\kappa(J) = \\sigma_{\\max} / \\sigma_{\\min}$. If $\\kappa(J)$ exceeds a large threshold, such as $10^8$, then columns of $J$ are nearly linearly dependent, indicating strong parameter correlation and poor local identifiability.\n\nIn the four test cases:\n\n- In Test case A, with $F = 0$ known and doses spanning below and above $E_T$, the two-parameter fit is well-conditioned, and the estimates $\\widehat{\\gamma}$ and $\\widehat{E_T}$ recover the generating values when data are noiseless.\n\n- In Test case B, with $F = 5.0$ known and an $E$ grid including $E = 0$, the two-parameter fit again yields the generating parameters.\n\n- In Test case C, with only high doses $E \\gg F$ and co-estimation of $F$, the sensitivity of $y$ to $F$ is suppressed because $E + F \\approx E$, so $\\partial y / \\partial F \\approx 0$ uniformly across samples. In addition, changes in $E_T$ can compensate small changes in $F$, making the Jacobian columns nearly collinear. Thus $J$ is ill-conditioned and $\\kappa(J)$ is large, triggering the poor identifiability flag.\n\n- In Test case D, including $E = 0$ and other low doses, the model samples the strongly nonlinear region where $E_{\\mathrm{eff}} \\sim E_T$. Here $\\partial y / \\partial F$ is appreciable and qualitatively distinct from $\\partial y / \\partial E_T$ and $\\partial y / \\partial \\gamma$, restoring identifiability and yielding a moderate $\\kappa(J)$.\n\nAlgorithmically, the program:\n\n1. Defines the Hill model $y(E; \\gamma, E_T, F)$.\n2. Generates noiseless $y$ for each test case using the specified true parameters and $E$ values.\n3. Solves the constrained nonlinear least-squares problem using initial guesses and positivity bounds, fitting $(\\gamma, E_T)$ for known $F$ and $(\\gamma, E_T, F)$ otherwise.\n4. Computes the Jacobian analytically at the fitted parameters and evaluates $\\kappa(J)$ for identifiability in the three-parameter fits.\n5. Prints the outputs in the required aggregate format, rounding floats to six decimal places and using $\\mathrm{mJ/cm^2}$ implicitly in the $E_T$ values.\n\nBecause the data are noiseless and the model used for fitting matches the generating model, the fitted $\\widehat{\\gamma}$ and $\\widehat{E_T}$ in Test cases A and B exactly recover the true values to within numerical tolerance. In Test case C, the Jacobian condition number exceeds $10^8$, indicating poor identifiability; in Test case D, it does not.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import least_squares\n\ndef hill_cd(E, gamma, ET, F):\n    # Normalized CD: 1 / (1 + (ET / (E + F))^gamma)\n    Eeff = E + F\n    # Avoid divide-by-zero for any Eeff <= 0 (should not occur with F>=0 and E>=0)\n    if np.any(Eeff <= 0):\n        raise ValueError(\"Effective dose must be positive.\")\n    r = (ET / Eeff) ** gamma\n    y = 1.0 / (1.0 + r)\n    return y\n\ndef residuals_two_params(x, E, y_obs, F_fixed):\n    gamma, ET = x\n    y_pred = hill_cd(E, gamma, ET, F_fixed)\n    return y_pred - y_obs\n\ndef residuals_three_params(x, E, y_obs):\n    gamma, ET, F = x\n    y_pred = hill_cd(E, gamma, ET, F)\n    return y_pred - y_obs\n\ndef jacobian_y_wrt_params(E, gamma, ET, F, fit_F):\n    # Compute analytic Jacobian of y wrt parameters at given params.\n    # If fit_F is False: return Nx2 Jacobian for params [gamma, ET]\n    # If fit_F is True: return Nx3 Jacobian for params [gamma, ET, F]\n    Eeff = E + F\n    r = (ET / Eeff) ** gamma\n    denom = (1.0 + r) ** 2\n    # Partial derivatives\n    # dy/dgamma\n    dyg = - (r * np.log(ET / Eeff)) / denom\n    # dy/dET\n    dyET = - (gamma * r) / (ET * denom)\n    if fit_F:\n        # dy/dF\n        dyF = (gamma * r) / (Eeff * denom)\n        J = np.vstack([dyg, dyET, dyF]).T\n    else:\n        J = np.vstack([dyg, dyET]).T\n    return J\n\ndef condition_number_of_jacobian(E, gamma, ET, F):\n    # Jacobian of residuals equals Jacobian of y since y_obs is constant\n    J = jacobian_y_wrt_params(E, gamma, ET, F, fit_F=True)\n    # Compute condition number via SVD\n    # Add a tiny epsilon to avoid 0 division if singular (though that would also indicate poor ID)\n    U, svals, Vt = np.linalg.svd(J, full_matrices=False)\n    smax = np.max(svals) if svals.size > 0 else 0.0\n    smin = np.min(svals) if svals.size > 0 else 0.0\n    if smin == 0.0:\n        return np.inf\n    return float(smax / smin)\n\ndef fit_two_params(E, y_obs, F_fixed):\n    # Bounds: gamma in (1e-4, 50), ET in (1e-3, 1e3)\n    bounds = ([1e-4, 1e-3], [50.0, 1e3])\n    # Initial guess: gamma=2, ET ~ median(E+F)\n    ET0 = max(1e-3, np.median(E + F_fixed))\n    x0 = np.array([2.0, ET0], dtype=float)\n    res = least_squares(residuals_two_params, x0, bounds=bounds, args=(E, y_obs, F_fixed), xtol=1e-14, ftol=1e-14, gtol=1e-14, max_nfev=10000)\n    return res.x\n\ndef fit_three_params(E, y_obs):\n    # Bounds: gamma in (1e-4, 50), ET in (1e-3, 1e3), F in [0, 1e3]\n    bounds = ([1e-4, 1e-3, 0.0], [50.0, 1e3, 1e3])\n    # Initial guess: gamma=2, ET ~ median(E+1), F=1\n    ET0 = max(1e-3, np.median(E + 1.0))\n    x0 = np.array([2.0, ET0, 1.0], dtype=float)\n    res = least_squares(residuals_three_params, x0, bounds=bounds, args=(E, y_obs), xtol=1e-14, ftol=1e-14, gtol=1e-14, max_nfev=20000)\n    return res.x\n\ndef fmt(x):\n    if isinstance(x, (float, np.floating)):\n        return f\"{x:.6f}\"\n    if isinstance(x, (bool, np.bool_)):\n        return \"True\" if bool(x) else \"False\"\n    if isinstance(x, (int, np.integer)):\n        return str(int(x))\n    return str(x)\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    results = []\n\n    # Test case A: gamma=3.0, ET=20.0, F=0.0; E=[5,10,15,20,25,30,40,60]; fit gamma and ET with F fixed\n    gamma_A_true = 3.0\n    ET_A_true = 20.0\n    F_A = 0.0\n    E_A = np.array([5.0, 10.0, 15.0, 20.0, 25.0, 30.0, 40.0, 60.0])\n    y_A = hill_cd(E_A, gamma_A_true, ET_A_true, F_A)\n    gamma_A_hat, ET_A_hat = fit_two_params(E_A, y_A, F_A)\n    results.extend([gamma_A_hat, ET_A_hat])\n\n    # Test case B: gamma=2.0, ET=30.0, F=5.0; E=[0,5,10,15,20,30,50]; fit gamma and ET with F fixed\n    gamma_B_true = 2.0\n    ET_B_true = 30.0\n    F_B = 5.0\n    E_B = np.array([0.0, 5.0, 10.0, 15.0, 20.0, 30.0, 50.0])\n    y_B = hill_cd(E_B, gamma_B_true, ET_B_true, F_B)\n    gamma_B_hat, ET_B_hat = fit_two_params(E_B, y_B, F_B)\n    results.extend([gamma_B_hat, ET_B_hat])\n\n    # Test case C: gamma=2.0, ET=30.0, F=5.0; E=[50,100,150,200]; fit gamma, ET, F and check identifiability\n    gamma_C_true = 2.0\n    ET_C_true = 30.0\n    F_C_true = 5.0\n    E_C = np.array([50.0, 100.0, 150.0, 200.0])\n    y_C = hill_cd(E_C, gamma_C_true, ET_C_true, F_C_true)\n    gamma_C_hat, ET_C_hat, F_C_hat = fit_three_params(E_C, y_C)\n    kappa_C = condition_number_of_jacobian(E_C, gamma_C_hat, ET_C_hat, F_C_hat)\n    poorID_C = (kappa_C > 1e8)\n    results.append(poorID_C)\n\n    # Test case D: gamma=2.0, ET=30.0, F=5.0; E=[0,2,4,6,8,10,20,40]; fit gamma, ET, F and check identifiability\n    gamma_D_true = 2.0\n    ET_D_true = 30.0\n    F_D_true = 5.0\n    E_D = np.array([0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 20.0, 40.0])\n    y_D = hill_cd(E_D, gamma_D_true, ET_D_true, F_D_true)\n    gamma_D_hat, ET_D_hat, F_D_hat = fit_three_params(E_D, y_D)\n    kappa_D = condition_number_of_jacobian(E_D, gamma_D_hat, ET_D_hat, F_D_hat)\n    poorID_D = (kappa_D > 1e8)\n    results.append(poorID_D)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(fmt(r) for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "To achieve design-for-manufacturing, we must model the entire pattern transfer process, from the initial design to the final etched feature. This exercise tasks you with building and calibrating a complete empirical model that accounts for systematic biases introduced during both the lithography and etch steps, including pattern density effects known as microloading. By performing linear regression and quantifying parameter uncertainty, you will practice a core skill in developing the predictive process models that enable modern integrated circuit manufacturing. ",
            "id": "4288269",
            "problem": "You are given a modeling and calibration task for pattern transfer in photolithography within integrated circuits and electronic design automation. You must write a program that performs a two-stage linear regression to calibrate resist and etch bias parameters using a dataset of drawn critical dimensions, measured pre-etch resist critical dimensions, and measured post-etch critical dimensions across multiple pitches. The program must also compute two-sided confidence intervals for each fitted parameter under a standard linear model with independent, identically distributed Gaussian noise.\n\nModeling assumptions and fundamental base:\n- Let $D_i$ be the drawn critical dimension (in nm) for sample $i$ at pitch $P_i$ (in nm). Let $R_i$ be the measured pre-etch resist critical dimension (in nm), and let $E_i$ be the measured post-etch critical dimension (in nm).\n- Assume the resist development and etch transfer can each be described by a linear relationship with an intercept, a slope with respect to its upstream dimension, and a microloading term proportional to $1/P_i$:\n  - Resist model: $R_i = \\alpha_0 + \\alpha_1 D_i + \\alpha_2 \\left(\\dfrac{1}{P_i}\\right) + \\varepsilon^{(r)}_i$.\n  - Etch model: $E_i = \\beta_0 + \\beta_1 R_i + \\beta_2 \\left(\\dfrac{1}{P_i}\\right) + \\varepsilon^{(e)}_i$.\n- Noise terms follow independent, identically distributed zero-mean Gaussian distributions with finite variance: $\\varepsilon^{(r)}_i \\sim \\mathcal{N}(0,\\sigma_r^2)$ and $\\varepsilon^{(e)}_i \\sim \\mathcal{N}(0,\\sigma_e^2)$. Within each regression, adopt the standard linear model assumptions that justify ordinary least squares: linearity in parameters, independence, homoscedasticity, and zero-mean Gaussian errors.\n- Calibrate parameters by ordinary least squares: construct the design matrix $X$ with columns for the intercept, the upstream dimension, and $1/P_i$, and estimate the parameter vector $\\hat{\\theta} = (X^\\top X)^{-1} X^\\top y$. Use the unbiased residual variance estimator $\\hat{\\sigma}^2 = \\dfrac{\\|y - X \\hat{\\theta}\\|_2^2}{n - p}$, where $n$ is the number of samples and $p$ is the number of parameters, and the parameter covariance $\\widehat{\\mathrm{Cov}}(\\hat{\\theta}) = \\hat{\\sigma}^2 (X^\\top X)^{-1}$. For a two-sided confidence interval with nominal coverage $1 - \\alpha$, use the Student-$t$ quantile $t_{1 - \\alpha/2,\\ \\nu}$ with degrees of freedom $\\nu = n - p$, so that the interval for component $k$ is $\\hat{\\theta}_k \\pm t_{1 - \\alpha/2,\\ \\nu} \\cdot \\mathrm{SE}(\\hat{\\theta}_k)$, where $\\mathrm{SE}(\\hat{\\theta}_k)$ is the square root of the $k$-th diagonal of $\\widehat{\\mathrm{Cov}}(\\hat{\\theta})$.\n\nProgram requirements:\n- Implement two separate regressions:\n  - Resist regression to estimate $\\alpha_0$, $\\alpha_1$, $\\alpha_2$ from $\\{(D_i, P_i, R_i)\\}$.\n  - Etch regression to estimate $\\beta_0$, $\\beta_1$, $\\beta_2$ from $\\{(R_i, P_i, E_i)\\}$.\n- Compute two-sided confidence intervals at $95\\%$ nominal coverage (i.e., $\\alpha = 0.05$) for each parameter using the $t$-distribution with appropriate degrees of freedom.\n- All critical dimensions must be treated in nanometers and pitch in nanometers. Report the parameter estimates in nanometers for intercept terms ($\\alpha_0$, $\\beta_0$), dimensionless for slopes ($\\alpha_1$, $\\beta_1$), and in $\\mathrm{nm}^2$ for microloading coefficients ($\\alpha_2$, $\\beta_2$). The confidence interval bounds carry the same units as their corresponding parameters. Round all reported floating-point results to $3$ decimals.\n\nTest suite specification:\n- For reproducibility, your program must generate synthetic datasets for three test cases using independent pseudo-random number generator seeds. For each case, generate $N$ samples by:\n  - Drawing $D_i$ independently and uniformly in a specified range $[D_{\\min}, D_{\\max}]$ (in nm).\n  - Drawing $P_i$ independently from a specified finite set of pitches (in nm).\n  - Generating $R_i$ and $E_i$ according to the models with the specified true parameters and adding Gaussian noise with the specified standard deviations.\n- The test suite is as follows:\n  - Case $1$ (typical microloading, moderate noise):\n    - True resist parameters: $\\alpha_0 = -2.0$ nm, $\\alpha_1 = 1.02$, $\\alpha_2 = 300.0$ $\\mathrm{nm}^2$.\n    - True etch parameters: $\\beta_0 = -1.0$ nm, $\\beta_1 = 0.97$, $\\beta_2 = 200.0$ $\\mathrm{nm}^2$.\n    - Noise standard deviations: $\\sigma_r = 1.0$ nm, $\\sigma_e = 1.2$ nm.\n    - Drawn CD range: $[20.0, 80.0]$ nm.\n    - Pitch set: $\\{64.0, 72.0, 80.0, 90.0, 104.0, 128.0, 160.0, 200.0\\}$ nm.\n    - Number of samples: $N = 80$.\n    - Random seed: $12345$.\n  - Case $2$ (strong microloading, low noise):\n    - True resist parameters: $\\alpha_0 = -1.0$ nm, $\\alpha_1 = 1.01$, $\\alpha_2 = 800.0$ $\\mathrm{nm}^2$.\n    - True etch parameters: $\\beta_0 = -0.5$ nm, $\\beta_1 = 0.98$, $\\beta_2 = 1000.0$ $\\mathrm{nm}^2$.\n    - Noise standard deviations: $\\sigma_r = 0.5$ nm, $\\sigma_e = 0.5$ nm.\n    - Drawn CD range: $[20.0, 80.0]$ nm.\n    - Pitch set: $\\{64.0, 72.0, 80.0, 90.0, 104.0, 128.0, 160.0, 200.0\\}$ nm.\n    - Number of samples: $N = 100$.\n    - Random seed: $67890$.\n  - Case $3$ (boundary case with negligible biases):\n    - True resist parameters: $\\alpha_0 = 0.0$ nm, $\\alpha_1 = 1.00$, $\\alpha_2 = 0.0$ $\\mathrm{nm}^2$.\n    - True etch parameters: $\\beta_0 = 0.0$ nm, $\\beta_1 = 1.00$, $\\beta_2 = 0.0$ $\\mathrm{nm}^2$.\n    - Noise standard deviations: $\\sigma_r = 0.8$ nm, $\\sigma_e = 0.8$ nm.\n    - Drawn CD range: $[20.0, 80.0]$ nm.\n    - Pitch set: $\\{64.0, 72.0, 80.0, 90.0, 104.0, 128.0, 160.0, 200.0\\}$ nm.\n    - Number of samples: $N = 60$.\n    - Random seed: $24680$.\n\nFinal output format:\n- Your program should produce a single line of output containing a list of three sublists, one per test case. For each test case, output a flat list of $18$ numbers in the following exact order, all rounded to $3$ decimals:\n  - $\\hat{\\alpha}_0$, $\\hat{\\alpha}_1$, $\\hat{\\alpha}_2$, $\\hat{\\beta}_0$, $\\hat{\\beta}_1$, $\\hat{\\beta}_2$, followed by the lower and upper bounds of the $95\\%$ confidence intervals for each parameter in the same order: $\\alpha_0^{\\text{lo}}$, $\\alpha_0^{\\text{hi}}$, $\\alpha_1^{\\text{lo}}$, $\\alpha_1^{\\text{hi}}$, $\\alpha_2^{\\text{lo}}$, $\\alpha_2^{\\text{hi}}$, $\\beta_0^{\\text{lo}}$, $\\beta_0^{\\text{hi}}$, $\\beta_1^{\\text{lo}}$, $\\beta_1^{\\text{hi}}$, $\\beta_2^{\\text{lo}}$, $\\beta_2^{\\text{hi}}$.\n- The final printed structure must therefore be a list of three lists, for example: $[[\\dots],[\\dots],[\\dots]]$.",
            "solution": "The problem requires the calibration of two linear models for pattern transfer in photolithography using ordinary least squares (OLS) regression. The first model describes the formation of a resist pattern from a drawn layout, and the second describes the etching of the substrate using the resist pattern as a mask. For each model, we must estimate its parameters and compute their $95\\%$ confidence intervals.\n\nThe general form of a linear regression model is given by:\n$$ \\mathbf{y} = \\mathbf{X} \\mathbf{\\theta} + \\mathbf{\\varepsilon} $$\nwhere $\\mathbf{y}$ is an $n \\times 1$ vector of observations, $\\mathbf{X}$ is an $n \\times p$ design matrix of predictors, $\\mathbf{\\theta}$ is a $p \\times 1$ vector of unknown parameters to be estimated, and $\\mathbf{\\varepsilon}$ is an $n \\times 1$ vector of random errors. The OLS method finds the parameter estimate $\\hat{\\mathbf{\\theta}}$ that minimizes the sum of squared residuals, $\\| \\mathbf{y} - \\mathbf{X} \\mathbf{\\theta} \\|_2^2$. The solution is given by the normal equations:\n$$ \\hat{\\mathbf{\\theta}} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y} $$\nThis requires the matrix $\\mathbf{X}^\\top \\mathbf{X}$ to be invertible, which is generally true if the columns of $\\mathbf{X}$ are linearly independent and the number of samples $n$ is greater than the number of parameters $p$.\n\nThe problem specifies two distinct regression tasks:\n\n1.  **Resist Model Calibration**: The model is $R_i = \\alpha_0 + \\alpha_1 D_i + \\alpha_2 \\left(\\frac{1}{P_i}\\right) + \\varepsilon^{(r)}_i$. We are estimating the parameter vector $\\mathbf{\\theta}^{(r)} = [\\alpha_0, \\alpha_1, \\alpha_2]^\\top$. The response vector $\\mathbf{y}^{(r)}$ consists of the measured pre-etch resist critical dimensions, $\\{R_i\\}_{i=1}^n$. The design matrix $\\mathbf{X}^{(r)}$ is constructed from the drawn critical dimensions $\\{D_i\\}_{i=1}^n$ and pitches $\\{P_i\\}_{i=1}^n$. Each row $i$ of $\\mathbf{X}^{(r)}$ corresponds to a sample and has the form $[1, D_i, 1/P_i]$.\n    $$ \\mathbf{y}^{(r)} = \\begin{pmatrix} R_1 \\\\ R_2 \\\\ \\vdots \\\\ R_n \\end{pmatrix}, \\quad \\mathbf{X}^{(r)} = \\begin{pmatrix} 1 & D_1 & 1/P_1 \\\\ 1 & D_2 & 1/P_2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & D_n & 1/P_n \\end{pmatrix}, \\quad \\mathbf{\\theta}^{(r)} = \\begin{pmatrix} \\alpha_0 \\\\ \\alpha_1 \\\\ \\alpha_2 \\end{pmatrix} $$\n\n2.  **Etch Model Calibration**: The model is $E_i = \\beta_0 + \\beta_1 R_i + \\beta_2 \\left(\\frac{1}{P_i}\\right) + \\varepsilon^{(e)}_i$. We are estimating the parameter vector $\\mathbf{\\theta}^{(e)} = [\\beta_0, \\beta_1, \\beta_2]^\\top$. The response vector $\\mathbf{y}^{(e)}$ consists of the measured post-etch critical dimensions, $\\{E_i\\}_{i=1}^n$. The design matrix $\\mathbf{X}^{(e)}$ is constructed from the measured resist dimensions $\\{R_i\\}_{i=1}^n$ and pitches $\\{P_i\\}_{i=1}^n$. Each row $i$ of $\\mathbf{X}^{(e)}$ has the form $[1, R_i, 1/P_i]$.\n    $$ \\mathbf{y}^{(e)} = \\begin{pmatrix} E_1 \\\\ E_2 \\\\ \\vdots \\\\ E_n \\end{pmatrix}, \\quad \\mathbf{X}^{(e)} = \\begin{pmatrix} 1 & R_1 & 1/P_1 \\\\ 1 & R_2 & 1/P_2 \\\\ \\vdots & \\vdots & \\vdots \\\\ 1 & R_n & 1/P_n \\end{pmatrix}, \\quad \\mathbf{\\theta}^{(e)} = \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\end{pmatrix} $$\n\nFor both models, the number of parameters is $p=3$.\n\nTo construct confidence intervals for the estimated parameters, we assume the errors $\\varepsilon_i$ are independent and identically distributed as $\\mathcal{N}(0, \\sigma^2)$. An unbiased estimator for the error variance $\\sigma^2$ is the residual variance:\n$$ \\hat{\\sigma}^2 = \\frac{1}{n-p} \\| \\mathbf{y} - \\mathbf{X} \\hat{\\mathbf{\\theta}} \\|_2^2 = \\frac{1}{n-p} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$\nwhere $\\hat{y}_i$ are the predicted values from the model. The covariance matrix of the parameter estimates $\\hat{\\mathbf{\\theta}}$ is then estimated by:\n$$ \\widehat{\\mathrm{Cov}}(\\hat{\\mathbf{\\theta}}) = \\hat{\\sigma}^2 (\\mathbf{X}^\\top \\mathbf{X})^{-1} $$\nThe standard error of the $k$-th parameter estimate, $\\mathrm{SE}(\\hat{\\theta}_k)$, is the square root of the $k$-th diagonal element of this covariance matrix. A two-sided $100(1-\\alpha)\\%$ confidence interval for a parameter $\\theta_k$ is given by:\n$$ \\hat{\\theta}_k \\pm t_{1-\\alpha/2, \\nu} \\cdot \\mathrm{SE}(\\hat{\\theta}_k) $$\nHere, $\\nu = n-p$ are the degrees of freedom for the residuals, and $t_{1-\\alpha/2, \\nu}$ is the upper-tailed critical value of the Student's $t$-distribution for a given confidence level $1-\\alpha$. For a $95\\%$ confidence interval, $\\alpha = 0.05$, and we use the quantile $t_{0.975, n-3}$.\n\nThe implementation will first generate synthetic data for each test case according to the specified true parameters, noise levels, and sampling distributions. Then, for each model (resist and etch), it will construct the respective design matrix and response vector. OLS regression will be performed to obtain the parameter estimates. Subsequently, the residual variance, parameter covariance matrix, standard errors, and the appropriate $t$-statistic will be calculated to construct the $95\\%$ confidence intervals. The final results, comprising the six parameter estimates and their corresponding confidence interval bounds (a total of $18$ values per test case), will be rounded to three decimal places and formatted as specified.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef perform_regression(x_upstream, p_pitch, y_downstream, confidence_level=0.95):\n    \"\"\"\n    Performs multiple linear regression and calculates confidence intervals for parameters.\n    \n    Args:\n        x_upstream (np.ndarray): The upstream dimension vector.\n        p_pitch (np.ndarray): The pitch vector.\n        y_downstream (np.ndarray): The response vector (downstream dimension).\n        confidence_level (float): The confidence level for the intervals.\n\n    Returns:\n        tuple: A tuple containing (theta_hat, ci_lower, ci_upper), where\n               theta_hat are the estimated parameters,\n               ci_lower are the lower bounds of the confidence intervals,\n               ci_upper are the upper bounds of the confidence intervals.\n    \"\"\"\n    n = len(y_downstream)\n    p = 3  # Number of parameters: intercept, slope, microloading\n\n    # Construct the design matrix X\n    X = np.c_[np.ones(n), x_upstream, 1.0 / p_pitch]\n    \n    # Solve for parameters using ordinary least squares\n    # np.linalg.lstsq is numerically stable\n    theta_hat = np.linalg.lstsq(X, y_downstream, rcond=None)[0]\n\n    # Calculate residuals and residual sum of squares (RSS)\n    y_hat = X @ theta_hat\n    residuals = y_downstream - y_hat\n    rss = np.sum(residuals**2)\n\n    # Calculate unbiased estimator of error variance\n    df = n - p\n    sigma_sq_hat = rss / df\n\n    # Calculate covariance matrix of parameter estimates\n    # For stability, check invertibility if necessary, though unlikely with generated data.\n    try:\n        X_T_X_inv = np.linalg.inv(X.T @ X)\n    except np.linalg.LinAlgError:\n        # Fallback to pseudo-inverse if X.T @ X is singular\n        X_T_X_inv = np.linalg.pinv(X.T @ X)\n\n    cov_theta_hat = sigma_sq_hat * X_T_X_inv\n\n    # Standard errors are the sqrt of the diagonal elements of the covariance matrix\n    se_theta_hat = np.sqrt(np.diag(cov_theta_hat))\n\n    # Calculate the t-statistic for the given confidence level\n    alpha = 1.0 - confidence_level\n    t_crit = stats.t.ppf(1 - alpha / 2, df)\n\n    # Calculate confidence intervals\n    ci_half_width = t_crit * se_theta_hat\n    ci_lower = theta_hat - ci_half_width\n    ci_upper = theta_hat + ci_half_width\n\n    return theta_hat, ci_lower, ci_upper\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"name\": \"Case 1 (typical microloading, moderate noise)\",\n            \"true_alpha\": np.array([-2.0, 1.02, 300.0]),\n            \"true_beta\": np.array([-1.0, 0.97, 200.0]),\n            \"sigma_r\": 1.0,\n            \"sigma_e\": 1.2,\n            \"D_range\": [20.0, 80.0],\n            \"P_set\": [64.0, 72.0, 80.0, 90.0, 104.0, 128.0, 160.0, 200.0],\n            \"N\": 80,\n            \"seed\": 12345,\n        },\n        {\n            \"name\": \"Case 2 (strong microloading, low noise)\",\n            \"true_alpha\": np.array([-1.0, 1.01, 800.0]),\n            \"true_beta\": np.array([-0.5, 0.98, 1000.0]),\n            \"sigma_r\": 0.5,\n            \"sigma_e\": 0.5,\n            \"D_range\": [20.0, 80.0],\n            \"P_set\": [64.0, 72.0, 80.0, 90.0, 104.0, 128.0, 160.0, 200.0],\n            \"N\": 100,\n            \"seed\": 67890,\n        },\n        {\n            \"name\": \"Case 3 (boundary case with negligible biases)\",\n            \"true_alpha\": np.array([0.0, 1.00, 0.0]),\n            \"true_beta\": np.array([0.0, 1.00, 0.0]),\n            \"sigma_r\": 0.8,\n            \"sigma_e\": 0.8,\n            \"D_range\": [20.0, 80.0],\n            \"P_set\": [64.0, 72.0, 80.0, 90.0, 104.0, 128.0, 160.0, 200.0],\n            \"N\": 60,\n            \"seed\": 24680,\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        rng = np.random.default_rng(case[\"seed\"])\n        N = case[\"N\"]\n\n        # Generate synthetic data\n        D = rng.uniform(case[\"D_range\"][0], case[\"D_range\"][1], size=N)\n        P = rng.choice(case[\"P_set\"], size=N, replace=True)\n\n        noise_r = rng.normal(0, case[\"sigma_r\"], size=N)\n        R = case[\"true_alpha\"][0] + case[\"true_alpha\"][1] * D + case[\"true_alpha\"][2] / P + noise_r\n        \n        noise_e = rng.normal(0, case[\"sigma_e\"], size=N)\n        E = case[\"true_beta\"][0] + case[\"true_beta\"][1] * R + case[\"true_beta\"][2] / P + noise_e\n\n        # Perform resist regression\n        alpha_hat, alpha_ci_lo, alpha_ci_hi = perform_regression(D, P, R)\n\n        # Perform etch regression\n        beta_hat, beta_ci_lo, beta_ci_hi = perform_regression(R, P, E)\n        \n        # Assemble results in the specified order\n        case_result = [\n            alpha_hat[0], alpha_hat[1], alpha_hat[2],\n            beta_hat[0], beta_hat[1], beta_hat[2],\n            alpha_ci_lo[0], alpha_ci_hi[0],\n            alpha_ci_lo[1], alpha_ci_hi[1],\n            alpha_ci_lo[2], alpha_ci_hi[2],\n            beta_ci_lo[0], beta_ci_hi[0],\n            beta_ci_lo[1], beta_ci_hi[1],\n            beta_ci_lo[2], beta_ci_hi[2],\n        ]\n        \n        all_results.append(case_result)\n\n    # Format the final output string precisely as a list of lists.\n    outer_parts = []\n    for res_list in all_results:\n        inner_parts = [f\"{x:.3f}\" for x in res_list]\n        outer_parts.append(f\"[{','.join(inner_parts)}]\")\n    \n    final_output_string = f\"[{','.join(outer_parts)}]\"\n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}