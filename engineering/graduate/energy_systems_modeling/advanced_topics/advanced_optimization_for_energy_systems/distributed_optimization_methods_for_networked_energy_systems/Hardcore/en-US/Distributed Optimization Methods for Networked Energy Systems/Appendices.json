{
    "hands_on_practices": [
        {
            "introduction": "This first exercise will illuminate the core principle of price-based coordination using the dual ascent method. By calculating a single update step for a simple two-agent energy system, you will see firsthand how a shared resource limit gives rise to a dual variable, or 'price', and how this price signal guides local decisions toward a system-wide efficient outcome. This practice provides a concrete numerical grasp of the foundational mechanism behind many distributed optimization techniques. ",
            "id": "4085630",
            "problem": "Consider a networked multi-energy system with two local agents coupled by a shared natural gas feeder of limited thermal throughput. Agent $1$ is a microgrid with a Combined Heat and Power (CHP) unit, and Agent $2$ is an industrial heat plant with a boiler. At a single dispatch interval, each agent $i \\in \\{1,2\\}$ chooses its natural gas thermal power consumption $u_{i}$, measured in $\\mathrm{MW_{th}}$, to track a desired setpoint $t_{i}$ derived from local multi-energy needs. The local tracking disutility is modeled as a convex quadratic cost $c_{i}(u_{i}) = \\frac{1}{2} a_{i} (u_{i} - t_{i})^{2}$, and each agent must obey a local bound $0 \\leq u_{i} \\leq U_{i}^{\\max}$. The network-level coupling constraint is a feeder throughput limit $\\sum_{i=1}^{2} u_{i} \\leq G^{\\max}$.\n\nAssume a centralized planner seeks to minimize $\\sum_{i=1}^{2} c_{i}(u_{i})$ subject to the coupling and local bounds, and applies the method of Lagrangian dual ascent (DA), where the dual variable $\\lambda \\geq 0$ represents the marginal price (shadow cost) per unit of natural gas throughput. For a given dual price $\\lambda$, each agent solves its local problem parameterized by $\\lambda$ and returns $u_{i}^{\\star}(\\lambda)$. The planner then updates $\\lambda$ by a dual ascent step using the coupling constraint residual and projects onto the nonnegative orthant, ensuring $\\lambda \\geq 0$.\n\nUse the following numerically specified and scientifically sound parameters:\n- Agent $1$: $a_{1} = 3$, $t_{1} = 7\\,\\mathrm{MW_{th}}$, $U_{1}^{\\max} = 9\\,\\mathrm{MW_{th}}$.\n- Agent $2$: $a_{2} = 2$, $t_{2} = 6\\,\\mathrm{MW_{th}}$, $U_{2}^{\\max} = 10\\,\\mathrm{MW_{th}}$.\n- Feeder limit: $G^{\\max} = 12\\,\\mathrm{MW_{th}}$.\n- Current dual price: $\\lambda^{(0)} = 1\\,\\mathrm{\\$\\,MW_{th}^{-1}}$.\n- Dual ascent step size: $\\rho = 0.4\\,\\mathrm{\\$\\,MW_{th}^{-2}}$.\n\nStarting from $\\lambda^{(0)}$, compute one dual ascent step to obtain $\\lambda^{(1)}$. Explicitly determine the local optimal decisions $u_{1}^{\\star}(\\lambda^{(0)})$ and $u_{2}^{\\star}(\\lambda^{(0)})$ based on fundamental principles of Lagrangian duality, form the coupling residual, and apply the projected dual ascent update. Express the final dual price in dollars per megawatt-thermal as instructed, but provide only the numerical value in your final boxed answer. No rounding is required; report the exact value.",
            "solution": "The user has asked for a critical validation of the problem statement, followed by a complete solution if the problem is deemed valid.\n\n### Step 1: Extract Givens\n-   Agent 1 cost parameter: $a_{1} = 3$\n-   Agent 1 setpoint: $t_{1} = 7\\,\\mathrm{MW_{th}}$\n-   Agent 1 local bound: $U_{1}^{\\max} = 9\\,\\mathrm{MW_{th}}$\n-   Agent 2 cost parameter: $a_{2} = 2$\n-   Agent 2 setpoint: $t_{2} = 6\\,\\mathrm{MW_{th}}$\n-   Agent 2 local bound: $U_{2}^{\\max} = 10\\,\\mathrm{MW_{th}}$\n-   Feeder throughput limit: $G^{\\max} = 12\\,\\mathrm{MW_{th}}$\n-   Current dual price: $\\lambda^{(0)} = 1\\,\\mathrm{\\$\\,MW_{th}^{-1}}$\n-   Dual ascent step size: $\\rho = 0.4\\,\\mathrm{\\$\\,MW_{th}^{-2}}$\n-   Agent decision variables: $u_{i}$ for $i \\in \\{1,2\\}$\n-   Agent cost functions: $c_{i}(u_{i}) = \\frac{1}{2} a_{i} (u_{i} - t_{i})^{2}$\n-   Local constraints: $0 \\leq u_{i} \\leq U_{i}^{\\max}$\n-   Coupling constraint: $\\sum_{i=1}^{2} u_{i} \\leq G^{\\max}$\n-   Objective: Minimize $\\sum_{i=1}^{2} c_{i}(u_{i})$\n-   Method: One step of projected dual ascent.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific Grounding**: The problem is well-grounded in the field of optimization and control for energy systems. It describes a classic economic dispatch problem, a fundamental task in power and energy system operation. The use of quadratic cost functions, linear constraints, and the Lagrangian dual ascent method are standard, well-established techniques for solving such problems, particularly in a distributed manner. The parameters and units are physically consistent.\n2.  **Well-Posedness**: The objective function $\\sum_{i=1}^{2} \\frac{1}{2} a_{i} (u_{i} - t_{i})^{2}$ is strictly convex since $a_i > 0$. The feasible region, defined by linear inequalities (box constraints and a sum constraint), is a convex and compact set. This guarantees the existence of a unique optimal solution to the primal problem. The task of computing a single step of the dual ascent algorithm is a well-defined mathematical procedure.\n3.  **Objectivity**: The problem statement is composed of precise, quantitative, and technical definitions and instructions. It is free of any subjective, ambiguous, or opinion-based language.\n4.  **Completeness and Consistency**: All numerical values and functional forms required to perform the calculation are provided. The unconstrained optimum ($u_1 = 7, u_2 = 6$) has a sum of $13$, which violates the coupling constraint $G^{\\max}=12$, making the constraint active and the problem non-trivial. The local setpoints are within their respective bounds ($t_1  U_1^{\\max}$ and $t_2  U_2^{\\max}$). There are no contradictions.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, and complete. It is a valid problem. I will proceed with the solution.\n\nThe optimization problem to be solved by the centralized planner is:\n$$\n\\min_{u_1, u_2} \\quad J(u_1, u_2) = \\frac{1}{2} a_{1} (u_{1} - t_{1})^{2} + \\frac{1}{2} a_{2} (u_{2} - t_{2})^{2}\n$$\nsubject to:\n$$\n\\sum_{i=1}^{2} u_{i} \\leq G^{\\max}\n$$\n$$\n0 \\leq u_{i} \\leq U_{i}^{\\max}, \\quad i \\in \\{1, 2\\}\n$$\n\nTo apply the dual ascent method, we form the Lagrangian by associating a dual variable (Lagrange multiplier) $\\lambda \\geq 0$ with the coupling constraint $\\sum_{i=1}^{2} u_{i} - G^{\\max} \\leq 0$. The local constraints (box constraints) are handled explicitly within each agent's subproblem.\nThe Lagrangian function $\\mathcal{L}(u_1, u_2, \\lambda)$ is:\n$$\n\\mathcal{L}(u_1, u_2, \\lambda) = \\sum_{i=1}^{2} c_{i}(u_{i}) + \\lambda \\left( \\sum_{i=1}^{2} u_{i} - G^{\\max} \\right)\n$$\nBy rearranging terms, the Lagrangian can be separated into two independent problems, one for each agent, plus a term that is constant with respect to the primal variables $u_i$:\n$$\n\\mathcal{L}(u_1, u_2, \\lambda) = \\left[ \\frac{1}{2} a_{1} (u_{1} - t_{1})^{2} + \\lambda u_{1} \\right] + \\left[ \\frac{1}{2} a_{2} (u_{2} - t_{2})^{2} + \\lambda u_{2} \\right] - \\lambda G^{\\max}\n$$\nFor a given dual price $\\lambda$, each agent $i$ solves its local subproblem to find its optimal gas consumption $u_i^{\\star}(\\lambda)$:\n$$\nu_{i}^{\\star}(\\lambda) = \\arg\\min_{0 \\leq u_{i} \\leq U_{i}^{\\max}} \\left( \\frac{1}{2} a_{i} (u_{i} - t_{i})^{2} + \\lambda u_{i} \\right)\n$$\nTo find the unconstrained minimizer of the local objective, we differentiate with respect to $u_i$ and set the result to zero:\n$$\n\\frac{\\partial}{\\partial u_i} \\left( \\frac{1}{2} a_{i} (u_{i} - t_{i})^{2} + \\lambda u_{i} \\right) = a_{i}(u_{i} - t_{i}) + \\lambda = 0\n$$\nSolving for $u_i$ yields the unconstrained solution:\n$$\nu_{i} = t_{i} - \\frac{\\lambda}{a_{i}}\n$$\nThe constrained solution $u_i^{\\star}(\\lambda)$ is the projection of this value onto the feasible interval $[0, U_{i}^{\\max}]$:\n$$\nu_{i}^{\\star}(\\lambda) = \\max\\left(0, \\min\\left(U_{i}^{\\max}, t_{i} - \\frac{\\lambda}{a_{i}}\\right)\\right)\n$$\nWe are given the initial dual price $\\lambda^{(0)} = 1$. We first compute the optimal local decisions $u_{1}^{\\star}(\\lambda^{(0)})$ and $u_{2}^{\\star}(\\lambda^{(0)})$.\n\nFor Agent $1$: $a_1=3$, $t_1=7$, $U_1^{\\max}=9$.\n$$\nu_{1}^{\\text{unc}}(\\lambda^{(0)}) = t_{1} - \\frac{\\lambda^{(0)}}{a_{1}} = 7 - \\frac{1}{3} = \\frac{21 - 1}{3} = \\frac{20}{3}\n$$\nSince $0 \\leq \\frac{20}{3} \\leq 9$ is true, the local constraints are not active.\n$$\nu_{1}^{\\star}(\\lambda^{(0)}) = \\frac{20}{3}\n$$\n\nFor Agent $2$: $a_2=2$, $t_2=6$, $U_2^{\\max}=10$.\n$$\nu_{2}^{\\text{unc}}(\\lambda^{(0)}) = t_{2} - \\frac{\\lambda^{(0)}}{a_{2}} = 6 - \\frac{1}{2} = \\frac{12 - 1}{2} = \\frac{11}{2}\n$$\nSince $0 \\leq \\frac{11}{2} \\leq 10$ is true, the local constraints are not active.\n$$\nu_{2}^{\\star}(\\lambda^{(0)}) = \\frac{11}{2}\n$$\n\nThe projected dual ascent update rule for $\\lambda$ is given by:\n$$\n\\lambda^{(k+1)} = \\left[ \\lambda^{(k)} + \\rho \\left( \\sum_{i=1}^{2} u_{i}^{\\star}(\\lambda^{(k)}) - G^{\\max} \\right) \\right]^{+}\n$$\nwhere $[\\cdot]^{+} = \\max(0, \\cdot)$ denotes projection onto the non-negative orthant. The term $\\sum u_i^{\\star} - G^{\\max}$ is the gradient of the dual function.\n\nWe now compute the gradient term (the coupling constraint residual) for our first step, using the values of $u_i^{\\star}(\\lambda^{(0)})$ calculated above and the feeder limit $G^{\\max} = 12$:\n$$\n\\sum_{i=1}^{2} u_{i}^{\\star}(\\lambda^{(0)}) - G^{\\max} = u_{1}^{\\star}(1) + u_{2}^{\\star}(1) - 12 = \\frac{20}{3} + \\frac{11}{2} - 12\n$$\nTo sum these values, we find a common denominator, which is $6$:\n$$\n\\frac{20 \\cdot 2}{6} + \\frac{11 \\cdot 3}{6} - \\frac{12 \\cdot 6}{6} = \\frac{40}{6} + \\frac{33}{6} - \\frac{72}{6} = \\frac{40 + 33 - 72}{6} = \\frac{73 - 72}{6} = \\frac{1}{6}\n$$\nThe residual is positive, indicating that the current consumption exceeds the feeder limit, and thus the dual price $\\lambda$ should increase.\n\nFinally, we apply the update rule with the initial price $\\lambda^{(0)} = 1$ and the step size $\\rho = 0.4 = \\frac{2}{5}$:\n$$\n\\lambda^{(1)} = \\left[ 1 + (0.4) \\cdot \\left(\\frac{1}{6}\\right) \\right]^{+} = \\left[ 1 + \\frac{2}{5} \\cdot \\frac{1}{6} \\right]^{+}\n$$\n$$\n\\lambda^{(1)} = \\left[ 1 + \\frac{2}{30} \\right]^{+} = \\left[ 1 + \\frac{1}{15} \\right]^{+} = \\left[ \\frac{15}{15} + \\frac{1}{15} \\right]^{+} = \\left[ \\frac{16}{15} \\right]^{+}\n$$\nSince $\\frac{16}{15} > 0$, the projection has no effect. The updated dual price is:\n$$\n\\lambda^{(1)} = \\frac{16}{15}\n$$\nThis is the value of the dual variable in $\\mathrm{\\$\\,MW_{th}^{-1}}$ after one iteration.",
            "answer": "$$\\boxed{\\frac{16}{15}}$$"
        },
        {
            "introduction": "Building on the fundamentals, this practice advances to the more powerful Alternating Direction Method of Multipliers (ADMM) in a dynamic setting. You will apply ADMM to a common problem in networked energy systems: coordinating the future tie-line power flow between two areas using Model Predictive Control. This exercise demonstrates how ADMM achieves consensus on a shared decision trajectory, a cornerstone of distributed control and planning. ",
            "id": "4085653",
            "problem": "Consider a two-area networked energy system connected by a single tie-line. Each area implements Model Predictive Control (MPC) over a finite horizon of length $N=3$ time steps to plan the forecasted tie-line flow trajectory. Let the oriented tie-line flow trajectory be represented by a vector $\\boldsymbol{x}_{i} \\in \\mathbb{R}^{3}$ for area $i \\in \\{\\text{A}, \\text{B}\\}$, with entries in megawatts (MW). Each area seeks to track a forecasted net demand mismatch $\\boldsymbol{d}_{i} \\in \\mathbb{R}^{3}$ while regularizing ramping through a quadratic penalty on first differences. The local convex objective for area $i$ is\n$$\nf_{i}(\\boldsymbol{x}_{i}) \\;=\\; \\frac{1}{2}\\|\\boldsymbol{x}_{i} - \\boldsymbol{d}_{i}\\|_{2}^{2} \\;+\\; \\frac{\\gamma_{i}}{2}\\|D \\boldsymbol{x}_{i}\\|_{2}^{2},\n$$\nwhere $D \\in \\mathbb{R}^{2 \\times 3}$ is the first-difference matrix\n$$\nD \\;=\\; \\begin{pmatrix}\n1  -1  0 \\\\\n0  1  -1\n\\end{pmatrix},\n$$\nand $\\gamma_{i}  0$ is the ramping weight for area $i$.\n\nTo enforce physical consistency of the forecasted tie-line flow, both areas must agree on a shared trajectory represented by a consensus variable $\\boldsymbol{z} \\in \\mathbb{R}^{3}$, i.e., the consensus constraints $\\boldsymbol{x}_{\\text{A}} = \\boldsymbol{z}$ and $\\boldsymbol{x}_{\\text{B}} = \\boldsymbol{z}$. The resulting distributed optimization problem is solved using the Alternating Direction Method of Multipliers (ADMM), which is employed in the scaled form with scaled dual variables $\\boldsymbol{y}_{\\text{A}}$ and $\\boldsymbol{y}_{\\text{B}}$, penalty parameter $\\rho  0$, and standard consensus updates.\n\nStarting from the augmented Lagrangian for the consensus formulation and its scaled form, construct the ADMM scheme by writing the explicit updates for $\\boldsymbol{x}_{\\text{A}}^{k+1}$, $\\boldsymbol{x}_{\\text{B}}^{k+1}$, $\\boldsymbol{z}^{k+1}$, $\\boldsymbol{y}_{\\text{A}}^{k+1}$, and $\\boldsymbol{y}_{\\text{B}}^{k+1}$, specializing the $\\boldsymbol{x}_{i}$-updates to the given quadratic objectives. Then, using the following numerical parameters:\n- Horizon length $N = 3$,\n- Ramping weights $\\gamma_{\\text{A}} = 0.2$ and $\\gamma_{\\text{B}} = 0.5$,\n- Penalty parameter $\\rho = 2$,\n- Initial consensus and duals $\\boldsymbol{z}^{0} = \\boldsymbol{0}$, $\\boldsymbol{y}_{\\text{A}}^{0} = \\boldsymbol{0}$, $\\boldsymbol{y}_{\\text{B}}^{0} = \\boldsymbol{0}$,\n- Forecasted mismatches $\\boldsymbol{d}_{\\text{A}} = \\begin{pmatrix}10 \\\\ 8 \\\\ 6\\end{pmatrix}$ MW and $\\boldsymbol{d}_{\\text{B}} = \\begin{pmatrix}8 \\\\ 9 \\\\ 7\\end{pmatrix}$ MW,\ncompute exactly the second component of the updated consensus trajectory $\\boldsymbol{z}^{1}$ after the first ADMM iteration (i.e., after performing the $\\boldsymbol{x}$-updates and the $\\boldsymbol{z}$-update based on $\\boldsymbol{y}^{0}$). Express your final numerical quantity in megawatts (MW). No rounding is required.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n- **System**: A two-area networked energy system, labeled A and B.\n- **Control Horizon**: $N=3$.\n- **Local Variables**: Tie-line flow trajectory $\\boldsymbol{x}_{i} \\in \\mathbb{R}^{3}$ for area $i \\in \\{\\text{A}, \\text{B}\\}$.\n- **Local Objective Functions**: $f_{i}(\\boldsymbol{x}_{i}) = \\frac{1}{2}\\|\\boldsymbol{x}_{i} - \\boldsymbol{d}_{i}\\|_{2}^{2} + \\frac{\\gamma_{i}}{2}\\|D \\boldsymbol{x}_{i}\\|_{2}^{2}$.\n- **First-Difference Matrix**: $D = \\begin{pmatrix} 1  -1  0 \\\\ 0  1  -1 \\end{pmatrix}$.\n- **Ramping Weights**: $\\gamma_{\\text{A}} = 0.2$ and $\\gamma_{\\text{B}} = 0.5$.\n- **Consensus Variable**: $\\boldsymbol{z} \\in \\mathbb{R}^{3}$.\n- **Consensus Constraints**: $\\boldsymbol{x}_{\\text{A}} = \\boldsymbol{z}$ and $\\boldsymbol{x}_{\\text{B}} = \\boldsymbol{z}$.\n- **Algorithm**: Alternating Direction Method of Multipliers (ADMM) in scaled form.\n- **ADMM Parameters**: Penalty parameter $\\rho = 2$, scaled dual variables $\\boldsymbol{y}_{\\text{A}}, \\boldsymbol{y}_{\\text{B}}$.\n- **Initial Conditions**: $\\boldsymbol{z}^{0} = \\boldsymbol{0}$, $\\boldsymbol{y}_{\\text{A}}^{0} = \\boldsymbol{0}$, $\\boldsymbol{y}_{\\text{B}}^{0} = \\boldsymbol{0}$.\n- **Forecasted Mismatches**: $\\boldsymbol{d}_{\\text{A}} = \\begin{pmatrix} 10 \\\\ 8 \\\\ 6 \\end{pmatrix}$ MW and $\\boldsymbol{d}_{\\text{B}} = \\begin{pmatrix} 8 \\\\ 9 \\\\ 7 \\end{pmatrix}$ MW.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem uses a standard consensus optimization framework (ADMM) to solve a Model Predictive Control (MPC) problem for a networked energy system. The objective function, comprising a tracking term and a Tikhonov regularization term (for ramping), is a standard formulation in control and power systems engineering. This is a well-established and scientifically sound problem.\n- **Well-Posed**: The objective functions $f_i$ are strictly convex because they are sums of squared Euclidean norms, with the term involving $D^T D$ being positive semi-definite and the other terms being strictly convex. The constraints are linear. This defines a convex optimization problem, which has a unique solution. ADMM is a suitable algorithm for this structure and is guaranteed to converge to the optimal solution.\n- **Objective**: The problem is specified using precise mathematical definitions and numerical values. There is no ambiguity or subjective language. All necessary information is provided.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will now be provided.\n\nThe distributed optimization problem is to minimize the sum of local objectives subject to consensus:\n$$ \\min_{\\boldsymbol{x}_{\\text{A}}, \\boldsymbol{x}_{\\text{B}}, \\boldsymbol{z}} f_{\\text{A}}(\\boldsymbol{x}_{\\text{A}}) + f_{\\text{B}}(\\boldsymbol{x}_{\\text{B}}) \\quad \\text{subject to} \\quad \\boldsymbol{x}_{\\text{A}} = \\boldsymbol{z}, \\boldsymbol{x}_{\\text{B}} = \\boldsymbol{z}. $$\nThe scaled-form augmented Lagrangian $L_{\\rho}$ for this problem is:\n$$ L_{\\rho}(\\boldsymbol{x}_{\\text{A}}, \\boldsymbol{x}_{\\text{B}}, \\boldsymbol{z}, \\boldsymbol{y}_{\\text{A}}, \\boldsymbol{y}_{\\text{B}}) = \\sum_{i \\in \\{\\text{A},\\text{B}\\}} \\left( f_{i}(\\boldsymbol{x}_{i}) + \\frac{\\rho}{2}\\|\\boldsymbol{x}_{i} - \\boldsymbol{z} + \\boldsymbol{y}_{i}\\|_{2}^{2} - \\frac{\\rho}{2}\\|\\boldsymbol{y}_{i}\\|_{2}^{2} \\right). $$\nThe ADMM scheme consists of iterative updates. At iteration $k+1$:\n\n1.  **$\\boldsymbol{x}$-updates (in parallel for each area $i$):**\n    $$ \\boldsymbol{x}_{i}^{k+1} = \\arg\\min_{\\boldsymbol{x}_{i}} \\left( f_{i}(\\boldsymbol{x}_{i}) + \\frac{\\rho}{2}\\|\\boldsymbol{x}_{i} - \\boldsymbol{z}^{k} + \\boldsymbol{y}_{i}^{k}\\|_{2}^{2} \\right). $$\n    Substituting the given quadratic objective $f_i$:\n    $$ \\boldsymbol{x}_{i}^{k+1} = \\arg\\min_{\\boldsymbol{x}_{i}} \\left( \\frac{1}{2}\\|\\boldsymbol{x}_{i} - \\boldsymbol{d}_{i}\\|_{2}^{2} + \\frac{\\gamma_{i}}{2}\\|D \\boldsymbol{x}_{i}\\|_{2}^{2} + \\frac{\\rho}{2}\\|\\boldsymbol{x}_{i} - (\\boldsymbol{z}^{k} - \\boldsymbol{y}_{i}^{k})\\|_{2}^{2} \\right). $$\n    The objective is convex and differentiable. We find the minimum by setting the gradient with respect to $\\boldsymbol{x}_{i}$ to zero:\n    $$ (\\boldsymbol{x}_{i} - \\boldsymbol{d}_{i}) + \\gamma_{i} D^{T}D \\boldsymbol{x}_{i} + \\rho(\\boldsymbol{x}_{i} - (\\boldsymbol{z}^{k} - \\boldsymbol{y}_{i}^{k})) = \\boldsymbol{0}. $$\n    Rearranging terms to solve for $\\boldsymbol{x}_{i}$:\n    $$ (I + \\gamma_{i}D^{T}D + \\rho I) \\boldsymbol{x}_{i} = \\boldsymbol{d}_{i} + \\rho(\\boldsymbol{z}^{k} - \\boldsymbol{y}_{i}^{k}). $$\n    The explicit update for $\\boldsymbol{x}_{i}^{k+1}$ is:\n    $$ \\boldsymbol{x}_{i}^{k+1} = \\left((1+\\rho)I + \\gamma_{i}D^{T}D\\right)^{-1} \\left( \\boldsymbol{d}_{i} + \\rho(\\boldsymbol{z}^{k} - \\boldsymbol{y}_{i}^{k}) \\right). $$\n    Thus, for areas A and B, we have:\n    $$ \\boldsymbol{x}_{\\text{A}}^{k+1} = \\left((1+\\rho)I + \\gamma_{\\text{A}}D^{T}D\\right)^{-1} \\left( \\boldsymbol{d}_{\\text{A}} + \\rho(\\boldsymbol{z}^{k} - \\boldsymbol{y}_{\\text{A}}^{k}) \\right) $$\n    $$ \\boldsymbol{x}_{\\text{B}}^{k+1} = \\left((1+\\rho)I + \\gamma_{\\text{B}}D^{T}D\\right)^{-1} \\left( \\boldsymbol{d}_{\\text{B}} + \\rho(\\boldsymbol{z}^{k} - \\boldsymbol{y}_{\\text{B}}^{k}) \\right) $$\n\n2.  **$\\boldsymbol{z}$-update:**\n    $$ \\boldsymbol{z}^{k+1} = \\arg\\min_{\\boldsymbol{z}} \\left( \\frac{\\rho}{2}\\|\\boldsymbol{x}_{\\text{A}}^{k+1} - \\boldsymbol{z} + \\boldsymbol{y}_{\\text{A}}^{k}\\|_{2}^{2} + \\frac{\\rho}{2}\\|\\boldsymbol{x}_{\\text{B}}^{k+1} - \\boldsymbol{z} + \\boldsymbol{y}_{\\text{B}}^{k}\\|_{2}^{2} \\right). $$\n    Setting the gradient with respect to $\\boldsymbol{z}$ to zero:\n    $$ -\\rho(\\boldsymbol{x}_{\\text{A}}^{k+1} - \\boldsymbol{z} + \\boldsymbol{y}_{\\text{A}}^{k}) - \\rho(\\boldsymbol{x}_{\\text{B}}^{k+1} - \\boldsymbol{z} + \\boldsymbol{y}_{\\text{B}}^{k}) = \\boldsymbol{0}. $$\n    Solving for $\\boldsymbol{z}$ gives the average of the primal-dual variables:\n    $$ \\boldsymbol{z}^{k+1} = \\frac{1}{2}\\left( (\\boldsymbol{x}_{\\text{A}}^{k+1} + \\boldsymbol{y}_{\\text{A}}^{k}) + (\\boldsymbol{x}_{\\text{B}}^{k+1} + \\boldsymbol{y}_{\\text{B}}^{k}) \\right). $$\n\n3.  **$\\boldsymbol{y}$-updates (dual variable updates):**\n    $$ \\boldsymbol{y}_{\\text{A}}^{k+1} = \\boldsymbol{y}_{\\text{A}}^{k} + \\boldsymbol{x}_{\\text{A}}^{k+1} - \\boldsymbol{z}^{k+1} $$\n    $$ \\boldsymbol{y}_{\\text{B}}^{k+1} = \\boldsymbol{y}_{\\text{B}}^{k} + \\boldsymbol{x}_{\\text{B}}^{k+1} - \\boldsymbol{z}^{k+1} $$\n\nNow, we compute the first iteration ($k=0$) using the given numerical parameters.\nInitial values: $\\boldsymbol{z}^{0}=\\boldsymbol{0}$, $\\boldsymbol{y}_{\\text{A}}^{0}=\\boldsymbol{0}$, $\\boldsymbol{y}_{\\text{B}}^{0}=\\boldsymbol{0}$.\n\nFirst, compute the matrix $D^{T}D$:\n$$ D^{T}D = \\begin{pmatrix} 1  0 \\\\ -1  1 \\\\ 0  -1 \\end{pmatrix} \\begin{pmatrix} 1  -1  0 \\\\ 0  1  -1 \\end{pmatrix} = \\begin{pmatrix} 1  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  1 \\end{pmatrix}. $$\nThe $\\boldsymbol{x}$-updates at $k=0$ simplify to:\n$$ \\boldsymbol{x}_{i}^{1} = \\left((1+\\rho)I + \\gamma_{i}D^{T}D\\right)^{-1} \\boldsymbol{d}_{i}. $$\nWith $\\rho=2$, we have $1+\\rho=3$.\n\nFor area A ($\\gamma_{\\text{A}}=0.2$):\nLet $H_{\\text{A}} = 3I + 0.2 D^{T}D = \\begin{pmatrix} 3  0  0 \\\\ 0  3  0 \\\\ 0  0  3 \\end{pmatrix} + 0.2 \\begin{pmatrix} 1  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  1 \\end{pmatrix} = \\begin{pmatrix} 3.2  -0.2  0 \\\\ -0.2  3.4  -0.2 \\\\ 0  -0.2  3.2 \\end{pmatrix}$.\nWe solve $H_{\\text{A}}\\boldsymbol{x}_{\\text{A}}^{1} = \\boldsymbol{d}_{\\text{A}}$:\n$$ \\begin{pmatrix} 3.2  -0.2  0 \\\\ -0.2  3.4  -0.2 \\\\ 0  -0.2  3.2 \\end{pmatrix} \\begin{pmatrix} x_{\\text{A},1}^{1} \\\\ x_{\\text{A},2}^{1} \\\\ x_{\\text{A},3}^{1} \\end{pmatrix} = \\begin{pmatrix} 10 \\\\ 8 \\\\ 6 \\end{pmatrix}. $$\nThis is a system of linear equations. Using fractional representation, $H_{\\text{A}} = \\frac{1}{5}\\begin{pmatrix} 16  -1  0 \\\\ -1  17  -1 \\\\ 0  -1  16 \\end{pmatrix}$. The system becomes $\\begin{pmatrix} 16  -1  0 \\\\ -1  17  -1 \\\\ 0  -1  16 \\end{pmatrix}\\boldsymbol{x}_{\\text{A}}^{1} = 5\\boldsymbol{d}_{\\text{A}} = \\begin{pmatrix} 50 \\\\ 40 \\\\ 30 \\end{pmatrix}$.\nSolving this system yields $x_{\\text{A},1}^{1} = \\frac{79}{24}$, $x_{\\text{A},2}^{1} = \\frac{8}{3}$, and $x_{\\text{A},3}^{1} = \\frac{49}{24}$. So, $\\boldsymbol{x}_{\\text{A}}^{1} = \\begin{pmatrix} 79/24 \\\\ 8/3 \\\\ 49/24 \\end{pmatrix}$.\n\nFor area B ($\\gamma_{\\text{B}}=0.5$):\nLet $H_{\\text{B}} = 3I + 0.5 D^{T}D = \\begin{pmatrix} 3  0  0 \\\\ 0  3  0 \\\\ 0  0  3 \\end{pmatrix} + 0.5 \\begin{pmatrix} 1  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  1 \\end{pmatrix} = \\begin{pmatrix} 3.5  -0.5  0 \\\\ -0.5  4  -0.5 \\\\ 0  -0.5  3.5 \\end{pmatrix}$.\nWe solve $H_{\\text{B}}\\boldsymbol{x}_{\\text{B}}^{1} = \\boldsymbol{d}_{\\text{B}}$:\n$$ \\begin{pmatrix} 3.5  -0.5  0 \\\\ -0.5  4  -0.5 \\\\ 0  -0.5  3.5 \\end{pmatrix} \\begin{pmatrix} x_{\\text{B},1}^{1} \\\\ x_{\\text{B},2}^{1} \\\\ x_{\\text{B},3}^{1} \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ 9 \\\\ 7 \\end{pmatrix}. $$\nUsing fractional representation, $H_{\\text{B}} = \\frac{1}{2}\\begin{pmatrix} 7  -1  0 \\\\ -1  8  -1 \\\\ 0  -1  7 \\end{pmatrix}$. The system becomes $\\begin{pmatrix} 7  -1  0 \\\\ -1  8  -1 \\\\ 0  -1  7 \\end{pmatrix}\\boldsymbol{x}_{\\text{B}}^{1} = 2\\boldsymbol{d}_{\\text{B}} = \\begin{pmatrix} 16 \\\\ 18 \\\\ 14 \\end{pmatrix}$.\nSolving this system yields $x_{\\text{B},1}^{1} = \\frac{170}{63}$, $x_{\\text{B},2}^{1} = \\frac{26}{9}$, and $x_{\\text{B},3}^{1} = \\frac{152}{63}$. So, $\\boldsymbol{x}_{\\text{B}}^{1} = \\begin{pmatrix} 170/63 \\\\ 26/9 \\\\ 152/63 \\end{pmatrix}$.\n\nNext, we perform the $\\boldsymbol{z}$-update for $k=0$. With $\\boldsymbol{y}_{\\text{A}}^{0} = \\boldsymbol{0}$ and $\\boldsymbol{y}_{\\text{B}}^{0} = \\boldsymbol{0}$, the update is simply the average of the $\\boldsymbol{x}^{1}$ variables:\n$$ \\boldsymbol{z}^{1} = \\frac{1}{2}(\\boldsymbol{x}_{\\text{A}}^{1} + \\boldsymbol{x}_{\\text{B}}^{1}). $$\nThe problem asks for the second component of $\\boldsymbol{z}^{1}$, denoted $z_{2}^{1}$:\n$$ z_{2}^{1} = \\frac{1}{2}(x_{\\text{A},2}^{1} + x_{\\text{B},2}^{1}). $$\nSubstituting the computed values:\n$$ z_{2}^{1} = \\frac{1}{2}\\left(\\frac{8}{3} + \\frac{26}{9}\\right). $$\nTo add the fractions, we find a common denominator:\n$$ z_{2}^{1} = \\frac{1}{2}\\left(\\frac{8 \\times 3}{3 \\times 3} + \\frac{26}{9}\\right) = \\frac{1}{2}\\left(\\frac{24}{9} + \\frac{26}{9}\\right). $$\n$$ z_{2}^{1} = \\frac{1}{2}\\left(\\frac{24+26}{9}\\right) = \\frac{1}{2}\\left(\\frac{50}{9}\\right). $$\n$$ z_{2}^{1} = \\frac{25}{9}. $$\nThe second component of the updated consensus trajectory $\\boldsymbol{z}^{1}$ is $\\frac{25}{9}$ MW.",
            "answer": "$$ \\boxed{\\frac{25}{9}} $$"
        },
        {
            "introduction": "A crucial aspect of implementing iterative algorithms is knowing when to stop. This final exercise focuses on the practical measures of convergence for ADMM by guiding you through the calculation of primal and dual residuals. Understanding these metrics is essential for developing robust and efficient distributed optimization solvers, as they provide a clear signal that the algorithm has reached a solution that is both feasible and optimal. ",
            "id": "4085665",
            "problem": "Consider a distributed economic dispatch for a networked energy system with three agents (microgrids) coordinated via a consensus variable, formulated for the Alternating Direction Method of Multipliers (ADMM). Let the per-agent generation decision be $g \\in \\mathbb{R}^{3}$ and the global consensus signal be $z \\in \\mathbb{R}$, with the consensus constraint $g_{i} = z$ for $i \\in \\{1,2,3\\}$. Write this as $A g + B z = c$ with $A = I_{3}$, $B = -\\mathbf{1}_{3}$, and $c = \\mathbf{0}_{3}$, where $I_{3}$ is the $3 \\times 3$ identity and $\\mathbf{1}_{3}$ is the $3 \\times 1$ vector of ones. All quantities are expressed in per-unit (dimensionless) on a shared base.\n\nStarting from the definition of the augmented Lagrangian and the Karush–Kuhn–Tucker (KKT) conditions for the linearly constrained convex program, derive the ADMM primal residual $r^{k}$ and dual residual $s^{k}$ in terms of $A$, $B$, $c$, $g^{k}$, $z^{k}$, and $z^{k-1}$ for the scaled form of ADMM. Then, define the stopping criteria based on primal and dual feasibility tolerances $\\epsilon_{\\mathrm{pri}}$ and $\\epsilon_{\\mathrm{dual}}$ using the standard absolute tolerance $\\epsilon_{\\mathrm{abs}}$ and relative tolerance $\\epsilon_{\\mathrm{rel}}$, and the unscaled dual variable $y^{k} = \\rho u^{k}$ where $u^{k}$ is the scaled dual and $\\rho > 0$ is the penalty parameter.\n\nFinally, for a particular ADMM iteration $k$, compute the numerical values of the norms $\\| r^{k} \\|_{2}$ and $\\| s^{k} \\|_{2}$, and the tolerances $\\epsilon_{\\mathrm{pri}}$ and $\\epsilon_{\\mathrm{dual}}$, given:\n- $g^{k} = \\begin{pmatrix} 1.023 \\\\ 0.978 \\\\ 0.999 \\end{pmatrix}$,\n- $z^{k} = 1.000$,\n- $z^{k-1} = 0.994$,\n- $u^{k} = \\begin{pmatrix} 0.15 \\\\ -0.20 \\\\ 0.05 \\end{pmatrix}$,\n- $\\rho = 0.8$,\n- $\\epsilon_{\\mathrm{abs}} = 10^{-3}$,\n- $\\epsilon_{\\mathrm{rel}} = 10^{-2}$.\n\nReport your final results as the row vector $\\left( \\| r^{k} \\|_{2}, \\| s^{k} \\|_{2}, \\epsilon_{\\mathrm{pri}}, \\epsilon_{\\mathrm{dual}} \\right)$, and round your answer to four significant figures. Because all quantities are per-unit, no physical units are required in the final numerical values.",
            "solution": "We begin from the standard convex linearly constrained formulation\n$$\n\\min_{g,\\,z} \\; f(g) + h(z) \\quad \\text{subject to} \\quad A g + B z = c,\n$$\nwith $A = I_{3}$, $B = -\\mathbf{1}_{3}$, and $c = \\mathbf{0}_{3}$ to encode the consensus constraints $g_{i} = z$ for $i \\in \\{1,2,3\\}$. The augmented Lagrangian for penalty parameter $\\rho > 0$ and unscaled dual variable $y$ is\n$$\n\\mathcal{L}_{\\rho}(g, z, y) \\;=\\; f(g) + h(z) + y^{\\top}\\!\\left(A g + B z - c \\right) + \\frac{\\rho}{2} \\left\\| A g + B z - c \\right\\|_{2}^{2}.\n$$\nThe Alternating Direction Method of Multipliers (ADMM) proceeds by alternating minimization in $g$ and $z$, and a dual ascent step. In the scaled form of ADMM, we use the scaled dual variable $u^{k} = \\frac{1}{\\rho} y^{k}$ and define the primal residual at iteration $k$ as the violation of the linear constraint,\n$$\nr^{k} \\;=\\; A g^{k} + B z^{k} - c.\n$$\nThe dual residual arises from the stationarity condition with respect to $g$ and captures the change in the $z$-iterate weighted by the coupling in the constraint. Its standard expression in the scaled ADMM is\n$$\ns^{k} \\;=\\; \\rho\\, A^{\\top} B \\left( z^{k} - z^{k-1} \\right).\n$$\nFor our specific consensus constraint with $A = I_{3}$ and $B = -\\mathbf{1}_{3}$, these simplify to\n$$\nr^{k} \\;=\\; g^{k} - \\mathbf{1}_{3} z^{k}, \\qquad s^{k} \\;=\\; -\\,\\rho\\, \\mathbf{1}_{3} \\left( z^{k} - z^{k-1} \\right).\n$$\n\nADMM stopping criteria compare the primal and dual residual norms to tolerances composed of absolute and relative components. The primal tolerance is\n$$\n\\epsilon_{\\mathrm{pri}} \\;=\\; \\sqrt{p}\\, \\epsilon_{\\mathrm{abs}} \\;+\\; \\epsilon_{\\mathrm{rel}}\\, \\max\\!\\left\\{ \\left\\| A g^{k} \\right\\|_{2},\\, \\left\\| B z^{k} \\right\\|_{2},\\, \\left\\| c \\right\\|_{2} \\right\\},\n$$\nwhere $p$ is the dimension of the constraint (here $p = 3$). The dual tolerance is\n$$\n\\epsilon_{\\mathrm{dual}} \\;=\\; \\sqrt{n}\\, \\epsilon_{\\mathrm{abs}} \\;+\\; \\epsilon_{\\mathrm{rel}}\\, \\left\\| A^{\\top} y^{k} \\right\\|_{2},\n$$\nwhere $n$ is the dimension of $g$ (here $n = 3$) and $y^{k} = \\rho\\, u^{k}$ is the unscaled dual variable.\n\nWe now compute the requested quantities numerically for the given iteration data.\n\nFirst, the primal residual\n$$\nr^{k} \\;=\\; g^{k} - \\mathbf{1}_{3} z^{k} \\;=\\; \\begin{pmatrix} 1.023 \\\\ 0.978 \\\\ 0.999 \\end{pmatrix} - \\begin{pmatrix} 1.000 \\\\ 1.000 \\\\ 1.000 \\end{pmatrix} \\;=\\; \\begin{pmatrix} 0.023 \\\\ -0.022 \\\\ -0.001 \\end{pmatrix}.\n$$\nIts Euclidean norm is\n$$\n\\| r^{k} \\|_{2} \\;=\\; \\sqrt{(0.023)^{2} + (-0.022)^{2} + (-0.001)^{2}} \\;=\\; \\sqrt{0.000529 + 0.000484 + 0.000001} \\;=\\; \\sqrt{0.001014}.\n$$\n\nSecond, the dual residual\n$$\ns^{k} \\;=\\; -\\,\\rho\\, \\mathbf{1}_{3} \\left( z^{k} - z^{k-1} \\right) \\;=\\; -\\,0.8\\, \\mathbf{1}_{3} \\left( 1.000 - 0.994 \\right) \\;=\\; -\\,0.8\\, \\mathbf{1}_{3} \\cdot 0.006 \\;=\\; -\\,0.0048\\, \\mathbf{1}_{3}.\n$$\nIts Euclidean norm is\n$$\n\\| s^{k} \\|_{2} \\;=\\; \\| -0.0048\\, \\mathbf{1}_{3} \\|_{2} \\;=\\; 0.0048\\, \\| \\mathbf{1}_{3} \\|_{2} \\;=\\; 0.0048\\, \\sqrt{3}.\n$$\n\nThird, the primal tolerance requires $\\| A g^{k} \\|_{2}$, $\\| B z^{k} \\|_{2}$, and $\\| c \\|_{2}$. We have\n$$\n\\| A g^{k} \\|_{2} \\;=\\; \\| g^{k} \\|_{2} \\;=\\; \\sqrt{(1.023)^{2} + (0.978)^{2} + (0.999)^{2}} \\;=\\; \\sqrt{1.046529 + 0.956484 + 0.998001} \\;=\\; \\sqrt{3.001014},\n$$\n$$\n\\| B z^{k} \\|_{2} \\;=\\; \\| -\\mathbf{1}_{3} \\cdot 1.000 \\|_{2} \\;=\\; \\| \\mathbf{1}_{3} \\|_{2} \\cdot |1.000| \\;=\\; \\sqrt{3},\n$$\n$$\n\\| c \\|_{2} \\;=\\; \\| \\mathbf{0}_{3} \\|_{2} \\;=\\; 0.\n$$\nTherefore,\n$$\n\\epsilon_{\\mathrm{pri}} \\;=\\; \\sqrt{3}\\, \\epsilon_{\\mathrm{abs}} \\;+\\; \\epsilon_{\\mathrm{rel}} \\cdot \\max\\!\\left\\{ \\sqrt{3.001014},\\, \\sqrt{3},\\, 0 \\right\\} \\;=\\; \\sqrt{3}\\cdot 10^{-3} \\;+\\; 10^{-2} \\cdot \\sqrt{3.001014}.\n$$\n\nFourth, for the dual tolerance we compute $y^{k} = \\rho\\, u^{k} = 0.8 \\begin{pmatrix} 0.15 \\\\ -0.20 \\\\ 0.05 \\end{pmatrix} = \\begin{pmatrix} 0.12 \\\\ -0.16 \\\\ 0.04 \\end{pmatrix}$. Then, with $A^{\\top} = I_{3}$,\n$$\n\\| A^{\\top} y^{k} \\|_{2} \\;=\\; \\| y^{k} \\|_{2} \\;=\\; \\sqrt{(0.12)^{2} + (-0.16)^{2} + (0.04)^{2}} \\;=\\; \\sqrt{0.0144 + 0.0256 + 0.0016} \\;=\\; \\sqrt{0.0416}.\n$$\nThus,\n$$\n\\epsilon_{\\mathrm{dual}} \\;=\\; \\sqrt{3}\\, \\epsilon_{\\mathrm{abs}} \\;+\\; \\epsilon_{\\mathrm{rel}} \\cdot \\| A^{\\top} y^{k} \\|_{2} \\;=\\; \\sqrt{3}\\cdot 10^{-3} \\;+\\; 10^{-2} \\cdot \\sqrt{0.0416}.\n$$\n\nCollecting the numerical values:\n- $\\| r^{k} \\|_{2} = \\sqrt{0.001014}$,\n- $\\| s^{k} \\|_{2} = 0.0048\\, \\sqrt{3}$,\n- $\\epsilon_{\\mathrm{pri}} = \\sqrt{3}\\cdot 10^{-3} + 10^{-2}\\cdot \\sqrt{3.001014}$,\n- $\\epsilon_{\\mathrm{dual}} = \\sqrt{3}\\cdot 10^{-3} + 10^{-2}\\cdot \\sqrt{0.0416}$.\n\nNumerical evaluation and rounding to four significant figures:\n- $\\| r^{k} \\|_{2} \\approx 0.03184$,\n- $\\| s^{k} \\|_{2} \\approx 0.008314$,\n- $\\epsilon_{\\mathrm{pri}} \\approx 0.01906$,\n- $\\epsilon_{\\mathrm{dual}} \\approx 0.003772$.\n\nTherefore, the requested row vector is $\\left( \\| r^{k} \\|_{2}, \\| s^{k} \\|_{2}, \\epsilon_{\\mathrm{pri}}, \\epsilon_{\\mathrm{dual}} \\right)$ with the above rounded values.",
            "answer": "$$\\boxed{\\begin{pmatrix}0.03184  0.008314  0.01906  0.003772\\end{pmatrix}}$$"
        }
    ]
}