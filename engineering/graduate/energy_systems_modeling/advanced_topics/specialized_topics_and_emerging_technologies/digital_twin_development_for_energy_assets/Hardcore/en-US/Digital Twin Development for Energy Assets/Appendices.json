{
    "hands_on_practices": [
        {
            "introduction": "The foundation of a high-fidelity digital twin is often a dynamic model derived from physical first principles. This exercise guides you through this foundational process, starting from the law of conservation of energy to derive the governing partial differential equation (PDE) for temperature in a district heating pipe. You will then use the Finite Volume Method to discretize this PDE into a state-space representation—a set of ordinary differential equations ready for simulation—a cornerstone skill for modeling distributed energy assets .",
            "id": "4084215",
            "problem": "A digital twin of a district heating network requires a dynamical model of temperature evolution in pipes based on conservation laws. Consider a one-dimensional pipe carrying incompressible fluid with constant density and specific heat capacity. Starting from the principle of conservation of energy for a differential control volume, and using Fourier heat conduction and Newton cooling to represent axial dispersion and wall-to-ground heat exchange, the governing partial differential equation (PDE) for the bulk-fluid temperature field is to be derived and then discretized using the Finite Volume Method (FVM).\n\nFundamental base to use:\n- Conservation of energy for a one-dimensional differential control volume of length $\\mathrm{d}x$: the rate of change of internal energy equals the net convective heat inflow plus axial conductive heat inflow minus heat loss to the environment.\n- Newton cooling law for distributed heat exchange per unit length: $q' = h P (T - T_g)$, where $h$ is the convective heat transfer coefficient, $P$ is the wetted perimeter, $T$ is the fluid temperature, and $T_g$ is the ground temperature.\n- Fourier’s law for axial conduction modeled via an effective axial thermal diffusivity $\\alpha$ for the bulk (accounting for dispersion): heat flux proportional to temperature gradient.\n- Definitions: mass density $\\rho$, specific heat capacity $c$, cross-sectional area $A$, axial fluid velocity $v$.\n\nLet the pipe domain be partitioned into $N$ finite volumes of width $\\Delta x$, with cell-average temperatures $T_i(t)$ for indices $i \\in \\{0,\\dots,N-1\\}$. Use an upwind numerical flux for advection assuming strictly positive velocity $v \\ge 0$, a central difference for axial dispersion, and boundary conditions given by a prescribed inlet temperature $T_{\\mathrm{in}}(t)$ and an outflow convective boundary at the outlet. Assume the ground temperature $T_g$ is constant. The semidiscrete state-space should be expressed in the continuous-time form\n$$\n\\frac{\\mathrm{d}\\mathbf{T}}{\\mathrm{d}t} = \\mathbf{A}\\,\\mathbf{T} + \\mathbf{b}_{\\mathrm{in}}\\,T_{\\mathrm{in}} + \\mathbf{b}_{g}\\,T_g,\n$$\nwhere $\\mathbf{T} = [T_0,\\dots,T_{N-1}]^\\top$. Derive the entries of $\\mathbf{A}$ and the input vectors $\\mathbf{b}_{\\mathrm{in}}$ and $\\mathbf{b}_{g}$ by integrating the conservation law over each finite volume with the specified flux approximations and boundary conditions.\n\nTime integration is to be performed using explicit forward Euler for a single-step update. To ensure numerical stability, derive the stability constraints on the time step $\\Delta t$ from first principles, combining the Courant-Friedrichs-Lewy (CFL) condition for advection, the explicit stability bound for axial dispersion, and the explicit bound for the linear sink term originating from wall-to-ground heat exchange. Formulate the final constraint $\\Delta t_{\\max}$ as the minimum of the applicable component-wise bounds. If a coefficient is zero, the corresponding bound is nonrestrictive.\n\nFor test case setup, the parameters are provided in physically consistent units. The program must build the state-space representation for each test case, compute the maximum stable time step bound, and perform any specified single-step update. All temperatures must be treated in kelvin, distances in meters, velocities in meters per second, time in seconds, mass density in kilograms per cubic meter, specific heat capacity in joules per kilogram-kelvin, and heat transfer coefficient in watts per square meter-kelvin.\n\nYour program must implement the following test suite and produce results as specified:\n\n- Test case $1$ (happy path, pure advection):\n  - Pipe length $L = 100\\,\\mathrm{m}$, number of cells $N = 10$, cell width $\\Delta x = 10\\,\\mathrm{m}$.\n  - Velocity $v = 1\\,\\mathrm{m/s}$, axial diffusivity $\\alpha = 0\\,\\mathrm{m^2/s}$, heat transfer coefficient $h = 0\\,\\mathrm{W/(m^2\\,K)}$.\n  - Pipe diameter $D = 0.2\\,\\mathrm{m}$, cross-sectional area $A = \\pi D^2/4$, perimeter $P = \\pi D$.\n  - Fluid properties: $\\rho = 1000\\,\\mathrm{kg/m^3}$, $c = 4180\\,\\mathrm{J/(kg\\,K)}$.\n  - Ground temperature $T_g = 300\\,\\mathrm{K}$, inlet temperature $T_{\\mathrm{in}} = 350\\,\\mathrm{K}$ (constant).\n  - Compute the maximum stable time step bound $\\Delta t_{\\max}$ and check whether a chosen $\\Delta t = 9\\,\\mathrm{s}$ satisfies stability. The output for this case must be a boolean computed as the truth value of $\\Delta t \\le \\Delta t_{\\max}$.\n\n- Test case $2$ (heat-loss dominated bound):\n  - Pipe length $L = 50\\,\\mathrm{m}$, number of cells $N = 5$, cell width $\\Delta x = 10\\,\\mathrm{m}$.\n  - Velocity $v = 0.5\\,\\mathrm{m/s}$, axial diffusivity $\\alpha = 0.05\\,\\mathrm{m^2/s}$, heat transfer coefficient $h = 5\\,\\mathrm{W/(m^2\\,K)}$.\n  - Pipe diameter $D = 0.2\\,\\mathrm{m}$, cross-sectional area $A = \\pi D^2/4$, perimeter $P = \\pi D$.\n  - Fluid properties: $\\rho = 1000\\,\\mathrm{kg/m^3}$, $c = 4180\\,\\mathrm{J/(kg\\,K)}$.\n  - Ground temperature $T_g = 295\\,\\mathrm{K}$, inlet temperature $T_{\\mathrm{in}} = 340\\,\\mathrm{K}$ (constant).\n  - Compute the linear sink coefficient $s = \\frac{h P}{\\rho c A}$ and the maximum stable time step bound $\\Delta t_{\\max}$ resulting from the combined constraints. The output for this case must be a float equal to $\\Delta t_{\\max}$ in seconds.\n\n- Test case $3$ (network coupling: two pipes in series):\n  - Pipe $1$: $L_1 = 80\\,\\mathrm{m}$, $N_1 = 8$, $\\Delta x_1 = 10\\,\\mathrm{m}$, $v_1 = 1.2\\,\\mathrm{m/s}$, $\\alpha_1 = 0.02\\,\\mathrm{m^2/s}$, $D_1 = 0.15\\,\\mathrm{m}$, $h_1 = 4\\,\\mathrm{W/(m^2\\,K)}$, $A_1 = \\pi D_1^2/4$, $P_1 = \\pi D_1$.\n  - Pipe $2$: $L_2 = 60\\,\\mathrm{m}$, $N_2 = 6$, $\\Delta x_2 = 10\\,\\mathrm{m}$, $v_2 = 1.2\\,\\mathrm{m/s}$, $\\alpha_2 = 0.02\\,\\mathrm{m^2/s}$, $D_2 = 0.15\\,\\mathrm{m}$, $h_2 = 6\\,\\mathrm{W/(m^2\\,K)}$, $A_2 = \\pi D_2^2/4$, $P_2 = \\pi D_2$.\n  - Fluid for both pipes: $\\rho = 1000\\,\\mathrm{kg/m^3}$, $c = 4180\\,\\mathrm{J/(kg\\,K)}$.\n  - Ground temperature $T_g = 300\\,\\mathrm{K}$ for both pipes.\n  - Inlet temperature $T_{\\mathrm{in}} = 360\\,\\mathrm{K}$ enters pipe $1$; the outlet temperature of pipe $1$ is used as the inlet temperature for pipe $2$.\n  - Initial cell-average temperatures for both pipes are uniform at $T_i(0) = 350\\,\\mathrm{K}$.\n  - Compute $s_1 = \\frac{h_1 P_1}{\\rho c A_1}$ and $s_2 = \\frac{h_2 P_2}{\\rho c A_2}$. Build $\\mathbf{A}$, $\\mathbf{b}_{\\mathrm{in}}$, and $\\mathbf{b}_{g}$ for each pipe. Let $\\Delta t$ be $0.9$ times the minimum of the stable bounds across both pipes. Perform one explicit forward Euler update simultaneously: update pipe $1$ using $T_{\\mathrm{in}}$ and $T_g$, take its outlet cell temperature $T_{1,\\mathrm{out}}$ after the update, then update pipe $2$ using $T_{1,\\mathrm{out}}$ as its inlet temperature and its $T_g$.\n  - The output for this case must be a list of two floats in kelvin, containing the outlet cell temperatures of pipe $1$ and pipe $2$ after the single-step update.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result1,result2,result3]$), where $result1$ is the boolean from test case $1$, $result2$ is the float from test case $2$ (in seconds), and $result3$ is the list from test case $3$.",
            "solution": "The user wants to solve a heat transfer problem in a district heating pipe, which involves deriving the governing partial differential equation (PDE), discretizing it using the Finite Volume Method (FVM), constructing a state-space model, analyzing its numerical stability, and implementing the solution for specific test cases.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Governing Principles:** Conservation of energy, Fourier's law for axial conduction (modeled with effective axial thermal diffusivity $\\alpha$), Newton's cooling law for wall-to-ground heat exchange.\n- **Physical Quantities  Definitions:** Fluid temperature $T(x,t)$, ground temperature $T_g$, inlet temperature $T_{\\mathrm{in}}(t)$, mass density $\\rho$, specific heat capacity $c$, cross-sectional area $A$, wetted perimeter $P$, axial fluid velocity $v \\ge 0$, convective heat transfer coefficient $h$.\n- **FVM Setup:** One-dimensional domain partitioned into $N$ finite volumes of width $\\Delta x$. Cell-average temperatures are $T_i(t)$ for $i \\in \\{0, \\dots, N-1\\}$.\n- **Numerical Schemes:** Upwind for advection, central difference for axial dispersion.\n- **Boundary Conditions (BCs):** Prescribed inlet temperature $T_{\\mathrm{in}}(t)$ at $x=0$. Convective outflow boundary at the outlet $x=L$.\n- **State-Space Form:** $\\frac{\\mathrm{d}\\mathbf{T}}{\\mathrm{d}t} = \\mathbf{A}\\,\\mathbf{T} + \\mathbf{b}_{\\mathrm{in}}\\,T_{\\mathrm{in}} + \\mathbf{b}_{g}\\,T_g$, where $\\mathbf{T} = [T_0, \\dots, T_{N-1}]^\\top$.\n- **Time Integration:** Explicit forward Euler.\n- **Stability Analysis:** Derive $\\Delta t_{\\max}$ by combining Courant-Friedrichs-Lewy (CFL) for advection, explicit bound for diffusion, and explicit bound for the sink term.\n- **Test Case 1:** $L=100\\,\\mathrm{m}$, $N=10$, $\\Delta x=10\\,\\mathrm{m}$, $v=1\\,\\mathrm{m/s}$, $\\alpha=0\\,\\mathrm{m^2/s}$, $h=0\\,\\mathrm{W/(m^2\\,K)}$, $D=0.2\\,\\mathrm{m}$, $\\rho=1000\\,\\mathrm{kg/m^3}$, $c=4180\\,\\mathrm{J/(kg\\,K)}$, $T_g=300\\,\\mathrm{K}$, $T_{\\mathrm{in}}=350\\,\\mathrm{K}$. Check if $\\Delta t = 9\\,\\mathrm{s}$ is stable.\n- **Test Case 2:** $L=50\\,\\mathrm{m}$, $N=5$, $\\Delta x=10\\,\\mathrm{m}$, $v=0.5\\,\\mathrm{m/s}$, $\\alpha=0.05\\,\\mathrm{m^2/s}$, $h=5\\,\\mathrm{W/(m^2\\,K)}$, $D=0.2\\,\\mathrm{m}$, $\\rho=1000\\,\\mathrm{kg/m^3}$, $c=4180\\,\\mathrm{J/(kg\\,K)}$, $T_g=295\\,\\mathrm{K}$, $T_{\\mathrm{in}}=340\\,\\mathrm{K}$. Compute $\\Delta t_{\\max}$.\n- **Test Case 3:** Two pipes in series.\n  - Pipe 1: $L_1=80\\,\\mathrm{m}$, $N_1=8$, $\\Delta x_1=10\\,\\mathrm{m}$, $v_1=1.2\\,\\mathrm{m/s}$, $\\alpha_1=0.02\\,\\mathrm{m^2/s}$, $D_1=0.15\\,\\mathrm{m}$, $h_1=4\\,\\mathrm{W/(m^2\\,K)}$.\n  - Pipe 2: $L_2=60\\,\\mathrm{m}$, $N_2=6$, $\\Delta x_2=10\\,\\mathrm{m}$, $v_2=1.2\\,\\mathrm{m/s}$, $\\alpha_2=0.02\\,\\mathrm{m^2/s}$, $D_2=0.15\\,\\mathrm{m}$, $h_2=6\\,\\mathrm{W/(m^2\\,K)}$.\n  - Common: $\\rho=1000\\,\\mathrm{kg/m^3}$, $c=4180\\,\\mathrm{J/(kg\\,K)}$, $T_g=300\\,\\mathrm{K}$.\n  - Conditions: $T_{\\mathrm{in},1}=360\\,\\mathrm{K}$, initial uniform temp $T_i(0)=350\\,\\mathrm{K}$ for both pipes. Perform one Euler step with $\\Delta t = 0.9 \\times \\Delta t_{\\max, \\text{system}}$. Output outlet temperatures of both pipes.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is scientifically grounded, deriving from first principles of transport phenomena (conservation of energy). It is well-posed, providing sufficient physical parameters, boundary conditions, and numerical methods to construct a unique model. The language is objective and precise. The tasks are specified clearly. There are no contradictions, ambiguities, or factual unsoundness. The problem is a standard exercise in computational fluid dynamics and heat transfer.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. A full solution will be provided.\n\n### Principle-Based Solution Derivation\n\n**1. Governing PDE Derivation**\nWe apply the principle of conservation of energy to a differential control volume of the fluid within the pipe, of length $\\mathrm{d}x$ and cross-sectional area $A$.\nThe energy balance states:\n(Rate of change of internal energy) = (Net rate of heat advection) + (Net rate of heat conduction) - (Rate of heat loss to surroundings).\n\n- **Internal Energy Change:** The internal energy is $\\rho c (A \\mathrm{d}x) T$. Its rate of change is $\\frac{\\partial}{\\partial t}(\\rho c A T) \\mathrm{d}x$.\n- **Advection:** The heat advected by the fluid flow is $\\dot{m} c T = (\\rho v A) c T$. The net rate of heat inflow is $[(\\rho v A c T)|_x - (\\rho v A c T)|_{x+\\mathrm{d}x}]$.\n- **Conduction (Dispersion):** Fourier's law gives heat flux $q_{cond} = -k_{eff} \\frac{\\partial T}{\\partial x}$. The problem specifies an effective thermal diffusivity $\\alpha = k_{eff}/(\\rho c)$, so the flux is $q_{cond} = -\\rho c \\alpha \\frac{\\partial T}{\\partial x}$. The net heat inflow due to conduction across the control volume's faces is $[(-\\rho c \\alpha A \\frac{\\partial T}{\\partial x})|_x - (-\\rho c \\alpha A \\frac{\\partial T}{\\partial x})|_{x+\\mathrm{d}x}]$.\n- **Heat Loss:** Newton's cooling law gives the heat loss per unit length as $q' = h P (T - T_g)$. For the volume of length $\\mathrm{d}x$, the total heat loss rate is $h P (T - T_g) \\mathrm{d}x$.\n\nCombining these terms:\n$$\n\\rho c A \\frac{\\partial T}{\\partial t} \\mathrm{d}x = [(\\rho v A c T)|_x - (\\rho v A c T)|_{x+\\mathrm{d}x}] + [(-\\rho c \\alpha A \\frac{\\partial T}{\\partial x})|_x - (-\\rho c \\alpha A \\frac{\\partial T}{\\partial x})|_{x+\\mathrm{d}x}] - h P (T - T_g) \\mathrm{d}x\n$$\nDividing by $\\rho c A \\mathrm{d}x$ and taking the limit as $\\mathrm{d}x \\to 0$ gives the partial differential equation:\n$$\n\\frac{\\partial T}{\\partial t} = -v \\frac{\\partial T}{\\partial x} + \\alpha \\frac{\\partial^2 T}{\\partial x^2} - \\frac{hP}{\\rho c A}(T - T_g)\n$$\nLet $s = \\frac{hP}{\\rho c A}$ be the heat loss coefficient. The PDE is:\n$$\n\\frac{\\partial T}{\\partial t} + v \\frac{\\partial T}{\\partial x} = \\alpha \\frac{\\partial^2 T}{\\partial x^2} - s(T - T_g)\n$$\n\n**2. Finite Volume Method (FVM) Discretization**\nWe integrate the PDE over the $i$-th finite volume, from face $i-1/2$ to $i+1/2$, with width $\\Delta x$. Let $T_i$ be the cell-average temperature.\n$$\n\\int_{i-1/2}^{i+1/2} \\frac{\\partial T}{\\partial t} \\mathrm{d}x + \\int_{i-1/2}^{i+1/2} v \\frac{\\partial T}{\\partial x} \\mathrm{d}x = \\int_{i-1/2}^{i+1/2} \\alpha \\frac{\\partial^2 T}{\\partial x^2} \\mathrm{d}x - \\int_{i-1/2}^{i+1/2} s(T - T_g) \\mathrm{d}x\n$$\nApproximating each term:\n- $\\int_{i-1/2}^{i+1/2} \\frac{\\partial T}{\\partial t} \\mathrm{d}x \\approx \\Delta x \\frac{\\mathrm{d}T_i}{\\mathrm{d}t}$\n- Advection flux: $\\int_{i-1/2}^{i+1/2} v \\frac{\\partial T}{\\partial x} \\mathrm{d}x = v[T_{i+1/2} - T_{i-1/2}]$. Using the upwind scheme for $v \\ge 0$, the face temperatures are taken from the upstream cell: $T_{i+1/2} \\approx T_i$ and $T_{i-1/2} \\approx T_{i-1}$. The term becomes $v(T_i - T_{i-1})$.\n- Diffusion flux: $\\int_{i-1/2}^{i+1/2} \\alpha \\frac{\\partial^2 T}{\\partial x^2} \\mathrm{d}x = \\alpha [(\\frac{\\partial T}{\\partial x})_{i+1/2} - (\\frac{\\partial T}{\\partial x})_{i-1/2}]$. Using central differences for gradients at the faces: $(\\frac{\\partial T}{\\partial x})_{i+1/2} \\approx \\frac{T_{i+1}-T_i}{\\Delta x}$ and $(\\frac{\\partial T}{\\partial x})_{i-1/2} \\approx \\frac{T_i-T_{i-1}}{\\Delta x}$. The term becomes $\\alpha \\frac{T_{i+1} - 2T_i + T_{i-1}}{\\Delta x}$.\n- Source term: $\\int_{i-1/2}^{i+1/2} s(T - T_g) \\mathrm{d}x \\approx s(T_i - T_g)\\Delta x$.\n\nSubstituting these into the integrated equation and dividing by $\\Delta x$:\n$$\n\\frac{\\mathrm{d}T_i}{\\mathrm{d}t} + \\frac{v}{\\Delta x}(T_i - T_{i-1}) = \\frac{\\alpha}{(\\Delta x)^2}(T_{i+1} - 2T_i + T_{i-1}) - s(T_i - T_g)\n$$\nRearranging to solve for $\\frac{\\mathrm{d}T_i}{\\mathrm{d}t}$:\n$$\n\\frac{\\mathrm{d}T_i}{\\mathrm{d}t} = \\left(\\frac{v}{\\Delta x} + \\frac{\\alpha}{(\\Delta x)^2}\\right)T_{i-1} - \\left(\\frac{v}{\\Delta x} + \\frac{2\\alpha}{(\\Delta x)^2} + s\\right)T_i + \\frac{\\alpha}{(\\Delta x)^2}T_{i+1} + sT_g\n$$\nThis is valid for internal cells $i \\in \\{1, \\dots, N-2\\}$. We now apply boundary conditions.\n\n- **Inlet ($i=0$):** The prescribed inlet temperature $T_{\\mathrm{in}}$ is a Dirichlet BC. We modify the fluxes at face $-1/2$. The advective flux uses $T_{-1/2} \\approx T_{\\mathrm{in}}$. For diffusion, we use a ghost cell $T_{-1}$ such that $(T_{-1}+T_0)/2=T_{\\mathrm{in}}$, implying $T_{-1} = 2T_{\\mathrm{in}}-T_0$.\nThe equation for $i=0$ becomes:\n$$\n\\frac{\\mathrm{d}T_0}{\\mathrm{d}t} + \\frac{v}{\\Delta x}(T_0 - T_{\\mathrm{in}}) = \\frac{\\alpha}{(\\Delta x)^2}(T_1 - 2T_0 + (2T_{\\mathrm{in}}-T_0)) - s(T_0 - T_g)\n$$\n$$\n\\frac{\\mathrm{d}T_0}{\\mathrm{d}t} = - \\left(\\frac{v}{\\Delta x} + \\frac{3\\alpha}{(\\Delta x)^2} + s \\right) T_0 + \\frac{\\alpha}{(\\Delta x)^2} T_1 + \\left(\\frac{v}{\\Delta x} + \\frac{2\\alpha}{(\\Delta x)^2}\\right) T_{\\mathrm{in}} + s T_g\n$$\n- **Outlet ($i=N-1$):** A convective outflow boundary condition implies zero diffusive flux, $(\\partial T/\\partial x)_L=0$. This is modeled with a ghost cell $T_N=T_{N-1}$.\nThe equation for $i=N-1$ becomes:\n$$\n\\frac{\\mathrm{d}T_{N-1}}{\\mathrm{d}t} + \\frac{v}{\\Delta x}(T_{N-1} - T_{N-2}) = \\frac{\\alpha}{(\\Delta x)^2}(T_{N-1} - 2T_{N-1} + T_{N-2}) - s(T_{N-1} - T_g)\n$$\n$$\n\\frac{\\mathrm{d}T_{N-1}}{\\mathrm{d}t} = \\left(\\frac{v}{\\Delta x} + \\frac{\\alpha}{(\\Delta x)^2}\\right) T_{N-2} - \\left(\\frac{v}{\\Delta x} + \\frac{\\alpha}{(\\Delta x)^2} + s\\right) T_{N-1} + s T_g\n$$\n\n**3. State-Space Model Construction**\nThe system of ODEs can be written in matrix form $\\dot{\\mathbf{T}} = \\mathbf{A}\\mathbf{T} + \\mathbf{b}_{\\mathrm{in}}T_{\\mathrm{in}} + \\mathbf{b}_g T_g$.\nLet $c_{adv} = v/\\Delta x$ and $c_{diff} = \\alpha/(\\Delta x)^2$.\nThe entries of the tridiagonal matrix $\\mathbf{A}$ are:\n- Main diagonal:\n  - $A_{0,0} = -(c_{adv} + 3c_{diff} + s)$\n  - $A_{i,i} = -(c_{adv} + 2c_{diff} + s)$ for $i \\in \\{1, \\dots, N-2\\}$\n  - $A_{N-1,N-1} = -(c_{adv} + c_{diff} + s)$\n- Lower diagonal ($A_{i, i-1}$):\n  - $A_{i,i-1} = c_{adv} + c_{diff}$ for $i \\in \\{1, \\dots, N-1\\}$\n- Upper diagonal ($A_{i, i+1}$):\n  - $A_{i,i+1} = c_{diff}$ for $i \\in \\{0, \\dots, N-2\\}$\n\nThe input vectors $\\mathbf{b}_{\\mathrm{in}}$ and $\\mathbf{b}_g$ are:\n- $\\mathbf{b}_{\\mathrm{in}} = [c_{adv} + 2c_{diff}, 0, \\dots, 0]^\\top$\n- $\\mathbf{b}_g = [s, s, \\dots, s]^\\top$\n\n**4. Stability of Forward Euler Integration**\nThe forward Euler method for $\\dot{\\mathbf{T}}=f(\\mathbf{T})$ is $\\mathbf{T}^{n+1} = \\mathbf{T}^n + \\Delta t f(\\mathbf{T}^n)$. For numerical stability of this explicit method, the time step $\\Delta t$ must be sufficiently small. The constraints from each physical process are considered separately and the most restrictive one is chosen.\n- **Advection (CFL Condition):** The Courant number $C = v \\Delta t / \\Delta x$ must be less than or equal to $1$. This gives $\\Delta t_{adv} \\le \\frac{\\Delta x}{v}$.\n- **Diffusion:** The diffusion number $d = \\alpha \\Delta t / (\\Delta x)^2$ must be less than or equal to $1/2$. This gives $\\Delta t_{diff} \\le \\frac{(\\Delta x)^2}{2\\alpha}$.\n- **Reaction (Sink Term):** For the ODE $\\dot{T} = -sT$, the update is $T^{n+1} = (1-s\\Delta t)T^n$. For stability, $|1-s\\Delta t| \\le 1$, which requires $s\\Delta t \\le 2$. This gives a a bound $\\Delta t_{sink} \\le \\frac{2}{s}$.\n\nIf any coefficient ($v$, $\\alpha$, or $s$) is zero, the corresponding constraint is non-restrictive (infinite bound). The overall maximum stable time step is the minimum of these individual bounds:\n$$\n\\Delta t_{\\max} = \\min\\left( \\frac{\\Delta x}{v}, \\frac{(\\Delta x)^2}{2\\alpha}, \\frac{2}{s} \\right)\n$$",
            "answer": "```python\nimport numpy as np\n\ndef build_system(N, v, alpha, D, h, rho, c, dx):\n    \"\"\"\n    Builds the state-space matrices A, b_in, and b_g for the pipe model.\n    \"\"\"\n    if v  0:\n        raise ValueError(\"Velocity v must be non-negative.\")\n    \n    A_geom = np.pi * D**2 / 4\n    P = np.pi * D\n    \n    s = (h * P) / (rho * c * A_geom) if rho * c * A_geom  0 else 0\n    \n    c_adv = v / dx if dx  0 else 0\n    c_diff = alpha / dx**2 if dx  0 else 0\n    \n    A = np.zeros((N, N))\n    b_in = np.zeros(N)\n    b_g = np.full(N, s)\n    \n    # Inlet cell i=0\n    if N  0:\n        A[0, 0] = -(c_adv + 3 * c_diff + s)\n        b_in[0] = c_adv + 2 * c_diff\n        if N  1:\n            A[0, 1] = c_diff\n\n    # Internal cells i = 1 to N-2\n    for i in range(1, N - 1):\n        A[i, i-1] = c_adv + c_diff\n        A[i, i]   = -(c_adv + 2 * c_diff + s)\n        A[i, i+1] = c_diff\n        \n    # Outlet cell i=N-1\n    if N  1:\n        A[N-1, N-2] = c_adv + c_diff\n        A[N-1, N-1] = -(c_adv + c_diff + s)\n        \n    return A, b_in, b_g, s\n\n\ndef get_max_stable_dt(dx, v, alpha, s):\n    \"\"\"\n    Calculates the maximum stable time step based on individual constraints.\n    \"\"\"\n    dt_adv = dx / v if v  0 else np.inf\n    dt_diff = dx**2 / (2 * alpha) if alpha  0 else np.inf\n    dt_sink = 2 / s if s  0 else np.inf\n    \n    return min(dt_adv, dt_diff, dt_sink)\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    results = []\n\n    # --- Test Case 1: Happy path, pure advection ---\n    L1, N1, v1, alpha1, h1, D1 = 100.0, 10, 1.0, 0.0, 0.0, 0.2\n    rho1, c1 = 1000.0, 4180.0\n    Tg1, Tin1 = 300.0, 350.0\n    dt1_chosen = 9.0\n    \n    dx1 = L1 / N1\n    A1_geom = np.pi * D1**2 / 4\n    P1 = np.pi * D1\n    s1 = (h1 * P1) / (rho1 * c1 * A1_geom) if rho1 * c1 * A1_geom  0 else 0\n    dt1_max = get_max_stable_dt(dx1, v1, alpha1, s1)\n    results.append(dt1_chosen = dt1_max)\n\n    # --- Test Case 2: Heat-loss dominated bound ---\n    L2, N2, v2, alpha2, h2, D2 = 50.0, 5, 0.5, 0.05, 5.0, 0.2\n    rho2, c2 = 1000.0, 4180.0\n    \n    dx2 = L2 / N2\n    A2_geom = np.pi * D2**2 / 4\n    P2 = np.pi * D2\n    s2 = (h2 * P2) / (rho2 * c2 * A2_geom)\n    dt2_max = get_max_stable_dt(dx2, v2, alpha2, s2)\n    results.append(dt2_max)\n\n    # --- Test Case 3: Network coupling: two pipes in series ---\n    # Pipe 1 params\n    L3_1, N3_1, v3_1, alpha3_1, h3_1, D3_1 = 80.0, 8, 1.2, 0.02, 4.0, 0.15\n    dx3_1 = L3_1 / N3_1\n    \n    # Pipe 2 params\n    L3_2, N3_2, v3_2, alpha3_2, h3_2, D3_2 = 60.0, 6, 1.2, 0.02, 6.0, 0.15\n    dx3_2 = L3_2 / N3_2\n    \n    # Common params\n    rho3, c3 = 1000.0, 4180.0\n    Tg3 = 300.0\n    Tin_pipe1 = 360.0\n    T_initial = 350.0\n\n    # Build systems\n    A3_1, b_in3_1, b_g3_1, s3_1 = build_system(N3_1, v3_1, alpha3_1, D3_1, h3_1, rho3, c3, dx3_1)\n    A3_2, b_in3_2, b_g3_2, s3_2 = build_system(N3_2, v3_2, alpha3_2, D3_2, h3_2, rho3, c3, dx3_2)\n\n    # Stability analysis for the whole system\n    dt_max1 = get_max_stable_dt(dx3_1, v3_1, alpha3_1, s3_1)\n    dt_max2 = get_max_stable_dt(dx3_2, v3_2, alpha3_2, s3_2)\n    dt_system_max = min(dt_max1, dt_max2)\n    dt3 = 0.9 * dt_system_max\n    \n    # Initial temperatures\n    T_pipe1 = np.full(N3_1, T_initial)\n    T_pipe2 = np.full(N3_2, T_initial)\n    \n    # --- Single-step update ---\n    # 1. Update Pipe 1\n    dT1_dt = A3_1 @ T_pipe1 + b_in3_1 * Tin_pipe1 + b_g3_1 * Tg3\n    T_pipe1_new = T_pipe1 + dt3 * dT1_dt\n    T_out_pipe1 = T_pipe1_new[-1]\n    \n    # 2. Update Pipe 2 using outlet of Pipe 1 as inlet\n    Tin_pipe2 = T_out_pipe1\n    dT2_dt = A3_2 @ T_pipe2 + b_in3_2 * Tin_pipe2 + b_g3_2 * Tg3\n    T_pipe2_new = T_pipe2 + dt3 * dT2_dt\n    T_out_pipe2 = T_pipe2_new[-1]\n\n    results.append([T_out_pipe1, T_out_pipe2])\n    \n    # Final print statement in the exact required format\n    # Using a custom mapping to handle list-within-list formatting\n    results_str = []\n    for res in results:\n        if isinstance(res, list):\n            # Format list with no spaces\n            results_str.append(f\"[{','.join(f'{x:.16g}' for x in res)}]\")\n        elif isinstance(res, float):\n            results_str.append(f'{res:.16g}')\n        else:\n            results_str.append(str(res))\n            \n    print(f\"[{','.join(results_str)}]\")\n\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        },
        {
            "introduction": "A physics-based or empirical model is only as good as its parameters, and the process of tuning these parameters against experimental data is known as calibration or system identification. This practice delves into this crucial step by having you fit a nonlinear model for a battery's Open-Circuit Voltage (OCV) as a function of its State of Charge (SOC). By deriving and implementing the Gauss-Newton algorithm, you will tackle a common challenge in creating accurate digital twins for energy storage systems .",
            "id": "4084192",
            "problem": "You are designing a calibration module for the digital twin of a lithium-ion battery pack. The twin uses an empirical Open Circuit Voltage (OCV) versus State of Charge (SOC) relationship, and its calibration loop relies on a Nonlinear Least Squares (NLS) estimator updated via the Gauss–Newton method. Construct the estimator and compute the analytic Jacobian needed in the Gauss–Newton update from first principles. Use a differentiable composite model with physically interpretable features to describe the OCV-SOC curve. The goal is to fit model parameters to provided measurement datasets.\n\nDefinitions, model, and assumptions:\n- Let the State of Charge (SOC) be denoted by $s \\in [0,1]$.\n- Let the Open Circuit Voltage (OCV) be denoted by $V_{\\mathrm{oc}}(s;\\theta)$ in volts.\n- Let the measurement data be $\\{(s_i, v_i)\\}_{i=1}^{N}$, where $v_i$ is the measured OCV in volts at SOC $s_i$.\n- Introduce a small positive constant $\\varepsilon$ to avoid singularities at $s=0$ and $s=1$ in logarithmic terms.\n- Use the following parametric model with parameter vector $\\theta \\in \\mathbb{R}^7$:\n$$\nV_{\\mathrm{oc}}(s;\\theta) \\equiv \\theta_0 + \\theta_1 s + \\theta_2 s^2 + \\theta_3 \\ln(s+\\varepsilon) + \\theta_4 \\ln(1-s+\\varepsilon) + \\theta_5 \\exp(-\\theta_6 s).\n$$\nHere, $\\theta_0$, $\\theta_1$, $\\theta_2$, $\\theta_3$, $\\theta_4$, and $\\theta_5$ have units of volts, while $\\theta_6$ is dimensionless. This composite is designed to capture baseline voltage, linear and quadratic SOC trends, entropic effects near the ends of SOC from logarithmic terms, and an exponential tail that models kinetic or side-reaction influences. Physically admissible parameters satisfy $\\theta_6 \\ge 0$.\n- Define the residual vector $r(\\theta) \\in \\mathbb{R}^N$ with entries\n$$\nr_i(\\theta) \\equiv V_{\\mathrm{oc}}(s_i;\\theta) - v_i,\n$$\nand the sum-of-squares objective\n$$\nS(\\theta) \\equiv \\frac{1}{2}\\sum_{i=1}^{N} \\left( r_i(\\theta) \\right)^2.\n$$\n\nTask requirements:\n1. Starting only from the definition of $S(\\theta)$ and first-order Taylor linearization of $r(\\theta)$ around a current iterate, derive the Gauss–Newton step for updating $\\theta$. Explicitly compute the analytic Jacobian $J(\\theta) \\in \\mathbb{R}^{N \\times 7}$ with entries $J_{i,j}(\\theta) \\equiv \\frac{\\partial r_i(\\theta)}{\\partial \\theta_j}$ for the model above. Do not introduce or use any shortcut formulas not justified from these first principles.\n2. Implement an algorithm that, given $(s_i, v_i)$ data, $\\varepsilon$, an initial guess $\\theta^{(0)}$, and a fixed number of iterations, applies the Gauss–Newton method to produce an updated estimate $\\theta^{(K)}$. Enforce the physical admissibility condition by projecting onto $\\theta_6 \\ge 0$ after each update.\n3. Numerical units: express all volt-related parameter outputs in volts, and keep $\\theta_6$ dimensionless. There is no angular quantity in this problem.\n4. Final output format: your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\"). Each result must be a list of seven floats corresponding to the final estimated parameter vector $\\theta^{(K)}$ for a given test case, in the order $[\\theta_0,\\theta_1,\\theta_2,\\theta_3,\\theta_4,\\theta_5,\\theta_6]$. Each float must be rounded to six decimal places. The overall output must be a single line string of the form `[[θ₀⁽ᴷ⁾,θ₁⁽ᴷ⁾,...,θ₆⁽ᴷ⁾],[...],[...]]` with no spaces.\n5. Test suite and coverage:\n   - Case A (general, well-distributed SOC): Let $N=11$, $s_i \\in \\{0.0,0.1,0.2,\\dots,1.0\\}$, $\\varepsilon=10^{-3}$, and synthetic ground-truth parameters\n     $$\n     \\theta^{\\star}_{\\mathrm{A}} = [3.7,\\,0.1,\\,-0.05,\\,0.02,\\,-0.02,\\,0.05,\\,4.0].\n     $$\n     Use noiseless measurements $v_i = V_{\\mathrm{oc}}(s_i;\\theta^{\\star}_{\\mathrm{A}})$ and initial guess\n     $$\n     \\theta^{(0)}_{\\mathrm{A}} = [3.6,\\,0.0,\\,0.0,\\,0.0,\\,0.0,\\,0.1,\\,1.0],\n     $$\n     with $K=12$ Gauss–Newton iterations.\n   - Case B (boundary-dominant behavior, identifiability edge): Let $N=9$, $s_i \\in \\{0.0,0.001,0.01,0.1,0.5,0.9,0.99,0.999,1.0\\}$, $\\varepsilon=10^{-3}$, and ground-truth parameters\n     $$\n     \\theta^{\\star}_{\\mathrm{B}} = [3.9,\\,-0.2,\\,0.3,\\,0.05,\\,0.07,\\,0.0,\\,2.0].\n     $$\n     Use noiseless measurements $v_i = V_{\\mathrm{oc}}(s_i;\\theta^{\\star}_{\\mathrm{B}})$ and initial guess\n     $$\n     \\theta^{(0)}_{\\mathrm{B}} = [3.0,\\,0.1,\\,0.1,\\,0.0,\\,0.0,\\,0.2,\\,5.0],\n     $$\n     with $K=20$ iterations. This case tests the identifiability challenge when $\\theta_5 \\to 0$ causing weak sensitivity to $\\theta_6$.\n   - Case C (many points with deterministic measurement bias): Let $N=21$, $s_i$ uniformly spaced in $[0,1]$, i.e., $s_i = i/20$ for $i=0,1,\\dots,20$, $\\varepsilon=10^{-3}$, and ground-truth parameters\n     $$\n     \\theta^{\\star}_{\\mathrm{C}} = [4.1,\\,-0.05,\\,0.02,\\,-0.03,\\,0.01,\\,0.08,\\,8.0].\n     $$\n     Measurements are biased deterministically by $\\delta_i = 0.001 \\cos(10 s_i)$, so $v_i = V_{\\mathrm{oc}}(s_i;\\theta^{\\star}_{\\mathrm{C}}) + \\delta_i$. Initial guess\n     $$\n     \\theta^{(0)}_{\\mathrm{C}} = [4.0,\\,0.0,\\,0.0,\\,0.0,\\,0.0,\\,0.05,\\,1.0],\n     $$\n     with $K=15$ iterations. This case checks robustness under small structured deviations.\n\nYour program must implement the estimator and produce the final estimates for the three cases, aggregated and printed exactly as specified in the single-line output format. All voltage-related outputs must be in volts, and $\\theta_6$ must be dimensionless. The only permitted libraries are the Python standard library, Numerical Python (NumPy), and SciPy, though SciPy should not be necessary.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the field of energy systems modeling, specifically battery state estimation. It is well-posed, providing a complete and consistent set of definitions, data, and objectives for a standard nonlinear least squares parameter estimation task. The problem is objective and free of any ambiguities or non-formalizable components. We may therefore proceed with the derivation and solution.\n\nThe task is to estimate the parameter vector $\\theta \\in \\mathbb{R}^7$ for a given Open Circuit Voltage (OCV) vs. State of Charge (SOC) model for a lithium-ion battery. The estimation is to be performed using the Gauss-Newton method for nonlinear least squares.\n\nThe model for the OCV, $V_{\\mathrm{oc}}$, as a function of SOC, $s$, and parameters, $\\theta$, is given by:\n$$\nV_{\\mathrm{oc}}(s;\\theta) = \\theta_0 + \\theta_1 s + \\theta_2 s^2 + \\theta_3 \\ln(s+\\varepsilon) + \\theta_4 \\ln(1-s+\\varepsilon) + \\theta_5 \\exp(-\\theta_6 s)\n$$\nwhere $\\theta = [\\theta_0, \\theta_1, \\theta_2, \\theta_3, \\theta_4, \\theta_5, \\theta_6]^T$. We are given a set of $N$ measurements $\\{(s_i, v_i)\\}_{i=1}^{N}$. The residual for the $i$-th measurement is defined as the difference between the model's prediction and the measured value:\n$$\nr_i(\\theta) = V_{\\mathrm{oc}}(s_i;\\theta) - v_i\n$$\nThe goal of the least squares estimation is to find the parameter vector $\\theta$ that minimizes the sum-of-squares of the residuals, $S(\\theta)$:\n$$\nS(\\theta) = \\frac{1}{2}\\sum_{i=1}^{N} \\left( r_i(\\theta) \\right)^2 = \\frac{1}{2} r(\\theta)^T r(\\theta)\n$$\nwhere $r(\\theta) = [r_1(\\theta), r_2(\\theta), \\dots, r_N(\\theta)]^T$ is the residual vector.\n\n**1. Derivation of the Gauss–Newton Step**\n\nThe Gauss-Newton method is an iterative algorithm that finds a local minimum of $S(\\theta)$. At each iteration $k$, we seek an update step $\\Delta\\theta$ such that $\\theta^{(k+1)} = \\theta^{(k)} + \\Delta\\theta$ moves closer to the minimum. The method approximates the nonlinear residual function $r(\\theta)$ with a first-order Taylor expansion around the current estimate $\\theta^{(k)}$:\n$$\nr(\\theta^{(k)} + \\Delta\\theta) \\approx r(\\theta^{(k)}) + J(\\theta^{(k)}) \\Delta\\theta\n$$\nHere, $J(\\theta^{(k)})$ is the Jacobian matrix of the residual vector $r$ evaluated at $\\theta^{(k)}$. Its entries are given by $J_{i,j} = \\frac{\\partial r_i}{\\partial \\theta_j}$.\n\nSubstituting this linear approximation into the objective function $S(\\theta)$:\n$$\nS(\\theta^{(k)} + \\Delta\\theta) \\approx \\frac{1}{2} \\left( r(\\theta^{(k)}) + J(\\theta^{(k)}) \\Delta\\theta \\right)^T \\left( r(\\theta^{(k)}) + J(\\theta^{(k)}) \\Delta\\theta \\right)\n$$\nLet's denote $r^{(k)} = r(\\theta^{(k)})$ and $J^{(k)} = J(\\theta^{(k)})$ for brevity. Expanding the expression gives:\n$$\nS(\\theta^{(k)} + \\Delta\\theta) \\approx \\frac{1}{2} \\left( (r^{(k)})^T r^{(k)} + (r^{(k)})^T J^{(k)} \\Delta\\theta + (\\Delta\\theta)^T (J^{(k)})^T r^{(k)} + (\\Delta\\theta)^T (J^{(k)})^T J^{(k)} \\Delta\\theta \\right)\n$$\nSince $(\\Delta\\theta)^T (J^{(k)})^T r^{(k)}$ is a scalar, it is equal to its transpose, $( (J^{(k)})^T r^{(k)} )^T (\\Delta\\theta) = (r^{(k)})^T (J^{(k)})^{T T} \\Delta\\theta = (r^{(k)})^T J^{(k)} \\Delta\\theta$. Thus, we can combine the two middle terms:\n$$\nS(\\theta^{(k)} + \\Delta\\theta) \\approx \\frac{1}{2} (r^{(k)})^T r^{(k)} + (\\Delta\\theta)^T (J^{(k)})^T r^{(k)} + \\frac{1}{2} (\\Delta\\theta)^T (J^{(k)})^T J^{(k)} \\Delta\\theta\n$$\nTo find the step $\\Delta\\theta$ that minimizes this quadratic approximation, we take the gradient with respect to $\\Delta\\theta$ and set it to zero:\n$$\n\\nabla_{\\Delta\\theta} S \\approx (J^{(k)})^T r^{(k)} + (J^{(k)})^T J^{(k)} \\Delta\\theta = 0\n$$\nThis yields the so-called *normal equations* for the Gauss-Newton step:\n$$\n\\left( (J^{(k)})^T J^{(k)} \\right) \\Delta\\theta = - (J^{(k)})^T r^{(k)}\n$$\nThe step $\\Delta\\theta$ is found by solving this linear system of equations. The parameter update rule is then:\n$$\n\\theta^{(k+1)} = \\theta^{(k)} + \\Delta\\theta\n$$\nThis derivation fulfills the first requirement of the task.\n\n**2. Analytic Jacobian Calculation**\n\nThe second requirement is to compute the analytic Jacobian matrix $J(\\theta)$. The entries are $J_{i,j}(\\theta) = \\frac{\\partial r_i(\\theta)}{\\partial \\theta_j}$. Since $v_i$ is a constant with respect to $\\theta$, this is equivalent to $J_{i,j}(\\theta) = \\frac{\\partial V_{\\mathrm{oc}}(s_i;\\theta)}{\\partial \\theta_j}$. We compute the partial derivatives of $V_{\\mathrm{oc}}(s_i;\\theta)$ with respect to each parameter $\\theta_j$ for $j \\in \\{0, 1, ..., 6\\}$.\n\nFor $\\theta_0$:\n$$ \\frac{\\partial V_{\\mathrm{oc}}}{\\partial \\theta_0} = 1 $$\n\nFor $\\theta_1$:\n$$ \\frac{\\partial V_{\\mathrm{oc}}}{\\partial \\theta_1} = s_i $$\n\nFor $\\theta_2$:\n$$ \\frac{\\partial V_{\\mathrm{oc}}}{\\partial \\theta_2} = s_i^2 $$\n\nFor $\\theta_3$:\n$$ \\frac{\\partial V_{\\mathrm{oc}}}{\\partial \\theta_3} = \\ln(s_i+\\varepsilon) $$\n\nFor $\\theta_4$:\n$$ \\frac{\\partial V_{\\mathrm{oc}}}{\\partial \\theta_4} = \\ln(1-s_i+\\varepsilon) $$\n\nFor $\\theta_5$:\n$$ \\frac{\\partial V_{\\mathrm{oc}}}{\\partial \\theta_5} = \\exp(-\\theta_6 s_i) $$\n\nFor $\\theta_6$:\n$$ \\frac{\\partial V_{\\mathrm{oc}}}{\\partial \\theta_6} = \\frac{\\partial}{\\partial \\theta_6} \\left( \\theta_5 \\exp(-\\theta_6 s_i) \\right) = \\theta_5 \\left( \\exp(-\\theta_6 s_i) \\cdot (-s_i) \\right) = -\\theta_5 s_i \\exp(-\\theta_6 s_i) $$\n\nThus, the $i$-th row of the Jacobian matrix $J(\\theta)$ is the $1 \\times 7$ vector:\n$$\nJ_{i,:} = \\left[ 1, \\quad s_i, \\quad s_i^2, \\quad \\ln(s_i+\\varepsilon), \\quad \\ln(1-s_i+\\varepsilon), \\quad \\exp(-\\theta_6 s_i), \\quad -\\theta_5 s_i \\exp(-\\theta_6 s_i) \\right]\n$$\nThe full Jacobian $J(\\theta)$ is an $N \\times 7$ matrix where each row $i$ corresponds to the measurement data point $s_i$.\n\n**3. Algorithmic Implementation**\n\nThe algorithm proceeds as follows:\n1. Initialize the parameter vector $\\theta$ with the given initial guess $\\theta^{(0)}$.\n2. For $k$ from $0$ to $K-1$:\n    a. For each measurement point $i=1, \\dots, N$:\n        i. Calculate the model prediction $V_{\\mathrm{oc}}(s_i; \\theta^{(k)})$.\n        ii. Calculate the residual $r_i(\\theta^{(k)}) = V_{\\mathrm{oc}}(s_i; \\theta^{(k)}) - v_i$.\n        iii. Calculate the $i$-th row of the Jacobian matrix $J(\\theta^{(k)})$ using the derived analytic expressions.\n    b. Assemble the residual vector $r(\\theta^{(k)}) \\in \\mathbb{R}^N$ and the Jacobian matrix $J(\\theta^{(k)}) \\in \\mathbb{R}^{N \\times 7}$.\n    c. Solve the linear system $(J^T J)\\Delta\\theta = -J^T r$ for the step $\\Delta\\theta$. For better numerical stability, this is equivalent to solving the linear least squares problem $J\\Delta\\theta = -r$.\n    d. Update the parameters: $\\theta_{\\text{temp}} = \\theta^{(k)} + \\Delta\\theta$.\n    e. Enforce the physical admissibility constraint by projecting $\\theta_6$ onto the non-negative half-line: $\\theta_6^{(k+1)} = \\max(0, \\theta_{6, \\text{temp}})$. The other parameters are unconstrained. The final update is $\\theta^{(k+1)} = [\\theta_{0,\\text{temp}}, \\dots, \\theta_{5,\\text{temp}}, \\max(0, \\theta_{6,\\text{temp}})]^T$.\n3. After $K$ iterations, the final estimated parameter vector is $\\theta^{(K)}$.\n\nThis procedure will be implemented for the three test cases provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the Gauss-Newton estimator for all test cases.\n    \"\"\"\n\n    def voc_model(s, theta, eps):\n        \"\"\"\n        Calculates the OCV based on the given parametric model.\n        Args:\n            s (np.ndarray): Array of SOC values.\n            theta (np.ndarray): 7-element parameter vector.\n            eps (float): Small constant to avoid singularities.\n        Returns:\n            np.ndarray: Array of calculated OCV values.\n        \"\"\"\n        th0, th1, th2, th3, th4, th5, th6 = theta\n        s_arr = np.array(s)\n        \n        term0 = th0\n        term1 = th1 * s_arr\n        term2 = th2 * s_arr**2\n        term3 = th3 * np.log(s_arr + eps)\n        term4 = th4 * np.log(1 - s_arr + eps)\n        term5 = th5 * np.exp(-th6 * s_arr)\n        \n        return term0 + term1 + term2 + term3 + term4 + term5\n\n    def get_jacobian(s, theta, eps):\n        \"\"\"\n        Computes the analytic Jacobian of the residual function.\n        Args:\n            s (np.ndarray): Array of SOC values.\n            theta (np.ndarray): 7-element parameter vector.\n            eps (float): Small constant to avoid singularities.\n        Returns:\n            np.ndarray: The N x 7 Jacobian matrix.\n        \"\"\"\n        s_arr = np.array(s)\n        N = s_arr.shape[0]\n        J = np.zeros((N, 7))\n        \n        th5, th6 = theta[5], theta[6]\n        \n        J[:, 0] = 1.0\n        J[:, 1] = s_arr\n        J[:, 2] = s_arr**2\n        J[:, 3] = np.log(s_arr + eps)\n        J[:, 4] = np.log(1 - s_arr + eps)\n        \n        exp_term = np.exp(-th6 * s_arr)\n        J[:, 5] = exp_term\n        J[:, 6] = -th5 * s_arr * exp_term\n        \n        return J\n\n    def gauss_newton_estimator(s_data, v_data, eps, theta_initial, K):\n        \"\"\"\n        Performs parameter estimation using the Gauss-Newton method.\n        Args:\n            s_data (np.ndarray): SOC measurement points.\n            v_data (np.ndarray): OCV measurement points.\n            eps (float): Small constant.\n            theta_initial (list or np.ndarray): Initial guess for parameters.\n            K (int): Number of iterations.\n        Returns:\n            list: The final estimated parameter vector.\n        \"\"\"\n        theta = np.array(theta_initial, dtype=float)\n        \n        for _ in range(K):\n            # Calculate model prediction and residuals\n            v_model = voc_model(s_data, theta, eps)\n            r = v_model - v_data\n            \n            # Calculate Jacobian\n            J = get_jacobian(s_data, theta, eps)\n            \n            # Solve the linear least squares problem J*delta_theta = -r\n            # This is numerically more stable than forming the normal equations explicitly.\n            delta_theta, _, _, _ = np.linalg.lstsq(J, -r, rcond=None)\n            \n            # Update theta\n            theta += delta_theta\n            \n            # Enforce physical admissibility condition by projection\n            theta[6] = max(0.0, theta[6])\n            \n        return theta.tolist()\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"s\": np.linspace(0.0, 1.0, 11),\n            \"eps\": 1e-3,\n            \"theta_star\": [3.7, 0.1, -0.05, 0.02, -0.02, 0.05, 4.0],\n            \"theta0\": [3.6, 0.0, 0.0, 0.0, 0.0, 0.1, 1.0],\n            \"K\": 12,\n            \"bias_func\": lambda s: 0.0,\n        },\n        {\n            \"name\": \"Case B\",\n            \"s\": np.array([0.0, 0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999, 1.0]),\n            \"eps\": 1e-3,\n            \"theta_star\": [3.9, -0.2, 0.3, 0.05, 0.07, 0.0, 2.0],\n            \"theta0\": [3.0, 0.1, 0.1, 0.0, 0.0, 0.2, 5.0],\n            \"K\": 20,\n            \"bias_func\": lambda s: 0.0,\n        },\n        {\n            \"name\": \"Case C\",\n            \"s\": np.linspace(0.0, 1.0, 21),\n            \"eps\": 1e-3,\n            \"theta_star\": [4.1, -0.05, 0.02, -0.03, 0.01, 0.08, 8.0],\n            \"theta0\": [4.0, 0.0, 0.0, 0.0, 0.0, 0.05, 1.0],\n            \"K\": 15,\n            \"bias_func\": lambda s: 0.001 * np.cos(10 * s),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        s_data = case[\"s\"]\n        eps = case[\"eps\"]\n        theta_star = case[\"theta_star\"]\n        \n        # Generate synthetic measurement data v_i\n        v_true = voc_model(s_data, theta_star, eps)\n        bias = case[\"bias_func\"](s_data)\n        v_data = v_true + bias\n        \n        # Run the estimator\n        theta_final = gauss_newton_estimator(\n            s_data, v_data, eps, case[\"theta0\"], case[\"K\"]\n        )\n        results.append(theta_final)\n\n    # Format the final output string as required.\n    inner_strings = []\n    for vec in results:\n        # Round each float to 6 decimal places and format\n        formatted_vec = \",\".join([f\"{x:.6f}\" for x in vec])\n        inner_strings.append(f\"[{formatted_vec}]\")\n    \n    final_output_string = f\"[{','.join(inner_strings)}]\"\n\n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "A digital twin must continuously synchronize with its physical asset by assimilating streams of real-time sensor data. This exercise focuses on an essential data fusion task: how to produce a single, optimal state estimate from multiple, noisy sensor readings. By deriving the Best Linear Unbiased Estimator (BLUE) from first principles, you will discover how to weight each sensor's measurement based on its known uncertainty, a fundamental technique for ensuring the digital twin reflects the most accurate possible reality .",
            "id": "4084247",
            "problem": "A digital twin for an energy pipeline asset maintains a physics-informed estimate of internal pressure by assimilating redundant sensor data at each assimilation step. At a given time stamp, the digital twin receives simultaneous readings from $3$ calibrated, redundant static pressure sensors assumed to measure the same true pipeline pressure $p^{\\ast}$. Each sensor is modeled as an unbiased measurement corrupted by independent, zero-mean Gaussian noise with known variance. Let the measurement model be $y_{i} = p^{\\ast} + \\varepsilon_{i}$, where $\\varepsilon_{i} \\sim \\mathcal{N}(0,\\sigma_{i}^{2})$ and $\\varepsilon_{i}$ are independent across sensors. The digital twin seeks a linear fused estimate $\\hat{p} = \\sum_{i=1}^{3} w_{i} y_{i}$ that is unbiased and has minimum variance. \n\nStarting from the definitions of unbiasedness and variance, and without invoking any pre-derived estimator formulas, formulate and solve the constrained optimization problem that determines the optimal fusion weights using the method of Lagrange multipliers. Explicitly derive the general expression for the optimal weights in terms of the known variances. \n\nThen, using the following sensor data and known variances, compute the fused pressure estimate:\n- Sensor readings: $y_{1} = 102.3$ kPa, $y_{2} = 101.9$ kPa, $y_{3} = 103.1$ kPa.\n- Noise variances: $\\sigma_{1}^{2} = 1.0~\\text{kPa}^{2}$, $\\sigma_{2}^{2} = 4.0~\\text{kPa}^{2}$, $\\sigma_{3}^{2} = 9.0~\\text{kPa}^{2}$.\n\nExpress the final fused pressure in kPa and round your answer to four significant figures. The final answer must be a single real-valued number.",
            "solution": "The problem statement is well-posed, scientifically grounded, and contains all necessary information to derive a unique solution. It is a standard problem in estimation theory, specifically finding the Best Linear Unbiased Estimator (BLUE) for a constant parameter from multiple measurements with known noise characteristics. We shall proceed with the derivation.\n\nThe problem asks for a linear fused estimate of the true pressure $p^{\\ast}$ of the form:\n$$\n\\hat{p} = \\sum_{i=1}^{3} w_{i} y_{i}\n$$\nwhere $y_i$ are the sensor measurements and $w_i$ are the weights to be determined. The measurement model for each sensor is given by $y_{i} = p^{\\ast} + \\varepsilon_{i}$, where the noise terms $\\varepsilon_{i}$ are independent and drawn from a normal distribution with zero mean and variance $\\sigma_{i}^{2}$, i.e., $\\varepsilon_{i} \\sim \\mathcal{N}(0, \\sigma_{i}^{2})$.\n\nThe estimate $\\hat{p}$ must satisfy two conditions: it must be unbiased and have minimum variance.\n\nFirst, we formalize the unbiasedness constraint. An estimator is unbiased if its expected value equals the true value of the parameter being estimated. Here, we require $E[\\hat{p}] = p^{\\ast}$.\n$$\nE[\\hat{p}] = E\\left[\\sum_{i=1}^{3} w_{i} y_{i}\\right]\n$$\nBy the linearity of the expectation operator:\n$$\nE[\\hat{p}] = \\sum_{i=1}^{3} w_{i} E[y_{i}]\n$$\nThe expected value of each measurement is:\n$$\nE[y_{i}] = E[p^{\\ast} + \\varepsilon_{i}] = E[p^{\\ast}] + E[\\varepsilon_{i}]\n$$\nSince $p^{\\ast}$ is a constant (the true pressure at a given time), $E[p^{\\ast}] = p^{\\ast}$. The noise term $\\varepsilon_{i}$ has zero mean, so $E[\\varepsilon_{i}] = 0$. Therefore, $E[y_{i}] = p^{\\ast}$.\nSubstituting this back into the expression for $E[\\hat{p}]$:\n$$\nE[\\hat{p}] = \\sum_{i=1}^{3} w_{i} p^{\\ast} = p^{\\ast} \\sum_{i=1}^{3} w_{i}\n$$\nFor the unbiasedness condition $E[\\hat{p}] = p^{\\ast}$ to hold for any non-zero $p^{\\ast}$, we must have:\n$$\n\\sum_{i=1}^{3} w_{i} = 1\n$$\nThis is the constraint for our optimization problem.\n\nNext, we formulate the objective function, which is the variance of the estimator $\\hat{p}$, to be minimized.\n$$\n\\text{Var}(\\hat{p}) = \\text{Var}\\left(\\sum_{i=1}^{3} w_{i} y_{i}\\right)\n$$\nSince the noise terms $\\varepsilon_{i}$ are independent, the measurements $y_{i}$ are also independent. For independent random variables, the variance of a weighted sum is the weighted sum of the variances:\n$$\n\\text{Var}(\\hat{p}) = \\sum_{i=1}^{3} \\text{Var}(w_{i} y_{i})\n$$\nUsing the variance property $\\text{Var}(aX) = a^2 \\text{Var}(X)$:\n$$\n\\text{Var}(\\hat{p}) = \\sum_{i=1}^{3} w_{i}^{2} \\text{Var}(y_{i})\n$$\nThe variance of a single measurement is:\n$$\n\\text{Var}(y_{i}) = \\text{Var}(p^{\\ast} + \\varepsilon_{i}) = \\text{Var}(\\varepsilon_{i}) = \\sigma_{i}^{2}\n$$\nsince adding a constant ($p^{\\ast}$) does not change the variance.\nThus, the objective function to be minimized is:\n$$\nf(w_1, w_2, w_3) = \\text{Var}(\\hat{p}) = \\sum_{i=1}^{3} w_{i}^{2} \\sigma_{i}^{2}\n$$\n\nThe problem is now a constrained optimization problem: minimize $f(w_1, w_2, w_3) = \\sum_{i=1}^{3} w_{i}^{2} \\sigma_{i}^{2}$ subject to the constraint $g(w_1, w_2, w_3) = \\sum_{i=1}^{3} w_{i} - 1 = 0$. We use the method of Lagrange multipliers. The Lagrangian function $\\mathcal{L}$ is:\n$$\n\\mathcal{L}(w_1, w_2, w_3, \\lambda) = f(w_1, w_2, w_3) - \\lambda g(w_1, w_2, w_3) = \\sum_{i=1}^{3} w_{i}^{2} \\sigma_{i}^{2} - \\lambda \\left(\\sum_{i=1}^{3} w_{i} - 1\\right)\n$$\nTo find the minimum, we set the partial derivatives of $\\mathcal{L}$ with respect to each $w_i$ and $\\lambda$ to zero. For each $i \\in \\{1, 2, 3\\}$:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial w_{i}} = 2 w_{i} \\sigma_{i}^{2} - \\lambda = 0\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = -\\left(\\sum_{i=1}^{3} w_{i} - 1\\right) = 0\n$$\nFrom the first set of equations, we solve for $w_i$ in terms of $\\lambda$:\n$$\nw_{i} = \\frac{\\lambda}{2\\sigma_{i}^{2}}\n$$\nThis shows that the optimal weight for each sensor is inversely proportional to its variance, which is intuitively correct. Now, we substitute this expression for $w_i$ into the constraint equation:\n$$\n\\sum_{i=1}^{3} \\frac{\\lambda}{2\\sigma_{i}^{2}} = 1\n$$\nFactoring out the constant terms:\n$$\n\\frac{\\lambda}{2} \\sum_{i=1}^{3} \\frac{1}{\\sigma_{i}^{2}} = 1\n$$\nSolving for the Lagrange multiplier $\\lambda$:\n$$\n\\lambda = \\frac{2}{\\sum_{j=1}^{3} \\frac{1}{\\sigma_{j}^{2}}}\n$$\nFinally, we substitute $\\lambda$ back into the expression for $w_i$ to find the general formula for the optimal weights:\n$$\nw_{i} = \\frac{1}{2\\sigma_{i}^{2}} \\left( \\frac{2}{\\sum_{j=1}^{3} \\frac{1}{\\sigma_{j}^{2}}} \\right) = \\frac{\\frac{1}{\\sigma_{i}^{2}}}{\\sum_{j=1}^{3} \\frac{1}{\\sigma_{j}^{2}}}\n$$\nThis is the general expression for the optimal fusion weights.\n\nNow, we apply this result to the given data:\n- Sensor readings: $y_{1} = 102.3$ kPa, $y_{2} = 101.9$ kPa, $y_{3} = 103.1$ kPa.\n- Noise variances: $\\sigma_{1}^{2} = 1.0~\\text{kPa}^{2}$, $\\sigma_{2}^{2} = 4.0~\\text{kPa}^{2}$, $\\sigma_{3}^{2} = 9.0~\\text{kPa}^{2}$.\n\nFirst, we compute the inverse variances and their sum. Let $S = \\sum_{j=1}^{3} 1/\\sigma_{j}^{2}$.\n$$\n\\frac{1}{\\sigma_{1}^{2}} = \\frac{1}{1.0} = 1.0\n$$\n$$\n\\frac{1}{\\sigma_{2}^{2}} = \\frac{1}{4.0} = 0.25\n$$\n$$\n\\frac{1}{\\sigma_{3}^{2}} = \\frac{1}{9.0}\n$$\nThe sum is:\n$$\nS = 1.0 + 0.25 + \\frac{1}{9} = \\frac{5}{4} + \\frac{1}{9} = \\frac{45 + 4}{36} = \\frac{49}{36}\n$$\nNow, we calculate the optimal weights $w_i = (1/\\sigma_i^2)/S$:\n$$\nw_{1} = \\frac{1.0}{49/36} = \\frac{36}{49}\n$$\n$$\nw_{2} = \\frac{0.25}{49/36} = \\frac{1/4}{49/36} = \\frac{1}{4} \\cdot \\frac{36}{49} = \\frac{9}{49}\n$$\n$$\nw_{3} = \\frac{1/9}{49/36} = \\frac{1}{9} \\cdot \\frac{36}{49} = \\frac{4}{49}\n$$\nAs a check, the weights sum to unity: $w_1+w_2+w_3 = \\frac{36+9+4}{49} = \\frac{49}{49} = 1$.\n\nFinally, we compute the fused pressure estimate $\\hat{p}$:\n$$\n\\hat{p} = \\sum_{i=1}^{3} w_{i} y_{i} = w_{1}y_{1} + w_{2}y_{2} + w_{3}y_{3}\n$$\n$$\n\\hat{p} = \\left(\\frac{36}{49}\\right)(102.3) + \\left(\\frac{9}{49}\\right)(101.9) + \\left(\\frac{4}{49}\\right)(103.1)\n$$\n$$\n\\hat{p} = \\frac{1}{49} \\left( 36 \\times 102.3 + 9 \\times 101.9 + 4 \\times 103.1 \\right)\n$$\n$$\n\\hat{p} = \\frac{1}{49} \\left( 3682.8 + 917.1 + 412.4 \\right)\n$$\n$$\n\\hat{p} = \\frac{5012.3}{49} \\approx 102.2918367...\n$$\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $1$, $0$, $2$, $2$. The fifth digit is $9$, so we round up the fourth digit.\n$$\n\\hat{p} \\approx 102.3 \\text{ kPa}\n$$",
            "answer": "$$\n\\boxed{102.3}\n$$"
        }
    ]
}