{
    "hands_on_practices": [
        {
            "introduction": "This practice guides you through the end-to-end process of building a reduced-order model (ROM) for a physical system. Starting from the governing equations of a linearized gas pipeline, you will discretize the model, generate simulation data, and then apply Proper Orthogonal Decomposition (POD) and Galerkin projection to create and validate a low-dimensional ROM. This exercise  solidifies the entire theoretical workflow into a concrete computational task.",
            "id": "4114823",
            "problem": "Consider a one-dimensional, isothermal gas pipeline modeled on a periodic domain of length $L$ by the linearized conservation of mass and momentum equations, leading to the first-order system of partial differential equations (PDE): $\\frac{\\partial p}{\\partial t} = -a^2 \\frac{\\partial q}{\\partial x}$ and $\\frac{\\partial q}{\\partial t} = -\\frac{\\partial p}{\\partial x} - f q$, where $p$ denotes pressure deviation around a nominal operating point, $q$ denotes mass flow deviation, $a$ denotes wave speed, and $f$ denotes a small linearized friction coefficient. Discretize the spatial coordinate into $N$ uniformly spaced points with periodic boundary conditions, approximate the spatial derivative $\\frac{\\partial}{\\partial x}$ using a centered finite difference scheme, and form the semi-discrete linear state-space model $\\dot{x} = A x$ with $x = [p;q] \\in \\mathbb{R}^{2N}$ and a block matrix $A$ consistent with the discretization and the PDE structure, where the grid spacing is $\\Delta x = L / N$.\n\nUsing simulated transients of the semi-discrete model, compute Proper Orthogonal Decomposition (POD) modes that capture the dominant spatial-temporal structures of the state. Then, build a Reduced-Order Model (ROM) by a Galerkin projection of the full-order model onto the subspace spanned by the leading POD modes. Validate that the ROM reproduces pressure wave propagation with a specified accuracy by computing the space-time normalized root-mean-square error (NRMSE) of the pressure component between the full-order and reconstructed ROM trajectories. The NRMSE must be reported as a decimal fraction. No physical units are required for this problem; all quantities are dimensionless due to normalization around the nominal operating point.\n\nFundamental base to use: conservation of mass and momentum as stated above, spatial finite differences on a periodic grid, and the definition of POD as the set of orthonormal modes maximizing captured snapshot variance under an $\\ell_2$ inner product. The derivation must proceed from these principles, without introducing shortcut formulas that are not derived from the base.\n\nAlgorithmic requirements:\n- Construct the periodic centered finite difference operator $D \\in \\mathbb{R}^{N \\times N}$ such that for a vector $u \\in \\mathbb{R}^N$, $Du$ approximates $\\frac{\\partial u}{\\partial x}$ on the periodic grid.\n- Form the block matrix $A \\in \\mathbb{R}^{2N \\times 2N}$ consistent with the PDE structure.\n- Initialize a transient with a smooth Gaussian pressure bump and zero mass flow: $p_i(0) = \\exp\\left(-\\frac{(x_i - x_c)^2}{2 \\sigma^2}\\right)$ for grid points $x_i$, with $q_i(0) = 0$.\n- Simulate the full-order linear system using a time-stepping scheme derived from the matrix exponential of $A$ over a fixed time step $\\Delta t$, accumulating snapshots for all time steps from $t=0$ to $t=T$ inclusive.\n- Assemble the snapshot matrix $X \\in \\mathbb{R}^{2N \\times M}$ with columns equal to the concatenated state vectors at each time step, where $M$ is the number of snapshots.\n- Compute POD modes by performing a singular value decomposition of $X$ and extracting the first $r$ left singular vectors as the POD basis $V_r \\in \\mathbb{R}^{2N \\times r}$.\n- Project the full-order dynamics onto the POD subspace to obtain the ROM matrix $A_r = V_r^\\top A V_r \\in \\mathbb{R}^{r \\times r}$, and simulate the ROM using the same time-stepping scheme, with the ROM initial condition $x_r(0) = V_r^\\top x(0)$.\n- Reconstruct the ROM trajectory in the full space as $\\hat{x}(t) = V_r x_r(t)$, extract the pressure components $p(t)$ and $\\hat{p}(t)$, and compute the space-time NRMSE:\n$$\\mathrm{NRMSE} = \\sqrt{\\frac{\\sum_{k=0}^{M-1} \\| p(t_k) - \\hat{p}(t_k) \\|_2^2}{\\sum_{k=0}^{M-1} \\| p(t_k) \\|_2^2}}.$$\n- For each test case, return a boolean indicating whether $\\mathrm{NRMSE} \\leq \\varepsilon$, where $\\varepsilon$ is the specified tolerance.\n\nTest suite:\n- Case $1$: $N = 64$, $L = 1$, $a = 1$, $f = 0.02$, $T = 1.0$, $\\Delta t = 0.002$, $x_c = 0.5$, $\\sigma = 0.12$, $r = 6$, $\\varepsilon = 0.15$.\n- Case $2$: $N = 64$, $L = 1$, $a = 1$, $f = 0.05$, $T = 1.0$, $\\Delta t = 0.002$, $x_c = 0.5$, $\\sigma = 0.12$, $r = 2$, $\\varepsilon = 0.25$.\n- Case $3$: $N = 64$, $L = 1$, $a = 1$, $f = 0.0$, $T = 1.0$, $\\Delta t = 0.002$, $x_c = 0.5$, $\\sigma = 0.12$, $r = 1$, $\\varepsilon = 0.12$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3]$), where each entry is a boolean corresponding to each test case in the order specified above.",
            "solution": "The problem requires the development and validation of a reduced-order model (ROM) for a linearized one-dimensional gas pipeline model using Proper Orthogonal Decomposition (POD). The process involves spatial discretization of the governing partial differential equations (PDEs), simulation of the resulting full-order model (FOM), derivation of a POD basis, construction of the ROM via Galerkin projection, simulation of the ROM, and finally, validation by comparing the ROM's output to the FOM's output.\n\n### 1. Full-Order Model (FOM) Formulation\n\nThe physical system is described by a pair of linearized first-order PDEs on a periodic domain of length $L$:\n$$\n\\frac{\\partial p}{\\partial t} = -a^2 D \\mathbf{q} \\\\\n\\frac{\\partial q}{\\partial t} = -D \\mathbf{p} - f I_N \\mathbf{q}\n$$\nHere, $p(x, t)$ is the pressure deviation, $q(x, t)$ is the mass flow deviation, $a$ is the wave speed, and $f$ is a friction coefficient.\n\nTo formulate a state-space model, we first discretize the spatial domain. We define $N$ uniformly spaced grid points $x_i = i \\Delta x$ for $i = 0, 1, \\dots, N-1$, where the grid spacing is $\\Delta x = L/N$. The state at any time $t$ is represented by vectors of pressure and mass flow at these grid points, denoted $\\mathbf{p}(t) \\in \\mathbb{R}^N$ and $\\mathbf{q}(t) \\in \\mathbb{R}^N$.\n\nThe spatial derivative $\\frac{\\partial}{\\partial x}$ is approximated using a second-order centered finite difference scheme on the periodic grid. For a function $u(x)$ evaluated at the grid points, its derivative at $x_i$ is approximated as:\n$$\n\\frac{\\partial u}{\\partial x} \\bigg|_{x_i} \\approx \\frac{u(x_{i+1}) - u(x_{i-1})}{2 \\Delta x}\n$$\nDue to periodicity, we enforce $u(x_N) = u(x_0)$ and $u(x_{-1}) = u(x_{N-1})$. This numerical differentiation can be expressed in matrix form as $D\\mathbf{u}$, where $D \\in \\mathbb{R}^{N \\times N}$ is the differentiation matrix. Its elements are given by:\n$$\nD_{i,j} =\n\\begin{cases}\n    1 / (2 \\Delta x) & \\text{if } j = (i+1) \\pmod{N} \\\\\n    -1 / (2 \\Delta x) & \\text{if } j = (i-1) \\pmod{N} \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n$$\nThis results in a skew-symmetric circulant matrix, $D^T = -D$.\n\nApplying this discretization to the governing PDEs yields a system of ordinary differential equations (ODEs):\n$$\n\\frac{d\\mathbf{p}}{dt} = -a^2 D \\mathbf{q} \\\\\n\\frac{d\\mathbf{q}}{dt} = -D \\mathbf{p} - f I_N \\mathbf{q}\n$$\nwhere $I_N$ is the $N \\times N$ identity matrix.\n\nWe define the state vector $x \\in \\mathbb{R}^{2N}$ by concatenating the pressure and mass flow vectors: $x = [\\mathbf{p}^T, \\mathbf{q}^T]^T$. The system of ODEs can then be written in the standard linear state-space form $\\dot{x} = Ax$, where the state matrix $A \\in \\mathbb{R}^{2N \\times 2N}$ is a block matrix:\n$$\nA = \\begin{pmatrix}\n0_{N \\times N} & -a^2 D \\\\\n-D & -f I_N\n\\end{pmatrix}\n$$\nHere, $0_{N \\times N}$ is the $N \\times N$ zero matrix. This constitutes our full-order model (FOM).\n\n### 2. FOM Simulation and Snapshot Collection\n\nThe problem specifies an initial condition of a Gaussian pressure bump and zero mass flow:\n$$\np_i(0) = \\exp\\left(-\\frac{(x_i - x_c)^2}{2 \\sigma^2}\\right), \\quad q_i(0) = 0\n$$\nThe FOM is simulated over a time interval $[0, T]$ with a constant time step $\\Delta t$. The exact solution to the linear system $\\dot{x} = Ax$ is given by $x(t) = e^{At}x(0)$. We can use this to step forward in time:\n$$\nx(t_{k+1}) = e^{A \\Delta t} x(t_k)\n$$\nWe collect the state vectors at each time step $t_k = k \\Delta t$ for $k = 0, 1, \\dots, M-1$, where $M = T/\\Delta t + 1$ is the total number of snapshots. These snapshots are assembled as columns of a snapshot matrix $X$:\n$$\nX = [x(t_0), x(t_1), \\dots, x(t_{M-1})] \\in \\mathbb{R}^{2N \\times M}\n$$\n\n### 3. Model Reduction via Proper Orthogonal Decomposition (POD)\n\nThe goal of POD is to find a low-dimensional subspace that best captures the energy (variance) of the snapshot data. The optimal orthonormal basis for this subspace, in the $\\ell_2$ sense, is given by the leading left singular vectors of the snapshot matrix $X$. We compute the Singular Value Decomposition (SVD) of $X$:\n$$\nX = U \\Sigma W^T\n$$\nwhere $U \\in \\mathbb{R}^{2N \\times M}$ (in its economy form) has orthonormal columns (the POD modes), $\\Sigma \\in \\mathbb{R}^{M \\times M}$ is a diagonal matrix of singular values, and $W \\in \\mathbb{R}^{M \\times M}$ has orthonormal columns. The POD modes are the columns of $U$. A reduced basis of rank $r$ is formed by taking the first $r$ columns of $U$, corresponding to the $r$ largest singular values:\n$$\nV_r = U[:, 0:r] \\in \\mathbb{R}^{2N \\times r}\n$$\n\n### 4. Reduced-Order Model (ROM) Formulation and Simulation\n\nA ROM is constructed by projecting the FOM onto the subspace spanned by the POD basis $V_r$. The state $x(t)$ is approximated by a linear combination of the basis vectors: $x(t) \\approx \\hat{x}(t) = V_r x_r(t)$, where $x_r(t) \\in \\mathbb{R}^r$ are the time-dependent modal coefficients. Substituting this approximation into the FOM equation and applying a Galerkin projection (projecting the residual onto the basis $V_r$) yields the ROM:\n$$\nV_r^T (V_r \\dot{x}_r) = V_r^T (A V_r x_r) \\implies \\dot{x}_r = (V_r^T A V_r) x_r\n$$\nThis gives the reduced-order linear system $\\dot{x}_r = A_r x_r$ with the ROM matrix $A_r = V_r^T A V_r \\in \\mathbb{R}^{r \\times r}$.\nThe initial condition for the ROM is obtained by projecting the full initial state: $x_r(0) = V_r^T x(0)$.\nThe ROM is then simulated using the same time-stepping scheme as the FOM:\n$$\nx_r(t_{k+1}) = e^{A_r \\Delta t} x_r(t_k)\n$$\n\n### 5. Validation and Error Quantification\n\nTo validate the ROM, we compare its solution to the FOM's solution. First, the ROM state trajectory $x_r(t_k)$ is reconstructed back into the full state space:\n$$\n\\hat{x}(t_k) = V_r x_r(t_k)\n$$\nThe comparison is performed using the space-time Normalized Root-Mean-Square Error (NRMSE) of the pressure component. The pressure vectors from the FOM and reconstructed ROM trajectories are $p(t_k) = x(t_k)[0:N]$ and $\\hat{p}(t_k) = \\hat{x}(t_k)[0:N]$, respectively. The NRMSE is defined as:\n$$\n\\mathrm{NRMSE} = \\sqrt{\\frac{\\sum_{k=0}^{M-1} \\| p(t_k) - \\hat{p}(t_k) \\|_2^2}{\\sum_{k=0}^{M-1} \\| p(t_k) \\|_2^2}}\n$$\nThis metric quantifies the relative error in the pressure solution over the entire simulation domain and time interval. The validation for each test case consists of checking if the computed $\\mathrm{NRMSE}$ is less than or equal to a given tolerance $\\varepsilon$.",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef solve():\n    \"\"\"\n    Solves the model reduction problem for all specified test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1: N=64, L=1, a=1, f=0.02, T=1.0, dt=0.002, xc=0.5, sigma=0.12, r=6, eps=0.15\n        {'N': 64, 'L': 1.0, 'a': 1.0, 'f': 0.02, 'T': 1.0, 'dt': 0.002, 'xc': 0.5, 'sigma': 0.12, 'r': 6, 'epsilon': 0.15},\n        # Case 2: N=64, L=1, a=1, f=0.05, T=1.0, dt=0.002, xc=0.5, sigma=0.12, r=2, eps=0.25\n        {'N': 64, 'L': 1.0, 'a': 1.0, 'f': 0.05, 'T': 1.0, 'dt': 0.002, 'xc': 0.5, 'sigma': 0.12, 'r': 2, 'epsilon': 0.25},\n        # Case 3: N=64, L=1, a=1, f=0.0, T=1.0, dt=0.002, xc=0.5, sigma=0.12, r=1, eps=0.12\n        {'N': 64, 'L': 1.0, 'a': 1.0, 'f': 0.0, 'T': 1.0, 'dt': 0.002, 'xc': 0.5, 'sigma': 0.12, 'r': 1, 'epsilon': 0.12},\n    ]\n\n    results = []\n    for params in test_cases:\n        results.append(run_simulation_and_reduction(**params))\n\n    # Format the final output as a string list of booleans\n    print(f\"[{','.join(str(r) for r in results)}]\")\n\ndef run_simulation_and_reduction(N, L, a, f, T, dt, xc, sigma, r, epsilon):\n    \"\"\"\n    Carries out the full process for a single test case: FOM simulation, POD, ROM simulation, and validation.\n    \"\"\"\n    # 1. Discretization and Model Setup\n    dx = L / N\n    x_grid = np.linspace(0, L, N, endpoint=False)\n    \n    # 2. Construct spatial differentiation matrix D for periodic BCs\n    D_super_diag = np.ones(N - 1)\n    D_sub_diag = -np.ones(N - 1)\n    D = (np.diag(D_super_diag, k=1) + np.diag(D_sub_diag, k=-1)) / (2 * dx)\n    D[0, N-1] = -1 / (2 * dx)\n    D[N-1, 0] = 1 / (2 * dx)\n\n    # 3. Construct the full-order state matrix A\n    A = np.block([\n        [np.zeros((N, N)), -a**2 * D],\n        [-D, -f * np.identity(N)]\n    ])\n\n    # 4. Initial Condition\n    p0 = np.exp(-(x_grid - xc)**2 / (2 * sigma**2))\n    q0 = np.zeros(N)\n    x0 = np.concatenate([p0, q0])\n\n    # 5. Full-Order Model (FOM) Simulation\n    num_steps = int(round(T / dt))\n    M = num_steps + 1\n    snapshot_matrix = np.zeros((2 * N, M))\n    snapshot_matrix[:, 0] = x0\n    \n    # Time-stepper matrix from matrix exponential\n    E_fom = expm(A * dt)\n    \n    x_current = x0\n    for k in range(1, M):\n        x_current = E_fom @ x_current\n        snapshot_matrix[:, k] = x_current\n\n    # 6. Proper Orthogonal Decomposition (POD)\n    # The economy SVD is sufficient and more efficient.\n    U, s, Vh = np.linalg.svd(snapshot_matrix, full_matrices=False)\n    # POD basis is the first r left singular vectors\n    Vr = U[:, :r]\n\n    # 7. Reduced-Order Model (ROM) Formulation and Simulation\n    Ar = Vr.T @ A @ Vr\n    xr0 = Vr.T @ x0\n    \n    # Time-stepper for ROM\n    E_rom = expm(Ar * dt)\n    \n    xr_snapshots = np.zeros((r, M))\n    xr_snapshots[:, 0] = xr0\n    \n    xr_current = xr0\n    for k in range(1, M):\n        xr_current = E_rom @ xr_current\n        xr_snapshots[:, k] = xr_current\n\n    # 8. Reconstruct ROM trajectory in full space\n    x_hat_snapshots = Vr @ xr_snapshots\n\n    # 9. Compute NRMSE for validation\n    p_fom_snapshots = snapshot_matrix[:N, :]\n    p_rom_reconstructed_snapshots = x_hat_snapshots[:N, :]\n    \n    error_p_matrix = p_fom_snapshots - p_rom_reconstructed_snapshots\n    \n    numerator = np.sum(error_p_matrix**2)\n    denominator = np.sum(p_fom_snapshots**2)\n    \n    if denominator == 0:\n        nrmse = 0.0\n    else:\n        nrmse = np.sqrt(numerator / denominator)\n    \n    # 10. Return boolean result of validation check\n    return nrmse = epsilon\n\nif __name__ == '__main__':\n    solve()\n\n```"
        },
        {
            "introduction": "Once a POD basis is computed, a critical decision is how many modes, $r$, to retain for the reduced-order model. This choice represents a fundamental trade-off between accuracy and computational efficiency. This practice  focuses on the widely used energy criterion, requiring you to derive the selection rule and analyze the consequences of a slowly decaying energy spectrum, a common challenge in complex systems.",
            "id": "4114865",
            "problem": "An energy systems model for a transmission network is simulated over a time window to collect $p$ state snapshots. Let the state dimension be $n$, and assemble the snapshot matrix $X \\in \\mathbb{R}^{n \\times p}$ whose columns are the centered snapshots. Consider Proper Orthogonal Decomposition (POD) under the Euclidean inner product, and let the singular value decomposition of $X$ be $X = U \\Sigma V^{\\top}$ with singular values $\\sigma_{1} \\ge \\sigma_{2} \\ge \\cdots \\ge \\sigma_{q} \\ge 0$, where $q = \\min(n,p)$. Let $U_{r} \\in \\mathbb{R}^{n \\times r}$ denote the first $r$ left singular vectors. The rank-$r$ POD reconstruction of the snapshots is $X_{r} = U_{r} U_{r}^{\\top} X$. Define the total snapshot energy to be the squared Frobenius norm $\\lVert X \\rVert_{F}^{2}$, and the captured energy to be $\\lVert X_{r} \\rVert_{F}^{2}$.\n\nA model reduction requirement is to meet a target captured energy fraction $\\eta^{\\ast} \\in (0,1)$ with the smallest number of modes. Starting from the definitions of the singular value decomposition, the Frobenius norm, and orthogonal projection, derive an explicit criterion in terms of the singular values that selects $r$ as the smallest index meeting the target energy fraction. Then, reason about the implications when the singular values decay slowly, in terms of projection error and computational trade-offs for reduced-order modeling in energy systems.\n\nWhich option both states a correct explicit selection criterion for $r$ and correctly characterizes the trade-offs under slow singular value decay?\n\nA. Choose $r$ as $r = \\min \\{ k \\in \\{1,\\dots,q\\} : \\sum_{i=1}^{k} \\sigma_{i}^{2} / \\sum_{i=1}^{q} \\sigma_{i}^{2} \\ge \\eta^{\\ast} \\}$, since $\\lVert X_{r} \\rVert_{F}^{2} = \\sum_{i=1}^{r} \\sigma_{i}^{2}$ and $\\lVert X \\rVert_{F}^{2} = \\sum_{i=1}^{q} \\sigma_{i}^{2}$. If $\\{\\sigma_{i}\\}$ decays slowly, then many modes contribute materially to the energy, so $r$ must be large to meet $\\eta^{\\ast}$. This increases offline costs (e.g., singular value decomposition on a larger retained subspace), online costs (e.g., reduced-order simulation scales with $r$), memory, and possibly stiffness/conditioning of the reduced dynamics, while providing diminishing accuracy gains per additional mode; alternative responses include relaxing $\\eta^{\\ast}$, goal-oriented POD, hyper-reduction, or reweighting snapshots.\n\nB. Choose $r$ as $r = \\min \\{ k : \\sum_{i=1}^{k} \\sigma_{i} / \\sum_{i=1}^{q} \\sigma_{i} \\ge \\eta^{\\ast} \\}$, since energy is the sum of singular values, not their squares. If $\\{\\sigma_{i}\\}$ decays slowly, the threshold is reached with a small $r$, ensuring both high accuracy and aggressive reduction without trade-offs.\n\nC. Choose $r$ by requiring $\\sigma_{r} / \\sigma_{1} \\ge \\eta^{\\ast}$, because the relative magnitude of the $r$-th singular value controls the projection error. If $\\{\\sigma_{i}\\}$ decays slowly, $\\sigma_{r}$ remains close to $\\sigma_{1}$ for moderate $r$, so one can take small $r$ without sacrificing accuracy, avoiding computational overhead.\n\nD. Choose $r$ at the first index where a large relative gap appears, i.e., $\\sigma_{r} / \\sigma_{r+1} \\ge \\tau$ for a fixed $\\tau  1$, because the spectral gap identifies the intrinsic dimensionality; the energy fraction is not required. Under slow decay, there is no clear gap, so $r$ is ambiguous, but using any small $r$ is acceptable because the gap heuristic supersedes the energy target.\n\nE. Replace the Euclidean inner product by an energy-weighted inner product with a mass matrix $M \\succ 0$, and choose $r = \\min \\{ k : \\sum_{i=1}^{k} \\lambda_{i} / \\sum_{i=1}^{q} \\lambda_{i} \\ge \\eta^{\\ast} \\}$, where $\\{ \\lambda_{i} \\}$ are eigenvalues of $X^{\\top} M X$. Slow decay of $\\{ \\sigma_{i} \\}$ is irrelevant because weighting reorders modes to meet any $\\eta^{\\ast}$ with small $r$, eliminating trade-offs.",
            "solution": "The problem statement has been analyzed and is determined to be valid. It is scientifically grounded, well-posed, and objective, providing a complete and consistent setup for a standard problem in model order reduction using Proper Orthogonal Decomposition (POD).\n\nThe task is to derive an explicit criterion for selecting the reduced-order model dimension $r$ and to analyze the implications of a slow decay in singular values.\n\n**1. Derivation of the Selection Criterion for $r$**\n\nThe problem defines the total snapshot energy as $\\mathcal{E} = \\lVert X \\rVert_{F}^{2}$ and the captured energy in a rank-$r$ model as $\\mathcal{E}_{r} = \\lVert X_{r} \\rVert_{F}^{2}$. The requirement is to find the smallest integer $r$ such that the captured energy fraction meets a target $\\eta^{\\ast} \\in (0,1)$. This can be stated as:\n$$\n\\frac{\\mathcal{E}_{r}}{\\mathcal{E}} = \\frac{\\lVert X_{r} \\rVert_{F}^{2}}{\\lVert X \\rVert_{F}^{2}} \\ge \\eta^{\\ast}\n$$\n\nWe must express both the numerator and the denominator in terms of the singular values $\\{\\sigma_i\\}$ of the snapshot matrix $X$.\n\nThe Frobenius norm of a matrix $A$ is related to its singular values. The squared Frobenius norm is the sum of the squares of its singular values. Let's derive this from first principles. The squared Frobenius norm is the sum of squared entries, which is also the trace of $A^{\\top}A$: $\\lVert A \\rVert_{F}^{2} = \\mathrm{Tr}(A^{\\top}A)$.\n\nFor the total energy $\\mathcal{E}$, we use the snapshot matrix $X$ with its singular value decomposition (SVD) $X = U \\Sigma V^{\\top}$.\n$$\n\\mathcal{E} = \\lVert X \\rVert_{F}^{2} = \\mathrm{Tr}(X^{\\top}X) = \\mathrm{Tr}\\left( (U \\Sigma V^{\\top})^{\\top} (U \\Sigma V^{\\top}) \\right)\n$$\nUsing the property $(ABC)^{\\top} = C^{\\top}B^{\\top}A^{\\top}$:\n$$\n\\mathcal{E} = \\mathrm{Tr}(V \\Sigma^{\\top} U^{\\top} U \\Sigma V^{\\top})\n$$\nThe matrix $U$ consists of orthonormal columns, so $U^{\\top}U = I$, the identity matrix.\n$$\n\\mathcal{E} = \\mathrm{Tr}(V \\Sigma^{\\top} \\Sigma V^{\\top})\n$$\nUsing the cyclic property of the trace, $\\mathrm{Tr}(ABC) = \\mathrm{Tr}(CAB)$:\n$$\n\\mathcal{E} = \\mathrm{Tr}(\\Sigma^{\\top} \\Sigma V^{\\top}V)\n$$\nThe matrix $V$ also consists of orthonormal columns, so $V^{\\top}V = I$.\n$$\n\\mathcal{E} = \\mathrm{Tr}(\\Sigma^{\\top} \\Sigma)\n$$\nThe matrix $\\Sigma \\in \\mathbb{R}^{n \\times p}$ has the singular values $\\sigma_1, \\dots, \\sigma_q$ on its main diagonal, where $q = \\min(n,p)$. The matrix $\\Sigma^{\\top}\\Sigma$ is a $p \\times p$ diagonal matrix whose first $q$ diagonal entries are $\\sigma_1^2, \\dots, \\sigma_q^2$. The trace is the sum of the diagonal elements.\n$$\n\\mathcal{E} = \\lVert X \\rVert_{F}^{2} = \\sum_{i=1}^{q} \\sigma_{i}^{2}\n$$\n\nFor the captured energy $\\mathcal{E}_{r}$, we use the rank-$r$ POD reconstruction $X_{r} = U_{r} U_{r}^{\\top} X$. The matrix $P_r = U_r U_r^{\\top}$ is the orthogonal projector onto the subspace spanned by the first $r$ POD modes (the columns of $U_r$). By the Eckart-Young-Mirsky theorem, this projection $X_r$ is the best rank-$r$ approximation of $X$ in the Frobenius norm and is given by truncating the SVD of $X$:\n$$\nX_{r} = \\sum_{i=1}^{r} \\sigma_{i} u_{i} v_{i}^{\\top}\n$$\nwhere $u_i$ and $v_i$ are the $i$-th columns of $U$ and $V$, respectively. This matrix $X_r$ has an SVD given by $X_r = U_r \\Sigma_r V_r^{\\top}$, where $U_r \\in \\mathbb{R}^{n \\times r}$, $V_r \\in \\mathbb{R}^{p \\times r}$, and $\\Sigma_r = \\mathrm{diag}(\\sigma_1, \\dots, \\sigma_r)$. Applying the same derivation for the Frobenius norm:\n$$\n\\mathcal{E}_{r} = \\lVert X_{r} \\rVert_{F}^{2} = \\sum_{i=1}^{r} \\sigma_{i}^{2}\n$$\n\nCombining these results, the condition for selecting $r$ becomes:\n$$\n\\frac{\\sum_{i=1}^{r} \\sigma_{i}^{2}}{\\sum_{i=1}^{q} \\sigma_{i}^{2}} \\ge \\eta^{\\ast}\n$$\nSince the problem asks for the smallest number of modes, we select $r$ as the minimum integer $k$ that satisfies this inequality.\n$$\nr = \\min \\left\\{ k \\in \\{1, \\dots, q\\} : \\frac{\\sum_{i=1}^{k} \\sigma_{i}^{2}}{\\sum_{i=1}^{q} \\sigma_{i}^{2}} \\ge \\eta^{\\ast} \\right\\}\n$$\n\n**2. Implications of Slow Singular Value Decay**\n\nA slow decay of singular values means that $\\sigma_i$ decreases slowly as the index $i$ increases. This implies that there is no small set of dominant modes; instead, many modes make a non-negligible contribution to the total energy.\n\n-   **Impact on $r$**: To satisfy the energy criterion for a high target fraction $\\eta^{\\ast}$ (e.g., $\\eta^{\\ast} = 0.999$), the cumulative sum $\\sum_{i=1}^{k} \\sigma_{i}^{2}$ must capture a large portion of the total sum. If the terms $\\sigma_{i}^{2}$ decrease slowly, this cumulative sum will also grow slowly. Consequently, a large number of terms $k$ will be required, meaning the necessary POD rank $r$ will be large.\n\n-   **Computational Trade-offs**: The primary goal of model reduction is to reduce computational cost. A large $r$ works against this objective.\n    -   **Online Cost**: The cost of simulating the reduced-order model (ROM) is a function of $r$. For a system of ODEs, $\\dot{\\mathbf{y}} = \\mathbf{f}(\\mathbf{y})$, where $\\mathbf{y} \\in \\mathbb{R}^{r}$, the cost per time step is typically polynomial in $r$, e.g., $O(r^2)$ or $O(r^3)$. A large $r$ leads to expensive online simulations, diminishing the benefit of model reduction.\n    -   **Offline Cost**: The cost of constructing the ROM includes computing the SVD of the snapshot matrix $X \\in \\mathbb{R}^{n \\times p}$ and storing the basis $U_r \\in \\mathbb{R}^{n \\times r}$. While the SVD cost itself is often dominated by the dimensions $n$ and $p$, a large $r$ increases memory requirements for storing the basis $U_r$ and potentially for storing reduced-order operators, which can be dense tensors of size scaling with $r$.\n    -   **Accuracy vs. Complexity**: Slow decay implies a poor trade-off. Each additional mode (increasing $r$ by one) adds an amount of energy $\\sigma_{r+1}^2$ to the reconstruction. If this value is small, the accuracy gain is marginal, yet the computational cost increases. This represents a case of diminishing returns.\n    -   **System Properties**: A system with a slow-decaying singular value spectrum is often called \"less reducible.\" This can sometimes be associated with systems that have complex, multi-scale dynamics or chaotic behavior. Including modes with smaller singular values can also introduce stiffness into the reduced dynamical system, complicating its numerical integration.\n\n-   **Alternative Strategies**: When faced with slow decay, a simple energy-based POD may be insufficient. Standard practice involves considering other approaches, such as: relaxing the energy target $\\eta^{\\ast}$ (sacrificing accuracy for speed), using goal-oriented or weighted POD to focus accuracy on a specific quantity of interest, employing hyper-reduction techniques (like DEIM) to reduce the cost of evaluating nonlinear terms, or pre-processing the snapshots to emphasize certain dynamics.\n\n**3. Evaluation of Provided Options**\n\n**A. Choose $r$ as $r = \\min \\{ k \\in \\{1,\\dots,q\\} : \\sum_{i=1}^{k} \\sigma_{i}^{2} / \\sum_{i=1}^{q} \\sigma_{i}^{2} \\ge \\eta^{\\ast} \\}$, since $\\lVert X_{r} \\rVert_{F}^{2} = \\sum_{i=1}^{r} \\sigma_{i}^{2}$ and $\\lVert X \\rVert_{F}^{2} = \\sum_{i=1}^{q} \\sigma_{i}^{2}$. If $\\{\\sigma_{i}\\}$ decays slowly, then many modes contribute materially to the energy, so $r$ must be large to meet $\\eta^{\\ast}$. This increases offline costs (e.g., singular value decomposition on a larger retained subspace), online costs (e.g., reduced-order simulation scales with $r$), memory, and possibly stiffness/conditioning of the reduced dynamics, while providing diminishing accuracy gains per additional mode; alternative responses include relaxing $\\eta^{\\ast}$, goal-oriented POD, hyper-reduction, or reweighting snapshots.**\n-   This option presents the correct selection criterion for $r$, perfectly matching our derivation. The reasoning for the expressions for captured and total energy is also correct. The analysis of slow singular value decay is comprehensive and accurate, correctly identifying that a large $r$ is needed and detailing the resulting trade-offs in computational costs, memory, and accuracy. It also correctly lists relevant advanced strategies used in practice.\n-   **Verdict: Correct.**\n\n**B. Choose $r$ as $r = \\min \\{ k : \\sum_{i=1}^{k} \\sigma_{i} / \\sum_{i=1}^{q} \\sigma_{i} \\ge \\eta^{\\ast} \\}$, since energy is the sum of singular values, not their squares. If $\\{\\sigma_{i}\\}$ decays slowly, the threshold is reached with a small $r$, ensuring both high accuracy and aggressive reduction without trade-offs.**\n-   The selection criterion is incorrect. The problem defines energy via the squared Frobenius norm, which corresponds to the sum of *squared* singular values ($\\sum \\sigma_i^2$), not the sum of singular values ($\\sum \\sigma_i$). The subsequent analysis is also flawed: slow decay necessitates a *large* $r$, not a small one, and claiming there are \"no trade-offs\" is fundamentally incorrect in model reduction.\n-   **Verdict: Incorrect.**\n\n**C. Choose $r$ by requiring $\\sigma_{r} / \\sigma_{1} \\ge \\eta^{\\ast}$, because the relative magnitude of the $r$-th singular value controls the projection error. If $\\{\\sigma_{i}\\}$ decays slowly, $\\sigma_{r}$ remains close to $\\sigma_{1}$ for moderate $r$, so one can take small $r$ without sacrificing accuracy, avoiding computational overhead.**\n-   This proposes a different, heuristic criterion for choosing $r$, which does not satisfy the problem's explicit requirement of meeting a *cumulative energy fraction*. The analysis is also flawed; slow decay means the total error from omitted modes ($\\sum_{i=r+1}^q \\sigma_i^2$) is large for small $r$, so accuracy is indeed sacrificed.\n-   **Verdict: Incorrect.**\n\n**D. Choose $r$ at the first index where a large relative gap appears, i.e., $\\sigma_{r} / \\sigma_{r+1} \\ge \\tau$ for a fixed $\\tau  1$, because the spectral gap identifies the intrinsic dimensionality; the energy fraction is not required. Under slow decay, there is no clear gap, so $r$ is ambiguous, but using any small $r$ is acceptable because the gap heuristic supersedes the energy target.**\n-   This is another heuristic that ignores the problem's explicit objective based on the energy fraction $\\eta^{\\ast}$. It incorrectly claims the energy fraction is not required. The conclusion that \"any small $r$ is acceptable\" is unsubstantiated and disregards the accuracy requirements of the modeling task.\n-   **Verdict: Incorrect.**\n\n**E. Replace the Euclidean inner product by an energy-weighted inner product with a mass matrix $M \\succ 0$, and choose $r = \\min \\{ k : \\sum_{i=1}^{k} \\lambda_{i} / \\sum_{i=1}^{q} \\lambda_{i} \\ge \\eta^{\\ast} \\}$, where $\\{ \\lambda_{i} \\}$ are eigenvalues of $X^{\\top} M X$. Slow decay of $\\{ \\sigma_{i} \\}$ is irrelevant because weighting reorders modes to meet any $\\eta^{\\ast}$ with small $r$, eliminating trade-offs.**\n-   This option changes the problem statement, which explicitly specifies the \"Euclidean inner product\". While weighted POD is a valid technique, it is not the subject of the question. Furthermore, the claim that weighting can \"meet any $\\eta^{\\ast}$ with small $r$, eliminating trade-offs\" is a gross oversimplification and generally false. A different weighting changes the definition of error and may or may not lead to a faster spectral decay; it never eliminates the fundamental trade-off between accuracy and complexity.\n-   **Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Standard POD optimally captures the variance of observed states but may not be optimal for input-output systems. Balanced POD extends this idea by incorporating system-theoretic concepts of controllability and observability, seeking a basis that balances the input energy and output energy. This advanced practice  explores a snapshot-based method for approximating a balanced transformation, connecting data-driven methods with the rich framework of control theory.",
            "id": "4114809",
            "problem": "Consider a stable continuous-time linear time-invariant (LTI) model of an energy system given by the state-space equations $ \\dot{x}(t) = A x(t) + B u(t) $ and $ y(t) = C x(t) $, where $ A \\in \\mathbb{R}^{n \\times n} $ is Hurwitz (all eigenvalues of $ A $ have negative real part), $ B \\in \\mathbb{R}^{n \\times p} $, and $ C \\in \\mathbb{R}^{q \\times n} $. The controllability Gramian $ W_{c} \\in \\mathbb{R}^{n \\times n} $ and observability Gramian $ W_{o} \\in \\mathbb{R}^{n \\times n} $ are defined by the integrals\n$$\nW_{c} = \\int_{0}^{\\infty} \\exp(A t) B B^{\\top} \\exp(A^{\\top} t) \\, dt, \\qquad\nW_{o} = \\int_{0}^{\\infty} \\exp(A^{\\top} t) C^{\\top} C \\exp(A t) \\, dt.\n$$\nBalanced Proper Orthogonal Decomposition (Balanced POD) constructs reduced-order models by approximating these Gramians using time-domain impulse responses of the primal and adjoint systems. Let $ \\{ t_{i} \\}_{i=1}^{m} $ be positive time samples with associated positive quadrature weights $ \\{ w_{i} \\}_{i=1}^{m} $ that consistently approximate integrals over $ [0, \\infty) $ for stable $ A $. Define the primal impulse-response snapshots and the adjoint impulse-response snapshots by\n$$\nX = \\big[ \\sqrt{w_{1}} \\exp(A t_{1}) B \\ \\ \\sqrt{w_{2}} \\exp(A t_{2}) B \\ \\ \\cdots \\ \\ \\sqrt{w_{m}} \\exp(A t_{m}) B \\big] \\in \\mathbb{R}^{n \\times (m p)},\n$$\n$$\nY = \\big[ \\sqrt{w_{1}} \\exp(A^{\\top} t_{1}) C^{\\top} \\ \\ \\sqrt{w_{2}} \\exp(A^{\\top} t_{2}) C^{\\top} \\ \\ \\cdots \\ \\ \\sqrt{w_{m}} \\exp(A^{\\top} t_{m}) C^{\\top} \\big] \\in \\mathbb{R}^{n \\times (m q)}.\n$$\nBy starting from the foundational definitions of $ W_{c} $ and $ W_{o} $, and using the impulse-response characterization of $ \\exp(A t) $ and $ \\exp(A^{\\top} t) $ with the given quadrature rule, derive how $ X X^{\\top} $ and $ Y Y^{\\top} $ approximate $ W_{c} $ and $ W_{o} $, respectively. Then, show that the rectangular matrix $ Y^{\\top} X $ approximates the continuous-time Hankel operator $ \\int_{0}^{\\infty} C \\exp(A t) B \\, dt $ that maps past inputs to future outputs, and explain why its singular value decomposition (SVD) $ Y^{\\top} X = U \\Sigma V^{\\top} $ yields approximate balancing coordinates in which the empirical controllability and observability Gramians are simultaneously diagonal. Finally, express the right balancing transform that produces balanced coordinates directly in terms of the snapshot matrix $ X $ and the SVD factors $ U $, $ \\Sigma $, and $ V $ of $ Y^{\\top} X $. Provide this transform as a single closed-form analytic expression. No numerical evaluation is required, and there is no rounding specification. Your final answer must be a single analytic expression without units.",
            "solution": "The system $ \\dot{x}(t) = A x(t) + B u(t) $ and $ y(t) = C x(t) $ with $ A $ Hurwitz has well-defined controllability and observability Gramians,\n$$\nW_{c} = \\int_{0}^{\\infty} \\exp(A t) B B^{\\top} \\exp(A^{\\top} t) \\, dt, \\qquad\nW_{o} = \\int_{0}^{\\infty} \\exp(A^{\\top} t) C^{\\top} C \\exp(A t) \\, dt,\n$$\nwhich quantify, respectively, the energy required to reach states from inputs and the energy in outputs generated by states. The impulse response of the primal system to $ u(t) = \\delta(t) e_{j} $, where $ e_{j} $ is the $ j $-th canonical basis vector in $ \\mathbb{R}^{p} $, is $ x_{j}(t) = \\exp(A t) b_{j} $, where $ b_{j} $ is the $ j $-th column of $ B $. Collecting these for all inputs $ j = 1, \\dots, p $ produces the primal impulse-response matrix $ \\exp(A t) B \\in \\mathbb{R}^{n \\times p} $. Similarly, for the adjoint system $ \\dot{z}(t) = A^{\\top} z(t) + C^{\\top} v(t) $ driven by $ v(t) = \\delta(t) e_{\\ell} $, $ \\ell = 1, \\dots, q $, the impulse response is $ z_{\\ell}(t) = \\exp(A^{\\top} t) c_{\\ell} $, where $ c_{\\ell} $ is the $ \\ell $-th column of $ C^{\\top} $. Collecting these yields $ \\exp(A^{\\top} t) C^{\\top} \\in \\mathbb{R}^{n \\times q} $.\n\nTo approximate the integrals defining $ W_{c} $ and $ W_{o} $, we use the quadrature rule with nodes $ \\{ t_{i} \\}_{i=1}^{m} $ and weights $ \\{ w_{i} \\}_{i=1}^{m} $, yielding\n$$\nW_{c} \\approx \\sum_{i=1}^{m} w_{i} \\exp(A t_{i}) B B^{\\top} \\exp(A^{\\top} t_{i}}, \\qquad\nW_{o} \\approx \\sum_{i=1}^{m} w_{i} \\exp(A^{\\top} t_{i}) C^{\\top} C \\exp(A t_{i}).\n$$\nDefine the snapshot matrices\n$$\nX = \\big[ \\sqrt{w_{1}} \\exp(A t_{1}) B \\ \\ \\sqrt{w_{2}} \\exp(A t_{2}) B \\ \\ \\cdots \\ \\ \\sqrt{w_{m}} \\exp(A t_{m}) B \\big] \\in \\mathbb{R}^{n \\times (m p)},\n$$\n$$\nY = \\big[ \\sqrt{w_{1}} \\exp(A^{\\top} t_{1}) C^{\\top} \\ \\ \\sqrt{w_{2}} \\exp(A^{\\top} t_{2}) C^{\\top} \\ \\ \\cdots \\ \\ \\sqrt{w_{m}} \\exp(A^{\\top} t_{m}) C^{\\top} \\big] \\in \\mathbb{R}^{n \\times (m q)}.\n$$\nThen,\n$$\nX X^{\\top} = \\sum_{i=1}^{m} w_{i} \\exp(A t_{i}) B \\big( \\exp(A t_{i}) B \\big)^{\\top}\n= \\sum_{i=1}^{m} w_{i} \\exp(A t_{i}) B B^{\\top} \\exp(A^{\\top} t_{i}) \\approx W_{c},\n$$\nand similarly,\n$$\nY Y^{\\top} = \\sum_{i=1}^{m} w_{i} \\exp(A^{\\top} t_{i}) C^{\\top} \\big( \\exp(A^{\\top} t_{i}) C^{\\top} \\big)^{\\top}\n= \\sum_{i=1}^{m} w_{i} \\exp(A^{\\top} t_{i}) C^{\\top} C \\exp(A t_{i}) \\approx W_{o}.\n$$\nThus, $ X X^{\\top} $ and $ Y Y^{\\top} $ are empirical approximations of the Gramians.\n\nNext, consider the rectangular cross-product\n$$\nY^{\\top} X = \\sum_{i=1}^{m} w_{i} \\big( \\exp(A^{\\top} t_{i}) C^{\\top} \\big)^{\\top} \\exp(A t_{i}) B\n= \\sum_{i=1}^{m} w_{i} C \\exp(A t_{i}) B \\approx \\int_{0}^{\\infty} C \\exp(A t) B \\, dt,\n$$\nwhich is an empirical approximation of the continuous-time Hankel operator mapping past inputs to future outputs. The singular value decomposition (SVD) of $ Y^{\\top} X $ is\n$$\nY^{\\top} X = U \\Sigma V^{\\top},\n$$\nwhere $ U \\in \\mathbb{R}^{(m q) \\times r} $ and $ V \\in \\mathbb{R}^{(m p) \\times r} $ have orthonormal columns, $ \\Sigma \\in \\mathbb{R}^{r \\times r} $ is diagonal with positive entries, and $ r = \\operatorname{rank}(Y^{\\top} X) $ (or a chosen truncation). The diagonal entries of $ \\Sigma $ approximate the Hankel singular values of the system, and the columns of $ U $ and $ V $ parameterize input-output dominant directions over the snapshot ensemble.\n\nBalanced coordinates are constructed so that the empirical controllability and observability Gramians coincide and are diagonal. Define the right and left balancing transforms via the primal and adjoint snapshot matrices and the SVD factors by\n$$\n\\Phi := X V \\Sigma^{-1/2}, \\qquad \\Psi := Y U \\Sigma^{-1/2}.\n$$\nWe verify biorthonormality,\n$$\n\\Psi^{\\top} \\Phi = \\Sigma^{-1/2} U^{\\top} Y^{\\top} X V \\Sigma^{-1/2}\n= \\Sigma^{-1/2} U^{\\top} (U \\Sigma V^{\\top}) V \\Sigma^{-1/2}\n= \\Sigma^{-1/2} \\Sigma \\Sigma^{-1/2} = I,\n$$\nwhere we used $ U^{\\top} U = I $ and $ V^{\\top} V = I $. In these coordinates, the empirical Gramians become\n$$\n\\Phi^{\\top} (Y Y^{\\top}) \\Phi\n= \\Sigma^{-1/2} V^{\\top} X^{\\top} Y Y^{\\top} X V \\Sigma^{-1/2}\n= \\Sigma^{-1/2} V^{\\top} (X^{\\top} Y) (Y^{\\top} X) V \\Sigma^{-1/2}.\n$$\nUsing $ Y^{\\top} X = U \\Sigma V^{\\top} $ and $ X^{\\top} Y = (Y^{\\top} X)^{\\top} = V \\Sigma U^{\\top} $, we obtain\n$$\n\\Phi^{\\top} (Y Y^{\\top}) \\Phi\n= \\Sigma^{-1/2} V^{\\top} (V \\Sigma U^{\\top}) (U \\Sigma V^{\\top}) V \\Sigma^{-1/2}\n= \\Sigma^{-1/2} (V^{\\top} V) \\Sigma^{2} (V^{\\top} V) \\Sigma^{-1/2}\n= \\Sigma.\n$$\nSimilarly,\n$$\n\\Psi^{\\top} (X X^{\\top}) \\Psi\n= \\Sigma^{-1/2} U^{\\top} Y^{\\top} X X^{\\top} Y U \\Sigma^{-1/2}\n= \\Sigma^{-1/2} U^{\\top} (Y^{\\top} X) (X^{\\top} Y) U \\Sigma^{-1/2}\n= \\Sigma^{-1/2} U^{\\top} (U \\Sigma V^{\\top}) (V \\Sigma U^{\\top}) U \\Sigma^{-1/2}\n= \\Sigma^{-1/2} (U^{\\top} U) \\Sigma^{2} (U^{\\top} U) \\Sigma^{-1/2}\n= \\Sigma.\n$$\nTherefore, the coordinate transforms $ \\Phi $ and $ \\Psi $ simultaneously diagonalize the empirical controllability and observability Gramians to the same diagonal matrix $ \\Sigma $, constituting an approximation to balanced truncation from first principles using impulse-response snapshots and quadrature. The right balancing transform, expressed directly in terms of the primal snapshots $ X $ and the SVD factors of $ Y^{\\top} X $, is\n$$\n\\Phi = X V \\Sigma^{-1/2}.\n$$\nThis expression completes the derivation of how the SVD of $ Y^{\\top} X $ approximates the balancing transform factors in the snapshot-based Balanced Proper Orthogonal Decomposition (Balanced POD) algorithm.",
            "answer": "$$\\boxed{X V \\Sigma^{-1/2}}$$"
        }
    ]
}