{
    "hands_on_practices": [
        {
            "introduction": "To bridge long-term investment and short-term operations, energy system models often use a reduced set of \"representative periods\" to approximate a full year. However, this temporal aggregation can inadvertently make physically feasible operations appear infeasible. This practice problem  challenges you to determine the minimum number of linked representative periods required to accurately model the cycling of a thermal unit, considering its minimum up and down times. By working through this, you will gain a crucial, hands-on understanding of how to design a model's time horizon to respect core physical constraints.",
            "id": "4102481",
            "problem": "A power system planning model uses a reduced chronological time representation based on representative periods to couple long-term investment decisions with short-term operational feasibility. Consider a single inflexible thermal unit subject to minimum up and minimum down time constraints, scheduled through a binary commitment variable that may only change state at the boundaries of fixed-length representative periods.\n\nAssume the following physically grounded data and modeling choices:\n- Each representative period has length $L$ hours, and periods are linked in sequence to enforce chronology. In this problem, take $L = 24$ hours.\n- The unit has minimum up time $U$ hours and minimum down time $D$ hours. In this problem, take $U = 72$ hours and $D = 36$ hours.\n- The typical weekly residual load pattern is such that, absent minimum time constraints, the unit would be economically committed for $H_{\\text{on}}$ consecutive hours and then decommitted for $H_{\\text{off}}$ consecutive hours within each repeating weekly cycle. In this problem, take $H_{\\text{on}} = 5 \\times 24$ hours and $H_{\\text{off}} = 2 \\times 24$ hours, reflecting five high-load weekdays followed by two low-load weekend days.\n\nStarting only from the core definitions of minimum up and minimum down times in unit commitment and the construction of representative periods as fixed-length chronological blocks, derive a necessary lower bound on the number $K$ of representative periods that must be linked in sequence so that the reduced model can represent at least one full on-off weekly cycle that is feasible with respect to the unit’s minimum time constraints and faithful to the stated weekly load regime. Then, compute the minimum $K$ under the given numerical values. Express the final answer as a single integer (unitless). No rounding is required.",
            "solution": "The problem will be validated before a solution is attempted.\n\n### Step 1: Extract Givens\n- Length of a representative period: $L = 24$ hours.\n- Minimum up time of the thermal unit: $U = 72$ hours.\n- Minimum down time of the thermal unit: $D = 36$ hours.\n- Economic commitment duration per cycle: $H_{\\text{on}} = 5 \\times 24$ hours.\n- Economic decommitment duration per cycle: $H_{\\text{off}} = 2 \\times 24$ hours.\n- The unit's commitment state (on/off) is represented by a binary variable.\n- State changes can only occur at the boundaries of representative periods.\n- The objective is to find the necessary lower bound on the number of linked representative periods, $K$, to represent one full, feasible on-off cycle.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria.\n- **Scientifically Grounded**: The problem is well-grounded in the field of power systems engineering and operations research. The concepts of unit commitment, minimum up/down times, and the use of representative periods (time-slicing) are standard techniques in long-term energy planning models (e.g., capacity expansion models) to manage computational complexity while retaining operational feasibility. The numerical values provided are realistic for a large baseload or mid-merit thermal power plant.\n- **Well-Posed**: The problem is well-posed. It provides a clear objective (find a minimum integer $K$) and a complete set of constraints and parameters ($L, U, D, H_{\\text{on}}, H_{\\text{off}}$). A unique and meaningful solution can be derived from the given information.\n- **Objective**: The problem is stated in precise, objective language common to engineering and mathematical modeling. There are no subjective or ambiguous terms.\n\nThe problem does not exhibit any of the invalidity flaws. It is not scientifically unsound, non-formalizable, incomplete, unrealistic, ill-posed, or trivial. It poses a genuine and relevant question in energy systems modeling.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be derived.\n\n### Solution Derivation\n\nThe problem requires determining the minimum number of sequentially linked representative periods, $K$, needed to model a single, feasible on-off cycle of a thermal unit. The model's time representation is discrete, consisting of periods of length $L$. However, the unit's physical constraints operate in continuous time.\n\nLet the number of consecutive periods the unit is committed (ON) be $N_{\\text{on}}$, and the number of consecutive periods it is decommitted (OFF) be $N_{\\text{off}}$. Since the commitment state can only change at period boundaries, $N_{\\text{on}}$ and $N_{\\text{off}}$ must be integers.\n\nThe total duration of the commitment phase in the model is $T_{\\text{on}} = N_{\\text{on}} L$. This duration must satisfy two conditions:\n1.  **Physical Feasibility**: The commitment duration must respect the unit's minimum up time, $U$. Therefore, $T_{\\text{on}} \\ge U$.\n2.  **Faithfulness to Load Regime**: The model must be capable of representing the economic imperative to be online for $H_{\\text{on}}$ hours. This means the scheduled ON duration must be at least as long as the desired economic ON duration. If $T_{\\text{on}}  H_{\\text{on}}$, the model could not satisfy the economic signal, violating the problem's premise. Therefore, $T_{\\text{on}} \\ge H_{\\text{on}}$.\n\nCombining these two conditions, the total ON time in the reduced model must be greater than or equal to the maximum of the physical and economic requirements:\n$$N_{\\text{on}} L \\ge \\max(U, H_{\\text{on}})$$\nSince $N_{\\text{on}}$ must be an integer, the minimum number of periods required for the ON phase is found by isolating $N_{\\text{on}}$ and taking the ceiling of the resulting expression, as any fractional part would require an additional full period.\n$$N_{\\text{on}} = \\left\\lceil \\frac{\\max(U, H_{\\text{on}})}{L} \\right\\rceil$$\n\nSimilarly, the total duration of the decommitment phase is $T_{\\text{off}} = N_{\\text{off}} L$. This duration must also satisfy two analogous conditions:\n1.  **Physical Feasibility**: The decommitment duration must respect the unit's minimum down time, $D$. Therefore, $T_{\\text{off}} \\ge D$.\n2.  **Faithfulness to Load Regime**: The model must be able to represent the economic imperative to be offline for $H_{\\text{off}}$ hours. Therefore, $T_{\\text{off}} \\ge H_{\\text{off}}$.\n\nCombining these, the total OFF time must satisfy:\n$$N_{\\text{off}} L \\ge \\max(D, H_{\\text{off}})$$\nThe minimum integer number of periods required for the OFF phase is:\n$$N_{\\text{off}} = \\left\\lceil \\frac{\\max(D, H_{\\text{off}})}{L} \\right\\rceil$$\n\nA \"full on-off weekly cycle\" requires a sequence of ON periods followed by a sequence of OFF periods. The total number of representative periods, $K$, needed to model this complete cycle is the sum of the minimum periods for the ON phase and the minimum periods for the OFF phase.\n$$K = N_{\\text{on}} + N_{\\text{off}} = \\left\\lceil \\frac{\\max(U, H_{\\text{on}})}{L} \\right\\rceil + \\left\\lceil \\frac{\\max(D, H_{\\text{off}})}{L} \\right\\rceil$$\n\nNow, we substitute the given numerical values:\n- $L = 24$\n- $U = 72$\n- $D = 36$\n- $H_{\\text{on}} = 5 \\times 24 = 120$\n- $H_{\\text{off}} = 2 \\times 24 = 48$\n\nFirst, calculate $N_{\\text{on}}$:\n$$\\max(U, H_{\\text{on}}) = \\max(72, 120) = 120$$\n$$N_{\\text{on}} = \\left\\lceil \\frac{120}{24} \\right\\rceil = \\lceil 5 \\rceil = 5$$\n\nNext, calculate $N_{\\text{off}}$:\n$$\\max(D, H_{\\text{off}}) = \\max(36, 48) = 48$$\n$$N_{\\text{off}} = \\left\\lceil \\frac{48}{24} \\right\\rceil = \\lceil 2 \\rceil = 2$$\n\nFinally, the total minimum number of linked periods, $K$, is:\n$$K = N_{\\text{on}} + N_{\\text{off}} = 5 + 2 = 7$$\n\nThus, a minimum of $7$ representative periods (each of length $24$ hours) must be linked chronologically to ensure that the model can represent a feasible on-off cycle that is consistent with both the unit's physical constraints and the specified weekly operating pattern.",
            "answer": "$$\\boxed{7}$$"
        },
        {
            "introduction": "Once a model structure links long-term investment with short-term operations, a robust algorithm is needed to solve it efficiently. Benders decomposition is a powerful technique that achieves this by iteratively passing information between an investment \"master\" problem and an operational \"subproblem.\" In this exercise , you will derive the mathematical foundation of this information exchange by constructing the dual of an operational subproblem. This will allow you to formulate a Benders optimality cut and see precisely how the shadow prices of operational constraints inform the marginal value of new capacity in the investment plan.",
            "id": "4102493",
            "problem": "Consider a two-level planning model for an electricity system with a long-term investment master problem and a short-term operations subproblem. The investment vector is $y = (y_{E}, y_{P}, y_{G})$, where $y_{E}$ is the installed storage energy capacity in megawatt-hours (MWh), $y_{P}$ is the installed storage power capacity in megawatts (MW) (assumed to bound both charging and discharging rates), and $y_{G}$ is the installed dispatchable generation capacity in megawatts (MW). For a given investment $y$, the operations subproblem optimizes over $T$ hourly periods. The operational decision variables are, for each hour $t \\in \\{1,\\dots,T\\}$: dispatchable generation $g_{t} \\ge 0$, storage charge $c_{t} \\ge 0$, storage discharge $d_{t} \\ge 0$, and state of charge $s_{t} \\ge 0$. Let demand $D_{t} \\ge 0$ be given, let the initial state of charge be $s_{0} \\ge 0$, and let charging and discharging efficiencies be $\\eta_{c} \\in (0,1]$ and $\\eta_{d} \\in (0,1]$. Let nonnegative linear operating costs be $C_{G}$ (in dollars per megawatt-hour, denoted $\\$\\!/ \\mathrm{MWh}$) for generation, $C_{c}$ (in $\\$\\!/ \\mathrm{MWh}$) for charging, and $C_{d}$ (in $\\$\\!/ \\mathrm{MWh}$) for discharging. The operations subproblem is the following linear program:\n$$\n\\min_{g_{t},\\,c_{t},\\,d_{t},\\,s_{t} \\ge 0} \\;\\sum_{t=1}^{T} \\big( C_{G}\\, g_{t} + C_{c}\\, c_{t} + C_{d}\\, d_{t} \\big)\n$$\nsubject to, for all $t=1,\\dots,T$,\n$$\n\\text{(balance)}\\quad g_{t} + d_{t} - c_{t} = D_{t},\n$$\n$$\n\\text{(intertemporal)}\\quad s_{t} = s_{t-1} + \\eta_{c}\\, c_{t} - \\eta_{d}^{-1} d_{t},\n$$\n$$\n\\text{(gen cap)}\\quad g_{t} \\le y_{G},\n$$\n$$\n\\text{(charge cap)}\\quad c_{t} \\le y_{P},\n$$\n$$\n\\text{(discharge cap)}\\quad d_{t} \\le y_{P},\n$$\n$$\n\\text{(energy cap)}\\quad s_{t} \\le y_{E},\n$$\nand the terminal cycling condition\n$$\n\\text{(terminal)}\\quad s_{T} = s_{0}.\n$$\nYou may assume all data are feasible and that the operations subproblem has a finite optimal solution for any nonnegative $y$.\n\nStarting from the standard duality of linear programming, and using only fundamental linear optimization principles, proceed as follows:\n- Reformulate the operations subproblem in matrix form as a minimization with equality constraints and less-than-or-equal-to capacity constraints whose right-hand sides depend affinely on $y$.\n- Derive its dual, clearly identifying the dual variables associated with each class of constraints: let $\\lambda_{t}$ be the dual variable for the balance equality, $\\nu_{t}$ be the dual variable for the intertemporal equality, $\\tau$ be the dual variable for the terminal equality, and let $\\alpha_{t} \\ge 0$, $\\beta_{t} \\ge 0$, $\\gamma_{t} \\ge 0$, $\\sigma_{t} \\ge 0$ be the dual variables for the generation, charge, discharge, and energy capacity constraints, respectively.\n- Use strong duality to write the optimal operations cost as the value of the dual objective at an optimal dual solution. Identify the recourse value’s dependence on $y$ and express the Benders optimality cut’s coefficient vector with respect to $y$ as a function of the optimal dual variables.\n\nYour final output should be the coefficient vector of the Benders optimality cut with respect to $(y_{E}, y_{P}, y_{G})$, written compactly as a single row vector whose components are symbolic expressions in the dual variables $\\alpha_{t}$, $\\beta_{t}$, $\\gamma_{t}$, and $\\sigma_{t}$. Express this vector in monetary units per capacity unit, with the first component in dollars per megawatt-hour, and the second and third components in dollars per megawatt. Do not include units in your final boxed answer. No rounding is required; provide an exact symbolic expression.",
            "solution": "The user wants to derive the coefficient vector of a Benders optimality cut for a two-level energy system planning problem.\n\n### **Step 1: Problem Validation**\nThe problem statement describes a standard two-stage stochastic programming structure applied to energy system planning, where the first-stage (master problem) decisions are investments $y = (y_E, y_P, y_G)$ and the second-stage (subproblem) decisions are hourly operations. The subproblem is a linear program (LP) whose constraints depend on the investment vector $y$. The task is to reformulate this LP, derive its dual, and determine the coefficients of the Benders optimality cut corresponding to the investment variables.\n\n**Givens:**\n-   Investment vector: $y = (y_{E}, y_{P}, y_{G})$ for storage energy capacity (MWh), storage power capacity (MW), and generation capacity (MW).\n-   Operational variables for $t \\in \\{1,\\dots,T\\}$: $g_t, c_t, d_t, s_t \\ge 0$.\n-   Parameters: $D_t, s_0, \\eta_c, \\eta_d, C_G, C_c, C_d$.\n-   Primal Operations Subproblem $P(y)$:\n    $$\n    \\min_{g_{t},\\,c_{t},\\,d_{t},\\,s_{t} \\ge 0} \\;\\sum_{t=1}^{T} \\big( C_{G}\\, g_{t} + C_{c}\\, c_{t} + C_{d}\\, d_{t} \\big)\n    $$\n    subject to, for $t=1,\\dots,T$:\n    1.  $g_{t} + d_{t} - c_{t} = D_{t}$\n    2.  $s_{t} = s_{t-1} + \\eta_{c}\\, c_{t} - \\eta_{d}^{-1} d_{t}$\n    3.  $g_{t} \\le y_{G}$\n    4.  $c_{t} \\le y_{P}$\n    5.  $d_{t} \\le y_{P}$\n    6.  $s_{t} \\le y_{E}$\n    and $s_{T} = s_{0}$.\n-   Assumption: The subproblem is feasible and bounded for any $y \\ge 0$.\n-   Dual variable assignments: $\\lambda_t$ for balance, $\\nu_t$ for intertemporal, $\\tau$ for terminal, and $\\alpha_t, \\beta_t, \\gamma_t, \\sigma_t \\ge 0$ for capacity constraints.\n\n**Validation:**\n1.  **Scientifically Grounded:** The model is a standard, simplified representation of an electricity system with dispatchable generation and energy storage. The constraints represent fundamental principles such as energy balance and capacity limits. The formulation is scientifically sound.\n2.  **Well-Posed:** The problem is a well-defined linear program. The task of deriving a Benders cut from an LP subproblem is a standard procedure in optimization theory. The assumption of feasibility and boundedness ensures a solution exists.\n3.  **Objective:** The problem is stated with mathematical precision and without ambiguity.\n\nThe problem is deemed **valid**. We may proceed with the solution.\n\n### **Step 2: Reformulation and Dual Derivation**\n\nWe begin by formalizing the primal subproblem $P(y)$ and then derive its dual. The problem can be written in a standard form for which duality theory applies.\n\n**Primal Problem Reformulation:**\nThe operations subproblem can be stated as:\n$$\nQ(y) = \\min_{g,c,d,s} \\sum_{t=1}^{T} (C_{G} g_{t} + C_{c} c_{t} + C_{d} d_{t})\n$$\nsubject to:\n-   $g_{t} - c_{t} + d_{t} - D_{t} = 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$ (associated dual variable: $\\lambda_t$)\n-   $s_{t} - s_{t-1} - \\eta_{c} c_{t} + \\eta_{d}^{-1} d_{t} = 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$ (associated dual variable: $\\nu_t$)\n-   $s_{T} - s_{0} = 0$ (associated dual variable: $\\tau$)\n-   $g_{t} - y_{G} \\le 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$ (associated dual variable: $\\alpha_t \\ge 0$)\n-   $c_{t} - y_{P} \\le 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$ (associated dual variable: $\\beta_t \\ge 0$)\n-   $d_{t} - y_{P} \\le 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$ (associated dual variable: $\\gamma_t \\ge 0$)\n-   $s_{t} - y_{E} \\le 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$ (associated dual variable: $\\sigma_t \\ge 0$)\n-   $g_t, c_t, d_t, s_t \\ge 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$\n\nNote that $s_0$ is a fixed parameter. In the intertemporal constraint for $t=1$, $s_{t-1}$ is $s_0$. This can be formally incorporated by forming the Lagrangian.\n\n**Lagrangian Formulation:**\nThe Lagrangian $\\mathcal{L}$ for this problem is:\n$$\n\\mathcal{L} = \\sum_{t=1}^{T} (C_{G} g_{t} + C_{c} c_{t} + C_{d} d_{t}) \\\\\n+ \\sum_{t=1}^{T} \\lambda_{t} (g_{t} - c_{t} + d_{t} - D_{t}) \\\\\n+ \\sum_{t=1}^{T} \\nu_{t} (s_{t} - s_{t-1} - \\eta_{c} c_{t} + \\eta_{d}^{-1} d_{t}) \\\\\n+ \\tau (s_{T} - s_{0}) \\\\\n+ \\sum_{t=1}^{T} \\alpha_{t} (g_{t} - y_{G}) \\\\\n+ \\sum_{t=1}^{T} \\beta_{t} (c_{t} - y_{P}) \\\\\n+ \\sum_{t=1}^{T} \\gamma_{t} (d_{t} - y_{P}) \\\\\n+ \\sum_{t=1}^{T} \\sigma_{t} (s_{t} - y_{E})\n$$\nwhere $\\alpha_t, \\beta_t, \\gamma_t, \\sigma_t \\ge 0$, and $\\lambda_t, \\nu_t, \\tau$ are unrestricted in sign.\n\nWe group terms by the primal decision variables $g_t, c_t, d_t, s_t$:\n$$\n\\mathcal{L} = \\sum_{t=1}^{T} g_{t} (C_{G} + \\lambda_{t} + \\alpha_{t}) \\\\\n+ \\sum_{t=1}^{T} c_{t} (C_{c} - \\lambda_{t} - \\eta_{c} \\nu_{t} + \\beta_{t}) \\\\\n+ \\sum_{t=1}^{T} d_{t} (C_{d} + \\lambda_{t} + \\eta_{d}^{-1} \\nu_{t} + \\gamma_{t}) \\\\\n+ \\sum_{t=1}^{T-1} s_{t} (\\nu_{t} - \\nu_{t+1} + \\sigma_{t}) + s_{T}(\\nu_T + \\tau + \\sigma_T) \\\\\n+ \\text{terms not involving decision variables}\n$$\nThe dual problem is obtained by maximizing the dual function $q(\\lambda, \\dots, \\sigma) = \\inf_{g,c,d,s \\ge 0} \\mathcal{L}$. For this infimum to be bounded, the coefficients of the primal variables must be non-negative. This yields the dual constraints.\n\n**Dual Problem:**\nThe dual constraints are:\n1.  $C_{G} + \\lambda_{t} + \\alpha_{t} \\ge 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$\n2.  $C_{c} - \\lambda_{t} - \\eta_{c} \\nu_{t} + \\beta_{t} \\ge 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$\n3.  $C_{d} + \\lambda_{t} + \\eta_{d}^{-1} \\nu_{t} + \\gamma_{t} \\ge 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$\n4.  $\\nu_{t} - \\nu_{t+1} + \\sigma_{t} \\ge 0 \\quad \\forall t \\in \\{1, \\dots, T-1\\}$\n5.  $\\nu_T + \\tau + \\sigma_T \\ge 0$\n6.  $\\alpha_t, \\beta_t, \\gamma_t, \\sigma_t \\ge 0 \\quad \\forall t \\in \\{1, \\dots, T\\}$\n\nThe dual objective is to maximize the remaining terms of $\\mathcal{L}$, which constitute the dual function $q$:\n$$\n\\max_{\\lambda, \\nu, \\tau, \\alpha, \\beta, \\gamma, \\sigma} \\left\\{ -\\sum_{t=1}^{T} \\lambda_{t} D_{t} - \\nu_{1}s_{0} - \\tau s_{0} - \\sum_{t=1}^{T} \\alpha_t y_G - \\sum_{t=1}^{T} \\beta_t y_P - \\sum_{t=1}^{T} \\gamma_t y_P - \\sum_{t=1}^{T} \\sigma_t y_E \\right\\}\n$$\nThis can be written as:\n$$\n\\max \\left\\{ -\\sum_{t=1}^{T} \\lambda_{t} D_{t} - (\\nu_{1} + \\tau)s_{0} - y_G \\sum_{t=1}^{T} \\alpha_t - y_P \\sum_{t=1}^{T} (\\beta_t + \\gamma_t) - y_E \\sum_{t=1}^{T} \\sigma_t \\right\\}\n$$\nsubject to the dual constraints derived above.\n\n### **Step 3: Benders Optimality Cut**\nBy strong duality for linear programming (since the primal is assumed to be feasible and bounded), the optimal value of the primal subproblem, $Q(y)$, is equal to the optimal value of its dual. Let an optimal solution to the dual problem be denoted by $(\\lambda^*, \\nu^*, \\tau^*, \\alpha^*, \\beta^*, \\gamma^*, \\sigma^*)$. Then:\n$$\nQ(y) = -\\sum_{t=1}^{T} \\lambda^*_{t} D_{t} - (\\nu^*_{1} + \\tau^*)s_{0} - y_G \\sum_{t=1}^{T} \\alpha^*_t - y_P \\sum_{t=1}^{T} (\\beta^*_t + \\gamma^*_t) - y_E \\sum_{t=1}^{T} \\sigma^*_t\n$$\nThe function $Q(y)$ is the value function of the subproblem. It is a convex function of $y$. In the context of Benders decomposition, the master problem minimizes investment costs plus an approximation of $Q(y)$. An optimality cut provides a linear lower bound on $Q(y)$. For a given investment point $\\bar{y}$, the cut is formed using the optimal dual variables from the subproblem solved at $\\bar{y}$.\n\nThe Benders optimality cut is a supporting hyperplane to the epigraph of $Q(y)$ at $\\bar{y}$. It is given by the inequality:\n$$\n\\theta \\ge Q(\\bar{y}) + (\\nabla_y Q(\\bar{y}))^T (y - \\bar{y})\n$$\nwhere $\\theta$ is the master problem variable representing the subproblem cost.\nThe gradient (or a subgradient if not unique) $\\nabla_y Q(y)$ can be found by applying sensitivity analysis (or Danskin's Theorem). The partial derivatives of the optimal value function $Q(y)$ with respect to the right-hand side parameters are given by the negative of the optimal dual variables of the corresponding constraints.\nIn our formulation, the constraints are of the form $g_t \\le y_G$, not $g_t - y_G \\le 0$. A more direct approach is to differentiate the dual objective value with respect to $y$, holding the optimal dual variables fixed at their values for $\\bar{y}$:\n$$\n\\frac{\\partial Q(y)}{\\partial y_E} = -\\sum_{t=1}^{T} \\sigma^*_t\n$$\n$$\n\\frac{\\partial Q(y)}{\\partial y_P} = -\\sum_{t=1}^{T} (\\beta^*_t + \\gamma^*_t)\n$$\n$$\n\\frac{\\partial Q(y)}{\\partial y_G} = -\\sum_{t=1}^{T} \\alpha^*_t\n$$\nThe Benders cut is typically written in the master problem as $\\theta + (\\text{coeffs})^T y \\ge \\text{const}$. The coefficient vector for $y = (y_E, y_P, y_G)$ in this form is $-\\nabla_y Q(\\bar{y})$.\nThe coefficient vector is therefore:\n$$\n\\begin{pmatrix} -\\frac{\\partial Q(\\bar{y})}{\\partial y_E} \\\\ -\\frac{\\partial Q(\\bar{y})}{\\partial y_P} \\\\ -\\frac{\\partial Q(\\bar{y})}{\\partial y_G} \\end{pmatrix} = \\begin{pmatrix} \\sum_{t=1}^{T} \\sigma^*_t \\\\ \\sum_{t=1}^{T} (\\beta^*_t + \\gamma^*_t) \\\\ \\sum_{t=1}^{T} \\alpha^*_t \\end{pmatrix}\n$$\nThe problem requests this coefficient vector with respect to $(y_E, y_P, y_G)$, written as a row vector. Omitting the asterisk superscript for notational simplicity as per convention in the final expression, the components are the sums of the optimal dual variables, representing the marginal value (shadow price) of each type of capacity.\n\n-   Coefficient for $y_E$ (in $\\$!/ \\mathrm{MWh}$): $\\sum_{t=1}^{T} \\sigma_t$\n-   Coefficient for $y_P$ (in $\\$!/ \\mathrm{MW}$): $\\sum_{t=1}^{T} (\\beta_t + \\gamma_t)$\n-   Coefficient for $y_G$ (in $\\$!/ \\mathrm{MW}$): $\\sum_{t=1}^{T} \\alpha_t$\n\nThe resulting coefficient row vector is $(\\sum_{t=1}^{T} \\sigma_t, \\sum_{t=1}^{T} (\\beta_t + \\gamma_t), \\sum_{t=1}^{T} \\alpha_t)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\sum_{t=1}^{T} \\sigma_{t}  \\sum_{t=1}^{T} (\\beta_{t} + \\gamma_{t})  \\sum_{t=1}^{T} \\alpha_{t}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The theoretical choices in model design, such as temporal resolution, have direct practical consequences for the trade-off between computational runtime and solution accuracy. This hands-on coding practice  allows you to explore this fundamental trade-off empirically. You will implement a simulation of an energy system, evaluate its performance at different time resolutions, and generate a Pareto frontier that visualizes the balance between computational cost and solution error. By identifying the \"knee\" of this curve, you will learn a practical method for choosing a model resolution that offers the best compromise, avoiding unnecessary computational burden for marginal gains in accuracy.",
            "id": "4102533",
            "problem": "Design and implement a complete, runnable program that evaluates the trade-off between algorithmic runtime and solution quality for discretized multi-horizon energy system models and identifies where diminishing returns occur. The model consists of a deterministic electric load, exogenous renewable generation, and a single idealized energy storage device. The program must compute the Pareto frontier over a set of horizon lengths and time resolutions, and output, for each test case, the time resolution at which diminishing returns first occur. All calculations must be reproducible and derived from first principles of energy balance and algorithmic complexity. Angles used in trigonometric functions must be expressed in radians. Units must be handled explicitly as specified.\n\nYou must use the following base physical definitions and constraints to construct the discrete-time model from continuous-time functions:\n\n- Energy balance and conservation: over each time step of duration $\\Delta t$ (in hours), the thermal generation $g_k$ (in megawatts), renewable generation $r_k$ (in megawatts), load $L_k$ (in megawatts), charging power $c_k$ (in megawatts), and discharging power $d_k$ (in megawatts) satisfy\n$$\ng_k + r_k + d_k = L_k + c_k,\n$$\nwith $g_k \\ge 0$, $c_k \\ge 0$, and $d_k \\ge 0$.\n- Storage dynamics: the storage state $s_k$ (in megawatt-hours) evolves as\n$$\ns_{k+1} = s_k + \\eta_c \\, c_k \\, \\Delta t - \\frac{d_k \\, \\Delta t}{\\eta_d},\n$$\nwith bounds $0 \\le s_k \\le S_{\\max}$, charge power bound $0 \\le c_k \\le P_c$, and discharge power bound $0 \\le d_k \\le P_d$. Here $\\eta_c \\in (0,1]$ and $\\eta_d \\in (0,1]$ are the charge and discharge efficiencies, respectively.\n\nThe continuous-time load and renewable generation are given by smooth, bounded functions of time $t$ (in hours), denoted $L(t)$ and $R(t)$. The discrete-time approximation uses point sampling at the midpoint of each interval, $t_k = (k + \\tfrac{1}{2}) \\Delta t$, to obtain $L_k = L(t_k)$ and $r_k = R(t_k)$.\n\nFor each discretization, define the algorithmic runtime proxy as the total primitive operation count,\n$$\n\\mathcal{T} = c_{\\text{ops}} \\, N,\n$$\nwhere $c_{\\text{ops}}$ is a fixed constant representing the number of primitive operations per step, and $N = H / \\Delta t$ is the number of steps for horizon length $H$ (in hours). This proxy has units of \"primitive operations\" and is not a physical time unit.\n\nDefine solution quality as the absolute megawatt-hour difference between the total thermal generation energy under a given discretization and a high-fidelity reference computed at a fine resolution $\\Delta t_{\\text{ref}}$. Specifically, with total fossil energy over the horizon\n$$\nE_{\\text{fossil}} = \\sum_{k=0}^{N-1} g_k \\, \\Delta t,\n$$\nand reference $E_{\\text{fossil}}^{\\text{ref}}$ computed with $\\Delta t_{\\text{ref}}$, the solution quality error is\n$$\n\\varepsilon = \\left| E_{\\text{fossil}} - E_{\\text{fossil}}^{\\text{ref}} \\right| \\quad \\text{(in megawatt-hours)}.\n$$\n\nAlgorithmic policy requirement: derive and implement a myopic storage control based on energy conservation and linear costs, where charging occurs only when $r_k > L_k$ and discharging occurs only when $r_k  L_k$, each subject to power limits and storage bounds. State any assumptions needed to justify this policy from the base definitions.\n\nPareto frontier requirement: for each test case, evaluate all specified time resolutions and compute the set of non-dominated pairs $(\\mathcal{T}, \\varepsilon)$ under simultaneous minimization of both coordinates. Then, in normalized coordinates\n$$\nx_i = \\frac{\\mathcal{T}_i - \\min_j \\mathcal{T}_j}{\\max_j \\mathcal{T}_j - \\min_j \\mathcal{T}_j}, \\quad\ny_i = \\frac{\\varepsilon_i - \\min_j \\varepsilon_j}{\\max_j \\varepsilon_j - \\min_j \\varepsilon_j},\n$$\nidentify the first point along increasing $x$ where the absolute slope $\\left| \\Delta y / \\Delta x \\right|$ drops below a threshold $\\tau$ (dimensionless), and report the corresponding $\\Delta t$ (in hours) as the diminishing-returns resolution. If no such point exists, select the resolution that minimizes $x + y$ in normalized space.\n\nPhysical and numerical units:\n- Horizon length $H$ is in hours.\n- Time resolution $\\Delta t$ is in hours.\n- Power quantities $L_k$, $r_k$, $g_k$, $c_k$, $d_k$, $P_c$, and $P_d$ are in megawatts.\n- Storage quantities $s_k$ and $S_{\\max}$ are in megawatt-hours.\n- Efficiencies $\\eta_c$ and $\\eta_d$ are dimensionless.\n- The solution quality error $\\varepsilon$ must be computed and handled in megawatt-hours.\n- Angles inside trigonometric functions must be in radians.\n\nTest suite:\nImplement the program to solve the following three cases. For each case, use the reference resolution $\\Delta t_{\\text{ref}} = 0.125$ hours and $c_{\\text{ops}} = 40$ primitive operations per step; use slope threshold $\\tau = 0.15$.\n\n- Case A (daily horizon):\n  - Horizon length $H = 24$.\n  - Load $L(t) = L_b + A_L \\sin\\!\\left( \\frac{2\\pi t}{24} \\right) + B_L \\sin\\!\\left( \\frac{2\\pi t}{24 \\cdot 7} + \\psi \\right)$ with $L_b = 50$, $A_L = 10$, $B_L = 5$, $\\psi = 0.3$.\n  - Renewable $R(t) = A_R \\max\\!\\left( 0, \\sin\\!\\left( \\frac{2\\pi (t \\pmod{24})}{24} - \\frac{\\pi}{2} \\right) \\right)$ with $A_R = 30$.\n  - Storage $S_{\\max} = 50$, $P_c = 20$, $P_d = 20$, $\\eta_c = 0.95$, $\\eta_d = 0.90$, and initial state $s_0 = S_{\\max}/2$.\n  - Candidate resolutions $\\Delta t \\in \\{ 8, 4, 2, 1, 0.5 \\}$.\n\n- Case B (short horizon):\n  - Horizon length $H = 6$.\n  - Load $L(t) = L_b + A_L \\sin\\!\\left( \\frac{2\\pi t}{24} + \\phi \\right)$ with $L_b = 60$, $A_L = 15$, $\\phi = -0.5$.\n  - Renewable $R(t) = A_R \\max\\!\\left( 0, \\sin\\!\\left( \\frac{2\\pi (t \\pmod{24})}{24} - \\frac{\\pi}{2} \\right) \\right)$ with $A_R = 10$.\n  - Storage $S_{\\max} = 30$, $P_c = 15$, $P_d = 15$, $\\eta_c = 0.95$, $\\eta_d = 0.90$, and initial state $s_0 = S_{\\max}/2$.\n  - Candidate resolutions $\\Delta t \\in \\{ 3, 2, 1, 0.5, 0.25 \\}$.\n\n- Case C (weekly horizon):\n  - Horizon length $H = 168$.\n  - Load $L(t) = L_b + A_L \\sin\\!\\left( \\frac{2\\pi t}{24} \\right) + B_L \\sin\\!\\left( \\frac{2\\pi t}{24 \\cdot 7} + \\psi \\right)$ with $L_b = 55$, $A_L = 8$, $B_L = 12$, $\\psi = -0.7$.\n  - Renewable $R(t) = A_R \\max\\!\\left( 0, \\sin\\!\\left( \\frac{2\\pi (t \\pmod{24})}{24} - \\frac{\\pi}{2} \\right) \\right)$ with $A_R = 25$.\n  - Storage $S_{\\max} = 200$, $P_c = 50$, $P_d = 50$, $\\eta_c = 0.95$, $\\eta_d = 0.90$, and initial state $s_0 = S_{\\max}/2$.\n  - Candidate resolutions $\\Delta t \\in \\{ 24, 12, 6, 3, 1.5 \\}$.\n\nYour program must:\n- Implement the discrete-time simulation using midpoint sampling $t_k = (k + \\tfrac{1}{2}) \\Delta t$.\n- For each case, compute $E_{\\text{fossil}}^{\\text{ref}}$ at $\\Delta t_{\\text{ref}}$ and the set of $(\\mathcal{T}, \\varepsilon)$ pairs for all candidate $\\Delta t$.\n- Compute the Pareto frontier under bi-criteria minimization of $\\mathcal{T}$ and $\\varepsilon$.\n- Determine the diminishing-returns resolution using the slope threshold $\\tau$ applied to normalized $(x,y)$ coordinates, with the stated fallback if needed.\n\nFinal Output Format:\nYour program should produce a single line of output containing the diminishing-returns resolutions (one per test case) in hours, rounded to two decimal places, as a comma-separated list enclosed in square brackets (e.g., `[result1,result2,result3]`). The results are floats in hours.",
            "solution": "We start from the conservation of energy over each discrete interval of length $\\Delta t$ hours. At step $k$, the balance reads\n$$\ng_k + r_k + d_k = L_k + c_k,\n$$\nwhere $g_k$ represents thermal generation required to meet residual demand not met by renewables or storage discharge. The storage state evolves by the first principles of energy accounting:\n$$\ns_{k+1} = s_k + \\eta_c \\, c_k \\, \\Delta t - \\frac{d_k \\, \\Delta t}{\\eta_d},\n$$\nsubject to bounds $0 \\le s_k \\le S_{\\max}$, $0 \\le c_k \\le P_c$, and $0 \\le d_k \\le P_d$. Here $\\eta_c \\in (0,1]$ models charging losses and $\\eta_d \\in (0,1]$ models discharging losses. Power quantities are in megawatts and energy quantities are in megawatt-hours.\n\nUnder linear thermal generation cost and no arbitrage valuation of stored energy beyond its contribution to meeting load, the optimal control policy that minimizes total thermal energy over the horizon is myopic and greedy: charge when there is renewable surplus and discharge when there is a deficit, each action bounded by device limits and conservation constraints. This follows because the marginal value of stored energy is constant across time in the absence of time-varying prices, curtailment penalties, or storage degradation, so using surplus energy to reduce thermal generation immediately or later via storage is always beneficial until limits bind. Formally, let the surplus power be $\\sigma_k = r_k - L_k$. If $\\sigma_k > 0$, charging is bounded by three constraints: charge power limit $P_c$, available surplus $\\sigma_k$, and headroom in storage $(S_{\\max} - s_k)$ scaled by charging efficiency over the step, namely\n$$\nc_k = \\min\\!\\left( P_c, \\sigma_k, \\frac{S_{\\max} - s_k}{\\eta_c \\, \\Delta t} \\right),\n$$\nleading to $g_k = 0$ and $s_{k+1} = s_k + \\eta_c c_k \\Delta t.$ If $\\sigma_k  0$ (a deficit), discharging is bounded by discharge power limit $P_d$, the deliverable energy from the current state $s_k$ over the step, and the deficit magnitude $-\\sigma_k$. The deliverable discharge power over the step is bounded by $s_k \\eta_d / \\Delta t$ (since discharging at power $d_k$ for $\\Delta t$ lowers stored energy by $d_k \\Delta t / \\eta_d$ and we require $s_{k+1} \\ge 0$). Therefore,\n$$\nd_k = \\min\\!\\left( P_d, \\frac{s_k \\eta_d}{\\Delta t}, -\\sigma_k \\right),\n$$\nleading to $g_k = -\\sigma_k - d_k$ and $s_{k+1} = s_k - \\frac{d_k \\Delta t}{\\eta_d}.$ When $\\sigma_k = 0$, set $c_k = d_k = 0$, $g_k = 0$.\n\nWe discretize the continuous load $L(t)$ and renewable generation $R(t)$ by midpoint sampling $t_k = (k + \\tfrac{1}{2}) \\Delta t$, yielding $L_k = L(t_k)$ and $r_k = R(t_k)$. The total thermal energy over horizon length $H$ is\n$$\nE_{\\text{fossil}} = \\sum_{k=0}^{N-1} g_k \\, \\Delta t,\n$$\nwhere $N = H / \\Delta t$ is the number of steps. The reference thermal energy $E_{\\text{fossil}}^{\\text{ref}}$ is computed analogously using a finer resolution $\\Delta t_{\\text{ref}}$. The solution quality error is the absolute difference in megawatt-hours,\n$$\n\\varepsilon = \\left| E_{\\text{fossil}} - E_{\\text{fossil}}^{\\text{ref}} \\right|.\n$$\n\nWe now define the runtime proxy. A step of the greedy control requires evaluating a few arithmetic operations (subtractions to form $\\sigma_k$), comparisons, and minimum operations, plus updates to $s_{k+1}$ and accumulation of $E_{\\text{fossil}}$. These constitute a constant number of primitive operations per step. We model the runtime proxy by\n$$\n\\mathcal{T} = c_{\\text{ops}} \\, N,\n$$\nwith $c_{\\text{ops}}$ fixed; here we set $c_{\\text{ops}} = 40$ to represent a reasonable constant number of primitive operations per step. This proxy is dimensionless in the sense of computational operations and not a physical time.\n\nTo compute the Pareto frontier under bi-criteria minimization of $(\\mathcal{T}, \\varepsilon)$ across candidate resolutions for a given horizon, we proceed as follows. Let $\\{ (\\mathcal{T}_i, \\varepsilon_i, \\Delta t_i) \\}_{i=1}^M$ be the set of evaluated points. A point $i$ is dominated if there exists $j$ such that $\\mathcal{T}_j \\le \\mathcal{T}_i$ and $\\varepsilon_j \\le \\varepsilon_i$ with at least one strict inequality. The non-dominated set is the Pareto frontier. Since $\\mathcal{T}$ increases monotonically as $\\Delta t$ decreases and we expect $\\varepsilon$ to decrease with decreasing $\\Delta t$, a simple frontier extraction algorithm sorts points by increasing $\\mathcal{T}$ and retains points with strictly decreasing $\\varepsilon$ relative to the running minimum.\n\nTo identify diminishing returns, we normalize $\\mathcal{T}$ and $\\varepsilon$ to $x \\in [0,1]$ and $y \\in [0,1]$ using\n$$\nx_i = \\frac{\\mathcal{T}_i - \\min_j \\mathcal{T}_j}{\\max_j \\mathcal{T}_j - \\min_j \\mathcal{T}_j}, \\quad\ny_i = \\frac{\\varepsilon_i - \\min_j \\varepsilon_j}{\\max_j \\varepsilon_j - \\min_j \\varepsilon_j}.\n$$\nWe traverse the frontier in increasing $x$ and compute local slopes $\\Delta y / \\Delta x$ between consecutive points. The onset of diminishing returns is the first index $k$ for which\n$$\n\\left| \\frac{y_k - y_{k-1}}{x_k - x_{k-1}} \\right|  \\tau,\n$$\nwith $\\tau = 0.15$. This criterion detects when marginal quality improvement per unit runtime becomes small relative to the normalized scales. If no such $k$ exists (i.e., improvements remain steep across all points), we select the point minimizing $x_i + y_i$ to balance runtime and error in normalized space.\n\nWe apply this procedure to the three test cases:\n\n- Case A: $H = 24$, $L(t) = L_b + A_L \\sin( 2\\pi t / 24 ) + B_L \\sin( 2\\pi t / (24 \\cdot 7) + \\psi )$ with $(L_b, A_L, B_L, \\psi) = (50, 10, 5, 0.3)$; $R(t) = A_R \\max(0, \\sin( 2\\pi (t \\pmod{24})/24 - \\pi/2))$ with $A_R = 30$; storage $(S_{\\max}, P_c, P_d, \\eta_c, \\eta_d, s_0) = (50, 20, 20, 0.95, 0.90, 25)$; candidate $\\Delta t \\in \\{8,4,2,1,0.5\\}$; reference $\\Delta t_{\\text{ref}} = 0.125$; $c_{\\text{ops}} = 40$; $\\tau = 0.15$.\n\n- Case B: $H = 6$, $L(t) = L_b + A_L \\sin( 2\\pi t / 24 + \\phi )$ with $(L_b, A_L, \\phi) = (60, 15, -0.5)$; $R(t)$ as above with $A_R = 10$; storage $(S_{\\max}, P_c, P_d, \\eta_c, \\eta_d, s_0) = (30, 15, 15, 0.95, 0.90, 15)$; candidate $\\Delta t \\in \\{3,2,1,0.5,0.25\\}$; reference $\\Delta t_{\\text{ref}} = 0.125$; $c_{\\text{ops}} = 40$; $\\tau = 0.15$.\n\n- Case C: $H = 168$, $L(t) = L_b + A_L \\sin( 2\\pi t / 24 ) + B_L \\sin( 2\\pi t / (24 \\cdot 7) + \\psi )$ with $(L_b, A_L, B_L, \\psi) = (55, 8, 12, -0.7)$; $R(t)$ as above with $A_R = 25$; storage $(S_{\\max}, P_c, P_d, \\eta_c, \\eta_d, s_0) = (200, 50, 50, 0.95, 0.90, 100)$; candidate $\\Delta t \\in \\{24,12,6,3,1.5\\}$; reference $\\Delta t_{\\text{ref}} = 0.125$; $c_{\\text{ops}} = 40$; $\\tau = 0.15$.\n\nThe final output must be a single line containing the diminishing-returns resolutions for Case A, Case B, and Case C, respectively, in hours, rounded to two decimal places, as a comma-separated list in square brackets. For example, `[8.00,3.00,12.00]`.\n\nAlgorithmic steps:\n\n1. For each case, compute $E_{\\text{fossil}}^{\\text{ref}}$ using $\\Delta t_{\\text{ref}}$ by simulating the storage policy over $N_{\\text{ref}} = H / \\Delta t_{\\text{ref}}$ midpoint samples.\n2. For each candidate $\\Delta t$, compute $E_{\\text{fossil}}$ and the error $\\varepsilon = | E_{\\text{fossil}} - E_{\\text{fossil}}^{\\text{ref}} |$; compute $\\mathcal{T} = c_{\\text{ops}} \\cdot (H / \\Delta t)$.\n3. Extract the Pareto frontier by sorting points by increasing $\\mathcal{T}$ and keeping those with strictly decreasing $\\varepsilon$ relative to the current minimum.\n4. Normalize $\\mathcal{T}$ and $\\varepsilon$ to $(x,y)$; scan consecutive points and select the first index with $| \\Delta y / \\Delta x |  \\tau$; if none, select the point with minimal $x + y$.\n5. Output the selected $\\Delta t$ for each case in the specified format, rounded to two decimal places.\n\nThis procedure respects the base laws of energy conservation, uses well-tested numerical discretization, and frames a reproducible notion of runtime via primitive operation counts. It tests both short-term and long-term horizon designs by varying $H$ and $\\Delta t$ and yields quantifiable, unit-aware outputs.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef load_case_A(t):\n    # L(t) = L_b + A_L * sin(2π t / 24) + B_L * sin(2π t / (24*7) + psi)\n    L_b, A_L, B_L, psi = 50.0, 10.0, 5.0, 0.3\n    return L_b + A_L * np.sin(2.0 * np.pi * t / 24.0) + B_L * np.sin(2.0 * np.pi * t / (24.0 * 7.0) + psi)\n\ndef load_case_B(t):\n    # L(t) = L_b + A_L * sin(2π t / 24 + phi)\n    L_b, A_L, phi = 60.0, 15.0, -0.5\n    return L_b + A_L * np.sin(2.0 * np.pi * t / 24.0 + phi)\n\ndef load_case_C(t):\n    # L(t) = L_b + A_L * sin(2π t / 24) + B_L * sin(2π t / (24*7) + psi)\n    L_b, A_L, B_L, psi = 55.0, 8.0, 12.0, -0.7\n    return L_b + A_L * np.sin(2.0 * np.pi * t / 24.0) + B_L * np.sin(2.0 * np.pi * t / (24.0 * 7.0) + psi)\n\ndef solar_R(t, A_R):\n    # R(t) = A_R * max(0, sin(2π (t mod 24)/24 - π/2))\n    tmod = np.mod(t, 24.0)\n    val = np.sin(2.0 * np.pi * tmod / 24.0 - np.pi / 2.0)\n    return A_R * np.maximum(0.0, val)\n\ndef simulate_storage(H, dt, load_func, A_R, S_max, P_c, P_d, eta_c, eta_d, s0):\n    \"\"\"\n    Simulate greedy storage over horizon H with step dt.\n    Returns total fossil energy E_fossil (MWh).\n    \"\"\"\n    N = int(round(H / dt))\n    # Ensure exact division\n    assert abs(N * dt - H)  1e-9, \"H must be divisible by dt\"\n    s = s0\n    E_fossil = 0.0\n    for k in range(N):\n        t_mid = (k + 0.5) * dt\n        Lk = load_func(t_mid)\n        rk = solar_R(t_mid, A_R)\n        sigma = rk - Lk  # surplus if positive, deficit if negative\n        if sigma > 0.0:\n            # Charging\n            # Max charge power from surplus and device limits; also ensure not exceeding S_max\n            max_charge_power_by_headroom = (S_max - s) / (eta_c * dt) if eta_c > 0 else 0.0\n            c_power = min(P_c, sigma, max_charge_power_by_headroom)\n            s += eta_c * c_power * dt\n            # No thermal generation needed when surplus handled by storage\n            g = 0.0\n        elif sigma  0.0:\n            deficit = -sigma\n            # Discharging\n            max_discharge_power_by_state = (s * eta_d) / dt if eta_d > 0 else 0.0\n            d_power = min(P_d, max_discharge_power_by_state, deficit)\n            s -= (d_power * dt) / eta_d\n            # Remaining deficit met by thermal generation\n            g = deficit - d_power\n        else:\n            # Exact balance\n            g = 0.0\n        # Enforce numerical bounds\n        if s  0.0:\n            # Numerically clip\n            s = 0.0\n        if s > S_max:\n            s = S_max\n        E_fossil += g * dt\n    return E_fossil\n\ndef pareto_frontier(points):\n    \"\"\"\n    points: list of tuples (runtime_ops, error_MWh, dt)\n    Returns frontier sorted by runtime_ops ascending with strictly decreasing error.\n    \"\"\"\n    pts_sorted = sorted(points, key=lambda x: (x[0], x[1]))\n    frontier = []\n    best_err = np.inf\n    for rt, err, dt in pts_sorted:\n        # Keep point if it improves error (strictly less than best_err)\n        if err  best_err - 1e-12:\n            frontier.append((rt, err, dt))\n            best_err = err\n    return frontier\n\ndef select_knee(frontier, tau=0.15):\n    \"\"\"\n    Given frontier [(rt, err, dt), ...], select diminishing-returns resolution dt.\n    Uses normalized slope threshold tau; fallback minimizes x + y.\n    \"\"\"\n    rts = np.array([p[0] for p in frontier], dtype=float)\n    errs = np.array([p[1] for p in frontier], dtype=float)\n    dts = [p[2] for p in frontier]\n    # Normalize to [0,1]\n    rt_min, rt_max = float(np.min(rts)), float(np.max(rts))\n    err_min, err_max = float(np.min(errs)), float(np.max(errs))\n    # Handle potential zero ranges\n    x = (rts - rt_min) / (rt_max - rt_min) if rt_max > rt_min else np.zeros_like(rts)\n    y = (errs - err_min) / (err_max - err_min) if err_max > err_min else np.zeros_like(errs)\n    # Traverse in increasing x; check slopes between consecutive points\n    knee_idx = None\n    for i in range(1, len(x)):\n        dx = x[i] - x[i - 1]\n        dy = y[i] - y[i - 1]\n        slope = abs(dy / dx) if dx != 0.0 else np.inf\n        if slope  tau:\n            knee_idx = i\n            break\n    if knee_idx is None:\n        # Fallback: minimize x + y\n        scores = x + y\n        knee_idx = int(np.argmin(scores))\n    return float(dts[knee_idx])\n\ndef solve():\n    # Constants\n    dt_ref = 0.125  # hours\n    c_ops = 40      # operations per step\n    tau = 0.15      # slope threshold (dimensionless)\n\n    # Define test cases\n    test_cases = [\n        {\n            \"name\": \"A\",\n            \"H\": 24.0,\n            \"load_func\": load_case_A,\n            \"A_R\": 30.0,\n            \"S_max\": 50.0,\n            \"P_c\": 20.0,\n            \"P_d\": 20.0,\n            \"eta_c\": 0.95,\n            \"eta_d\": 0.90,\n            \"s0\": 25.0,\n            \"dts\": [8.0, 4.0, 2.0, 1.0, 0.5],\n        },\n        {\n            \"name\": \"B\",\n            \"H\": 6.0,\n            \"load_func\": load_case_B,\n            \"A_R\": 10.0,\n            \"S_max\": 30.0,\n            \"P_c\": 15.0,\n            \"P_d\": 15.0,\n            \"eta_c\": 0.95,\n            \"eta_d\": 0.90,\n            \"s0\": 15.0,\n            \"dts\": [3.0, 2.0, 1.0, 0.5, 0.25],\n        },\n        {\n            \"name\": \"C\",\n            \"H\": 168.0,\n            \"load_func\": load_case_C,\n            \"A_R\": 25.0,\n            \"S_max\": 200.0,\n            \"P_c\": 50.0,\n            \"P_d\": 50.0,\n            \"eta_c\": 0.95,\n            \"eta_d\": 0.90,\n            \"s0\": 100.0,\n            \"dts\": [24.0, 12.0, 6.0, 3.0, 1.5],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        H = case[\"H\"]\n        load_func = case[\"load_func\"]\n        A_R = case[\"A_R\"]\n        S_max = case[\"S_max\"]\n        P_c = case[\"P_c\"]\n        P_d = case[\"P_d\"]\n        eta_c = case[\"eta_c\"]\n        eta_d = case[\"eta_d\"]\n        s0 = case[\"s0\"]\n        dts = case[\"dts\"]\n\n        # Reference fossil energy at fine resolution\n        E_ref = simulate_storage(H, dt_ref, load_func, A_R, S_max, P_c, P_d, eta_c, eta_d, s0)\n\n        # Evaluate candidate resolutions\n        points = []\n        for dt in dts:\n            E_fossil = simulate_storage(H, dt, load_func, A_R, S_max, P_c, P_d, eta_c, eta_d, s0)\n            err = abs(E_fossil - E_ref)  # MWh\n            N = int(round(H / dt))\n            runtime_ops = c_ops * N\n            points.append((runtime_ops, err, dt))\n\n        # Compute Pareto frontier and knee\n        frontier = pareto_frontier(points)\n        knee_dt = select_knee(frontier, tau=tau)\n        results.append(round(knee_dt, 2))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(lambda x: f'{x:.2f}', results))}]\")\n\nsolve()\n```"
        }
    ]
}