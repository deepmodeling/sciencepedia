{
    "hands_on_practices": [
        {
            "introduction": "本练习将指导您完成渐进式对冲算法（Progressive Hedging）的一次具体迭代。通过将该方法应用于一个小型发电问题，您将获得关于其核心机制的动手经验：求解特定情景的子问题并更新共识决策变量。这项基础性练习旨在阐明该算法核心的迭代过程 。",
            "id": "4114574",
            "problem": "考虑一个小型能源系统的两阶段随机运营模型，该系统有两个热力发电机组，索引为 $j \\in \\{1,2\\}$，以及两个场景，索引为 $s \\in \\{1,2\\}$，其概率分别为 $p_{1} = 0.7$ 和 $p_{2} = 0.3$。第一阶段决策是与场景无关的日前基本发电向量 $u = (u_{1}, u_{2})$，单位为兆瓦 (MW)，由跨场景的非预期性（nonanticipativity）强制执行。在渐进对冲 (Progressive Hedging, PH) 算法下，为实现分解，引入了特定于场景的副本 $u_{s} = (u_{1,s}, u_{2,s})$，并通过带有惩罚参数 $\\rho$ 的增广拉格朗日量来强制执行非预期性。\n\n每个场景的基本发电计划都有一个二次运营成本，\n$$\nf_{s}(u_{s}) \\;=\\; \\sum_{j=1}^{2} \\left( \\frac{1}{2}\\,\\alpha_{j,s}\\,u_{j,s}^{2} \\;+\\; \\beta_{j,s}\\,u_{j,s} \\right),\n$$\n受制于发电机组容量限制 $0 \\leq u_{j,s} \\leq U_{j}$。为符合物理现实，设 $U_{1} = 100$ 兆瓦和 $U_{2} = 80$ 兆瓦，场景系数如下：\n$$\n\\alpha_{1,1} = 2,\\;\\; \\beta_{1,1} = 10;\\quad \\alpha_{2,1} = 4,\\;\\; \\beta_{2,1} = 8; \\\\\n\\alpha_{1,2} = 3,\\;\\; \\beta_{1,2} = 6;\\quad \\alpha_{2,2} = 1,\\;\\; \\beta_{2,2} = 5.\n$$\n假设 PH 惩罚参数为 $\\rho = 2$，初始乘子为 $\\lambda_{1}^{0} = (0,0)$ 和 $\\lambda_{2}^{0} = (0,0)$，初始平均计划为 $\\bar{u}^{0} = (20, 30)$ 兆瓦。执行一次从迭代 $k=0$ 到 $k=1$ 的渐进对冲迭代：对于每个场景 $s$，求解 PH 场景子问题。该子问题通过增加一个将 $u_{s}$ 拉向 $\\bar{u}^{0}$ 的惩罚项和当前乘子 $\\lambda_{s}^{0}$ 来增强 $f_{s}(u_{s})$，并受给定的边界条件约束。假设无约束最小化解是内部解（即，它们无需投影即满足边界条件）。然后，计算新的概率加权非预期性平均值\n$$\n\\bar{u}^{1} \\;=\\; \\sum_{s=1}^{2} p_{s}\\,u_{s}^{1},\n$$\n其中 $u_{s}^{1}$ 表示在此次迭代中获得的场景解。将最终答案表示为一个双元素行向量，给出 $\\bar{u}^{1}$ 的分量，单位为兆瓦。以精确的简化分数形式提供分量；不要四舍五入。",
            "solution": "首先根据既定标准对问题进行验证。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n- **模型：**一个两阶段随机运营模型。\n- **发电机组：**索引为 $j \\in \\{1,2\\}$。\n- **场景：**索引为 $s \\in \\{1,2\\}$。\n- **场景概率：**$p_{1} = 0.7$ 和 $p_{2} = 0.3$。\n- **第一阶段决策：**与场景无关的发电向量 $u = (u_{1}, u_{2})$。\n- **渐进对冲 (PH) 算法：**\n  - 特定于场景的决策副本：$u_{s} = (u_{1,s}, u_{2,s})$。\n  - 惩罚参数：$\\rho = 2$。\n- **场景成本函数：**$f_{s}(u_{s}) = \\sum_{j=1}^{2} \\left( \\frac{1}{2}\\,\\alpha_{j,s}\\,u_{j,s}^{2} + \\beta_{j,s}\\,u_{j,s} \\right)$。\n- **发电机组容量限制：**$0 \\leq u_{j,s} \\leq U_{j}$，其中 $U_{1} = 100$ MW 且 $U_{2} = 80$ MW。\n- **成本系数：**\n  - 对于 $s=1$：$\\alpha_{1,1} = 2$，$\\beta_{1,1} = 10$；$\\alpha_{2,1} = 4$，$\\beta_{2,1} = 8$。\n  - 对于 $s=2$：$\\alpha_{1,2} = 3$，$\\beta_{1,2} = 6$；$\\alpha_{2,2} = 1$，$\\beta_{2,2} = 5$。\n- **初始条件（迭代 $k=0$）：**\n  - 乘子：$\\lambda_{1}^{0} = (0,0)$ 和 $\\lambda_{2}^{0} = (0,0)$。\n  - 平均计划：$\\bar{u}^{0} = (20, 30)$。\n- **任务：**执行一次 PH 迭代，计算 $s=1,2$ 的子问题解 $u_{s}^{1}$，然后计算新的概率加权平均值 $\\bar{u}^{1} = \\sum_{s=1}^{2} p_{s}\\,u_{s}^{1}$。\n- **假设：**子问题的无约束最小化解位于容量限制的内部。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，采用了随机优化（渐进对冲）的标准方法，并应用于能源系统建模（二次发电机组成本）。该问题是适定的，具有凸二次目标函数和线性约束，保证了子问题的唯一解。所有必要的数据和条件均已提供，且没有内部矛盾。数值在当前情境下是物理上合理的。该问题是客观、可形式化和可验证的。\n\n**步骤 3：结论与行动**\n问题有效。将提供解答。\n\n### 解\n\n渐进对冲 (PH) 算法按场景分解随机优化问题。对于每个场景 $s$，都会求解一个子问题。在迭代 $k+1$ 时，场景 $s$ 的子问题是找到决策向量 $u_s^{k+1}$，以最小化增广拉格朗日函数：\n$$ u_{s}^{k+1} = \\arg\\min_{u_{s} \\in C_{s}} \\left\\{ f_{s}(u_{s}) + (\\lambda_{s}^{k})^{T} u_{s} + \\frac{\\rho}{2} \\| u_{s} - \\bar{u}^{k} \\|_{2}^{2} \\right\\} $$\n其中 $C_s$ 表示场景 $s$ 的可行集，在本例中由发电机组容量限制 $0 \\leq u_{j,s} \\leq U_{j}$ 定义。\n\n我们需要执行一次迭代，从 $k=0$ 开始，以找到 $\\bar{u}^1$。需要为场景 $s$ 最小化的目标函数是：\n$$ L_s(u_s) = f_{s}(u_{s}) + (\\lambda_{s}^{0})^{T} u_{s} + \\frac{\\rho}{2} \\| u_{s} - \\bar{u}^{0} \\|_{2}^{2} $$\n鉴于初始乘子是零向量，$\\lambda_s^0 = (0,0)$，项 $(\\lambda_{s}^{0})^{T} u_{s}$ 为零。目标函数简化为：\n$$ L_s(u_s) = \\sum_{j=1}^{2} \\left( \\frac{1}{2}\\,\\alpha_{j,s}\\,u_{j,s}^{2} + \\beta_{j,s}\\,u_{j,s} \\right) + \\frac{\\rho}{2} \\sum_{j=1}^{2} (u_{j,s} - \\bar{u}_{j}^{0})^{2} $$\n该目标函数就发电机组索引 $j$ 而言是可分的。因此，对于每个场景 $s$ 和每个发电机组 $j$，我们可以求解一个独立的一维优化问题：\n$$ \\min_{u_{j,s}} \\left\\{ J_{j,s}(u_{j,s}) = \\frac{1}{2}\\,\\alpha_{j,s}\\,u_{j,s}^{2} + \\beta_{j,s}\\,u_{j,s} + \\frac{\\rho}{2} (u_{j,s} - \\bar{u}_{j}^{0})^{2} \\right\\} $$\n受制于 $0 \\leq u_{j,s} \\leq U_{j}$。\n\n目标函数 $J_{j,s}(u_{j,s})$ 是一个严格凸的二次函数，因为 $\\alpha_{j,s} > 0$ 且 $\\rho > 0$。其无约束最小化解可通过将其关于 $u_{j,s}$ 的一阶导数设为零来找到：\n$$ \\frac{dJ_{j,s}}{du_{j,s}} = \\alpha_{j,s}\\,u_{j,s} + \\beta_{j,s} + \\rho(u_{j,s} - \\bar{u}_{j}^{0}) = 0 $$\n求解 $u_{j,s}$ 可得此次迭代的场景子问题的解，记为 $u_{j,s}^1$：\n$$ (\\alpha_{j,s} + \\rho)u_{j,s}^1 = \\rho\\,\\bar{u}_{j}^{0} - \\beta_{j,s} \\implies u_{j,s}^{1} = \\frac{\\rho\\,\\bar{u}_{j}^{0} - \\beta_{j,s}}{\\alpha_{j,s} + \\rho} $$\n问题陈述假设此无约束解是内部解，即它位于边界 $[0, U_j]$ 之内。我们将在计算后验证这一假设。我们使用给定值：$\\rho = 2$ 和 $\\bar{u}^{0} = (20, 30)$。\n\n**场景 $s=1$：**\n- 对于发电机组 $j=1$：$\\alpha_{1,1}=2$，$\\beta_{1,1}=10$，$\\bar{u}_1^0=20$。\n  $$ u_{1,1}^{1} = \\frac{2 \\cdot 20 - 10}{2 + 2} = \\frac{40 - 10}{4} = \\frac{30}{4} = \\frac{15}{2} $$\n- 对于发电机组 $j=2$：$\\alpha_{2,1}=4$，$\\beta_{2,1}=8$，$\\bar{u}_2^0=30$。\n  $$ u_{2,1}^{1} = \\frac{2 \\cdot 30 - 8}{4 + 2} = \\frac{60 - 8}{6} = \\frac{52}{6} = \\frac{26}{3} $$\n场景 1 的解为 $u_1^1 = (\\frac{15}{2}, \\frac{26}{3})$。边界验证：$0 \\leq \\frac{15}{2} \\leq 100$ 且 $0 \\leq \\frac{26}{3} \\leq 80$。两者皆为真。\n\n**场景 $s=2$：**\n- 对于发电机组 $j=1$：$\\alpha_{1,2}=3$，$\\beta_{1,2}=6$，$\\bar{u}_1^0=20$。\n  $$ u_{1,2}^{1} = \\frac{2 \\cdot 20 - 6}{3 + 2} = \\frac{40 - 6}{5} = \\frac{34}{5} $$\n- 对于发电机组 $j=2$：$\\alpha_{2,2}=1$，$\\beta_{2,2}=5$，$\\bar{u}_2^0=30$。\n  $$ u_{2,2}^{1} = \\frac{2 \\cdot 30 - 5}{1 + 2} = \\frac{60 - 5}{3} = \\frac{55}{3} $$\n场景 2 的解为 $u_2^1 = (\\frac{34}{5}, \\frac{55}{3})$。边界验证：$0 \\leq \\frac{34}{5} \\leq 100$ 且 $0 \\leq \\frac{55}{3} \\leq 80$。两者皆为真。假设成立。\n\n最后一步是计算新的概率加权平均计划 $\\bar{u}^1$：\n$$ \\bar{u}^{1} = \\sum_{s=1}^{2} p_{s}\\,u_{s}^{1} = p_{1}\\,u_{1}^{1} + p_{2}\\,u_{2}^{1} $$\n使用 $p_1 = 0.7 = \\frac{7}{10}$ 和 $p_2 = 0.3 = \\frac{3}{10}$，我们分别计算 $\\bar{u}^1 = (\\bar{u}_1^1, \\bar{u}_2^1)$ 的分量。\n\n- 分量 $\\bar{u}_1^1$：\n  $$ \\bar{u}_{1}^{1} = p_{1}\\,u_{1,1}^{1} + p_{2}\\,u_{1,2}^{1} = \\frac{7}{10} \\cdot \\frac{15}{2} + \\frac{3}{10} \\cdot \\frac{34}{5} $$\n  $$ \\bar{u}_{1}^{1} = \\frac{105}{20} + \\frac{102}{50} = \\frac{21}{4} + \\frac{51}{25} $$\n  $$ \\bar{u}_{1}^{1} = \\frac{21 \\cdot 25}{4 \\cdot 25} + \\frac{51 \\cdot 4}{25 \\cdot 4} = \\frac{525}{100} + \\frac{204}{100} = \\frac{729}{100} $$\n\n- 分量 $\\bar{u}_2^1$：\n  $$ \\bar{u}_{2}^{1} = p_{1}\\,u_{2,1}^{1} + p_{2}\\,u_{2,2}^{1} = \\frac{7}{10} \\cdot \\frac{26}{3} + \\frac{3}{10} \\cdot \\frac{55}{3} $$\n  $$ \\bar{u}_{2}^{1} = \\frac{182}{30} + \\frac{165}{30} = \\frac{182 + 165}{30} = \\frac{347}{30} $$\n\n一次迭代后更新的平均发电计划为 $\\bar{u}^1 = (\\frac{729}{100}, \\frac{347}{30})$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{729}{100}  \\frac{347}{30}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "惩罚参数 $ \\rho $ 是渐进式对冲算法中达成共识的引擎，但其效果可能很微妙。本练习通过分析 $ \\rho $ 在两种极端情况下的行为——当它趋近于零和趋近于无穷大时——来探究其根本作用。通过这种极限分析，您将对该算法如何在情景最优性与非预期性约束之间进行权衡建立更深刻的直觉 。",
            "id": "4114638",
            "problem": "考虑一个两情景随机能源采购模型，其中有一个第一阶段决策变量 $q \\in \\mathbb{R}$，根据非预期性原则，该变量在所有情景中必须保持一致。情景 $s \\in \\{1,2\\}$ 以已知概率 $p_{s} \\in (0,1)$ 发生，并具有一个凸二次运营成本\n$$\nF_{s}(q) \\;=\\; \\frac{1}{2} a_{s} q^{2} + b_{s} q,\n$$\n其中 $a_{s} \\in \\mathbb{R}_{>0}$ 和 $b_{s} \\in \\mathbb{R}$ 是给定系数，且 $p_{1}+p_{2}=1$。为了通过情景分解强制实现非预期性，应用渐进对冲（Progressive Hedging, PH）算法，该算法将 $q$ 复制为 $(q_{1},q_{2})$，并通过一个共识变量 $z \\in \\mathbb{R}$、情景乘子 $(u_{1},u_{2}) \\in \\mathbb{R}^{2}$ 以及一个二次惩罚参数 $\\rho \\in \\mathbb{R}_{>0}$ 将这些副本耦合起来。在迭代 $k \\in \\mathbb{N}$ 时，PH 算法对每个情景 $s \\in \\{1,2\\}$ 求解以下无约束子问题：\n$$\n\\min_{q_{s} \\in \\mathbb{R}} \\; F_{s}(q_{s}) \\;+\\; u_{s}^{k}\\left(q_{s}-z^{k}\\right) \\;+\\; \\frac{\\rho}{2}\\left(q_{s}-z^{k}\\right)^{2},\n$$\n然后通过概率加权平均来更新共识变量：\n$$\nz^{k+1} \\;=\\; p_{1} q_{1}^{k+1} \\;+\\; p_{2} q_{2}^{k+1},\n$$\n并通过以下方式更新乘子：\n$$\nu_{s}^{k+1} \\;=\\; u_{s}^{k} \\;+\\; \\rho \\left(q_{s}^{k+1} - z^{k+1}\\right).\n$$\n假设采用标准初始化 $u_{1}^{0}=u_{2}^{0}=0$ 和任意 $z^{0} \\in \\mathbb{R}$，并考虑 PH 的第一次迭代（$k=0 \\to 1$）。从情景子问题的凸优化最优性第一性原理和给定的 PH 更新规则出发，推导 $z^{1}$ 作为 $\\rho, a_{1}, a_{2}, b_{1}, b_{2}, p_{1}, p_{2}$ 和 $z^{0}$ 的函数的闭式表达式。然后，计算以下两个极限值：\n$$\n\\lim_{\\rho \\to 0} z^{1}\n\\quad \\text{和} \\quad\n\\lim_{\\rho \\to \\infty} z^{1},\n$$\n并从独立情景解与投影到非预期性共识集这两个角度来解释这些极限的含义。\n\n将你的最终答案以单行的形式给出，其中包含按顺序 $\\left(\\lim_{\\rho \\to 0} z^{1}, \\; \\lim_{\\rho \\to \\infty} z^{1}\\right)$ 排列的两个闭式极限。无需四舍五入，也不需要单位。你的答案必须是单个解析表达式。",
            "solution": "本问题要求在一个用于两情景随机规划的渐进对冲（PH）方案中，推导第一次迭代的共识变量 $z^{1}$，并评估当惩罚参数 $\\rho$ 趋于零和无穷大时该变量的极限。\n\n### 步骤 1：求解情景子问题\nPH 算法从迭代 $k=0$ 开始，初始共识变量为 $z^{0} \\in \\mathbb{R}$，初始乘子为 $u_{1}^{0}=0$ 和 $u_{2}^{0}=0$。对于每个情景 $s \\in \\{1,2\\}$，我们求解一个无约束子问题来找到 $q_{s}^{1}$。情景 $s$ 的子问题是：\n$$\n\\min_{q_{s} \\in \\mathbb{R}} \\; F_{s}(q_{s}) \\;+\\; u_{s}^{0}\\left(q_{s}-z^{0}\\right) \\;+\\; \\frac{\\rho}{2}\\left(q_{s}-z^{0}\\right)^{2}\n$$\n给定成本函数 $F_{s}(q_{s}) = \\frac{1}{2} a_{s} q_{s}^{2} + b_{s} q_{s}$ 和初始化 $u_{s}^{0}=0$，该子问题的目标函数（我们记为 $L_{s}(q_{s})$）简化为：\n$$\nL_{s}(q_{s}) = \\frac{1}{2} a_{s} q_{s}^{2} + b_{s} q_{s} + \\frac{\\rho}{2}\\left(q_{s}-z^{0}\\right)^{2}\n$$\n这是一个无约束凸优化问题。由于系数 $a_{s}$ 和 $\\rho$ 均被给定为严格正数（$a_{s} \\in \\mathbb{R}_{>0}$, $\\rho \\in \\mathbb{R}_{>0}$），目标函数 $L_{s}(q_{s})$ 相对于 $q_{s}$ 是严格凸的。通过应用一阶最优性条件，即将 $L_{s}(q_{s})$ 对 $q_{s}$ 的导数设为零，可以找到唯一的最小值。\n$$\n\\frac{d L_{s}}{d q_{s}} = \\frac{d}{d q_{s}} \\left( \\frac{1}{2} a_{s} q_{s}^{2} + b_{s} q_{s} + \\frac{\\rho}{2}(q_{s}^{2} - 2q_{s}z^{0} + (z^{0})^{2}) \\right) = 0\n$$\n$$\na_{s} q_{s} + b_{s} + \\rho(q_{s}-z^{0}) = 0\n$$\n令 $q_{s}^{1}$ 为此方程的解。我们整理各项来求解 $q_{s}^{1}$：\n$$\n(a_{s} + \\rho) q_{s}^{1} + b_{s} - \\rho z^{0} = 0\n$$\n$$\n(a_{s} + \\rho) q_{s}^{1} = \\rho z^{0} - b_{s}\n$$\n$$\nq_{s}^{1} = \\frac{\\rho z^{0} - b_{s}}{a_{s} + \\rho}\n$$\n这就给出了第一次迭代时每个特定情景子问题的最优解。\n\n### 步骤 2：更新共识变量\nPH 算法的下一步是通过计算各情景解 $q_{s}^{1}$ 的概率加权平均值来更新共识变量 $z$。$z^{1}$ 的更新规则是：\n$$\nz^{1} = p_{1} q_{1}^{1} + p_{2} q_{2}^{1}\n$$\n代入上一步推导出的 $q_{1}^{1}$ 和 $q_{2}^{1}$ 的表达式：\n$$\nz^{1} = p_{1} \\left( \\frac{\\rho z^{0} - b_{1}}{a_{1} + \\rho} \\right) + p_{2} \\left( \\frac{\\rho z^{0} - b_{2}}{a_{2} + \\rho} \\right)\n$$\n这就是所要求的 $z^{1}$ 的闭式表达式。\n\n### 步骤 3：计算 $\\rho \\to 0$ 时的极限\n我们首先计算当 $\\rho$ 趋于 $0$ 时 $z^{1}$ 的极限。由于 $\\rho$ 被定义为正参数，我们隐含地考虑从右侧趋近的极限，即 $\\rho \\to 0^{+}$。$z^{1}$ 的表达式是关于 $\\rho$ 的有理函数。因为 $a_{s} > 0$，分母 $a_{s}+\\rho$ 在 $\\rho=0$ 处不为零。因此，该极限可通过直接代入 $\\rho=0$ 求得：\n$$\n\\lim_{\\rho \\to 0} z^{1} = \\lim_{\\rho \\to 0} \\left[ p_{1} \\left( \\frac{\\rho z^{0} - b_{1}}{a_{1} + \\rho} \\right) + p_{2} \\left( \\frac{\\rho z^{0} - b_{2}}{a_{2} + \\rho} \\right) \\right]\n$$\n$$\n\\lim_{\\rho \\to 0} z^{1} = p_{1} \\left( \\frac{0 \\cdot z^{0} - b_{1}}{a_{1} + 0} \\right) + p_{2} \\left( \\frac{0 \\cdot z^{0} - b_{2}}{a_{2} + 0} \\right) = p_{1} \\left( \\frac{-b_{1}}{a_{1}} \\right) + p_{2} \\left( \\frac{-b_{2}}{a_{2}} \\right)\n$$\n$$\n\\lim_{\\rho \\to 0} z^{1} = -\\left(\\frac{p_{1} b_{1}}{a_{1}} + \\frac{p_{2} b_{2}}{a_{2}}\\right)\n$$\n这个极限有一个清晰的物理解释。量 $q_{s}^{*} = -b_{s}/a_{s}$ 是 $\\min_{q} F_{s}(q)$ 的解，即在情景 $s$ 确定发生的情况下的最优决策。因此，当不一致的惩罚趋于零时（$\\rho \\to 0$），子问题就变成了对原始情景成本的解耦最小化问题。最终得到的共识变量 $z^{1}$ 是各个独立的情景最优解的概率加权平均值。这表示将各个最优解组成的向量 $(q_{1}^{*}, q_{2}^{*})$ 投影到非预期性共识集上。\n\n### 步骤 4：计算 $\\rho \\to \\infty$ 时的极限\n接下来，我们计算当 $\\rho \\to \\infty$ 时 $z^{1}$ 的极限。为求此极限，我们可以分析 $z^{1}$ 表达式中各项的渐近行为。我们将每个分数的分子和分母同除以 $\\rho$：\n$$\nz^{1} = p_{1} \\left( \\frac{z^{0} - \\frac{b_{1}}{\\rho}}{\\frac{a_{1}}{\\rho} + 1} \\right) + p_{2} \\left( \\frac{z^{0} - \\frac{b_{2}}{\\rho}}{\\frac{a_{2}}{\\rho} + 1} \\right)\n$$\n现在，我们取 $\\rho \\to \\infty$ 的极限。当 $\\rho \\to \\infty$ 时，$\\frac{b_{s}}{\\rho}$ 和 $\\frac{a_{s}}{\\rho}$ 这两项都趋于 $0$。\n$$\n\\lim_{\\rho \\to \\infty} z^{1} = \\lim_{\\rho \\to \\infty} \\left[ p_{1} \\left( \\frac{z^{0} - \\frac{b_{1}}{\\rho}}{\\frac{a_{1}}{\\rho} + 1} \\right) + p_{2} \\left( \\frac{z^{0} - \\frac{b_{2}}{\\rho}}{\\frac{a_{2}}{\\rho} + 1} \\right) \\right]\n$$\n$$\n\\lim_{\\rho \\to \\infty} z^{1} = p_{1} \\left( \\frac{z^{0} - 0}{0 + 1} \\right) + p_{2} \\left( \\frac{z^{0} - 0}{0 + 1} \\right) = p_{1}z^{0} + p_{2}z^{0}\n$$\n利用 $p_{1} + p_{2} = 1$ 这一事实：\n$$\n\\lim_{\\rho \\to \\infty} z^{1} = (p_{1} + p_{2}) z^{0} = 1 \\cdot z^{0} = z^{0}\n$$\n这个结果表明，当惩罚参数 $\\rho$ 变得无限大时，$\\frac{\\rho}{2}(q_{s} - z^{0})^{2}$ 项在子问题的目标函数中占主导地位。最小化这个主导项需要强制使 $q_{s}^{1}$ 等于 $z^{0}$。因此，更新后的共识变量 $z^{1}$ 作为所有值都等于 $z^{0}$ 的平均值，结果就是 $z^{0}$。在这种机制下，由于偏离初始共识的惩罚是压倒性的，算法无法从初始共识猜测中取得任何进展。向共识集上的投影是平凡的，因为子问题的解已经被迫与初始共识值保持一致。\n\n因此，这两个极限值是 $-\\left(\\frac{p_{1} b_{1}}{a_{1}} + \\frac{p_{2} b_{2}}{a_{2}}\\right)$ 和 $z^{0}$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\left(\\frac{p_{1} b_{1}}{a_{1}} + \\frac{p_{2} b_{2}}{a_{2}}\\right)  z^{0}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "将渐进式对冲算法应用于包含二元（开/关）决策的问题，如机组组合问题，会引入在连续问题中不存在的独特挑战。本练习将考察二次惩罚项如何与整数变量相互作用，并揭示其可能“过早收敛”到次优解的风险。理解这种行为对于成功地将该算法应用于实际的、混合整数的能源系统模型至关重要 。",
            "id": "4114608",
            "problem": "考虑能源系统中单个火力发电机的两阶段随机机组组合模型。第 $0$ 阶段的机组组合决策是二元的 $x \\in \\{0,1\\}$，其中 $x=1$ 表示发电机已启用（可用），$x=0$ 表示未启用。在概率为 $p_s$ 的场景 $s \\in \\{1,2\\}$ 中，第 $1$ 阶段的调度决策 $q^s \\in [0,Q]$ 会产生可变成本 $c q^s$。如果需求 $D^s$ 未被完全满足，则对未满足的量支付每兆瓦时 $U$ 的短缺惩罚。发电机在启用时容量为 $Q$ 并且有固定成本 $F$。假设 $Q \\ge \\max\\{D^1, D^2\\}$ 且 $c  U$。在这些条件下，如果 $x=1$，则最优调度设置 $q^s = D^s$，场景成本为 $C_s(1) = F + c D^s$；而如果 $x=0$，则 $q^s = 0$，场景成本为 $C_s(0) = U D^s$。\n\n非预期性要求第 $0$ 阶段的决策在所有场景中保持一致。Progressive Hedging (PH) 算法通过使用增广拉格朗日量对场景子问题进行迭代来强制实现非预期性。在迭代次数为 $k$ 时，给定场景乘子 $w_s^k$ 和当前概率加权平均值 $\\bar x^k = \\sum_s p_s x_s^k$，场景 $s$ 的 PH 子问题通过最小化以下表达式来选择 $x_s^{k+1} \\in \\{0,1\\}$\n$$\nC_s(x_s) + w_s^k x_s + \\frac{\\rho}{2}\\left(x_s - \\bar x^k\\right)^2,\n$$\n然后更新 $\\bar x^{k+1} = \\sum_s p_s x_s^{k+1}$ 和 $w_s^{k+1} = w_s^k + \\rho\\left(x_s^{k+1} - \\bar x^{k+1}\\right)$。\n\n取数值 $F = 3000$，$c = 50$，$U = 200$，$D^1 = 100$，$D^2 = 15$，$p_1 = 0.4$，$p_2 = 0.6$ 以及 $Q \\ge 100$。考虑一次 PH 迭代，其中 $w_1^k = w_2^k = 0$ 且 $\\bar x^k = 0$。使用第一性原理和上述定义：\n\n- 推导惩罚参数 $\\rho$ 如何通过二次近端项与二元机组组合决策相互作用，并将选择 $x_s=1$ 与选择 $x_s=0$ 之间的近端惩罚差异表示为 $\\rho$ 和 $\\bar x^k$ 的函数。\n- 确定真实的非预期性最优机组组合决策 $x$ 及其期望成本。\n- 展示在 $\\bar x^k=0$ 时，对于满足 $C_s(1) - C_s(0) > 0$ 的场景，在 $\\rho$ 的什么阈值下会选择 $x_s^{k+1}=0$，并解释为什么过大的 $\\rho$ 会在混合整数决策的 PH 算法中强制过早地收敛到次优的整数模式。\n\n下列哪个陈述是正确的？\n\nA. 当 $\\bar{x}^k = 0$ 时，如果 $\\rho > 12000$，场景 1 会选择 $x_1^{k+1} = 0$，从而强制在 $x=0$ 处达成共识，即使期望最优解是 $x=1$。\n\nB. 对于二元变量 $x \\in \\{0,1\\}$，在给定的 $\\bar{x}$ 下，选择 $x=1$ 与 $x=0$ 的 Progressive Hedging 近端惩罚之差等于 $\\frac{\\rho}{2}(1 - 2\\bar{x})$，它作为一个与场景无关的转换成本加到场景目标函数上。\n\nC. 根据给定的数据，期望非预期性最优解是 $x=1$，期望成本为 $5450$，但在 $\\bar{x}^k = 0$ 和 $\\rho = 30000$ 的情况下，PH 场景子问题会为两个场景都选择 $x_s^{k+1} = 0$，从而在一个次优的整数模式上过早地达成共识。\n\nD. Progressive Hedging 惩罚项是 $\\rho|x_s - \\bar{x}^k|$，因此对于二元变量 $x$，它在 $\\bar{x}^k=0$ 和 $\\bar{x}^k=1$ 时的效果是相同的。\n\nE. 在包含混合整数决策的 Progressive Hedging 中，取 $\\rho \\to \\infty$ 可以保证收敛到全局最优的非预期性解，因为惩罚项抵消了所有的偏差。\n\n选择所有适用的选项。",
            "solution": "用户提供了一个关于 Progressive Hedging (PH) 算法应用于两阶段随机机组组合问题的陈述。任务是验证该问题，从第一性原理推导解决方案，并评估给定的选项。\n\n### 问题验证\n\n首先，我将提取给定信息并验证问题陈述。\n\n**第1步：提取给定信息**\n- **模型：** 单个火力发电机的两阶段随机机组组合。\n- **第0阶段决策：** 二元机组组合 $x \\in \\{0, 1\\}$。\n- **场景：** $s \\in \\{1, 2\\}$，概率为 $p_s$。\n- **第1阶段决策：** 调度量 $q^s \\in [0, Q]$。\n- **成本：** 可变成本 $c q^s$，未满足需求的短缺惩罚为每兆瓦时 $U$，如果 $x=1$ 则有固定成本 $F$。\n- **参数：** 容量 $Q$，需求 $D^s$。\n- **假设：** $Q \\ge \\max\\{D^1, D^2\\}$, $c  U$。\n- **推导的场景成本：** 如果 $x=1$，成本为 $C_s(1) = F + c D^s$。如果 $x=0$，成本为 $C_s(0) = U D^s$。\n- **Progressive Hedging (PH) 算法：**\n    - **在迭代 $k+1$ 时场景 $s$ 的子问题：** 选择 $x_s^{k+1} \\in \\{0, 1\\}$ 以最小化 $C_s(x_s) + w_s^k x_s + \\frac{\\rho}{2}(x_s - \\bar{x}^k)^2$。\n    - **变量更新：**\n        - $\\bar{x}^{k+1} = \\sum_s p_s x_s^{k+1}$\n        - $w_s^{k+1} = w_s^k + \\rho(x_s^{k+1} - \\bar{x}^{k+1})$\n- **数值数据：**\n    - $F = 3000$\n    - $c = 50$\n    - $U = 200$\n    - $D^1 = 100$\n    - $D^2 = 15$\n    - $p_1 = 0.4$\n    - $p_2 = 0.6$\n    - $Q \\ge 100$\n- **初始 PH 状态：** $w_1^k = w_2^k = 0$, $\\bar{x}^k = 0$。\n\n**第2步：使用提取的给定信息进行验证**\n该问题具有科学依据，是 Progressive Hedging 算法在能源系统建模中一个著名问题（随机机组组合）上的标准应用。假设（$c  U$）是标准的，并确保调度逻辑是直接的（生产总是比承担惩罚更便宜）。提供的成本函数 $C_s(x)$ 是从这些假设中正确推导出来的。PH 算法的数学公式是标准的。该问题是适定的、客观的、自洽的，没有矛盾。\n\n**第3步：结论和行动**\n问题陈述是**有效的**。我将继续进行推导和分析。\n\n### 解题推导\n\n解题过程将分三部分进行：首先，确定真正的最优非预期性解；其次，分析给定迭代中 PH 算法的行为；最后，评估每个选项。\n\n**第1部分：真正的非预期性最优解**\n\n真正的问题是找到 $x \\in \\{0, 1\\}$ 以最小化期望成本 $\\mathbb{E}[C(x)] = \\sum_s p_s C_s(x)$。\n\n首先，使用给定数据计算 $x \\in \\{0, 1\\}$ 和 $s \\in \\{1, 2\\}$ 的场景成本 $C_s(x)$：\n- $F = 3000$, $c = 50$, $U = 200$, $D^1 = 100$, $D^2 = 15$。\n\n对于场景 $s=1$：\n- 启用时的成本 ($x=1$)：$C_1(1) = F + c D^1 = 3000 + 50 \\times 100 = 3000 + 5000 = 8000$。\n- 未启用时的成本 ($x=0$)：$C_1(0) = U D^1 = 200 \\times 100 = 20000$。\n\n对于场景 $s=2$：\n- 启用时的成本 ($x=1$)：$C_2(1) = F + c D^2 = 3000 + 50 \\times 15 = 3000 + 750 = 3750$。\n- 未启用时的成本 ($x=0$)：$C_2(0) = U D^2 = 200 \\times 15 = 3000$。\n\n接下来，使用概率 $p_1 = 0.4$ 和 $p_2 = 0.6$ 计算每个非预期性决策 $x \\in \\{0, 1\\}$ 的期望成本：\n- $x=1$ 的期望成本：\n$$ \\mathbb{E}[C(1)] = p_1 C_1(1) + p_2 C_2(1) = 0.4 \\times 8000 + 0.6 \\times 3750 = 3200 + 2250 = 5450 $$\n- $x=0$ 的期望成本：\n$$ \\mathbb{E}[C(0)] = p_1 C_1(0) + p_2 C_2(0) = 0.4 \\times 20000 + 0.6 \\times 3000 = 8000 + 1800 = 9800 $$\n\n比较期望成本，$\\mathbb{E}[C(1)] = 5450  \\mathbb{E}[C(0)] = 9800$。因此，真正的非预期性最优机组组合决策是 $x=1$，期望成本为 $5450$。\n\n**第2部分：Progressive Hedging 迭代分析**\n\n场景 $s$ 的 PH 子问题旨在找到 $x_s^{k+1} \\in \\{0, 1\\}$ 以最小化增广成本函数：\n$$ J_s(x_s) = C_s(x_s) + w_s^k x_s + \\frac{\\rho}{2}(x_s - \\bar{x}^k)^2 $$\n我们已知迭代开始时的状态：$w_1^k = 0$, $w_2^k = 0$ 和 $\\bar{x}^k = 0$。目标函数简化为：\n$$ J_s(x_s) = C_s(x_s) + (0) \\cdot x_s + \\frac{\\rho}{2}(x_s - 0)^2 = C_s(x_s) + \\frac{\\rho}{2}x_s^2 $$\n由于 $x_s$ 是一个二元变量，$x_s \\in \\{0, 1\\}$，我们有 $x_s^2 = x_s$。目标函数进一步简化为：\n$$ J_s(x_s) = C_s(x_s) + \\frac{\\rho}{2}x_s $$\n为了找到最优的 $x_s^{k+1}$，我们比较 $x_s=0$ 和 $x_s=1$ 时的目标值：\n- $x_s=0$ 时的值：$J_s(0) = C_s(0) + \\frac{\\rho}{2}(0) = C_s(0)$。\n- $x_s=1$ 时的值：$J_s(1) = C_s(1) + \\frac{\\rho}{2}(1) = C_s(1) + \\frac{\\rho}{2}$。\n\n如果 $J_s(1)  J_s(0)$，子问题将选择 $x_s^{k+1}=1$，这意味着 $C_s(1) + \\frac{\\rho}{2}  C_s(0)$。整理后，选择 $x_s^{k+1}=1$ 的条件是：\n$$ C_s(1) - C_s(0)  -\\frac{\\rho}{2} $$\n否则，选择 $x_s^{k+1}=0$。\n\n现在，我们将此条件应用于每个场景：\n- **场景1：** $C_1(1) - C_1(0) = 8000 - 20000 = -12000$。\n  选择 $x_1^{k+1}=1$ 的条件是 $-12000  -\\frac{\\rho}{2}$，化简为 $12000 > \\frac{\\rho}{2}$，即 $\\rho  24000$。\n  因此，对于场景1，如果 $\\rho > 24000$，将会选择 $x_1^{k+1}=0$。\n\n- **场景2：** $C_2(1) - C_2(0) = 3750 - 3000 = 750$。\n  选择 $x_2^{k+1}=1$ 的条件是 $750  -\\frac{\\rho}{2}$。由于 $\\rho > 0$，右侧为负数。这个不等式永远无法满足。\n  因此，对于场景2，在此次迭代中，对于任何 $\\rho > 0$ 都会选择 $x_2^{k+1}=0$。\n\n此分析表明，如果 $\\rho > 24000$，两个场景都将决定 $x_1^{k+1}=0$ 和 $x_2^{k+1}=0$。这导致在次优解 $x=0$ 处达成共识（$\\bar{x}^{k+1}=0$）。然后算法会卡住，因为残差 $x_s^{k+1} - \\bar{x}^{k+1}$ 将为零，导致乘子 $w_s$ 不会更新，下一次迭代将从相同的状态开始。\n\n**第3部分：逐项分析**\n\n**A. 当 $\\bar x^k = 0$ 时，如果 $\\rho  12000$，场景 1 会选择 $x_1^{k+1} = 0$，从而强制在 $x=0$ 处达成共识，即使期望最优解是 $x=1$。**\n如第2部分推导，场景1在 $\\rho  24000$ 时选择 $x_1^{k+1}=0$。阈值 $\\rho  12000$ 是不正确的。虽然对于足够大的 $\\rho$，所描述的后果（强制在次优解 $x=0$ 处达成共识）是正确的，但具体条件是错误的。\n**结论：不正确**\n\n**B. 对于二元变量 $x \\in \\{0,1\\}$，在给定的 $\\bar x$ 下，选择 $x=1$ 与 $x=0$ 的 Progressive Hedging 近端惩罚之差等于 $\\frac{\\rho}{2}\\left(1 - 2\\bar x\\right)$，它作为一个与场景无关的转换成本加到场景目标函数上。**\n近端惩罚项是 $P(x_s) = \\frac{\\rho}{2}(x_s - \\bar{x}^k)^2$。让我们计算 $x_s=1$ 与 $x_s=0$ 之间的差异：\n$$ P(1) - P(0) = \\frac{\\rho}{2}(1 - \\bar{x}^k)^2 - \\frac{\\rho}{2}(0 - \\bar{x}^k)^2 = \\frac{\\rho}{2}\\left[ (1 - 2\\bar{x}^k + (\\bar{x}^k)^2) - (\\bar{x}^k)^2 \\right] = \\frac{\\rho}{2}(1 - 2\\bar{x}^k) $$\n数学表达式是正确的。为了理解其作用，考虑完整的决策准则：如果总成本较低，则选择 $x_s=1$ 而不是 $x_s=0$。总成本的差异是 $\\Delta J_s = (C_s(1) - C_s(0)) + w_s^k + (P(1) - P(0))$。项 $\\frac{\\rho}{2}(1 - 2\\bar{x}^k)$ 修改了选择 $x_s=1$ 和 $x_s=0$ 之间的成本差异。该项与场景 $s$ 无关，仅取决于 $\\rho$ 和当前的平均值 $\\bar{x}^k$。因此，它充当了选择 $x_s=1$ 的一个“转换成本”（或收益），这个成本对所有场景都是共同的，从而推动它们达成共识。这个解释是合理的。\n**结论：正确**\n\n**C. 根据给定的数据，期望非预期性最优解是 $x=1$，期望成本为 $5450$，但在 $\\bar x^k = 0$ 和 $\\rho = 30000$ 的情况下，PH 场景子问题会为两个场景都选择 $x_s^{k+1} = 0$，从而在一个次优的整数模式上过早地达成共识。**\n这个陈述由三个论断组成。\n1. “期望非预期性最优解是 $x=1$，期望成本为 $5450$”。如第1部分所示，这是正确的。\n2. “在 $\\bar x^k = 0$ 和 $\\rho = 30000$ 的情况下，PH 场景子问题会为两个场景都选择 $x_s^{k+1} = 0$”。如第2部分所示，对于场景1，如果 $\\rho  24000$ 会选择 $x_1^{k+1}=0$。由于 $30000  24000$，这成立。对于场景2，对于任何 $\\rho  0$ 都会选择 $x_2^{k+1}=0$。因此，两个场景都选择 $x_s^{k+1}=0$。这是正确的。\n3. “从而在一个次优的整数模式上过早地达成共识”。共识在 $x=0$ 处，而最优解是 $x=1$。这是在第一次正式迭代中达成的次优共识。这个论断也是正确的。\n由于陈述的所有部分都为真，因此整个陈述是正确的。\n**结论：正确**\n\n**D. Progressive Hedging 惩罚项是 $\\rho\\,\\lvert x_s - \\bar x^k\\rvert$，因此对于二元变量 $x$，它在 $\\bar x^k=0$ 和 $\\bar x^k=1$ 时的效果是相同的。**\n这个前提是错误的。问题陈述正确地将标准的 PH 惩罚项定义为二次项 $\\frac{\\rho}{2}(x_s - \\bar{x}^k)^2$，而不是 L1 范数 $\\rho|x_s - \\bar{x}^k|$。该陈述以一个相对于问题定义而言在事实上不正确的公式开始。\n**结论：不正确**\n\n**E. 在包含混合整数决策的 Progressive Hedging 中，取 $\\rho \\to \\infty$ 可以保证收敛到全局最优的非预期性解，因为惩罚项抵消了所有的偏差。**\n这是关于 PH 算法用于混合整数规划（MIP）问题的一般性论断。众所周知，对于像 MIP 这样的非凸问题，PH 是一种启发式算法，不保证收敛到全局最优解。一个非常大的 $\\rho$ 会严重惩罚非共识，通常会在对偶乘子（$w_s$）能够引导搜索走向真正最优解之前，就迫使所有整数变量在一个次优模式上达成一致。我们当前的问题提供了一个直接的反例：对于任何 $\\rho  24000$，算法都会收敛到次优解 $x=0$。因此，取 $\\rho \\to \\infty$ 并不能保证最优性。\n**结论：不正确**",
            "answer": "$$\\boxed{BC}$$"
        }
    ]
}