{
    "hands_on_practices": [
        {
            "introduction": "Transitioning from simple deterministic metrics to a probabilistic understanding of reliability is a cornerstone of modern resource adequacy. While an intuitive metric, the Planning Reserve Margin ($PRM$) can be misleading as it fails to account for the actual performance and outage probabilities of generators. This first practice bridges that conceptual gap, asking you to demonstrate mathematically how a fixed $PRM$ can lead to vastly different reliability outcomes and, more importantly, how to derive the reserve margin required to meet a specific probabilistic target, such as a Loss of Load Expectation ($LOLE$) of 1 day in 10 years. By working through this idealized scenario, you will build a foundational appreciation for why probabilistic methods are essential for consistent and economically efficient grid planning. ",
            "id": "4119073",
            "problem": "Consider a stylized power system used for resource adequacy assessment. The system serves a constant peak load $L$ for $T$ hours per year, and the generation fleet consists of $N$ identical, statistically independent units, each with nameplate capacity $C$ and a constant Forced Outage Rate (FOR), denoted $\\mathrm{FOR} \\in (0,1)$. The Planning Reserve Margin (PRM) is defined deterministically by the relation that installed capacity equals $(1+\\mathrm{PRM})$ times the peak load, that is $N C = (1+\\mathrm{PRM}) L$. Let the number of units online at any instant be a random variable $X$ that follows the binomial distribution with success probability $p = 1 - \\mathrm{FOR}$. A loss-of-load event occurs if the available capacity is less than the load, i.e., if $X C < L$. The Loss of Load Expectation (LOLE) is the expected number of hours per year with loss of load, which for this stylized constant-load system is $T$ times the probability of a shortfall event. Let $r = L/C$ denote the number of online units required to exactly meet the peak load, and suppose $r$ is not an integer so that the shortfall threshold is $X < r$.\n\nUsing only fundamental probabilistic definitions and well-tested approximations appropriate for large fleets (e.g., the normal approximation to the binomial distribution with appropriate continuity correction), answer the following:\n\n1. Starting from the definition of LOLE as an expectation over shortfall events under $X \\sim \\mathrm{Binomial}(N,p)$, explain mathematically why a fixed deterministic $\\mathrm{PRM}$ produces different adequacy outcomes (different LOLE) when $\\mathrm{FOR}$ changes. Your explanation should derive the dependence of LOLE on $\\mathrm{FOR}$ through $p$ and make clear the role of $N$, $C$, and $L$.\n\n2. Let the target adequacy standard be a specified $\\mathrm{LOLE}^{\\star}$ (in hours per year), and let $q = \\mathrm{LOLE}^{\\star}/T$ be the corresponding target shortfall probability per hour under the constant-load stylization. Under the normal approximation for $X$, derive a closed-form analytic expression for the deterministic $\\mathrm{PRM}$ required to achieve $\\mathrm{LOLE}^{\\star}$ as a function of $p$, $q$, and $r$, using a continuity correction of $0.5$ units. Your final expression must be a single closed-form analytic expression in terms of $p$, $q$, and $r$ (you may use the inverse of the standard normal cumulative distribution function), and it must explicitly solve for $\\mathrm{PRM}$.\n\nExpress the final $\\mathrm{PRM}$ as a dimensionless decimal (for example, $0.15$ for fifteen percent). No numerical evaluation is required; provide the symbolic expression only. The final answer must be a single analytic expression.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It utilizes a standard, albeit simplified, model from power system reliability analysis. All variables and conditions are sufficiently defined to permit a unique, meaningful solution. The problem is therefore deemed **valid**.\n\n### Part 1: Impact of FOR on LOLE for a Fixed PRM\n\nThe Loss of Load Expectation (LOLE) is defined as the expected number of hours per year with a generation shortfall. For the stylized system with a constant load $L$ for $T$ hours, this is given by:\n$$\n\\mathrm{LOLE} = T \\times P(\\text{shortfall})\n$$\nA shortfall event occurs when the total available capacity is less than the load. Let $X$ be the number of online generating units out of a total of $N$. The total available capacity is $X C$, where $C$ is the capacity of a single unit. The shortfall condition is $X C < L$, which can be rewritten as $X < L/C$.\nThe problem defines $r = L/C$, so the condition is $X < r$.\n\nThe number of online units $X$ is a random variable that follows a binomial distribution, as the $N$ units are statistically independent with an availability (success probability) of $p = 1 - \\mathrm{FOR}$. Thus, $X \\sim \\mathrm{Binomial}(N, p)$. The probability of a shortfall event is the cumulative probability that $X$ is less than $r$. Since $X$ is an integer and $r$ is specified not to be an integer, this probability is:\n$$\nP(X < r) = P(X \\le \\lfloor r \\rfloor) = \\sum_{k=0}^{\\lfloor r \\rfloor} \\binom{N}{k} p^k (1-p)^{N-k}\n$$\nThe Planning Reserve Margin (PRM) is defined by the relation between total installed capacity $NC$ and peak load $L$:\n$$\nNC = (1+\\mathrm{PRM})L\n$$\nWe can express the total number of units, $N$, in terms of $r$ and the PRM. By substituting $L=rC$ into the PRM definition, we find:\n$$\nNC = (1+\\mathrm{PRM})rC \\implies N = (1+\\mathrm{PRM})r\n$$\nFor a fixed PRM and a fixed system scale (i.e., fixed $r=L/C$), the total number of generators $N$ is also fixed. The LOLE is then:\n$$\n\\mathrm{LOLE} = T \\times \\sum_{k=0}^{\\lfloor r \\rfloor} \\binom{(1+\\mathrm{PRM})r}{k} (1-\\mathrm{FOR})^k (\\mathrm{FOR})^{(1+\\mathrm{PRM})r-k}\n$$\nThis expression demonstrates that LOLE is an explicit function of the Forced Outage Rate, $\\mathrm{FOR}$, through the availability $p = 1 - \\mathrm{FOR}$ and unavailability $1-p = \\mathrm{FOR}$.\n\nTo understand the nature of this dependence, we consider the properties of the binomial distribution $X \\sim \\mathrm{Binomial}(N, p)$. The expected number of online units is $\\mu = E[X] = Np$. As $\\mathrm{FOR}$ increases, $p$ decreases, and consequently, the expected number of online units $\\mu$ decreases. This means the entire probability mass function of $X$ shifts towards lower values. The shortfall threshold, $r$, however, remains fixed. A shift of the distribution's mass to the left while the threshold remains constant necessarily increases the cumulative probability of falling below that threshold. In other words, as $\\mathrm{FOR}$ increases, the probability $P(X < r)$ increases, leading to a higher LOLE.\n\nA fixed PRM ensures that the total installed capacity is a certain percentage above the peak load, but it provides no information about the expected *available* capacity, which is $E[XC] = E[X]C = (Np)C$. This expected available capacity is directly dependent on the reliability of the generators (the FOR). Therefore, a deterministic metric like PRM is insufficient on its own to guarantee a specific probabilistic reliability level like LOLE; a higher FOR requires a higher PRM to achieve the same LOLE.\n\n### Part 2: Derivation of PRM for a Target LOLE\n\nThe goal is to find the PRM required to achieve a target adequacy standard $\\mathrm{LOLE}^{\\star}$. This corresponds to a target shortfall probability per hour of $q = \\mathrm{LOLE}^{\\star}/T$. The condition to be met is:\n$$\nP(X < r) = q\n$$\nWe are instructed to use the normal approximation to the binomial distribution. For $X \\sim \\mathrm{Binomial}(N, p)$, the approximation is $X \\approx \\mathcal{N}(\\mu, \\sigma^2)$, with mean $\\mu = Np$ and variance $\\sigma^2 = Np(1-p)$.\n\nTo approximate the probability for the discrete variable $X$, we apply a continuity correction. The event $X < r$ is equivalent to $X \\le \\lfloor r \\rfloor$ because $X$ is an integer and $r$ is not. The problem statement refers to a continuity correction of $0.5$ units. This is interpreted as approximating the discrete probability $P(X < r)$ by evaluating the cumulative distribution function of the corresponding normal approximation at the point $r - 0.5$. Let $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$, and let $\\Phi(z)$ be its cumulative distribution function (CDF).\n$$\nP(X < r) \\approx P\\left( Z \\le \\frac{(r - 0.5) - \\mu}{\\sigma} \\right) = \\Phi\\left(\\frac{(r - 0.5) - Np}{\\sqrt{Np(1-p)}}\\right)\n$$\nWe set this probability equal to the target $q$:\n$$\n\\Phi\\left(\\frac{(r - 0.5) - Np}{\\sqrt{Np(1-p)}}\\right) = q\n$$\nApplying the inverse standard normal CDF, $\\Phi^{-1}$, to both sides yields:\n$$\n\\frac{(r - 0.5) - Np}{\\sqrt{Np(1-p)}} = \\Phi^{-1}(q)\n$$\nTo solve for $N$, we rearrange the equation. Let $z_q = \\Phi^{-1}(q)$ for notational convenience.\n$$\n(r - 0.5) - Np = z_q \\sqrt{N} \\sqrt{p(1-p)}\n$$\nThis can be written as a quadratic equation in terms of $\\sqrt{N}$:\n$$\np(\\sqrt{N})^2 + \\left(z_q \\sqrt{p(1-p)}\\right)(\\sqrt{N}) - (r - 0.5) = 0\n$$\nWe solve for $\\sqrt{N}$ using the quadratic formula, $\\sqrt{N} = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$, where $a=p$, $b=z_q \\sqrt{p(1-p)}$, and $c=-(r-0.5)$. Since $\\sqrt{N}$ must be a positive real number, we take the positive root:\n$$\n\\sqrt{N} = \\frac{-z_q \\sqrt{p(1-p)} + \\sqrt{\\left(z_q \\sqrt{p(1-p)}\\right)^2 - 4(p)(-(r - 0.5))}}{2p}\n$$\n$$\n\\sqrt{N} = \\frac{-z_q \\sqrt{p(1-p)} + \\sqrt{z_q^2 p(1-p) + 4p(r - 0.5)}}{2p}\n$$\nSquaring both sides gives the required number of units, $N$:\n$$\nN = \\left( \\frac{-z_q \\sqrt{p(1-p)} + \\sqrt{z_q^2 p(1-p) + 4p(r - 0.5)}}{2p} \\right)^2\n$$\nFinally, we use the definition of PRM, $\\mathrm{PRM} = \\frac{N}{r} - 1$, to find the required reserve margin. Substituting the expression for $N$ and replacing $z_q$ with $\\Phi^{-1}(q)$:\n$$\n\\mathrm{PRM} = \\frac{1}{r} \\left( \\frac{-\\Phi^{-1}(q) \\sqrt{p(1-p)} + \\sqrt{(\\Phi^{-1}(q))^2 p(1-p) + 4p(r - 0.5)}}{2p} \\right)^2 - 1\n$$\nThis is the closed-form analytic expression for the PRM as a function of $p$, $q$, and $r$.",
            "answer": "$$\\boxed{\\frac{1}{r} \\left( \\frac{-\\Phi^{-1}(q) \\sqrt{p(1-p)} + \\sqrt{(\\Phi^{-1}(q))^{2} p(1-p) + 4p(r - 0.5)}}{2p} \\right)^{2} - 1}$$"
        },
        {
            "introduction": "Once we establish a probabilistic framework for system reliability, the next critical question is how to quantify the contribution of an individual resource. This is the essence of capacity credit, and the \"gold standard\" metric is the Effective Load Carrying Capability ($ELCC$). This practice guides you through a foundational derivation of a linearized $ELCC$ formula using first-order perturbation analysis. This exercise is invaluable as it reveals the core principle of capacity value: a resource's contribution is not merely its rated capacity, but is instead a weighted average of its output, with the weights being highest during hours of the greatest system stress. ",
            "id": "4119068",
            "problem": "Consider a single-area power system modeled over discrete time steps $t \\in \\{1,\\dots,T\\}$. At each time $t$, the net demand (load) $D_t$ is a continuous random variable with cumulative distribution function $F_{D_t}(d)$ and probability density function $f_{D_t}(d)$ that is differentiable in a neighborhood of $d=X_t$, where $X_t$ is the baseline available firm capacity (deterministic) at time $t$. An additional resource provides a deterministic output vector $\\{y_t\\}_{t=1}^{T}$, with each $y_t$ measured in Megawatts (MW). The system reliability metric is the Loss of Load Expectation (LOLE), defined as the expected count of time steps in which demand exceeds available capacity:\n$$\n\\mathrm{LOLE}(\\{c_t\\}_{t=1}^{T}) \\equiv \\sum_{t=1}^{T} \\mathbb{P}\\!\\left(D_t > c_t\\right).\n$$\nWith the added resource, available capacity at time $t$ is $X_t + y_t$. The average Effective Load Carrying Capability (ELCC) $\\Delta C$ of the resource is defined as the constant firm capacity addition (in MW) that achieves the same Loss of Load Expectation as the time-varying addition $\\{y_t\\}_{t=1}^{T}$:\n$$\n\\sum_{t=1}^{T} \\mathbb{P}\\!\\left(D_t > X_t + y_t\\right) \\;=\\; \\sum_{t=1}^{T} \\mathbb{P}\\!\\left(D_t > X_t + \\Delta C\\right).\n$$\nStarting from the definition of Loss of Load Expectation and the differentiability of $F_{D_t}$, use a first-order perturbation analysis around $\\{y_t\\}=\\{0\\}$ and $\\Delta C=0$ to derive a closed-form analytic expression for $\\Delta C$ in terms of $\\{y_t\\}_{t=1}^{T}$ and $\\{f_{D_t}(X_t)\\}_{t=1}^{T}$. Clearly state any regularity conditions you use. Express your final formula for $\\Delta C$; when evaluated with inputs in Megawatts (MW), $\\Delta C$ will be in Megawatts (MW). Your final answer must be a single closed-form expression.",
            "solution": "The problem statement is a valid, well-posed problem in energy systems modeling, specifically in the domain of resource adequacy assessment. It is scientifically grounded, objective, and contains sufficient information to derive the requested expression. We proceed with the solution.\n\nThe objective is to find a first-order approximation for the average Effective Load Carrying Capability (ELCC), denoted as $\\Delta C$, of a resource with time-varying output $\\{y_t\\}_{t=1}^{T}$. The definition of $\\Delta C$ equates the Loss of Load Expectation (LOLE) of a system with the added resource to the LOLE of a system with a constant firm capacity addition of $\\Delta C$.\n\nThe defining equation is given as:\n$$\n\\sum_{t=1}^{T} \\mathbb{P}\\!\\left(D_t > X_t + y_t\\right) = \\sum_{t=1}^{T} \\mathbb{P}\\!\\left(D_t > X_t + \\Delta C\\right)\n$$\nwhere $D_t$ is the random demand at time $t$, $X_t$ is the baseline firm capacity, and $y_t$ is the output of the new resource.\n\nFor a continuous random variable $D_t$ with a cumulative distribution function (CDF) $F_{D_t}(d)$, the probability of a loss-of-load event $\\mathbb{P}(D_t > c)$ can be expressed as:\n$$\n\\mathbb{P}(D_t > c) = 1 - \\mathbb{P}(D_t \\le c) = 1 - F_{D_t}(c)\n$$\nSubstituting this into the defining equation for $\\Delta C$ yields:\n$$\n\\sum_{t=1}^{T} \\left(1 - F_{D_t}(X_t + y_t)\\right) = \\sum_{t=1}^{T} \\left(1 - F_{D_t}(X_t + \\Delta C)\\right)\n$$\nThe constant term $T = \\sum_{t=1}^{T} 1$ can be cancelled from both sides, simplifying the equation to:\n$$\n\\sum_{t=1}^{T} F_{D_t}(X_t + y_t) = \\sum_{t=1}^{T} F_{D_t}(X_t + \\Delta C)\n$$\nLet us define a function $G_t(z) = F_{D_t}(X_t + z)$ for each time step $t$. The equation becomes:\n$$\n\\sum_{t=1}^{T} G_t(y_t) = \\sum_{t=1}^{T} G_t(\\Delta C)\n$$\nThe problem requires a first-order perturbation analysis around $\\{y_t\\}=\\{0\\}$ and $\\Delta C=0$. This is equivalent to performing a first-order Taylor series expansion of the functions $G_t(z)$ around $z=0$. The expansion is:\n$$\nG_t(z) \\approx G_t(0) + G_t'(0) \\cdot z\n$$\nTo find the derivative $G_t'(z)$, we use the chain rule. The derivative of the CDF $F_{D_t}(d)$ with respect to its argument $d$ is the probability density function (PDF), $f_{D_t}(d)$. The problem statement guarantees that $F_{D_t}$ is differentiable in a neighborhood of $X_t$, so this derivative exists.\n$$\nG_t'(z) = \\frac{d}{dz} F_{D_t}(X_t + z) = f_{D_t}(X_t + z) \\cdot \\frac{d}{dz}(X_t + z) = f_{D_t}(X_t + z)\n$$\nEvaluating the derivative at $z=0$:\n$$\nG_t'(0) = f_{D_t}(X_t)\n$$\nNow, we can write the first-order approximations for the terms in our summation.\nFor the left-hand side (LHS), we approximate each term $G_t(y_t)$:\n$$\nG_t(y_t) \\approx G_t(0) + G_t'(0) \\cdot y_t = F_{D_t}(X_t) + f_{D_t}(X_t) \\cdot y_t\n$$\nSumming over all time steps $t$:\n$$\n\\text{LHS} = \\sum_{t=1}^{T} G_t(y_t) \\approx \\sum_{t=1}^{T} \\left( F_{D_t}(X_t) + f_{D_t}(X_t) \\cdot y_t \\right) = \\sum_{t=1}^{T} F_{D_t}(X_t) + \\sum_{t=1}^{T} f_{D_t}(X_t) \\cdot y_t\n$$\nFor the right-hand side (RHS), we have a single perturbation variable $\\Delta C$ that is constant across all $t$. We approximate each term $G_t(\\Delta C)$:\n$$\nG_t(\\Delta C) \\approx G_t(0) + G_t'(0) \\cdot \\Delta C = F_{D_t}(X_t) + f_{D_t}(X_t) \\cdot \\Delta C\n$$\nSumming over all time steps $t$:\n$$\n\\text{RHS} = \\sum_{t=1}^{T} G_t(\\Delta C) \\approx \\sum_{t=1}^{T} \\left( F_{D_t}(X_t) + f_{D_t}(X_t) \\cdot \\Delta C \\right) = \\sum_{t=1}^{T} F_{D_t}(X_t) + \\Delta C \\sum_{t=1}^{T} f_{D_t}(X_t)\n$$\nNow, we equate the linearized expressions for the LHS and RHS:\n$$\n\\sum_{t=1}^{T} F_{D_t}(X_t) + \\sum_{t=1}^{T} f_{D_t}(X_t) \\cdot y_t = \\sum_{t=1}^{T} F_{D_t}(X_t) + \\Delta C \\sum_{t=1}^{T} f_{D_t}(X_t)\n$$\nThe term $\\sum_{t=1}^{T} F_{D_t}(X_t)$ cancels from both sides, leaving:\n$$\n\\sum_{t=1}^{T} y_t \\cdot f_{D_t}(X_t) = \\Delta C \\cdot \\sum_{t=1}^{T} f_{D_t}(X_t)\n$$\nFinally, we solve for $\\Delta C$ by isolating it. This requires the assumption that the sum in the denominator is non-zero, a necessary regularity condition. Given that $f_{D_t}(d) \\ge 0$ for all $d$ and $t$, this sum would only be zero if $f_{D_t}(X_t) = 0$ for all $t$, which is a trivial case where the system is never at risk at the capacity level $X_t$, making the ELCC calculation ill-defined. We assume $\\sum_{t=1}^{T} f_{D_t}(X_t) > 0$.\n$$\n\\Delta C = \\frac{\\sum_{t=1}^{T} y_t \\cdot f_{D_t}(X_t)}{\\sum_{t=1}^{T} f_{D_t}(X_t)}\n$$\nThis expression represents the first-order approximation of the ELCC. It is a weighted average of the resource's time-varying output $\\{y_t\\}$, where the weights are the probability densities of demand at the baseline capacity level, $f_{D_t}(X_t)$. These weights represent the relative likelihood of a loss-of-load event occurring at each time step $t$ in the baseline system.\n\nThe regularity conditions used in this derivation are:\n1.  For each $t$, the CDF $F_{D_t}(d)$ is differentiable in a neighborhood of $d=X_t$. This is given in the problem.\n2.  The perturbations $\\{y_t\\}$ and $\\Delta C$ are sufficiently small such that the first-order Taylor approximation is valid. This is implicit in the request for a \"first-order perturbation analysis.\"\n3.  $\\sum_{t=1}^{T} f_{D_t}(X_t) > 0$. This ensures the denominator is non-zero, making $\\Delta C$ well-defined.",
            "answer": "$$\\boxed{\\frac{\\sum_{t=1}^{T} y_t f_{D_t}(X_t)}{\\sum_{t=1}^{T} f_{D_t}(X_t)}}$$"
        },
        {
            "introduction": "The principles of capacity credit become particularly insightful when applied to modern, energy-limited resources like battery storage. Unlike a conventional generator, the ability of a storage device to contribute to resource adequacy is constrained by both its power capacity ($P$, in MW) and its energy capacity ($E$, in MWh). This final practice moves from analytical derivation to numerical application, challenging you to compute the $ELCC$ of storage based on an Expected Energy Unserved ($EUE$) criterion. By comparing a short-duration and a long-duration device across different types of shortfall events, you will gain hands-on experience showing how a resource's capacity value is intricately linked to the specific reliability challenges—such as short, sharp peaks versus long, multi-hour deficits—that a system faces. ",
            "id": "4119026",
            "problem": "Consider a stylized resource adequacy setting where shortfall events are represented by hourly deficit profiles. The reliability target is based on Energy Unserved (EUE), and the Effective Load Carrying Capability (ELCC) of a storage device is defined as the uniform load increase, expressed as a constant in megawatts, that the system can tolerate with the device added while keeping the total EUE equal to the baseline EUE without the device. Assume the following foundations and constraints:\n\n- Energy Unserved (EUE) is defined as the integral of the demand shortfall over time, equivalently the sum over discrete hours: for a deficit profile $\\{d_t\\}$ over an event, its EUE is $\\sum_t d_t$ with $d_t \\ge 0$, in megawatt-hours.\n- Effective Load Carrying Capability (ELCC) is defined as the constant load increase $L$ (in megawatts) that can be added uniformly to all event hours such that the EUE with the resource and added load equals the EUE of the baseline system without the resource.\n- Storage device constraints:\n  - Discharge power limit $P$ (in megawatts).\n  - Usable energy capacity $E$ (in megawatt-hours).\n  - Round-trip efficiency equals $1$.\n  - Perfect foresight and event independence: the device is fully charged at the start of each shortfall event and can recharge without constraint between events; no inter-event coupling.\n- Events are disjoint and cover only hours with baseline deficits; outside these hours, there is sufficient margin such that adding load does not create new deficits.\n\nModeling assumptions and objective:\n- For each event $e$ with duration $h_e$ hours and deficit profile $\\{d_{e,t}\\}_{t=1}^{h_e}$, under a uniform load increase $L$ and optimal EUE-minimizing dispatch, the device’s discharge in hour $t$ is bounded by $0 \\leq x_{e,t} \\leq \\min\\{P, d_{e,t} + L\\}$ and the total discharge over the event satisfies $\\sum_{t=1}^{h_e} x_{e,t} \\leq E$. The device acts to minimize EUE by reducing deficits subject to these constraints.\n- The EUE with the device and load increase $L$ across all events is $\\sum_e \\left[\\sum_{t=1}^{h_e} (d_{e,t} + L) - \\sum_{t=1}^{h_e} x_{e,t}\\right]$.\n\nDerive, from the above, the ELCC equation in a purely mathematical form and implement an algorithm to compute $L$ for a given set of events and device parameters $(P,E)$, assuming optimal EUE-minimizing dispatch. Your program must:\n- Use the derived optimal dispatch characterization to compute the delivered energy in event $e$ under load increase $L$ as $\\min\\left\\{E, \\sum_{t=1}^{h_e} \\min\\{P, d_{e,t} + L\\}\\right\\}$ and then solve for the ELCC $L$ satisfying\n$$\n\\sum_e \\min\\left\\{E, \\sum_{t=1}^{h_e} \\min\\{P, d_{e,t} + L\\}\\right\\} \\;=\\; L \\sum_e h_e \\, .\n$$\n- Compute the ELCCs for two devices at identical $P$: a short-duration storage device with $E = 2P$ and a long-duration storage device with $E = 20P$.\n- Report the ELCC values in megawatts and the ratio of long-duration ELCC to short-duration ELCC as decimals without any percentage sign.\n- Use the following test suite, with all deficits expressed in megawatts and durations in hours. For each case, $P$ is specified, and the events are lists of hourly deficits:\n\nTest Case 1 (mixture of short and long events):\n- $P = 100$\n- Events:\n  - Event $1$: duration $2$ hours, deficits $\\{120, 140\\}$.\n  - Event $2$: duration $12$ hours, deficits $\\{85, 95, 105, 115, 110, 100, 90, 80, 70, 60, 55, 50\\}$.\n  - Event $3$: duration $1$ hour, deficits $\\{200\\}$.\n  - Event $4$: duration $18$ hours, deficits $\\{60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60\\}$.\n\nTest Case 2 (only short events):\n- $P = 100$\n- Events:\n  - Event $1$: duration $1$ hour, deficits $\\{70\\}$.\n  - Event $2$: duration $2$ hours, deficits $\\{80, 90\\}$.\n  - Event $3$: duration $2$ hours, deficits $\\{50, 45\\}$.\n\nTest Case 3 (only long events):\n- $P = 100$\n- Events:\n  - Event $1$: duration $15$ hours, deficits $\\{90, 95, 100, 105, 110, 115, 120, 125, 130, 125, 120, 115, 110, 105, 100\\}$.\n  - Event $2$: duration $20$ hours, deficits $\\{70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70\\}$.\n\nExpress all computed ELCCs in megawatts. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list of three numbers $[L_{\\text{short}}, L_{\\text{long}}, L_{\\text{long}}/L_{\\text{short}}]$. For example, the final output format must be exactly like:\n$[[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3]]$\nwith the numerical values in place of $a_i$, $b_i$, and $c_i$.",
            "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded in the principles of resource adequacy assessment, is mathematically well-posed, and provides a complete and consistent set of data and definitions.\n\nThe objective is to derive the governing equation for the Effective Load Carrying Capability (ELCC) and implement a numerical algorithm to solve it for specified test cases. The ELCC, denoted by $L$, represents the constant load increase a power system can sustain after adding a new resource (in this case, an energy storage device) while maintaining the same level of reliability, measured here by Expected Energy Unserved (EUE).\n\nFirst, we establish the mathematical foundation based on the problem's definitions. The baseline EUE, without the storage device, is the sum of all energy deficits across all shortfall events:\n$$ EUE_{base} = \\sum_e \\sum_{t=1}^{h_e} d_{e,t} $$\nwhere $d_{e,t}$ is the energy deficit in megawatt-hours (MW-h) for hour $t$ of event $e$, which has a duration of $h_e$ hours.\n\nWhen a storage device is added and a uniform load increase of $L$ megawatts (MW) is applied to the system, the deficit in each hour $t$ of event $e$ becomes $(d_{e,t} + L)$. The storage device dispatches energy $x_{e,t}$ to mitigate this new, larger deficit. The new EUE is:\n$$ EUE_{new} = \\sum_e \\sum_{t=1}^{h_e} (d_{e,t} + L - x_{e,t}) $$\nThe definition of ELCC requires that the reliability level remains unchanged, i.e., $EUE_{new} = EUE_{base}$. Setting these two expressions equal yields:\n$$ \\sum_e \\sum_{t=1}^{h_e} (d_{e,t} + L - x_{e,t}) = \\sum_e \\sum_{t=1}^{h_e} d_{e,t} $$\nBy canceling the $\\sum_e \\sum_t d_{e,t}$ term from both sides and rearranging, we obtain a fundamental relationship:\n$$ \\sum_e \\sum_{t=1}^{h_e} L = \\sum_e \\sum_{t=1}^{h_e} x_{e,t} $$\n$$ L \\sum_e h_e = \\sum_e \\left(\\sum_{t=1}^{h_e} x_{e,t}\\right) $$\nThis equation states that the total energy added to the system due to the uniform load increase $L$ must be exactly offset by the total energy discharged by the storage device across all events.\n\nThe next step is to determine the total discharged energy, $\\sum_e (\\sum_t x_{e,t})$. The problem specifies an optimal EUE-minimizing dispatch strategy under perfect foresight for each independent event. For a given event $e$, the device acts to reduce the hourly shortfalls $(d_{e,t} + L)$ as much as possible. The discharge in any hour $t$, $x_{e,t}$, is limited by the device's maximum power output $P$. Therefore, to minimize the remaining deficit, the device will discharge an amount equal to the new deficit, up to its power limit:\n$$ x_{e,t} = \\min\\{P, d_{e,t} + L\\} $$\nThis greedy hourly dispatch is optimal for minimizing EUE within an event because there is no other inter-temporal linkage besides the total energy constraint for that event.\n\nThe total potential energy the device could discharge during event $e$ is the sum of these optimal hourly discharges:\n$$ \\text{Potential Discharge}_e = \\sum_{t=1}^{h_e} \\min\\{P, d_{e,t} + L\\} $$\nHowever, the device is also constrained by its total usable energy capacity, $E$. The actual total energy discharged during event $e$ is therefore the lesser of the potential discharge and the available energy:\n$$ \\sum_{t=1}^{h_e} x_{e,t} = \\min\\left\\{E, \\sum_{t=1}^{h_e} \\min\\{P, d_{e,t} + L\\}\\right\\} $$\n\nSubstituting this expression for the total discharged energy back into our derived relationship gives the final equation for the ELCC, $L$:\n$$ L \\sum_e h_e = \\sum_e \\min\\left\\{E, \\sum_{t=1}^{h_e} \\min\\{P, d_{e,t} + L\\}\\right\\} $$\nThis is a non-linear equation in the single variable $L$, which must be solved numerically.\n\nTo implement an algorithm, we rearrange the equation into a root-finding problem. Let's define a function $f(L)$:\n$$ f(L) = \\left( \\sum_e \\min\\left\\{E, \\sum_{t=1}^{h_e} \\min\\{P, d_{e,t} + L\\}\\right\\} \\right) - L \\sum_e h_e $$\nWe need to find the value of $L \\ge 0$ such that $f(L) = 0$.\n\nThe function $f(L)$ can be shown to be continuous and monotonically non-increasing. The first term, representing total delivered energy, is a sum of piecewise linear, concave, non-decreasing functions of $L$, and its rate of increase with $L$ is bounded above by $\\sum_e h_e$. The second term, $-L \\sum_e h_e$, decreases linearly with a slope of $-\\sum_e h_e$. Consequently, the overall function $f(L)$ is non-increasing. This property makes it well-suited for robust numerical root-finding algorithms like the bisection method or Brent's method.\n\nThe algorithm proceeds as follows:\n$1$. For a given test case (a set of event deficit profiles and a power capacity $P$), define the parameters for the short-duration ($E_{short} = 2P$) and long-duration ($E_{long} = 20P$) storage devices.\n$2$. For each device configuration ($P, E$), solve the equation $f(L)=0$.\n$3$. A numerical solver, such as `scipy.optimize.brentq`, is employed. This requires finding a search interval $[a, b]$ where $f(a)$ and $f(b)$ have opposite signs. A natural lower bound is $a=0$. At $L=0$, the delivered energy is non-negative, so $f(0) \\ge 0$. An upper bound $b$ can be found such that $f(b) < 0$; a value such as $b=P$ or $b=2P$ is typically sufficient, as the ELCC is physically constrained by the device's power rating. If $f(b)$ is not negative, the bound can be iteratively increased until it brackets a root.\n$4$. The root found by the solver is the ELCC value $L$ in megawatts.\n$5$. This procedure is repeated for each test case and for both storage durations. The ratio of the long-duration ELCC to the short-duration ELCC is then computed.\n$6$. The final results, $[L_{\\text{short}}, L_{\\text{long}}, L_{\\text{long}}/L_{\\text{short}}]$, are compiled for all test cases.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef elcc_equation(L, P, E, events, total_h):\n    \"\"\"\n    Represents the function f(L) = 0 to be solved for the ELCC.\n    f(L) = (Total Delivered Energy) - (Total Added Load Energy)\n    \n    Args:\n        L (float): The ELCC value (variable to be solved for).\n        P (float): Power capacity of the storage device (MW).\n        E (float): Energy capacity of the storage device (MWh).\n        events (list of np.ndarray): A list where each element is a NumPy array\n                                     representing the deficit profile of an event (MW).\n        total_h (int): Pre-calculated total duration of all events in hours.\n        \n    Returns:\n        float: The value of the function f(L).\n    \"\"\"\n    total_delivered_energy = 0.0\n    for deficit_profile in events:\n        hourly_discharge = np.minimum(P, deficit_profile + L)\n        potential_event_delivery = np.sum(hourly_discharge)\n        actual_event_delivery = min(E, potential_event_delivery)\n        total_delivered_energy += actual_event_delivery\n        \n    return total_delivered_energy - L * total_h\n\ndef solve_for_case(case):\n    \"\"\"\n    Solves for the ELCC for a single test case with both short- and long-duration storage.\n\n    Args:\n        case (tuple): A tuple containing P (int) and a list of event deficit lists.\n    \n    Returns:\n        list: A list containing [L_short, L_long, ratio].\n    \"\"\"\n    P, event_list = case\n    events = [np.array(d, dtype=float) for d in event_list]\n    total_h = sum(len(d) for d in events)\n    E_short = 2.0 * P\n    E_long = 20.0 * P\n    \n    # --- Solve for short-duration storage ELCC (L_short) ---\n    L_short = 0.0\n    if elcc_equation(0, P, E_short, events, total_h) > 1e-9:\n        a, b = 0.0, float(P) * 2.0 # Set a search bracket [a, b]\n        while elcc_equation(b, P, E_short, events, total_h) > 0:\n            b *= 2.0\n        L_short = brentq(elcc_equation, a, b, args=(P, E_short, events, total_h))\n        \n    # --- Solve for long-duration storage ELCC (L_long) ---\n    L_long = 0.0\n    if elcc_equation(0, P, E_long, events, total_h) > 1e-9:\n        a, b = 0.0, float(P) * 2.0\n        while elcc_equation(b, P, E_long, events, total_h) > 0:\n            b *= 2.0\n        L_long = brentq(elcc_equation, a, b, args=(P, E_long, events, total_h))\n\n    ratio = L_long / L_short if L_short > 1e-9 else 0.0\n    \n    return [L_short, L_long, ratio]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    test_cases = [\n        (100, [\n            [120, 140],\n            [85, 95, 105, 115, 110, 100, 90, 80, 70, 60, 55, 50],\n            [200],\n            [60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60]\n        ]),\n        (100, [\n            [70],\n            [80, 90],\n            [50, 45]\n        ]),\n        (100, [\n            [90, 95, 100, 105, 110, 115, 120, 125, 130, 125, 120, 115, 110, 105, 100],\n            [70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70]\n        ])\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_for_case(case)\n        results.append(result)\n\n    result_strings = [f\"[{res[0]},{res[1]},{res[2]}]\" for res in results]\n    print(f\"[[{results[0][0]},{results[0][1]},{results[0][2]}],[{results[1][0]},{results[1][1]},{results[1][2]}],[{results[2][0]},{results[2][1]},{results[2][2]}]]\")\n\nsolve()\n```"
        }
    ]
}