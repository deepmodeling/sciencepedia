{
    "hands_on_practices": [
        {
            "introduction": "在模型校准中，参数的可辨识性是至关重要的第一步。如果调整一个参数时，模型的输出几乎没有变化，那么从实验数据中准确估计该参数几乎是不可能的。本实践介绍了局部灵敏度分析，它是一种评估参数可辨识性的定量工具。通过计算热泵模型的输出对其参数的偏导数，您将学习如何识别哪些参数在特定操作条件下影响最大，从而最适合进行校准 。",
            "id": "4073866",
            "problem": "一台单级蒸汽压缩热泵在稳态下的特性由一个参数化性能图描述，该图预测了其制热量作为运行工况的函数。设运行工况点向量为 $x_{t} = (T_{h}, T_{c}, f, m)$，其中 $T_{h}$ 是冷凝器制冷剂温度（单位：开尔文），$T_{c}$ 是蒸发器制冷剂温度（单位：开尔文），$f$ 是压缩机电频率（单位：赫兹），$m$ 是制冷剂质量流量（单位：千克/秒）。制热量的模型为\n$$\nf_{\\theta}(x) \\;=\\; \\theta_{1} \\;+\\; \\theta_{2}\\,(T_{h} - T_{c}) \\;+\\; \\theta_{3}\\,\\ln\\!\\left(\\frac{T_{h}}{T_{c}}\\right) \\;+\\; \\theta_{4}\\,\\frac{f}{f + \\theta_{5}} \\;+\\; \\theta_{6}\\,\\exp\\!\\left(-\\frac{\\theta_{7}}{m}\\right),\n$$\n其中 $\\theta = (\\theta_{1}, \\theta_{2}, \\theta_{3}, \\theta_{4}, \\theta_{5}, \\theta_{6}, \\theta_{7})$ 是未知参数向量，$f_{\\theta}(x)$ 以千瓦为单位。假设局部运行工况点为 $T_{h} = 315 \\ \\mathrm{K}$，$T_{c} = 275 \\ \\mathrm{K}$，$f = 50 \\ \\mathrm{Hz}$，以及 $m = 0.10 \\ \\mathrm{kg \\ s^{-1}}$。当前的参数估计值为 $\\theta_{1} = 3.0 \\ \\mathrm{kW}$，$\\theta_{2} = 0.12 \\ \\mathrm{kW \\ K^{-1}}$，$\\theta_{3} = 1.5 \\ \\mathrm{kW}$，$\\theta_{4} = 2.0 \\ \\mathrm{kW}$，$\\theta_{5} = 60 \\ \\mathrm{Hz}$，$\\theta_{6} = 1.2 \\ \\mathrm{kW}$，以及 $\\theta_{7} = 0.05 \\ \\mathrm{kg \\ s^{-1}}$。\n\n从第一性原理出发——即局部灵敏度定义为输出对参数的偏导数，以及在加性测量噪声模型下灵敏度在参数估计中的作用——完成以下任务：\n\n- 计算在运行工况点 $x_{t}$ 处，对于 $i \\in \\{1,2,3,4,5,6,7\\}$ 的局部灵敏度 $\\frac{\\partial f_{\\theta}(x_{t})}{\\partial \\theta_{i}}$。\n- 构造无量纲、参数标度的灵敏度大小\n$$\n\\tilde{s}_{i} \\;=\\; \\left| \\frac{\\partial f_{\\theta}(x_{t})}{\\partial \\theta_{i}} \\cdot \\frac{\\theta_{i}}{f_{\\theta}(x_{t})} \\right|\n$$\n对于 $i \\in \\{1,2,3,4,5,6,7\\}$，然后计算标度化灵敏度向量的无穷范数 $\\|\\tilde{s}\\|_{\\infty} = \\max_{i} \\tilde{s}_{i}$。将最终报告的无穷范数四舍五入到四位有效数字，并以纯数（无量纲）形式表示。\n- 使用高斯测量噪声下的 Fisher 信息矩阵 (FIM) 框架，定性解释这些标度化灵敏度的大小如何指导哪些参数可以在 $x_{t}$ 处被可靠地校准，而哪些参数需要额外的激励或实验设计。\n\n你的最终答案必须是 $\\|\\tilde{s}\\|_{\\infty}$ 的单个数值，四舍五入到四位有效数字，并表示为一个无单位的纯数。",
            "solution": "问题陈述已经过验证，被认为是有效的。它具有科学依据，提法明确，客观，并包含完整解答所需的所有必要信息。没有矛盾、歧义或不可靠的前提。我们可以开始解题。\n\n问题要求进行三部分分析：\n1.  推导和计算热泵模型输出相对于其参数的局部灵敏度。\n2.  计算无量纲、参数标度的灵敏度大小及其无穷范数。\n3.  在 Fisher 信息矩阵 (FIM) 的框架下，定性解释这些灵敏度在参数可辨识性中的作用。\n\n制热量模型 $f_{\\theta}(x)$ 由下式给出：\n$$f_{\\theta}(x) \\;=\\; \\theta_{1} \\;+\\; \\theta_{2}\\,(T_{h} - T_{c}) \\;+\\; \\theta_{3}\\,\\ln\\!\\left(\\frac{T_{h}}{T_{c}}\\right) \\;+\\; \\theta_{4}\\,\\frac{f}{f + \\theta_{5}} \\;+\\; \\theta_{6}\\,\\exp\\!\\left(-\\frac{\\theta_{7}}{m}\\right)$$\n运行工况点为 $x_{t} = (T_{h}, T_{c}, f, m)$，其中 $T_{h} = 315 \\ \\mathrm{K}$，$T_{c} = 275 \\ \\mathrm{K}$，$f = 50 \\ \\mathrm{Hz}$，且 $m = 0.10 \\ \\mathrm{kg \\ s^{-1}}$。\n参数向量为 $\\theta = (\\theta_{1}, \\theta_{2}, \\theta_{3}, \\theta_{4}, \\theta_{5}, \\theta_{6}, \\theta_{7})$，其值为 $\\theta_1 = 3.0 \\ \\mathrm{kW}$，$\\theta_2 = 0.12 \\ \\mathrm{kW \\ K^{-1}}$，$\\theta_3 = 1.5 \\ \\mathrm{kW}$，$\\theta_4 = 2.0 \\ \\mathrm{kW}$，$\\theta_5 = 60 \\ \\mathrm{Hz}$，$\\theta_6 = 1.2 \\ \\mathrm{kW}$，以及 $\\theta_7 = 0.05 \\ \\mathrm{kg \\ s^{-1}}$。\n\n首先，我们计算局部灵敏度，即模型输出 $f_{\\theta}(x)$ 对每个参数 $\\theta_{i}$ 的偏导数，并在给定的运行工况点 $x_t$ 和参数估计值 $\\theta$ 处进行求值。\n\n偏导数如下：\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{1}} = 1 $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{2}} = T_{h} - T_{c} $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{3}} = \\ln\\left(\\frac{T_{h}}{T_{c}}\\right) $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{4}} = \\frac{f}{f + \\theta_{5}} $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{5}} = \\frac{\\partial}{\\partial \\theta_{5}} \\left( \\theta_{4} f (f + \\theta_{5})^{-1} \\right) = - \\frac{\\theta_{4} f}{(f + \\theta_{5})^{2}} $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{6}} = \\exp\\left(-\\frac{\\theta_{7}}{m}\\right) $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{7}} = \\frac{\\partial}{\\partial \\theta_{7}} \\left( \\theta_{6} \\exp\\left(-\\frac{\\theta_{7}}{m}\\right) \\right) = \\theta_{6} \\exp\\left(-\\frac{\\theta_{7}}{m}\\right) \\left(-\\frac{1}{m}\\right) = -\\frac{\\theta_{6}}{m} \\exp\\left(-\\frac{\\theta_{7}}{m}\\right) $$\n\n接下来，我们在指定点计算这些导数的值：\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{1}} = 1 $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{2}} = 315 - 275 = 40 $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{3}} = \\ln\\left(\\frac{315}{275}\\right) \\approx 0.135760 $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{4}} = \\frac{50}{50 + 60} = \\frac{50}{110} = \\frac{5}{11} \\approx 0.454545 $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{5}} = - \\frac{2.0 \\cdot 50}{(50 + 60)^{2}} = - \\frac{100}{110^{2}} = - \\frac{100}{12100} = -\\frac{1}{121} \\approx -0.00826446 $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{6}} = \\exp\\left(-\\frac{0.05}{0.10}\\right) = \\exp(-0.5) \\approx 0.606531 $$\n$$ \\frac{\\partial f_{\\theta}}{\\partial \\theta_{7}} = -\\frac{1.2}{0.10} \\exp(-0.5) = -12 \\exp(-0.5) \\approx -7.278368 $$\n\n为了计算无量纲、标度化灵敏度 $\\tilde{s}_{i}$，我们首先需要模型输出值 $f_{\\theta}(x_t)$：\n$$ f_{\\theta}(x_t) = 3.0 + 0.12(315 - 275) + 1.5\\ln\\left(\\frac{315}{275}\\right) + 2.0\\left(\\frac{50}{50+60}\\right) + 1.2\\exp\\left(-\\frac{0.05}{0.1}\\right) $$\n$$ f_{\\theta}(x_t) \\approx 3.0 + 0.12(40) + 1.5(0.135760) + 2.0(0.454545) + 1.2(0.606531) $$\n$$ f_{\\theta}(x_t) \\approx 3.0 + 4.8 + 0.203640 + 0.909091 + 0.727837 $$\n$$ f_{\\theta}(x_t) \\approx 9.640568 \\ \\mathrm{kW} $$\n\n现在，我们计算每个标度化灵敏度 $\\tilde{s}_{i} = \\left| \\frac{\\partial f_{\\theta}(x_{t})}{\\partial \\theta_{i}} \\cdot \\frac{\\theta_{i}}{f_{\\theta}(x_{t})} \\right|$：\n$$ \\tilde{s}_{1} = \\left| 1 \\cdot \\frac{3.0}{9.640568} \\right| \\approx 0.311183 $$\n$$ \\tilde{s}_{2} = \\left| 40 \\cdot \\frac{0.12}{9.640568} \\right| = \\left| \\frac{4.8}{9.640568} \\right| \\approx 0.497893 $$\n$$ \\tilde{s}_{3} = \\left| 0.135760 \\cdot \\frac{1.5}{9.640568} \\right| \\approx 0.021123 $$\n$$ \\tilde{s}_{4} = \\left| \\frac{5}{11} \\cdot \\frac{2.0}{9.640568} \\right| \\approx 0.094298 $$\n$$ \\tilde{s}_{5} = \\left| -\\frac{1}{121} \\cdot \\frac{60}{9.640568} \\right| \\approx |-0.00826446 \\cdot 6.22361| \\approx 0.051435 $$\n$$ \\tilde{s}_{6} = \\left| \\exp(-0.5) \\cdot \\frac{1.2}{9.640568} \\right| \\approx |0.606531 \\cdot 0.124474| \\approx 0.075498 $$\n$$ \\tilde{s}_{7} = \\left| -12 \\exp(-0.5) \\cdot \\frac{0.05}{9.640568} \\right| \\approx |-7.278368 \\cdot 0.0051864| \\approx 0.037749 $$\n\n标度化灵敏度大小的向量为 $\\tilde{s} \\approx (0.3112, 0.4979, 0.0211, 0.0943, 0.0514, 0.0755, 0.0377)$。\n该向量的无穷范数是其分量中的最大值：\n$$ \\|\\tilde{s}\\|_{\\infty} = \\max_{i} \\tilde{s}_{i} = \\max\\{0.311183, 0.497893, 0.021123, 0.094298, 0.051435, 0.075498, 0.037749\\} $$\n$$ \\|\\tilde{s}\\|_{\\infty} = \\tilde{s}_{2} \\approx 0.497893 $$\n四舍五入到四位有效数字，我们得到 $\\|\\tilde{s}\\|_{\\infty} = 0.4979$。\n\n最后，我们讨论这些灵敏度的定性作用。该框架始于一个制热量测量的加性噪声模型，$y_t = f_{\\theta}(x_t) + \\epsilon_t$，其中 $\\epsilon_t$ 通常被假设为独立同分布 (i.i.d.) 的高斯噪声，均值为零，方差为 $\\sigma^2$，即 $\\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$。\nFisher 信息矩阵 (FIM) 是参数估计理论中的一个基本概念。对于单个数据点 $y_t$，其元素由下式给出：\n$$ \\mathcal{I}_{ij}(\\theta) = \\frac{1}{\\sigma^2} \\frac{\\partial f_{\\theta}(x_t)}{\\partial \\theta_i} \\frac{\\partial f_{\\theta}(x_t)}{\\partial \\theta_j} $$\nFIM 的重要性源于 Cramér-Rao 下界 (CRLB)，该下界指出任何无偏估计量 $\\hat{\\theta}$ 的方差都有一个由 FIM 的逆矩阵决定的下界：$\\mathrm{Cov}(\\hat{\\theta}) \\ge \\mathcal{I}(\\theta)^{-1}$。这意味着 FIM 的对角元素 $\\mathcal{I}_{ii}(\\theta) = \\frac{1}{\\sigma^2} \\left(\\frac{\\partial f_{\\theta}(x_t)}{\\partial \\theta_i}\\right)^2$ 与参数 $\\theta_i$ 估计值的最小可达方差成反比。较大的 $\\mathcal{I}_{ii}(\\theta)$ 值对应于较小的方差界，表明 $\\theta_i$ 可以被高精度地估计。\n\n局部灵敏度 $\\frac{\\partial f_{\\theta}(x_t)}{\\partial \\theta_i}$ 直接决定了这些 FIM 对角元素的大小。较大的灵敏度大小意味着参数 $\\theta_i$ 的微小变化会引起模型输出的较大变化，使其效应更容易与测量噪声区分开来。无量纲标度化灵敏度 $\\tilde{s}_i$ 允许在具有不同单位和量级的参数之间进行公平比较。它表示参数变化百分之一时，输出变化的百分比。\n\n在本分析中：\n- 参数 $\\theta_2$ ($\\tilde{s}_2 \\approx 0.498$) 和 $\\theta_1$ ($\\tilde{s}_1 \\approx 0.311$) 表现出最高的标度化灵敏度。这表明在运行工况点 $x_t$，模型输出对温差系数和基线偏移量的变化最为敏感。因此，在 $x_t$ 或其附近收集的数据对于校准 $\\theta_1$ 和 $\\theta_2$ 来说信息量最大。\n- 具有低标度化灵敏度的参数，例如 $\\theta_3$ ($\\tilde{s}_3 \\approx 0.021$)、$\\theta_7$ ($\\tilde{s}_7 \\approx 0.038$) 和 $\\theta_5$ ($\\tilde{s}_5 \\approx 0.051$)，在此特定运行工况点对输出的影响很小。仅使用来自该工况的数据来估计这些参数是不可靠的；它们的效应将难以从系统噪声中分离出来，导致其估计值具有较大的方差（即较大的 CRLB）以及与其他参数估计值的高度相关性。FIM 将会是病态的。\n- 为了可靠地校准这些灵敏度较低的参数，必须进行实验设计。这涉及到选择额外的运行工况点 ($x_t$)，以专门“激励”模型对这些参数的灵敏度。例如，为了提高 $\\theta_3$ 的可辨识性，需要进行具有更宽温度比 $T_h/T_c$ 范围的实验。为了辨识 $\\theta_5$，应改变压缩机频率 $f$，尤其是在当前估计值 $60 \\ \\mathrm{Hz}$ 附近。对于 $\\theta_7$，改变质量流量 $m$ 至关重要。这种选择信息丰富实验的过程被称为优化实验设计，其目的在于最大化数据的信息含量，通常通过最大化 FIM 的某个标量度量（例如其行列式）来实现。",
            "answer": "$$\\boxed{0.4979}$$"
        },
        {
            "introduction": "一旦我们确定一个参数是可辨识的，校准的核心任务就是找到其最佳拟合值，并量化我们对该估计的信心。这个过程常常因为模型中存在其他未知的“滋扰”参数而变得复杂。本练习将指导您使用剖面似然法（profile likelihood method），这是一种强大的频率派技术，用于在考虑滋扰参数的同时估计目标参数。您将把这种方法应用于一个热模型，不仅确定传热系数的最可能值，还为其构建一个统计上严谨的置信区间 。",
            "id": "4073888",
            "problem": "考虑一个集总参数能量系统中对流传热系数的校准。一个具有已知表面积和热容的刚体与处于已知恒定温度的环境空气进行热交换。该模型的基本依据是牛顿冷却定律和一个高斯观测模型。假设热平衡由应用于集总参数模型的牛顿冷却定律给出：\n$$\nC \\frac{dT(t)}{dt} = -h A \\left(T(t) - T_{\\infty}\\right),\n$$\n其中，$T(t)$ 是物体在时间 $t$ 的真实温度，$h$ 是对流传热系数，$A$ 是表面积，$C$ 是热容，$T_{\\infty}$ 是环境温度。$t=0$ 时的初始温度为 $T(0)=T_0$。这个一阶常微分方程的解给出了一个向 $T_{\\infty}$ 指数衰减的温度轨迹。\n\n观测值被建模为独立同分布 (IID) 的高斯测量：\n$$\ny_i = T(t_i; h, T_0) + \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2),\n$$\n对于 $i=1,\\dots,n$，其中 $t_i$ 是已知的采样时间，$y_i$ 是观测到的温度，$\\sigma^2$ 是一个未知的测量噪声方差。我们感兴趣的参数是 $h$，而 $T_0$ 和 $\\sigma^2$ 是讨厌参数。使用最大似然估计 (MLE) 原理，通过对每个固定的 $h$ 在讨厌参数 $(T_0, \\sigma^2)$ 上最大化似然函数来构建 $h$ 的剖面似然。然后，基于渐近似然比，计算 $h$ 的一个近似双边 95% 置信区间。\n\n你的程序必须：\n- 实现由常微分方程所蕴含的正向模型，以计算 $T(t; h, T_0)$。\n- 对于每个固定的 $h$，解析地或数值地在 $T_0$ 和 $\\sigma^2$ 上最大化似然函数，以构建 $h$ 的剖面对数似然。\n- 通过在 $\\text{W}/(\\text{m}^2\\cdot\\text{K})$ 中一个物理上合理的 $h$ 区间上最大化剖面对数似然，来计算最大似然估计值 $\\hat{h}$。\n- 使用剖面似然比和自由度为 1 的卡方分布来确定 $h$ 的近似 95% 置信区间的端点，单位为 $\\text{W}/(\\text{m}^2\\cdot\\text{K})$。\n- 将所有与 $h$ 相关的输出以 $\\text{W}/(\\text{m}^2\\cdot\\text{K})$ 为单位表示为小数，并四舍五入到小数点后恰好 6 位。\n\n测试套件：\n对于所有情况，环境温度为 $T_{\\infty} = 293$ 开尔文，热容为 $C = 2000$ 焦耳每开尔文，表面积为 $A = 0.5$ 平方米。观测值是通过使用指定的真实参数根据模型模拟 $y_i$ 生成，然后添加具有给定标准差的高斯噪声 $\\varepsilon_i$。使用以下情况，其中种子引用一个固定的伪随机数生成器初始化：\n\n- 情况 1 (理想路径，中等冷却)：$T_0 = 353$，$h_{\\text{true}} = 15$，时间 $t_i$ 从 0 到 1800 秒，步长为 60，噪声标准差为 0.5 开尔文，种子为 1。\n- 情况 2 (缓慢冷却，有限动态)：$T_0 = 298$，$h_{\\text{true}} = 2$，时间 $t_i$ 从 0 到 1800 秒，步长为 120，噪声标准差为 0.5 开尔文，种子为 2。\n- 情况 3 (快速冷却，短观测窗口)：$T_0 = 353$，$h_{\\text{true}} = 100$，时间 $t_i$ 从 0 到 180 秒，步长为 10，噪声标准差为 0.5 开尔文，种子为 3。\n- 情况 4 (高噪声测量)：$T_0 = 333$，$h_{\\text{true}} = 20$，时间 $t_i$ 从 0 到 1200 秒，步长为 60，噪声标准差为 2.0 开尔文，种子为 4。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。对于每种情况，输出三元组 $[\\hat{h}, h_{\\text{low}}, h_{\\text{high}}]$，其中 $\\hat{h}$ 是最大似然估计值，$h_{\\text{low}}$ 和 $h_{\\text{high}}$ 是 $h$ 的近似双边 95% 置信区间的下界和上界。按照情况的顺序将这些聚合到一个扁平列表中，并格式化为小数点后六位，例如：\n$$\n[\\hat{h}_1, h_{\\text{low},1}, h_{\\text{high},1}, \\hat{h}_2, h_{\\text{low},2}, h_{\\text{high},2}, \\hat{h}_3, h_{\\text{low},3}, h_{\\text{high},3}, \\hat{h}_4, h_{\\text{low},4}, h_{\\text{high},4}].\n$$\n所有的 $h$ 值和区间端点都必须以 $\\text{W}/(\\text{m}^2\\cdot\\text{K})$ 为单位，并打印为小数点后恰好六位。不涉及角度。不得使用百分比；所有置信水平都必须通过数值界限隐式地表达。无需用户输入；所有数据都应由程序使用指定的种子在内部生成。",
            "solution": "该问题要求从一个冷却体的带噪声温度测量值中估计对流传热系数 $h$。我们将确定 $h$ 的最大似然估计 (MLE) 并使用剖面似然法构建一个近似的 95% 置信区间。该过程包括几个步骤：推导物理模型，构建统计似然函数，剖析掉讨厌参数，以及应用渐近似然理论。\n\n**1. 物理模型：牛顿冷却定律**\n\n该系统由集总参数热平衡控制，由以下一阶常微分方程 (ODE) 描述：\n$$\nC \\frac{dT(t)}{dt} = -h A \\left(T(t) - T_{\\infty}\\right)\n$$\n其中 $T(t)$ 是物体在时间 $t$ 的温度，$C$ 是其热容，$A$ 是其表面积，$h$ 是对流传热系数，$T_{\\infty}$ 是恒定的环境温度。初始条件是 $T(0) = T_0$。\n\n这个线性常微分方程可以通过分离变量法求解。令 $\\theta(t) = T(t) - T_{\\infty}$。方程变为 $C \\frac{d\\theta}{dt} = -hA\\theta$。积分得到：\n$$\n\\int \\frac{d\\theta}{\\theta} = -\\int \\frac{hA}{C} dt \\implies \\ln(\\theta) = -\\frac{hA}{C}t + K\n$$\n其中 $K$ 是积分常数。取指数得到 $\\theta(t) = e^K e^{-\\frac{hA}{C}t}$。使用初始条件 $\\theta(0) = T(0) - T_{\\infty} = T_0 - T_{\\infty}$，我们找到常数 $e^K = T_0 - T_{\\infty}$。将 $\\theta(t)$ 代回，我们得到温度轨迹的正向模型：\n$$\nT(t; h, T_0) = T_{\\infty} + (T_0 - T_{\\infty}) e^{-\\frac{hA}{C}t}\n$$\n对于给定的参数 $h$ 和 $T_0$，此函数预测在任何时间 $t$ 的真实温度。\n\n**2. 统计模型与似然函数**\n\n在已知时间 $\\{t_i\\}_{i=1}^n$ 的温度观测值 $\\{y_i\\}_{i=1}^n$ 被建模为真实温度加上独立同分布 (IID) 的高斯噪声：\n$$\ny_i = T(t_i; h, T_0) + \\varepsilon_i, \\quad \\text{where} \\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\n$$\n完整模型的参数是 $\\theta = (h, T_0, \\sigma^2)$。单个观测值 $y_i$ 的概率密度是：\n$$\np(y_i | h, T_0, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - T(t_i; h, T_0))^2}{2\\sigma^2}\\right)\n$$\n由于 IID 假设，所有观测值 $\\mathbf{y}=(y_1, \\dots, y_n)$ 的联合似然是各个密度的乘积：\n$$\nL(h, T_0, \\sigma^2 | \\mathbf{y}) = \\prod_{i=1}^n p(y_i | h, T_0, \\sigma^2) = (2\\pi\\sigma^2)^{-n/2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - T(t_i; h, T_0))^2\\right)\n$$\n为了最大化，使用对数似然函数更为方便：\n$$\n\\ell(h, T_0, \\sigma^2 | \\mathbf{y}) = -\\frac{n}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - T(t_i; h, T_0))^2\n$$\n\n**3. $h$ 的剖面似然**\n\n我们感兴趣的参数是 $h$，而 $T_0$ 和 $\\sigma^2$ 是讨厌参数。我们通过对每个固定的 $h$ 值在讨厌参数上最大化 $\\ell$ 来构建 $h$ 的剖面对数似然：\n$$\n\\ell_p(h) = \\max_{T_0, \\sigma^2} \\ell(h, T_0, \\sigma^2 | \\mathbf{y})\n$$\n这个最大化过程分两步进行。\n\n首先，对于固定的 $h$ 和 $T_0$，我们对 $\\sigma^2$ 进行最大化。令 $S(h, T_0) = \\sum_{i=1}^n (y_i - T(t_i; h, T_0))^2$ 为残差平方和。\n$$\n\\frac{\\partial \\ell}{\\partial \\sigma^2} = -\\frac{n}{2\\sigma^2} + \\frac{S(h, T_0)}{2(\\sigma^2)^2} = 0 \\implies \\hat{\\sigma}^2(h, T_0) = \\frac{S(h, T_0)}{n}\n$$\n将 $\\hat{\\sigma}^2$ 代回 $\\ell$ 中，得到集中对数似然 (在 $\\sigma^2$ 上剖析后)：\n$$\n\\ell_c(h, T_0) = -\\frac{n}{2}(\\ln(2\\pi) + 1) - \\frac{n}{2}\\ln\\left(\\frac{S(h, T_0)}{n}\\right)\n$$\n对 $T_0$ 最大化 $\\ell_c(h, T_0)$ 等价于最小化残差平方和 $S(h, T_0)$。\n\n其次，对于一个固定的 $h$，我们找到使 $S(h, T_0)$ 最小化的 $T_0$ 值。模型 $T(t; h, T_0)$ 对 $T_0$ 是线性的。令 $\\beta = \\frac{hA}{C}$ 且 $E_i = e^{-\\beta t_i}$。模型可以写为 $T(t_i) = T_{\\infty} + (T_0 - T_{\\infty})E_i = T_0 E_i + T_{\\infty}(1-E_i)$。\n最小化 $S(h, T_0) = \\sum_{i=1}^n (y_i - (T_0 E_i + T_{\\infty}(1-E_i)))^2$ 是一个关于 $T_0$ 的线性最小二乘问题。将偏导数 $\\frac{\\partial S}{\\partial T_0}$ 设为零，可以得到给定 $h$ 时 $T_0$ 的最大似然估计的解析解：\n$$\n\\hat{T_0}(h) = \\frac{\\sum_{i=1}^n (y_i - T_{\\infty}(1-E_i))E_i}{\\sum_{i=1}^n E_i^2}\n$$\n通过将 $\\hat{T_0}(h)$ 代入 $S(h, T_0)$，我们得到 $S(h, \\hat{T_0}(h))$，然后可以用它来计算剖面对数似然 $\\ell_p(h)$。$h$ 的最大似然估计值，记作 $\\hat{h}$，是使 $\\ell_p(h)$ 最大化的值，这等价于最小化 $S(h, \\hat{T_0}(h))$：\n$$\n\\hat{h} = \\underset{h}{\\arg\\max} \\, \\ell_p(h) = \\underset{h}{\\arg\\min} \\, S(h, \\hat{T_0}(h))\n$$\n由于这个目标函数对 $h$ 是非线性的，$\\hat{h}$ 必须通过数值优化来找到。\n\n**4. 近似置信区间**\n\n根据 Wilks' 定理，可以使用似然比检验统计量构建 $h$ 的一个近似 $(1-\\alpha)$ 置信区间。统计量 $W(h) = 2(\\ell_p(\\hat{h}) - \\ell_p(h))$ 渐近服从自由度为 1 的卡方分布 ($\\chi^2_1$)，因为只有一个参数 ($h$) 受到约束。\n\n$h$ 的 95% 置信区间是检验不拒绝原假设 $H_0: h = h_{test}$ 的所有值的集合，即满足以下条件的 $h$ 的集合：\n$$\n2(\\ell_p(\\hat{h}) - \\ell_p(h)) \\le \\chi^2_{1, 0.95}\n$$\n其中 $\\chi^2_{1, 0.95} \\approx 3.841$ 是 $\\chi^2_1$ 分布的第 95 百分位数。置信区间的端点是以下方程的解：\n$$\n\\ell_p(h) = \\ell_p(\\hat{h}) - \\frac{\\chi^2_{1, 0.95}}{2}\n$$\n将用残差平方和表示的 $\\ell_p(h)$ 的表达式代入，该方程可以被简化以增强数值稳定性。\n$$\n-\\frac{n}{2}\\ln\\left(\\frac{S(h, \\hat{T_0}(h))}{n}\\right) = -\\frac{n}{2}\\ln\\left(\\frac{S(\\hat{h}, \\hat{T_0}(\\hat{h}))}{n}\\right) - \\frac{\\chi^2_{1, 0.95}}{2}\n$$\n$$\n\\ln(S(h, \\hat{T_0}(h))) = \\ln(S(\\hat{h}, \\hat{T_0}(\\hat{h}))) + \\frac{\\chi^2_{1, 0.95}}{n}\n$$\n$$\nS(h, \\hat{T_0}(h)) = S(\\hat{h}, \\hat{T_0}(\\hat{h})) \\cdot \\exp\\left(\\frac{\\chi^2_{1, 0.95}}{n}\\right)\n$$\n该方程的两个根 $h_{\\text{low}}$ 和 $h_{\\text{high}}$ 构成了置信区间的下界和上界。这些根必须使用求根算法进行数值求解。对 $h_{\\text{low}}$ 的搜索在区间 $(0, \\hat{h})$ 中进行，对 $h_{\\text{high}}$ 的搜索在 $(\\hat{h}, \\infty)$ 中进行。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize_scalar, brentq\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Performs Maximum Likelihood Estimation to find the convective heat transfer\n    coefficient 'h' and its 95% confidence interval using profile likelihood.\n    \"\"\"\n    # Global constants for the physical model\n    T_INF = 293.0  # Ambient temperature in Kelvin\n    C = 2000.0     # Thermal capacitance in J/K\n    A = 0.5        # Surface area in m^2\n\n    # Test suite definition\n    test_cases = [\n        # (T0_true, h_true, t_start, t_end, t_step, sigma, seed)\n        (353.0, 15.0, 0, 1800, 60, 0.5, 1),\n        (298.0, 2.0, 0, 1800, 120, 0.5, 2),\n        (353.0, 100.0, 0, 180, 10, 0.5, 3),\n        (333.0, 20.0, 0, 1200, 60, 2.0, 4),\n    ]\n\n    all_results = []\n    \n    # Critical value for 95% CI from chi-square distribution with 1 df\n    crit_val = chi2.ppf(0.95, df=1)\n\n    for T0_true, h_true, t_start, t_end, t_step, sigma, seed in test_cases:\n        # 1. Generate synthetic observation data\n        ts = np.arange(t_start, t_end + 1e-9, t_step) # Use a small epsilon to ensure endpoint inclusion\n        n = len(ts)\n        rng = np.random.default_rng(seed=seed)\n\n        beta_true = h_true * A / C\n        T_model_true = T_INF + (T0_true - T_INF) * np.exp(-beta_true * ts)\n        ys = T_model_true + rng.normal(loc=0.0, scale=sigma, size=n)\n\n        # 2. Define the objective function for minimization\n        # This function computes the sum of squared residuals S(h, T0_hat(h)) for a given h.\n        def get_sum_sq_for_h(h, times, y_obs, cap, area, T_amb):\n            if h = 0:\n                return np.inf\n\n            beta = h * area / cap\n            E = np.exp(-beta * times)\n            \n            # Analytically find the MLE for T0 given h\n            numerator_T0 = np.sum((y_obs - T_amb * (1 - E)) * E)\n            denominator_T0 = np.sum(E**2)\n            \n            # Avoid division by zero for very large h where E is almost zero.\n            if denominator_T0  1e-15:\n                T0_hat = y_obs[0]\n            else:\n                T0_hat = numerator_T0 / denominator_T0\n\n            # Calculate predicted temperatures and sum of squared residuals\n            T_pred = T_amb + (T0_hat - T_amb) * E\n            ssq = np.sum((y_obs - T_pred)**2)\n            return ssq\n\n        # 3. Find h_hat (MLE for h) by minimizing the sum of squares\n        h_search_bounds = (0.01, 500.0)\n        opt_result = minimize_scalar(\n            get_sum_sq_for_h,\n            args=(ts, ys, C, A, T_INF),\n            bounds=h_search_bounds,\n            method='bounded'\n        )\n        h_hat = opt_result.x\n        ssq_min = opt_result.fun\n\n        # 4. Compute the confidence interval using the likelihood ratio test\n        # The endpoints are roots of S(h) = S(h_hat) * exp(chi^2_crit / n)\n        ssq_target = ssq_min * np.exp(crit_val / n)\n\n        def ci_root_function(h, times, y_obs, cap, area, T_amb, target):\n            return get_sum_sq_for_h(h, times, y_obs, cap, area, T_amb) - target\n        \n        # Find lower bound of the CI\n        try:\n            h_low = brentq(\n                ci_root_function,\n                a=h_search_bounds[0],\n                b=h_hat,\n                args=(ts, ys, C, A, T_INF, ssq_target)\n            )\n        except ValueError:\n            h_low = np.nan # Should not happen with well-behaved data\n\n        # Find upper bound of the CI\n        try:\n            h_high = brentq(\n                ci_root_function,\n                a=h_hat,\n                b=h_search_bounds[1],\n                args=(ts, ys, C, A, T_INF, ssq_target)\n            )\n        except ValueError:\n            h_high = np.nan\n\n        all_results.extend([h_hat, h_low, h_high])\n\n    # Format the final output as a comma-separated list of strings\n    formatted_results = [f\"{x:.6f}\" for x in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "校准动态模型，特别是那些经过多个时间步模拟的模型，通常需要使用基于梯度的优化方法来最小化成本函数。如何高效地计算这个梯度是一个重大的计算挑战。本实践介绍了离散伴随法（discrete adjoint method），这是一种先进的技术，其计算成本与参数数量无关，能够高效地计算梯度。您将为一个储能模型实施该方法，并验证其准确性，从而掌握一项对于校准大规模能源系统至关重要的工具 。",
            "id": "4073858",
            "problem": "考虑一个源于能量守恒的单状态、时间步长的储能模型。设 $x_t$ 表示在离散时间索引 $t$ 的充电状态（单位：兆瓦时，MWh），设 $u_t$ 表示净充电功率输入（单位：兆瓦，MW），设 $\\Delta t$ 表示时间步长（单位：小时）。该储能系统存在自放电现象，由参数 $\\theta$ 建模，其单位为每小时（$\\mathrm{h}^{-1}$）。离散时间动态由能量平衡定义\n$$\nx_{t+1} = x_t + \\Delta t \\, \\big(-\\theta \\, x_t + u_t\\big),\n$$\n并给定初始条件 $x_0$。为了在能源系统建模中校准模型参数，考虑一个跟踪目标，即充电状态跟踪参考曲线 $r_t$，带有非负权重 $w_t$ 和对 $\\theta$ 的二次正则化项：\n$$\nJ(\\theta) = \\frac{1}{2} \\sum_{t=0}^{T} w_t \\, \\big(x_t - r_t\\big)^2 \\, \\Delta t \\;+\\; \\frac{1}{2} \\, \\alpha \\, \\theta^2.\n$$\n任务是为时间步长模拟器实现一种离散伴随方法，以计算梯度 $\\frac{dJ}{d\\theta}$，并通过与 $\\frac{dJ}{d\\theta}$ 的中心有限差分近似进行比较来验证其准确性。\n\n您的程序必须：\n- 针对给定的 $(T, \\Delta t, x_0, \\theta, \\{u_t\\}_{t=0}^{T-1}, \\{r_t\\}_{t=0}^{T}, \\{w_t\\}_{t=0}^{T}, \\alpha)$ 模拟正向动态。\n- 实现模拟器的离散伴随方法以获得 $\\frac{dJ}{d\\theta}$。\n- 实现带有扰动 $\\varepsilon$ 的中心有限差分近似：\n$$\n\\frac{dJ}{d\\theta} \\approx \\frac{J(\\theta + \\varepsilon) - J(\\theta - \\varepsilon)}{2 \\varepsilon}.\n$$\n- 使用相对误差准则比较伴随梯度和有限差分梯度。定义绝对差 $d = \\big|\\big(\\frac{dJ}{d\\theta}\\big)_{\\mathrm{adj}} - \\big(\\frac{dJ}{d\\theta}\\big)_{\\mathrm{fd}}\\big|$ 并检查是否满足 $d \\le \\max\\big(\\tau_{\\mathrm{abs}}, \\tau_{\\mathrm{rel}} \\cdot \\max(1, \\big|\\big(\\frac{dJ}{d\\theta}\\big)_{\\mathrm{fd}}\\big|)\\big)$。\n\n单位和数值要求：\n- 将 $x_t$ 的单位解释为 MWh，$u_t$ 为 MW，$\\Delta t$ 为小时，$\\theta$ 为每小时（$\\mathrm{h}^{-1}$）。\n- 在最终输出中，将关于 $\\theta$ 的梯度值以每小时（$\\mathrm{h}^{-1}$）为单位，表示为纯数字浮点数。\n- 角度（若有）必须以弧度为单位；提供的测试套件不使用角度。\n- 百分比（若有）必须表示为小数；提供的测试套件不使用百分比。\n\n使用以下参数值测试套件来检验模型和伴随方法的不同运行机制：\n- 测试用例 A（一般情况）：\n  - $T = 48$, $\\Delta t = 1.0$, $x_0 = 1.0$, $\\theta = 0.02$, $\\alpha = 0.01$。\n  - 对于 $t = 0, 1, \\dots, T-1$，定义 $u_t = 0.5 \\cdot \\sin\\!\\big(\\frac{2\\pi t}{24}\\big) + 0.1$。\n  - 对于 $t = 0, 1, \\dots, T$，定义 $r_t = 1.0$ 和 $w_t = 1.0$。\n  - 使用 $\\varepsilon = 10^{-6}$, $\\tau_{\\mathrm{abs}} = 10^{-9}$, $\\tau_{\\mathrm{rel}} = 10^{-6}$。\n- 测试用例 B（接近零自放电的边界情况）：\n  - $T = 24$, $\\Delta t = 1.0$, $x_0 = 0.0$, $\\theta = 0.0$, $\\alpha = 0.0$。\n  - 对于 $t = 0, 1, \\dots, 11$，定义 $u_t = 0.1$，对于 $t = 12, 13, \\dots, 23$，定义 $u_t = -0.1$。\n  - 对于 $t = 0, 1, \\dots, T$，定义 $r_t = 0.0$ 和 $w_t = 1.5$。\n  - 使用 $\\varepsilon = 10^{-6}$, $\\tau_{\\mathrm{abs}} = 10^{-9}$, $\\tau_{\\mathrm{rel}} = 10^{-6}$。\n- 测试用例 C（具有较大自放电和非均匀权重的单步边缘情况）：\n  - $T = 1$, $\\Delta t = 2.0$, $x_0 = 0.0$, $\\theta = 0.5$, $\\alpha = 0.1$。\n  - 对于 $t = 0$，定义 $u_t = 1.0$。\n  - 对于 $t = 0, 1$，定义 $r_t = 1.0$，以及 $w_0 = 0.5$, $w_1 = 2.0$。\n  - 使用 $\\varepsilon = 10^{-6}$, $\\tau_{\\mathrm{abs}} = 10^{-9}$, $\\tau_{\\mathrm{rel}} = 10^{-6}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表。对于每个测试用例，记录有限差分梯度、伴随梯度和准确性检查的布尔结果。最终输出必须为以下形式\n$$\n[\\;g_{\\mathrm{fd},A},\\;g_{\\mathrm{adj},A},\\;\\text{ok}_A,\\;g_{\\mathrm{fd},B},\\;g_{\\mathrm{adj},B},\\;\\text{ok}_B,\\;g_{\\mathrm{fd},C},\\;g_{\\mathrm{adj},C},\\;\\text{ok}_C\\;],\n$$\n其中每个 $g_{\\mathrm{fd},\\cdot}$ 和 $g_{\\mathrm{adj},\\cdot}$ 是一个浮点数，每个 $\\text{ok}_{\\cdot}$ 是一个布尔值。",
            "solution": "所提出的问题是有效的。这是计算科学中一个明确定义的任务，其基础是最优控制和离散时间系统灵敏度分析的原理。所有必要的数据和条件都已提供，该问题在科学上和数学上都是合理的。\n\n问题的核心是，对于一个由离散时间动态控制的系统，计算标量目标函数 $J(\\theta)$ 关于模型参数 $\\theta$ 的梯度。这是动态模型参数估计、校准和优化中的一个常见要求。离散伴随方法是实现此目的的一种高效而优雅的技术，特别是对于具有许多时间步长的系统，因为其计算成本在很大程度上与参数数量无关。\n\n储能模型由状态转移方程描述：\n$$x_{t+1} = x_t + \\Delta t \\, \\big(-\\theta \\, x_t + u_t\\big) = (1 - \\Delta t \\, \\theta) x_t + \\Delta t \\, u_t$$\n其中 $x_t$ 是时间步长 $t$ 时的充电状态，$u_t$ 是净功率输入，$\\theta$ 是自放电率参数，$\\Delta t$ 是时间步长的持续时间。模拟从 $t=0$ 运行到 $t=T$，从给定的初始状态 $x_0$ 开始。\n\n要最小化的目标函数是一个二次代价函数，它惩罚状态轨迹 $\\{x_t\\}$ 与参考轨迹 $\\{r_t\\}$ 的偏差，并包含一个关于参数 $\\theta$ 的正则化项：\n$$J(\\theta) = \\frac{1}{2} \\sum_{t=0}^{T} w_t \\, \\big(x_t - r_t\\big)^2 \\, \\Delta t \\;+\\; \\frac{1}{2} \\, \\alpha \\, \\theta^2$$\n此处，$w_t$ 是非负权重，$\\alpha$ 是正则化系数。\n\n为了使用离散伴随方法计算梯度 $\\frac{dJ}{d\\theta}$，我们引入一个拉格朗日函数 $\\mathcal{L}$，它通过一系列拉格朗日乘子（或称伴随变量）$\\{\\lambda_t\\}$ 加权的系统动态来增广目标函数：\n$$ \\mathcal{L} = J(\\theta) + \\sum_{t=0}^{T-1} \\lambda_{t+1} \\left[ (1 - \\Delta t \\, \\theta) x_t + \\Delta t \\, u_t - x_{t+1} \\right] $$\n根据构造，对于任何满足系统动态的轨迹，$\\mathcal{L} = J(\\theta)$。因此，$J$ 关于 $\\theta$ 的全导数等于 $\\mathcal{L}$ 的全导数。应用链式法则，我们有：\n$$ \\frac{dJ}{d\\theta} = \\frac{d\\mathcal{L}}{d\\theta} = \\frac{\\partial \\mathcal{L}}{\\partial \\theta} + \\sum_{t=1}^{T} \\frac{\\partial \\mathcal{L}}{\\partial x_t} \\frac{dx_t}{d\\theta} $$\n初始状态 $x_0$ 是给定的，不依赖于 $\\theta$，所以 $\\frac{dx_0}{d\\theta} = 0$。根据状态轨迹的定义，项 $\\frac{\\partial\\mathcal{L}}{\\partial\\lambda_t}$ 为零。\n\n伴随方法的核心是选择乘子序列 $\\{\\lambda_t\\}$ 以消除包含状态灵敏度 $\\frac{dx_t}{d\\theta}$ 的项。这通过将拉格朗日函数关于状态 $x_t$（对于 $t=1, \\dots, T$）的偏导数设为零来实现。\n$$ \\frac{\\partial \\mathcal{L}}{\\partial x_t} = 0 \\quad \\text{for } t=1, \\dots, T $$\n让我们计算这些偏导数。对于终端状态 $x_T$：\n$$ \\frac{\\partial \\mathcal{L}}{\\partial x_T} = w_T(x_T - r_T)\\Delta t - \\lambda_T = 0 \\implies \\lambda_T = w_T(x_T - r_T)\\Delta t $$\n这为伴随系统提供了终端条件。对于中间状态 $x_t$，其中 $t \\in \\{1, \\dots, T-1\\}$：\n$$ \\frac{\\partial \\mathcal{L}}{\\partial x_t} = w_t(x_t - r_t)\\Delta t + \\lambda_{t+1}(1 - \\Delta t \\, \\theta) - \\lambda_t = 0 $$\n这给出了伴随变量的反向递推关系：\n$$ \\lambda_t = (1 - \\Delta t \\, \\theta) \\lambda_{t+1} + w_t(x_t - r_t)\\Delta t \\quad \\text{for } t=T-1, \\dots, 1 $$\n通过满足这些伴随方程，涉及状态灵敏度的和项消失，梯度计算简化为：\n$$ \\frac{dJ}{d\\theta} = \\frac{\\partial \\mathcal{L}}{\\partial \\theta} $$\n$\\mathcal{L}$ 关于 $\\theta$ 的偏导数（将所有 $x_t$ 和 $\\lambda_t$ 视为独立变量）是：\n$$ \\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\alpha \\, \\theta + \\sum_{t=0}^{T-1} \\lambda_{t+1} (-\\Delta t \\, x_t) $$\n因此，梯度由下式给出：\n$$ \\frac{dJ}{d\\theta}_{\\mathrm{adj}} = \\alpha \\, \\theta - \\Delta t \\sum_{t=0}^{T-1} x_t \\lambda_{t+1} $$\n整个算法是一个三步过程：\n1. **正向传递**：给定参数 $\\theta$，从 $t=0$ 到 $t=T$ 正向模拟系统动态，以获得状态轨迹 $\\{x_0, x_1, \\dots, x_T\\}$。\n2. **反向传递**：使用存储的状态轨迹，利用上面推导的伴随方程，从 $t=T$ 反向到 $t=1$ 计算伴随变量。\n3. **梯度计算**：如最终表达式所示，通过对状态和伴随变量的乘积求和来计算梯度 $\\frac{dJ}{d\\theta}$。\n\n为了验证此推导及其实现的正确性，我们将所得梯度与通过中心有限差分公式获得的数值近似进行比较：\n$$ \\frac{dJ}{d\\theta}_{\\mathrm{fd}} \\approx \\frac{J(\\theta + \\varepsilon) - J(\\theta - \\varepsilon)}{2 \\varepsilon} $$\n对于一个小的扰动 $\\varepsilon$。如果绝对差 $d = |\\frac{dJ}{d\\theta}_{\\mathrm{adj}} - \\frac{dJ}{d\\theta}_{\\mathrm{fd}}|$ 在指定的容差范围内，即 $d \\le \\max(\\tau_{\\mathrm{abs}}, \\tau_{\\mathrm{rel}} \\cdot \\max(1, |\\frac{dJ}{d\\theta}_{\\mathrm{fd}}|))$，则确认其准确性，其中 $\\tau_{\\mathrm{abs}}$ 和 $\\tau_{\\mathrm{rel}}$ 分别是绝对和相对容差阈值。\n\n提供的 Python 代码实现了这整个过程，包括正向模拟器、代价函数 $J(\\theta)$、伴随梯度计算、有限差分近似以及对三个指定测试用例中每一个的最终准确性检查。",
            "answer": "```python\nimport numpy as np\n\ndef get_cost(theta, T, dt, x0, u, r, w, alpha):\n    \"\"\"\n    Computes the objective function J(theta) for a given set of parameters.\n    This involves a forward simulation of the state trajectory.\n    \"\"\"\n    x = np.zeros(T + 1)\n    x[0] = x0\n    \n    # Forward simulation to find the state trajectory x_t\n    for t in range(T):\n        x[t+1] = (1.0 - dt * theta) * x[t] + dt * u[t]\n        \n    # Cost calculation\n    cost_sum = np.sum(w * (x - r)**2)\n        \n    J = 0.5 * cost_sum * dt + 0.5 * alpha * theta**2\n    return J\n\ndef get_adjoint_gradient(theta, T, dt, x0, u, r, w, alpha):\n    \"\"\"\n    Computes the gradient dJ/dtheta using the discrete adjoint method.\n    \"\"\"\n    \n    # 1. Forward Pass: Simulate and store the state trajectory\n    x = np.zeros(T + 1)\n    x[0] = x0\n    for t in range(T):\n        x[t+1] = (1.0 - dt * theta) * x[t] + dt * u[t]\n\n    # 2. Backward Pass: Compute the adjoint variables\n    lamb = np.zeros(T + 1)  # Use 'lamb' to avoid conflict with Python's 'lambda'\n    lamb[T] = w[T] * (x[T] - r[T]) * dt\n    for t in range(T - 1, 0, -1):  # Iterate from t=T-1 down to 1\n        lamb[t] = (1.0 - dt * theta) * lamb[t+1] + w[t] * (x[t] - r[t]) * dt\n        \n    # 3. Gradient Calculation\n    # The gradient expression is dJ/d(theta) = alpha*theta - dt * sum_{t=0}^{T-1} x_t * lambda_{t+1}\n    grad_sum = np.dot(x[:T], lamb[1:])\n        \n    grad_J_theta = alpha * theta - dt * grad_sum\n    \n    return grad_J_theta\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Test Case A: General case\n        {\n            \"name\": \"A\",\n            \"T\": 48, \"dt\": 1.0, \"x0\": 1.0, \"theta\": 0.02, \"alpha\": 0.01,\n            \"u_func\": lambda t: 0.5 * np.sin(2 * np.pi * t / 24.0) + 0.1,\n            \"r_val\": 1.0, \"w_val\": 1.0,\n            \"eps\": 1e-6, \"tau_abs\": 1e-9, \"tau_rel\": 1e-6\n        },\n        # Test Case B: Boundary case near zero self-discharge\n        {\n            \"name\": \"B\",\n            \"T\": 24, \"dt\": 1.0, \"x0\": 0.0, \"theta\": 0.0, \"alpha\": 0.0,\n            \"u_func\": lambda t: 0.1 if t  12 else -0.1,\n            \"r_val\": 0.0, \"w_val\": 1.5,\n            \"eps\": 1e-6, \"tau_abs\": 1e-9, \"tau_rel\": 1e-6\n        },\n        # Test Case C: Single-step edge case\n        {\n            \"name\": \"C\",\n            \"T\": 1, \"dt\": 2.0, \"x0\": 0.0, \"theta\": 0.5, \"alpha\": 0.1,\n            \"u_func\": lambda t: 1.0,\n            \"r_val\": 1.0, \n            \"w_arr\": [0.5, 2.0], # Non-uniform weights\n            \"eps\": 1e-6, \"tau_abs\": 1e-9, \"tau_rel\": 1e-6\n        }\n    ]\n    \n    all_results = []\n    \n    for case in test_cases:\n        T = case[\"T\"]\n        dt = case[\"dt\"]\n        x0 = case[\"x0\"]\n        theta = case[\"theta\"]\n        alpha = case[\"alpha\"]\n        eps = case[\"eps\"]\n        tau_abs = case[\"tau_abs\"]\n        tau_rel = case[\"tau_rel\"]\n        \n        # Prepare inputs u, r, w as numpy arrays\n        u = np.array([case[\"u_func\"](t) for t in range(T)], dtype=float)\n        \n        if \"w_arr\" in case:\n            w = np.array(case[\"w_arr\"], dtype=float)\n        else:\n            w = np.full(T + 1, case[\"w_val\"], dtype=float)\n            \n        r = np.full(T + 1, case[\"r_val\"], dtype=float)\n        \n        # Calculate Adjoint Gradient\n        g_adj = get_adjoint_gradient(theta, T, dt, x0, u, r, w, alpha)\n        \n        # Calculate Finite Difference Gradient\n        J_plus = get_cost(theta + eps, T, dt, x0, u, r, w, alpha)\n        J_minus = get_cost(theta - eps, T, dt, x0, u, r, w, alpha)\n        g_fd = (J_plus - J_minus) / (2.0 * eps)\n        \n        # Accuracy Check\n        abs_diff = np.abs(g_adj - g_fd)\n        # Using a relative-error-like criterion as specified\n        tolerance = max(tau_abs, tau_rel * max(1.0, np.abs(g_fd)))\n        is_ok = abs_diff = tolerance\n        \n        all_results.extend([g_fd, g_adj, is_ok])\n\n    # Format the final output string as specified in the problem\n    # [g_fd,A, g_adj,A, ok_A, g_fd,B, g_adj,B, ok_B, ...]\n    # str(bool) in Python gives \"True\" or \"False\", which is a standard representation.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}