{
    "hands_on_practices": [
        {
            "introduction": "本练习旨在建立一个基础但至关重要的联系，即一个间歇性负荷的占空比的统计特性如何直接转化为其平均功率的统计特性。通过一个简单的开关模型，您将推导出负荷平均功率的变异系数（$CV$）完全由其占空比的均值（$\\mu_D$）和标准差（$\\sigma_D$）决定的关系。这个练习揭示了一个核心原理：负荷功率的相对波动性等同于其占空比自身的相对波动性，这为更复杂的负荷建模奠定了理论基础。",
            "id": "4101854",
            "problem": "一个电器被建模为一个具有恒定开启状态有功功率 $P_{\\text{on}} > 0$ 的通断负载。令 $I(t) \\in \\{0,1\\}$ 表示其在时间 $t$ 的状态指示器，其中当设备开启时 $I(t) = 1$，否则 $I(t) = 0$。瞬时有功功率为 $p(t) = P_{\\text{on}} I(t)$。考虑一个持续时间为 $T$ 的观测窗口，该窗口相对于设备的内部开关时间尺度而言很大，并将窗口平均功率定义为 $\\overline{P}_T = \\frac{1}{T} \\int_{0}^{T} p(t) \\, dt$。将此窗口内的占空比定义为 $D_T = \\frac{1}{T} \\int_{0}^{T} I(t) \\, dt$。由于缓慢的外生变异性（例如，用户行为或环境条件），占空比 $D_T$ 在不同窗口间是一个支撑集为 $[0,1]$ 的随机变量 $D$，其均值为 $\\mu_D = \\mathbb{E}[D] \\in (0,1]$，方差为 $\\sigma_D^2 = \\operatorname{Var}(D) \\ge 0$。假设 $T$ 足够大，以至于窗口内由快速开关引起的变异性与由 $D$ 捕获的缓慢变异性相比可以忽略不计。\n\n仅使用窗口平均、期望、方差和变异系数（对于随机变量 $X$ 定义为 $CV = \\sigma_X / \\mu_X$）的定义，推导随机窗口平均功率 $\\overline{P}_T$ 的变异系数的闭式表达式，该表达式应使用 $P_{\\text{on}}$、$\\mu_D$ 和 $\\sigma_D$ 表示。您的最终答案必须是单一的解析表达式。请将最终结果表示为一个纯数（无量纲）。无需进行四舍五入。",
            "solution": "首先对问题进行有效性检查。\n\n### 步骤 1：提取已知条件\n- 一个电器被建模为通断负载。\n- 恒定的开启状态有功功率：$P_{\\text{on}} > 0$。\n- 在时间 $t$ 的状态指示器：$I(t) \\in \\{0,1\\}$，其中 $I(t) = 1$ 表示“开启”，$I(t) = 0$ 表示“关闭”。\n- 瞬时有功功率：$p(t) = P_{\\text{on}} I(t)$。\n- 观测窗口持续时间：$T$。\n- $T$ 相对于设备的内部开关时间尺度而言很大。\n- 窗口平均功率：$\\overline{P}_T = \\frac{1}{T} \\int_{0}^{T} p(t) \\, dt$。\n- 此窗口内的占空比：$D_T = \\frac{1}{T} \\int_{0}^{T} I(t) \\, dt$。\n- 在不同窗口间，$D_T$ 被视为一个随机变量 $D$。\n- $D$ 的支撑集为 $[0,1]$。\n- $D$ 的均值：$\\mu_D = \\mathbb{E}[D] \\in (0,1]$。\n- $D$ 的方差：$\\sigma_D^2 = \\operatorname{Var}(D) \\ge 0$。\n- 有一个假设，$T$ 足够大，使得窗口内的变异性与 $D$ 的缓慢变异性相比可以忽略不计。\n- 随机变量 $X$ 的变异系数定义为 $CV_X = \\sigma_X / \\mu_X$。\n- 目标是推导随机窗口平均功率的变异系数 $CV_{\\overline{P}_T}$ 的闭式表达式，该表达式用 $P_{\\text{on}}$、$\\mu_D$ 和 $\\sigma_D$ 表示。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据。在电气工程和能源系统分析中，带有占空比的间歇性负载模型是一种标准和基础的抽象。将占空比视为随机变量以解释较慢的变化条件（例如用户行为）是一种有效且常见的建模技术。问题提法得当，提供了推导所需量所需的所有必要定义（平均功率、占空比、均值、方差、变异系数）和参数。语言客观且数学上精确。问题是自洽的、一致的，并且不违反任何物理或数学原理。这是一个与负载特性直接相关的可形式化问题。\n\n### 步骤 3：结论与行动\n问题被判定为有效。将提供完整解答。\n\n目标是求出窗口平均功率 $\\overline{P}_T$ 的变异系数。该量记为 $CV_{\\overline{P}_T}$，定义为其标准差与均值的比率：\n$$CV_{\\overline{P}_T} = \\frac{\\sigma_{\\overline{P}_T}}{\\mu_{\\overline{P}_T}}$$\n我们必须首先求出随机变量 $\\overline{P}_T$ 的均值 $\\mu_{\\overline{P}_T} = \\mathbb{E}[\\overline{P}_T]$ 和标准差 $\\sigma_{\\overline{P}_T} = \\sqrt{\\operatorname{Var}(\\overline{P}_T)}$。\n\n首先，我们建立窗口平均功率 $\\overline{P}_T$ 和占空比 $D_T$ 之间的直接关系。根据定义，\n$$\\overline{P}_T = \\frac{1}{T} \\int_{0}^{T} p(t) \\, dt$$\n代入瞬时功率的表达式 $p(t) = P_{\\text{on}} I(t)$，我们得到：\n$$\\overline{P}_T = \\frac{1}{T} \\int_{0}^{T} P_{\\text{on}} I(t) \\, dt$$\n由于 $P_{\\text{on}}$ 是一个常数，它可以从积分中提出：\n$$\\overline{P}_T = P_{\\text{on}} \\left( \\frac{1}{T} \\int_{0}^{T} I(t) \\, dt \\right)$$\n括号中的项是占空比 $D_T$ 的定义。因此，窗口平均功率与该窗口的占空比成正比：\n$$\\overline{P}_T = P_{\\text{on}} D_T$$\n问题陈述，由于缓慢的变异性，当在多个窗口间观察时，占空比 $D_T$ 被视为一个随机变量 $D$。因此，$\\overline{P}_T$ 也是一个随机变量，通过线性变换 $\\overline{P}_T = P_{\\text{on}} D$ 与 $D$ 相关。我们现在可以使用 $D$ 的已知属性来计算 $\\overline{P}_T$ 的统计特性。\n\n接下来，我们计算 $\\overline{P}_T$ 的均值。$\\overline{P}_T$ 的均值或期望为：\n$$\\mu_{\\overline{P}_T} = \\mathbb{E}[\\overline{P}_T] = \\mathbb{E}[P_{\\text{on}} D]$$\n利用期望算子的线性性质，常数 $P_{\\text{on}}$ 可以被提出来：\n$$\\mu_{\\overline{P}_T} = P_{\\text{on}} \\mathbb{E}[D]$$\n问题给出 $\\mathbb{E}[D] = \\mu_D$。因此，窗口平均功率的均值为：\n$$\\mu_{\\overline{P}_T} = P_{\\text{on}} \\mu_D$$\n由于 $P_{\\text{on}} > 0$ 且 $\\mu_D \\in (0,1]$，平均功率 $\\mu_{\\overline{P}_T}$ 严格为正。\n\n现在，我们计算 $\\overline{P}_T$ 的方差。方差定义为 $\\sigma_{\\overline{P}_T}^2 = \\operatorname{Var}(\\overline{P}_T)$。\n$$\\sigma_{\\overline{P}_T}^2 = \\operatorname{Var}(\\overline{P}_T) = \\operatorname{Var}(P_{\\text{on}} D)$$\n使用方差的性质 $\\operatorname{Var}(aX) = a^2 \\operatorname{Var}(X)$（其中 $a$ 是常数，$X$ 是随机变量），我们有：\n$$\\sigma_{\\overline{P}_T}^2 = (P_{\\text{on}})^2 \\operatorname{Var}(D)$$\n问题给出 $\\operatorname{Var}(D) = \\sigma_D^2$。因此，窗口平均功率的方差是：\n$$\\sigma_{\\overline{P}_T}^2 = P_{\\text{on}}^2 \\sigma_D^2$$\n标准差 $\\sigma_{\\overline{P}_T}$ 是方差的平方根。由于标准差是非负的且 $P_{\\text{on}} > 0$，我们有：\n$$\\sigma_{\\overline{P}_T} = \\sqrt{P_{\\text{on}}^2 \\sigma_D^2} = |P_{\\text{on}}| |\\sigma_D| = P_{\\text{on}} \\sigma_D$$\n\n最后，我们可以通过将其均值和标准差的表达式代入其定义来计算 $\\overline{P}_T$ 的变异系数：\n$$CV_{\\overline{P}_T} = \\frac{\\sigma_{\\overline{P}_T}}{\\mu_{\\overline{P}_T}} = \\frac{P_{\\text{on}} \\sigma_D}{P_{\\text{on}} \\mu_D}$$\n常数项 $P_{\\text{on}}$ 同时出现在分子和分母中。由于 $P_{\\text{on}} > 0$，我们可以消去它：\n$$CV_{\\overline{P}_T} = \\frac{\\sigma_D}{\\mu_D}$$\n该表达式仅用占空比的统计特性 $\\mu_D$ 和 $\\sigma_D$ 给出了窗口平均功率的变异系数。结果与开启状态功率水平 $P_{\\text{on}}$ 无关。这表明平均功率的相对变异性与占空比本身的相对变异性相同。结果是无量纲的，因为 $\\sigma_D$ 和 $\\mu_D$ 都是无量纲的量。",
            "answer": "$$\\boxed{\\frac{\\sigma_D}{\\mu_D}}$$"
        },
        {
            "introduction": "在工程实践中，仅依赖平均功率等简单指标来评估设备利用率可能导致严重误判，尤其是在处理可变速驱动（VSD）等非线性或可变负荷时。本练习通过一个思想实验，对比了两个具有相同平均功率但波形不同的负荷曲线，展示了它们对设备产生的热应力截然不同。通过这个练习，您将理解为何基于物理损耗机制（如与电流平方$I^2$相关的损耗）的度量标准对于准确评估设备的安全运行和寿命至关重要。",
            "id": "4101853",
            "problem": "一台工业变速驱动器 (VSD) 从一个稳定电网为一台三相电机供电，该电网的线间电压近似恒定，且在 VSD 的工作范围内功率因数接近于 1。考虑两个为时一小时的负载周期，它们为被驱动的设备提供相同的净能量。VSD 和上游导体的热限制主要由与电流平方成比例的传导相关损耗决定。假设在工作范围内，输入电流约与输入电功率成正比，因此内部焦耳热和传导损耗与输入功率平方的时间积分成正比。同时假设限制性元件的热时间常数远大于周期时长，因此累积损耗能量是相关的严酷性度量。\n\n设 VSD 的额定输入功率为 $P_{\\text{rated}} = 10\\,\\text{kW}$。定义两个持续时间为 $T = 1\\,\\text{h}$ 的负载周期：\n\n- 方案 A：对于所有 $t \\in [0,T]$，输入功率恒为 $P(t) = 5\\,\\text{kW}$。\n- 方案 B：方波输入功率，当 $t \\in [0,0.5T)$ 时，$P(t) = 10\\,\\text{kW}$；当 $t \\in [0.5T,T]$ 时，$P(t) = 0\\,\\text{kW}$。\n\n两种方案提供相同的净能量 $\\int_{0}^{T} P(t)\\,dt$。\n\n一个常用的利用率因子定义为平均输入功率与额定输入功率之比。在实践中，该因子常用于对负载严酷性进行分类。请您评估在上述变速运行的假设下，此因子是否能恰当地反映热严酷性，如果不能，请评估一个与假定的损耗机制一致、并对功率峰值进行惩罚的修正严酷性指标。\n\n下列陈述中哪些是正确的？\n\nA. 因为两种方案具有相同的平均输入功率，所以利用率因子正确地推断出，对于这两种方案，二次方比例的热严酷性是相同的。\n\nB. 一个与假定损耗机制一致、并通过能量吞吐量和额定功率进行归一化的无量纲修正严酷性指标，对于这两种方案，得出的值为 $M_{\\text{A}} = 0.5$ 和 $M_{\\text{B}} = 1.0$，因此将方案 B 排为更严酷。\n\nC. 在所述假设下，周期内的累积传导相关热损耗与 $\\int_{0}^{T} P(t)\\,dt$ 成比例，因此两种方案在热学上是等效的。\n\nD. 如果输入功率波形 $P(t)$ 乘以一个恒定的振幅因子 $c>0$ 而 $P_{\\text{rated}}$ 保持不变，则修正的严酷性指标保持不变。\n\nE. 陈述 B 中的修正严酷性指标可以等效地写为比率 $\\dfrac{P_{\\text{RMS}}^{2}}{P_{\\text{rated}}\\,P_{\\text{avg}}}$，其中 $P_{\\text{RMS}}^{2} \\equiv \\dfrac{1}{T}\\int_{0}^{T} P^{2}(t)\\,dt$ 且 $P_{\\text{avg}} \\equiv \\dfrac{1}{T}\\int_{0}^{T} P(t)\\,dt$。",
            "solution": "首先根据指定标准对问题陈述进行验证。\n\n### 问题验证\n\n**第 1 步：提取给定信息**\n\n*   **系统**：一台工业变速驱动器 (VSD) 从一个稳定电网为一台三相电机供电。\n*   **电网条件**：近似恒定的线间电压。\n*   **功率因数**：在工作范围内接近于 1。\n*   **热限制**：主要由传导相关损耗引起。\n*   **损耗比例假设**：损耗与电流的平方 ($I^2$) 成比例。\n*   **电流-功率假设**：输入电流约与输入电功率成正比，$I \\propto P(t)$。\n*   **由此产生的损耗比例**：内部焦耳热和传导损耗与输入功率平方的时间积分成正比。这意味着累积损耗能量 $E_{\\text{loss}}$ 与 $\\int_{0}^{T} P^{2}(t)\\,dt$ 成比例。\n*   **热时间常数假设**：限制性元件的热时间常数远大于周期时长。\n*   **严酷性度量**：累积损耗能量是相关的严酷性度量。\n*   **额定功率**：$P_{\\text{rated}} = 10\\,\\text{kW}$。\n*   **周期时长**：$T = 1\\,\\text{h}$。\n*   **方案 A**：对于所有 $t \\in [0,T]$，输入功率恒为 $P(t) = 5\\,\\text{kW}$。\n*   **方案 B**：方波输入功率，当 $t \\in [0,0.5T)$ 时 $P(t) = 10\\,\\text{kW}$，当 $t \\in [0.5T,T]$ 时 $P(t) = 0\\,\\text{kW}$。\n*   **能量等效性**：两种方案提供相同的净能量 $\\int_{0}^{T} P(t)\\,dt$。\n*   **定义**：利用率因子定义为平均输入功率与额定输入功率之比。\n\n**第 2 步：使用提取信息进行验证**\n\n1.  **科学基础**：该问题在电气工程和电气设备热分析原理方面有充分的依据。传导损耗（$I^2R$ 损耗）占主导地位的假设是合理的。当电压 $V_{LL}$ 和功率因数 $\\cos(\\phi)$ 假设为常数时，从功率方程 $P = \\sqrt{3} V_{LL} I \\cos(\\phi)$ 可得出 $I \\propto P(t)$ 的假设，这在问题中已明确说明（稳定电网，接近单位功率因数）。损耗能量与 $\\int P^2(t)\\,dt$ 成比例的结论是基于这些前提的直接逻辑推论。长热时间常数的假设是将负载周期分析简化为基于能量的方法的标准做法。\n\n2.  **良构性**：问题是良构的。所有进行所需计算和评估陈述的必要数据和定义都已提供。问题具体且可回答。\n\n3.  **客观性**：问题以客观、技术性的语言陈述，没有主观或带有偏见的措辞。\n\n4.  **完整性与一致性**：设置既完整又内部一致。可以验证两种方案提供相同净能量的说法：\n    *   方案 A 的能量：$E_A = \\int_{0}^{T} (5\\,\\text{kW})\\,dt = (5\\,\\text{kW}) \\cdot T$。\n    *   方案 B 的能量：$E_B = \\int_{0}^{0.5T} (10\\,\\text{kW})\\,dt + \\int_{0.5T}^{T} (0\\,\\text{kW})\\,dt = (10\\,\\text{kW}) \\cdot (0.5T) = (5\\,\\text{kW}) \\cdot T$。\n    *   能量确实相等，证实了陈述的一致性。\n\n5.  **现实性**：功率水平、负载周期形状以及整个场景对于 VSD 和电机的工业应用是现实的。\n\n**第 3 步：结论与行动**\n\n问题陈述是有效的。它在科学上是合理的、自洽的、良构的，并且基于合理且明确陈述的物理假设。可以进行求解过程。\n\n### 求解推导\n\n问题的核心是比较两个负载周期的热严酷性。根据问题陈述，热严酷性由累积损耗能量决定，该能量与输入功率平方的时间积分成正比。设比例常数为 $k$。\n$$E_{\\text{loss}} = k \\int_{0}^{T} P(t)^2 \\,dt$$\n为了比较不同方案的严酷性，我们需要为每个方案计算这个积分。使用均方根 (RMS) 功率会很方便，因为其平方与损耗能量产生的平均速率成正比。\n平均功率为 $P_{\\text{avg}} = \\frac{1}{T}\\int_{0}^{T} P(t)\\,dt$。\n均方功率为 $P_{\\text{RMS}}^2 = \\frac{1}{T}\\int_{0}^{T} P^2(t)\\,dt$。\n因此，总损耗能量为 $E_{\\text{loss}} = k \\cdot T \\cdot P_{\\text{RMS}}^2$。对于固定的持续时间 $T$，热严酷性与 $P_{\\text{RMS}}^2$ 成正比。\n\n**方案 A 的计算：**\n功率是恒定的，$P_A(t) = 5\\,\\text{kW}$。\n平均功率为：\n$$P_{A, \\text{avg}} = \\frac{1}{T} \\int_{0}^{T} 5 \\,dt = 5\\,\\text{kW}$$\n均方功率为：\n$$P_{A, \\text{RMS}}^2 = \\frac{1}{T} \\int_{0}^{T} (5)^2 \\,dt = \\frac{1}{T} \\int_{0}^{T} 25 \\,dt = 25\\,(\\text{kW})^2$$\n\n**方案 B 的计算：**\n功率是方波，$P_B(t) = 10\\,\\text{kW}$ 当 $t \\in [0, 0.5T)$，$P_B(t) = 0\\,\\text{kW}$ 当 $t \\in [0.5T, T]$。\n平均功率为：\n$$P_{B, \\text{avg}} = \\frac{1}{T} \\left( \\int_{0}^{0.5T} 10 \\,dt + \\int_{0.5T}^{T} 0 \\,dt \\right) = \\frac{1}{T} (10 \\cdot 0.5T) = 5\\,\\text{kW}$$\n均方功率为：\n$$P_{B, \\text{RMS}}^2 = \\frac{1}{T} \\left( \\int_{0}^{0.5T} (10)^2 \\,dt + \\int_{0.5T}^{T} (0)^2 \\,dt \\right) = \\frac{1}{T} (100 \\cdot 0.5T) = 50\\,(\\text{kW})^2$$\n\n**热严酷性比较：**\n热严酷性与 $P_{\\text{RMS}}^2$ 成正比。\n对于方案 A，严酷性与 $25\\,(\\text{kW})^2$ 成正比。\n对于方案 B，严酷性与 $50\\,(\\text{kW})^2$ 成正比。\n尽管方案 B 的平均功率与方案 A 相同，但其热严酷性是方案 A 的两倍。\n\n### 逐项分析\n\n**A. 因为两种方案具有相同的平均输入功率，所以利用率因子正确地推断出，对于这两种方案，二次方比例的热严酷性是相同的。**\n两种方案的 $P_{\\text{avg}} = 5\\,\\text{kW}$。额定功率为 $P_{\\text{rated}} = 10\\,\\text{kW}$。两者的利用率因子均为 $\\frac{5\\,\\text{kW}}{10\\,\\text{kW}} = 0.5$。如果此因子是热严酷性的正确度量，则意味着两种方案的严酷性相同。然而，我们的分析表明，热严酷性（与 $P_{\\text{RMS}}^2$ 成正比）对于方案 A 是 $25\\,(\\text{kW})^2$，对于方案 B 是 $50\\,(\\text{kW})^2$。严酷性不相同。因此，基于平均功率的利用率因子对于这种损耗机制是一个不正确的度量。\n结论：错误。\n\n**B. 一个与假定损耗机制一致、并通过能量吞吐量和额定功率进行归一化的无量纲修正严酷性指标，对于这两种方案，得出的值为 $M_{\\text{A}} = 0.5$ 和 $M_{\\text{B}} = 1.0$，因此将方案 B 排为更严酷。**\n与损耗机制一致的指标必须与总损耗能量 $\\int_{0}^{T} P(t)^2\\,dt$ 成正比。能量吞吐量为 $E_{\\text{net}} = \\int_{0}^{T} P(t)\\,dt$。通过能量吞吐量和额定功率进行归一化，建议指标的形式为：\n$$M = \\frac{\\int_{0}^{T} P(t)^2\\,dt}{(\\int_{0}^{T} P(t)\\,dt) \\cdot P_{\\text{rated}}}$$\n让我们为两种方案计算这个值。我们知道 $P_{\\text{rated}} = 10\\,\\text{kW}$ 且对于两种方案都有 $\\int_{0}^{T} P(t)\\,dt = (5\\,\\text{kW}) \\cdot T$。\n对于方案 A：\n$$M_A = \\frac{\\int_{0}^{T} (5)^2\\,dt}{(5T) \\cdot 10} = \\frac{25T}{50T} = 0.5$$\n对于方案 B：\n$$M_B = \\frac{\\int_{0}^{0.5T} (10)^2\\,dt}{(5T) \\cdot 10} = \\frac{100 \\cdot (0.5T)}{50T} = \\frac{50T}{50T} = 1.0$$\n计算出的值 $M_A = 0.5$ 和 $M_B = 1.0$ 与陈述相符。该指标正确地将方案 B ($M_B=1.0$) 排列为比方案 A ($M_A=0.5$) 更严酷。\n结论：正确。\n\n**C. 在所述假设下，周期内的累积传导相关热损耗与 $\\int_{0}^{T} P(t)\\,dt$ 成比例，因此两种方案在热学上是等效的。**\n这个陈述与问题的假设直接矛盾。问题明确指出，损耗与电流的平方成比例，而电流与功率成正比。因此，累积损耗与 $\\int_{0}^{T} P(t)^2\\,dt$ 成比例，而不是与 $\\int_{0}^{T} P(t)\\,dt$ 成比例。由于两种方案的 $P(t)$ 积分相同，但 $P(t)^2$ 的积分不同，因此热等效的结论是错误的。\n结论：错误。\n\n**D. 如果输入功率波形 $P(t)$ 乘以一个恒定的振幅因子 $c>0$ 而 $P_{\\text{rated}}$ 保持不变，则修正的严酷性指标保持不变。**\n设新波形为 $P'(t) = c \\cdot P(t)$。选项 B 中的修正指标为 $M = \\frac{\\int_{0}^{T} P(t)^2\\,dt}{(\\int_{0}^{T} P(t)\\,dt) \\cdot P_{\\text{rated}}}$。让我们为波形 $P'(t)$ 计算新指标 $M'$：\n$$M' = \\frac{\\int_{0}^{T} (P'(t))^2\\,dt}{(\\int_{0}^{T} P'(t)\\,dt) \\cdot P_{\\text{rated}}} = \\frac{\\int_{0}^{T} (c \\cdot P(t))^2\\,dt}{(\\int_{0}^{T} c \\cdot P(t)\\,dt) \\cdot P_{\\text{rated}}}$$\n$$M' = \\frac{c^2 \\int_{0}^{T} P(t)^2\\,dt}{c \\int_{0}^{T} P(t)\\,dt \\cdot P_{\\text{rated}}} = c \\left( \\frac{\\int_{0}^{T} P(t)^2\\,dt}{(\\int_{0}^{T} P(t)\\,dt) \\cdot P_{\\text{rated}}} \\right) = c \\cdot M$$\n指标 $M'$ 等于 $c \\cdot M$，而不是 $M$。因此，该指标不是不变的；它与因子 $c$ 呈线性比例关系。\n结论：错误。\n\n**E. 陈述 B 中的修正严酷性指标可以等效地写为比率 $\\dfrac{P_{\\text{RMS}}^{2}}{P_{\\text{rated}}\\,P_{\\text{avg}}}$，其中 $P_{\\text{RMS}}^{2} \\equiv \\dfrac{1}{T}\\int_{0}^{T} P^{2}(t)\\,dt$ 且 $P_{\\text{avg}} \\equiv \\dfrac{1}{T}\\int_{0}^{T} P(t)\\,dt$。**\n让我们将 $P_{\\text{RMS}}^2$ 和 $P_{\\text{avg}}$ 的定义代入给定的比率中：\n$$\\frac{P_{\\text{RMS}}^{2}}{P_{\\text{rated}}\\,P_{\\text{avg}}} = \\frac{\\frac{1}{T}\\int_{0}^{T} P(t)^2\\,dt}{P_{\\text{rated}} \\cdot \\left(\\frac{1}{T}\\int_{0}^{T} P(t)\\,dt\\right)}$$\n分子和分母中的因子 $\\frac{1}{T}$ 相互抵消，剩下：\n$$\\frac{\\int_{0}^{T} P(t)^2\\,dt}{P_{\\text{rated}} \\cdot \\int_{0}^{T} P(t)\\,dt}$$\n这个表达式与我们在选项 B 分析中为修正严酷性指标 $M$ 构建的表达式相同。因此，该陈述是该指标的正确代数重构。\n结论：正确。",
            "answer": "$$\\boxed{BE}$$"
        },
        {
            "introduction": "现代能源系统分析通常需要处理海量的负荷数据，并从中自动识别出具有代表性的用电模式。本练习将指导您从零开始实现一种强大的无监督机器学习方法——$k$-means聚类算法，用于对标准化的日负荷曲线进行分类。您不仅需要实现核心的分配和更新步骤，还将学习如何使用轮廓系数（silhouette score）这一关键指标来科学地确定最佳的聚类数量$k$，从而将原始数据划分为具有实际意义的不同占空比类别。",
            "id": "4101893",
            "problem": "考虑一组每日电力负荷曲线，表示为一天内每小时的平均功率测量值。设每条曲线为一个向量 $x \\in \\mathbb{R}^{24}$，其分量为非负值，单位为千瓦。为了关注工作周期形状而非绝对大小，每条曲线都通过每日总能量单位化归一进行转换：对于给定的 $x$，定义 $y = x / \\left(\\sum_{t=1}^{24} x_t\\right)$；归一化后的曲线 $y \\in \\mathbb{R}^{24}$ 满足 $\\sum_{t=1}^{24} y_t = 1$，并编码了每日能量在各小时的相对分布。\n\n任务是从基本原理出发，推导并使用 $k$-均值方法对这些归一化曲线进行聚类，然后使用轮廓系数确定聚类数量 $k$，以捕获不同的工作周期类别。使用以下基本依据：\n\n- 在 $T=24$ 的 $\\mathbb{R}^{T}$ 空间中欧几里得距离的定义，其中对于两个向量 $u,v \\in \\mathbb{R}^{24}$，其平方距离为 $\\|u - v\\|_2^2 = \\sum_{t=1}^{24} (u_t - v_t)^2$。\n- $k$-均值聚类目标，定义为最小化簇内数据点与其指定簇质心之间的欧几里得距离平方和。\n- 对于给定的聚类，每个数据点 $i$ 的轮廓系数定义为 $s(i) = \\dfrac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}$，其中 $a(i)$ 是点 $i$ 到其所属簇内其他点的平均距离，而 $b(i)$ 是点 $i$ 到其他簇中各点平均距离的最小值。总轮廓系数是所有点的 $s(i)$ 的平均值。\n\n您必须：\n- 从上述基本依据和定义出发，基于最小化簇内欧几里得距离平方和，推导 $k$-均值的质心更新规则和分配规则。\n- 从基本原理出发，基于簇内平均距离和最近的其他簇平均距离，推导轮廓系数公式。\n- 从头开始实现 $k$-均值算法（不使用外部聚类库），并对归一化曲线 $y$ 进行操作。\n- 为选择 $k$，评估候选 $k$ 值的平均轮廓系数，并选择使该分数最大化的 $k$。如果不同 $k$ 值的平均轮廓系数出现平局，则选择其中最小的 $k$。\n\n设计程序以处理以下测试套件，每个测试用例指定一个合成数据集和一组候选 $k$ 值。所有随机生成必须按规定设置种子，以确保可复现性。\n\n测试用例 1 (正常路径，三个不同的工作周期类别):\n- 小时数 $T = 24$。\n- 曲线数量 $N = 90$。\n- 使用小时索引 $t \\in \\{1,\\dots,24\\}$ 构建三个原型归一化形状：\n  - 连续基底负载: $p^{(1)}_t = 1$ for all $t$。\n  - 日间峰值: $p^{(2)}_t = 0.2 + \\exp\\left(-\\dfrac{(t-13)^2}{2\\cdot 3^2}\\right)$。\n  - 晚间峰值: $p^{(3)}_t = 0.2 + \\exp\\left(-\\dfrac{(t-20)^2}{2\\cdot 2^2}\\right)$。\n- 从每个原型生成 30 条曲线，通过添加独立的标准差为 $\\sigma = 0.05$ 的高斯噪声 $n_t \\sim \\mathcal{N}(0, \\sigma^2)$，然后使用一个小的下限值 $\\epsilon = 10^{-6}$ 裁剪为非负值，最后归一化为总和为 1，即 $y = x / \\left(\\sum_{t=1}^{24} x_t\\right)$。\n- 归一化前的随机幅度缩放：对于每个样本，将 $p^{(j)}$ 乘以一个从 $[0.8, 1.2]$ 上的均匀分布中抽取的因子 $\\alpha$。\n- 此测试用例的随机种子: $\\text{seed} = 42$。\n- 候选 $k$ 值: $\\{2,3,4,5\\}$。\n\n测试用例 2 (两个类别部分重叠，测试轮廓系数避免过度分割的能力):\n- 小时数 $T = 24$。\n- 曲线数量 $N = 80$。\n- 构建两个原型归一化形状：\n  - 早间峰值: $p^{(4)}_t = 0.25 + \\exp\\left(-\\dfrac{(t-8)^2}{2\\cdot 3^2}\\right)$。\n  - 午间峰值: $p^{(5)}_t = 0.25 + \\exp\\left(-\\dfrac{(t-13)^2}{2\\cdot 4^2}\\right)$。\n- 从每个原型生成 40 条曲线，使用标准差为 $\\sigma = 0.08$ 的高斯噪声，使用 $\\epsilon = 10^{-6}$ 裁剪为非负值，并归一化为总和为 1。\n- 归一化前的随机幅度缩放: $\\alpha \\sim \\text{Uniform}[0.85, 1.15]$。\n- 此测试用例的随机种子: $\\text{seed} = 123$。\n- 候选 $k$ 值: $\\{2,3,4,5\\}$。\n\n测试用例 3 (边界条件，使用非常小的数据集):\n- 小时数 $T = 24$。\n- 曲线数量 $N = 4$。\n- 构建两个原型归一化形状：\n  - 晚间高负载: $p^{(6)}_t = 0.2 + \\exp\\left(-\\dfrac{(t-19)^2}{2\\cdot 2^2}\\right)$。\n  - 平坦基线: $p^{(7)}_t = 1$ for all $t$。\n- 从每个原型生成 2 条曲线，使用标准差为 $\\sigma = 0.02$ 的高斯噪声，使用 $\\epsilon = 10^{-6}$ 裁剪为非负值，并归一化为总和为 1。\n- 归一化前的随机幅度缩放: $\\alpha \\sim \\text{Uniform}[0.9, 1.1]$。\n- 此测试用例的随机种子: $\\text{seed} = 999$。\n- 候选 $k$ 值: $\\{2,3,4\\}$。\n\n算法要求：\n- 通过选择 $k$ 个不同的数据点作为初始质心来实现 $k$-均值的随机初始化。迭代分配和质心更新步骤直至收敛，收敛的定义是分配不再改变，或最大质心位移小于容差 $\\tau = 10^{-6}$，或达到最大迭代次数 $I_{\\max} = 300$。\n- 为减轻对初始化的敏感性，执行 $R = 10$ 次随机重启，并选择使簇内平方距离和最小化的那次运行。通过将空簇的质心重新初始化为一个随机选择的数据点来处理空簇问题。\n- 使用归一化曲线上的欧几里得距离计算轮廓系数。对于单例簇，在计算其成员的轮廓系数公式时，定义 $a(i) = 0$。\n\n输出规范：\n- 对于每个测试用例，按所述选择其候选集中的 $k$ 值，该 $k$ 值能使平均轮廓系数最大化。如果在数值容差 $\\delta = 10^{-9}$ 内，多个 $k$ 值达到相同的最大平均轮廓系数，则选择其中最小的 $k$。\n- 您的程序应生成单行输出，其中包含一个方括号内的逗号分隔列表形式的结果，例如 $[k_1,k_2,k_3]$，其中 $k_j$ 是为测试用例 $j$ 选择的聚类数量。",
            "solution": "该问题是有效的，因为它在科学上基于聚类分析的原理，在数学上是适定的，并提供了一套完整且一致的定义、算法和测试用例。这是能源系统建模标准领域中的一个客观且可验证的任务。\n\n### $k$-均值算法的推导\n\n$k$-均值算法旨在将一组 $N$ 个数据点 $\\{y_1, y_2, \\dots, y_N\\}$（其中每个 $y_i \\in \\mathbb{R}^{T}$）划分为 $k$ 个不相交的簇 $\\{C_1, C_2, \\dots, C_k\\}$。其目标是最小化簇内平方和（WCSS），也称为惯性。目标函数 $J$ 定义为每个数据点与其所属簇的质心之间的欧几里得距离平方的总和。\n\n设 $\\mu_j$ 为簇 $C_j$ 的质心。目标函数为：\n$$\nJ = \\sum_{j=1}^{k} \\sum_{y_i \\in C_j} \\|y_i - \\mu_j\\|_2^2\n$$\n其中 $\\|y_i - \\mu_j\\|_2^2 = \\sum_{t=1}^{T} (y_{it} - \\mu_{jt})^2$ 是欧几里得距离的平方。\n\n同时对簇分配（集合 $C_j$）和质心（向量 $\\mu_j$）最小化 $J$ 是一个计算上困难的问题。$k$-均值算法采用迭代坐标下降法，在固定另一组变量的同时，交替优化一组变量。该过程包括两个步骤：分配步骤和更新步骤。\n\n**1. 分配步骤 (E-step):**\n在此步骤中，我们假设簇质心 $\\{\\mu_1, \\dots, \\mu_k\\}$ 是固定的。我们的目标是通过将每个数据点 $y_i$ 分配到一个簇来最小化 $J$。由于 $J$ 是所有簇的总和，且每个点仅属于一个簇，我们可以通过单独最小化每个点的贡献来最小化 $J$。对于单个点 $y_i$，它对 $J$ 的贡献是 $\\|y_i - \\mu_j\\|_2^2$，其中 $j$ 是 $y_i$ 所属簇的索引。为最小化此项，我们必须将 $y_i$ 分配给质心最近的簇。这给出了分配规则：\n$$\ny_i \\in C_j \\iff \\|y_i - \\mu_j\\|_2 \\le \\|y_i - \\mu_l\\|_2 \\quad \\forall l \\in \\{1, \\dots, k\\}\n$$\n在实践中，这等同于比较距离的平方，这在计算上更高效：\n$$\ny_i \\text{ is assigned to cluster } j^* = \\arg\\min_{j \\in \\{1,\\dots,k\\}} \\|y_i - \\mu_j\\|_2^2\n$$\n\n**2. 更新步骤 (M-step):**\n在此步骤中，我们假设簇分配 $\\{C_1, \\dots, C_k\\}$ 是固定的。我们的目标是通过更新质心 $\\{\\mu_1, \\dots, \\mu_k\\}$ 来最小化 $J$。目标函数 $J$ 是一系列项的和，每项仅依赖于一个质心 $\\mu_j$。因此我们可以通过独立地最小化每一项来最小化 $J$：\n$$\n\\min_{\\mu_j} \\left( J_j = \\sum_{y_i \\in C_j} \\|y_i - \\mu_j\\|_2^2 \\right) \\quad \\text{for each } j \\in \\{1, \\dots, k\\}\n$$\n为找到最小化平方距离和 $J_j$ 的向量 $\\mu_j$，我们对 $J_j$ 求关于 $\\mu_j$ 的梯度并将其设为零。\n簇 $j$ 的目标是 $J_j = \\sum_{y_i \\in C_j} (y_i - \\mu_j)^T (y_i - \\mu_j)$。\n其梯度为：\n$$\n\\nabla_{\\mu_j} J_j = \\nabla_{\\mu_j} \\sum_{y_i \\in C_j} (y_i^T y_i - 2y_i^T \\mu_j + \\mu_j^T \\mu_j) = \\sum_{y_i \\in C_j} (-2y_i + 2\\mu_j)\n$$\n将梯度设为零以找到最小值：\n$$\n\\sum_{y_i \\in C_j} (-2y_i + 2\\mu_j) = 0 \\implies \\sum_{y_i \\in C_j} 2\\mu_j = \\sum_{y_i \\in C_j} 2y_i\n$$\n设 $|C_j|$ 是簇 $C_j$ 中的点数。则 $\\sum_{y_i \\in C_j} \\mu_j = |C_j| \\mu_j$。\n$$\n|C_j| \\mu_j = \\sum_{y_i \\in C_j} y_i \\implies \\mu_j = \\frac{1}{|C_j|} \\sum_{y_i \\in C_j} y_i\n$$\n这个推导表明，一个簇的最优质心是分配给它的所有数据点的算术平均值（质心）。\n\n算法在这两个步骤之间迭代，直到收敛。收敛通常定义为簇分配不再改变，或质心移动量可忽略不计。\n\n### 轮廓系数的推导\n\n轮廓系数是用于评估聚类质量的一种度量。它量化了每个数据点与其所属簇的拟合程度，以及与其他相邻簇的对比情况。该分数是为每个点计算，然后对所有点取平均。\n\n对于簇 $C_j$ 中的单个数据点 $y_i$：\n\n**1. 簇内距离 $a(i)$：**\n该值衡量了点相对于其自身簇的内聚性。它定义为从 $y_i$ 到同一簇 $C_j$ 中所有其他点的平均欧几里得距离。\n$$\na(i) = \\frac{1}{|C_j| - 1} \\sum_{y_l \\in C_j, l \\ne i} \\|y_i - y_l\\|_2\n$$\n较小的 $a(i)$ 值表示该点与其簇匹配良好。如果簇 $C_j$ 只包含一个点（即单例簇，$|C_j|=1$），则求和为空，此时定义 $a(i)$ 为 $0$。\n\n**2. 簇间距离 $b(i)$：**\n该值衡量了点与其他簇的分离度。它定义为从 $y_i$ 到任何其他簇 $C_m$（其中 $m \\ne j$）中所有点的平均距离的最小值。\n首先，对于每个其他簇 $C_m$，我们计算从 $y_i$ 到其点的平均距离：\n$$\nd(i, C_m) = \\frac{1}{|C_m|} \\sum_{y_l \\in C_m} \\|y_i - y_l\\|_2\n$$\n然后，$b(i)$ 是在 $y_i$ 不属于的所有簇中这些值的最小值。这代表了到“最近的相邻簇”的距离。\n$$\nb(i) = \\min_{m \\ne j} \\{ d(i, C_m) \\}\n$$\n较大的 $b(i)$ 值表示该点远离其他簇。\n\n**3. 轮廓系数 $s(i)$：**\n点 $y_i$ 的轮廓系数将 $a(i)$ 和 $b(i)$ 组合成一个单一的归一化分数：\n$$\ns(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}\n$$\n$s(i)$ 的值范围从 -1 到 1：\n- $s(i) \\approx 1$：表示该点聚类效果好。其簇内距离 $a(i)$ 远小于其簇间距离 $b(i)$。\n- $s(i) \\approx 0$：表示该点位于两个簇的决策边界上或附近。其距离 $a(i)$ 和 $b(i)$ 相当。\n- $s(i) \\approx -1$：表示该点可能被错误分类。其簇内距离 $a(i)$ 远大于其簇间距离 $b(i)$，表明它更接近相邻簇而不是其自身所在的簇。\n\n对于给定的 $k$，聚类的总体质量是所有 $N$ 个数据点的平均轮廓系数：\n$$\nS_k = \\frac{1}{N} \\sum_{i=1}^{N} s(i)\n$$\n最佳聚类数 $k$ 被选为使该平均分数最大化的那个值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_data(T, prototypes, n_per_proto, noise_sigma, amp_range, seed):\n    \"\"\"Generates synthetic load profile data for a test case.\"\"\"\n    rng = np.random.default_rng(seed)\n    data = []\n    t_coords = np.arange(1, T + 1)\n    \n    # Pre-defined prototype shapes\n    proto_defs = {\n        1: lambda t: np.ones_like(t, dtype=float),\n        2: lambda t: 0.2 + np.exp(-(t - 13)**2 / (2 * 3**2)),\n        3: lambda t: 0.2 + np.exp(-(t - 20)**2 / (2 * 2**2)),\n        4: lambda t: 0.25 + np.exp(-(t - 8)**2 / (2 * 3**2)),\n        5: lambda t: 0.25 + np.exp(-(t - 13)**2 / (2 * 4**2)),\n        6: lambda t: 0.2 + np.exp(-(t - 19)**2 / (2 * 2**2)),\n        7: lambda t: np.ones_like(t, dtype=float),\n    }\n\n    for proto_idx, n in zip(prototypes, n_per_proto):\n        p_base = proto_defs[proto_idx](t_coords)\n        for _ in range(n):\n            alpha = rng.uniform(amp_range[0], amp_range[1])\n            noise = rng.normal(0, noise_sigma, size=T)\n            \n            x = alpha * p_base + noise\n            x = np.maximum(x, 1e-6)  # Clip to be non-negative\n            \n            y = x / np.sum(x)  # Normalize to unit daily energy\n            data.append(y)\n    \n    return np.array(data)\n\ndef kmeans(data, k, n_restarts, max_iter, tol, seed):\n    \"\"\"\n    Implements k-means clustering from first principles.\n    \n    Returns the best clustering (labels, centroids, wcss) found over all restarts.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    n_samples, n_features = data.shape\n    \n    best_wcss = np.inf\n    best_labels = None\n    best_centroids = None\n    \n    restart_seeds = rng.integers(0, 2**32 - 1, size=n_restarts)\n\n    for i in range(n_restarts):\n        restart_rng = np.random.default_rng(restart_seeds[i])\n        \n        initial_indices = restart_rng.choice(n_samples, k, replace=False)\n        centroids = data[initial_indices]\n        \n        current_labels = np.full(n_samples, -1, dtype=int)\n\n        for iteration in range(max_iter):\n            # Assignment step\n            dist_sq = np.sum((data[:, np.newaxis, :] - centroids[np.newaxis, :, :])**2, axis=2)\n            new_labels = np.argmin(dist_sq, axis=1)\n\n            # Convergence check: no change in assignments\n            if np.array_equal(new_labels, current_labels):\n                break\n            \n            current_labels = new_labels\n            \n            # Update step\n            old_centroids = np.copy(centroids)\n            for c_idx in range(k):\n                cluster_points = data[current_labels == c_idx]\n                if len(cluster_points) == 0:\n                    # Handle empty cluster by re-initializing to a random point\n                    reinit_idx = restart_rng.choice(n_samples)\n                    centroids[c_idx] = data[reinit_idx]\n                else:\n                    centroids[c_idx] = cluster_points.mean(axis=0)\n\n            # Convergence check: centroid shift below tolerance\n            centroid_shifts = np.linalg.norm(centroids - old_centroids, axis=1)\n            if np.max(centroid_shifts)  tol:\n                break\n        \n        # Calculate WCSS for this run\n        wcss = 0\n        for c_idx in range(k):\n            cluster_points = data[current_labels == c_idx]\n            if len(cluster_points) > 0:\n                wcss += np.sum((cluster_points - centroids[c_idx])**2)\n        \n        if wcss  best_wcss:\n            best_wcss = wcss\n            best_labels = current_labels\n            best_centroids = centroids\n            \n    return best_labels, best_centroids, best_wcss\n\ndef calculate_silhouette_score(data, labels):\n    \"\"\"Calculates the average silhouette score for a given clustering.\"\"\"\n    n_samples = data.shape[0]\n    unique_labels = np.unique(labels)\n    n_clusters = len(unique_labels)\n    \n    if n_clusters = 1:\n        return 0.0\n    if n_clusters == n_samples:\n        return 0.0 # Problem asks for k=2,3,4 on N=4. k=4 yields 4 singletons. Silhouette should be defined. Returning 0 is a safe choice. Some implementations return 1.\n\n    dist_matrix = np.linalg.norm(data[:, np.newaxis, :] - data[np.newaxis, :, :], axis=2)\n    \n    s_scores = np.zeros(n_samples)\n    for i in range(n_samples):\n        my_label = labels[i]\n        \n        # Intra-cluster distance a(i)\n        in_cluster_mask = (labels == my_label)\n        in_cluster_mask[i] = False\n        n_in_cluster = np.sum(in_cluster_mask)\n        \n        if n_in_cluster == 0:\n            a_i = 0.0  # Singleton cluster\n        else:\n            in_cluster_dists = dist_matrix[i, in_cluster_mask]\n            a_i = np.mean(in_cluster_dists)\n\n        # Inter-cluster distance b(i)\n        b_i = np.inf\n        other_labels = unique_labels[unique_labels != my_label]\n        for other_label in other_labels:\n            other_cluster_mask = (labels == other_label)\n            other_cluster_dists = dist_matrix[i, other_cluster_mask]\n            mean_dist = np.mean(other_cluster_dists)\n            if mean_dist  b_i:\n                b_i = mean_dist\n        \n        if max(a_i, b_i) == 0:\n            s_scores[i] = 0.0\n        else:\n            s_scores[i] = (b_i - a_i) / max(a_i, b_i)\n            \n    return np.mean(s_scores)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"T\": 24, \"N\": 90,\n            \"prototypes\": [1, 2, 3], \"n_per_proto\": [30, 30, 30],\n            \"noise_sigma\": 0.05, \"amp_range\": [0.8, 1.2],\n            \"seed\": 42, \"candidate_k\": [2, 3, 4, 5]\n        },\n        {\n            \"T\": 24, \"N\": 80,\n            \"prototypes\": [4, 5], \"n_per_proto\": [40, 40],\n            \"noise_sigma\": 0.08, \"amp_range\": [0.85, 1.15],\n            \"seed\": 123, \"candidate_k\": [2, 3, 4, 5]\n        },\n        {\n            \"T\": 24, \"N\": 4,\n            \"prototypes\": [6, 7], \"n_per_proto\": [2, 2],\n            \"noise_sigma\": 0.02, \"amp_range\": [0.9, 1.1],\n            \"seed\": 999, \"candidate_k\": [2, 3, 4]\n        }\n    ]\n\n    # Algorithmic parameters\n    I_MAX = 300\n    TOL = 1e-6\n    R = 10\n    DELTA = 1e-9\n\n    results = []\n    case_idx = 0\n    for case in test_cases:\n        case_idx += 1\n        data = generate_data(\n            T=case[\"T\"],\n            prototypes=case[\"prototypes\"],\n            n_per_proto=case[\"n_per_proto\"],\n            noise_sigma=case[\"noise_sigma\"],\n            amp_range=case[\"amp_range\"],\n            seed=case[\"seed\"]\n        )\n        \n        best_k = -1\n        max_silhouette = -np.inf\n        \n        # Use a consistent seed for k-means runs for reproducibility\n        kmeans_seed_base = case[\"seed\"]\n\n        for k in sorted(case[\"candidate_k\"]):\n            labels, _, _ = kmeans(\n                data=data, k=k, n_restarts=R,\n                max_iter=I_MAX, tol=TOL, seed=kmeans_seed_base\n            )\n            score = calculate_silhouette_score(data, labels)\n            \n            # Select k that maximizes silhouette score.\n            # Only update if score is significantly better.\n            # This preserves the smallest k in case of a tie.\n            if score > max_silhouette + DELTA:\n                max_silhouette = score\n                best_k = k\n        \n        results.append(best_k)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}