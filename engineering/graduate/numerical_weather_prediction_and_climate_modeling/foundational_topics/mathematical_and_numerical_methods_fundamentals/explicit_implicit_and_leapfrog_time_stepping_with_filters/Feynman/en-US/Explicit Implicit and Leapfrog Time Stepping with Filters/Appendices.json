{
    "hands_on_practices": [
        {
            "introduction": "The stability of an explicit time-stepping scheme is a paramount concern in numerical modeling, directly constraining the maximum permissible time step, $\\Delta t$. This practice provides a foundational exercise in stability analysis, guiding you through the process of deriving a concrete stability limit for a widely used third-order Runge-Kutta method. By deriving the method's stability polynomial and analyzing its behavior on the imaginary axis, you will determine the Courant–Friedrichs–Lewy (CFL) condition imposed by the spectrum of the spatial discretization operator .",
            "id": "4041369",
            "problem": "Consider the one-dimensional linear advection equation on a uniform periodic grid with spacing $\\Delta x$,\n$$\n\\partial_t u(x,t) + a\\,\\partial_x u(x,t) = 0,\n$$\nwhere $a$ is a constant advection speed. Using second-order centered finite differences in space, the semi-discrete system for the grid point values $u_j(t)$ can be written as\n$$\n\\partial_t u_j(t) = -a\\,\\frac{u_{j+1}(t) - u_{j-1}(t)}{2\\,\\Delta x},\n$$\nwhich is of the form $\\partial_t \\mathbf{u}(t) = \\mathbf{L}\\,\\mathbf{u}(t)$ with a constant matrix $\\mathbf{L}$. For this spatial discretization with periodic boundaries, the Fourier modes $e^{\\mathrm{i} k j \\Delta x}$ are eigenvectors of $\\mathbf{L}$ with corresponding eigenvalues\n$$\n\\lambda(k) = \\mathrm{i}\\,a\\,\\frac{\\sin(k\\,\\Delta x)}{\\Delta x}.\n$$\nYou will time step this semi-discrete system using the three-stage, third-order Strong Stability-Preserving Runge–Kutta method (SSPRK(3,3)), given in Shu–Osher form by the stages\n$$\n\\mathbf{u}^{(1)} = \\mathbf{u}^n + \\Delta t\\,\\mathbf{L}\\,\\mathbf{u}^n,\n$$\n$$\n\\mathbf{u}^{(2)} = \\frac{3}{4}\\,\\mathbf{u}^n + \\frac{1}{4}\\left(\\mathbf{u}^{(1)} + \\Delta t\\,\\mathbf{L}\\,\\mathbf{u}^{(1)}\\right),\n$$\n$$\n\\mathbf{u}^{n+1} = \\frac{1}{3}\\,\\mathbf{u}^n + \\frac{2}{3}\\left(\\mathbf{u}^{(2)} + \\Delta t\\,\\mathbf{L}\\,\\mathbf{u}^{(2)}\\right).\n$$\nStarting from the foundational facts that stability of a linear time-stepping method applied to $\\partial_t \\mathbf{u} = \\mathbf{L}\\,\\mathbf{u}$ is governed by the method’s scalar stability polynomial $R(z)$ via the requirement $|R(\\Delta t\\,\\lambda_k)| \\leq 1$ for all eigenvalues $\\lambda_k$ of $\\mathbf{L}$, and that discrete Fourier analysis characterizes the spectrum of $\\mathbf{L}$ for periodic linear advection, derive the stability polynomial $R(z)$ of SSPRK(3,3), determine its $|\\cdot| \\leq 1$ region along the imaginary axis, and compute the largest time step $\\Delta t$ that ensures $|R(\\Delta t\\,\\lambda(k))| \\leq 1$ for all wavenumbers $k$ supported by the grid. Express your final answer as a single closed-form analytic expression in terms of $a$ and $\\Delta x$. Express the final allowable time step in seconds. No rounding is required.",
            "solution": "The problem asks for the largest allowable time step, $\\Delta t$, for the numerical solution of the linear advection equation using a specific spatial discretization and time integration scheme. The stability of this process is governed by the condition $|R(\\Delta t\\,\\lambda_k)| \\leq 1$ for all eigenvalues $\\lambda_k$ of the semi-discrete operator $\\mathbf{L}$. The solution requires three main steps: first, deriving the stability polynomial $R(z)$ for the given time-stepping method (SSPRK(3,3)); second, determining the stability region of this polynomial along the imaginary axis, as the eigenvalues $\\lambda_k$ are purely imaginary; and third, using this stability region to constrain $\\Delta t$.\n\nThe semi-discrete system is given by $\\partial_t \\mathbf{u}(t) = \\mathbf{L}\\,\\mathbf{u}(t)$. To find the stability polynomial $R(z)$, we express $\\mathbf{u}^{n+1}$ solely in terms of $\\mathbf{u}^n$. Let $z = \\Delta t\\,\\mathbf{L}$. The method can be written as $\\mathbf{u}^{n+1} = R(z)\\,\\mathbf{u}^n$.\n\nFirst stage:\n$$\n\\mathbf{u}^{(1)} = (\\mathbf{I} + z)\\,\\mathbf{u}^n\n$$\nSecond stage: We substitute the expression for $\\mathbf{u}^{(1)}$ into the definition of $\\mathbf{u}^{(2)}$, noting that $\\mathbf{u}^{(1)} + \\Delta t\\,\\mathbf{L}\\,\\mathbf{u}^{(1)} = (\\mathbf{I}+z)\\mathbf{u}^{(1)}$.\n$$\n\\mathbf{u}^{(2)} = \\frac{3}{4}\\,\\mathbf{u}^n + \\frac{1}{4}(\\mathbf{I}+z)\\mathbf{u}^{(1)} = \\frac{3}{4}\\,\\mathbf{u}^n + \\frac{1}{4}(\\mathbf{I}+z)(\\mathbf{I}+z)\\,\\mathbf{u}^n = \\left(\\frac{3}{4}\\mathbf{I} + \\frac{1}{4}(\\mathbf{I}+z)^2\\right)\\,\\mathbf{u}^n\n$$\nExpanding the polynomial in $z$:\n$$\n\\frac{3}{4}\\mathbf{I} + \\frac{1}{4}(\\mathbf{I} + 2z + z^2) = \\left(\\frac{3}{4}+\\frac{1}{4}\\right)\\mathbf{I} + \\frac{2}{4}z + \\frac{1}{4}z^2 = \\mathbf{I} + \\frac{1}{2}z + \\frac{1}{4}z^2\n$$\nSo, $\\mathbf{u}^{(2)} = \\left(\\mathbf{I} + \\frac{1}{2}z + \\frac{1}{4}z^2\\right)\\mathbf{u}^n$.\n\nThird stage: We substitute the polynomial expression for $\\mathbf{u}^{(2)}$ into the expression for $\\mathbf{u}^{n+1}$, noting that $\\mathbf{u}^{(2)} + \\Delta t\\,\\mathbf{L}\\,\\mathbf{u}^{(2)} = (\\mathbf{I}+z)\\mathbf{u}^{(2)}$.\n$$\n\\mathbf{u}^{n+1} = \\frac{1}{3}\\,\\mathbf{u}^n + \\frac{2}{3}(\\mathbf{I}+z)\\mathbf{u}^{(2)} = \\left(\\frac{1}{3}\\mathbf{I} + \\frac{2}{3}(\\mathbf{I}+z)\\left(\\mathbf{I} + \\frac{1}{2}z + \\frac{1}{4}z^2\\right)\\right)\\mathbf{u}^n\n$$\nThe operator multiplying $\\mathbf{u}^n$ is the stability polynomial $R(z)$.\n$$\nR(z) = \\frac{1}{3} + \\frac{2}{3}(1+z)\\left(1 + \\frac{1}{2}z + \\frac{1}{4}z^2\\right)\n$$\nWe expand the product:\n$$\n(1+z)\\left(1 + \\frac{1}{2}z + \\frac{1}{4}z^2\\right) = 1 + \\frac{1}{2}z + \\frac{1}{4}z^2 + z + \\frac{1}{2}z^2 + \\frac{1}{4}z^3 = 1 + \\frac{3}{2}z + \\frac{3}{4}z^2 + \\frac{1}{4}z^3\n$$\nSubstituting this back into the expression for $R(z)$:\n$$\nR(z) = \\frac{1}{3} + \\frac{2}{3}\\left(1 + \\frac{3}{2}z + \\frac{3}{4}z^2 + \\frac{1}{4}z^3\\right) = \\frac{1}{3} + \\frac{2}{3} + z + \\frac{1}{2}z^2 + \\frac{1}{6}z^3\n$$\nThus, the stability polynomial for SSPRK(3,3) is:\n$$\nR(z) = 1 + z + \\frac{1}{2}z^2 + \\frac{1}{6}z^3\n$$\nThis is the third-order Taylor series expansion of $\\exp(z)$, consistent with the method's order of accuracy.\n\nNext, we analyze the stability of $R(z)$ on the imaginary axis. The eigenvalues of the spatial operator are given as $\\lambda(k) = \\mathrm{i}\\,a\\,\\frac{\\sin(k\\,\\Delta x)}{\\Delta x}$, which are purely imaginary. Therefore, the argument of the stability polynomial, $z_k = \\Delta t\\,\\lambda(k)$, is also purely imaginary. We set $z = \\mathrm{i} y$ for a real number $y$ and find the values of $y$ for which $|R(\\mathrm{i} y)| \\leq 1$.\n$$\nR(\\mathrm{i} y) = 1 + (\\mathrm{i} y) + \\frac{1}{2}(\\mathrm{i} y)^2 + \\frac{1}{6}(\\mathrm{i} y)^3 = 1 + \\mathrm{i} y - \\frac{1}{2}y^2 - \\frac{\\mathrm{i}}{6}y^3\n$$\nGrouping real and imaginary parts:\n$$\nR(\\mathrm{i} y) = \\left(1 - \\frac{1}{2}y^2\\right) + \\mathrm{i}\\left(y - \\frac{1}{6}y^3\\right)\n$$\nThe squared magnitude is:\n$$\n|R(\\mathrm{i} y)|^2 = \\left(1 - \\frac{1}{2}y^2\\right)^2 + \\left(y - \\frac{1}{6}y^3\\right)^2\n$$\nExpanding the terms:\n$$\n|R(\\mathrm{i} y)|^2 = \\left(1 - y^2 + \\frac{1}{4}y^4\\right) + \\left(y^2 - \\frac{2}{6}y^4 + \\frac{1}{36}y^6\\right)\n$$\n$$\n|R(\\mathrm{i} y)|^2 = 1 - y^2 + \\frac{1}{4}y^4 + y^2 - \\frac{1}{3}y^4 + \\frac{1}{36}y^6\n$$\n$$\n|R(\\mathrm{i} y)|^2 = 1 + \\left(\\frac{1}{4} - \\frac{1}{3}\\right)y^4 + \\frac{1}{36}y^6 = 1 - \\frac{1}{12}y^4 + \\frac{1}{36}y^6\n$$\nThe stability condition $|R(\\mathrm{i} y)|^2 \\leq 1$ becomes:\n$$\n1 - \\frac{1}{12}y^4 + \\frac{1}{36}y^6 \\leq 1\n$$\n$$\n\\frac{1}{36}y^6 - \\frac{1}{12}y^4 \\leq 0\n$$\nAssuming $y \\neq 0$, we can divide by the positive quantity $\\frac{y^4}{36}$:\n$$\ny^2 - 3 \\leq 0 \\implies y^2 \\leq 3\n$$\nThis implies $|y| \\leq \\sqrt{3}$. The stability interval for the SSPRK(3,3) method along the imaginary axis is $[-i\\sqrt{3}, i\\sqrt{3}]$.\n\nFinally, we apply this constraint to the given problem. The stability condition requires that for all wavenumbers $k$, the value $z_k = \\Delta t\\,\\lambda(k)$ must lie within this stability interval.\n$$\nz_k = \\Delta t \\left(\\mathrm{i}\\,a\\,\\frac{\\sin(k\\,\\Delta x)}{\\Delta x}\\right) = \\mathrm{i} \\left(\\frac{a\\,\\Delta t}{\\Delta x}\\sin(k\\,\\Delta x)\\right)\n$$\nThis is of the form $\\mathrm{i} y_k$ with $y_k = \\frac{a\\,\\Delta t}{\\Delta x}\\sin(k\\,\\Delta x)$. The stability condition $|y_k| \\leq \\sqrt{3}$ must hold for all $k$.\n$$\n\\left|\\frac{a\\,\\Delta t}{\\Delta x}\\sin(k\\,\\Delta x)\\right| \\leq \\sqrt{3}\n$$\nSince $\\Delta t > 0$ and $\\Delta x > 0$, this is equivalent to:\n$$\n\\frac{|a|\\,\\Delta t}{\\Delta x}|\\sin(k\\,\\Delta x)| \\leq \\sqrt{3}\n$$\nTo ensure this inequality holds for all wavenumbers $k$ supported by the grid, we must consider the worst case, where $|\\sin(k\\,\\Delta x)|$ reaches its maximum value. The maximum value of $|\\sin(\\theta)|$ is $1$. Therefore, we must satisfy:\n$$\n\\frac{|a|\\,\\Delta t}{\\Delta x} \\cdot 1 \\leq \\sqrt{3}\n$$\nThe largest time step $\\Delta t$ is found by taking the equality:\n$$\n\\Delta t = \\frac{\\sqrt{3}\\,\\Delta x}{|a|}\n$$\nThis expression provides the maximum allowable time step $\\Delta t$ in seconds that ensures numerical stability for all wavenumbers.",
            "answer": "$$\n\\boxed{\\frac{\\sqrt{3} \\Delta x}{|a|}}\n$$"
        },
        {
            "introduction": "Beyond numerical stability, a scheme's ability to preserve fundamental physical properties is critical for realistic simulations. This exercise investigates the leapfrog scheme's performance regarding a crucial constraint: nonnegativity, which is essential when modeling quantities like moisture or chemical concentrations that cannot physically be negative. By considering the scheme's behavior under a \"worst-case\" scenario for arbitrary non-negative data, you will uncover a significant structural limitation of the standard leapfrog method and reflect on the need for more sophisticated approaches to ensure physical realism .",
            "id": "4041408",
            "problem": "Consider the one-dimensional linear advection of a conserved, nonreactive moisture mixing ratio $q(x,t)$ governed by the conservation law $q_{t} + a\\,q_{x} = 0$ on a periodic domain with uniform grid spacing $\\Delta x$ and constant advection speed $a \\in \\mathbb{R}$. Let $q_{j}^{n}$ denote the discrete approximation of $q$ at spatial index $j \\in \\mathbb{Z}$ and discrete time level $n \\in \\mathbb{Z}$, with uniform time step $\\Delta t$. The leapfrog-in-time, centered-in-space discretization is defined by\n$$\n\\frac{q_{j}^{n+1} - q_{j}^{n-1}}{2\\,\\Delta t} + a\\,\\frac{q_{j+1}^{n} - q_{j-1}^{n}}{2\\,\\Delta x} \\;=\\; 0,\n$$\nwhich can be written as\n$$\nq_{j}^{n+1} \\;=\\; q_{j}^{n-1} \\;-\\; \\lambda\\left(q_{j+1}^{n} - q_{j-1}^{n}\\right),\n$$\nwhere the Courant number is $\\lambda \\equiv \\frac{a\\,\\Delta t}{\\Delta x}$. In addition, suppose a Robert–Asselin (RA) filter with coefficient $\\nu \\in [0,1)$ is applied after each update to damp the computational mode, defined by\n$$\nq_{j}^{n} \\;\\leftarrow\\; q_{j}^{n} \\;+\\; \\nu\\left(q_{j}^{n-1} - 2\\,q_{j}^{n} + q_{j}^{n+1}\\right).\n$$\nAssume that the discrete fields entering the update satisfy $q_{j}^{n-1} \\ge 0$ and $q_{j}^{n} \\ge 0$ for all $j$, with no further restriction on their spatial distribution. Starting from the conservation law and the given discretization, derive a condition on the Courant number $\\lambda$ (expressed as a single bound) under which the leapfrog scheme preserves nonnegativity in the sense that $q_{j}^{n+1} \\ge 0$ for all $j$ whenever $q_{j}^{n-1} \\ge 0$ and $q_{j}^{n} \\ge 0$ for all $j$. Then, analyze whether the presence of the RA filter with arbitrary fixed $\\nu \\in [0,1)$ can relax or modify this bound at the update step $n \\mapsto n+1$. Provide your final condition as a single real-valued number or a single closed-form expression for the maximal allowable Courant number $\\lambda_{\\max}(\\nu)$ that guarantees nonnegativity preservation at the update. No rounding is required, and the Courant number is dimensionless, so no physical units are needed.",
            "solution": "The problem is solved by first analyzing the unfiltered scheme for nonnegativity preservation and then considering the effect of the Robert–Asselin filter.\n\n**Part 1: Nonnegativity of the Unfiltered Leapfrog Scheme**\n\nThe leapfrog-in-time, centered-in-space scheme is given by the update rule:\n$$q_{j}^{n+1} = q_{j}^{n-1} - \\lambda(q_{j+1}^{n} - q_{j-1}^{n})$$\nWe are given that the fields at time levels $n-1$ and $n$ are non-negative, i.e., $q_{k}^{n-1} \\ge 0$ and $q_{k}^{n} \\ge 0$ for all spatial indices $k \\in \\mathbb{Z}$. The problem requires finding the condition on the Courant number $\\lambda$ that guarantees $q_{j}^{n+1} \\ge 0$ for all $j$, given that the initial data $q^{n-1}$ and $q^{n}$ can be any non-negative fields, \"with no further restriction on their spatial distribution.\"\n\nThis requires that the following inequality holds for any choice of non-negative fields $q^{n-1}$ and $q^{n}$:\n$$q_{j}^{n-1} - \\lambda(q_{j+1}^{n} - q_{j-1}^{n}) \\ge 0$$\nTo find a condition on $\\lambda$ that holds universally, we must consider the \"worst-case\" scenario that is most likely to violate this inequality. Such a scenario would seek to make the left-hand side as small (i.e., as negative) as possible.\n\nThe term $q_{j}^{n-1}$ is non-negative by assumption. To minimize the expression, we can choose a non-negative field $q^{n-1}$ where $q_j^{n-1}$ is at its minimum possible value, which is $0$. For instance, we may select the trivial field $q_{k}^{n-1} = 0$ for all $k$. This is a valid choice according to the problem statement.\n\nWith $q_{j}^{n-1} = 0$, the inequality reduces to:\n$$-\\lambda(q_{j+1}^{n} - q_{j-1}^{n}) \\ge 0$$\nThis must hold for any non-negative field $q^n$. We analyze this based on the sign of $\\lambda$, which can be positive, negative, or zero.\n\nCase 1: $\\lambda > 0$.\nThe condition becomes $q_{j+1}^{n} - q_{j-1}^{n} \\le 0$, or $q_{j+1}^{n} \\le q_{j-1}^{n}$. This inequality would have to hold for all $j$ and for any non-negative field $q^n$. This is manifestly false. We are free to choose a non-negative field $q^n$ that violates this. For a specific index $j$, consider the field defined by:\n$$\nq_{k}^{n} = \\begin{cases} 1 & \\text{if } k = j+1 \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nThis field is non-negative. For this choice, $q_{j+1}^{n} = 1$ and $q_{j-1}^{n} = 0$, so $q_{j+1}^{n} - q_{j-1}^{n} = 1 > 0$. The condition is violated. The resulting value at $j$ is $q_{j}^{n+1} = 0 - \\lambda(1 - 0) = -\\lambda$. Since $\\lambda > 0$, $q_{j}^{n+1} < 0$. Thus, no $\\lambda > 0$ can guarantee nonnegativity.\n\nCase 2: $\\lambda < 0$.\nThe condition becomes $q_{j+1}^{n} - q_{j-1}^{n} \\ge 0$, or $q_{j+1}^{n} \\ge q_{j-1}^{n}$. Again, this must hold for any non-negative field $q^n$, which is not true. Consider the counterexample field:\n$$\nq_{k}^{n} = \\begin{cases} 1 & \\text{if } k = j-1 \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nThis field is non-negative. For this choice, $q_{j+1}^{n} = 0$ and $q_{j-1}^{n} = 1$, so $q_{j+1}^{n} - q_{j-1}^{n} = -1 < 0$. The condition is violated. The resulting value at $j$ is $q_{j}^{n+1} = 0 - \\lambda(0 - 1) = \\lambda$. Since $\\lambda < 0$, $q_{j}^{n+1} < 0$. Thus, no $\\lambda < 0$ can guarantee nonnegativity.\n\nCase 3: $\\lambda = 0$.\nThe update rule becomes $q_{j}^{n+1} = q_{j}^{n-1}$. Since we assumed $q_{j}^{n-1} \\ge 0$, it follows that $q_{j}^{n+1} \\ge 0$. This condition holds.\n\nFrom this analysis, the only value of the Courant number for which the unfiltered leapfrog scheme preserves nonnegativity for arbitrary non-negative input fields is $\\lambda = 0$.\n\n**Part 2: Effect of the Robert–Asselin Filter**\n\nThe problem describes a two-step process. First, a provisional value for $q_j^{n+1}$ is computed using the leapfrog rule. Second, the RA filter updates the value at the current time level, $q_j^n$.\nThe question of whether $q_j^{n+1}$ is non-negative is determined solely by the first step:\n$$q_{j}^{n+1} = q_{j}^{n-1} - \\lambda(q_{j+1}^{n} - q_{j-1}^{n})$$\nThis equation does not involve the filter parameter $\\nu$. The filter is applied *after* $q_{j}^{n+1}$ is computed and uses this value to modify $q_j^n$. The filter, as defined, does not alter the value of $q_{j}^{n+1}$ at the current update.\n\nTherefore, the condition for ensuring $q_{j}^{n+1} \\ge 0$ is completely independent of the RA filter. The analysis from Part 1 remains unchanged. The introduction of the RA filter does not relax or modify the bound on $\\lambda$. The maximal allowable Courant number as a function of $\\nu$, $\\lambda_{\\max}(\\nu)$, is a constant function.\n$$\\lambda_{\\max}(\\nu) = 0$$",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "The leapfrog scheme, while computationally efficient and neutrally stable for oscillations, suffers from a well-known artifact: an unphysical computational mode that can corrupt the solution. This practice moves beyond analysis and into design, tasking you with creating a time filter to address this very issue. You will formulate and solve a constrained optimization problem to design a three-point filter that maximally damps the unwanted computational mode while minimizing distortion of the physical solution, providing a hands-on experience with the practical trade-offs inherent in numerical scheme development .",
            "id": "4041376",
            "problem": "You are given a discrete-time linear wave problem representative of numerical weather prediction and climate modeling. Consider a scalar complex amplitude $y(t)$ governed by the linear ordinary differential equation $dy/dt = i \\omega y$, where $\\omega$ is a real angular frequency. Discrete-time stepping schemes over a uniform time step $\\Delta t$ are defined by the following three canonical methods, whose qualitative properties are well-established in the literature:\n\n- Explicit (forward Euler): $y^{n+1} = y^n + i \\omega \\Delta t \\, y^n$.\n- Implicit (backward Euler): $y^{n+1} = y^n + i \\omega \\Delta t \\, y^{n+1}$.\n- Leapfrog: $y^{n+1} = y^{n-1} + 2 i \\omega \\Delta t \\, y^n$.\n\nThe explicit and implicit one-step methods do not introduce a time-decoupling computational mode. In contrast, the two-step leapfrog method supports two temporal eigenmodes: a physical mode and a computational mode, a consequence of the two-step time-level coupling. A common remedy is to apply a linear time filter after each leapfrog update to suppress the computational mode while preserving the physical mode properties as much as possible.\n\nDesign a minimal-order linear time filter acting on three consecutive time levels,\n$$\ny^n_{\\mathrm{filt}} = a \\, y^{n-1} + b \\, y^n + c \\, y^{n+1},\n$$\nsubject to the following constraints:\n- Constant preservation: $a + b + c = 1$.\n- Minimal phase error for the physical mode: enforce symmetry $a = c$ so that the physical mode incurs zero phase shift by the filter.\n- Nonnegativity of filter weights: $a \\ge 0$, $b \\ge 0$, $c \\ge 0$.\n\nLet the discrete oscillation frequency be $\\theta = \\omega \\Delta t$, specified in radians. Analyze the action of the filter on the two modal time sequences:\n- Physical mode sequence: $y^n = e^{i n \\theta}$.\n- Computational mode sequence: $y^n = (-1)^n e^{i n \\theta}$.\n\nUsing Fourier analysis in time, derive the physical-mode and computational-mode amplification factors of the filter, expressed as functions of $a$, $b$, $c$, and $\\theta$, and enforce the symmetry $a = c$.\n\nNow pose the design as an optimization problem: for a given $\\theta$ and a prescribed bound $\\delta$ on the allowable physical-mode amplitude loss per filter application,\n$$\n|1 - \\text{(physical-mode amplification)}| \\le \\delta,\n$$\nchoose $(a,b,c)$ that maximally damps the computational mode (i.e., minimizes the absolute value of its amplification factor) while strictly satisfying the constraints above and maintaining zero phase error on the physical mode. Express the coefficients $(a,b,c)$ in terms of an auxiliary parameter and derive the closed-form optimal choice as a function of $\\theta$ and $\\delta$. Ensure scientific realism and consistency of your assumptions.\n\nYour program must implement this design and compute, for each test case, the following outputs in this order:\n- The coefficients $a$, $b$, $c$.\n- The physical-mode amplitude factor (a real number).\n- The physical-mode phase error in radians (a real number; use $0$ when the filter is symmetric and the amplitude factor is nonnegative).\n- The computational-mode amplitude factor (a real number).\n\nAll angle inputs are in radians. There are no physical units beyond angles in this problem.\n\nTest Suite:\nProvide computations for the following $(\\theta,\\delta)$ pairs (with $\\theta$ in radians and $\\delta$ unitless amplitude-loss bound):\n1. $\\theta = 1.0$, $\\delta = 0.02$.\n2. $\\theta = 0.05$, $\\delta = 0.02$.\n3. $\\theta = 3.12$, $\\delta = 0.10$.\n4. $\\theta = 1.0$, $\\delta = 0.35$.\n5. $\\theta = 0.0$, $\\delta = 0.02$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result should itself be a list in the order\n$[a,b,c,\\text{phys\\_amp},\\text{phys\\_phase\\_error},\\text{comp\\_amp}]$.\nFor example, the overall printed output must look like\n$[[\\ldots],[\\ldots],[\\ldots],[\\ldots],[\\ldots]]$.",
            "solution": "The filter is defined as $y^n_{\\mathrm{filt}} = a y^{n-1} + b y^n + c y^{n+1}$. The constraints $a=c$ and $a+b+c=1$ simplify the filter coefficients. Substituting $c=a$ into the second constraint gives $2a+b=1$, so $b=1-2a$. The nonnegativity constraints $a, c \\ge 0$ and $b \\ge 0$ translate to $a \\ge 0$ and $1-2a \\ge 0$, which restricts the free parameter $a$ to the range $0 \\le a \\le 1/2$.\n\nFirst, we derive the filter's amplification factors. The amplification factor $\\lambda$ is defined by the relation $y^n_{\\mathrm{filt}} = \\lambda y^n$. We apply the filter to each mode.\n\n**Physical Mode:** For $y^n = e^{i n \\theta}$, the filtered value is:\n$$\ny^n_{\\mathrm{filt}} = a e^{i(n-1)\\theta} + b e^{in\\theta} + c e^{i(n+1)\\theta} = (a e^{-i\\theta} + b + c e^{i\\theta}) y^n\n$$\nThe physical mode amplification factor is $\\lambda_{\\text{phys}} = a e^{-i\\theta} + b + c e^{i\\theta}$. Using $a=c$ and $b=1-2a$:\n$$\n\\lambda_{\\text{phys}} = a(e^{-i\\theta} + e^{i\\theta}) + (1-2a) = 2a\\cos\\theta + 1 - 2a = 1 - 2a(1-\\cos\\theta)\n$$\nSince $a$ and $\\theta$ are real, $\\lambda_{\\text{phys}}$ is real. The symmetry constraint $a=c$ ensures zero phase shift.\n\n**Computational Mode:** For $y^n = (-1)^n e^{i n \\theta}$, the filtered value is:\n$$\ny^n_{\\mathrm{filt}} = a(-1)^{n-1}e^{i(n-1)\\theta} + b(-1)^n e^{in\\theta} + c(-1)^{n+1}e^{i(n+1)\\theta}\n$$\nDividing by $y^n$ gives the amplification factor:\n$$\n\\lambda_{\\text{comp}} = -a e^{-i\\theta} + b - c e^{i\\theta}\n$$\nUsing $a=c$ and $b=1-2a$:\n$$\n\\lambda_{\\text{comp}} = -a(e^{-i\\theta} + e^{i\\theta}) + (1-2a) = -2a\\cos\\theta + 1 - 2a = 1 - 2a(1+\\cos\\theta)\n$$\nThis factor is also real. The objective is to choose $a$ to minimize $|\\lambda_{\\text{comp}}|$ subject to the constraints.\n\nThe physical mode constraint is $|1 - \\lambda_{\\text{phys}}| \\le \\delta$. Substituting the expression for $\\lambda_{\\text{phys}}$ gives:\n$$\n|1 - (1 - 2a(1-\\cos\\theta))| \\le \\delta \\implies |2a(1-\\cos\\theta)| \\le \\delta\n$$\nSince $a \\ge 0$ and $1-\\cos\\theta \\ge 0$, this simplifies to $2a(1-\\cos\\theta) \\le \\delta$. If $1-\\cos\\theta > 0$, this gives an upper bound on $a$: $a \\le \\frac{\\delta}{2(1-\\cos\\theta)}$. The complete feasible range for $a$ is $0 \\le a \\le a_{\\max}$, where $a_{\\max} = \\min\\left(\\frac{1}{2}, \\frac{\\delta}{2(1-\\cos\\theta)}\\right)$ for $\\cos\\theta \\ne 1$, and $a_{\\max}=1/2$ for $\\cos\\theta=1$.\n\nThe objective function to minimize is $|\\lambda_{\\text{comp}}| = |1 - 2a(1+\\cos\\theta)|$. The unconstrained minimum of this function is $0$, which occurs at $a = a^* = \\frac{1}{2(1+\\cos\\theta)}$ (for $\\cos\\theta \\ne -1$). The optimal choice for $a$ over the constrained interval $[0, a_{\\max}]$ is the point in the interval closest to $a^*$, which is $a_{\\text{opt}} = \\min(a_{\\max}, a^*)$.\n\nThis leads to the closed-form solution for the optimal coefficient $a$:\n$$\na_{\\text{opt}} = \\min\\left( \\frac{1}{2}, \\frac{\\delta}{2(1-\\cos\\theta)}, \\frac{1}{2(1+\\cos\\theta)} \\right)\n$$\nThis general form covers the cases where $\\cos\\theta \\ne \\pm 1$. The special cases are handled as follows:\n- If $\\cos\\theta=1$ (e.g., $\\theta=0$), the constraint from $\\delta$ is removed, and $\\lambda_{\\text{comp}} = 1-4a$. To minimize $|1-4a|$ on $[0, 1/2]$, we choose $a_{\\text{opt}} = 1/4$.\n- If $\\cos\\theta=-1$ (e.g., $\\theta=\\pi$), $\\lambda_{\\text{comp}}=1$ and cannot be damped. The optimal choice is the largest allowed value, $a_{\\text{opt}} = \\min(1/2, \\delta/4)$.\n\nThese derived coefficients are then used to calculate the required outputs for each test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the optimal time filter coefficients and their properties\n    for a given set of test cases.\n    \"\"\"\n    # Test cases: (theta, delta) pairs\n    test_cases = [\n        (1.0, 0.02),\n        (0.05, 0.02),\n        (3.12, 0.10),\n        (1.0, 0.35),\n        (0.0, 0.02)\n    ]\n\n    results = []\n    # Small number to handle floating point comparisons\n    epsilon = 1e-12\n\n    for theta, delta in test_cases:\n        cos_theta = np.cos(theta)\n        \n        # Determine the optimal coefficient 'a' based on the optimization problem\n        if abs(1.0 - cos_theta) < epsilon:\n            # Special case: theta = 2k*pi, cos(theta) = 1\n            # Physical mode constraint is always satisfied.\n            # Lambda_comp = 1 - 4a. Minimized at a = 1/4.\n            a = 0.25\n        elif abs(1.0 + cos_theta) < epsilon:\n            # Special case: theta = (2k+1)*pi, cos(theta) = -1\n            # Lambda_comp = 1, cannot be damped.\n            # a_star is undefined. We choose the largest 'a' allowed\n            # by other constraints.\n            a = min(0.5, delta / 4.0)\n        else:\n            # General case\n            # Constraint from physical mode damping\n            a_from_delta = delta / (2.0 * (1.0 - cos_theta))\n            \n            # Constraint from non-negativity of b (b = 1-2a >= 0 -> a <= 0.5)\n            a_from_b = 0.5\n            \n            # Value of 'a' that makes computational mode amplification zero\n            a_star = 1.0 / (2.0 * (1.0 + cos_theta))\n            \n            # The optimal 'a' is the smallest of these three values, as it must satisfy\n            # all constraints and be as close as possible to a_star to minimize |lambda_comp|\n            a = min(a_from_delta, a_from_b, a_star)\n\n        # The other coefficients are derived from 'a'\n        c = a\n        b = 1.0 - 2.0 * a\n\n        # Calculate the amplification factors for the physical and computational modes.\n        # With the chosen 'a', these are guaranteed to be real.\n        phys_amp_complex = 1.0 - 2.0 * a * (1.0 - cos_theta)\n        comp_amp_complex = 1.0 - 2.0 * a * (1.0 + cos_theta)\n\n        # \"Amplitude factor\" is the magnitude of the complex amplification factor.\n        # Our derivation shows both factors are non-negative for the optimal 'a'.\n        # Using abs() is the most robust implementation.\n        phys_amp = abs(phys_amp_complex)\n        comp_amp = abs(comp_amp_complex)\n\n        # The phase error for the physical mode is the argument of its amplification factor.\n        # Since the filter is symmetric and the amplification factor is real and non-negative,\n        # the phase error is zero, as specified in the problem.\n        phys_phase_error = 0.0\n        \n        current_result = [a, b, c, phys_amp, phys_phase_error, comp_amp]\n        results.append(current_result)\n\n    # Format the final output string to match the required format precisely.\n    # e.g., [[val1,val2,...],[val1,val2,...]] with no spaces.\n    list_of_strs = []\n    for res in results:\n        list_of_strs.append(f\"[{','.join(map(str, res))}]\")\n    \n    print(f\"[{','.join(list_of_strs)}]\")\n\nsolve()\n```"
        }
    ]
}