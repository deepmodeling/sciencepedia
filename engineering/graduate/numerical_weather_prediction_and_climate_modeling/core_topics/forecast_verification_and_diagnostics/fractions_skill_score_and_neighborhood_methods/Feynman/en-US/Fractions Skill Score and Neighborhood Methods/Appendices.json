{
    "hands_on_practices": [
        {
            "introduction": "To truly understand how the Fractions Skill Score (FSS) works, it's helpful to apply it to an extreme case. This exercise  presents a 'worst-case' scenario of high-frequency error: a forecast that is merely a one-grid-cell shift of a perfect checkerboard observation. By deriving the FSS analytically, you will gain a fundamental understanding of how neighborhood averaging smooths out spatial errors and how skill systematically improves as the verification scale increases.",
            "id": "4045627",
            "problem": "Consider an infinite two-dimensional periodic square grid with unit grid spacing and binary fields defined on gridpoint centers. Let the observed binary field $O(i,j)$ be a perfect checkerboard such that $O(i,j) = 1$ if $i+j$ is even and $O(i,j) = 0$ if $i+j$ is odd, for all integers $i$ and $j$. The forecast binary field is a one-gridpoint shift of the observed field in the $x$-direction, $F(i,j) = O(i+1,j)$. You will evaluate the Fractions Skill Score (FSS) under the neighborhood method using square windows.\n\nDefine the neighborhood fractions $o_{s}(i,j)$ and $f_{s}(i,j)$ as the mean of $O$ and $F$, respectively, over the $s \\times s$ square of gridpoints centered at $(i,j)$, where $s \\in \\mathbb{N}$ is the window side length measured in gridpoints. Assume periodicity so that window sums are well-defined at every $(i,j)$. Define the Fractions Skill Score (FSS) for window size $s$ as\n$$\n\\mathrm{FSS}(s) \\equiv 1 - \\frac{\\mathrm{MSE}(s)}{\\mathrm{MSE}_{\\mathrm{ref}}(s)},\n$$\nwhere\n$$\n\\mathrm{MSE}(s) \\equiv \\lim_{N \\to \\infty} \\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\left(f_{s}(i,j) - o_{s}(i,j)\\right)^{2},\n$$\nand\n$$\n\\mathrm{MSE}_{\\mathrm{ref}}(s) \\equiv \\lim_{N \\to \\infty} \\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\left(f_{s}(i,j)^{2} + o_{s}(i,j)^{2}\\right).\n$$\n\nStarting from these definitions and using only fundamental properties of averages and periodicity, derive a closed-form analytic expression for $\\mathrm{FSS}(s)$ that is valid for all integer $s \\geq 1$. Then, adopting the widely used operational definition of the “useful scale” as the smallest $s$ such that $\\mathrm{FSS}(s)$ exceeds the base-rate-dependent threshold\n$$\nT \\equiv \\frac{1}{2} + \\frac{f}{2},\n$$\nwhere $f$ is the domain-mean of $O$ at the native grid scale, determine the useful scale $s^{\\ast}$ for this configuration.\n\nProvide two outputs: (i) the analytic expression for $\\mathrm{FSS}(s)$ valid for all integer $s \\geq 1$, and (ii) the smallest integer $s^{\\ast}$ meeting the above threshold criterion. No rounding is required. The final answer must be presented as a two-entry row matrix as specified.",
            "solution": "The problem asks for an analytical expression for the Fractions Skill Score, $\\mathrm{FSS}(s)$, for a specific configuration of observed and forecast fields, and for the \"useful scale\" $s^{\\ast}$ derived from it.\n\nThe observed field is a checkerboard pattern, $O(i,j) = 1$ if $i+j$ is even and $O(i,j) = 0$ if $i+j$ is odd. The forecast field is a one-gridpoint shift, $F(i,j) = O(i+1,j)$.\n\nFirst, we establish a relationship between the fields $O(i,j)$ and $F(i,j)$.\nThe value of $O(i,j)$ depends on the parity of $i+j$.\nThe value of $F(i,j) = O(i+1,j)$ depends on the parity of $(i+1)+j = (i+j)+1$.\nIf $i+j$ is even, $O(i,j)=1$. Then $(i+j)+1$ is odd, so $F(i,j)=O(i+1,j)=0$.\nIf $i+j$ is odd, $O(i,j)=0$. Then $(i+j)+1$ is even, so $F(i,j)=O(i+1,j)=1$.\nIn both cases, $F(i,j) = 1 - O(i,j)$. The forecast field is the complement of the observed field.\n\nThe neighborhood fractions, $o_{s}(i,j)$ and $f_{s}(i,j)$, are the means of $O$ and $F$ over an $s \\times s$ window. Due to the linearity of the averaging operator, a similar relationship holds for the fractions:\n$$f_{s}(i,j) = \\frac{1}{s^2} \\sum_{\\text{window}} F(k,l) = \\frac{1}{s^2} \\sum_{\\text{window}} (1 - O(k,l)) = 1 - \\frac{1}{s^2} \\sum_{\\text{window}} O(k,l) = 1 - o_{s}(i,j)$$\n\nNow we can rewrite the Mean Squared Error (MSE) terms. The notation $\\langle \\cdot \\rangle$ will be used for the spatial average $\\lim_{N \\to \\infty} \\frac{1}{N^{2}} \\sum_{i=1}^{N} \\sum_{j=1}^{N} (\\cdot)$.\n$$\\mathrm{MSE}(s) = \\langle (f_{s}(i,j) - o_{s}(i,j))^2 \\rangle = \\langle (1 - o_{s}(i,j) - o_{s}(i,j))^2 \\rangle = \\langle (1 - 2o_{s}(i,j))^2 \\rangle$$\n$$\\mathrm{MSE}_{\\mathrm{ref}}(s) = \\langle f_{s}(i,j)^2 + o_{s}(i,j)^2 \\rangle = \\langle (1 - o_{s}(i,j))^2 + o_{s}(i,j)^2 \\rangle$$\n\nExpanding these expressions:\n$$\\mathrm{MSE}(s) = \\langle 1 - 4o_{s}(i,j) + 4o_{s}(i,j)^2 \\rangle = 1 - 4 \\langle o_{s} \\rangle + 4 \\langle o_{s}^2 \\rangle$$\n$$\\mathrm{MSE}_{\\mathrm{ref}}(s) = \\langle 1 - 2o_{s}(i,j) + 2o_{s}(i,j)^2 \\rangle = 1 - 2 \\langle o_{s} \\rangle + 2 \\langle o_{s}^2 \\rangle$$\nTo proceed, we need to compute the spatial averages $\\langle o_s \\rangle$ and $\\langle o_s^2 \\rangle$.\n\nThe average of theconvolved field $o_s$ is the average of the original field $O$. The field $O$ consists of equal numbers of $1$s and $0$s. Therefore, its spatial average is $\\frac{1}{2}$.\n$$\\langle O \\rangle = \\frac{1}{2} \\implies \\langle o_s \\rangle = \\frac{1}{2} \\text{ for any } s \\ge 1$$\n\nThe calculation of $\\langle o_s^2 \\rangle$ depends on the parity of the window size $s$.\n\nCase 1: $s$ is even.\nLet $s=2k$ for some integer $k \\ge 1$. An $s \\times s$ window can be perfectly tiled by $k^2$ non-overlapping $2 \\times 2$ blocks. In a checkerboard grid, any $2 \\times 2$ block of grid points contains exactly two points where $O=1$ and two points where $O=0$. Thus, the sum of $O$ over a $2 \\times 2$ block is $2$. The sum of $O$ over an $s \\times s$ window is $k^2 \\times 2 = (s/2)^2 \\times 2 = s^2/2$.\nThe fraction of $1$s in any $s \\times s$ window is constant:\n$$o_{s}(i,j) = \\frac{s^2/2}{s^2} = \\frac{1}{2} \\quad (\\text{for } s \\text{ even})$$\nSince $o_s(i,j)$ is a constant, its average is $\\langle o_s \\rangle = \\frac{1}{2}$ and its mean square is $\\langle o_s^2 \\rangle = (\\frac{1}{2})^2 = \\frac{1}{4}$.\nNow we find the MSE terms for even $s$:\n$$\\mathrm{MSE}(s) = 1 - 4(\\frac{1}{2}) + 4(\\frac{1}{4}) = 1 - 2 + 1 = 0$$\n$$\\mathrm{MSE}_{\\mathrm{ref}}(s) = 1 - 2(\\frac{1}{2}) + 2(\\frac{1}{4}) = 1 - 1 + \\frac{1}{2} = \\frac{1}{2}$$\nThe FSS for even $s$ is:\n$$\\mathrm{FSS}(s) = 1 - \\frac{\\mathrm{MSE}(s)}{\\mathrm{MSE}_{\\mathrm{ref}}(s)} = 1 - \\frac{0}{1/2} = 1$$\n\nCase 2: $s$ is odd.\nLet $s=2k+1$ for some integer $k \\ge 0$. The total number of points in the window is $s^2$. In this case, the number of $1$s and $0$s is not equal.\nFor a window centered at $(i,j)$, if $O(i,j)=1$ (i.e., $i+j$ is even), the window contains $\\frac{s^2+1}{2}$ points with value $1$. If $O(i,j)=0$ (i.e., $i+j$ is odd), it contains $\\frac{s^2-1}{2}$ points with value $1$.\nSo, $o_s(i,j)$ takes on two possible values:\n$$o_s(i,j) = \\frac{s^2+1}{2s^2} \\quad \\text{if } i+j \\text{ is even}$$\n$$o_s(i,j) = \\frac{s^2-1}{2s^2} \\quad \\text{if } i+j \\text{ is odd}$$\nSince $i+j$ is even for half the grid points and odd for the other half, the spatial average $\\langle o_s^2 \\rangle$ is:\n$$\\langle o_s^2 \\rangle = \\frac{1}{2} \\left( \\frac{s^2+1}{2s^2} \\right)^2 + \\frac{1}{2} \\left( \\frac{s^2-1}{2s^2} \\right)^2$$\n$$\\langle o_s^2 \\rangle = \\frac{1}{2 \\cdot 4s^4} \\left[ (s^4+2s^2+1) + (s^4-2s^2+1) \\right] = \\frac{1}{8s^4} (2s^4+2) = \\frac{s^4+1}{4s^4}$$\nNow we find the MSE terms for odd $s$:\n$$\\mathrm{MSE}(s) = 1 - 4(\\frac{1}{2}) + 4\\left(\\frac{s^4+1}{4s^4}\\right) = 1 - 2 + \\frac{s^4+1}{s^4} = -1 + 1 + \\frac{1}{s^4} = \\frac{1}{s^4}$$\n$$\\mathrm{MSE}_{\\mathrm{ref}}(s) = 1 - 2(\\frac{1}{2}) + 2\\left(\\frac{s^4+1}{4s^4}\\right) = 1 - 1 + \\frac{s^4+1}{2s^4} = \\frac{s^4+1}{2s^4}$$\nThe FSS for odd $s$ is:\n$$\\mathrm{FSS}(s) = 1 - \\frac{1/s^4}{(s^4+1)/(2s^4)} = 1 - \\frac{2s^4}{s^4(s^4+1)} = 1 - \\frac{2}{s^4+1} = \\frac{s^4+1-2}{s^4+1} = \\frac{s^4-1}{s^4+1}$$\n\nTo provide a single analytic expression for all integer $s \\ge 1$:\n$$ \\mathrm{FSS}(s) = \\begin{cases} \\frac{s^4-1}{s^4+1} & \\text{if } s \\text{ is odd} \\\\ 1 & \\text{if } s \\text{ is even} \\end{cases} $$\nThis can be unified using the term $(-1)^s$:\n$$\\mathrm{FSS}(s) = \\frac{s^4+(-1)^s}{s^4+1}$$\nThis expression correctly yields $1$ for even $s$ and $\\frac{s^4-1}{s^4+1}$ for odd $s$.\n\nNext, we determine the useful scale $s^{\\ast}$. This is the smallest integer $s$ such that $\\mathrm{FSS}(s) > T$, where $T = \\frac{1}{2} + \\frac{f}{2}$.\nThe base rate $f$ is the domain-mean of $O$ at the native scale, which is $f = \\langle O \\rangle = \\frac{1}{2}$.\nThe threshold is $T = \\frac{1}{2} + \\frac{1/2}{2} = \\frac{1}{2} + \\frac{1}{4} = \\frac{3}{4}$.\n\nWe seek the smallest integer $s \\ge 1$ such that $\\mathrm{FSS}(s) > \\frac{3}{4}$.\nLet's test small integer values of $s$:\nFor $s=1$ (odd):\n$$\\mathrm{FSS}(1) = \\frac{1^4-1}{1^4+1} = 0$$\n$0 \\ngtr \\frac{3}{4}$, so $s=1$ is not the useful scale.\nFor $s=2$ (even):\n$$\\mathrm{FSS}(2) = 1$$\n$1 > \\frac{3}{4}$, so $s=2$ meets the criterion.\nSince we are looking for the smallest integer $s$, and we have found that $s=2$ satisfies the condition while $s=1$ does not, the useful scale is $s^{\\ast}=2$.\n\nThe two required outputs are the expression for $\\mathrm{FSS}(s)$ and the value of $s^{\\ast}$.\n(i) $\\mathrm{FSS}(s) = \\frac{s^4+(-1)^s}{s^4+1}$\n(ii) $s^{\\ast}=2$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{s^4+(-1)^s}{s^4+1} & 2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Forecasts often exhibit systematic biases, such as predicting an event area that is too large or too small. This practice  explores the effect of such an area bias on the FSS in a clear, one-dimensional setting. Through this analytical derivation, you will not only quantify how the score is impacted by the bias but also learn how to implement a bias-correction to obtain a fairer measure of the forecast's spatial placement skill.",
            "id": "4045671",
            "problem": "Consider a one-dimensional idealized transect representation of a binary precipitation-exceedance event used to illustrate neighborhood methods in numerical weather prediction and climate modeling. Let the true observed event occupy the interval $\\left[-R, R\\right] \\subset \\mathbb{R}$ and the forecast event (which overpredicts the event extent by a factor of two) occupy the interval $\\left[-2R, 2R\\right]$, both centered at the origin. For a sliding neighborhood window of half-width $L>0$, define the window fraction $f_w$ at location $x \\in \\mathbb{R}$ as the fraction of the window $\\left[x-L, x+L\\right]$ covered by the event, i.e., $f_w(x) = \\frac{1}{2L} \\left|\\left[x-L, x+L\\right] \\cap \\text{event}\\right|$. Denote by $f_w^{(O)}(x)$ and $f_w^{(F)}(x)$ the observed and forecast window-fraction fields, respectively.\n\nStarting from the geometric definition of $f_w$ and the continuous-domain definition of the Fractions Skill Score (FSS) for neighborhood methods,\n$$\n\\mathrm{FSS}(L) \\equiv \\frac{2 \\int_{\\mathbb{R}} f_w^{(F)}(x)\\, f_w^{(O)}(x)\\, dx}{\\int_{\\mathbb{R}} \\left(f_w^{(F)}(x)\\right)^{2}\\, dx + \\int_{\\mathbb{R}} \\left(f_w^{(O)}(x)\\right)^{2}\\, dx},\n$$\nderive how $f_w^{(O)}(x)$ and $f_w^{(F)}(x)$ vary with the window size under the regime $0 < L \\leq \\frac{R}{2}$, and then obtain a closed-form expression for $\\mathrm{FSS}(L)$ in terms of $L$ and $R$.\n\nFinally, to interpret skill fairly in the presence of the known area bias, propose an area-bias correction that rescales the forecast window fraction by the known bias factor $b=2$ to equalize mean coverage (i.e., use the debiased forecast fraction $\\tilde{f}_w^{(F)}(x) = \\frac{1}{b} f_w^{(F)}(x)$), and derive the corresponding closed-form expression for the bias-corrected Fractions Skill Score\n$$\n\\mathrm{FSS}_{\\mathrm{corr}}(L) \\equiv \\frac{2 \\int_{\\mathbb{R}} \\tilde{f}_w^{(F)}(x)\\, f_w^{(O)}(x)\\, dx}{\\int_{\\mathbb{R}} \\left(\\tilde{f}_w^{(F)}(x)\\right)^{2}\\, dx + \\int_{\\mathbb{R}} \\left(f_w^{(O)}(x)\\right)^{2}\\, dx}.\n$$\n\nExpress both final formulas for $\\mathrm{FSS}(L)$ and $\\mathrm{FSS}_{\\mathrm{corr}}(L)$ as analytic functions of $L$ and $R$. No rounding is required. The final answer must be presented as a single row matrix containing these two expressions, in exact form without units.",
            "solution": "### 1. Derivation of Window Fraction Fields\n\nFirst, we determine the analytical form of the window fraction fields, $f_w^{(O)}(x)$ for the observed event $E_O = [-R, R]$ and $f_w^{(F)}(x)$ for the forecast event $E_F = [-2R, 2R]$. The fraction $f_w(x)$ at a location $x$ is the length of the intersection of the window $[x-L, x+L]$ and the event interval, divided by the window length $2L$. This results in symmetric trapezoidal functions.\n\nFor the observed field $f_w^{(O)}(x)$:\n- For $|x| \\leq R-L$: $f_w^{(O)}(x) = 1$ (window fully inside the event).\n- For $R-L < |x| < R+L$: $f_w^{(O)}(x)$ decreases linearly from 1 to 0. Specifically, $f_w^{(O)}(x) = \\frac{R+L-|x|}{2L}$.\n- For $|x| \\geq R+L$: $f_w^{(O)}(x) = 0$ (window fully outside the event).\n\nThe forecast field $f_w^{(F)}(x)$ has the same functional form, with $R$ replaced by $2R$.\n\n### 2. Calculation of Integrals for FSS(L)\n\nThe FSS formula requires three integrals. We can integrate from $0$ to $\\infty$ and multiply by $2$ due to symmetry.\n\n- **Mean Square Observed Fraction:** $I_O \\equiv \\int_{\\mathbb{R}} (f_w^{(O)}(x))^2 dx$\n  $$ I_O = 2 \\left[ \\int_{0}^{R-L} 1^2 \\,dx + \\int_{R-L}^{R+L} \\left(\\frac{R+L-x}{2L}\\right)^2 \\,dx \\right] = 2 \\left[ (R-L) + \\frac{2L}{3} \\right] = 2R - \\frac{2L}{3} $$\n\n- **Mean Square Forecast Fraction:** $I_F \\equiv \\int_{\\mathbb{R}} (f_w^{(F)}(x))^2 dx$\n  This has the same structure as $I_O$, but with $R$ replaced by $2R$:\n  $$ I_F = 2(2R) - \\frac{2L}{3} = 4R - \\frac{2L}{3} $$\n\n- **Cross-Product Term:** $I_{FO} \\equiv \\int_{\\mathbb{R}} f_w^{(F)}(x) f_w^{(O)}(x) dx$\n  The problem states the regime $0 < L \\leq \\frac{R}{2}$, which implies $R+L \\leq 2R-L$. The function $f_w^{(O)}(x)$ is non-zero only for $|x| < R+L$. Within this range, $|x| < 2R-L$, which means $f_w^{(F)}(x)$ is always equal to $1$. Therefore, the integral simplifies to the area under the $f_w^{(O)}(x)$ curve:\n  $$ I_{FO} = \\int_{\\mathbb{R}} 1 \\cdot f_w^{(O)}(x) \\,dx = 2R $$\n  This is because the integral of a window fraction field over the entire domain equals the size of the original event.\n\n### 3. Derivation of FSS(L)\n\nSubstituting the integrals into the FSS definition:\n$$ \\mathrm{FSS}(L) = \\frac{2 I_{FO}}{I_F + I_O} = \\frac{2(2R)}{(4R - \\frac{2L}{3}) + (2R - \\frac{2L}{3})} = \\frac{4R}{6R - \\frac{4L}{3}} = \\frac{12R}{18R - 4L} = \\frac{6R}{9R - 2L} $$\n\n### 4. Derivation of FSS_corr(L)\n\nFor the bias-corrected score, we use the debiased forecast fraction $\\tilde{f}_w^{(F)}(x) = \\frac{1}{b} f_w^{(F)}(x) = \\frac{1}{2} f_w^{(F)}(x)$. The required integrals are scaled versions of our previous results:\n- Numerator integral: $\\int \\tilde{f}_w^{(F)} f_w^{(O)} dx = \\frac{1}{2} I_{FO} = R$.\n- Denominator integral 1: $\\int (\\tilde{f}_w^{(F)})^2 dx = \\frac{1}{4} I_F = \\frac{1}{4}(4R - \\frac{2L}{3}) = R - \\frac{L}{6}$.\n- Denominator integral 2: $\\int (f_w^{(O)})^2 dx = I_O = 2R - \\frac{2L}{3}$.\n\nSubstituting these into the $\\mathrm{FSS}_{\\mathrm{corr}}(L)$ formula:\n$$ \\mathrm{FSS}_{\\mathrm{corr}}(L) = \\frac{2(R)}{(R - \\frac{L}{6}) + (2R - \\frac{2L}{3})} = \\frac{2R}{3R - \\frac{5L}{6}} = \\frac{12R}{18R - 5L} $$\nThis completes the derivation.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{6R}{9R - 2L} & \\frac{12R}{18R - 5L}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "This final practice transitions from analytical derivations to a full computational application within the realistic context of ensemble forecasting. The goal is to move beyond a single FSS value and instead compute FSS across a range of scales to determine the 'useful scale'—the smallest scale at which a forecast provides meaningful skill. By applying this methodology  to both individual ensemble members and the ensemble mean, you will develop practical skills for interpreting ensemble performance and consistency.",
            "id": "4045696",
            "problem": "You are given a gridded event field representing the occurrence of a meteorological phenomenon (e.g., thresholded precipitation \"yes/no\") and an ensemble of forecast fields, each represented as a binary array where the value $1$ denotes event occurrence and $0$ denotes non-occurrence. Your task is to construct a method to compute the \"useful scale\" for each ensemble member and for the ensemble mean using a neighborhood-based evaluation with the Fraction Skill Score (FSS), and to compare the distributions of useful scales across ensemble members.\n\nThe fundamental base in this setting consists of the following definitions and well-tested formulas:\n\n1. Let the forecast field be a binary array $F \\in \\{0,1\\}^{N_x \\times N_y}$ and the observation field be a binary array $O \\in \\{0,1\\}^{N_x \\times N_y}$.\n\n2. For a given neighborhood scale $s$ (in kilometers), and grid spacing $\\Delta x$ (in kilometers), define an odd integer window width in grid cells $w(s)$ by choosing the odd integer closest to $s/\\Delta x$. Given a square averaging kernel $K_s$ with $K_s(i,j) = 1$ for $-r \\le i,j \\le r$ where $w(s) = 2r+1$, define the neighborhood fraction fields $f_s$ and $o_s$ by discrete convolution\n   $$\n   f_s = \\frac{1}{w(s)^2} \\left( K_s * F \\right), \\quad o_s = \\frac{1}{w(s)^2} \\left( K_s * O \\right),\n   $$\n   where $*$ denotes two-dimensional discrete convolution and reflective boundary conditions are used so that values at the edges are treated by symmetric reflection.\n\n3. The Fraction Skill Score (FSS) at scale $s$ is defined by the normalized mean squared error formula\n   $$\n   \\mathrm{FSS}(s) = 1 - \\frac{\\sum_{i=1}^{N_x} \\sum_{j=1}^{N_y} \\left( f_s(i,j) - o_s(i,j) \\right)^2}{\\sum_{i=1}^{N_x} \\sum_{j=1}^{N_y} \\left( f_s(i,j)^2 + o_s(i,j)^2 \\right)}.\n   $$\n   If the denominator is zero (which can occur only when both $f_s$ and $o_s$ are identically zero), define $\\mathrm{FSS}(s) = 1$.\n\n4. For an ensemble of $M$ members $\\{F^{(m)}\\}_{m=1}^M$, define the ensemble mean field $E$ by\n   $$\n   E = \\frac{1}{M} \\sum_{m=1}^M F^{(m)},\n   $$\n   which is a real-valued field in $[0,1]^{N_x \\times N_y}$. At scale $s$, compute the smoothed ensemble mean fraction field $e_s$ by\n   $$\n   e_s = \\frac{1}{w(s)^2} \\left( K_s * E \\right),\n   $$\n   and compute $\\mathrm{FSS}_{\\text{mean}}(s)$ by replacing $f_s$ with $e_s$ in the Fraction Skill Score formula.\n\n5. Given a critical skill threshold $q \\in (0,1)$, define the useful scale $s^\\ast$ for a forecast (either a single member or the ensemble mean) as\n   $$\n   s^\\ast = \\min \\{ s \\in \\mathcal{S} : \\mathrm{FSS}(s) \\ge q \\},\n   $$\n   where $\\mathcal{S}$ is the set of tested scales. If no tested scale meets or exceeds the threshold, set $s^\\ast = \\max(\\mathcal{S})$.\n\nImplement a program that applies these definitions and computes, for each provided test case:\n- The useful scale for the ensemble mean, expressed in kilometers.\n- The median useful scale across ensemble members, expressed in kilometers.\n- The variance of the useful scales across ensemble members, expressed in square kilometers.\n\nUse the neighborhood method as defined above and the Fraction Skill Score (FSS) to compute useful scales. Reflective boundary conditions must be used during convolution. All outputs must be expressed in kilometers (for variance, square kilometers) without percentage signs. Angles are not involved. The program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, aggregating the results from all test cases as a list of lists in the form\n\"[ [case1_mean,case1_median,case1_variance], [case2_mean,case2_median,case2_variance], [case3_mean,case3_median,case3_variance] ]\"\nwith all entries being floats.\n\nTest Suite:\n\nAll test cases use a grid of size $N_x = N_y = 64$ with grid spacing $\\Delta x = 2$ kilometers. The observation and ensemble members are disks (filled circles) defined by a center $(c_x,c_y)$ in grid indices and a radius $R$ in grid cells. A disk of radius $R$ cells means all grid points $(i,j)$ satisfying $(i - c_x)^2 + (j - c_y)^2 \\le R^2$ are assigned the value $1$, otherwise $0$.\n\n- Test Case 1 (general case with varying member errors):\n  - Observation: center $(32,32)$, radius $R_O = 8$.\n  - Ensemble members (each specified as $(c_x,c_y,R)$):\n    $$\n    \\{(27,28,8), (29,34,9), (34,31,7), (36,35,9), (30,37,8), (38,26,10), (32,32,8), (33,33,8), (31,30,8), (35,28,7), (26,37,11), (37,38,10)\\}.\n    $$\n  - Tested scales in kilometers: $\\mathcal{S} = [2, 6, 10, 14, 18, 22, 26]$.\n  - Critical threshold: $q = 0.5$.\n\n- Test Case 2 (perfect forecasts):\n  - Observation: center $(30,30)$, radius $R_O = 6$.\n  - Ensemble members: six identical copies of the observation $(30,30,6)$.\n  - Tested scales in kilometers: $\\mathcal{S} = [2, 4, 6, 8, 10]$.\n  - Critical threshold: $q = 0.7$.\n\n- Test Case 3 (poor forecasts far from the observation):\n  - Observation: center $(28,35)$, radius $R_O = 10$.\n  - Ensemble members:\n    $$\n    \\{(5,5,4), (55,55,4), (5,55,4), (55,5,4), (10,50,3), (50,10,3), (20,20,3), (44,44,3)\\}.\n    $$\n  - Tested scales in kilometers: $\\mathcal{S} = [2, 10, 18, 26, 34]$.\n  - Critical threshold: $q = 0.5$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[[result1_case1,result2_case1,result3_case1],[result1_case2,result2_case2,result3_case2],[result1_case3,result2_case3,result3_case3]]\"), where each \"result\" is a float as defined above, in kilometers for the first two entries and in square kilometers for the third entry in each case.",
            "solution": "The solution implements a computational methodology that proceeds in a sequence of well-defined steps, adhering strictly to the provided definitions.\n\nFirst, for each test case, the binary grid fields for the observation and each ensemble member are constructed. The grid has dimensions $N_x = 64, N_y = 64$, with a grid spacing of $\\Delta x = 2$ km. An event, represented as a filled circle (disk), is defined by its center $(c_x, c_y)$ and radius $R$. A grid cell at integer coordinates $(j, i)$ (column, row) is assigned a value of $1$ if the condition $(j-c_x)^2 + (i-c_y)^2 \\le R^2$ is met, and $0$ otherwise.\n\nSecond, the Fractions Skill Score, $\\mathrm{FSS}(s)$, is computed for a set of specified neighborhood scales $\\mathcal{S}$. This requires several sub-steps for each scale $s \\in \\mathcal{S}$:\n\n1.  The neighborhood window width, $w(s)$, is determined as the odd integer closest to the ratio $s/\\Delta x$.\n2.  The neighborhood fraction fields are generated. For an observation field $O$ and a forecast field $F$ (which can be a single ensemble member $F^{(m)}$ or the ensemble mean $E$), the fraction fields $o_s$ and $f_s$ (or $e_s$ for the ensemble mean) are computed. This is done via a two-dimensional discrete convolution with a square kernel of size $w(s) \\times w(s)$ consisting of ones, using reflective boundary conditions. The result is normalized by the kernel's area, $w(s)^2$.\n3.  The $\\mathrm{FSS}(s)$ is calculated using the provided formula:\n    $$ \\mathrm{FSS}(s) = 1 - \\frac{\\mathrm{MSE}(s)}{\\mathrm{MSE}_{\\mathrm{ref}}(s)} = 1 - \\frac{\\sum ( f_s - o_s )^2}{\\sum ( f_s^2 + o_s^2 )} $$\n    If the denominator is zero, $\\mathrm{FSS}(s)$ is set to 1.\n\nThird, the \"useful scale,\" $s^\\ast$, is determined for each forecast. Given a critical skill threshold $q$, the useful scale is the smallest scale $s \\in \\mathcal{S}$ for which $\\mathrm{FSS}(s) \\ge q$. If no scale meets the threshold, $s^\\ast$ is set to the maximum tested scale, $\\max(\\mathcal{S})$. This procedure is applied to each ensemble member to get a set of useful scales $\\{s^\\ast_m\\}$, and to the ensemble mean forecast $E$ to get its useful scale $s^\\ast_{\\text{mean}}$.\n\nFinally, the required output statistics are computed for each test case:\n1.  The useful scale for the ensemble mean, $s^\\ast_{\\text{mean}}$.\n2.  The median of the useful scales across the individual ensemble members, $\\mathrm{median}(\\{s^\\ast_m\\})$.\n3.  The variance of the useful scales across the individual ensemble members, $\\mathrm{var}(\\{s^\\ast_m\\})$.\n\nThe entire process is implemented in a program using the `NumPy` library for array manipulations and the `SciPy` library for the convolution operation, as shown in the answer.",
            "answer": "```python\nimport numpy as np\nfrom scipy.ndimage import convolve\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"grid_size\": (64, 64),\n            \"dx_km\": 2.0,\n            \"obs_params\": {\"center\": (32, 32), \"radius\": 8},\n            \"ensemble_params\": [\n                {\"center\": (27, 28), \"radius\": 8}, {\"center\": (29, 34), \"radius\": 9},\n                {\"center\": (34, 31), \"radius\": 7}, {\"center\": (36, 35), \"radius\": 9},\n                {\"center\": (30, 37), \"radius\": 8}, {\"center\": (38, 26), \"radius\": 10},\n                {\"center\": (32, 32), \"radius\": 8}, {\"center\": (33, 33), \"radius\": 8},\n                {\"center\": (31, 30), \"radius\": 8}, {\"center\": (35, 28), \"radius\": 7},\n                {\"center\": (26, 37), \"radius\": 11}, {\"center\": (37, 38), \"radius\": 10},\n            ],\n            \"scales_km\": np.array([2.0, 6.0, 10.0, 14.0, 18.0, 22.0, 26.0]),\n            \"q\": 0.5,\n        },\n        {\n            \"grid_size\": (64, 64),\n            \"dx_km\": 2.0,\n            \"obs_params\": {\"center\": (30, 30), \"radius\": 6},\n            \"ensemble_params\": [\n                {\"center\": (30, 30), \"radius\": 6} for _ in range(6)\n            ],\n            \"scales_km\": np.array([2.0, 4.0, 6.0, 8.0, 10.0]),\n            \"q\": 0.7,\n        },\n        {\n            \"grid_size\": (64, 64),\n            \"dx_km\": 2.0,\n            \"obs_params\": {\"center\": (28, 35), \"radius\": 10},\n            \"ensemble_params\": [\n                {\"center\": (5, 5), \"radius\": 4}, {\"center\": (55, 55), \"radius\": 4},\n                {\"center\": (5, 55), \"radius\": 4}, {\"center\": (55, 5), \"radius\": 4},\n                {\"center\": (10, 50), \"radius\": 3}, {\"center\": (50, 10), \"radius\": 3},\n                {\"center\": (20, 20), \"radius\": 3}, {\"center\": (44, 44), \"radius\": 3},\n            ],\n            \"scales_km\": np.array([2.0, 10.0, 18.0, 26.0, 34.0]),\n            \"q\": 0.5,\n        }\n    ]\n    \n    all_results = []\n    \n    for case in test_cases:\n        all_results.append(solve_case(case))\n        \n    # Format the final output string exactly as required\n    inner_parts = [f\"[{','.join(map(str, r))}]\" for r in all_results]\n    final_output = f\"[{','.join(inner_parts)}]\"\n    print(final_output)\n\ndef create_disk_field(grid_size, center, radius):\n    \"\"\"\n    Creates a binary grid with a filled circle (disk).\n    \n    Args:\n        grid_size (tuple): (Ny, Nx) dimensions of the grid.\n        center (tuple): (cx, cy) 0-indexed center coordinates (column, row).\n        radius (int): Radius of the disk in grid cells.\n        \n    Returns:\n        np.ndarray: A 2D binary grid.\n    \"\"\"\n    ny, nx = grid_size\n    cx, cy = center\n    radius_sq = radius**2\n    \n    y_indices, x_indices = np.ogrid[:ny, :nx]\n    \n    dist_sq = (x_indices - cx)**2 + (y_indices - cy)**2\n    \n    return (dist_sq <= radius_sq).astype(float)\n\ndef get_window_width(s, dx):\n    \"\"\"\n    Calculates the odd integer window width closest to s/dx.\n    Tie-breaking rule: choose the larger odd integer.\n    \"\"\"\n    val = s / dx\n    w = int(round(val))\n    if w <= 0:\n        return 1\n    if w % 2 == 0:\n        if val < w:\n            w = w - 1\n        else:\n            w = w + 1\n    return w\n\ndef calculate_fss_over_scales(forecast_field, obs_field, scales_km, dx):\n    \"\"\"\n    Computes the Fraction Skill Score (FSS) over a range of scales.\n    \n    Args:\n        forecast_field, obs_field (np.ndarray): The 2D fields.\n        scales_km (np.ndarray): Array of scales in kilometers.\n        dx (float): Grid spacing in kilometers.\n        \n    Returns:\n        np.ndarray: Array of FSS values for each scale.\n    \"\"\"\n    fss_values = []\n    for s in scales_km:\n        w = get_window_width(s, dx)\n        kernel = np.ones((w, w))\n        \n        o_s = convolve(obs_field, kernel, mode='reflect') / (w**2)\n        f_s = convolve(forecast_field, kernel, mode='reflect') / (w**2)\n        \n        mse = np.sum((f_s - o_s)**2)\n        mse_ref = np.sum(f_s**2 + o_s**2)\n        \n        if mse_ref == 0:\n            fss = 1.0\n        else:\n            fss = 1.0 - (mse / mse_ref)\n        fss_values.append(fss)\n        \n    return np.array(fss_values)\n\ndef find_useful_scale(fss_values, scales_km, q):\n    \"\"\"\n    Determines the useful scale from a set of FSS values.\n    \"\"\"\n    above_threshold = np.where(fss_values >= q)[0]\n    \n    if len(above_threshold) > 0:\n        return scales_km[above_threshold[0]]\n    else:\n        return np.max(scales_km)\n\ndef solve_case(case_params):\n    \"\"\"\n    Solves a single test case.\n    \"\"\"\n    grid_size = case_params[\"grid_size\"]\n    dx_km = case_params[\"dx_km\"]\n    obs_params = case_params[\"obs_params\"]\n    ensemble_params = case_params[\"ensemble_params\"]\n    scales_km = case_params[\"scales_km\"]\n    q = case_params[\"q\"]\n\n    # Create observation field\n    obs_field = create_disk_field(grid_size, obs_params[\"center\"], obs_params[\"radius\"])\n\n    # Process each ensemble member\n    ensemble_fields = []\n    member_useful_scales = []\n    for params in ensemble_params:\n        member_field = create_disk_field(grid_size, params[\"center\"], params[\"radius\"])\n        ensemble_fields.append(member_field)\n        \n        fss_values = calculate_fss_over_scales(member_field, obs_field, scales_km, dx_km)\n        s_star = find_useful_scale(fss_values, scales_km, q)\n        member_useful_scales.append(s_star)\n\n    member_useful_scales = np.array(member_useful_scales)\n\n    # Calculate statistics for members\n    median_s_star = np.median(member_useful_scales)\n    variance_s_star = np.var(member_useful_scales)\n    \n    # Process ensemble mean\n    ensemble_mean_field = np.mean(ensemble_fields, axis=0)\n    mean_fss_values = calculate_fss_over_scales(ensemble_mean_field, obs_field, scales_km, dx_km)\n    mean_s_star = find_useful_scale(mean_fss_values, scales_km, q)\n    \n    return [mean_s_star, median_s_star, variance_s_star]\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}