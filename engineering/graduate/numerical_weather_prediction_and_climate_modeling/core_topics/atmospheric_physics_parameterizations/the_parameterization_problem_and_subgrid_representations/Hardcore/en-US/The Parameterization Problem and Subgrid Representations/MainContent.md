## Introduction
Numerical models of the atmosphere and ocean are indispensable tools for weather forecasting and climate projection, but they are built on a fundamental compromise. The laws of fluid motion describe a continuous world with processes spanning a vast range of spatial and temporal scales, from continental weather systems down to millimeter-sized turbulent eddies. However, a computational model can only represent this world on a discrete grid of finite resolution. This disparity between continuous physics and discrete representation gives rise to the "parameterization problem," one of the most significant and persistent challenges in modern [environmental modeling](@entry_id:1124562). At its core, the problem is that the equations for the resolved, grid-scale flow depend on the effects of motions that are too small to be captured, creating a knowledge gap that must be bridged with physical approximations.

This article provides a comprehensive exploration of the parameterization problem, designed to build understanding from first principles to advanced applications. In "Principles and Mechanisms," we will delve into the mathematical origins of the problem by examining how filtering the governing equations gives rise to unresolved subgrid-scale terms. We will explore the physical nature of these scales, the fundamental approaches—both deterministic and stochastic—used to model them, and examine key mechanisms like [mass-flux schemes](@entry_id:1127658) and assumed-PDF methods. Following this, "Applications and Interdisciplinary Connections" demonstrates how these principles are put into practice. This chapter showcases how parameterizations represent crucial real-world phenomena such as convection, boundary layer turbulence, and [gravity wave drag](@entry_id:1125751), and extends these concepts to land-surface modeling and oceanography. Finally, "Hands-On Practices" offers a chance to apply this knowledge directly, guiding you through exercises from calculating eddy viscosity to building a complete entraining [plume model](@entry_id:1129836), thus cementing the connection between theory and practical implementation.

By progressing through these chapters, you will gain a robust understanding of why parameterization is necessary, how it is implemented, and the frontiers of current research. We begin by dissecting the core principles that define and shape this essential field of climate and weather science.

## Principles and Mechanisms

The equations governing fluid motion are fundamentally nonlinear and describe phenomena across a continuous spectrum of spatial and temporal scales. Numerical models of the atmosphere and ocean, however, are constrained to a discrete grid with a finite resolution. This fundamental disparity between the continuous reality and its discrete representation gives rise to one of the most significant challenges in modern environmental modeling: the **parameterization problem**. This chapter delineates the principles that define this problem and explores the key mechanisms developed to address it.

### The Origin of Subgrid-Scale Terms: Filtering and Averaging

To understand the parameterization problem from first principles, we must consider how the governing equations are adapted for a coarse-resolution model. The process involves applying a **spatial filtering operator**, denoted $\mathcal{F}_\Delta$, which effectively averages the flow field over a region of characteristic size $\Delta$, corresponding to the model's grid spacing. Any field variable, such as a scalar concentration $\phi$, can be decomposed into a resolved-scale component, $\overline{\phi} = \mathcal{F}_\Delta[\phi]$, and a subgrid-scale component, $\phi' = \phi - \overline{\phi}$.

Consider the conservation law for a scalar $\phi$ advected by a velocity field $\mathbf{u}$:
$$
\frac{\partial \phi}{\partial t} + \nabla \cdot (\mathbf{u}\phi) = \mathcal{S}(\phi, \mathbf{x}, t)
$$
where $\mathcal{S}$ represents [sources and sinks](@entry_id:263105). When we apply the filter operator $\mathcal{F}_\Delta$ to this equation, we obtain an equation for the evolution of the resolved field, $\overline{\phi}$. Assuming the filter commutes with differentiation, the equation becomes:
$$
\frac{\partial \overline{\phi}}{\partial t} + \nabla \cdot (\overline{\mathbf{u}\phi}) = \overline{\mathcal{S}}
$$
The difficulty arises in the nonlinear advection term, $\overline{\mathbf{u}\phi}$. Because the average of a product is not generally equal to the product of the averages, we find that $\overline{\mathbf{u}\phi} \neq \overline{\mathbf{u}}\overline{\phi}$. We can rewrite the filtered advection term to make the dependency explicit:
$$
\nabla \cdot (\overline{\mathbf{u}\phi}) = \nabla \cdot (\overline{\mathbf{u}}\overline{\phi} + (\overline{\mathbf{u}\phi} - \overline{\mathbf{u}}\overline{\phi}))
$$
Substituting this into the filtered conservation law and rearranging yields the prognostic equation for the resolved field $\overline{\phi}$:
$$
\frac{\partial \overline{\phi}}{\partial t} + \nabla \cdot (\overline{\mathbf{u}}\overline{\phi}) = \overline{\mathcal{S}} - \nabla \cdot \boldsymbol{\tau}_\Delta
$$
Here, a new term has appeared: $\boldsymbol{\tau}_\Delta = \overline{\mathbf{u}\phi} - \overline{\mathbf{u}}\overline{\phi} = \overline{\mathbf{u}'\phi'}$. This is the **subgrid-scale (SGS) flux**, representing the transport of the scalar $\phi$ by the subgrid-scale motions. The equation for the resolved variable $\overline{\phi}$ now depends on a correlation between subgrid-scale quantities ($\mathbf{u}'$ and $\phi'$), which are not resolved by the model. This is the essence of the **closure problem**: the system of equations is not closed because there are more unknowns than equations. A **[subgrid-scale parameterization](@entry_id:1132593)** is a model, or "closure," that seeks to represent the subgrid flux $\boldsymbol{\tau}_\Delta$ (or its divergence) in terms of the available resolved-scale variables .

It is critical to distinguish this physical modeling problem from two other sources of error in a numerical model. **Numerical discretization error** is a mathematical error that arises from approximating continuous derivatives on a discrete grid; this error, often denoted by a truncation residual $T_{\Delta x}$, depends on the grid spacing and the order of the numerical scheme. **Model [structural error](@entry_id:1132551)** is a physical knowledge gap, occurring when the governing equations or the functional forms used to represent processes (e.g., in the source term $\mathcal{S}$) are incomplete or incorrect. A parameterization is designed to represent the physical effects of $\boldsymbol{\tau}_\Delta$, not to correct for discretization or structural errors .

For compressible atmospheric flows, where density $\rho$ can vary significantly, simple Reynolds averaging introduces additional complexities. Averaging the momentum flux term $\rho u_i u_j$ with a simple arithmetic mean, where $\rho = \overline{\rho} + \rho'$, leads to multiple unclosed correlations, including turbulent mass fluxes like $\overline{\rho'u_j'}$, which make the resulting equations cumbersome. To simplify this, **Favre (density-weighted) averaging** is employed. The Favre average of a quantity $\phi$ is defined as $\tilde{\phi} = \overline{\rho\phi}/\overline{\rho}$. Under this framework, the averaged momentum equation retains a form analogous to the incompressible case, consolidating all subgrid turbulent effects into a single term: the compressible Reynolds stress tensor, $\overline{\rho u_i'' u_j''}$, where $u_i''$ is the fluctuation from the Favre-mean velocity $\tilde{u}_i$. This term represents the [momentum transport](@entry_id:139628) by unresolved turbulent motions and must be parameterized .

### The Physical Nature of Subgrid Scales

To build effective parameterizations, we must understand the physical nature of the unresolved scales. Atmospheric and oceanic flows are characterized by extremely high **Reynolds numbers**, $Re = UL/\nu$, where $U$ and $L$ are characteristic velocity and length scales of the large-scale flow, and $\nu$ is the kinematic molecular viscosity.

For a typical atmospheric boundary layer flow with $U = 10 \text{ m/s}$ and $L = 1000 \text{ m}$, the molecular viscosity of air is $\nu \approx 1.5 \times 10^{-5} \text{ m}^2 \text{s}^{-1}$. The Reynolds number based on these large scales is enormous, $Re_L \approx 6.7 \times 10^8$. At such high Reynolds numbers, energy injected at large scales cascades down to progressively smaller eddies until it reaches the **Kolmogorov microscale**, $\eta$, where molecular viscosity finally becomes effective and dissipates the energy as heat. For the example flow, the Kolmogorov scale is on the order of millimeters ($\eta \sim (\nu^3/\varepsilon)^{1/4} \approx 0.24 \text{ mm}$, where $\varepsilon \sim U^3/L$ is the energy dissipation rate). The local Reynolds number at this scale, $Re_\eta = u_\eta \eta / \nu$, is by definition of order unity .

A numerical model with a grid spacing of, for instance, $\Delta = 1000 \text{ m}$, explicitly resolves motions larger than $\Delta$ but cannot resolve the vast range of turbulent eddies between $\Delta$ and $\eta$. The direct effect of molecular viscosity is utterly negligible at the grid scale. Instead, the net effect of the unresolved turbulent eddies is to transport momentum and scalars, acting as a powerful mixing agent. This turbulent transport is modeled using an **eddy viscosity**, $\nu_t$. Unlike the physical constant $\nu$, $\nu_t$ is a property of the flow itself, representing the efficacy of momentum transfer by unresolved turbulence. In the atmospheric boundary layer, $\nu_t$ is typically orders of magnitude larger than $\nu$, highlighting the dominance of turbulent transport over molecular diffusion at grid scales .

The separation between resolved and unresolved scales can be visualized in spectral space. The kinetic energy of turbulence is distributed across wavenumbers $k$ (where $k \propto 1/\text{length}$) according to a spectrum $E(k)$. In the [inertial range](@entry_id:265789) of turbulence, this often follows the famous Kolmogorov power law, $E(k) \propto k^{-5/3}$. A model with grid spacing $\Delta$ can be seen as applying a filter with a cutoff wavenumber $k_c \approx \pi/\Delta$. All energy at wavenumbers $k > k_c$ is subgrid and its effects must be parameterized. For a flow with a given energy spectrum, one can quantitatively define a criterion for scale separation. For example, we might require that the fraction of kinetic energy in the unresolved scales, $\int_{k_c}^{k_d} E(k) dk$, be less than a certain tolerance relative to the total turbulent energy, $\int_{k_0}^{k_d} E(k) dk$, where $k_0$ and $k_d$ define the range of energetically active wavenumbers . This provides a concrete link between the grid resolution $\Delta$ and the amount of energy that must be handled by parameterizations.

### Fundamental Approaches to Parameterization

Given the necessity of parameterizing subgrid effects, modelers have developed several classes of closures. At a high level, these can be divided into deterministic and stochastic approaches .

**Deterministic closures** provide a single, unique value for the subgrid tendency for any given resolved state. Most operational parameterizations fall into this category. The eddy viscosity model, which relates the subgrid stress to the resolved strain rate ($\boldsymbol{\tau} \approx -\nu_t \mathbf{S}_{\text{resolved}}$), is a classic example. In probabilistic terms, a deterministic parameterization attempts to model the [conditional expectation](@entry_id:159140) (the mean effect) of the subgrid tendency, given the resolved state: $P_{\text{det}} \approx \mathbb{E}[\text{SGS tendency} | \text{resolved state}]$.

**Stochastic representations**, by contrast, acknowledge that for any given resolved [macrostate](@entry_id:155059), a multitude of subgrid [microstates](@entry_id:147392) are possible. This leads to a distribution of possible subgrid tendencies, not a single value. Stochastic schemes model this by supplementing a deterministic component (representing the mean effect) with a random, or stochastic, component. This stochastic term is not arbitrary noise; its statistical properties (e.g., variance, correlation timescale) are designed to be state-dependent and to represent the known statistical characteristics of turbulence, such as intermittency and variance. A key advantage of stochastic parameterizations is their ability to represent **energy backscatter**, the transfer of energy from subgrid to resolved scales, a process that purely dissipative deterministic schemes cannot capture. A probabilistic view frames this as modeling not just the conditional mean, but also the [conditional variance](@entry_id:183803) and other [higher-order statistics](@entry_id:193349) of the subgrid tendencies .

### Mechanisms of Parameterization: Illustrative Examples

The abstract principles of closure are realized through specific physical and statistical models tailored to different processes.

#### Mass-Flux Schemes for Convection

Atmospheric convection is a vertically coherent process involving organized updrafts and downdrafts that are often much smaller than a typical climate model grid cell. To represent this, **[mass-flux parameterization](@entry_id:1127657) schemes** are widely used. These schemes conceptually divide a grid column into distinct regions: a convective updraft ensemble and a surrounding environment .

The core of the scheme is the **updraft mass flux**, $M(z) = \rho(z) a(z) w_u(z)$, which represents the total mass of air moving upward through the convective plumes per unit horizontal area. Here, $a(z)$ is the fractional area occupied by the updrafts and $w_u(z)$ is their mean vertical velocity. The vertical evolution of this mass flux is governed by **[entrainment](@entry_id:275487)**, $\varepsilon(z)$, the rate at which environmental air is mixed into the plume, and **detrainment**, $\delta(z)$, the rate at which plume air is ejected into the environment. Conservation of mass for the updraft yields a governing equation:
$$
\frac{dM}{dz} = (\varepsilon - \delta) M
$$
This simple equation forms the backbone of the parameterization. The tendencies of temperature, moisture, and momentum are then calculated based on the vertical divergence of the convective fluxes, which are given by $F_c = M(s_u - s_e)$, where $s_u$ and $s_e$ are the scalar values in the updraft and environment, respectively. The closure problem is thus transformed into finding physically based expressions for the mass flux at the base of the convection and for the [entrainment and detrainment](@entry_id:1124548) rates, which are typically linked to the [thermodynamic state](@entry_id:200783) of the resolved-scale environment (e.g., buoyancy or CAPE). This physically based approach contrasts sharply with older **adjustment schemes**, which simply relax an unstable atmospheric column back toward a neutral reference profile over a fixed timescale without explicitly modeling the underlying updrafts or mixing processes .

#### Assumed-PDF Methods for Microphysics

Many crucial processes, like cloud formation or [atmospheric chemistry](@entry_id:198364), are highly nonlinear and depend not just on the grid-mean state but on the full distribution of subgrid variables. For example, condensation occurs only in the portions of a grid box where the water vapor [mixing ratio](@entry_id:1127970) $q$ exceeds the saturation value $q_s$. A simple **deterministic threshold approach**, which approximates the grid-mean source term $\overline{S(q)}$ as $S(\overline{q})$, will fail to produce any condensation if the grid-mean value $\overline{q}$ is below saturation, even if a significant fraction of the grid box is supersaturated.

To address this, **assumed-PDF methods** are used. This statistical approach involves positing a [parametric form](@entry_id:176887) for the subgrid probability density function (PDF), $p(q)$, such as a Gaussian or Beta distribution. The parameters of this PDF are determined by the resolved-scale moments, typically the grid-mean $\overline{q}$ and variance $\sigma_q^2$. With the PDF defined, any required grid-mean quantity can be calculated by integration . For instance, the mean source term is computed as an expectation:
$$
\overline{S(q)} = \int S(q) p(q) dq
$$
This approach correctly captures effects of subgrid variability on the mean state. Furthermore, it allows for a consistent prediction of the evolution of higher-order moments. For example, the contribution of the microphysical source term to the tendency of the subgrid variance is given by $2\overline{(q-\overline{q})S(q)}$, which is computed as:
$$
\partial_t \sigma_q^2\vert_{S} = 2 \int (q - \overline{q}) S(q) p(q) dq
$$
This term represents how condensation preferentially removes moisture from the wettest parts of the distribution, thereby reducing subgrid variance—a physical effect that deterministic bulk models completely ignore .

### Guiding Principles for Robust Parameterization

Beyond specific mechanisms, the development of reliable parameterization suites is guided by a set of overarching principles.

#### Conservation Laws

Perhaps the most fundamental principle is that parameterizations must not spuriously create or destroy globally conserved quantities like mass, energy, and elemental species. While parameterizations act to redistribute these quantities within an atmospheric column (e.g., convection moving heat and moisture upward), their column-integrated effect must be consistent with the only true sources and sinks: fluxes across the top and bottom boundaries of the atmosphere . For example:
- **Total water mass**: The column-integrated tendency of total water from all parameterizations must equal the surface evaporation rate minus the precipitation rate ($E - P$).
- **Total moist energy**: The column-integrated tendency of moist enthalpy (including latent heats of all water phases) plus the rate of kinetic [energy dissipation](@entry_id:147406) must equal the net radiative flux, the surface sensible and latent heat fluxes, minus the enthalpy exported by falling precipitation ($F_R^{\text{TOA}} + F_H + F_E - \Phi_P$).

Enforcing these constraints is absolutely essential for long-term climate simulations. Any small, systematic violation can accumulate over time, leading to unrealistic drifts in global mean temperature, humidity, sea level, and other critical climate variables .

#### Scale Awareness and the Grey Zone

A major frontier in parameterization is developing schemes that are **scale-aware**. Traditional parameterizations are designed for a specific regime where the grid spacing $\Delta$ is much larger than the characteristic scale of the process being parameterized, $L_c$ (e.g., $\Delta \gg 10 \text{ km}$ for deep convection). As computational power increases, models are now run at resolutions where $\Delta$ becomes comparable to $L_c$. This is known as the **"grey zone"** .

In the grey zone, a physical process like convection is partially resolved by the model's dynamics but not fully. A traditional parameterization, which assumes the process is entirely subgrid, will "double count" the transport by adding its own contribution on top of the already-present resolved transport. Conversely, simply turning the parameterization off would lead to a gap, as the model cannot yet resolve the process with full fidelity.

Scale-aware parameterizations are designed to solve this problem by smoothly adapting their behavior as a function of the model's resolution. The core objective is to ensure that the sum of the resolved tendency and the parameterized tendency provides a consistent representation of the total physical tendency across all scales. A common way to achieve this is to multiply the parameterized tendency by a non-dimensional, scale-dependent amplitude factor, $f(\Delta/L_c)$. This factor is designed to approach $1$ in the fully parameterized limit ($\Delta \gg L_c$) and to approach $0$ in the fully resolved limit ($\Delta \ll L_c$) . A physically based functional form for $f$ can be derived by considering the fraction of turbulent variance that remains unresolved by the grid. For a turbulent spectrum $E(k) \propto k^{-p}$, this fraction, and thus the scale-aware factor, can be shown to scale as $f(\Delta/L) \propto (\Delta/L)^{p-1}$ within the grey zone, providing a dynamic bridge between the parameterized and resolved worlds .