## 引言
全球气候模式（GCMs）是理解和预测未来气候变化的关键工具，但其粗糙的空间分辨率限制了它们在评估区域和地方尺度影响方面的直接应用。如何将GCM提供的宏观气候情景转化为对特定流域、生态系统或城市具有实际意义的精细化信息？这便是[统计降尺度](@entry_id:1132326)（Statistical Downscaling）技术所要解决的核心问题。它通过建立大尺度[气候预测](@entry_id:184747)变量与局地响应变量之间的统计关系，为我们架起了一座连接全球变化与局地影响的关键桥梁，对[水资源管理](@entry_id:1133968)、生态保护和公共卫生[风险评估](@entry_id:170894)等领域至关重要。

本文旨在系统性地介绍[统计降尺度](@entry_id:1132326)技术。在“原理与机制”一章中，我们将深入探讨其核心假设、主流方法（如回归、[天气发生器](@entry_id:1134017)、[分位数映射](@entry_id:1130373)）及其内在机制。接着，在“应用与跨学科联系”一章，我们将展示这些技术如何在水文学、生态学等领域应对复杂的现实挑战，并讨论多变量处理、极端事件分析及不确定性量化等高级主题。最后，通过“动手实践”部分，您将有机会应用所学知识，解决从预测变量筛选到模型解释的实际问题。让我们首先从理解统计降尺度的基本原理与机制开始。

## 原理与机制

本章旨在深入探讨统计降尺度领域的核心科学原理与关键技术机制。我们将从统计降尺度旨在解决的根本问题出发，系统性地构建一个理解该领域的理论框架。我们将阐述支撑各类降尺度方法的基础假设，特别是[平稳性假设](@entry_id:272270)及其在气候变化背景下面临的挑战。随后，我们将详细剖析几类主流的统计降尺度方法，包括基于回归的转换函数、随机[天气发生器](@entry_id:1134017)以及[分位数映射](@entry_id:1130373)等。最后，我们将讨论评估这些模型性能的严谨验证方法，并对降尺度预测中固有的不确定性来源进行分类与量化。

### 根本挑战：连接尺度

气候科学的一个核心挑战在于，全球气候模式（General Circulation Models, GCMs）在解决全球尺度动力学问题上表现出色，但其空间分辨率（通常为数十至数百公里）对于评估区域和地方尺度的气候影响而言过于粗糙。例如，一个GCM格点的平均降水量可能无法代表该格点内某个特定流域或城市的水文响应。统计降尺度的根本目的就是为了构建从GCM提供的**粗分辨率预测变量**（predictor）到我们关心的**局地尺度响应变量**（predictand）之间的数学桥梁。

让我们用更严谨的语言来描述这个问题。假设存在一个大气[标量场](@entry_id:151443) $X(\mathbf{s}, t)$，其中 $\mathbf{s}$ 是空间位置，$t$ 是时间。一个GCM在以 $\mathbf{s}_0$ 为中心的格点上，提供的是该格点区域 $A_{\Delta}$（特征尺度为 $\Delta$）内的[空间平均](@entry_id:203499)值，我们记为 $\bar{X}_{\Delta}(\mathbf{s}_0, t)$。而我们通常关心的是位于该格点内某个特定位置（如一个气象站）的**点尺度**观测值 $X(\mathbf{s}_o, t)$，其中 $\mathbf{s}_o \in A_{\Delta}$。

直接将格点平均值 $\bar{X}_{\Delta}$ 作为点尺度值的估计，会引入一种被称为**代表性误差**（representativeness error）的偏差 。这种误差并非源于观测仪器的不精确，而是源于模型输出与观测数据在**空间支持**（spatial support）上的根本不匹配——即一个是面积平均，另一个是点测量。由于大气过程（如对流、[湍流](@entry_id:151300)）在GCM格点内部存在显著的次网格变率，点尺度的真实值通常会偏离格点平均值。

我们可以从两个角度来量化这一误差。假设该空间场是二阶平稳的，其空间协方差仅依赖于两点间的距离向量 $\mathbf{h}$，记为 $C(\mathbf{h})$。[代表性误差](@entry_id:754253)的方差 $\sigma_r^2$ 可以表示为：
$$
\sigma_r^2 = \mathrm{Var}\big(X(\mathbf{s}_o) - \bar{X}_\Delta(\mathbf{s}_0)\big) = C(\mathbf{0}) + \frac{1}{|A_\Delta|^2}\iint_{A_\Delta \times A_\Delta} C(\mathbf{s}-\mathbf{s}')\,\mathrm{d}\mathbf{s}\,\mathrm{d}\mathbf{s}' - \frac{2}{|A_\Delta|}\int_{A_\Delta} C(\mathbf{s}_o-\mathbf{s})\,\mathrm{d}\mathbf{s}
$$
这个表达式清晰地表明，只要在格点 $A_{\Delta}$ 内存在空间变率（即 $C(\mathbf{h})$ 不为常数），[代表性误差](@entry_id:754253)的方差就必然为正。从[频谱](@entry_id:276824)的角度看，[空间平均](@entry_id:203499)算子相当于一个**低通滤波器**。若场的[功率谱](@entry_id:159996)为 $S(\mathbf{k})$，滤波器的传递函数为 $G_{\Delta}(\mathbf{k})$，那么代表性误差的方差就是被该滤波器衰减掉的高波数（小尺度）分量的总能量 ：
$$
\sigma_r^2 = \int_{\mathbb{R}^2} \big|1 - G_\Delta(\mathbf{k})\big|^2\, S(\mathbf{k})\, \mathrm{d}\mathbf{k}
$$
因此，为了获得可靠的局地气候信息，我们必须采用某种降尺度技术来弥补这种因[尺度不匹配](@entry_id:1131268)造成的信息损失。

### 两大范式：[动力降尺度](@entry_id:1124043)与[统计降尺度](@entry_id:1132326)

为解决[尺度不匹配](@entry_id:1131268)问题，学界发展出两大主流技术范式：**动力降尺度**（dynamical downscaling）和**[统计降尺度](@entry_id:1132326)**（statistical downscaling）。

**[动力降尺度](@entry_id:1124043)**本质上是一种基于物理的方法 。它在一个感兴趣的区域内，嵌套一个高分辨率的**区域气候模式**（Regional Climate Model, RCM）。RCM使用来自GCM的输出作为其初始条件和[侧边界条件](@entry_id:1127097)，然后在更精细的网格上求解控制大气运动和热力过程的物理方程组（如[原始方程](@entry_id:1130162)）。其核心假设是，只要物理定律和[参数化](@entry_id:265163)方案足够精确，RCM就能够生成与高分辨率地形、下垫面等强迫相协调的、物理上一致的三维大气状态场。动力降尺度不依赖于局地的历史观测数据进行“训练”，但其计算成本极为高昂。

与此相对，**[统计降尺度](@entry_id:1132326)**是一种数据驱动的方法。其核心思想是，利用历史观测数据来学习和量化大尺度气候预测变量（predictors）与局地气候响应变量（predictand）之间的统计关系。这个关系一旦建立，就可以应用于GCM对未来气候的预测，从而推断出未来的局地气候情景。形式上，它旨在估计[条件概率分布](@entry_id:163069) $p\big(Y(\mathbf{s}, t)\,|\,X_{\Delta}(\cdot, t)\big)$ 或其某个泛函（如[条件期望](@entry_id:159140)）。这种方法的成功依赖于两个关键因素：一是足够长且高质量的、包含预测变量和响应变量的配对历史数据集；二是该统计关系在时间上的稳定性，即**[平稳性假设](@entry_id:272270)**。相比动力降尺度，统计降尺度计算成本低廉，能够针对特定站点进行高效校准，但其输出本质上是[统计推断](@entry_id:172747)，不保证物理守恒定律在空间上的严格满足 。

本章的后续部分将聚焦于统计降尺度的原理与机制。

### 核心假设：平稳性及其在气候变化中的挑战

几乎所有[统计降尺度](@entry_id:1132326)方法都隐含着一个核心假设：**[平稳性](@entry_id:143776)**（stationarity）。这个假设断言，在历史时期学习到的预测变量与响应变量之间的统计关系，在未来应用时期将保持不变。

在统计学中，平稳性有不同层次的定义 。**[严平稳性](@entry_id:260987)**（strict stationarity）要求一个[随机过程](@entry_id:268487)的任何有限维[联合分布](@entry_id:263960)都不随时间平移而改变。这是一个非常强的条件。在实践中，我们更常依赖于**[弱平稳性](@entry_id:171204)**（weak stationarity）或**二阶平稳性**（second-order stationarity）。对于一个由预测变量 $\boldsymbol{Z}_t$ 和响应变量 $Y_t$ 组成的联合过程 $\boldsymbol{X}_t = (\boldsymbol{Z}_t^\top, Y_t)^\top$，[弱平稳性](@entry_id:171204)要求：
1.  **均值恒定**: $\mathbb{E}[\boldsymbol{X}_t] = \boldsymbol{\mu}$，对所有时间 $t$ 成立。
2.  **协方差仅依赖于时间滞后**: $\mathrm{Cov}(\boldsymbol{X}_t, \boldsymbol{X}_{t+\tau}) = \boldsymbol{\Gamma}(\tau)$，对所有时间 $t$ 和滞后 $\tau$ 成立。这包括了各自的[自协方差](@entry_id:270483)和它们之间的互协方差，如 $\mathrm{Cov}(Y_t, \boldsymbol{Z}_{t+\tau})$。

对于统计降尺度而言，最关键的[平稳性假设](@entry_id:272270)体现在[条件分布](@entry_id:138367) $p(Y_t | \boldsymbol{Z}_t)$ 的[时不变性](@entry_id:198838)上。然而，由人类活动引起的**外部强迫**（如温室气体浓度增加）驱动的气候变化，从根本上挑战了这一假设 。气候变化会导致气候系统的平均态、变率乃至物理过程本身发生系统性演变，即出现**[长期趋势](@entry_id:918221)**（secular trends）。这意味着，像 $\mathbb{E}[Y_t]$ 和 $\mathbb{E}[\boldsymbol{Z}_t]$ 这样的[期望值](@entry_id:150961)会随时间 $t$ 变化，从而直接违背了[弱平稳性](@entry_id:171204)。更深层次的问题是，气候系统对强迫的响应可能是[非线性](@entry_id:637147)的，这可能导致预测变量和响应变量之间的物理关联，即[条件分布](@entry_id:138367) $p(Y_t | \boldsymbol{Z}_t)$ 本身，也随气候状态的改变而演变。

因此，一个核心挑战和研究前沿就是如何发展能够在非平稳气候背景下依然稳健的降尺度方法。尽管如此，理解基于[平稳性假设](@entry_id:272270)的经典方法仍然是学习该领域的第一步。

### [统计降尺度](@entry_id:1132326)方法的主要类别

[统计降尺度](@entry_id:1132326)并非单一方法，而是一个包含多种技术和理念的大家族。我们可以将其划分为几个主要类别。

#### 偏差校正 vs. “真正”的降尺度

首先，有必要厘清两个经常被提及但含义不同的概念：**偏差校正**（bias correction）与更广义的**统计降尺度** 。

**偏差校正**，特别是单变量偏差校正，其目标通常是调整模型输出的**[边际分布](@entry_id:264862)**（marginal distribution），使其与观测的[边际分布](@entry_id:264862)相匹配。例如，**[分位数映射](@entry_id:1130373)**（Quantile Mapping）方法就是通过构建一个单调变换函数 $T$，使得校正后的变量 $T(X_t)$ 的[累积分布函数](@entry_id:143135)（CDF）与观测变量 $Y_t$ 的CDF一致，即 $F_{T(X)} \approx F_Y$。这种方法主要用于消除模型在统计矩（如均值、方差、[分位数](@entry_id:178417)）上的系统性偏差。

而更一般意义上的**统计降尺度**，其目标是构建一个**[条件模型](@entry_id:920968)**（conditional model），即对[条件概率分布](@entry_id:163069) $p(Y_t | X_t, W_t)$ 进行建模。这里的预测变量不仅可以包括GCM在本地的输出 $X_t$，还可以包括其他大尺度环流场、遥相关指数等信息 $W_t$。

偏差校正本身可以被视为一种简单的降尺度方法。在某些理想情况下，例如当响应变量 $Y_t$ 可以被看作是本地预测变量 $X_t$ 的一个确定性[单调函数](@entry_id:145115) $h$ 时（$Y_t = h(X_t)$），偏差校正（如[分位数映射](@entry_id:1130373)）就足以完美地恢复这个关系 。然而，在更常见的情况下，偏差校正是不充分的。特别是当：
1.  存在未被 $X_t$ 包含但对 $Y_t$ 有显著影响的**其他预测变量** $W_t$ 时，即 $p(Y_t|X_t, W_t) \neq p(Y_t|X_t)$。
2.  $Y_t$ 的[条件方差](@entry_id:183803)或极端事件的发生概率不仅依赖于 $X_t$，还依赖于 $W_t$（例如，特定的天气型会改变局地降水的变率）。

在这些情况下，一个只作用于 $X_t$ 的单变量映射 $T$ 在结构上就无法捕捉到这些由 $W_t$ 调制的复杂关系，因此需要更全面的[条件模型](@entry_id:920968) 。

#### 转换函数（基于回归的方法）

这类方法直接对预测变量到响应变量的函数关系进行建模，旨在估计[条件期望](@entry_id:159140) $\mathbb{E}[Y_t | X_t]$ 或[条件分布](@entry_id:138367)的其他参数。

最基础的转换函数是**线性回归**（linear regression）。模型形式为 $Y_t = X_t^T \beta + \varepsilon_t$，其中 $Y_t$ 是响应变量（如日最高气温），$X_t$ 是预测变量向量，$\beta$ 是[回归系数](@entry_id:634860)，$\varepsilon_t$ 是误差项。经典线性模型的有效性依赖于一系列假设：
*   **线性响应**：[条件期望](@entry_id:159140) $\mathbb{E}[Y_t | X_t]$ 是 $X_t$ 的线性函数。
*   **[同方差性](@entry_id:634679)**（Homoscedasticity）：误差的[条件方差](@entry_id:183803)恒定，即 $\mathrm{Var}(\varepsilon_t | X_t) = \sigma^2$。
*   **误差独立性**：不同时间的误差项序列不相关，且误差项与预测变量不相关（即 $\mathbb{E}[\varepsilon_t | X_t] = 0$）。

在气候应用中，特别是处理时间[序列数据](@entry_id:636380)时，**误差独立性**假设常常被违背，因为许多气候变量（及其模型误差）都表现出显著的**[自相关](@entry_id:138991)**性（autocorrelation）。例如，误差项可能呈现一阶自回归结构 $\text{AR}(1)$。在这种情况下，虽然普通最小二乘（OLS）估计的[回归系数](@entry_id:634860) $\beta$ 依然是无偏和一致的，但它不再是[最佳线性无偏估计量](@entry_id:137602)（BLUE），并且其[标准误](@entry_id:635378)的常规计算公式会失效，导致错误的统计推断。正确的处理方法是采用**[广义最小二乘法](@entry_id:272590)**（GLS）来获得更有效的估计，或者使用**异方差和自相关稳健**（HAC）的[标准误](@entry_id:635378)（如Newey-West[标准误](@entry_id:635378)）进行推断 。

当然，线性模型只是一个起点。当关系为[非线性](@entry_id:637147)时，可以采用**[广义线性模型](@entry_id:900434)**（GLMs）、**广义加性模型**（GAMs）或各种机器学习算法（如[随机森林](@entry_id:146665)、神经网络）来构建更灵活的转换函数。

#### [天气发生器](@entry_id:1134017)（[随机模拟](@entry_id:168869)）

与直接预测响应变量数值的转换函数不同，**随机[天气发生器](@entry_id:1134017)**（stochastic weather generator）是一类旨在生成具有与观测相似统计特性的、无限长的局地气象变量**合成时间序列**的模型。这类方法在水文、农业等领域的[影响评估](@entry_id:896910)中尤为重要，因为它们能提供现实的逐日变率、持续性（如干旱或连阴雨）以及极端事件信息。

以日降水为例，一个典型的[天气发生器](@entry_id:1134017)通常包含两个部分 ：
1.  **发生过程模型**（Occurrence Model）：用于模拟每日是干（$W_t=0$）还是湿（$W_t=1$）。由于降水具有“记忆性”（即今天下雨会增加明天下雨的概率），这个过程通常用一个**二状态一阶马尔可夫链**来描述。该链由转移[概率矩阵](@entry_id:274812) $\mathbf{P} = \{p_{ij} = P(W_t=j | W_{t-1}=i)\}$ 定义。通过[求解方程组](@entry_id:152624)，可以使模型的[稳态](@entry_id:139253)湿日概率 $\pi = \frac{p_{01}}{p_{01}+p_{10}}$ 和一阶自[相关系数](@entry_id:147037) $r_1 = \frac{p_{11}-\pi}{1-\pi}$ 与观测值匹配，从而再现观测到的湿日频率和持续性。

2.  **量级过程模型**（Amount Model）：在确定某一天为湿日（$W_t=1$）的条件下，用一个概率分布来模拟该日的降水量 $Y_t$。由于日降水量是严格为正且通常呈[右偏分布](@entry_id:275398)的，**伽马分布**（Gamma distribution）是一个常用且合适的选择。伽马分布的[形状参数](@entry_id:270600) $k$ 和尺度参数 $\theta$ 可以通过**矩估计法**从观测的湿日平均降水量 $m_a$ 和方差 $v_a$ 中确定：$k = m_a^2/v_a$ 和 $\theta = v_a/m_a$。

为了将[天气发生器](@entry_id:1134017)用于**降尺度**，其参数需要被大尺度预测变量 $X_t$ 所“驱动”。例如，可以通过[广义线性模型](@entry_id:900434)（如logistic回归）让[马尔可夫链](@entry_id:150828)的转移概率成为 $X_t$ 的函数，或者让伽马分布的均值成为 $X_t$ 的函数（通常使用[对数连接函数](@entry_id:163146)以保证均值为正）。这样，生成的天气序列就会受到大尺度气候模式所预测的天气型和气候态的调制。

#### 方法论分野：完美预报 vs. 模式输出统计

值得注意的是，上述的回归模型或[天气发生器](@entry_id:1134017)等，可以根据其训练数据的来源，归入两种经典的方法论框架：**完美预报**（Perfect Prognosis, PP）和**模式输出统计**（Model Output Statistics, MOS）。

**完美预报 (PP)** 框架在**训练阶段**使用**观测到的大尺度场**（通常来自再分析资料，如ERA5）作为预测变量，与同期的局地观测响应变量进行配对，来建立[统计模型](@entry_id:165873) $f_{\text{PP}}$。其核心思想是学习“真实大气”中大尺度场与局地气候之间的物理关系。在**应用阶段**，将此模型应用于GCM预测的未来大尺度场。PP方法的优点是模型本身与任何特定的GCM无关，具有一定的普适性。但其致命弱点是，它假设GCM能够“完美”地预报大尺度场。如果GCM输出的预测变量本身存在系统性偏差，这些偏差会直接传入统计模型，导致最终的降尺度结果出现错误。

**模式输出统计 (MOS)** 框架则直接面对GCM的不完美性。它在**训练阶段**使用**GCM的[历史模拟](@entry_id:136441)（[后报](@entry_id:1126122)）输出**作为预测变量，与同期的局地观测响应变量进行配对，来建立统计模型 $f_{\text{MOS}}$。通过将有偏差的模式输出直接与真实的局地观测进行关联，MOS模型能够**内隐地学习并校正**该GCM特有的系统性偏差。这使得MOS方法通常在预报技巧上优于PP。然而，其代价是模型高度**依赖于特定的GCM**。一旦GCM版本更新或更换，其偏差特性可能改变，MOS模型就需要重新训练。

### 深入剖析：[分位数映射](@entry_id:1130373)

**[分位数映射](@entry_id:1130373)**（Quantile Mapping, QM），又称[分位数](@entry_id:178417)-[分位数映射](@entry_id:1130373)，是一种非常流行的方法，它既可以被看作一种复杂的偏差校正技术，也可以作为一种非参数的降尺度转换函数。

其核心思想是：对于GCM模拟的任意一个值 $x^{\text{GCM}}$，首先确定它在GCM模拟值分布中的分位点（即累积概率），然后找到观测值分布中具有**相同分位点**的值，并将该值作为校正后的结果 。用数学语言来说，校正后的值 $x^{\text{adj}}$ 通过以下变换得到：
$$
x^{\text{adj}} = \left(F^{\text{obs}}\right)^{-1}\! \left(F^{\text{GCM}}(x^{\text{GCM}})\right)
$$
这里，$F^{\text{GCM}}$ 和 $F^{\text{obs}}$ 分别是GCM和观测变量在历史校准期的[累积分布函数](@entry_id:143135)（CDF），而 $(F^{\text{obs}})^{-1}$ 是观测CDF的[反函数](@entry_id:141256)，也即观测的[分位数函数](@entry_id:271351)。这个变换是单调的，它能够校正GCM分布的所有统计矩，使其与观测分布完全一致（在校准期内）。

与所有统计方法一样，QM的成功应用依赖于**[平稳性假设](@entry_id:272270)**。具体而言，它假设GCM的偏差结构，即模拟分布与观测分布之间的**分位数-分位数关系**，在时间上是稳定的。

QM在实践中面临一个关键挑战：**外推**（extrapolation）。在未来的气候情景下（例如一个更暖的全球背景），GCM可能预测出超出历史校准期范围的值（例如，前所未有的高温）。如果CDF是基于历史数据的[经验分布函数](@entry_id:178599)（ECDF）估计的，那么任何超出历史最大值的新值，其分位点都为1。经过QM变换后，其校正值将被“裁剪”到历史观测的最大值，这显然是不现实的，因为它阻止了模型预测出比历史上更极端的事件。一个更科学的处理方法是，使用合适的**[参数化](@entry_id:265163)分布**（例如，对分布主体使用伽马或[威布尔分布](@entry_id:270143)，对尾部使用[广义帕累托分布](@entry_id:137241)GPD）来拟合GCM和观测数据，然后在这些能够平滑外推的[参数化](@entry_id:265163)分布之间进行[分位数映射](@entry_id:1130373) 。

### [模型验证](@entry_id:141140)与不确定性量化

开发一个[统计降尺度](@entry_id:1132326)模型后，必须回答两个关键问题：“这个模型的效果如何？”以及“我们对它的预测有多大信心？”这分别对应[模型验证](@entry_id:141140)和[不确定性量化](@entry_id:138597)。

#### 严谨的[模型验证](@entry_id:141140)

评估模型性能最常用的方法是**[交叉验证](@entry_id:164650)**（Cross-Validation, CV）。然而，对于气候这类具有显著**时空依赖性**的数据，天真地使用标准随机K折交叉验证是错误的，因为它会导致**信息泄露**（information leakage）。当数据点被随机分配到[训练集](@entry_id:636396)和[验证集](@entry_id:636445)时，由于自相关性，[验证集](@entry_id:636445)中的某个数据点（如某一天）的紧邻（如前一天和后一天）很可能出现在训练集中。模型可以轻易地利用这种相关性来“偷看”答案，从而得到一个过于乐观（即误差偏低）的性能评估。

正确的验证方法必须尊重数据的依赖结构，确保训练集和[验证集](@entry_id:636445)之间的近似独立性。常用的严谨策略包括：
*   **块状[交叉验证](@entry_id:164650)**（Block Cross-Validation）：将数据按时间和/或空间进行分块，并确保整个块（而不是单个数据点）被作为一个整体划分到训练集或[验证集](@entry_id:636445)。例如，可以按“年份”进行划分（留一年法），或者将空间上邻近的站点聚类后按“站点簇”进行划分。为了进一步保证独立性，还可以在训练块和验证块之间设置一个时间或空间上的“缓冲区”。
*   **前向链式验证**（Forward-Chaining）：这种方法严格遵循时间顺序，模拟真实的预报过程。模型在时间点 $1$ 到 $t$ 的数据上训练，然后在时间点 $t+1$ 上进行预测；然后，将数据扩充到 $t+1$，在 $1$ 到 $t+1$ 的数据上训练，在 $t+2$ 上预测，依此类推。

使用如**[嵌套交叉验证](@entry_id:176273)**（Nested CV）的框架，可以在外循环中使用块状划分来获得无偏的性能估计，同时在内循环中对每个训练子集进行[超参数调优](@entry_id:143653)，这是处理依赖性数据时进行[模型选择](@entry_id:155601)和评估的黄金标准 。

#### 量化不确定性

[统计降尺度](@entry_id:1132326)的最终输出不是一个确定的数字，而是一个伴随着不确定性的预测。理解和量化这些[不确定性的来源](@entry_id:164809)对于科学决策至关重要。降尺度预测的不确定性主要来自以下几个方面 ：

1.  **情景不确定性**（Scenario Uncertainty）：源于对未来社会经济发展路径和温室气体排放路径的未知。这是关于“世界将如何发展”的不确定性，通过对比不同排放情景（如SSPs）下的降尺度结果来评估。

2.  **预测变量（GCM）不确定性**（Predictor Uncertainty）：即使在同一排放情景下，不同的GCM由于其内部物理过程、[参数化](@entry_id:265163)方案和分辨率的差异，也会产生不同的大尺度气候预测。这种不确定性通过使用来自多个GCM的[多模式集合](@entry_id:1128268)进行降尺度来量化。

3.  **降尺度模型不确定性**（Downscaling Model Uncertainty）：选择哪种统计降尺度模型（例如，[线性回归](@entry_id:142318)、[天气发生器](@entry_id:1134017)还是神经网络）本身就存在不确定性。这种不确定性可以通过构建一个包含多种不同结构模型的集合，并使用**[贝叶斯模型平均](@entry_id:168960)**（BMA）等方法进行评估。

4.  **参数不确定性**（Parameter Uncertainty）：即使选定了一种降尺度模型结构，其内部参数（如[回归系数](@entry_id:634860) $\beta$）的估计也因训练数据的有限性而存在不确定性。在贝叶斯框架下，这表现为参数的[后验分布](@entry_id:145605)，可以通过从[后验分布](@entry_id:145605)中抽样来传播这种不确定性。

利用**[全方差公式](@entry_id:177482)**（Law of Total Variance），我们可以将给定情景 $S$ 下的总预测[方差分解](@entry_id:912477)为可归因于上述不确定性来源的部分和模型固有的随机性部分 。一个完整的降尺度研究应当清晰地呈现这些不同来源的不确定性，从而为使用者提供关于预测结果可靠性的全面信息。