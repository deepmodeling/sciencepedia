{
    "hands_on_practices": [
        {
            "introduction": "构建一个有效的统计降尺度模型，首要任务是从众多全球气候模型（GCM）输出的潜在预测变量中，筛选出最关键的少数几个。直接使用所有变量不仅计算成本高，还容易导致模型过拟合，使其对训练数据之外的情况泛化能力变差。本实践将引导你应用一种结合了信息论和统计学的系统性方法，即利用互信息（Mutual Information）来衡量预测变量与目标变量（如局地降水）的相关性，并结合偏相关（Partial Correlation）来剔除冗余信息，从而构建一个既简约又强大的预测变量集 。",
            "id": "4094010",
            "problem": "给定一个用于统计降尺度的综合但科学上合理的设置，该方法旨在从大尺度全球环流模型 (GCM) 的预测因子中降尺度得到局部降水。任务是实现一个程序，在联合高斯假设下，通过结合互信息 (MI) 和偏相关 (PC) 来执行特征筛选，并选择一个携带关于局部降水的独特信息的最小预测因子子集。\n\n您必须使用的基本原理包括以下内容：\n- 互信息 (MI) 定义为联合分布与其边缘分布乘积之间的库尔贝克-莱布勒散度，对于联合高斯变量，其仅取决于它们的线性相关性。\n- 相关性和协方差定义为标准化距平的二阶矩统计量。\n- 偏相关 (PC) 定义为通过对变量进行线性投影并移除条件变量的影响后，所得到的残差之间的相关性。\n\n目标是设计一个从这些定义出发的逻辑和数值算法，不使用任何绕过这些基本原理的启发式捷径，通过序贯前向筛选策略获得一个最小的预测因子子集。\n\n数据生成协议（您的程序需精确复现）：\n- 为 $6$ 个 GCM 预测因子生成 $N = 600$ 个时间步的月度距平，顺序为 $[u, v, T, q, \\omega, \\Phi]$，其中 $u$ 和 $v$ 是纬向和经向风分量，$T$ 是气温，$q$ 是比湿，$\\omega$ 是垂直速度，$\\Phi$ 是位势高度。创建三个独立的潜因子 $L_1, L_2, L_3 \\sim \\mathcal{N}(0,1)$ 和每个预测因子独立的、$\\sigma_\\epsilon = 0.2$ 的高斯噪声 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma_\\epsilon^2)$。为保证可复现性，使用固定的随机种子 $42$。\n- 将预测因子构建为潜因子的线性混合：\n  - $u = 0.8\\,L_1 + 0.2\\,L_2 + \\epsilon_1$\n  - $v = 0.7\\,L_1 - 0.1\\,L_3 + \\epsilon_2$\n  - $T = 0.9\\,L_2 + 0.1\\,L_1 + \\epsilon_3$\n  - $q = 0.85\\,L_2 + \\epsilon_4$\n  - $\\omega = 0.8\\,L_3 + 0.2\\,L_1 + \\epsilon_5$\n  - $\\Phi = -0.7\\,L_3 + 0.1\\,L_2 + \\epsilon_6$\n- 将局部降水距平构建为部分预测因子的线性组合加上独立噪声：\n  - $y = 0.6\\,q + 0.4\\,\\omega + 0.2\\,u + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0,\\sigma_\\eta^2)$ 且 $\\sigma_\\eta = 0.7$，并与所有其他变量独立。\n\n处理和筛选要求：\n- 在计算任何统计数据之前，将所有序列（$y$ 和每个预测因子）标准化，使其均值为零，方差为一。\n- 在联合高斯假设下，仅使用相关性所隐含的线性依赖结构来计算 $y$ 与每个预测因子之间的互信息。\n- 对于 $y$ 和任何候选预测因子在给定当前已选集合下的偏相关，应从第一性原理出发，计算 $y$ 和该候选预测因子在线性投影到当前已选预测因子张成的空间后，两者残差之间的相关性。\n- 实现一个序贯前向筛选算法：\n  - 用一个空集 $S$ 初始化已选集合。\n  - 在每一步中，在所有不在 $S$ 中的预测因子中，计算与 $y$ 的互信息，并选择互信息最大的候选者。如果这个最大互信息低于给定的互信息阈值 $\\tau_{\\mathrm{MI}}$，则终止。\n  - 对于选定的候选者，计算其与 $y$ 在当前 $S$ 条件下的偏相关。如果偏相关的绝对值至少为给定的阈值 $\\tau_{\\mathrm{PC}}$，则将该候选者添加到 $S$ 中。否则，丢弃该候选者，但继续筛选剩余的预测因子。\n  - 继续此过程，直到没有剩余预测因子的互信息高于 $\\tau_{\\mathrm{MI}}$，或者所有预测因子都已被选择或丢弃。\n\n测试套件：\n- 将您的算法应用于具有以下参数对 $(\\tau_{\\mathrm{MI}}, \\tau_{\\mathrm{PC}})$ 的综合数据集：\n  - 情况 1：$(0.075, 0.12)$\n  - 情况 2：$(0.14, 0.12)$\n  - 情况 3：$(0.075, 0.45)$\n  - 情况 4：$(0.40, 0.10)$\n  这些情况被选择用于测试典型情况、更严格的互信息阈值、更严格的偏相关阈值，以及没有预测因子满足互信息阈值的边界情况。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表，每个结果是算法按选择顺序列出的已选预测因子索引列表（使用从零开始的索引，顺序为 $[u, v, T, q, \\omega, \\Phi]$）。例如，一个有效的输出格式为 $[[a_1,a_2],[b_1],[],[c_1,c_2,c_3]]$，其中每个内部列表对应于四个测试用例之一。\n- 此问题中不需要进行物理单位转换。所有计算都是无量纲的距平值。",
            "solution": "该问题要求实现一个统计降尺度特征选择算法。该过程是一种序贯前向筛选方法，它结合了用于候选选择的互信息 (MI) 和用于冗余检查的偏相关 (PC)。整个过程将在一个综合生成的数据集上进行验证，该数据集模拟了大尺度大气预测因子与局部降水之间可能存在的合理关系。\n\n首先，我们建立算法所依赖的理论和数学框架。问题提供了一个明确定义的数据生成协议，我们必须精确地复现它。\n\n**1. 数据生成和标准化**\n\n综合数据包含 $N=600$ 个时间步。我们生成三个独立的潜因子 $L_1, L_2, L_3$，每个因子都从标准正态分布 $L_k \\sim \\mathcal{N}(0, 1)$ 中抽样。六个预测因子变量，对应于大气场 $[u, v, T, q, \\omega, \\Phi]$，被构建为这些潜因子的线性组合，并加上独立的标准差为 $\\sigma_\\epsilon = 0.2$ 的高斯噪声 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$。然后，预测变量（局部降水 $y$）被构建为这些预测因子（$u$，$q$，$\\omega$）子集的线性组合，并加上其自身的、标准差为 $\\sigma_\\eta = 0.7$ 的独立噪声项 $\\eta \\sim \\mathcal{N}(0, \\sigma_\\eta^2)$。这种构造确保了所有变量都是联合高斯的，这是后续分析的一个关键假设。使用固定的随机种子 $42$ 来确保可复现性。\n\n在进行任何统计分析之前，所有生成的时间序列（6个预测因子和预测变量 $y$）都必须进行标准化。对于任何时间序列向量 $\\mathbf{x}$，其标准化版本 $\\mathbf{x}_{std}$ 的计算方式如下：\n$$ \\mathbf{x}_{std} = \\frac{\\mathbf{x} - \\mu_x}{\\sigma_x} $$\n其中 $\\mu_x$ 是 $\\mathbf{x}$ 的均值，$\\sigma_x$ 是其标准差。该变换使得序列的均值为零，方差为一，从而简化了相关性的计算。\n\n**2. 统计度量**\n\n筛选算法依赖于两个关键的统计度量：互信息和偏相关。\n\n**2.1. 互信息 (MI)**\n在两个变量（例如 $X$ 和 $Y$）是联合高斯的假设下，它们的互信息 $I(X; Y)$ 是其皮尔逊相关系数 $\\rho_{XY}$ 的函数：\n$$ I(X; Y) = -\\frac{1}{2} \\ln(1 - \\rho_{XY}^2) $$\n由于我们的数据已经标准化，两个长度为 $N$ 的序列向量 $\\mathbf{x}$ 和 $\\mathbf{y}$ 之间的相关系数计算为 $\\rho_{XY} = \\frac{1}{N} \\mathbf{x}^T \\mathbf{y}$。MI 量化了两个变量之间的总统计依赖性。在我们的算法中，它被用来在每一步中从可用候选项中识别信息量最大的预测因子。\n\n**2.2. 偏相关 (PC)**\n偏相关衡量了在移除一个或多个其他变量的线性影响后，两个变量之间的线性关系。预测变量 $\\mathbf{y}$ 和候选预测因子 $\\mathbf{x}_c$ 之间，以一组已选预测因子 $S = \\{\\mathbf{s}_1, \\dots, \\mathbf{s}_k\\}$ 为条件的偏相关，被定义为在 $\\mathbf{y}$ 和 $\\mathbf{x}_c$ 对 $S$ 中的变量进行线性回归后，它们残差之间的相关性。\n\n设 $\\mathbf{Z}$ 是一个 $N \\times k$ 矩阵，其列是 $S$ 中预测因子​​的时间序列。向量 $\\mathbf{v}$ 在 $\\mathbf{Z}$ 的列空间上的线性投影由下式给出：\n$$ \\text{proj}_{\\mathbf{Z}}(\\mathbf{v}) = \\mathbf{Z}(\\mathbf{Z}^T \\mathbf{Z})^{-1} \\mathbf{Z}^T \\mathbf{v} $$\n$\\mathbf{y}$ 和 $\\mathbf{x}_c$ 的残差为：\n$$ \\mathbf{y}_{res} = \\mathbf{y} - \\text{proj}_{\\mathbf{Z}}(\\mathbf{y}) $$\n$$ \\mathbf{x}_{c,res} = \\mathbf{x}_c - \\text{proj}_{\\mathbf{Z}}(\\mathbf{x}_c) $$\n偏相关即为这两个残差向量的皮尔逊相关：\n$$ \\rho_{y,x_c \\cdot S} = \\text{corr}(\\mathbf{y}_{res}, \\mathbf{x}_{c,res}) = \\frac{\\mathbf{y}_{res}^T \\mathbf{x}_{c,res}}{\\sqrt{(\\mathbf{y}_{res}^T \\mathbf{y}_{res}) (\\mathbf{x}_{c,res}^T \\mathbf{x}_{c,res})}} $$\n在算法中，较高的偏相关绝对值表示候选预测因子提供了关于预测变量的新的、非冗余的信息。为了数值稳定性，最好使用最小二乘解算器来计算投影，而不是通过显式地对矩阵 $\\mathbf{Z}^T \\mathbf{Z}$ 求逆。如果已选预测因子集合 $S$ 为空，则偏相关简化为简单相关 $\\rho_{y,x_c}$。\n\n**3. 序贯前向筛选算法**\n\n问题的核心是为给定的阈值对 $(\\tau_{\\mathrm{MI}}, \\tau_{\\mathrm{PC}})$ 实现以下迭代算法：\n\n1.  **初始化**：\n    - 令 $P = \\{0, 1, 2, 3, 4, 5\\}$ 为所有预测因子索引的集合。\n    - 初始化可用预测因子集合 $P_{avail} = P$。\n    - 初始化已选预测因子集合 $S = \\emptyset$。最终结果将是基于此集合的有序列表。\n\n2.  **迭代循环**：只要 $P_{avail}$ 不为空，该过程就继续。\n    a. **候选选择**：对于每个预测因子 $p \\in P_{avail}$，计算互信息 $I(y; p)$。识别使该 MI 值最大化的候选预测因子 $p^*$：$p^* = \\arg\\max_{p \\in P_{avail}} I(y; p)$。\n    b. **MI 阈值判断**：如果 $I(y; p^*)  \\tau_{\\mathrm{MI}}$，则剩余的预测因子信息量不足。终止算法。\n    c. **冗余检查**：计算候选者 $p^*$ 与预测变量 $y$ 之间的偏相关 $\\rho_{y, p^* \\cdot S}$，条件是当前已选预测因子集合 $S$。\n    d. **PC 阈值判断**：\n        - 如果 $|\\rho_{y, p^* \\cdot S}| \\ge \\tau_{\\mathrm{PC}}$，则候选者 $p^*$ 提供了独特的信息。将其索引添加到已选预测因子的有序列表中，并将其添加到条件集 $S$ 中以用于后续步骤。\n        - 如果 $|\\rho_{y, p^* \\cdot S}|  \\tau_{\\mathrm{PC}}$，则该候选者是冗余的。它将被丢弃，不添加到已选集合中。\n    e. **更新**：无论 PC 测试的结果如何，都从 $P_{avail}$ 中移除 $p^*$。这确保每个预测因子只被考虑一次。\n\n3.  **终止**：当最佳可用候选者的 MI 低于 $\\tau_{\\mathrm{MI}}$ 或所有预测因子都已被考虑（即 $P_{avail}$ 为空）时，循环终止。最终输出是所选预测因子索引的有序列表。对四个测试用例中的每一个都重复此完整过程。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a sequential forward screening algorithm for statistical downscaling\n    based on Mutual Information and Partial Correlation.\n    \"\"\"\n\n    # --- Step 1: Data Generation ---\n    def _generate_data(N=600, seed=42):\n        rng = np.random.default_rng(seed)\n        \n        # Latent factors\n        L1 = rng.normal(size=N)\n        L2 = rng.normal(size=N)\n        L3 = rng.normal(size=N)\n        \n        # Noise terms\n        sigma_eps = 0.2\n        eps = rng.normal(scale=sigma_eps, size=(N, 6))\n        \n        # Predictors [u, v, T, q, omega, Phi]\n        predictors = np.zeros((N, 6))\n        predictors[:, 0] = 0.8 * L1 + 0.2 * L2 + eps[:, 0]  # u\n        predictors[:, 1] = 0.7 * L1 - 0.1 * L3 + eps[:, 1]  # v\n        predictors[:, 2] = 0.9 * L2 + 0.1 * L1 + eps[:, 2]  # T\n        predictors[:, 3] = 0.85 * L2 + eps[:, 3]             # q\n        predictors[:, 4] = 0.8 * L3 + 0.2 * L1 + eps[:, 4]  # omega\n        predictors[:, 5] = -0.7 * L3 + 0.1 * L2 + eps[:, 5] # Phi\n        \n        # Predictand (local precipitation)\n        sigma_eta = 0.7\n        eta = rng.normal(scale=sigma_eta, size=N)\n        y = (0.6 * predictors[:, 3] + \n             0.4 * predictors[:, 4] + \n             0.2 * predictors[:, 0] + \n             eta)\n        \n        # Standardization\n        def standardize(series):\n            return (series - np.mean(series)) / np.std(series)\n            \n        y_std = standardize(y)\n        predictors_std = np.apply_along_axis(standardize, 0, predictors)\n        \n        return y_std, predictors_std\n\n    # --- Step 2: Statistical Helper Functions ---\n    def _calculate_mi(x, y):\n        \"\"\"Calculates Mutual Information for standardized Gaussian variables.\"\"\"\n        # For standardized variables, corr = mean(x*y)\n        rho_sq = np.corrcoef(x, y)[0, 1]**2\n        # np.clip to avoid log(0) from floating point inaccuracies if rho_sq is exactly 1\n        return -0.5 * np.log(1 - np.clip(rho_sq, 0, 1 - 1e-15))\n\n    def _calculate_pc(y_target, x_candidate, Z_conditioning):\n        \"\"\"\n        Calculates Partial Correlation of y and x, conditioning on columns of Z.\n        y_target, x_candidate are (N,) arrays.\n        Z_conditioning is an (N, k) array of k conditioning variables.\n        \"\"\"\n        if Z_conditioning.shape[1] == 0:\n            # If conditioning set is empty, PC is just the simple correlation\n            return np.corrcoef(y_target, x_candidate)[0, 1]\n        \n        # Regress y_target on Z_conditioning\n        beta_y = np.linalg.lstsq(Z_conditioning, y_target, rcond=None)[0]\n        y_res = y_target - Z_conditioning @ beta_y\n        \n        # Regress x_candidate on Z_conditioning\n        beta_x = np.linalg.lstsq(Z_conditioning, x_candidate, rcond=None)[0]\n        x_res = x_candidate - Z_conditioning @ beta_x\n        \n        # Correlation of residuals\n        return np.corrcoef(y_res, x_res)[0, 1]\n\n\n    # --- Step 3: Main Screening Algorithm ---\n    y, predictors = _generate_data()\n    num_predictors = predictors.shape[1]\n    \n    test_cases = [\n        (0.075, 0.12),  # Case 1\n        (0.14, 0.12),   # Case 2\n        (0.075, 0.45),   # Case 3\n        (0.40, 0.10)    # Case 4\n    ]\n    \n    final_results = []\n\n    for tau_mi, tau_pc in test_cases:\n        selected_indices = []\n        available_indices = list(range(num_predictors))\n        \n        while available_indices:\n            # a. Candidate Selection based on MI\n            mis = {i: _calculate_mi(predictors[:, i], y) for i in available_indices}\n            \n            if not mis: break # Should not happen with while loop condition, but for safety.\n            \n            best_candidate_idx = max(mis, key=mis.get)\n            max_mi = mis[best_candidate_idx]\n            \n            # b. MI Thresholding\n            if max_mi  tau_mi:\n                break\n            \n            # c. Redundancy Check with PC\n            if selected_indices:\n                Z = predictors[:, selected_indices]\n            else:\n                # Create an empty array with correct number of rows for the helper\n                Z = np.empty((y.shape[0], 0))\n\n            candidate_predictor = predictors[:, best_candidate_idx]\n            pc = _calculate_pc(y, candidate_predictor, Z)\n            \n            # d. PC Thresholding\n            if abs(pc) = tau_pc:\n                selected_indices.append(best_candidate_idx)\n            \n            # e. Update available predictors\n            available_indices.remove(best_candidate_idx)\n            \n        final_results.append(selected_indices)\n\n    # Convert results to the required string format\n    result_str = \"[\" + \",\".join([str(res) for res in final_results]) + \"]\"\n    print(result_str.replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "在选定了合适的预测变量并构建了初步的回归模型后，我们必须处理气候时间序列数据中一个常见而棘手的问题：自相关。标准线性回归模型的一个核心假设是误差项（即模型无法解释的部分）是相互独立的，但气候系统具有“记忆性”，例如，今天的温度会影响明天的温度，这导致误差项随时间呈现相关性。本实践将带你诊断并解决这一问题 ：你将首先使用Durbin-Watson等检验来识别残差中的自相关性，然后应用可行广义最小二乘法（Feasible Generalized Least Squares）来调整模型，从而获得更可靠、更高效的参数估计。",
            "id": "4094057",
            "problem": "考虑一个统计降尺度（statistical downscaling）的场景，其中一个站点的温度时间序列被建模为对大尺度预报因子的线性响应，并带有自回归噪声。设站点温度为 $T_t$（单位：摄氏度），大尺度位势高度为 $Z_t$（单位：米），大尺度比湿度为 $H_t$（单位：千克/千克）。假设线性模型为\n$$\nT_t \\;=\\; \\beta_0 \\;+\\; \\beta_1 Z_t \\;+\\; \\beta_2 H_t \\;+\\; \\varepsilon_t,\n$$\n其误差为一阶自回归（AutoRegressive of order one, AR(1)）误差，由下式给出：\n$$\n\\varepsilon_t \\;=\\; \\phi\\,\\varepsilon_{t-1} \\;+\\; u_t,\n$$\n其中 $\\phi$ 是滞后-1自回归系数，$u_t$ 是均值为零、方差有限的白噪声。任何三角函数中出现的角度都必须以弧度处理。\n\n您必须实现普通最小二乘法（Ordinary Least Squares, OLS）来拟合该线性模型以获得 $\\hat{\\beta}$，检验 OLS 残差是否存在滞后-1自相关，然后通过应用带有估计值 $\\hat{\\phi}$ 的 Prais–Winsten 变换，在 AR(1) 误差假设下使用可行广义最小二乘法（Feasible Generalized Least Squares, FGLS）来调整回归。对于自相关检验，计算 Durbin–Watson 统计量和滞后为 1 的 Ljung–Box 检验统计量，并使用自由度为 1 的卡方分布来获得 $p$ 值。如果 $p$ 值  0.05，则判定检测到自相关。\n\n为确保不依赖外部随机性的可复现性，您需要通过线性同余生成器（Linear Congruential Generator, LCG）确定性地生成一个伪随机均匀序列来产生 $u_t$，并将其重新缩放以达到指定的目标标准差。使用以下递推关系：\n$$\ns_t \\;=\\; (a\\,s_{t-1} + c)\\;\\bmod\\; m,\\quad x_t \\;=\\; \\frac{s_t}{m},\\quad v_t \\;=\\; x_t - \\frac{1}{2},\\quad u_t \\;=\\; \\frac{\\sigma}{\\sqrt{1/12}}\\; v_t,\n$$\n其中 $a=16807$, $c=0$, $m=2147483647$，并指定 $s_0$（种子）。单位如下：温度 $T_t$ 为摄氏度，位势高度 $Z_t$ 为米，比湿度 $H_t$ 为千克/千克。将所有最终回归系数表示为：$\\beta_0$ 以摄氏度为单位，$\\beta_1$ 以摄氏度/米为单位，$\\beta_2$ 以摄氏度/（千克/千克）为单位。Durbin–Watson 统计量和 Ljung–Box $p$ 值是无单位的。\n\n使用以下公式构建时间序列：\n$$\nZ_t \\;=\\; z_0 \\;+\\; A_Z \\sin\\!\\left(\\frac{2\\pi t}{12}\\right),\n$$\n$$\nH_t \\;=\\; h_0 \\;+\\; A_H \\cos\\!\\left(\\frac{2\\pi t}{12} + \\theta\\right),\n$$\n其中 $t=1,2,\\dots,N$，以及 AR(1) 递推关系 $\\varepsilon_t = \\phi\\,\\varepsilon_{t-1} + u_t$（$\\varepsilon_0 = 0$）。\n\n对于每个测试用例，计算：\n- OLS 系数 $\\hat{\\beta}_0$、$\\hat{\\beta}_1$、$\\hat{\\beta}_2$。\n- 根据 OLS 残差 $r_t$ 计算的 Durbin–Watson 统计量 $D$：\n$$\nD \\;=\\; \\frac{\\sum_{t=2}^{N} (r_t - r_{t-1})^2}{\\sum_{t=1}^{N} r_t^2}.\n$$\n- 使用以下公式计算的 Ljung–Box 滞后-1 $p$ 值：\n$$\nr_1 \\;=\\; \\frac{\\sum_{t=2}^{N} r_t r_{t-1}}{\\sum_{t=1}^{N} r_t^2},\\quad\nQ \\;=\\; \\frac{N(N+2)}{N-1}\\, r_1^2,\\quad p \\;=\\; 1 - F_{\\chi^2,1}(Q),\n$$\n其中 $F_{\\chi^2,1}$ 是自由度为 1 的卡方分布的累积分布函数。\n- 自回归参数估计值：\n$$\n\\hat{\\phi} \\;=\\; \\frac{\\sum_{t=2}^{N} r_t r_{t-1}}{\\sum_{t=2}^{N} r_{t-1}^2},\n$$\n为保证数值稳定性，该值将被裁剪到区间 $[-0.99,0.99]$ 内。\n- Prais–Winsten FGLS 系数 $\\tilde{\\beta}_0$、$\\tilde{\\beta}_1$、$\\tilde{\\beta}_2$，通过对设计矩阵和响应变量进行如下变换得到：\n$$\nY_t^* \\;=\\; \n\\begin{cases}\n\\sqrt{1-\\hat{\\phi}^2}\\; Y_1,  t=1 \\\\[4pt]\nY_t - \\hat{\\phi}\\,Y_{t-1},  t=2,\\dots,N,\n\\end{cases}\n\\qquad\nX_t^* \\;=\\;\n\\begin{cases}\n\\sqrt{1-\\hat{\\phi}^2}\\; X_1,  t=1 \\\\[4pt]\nX_t - \\hat{\\phi}\\,X_{t-1},  t=2,\\dots,N,\n\\end{cases}\n$$\n并通过对 $X^*$ 回归 $Y^*$ 的 OLS 得到，其中 $X_t = [1,\\;Z_t,\\;H_t]$ 包含一个截距项。\n\n使用以下参数集的测试套件，每个测试用例由 $(N,\\;\\phi,\\;\\beta_0,\\;\\beta_1,\\;\\beta_2,\\;z_0,\\;A_Z,\\;h_0,\\;A_H,\\;\\theta,\\;\\sigma,\\;s_0)$ 指定：\n\n- 测试用例 1（具有中等自相关的一般情况）：$(N=\\;120,\\;\\phi=\\;0.6,\\;\\beta_0=\\;5.0,\\;\\beta_1=\\;-0.004,\\;\\beta_2=\\;8.0,\\;z_0=\\;1500,\\;A_Z=\\;100,\\;h_0=\\;0.006,\\;A_H=\\;0.002,\\;\\theta=\\;0.7,\\;\\sigma=\\;0.5,\\;s_0=\\;13579)$。\n- 测试用例 2（无自相关的边界情况）：$(N=\\;100,\\;\\phi=\\;0.0,\\;\\beta_0=\\;2.0,\\;\\beta_1=\\;0.003,\\;\\beta_2=\\;-4.0,\\;z_0=\\;3000,\\;A_Z=\\;50,\\;h_0=\\;0.012,\\;A_H=\\;0.001,\\;\\theta=\\;1.1,\\;\\sigma=\\;0.4,\\;s_0=\\;24680)$。\n- 测试用例 3（具有接近单位根自相关的边缘情况）：$(N=\\;200,\\;\\phi=\\;0.95,\\;\\beta_0=\\;0.0,\\;\\beta_1=\\;0.001,\\;\\beta_2=\\;2.0,\\;z_0=\\;500,\\;A_Z=\\;200,\\;h_0=\\;0.010,\\;A_H=\\;0.003,\\;\\theta=\\;0.3,\\;\\sigma=\\;0.2,\\;s_0=\\;98765)$。\n\n您的程序必须：\n- 对于每个测试用例，构建 $Z_t$、$H_t$，通过 LCG 生成 $u_t$ 和通过 AR(1) 递推生成 $\\varepsilon_t$，然后根据指定的线性模型计算 $T_t$。\n- 执行 OLS 以获得 $\\hat{\\beta}$，计算 Durbin–Watson 统计量 $D$，计算 Ljung–Box $p$ 值，估计 $\\hat{\\phi}$，并执行 Prais–Winsten FGLS 以获得 $\\tilde{\\beta}$。\n- 对每个测试用例，按顺序生成扁平化序列作为输出：\n$$\n\\left[\\hat{\\beta}_0,\\;\\hat{\\beta}_1,\\;\\hat{\\beta}_2,\\;D,\\;p,\\;\\hat{\\phi},\\;\\tilde{\\beta}_0,\\;\\tilde{\\beta}_1,\\;\\tilde{\\beta}_2\\right],\n$$\n其中所有浮点数四舍五入到六位小数。通过串联将所有三个测试用例的结果汇总到一个列表中。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result1,result2,\\dots]$）的结果，其中所有浮点数都四舍五入到六位小数，布尔值（如有）将显示为 $True$ 或 $False$。角度必须以弧度为单位，所有物理量必须遵守上述单位。",
            "solution": "该问题要求为一个带有自回归误差的时间序列模型实现一个统计分析流程。该过程涉及数据生成、通过普通最小二乘法（OLS）进行模型估计、自相关诊断检验，以及使用可行广义最小二乘法（FGLS）通过 Prais-Winsten 变换进行模型校正。整个过程是确定性的，以确保可复现性。\n\n**1. 数据生成**\n\n第一步是为每个测试用例构建时间序列数据集。模型由下式给出：\n$$\nT_t = \\beta_0 + \\beta_1 Z_t + \\beta_2 H_t + \\varepsilon_t\n$$\n其中 $T_t$ 是响应变量（温度），$Z_t$ 和 $H_t$ 是预报因子（位势高度和比湿度）。预报因子是作为时间 $t=1, 2, \\dots, N$ 的确定性正弦函数生成的：\n$$\nZ_t = z_0 + A_Z \\sin\\left(\\frac{2\\pi t}{12}\\right)\n$$\n$$\nH_t = h_0 + A_H \\cos\\left(\\frac{2\\pi t}{12} + \\theta\\right)\n$$\n误差项 $\\varepsilon_t$ 服从一阶自回归（AR(1)）过程，这引入了序列相关性：\n$$\n\\varepsilon_t = \\phi\\,\\varepsilon_{t-1} + u_t\n$$\n初始条件为 $\\varepsilon_0 = 0$。$u_t$ 项代表白噪声，它是使用线性同余生成器（LCG）确定性地生成的，以确保结果可复现。LCG 序列 $s_t$ 由 $s_t = (a s_{t-1} + c) \\pmod m$ 定义，其中给定参数 $a = 16807$，$c = 0$，$m = 2147483647$，以及一个特定的种子 $s_0$。该序列随后被转换为一个均值为零、标准差为 $\\sigma$ 的序列 $u_t$。变换公式为：\n$$\nu_t = \\frac{\\sigma}{\\sqrt{1/12}} \\left( \\frac{s_t}{m} - \\frac{1}{2} \\right)\n$$\n这种缩放是正确的，因为 $[0,1]$ 上的均匀分布的方差为 $1/12$，减去 $1/2$ 将均值中心化到 $0$ 而不改变方差。\n\n**2. 普通最小二乘法（OLS）估计**\n\n我们首先使用 OLS 拟合模型，该方法假设误差 $\\varepsilon_t$ 是不相关的。模型以矩阵形式表示为 $Y = X\\beta + \\varepsilon$，其中 $Y$ 是温度 $T_t$ 的向量，$X$ 是设计矩阵，其列分别对应截距、$Z_t$ 和 $H_t$。$\\beta = [\\beta_0, \\beta_1, \\beta_2]^T$ 的 OLS 估计量为：\n$$\n\\hat{\\beta} = (X^T X)^{-1} X^T Y\n$$\n这提供了初始估计值 $(\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2)$。\n\n**3. 自相关诊断**\n\n由于数据是在存在 AR(1) 误差的情况下生成的（当 $\\phi \\neq 0$ 时），OLS 的非相关误差假设被违反了。这可能导致系数估计效率低下和标准误有偏。我们使用 OLS 残差 $r_t = T_t - (\\hat{\\beta}_0 + \\hat{\\beta}_1 Z_t + \\hat{\\beta}_2 H_t)$ 来检验这一点。\n\n- **Durbin-Watson 统计量 ($D$)**：该统计量用于检验一阶自相关。其计算公式为：\n  $$\n  D = \\frac{\\sum_{t=2}^{N} (r_t - r_{t-1})^2}{\\sum_{t=1}^{N} r_t^2}\n  $$\n  $D \\approx 2$ 的值表明没有自相关，而接近 $0$ 的值表示正自相关，接近 $4$ 的值表示负自相关。\n\n- **Ljung-Box 检验**：这是一个更通用的检验。对于滞后 1，检验统计量 $Q$ 是根据残差的一阶样本自相关 $r_1$ 计算的：\n  $$\n  r_1 = \\frac{\\sum_{t=2}^{N} r_t r_{t-1}}{\\sum_{t=1}^{N} r_t^2}, \\quad Q = \\frac{N(N+2)}{N-1} r_1^2\n  $$\n  在无自相关的原假设下，$Q$ 服从自由度为 1 的卡方分布（$\\chi^2_1$）。$p$ 值是观察到等于或比 $Q$ 更极端的检验统计量的概率，计算为 $p = 1 - F_{\\chi^2,1}(Q)$，其中 $F$ 是累积分布函数（CDF）。\n\n**4. 可行广义最小二乘法（FGLS）估计**\n\n如果检测到自相关，我们可以应用 FGLS 来获得更有效的估计。Prais-Winsten 方法是针对 AR(1) 误差的一种 FGLS 程序。\n\n- **估计自相关系数 ($\\hat{\\phi}$)**：首先，通过将 OLS 残差 $r_t$ 对 $r_{t-1}$ 进行回归来估计 AR(1) 参数 $\\phi$：\n  $$\n  \\hat{\\phi} = \\frac{\\sum_{t=2}^{N} r_t r_{t-1}}{\\sum_{t=2}^{N} r_{t-1}^2}\n  $$\n  为确保下一步的稳定性，此估计值被裁剪到区间 $[-0.99, 0.99]$ 内。\n\n- **Prais-Winsten 变换**：对原始数据进行变换以消除自相关。该变换对数据进行准差分：\n  $$\n  Y_t^* = Y_t - \\hat{\\phi} Y_{t-1}, \\quad X_t^* = X_t - \\hat{\\phi} X_{t-1} \\quad \\text{对于 } t=2, \\dots, N\n  $$\n  为了保留其信息，第一个观测值（$t=1$）被特殊处理，用 $\\sqrt{1-\\hat{\\phi}^2}$ 加权：\n  $$\n  Y_1^* = \\sqrt{1-\\hat{\\phi}^2} Y_1, \\quad X_1^* = \\sqrt{1-\\hat{\\phi}^2} X_1\n  $$\n  变换后的模型 $Y^* = X^*\\beta + u^*$ 现在有一个近似为白噪声的误差项 $u^*$。\n\n- **对变换后的数据进行 OLS**：最后，对变换后的变量应用 OLS 以获得 FGLS 估计量 $\\tilde{\\beta}$：\n  $$\n  \\tilde{\\beta} = ((X^*)^T X^*)^{-1} (X^*)^T Y^*\n  $$\n这提供了校正后的 FGLS 系数 $(\\tilde{\\beta}_0, \\tilde{\\beta}_1, \\tilde{\\beta}_2)$，在存在序列相关的情况下，这些系数通常比 OLS 估计更有效。实现将对提供的三个测试用例中的每一个执行此完整序列。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    Generates time series data with AR(1) errors, performs OLS and FGLS,\n    and computes autocorrelation diagnostics.\n    \"\"\"\n    test_cases = [\n        # (N, phi, beta0, beta1, beta2, z0, AZ, h0, AH, theta, sigma, s0)\n        (120, 0.6, 5.0, -0.004, 8.0, 1500, 100, 0.006, 0.002, 0.7, 0.5, 13579),\n        (100, 0.0, 2.0, 0.003, -4.0, 3000, 50, 0.012, 0.001, 1.1, 0.4, 24680),\n        (200, 0.95, 0.0, 0.001, 2.0, 500, 200, 0.010, 0.003, 0.3, 0.2, 98765)\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        N, phi, beta0, beta1, beta2, z0, AZ, h0, AH, theta, sigma, s0 = case\n        \n        # 1. Data Generation\n        t = np.arange(1, N + 1)\n        \n        # Generate predictors\n        Z_t = z0 + AZ * np.sin(2 * np.pi * t / 12)\n        H_t = h0 + AH * np.cos(2 * np.pi * t / 12 + theta)\n        \n        # Generate white noise u_t using LCG\n        s = np.zeros(N, dtype=np.int64)\n        s_prev = s0\n        a, c, m = 16807, 0, 2147483647\n        for i in range(N):\n            s_curr = (a * s_prev + c) % m\n            s[i] = s_curr\n            s_prev = s_curr\n        \n        x_t = s / m\n        v_t = x_t - 0.5\n        u_t = (sigma / np.sqrt(1/12)) * v_t\n        \n        # Generate AR(1) errors epsilon_t\n        eps_t = np.zeros(N)\n        eps_t[0] = phi * 0 + u_t[0]  # eps_0 = 0\n        for i in range(1, N):\n            eps_t[i] = phi * eps_t[i-1] + u_t[i]\n            \n        # Generate response variable T_t\n        T_t = beta0 + beta1 * Z_t + beta2 * H_t + eps_t\n        \n        # 2. Ordinary Least Squares (OLS)\n        Y = T_t\n        X = np.c_[np.ones(N), Z_t, H_t]\n        \n        try:\n            beta_hat = np.linalg.inv(X.T @ X) @ X.T @ Y\n        except np.linalg.LinAlgError:\n            # Fallback to pseudo-inverse for near-singular matrices\n            beta_hat = np.linalg.pinv(X.T @ X) @ X.T @ Y\n\n        b0_hat, b1_hat, b2_hat = beta_hat\n        \n        # 3. Autocorrelation Diagnostics\n        residuals = Y - X @ beta_hat\n        \n        # Durbin-Watson statistic\n        dw_num = np.sum((residuals[1:] - residuals[:-1])**2)\n        dw_den = np.sum(residuals**2)\n        D = dw_num / dw_den\n        \n        # Ljung-Box lag-1 test\n        r1_num = np.sum(residuals[1:] * residuals[:-1])\n        r1_den = np.sum(residuals**2)\n        r1 = r1_num / r1_den\n        Q = N * (N + 2) / (N - 1) * r1**2\n        p_value = 1.0 - chi2.cdf(Q, df=1)\n        \n        # 4. Feasible Generalized Least Squares (FGLS)\n        # Estimate phi from OLS residuals\n        phi_hat_num = np.sum(residuals[1:] * residuals[:-1])\n        phi_hat_den = np.sum(residuals[:-1]**2)\n        phi_hat_raw = phi_hat_num / phi_hat_den\n        phi_hat = np.clip(phi_hat_raw, -0.99, 0.99)\n        \n        # Prais-Winsten transformation\n        Y_star = np.zeros_like(Y)\n        X_star = np.zeros_like(X)\n        \n        pw_factor = np.sqrt(1 - phi_hat**2)\n        \n        Y_star[0] = pw_factor * Y[0]\n        X_star[0, :] = pw_factor * X[0, :]\n        \n        Y_star[1:] = Y[1:] - phi_hat * Y[:-1]\n        X_star[1:, :] = X[1:, :] - phi_hat * X[:-1, :]\n        \n        # OLS on transformed data\n        try:\n            beta_tilde = np.linalg.inv(X_star.T @ X_star) @ X_star.T @ Y_star\n        except np.linalg.LinAlgError:\n            beta_tilde = np.linalg.pinv(X_star.T @ X_star) @ X_star.T @ Y_star\n\n        b0_tilde, b1_tilde, b2_tilde = beta_tilde\n        \n        # 5. Collect and format results\n        # The problem asks for the clipped phi_hat to be reported\n        case_results = [\n            b0_hat, b1_hat, b2_hat,\n            D, p_value, phi_hat,\n            b0_tilde, b1_tilde, b2_tilde\n        ]\n        \n        all_results.extend([round(v, 6) for v in case_results])\n\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}