{
    "hands_on_practices": [
        {
            "introduction": "在尝试优化任何模型参数之前，我们必须首先确定这些参数是否是“可辨识的”。如果不同的参数组合能够产生完全相同的模型输出，那么任何观测数据都无法将它们区分开。本练习探讨了模型输出对参数的敏感性（即雅可比矩阵）与参数可辨识性之间的根本联系，并展示了如何通过重新参数化的策略来解决非唯一的校准问题。",
            "id": "4065497",
            "problem": "考虑一个在数值天气预报和气候模拟中使用的简化单柱模式中的调谐任务，其中三个标量参数 $\\boldsymbol{\\theta} = (\\theta_{1}, \\theta_{2}, \\theta_{3})^{\\top}$ 控制着影响 $m$ 个可观测物理量（例如，多个层面或时间的短波辐射通量）的次网格过程参数化。在背景状态附近的小扰动下，假设模型输出和参数之间的线性化关系为 $\\Delta \\boldsymbol{y} = S \\, \\Delta \\boldsymbol{\\theta}$，其中 $S \\in \\mathbb{R}^{m \\times p}$ 是由列向量 $s_{1}, s_{2}, s_{3} \\in \\mathbb{R}^{m}$ 组成的敏感度矩阵。假设观测误差是独立同分布的高斯分布，方差为 $\\sigma^{2}$，因此权重矩阵为 $W = \\sigma^{-2} I_{m}$。\n\n1. 从高斯误差下费雪信息矩阵 (FIM) 的定义出发，推导出一个因敏感度矩阵列之间的共线性而导致参数线性组合局部不可辨识的充分必要条件。你的推导必须用敏感度矩阵 $S$ 的秩和零空间以及 FIM 的正定性来表示。\n\n2. 现在考虑一个具体设置，其中有 $m=4$ 个输出和 $p=3$ 个参数，敏感度矩阵如下：\n$$\nS \\;=\\;\n\\begin{pmatrix}\n1  0  0 \\\\\n0  2  1 \\\\\n1  0  0 \\\\\n0  2  1\n\\end{pmatrix}.\n$$\n假设对于某个 $\\sigma^{2} > 0$，有 $W = \\sigma^{-2} I_{4}$。识别一个局部不可辨识的参数的非平凡线性组合和一个局部可辨识的组合。构造一个线性重参数化 $\\boldsymbol{\\phi} = R \\boldsymbol{\\theta}$，其中 $R \\in \\mathbb{R}^{3 \\times 3}$ 具有整数项且满行秩，使得 $\\boldsymbol{\\phi}$ 的前两个分量张成可辨识方向，而第三个分量完全位于参数空间的不可辨识子空间中。明确给出重参数化的参数向量 $\\boldsymbol{\\phi}$ 作为 $\\theta_{1}$、$\\theta_{2}$ 和 $\\theta_{3}$ 的函数。你的最终答案必须是写成行矩阵形式的 $\\boldsymbol{\\phi}$ 的闭式解析表达式。无需数值舍入。最终答案无需单位。",
            "solution": "该问题是有效的，因为它在参数估计理论中有科学依据，问题设定良好，目标明确，且没有矛盾或含糊之处。\n\n此问题分为两部分。第一部分要求对局部不可辨识性条件进行理论推导。第二部分将此理论应用于一个具体示例。\n\n**第一部分：局部不可辨识性条件**\n\n模型参数 $\\Delta \\boldsymbol{\\theta} \\in \\mathbb{R}^{p}$ 的小扰动与模型输出 $\\Delta \\boldsymbol{y} \\in \\mathbb{R}^{m}$ 之间的关系由以下线性模型给出：\n$$ \\Delta \\boldsymbol{y} = S \\, \\Delta \\boldsymbol{\\theta} $$\n其中 $S \\in \\mathbb{R}^{m \\times p}$ 是敏感度矩阵。假设观测误差是独立同分布的高斯分布，方差为 $\\sigma^{2}$。相应的误差协方差矩阵为 $C_e = \\sigma^{2} I_{m}$。权重矩阵是误差协方差矩阵的逆，即 $W = C_e^{-1} = \\sigma^{-2} I_{m}$。\n\n费雪信息矩阵 (FIM)，记为 $\\mathcal{I}$，量化了可观测数据 $\\boldsymbol{y}$ 中包含的关于未知参数 $\\boldsymbol{\\theta}$ 的信息量。对于带有加性高斯噪声的线性模型，FIM 由以下表达式给出：\n$$ \\mathcal{I} = S^{\\top} W S $$\n代入给定的权重矩阵 $W = \\sigma^{-2} I_{m}$：\n$$ \\mathcal{I} = S^{\\top} (\\sigma^{-2} I_{m}) S = \\sigma^{-2} S^{\\top} S $$\n由于 $\\sigma^{2} > 0$，常数 $\\sigma^{-2}$ 是一个正标量，除了缩放之外，不影响 FIM 的正（半）定性。\n\n参数向量 $\\boldsymbol{\\theta}$ 的局部可辨识性要求 FIM $\\mathcal{I}$ 是可逆的，这意味着它必须是严格正定的。如果 $\\mathcal{I}$ 是奇异的（即，仅是半正定的），则参数是局部不可辨识的。这种奇异性意味着在参数空间中存在非零方向，沿着这些方向模型输出不发生变化，从而无法区分这些方向上的不同参数值。\n\n对于一个非零向量 $c \\in \\mathbb{R}^{p}$，一个特定的参数线性组合 $c^{\\top} \\boldsymbol{\\theta}$ 是局部不可辨识的，如果其估计量的方差是无穷大。根据克拉默-拉奥下界，这种情况发生于向量 $c$ 位于 FIM 的零空间中。因此，组合 $c^{\\top} \\boldsymbol{\\theta}$ 不可辨识的条件是：\n$$ \\mathcal{I} c = 0 $$\n对于一个非零向量 $c$。代入 $\\mathcal{I}$ 的表达式：\n$$ (\\sigma^{-2} S^{\\top} S) c = 0 $$\n$$ S^{\\top} S c = 0 $$\n此方程表明，FIM $\\mathcal{I}$ 的零空间与矩阵 $S^{\\top} S$ 的零空间相同。\n\n现在，我们建立 $S^{\\top} S$ 的零空间与 $S$ 的零空间之间的关系。设 $c \\in \\text{Null}(S)$。这意味着 $S c = 0$。于是有 $S^{\\top} S c = S^{\\top}(0) = 0$，所以 $c \\in \\text{Null}(S^{\\top} S)$。反之，设 $c \\in \\text{Null}(S^{\\top} S)$，所以 $S^{\\top} S c = 0$。用 $c^{\\top}$ 左乘得到 $c^{\\top} S^{\\top} S c = 0$。这可以重写为 $(Sc)^{\\top}(Sc) = \\|Sc\\|_{2}^{2} = 0$。一个向量的欧几里得范数的平方为零，当且仅当该向量本身是零向量。因此，$Sc=0$，这意味着 $c \\in \\text{Null}(S)$。所以，这两个零空间是相同的：$\\text{Null}(S^{\\top} S) = \\text{Null}(S)$。\n\n这就导出了充分必要条件：一个线性组合 $c^{\\top} \\boldsymbol{\\theta}$ 是局部不可辨识的，当且仅当向量 $c$ 是敏感度矩阵 $S$ 的零空间中的一个非零向量，即 $Sc = 0$。这样一个非零向量 $c$ 的存在等价于 $S$ 的列是线性相关的（共线性），这又意味着 $S$ 的秩小于参数数量 $p$，即 $\\text{rank}(S)  p$。参数空间中的不可辨识方向恰好是由 $S$ 的零空间的基向量所张成的。\n\n**第二部分：具体应用**\n\n我们得到一个具有 $m=4$ 个输出和 $p=3$ 个参数的系统的敏感度矩阵：\n$$\nS =\n\\begin{pmatrix}\n1  0  0 \\\\\n0  2  1 \\\\\n1  0  0 \\\\\n0  2  1\n\\end{pmatrix}\n$$\n设 $S$ 的列为 $s_{1}, s_{2}, s_{3}$。我们检查这些列的线性相关性：\n$s_{1} = (1, 0, 1, 0)^{\\top}$，$s_{2} = (0, 2, 0, 2)^{\\top}$，$s_{3} = (0, 1, 0, 1)^{\\top}$。\n通过观察，我们发现 $s_{2} = 2 s_{3}$。这意味着存在线性相关性：\n$$ 0 \\cdot s_{1} + 1 \\cdot s_{2} - 2 \\cdot s_{3} = 0 $$\n这是一个形如 $S c = 0$ 的方程，其中 $c = (0, 1, -2)^{\\top}$。由于在 $S$ 的零空间中存在一个非零向量 $c$，所以 $S$ 的秩小于 $3$。具体来说，由于 $s_{1}$ 和 $s_{3}$ 是线性无关的，所以 $S$ 的秩为 $2$。$S$ 的零空间是一个由向量 $c = (0, 1, -2)^{\\top}$ 张成的一维子空间。\n\n一个局部不可辨识的参数的非平凡线性组合对应于这个向量 $c$。该组合为 $c^{\\top} \\boldsymbol{\\theta}$：\n$$ 0 \\cdot \\theta_{1} + 1 \\cdot \\theta_{2} - 2 \\cdot \\theta_{3} = \\theta_{2} - 2\\theta_{3} $$\n这个组合是局部不可辨识的。\n\n一个线性组合 $d^{\\top} \\boldsymbol{\\theta}$ 是局部可辨识的，如果向量 $d$ 不在 $S$ 的零空间中。一个简单的选择是 $d = (1, 0, 0)^{\\top}$，这显然不是 $(0, 1, -2)^{\\top}$ 的标量倍。相应的可辨识组合是 $d^{\\top} \\boldsymbol{\\theta} = \\theta_{1}$。\n\n接下来，我们构造重参数化 $\\boldsymbol{\\phi} = R \\boldsymbol{\\theta}$。矩阵 $R$ 必须具有整数项且满秩。新参数 $\\phi_{1}, \\phi_{2}, \\phi_{3}$ 由 $R$ 的行定义。\n第三个分量 $\\phi_{3}$ 必须完全位于不可辨识子空间中。这意味着它在 $R$ 中对应的行向量，我们称之为 $r_{3}^{\\top}$，必须是 $S$ 的零空间的一个基向量。我们可以选择 $r_{3}^{\\top} = (0, 1, -2)$。这得到 $\\phi_{3} = \\theta_{2} - 2\\theta_{3}$。\n\n前两个分量 $\\phi_{1}$ 和 $\\phi_{2}$ 必须张成可辨识方向。可辨识子空间是 $S$ 的零空间的正交补。这是向量 $v$ 的集合，使得 $v \\cdot (0, 1, -2)^{\\top} = 0$。行向量 $r_{1}^{\\top}$ 和 $r_{2}^{\\top}$ 必须是满足此条件的线性无关向量。我们需要整数项。\n\n设 $r_{1}^{\\top} = (a, b, c)$。条件是 $b - 2c = 0$。一个简单的选择是 $r_{1}^{\\top} = (1, 0, 0)$，它满足 $0 - 2(0) = 0$。这得到 $\\phi_{1} = \\theta_{1}$。\n\n对于 $r_{2}^{\\top} = (d, e, f)$，我们需要 $e - 2f = 0$ 且 $r_{2}^{\\top}$ 与 $r_{1}^{\\top}$ 线性无关。一个简单的选择是设 $f=1$，这意味着 $e=2$，并且我们可以取 $d=0$。所以，$r_{2}^{\\top} = (0, 2, 1)$。这得到 $\\phi_{2} = 2\\theta_{2} + \\theta_{3}$。\n\n现在我们组装矩阵 $R$：\n$$\nR = \\begin{pmatrix}\n1  0  0 \\\\\n0  2  1 \\\\\n0  1  -2\n\\end{pmatrix}\n$$\n各项均为整数。我们通过计算其行列式来检查 $R$ 是否满秩：$\\det(R) = 1(2(-2) - 1(1)) - 0 + 0 = -5 \\neq 0$。因此，$R$ 是满秩的。\n\n重参数化的向量 $\\boldsymbol{\\phi} = (\\phi_{1}, \\phi_{2}, \\phi_{3})^{\\top}$ 由以下各式给出：\n$$ \\phi_{1} = \\theta_{1} $$\n$$ \\phi_{2} = 2\\theta_{2} + \\theta_{3} $$\n$$ \\phi_{3} = \\theta_{2} - 2\\theta_{3} $$\n此构造满足了问题的所有要求。最终答案是 $\\boldsymbol{\\phi}$ 作为行矩阵的表达式。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\theta_{1}  2\\theta_{2} + \\theta_{3}  \\theta_{2} - 2\\theta_{3}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "现代数值模型的调优通常需要平衡多个、有时甚至是相互竞争的目标，例如确定性预报的准确性（以均方根误差 $RMSE$ 衡量）和概率预报的技巧（以连续分级概率评分 $CRPS$ 衡量）。本练习将指导您推导此类复合损失函数的梯度，这是所有基于梯度的优化算法的第一步。掌握这一技能使您能够设计出能反映特定科学目标的定制化目标函数。",
            "id": "4065511",
            "problem": "在数值天气预报和气候建模的背景下，考虑一个大小为 $N$ 的训练集，由数对 $\\{(x_i,y_i)\\}_{i=1}^{N}$ 组成，其中 $x_i$ 是一个特征向量，$y_i \\in \\mathbb{R}$ 是一个观测到的标量值（例如，近地面温度）。一个带有参数向量 $\\theta \\in \\mathbb{R}^{p}$ 的参数化预报模型为每个 $x_i$ 提供确定性预报和概率性预报如下：\n\n- 一个由可微函数 $\\mu_{\\theta}(x_i)$ 给出的确定性点预报。\n- 一个由累积分布函数 $F_{\\theta,i}(z)$（其中 $z \\in \\mathbb{R}$）表示的概率性预报，对于每个 $i$，映射 $(\\theta,z) \\mapsto F_{\\theta,i}(z)$ 对所有 $z$ 均在 $\\theta$ 上可微，并且当 $z \\to -\\infty$ 时 $F_{\\theta,i}(z) \\to 0$，当 $z \\to +\\infty$ 时 $F_{\\theta,i}(z) \\to 1$，且具有可积的平方偏差。\n\n定义经验均方根误差 (RMSE) 和经验连续分级概率评分 (CRPS) 如下：\n$$\n\\mathrm{RMSE}(\\theta) \\equiv \\left(\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)^{2}\\right)^{\\tfrac{1}{2}},\n$$\n$$\n\\mathrm{CRPS}(\\theta) \\equiv \\frac{1}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)^{2}\\,\\mathrm{d}z,\n$$\n其中 $\\mathbf{1}\\{y_i \\le z\\}$ 表示指示函数。考虑复合损失\n$$\nJ(\\theta) \\equiv \\alpha\\,\\mathrm{RMSE}(\\theta)+\\beta\\,\\mathrm{CRPS}(\\theta),\n$$\n其中 $\\alpha0$ 且 $\\beta0$。\n\n假设有足够的正则性（包括 $\\mu_{\\theta}(\\cdot)$ 和 $F_{\\theta,i}(\\cdot)$ 在 $\\theta$ 上的可微性，以及根据控制收敛定理证明梯度、求和与积分可以互换的条件），使得以下所有梯度和积分都存在且可以互换。仅从上述定义和微积分基本法则出发，推导梯度 $\\nabla_{\\theta} J(\\theta)$ 的显式表达式，用 $\\mu_{\\theta}(x_i)$、$\\nabla_{\\theta}\\mu_{\\theta}(x_i)$、$F_{\\theta,i}(z)$ 和 $\\nabla_{\\theta}F_{\\theta,i}(z)$ 表示。将最终答案表示为单一的封闭形式解析表达式。无需四舍五入，也无需单位。",
            "solution": "用户希望我推导复合损失函数 $J(\\theta)$ 的梯度，该函数用于数值天气预报和气候建模。\n\n首先，我将验证问题陈述。\n\n### 步骤1：提取已知条件\n- 一个训练集 $\\{(x_i,y_i)\\}_{i=1}^{N}$，其中 $x_i$ 是一个特征向量，$y_i \\in \\mathbb{R}$ 是一个标量观测值。\n- 一个参数向量 $\\theta \\in \\mathbb{R}^{p}$。\n- 一个确定性预报模型 $\\mu_{\\theta}(x_i)$，在 $\\theta$ 上可微。\n- 一个由累积分布函数 $F_{\\theta,i}(z)$ 给出的概率性预报模型，其中映射 $(\\theta,z) \\mapsto F_{\\theta,i}(z)$ 在 $\\theta$ 上可微。\n- 经验均方根误差 (RMSE) 定义为：\n$$\n\\mathrm{RMSE}(\\theta) \\equiv \\left(\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)^{2}\\right)^{\\frac{1}{2}}\n$$\n- 经验连续分级概率评分 (CRPS) 定义为：\n$$\n\\mathrm{CRPS}(\\theta) \\equiv \\frac{1}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)^{2}\\,\\mathrm{d}z\n$$\n- 复合损失函数为 $J(\\theta) \\equiv \\alpha\\,\\mathrm{RMSE}(\\theta)+\\beta\\,\\mathrm{CRPS}(\\theta)$，其中常数 $\\alpha0$ 且 $\\beta0$。\n- 假设我们有足够的正则性来互换梯度、求和和积分算子。\n\n### 步骤2：使用提取的已知条件进行验证\n1.  **科学依据：** 该问题牢固地植根于统计学和机器学习，特别是在预报验证和参数估计的背景下。RMSE 和 CRPS 分别是确定性预报和概率性预报的标准评分规则。该问题在科学上是合理的。\n2.  **良态性：** 该问题要求计算一个定义明确的函数 $J(\\theta)$ 的梯度。关于可微性和算子可互换性的明确假设确保了唯一数学解的存在并且可以被推导出来。\n3.  **客观性：** 该问题以精确的数学语言陈述，没有歧义或主观论断。\n4.  **完整性：** 该问题提供了推导所需的所有必要定义和假设。它是自洽的。\n\n### 步骤3：结论和行动\n该问题是有效的。它是在一个应用背景下的一个定义明确的数学问题。我将继续进行推导。\n\n### 梯度 $\\nabla_{\\theta} J(\\theta)$ 的推导\n\n复合损失函数由下式给出\n$$\nJ(\\theta) = \\alpha\\,\\mathrm{RMSE}(\\theta)+\\beta\\,\\mathrm{CRPS}(\\theta)\n$$\n根据梯度算子 $\\nabla_{\\theta}$ 的线性性质，我们有\n$$\n\\nabla_{\\theta} J(\\theta) = \\alpha\\,\\nabla_{\\theta}\\mathrm{RMSE}(\\theta)+\\beta\\,\\nabla_{\\theta}\\mathrm{CRPS}(\\theta)\n$$\n我们将分别计算每一项的梯度。\n\n**1. RMSE 项的梯度**\n\nRMSE 定义为\n$$\n\\mathrm{RMSE}(\\theta) = \\left(\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)^{2}\\right)^{\\frac{1}{2}}\n$$\n令均方误差 (MSE) 为 $\\mathrm{MSE}(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)^{2}$。那么 $\\mathrm{RMSE}(\\theta) = (\\mathrm{MSE}(\\theta))^{\\frac{1}{2}}$。\n对向量值函数使用链式法则，梯度为\n$$\n\\nabla_{\\theta}\\mathrm{RMSE}(\\theta) = \\frac{1}{2}(\\mathrm{MSE}(\\theta))^{-\\frac{1}{2}} \\nabla_{\\theta}\\mathrm{MSE}(\\theta) = \\frac{1}{2\\,\\mathrm{RMSE}(\\theta)} \\nabla_{\\theta}\\mathrm{MSE}(\\theta)\n$$\n现在，我们计算 MSE 的梯度：\n$$\n\\nabla_{\\theta}\\mathrm{MSE}(\\theta) = \\nabla_{\\theta}\\left(\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)^{2}\\right)\n$$\n利用梯度和求和的线性性质，我们将梯度算子移到求和内部：\n$$\n\\nabla_{\\theta}\\mathrm{MSE}(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}\\nabla_{\\theta}\\left(\\mu_{\\theta}(x_i)-y_i\\right)^{2}\n$$\n再次应用链式法则，并注意到 $y_i$ 是关于 $\\theta$ 的常数：\n$$\n\\nabla_{\\theta}\\left(\\mu_{\\theta}(x_i)-y_i\\right)^{2} = 2\\left(\\mu_{\\theta}(x_i)-y_i\\right)\\nabla_{\\theta}\\left(\\mu_{\\theta}(x_i)-y_i\\right) = 2\\left(\\mu_{\\theta}(x_i)-y_i\\right)\\nabla_{\\theta}\\mu_{\\theta}(x_i)\n$$\n将此代回 $\\nabla_{\\theta}\\mathrm{MSE}(\\theta)$ 的表达式中：\n$$\n\\nabla_{\\theta}\\mathrm{MSE}(\\theta) = \\frac{2}{N}\\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)\\nabla_{\\theta}\\mu_{\\theta}(x_i)\n$$\n最后，我们将此代入 $\\nabla_{\\theta}\\mathrm{RMSE}(\\theta)$ 的表达式中：\n$$\n\\nabla_{\\theta}\\mathrm{RMSE}(\\theta) = \\frac{1}{2\\,\\mathrm{RMSE}(\\theta)} \\left(\\frac{2}{N}\\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)\\nabla_{\\theta}\\mu_{\\theta}(x_i)\\right) = \\frac{1}{N\\,\\mathrm{RMSE}(\\theta)} \\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)\\nabla_{\\theta}\\mu_{\\theta}(x_i)\n$$\n为了得到一个自洽的表达式，我们代入 $\\mathrm{RMSE}(\\theta)$ 的定义：\n$$\n\\nabla_{\\theta}\\mathrm{RMSE}(\\theta) = \\frac{1}{N \\left(\\frac{1}{N}\\sum_{j=1}^{N}\\left(\\mu_{\\theta}(x_j)-y_j\\right)^{2}\\right)^{\\frac{1}{2}}} \\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)\\nabla_{\\theta}\\mu_{\\theta}(x_i)\n$$\n通过处理常数 $N$，可以简化此式：\n$$\n\\nabla_{\\theta}\\mathrm{RMSE}(\\theta) = \\frac{1}{\\sqrt{N}\\left(\\sum_{j=1}^{N}\\left(\\mu_{\\theta}(x_j)-y_j\\right)^{2}\\right)^{\\frac{1}{2}}} \\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)\\nabla_{\\theta}\\mu_{\\theta}(x_i)\n$$\n我们在分母的求和中使用不同的索引 $j$，以避免与主求和的索引 $i$ 混淆。\n\n**2. CRPS 项的梯度**\n\nCRPS 定义为\n$$\n\\mathrm{CRPS}(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)^{2}\\,\\mathrm{d}z\n$$\n对 $\\theta$ 求梯度：\n$$\n\\nabla_{\\theta}\\mathrm{CRPS}(\\theta) = \\nabla_{\\theta}\\left(\\frac{1}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)^{2}\\,\\mathrm{d}z\\right)\n$$\n利用梯度和求和的线性性质，我们有\n$$\n\\nabla_{\\theta}\\mathrm{CRPS}(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}\\nabla_{\\theta}\\int_{-\\infty}^{\\infty}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)^{2}\\,\\mathrm{d}z\n$$\n问题陈述中提供了足够的正则性假设，以互换梯度和积分（莱布尼茨积分法则）。因此，\n$$\n\\nabla_{\\theta}\\mathrm{CRPS}(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\nabla_{\\theta}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)^{2}\\,\\mathrm{d}z\n$$\n我们对被积函数应用链式法则。注意指示函数 $\\mathbf{1}\\{y_i \\le z\\}$ 不依赖于 $\\theta$，因此其梯度为零。\n$$\n\\nabla_{\\theta}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)^{2} = 2\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right) \\nabla_{\\theta}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)\n$$\n$$\n= 2\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right) \\nabla_{\\theta}F_{\\theta,i}(z)\n$$\n将此结果代回 CRPS 梯度的表达式中：\n$$\n\\nabla_{\\theta}\\mathrm{CRPS}(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}2\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)\\nabla_{\\theta}F_{\\theta,i}(z)\\,\\mathrm{d}z\n$$\n$$\n\\nabla_{\\theta}\\mathrm{CRPS}(\\theta) = \\frac{2}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)\\nabla_{\\theta}F_{\\theta,i}(z)\\,\\mathrm{d}z\n$$\n\n**3. 组合结果**\n\n我们现在组装复合损失函数 $J(\\theta)$ 的完整梯度：\n$$\n\\nabla_{\\theta} J(\\theta) = \\alpha\\,\\nabla_{\\theta}\\mathrm{RMSE}(\\theta)+\\beta\\,\\nabla_{\\theta}\\mathrm{CRPS}(\\theta)\n$$\n代入每一项的推导表达式：\n$$\n\\nabla_{\\theta} J(\\theta) = \\alpha \\left( \\frac{\\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)\\nabla_{\\theta}\\mu_{\\theta}(x_i)}{\\sqrt{N}\\left(\\sum_{j=1}^{N}\\left(\\mu_{\\theta}(x_j)-y_j\\right)^{2}\\right)^{\\frac{1}{2}}} \\right) + \\beta \\left( \\frac{2}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)\\nabla_{\\theta}F_{\\theta,i}(z)\\,\\mathrm{d}z \\right)\n$$\n这个表达式可以稍微重新排列成其最终形式：\n$$\n\\nabla_{\\theta} J(\\theta) = \\frac{\\alpha \\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)\\nabla_{\\theta}\\mu_{\\theta}(x_i)}{\\left(N\\sum_{j=1}^{N}\\left(\\mu_{\\theta}(x_j)-y_j\\right)^{2}\\right)^{\\frac{1}{2}}} + \\frac{2\\beta}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)\\nabla_{\\theta}F_{\\theta,i}(z)\\,\\mathrm{d}z\n$$\n这就是所求的梯度 $\\nabla_{\\theta} J(\\theta)$ 的封闭形式解析表达式。",
            "answer": "$$\n\\boxed{\\frac{\\alpha \\sum_{i=1}^{N}\\left(\\mu_{\\theta}(x_i)-y_i\\right)\\nabla_{\\theta}\\mu_{\\theta}(x_i)}{\\left(N \\sum_{j=1}^{N}\\left(\\mu_{\\theta}(x_j)-y_j\\right)^{2}\\right)^{\\frac{1}{2}}} + \\frac{2\\beta}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\left(F_{\\theta,i}(z)-\\mathbf{1}\\{y_i \\le z\\}\\right)\\nabla_{\\theta}F_{\\theta,i}(z)\\,\\mathrm{d}z}\n$$"
        },
        {
            "introduction": "有了目标函数及其梯度，我们就需要一个算法来实际计算参数的更新步骤。Levenberg-Marquardt (LM) 算法是解决非线性最小二乘问题的经典方法，在参数调优中应用广泛。通过从头推导其更新规则，您将深入理解该算法如何巧妙地在陡峭的梯度下降法和快速收敛的高斯-牛顿法之间取得平衡，从而实现稳健而高效的优化。",
            "id": "4065506",
            "problem": "考虑在一个用于数值天气预报 (NWP) 和长期气候预测的全球气候模型中，调优一个不确定的次网格过程参数矢量 $\\boldsymbol{\\theta} \\in \\mathbb{R}^{p}$。设观测算子 $H(\\boldsymbol{\\theta}) \\in \\mathbb{R}^{m}$ 将参数映射到一组 $m$ 个诊断量（例如，区域平均降水量、大气层顶辐射和近地表温度），这些诊断量与受观测约束的目标 $\\mathbf{y} \\in \\mathbb{R}^{m}$ 进行比较。定义残差矢量 $r(\\boldsymbol{\\theta}) = H(\\boldsymbol{\\theta}) - \\mathbf{y}$，以及最小二乘目标 $\\Phi(\\boldsymbol{\\theta}) = \\frac{1}{2}\\|r(\\boldsymbol{\\theta})\\|^{2}$，其中 $\\|\\cdot\\|$ 表示欧几里得范数。在当前迭代点 $\\boldsymbol{\\theta}_{k}$ 处，记 $r = r(\\boldsymbol{\\theta}_{k})$ 和雅可比矩阵 $J' = \\frac{\\partial r}{\\partial \\boldsymbol{\\theta}}\\big|_{\\boldsymbol{\\theta}_{k}} \\in \\mathbb{R}^{m \\times p}$。\n\n为获得一个平衡了曲率信息与稳健性的稳定参数更新 $\\delta \\in \\mathbb{R}^{p}$，您决定使用 Levenberg-Marquardt (LM) 方法，也称为阻尼高斯-牛顿法。该方法通过一个由阻尼系数 $\\lambda  0$ 控制的各向同性正则化项来增广局部二次模型。\n\n从最小二乘最小化的基本定义和残差的一阶泰勒展开出发，推导阻尼局部模型的平稳性条件，并获得 LM 更新 $\\delta$ 关于 $J'$、$r$ 和 $\\lambda$ 的显式闭式表达式。您的推导应从围绕 $\\boldsymbol{\\theta}_{k}$ 的线性化残差开始，通过最小化目标的阻尼二次近似来进行。请以 $\\delta$ 的单个闭式解析表达式的形式给出您的最终答案。无需进行数值计算。如果引入任何其他符号，请明确定义它们。最终答案请勿包含单位。",
            "solution": "问题 R-0391 要求推导用于非线性最小二乘优化问题的 Levenberg-Marquardt (LM) 参数更新步骤，特别是在气候模型参数调优的背景下。推导必须从基本定义开始，并逻辑地推演至最终表达式。\n\n首先，我们对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n- 参数矢量：$\\boldsymbol{\\theta} \\in \\mathbb{R}^{p}$\n- 观测算子：$H(\\boldsymbol{\\theta}) \\in \\mathbb{R}^{m}$\n- 观测目标：$\\mathbf{y} \\in \\mathbb{R}^{m}$\n- 残差矢量：$r(\\boldsymbol{\\theta}) = H(\\boldsymbol{\\theta}) - \\mathbf{y}$\n- 最小二乘目标函数：$\\Phi(\\boldsymbol{\\theta}) = \\frac{1}{2}\\|r(\\boldsymbol{\\theta})\\|^{2}$，其中 $\\|\\cdot\\|$ 是欧几里得范数。\n- 当前参数迭代点：$\\boldsymbol{\\theta}_{k}$\n- 当前迭代点的残差：$r = r(\\boldsymbol{\\theta}_{k})$\n- 当前迭代点残差的雅可比矩阵：$J' = \\frac{\\partial r}{\\partial \\boldsymbol{\\theta}}\\big|_{\\boldsymbol{\\theta}_{k}} \\in \\mathbb{R}^{m \\times p}$\n- 参数更新步长：$\\delta \\in \\mathbb{R}^{p}$\n- 阻尼系数：$\\lambda  0$\n- 方法：Levenberg-Marquardt (阻尼高斯-牛顿法)\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在科学和数学上都是合理的。它描述了数值优化中的一种标准、成熟的技术——Levenberg-Marquardt 算法。如问题所述，该方法广泛应用于许多科学和工程领域，包括数值天气预报和气候科学中使用的复杂模型的参数调优。问题是适定的、客观的、自洽的，提供了推导所需表达式的所有必要定义和变量。没有矛盾、歧义或事实错误。问题要求进行形式化的数学推导，这是应用数学和计算科学中的标准程序。\n\n### 步骤 3：结论与行动\n该问题是 **有效的**。将提供解答。\n\n### Levenberg-Marquardt 更新的推导\n目标是找到一个参数更新 $\\delta$ 来最小化目标函数 $\\Phi(\\boldsymbol{\\theta})$。我们的目的是确定更新 $\\delta$，使得下一个迭代点 $\\boldsymbol{\\theta}_{k+1} = \\boldsymbol{\\theta}_{k} + \\delta$ 能减小 $\\Phi$ 的值。Levenberg-Marquardt 方法通过最小化目标函数的一个局部的、带阻尼的二次模型来实现这一目标。\n\n目标函数为 $\\Phi(\\boldsymbol{\\theta}) = \\frac{1}{2} \\|r(\\boldsymbol{\\theta})\\|^{2}$。我们想要分析它在新点 $\\boldsymbol{\\theta}_{k} + \\delta$ 处的值。为此，我们首先使用一阶泰勒级数展开，在当前迭代点 $\\boldsymbol{\\theta}_{k}$ 周围构造残差矢量 $r(\\boldsymbol{\\theta})$ 的一个线性近似：\n$$\nr(\\boldsymbol{\\theta}_{k} + \\delta) \\approx r(\\boldsymbol{\\theta}_{k}) + \\left.\\frac{\\partial r}{\\partial \\boldsymbol{\\theta}}\\right|_{\\boldsymbol{\\theta}_{k}} \\delta\n$$\n使用问题陈述中提供的记法，$r = r(\\boldsymbol{\\theta}_{k})$ 和 $J' = \\frac{\\partial r}{\\partial \\boldsymbol{\\theta}}\\big|_{\\boldsymbol{\\theta}_{k}}$，该近似变为：\n$$\nr(\\boldsymbol{\\theta}_{k} + \\delta) \\approx r + J' \\delta\n$$\n将这个残差的线性近似代入目标函数 $\\Phi$ 中，得到一个局部二次模型，我们将其记为 $\\tilde{\\Phi}(\\delta)$:\n$$\n\\Phi(\\boldsymbol{\\theta}_{k} + \\delta) \\approx \\tilde{\\Phi}(\\delta) = \\frac{1}{2} \\|r + J' \\delta\\|^{2}\n$$\n纯高斯-牛顿法试图最小化 $\\tilde{\\Phi}(\\delta)$。然而，如果雅可比矩阵 $J'$ 是病态的或秩亏的，这种方法可能不稳定。Levenberg-Marquardt 方法引入一个阻尼（或正则化）项 $\\frac{1}{2}\\lambda\\|\\delta\\|^2$ 来稳定问题。该项惩罚大的更新步长，从而将新的迭代点 $\\boldsymbol{\\theta}_{k} + \\delta$ 保持在残差的线性近似更可能有效的区域内。\n\n因此，我们将阻尼目标函数定义为 $L(\\delta)$：\n$$\nL(\\delta) = \\frac{1}{2} \\|r + J' \\delta\\|^{2} + \\frac{1}{2} \\lambda \\|\\delta\\|^{2}\n$$\n其中 $\\lambda  0$ 是阻尼系数。我们的目标是找到最小化 $L(\\delta)$ 的更新矢量 $\\delta$。为此，我们用矢量转置来重写范数：\n$$\nL(\\delta) = \\frac{1}{2} (r + J' \\delta)^{T} (r + J' \\delta) + \\frac{1}{2} \\lambda \\delta^{T} \\delta\n$$\n展开第一项：\n$$\n(r + J' \\delta)^{T} (r + J' \\delta) = (r^{T} + \\delta^{T} (J')^{T}) (r + J' \\delta) = r^{T}r + r^{T}J'\\delta + \\delta^{T}(J')^{T}r + \\delta^{T}(J')^{T}J'\\delta\n$$\n由于 $r^{T}J'\\delta$ 是一个标量，它等于其自身的转置 $(\\delta^{T}(J')^{T}r)$。因此，$r^{T}J'\\delta + \\delta^{T}(J')^{T}r = 2r^{T}J'\\delta$。\n目标函数变为：\n$$\nL(\\delta) = \\frac{1}{2} (r^{T}r + 2 r^{T}J'\\delta + \\delta^{T}(J')^{T}J'\\delta) + \\frac{1}{2} \\lambda \\delta^{T} I \\delta\n$$\n其中 $I$ 是大小为 $p \\times p$ 的单位矩阵。\n\n为求 $L(\\delta)$ 的最小值，我们计算它关于 $\\delta$ 的梯度，并将其设为零矢量。\n$$\n\\nabla_{\\delta} L(\\delta) = \\frac{\\partial}{\\partial \\delta} \\left[ \\frac{1}{2} r^{T}r + r^{T}J'\\delta + \\frac{1}{2} \\delta^{T}(J')^{T}J'\\delta + \\frac{1}{2} \\lambda \\delta^{T} I \\delta \\right]\n$$\n使用标准的矩阵微积分恒等式，特别是对于对称矩阵 $A$，有 $\\nabla_x (a^T x) = a$ 和 $\\nabla_x (\\frac{1}{2} x^T A x) = Ax$：\n- 项 $\\frac{1}{2} r^{T}r$ 关于 $\\delta$ 是常数，所以其梯度为 $\\mathbf{0}$。\n- $r^{T}J'\\delta$ 的梯度是 $(r^{T}J')^{T} = (J')^{T}r$。\n- 矩阵 $(J')^{T}J'$ 是对称的，所以 $\\frac{1}{2} \\delta^{T}(J')^{T}J'\\delta$ 的梯度是 $(J')^{T}J'\\delta$。\n- 矩阵 $\\lambda I$ 是对称的，所以 $\\frac{1}{2} \\lambda \\delta^{T} I \\delta$ 的梯度是 $\\lambda I \\delta$。\n\n结合这些结果，$L(\\delta)$ 的梯度为：\n$$\n\\nabla_{\\delta} L(\\delta) = (J')^{T}r + (J')^{T}J'\\delta + \\lambda I \\delta\n$$\n通过将梯度设为零矢量 $\\nabla_{\\delta} L(\\delta) = \\mathbf{0}$ 来找到平稳性条件：\n$$\n(J')^{T}J'\\delta + \\lambda I \\delta = -(J')^{T}r\n$$\n在左侧提取因子 $\\delta$ 可得：\n$$\n((J')^{T}J' + \\lambda I) \\delta = -(J')^{T}r\n$$\n这是一个关于更新矢量 $\\delta$ 的线性方程组。矩阵 $(J')^{T}J'$ 是高斯-牛顿法中的“近似海森矩阵”；它是对称且半正定的。由于 $\\lambda  0$，矩阵 $(J')^{T}J' + \\lambda I$ 是对称且正定的，这保证了它是可逆的。因此，我们可以通过在等式两边左乘该矩阵的逆来求解 $\\delta$：\n$$\n\\delta = - ((J')^{T}J' + \\lambda I)^{-1} (J')^{T}r\n$$\n此表达式提供了 Levenberg-Marquardt 更新步长 $\\delta$ 关于雅可比矩阵 $J'$、残差矢量 $r$ 和阻尼参数 $\\lambda$ 的闭式解析解。",
            "answer": "$$\n\\boxed{-((J')^{T} J' + \\lambda I)^{-1} (J')^{T} r}\n$$"
        }
    ]
}