{
    "hands_on_practices": [
        {
            "introduction": "数据同化是现代天气预报的基石，其核心在于将模型预测与现实世界的观测数据进行最优融合。这个过程的数学基础是贝叶斯推断：利用新的证据（观测）来更新我们的先验信念（预报），从而得到一个更精确的后验估计（分析场）。本练习将引导你完成一个简化标量情况下的核心推导过程。掌握这一基础的解析推导，对于理解如四维变分（$4D-Var$）或集合卡尔曼滤波器（$EnKF$）等复杂高维数据同化系统的内在逻辑至关重要。",
            "id": "4030133",
            "problem": "考虑一个数值天气预报（NWP）系统中的一维数据同化步骤，针对单个网格点的大气标量状态，记为 $x$。关于 $x$ 的背景（先验）信息被建模为一个高斯随机变量 $x_b \\sim \\mathcal{N}(\\mu_b,\\sigma_b^2)$，其中 $x_b$ 代表背景预报，$\\mu_b$ 是其均值，$\\sigma_b^2$ 是其误差方差。通过一个线性测量模型 $y = x + \\epsilon$ 可获得该状态的单个同位观测值 $y$。其中，观测误差 $\\epsilon$ 是高斯分布的，满足 $\\epsilon \\sim \\mathcal{N}(0,\\sigma_o^2)$，且与背景误差无关。假设所有分布和参数都已正确指定，并且 $x$ 是待推断的潜在真实状态。\n\n仅从贝叶斯定理以及高斯先验和高斯似然的定义出发，推导后验分布 $p(x \\mid y)$，并明确求出后验均值 $\\mu_a$ 和后验方差 $\\sigma_a^2$ 的闭式表达式。将后验均值表示为背景均值和观测值的凸组合 $\\mu_a = w_b \\mu_b + w_o y$，并提供权重 $w_b$ 和 $w_o$ 关于 $\\sigma_b^2$ 和 $\\sigma_o^2$ 的解析表达式。将 $\\mu_a$、$\\sigma_a^2$、$w_b$ 和 $w_o$ 的最终答案表述为 $\\mu_b$、$y$、$\\sigma_b^2$ 和 $\\sigma_o^2$ 的显式函数。不需要进行数值计算，也不需要四舍五入。最终答案必须以单个行向量的形式给出，按顺序包含 $\\mu_a$、$\\sigma_a^2$、$w_b$ 和 $w_o$。",
            "solution": "该问题提出了一个数据同化背景下的标准贝叶斯推断任务，在标量情况下通常被称为最优插值。该问题具有扎实的科学基础，在数学上是适定的，信息是完全指定的，并且是客观的。这是一个有效的问题。\n\n我们被要求推导在给定观测值 $y$ 的情况下状态 $x$ 的后验分布 $p(x | y)$。推导从贝叶斯定理开始：\n$$\np(x \\mid y) = \\frac{p(y \\mid x) p(x)}{p(y)}\n$$\n项 $p(y)$ 是一个不依赖于 $x$ 的归一化常数。因此，我们可以使用正比关系：\n$$\np(x \\mid y) \\propto p(y \\mid x) p(x)\n$$\n\n首先，我们定义先验分布 $p(x)$。问题陈述，关于 $x$ 的背景信息被建模为一个均值为 $\\mu_b$、方差为 $\\sigma_b^2$ 的高斯随机变量。因此，真实状态 $x$ 的先验分布为：\n$$\np(x) = \\mathcal{N}(x \\mid \\mu_b, \\sigma_b^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_b^2}} \\exp\\left( -\\frac{(x - \\mu_b)^2}{2\\sigma_b^2} \\right)\n$$\n\n接下来，我们定义似然函数 $p(y \\mid x)$。观测模型由 $y = x + \\epsilon$ 给出，其中观测误差 $\\epsilon$ 是一个均值为零、方差为 $\\sigma_o^2$ 的高斯随机变量，即 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_o^2)$。这意味着在给定真实状态 $x$ 的情况下，观测值 $y$ 是一个均值为 $x$、方差为 $\\sigma_o^2$ 的高斯随机变量。因此，似然函数为：\n$$\np(y \\mid x) = \\mathcal{N}(y \\mid x, \\sigma_o^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_o^2}} \\exp\\left( -\\frac{(y - x)^2}{2\\sigma_o^2} \\right)\n$$\n\n现在，我们将这些表达式代入后验分布的正比关系中：\n$$\np(x \\mid y) \\propto \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma_o^2}} \\exp\\left( -\\frac{(y - x)^2}{2\\sigma_o^2} \\right) \\right] \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma_b^2}} \\exp\\left( -\\frac{(x - \\mu_b)^2}{2\\sigma_b^2} \\right) \\right]\n$$\n忽略常数乘法项，后验分布与指数项成正比：\n$$\np(x \\mid y) \\propto \\exp\\left( -\\frac{(y - x)^2}{2\\sigma_o^2} - \\frac{(x - \\mu_b)^2}{2\\sigma_b^2} \\right)\n$$\n两个高斯分布（或其概率密度函数）的乘积是另一个高斯分布。我们知道后验分布 $p(x \\mid y)$ 将是一个高斯分布，我们将其表示为 $\\mathcal{N}(x \\mid \\mu_a, \\sigma_a^2)$，其形式为：\n$$\np(x \\mid y) \\propto \\exp\\left( -\\frac{(x - \\mu_a)^2}{2\\sigma_a^2} \\right)\n$$\n为了找到后验均值 $\\mu_a$ 和方差 $\\sigma_a^2$，我们必须处理我们推导出的后验分布的指数部分，使其与标准高斯形式匹配。这可以通过对 $x$ 使用配方法来实现。让我们分析指数部分，我们将其记为 $E(x)$：\n$$\nE(x) = -\\frac{(y - x)^2}{2\\sigma_o^2} - \\frac{(x - \\mu_b)^2}{2\\sigma_b^2}\n$$\n我们展开括号内的二次项：\n$$\nE(x) = -\\frac{1}{2}\\left( \\frac{y^2 - 2yx + x^2}{\\sigma_o^2} + \\frac{x^2 - 2x\\mu_b + \\mu_b^2}{\\sigma_b^2} \\right)\n$$\n我们根据 $x$ 的幂次收集项：\n$$\nE(x) = -\\frac{1}{2}\\left[ x^2 \\left(\\frac{1}{\\sigma_o^2} + \\frac{1}{\\sigma_b^2}\\right) - 2x \\left(\\frac{y}{\\sigma_o^2} + \\frac{\\mu_b}{\\sigma_b^2}\\right) + \\left(\\frac{y^2}{\\sigma_o^2} + \\frac{\\mu_b^2}{\\sigma_b^2}\\right) \\right]\n$$\n高斯分布 $\\mathcal{N}(x \\mid \\mu_a, \\sigma_a^2)$ 的指数的一般形式是：\n$$\n-\\frac{(x - \\mu_a)^2}{2\\sigma_a^2} = -\\frac{1}{2\\sigma_a^2}(x^2 - 2x\\mu_a + \\mu_a^2) = -\\frac{1}{2}\\left[ x^2\\left(\\frac{1}{\\sigma_a^2}\\right) - 2x\\left(\\frac{\\mu_a}{\\sigma_a^2}\\right) + \\frac{\\mu_a^2}{\\sigma_a^2} \\right]\n$$\n通过将 $E(x)$ 中 $x^2$ 项的系数与一般形式进行比较，我们可以确定后验方差 $\\sigma_a^2$ 的倒数：\n$$\n\\frac{1}{\\sigma_a^2} = \\frac{1}{\\sigma_o^2} + \\frac{1}{\\sigma_b^2} = \\frac{\\sigma_b^2 + \\sigma_o^2}{\\sigma_o^2 \\sigma_b^2}\n$$\n求解 $\\sigma_a^2$ 得到后验方差：\n$$\n\\sigma_a^2 = \\left( \\frac{\\sigma_b^2 + \\sigma_o^2}{\\sigma_o^2 \\sigma_b^2} \\right)^{-1} = \\frac{\\sigma_o^2 \\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}\n$$\n接下来，通过比较 $x$ 的一次项系数，我们发现：\n$$\n\\frac{\\mu_a}{\\sigma_a^2} = \\frac{y}{\\sigma_o^2} + \\frac{\\mu_b}{\\sigma_b^2}\n$$\n求解后验均值 $\\mu_a$：\n$$\n\\mu_a = \\sigma_a^2 \\left( \\frac{y}{\\sigma_o^2} + \\frac{\\mu_b}{\\sigma_b^2} \\right)\n$$\n代入我们关于 $\\sigma_a^2$ 的表达式：\n$$\n\\mu_a = \\left( \\frac{\\sigma_o^2 \\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2} \\right) \\left( \\frac{y\\sigma_b^2 + \\mu_b\\sigma_o^2}{\\sigma_o^2 \\sigma_b^2} \\right)\n$$\n项 $(\\sigma_o^2 \\sigma_b^2)$ 被消去，得到：\n$$\n\\mu_a = \\frac{y\\sigma_b^2 + \\mu_b\\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2}\n$$\n问题要求将后验均值表示为凸组合 $\\mu_a = w_b \\mu_b + w_o y$。我们可以重新整理我们关于 $\\mu_a$ 的表达式以匹配此形式：\n$$\n\\mu_a = \\left( \\frac{\\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2} \\right) \\mu_b + \\left( \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2} \\right) y\n$$\n通过与 $\\mu_a = w_b \\mu_b + w_o y$直接比较，我们确定权重 $w_b$ 和 $w_o$：\n$$\nw_b = \\frac{\\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2}\n$$\n$$\nw_o = \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}\n$$\n权重之和为 $w_b + w_o = \\frac{\\sigma_o^2 + \\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2} = 1$。由于方差是非负的，权重也是非负的，这证实了它是一个真凸组合。\n\n最终所需的表达式为：\n1.  后验均值 $\\mu_a = \\frac{\\mu_b \\sigma_o^2 + y \\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}$\n2.  后验方差 $\\sigma_a^2 = \\frac{\\sigma_b^2 \\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2}$\n3.  背景均值的权重 $w_b = \\frac{\\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2}$\n4.  观测值的权重 $w_o = \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}$\n\n这些是所需的解析形式。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{\\mu_b \\sigma_o^2 + y \\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2} & \\frac{\\sigma_b^2 \\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2} & \\frac{\\sigma_o^2}{\\sigma_b^2 + \\sigma_o^2} & \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_o^2}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在理解了单步的贝叶斯更新之后，我们现在转向一个动态系统，其中预报和分析随时间顺序进行。卡尔曼滤波器是在线性系统中递归执行数据同化的经典算法，本练习将要求你实现一个完整的预报-分析循环。通过这个动手实践，你将能探索数值天气预报中的一个关键现实挑战：当模型误差协方差（$Q$）设定不准确时会产生何种影响。你将诊断出我们对预报模型准确性的假设缺陷如何导致系统性误差或分析“漂移”，从而深入理解业务化数据同化系统的调试与验证过程。",
            "id": "4030151",
            "problem": "考虑一个一维线性高斯状态空间模型，该模型被用作数值天气预报 (NWP) 中数据同化 (DA) 的简化构建模块。物理量被抽象为无量纲的标量。真实状态根据稳定或近乎稳定的自回归动态演化，观测是带有噪声的状态直接测量值。您将使用卡尔曼滤波器 (KF) 实现一个分析循环，其中模型误差协方差可能被错误指定。您的任务是计算每个循环的分析增量，并在模型误差协方差被错误指定时，量化预报误差随时间的漂移。\n\n使用的基本原理：\n- 线性状态空间模型、高斯加性误差，以及线性高斯情况下的贝叶斯滤波。\n- 状态演化遵循 $x_{k+1} = a\\,x_k + w_k$，其中 $w_k$ 是均值为零、方差为 $Q_{\\text{true}}$ 的高斯模型误差。\n- 在循环 $k$ 的观测为 $y_k = x_k + v_k$，其中 $v_k$ 是均值为零、方差为 $R$ 的高斯观测误差。\n- 卡尔曼滤波器 (KF) 分析循环包括预测（预报）和更新（分析）步骤，这些步骤源自线性高斯贝叶斯框架和高斯-马尔可夫定理，不依赖于快捷公式。\n\n定义和待计算的量：\n- 预报均值 $x_f(k)$ 和预报方差 $P_f(k)$，通过将前一步的分析结果，使用模型 $(a)$ 和假定的模型误差方差 $Q_{\\text{assumed}}$ 进行传播得到。\n- 分析均值 $x_a(k)$ 和分析方差 $P_a(k)$，通过在线性高斯更新框架下，将预报与当前观测 $y_k$ 相结合得到，此更新从第一性原理推导。\n- 在循环 $k$ 的分析增量：$\\Delta(k) = x_a(k) - x_f(k)$。\n- 在循环 $k$ 的预报误差：$e_f(k) = x_f(k) - x_{\\text{true}}(k)$。\n- 漂移度量：序列 $\\{e_f(k)\\}_{k=1}^N$ 相对于循环指数 $k$ 的最小二乘线性趋势（斜率）$s$，其中 $N$ 是总循环次数。也就是说，以最小二乘法拟合 $e_f(k) \\approx s\\,k + b$ 并报告 $s$。\n\n所有量均为无量纲。不使用角度。不使用百分比。您必须将漂移度量 $s$ 和平均绝对分析增量 $\\overline{|\\Delta|}$ 表示为十进制浮点数。\n\n初始化：\n- 初始真实状态为 $x_{\\text{true}}(0) = x_0$。\n- 初始分析均值为 $x_a(0) = x_0$。\n- 初始分析方差为 $P_a(0) = P_0$。\n\n每个时间步 $k = 1,\\dots,N$ 的仿真和分析循环：\n- 推进真实状态，使用 $x_{\\text{true}}(k) = a\\,x_{\\text{true}}(k-1) + w_k$，其中 $w_k$ 从一个均值为零、方差为 $Q_{\\text{true}}$ 的高斯分布中抽取。\n- 生成观测 $y_k = x_{\\text{true}}(k) + v_k$，其中 $v_k$ 从一个均值为零、方差为 $R$ 的高斯分布中抽取。\n- 使用步骤 $k-1$ 的分析结果和假定的模型误差方差 $Q_{\\text{assumed}}$，计算预报均值 $x_f(k)$ 和预报方差 $P_f(k)$。\n- 使用观测 $y_k$ 和线性高斯贝叶斯更新方法，计算分析均值 $x_a(k)$ 和分析方差 $P_a(k)$。不要依赖快捷公式；从第一性原理（高斯-马尔可夫定理所蕴含的新息和最小二乘加权）推导更新过程。\n- 计算分析增量 $\\Delta(k) = x_a(k) - x_f(k)$ 和预报误差 $e_f(k) = x_f(k) - x_{\\text{true}}(k)$。\n\n每个测试用例需报告的输出：\n- 平均绝对分析增量 $\\overline{|\\Delta|} = \\frac{1}{N}\\sum_{k=1}^{N} |\\Delta(k)|$。\n- 漂移度量 $s$（$e_f(k)$ 相对于 $k$ 的最小二乘拟合斜率），以状态单位/循环表示。\n\n为保证可复现性，请提供以下使用固定随机种子的测试套件：\n- 测试用例 1（理想情况，正确指定的 $Q$）：$a = 0.95$, $Q_{\\text{true}} = 0.04$, $Q_{\\text{assumed}} = 0.04$, $R = 0.09$, $x_0 = 1.0$, $P_0 = 0.1$, $N = 60$, $\\text{seed} = 123$。\n- 测试用例 2（离散不足的预报模型）：$a = 0.95$, $Q_{\\text{true}} = 0.04$, $Q_{\\text{assumed}} = 0.0$, $R = 0.09$, $x_0 = 1.0$, $P_0 = 0.1$, $N = 60$, $\\text{seed} = 123$。\n- 测试用例 3（离散过度的预报模型）：$a = 0.95$, $Q_{\\text{true}} = 0.04$, $Q_{\\text{assumed}} = 0.2$, $R = 0.09$, $x_0 = 1.0$, $P_0 = 0.1$, $N = 60$, $\\text{seed} = 123$。\n- 测试用例 4（近乎不稳定的动态）：$a = 1.05$, $Q_{\\text{true}} = 0.04$, $Q_{\\text{assumed}} = 0.04$, $R = 0.09$, $x_0 = 1.0$, $P_0 = 0.1$, $N = 60$, $\\text{seed} = 456$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为方括号内包含的逗号分隔列表，每个测试用例的结果是一个双元素列表 $[\\overline{|\\Delta|}, s]$。\n- 每个浮点数必须四舍五入到 $6$ 位小数。\n- 例如，输出应如下所示 $[[0.123456,-0.000789],[\\dots,\\dots],[\\dots,\\dots],[\\dots,\\dots]]$。",
            "solution": "该问题要求实现一个一维卡尔曼滤波器 (KF) 来执行数据同化分析循环。我们必须模拟一个真实状态，生成带噪声的观测，然后应用 KF 来估计该状态。一个关键方面是分析当滤波器使用的模型误差协方差 $Q_{\\text{assumed}}$ 与真实值 $Q_{\\text{true}}$ 不同时，滤波器的性能。要求的输出是平均绝对分析增量和预报误差的漂移度量。\n\n解决方案按要求从第一性原理出发进行开发。卡尔曼滤波器是线性高斯状态空间系统的最优线性估计器，其方程可以直接从贝叶斯原理推导得出。\n\n**1. 状态空间模型**\n\n该系统由一个线性状态空间模型定义：\n- **状态方程（过程模型）：** 在循环 $k$ 的真实状态 $x_{\\text{true}}(k)$ 根据一个带加性高斯噪声的一阶自回归过程演化：\n$$ x_{\\text{true}}(k) = a \\, x_{\\text{true}}(k-1) + w_{k-1} $$\n其中 $a$ 是动态系数，$w_{k-1} \\sim \\mathcal{N}(0, Q_{\\text{true}})$ 是过程噪声，其真实方差为 $Q_{\\text{true}}$。\n\n- **观测方程（测量模型）：** 在循环 $k$ 的观测 $y_k$ 是对真实状态的直接、带噪声的测量：\n$$ y_k = x_{\\text{true}}(k) + v_k $$\n其中 $v_k \\sim \\mathcal{N}(0, R)$ 是测量噪声，其方差为 $R$。\n\n**2. 卡尔曼滤波算法**\n\n卡尔曼滤波器通过执行一个两步循环：预测（预报）和更新（分析），来递归地计算状态的估计值。\n\n**2.1. 预测（预报）步骤**\n\n预测步骤将状态估计及其不确定性向前投影到未来时间。从第 $k-1$ 个循环的状态分析（后验）估计（我们用其均值 $x_a(k-1)$ 和方差 $P_a(k-1)$ 表示）开始，我们计算第 $k$ 个循环的预报（先验）估计。\n- **预报均值：** 第 $k$ 个循环的状态期望值通过应用过程模型的确定性部分得到：\n$$ x_f(k) = E[a \\, x_a(k-1) + w_{k-1}] = a \\, E[x_a(k-1)] = a \\, x_a(k-1) $$\n- **预报方差：** 预报的方差是传播后的分析方差与假定的模型误差方差之和。滤波器使用 $Q_{\\text{assumed}}$，它可能不等于 $Q_{\\text{true}}$。\n$$ P_f(k) = \\text{Var}[a \\, x_a(k-1) + w_{k-1}] = a^2 \\, \\text{Var}[x_a(k-1)] + \\text{Var}[w_{k-1}] = a^2 P_a(k-1) + Q_{\\text{assumed}} $$\n\n**2.2. 从第一性原理推导的更新（分析）步骤**\n\n更新步骤通过融合新的观测 $y_k$ 来优化预报估计。这是一个贝叶斯更新过程，其中预报作为先验，观测提供似然。\n\n- **先验：** 预报为状态 $x_k$ 提供了一个先验概率分布，该分布是高斯的：$p(x_k) = \\mathcal{N}(x_k | x_f(k), P_f(k))$。其概率密度函数 (PDF) 正比于：\n$$ p(x_k) \\propto \\exp\\left(-\\frac{1}{2} \\frac{(x_k - x_f(k))^2}{P_f(k)}\\right) $$\n\n- **似然：** 观测模型 $y_k = x_k + v_k$ 给出了在给定状态 $x_k$ 的条件下观测到 $y_k$ 的似然：$p(y_k|x_k) = \\mathcal{N}(y_k | x_k, R)$。其 PDF 正比于：\n$$ p(y_k|x_k) \\propto \\exp\\left(-\\frac{1}{2} \\frac{(y_k - x_k)^2}{R}\\right) $$\n\n- **后验：** 根据贝叶斯定理，状态的后验分布 $p(x_k|y_k)$ 正比于先验和似然的乘积。这个后验就是分析分布，即 $\\mathcal{N}(x_k | x_a(k), P_a(k))$。\n$$ p(x_k|y_k) \\propto p(y_k|x_k) p(x_k) \\propto \\exp\\left(-\\frac{1}{2} \\left[ \\frac{(x_k - x_f(k))^2}{P_f(k)} + \\frac{(x_k - y_k)^2}{R} \\right]\\right) $$\n两个高斯 PDF 的乘积是另一个高斯 PDF（不计归一化常数）。为了找到其均值 $x_a(k)$ 和方差 $P_a(k)$，我们对指数中关于 $x_k$ 的项进行配方。关于 $x_k$ 的二次项是 $x_k^2 \\left(\\frac{1}{P_f(k)} + \\frac{1}{R}\\right)$，这意味着后验方差的倒数（精度）是先验精度的和：\n$$ \\frac{1}{P_a(k)} = \\frac{1}{P_f(k)} + \\frac{1}{R} \\implies P_a(k) = \\frac{P_f(k) R}{P_f(k) + R} $$\n关于 $x_k$ 的一次项是 $-2x_k \\left(\\frac{x_f(k)}{P_f(k)} + \\frac{y_k}{R}\\right)$。通过将其与高斯指数的规范形式进行比较，我们得到后验均值 $x_a(k)$：\n$$ \\frac{x_a(k)}{P_a(k)} = \\frac{x_f(k)}{P_f(k)} + \\frac{y_k}{R} \\implies x_a(k) = P_a(k) \\left(\\frac{x_f(k)}{P_f(k)} + \\frac{y_k}{R}\\right) $$\n代入 $P_a(k)$ 的表达式并化简，得到预报和观测的加权平均值：\n$$ x_a(k) = \\frac{R x_f(k) + P_f(k) y_k}{P_f(k) + R} $$\n这个方程可以重排成更常见的“新息”形式：\n$$ x_a(k) = x_f(k) + \\frac{P_f(k)}{P_f(k) + R}(y_k - x_f(k)) $$\n这里，$K_k = \\frac{P_f(k)}{P_f(k) + R}$ 是卡尔曼增益，而 $(y_k - x_f(k))$ 是新息或测量残差。这个从第一性原理出发的推导，为使用这些标准的 KF 更新方程提供了合法性。\n\n**3. 仿真与诊断**\n\n仿真从初始条件 $x_{\\text{true}}(0) = x_0$、$x_a(0) = x_0$ 和 $P_a(0) = P_0$ 开始，进行 $k = 1, \\dots, N$ 个循环。在每个循环中，我们：\n1.  使用给定的随机种子生成真实状态 $x_{\\text{true}}(k)$ 和观测 $y_k$。\n2.  执行 KF 预测步骤以得到 $x_f(k)$ 和 $P_f(k)$。\n3.  执行 KF 更新步骤以得到 $x_a(k)$ 和 $P_a(k)$。\n4.  计算所需的诊断量：\n    - **分析增量：** $\\Delta(k) = x_a(k) - x_f(k)$。这代表了根据新观测对预报所做的修正。平均绝对增量计算为 $\\overline{|\\Delta|} = \\frac{1}{N}\\sum_{k=1}^{N} |\\Delta(k)|$。\n    - **预报误差：** $e_f(k) = x_f(k) - x_{\\text{true}}(k)$。这衡量了预报偏离（在现实中不可知的）真实状态的程度。\n    - **漂移度量 ($s$)：** 该度量用于量化预报误差随时间的任何系统性漂移。它通过将预报误差时间序列 $\\{e_f(k)\\}_{k=1}^N$ 对循环指数 $k$ 进行线性最小二乘回归拟合，计算得到的直线斜率。非零斜率表示滤波器发散或次优、有偏的性能。拟合模型为 $e_f(k) \\approx s \\cdot k + b$。\n\n**4. 实现**\n\n最终的实现将针对所提供的每个测试用例遵循此逻辑。为了可复现性，随机数生成器将被设定种子。输出 $\\overline{|\\Delta|}$ 和 $s$ 将按规定进行计算和格式化。$Q$ 的错误指定（$Q_{\\text{assumed}} \\neq Q_{\\text{true}}$）测试了滤波器的鲁棒性。如果 $Q_{\\text{assumed}}$ 太小（离散不足），滤波器会变得过于自信并可能忽略观测，导致误差漂移（$s \\neq 0$）。如果 $Q_{\\text{assumed}}$ 太大（离散过度），滤波器会过于保守，过度依赖带噪声的观测，导致性能次优但通常稳定。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_kalman_filter_simulation(a, Q_true, Q_assumed, R, x0, P0, N, seed):\n    \"\"\"\n    Performs a data assimilation simulation using a 1D Kalman Filter.\n\n    This function simulates a true state, generates observations, runs the Kalman\n    Filter, and computes diagnostic metrics.\n\n    Args:\n        a (float): State transition scalar.\n        Q_true (float): True variance of the model error.\n        Q_assumed (float): Assumed variance of the model error for the filter.\n        R (float): Variance of the observation error.\n        x0 (float): Initial true state and analysis mean.\n        P0 (float): Initial analysis variance.\n        N (int): Total number of simulation cycles.\n        seed (int): Seed for the random number generator for reproducibility.\n\n    Returns:\n        list: A two-element list containing the mean absolute analysis\n              increment and the forecast error drift metric (slope), both\n              rounded to 6 decimal places.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Initialize state variables and histories\n    x_true = x0\n    x_a = x0\n    P_a = P0\n\n    forecast_errors = []\n    analysis_increments = []\n\n    # Simulation loop for cycles k = 1, ..., N\n    for _ in range(1, N + 1):\n        # 1. Advance the true state\n        w_k = rng.normal(loc=0.0, scale=np.sqrt(Q_true))\n        x_true = a * x_true + w_k\n\n        # 2. Generate the observation from the new true state\n        v_k = rng.normal(loc=0.0, scale=np.sqrt(R))\n        y_k = x_true + v_k\n\n        # 3. Kalman Filter: Prediction (Forecast) Step\n        # Propagate state estimate and its variance using previous analysis\n        x_f = a * x_a\n        P_f = a * P_a * a + Q_assumed\n\n        # 4. Kalman Filter: Update (Analysis) Step\n        # Derivation: The analysis is the Bayesian combination of the forecast prior\n        # and observation likelihood. The resulting mean is a weighted average.\n        # This leads to the standard Kalman update equations.\n        innovation = y_k - x_f\n        # Innovation covariance S_k = H P_f H' + R, where H=1 in our 1D case.\n        S_k = P_f + R\n        # Kalman Gain K_k = P_f H' inv(S_k), where H=1, H'=1.\n        K_k = P_f / S_k\n        \n        # Update analysis (posterior) mean and variance\n        x_a = x_f + K_k * innovation\n        P_a = (1.0 - K_k) * P_f\n\n        # 5. Compute and store diagnostic quantities\n        delta_k = x_a - x_f\n        analysis_increments.append(delta_k)\n\n        e_f_k = x_f - x_true\n        forecast_errors.append(e_f_k)\n\n    # Post-processing to calculate final metrics\n    # a. Mean absolute analysis increment\n    mean_abs_delta = np.mean(np.abs(np.array(analysis_increments)))\n\n    # b. Drift metric 's' (slope of least-squares fit of forecast error vs. time)\n    k_values = np.arange(1, N + 1)\n    # np.polyfit returns coefficients [slope, intercept] for a degree 1 polynomial\n    poly_coeffs = np.polyfit(k_values, forecast_errors, 1)\n    s = poly_coeffs[0]\n\n    return [round(mean_abs_delta, 6), round(s, 6)]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (a, Q_true, Q_assumed, R, x0, P0, N, seed)\n        (0.95, 0.04, 0.04, 0.09, 1.0, 0.1, 60, 123),  # Test case 1\n        (0.95, 0.04, 0.0, 0.09, 1.0, 0.1, 60, 123),   # Test case 2\n        (0.95, 0.04, 0.2, 0.09, 1.0, 0.1, 60, 123),  # Test case 3\n        (1.05, 0.04, 0.04, 0.09, 1.0, 0.1, 60, 456),  # Test case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        a, Q_true, Q_assumed, R, x0, P0, N, seed = case\n        result = run_kalman_filter_simulation(a, Q_true, Q_assumed, R, x0, P0, N, seed)\n        results.append(result)\n\n    # Format the final output string exactly as specified.\n    # The default str() for a list includes spaces, so we build the string manually.\n    result_strings = [f\"[{res[0]},{res[1]}]\" for res in results]\n    final_output = f\"[{','.join(result_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "以卷积神经网络（$CNN$）为代表的深度学习模型正逐渐成为数据驱动天气预报的主流方法。然而，尽管这些模型能达到很高的预测精度，它们通常像“黑箱”一样运作，使我们难以完全信任其预测或从中获得科学洞见。本练习将介绍一种名为“显著性图”（saliency map）的模型可解释性技术，它通过计算输出对输入的梯度来揭示模型的关注点。通过实践这一技术，你将学会如何可视化一个基于$CNN$的降水预报模型认为最重要的输入特征，从而连接机器学习与大气科学，并评估该模型是否学到了物理上有意义的关联，例如将降水与高湿度和大气辐合区域联系起来。",
            "id": "4030093",
            "problem": "给定一个简化的、科学上合理的卷积神经网络（CNN）架构，用于在数值天气预报和气候建模的背景下，从网格化的多个大气输入场中预测标量降雨量。该CNN使用“相同”填充的互相关、修正线性单元（ReLU）激活和全局平均池化来产生单个标量预测。您的任务是通过评估预测降雨量相对于输入场的梯度来计算此CNN的显著性图，并总结在具有高湿度和正辐合的区域内，显著性的物理上有意义的集中程度。\n\n基本原理和定义：\n- 卷积神经网络（CNN）定义如下。设输入为 $x \\in \\mathbb{R}^{C \\times H \\times W}$，其中有 $C$ 个通道和 $H \\times W$ 的空间维度。此处，$x^{(1)}$ 是单位为 $\\mathrm{kg}\\,\\mathrm{m}^{-2}$ 的整层积分水汽，$x^{(2)}$ 是单位为 $\\mathrm{K}$ 的近地表温度异常，$x^{(3)}$ 是单位为 $\\mathrm{s}^{-1}$ 的水平辐合。您可以假设 $C = 3$，$H = W = 16$。\n- 该CNN有 $F$ 个滤波器（此处 $F = 2$）。滤波器 $f$ 在位置 $(i,j)$ 的预激活图为\n$$\nz^{(f)}_{i,j} = \\sum_{c=1}^{C} \\sum_{u=1}^{k} \\sum_{v=1}^{k} K^{(f)}_{c,u,v}\\,x^{(c)}_{i+u',j+v'} + b^{(f)},\n$$\n其中 $K^{(f)} \\in \\mathbb{R}^{C \\times k \\times k}$ 是滤波器核，$b^{(f)} \\in \\mathbb{R}$ 是一个偏置，$k=3$，索引 $(u',v')$ 实现与互相关中相同的“相同”填充（在前向传播中没有核旋转），并且填充确保了对于所有的 $(i,j)$，该求和都有明确定义。\n- 激活值为 $a^{(f)}_{i,j} = \\max(0, z^{(f)}_{i,j})$，而全局平均池化后的特征为\n$$\ng^{(f)} = \\frac{1}{H W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} a^{(f)}_{i,j}.\n$$\n- 标量降雨预测值为\n$$\n\\hat{y} = \\sum_{f=1}^{F} w_f\\, g^{(f)} + b_{\\mathrm{out}},\n$$\n单位为 $\\mathrm{mm}\\,\\mathrm{h}^{-1}$。\n\n显著性及物理解释：\n- 将通道 $c$ 的显著性图定义为\n$$\nS^{(c)}_{i,j} = \\frac{\\partial \\hat{y}}{\\partial x^{(c)}_{i,j}}.\n$$\n- 定义具有物理意义的掩码\n$$\nM_{i,j} = \\begin{cases}\n1  \\text{if } x^{(1)}_{i,j} > q_{\\mathrm{th}} \\text{ and } x^{(3)}_{i,j} > 0, \\\\\n0  \\text{otherwise},\n\\end{cases}\n$$\n其中阈值 $q_{\\mathrm{th}} = 25$（单位为 $\\mathrm{kg}\\,\\mathrm{m}^{-2}$）。\n- 定义显著性集中度分数\n$$\n\\phi = \\frac{\\sum_{i=1}^{H} \\sum_{j=1}^{W} \\sum_{c=1}^{C} \\left| S^{(c)}_{i,j} \\right|\\, M_{i,j}}{\\sum_{i=1}^{H} \\sum_{j=1}^{W} \\sum_{c=1}^{C} \\left| S^{(c)}_{i,j} \\right|},\n$$\n该分数测量了位于高湿度、辐合区域的总显著性大小所占的比例（$\\phi \\in [0,1]$，无量纲）。\n\n网络规格（固定且已知）：\n- 滤波器 $f=1$（“降雨支持”）：\n  - $K^{(1)}_{q} = 0.02 \\times \\mathbf{1}_{3 \\times 3}$,\n  - $K^{(1)}_{T'} = 0.01 \\times \\mathbf{1}_{3 \\times 3}$,\n  - $K^{(1)}_{c} = 500 \\times \\mathbf{1}_{3 \\times 3}$,\n  - $b^{(1)} = 0$,\n  - $w_1 = 20$.\n- 滤波器 $f=2$（“锋面探测器”）：\n  - $K^{(2)}_{q} = \\mathbf{0}_{3 \\times 3}$,\n  - $K^{(2)}_{T'} = 0.5 \\times \\begin{bmatrix} -1  0  1 \\\\ -1  0  1 \\\\ -1  0  1 \\end{bmatrix}$,\n  - $K^{(2)}_{c} = \\mathbf{0}_{3 \\times 3}$,\n  - $b^{(2)} = 0$,\n  - $w_2 = 5$.\n- 输出偏置：$b_{\\mathrm{out}} = 0$。\n\n测试套件：\n在一个大小为 $H=W=16$、索引为 $i,j \\in \\{0,1,\\dots,15\\}$ 的空间网格上进行操作，并为 $(x^{(1)}, x^{(2)}, x^{(3)})$ 构建以下4个测试用例：\n- 用例1（理想路径，中央湿润辐合羽流）：\n  - $x^{(1)}_{i,j} = 10 + 30 \\, G(i,j; c_x=8, c_y=8, \\sigma=2)$,\n  - $x^{(2)}_{i,j} = 2 \\, G(i,j; c_x=8, c_y=8, \\sigma=2)$,\n  - $x^{(3)}_{i,j} = 10^{-3} \\, G(i,j; c_x=8, c_y=8, \\sigma=2)$.\n- 用例2（边界条件，角落羽流）：\n  - $x^{(1)}_{i,j} = 10 + 30 \\, G(i,j; c_x=3, c_y=3, \\sigma=2)$,\n  - $x^{(2)}_{i,j} = 2 \\, G(i,j; c_x=3, c_y=3, \\sigma=2)$,\n  - $x^{(3)}_{i,j} = 10^{-3} \\, G(i,j; c_x=3, c_y=3, \\sigma=2)$.\n- 用例3（边缘情况，均匀场）：\n  - $x^{(1)}_{i,j} = 20$,\n  - $x^{(2)}_{i,j} = 0$,\n  - $x^{(3)}_{i,j} = 0$.\n- 用例4（反物理辐合，环形湿度和冷异常）：\n  - $x^{(1)}_{i,j} = 10 + 35 \\left[ G(i,j; c_x=8, c_y=8, \\sigma=3) - 0.7\\, G(i,j; c_x=8, c_y=8, \\sigma=1.5) \\right]$ 下方截断为0,\n  - $x^{(2)}_{i,j} = -2 \\, G(i,j; c_x=8, c_y=8, \\sigma=2.5)$,\n  - $x^{(3)}_{i,j} = -10^{-3} \\, G(i,j; c_x=8, c_y=8, \\sigma=2)$.\n- 此处高斯函数定义为\n$$\nG(i,j; c_x, c_y, \\sigma) = \\exp\\left( -\\frac{(i-c_x)^2 + (j-c_y)^2}{2\\sigma^2} \\right).\n$$\n\n任务：\n1. 实现指定的CNN前向映射，以获取每个用例的 $\\hat{y}$。\n2. 通过应用链式法则和互相关的定义，精确计算显著性图 $S^{(c)}_{i,j} = \\partial \\hat{y} / \\partial x^{(c)}_{i,j}$。利用ReLU的导数对于正预激活值为1，否则为0，以及全局平均池化的导数是按 $1/(H W)$ 进行的常数缩放这一事实。对于通过互相关的反向映射，使用上游梯度与每通道旋转 $180^\\circ$ 的核进行相关运算。\n3. 使用 $q_{\\mathrm{th}} = 25$（单位为 $\\mathrm{kg}\\,\\mathrm{m}^{-2}$）计算掩码 $M_{i,j}$，并计算所定义的集中度分数 $\\phi$。\n4. 对每个用例，产出两个量：\n   - 预测的降雨量 $\\hat{y}$，单位为 $\\mathrm{mm}\\,\\mathrm{h}^{-1}$，并四舍五入到三位小数。\n   - 无量纲的显著性集中度分数 $\\phi$，四舍五入到三位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为 $[\\hat{y}_1, \\phi_1, \\hat{y}_2, \\phi_2, \\hat{y}_3, \\phi_3, \\hat{y}_4, \\phi_4]$，其中下标索引对应于上述编号的测试用例。每个数字必须精确格式化为三位小数。\n\n确保科学真实性：CNN和场必须按规定实现，所有计算必须是确定性的和自包含的，无需外部数据。本问题不使用角度。输入使用的单位是 $\\mathrm{kg}\\,\\mathrm{m}^{-2}$、$\\mathrm{K}$、$\\mathrm{s}^{-1}$，输出使用的单位是 $\\mathrm{mm}\\,\\mathrm{h}^{-1}$。",
            "solution": "用户提供的问题是科学机器学习领域内一个定义明确的计算练习，具体而言，是关于解释在简化的天气预报背景下使用的卷积神经网络（CNN）。该问题具有科学依据，数学上一致，并且为确定唯一解提供了所有必要的参数和定义。因此，我们将着手提供一个完整的解决方案。\n\n该解决方案涉及三个主要的计算步骤：\n1.  通过CNN进行**前向传播**，为每个输入的大气状态计算标量降雨预测值 $\\hat{y}$。\n2.  使用链式法则进行**反向传播**，计算预测值 $\\hat{y}$ 相对于每个输入变量的梯度，从而得到显著性图 $S^{(c)}$。\n3.  一个**分析步骤**，基于有物理动机的掩码 $M$ 来计算显著性集中度分数 $\\phi$。\n\n我们现在将详细说明每个步骤的数学公式。\n\n### 1. 前向传播\n\n前向传播从输入张量 $x \\in \\mathbb{R}^{C \\times H \\times W}$ 计算预测的降雨量 $\\hat{y}$，其中 $C=3$，$H=16$，$W=16$。输入通道为 $x^{(1)}$（水汽）、$x^{(2)}$（温度异常）和 $x^{(3)}$（辐合）。\n\n首先，对于 $F=2$ 个滤波器中的每一个，我们计算一个预激活图 $z^{(f)}$。这是通过对输入 $x$ 与滤波器核 $K^{(f)} \\in \\mathbb{R}^{C \\times k \\times k}$（$k=3$）进行多通道二维互相关，然后加上一个偏置项 $b^{(f)}$ 来实现的。该操作使用“相同”填充，意味着输入被用零填充，以使输出图具有与输入图相同的空间维度 $H \\times W$。\n\n在网格点 $(i,j)$ 处，滤波器 $f$ 的预激活值为：\n$$\nz^{(f)}_{i,j} = b^{(f)} + \\sum_{c=1}^{C} (K^{(f)}_c \\star x^{(c)})_{i,j}\n$$\n其中 $\\star$ 表示二维互相关，$K^{(f)}_c$ 是用于通道 $c$ 的核切片。\n\n其次，将修正线性单元（ReLU）激活函数逐元素应用于预激活图。这为模型引入了非线性。\n$$\na^{(f)}_{i,j} = \\max(0, z^{(f)}_{i,j})\n$$\n\n第三，通过全局平均池化，每个激活图 $a^{(f)}$ 被缩减为单个标量特征 $g^{(f)}$。\n$$\ng^{(f)} = \\frac{1}{H W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} a^{(f)}_{i,j}\n$$\n\n最后，标量降雨预测值 $\\hat{y}$（单位为 $\\mathrm{mm}\\,\\mathrm{h}^{-1}$）被计算为特征 $g^{(f)}$ 的加权和，再加上一个输出偏置 $b_{\\mathrm{out}}$。\n$$\n\\hat{y} = b_{\\mathrm{out}} + \\sum_{f=1}^{F} w_f g^{(f)}\n$$\n所有网络参数（$K^{(f)}$、$b^{(f)}$、$w_f$、$b_{\\mathrm{out}}$）均在问题陈述中提供。\n\n### 2. 用于显著性图的反向传播\n\n输入通道 $c$ 的显著性图 $S^{(c)}$ 被定义为输出预测值 $\\hat{y}$ 相对于输入图 $x^{(c)}$ 的偏导数。我们使用链式法则计算这个值，将梯度从输出反向传播到输入。\n\n1.  **输出层的梯度**：$\\hat{y}$ 相对于池化特征 $g^{(f)}$ 的导数就是输出权重 $w_f$。\n    $$\n    \\frac{\\partial \\hat{y}}{\\partial g^{(f)}} = w_f\n    $$\n\n2.  **池化层的梯度**：由于是平均操作，$g^{(f)}$ 相对于激活图 $a^{(f)}_{i,j}$ 的单个元素的导数是恒定的。\n    $$\n    \\frac{\\partial g^{(f)}}{\\partial a^{(f)}_{i,j}} = \\frac{1}{H W}\n    $$\n    根据链式法则，$\\hat{y}$ 相对于 $a^{(f)}_{i,j}$ 的梯度是一个常数图：\n    $$\n    \\frac{\\partial \\hat{y}}{\\partial a^{(f)}_{i,j}} = \\frac{\\partial \\hat{y}}{\\partial g^{(f)}} \\frac{\\partial g^{(f)}}{\\partial a^{(f)}_{i,j}} = \\frac{w_f}{H W}\n    $$\n\n3.  **激活层的梯度**：ReLU激活 $a^{(f)}_{i,j}$ 相对于其输入 $z^{(f)}_{i,j}$ 的导数在 $z^{(f)}_{i,j} > 0$ 时为 $1$，否则为 $0$。我们用赫维赛德阶跃函数 $H(\\cdot)$ 来表示它。\n    $$\n    \\frac{\\partial a^{(f)}_{i,j}}{\\partial z^{(f)}_{i,j}} = H(z^{(f)}_{i,j}) = \\begin{cases} 1  \\text{if } z^{(f)}_{i,j} > 0 \\\\ 0  \\text{if } z^{(f)}_{i,j} \\le 0 \\end{cases}\n    $$\n    因此，预激活图的上游梯度为：\n    $$\n    \\frac{\\partial \\hat{y}}{\\partial z^{(f)}_{i,j}} = \\frac{\\partial \\hat{y}}{\\partial a^{(f)}_{i,j}} \\frac{\\partial a^{(f)}_{i,j}}{\\partial z^{(f)}_{i,j}} = \\frac{w_f}{HW} H(z^{(f)}_{i,j})\n    $$\n    将这个上游梯度图表示为 $\\delta z^{(f)}$。\n\n4.  **互相关层的梯度**：最后一步是求相对于输入 $x^{(c)}$ 的梯度。预激活 $z^{(f)}$ 是输入通道上互相关运算的和。互相关操作相对于其输入的导数是与原始核的卷积操作。\n    $$\n    S^{(c)} = \\frac{\\partial \\hat{y}}{\\partial x^{(c)}} = \\sum_{f=1}^{F} \\frac{\\partial z^{(f)}}{\\partial x^{(c)}} \\frac{\\partial \\hat{y}}{\\partial z^{(f)}} = \\sum_{f=1}^{F} (\\delta z^{(f)} \\circledast K^{(f)}_c)\n    $$\n    其中 $\\circledast$ 表示二维卷积，$K^{(f)}_c$ 是滤波器 $f$ 和通道 $c$ 的核。此操作等效于将上游梯度图 $\\delta z^{(f)}$ 与旋转180度的核 $K^{(f)}_{c, \\text{rot180}}$ 进行互相关。每个通道 $c$ 的显著性图是来自所有滤波器 $f$ 贡献的总和。\n\n### 3. 显著性集中度分数\n\n分数 $\\phi$ 量化了模型的敏感度（显著性）在多大程度上集中于物理上有利于降雨的区域。\n\n首先，创建一个二元掩码 $M \\in \\{0,1\\}^{H \\times W}$。它识别出同时具有高大气湿度和正辐合的网格点，这是许多类型降水的先决条件。\n$$\nM_{i,j} = \\begin{cases} 1  \\text{if } x^{(1)}_{i,j} > q_{\\mathrm{th}} \\text{ and } x^{(3)}_{i,j} > 0 \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n其中湿度阈值为 $q_{\\mathrm{th}} = 25 \\, \\mathrm{kg}\\,\\mathrm{m}^{-2}$。\n\n然后，显著性集中度分数 $\\phi$ 被计算为掩码区域内总绝对显著性与整个域上总绝对显著性的比率。\n$$\n\\phi = \\frac{\\sum_{c=1}^{C} \\sum_{i=1}^{H} \\sum_{j=1}^{W} |S^{(c)}_{i,j}| M_{i,j}}{\\sum_{c=1}^{C} \\sum_{i=1}^{H} \\sum_{j=1}^{W} |S^{(c)}_{i,j}|}\n$$\n接近 $1$ 的 $\\phi$ 值表明模型主要使用来自物理相关区域的信息进行预测，这表明它已经学到了一个具有物理意义的关系。接近 $0$ 的值则表明情况相反。如果总显著性为零，则 $\\phi$ 定义为 $0$。\n\n实现将针对所提供的四个测试用例中的每一个，遵循这些步骤。",
            "answer": "```python\nimport numpy as np\nfrom scipy import signal\n\ndef solve():\n    \"\"\"\n    Main function to solve the CNN saliency problem for all test cases.\n    \"\"\"\n    \n    # -------------------\n    # Problem Configuration\n    # -------------------\n    H, W = 16, 16\n    C, F = 3, 2\n    k = 3\n    q_th = 25.0\n\n    # Network parameters\n    kernels = np.zeros((F, C, k, k))\n    # Filter f=1 (index 0)\n    kernels[0, 0, :, :] = 0.02 * np.ones((k, k))  # K_q\n    kernels[0, 1, :, :] = 0.01 * np.ones((k, k))  # K_T'\n    kernels[0, 2, :, :] = 500.0 * np.ones((k, k)) # K_c\n    # Filter f=2 (index 1)\n    kernels[1, 0, :, :] = 0.0 * np.zeros((k, k)) # K_q\n    kernels[1, 1, :, :] = 0.5 * np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]) # K_T'\n    kernels[1, 2, :, :] = 0.0 * np.zeros((k, k)) # K_c\n\n    biases_conv = np.array([0.0, 0.0])\n    weights_out = np.array([20.0, 5.0])\n    bias_out = 0.0\n\n    # -------------------\n    # Helper Functions\n    # -------------------\n    def gaussian(i_grid, j_grid, cx, cy, sigma):\n        return np.exp(-((i_grid - cx)**2 + (j_grid - cy)**2) / (2 * sigma**2))\n\n    # Grid for generating fields\n    i_grid, j_grid = np.meshgrid(np.arange(H), np.arange(W), indexing='ij')\n\n    # Test Case Definitions\n    test_cases = [\n        # Case 1: Central plume\n        (\n            10 + 30 * gaussian(i_grid, j_grid, 8, 8, 2),\n            2 * gaussian(i_grid, j_grid, 8, 8, 2),\n            1e-3 * gaussian(i_grid, j_grid, 8, 8, 2)\n        ),\n        # Case 2: Corner plume\n        (\n            10 + 30 * gaussian(i_grid, j_grid, 3, 3, 2),\n            2 * gaussian(i_grid, j_grid, 3, 3, 2),\n            1e-3 * gaussian(i_grid, j_grid, 3, 3, 2)\n        ),\n        # Case 3: Uniform fields\n        (\n            20 * np.ones((H, W)),\n            0 * np.ones((H, W)),\n            0 * np.ones((H, W))\n        ),\n        # Case 4: Ring moisture, central cold anomaly, divergence\n        (\n            np.maximum(0, 10 + 35 * (gaussian(i_grid, j_grid, 8, 8, 3) - 0.7 * gaussian(i_grid, j_grid, 8, 8, 1.5))),\n            -2 * gaussian(i_grid, j_grid, 8, 8, 2.5),\n            -1e-3 * gaussian(i_grid, j_grid, 8, 8, 2)\n        )\n    ]\n    \n    results = []\n    \n    for case_data in test_cases:\n        x = np.array(case_data)  # Shape (C, H, W)\n\n        # -------------------\n        # 1. Forward Pass\n        # -------------------\n        z_maps = np.zeros((F, H, W))\n        a_maps = np.zeros((F, H, W))\n        g_features = np.zeros(F)\n\n        for f in range(F):\n            z_f = np.full((H, W), biases_conv[f])\n            for c in range(C):\n                z_f += signal.correlate2d(x[c, :, :], kernels[f, c, :, :], mode='same', boundary='fill', fillvalue=0)\n            z_maps[f, :, :] = z_f\n            a_maps[f, :, :] = np.maximum(0, z_f)\n            g_features[f] = np.mean(a_maps[f, :, :])\n\n        y_hat = np.sum(weights_out * g_features) + bias_out\n\n        # -------------------\n        # 2. Backward Pass (Saliency)\n        # -------------------\n        saliency_maps = np.zeros((C, H, W))\n        \n        for f in range(F):\n            # Upstream gradient from output layer, through pooling\n            d_y_hat_d_g_f = weights_out[f]\n            d_g_f_d_a_f = 1.0 / (H * W)\n            d_y_hat_d_a_f = d_y_hat_d_g_f * d_g_f_d_a_f\n            \n            # Upstream gradient through ReLU\n            d_a_f_d_z_f = (z_maps[f, :, :] > 0).astype(float)\n            delta_z_f = d_y_hat_d_a_f * d_a_f_d_z_f\n\n            # Gradient w.r.t input x\n            for c in range(C):\n                # Gradient of cross-correlation is convolution with original kernel\n                saliency_maps[c, :, :] += signal.convolve2d(delta_z_f, kernels[f, c, :, :], mode='same', boundary='fill', fillvalue=0)\n        \n        # -------------------\n        # 3. Saliency Concentration Fraction (phi)\n        # -------------------\n        mask = ((x[0, :, :] > q_th)  (x[2, :, :] > 0)).astype(float)\n        \n        saliency_abs_total = np.sum(np.abs(saliency_maps))\n        \n        numerator = np.sum(np.abs(saliency_maps) * mask[np.newaxis, :, :])\n        \n        phi = 0.0\n        if saliency_abs_total > 1e-12: # Avoid division by zero\n            phi = numerator / saliency_abs_total\n            \n        # Store results\n        results.append(y_hat)\n        results.append(phi)\n        \n    # Format and print the final output\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}