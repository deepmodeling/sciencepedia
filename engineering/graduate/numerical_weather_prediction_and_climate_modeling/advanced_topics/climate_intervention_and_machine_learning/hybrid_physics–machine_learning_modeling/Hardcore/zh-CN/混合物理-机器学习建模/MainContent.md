## 引言
近年来，[混合物理-机器学习](@entry_id:1126241)（Hybrid Physics-Machine Learning, P-ML）建模已成为科学与工程计算领域的一个前沿范式。这种方法旨在融合基于第一性原理的物理模型的严谨性与机器学习从海量数据中学习复杂模式的强大能力，为模拟和预测复杂系统（如地球气候和工程结构）提供了前所未有的机遇。

然而，这一融合并非易事。传统的物理模型虽然根植于成熟的理论，但常常受困于“[模型形式不确定性](@entry_id:1128038)”，特别是对无法显式解析的次网格过程的近似（即[参数化](@entry_id:265163)），导致了难以消除的系统性误差。另一方面，纯粹的“黑箱”[机器学习模型](@entry_id:262335)虽然灵活，却常常缺乏物理可解释性，并且在应用于长期、耦合的模拟时，容易违反基本的守恒定律，导致数值不稳定和不切实际的预测。本文旨在解决这一知识鸿沟，系统性地阐述如何构建既具有高预测精度又遵守物理约束的[混合模型](@entry_id:266571)。

为了实现这一目标，本文将分为三个核心部分。在“原理与机制”一章中，我们将深入探讨混合建[模的基](@entry_id:156416)本原理，从模型误差的分类到确保物理一致性和[数值稳定性](@entry_id:175146)的关键技术。接着，在“应用与跨学科连接”一章，我们将通过地球科学、工程和基础物理等领域的丰富案例，展示这些原理在实践中的强大威力。最后，“动手实践”部分提供了具体的编程练习，让读者能够亲手实现和体验混合建模的关键思想。通过这三个章节的学习，读者将全面掌握构建和应用稳健、可靠的[混合物理-机器学习](@entry_id:1126241)模型的理论基础和实践方法。

## 原理与机制

本章深入探讨[混合物理-机器学习](@entry_id:1126241)模型的基本原理和运行机制，特别关注其在数值天气预报（NWP）和气候建模中的应用。我们将从混合模型需求的理论基础出发，探讨其构建的架构范式、确保物理一致性和稳定性的关键挑战，最后讨论其数值实现和泛化方面的进阶主题。

### 混合化的基本原理：理解和修正模型误差

物理系统的数值模型，例如大气模型，是一种近似。由于多种因素的综合作用，其预测不可避免地会与现实产生偏差。在混合建模的背景下，首先必须对这些偏差进行定性，因为它们构成了机器学习组件试图学习和修正的目标。

#### 结构性误差与参数性误差

一个预报变量（比方说 $\phi$）的演化由物理定律所决定的真实倾向 $\mathcal{F}_{\mathrm{true}}(\phi)$ 控制。数值模型通过一个[参数化](@entry_id:265163)算子 $\mathcal{F}_{\mathrm{num}}(\phi; \theta)$ 来近似它，其中 $\theta$ 是一个可调参数的向量。**模型误差**可以定义为在给定状态下这些倾向之间的差异：$\varepsilon(\phi) = \mathcal{F}_{\mathrm{true}}(\phi) - \mathcal{F}_{\mathrm{num}}(\phi; \theta)$ 。这个误差就是混合模型的数据驱动组件旨在近似的量。

该模型误差可以大致分为两类：

1.  **参数性误差**：当模型的函数形式 $\mathcal{F}_{\mathrm{num}}$ 基本正确，但为参数 $\theta$ 选择的值不正确时，就会发生这种误差。例如，在[暖雨微物理](@entry_id:1133953)方案中，云水向雨水的自动转化通常通过云水混合比的阈值来[参数化](@entry_id:265163)。使用不正确的阈值就构成了参数性误差。原则上，这类误差可以通过校准或“调整”参数 $\theta$ 来对照观测数据进行修正。

2.  **结构性误差**：这是一种更深层次的缺陷，即 $\mathcal{F}_{\mathrm{num}}$ 的函数形式本身不正确或不完整。它可能是对真实物理的过度简化表示，或者可能完全忽略了某些过程。例如，在冰晶过程显著的[混合相云](@entry_id:1127959)中使用仅包含暖雨过程的微物理方案，是一种结构性误差 。同样，在长波辐射模型中，在有云的整层大气中假设晴空条件，或在短波模型中，忽略气溶胶的吸收效应，都属于结构性误差 。任何对现有参数 $\theta$ 的调整都无法纠正结构性误差；修正它需要修改模型的控制方程。

机器学习为解决结构性误差提供了一条强有力的途径，它能直接从数据中学习复杂的、依赖于状态的[误差函数](@entry_id:176269) $\varepsilon(\phi)$，而无需从第一性原理推导其解析形式。

#### [次网格尺度参数化](@entry_id:1132601)的作用

许多结构性误差源于尺度问题。NWP和气候模型在具有特征间距 $\Delta$ 的离散网格上求解控制方程。发生在小于 $\Delta$ 尺度上的过程无法被显式解析。当我们对控制方程进行形式上的滤波以分离已解析和未解析的尺度时，会得到额外的项，这些项代表了**[次网格尺度](@entry_id:1132591)（SGS）**过程对已解析流的影响。例如，对[动量方程](@entry_id:197225)进行滤波会产生一个次网格应力张量，通常称为[雷诺应力](@entry_id:263788)，$\tau_{ij} = \overline{u_i u_j} - \overline{u}_i \overline{u}_j$，它表示未解析运动对已解析动量的输送。

**[次网格参数化](@entry_id:1132597)**是一种闭合模型，旨在将这些未闭合的、未解析的项（如 $\tau_{ij}$）表示为已解析尺度变量的函数 。这正是混合模型经常介入的地方：机器学习组件被训练来充当一个数据驱动的[次网格参数化](@entry_id:1132597)方案。

为了有效地设计这样一个组件，必须了解宿主数值模型的结构。一个关键的区别在于**预报变量**和**诊断变量**。预报变量是通过倾向方程（例如温度、风、湿度）进行时间推进的变量。诊断变量是在单个时间步内根据预报变量的当前状态“即时”计算的，并且不会被带到下一个时间步。例如，在典型的对流质量通量方案中，对流质量通量和由此产生的加热率是根据那一刻的大气状态诊断出来的。相比之下，一个[湍流](@entry_id:151300)方案可能将[湍流](@entry_id:151300)动能（TKE）作为一个带有自身倾向方程的预报变量，而从TKE导出的涡流扩散系数则是诊断的 。机器学习模型可以被设计为预测预报变量的倾向，或模拟诊断量的计算。

### [混合模型](@entry_id:266571)的架构范式

一旦我们确定了学习的目标——模型误差，通常以次网格倾向的形式存在——就必须决定整合基于物理和数据驱动组件的架构。这不是一个“一刀切”的选择；不同的策略体现了对先验物理知识和数据作用的不同假设 。

假设系统状态 $\mathbf{x}(t)$ 的连续演化由一个[偏微分](@entry_id:194612)方程算子 $\mathcal{F}$ 控制，即 $\partial_t \mathbf{x} = \mathcal{F}(\mathbf{x})$。数值模型提供了一个离散的时间步进映射 $\mathcal{M}_{\Delta t}$ 来近似这个演化，使得 $\mathbf{x}_{t+\Delta t} = \mathcal{M}_{\Delta t}(\mathbf{x}_t)$。我们可以识别出一系列混合建模策略：

*   **黑箱模拟器**：这种方法摒弃了对基于物理的算子 $\mathcal{M}_{\Delta t}$ 的显式使用，而是训练一个[机器学习模型](@entry_id:262335)（通常是深度神经网络）来直接从时空数据（例如，[再分析数据](@entry_id:1130710)或高分辨率模型输出）中学习整个时间步进映射 $\hat{\mathcal{M}}_{\Delta t, \boldsymbol{\theta}} : \mathbf{x}_t \mapsto \mathbf{x}_{t+\Delta t}$。该策略假设训练数据对系统的[吸引子](@entry_id:270989)提供了足够的覆盖，从而可以进行准确的插值。虽然概念上简单，但黑箱模拟器带有重大风险。除非将基本物理原理（如质量或能量守恒）明确编码到[网络架构](@entry_id:268981)或损失函数中，否则它们无法提供内置的保证来尊重这些原理。

*   **灰箱[残差模型](@entry_id:897350)**：这可以说是混合物理建模中最普遍和最有前途的策略。它假设基于物理的算子 $\mathcal{M}_{\Delta t}$ 能正确捕捉主导动力学，但存在结构性的、依赖于状态的误差。然后，机器学习模型被训练来仅预测这个误差或残差。混合更新的形式为 $\mathbf{x}_{t+\Delta t} \approx \mathcal{M}_{\Delta t}(\mathbf{x}_t) + \hat{R}_{\boldsymbol{\phi}}(\mathbf{x}_t)$，其中 $\hat{R}_{\boldsymbol{\phi}}$ 是学习到的残差修正  。这种方法有几个优点：它利用了编码在 $\mathcal{M}_{\Delta t}$ 中的大量现有物理知识，并且机器学习模型被赋予了一个更简单的学习问题（学习误差而不是完整的动力学）。此外，物理约束可以更容易地施加在修正项 $\hat{R}_{\boldsymbol{\phi}}$ 上。

*   **[物理信息神经网络](@entry_id:145229)（[PINNs](@entry_id:145229)）**：这种方法在方程的连续形式上操作。构建一个神经网络来表示解本身，例如 $\hat{\mathbf{x}}(\vec{r}, t; \boldsymbol{\theta})$。然后通过最小化一个包含[偏微分](@entry_id:194612)方程残差 $\mathcal{R}(\hat{\mathbf{x}}) = \partial_t \hat{\mathbf{x}} - \mathcal{F}(\hat{\mathbf{x}})$ 的损失函数来训练网络，该残差在空间和时间的多个[配置点](@entry_id:169000)上进行评估。这迫使学习到的解近似满足控制方程。PINNs假设算子 $\mathcal{F}$ 的解析形式是已知且可微的。当观测数据稀疏时，它们在解决[正向和反向问题](@entry_id:1125252)方面特别强大，因为[偏微分](@entry_id:194612)方程本身提供了一个强有力的物理正则化器。

将这些“在线”或“模型内”的[混合方法](@entry_id:163463)与传统的“离线”统计修正区分开来至关重要。业务天气预报中的一个长期技术是**模式输出统计（MOS）**，它在完整的物理模型完成其积分*之后*应用一个学习到的统计修正。MOS学习一个从模型输出（例如，特定位置的预测温度）到相应观测量的映射，有效地校正系统性偏差和[表示误差](@entry_id:171287)。相比之下，混合模型在预报*期间*修改积分，从而改变模型自身的轨迹 。

### 确保物理一致性和稳定性

纯数据驱动模型的主要吸[引力](@entry_id:189550)在于其灵活性和捕捉复杂关系的能力，而不受现有理论的限制。然而，这种灵活性也是它们最大的弱点。当耦合到时间步进模拟中时，一个未经设计的机器学习组件很容易违反基本的物理定律，导致不符合物理的行为和灾难性的[数值不稳定性](@entry_id:137058)。因此，一个成功的混合模型必须被设计为在长期积分中既能保持物理一致性，又能保持[数值稳定性](@entry_id:175146)。

#### [数值稳定性](@entry_id:175146)

数值稳定性关注模拟中误差的行为。一个不稳定的方案会导致小误差（来自截断或舍入）指数级放大，最终摧毁解。

*   **线性稳定性**：分析稳定性的标准方法是在一个不动点或[稳态](@entry_id:139253) $\bar{\mathbf{x}}$ 周围对动力学进行线性化。数值映射的一个不动点满足 $\bar{\mathbf{x}} = \bar{\mathbf{x}} + \Delta t \Psi(\bar{\mathbf{x}})$，这意味着离散倾向 $\Psi(\bar{\mathbf{x}}) = 0$。对于混合[残差模型](@entry_id:897350)，倾向是 $\Psi(\mathbf{x}) + \mathcal{C}(\mathbf{x};\theta)$。小扰动 $e^n = \mathbf{x}^n - \bar{\mathbf{x}}$ 的演化由总倾向的[雅可比矩阵](@entry_id:178326) $J = \left.\frac{\partial}{\partial \mathbf{x}}\left(\mathcal{L}(\mathbf{x})+\mathcal{C}_{\theta}(\mathbf{x})\right)\right|_{\mathbf{x}=\bar{\mathbf{x}}}$ 控制。对于一个[显式时间积分](@entry_id:165797)器，如果[放大矩阵](@entry_id:746417)（其依赖于 $\Delta t \cdot J$）的特征值的模都小于或等于一，则该方案是线性稳定的。机器学习组件 $\mathcal{C}_{\theta}$ 直接贡献于[雅可比矩阵](@entry_id:178326) $J$，从而从根本上改变了系统的稳定性属性 。

*   **[平衡态](@entry_id:270364)的保持**：确保稳定性的关键第一步是要求混合模型不改变原始物理模型的不动点。如果 $\mathbf{x}^*$ 是物理模型的一个不动点，其倾向为零：$\Psi(\mathbf{x}^*) = 0$。为了使它也成为[混合模型](@entry_id:266571)的不动点，混合倾向也必须为零：$\Psi(\mathbf{x}^*) + \mathcal{C}(\mathbf{x}^*;\theta) = 0$。这意味着对学习到的修正有一个必要条件：它必须在物理模型的不动点处为零，即 $\mathcal{C}(\mathbf{x}^*;\theta) = 0$ 。这是一个直观的结果：如果物理模型在[平衡态](@entry_id:270364)下已经完美，那么修正应该为零。

*   **[能量稳定性](@entry_id:748991)**：线性稳定性只分析无穷小的扰动。一个更强的[非线性](@entry_id:637147)概念是**[能量稳定性](@entry_id:748991)**，它要求系统的物理或数学“能量”不随时间增长。对于许多物理系统，我们可以定义一个二次[能量泛函](@entry_id:170311)，$E(\mathbf{x}) = \frac{1}{2}\mathbf{x}^{\top} W \mathbf{x}$，其中 $W$ 是一个[对称正定矩阵](@entry_id:136714)。如果 $\frac{dE}{dt} \le 0$，则[连续系统](@entry_id:178397)是耗散的。这通常发生在已解析动力学算子 $\mathcal{L}$ 是能量守恒的（或 $W$-斜对称，即 $\mathbf{x}^{\top} W \mathcal{L}(\mathbf{x})=0$），而次网格闭合是耗散的（$W$-耗散，即 $\mathbf{x}^{\top} W \mathcal{C}_{\theta}(\mathbf{x})\le 0$）时。[显式时间积分](@entry_id:165797)器不会自动保持此属性。确保离散[能量稳定性](@entry_id:748991)，$E(\mathbf{x}^{n+1}) \le E(\mathbf{x}^n)$，要么需要足够小的时间步长，要么需要使用专门的积分器，并且关键取决于机器学习组件 $\mathcal{C}_{\theta}$ 的耗散特性 。

#### 守恒律

也许最重要的物理约束是质量、动量和能量等量的守恒律。这些定律不仅仅是美学上的要求；它们对于气候模拟的长期稳定性和真实性至关重要。

*   **硬约束与软约束**：在机器学习组件上强制执行这些定律主要有两种策略 。
    *   **软约束**：这涉及在训练损失函数中添加一个惩罚项，以抑制对定律的违反。例如，为了促使一个学习到的源项 $S_{\theta}$ 守恒质量，可以添加一个与 $(\int_{\Omega} S_{\theta} d\mathbf{x})^2$ 成正比的惩罚。这种方法易于实现，但不能保证精确守恒。
    *   **硬约束**：这种方法通过模型的架构来精确地强制执行守恒律。例如，可以通过减去其空间平均值来构造一个严格质量中性的输出 $S_{\theta}$，$S_{\theta} \rightarrow S_{\theta} - \langle S_{\theta} \rangle$。这种方法设计起来更困难，但提供了精确的保证。

*   **小误差的危害**：对于长期气候模拟，强烈推荐使用硬约束。软约束可能在每个时间步留下一个小的残余违规量 $\varepsilon_n$。虽然很小，但这个误差可以在数百万个时间步中累积。如果误差有小的系统性偏差，总[守恒量](@entry_id:161475)将随时间漂移，其大小为 $N\varepsilon$，其中 $N$ 是步数。这可能导致灾难性的、不符合物理的结果，例如一个行星慢慢失去其大气层或海洋无限制地持续升温 。

*   **设计守恒模型**：构建一个守恒的混合模型最稳健的方法是，设计它使其尊重守恒律的[数值离散化](@entry_id:752782)。在**有限体积（FV）方法**中，守恒是通过将方程离散化为**[通量形式](@entry_id:273811)**来实现的。控制体积内某个量的变化由跨其面的通量之和决定。如果离开一个单元的[数值通量](@entry_id:145174)与进入相邻单元的通量完全相同（一种称为[反对称性](@entry_id:261893)的属性），则全局守恒得到保证 。这为守恒的机器学习提供了一个清晰的设计原则：机器学习模型不应学习以单元为中心的倾向（源/汇项），而应学习对[单元间通量](@entry_id:750708)的修正。通过对学习到的[通量修正](@entry_id:1125150)强制执行[反对称性](@entry_id:261893)，全局守恒就通过构造自动得到保证 。如果[机器学习模型](@entry_id:262335)必须产生以单元为中心的倾向，只要模型架构确保这些倾向的全局总和恒为零，仍然可以强制守恒。如果倾向可以表示为某个底层学习到的通量场的离散散度，就可以实现这一点 。

在应用科学中，这些原理的一个强大应用涉及**湿静力能（MSE）**，定义为 $h = c_p T + g z + L_v q_v$，它结合了感热、位能和潜热。对于没有降水的[绝热流](@entry_id:262576)体块运动，MSE是一个[守恒量](@entry_id:161475) 。对流可以被看作是一个垂直重新分配MSE但不对整个大气柱创造或销毁MSE的内部过程。因此，一个机器学习对流方案的热力学一致性的关键诊断是检查其产生的整层大气积分的MSE倾向是否总和为零（或者更一般地，等于来自辐射和地表通量等外部源的净能量输入）。一个显著的非零残差表明[机器学习模型](@entry_id:262335)正在不符合物理地创造或销毁能量。

### 进阶主题与开放挑战

构建一个稳定且守恒的[混合模型](@entry_id:266571)是成功的必要但不充分条件。我们还必须考虑其数值实现的具体细节以及泛化到未见条件的最终挑战。

#### 数值耦合策略

[混合模型](@entry_id:266571)涉及两个算子：物理倾向 $\mathcal{L}$ 和机器学习倾向 $\mathcal{G}$。完整的演化由 $\frac{du}{dt} = \mathcal{L}(u) + \mathcal{G}(u)$ 给出。如何在一个时间步 $\Delta t$ 内数值地组合这两个算子是一个不平凡的选择。

*   **[算子分裂](@entry_id:634210)**：这种方法将完整的更新分解为来自单个算子的一系列更新。
    *   **序贯（李）分裂**：一个接一个地应用算子：$u^{n+1} = \varphi_{\mathcal{G}}^{\Delta t} \circ \varphi_{\mathcal{L}}^{\Delta t} (u^n)$，其中 $\varphi^{\Delta t}$ 表示该算子的数值求解器。此方法简单但时间精度只有一阶。主导误差项与算子的对易子 $[\mathcal{L}, \mathcal{G}] = \mathcal{L}\mathcal{G} - \mathcal{G}\mathcal{L}$ 成正比 。
    *   **斯特朗（对称）分裂**：一个更精确的方法涉及一个对称序列，例如，$u^{n+1} = \varphi_{\mathcal{L}}^{\Delta t/2} \circ \varphi_{\mathcal{G}}^{\Delta t} \circ \varphi_{\mathcal{L}}^{\Delta t/2} (u^n)$。这消除了阶误差项，从而得到一个二阶精度的方。
    分裂的一个关键优点是它可以保留几何属性。如果每个子求解器 $\varphi_{\mathcal{L}}$ 和 $\varphi_{\mathcal{G}}$ 单独保持一个二次不变量（如能量），那么它们的组合也将精确地保持它 。

*   **加性方法**：这种方法在单个[时间积分](@entry_id:267413)器内将倾向的总和一起处理。一个简单的例子是显式前向欧拉方法：$u^{n+1} = u^n + \Delta t (\mathcal{L}(u^n) + \mathcal{G}(u^n))$。虽然简单，但这通常存在问题。许多物理系统包含快（刚性）和慢（非刚性）过程。显式方法受最快时间尺度的限制，需要非常小的 $\Delta t$。如果机器学习[参数化](@entry_id:265163) $\mathcal{G}$ 是刚性的，**隐式-显式（IMEX）**方案通常是更好的选择。IMEX方案隐式处理刚性部分（允许大时间步长），显式处理非刚性部分，提供了一个稳定而高效的折衷方案 。

#### 泛化与尺度感知

*   **尺度感知**：[次网格参数化](@entry_id:1132597)取决于网格尺度 $\Delta$ 的选择。随着[网格细化](@entry_id:168565)（$\Delta \to 0$），更多的物理过程被解析，次网格分量的贡献应该消失。一个不依赖于 $\Delta$ 的[参数化](@entry_id:265163)是**尺度无知**的。当在具有可变网格分辨率的模型中使用时，这种方案会错误地将次网格修正应用于现在由模型显式解析的运动，这个问题被称为“双重计算” 。一个**尺度感知**的[参数化](@entry_id:265163)必须显式地依赖于 $\Delta$，使其影响随着 $\Delta \to 0$ 而减小。这可以通过设计机器学习模型将 $\Delta$ 作为输入来实现，或者更正式地，通过确保学习到的闭合仅作用于[状态空间](@entry_id:160914)的未解析部分，例如通过将其输出投影到波数大于网格截止频率的傅里叶模态上 。

*   **分布外泛化**：这可以说是混合气候建模的巨大挑战。[机器学习模型](@entry_id:262335)是在当前或过去气候的数据上训练的，其特征是概率分布 $P_{\text{train}}(\mathbf{x}, y)$。然后，它们被要求对未来气候进行预测，而未来气候将具有不同的分布 $P_{\text{test}}(\mathbf{x}, y)$。当 $P_{\text{test}} \neq P_{\text{train}}$ 时表现良好的能力被称为**分布外（OOD）泛化**。这种[分布偏移](@entry_id:915633)的性质至关重要 ：
    *   **[协变量偏移](@entry_id:636196)**：大气状态的分布发生变化（$P_{\text{test}}(\mathbf{x}) \neq P_{\text{train}}(\mathbf{x})$），但将状态与次网格倾向联系起来的潜在物理定律保持不变（$P_{\text{test}}(y|\mathbf{x}) = P_{\text{train}}(y|\mathbf{x})$）。如果大尺度环流模式发生变化，使得某些天气状态变得更频繁或更不频繁，就可能发生这种情况。
    *   **概念偏移**：物理定律本身发生变化（$P_{\text{test}}(y|\mathbf{x}) \neq P_{\text{train}}(y|\mathbf{x})$）。例如，气溶胶浓度的变化可能会改变云微物理，这意味着相同的已解析大气状态 $\mathbf{x}$ 会产生不同的云响应 $y$。这是一个根本性的挑战，因为[机器学习模型](@entry_id:262335)学习到的关系不再有效。
    *   **标签偏移**：离散天气模态的频率发生变化（$P_{\text{test}}(y) \neq P_{\text{train}}(y)$），但给定模态的大气状态特征是稳定的。

构建能够在这些偏移（特别是概念偏移这种困难情况）下稳健泛化的混合模型是一个前沿研究领域。希望通过将机器学习组件植根于一个稳健的物理核心并强制执行物理约束，所得到的混合模型将具有更强的[归纳偏置](@entry_id:137419)，使其比一个纯[黑箱模型](@entry_id:1121697)，在面对未来气候的新条件时能更可靠地进行外推。