{
    "hands_on_practices": [
        {
            "introduction": "Before we can evaluate a model against climatology, we must first rigorously define our baseline. In a non-stationary climate, the choice of a \"climatological reference period\" is not a trivial matter and has profound implications for the interpretation of model biases. This first exercise  tackles this foundational issue head-on, exploring how a background warming trend can create an artificial offset when comparing anomalies computed over different time intervals. By working through this problem, you will develop a critical awareness of the importance of consistent reference periods for ensuring a fair and meaningful model-data comparison.",
            "id": "4022305",
            "problem": "A research group evaluates a climate model’s representation of near-surface air temperature by comparing model anomalies to observational anomalies. An anomaly is defined relative to a chosen climatological reference period. Consider a scalar climate variable $x(t)$, with $t$ measured in years, modeled as a sum of a deterministic linear trend and a zero-mean stationary residual: $x(t) = \\alpha + \\beta t + \\varepsilon(t)$, where $\\alpha$ and $\\beta$ are constants and the residual $\\varepsilon(t)$ is a stationary process satisfying $\\mathbb{E}[\\varepsilon(t)] = 0$ and finite variance. The climatological mean over a finite interval $[T_1, T_2]$ is defined as the time average $\\bar{x}_{[T_1,T_2]} = \\frac{1}{T_2 - T_1} \\int_{T_1}^{T_2} x(t)\\,\\mathrm{d}t$. An anomaly with respect to a reference period $[T_1, T_2]$ is $a(t) = x(t) - \\bar{x}_{[T_1,T_2]}$. \n\n- Using only the definitions above and standard properties of integrals and expectations, derive how a linear trend affects $\\bar{x}_{[T_1,T_2]}$ and obtain an expression for the difference between climatological means computed over two different reference intervals $[T_1, T_2]$ and $[S_1, S_2]$.\n- Then, apply your result to a practical evaluation scenario in which the model anomalies are referenced to $1981$–$2010$ (that is, $[T_1,T_2] = [1981, 2010]$) while the observational anomalies are referenced to $1991$–$2020$ (that is, $[S_1,S_2] = [1991, 2020]$). Assume the variable has a trend $\\beta = 2.0 \\times 10^{-2}\\ \\mathrm{K\\,yr^{-1}}$. Compute the expected offset between these anomaly baselines implied purely by the linear trend, expressed as the model anomaly baseline minus the observational anomaly baseline. Express your final answer in $\\mathrm{K}$ and round your answer to four significant figures.",
            "solution": "The user wants me to act as a meticulous STEM professor.\n\nMy task is to:\n1.  **Validate the problem statement.**\n2.  If valid, provide a detailed, reasoned solution.\n3.  If invalid, explain why and terminate.\n4.  Follow strict formatting rules, especially for LaTeX and the final XML-like structure.\n\n**Problem Breakdown:**\n\n1.  **Model Definition**: A scalar climate variable `x(t)` is given as:\n    `x(t) = α + βt + ε(t)`\n    - `α`, `β` are constants.\n    - `t` is time in years.\n    - `ε(t)` is a stationary process with `E[ε(t)] = 0` and finite variance.\n\n2.  **Climatological Mean Definition**:\n    `x̄_[T1,T2] = (1 / (T2 - T1)) * ∫[T1, T2] x(t) dt`\n\n3.  **Anomaly Definition**:\n    `a(t) = x(t) - x̄_[T1,T2]`\n\n4.  **Part 1: Derivations**\n    -  Derive how the linear trend (`βt`) affects the climatological mean `x̄_[T1,T2]`.\n    -  Obtain an expression for the difference between two climatological means: `x̄_[T1,T2] - x̄_[S1,S2]`.\n\n5.  **Part 2: Application**\n    -  Model reference period: `[T1, T2] = [1981, 2010]`.\n    -  Observational reference period: `[S1, S2] = [1991, 2020]`.\n    -  Trend: `β = 2.0 * 10^-2 K/yr`.\n    -  Compute the expected offset between the baselines: `E[x̄_[T1,T2] - x̄_[S1,S2]]`.\n    -  The offset is defined as \"model anomaly baseline minus the observational anomaly baseline\", which corresponds to `x̄_[T1,T2] - x̄_[S1,S2]`.\n    -  The problem asks for the *expected* offset *implied purely by the linear trend*. This means I should consider the expectation `E[...]` and note that `E[ε(t)] = 0`.\n    -  The final answer should be in `K` and rounded to four significant figures.\n\n**Validation Step-by-Step:**\n\n**Step 1: Extract Givens**\n\n-   A scalar climate variable $x(t)$ is modeled as $x(t) = \\alpha + \\beta t + \\varepsilon(t)$.\n-   $t$ is time in years.\n-   $\\alpha$ and $\\beta$ are constants.\n-   $\\varepsilon(t)$ is a stationary process.\n-   $\\mathbb{E}[\\varepsilon(t)] = 0$.\n-   $\\varepsilon(t)$ has finite variance.\n-   The climatological mean over a finite interval $[T_1, T_2]$ is $\\bar{x}_{[T_1,T_2]} = \\frac{1}{T_2 - T_1} \\int_{T_1}^{T_2} x(t)\\,\\mathrm{d}t$.\n-   An anomaly with respect to a reference period $[T_1, T_2]$ is $a(t) = x(t) - \\bar{x}_{[T_1,T_2]}$.\n-   Model reference period: $[T_1, T_2] = [1981, 2010]$.\n-   Observational reference period: $[S_1, S_2] = [1991, 2020]$.\n-   Trend: $\\beta = 2.0 \\times 10^{-2}\\ \\mathrm{K\\,yr^{-1}}$.\n-   Task: Compute the expected offset between anomaly baselines, defined as the model anomaly baseline minus the observational anomaly baseline.\n-   The final answer must be in K and rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientifically Grounded?** Yes. The model $x(t) = \\alpha + \\beta t + \\varepsilon(t)$ is a standard, simplified model for a climate time series with a linear trend and natural variability. The concept of anomalies and reference periods is fundamental in climatology. The value of the trend $\\beta = 0.02 \\ \\mathrm{K/yr}$ (or $0.2 \\ \\mathrm{K/decade}$) is realistic for global mean temperature trends in recent decades. The problem is based on established statistical and climatological methods.\n\n2.  **Well-Posed?** Yes. The definitions are clear. The model is specified. The question asks for a specific calculation based on these definitions. The problem provides all necessary information (`β`, the two time intervals) to calculate a unique numerical answer.\n\n3.  **Objective?** Yes. The language is precise and technical. There are no subjective or opinion-based statements.\n\n4.  **Scientific or Factual Unsoundness?** No. The model is sound and widely used for first-order analysis. The definitions are standard.\n\n5.  **Non-Formalizable or Irrelevant?** No. The problem is formalizable using calculus and statistics. It is highly relevant to the topic of climate model evaluation.\n\n6.  **Incomplete or Contradictory Setup?** No. All data required for the calculation are provided. The definitions are consistent. The time intervals are clearly defined. A potential point of confusion could be the time units. The problem states `$t$` is in years, and the intervals are given in years. The trend `$\\beta$` is in `K/yr`. All consistent.\n\n7.  **Unrealistic or Infeasible?** No. The conditions and data are realistic.\n\n8.  **Ill-Posed or Poorly Structured?** No. A unique, stable, and meaningful solution exists. The term \"expected offset\" is well-defined in the context of the model given `E[ε(t)] = 0`.\n\n9.  **Pseudo-Profound, Trivial, or Tautological?** No. The problem requires a multi-step derivation and calculation. It tests the understanding of how baseline choices affect anomaly comparisons in the presence of a trend, which is a non-trivial issue in climate science.\n\n10. **Outside Scientific Verifiability?** No. The derivation and calculation are verifiable through standard mathematics.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. I will proceed with the solution.\n\n**Solution Plan:**\n\n**Part 1: Derivations**\n\n1.  Calculate the climatological mean $\\bar{x}_{[T_1,T_2]}$ by substituting $x(t) = \\alpha + \\beta t + \\varepsilon(t)$ into the integral definition.\n    $\\bar{x}_{[T_1,T_2]} = \\frac{1}{T_2 - T_1} \\int_{T_1}^{T_2} (\\alpha + \\beta t + \\varepsilon(t))\\,\\mathrm{d}t$\n2.  Separate the integral into three parts.\n    -   $\\int \\alpha \\,\\mathrm{d}t = \\alpha t$\n    -   $\\int \\beta t \\,\\mathrm{d}t = \\frac{1}{2}\\beta t^2$\n    -   $\\int \\varepsilon(t) \\,\\mathrm{d}t$\n3.  Evaluate the definite integrals for the deterministic parts.\n    -   $\\int_{T_1}^{T_2} \\alpha \\,\\mathrm{d}t = \\alpha (T_2 - T_1)$\n    -   $\\int_{T_1}^{T_2} \\beta t \\,\\mathrm{d}t = \\frac{1}{2}\\beta (T_2^2 - T_1^2) = \\frac{1}{2}\\beta (T_2 - T_1)(T_2 + T_1)$\n4.  Combine the terms to get an expression for $\\bar{x}_{[T_1,T_2]}$.\n    $\\bar{x}_{[T_1,T_2]} = \\alpha + \\beta \\frac{T_1+T_2}{2} + \\frac{1}{T_2-T_1}\\int_{T_1}^{T_2} \\varepsilon(t)\\,\\mathrm{d}t$.\n5.  This expression shows how the linear trend affects the mean. The trend term contributes $\\beta \\frac{T_1+T_2}{2}$, which is the value of the trend at the midpoint of the interval.\n6.  Now, find the difference between two climatological means: $\\bar{x}_{[T_1,T_2]} - \\bar{x}_{[S_1,S_2]}$.\n    $\\bar{x}_{[T_1,T_2]} - \\bar{x}_{[S_1,S_2]} = (\\alpha + \\beta \\frac{T_1+T_2}{2} + \\bar{\\varepsilon}_{[T_1,T_2]}) - (\\alpha + \\beta \\frac{S_1+S_2}{2} + \\bar{\\varepsilon}_{[S_1,S_2]})$\n    where $\\bar{\\varepsilon}_{[a,b]} = \\frac{1}{b-a}\\int_a^b \\varepsilon(t) \\,\\mathrm{d}t$.\n    This simplifies to:\n    $\\beta (\\frac{T_1+T_2}{2} - \\frac{S_1+S_2}{2}) + (\\bar{\\varepsilon}_{[T_1,T_2]} - \\bar{\\varepsilon}_{[S_1,S_2]})$.\n\n**Part 2: Application**\n\n1.  The problem asks for the *expected* offset implied *purely by the linear trend*. This means we need to take the expectation of the difference.\n    $\\mathbb{E}[\\bar{x}_{[T_1,T_2]} - \\bar{x}_{[S_1,S_2]}] = \\mathbb{E}[\\beta (\\frac{T_1+T_2}{2} - \\frac{S_1+S_2}{2}) + (\\bar{\\varepsilon}_{[T_1,T_2]} - \\bar{\\varepsilon}_{[S_1,S_2]})]$\n2.  Use the linearity of expectation:\n    $\\mathbb{E}[\\dots] = \\beta (\\frac{T_1+T_2}{2} - \\frac{S_1+S_2}{2}) + \\mathbb{E}[\\bar{\\varepsilon}_{[T_1,T_2]}] - \\mathbb{E}[\\bar{\\varepsilon}_{[S_1,S_2]}]$\n3.  Calculate the expectation of the averaged residual.\n    $\\mathbb{E}[\\bar{\\varepsilon}_{[a,b]}] = \\mathbb{E}[\\frac{1}{b-a}\\int_a^b \\varepsilon(t) \\,\\mathrm{d}t]$\n    By Fubini's theorem (or just linearity of expectation and integral), we can swap expectation and integration:\n    $\\mathbb{E}[\\bar{\\varepsilon}_{[a,b]}] = \\frac{1}{b-a}\\int_a^b \\mathbb{E}[\\varepsilon(t)] \\,\\mathrm{d}t$\n    Since $\\mathbb{E}[\\varepsilon(t)] = 0$ for all $t$:\n    $\\mathbb{E}[\\bar{\\varepsilon}_{[a,b]}] = \\frac{1}{b-a}\\int_a^b 0 \\,\\mathrm{d}t = 0$.\n4.  Therefore, the expected offset is purely due to the trend term:\n    $\\Delta = \\mathbb{E}[\\bar{x}_{[T_1,T_2]} - \\bar{x}_{[S_1,S_2]}] = \\beta (\\frac{T_1+T_2}{2} - \\frac{S_1+S_2}{2})$\n    This is the expected offset between the two climatological means (baselines).\n\n5.  Now, substitute the given values:\n    -   $[T_1, T_2] = [1981, 2010]$ (Model baseline)\n    -   $[S_1, S_2] = [1991, 2020]$ (Observational baseline)\n    -   $\\beta = 2.0 \\times 10^{-2}\\ \\mathrm{K\\,yr^{-1}}$\n\n6.  Calculate the midpoints of the intervals:\n    -   Midpoint of model baseline: $\\frac{T_1+T_2}{2} = \\frac{1981+2010}{2} = \\frac{3991}{2} = 1995.5$\n    -   Midpoint of observational baseline: $\\frac{S_1+S_2}{2} = \\frac{1991+2020}{2} = \\frac{4011}{2} = 2005.5$\n\n7.  Calculate the difference in midpoints:\n    $\\frac{T_1+T_2}{2} - \\frac{S_1+S_2}{2} = 1995.5 - 2005.5 = -10.0$ years.\n\n8.  Calculate the final offset $\\Delta$:\n    $\\Delta = \\beta \\times (-10.0 \\ \\mathrm{yr})$\n    $\\Delta = (2.0 \\times 10^{-2}\\ \\mathrm{K\\,yr^{-1}}) \\times (-10.0 \\ \\mathrm{yr})$\n    $\\Delta = -20.0 \\times 10^{-2}\\ \\mathrm{K}$\n    $\\Delta = -0.20\\ \\mathrm{K}$.\n\n9.  Rounding: The problem asks for the answer to be rounded to four significant figures.\n    $-0.20$ is two significant figures. The given `β` has two significant figures (`2.0`). The time difference `-10.0` has three. The result of a multiplication should have the same number of significant figures as the least precise measurement, which is two.\n    Let me re-read the rounding instruction: \"round your answer to four significant figures\". This is a direct instruction, so I must follow it, even if standard sig-fig rules suggest otherwise.\n    So, `-0.20` becomes `-0.2000`.\n\nLet me double check the calculation.\n$T_1 = 1981, T_2 = 2010$ -> Midpoint = $1995.5$\n$S_1 = 1991, S_2 = 2020$ -> Midpoint = $2005.5$\nDifference of midpoints = $1995.5 - 2005.5 = -10$ years.\n$\\beta = 0.02 \\ \\mathrm{K/yr}$.\nOffset = $0.02 \\times (-10) = -0.2 \\ \\mathrm{K}$.\nYes, the calculation is correct. The requirement for four significant figures means I should write the answer as $-0.2000$.\n\nThe question asks for \"model anomaly baseline minus the observational anomaly baseline\".\nThe model anomaly is $a_{model}(t) = x(t) - \\bar{x}_{[T_1, T_2]}$. The baseline is $\\bar{x}_{[T_1, T_2]}$.\nThe observational anomaly is $a_{obs}(t) = x(t) - \\bar{x}_{[S_1, S_2]}$. The baseline is $\\bar{x}_{[S_1, S_2]}$.\nThe difference is $\\bar{x}_{[T_1, T_2]} - \\bar{x}_{[S_1, S_2]}$. The problem asks for the *expected* offset, so my calculation of $\\mathbb{E}[\\bar{x}_{[T_1,T_2]} - \\bar{x}_{[S_1,S_2]}]$ is what is required.\nEverything looks good.",
            "answer": "$$\\boxed{-0.2000}$$"
        },
        {
            "introduction": "With a properly defined climatological baseline, we can then ask a fundamental question: does our sophisticated climate model provide more valuable information than a simple forecast based on long-term averages? This practice  introduces a powerful tool for answering this question: the skill score. You will derive the Brier Score, a classic metric for evaluating probabilistic forecasts, and use it to construct the Brier Skill Score ($BSS$), which quantifies the model's performance improvement relative to climatology. This exercise provides a concrete method for demonstrating the added value of a predictive model.",
            "id": "4022369",
            "problem": "Consider the binary event forecast-verification context in which each outcome is represented by an indicator variable $o \\in \\{0,1\\}$, and a probabilistic forecast assigns a value $p \\in [0,1]$ interpreted as the forecast probability that the event occurs. Suppose events are independent and identically distributed conditional on the true event probability, and let the fundamental definition of a proper scoring rule be that the expected score is minimized when the forecast probability equals the true event probability. Starting from this definition, and taking the squared deviation between the forecast probability and the realized outcome as the elementary penalty, derive the empirical score for a sample of $N$ forecasts and outcomes. Then, using this score, define a skill score relative to a constant reference forecast based on climatology.\n\nYou are given a scientifically realistic validation set for winter daily precipitation occurrence in a mid-latitude maritime region, where the long-term climatological probability of a wet day (precipitation at least $1\\,\\text{mm}$) is $p_{\\text{clim}} = 0.6$. A seasonal climate prediction system produces probabilistic forecasts $p_i$ for $N=15$ randomly sampled winter days, and observations $o_i$ record whether a wet day occurred ($o_i=1$) or not ($o_i=0$). The data are:\n- $i=1$: $p_1 = 0.75$, $o_1 = 1$\n- $i=2$: $p_2 = 0.20$, $o_2 = 0$\n- $i=3$: $p_3 = 0.65$, $o_3 = 1$\n- $i=4$: $p_4 = 0.70$, $o_4 = 1$\n- $i=5$: $p_5 = 0.35$, $o_5 = 0$\n- $i=6$: $p_6 = 0.80$, $o_6 = 1$\n- $i=7$: $p_7 = 0.40$, $o_7 = 0$\n- $i=8$: $p_8 = 0.55$, $o_8 = 1$\n- $i=9$: $p_9 = 0.60$, $o_9 = 1$\n- $i=10$: $p_{10} = 0.25$, $o_{10} = 0$\n- $i=11$: $p_{11} = 0.70$, $o_{11} = 1$\n- $i=12$: $p_{12} = 0.30$, $o_{12} = 0$\n- $i=13$: $p_{13} = 0.85$, $o_{13} = 1$\n- $i=14$: $p_{14} = 0.60$, $o_{14} = 1$\n- $i=15$: $p_{15} = 0.45$, $o_{15} = 0$\n\nUsing your derived empirical score for the model and for the constant climatology forecast $p_{\\text{clim}}$, compute the skill score relative to climatology. Express the final skill score as a dimensionless number and round your answer to four significant figures.",
            "solution": "The user wants me to solve the problem by first doing a validation and then providing the solution.\n\n### Step 1: Extract Givens\n- Context: Binary event forecast-verification.\n- Outcome variable: $o \\in \\{0,1\\}$.\n- Probabilistic forecast: $p \\in [0,1]$.\n- Assumption: Events are independent and identically distributed conditional on the true event probability.\n- Definition: A proper scoring rule's expected score is minimized when the forecast probability equals the true event probability.\n- Elementary penalty: Squared deviation between forecast probability and realized outcome, i.e., $(p-o)^2$.\n- Task 1: Derive the empirical score for a sample of $N$ forecasts and outcomes.\n- Task 2: Define a skill score relative to a constant reference forecast based on climatology.\n- Data:\n    - Long-term climatological probability: $p_{\\text{clim}} = 0.6$.\n    - Sample size: $N=15$.\n    - Forecast-observation pairs $(p_i, o_i)$:\n        - $i=1$: $(0.75, 1)$\n        - $i=2$: $(0.20, 0)$\n        - $i=3$: $(0.65, 1)$\n        - $i=4$: $(0.70, 1)$\n        - $i=5$: $(0.35, 0)$\n        - $i=6$: $(0.80, 1)$\n        - $i=7$: $(0.40, 0)$\n        - $i=8$: $(0.55, 1)$\n        - $i=9$: $(0.60, 1)$\n        - $i=10$: $(0.25, 0)$\n        - $i=11$: $(0.70, 1)$\n        - $i=12$: $(0.30, 0)$\n        - $i=13$: $(0.85, 1)$\n        - $i=14$: $(0.60, 1)$\n        - $i=15$: $(0.45, 0)$\n- Task 3: Compute the skill score relative to climatology.\n- Output requirement: Round the final dimensionless number to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the established field of forecast verification. The score to be derived, the Brier Score, is a fundamental proper scoring rule. The use of a skill score relative to a climatological reference is standard practice in meteorology and climate science. The problem is well-posed, providing all necessary definitions and data for a unique solution. The language is objective and precise. The problem does not violate any of the invalidity criteria.\n1.  **Scientific or Factual Unsoundness**: None.\n2.  **Non-Formalizable or Irrelevant**: None.\n3.  **Incomplete or Contradictory Setup**: None.\n4.  **Unrealistic or Infeasible**: None. The data are physically plausible.\n5.  **Ill-Posed or Poorly Structured**: None.\n6.  **Pseudo-Profound, Trivial, or Tautological**: None.\n7.  **Outside Scientific Verifiability**: None.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full, reasoned solution will be provided.\n\nThe problem asks for the derivation of an empirical score, the definition of a related skill score, and its computation for a given dataset.\n\nFirst, we derive the scoring rule. Let the true probability of an event occurring ($O=1$) be $\\pi$, so $P(O=1) = \\pi$ and $P(O=0) = 1-\\pi$. The forecaster provides a probability $p$. The elementary penalty is the squared deviation between the forecast $p$ and the outcome $o$, which is $(p-o)^2$. The score $S(p,o)$ is this penalty. A scoring rule is proper if the expected score, $E[S(p,O)]$, is minimized when the forecast probability $p$ is equal to the true probability $\\pi$. The expectation is taken over the distribution of the outcome $O$.\n\nThe expected score is:\n$$E[S(p,O)] = P(O=1) \\cdot S(p,1) + P(O=0) \\cdot S(p,0)$$\n$$E[S(p,O)] = \\pi (p-1)^2 + (1-\\pi) (p-0)^2 = \\pi (p-1)^2 + (1-\\pi) p^2$$\nTo find the value of $p$ that minimizes this expectation, we take the derivative with respect to $p$ and set it to $0$:\n$$\\frac{d}{dp} E[S(p,O)] = \\frac{d}{dp} \\left[ \\pi(p^2 - 2p + 1) + (1-\\pi)p^2 \\right]$$\n$$\\frac{d}{dp} E[S(p,O)] = \\pi(2p - 2) + (1-\\pi)(2p) = 2\\pi p - 2\\pi + 2p - 2\\pi p = 2p - 2\\pi$$\nSetting the derivative to zero gives $2p - 2\\pi = 0$, which implies $p = \\pi$. The second derivative is $\\frac{d^2}{dp^2} E[S(p,O)] = 2$, which is positive, confirming that $p=\\pi$ is a minimum. Thus, the score based on the squared deviation is a proper scoring rule. This score is known as the Brier Score.\n\nThe empirical score for a sample of $N$ forecast-outcome pairs $\\{(p_i, o_i)\\}_{i=1}^N$ is the average of the elementary penalties over the sample. This is the sample Brier Score, denoted $BS$:\n$$BS = \\frac{1}{N} \\sum_{i=1}^N (p_i - o_i)^2$$\nThis is the derived empirical score.\n\nNext, we define a skill score. A skill score, $SS$, measures the improvement of a forecast over a reference forecast. For a negatively-oriented score like $BS$ (where lower is better) and where a perfect score is $0$, the skill score is defined as:\n$$SS = 1 - \\frac{BS_{\\text{model}}}{BS_{\\text{ref}}}$$\nHere, $BS_{\\text{model}}$ is the Brier Score of the forecast system being evaluated, and $BS_{\\text{ref}}$ is the Brier Score of the reference forecast. A skill score of $1$ indicates a perfect forecast, $0$ indicates no skill relative to the reference, and negative values indicate the forecast is worse than the reference.\n\nIn this problem, the model's Brier Score is:\n$$BS_{\\text{model}} = \\frac{1}{N} \\sum_{i=1}^N (p_i - o_i)^2$$\nThe reference forecast is the constant climatological probability, $p_i = p_{\\text{clim}}$ for all $i$. So, the reference Brier Score is:\n$$BS_{\\text{ref}} = \\frac{1}{N} \\sum_{i=1}^N (p_{\\text{clim}} - o_i)^2$$\nThe resulting skill score is the Brier Skill Score ($BSS$):\n$$BSS = 1 - \\frac{\\frac{1}{N} \\sum_{i=1}^N (p_i - o_i)^2}{\\frac{1}{N} \\sum_{i=1}^N (p_{\\text{clim}} - o_i)^2} = 1 - \\frac{\\sum_{i=1}^N (p_i - o_i)^2}{\\sum_{i=1}^N (p_{\\text{clim}} - o_i)^2}$$\n\nNow, we compute the $BSS$ for the given data. We have $N=15$ and $p_{\\text{clim}} = 0.6$.\nFirst, we calculate the sum of squared errors for the model forecast, $\\sum (p_i - o_i)^2$:\n- $(0.75-1)^2 = (-0.25)^2 = 0.0625$\n- $(0.20-0)^2 = (0.20)^2 = 0.0400$\n- $(0.65-1)^2 = (-0.35)^2 = 0.1225$\n- $(0.70-1)^2 = (-0.30)^2 = 0.0900$\n- $(0.35-0)^2 = (0.35)^2 = 0.1225$\n- $(0.80-1)^2 = (-0.20)^2 = 0.0400$\n- $(0.40-0)^2 = (0.40)^2 = 0.1600$\n- $(0.55-1)^2 = (-0.45)^2 = 0.2025$\n- $(0.60-1)^2 = (-0.40)^2 = 0.1600$\n- $(0.25-0)^2 = (0.25)^2 = 0.0625$\n- $(0.70-1)^2 = (-0.30)^2 = 0.0900$\n- $(0.30-0)^2 = (0.30)^2 = 0.0900$\n- $(0.85-1)^2 = (-0.15)^2 = 0.0225$\n- $(0.60-1)^2 = (-0.40)^2 = 0.1600$\n- $(0.45-0)^2 = (0.45)^2 = 0.2025$\nSumming these values:\n$$\\sum_{i=1}^{15} (p_i - o_i)^2 = 1.6275$$\nSo, $BS_{\\text{model}} = \\frac{1.6275}{15} = 0.1085$.\n\nNext, we calculate the sum of squared errors for the reference climatological forecast, $\\sum (p_{\\text{clim}} - o_i)^2$.\nFirst, we count the number of occurrences ($o_i=1$) and non-occurrences ($o_i=0$) in the sample.\nThe indices where $o_i=1$ are $1, 3, 4, 6, 8, 9, 11, 13, 14$. The number of occurrences is $N_1 = 9$.\nThe indices where $o_i=0$ are $2, 5, 7, 10, 12, 15$. The number of non-occurrences is $N_0 = 6$.\nThe total sample size is $N = N_1 + N_0 = 9 + 6 = 15$.\nThe sum of squared errors for the reference forecast is:\n$$\\sum_{i=1}^{15} (p_{\\text{clim}} - o_i)^2 = N_1 (p_{\\text{clim}}-1)^2 + N_0 (p_{\\text{clim}}-0)^2$$\nSubstituting the values $N_1=9$, $N_0=6$, and $p_{\\text{clim}} = 0.6$:\n$$\\sum_{i=1}^{15} (0.6 - o_i)^2 = 9 \\cdot (0.6 - 1)^2 + 6 \\cdot (0.6 - 0)^2$$\n$$= 9 \\cdot (-0.4)^2 + 6 \\cdot (0.6)^2$$\n$$= 9 \\cdot (0.16) + 6 \\cdot (0.36)$$\n$$= 1.44 + 2.16 = 3.6$$\nSo, $BS_{\\text{ref}} = \\frac{3.6}{15} = 0.24$.\n\nFinally, we compute the Brier Skill Score:\n$$BSS = 1 - \\frac{\\sum (p_i - o_i)^2}{\\sum (p_{\\text{clim}} - o_i)^2} = 1 - \\frac{1.6275}{3.6}$$\n$$BSS = 1 - 0.45208333...$$\n$$BSS = 0.54791666...$$\nRounding to four significant figures, we get $0.5479$.\nThe positive value indicates that the model has more skill than a simple climatological forecast for this sample.",
            "answer": "$$\\boxed{0.5479}$$"
        },
        {
            "introduction": "The final step in a robust evaluation is to assess the statistical significance of our findings. When we calculate a mean model bias, for example, we must determine if it represents a true systematic error or could simply be due to random chance. This task is complicated by the fact that climate time series are rarely independent; today's weather is related to yesterday's. This practice  delves into the critical concept of temporal autocorrelation and its effect on uncertainty, guiding you through the derivation of the \"effective sample size.\" Mastering this concept is essential for constructing accurate confidence intervals and avoiding overconfident conclusions about model performance.",
            "id": "4022313",
            "problem": "A climate model is evaluated against a reference observational climatology by forming a monthly anomaly time series of model-minus-observed differences, denoted by $\\{X_{t}\\}_{t=1}^{N}$. Assume $X_{t} = \\mu + \\varepsilon_{t}$ where $\\mu$ is a constant mean bias and the residual process $\\{\\varepsilon_{t}\\}$ is weakly stationary and follows a first-order AutoRegressive (AR) process with coefficient $\\phi$, that is, $\\varepsilon_{t} = \\phi\\,\\varepsilon_{t-1} + w_{t}$, where $\\{w_{t}\\}$ is zero-mean white noise with finite variance. Let $\\rho(k)$ denote the autocorrelation function of $\\{\\varepsilon_{t}\\}$ at lag $k$.\n\n1) Starting from the definition of the sample mean $\\bar{X}_{N} = \\frac{1}{N}\\sum_{t=1}^{N} X_{t}$ and the identity $\\operatorname{Var}(\\bar{X}_{N}) = \\frac{1}{N^{2}}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\operatorname{Cov}(X_{i},X_{j})$, derive, under the large-$N$ approximation appropriate for weakly stationary AR(1) residuals, a closed-form expression for an effective sample size $n_{\\text{eff}}$ such that $\\operatorname{Var}(\\bar{X}_{N}) \\approx \\sigma^{2}/n_{\\text{eff}}$, where $\\sigma^{2} = \\operatorname{Var}(\\varepsilon_{t})$, expressed only in terms of $N$ and the lag-$1$ autocorrelation $\\rho(1)$.\n\n2) Explain how $n_{\\text{eff}}$ modifies the standard error used to construct a two-sided confidence interval for the mean climatology difference $\\mu$ and why this modification is necessary when residuals are temporally correlated.\n\n3) Now consider a practical evaluation with $N=480$ monthly anomalies, an estimated lag-$1$ autocorrelation $\\rho(1)=0.50$, and a sample residual variance $s^{2} = 2.25$ in units of kelvin squared. Using the effective sample size you derived and the large-sample Gaussian critical value for a two-sided confidence interval with nominal coverage $0.95$, compute the half-width of the confidence interval for $\\mu$. Express the final half-width in kelvin and round your answer to three significant figures.",
            "solution": "The problem is valid as it is scientifically grounded in time series analysis, well-posed with clear objectives and sufficient information, and uses standard, objective terminology from statistics and climate science.\n\nThe problem is addressed in three parts: 1) derivation of the effective sample size $n_{\\text{eff}}$, 2) explanation of its use in constructing confidence intervals, and 3) a numerical calculation of a confidence interval half-width.\n\n1) Derivation of the effective sample size $n_{\\text{eff}}$\n\nWe are given a time series $X_{t} = \\mu + \\varepsilon_{t}$, where $\\mu$ is a constant and $\\{\\varepsilon_{t}\\}$ is a weakly stationary AR(1) process. The sample mean is $\\bar{X}_{N} = \\frac{1}{N}\\sum_{t=1}^{N} X_{t}$. The variance of the sample mean is given by the identity:\n$$ \\operatorname{Var}(\\bar{X}_{N}) = \\frac{1}{N^{2}}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\operatorname{Cov}(X_{i},X_{j}) $$\nSince $\\mu$ is a constant, the covariance is determined entirely by the residual process:\n$$ \\operatorname{Cov}(X_{i},X_{j}) = \\operatorname{Cov}(\\mu + \\varepsilon_{i}, \\mu + \\varepsilon_{j}) = \\operatorname{Cov}(\\varepsilon_{i},\\varepsilon_{j}) $$\nFor a weakly stationary process, the autocovariance depends only on the time lag $k = i-j$. Let $\\gamma(k) = \\operatorname{Cov}(\\varepsilon_{i},\\varepsilon_{j})$ where $k = i-j$. The variance of the process is $\\sigma^2 = \\operatorname{Var}(\\varepsilon_t) = \\gamma(0)$. The autocorrelation function is $\\rho(k) = \\gamma(k)/\\gamma(0)$.\n\nSubstituting the autocovariance into the variance expression:\n$$ \\operatorname{Var}(\\bar{X}_{N}) = \\frac{1}{N^{2}}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\gamma(i-j) $$\nThe double summation can be re-indexed by the lag $k = i-j$. The lag $k$ ranges from $-(N-1)$ to $N-1$. For any given lag $k$, there are $N-|k|$ pairs of $(i,j)$ in the sum. Thus, we can write:\n$$ \\sum_{i=1}^{N}\\sum_{j=1}^{N}\\gamma(i-j) = \\sum_{k=-(N-1)}^{N-1} (N-|k|)\\gamma(k) $$\nSince $\\{\\varepsilon_{t}\\}$ is stationary, its autocovariance function is symmetric, i.e., $\\gamma(k) = \\gamma(-k)$. We can split the sum:\n$$ \\sum_{k=-(N-1)}^{N-1} (N-|k|)\\gamma(k) = (N-0)\\gamma(0) + \\sum_{k=1}^{N-1}(N-k)\\gamma(k) + \\sum_{k=-(N-1)}^{-1}(N-|k|)\\gamma(k) $$\n$$ = N\\gamma(0) + 2\\sum_{k=1}^{N-1}(N-k)\\gamma(k) $$\nSubstituting this back into the expression for $\\operatorname{Var}(\\bar{X}_{N})$:\n$$ \\operatorname{Var}(\\bar{X}_{N}) = \\frac{1}{N^2}\\left[ N\\gamma(0) + 2\\sum_{k=1}^{N-1}(N-k)\\gamma(k) \\right] = \\frac{\\gamma(0)}{N}\\left[ 1 + 2\\sum_{k=1}^{N-1}\\left(1 - \\frac{k}{N}\\right)\\frac{\\gamma(k)}{\\gamma(0)} \\right] $$\nUsing the definitions $\\sigma^2 = \\gamma(0)$ and $\\rho(k) = \\gamma(k)/\\gamma(0)$, we get the exact expression:\n$$ \\operatorname{Var}(\\bar{X}_{N}) = \\frac{\\sigma^2}{N}\\left[ 1 + 2\\sum_{k=1}^{N-1}\\left(1 - \\frac{k}{N}\\right)\\rho(k) \\right] $$\nThe problem asks for an approximation for large $N$. For large $N$, the term $(1 - k/N) \\approx 1$ for values of $k$ where $\\rho(k)$ is significantly different from zero, as $\\rho(k) \\to 0$ for large $k$ in a stationary process. Also, the sum can be extended to infinity as the additional terms are negligible.\n$$ \\operatorname{Var}(\\bar{X}_{N}) \\approx \\frac{\\sigma^2}{N}\\left[ 1 + 2\\sum_{k=1}^{\\infty}\\rho(k) \\right] $$\nFor the specified AR(1) process, $\\varepsilon_{t} = \\phi\\,\\varepsilon_{t-1} + w_{t}$, the autocorrelation function is $\\rho(k) = \\phi^{|k|}$. Substituting this into the approximation:\n$$ \\operatorname{Var}(\\barX_N) \\approx \\frac{\\sigma^2}{N} \\left[ 1 + 2\\sum_{k=1}^{\\infty}\\phi^k \\right] $$\nThe infinite sum is a standard geometric series, which converges for $|\\phi|<1$ (a condition for stationarity):\n$$ \\sum_{k=1}^{\\infty}\\phi^k = \\frac{\\phi}{1-\\phi} $$\nSubstituting the sum back into the variance expression:\n$$ \\operatorname{Var}(\\barX_N) \\approx \\frac{\\sigma^2}{N} \\left[ 1 + 2\\frac{\\phi}{1-\\phi} \\right] = \\frac{\\sigma^2}{N} \\left[ \\frac{1-\\phi+2\\phi}{1-\\phi} \\right] = \\frac{\\sigma^2}{N} \\left( \\frac{1+\\phi}{1-\\phi} \\right) $$\nWe are asked to find the effective sample size $n_{\\text{eff}}$ such that $\\operatorname{Var}(\\bar{X}_{N}) \\approx \\sigma^{2}/n_{\\text{eff}}$. Equating the two expressions for the variance:\n$$ \\frac{\\sigma^{2}}{n_{\\text{eff}}} = \\frac{\\sigma^{2}}{N} \\left( \\frac{1+\\phi}{1-\\phi} \\right) $$\nSolving for $n_{\\text{eff}}$ yields:\n$$ n_{\\text{eff}} = N \\left( \\frac{1-\\phi}{1+\\phi} \\right) $$\nFor an AR(1) process, the lag-$1$ autocorrelation is $\\rho(1) = \\phi$. Therefore, the expression in terms of $N$ and $\\rho(1)$ is:\n$$ n_{\\text{eff}} = N \\left( \\frac{1-\\rho(1)}{1+\\rho(1)} \\right) $$\n\n2) Modification of the standard error for confidence intervals\n\nThe standard error of the mean, $\\text{SE}(\\bar{X}_N)$, is the standard deviation of the sampling distribution of the sample mean, i.e., $\\text{SE}(\\bar{X}_N) = \\sqrt{\\operatorname{Var}(\\bar{X}_N)}$. For a sample of $N$ independent and identically distributed (i.i.d.) observations with variance $\\sigma^2$, the variance of the mean is $\\operatorname'Var}(\\bar{X}_N) = \\sigma^2/N$, and the standard error is $\\sigma/\\sqrt{N}$. A two-sided $100(1-\\alpha)\\%$ confidence interval for the mean $\\mu$ is constructed as $\\bar{X}_N \\pm z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{N}}$, where $z_{\\alpha/2}$ is the critical value from the standard normal distribution.\n\nHowever, when observations are temporally correlated, as in this problem, the i.i.d. assumption is violated, and $\\operatorname{Var}(\\bar{X}_N)$ is no longer $\\sigma^2/N$. As derived in part 1), the variance is approximately $\\frac{\\sigma^2}{N} \\left( \\frac{1+\\rho(1)}{1-\\rho(1)} \\right)$. The effective sample size, $n_{\\text{eff}} = N \\left( \\frac{1-\\rho(1)}{1+\\rho(1)} \\right)$, is a conceptual tool that quantifies the number of independent observations that would provide the same amount of information about the mean as the $N$ correlated observations.\n\nThe standard error is therefore modified by replacing $N$ with $n_{\\text{eff}}$:\n$$ \\text{SE}(\\bar{X}_N) = \\sqrt{\\operatorname{Var}(\\bar{X}_N)} \\approx \\sqrt{\\frac{\\sigma^2}{n_{\\text{eff}}}} = \\frac{\\sigma}{\\sqrt{n_{\\text{eff}}}} $$\nThe confidence interval for $\\mu$ is then correctly constructed as $\\bar{X}_N \\pm z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n_{\\text{eff}}}}$.\n\nThis modification is necessary because temporal correlation affects the amount of independent information in the sample. For geophysical time series, positive autocorrelation ($\\rho(1) > 0$) is common. In this case, $(1-\\rho(1))/(1+\\rho(1)) < 1$, which means $n_{\\text{eff}} < N$. This reflects the fact that each successive data point is partially predictable from the previous one, carrying redundant information. The true uncertainty in the sample mean is therefore larger than would be suggested by the nominal sample size $N$. Ignoring this effect and using $N$ instead of $n_{\\text{eff}}$ would lead to an underestimation of the standard error. This would result in a confidence interval that is deceptively narrow, implying false precision and leading to an actual coverage probability lower than the nominal level (e.g., less than $95\\%$). This increases the rate of Type I errors (false positives) in hypothesis testing, for example, incorrectly concluding that a model has a statistically significant bias ($\\mu \\neq 0$) when it does not.\n\n3) Calculation of the confidence interval half-width\n\nWe are given the following values for a practical evaluation:\n- Sample size: $N=480$\n- Estimated lag-$1$ autocorrelation: $\\rho(1)=0.50$\n- Sample residual variance: $s^{2} = 2.25 \\, \\text{K}^2$ (we use $s^2$ as an estimate for $\\sigma^2$)\n- Nominal coverage: $0.95$\n\nFirst, we compute the effective sample size $n_{\\text{eff}}$ using the formula from part 1):\n$$ n_{\\text{eff}} = N \\left( \\frac{1-\\rho(1)}{1+\\rho(1)} \\right) = 480 \\left( \\frac{1-0.50}{1+0.50} \\right) = 480 \\left( \\frac{0.50}{1.50} \\right) = 480 \\times \\frac{1}{3} = 160 $$\nThe effective sample size is $160$, which is significantly smaller than the nominal sample size of $480$.\n\nNext, we calculate the estimated standard error of the mean, $\\text{SE}(\\bar{X}_N)$, using $n_{\\text{eff}}$ and the sample variance $s^2$:\n$$ \\text{SE}(\\bar{X}_N) \\approx \\sqrt{\\frac{s^2}{n_{\\text{eff}}}} = \\sqrt{\\frac{2.25}{160}} \\, \\text{K} $$\nThe half-width (HW) of a two-sided confidence interval is given by the product of the appropriate critical value and the standard error. For a large sample and a $0.95$ nominal coverage, the critical value $z_{\\alpha/2} = z_{0.025}$ from the standard normal distribution is $1.96$.\n$$ \\text{HW} = z_{0.025} \\times \\text{SE}(\\bar{X}_N) = 1.96 \\times \\sqrt{\\frac{2.25}{160}} \\, \\text{K} $$\nNow, we compute the numerical value:\n$$ \\text{HW} = 1.96 \\times \\frac{\\sqrt{2.25}}{\\sqrt{160}} = 1.96 \\times \\frac{1.5}{\\sqrt{160}} \\approx 1.96 \\times \\frac{1.5}{12.6491} \\approx 1.96 \\times 0.118585 \\, \\text{K} $$\n$$ \\text{HW} \\approx 0.232427 \\, \\text{K} $$\nThe problem requires the answer to be rounded to three significant figures.\n$$ \\text{HW} \\approx 0.232 \\, \\text{K} $$",
            "answer": "$$ \\boxed{0.232} $$"
        }
    ]
}