{
    "hands_on_practices": [
        {
            "introduction": "在不确定性量化中，第一步通常是理解模型的输出对参数微小变化的响应程度。局部敏感性分析通过计算模型输出关于其参数的梯度来提供这种洞察力，这本质上是模型响应的一阶泰勒近似。这项练习将帮助您掌握计算局部敏感性的基本技能，并理解参数缩放在模型调优中的实际影响，这是在复杂方案（如对流参数化）中一个至关重要的考虑因素。",
            "id": "4107171",
            "problem": "一个数值天气预报（NWP）模型中的对流参数化方案，使用一个简化的、局域无量纲的诊断成本函数 $y(\\theta_{1},\\theta_{2})$ 进行调优。该函数聚合了归一化平均对流降水偏差和羽流能量学不匹配。设诊断量为 $y=\\theta_{1}^{2}+\\theta_{2}$，其中 $(\\theta_{1},\\theta_{2})$ 是无量纲控制参数，通过已知尺度 $(s_{1},s_{2})$ 对物理参数 $(p_{1},p_{2})$ 进行无量纲化得到，即 $\\theta_{i}=p_{i}/s_{i}$，$i\\in\\{1,2\\}$。假设 $y$ 是无量纲且可微的，并且小扰动通过与不确定性量化和扰动参数集合中的局域方法一致的一阶泰勒线性化来解释。\n\n从偏导数的基本定义和一阶泰勒线性化出发，计算在 $\\theta=(1,2)$ 处的局域敏感性向量 $\\nabla_{\\theta}y$，并表示为行向量。然后，使用链式法则，讨论相对于有量纲参数 $(p_{1},p_{2})$ 的敏感性如何依赖于 $(s_{1},s_{2})$，并解释这些有量纲敏感性的单位以及参数缩放在对流方案调优中的意义。你必须给出在 $\\theta=(1,2)$ 处求值的、相对于 $(\\theta_{1},\\theta_{2})$ 的局域敏感性向量的数值；无需四舍五入。请使用行矩阵表示你的最终敏感性向量答案。",
            "solution": "问题陈述已经过验证，被认为是有效的。它具有科学依据、是适定且客观的。它在参数敏感性分析（数值模拟和不确定性量化中的一个基本课题）的背景下，提出了一个清晰、可解的问题。所有必要的定义和数据都已提供，不存在内部矛盾或歧义。\n\n该问题要求计算一个局域敏感性向量，并随后讨论一个相关的变量变换。我们从第一部分开始。\n\n诊断成本函数给定为 $y(\\theta_{1}, \\theta_{2}) = \\theta_{1}^{2} + \\theta_{2}$，其中 $\\theta_{1}$ 和 $\\theta_{2}$ 是无量綱控制参数。成本函数 $y$ 对这些参数的局域敏感性由 $y$ 的梯度来量化，记为 $\\nabla_{\\theta}y$。梯度是一个向量，其分量是函数关于其各个变量的偏导数。对于两个变量的标量函数，它定义为：\n$$\n\\nabla_{\\theta}y = \\begin{pmatrix} \\frac{\\partial y}{\\partial \\theta_{1}}  \\frac{\\partial y}{\\partial \\theta_{2}} \\end{pmatrix}\n$$\n问题要求将其表示为行向量，这是标量场梯度的一种常见约定。\n\n首先，我们计算 $y$ 相对于 $\\theta_{1}$ 和 $\\theta_{2}$ 的偏导数：\n相对于 $\\theta_{1}$ 的偏导数是：\n$$\n\\frac{\\partial y}{\\partial \\theta_{1}} = \\frac{\\partial}{\\partial \\theta_{1}} (\\theta_{1}^{2} + \\theta_{2}) = 2\\theta_{1}\n$$\n相对于 $\\theta_{2}$ 的偏导数是：\n$$\n\\frac{\\partial y}{\\partial \\theta_{2}} = \\frac{\\partial}{\\partial \\theta_{2}} (\\theta_{1}^{2} + \\theta_{2}) = 1\n$$\n因此，作为 $\\theta = (\\theta_{1}, \\theta_{2})$ 函数的敏感性向量是：\n$$\n\\nabla_{\\theta}y(\\theta_{1}, \\theta_{2}) = \\begin{pmatrix} 2\\theta_{1}  1 \\end{pmatrix}\n$$\n问题要求在特定点 $\\theta = (1, 2)$ 处计算此向量。我们将 $\\theta_{1} = 1$ 和 $\\theta_{2} = 2$ 代入梯度的表达式中：\n$$\n\\nabla_{\\theta}y(1, 2) = \\begin{pmatrix} 2(1)  1 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\end{pmatrix}\n$$\n这个数值向量表示在指定点上，成本函数对无量纲参数扰动的局域敏感性。在该点，$\\theta_{1}$ 的变化对 $y$ 的影响是相同幅度 $\\theta_{2}$ 变化的两倍。该向量是 $y$ 变化量的一阶泰勒线性化，即对于小扰动 $(\\delta\\theta_{1}, \\delta\\theta_{2})$，$y$ 的变化近似为 $\\delta y \\approx 2\\delta\\theta_{1} + 1\\delta\\theta_{2}$。\n\n接下来，我们处理问题的第二部分：关于无量纲参数 $(\\theta_{1}, \\theta_{2})$ 的敏感性与关于有量纲物理参数 $(p_{1}, p_{2})$ 的敏感性之间的关系。这些参数通过缩放关系 $\\theta_{i} = p_{i}/s_{i}$（$i \\in \\{1, 2\\}$）相关联，其中 $(s_1, s_2)$ 是已知的恒定缩放因子。\n\n为了求出 $y$ 相对于 $(p_{1}, p_{2})$ 的敏感性，我们必须应用多变量函数的链式法则。函数 $y$ 是一个复合函数，$y(p_{1}, p_{2}) = y(\\theta_{1}(p_{1}), \\theta_{2}(p_{2}))$。$y$ 相对于 $p_{1}$ 的偏导数是：\n$$\n\\frac{\\partial y}{\\partial p_{1}} = \\frac{\\partial y}{\\partial \\theta_{1}} \\frac{\\partial \\theta_{1}}{\\partial p_{1}} + \\frac{\\partial y}{\\partial \\theta_{2}} \\frac{\\partial \\theta_{2}}{\\partial p_{1}}\n$$\n类似地，$y$ 相对于 $p_{2}$ 的偏导数是：\n$$\n\\frac{\\partial y}{\\partial p_{2}} = \\frac{\\partial y}{\\partial \\theta_{1}} \\frac{\\partial \\theta_{1}}{\\partial p_{2}} + \\frac{\\partial y}{\\partial \\theta_{2}} \\frac{\\partial \\theta_{2}}{\\partial p_{2}}\n$$\n我们计算缩放关系的导数：\n$$\n\\frac{\\partial \\theta_{1}}{\\partial p_{1}} = \\frac{\\partial}{\\partial p_{1}}\\left(\\frac{p_{1}}{s_{1}}\\right) = \\frac{1}{s_{1}}\n$$\n$$\n\\frac{\\partial \\theta_{2}}{\\partial p_{2}} = \\frac{\\partial}{\\partial p_{2}}\\left(\\frac{p_{2}}{s_{2}}\\right) = \\frac{1}{s_{2}}\n$$\n由于 $\\theta_{1}$ 独立于 $p_{2}$，$\\theta_{2}$ 独立于 $p_{1}$，我们有：\n$$\n\\frac{\\partial \\theta_{1}}{\\partial p_{2}} = 0 \\quad \\text{和} \\quad \\frac{\\partial \\theta_{2}}{\\partial p_{1}} = 0\n$$\n将这些代入链式法则表达式中得出：\n$$\n\\frac{\\partial y}{\\partial p_{1}} = \\frac{\\partial y}{\\partial \\theta_{1}} \\left(\\frac{1}{s_{1}}\\right) + \\frac{\\partial y}{\\partial \\theta_{2}} (0) = \\frac{1}{s_{1}} \\frac{\\partial y}{\\partial \\theta_{1}}\n$$\n$$\n\\frac{\\partial y}{\\partial p_{2}} = \\frac{\\partial y}{\\partial \\theta_{1}} (0) + \\frac{\\partial y}{\\partial \\theta_{2}} \\left(\\frac{1}{s_{2}}\\right) = \\frac{1}{s_{2}} \\frac{\\partial y}{\\partial \\theta_{2}}\n$$\n因此，相对于有量纲参数的敏感性向量 $\\nabla_{p}y$ 是：\n$$\n\\nabla_{p}y = \\begin{pmatrix} \\frac{1}{s_{1}} \\frac{\\partial y}{\\partial \\theta_{1}}  \\frac{1}{s_{2}} \\frac{\\partial y}{\\partial \\theta_{2}} \\end{pmatrix}\n$$\n\n现在我们解释这个结果的单位和意义。\n设一个量 $q$ 的物理单位表示为 $[q]$。问题陈述指出 $y$、$\\theta_{1}$ 和 $\\theta_{2}$ 是无量纲的。这意味着 $[y] = 1$ 和 $[\\theta_i] = 1$。因此，敏感性 $\\frac{\\partial y}{\\partial \\theta_i}$ 也是无量纲的，因为 $[\\frac{\\partial y}{\\partial \\theta_i}] = \\frac{[y]}{[\\theta_i]} = \\frac{1}{1} = 1$。物理参数 $p_i$ 具有量纲 $[p_i]$。为了使 $\\theta_i = p_i/s_i$ 无量纲，缩放因子 $s_i$ 必须具有与相应物理参数相同的单位，即 $[s_i] = [p_i]$。那么，有量纲敏感性 $\\frac{\\partial y}{\\partial p_i}$ 的单位是：\n$$\n\\left[\\frac{\\partial y}{\\partial p_i}\\right] = \\frac{[y]}{[p_i]} = \\frac{1}{[p_i]} = [p_i]^{-1}\n$$\n例如，如果 $p_{1}$ 表示一个对流夹带率，单位为逆长度 ($m^{-1}$)，那么敏感性 $\\frac{\\partial y}{\\partial p_1}$ 的单位将是长度 ($m$)。这表示夹带率每单位变化所引起的无量纲成本函数的变化。\n\n这对于对流方案中的参数调优具有重要意义。关系式 $\\frac{\\partial y}{\\partial p_i} = \\frac{1}{s_i} \\frac{\\partial y}{\\partial \\theta_i}$ 表明，模型的成本函数对有量纲物理参数 $p_i$ 的敏感性与其特征缩放因子 $s_i$ 成反比。\n如果选择的缩放因子 $s_i$ 很大，则意味着需要物理参数 $p_i$ 的一个较大的绝对变化才能在无量纲参数 $\\theta_i$ 中产生单位变化。因此，大的 $s_i$ 会使成本函数 $y$ 对 $p_i$ 不那么敏感。这会使得该参数难以“调优”或约束，因为即使对其值进行大幅调整，也可能只导致由 $y$ 衡量的模型性能发生微小变化。\n相反，如果 $s_i$ 很小，成本函数就会对 $p_i$ 高度敏感。对 $p_i$ 的微小调整会被放大，导致 $\\theta_i$ 乃至 $y$ 发生巨大变化。这类参数在调优过程中必须非常谨慎地处理，因为其设定中的微小误差可能导致模型性能的大幅下降。\n缩放因子 $(s_1, s_2)$ 的选择是参数估计和不确定性量化中的一个关键步骤。这些尺度通常基于物理推理来选择，以代表参数的特征量级或变化范围。理想情况下，选择它们是为了使无量纲敏感性 $\\frac{\\partial y}{\\partial \\theta_i}$ 具有相似的量级（例如，一阶量级），这可以导向一个条件更好的优化问题。这种无量纲化和缩放的过程对于理解和比较像对流参数化方案这样的复杂模型中不同物理过程的相对重要性是至关重要的。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2  1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "从确定性的局部敏感性分析更进一步，我们可以采用概率框架来更新我们对不确定参数的认识。贝叶斯定理为此提供了数学基础，使我们能够系统地将先验知识与新的观测数据相结合，从而得到更精确的后验估计。本练习通过一个高斯先验和高斯似然函数的经典共轭示例，清晰地揭示了贝叶斯更新的核心过程，并阐释了“收缩”效应和精度加权平均等关键概念。",
            "id": "4107138",
            "problem": "考虑在数值天气预报 (NWP) 和气候建模中使用扰动参数集合 (PPE; perturbed parameter ensemble) 对标量不确定参数 $\\theta$ 进行简化校准。假设 $\\theta$ 代表一个次网格过程系数，其在集合中的先验不确定性由高斯先验 $\\theta \\sim \\mathcal{N}(0, 1)$ 描述。您通过模型-数据比较获得单个诊断观测值 $y$，其似然为 $y \\mid \\theta \\sim \\mathcal{N}(\\theta, 1)$，反映了方差为 $1$ 的附加观测误差和表示误差。您观测到 $y = 2$。\n\n从贝叶斯定理和高斯密度的定义出发，通过显式地组合先验和似然，并在指数项中进行配方，以闭合形式推导出后验分布 $p(\\theta \\mid y)$。然后，确定后验均值和后验方差，并根据精度加权平均解释后验均值相对于观测值 $y$ 如何收缩，以及在此 PPE 背景下，为什么后验方差相对于先验方差减小。\n\n请将后验均值和后验方差的最终数值答案以一个包含两个条目的行矩阵形式提供，这两个条目按顺序分别对应后验均值和后验方差。无需四舍五入。",
            "solution": "该问题是根据给定的先验分布和来自似然模型的单个观测值$y$，推导不确定参数$\\theta$的后验分布。这是贝叶斯定理在共轭先验背景下的标准应用。\n\n给定条件如下：\n- $\\theta$的先验分布：$\\theta \\sim \\mathcal{N}(\\mu_p, \\sigma_p^2)$，其中先验均值$\\mu_p = 0$，先验方差$\\sigma_p^2 = 1$。\n- 观测值$y$的似然模型：$y \\mid \\theta \\sim \\mathcal{N}(\\theta, \\sigma_l^2)$，其中似然方差$\\sigma_l^2 = 1$。\n- 一个具体观测值：$y = 2$。\n\n根据贝叶斯定理，后验概率分布$p(\\theta \\mid y)$与似然$p(y \\mid \\theta)$和先验$p(\\theta)$的乘积成正比：\n$$\np(\\theta \\mid y) \\propto p(y \\mid \\theta) \\, p(\\theta)\n$$\n高斯先验的概率密度函数 (PDF) 为：\n$$\np(\\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma_p^2}} \\exp\\left( -\\frac{(\\theta - \\mu_p)^2}{2\\sigma_p^2} \\right) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left( -\\frac{\\theta^2}{2} \\right)\n$$\n高斯似然的 PDF 为：\n$$\np(y \\mid \\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma_l^2}} \\exp\\left( -\\frac{(y - \\theta)^2}{2\\sigma_l^2} \\right) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left( -\\frac{(y - \\theta)^2}{2} \\right)\n$$\n将先验与似然相乘，由于我们处理的是比例关系，可以忽略归一化常数$(2\\pi)^{-1/2}$：\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\frac{\\theta^2}{2} \\right) \\exp\\left( -\\frac{(y - \\theta)^2}{2} \\right)\n$$\n我们可以合并指数项：\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\frac{1}{2} \\left[ \\theta^2 + (y - \\theta)^2 \\right] \\right)\n$$\n为确定后验分布的形式，我们需要分析指数中的表达式。这涉及展开各项并对$\\theta$进行配方。方括号内的项为：\n$$\n\\theta^2 + (y - \\theta)^2 = \\theta^2 + (y^2 - 2y\\theta + \\theta^2) = 2\\theta^2 - 2y\\theta + y^2\n$$\n现在，我们对涉及$\\theta$的项进行配方：\n$$\n2\\theta^2 - 2y\\theta + y^2 = 2\\left(\\theta^2 - y\\theta\\right) + y^2\n$$\n为对$\\theta^2 - y\\theta$进行配方，我们加上并减去$(y/2)^2$：\n$$\n2\\left( \\left[\\theta^2 - y\\theta + \\left(\\frac{y}{2}\\right)^2\\right] - \\left(\\frac{y}{2}\\right)^2 \\right) + y^2 = 2\\left( \\left(\\theta - \\frac{y}{2}\\right)^2 - \\frac{y^2}{4} \\right) + y^2\n$$\n$$\n= 2\\left(\\theta - \\frac{y}{2}\\right)^2 - 2\\frac{y^2}{4} + y^2 = 2\\left(\\theta - \\frac{y}{2}\\right)^2 - \\frac{y^2}{2} + y^2 = 2\\left(\\theta - \\frac{y}{2}\\right)^2 + \\frac{y^2}{2}\n$$\n将此代回后验 PDF 的表达式中：\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\frac{1}{2} \\left[ 2\\left(\\theta - \\frac{y}{2}\\right)^2 + \\frac{y^2}{2} \\right] \\right)\n$$\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\left(\\theta - \\frac{y}{2}\\right)^2 - \\frac{y^2}{4} \\right) = \\exp\\left( -\\left(\\theta - \\frac{y}{2}\\right)^2 \\right) \\exp\\left( -\\frac{y^2}{4} \\right)\n$$\n由于项$\\exp(-y^2/4)$不依赖于$\\theta$，因此它相对于$\\theta$是一个常数，可以被吸收到比例常数中。因此，我们有：\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\left(\\theta - \\frac{y}{2}\\right)^2 \\right)\n$$\n为了将其与高斯 PDF 的标准形式$p(x) \\propto \\exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2} \\right)$相匹配，我们重写指数：\n$$\np(\\theta \\mid y) \\propto \\exp\\left( -\\frac{\\left(\\theta - \\frac{y}{2}\\right)^2}{2\\left(\\frac{1}{2}\\right)} \\right)\n$$\n这是$\\theta$的高斯分布的核。通过观察，我们可以确定后验均值和方差。后验分布为$\\theta \\mid y \\sim \\mathcal{N}(\\mu_{\\text{post}}, \\sigma_{\\text{post}}^2)$，其中：\n- 后验均值：$\\mu_{\\text{post}} = \\frac{y}{2}$\n- 后验方差：$\\sigma_{\\text{post}}^2 = \\frac{1}{2}$\n\n对于给定的观测值$y=2$，后验均值为：\n$$\n\\mu_{\\text{post}} = \\frac{2}{2} = 1\n$$\n后验方差为$\\sigma_{\\text{post}}^2 = \\frac{1}{2}$。\n\n用精度加权平均解释结果：\n精度定义为方差的倒数，$\\tau = 1/\\sigma^2$。它代表了估计的确定性。\n- 先验精度为 $\\tau_p = 1/\\sigma_p^2 = 1/1 = 1$。\n- 数据（似然）精度为 $\\tau_l = 1/\\sigma_l^2 = 1/1 = 1$。\n\n对于高斯-高斯模型，后验均值是先验均值和观测值的精度加权平均：\n$$\n\\mu_{\\text{post}} = \\frac{\\tau_p \\mu_p + \\tau_l y}{\\tau_p + \\tau_l} = \\frac{(1)(0) + (1)(y)}{1 + 1} = \\frac{y}{2}\n$$\n这显示了后验均值是如何在先验信念 ($\\mu_p=0$) 和来自数据的信息 ($y$) 之间取得折衷的。当$y=2$时，后验均值为$1$。这个值从观测值$y=2$向先验均值$\\mu_p=0$“收缩”。由于先验和数据的精度相等，后验均值恰好位于它们之间的中点。这种收缩是贝叶斯更新的一个典型特征，通过将估计值拉向先验信念来对其进行正则化。\n\n后验精度是先验精度和数据精度的总和：\n$$\n\\tau_{\\text{post}} = \\tau_p + \\tau_l = 1 + 1 = 2\n$$\n后验方差是后验精度的倒数：\n$$\n\\sigma_{\\text{post}}^2 = \\frac{1}{\\tau_{\\text{post}}} = \\frac{1}{2}\n$$\n后验方差 ($\\sigma_{\\text{post}}^2 = 1/2$) 小于先验方差 ($\\sigma_p^2 = 1$) 和似然方差 ($\\sigma_l^2 = 1$)。这反映了一个事实，即通过结合两个信息来源（先验和数据），我们减少了关于参数$\\theta$的不确定性。我们的后验知识比我们最初的信念或仅来自单个观测值的信息都更精确。在扰动参数集合 (PPE) 的背景下，这个过程展示了观测如何约束初始的参数集合，从而导致一个更小、更精炼的集合，并因此减少了参数不确定性。\n\n后验均值和后验方差的最终数值答案分别为$1$和$\\frac{1}{2}$。",
            "answer": "$$\\boxed{\\begin{pmatrix} 1  \\frac{1}{2} \\end{pmatrix}}$$"
        },
        {
            "introduction": "虽然一次只改变一个参数（OAT）的方法在概念上很简单，但它在处理参数相互作用或相关性时存在固有的局限性。当模型响应不是各参数效应的简单叠加时，这种简化方法可能导致对输出不确定性的严重误判。这项练习通过分析一个包含双线性交互项的模型，从数学上推导出OAT方差估计器的偏差，从而有力地证明了在复杂模型中采用能够捕捉参数联合分布的全套扰动参数集（PPE）的必要性。",
            "id": "4107110",
            "problem": "在数值天气预报 (NWP) 和气候模拟中，一种常见的不确定性量化方法是扰动参数集合 (PPE)，其中模型参数被视为随机变量。另一种方法是一次一参数 (OAT) 确定性扰动策略，其中每个参数围绕基准线单独进行扰动，而其他参数保持不变，由此产生的局部敏感度用于近似输出方差。考虑一个气候学诊断量 $Y$ 的简化 PPE，其对两个不确定参数 $(\\theta_1,\\theta_2)$ 的依赖关系由一个双线性响应近似：\n$$\nY \\;=\\; f(\\theta_1,\\theta_2) \\;=\\; \\alpha_1 \\,\\theta_1 \\;+\\; \\alpha_2 \\,\\theta_2 \\;+\\; \\beta \\,\\theta_1 \\theta_2,\n$$\n其中 $\\alpha_1$、$\\alpha_2$ 和 $\\beta$ 是由模型的物理过程和数值方法决定的常数。假设 $(\\theta_1,\\theta_2)$ 服从联合高斯分布，其均值为 $(\\mu_1,\\mu_2)$，方差为 $(\\sigma_1^2,\\sigma_2^2)$，相关系数为 $\\rho$。\n\n在 OAT 确定性扰动设计中，局部线性敏感度在基准线 $(\\mu_1,\\mu_2)$ 处进行求值，得到：\n$$\nc_1 \\;=\\; \\left.\\frac{\\partial f}{\\partial \\theta_1}\\right|_{(\\mu_1,\\mu_2)} \\;=\\; \\alpha_1 + \\beta \\mu_2,\n\\qquad\nc_2 \\;=\\; \\left.\\frac{\\partial f}{\\partial \\theta_2}\\right|_{(\\mu_1,\\mu_2)} \\;=\\; \\alpha_2 + \\beta \\mu_1.\n$$\n一个标准的基于 OAT 的方差估计量则忽略协方差项和曲率项，并使用：\n$$\n\\widehat{\\mathrm{Var}}_{\\mathrm{OAT}} \\;=\\; c_1^2 \\,\\sigma_1^2 \\;+\\; c_2^2 \\,\\sigma_2^2.\n$$\n\n使用随机变量变换的第一性原理和多元正态分布的性质，推导在联合随机扰动集合下的精确输出方差 $\\mathrm{Var}(Y)$，然后计算偏差：\n$$\n\\mathrm{Bias} \\;=\\; \\mathrm{Var}(Y) \\;-\\; \\widehat{\\mathrm{Var}}_{\\mathrm{OAT}}.\n$$\n将你的最终答案表示为关于 $\\alpha_1$、$\\alpha_2$、$\\beta$、$\\mu_1$、$\\mu_2$、$\\sigma_1$、$\\sigma_2$ 和 $\\rho$ 的单一闭式解析表达式。无需四舍五入。最终表达式中无需报告物理单位。",
            "solution": "问题要求计算一次一参数 (OAT) 方差估计量相对于模型输出 $Y$ 的精确方差的偏差。该模型是两个联合高斯随机参数 $\\theta_1$ 和 $\\theta_2$ 的双线性函数。偏差定义为 $\\mathrm{Bias} = \\mathrm{Var}(Y) - \\widehat{\\mathrm{Var}}_{\\mathrm{OAT}}$。\n\n首先，我们推导输出的精确方差 $\\mathrm{Var}(Y)$。输出 $Y$ 由下式给出：\n$$\nY = f(\\theta_1, \\theta_2) = \\alpha_1 \\theta_1 + \\alpha_2 \\theta_2 + \\beta \\theta_1 \\theta_2\n$$\n参数 $(\\theta_1, \\theta_2)$ 服从二元正态分布，其均值为 $E[\\theta_1] = \\mu_1$，$E[\\theta_2]=\\mu_2$，方差为 $\\mathrm{Var}(\\theta_1) = \\sigma_1^2$，$\\mathrm{Var}(\\theta_2) = \\sigma_2^2$，相关系数为 $\\mathrm{Corr}(\\theta_1, \\theta_2) = \\rho$。协方差为 $\\mathrm{Cov}(\\theta_1, \\theta_2) = \\rho\\sigma_1\\sigma_2$。\n\n随机变量 $Y$ 的方差由 $\\mathrm{Var}(Y) = E[(Y - E[Y])^2]$ 给出。我们首先计算 $Y$ 的期望值 $E[Y]$。利用期望的线性性质：\n$$\nE[Y] = E[\\alpha_1 \\theta_1 + \\alpha_2 \\theta_2 + \\beta \\theta_1 \\theta_2] = \\alpha_1 E[\\theta_1] + \\alpha_2 E[\\theta_2] + \\beta E[\\theta_1 \\theta_2]\n$$\n项 $E[\\theta_1 \\theta_2]$ 与协方差相关：$\\mathrm{Cov}(\\theta_1, \\theta_2) = E[\\theta_1 \\theta_2] - E[\\theta_1]E[\\theta_2]$。\n因此，$E[\\theta_1 \\theta_2] = \\mathrm{Cov}(\\theta_1, \\theta_2) + E[\\theta_1]E[\\theta_2] = \\rho\\sigma_1\\sigma_2 + \\mu_1\\mu_2$。\n将此代入 $E[Y]$ 的表达式中，得到：\n$$\nE[Y] = \\alpha_1 \\mu_1 + \\alpha_2 \\mu_2 + \\beta(\\mu_1 \\mu_2 + \\rho\\sigma_1\\sigma_2)\n$$\n接下来，我们表示中心化变量 $Y - E[Y]$。让我们定义中心化随机变量 $\\delta\\theta_1 = \\theta_1 - \\mu_1$ 和 $\\delta\\theta_2 = \\theta_2 - \\mu_2$。它们的均值为零，$E[\\delta\\theta_1] = E[\\delta\\theta_2] = 0$。它们的二阶矩为：$E[\\delta\\theta_1^2] = \\sigma_1^2$，$E[\\delta\\theta_2^2] = \\sigma_2^2$，以及 $E[\\delta\\theta_1 \\delta\\theta_2] = \\mathrm{Cov}(\\theta_1, \\theta_2) = \\rho\\sigma_1\\sigma_2$。\n\n我们用这些中心化变量重写 $Y$：\n$$\nY = \\alpha_1(\\mu_1 + \\delta\\theta_1) + \\alpha_2(\\mu_2 + \\delta\\theta_2) + \\beta(\\mu_1 + \\delta\\theta_1)(\\mu_2 + \\delta\\theta_2)\n$$\n$$\nY = \\alpha_1\\mu_1 + \\alpha_1\\delta\\theta_1 + \\alpha_2\\mu_2 + \\alpha_2\\delta\\theta_2 + \\beta(\\mu_1\\mu_2 + \\mu_1\\delta\\theta_2 + \\mu_2\\delta\\theta_1 + \\delta\\theta_1\\delta\\theta_2)\n$$\n减去 $E[Y]$：\n$$\nY - E[Y] = (\\alpha_1\\mu_1 + \\alpha_2\\mu_2 + \\beta\\mu_1\\mu_2) + (\\alpha_1 + \\beta\\mu_2)\\delta\\theta_1 + (\\alpha_2 + \\beta\\mu_1)\\delta\\theta_2 + \\beta\\delta\\theta_1\\delta\\theta_2 - E[Y]\n$$\n代入 $E[Y]$ 的表达式，得到：\n$$\nY - E[Y] = (\\alpha_1 \\mu_1 + \\alpha_2 \\mu_2 + \\beta\\mu_1 \\mu_2) + (\\alpha_1 + \\beta\\mu_2)\\delta\\theta_1 + (\\alpha_2 + \\beta\\mu_1)\\delta\\theta_2 + \\beta\\delta\\theta_1\\delta\\theta_2 - (\\alpha_1 \\mu_1 + \\alpha_2 \\mu_2 + \\beta\\mu_1 \\mu_2 + \\beta\\rho\\sigma_1\\sigma_2)\n$$\n$$\nY - E[Y] = (\\alpha_1 + \\beta\\mu_2)\\delta\\theta_1 + (\\alpha_2 + \\beta\\mu_1)\\delta\\theta_2 + \\beta(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2)\n$$\n使用给定的 OAT 敏感度定义，$c_1 = \\alpha_1 + \\beta\\mu_2$ 和 $c_2 = \\alpha_2 + \\beta\\mu_1$，我们有：\n$$\nY - E[Y] = c_1\\delta\\theta_1 + c_2\\delta\\theta_2 + \\beta(\\delta\\theta_1\\delta\\theta_2 - E[\\delta\\theta_1\\delta\\theta_2])\n$$\n现在我们计算方差，$\\mathrm{Var}(Y) = E[(Y - E[Y])^2]$：\n$$\n\\mathrm{Var}(Y) = E \\left[ \\left( c_1\\delta\\theta_1 + c_2\\delta\\theta_2 + \\beta(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2) \\right)^2 \\right]\n$$\n展开平方：\n$$\n\\mathrm{Var}(Y) = E \\left[ c_1^2\\delta\\theta_1^2 + c_2^2\\delta\\theta_2^2 + \\beta^2(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2)^2 + 2c_1c_2\\delta\\theta_1\\delta\\theta_2 + 2c_1\\beta\\delta\\theta_1(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2) + 2c_2\\beta\\delta\\theta_2(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2) \\right]\n$$\n根据期望的线性性质，我们可以逐项计算：\n1.  $E[c_1^2\\delta\\theta_1^2] = c_1^2 E[\\delta\\theta_1^2] = c_1^2\\sigma_1^2$。\n2.  $E[c_2^2\\delta\\theta_2^2] = c_2^2 E[\\delta\\theta_2^2] = c_2^2\\sigma_2^2$。\n3.  $E[2c_1c_2\\delta\\theta_1\\delta\\theta_2] = 2c_1c_2 E[\\delta\\theta_1\\delta\\theta_2] = 2c_1c_2\\rho\\sigma_1\\sigma_2$。\n4.  $E[2c_1\\beta\\delta\\theta_1(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2)] = 2c_1\\beta(E[\\delta\\theta_1^2\\delta\\theta_2] - \\rho\\sigma_1\\sigma_2 E[\\delta\\theta_1])$。由于 $\\delta\\theta_1$ 和 $\\delta\\theta_2$ 是联合高斯分布且中心化的，任何奇数阶矩都为零。因此，$E[\\delta\\theta_1]=0$ 且 $E[\\delta\\theta_1^2\\delta\\theta_2]=0$。此项为零。\n5.  类似地，$E[2c_2\\beta\\delta\\theta_2(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2)] = 2c_2\\beta(E[\\delta\\theta_1\\delta\\theta_2^2] - \\rho\\sigma_1\\sigma_2 E[\\delta\\theta_2]) = 0$。\n6.  最后一项是 $E[\\beta^2(\\delta\\theta_1\\delta\\theta_2 - \\rho\\sigma_1\\sigma_2)^2] = \\beta^2 E[(\\delta\\theta_1\\delta\\theta_2 - E[\\delta\\theta_1\\delta\\theta_2])^2] = \\beta^2\\mathrm{Var}(\\delta\\theta_1\\delta\\theta_2)$。对于中心化的二元正态变量，其乘积的方差为 $\\mathrm{Var}(\\delta\\theta_1\\delta\\theta_2) = (1+\\rho^2)\\sigma_1^2\\sigma_2^2$。这个结果源于 Isserlis 定理，该定理给出 $E[\\delta\\theta_1^2\\delta\\theta_2^2] = E[\\delta\\theta_1^2]E[\\delta\\theta_2^2] + 2(E[\\delta\\theta_1\\delta\\theta_2])^2 = \\sigma_1^2\\sigma_2^2 + 2(\\rho\\sigma_1\\sigma_2)^2 = (1+2\\rho^2)\\sigma_1^2\\sigma_2^2$。那么 $\\mathrm{Var}(\\delta\\theta_1\\delta\\theta_2) = E[\\delta\\theta_1^2\\delta\\theta_2^2] - (E[\\delta\\theta_1\\delta\\theta_2])^2 = (1+2\\rho^2)\\sigma_1^2\\sigma_2^2 - (\\rho\\sigma_1\\sigma_2)^2 = (1+\\rho^2)\\sigma_1^2\\sigma_2^2$。因此，此项等于 $\\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2$。\n\n将非零项相加，精确方差为：\n$$\n\\mathrm{Var}(Y) = c_1^2\\sigma_1^2 + c_2^2\\sigma_2^2 + 2c_1c_2\\rho\\sigma_1\\sigma_2 + \\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2\n$$\n问题将基于 OAT 的方差估计量指定为：\n$$\n\\widehat{\\mathrm{Var}}_{\\mathrm{OAT}} = c_1^2\\sigma_1^2 + c_2^2\\sigma_2^2\n$$\n偏差是精确方差与估计方差之间的差值：\n$$\n\\mathrm{Bias} = \\mathrm{Var}(Y) - \\widehat{\\mathrm{Var}}_{\\mathrm{OAT}}\n$$\n$$\n\\mathrm{Bias} = (c_1^2\\sigma_1^2 + c_2^2\\sigma_2^2 + 2c_1c_2\\rho\\sigma_1\\sigma_2 + \\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2) - (c_1^2\\sigma_1^2 + c_2^2\\sigma_2^2)\n$$\n$$\n\\mathrm{Bias} = 2c_1c_2\\rho\\sigma_1\\sigma_2 + \\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2\n$$\n最后，我们将 $c_1$ 和 $c_2$ 的表达式代回，以基本模型参数表示偏差：\n$$\nc_1 = \\alpha_1 + \\beta\\mu_2\n$$\n$$\nc_2 = \\alpha_2 + \\beta\\mu_1\n$$\n$$\n\\mathrm{Bias} = 2(\\alpha_1 + \\beta\\mu_2)(\\alpha_2 + \\beta\\mu_1)\\rho\\sigma_1\\sigma_2 + \\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2\n$$\n该表达式表示 OAT 估计量中两个误差来源：第一项源于忽略参数效应之间的协方差（当 $\\rho \\neq 0$ 时非零），第二项源于忽略模型的非线性或曲率（当 $\\beta \\neq 0$ 时非零）。",
            "answer": "$$\n\\boxed{2(\\alpha_1 + \\beta\\mu_2)(\\alpha_2 + \\beta\\mu_1)\\rho\\sigma_1\\sigma_2 + \\beta^2(1+\\rho^2)\\sigma_1^2\\sigma_2^2}\n$$"
        }
    ]
}