{
    "hands_on_practices": [
        {
            "introduction": "The rank histogram is a fundamental diagnostic for assessing the reliability of an ensemble forecast. This exercise goes beyond simply creating a histogram; it challenges you to investigate the statistical validity of the common chi-squared test for uniformity. By simulating the test's performance under different ensemble and sample sizes, you will gain a crucial, hands-on understanding of how discretization bias can affect our conclusions about forecast reliability .",
            "id": "4079028",
            "problem": "You are tasked with quantifying how ensemble size affects the reliability assessment of probabilistic forecasts through rank histograms and a standard uniformity test, with an emphasis on discretization bias arising from finite, discrete bins. Consider an ensemble forecast with $M$ members and a single verifying observation per forecast case. Under forecast reliability (observations and ensemble members sampled independently from the same distribution), the rank of the observation among the sorted ensemble members is discrete uniform on the set $\\{0,1,\\dots,M\\}$. The rank histogram collected over $N$ forecast cases therefore has $M+1$ bins with equal expected probability $p_i = 1/(M+1)$ for each bin $i$. A commonly used uniformity test is Pearson’s chi-squared (Pearson $\\chi^2$) test, which compares observed bin counts to expected counts under the null hypothesis of uniformity. In practice, the test employs the asymptotic chi-squared distribution as its reference. When expected bin counts are small, the discreteness of ranks (which depends on $M$) and finite $N$ can induce a discrepancy between the true finite-sample distribution of the test statistic and its asymptotic reference; this discrepancy manifests as a difference between the nominal significance level and the empirical Type I rejection rate. We define this difference as the discretization bias of the uniformity test at a given ensemble size.\n\nStarting from the following fundamental base:\n\n- Under reliability, the observation $y$ and each ensemble member $e_m$ are independent and identically distributed draws from a common continuous distribution (e.g., the standard normal distribution). The rank $R$ of $y$ among $M$ ensemble members is given by $R = \\sum_{m=1}^{M} \\mathbb{1}\\{e_m  y\\}$, which is discrete uniform on $\\{0,\\dots,M\\}$ when the distribution is continuous and ties occur with probability zero.\n\n- For $N$ independent forecast cases producing ranks $R_j$ with $j=1,\\dots,N$, the bin counts $(O_0,\\dots,O_M)$ are distributed as a multinomial random vector with parameters $N$ and category probabilities $p_i = 1/(M+1)$ under reliability.\n\n- Pearson’s chi-squared statistic is defined by\n$$\nX^2 = \\sum_{i=0}^{M} \\frac{(O_i - E_i)^2}{E_i},\n$$\nwhere $E_i = N p_i = N/(M+1)$ are the expected bin counts. Under the multinomial model with equal category probabilities, the exact expectation of $X^2$ is $\\mathbb{E}[X^2] = M$, but its finite-sample distribution differs from the asymptotic chi-squared distribution with $M$ degrees of freedom when expected counts are small.\n\nWrite a complete program that does the following:\n\n- For each specified test case, simulate $R$ independent Monte Carlo replicates. In each replicate, generate $N$ forecast cases with an ensemble size of $M$, where the ensemble members $e_m$ and the verifying observation $y$ are independent draws from the standard normal distribution $\\mathcal{N}(0,1)$. For each case, compute the rank $R_j = \\sum_{m=1}^{M} \\mathbb{1}\\{e_{j,m}  y_j\\}$, for $j=1,\\dots,N$. Accumulate a rank histogram $(O_0,\\dots,O_M)$ across the $N$ cases, then compute the Pearson $X^2$ statistic with $E_i = N/(M+1)$ for all bins $i$ and perform a rejection decision at significance level $\\alpha$ using the asymptotic chi-squared threshold $q_{1-\\alpha}$ with $M$ degrees of freedom. Over the $R$ replicates, estimate the empirical Type I rejection rate $\\hat{\\rho}$ and report the discretization bias $\\hat{b} = \\hat{\\rho} - \\alpha$ as a decimal (not a percentage).\n\n- Use a fixed random seed to ensure reproducibility.\n\n- Express all results as decimals and aggregate the outputs for all test cases into a single line in the specified format.\n\nTest Suite:\n\n- Use a fixed random seed of $42$ for the entire simulation.\n\n- Use $R = 500$ Monte Carlo replicates per test case.\n\n- Use the following test cases, all under the reliability assumption (observation and ensemble members sampled independently from $\\mathcal{N}(0,1)$), with nominal significance level $\\alpha = 0.1$:\n\n    1. $(M, N, \\alpha) = (1, 200, 0.1)$\n\n    2. $(M, N, \\alpha) = (2, 200, 0.1)$\n\n    3. $(M, N, \\alpha) = (10, 200, 0.1)$\n\n    4. $(M, N, \\alpha) = (50, 200, 0.1)$\n\n    5. $(M, N, \\alpha) = (50, 100, 0.1)$\n\nRequired Final Output Format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the discretization bias $\\hat{b}$ for each test case, in the same order as listed above, each rounded to $4$ decimal places, such as $[\\hat{b}_1,\\hat{b}_2,\\hat{b}_3,\\hat{b}_4,\\hat{b}_5]$.\n\nScientific realism and self-consistency:\n\n- Use a continuous distribution (the standard normal distribution $\\mathcal{N}(0,1)$) so that ties have probability zero, ensuring the rank distribution is exactly discrete uniform under reliability.\n\n- The simulation-based estimation of discretization bias is justified because the finite-sample distribution of $X^2$ under a multinomial model differs from the asymptotic chi-squared distribution when expected counts $E_i$ are small, which happens for large $M$ or small $N$.\n\nYour task is to implement this simulation accurately, adhering to the specified parameters and output format. No physical units or angle units apply in this problem.",
            "solution": "The problem is valid. It is scientifically grounded in the principles of statistical hypothesis testing and ensemble forecast verification, well-posed with all necessary parameters and methods specified, and objective in its formulation. We will proceed with a solution.\n\nThe objective is to quantify the discretization bias of the Pearson $\\chi^2$ uniformity test as applied to ensemble forecast rank histograms. This bias, denoted $\\hat{b}$, is the difference between the empirical Type I error rate, $\\hat{\\rho}$, and the nominal significance level, $\\alpha$. It arises because the finite-sample distribution of the test statistic deviates from its assumed asymptotic $\\chi^2$ distribution, particularly when expected bin counts are low. The analysis is conducted via a Monte Carlo simulation.\n\nThe core of the methodology is to simulate the process of generating rank histograms under the null hypothesis of perfect forecast reliability and then perform a $\\chi^2$ test. This process is repeated many times to estimate the true rejection rate.\n\nFor each test case, defined by a specific ensemble size $M$, number of forecast cases $N$, and significance level $\\alpha$, the simulation procedure is as follows:\n\n1.  **Initialization**: We perform $R = 500$ independent Monte Carlo replicates. The nominal significance level for the hypothesis test is fixed at $\\alpha = 0.1$. A counter for the number of rejections is initialized to $0$.\n\n2.  **Determine Critical Value**: The null hypothesis of uniformity is tested using the Pearson $\\chi^2$ statistic. The asymptotic reference distribution for this statistic is the chi-squared distribution with $M$ degrees of freedom, $\\chi^2_M$. The degrees of freedom are calculated as the number of bins ($M+1$) minus $1$, since the bin probabilities are pre-specified by the null hypothesis and not estimated from the data. The null hypothesis is rejected if the calculated statistic $X^2$ exceeds the critical value $q_{1-\\alpha}$, which is the $(1-\\alpha)$-quantile of the $\\chi^2_M$ distribution. This value is pre-calculated for each test case.\n\n3.  **Monte Carlo Replicates**: For each of the $R$ replicates:\n    a. **Data Generation**: We simulate $N$ forecast-verification pairs. For each pair $j=1, \\dots, N$, we generate $M$ ensemble members, $\\{e_{j,m}\\}_{m=1}^M$, and one verifying observation, $y_j$. According to the problem's reliability assumption, all $M+1$ values are independent draws from the standard normal distribution, $\\mathcal{N}(0, 1)$. This setup perfectly satisfies the null hypothesis.\n\n    b. **Rank Calculation**: For each of the $N$ pairs, the rank of the observation $y_j$ relative to its corresponding ensemble members is computed. The rank $R_j$ is the number of ensemble members smaller than the observation: $R_j = \\sum_{m=1}^{M} \\mathbb{1}\\{e_{j,m}  y_j\\}$. Since the underlying distribution is continuous, the probability of ties is zero, and the rank $R_j$ is an integer in the set $\\{0, 1, \\dots, M\\}$.\n\n    c. **Rank Histogram**: The $N$ computed ranks are aggregated into a rank histogram, which consists of $M+1$ counts, $(O_0, O_1, \\dots, O_M)$, where each $O_i$ is the number of times the rank was equal to $i$.\n\n    d. **Chi-Squared Test**: The Pearson $\\chi^2$ statistic is calculated using the formula:\n    $$\n    X^2 = \\sum_{i=0}^{M} \\frac{(O_i - E_i)^2}{E_i}\n    $$\n    Here, $O_i$ are the observed counts in the rank histogram. Under the null hypothesis of uniformity, the expected count for each bin $i$ is identical: $E_i = N \\times p_i = N/(M+1)$.\n\n    e. **Hypothesis Decision**: The calculated $X^2$ value is compared to the pre-determined critical value $q_{1-\\alpha}$. If $X^2  q_{1-\\alpha}$, the null hypothesis is rejected for this replicate, and the rejection counter is incremented.\n\n4.  **Bias Calculation**: After all $R$ replicates are completed, the empirical Type I rejection rate, $\\hat{\\rho}$, is estimated as the total number of rejections divided by $R$. The discretization bias is then computed as the deviation of this empirical rate from the nominal rate:\n    $$\n    \\hat{b} = \\hat{\\rho} - \\alpha\n    $$\n\nThis entire procedure is implemented in the provided Python program. The use of a fixed random seed ensures the reproducibility of the simulation results. The program iterates through the specified test cases, computes $\\hat{b}$ for each, and formats the output as required. The simulation is vectorized for computational efficiency, allowing for the simultaneous calculation of all $N$ ranks within a single replicate.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef run_simulation_vectorized(M, N, R, alpha, rng):\n    \"\"\"\n    Runs the vectorized Monte Carlo simulation for a single test case.\n\n    Args:\n        M (int): The ensemble size.\n        N (int): The number of forecast cases.\n        R (int): The number of Monte Carlo replicates.\n        alpha (float): The nominal significance level.\n        rng (numpy.random.Generator): The random number generator instance.\n\n    Returns:\n        float: The calculated discretization bias.\n    \"\"\"\n    num_bins = M + 1\n    rejection_count = 0\n    \n    # Degrees of freedom for the chi-squared test is M.\n    df = M\n    \n    # The chi-squared test is not defined for df=0, but problem constraints (M=1) prevent this.\n    if df == 0:\n        return -alpha\n\n    # Critical value from the asymptotic chi-squared distribution\n    critical_value = chi2.ppf(1 - alpha, df)\n    \n    expected_counts = N / num_bins\n    \n    for _ in range(R):\n        # Generate all random numbers for N forecast cases at once\n        ensemble_members = rng.standard_normal(size=(N, M))\n        observations = rng.standard_normal(size=(N, 1))\n        \n        # Calculate N ranks using vectorization and broadcasting.\n        # np.sum counts the number of ensemble members less than the observation for each case.\n        ranks = np.sum(ensemble_members  observations, axis=1)\n        \n        # Create the rank histogram (observed counts) using np.bincount.\n        # minlength ensures the array has M+1 bins even if high ranks don't occur.\n        observed_counts = np.bincount(ranks, minlength=num_bins)\n        \n        # Calculate Pearson's chi-squared statistic\n        if expected_counts  0:\n            chi_sq_stat = np.sum((observed_counts - expected_counts)**2 / expected_counts)\n        else: # This case will not be reached given N0.\n            chi_sq_stat = 0.0\n\n        # Perform the hypothesis test by comparing with the critical value\n        if chi_sq_stat  critical_value:\n            rejection_count += 1\n            \n    # Estimate the empirical Type I rejection rate\n    empirical_rejection_rate = rejection_count / R\n    \n    # Calculate the discretization bias\n    discretization_bias = empirical_rejection_rate - alpha\n    \n    return discretization_bias\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    Initializes parameters, iterates through test cases, and prints the final result.\n    \"\"\"\n    # Define fixed parameters from the problem statement\n    random_seed = 42\n    num_replicates = 500\n    \n    # Initialize the random number generator with a fixed seed for reproducibility\n    rng = np.random.default_rng(random_seed)\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (M, N, alpha)\n    test_cases = [\n        (1, 200, 0.1),\n        (2, 200, 0.1),\n        (10, 200, 0.1),\n        (50, 200, 0.1),\n        (50, 100, 0.1),\n    ]\n\n    results = []\n    for m_val, n_val, alpha_val in test_cases:\n        # Run the simulation for the current test case.\n        bias = run_simulation_vectorized(m_val, n_val, num_replicates, alpha_val, rng)\n        results.append(bias)\n\n    # Format the final output as a comma-separated list in brackets,\n    # with each result rounded to 4 decimal places.\n    formatted_results = [f'{res:.4f}' for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n# Execute the main solver function.\nsolve()\n```"
        },
        {
            "introduction": "While rank histograms provide a visual, rank-based assessment, scoring rules offer a quantitative measure of forecast quality. The Brier score is a cornerstone for verifying probabilistic forecasts of binary events. This practice requires you to derive and calculate its reliability component, providing insight into how a forecast's skill is directly tied to the correspondence between its stated probabilities and the actual observed frequencies of events .",
            "id": "4079061",
            "problem": "A research group is evaluating probabilistic forecasts from a convection-permitting Numerical Weather Prediction (NWP) ensemble for the binary event \"six-hour precipitation accumulation exceeds $10$ mm\" over a river basin. Let $Y \\in \\{0,1\\}$ denote the verifying indicator for the occurrence of the event, and let $F \\in [0,1]$ denote the issued forecast probability from the ensemble. The Brier score is defined as $BS = \\mathbb{E}[(F - Y)^{2}]$, where the expectation is taken with respect to the joint distribution of $(F,Y)$ induced by the forecasting system and the verifying nature.\n\nUsing the decomposition of the Brier score into reliability, resolution, and uncertainty components via the law of total expectation and the properties of conditional expectation, derive from first principles the reliability component as an expectation involving $F$ and the conditional event frequency $\\mathbb{E}[Y \\mid F]$. Then, under a reliability diagram binning scheme that partitions the forecast space into $K$ discrete bins with representative probabilities $q_{k}$, empirical counts $n_{k}$, and observed relative frequencies $\\bar{y}_{k}$ within each bin, obtain a consistent finite-sample estimator of the reliability component using the bin summaries.\n\nA particular year-long evaluation produced the following reliability diagram summaries for $K=5$ bins:\n- Bin $k=1$: $q_{1} = 0.05$, $n_{1} = 40$, $\\bar{y}_{1} = 0.10$.\n- Bin $k=2$: $q_{2} = 0.15$, $n_{2} = 60$, $\\bar{y}_{2} = 0.12$.\n- Bin $k=3$: $q_{3} = 0.35$, $n_{3} = 80$, $\\bar{y}_{3} = 0.30$.\n- Bin $k=4$: $q_{4} = 0.65$, $n_{4} = 50$, $\\bar{y}_{4} = 0.60$.\n- Bin $k=5$: $q_{5} = 0.85$, $n_{5} = 70$, $\\bar{y}_{5} = 0.90$.\n\nLet $N = \\sum_{k=1}^{K} n_{k}$ denote the total number of forecast–verification pairs. Using the estimator you derived, compute the reliability component for this data set. Express the final answer as an exact reduced fraction (dimensionless). Do not use a percentage sign.",
            "solution": "The problem statement has been analyzed and is deemed valid. It is scientifically grounded in the principles of probabilistic forecast verification, well-posed with sufficient data for a unique solution, and expressed in objective, unambiguous language. We may proceed with the solution.\n\nThe problem asks for two main tasks: first, to derive the reliability component of the Brier score from first principles; and second, to derive a finite-sample estimator for it and use this estimator to compute its value for a given data set.\n\nLet $Y \\in \\{0, 1\\}$ be the binary variable for the event's occurrence and $F \\in [0, 1]$ be the forecast probability. The Brier score ($BS$) is defined as the mean squared error of the forecast:\n$$\nBS = \\mathbb{E}[(F - Y)^{2}]\n$$\nThe expectation $\\mathbb{E}[\\cdot]$ is taken over the joint distribution of forecasts and observations.\n\n**Part 1: Derivation of the Reliability Component**\n\nWe can decompose the Brier score using the law of total expectation. We condition on the forecast value $F$.\n$$\nBS = \\mathbb{E}_{F} \\left[ \\mathbb{E}_{Y \\mid F} [(F - Y)^{2} \\mid F] \\right]\n$$\nLet us analyze the inner expectation, $\\mathbb{E}[(F-Y)^2 \\mid F]$. Given a specific forecast value $F=f$, $f$ is a constant.\n$$\n\\mathbb{E}[(f - Y)^{2} \\mid F=f] = \\mathbb{E}[f^2 - 2fY + Y^2 \\mid F=f]\n$$\nBy the linearity of expectation:\n$$\n= f^2 - 2f \\mathbb{E}[Y \\mid F=f] + \\mathbb{E}[Y^2 \\mid F=f]\n$$\nSince $Y$ is an indicator variable, $Y \\in \\{0, 1\\}$, it follows that $Y^2 = Y$. Therefore, $\\mathbb{E}[Y^2 \\mid F=f] = \\mathbb{E}[Y \\mid F=f]$. Let us define the conditional event frequency, or the true probability of the event given the forecast, as $\\bar{y}(f) \\equiv \\mathbb{E}[Y \\mid F=f]$. Substituting this into the expression gives:\n$$\n\\mathbb{E}[(f - Y)^{2} \\mid F=f] = f^2 - 2f \\bar{y}(f) + \\bar{y}(f)\n$$\nWe can add and subtract $(\\bar{y}(f))^2$ to complete the square:\n$$\n= f^2 - 2f \\bar{y}(f) + (\\bar{y}(f))^2 - (\\bar{y}(f))^2 + \\bar{y}(f)\n$$\n$$\n= (f - \\bar{y}(f))^2 + (\\bar{y}(f) - (\\bar{y}(f))^2)\n$$\nNow, we take the outer expectation with respect to $F$ to get back to the Brier score:\n$$\nBS = \\mathbb{E}_{F} \\left[ (F - \\bar{y}(F))^2 + (\\bar{y}(F) - (\\bar{y}(F))^2) \\right]\n$$\n$$\nBS = \\mathbb{E} \\left[ (F - \\mathbb{E}[Y \\mid F])^2 \\right] + \\mathbb{E} \\left[ \\mathbb{E}[Y \\mid F] (1 - \\mathbb{E}[Y \\mid F]) \\right]\n$$\nThis expression decomposes the Brier score into two terms. The first term, $\\mathbb{E}[(F - \\mathbb{E}[Y \\mid F])^2]$, is the **reliability component**. It measures the weighted mean squared difference between the forecast probabilities and the conditional mean of the observations for those probabilities. A perfectly reliable forecast system would have $\\mathbb{E}[Y \\mid F=f] = f$ for all $f$, making this component zero. This completes the first part of the derivation.\n\nThe second term can be further decomposed into resolution and uncertainty, yielding the full decomposition $BS = REL - RES + UNC$, but this is beyond the scope of the immediate problem. The reliability component is:\n$$\nREL = \\mathbb{E} \\left[ (F - \\mathbb{E}[Y \\mid F])^2 \\right]\n$$\n\n**Part 2: Finite-Sample Estimator and Calculation**\n\nTo obtain a finite-sample estimator from a set of $N$ forecast-verification pairs, we typically use a binning approach, as described in the problem. The forecast probability space $[0,1]$ is partitioned into $K$ bins. For each bin $k \\in \\{1, \\dots, K\\}$, we have:\n- $n_k$: the number of forecasts that fall into bin $k$.\n- $q_k$: a representative forecast probability for bin $k$ (e.g., the bin midpoint or the average of forecasts in the bin). This is our empirical counterpart to $F$.\n- $\\bar{y}_k$: the observed relative frequency of the event for forecasts in bin $k$. This is our empirical estimate of the conditional expectation $\\mathbb{E}[Y \\mid F \\in \\text{bin } k]$.\n\nThe overall expectation $\\mathbb{E}[\\cdot]$ is estimated as an average over all $N$ samples, which translates to a weighted average over the $K$ bins. The weight for each bin $k$ is its sample frequency, $n_k/N$. The term inside the expectation, $(F - \\mathbb{E}[Y \\mid F])^2$, is estimated for each bin $k$ by $(q_k - \\bar{y}_k)^2$.\n\nCombining these, the finite-sample estimator for the reliability component, which we will denote as $\\widehat{REL}$, is:\n$$\n\\widehat{REL} = \\sum_{k=1}^{K} \\frac{n_k}{N} (q_k - \\bar{y}_k)^2\n$$\nwhere $N = \\sum_{k=1}^{K} n_k$.\n\nNow, we compute $\\widehat{REL}$ using the provided data:\n- Bin $k=1$: $q_{1} = 0.05$, $n_{1} = 40$, $\\bar{y}_{1} = 0.10$.\n- Bin $k=2$: $q_{2} = 0.15$, $n_{2} = 60$, $\\bar{y}_{2} = 0.12$.\n- Bin $k=3$: $q_{3} = 0.35$, $n_{3} = 80$, $\\bar{y}_{3} = 0.30$.\n- Bin $k=4$: $q_{4} = 0.65$, $n_{4} = 50$, $\\bar{y}_{4} = 0.60$.\n- Bin $k=5$: $q_{5} = 0.85$, $n_{5} = 70$, $\\bar{y}_{5} = 0.90$.\n\nFirst, we calculate the total number of forecast-verification pairs $N$:\n$$\nN = n_1 + n_2 + n_3 + n_4 + n_5 = 40 + 60 + 80 + 50 + 70 = 300\n$$\nNow, we calculate the term for each bin:\n- Bin 1: $\\frac{40}{300} (0.05 - 0.10)^2 = \\frac{4}{30} (-0.05)^2 = \\frac{2}{15} (0.0025) = \\frac{2}{15} \\left(\\frac{1}{400}\\right) = \\frac{2}{6000} = \\frac{1}{3000}$.\n- Bin 2: $\\frac{60}{300} (0.15 - 0.12)^2 = \\frac{6}{30} (0.03)^2 = \\frac{1}{5} (0.0009) = \\frac{1}{5} \\left(\\frac{9}{10000}\\right) = \\frac{9}{50000}$.\n- Bin 3: $\\frac{80}{300} (0.35 - 0.30)^2 = \\frac{8}{30} (0.05)^2 = \\frac{4}{15} (0.0025) = \\frac{4}{15} \\left(\\frac{1}{400}\\right) = \\frac{4}{6000} = \\frac{1}{1500}$.\n- Bin 4: $\\frac{50}{300} (0.65 - 0.60)^2 = \\frac{5}{30} (0.05)^2 = \\frac{1}{6} (0.0025) = \\frac{1}{6} \\left(\\frac{1}{400}\\right) = \\frac{1}{2400}$.\n- Bin 5: $\\frac{70}{300} (0.85 - 0.90)^2 = \\frac{7}{30} (-0.05)^2 = \\frac{7}{30} (0.0025) = \\frac{7}{30} \\left(\\frac{1}{400}\\right) = \\frac{7}{12000}$.\n\nNow we sum these contributions:\n$$\n\\widehat{REL} = \\frac{1}{3000} + \\frac{9}{50000} + \\frac{1}{1500} + \\frac{1}{2400} + \\frac{7}{12000}\n$$\nTo sum these fractions, we find a common denominator. The denominators are $3000=3\\times10^3$, $50000=5\\times10^4$, $1500=1.5\\times10^3$, $2400=2.4\\times10^3$, and $12000=1.2\\times10^4$. The least common multiple of the denominators $(3000, 50000, 1500, 2400, 12000)$ is $300000$.\nConverting each fraction to have this denominator:\n$$\n\\frac{1}{3000} = \\frac{100}{300000}\n$$\n$$\n\\frac{9}{50000} = \\frac{9 \\times 6}{50000 \\times 6} = \\frac{54}{300000}\n$$\n$$\n\\frac{1}{1500} = \\frac{200}{300000}\n$$\n$$\n\\frac{1}{2400} = \\frac{125}{300000}\n$$\n$$\n\\frac{7}{12000} = \\frac{7 \\times 25}{12000 \\times 25} = \\frac{175}{300000}\n$$\nSumming the numerators:\n$$\n100 + 54 + 200 + 125 + 175 = 654\n$$\nSo, the reliability component is:\n$$\n\\widehat{REL} = \\frac{654}{300000}\n$$\nFinally, we reduce the fraction to its simplest form. Both numerator and denominator are divisible by $6$:\n$$\n\\widehat{REL} = \\frac{654 \\div 6}{300000 \\div 6} = \\frac{109}{50000}\n$$\nSince $109$ is a prime number, this fraction is fully reduced.",
            "answer": "$$\n\\boxed{\\frac{109}{50000}}\n$$"
        },
        {
            "introduction": "A key goal of probabilistic forecasting is to inform better decision-making, which often requires converting a probability into a binary \"yes/no\" action. This exercise bridges theory and application by asking you to determine the optimal probability threshold for issuing a warning. Using the Peirce Skill Score, you will learn how to maximize the discriminatory power of a forecast system for a specific event .",
            "id": "4079041",
            "problem": "A global ensemble prediction system issues probabilistic forecasts for a rare binary extreme event defined as the daily maximum wind exceeding a fixed threshold at a given location. For each verification day, the system outputs the event probability forecast $\\hat{p}$, interpretable as the fraction of ensemble members predicting the event. Consider the following stylized but scientifically plausible parametric characterization of forecast–outcome behavior, conditioned on the verifying outcome:\n- Conditional on the event occurring, the forecast probability $\\hat{p}$ has a density $f_{1}(p)$ on $[0,1]$ given by the Beta distribution with parameters $(\\alpha_{1},\\beta_{1})=(3,1)$, i.e., $f_{1}(p)=3\\,p^{2}$ for $p \\in [0,1]$.\n- Conditional on the event not occurring, the forecast probability $\\hat{p}$ has a density $f_{0}(p)$ on $[0,1]$ given by the Beta distribution with parameters $(\\alpha_{0},\\beta_{0})=(1,3)$, i.e., $f_{0}(p)=3\\,(1-p)^{2}$ for $p \\in [0,1]$.\n\nA deterministic decision is obtained by thresholding the probability at level $\\tau \\in [0,1]$: forecast “event” if $\\hat{p} \\ge \\tau$ and “no event” otherwise. Let $\\text{TPR}(\\tau)$ denote the True Positive Rate (TPR), defined as the conditional probability of forecasting “event” given that the event occurs, and let $\\text{FPR}(\\tau)$ denote the False Positive Rate (FPR), defined as the conditional probability of forecasting “event” given that the event does not occur. The Peirce Skill Score (also known as the True Skill Statistic (TSS)) at threshold $\\tau$ is defined as $\\text{TSS}(\\tau)=\\text{TPR}(\\tau)-\\text{FPR}(\\tau)$.\n\nStarting only from these definitions and from the provided densities $f_{1}$ and $f_{0}$:\n- Derive $\\text{TPR}(\\tau)$ and $\\text{FPR}(\\tau)$ in terms of integrals of $f_{1}$ and $f_{0}$, and then obtain explicit closed-form expressions for $\\text{TSS}(\\tau)$ as a function of $\\tau$.\n- Evaluate $\\text{TSS}(\\tau)$ for the thresholds $\\tau \\in \\{0,\\tfrac{1}{4},\\tfrac{1}{2},\\tfrac{3}{4},1\\}$.\n- Identify the unique threshold $\\tau^{\\star} \\in [0,1]$ that maximizes $\\text{TSS}(\\tau)$.\n\nProvide as your final answer only the exact value of $\\tau^{\\star}$, expressed as a reduced fraction with no units. No rounding is required; express the final answer exactly.",
            "solution": "The problem is first validated against the required criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Event Definition**: A rare binary extreme event.\n- **Forecast Probability**: $\\hat{p} \\in [0,1]$, the fraction of ensemble members predicting the event.\n- **Conditional Density (Event Occurs)**: For an outcome where the event occurs, the forecast probability $\\hat{p}$ is a random variable $p$ with a probability density function $f_{1}(p)$ on $[0,1]$ given by a Beta distribution with parameters $(\\alpha_{1},\\beta_{1})=(3,1)$. This density is $f_{1}(p)=3\\,p^{2}$ for $p \\in [0,1]$.\n- **Conditional Density (Event Does Not Occur)**: For an outcome where the event does not occur, the forecast probability $\\hat{p}$ is a random variable $p$ with a probability density function $f_{0}(p)$ on $[0,1]$ given by a Beta distribution with parameters $(\\alpha_{0},\\beta_{0})=(1,3)$. This density is $f_{0}(p)=3\\,(1-p)^{2}$ for $p \\in [0,1]$.\n- **Decision Rule**: A deterministic forecast is made by thresholding the probability $\\hat{p}$ at a level $\\tau \\in [0,1]$.\n    - Forecast “event” if $\\hat{p} \\ge \\tau$.\n    - Forecast “no event” if $\\hat{p}  \\tau$.\n- **True Positive Rate (TPR)**: $\\text{TPR}(\\tau)$ is the conditional probability of forecasting “event” given that the event occurs.\n- **False Positive Rate (FPR)**: $\\text{FPR}(\\tau)$ is the conditional probability of forecasting “event” given that the event does not occur.\n- **Peirce Skill Score (TSS)**: $\\text{TSS}(\\tau) = \\text{TPR}(\\tau) - \\text{FPR}(\\tau)$.\n- **Tasks**:\n    1. Derive explicit closed-form expressions for $\\text{TPR}(\\tau)$, $\\text{FPR}(\\tau)$, and $\\text{TSS}(\\tau)$.\n    2. Evaluate $\\text{TSS}(\\tau)$ for $\\tau \\in \\{0, \\frac{1}{4}, \\frac{1}{2}, \\frac{3}{4}, 1\\}$.\n    3. Find the unique threshold $\\tau^{\\star} \\in [0,1]$ that maximizes $\\text{TSS}(\\tau)$.\n\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is well-grounded in the theory of probabilistic forecast verification, a standard topic in numerical weather prediction and climate modeling. The use of Beta distributions to model forecast probabilities, and the definitions of TPR, FPR, and TSS are standard and scientifically sound.\n- **Well-Posedness**: The problem is self-contained, providing all necessary definitions and functions. The objectives are clear and mathematically tractable. A unique solution is expected to exist.\n- **Objectivity**: The problem is stated using precise mathematical language, free from any subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A full solution will be provided.\n\n### Solution\n\nThe first task is to derive expressions for the True Positive Rate, $\\text{TPR}(\\tau)$, and the False Positive Rate, $\\text{FPR}(\\tau)$.\n\nThe $\\text{TPR}(\\tau)$ is the conditional probability that the forecast is \"event\" (i.e., $\\hat{p} \\ge \\tau$) given that the event actually occurred. The probability distribution of the forecast $\\hat{p}$ in this case is given by the density $f_{1}(p)$. Therefore, $\\text{TPR}(\\tau)$ is the integral of $f_{1}(p)$ over the range $[\\tau, 1]$.\n$$\n\\text{TPR}(\\tau) = P(\\hat{p} \\ge \\tau | \\text{event occurs}) = \\int_{\\tau}^{1} f_{1}(p) \\, dp\n$$\nSubstituting the given expression for $f_{1}(p) = 3p^2$:\n$$\n\\text{TPR}(\\tau) = \\int_{\\tau}^{1} 3p^{2} \\, dp = \\left[p^{3}\\right]_{\\tau}^{1} = 1^{3} - \\tau^{3} = 1 - \\tau^{3}\n$$\n\nThe $\\text{FPR}(\\tau)$ is the conditional probability that the forecast is \"event\" (i.e., $\\hat{p} \\ge \\tau$) given that the event did not occur. The probability distribution of the forecast $\\hat{p}$ in this case is given by the density $f_{0}(p)$. Therefore, $\\text{FPR}(\\tau)$ is the integral of $f_{0}(p)$ over the range $[\\tau, 1]$.\n$$\n\\text{FPR}(\\tau) = P(\\hat{p} \\ge \\tau | \\text{event does not occur}) = \\int_{\\tau}^{1} f_{0}(p) \\, dp\n$$\nSubstituting the given expression for $f_{0}(p) = 3(1-p)^2$:\n$$\n\\text{FPR}(\\tau) = \\int_{\\tau}^{1} 3(1-p)^{2} \\, dp\n$$\nTo evaluate this integral, we can use the substitution $u = 1-p$, which implies $du = -dp$. When $p=\\tau$, $u=1-\\tau$. When $p=1$, $u=0$.\n$$\n\\text{FPR}(\\tau) = \\int_{1-\\tau}^{0} 3u^{2} (-du) = \\int_{0}^{1-\\tau} 3u^{2} \\, du = \\left[u^{3}\\right]_{0}^{1-\\tau} = (1-\\tau)^{3} - 0^{3} = (1-\\tau)^{3}\n$$\n\nNow, we derive the expression for the Peirce Skill Score, $\\text{TSS}(\\tau)$.\n$$\n\\text{TSS}(\\tau) = \\text{TPR}(\\tau) - \\text{FPR}(\\tau) = (1 - \\tau^{3}) - (1-\\tau)^{3}\n$$\nExpanding the term $(1-\\tau)^{3}$:\n$$\n(1-\\tau)^{3} = 1^{3} - 3(1)^{2}\\tau + 3(1)\\tau^{2} - \\tau^{3} = 1 - 3\\tau + 3\\tau^{2} - \\tau^{3}\n$$\nSubstituting this back into the expression for $\\text{TSS}(\\tau)$:\n$$\n\\text{TSS}(\\tau) = (1 - \\tau^{3}) - (1 - 3\\tau + 3\\tau^{2} - \\tau^{3}) = 1 - \\tau^{3} - 1 + 3\\tau - 3\\tau^{2} + \\tau^{3}\n$$\n$$\n\\text{TSS}(\\tau) = 3\\tau - 3\\tau^{2} = 3\\tau(1-\\tau)\n$$\n\nThe second task is to evaluate $\\text{TSS}(\\tau)$ for the given thresholds.\n- For $\\tau = 0$: $\\text{TSS}(0) = 3(0)(1-0) = 0$.\n- For $\\tau = \\frac{1}{4}$: $\\text{TSS}(\\frac{1}{4}) = 3(\\frac{1}{4})(1-\\frac{1}{4}) = 3(\\frac{1}{4})(\\frac{3}{4}) = \\frac{9}{16}$.\n- For $\\tau = \\frac{1}{2}$: $\\text{TSS}(\\frac{1}{2}) = 3(\\frac{1}{2})(1-\\frac{1}{2}) = 3(\\frac{1}{2})(\\frac{1}{2}) = \\frac{3}{4}$.\n- For $\\tau = \\frac{3}{4}$: $\\text{TSS}(\\frac{3}{4}) = 3(\\frac{3}{4})(1-\\frac{3}{4}) = 3(\\frac{3}{4})(\\frac{1}{4}) = \\frac{9}{16}$.\n- For $\\tau = 1$: $\\text{TSS}(1) = 3(1)(1-1) = 0$.\n\nThe final task is to find the threshold $\\tau^{\\star}$ that maximizes $\\text{TSS}(\\tau)$ on the interval $[0,1]$. We need to find the maximum of the function $S(\\tau) = 3\\tau - 3\\tau^{2}$. This is a quadratic function of $\\tau$, representing a downward-opening parabola. The maximum occurs at its vertex. To find this point, we compute the derivative with respect to $\\tau$ and set it to zero.\n$$\n\\frac{d}{d\\tau} \\text{TSS}(\\tau) = \\frac{d}{d\\tau}(3\\tau - 3\\tau^{2}) = 3 - 6\\tau\n$$\nSetting the derivative to zero to find the critical point:\n$$\n3 - 6\\tau = 0 \\implies 6\\tau = 3 \\implies \\tau = \\frac{3}{6} = \\frac{1}{2}\n$$\nTo confirm this is a maximum, we examine the second derivative:\n$$\n\\frac{d^{2}}{d\\tau^{2}} \\text{TSS}(\\tau) = \\frac{d}{d\\tau}(3 - 6\\tau) = -6\n$$\nSince the second derivative is negative, the critical point $\\tau = \\frac{1}{2}$ is a local maximum. As this is the only critical point in the interval $[0,1]$ and the function value at the endpoints ($\\text{TSS}(0)=0$, $\\text{TSS}(1)=0$) is less than the value at the critical point ($\\text{TSS}(\\frac{1}{2}) = \\frac{3}{4}$), $\\tau^{\\star} = \\frac{1}{2}$ is the unique threshold that maximizes the Peirce Skill Score.\n\nAn alternative, more general method to find the maximum of $\\text{TSS}(\\tau)$ is to note that the derivative of $\\text{TSS}(\\tau)$ with respect to $\\tau$ is:\n$$\n\\frac{d}{d\\tau} \\text{TSS}(\\tau) = \\frac{d}{d\\tau} \\left( \\int_{\\tau}^{1} f_{1}(p) \\, dp - \\int_{\\tau}^{1} f_{0}(p) \\, dp \\right)\n$$\nUsing the Fundamental Theorem of Calculus (specifically, the Leibniz integral rule):\n$$\n\\frac{d}{d\\tau} \\text{TSS}(\\tau) = -f_{1}(\\tau) - (-f_{0}(\\tau)) = f_{0}(\\tau) - f_{1}(\\tau)\n$$\nSetting the derivative to zero implies $f_{0}(\\tau^{\\star}) = f_{1}(\\tau^{\\star})$. The optimal threshold is where the two conditional densities are equal.\n$$\n3(1-\\tau^{\\star})^{2} = 3(\\tau^{\\star})^{2}\n$$\n$$\n(1-\\tau^{\\star})^{2} = (\\tau^{\\star})^{2}\n$$\nTaking the square root of both sides:\n$$\n1-\\tau^{\\star} = \\pm \\tau^{\\star}\n$$\nSince $\\tau^{\\star}$ must be in $[0,1]$, we take the positive root $1-\\tau^{\\star} = \\tau^{\\star}$ (the negative root $1-\\tau^{\\star} = -\\tau^{\\star}$ yields $1=0$, which is a contradiction).\n$$\n1 = 2\\tau^{\\star} \\implies \\tau^{\\star} = \\frac{1}{2}\n$$\nThis confirms the previous result. The unique threshold that maximizes the Peirce Skill Score is $\\tau^{\\star} = \\frac{1}{2}$.",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        }
    ]
}