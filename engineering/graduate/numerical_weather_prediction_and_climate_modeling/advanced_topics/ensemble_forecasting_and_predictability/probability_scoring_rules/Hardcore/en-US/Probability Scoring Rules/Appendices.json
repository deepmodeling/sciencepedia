{
    "hands_on_practices": [
        {
            "introduction": "This exercise serves as a fundamental exploration of the Brier score, a cornerstone for verifying probabilistic forecasts of binary events. By first calculating the expected score for a hypothetical perfect forecast, we establish a theoretical baseline for ideal performance. We then investigate how this baseline is compromised by the presence of observation error, a practical challenge in any real-world verification system. ",
            "id": "4079336",
            "problem": "Consider a binary event verification setting in numerical weather prediction and climate modeling, where the event indicator is denoted by $y \\in \\{0,1\\}$ and a forecast issues a probability $p \\in [0,1]$. The Brier score for a single binary forecast-observation pair is defined as $S(p,y) = (p - y)^{2}$. Suppose there exists a deterministic oracle that has access to the true event and issues $p = y$ for every case.\n\nNow consider two verification scenarios:\n- Perfect verification: the evaluation uses the true indicator $y$.\n- Observation error: the verification uses a corrupted indicator $\\tilde{y}$ such that, conditional on $y$, the observed $\\tilde{y}$ equals $y$ with probability $1 - \\epsilon$ and equals $1 - y$ with probability $\\epsilon$, where $0 \\leq \\epsilon \\leq 1$. Assume the misclassification is independent of the forecast and of the data-generating mechanism for $y$.\n\nUnder these assumptions, derive from first principles the expected Brier score in each scenario for the deterministic oracle $p = y$. In the observation error scenario, the expectation must be taken with respect to the joint distribution induced by the true $y$ and the error process for $\\tilde{y}$, and the final answer must be expressed purely as a function of $\\epsilon$ (i.e., it must not depend on the distribution of $y$).\n\nProvide the final answer as a two-entry row matrix containing:\n- the expected Brier score under perfect verification, and\n- the expected Brier score under the observation error model described above.\n\nNo numerical approximation is required. If you choose to simplify, express any final expression in exact symbolic form. The final answer must be unitless and expressed exactly.",
            "solution": "The problem asks for the expected Brier score for a deterministic oracle under two distinct verification scenarios: one with perfect observations and one with corrupted observations. We will address each scenario separately.\n\nThe Brier score for a single forecast-observation pair is given by $S(p,y) = (p - y)^{2}$, where $p \\in [0,1]$ is the forecast probability and $y \\in \\{0,1\\}$ is the binary event indicator.\nThe deterministic oracle is defined as having perfect knowledge of the true event, thus issuing the forecast $p = y$.\n\n**Scenario 1: Perfect Verification**\nIn this scenario, the evaluation uses the true event indicator, $y$. The forecast from the oracle is $p = y$. We substitute this into the Brier score definition:\n$$\nS(p,y) = S(y,y) = (y - y)^{2}\n$$\nFor any realization of the event, whether $y=0$ or $y=1$, the score is:\n$$\nS(y,y) = (0)^{2} = 0\n$$\nSince the score is identically $0$ for every possible outcome of the event $y$, its expected value is also $0$. Let $E[\\cdot]$ denote the expectation operator over the distribution of $y$.\n$$\nE[S(p,y)] = E[(y-y)^{2}] = E[0] = 0\n$$\nTherefore, the expected Brier score for the perfect oracle under perfect verification is $0$. This result is independent of the underlying climatological probability of the event $y$.\n\n**Scenario 2: Observation Error**\nIn this scenario, the evaluation uses a corrupted event indicator, $\\tilde{y}$. The oracle's forecast remains based on the true event, so $p=y$. The Brier score is now calculated as $S(p, \\tilde{y}) = (p - \\tilde{y})^{2}$. Substituting $p=y$, the score becomes:\n$$\nS(y, \\tilde{y}) = (y - \\tilde{y})^{2}\n$$\nWe are asked to compute the expected value of this score, $E[(y - \\tilde{y})^{2}]$, where the expectation is taken over the joint distribution of the true event $y$ and the corrupted observation $\\tilde{y}$. We can compute this using the law of total expectation, conditioning on the true event $y$:\n$$\nE[(y - \\tilde{y})^{2}] = E_{y} \\left[ E_{\\tilde{y}|y} \\left[ (y - \\tilde{y})^{2} | y \\right] \\right]\n$$\nLet's first compute the inner expectation, which is the expected score conditional on a specific realization of the true event $y$. The distribution of the corrupted observation $\\tilde{y}$ is given as conditional on $y$:\n$P(\\tilde{y} = y | y) = 1 - \\epsilon$\n$P(\\tilde{y} = 1 - y | y) = \\epsilon$\n\nThe term $(y - \\tilde{y})^{2}$ can take on two possible values depending on the value of $\\tilde{y}$:\n1. If $\\tilde{y} = y$ (no error), then $(y - \\tilde{y})^{2} = (y-y)^{2} = 0$. This occurs with probability $1 - \\epsilon$.\n2. If $\\tilde{y} = 1 - y$ (error), then $(y - \\tilde{y})^{2} = (y - (1-y))^{2} = (2y - 1)^{2}$. This occurs with probability $\\epsilon$.\n\nThe inner conditional expectation is therefore:\n$$\nE_{\\tilde{y}|y} \\left[ (y - \\tilde{y})^{2} | y \\right] = 0 \\cdot P(\\tilde{y}=y|y) + (2y - 1)^{2} \\cdot P(\\tilde{y}=1-y|y)\n$$\n$$\nE_{\\tilde{y}|y} \\left[ (y - \\tilde{y})^{2} | y \\right] = 0 \\cdot (1-\\epsilon) + (2y - 1)^{2} \\cdot \\epsilon = (2y - 1)^{2} \\epsilon\n$$\nNow, we must compute the outer expectation over the distribution of the true event $y$:\n$$\nE[(y - \\tilde{y})^{2}] = E_{y} \\left[ (2y - 1)^{2} \\epsilon \\right]\n$$\nSince $\\epsilon$ is a constant, we can pull it out of the expectation:\n$$\nE[(y - \\tilde{y})^{2}] = \\epsilon \\cdot E_{y} \\left[ (2y - 1)^{2} \\right]\n$$\nThe random variable $y$ can only take values in $\\{0, 1\\}$. Let's evaluate the term $(2y-1)^{2}$ for each case:\n- If $y=1$, then $(2(1)-1)^{2} = (1)^{2} = 1$.\n- If $y=0$, then $(2(0)-1)^{2} = (-1)^{2} = 1$.\nIn both possible states for the true event $y$, the quantity $(2y-1)^{2}$ is identically equal to $1$. Therefore, its expectation is also $1$, regardless of the probability distribution of $y$ (i.e., regardless of $P(y=1)$):\n$$\nE_{y} \\left[ (2y - 1)^{2} \\right] = 1\n$$\nSubstituting this back into our expression for the total expected score:\n$$\nE[(y - \\tilde{y})^{2}] = \\epsilon \\cdot 1 = \\epsilon\n$$\nThe expected Brier score for the perfect oracle under the specified observation error model is $\\epsilon$. This result depends only on the error probability $\\epsilon$ and not on the climatology of the event $y$, as required by the problem statement.\n\nTo summarize, the two required values are:\n1. Expected Brier score under perfect verification: $0$.\n2. Expected Brier score under observation error: $\\epsilon$.\n\nThese are presented as a two-entry row matrix.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0  \\epsilon\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Beyond a single summary score, a thorough forecast evaluation must distinguish between a forecast's ability to rank events by likelihood (discrimination) and its statistical reliability (calibration). This practice problem delves into this critical distinction by proving that the Receiver Operating Characteristic (ROC) curve is a measure of pure discrimination, invariant to calibration errors. In contrast, you will show that precision is sensitive to calibration, thereby solidifying your understanding of how different metrics assess different aspects of forecast quality. ",
            "id": "4079328",
            "problem": "In the context of numerical weather prediction, consider probabilistic forecasts for a binary event $Y \\in \\{0,1\\}$ indicating whether daily rainfall at a given station exceeds a scientifically meaningful threshold (for example, $20 \\, \\mathrm{mm}$). Let a forecast system output a scalar score $s \\in [0,1]$ used to rank the likelihood of $Y=1$. A calibrated probability forecast $p$ is a measurable function of $s$ satisfying the defining property of calibration: for almost every $\\lambda \\in [0,1]$, $P(Y=1 \\mid p=\\lambda)=\\lambda$. A recalibrated or miscalibrated forecast is $q=g(p)$ for a strictly increasing function $g:[0,1]\\to[0,1]$ that is not the identity and does not in general satisfy $P(Y=1 \\mid q=\\lambda)=\\lambda$.\n\nReceiver Operating Characteristic (ROC) analysis evaluates ranking skill by the set of pairs $(\\mathrm{TPR}(\\theta),\\mathrm{FPR}(\\theta))$ traced as a classification threshold varies, where $\\mathrm{TPR}(\\theta)=P(s \\ge \\theta \\mid Y=1)$ and $\\mathrm{FPR}(\\theta)=P(s \\ge \\theta \\mid Y=0)$. Precision (also called positive predictive value) at threshold $\\tau \\in (0,1)$ is $P(Y=1 \\mid p \\ge \\tau)$ for the calibrated forecast and $P(Y=1 \\mid q \\ge \\tau)$ for the miscalibrated forecast, with prediction rule “predict $Y=1$ if the forecast probability is at least $\\tau$.”\n\nStarting from the fundamental definitions above and Bayes’ theorem, do the following:\n\n1. Prove that strictly increasing calibration transformations $q=g(p)$ do not alter the ROC curve, in the sense that the set $\\{(\\mathrm{TPR}(\\theta),\\mathrm{FPR}(\\theta)):\\theta \\in [0,1]\\}$ obtained by thresholding $p$ is identical to the set obtained by thresholding $q$ (up to reparameterization of the threshold). Your argument must begin from the definitions of $\\mathrm{TPR}$ and $\\mathrm{FPR}$ and the property that $g$ is strictly increasing; you may not invoke any pre-derived ROC invariance formula.\n\n2. Prove that calibration transformations $q=g(p)$ do affect precision at a fixed numeric threshold $\\tau$, and isolate the mechanism “via the denominator” by deriving an expression for $P(Y=1 \\mid q \\ge \\tau)$ in terms of $P(p \\ge g^{-1}(\\tau) \\mid Y=1)$ and $P(p \\ge g^{-1}(\\tau) \\mid Y=0)$, explicitly showing the role of $P(q \\ge \\tau)$.\n\n3. Construct a calibrated versus miscalibrated forecast pair with identical ROC but different precision, by specifying a scientifically plausible conditional distribution of the ranking score $s$ under $Y=1$ and $Y=0$, a base rate $P(Y=1)$ consistent with extreme-rainfall climatology, and a strictly increasing recalibration function $g$. Use the following concrete choice: $P(Y=1)=\\pi$ with $\\pi=0.3$, the conditional distribution $s \\mid Y=1 \\sim \\mathrm{Uniform}(0.2, 1)$ and $s \\mid Y=0 \\sim \\mathrm{Uniform}(0, 0.9)$, the calibrated probability $p=s$, and the miscalibrated probability $q=g(p)$ with $g(x)=x^{2}$. Adopt the operational warning threshold $\\tau=0.64$ (which equals $\\frac{16}{25}$). Compute the precision for the calibrated forecast at threshold $\\tau$ and for the miscalibrated forecast at the same numeric threshold $\\tau$, and then compute their difference “miscalibrated minus calibrated.” Express your final answer as a single reduced rational number with no units. No rounding is required.",
            "solution": "The problem addresses the distinction between two key attributes of a probabilistic forecast: discrimination and calibration. Discrimination, the ability to separate events from non-events, is measured by the ROC curve. Calibration refers to the statistical consistency of the forecast probabilities. We are asked to prove that the ROC curve is invariant to calibration transformations, whereas precision (a metric that depends on both discrimination and calibration, as well as the base rate) is not.\n\nThroughout this analysis, we identify the ranking score $s$ with the calibrated probability $p$, as specified for the concrete example in Part 3. The quantities $\\mathrm{TPR}$ and $\\mathrm{FPR}$ can thus be defined by thresholding $p$.\n\n**Part 1: Proof of ROC Invariance**\n\nThe ROC curve is a plot of the True Positive Rate against the False Positive Rate for all possible classification thresholds. For the forecast $p$, the set of points on its ROC curve, $\\mathcal{C}_p$, is given by:\n$$ \\mathcal{C}_p = \\{ (P(p \\ge \\theta \\mid Y=1), P(p \\ge \\theta \\mid Y=0)) : \\theta \\in [0,1] \\} $$\nFor the transformed forecast $q=g(p)$, the ROC curve, $\\mathcal{C}_q$, is similarly defined by thresholding $q$:\n$$ \\mathcal{C}_q = \\{ (P(q \\ge \\theta' \\mid Y=1), P(q \\ge \\theta' \\mid Y=0)) : \\theta' \\in [0,1] \\} $$\nWe are given that $g: [0,1] \\to [0,1]$ is a strictly increasing function. This property implies that $g$ has a strictly increasing inverse, $g^{-1}$, defined on the range of $g$. The condition $a \\ge b$ is equivalent to $g(a) \\ge g(b)$, and likewise $c \\ge d$ is equivalent to $g^{-1}(c) \\ge g^{-1}(d)$ for $c, d$ in the range of $g$.\n\nLet's show that any point on $\\mathcal{C}_q$ is also on $\\mathcal{C}_p$.\nConsider an arbitrary point on $\\mathcal{C}_q$ generated by a threshold $\\theta'$. The coordinates of this point are $(P(q \\ge \\theta' \\mid Y=1), P(q \\ge \\theta' \\mid Y=0))$.\nThe inequality $q \\ge \\theta'$ is equivalent to $g(p) \\ge \\theta'$. Because $g$ is strictly increasing, we can apply its inverse $g^{-1}$ to both sides without changing the inequality's direction. This gives $p \\ge g^{-1}(\\theta')$.\nLet us define a new threshold $\\theta = g^{-1}(\\theta')$. As $\\theta'$ sweeps its domain (the range of $g$), $\\theta$ sweeps the domain of $g$, which is $[0,1]$.\nTherefore, the coordinates of the point on $\\mathcal{C}_q$ can be rewritten:\n$$ P(q \\ge \\theta' \\mid Y=1) = P(p \\ge g^{-1}(\\theta') \\mid Y=1) = P(p \\ge \\theta \\mid Y=1) $$\n$$ P(q \\ge \\theta' \\mid Y=0) = P(p \\ge g^{-1}(\\theta') \\mid Y=0) = P(p \\ge \\theta \\mid Y=0) $$\nThis demonstrates that any point on the ROC curve for $q$ is identical to a point on the ROC curve for $p$ associated with the threshold $\\theta = g^{-1}(\\theta')$. Thus, $\\mathcal{C}_q \\subseteq \\mathcal{C}_p$.\n\nConversely, let's show that any point on $\\mathcal{C}_p$ is also on $\\mathcal{C}_q$.\nConsider a point on $\\mathcal{C}_p$ generated by a threshold $\\theta$. The condition is $p \\ge \\theta$. Since $g$ is strictly increasing, this is equivalent to $g(p) \\ge g(\\theta)$.\nLet us define a new threshold $\\theta' = g(\\theta)$. The condition becomes $q \\ge \\theta'$.\nThe coordinates of the point on $\\mathcal{C}_p$ can be rewritten:\n$$ P(p \\ge \\theta \\mid Y=1) = P(g(p) \\ge g(\\theta) \\mid Y=1) = P(q \\ge \\theta' \\mid Y=1) $$\n$$ P(p \\ge \\theta \\mid Y=0) = P(g(p) \\ge g(\\theta) \\mid Y=0) = P(q \\ge \\theta' \\mid Y=0) $$\nThis shows that any point on the ROC curve for $p$ is identical to a point on the ROC curve for $q$ associated with the threshold $\\theta' = g(\\theta)$. Thus, $\\mathcal{C}_p \\subseteq \\mathcal{C}_q$.\n\nSince $\\mathcal{C}_q \\subseteq \\mathcal{C}_p$ and $\\mathcal{C}_p \\subseteq \\mathcal{C}_q$, the two sets are identical: $\\mathcal{C}_p = \\mathcal{C}_q$. The transformation $g$ only reparameterizes the curve. This concludes the proof.\n\n**Part 2: Effect of Calibration on Precision**\n\nPrecision, or Positive Predictive Value (PPV), is defined as $P(Y=1 \\mid \\text{forecast} \\ge \\tau)$. For the miscalibrated forecast $q$ at a fixed numeric threshold $\\tau$, the precision is $P(Y=1 \\mid q \\ge \\tau)$.\nUsing the definition of conditional probability (Bayes' theorem):\n$$ P(Y=1 \\mid q \\ge \\tau) = \\frac{P(q \\ge \\tau \\mid Y=1) P(Y=1)}{P(q \\ge \\tau)} $$\nThe problem asks to show the role of the denominator, $P(q \\ge \\tau)$, and to express the numerator in terms of probabilities involving $p$.\nAs shown in Part 1, the event $q \\ge \\tau$ is identical to the event $p \\ge g^{-1}(\\tau)$.\nThus, we can rewrite the numerator term $P(q \\ge \\tau \\mid Y=1)$ as $P(p \\ge g^{-1}(\\tau) \\mid Y=1)$.\nSubstituting this into the expression for precision gives:\n$$ P(Y=1 \\mid q \\ge \\tau) = \\frac{P(p \\ge g^{-1}(\\tau) \\mid Y=1) P(Y=1)}{P(q \\ge \\tau)} $$\nThis expression isolates the mechanism \"via the denominator\" by explicitly showing $P(q \\ge \\tau)$.\nTo expand the denominator and show the full dependence, we use the law of total probability:\n$$ P(q \\ge \\tau) = P(q \\ge \\tau \\mid Y=1)P(Y=1) + P(q \\ge \\tau \\mid Y=0)P(Y=0) $$\nAgain, using the equivalence of events, this becomes:\n$$ P(q \\ge \\tau) = P(p \\ge g^{-1}(\\tau) \\mid Y=1)P(Y=1) + P(p \\ge g^{-1}(\\tau) \\mid Y=0)P(Y=0) $$\nThe precision for the calibrated forecast $p$ at the same numeric threshold $\\tau$ is:\n$$ P(Y=1 \\mid p \\ge \\tau) = \\frac{P(p \\ge \\tau \\mid Y=1) P(Y=1)}{P(p \\ge \\tau)} $$\nSince $g$ is not the identity function, in general $g^{-1}(\\tau) \\neq \\tau$. This means the condition for issuing a warning is different for the two forecasts, $p \\ge g^{-1}(\\tau)$ versus $p \\ge \\tau$. Consequently, both the true positive rate for the warning ($P(p \\ge \\text{threshold} \\mid Y=1)$) and the overall probability of issuing a warning ($P(p \\ge \\text{threshold})$) are different. This leads to different precision values for the calibrated and miscalibrated forecasts at the same numeric threshold $\\tau$.\n\n**Part 3: Concrete Example and Calculation**\n\nWe are given:\n-   $P(Y=1) = \\pi = 0.3 = \\frac{3}{10}$, so $P(Y=0) = 1-\\pi = 0.7 = \\frac{7}{10}$.\n-   The PDF of $s$ given $Y=1$ is $f_1(s) = \\frac{1}{1-0.2} = \\frac{1}{0.8} = \\frac{5}{4}$ for $s \\in [0.2, 1]$.\n-   The PDF of $s$ given $Y=0$ is $f_0(s) = \\frac{1}{0.9-0} = \\frac{1}{0.9} = \\frac{10}{9}$ for $s \\in [0, 0.9]$.\n-   Calibrated forecast $p=s$. Miscalibrated forecast $q=p^2=s^2$.\n-   Threshold $\\tau=0.64 = \\frac{16}{25}$.\n\nFirst, we calculate the precision for the calibrated forecast, $\\text{Prec}_p = P(Y=1 \\mid p \\ge \\tau) = P(Y=1 \\mid s \\ge 0.64)$.\nBy Bayes' theorem: $\\text{Prec}_p = \\frac{P(s \\ge 0.64 \\mid Y=1)P(Y=1)}{P(s \\ge 0.64)}$.\n\nCalculate the conditional probabilities:\n$P(s \\ge 0.64 \\mid Y=1) = \\int_{0.64}^{1} f_1(s) ds = \\int_{0.64}^{1} \\frac{5}{4} ds = \\frac{5}{4}[s]_{0.64}^{1} = \\frac{5}{4}(1 - 0.64) = \\frac{5}{4}(0.36) = \\frac{9}{20}$.\n$P(s \\ge 0.64 \\mid Y=0) = \\int_{0.64}^{0.9} f_0(s) ds = \\int_{0.64}^{0.9} \\frac{10}{9} ds = \\frac{10}{9}[s]_{0.64}^{0.9} = \\frac{10}{9}(0.9 - 0.64) = \\frac{10}{9}(0.26) = \\frac{26}{90} = \\frac{13}{45}$.\n\nCalculate the total probability of an alarm, $P(s \\ge 0.64)$:\n$P(s \\ge 0.64) = P(s \\ge 0.64 \\mid Y=1)P(Y=1) + P(s \\ge 0.64 \\mid Y=0)P(Y=0)$\n$P(s \\ge 0.64) = \\left(\\frac{9}{20}\\right)\\left(\\frac{3}{10}\\right) + \\left(\\frac{13}{45}\\right)\\left(\\frac{7}{10}\\right) = \\frac{27}{200} + \\frac{91}{450} = \\frac{27 \\times 9}{1800} + \\frac{91 \\times 4}{1800} = \\frac{243+364}{1800} = \\frac{607}{1800}$.\n\nNow, compute $\\text{Prec}_p$:\n$\\text{Prec}_p = \\frac{(9/20)(3/10)}{607/1800} = \\frac{27/200}{607/1800} = \\frac{27}{200} \\times \\frac{1800}{607} = \\frac{27 \\times 9}{607} = \\frac{243}{607}$.\n\nNext, we calculate the precision for the miscalibrated forecast, $\\text{Prec}_q = P(Y=1 \\mid q \\ge \\tau)$.\nThe condition is $q \\ge 0.64$, which is $s^2 \\ge 0.64$. Since $s \\ge 0$, this is equivalent to $s \\ge \\sqrt{0.64} = 0.8$.\nSo, $\\text{Prec}_q = P(Y=1 \\mid s \\ge 0.8) = \\frac{P(s \\ge 0.8 \\mid Y=1)P(Y=1)}{P(s \\ge 0.8)}$.\n\nCalculate the new conditional probabilities:\n$P(s \\ge 0.8 \\mid Y=1) = \\int_{0.8}^{1} \\frac{5}{4} ds = \\frac{5}{4}(1 - 0.8) = \\frac{5}{4}(0.2) = \\frac{1}{4}$.\n$P(s \\ge 0.8 \\mid Y=0) = \\int_{0.8}^{0.9} \\frac{10}{9} ds = \\frac{10}{9}(0.9 - 0.8) = \\frac{10}{9}(0.1) = \\frac{1}{9}$.\n\nCalculate the new total probability of an alarm, $P(s \\ge 0.8)$:\n$P(s \\ge 0.8) = P(s \\ge 0.8 \\mid Y=1)P(Y=1) + P(s \\ge 0.8 \\mid Y=0)P(Y=0)$\n$P(s \\ge 0.8) = \\left(\\frac{1}{4}\\right)\\left(\\frac{3}{10}\\right) + \\left(\\frac{1}{9}\\right)\\left(\\frac{7}{10}\\right) = \\frac{3}{40} + \\frac{7}{90} = \\frac{27}{360} + \\frac{28}{360} = \\frac{55}{360} = \\frac{11}{72}$.\n\nNow, compute $\\text{Prec}_q$:\n$\\text{Prec}_q = \\frac{(1/4)(3/10)}{11/72} = \\frac{3/40}{11/72} = \\frac{3}{40} \\times \\frac{72}{11} = \\frac{3 \\times 9}{5 \\times 11} = \\frac{27}{55}$.\n\nFinally, we compute the difference: miscalibrated minus calibrated precision.\nDifference $= \\text{Prec}_q - \\text{Prec}_p = \\frac{27}{55} - \\frac{243}{607}$.\nTo subtract, we find a common denominator, which is $55 \\times 607 = 33385$.\nDifference $= \\frac{27 \\times 607}{55 \\times 607} - \\frac{243 \\times 55}{55 \\times 607} = \\frac{16389 - 13365}{33385} = \\frac{3024}{33385}$.\nThe denominator is $33385 = 5 \\times 11 \\times 607$. The prime $607$ is not a factor of the numerator $3024$ (since $5 \\times 607 = 3035$). The numerator is not divisible by $5$ or $11$. Therefore, the fraction is in its reduced form.",
            "answer": "$$\\boxed{\\frac{3024}{33385}}$$"
        },
        {
            "introduction": "Moving from binary events to continuous variables like temperature requires a different scoring rule, the Continuous Ranked Probability Score (CRPS). This hands-on exercise addresses the practical task of evaluating a modern ensemble forecast, which consists of multiple model runs. You will derive an efficient, computationally tractable formula for the ensemble CRPS, a crucial skill for processing and verifying the large datasets generated in operational numerical weather prediction. ",
            "id": "4079332",
            "problem": "A numerical weather prediction system issues an equally weighted ensemble forecast of daily $2$-meter air temperature (Kelvin) for a single location, with $m$ ensemble members $\\{x_{i}\\}_{i=1}^{m}$ and a verifying observation $y$. The task is to evaluate the quality of this probabilistic forecast using the Continuous Ranked Probability Score (CRPS), defined for a forecast cumulative distribution function $F$ and observation $y$ by the integral\n$$\n\\mathrm{CRPS}(F,y) = \\int_{-\\infty}^{\\infty} \\left(F(z) - \\mathbb{1}\\{z \\ge y\\}\\right)^{2} \\, dz,\n$$\nwhere $\\mathbb{1}\\{\\cdot\\}$ denotes the indicator function. For an equally weighted ensemble, the forecast cumulative distribution function is the empirical distribution\n$$\nF(z) = \\frac{1}{m} \\sum_{i=1}^{m} \\mathbb{1}\\{x_{i} \\le z\\}.\n$$\nStarting only from these definitions, derive a closed-form algebraic expression for $\\mathrm{CRPS}(F,y)$ in terms of the sorted ensemble $\\{x_{(i)}\\}_{i=1}^{m}$, the observation $y$, and cumulative sums that can be computed after sorting. Your expression must make clear how to achieve an algorithm with computational complexity $\\mathcal{O}(m \\log m)$ by sorting $\\{x_{i}\\}$ and using cumulative sums to evaluate the needed quantities.\n\nThen, apply your derived expression to the following ensemble (Kelvin) and observation (Kelvin), given in unsorted order:\n$$\n\\{x_{i}\\}_{i=1}^{8} = \\{300, 295, 303, 289, 298, 301, 296, 292\\}, \\quad y = 297.\n$$\nCompute the CRPS in Kelvin and round your final numerical answer to four significant figures. Express the final score in Kelvin. For context, note that other probability scoring rules such as the Brier Score (BS) and the Receiver Operating Characteristic (ROC) curve target different aspects of forecast quality, but this problem focuses on the CRPS.",
            "solution": "The problem requires the derivation of a closed-form expression for the Continuous Ranked Probability Score (CRPS) for an equally weighted ensemble forecast, starting from its integral definition. The CRPS for a forecast cumulative distribution function (CDF) $F$ and a scalar observation $y$ is given by\n$$\n\\mathrm{CRPS}(F,y) = \\int_{-\\infty}^{\\infty} \\left(F(z) - \\mathbb{1}\\{z \\ge y\\}\\right)^{2} \\, dz\n$$\nwhere $\\mathbb{1}\\{\\cdot\\}$ is the indicator function. The ensemble-based forecast CDF is the empirical distribution of the $m$ ensemble members $\\{x_i\\}_{i=1}^m$:\n$$\nF(z) = \\frac{1}{m} \\sum_{i=1}^{m} \\mathbb{1}\\{x_{i} \\le z\\}\n$$\nThe indicator function $\\mathbb{1}\\{z \\ge y\\}$ is equivalent to the Heaviside step function $H(z-y)$. We can split the integral at $z=y$:\n$$\n\\mathrm{CRPS}(F,y) = \\int_{-\\infty}^{y} \\left(F(z) - 0\\right)^{2} \\, dz + \\int_{y}^{\\infty} \\left(F(z) - 1\\right)^{2} \\, dz = \\int_{-\\infty}^{y} F(z)^2 \\, dz + \\int_{y}^{\\infty} \\left(1 - F(z)\\right)^2 \\, dz\n$$\nTo evaluate these integrals, we must first sort the ensemble members in non-decreasing order, denoted $\\{x_{(i)}\\}_{i=1}^{m}$, where $x_{(1)} \\le x_{(2)} \\le \\dots \\le x_{(m)}$. The empirical CDF $F(z)$ is a step function that is piecewise constant. Its value increases by $1/m$ at each $x_{(i)}$. Specifically, for $z$ in an interval $[x_{(i)}, x_{(i+1)})$, the number of ensemble members less than or equal to $z$ is $i$, so $F(z) = i/m$. For convenience, we define $x_{(0)} = -\\infty$ and $x_{(m+1)} = \\infty$.\nLet $k$ be the number of ensemble members less than or equal to the observation $y$. We can find $k$ such that $x_{(k)} \\le y  x_{(k+1)}$ (with $k=0$ if $y  x_{(1)}$ and $k=m$ if $y \\ge x_{(m)}$).\n\nLet's evaluate the first integral, $I_1 = \\int_{-\\infty}^{y} F(z)^2 \\, dz$. We partition the integration domain $(-\\infty, y]$ using the sorted ensemble members up to $x_{(k)}$.\n\\begin{align*}\nI_1 = \\sum_{i=0}^{k-1} \\int_{x_{(i)}}^{x_{(i+1)}} F(z)^2 \\, dz + \\int_{x_{(k)}}^{y} F(z)^2 \\, dz \\\\\n= \\sum_{i=1}^{k-1} \\int_{x_{(i)}}^{x_{(i+1)}} \\left(\\frac{i}{m}\\right)^2 \\, dz + \\int_{x_{(k)}}^{y} \\left(\\frac{k}{m}\\right)^2 \\, dz \\quad (\\text{since } F(z)=0 \\text{ for } zx_{(1)}) \\\\\n= \\frac{1}{m^2} \\left[ \\sum_{i=1}^{k-1} i^2 (x_{(i+1)} - x_{(i)}) + k^2 (y - x_{(k)}) \\right]\n\\end{align*}\nThe sum can be rearranged via summation by parts:\n\\begin{align*}\n\\sum_{i=1}^{k-1} i^2 (x_{(i+1)} - x_{(i)}) = \\sum_{i=1}^{k-1} i^2 x_{(i+1)} - \\sum_{i=1}^{k-1} i^2 x_{(i)} \\\\\n= \\sum_{j=2}^{k} (j-1)^2 x_{(j)} - \\sum_{i=1}^{k-1} i^2 x_{(i)} \\\\\n= -x_{(1)} + \\sum_{i=2}^{k-1} \\left((i-1)^2 - i^2\\right) x_{(i)} + (k-1)^2 x_{(k)} \\\\\n= -x_{(1)} + \\sum_{i=2}^{k-1} (1-2i) x_{(i)} + (k^2-2k+1) x_{(k)}\n\\end{align*}\nSubstituting this back into the expression for $I_1$:\n$$\nm^2 I_1 = -x_{(1)} + \\sum_{i=2}^{k-1} (1-2i) x_{(i)} + (k^2-2k+1) x_{(k)} + k^2 y - k^2 x_{(k)} = k^2 y + \\sum_{i=1}^{k} (1-2i) x_{(i)}\n$$\nSo, $I_1 = \\frac{1}{m^2} \\left[ k^2 y + \\sum_{i=1}^{k} (1-2i) x_{(i)} \\right]$.\n\nNow we evaluate the second integral, $I_2 = \\int_{y}^{\\infty} (1-F(z))^2 \\, dz$.\n\\begin{align*}\nI_2 = \\int_{y}^{x_{(k+1)}} (1 - F(z))^2 \\, dz + \\sum_{i=k+1}^{m-1} \\int_{x_{(i)}}^{x_{(i+1)}} (1 - F(z))^2 \\, dz \\\\\n= \\int_{y}^{x_{(k+1)}} \\left(1-\\frac{k}{m}\\right)^2 \\, dz + \\sum_{i=k+1}^{m-1} \\int_{x_{(i)}}^{x_{(i+1)}} \\left(1-\\frac{i}{m}\\right)^2 \\, dz \\quad (\\text{since } 1-F(z)=0 \\text{ for } z \\ge x_{(m)}) \\\\\n= \\frac{1}{m^2} \\left[ (m-k)^2 (x_{(k+1)} - y) + \\sum_{i=k+1}^{m-1} (m-i)^2 (x_{(i+1)} - x_{(i)}) \\right]\n\\end{align*}\nUsing a similar summation by parts for the sum term, we find:\n$$\nm^2 I_2 = (m-k)^2 (x_{(k+1)} - y) - (m-k-1)^2 x_{(k+1)} + \\sum_{i=k+2}^{m-1} ((m-i+1)^2 - (m-i)^2) x_{(i)} + x_{(m)}\n$$\nThe coefficient becomes $2(m-i)+1$. This yields:\n$$\nm^2 I_2 = -(m-k)^2 y + (2(m-k)-1)x_{(k+1)} + \\sum_{i=k+2}^{m} (2(m-i)+1)x_{(i)} = -(m-k)^2 y + \\sum_{i=k+1}^{m} (2(m-i)+1) x_{(i)}\n$$\nSo, $I_2 = \\frac{1}{m^2} \\left[ -(m-k)^2 y + \\sum_{i=k+1}^{m} (2(m-i)+1) x_{(i)} \\right]$.\n\nCombining $I_1$ and $I_2$:\n\\begin{align*}\n\\mathrm{CRPS} = I_1 + I_2 \\\\\n= \\frac{1}{m^2} \\left[ (k^2 - (m-k)^2) y + \\sum_{i=1}^{k} (1-2i) x_{(i)} + \\sum_{i=k+1}^{m} (2m-2i+1) x_{(i)} \\right] \\\\\n= \\frac{m(2k-m)}{m^2} y + \\frac{1}{m^2} \\left[ \\sum_{i=1}^{k} (1-2i) x_{(i)} + \\sum_{i=k+1}^{m} (2m-2i+1) x_{(i)} \\right]\n\\end{align*}\nThis expression can be computed in $\\mathcal{O}(m \\log m)$ due to sorting, followed by $\\mathcal{O}(m)$ for the sums. To make the use of cumulative sums explicit, we can simplify the summation term. Let $S_j = \\sum_{i=1}^j x_{(i)}$ and $W_j = \\sum_{i=1}^j i x_{(i)}$.\nThe summation term is $\\sum_{i=1}^m A_i x_{(i)}$ where $A_i = (1-2i)$ if $i \\le k$ and $A_i = (2m-2i+1)$ if $i  k$.\nThis can be rewritten as:\n$$\n\\sum_{i=1}^m (2m-2i+1)x_{(i)} - \\sum_{i=1}^k ( (2m-2i+1) - (1-2i) ) x_{(i)} \\\\\n= (2m+1)S_m - 2W_m - \\sum_{i=1}^k (2m) x_{(i)} \\\\\n= (2m+1)S_m - 2W_m - 2m S_k\n$$\nThus, the final expression for the CRPS is:\n$$\n\\mathrm{CRPS}(F,y) = \\frac{2k-m}{m} y + \\frac{1}{m^2} \\left[ (2m+1)\\sum_{i=1}^m x_{(i)} - 2\\sum_{i=1}^m i x_{(i)} - 2m\\sum_{i=1}^k x_{(i)} \\right]\n$$\nThis form shows that after sorting the ensemble members ($\\mathcal{O}(m \\log m)$), one can precompute the cumulative sum of members $S_m$, the weighted sum of members $W_m$, and the partial cumulative sums $S_k$ ($\\mathcal{O}(m)$). For any given observation $y$, finding $k$ takes $\\mathcal{O}(\\log m)$ via binary search, and the CRPS is then computed in $\\mathcal{O}(1)$.\n\nNow, we apply this formula to the given data.\nEnsemble: $\\{x_{i}\\}_{i=1}^{8} = \\{300, 295, 303, 289, 298, 301, 296, 292\\}$.\nObservation: $y = 297 \\, \\mathrm{K}$.\nNumber of members: $m=8$.\n\n1.  Sort the ensemble:\n    $\\{x_{(i)}\\}_{i=1}^{8} = \\{289, 292, 295, 296, 298, 300, 301, 303\\}$.\n\n2.  Determine $k$, the number of members $\\le y$:\n    $y=297$. The members $289, 292, 295, 296$ are less than or equal to $297$.\n    So, $k=4$.\n\n3.  Calculate the required sums:\n    $S_k = S_4 = \\sum_{i=1}^4 x_{(i)} = 289 + 292 + 295 + 296 = 1172$.\n    $S_m = S_8 = \\sum_{i=1}^8 x_{(i)} = 1172 + (298 + 300 + 301 + 303) = 1172 + 1202 = 2374$.\n    $W_m = W_8 = \\sum_{i=1}^8 i x_{(i)} = 1(289) + 2(292) + 3(295) + 4(296) + 5(298) + 6(300) + 7(301) + 8(303)$.\n    $W_8 = 289 + 584 + 885 + 1184 + 1490 + 1800 + 2107 + 2424 = 10763$.\n\n4.  Compute the CRPS.\n    We have $m=8$, $k=4$, $y=297$.\n    The first term is $\\frac{2k-m}{m} y = \\frac{2(4)-8}{8} (297) = \\frac{0}{8} (297) = 0$.\n    The second term requires the values: $m^2 = 64$, $2m+1 = 17$, $2m=16$.\n    $$\n    \\mathrm{CRPS} = 0 + \\frac{1}{64} \\left[ 17 \\cdot S_8 - 2 \\cdot W_8 - 16 \\cdot S_4 \\right]\n    $$\n    Substituting the computed sums:\n    \\begin{align*}\n    \\mathrm{CRPS} = \\frac{1}{64} \\left[ 17(2374) - 2(10763) - 16(1172) \\right] \\\\\n    = \\frac{1}{64} \\left[ 40358 - 21526 - 18752 \\right] \\\\\n    = \\frac{1}{64} \\left[ 40358 - 40278 \\right] \\\\\n    = \\frac{80}{64} = \\frac{5}{4} = 1.25\n    \\end{align*}\nThe CRPS is $1.25 \\, \\mathrm{K}$. Rounding to four significant figures gives $1.250 \\, \\mathrm{K}$.",
            "answer": "$$\\boxed{1.250}$$"
        }
    ]
}