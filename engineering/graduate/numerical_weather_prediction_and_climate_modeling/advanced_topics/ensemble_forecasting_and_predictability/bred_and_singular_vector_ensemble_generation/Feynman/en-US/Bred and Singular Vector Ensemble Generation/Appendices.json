{
    "hands_on_practices": [
        {
            "introduction": "The Tangent Linear Model (TLM) approximates the evolution of small perturbations along a forecast trajectory and is the cornerstone for generating singular vectors. Before deploying a TLM, it is crucial to verify its implementation is correct. This practice guides you through a fundamental validation test where you will compare the TLM's prediction against the true nonlinear evolution of scaled perturbations, ensuring the linear approximation holds for sufficiently small amplitudes .",
            "id": "4018800",
            "problem": "Consider the forced Lorenz $96$ system, a standard conceptual model in numerical weather prediction and climate modeling, defined for dimension $K \\in \\mathbb{N}$ by the ordinary differential equation\n$$\n\\frac{d x_i}{d t} = \\left(x_{i+1} - x_{i-2}\\right) x_{i-1} - x_i + F, \\quad i = 1, \\dots, K,\n$$\nwith cyclic indexing such that $x_{0} \\equiv x_{K}$, $x_{-1} \\equiv x_{K-1}$, $x_{K+1} \\equiv x_{1}$, and so on. Here $F \\in \\mathbb{R}$ is a constant forcing. The associated Jacobian matrix of the vector field evaluated at a state $\\mathbf{x} \\in \\mathbb{R}^K$ is the $K \\times K$ matrix $\\mathbf{J}(\\mathbf{x})$ whose entries are given by\n$$\n\\frac{\\partial}{\\partial x_j}\\left[\\left(x_{i+1} - x_{i-2}\\right) x_{i-1} - x_i + F\\right] = \n\\begin{cases}\nx_{i+1} - x_{i-2},  j = i-1, \\\\\nx_{i-1},  j = i+1, \\\\\n- x_{i-1},  j = i-2, \\\\\n-1,  j = i, \\\\\n0,  \\text{otherwise},\n\\end{cases}\n$$\nwith cyclic indexing.\n\nDefine the nonlinear flow map $\\mathcal{M}_T : \\mathbb{R}^K \\to \\mathbb{R}^K$ as the mapping from an initial condition $\\mathbf{x}_0$ to the state at time $T  0$ obtained by numerically integrating the Lorenz $96$ system. Define the Tangent Linear Model (TLM) as the linear time-dependent system\n$$\n\\frac{d \\mathbf{z}}{d t} = \\mathbf{J}(\\mathbf{x}(t)) \\, \\mathbf{z},\n$$\nwhere $\\mathbf{x}(t)$ is the nonlinear trajectory starting from $\\mathbf{x}_0$ and $\\mathbf{z}(t)$ evolves from an initial perturbation $\\mathbf{z}(0) = \\mathbf{p}_0$. The TLM solution at time $T$ is denoted $\\mathbf{z}(T)$, which approximates the evolution of small perturbations along the nonlinear trajectory.\n\nYou must construct a numerical test to validate a coded TLM by comparing nonlinear perturbation differences to TLM predictions under amplitude scaling. Specifically, for a given set of amplitudes $\\alpha \\in \\mathcal{A}$, define the nonlinear perturbation difference at time $T$ as\n$$\n\\delta_{\\text{nl}}(\\alpha) = \\mathcal{M}_T\\big(\\mathbf{x}_0 + \\alpha \\mathbf{p}_0\\big) - \\mathcal{M}_T(\\mathbf{x}_0).\n$$\nThe TLM prediction for amplitude $\\alpha$ is\n$$\n\\delta_{\\text{tl}}(\\alpha) = \\alpha \\, \\mathbf{z}(T),\n$$\nwhere $\\mathbf{z}(T)$ is computed by integrating the TLM along the base trajectory $\\mathbf{x}(t)$ from $\\mathbf{z}(0) = \\mathbf{p}_0$.\n\nYour program must:\n- Implement the Lorenz $96$ model and its Jacobian.\n- Integrate the nonlinear system and the TLM using a fourth-order Runge–Kutta method with a fixed time step $\\Delta t$.\n- For each test case, generate a base state $\\mathbf{x}_0$ and an initial perturbation direction $\\mathbf{p}_0$ using a fixed random seed, normalize $\\mathbf{p}_0$ to satisfy $\\lVert \\mathbf{p}_0 \\rVert_2 = 1$, compute $\\mathbf{z}(T)$ along the base trajectory, and then compute the nonlinear differences $\\delta_{\\text{nl}}(\\alpha)$ for all $\\alpha \\in \\mathcal{A}$.\n- For each test case, compute the maximum relative discrepancy across the amplitude set\n$$\nE_{\\max} = \\max_{\\alpha \\in \\mathcal{A}} \\frac{\\left\\lVert \\delta_{\\text{nl}}(\\alpha) - \\delta_{\\text{tl}}(\\alpha) \\right\\rVert_2}{\\left\\lVert \\delta_{\\text{tl}}(\\alpha) \\right\\rVert_2}.\n$$\n\nAll variables are dimensionless; no physical units are involved.\n\nTest suite and parameters:\n- Case $1$ (happy path): $K = 10$, $F = 8$, $T = 1.0$, $\\Delta t = 0.01$, $\\mathcal{A} = \\{10^{-6}, 5 \\cdot 10^{-6}, 10^{-5}\\}$, random seed $0$.\n- Case $2$ (longer window): $K = 10$, $F = 8$, $T = 5.0$, $\\Delta t = 0.01$, $\\mathcal{A} = \\{10^{-6}, 5 \\cdot 10^{-6}, 10^{-5}\\}$, random seed $1$.\n- Case $3$ (large amplitudes, breakdown check): $K = 10$, $F = 8$, $T = 1.0$, $\\Delta t = 0.01$, $\\mathcal{A} = \\{10^{-3}, 5 \\cdot 10^{-3}, 10^{-2}\\}$, random seed $2$.\n- Case $4$ (edge: small dimension and tiny amplitudes): $K = 5$, $F = 8$, $T = 1.0$, $\\Delta t = 0.01$, $\\mathcal{A} = \\{10^{-8}, 5 \\cdot 10^{-8}, 10^{-7}\\}$, random seed $3$.\n\nBase and perturbation generation:\n- For each test case, draw $\\mathbf{x}_0$ by sampling independent standard normal components and setting $\\mathbf{x}_0 = F \\cdot \\mathbf{1} + 0.01 \\, \\boldsymbol{\\eta}$ where $\\boldsymbol{\\eta}$ is the standard normal vector and $\\mathbf{1}$ is the all-ones vector.\n- Draw $\\mathbf{p}_0$ as an independent standard normal vector, then normalize to unit Euclidean norm.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one entry per test case in the order listed above. Each entry must be the floating-point value of $E_{\\max}$ for that case. For example, the output format must be\n$$\n[\\text{E}_{\\max}^{(1)},\\text{E}_{\\max}^{(2)},\\text{E}_{\\max}^{(3)},\\text{E}_{\\max}^{(4)}].\n$$",
            "solution": "The user has provided a problem that requires the implementation and validation of a Tangent Linear Model (TLM) for the Lorenz $96$ dynamical system.\n\n### Step 1: Problem Validation\n\nFirst, I will extract the given information and validate the problem statement.\n\n#### Extracted Givens:\n1.  **Lorenz 96 Model**:\n    $$\n    \\frac{d x_i}{d t} = \\left(x_{i+1} - x_{i-2}\\right) x_{i-1} - x_i + F, \\quad i = 1, \\dots, K\n    $$\n    with cyclic indexing ($x_0 \\equiv x_K$, etc.) and constant forcing $F$.\n\n2.  **Jacobian Matrix $\\mathbf{J}(\\mathbf{x})$**:\n    $$\n    J_{ij} = \\frac{\\partial}{\\partial x_j}\\left(\\frac{dx_i}{dt}\\right) = \n    \\begin{cases}\n    x_{i+1} - x_{i-2},  j = i-1, \\\\\n    x_{i-1},  j = i+1, \\\\\n    - x_{i-1},  j = i-2, \\\\\n    -1,  j = i, \\\\\n    0,  \\text{otherwise},\n    \\end{cases}\n    $$\n    with cyclic indexing.\n\n3.  **Flow Map and Tangent Linear Model (TLM)**:\n    -   Nonlinear flow map: $\\mathcal{M}_T: \\mathbb{R}^K \\to \\mathbb{R}^K$, evolving $\\mathbf{x}_0$ to $\\mathbf{x}(T)$.\n    -   TLM equation: $\\frac{d \\mathbf{z}}{d t} = \\mathbf{J}(\\mathbf{x}(t)) \\, \\mathbf{z}$, where $\\mathbf{x}(t)$ is the base trajectory from $\\mathbf{x}_0$. $\\mathbf{z}(T)$ is the solution at time $T$ from an initial perturbation $\\mathbf{z}(0) = \\mathbf{p}_0$.\n\n4.  **Validation Quantities**:\n    -   Nonlinear perturbation difference: $\\delta_{\\text{nl}}(\\alpha) = \\mathcal{M}_T\\big(\\mathbf{x}_0 + \\alpha \\mathbf{p}_0\\big) - \\mathcal{M}_T(\\mathbf{x}_0)$.\n    -   TLM prediction: $\\delta_{\\text{tl}}(\\alpha) = \\alpha \\, \\mathbf{z}(T)$.\n    -   Maximum relative discrepancy: $E_{\\max} = \\max_{\\alpha \\in \\mathcal{A}} \\frac{\\left\\lVert \\delta_{\\text{nl}}(\\alpha) - \\delta_{\\text{tl}}(\\alpha) \\right\\rVert_2}{\\left\\lVert \\delta_{\\text{tl}}(\\alpha) \\right\\rVert_2}$.\n\n5.  **Numerical Method**:\n    -   Integrator: Fourth-order Runge–Kutta (RK4).\n    -   Time step: $\\Delta t$.\n\n6.  **Initial Conditions Generation**:\n    -   Use a fixed random seed for each test case.\n    -   Base state: $\\mathbf{x}_0 = F \\cdot \\mathbf{1} + 0.01 \\, \\boldsymbol{\\eta}$, where $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$.\n    -   Initial perturbation: Draw $\\mathbf{p}_0$ from $\\mathcal{N}(\\mathbf{0}, \\mathbf{I})$, then normalize so $\\lVert \\mathbf{p}_0 \\rVert_2 = 1$.\n\n7.  **Test Cases**:\n    -   Case $1$: $K = 10$, $F = 8$, $T = 1.0$, $\\Delta t = 0.01$, $\\mathcal{A} = \\{10^{-6}, 5 \\cdot 10^{-6}, 10^{-5}\\}$, seed $0$.\n    -   Case $2$: $K = 10$, $F = 8$, $T = 5.0$, $\\Delta t = 0.01$, $\\mathcal{A} = \\{10^{-6}, 5 \\cdot 10^{-6}, 10^{-5}\\}$, seed $1$.\n    -   Case $3$: $K = 10$, $F = 8$, $T = 1.0$, $\\Delta t = 0.01$, $\\mathcal{A} = \\{10^{-3}, 5 \\cdot 10^{-3}, 10^{-2}\\}$, seed $2$.\n    -   Case $4$: $K = 5$, $F = 8$, $T = 1.0$, $\\Delta t = 0.01$, $\\mathcal{A} = \\{10^{-8}, 5 \\cdot 10^{-8}, 10^{-7}\\}$, seed $3$.\n\n8.  **Output Format**: A single line with a comma-separated list of $E_{\\max}$ values for each case, enclosed in square brackets: $[\\text{E}_{\\max}^{(1)},\\text{E}_{\\max}^{(2)},\\text{E}_{\\max}^{(3)},\\text{E}_{\\max}^{(4)}]$.\n\n#### Verdict:\nThe problem is **valid**.\n-   It is **scientifically grounded**: The Lorenz $96$ system, its Jacobian, the concept of a Tangent Linear Model, and the RK4 integration scheme are all standard and well-established in the field of numerical modeling of dynamical systems. The validation test itself, which compares the evolution of a small finite perturbation in the nonlinear model with the prediction from the linearized model, is a fundamental technique for verifying TLM implementations. The expected result is that the discrepancy should be of order $\\alpha$, which the test measures.\n-   It is **well-posed**: All necessary parameters, initial conditions, and numerical methods are specified, ensuring that a unique numerical solution can be computed. The process is deterministic given the random seeds.\n-   It is **objective**: The problem is stated in precise mathematical and algorithmic terms, free from ambiguity or subjective interpretation.\n-   The problem does not exhibit any of the invalidity flags. It is a well-defined computational task within the specified domain.\n\n### Step 2: Solution Design\n\nThe core of the solution is to implement the numerical integration for both the nonlinear Lorenz $96$ model and its associated Tangent Linear Model.\n\n#### Algorithm:\n\n1.  **Implement the Lorenz $96$ System**:\n    A function `lorenz96_rhs(x, F)` will compute the right-hand side (the time derivative) of the Lorenz $96$ equations. This can be efficiently implemented using `numpy.roll` for the cyclic boundary conditions. For a state vector `x` of size $K$, the derivative is computed as:\n    `dxdt = (np.roll(x, -1) - np.roll(x, 2)) * np.roll(x, 1) - x + F`.\n\n2.  **Implement the Jacobian**:\n    A function `lorenz96_jacobian(x)` will construct the $K \\times K$ Jacobian matrix $\\mathbf{J}(\\mathbf{x})$. The matrix is sparse with four non-zero diagonals (including the main diagonal) with cyclic wrapping. For a given state `x`, the matrix entries will be populated according to the provided formula.\n\n3.  **Implement the Integrator**:\n    A generic fourth-order Runge-Kutta step function, `rk4_step(rhs_func, y, dt, *args)`, will be implemented. This function will advance a state vector `y` by a time step `dt` using the dynamics defined by `rhs_func`.\n\n4.  **Integrate the Coupled System**:\n    To accurately integrate the TLM, which depends on the state of the nonlinear trajectory at each instant, we integrate a combined state vector $\\mathbf{y} = [\\mathbf{x}, \\mathbf{z}]^T$ of size $2K$. The right-hand side for this augmented system is:\n    $$\n    \\frac{d\\mathbf{y}}{dt} = \\begin{bmatrix} d\\mathbf{x}/dt \\\\ d\\mathbf{z}/dt \\end{bmatrix} = \\begin{bmatrix} \\text{lorenz96\\_rhs}(\\mathbf{x}, F) \\\\ \\mathbf{J}(\\mathbf{x})\\mathbf{z} \\end{bmatrix}\n    $$\n    An `augmented_rhs` function will be created for this purpose. Integrating this system from an initial state $\\mathbf{y}_0 = [\\mathbf{x}_0, \\mathbf{p}_0]^T$ for a duration $T$ yields the final state $[\\mathbf{x}(T), \\mathbf{z}(T)]^T$. The component $\\mathbf{x}(T)$ is the reference final state $\\mathcal{M}_T(\\mathbf{x}_0)$, and $\\mathbf{z}(T)$ is the evolved initial perturbation.\n\n5.  **Compute Discrepancy**:\n    For each test case:\n    a.  Set up the parameters ($K, F, T, \\Delta t, \\mathcal{A}$, seed).\n    b.  Generate initial conditions $\\mathbf{x}_0$ and $\\mathbf{p}_0$ as specified.\n    c.  Integrate the augmented system from $[\\mathbf{x}_0, \\mathbf{p}_0]^T$ to get the reference final state $\\mathbf{x}_{\\text{ref}}(T) = \\mathcal{M}_T(\\mathbf{x}_0)$ and the evolved perturbation $\\mathbf{z}(T)$.\n    d.  For each amplitude $\\alpha \\in \\mathcal{A}$:\n        i.   Calculate the TLM prediction: $\\delta_{\\text{tl}}(\\alpha) = \\alpha \\, \\mathbf{z}(T)$.\n        ii.  Create the perturbed initial condition $\\mathbf{x}_0^{\\text{pert}} = \\mathbf{x}_0 + \\alpha \\mathbf{p}_0$.\n        iii. Integrate the *nonlinear* Lorenz $96$ system from $\\mathbf{x}_0^{\\text{pert}}$ for duration $T$ to get $\\mathbf{x}_{\\text{pert}}(T) = \\mathcal{M}_T(\\mathbf{x}_0^{\\text{pert}})$.\n        iv.  Calculate the nonlinear difference: $\\delta_{\\text{nl}}(\\alpha) = \\mathbf{x}_{\\text{pert}}(T) - \\mathbf{x}_{\\text{ref}}(T)$.\n        v.   Compute the relative discrepancy: $\\frac{\\left\\lVert \\delta_{\\text{nl}}(\\alpha) - \\delta_{\\text{tl}}(\\alpha) \\right\\rVert_2}{\\left\\lVert \\delta_{\\text{tl}}(\\alpha) \\right\\rVert_2}$.\n    e.  The result for the test case, $E_{\\max}$, is the maximum of these discrepancies over all $\\alpha$.\n\n6.  **Final Output**:\n    The $E_{\\max}$ values from all test cases will be collected into a list and printed in the specified format. The number of integration steps will be calculated as `int(round(T / dt))` to handle potential floating-point inaccuracies.",
            "answer": "```python\nimport numpy as np\n\ndef lorenz96_rhs(x, F):\n    \"\"\"Computes the right-hand side of the Lorenz 96 system.\"\"\"\n    K = len(x)\n    dxdt = np.zeros(K)\n    \n    # Vectorized computation using np.roll for cyclic boundary conditions\n    x_p1 = np.roll(x, -1)  # x_{i+1}\n    x_m1 = np.roll(x, 1)   # x_{i-1}\n    x_m2 = np.roll(x, 2)   # x_{i-2}\n    \n    dxdt = (x_p1 - x_m2) * x_m1 - x + F\n    return dxdt\n\ndef lorenz96_jacobian(x):\n    \"\"\"Computes the Jacobian matrix of the Lorenz 96 system.\"\"\"\n    K = len(x)\n    J = np.zeros((K, K))\n    \n    x_p1 = np.roll(x, -1) # x_{i+1} at index i\n    x_m1 = np.roll(x, 1)  # x_{i-1} at index i\n    x_m2 = np.roll(x, 2)  # x_{i-2} at index i\n\n    # Populate the Jacobian matrix row by row\n    # This explicit loop is clear and efficient enough for K values used.\n    for i in range(K):\n        # j = i\n        J[i, i] = -1.0\n        # j = i+1\n        J[i, (i + 1) % K] = x_m1[i]\n        # j = i-1\n        J[i, (i - 1 + K) % K] = x_p1[i] - x_m2[i]\n        # j = i-2\n        J[i, (i - 2 + K) % K] = -x_m1[i]\n        \n    return J\n\ndef rk4_step(rhs_func, y, dt, *args):\n    \"\"\"Performs a single fourth-order Runge-Kutta step.\"\"\"\n    k1 = rhs_func(y, *args)\n    k2 = rhs_func(y + dt / 2.0 * k1, *args)\n    k3 = rhs_func(y + dt / 2.0 * k2, *args)\n    k4 = rhs_func(y + dt * k3, *args)\n    return y + dt / 6.0 * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n\ndef solve():\n    \"\"\"\n    Main solver function to run the test suite and compute maximum relative discrepancies.\n    \"\"\"\n    test_cases = [\n        # Case 1: happy path\n        {'K': 10, 'F': 8.0, 'T': 1.0, 'dt': 0.01, 'A': [1e-6, 5e-6, 1e-5], 'seed': 0},\n        # Case 2: longer window\n        {'K': 10, 'F': 8.0, 'T': 5.0, 'dt': 0.01, 'A': [1e-6, 5e-6, 1e-5], 'seed': 1},\n        # Case 3: large amplitudes, breakdown check\n        {'K': 10, 'F': 8.0, 'T': 1.0, 'dt': 0.01, 'A': [1e-3, 5e-3, 1e-2], 'seed': 2},\n        # Case 4: edge case with small dimension and tiny amplitudes\n        {'K': 5, 'F': 8.0, 'T': 1.0, 'dt': 0.01, 'A': [1e-8, 5e-8, 1e-7], 'seed': 3},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        K, F, T, dt, A, seed = case['K'], case['F'], case['T'], case['dt'], case['A'], case['seed']\n        \n        # --- Setup Initial Conditions ---\n        rng = np.random.default_rng(seed)\n        eta = rng.standard_normal(K)\n        x0 = F * np.ones(K) + 0.01 * eta\n        \n        p0 = rng.standard_normal(K)\n        p0 /= np.linalg.norm(p0)\n        \n        num_steps = int(round(T / dt))\n\n        # --- Define RHS for augmented (Nonlinear + TLM) system ---\n        def augmented_rhs(y, F_val):\n            K_val = len(y) // 2\n            x = y[:K_val]\n            z = y[K_val:]\n            \n            dxdt = lorenz96_rhs(x, F_val)\n            J = lorenz96_jacobian(x)\n            dzdt = J @ z\n            \n            return np.concatenate([dxdt, dzdt])\n\n        # --- Integrate to find reference trajectory and z(T) ---\n        y_augmented = np.concatenate([x0, p0])\n        for _ in range(num_steps):\n            y_augmented = rk4_step(augmented_rhs, y_augmented, dt, F)\n            \n        x_T_ref = y_augmented[:K]\n        z_T = y_augmented[K:]\n\n        # --- Compute TLM vs Nonlinear Discrepancy ---\n        discrepancies = []\n        for alpha in A:\n            # TLM prediction\n            delta_tl = alpha * z_T\n            \n            # Full nonlinear integration of perturbed state\n            x0_pert = x0 + alpha * p0\n            x_pert_current = x0_pert\n            for _ in range(num_steps):\n                x_pert_current = rk4_step(lorenz96_rhs, x_pert_current, dt, F)\n            x_T_pert = x_pert_current\n            \n            # Nonlinear difference\n            delta_nl = x_T_pert - x_T_ref\n            \n            # Relative discrepancy\n            norm_tl = np.linalg.norm(delta_tl)\n            if norm_tl > 0:\n                discrepancy = np.linalg.norm(delta_nl - delta_tl) / norm_tl\n                discrepancies.append(discrepancy)\n        \n        E_max = max(discrepancies) if discrepancies else 0.0\n        results.append(E_max)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "With a validated Tangent Linear Model, we can identify the specific initial perturbations that exhibit the fastest growth over a finite time, which are known as singular vectors (SVs). This exercise applies this concept to a simplified physical model of an atmospheric column, allowing you to explore how the structure and growth rate of the leading SV are influenced by different physical regimes, such as saturated versus unsaturated conditions . This practice bridges the gap between the abstract mathematical definition of SVs and their concrete physical meaning in atmospheric science.",
            "id": "4018774",
            "problem": "Consider a simplified single-column moist thermodynamic model linearized about a fixed base state. The perturbation state vector is defined as $\\mathbf{x}(t) = [T'(t),\\, q'(t)]^\\top$, where $T'$ is temperature perturbation and $q'$ is specific humidity perturbation. The linearized tendency is modeled as a time-invariant linear ordinary differential equation\n$$\n\\frac{d\\mathbf{x}}{dt} = \\mathbf{A}\\,\\mathbf{x},\n$$\nwith\n$$\n\\mathbf{A} = \\begin{bmatrix}\n-a  \\lambda \\\\\n-\\mu  -b\n\\end{bmatrix}.\n$$\nThe parameters $a$ and $b$ (both in $\\mathrm{hr}^{-1}$) represent linear damping rates arising from processes such as radiative cooling and moist relaxation, and the parameters $\\lambda$ and $\\mu$ (both in $\\mathrm{hr}^{-1}$) capture linearized moist coupling: latent heating from condensation warms the column when $q'$ is positive (modeled by $\\lambda  0$), and increased saturation vapor pressure with warmer $T'$ reduces $q'$ under saturation (modeled by $\\mu  0$). In an unsaturated base state, both $\\lambda$ and $\\mu$ can be idealized as zero for small perturbations. For a finite time horizon $\\tau$ (in hours), the linear propagator is\n$$\n\\mathbf{M}(\\tau) = \\exp(\\mathbf{A}\\,\\tau),\n$$\nso that $\\mathbf{x}(\\tau) = \\mathbf{M}(\\tau)\\,\\mathbf{x}(0)$.\n\nTo quantify perturbation growth and orientation, use a weighted energy norm defined by a symmetric positive-definite matrix $\\mathbf{W} = \\mathrm{diag}(c_T, c_q)$ with $c_T  0$ and $c_q  0$. The induced norm is $\\|\\mathbf{x}\\|_{\\mathbf{W}} = \\|\\mathbf{W}^{1/2}\\mathbf{x}\\|_2$. The leading singular vector (the initial perturbation direction that maximizes the norm growth over time $\\tau$) is defined as the maximizer of\n$$\n\\max_{\\mathbf{x}(0) \\neq \\mathbf{0}} \\frac{\\|\\mathbf{W}^{1/2}\\,\\mathbf{M}(\\tau)\\,\\mathbf{x}(0)\\|_2}{\\|\\mathbf{W}^{1/2}\\,\\mathbf{x}(0)\\|_2}.\n$$\nEquivalently, letting $\\widetilde{\\mathbf{M}} = \\mathbf{W}^{1/2}\\,\\mathbf{M}(\\tau)\\,\\mathbf{W}^{-1/2}$, the leading right singular vector of $\\widetilde{\\mathbf{M}}$ determines the optimal initial direction in the weighted space; mapping back to the physical space yields the leading singular vector $\\mathbf{v}_0 = \\mathbf{W}^{-1/2}\\,\\mathbf{v}$, where $\\mathbf{v}$ is the leading right singular vector of $\\widetilde{\\mathbf{M}}$.\n\nDefine the orientation angle $\\theta$ (in degrees) of the leading singular vector $\\mathbf{v}_0 = [v_T, v_q]^\\top$ relative to the temperature axis as the unsigned angle between $\\mathbf{v}_0$ and the unit vector $\\mathbf{e}_T = [1, 0]^\\top$:\n$$\n\\theta = \\arccos\\left(\\frac{|v_T|}{\\sqrt{v_T^2 + v_q^2}}\\right)\\cdot \\frac{180}{\\pi}.\n$$\nThis definition ensures $\\theta \\in [0, 90]$ degrees. Define the finite-time growth factor $\\sigma_1$ as the largest singular value of $\\widetilde{\\mathbf{M}}$ and the corresponding growth rate $g$ (in $\\mathrm{hr}^{-1}$) as\n$$\ng = \\frac{1}{\\tau}\\,\\ln(\\sigma_1).\n$$\n\nYour task is to write a program that, for the parameter sets listed below, computes the leading singular vector orientation $\\theta$ (in degrees) and the growth rate $g$ (in $\\mathrm{hr}^{-1}$). Use the matrix exponential for $\\mathbf{M}(\\tau)$. For each case, the weight matrix is $\\mathbf{W} = \\mathrm{diag}(1, w_q)$ with the specified $w_q$. Report $\\theta$ rounded to three decimal places (in degrees) and $g$ rounded to six decimal places (in $\\mathrm{hr}^{-1}$).\n\nTest suite (each case is $(a, b, \\lambda, \\mu, \\tau, w_q)$ in $\\mathrm{hr}^{-1}$, $\\mathrm{hr}^{-1}$, $\\mathrm{hr}^{-1}$, $\\mathrm{hr}^{-1}$, $\\mathrm{hr}$, and unitless, respectively):\n- Case $1$ (unsaturated base, happy path): $(0.1, 0.2, 0.0, 0.0, 6.0, 1.0)$.\n- Case $2$ (saturated base, moderate coupling): $(0.1, 1.5, 0.8, 0.6, 6.0, 1.0)$.\n- Case $3$ (saturated base, strong coupling): $(0.1, 1.5, 1.2, 1.0, 6.0, 1.0)$.\n- Case $4$ (unsaturated base, weak damping and longer horizon): $(0.05, 0.06, 0.0, 0.0, 12.0, 1.0)$.\n- Case $5$ (saturated base, moderate coupling with moisture-dominant metric): $(0.1, 1.5, 0.8, 0.6, 6.0, 9.0)$.\n\nRequirements:\n- All rates $a$, $b$, $\\lambda$, $\\mu$ must be interpreted in $\\mathrm{hr}^{-1}$, the time horizon $\\tau$ in $\\mathrm{hr}$, and the output growth rate $g$ in $\\mathrm{hr}^{-1}$. Angles must be in degrees.\n- Compute $\\mathbf{M}(\\tau) = \\exp(\\mathbf{A}\\,\\tau)$ via a matrix exponential and obtain $\\sigma_1$ and $\\mathbf{v}_0$ via a singular value decomposition in the weighted space.\n- For each case, output the pair $[\\theta, g]$ with the specified rounding.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the two-element list for a case, in the order given. For example: $[[\\theta_1, g_1],[\\theta_2, g_2],\\dots]$.",
            "solution": "The problem is evaluated as valid. It is scientifically grounded in the principles of atmospheric dynamics and predictability theory, well-posed with a complete and consistent set of definitions and parameters, and expressed in objective, formal language. A unique, meaningful solution can be derived through standard matrix analysis.\n\nThe task is to compute the orientation angle $\\theta$ and growth rate $g$ of the leading singular vector for a simplified moist thermodynamic model. The procedure involves forming the system matrices, propagating the system forward in time, and performing a singular value decomposition in a weighted norm. This process is repeated for each set of specified parameters.\n\nThe state of the system is described by the perturbation vector $\\mathbf{x}(t) = [T'(t), q'(t)]^\\top$, where $T'$ is the temperature perturbation and $q'$ is the specific humidity perturbation. Its evolution is governed by the linear ordinary differential equation:\n$$\n\\frac{d\\mathbf{x}}{dt} = \\mathbf{A}\\,\\mathbf{x}\n$$\nThe system matrix $\\mathbf{A}$ is given by:\n$$\n\\mathbf{A} = \\begin{bmatrix}\n-a  \\lambda \\\\\n-\\mu  -b\n\\end{bmatrix}\n$$\nwhere the parameters $a$, $b$, $\\lambda$, and $\\mu$ are provided for each case. All rates are in units of $\\mathrm{hr}^{-1}$.\n\nThe solution for $\\mathbf{x}(t)$ after a time interval $\\tau$ (in hours) is found using the linear propagator matrix $\\mathbf{M}(\\tau)$, which is the matrix exponential of $\\mathbf{A}\\tau$:\n$$\n\\mathbf{x}(\\tau) = \\mathbf{M}(\\tau)\\,\\mathbf{x}(0) \\quad \\text{where} \\quad \\mathbf{M}(\\tau) = \\exp(\\mathbf{A}\\,\\tau)\n$$\n\nWe are interested in the initial perturbation $\\mathbf{x}(0)$ that experiences the maximum growth over the interval $\\tau$, measured in a weighted energy norm. This norm is defined by the symmetric positive-definite matrix $\\mathbf{W} = \\mathrm{diag}(1, w_q)$:\n$$\n\\|\\mathbf{x}\\|_{\\mathbf{W}} = \\sqrt{\\mathbf{x}^\\top \\mathbf{W} \\mathbf{x}} = \\|\\mathbf{W}^{1/2}\\mathbf{x}\\|_2\n$$\nThe growth factor for an initial perturbation $\\mathbf{x}(0)$ is the ratio of final to initial norm:\n$$\n\\frac{\\|\\mathbf{x}(\\tau)\\|_{\\mathbf{W}}}{\\|\\mathbf{x}(0)\\|_{\\mathbf{W}}} = \\frac{\\|\\mathbf{W}^{1/2}\\,\\mathbf{M}(\\tau)\\,\\mathbf{x}(0)\\|_2}{\\|\\mathbf{W}^{1/2}\\,\\mathbf{x}(0)\\|_2}\n$$\nTo simplify this expression, we define a transformed initial state $\\mathbf{y}(0) = \\mathbf{W}^{1/2}\\,\\mathbf{x}(0)$, which implies $\\mathbf{x}(0) = \\mathbf{W}^{-1/2}\\,\\mathbf{y}(0)$. Substituting this into the growth factor expression gives:\n$$\n\\frac{\\|\\mathbf{W}^{1/2}\\,\\mathbf{M}(\\tau)\\,\\mathbf{W}^{-1/2}\\,\\mathbf{y}(0)\\|_2}{\\|\\mathbf{y}(0)\\|_2} = \\frac{\\|\\widetilde{\\mathbf{M}}\\,\\mathbf{y}(0)\\|_2}{\\|\\mathbf{y}(0)\\|_2}\n$$\nwhere $\\widetilde{\\mathbf{M}} = \\mathbf{W}^{1/2}\\,\\mathbf{M}(\\tau)\\,\\mathbf{W}^{-1/2}$ is the propagator in the weighted coordinate system.\n\nThe maximum value of this ratio is, by definition, the largest singular value of $\\widetilde{\\mathbf{M}}$, denoted $\\sigma_1$. The initial perturbation $\\mathbf{y}(0)$ that achieves this maximum is the corresponding leading right singular vector of $\\widetilde{\\mathbf{M}}$, which we denote as $\\mathbf{v}$.\n\nThe algorithm for each test case is as follows:\n\n1.  **Construct Matrices**: Given the parameters $(a, b, \\lambda, \\mu, \\tau, w_q)$, construct the matrix $\\mathbf{A}$. The weight matrix is $\\mathbf{W} = \\mathrm{diag}(1, w_q)$. Its square root and inverse square root are $\\mathbf{W}^{1/2} = \\mathrm{diag}(1, \\sqrt{w_q})$ and $\\mathbf{W}^{-1/2} = \\mathrm{diag}(1, 1/\\sqrt{w_q})$, respectively.\n\n2.  **Compute Propagator**: Calculate the propagator matrix $\\mathbf{M}(\\tau) = \\exp(\\mathbf{A}\\,\\tau)$ using a numerical matrix exponential function.\n\n3.  **Transform Propagator**: Compute the weighted propagator $\\widetilde{\\mathbf{M}} = \\mathbf{W}^{1/2}\\,\\mathbf{M}(\\tau)\\,\\mathbf{W}^{-1/2}$.\n\n4.  **Singular Value Decomposition (SVD)**: Perform the SVD of $\\widetilde{\\mathbf{M}}$ to find its largest singular value $\\sigma_1$ and the corresponding right singular vector $\\mathbf{v}$. The SVD is given by $\\widetilde{\\mathbf{M}} = \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^\\top$. The value $\\sigma_1$ is the first entry on the diagonal of $\\mathbf{\\Sigma}$, and $\\mathbf{v}$ is the first column of the matrix $\\mathbf{V}$.\n\n5.  **Calculate Growth Rate ($g$)**: The finite-time growth rate $g$ is derived from $\\sigma_1$ and $\\tau$ as:\n    $$\n    g = \\frac{1}{\\tau}\\,\\ln(\\sigma_1)\n    $$\n    The result is given in $\\mathrm{hr}^{-1}$ and rounded to six decimal places.\n\n6.  **Find the Physical Singular Vector ($\\mathbf{v}_0$)**: The optimal initial perturbation in the physical space, $\\mathbf{v}_0 = [v_T, v_q]^\\top$, is obtained by transforming $\\mathbf{v}$ back from the weighted space:\n    $$\n    \\mathbf{v}_0 = \\mathbf{W}^{-1/2}\\,\\mathbf{v}\n    $$\n\n7.  **Calculate Orientation Angle ($\\theta$)**: The orientation angle $\\theta$ of $\\mathbf{v}_0$ relative to the temperature axis is the unsigned angle, ensuring $\\theta \\in [0, 90]$ degrees:\n    $$\n    \\theta = \\arccos\\left(\\frac{|v_T|}{\\|\\mathbf{v}_0\\|_2}\\right) \\cdot \\frac{180}{\\pi} = \\arccos\\left(\\frac{|v_T|}{\\sqrt{v_T^2 + v_q^2}}\\right) \\cdot \\frac{180}{\\pi}\n    $$\n    The result is given in degrees and rounded to three decimal places.\n\nThis procedure is systematically applied to each of the five test cases provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef solve():\n    \"\"\"\n    Computes the leading singular vector orientation and growth rate for a\n    linearized moist thermodynamic model for several parameter sets.\n    \"\"\"\n    # Test suite: each tuple is (a, b, lambda, mu, tau, w_q)\n    # The parameters from the problem statement use commas for decimals, which are\n    # interpreted as dots for standard float representation.\n    test_cases = [\n        # Case 1 (unsaturated base, happy path)\n        (0.1, 0.2, 0.0, 0.0, 6.0, 1.0),\n        # Case 2 (saturated base, moderate coupling)\n        (0.1, 1.5, 0.8, 0.6, 6.0, 1.0),\n        # Case 3 (saturated base, strong coupling)\n        (0.1, 1.5, 1.2, 1.0, 6.0, 1.0),\n        # Case 4 (unsaturated base, weak damping and longer horizon)\n        (0.05, 0.06, 0.0, 0.0, 12.0, 1.0),\n        # Case 5 (saturated base, moderate coupling with moisture-dominant metric)\n        (0.1, 1.5, 0.8, 0.6, 6.0, 9.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        a, b, lam, mu, tau, w_q = case\n        \n        # Step 1: Construct the system matrix A\n        A = np.array([\n            [-a, lam],\n            [-mu, -b]\n        ])\n\n        # Step 2: Compute the propagator M(tau)\n        M_tau = expm(A * tau)\n\n        # Step 3: Construct weight matrices and transform the propagator\n        # W = diag(1, w_q)\n        # W_sqrt = diag(1, sqrt(w_q))\n        # W_inv_sqrt = diag(1, 1/sqrt(w_q))\n        sqrt_w_q = np.sqrt(w_q)\n        W_sqrt = np.diag([1.0, sqrt_w_q])\n        W_inv_sqrt = np.diag([1.0, 1.0 / sqrt_w_q])\n        \n        # M_tilde = W_sqrt * M_tau * W_inv_sqrt\n        M_tilde = W_sqrt @ M_tau @ W_inv_sqrt\n\n        # Step 4: Perform Singular Value Decomposition (SVD) of M_tilde\n        # U, s, Vh = svd(M_tilde), where Vh is V.T\n        _, s, Vh = np.linalg.svd(M_tilde)\n        \n        # The largest singular value is the first element of s\n        sigma_1 = s[0]\n        \n        # The leading right singular vector is the first column of V (or first row of Vh)\n        v = Vh[0, :]\n\n        # Step 5: Calculate the growth rate g\n        g = np.log(sigma_1) / tau\n\n        # Step 6: Find the physical singular vector v0\n        # v0 = W_inv_sqrt * v\n        v0 = W_inv_sqrt @ v\n        vT, vq = v0[0], v0[1]\n\n        # Step 7: Calculate the orientation angle theta\n        norm_v0 = np.linalg.norm(v0)\n        # Handle case where v0 might be a zero vector, though unlikely\n        if norm_v0 == 0:\n            theta = 0.0\n        else:\n            # arccos is in radians, convert to degrees\n            theta = np.arccos(np.abs(vT) / norm_v0) * (180.0 / np.pi)\n\n        # Format results as specified\n        result = [round(theta, 3), round(g, 6)]\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The theoretical appeal of singular vectors lies in their optimality, but their practical utility must be demonstrated. This final practice challenges you to design and execute a numerical experiment to rigorously quantify the superiority of SV-based perturbations over random perturbations for assessing forecast sensitivity . By employing a Monte Carlo setup and statistical hypothesis testing, you will provide concrete evidence that SVs are not just a theoretical curiosity but a powerful tool for ensemble forecasting.",
            "id": "4018795",
            "problem": "Consider a linear tangent model representative of a short-range forecast for a state vector with dimension $n$ defined by $x(T) = M x(0)$, where $M \\in \\mathbb{R}^{n \\times n}$ is the linear propagator from initial time $0$ to forecast verification time $T$. Let the initial condition norm be defined by a symmetric positive-definite matrix $V \\succ 0$ through $\\|x\\|_{V} = \\|V^{1/2} x\\|_{2}$, and let the chosen forecast metric be the weighted norm defined by a symmetric positive-definite matrix $W \\succ 0$ through $\\|y\\|_{W} = \\|W^{1/2} y\\|_{2}$. The forecast metric amplitude for a perturbation $\\delta x$ is $A(\\delta x) = \\|W^{1/2} M \\delta x\\|_{2}^{2}$.\n\nSingular vectors are defined as the directions of initial perturbations $\\delta x$ that maximize the forecast metric amplitude at time $T$ subject to a fixed initial norm constraint. Formally, the leading singular vector solves\n$$\n\\max_{\\delta x \\in \\mathbb{R}^{n}} \\|W^{1/2} M \\delta x\\|_{2} \\quad \\text{subject to} \\quad \\|V^{1/2} \\delta x\\|_{2} = 1.\n$$\nThis can be computed by the Singular Value Decomposition (SVD), where if $A = W^{1/2} M V^{-1/2}$ has SVD $A = U \\Sigma Q^{\\top}$ with $\\Sigma = \\operatorname{diag}(\\sigma_{1}, \\sigma_{2}, \\dots)$ and $Q$ orthogonal, then the leading right singular vector $q_{1}$ gives the leading initial condition singular vector $\\delta x^{\\ast} = V^{-1/2} q_{1}$ normalized to satisfy $\\|V^{1/2} \\delta x^{\\ast}\\|_{2} = 1$.\n\nDesign and implement an experiment to evaluate whether singular vector perturbations improve forecast sensitivity to the chosen metric relative to random perturbations. Use a Monte Carlo setup to generate:\n- A random ensemble of $N$ perturbations by sampling directions uniformly on the unit sphere induced by the initial norm $\\|\\cdot\\|_{V}$ and normalizing each sampled perturbation to have $\\|V^{1/2} \\delta x\\|_{2} = 1$.\n- A singular vector ensemble of $N$ perturbations by sampling directions in a small neighborhood around the leading singular vector and renormalizing each to have $\\|V^{1/2} \\delta x\\|_{2} = 1$. Specifically, generate each singular vector ensemble member as $\\delta x_{i}^{\\text{sv}} = \\operatorname{normalize}_{V}(\\delta x^{\\ast} + \\varepsilon \\,\\eta_{i})$, where $\\eta_{i}$ is a random direction drawn uniformly on the $V$-norm unit sphere and $\\varepsilon  0$ is a small dispersion parameter.\n\nFor each ensemble, compute the sample of forecast metric amplitudes $A(\\delta x)$ and perform a statistical test to assess whether the singular vector ensemble has strictly larger mean forecast metric amplitude than the random ensemble. Use the Welch’s $t$-test for unequal variances with the one-sided null hypothesis $H_{0}: \\mu_{\\text{sv}} \\le \\mu_{\\text{rand}}$ versus the alternative $H_{1}: \\mu_{\\text{sv}}  \\mu_{\\text{rand}}$, where $\\mu_{\\text{sv}}$ and $\\mu_{\\text{rand}}$ denote the population means of $A(\\delta x)$ under the singular vector and random ensembles, respectively. Report a boolean result per test case defined as true if the sample mean under the singular vector ensemble exceeds the sample mean under the random ensemble and the one-sided Welch’s $t$-test $p$-value is strictly less than a prescribed significance level $\\alpha$, and false otherwise.\n\nStart from the following fundamental bases and definitions:\n- Linear propagation of small perturbations through a tangent model: $x(T) = M x(0)$.\n- Weighted norms induced by symmetric positive-definite matrices: $\\|x\\|_{V}^{2} = x^{\\top} V x$ and $\\|y\\|_{W}^{2} = y^{\\top} W y$.\n- Singular Value Decomposition (SVD) for computing singular vectors under weighted norms via the transformation $A = W^{1/2} M V^{-1/2}$.\n- Welch’s $t$-test for comparing means under unequal variances.\n\nYour program must implement:\n- Construction of $V^{1/2}$ and $V^{-1/2}$ and similarly $W^{1/2}$ through a Cholesky factorization.\n- Computation of the leading singular vector via SVD of $A = W^{1/2} M V^{-1/2}$.\n- Generation of random perturbations uniformly on the unit sphere induced by $\\|\\cdot\\|_{V}$ using isotropic Gaussian sampling and normalization.\n- Generation of singular vector ensemble perturbations by adding small $V$-isotropic noise to the leading singular vector and renormalizing.\n- Computation of the forecast metric amplitude $A(\\delta x) = \\|W^{1/2} M \\delta x\\|_{2}^{2}$.\n- Execution of the one-sided Welch’s $t$-test and decision logic at a given significance level $\\alpha$.\n\nAngle units are not involved; no physical units are required.\n\nUse the following test suite. For each case, the dimension $n$, propagator $M$, initial norm matrix $V$, metric matrix $W$, ensemble size $N$, singular vector ensemble dispersion $\\varepsilon$, significance level $\\alpha$, and a pseudo-random seed are specified. These choices are scientifically plausible and test different facets of the method.\n\n- Case 1 (anisotropic growth, identity norms, expected improvement):\n  - $n = 2$, $M = \\begin{bmatrix} 1.6  0.1 \\\\ 0.0  0.7 \\end{bmatrix}$, $V = I_{2}$, $W = I_{2}$, $N = 1000$, $\\varepsilon = 0.05$, $\\alpha = 0.05$, seed $= 123$.\n- Case 2 (isotropic growth, identity norms, no expected improvement):\n  - $n = 2$, $M = s R(\\theta)$ with $s = 1.2$ and $R(\\theta) = \\begin{bmatrix} \\cos\\theta  -\\sin\\theta \\\\ \\sin\\theta  \\cos\\theta \\end{bmatrix}$, set $\\theta = 0.7$ radians, $V = I_{2}$, $W = I_{2}$, $N = 1000$, $\\varepsilon = 0.05$, $\\alpha = 0.05$, seed $= 456$.\n- Case 3 (anisotropic growth, small sample size, borderline significance):\n  - $n = 2$, $M = \\begin{bmatrix} 1.4  0.0 \\\\ 0.0  0.6 \\end{bmatrix}$, $V = I_{2}$, $W = I_{2}$, $N = 30$, $\\varepsilon = 0.10$, $\\alpha = 0.05$, seed $= 789$.\n- Case 4 (three-dimensional, nontrivial metric weights):\n  - $n = 3$, $M = \\begin{bmatrix} 1.7  0.2  0.0 \\\\ 0.0  0.9  0.1 \\\\ 0.0  0.0  0.6 \\end{bmatrix}$, $V = \\operatorname{diag}(1.0, 2.0, 0.5)$, $W = \\operatorname{diag}(2.0, 0.5, 3.0)$, $N = 800$, $\\varepsilon = 0.05$, $\\alpha = 0.05$, seed $= 101112$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"), where each result is a boolean corresponding to each test case in the order listed above. A result is true if the singular vector ensemble has a strictly larger sample mean of $A(\\delta x)$ than the random ensemble and the one-sided Welch’s $t$-test $p$-value is strictly less than the given $\\alpha$, and false otherwise.",
            "solution": "The problem requires a computational experiment to validate the theoretical premise that initial perturbations aligned with the leading singular vector of a linear forecast model lead to greater amplification in a chosen forecast metric compared to random perturbations. This is a cornerstone concept in predictability studies and ensemble forecasting, where identifying the directions of fastest error growth is crucial for quantifying forecast uncertainty. The experiment will be conducted via a Monte Carlo simulation, comparing two ensembles of initial perturbations and using a statistical hypothesis test to formalize the comparison.\n\nThe solution proceeds in several stages: first, establishing the mathematical framework for singular vectors in the context of weighted norms; second, defining the procedures for generating the two perturbation ensembles; third, specifying the metric for evaluating perturbation growth; and finally, outlining the statistical test for comparing the ensembles.\n\n**1. Mathematical Formulation and Singular Vector Computation**\n\nThe system dynamics are described by a linear tangent model, where an initial state perturbation $\\delta x(0)$ evolves to a final perturbation $\\delta x(T) = M \\delta x(0)$, with $M \\in \\mathbb{R}^{n \\times n}$ being the propagator matrix.\n\nThe magnitude of the initial perturbation is measured by a weighted norm $\\| \\delta x \\|_{V} = ( \\delta x^{\\top} V \\delta x )^{1/2}$, where $V$ is a symmetric positive-definite ($V \\succ 0$) matrix defining an energy inner product. Similarly, the magnitude of the final perturbation is measured by a forecast metric norm $\\| \\delta x(T) \\|_{W} = ( \\delta x(T)^{\\top} W \\delta x(T) )^{1/2}$, with $W \\succ 0$.\n\nThe goal is to find the initial perturbation $\\delta x$ that maximizes the final-time amplitude, defined as $A(\\delta x) = \\| \\delta x(T) \\|_{W}^{2} = \\| M \\delta x \\|_{W}^{2}$, subject to a unit initial norm constraint, $\\|\\delta x\\|_{V} = 1$. The optimization problem is:\n$$\n\\max_{\\delta x \\in \\mathbb{R}^{n}} \\| M \\delta x \\|_{W} \\quad \\text{subject to} \\quad \\|\\delta x\\|_{V} = 1\n$$\nThis is a generalized singular value problem. It can be transformed into a standard singular value problem. Since $V$ and $W$ are symmetric positive-definite, they admit matrix square roots, $V^{1/2}$ and $W^{1/2}$. The norms can be expressed using the standard Euclidean $2$-norm: $\\| \\delta x \\|_{V} = \\|V^{1/2} \\delta x\\|_{2}$ and $\\| M \\delta x \\|_{W} = \\|W^{1/2} M \\delta x\\|_{2}$.\n\nLet's introduce a change of variables: $u = V^{1/2} \\delta x$. Then $\\delta x = V^{-1/2} u$. The constraint $\\|\\delta x\\|_{V} = 1$ becomes $\\|u\\|_{2} = 1$. The objective function becomes:\n$$\n\\|W^{1/2} M \\delta x\\|_{2} = \\|W^{1/2} M V^{-1/2} u\\|_{2}\n$$\nDefining the matrix $A = W^{1/2} M V^{-1/2}$, the problem is transformed into:\n$$\n\\max_{u \\in \\mathbb{R}^{n}} \\| A u \\|_{2} \\quad \\text{subject to} \\quad \\|u\\|_{2} = 1\n$$\nThe solution to this standard problem is given by the Singular Value Decomposition (SVD) of $A$. Let the SVD of $A$ be $A = U \\Sigma Q^{\\top}$, where $U$ and $Q$ are orthogonal matrices and $\\Sigma$ is a diagonal matrix of singular values $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge 0$. The maximum value of $\\|Au\\|_2$ is the largest singular value, $\\sigma_1$, which is achieved when $u$ is the corresponding leading right singular vector, $q_1$ (the first column of $Q$).\n\nTransforming back to the original variable $\\delta x$, the optimal initial perturbation, i.e., the leading singular vector, is $\\delta x^{\\ast} = V^{-1/2} q_1$. The resulting maximum amplitude is $A(\\delta x^*) = \\|W^{1/2} M \\delta x^*\\|_2^2 = \\| A q_1 \\|_2^2 = \\sigma_1^2$.\n\nPractically, the matrix square roots and their inverses are computed using Cholesky decomposition. If $V = L_V L_V^{\\top}$ is the Cholesky decomposition of $V$, then a valid choice for $V^{1/2}$ is $L_V^{\\top}$. Consequently, $V^{-1/2} = (L_V^{\\top})^{-1} = L_V^{-\\top}$. The same applies to $W$.\n\n**2. Ensemble Generation**\n\nTo test the hypothesis, we generate two ensembles of $N$ perturbations each.\n\n**Random Ensemble:** The perturbations must be drawn from a uniform distribution on the $n$-dimensional sphere defined by the $V$-norm. A standard procedure to achieve this is:\n1. Generate a vector $g_i \\in \\mathbb{R}^n$ with components drawn from the standard normal distribution, i.e., $g_i \\sim \\mathcal{N}(0, I_n)$.\n2. Normalize $g_i$ in the Euclidean norm to obtain a vector $u_i = g_i / \\|g_i\\|_2$ which is uniformly distributed on the standard Euclidean unit sphere.\n3. Transform $u_i$ to the $V$-norm unit sphere: $\\delta x^{\\text{rand}}_i = V^{-1/2} u_i$. This ensures $\\|V^{1/2} \\delta x^{\\text{rand}}_i\\|_2 = \\|V^{1/2} V^{-1/2} u_i\\|_2 = \\|u_i\\|_2 = 1$.\n\n**Singular Vector Ensemble:** This ensemble is designed to sample perturbations in a small neighborhood around the leading singular vector $\\delta x^{\\ast}$. Each member is generated as:\n$$\n\\delta x_{i}^{\\text{sv}} = \\frac{\\delta x^{\\ast} + \\varepsilon \\,\\eta_{i}}{\\|V^{1/2} (\\delta x^{\\ast} + \\varepsilon \\,\\eta_{i})\\|_{2}}\n$$\nwhere $\\delta x^{\\ast}$ is the leading singular vector, $\\varepsilon  0$ is a small dispersion parameter, and $\\eta_i$ is a random perturbation drawn uniformly from the $V$-norm unit sphere, generated using the same method as for the random ensemble. The denominator ensures that each member $\\delta x_{i}^{\\text{sv}}$ is correctly normalized to have a unit $V$-norm.\n\n**3. Statistical Comparison**\n\nFor each perturbation $\\delta x_i$ in both ensembles, we compute the forecast metric amplitude:\n$$\nA(\\delta x_i) = \\|W^{1/2} M \\delta x_i\\|_{2}^{2}\n$$\nThis results in two sets of scalar values: $\\{A(\\delta x^{\\text{rand}}_i)\\}_{i=1}^N$ and $\\{A(\\delta x^{\\text{sv}}_i)\\}_{i=1}^N$. We want to test if the mean amplitude of the singular vector ensemble is significantly greater than that of the random ensemble. Let $\\mu_{\\text{sv}}$ and $\\mu_{\\text{rand}}$ be the true population means of the amplitudes for the respective ensembles. The hypothesis test is formulated as:\n- Null Hypothesis $H_0: \\mu_{\\text{sv}} \\le \\mu_{\\text{rand}}$\n- Alternative Hypothesis $H_1: \\mu_{\\text{sv}}  \\mu_{\\text{rand}}$\n\nSince the method of generation does not guarantee equal variances between the two amplitude distributions, Welch's $t$-test for unequal variances is the appropriate statistical tool. The $t$-statistic is calculated as:\n$$\nt = \\frac{\\bar{A}_{\\text{sv}} - \\bar{A}_{\\text{rand}}}{\\sqrt{\\frac{s_{\\text{sv}}^2}{N} + \\frac{s_{\\text{rand}}^2}{N}}}\n$$\nwhere $\\bar{A}$ and $s^2$ are the sample mean and variance of the amplitudes for each ensemble. The degrees of freedom are estimated using the Welch-Satterthwaite equation.\n\nFrom the $t$-statistic and degrees of freedom, a one-sided $p$-value is computed. This $p$-value represents the probability of observing a difference in sample means as large as or larger than the one computed, assuming the null hypothesis is true.\n\nThe final decision rule is: the result for a test case is `true` if and only if both conditions are met:\n1. The sample mean of the singular vector ensemble is strictly greater than that of the random ensemble ($\\bar{A}_{\\text{sv}}  \\bar{A}_{\\text{rand}}$).\n2. The calculated one-sided $p$-value is strictly less than the prescribed significance level $\\alpha$.\nOtherwise, the result is `false`.\n\nThis procedure is systematically applied to each test case provided, using the specified parameters and random seed to ensure reproducibility.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import ttest_ind\n\ndef solve():\n    \"\"\"\n    Solves the problem by running a Monte Carlo experiment for each test case\n    to compare singular vector and random perturbation ensembles.\n    \"\"\"\n    \n    # Case 1: Anisotropic growth, identity norms\n    M1 = np.array([[1.6, 0.1], [0.0, 0.7]])\n    V1 = np.eye(2)\n    W1 = np.eye(2)\n    case1 = (2, M1, V1, W1, 1000, 0.05, 0.05, 123)\n\n    # Case 2: Isotropic growth, identity norms\n    s2 = 1.2\n    theta2 = 0.7\n    R2 = np.array([[np.cos(theta2), -np.sin(theta2)], [np.sin(theta2), np.cos(theta2)]])\n    M2 = s2 * R2\n    V2 = np.eye(2)\n    W2 = np.eye(2)\n    case2 = (2, M2, V2, W2, 1000, 0.05, 0.05, 456)\n\n    # Case 3: Anisotropic growth, small sample size\n    M3 = np.array([[1.4, 0.0], [0.0, 0.6]])\n    V3 = np.eye(2)\n    W3 = np.eye(2)\n    case3 = (2, M3, V3, W3, 30, 0.10, 0.05, 789)\n\n    # Case 4: Three-dimensional, nontrivial metric weights\n    M4 = np.array([[1.7, 0.2, 0.0], [0.0, 0.9, 0.1], [0.0, 0.0, 0.6]])\n    V4 = np.diag([1.0, 2.0, 0.5])\n    W4 = np.diag([2.0, 0.5, 3.0])\n    case4 = (3, M4, V4, W4, 800, 0.05, 0.05, 101112)\n\n    test_cases = [case1, case2, case3, case4]\n    results = []\n\n    for n, M, V, W, N, epsilon, alpha, seed in test_cases:\n        np.random.seed(seed)\n\n        # Step 1: Compute matrix square roots and their inverses via Cholesky\n        L_V = np.linalg.cholesky(V)\n        V_sqrt = L_V.T\n        V_inv_sqrt = np.linalg.inv(V_sqrt)\n\n        L_W = np.linalg.cholesky(W)\n        W_sqrt = L_W.T\n\n        # Step 2: Compute the leading singular vector\n        A = W_sqrt @ M @ V_inv_sqrt\n        # np.linalg.svd returns U, s, Vt where Vt is V.T in U*S*V.T\n        # The rows of Vt are the right singular vectors.\n        _, _, Vt = np.linalg.svd(A)\n        q1 = Vt[0, :]  # Leading right singular vector\n        sv_leading = V_inv_sqrt @ q1\n        \n        # Helper function to generate perturbations on the V-norm unit sphere\n        def generate_v_norm_sphere_samples(num_samples):\n            gaussians = np.random.standard_normal(size=(num_samples, n))\n            norms = np.linalg.norm(gaussians, axis=1, keepdims=True)\n            unit_euclidean = gaussians / norms\n            # Each row is a sample vector\n            v_norm_samples = (V_inv_sqrt @ unit_euclidean.T).T\n            return v_norm_samples\n\n        # Step 3: Generate the two ensembles\n        # Random ensemble\n        random_ensemble = generate_v_norm_sphere_samples(N)\n\n        # Singular vector ensemble\n        sv_ensemble_list = []\n        random_directions = generate_v_norm_sphere_samples(N)\n        for i in range(N):\n            eta_i = random_directions[i, :]\n            # Create perturbed SV\n            z = sv_leading + epsilon * eta_i\n            # Renormalize in the V-norm\n            norm_z_v = np.linalg.norm(V_sqrt @ z)\n            sv_ensemble_list.append(z / norm_z_v)\n        sv_ensemble = np.array(sv_ensemble_list)\n\n        # Step 4: Compute forecast metric amplitudes for both ensembles\n        def compute_amplitudes(ensemble):\n            # Propagate perturbations\n            evolved_ensemble = (M @ ensemble.T).T\n            # Compute W-norm of propagated perturbations\n            w_normed_evolved = (W_sqrt @ evolved_ensemble.T).T\n            # Amplitudes are the squared norms\n            amplitudes = np.linalg.norm(w_normed_evolved, axis=1)**2\n            return amplitudes\n\n        amplitudes_rand = compute_amplitudes(random_ensemble)\n        amplitudes_sv = compute_amplitudes(sv_ensemble)\n\n        # Step 5: Perform statistical test and check conditions\n        mean_rand = np.mean(amplitudes_rand)\n        mean_sv = np.mean(amplitudes_sv)\n\n        # Use Welch's t-test for a one-sided hypothesis H1: mean_sv > mean_rand\n        _, p_value = ttest_ind(\n            amplitudes_sv, amplitudes_rand, \n            equal_var=False, alternative='greater'\n        )\n\n        # The result is true if mean of SV is strictly larger AND p-value is significant\n        is_improvement = (mean_sv > mean_rand) and (p_value  alpha)\n        results.append(is_improvement)\n    \n    # Format boolean results to be lowercase strings for the join map.\n    # The problem description's example output shows \"True\", \"False\" which str() does.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}