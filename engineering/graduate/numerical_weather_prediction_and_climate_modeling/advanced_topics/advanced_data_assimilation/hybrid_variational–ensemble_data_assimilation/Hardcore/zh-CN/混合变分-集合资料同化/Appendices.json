{
    "hands_on_practices": [
        {
            "introduction": "数据同化的核心是模型预测与现实观测的最优组合。第一个实践练习将复杂性剥离，揭示其基本原理：贝叶斯推断。通过一个简单的一维示例，你将看到背景估计（先验）如何被观测（似然）更新，从而产生更准确的分析（后验），其中权重由它们各自的不确定性决定。这个练习  为后续更复杂的系统建立了坚实的理论基础。",
            "id": "3795131",
            "problem": "考虑使用混合集合-变分（EnVar）数据同化方法，在单个格点上进行一维海表温度分析，其中混合背景协方差由一个有效的标量方差表示。假设观测模型为线性且误差为高斯分布，这与线性高斯极限情况一致，在该极限下，混合方法简化为使用有效背景协方差的贝叶斯更新。具体而言，令真实状态 $x$（温度，单位：摄氏度）服从均值为 $x_b$、方差为 $B$ 的高斯先验分布，并令观测算子为 $H$，使得观测值 $y$ 满足 $y = H x + \\varepsilon$，其中观测误差 $\\varepsilon$ 服从均值为零、方差为 $R$ 的高斯分布。因此，先验和似然与线性高斯贝叶斯估计的基本假设一致。\n\n对于 $H = 1$ 的单个直接温度计观测，使用以下物理上合理的参数：$x_b = 10$（摄氏度），$B = 4$（平方摄氏度），$y = 12$（摄氏度），以及 $R = 1$（平方摄氏度）。从高斯先验和似然的定义以及贝叶斯定理的应用出发，在线性高斯设定下推导给定 $y$ 时 $x$ 的后验分布，然后计算后验均值 $x_a$（分析温度）和后验方差 $P_a$（分析不确定性）。\n\n将后验均值 $x_a$ 以摄氏度表示，后验方差 $P_a$ 以平方摄氏度表示。最终的数值应为精确值（不要四舍五入）。将最终答案以有序对 $\\left(x_a, P_a\\right)$ 的形式报告。",
            "solution": "问题陈述已经过严格验证，被认为是有效的。它具有科学依据、适定且客观。该问题提供了一套自洽、一致的参数，并要求进行贝叶斯统计中的标准推导，这是数据同化的基石。\n\n该问题要求计算在给定先验分布和观测值 $y$ 的情况下，状态变量 $x$（温度）的后验概率分布 $p(x|y)$。根据贝叶斯定理，后验分布正比于似然函数与先验分布的乘积：\n$$\np(x|y) \\propto p(y|x) p(x)\n$$\n状态 $x$ 的先验分布是均值为 $x_b$、方差为 $B$ 的高斯分布：\n$$\np(x) = \\mathcal{N}(x; x_b, B) = \\frac{1}{\\sqrt{2\\pi B}} \\exp\\left(-\\frac{1}{2} \\frac{(x-x_b)^2}{B}\\right)\n$$\n观测模型为 $y = Hx + \\varepsilon$，其中观测误差 $\\varepsilon$ 从均值为 0、方差为 $R$ 的高斯分布中抽取。这意味着似然函数，即在给定状态 $x$ 的情况下观测到 $y$ 的概率，也是一个均值为 $Hx$、方差为 $R$ 的高斯分布：\n$$\np(y|x) = \\mathcal{N}(y; Hx, R) = \\frac{1}{\\sqrt{2\\pi R}} \\exp\\left(-\\frac{1}{2} \\frac{(y-Hx)^2}{R}\\right)\n$$\n将这些代入贝叶斯定理：\n$$\np(x|y) \\propto \\exp\\left(-\\frac{1}{2} \\frac{(y-Hx)^2}{R}\\right) \\exp\\left(-\\frac{1}{2} \\frac{(x-x_b)^2}{B}\\right)\n$$\n$$\np(x|y) \\propto \\exp\\left(-\\frac{1}{2} \\left[ \\frac{(y-Hx)^2}{R} + \\frac{(x-x_b)^2}{B} \\right]\\right)\n$$\n方括号中的项是变分代价函数，通常表示为 $J(x)$。后验分布是一个高斯分布，因为两个高斯分布的乘积是一个未归一化的高斯分布。为了找到其参数（均值 $x_a$ 和方差 $P_a$），我们需要将指数项重新整理成规范的二次型形式 $-\\frac{1}{2} \\frac{(x-x_a)^2}{P_a}$。\n我们来分析指数项 $J(x)$：\n$$\nJ(x) = \\frac{(y-Hx)^2}{R} + \\frac{(x-x_b)^2}{B}\n$$\n我们展开平方项：\n$$\nJ(x) = \\frac{y^2 - 2yHx + H^2x^2}{R} + \\frac{x^2 - 2xx_b + x_b^2}{B}\n$$\n现在，我们按 $x$ 的幂次合并同类项：\n$$\nJ(x) = x^2 \\left(\\frac{H^2}{R} + \\frac{1}{B}\\right) - 2x \\left(\\frac{Hy}{R} + \\frac{x_b}{B}\\right) + \\left(\\frac{y^2}{R} + \\frac{x_b^2}{B}\\right)\n$$\n为了对 $x$ 进行配方，我们识别出 $\\frac{1}{P_a}(x-x_a)^2 = \\frac{1}{P_a}(x^2 - 2xx_a + x_a^2)$ 的形式。\n比较 $x^2$ 的系数，我们得到后验方差 $P_a$ 的倒数：\n$$\n\\frac{1}{P_a} = \\frac{H^2}{R} + \\frac{1}{B}\n$$\n比较 $-2x$ 项的系数，我们有：\n$$\n\\frac{x_a}{P_a} = \\frac{Hy}{R} + \\frac{x_b}{B}\n$$\n由此，我们可以解出后验均值 $x_a$：\n$$\nx_a = P_a \\left(\\frac{Hy}{R} + \\frac{x_b}{B}\\right)\n$$\n代入 $P_a^{-1}$ 的表达式：\n$$\nx_a = \\left(\\frac{H^2}{R} + \\frac{1}{B}\\right)^{-1} \\left(\\frac{Hy}{R} + \\frac{x_b}{B}\\right)\n$$\n问题指定了直接观测，所以观测算子 $H$ 是单位算子，$H=1$。公式简化为：\n$$\n\\frac{1}{P_a} = \\frac{1}{R} + \\frac{1}{B} = \\frac{B+R}{BR} \\implies P_a = \\frac{BR}{B+R}\n$$\n对于后验均值 $x_a$：\n$$\nx_a = P_a \\left(\\frac{y}{R} + \\frac{x_b}{B}\\right) = \\frac{BR}{B+R} \\left(\\frac{yB + x_bR}{BR}\\right) = \\frac{yB + x_bR}{B+R}\n$$\n$x_a$ 的这个表达式可以解释为背景均值 $x_b$ 和观测值 $y$ 的加权平均：\n$$\nx_a = \\left(\\frac{R}{B+R}\\right)x_b + \\left(\\frac{B}{B+R}\\right)y\n$$\n观测值的权重是 $K = \\frac{B}{B+R}$，在这种标量情况下称为卡尔曼增益。\n\n现在，我们代入给定的数值：\n- 背景均值：$x_b = 10$\n- 背景方差：$B = 4$\n- 观测值：$y = 12$\n- 观测误差方差：$R = 1$\n\n我们首先计算后验方差 $P_a$：\n$$\nP_a = \\frac{BR}{B+R} = \\frac{4 \\times 1}{4+1} = \\frac{4}{5}\n$$\n接着，我们计算后验均值 $x_a$：\n$$\nx_a = \\frac{yB + x_bR}{B+R} = \\frac{(12)(4) + (10)(1)}{4+1} = \\frac{48 + 10}{5} = \\frac{58}{5}\n$$\n因此，后验分布是均值为 $x_a = \\frac{58}{5}$、方差为 $P_a = \\frac{4}{5}$ 的高斯分布。\n分析温度为 $x_a = 11.6$ 摄氏度，分析不确定性（方差）为 $P_a = 0.8$ 平方摄氏度。问题要求给出有序对 $(x_a, P_a)$。\n\n最终答案为有序对 $\\left(x_a, P_a\\right) = \\left(\\frac{58}{5}, \\frac{4}{5}\\right)$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{58}{5} & \\frac{4}{5}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "现实世界中的系统，如大气和海洋，是多维的。本练习将基本的贝叶斯概念扩展到矢量状态，介绍了混合变分数据同化的核心组成部分。你将通过融合静态和集合衍生的信息，显式地构建一个混合背景误差协方差矩阵（$B_{\\text{hyb}}$）。在这个小而完整的系统中求解分析增量 ，将为你提供支撑业务化三维变分系统运行的核心矩阵代数运算的实践经验。",
            "id": "4053122",
            "problem": "考虑在数值天气预报和气候模拟中，针对单个分析时刻的线性高斯三维变分资料同化。设状态增量为三维向量 $\\delta \\mathbf{x} \\in \\mathbb{R}^{3}$，两个独立观测被收集在一个二维向量 $\\mathbf{y} \\in \\mathbb{R}^{2}$ 中。从模式空间映射到观测空间的观测算子是线性的，用矩阵 $\\mathbf{H} \\in \\mathbb{R}^{2 \\times 3}$ 表示，观测误差协方差矩阵为 $\\mathbf{R} \\in \\mathbb{R}^{2 \\times 2}$。假设混合背景误差协方差是通过静态协方差 $\\mathbf{B}_{\\text{stat}} \\in \\mathbb{R}^{3 \\times 3}$ 和局地化集合协方差 $\\mathbf{P}_{e} \\in \\mathbb{R}^{3 \\times 3}$ 的线性组合构建的，标量权重为 $w \\in (0,1)$：\n$$\n\\mathbf{B}_{\\text{hyb}} = w \\,\\mathbf{B}_{\\text{stat}} + (1-w)\\,\\mathbf{P}_{e}.\n$$\n新息定义为 $\\mathbf{d} = \\mathbf{y} - \\mathbf{H}\\mathbf{x}_{b}$，其中 $\\mathbf{x}_{b}$ 是模式空间中的背景态。分析增量 $\\delta \\mathbf{x}$ 最小化标准线性高斯三维变分代价函数\n$$\nJ(\\delta \\mathbf{x}) = \\frac{1}{2}\\,\\delta \\mathbf{x}^{\\top}\\mathbf{B}_{\\text{hyb}}^{-1}\\delta \\mathbf{x} + \\frac{1}{2}\\,\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big)^{\\top}\\mathbf{R}^{-1}\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big).\n$$\n使用此框架，推导分析增量的表达式，然后对以下给定的矩阵和向量进行显式计算：\n- 静态背景误差协方差\n$$\n\\mathbf{B}_{\\text{stat}} = \\begin{pmatrix}\n4  1  2 \\\\\n1  2  0 \\\\\n2  0  5\n\\end{pmatrix}.\n$$\n- 局地化集合协方差\n$$\n\\mathbf{P}_{e} = \\begin{pmatrix}\n3  0  1 \\\\\n0  2  0 \\\\\n1  0  4\n\\end{pmatrix}.\n$$\n- 混合权重 $w = \\frac{1}{2}$。\n- 观测算子\n$$\n\\mathbf{H} = \\begin{pmatrix}\n1  0  1 \\\\\n0  1  0\n\\end{pmatrix}.\n$$\n- 观测误差协方差\n$$\n\\mathbf{R} = \\begin{pmatrix}\n1  0 \\\\\n0  2\n\\end{pmatrix}.\n$$\n- 新息\n$$\n\\mathbf{d} = \\begin{pmatrix}\n2 \\\\\n-1\n\\end{pmatrix}.\n$$\n从给定的代价函数定义和基本线性估计原理出发，求得分析增量，然后逐步执行所有矩阵向量运算（包括所有中间乘积和逆）来计算 $\\delta \\mathbf{x}$。使用 LaTeX 的 `pmatrix` 环境将最终答案表示为单个行矩阵。不需要四舍五入，也不涉及单位。",
            "solution": "该问题陈述已经过验证，被认为是具有科学依据、适定且客观的。它展示了带有混合背景误差协方差模型的三维变分资料同化（3D-Var）的一个标准应用。所有给定的矩阵和向量在维度上是一致的，并且协方差矩阵（$\\mathbf{B}_{\\text{stat}}$, $\\mathbf{P}_{e}$, $\\mathbf{R}$）是对称且正定的，这确保了代价函数有唯一的最小值。因此，该问题是有效的，并且可以推导出解。\n\n分析增量 $\\delta \\mathbf{x}$ 是最小化代价函数 $J(\\delta \\mathbf{x})$ 的向量。代价函数由下式给出：\n$$\nJ(\\delta \\mathbf{x}) = \\frac{1}{2}\\,\\delta \\mathbf{x}^{\\top}\\mathbf{B}_{\\text{hyb}}^{-1}\\delta \\mathbf{x} + \\frac{1}{2}\\,\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big)^{\\top}\\mathbf{R}^{-1}\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big)\n$$\n为了找到最小值，我们必须计算 $J(\\delta \\mathbf{x})$ 关于 $\\delta \\mathbf{x}$ 的梯度，并将其设为零向量。首先，我们展开第二项：\n$$\n\\frac{1}{2}\\,\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big)^{\\top}\\mathbf{R}^{-1}\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big) = \\frac{1}{2}\\left( (\\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top} - \\mathbf{d}^{\\top})\\mathbf{R}^{-1}(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}) \\right)\n$$\n$$\n= \\frac{1}{2}\\left( \\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x} - \\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d} - \\mathbf{d}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x} + \\mathbf{d}^{\\top}\\mathbf{R}^{-1}\\mathbf{d} \\right)\n$$\n由于 $\\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d}$ 是一个标量，它等于其转置 $\\mathbf{d}^{\\top}(\\mathbf{R}^{-1})^{\\top}\\mathbf{H}\\delta \\mathbf{x}$。鉴于协方差矩阵 $\\mathbf{R}$ 是对称的，其逆矩阵 $\\mathbf{R}^{-1}$ 也是对称的。因此，$\\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d} = \\mathbf{d}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x}$。代价函数变为：\n$$\nJ(\\delta \\mathbf{x}) = \\frac{1}{2}\\delta \\mathbf{x}^{\\top}\\mathbf{B}_{\\text{hyb}}^{-1}\\delta \\mathbf{x} + \\frac{1}{2}\\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x} + \\frac{1}{2}\\mathbf{d}^{\\top}\\mathbf{R}^{-1}\\mathbf{d}\n$$\n现在，我们使用矩阵微积分恒等式 $\\nabla_{\\mathbf{x}}(\\mathbf{x}^{\\top}\\mathbf{A}\\mathbf{x}) = 2\\mathbf{A}\\mathbf{x}$（对于对称矩阵 $\\mathbf{A}$）和 $\\nabla_{\\mathbf{x}}(\\mathbf{b}^{\\top}\\mathbf{x}) = \\mathbf{b}$，对 $\\delta \\mathbf{x}$ 求梯度：\n$$\n\\nabla_{\\delta \\mathbf{x}} J(\\delta \\mathbf{x}) = \\mathbf{B}_{\\text{hyb}}^{-1}\\delta \\mathbf{x} + \\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d}\n$$\n将梯度设为零，$\\nabla_{\\delta \\mathbf{x}} J(\\delta \\mathbf{x}) = \\mathbf{0}$，得到：\n$$\n(\\mathbf{B}_{\\text{hyb}}^{-1} + \\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{H})\\delta \\mathbf{x} = \\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d}\n$$\n$\\delta \\mathbf{x}$ 的解在形式上为 $\\delta \\mathbf{x} = (\\mathbf{B}_{\\text{hyb}}^{-1} + \\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{H})^{-1}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d}$。使用 Woodbury 矩阵恒等式，可以证明这等价于卡尔曼增益形式，后者更便于计算：\n$$\n\\delta \\mathbf{x} = \\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top}(\\mathbf{H}\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top} + \\mathbf{R})^{-1}\\mathbf{d}\n$$\n我们现在将使用给定的值逐步计算此表达式。\n\n第 1 步：计算混合背景误差协方差矩阵 $\\mathbf{B}_{\\text{hyb}}$。\n当 $w = \\frac{1}{2}$ 时，我们有：\n$$\n\\mathbf{B}_{\\text{hyb}} = \\frac{1}{2}\\mathbf{B}_{\\text{stat}} + \\left(1-\\frac{1}{2}\\right)\\mathbf{P}_{e} = \\frac{1}{2}(\\mathbf{B}_{\\text{stat}} + \\mathbf{P}_{e})\n$$\n$$\n\\mathbf{B}_{\\text{stat}} + \\mathbf{P}_{e} = \\begin{pmatrix} 4  1  2 \\\\ 1  2  0 \\\\ 2  0  5 \\end{pmatrix} + \\begin{pmatrix} 3  0  1 \\\\ 0  2  0 \\\\ 1  0  4 \\end{pmatrix} = \\begin{pmatrix} 7  1  3 \\\\ 1  4  0 \\\\ 3  0  9 \\end{pmatrix}\n$$\n$$\n\\mathbf{B}_{\\text{hyb}} = \\frac{1}{2}\\begin{pmatrix} 7  1  3 \\\\ 1  4  0 \\\\ 3  0  9 \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{2}  \\frac{1}{2}  \\frac{3}{2} \\\\ \\frac{1}{2}  2  0 \\\\ \\frac{3}{2}  0  \\frac{9}{2} \\end{pmatrix}\n$$\n\n第 2 步：计算矩阵项 $\\mathbf{M} = \\mathbf{H}\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top} + \\mathbf{R}$。\n首先，我们计算 $\\mathbf{H}\\mathbf{B}_{\\text{hyb}}$：\n$$\n\\mathbf{H}\\mathbf{B}_{\\text{hyb}} = \\begin{pmatrix} 1  0  1 \\\\ 0  1  0 \\end{pmatrix} \\begin{pmatrix} \\frac{7}{2}  \\frac{1}{2}  \\frac{3}{2} \\\\ \\frac{1}{2}  2  0 \\\\ \\frac{3}{2}  0  \\frac{9}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{2}+\\frac{3}{2}  \\frac{1}{2}+0  \\frac{3}{2}+\\frac{9}{2} \\\\ \\frac{1}{2}  2  0 \\end{pmatrix} = \\begin{pmatrix} 5  \\frac{1}{2}  6 \\\\ \\frac{1}{2}  2  0 \\end{pmatrix}\n$$\n接下来，我们计算 $\\mathbf{H}\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top}$：\n$$\n\\mathbf{H}\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top} = \\begin{pmatrix} 5  \\frac{1}{2}  6 \\\\ \\frac{1}{2}  2  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  0 \\end{pmatrix} = \\begin{pmatrix} 5(1)+6(1)  5(0)+\\frac{1}{2}(1) \\\\ \\frac{1}{2}(1)+0(1)  \\frac{1}{2}(0)+2(1) \\end{pmatrix} = \\begin{pmatrix} 11  \\frac{1}{2} \\\\ \\frac{1}{2}  2 \\end{pmatrix}\n$$\n现在，我们加上 $\\mathbf{R}$ 以构成 $\\mathbf{M}$：\n$$\n\\mathbf{M} = \\begin{pmatrix} 11  \\frac{1}{2} \\\\ \\frac{1}{2}  2 \\end{pmatrix} + \\begin{pmatrix} 1  0 \\\\ 0  2 \\end{pmatrix} = \\begin{pmatrix} 12  \\frac{1}{2} \\\\ \\frac{1}{2}  4 \\end{pmatrix}\n$$\n\n第 3 步：计算逆矩阵 $\\mathbf{M}^{-1}$。\n$\\mathbf{M}$ 的行列式是：\n$$\n\\det(\\mathbf{M}) = (12)(4) - \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) = 48 - \\frac{1}{4} = \\frac{191}{4}\n$$\n逆矩阵是：\n$$\n\\mathbf{M}^{-1} = \\frac{1}{\\det(\\mathbf{M})} \\begin{pmatrix} 4  -\\frac{1}{2} \\\\ -\\frac{1}{2}  12 \\end{pmatrix} = \\frac{4}{191} \\begin{pmatrix} 4  -\\frac{1}{2} \\\\ -\\frac{1}{2}  12 \\end{pmatrix} = \\frac{1}{191} \\begin{pmatrix} 16  -2 \\\\ -2  48 \\end{pmatrix}\n$$\n\n第 4 步：计算项 $\\mathbf{M}^{-1}\\mathbf{d}$。\n$$\n\\mathbf{M}^{-1}\\mathbf{d} = \\frac{1}{191} \\begin{pmatrix} 16  -2 \\\\ -2  48 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} = \\frac{1}{191} \\begin{pmatrix} 16(2) + (-2)(-1) \\\\ -2(2) + 48(-1) \\end{pmatrix} = \\frac{1}{191} \\begin{pmatrix} 32+2 \\\\ -4-48 \\end{pmatrix} = \\frac{1}{191} \\begin{pmatrix} 34 \\\\ -52 \\end{pmatrix}\n$$\n\n第 5 步：计算项 $\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top}$。\n因为 $\\mathbf{B}_{\\text{hyb}}$ 是对称的，所以这是第 2 步中计算的矩阵 $\\mathbf{H}\\mathbf{B}_{\\text{hyb}}$ 的转置。\n$$\n\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top} = \\begin{pmatrix} 5  \\frac{1}{2}  6 \\\\ \\frac{1}{2}  2  0 \\end{pmatrix}^{\\top} = \\begin{pmatrix} 5  \\frac{1}{2} \\\\ \\frac{1}{2}  2 \\\\ 6  0 \\end{pmatrix}\n$$\n\n第 6 步：计算最终的分析增量 $\\delta \\mathbf{x}$。\n$$\n\\delta \\mathbf{x} = (\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top}) (\\mathbf{M}^{-1}\\mathbf{d})\n$$\n$$\n\\delta \\mathbf{x} = \\begin{pmatrix} 5  \\frac{1}{2} \\\\ \\frac{1}{2}  2 \\\\ 6  0 \\end{pmatrix} \\left( \\frac{1}{191} \\begin{pmatrix} 34 \\\\ -52 \\end{pmatrix} \\right) = \\frac{1}{191} \\begin{pmatrix} 5(34) + \\frac{1}{2}(-52) \\\\ \\frac{1}{2}(34) + 2(-52) \\\\ 6(34) + 0(-52) \\end{pmatrix}\n$$\n$$\n\\delta \\mathbf{x} = \\frac{1}{191} \\begin{pmatrix} 170 - 26 \\\\ 17 - 104 \\\\ 204 \\end{pmatrix} = \\frac{1}{191} \\begin{pmatrix} 144 \\\\ -87 \\\\ 204 \\end{pmatrix} = \\begin{pmatrix} \\frac{144}{191} \\\\ -\\frac{87}{191} \\\\ \\frac{204}{191} \\end{pmatrix}\n$$\n问题要求将结果表示为单个行矩阵。\n$$\n\\delta \\mathbf{x}^{\\top} = \\begin{pmatrix} \\frac{144}{191}  -\\frac{87}{191}  \\frac{204}{191} \\end{pmatrix}\n$$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{144}{191} & -\\frac{87}{191} & \\frac{204}{191} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "业务化模型中的状态向量可能包含数十亿个变量，这使得直接求解分析方程在计算上是不可行的。最后一个实践练习介绍了一项关键的优化技术：在集合子空间中求解问题。你将学习如何将分析增量表示为少数集合成员的线性组合，从而将一个巨大的问题转化为一个可解的小问题。这种集合空间方法  是现代混合数据同化系统的基石，使其在实际应用中变得可行。",
            "id": "4053084",
            "problem": "考虑一个用于数值天气预报 (NWP) 的数据同化 (DA) 中的线性观测模型：观测值 $y$ 与模式状态 $x$ 通过 $y = H x + \\varepsilon$ 相关联，其中 $H$ 是一个线性观测算子，$\\varepsilon$ 是观测误差，假设其服从零均值和协方差矩阵为 $R$ 的高斯分布。在混合变分-集合体DA中，背景场误差协方差在集合空间中被近似为 $B \\approx X X^T$，其中 $X \\in \\mathbb{R}^{n \\times m}$ 在一个维度为 $n$ 的模式空间中包含了 $m$ 列缩放后的集合异常。集合空间增量被参数化为 $\\delta x = X w$，其中 $w \\in \\mathbb{R}^m$ 是集合权重。观测新息为 $d = y - H x^b$，其中 $x^b$ 是背景场状态。\n\n在线性高斯假设下，以及从高斯-马尔可夫定理和贝叶斯估计推导出的二次代价函数，通过最小化集合空间中的代价函数，可以得到关于集合权重 $w$ 的正规方程：\n$$(I + (H X)^T R^{-1} H X) w = (H X)^T R^{-1} d,$$\n模式空间增量则通过 $\\delta x = X w$ 恢复。此处，$I$ 是维度为 $m$ 的单位矩阵。本问题中所有的矩阵 $R$ 都是对称正定 (SPD) 的，这确保了 $R^{-1}$ 存在且该系统有唯一解。\n\n您的任务是实现一个完整、可运行的程序，该程序能够：\n- 构建 $Y = H X$，\n- 使用避免显式计算 $R^{-1}$ 的数值稳定方法，在SPD线性系统 $(I + Y^T R^{-1} Y) w = Y^T R^{-1} d$ 中求解 $w$，\n- 将 $w$ 映射回模式空间以获得 $\\delta x = X w$，\n- 报告每个测试用例中 $w$ 的欧几里得范数和 $\\delta x$ 的欧几里得范数。\n\n您必须基于基本原理推导算法：线性高斯估计、最小二乘正规方程以及SPD矩阵的性质，不得使用超出这些基础的捷径公式。您的实现必须是数值稳定的，并且不得计算任何显式的矩阵逆。请使用适合SPD矩阵的直接求解器。\n\n此问题中没有物理单位；所有量纲均为无量纲。不涉及角度和百分比。\n\n测试套件：\n使用以下三个测试用例，每个用例都由 $(H, X, R, d)$ 及其精确的数值条目指定。\n\n- 测试用例1（正常路径，对角阵 $R$，简单的 $H$）：\n  - $n = 3$, $m = 2$, $p = 2$。\n  - $X = \\begin{bmatrix} 0.8  -0.2 \\\\ 0.1  0.4 \\\\ -0.3  0.5 \\end{bmatrix}$。\n  - $H = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\end{bmatrix}$。\n  - $R = \\mathrm{diag}([0.09, 0.04]) = \\begin{bmatrix} 0.09  0 \\\\ 0  0.04 \\end{bmatrix}$。\n  - $d = \\begin{bmatrix} 0.5 \\\\ -0.1 \\end{bmatrix}$。\n\n- 测试用例2（非对角相关的 $R$，非平凡的 $H$，$X$ 中存在近似共线的列）：\n  - $n = 4$, $m = 3$, $p = 3$。\n  - $X = \\begin{bmatrix}\n    0.6  0.58  -0.12 \\\\\n    0.2  0.21  0.05 \\\\\n    -0.1  -0.098  0.02 \\\\\n    0.0  0.01  -0.03\n  \\end{bmatrix}$。\n  - $H = \\begin{bmatrix}\n    1  0  0  0 \\\\\n    0  1  1  0 \\\\\n    0.5  0  0  1\n  \\end{bmatrix}$。\n  - $R = \\begin{bmatrix}\n    0.04  0.01  0.0 \\\\\n    0.01  0.09  0.02 \\\\\n    0.0  0.02  0.16\n  \\end{bmatrix}$。\n  - $d = \\begin{bmatrix} -0.2 \\\\ 0.3 \\\\ 0.05 \\end{bmatrix}$。\n\n- 测试用例3（由于 $X$ 中列的共线性导致 $Y$ 秩亏，小 $R$ 带来的强观测）：\n  - $n = 2$, $m = 2$, $p = 2$。\n  - $X = \\begin{bmatrix} 1.0  2.0 \\\\ 2.0  4.0 \\end{bmatrix}$。\n  - $H = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$。\n  - $R = \\mathrm{diag}([0.01, 0.01]) = \\begin{bmatrix} 0.01  0 \\\\ 0  0.01 \\end{bmatrix}$。\n  - $d = \\begin{bmatrix} 0.3 \\\\ -0.6 \\end{bmatrix}$。\n\n输出规范：\n对于每个测试用例，计算欧几里得范数 $\\|w\\|_2$ 和 $\\|\\delta x\\|_2$。您的程序应生成单行输出，其中按顺序包含这六个浮点数值，格式为用方括号括起来的逗号分隔列表：$[\\|w_1\\|_2, \\|\\delta x_1\\|_2, \\|w_2\\|_2, \\|\\delta x_2\\|_2, \\|w_3\\|_2, \\|\\delta x_3\\|_2]$。将每个值表示为标准十进制数。不应打印其他任何文本。",
            "solution": "该问题要求在一个混合变分-集合体数据同化框架中，求解关于集合权重 $w$ 的正规方程。我们还被要求计算由此产生的模式空间增量 $\\delta x$。解决方案必须从基本原理推导得出，并以数值稳定的方式实现，特别是要避免任何矩阵逆的显式计算。\n\n该问题已经过验证，被认为是具有科学依据、适定、客观且内部一致的。所有必要的数据都已提供。该公式是在线性高斯假设下，变分数据同化系统中基于集合的更新步骤的标准表示。正规方程中单位矩阵 $I$ 的存在提供了正则化，确保了即使在投影的集合异常 $HX$ 是秩亏的情况下（如测试用例3中所示），该系统仍然是可解的。\n\n控制方程如下：\n$$(I + (H X)^T R^{-1} H X) w = (H X)^T R^{-1} d$$\n$$\\delta x = X w$$\n\n让我们将投影集合异常矩阵定义为 $Y = H X$。这些矩阵的维度分别为 $H \\in \\mathbb{R}^{p \\times n}$，$X \\in \\mathbb{R}^{n \\times m}$，$Y \\in \\mathbb{R}^{p \\times m}$，$R \\in \\mathbb{R}^{p \\times p}$，$d \\in \\mathbb{R}^{p}$，以及 $w \\in \\mathbb{R}^{m}$。单位矩阵 $I$ 的维度为 $m \\times m$。正规方程可以更紧凑地重写为：\n$$(I + Y^T R^{-1} Y) w = Y^T R^{-1} d$$\n\n一种直接但数值不稳定的方法是显式计算 $R^{-1}$，然后构建方程组。题目正确地禁止了这种做法。一种在数值上更优的策略是利用观测误差协方差矩阵 $R$ 的性质，该矩阵被指定为对称正定 (SPD)。对于一个SPD矩阵，我们可以使用其Cholesky分解来求解涉及其逆的线性系统。\n\n令 $R = L L^T$ 为 $R$ 的Cholesky分解，其中 $L$ 是一个下三角矩阵。那么其逆 $R^{-1}$ 就是 $ (L L^T)^{-1} = (L^T)^{-1} L^{-1}$。为了计算像 $R^{-1} M$ 这样的乘积（其中 $M$ 是某个矩阵），我们不应计算逆因子，而应求解方程组 $R Z = M$。这可以通过两个步骤完成：\n1. 使用前向代换求解 $L V = M$ 得到 $V$。\n2. 使用回代求解 $L^T Z = V$ 得到 $Z$。\n\n这个过程使我们能够在不构造任何逆矩阵的情况下计算出 $R^{-1}Y$ 和 $R^{-1}d$。我们定义两个中间量：\n1. $Z = R^{-1} Y$\n2. $v = R^{-1} d$\n\n这些量可以通过使用 $R$ 的Cholesky分解来分别求解线性系统 $RZ = Y$ 和 $Rv = d$ 来高效地计算。为了提高实现效率，可以构造一个增广矩阵 $[Y | d]$ 并求解单个系统。\n\n一旦 $Z$ 和 $v$ 已知，正规方程变为：\n$$(I + Y^T Z) w = Y^T v$$\n\n我们定义系统矩阵 $A = I + Y^T Z$ 和右端向量 $b = Y^T v$。需要求解的系统是 $A w = b$。我们必须分析矩阵 $A$ 的性质。\n矩阵 $A$ 是SPD的。单位矩阵 $I$ 是SPD的。矩阵 $Y^T R^{-1} Y = Y^T Z$ 至少是半正定 (PSD) 的，因为对于任意向量 $u \\in \\mathbb{R}^m$，有 $u^T (Y^T R^{-1} Y) u = (Y u)^T R^{-1} (Y u)$。由于 $R^{-1}$ 是SPD的，因此 $(Y u)^T R^{-1} (Y u) \\geq 0$。一个SPD矩阵（$I$）和一个PSD矩阵（$Y^T Z$）的和总是SPD的。\n\n由于 $A$ 是一个SPD矩阵，系统 $A w = b$ 有唯一解，并且最好再次使用Cholesky分解来求解。令 $A = L_A L_A^T$。我们可以通过以下步骤找到 $w$：\n1. 使用前向代换求解 $L_A u = b$ 得到 $u$。\n2. 使用回代求解 $L_A^T w = u$ 得到 $w$。\n\n在获得集合权重 $w$ 的解之后，通过线性变换 $\\delta x = X w$ 恢复模式空间增量 $\\delta x$。\n\n最后，按照要求为每个测试用例计算所得向量的欧几里得范数 $\\|w\\|_2$ 和 $\\|\\delta x\\|_2$。\n\n完整的算法如下：\n1. 对于每个测试用例，给定矩阵 $H, X, R$ 和向量 $d$：\n2. 计算 $Y = H X$。\n3. 计算 $R = L L^T$ 的Cholesky分解。\n4. 从系统 $R S = [Y | d]$ 中求解中间矩阵 $S$，其中 $[Y|d]$ 是 $Y$ 和 $d$ 的拼接。这通过使用 $L$ 进行前向和回代来完成。令 $Z$ 为 $S$ 的前 $m$ 列（对应于 $R^{-1}Y$），令 $v$ 为 $S$ 的最后一列（对应于 $R^{-1}d$）。\n5. 构建SPD系统矩阵 $A = I + Y^T Z$。\n6. 构建右端向量 $b = Y^T v$。\n7. 计算 $A = L_A L_A^T$ 的Cholesky分解。\n8. 使用 $L_A$ 进行前向和回代，求解系统 $A w = b$ 得到 $w$。\n9. 计算模式空间增量 $\\delta x = X w$。\n10. 计算欧几里得范数 $\\|w\\|_2$ 和 $\\|\\delta x\\|_2$。\n11. 收集并报告结果。\n\n此过程遵循了所有问题约束，并建立在用于解决线性高斯估计问题的数值线性代数的既定原则之上。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import cho_factor, cho_solve\n\ndef solve():\n    \"\"\"\n    Solves the ensemble-space data assimilation problem for three test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        (\n            np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]), # H\n            np.array([[0.8, -0.2], [0.1, 0.4], [-0.3, 0.5]]), # X\n            np.array([[0.09, 0.0], [0.0, 0.04]]), # R\n            np.array([0.5, -0.1]) # d\n        ),\n        # Test Case 2\n        (\n            np.array([[1.0, 0.0, 0.0, 0.0], \n                      [0.0, 1.0, 1.0, 0.0], \n                      [0.5, 0.0, 0.0, 1.0]]), # H\n            np.array([[0.6, 0.58, -0.12],\n                      [0.2, 0.21, 0.05],\n                      [-0.1, -0.098, 0.02],\n                      [0.0, 0.01, -0.03]]), # X\n            np.array([[0.04, 0.01, 0.0], \n                      [0.01, 0.09, 0.02], \n                      [0.0, 0.02, 0.16]]), # R\n            np.array([-0.2, 0.3, 0.05]) # d\n        ),\n        # Test Case 3\n        (\n            np.array([[1.0, 0.0], [0.0, 1.0]]), # H\n            np.array([[1.0, 2.0], [2.0, 4.0]]), # X\n            np.array([[0.01, 0.0], [0.0, 0.01]]), # R\n            np.array([0.3, -0.6]) # d\n        )\n    ]\n\n    results = []\n    \n    for H, X, R, d in test_cases:\n        # Get dimensions\n        # n = X.shape[0]  # model space dim\n        m = X.shape[1]  # ensemble size\n        # p = H.shape[0] # observation space dim\n\n        # Step 1: Form Y = H X\n        Y = H @ X\n\n        # Step 2: Solve systems involving R^{-1} without explicit inversion.\n        # We need to compute Z = R^{-1}Y and v = R^{-1}d.\n        # This can be done by solving RZ=Y and Rv=d.\n        # For efficiency, we form an augmented matrix M and solve RS = M.\n        \n        # d must be a column vector for hstack\n        d_col = d.reshape(-1, 1)\n        M = np.hstack((Y, d_col))\n        \n        # Since R is SPD, use Cholesky factorization to solve RS=M.\n        # L, lower = cho_factor(R, lower=True) computes L such that R = L L^T.\n        # cho_solve((L, lower), M) solves the system efficiently.\n        try:\n            cho_R, lower_R = cho_factor(R, lower=True)\n            S = cho_solve((cho_R, lower_R), M)\n        except np.linalg.LinAlgError:\n            # This should not happen since R is specified as SPD.\n            # Handle potential numerical issues if R is only PSD.\n            # Use pseudo-inverse for a more general solver (not needed here)\n            S = np.linalg.pinv(R) @ M\n\n        # Extract Z and v from the solution S\n        Z = S[:, :m] # Z = R^{-1}Y\n        v = S[:, m]  # v = R^{-1}d\n\n        # Step 3: Form the linear system for w: (I + Y^T R^{-1} Y) w = Y^T R^{-1} d\n        # This is A w = b, where A = I + Y^T Z and b = Y^T v.\n        A = np.eye(m) + Y.T @ Z\n        b = Y.T @ v\n\n        # Step 4: Solve for w.\n        # The matrix A is guaranteed to be SPD, so we use Cholesky decomposition again.\n        try:\n            cho_A, lower_A = cho_factor(A, lower=True)\n            w = cho_solve((cho_A, lower_A), b)\n        except np.linalg.LinAlgError:\n            # Handle cases where A might be numerically ill-conditioned.\n            w = np.linalg.solve(A, b)\n\n        # Step 5: Map w back to model space to get the increment dx.\n        delta_x = X @ w\n\n        # Step 6: Compute the Euclidean norms.\n        norm_w = np.linalg.norm(w)\n        norm_delta_x = np.linalg.norm(delta_x)\n\n        results.extend([norm_w, norm_delta_x])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}