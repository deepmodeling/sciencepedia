{
    "hands_on_practices": [
        {
            "introduction": "数据同化的核心是贝叶斯统计的实际应用。第一个练习 () 将问题简化至其本质：用单个观测来更新单个状态变量。通过从基本原理推导后验均值和方差，您将为数据同化如何以最优方式融合来自模式预报（先验）和新观测（似然）的信息建立坚实的直觉。",
            "id": "3795131",
            "problem": "考虑使用混合集合-变分（EnVar）资料同化方法，在单个网格点上进行一维海表温度分析，其中混合背景协方差由一个有效的标量方差表示。假设观测模型为线性且误差为高斯分布，这与线性高斯极限情况一致，在该极限下，混合方法简化为使用有效背景协方差的贝叶斯更新。具体来说，令真实状态 $x$（单位：摄氏度）服从均值为 $x_b$、方差为 $B$ 的高斯先验分布，并令观测算子为 $H$，使得观测值 $y$ 满足 $y = H x + \\varepsilon$，其中观测误差 $\\varepsilon$ 服从均值为零、方差为 $R$ 的高斯分布。因此，先验和似然与线性高斯贝叶斯估计的基本假设一致。\n\n对于 $H = 1$ 的单个直接温度计观测，使用以下物理上合理的参数：$x_b = 10$（摄氏度），$B = 4$（平方摄氏度），$y = 12$（摄氏度），以及 $R = 1$（平方摄氏度）。从高斯先验和似然的定义以及 Bayes 定理的应用出发，在线性高斯设定下推导给定 $y$ 时 $x$ 的后验分布，然后计算后验均值 $x_a$（分析温度）和后验方差 $P_a$（分析不确定性）。\n\n将后验均值 $x_a$ 以摄氏度表示，后验方差 $P_a$ 以平方摄氏度表示。你的最终数值应为精确值（不要四舍五入）。将你的最终答案以有序对 $\\left(x_a, P_a\\right)$ 的形式报告。",
            "solution": "问题陈述已经过严格验证，被认为是有效的。它有科学依据、适定且客观。该问题提供了一套自洽、一致的参数，并要求在贝叶斯统计中进行标准推导，这是资料同化的基石。\n\n该问题要求在给定先验分布和观测值 $y$ 的情况下，求状态变量 $x$（温度）的后验概率分布 $p(x|y)$。根据 Bayes 定理，后验分布正比于似然与先验的乘积：\n$$\np(x|y) \\propto p(y|x) p(x)\n$$\n状态 $x$ 的先验分布是均值为 $x_b$、方差为 $B$ 的高斯分布：\n$$\np(x) = \\mathcal{N}(x; x_b, B) = \\frac{1}{\\sqrt{2\\pi B}} \\exp\\left(-\\frac{1}{2} \\frac{(x-x_b)^2}{B}\\right)\n$$\n观测模型为 $y = Hx + \\varepsilon$，其中观测误差 $\\varepsilon$ 从均值为 $0$、方差为 $R$ 的高斯分布中抽取。这意味着似然函数，即给定状态 $x$ 时观测到 $y$ 的概率，也是一个均值为 $Hx$、方差为 $R$ 的高斯分布：\n$$\np(y|x) = \\mathcal{N}(y; Hx, R) = \\frac{1}{\\sqrt{2\\pi R}} \\exp\\left(-\\frac{1}{2} \\frac{(y-Hx)^2}{R}\\right)\n$$\n将这些代入 Bayes 定理：\n$$\np(x|y) \\propto \\exp\\left(-\\frac{1}{2} \\frac{(y-Hx)^2}{R}\\right) \\exp\\left(-\\frac{1}{2} \\frac{(x-x_b)^2}{B}\\right)\n$$\n$$\np(x|y) \\propto \\exp\\left(-\\frac{1}{2} \\left[ \\frac{(y-Hx)^2}{R} + \\frac{(x-x_b)^2}{B} \\right]\\right)\n$$\n方括号中的项是变分代价函数，通常表示为 $J(x)$。后验分布是高斯分布，因为两个高斯分布的乘积是一个未归一化的高斯分布。为了找到其参数（均值 $x_a$ 和方差 $P_a$），我们需要将指数项重新整理成规范的二次型 $-\\frac{1}{2} \\frac{(x-x_a)^2}{P_a}$。\n让我们分析指数项 $J(x)$：\n$$\nJ(x) = \\frac{(y-Hx)^2}{R} + \\frac{(x-x_b)^2}{B}\n$$\n我们展开平方项：\n$$\nJ(x) = \\frac{y^2 - 2yHx + H^2x^2}{R} + \\frac{x^2 - 2xx_b + x_b^2}{B}\n$$\n现在，我们按 $x$ 的幂次合并各项：\n$$\nJ(x) = x^2 \\left(\\frac{H^2}{R} + \\frac{1}{B}\\right) - 2x \\left(\\frac{Hy}{R} + \\frac{x_b}{B}\\right) + \\left(\\frac{y^2}{R} + \\frac{x_b^2}{B}\\right)\n$$\n为了对 $x$ 进行配方，我们识别出 $\\frac{1}{P_a}(x-x_a)^2 = \\frac{1}{P_a}(x^2 - 2xx_a + x_a^2)$ 的形式。\n比较 $x^2$ 的系数，我们得到后验方差 $P_a$ 的倒数：\n$$\n\\frac{1}{P_a} = \\frac{H^2}{R} + \\frac{1}{B}\n$$\n比较 $-2x$ 项的系数，我们有：\n$$\n\\frac{x_a}{P_a} = \\frac{Hy}{R} + \\frac{x_b}{B}\n$$\n由此，我们可以解出后验均值 $x_a$：\n$$\nx_a = P_a \\left(\\frac{Hy}{R} + \\frac{x_b}{B}\\right)\n$$\n代入 $P_a^{-1}$ 的表达式：\n$$\nx_a = \\left(\\frac{H^2}{R} + \\frac{1}{B}\\right)^{-1} \\left(\\frac{Hy}{R} + \\frac{x_b}{B}\\right)\n$$\n问题指定了直接观测，所以观测算子 $H$ 是单位算子，$H=1$。公式简化为：\n$$\n\\frac{1}{P_a} = \\frac{1}{R} + \\frac{1}{B} = \\frac{B+R}{BR} \\implies P_a = \\frac{BR}{B+R}\n$$\n对于后验均值 $x_a$：\n$$\nx_a = P_a \\left(\\frac{y}{R} + \\frac{x_b}{B}\\right) = \\frac{BR}{B+R} \\left(\\frac{yB + x_bR}{BR}\\right) = \\frac{yB + x_bR}{B+R}\n$$\n$x_a$ 的这个表达式可以解释为背景均值 $x_b$ 和观测值 $y$ 的加权平均：\n$$\nx_a = \\left(\\frac{R}{B+R}\\right)x_b + \\left(\\frac{B}{B+R}\\right)y\n$$\n观测值的权重是 $K = \\frac{B}{B+R}$，在这种标量情况下称为 Kalman 增益。\n\n现在，我们代入给定的数值：\n- 背景均值: $x_b = 10$\n- 背景方差: $B = 4$\n- 观测值: $y = 12$\n- 观测误差方差: $R = 1$\n\n我们首先计算后验方差 $P_a$：\n$$\nP_a = \\frac{BR}{B+R} = \\frac{4 \\times 1}{4+1} = \\frac{4}{5}\n$$\n接下来，我们计算后验均值 $x_a$：\n$$\nx_a = \\frac{yB + x_bR}{B+R} = \\frac{(12)(4) + (10)(1)}{4+1} = \\frac{48 + 10}{5} = \\frac{58}{5}\n$$\n因此，后验分布是均值为 $x_a = \\frac{58}{5}$、方差为 $P_a = \\frac{4}{5}$ 的高斯分布。\n分析温度为 $x_a = 11.6$ 摄氏度，分析不确定性（方差）为 $P_a = 0.8$ 平方摄氏度。问题要求给出有序对 $(x_a, P_a)$。\n\n最终答案为有序对 $\\left(x_a, P_a\\right) = \\left(\\frac{58}{5}, \\frac{4}{5}\\right)$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{58}{5}  \\frac{4}{5}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "真实世界的系统是多维的。本练习 () 将基础概念扩展到向量状态，引入了变分分析的矩阵形式。您将通过组合静态和集合衍生的分量来构建一个混合背景误差协方差，然后求解分析增量，为三维变分（3D-Var）算法的实际运作提供一个具体的例子。",
            "id": "4053122",
            "problem": "考虑在数值天气预报和气候模拟中，针对单一分析时刻的线性、高斯三维变分资料同化。设状态增量为一个三维向量 $\\delta \\mathbf{x} \\in \\mathbb{R}^{3}$，两个独立的观测被收集到一个二维向量 $\\mathbf{y} \\in \\mathbb{R}^{2}$ 中。从模式空间映射到观测空间的观测算子是线性的，记为矩阵 $\\mathbf{H} \\in \\mathbb{R}^{2 \\times 3}$，观测误差协方差矩阵为 $\\mathbf{R} \\in \\mathbb{R}^{2 \\times 2}$。假设混合背景误差协方差由静态协方差 $\\mathbf{B}_{\\text{stat}} \\in \\mathbb{R}^{3 \\times 3}$ 和局地化集合协方差 $\\mathbf{B}_{e} \\in \\mathbb{R}^{3 \\times 3}$ 通过标量权重 $w \\in (0,1)$ 线性组合而成：\n$$\n\\mathbf{B}_{\\text{hyb}} = (1-w) \\,\\mathbf{B}_{\\text{stat}} + w\\,\\mathbf{B}_{e}.\n$$\n新息定义为 $\\mathbf{d} = \\mathbf{y} - \\mathbf{H}\\mathbf{x}_{b}$，其中 $\\mathbf{x}_{b}$ 是模式空间中的背景场状态。分析增量 $\\delta \\mathbf{x}$ 最小化标准线性高斯三维变分代价函数\n$$\nJ(\\delta \\mathbf{x}) = \\frac{1}{2}\\,\\delta \\mathbf{x}^{\\top}\\mathbf{B}_{\\text{hyb}}^{-1}\\delta \\mathbf{x} + \\frac{1}{2}\\,\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big)^{\\top}\\mathbf{R}^{-1}\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big).\n$$\n在此框架下，推导分析增量的表达式，然后使用以下给定的矩阵和向量显式计算它：\n- 静态背景误差协方差\n$$\n\\mathbf{B}_{\\text{stat}} = \\begin{pmatrix}\n4  1  2 \\\\\n1  2  0 \\\\\n2  0  5\n\\end{pmatrix}.\n$$\n- 局地化集合协方差\n$$\n\\mathbf{B}_{e} = \\begin{pmatrix}\n3  0  1 \\\\\n0  2  0 \\\\\n1  0  4\n\\end{pmatrix}.\n$$\n- 混合权重 $w = \\frac{1}{2}$。\n- 观测算子\n$$\n\\mathbf{H} = \\begin{pmatrix}\n1  0  1 \\\\\n0  1  0\n\\end{pmatrix}.\n$$\n- 观测误差协方差\n$$\n\\mathbf{R} = \\begin{pmatrix}\n1  0 \\\\\n0  2\n\\end{pmatrix}.\n$$\n- 新息\n$$\n\\mathbf{d} = \\begin{pmatrix}\n2 \\\\\n-1\n\\end{pmatrix}.\n$$\n从给定的代价函数定义和基本线性估计原理出发，求得分析增量，然后逐步执行所有矩阵-向量运算（包括所有中间乘积和逆矩阵）以计算 $\\delta \\mathbf{x}$。使用 LaTeX 的 $\\texttt{pmatrix}$ 环境将最终答案表示为单个行矩阵。无需四舍五入，也不涉及单位。",
            "solution": "问题陈述已经过验证，被认为是科学上成立、适定且客观的。它展示了带有混合背景误差协方差模型的三维变分资料同化 (3D-Var) 的一个标准应用。所有给定的矩阵和向量在维度上是一致的，且协方差矩阵（$\\mathbf{B}_{\\text{stat}}$、$\\mathbf{B}_{e}$、$\\mathbf{R}$）是对称正定的，这确保了代价函数有唯一的最小值。因此，该问题是有效的，可以推导出解。\n\n分析增量 $\\delta \\mathbf{x}$ 是使代价函数 $J(\\delta \\mathbf{x})$ 最小化的向量。代价函数由下式给出：\n$$\nJ(\\delta \\mathbf{x}) = \\frac{1}{2}\\,\\delta \\mathbf{x}^{\\top}\\mathbf{B}_{\\text{hyb}}^{-1}\\delta \\mathbf{x} + \\frac{1}{2}\\,\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big)^{\\top}\\mathbf{R}^{-1}\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big)\n$$\n为求最小值，我们必须计算 $J(\\delta \\mathbf{x})$ 关于 $\\delta \\mathbf{x}$ 的梯度，并将其设为零向量。首先，我们展开第二项：\n$$\n\\frac{1}{2}\\,\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big)^{\\top}\\mathbf{R}^{-1}\\big(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}\\big) = \\frac{1}{2}\\left( (\\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top} - \\mathbf{d}^{\\top})\\mathbf{R}^{-1}(\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}) \\right)\n$$\n$$\n= \\frac{1}{2}\\left( \\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x} - \\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d} - \\mathbf{d}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x} + \\mathbf{d}^{\\top}\\mathbf{R}^{-1}\\mathbf{d} \\right)\n$$\n由于 $\\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d}$ 是一个标量，它等于其转置 $\\mathbf{d}^{\\top}(\\mathbf{R}^{-1})^{\\top}\\mathbf{H}\\delta \\mathbf{x}$。鉴于协方差矩阵 $\\mathbf{R}$ 是对称的，其逆矩阵 $\\mathbf{R}^{-1}$ 也是对称的。因此，$\\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d} = \\mathbf{d}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x}$。代价函数变为：\n$$\nJ(\\delta \\mathbf{x}) = \\frac{1}{2}\\delta \\mathbf{x}^{\\top}\\mathbf{B}_{\\text{hyb}}^{-1}\\delta \\mathbf{x} + \\frac{1}{2}\\delta \\mathbf{x}^{\\top}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{d}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x} + \\frac{1}{2}\\mathbf{d}^{\\top}\\mathbf{R}^{-1}\\mathbf{d}\n$$\n现在，我们使用矩阵微积分恒等式 $\\nabla_{\\mathbf{x}}(\\mathbf{x}^{\\top}\\mathbf{A}\\mathbf{x}) = 2\\mathbf{A}\\mathbf{x}$（对于对称矩阵 $\\mathbf{A}$）和 $\\nabla_{\\mathbf{x}}(\\mathbf{b}^{\\top}\\mathbf{x}) = \\mathbf{b}$，求关于 $\\delta \\mathbf{x}$ 的梯度：\n$$\n\\nabla_{\\delta \\mathbf{x}} J(\\delta \\mathbf{x}) = \\mathbf{B}_{\\text{hyb}}^{-1}\\delta \\mathbf{x} + \\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{H}\\delta \\mathbf{x} - \\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d}\n$$\n将梯度设为零，$\\nabla_{\\delta \\mathbf{x}} J(\\delta \\mathbf{x}) = \\mathbf{0}$，得到：\n$$\n(\\mathbf{B}_{\\text{hyb}}^{-1} + \\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{H})\\delta \\mathbf{x} = \\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d}\n$$\n$\\delta \\mathbf{x}$ 的解在形式上为 $\\delta \\mathbf{x} = (\\mathbf{B}_{\\text{hyb}}^{-1} + \\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{H})^{-1}\\mathbf{H}^{\\top}\\mathbf{R}^{-1}\\mathbf{d}$。使用 Woodbury 矩阵恒等式，可以证明这等价于卡尔曼增益形式，后者在计算上更为方便：\n$$\n\\delta \\mathbf{x} = \\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top}(\\mathbf{H}\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top} + \\mathbf{R})^{-1}\\mathbf{d}\n$$\n我们现在将使用给定的值逐步计算此表达式。\n\n步骤 1：计算混合背景误差协方差矩阵 $\\mathbf{B}_{\\text{hyb}}$。\n根据 $w = \\frac{1}{2}$ 和公式 $\\mathbf{B}_{\\text{hyb}} = (1-w)\\mathbf{B}_{\\text{stat}} + w\\mathbf{B}_{e}$，我们有：\n$$\n\\mathbf{B}_{\\text{hyb}} = \\left(1-\\frac{1}{2}\\right)\\mathbf{B}_{\\text{stat}} + \\frac{1}{2}\\mathbf{B}_{e} = \\frac{1}{2}(\\mathbf{B}_{\\text{stat}} + \\mathbf{B}_{e})\n$$\n$$\n\\mathbf{B}_{\\text{stat}} + \\mathbf{B}_{e} = \\begin{pmatrix} 4  1  2 \\\\ 1  2  0 \\\\ 2  0  5 \\end{pmatrix} + \\begin{pmatrix} 3  0  1 \\\\ 0  2  0 \\\\ 1  0  4 \\end{pmatrix} = \\begin{pmatrix} 7  1  3 \\\\ 1  4  0 \\\\ 3  0  9 \\end{pmatrix}\n$$\n$$\n\\mathbf{B}_{\\text{hyb}} = \\frac{1}{2}\\begin{pmatrix} 7  1  3 \\\\ 1  4  0 \\\\ 3  0  9 \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{2}  \\frac{1}{2}  \\frac{3}{2} \\\\ \\frac{1}{2}  2  0 \\\\ \\frac{3}{2}  0  \\frac{9}{2} \\end{pmatrix}\n$$\n\n步骤 2：计算矩阵项 $\\mathbf{M} = \\mathbf{H}\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top} + \\mathbf{R}$。\n首先，我们计算 $\\mathbf{H}\\mathbf{B}_{\\text{hyb}}$：\n$$\n\\mathbf{H}\\mathbf{B}_{\\text{hyb}} = \\begin{pmatrix} 1  0  1 \\\\ 0  1  0 \\end{pmatrix} \\begin{pmatrix} \\frac{7}{2}  \\frac{1}{2}  \\frac{3}{2} \\\\ \\frac{1}{2}  2  0 \\\\ \\frac{3}{2}  0  \\frac{9}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{2}+\\frac{3}{2}  \\frac{1}{2}+0  \\frac{3}{2}+\\frac{9}{2} \\\\ \\frac{1}{2}  2  0 \\end{pmatrix} = \\begin{pmatrix} 5  \\frac{1}{2}  6 \\\\ \\frac{1}{2}  2  0 \\end{pmatrix}\n$$\n接下来，我们计算 $\\mathbf{H}\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top}$：\n$$\n\\mathbf{H}\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top} = \\begin{pmatrix} 5  \\frac{1}{2}  6 \\\\ \\frac{1}{2}  2  0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  0 \\end{pmatrix} = \\begin{pmatrix} 5(1)+6(1)  5(0)+\\frac{1}{2}(1) \\\\ \\frac{1}{2}(1)+0(1)  \\frac{1}{2}(0)+2(1) \\end{pmatrix} = \\begin{pmatrix} 11  \\frac{1}{2} \\\\ \\frac{1}{2}  2 \\end{pmatrix}\n$$\n现在，我们加上 $\\mathbf{R}$ 构成 $\\mathbf{M}$：\n$$\n\\mathbf{M} = \\begin{pmatrix} 11  \\frac{1}{2} \\\\ \\frac{1}{2}  2 \\end{pmatrix} + \\begin{pmatrix} 1  0 \\\\ 0  2 \\end{pmatrix} = \\begin{pmatrix} 12  \\frac{1}{2} \\\\ \\frac{1}{2}  4 \\end{pmatrix}\n$$\n\n步骤 3：计算逆矩阵 $\\mathbf{M}^{-1}$。\n$\\mathbf{M}$ 的行列式为：\n$$\n\\det(\\mathbf{M}) = (12)(4) - \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) = 48 - \\frac{1}{4} = \\frac{191}{4}\n$$\n逆矩阵为：\n$$\n\\mathbf{M}^{-1} = \\frac{1}{\\det(\\mathbf{M})} \\begin{pmatrix} 4  -\\frac{1}{2} \\\\ -\\frac{1}{2}  12 \\end{pmatrix} = \\frac{4}{191} \\begin{pmatrix} 4  -\\frac{1}{2} \\\\ -\\frac{1}{2}  12 \\end{pmatrix} = \\frac{1}{191} \\begin{pmatrix} 16  -2 \\\\ -2  48 \\end{pmatrix}\n$$\n\n步骤 4：计算项 $\\mathbf{M}^{-1}\\mathbf{d}$。\n$$\n\\mathbf{M}^{-1}\\mathbf{d} = \\frac{1}{191} \\begin{pmatrix} 16  -2 \\\\ -2  48 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} = \\frac{1}{191} \\begin{pmatrix} 16(2) + (-2)(-1) \\\\ -2(2) + 48(-1) \\end{pmatrix} = \\frac{1}{191} \\begin{pmatrix} 32+2 \\\\ -4-48 \\end{pmatrix} = \\frac{1}{191} \\begin{pmatrix} 34 \\\\ -52 \\end{pmatrix}\n$$\n\n步骤 5：计算项 $\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top}$。\n由于 $\\mathbf{B}_{\\text{hyb}}$ 是对称的，这是步骤 2 中计算的矩阵 $\\mathbf{H}\\mathbf{B}_{\\text{hyb}}$ 的转置。\n$$\n\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top} = \\begin{pmatrix} 5  \\frac{1}{2}  6 \\\\ \\frac{1}{2}  2  0 \\end{pmatrix}^{\\top} = \\begin{pmatrix} 5  \\frac{1}{2} \\\\ \\frac{1}{2}  2 \\\\ 6  0 \\end{pmatrix}\n$$\n\n步骤 6：计算最终的分析增量 $\\delta \\mathbf{x}$。\n$$\n\\delta \\mathbf{x} = (\\mathbf{B}_{\\text{hyb}}\\mathbf{H}^{\\top}) (\\mathbf{M}^{-1}\\mathbf{d})\n$$\n$$\n\\delta \\mathbf{x} = \\begin{pmatrix} 5  \\frac{1}{2} \\\\ \\frac{1}{2}  2 \\\\ 6  0 \\end{pmatrix} \\left( \\frac{1}{191} \\begin{pmatrix} 34 \\\\ -52 \\end{pmatrix} \\right) = \\frac{1}{191} \\begin{pmatrix} 5(34) + \\frac{1}{2}(-52) \\\\ \\frac{1}{2}(34) + 2(-52) \\\\ 6(34) + 0(-52) \\end{pmatrix}\n$$\n$$\n\\delta \\mathbf{x} = \\frac{1}{191} \\begin{pmatrix} 170 - 26 \\\\ 17 - 104 \\\\ 204 \\end{pmatrix} = \\frac{1}{191} \\begin{pmatrix} 144 \\\\ -87 \\\\ 204 \\end{pmatrix} = \\begin{pmatrix} \\frac{144}{191} \\\\ -\\frac{87}{191} \\\\ \\frac{204}{191} \\end{pmatrix}\n$$\n问题要求将结果表示为单个行矩阵。\n$$\n\\delta \\mathbf{x}^{\\top} = \\begin{pmatrix} \\frac{144}{191}  -\\frac{87}{191}  \\frac{204}{191} \\end{pmatrix}\n$$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{144}{191}  -\\frac{87}{191}  \\frac{204}{191} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "在可能包含数百万个变量的完整模式空间中直接求解分析问题，其计算成本是令人望而却步的。本练习 () 介绍了一项关键的优化技术：在维度低得多的集合子空间中重新构建问题。您将实现这种数值稳定的方法，以求解集合权重并恢复分析增量，从而深入了解许多业务化数据同化系统背后的高效引擎。",
            "id": "4053084",
            "problem": "考虑一个用于数值天气预报 (NWP) 的数据同化 (DA) 中的线性观测模型：观测值 $y$ 通过 $y = H x + \\varepsilon$ 与模式状态 $x$ 相关联，其中 $H$ 是一个线性观测算子，$\\varepsilon$ 是观测误差，假定其服从零均值和协方差矩阵为 $R$ 的高斯分布。在混合变分-集合 DA 中，背景误差协方差在集合空间中被近似为 $B \\approx X X^T$，其中 $X \\in \\mathbb{R}^{n \\times m}$ 包含 $m$ 列在维度为 $n$ 的模式空间中的缩放后的集合异常。集合空间增量被参数化为 $\\delta x = X w$，其中 $w \\in \\mathbb{R}^m$ 是集合权重。观测新息为 $d = y - H x^b$，其中 $x^b$ 是背景状态。\n\n在线性高斯假设下，以及根据 Gauss–Markov 定理和贝叶斯估计推导出的二次代价函数，在集合空间中最小化代价函数可得到关于集合权重 $w$ 的正规方程组：\n$$(I + (H X)^T R^{-1} H X) w = (H X)^T R^{-1} d,$$\n模式空间增量则通过 $\\delta x = X w$ 恢复。此处，$I$ 是维度为 $m$ 的单位矩阵。本问题中所有矩阵 $R$ 都是对称正定 (SPD) 的，这确保了 $R^{-1}$ 存在且该系统有唯一解。\n\n你的任务是实现一个完整、可运行的程序，该程序能够：\n- 构建 $Y = H X$，\n- 使用数值稳定的方法求解 SPD 线性系统 $(I + Y^T R^{-1} Y) w = Y^T R^{-1} d$ 中的 $w$，并避免显式计算 $R^{-1}$，\n- 将 $w$ 映射回模式空间以获得 $\\delta x = X w$，\n- 报告每个测试用例中 $w$ 的欧几里得范数和 $\\delta x$ 的欧几里得范数。\n\n你必须基于基本原理推导算法：线性高斯估计、最小二乘正规方程组以及 SPD 矩阵的性质，而不使用超出这些基础的快捷公式。你的实现必须是数值稳定的，并且不得计算任何显式矩阵逆。使用适用于 SPD 矩阵的直接求解器。\n\n本问题中没有物理单位；所有量都是无量纲的。不涉及角度和百分比。\n\n测试套件：\n使用以下三个测试用例，每个用例都由 $(H, X, R, d)$ 及其精确数值条目指定。\n\n- 测试用例 1 (理想情况，对角阵 $R$，简单的 $H$)：\n  - $n = 3$， $m = 2$， $p = 2$。\n  - $X = \\begin{bmatrix} 0.8  -0.2 \\\\ 0.1  0.4 \\\\ -0.3  0.5 \\end{bmatrix}$。\n  - $H = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\end{bmatrix}$。\n  - $R = \\mathrm{diag}([0.09, 0.04]) = \\begin{bmatrix} 0.09  0 \\\\ 0  0.04 \\end{bmatrix}$。\n  - $d = \\begin{bmatrix} 0.5 \\\\ -0.1 \\end{bmatrix}$。\n\n- 测试用例 2 (非对角相关 $R$，非平凡的 $H$，$X$ 中存在近似共线的列)：\n  - $n = 4$， $m = 3$， $p = 3$。\n  - $X = \\begin{bmatrix}\n    0.6  0.58  -0.12 \\\\\n    0.2  0.21  0.05 \\\\\n    -0.1  -0.098  0.02 \\\\\n    0.0  0.01  -0.03\n  \\end{bmatrix}$。\n  - $H = \\begin{bmatrix}\n    1  0  0  0 \\\\\n    0  1  1  0 \\\\\n    0.5  0  0  1\n  \\end{bmatrix}$。\n  - $R = \\begin{bmatrix}\n    0.04  0.01  0.0 \\\\\n    0.01  0.09  0.02 \\\\\n    0.0  0.02  0.16\n  \\end{bmatrix}$。\n  - $d = \\begin{bmatrix} -0.2 \\\\ 0.3 \\\\ 0.05 \\end{bmatrix}$。\n\n- 测试用例 3 (由于 $X$ 中存在共线列导致 $Y$ 秩亏，小 $R$ 带来的强观测)：\n  - $n = 2$，$m = 2$，$p = 2$。\n  - $X = \\begin{bmatrix} 1.0  2.0 \\\\ 2.0  4.0 \\end{bmatrix}$。\n  - $H = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$。\n  - $R = \\mathrm{diag}([0.01, 0.01]) = \\begin{bmatrix} 0.01  0 \\\\ 0  0.01 \\end{bmatrix}$。\n  - $d = \\begin{bmatrix} 0.3 \\\\ -0.6 \\end{bmatrix}$。\n\n输出规格：\n对于每个测试用例，计算欧几里得范数 $\\|w\\|_2$ 和 $\\|\\delta x\\|_2$。你的程序应生成单行输出，其中按顺序包含这六个浮点数值，形式为用方括号括起来的逗号分隔列表：\n$[\\|w_1\\|_2, \\|\\delta x_1\\|_2, \\|w_2\\|_2, \\|\\delta x_2\\|_2, \\|w_3\\|_2, \\|\\delta x_3\\|_2]$。\n将每个值表示为标准十进制数。不应打印任何其他文本。",
            "solution": "该问题要求在混合变分-集合数据同化框架中求解关于集合权重 $w$ 的正规方程组。我们还需要计算由此产生的模式空间增量 $\\delta x$。解决方案必须从基本原理推导，并以数值稳定的方式实现，特别是要避免任何矩阵的显式逆计算。\n\n该问题经验证，被认为是具有科学依据、适定、客观且内部一致的。所有必要的数据均已提供。该公式是在线性高斯假设下，变分数据同化系统中基于集合的更新步骤的标准表示。正规方程组中单位矩阵 $I$ 的存在提供了正则化，确保即使在投影后的集合异常 $HX$ 秩亏的情况下（如测试用例 3 中所强调），系统仍然可解。\n\n控制方程为：\n$$(I + (H X)^T R^{-1} H X) w = (H X)^T R^{-1} d$$\n$$\\delta x = X w$$\n\n让我们将投影集合异常矩阵定义为 $Y = H X$。这些矩阵的维度分别为 $H \\in \\mathbb{R}^{p \\times n}$，$X \\in \\mathbb{R}^{n \\times m}$，$Y \\in \\mathbb{R}^{p \\times m}$，$R \\in \\mathbb{R}^{p \\times p}$，$d \\in \\mathbb{R}^{p}$，以及 $w \\in \\mathbb{R}^{m}$。单位矩阵 $I$ 的维度为 $m \\times m$。正规方程组可以更紧凑地重写为：\n$$(I + Y^T R^{-1} Y) w = Y^T R^{-1} d$$\n\n一种直接但数值不稳定的方法是显式计算 $R^{-1}$，然后构建系统。本问题正确地禁止了这种做法。一种在数值上更优越的策略是利用观测误差协方差矩阵 $R$ 的性质，该矩阵被指定为对称正定 (SPD)。对于 SPD 矩阵，我们可以使用其 Cholesky 分解来求解涉及其逆的线性系统。\n\n令 $R = L L^T$ 为 $R$ 的 Cholesky 分解，其中 $L$ 是一个下三角矩阵。那么逆矩阵 $R^{-1}$ 就是 $ (L L^T)^{-1} = (L^T)^{-1} L^{-1}$。为了计算像 $R^{-1} M$ 这样的乘积（其中 $M$ 是某个矩阵），不应计算逆因子，而应求解系统 $R Z = M$。这分两步完成：\n1.  使用前向代入法求解 $L V = M$ 得到 $V$。\n2.  使用后向代入法求解 $L^T Z = V$ 得到 $Z$。\n\n这个过程使我们能够在不形成任何逆矩阵的情况下计算出 $R^{-1}Y$ 和 $R^{-1}d$。让我们定义两个中间量：\n1.  $Z = R^{-1} Y$\n2.  $v = R^{-1} d$\n\n这些量可以通过分别求解线性系统 $RZ = Y$ 和 $Rv = d$ 来高效计算，计算中使用了 $R$ 的 Cholesky 分解。为了提高实现效率，可以构建一个增广矩阵 $[Y | d]$ 并求解一个单一系统。\n\n一旦 $Z$ 和 $v$ 已知，正规方程组就变为：\n$$(I + Y^T Z) w = Y^T v$$\n\n让我们定义系统矩阵 $A = I + Y^T Z$ 和右端向量 $b = Y^T v$。待求解的系统是 $A w = b$。我们必须分析矩阵 $A$ 的性质。\n矩阵 $A$ 是 SPD 的。单位矩阵 $I$ 是 SPD 的。矩阵 $Y^T R^{-1} Y = Y^T Z$ 至少是半正定 (PSD) 的，因为对于任何向量 $u \\in \\mathbb{R}^m$，有 $u^T (Y^T R^{-1} Y) u = (Y u)^T R^{-1} (Y u)$。由于 $R^{-1}$ 是 SPD 的，因此 $(Y u)^T R^{-1} (Y u) \\geq 0$。一个 SPD 矩阵 ($I$) 和一个 PSD 矩阵 ($Y^T Z$) 的和总是 SPD 的。\n\n由于 $A$ 是一个 SPD 矩阵，系统 $A w = b$ 有唯一解，并且最好再次使用 Cholesky 分解来求解。设 $A = L_A L_A^T$。我们可以通过以下步骤找到 $w$：\n1.  使用前向代入法求解 $L_A u = b$ 得到 $u$。\n2.  使用后向代入法求解 $L_A^T w = u$ 得到 $w$。\n\n在获得集合权重 $w$ 的解之后，模式空间增量 $\\delta x$ 通过线性变换 $\\delta x = X w$ 恢复。\n\n最后，按要求为每个测试用例计算所得向量的欧几里得范数 $\\|w\\|_2$ 和 $\\|\\delta x\\|_2$。\n\n完整的算法如下：\n1.  对于每个测试用例，给定矩阵 $H, X, R$ 和向量 $d$：\n2.  计算 $Y = H X$。\n3.  计算 $R$ 的 Cholesky 分解 $R = L L^T$。\n4.  求解系统 $R S = [Y | d]$ 得到中间矩阵 $S$，其中 $[Y|d]$ 是 $Y$ 和 $d$ 的拼接。这通过使用 $L$ 进行前向和后向代入来完成。令 $Z$ 为 $S$ 的前 $m$ 列（对应于 $R^{-1}Y$），令 $v$ 为 $S$ 的最后一列（对应于 $R^{-1}d$）。\n5.  构建 SPD 系统矩阵 $A = I + Y^T Z$。\n6.  构建右端向量 $b = Y^T v$。\n7.  计算 $A$ 的 Cholesky 分解 $A = L_A L_A^T$。\n8.  使用 $L_A$ 通过前向和后向代入求解系统 $A w = b$ 得到 $w$。\n9.  计算模式空间增量 $\\delta x = X w$。\n10. 计算欧几里得范数 $\\|w\\|_2$ 和 $\\|\\delta x\\|_2$。\n11. 收集并报告结果。\n\n此过程遵守所有问题约束，并基于求解线性高斯估计问题的数值线性代数既定原则。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import cho_factor, cho_solve\n\ndef solve():\n    \"\"\"\n    Solves the ensemble-space data assimilation problem for three test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        (\n            np.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]), # H\n            np.array([[0.8, -0.2], [0.1, 0.4], [-0.3, 0.5]]), # X\n            np.array([[0.09, 0.0], [0.0, 0.04]]), # R\n            np.array([0.5, -0.1]) # d\n        ),\n        # Test Case 2\n        (\n            np.array([[1.0, 0.0, 0.0, 0.0], \n                      [0.0, 1.0, 1.0, 0.0], \n                      [0.5, 0.0, 0.0, 1.0]]), # H\n            np.array([[0.6, 0.58, -0.12],\n                      [0.2, 0.21, 0.05],\n                      [-0.1, -0.098, 0.02],\n                      [0.0, 0.01, -0.03]]), # X\n            np.array([[0.04, 0.01, 0.0], \n                      [0.01, 0.09, 0.02], \n                      [0.0, 0.02, 0.16]]), # R\n            np.array([-0.2, 0.3, 0.05]) # d\n        ),\n        # Test Case 3\n        (\n            np.array([[1.0, 0.0], [0.0, 1.0]]), # H\n            np.array([[1.0, 2.0], [2.0, 4.0]]), # X\n            np.array([[0.01, 0.0], [0.0, 0.01]]), # R\n            np.array([0.3, -0.6]) # d\n        )\n    ]\n\n    results = []\n    \n    for H, X, R, d in test_cases:\n        # Get dimensions\n        # n = X.shape[0]  # model space dim\n        m = X.shape[1]  # ensemble size\n        # p = H.shape[0] # observation space dim\n\n        # Step 1: Form Y = H X\n        Y = H @ X\n\n        # Step 2: Solve systems involving R^{-1} without explicit inversion.\n        # We need to compute Z = R^{-1}Y and v = R^{-1}d.\n        # This can be done by solving RZ=Y and Rv=d.\n        # For efficiency, we form an augmented matrix M and solve RS = M.\n        \n        # d must be a column vector for hstack\n        d_col = d.reshape(-1, 1)\n        M = np.hstack((Y, d_col))\n        \n        # Since R is SPD, use Cholesky factorization to solve RS=M.\n        # L, lower = cho_factor(R, lower=True) computes L such that R = L L^T.\n        # cho_solve((L, lower), M) solves the system efficiently.\n        try:\n            cho_R, lower_R = cho_factor(R, lower=True)\n            S = cho_solve((cho_R, lower_R), M)\n        except np.linalg.LinAlgError:\n            # This should not happen since R is specified as SPD.\n            # Handle potential numerical issues if R is only PSD.\n            # Use pseudo-inverse for a more general solver (not needed here)\n            S = np.linalg.pinv(R) @ M\n\n        # Extract Z and v from the solution S\n        Z = S[:, :m] # Z = R^{-1}Y\n        v = S[:, m]  # v = R^{-1}d\n\n        # Step 3: Form the linear system for w: (I + Y^T R^{-1} Y) w = Y^T R^{-1} d\n        # This is A w = b, where A = I + Y^T Z and b = Y^T v.\n        A = np.eye(m) + Y.T @ Z\n        b = Y.T @ v\n\n        # Step 4: Solve for w.\n        # The matrix A is guaranteed to be SPD, so we use Cholesky decomposition again.\n        try:\n            cho_A, lower_A = cho_factor(A, lower=True)\n            w = cho_solve((cho_A, lower_A), b)\n        except np.linalg.LinAlgError:\n            # Handle cases where A might be numerically ill-conditioned.\n            w = np.linalg.solve(A, b)\n\n        # Step 5: Map w back to model space to get the increment dx.\n        delta_x = X @ w\n\n        # Step 6: Compute the Euclidean norms.\n        norm_w = np.linalg.norm(w)\n        norm_delta_x = np.linalg.norm(delta_x)\n\n        results.extend([norm_w, norm_delta_x])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}