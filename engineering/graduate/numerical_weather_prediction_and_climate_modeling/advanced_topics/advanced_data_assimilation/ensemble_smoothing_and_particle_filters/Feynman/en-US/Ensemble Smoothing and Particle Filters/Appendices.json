{
    "hands_on_practices": [
        {
            "introduction": "At the heart of many advanced smoothing techniques lies the principle of variational data assimilation, which reframes the inference problem as an optimization problem. This exercise walks you through the derivation of the objective function that forms the basis of methods like 4D-Var. By starting from Bayes' rule and applying Gaussian assumptions for model and observation errors, you will see how finding the most probable state trajectory is equivalent to minimizing a quadratic cost function representing the misfit to the model dynamics and observations . Calculating the gradient of this function is the crucial first step toward developing numerical algorithms that can solve for the optimal atmospheric state history.",
            "id": "4037876",
            "problem": "Consider a discrete-time state-space model used in numerical weather prediction and climate modeling over an assimilation window indexed by times $t = 0, 1, \\dots, T$. The true state of the atmosphere is represented by the sequence $x_{0:T}$ with $x_t \\in \\mathbb{R}^{n}$, and the observed data are $y_{0:T}$ with $y_t \\in \\mathbb{R}^{m_t}$. Assume the following:\n- The forecast model propagates the state as $x_t = M_t x_{t-1} + \\eta_t$, where $M_t \\in \\mathbb{R}^{n \\times n}$ is a known linearized model operator and $\\eta_t \\sim \\mathcal{N}(0, Q_t)$ with $Q_t \\in \\mathbb{R}^{n \\times n}$ symmetric positive definite, independently across time.\n- The observation model is $y_t = h_t(x_t) + \\epsilon_t$, where $h_t: \\mathbb{R}^{n} \\to \\mathbb{R}^{m_t}$ is a differentiable (possibly nonlinear) observation operator, and $\\epsilon_t \\sim \\mathcal{N}(0, R_t)$ with $R_t \\in \\mathbb{R}^{m_t \\times m_t}$ symmetric positive definite, independently across time and independent of $\\eta_{1:T}$.\n- The prior over $x_0$ is taken to be uninformative (flat), so it contributes no penalty to the objective.\n- Define the weighted norm $\\|v\\|_{A^{-1}}^{2}$ for $v \\in \\mathbb{R}^{k}$ and symmetric positive definite $A \\in \\mathbb{R}^{k \\times k}$ by $\\|v\\|_{A^{-1}}^{2} = v^{\\top} A^{-1} v$.\n\nStarting from Bayes’ rule and the Gaussian assumptions above, derive the negative log-posterior objective for the path $x_{0:T}$ up to an additive constant. Then, compute the gradient of this objective with respect to a single state $x_t$ for an arbitrary index $t \\in \\{0, 1, \\dots, T\\}$. Express your final gradient as a single closed-form analytic expression that is valid for all $t$, using indicator functions to handle boundary cases $t=0$ and $t=T$. Let $H_t(x_t) \\in \\mathbb{R}^{m_t \\times n}$ denote the Jacobian of $h_t$ at $x_t$, and write $H_t$ as shorthand for $H_t(x_t)$. Your final answer must be a single closed-form analytic expression. Do not include any units.",
            "solution": "The problem is to derive the negative log-posterior objective function for a state trajectory $x_{0:T}$ and then compute its gradient with respect to the state $x_t$ at an arbitrary time $t$. The problem is well-posed and scientifically grounded within the framework of variational data assimilation.\n\nFirst, we derive the objective function. The posterior probability of the state trajectory $x_{0:T} = (x_0, x_1, \\dots, x_T)$ given the observations $y_{0:T} = (y_0, y_1, \\dots, y_T)$ is given by Bayes' rule:\n$$\np(x_{0:T} | y_{0:T}) \\propto p(y_{0:T} | x_{0:T}) p(x_{0:T})\n$$\nThe term $p(x_{0:T})$ is the prior probability of the state trajectory, and $p(y_{0:T} | x_{0:T})$ is the likelihood of the observations given the trajectory.\n\nThe prior $p(x_{0:T})$ can be decomposed using the chain rule of probability and the Markov property of the dynamic model:\n$$\np(x_{0:T}) = p(x_0) \\prod_{t=1}^{T} p(x_t | x_{t-1})\n$$\nThe problem states that the prior over $x_0$ is uninformative, which means $p(x_0)$ is a constant. The state propagation model is $x_t = M_t x_{t-1} + \\eta_t$, with model error $\\eta_t \\sim \\mathcal{N}(0, Q_t)$. This implies that the conditional distribution $p(x_t | x_{t-1})$ is a multivariate normal distribution with mean $M_t x_{t-1}$ and covariance $Q_t$. The probability density function is:\n$$\np(x_t | x_{t-1}) \\propto \\exp\\left( -\\frac{1}{2} (x_t - M_t x_{t-1})^{\\top} Q_t^{-1} (x_t - M_t x_{t-1}) \\right) = \\exp\\left( -\\frac{1}{2} \\|x_t - M_t x_{t-1}\\|_{Q_t^{-1}}^2 \\right)\n$$\nThus, the full prior is:\n$$\np(x_{0:T}) \\propto \\prod_{t=1}^{T} \\exp\\left( -\\frac{1}{2} \\|x_t - M_t x_{t-1}\\|_{Q_t^{-1}}^2 \\right) = \\exp\\left( -\\frac{1}{2} \\sum_{t=1}^{T} \\|x_t - M_t x_{t-1}\\|_{Q_t^{-1}}^2 \\right)\n$$\n\nThe likelihood term $p(y_{0:T} | x_{0:T})$ considers the observation model $y_t = h_t(x_t) + \\epsilon_t$, with observation error $\\epsilon_t \\sim \\mathcal{N}(0, R_t)$. The observations at a given time $t$ depend only on the state at that time, $x_t$. The observation errors are independent across time. Therefore, the likelihood can be factored as:\n$$\np(y_{0:T} | x_{0:T}) = \\prod_{t=0}^{T} p(y_t | x_t)\n$$\nThe distribution of $y_t$ given $x_t$ is a multivariate normal distribution with mean $h_t(x_t)$ and covariance $R_t$. The probability density function is:\n$$\np(y_t | x_t) \\propto \\exp\\left( -\\frac{1}{2} (y_t - h_t(x_t))^{\\top} R_t^{-1} (y_t - h_t(x_t)) \\right) = \\exp\\left( -\\frac{1}{2} \\|y_t - h_t(x_t)\\|_{R_t^{-1}}^2 \\right)\n$$\nThe full likelihood is:\n$$\np(y_{0:T} | x_{0:T}) \\propto \\prod_{t=0}^{T} \\exp\\left( -\\frac{1}{2} \\|y_t - h_t(x_t)\\|_{R_t^{-1}}^2 \\right) = \\exp\\left( -\\frac{1}{2} \\sum_{t=0}^{T} \\|y_t - h_t(x_t)\\|_{R_t^{-1}}^2 \\right)\n$$\n\nCombining the prior and the likelihood, the posterior probability is proportional to:\n$$\np(x_{0:T} | y_{0:T}) \\propto \\exp\\left( -\\frac{1}{2} \\sum_{t=1}^{T} \\|x_t - M_t x_{t-1}\\|_{Q_t^{-1}}^2 - \\frac{1}{2} \\sum_{t=0}^{T} \\|y_t - h_t(x_t)\\|_{R_t^{-1}}^2 \\right)\n$$\nThe negative log-posterior objective function, denoted $J(x_{0:T})$, is obtained by taking the negative logarithm of the posterior, dropping additive constants. A factor of $\\frac{1}{2}$ is conventionally retained.\n$$\nJ(x_{0:T}) = \\frac{1}{2} \\sum_{t=1}^{T} \\|x_t - M_t x_{t-1}\\|_{Q_t^{-1}}^2 + \\frac{1}{2} \\sum_{t=0}^{T} \\|y_t - h_t(x_t)\\|_{R_t^{-1}}^2\n$$\nThis expression is the standard weak-constraint 4D-Var cost function.\n\nNext, we compute the gradient of $J(x_{0:T})$ with respect to the state $x_t$ at an arbitrary time $t \\in \\{0, 1, \\dots, T\\}$. The state vector $x_t$ appears in at most three terms of the objective function:\n1.  The observation term at time $t$: $\\frac{1}{2} \\|y_t - h_t(x_t)\\|_{R_t^{-1}}^2$.\n2.  The model dynamics term connecting $t-1$ and $t$: $\\frac{1}{2} \\|x_t - M_t x_{t-1}\\|_{Q_t^{-1}}^2$, which is present for $t \\ge 1$.\n3.  The model dynamics term connecting $t$ and $t+1$: $\\frac{1}{2} \\|x_{t+1} - M_{t+1} x_t\\|_{Q_{t+1}^{-1}}^2$, which is present for $t \\le T-1$.\n\nWe compute the gradient of each of these terms with respect to $x_t$ using standard rules of vector calculus. Let $H_t$ be the Jacobian of $h_t$ at $x_t$. The matrices $Q_t^{-1}$ and $R_t^{-1}$ are symmetric.\n\n1.  Gradient of the observation term:\n    $$\n    \\nabla_{x_t} \\left( \\frac{1}{2} (y_t - h_t(x_t))^{\\top} R_t^{-1} (y_t - h_t(x_t)) \\right) = -H_t^{\\top} R_t^{-1} (y_t - h_t(x_t))\n    $$\n    This term is present for all $t \\in \\{0, 1, \\dots, T\\}$.\n\n2.  Gradient of the model dynamics term for the interval $[t-1, t]$:\n    $$\n    \\nabla_{x_t} \\left( \\frac{1}{2} (x_t - M_t x_{t-1})^{\\top} Q_t^{-1} (x_t - M_t x_{t-1}) \\right) = Q_t^{-1} (x_t - M_t x_{t-1})\n    $$\n    This term is present for $t \\in \\{1, \\dots, T\\}$.\n\n3.  Gradient of the model dynamics term for the interval $[t, t+1]$:\n    $$\n    \\nabla_{x_t} \\left( \\frac{1}{2} (x_{t+1} - M_{t+1} x_t)^{\\top} Q_{t+1}^{-1} (x_{t+1} - M_{t+1} x_t) \\right) = -M_{t+1}^{\\top} Q_{t+1}^{-1} (x_{t+1} - M_{t+1} x_t)\n    $$\n    This term is present for $t \\in \\{0, \\dots, T-1\\}$.\n\nTo form a single expression for the gradient $\\nabla_{x_t} J(x_{0:T})$ that is valid for all $t \\in \\{0, 1, \\dots, T\\}$, we combine these components using indicator functions. Let $\\mathbb{I}_{condition}$ be an indicator function that equals $1$ if the condition is true and $0$ otherwise.\n\nThe total gradient is the sum of the gradients from the relevant terms:\n$$\n\\nabla_{x_t} J(x_{0:T}) = -H_t^{\\top} R_t^{-1} (y_t - h_t(x_t)) + \\mathbb{I}_{t \\ge 1} Q_t^{-1} (x_t - M_t x_{t-1}) - \\mathbb{I}_{t \\le T-1} M_{t+1}^{\\top} Q_{t+1}^{-1} (x_{t+1} - M_{t+1} x_t)\n$$\nThis expression holds for all $t \\in \\{0, 1, \\dots, T\\}$.\n- For an interior time $1 \\le t \\le T-1$, both indicators are $1$.\n- For the initial time $t=0$, $\\mathbb{I}_{t \\ge 1}=0$ and $\\mathbb{I}_{t \\le T-1}=1$ (assuming $T \\ge 1$), yielding $\\nabla_{x_0} J = -H_0^{\\top} R_0^{-1} (y_0 - h_0(x_0)) - M_1^{\\top} Q_1^{-1} (x_1 - M_1 x_0)$.\n- For the final time $t=T$, $\\mathbb{I}_{t \\ge 1}=1$ (assuming $T \\ge 1$) and $\\mathbb{I}_{t \\le T-1}=0$, yielding $\\nabla_{x_T} J = -H_T^{\\top} R_T^{-1} (y_T - h_T(x_T)) + Q_T^{-1} (x_T - M_T x_{T-1})$.\nThese special cases are correctly handled by the general formula.",
            "answer": "$$\n\\boxed{-H_t^{\\top} R_t^{-1} (y_t - h_t(x_t)) + \\mathbb{I}_{t \\ge 1} Q_t^{-1} (x_t - M_t x_{t-1}) - \\mathbb{I}_{t \\le T-1} M_{t+1}^{\\top} Q_{t+1}^{-1} (x_{t+1} - M_{t+1} x_t)}\n$$"
        },
        {
            "introduction": "While variational methods seek an optimal trajectory by minimizing a cost function, ensemble methods approximate the posterior probability distribution using a finite collection of state vectors. A key challenge is to update the forecast ensemble to an analysis ensemble whose statistics appropriately reflect the new information from observations. This practice explores the mechanics of deterministic \"square-root\" ensemble Kalman filters, which elegantly achieve this goal without the need to perturb observations—a source of sampling error in stochastic formulations . By constructing the transformation matrix that updates the ensemble anomalies, you will gain a concrete understanding of how these advanced filters maintain consistency with Kalman filter theory in a computationally efficient manner.",
            "id": "4037861",
            "problem": "In a single linear-Gaussian data assimilation step representative of numerical weather prediction and climate modeling, consider a state vector of dimension $n$ with a forecast ensemble of size $m>1$. Let the matrix of forecast ensemble anomalies be $A^{f} \\in \\mathbb{R}^{n \\times m}$ whose columns sum to zero, and let the forecast error covariance be $P^{f} = \\frac{1}{m-1} A^{f} (A^{f})^{\\mathsf{T}}$. Observations follow the linear model $y = H x + \\varepsilon$ with observation operator $H \\in \\mathbb{R}^{p \\times n}$ and observational error $\\varepsilon \\sim \\mathcal{N}(0,R)$ with a symmetric positive definite covariance matrix $R \\in \\mathbb{R}^{p \\times p}$. The Kalman filter analysis covariance for this linear-Gaussian system is $P^{a} = P^{f} - P^{f} H^{\\mathsf{T}} \\left(H P^{f} H^{\\mathsf{T}} + R\\right)^{-1} H P^{f}$.\n\nCompare the stochastic Ensemble Kalman Filter (EnKF), which perturbs observations, with a deterministic square-root EnKF that avoids perturbing observations. Then, using only the definitions above and fundamental properties of the Kalman filter for linear-Gaussian systems, construct a deterministic ensemble-space transformation matrix $T \\in \\mathbb{R}^{m \\times m}$ such that the analysis anomalies $A^{a} = A^{f} T$ satisfy $\\frac{1}{m-1} A^{a} (A^{a})^{\\mathsf{T}} = P^{a}$ without perturbing observations. Your construction must be given explicitly in closed form in terms of $H$, $R$, $A^{f}$, and $m$.\n\nDefine the ensemble-projected observation anomalies as $Y^{f} = H A^{f} \\in \\mathbb{R}^{p \\times m}$ and express your final answer for $T$ solely in terms of $Y^{f}$, $R$, and $m$. The final answer must be a single closed-form analytic expression for $T$. No numerical evaluation is required. If needed, you may use the symmetric positive-definite matrix square root notation. Express the final answer as a single analytic matrix expression. No units are required.",
            "solution": "The problem is first critically validated before a solution is attempted.\n\n### Step 1: Extract Givens\n- State vector dimension: $n$\n- Ensemble size: $m > 1$\n- Matrix of forecast ensemble anomalies: $A^{f} \\in \\mathbb{R}^{n \\times m}$, with columns summing to zero.\n- Forecast error covariance: $P^{f} = \\frac{1}{m-1} A^{f} (A^{f})^{\\mathsf{T}}$\n- Observation model: $y = H x + \\varepsilon$\n- Observation operator: $H \\in \\mathbb{R}^{p \\times n}$\n- Observational error: $\\varepsilon \\sim \\mathcal{N}(0,R)$\n- Observational error covariance matrix: $R \\in \\mathbb{R}^{p \\times p}$, symmetric positive definite.\n- Kalman filter analysis covariance: $P^{a} = P^{f} - P^{f} H^{\\mathsf{T}} \\left(H P^{f} H^{\\mathsf{T}} + R\\right)^{-1} H P^{f}$\n- Analysis ensemble anomalies: $A^{a} = A^{f} T$, where $T \\in \\mathbb{R}^{m \\times m}$ is the transformation matrix to be found.\n- The condition to be satisfied: $\\frac{1}{m-1} A^{a} (A^{a})^{\\mathsf{T}} = P^{a}$\n- Definition of ensemble-projected observation anomalies: $Y^{f} = H A^{f} \\in \\mathbb{R}^{p \\times m}$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, as it describes a core derivation within the theory of ensemble data assimilation, specifically for deterministic square-root Ensemble Kalman Filters (EnKFs). The provided equations for the forecast and analysis covariances are standard in linear-Gaussian estimation theory. The problem is well-posed, objective, and self-contained, providing all necessary definitions to construct the matrix $T$. There are no contradictions, ambiguities, or factual errors. The problem is a formalizable and relevant exercise in matrix algebra applied to numerical weather prediction and climate modeling.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be constructed.\n\n### Solution Derivation\nThe objective is to find a deterministic transformation matrix $T \\in \\mathbb{R}^{m \\times m}$ such that the analysis ensemble anomalies, defined as $A^{a} = A^{f} T$, have a sample covariance that matches the theoretical analysis error covariance from the Kalman filter, $P^{a}$.\n\nThe sample covariance of the analysis ensemble is given by:\n$$\n\\frac{1}{m-1} A^{a} (A^{a})^{\\mathsf{T}} = \\frac{1}{m-1} (A^{f} T) (A^{f} T)^{\\mathsf{T}} = \\frac{1}{m-1} A^{f} T T^{\\mathsf{T}} (A^{f})^{\\mathsf{T}}\n$$\nWe must equate this to the Kalman analysis covariance, $P^{a}$:\n$$\n\\frac{1}{m-1} A^{f} T T^{\\mathsf{T}} (A^{f})^{\\mathsf{T}} = P^{a}\n$$\nSubstituting the given expression for $P^{a}$:\n$$\n\\frac{1}{m-1} A^{f} T T^{\\mathsf{T}} (A^{f})^{\\mathsf{T}} = P^{f} - P^{f} H^{\\mathsf{T}} \\left(H P^{f} H^{\\mathsf{T}} + R\\right)^{-1} H P^{f}\n$$\nNow, substitute the definition of the forecast error covariance, $P^{f} = \\frac{1}{m-1} A^{f} (A^{f})^{\\mathsf{T}}$, into this equation.\n$$\n\\frac{1}{m-1} A^{f} T T^{\\mathsf{T}} (A^{f})^{\\mathsf{T}} = \\frac{1}{m-1} A^{f} (A^{f})^{\\mathsf{T}} - \\left(\\frac{1}{m-1} A^{f} (A^{f})^{\\mathsf{T}}\\right) H^{\\mathsf{T}} \\left(H \\left(\\frac{1}{m-1} A^{f} (A^{f})^{\\mathsf{T}}\\right) H^{\\mathsf{T}} + R\\right)^{-1} H \\left(\\frac{1}{m-1} A^{f} (A^{f})^{\\mathsf{T}}\\right)\n$$\nWe can use the definition $Y^{f} = H A^{f}$. This implies that $H P^{f} H^{\\mathsf{T}} = \\frac{1}{m-1} H A^{f} (A^{f})^{\\mathsf{T}} H^{\\mathsf{T}} = \\frac{1}{m-1} (H A^{f}) (H A^{f})^{\\mathsf{T}} = \\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}}$. Also, $P^{f} H^{\\mathsf{T}} = \\frac{1}{m-1} A^{f} (A^{f})^{\\mathsf{T}} H^{\\mathsf{T}} = \\frac{1}{m-1} A^{f} (H A^{f})^{\\mathsf{T}} = \\frac{1}{m-1} A^{f} (Y^{f})^{\\mathsf{T}}$.\n\nSubstituting these into the equation for $P^{a}$:\n$$\n\\frac{1}{m-1} A^{f} T T^{\\mathsf{T}} (A^{f})^{\\mathsf{T}} = \\frac{1}{m-1} A^{f} (A^{f})^{\\mathsf{T}} - \\left(\\frac{1}{m-1} A^{f} (Y^{f})^{\\mathsf{T}}\\right) \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right)^{-1} \\left(\\frac{1}{m-1} (Y^{f}) (A^{f})^{\\mathsf{T}}\\right)\n$$\nFactoring out $A^{f}$ on the left and $(A^{f})^{\\mathsf{T}}$ on the right of the right-hand side gives:\n$$\n\\frac{1}{m-1} A^{f} T T^{\\mathsf{T}} (A^{f})^{\\mathsf{T}} = \\frac{1}{m-1} A^{f} \\left( I_m - \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right)^{-1} Y^{f} \\right) (A^{f})^{\\mathsf{T}}\n$$\nwhere $I_m$ is the $m \\times m$ identity matrix. By comparing the terms between $A^{f}$ and $(A^{f})^{\\mathsf{T}}$ on both sides, we identify an expression for $T T^{\\mathsf{T}}$:\n$$\nT T^{\\mathsf{T}} = I_m - \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right)^{-1} Y^{f}\n$$\nThis expression can be simplified using the Woodbury matrix identity, which states that $(A+UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1}+VA^{-1}U)^{-1}VA^{-1}$. A more convenient form for this problem is to show that the inverse of a related matrix has a simpler form. Let's propose that the inverse of $T T^{\\mathsf{T}}$ is $I_m + \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} R^{-1} Y^{f}$. We verify this by multiplication:\n$$\n\\left( I_m - \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right)^{-1} Y^{f} \\right) \\left( I_m + \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} R^{-1} Y^{f} \\right)\n$$\nLet's expand this product:\n$$\n= I_m + \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} R^{-1} Y^{f} - \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right)^{-1} Y^{f} - \\frac{1}{(m-1)^2} (Y^{f})^{\\mathsf{T}} \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right)^{-1} Y^{f} (Y^{f})^{\\mathsf{T}} R^{-1} Y^{f}\n$$\nFactor out $(Y^{f})^{\\mathsf{T}}$ and $Y^{f}$:\n$$\n= I_m + \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} \\left[ R^{-1} - \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right)^{-1} - \\frac{1}{m-1} \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right)^{-1} Y^{f} (Y^{f})^{\\mathsf{T}} R^{-1} \\right] Y^{f}\n$$\nFocus on the term in the square brackets. Factor out the common inverse matrix:\n$$\n= R^{-1} - \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right)^{-1} \\left( I_p + \\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} R^{-1} \\right)\n$$\nwhere $I_p$ is the $p \\times p$ identity matrix. We can rewrite the last parenthesis as:\n$$\nI_p + \\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} R^{-1} = \\left(R + \\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}}\\right) R^{-1}\n$$\nSubstituting this back into the bracketed expression:\n$$\nR^{-1} - \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right)^{-1} \\left(\\frac{1}{m-1} Y^{f} (Y^{f})^{\\mathsf{T}} + R\\right) R^{-1} = R^{-1} - I_p R^{-1} = R^{-1} - R^{-1} = 0\n$$\nSince the term in square brackets is zero, the entire product simplifies to $I_m$. This proves that:\n$$\n(T T^{\\mathsf{T}})^{-1} = I_m + \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} R^{-1} Y^{f}\n$$\nTherefore:\n$$\nT T^{\\mathsf{T}} = \\left( I_m + \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} R^{-1} Y^{f} \\right)^{-1}\n$$\nThe problem asks for the construction of a deterministic matrix $T$. A common and stable choice for such a matrix in square-root filters is the symmetric positive-definite square root of $T T^{\\mathsf{T}}$. Let's define the matrix $S = I_m + \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} R^{-1} Y^{f}$. Since $R$ is symmetric positive definite, $R^{-1}$ is as well, and thus $(Y^{f})^{\\mathsf{T}} R^{-1} Y^{f}$ is symmetric positive semi-definite. Therefore, $S$ is a symmetric positive-definite matrix. As such, it admits a unique symmetric positive-definite square root, denoted $S^{1/2}$.\n\nWe choose $T$ to be the symmetric matrix $T = (S^{-1})^{1/2} = S^{-1/2}$. This choice gives $T T^{\\mathsf{T}} = T^2 = S^{-1}$, satisfying the condition. The problem statement explicitly permits the use of symmetric positive-definite matrix square root notation.\n\nThe final expression for $T$ is therefore the inverse symmetric square root of the matrix $S$.\n\n$$\nT = \\left( I_m + \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} R^{-1} Y^{f} \\right)^{-1/2}\n$$\nThis expression is in closed form and depends only on $Y^{f}$, $R$, and $m$, as required.",
            "answer": "$$\\boxed{\\left( I_m + \\frac{1}{m-1} (Y^{f})^{\\mathsf{T}} R^{-1} Y^{f} \\right)^{-1/2}}$$"
        },
        {
            "introduction": "A critical parameter in any smoothing application is the length of the assimilation window, which determines how far back in time observations are used to correct the state. In chaotic systems like the atmosphere, the influence of past observations decays over time due to the exponential growth of small errors. This exercise connects the practical choice of window length to the fundamental properties of the system, specifically its leading Lyapunov exponent which quantifies the rate of chaos . By deriving a criterion for the optimal window length, you will learn to balance computational cost with the actual information content available, ensuring your smoother is both efficient and effective.",
            "id": "4037882",
            "problem": "Consider a discrete-time chaotic dynamical system used in numerical weather prediction and climate modeling. Let the system be linearized along a trajectory so that perturbations evolve according to a tangent propagator with a leading Lyapunov exponent $\\lambda_{1} > 0$. This implies that a small perturbation $\\delta \\mathbf{x}_{k}$ at time index $k$ grows on average as $\\|\\delta \\mathbf{x}_{k+\\tau}\\| \\approx \\mathrm{e}^{\\lambda_{1} \\tau} \\|\\delta \\mathbf{x}_{k}\\|$ for lag $\\tau \\in \\mathbb{N}$. Assume that scalar observations aligned with the leading unstable subspace are available at every integer time step with independent Gaussian noise of variance $R > 0$, and that process noise is sufficiently small that, over the window considered, the linearization is valid. Consider a fixed-interval ensemble smoother or a particle smoother applied over an assimilation window of integer length $T \\in \\mathbb{N}$ time steps.\n\nStart from the fundamental base that in linear-Gaussian settings, fixed-interval smoothing can be expressed in information form, where the total information (inverse variance) accumulated about the initial state along a given mode is the sum of the contributions from future observations, each contribution being proportional to the squared backward sensitivity of that observation to the initial state and inversely proportional to the observation noise variance. Using the definition of the leading Lyapunov exponent $\\lambda_{1}$ and the fact that backward sensitivities along the leading unstable subspace decay geometrically with lag due to time-reversal of the unstable growth, derive the dependence of the total information captured by a window of length $T$ on $\\lambda_{1}$, and show that the missing information from lags beyond $T$ decays exponentially with $T$.\n\nDefine a rigorous criterion for choosing $T$ based on a tolerance parameter $\\varepsilon \\in (0,1)$ such that the fraction of asymptotic information not captured by the window is at most $\\varepsilon$. Derive an explicit expression for the minimal integer $T^{\\star}$ satisfying this criterion in terms of $\\lambda_{1}$ and $\\varepsilon$. Then, for each test case specified below, compute:\n- The recommended window length $T^{\\star}$ in discrete time steps (dimensionless).\n- The fraction of asymptotic smoothing information actually captured by this window, denoted $F(T^{\\star}) \\in (0,1)$, rounded to at least six decimal places.\n\nAssume all time is measured in discrete model time steps and report $T^{\\star}$ as a nonnegative integer and $F(T^{\\star})$ as a floating-point number in $[0,1)$.\n\nTest suite (each case is a tuple $(\\lambda_{1}, \\varepsilon, T_{\\max})$ where $T_{\\max}$ is an upper bound on allowable window length; if the derived $T^{\\star}$ exceeds $T_{\\max}$, use $T^{\\star} = T_{\\max}$ and still report the corresponding $F(T^{\\star})$):\n- Case $1$: $(\\lambda_{1}, \\varepsilon, T_{\\max}) = (0.5, 0.01, 100)$.\n- Case $2$: $(\\lambda_{1}, \\varepsilon, T_{\\max}) = (0.1, 0.001, 250)$.\n- Case $3$: $(\\lambda_{1}, \\varepsilon, T_{\\max}) = (1.0, 0.1, 20)$.\n- Case $4$: $(\\lambda_{1}, \\varepsilon, T_{\\max}) = (0.02, 0.001, 300)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n$[T^{\\star}_{1}, F(T^{\\star}_{1}), T^{\\star}_{2}, F(T^{\\star}_{2}), T^{\\star}_{3}, F(T^{\\star}_{3}), T^{\\star}_{4}, F(T^{\\star}_{4})]$,\nwhere the subscript denotes the case index from $1$ to $4$.\n\nThe problem is entirely mathematical and requires no physical units beyond the discrete time step specification above. Angles are not involved. All outputs must be as specified types: integers for $T^{\\star}$ and floating-point numbers for $F(T^{\\star})$.",
            "solution": "The problem requires the derivation of an optimal assimilation window length $T^{\\star}$ for a fixed-interval smoother based on the system's leading Lyapunov exponent $\\lambda_{1}$ and a specified information tolerance $\\varepsilon$.\n\nThe foundation of this analysis rests on the information-theoretic view of Kalman smoothing in a linear-Gaussian context. The total information gained about the initial state of the system is the sum of information contributions from each observation within the assimilation window. We are concerned with the component of the state aligned with the most unstable direction, which grows according to the leading Lyapunov exponent $\\lambda_{1} > 0$.\n\nLet the system be observed at discrete time steps $k=1, 2, 3, \\dots$. The problem states that the information contribution from an observation is proportional to the squared backward sensitivity. The term \"backward sensitivity\" in this context refers to the influence that an observation at a future time $k$ has on the estimate of the state at the initial time, say $t=0$. In a chaotic system, the forward dynamics are unstable, characterized by a positive Lyapunov exponent $\\lambda_1$. A small perturbation $\\delta \\mathbf{x}_0$ at time $0$ grows as $\\|\\delta\\mathbf{x}_k\\| \\approx e^{\\lambda_1 k} \\|\\delta\\mathbf{x}_0\\|$.\n\nConversely, the influence of an observation at time $k$ on the state estimate at time $0$ must decay as $k$ increases. This is because, when viewed backward in time, the stable dynamics correspond to the unstable forward dynamics. The influence of the innovation (observation minus forecast) at time $k$ on the smoothed estimate at time $0$ decays proportionally to $\\mathrm{e}^{-\\lambda_{1} k}$. This is a direct consequence of the duality between forward prediction error covariance evolution and backward smoothing gain propagation.\n\nThe information gained, which is equivalent to the reduction in variance, is proportional to the square of this influence. Therefore, the information contributed by an observation at lag $k$ (i.e., at time step $k$) about the state at time $0$ can be modeled as:\n$$ I_k = C \\cdot \\left(\\mathrm{e}^{-\\lambda_{1} k}\\right)^2 = C \\cdot \\mathrm{e}^{-2\\lambda_{1} k} $$\nwhere $C$ is a constant of proportionality that depends on the observation operator and the observation error variance $R$, but is independent of the lag $k$.\n\nThe total information captured by a smoothing window of length $T$ is the sum of contributions from observations at lags $k=1, 2, \\dots, T$:\n$$ I_{\\text{total}}(T) = \\sum_{k=1}^{T} I_k = C \\sum_{k=1}^{T} \\mathrm{e}^{-2\\lambda_{1} k} $$\n\nThe asymptotic information is the total information that could be gained from an infinitely long window ($T \\to \\infty$):\n$$ I_{\\text{asymptotic}} = \\sum_{k=1}^{\\infty} I_k = C \\sum_{k=1}^{\\infty} \\mathrm{e}^{-2\\lambda_{1} k} $$\nThis is a geometric series with first term $a = C \\mathrm{e}^{-2\\lambda_{1}}$ and common ratio $r = \\mathrm{e}^{-2\\lambda_{1}}$. Since $\\lambda_1 > 0$, we have $0 < r < 1$, and the series converges to:\n$$ I_{\\text{asymptotic}} = C \\frac{\\mathrm{e}^{-2\\lambda_{1}}}{1 - \\mathrm{e}^{-2\\lambda_{1}}} $$\n\nThe information *not* captured by the window of length $T$ (the \"missing information\") consists of the contributions from all observations beyond lag $T$:\n$$ I_{\\text{missing}}(T) = \\sum_{k=T+1}^{\\infty} I_k = C \\sum_{k=T+1}^{\\infty} (\\mathrm{e}^{-2\\lambda_{1}})^k $$\nThis is also a geometric series, with the first term being $C \\mathrm{e}^{-2\\lambda_{1}(T+1)}$. Its sum is:\n$$ I_{\\text{missing}}(T) = C \\frac{\\mathrm{e}^{-2\\lambda_{1}(T+1)}}{1 - \\mathrm{e}^{-2\\lambda_{1}}} $$\nAs can be seen, $I_{\\text{missing}}(T)$ is proportional to $\\mathrm{e}^{-2\\lambda_{1}T}$, demonstrating that the missing information decays exponentially with the window length $T$.\n\nThe problem defines a criterion based on the fraction of asymptotic information that is missed. This fraction is:\n$$ \\frac{I_{\\text{missing}}(T)}{I_{\\text{asymptotic}}} = \\frac{C \\frac{\\mathrm{e}^{-2\\lambda_{1}(T+1)}}{1 - \\mathrm{e}^{-2\\lambda_{1}}}}{C \\frac{\\mathrm{e}^{-2\\lambda_{1}}}{1 - \\mathrm{e}^{-2\\lambda_{1}}}} = \\frac{\\mathrm{e}^{-2\\lambda_{1}(T+1)}}{\\mathrm{e}^{-2\\lambda_{1}}} = \\mathrm{e}^{-2\\lambda_{1}T} $$\nThe criterion requires this fraction to be at most $\\varepsilon$, where $\\varepsilon \\in (0,1)$ is a given tolerance:\n$$ \\mathrm{e}^{-2\\lambda_{1}T} \\le \\varepsilon $$\nTo find the minimum window length $T$ that satisfies this, we solve the inequality for $T$. Taking the natural logarithm of both sides:\n$$ -2\\lambda_{1}T \\le \\ln(\\varepsilon) $$\nSince $\\lambda_1 > 0$, dividing by $-2\\lambda_1$ reverses the inequality:\n$$ T \\ge -\\frac{\\ln(\\varepsilon)}{2\\lambda_{1}} = \\frac{\\ln(1/\\varepsilon)}{2\\lambda_{1}} $$\nThe minimal integer window length $T$ satisfying this condition, which we denote $T^{\\star}_{\\text{derived}}$, is the ceiling of the right-hand side:\n$$ T^{\\star}_{\\text{derived}} = \\left\\lceil \\frac{\\ln(1/\\varepsilon)}{2\\lambda_{1}} \\right\\rceil $$\nThe problem further imposes an upper bound $T_{\\max}$ on the window length. Thus, the final recommended window length $T^{\\star}$ is:\n$$ T^{\\star} = \\min\\left(T^{\\star}_{\\text{derived}}, T_{\\max}\\right) $$\nThe fraction of asymptotic information actually captured by this window of length $T^{\\star}$, denoted $F(T^{\\star})$, is given by:\n$$ F(T^{\\star}) = 1 - \\frac{I_{\\text{missing}}(T^{\\star})}{I_{\\text{asymptotic}}} = 1 - \\mathrm{e}^{-2\\lambda_{1}T^{\\star}} $$\nWe now apply these derived formulae to the specified test cases.\n\nCase 1: $(\\lambda_{1}, \\varepsilon, T_{\\max}) = (0.5, 0.01, 100)$\n$T^{\\star}_{\\text{derived}} = \\lceil \\frac{\\ln(1/0.01)}{2 \\times 0.5} \\rceil = \\lceil \\ln(100) \\rceil = \\lceil 4.605...\\rceil = 5$.\n$T^{\\star} = \\min(5, 100) = 5$.\n$F(5) = 1 - \\mathrm{e}^{-2 \\times 0.5 \\times 5} = 1 - \\mathrm{e}^{-5} \\approx 0.993262$.\n\nCase 2: $(\\lambda_{1}, \\varepsilon, T_{\\max}) = (0.1, 0.001, 250)$\n$T^{\\star}_{\\text{derived}} = \\lceil \\frac{\\ln(1/0.001)}{2 \\times 0.1} \\rceil = \\lceil \\frac{\\ln(1000)}{0.2} \\rceil = \\lceil 34.538...\\rceil = 35$.\n$T^{\\star} = \\min(35, 250) = 35$.\n$F(35) = 1 - \\mathrm{e}^{-2 \\times 0.1 \\times 35} = 1 - \\mathrm{e}^{-7} \\approx 0.999088$.\n\nCase 3: $(\\lambda_{1}, \\varepsilon, T_{\\max}) = (1.0, 0.1, 20)$\n$T^{\\star}_{\\text{derived}} = \\lceil \\frac{\\ln(1/0.1)}{2 \\times 1.0} \\rceil = \\lceil \\frac{\\ln(10)}{2} \\rceil = \\lceil 1.151...\\rceil = 2$.\n$T^{\\star} = \\min(2, 20) = 2$.\n$F(2) = 1 - \\mathrm{e}^{-2 \\times 1.0 \\times 2} = 1 - \\mathrm{e}^{-4} \\approx 0.981684$.\n\nCase 4: $(\\lambda_{1}, \\varepsilon, T_{\\max}) = (0.02, 0.001, 300)$\n$T^{\\star}_{\\text{derived}} = \\lceil \\frac{\\ln(1/0.001)}{2 \\times 0.02} \\rceil = \\lceil \\frac{\\ln(1000)}{0.04} \\rceil = \\lceil 172.693...\\rceil = 173$.\n$T^{\\star} = \\min(173, 300) = 173$.\n$F(173) = 1 - \\mathrm{e}^{-2 \\times 0.02 \\times 173} = 1 - \\mathrm{e}^{-6.92} \\approx 0.999012$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the recommended smoother window length T_star and the \n    corresponding fraction of captured information F(T_star) for a set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (lambda_1, epsilon, T_max).\n    test_cases = [\n        (0.5, 0.01, 100),\n        (0.1, 0.001, 250),\n        (1.0, 0.1, 20),\n        (0.02, 0.001, 300),\n    ]\n\n    results = []\n    for case in test_cases:\n        lambda_1, epsilon, T_max = case\n\n        # The fraction of missing information for a window of length T is exp(-2 * lambda_1 * T).\n        # We want this to be = epsilon.\n        # exp(-2 * lambda_1 * T) = epsilon\n        # -2 * lambda_1 * T = log(epsilon)\n        # T >= -log(epsilon) / (2 * lambda_1)\n        # T >= log(1/epsilon) / (2 * lambda_1)\n        \n        # Calculate the theoretical minimum T to satisfy the criterion.\n        # Since T must be an integer number of time steps, we take the ceiling.\n        T_star_derived = np.ceil(np.log(1.0 / epsilon) / (2.0 * lambda_1))\n\n        # The final T_star is the minimum of the derived value and the specified maximum T_max.\n        # The result must be an integer.\n        T_star = int(min(T_star_derived, T_max))\n\n        # Calculate the fraction of information actually captured by this window length T_star.\n        # F(T) = 1 - (fraction of missing information)\n        F_T_star = 1.0 - np.exp(-2.0 * lambda_1 * T_star)\n        \n        results.append(T_star)\n        results.append(F_T_star)\n\n    # Format the results into a single comma-separated string as required.\n    # The default string conversion for floats provides sufficient precision.\n    output_string = \",\".join(map(str, results))\n    \n    # Final print statement in the exact required format.\n    print(f\"[{output_string}]\")\n\nsolve()\n```"
        }
    ]
}