{
    "hands_on_practices": [
        {
            "introduction": "The promise of dynamical downscaling lies in its ability to resolve fine-scale atmospheric features. However, a nested model is fundamentally constrained by the information it receives from its parent model at the lateral boundaries. This exercise  invites you to apply principles from information theory to quantify the inherent loss of detail at the interface between a coarse parent grid and a fine child grid, highlighting a key theoretical limitation of one-way nesting.",
            "id": "4032869",
            "problem": "Consider a one-way nested dynamical downscaling configuration within Numerical Weather Prediction (NWP). A parent model provides lateral boundary conditions to a finer child Regional Climate Model (RCM). Both models use rectilinear, horizontally uniform grids aligned such that child grid points lie within parent grid cells. The parent horizontal grid spacing is $\\Delta x_p = 12$ km and the child horizontal grid spacing is $\\Delta x_c = 4$ km. Assume the boundary update at the child model’s lateral boundary uses bilinear interpolation in space from parent model prognostic variables at the nearest four parent grid points (i.e., the four corners of the enclosing parent grid cell), and linear interpolation in time (neglect the temporal aspect for this question). Assume no prefiltering or smoothing is applied, and child boundary points do not lie exactly on parent cell edges or corners.\n\nStarting from the Nyquist–Shannon sampling theorem and the definition of one-way nesting (information flows from parent to child only), answer the following:\n\n1. Determine the number of distinct parent grid cells that contribute to the spatial interpolation for a single child boundary point update.\n\n2. Define the potential information loss along the boundary as the fraction of the independent spatial samples per unit length that the child grid can accept but are not supplied by the parent grid, in the limit of a long, straight boundary where endpoint effects are negligible. Express this fraction in exact form (as a decimal or a fraction), and do not use a percentage sign.\n\nProvide your final answer as a pair, with the first entry being the number of contributing parent grid cells and the second entry being the information loss fraction. No rounding is required.",
            "solution": "This problem consists of two parts concerning a one-way nested dynamical downscaling setup. The first part addresses the spatial interpolation scheme, and the second part quantifies the information loss at the boundary between the parent and child models.\n\nPart 1: Determine the number of distinct parent grid cells that contribute to the spatial interpolation for a single child boundary point update.\n\nThe problem states that the boundary update for the child model uses \"bilinear interpolation in space from parent model prognostic variables at the nearest four parent grid points (i.e., the four corners of the enclosing parent grid cell)\".\n\nBilinear interpolation is a method for interpolating functions of two variables (e.g., longitude and latitude) on a rectilinear grid. For any point $(x, y)$ located within a rectangular cell defined by four corner points $(x_1, y_1)$, $(x_2, y_1)$, $(x_1, y_2)$, and $(x_2, y_2)$, the interpolated value is a weighted average of the values at these four corners.\n\nThe problem specifies that the child boundary points do not lie exactly on parent cell edges or corners, ensuring that any given child boundary point is unambiguously *enclosed* by a single parent grid cell. The four parent grid points used for the interpolation are, by definition, the vertices of this single enclosing cell. Therefore, the data used for the interpolation for a single child point are drawn from the corners of exactly one parent grid cell.\n\nThe number of distinct parent grid cells contributing to the update of a single child boundary point is $1$.\n\nPart 2: Define and calculate the potential information loss along the boundary.\n\nThe potential information loss is defined as \"the fraction of the independent spatial samples per unit length that the child grid can accept but are not supplied by the parent grid\". This concept is rooted in the Nyquist-Shannon sampling theorem, which relates grid spacing to the maximum resolvable spatial frequency (or minimum wavelength).\n\nAccording to the sampling theorem, a grid with spacing $\\Delta x$ can resolve wavelengths down to a minimum of $\\lambda_{\\text{min}} = 2\\Delta x$. The number of independent spatial samples per unit length, which we denote as $S$, is inversely proportional to this minimum resolvable feature size or, more directly, to the grid spacing itself. Thus, we can write $S \\propto \\frac{1}{\\Delta x}$.\n\nThe child grid, with spacing $\\Delta x_c$, can accept or represent information content corresponding to a sampling density of:\n$$S_c \\propto \\frac{1}{\\Delta x_c}$$\n\nThe parent model, with a coarser grid spacing $\\Delta x_p$, provides the boundary conditions. The information it contains is limited by its own resolution. The information content supplied by the parent grid corresponds to a sampling density of:\n$$S_p \\propto \\frac{1}{\\Delta x_p}$$\n\nDue to the one-way nesting, where information flows only from parent to child, the child model's boundary cannot contain information at scales finer than what the parent model can resolve and supply. The interpolation process transfers the parent model's information but does not create new, higher-frequency information.\n\nThe number of samples per unit length that the child grid can accept but are not supplied by the parent is the difference $S_c - S_p$. The fractional information loss, $L$, is this difference normalized by the total capacity of the child grid, $S_c$:\n$$L = \\frac{S_c - S_p}{S_c} = 1 - \\frac{S_p}{S_c}$$\n\nSubstituting the proportional relationships for $S_c$ and $S_p$:\n$$L = 1 - \\frac{k/\\Delta x_p}{k/\\Delta x_c}$$\nwhere $k$ is the constant of proportionality. The constant $k$ cancels out, yielding:\n$$L = 1 - \\frac{\\Delta x_c}{\\Delta x_p}$$\n\nWe are given the grid spacings:\n- Parent grid spacing: $\\Delta x_p = 12$ km\n- Child grid spacing: $\\Delta x_c = 4$ km\n\nSubstituting these values into the expression for the loss fraction $L$:\n$$L = 1 - \\frac{4}{12} = 1 - \\frac{1}{3} = \\frac{2}{3}$$\n\nThis fraction represents the portion of the spatial scales that the child model is designed to resolve but for which no information is provided by the parent model at the boundary.\n\nThe final answer consists of the number of contributing cells from Part 1 and the information loss fraction from Part 2.\n- Number of contributing cells: $1$\n- Information loss fraction: $\\frac{2}{3}$",
            "answer": "$$\\boxed{\\begin{pmatrix} 1  \\frac{2}{3} \\end{pmatrix}}$$"
        },
        {
            "introduction": "A critical challenge in nested modeling is ensuring a smooth transition of atmospheric fields from the coarse parent model to the fine child model. Abrupt changes at the lateral boundaries can generate spurious numerical waves that corrupt the high-resolution simulation. This practice  explores the concept of a lateral buffer zone with Newtonian relaxation, a standard technique to damp these inconsistencies, allowing you to quantify the effectiveness of this 'nudging' process on an incoming disturbance.",
            "id": "4032871",
            "problem": "A one-way nested Limited-Area Model (LAM) of lateral width $600\\ \\mathrm{km}$ employs a lateral buffer zone of uniform width $W=60\\ \\mathrm{km}$, within which Newtonian relaxation (also called Davies-type relaxation) is applied uniformly in time with a constant relaxation timescale $\\tau=600\\ \\mathrm{s}$. Consider a synoptic-scale perturbation of passive scalar amplitude $a$ that enters the buffer from the outer boundary and is advected steadily inward with constant phase speed $U=15\\ \\mathrm{m}\\ \\mathrm{s}^{-1}$ normal to the boundary. Assume the perturbation evolves within the buffer by linear advection and linear Newtonian relaxation only, with no sources, sinks, or nonlinearity, and that $a$ is sufficiently small to justify linear superposition.\n\nStarting from first principles of linear advection and Newtonian relaxation along a Lagrangian trajectory, derive the expression for the attenuation factor $A$, defined as the ratio of the perturbation amplitude at the inner edge of the buffer to its amplitude at the outer boundary. Then evaluate $A$ for the given parameters. Express the final answer as a dimensionless number rounded to three significant figures.",
            "solution": "The problem concerns the amplitude evolution of a passively advected perturbation subject to Newtonian relaxation in a buffer zone. The foundational elements are:\n\n1. Linear advection of a materially conserved quantity implies that along a Lagrangian trajectory, advection alone does not change the amplitude $a$; material changes arise from non-advective processes.\n2. Newtonian relaxation of a perturbation $a$ with timescale $\\tau$ imposes a linear damping tendency proportional to $-a/\\tau$.\n\nLet $a(t)$ denote the perturbation amplitude following the parcel as it traverses the buffer. Under the assumptions stated, the amplitude evolution along the Lagrangian trajectory within the buffer is governed by the ordinary differential equation\n$$\n\\frac{\\mathrm{d}a}{\\mathrm{d}t} \\;=\\; -\\frac{1}{\\tau}\\,a.\n$$\nThis equation follows from the fact that advection transports $a$ without changing it along a trajectory, while the only local process acting on $a$ is Newtonian relaxation with rate $1/\\tau$.\n\nSolving this linear ordinary differential equation by separation of variables yields\n$$\n\\frac{\\mathrm{d}a}{a} \\;=\\; -\\frac{\\mathrm{d}t}{\\tau}\n\\quad\\Rightarrow\\quad\n\\ln a(t) - \\ln a(0) \\;=\\; -\\frac{t}{\\tau}\n\\quad\\Rightarrow\\quad\na(t) \\;=\\; a(0)\\,\\exp\\!\\left(-\\frac{t}{\\tau}\\right).\n$$\nThe perturbation enters the buffer at time $t=0$ at the outer boundary, and exits the buffer at time $t=t_{\\mathrm{buf}}$ at the inner edge. The travel time across the buffer of width $W$ at speed $U$ is the advection time\n$$\nt_{\\mathrm{buf}} \\;=\\; \\frac{W}{U}.\n$$\nTherefore, the attenuation factor $A$, defined as the ratio of the amplitude at the inner edge to that at the outer boundary, is\n$$\nA \\;\\equiv\\; \\frac{a(t_{\\mathrm{buf}})}{a(0)} \\;=\\; \\exp\\!\\left(-\\frac{t_{\\mathrm{buf}}}{\\tau}\\right) \\;=\\; \\exp\\!\\left(-\\frac{W}{U\\,\\tau}\\right).\n$$\n\nFor the given values $W=60\\ \\mathrm{km}=60{,}000\\ \\mathrm{m}$, $U=15\\ \\mathrm{m}\\ \\mathrm{s}^{-1}$, and $\\tau=600\\ \\mathrm{s}$, we compute\n$$\nt_{\\mathrm{buf}} \\;=\\; \\frac{60{,}000\\ \\mathrm{m}}{15\\ \\mathrm{m}\\ \\mathrm{s}^{-1}} \\;=\\; 4{,}000\\ \\mathrm{s},\n$$\nand thus\n$$\n\\frac{t_{\\mathrm{buf}}}{\\tau} \\;=\\; \\frac{4{,}000\\ \\mathrm{s}}{600\\ \\mathrm{s}} \\;=\\; \\frac{20}{3} \\;\\approx\\; 6.666\\overline{6}.\n$$\nHence,\n$$\nA \\;=\\; \\exp\\!\\left(-\\frac{20}{3}\\right) \\;\\approx\\; 1.2726338\\times 10^{-3}.\n$$\n\nRounded to three significant figures, the attenuation factor is $1.27\\times 10^{-3}$. Interpreting this value, the perturbation experiences approximately $6.67$ e-foldings of decay across the buffer, which strongly damps incoming synoptic disturbances within the buffer transit time, indicating that the chosen relaxation timescale is adequate for $U=15\\ \\mathrm{m}\\ \\mathrm{s}^{-1}$ synoptic motions. However, as required, the requested final answer is the numerical value of $A$.",
            "answer": "$$\\boxed{1.27 \\times 10^{-3}}$$"
        },
        {
            "introduction": "Running a high-resolution nested model is computationally expensive, so it is crucial to quantitatively assess whether it provides a genuine improvement over its parent model. This concept of 'added value' is especially important when forecasting high-impact events like extreme precipitation. This exercise  introduces a sophisticated probabilistic verification metric, the Quantile Score, to move beyond simple error measures and rigorously evaluate the performance of both parent and child models in predicting the upper tail of a distribution.",
            "id": "4032939",
            "problem": "Consider a nested dynamical downscaling setup within Numerical Weather Prediction (NWP), where a $12\\,\\mathrm{km}$ \"parent\" model provides lateral boundary conditions and a $3\\,\\mathrm{km}$ \"child\" model refines the solution over a smaller domain. Verification is performed against observations aggregated to a $5\\,\\mathrm{km}$ scale for an event characterized by precipitation extremes. The objective is to quantify the difference in extremal quantile skill between the parent and child and interpret the added value of the child. Work entirely in mathematical terms using the following definitions and test data.\n\nDefinitions:\n- Let $\\tau \\in (0,1)$ denote the quantile level. For extremes, take $\\tau$ close to $1$ (e.g., $\\tau=0.98$).\n- For a set of $n$ verification points with observed precipitation intensities $y_i$ in $\\mathrm{mm}/\\mathrm{h}$ and a model’s predicted $\\tau$-quantile $q_i$, define the Quantile Score (QS), also known as the pinball loss, as\n$$\n\\mathrm{QS}_\\tau(y,q) \\equiv \\frac{1}{n}\\sum_{i=1}^{n} \\left(\\tau - \\mathbb{I}\\{y_i  q_i\\}\\right)\\,(y_i - q_i),\n$$\nwhere $\\mathbb{I}\\{\\cdot\\}$ is the indicator function.\n- Given a common reference quantile predictor $q_i^{\\mathrm{ref}}$ (e.g., a climatological $\\tau$-quantile) with $\\mathrm{QS}_\\tau(y,q^{\\mathrm{ref}})  0$, define the Quantile Score Skill (QSS) for a model with quantile prediction $q$ as\n$$\n\\mathrm{QSS}_\\tau(y,q; q^{\\mathrm{ref}}) \\equiv 1 - \\frac{\\mathrm{QS}_\\tau(y,q)}{\\mathrm{QS}_\\tau(y,q^{\\mathrm{ref}})}.\n$$\nHigher values of $\\mathrm{QSS}_\\tau$ indicate better skill relative to the reference.\n- Define the skill difference\n$$\n\\Delta \\mathrm{QSS}_\\tau \\equiv \\mathrm{QSS}_\\tau(y,q^{\\mathrm{child}}; q^{\\mathrm{ref}}) - \\mathrm{QSS}_\\tau(y,q^{\\mathrm{parent}}; q^{\\mathrm{ref}}),\n$$\nwhere $q^{\\mathrm{parent}}$ and $q^{\\mathrm{child}}$ are the parent and child model $\\tau$-quantile predictions, respectively. A positive $\\Delta \\mathrm{QSS}_\\tau$ indicates that the child model has higher skill than the parent relative to the same reference.\n- For interpretation of added value, also consider the fractional improvement of the child over the parent in terms of the Quantile Score:\n$$\n\\mathrm{AV}_\\tau \\equiv \\frac{\\mathrm{QS}_\\tau(y,q^{\\mathrm{parent}}) - \\mathrm{QS}_\\tau(y,q^{\\mathrm{child}})}{\\mathrm{QS}_\\tau(y,q^{\\mathrm{parent}})}.\n$$\nA positive $\\mathrm{AV}_\\tau$ indicates added value from the child model.\n\nUse the following test suite with $\\tau = 0.98$ and precipitation intensities in $\\mathrm{mm}/\\mathrm{h}$:\n\n- Test Case $1$ (general extreme event with mixed dry and heavy points):\n  - Observations $y$: $[0, 12, 35, 0.5, 60, 80]$.\n  - Parent $\\tau$-quantile predictions $q^{\\mathrm{parent}}$: $[5, 20, 40, 5, 50, 70]$.\n  - Child $\\tau$-quantile predictions $q^{\\mathrm{child}}$: $[3, 25, 45, 2, 55, 85]$.\n  - Reference $\\tau$-quantile predictions $q^{\\mathrm{ref}}$: $[10, 10, 10, 10, 10, 10]$.\n\n- Test Case $2$ (boundary condition with identical parent and child predictions):\n  - Observations $y$: $[10, 10, 10, 10]$.\n  - Parent $\\tau$-quantile predictions $q^{\\mathrm{parent}}$: $[12, 12, 12, 12]$.\n  - Child $\\tau$-quantile predictions $q^{\\mathrm{child}}$: $[12, 12, 12, 12]$.\n  - Reference $\\tau$-quantile predictions $q^{\\mathrm{ref}}$: $[15, 15, 15, 15]$.\n\n- Test Case $3$ (edge case combining dry points and extreme heavy precipitation):\n  - Observations $y$: $[0, 0, 0, 40, 100]$.\n  - Parent $\\tau$-quantile predictions $q^{\\mathrm{parent}}$: $[5, 5, 5, 50, 90]$.\n  - Child $\\tau$-quantile predictions $q^{\\mathrm{child}}$: $[1, 1, 1, 60, 110]$.\n  - Reference $\\tau$-quantile predictions $q^{\\mathrm{ref}}$: $[8, 8, 8, 40, 100]$.\n\nRequirements:\n- Implement the above definitions to compute $\\Delta \\mathrm{QSS}_\\tau$ for each test case.\n- All precipitation values are in $\\mathrm{mm}/\\mathrm{h}$; the outputs are dimensionless skill differences.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3]$), where each $result_i$ is the value of $\\Delta \\mathrm{QSS}_\\tau$ for Test Case $i$, rounded to six decimal places.",
            "solution": "We start from the definition of a $\\tau$-quantile estimator in probabilistic forecasting, which is grounded in minimizing the expected pinball loss. For a given $\\tau \\in (0,1)$ and a forecast $\\tau$-quantile $q$, the pinball loss for a single observation $y$ is defined by the function\n$$\n\\ell_\\tau(y,q) = \\left(\\tau - \\mathbb{I}\\{y  q\\}\\right)\\,(y - q).\n$$\nThis loss is nonnegative because when $y \\ge q$ the term is $\\tau (y - q) \\ge 0$, and when $y  q$ it becomes $(1-\\tau)(q - y) \\ge 0$. Aggregating over $n$ verification points yields the Quantile Score (QS),\n$$\n\\mathrm{QS}_\\tau(y,q) = \\frac{1}{n}\\sum_{i=1}^{n} \\ell_\\tau(y_i,q_i) = \\frac{1}{n}\\sum_{i=1}^{n}\\left(\\tau - \\mathbb{I}\\{y_i  q_i\\}\\right)\\,(y_i - q_i).\n$$\nLower values of $\\mathrm{QS}_\\tau$ are better because they indicate smaller pinball loss.\n\nTo obtain a skill measure relative to a fixed reference forecast $q^{\\mathrm{ref}}$, we define the Quantile Score Skill (QSS) as\n$$\n\\mathrm{QSS}_\\tau(y,q; q^{\\mathrm{ref}}) = 1 - \\frac{\\mathrm{QS}_\\tau(y,q)}{\\mathrm{QS}_\\tau(y,q^{\\mathrm{ref}})}.\n$$\nThis construction is analogous to conventional skill scores: if $\\mathrm{QS}_\\tau(y,q)$ is much smaller than $\\mathrm{QS}_\\tau(y,q^{\\mathrm{ref}})$, then $\\mathrm{QSS}_\\tau$ approaches $1$; if the model is worse than the reference, then $\\mathrm{QSS}_\\tau$ becomes negative.\n\nThe difference in skill between the child and parent models is\n$$\n\\Delta \\mathrm{QSS}_\\tau = \\mathrm{QSS}_\\tau(y,q^{\\mathrm{child}}; q^{\\mathrm{ref}}) - \\mathrm{QSS}_\\tau(y,q^{\\mathrm{parent}}; q^{\\mathrm{ref}})\n= \\left(1 - \\frac{\\mathrm{QS}_\\tau(y,q^{\\mathrm{child}})}{\\mathrm{QS}_\\tau(y,q^{\\mathrm{ref}})}\\right) - \\left(1 - \\frac{\\mathrm{QS}_\\tau(y,q^{\\mathrm{parent}})}{\\mathrm{QS}_\\tau(y,q^{\\mathrm{ref}})}\\right),\n$$\nwhich simplifies to\n$$\n\\Delta \\mathrm{QSS}_\\tau = \\frac{\\mathrm{QS}_\\tau(y,q^{\\mathrm{parent}}) - \\mathrm{QS}_\\tau(y,q^{\\mathrm{child}})}{\\mathrm{QS}_\\tau(y,q^{\\mathrm{ref}})}.\n$$\nThis shows that the sign and magnitude of $\\Delta \\mathrm{QSS}_\\tau$ depend on the difference in pinball losses between parent and child, scaled by the reference loss. A positive $\\Delta \\mathrm{QSS}_\\tau$ means the child has lower pinball loss than the parent, hence higher skill relative to the same reference.\n\nFor interpretation of added value, we also define\n$$\n\\mathrm{AV}_\\tau = \\frac{\\mathrm{QS}_\\tau(y,q^{\\mathrm{parent}}) - \\mathrm{QS}_\\tau(y,q^{\\mathrm{child}})}{\\mathrm{QS}_\\tau(y,q^{\\mathrm{parent}})}.\n$$\nThis is a fractional improvement metric: $\\mathrm{AV}_\\tau  0$ indicates the child reduces loss relative to the parent, and its magnitude indicates the fraction of the parent’s loss that is eliminated.\n\nAlgorithmic steps:\n1. Fix $\\tau = 0.98$ for all test cases.\n2. For each test case, read arrays $y$, $q^{\\mathrm{parent}}$, $q^{\\mathrm{child}}$, and $q^{\\mathrm{ref}}$.\n3. Compute $\\mathrm{QS}_\\tau(y,q)$ for $q \\in \\{q^{\\mathrm{parent}}, q^{\\mathrm{child}}, q^{\\mathrm{ref}}\\}$ via the formula for $\\ell_\\tau(y_i,q_i)$ and averaging over all points.\n4. Compute $\\mathrm{QSS}_\\tau$ for parent and child using the reference.\n5. Compute $\\Delta \\mathrm{QSS}_\\tau$ as the difference of the child and parent skills.\n6. Round each $\\Delta \\mathrm{QSS}_\\tau$ to six decimal places and output the three results in a single list as specified.\n\nAnalytical verification for Test Case $1$ (to confirm magnitudes):\n- Using $\\tau = 0.98$, compute the per-point pinball losses and average them to obtain $\\mathrm{QS}_\\tau(y,q^{\\mathrm{parent}}) \\approx 3.341667$, $\\mathrm{QS}_\\tau(y,q^{\\mathrm{child}}) \\approx 0.925000$, and $\\mathrm{QS}_\\tau(y,q^{\\mathrm{ref}}) \\approx 24.075000$.\n- Then $\\mathrm{QSS}_\\tau(y,q^{\\mathrm{parent}}; q^{\\mathrm{ref}}) \\approx 1 - 3.341667/24.075 \\approx 0.8613$, $\\mathrm{QSS}_\\tau(y,q^{\\mathrm{child}}; q^{\\mathrm{ref}}) \\approx 1 - 0.925/24.075 \\approx 0.9616$, giving $\\Delta \\mathrm{QSS}_\\tau \\approx 0.1003  0$, indicating higher skill for the child and positive added value.\n\nFor Test Case $2$, since $q^{\\mathrm{child}} = q^{\\mathrm{parent}}$, both skill scores are equal and $\\Delta \\mathrm{QSS}_\\tau = 0$, meaning no added value.\n\nFor Test Case $3$, the child substantially reduces pinball loss relative to the parent, while the reference is unusually close to observations for heavy points, yielding a small $\\mathrm{QS}_\\tau(y,q^{\\mathrm{ref}})$ and thus a large positive $\\Delta \\mathrm{QSS}_\\tau$. This corresponds to strong added value from the child in representing extremes.\n\nThe program implements these steps to produce the required outputs.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef quantile_score(y: np.ndarray, q: np.ndarray, tau: float) - float:\n    \"\"\"\n    Compute the Quantile Score (pinball loss) for quantile level tau.\n    QS_tau(y,q) = mean( (tau - I[y  q]) * (y - q) )\n    \"\"\"\n    indicator = (y  q).astype(float)\n    loss = (tau - indicator) * (y - q)\n    return float(np.mean(loss))\n\ndef compute_delta_qss(y: np.ndarray, q_parent: np.ndarray, q_child: np.ndarray,\n                      q_ref: np.ndarray, tau: float) - float:\n    \"\"\"\n    Compute ΔQSS_tau = QSS_child - QSS_parent using a common reference.\n    \"\"\"\n    qs_parent = quantile_score(y, q_parent, tau)\n    qs_child = quantile_score(y, q_child, tau)\n    qs_ref = quantile_score(y, q_ref, tau)\n    # To avoid division by zero (should not occur with provided test cases),\n    # add a minimal epsilon safeguard if qs_ref is extremely small.\n    eps = 1e-12\n    denom = qs_ref if qs_ref  eps else eps\n    qss_parent = 1.0 - (qs_parent / denom)\n    qss_child = 1.0 - (qs_child / denom)\n    delta_qss = qss_child - qss_parent\n    return delta_qss\n\ndef solve():\n    tau = 0.98\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        (\n            np.array([0.0, 12.0, 35.0, 0.5, 60.0, 80.0]),\n            np.array([5.0, 20.0, 40.0, 5.0, 50.0, 70.0]),\n            np.array([3.0, 25.0, 45.0, 2.0, 55.0, 85.0]),\n            np.array([10.0, 10.0, 10.0, 10.0, 10.0, 10.0]),\n        ),\n        # Test Case 2\n        (\n            np.array([10.0, 10.0, 10.0, 10.0]),\n            np.array([12.0, 12.0, 12.0, 12.0]),\n            np.array([12.0, 12.0, 12.0, 12.0]),\n            np.array([15.0, 15.0, 15.0, 15.0]),\n        ),\n        # Test Case 3\n        (\n            np.array([0.0, 0.0, 0.0, 40.0, 100.0]),\n            np.array([5.0, 5.0, 5.0, 50.0, 90.0]),\n            np.array([1.0, 1.0, 1.0, 60.0, 110.0]),\n            np.array([8.0, 8.0, 8.0, 40.0, 100.0]),\n        ),\n    ]\n\n    results = []\n    for (y, q_parent, q_child, q_ref) in test_cases:\n        delta_qss = compute_delta_qss(y, q_parent, q_child, q_ref, tau)\n        # Round to six decimal places as required\n        results.append(round(delta_qss, 6))\n\n    # Final print statement in the exact required format (no spaces).\n    print(\"[\" + \",\".join(f\"{r:.6f}\" for r in results) + \"]\")\n\nsolve()\n```"
        }
    ]
}