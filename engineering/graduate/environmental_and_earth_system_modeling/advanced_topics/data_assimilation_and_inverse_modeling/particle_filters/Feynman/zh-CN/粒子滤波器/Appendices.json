{
    "hands_on_practices": [
        {
            "introduction": "在粒子滤波器的实际应用中，重要性权重可能跨越多个数量级，直接计算会导致数值溢出或下溢。因此，标准做法是处理对数权重，并使用数值稳定技术来计算归一化权重和有效样本量 (Effective Sample Size, ESS)。本练习将指导您实现一个能够稳健处理极端权重值的过程，这是诊断粒子集健康状况和决定何时重采样的关键第一步。",
            "id": "3906073",
            "problem": "考虑一个用于环境和地球系统建模的序贯重要性采样场景，其中潜在环境状态的概率分布通过加权粒子集合来近似。设有 $N$ 个粒子，索引为 $i \\in \\{1, \\dots, N\\}$，其未归一化的重要性权重为 $\\tilde{w}_i \\geq 0$。归一化权重 $w_i$ 满足 $\\sum_{i=1}^{N} w_i = 1$ 且对于所有 $i$ 都有 $w_i \\geq 0$。在实际实现中，所提供的值通常是未归一化权重的对数，记为 $\\ell_i = \\log \\tilde{w}_i$，因为 $\\tilde{w}_i$ 的值可能跨越多个数量级。粒子滤波器中的一个核心问题是退化现象，即只有少数粒子具有可观的权重。一个公认的退化度量是有效样本量，它取决于归一化权重的二阶矩。\n\n从重要性采样和归一化的核心定义出发，推导并实现数值稳定的程序来完成以下任务：\n- 将一个包含 $N$ 个对数权重的向量 $\\{\\ell_i\\}_{i=1}^N$ 转换为总和为 $1$ 的归一化权重 $\\{w_i\\}_{i=1}^N$，并避免计算过程中的数值下溢或上溢。\n- 使用基于归一化权重的、有原则的定义来计算有效样本量。\n\n您的实现必须能处理 $\\ell_i$ 的极端值，包括非常大的负值和负无穷大，其处理方式需与归一化和有效样本量的数学性质保持一致。\n\n您将在五个模拟不同退化程度和数值压力的场景下，使用 $N=1000$ 个粒子来测试您的程序。为保证可复现性，每个场景都指定了一个伪随机数生成器种子和构建对数权重 $\\{\\ell_i\\}_{i=1}^N$ 的规则：\n\n- 测试用例 1 (平衡的可变性)：$N = 1000$。使用种子为 $s_1 = 42$ 的伪随机数生成器，令 $\\ell_i$ 从均值为 $0$、标准差为 $1$ 的正态分布中独立抽取。\n- 测试用例 2 (均匀权重)：$N = 1000$。对所有 $i$ 设置 $\\ell_i = 0$。\n- 测试用例 3 (接近完全退化)：$N = 1000$。设置 $\\ell_1 = 0$，且对所有 $i \\in \\{2, \\dots, 1000\\}$ 设置 $\\ell_i = -100$。\n- 测试用例 4 (极小权重)：$N = 1000$。使用种子为 $s_4 = 123$ 的伪随机数生成器，令 $\\ell_i$ 从均值为 $-1000$、标准差为 $10$ 的正态分布中独立抽取。\n- 测试用例 5 (结构性零)：$N = 1000$。对 $i \\in \\{1, \\dots, 500\\}$ 设置 $\\ell_i = 0$，对 $i \\in \\{501, \\dots, 1000\\}$ 设置 $\\ell_i = -\\infty$，其中 $-\\infty$ 表示精确的负无穷大值。\n\n您的程序必须：\n1. 对每个测试用例，使用一种能保持 $\\sum_{i=1}^{N} w_i = 1$ 的数值稳定方法，根据所提供的对数权重 $\\{\\ell_i\\}_{i=1}^N$ 计算归一化权重 $\\{w_i\\}_{i=1}^N$。\n2. 使用归一化权重计算每个测试用例的有效样本量。\n\n每个测试用例的输出必须是实数。您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的列表，列表内含五个有效样本量的值，顺序与上述测试用例的描述一致（即 $[\\text{ESS}_1,\\text{ESS}_2,\\text{ESS}_3,\\text{ESS}_4,\\text{ESS}_5]$）。不涉及物理单位，也不需要角度或百分比。每个条目的结果类型必须是浮点数。",
            "solution": "该问题要求推导并实现数值稳定的方法，以便从一组给定的对数权重中计算出归一化的重要性权重和有效样本量（ESS）。这是序贯重要性采样方法（如粒子滤波器）中的一项基础任务，这些方法广泛应用于环境和地球系统建模中，用以近似后验分布。\n\n解决方案分为两部分。首先，我们推导一个用于权重归一化的数值稳定程序。其次，我们定义有效样本量并概述其计算方法。\n\n**1. 对数权重的数值稳定归一化**\n\n设 $\\{\\ell_i\\}_{i=1}^N$ 为 $N$ 个粒子的未归一化重要性权重的对数向量，其中 $\\ell_i = \\log \\tilde{w}_i$。因此，未归一化的权重为 $\\tilde{w}_i = \\exp(\\ell_i)$。\n\n第 $i$ 个粒子的归一化权重 $w_i$ 定义为其未归一化权重除以所有未归一化权重的总和：\n$$\nw_i = \\frac{\\tilde{w}_i}{\\sum_{j=1}^{N} \\tilde{w}_j} = \\frac{\\exp(\\ell_i)}{\\sum_{j=1}^{N} \\exp(\\ell_j)}\n$$\n对此表达式进行朴素计算容易产生严重的数值错误。如果任何一个 $\\ell_j$ 是一个大的正数（例如 $\\ell_j > 709$），$\\exp(\\ell_j)$ 将会超过标准64位浮点数所能表示的最大值，导致上溢。相反，如果 $\\ell_j$ 是一个大的负数（例如 $\\ell_j  -709$），$\\exp(\\ell_j)$ 将会下溢到 $0$，如果所有权重都下溢，可能会导致精度损失或除以零的错误。\n\n为了规避这个问题，我们采用一种标准的数值稳定技术，通常称为“log-sum-exp”技巧。令 $\\ell_{\\max} = \\max_{j=1}^N \\{\\ell_j\\}$。我们可以从 $w_i$ 的表达式中提出公因子 $\\exp(\\ell_{\\max})$：\n$$\nw_i = \\frac{\\exp(\\ell_i)}{\\exp(\\ell_{\\max}) \\sum_{j=1}^{N} \\frac{\\exp(\\ell_j)}{\\exp(\\ell_{\\max})}} = \\frac{\\exp(\\ell_i - \\ell_{\\max})}{\\sum_{j=1}^{N} \\exp(\\ell_j - \\ell_{\\max})}\n$$\n这个修正后的公式是数值稳定的。分子指数中的项 $\\ell_i - \\ell_{\\max}$ 总是小于或等于 $0$，因此 $\\exp(\\ell_i - \\ell_{\\max})$ 的计算结果将在 $0$ 和 $1$ 之间，从而防止上溢。类似地，分母求和中的所有项也都在 $0$ 和 $1$ 之间。对应于最大对数权重的项，即 $\\ell_j = \\ell_{\\max}$ 的项，其值为 $\\exp(0) = 1$，这确保了分母中的和至少为 $1$（除非所有的 $\\ell_i$ 都是 $-\\infty$），从而防止了该和的下溢。\n\n这种表述方式也能正确处理对数权重为 $-\\infty$ 的情况。如果 $\\ell_i = -\\infty$，这在物理上对应于未归一化权重 $\\tilde{w}_i = 0$。在我们的稳定公式中，如果 $\\ell_i = -\\infty$ 且 $\\ell_{\\max}$ 是有限值，那么 $\\ell_i - \\ell_{\\max} = -\\infty$，而 $\\exp(-\\infty)$ 的计算结果为 $0$。最终得到的归一化权重 $w_i$ 将被正确地计算为 $0$。在所有 $\\ell_i = -\\infty$ 的特殊情况下，$\\ell_{\\max} = -\\infty$。这意味着所有粒子的权重都为零，分布未定义，有效样本量为零。\n\n**2. 有效样本量 (ESS)**\n\n有效样本量 $ESS$ 是一个用于量化粒子集退化程度的度量指标。如果一个粒子集中少数粒子的权重接近 $1$，而其余粒子的权重接近 $0$，则认为该粒子集是退化的。一个大小为 $N$ 的理想非退化样本将具有均匀权重，即对所有 $i$ 都有 $w_i = 1/N$。$ESS$ 提供了一个估计值，表示与当前加权粒子集具有相同统计方差的等效均匀加权粒子数量。\n\n问题陈述指明 $ESS$ 取决于归一化权重的二阶矩。我们在此采用的标准且有原则的定义是：\n$$\nESS = \\frac{1}{\\sum_{i=1}^{N} w_i^2}\n$$\n这个定义与对退化的定性理解相符。\n- 对于一个具有均匀权重 $w_i = 1/N$ 的非退化样本，其平方和为 $\\sum_{i=1}^{N} (1/N)^2 = N \\cdot (1/N^2) = 1/N$。因此，$ESS = 1 / (1/N) = N$，这是可能的最大值。\n- 对于一个最大程度退化的样本，其中一个粒子 $k$ 的权重 $w_k = 1$，而所有其他粒子 $j \\neq k$ 的权重 $w_j = 0$，其平方和为 $\\sum_{i=1}^{N} w_i^2 = 1^2 = 1$。因此，$ESS = 1/1 = 1$，这是一个有效的权重分布所可能的最小值。\n\n$ESS$ 的值范围从 $1$ 到 $N$，提供了一个衡量样本质量的连续指标。当 $ESS$ 相对于 $N$ 较低时，这表明在粒子滤波器算法中需要进行重采样。\n\n**完整算法摘要**\n\n从对数权重向量 $\\{\\ell_i\\}_{i=1}^N$ 计算 $ESS$ 的组合程序如下：\n1. 给定输入对数权重向量 $\\boldsymbol{\\ell} = [\\ell_1, \\dots, \\ell_N]$。\n2. 找到最大对数权重：$\\ell_{\\max} = \\max_{i} \\{\\ell_i\\}$。\n3. 如果 $\\ell_{\\max} = -\\infty$（即所有对数权重均为 $-\\infty$），则有效样本量为 $0$。\n4. 否则，计算平移后的对数权重：$\\boldsymbol{\\ell'} = \\boldsymbol{\\ell} - \\ell_{\\max}$。\n5. 对平移后的对数权重取指数，得到中间值：$u_i = \\exp(\\ell'_i)$。\n6. 将这些值求和，得到归一化常数：$S = \\sum_{i=1}^{N} u_i$。\n7. 计算归一化权重：$w_i = u_i / S$。\n8. 计算归一化权重的平方和：$V = \\sum_{i=1}^{N} w_i^2$。\n9. 有效样本量是该和的倒数：$ESS = 1/V$。\n该算法在数值上是稳健的，并能正确处理问题陈述中指定的极端值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by generating test cases, computing the effective\n    sample size for each, and printing the results in the specified format.\n    \"\"\"\n\n    def compute_ess_from_log_weights(log_weights: np.ndarray) - float:\n        \"\"\"\n        Computes the effective sample size (ESS) from a vector of log-weights\n        using a numerically stable method.\n\n        Args:\n            log_weights: A 1D NumPy array of log-weights.\n\n        Returns:\n            The effective sample size as a float.\n        \"\"\"\n        # Find the maximum log-weight. np.max correctly handles -np.inf.\n        l_max = np.max(log_weights)\n\n        # If all log-weights are -inf, the maximum will be -inf.\n        # This implies all weights are zero, so the effective sample size is 0.\n        if l_max == -np.inf:\n            return 0.0\n\n        # Shift the log-weights by subtracting the maximum value.\n        # This prevents overflow/underflow in the exp calculation (log-sum-exp trick).\n        # log_weights - l_max results in values = 0.\n        shifted_logs = log_weights - l_max\n\n        # Exponentiate the shifted log-weights.\n        # np.exp(-np.inf) correctly evaluates to 0.0.\n        unnormalized_weights = np.exp(shifted_logs)\n\n        # Calculate the sum for normalization.\n        sum_weights = np.sum(unnormalized_weights)\n\n        # Normalize the weights.\n        # This check is for the unlikely case that sum_weights is zero\n        # despite l_max not being -inf (e.g., due to catastrophic cancellation,\n        # though unlikely here).\n        if sum_weights == 0:\n            return 0.0\n            \n        normalized_weights = unnormalized_weights / sum_weights\n\n        # Compute the sum of the squares of the normalized weights.\n        # This is the second-order moment.\n        sum_sq_weights = np.sum(normalized_weights**2)\n        \n        # The sum of squared weights for a valid probability distribution cannot be zero.\n        # A check for zero is good practice to prevent division by zero errors.\n        if sum_sq_weights == 0:\n            return 0.0 # Should not be reached with valid normalized_weights\n\n        # The effective sample size is the reciprocal of the sum of squared weights.\n        ess = 1.0 / sum_sq_weights\n        \n        return ess\n\n    # --- Test Case Generation and Execution ---\n\n    N = 1000\n    test_cases = [\n        # Test Case 1: Balanced variability\n        {\"name\": \"balanced\", \"seed\": 42, \"type\": \"normal\", \"params\": {\"loc\": 0, \"scale\": 1}},\n        # Test Case 2: Uniform weights\n        {\"name\": \"uniform\", \"type\": \"constant\", \"value\": 0.0},\n        # Test Case 3: Near-total degeneracy\n        {\"name\": \"degenerate\", \"type\": \"specific\"},\n        # Test Case 4: Extremely small weights\n        {\"name\": \"small\", \"seed\": 123, \"type\": \"normal\", \"params\": {\"loc\": -1000, \"scale\": 10}},\n        # Test Case 5: Structural zeros\n        {\"name\": \"zeros\", \"type\": \"structural\"}\n    ]\n\n    results = []\n    for case in test_cases:\n        log_weights = np.zeros(N, dtype=float)\n        \n        if case[\"type\"] == \"normal\":\n            rng = np.random.default_rng(seed=case[\"seed\"])\n            log_weights = rng.normal(loc=case[\"params\"][\"loc\"], scale=case[\"params\"][\"scale\"], size=N)\n        elif case[\"type\"] == \"constant\":\n            log_weights = np.full(N, case[\"value\"])\n        elif case[\"type\"] == \"specific\": # Case 3\n            log_weights = np.full(N, -100.0)\n            log_weights[0] = 0.0\n        elif case[\"type\"] == \"structural\": # Case 5\n            # These indices correspond to mathematical i in {1, ..., 500}\n            log_weights[0:500] = 0.0\n            # These indices correspond to mathematical i in {501, ..., 1000}\n            log_weights[500:1000] = -np.inf\n            \n        ess = compute_ess_from_log_weights(log_weights)\n        results.append(ess)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当有效样本量过低，表明粒子集出现退化时，必须进行重采样来“复活”粒子总体，避免滤波器失效。分层重采样是一种高效的策略，与简单的多项式重采样相比，它能显著减小采样过程引入的蒙特卡洛方差。本练习将通过一个具体算例，引导您亲手执行分层重采样算法，并从第一性原理出发推导其无偏性，从而加深您对这一核心算法组件的理解。",
            "id": "3906053",
            "problem": "针对一维温室气体示踪剂的序贯蒙特卡罗（SMC）粒子滤波器中的一个数据同化步骤，使用分层重采样来解决权重退化问题。现有 $N=8$ 个粒子，其归一化重要性权重 $\\tilde{w}_{1:8}$ 如下：\n$$\n\\tilde{w}_{1:8} = \\big(0.05,\\; 0.10,\\; 0.20,\\; 0.15,\\; 0.25,\\; 0.05,\\; 0.10,\\; 0.10\\big),\n$$\n这是基于当前时间步的单次卫星反演。令累积和为 $c_{j} = \\sum_{k=1}^{j} \\tilde{w}_{k}$（$j=1,\\dots,8$），并定义 $c_{0}=0$。在分层重采样中，重采样的祖先索引定义为 $a_{i} = \\min\\{j : c_{j} \\geq U_{i}\\}$（$i=1,\\dots,N$），其中 $U_{i}$ 是从 $[0,1]$ 上的 $N$ 个等长分层中独立抽取的均匀分布样本：\n$$\nU_{i} = \\frac{i-1 + \\epsilon_{i}}{N}, \\quad \\epsilon_{i} \\sim \\text{Uniform}(0,1], \\quad \\text{independent for } i=1,\\dots,N.\n$$\n对于此实现，假设随机偏移量为\n$$\n\\epsilon_{1:8} = \\big(0.12,\\; 0.87,\\; 0.44,\\; 0.03,\\; 0.59,\\; 0.77,\\; 0.21,\\; 0.66\\big).\n$$\n任务1：对于给定的 $\\tilde{w}_{1:8}$ 和 $\\epsilon_{1:8}$，在分层重采样下计算重采样的祖先索引向量 $a_{1:8}$。请按照索引从1开始的约定，以有序的索引行形式报告您的答案。\n\n任务2：从分层重采样的定义和区间上均匀分布的性质出发，从第一性原理推导期望重采样计数满足的无偏性属性 $\\mathbb{E}[N_{j}] = N \\tilde{w}_{j}, \\quad j=1,\\dots,8,$，其中 $N_{j} = \\sum_{i=1}^{N} \\mathbf{1}\\{a_{i}=j\\}$ 是粒子 $j$ 被选择的次数。您的推导必须仅依赖于给定的定义和关于均匀分布下区间长度的标准事实。\n\n答案说明：将任务1的祖先索引行作为最终答案。无需四舍五入。不要包含任何单位。任务2的推导过程应出现在您的解题步骤中，但无需在最终答案中体现。",
            "solution": "该问题提法明确，具有科学依据，并为获得唯一解提供了所有必要信息。这些任务涉及分层重采样算法的直接应用及其无偏性属性的标准推导。我们将按顺序处理每个任务。\n\n### 任务1：计算祖先索引向量\n\n第一个任务是为具有 $N=8$ 个粒子的粒子滤波器计算重采样的祖先索引向量 $a_{1:8}$。\n\n给定的归一化重要性权重为：\n$$\n\\tilde{w}_{1:8} = \\big(0.05,\\; 0.10,\\; 0.20,\\; 0.15,\\; 0.25,\\; 0.05,\\; 0.10,\\; 0.10\\big)\n$$\n首先，我们计算累积和 $c_j = \\sum_{k=1}^{j} \\tilde{w}_k$，其中 $c_0 = 0$。\n\\begin{align*}\nc_0 = 0 \\\\\nc_1 = 0.05 \\\\\nc_2 = 0.05 + 0.10 = 0.15 \\\\\nc_3 = 0.15 + 0.20 = 0.35 \\\\\nc_4 = 0.35 + 0.15 = 0.50 \\\\\nc_5 = 0.50 + 0.25 = 0.75 \\\\\nc_6 = 0.75 + 0.05 = 0.80 \\\\\nc_7 = 0.80 + 0.10 = 0.90 \\\\\nc_8 = 0.90 + 0.10 = 1.00\n\\end{align*}\n这些累积和定义了 $[0,1]$ 上对应于每个粒子索引的区间的边界。\n\n接下来，我们计算分层随机数 $U_i$（$i=1, \\dots, 8$）。公式为 $U_i = \\frac{i-1 + \\epsilon_i}{N}$，其中 $N=8$，给定的随机偏移量为 $\\epsilon_{1:8} = \\big(0.12,\\; 0.87,\\; 0.44,\\; 0.03,\\; 0.59,\\; 0.77,\\; 0.21,\\; 0.66\\big)$。\n\\begin{align*}\nU_1 = \\frac{1-1 + 0.12}{8} = \\frac{0.12}{8} = 0.015 \\\\\nU_2 = \\frac{2-1 + 0.87}{8} = \\frac{1.87}{8} = 0.23375 \\\\\nU_3 = \\frac{3-1 + 0.44}{8} = \\frac{2.44}{8} = 0.305 \\\\\nU_4 = \\frac{4-1 + 0.03}{8} = \\frac{3.03}{8} = 0.37875 \\\\\nU_5 = \\frac{5-1 + 0.59}{8} = \\frac{4.59}{8} = 0.57375 \\\\\nU_6 = \\frac{6-1 + 0.77}{8} = \\frac{5.77}{8} = 0.72125 \\\\\nU_7 = \\frac{7-1 + 0.21}{8} = \\frac{6.21}{8} = 0.77625 \\\\\nU_8 = \\frac{8-1 + 0.66}{8} = \\frac{7.66}{8} = 0.9575\n\\end{align*}\n\n祖先索引 $a_i$ 通过找到满足 $c_j \\geq U_i$ 的最小索引 $j$ 来确定。这等价于找到包含 $U_i$ 的区间 $(c_{j-1}, c_j]$。\n\\begin{itemize}\n    \\item 对于 $U_1 = 0.015$：$c_0=0  0.015 \\leq c_1=0.05$，所以 $a_1=1$。\n    \\item 对于 $U_2 = 0.23375$：$c_2=0.15  0.23375 \\leq c_3=0.35$，所以 $a_2=3$。\n    \\item 对于 $U_3 = 0.305$：$c_2=0.15  0.305 \\leq c_3=0.35$，所以 $a_3=3$。\n    \\item 对于 $U_4 = 0.37875$：$c_3=0.35  0.37875 \\leq c_4=0.50$，所以 $a_4=4$。\n    \\item 对于 $U_5 = 0.57375$：$c_4=0.50  0.57375 \\leq c_5=0.75$，所以 $a_5=5$。\n    \\item 对于 $U_6 = 0.72125$：$c_4=0.50  0.72125 \\leq c_5=0.75$，所以 $a_6=5$。\n    \\item 对于 $U_7 = 0.77625$：$c_5=0.75  0.77625 \\leq c_6=0.80$，所以 $a_7=6$。\n    \\item 对于 $U_8 = 0.9575$：$c_7=0.90  0.9575 \\leq c_8=1.00$，所以 $a_8=8$。\n\\end{itemize}\n得到的祖先索引向量为 $a_{1:8} = (1, 3, 3, 4, 5, 5, 6, 8)$。\n\n### 任务2：无偏性属性的推导\n\n第二个任务是推导分层重采样的无偏性属性，该属性指出粒子 $j$ 被选择的期望次数 $\\mathbb{E}[N_j]$ 等于 $N \\tilde{w}_j$。\n\n粒子 $j$ 被选择的次数 $N_j$ 由指示函数的和给出：\n$$\nN_j = \\sum_{i=1}^{N} \\mathbf{1}\\{a_i = j\\}\n$$\n其中，如果事件 $E$ 为真，则 $\\mathbf{1}\\{E\\}$ 为 $1$，否则为 $0$。\n\n根据期望的线性性质，$N_j$ 的期望值为：\n$$\n\\mathbb{E}[N_j] = \\mathbb{E}\\left[\\sum_{i=1}^{N} \\mathbf{1}\\{a_i = j\\}\\right] = \\sum_{i=1}^{N} \\mathbb{E}[\\mathbf{1}\\{a_i = j\\}]\n$$\n指示函数的期望是它所指示事件的概率。\n$$\n\\mathbb{E}[\\mathbf{1}\\{a_i = j\\}] = P(a_i = j)\n$$\n因此，我们有：\n$$\n\\mathbb{E}[N_j] = \\sum_{i=1}^{N} P(a_i = j)\n$$\n祖先索引 $a_i$ 定义为 $a_i = \\min\\{k : c_k \\geq U_i\\}$。因此，条件 $a_i = j$ 等价于 $U_i$ 落入对应于粒子 $j$ 的区间，即 $(c_{j-1}, c_j]$。所以，\n$$\nP(a_i = j) = P(c_{j-1}  U_i \\leq c_j)\n$$\n随机变量 $U_i$ 定义为 $U_i = \\frac{i-1+\\epsilon_i}{N}$，其中 $\\epsilon_i$ 从 $(0, 1]$ 上的均匀分布中抽取。这意味着 $i-1  i-1+\\epsilon_i \\leq i$，因此 $\\frac{i-1}{N}  U_i \\leq \\frac{i}{N}$。这表明 $U_i$ 是一个在第 $i$ 个分层 $S_i = (\\frac{i-1}{N}, \\frac{i}{N}]$ 上均匀分布的随机变量，其长度为 $\\frac{1}{N}$。\n\n概率 $P(c_{j-1}  U_i \\leq c_j)$ 是事件区间 $E_j = (c_{j-1}, c_j]$ 与 $U_i$ 的支撑集 $S_i$ 的交集的长度，除以 $U_i$ 的支撑集的长度。\n$$\nP(a_i = j) = \\frac{\\text{length}(E_j \\cap S_i)}{\\text{length}(S_i)} = \\frac{\\text{length}\\left((c_{j-1}, c_j] \\cap \\left(\\frac{i-1}{N}, \\frac{i}{N}\\right]\\right)}{1/N} = N \\cdot \\text{length}\\left((c_{j-1}, c_j] \\cap \\left(\\frac{i-1}{N}, \\frac{i}{N}\\right]\\right)\n$$\n现在，我们将此代入 $\\mathbb{E}[N_j]$ 的表达式中：\n$$\n\\mathbb{E}[N_j] = \\sum_{i=1}^{N} N \\cdot \\text{length}\\left((c_{j-1}, c_j] \\cap \\left(\\frac{i-1}{N}, \\frac{i}{N}\\right]\\right)\n$$\n我们可以提出因子 $N$：\n$$\n\\mathbb{E}[N_j] = N \\sum_{i=1}^{N} \\text{length}\\left((c_{j-1}, c_j] \\cap \\left(\\frac{i-1}{N}, \\frac{i}{N}\\right]\\right)\n$$\n对于 $i=1, \\dots, N$，分层 $S_i = (\\frac{i-1}{N}, \\frac{i}{N}]$ 是不相交的，并且它们的并集覆盖了整个区间 $(0, 1]$。也就是说，$\\bigcup_{i=1}^{N} S_i = (0, 1]$ 且当 $i \\neq k$ 时 $S_i \\cap S_k = \\emptyset$。\n由于这个划分属性，交集长度的和等于 $E_j$ 与所有分层并集的交集长度：\n$$\n\\sum_{i=1}^{N} \\text{length}(E_j \\cap S_i) = \\text{length}\\left(E_j \\cap \\left(\\bigcup_{i=1}^{N} S_i\\right)\\right) = \\text{length}((c_{j-1}, c_j] \\cap (0, 1])\n$$\n由于权重是归一化的，我们有对于所有 $j=1,\\dots,N$ 都有 $0 \\leq c_{j-1}  c_j \\leq 1$。因此，交集 $(c_{j-1}, c_j] \\cap (0, 1]$ 就是区间 $(c_{j-1}, c_j]$ 本身。这个区间的长度是 $c_j - c_{j-1}$。\n根据累积和的定义，$c_j - c_{j-1} = \\tilde{w}_j$。\n因此，\n$$\n\\sum_{i=1}^{N} \\text{length}(E_j \\cap S_i) = c_j - c_{j-1} = \\tilde{w}_j\n$$\n将此结果代回到 $\\mathbb{E}[N_j]$ 的表达式中，得到最终结果：\n$$\n\\mathbb{E}[N_j] = N \\tilde{w}_j\n$$\n这就完成了分层重采样无偏性属性的推导。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1  3  3  4  5  5  6  8\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "粒子滤波器的性能在很大程度上取决于提议分布的设计，一个好的提议分布能够引导粒子到达后验概率高的区域。在许多地球系统模型中，状态变量（如化学物质浓度）受到物理定律的严格约束，例如非负性。本练习将向您展示一种高级技巧，即通过在对数空间中采样来自然地满足这种约束，并指导您推导因变量变换而产生的雅可比 (Jacobian) 校正项，以确保重要性权重的计算仍然准确无误。",
            "id": "3906030",
            "problem": "考虑一个应用于大气化学输运模型的序列重要性重采样粒子滤波器（PF），其中状态是在 $d$ 个网格单元上的非负污染物浓度向量 $c \\in \\mathbb{R}_{+}^{d}$。观测值 $y \\in \\mathbb{R}^{m}$ 通过一个线性测量算子 $H \\in \\mathbb{R}^{m \\times d}$ 和加性高斯测量噪声与浓度相关，因此观测模型为 $y \\mid c \\sim \\mathcal{N}(H c, R)$，其中 $R \\in \\mathbb{R}^{m \\times m}$ 是一个已知的正定协方差矩阵。模型的预报步骤产生关于 $c$ 的先验密度 $p(c)$。\n\n为了在提议分布设计中强制浓度的非负性，考虑在对数空间中进行如下采样：逐分量地定义 $u = \\ln c$（即对于 $i = 1, \\dots, d$，有 $u_{i} = \\ln c_{i}$）。假设对数空间中的提议分布被选为一个多元高斯分布 $q_{u}(u \\mid y) = \\mathcal{N}(u; \\mu, \\Sigma)$，其均值向量为 $\\mu \\in \\mathbb{R}^{d}$，正定协方差矩阵为 $\\Sigma \\in \\mathbb{R}^{d \\times d}$，然后通过 $c = \\exp(u)$ 逐分量地映射回浓度空间。\n\n从粒子滤波器权重的重要性采样恒等式和概率密度的变量替换定理出发，推导未归一化重要性权重作为 $c$ 的函数的显式闭式表达式。该权重对应于目标后验密度 $p(y \\mid c) \\, p(c)$ 以及在变换 $c = \\exp(u)$ 下由 $q_{u}(u \\mid y)$ 导出的提议分布。你的推导必须包含强制非负性的变换所需的正确雅可比调整项。\n\n在似然和提议分布中，对多元正态分布使用标准的显式概率密度函数：\n$$\np(y \\mid c) = (2\\pi)^{-m/2} \\, |R|^{-1/2} \\, \\exp\\!\\left( -\\frac{1}{2} (y - H c)^{\\top} R^{-1} (y - H c) \\right),\n$$\n$$\nq_{u}(u \\mid y) = (2\\pi)^{-d/2} \\, |\\Sigma|^{-1/2} \\, \\exp\\!\\left( -\\frac{1}{2} (u - \\mu)^{\\top} \\Sigma^{-1} (u - \\mu) \\right).\n$$\n\n将你的最终答案表示为未归一化重要性权重 $w(c)$ 的单一闭式解析表达式，该表达式是 $c$、$y$、$H$、$R$、$\\mu$、$\\Sigma$ 以及先验 $p(c)$ 的函数。不要使用比例符号；包括变量替换定理所需的所有乘法因子。不需要进行数值计算或四舍五入，最终表达式中不应出现物理单位。",
            "solution": "该问题提法恰当，有科学依据，并包含了推导所要求表达式的所有必要信息。\n\n在序列重要性重采样粒子滤波器中，一个粒子（即一个样本状态向量）$c$ 的未归一化重要性权重 $w(c)$ 由目标密度与提议密度的比值给出，并在该粒子处进行求值。目标密度是给定观测值时状态的未归一化后验概率密度，它正比于似然乘以先验，即 $p(c \\mid y) \\propto p(y \\mid c) p(c)$。\n\n因此，重要性权重 $w(c)$ 定义为：\n$$\nw(c) = \\frac{p(y \\mid c) p(c)}{q_c(c \\mid y)}\n$$\n其中 $p(y \\mid c)$ 是给定状态 $c$ 时观测到 $y$ 的似然，$p(c)$ 是状态的先验密度，而 $q_c(c \\mid y)$ 是从中抽取粒子 $c$ 的提议密度。\n\n问题给出了似然 $p(y \\mid c)$ 的显式形式，而先验 $p(c)$ 是一个给定函数。主要任务是找到浓度空间 $c$ 中提议密度 $q_c(c \\mid y)$ 的表达式。我们已知对数空间中的提议密度 $q_u(u \\mid y)$，其中 $u = \\ln c$ 是逐分量定义的。我们必须使用概率密度的变量替换定理将 $q_u(u \\mid y)$ 变换为 $q_c(c \\mid y)$。\n\n两个随机变量向量 $U$ 和 $C$ 通过一个可逆、可微的变换 $C = g(U)$（或等价地 $U = g^{-1}(C)$）相关联，它们密度之间的关系由下式给出：\n$$\np_C(c) = p_U(g^{-1}(c)) \\left| \\det\\left( J_{g^{-1}}(c) \\right) \\right|\n$$\n其中 $J_{g^{-1}}(c)$ 是逆变换 $g^{-1}$ 的雅可比矩阵。\n\n在我们的情况中，状态变量是 $c \\in \\mathbb{R}_{+}^{d}$，变换后的变量是 $u \\in \\mathbb{R}^{d}$。变换是从 $u$ 到 $c$：$c = \\exp(u)$，其中指数函数是逐分量应用的，因此对于 $i=1, \\dots, d$，有 $c_i = \\exp(u_i)$。逆变换是从 $c$ 到 $u$：$u = \\ln c$，其中对数函数是逐分量应用的，因此对于 $i=1, \\dots, d$，有 $u_i = \\ln(c_i)$。这里，$g^{-1}(c) = \\ln(c)$。\n\n我们需要计算这个逆变换的雅可比矩阵，$J_{\\ln(c)} = \\frac{\\partial u}{\\partial c}$。该矩阵的元素是 $J_{ij} = \\frac{\\partial u_i}{\\partial c_j}$。\n$$\nJ_{ij} = \\frac{\\partial (\\ln c_i)}{\\partial c_j} =\n\\begin{cases}\n    \\frac{1}{c_i}   \\text{if } i=j \\\\\n    0   \\text{if } i \\neq j\n\\end{cases}\n$$\n这表明雅可比矩阵是一个对角矩阵：\n$$\nJ_{\\ln(c)} = \\text{diag}\\left(\\frac{1}{c_1}, \\frac{1}{c_2}, \\dots, \\frac{1}{c_d}\\right)\n$$\n对角矩阵的行列式是其对角元素的乘积：\n$$\n\\det\\left( J_{\\ln(c)} \\right) = \\prod_{i=1}^{d} \\frac{1}{c_i}\n$$\n由于浓度 $c_i$ 是严格为正的（$c \\in \\mathbb{R}_{+}^{d}$），行列式的绝对值就是行列式本身：\n$$\n\\left| \\det\\left( J_{\\ln(c)} \\right) \\right| = \\prod_{i=1}^{d} \\frac{1}{c_i} = \\left(\\prod_{i=1}^{d} c_i\\right)^{-1}\n$$\n这就是雅可比调整因子。\n\n现在我们可以使用给定的 $u$ 空间中的提议分布 $q_u(u \\mid y) = \\mathcal{N}(u; \\mu, \\Sigma)$，来写出 $c$ 空间中的提议密度 $q_c(c \\mid y)$:\n$$\nq_c(c \\mid y) = q_u(\\ln c \\mid y) \\left| \\det\\left( J_{\\ln(c)} \\right) \\right|\n$$\n代入 $q_u$ 的显式形式和雅可比行列式：\n$$\nq_c(c \\mid y) = \\left( (2\\pi)^{-d/2} |\\Sigma|^{-1/2} \\exp\\left( -\\frac{1}{2} (\\ln c - \\mu)^{\\top} \\Sigma^{-1} (\\ln c - \\mu) \\right) \\right) \\left( \\prod_{i=1}^{d} \\frac{1}{c_i} \\right)\n$$\n这里，$\\ln c$ 是向量 $(\\ln c_1, \\dots, \\ln c_d)^{\\top}$。\n\n最后，我们将所有分量代回重要性权重 $w(c)$ 的公式中：\n$$\nw(c) = \\frac{p(y \\mid c) p(c)}{q_c(c \\mid y)} = \\frac{ \\left( (2\\pi)^{-m/2} |R|^{-1/2} \\exp\\left( -\\frac{1}{2} (y - H c)^{\\top} R^{-1} (y - H c) \\right) \\right) p(c) }{ \\left( (2\\pi)^{-d/2} |\\Sigma|^{-1/2} \\exp\\left( -\\frac{1}{2} (\\ln c - \\mu)^{\\top} \\Sigma^{-1} (\\ln c - \\mu) \\right) \\right) \\left( \\prod_{i=1}^{d} c_i^{-1} \\right) }\n$$\n为了简化，我们可以重新整理这些项。分母中的项 $\\left( \\prod_{i=1}^{d} c_i^{-1} \\right)$ 移到分子。分母中的指数项也移到分子，其参数的符号反转。\n$$\nw(c) = \\frac{(2\\pi)^{-m/2} |R|^{-1/2}}{(2\\pi)^{-d/2} |\\Sigma|^{-1/2}} \\left( \\prod_{i=1}^{d} c_i \\right) p(c) \\exp\\left( -\\frac{1}{2} (y - H c)^{\\top} R^{-1} (y - H c) - \\left(-\\frac{1}{2} (\\ln c - \\mu)^{\\top} \\Sigma^{-1} (\\ln c - \\mu) \\right) \\right)\n$$\n将常数前置因子分组并合并指数部分：\n$$\nw(c) = (2\\pi)^{(d-m)/2} \\frac{|\\Sigma|^{1/2}}{|R|^{1/2}} \\left( \\prod_{i=1}^{d} c_i \\right) p(c) \\exp\\left( -\\frac{1}{2} (y - H c)^{\\top} R^{-1} (y - H c) + \\frac{1}{2} (\\ln c - \\mu)^{\\top} \\Sigma^{-1} (\\ln c - \\mu) \\right)\n$$\n这就是未归一化重要性权重 $w(c)$ 的最终显式闭式表达式。",
            "answer": "$$\n\\boxed{(2\\pi)^{\\frac{d-m}{2}} \\left( \\frac{|\\Sigma|}{|R|} \\right)^{\\frac{1}{2}} \\left( \\prod_{i=1}^{d} c_i \\right) p(c) \\exp\\left(-\\frac{1}{2} (y - H c)^{\\top} R^{-1} (y - H c) + \\frac{1}{2} (\\ln c - \\mu)^{\\top} \\Sigma^{-1} (\\ln c - \\mu)\\right)}\n$$"
        }
    ]
}