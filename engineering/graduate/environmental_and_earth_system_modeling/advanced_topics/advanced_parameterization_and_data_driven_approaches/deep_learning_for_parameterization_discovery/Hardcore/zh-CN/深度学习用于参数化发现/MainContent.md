## 引言
[地球系统模型](@entry_id:1124096)（ESM）是理解和预测气候变化不可或缺的工具，但其准确性长期受限于一个核心挑战：[参数化](@entry_id:265163)。由于计算资源的限制，模型无法直接解析云的形成、海洋涡流和[湍流混合](@entry_id:202591)等关键的[次网格尺度过程](@entry_id:1132602)。传统方法依赖于简化的物理假设来表示这些过程的影响，这引入了显著的结构性误差，成为[气候预测](@entry_id:184747)不确定性的主要来源。[深度学习](@entry_id:142022)的崛起为这一难题提供了全新的解决范式——不是简单地标定现有公式的参数，而是直接从高分辨率数据中“发现”控制这些复杂过程的未知物理函数关系。

然而，如何确保这些数据驱动的模型在物理上是一致且可靠的？本文旨在系统性地解答这一问题。我们将深入探讨如何将[深度学习](@entry_id:142022)应用于[参数化](@entry_id:265163)发现，重点关注物理知识与机器学习的深度融合。通过本文的学习，读者将掌握构建、约束和验证物理一致性神经[网络模型](@entry_id:136956)的关键技术。

文章分为三个核心部分：第一章“原理与机制”将奠定理论基础，阐明[参数化](@entry_id:265163)问题的本质，并详细介绍如何通过架构设计和损失函数将物理守恒律嵌入模型。第二章“应用与跨学科连接”将通过大气、海洋和[冰冻圈](@entry_id:1123254)等领域的丰富案例，展示这些原理的实际应用，并探索其在其他科学领域的共通性。最后，第三章“动手实践”将提供具体练习，帮助读者将理论知识转化为解决实际问题的能力。现在，让我们从理解[参数化](@entry_id:265163)问题的基本原理开始。

## 原理与机制

本章深入探讨了利用[深度学习](@entry_id:142022)发现[地球系统模型](@entry_id:1124096)（ESM）中[参数化](@entry_id:265163)方案的基本原理和核心机制。我们将首先明确[参数化](@entry_id:265163)问题的本质，并将其与[数值误差](@entry_id:635587)区分开。随后，我们将探讨数据驱动方法与传统方法的区别，并详细介绍如何设计、约束和验证神经网络，使其不仅能从数据中学习，还能遵守基本的物理定律。

### [地球系统模型](@entry_id:1124096)中的[参数化](@entry_id:265163)问题

[地球系统模型](@entry_id:1124096)通过在有限的网格上求解一系列预报性的守恒律来模拟气候系统。这些方程，例如[流体动力](@entry_id:750449)学的[纳维-斯托克斯方程](@entry_id:142275)，描述了质量、动量和能量等物理量的演变。然而，一个根本性的挑战在于尺度问题。模型的[计算网格](@entry_id:168560)（例如，水平分辨率为25公里）远大于许多关键物理过程（如云的形成、湍流混合）发生的尺度。因此，模型只能直接解析“网格尺度”或“已解析尺度”的运动。

为了推导出在粗糙网格上求解的方程，我们必须对原始的连续控制方程进行滤波或[空间平均](@entry_id:203499)。以一个标量示踪剂场 $q(\mathbf{x}, t)$ 为例，其守恒律可以写为：
$$
\partial_t q + \nabla \cdot (\mathbf{u} q) = \nabla \cdot (K \nabla q) + S
$$
其中 $\mathbf{u}$ 是速度场，$K$ 是扩散系数，$S$ 是源汇项。对该方程进行滤波（用上划线表示），我们得到：
$$
\partial_t \bar{q} + \nabla \cdot \overline{(\mathbf{u} q)} = \dots
$$
问题出在[非线性](@entry_id:637147)项上，例如平流项 $\overline{\mathbf{u} q}$。一般来说，滤波后的变量乘积不等于变量滤波后的乘积，即 $\overline{\mathbf{u} q} \neq \bar{\mathbf{u}} \bar{q}$。通过将变量分解为已解析部分（$\bar{q}$）和次网格部分（$q'$），我们可以看到滤波后会产生额外的项，例如[雷诺应力](@entry_id:263788)项 $\overline{\mathbf{u}'q'}$。这些项代表了未解析的次网格尺度（subgrid-scale, SGS）物理过程对已解析尺度的影响。由于这些项不能仅通过已解析变量 $\bar{q}$ 和 $\bar{\mathbf{u}}$ 来表达，因此它们是“未闭合的”。

**[参数化](@entry_id:265163)（parameterization）**的本质是一个物理闭合问题：它旨在为这些由滤波或平均产生的未闭合项（如次网格通量和源项）建立模型，将其表示为已解析尺度变量的函数。这些未闭合项代表了真实的、但未被模型直接解析的物理过程。

必须强调，[参数化](@entry_id:265163)与**[数值离散化](@entry_id:752782)误差（numerical discretization error）**有着本质的区别。[数值离散化](@entry_id:752782)误差是在我们将（已经滤波的）[偏微分](@entry_id:194612)方程中的微分算子（如 $\partial_t$、$\nabla$）替换为离散的代数形式（如有限差分）以便在计算机上求解时引入的数学近似误差。这种误差是数值方法的产物，它会随着网格分辨率的提高而减小。与之相反，[参数化](@entry_id:265163)代表的是被模型网格“平均掉”的真实物理效应。因此，深度学习在这一领域的应用目标是发现物理上未知的函数关系，而不是修正数值计算方法本身引入的误差 。

### [数据驱动的发现](@entry_id:274863)与传统标定

为次网格过程构建闭合方案的传统方法通常是**参数标定（parameter calibration）**。这种方法首先假设一个固定的函数结构来描述次网格效应，这个结构通常基于简化的物理理论或经验。例如，对于未解析的湍流通量 $\mathbf{F}_{\text{sub}}$，一个经典的假设是它与已[解析梯度](@entry_id:1120999)的方向相反，形式为 $\mathbf{F}_{\text{sub}} = - K \nabla q$，其中 $K$ 是所谓的“[涡动扩散系数](@entry_id:196515)”。模型开发者可能会进一步假设 $K$ 的函数形式，比如 $K = \alpha N^{\beta}$，其中 $N$ 是一个稳定性度量。然后，通过与观测数据或高分辨率模拟数据进行比较，来估计或“标定”其中的待定系数（如 $\alpha$ 和 $\beta$）。

这种方法的成败完全取决于最初的函数结构假设是否正确。如果假设的结构（例如，幂律关系）与真实物理在高稳定性或极端条件下的行为（例如，饱和效应）不符，那么即使在训练数据范围内拟合得很好，模型在训练范围之外的外推（extrapolation）能力也会很差。这种由于模型结构本身不正确而导致的误差被称为**结构性误差（structural error）**。

与此相对，**[参数化](@entry_id:265163)发现（parameterization discovery）**采用了一种更灵活的策略。它不预先设定严格的函数形式，而是利用[深度神经网络](@entry_id:636170)等具有强大[表达能力](@entry_id:149863)的[函数逼近](@entry_id:141329)器，直接从数据中学习从已解析状态到未解析效应的复杂映射关系。例如，模型 $\mathbf{F}_\phi = - D_\phi(q, N)\,\nabla q$ 允许神经网络 $\phi$ 学习一个非常灵活的扩散系数函数 $D_\phi$，这个函数可能比任何简单的幂律形式都更接近真实物理。

深度学习方法的优势在于它有潜力发现未知的、非平凡的函数关系，从而减少结构性误差。然而，这种灵活性也带来了挑战。为了使模型具有良好的泛化和外推能力，必须将已知的物理原理作为**[归纳偏置](@entry_id:137419)（inductive biases）**编码到模型中。例如，强制扩散系数 $D_\phi \geq 0$ 可以保证模型遵守[热力学](@entry_id:172368)第二定律（即[湍流](@entry_id:151300)总是耗散梯度，而不是产生梯度）。这些物理约束缩小了可能的函数空间，排除了大量不符合物理规律的解，从而提高了模型在训练数据之外（即发生[协变量偏移](@entry_id:636196)时）的可信度和鲁棒性 。

### 学习物理依赖性的[神经网络架构](@entry_id:637524)

选择合适的[神经网络架构](@entry_id:637524)对于成功发现[参数化](@entry_id:265163)至关重要。不同的架构包含不同的[归纳偏置](@entry_id:137419)，使其天然地适合于表示特定类型的物理依赖关系。

#### 局部依赖性与等变性

许多次网格过程（如湍流混合）主要是局部的，即一个网格单元的次网格倾向主要取决于该单元及其近邻的状态。
*   在均匀的[笛卡尔](@entry_id:925811)网格上，物理定律通常具有**[平移等变性](@entry_id:636340)（translation equivariance）**，即物理过程不应依赖于其在空间中的绝对位置。**[卷积神经网络](@entry_id:178973)（CNN）**通过其[局部感受野](@entry_id:634395)和[权重共享](@entry_id:633885)机制，完美地内嵌了这两种偏置（局部性和[平移等变性](@entry_id:636340)）。因此，CNN是模拟均匀网格上局部闭合方案的理想选择  。
*   然而，在非结构化网格（如用于天气预报的[二十面体网格](@entry_id:1126331)）或球形网格上，标准的CNN不再适用。在球面上，物理定律应遵守**旋转[等变性](@entry_id:636671)（rotational equivariance）**，即物理规律不应随坐标系的旋转而改变。为此，研究人员开发了**球形CNNs（Spherical CNNs）**，它们通过使用球谐函数或[群卷积](@entry_id:635449)来保证 $\mathrm{SO}(3)$ 旋转[等变性](@entry_id:636671)。对于更一般的非结构化网格，其对称性主要体现在节点标签的**置换等变性（permutation equivariance）**上。**[图神经网络](@entry_id:136853)（GNN）**通过在图的节点和边之间进行局部信息传递（message passing），并使用置换不变的聚合函数（如求和或平均），天然地满足了这一要求。因此，GNN非常适合在[非结构化网格](@entry_id:756354)上构建[参数化](@entry_id:265163)方案 。

#### 非局部与[长程依赖](@entry_id:181727)性

某些物理过程，如辐射传输，本质上是**非局部的（nonlocal）**。一个点的辐射收支取决于整个大气柱的状态。
*   **变换器（Transformers）**架构中的[自注意力机制](@entry_id:638063)能够计算输入序列中所有元素之间的成对交互，这为模拟长程空间依赖和[非局部效应](@entry_id:198046)提供了强大的[归纳偏置](@entry_id:137419)。
*   **[神经算子](@entry_id:1128605)（Neural Operators）**，特别是**[傅里叶神经算子](@entry_id:189138)（FNO）**，被设计用来学习[函数空间](@entry_id:143478)之间的映射。FNO在傅里叶空间中执行全局卷积，这与[积分算子](@entry_id:262332)的形式非常相似，使其天然适合表示非局部闭合。一个关键优势是，由于它学习的是[连续函数空间](@entry_id:150395)中的算子，因此可以在不同分辨率的网格上进行“零样本”泛化，而无需重新训练 。

### 将物理学嵌入神经网络

纯粹的数据驱动模型即使在离线测试中表现出色，也常常在与气候模型的动态核心耦合时出现不稳定或违反基本守恒律的问题。因此，将物理约束整合到学习过程中是至关重要的。

#### 混合建模

一个稳健的策略是**混合建模（Hybrid Modeling）**。在这种范式中，我们并不用神经网络取代整个物理模型，而是将其作为一个组件嵌入到现有的物理求解器中。一个科学合理的划分策略是：
1.  **保留**模型中那些描述已充分理解的、控制着基本守恒律的已解析动力学部分（例如，由 $\mathcal{F}(\mathbf{q})$ 代表的大尺度平流、科里奥利力等）。
2.  **替换**或增强那些不确定性高、难以从第一性原理推导的[次网格参数化](@entry_id:1132597)部分。

这样，混合后的方程形式为 $\partial_t \mathbf{q} = \mathcal{F}(\mathbf{q}) + \hat{\mathbf{s}}(\mathbf{q}; \boldsymbol{\theta})$，其中 $\hat{\mathbf{s}}$ 是神经网络学习的次网格倾向。这种方法利用了物理模型的严谨性和守恒性，同时借助机器学习的灵活性来处理模型中的未知部分 。

#### 硬约束：保证守恒的架构设计

最强的物理约束形式是通过架构设计来强制执行，即所谓的**硬约束（hard constraints）**。这种方法可以保证无论神经网络的参数如何，某些物理定律都始终得到满足。

在[有限体积法](@entry_id:141374)中，局部质量守恒要求通过相邻网格单元之间共享面的通量必须大小相等、方向相反。我们可以设计一个神经网络，使其直接预测面上的通量，并保证这种[反对称性](@entry_id:261893)。例如，一个面的法向通量 $\widehat{\phi}_f$ 可以被建模为面两侧状态[特征函数](@entry_id:186820)之差：
$$
\widehat{\phi}_f(\mathbf{z}_L, \mathbf{z}_R) = h_{\boldsymbol{\theta}}(\mathbf{z}_L) - h_{\boldsymbol{\theta}}(\mathbf{z}_R)
$$
其中 $h_{\boldsymbol{\theta}}$ 是一个共享的神经网络，$\mathbf{z}_L$ 和 $\mathbf{z}_R$ 分别是面左侧和右侧的状态特征。这种结构天生就是反对称的，即 $\widehat{\phi}_f(\mathbf{z}_L, \mathbf{z}_R) = -\widehat{\phi}_f(\mathbf{z}_R, \mathbf{z}_L)$，从而在代数上精确地保证了局部[质量守恒](@entry_id:204015)，而与网络参数 $\boldsymbol{\theta}$ 的具体取值无关。另一种方法是预测一个[标量势](@entry_id:276177)场 $\psi$，然后通过其[离散梯度](@entry_id:171970)来定义通量，这种形式同样能保证守恒性 。

#### 软约束：基于物理的正则化

另一种施加约束的方法是**软约束（soft constraints）**，即在训练的[损失函数](@entry_id:634569)中加入惩罚项，以惩罚对物理定律的违反。这种方法虽然不能像硬约束那样提供绝对保证，但它更加灵活，可以用于施加难以通过架构设计的复杂约束。

例如，我们可以设计一个正则化项 $R(\boldsymbol{\theta})$，它包含两部分 ：
1.  **PDE残差惩罚**：将神经网络的输出代入控制方程的[弱形式](@entry_id:142897)（通过与一组测试函数 $\varphi_m$ 做[内积](@entry_id:750660)得到），并惩罚其与零的偏差。通过[分部积分](@entry_id:136350)，可以避免对神经网络输出进行显式求导。
2.  **[热力学约束](@entry_id:755911)惩罚**：许多次网格过程是耗散的，例如，它们应该导致示踪剂方差的减少。这意味着次网格通量 $\boldsymbol{q}_{\boldsymbol{\theta}}$ 与示踪剂梯度 $\nabla \bar{T}$ 的[内积](@entry_id:750660)在全局平均意义下应为非正，即 $\langle \boldsymbol{q}_{\boldsymbol{\theta}}, \nabla \bar{T} \rangle \leq 0$。我们可以只惩罚对这个不等式的违反，例如通过惩罚项 $(\left[ \langle \boldsymbol{q}_{\boldsymbol{\theta}}^n, \nabla \bar{T}^n \rangle \right]_+)^2$，其中 $[x]_+ := \max(x, 0)$。

一个综合的正则化项可以写为：
$$
R(\boldsymbol{\theta}) = \frac{1}{N} \sum_{n=1}^{N} \left[ \sum_{m=1}^{M} \left( \text{weak PDE residual} \right)^{2} + \alpha \left( \left[ \langle \boldsymbol{q}_{\boldsymbol{\theta}}^n, \nabla \bar{T}^n \rangle \right]_+ \right)^{2} \right]
$$
通过最小化包含这种正则化项的总[损失函数](@entry_id:634569)，可以引导神经网络学习出更符合物理规律的解。

### 数据、验证与不确定性

#### 训练数据源

[参数化](@entry_id:265163)发现的成功在很大程度上取决于训练数据的质量。理想的训练数据应由能够完全解析我们希望[参数化](@entry_id:265163)的物理过程的模拟生成。主要的数据源包括 ：
*   **[直接数值模拟](@entry_id:149543)（DNS）**：解析流体运动的所有尺度，提供最精确的“真值”。但由于计算成本极高，通常只能在小空间域和理想化的物理条件下进行，其代表性有限。
*   **大涡模拟（LES）**：解析大尺度的能量包含涡，而对更小的次网格尺度涡进行[参数化](@entry_id:265163)。LES可以在比DNS大得多的区域内进行，并包含更复杂的物理过程（如云），是当前为大气[参数化](@entry_id:265163)方案提供训练数据最常用的工具。其自身[次网格模型](@entry_id:755601)带来的偏差通常远小于待[参数化](@entry_id:265163)过程的尺度，因此可被视为高质量的训练目标。
*   **再分析资料（Reanalysis）**：通过[数据同化技术](@entry_id:637566)将全球观测数据融合到[天气预报模型](@entry_id:1134014)中生成的产品。它具有全球覆盖和物理过程完备的优点，但其分辨率与目标模型相当，并未解析次网格过程。更重要的是，再分析资料本身就包含了其宿[主模](@entry_id:263463)型自身的[参数化](@entry_id:265163)方案，试图用它来学习一个新的[参数化](@entry_id:265163)方案会导致“循[环论](@entry_id:143825)证”，难以识别出真实的物理闭合项。
*   **卫星产品**：提供全球覆盖的高分辨率观测，但通常是诊断量（如辐射），而非模型直接预报的变量。从观测反演物理状态的过程会引入显著偏差。此外，卫星观测的时间采样率通常较低，难以计算倾向项，因此不适合直接用于训练倾向基的闭合方案。

#### 验证的层级

验证一个学习到的[参数化](@entry_id:265163)方案是一个多阶段的过程，以确保其在与复杂[气候模型耦合](@entry_id:1122464)时的鲁棒性。这个过程通常分为三个层级 ：
1.  **离线验证（Offline Validation）**：在不运行预报模型的情况下，将神经网络的预测结果与一个独立的测试数据集（即“[真值](@entry_id:636547)”倾向）进行比较。这是标准的监督学习评估，用于检验模型的瞬时预测精度。
2.  **部分耦合验证（Partially Coupled Validation）**：将学习到的[参数化](@entry_id:265163)方案放入一个简化的、但仍具有时间演化的测试平台中。例如，在[单柱模型](@entry_id:1131703)（SCM）中，本地的垂直物理过程（由神经网络[参数化](@entry_id:265163)）与规定的大尺度强迫相互作用。这个中间步骤对于诊断在完全耦合时可能出现的稳定性和偏差问题至关重要。
3.  **在线验证（Online Validation）**：将学习到的[参数化](@entry_id:265163)方案完全整合到三维的[地球系统模型](@entry_id:1124096)中，并进行长时间的积分（数年到数百年）。这是最终的测试，评估模型是否能在数值上保持稳定，是否能保持全局能量和物质守恒，以及是否能再现出真实气候系统的平均态、变率和极端事件等涌现特性。

一个鲁棒的[参数化](@entry_id:265163)方案必须成功通过所有这三个层级的考验。离线成功是必要条件，但远非充分条件，因为微小的离线误差可能在[非线性](@entry_id:637147)的在线耦合中被放大，导致灾难性的失败。

#### 不确定性量化

最后，一个可信的[参数化](@entry_id:265163)方案应该能够量化其预测的不确定性。不确定性主要分为两类 ：
*   **[偶然不确定性](@entry_id:634772)（Aleatoric Uncertainty）**：源于数据生成过程内在的、不可约的随机性。在气候模型中，这对应于次网格过程（如[湍流](@entry_id:151300)和微物理过程）的固有随机行为。这种不确定性可以通过让神经网络预测一个与输入相关的概率分布来建模，例如，通过**异方差输出（heteroscedastic outputs）**，即网络不仅预测均值 $\mu_\theta(s)$，还预测方差 $\sigma_\theta^2(s)$。
*   **认知不确定性（Epistemic Uncertainty）**：源于我们知识的局限，包括模型结构的不完善和训练数据的有限性。这种不确定性可以通过训练一个**模型集成（ensemble）**来估计。集成中的每个模型都使用不同的初始化或不同的数据子集（如自助法）进行训练。在数据稀疏或分布外的区域，不同模型成员的预测会产生[分歧](@entry_id:193119)，这种分歧（即集成预测的方差）就是认知不确定性的一个度量。

通过同时建模这两种不确定性，我们可以得到一个更全面的预测。总预测不确定性可以根据[全方差公式](@entry_id:177482)分解为两部分：[偶然不确定性](@entry_id:634772)（各成员预测方差的平均值）和认知不确定性（各成员预测均值的方差）。这种分解具有重要的实际意义：[偶然不确定性](@entry_id:634772)的大小指导我们是否应采用[随机参数化](@entry_id:1132435)方案来表示次网格的统计特性；而认知不确定性的高低则可以作为一个“置信度”指标，用于检测模型何时在处理其未曾见过的、不可靠的输入，从而触发安全回退机制，降低[模型风险](@entry_id:136904)。