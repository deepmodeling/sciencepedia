## 应用与跨学科连接

### 引言

在前面的章节中，我们已经探讨了利用深度学习发现[参数化](@entry_id:265163)方案的核心原理与机制。我们了解到，通过将物理约束嵌入神经网络的架构和学习过程中，可以开发出能够模拟复杂地球系统中未解析过程的数据驱动模型。本章的目标是搭建一座桥梁，连接这些理论基础与它们在真实世界中的多样化应用。我们将不再重复核心概念，而是展示这些原理如何在不同科学与工程领域中得到应用、扩展和整合。

[参数化](@entry_id:265163)是[地球系统模型](@entry_id:1124096)中无处不在的挑战，从云的形成到海洋涡流，再到冰盖的流动，许多关键过程由于尺度过小而无法在计算网格上直接解析。传统[参数化](@entry_id:265163)方案基于简化假设，往往成为模型不确定性的主要来源。深度学习为这一悠久挑战提供了全新的范式。本章将通过一系列应用实例，探索深度学习[参数化](@entry_id:265163)在不同领域的应用，包括大气科学、物理海洋学、[冰冻圈](@entry_id:1123254)动力学，并触及更广泛的交叉学科，如数据同化、工程热物理和[计算生物学](@entry_id:146988)。通过这些案例，我们将揭示，[深度学习](@entry_id:142022)并非取代物理理解的“黑箱”，而是与物理原理协同作用，共同构建更准确、更稳健、更可信的复杂系统模型的强大工具。

### 大气过程：从对流到边界层

大气是地球系统中最具动态性和挑战性的组成部分之一，其多尺度相互作用为[参数化](@entry_id:265163)提供了丰富的应用场景。从驱动天气的[湿对流](@entry_id:1128092)到地表与大气间的能量交换，深度学习正在为这些过程的建模带来变革。

#### [湿对流](@entry_id:1128092)

[湿对流](@entry_id:1128092)，即潮湿空气的上升和下沉运动，是热带天气和[全球大气环流](@entry_id:189520)的关键驱动力。由于其尺度远小于典型气候模型的网格尺寸，对流必须被[参数化](@entry_id:265163)。一个成功的对流[参数化](@entry_id:265163)方案必须在物理上完备且在[热力学](@entry_id:172368)上自洽，特别是在能量和水的守恒方面。设计一个[深度学习](@entry_id:142022)对流[闭包](@entry_id:148169)方案时，最关键的决策在于选择合适的预测因子（输入）和目标（输出）。为了确保物理一致性，预测因子必须能完全描述大气柱的状态及其受到的驱动力，这包括整层大气的[热力学](@entry_id:172368)廓线（如温度和湿度）以及大尺度强迫（如垂直运动和[辐射加热](@entry_id:754016)）。相应地，学习目标不应是中间诊断量（如对流有效位能CAPE），而应是直接驱动状态变量演化的项，即未解析的对流过程对守恒变量（如[湿静力能](@entry_id:1128097) $h$ 和总水物质 $q_t$）的垂直倾向廓线。通过学习从完整的状态和强迫到[守恒量](@entry_id:161475)倾向的映射，神经网络可以直接为[预报方程](@entry_id:1130221)提供闭合项。这种设计框架不仅因果关系清晰，而且便于在训练过程中通过约束垂[直积](@entry_id:143046)分来强制执行能量和水的守恒定律，从而确保模型的长期稳定性和物理真实性。

#### 边界层[湍流](@entry_id:151300)

[大气边界层](@entry_id:1121182)是地球表面与自由大气相互作用的区域，其[湍流混合](@entry_id:202591)过程对天气和气候至关重要。在由地表加热驱动的对流边界层中，一个经典的难题是所谓的“逆梯度输送”（countergradient transport）。大型湍涡可以将热量从地表一直向上输送到边界层顶部，即使在[混合层](@entry_id:926526)中部，平均位温梯度近乎为零。传统的局部[扩散模型](@entry_id:142185)，其形式为 $\overline{w'\theta'} = -K \frac{\partial \bar{\theta}}{\partial z}$（其中 $K \ge 0$），在这种情况下会预测通量为零，从而无法捕捉到观测到的向上[热输送](@entry_id:199637)。此外，在边界层顶部的卷夹层，[湍流](@entry_id:151300)会将上方自由大气的暖空气向下混合，形成一个负的热通量，这对边界层的增长至关重要。一个纯粹的局部模型难以同时准确地描述[混合层](@entry_id:926526)内部的正通量和顶部的负通量。

为了解决这个问题，需要非局部的[闭包](@entry_id:148169)方案。深度学习为此提供了强大的工具。一个物理上一致的非局部[闭包](@entry_id:148169)可以将[湍流通量](@entry_id:1133513)分解为局部（梯度驱动）和非局部（非梯度驱动）两部分。神经网络可以被训练来学习一个非局部的输送项，该项不依赖于局部梯度，而是依赖于整个边界层的状态（如边界层高度 $h$、地表通量等）。通过在架构中强制执行守恒定律（例如，确保非局部项在垂[直积](@entry_id:143046)分后对总热量没有净贡献）和边界条件（例如，在边界层顶部满足卷夹通量关系 $F_e = -\Delta \theta \frac{dh}{dt}$），所学习的[参数化](@entry_id:265163)方案能够生成真实的通量廓线，包括逆梯度的内部输送，同时保持物理的严谨性。

#### 地表层通量

地表层是[大气边界层](@entry_id:1121182)的最底层，这里的[湍流通量](@entry_id:1133513)直接控制着地表与大气之间的动量、热量和水分交换。[Monin-Obukhov相似性理论](@entry_id:1128126)（MOST）是描述[地表层](@entry_id:1132680)通量-梯度关系的基石。该理论指出，在无量纲化后，平均风、温度和湿度的垂直梯度是稳定度参数 $\zeta = z/L$ 的普适函数，其中 $L$ 是[Monin-Obukhov长度](@entry_id:1128125)，它表征了[浮力](@entry_id:154088)生成和剪切生成[湍流](@entry_id:151300)的相对重要性。传统的[参数化](@entry_id:265163)方案依赖于经验拟合的普适函数形式（$\phi_m(\zeta)$ 和 $\phi_h(\zeta)$）。

深度学习提供了一种从数据中直接学习这些关系而无需预先指定函数形式的方法。通过构建无量纲化的输入特征（例如，使用稳定度参数 $\zeta$ 或[梯度理查森数](@entry_id:276161) $Ri_g$），并将目标（如无量纲梯度）进行适当的尺度化，神经网络可以学习从稳定度到[湍流](@entry_id:151300)输送效率的复杂依赖关系。更重要的是，可以通过在损失函数中加入物理约束来增强模型的泛化能力，例如，强制模型在趋于中性条件时（$\zeta \to 0$）恢[复对数](@entry_id:174857)律剖面（即 $\phi_m(0)=1, \phi_h(0)=1$），并确保其在稳定和不稳定条件下的响应是单调的。这种方法不仅能够复现经典的MOST关系，还可能从高保真度数据中发现新的、更精细的依赖性，同时保持了物理框架的完整性。

#### 云微物理过程

云的形成和降水涉及到水汽、云滴、雨滴、冰晶等多种[水凝物](@entry_id:1126277)之间的复杂相变和相互作用，这些被称为云微物理过程。例如，云滴通过自身碰撞合并形成雨滴的过程称为“[自动转化](@entry_id:1121257)”（autoconversion），而雨滴下落过程中碰并云滴而增长的过程称为“[碰并](@entry_id:1122642)”（accretion）。这些过程的[参数化](@entry_id:265163)对准确预报降水至关重要。一个关键的挑战是确保[参数化](@entry_id:265163)方案在离散的时间步长内严格遵守物理守恒定律。

设计一个用于微物理过程的神经网络代理模型时，必须将物理约束硬编码到其架构中。例如，可以通过“反应网络”的框架来保证质量守恒。在这个框架中，每个微物理过程（如自动转化）被表示为一个化学反应式的向量，其元素之和为零。例如，从云水（$q_c$）到雨水（$q_r$）的转化可以表示为 $[0, -1, +1]^T$ 作用于 $[q_v, q_c, q_r]$ 的倾向。模型的更新由一个[化学计量矩阵](@entry_id:275342)和一个由神经网络预测的非负[反应速率](@entry_id:185114)向量的乘积给出，这种结构在数学上保证了总水物质守恒。此外，还必须强制执行“施主限制”（donor limitation），即在一个时间步内从一个物种中移除的质量不能超过其现有质量。最后，模型必须包含一个可微的[饱和度调整](@entry_id:1131227)步骤，确保任何由于冷却或蒸发不足而产生的过饱和水汽都能凝结成云水，从而遵守Clausius-[Clapeyron关系](@entry_id:1122419)。通过这种方式构建的代理模型，其预测在每一步都天然地满足物理定律，而不是仅仅在平均意义上满足。

### 海洋与冰冻圈动力学

深度学习[参数化](@entry_id:265163)的原理同样适用于海洋和冰冻圈。这些领域中的挑战，如模拟海洋[中尺度涡](@entry_id:1127814)旋和海冰的力学行为，也亟需超越传统[参数化](@entry_id:265163)方案的创新方法。

#### 海洋中尺度涡旋

海洋中尺度涡旋（直径约为10-100公里）是海洋中的“天气系统”，它们在全球热量、盐分和生物地球化学物质的输送中扮演着至关重要的角色。由于计算成本的限制，大多数[全球气候模型](@entry_id:1125665)无法直接解析这些涡旋，因此必须对其影响进行[参数化](@entry_id:265163)。Gent-McWilliams（GM）[参数化](@entry_id:265163)是其中最经典和最广泛使用的方案之一。其核心思想是，[中尺度涡](@entry_id:1127814)旋倾向于通过混合等密度面上的水体来释放有效位能，从而使等密度面变得平缓。这一过程是绝热的，即混合沿着等密度面发生，而没有跨等密度面的输送。

为了在深度学习框架中实现这一点，[参数化](@entry_id:265163)的结构必须从设计上就保证[质量守恒](@entry_id:204015)和对密度（或任何被输送的示踪剂）的中性。这可以通过引入一个“伪速度”或“涌流速度” $\mathbf{u}^*$ 来实现，该速度场本身是无辐散的（$\nabla \cdot \mathbf{u}^* = 0$，保证质量守恒），并且其方向与等密度面法向矢量正交（$\mathbf{u}^* \cdot \nabla \rho = 0$，保证绝热性）。神经网络的任务不是去学习这个速度场的所有分量，而是学习控制其大小的单个标量系数——等效的“厚度扩散系数”$K_\theta$。通过将 $K_\theta$ [参数化](@entry_id:265163)为当地海洋状态（如涡动能、层结强度）和模型分辨率的函数，并强制 $K_\theta \ge 0$ 以确保能量耗散，所学习的[参数化](@entry_id:265163)方案能够以一种物理上自洽且具有尺度感知能力的方式模拟涡旋混合效应。

#### 海冰力学

海冰是气候系统中的一个活跃组成部分，其运动和变形由风、洋流和冰内部的力学应力共同决定。在连续介质力学的框架下，海冰的内部[应力与应变率](@entry_id:263123)之间的关系由其“本构关系”或“流变学”来描述。当海冰受到挤压时，会发生破碎、堆积，形成“冰脊”（ridging），这一过程不仅改变了海冰的厚度和密集度分布，也是一个主要的[能量耗散](@entry_id:147406)机制。

为海冰力学开发一个学习型[闭包](@entry_id:148169)方案时，一个不可逾越的底线是动量守恒。根据[牛顿第二定律](@entry_id:274217)，一个封闭或周期性系统[内力](@entry_id:167605)的总和必须为零。在连续介质模型中，[内力](@entry_id:167605)通过应力[张量的散度](@entry_id:191736) $\nabla \cdot \boldsymbol{\sigma}$ 进入[动量方程](@entry_id:197225)。为了在离散的数值模型中保证动量守恒，$\nabla \cdot \boldsymbol{\sigma}$ 必须以“[通量形式](@entry_id:273811)”计算，即通过计算每个单元格边界上的应力通量来实现。这种离散化方式确保了内部作用力在整个计算域上求和时能够精确抵消。因此，一个学习型的[流变学](@entry_id:138671)模型不应直接预测每个网格中心的加速度或力，而应预测[应力张量](@entry_id:148973)本身。此外，为了保证角动量守恒，预测的应力张量 $\boldsymbol{\sigma}$ 必须是对称的。神经网络的输出（例如，等效的粘性系数）可以被构造成[应变率](@entry_id:154778)不变量的函数，以保证客观性（即与坐标系旋转无关），并被约束为正值以确保力学[能量耗散](@entry_id:147406)。只有在这种物理约束的框架下，学习到的[参数化](@entry_id:265163)方案才能在长期模拟中保持稳定和物理真实性。

### 先进方法论与共通主题

除了针对特定物理过程的应用，[深度学习](@entry_id:142022)[参数化](@entry_id:265163)的发展也催生了一系列共通的方法论。这些方法论关注如何设计[网络架构](@entry_id:268981)、如何学习复杂的数学算子，以及如何平衡模型的预测能力与[可解释性](@entry_id:637759)。

#### 物理对称性的架构设计

物理定律通常具有对称性，例如，流体[动力学方程](@entry_id:751029)在水平方向上是平移不变的。这意味着物理过程本身不依赖于其在空间中的绝对位置。一个成功的[参数化](@entry_id:265163)方案应该尊重这种对称性。在设计[神经网络架构](@entry_id:637524)时，可以将这些对称性作为强大的归纳偏置（inductive bias）。例如，在预测一个大气柱的对流倾向时，该倾向不仅取决于该柱内的垂直廓线，还受到周围水平天气模式的影响。处理水平输入的网络模块应该使用二维卷积神经网络（CNN），因为CNN的共享权重结构天然地具有[平移等变性](@entry_id:636340)（translation equivariance），即输入平移会导致输出发生相应平移。相比之下，由于重力的存在，垂直方向是各向异性的，物理过程依赖于绝对高度或气压。因此，处理垂直输入的模块应该使用一维序列模型（如RNN或Transformer），并将垂直坐标作为显式输入，以打破垂直方向的平移对称性。最终，所学习的物理量（如柱积分倾向）应通过一个硬编码的、基于物理定义的积分层（例如，包含密度权重的求和）来计算，而不是让网络从数据中“学习”积分。这种“双塔”架构将不同的物理对称性分别编码到不同的网络组件中，显著提高了模型的泛化能力和物理一致性。[@problem-id:3873762]

#### 用于非局部[闭包](@entry_id:148169)的[算子学习](@entry_id:752958)

许多[物理参数化](@entry_id:1129649)问题，特别是[湍流](@entry_id:151300)[闭包](@entry_id:148169)，本质上是非局部的。[子网](@entry_id:156282)格通量在某一点的值不仅依赖于该点的解析尺度场，还依赖于其邻域乃至整个场的结构。因此，[闭包](@entry_id:148169)方案在数学上应被视为一个“算子”（operator），即一个从函数（解析尺度场）到另一个函数（[子网](@entry_id:156282)格通量场）的映射。这与仅依赖于局部值的“逐点”（pointwise）映射形成对比。

[算子学习](@entry_id:752958)是[深度学习](@entry_id:142022)的一个前沿领域，旨在从数据中学习这种函数到函数的映射。两种主流架构是[傅里叶神经算子](@entry_id:189138)（Fourier Neural Operator, FNO）和[深度算子网络](@entry_id:748262)（[DeepONet](@entry_id:748262)）。
- **FNO** 通过在傅里叶空间中进行卷积来实现全局感受野。它非常适合于具有[平移不变性](@entry_id:195885)、在规则网格上定义的周期性问题（如均匀[湍流](@entry_id:151300)），因为它内置了强大的[傅里叶谱方法](@entry_id:749538)归纳偏置。
- **[DeepONet](@entry_id:748262)** 则将算子近似为一个可分离的低秩形式，其输入是函数在某些“传感器”点上的值，输出可在任意查询点上评估。这使得[DeepONet](@entry_id:748262)与网格无关，非常适合处理非规则几何形状、非结构化网格或数据稀疏的问题。
选择哪种架构取决于问题的内在结构和数据的性质。对于需要捕捉[长程相互作用](@entry_id:140725)的非局部[参数化](@entry_id:265163)，这两种[算子学习](@entry_id:752958)方法都提供了比传统CNN更强大的框架。

#### 可解释性与控制[方程发现](@entry_id:1124591)

在许多应用中，尤其是在[数字孪生](@entry_id:171650)（digital twin）和信息物理系统（cyber-physical systems）等安全关键领域，模型的“可解释性”与预测精度同等重要。一个可解释的模型应具有透明、人类可读的结构，并能与物理上有意义的变量和操作对应起来。与传统的深度学习“黑箱”模型相比，一些方法旨在从数据中直接发现简洁的、符号化的控制方程。

- **稀疏非线性动力学辨识（SINDy）** 是一种代表性方法。它首先构建一个包含候选[非线性](@entry_id:637147)函数（如多项式、[三角函数](@entry_id:178918)等）的庞大库。然后，它通过[稀疏回归](@entry_id:276495)（如[套索回归](@entry_id:141759)[LASSO](@entry_id:751223)）来寻找一个能以最少项的[线性组合](@entry_id:154743)来描述系统动力学的稀疏系数向量。其输出是明确的[微分](@entry_id:158422)方程，例如 $\dot{x} = -0.1x + 2.5y^2$。这种方法强制模型具有“简约性”（parsimony），即用最少的机理来解释数据。
- **[符号回归](@entry_id:140405)（Symbolic Regression）** 则更进一步，它不局限于预定义的函数库，而是通过[演化算法](@entry_id:637616)（如遗传规划）在广阔的数学表达式空间中搜索，以发现能够拟合数据的最佳封[闭式](@entry_id:271343)公式，同时通过[复杂度惩罚](@entry_id:1122726)来鼓励[简约性](@entry_id:141352)。

这两种方法产生的白箱或[灰箱模型](@entry_id:1125766)，其结构清晰，易于物理学家和工程师理解、验证和用于后续的控制设计，与构成复杂但晦涩映射的[深度神经网络](@entry_id:636170)形成鲜明对比。

### 与现有框架和数据源的整合

[深度学习](@entry_id:142022)[参数化](@entry_id:265163)的成功不仅取决于其自身的[算法设计](@entry_id:634229)，还取决于它如何与现有的科学计算生态系统（如数据同化系统）以及其他学科的知识进行整合。

#### 从数据同化中学习

在业务化的天气预报和气候再分析中，数据同化（Data Assimilation, DA）系统通过融合模型预测和不完整的、带噪声的观测来产生对地球系统状态的最佳估计。在这个过程中，会产生两个重要的“残差”量：一个是“创新向量”（innovation），即观测与模型预报在观测空间的差异；另一个是“分析增量”（analysis increment），即同化系统对模型预报的修正量。长期以来，这些残差的系统性偏差被视为模型存在结构性误差的明确信号。

这为学习[模型误差](@entry_id:175815)[参数化](@entry_id:265163)提供了一个绝佳的、无需额外标注的数据来源。分析增量的系统性部分，可以被看作是模型缺失的物理过程（即[闭包](@entry_id:148169)误差）在经过观测算子和卡尔曼增益投影后的一个有噪声的“测量”。因此，我们可以构建一个神经网络来[参数化](@entry_id:265163)这个缺失的物理过程倾向，其训练目标是使其预测的倾向在经过相同的投影后，能够最大程度地匹配观测到的分析增量。这种方法被称为“[在线学习](@entry_id:637955)”，因为它直接利用业务化流程中产生的数据来持续改进模型，构成了机器学习与数据同化之间一个强大的协同回路。

#### 工程与生物学中的类比

深度学习[参数化](@entry_id:265163)背后的物理约束思想具有广泛的普适性，在其他科学和工程领域中也能找到对应。
- 在**工程热物理**中，经典的对流换热关联式（如努塞尔数$\mathrm{Nu}$与雷诺数$\mathrm{Re}$、普朗特数$\mathrm{Pr}$之间的关系）也可以通过物理信息机器学习（PINN）进行增强。通过将[无量纲分析](@entry_id:188181)、[正定性](@entry_id:149643)、[单调性](@entry_id:143760)以及渐近极限行为等物理[约束编码](@entry_id:197822)到模型架构和[损失函数](@entry_id:634569)中，可以从少量高保真数据中学习到比传统关联式更精确、[适用范围](@entry_id:636189)更广的模型，同时避免了纯[黑箱模型](@entry_id:1121697)在物理外推上的失败。
- 在**[计算生物学](@entry_id:146988)**中，蛋白质结构的预测同样受到严格的物理和化学规律约束。例如，物理空间的欧几里得对称性要求模型对全局[旋转和平移](@entry_id:175994)具有[等变性](@entry_id:636671)（`[SE(3)](@entry_id:1131325)-equivariance`）；物理相互作用的[局域性原理](@entry_id:753741)支持在模型中使用[图卷积](@entry_id:190378)或[注意力机制](@entry_id:917648)并限制其感受野；而[立体化学约束](@entry_id:202820)则要求模型必须保持正确的[共价键](@entry_id:146178)长、键角和手性。这些归纳偏置与[地球系统模型](@entry_id:1124096)中使用的守恒律和对称性约束在精神上是完全一致的，它们都是将先验知识注入学习过程以缩小[解空间](@entry_id:200470)、提高泛化能力的关键。
- 在**[数学生物学](@entry_id:268650)**中，图灵（Turing）提出的[反应-扩散系统](@entry_id:136900)是解释[生物形态发生](@entry_id:180145)（如动物斑纹形成）的经典模型。该模型由一组[偏微分](@entry_id:194612)方程描述，其参数（如扩散系数和[反应速率](@entry_id:185114)）往往未知。物理信息神经网络（PINN）为这类“[逆问题](@entry_id:143129)”提供了强大的求解框架。通过将PDE残差、边界条件和初始条件作为损失函数的一部分，PINN能够仅从稀疏、带噪声的观测数据中同时反演出未知的物理参数并拟合出完整的时空动态场。这展示了将控制方程作为强正则化项来指导参数发现的普遍有效性。

### 气候变化外推的挑战

将深度学习[参数化](@entry_id:265163)应用于[气候预测](@entry_id:184747)时，一个最严峻的挑战是“外推”（extrapolation），即模型能否在训练数据中未曾见过的未来气候情景（如全球变暖）下做出可靠的预测。一个仅从历史数据中学习统计模式的黑箱模型，在面对因气候变化而改变的基础物理状态时，很可能会失效。

为了构建能够可靠外推的[参数化](@entry_id:265163)方案，必须超越简单的模式拟合，利用更深层次的物理[不变性](@entry_id:140168)。有两种主要的策略：
1.  **基于无量纲化的不变性**：物理定律通常可以用[无量纲数](@entry_id:260863)来表示，这些表示形式在不同的物理尺度和条件下是普适的。如果能通过白金汉$\Pi$定理等方法，将模型的输入和输出都转化为物理上合理的无量纲形式，那么学习任务就从学习一个依赖于气候参数（如[海表温度](@entry_id:1131347)、温室气体浓度）的函数族，转变为学习一个在无量纲空间中普适的、不依赖于气候参数的单一函数。只要未来气候下的无量纲输入状态仍然落在训练数据所覆盖的无量纲空间范围内，外推问题就转化为了一个更可靠的插值问题。
2.  **基于参数插值的连续性**：另一种策略是，将气候参数（如[海表温度](@entry_id:1131347)$T_s$）作为模型的显式输入。通过在包含不同$T_s$值的多个气候模拟数据集上进行训练，神经网络可以学习到一个关于$T_s$的连续函数族。如果未来气候的$T_s$值位于训练所用$T_s$值的范围之内（即在参数空间中是插值），那么模型就有可能做出合理的预测。在这种情况下，强制执行能量守恒等物理约束尤为重要，因为它能引导模型在[参数空间](@entry_id:178581)中的插值行为更加符合物理规律。

这两种策略都强调了将物理知识与数据驱动方法相结合的重要性，是实现机器学习在气候变化预测中可靠应用的关键途径。

### 结论

本章通过一系列跨越[地球系统科学](@entry_id:175035)及相关领域的应用案例，展示了深度学习在[参数化](@entry_id:265163)发现中的广阔前景和巨大潜力。从[大气对流](@entry_id:1121188)、[海洋涡旋](@entry_id:1129056)到海冰力学，我们看到，通过精心设计能够体现守恒律、对称性和物理约束的[神经网络架构](@entry_id:637524)与学习范式，数据驱动模型能够捕捉到传统[参数化](@entry_id:265163)方案难以刻画的复杂过程。

核心的启示在于，最成功、最可信赖的应用并非将深度学习视为一个替代物理模型的“黑箱”，而是将其作为一个强大的、可与物理原理深度融合的工具。无论是通过[算子学习](@entry_id:752958)捕捉[非局部效应](@entry_id:198046)，通过架构设计编码对称性，还是通过从数据同化残差中学习[模型误差](@entry_id:175815)，这些前沿方法都体现了数据与物理知识的协同。最终，这种协同不仅能提升我们对现有地球系统的模拟能力，也为我们应对未来气候变化的预测挑战提供了更有力的科学武器。