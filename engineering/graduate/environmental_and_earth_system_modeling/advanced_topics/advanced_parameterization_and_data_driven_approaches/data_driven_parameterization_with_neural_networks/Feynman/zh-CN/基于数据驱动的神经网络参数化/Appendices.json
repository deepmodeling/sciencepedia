{
    "hands_on_practices": [
        {
            "introduction": "构建能够跨尺度和物理情景泛化的模型，始于精心设计的输入特征。一种强大的方法是利用量纲分析将物理变量转换为无量纲数，从而使模型能够学习到独立于特定单位或尺度的普适物理关系。这个练习将指导你应用白金汉 $\\Pi$ 定理，从一组与大气对流相关的典型变量中推导出无量纲输入特征，这是构建稳健的物理感知机器学习模型的关键第一步 。",
            "id": "3873146",
            "problem": "您正在使用人工神经网络 (ANN) 设计大气柱模型中的数据驱动对流参数化方案。为了提高跨尺度的泛化能力，您决定将 ANN 的输入限制为从白金汉 $\\Pi$ 定理派生的无量纲特征。考虑以下与稳定分层大气中干对流动力学相关的可测量变量：垂直速度 $w$、绝对温度 $T$、水汽混合比 $q_v$、布伦特-维萨拉频率 $N$ 和水平网格间距 $\\Delta$。假设 $w$ 的量纲是长度每时间， $T$ 的量纲是热力学温度， $q_v$ 是质量之比因此是无量纲的， $N$ 的量纲是时间的倒数，而 $\\Delta$ 的量纲是长度。除了 $N$ 中隐含的量纲外，没有其他量纲常数（例如，重力加速度或参考热力学量）可用于无量纲化。仅使用基本量纲长度 $L$ 、时间 $T_{\\text{dim}}$ 和热力学温度 $\\Theta$，应用白金汉 $\\Pi$ 定理，从 $\\{w, T, q_v, N, \\Delta\\}$ 中构建一个最小的独立无量纲输入特征集。将您的最终答案表示为最简乘幂形式的独立 $\\Pi$ 组的行向量。不要引入额外的参考尺度、经验常数或外部参数。以闭合形式的符号表达式提供特征。不需要四舍五入，答案应为无单位的。",
            "solution": "在进行求解之前，需要对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n-   变量：垂直速度 ($w$)、绝对温度 ($T$)、水汽混合比 ($q_v$)、布伦特-维萨拉频率 ($N$) 和水平网格间距 ($\\Delta$)。\n-   变量数量, $n=5$。\n-   基本量纲：长度 ($L$)、时间 ($T_{dim}$) 和热力学温度 ($\\Theta$)。我们使用 $T_{dim}$ 来表示时间量纲，以避免与温度变量 $T$ 混淆。\n-   变量的量纲：\n    -   $[w] = L T_{dim}^{-1}$\n    -   $[T] = \\Theta$\n    -   $[q_v] = 1$ (无量纲)\n    -   $[N] = T_{dim}^{-1}$\n    -   $[\\Delta] = L$\n-   基本量纲数量, $k=3$。\n-   约束：没有其他量纲常数或参考量可用。\n-   目标：使用白金汉 $\\Pi$ 定理，从给定变量中找到一个最小的独立无量纲组（$\\Pi$ 组）集合。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，提法明确且客观。它提出了一个源于大气物理学的标准量纲分析问题。在干对流动力学的背景下，这些变量及其量纲在物理上是正确的。问题是自洽的，并提供了应用白金汉 $\\Pi$ 定理所需的所有必要信息。不存在矛盾、模糊或事实错误。只使用给定变量的约束是明确的，并且对推导至关重要。\n\n### 步骤 3：结论与行动\n问题有效。将提供完整的解答。\n\n### 解题推导\n白金汉 $\\Pi$ 定理指出，一个涉及 $n$ 个变量的物理上有意义的方程，如果可以用 $k$ 个基本量纲来表示，那么它可以被重写为一个包含 $p = n - r$ 个无量纲参数（$\\Pi_i$）的方程，其中 $r$ 是量纲矩阵的秩。\n\n首先，我们确定变量的数量为 $n=5$，即 $\\{w, T, q_v, N, \\Delta\\}$。\n基本量纲是长度 ($L$)、时间 ($T_{dim}$) 和热力学温度 ($\\Theta$)，因此有 $k=3$ 个量纲。\n\n每个变量的量纲可以表示为基本量纲 $(L, T_{dim}, \\Theta)$ 的指数向量：\n-   $w \\rightarrow (1, -1, 0)$\n-   $T \\rightarrow (0, 0, 1)$\n-   $q_v \\rightarrow (0, 0, 0)$\n-   $N \\rightarrow (0, -1, 0)$\n-   $\\Delta \\rightarrow (1, 0, 0)$\n\n我们将这些向量排列为列来构建量纲矩阵：\n$$ M = \\begin{pmatrix} 1  & 0 & 0 & 0 & 1 \\\\ -1 & 0 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & 0 & 0 \\end{pmatrix} $$\n行分别对应 $L$、$T_{dim}$ 和 $\\Theta$，列对应 $w、T、q_v、N、\\Delta$。\n\n该矩阵的秩 $r$ 是列空间的维数。我们可以找到一个行列式不为零的 $3 \\times 3$ 子矩阵。例如，选择对应 $w$、$T$ 和 $\\Delta$ 的列：\n$$ \\det \\begin{pmatrix} 1 & 0 & 1 \\\\ -1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{pmatrix} = 1(0) - 0(0) + 1(-1) = -1 \\neq 0 $$\n因此，该矩阵的秩为 $r=3$。\n\n独立无量纲组的数量为 $p = n - r = 5 - 3 = 2$。因此，我们必须找到两个独立的 $\\Pi$ 组。\n\n设一个通用的无量纲组 $\\Pi$ 由变量的特定次幂的乘积形成：\n$$ \\Pi = w^{a_1} T^{a_2} q_v^{a_3} N^{a_4} \\Delta^{a_5} $$\n要使 $\\Pi$ 无量纲，其量纲表示必须为 $L^0 T_{dim}^0 \\Theta^0$。\n$$ [\\Pi] = [w]^{a_1} [T]^{a_2} [q_v]^{a_3} [N]^{a_4} [\\Delta]^{a_5} $$\n$$ [\\Pi] = (L T_{dim}^{-1})^{a_1} (\\Theta)^{a_2} (1)^{a_3} (T_{dim}^{-1})^{a_4} (L)^{a_5} $$\n$$ [\\Pi] = L^{a_1+a_5} T_{dim}^{-a_1-a_4} \\Theta^{a_2} $$\n为了满足 $[\\Pi] = L^0 T_{dim}^0 \\Theta^0$，我们必须求解以下线性方程组：\n1.  $a_1 + a_5 = 0$\n2.  $-a_1 - a_4 = 0$\n3.  $a_2 = 0$\n\n第三个方程 $a_2=0$ 是一个直接结果，因为绝对温度 $T$ 是唯一具有热力学温度 $\\Theta$ 量纲的变量。由于没有其他变量或常数可以用来抵消这个量纲，所以 $T$ 不能成为任何无量纲组的一部分。\n\n变量 $q_v$ 已被指定为无量纲。因此，我们可以选择它作为我们的第一个 $\\Pi$ 组。\n$$ \\Pi_1 = q_v $$\n这对应于设置 $a_3=1$ 且所有其他指数为零 ($a_1=a_2=a_4=a_5=0$)，这满足该方程组。\n\n对于第二个 $\\Pi$ 组，我们必须找到该方程组的第二个独立解。我们寻求剩余量纲变量 $\\{w, N, \\Delta\\}$ 的一个组合。该方程组简化为：\n1.  $a_1 + a_5 = 0$\n2.  $-a_1 - a_4 = 0$\n\n我们有两个方程和三个未知数 ($a_1, a_4, a_5$)。我们可以选择一个指数并求解其他指数。按照惯例，我们选择我们希望进行无量纲化的变量（在此情况下为 $w$）的指数为 $a_1=1$。\n-   将 $a_1=1$ 代入第一个方程：$1 + a_5 = 0 \\implies a_5 = -1$。\n-   将 $a_1=1$ 代入第二个方程：$-1 - a_4 = 0 \\implies a_4 = -1$。\n该组的指数为 $a_1=1$, $a_2=0$, $a_3=0$, $a_4=-1$, $a_5=-1$。\n这给出了第二个无量纲组：\n$$ \\Pi_2 = w^{1} T^{0} q_v^{0} N^{-1} \\Delta^{-1} = \\frac{w}{N\\Delta} $$\n该组在物理上是有意义的，代表一个无量纲速度，类似于分层流体环境中的弗劳德数 (Froude number)。\n\n这两个独立的无量纲组，以其最简乘幂形式表示，是 $\\Pi_1=q_v$ 和 $\\Pi_2=\\frac{w}{N\\Delta}$。问题要求将答案表示为行向量。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} q_v  & \\frac{w}{N\\Delta} \\end{pmatrix} } $$"
        },
        {
            "introduction": "神经网络的原始输出是无约束的实数，但许多物理量（如扩散系数或混合比）必须遵守严格的物理边界，例如非负性或介于 $0$ 和 $1$ 之间的范围。在网络架构层面直接“通过设计”强制施加这些约束，对于保证模型的稳定性和物理真实性至关重要。在此练习中，你将评估和比较多种策略，学习如何将神经网络的无约束输出映射为物理上合理的涡流扩散系数 $K$ 和混合系数 $\\alpha$，并分析不同激活函数在确保物理约束、维持数值稳定性和实现高效梯度学习等方面的优劣权衡 。",
            "id": "3873105",
            "problem": "在环境大气环流模型中，一个标量示踪剂 $\\theta(\\mathbf{x}, t)$ 在平流和次网格扩散的作用下演变，其方程为 $\\,\\partial_t \\theta = \\nabla \\cdot \\left(K(\\mathbf{x}, t)\\,\\nabla \\theta\\right) + S(\\mathbf{x}, t)\\,$，其中 $\\,K(\\mathbf{x}, t)\\,$ 是涡动扩散系数，$\\,S(\\mathbf{x}, t)\\,$ 是一个源项。Fickian 扩散意味着通量为 $\\,\\mathbf{J} = -\\,K\\,\\nabla \\theta\\,$。抛物线算子的适定性和热力学第二定律要求 $\\,K \\ge 0\\,$，以避免反扩散行为。在许多闭合方案中，一个分数混合或夹带系数 $\\,\\alpha(\\mathbf{x}, t)\\,$ 将两个倾向项 $\\,T_1(\\mathbf{x}, t)\\,$ 和 $\\,T_2(\\mathbf{x}, t)\\,$ 组合为 $\\,T = \\alpha\\,T_1 + (1-\\alpha)\\,T_2\\,$。物理上的可容许性要求 $\\,\\alpha \\in [0, 1]\\,$ 以确保凸性和稳定性。\n\n假设一个人工神经网络 (ANN) 产生无约束的预激活值 $\\,z_K \\in \\mathbb{R}\\,$ 和 $\\,z_\\alpha \\in \\mathbb{R}\\,$，分别用于参数化 $\\,K\\,$ 和 $\\,\\alpha\\,$。该设计必须将 $\\,z_K\\,$ 和 $\\,z_\\alpha\\,$ 映射到物理上允许的范围内，同时平衡优化和数值上的考量。具体来说，该设计应：\n- 强制 $\\,K \\ge 0\\,$ 和 $\\,\\alpha \\in [0,1]\\,$，\n- 避免生成可能在时间积分中引入数值刚度的极大 $\\,K\\,$ 值，\n- 在 $\\,z_K\\,$ 和 $\\,z_\\alpha\\,$ 的典型范围内减少梯度饱和，以支持稳定的训练，\n- 保持基于梯度的学习所需的可微性。\n\n设 $\\,\\sigma(u) = \\frac{1}{1 + e^{-u}}\\,$ 表示 logistic sigmoid 函数，$\\,\\operatorname{softplus}(u) = \\log\\!\\big(1 + e^{u}\\big)\\,$ 表示 softplus 函数。考虑以下候选参数化方案及其相关的权衡。选择最能满足上述所有四个设计目标的选项。\n\nA. $\\,K = \\exp(z_K)\\,$ 且 $\\,\\alpha = \\sigma(z_\\alpha)\\,$。这保证了 $\\,K \\ge 0\\,$ 和 $\\,\\alpha \\in [0, 1]\\,$。然而，对于类高斯分布的 $\\,z_K\\,$，$\\,K\\,$ 会近似呈对数正态分布，可能产生重尾和非常大的 $\\,K\\,$ 值。梯度 $\\,\\partial K / \\partial z_K = \\exp(z_K)\\,$ 和 $\\,\\partial \\alpha / \\partial z_\\alpha = \\sigma(z_\\alpha)\\,\\big(1 - \\sigma(z_\\alpha)\\big)\\,$ 在 $\\,|z_\\alpha|\\,$ 较大时会饱和，在 $\\,z_K\\,$ 为大的正数时会爆炸。\n\nB. $\\,K = \\operatorname{softplus}(z_K) + K_{\\min}\\,$（其中 $\\,K_{\\min} > 0\\,$）且 $\\,\\alpha = \\operatorname{clip}(z_\\alpha, 0, 1)\\,$，其中 $\\,\\operatorname{clip}\\,$ 将值硬性限制在区间 $[0,1]$ 内。这强制了 $\\,K \\ge K_{\\min} > 0\\,$ 和 $\\,\\alpha \\in [0, 1]\\,$。softplus 函数的增长比指数函数温和，但截断操作使得在 $[0,1]$ 区间外 $\\,\\partial \\alpha / \\partial z_\\alpha = 0\\,$，并且在边界处无定义，这会破坏基于梯度的学习并可能使训练产生偏差。\n\nC. $\\,K = \\exp(z_K) + K_{\\min}\\,$（其中 $\\,K_{\\min} > 0\\,$）且 $\\,\\alpha = \\tanh(z_\\alpha)\\,$。虽然 $\\,K \\ge K_{\\min} > 0\\,$ 成立，但 $\\,\\alpha = \\tanh(z_\\alpha) \\in (-1, 1)\\,$ 并不保证 $\\,\\alpha \\in [0, 1]\\,$，因此违反了凸性混合的要求，除非引入一个额外的到 $[0,1]$ 的仿射映射，而这里没有。\n\nD. $\\,K = \\epsilon + \\operatorname{softplus}(z_K)\\,$（其中 $\\,\\epsilon > 0\\,$ 为小值）且 $\\,\\alpha = \\sigma\\!\\big(z_\\alpha / \\tau\\big)\\,$（其中温度参数 $\\,\\tau > 0\\,$ 与 ANN 联合学习）。这强制了 $\\,K \\ge \\epsilon > 0\\,$ 和 $\\,\\alpha \\in [0, 1]\\,$。对于大的正 $\\,z_K\\,$，softplus 函数产生近线性的增长，相对于 $\\,\\exp\\,$ 减轻了极端的 $\\,K\\,$ 值和刚度问题，同时保持了平滑的梯度 $\\,\\partial K / \\partial z_K = \\sigma(z_K)\\,$。一个可学习的 $\\,\\tau\\,$ 控制 sigmoid 函数的锐度，以在典型的 $\\,z_\\alpha\\,$ 范围内减少饱和，从而改善优化。",
            "solution": "该问题要求从无约束的神经网络输出 $z_K \\in \\mathbb{R}$ 和 $z_\\alpha \\in \\mathbb{R}$ 中，为涡动扩散系数 $K$ 和混合系数 $\\alpha$ 选择最佳的参数化方案。选择必须基于四个设计目标：\n1.  **物理可容许性**：强制约束 $K \\ge 0$ 和 $\\alpha \\in [0, 1]$。\n2.  **数值稳定性**：避免可能导致数值刚度的极大 $K$ 值。\n3.  **优化稳定性**：减少梯度饱和或爆炸，以促进稳定的训练。\n4.  **可微性**：确保参数化函数对于基于梯度的优化方法是可微的。\n\n让我们根据这四个标准来分析每个选项。\n\n### 逐项分析\n\n**A. $\\,K = \\exp(z_K)\\,$ 且 $\\,\\alpha = \\sigma(z_\\alpha)\\,$**\n\n1.  **物理可容许性**：\n    -   对于任何 $z_K \\in \\mathbb{R}$，$K = \\exp(z_K)$ 始终在 $(0, \\infty)$ 范围内，因此满足条件 $K \\ge 0$。\n    -   logistic sigmoid 函数 $\\sigma(z_\\alpha) = \\frac{1}{1 + e^{-z_\\alpha}}$ 将任何 $z_\\alpha \\in \\mathbb{R}$ 映射到开区间 $(0, 1)$。这个范围是所需闭区间 $[0, 1]$ 的子集，因此满足条件 $\\alpha \\in [0, 1]$。\n    -   此选项在物理上是可容许的。\n\n2.  **数值稳定性**：\n    -   指数函数 $\\exp(z_K)$ 对正的 $z_K$ 增长极快。即使是神经网络输出的中等大小的 $z_K$ 值，也可能导致 $K$ 值大得惊人。例如，如果 $z_K = 10$，$K \\approx 2.2 \\times 10^4$。如此大的扩散系数值会显著减小显式时间积分方案的稳定时间步长（$\\Delta t \\propto 1/K$），导致严重的数值刚度问题。这未能满足第二个设计目标。\n\n3.  **优化稳定性**：\n    -   $K$ 的梯度是 $\\frac{\\partial K}{\\partial z_K} = \\frac{\\partial}{\\partial z_K} \\exp(z_K) = \\exp(z_K)$。对于大的正 $z_K$，该梯度会变得非常大，导致训练过程中的“梯度爆炸”问题。\n    -   $\\alpha$ 的梯度是 $\\frac{\\partial \\alpha}{\\partial z_\\alpha} = \\sigma(z_\\alpha)(1 - \\sigma(z_\\alpha))$。对于大的 $|z_\\alpha|$，该梯度趋近于 $0$，这是 sigmoid 函数众所周知的“梯度消失”或“梯度饱和”问题，会阻碍学习。\n    -   此选项带来了显著的优化挑战。\n\n4.  **可微性**：\n    -   $\\exp(u)$ 和 $\\sigma(u)$ 都是无限可微（$C^\\infty$）函数。此标准得到满足。\n\n*对 A 的裁定*：**不正确**。虽然在物理上可容许且可微，但这种参数化方案容易因大的 $K$ 值而产生数值不稳定性，并因梯度爆炸和梯度消失而产生优化不稳定性。\n\n**B. $\\,K = \\operatorname{softplus}(z_K) + K_{\\min}\\,$（其中 $\\,K_{\\min} > 0\\,$）且 $\\,\\alpha = \\operatorname{clip}(z_\\alpha, 0, 1)\\,$**\n\n1.  **物理可容许性**：\n    -   softplus 函数 $\\operatorname{softplus}(u) = \\log(1+e^u)$ 将 $\\mathbb{R}$ 映射到 $(0, \\infty)$。加上一个正常数 $K_{\\min} > 0$，使得 $K = \\operatorname{softplus}(z_K) + K_{\\min}$ 始终大于 $K_{\\min}$，因此 $K \\ge 0$ 得到满足。\n    -   $\\operatorname{clip}(u, 0, 1)$ 函数根据定义将其输出限制在闭区间 $[0, 1]$ 内。因此，$\\alpha \\in [0, 1]$ 得到满足。\n    -   此选项在物理上是可容许的。\n\n2.  **数值稳定性**：\n    -   对于大的正 $u$，$\\operatorname{softplus}(u) \\approx u$。因此，$K$ 随 $z_K$ 线性增长，而非指数增长。这是一种比选项 A 中受控得多的行为，并大大降低了生成极大 $K$ 值的风险，从而提高了数值稳定性。\n\n3.  **优化稳定性**：\n    -   $K$ 的梯度是 $\\frac{\\partial K}{\\partial z_K} = \\frac{\\partial}{\\partial z_K} \\log(1+e^{z_K}) = \\frac{e^{z_K}}{1+e^{z_K}} = \\sigma(z_K)$。该梯度被限制在 $(0, 1)$ 内，防止了 $K$ 参数化中的梯度爆炸和梯度消失问题。这对优化非常有利。\n    -   然而，$\\alpha$ 的梯度存在问题。$\\operatorname{clip}(z_\\alpha, 0, 1)$ 关于 $z_\\alpha$ 的梯度在 $z_\\alpha  0$ 和 $z_\\alpha  1$ 时为 $0$。如果网络输出 $z_\\alpha$ 落入这些区域，梯度信息将无法回传到网络，负责此输出的权重也无法更新。这个“死梯度”问题严重损害了学习。\n\n4.  **可微性**：\n    -   clip 函数在点 $z_\\alpha = 0$ 和 $z_\\alpha = 1$ 处不可微。在这些点上缺少明确定义的梯度，违反了许多基于梯度的优化器对可微性的要求。\n\n*对 B 的裁定*：**不正确**。使用 `clip` 函数引入了不可微性，并在目标区间外导致了灾难性的梯度饱和（梯度为零），使其不适合于稳健的基于梯度的学习。\n\n**C. $\\,K = \\exp(z_K) + K_{\\min}\\,$（其中 $\\,K_{\\min}  0\\,$）且 $\\,\\alpha = \\tanh(z_\\alpha)\\,$**\n\n1.  **物理可容许性**：\n    -   对于 $K$，在 $\\exp(z_K)$ 上加上 $K_{\\min}0$ 确保了 $K  K_{\\min}  0$。条件 $K \\ge 0$ 得到满足。\n    -   双曲正切函数 $\\tanh(z_\\alpha)$ 的值域是 $(-1, 1)$。该范围并未包含在物理上要求的区间 $[0, 1]$ 内。对于凸性混合方案，$\\alpha$ 的负值在物理上是无效的。\n    -   此选项在 $\\alpha$ 的物理可容许性测试上严重失败。\n\n2.  **数值稳定性**：\n    -   使用 $\\exp(z_K)$，因此存在与选项 A 相同的数值刚度问题。\n\n3.  **优化稳定性**：\n    -   使用 $\\exp(z_K)$，因此具有与选项 A 相同的梯度爆炸可能性。$\\tanh(z_\\alpha)$ 的梯度是 $1 - \\tanh^2(z_\\alpha)$，它在 $|z_\\alpha|$ 较大时会饱和，类似于 sigmoid 函数。\n\n4.  **可微性**：\n    -   $\\exp(u)$ 和 $\\tanh(u)$ 都是 $C^\\infty$ 函数。\n\n*对 C 的裁定*：**不正确**。此选项根本上是无效的，因为它不能保证物理约束 $\\alpha \\in [0, 1]$。\n\n**D. $\\,K = \\epsilon + \\operatorname{softplus}(z_K)\\,$（其中 $\\,\\epsilon  0\\,$ 为小值）且 $\\,\\alpha = \\sigma\\!\\big(z_\\alpha / \\tau\\big)\\,$（其中温度参数 $\\,\\tau  0\\,$）**\n\n1.  **物理可容许性**：\n    -   如选项 B 的分析所证，函数 $\\epsilon + \\operatorname{softplus}(z_K)$ 确保了 $K  \\epsilon  0$，因此满足 $K \\ge 0$。\n    -   如选项 A 的分析所证，sigmoid 函数 $\\sigma(\\cdot)$ 确保其输出在 $(0, 1)$ 内，因此满足 $\\alpha \\in [0, 1]$。\n    -   此选项在物理上是可容许的。\n\n2.  **数值稳定性**：\n    -   与选项 B 一样，使用 $\\operatorname{softplus}(z_K)$ 确保了对于大的正 $z_K$，$K$ 呈近线性增长。这有效地减轻了极大 $K$ 值和相关数值刚度的风险，满足了第二个设计目标。\n\n3.  **优化稳定性**：\n    -   $K$ 的梯度是 $\\frac{\\partial K}{\\partial z_K} = \\sigma(z_K)$，它被限制在 $(0, 1)$ 内，并提供了出色的优化稳定性。\n    -   $\\alpha$ 的梯度是 $\\frac{\\partial \\alpha}{\\partial z_\\alpha} = \\frac{1}{\\tau} \\sigma(z_\\alpha / \\tau)(1 - \\sigma(z_\\alpha / \\tau))$。温度参数 $\\tau$ 对 sigmoid 的输入进行缩放。较大的 $\\tau$ 会“拉伸”函数，使从 $0$ 到 $1$ 的过渡更加平缓。这种对活动区域（梯度非可忽略的区域）的拓宽有助于在更宽的 $z_\\alpha$ 值范围内防止梯度饱和。将 $\\tau$ 设为可学习的参数，允许模型在训练期间动态调整过渡的锐度以找到最佳平衡。这直接解决了梯度饱和问题。\n    -   此选项为两个参数的优化稳定性提供了一个稳健的解决方案。\n\n4.  **可微性**：\n    -   $\\operatorname{softplus}(u)$ 和 $\\sigma(u)$ 都是 $C^\\infty$ 函数。整个参数化方案是平滑且可微的。\n\n*对 D 的裁定*：**正确**。此选项成功地满足了所有四个设计目标。它使用平滑、可微的函数来确保物理约束。它通过对 $K$ 使用 softplus 函数来防止数值刚度。它通过对 $K$ 使用有界梯度的 softplus 和对 $\\alpha$ 使用温度缩放的 sigmoid 来减轻梯度饱和，从而促进了稳定的优化。\n\n### 结论\n\n比较四个选项，选项 D 无疑是最佳的。它在神经网络的背景下，采用现代、先进的技术来参数化有物理约束的变量，以一种有原则的方式解决了所有指定的设计挑战。选项 A、B 和 C 各自至少有一个关键缺陷，使它们不适用。",
            "answer": "$$\\boxed{D}$$"
        },
        {
            "introduction": "在施加了对单个变量的边界约束之后，下一步是处理控制多个输出之间关系的系统级物理定律，例如能量守恒或质量守恒。在本练习中，你将聚焦于地表能量平衡这一基本守恒定律：$R_{n} = H + LE + G$。你将探索和比较多种在训练过程中强制执行该定律的先进方法，从简单的软惩罚项到硬性的架构约束，以确保你的神经网络对感热、潜热和地表热通量的预测严格遵守能量守恒 。",
            "id": "3873150",
            "problem": "您正在使用神经网络 $f_{\\theta}$ 训练一个数据驱动的参数化方案，以根据气象特征 $x \\in \\mathbb{R}^{p}$ 和地表状态变量来预测地表感热通量 $H$、潜热通量 $LE$ 和地热通量 $G$。训练数据提供了净辐射 $R_{n}$ 以及通量 $H, LE, G$，根据地表能量守恒定律，地表能量平衡闭合关系成立：$R_{n} = H + LE + G$。目标是确保学习到的模型在训练和推理过程中不违反此能量收支平衡，同时与带噪声的观测数据和可微优化方法保持一致。\n\n利用能量守恒基本物理定律 $R_{n} = H + LE + G$ 和标准的约束优化原理，选择所有正确指定了约束设计并描述了在 $f_{\\theta}$ 训练期间强制执行该约束的有效方法的选项：\n\nA. 通过向数据拟合目标中添加一个二次的能量收支违反惩罚项来引入软约束。对于预测值 $(\\hat{H}, \\hat{LE}, \\hat{G}) = f_{\\theta}(x)$，最小化损失函数\n$$\n\\mathcal{L}(\\theta) = \\frac{1}{N}\\sum_{i=1}^{N}\\left[\\left(\\hat{H}_{i}-H_{i}\\right)^{2}+\\left(\\hat{LE}_{i}-LE_{i}\\right)^{2}+\\left(\\hat{G}_{i}-G_{i}\\right)^{2}\\right] + \\lambda\\,\\frac{1}{N}\\sum_{i=1}^{N}\\left(R_{n,i}-\\hat{H}_{i}-\\hat{LE}_{i}-\\hat{G}_{i}\\right)^{2},\n$$\n其中 $\\lambda0$ 平衡了数据拟合和能量收支闭合，并通过随机梯度下降 (SGD) 优化 $\\theta$。这鼓励模型在期望上满足能量收支，同时允许测量噪声的存在。\n\nB. 通过重参数化输出，将其限制在由能量收支定义的仿射子空间上，从而施加硬约束。让网络产生一个无约束的向量 $\\tilde{y}_{i} = [\\tilde{H}_{i},\\tilde{LE}_{i},\\tilde{G}_{i}]^{\\top}$，并定义有约束的预测\n$$\n\\begin{aligned}\ny_{i} = [\\hat{H}_{i},\\hat{LE}_{i},\\hat{G}_{i}]^{\\top} \\\\\n= \\tilde{y}_{i} - \\frac{1}{3}\\left(\\mathbf{1}^{\\top}\\tilde{y}_{i}-R_{n,i}\\right)\\mathbf{1}, \\quad \\text{其中 } \\mathbf{1} = [1,1,1]^{\\top}.\n\\end{aligned}\n$$\n通过使用 SGD 最小化 $y_{i}$ 和 $[H_{i},LE_{i},G_{i}]^{\\top}$ 之间的均方误差 (MSE) 进行训练。这保证了在每次前向传播中，$R_{n,i} = \\hat{H}_{i}+\\hat{LE}_{i}+\\hat{G}_{i}$ 都精确成立。\n\nC. 使用增广拉格朗日 (AL) 方法将问题表述为等式约束学习。定义约束 $c_{i}(\\theta) = R_{n,i} - \\hat{H}_{i} - \\hat{LE}_{i} - \\hat{G}_{i} = 0$ 和增广拉格朗日函数\n$$\n\\mathcal{L}_{\\text{AL}}(\\theta,\\mu) = \\frac{1}{N}\\sum_{i=1}^{N}\\left[\\left(\\hat{H}_{i}-H_{i}\\right)^{2}+\\left(\\hat{LE}_{i}-LE_{i}\\right)^{2}+\\left(\\hat{G}_{i}-G_{i}\\right)^{2}\\right] + \\frac{1}{N}\\sum_{i=1}^{N}\\left[\\mu\\,c_{i}(\\theta) + \\frac{\\rho}{2}\\,c_{i}(\\theta)^{2}\\right],\n$$\n其中 $\\mu$ 是对偶变量，$\\rho0$ 是惩罚参数。交替进行对 $\\theta$ 的梯度步骤以减小 $\\mathcal{L}_{\\text{AL}}$，并更新 $\\mu \\leftarrow \\mu + \\rho\\,\\frac{1}{N}\\sum_{i=1}^{N}c_{i}(\\theta)$，直到约束残差 $\\{c_{i}\\}$ 消失。\n\nD. 仅在训练后应用事后重缩放，在验证集上将 $(\\hat{H},\\hat{LE},\\hat{G})$ 替换为 $R_{n}\\cdot(\\hat{H},\\hat{LE},\\hat{G})/\\left(\\hat{H}+\\hat{LE}+\\hat{G}\\right)$。这强制执行了能量收支平衡，但没有改变训练目标或梯度，因此保留了学习到的参数。\n\nE. 在输出层插入批量归一化 (Batch Normalization)，以在小批量 (mini-batch) 内对 $(\\hat{H},\\hat{LE},\\hat{G})$ 进行归一化。因为归一化改变了输出的尺度，其总和将在期望上匹配 $R_{n}$，从而在训练期间强制执行能量收支。\n\n选择所有适用项。",
            "solution": "### 第 1 步：提取已知条件\n- 神经网络模型：$f_{\\theta}$\n- 模型输入：气象特征 $x \\in \\mathbb{R}^{p}$ 和地表状态变量。\n- 模型输出（预测值）：地表感热通量 $\\hat{H}$、潜热通量 $\\hat{LE}$ 和地热通量 $\\hat{G}$。\n- 训练数据提供：净辐射 $R_{n}$ 和观测到的通量 $H, LE, G$。\n- 物理定律（约束）：地表能量平衡闭合，即 $R_{n} = H + LE + G$。此关系对数据成立。\n- 目标：确保学习到的模型的预测值在训练和推理过程中满足能量收支平衡，即 $\\hat{H} + \\hat{LE} + \\hat{G} = R_{n}$。\n- 方法论约束：解决方案必须与带噪声的观测数据兼容，并适用于可微优化（例如，使用随机梯度下降，SGD）。\n- 问题：选择所有正确指定了约束设计并在训练期间强制执行该约束的有效方法的选项。\n\n### 第 2 步：使用提取的已知条件进行验证\n- **科学依据：** 该问题基于应用于地球表面的能量守恒原理，这是环境物理学和气候科学的基石。方程 $R_{n} = H + LE + G$ 是地表能量平衡的标准表示。将此类物理定律嵌入机器学习模型的任务是物理信息机器学习中一个关键且活跃的研究领域。该问题在科学上是合理的。\n- **良态性 (Well-Posed)：** 问题定义清晰。它提出了一个特定的、可形式化的线性等式约束（$\\hat{H} + \\hat{LE} + \\hat{G} = R_{n}$），该约束需要施加在神经网络的输出上。它要求在梯度优化背景下评估实现这一目标的标准方法。这种结构允许对所提出的技术进行唯一且有意义的分析。\n- **客观性：** 问题陈述使用精确的数学和技术语言表达，没有歧义或主观论断。所有变量和目标都已明确定义。\n\n### 第 3 步：结论与行动\n问题陈述是有效的。它具有科学依据，是良态的、客观的，并且描述了数据驱动的地球系统建模中的一个现实挑战。我将继续分析每个选项。\n\n### 基于原理的推导和选项分析\n核心任务是在训练一个预测 $(\\hat{H}_i, \\hat{LE}_i, \\hat{G}_i) = f_{\\theta}(x_i)$ 的神经网络 $f_{\\theta}$ 的过程中，对每个数据样本 $i$ 强制执行线性等式约束 $\\hat{H}_i + \\hat{LE}_i + \\hat{G}_i = R_{n,i}$。这些方法必须与基于梯度的优化兼容。\n\n**A. 通过向数据拟合目标中添加一个二次的能量收支违反惩罚项来引入软约束……**\n此选项提出了一种惩罚方法，这是约束优化中的一种经典技术。损失函数由两项组成：一个数据拟合项（均方误差，MSE）和一个约束违反项。\n$$\n\\mathcal{L}(\\theta) = \\underbrace{\\frac{1}{N}\\sum_{i=1}^{N}\\left[\\left(\\hat{H}_{i}-H_{i}\\right)^{2}+\\left(\\hat{LE}_{i}-LE_{i}\\right)^{2}+\\left(\\hat{G}_{i}-G_{i}\\right)^{2}\\right]}_{\\text{数据拟合 (MSE)}} + \\underbrace{\\lambda\\,\\frac{1}{N}\\sum_{i=1}^{N}\\left(R_{n,i}-\\hat{H}_{i}-\\hat{LE}_{i}-\\hat{G}_{i}\\right)^{2}}_{\\text{约束惩罚}}\n$$\n只要 $f_{\\theta}$ 是可微的，这个复合损失函数对模型参数 $\\theta$ 就是可微的。因此，可以使用 SGD 或其变体进行优化。超参数 $\\lambda  0$ 控制惩罚的强度。较大的 $\\lambda$ 会迫使模型优先满足能量收支。这种方法不保证每个预测都精确满足约束，但它“鼓励”模型学习接近约束曲面的解。在处理噪声数据时，这种灵活性可能是有利的，因为在这些数据中，能量收支可能无法完美闭合。所给的描述准确地刻画了这种方法的行为和效用。\n**结论：正确**\n\n**B. 通过重参数化输出，将其限制在由能量收支定义的仿射子空间上，从而施加硬约束……**\n此选项描述了一种通过架构设计来强制执行约束的方法。网络首先产生一个无约束的中间输出 $\\tilde{y}_{i} = [\\tilde{H}_{i},\\tilde{LE}_{i},\\tilde{G}_{i}]^{\\top}$。然后，该向量被正交投影到由约束 $\\hat{H}_{i}+\\hat{LE}_{i}+\\hat{G}_{i} = R_{n,i}$ 定义的仿射子空间上。提供的公式 $y_{i} = \\tilde{y}_{i} - \\frac{1}{3}\\left(\\mathbf{1}^{\\top}\\tilde{y}_{i}-R_{n,i}\\right)\\mathbf{1}$ 正是该投影的公式。我们来验证一下：\n最终输出 $y_i$ 的分量之和为：\n$$\n\\mathbf{1}^{\\top}y_{i} = \\mathbf{1}^{\\top}\\left( \\tilde{y}_{i} - \\frac{1}{3}\\left(\\mathbf{1}^{\\top}\\tilde{y}_{i}-R_{n,i}\\right)\\mathbf{1} \\right)\n$$\n$$\n= \\mathbf{1}^{\\top}\\tilde{y}_{i} - \\frac{1}{3}\\left(\\mathbf{1}^{\\top}\\tilde{y}_{i}-R_{n,i}\\right)(\\mathbf{1}^{\\top}\\mathbf{1})\n$$\n由于 $\\mathbf{1} = [1,1,1]^{\\top}$，所以 $\\mathbf{1}^{\\top}\\mathbf{1} = 1^2 + 1^2 + 1^2 = 3$。\n$$\n= \\mathbf{1}^{\\top}\\tilde{y}_{i} - \\frac{1}{3}\\left(\\mathbf{1}^{\\top}\\tilde{y}_{i}-R_{n,i}\\right)(3)\n$$\n$$\n= \\mathbf{1}^{\\top}\\tilde{y}_{i} - \\left(\\mathbf{1}^{\\top}\\tilde{y}_{i}-R_{n,i}\\right) = R_{n,i}\n$$\n对于任何 $\\tilde{y}_{i}$，约束都精确满足。该投影是一个可微操作，因此从输入 $x_i$ 到最终有约束输出 $y_i$ 的整个模型保持端到端可微。然后可以通过最小化有约束的预测 $y_i$ 与观测到的通量之间的 MSE 来训练模型。如选项所述，此方法强制执行了一个在每次前向传播中都成立的“硬”约束。\n**结论：正确**\n\n**C. 使用增广拉格朗日 (AL) 方法将问题表述为等式约束学习……**\n此选项建议使用增广拉格朗日方法，这是约束优化文献中一种复杂而强大的算法。AL 函数结合了数据拟合目标、一个拉格朗日乘子项和一个二次惩罚项。\n$$\n\\mathcal{L}_{\\text{AL}}(\\theta,\\mu) = \\text{MSE} + \\frac{1}{N}\\sum_{i=1}^{N}\\left[\\mu\\,c_{i}(\\theta) + \\frac{\\rho}{2}\\,c_{i}(\\theta)^{2}\\right]\n$$\n其中 $c_{i}(\\theta) = R_{n,i} - \\hat{H}_{i} - \\hat{LE}_{i} - \\hat{G}_{i}$ 是约束残差。训练过程涉及一个迭代的两步过程：\n1. 对于固定的对偶变量 $\\mu$ 和惩罚参数 $\\rho  0$，关于模型参数 $\\theta$ 最小化 $\\mathcal{L}_{\\text{AL}}$。在深度学习中，这通常通过一定数量的 SGD 步骤完成。\n2. 使用对偶上升步骤更新对偶变量（拉格朗日乘子）：$\\mu \\leftarrow \\mu + \\rho\\,\\langle c_i(\\theta) \\rangle$。\n重复此过程直至收敛。与选项 A 中的简单惩罚方法相比，AL 方法可以实现精确的约束满足，而无需惩罚参数 $\\rho$ 趋于无穷大。所描述的公式和更新规则是此方法的标准和正确形式。这是一种在训练期间强制执行约束的有效且稳健的方法。\n**结论：正确**\n\n**D. 仅在训练后应用事后重缩放……**\n此选项建议在没有任何物理约束的情况下训练模型（即仅最小化 MSE），然后在训练完成后应用校正。校正步骤涉及将预测的通量 $(\\hat{H}, \\hat{LE}, \\hat{G})$ 通过因子 $R_{n}/\\left(\\hat{H}+\\hat{LE}+\\hat{G}\\right)$ 进行重缩放。虽然此过程确实在最终输出上强制执行了能量收支，但它违反了问题陈述的一个关键要求：“确保学习到的模型**在训练期间**不违反此能量收支……”。此方法明确地将训练与约束执行分离开来。模型参数 $\\theta$ 的学习过程没有任何物理约束的指导。这可能导致模型学习到物理上不一致的关系，并且最终的事后校正可能是一个巨大的、扭曲性的调整。由于约束不是*在训练期间*强制执行的，因此该方法不是对所提问题的正确答案。\n**结论：不正确**\n\n**E. 在输出层插入批量归一化……**\n此选项建议在输出层使用批量归一化 (BN) 来强制执行约束。这暴露了对 BN 工作原理的根本误解。BN 是在*一个小批量中的样本之间*，对每个特征独立进行操作的。例如，它将对一个小批量中所有 $\\hat{H}$ 值的向量进行归一化，对所有 $\\hat{LE}$ 值的向量进行归一化，以及对所有 $\\hat{G}$ 值的向量进行归一化，每个都是独立的。它不会对单个样本的特征之间进行操作。标准 BN 算法内部没有机制可以强制执行像 $\\hat{H}_{i}+\\hat{LE}_{i}+\\hat{G}_{i} = R_{n,i}$ 这样的线性关系。关于“其总和将在期望上匹配 $R_{n}$”的说法是没有根据的。BN 归一化的是一个批量中每个特征分布的一阶和二阶矩，这与满足每个单独预测的代数和约束无关。\n**结论：不正确**",
            "answer": "$$\\boxed{ABC}$$"
        }
    ]
}