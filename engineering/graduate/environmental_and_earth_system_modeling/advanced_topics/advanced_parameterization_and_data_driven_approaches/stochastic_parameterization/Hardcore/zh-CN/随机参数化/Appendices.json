{
    "hands_on_practices": [
        {
            "introduction": "Ornstein-Uhlenbeck (O-U) 过程是随机参数化中最核心的构建模块，它描述了一个在随机噪声扰动下向平均状态回归的物理过程。本练习将引导你运用伊藤引理（Itô's lemma）这一关键工具，来解析性地推导出O-U过程的稳态均值和方差，这是理解其长期统计行为和进行参数校准的基础。",
            "id": "3916404",
            "problem": "在一个简化的降阶大气-海洋柱模型中，一个守恒示踪物的未解析次网格倾向由一个线性随机微分方程（SDE）表示，该方程由标准维纳过程驱动，形式为 $dx(t)=-\\lambda\\,x(t)\\,dt+\\sigma\\,dW_t$。其中 $x(t)$ 是随机倾向模拟器，$\\lambda>0$ 是一个恒定的线性弛豫率，$\\sigma>0$ 是一个恒定的噪声振幅，$W_t$ 是一个标准维纳过程。这种表示方法遵循了环境和地球系统建模中广泛使用的随机参数化方案。假设系数是时不变的，且该过程是遍历的。\n\n从期望和方差的定义、标准维纳过程 $W_t$ 的性质以及伊藤积分（包括二次变分）出发，在存在平稳分布的假设下，推导 $x(t)$ 的闭式平稳均值和平稳方差。请用 $\\lambda$ 和 $\\sigma$ 的解析表达式表示你的最终答案。最终表达式无需四舍五入，也无需报告物理单位。",
            "solution": "该问题陈述是随机过程领域中一个有效的、适定的问题，具体涉及奥恩斯坦-乌伦贝克过程，该过程是物理科学中随机建模的基石。所有提供的信息都是一致的，足以进行严格的推导。\n\n该随机过程由线性伊藤随机微分方程（SDE）描述：\n$$dx(t) = -\\lambda\\,x(t)\\,dt + \\sigma\\,dW_t$$\n其中 $\\lambda > 0$ 和 $\\sigma > 0$ 是常数，$W_t$ 是一个标准维纳过程。我们的任务是，在平稳状态存在的假设下，推导 $x(t)$ 在平稳状态下的均值和方差。\n\n**1. 平稳均值的推导**\n\n令 $\\mu(t)$ 表示过程 $x(t)$ 的期望，即 $\\mu(t) = \\mathbb{E}[x(t)]$。我们对整个SDE取期望。根据期望算子的线性性质，我们可以写出：\n$$\\mathbb{E}[dx(t)] = \\mathbb{E}[-\\lambda\\,x(t)\\,dt + \\sigma\\,dW_t]$$\n$$\\mathbb{E}[dx(t)] = -\\lambda\\,\\mathbb{E}[x(t)]\\,dt + \\sigma\\,\\mathbb{E}[dW_t]$$\n假设有足够的正则性可以交换期望和微分算子，我们有 $d\\mathbb{E}[x(t)] = \\mathbb{E}[dx(t)]$。这得到：\n$$d\\mu(t) = -\\lambda\\,\\mu(t)\\,dt + \\sigma\\,\\mathbb{E}[dW_t]$$\n关于标准维纳过程的伊藤积分的一个基本性质是，它是一个均值为零的鞅。增量 $dW_t = W_{t+dt} - W_t$ 是一个随机变量，服从均值为 $0$、方差为 $dt$ 的正态分布。因此，其期望为零：\n$$\\mathbb{E}[dW_t] = 0$$\n将此代入 $d\\mu(t)$ 的方程，得到一个关于均值的确定性常微分方程（ODE）：\n$$d\\mu(t) = -\\lambda\\,\\mu(t)\\,dt$$\n$$\\frac{d\\mu(t)}{dt} = -\\lambda\\,\\mu(t)$$\n在平稳状态下，该过程的统计特性与时间无关。因此，均值必须是一个常数，我们记为 $\\mu_{ss}$。这意味着其时间导数为零：\n$$\\frac{d\\mu_{ss}}{dt} = 0$$\n将此条件代入ODE，得到：\n$$0 = -\\lambda\\,\\mu_{ss}$$\n根据问题陈述中 $\\lambda > 0$ 的条件，唯一可能的解是：\n$$\\mu_{ss} = 0$$\n因此，过程 $x(t)$ 的平稳均值为 $0$。\n\n**2. 平稳方差的推导**\n\n$x(t)$ 的方差定义为 $V(t) = \\text{Var}[x(t)] = \\mathbb{E}[x(t)^2] - (\\mathbb{E}[x(t)])^2$。由于我们关心的是平稳方差 $V_{ss}$，我们可以使用平稳均值 $\\mu_{ss}=0$。该定义简化为：\n$$V_{ss} = \\mathbb{E}_{ss}[x(t)^2]$$\n其中 $\\mathbb{E}_{ss}[\\cdot]$ 表示平稳状态下的期望。我们需要找到平稳二阶矩 $M_{2,ss} = \\mathbb{E}_{ss}[x(t)^2]$。为此，我们推导二阶矩 $\\mathbb{E}[x(t)^2]$ 的动态过程。\n\n我们对函数 $f(x(t)) = x(t)^2$ 应用伊藤引理。对于一个一般的伊藤过程 $dx(t) = a(x,t)dt + b(x,t)dW_t$，伊藤引理表明：\n$$df(x(t)) = \\left( a(x,t)\\frac{\\partial f}{\\partial x} + \\frac{1}{2}b(x,t)^2\\frac{\\partial^2 f}{\\partial x^2} \\right)dt + b(x,t)\\frac{\\partial f}{\\partial x}dW_t$$\n在我们的例子中，漂移系数是 $a(x,t) = -\\lambda x(t)$，扩散系数是 $b(x,t) = \\sigma$。函数 $f(x) = x^2$ 的导数是 $\\frac{\\partial f}{\\partial x} = 2x$ 和 $\\frac{\\partial^2 f}{\\partial x^2} = 2$。包含二阶导数的项源于维纳过程的非零二次变分，其中 $(dW_t)^2 = dt$。\n\n将这些代入伊藤引理：\n$$d(x^2) = \\left( (-\\lambda x)(2x) + \\frac{1}{2}\\sigma^2(2) \\right)dt + \\sigma(2x)dW_t$$\n$$d(x^2) = (-2\\lambda x^2 + \\sigma^2)dt + 2\\sigma x dW_t$$\n现在，我们对该方程取期望，以求得二阶矩 $M_2(t) = \\mathbb{E}[x(t)^2]$ 的动态过程：\n$$\\mathbb{E}[d(x^2)] = \\mathbb{E}[(-2\\lambda x^2 + \\sigma^2)dt + 2\\sigma x dW_t]$$\n$$d\\mathbb{E}[x^2] = (-2\\lambda \\mathbb{E}[x^2] + \\sigma^2)dt + 2\\sigma \\mathbb{E}[x dW_t]$$\n最后一项是伊藤积分的期望。过程 $x(t)$ 适应于由 $W_t$ 生成的筛选，这意味着它是非预期的。伊藤积分的一个关键性质是，对于一个非预期过程，其关于 $dW_t$ 的积分的期望为零。形式上，对于一个合适的非预期过程 $g(s)$，有 $\\mathbb{E}[\\int_0^t g(s)dW_s] = 0$。用微分形式表示，这意味着：\n$$\\mathbb{E}[x(t)dW_t] = 0$$\n这样我们就得到了关于二阶矩 $M_2(t)$ 的以下ODE：\n$$\\frac{dM_2(t)}{dt} = -2\\lambda M_2(t) + \\sigma^2$$\n在平稳状态下，二阶矩是常数 $M_{2,ss}$，因此其时间导数为零：\n$$\\frac{dM_{2,ss}}{dt} = 0$$\n将此代入二阶矩的ODE，得到：\n$$0 = -2\\lambda M_{2,ss} + \\sigma^2$$\n解出 $M_{2,ss}$：\n$$2\\lambda M_{2,ss} = \\sigma^2$$\n$$M_{2,ss} = \\frac{\\sigma^2}{2\\lambda}$$\n如前所述，由于平稳均值为零，平稳方差 $V_{ss}$ 等于平稳二阶矩。\n$$V_{ss} = M_{2,ss} - \\mu_{ss}^2 = \\frac{\\sigma^2}{2\\lambda} - 0^2$$\n因此，平稳方差为：\n$$V_{ss} = \\frac{\\sigma^2}{2\\lambda}$$\n问题要求的是平稳均值和平稳方差。推导出的表达式分别为 $\\mu_{ss} = 0$ 和 $V_{ss} = \\frac{\\sigma^2}{2\\lambda}$。两者都用给定的参数 $\\lambda$ 和 $\\sigma$ 表示。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0  \\frac{\\sigma^2}{2\\lambda}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "理论模型最终需要转化为可执行的数值代码才能应用于地球系统模型中。本练习将理论与实践相结合，要求你为一个简单的一维扩散方程编写一个数值求解器，并对比确定性参数化方案与随机参数化方案的差异。通过该实践，你将亲身体验随机性如何产生集合离散度（ensemble spread），这是随机参数化方案用于表征模型不确定性的核心功能。",
            "id": "3916381",
            "problem": "考虑周期区间 $x \\in [0,1)$ 上一维被动标量场 $u(x,t)$ 的扩散，其受守恒律 $\\partial_t u = -\\partial_x J$ 和菲克定律 (Fick’s law) $J = -K(t)\\partial_x u$ 控制。对于空间均匀但随时间变化的涡流扩散系数 $K(t)$，可得到扩散方程 $u_t = \\partial_x\\left(K(t)\\partial_x u\\right) = K(t)\\,\\partial_{xx}u$。考虑 $K(t)$ 的两种闭合方案：\n- 确定性涡流扩散闭合：$K(t) = \\bar{K}$，一个常数。\n- 随机涡流扩散闭合：$K(t) = \\bar{K} + \\sigma\\,\\xi(t)$，其中 $\\xi(t)$ 是高斯白噪声 (GWN)，在离散时间中建模为每个时间步长上独立同分布的标准正态变量。为确保物理真实性（非负扩散系数），通过截断施加 $K(t) \\ge K_{\\min}$，其中 $K_{\\min}  0$ 是一个小的正常数下界。\n\n从守恒律和菲克定律出发，为周期域推导一个一致的显式时间步进和二阶中心差分空间离散化方案。设 $N_x$ 为空间网格点数，$\\Delta x = 1/N_x$ 为空间步长，$N_t$ 为时间步数，$\\Delta t$ 为时间步长，使得 $t_n = n\\,\\Delta t$ 且 $N_t = T/\\Delta t$ 为整数。使用更新公式\n$$\nu^{n+1}_m = u^{n}_m + \\Delta t\\,K^n_m\\,\\mathcal{L}u^{n}_m,\n$$\n其中 $m$ 是系综成员的索引，$n$ 是时间步的索引，$\\mathcal{L}$ 是离散周期拉普拉斯算子\n$$\n\\left(\\mathcal{L}u\\right)_i = \\frac{u_{i+1} - 2\\,u_i + u_{i-1}}{\\Delta x^2},\n$$\n具有周期性索引 $u_{-1} \\equiv u_{N_x-1}$ 和 $u_{N_x} \\equiv u_0$。\n\n使用初始条件\n$$\nu(x,0) = \\sin\\left(2\\pi x\\right) + \\frac{1}{2}\\sin\\left(4\\pi x\\right),\n$$\n在 $x_i = i\\,\\Delta x$（$i = 0,1,\\dots,N_x-1$）处采样。\n\n定义最终时刻 $T$ 的系综平均值为\n$$\n\\bar{u}(x_i,T) = \\frac{1}{M}\\sum_{m=1}^M u^{(m)}(x_i,T),\n$$\n以及系综方差场为\n$$\n\\mathrm{Var}[u](x_i,T) = \\frac{1}{M}\\sum_{m=1}^M \\left(u^{(m)}(x_i,T) - \\bar{u}(x_i,T)\\right)^2.\n$$\n通过空间平均来量化标量系综方差，\n$$\nV(T) = \\frac{1}{N_x}\\sum_{i=0}^{N_x-1}\\mathrm{Var}[u](x_i,T).\n$$\n对每个测试案例，计算随机闭合与确定性闭合在最终时刻 $T$ 的系综方差之差：\n$$\n\\Delta V = V_{\\mathrm{stoch}}(T) - V_{\\mathrm{det}}(T).\n$$\n注意，对于具有相同系综成员的确定性闭合，$V_{\\mathrm{det}}(T)$ 精确等于 $0$。\n\n数值实现要求：\n- 按照规定，在周期网格上使用显式欧拉法离散化时间，使用二阶中心差分法离散化空间。\n- 将随机涡流扩散闭合建模为 $K^n_m = \\max\\!\\left(K_{\\min},\\,\\bar{K} + \\sigma\\,\\xi^n_m\\right)$，其中对于每个系综成员 $m$ 和时间索引 $n$，$\\xi^n_m \\sim \\mathcal{N}(0,1)$ 是独立的。\n- 使用一个小的正常数下界 $K_{\\min} = 10^{-8}$。\n- 通过选择满足标准显式扩散稳定性条件 $ \\Delta t \\lesssim \\Delta x^2 / \\left(2\\,K_{\\text{max}}\\right)$ 的 $\\Delta t$ 值来确保数值稳定性，其中 $K_{\\text{max}}$ 是模拟过程中 $K(t)$ 的上界。在下面的测试套件中，$\\Delta t$ 是据此选择的。\n\n测试套件：\n- 案例 1：$N_x = 64$，$\\Delta t = 0.0005$， $T = 0.1$， $M = 200$， $\\bar{K} = 0.05$， $\\sigma = 0.01$，随机种子 $= 42$。\n- 案例 2（边界情况，纯确定性）：$N_x = 64$，$\\Delta t = 0.0005$， $T = 0.1$， $M = 200$， $\\bar{K} = 0.05$， $\\sigma = 0$，随机种子 $= 123$。\n- 案例 3（边缘情况，低平均扩散系数和较大噪声，通过截断强制正定性）：$N_x = 128$，$\\Delta t = 0.0003$， $T = 0.06$， $M = 300$， $\\bar{K} = 0.01$， $\\sigma = 0.015$，随机种子 $= 2025$。\n\n你的程序必须：\n- 按规定实现两种闭合方案。\n- 对每个测试案例，计算 $\\Delta V$ 作为浮点数。\n- 生成单行输出，其中包含按测试案例顺序排列的结果，格式为方括号内的逗号分隔列表，并四舍五入到 $6$ 位小数：$[\\Delta V_1,\\Delta V_2,\\Delta V_3]$。",
            "solution": "用户提供了一个科学基础扎实、提法恰当且客观的问题。这是计算流体动力学和地球物理建模领域的一个标准数值练习，重点关注未解析过程的随机参数化概念。所有参数、方程和数值方法都已清晰、正确地指定。该问题是有效的，可以按所述方式解决。\n\n### 基于原理的解决方案设计\n\n该问题要求对周期域 $x \\in [0,1)$ 上的被动标量 $u(x,t)$ 的一维扩散方程进行数值求解。其控制方程源于守恒律 $\\partial_t u = -\\partial_x J$ 和菲克扩散定律 $J = -K(t)\\partial_x u$。对于空间均匀但随时间变化的扩散系数 $K(t)$，方程简化为：\n$$\n\\frac{\\partial u}{\\partial t} = K(t) \\frac{\\partial^2 u}{\\partial x^2}\n$$\n问题比较了涡流扩散系数 $K(t)$ 的两种不同模型或闭合方案：一个简单的确定性模型和一个更复杂的随机模型。\n\n1.  **确定性闭合**：$K(t) = \\bar{K}$，一个恒定的平均扩散系数。\n2.  **随机闭合**：$K(t) = \\bar{K} + \\sigma\\,\\xi(t)$，其中 $\\bar{K}$ 是平均值，$\\sigma$ 是噪声振幅，$\\xi(t)$ 是高斯白噪声。该闭合方案代表了影响有效扩散系数的未解析湍流脉动。施加物理约束 $K(t) \\ge K_{\\min}  0$ 以防止非物理的负扩散系数，负扩散系数将对应于非物理的反扩散（梯度的自发锐化）。\n\n核心任务是为此方程实现一个数值求解器，并用它来量化随机参数化对解的系综统计量的影响。\n\n#### 离散化策略\n问题指定了数值格式：\n-   **空间离散化**：在具有 $N_x$ 个点的均匀周期网格上采用二阶中心差分格式。网格间距为 $\\Delta x = 1/N_x$。作用于网格函数 $u_i$ 的离散拉普拉斯算子 $\\mathcal{L}$ 由下式给出：\n    $$\n    (\\mathcal{L}u)_i = \\frac{u_{i+1} - 2u_i + u_{i-1}}{\\Delta x^2}\n    $$\n    周期性要求索引按模 $N_x$ 处理，使得 $u_{N_x} \\equiv u_0$ 和 $u_{-1} \\equiv u_{N_x-1}$。\n-   **时间离散化**：采用时间步长为 $\\Delta t$ 的显式欧拉（前向欧拉）方法。对于单个系综成员 $m$，解 $u_i^n \\approx u(x_i, t_n)$ 从时间步 $n$ 到 $n+1$ 的更新规则是：\n    $$\n    u_m^{n+1} = u_m^n + \\Delta t \\cdot K_m^n \\cdot (\\mathcal{L}u_m^n)\n    $$\n    其中 $K_m^n$ 是成员 $m$ 在时间步 $n$ 的扩散系数的实现。\n\n#### 系综模拟\n为研究随机闭合，执行了 $M$ 次模拟的系综。系综中的每个成员代表随机过程 $K(t)$ 历史的一个可能实现。\n-   **初始条件**：所有系综成员从相同的初始状态开始，该状态通过在空间网格上采样函数 $u(x,0) = \\sin(2\\pi x) + \\frac{1}{2}\\sin(4\\pi x)$ 给出。\n-   **随机强迫**：对于随机闭合，在每个时间步 $n$，为每个系综成员 $m$ 计算一个唯一的扩散系数 $K_m^n$。这是通过从标准正态分布 $\\mathcal{N}(0,1)$ 中抽取一个独立的随机数 $\\xi_m^n$ 并应用截断公式来完成的：\n    $$\n    K_m^n = \\max(K_{\\min}, \\bar{K} + \\sigma \\xi_m^n)\n    $$\n-   **确定性情况**：对于确定性情况，$K_m^n = \\bar{K}$ 对所有 $m$ 和 $n$ 成立。由于所有成员都从相同的初始状态开始，并在相同的确定性方程下演化，因此它们在所有时间内都保持相同。\n\n#### 结果分析\n在对系综进行总时间 $T$ 的模拟后，我们分析最终时刻的统计数据。\n-   **系综平均值**：$\\bar{u}(x_i, T) = \\frac{1}{M}\\sum_{m=1}^M u_m(x_i, T)$。这代表了标量场的期望演化。\n-   **系综方差场**：$\\mathrm{Var}[u](x_i, T) = \\frac{1}{M}\\sum_{m=1}^M (u_m(x_i, T) - \\bar{u}(x_i, T))^2$。该场量化了每个网格点上系综的不确定性或离散程度，这直接源于 $K(t)$ 的随机性。\n-   **空间平均方差**：$V(T) = \\frac{1}{N_x}\\sum_{i=0}^{N_x-1} \\mathrm{Var}[u](x_i, T)$。这个标量提供了一个衡量总系综离散程度的单一指标。\n\n目标量是 $\\Delta V = V_{\\mathrm{stoch}}(T) - V_{\\mathrm{det}}(T)$。如前所述，对于确定性闭合，所有系综成员都相同，因此其方差为零，$V_{\\mathrm{det}}(T) = 0$。因此，问题简化为为每个测试案例计算 $V_{\\mathrm{stoch}}(T)$。这通过使用指定的随机参数运行系综模拟来实现。对于 $\\sigma=0$ 的测试案例，“随机”运行变为确定性运行，计算出的方差预期为零，这可作为一种自洽性检验。\n\n#### 算法实现\n该算法使用 Python 的 `numpy` 库实现，以进行高效的向量化计算。\n1.  定义了一个函数 `simulate` 来封装一次完整系综模拟的逻辑。它将所有物理和数值参数作为参数。\n2.  在 `simulate` 内部，设置了一个随机种子以确保可复现性。\n3.  创建了空间网格和形状为 $(M, N_x)$ 的初始条件数组 `u`。所有 $M$ 行（系综成员）都被初始化为相同的。\n4.  主模拟循环迭代 $N_t = T/\\Delta t$ 次。在每次迭代中：\n    a. 使用 `numpy.roll` 处理周期性边界条件和向量化算术，同时为所有 $M$ 个成员计算离散拉普拉斯算子。\n    b. 计算所有 $M$ 个成员的扩散系数 $K$。如果 $\\sigma  0$，这涉及生成一个包含 $M$ 个随机数的数组。结果是一个形状为 $(M, 1)$ 的数组，以便进行广播。\n    c. 使用显式欧拉步骤更新状态 `u`。广播确保 `u` 数组中每个成员的状态都用其自身的特定 $K$ 值进行更新。\n5.  循环结束后，使用最终的系综 `u`，根据提供的公式计算系综平均场和方差场，并最终计算标量空间平均方差 $V(T)$。所有平均操作都使用 `numpy.mean`。\n6.  一个主脚本遍历测试案例，为每个案例调用 `simulate` 函数，并收集结果 ($\\Delta V = V(T)$)。\n7.  最终结果被格式化为 $6$ 位小数，并以要求的列表格式打印。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef simulate(Nx, dt, T, M, K_bar, sigma, K_min, seed):\n    \"\"\"\n    Runs an ensemble simulation of the 1D stochastic diffusion equation.\n\n    Args:\n        Nx (int): Number of spatial grid points.\n        dt (float): Time step size.\n        T (float): Total simulation time.\n        M (int): Number of ensemble members.\n        K_bar (float): Mean diffusivity.\n        sigma (float): Noise amplitude for diffusivity.\n        K_min (float): Minimum allowed diffusivity.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        float: The spatially averaged ensemble variance V(T) at final time T.\n    \"\"\"\n    # 1. Set seed for reproducibility\n    np.random.seed(seed)\n\n    # 2. Grid and parameter setup\n    dx = 1.0 / Nx\n    x = np.arange(Nx) * dx\n    Nt = int(round(T / dt))\n\n    # 3. Initial Condition\n    # All M ensemble members start with the same initial condition.\n    # The array u has shape (M, Nx).\n    u0 = np.sin(2 * np.pi * x) + 0.5 * np.sin(4 * np.pi * x)\n    u = np.tile(u0, (M, 1))\n\n    # 4. Time stepping loop\n    for _ in range(Nt):\n        # 4a. Compute discrete Laplacian for all ensemble members (vectorized)\n        # np.roll handles periodic boundary conditions.\n        u_lap = (np.roll(u, -1, axis=1) - 2 * u + np.roll(u, 1, axis=1)) / (dx**2)\n\n        # 4b. Compute stochastic diffusivity K for each member\n        if sigma == 0:\n            # Deterministic case, K is a scalar applied to all members.\n            K = K_bar\n        else:\n            # Stochastic case: one K per member.\n            # Generate M random numbers from N(0,1).\n            xi = np.random.randn(M, 1)\n            # Calculate K and apply truncation. Shape is (M, 1) for broadcasting.\n            K = np.maximum(K_min, K_bar + sigma * xi)\n        \n        # 4c. Update u using explicit Euler step (vectorized)\n        # K (M,1) or scalar is broadcast across u_lap (M, Nx).\n        u += dt * K * u_lap\n    \n    # 5. Compute final statistics\n    if M == 1:\n        # Variance requires at least 2 members.\n        return 0.0\n\n    # 5a. Ensemble mean field over all members (axis=0)\n    u_mean = np.mean(u, axis=0)  # Shape: (Nx,)\n\n    # 5b. Ensemble variance field. u_mean is broadcast for subtraction.\n    u_var_field = np.mean((u - u_mean)**2, axis=0) # Shape: (Nx,)\n\n    # 5c. Spatially averaged variance\n    V_T = np.mean(u_var_field)\n\n    return V_T\n\ndef solve():\n    \"\"\"\n    Sets up and runs the test cases, then prints the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {'Nx': 64, 'dt': 0.0005, 'T': 0.1, 'M': 200, 'K_bar': 0.05, 'sigma': 0.01, 'seed': 42},\n        # Case 2\n        {'Nx': 64, 'dt': 0.0005, 'T': 0.1, 'M': 200, 'K_bar': 0.05, 'sigma': 0, 'seed': 123},\n        # Case 3\n        {'Nx': 128, 'dt': 0.0003, 'T': 0.06, 'M': 300, 'K_bar': 0.01, 'sigma': 0.015, 'seed': 2025},\n    ]\n\n    K_min = 1e-8\n    results = []\n    \n    for case in test_cases:\n        # Per the problem statement, Delta_V = V_stoch(T) - V_det(T).\n        # Since V_det(T) is exactly 0, we only need to compute V_stoch(T).\n        # The simulate function calculates this value for the parameters of each test case.\n        delta_V = simulate(\n            Nx=case['Nx'],\n            dt=case['dt'],\n            T=case['T'],\n            M=case['M'],\n            K_bar=case['K_bar'],\n            sigma=case['sigma'],\n            K_min=K_min,\n            seed=case['seed']\n        )\n        results.append(delta_V)\n\n    # Format the results to 6 decimal places and print in the required format.\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个随机参数化方案的有效性依赖于其参数的合理设定，例如O-U过程中的退相关时间和方差。本练习旨在连接理论模型与实际应用，指导你从一个给定的时间序列数据（如预报与分析的残差序列）中估计这些关键参数。你将推导并实现一个最大似然估计器（Maximum Likelihood Estimator），掌握如何通过统计方法校准随机模型，这是将随机参数化方案应用于实际预测系统中的关键一步。",
            "id": "4094933",
            "problem": "考虑一个用于预报减分析残差的Ornstein–Uhlenbeck (OU) 模型，该模型用于随机参数化方案，例如随机动能反向散射 (Stochastic Kinetic Energy Backscatter, SKEB) 和随机对流。令连续时间残差过程由以下线性随机微分方程建模\n$$\n\\mathrm{d}X_t = -\\frac{1}{T} X_t \\,\\mathrm{d}t + \\sqrt{\\frac{2\\sigma^2}{T}} \\,\\mathrm{d}W_t,\n$$\n其中 $T$ 是去相关时间，$\\sigma^2$ 是 $X_t$ 的平稳方差，而 $W_t$ 是标准维纳过程。假设该过程是严格平稳的。对于固定的采样间隔 $\\Delta t$，该OU过程的精确离散时间转移可以表示为具有高斯新息的一阶自回归过程。要求您推导有限残差样本的似然函数，然后设计一个算法，通过最大似然法从时间序列数据中估计 $T$ 和 $\\sigma^2$。\n\n从OU过程的基本定义和高斯马尔可夫过程的性质出发，推导OU模型下在时间点 $t_n = n \\Delta t$ 的离散时间样本 $\\{x_0, x_1, \\dots, x_N\\}$ 的条件似然。使用此似然函数为参数 $T$ 和 $\\sigma^2$ 构建最大似然估计器。您的推导必须从OU动力学的线性、增量的高斯性和马尔可夫性质出发，不得使用现成的自回归估计器公式。\n\n在一个完整、可运行的程序中实现您的估计器。该程序必须：\n- 使用连续时间OU过程所蕴含的精确离散时间表示，根据给定的参数集在OU模型下模拟合成的预报减分析残差序列。\n- 使用推导出的最大似然法从每个模拟序列中估计 $\\hat{T}$ 和 $\\hat{\\sigma}^2$。\n- 以单行输出结果，格式为方括号内以逗号分隔的列表，顺序为 $[\\hat{T}_1, \\hat{\\sigma}^2_1, \\hat{T}_2, \\hat{\\sigma}^2_2, \\hat{T}_3, \\hat{\\sigma}^2_3, \\hat{T}_4, \\hat{\\sigma}^2_4]$。\n\n物理单位：\n- 所有去相关时间 $T$ 和 $\\hat{T}$ 均以秒为单位报告。\n- 方差 $\\sigma^2$ 和 $\\hat{\\sigma}^2$ 与残差变量的单位一致；将它们视为量纲一致的标量，并报告其数值，不带单位。\n\n角度单位不是必需的。任何表示为比例的量都必须以小数形式提供。\n\n测试套件：\n使用以下参数集生成合成时间序列。对于每种情况，在 $t_0$ 时从平稳分布中模拟，然后遵循精确的离散时间OU动力学进行后续的 $N$ 步。\n- 情况 1：$\\Delta t = 300$ s, $T = 3600$ s, $\\sigma^2 = 4.0$, $N = 2000$, 随机种子 $= 42$。\n- 情况 2：$\\Delta t = 300$ s, $T = 600$ s, $\\sigma^2 = 1.0$, $N = 1500$, 随机种子 $= 123$。\n- 情况 3：$\\Delta t = 600$ s, $T = 1800$ s, $\\sigma^2 = 9.0$, $N = 30$, 随机种子 $= 7$。\n- 情况 4：$\\Delta t = 60$ s, $T = 86400$ s, $\\sigma^2 = 2.25$, $N = 5000$, 随机种子 $= 31415$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个方括号内的逗号分隔列表，顺序与上文指定完全一致。例如，输出行应类似于 $[r_1,r_2,r_3,r_4,r_5,r_6,r_7,r_8]$，其中每个 $r_k$ 是一个浮点数。",
            "solution": "该问题要求从离散时间观测序列中，推导并实现Ornstein-Uhlenbeck (OU) 过程参数的最大似然估计器 (Maximum Likelihood Estimator, MLE)。\n\n连续时间OU过程由以下随机微分方程 (stochastic differential equation, SDE) 定义：\n$$\n\\mathrm{d}X_t = -\\frac{1}{T} X_t \\,\\mathrm{d}t + \\sqrt{\\frac{2\\sigma^2}{T}} \\,\\mathrm{d}W_t\n$$\n其中 $T$ 是去相关时间，$\\sigma^2$ 是过程 $X_t$ 的平稳方差，而 $W_t$ 代表标准维纳过程。\n\n首先，我们推导该过程的精确离散时间表示。该SDE是一个线性一阶方程。其在时间间隔 $\\Delta t = t_{n+1} - t_n$ 上的解给出了 $X_{t_{n+1}}$ 和 $X_{t_n}$ 之间的关系。令 $X_n = X_{t_n}$。解为：\n$$\nX_{n+1} = X_n e^{- \\frac{\\Delta t}{T}} + \\sqrt{\\frac{2\\sigma^2}{T}} \\int_{t_n}^{t_{n+1}} e^{-\\frac{1}{T}(t_{n+1}-s)} \\,\\mathrm{d}W_s\n$$\n该方程描述了一个形式为 $X_{n+1} = a X_n + \\epsilon_n$ 的一阶自回归 (AR(1)) 过程。\n\n通过观察可确定自回归参数 $a$：\n$$\na = e^{-\\frac{\\Delta t}{T}}\n$$\n新息项 $\\epsilon_n$ 是随机积分。作为一个Itō积分（积分对象为确定性函数），它是一个均值为零的高斯随机变量，即 $E[\\epsilon_n] = 0$。其方差 $\\sigma_\\epsilon^2 = E[\\epsilon_n^2]$ 可使用Itō等距性质确定：\n$$\n\\sigma_\\epsilon^2 = \\left(\\sqrt{\\frac{2\\sigma^2}{T}}\\right)^2 \\int_{t_n}^{t_{n+1}} \\left(e^{-\\frac{1}{T}(t_{n+1}-s)}\\right)^2 \\,\\mathrm{d}s = \\frac{2\\sigma^2}{T} \\int_{t_n}^{t_{n+1}} e^{-\\frac{2}{T}(t_{n+1}-s)} \\,\\mathrm{d}s\n$$\n计算该积分得出：\n$$\n\\sigma_\\epsilon^2 = \\frac{2\\sigma^2}{T} \\left[ \\frac{T}{2} e^{-\\frac{2}{T}(t_{n+1}-s)} \\right]_{s=t_n}^{s=t_{n+1}} = \\sigma^2 \\left( e^0 - e^{-\\frac{2\\Delta t}{T}} \\right) = \\sigma^2 \\left(1 - \\left(e^{-\\frac{\\Delta t}{T}}\\right)^2 \\right)\n$$\n因此，新息的方差为 $\\sigma_\\epsilon^2 = \\sigma^2(1-a^2)$。\n\n问题要求解在初始观测值 $x_0$ 条件下，离散样本 $\\{x_0, x_1, \\dots, x_N\\}$ 的条件似然。由于AR(1)过程的马尔可夫性质，给定 $x_0$ 时 $\\{x_1, \\dots, x_N\\}$ 的联合概率密度函数是各个条件概率的乘积：\n$$\np(x_1, \\dots, x_N | x_0; T, \\sigma^2) = \\prod_{n=0}^{N-1} p(x_{n+1} | x_n; T, \\sigma^2)\n$$\n条件分布 $p(x_{n+1} | x_n)$ 是高斯分布，其均值为 $E[X_{n+1}|X_n=x_n] = a x_n$，方差为 $\\sigma_\\epsilon^2$。条件对数似然函数 $\\ell_c$ 为：\n$$\n\\ell_c(T, \\sigma^2) = \\log p(x_1, \\dots, x_N | x_0) = \\sum_{n=0}^{N-1} \\log p(x_{n+1} | x_n)\n$$\n$$\n\\ell_c = \\sum_{n=0}^{N-1} \\left( -\\frac{1}{2}\\log(2\\pi\\sigma_\\epsilon^2) - \\frac{(x_{n+1} - a x_n)^2}{2\\sigma_\\epsilon^2} \\right) = -\\frac{N}{2}\\log(2\\pi\\sigma_\\epsilon^2) - \\frac{1}{2\\sigma_\\epsilon^2} \\sum_{n=0}^{N-1} (x_{n+1} - a x_n)^2\n$$\n为了找到最大似然估计 (MLE)，我们使用 $\\sigma_\\epsilon^2 = \\sigma^2(1-a^2)$，将 $\\ell_c$ 用基本参数 $a$ 和 $\\sigma^2$ 表示：\n$$\n\\ell_c(a, \\sigma^2) = -\\frac{N}{2}\\log(2\\pi\\sigma^2(1-a^2)) - \\frac{1}{2\\sigma^2(1-a^2)} \\sum_{n=0}^{N-1} (x_{n+1} - a x_n)^2\n$$\n我们对该函数关于 $a$ 和 $\\sigma^2$ 求最大值。对 $\\sigma^2$ 求导并令结果为零，得到作为 $a$ 的函数的 $\\sigma^2$ 的最大似然估计：\n$$\n\\frac{\\partial \\ell_c}{\\partial \\sigma^2} = -\\frac{N}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2(1-a^2)} \\sum_{n=0}^{N-1} (x_{n+1} - a x_n)^2 = 0 \\implies \\hat{\\sigma}^2(a) = \\frac{1}{N(1-a^2)} \\sum_{n=0}^{N-1} (x_{n+1} - a x_n)^2\n$$\n将其代回 $\\ell_c$ 得到 $a$ 的剖面对数似然。最大化 $\\ell_c(a, \\hat{\\sigma}^2(a))$ 关于 $a$ 的值等价于最小化项 $\\hat{\\sigma}^2(a)(1-a^2)$：\n$$\n\\hat{\\sigma}^2(a)(1-a^2) = \\frac{1}{N} \\sum_{n=0}^{N-1} (x_{n+1} - a x_n)^2\n$$\n因此，$a$ 的最大似然估计（表示为 $\\hat{a}$）是使残差平方和 $S(a) = \\sum_{n=0}^{N-1} (x_{n+1} - a x_n)^2$ 最小化的值。这对应于一个普通最小二乘法 (ordinary least squares, OLS) 问题。将 $S(a)$ 的导数设为零，得到：\n$$\n\\frac{\\mathrm{d}S(a)}{\\mathrm{d}a} = -2\\sum_{n=0}^{N-1} x_n(x_{n+1} - a x_n) = 0 \\implies \\hat{a}\\sum_{n=0}^{N-1} x_n^2 = \\sum_{n=0}^{N-1} x_n x_{n+1}\n$$\n因此，估计量 $\\hat{a}$ 为：\n$$\n\\hat{a} = \\frac{\\sum_{n=0}^{N-1} x_n x_{n+1}}{\\sum_{n=0}^{N-1} x_n^2}\n$$\n有了 $\\hat{a}$，我们通过反转关系式 $a = e^{-\\Delta t/T}$ 来找到去相关时间的最大似然估计 $\\hat{T}$：\n$$\n\\hat{T} = -\\frac{\\Delta t}{\\log(\\hat{a})}\n$$\n最后，将 $\\hat{a}$ 代入 $\\hat{\\sigma}^2(a)$ 的表达式中，得到平稳方差的最大似然估计 $\\hat{\\sigma}^2$：\n$$\n\\hat{\\sigma}^2 = \\frac{1}{N(1-\\hat{a}^2)} \\sum_{n=0}^{N-1} (x_{n+1} - \\hat{a} x_n)^2\n$$\n这些公式提供了一个从数据中估计 $T$ 和 $\\sigma^2$ 的完整算法。该算法将被实现，用于基于OU模型模拟时间序列，然后从这些合成数据中估计参数。",
            "answer": "```python\nimport numpy as np\n\ndef simulate_ou_series(T, sigma2, dt, N, seed):\n    \"\"\"\n    Simulates a time series from an Ornstein-Uhlenbeck process.\n\n    Args:\n        T (float): Decorrelation time in seconds.\n        sigma2 (float): Stationary variance.\n        dt (float): Sampling interval in seconds.\n        N (int): Number of steps to simulate after the initial point.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        numpy.ndarray: A time series of length N+1.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # Calculate AR(1) parameters from OU parameters\n    a = np.exp(-dt / T)\n    sigma_epsilon_sq = sigma2 * (1 - a**2)\n    sigma_epsilon = np.sqrt(sigma_epsilon_sq)\n    \n    # Initialize the time series array\n    x = np.zeros(N + 1)\n    \n    # The process is stationary, so the first point is drawn from the stationary distribution\n    x[0] = rng.normal(loc=0, scale=np.sqrt(sigma2))\n    \n    # Generate all innovations at once for efficiency\n    epsilon = rng.normal(loc=0, scale=sigma_epsilon, size=N)\n    \n    # Propagate the process using the discrete-time AR(1) formula\n    for n in range(N):\n        x[n+1] = a * x[n] + epsilon[n]\n        \n    return x\n\ndef estimate_ou_params_mle(x, dt):\n    \"\"\"\n    Estimates OU parameters T and sigma2 from a time series using Maximum Likelihood.\n\n    Args:\n        x (numpy.ndarray): The time series data, of length N+1.\n        dt (float): The sampling interval in seconds.\n\n    Returns:\n        tuple[float, float]: A tuple containing the estimated T_hat and sigma2_hat.\n    \"\"\"\n    N = len(x) - 1\n    if N  1:\n        return (np.nan, np.nan)\n\n    # Create lagged and current series for autoregression\n    # x_n for n from 0 to N-1\n    x_lag = x[:-1]\n    # x_{n+1} for n from 0 to N-1\n    x_t = x[1:]\n\n    # Calculate sums required for the OLS estimate of the AR(1) parameter 'a'\n    # sum(x_n^2) from n=0 to N-1\n    C0 = np.sum(x_lag**2)\n    # sum(x_n * x_{n+1}) from n=0 to N-1\n    C1 = np.sum(x_lag * x_t)\n\n    # Handle the case of a zero-valued series\n    if C0 == 0:\n        return (np.nan, np.nan)\n\n    # Estimate 'a' using the derived MLE (which is the OLS estimator)\n    a_hat = C1 / C0\n    \n    # For a stationary process with T > 0, we require 0  a_hat  1.\n    # If a_hat is outside this range, the log will be undefined or yield a non-physical T.\n    # This can occur with small N or non-stationary data.\n    if not (0  a_hat  1):\n        return (np.nan, np.nan)\n\n    # Estimate T from a_hat\n    T_hat = -dt / np.log(a_hat)\n\n    # Calculate the sum of squared residuals for the AR(1) fit\n    residuals = x_t - a_hat * x_lag\n    SSR = np.sum(residuals**2)\n    \n    # Estimate sigma^2 (stationary variance) using its MLE formula\n    sigma2_hat = SSR / (N * (1 - a_hat**2))\n    \n    return T_hat, sigma2_hat\n\ndef solve():\n    \"\"\"\n    Main function to run simulations and estimations for the given test cases.\n    \"\"\"\n    test_cases = [\n        # (dt, T, sigma2, N, seed)\n        (300, 3600, 4.0, 2000, 42),\n        (300, 600, 1.0, 1500, 123),\n        (600, 1800, 9.0, 30, 7),\n        (60, 86400, 2.25, 5000, 31415),\n    ]\n\n    results = []\n    for dt, T_true, sigma2_true, N, seed in test_cases:\n        # 1. Simulate synthetic data\n        time_series = simulate_ou_series(T_true, sigma2_true, dt, N, seed)\n        \n        # 2. Estimate parameters from the synthetic data\n        T_hat, sigma2_hat = estimate_ou_params_mle(time_series, dt)\n        \n        results.extend([T_hat, sigma2_hat])\n\n    # 3. Format and print the final output as a single line\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}