{
    "hands_on_practices": [
        {
            "introduction": "Metropolis 算法是马尔可夫链蒙特卡洛（MCMC）方法的基础。其核心机制在于接受概率的计算，它通过满足细致平衡条件来确保采样链最终能收敛到目标分布。本练习  提供了一个清晰的计算任务，让你在一个对称提议分布的场景下，亲手计算接受概率，从而牢固掌握这一关键步骤。",
            "id": "1371728",
            "problem": "一位数据科学家正在实现一个马尔可夫链蒙特卡洛（MCMC）模拟，以从参数 $x$ 的后验概率分布中抽取样本。目标分布 $\\pi(x)$ 与参数绝对值的负指数成正比，即 $\\pi(x) \\propto \\exp(-|x|)$。\n\n该科学家使用 Metropolis 算法，其建议分布 $q(x'|x)$ 是对称的，即在给定当前状态 $x$ 的情况下建议新状态 $x'$ 的概率等于在给定 $x'$ 的情况下建议 $x$ 的概率（即 $q(x'|x) = q(x|x')$）。\n\n假设在模拟的某一步中，链的当前状态是 $x = 1.5$。然后，算法建议转移到一个新的候选状态 $x' = 2.0$。\n\n计算此特定转移的接受概率。您的答案应该是一个无量纲的实数。将最终答案四舍五入到四位有效数字。",
            "solution": "对于从 $x$ 到 $x'$ 的转移，当建议分布 $q(x'|x)=q(x|x')$ 对称时，Metropolis 接受概率为\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\n给定目标分布 $\\pi(x)\\propto \\exp(-|x|)$，该比率可简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\n当 $x=1.5$ 且 $x'=2.0$ 时，我们有 $|x|=1.5$ 且 $|x'|=2.0$，所以\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\n因此，\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\n数值上，$\\exp(-0.5)\\approx 0.6065$（四舍五入到四位有效数字）。",
            "answer": "$$\\boxed{0.6065}$$"
        },
        {
            "introduction": "在处理高维或具有复杂结构的模型时，吉布斯采样（Gibbs sampling）是一种非常高效的 MCMC 方法，在环境和地球系统建模中尤为常用。该方法通过从每个参数的完整条件分布中迭代抽样来运作，因此，准确推导这些条件分布是构建吉布斯采样器的核心技能。本练习  引导你为一个常见的时间序列状态空间模型推导其关键参数的后验条件分布，让你直接体验贝叶斯推断中的核心代数推导过程。",
            "id": "791654",
            "problem": "考虑一个线性高斯状态空间模型，也称为局部水平模型，该模型常用于时间序列分析。该模型定义于时间步 $t=1, \\dots, T$。\n\n1.  **观测方程：** 在时间 $t$ 的观测值 $y_t$ 依赖于潜在状态 $x_t$，遵循正态分布：\n    $$\n    y_t | x_t, \\sigma^2_y \\sim N(x_t, \\sigma^2_y)\n    $$\n    其中 $N( \\mu, \\sigma^2)$ 表示均值为 $\\mu$、方差为 $\\sigma^2$ 的正态分布。\n\n2.  **状态方程：** 潜在状态 $x_t$ 作为一个随机游走演化，依赖于前一个状态 $x_{t-1}$：\n    $$\n    x_t | x_{t-1}, \\sigma^2_x \\sim N(x_{t-1}, \\sigma^2_x)\n    $$\n\n在贝叶斯推断的背景下，特别是在使用吉布斯采样器时，需要计算每个潜在状态的全条件分布。对于一个中间时间步 $k$（其中 $1  k  T$），状态 $x_k$ 的全条件分布是在给定所有其他状态 $\\mathbf{x}_{-k} = \\{x_t\\}_{t \\neq k}$、所有观测值 $\\mathbf{y} = \\{y_t\\}_{t=1}^T$ 以及模型的方差参数的条件下，$x_k$ 的分布。\n\n给定此模型中，全条件分布 $p(x_k | \\mathbf{x}_{-k}, \\mathbf{y}, \\sigma_y^2, \\sigma_x^2)$ 是一个正态分布，我们将其表示为 $N(\\mu_k^*, (\\sigma_k^*)^2)$。对于本问题，假设观测方差 $\\sigma_y^2$ 和状态方差 $\\sigma_x^2$ 是已知的正常数。\n\n您的任务是推导该全条件分布的均值与方差之积 $\\mu_k^* (\\sigma_k^*)^2$ 的表达式。最终表达式应使用观测值 $y_k$、相邻的潜在状态 $x_{k-1}$ 和 $x_{k+1}$ 以及方差 $\\sigma_y^2$ 和 $\\sigma_x^2$ 来表示。",
            "solution": "我们要求解条件分布\n$$p(x_k\\mid\\mathbf x_{-k},\\mathbf y)\\;\\propto\\;p(y_k\\mid x_k)\\,p(x_k\\mid x_{k-1})\\,p(x_{k+1}\\mid x_k)\\,. $$\n由于每个因子都是高斯分布，我们写出关于 $x_k$ 的未归一化对数后验的指数部分：\n$$-\\tfrac12\\Bigl[\\tfrac1{\\sigma_y^2}(y_k - x_k)^2+\\tfrac1{\\sigma_x^2}(x_k - x_{k-1})^2+\\tfrac1{\\sigma_x^2}(x_{k+1}-x_k)^2\\Bigr]\\,. $$\n展开并合并关于 $x_k$ 的项，得到\n$$-\\tfrac12\\Bigl[\\bigl(\\tfrac1{\\sigma_y^2}+2\\tfrac1{\\sigma_x^2}\\bigr)x_k^2-2\\bigl(\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}\\bigr)x_k+\\cdots\\Bigr]\\,. $$\n因此，条件分布是高斯分布，其精度为\n$$\\lambda=\\frac1{\\sigma_y^2}+\\frac{2}{\\sigma_x^2},$$\n方差为\n$$ (\\sigma_k^*)^2=\\lambda^{-1},$$\n均值为\n$$ \\mu_k^*=\\frac{\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\lambda}\\,. $$\n因此\n$$\\mu_k^*(\\sigma_k^*)^2=\\frac{\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\lambda^2}  \n=\\frac{\\tfrac{y_k}{\\sigma_y^2}+\\tfrac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\bigl(\\tfrac1{\\sigma_y^2}+\\tfrac{2}{\\sigma_x^2}\\bigr)^2}\\,. $$",
            "answer": "$$\\boxed{\\frac{\\frac{y_k}{\\sigma_y^2}+\\frac{x_{k-1}+x_{k+1}}{\\sigma_x^2}}{\\Bigl(\\frac1{\\sigma_y^2}+\\frac{2}{\\sigma_x^2}\\Bigr)^2}}$$"
        },
        {
            "introduction": "理论上有效的 MCMC 采样器，其在实践中的性能往往严重依赖于调优参数（如提议步长）的设定。自适应 MCMC 是一种能够自动化此调优过程的先进技术，它通常在算法的“预烧期”（burn-in phase）利用随机近似等方法来动态调整参数，以达到最优采样效率。这项综合性练习  要求你将理论付诸实践，通过编程实现一个完整的自适应采样器，它完美展示了如何将核心理论（如 Metropolis 法则和接受率）转化为解决实际问题的稳健计算工具。",
            "id": "2411370",
            "problem": "实现一个自适应 Metropolis 随机游走马尔可夫链蒙特卡洛 (MCMC) 算法，该算法在预烧期（burn-in）调整一个标量提议步长，以达到并维持一个接近指定值的目标接受率。目标密度函数仅在相差一个归一化常数的情况下已知。您的实现必须是一个完整的、可运行的程序，不接受任何输入并打印所需的输出。该算法必须基于基本原理进行论证：(i) 基于细致平衡条件的 Metropolis-Hastings 构建，以及 (ii) 用于解决接受率根查找问题的随机近似。目标是设计自适应方案，使其仅限于预烧期，并在采样期间保持稳态分布不变。\n\n从以下基本基础出发：\n- 具有稳态密度 $\\pi(\\boldsymbol{x})$ 的马尔可夫链的转移核必须满足细致平衡，即对于所有状态 $\\boldsymbol{x}$ 和 $\\boldsymbol{y}$，$\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$。\n- 在使用提议密度 $q(\\boldsymbol{y}\\mid \\boldsymbol{x})$ 的 Metropolis-Hastings 构建中，必须选择接受概率以使细致平衡成立。\n- 在自适应方案中，预烧期的参数更新可以被看作是求解形式为 $\\mathbb{E}[h(\\theta)] = 0$ 的方程的随机近似，步长递减。\n\n您的任务是：\n1) 从细致平衡条件出发，推导对称高斯随机游走提议 $q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$ 的 Metropolis-Hastings 接受概率，并在代码中实现它。您必须在解决方案中从细致平衡出发论证该接受公式，不得依赖任何未经证明的简化公式。\n2) 推导并实现一个 Robbins-Monro 型随机近似，该近似在预烧期的第 $n$ 次迭代时，根据一个递减的步长序列来更新对数步长 $\\theta = \\log \\sigma$。目标是使期望接受概率趋向一个目标值 $a^\\star$。您的更新必须在对数尺度上进行以保持 $\\sigma$ 的正性，必须使用形式为 $\\gamma_n = c/(n+t_0)$ 的递减增益（其中常数 $c > 0$ 和 $t_0 \\ge 0$），并且必须严格限制在预烧期。在您的解决方案中清楚地陈述选择此方法的原因。\n3) 预烧期结束后，固定调整好的 $\\sigma$ 并生成样本。仅计算采样阶段的经验接受率。所有接受率必须以单位区间内的小数形式报告。\n\n您必须在以下测试套件上实现并测试您的程序。每个测试都指定了目标分布、维度、初始条件和随机种子。为保证可复现性，请使用指定的随机种子。在所有情况下，目标接受率均为 $a^\\star = 0.23$。\n\n- 测试 A (一维标准高斯分布):\n  - 维度 $d = 1$。\n  - 目标对数密度: $\\log \\pi(x) = -\\tfrac{1}{2} x^2$。\n  - 初始位置: $x_0 = 0$。\n  - 初始步长: $\\sigma_0 = 0.001$。\n  - 预烧期迭代次数: $N_{\\mathrm{burn}} = 6000$。\n  - 采样迭代次数: $N_{\\mathrm{sample}} = 12000$。\n  - 随机种子: $42$。\n\n- 测试 B (五维相关高斯分布):\n  - 维度 $d = 5$。\n  - 目标密度: $\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x}\\right)$，其中 $\\Sigma_{ij} = \\rho^{|i-j|}$ 且 $\\rho = 0.8$。\n  - 初始位置: $\\boldsymbol{x}_0 = \\boldsymbol{0}$。\n  - 初始步长: $\\sigma_0 = 10$。\n  - 预烧期迭代次数: $N_{\\mathrm{burn}} = 8000$。\n  - 采样迭代次数: $N_{\\mathrm{sample}} = 12000$。\n  - 随机种子: $123$。\n\n- 测试 C (二维 Rosenbrock 目标，曲率软化):\n  - 维度 $d = 2$。\n  - 定义势 $U(x_1,x_2) = 100\\,(x_2 - x_1^2)^2 + (1 - x_1)^2$。\n  - 目标密度: $\\pi(\\boldsymbol{x}) \\propto \\exp\\!\\left(-U(x_1,x_2)/20\\right)$。\n  - 初始位置: $\\boldsymbol{x}_0 = (0,\\,0)$。\n  - 初始步长: $\\sigma_0 = 1$。\n  - 预烧期迭代次数: $N_{\\mathrm{burn}} = 12000$。\n  - 采样迭代次数: $N_{\\mathrm{sample}} = 12000$。\n  - 随机种子: $2024$。\n\n算法要求:\n- 使用高斯随机游走提议 $\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n- 仅在预烧期，在每次提议时通过 Robbins-Monro 步骤更新 $\\theta_n = \\log \\sigma_n$，使用 $\\gamma_n = c/(n + t_0)$（其中 $c$ 和 $t_0$ 为固定常数），并利用该步骤观察到的接受概率。\n- 预烧期后，固定 $\\sigma$ 并继续采样，不再进行任何调整。\n- 为保证稳定性，您可以将 $\\theta_n$ 约束在一个较宽的区间内，以使 $\\sigma_n$ 保持有限。\n\n输出规格:\n- 对每个测试，仅计算 $N_{\\mathrm{sample}}$ 次采样迭代的经验接受率。\n- 您的程序必须打印一行，包含一个列表，其中按 A、B、C 的顺序包含 3 个接受率，每个接受率四舍五入到三位小数，以小数形式（无百分号）表示，格式严格如下：$[\\text{r}_A,\\text{r}_B,\\text{r}_C]$。\n\n此问题不涉及任何物理单位或角度单位。所有数值答案必须是小数。在给定种子下，输出必须是确定性的。最终程序必须是完整的、可直接运行的，无需输入，且不得访问任何外部资源。",
            "solution": "任务是实现一个自适应 Metropolis 随机游走马尔可夫链蒙特卡洛 (MCMC) 算法。该算法必须在预烧期调整其标量提议步长 $\\sigma$，以达到一个指定的目标接受率 $a^\\star$。该算法的理论基础——Metropolis-Hastings 接受规则和用于自适应的 Robbins-Monro 随机近似——必须从第一性原理推导。\n\n### 问题验证\n\n首先，我们验证问题陈述。\n\n#### 第 1 步：提取已知条件\n\n- **基本原理**:\n    - 细致平衡: $\\pi(\\boldsymbol{x}) P(\\boldsymbol{x},\\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y},\\boldsymbol{x})$。\n    - Metropolis-Hastings (M-H) 构建: 转移核 $P(\\boldsymbol{x},\\boldsymbol{y})$ 由一个提议密度 $q(\\boldsymbol{y}\\mid \\boldsymbol{x})$ 和一个接受概率 $\\alpha(\\boldsymbol{x},\\boldsymbol{y})$ 构建。\n    - 随机近似: 参数更新遵循一个方案，以递减的步长求解 $\\mathbb{E}[h(\\theta)] = 0$。\n\n- **任务**:\n    1.  从细致平衡出发，为对称高斯随机游走提议 $q(\\boldsymbol{y}\\mid \\boldsymbol{x}) = \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$ 推导 M-H 接受概率。\n    2.  推导并实现一个 Robbins-Monro 更新，用于对数步长 $\\theta = \\log \\sigma$，以使接受率趋向目标值 $a^\\star$。该更新必须使用增益 $\\gamma_n = c/(n+t_0)$ 且仅限于预烧期。\n    3.  实现完整算法，预烧期后固定 $\\sigma$，并计算采样阶段的经验接受率。\n\n- **算法要求**:\n    - 提议: 高斯随机游走 $\\boldsymbol{y} = \\boldsymbol{x} + \\sigma \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n    - 自适应: 仅在预烧期通过 Robbins-Monro 更新 $\\theta_n = \\log \\sigma_n$，增益为 $\\gamma_n = c/(n+t_0)$。\n    - 采样: 预烧期后固定 $\\sigma$。\n    - 目标接受率: 所有测试中 $a^\\star = 0.23$。\n\n- **测试用例**:\n    - **测试 A**: $d=1$，对数密度 $\\log \\pi(x) = -\\tfrac{1}{2} x^2$，$x_0 = 0$，$\\sigma_0 = 0.001$，$N_{\\mathrm{burn}} = 6000$，$N_{\\mathrm{sample}} = 12000$，种子 $42$。\n    - **测试 B**: $d=5$，$\\pi(\\boldsymbol{x}) \\propto \\exp(-\\tfrac{1}{2}\\boldsymbol{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{x})$，其中 $\\Sigma_{ij} = \\rho^{|i-j|}$ 且 $\\rho = 0.8$，$\\boldsymbol{x}_0 = \\boldsymbol{0}$，$\\sigma_0 = 10$，$N_{\\mathrm{burn}} = 8000$，$N_{\\mathrm{sample}} = 12000$，种子 $123$。\n    - **测试 C**: $d=2$，$\\pi(\\boldsymbol{x}) \\propto \\exp(-U(x_1,x_2)/20)$，其中 $U(x_1,x_2) = 100(x_2 - x_1^2)^2 + (1 - x_1)^2$，$\\boldsymbol{x}_0 = (0,0)$，$\\sigma_0 = 1$，$N_{\\mathrm{burn}} = 12000$，$N_{\\mathrm{sample}} = 12000$，种子 $2024$。\n\n- **输出规格**: 一行包含测试 A、B、C 的三个接受率的列表，四舍五入到三位小数：$[\\text{r}_A,\\text{r}_B,\\text{r}_C]$。\n\n#### 第 2 步：使用提取的已知条件进行验证\n\n根据验证标准对问题进行审查。\n- **科学依据**: 该问题基于计算统计和物理学中已建立的基本原理，即 MCMC 理论、细致平衡和随机近似。目标分布是该领域的标准基准。问题不含伪科学。\n- **良态问题**: 目标清晰，每个测试用例的所有必要参数（维度、目标密度、初始条件、迭代次数、随机种子）都已指定。输出格式定义明确。在给定种子的情况下，问题是确定性的。预期会有一个唯一且有意义的解。Robbins-Monro 常数 $c$ 和 $t_0$ 的选择留给实现者，这是一个标准的设计决策，而非缺陷。\n- **客观性**: 语言技术性强、精确且无歧义。没有主观或基于意见的陈述。\n\n问题是自洽的、一致的且科学上合理的。未发现任何缺陷。\n\n#### 第 3 步：结论与行动\n\n问题有效。我们继续进行求解。\n\n### 推导与算法设计\n\n#### 1. Metropolis-Hastings 接受概率\n\n目标是构建一个具有稳态分布 $\\pi(\\boldsymbol{x})$ 的马尔可夫链。转移核 $P(\\boldsymbol{x}, \\boldsymbol{y})$ 给出了从状态 $\\boldsymbol{x}$ 移动到 $\\boldsymbol{y}$ 的概率密度，它必须满足细致平衡条件：\n$$\n\\pi(\\boldsymbol{x}) P(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) P(\\boldsymbol{y}, \\boldsymbol{x})\n$$\n在 Metropolis-Hastings 框架中，转移是一个两步过程：从提议密度 $q(\\boldsymbol{y} \\mid \\boldsymbol{x})$ 中提议一个新状态 $\\boldsymbol{y}$，然后以概率 $\\alpha(\\boldsymbol{x}, \\boldsymbol{y})$ 接受它。对于 $\\boldsymbol{x} \\neq \\boldsymbol{y}$，转移核为 $P(\\boldsymbol{x}, \\boldsymbol{y}) = q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y})$。将其代入细致平衡方程，得到：\n$$\n\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x}) \\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y}) \\alpha(\\boldsymbol{y}, \\boldsymbol{x})\n$$\n这意味着接受概率的比率必须满足以下约束：\n$$\n\\frac{\\alpha(\\boldsymbol{x}, \\boldsymbol{y})}{\\alpha(\\boldsymbol{y}, \\boldsymbol{x})} = \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\n$$\n满足此条件的标准 Metropolis 接受概率选择是：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y}) q(\\boldsymbol{x} \\mid \\boldsymbol{y})}{\\pi(\\boldsymbol{x}) q(\\boldsymbol{y} \\mid \\boldsymbol{x})}\\right)\n$$\n问题指定了一个对称高斯随机游走提议：$\\boldsymbol{y} \\sim \\mathcal{N}(\\boldsymbol{x}, \\sigma^2 \\mathbf{I}_d)$。提议密度为：\n$$\nq(\\boldsymbol{y} \\mid \\boldsymbol{x}) = \\frac{1}{(2\\pi\\sigma^2)^{d/2}} \\exp\\left(-\\frac{1}{2\\sigma^2} (\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x})\\right)\n$$\n由于项 $(\\boldsymbol{y}-\\boldsymbol{x})^\\top (\\boldsymbol{y}-\\boldsymbol{x}) = (\\boldsymbol{x}-\\boldsymbol{y})^\\top (\\boldsymbol{x}-\\boldsymbol{y})$，提议是对称的，即 $q(\\boldsymbol{y} \\mid \\boldsymbol{x}) = q(\\boldsymbol{x} \\mid \\boldsymbol{y})$。接受率比值中的提议项相互抵消，得到简化的 Metropolis 接受概率：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\frac{\\pi(\\boldsymbol{y})}{\\pi(\\boldsymbol{x})}\\right)\n$$\n由于目标密度 $\\pi(\\boldsymbol{x})$ 通常仅在相差一个归一化常数的情况下已知，我们使用未归一化的密度或更稳定地使用其对数来计算此比率：\n$$\n\\alpha(\\boldsymbol{x}, \\boldsymbol{y}) = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x})\\right)\\right)\n$$\n这就是要实现的公式。\n\n#### 2. 使用随机近似的自适应步长\n\n目标是调整提议步长 $\\sigma$，使得期望接受率与目标值 $a^\\star$ 相匹配。设 $\\theta = \\log \\sigma$ 为待调整的参数。更新在预烧期执行。我们希望找到函数 $g(\\theta) = \\mathbb{E}[\\alpha(\\theta)] - a^\\star$ 的根，其中 $\\alpha(\\theta)$ 是给定 $\\theta$ 时的接受概率。\n\nRobbins-Monro 算法是一种随机根查找方法。对于函数 $g(\\theta)$，我们可以使用迭代方案 $\\theta_{n+1} = \\theta_n - \\gamma_n g_n(\\theta_n)$ 来找到其根，其中 $g_n$ 是在第 $n$ 步对 $g$ 的噪声观测，而 $\\{\\gamma_n\\}$ 是满足 $\\sum \\gamma_n = \\infty$ 和 $\\sum \\gamma_n^2  \\infty$ 的步长序列。\n\n在我们的情况下，我们观察第 $n$ 次迭代的接受概率 $\\alpha_n$，并将其用作我们的噪声测量。$\\theta_n = \\log\\sigma_n$ 的更新规则被制定为引导观察到的接受率趋向 $a^\\star$：\n$$\n\\theta_{n+1} = \\theta_n + \\gamma_n (\\alpha_n - a^\\star)\n$$\n符号为正，因为如果当前接受率 $\\alpha_n$ 高于目标 $a^\\star$，我们需要增加 $\\theta$（从而增加 $\\sigma$）以使提议更大胆并降低接受率。反之，如果 $\\alpha_n  a^\\star$，我们减小 $\\theta$ 以使提议更保守并增加接受率。\n\n步长序列（增益）被给定为 $\\gamma_n = c/(n + t_0)$，对于 $n \\geq 1$。我们将选择 $c=1.0$ 和 $t_0=10.0$ 作为合理的常数，以确保稳定性和有效的自适应。在对数尺度上更新 $\\theta = \\log\\sigma$ 自然确保了 $\\sigma = \\exp(\\theta)$ 保持正值。\n\n这种自适应方案使得马尔可夫链非齐次。为保证样本是从正确的稳态分布 $\\pi(\\boldsymbol{x})$ 中抽取的，自适应必须在预烧期后终止。在 $N_{\\mathrm{burn}}$ 次迭代后，步长 $\\sigma$ 被固定为其最终调整的值，随后的 $N_{\\mathrm{sample}}$ 次迭代作为标准的、齐次的 Metropolis MCMC 算法进行。马尔可夫链的遍历定理随后确保从这些样本计算的平均值收敛于关于 $\\pi(\\boldsymbol{x})$ 的期望。\n\n### 实现计划\n\n算法将在一个函数中实现，该函数接受测试用例的参数。对于从 $n=1$ 到 $N_{\\mathrm{burn}} + N_{\\mathrm{sample}}$ 的每次迭代：\n1.  生成一个提议 $\\boldsymbol{y} = \\boldsymbol{x}_{\\text{current}} + \\sigma_n \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\mathbf{I}_d)$。\n2.  计算 $\\alpha = \\min\\left(1, \\exp\\left(\\log\\pi(\\boldsymbol{y}) - \\log\\pi(\\boldsymbol{x}_{\\text{current}})\\right)\\right)$。\n3.  抽取 $u \\sim U(0,1)$。如果 $u  \\alpha$，设置 $\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{y}$ 并记录一次接受。否则，设置 $\\boldsymbol{x}_{\\text{next}} = \\boldsymbol{x}_{\\text{current}}$。\n4.  如果 $n \\le N_{\\mathrm{burn}}$:\n    - 使用 Robbins-Monro 步骤更新 $\\log \\sigma_n$：$\\log\\sigma_{n+1} = \\log\\sigma_n + \\gamma_n (\\alpha - a^\\star)$。\n    - 为保证鲁棒性，我们将把 $\\log\\sigma$ 裁剪到一个合理的范围，例如 $[-10, 10]$。\n5.  如果 $n > N_{\\mathrm{burn}}$:\n    - 保持 $\\sigma$ 固定。\n    - 统计接受次数，以计算采样阶段的最终经验接受率。\n\n此过程将应用于三个测试用例中的每一个，使用指定的参数和随机种子。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def run_adaptive_mcmc(log_target_density, x0, sigma0, d, N_burn, N_sample, seed, a_star, c, t0):\n        \"\"\"\n        Runs the adaptive Metropolis MCMC algorithm for a single test case.\n\n        Args:\n            log_target_density (function): Function that computes the log of the target density.\n            x0 (np.ndarray): Initial position.\n            sigma0 (float): Initial proposal step size.\n            d (int): Dimension of the state space.\n            N_burn (int): Number of burn-in iterations.\n            N_sample (int): Number of sampling iterations.\n            seed (int): Random seed for reproducibility.\n            a_star (float): Target acceptance rate.\n            c (float): Parameter for the Robbins-Monro gain.\n            t0 (float): Parameter for the Robbins-Monro gain.\n        \n        Returns:\n            float: The empirical acceptance rate during the sampling phase.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        x_current = np.array(x0, dtype=float)\n        log_sigma = np.log(sigma0)\n        \n        log_pi_current = log_target_density(x_current)\n        \n        accepted_in_sampling = 0\n        total_iterations = N_burn + N_sample\n\n        for n in range(1, total_iterations + 1):\n            sigma = np.exp(log_sigma)\n            \n            # 1. Propose a new state\n            proposal = x_current + sigma * rng.normal(size=d)\n            \n            # 2. Compute acceptance probability\n            log_pi_proposal = log_target_density(proposal)\n            log_alpha = log_pi_proposal - log_pi_current\n            alpha = min(1.0, np.exp(log_alpha))\n\n            # 3. Accept or reject the proposal\n            if rng.uniform()  alpha:\n                x_current = proposal\n                log_pi_current = log_pi_proposal\n                accepted = True\n            else:\n                accepted = False\n\n            # 4. Adaptation during burn-in\n            if n = N_burn:\n                gamma_n = c / (n + t0)\n                log_sigma = log_sigma + gamma_n * (alpha - a_star)\n                # For stability, constrain log_sigma to a broad interval\n                log_sigma = np.clip(log_sigma, -10.0, 10.0)\n            # 5. Tally acceptances during sampling\n            else:\n                if accepted:\n                    accepted_in_sampling += 1\n                    \n        return accepted_in_sampling / N_sample\n\n    # Common parameters\n    target_acceptance_rate = 0.23\n    # Robbins-Monro parameters (chosen based on common practice)\n    c_rm = 1.0\n    t0_rm = 10.0\n\n    # Test Case A: 1D Standard Gaussian\n    def log_pi_A(x):\n        return -0.5 * x[0]**2\n        \n    rate_A = run_adaptive_mcmc(\n        log_target_density=log_pi_A,\n        x0=[0.0],\n        sigma0=0.001,\n        d=1,\n        N_burn=6000,\n        N_sample=12000,\n        seed=42,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case B: 5D Correlated Gaussian\n    d_B = 5\n    rho_B = 0.8\n    sigma_matrix_B = np.array([[rho_B**abs(i - j) for j in range(d_B)] for i in range(d_B)])\n    sigma_inv_B = np.linalg.inv(sigma_matrix_B)\n    def log_pi_B(x):\n        return -0.5 * x @ sigma_inv_B @ x\n\n    rate_B = run_adaptive_mcmc(\n        log_target_density=log_pi_B,\n        x0=np.zeros(d_B),\n        sigma0=10.0,\n        d=d_B,\n        N_burn=8000,\n        N_sample=12000,\n        seed=123,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    # Test Case C: 2D Softened Rosenbrock\n    def log_pi_C(x):\n        U = 100.0 * (x[1] - x[0]**2)**2 + (1.0 - x[0])**2\n        return -U / 20.0\n\n    rate_C = run_adaptive_mcmc(\n        log_target_density=log_pi_C,\n        x0=[0.0, 0.0],\n        sigma0=1.0,\n        d=2,\n        N_burn=12000,\n        N_sample=12000,\n        seed=2024,\n        a_star=target_acceptance_rate,\n        c=c_rm,\n        t0=t0_rm\n    )\n\n    results = [rate_A, rate_B, rate_C]\n    \n    # Format the final output string exactly as specified.\n    results_str = ','.join(f\"{r:.3f}\" for r in results)\n    print(f\"[{results_str}]\")\n\nsolve()\n```"
        }
    ]
}