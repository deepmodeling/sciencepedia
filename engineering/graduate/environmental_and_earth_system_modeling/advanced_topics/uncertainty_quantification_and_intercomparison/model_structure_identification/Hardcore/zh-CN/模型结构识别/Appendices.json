{
    "hands_on_practices": [
        {
            "introduction": "本练习探讨了从数据中辨识偏微分方程（PDE）结构的一个根本性挑战：数据的“信息丰富度”。在一个基于回归的框架中，模型项（如扩散项 $u_{xx}$ 或平流项 $u_{x}$）的可辨识性取决于其在数据采集过程中是否表现出线性无关的行为。此实践  揭示了边界条件和系统激励（excitation）如何深刻地影响这种无关性，从而决定了我们能否从根本上区分不同的物理过程。",
            "id": "3895645",
            "problem": "给定一个在一维空间区间 $x \\in [0,1]$ 和时间区间 $t \\in [0,1]$ 上的无量纲环境示踪剂场 $u(x,t)$。任务是评估一个偏微分方程 (PDE) 结构模型中的哪些候选项，在不同的边界条件 (BC) 和激励选择下是唯一可辨识的。其基本依据是一维空间中的质量守恒定律，该定律意味着任何标量示踪剂的物理真实演化都可以写成空间通量散度与局部源或汇的组合。候选结构被限制为在环境和地球系统建模中普遍存在的项：空间二阶导数 $u_{xx}$、空间一阶导数 $u_{x}$ 和零阶项 $u$。你必须仅使用数据 $u(x,t)$ 及其导数的有限差分近似来确定这些候选项的结构可辨识性。\n\n定义与约束：\n- 定义 PDE 候选库 $\\mathcal{L} = \\{u, u_{x}, u_{xx}\\}$。\n- 在此背景下，结构可辨识性意味着：对于一个项为线性的 PDE 模型，其系数乘以 $\\mathcal{L}$ 中的各项，一个项是可辨识的，当且仅当其在由 $\\mathcal{L}$ 构建的回归矩阵中对应的列不是其余列的线性组合。等价地，如果回归矩阵是满列秩的，则所有系数都是可辨识的；如果矩阵是秩亏的，则至少有一个系数是不可辨识的。你必须逐项确定可辨识性。\n- 导数近似必须在内部网格点上使用中心差分计算。激励函数 $u(x,t)$ 必须遵守边界条件；三角函数中的角度必须以弧度为单位。\n- 不要估计任何物理参数。仅根据由 $u$、$u_{x}$ 和 $u_{xx}$ 构建的列的线性无关性来确定可辨识性。\n\n计算流程：\n1. 使用 $[0,1]$ 上的 $N_x$ 个点的均匀空间网格和 $[0,1]$ 上的 $N_t$ 个点的均匀时间网格对域进行离散化。\n2. 对于每个测试案例，在网格上构建 $u(x,t)$，使其满足指定的边界条件。使用内部中心差分来近似 $u_{x}$、$u_{xx}$ 和 $u_{t}$，并将所有量限制在空间和时间的内部点上（即，排除需要单边差分的边界索引）。\n3. 通过将在内部时空点上求值的 $u_{xx}$、$u_{x}$ 和 $u$ 对应的列堆叠起来，构建回归矩阵 $\\Theta$。设 $\\Theta \\in \\mathbb{R}^{M \\times 3}$，其中 $M$ 是内部时空样本的数量。\n4. 通过检查 $\\mathcal{L}$ 中每个项的列是否在其他两列的张成空间中，来确定其结构可辨识性。如果一个列在数值上为零，或者其在其他列的张成空间上的最小二乘投影的相对残差小于预设的数值容差，则该列被认为是不可辨识的。否则，它是可辨识的。使用 $10^{-8}$ 的相对残差容差，并将相对范数小于 $10^{-12}$ 的任何列视为数值上为零。\n5. 你的程序必须为每个测试案例输出一个包含三个布尔值的列表 $[I_{xx}, I_{x}, I_{0}]$，分别表示 $u_{xx}$、$u_{x}$ 和 $u$ 项的可辨识性。\n\n测试套件：\n使用以下四个科学上现实且自洽的测试案例，它们涵盖了不同的边界条件和激励结构。三角函数中的所有角度都必须以弧度为单位。此问题中没有物理单位；所有量都是无量纲的。\n\n- 测试案例 1 (周期性 BC 下的通用“理想路径”)：$N_x = 128$，$N_t = 64$，周期性 BC，以及激励\n  $$u(x,t) = e^{-t}\\left(\\sin(2\\pi x) + \\tfrac{1}{2}\\sin(4\\pi x)\\right)。$$\n  这组合了两个空间傅里叶模式，使得 $u$ 和 $u_{xx}$ 不共线，且 $u_{x}$ 是独特的，从而促进了完全的可辨识性。\n\n- 测试案例 2 (周期性 BC 下由边界引起的共线性)：$N_x = 128$，$N_t = 64$，周期性 BC，以及激励\n  $$u(x,t) = e^{-t}\\sin(2\\pi x)。$$\n  在这里，对于该空间模式，$u_{xx} = -(2\\pi)^2 u$，这使得 $u$ 和 $u_{xx}$ 在整个时空上共线，从而无法分开辨识反应和扩散结构。\n\n- 测试案例 3 (使用多项式激励的狄利克雷零值 BC)：$N_x = 129$，$N_t = 64$，狄利克雷 BC，其中 $u(0,t)=0$ 和 $u(1,t)=0$，以及激励\n  $$u(x,t) = e^{-t}x(1-x)。$$\n  这满足了边界条件，并在内部为 $u$、$u_{x}$ 和 $u_{xx}$ 产生了线性无关的样本。\n\n- 测试案例 4 (使用空间常数激励的诺伊曼零通量 BC)：$N_x = 129$，$N_t = 64$，诺伊曼 BC，其中 $u_{x}(0,t)=0$ 和 $u_{x}(1,t)=0$，以及激励\n  $$u(x,t) = e^{-t}。$$\n  这导致 $u_{x} \\equiv 0$ 和 $u_{xx} \\equiv 0$，使得平流和扩散项不可辨识，而零阶项仍然可辨识。\n\n最终输出格式：\n你的程序应该生成单行输出，其中包含四个测试案例的结果，格式为一个由方括号括起来的逗号分隔列表，其中每个元素是对应测试案例的三个布尔值的列表。例如：\n$$[\\,[I_{xx}^{(1)},I_{x}^{(1)},I_{0}^{(1)}],\\,[I_{xx}^{(2)},I_{x}^{(2)},I_{0}^{(2)}],\\,[I_{xx}^{(3)},I_{x}^{(3)},I_{0}^{(3)}],\\,[I_{xx}^{(4)},I_{x}^{(4)},I_{0}^{(4)}]\\,]$$\n以单行 Python 列表字面量的形式打印。",
            "solution": "起点是一维标量示踪剂的质量守恒，它指出在一个小的控制体积内，示踪剂密度 $u(x,t)$ 的变化率等于由通量散度引起的净流入加上局部源或汇。将通量表示为 $J(x,t)$，源表示为 $S(x,t)$，则守恒声明为\n$$\\frac{\\partial u}{\\partial t} = -\\frac{\\partial J}{\\partial x} + S.$$\n在环境建模中，在没有外力作用的情况下，一个被广泛接受和基本的通量分解是菲克扩散分量和平流分量之和：\n$$J = -D\\frac{\\partial u}{\\partial x} + v\\,u,$$\n其中 $D$ 是扩散参数，$v$ 是平流速度。一个线性反应源通常表示为\n$$S = r\\,u,$$\n其中 $r$ 是反应参数。将这些代入守恒定律得到\n$$\\frac{\\partial u}{\\partial t} = D\\,\\frac{\\partial^2 u}{\\partial x^2} - v\\,\\frac{\\partial u}{\\partial x} + r\\,u.$$\n我们在这里不估计参数 $D$、$v$ 和 $r$；相反，我们从数据中评估项 $u_{xx}$、$u_{x}$ 和 $u$ 的结构可辨识性。这是一种有原则的方法，原因在于，在线性项表示下，项系数的可解释性和唯一性问题简化为从候选项库在观测时空样本上求值构建的回归矩阵的列的线性无关性问题。\n\n给定二维网格上的采样场 $u(x_i,t_j)$，有限差分提供了所需导数的近似值。我们为空间和时间都选择中心差分，以最小化偏差并提高精度：\n- 对于内部空间点 $x_i$（其中 $i=1,\\dots,N_x-2$），一阶导数近似为\n$$u_{x}(x_i,t_j) \\approx \\frac{u(x_{i+1},t_j) - u(x_{i-1},t_j)}{2\\Delta x},$$\n二阶导数近似为\n$$u_{xx}(x_i,t_j) \\approx \\frac{u(x_{i+1},t_j) - 2u(x_i,t_j) + u(x_{i-1},t_j)}{\\Delta x^2},$$\n其中 $\\Delta x$ 是空间网格间距。\n- 对于内部时间点 $t_j$（其中 $j=1,\\dots,N_t-2$），时间导数近似为\n$$u_{t}(x_i,t_j) \\approx \\frac{u(x_i,t_{j+1}) - u(x_i,t_{j-1})}{2\\Delta t},$$\n其中 $\\Delta t$ 是时间步长。\n\n当我们将注意力限制在内部点时，这些近似与边界条件是一致的；激励函数 $u(x,t)$ 被构造成精确满足所述边界条件，这确保了物理真实性，而无需在边界处使用单边差分。\n\n为了构建回归矩阵，我们将 $u_{xx}$、$u_{x}$ 和 $u$ 的内部时空样本堆叠成列：\n$$\\Theta = \\begin{bmatrix}\n\\vdots  \\vdots  \\vdots \\\\\nu_{xx}(x_i,t_j)  u_{x}(x_i,t_j)  u(x_i,t_j) \\\\\n\\vdots  \\vdots  \\vdots\n\\end{bmatrix} \\in \\mathbb{R}^{M \\times 3},$$\n其中 $M$ 是内部时空样本的数量。\n\n结构可辨识性准则源于线性代数：\n- 如果 $\\mathrm{rank}(\\Theta) = 3$，则所有项都是可辨识的；原则上，每个系数都可以通过最小二乘法从数据中唯一确定，因为这些列是线性无关的。\n- 如果 $\\mathrm{rank}(\\Theta)  3$，则至少有一列是其他列的线性组合（或数值上为零），这意味着对应的系数是不可辨识的。更精细地说，如果一个给定项的列位于其余列的张成空间中，则该项是不可辨识的。反之，如果一个项的列不在其他列的张成空间中，则该项是可辨识的。\n\n在有限精度算术中逐项稳健地评估可辨识性：\n1. 计算每列的相对范数。如果相对范数低于一个微小的阈值（例如，$10^{-12}$），则将该列视为数值上为零，并声明该项不可辨识。\n2. 对于每一列 $j$，求解最小二乘问题\n$$\\min_{\\beta}\\left\\| \\Theta_{\\cdot j} - \\Theta_{\\cdot,-j}\\,\\beta \\right\\|_2,$$\n其中 $\\Theta_{\\cdot j}$ 表示第 $j$ 列，$\\Theta_{\\cdot,-j}$ 表示其他两列组成的矩阵。计算相对残差\n$$\\rho_j = \\frac{\\left\\| \\Theta_{\\cdot j} - \\Theta_{\\cdot,-j}\\,\\hat{\\beta} \\right\\|_2}{\\left\\| \\Theta_{\\cdot j} \\right\\|_2}.$$\n如果 $\\rho_j  10^{-8}$，则声明第 $j$ 列是相关的，并且对应的项是不可辨识的；否则，声明它是可辨识的。\n\n为什么边界条件很重要：\n- 在周期性或狄利克雷边界条件下，拉普拉斯算子的空间特征函数，例如 $\\sin(k\\pi x)$，满足 $u_{xx} = -\\lambda u$，其中对于狄利克雷条件 $\\lambda = (k\\pi)^2$，对于在 $[0,1]$ 上的周期性模式 $\\lambda = (2\\pi k)^2$。如果激励 $u$ 是一个随时间调制的单一特征函数，那么对应于 $u$ 和 $u_{xx}$ 的列是共线的，使得扩散和反应在结构上不可分离。添加多个不同的特征模式可以打破这种比例关系并恢复独立性。\n- 在诺伊曼零通量边界条件下，一个空间常数激励会产生 $u_{x} \\equiv 0$ 和 $u_{xx} \\equiv 0$，立即将平流和扩散从可辨识集合中移除，而零阶项仍然可辨识。\n- 满足狄利克雷边界条件的多项式激励（例如，$u = e^{-t}x(1-x)$）会为 $u$、$u_{x}$ 和 $u_{xx}$ 产生不同的空间模式，从而促进完全可辨识性。\n\n将该流程应用于测试套件：\n- 测试案例 1 组合了两个周期性傅里叶模式，使得 $u$ 和 $u_{xx}$ 不共线，且 $u_{x}$ 是独特的。算法将发现所有三项的列是独立的，并返回 $[{\\rm True},{\\rm True},{\\rm True}]$。\n- 测试案例 2 使用单个周期性傅里叶模式，因此 $u_{xx}$ 是 $u$ 的标量倍。最小二乘投影将在两个依赖方向上都产生接近零的残差，从而声明 $u_{xx}$ 和 $u$ 不可辨识，而 $u_{x}$ 仍然可辨识。结果是 $[{\\rm False},{\\rm True},{\\rm False}]$。\n- 测试案例 3 在狄利克雷边界条件下使用多项式；$u$、$u_{x}$ 和 $u_{xx}$ 的空间模式在内部点上是不同的，导致结果为 $[{\\rm True},{\\rm True},{\\rm True}]$。\n- 测试案例 4 在诺伊曼边界条件下使用空间常数激励；$u_{x}$ 和 $u_{xx}$ 的列在数值上为零，因此不可辨识，而 $u$ 列保持独立，导致结果为 $[{\\rm False},{\\rm False},{\\rm True}]$。\n\n程序实现了上述有限差分近似，构建了 $\\Theta$，并使用指定的数值容差执行可辨识性检查。它按照四个测试案例的顺序，将每个测试案例的三个布尔值列表作为单行 Python 列表字面量输出。",
            "answer": "```python\n# Python 3.12\n# Libraries: numpy 1.23.5, scipy 1.11.4 (not used)\nimport numpy as np\n\ndef generate_u(case, x, t):\n    \"\"\"\n    Generate u(x,t) for a given test case definition.\n    case: dict with keys 'bc' and 'excitation'\n    x: 1D array of spatial points\n    t: 1D array of time points\n    Returns u as a 2D array of shape (Nx, Nt) where Nx=len(x), Nt=len(t).\n    \"\"\"\n    X, T = np.meshgrid(x, t, indexing='ij')\n    exc = case['excitation']\n    if exc == 'periodic_mixture':\n        u = np.exp(-T) * (np.sin(2*np.pi*X) + 0.5*np.sin(4*np.pi*X))\n        # Periodic BC is satisfied by construction.\n    elif exc == 'periodic_single':\n        u = np.exp(-T) * np.sin(2*np.pi*X)\n        # Periodic BC satisfied.\n    elif exc == 'dirichlet_quadratic':\n        u = np.exp(-T) * X * (1.0 - X)\n        # Dirichlet BC: u(0,t)=0 and u(1,t)=0 satisfied.\n    elif exc == 'neumann_constant':\n        u = np.exp(-T) * np.ones_like(X)\n        # Neumann BC: ux=0 at boundaries satisfied since u is constant in space.\n    else:\n        raise ValueError(\"Unknown excitation type\")\n    return u\n\ndef finite_differences(u, x, t):\n    \"\"\"\n    Compute central-difference approximations of ux, uxx, ut on interior points.\n    Returns flattened vectors for the interior grid: ux_vec, uxx_vec, u_vec\n    \"\"\"\n    dx = x[1] - x[0]\n    dt = t[1] - t[0]\n\n    # Interior indices\n    ix0, ix1 = 1, len(x) - 2\n    it0, it1 = 1, len(t) - 2\n\n    # Slicing interior\n    u_int = u[ix0:ix1+1, it0:it1+1]\n\n    # Spatial derivatives using central differences on interior spatial points\n    ux_int = (u[ix0+1:ix1+2, it0:it1+1] - u[ix0-1:ix1, it0:it1+1]) / (2.0 * dx)\n    uxx_int = (u[ix0+1:ix1+2, it0:it1+1] - 2.0*u[ix0:ix1+1, it0:it1+1] + u[ix0-1:ix1, it0:it1+1]) / (dx*dx)\n\n    # Time derivative using central differences on interior time points\n    ut_int = (u[ix0:ix1+1, it0+1:it1+2] - u[ix0:ix1+1, it0-1:it1]) / (2.0 * dt)\n\n    # To align shapes, restrict u_int, ux_int, uxx_int and ut_int to common interior\n    # u_int is already (ix1-ix0+1, it1-it0+1)\n    # ux_int and uxx_int have same shape as u_int\n    # ut_int has same shape as u_int\n\n    # Flatten vectors\n    u_vec = u_int.reshape(-1)\n    ux_vec = ux_int.reshape(-1)\n    uxx_vec = uxx_int.reshape(-1)\n    ut_vec = ut_int.reshape(-1)\n\n    return ux_vec, uxx_vec, u_vec, ut_vec\n\ndef term_identifiability(theta, tol_zero=1e-12, tol_dep=1e-8):\n    \"\"\"\n    Determine identifiability of each column in theta by checking if the column is\n    numerically zero or lies in the span of the other columns.\n    Returns a list of booleans [I_xx, I_x, I_0] for columns in order [uxx, ux, u].\n    \"\"\"\n    M, K = theta.shape\n    assert K == 3, \"Theta must have 3 columns for [uxx, ux, u]\"\n    id_flags = []\n\n    # Pre-compute norms\n    col_norms = np.linalg.norm(theta, axis=0)\n    # Relative norms (scaled by overall matrix norm to guard)\n    mat_norm = np.linalg.norm(theta)\n    rel_norms = col_norms / (mat_norm + 1e-30)\n\n    for j in range(K):\n        # Zero column check\n        if rel_norms[j]  tol_zero:\n            id_flags.append(False)\n            continue\n        # Build matrix of other columns\n        other_indices = [i for i in range(K) if i != j]\n        Theta_others = theta[:, other_indices]\n        col_j = theta[:, j]\n\n        # If other columns are all near-zero, then col_j is independent\n        if np.linalg.matrix_rank(Theta_others) == 0 and np.linalg.norm(Theta_others)  tol_zero:\n            id_flags.append(True)\n            continue\n\n        # Least squares projection of col_j onto span of others\n        beta, *_ = np.linalg.lstsq(Theta_others, col_j, rcond=None)\n        residual = col_j - Theta_others @ beta\n        r_rel = np.linalg.norm(residual) / (np.linalg.norm(col_j) + 1e-30)\n        # If residual is tiny, column is dependent -> not identifiable\n        id_flags.append(r_rel >= tol_dep)\n    return id_flags\n\ndef run_case(case):\n    Nx = case['Nx']\n    Nt = case['Nt']\n    # Uniform grids on [0,1]\n    x = np.linspace(0.0, 1.0, Nx)\n    t = np.linspace(0.0, 1.0, Nt)\n    u = generate_u(case, x, t)\n    ux_vec, uxx_vec, u_vec, ut_vec = finite_differences(u, x, t)\n    # Build Theta with columns [uxx, ux, u]\n    Theta = np.column_stack([uxx_vec, ux_vec, u_vec])\n    # Determine identifiability\n    id_flags = term_identifiability(Theta, tol_zero=1e-12, tol_dep=1e-8)\n    return id_flags\n\ndef solve():\n    # Define test cases from the problem statement\n    test_cases = [\n        # Test Case 1: Periodic BC, mixture of Fourier modes\n        {'bc': 'periodic', 'excitation': 'periodic_mixture', 'Nx': 128, 'Nt': 64},\n        # Test Case 2: Periodic BC, single Fourier mode\n        {'bc': 'periodic', 'excitation': 'periodic_single', 'Nx': 128, 'Nt': 64},\n        # Test Case 3: Dirichlet zero value BC, polynomial excitation\n        {'bc': 'dirichlet', 'excitation': 'dirichlet_quadratic', 'Nx': 129, 'Nt': 64},\n        # Test Case 4: Neumann zero-flux BC, spatially constant excitation\n        {'bc': 'neumann', 'excitation': 'neumann_constant', 'Nx': 129, 'Nt': 64},\n    ]\n\n    results = []\n    for case in test_cases:\n        res = run_case(case)\n        results.append(res)\n\n    # Print single-line output in the exact required format\n    # e.g., [[True,True,True],[False,True,False],...]\n    def list_to_str(lst):\n        return \"[\" + \",\".join([\"True\" if v else \"False\" for v in lst]) + \"]\"\n    print(\"[\" + \",\".join([list_to_str(r) for r in results]) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "在确保数据足以进行模型辨识后，下一步是应用有效的算法来发现控制方程。本练习  介绍了一种先进的数据驱动发现技术：分组稀疏回归。通过求解一个分组LASSO（Least Absolute Shrinkage and Selection Operator）问题，我们可以从一个包含多个候选物理过程（如平流、扩散和反应）的库中自动选择出那些在结构上存在的项，从而揭示潜在的动力学规律。",
            "id": "3895649",
            "problem": "考虑一个守恒标量场 $c(\\boldsymbol{x}, t)$ 的二维平流-扩散-反应过程，该过程由质量守恒和本构关系支配，从而得到典型的输运形式\n$$\n\\frac{\\partial c}{\\partial t} + \\nabla \\cdot (\\boldsymbol{u} c) = \\nabla \\cdot \\left(D \\nabla c \\right) + R(c),\n$$\n其中 $\\boldsymbol{u}$ 是速度场，$D$ 是扩散系数，$R(c)$ 是一个反应项。在环境和地球系统建模的数据驱动模型结构识别中，人们构建一个算子库，并拟合一个在算子系数上呈线性的参数化模型。聚合时空样本会得到以下形式的回归：\n$$\n\\boldsymbol{y} = X_{\\mathrm{adv}} \\boldsymbol{\\beta}_{\\mathrm{adv}} + X_{\\mathrm{diff}} \\boldsymbol{\\beta}_{\\mathrm{diff}} + X_{\\mathrm{react}} \\boldsymbol{\\beta}_{\\mathrm{react}} + \\boldsymbol{\\varepsilon},\n$$\n其中 $\\boldsymbol{y} \\in \\mathbb{R}^{n}$ 是 $c$ 的测量时间趋势，而 $X_{\\mathrm{adv}} \\in \\mathbb{R}^{n \\times d_{\\mathrm{adv}}}$、$X_{\\mathrm{diff}} \\in \\mathbb{R}^{n \\times d_{\\mathrm{diff}}}$ 和 $X_{\\mathrm{react}} \\in \\mathbb{R}^{n \\times d_{\\mathrm{react}}}$ 分别汇集了平流、扩散和反应的求值后的算子模板。为了识别哪些算子在结构上存在，我们使用最小绝对收缩和选择算子 (LASSO) 的组形式，提出了一个组稀疏估计器：\n$$\n\\min_{\\boldsymbol{\\beta}_{\\mathrm{adv}},\\,\\boldsymbol{\\beta}_{\\mathrm{diff}},\\,\\boldsymbol{\\beta}_{\\mathrm{react}}} \\;\\; \\frac{1}{2n} \\left\\| \\boldsymbol{y} - X_{\\mathrm{adv}} \\boldsymbol{\\beta}_{\\mathrm{adv}} - X_{\\mathrm{diff}} \\boldsymbol{\\beta}_{\\mathrm{diff}} - X_{\\mathrm{react}} \\boldsymbol{\\beta}_{\\mathrm{react}} \\right\\|_{2}^{2} + \\lambda \\left( w_{\\mathrm{adv}} \\left\\|\\boldsymbol{\\beta}_{\\mathrm{adv}}\\right\\|_{2} + w_{\\mathrm{diff}} \\left\\|\\boldsymbol{\\beta}_{\\mathrm{diff}}\\right\\|_{2} + w_{\\mathrm{react}} \\left\\|\\boldsymbol{\\beta}_{\\mathrm{react}}\\right\\|_{2} \\right),\n$$\n其中 $\\lambda \\geq 0$ 是一个正则化水平，$w_{\\mathrm{adv}}$、$w_{\\mathrm{diff}}$ 和 $w_{\\mathrm{react}}$ 是正的组权重。假设以下科学上一致的预处理和数据条件成立：\n- 聚合样本的数量为 $n = 50$。\n- $X_{\\mathrm{adv}}$、$X_{\\mathrm{diff}}$ 和 $X_{\\mathrm{react}}$ 的列集已经被正交归一化和相互正交化，即对于每个组 $g \\in \\{\\mathrm{adv}, \\mathrm{diff}, \\mathrm{react}\\}$，有 $(1/n) X_{g}^{\\top} X_{g} = I_{d_{g}}$，并且对于 $g \\neq h$，有 $X_{g}^{\\top} X_{h} = 0$。\n- 组维度为 $d_{\\mathrm{adv}} = 2$，$d_{\\mathrm{diff}} = 1$ 和 $d_{\\mathrm{react}} = 3$。\n- 选择组权重为 $w_{g} = \\sqrt{d_{g}}$，以平衡不同大小组之间的惩罚。\n- 根据经验计算的算子-响应内积（来自数据和正交归一化设计）为 $X_{\\mathrm{adv}}^{\\top} \\boldsymbol{y} = \\begin{pmatrix} 9 \\\\ -3 \\end{pmatrix}$，$X_{\\mathrm{diff}}^{\\top} \\boldsymbol{y} = \\begin{pmatrix} 22 \\end{pmatrix}$ 和 $X_{\\mathrm{react}}^{\\top} \\boldsymbol{y} = \\begin{pmatrix} 4 \\\\ -2 \\\\ 1 \\end{pmatrix}$。\n\n从守恒定律和最小二乘数据拟合原理出发，推导出一个组被组惩罚项排除的充要选择条件，并用它们来确定最小正则化水平 $\\lambda_{\\min}$（无量纲），使得在上述问题的最优化解处，只有扩散算子组保持活跃，而平流和反应组被排除。将最终答案表示为精确的解析表达式，并以无量纲单位表示。无需四舍五入。最终答案必须是单个实值表达式。",
            "solution": "### 第1步：问题验证\n\n#### 提取已知条件\n- **控制方程**：其潜在的物理过程由标量场 $c(\\boldsymbol{x}, t)$ 的平流-扩散-反应方程描述：\n$$\n\\frac{\\partial c}{\\partial t} + \\nabla \\cdot (\\boldsymbol{u} c) = \\nabla \\cdot \\left(D \\nabla c \\right) + R(c)\n$$\n- **线性回归模型**：离散化后的问题被建模为一个线性回归：\n$$\n\\boldsymbol{y} = X_{\\mathrm{adv}} \\boldsymbol{\\beta}_{\\mathrm{adv}} + X_{\\mathrm{diff}} \\boldsymbol{\\beta}_{\\mathrm{diff}} + X_{\\mathrm{react}} \\boldsymbol{\\beta}_{\\mathrm{react}} + \\boldsymbol{\\varepsilon}\n$$\n- **优化问题 (组 LASSO)**：通过求解以下问题找到系数：\n$$\n\\min_{\\boldsymbol{\\beta}_{\\mathrm{adv}},\\,\\boldsymbol{\\beta}_{\\mathrm{diff}},\\,\\boldsymbol{\\beta}_{\\mathrm{react}}} \\;\\; \\frac{1}{2n} \\left\\| \\boldsymbol{y} - X_{\\mathrm{adv}} \\boldsymbol{\\beta}_{\\mathrm{adv}} - X_{\\mathrm{diff}} \\boldsymbol{\\beta}_{\\mathrm{diff}} - X_{\\mathrm{react}} \\boldsymbol{\\beta}_{\\mathrm{react}} \\right\\|_{2}^{2} + \\lambda \\left( w_{\\mathrm{adv}} \\left\\|\\boldsymbol{\\beta}_{\\mathrm{adv}}\\right\\|_{2} + w_{\\mathrm{diff}} \\left\\|\\boldsymbol{\\beta}_{\\mathrm{diff}}\\right\\|_{2} + w_{\\mathrm{react}} \\left\\|\\boldsymbol{\\beta}_{\\mathrm{react}}\\right\\|_{2} \\right)\n$$\n- **数据和参数**：\n  - 样本数量：$n = 50$。\n  - 正交性条件：对于每个组 $g \\in \\{\\mathrm{adv}, \\mathrm{diff}, \\mathrm{react}\\}$，有 $(1/n) X_{g}^{\\top} X_{g} = I_{d_{g}}$。对于任意两个不同的组 $g \\neq h$，有 $X_{g}^{\\top} X_{h} = 0$。\n  - 组维度：$d_{\\mathrm{adv}} = 2$, $d_{\\mathrm{diff}} = 1$, $d_{\\mathrm{react}} = 3$。\n  - 组权重：$w_{g} = \\sqrt{d_{g}}$。\n  - 经验内积：\n    - $X_{\\mathrm{adv}}^{\\top} \\boldsymbol{y} = \\begin{pmatrix} 9 \\\\ -3 \\end{pmatrix}$\n    - $X_{\\mathrm{diff}}^{\\top} \\boldsymbol{y} = \\begin{pmatrix} 22 \\end{pmatrix}$\n    - $X_{\\mathrm{react}}^{\\top} \\boldsymbol{y} = \\begin{pmatrix} 4 \\\\ -2 \\\\ 1 \\end{pmatrix}$\n- **目标**：找到最小的正则化水平 $\\lambda_{\\min}$，使得只有扩散组是活跃的（$\\boldsymbol{\\beta}_{\\mathrm{diff}} \\neq \\boldsymbol{0}$），而平流和反应组被排除（$\\boldsymbol{\\beta}_{\\mathrm{adv}} = \\boldsymbol{0}$, $\\boldsymbol{\\beta}_{\\mathrm{react}} = \\boldsymbol{0}$）。\n\n#### 使用提取的已知条件进行验证\n1.  **科学性或事实合理性**：该问题具有科学依据。它描述了科学机器学习和数据驱动建模中的一种标准且前沿的方法：使用组稀疏回归对动力系统进行稀疏辨识。其物理基础（平流-扩散-反应）是输运现象中的一个基本概念。\n2.  **适定性和一致性**：该问题是适定的。目标函数是一个严格凸的可微函数（最小二乘项，由于正交性条件隐含了满列秩）和一个凸的、不可微的函数（组 LASSO 惩罚项）之和。这保证了唯一极小值的存在。所有给定的数据和条件在数学上都是一致的。“正交归一化和相互正交化”的条件是一个强的、简化的假设，但其表述清晰且在数学上是合理的。\n3.  **客观性和清晰度**：问题以精确的数学语言陈述，没有歧义或主观陈述。\n\n#### 结论\n该问题是有效的。它是一个定义明确的数学优化问题，植根于有效的科学背景之中。\n\n### 第2步：解题推导\n\n设目标函数为 $J(\\boldsymbol{\\beta})$，其中 $\\boldsymbol{\\beta}$ 是所有组系数向量的拼接。\n$$\nJ(\\boldsymbol{\\beta}) = \\frac{1}{2n} \\left\\| \\boldsymbol{y} - \\sum_{g} X_g \\boldsymbol{\\beta}_g \\right\\|_{2}^{2} + \\lambda \\sum_{g} w_g \\|\\boldsymbol{\\beta}_g\\|_2\n$$\n设 $\\boldsymbol{\\beta}^*$ 是最小化 $J(\\boldsymbol{\\beta})$ 的最优解。根据 Karush-Kuhn-Tucker (KKT) 条件，在最优解 $\\boldsymbol{\\beta}^*$ 处，$J$ 的次梯度必须包含零向量。由于惩罚项的可分性和设计矩阵的正交性，我们可以独立地分析每个组 $g \\in \\{\\mathrm{adv}, \\mathrm{diff}, \\mathrm{react}\\}$ 的最优性条件。\n\n特定组 $g$ 的平稳性条件是：\n$$\n\\boldsymbol{0} \\in \\nabla_{\\boldsymbol{\\beta}_g} \\left( \\frac{1}{2n} \\left\\| \\boldsymbol{y} - \\sum_{h} X_h \\boldsymbol{\\beta}_h \\right\\|_{2}^{2} \\right)\\bigg|_{\\boldsymbol{\\beta}=\\boldsymbol{\\beta}^*} + \\partial \\left( \\lambda w_g \\|\\boldsymbol{\\beta}_g\\|_2 \\right)\\bigg|_{\\boldsymbol{\\beta}_g=\\boldsymbol{\\beta}_g^*}\n$$\n首先，我们计算最小二乘项关于 $\\boldsymbol{\\beta}_g$ 的梯度：\n$$\n\\nabla_{\\boldsymbol{\\beta}_g} \\left( \\frac{1}{2n} \\| \\boldsymbol{y} - X \\boldsymbol{\\beta} \\|_2^2 \\right) = -\\frac{1}{n} X_g^{\\top} (\\boldsymbol{y} - \\sum_{h} X_h \\boldsymbol{\\beta}_h)\n$$\n使用给定的正交性条件，$g \\neq h$ 时 $X_g^{\\top} X_h = 0$ 且 $X_g^{\\top} X_g = n I_{d_g}$：\n$$\n\\nabla_{\\boldsymbol{\\beta}_g} \\left( \\frac{1}{2n} \\| \\boldsymbol{y} - X \\boldsymbol{\\beta} \\|_2^2 \\right) = -\\frac{1}{n} X_g^{\\top} \\boldsymbol{y} + \\frac{1}{n} X_g^{\\top} X_g \\boldsymbol{\\beta}_g = -\\frac{1}{n} X_g^{\\top} \\boldsymbol{y} + \\boldsymbol{\\beta}_g\n$$\n组 $g$ 的惩罚项的次梯度为：\n$$\n\\partial \\left( \\lambda w_g \\|\\boldsymbol{\\beta}_g\\|_2 \\right) = \\begin{cases} \\{ \\lambda w_g \\frac{\\boldsymbol{\\beta}_g}{\\|\\boldsymbol{\\beta}_g\\|_2} \\}  \\text{if } \\boldsymbol{\\beta}_g \\neq \\boldsymbol{0} \\\\ \\{ \\boldsymbol{v} \\in \\mathbb{R}^{d_g} : \\|\\boldsymbol{v}\\|_2 \\le \\lambda w_g \\}  \\text{if } \\boldsymbol{\\beta}_g = \\boldsymbol{0} \\end{cases}\n$$\n现在，我们为一个组被包含在模型中或从模型中排除建立充要条件。\n\n**组排除条件 ($\\boldsymbol{\\beta}_g^* = \\boldsymbol{0}$)**\n如果组 $g$ 的最优系数向量是零向量，即 $\\boldsymbol{\\beta}_g^* = \\boldsymbol{0}$，则 KKT 条件变为：\n$$\n\\boldsymbol{0} \\in -\\frac{1}{n} X_g^{\\top} \\boldsymbol{y} + \\boldsymbol{0} + \\{ \\boldsymbol{v} : \\|\\boldsymbol{v}\\|_2 \\le \\lambda w_g \\}\n$$\n这等价于：\n$$\n\\frac{1}{n} X_g^{\\top} \\boldsymbol{y} \\in \\{ \\boldsymbol{v} : \\|\\boldsymbol{v}\\|_2 \\le \\lambda w_g \\}\n$$\n取欧几里得范数，我们得到组 $g$ 被排除的条件：\n$$\n\\left\\| \\frac{1}{n} X_g^{\\top} \\boldsymbol{y} \\right\\|_2 \\le \\lambda w_g\n$$\n\n**组包含条件 ($\\boldsymbol{\\beta}_g^* \\neq \\boldsymbol{0}$)**\n如果最优系数向量非零，即 $\\boldsymbol{\\beta}_g^* \\neq \\boldsymbol{0}$，则次梯度是单值的，KKT 条件是一个等式：\n$$\n\\boldsymbol{0} = -\\frac{1}{n} X_g^{\\top} \\boldsymbol{y} + \\boldsymbol{\\beta}_g^* + \\lambda w_g \\frac{\\boldsymbol{\\beta}_g^*}{\\|\\boldsymbol{\\beta}_g^*\\|_2}\n$$\n重新整理可得：\n$$\n\\frac{1}{n} X_g^{\\top} \\boldsymbol{y} = \\boldsymbol{\\beta}_g^* \\left(1 + \\frac{\\lambda w_g}{\\|\\boldsymbol{\\beta}_g^*\\|_2}\\right)\n$$\n对两边取范数：\n$$\n\\left\\| \\frac{1}{n} X_g^{\\top} \\boldsymbol{y} \\right\\|_2 = \\left\\| \\boldsymbol{\\beta}_g^* \\left(1 + \\frac{\\lambda w_g}{\\|\\boldsymbol{\\beta}_g^*\\|_2}\\right) \\right\\|_2 = \\|\\boldsymbol{\\beta}_g^*\\|_2 + \\lambda w_g\n$$\n由于 $\\|\\boldsymbol{\\beta}_g^*\\|_2 > 0$，因此组 $g$ 保持活跃的条件是：\n$$\n\\left\\| \\frac{1}{n} X_g^{\\top} \\boldsymbol{y} \\right\\|_2 > \\lambda w_g\n$$\n这些推导出的条件是问题所要求的充要选择标准。\n\n**应用条件寻找 $\\lambda_{\\min}$**\n我们需要一个正则化水平 $\\lambda$，使得平流和反应组被排除，而扩散组保持活跃。这可以转化为以下不等式组：\n1.  平流组被排除：$\\left\\| \\frac{1}{n} X_{\\mathrm{adv}}^{\\top} \\boldsymbol{y} \\right\\|_2 \\le \\lambda w_{\\mathrm{adv}} \\implies \\lambda \\ge \\frac{1}{w_{\\mathrm{adv}}} \\left\\| \\frac{1}{n} X_{\\mathrm{adv}}^{\\top} \\boldsymbol{y} \\right\\|_2$\n2.  反应组被排除：$\\left\\| \\frac{1}{n} X_{\\mathrm{react}}^{\\top} \\boldsymbol{y} \\right\\|_2 \\le \\lambda w_{\\mathrm{react}} \\implies \\lambda \\ge \\frac{1}{w_{\\mathrm{react}}} \\left\\| \\frac{1}{n} X_{\\mathrm{react}}^{\\top} \\boldsymbol{y} \\right\\|_2$\n3.  扩散组保持活跃：$\\left\\| \\frac{1}{n} X_{\\mathrm{diff}}^{\\top} \\boldsymbol{y} \\right\\|_2 > \\lambda w_{\\mathrm{diff}} \\implies \\lambda  \\frac{1}{w_{\\mathrm{diff}}} \\left\\| \\frac{1}{n} X_{\\mathrm{diff}}^{\\top} \\boldsymbol{y} \\right\\|_2$\n\n我们将每个组 $g$ 的 $\\lambda$ 的临界值定义为 $\\lambda_g^{crit} = \\frac{1}{w_g n} \\|X_g^{\\top} \\boldsymbol{y}\\|_2$。这些条件变为：\n$$\n\\lambda \\ge \\lambda_{\\mathrm{adv}}^{crit} \\quad \\text{and} \\quad \\lambda \\ge \\lambda_{\\mathrm{react}}^{crit} \\quad \\text{and} \\quad \\lambda  \\lambda_{\\mathrm{diff}}^{crit}\n$$\n将这些结合起来，我们得到：\n$$\n\\max(\\lambda_{\\mathrm{adv}}^{crit}, \\lambda_{\\mathrm{react}}^{crit}) \\le \\lambda  \\lambda_{\\mathrm{diff}}^{crit}\n$$\n问题要求满足这些条件的最小正则化水平 $\\lambda_{\\min}$。这是该区间的下界：\n$$\n\\lambda_{\\min} = \\max(\\lambda_{\\mathrm{adv}}^{crit}, \\lambda_{\\mathrm{react}}^{crit})\n$$\n现在我们使用给定的数据计算这些临界值。\n样本数量为 $n=50$。组权重为 $w_{\\mathrm{adv}} = \\sqrt{d_{\\mathrm{adv}}} = \\sqrt{2}$，$w_{\\mathrm{diff}} = \\sqrt{d_{\\mathrm{diff}}} = \\sqrt{1} = 1$，以及 $w_{\\mathrm{react}} = \\sqrt{d_{\\mathrm{react}}} = \\sqrt{3}$。\n\n首先，计算内积的范数：\n- $\\|X_{\\mathrm{adv}}^{\\top} \\boldsymbol{y}\\|_2 = \\left\\| \\begin{pmatrix} 9 \\\\ -3 \\end{pmatrix} \\right\\|_2 = \\sqrt{9^2 + (-3)^2} = \\sqrt{81 + 9} = \\sqrt{90} = 3\\sqrt{10}$\n- $\\|X_{\\mathrm{diff}}^{\\top} \\boldsymbol{y}\\|_2 = \\left\\| \\begin{pmatrix} 22 \\end{pmatrix} \\right\\|_2 = |22| = 22$\n- $\\|X_{\\mathrm{react}}^{\\top} \\boldsymbol{y}\\|_2 = \\left\\| \\begin{pmatrix} 4 \\\\ -2 \\\\ 1 \\end{pmatrix} \\right\\|_2 = \\sqrt{4^2 + (-2)^2 + 1^2} = \\sqrt{16 + 4 + 1} = \\sqrt{21}$\n\n现在，计算临界 $\\lambda$ 值：\n- $\\lambda_{\\mathrm{adv}}^{crit} = \\frac{1}{w_{\\mathrm{adv}} n} \\|X_{\\mathrm{adv}}^{\\top} \\boldsymbol{y}\\|_2 = \\frac{1}{\\sqrt{2} \\cdot 50} (3\\sqrt{10}) = \\frac{3\\sqrt{5}}{50}$\n- $\\lambda_{\\mathrm{diff}}^{crit} = \\frac{1}{w_{\\mathrm{diff}} n} \\|X_{\\mathrm{diff}}^{\\top} \\boldsymbol{y}\\|_2 = \\frac{1}{1 \\cdot 50} (22) = \\frac{22}{50}$\n- $\\lambda_{\\mathrm{react}}^{crit} = \\frac{1}{w_{\\mathrm{react}} n} \\|X_{\\mathrm{react}}^{\\top} \\boldsymbol{y}\\|_2 = \\frac{1}{\\sqrt{3} \\cdot 50} (\\sqrt{21}) = \\frac{\\sqrt{7}}{50}$\n\n我们需要找到 $\\lambda_{\\min} = \\max\\left(\\frac{3\\sqrt{5}}{50}, \\frac{\\sqrt{7}}{50}\\right)$。为了比较这两个值，我们比较它们的分子 $3\\sqrt{5}$ 和 $\\sqrt{7}$。我们将两者平方：\n- $(3\\sqrt{5})^2 = 9 \\times 5 = 45$\n- $(\\sqrt{7})^2 = 7$\n因为 $45 > 7$，所以我们有 $3\\sqrt{5} > \\sqrt{7}$。因此，$\\lambda_{\\mathrm{adv}}^{crit} > \\lambda_{\\mathrm{react}}^{crit}$。\n\n最小正则化水平是：\n$$\n\\lambda_{\\min} = \\lambda_{\\mathrm{adv}}^{crit} = \\frac{3\\sqrt{5}}{50}\n$$\n我们必须验证这个值仍然允许扩散组保持活跃，即 $\\lambda_{\\min}  \\lambda_{\\mathrm{diff}}^{crit}$：\n$$\n\\frac{3\\sqrt{5}}{50}  \\frac{22}{50}\n$$\n这等价于检查是否 $3\\sqrt{5}  22$。对两边进行平方得到 $(3\\sqrt{5})^2 = 45$ 和 $22^2 = 484$。因为 $45  484$，该不等式成立。因此，解是一致的。\n\n最小正则化水平是这样一个点，在该点平流组刚好被排除，而反应组已经被排除，扩散组则保持活跃。",
            "answer": "$$\\boxed{\\frac{3\\sqrt{5}}{50}}$$"
        },
        {
            "introduction": "真实世界的环境系统往往包含无法直接测量的“潜变量”（latent variables），例如未被监测的生物过程或季节性驱动力。本练习  探讨了在这种情况下如何进行模型结构辨识。通过引入状态空间表示和可观测性（observability）这一核心概念，您将学习如何从数学上严格判断一个包含潜变量的增广模型结构是否可以从有限的输出数据中被唯一确定。",
            "id": "3895655",
            "problem": "考虑一个湖泊中溶解态营养物质的环境单室质量平衡模型，其中该室在具有固定时间步长 $\\Delta t$ 的离散时间 $t$ 存储质量 $x_t$。基线守恒定律源于质量平衡：变化率等于流入量减去一阶去除量。经过线性化和时间离散化后，基线离散时间动态表示为 $x_{t+1} = a x_t + b u_t$，其中 $u_t$ 是已知的外部质量输入序列，$a \\in (0,1)$ 表示在一个时间步长内的去除。假设存在一个未建模的季节性驱动因素，表示为一个潜过程 $z_t$，它线性地耦合到室动态中，并按一阶自回归演化。增广状态向量为 $s_t = [x_t, z_t]^\\top$，并遵循线性时不变 (LTI) 动态\n$$\n\\begin{bmatrix}\nx_{t+1} \\\\\nz_{t+1}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\na  \\gamma \\\\\n0  \\phi\n\\end{bmatrix}\n\\begin{bmatrix}\nx_t \\\\\nz_t\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nb \\\\\n0\n\\end{bmatrix}\nu_t,\n$$\n其中 $\\gamma$ 量化了潜驱动因素与室的耦合程度，$\\phi \\in (-1,1)$ 是潜过程的自回归系数。系统的测量是单个标量输出\n$$\ny_t = [1,\\ \\lambda] \\begin{bmatrix}x_t \\\\ z_t\\end{bmatrix},\n$$\n其中 $\\lambda$ 捕捉了传感器对潜过程的任何线性交叉敏感性。在这种情况下，模型结构辨识需要确定，用潜过程增广状态是否会产生一个结构，在该结构中，增广状态 $[x_t, z_t]^\\top$ 可以从输出序列 $y_t$ 和已知输入序列 $u_t$ 中重构出来。\n\n仅从守恒定律（质量平衡）和线性时不变系统的结构可辨识性定义（即从有限的输出和输入序列中唯一推断初始增广状态的能力）出发，推导出一个判据，用于判断对于给定的参数 $(a,\\phi,\\gamma,\\lambda)$，增广状态是否是结构可辨识的。基于该判据，实现一个算法，该算法对每个参数集返回一个布尔值，如果增广状态是结构可辨识的，则为 $True$，否则为 $False$。使用容差为 $\\epsilon = 10^{-12}$ 的数值秩检验，使得奇异值小于或等于 $\\epsilon$ 的矩阵被视为秩亏。\n\n最终答案中无需物理单位，因为分析涉及无量纲化后线性映射的结构属性。不涉及角度，也不需要百分比。\n\n程序中要评估的测试套件参数：\n- 情况1（存在普遍耦合）：$(a,\\phi,\\gamma,\\lambda) = (0.85, 0.70, 0.10, 0.00)$。\n- 情况2（无耦合，无交叉敏感性）：$(a,\\phi,\\gamma,\\lambda) = (0.85, 0.70, 0.00, 0.00)$。\n- 情况3（无耦合，存在交叉敏感性，动态特性不同）：$(a,\\phi,\\gamma,\\lambda) = (0.85, 0.70, 0.00, 0.50)$。\n- 情况4（无耦合，存在交叉敏感性，动态特性相同）：$(a,\\phi,\\gamma,\\lambda) = (0.80, 0.80, 0.00, 0.50)$。\n- 情况5（可辨识性中的非平凡抵消）：$(a,\\phi,\\gamma,\\lambda) = (0.60, 0.90, -0.30, 1.00)$。\n- 情况6（近零耦合以测试数值鲁棒性）：$(a,\\phi,\\gamma,\\lambda) = (0.90, 0.50, 1\\times 10^{-14}, 0.00)$。\n- 情况7（符号混合，可辨识）：$(a,\\phi,\\gamma,\\lambda) = (0.50, 0.80, -0.10, 0.40)$。\n\n您的程序应生成单行输出，其中包含这七种情况的结果，格式为方括号括起来的逗号分隔列表（例如，$[result_1,result_2,\\dots,result_7]$），其中每个 $result_i$ 是如上定义的布尔值。",
            "solution": "该问题要求一个判据，以确定线性时不变 (LTI) 系统的增广状态向量是否是结构可辨识的。该系统由以下状态空间方程描述：\n$$\ns_{t+1} = A s_t + B u_t\n$$\n$$\ny_t = C s_t\n$$\n其中 $s_t = [x_t, z_t]^\\top$ 是增广状态向量，$u_t$ 是已知的标量输入，$y_t$ 是标量输出。矩阵定义如下：\n$$\nA = \\begin{bmatrix} a  \\gamma \\\\ 0  \\phi \\end{bmatrix}, \\quad B = \\begin{bmatrix} b \\\\ 0 \\end{bmatrix}, \\quad C = [1, \\lambda]\n$$\n参数 $(a, \\phi, \\gamma, \\lambda)$ 定义了模型结构。结构可辨识性定义为从有限的输出序列 $\\{y_t\\}$ 和输入序列 $\\{u_t\\}$ 中唯一确定初始状态 $s_0$ 的能力。在线性系统理论中，此属性被称为可观测性或可重构性。\n\n为了推导该判据，我们用初始状态 $s_0$ 和输入序列来表示输出。通过递归地代入状态方程，我们可以将时间 $t$ 的状态写为：\n$$\ns_t = A^t s_0 + \\sum_{j=0}^{t-1} A^{t-1-j} B u_j\n$$\n因此，时间 $t$ 的输出为：\n$$\ny_t = C s_t = C A^t s_0 + C \\sum_{j=0}^{t-1} A^{t-1-j} B u_j\n$$\n由于输入序列 $\\{u_t\\}$ 和系统矩阵 $A$、$B$ 和 $C$ 是已知的，代表强迫响应的第二项可以被计算出来并从测量输出 $y_t$ 中减去。我们定义一个修正输出 $\\tilde{y}_t$，它代表系统的自由响应（仅由初始状态 $s_0$ 引起的响应）：\n$$\n\\tilde{y}_t = y_t - C \\sum_{j=0}^{t-1} A^{t-1-j} B u_j = C A^t s_0\n$$\n确定 $s_0$ 的问题现在简化为使用 $\\tilde{y}_t$ 的已知值求解一个线性方程组。对于维数 $n=2$ 的状态向量，我们至少需要两个这样的方程，从两个时间步 $t=0$ 和 $t=1$ 收集：\n$$\n\\tilde{y}_0 = C A^0 s_0 = C s_0\n$$\n$$\n\\tilde{y}_1 = C A^1 s_0 = C A s_0\n$$\n我们可以将其写成矩阵形式：\n$$\n\\begin{bmatrix} \\tilde{y}_0 \\\\ \\tilde{y}_1 \\end{bmatrix} = \\begin{bmatrix} C \\\\ CA \\end{bmatrix} s_0\n$$\n初始状态 $s_0$ 能够被唯一确定，当且仅当乘以它的矩阵是可逆的。这个矩阵是配对 $(A, C)$ 的可观测性矩阵，记为 $\\mathcal{O}$。\n$$\n\\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\end{bmatrix}\n$$\n对于一个 $n$ 维状态空间，系统是可观测的，当且仅当可观测性矩阵 $\\mathcal{O}$ 具有满秩，即 $n$。在我们的例子中，$n=2$，所以可辨识性的条件是 $\\text{rank}(\\mathcal{O}) = 2$。\n\n让我们为给定系统构建矩阵 $\\mathcal{O}$。\n第一行是矩阵 $C$：\n$$\nC = [1, \\lambda]\n$$\n第二行是乘积 $CA$：\n$$\nCA = [1, \\lambda] \\begin{bmatrix} a  \\gamma \\\\ 0  \\phi \\end{bmatrix} = [1 \\cdot a + \\lambda \\cdot 0, \\quad 1 \\cdot \\gamma + \\lambda \\cdot \\phi] = [a, \\gamma + \\lambda\\phi]\n$$\n结合这两行，可观测性矩阵为：\n$$\n\\mathcal{O} = \\begin{bmatrix} 1  \\lambda \\\\ a  \\gamma + \\lambda\\phi \\end{bmatrix}\n$$\n如果这个 $2 \\times 2$ 矩阵的秩为 2，则系统是结构可辨识的。一个矩阵具有满秩，当且仅当其行列式非零。\n$$\n\\det(\\mathcal{O}) = (1)(\\gamma + \\lambda\\phi) - (\\lambda)(a) = \\gamma + \\lambda\\phi - \\lambda a = \\gamma + \\lambda(\\phi - a)\n$$\n因此，结构可辨识性的解析判据是：\n$$\n\\gamma + \\lambda(\\phi - a) \\neq 0\n$$\n这个条件有明确的物理解释。状态 $z_t$ 可被重构，如果它要么影响状态 $x_t$（即 $\\gamma \\neq 0$），而 $x_t$ 直接是测量的一部分；要么它被直接感知（即 $\\lambda \\neq 0$）。在后一种情况下（$\\gamma=0, \\lambda \\neq 0$），它的动态特性必须与 $x_t$ 的动态特性不同（即 $\\phi \\neq a$），以避免与来自 $x_t$ 的信号完全混淆。如果 $\\phi=a$，这两个模态会发生混叠，无法区分。\n\n对于数值实现，问题要求基于奇异值进行秩检验。矩阵的秩是其非零奇异值的数量。在数值计算中，我们检查奇异值是否大于一个小的容差 $\\epsilon$。如果矩阵的任何奇异值小于或等于此容差，则该矩阵被认为是秩亏的。条件 $\\text{rank}(\\mathcal{O}) = 2$ 在数值上等价于检查 $\\mathcal{O}$ 的最小奇异值（记为 $\\sigma_{\\min}(\\mathcal{O})$）是否大于给定的容差 $\\epsilon = 10^{-12}$。\n\n需要实现的算法如下：\n对于每个给定的参数集 $(a, \\phi, \\gamma, \\lambda)$：\n1.  构建可观测性矩阵 $\\mathcal{O} = \\begin{bmatrix} 1  \\lambda \\\\ a  \\gamma + \\lambda\\phi \\end{bmatrix}$。\n2.  计算 $\\mathcal{O}$ 的奇异值。\n3.  找到最小奇异值 $\\sigma_{\\min}$。\n4.  如果 $\\sigma_{\\min} > 10^{-12}$，则系统被认为是可辨识的。在这种情况下，结果为 $True$，否则为 $False$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and applies the structural identifiability criterion for a 2D LTI system.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (a, phi, gamma, lambda)\n        (0.85, 0.70, 0.10, 0.00),         # Case 1: general coupling present\n        (0.85, 0.70, 0.00, 0.00),         # Case 2: no coupling, no cross-sensitivity\n        (0.85, 0.70, 0.00, 0.50),         # Case 3: no coupling, cross-sensitivity, distinct dynamics\n        (0.80, 0.80, 0.00, 0.50),         # Case 4: no coupling, cross-sensitivity, identical dynamics\n        (0.60, 0.90, -0.30, 1.00),        # Case 5: nontrivial cancellation\n        (0.90, 0.50, 1e-14, 0.00),        # Case 6: near-zero coupling\n        (0.50, 0.80, -0.10, 0.40)         # Case 7: mixed signs, identifiable\n    ]\n\n    # Numerical tolerance for rank test\n    epsilon = 1e-12\n    \n    results = []\n    for case in test_cases:\n        a, phi, gamma, lambda_ = case\n        \n        # Construct the observability matrix O = [[C], [CA]]\n        # C = [1, lambda]\n        # CA = [a, gamma + lambda * phi]\n        observability_matrix = np.array([\n            [1.0, lambda_],\n            [a, gamma + lambda_ * phi]\n        ])\n        \n        # Compute the singular values of the observability matrix.\n        # We only need the singular values, not the full SVD.\n        singular_values = np.linalg.svd(observability_matrix, compute_uv=False)\n        \n        # The rank of the matrix is numerically determined by the number of singular\n        # values greater than the tolerance. For a 2x2 matrix to have full rank (rank 2),\n        # its smallest singular value must be greater than the tolerance.\n        min_singular_value = np.min(singular_values)\n        \n        # The state is structurally identifiable if the matrix has full rank.\n        is_identifiable = min_singular_value > epsilon\n        \n        results.append(is_identifiable)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\".replace(\"True\", \"True\").replace(\"False\", \"False\"))\n\nsolve()\n```"
        }
    ]
}