{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any agent-based model lies in its representation of the agent. This first practice delves into the micro-foundations of decision-making, exploring how to mathematically model an agent's choice under imperfect conditions . We move beyond the ideal of perfect rationality to examine how environmental noise can corrupt an agent's perception, leading to systematic biases in behavior—a core concept of bounded rationality that adds realism to our models.",
            "id": "3860603",
            "problem": "Consider a common-pool resource harvesting scenario represented within Agent-Based Modeling (ABM), where each agent $i$ chooses harvesting effort $e_i \\in [0,\\infty)$ to maximize a single-period utility $U_i(e_i)$ composed of a benefit term with diminishing returns from a shared environmental stock and a quadratic private cost. The agent’s true utility is $U_i(e_i) = \\pi_i(e_i) - c e_i^2$, where $c > 0$ is a constant capturing the convex cost of effort and the benefit function $\\pi_i(e)$ satisfies the following regularity conditions: $\\pi_i(e)$ is three-times continuously differentiable, strictly increasing, and strictly concave on $[0,\\infty)$, i.e., $\\pi_i'(e) > 0$ and $\\pi_i''(e)  0$ for all feasible $e$. Assume agents are myopic and make decisions at discrete time steps.\n\nUnder perfect information, the agent chooses $e_i$ to satisfy the first-order optimality condition derived from maximizing $U_i(e_i)$.\n\nNow suppose the agent’s perception of the marginal benefit is corrupted by environmental uncertainty in the form of additive Gaussian noise. Specifically, at the decision moment the agent observes a noisy marginal benefit signal $\\tilde{m}_i(e_i) = \\pi_i'(e_i) + \\varepsilon_i$, where $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ is independent of $e_i$ and independent across agents and time, and $\\sigma^2 > 0$ is known to the modeler. The agent chooses effort by equating this perceived marginal benefit to marginal cost, i.e., using the perceived first-order condition $\\tilde{m}_i(e_i) - 2 c e_i = 0$.\n\nTasks:\n- Derive the agent’s decision rule as an implicit function $e_i(\\varepsilon_i)$ of the noise realization $\\varepsilon_i$ around the perfect-information optimum $e_i^{\\star}$ that solves the perfect-information first-order condition.\n- Define the bias in effort due to noise as $B \\equiv \\mathbb{E}[e_i(\\varepsilon_i)] - e_i^{\\star}$ and, under the stated assumptions, compute $B$ to second order in the noise variance by a small-noise approximation. Express your final analytic expression for $B$ in terms of $\\pi_i''(e_i^{\\star})$, $\\pi_i'''(e_i^{\\star})$, $c$, and $\\sigma^2$.\n\nYour final answer must be a single closed-form analytic expression. No numerical evaluation is required and no rounding is needed.",
            "solution": "The user has provided a well-defined problem from the field of agent-based modeling and microeconomic theory. The problem is scientifically grounded, self-contained, and objective. All necessary functions, variables, and conditions are provided, and there are no contradictions. The task is to derive an analytical expression for the bias in an agent's decision-making under uncertainty using a small-noise approximation, which is a standard and valid mathematical exercise. Therefore, the problem is deemed valid and a solution will be provided.\n\nLet us begin by formalizing the agent's optimization problem under both perfect information and noisy perception.\n\nFirst, consider the case of perfect information. The agent's utility is given by $U_i(e_i) = \\pi_i(e_i) - c e_i^2$. The agent chooses the effort level $e_i$ to maximize this utility. The first-order condition (FOC) for an interior maximum is given by setting the derivative of the utility function with respect to effort to zero:\n$$ \\frac{dU_i}{de_i} = \\pi_i'(e_i) - 2ce_i = 0 $$\nLet $e_i^{\\star}$ denote the optimal effort level that solves this equation. Thus, $e_i^{\\star}$ satisfies:\n$$ \\pi_i'(e_i^{\\star}) - 2ce_i^{\\star} = 0 \\quad (1) $$\nThe second-order condition (SOC) for a maximum is $\\frac{d^2U_i}{de_i^2}  0$. We have $\\frac{d^2U_i}{de_i^2} = \\pi_i''(e_i) - 2c$. Given the problem states that $\\pi_i''(e_i)  0$ and $c > 0$, the SOC is always satisfied, ensuring that $e_i^{\\star}$ corresponds to a unique maximum.\n\nNext, consider the case with environmental uncertainty. The agent perceives a noisy marginal benefit $\\tilde{m}_i(e_i) = \\pi_i'(e_i) + \\varepsilon_i$, where $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$. The agent determines the effort level by equating the perceived marginal benefit to the marginal cost, $2ce_i$. This leads to the decision rule:\n$$ \\pi_i'(e_i) + \\varepsilon_i - 2ce_i = 0 $$\nThis equation implicitly defines the agent's chosen effort, $e_i$, as a function of the noise realization, $\\varepsilon_i$. We denote this function as $e_i(\\varepsilon_i)$. Let us define the implicit function $F(e_i, \\varepsilon_i) = \\pi_i'(e_i) - 2ce_i + \\varepsilon_i = 0$.\nWhen there is no noise, i.e., $\\varepsilon_i=0$, the decision rule becomes $\\pi_i'(e_i) - 2ce_i = 0$, which is identical to equation $(1)$. Therefore, the effort level chosen in the absence of noise is the perfect-information optimum, $e_i^\\star$. This means $e_i(0) = e_i^{\\star}$.\n\nThe problem asks for the bias in effort, defined as $B = \\mathbb{E}[e_i(\\varepsilon_i)] - e_i^{\\star}$. To compute this, we perform a small-noise approximation by taking a second-order Taylor series expansion of the function $e_i(\\varepsilon_i)$ around the point $\\varepsilon_i = 0$.\n$$ e_i(\\varepsilon_i) \\approx e_i(0) + \\frac{de_i}{d\\varepsilon_i}\\bigg|_{\\varepsilon_i=0} \\varepsilon_i + \\frac{1}{2!} \\frac{d^2e_i}{d\\varepsilon_i^2}\\bigg|_{\\varepsilon_i=0} \\varepsilon_i^2 $$\nWe need to find the first and second derivatives of $e_i$ with respect to $\\varepsilon_i$. We use implicit differentiation on the decision rule $F(e_i(\\varepsilon_i), \\varepsilon_i) = 0$. Differentiating with respect to $\\varepsilon_i$:\n$$ \\frac{dF}{d\\varepsilon_i} = \\frac{\\partial F}{\\partial e_i}\\frac{de_i}{d\\varepsilon_i} + \\frac{\\partial F}{\\partial \\varepsilon_i} = 0 $$\nThe partial derivatives are:\n$$ \\frac{\\partial F}{\\partial e_i} = \\pi_i''(e_i) - 2c $$\n$$ \\frac{\\partial F}{\\partial \\varepsilon_i} = 1 $$\nSubstituting these into the differentiated equation gives:\n$$ (\\pi_i''(e_i) - 2c)\\frac{de_i}{d\\varepsilon_i} + 1 = 0 $$\nSolving for the first derivative $\\frac{de_i}{d\\varepsilon_i}$:\n$$ \\frac{de_i}{d\\varepsilon_i} = -\\frac{1}{\\pi_i''(e_i) - 2c} $$\nWe evaluate this derivative at $\\varepsilon_i = 0$, which implies $e_i = e_i(0) = e_i^{\\star}$:\n$$ \\frac{de_i}{d\\varepsilon_i}\\bigg|_{\\varepsilon_i=0} = -\\frac{1}{\\pi_i''(e_i^{\\star}) - 2c} $$\nNext, we find the second derivative, $\\frac{d^2e_i}{d\\varepsilon_i^2}$, by differentiating $\\frac{de_i}{d\\varepsilon_i}$ with respect to $\\varepsilon_i$:\n$$ \\frac{d^2e_i}{d\\varepsilon_i^2} = \\frac{d}{d\\varepsilon_i} \\left( -[\\pi_i''(e_i) - 2c]^{-1} \\right) $$\nUsing the chain rule:\n$$ \\frac{d^2e_i}{d\\varepsilon_i^2} = -(-1)[\\pi_i''(e_i) - 2c]^{-2} \\cdot \\frac{d}{d\\varepsilon_i}(\\pi_i''(e_i) - 2c) $$\n$$ \\frac{d^2e_i}{d\\varepsilon_i^2} = [\\pi_i''(e_i) - 2c]^{-2} \\cdot \\left( \\pi_i'''(e_i) \\frac{de_i}{d\\varepsilon_i} \\right) $$\nSubstituting the expression for $\\frac{de_i}{d\\varepsilon_i}$:\n$$ \\frac{d^2e_i}{d\\varepsilon_i^2} = [\\pi_i''(e_i) - 2c]^{-2} \\cdot \\pi_i'''(e_i) \\cdot \\left( -\\frac{1}{\\pi_i''(e_i) - 2c} \\right) $$\n$$ \\frac{d^2e_i}{d\\varepsilon_i^2} = -\\frac{\\pi_i'''(e_i)}{(\\pi_i''(e_i) - 2c)^3} $$\nEvaluating this at $\\varepsilon_i = 0$ (so $e_i = e_i^{\\star}$):\n$$ \\frac{d^2e_i}{d\\varepsilon_i^2}\\bigg|_{\\varepsilon_i=0} = -\\frac{\\pi_i'''(e_i^{\\star})}{(\\pi_i''(e_i^{\\star}) - 2c)^3} $$\nNow we can write the Taylor expansion for $e_i(\\varepsilon_i)$:\n$$ e_i(\\varepsilon_i) \\approx e_i^{\\star} - \\frac{1}{\\pi_i''(e_i^{\\star}) - 2c}\\varepsilon_i - \\frac{1}{2}\\frac{\\pi_i'''(e_i^{\\star})}{(\\pi_i''(e_i^{\\star}) - 2c)^3}\\varepsilon_i^2 $$\nTo find the expected effort $\\mathbb{E}[e_i(\\varepsilon_i)]$, we take the expectation of this expansion. We use the properties of the noise term $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$, which are $\\mathbb{E}[\\varepsilon_i] = 0$ and $\\mathbb{E}[\\varepsilon_i^2] = \\text{Var}(\\varepsilon_i) + (\\mathbb{E}[\\varepsilon_i])^2 = \\sigma^2 + 0^2 = \\sigma^2$.\n$$ \\mathbb{E}[e_i(\\varepsilon_i)] \\approx \\mathbb{E}\\left[ e_i^{\\star} - \\frac{\\varepsilon_i}{\\pi_i''(e_i^{\\star}) - 2c} - \\frac{\\pi_i'''(e_i^{\\star})\\varepsilon_i^2}{2(\\pi_i''(e_i^{\\star}) - 2c)^3} \\right] $$\nBy linearity of expectation:\n$$ \\mathbb{E}[e_i(\\varepsilon_i)] \\approx e_i^{\\star} - \\frac{1}{\\pi_i''(e_i^{\\star}) - 2c}\\mathbb{E}[\\varepsilon_i] - \\frac{\\pi_i'''(e_i^{\\star})}{2(\\pi_i''(e_i^{\\star}) - 2c)^3}\\mathbb{E}[\\varepsilon_i^2] $$\nSubstituting the moments of $\\varepsilon_i$:\n$$ \\mathbb{E}[e_i(\\varepsilon_i)] \\approx e_i^{\\star} - \\frac{1}{\\pi_i''(e_i^{\\star}) - 2c}(0) - \\frac{\\pi_i'''(e_i^{\\star})}{2(\\pi_i''(e_i^{\\star}) - 2c)^3}\\sigma^2 $$\n$$ \\mathbb{E}[e_i(\\varepsilon_i)] \\approx e_i^{\\star} - \\frac{\\pi_i'''(e_i^{\\star})\\sigma^2}{2(\\pi_i''(e_i^{\\star}) - 2c)^3} $$\nFinally, we compute the bias $B = \\mathbb{E}[e_i(\\varepsilon_i)] - e_i^{\\star}$:\n$$ B \\approx \\left( e_i^{\\star} - \\frac{\\pi_i'''(e_i^{\\star})\\sigma^2}{2(\\pi_i''(e_i^{\\star}) - 2c)^3} \\right) - e_i^{\\star} $$\n$$ B \\approx -\\frac{\\pi_i'''(e_i^{\\star})\\sigma^2}{2(\\pi_i''(e_i^{\\star}) - 2c)^3} $$\nThis is the second-order approximation of the bias in effort due to the additive noise in the perceived marginal benefit.",
            "answer": "$$\n\\boxed{-\\frac{\\pi_i'''(e_i^{\\star})\\sigma^2}{2(\\pi_i''(e_i^{\\star}) - 2c)^3}}\n$$"
        },
        {
            "introduction": "Agent decisions gain meaning through their interaction with the environment. This exercise shifts our focus to constructing the 'world' in which agents operate, a critical task in modeling human-environment systems . You will implement a simulation of a resource flow network, specifically an irrigation system, where the collective actions of agents controlling canal gates determine the system-wide distribution of a vital resource. This practice highlights the process of translating physical and social rules into a computational model to observe emergent, aggregate outcomes.",
            "id": "3860567",
            "problem": "Consider a directed acyclic graph representing an irrigation network with nodes $\\mathcal{N}$ and edges $\\mathcal{E}$. Each edge $(i \\rightarrow j) \\in \\mathcal{E}$ represents a canal from upstream node $i$ to downstream node $j$. Agents control gate openings on edges, influencing effective throughput. You must implement a program that computes the allocation of water flows under agent-controlled gate settings subject to physical and social constraints, and reports quantitative outcomes for specified test cases.\n\nFundamental base and constraints:\n- Mass conservation (continuity): For each node $i \\in \\mathcal{N}$, let $S_i$ be exogenous inflow (source term), $I_i$ the sum of inflows arriving from upstream edges, $D_i$ the local environmental demand, and $L_i \\in [0,1)$ a dimensionless loss fraction representing outflow reduction due to infiltration and evaporation. The water available at node $i$ is $A_i = S_i + I_i$. The demand satisfied at node $i$ is $E_i = \\min(D_i, A_i)$, and the remaining allocable water before losses is $R_i = A_i - E_i$. The budget available for downstream allocation (after applying losses) is $B_i = (1 - L_i) R_i$.\n- Capacity and control: Each edge $e \\in \\mathcal{E}$ has a nominal capacity $C_e$ in $\\text{m}^3/\\text{s}$. An agent-controlled gate opening fraction $g_e \\in [0,1]$ modifies the effective capacity to $C^{\\text{eff}}_e = g_e C_e$. Flows must satisfy $0 \\leq F_e \\leq C^{\\text{eff}}_e$ for every edge $e$.\n- Fairness weights: Each edge $e$ originating at node $i$ has a nonnegative priority weight $w_e \\geq 0$ that governs proportional allocation among outgoing edges from node $i$. When $B_i$ is less than the sum of effective capacities of outgoing edges from $i$, flows from $i$ should be allocated proportionally to $\\{w_e\\}$ while respecting the capacity bounds; when $B_i$ exceeds the sum of effective capacities, edges are saturated at their effective capacities and any residual $B_i$ is not transported downstream (it is locally spilled and does not contribute to downstream demand satisfaction).\n- Topological computation: Because the graph is acyclic, the allocation can be performed in a topological order starting from sources and proceeding downstream, ensuring that $I_i$ is known when computing $A_i$, $E_i$, $R_i$, $B_i$, and the outgoing edge allocations.\n\nAllocation requirement at a node:\n- For each node $i$, let $\\mathcal{E}^+_i$ denote the set of outgoing edges with effective capacities $\\{C^{\\text{eff}}_e\\}$ and weights $\\{w_e\\}$. Allocate $B_i$ across $\\mathcal{E}^+_i$ such that:\n    1. $\\sum_{e \\in \\mathcal{E}^+_i} F_e = \\min\\left(B_i, \\sum_{e \\in \\mathcal{E}^+_i} C^{\\text{eff}}_e\\right)$,\n    2. $0 \\leq F_e \\leq C^{\\text{eff}}_e$ for all $e \\in \\mathcal{E}^+_i$,\n    3. If $\\sum_{e \\in \\mathcal{E}^+_i} C^{\\text{eff}}_e \\ge B_i$, then among unsaturated edges the ratio $F_e$ is proportional to $w_e$.\n\nYour program must implement a capacity-respecting weighted proportional allocation scheme at each node consistent with the above, using only the provided numerical inputs and the base principles. After computing flows and satisfied demands for all nodes, output the total unmet demand, defined as $\\sum_{i \\in \\mathcal{N}} (D_i - E_i)$, in $\\text{m}^3/\\text{s}$ for each test case.\n\nGraph and parameterization:\n- Nodes: $\\mathcal{N} = \\{0, 1, 2, 3\\}$.\n- Edges $\\mathcal{E}$ with nominal capacities $C_e$ in $\\text{m}^3/\\text{s}$, agent-controlled gate openings $g_e$ (unitless), and priority weights $w_e$ (unitless) are:\n    - Edge $e_0$: $0 \\rightarrow 1$, $C_{e_0} = 5$, $w_{e_0} = 1.0$.\n    - Edge $e_1$: $0 \\rightarrow 2$, $C_{e_1} = 6$, $w_{e_1} = 2.0$.\n    - Edge $e_2$: $1 \\rightarrow 3$, $C_{e_2} = 4$, $w_{e_2} = 1.0$.\n    - Edge $e_3$: $2 \\rightarrow 3$, $C_{e_3} = 3$, $w_{e_3} = 1.0$.\n- Loss fractions: $L_0 = 0.1$, $L_1 = 0.05$, $L_2 = 0.05$, $L_3 = 0$.\n- The graph is acyclic with topological order consistent with upstream-to-downstream traversal $0 \\rightarrow \\{1,2\\} \\rightarrow 3$.\n\nTest suite:\n- Case $1$ (happy path): exogenous inflows $S_0 = 10$, $S_1 = 0$, $S_2 = 0$, $S_3 = 0$; demands $D_0 = 2$, $D_1 = 3$, $D_2 = 1$, $D_3 = 4$; gate openings $g_{e_0} = 0.8$, $g_{e_1} = 0.5$, $g_{e_2} = 1.0$, $g_{e_3} = 1.0$.\n- Case $2$ (boundary with closed gate): exogenous inflows $S_0 = 10$, $S_1 = 0$, $S_2 = 0$, $S_3 = 0$; demands $D_0 = 2$, $D_1 = 3$, $D_2 = 1$, $D_3 = 4$; gate openings $g_{e_0} = 0.8$, $g_{e_1} = 0.0$, $g_{e_2} = 1.0$, $g_{e_3} = 1.0$.\n- Case $3$ (edge case with limited supply): exogenous inflows $S_0 = 3$, $S_1 = 0$, $S_2 = 0$, $S_3 = 0$; demands $D_0 = 1.5$, $D_1 = 2$, $D_2 = 1$, $D_3 = 4$; gate openings $g_{e_0} = 0.8$, $g_{e_1} = 0.5$, $g_{e_2} = 1.0$, $g_{e_3} = 1.0$.\n\nAngle units are not applicable. All reported quantities must be in $\\text{m}^3/\\text{s}$. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\text{result}_3]$), where each entry is the total unmet demand for the corresponding case, expressed as a float in $\\text{m}^3/\\text{s}$.",
            "solution": "The problem requires the computation of water allocation and resulting unmet demand in a simulated irrigation network. The network is modeled as a directed acyclic graph (DAG), which permits a sequential, node-by-node calculation following a specified topological order. The solution is derived by applying principles of mass conservation and a capacity-constrained weighted proportional allocation rule at each node.\n\n### Fundamental Principles and Algorithm\n\nThe calculation proceeds by processing each node in the specified topological order: $0 \\rightarrow 1 \\rightarrow 2 \\rightarrow 3$. For each node $i$, a water budget is calculated and then distributed according to physical and social constraints.\n\n**1. Mass Conservation at each Node:**\nFor any given node $i \\in \\mathcal{N}$, the water balance is calculated as follows:\n- **Total Inflow ($I_i$):** The sum of flows from all incoming edges. For a source node like node $0$, $I_0 = 0$. For other nodes, $I_i = \\sum_{j \\to i} F_{j \\to i}$, where $F_{j \\to i}$ is the flow on the edge from node $j$ to node $i$.\n- **Available Water ($A_i$):** The sum of exogenous inflow $S_i$ and total inflow $I_i$: $A_i = S_i + I_i$.\n- **Satisfied Demand ($E_i$):** The local environmental demand $D_i$ is met as much as possible by the available water: $E_i = \\min(D_i, A_i)$. The unmet demand at this node is $D_i - E_i$.\n- **Remaining Allocable Water ($R_i$):** The water left after satisfying local demand: $R_i = A_i - E_i$.\n- **Downstream Budget ($B_i$):** This is the water available for allocation to downstream nodes after accounting for local losses (e.g., infiltration, evaporation), given by the loss fraction $L_i$: $B_i = (1 - L_i) R_i$.\n\n**2. Downstream Flow Allocation:**\nThe budget $B_i$ is allocated among the set of outgoing edges from node $i$, denoted $\\mathcal{E}^+_i$. Each edge $e \\in \\mathcal{E}^+_i$ has an effective capacity $C^{\\text{eff}}_e = g_e C_e$, where $g_e$ is an agent-controlled gate opening, and a priority weight $w_e$. The total flow leaving node $i$ is constrained by the total effective capacity of its outgoing edges, $\\sum_{e \\in \\mathcal{E}^+_i} C^{\\text{eff}}_e$.\nThe total allocated flow from node $i$ is $\\sum_{e \\in \\mathcal{E}^+_i} F_e = \\min\\left(B_i, \\sum_{e \\in \\mathcal{E}^+_i} C^{\\text{eff}}_e\\right)$.\nThe allocation of this total flow among individual edges follows a capacity-respecting weighted proportional scheme:\n\n- **Oversupply Case:** If the budget $B_i$ is greater than or equal to the total outgoing effective capacity ($\\sum C^{\\text{eff}}_e$), each outgoing edge $e$ is saturated to its effective capacity: $F_e = C^{\\text{eff}}_e$. Any remaining budget ($B_i - \\sum C^{\\text{eff}}_e$) is considered spilled and is not transported downstream.\n- **Undersupply Case:** If the budget $B_i$ is less than the total outgoing effective capacity, the flow is distributed proportionally to the weights $\\{w_e\\}$, subject to the capacity constraints $\\{C^{\\text{eff}}_e\\}$. This is handled with an iterative algorithm:\n    1. Initialize the set of active edges to all outgoing edges from node $i$.\n    2. In a loop, with the remaining budget and active edges:\n        a. Calculate a provisional flow for each active edge, proportional to its weight.\n        b. If any provisional flow exceeds its edge's effective capacity, that edge is deemed a \"saturating candidate\".\n        c. If there are saturating candidates, fix their flows to their effective capacities, subtract these flows from the budget, remove them from the set of active edges, and repeat the process with the reduced budget and remaining edges.\n        d. If no edge's provisional flow exceeds its capacity, allocate the remaining budget proportionally among the remaining active edges, and the process for this node is complete.\n\n**3. Total Unmet Demand:**\nAfter processing all nodes in topological order and determining all flows and satisfied demands, the primary output is the total unmet demand across the entire network, calculated as $\\sum_{i \\in \\mathcal{N}} (D_i - E_i)$.\n\n### Worked Example: Case 1\n\n**Parameters:**\n- Exogenous Inflows: $S = \\{10, 0, 0, 0\\}$ $\\text{m}^3/\\text{s}$\n- Demands: $D = \\{2, 3, 1, 4\\}$ $\\text{m}^3/\\text{s}$\n- Gate Openings: $g = \\{g_{e_0}=0.8, g_{e_1}=0.5, g_{e_2}=1.0, g_{e_3}=1.0\\}$\n- Nominal Capacities: $C = \\{C_{e_0}=5, C_{e_1}=6, C_{e_2}=4, C_{e_3}=3\\}$ $\\text{m}^3/\\text{s}$\n- Weights: $w = \\{w_{e_0}=1.0, w_{e_1}=2.0, w_{e_2}=1.0, w_{e_3}=1.0\\}$\n- Loss Fractions: $L = \\{0.1, 0.05, 0.05, 0\\}$\n\n**Step 0: Pre-computation**\n- Effective Capacities:\n  - $C^{\\text{eff}}_{e_0} = 0.8 \\times 5 = 4.0$ $\\text{m}^3/\\text{s}$\n  - $C^{\\text{eff}}_{e_1} = 0.5 \\times 6 = 3.0$ $\\text{m}^3/\\text{s}$\n  - $C^{\\text{eff}}_{e_2} = 1.0 \\times 4 = 4.0$ $\\text{m}^3/\\text{s}$\n  - $C^{\\text{eff}}_{e_3} = 1.0 \\times 3 = 3.0$ $\\text{m}^3/\\text{s}$\n\n**Step 1: Process Node $0$**\n- $I_0 = 0$. $A_0 = S_0 + I_0 = 10 + 0 = 10$.\n- $E_0 = \\min(D_0, A_0) = \\min(2, 10) = 2$. Unmet demand at node $0$ is $0$.\n- $R_0 = A_0 - E_0 = 10 - 2 = 8$.\n- $B_0 = (1 - L_0) R_0 = (1 - 0.1) \\times 8 = 7.2$.\n- Allocate $B_0=7.2$ to edges $e_0$ ($0 \\to 1$) and $e_1$ ($0 \\to 2$).\n- Total outgoing capacity from node $0$ is $C^{\\text{eff}}_{e_0} + C^{\\text{eff}}_{e_1} = 4.0 + 3.0 = 7.0$.\n- Since $B_0=7.2 > 7.0$ (oversupply), edges are saturated.\n- $F_{e_0} = 4.0$. $F_{e_1} = 3.0$. A volume of $7.2 - 7.0 = 0.2$ $\\text{m}^3/\\text{s}$ is spilled.\n\n**Step 2: Process Node $1$**\n- $I_1 = F_{e_0} = 4.0$. $A_1 = S_1 + I_1 = 0 + 4.0 = 4.0$.\n- $E_1 = \\min(D_1, A_1) = \\min(3, 4.0) = 3$. Unmet demand at node $1$ is $0$.\n- $R_1 = A_1 - E_1 = 4.0 - 3 = 1.0$.\n- $B_1 = (1 - L_1) R_1 = (1 - 0.05) \\times 1.0 = 0.95$.\n- Allocate $B_1=0.95$ to edge $e_2$ ($1 \\to 3$).\n- $F_{e_2} = \\min(B_1, C^{\\text{eff}}_{e_2}) = \\min(0.95, 4.0) = 0.95$.\n\n**Step 3: Process Node $2$**\n- $I_2 = F_{e_1} = 3.0$. $A_2 = S_2 + I_2 = 0 + 3.0 = 3.0$.\n- $E_2 = \\min(D_2, A_2) = \\min(1, 3.0) = 1$. Unmet demand at node $2$ is $0$.\n- $R_2 = A_2 - E_2 = 3.0 - 1 = 2.0$.\n- $B_2 = (1 - L_2) R_2 = (1 - 0.05) \\times 2.0 = 1.9$.\n- Allocate $B_2=1.9$ to edge $e_3$ ($2 \\to 3$).\n- $F_{e_3} = \\min(B_2, C^{\\text{eff}}_{e_3}) = \\min(1.9, 3.0) = 1.9$.\n\n**Step 4: Process Node $3$**\n- $I_3 = F_{e_2} + F_{e_3} = 0.95 + 1.9 = 2.85$.\n- $A_3 = S_3 + I_3 = 0 + 2.85 = 2.85$.\n- $E_3 = \\min(D_3, A_3) = \\min(4, 2.85) = 2.85$. Unmet demand at node $3$ is $4 - 2.85 = 1.15$.\n- Node $3$ is a sink node with no outgoing edges.\n\n**Step 5: Final Calculation**\n- Total Unmet Demand = $\\sum (D_i - E_i) = 0 (\\text{node } 0) + 0 (\\text{node } 1) + 0 (\\text{node } 2) + 1.15 (\\text{node } 3) = 1.15$ $\\text{m}^3/\\text{s}$.\nThis same procedure is applied to all test cases to obtain their respective results.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef allocate_flow(budget, capacities, weights):\n    \"\"\"\n    Allocates a budget of water flow across outgoing edges based on a\n    capacity-constrained weighted proportional rule.\n\n    Args:\n        budget (float): The total available water budget to allocate.\n        capacities (dict): A dictionary mapping edge index to its effective capacity.\n        weights (dict): A dictionary mapping edge index to its priority weight.\n\n    Returns:\n        dict: A dictionary mapping edge index to its allocated flow.\n    \"\"\"\n    flows = {edge: 0.0 for edge in capacities}\n    \n    # Check for the simple oversupply case first\n    total_capacity = sum(capacities.values())\n    if budget = total_capacity:\n        return capacities.copy()\n\n    # Iterative allocation for the undersupply case\n    budget_remaining = budget\n    active_edges = list(capacities.keys())\n    \n    # Using a copy for iteration as we might modify the list\n    local_capacities = capacities.copy()\n\n    while budget_remaining  1e-9 and active_edges:\n        \n        # Calculate total weight of currently active edges\n        current_total_weight = sum(weights[edge] for edge in active_edges)\n        \n        if current_total_weight == 0:\n            # No weights to distribute remaining budget, so it's spilled/unallocated\n            break\n\n        # Provisional allocation\n        provisional_flows = {\n            edge: budget_remaining * weights[edge] / current_total_weight\n            for edge in active_edges\n        }\n\n        # Find edges that would be saturated by this provisional allocation\n        saturating_edges = []\n        for edge in active_edges:\n            if provisional_flows[edge] = local_capacities[edge]:\n                saturating_edges.append(edge)\n        \n        if not saturating_edges:\n            # No edge saturates, distribute the rest of the budget proportionally and finish\n            for edge in active_edges:\n                flows[edge] = provisional_flows[edge]\n            budget_remaining = 0\n            break\n        else:\n            # Some edges will saturate. We must handle this iteratively.\n            # Set flows for saturating edges to their capacity, then repeat.\n            # This is a simplification. A more robust way is to find the most constrained edge.\n            # Let's find the scaling factor alpha to saturate the first edge.\n            min_alpha_factor = float('inf')\n            \n            for edge in active_edges:\n                if weights[edge]  1e-9:\n                    # 'alpha' is the flow that would saturate this edge (given its weight)\n                    alpha = local_capacities[edge] / weights[edge]\n                    min_alpha_factor = min(min_alpha_factor, alpha)\n            \n            # The maximum budget that can be allocated without saturating any edge proportionally\n            distributable_budget = min_alpha_factor * current_total_weight\n            \n            if distributable_budget  budget_remaining:\n                # We saturate at least one edge.\n                allocated_now = distributable_budget\n                budget_remaining -= allocated_now\n                \n                edges_to_remove = []\n                for edge in active_edges:\n                    flow_add = min_alpha_factor * weights[edge]\n                    flows[edge] += flow_add\n                    local_capacities[edge] -= flow_add\n                    if local_capacities[edge]  1e-9:\n                        edges_to_remove.append(edge)\n                \n                active_edges = [e for e in active_edges if e not in edges_to_remove]\n            else:\n                # No edge saturates with the remaining budget. Distribute and finish.\n                allocated_now = budget_remaining\n                budget_remaining = 0\n                for edge in active_edges:\n                    flows[edge] += allocated_now * weights[edge] / current_total_weight\n                break\n\n    return flows\n\n\ndef solve():\n    # --- Static problem definition ---\n    # Graph structure\n    nodes = [0, 1, 2, 3]\n    edges = [(0, 1), (0, 2), (1, 3), (2, 3)] # edge_idx: 0, 1, 2, 3\n\n    # Adjacency lists for graph traversal\n    out_edges = {i: [] for i in nodes}\n    in_edges = {i: [] for i in nodes}\n    for i, (u, v) in enumerate(edges):\n        out_edges[u].append(i)\n        in_edges[v].append(i)\n        \n    topological_order = [0, 1, 2, 3]\n\n    # Parameters\n    C_nominal = np.array([5.0, 6.0, 4.0, 3.0])\n    weights = np.array([1.0, 2.0, 1.0, 1.0])\n    L = np.array([0.1, 0.05, 0.05, 0.0])\n\n    # --- Test Cases ---\n    test_cases = [\n        {\n            \"S\": np.array([10.0, 0.0, 0.0, 0.0]),\n            \"D\": np.array([2.0, 3.0, 1.0, 4.0]),\n            \"g\": np.array([0.8, 0.5, 1.0, 1.0])\n        },\n        {\n            \"S\": np.array([10.0, 0.0, 0.0, 0.0]),\n            \"D\": np.array([2.0, 3.0, 1.0, 4.0]),\n            \"g\": np.array([0.8, 0.0, 1.0, 1.0])\n        },\n        {\n            \"S\": np.array([3.0, 0.0, 0.0, 0.0]),\n            \"D\": np.array([1.5, 2.0, 1.0, 4.0]),\n            \"g\": np.array([0.8, 0.5, 1.0, 1.0])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        S = case[\"S\"]\n        D = case[\"D\"]\n        g = case[\"g\"]\n        \n        C_eff = C_nominal * g\n        \n        # State variables\n        F = np.zeros(len(edges))\n        E = np.zeros(len(nodes))\n        \n        # Simulation loop\n        for i in topological_order:\n            # 1. Calculate water available at node i\n            inflow_I = sum(F[edge_idx] for edge_idx in in_edges[i])\n            available_A = S[i] + inflow_I\n            \n            # 2. Satisfy local demand\n            satisfied_E = min(D[i], available_A)\n            E[i] = satisfied_E\n            \n            # 3. Calculate remaining water and budget for downstream\n            remaining_R = available_A - satisfied_E\n            budget_B = (1 - L[i]) * remaining_R\n            \n            # 4. Allocate budget to outgoing edges\n            if out_edges[i]:\n                # Prepare inputs for allocation function\n                node_out_edges = out_edges[i]\n                sub_capacities = {e: C_eff[e] for e in node_out_edges}\n                sub_weights = {e: weights[e] for e in node_out_edges}\n                \n                # Call allocation function\n                total_outgoing_capacity = sum(sub_capacities.values())\n                \n                if budget_B = total_outgoing_capacity:\n                    # Oversupply case: saturate all edges\n                    allocated_flows = sub_capacities\n                else:\n                    # Undersupply case: iterative proportional allocation\n                    \n                    b_rem = budget_B\n                    f_out = {e: 0.0 for e in node_out_edges}\n                    active_e = list(node_out_edges)\n                    \n                    while b_rem  1e-9 and active_e:\n                        w_rem = sum(sub_weights[e] for e in active_e)\n                        if w_rem  1e-9: break\n                        \n                        prop_flows = {e: b_rem * sub_weights[e] / w_rem for e in active_e}\n\n                        saturating = [e for e in active_e if prop_flows[e] = sub_capacities[e]]\n                        \n                        if not saturating:\n                            for e in active_e:\n                                f_out[e] += prop_flows[e]\n                            b_rem = 0.0\n                            break\n                        else:\n                            for e in saturating:\n                                f_out[e] = sub_capacities[e]\n                                b_rem -= sub_capacities[e]\n                            \n                            active_e = [e for e in active_e if e not in saturating]\n                            sub_capacities = {e: v for e, v in sub_capacities.items() if e not in saturating}\n                    \n                    allocated_flows = f_out\n\n                # Update global flow array\n                for edge_idx, flow_val in allocated_flows.items():\n                    F[edge_idx] = flow_val\n        \n        # Calculate total unmet demand for the case\n        total_unmet_demand = np.sum(D - E)\n        results.append(total_unmet_demand)\n        \n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "The most compelling feature of agent-based models is their ability to capture co-evolutionary dynamics, where agents and their environment continually adapt to one another. This final practice closes the feedback loop, challenging you to model agents that learn and adapt their strategies over time . By integrating a reinforcement learning framework with environmental dynamics, you will derive and compute the emergent steady state of a coupled system, revealing how collective behavior and environmental health can become locked into self-reinforcing patterns.",
            "id": "3860641",
            "problem": "Consider a population of identical agents embedded in a single-resource environment. Each agent faces a binary choice at each discrete time step: conservation ($C$) versus exploitation ($E$). The environment is represented by a normalized resource stock $s_t \\in [0,1]$ that evolves according to a discrete-time mean-field logistic replenishment with linear depletion caused by exploitation:\n$$\ns_{t+1} = s_t + \\rho (1 - s_t) - \\xi \\, \\pi_E \\, s_t,\n$$\nwhere $\\rho  0$ is the intrinsic replenishment rate, $\\xi \\ge 0$ is the exploitation impact coefficient, and $\\pi_E \\in [0,1]$ is the steady-state probability of choosing exploitation in the population (the mean-field approximation assumes each agent is negligibly small relative to the population).\n\nEach agent receives instantaneous rewards that depend on the current stock $s_t$:\n$$\nr_C(s_t) = g \\, s_t, \\qquad r_E(s_t) = f \\, s_t - c,\n$$\nwhere $f  0$ and $g \\ge 0$ are action-specific benefit coefficients and $c \\ge 0$ is an externalized exploitation cost measured in utility units.\n\nAgents learn action values using the on-policy Expected State–Action–Reward–State–Action (Expected-SARSA) update with softmax action selection. Let $Q_C$ and $Q_E$ denote the action-value estimates. The policy is the softmax with temperature $\\tau  0$:\n$$\n\\pi_a = \\frac{\\exp(Q_a / \\tau)}{\\exp(Q_C / \\tau) + \\exp(Q_E / \\tau)}, \\quad a \\in \\{C,E\\},\n$$\nand the Expected-SARSA fixed-point consistency for a single stationary state yields\n$$\nQ_a = r_a + \\gamma \\sum_{b \\in \\{C,E\\}} \\pi_b Q_b,\n$$\nwhere $\\gamma \\in [0,1)$ is the discount factor. At steady state, the resource stock $s^*$ and the exploitation probability $\\pi_E$ must be jointly self-consistent with the above definitions.\n\nStarting only from the foregoing core definitions and laws, derive a self-consistent scalar fixed-point equation for the steady-state exploitation probability $\\pi_E$ under the softmax policy with temperature $\\tau$, expressed in terms of the parameters $(\\tau,\\rho,\\xi,f,g,c,\\gamma)$. Implement an algorithm to compute the unique steady-state solution $\\pi_E \\in [0,1]$ for each parameter set and produce the final exploitation probability as a floating-point number. There is no need to compute $Q_C$, $Q_E$, or $s^*$ explicitly in the output, but your derivation must justify the final algorithmic form.\n\nAll quantities are dimensionless except the reward, which is measured in utility units; report the final exploitation probability as a unitless decimal. Angles are not involved. \n\nYour program must solve the following test suite, which is designed to exercise typical behavior, low and high temperature limits, and environmental edge cases. For each case, compute the steady-state exploitation probability $\\pi_E$ and round to six decimal places:\n\n- Case A (moderate temperature, baseline environment): $\\tau = 0.25$, $\\rho = 0.6$, $\\xi = 0.8$, $f = 1.0$, $g = 0.4$, $c = 0.2$, $\\gamma = 0.9$.\n- Case B (near-deterministic policy): $\\tau = 10^{-3}$, $\\rho = 0.6$, $\\xi = 0.8$, $f = 1.0$, $g = 0.4$, $c = 0.2$, $\\gamma = 0.9$.\n- Case C (high-temperature, near-random policy): $\\tau = 100.0$, $\\rho = 0.6$, $\\xi = 0.8$, $f = 1.0$, $g = 0.4$, $c = 0.2$, $\\gamma = 0.9$.\n- Case D (no exploitation impact on the resource): $\\tau = 0.5$, $\\rho = 0.6$, $\\xi = 0.0$, $f = 1.0$, $g = 0.4$, $c = 0.2$, $\\gamma = 0.9$.\n- Case E (high exploitation cost favoring conservation): $\\tau = 0.25$, $\\rho = 0.6$, $\\xi = 0.8$, $f = 1.0$, $g = 0.4$, $c = 0.8$, $\\gamma = 0.9$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, [$x_1,x_2,x_3,x_4,x_5$]), with each $x_i$ equal to the steady-state exploitation probability for the corresponding case, rounded to six decimal places.",
            "solution": "We begin from the agent-based learning and environmental dynamics definitions. There is a single stationary environmental state characterized by the resource stock $s_t \\in [0,1]$, with mean-field evolution\n$$\ns_{t+1} = s_t + \\rho (1 - s_t) - \\xi \\, \\pi_E \\, s_t,\n$$\nwhere $\\rho  0$ is the replenishment rate, $\\xi \\ge 0$ is the exploitation impact on the stock, and $\\pi_E$ is the steady exploitation probability. At steady state, set $s_{t+1} = s_t = s^*$ and solve for $s^*$:\n$$\n0 = \\rho (1 - s^*) - \\xi \\, \\pi_E \\, s^*, \\quad \\Rightarrow \\quad s^* = \\frac{\\rho}{\\rho + \\xi \\pi_E}.\n$$\n\nAgents receive instantaneous rewards depending on $s_t$:\n$$\nr_C(s) = g s, \\qquad r_E(s) = f s - c,\n$$\nwith $f  0$ and $g \\ge 0$ action-specific benefits, and $c \\ge 0$ the exploitation cost in utility units.\n\nAgents employ Expected State–Action–Reward–State–Action (Expected-SARSA) learning, with action values $Q_C,Q_E$ and a softmax policy at temperature $\\tau$:\n$$\n\\pi_a = \\frac{\\exp(Q_a/\\tau)}{\\exp(Q_C/\\tau) + \\exp(Q_E/\\tau)}, \\quad a \\in \\{C,E\\},\n$$\nand the Expected-SARSA fixed-point consistency for the single stationary state yields:\n$$\nQ_a = r_a + \\gamma \\sum_{b \\in \\{C,E\\}} \\pi_b Q_b, \\quad \\gamma \\in [0,1).\n$$\n\nDefine the soft value\n$$\nV = \\sum_{b \\in \\{C,E\\}} \\pi_b Q_b.\n$$\nSubstitute the Expected-SARSA form to express $V$:\n$$\nV = \\sum_b \\pi_b \\left(r_b + \\gamma V\\right) = \\sum_b \\pi_b r_b + \\gamma V.\n$$\nSolve for $V$:\n$$\nV = \\frac{\\sum_b \\pi_b r_b}{1 - \\gamma}.\n$$\nThen each action value is\n$$\nQ_a = r_a + \\gamma V = r_a + \\gamma \\frac{\\sum_b \\pi_b r_b}{1 - \\gamma}.\n$$\n\nConsider the difference of action values, which enters the softmax:\n$$\n\\Delta \\equiv Q_E - Q_C = \\left(r_E + \\gamma \\frac{\\sum_b \\pi_b r_b}{1 - \\gamma}\\right) - \\left(r_C + \\gamma \\frac{\\sum_b \\pi_b r_b}{1 - \\gamma}\\right) = r_E - r_C.\n$$\nTherefore, the learning dynamics with Expected-SARSA and softmax yield a stationary policy difference solely determined by the instantaneous reward difference. This cancellation is intuitive in a single stationary state because expected future returns contribute equally to both action values via $\\gamma V$.\n\nUsing the softmax form for two actions, the exploitation probability is the logistic function of $Q_E - Q_C$:\n$$\n\\pi_E = \\frac{1}{1 + \\exp\\left(-\\frac{Q_E - Q_C}{\\tau}\\right)} = \\frac{1}{1 + \\exp\\left(-\\frac{r_E - r_C}{\\tau}\\right)}.\n$$\nSubstitute $r_E(s^*) = f s^* - c$ and $r_C(s^*) = g s^*$:\n$$\nr_E - r_C = (f - g) s^* - c.\n$$\nUsing the steady-state stock $s^* = \\frac{\\rho}{\\rho + \\xi \\pi_E}$, we obtain the scalar fixed-point equation in $\\pi_E$:\n$$\n\\pi_E = \\frac{1}{1 + \\exp\\left(-\\frac{(f - g)\\, \\frac{\\rho}{\\rho + \\xi \\pi_E} - c}{\\tau}\\right)}.\n$$\n\nThis equation is well-defined on the interval $\\pi_E \\in [0,1]$ for $\\rho  0$, $\\xi \\ge 0$, $f  0$, $g \\ge 0$, $c \\ge 0$, and $\\tau  0$. The right-hand side is continuous and strictly bounded in $(0,1)$. Define the function\n$$\nh(\\pi) = \\frac{1}{1 + \\exp\\left(-\\frac{(f - g)\\, \\frac{\\rho}{\\rho + \\xi \\pi} - c}{\\tau}\\right)}.\n$$\nWe seek $\\pi^*$ such that $h(\\pi^*) = \\pi^*$. Consider $g(\\pi) = h(\\pi) - \\pi$. Then $g(0) = h(0) - 0  0$, since $h(0) \\in (0,1)$. Also $g(1) = h(1) - 1  0$, since $h(1) \\in (0,1)$. By the Intermediate Value Theorem, there exists at least one root in $[0,1]$. Monotonicity of $h(\\pi)$ under the stated parameter ranges implies uniqueness, because increasing $\\pi$ weakens the stock $s^*$ and often reduces $(f - g) s^* - c$, making $h(\\pi)$ nonincreasing for $(f - g) \\rho  0$ and $\\xi \\ge 0$. Thus a unique fixed point exists and can be found by a robust bracketing root finder on $g(\\pi)$ over $[0,1]$.\n\nAlgorithmic steps to compute $\\pi_E$ for a given parameter set:\n1. Define the logistic function $\\sigma(x) = \\frac{1}{1 + e^{-x}}$.\n2. For given $(\\tau,\\rho,\\xi,f,g,c)$, define $h(\\pi) = \\sigma\\left(\\frac{(f - g)\\, \\frac{\\rho}{\\rho + \\xi \\pi} - c}{\\tau}\\right)$ and $g(\\pi) = h(\\pi) - \\pi$.\n3. Use a bracketing root finder on $g(\\pi)$ over $[0,1]$ to obtain the unique fixed point $\\pi^*$.\n4. Round $\\pi^*$ to six decimal places.\n5. Repeat for each test case.\n\nNote that the discount factor $\\gamma$ cancels out of the exploitation probability due to the single stationary state and Expected-SARSA structure; the softmax depends only on $Q_E - Q_C = r_E - r_C$. Nevertheless, $\\gamma$ remains part of the foundational derivation.\n\nApply this to the test suite specified in the problem. For each case, the program computes the steady-state exploitation probability $\\pi_E$ by solving the fixed-point equation and returns the rounded values as a single comma-separated list in brackets.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef steady_state_exploitation_probability(tau, rho, xi, f, g, c, gamma):\n    \"\"\"\n    Compute steady-state exploitation probability pi_E under a softmax policy\n    with temperature tau, in a mean-field single-state environment with\n    logistic replenishment and linear depletion from exploitation.\n\n    Although gamma is part of the RL setup, pi_E depends only on reward\n    differences in the single stationary state and thus is independent of gamma.\n    \"\"\"\n    # Logistic function\n    def logistic(x):\n        # Use stable computation\n        # For large negative x, exp(-x) may overflow; handle with np.where\n        return 1.0 / (1.0 + np.exp(-x))\n\n    # Define the fixed-point function g(pi) = h(pi) - pi\n    def g_fun(pi):\n        # Steady-state stock s* = rho / (rho + xi * pi)\n        denom = rho + xi * pi\n        # Avoid division by zero; denom = rho  0 under given parameters\n        s_star = rho / denom\n        # Reward difference delta = (f - g) * s* - c\n        delta = (f - g) * s_star - c\n        # Softmax exploitation probability under two actions: logistic(delta / tau)\n        h_pi = logistic(delta / tau)\n        return h_pi - pi\n\n    # Root finding on interval [0,1]; g(0)  0 and g(1)  0 typically\n    # To ensure robustness, clip extreme tau values are still handled by brentq.\n    pi_star = brentq(g_fun, 0.0, 1.0, maxiter=1000, rtol=1e-12)\n    return pi_star\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (tau, rho, xi, f, g, c, gamma)\n    test_cases = [\n        (0.25, 0.6, 0.8, 1.0, 0.4, 0.2, 0.9),   # Case A\n        (1e-3, 0.6, 0.8, 1.0, 0.4, 0.2, 0.9),   # Case B\n        (100.0, 0.6, 0.8, 1.0, 0.4, 0.2, 0.9),  # Case C\n        (0.5, 0.6, 0.0, 1.0, 0.4, 0.2, 0.9),    # Case D\n        (0.25, 0.6, 0.8, 1.0, 0.4, 0.8, 0.9),   # Case E\n    ]\n\n    results = []\n    for case in test_cases:\n        tau, rho, xi, f, g, c, gamma = case\n        pi_e = steady_state_exploitation_probability(tau, rho, xi, f, g, c, gamma)\n        results.append(f\"{pi_e:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}