{
    "hands_on_practices": [
        {
            "introduction": "Effective LULC models begin with high-quality, informative input data, which often involves transforming raw satellite sensor measurements into scientifically meaningful features. This exercise focuses on calculating two of the most widely used vegetation indices, the Normalized Difference Vegetation Index ($NDVI$) and the Enhanced Vegetation Index ($EVI$). This practice will challenge you to think critically about their design and sensitivity to atmospheric noise, a fundamental aspect of remote sensing analysis. ",
            "id": "3888134",
            "problem": "A multispectral optical remote sensing pixel acquired over a mixed agricultural landscape is observed with three spectral bands, denoted $\\left(B_2,B_3,B_4\\right)$, whose bidirectional surface reflectances are $\\left(0.12,0.09,0.22\\right)$. Assume $B_2$ corresponds to the blue band, $B_3$ corresponds to the red band, and $B_4$ corresponds to the near-infrared band. Vegetation indices used in land use and land cover change modeling are constructed from physically motivated combinations of spectral reflectances that exploit the contrast between pigment absorption in the red and strong leaf scattering in the near-infrared, along with aerosol resistance terms.\n\nUsing only core definitions and well-tested formulas for vegetation indices, compute the Normalized Difference Vegetation Index (NDVI) and the Enhanced Vegetation Index (EVI) for this pixel. In deriving EVI, use the canonical coefficients adopted in the Moderate Resolution Imaging Spectroradiometer (MODIS) literature, with $G=2.5$, $L=1$, $C_1=6$, and $C_2=7.5$. Then, based on first principles, discuss which index is more sensitive to residual atmospheric effects (for example, additive path radiance remaining after imperfect correction) and why, referencing the role of the blue band and weighting terms.\n\nExpress each index as a pure number (dimensionless) and round your numerical results to four significant figures.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of optical remote sensing, is well-posed with all necessary information provided for computation, and is expressed in objective, precise language. It requires the application of standard, well-established formulas and a discussion based on first principles of atmospheric radiative transfer, which are central to environmental and earth system modeling.\n\nThe problem provides the surface reflectances for three spectral bands:\nBlue band reflectance, $\\rho_{\\text{blue}} = B_2 = 0.12$\nRed band reflectance, $\\rho_{\\text{red}} = B_3 = 0.09$\nNear-infrared (NIR) band reflectance, $\\rho_{\\text{NIR}} = B_4 = 0.22$\n\nWe are tasked with computing two standard vegetation indices, the Normalized Difference Vegetation Index (NDVI) and the Enhanced Vegetation Index (EVI), and discussing their relative sensitivity to atmospheric effects.\n\nFirst, we compute the NDVI. The formula for NDVI is defined as the normalized difference between the near-infrared and red reflectances:\n$$\n\\text{NDVI} = \\frac{\\rho_{\\text{NIR}} - \\rho_{\\text{red}}}{\\rho_{\\text{NIR}} + \\rho_{\\text{red}}}\n$$\nSubstituting the given reflectance values:\n$$\n\\text{NDVI} = \\frac{0.22 - 0.09}{0.22 + 0.09} = \\frac{0.13}{0.31}\n$$\nCalculating the numerical value:\n$$\n\\text{NDVI} \\approx 0.4193548...\n$$\nRounding to four significant figures, we get $\\text{NDVI} = 0.4194$.\n\nNext, we compute the EVI. The formula for EVI, incorporating the canonical MODIS coefficients, is:\n$$\n\\text{EVI} = G \\times \\frac{\\rho_{\\text{NIR}} - \\rho_{\\text{red}}}{\\rho_{\\text{NIR}} + C_1 \\times \\rho_{\\text{red}} - C_2 \\times \\rho_{\\text{blue}} + L}\n$$\nThe problem provides the coefficients: $G = 2.5$, $L = 1$, $C_1 = 6$, and $C_2 = 7.5$. Substituting these and the reflectance values into the formula:\n$$\n\\text{EVI} = 2.5 \\times \\frac{0.22 - 0.09}{0.22 + (6 \\times 0.09) - (7.5 \\times 0.12) + 1}\n$$\nFirst, we evaluate the terms in the denominator:\n$$\n6 \\times 0.09 = 0.54\n$$\n$$\n7.5 \\times 0.12 = 0.90\n$$\nNow, substitute these back into the EVI equation:\n$$\n\\text{EVI} = 2.5 \\times \\frac{0.13}{0.22 + 0.54 - 0.90 + 1}\n$$\n$$\n\\text{EVI} = 2.5 \\times \\frac{0.13}{0.86}\n$$\nCalculating the numerical value:\n$$\n\\text{EVI} \\approx 2.5 \\times 0.1511627... \\approx 0.3779069...\n$$\nRounding to four significant figures, we get $\\text{EVI} = 0.3779$.\n\nFinally, we discuss the relative sensitivity of NDVI and EVI to residual atmospheric effects. Atmospheric contamination, primarily from aerosol scattering and molecular (Rayleigh) scattering, introduces an additive signal known as path radiance. This effect is wavelength-dependent, being strongest at shorter wavelengths (i.e., in the blue band) and decreasing with increasing wavelength.\n\nThe NDVI is a simple ratio. While the ratio form can reduce multiplicative noise (e.g., variations in illumination angle), it is highly susceptible to additive noise like path radiance. If an additive atmospheric signal $\\delta_{\\lambda}$ exists in a band $\\lambda$, the measured at-sensor reflectance $\\rho^*_{\\lambda}$ is approximately $\\rho_{\\lambda} + \\delta_{\\lambda}$. The NDVI computed from at-sensor reflectances would be:\n$$\n\\text{NDVI}_{\\text{atm}} = \\frac{(\\rho_{\\text{NIR}} + \\delta_{\\text{NIR}}) - (\\rho_{\\text{red}} + \\delta_{\\text{red}})}{(\\rho_{\\text{NIR}} + \\delta_{\\text{NIR}}) + (\\rho_{\\text{red}} + \\delta_{\\text{red}})} = \\frac{\\rho_{\\text{NIR}} - \\rho_{\\text{red}} + \\delta_{\\text{NIR}} - \\delta_{\\text{red}}}{\\rho_{\\text{NIR}} + \\rho_{\\text{red}} + \\delta_{\\text{NIR}} + \\delta_{\\text{red}}}\n$$\nBecause the additive terms $\\delta_{\\lambda}$ do not cancel out, the NDVI is sensitive to atmospheric conditions, especially aerosol variations.\n\nThe EVI was specifically formulated to mitigate this issue. Its structure includes two key improvements over NDVI:\n1.  A soil adjustment factor $L$ in the denominator to decouple the vegetation signal from the canopy background brightness.\n2.  An atmospheric resistance term, built using the blue band and coefficients $C_1$ and $C_2$. The denominator term $\\rho_{\\text{NIR}} + C_1 \\rho_{\\text{red}} - C_2 \\rho_{\\text{blue}} + L$ uses the blue band to correct for aerosol influences. Aerosol path radiance is significantly higher in the blue spectrum than in the red. The EVI formula leverages this physical principle. The term $C_1 \\rho_{\\text{red}} - C_2 \\rho_{\\text{blue}}$ is designed such that the aerosol signal in the red band is coupled with the aerosol signal in the blue band. Since aerosol scattering adds to reflectance in both bands, but more strongly in the blue, this difference term provides a first-order correction for aerosol effects.\n\nTherefore, based on first principles embedded in their mathematical definitions, the NDVI is inherently more sensitive to residual atmospheric effects than the EVI. The EVI's inclusion of the blue band and the specific weighting coefficients $C_1$ and $C_2$ allows it to self-correct for a significant portion of atmospheric aerosol contamination, a capability that the simpler two-band NDVI lacks.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.4194 & 0.3779\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A land cover map, whether generated by classifying satellite imagery or as the output of a simulation model, is incomplete without a rigorous assessment of its accuracy. The confusion matrix is the cornerstone of this evaluation, providing a detailed breakdown of agreements and disagreements between the map and ground-truth data. This practice will guide you through the calculation and interpretation of key metrics derived from the confusion matrix, enabling you to quantify map reliability from both the user's and the producer's perspectives. ",
            "id": "3888144",
            "problem": "Consider a supervised land cover classification used within a Land Use and Land Cover (LULC) change modeling workflow, where a categorical raster map of predicted classes is validated against independent reference data obtained from field surveys and high-resolution aerial imagery, collected using a stratified random sampling design. Let the three thematic classes be $C_{1}$ (Forest), $C_{2}$ (Agriculture), and $C_{3}$ (Urban). Define the confusion matrix as a $3 \\times 3$ matrix $N$ whose entry $n_{ij}$ is the count of samples predicted as class $C_{i}$ while the reference indicates class $C_{j}$. For a particular study area, the following matrix is obtained:\n$$\nN \\;=\\; \\begin{pmatrix}\n460 & 40 & 20 \\\\\n30 & 310 & 25 \\\\\n10 & 50 & 155\n\\end{pmatrix},\n$$\nwith rows ordered by predicted classes $(C_{1}, C_{2}, C_{3})$ and columns ordered by reference classes $(C_{1}, C_{2}, C_{3})$. Using the fundamental definitions of classification accuracy in terms of event frequencies and their empirical probabilities, compute the Overall Accuracy (OA), the User’s Accuracy (UA) for each predicted class, and the Producer’s Accuracy (PA) for each reference class. Express OA, each UA, and each PA as decimals. Round your answers to four significant figures. Report your final results in the following order: $(\\text{OA}, \\text{UA}_{C_{1}}, \\text{UA}_{C_{2}}, \\text{UA}_{C_{3}}, \\text{PA}_{C_{1}}, \\text{PA}_{C_{2}}, \\text{PA}_{C_{3}})$. No units are required.",
            "solution": "The user has provided a problem that is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. The definitions and data conform to standard practices in the field of remote sensing and spatial analysis for land use and land cover change modeling. There are no contradictions, ambiguities, or factual unsoundness. Thus, the problem is deemed valid and a full solution is provided below.\n\nThe problem requires the calculation of several standard accuracy assessment metrics from a given confusion matrix $N$. The matrix is defined such that its element $n_{ij}$ represents the number of samples whose predicted class is $C_i$ and whose true (reference) class is $C_j$. The given matrix is:\n$$\nN \\;=\\; \\begin{pmatrix}\n460 & 40 & 20 \\\\\n30 & 310 & 25 \\\\\n10 & 50 & 155\n\\end{pmatrix}\n$$\nHere, rows correspond to predicted classes ($C_1$=Forest, $C_2$=Agriculture, $C_3$=Urban) and columns correspond to reference classes in the same order.\n\nFirst, we calculate the total number of samples, $S_{total}$, by summing all elements of the matrix $N$.\n$$\nS_{total} = \\sum_{i=1}^{3} \\sum_{j=1}^{3} n_{ij} = 460 + 40 + 20 + 30 + 310 + 25 + 10 + 50 + 155 = 1100\n$$\n\nNext, we calculate the required accuracy metrics.\n\nOverall Accuracy (OA):\nThe Overall Accuracy is the proportion of all samples that were correctly classified. This is computed by dividing the sum of the diagonal elements (correctly classified samples) by the total number of samples.\n$$\n\\text{OA} = \\frac{\\sum_{k=1}^{3} n_{kk}}{S_{total}} = \\frac{n_{11} + n_{22} + n_{33}}{S_{total}}\n$$\nSubstituting the values from the matrix $N$:\n$$\n\\text{OA} = \\frac{460 + 310 + 155}{1100} = \\frac{925}{1100} \\approx 0.840909...\n$$\nRounding to four significant figures, we get $\\text{OA} = 0.8409$.\n\nUser’s Accuracy (UA):\nThe User’s Accuracy for a class $C_i$ is the proportion of samples predicted as class $C_i$ that are actually class $C_i$. It measures the reliability of the map from the user's perspective (i.e., of the samples labeled as $C_i$ on the map, what fraction is truly $C_i$ on the ground?). It is calculated by dividing the number of correctly classified samples for class $C_i$ ($n_{ii}$) by the total number of samples predicted as class $C_i$ (the row sum $R_i = \\sum_{j=1}^{3} n_{ij}$).\n\nFor class $C_1$:\nThe row sum is $R_1 = 460 + 40 + 20 = 520$.\n$$\n\\text{UA}_{C_{1}} = \\frac{n_{11}}{R_1} = \\frac{460}{520} \\approx 0.884615...\n$$\nRounded to four significant figures, $\\text{UA}_{C_{1}} = 0.8846$.\n\nFor class $C_2$:\nThe row sum is $R_2 = 30 + 310 + 25 = 365$.\n$$\n\\text{UA}_{C_{2}} = \\frac{n_{22}}{R_2} = \\frac{310}{365} \\approx 0.849315...\n$$\nRounded to four significant figures, $\\text{UA}_{C_{2}} = 0.8493$.\n\nFor class $C_3$:\nThe row sum is $R_3 = 10 + 50 + 155 = 215$.\n$$\n\\text{UA}_{C_{3}} = \\frac{n_{33}}{R_3} = \\frac{155}{215} \\approx 0.720930...\n$$\nRounded to four significant figures, $\\text{UA}_{C_{3}} = 0.7209$.\n\nProducer’s Accuracy (PA):\nThe Producer’s Accuracy for a class $C_j$ is the proportion of reference samples of class $C_j$ that are correctly classified as $C_j$. It measures how well the producer of the map has represented the real-world features (i.e., of all the true $C_j$ areas on the ground, what fraction was correctly identified?). It is calculated by dividing the number of correctly classified samples for class $C_j$ ($n_{jj}$) by the total number of reference samples for class $C_j$ (the column sum $K_j = \\sum_{i=1}^{3} n_{ij}$).\n\nFor class $C_1$:\nThe column sum is $K_1 = 460 + 30 + 10 = 500$.\n$$\n\\text{PA}_{C_{1}} = \\frac{n_{11}}{K_1} = \\frac{460}{500} = 0.92\n$$\nExpressed with four significant figures, $\\text{PA}_{C_{1}} = 0.9200$.\n\nFor class $C_2$:\nThe column sum is $K_2 = 40 + 310 + 50 = 400$.\n$$\n\\text{PA}_{C_{2}} = \\frac{n_{22}}{K_2} = \\frac{310}{400} = 0.775\n$$\nExpressed with four significant figures, $\\text{PA}_{C_{2}} = 0.7750$.\n\nFor class $C_3$:\nThe column sum is $K_3 = 20 + 25 + 155 = 200$.\n$$\n\\text{PA}_{C_{3}} = \\frac{n_{33}}{K_3} = \\frac{155}{200} = 0.775\n$$\nExpressed with four significant figures, $\\text{PA}_{C_{3}} = 0.7750$.\n\nThe final results are collected and ordered as requested: $(\\text{OA}, \\text{UA}_{C_{1}}, \\text{UA}_{C_{2}}, \\text{UA}_{C_{3}}, \\text{PA}_{C_{1}}, \\text{PA}_{C_{2}}, \\text{PA}_{C_{3}})$.\nThe values are ($0.8409, 0.8846, 0.8493, 0.7209, 0.9200, 0.7750, 0.7750$).",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.8409 & 0.8846 & 0.8493 & 0.7209 & 0.9200 & 0.7750 & 0.7750\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "At the heart of LULC modeling is the simulation of dynamic spatial processes. Cellular Automata (CA) offer a powerful framework for capturing local interactions that give rise to complex, large-scale patterns like urban growth. This hands-on coding exercise challenges you to implement and calibrate a simple stochastic CA model, using observed landscape patterns to find the best parameter values and applying holdout validation to diagnose the critical problem of overfitting. ",
            "id": "3888174",
            "problem": "Consider a binary land cover raster represented as an $N \\times N$ grid of cells with states $0$ (non-developed) and $1$ (developed). A single-step stochastic Cellular Automaton (CA) is defined on this grid to model one time period of urban expansion. The CA uses the following assumptions and rules, grounded in the independence of local transition trials and the mapping from event intensity to occurrence probability: each non-developed cell assesses development pressure from its $4$-neighbor (Von Neumann) neighborhood, and the probability of transition to the developed state increases monotonically with the count of developed neighbors.\n\nFundamental base:\n- A CA time step is a synchronous update of all cells. Let $n_{i}$ denote the number of developed neighbors of cell $i$ under $4$-adjacency at the previous time. Each developed cell remains developed. Each non-developed cell independently transitions to developed with probability $P_{i} = 1 - e^{-\\alpha n_{i}}$, where $\\alpha \\ge 0$ is a scalar parameter expressing neighborhood contagion strength and $e$ denotes the base of the natural logarithm. This mapping follows the standard hazard-to-probability relationship for a Poisson process over a unit interval with constant intensity proportional to $n_{i}$.\n- A patch is a contiguous set of developed cells under $4$-adjacency. The patch size is the number of cells in the patch.\n- For any finite multiset of patch sizes, the empirical cumulative distribution function (ECDF) at integer $x$ is the fraction of patch sizes less than or equal to $x$. The Kolmogorov–Smirnov (KS) discrepancy between two finite samples with ECDFs $F$ and $G$ is $D = \\sup_{x} |F(x) - G(x)|$. If both samples are empty, define $D = 0$; if one sample is empty and the other is not, the KS discrepancy computed over the support of the non-empty sample yields $D = 1$.\n\nCalibration objective:\n- Given an initial map at time $t_{0}$ and an observed map at time $t_{1}$ (calibration map), calibrate $\\alpha$ by minimizing the expected KS discrepancy between the simulated patch size distribution (from the CA applied to the initial map) and the observed patch size distribution (from the calibration map). Because the CA is stochastic, the expected KS discrepancy must be approximated by Monte Carlo replication.\n\nHoldout diagnosis of overfitting:\n- A holdout map at time $t_{1}$ (validation map) is provided for each test case. After computing the calibrated $\\alpha^{\\star}$ that minimizes the calibration discrepancy, evaluate the KS discrepancy using the holdout map to form $D_{\\text{val}}(\\alpha^{\\star})$ and compute the generalization gap $g = D_{\\text{val}}(\\alpha^{\\star}) - D_{\\text{cal}}(\\alpha^{\\star})$. Overfitting is diagnosed when $g$ exceeds the threshold $\\tau = 0.1$ (expressed as a decimal), i.e., when $g > \\tau$.\n\nAlgorithmic requirements:\n- Use $R = 32$ Monte Carlo replicates to estimate the expected KS discrepancy at each tested $\\alpha$.\n- Search $\\alpha$ on a uniform grid $\\{0.00, 0.05, 0.10, \\dots, 1.00\\}$ and choose the smallest $\\alpha$ that achieves the minimum estimated discrepancy on the calibration map.\n- Patches are defined with $4$-adjacency. The CA update is synchronous. Random draws are independent across cells and replicates.\n\nTest suite:\nThree test cases are provided. Each case specifies an initial map at time $t_{0}$, an observed calibration map, and an observed holdout map. All grids are $8 \\times 8$ with entries $0$ or $1$.\n\nTest case 1:\n- Initial $t_{0}$:\n$$\n\\begin{bmatrix}\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&1&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&1&1&0&0&0\\\\\n0&0&0&1&1&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\n\\end{bmatrix}\n$$\n- Observed calibration:\n$$\n\\begin{bmatrix}\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&1&1\\\\\n0&0&1&1&1&1&1&1\\\\\n0&0&1&1&1&1&0&0\\\\\n0&0&1&1&1&1&0&0\\\\\n0&0&1&1&1&1&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\n\\end{bmatrix}\n$$\n- Observed holdout:\n$$\n\\begin{bmatrix}\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&1&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&1&1&1&0&0\\\\\n0&0&0&1&1&1&0&0\\\\\n0&0&0&1&1&1&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\n\\end{bmatrix}\n$$\n\nTest case 2:\n- Initial $t_{0}$:\n$$\n\\begin{bmatrix}\n0&0&0&0&0&0&0&0\\\\\n0&1&1&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\n\\end{bmatrix}\n$$\n- Observed calibration:\n$$\n\\begin{bmatrix}\n0&0&0&0&0&0&0&0\\\\\n0&1&1&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\n\\end{bmatrix}\n$$\n- Observed holdout:\n$$\n\\begin{bmatrix}\n0&0&0&0&0&0&0&0\\\\\n0&1&1&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\\\\\n0&0&0&0&0&0&0&0\n\\end{bmatrix}\n$$\n\nTest case 3:\n- Initial $t_{0}$:\n$$\n\\begin{bmatrix}\n0&0&0&0&0&0&0&0\\\\\n1&0&0&0&0&0&0&1\\\\\n0&0&1&0&0&0&0&0\\\\\n0&0&1&1&0&0&0&0\\\\\n0&0&0&1&0&0&0&0\\\\\n0&0&0&0&0&1&0&0\\\\\n0&1&0&0&0&1&0&0\\\\\n0&0&0&0&0&0&0&0\n\\end{bmatrix}\n$$\n- Observed calibration:\n$$\n\\begin{bmatrix}\n0&0&0&0&0&0&0&0\\\\\n1&0&0&0&0&0&1&1\\\\\n0&0&1&1&1&1&1&0\\\\\n0&0&1&1&1&1&0&0\\\\\n0&0&1&1&1&1&0&0\\\\\n0&0&1&1&1&1&1&0\\\\\n0&1&0&0&0&1&0&0\\\\\n0&0&0&0&0&0&0&0\n\\end{bmatrix}\n$$\n- Observed holdout:\n$$\n\\begin{bmatrix}\n0&0&0&0&0&0&0&0\\\\\n1&0&0&0&0&0&1&0\\\\\n0&0&1&1&1&0&0&0\\\\\n0&0&1&1&1&0&0&0\\\\\n0&0&1&1&1&0&0&0\\\\\n0&0&0&0&0&1&0&0\\\\\n0&1&0&0&0&1&0&0\\\\\n0&0&0&0&0&0&0&0\n\\end{bmatrix}\n$$\n\nRequired outputs:\n- For each test case, the program must output a list with four elements: $\\alpha^{\\star}$, $D_{\\text{cal}}(\\alpha^{\\star})$, $D_{\\text{val}}(\\alpha^{\\star})$, and a boolean indicating overfitting, defined as $D_{\\text{val}}(\\alpha^{\\star}) - D_{\\text{cal}}(\\alpha^{\\star}) > 0.1$.\n- All floating-point outputs must be expressed as decimals rounded to six digits after the decimal point. The boolean must be either True or False.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the four-element list for one test case in the same order as presented above (e.g., \"[[alpha1,Dcal1,Dval1,flag1],[alpha2,Dcal2,Dval2,flag2],[alpha3,Dcal3,Dval3,flag3]]\"). No additional text should be printed.",
            "solution": "We begin from the formal definition of a synchronous Cellular Automaton (CA) update and the standard conversion between a constant hazard rate and the probability of at least one event in a unit interval. Let a non-developed cell $i$ with $n_{i}$ developed neighbors under $4$-adjacency experience an intensity $\\lambda_{i}$ proportional to $n_{i}$, i.e., $\\lambda_{i} = \\alpha n_{i}$, where $\\alpha \\ge 0$ is the unknown parameter to calibrate. Under a Poisson assumption and independence across locations, the probability of at least one development event in unit time is $P_{i} = 1 - e^{-\\lambda_{i}} = 1 - e^{-\\alpha n_{i}}$. Developed cells remain developed for the one-step transition, which enforces monotonicity in development consistent with many land-use change models for short horizons.\n\nPatch size distribution construction follows from $4$-adjacency connected components on the developed state. For any map with developed state set $S$, we compute patch sizes by labeling each connected component under $4$-adjacency and counting the number of cells in each component. This yields a multiset $\\{s_{1}, s_{2}, \\dots, s_{k}\\}$ of patch sizes. The empirical cumulative distribution function (ECDF) $F(x)$ is defined as\n$$\nF(x) = \\frac{1}{k} \\sum_{j=1}^{k} \\mathbf{1}\\{s_{j} \\le x\\},\n$$\nwith the convention $F(x) = 0$ if $k = 0$. The Kolmogorov–Smirnov (KS) discrepancy between two samples with ECDFs $F$ and $G$ is\n$$\nD = \\sup_{x} |F(x) - G(x)|,\n$$\nwhich we evaluate at the union of the distinct observed sizes because the supremum of the difference between right-continuous step functions is attained at a jump point. If both samples are empty, then $F \\equiv 0$ and $G \\equiv 0$, yielding $D = 0$. If one sample is empty and the other has any mass, evaluating over the support of the non-empty sample produces $D = 1$.\n\nTo calibrate $\\alpha$, we approximate the expected KS discrepancy between the simulated CA output and the observed calibration map via Monte Carlo replication. Specifically, for each candidate $\\alpha$ on the grid $\\{0.00, 0.05, \\dots, 1.00\\}$, we perform $R = 32$ independent one-step CA simulations from the provided initial map. For each simulation, we compute the patch sizes, form the ECDF, and compute the KS discrepancy against the calibration ECDF. We then average the KS discrepancies across the $R$ replicates to estimate the expected discrepancy at that $\\alpha$. The calibrated parameter $\\alpha^{\\star}$ is the smallest $\\alpha$ that achieves the minimum average KS discrepancy.\n\nOverfitting diagnosis is performed using holdout maps. After fixing $\\alpha^{\\star}$ from calibration, we estimate the validation discrepancy $D_{\\text{val}}(\\alpha^{\\star})$ analogously by simulating $R = 32$ independent CA runs from the initial map and computing average KS against the holdout ECDF. The generalization gap is $g = D_{\\text{val}}(\\alpha^{\\star}) - D_{\\text{cal}}(\\alpha^{\\star})$. If $g > \\tau$, where $\\tau = 0.1$, we diagnose overfitting. The logic is that a model tuned to reduce calibration discrepancy but exhibiting substantially higher discrepancy on the holdout indicates the parameter has captured idiosyncratic calibration features rather than general structure, consistent with the statistical definition of overfitting.\n\nAlgorithmic implementation details:\n- Neighborhood counts $n_{i}$ are computed under $4$-adjacency with zero padding at the grid boundaries. For each cell $(r, c)$, $n_{r,c}$ is the sum of the developed state at $(r-1,c)$, $(r+1,c)$, $(r,c-1)$, and $(r,c+1)$ where indices are valid.\n- The CA update is synchronous: first compute all $n_{i}$ from the initial map, then compute $P_{i} = 1 - e^{-\\alpha n_{i}}$, and finally sample uniform random variables $U_{i} \\sim \\text{Uniform}(0,1)$ independently for each cell to decide transitions for non-developed cells via $\\mathbf{1}\\{U_{i} < P_{i}\\}$; developed cells remain $1$.\n- Connected component labeling uses breadth-first search (BFS) or depth-first search (DFS) over $4$-adjacency, marking visited developed cells and counting the size of each component to produce the patch size multiset.\n- The KS discrepancy $D$ is computed by evaluating ECDFs at the union of distinct sizes present in either sample, including the case of empty samples as described.\n\nEdge cases and coverage:\n- Test case 2 is a boundary case with no observed change between initial and both observed maps. The calibrated $\\alpha^{\\star}$ should be near $0$, and the KS discrepancies should be small, with negligible generalization gap and no overfitting diagnosis.\n- Test case 1 is a typical case where observed calibration exhibits substantial neighborhood-driven growth around an initial cluster, while the holdout map shows more modest growth, allowing a nontrivial calibration and a moderate generalization gap.\n- Test case 3 emphasizes dispersed seeds and strong calibration growth, with holdout maps indicating weaker expansion. This tests the overfitting diagnosis by potentially producing a larger validation discrepancy than calibration discrepancy.\n\nOutput specification:\n- For each test case, we output a list $[\\alpha^{\\star}, D_{\\text{cal}}(\\alpha^{\\star}), D_{\\text{val}}(\\alpha^{\\star}), \\text{flag}]$, where the flag is True if $D_{\\text{val}}(\\alpha^{\\star}) - D_{\\text{cal}}(\\alpha^{\\star}) > 0.1$ and False otherwise. All floating-point values are rounded to six decimal places.\n- The program prints a single line containing a list of these per-test-case lists, in order of the test suite definition.\n\nThis approach integrates a hazard-based CA formulation with statistical calibration via ECDF-based KS discrepancy and holdout validation to diagnose overfitting, consistent with principled environmental and earth system modeling of land use and land cover change.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef four_neighbor_counts(grid: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute the number of developed (1) neighbors under 4-adjacency for each cell.\n    \"\"\"\n    n = np.zeros_like(grid, dtype=int)\n    # neighbor below contributes to current cell's count\n    n[:-1, :] += grid[1:, :]\n    # neighbor above\n    n[1:, :] += grid[:-1, :]\n    # neighbor right\n    n[:, :-1] += grid[:, 1:]\n    # neighbor left\n    n[:, 1:] += grid[:, :-1]\n    return n\n\ndef ca_step(initial: np.ndarray, alpha: float, rng: np.random.Generator) -> np.ndarray:\n    \"\"\"\n    Perform one synchronous CA step using P = 1 - exp(-alpha * n_neighbors).\n    Developed cells remain developed.\n    \"\"\"\n    grid = initial\n    n = four_neighbor_counts(grid)\n    # Transition probabilities for non-developed cells\n    P = 1.0 - np.exp(-alpha * n.astype(float))\n    # Sample uniforms\n    U = rng.random(grid.shape)\n    next_grid = grid.copy()\n    zero_mask = (grid == 0)\n    # Apply transitions only to zero cells\n    next_grid[zero_mask] = (U[zero_mask] < P[zero_mask]).astype(int)\n    return next_grid\n\ndef patch_sizes(grid: np.ndarray) -> list:\n    \"\"\"\n    Compute patch sizes as 4-connected components of 1s.\n    Returns a list of integers.\n    \"\"\"\n    visited = np.zeros_like(grid, dtype=bool)\n    sizes = []\n    rows, cols = grid.shape\n\n    for r in range(rows):\n        for c in range(cols):\n            if grid[r, c] == 1 and not visited[r, c]:\n                # BFS from (r, c)\n                q = [(r, c)]\n                visited[r, c] = True\n                size = 0\n                while q:\n                    rr, cc = q.pop()\n                    size += 1\n                    # 4-neighbors\n                    if rr > 0 and grid[rr - 1, cc] == 1 and not visited[rr - 1, cc]:\n                        visited[rr - 1, cc] = True\n                        q.append((rr - 1, cc))\n                    if rr < rows - 1 and grid[rr + 1, cc] == 1 and not visited[rr + 1, cc]:\n                        visited[rr + 1, cc] = True\n                        q.append((rr + 1, cc))\n                    if cc > 0 and grid[rr, cc - 1] == 1 and not visited[rr, cc - 1]:\n                        visited[rr, cc - 1] = True\n                        q.append((rr, cc - 1))\n                    if cc < cols - 1 and grid[rr, cc + 1] == 1 and not visited[rr, cc + 1]:\n                        visited[rr, cc + 1] = True\n                        q.append((rr, cc + 1))\n                sizes.append(size)\n    return sizes\n\ndef ks_distance(sample_a: list, sample_b: list) -> float:\n    \"\"\"\n    Compute the Kolmogorov–Smirnov discrepancy between two finite samples of integers.\n    If both samples are empty, return 0. If one is empty and the other is non-empty, return 1.\n    \"\"\"\n    na = len(sample_a)\n    nb = len(sample_b)\n    if na == 0 and nb == 0:\n        return 0.0\n    if na == 0 and nb > 0:\n        # ECDF_A(x) == 0, ECDF_B reaches 1 across its support, so sup difference is 1\n        return 1.0\n    if nb == 0 and na > 0:\n        return 1.0\n\n    a_sorted = np.sort(np.array(sample_a))\n    b_sorted = np.sort(np.array(sample_b))\n    # Evaluate ECDFs on the union of unique points\n    xs = np.unique(np.concatenate([a_sorted, b_sorted]))\n    Fa = np.searchsorted(a_sorted, xs, side='right') / na\n    Fb = np.searchsorted(b_sorted, xs, side='right') / nb\n    return float(np.max(np.abs(Fa - Fb)))\n\ndef average_ks(initial: np.ndarray, obs_sizes: list, alpha: float, R: int, rng_seed: int) -> float:\n    \"\"\"\n    Estimate expected KS discrepancy by averaging over R replicates for a given alpha.\n    \"\"\"\n    rng = np.random.default_rng(rng_seed)\n    ks_vals = []\n    for _ in range(R):\n        sim_grid = ca_step(initial, alpha, rng)\n        sim_sizes = patch_sizes(sim_grid)\n        ks_vals.append(ks_distance(sim_sizes, obs_sizes))\n    return float(np.mean(ks_vals))\n\ndef calibrate_and_validate(initial: np.ndarray, obs_cal: np.ndarray, obs_val: np.ndarray,\n                           alpha_grid: np.ndarray, R: int, tau: float, seed_cal: int, seed_val: int):\n    \"\"\"\n    Calibrate alpha on obs_cal, then evaluate validation discrepancy on obs_val.\n    Return alpha_star, D_cal, D_val, overfit_flag.\n    \"\"\"\n    # Precompute observed patch size samples\n    obs_cal_sizes = patch_sizes(obs_cal)\n    obs_val_sizes = patch_sizes(obs_val)\n\n    # Grid search over alpha\n    best_alpha = None\n    best_score = None\n    # Use independent seeds per alpha but deterministic across alphas\n    # For comparability, we can use a fixed seed per alpha = seed_cal + int(alpha*1000)\n    for alpha in alpha_grid:\n        seed_for_alpha = seed_cal + int(round(alpha * 1000))\n        score = average_ks(initial, obs_cal_sizes, alpha, R, seed_for_alpha)\n        if best_score is None or score < best_score - 1e-12 or (abs(score - best_score) <= 1e-12 and (best_alpha is None or alpha < best_alpha)):\n            best_score = score\n            best_alpha = alpha\n\n    # Compute validation discrepancy at alpha*\n    D_cal = average_ks(initial, obs_cal_sizes, best_alpha, R, seed_cal)\n    D_val = average_ks(initial, obs_val_sizes, best_alpha, R, seed_val)\n    gap = D_val - D_cal\n    overfit = gap > tau\n    return best_alpha, D_cal, D_val, overfit\n\ndef to_float6(x: float) -> float:\n    \"\"\"\n    Round to six decimal places, returning a float for printing consistency.\n    \"\"\"\n    return float(f\"{x:.6f}\")\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = []\n\n    # Test case 1\n    I1 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,1,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,1,1,0,0,0],\n        [0,0,0,1,1,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    C1 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,1,1],\n        [0,0,1,1,1,1,1,1],\n        [0,0,1,1,1,1,0,0],\n        [0,0,1,1,1,1,0,0],\n        [0,0,1,1,1,1,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    V1 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,1,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,1,1,1,0,0],\n        [0,0,0,1,1,1,0,0],\n        [0,0,0,1,1,1,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    test_cases.append((I1, C1, V1, 12345, 54321))\n\n    # Test case 2\n    I2 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [0,1,1,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    C2 = I2.copy()\n    V2 = I2.copy()\n    test_cases.append((I2, C2, V2, 24680, 86420))\n\n    # Test case 3\n    I3 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [1,0,0,0,0,0,0,1],\n        [0,0,1,0,0,0,0,0],\n        [0,0,1,1,0,0,0,0],\n        [0,0,0,1,0,0,0,0],\n        [0,0,0,0,0,1,0,0],\n        [0,1,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    C3 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [1,0,0,0,0,0,1,1],\n        [0,0,1,1,1,1,1,0],\n        [0,0,1,1,1,1,0,0],\n        [0,0,1,1,1,1,0,0],\n        [0,0,1,1,1,1,1,0],\n        [0,1,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    V3 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [1,0,0,0,0,0,1,0],\n        [0,0,1,1,1,0,0,0],\n        [0,0,1,1,1,0,0,0],\n        [0,0,1,1,1,0,0,0],\n        [0,0,0,0,0,1,0,0],\n        [0,1,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    test_cases.append((I3, C3, V3, 13579, 97531))\n\n    # Calibration parameters\n    alpha_grid = np.round(np.linspace(0.0, 1.0, 21), 2)  # 0.00 to 1.00 in 0.05 steps\n    R = 32\n    tau = 0.1\n\n    results = []\n    for (initial, obs_cal, obs_val, seed_cal, seed_val) in test_cases:\n        alpha_star, D_cal, D_val, overfit = calibrate_and_validate(\n            initial, obs_cal, obs_val, alpha_grid, R, tau, seed_cal, seed_val\n        )\n        # Round floats to six decimal places\n        result = [to_float6(alpha_star), to_float6(D_cal), to_float6(D_val), overfit]\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(str(results))\n\nsolve()\n```"
        }
    ]
}