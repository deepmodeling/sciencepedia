{
    "hands_on_practices": [
        {
            "introduction": "土地利用与土地覆盖变化模型在很大程度上依赖于能够准确反映地表特征的输入数据。植被指数，例如归一化植被指数 $(NDVI)$ 和增强型植被指数 $(EVI)$，是从卫星遥感图像中提取的关键生物物理参数，用于量化植被的健康状况和密度。这项练习将指导您从原始光谱反射率数据计算这些指数，并探讨它们对大气效应的敏感性，这对于为特定环境分析选择正确的工具有着至关重要的实践意义。",
            "id": "3888134",
            "problem": "在混合农业景观上空获取的一个多光谱光学遥感像元，通过三个光谱波段进行观测，记为 $\\left(B_2,B_3,B_4\\right)$，其双向表面反射率分别为 $\\left(0.12,0.09,0.22\\right)$。假设 $B_2$ 对应蓝光波段，$B_3$ 对应红光波段，$B_4$ 对应近红外波段。用于土地利用和土地覆盖变化建模的植被指数是根据物理原理构建的光谱反射率组合，这些组合利用了红色波段的色素吸收与近红外波段的强烈叶片散射之间的对比，并加入了气溶胶阻抗项。\n\n仅使用植被指数的核心定义和经过充分检验的公式，计算该像元的归一化植被指数 (NDVI) 和增强型植被指数 (EVI)。在推导 EVI 时，使用中分辨率成像光谱仪 (MODIS) 文献中采纳的标准系数，即 $G=2.5$，$L=1$，$C_1=6$ 和 $C_2=7.5$。然后，根据基本原理，讨论哪个指数对残余大气效应（例如，不完全校正后残留的附加路径辐射）更敏感，并说明原因，同时阐述蓝光波段和权重项的作用。\n\n将每个指数表示为纯数（无量纲），并将您的数值结果四舍五入到四位有效数字。",
            "solution": "该问题是有效的，因为它科学地基于光学遥感的原理，问题设定适定，为计算提供了所有必要信息，并以客观、精确的语言表述。它要求应用标准、成熟的公式，并基于大气辐射传输的基本原理进行讨论，这些都是环境和地球系统建模的核心内容。\n\n问题提供了三个光谱波段的表面反射率：\n蓝光波段反射率，$\\rho_{\\text{blue}} = B_2 = 0.12$\n红光波段反射率，$\\rho_{\\text{red}} = B_3 = 0.09$\n近红外 (NIR) 波段反射率，$\\rho_{\\text{NIR}} = B_4 = 0.22$\n\n我们的任务是计算两个标准的植被指数，即归一化植被指数 (NDVI) 和增强型植被指数 (EVI)，并讨论它们对大气效应的相对敏感性。\n\n首先，我们计算 NDVI。NDVI 的公式定义为近红外和红光反射率之间的归一化差异：\n$$\n\\text{NDVI} = \\frac{\\rho_{\\text{NIR}} - \\rho_{\\text{red}}}{\\rho_{\\text{NIR}} + \\rho_{\\text{red}}}\n$$\n代入给定的反射率值：\n$$\n\\text{NDVI} = \\frac{0.22 - 0.09}{0.22 + 0.09} = \\frac{0.13}{0.31}\n$$\n计算数值：\n$$\n\\text{NDVI} \\approx 0.4193548...\n$$\n四舍五入到四位有效数字，我们得到 $\\text{NDVI} = 0.4194$。\n\n接下来，我们计算 EVI。包含 MODIS 标准系数的 EVI 公式为：\n$$\n\\text{EVI} = G \\times \\frac{\\rho_{\\text{NIR}} - \\rho_{\\text{red}}}{\\rho_{\\text{NIR}} + C_1 \\times \\rho_{\\text{red}} - C_2 \\times \\rho_{\\text{blue}} + L}\n$$\n问题提供了系数：$G = 2.5$，$L = 1$，$C_1 = 6$ 和 $C_2 = 7.5$。将这些系数和反射率值代入公式：\n$$\n\\text{EVI} = 2.5 \\times \\frac{0.22 - 0.09}{0.22 + (6 \\times 0.09) - (7.5 \\times 0.12) + 1}\n$$\n首先，我们计算分母中的各项：\n$$\n6 \\times 0.09 = 0.54\n$$\n$$\n7.5 \\times 0.12 = 0.90\n$$\n现在，将这些值代回 EVI 方程：\n$$\n\\text{EVI} = 2.5 \\times \\frac{0.13}{0.22 + 0.54 - 0.90 + 1}\n$$\n$$\n\\text{EVI} = 2.5 \\times \\frac{0.13}{0.86}\n$$\n计算数值：\n$$\n\\text{EVI} \\approx 2.5 \\times 0.1511627... \\approx 0.3779069...\n$$\n四舍五入到四位有效数字，我们得到 $\\text{EVI} = 0.3779$。\n\n最后，我们讨论 NDVI 和 EVI 对残余大气效应的相对敏感性。大气污染，主要来自气溶胶散射和分子（瑞利）散射，会引入一种称为路径辐射的附加信号。这种效应是波长相关的，在较短波长（即蓝光波段）处最强，并随波长增加而减弱。\n\nNDVI 是一个简单的比率。虽然比率形式可以减少乘性噪声（例如，光照角度的变化），但它对像路径辐射这样的加性噪声高度敏感。如果在一个波段 $\\lambda$ 中存在附加的大气信号 $\\delta_{\\lambda}$，那么在传感器处测得的反射率 $\\rho^*_{\\lambda}$ 约为 $\\rho_{\\lambda} + \\delta_{\\lambda}$。根据传感器处反射率计算的 NDVI 将是：\n$$\n\\text{NDVI}_{\\text{atm}} = \\frac{(\\rho_{\\text{NIR}} + \\delta_{\\text{NIR}}) - (\\rho_{\\text{red}} + \\delta_{\\text{red}})}{(\\rho_{\\text{NIR}} + \\delta_{\\text{NIR}}) + (\\rho_{\\text{red}} + \\delta_{\\text{red}})} = \\frac{\\rho_{\\text{NIR}} - \\rho_{\\text{red}} + \\delta_{\\text{NIR}} - \\delta_{\\text{red}}}{\\rho_{\\text{NIR}} + \\rho_{\\text{red}} + \\delta_{\\text{NIR}} + \\delta_{\\text{red}}}\n$$\n由于附加项 $\\delta_{\\lambda}$ 不会抵消，因此 NDVI 对大气条件，特别是气溶胶的变化很敏感。\n\nEVI 的专门设计就是为了缓解这个问题。其结构包括对 NDVI 的两项关键改进：\n1.  分母中有一个土壤调节因子 $L$，用于将植被信号与冠层背景亮度解耦。\n2.  一个大气阻抗项，使用蓝光波段和系数 $C_1$ 和 $C_2$ 构建。分母项 $\\rho_{\\text{NIR}} + C_1 \\rho_{\\text{red}} - C_2 \\rho_{\\text{blue}} + L$ 使用蓝光波段来校正气溶胶的影响。气溶胶的路径辐射在蓝色光谱中显著高于红色光谱。EVI 公式利用了这一物理原理。项 $C_1 \\rho_{\\text{red}} - C_2 \\rho_{\\text{blue}}$ 的设计使得红光波段中的气溶胶信号与蓝光波段中的气溶胶信号耦合。由于气溶胶散射会增加两个波段的反射率，但在蓝光波段中更强，因此该差异项为气溶胶效应提供了一阶校正。\n\n因此，根据其数学定义中内含的基本原理，NDVI 内在地比 EVI 对残余大气效应更敏感。EVI 包含了蓝光波段以及特定的权重系数 $C_1$ 和 $C_2$，这使其能够对大部分大气气溶胶污染进行自我校正，而这是更简单的双波段 NDVI所不具备的能力。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.4194  0.3779\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "生成土地覆盖图仅仅是建模工作流程的第一步；评估其准确性同样至关重要。混淆矩阵是评估分类模型性能的基石，它通过将模型预测结果与地面真实参考数据进行比较来提供详细的诊断信息。通过本练习，您将学习如何计算总体精度、用户精度和生产者精度，从而更深入地理解地图的可靠性以及不同类型的分类误差。",
            "id": "3888144",
            "problem": "考虑一个在土地利用与土地覆盖（LULC）变化建模工作流中使用的监督土地覆盖分类，其中一个预测类别的分类栅格图通过与独立参考数据进行验证，这些参考数据是通过分层随机抽样设计，从实地调查和高分辨率航空影像中获取的。设三个主题类别为 $C_{1}$ (森林)、$C_{2}$ (农业) 和 $C_{3}$ (城市)。定义混淆矩阵为一个 $3 \\times 3$ 的矩阵 $N$，其元素 $n_{ij}$ 是预测为类别 $C_{i}$ 而参考数据表明为类别 $C_{j}$ 的样本数量。对于一个特定的研究区域，得到以下矩阵：\n$$\nN \\;=\\; \\begin{pmatrix}\n460  40  20 \\\\\n30  310  25 \\\\\n10  50  155\n\\end{pmatrix},\n$$\n其中行按预测类别 $(C_{1}, C_{2}, C_{3})$ 排序，列按参考类别 $(C_{1}, C_{2}, C_{3})$ 排序。使用分类精度关于事件频率及其经验概率的基本定义，计算总体精度（OA）、每个预测类别的用户精度（UA）以及每个参考类别的生产者精度（PA）。将 OA、每个 UA 和每个 PA 表示为小数。将答案四舍五入到四位有效数字。按以下顺序报告您的最终结果：$(\\text{OA}, \\text{UA}_{C_{1}}, \\text{UA}_{C_{2}}, \\text{UA}_{C_{3}}, \\text{PA}_{C_{1}}, \\text{PA}_{C_{2}}, \\text{PA}_{C_{3}})$。无需单位。",
            "solution": "用户提供了一个具有科学依据、提法得当、客观且包含唯一解所需全部必要信息的问题。其定义和数据符合遥感及土地利用与土地覆盖变化建模的空间分析领域的标准实践。问题中没有矛盾、歧义或事实错误。因此，该问题被视为有效，并将在下面提供完整解答。\n\n该问题要求从给定的混淆矩阵 $N$ 中计算几个标准的精度评估指标。该矩阵的定义是，其元素 $n_{ij}$ 代表预测类别为 $C_i$ 且真实（参考）类别为 $C_j$ 的样本数量。给定的矩阵是：\n$$\nN \\;=\\; \\begin{pmatrix}\n460  40  20 \\\\\n30  310  25 \\\\\n10  50  155\n\\end{pmatrix}\n$$\n此处，行对应于预测类别（$C_1$=森林, $C_2$=农业, $C_3$=城市），列按相同顺序列对应于参考类别。\n\n首先，我们通过对矩阵 $N$ 的所有元素求和来计算样本总数 $S_{total}$。\n$$\nS_{total} = \\sum_{i=1}^{3} \\sum_{j=1}^{3} n_{ij} = 460 + 40 + 20 + 30 + 310 + 25 + 10 + 50 + 155 = 1100\n$$\n\n接下来，我们计算所需的精度指标。\n\n总体精度（OA）：\n总体精度是所有被正确分类的样本所占的比例。它通过将对角线元素（正确分类的样本）之和除以样本总数来计算。\n$$\n\\text{OA} = \\frac{\\sum_{k=1}^{3} n_{kk}}{S_{total}} = \\frac{n_{11} + n_{22} + n_{33}}{S_{total}}\n$$\n代入矩阵 $N$ 的值：\n$$\n\\text{OA} = \\frac{460 + 310 + 155}{1100} = \\frac{925}{1100} \\approx 0.840909...\n$$\n四舍五入到四位有效数字，我们得到 $\\text{OA} = 0.8409$。\n\n用户精度（UA）：\n类别 $C_i$ 的用户精度是指被预测为类别 $C_i$ 的样本中，实际上也属于类别 $C_i$ 的比例。它从用户的角度衡量地图的可靠性（即，在地图上标记为 $C_i$ 的样本中，有多大比例在地面上确实是 $C_i$？）。其计算方法是用类别 $C_i$ 的正确分类样本数（$n_{ii}$）除以预测为类别 $C_i$ 的样本总数（行和 $R_i = \\sum_{j=1}^{3} n_{ij}$）。\n\n对于类别 $C_1$：\n行和为 $R_1 = 460 + 40 + 20 = 520$。\n$$\n\\text{UA}_{C_{1}} = \\frac{n_{11}}{R_1} = \\frac{460}{520} \\approx 0.884615...\n$$\n四舍五入到四位有效数字，$\\text{UA}_{C_{1}} = 0.8846$。\n\n对于类别 $C_2$：\n行和为 $R_2 = 30 + 310 + 25 = 365$。\n$$\n\\text{UA}_{C_{2}} = \\frac{n_{22}}{R_2} = \\frac{310}{365} \\approx 0.849315...\n$$\n四舍五入到四位有效数字，$\\text{UA}_{C_{2}} = 0.8493$。\n\n对于类别 $C_3$：\n行和为 $R_3 = 10 + 50 + 155 = 215$。\n$$\n\\text{UA}_{C_{3}} = \\frac{n_{33}}{R_3} = \\frac{155}{215} \\approx 0.720930...\n$$\n四舍五入到四位有效数字，$\\text{UA}_{C_{3}} = 0.7209$。\n\n生产者精度（PA）：\n类别 $C_j$ 的生产者精度是指类别 $C_j$ 的参考样本中，被正确分类为 $C_j$ 的比例。它衡量地图的制作者在多大程度上正确表示了真实世界的地物（即，在地面上所有真实的 $C_j$ 区域中，有多大比例被正确识别了？）。其计算方法是用类别 $C_j$ 的正确分类样本数（$n_{jj}$）除以类别 $C_j$ 的参考样本总数（列和 $K_j = \\sum_{i=1}^{3} n_{ij}$）。\n\n对于类别 $C_1$：\n列和为 $K_1 = 460 + 30 + 10 = 500$。\n$$\n\\text{PA}_{C_{1}} = \\frac{n_{11}}{K_1} = \\frac{460}{500} = 0.92\n$$\n以四位有效数字表示，$\\text{PA}_{C_{1}} = 0.9200$。\n\n对于类别 $C_2$：\n列和为 $K_2 = 40 + 310 + 50 = 400$。\n$$\n\\text{PA}_{C_{2}} = \\frac{n_{22}}{K_2} = \\frac{310}{400} = 0.775\n$$\n以四位有效数字表示，$\\text{PA}_{C_{2}} = 0.7750$。\n\n对于类别 $C_3$：\n列和为 $K_3 = 20 + 25 + 155 = 200$。\n$$\n\\text{PA}_{C_{3}} = \\frac{n_{33}}{K_3} = \\frac{155}{200} = 0.775\n$$\n以四位有效数字表示，$\\text{PA}_{C_{3}} = 0.7750$。\n\n收集最终结果并按要求排序：$(\\text{OA}, \\text{UA}_{C_{1}}, \\text{UA}_{C_{2}}, \\text{UA}_{C_{3}}, \\text{PA}_{C_{1}}, \\text{PA}_{C_{2}}, \\text{PA}_{C_{3}})$。\n这些值为 ($0.8409, 0.8846, 0.8493, 0.7209, 0.9200, 0.7750, 0.7750$)。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.8409  0.8846  0.8493  0.7209  0.9200  0.7750  0.7750\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "超越静态地图评估，动态模拟土地利用变化是该领域的核心挑战。本练习将引导您构建一个简单的元胞自动机 (CA) 模型来模拟城市扩张，这是一个涉及参数校准和模型验证的完整建模过程。您将学习如何通过将模拟模式与观测数据进行匹配来校准模型参数，并使用保留数据诊断过拟合，这是确保模型预测能力和泛化能力的关键一步。",
            "id": "3888174",
            "problem": "考虑一个表示为 $N \\times N$ 单元格网格的二元土地覆盖栅格，其状态为 $0$（未开发）和 $1$（已开发）。在此网格上定义了一个单步随机元胞自动机 (CA)，以模拟一个时间周期的城市扩张。该 CA 使用以下假设和规则，这些假设和规则基于局部转换试验的独立性以及从事件强度到发生概率的映射：每个未开发的单元格评估其 $4$-邻域（冯·诺依曼）邻居带来的开发压力，并且转换到已开发状态的概率随着已开发邻居数量的增加而单调增加。\n\n基本基础：\n- 一个 CA 时间步是所有单元格的同步更新。令 $n_{i}$ 表示在先前时间步中，在 $4$-邻接下单元格 $i$ 的已开发邻居数量。每个已开发的单元格保持已开发状态。每个未开发的单元格以概率 $P_{i} = 1 - e^{-\\alpha n_{i}}$ 独立地转换为已开发状态，其中 $\\alpha \\ge 0$ 是一个表示邻域传染强度的标量参数，而 $e$ 表示自然对数的底数。此映射遵循泊松过程在单位区间内具有与 $n_{i}$ 成正比的恒定强度的标准风险-概率关系。\n- 斑块是在 $4$-邻接下的一个连续的已开发单元格集合。斑块大小是斑块中的单元格数量。\n- 对于任何有限的斑块大小多重集，整数 $x$ 处的经验累积分布函数 (ECDF) 是小于或等于 $x$ 的斑块大小的比例。具有 ECDF $F$ 和 $G$ 的两个有限样本之间的柯尔莫哥洛夫-斯米尔诺夫 (KS) 差异为 $D = \\sup_{x} |F(x) - G(x)|$。如果两个样本都为空，则定义 $D = 0$；如果一个样本为空而另一个不为空，则在非空样本的支持域上计算的 KS 差异得出 $D = 1$。\n\n校准目标：\n- 给定时间 $t_{0}$ 的初始地图和时间 $t_{1}$ 的观测地图（校准地图），通过最小化模拟斑块大小分布（从应用于初始地图的 CA 得出）与观测斑块大小分布（从校准地图得出）之间的期望 KS 差异来校准 $\\alpha$。由于 CA 是随机的，因此必须通过蒙特卡洛复制来近似期望 KS 差异。\n\n过拟合的留出诊断：\n- 为每个测试用例提供一个时间 $t_{1}$ 的留出地图（验证地图）。在计算出最小化校准差异的校准后 $\\alpha^{\\star}$ 之后，使用留出地图评估 KS 差异以形成 $D_{\\text{val}}(\\alpha^{\\star})$，并计算泛化差距 $g = D_{\\text{val}}(\\alpha^{\\star}) - D_{\\text{cal}}(\\alpha^{\\star})$。当 $g$ 超过阈值 $\\tau = 0.1$（表示为小数），即当 $g > \\tau$ 时，诊断为过拟合。\n\n算法要求：\n- 使用 $R = 32$ 次蒙特卡洛复制来估计每个测试 $\\alpha$ 值的期望 KS 差异。\n- 在均匀网格 $\\{0.00, 0.05, 0.10, \\dots, 1.00\\}$ 上搜索 $\\alpha$，并选择在校准地图上实现最小估计差异的最小 $\\alpha$。\n- 斑块使用 $4$-邻接定义。CA 更新是同步的。随机抽样在单元格和复制之间是独立的。\n\n测试套件：\n提供了三个测试用例。每个用例指定了时间 $t_{0}$ 的初始地图、一个观测校准地图和一个观测留出地图。所有网格均为 $8 \\times 8$，条目为 $0$ 或 $1$。\n\n测试用例 1：\n- 初始 $t_{0}$：\n$$\n\\begin{bmatrix}\n00000000\\\\\n00000010\\\\\n00000000\\\\\n00011000\\\\\n00011000\\\\\n00000000\\\\\n00000000\\\\\n00000000\n\\end{bmatrix}\n$$\n- 观测校准：\n$$\n\\begin{bmatrix}\n00000000\\\\\n00000011\\\\\n00111111\\\\\n00111100\\\\\n00111100\\\\\n00111100\\\\\n00000000\\\\\n00000000\n\\end{bmatrix}\n$$\n- 观测留出：\n$$\n\\begin{bmatrix}\n00000000\\\\\n00000010\\\\\n00000000\\\\\n00011100\\\\\n00011100\\\\\n00011100\\\\\n00000000\\\\\n00000000\n\\end{bmatrix}\n$$\n\n测试用例 2：\n- 初始 $t_{0}$：\n$$\n\\begin{bmatrix}\n00000000\\\\\n01100000\\\\\n00000000\\\\\n00000000\\\\\n00000000\\\\\n00000000\\\\\n00000000\\\\\n00000000\n\\end{bmatrix}\n$$\n- 观测校准：\n$$\n\\begin{bmatrix}\n00000000\\\\\n01100000\\\\\n00000000\\\\\n00000000\\\\\n00000000\\\\\n00000000\\\\\n00000000\\\\\n00000000\n\\end{bmatrix}\n$$\n- 观测留出：\n$$\n\\begin{bmatrix}\n00000000\\\\\n01100000\\\\\n00000000\\\\\n00000000\\\\\n00000000\\\\\n00000000\\\\\n00000000\\\\\n00000000\n\\end{bmatrix}\n$$\n\n测试用例 3：\n- 初始 $t_{0}$：\n$$\n\\begin{bmatrix}\n00000000\\\\\n10000001\\\\\n00100000\\\\\n00110000\\\\\n00010000\\\\\n00000100\\\\\n01000100\\\\\n00000000\n\\end{bmatrix}\n$$\n- 观测校准：\n$$\n\\begin{bmatrix}\n00000000\\\\\n10000011\\\\\n00111110\\\\\n00111100\\\\\n00111100\\\\\n00111110\\\\\n01000100\\\\\n00000000\n\\end{bmatrix}\n$$\n- 观测留出：\n$$\n\\begin{bmatrix}\n00000000\\\\\n10000010\\\\\n00111000\\\\\n00111000\\\\\n00111000\\\\\n00000100\\\\\n01000100\\\\\n00000000\n\\end{bmatrix}\n$$\n\n所需输出：\n- 对于每个测试用例，程序必须输出一个包含四个元素的列表：$\\alpha^{\\star}$、$D_{\\text{cal}}(\\alpha^{\\star})$、$D_{\\text{val}}(\\alpha^{\\star})$ 以及一个指示过拟合的布尔值，定义为 $D_{\\text{val}}(\\alpha^{\\star}) - D_{\\text{cal}}(\\alpha^{\\star}) > 0.1$。\n- 所有浮点输出必须表示为小数点后舍入到六位的小数。布尔值必须是 True 或 False。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素是对应一个测试用例的四元素列表，顺序与上文呈现的相同（例如，“[[alpha1,Dcal1,Dval1,flag1],[alpha2,Dcal2,Dval2,flag2],[alpha3,Dcal3,Dval3,flag3]]”）。不应打印任何额外的文本。",
            "solution": "我们从同步元胞自动机 (CA) 更新的正式定义以及恒定风险率与单位区间内至少发生一次事件的概率之间的标准转换开始。令一个未开发单元格 $i$ 在 $4$-邻接下有 $n_{i}$ 个已开发邻居，其经历的强度 $\\lambda_{i}$ 与 $n_{i}$ 成正比，即 $\\lambda_{i} = \\alpha n_{i}$，其中 $\\alpha \\ge 0$ 是待校准的未知参数。在泊松假设和跨位置独立性的前提下，单位时间内至少发生一次开发事件的概率为 $P_{i} = 1 - e^{-\\lambda_{i}} = 1 - e^{-\\alpha n_{i}}$。已开发的单元格在单步转换中保持已开发状态，这强制了开发的单调性，与许多短期土地利用变化模型一致。\n\n斑块大小分布的构建源于已开发状态上基于 $4$-邻接的连通分量。对于任何具有已开发状态集合 $S$ 的地图，我们通过标记 $4$-邻接下的每个连通分量并计算每个分量中的单元格数量来计算斑块大小。这将产生一个斑块大小的多重集 $\\{s_{1}, s_{2}, \\dots, s_{k}\\}$。经验累积分布函数 (ECDF) $F(x)$ 定义为\n$$\nF(x) = \\frac{1}{k} \\sum_{j=1}^{k} \\mathbf{1}\\{s_{j} \\le x\\},\n$$\n其中约定，如果 $k=0$，则 $F(x)=0$。具有 ECDF $F$ 和 $G$ 的两个样本之间的柯尔莫哥洛夫-斯米尔诺夫 (KS) 差异是\n$$\nD = \\sup_{x} |F(x) - G(x)|,\n$$\n我们将其在两个样本中观察到的不同大小的并集上进行评估，因为右连续阶梯函数之差的上确界是在一个跳跃点上达到的。如果两个样本都为空，则 $F \\equiv 0$ 且 $G \\equiv 0$，得出 $D=0$。如果一个样本为空而另一个样本有任何质量，则在非空样本的支持域上进行评估会产生 $D=1$。\n\n为了校准 $\\alpha$，我们通过蒙特卡洛复制来近似模拟的 CA 输出与观测校准地图之间的期望 KS 差异。具体来说，对于网格 $\\{0.00, 0.05, \\dots, 1.00\\}$ 上的每个候选 $\\alpha$，我们从提供的初始地图开始执行 $R = 32$ 次独立的单步 CA 模拟。对于每次模拟，我们计算斑块大小，形成 ECDF，并计算与校准 ECDF 的 KS 差异。然后，我们对 $R$ 次复制的 KS 差异进行平均，以估计该 $\\alpha$ 值的期望差异。校准参数 $\\alpha^{\\star}$ 是实现最小平均 KS 差异的最小 $\\alpha$。\n\n使用留出地图进行过拟合诊断。在从校准中固定 $\\alpha^{\\star}$ 后，我们通过从初始地图进行 $R = 32$ 次独立的 CA 运行并计算与留出 ECDF 的平均 KS 值来类似地估计验证差异 $D_{\\text{val}}(\\alpha^{\\star})$。泛化差距为 $g = D_{\\text{val}}(\\alpha^{\\star}) - D_{\\text{cal}}(\\alpha^{\\star})$。如果 $g > \\tau$，其中 $\\tau = 0.1$，我们诊断为过拟合。其逻辑是，一个模型经过调整以减少校准差异，但在留出数据上表现出显著更高的差异，这表明该参数捕获了特有的校准特征而非通用结构，这与过拟合的统计定义一致。\n\n算法实现细节：\n- 邻域计数 $n_{i}$ 在 $4$-邻接下计算，并在网格边界处进行零填充。对于每个单元格 $(r, c)$，$n_{r,c}$ 是在 $(r-1,c)$、$(r+1,c)$、$(r,c-1)$ 和 $(r,c+1)$ 处（当索引有效时）的已开发状态之和。\n- CA 更新是同步的：首先从初始地图计算所有 $n_{i}$，然后计算 $P_{i} = 1 - e^{-\\alpha n_{i}}$，最后为每个单元格独立地抽取均匀随机变量 $U_{i} \\sim \\text{Uniform}(0,1)$，通过 $\\mathbf{1}\\{U_{i}  P_{i}\\}$ 来决定未开发单元格的转换；已开发的单元格保持为 $1$。\n- 连通分量标记使用广度优先搜索 (BFS) 或深度优先搜索 (DFS) 在 $4$-邻接上进行，标记已访问的已开发单元格并计算每个分量的大小以生成斑块大小多重集。\n- KS 差异 $D$ 是通过在任一样本中存在的不同大小的并集上评估 ECDF 来计算的，包括所描述的空样本情况。\n\n边缘情况与覆盖范围：\n- 测试用例 2 是一个边界情况，初始地图与两个观测地图之间没有观察到变化。校准后的 $\\alpha^{\\star}$ 应接近 $0$，KS 差异应很小，泛化差距可忽略不计，并且不应诊断为过拟合。\n- 测试用例 1 是一个典型情况，其中观测校准显示出围绕初始簇的显著邻域驱动增长，而留出地图显示出更温和的增长，从而允许进行非平凡的校准和适度的泛化差距。\n- 测试用例 3 强调分散的种子和强烈的校准增长，而留出地图则表明较弱的扩张。这通过可能产生比校准差异更大的验证差异来测试过拟合诊断。\n\n输出规格：\n- 对于每个测试用例，我们输出一个列表 $[\\alpha^{\\star}, D_{\\text{cal}}(\\alpha^{\\star}), D_{\\text{val}}(\\alpha^{\\star}), \\text{flag}]$，其中如果 $D_{\\text{val}}(\\alpha^{\\star}) - D_{\\text{cal}}(\\alpha^{\\star})  0.1$，则标志为 True，否则为 False。所有浮点值都舍入到小数点后六位。\n- 程序按测试套件定义的顺序打印包含这些每个测试用例列表的单行列表。\n\n这种方法将基于风险的 CA 公式与通过基于 ECDF 的 KS 差异进行统计校准和留出验证相结合，以诊断过拟合，这与土地利用和土地覆盖变化的有原则的环境和地球系统建模一致。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef four_neighbor_counts(grid: np.ndarray) - np.ndarray:\n    \"\"\"\n    Compute the number of developed (1) neighbors under 4-adjacency for each cell.\n    \"\"\"\n    n = np.zeros_like(grid, dtype=int)\n    # neighbor below contributes to current cell's count\n    n[:-1, :] += grid[1:, :]\n    # neighbor above\n    n[1:, :] += grid[:-1, :]\n    # neighbor right\n    n[:, :-1] += grid[:, 1:]\n    # neighbor left\n    n[:, 1:] += grid[:, :-1]\n    return n\n\ndef ca_step(initial: np.ndarray, alpha: float, rng: np.random.Generator) - np.ndarray:\n    \"\"\"\n    Perform one synchronous CA step using P = 1 - exp(-alpha * n_neighbors).\n    Developed cells remain developed.\n    \"\"\"\n    grid = initial\n    n = four_neighbor_counts(grid)\n    # Transition probabilities for non-developed cells\n    P = 1.0 - np.exp(-alpha * n.astype(float))\n    # Sample uniforms\n    U = rng.random(grid.shape)\n    next_grid = grid.copy()\n    zero_mask = (grid == 0)\n    # Apply transitions only to zero cells\n    next_grid[zero_mask] = (U[zero_mask]  P[zero_mask]).astype(int)\n    return next_grid\n\ndef patch_sizes(grid: np.ndarray) - list:\n    \"\"\"\n    Compute patch sizes as 4-connected components of 1s.\n    Returns a list of integers.\n    \"\"\"\n    visited = np.zeros_like(grid, dtype=bool)\n    sizes = []\n    rows, cols = grid.shape\n\n    for r in range(rows):\n        for c in range(cols):\n            if grid[r, c] == 1 and not visited[r, c]:\n                # BFS from (r, c)\n                q = [(r, c)]\n                visited[r, c] = True\n                size = 0\n                while q:\n                    rr, cc = q.pop()\n                    size += 1\n                    # 4-neighbors\n                    if rr > 0 and grid[rr - 1, cc] == 1 and not visited[rr - 1, cc]:\n                        visited[rr - 1, cc] = True\n                        q.append((rr - 1, cc))\n                    if rr  rows - 1 and grid[rr + 1, cc] == 1 and not visited[rr + 1, cc]:\n                        visited[rr + 1, cc] = True\n                        q.append((rr + 1, cc))\n                    if cc > 0 and grid[rr, cc - 1] == 1 and not visited[rr, cc - 1]:\n                        visited[rr, cc - 1] = True\n                        q.append((rr, cc - 1))\n                    if cc  cols - 1 and grid[rr, cc + 1] == 1 and not visited[rr, cc + 1]:\n                        visited[rr, cc + 1] = True\n                        q.append((rr, cc + 1))\n                sizes.append(size)\n    return sizes\n\ndef ks_distance(sample_a: list, sample_b: list) - float:\n    \"\"\"\n    Compute the Kolmogorov–Smirnov discrepancy between two finite samples of integers.\n    If both samples are empty, return 0. If one is empty and the other is non-empty, return 1.\n    \"\"\"\n    na = len(sample_a)\n    nb = len(sample_b)\n    if na == 0 and nb == 0:\n        return 0.0\n    if na == 0 and nb > 0:\n        # ECDF_A(x) == 0, ECDF_B reaches 1 across its support, so sup difference is 1\n        return 1.0\n    if nb == 0 and na > 0:\n        return 1.0\n\n    a_sorted = np.sort(np.array(sample_a))\n    b_sorted = np.sort(np.array(sample_b))\n    # Evaluate ECDFs on the union of unique points\n    xs = np.unique(np.concatenate([a_sorted, b_sorted]))\n    Fa = np.searchsorted(a_sorted, xs, side='right') / na\n    Fb = np.searchsorted(b_sorted, xs, side='right') / nb\n    return float(np.max(np.abs(Fa - Fb)))\n\ndef average_ks(initial: np.ndarray, obs_sizes: list, alpha: float, R: int, rng_seed: int) - float:\n    \"\"\"\n    Estimate expected KS discrepancy by averaging over R replicates for a given alpha.\n    \"\"\"\n    rng = np.random.default_rng(rng_seed)\n    ks_vals = []\n    for _ in range(R):\n        sim_grid = ca_step(initial, alpha, rng)\n        sim_sizes = patch_sizes(sim_grid)\n        ks_vals.append(ks_distance(sim_sizes, obs_sizes))\n    return float(np.mean(ks_vals))\n\ndef calibrate_and_validate(initial: np.ndarray, obs_cal: np.ndarray, obs_val: np.ndarray,\n                           alpha_grid: np.ndarray, R: int, tau: float, seed_cal: int, seed_val: int):\n    \"\"\"\n    Calibrate alpha on obs_cal, then evaluate validation discrepancy on obs_val.\n    Return alpha_star, D_cal, D_val, overfit_flag.\n    \"\"\"\n    # Precompute observed patch size samples\n    obs_cal_sizes = patch_sizes(obs_cal)\n    obs_val_sizes = patch_sizes(obs_val)\n\n    # Grid search over alpha\n    best_alpha = None\n    best_score = None\n    # Use independent seeds per alpha but deterministic across alphas\n    # For comparability, we can use a fixed seed per alpha = seed_cal + int(alpha*1000)\n    for alpha in alpha_grid:\n        seed_for_alpha = seed_cal + int(round(alpha * 1000))\n        score = average_ks(initial, obs_cal_sizes, alpha, R, seed_for_alpha)\n        if best_score is None or score  best_score - 1e-12 or (abs(score - best_score) = 1e-12 and (best_alpha is None or alpha  best_alpha)):\n            best_score = score\n            best_alpha = alpha\n\n    # Compute validation discrepancy at alpha*\n    D_cal = average_ks(initial, obs_cal_sizes, best_alpha, R, seed_cal)\n    D_val = average_ks(initial, obs_val_sizes, best_alpha, R, seed_val)\n    gap = D_val - D_cal\n    overfit = gap > tau\n    return best_alpha, D_cal, D_val, overfit\n\ndef to_float6(x: float) - float:\n    \"\"\"\n    Round to six decimal places, returning a float for printing consistency.\n    \"\"\"\n    return float(f\"{x:.6f}\")\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = []\n\n    # Test case 1\n    I1 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,1,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,1,1,0,0,0],\n        [0,0,0,1,1,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    C1 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,1,1],\n        [0,0,1,1,1,1,1,1],\n        [0,0,1,1,1,1,0,0],\n        [0,0,1,1,1,1,0,0],\n        [0,0,1,1,1,1,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    V1 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,1,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,1,1,1,0,0],\n        [0,0,0,1,1,1,0,0],\n        [0,0,0,1,1,1,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    test_cases.append((I1, C1, V1, 12345, 54321))\n\n    # Test case 2\n    I2 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [0,1,1,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    C2 = I2.copy()\n    V2 = I2.copy()\n    test_cases.append((I2, C2, V2, 24680, 86420))\n\n    # Test case 3\n    I3 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [1,0,0,0,0,0,0,1],\n        [0,0,1,0,0,0,0,0],\n        [0,0,1,1,0,0,0,0],\n        [0,0,0,1,0,0,0,0],\n        [0,0,0,0,0,1,0,0],\n        [0,1,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    C3 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [1,0,0,0,0,0,1,1],\n        [0,0,1,1,1,1,1,0],\n        [0,0,1,1,1,1,0,0],\n        [0,0,1,1,1,1,0,0],\n        [0,0,1,1,1,1,1,0],\n        [0,1,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    V3 = np.array([\n        [0,0,0,0,0,0,0,0],\n        [1,0,0,0,0,0,1,0],\n        [0,0,1,1,1,0,0,0],\n        [0,0,1,1,1,0,0,0],\n        [0,0,1,1,1,0,0,0],\n        [0,0,0,0,0,1,0,0],\n        [0,1,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0,0]\n    ], dtype=int)\n    test_cases.append((I3, C3, V3, 13579, 97531))\n\n    # Calibration parameters\n    alpha_grid = np.round(np.linspace(0.0, 1.0, 21), 2)  # 0.00 to 1.00 in 0.05 steps\n    R = 32\n    tau = 0.1\n\n    results = []\n    for (initial, obs_cal, obs_val, seed_cal, seed_val) in test_cases:\n        alpha_star, D_cal, D_val, overfit = calibrate_and_validate(\n            initial, obs_cal, obs_val, alpha_grid, R, tau, seed_cal, seed_val\n        )\n        # Round floats to six decimal places\n        result = [to_float6(alpha_star), to_float6(D_cal), to_float6(D_val), overfit]\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(str(results))\n\nsolve()\n```"
        }
    ]
}