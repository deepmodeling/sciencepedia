{
    "hands_on_practices": [
        {
            "introduction": "在任何模型评估中，分析残差的第一步是计算其基本统计特性。本练习将指导您从第一性原理出发，计算残差序列的均值、方差和自相关系数，这些是诊断模型系统性偏差（如偏移）和时间依赖性的基础。通过这个实践，您将掌握解读模型基本行为的关键技能。",
            "id": "3862150",
            "problem": "考虑一个月度水文时间序列背景，其中观测径流量 $Q_t$（单位为立方米/秒，写作 $\\mathrm{m^3/s}$）与模型估计的径流量 $\\hat{Q}_t$ 在 $t = 1, \\dots, n$ 时刻配对。将时间 $t$ 的模型残差定义为 $r_t = Q_t - \\hat{Q}_t$，其中 $r_t$ 的单位为 $\\mathrm{m^3/s}$。从第一性原理的角度出发，使用描述性统计和时间序列分析（自相关函数ACF）中的经典样本定义，计算残差序列的三个汇总统计量：样本均值、无偏样本方差和滞后1阶样本自相关。滞后1阶自相关必须使用连续残差离差（相对于其样本均值）之间的相关性来计算。如果给定案例中 $r_t$ 的样本方差为零，则按惯例将滞后1阶自相关定义为 $0$。平均残差以 $\\mathrm{m^3/s}$ 表示，方差以 $(\\mathrm{m^3/s})^2$ 表示，滞后1阶自相关为无单位的纯数。此任务不涉及角度。\n\n仅从基本定义（样本均值、无偏样本方差和通过样本协方差计算的样本自相关）出发，实现一个程序，为每个提供的测试案例生成三个残差汇总统计量。问题陈述中不允许使用任何简化公式；解决方案必须从核心定义推导得出。\n\n使用以下测试套件。每个测试案例提供序列 $(Q_t)_{t=1}^n$ 和 $(\\hat{Q}_t)_{t=1}^n$：\n\n- 测试案例 1（季节性模型偏差，$n = 12$）：\n  - $Q_t = \\{42, 55, 60, 75, 110, 160, 190, 175, 140, 100, 70, 50\\}$。\n  - $\\hat{Q}_t = \\{40, 50, 58, 80, 120, 150, 180, 170, 130, 95, 75, 55\\}$。\n\n- 测试案例 2（完美模型，$n = 12$）：\n  - $Q_t = \\{60, 65, 70, 90, 130, 170, 200, 190, 150, 110, 80, 60\\}$。\n  - $\\hat{Q}_t = \\{60, 65, 70, 90, 130, 170, 200, 190, 150, 110, 80, 60\\}$。\n\n- 测试案例 3（恒定偏差，$n = 12$）：\n  - $Q_t = \\{42, 55, 60, 75, 110, 160, 190, 175, 140, 100, 70, 50\\}$。\n  - $\\hat{Q}_t = \\{22, 35, 40, 55, 90, 140, 170, 155, 120, 80, 50, 30\\}$。\n\n- 测试案例 4（残差中存在强正序列相关性，$n = 12$）：\n  - $Q_t = \\{50, 60, 70, 90, 120, 160, 190, 180, 150, 110, 80, 60\\}$。\n  - $\\hat{Q}_t = \\{45, 52, 58, 75, 103, 141, 170, 162, 134, 96, 70, 53\\}$。\n\n- 测试案例 5（交替残差，负序列相关性，$n = 12$）：\n  - $Q_t = \\{50, 60, 70, 90, 120, 160, 190, 180, 150, 110, 80, 60\\}$。\n  - $\\hat{Q}_t = \\{40, 70, 61, 99, 112, 168, 183, 187, 156, 104, 85, 55\\}$。\n\n- 测试案例 6（最小长度的边界情况，$n = 2$）：\n  - $Q_t = \\{100, 120\\}$。\n  - $\\hat{Q}_t = \\{95, 130\\}$。\n\n对于每个测试案例，计算：\n- 样本均值 $\\bar{r}$（单位为 $\\mathrm{m^3/s}$）。\n- 无偏样本方差 $s_r^2$（单位为 $(\\mathrm{m^3/s})^2$）。\n- 滞后1阶自相关 $\\rho_1$（无单位）。\n\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试案例的结果必须是一个包含三个小数值 $[\\bar{r}, s_r^2, \\rho_1]$ 的列表，并四舍五入到 $6$ 位小数，整体输出必须是按测试案例顺序排列的这些列表的列表，例如：$[[x_1,y_1,z_1],[x_2,y_2,z_2],\\dots]$。",
            "solution": "此问题经评估为有效。它在科学上基于时间序列分析和描述性统计应用于环境模型评估的原理。问题陈述清晰，提供了计算唯一且有意义解所需的所有数据和定义。语言客观而精确。我将按要求从第一性原理出发推导解决方案。\n\n任务是为模型残差的时间序列 $r_t = Q_t - \\hat{Q}_t$ 计算三个统计汇总量，其中 $Q_t$ 是观测径流量，$\\hat{Q}_t$ 是在时间 $t$ 模型估计的径流量，$t = 1, \\dots, n$。所需的汇总量为样本均值（$\\bar{r}$）、无偏样本方差（$s_r^2$）和滞后1阶样本自相关（$\\rho_1$）。\n\n设残差序列为 $r = \\{r_1, r_2, \\dots, r_n\\}$。\n\n**1. 样本均值 ($\\bar{r}$)**\n\n样本均值是残差值的算术平均值。这是样本分布的一阶矩。其经典定义是所有观测值之和除以观测次数 $n$。\n\n$$ \\bar{r} = \\frac{1}{n} \\sum_{t=1}^{n} r_t $$\n\n$\\bar{r}$ 的单位与 $r_t$ 的单位相同，即 $\\mathrm{m^3/s}$。\n\n**2. 无偏样本方差 ($s_r^2$)**\n\n无偏样本方差衡量数据围绕样本均值的离散程度。“无偏”一词表示分母为 $n-1$，这修正了因使用样本均值代替真实（但未知）的总体均值而引入的偏差。其定义为与样本均值的平方偏差之和除以 $n-1$。\n\n$$ s_r^2 = \\frac{1}{n-1} \\sum_{t=1}^{n} (r_t - \\bar{r})^2 $$\n\n此定义对 $n > 1$ 有效。所有提供的测试案例都满足此条件。$s_r^2$ 的单位是 $r_t$ 单位的平方，即 $(\\mathrm{m^3/s})^2$。\n\n**3. 滞后1阶样本自相关 ($\\rho_1$)**\n\n滞后1阶样本自相关衡量残差值 $r_t$ 与其后继残差值 $r_{t+1}$ 之间的线性关系。问题要求使用‘连续残差离差（相对于其样本均值）之间的相关性’来计算它。这对应于滞后1阶样本自相关函数（ACF）的标准定义，即滞后1阶样本自协方差除以样本方差（或滞后0阶自协方差）。\n\n滞后 $k$ 阶的样本自协方差，记为 $\\hat{\\gamma}(k)$，定义为：\n$$ \\hat{\\gamma}(k) = \\frac{1}{n} \\sum_{t=1}^{n-k} (r_t - \\bar{r})(r_{t+k} - \\bar{r}) $$\n\n对于滞后 $k=1$，自协方差为：\n$$ \\hat{\\gamma}(1) = \\frac{1}{n} \\sum_{t=1}^{n-1} (r_t - \\bar{r})(r_{t+1} - \\bar{r}) $$\n\n样本方差，即滞后 $k=0$ 时的自协方差，为：\n$$ \\hat{\\gamma}(0) = \\frac{1}{n} \\sum_{t=1}^{n} (r_t - \\bar{r})^2 $$\n\n滞后1阶样本自相关 $\\rho_1$ 是 $\\hat{\\gamma}(1)$ 与 $\\hat{\\gamma}(0)$ 的比值。分子和分母中的因子 $1/n$ 会消掉。\n\n$$ \\rho_1 = \\frac{\\hat{\\gamma}(1)}{\\hat{\\gamma}(0)} = \\frac{\\frac{1}{n} \\sum_{t=1}^{n-1} (r_t - \\bar{r})(r_{t+1} - \\bar{r})}{\\frac{1}{n} \\sum_{t=1}^{n} (r_t - \\bar{r})^2} = \\frac{\\sum_{t=1}^{n-1} (r_t - \\bar{r})(r_{t+1} - \\bar{r})}{\\sum_{t=1}^{n} (r_t - \\bar{r})^2} $$\n\n量 $\\rho_1$ 是一个无量綱的纯数，因为分子中的单位 $(\\mathrm{m^3/s})^2$与分母中的单位相抵消。根据问题陈述，必须处理一个特殊情况：如果样本方差为零，即分母 $\\sum_{t=1}^{n} (r_t - \\bar{r})^2$ 为零，则 $\\rho_1$ 定义为 $0$。这个惯例避免了除以零。这种情况当且仅当所有残差 $r_t$ 都相同时发生，从而导致 $s_r^2=0$。\n\n实现将针对每个提供的测试案例遵循这三个推导出的公式。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes residual summaries for multiple test cases and prints the results.\n    The summaries are: sample mean, unbiased sample variance, and lag-1 autocorrelation.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1 (seasonal model bias, n = 12)\n        (\n            np.array([42, 55, 60, 75, 110, 160, 190, 175, 140, 100, 70, 50], dtype=np.float64),\n            np.array([40, 50, 58, 80, 120, 150, 180, 170, 130, 95, 75, 55], dtype=np.float64)\n        ),\n        # Test Case 2 (perfect model, n = 12)\n        (\n            np.array([60, 65, 70, 90, 130, 170, 200, 190, 150, 110, 80, 60], dtype=np.float64),\n            np.array([60, 65, 70, 90, 130, 170, 200, 190, 150, 110, 80, 60], dtype=np.float64)\n        ),\n        # Test Case 3 (constant bias, n = 12)\n        (\n            np.array([42, 55, 60, 75, 110, 160, 190, 175, 140, 100, 70, 50], dtype=np.float64),\n            np.array([22, 35, 40, 55, 90, 140, 170, 155, 120, 80, 50, 30], dtype=np.float64)\n        ),\n        # Test Case 4 (strong positive serial dependence in residuals, n = 12)\n        (\n            np.array([50, 60, 70, 90, 120, 160, 190, 180, 150, 110, 80, 60], dtype=np.float64),\n            np.array([45, 52, 58, 75, 103, 141, 170, 162, 134, 96, 70, 53], dtype=np.float64)\n        ),\n        # Test Case 5 (alternating residuals, negative serial dependence, n = 12)\n        (\n            np.array([50, 60, 70, 90, 120, 160, 190, 180, 150, 110, 80, 60], dtype=np.float64),\n            np.array([40, 70, 61, 99, 112, 168, 183, 187, 156, 104, 85, 55], dtype=np.float64)\n        ),\n        # Test Case 6 (boundary case with minimal length, n = 2)\n        (\n            np.array([100, 120], dtype=np.float64),\n            np.array([95, 130], dtype=np.float64)\n        )\n    ]\n    \n    results_list = []\n    \n    for Q_t, Q_hat_t in test_cases:\n        \n        # 0. Calculate the residual series r_t = Q_t - Q_hat_t\n        r_t = Q_t - Q_hat_t\n        n = len(r_t)\n\n        # 1. Compute the sample mean of residuals, r_bar\n        # Formula: r_bar = (1/n) * sum(r_t) for t=1 to n\n        r_bar = np.mean(r_t)\n\n        # 2. Compute the unbiased sample variance, s_r^2\n        # Formula: s_r^2 = (1/(n-1)) * sum((r_t - r_bar)^2) for t=1 to n\n        # numpy.var with ddof=1 calculates the unbiased sample variance.\n        # This check is only for n=1, but all test cases have n>1.\n        if n > 1:\n            s_r_sq = np.var(r_t, ddof=1)\n        else:\n            s_r_sq = 0.0\n\n        # 3. Compute the lag-1 autocorrelation, rho_1\n        # Formula: rho_1 = sum((r_t - r_bar)(r_{t+1} - r_bar)) / sum((r_t - r_bar)^2)\n        # The sum in the numerator is from t=1 to n-1.\n        \n        # Calculate deviations from the mean (anomalies)\n        anomalies = r_t - r_bar\n        \n        # Calculate the denominator: sum of squared anomalies\n        sum_sq_anomalies = np.sum(anomalies**2)\n\n        # Handle the case where variance is zero, as specified in the problem\n        if sum_sq_anomalies  1e-12: # Use a small tolerance for float comparison\n            rho_1 = 0.0\n        else:\n            # Numerator: sum of products of consecutive anomalies\n            # anomalies[:-1] is {r_1-r_bar, ..., r_{n-1}-r_bar}\n            # anomalies[1:] is {r_2-r_bar, ..., r_n-r_bar}\n            numerator = np.sum(anomalies[:-1] * anomalies[1:])\n            rho_1 = numerator / sum_sq_anomalies\n        \n        # Store results for this case, formatted to 6 decimal places\n        case_result = [r_bar, s_r_sq, rho_1]\n        results_list.append(case_result)\n\n    # Format the final output string as a list of lists.\n    # Each sublist contains the three computed values rounded to 6 decimal places.\n    output_parts = []\n    for res in results_list:\n        # Format each number to 6 decimal places (f-string with :.6f)\n        # and create the string for one sub-list, e.g., \"[val1,val2,val3]\"\n        formatted_res = f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f}]\"\n        output_parts.append(formatted_res)\n\n    # Join the sub-list strings with commas and enclose in brackets,\n    # e.g., \"[[...],[...]]\"\n    final_output = f\"[{','.join(output_parts)}]\"\n\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "在评估了残差的总体特征之后，深入探究单个数据点的影响至关重要。本练习介绍了关键的回归诊断工具——杠杆值($h_{ii}$)、学生化残差($t_i$)和库克距离($D_i$)，它们是识别对模型参数有过度影响的观测点的利器。掌握这些诊断方法有助于确保模型的稳健性和可靠性。",
            "id": "3862109",
            "problem": "您正在分析用于环境与地球系统建模的线性普通最小二乘法 (OLS) 回归的残差，该回归用于根据河流流量和水温估算每日河流营养物负荷。考虑一个带截距的线性模型，其中响应变量是单位为千克/天的营养物负荷，预测变量是单位为立方米/秒的流量和单位为摄氏度的水温。使用以下模型设定：\n给定 $n$ 个观测值，定义设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$，其中 $p = 3$ 列（一个截距、流量和温度），响应向量 $y \\in \\mathbb{R}^n$，并假设线性模型为 $y = X \\beta + \\varepsilon$，其中 $\\beta \\in \\mathbb{R}^p$ 未知，$\\varepsilon$ 是均值为零、方差恒定的独立误差。\n\n从 OLS 估计量和残差的定义出发，对每个观测值 $i \\in \\{1,\\dots,n\\}$ 计算：\n- 杠杆值 $h_{ii}$（帽子矩阵的第 $i$ 个对角元素）。\n- 外学生化残差 $t_i$。\n- 库克距离 $D_i$。\n\n然后，使用以下决策规则识别影响斜率估计的强影响点：\n如果满足以下任一条件，则观测值 $i$ 被标记为强影响点：\n1) $D_i  \\frac{4}{n}$，或\n2) $h_{ii}  \\frac{2p}{n}$ 且 $|t_i|  t_{0.975}(n - p - 1)$，其中 $t_{0.975}(\\cdot)$ 表示具有指定自由度的学生t分布的上 $0.975$ 分位数。\n\n所有量 $h_{ii}$、$t_i$ 和 $D_i$ 都是无量纲的，并且必须以四舍五入到六位小数的浮点数形式报告。强影响点的索引必须使用从零开始的索引进行报告。\n\n使用以下三个测试用例。对于每个用例，用一列1（截距）、流量向量和温度向量来构建 $X$，并使用提供的营养物负荷向量 $y$。指定单位是为了科学真实性，但输出是无量纲的。\n\n测试用例1（理想路径，中等变异性，$n=8$）：\n- 流量向量 (单位 $\\mathrm{m}^3/\\mathrm{s}$): $[80, 95, 110, 125, 140, 155, 170, 185]$。\n- 温度向量 (单位 $^\\circ\\text{C}$): $[10, 12, 11, 13, 15, 14, 16, 12]$。\n- 营养物负荷向量 (单位 $\\mathrm{kg/day}$): $[255, 292, 327, 370, 418, 450, 491, 520]$。\n\n测试用例2（边界条件，存在高杠杆值候选点，$n=9$）：\n- 流量向量 (单位 $\\mathrm{m}^3/\\mathrm{s}$): $[80, 90, 100, 110, 120, 130, 140, 150, 350]$。\n- 温度向量 (单位 $^\\circ\\text{C}$): $[10, 11, 12, 13, 14, 12, 11, 13, 10]$。\n- 营养物负荷向量 (单位 $\\mathrm{kg/day}$): $[218, 241, 266, 290, 315, 332, 351, 378, 812]$。\n\n测试用例3（边缘案例，响应变量中存在异常值，$n=10$）：\n- 流量向量 (单位 $\\mathrm{m}^3/\\mathrm{s}$): $[100, 110, 120, 130, 140, 150, 160, 170, 180, 140]$。\n- 温度向量 (单位 $^\\circ\\text{C}$): $[12, 13, 14, 12, 13, 15, 14, 16, 15, 13]$。\n- 营养物负荷向量 (单位 $\\mathrm{kg/day}$): $[262, 284, 307, 322, 345, 370, 388, 415, 431, 420]$（注意最后一个值是相对于典型模式的有意设置的异常值）。\n\n算法要求：\n- 计算 OLS 估计量 $\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y$。\n- 计算残差 $r = y - X \\hat{\\beta}$。\n- 计算帽子矩阵 $H = X (X^\\top X)^{-1} X^\\top$ 及其对角线 $h_{ii}$。\n- 计算残差方差估计 $s^2 = \\frac{\\sum_{i=1}^{n} r_i^2}{n - p}$。\n- 通过恒等式计算留一法均方误差 $s_{(i)}^2$：$$s_{(i)}^2 = \\frac{(n - p) s^2 - \\frac{r_i^2}{1 - h_{ii}}}{n - p - 1},$$ 和外学生化残差 $$t_i = \\frac{r_i}{s_{(i)} \\sqrt{1 - h_{ii}}}.$$\n- 计算库克距离 $$D_i = \\frac{r_i^2}{p s^2} \\cdot \\frac{h_{ii}}{(1 - h_{ii})^2}.$$\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，输出一个包含四个元素的嵌套列表：$h_{ii}$ 值列表、$t_i$ 值列表、$D_i$ 值列表以及由决策规则确定的强影响点索引列表。所有浮点数必须四舍五入到六位小数。总输出必须是包含三个按用例划分的列表的单个顶级列表，例如：$[[h\\_1,t\\_1,D\\_1,I\\_1],[h\\_2,t\\_2,D\\_2,I\\_2],[h\\_3,t\\_3,D\\_3,I\\_3]]$，其中每个 $h\\_k$、$t\\_k$ 和 $D\\_k$ 本身是一个浮点数列表，每个 $I\\_k$ 是一个整数列表。",
            "solution": "该问题要求计算普通最小二乘法 (OLS) 线性回归的几个关键诊断统计量，并根据既定标准识别强影响点。该分析将在环境建模背景下对三个不同的测试用例进行。解决方案首先定义理论框架，然后将其算法化地应用于所提供的数据。\n\n多元线性回归模型的一般形式如下：\n$$ y = X \\beta + \\varepsilon $$\n其中，$y \\in \\mathbb{R}^n$ 是观测响应（营养物负荷）的向量，$X \\in \\mathbb{R}^{n \\times p}$ 是设计矩阵，$\\beta \\in \\mathbb{R}^p$ 是未知模型系数的向量，$\\varepsilon \\in \\mathbb{R}^n$ 是随机误差的向量。设计矩阵 $X$ 由预测变量（河流流量和水温）以及代表模型截距的前导全1列构成。因此，对于此问题，参数数量 $p$ 为 $3$。\n\n计算所需诊断统计量的分步过程如下：\n\n1.  **OLS 系数估计**：OLS 估计量 $\\hat{\\beta}$ 最小化残差平方和。它使用正规方程组计算：\n    $$ \\hat{\\beta} = (X^\\top X)^{-1} X^\\top y $$\n    这要求矩阵 $X^\\top X$ 是可逆的，如果 $X$ 的列是线性无关的，则该条件成立。\n\n2.  **拟合值和残差**：一旦找到 $\\hat{\\beta}$，拟合（或预测）值向量 $\\hat{y}$ 由下式给出：\n    $$ \\hat{y} = X \\hat{\\beta} $$\n    残差向量 $r$ 代表观测值和拟合值之间的差异，其计算公式为：\n    $$ r = y - \\hat{y} = y - X \\hat{\\beta} $$\n\n3.  **帽子矩阵和杠杆值**：帽子矩阵 $H$ 将观测响应向量 $y$ 映射到拟合值向量 $\\hat{y}$：\n    $$ \\hat{y} = X (X^\\top X)^{-1} X^\\top y = H y $$\n    帽子矩阵定义为 $H = X (X^\\top X)^{-1} X^\\top$。它是一个对称且幂等（$H^2=H$）的投影矩阵。帽子矩阵的对角元素 $h_{ii}$ 是每个观测值 $i$ 的杠杆值。杠杆值 $h_{ii}$ 衡量响应值 $y_i$ 对其自身拟合值 $\\hat{y}_i$ 的影响，即 $\\frac{\\partial \\hat{y}_i}{\\partial y_i} = h_{ii}$。它也反映了观测值 $i$ 的预测向量与预测变量空间中心的距离。$h_{ii}$ 的值有界，满足 $1/n \\le h_{ii} \\le 1$。\n\n4.  **残差方差估计**：误差方差 $\\sigma^2$ 的一个无偏估计量是均方误差 (MSE)，也记作 $s^2$：\n    $$ s^2 = \\frac{r^\\top r}{n - p} = \\frac{\\sum_{i=1}^{n} r_i^2}{n - p} $$\n    其中 $n-p$ 是残差自由度。\n\n5.  **外学生化残差**：观测值 $i$ 的外学生化残差 $t_i$ 是通过将残差 $r_i$ 与其标准误进行比较来计算的，其中标准误是使用*除*观测值 $i$ 之外的所有数据点拟合的模型来估计的。令 $s_{(i)}^2$ 为不包含观测值 $i$ 时计算的均方误差。学生化残差为：\n    $$ t_i = \\frac{r_i}{s_{(i)} \\sqrt{1 - h_{ii}}} $$\n    一个计算效率高的 $s_{(i)}^2$ 公式避免了重新拟合模型 $n$ 次：\n    $$ s_{(i)}^2 = \\frac{(n - p) s^2 - \\frac{r_i^2}{1 - h_{ii}}}{n - p - 1} $$\n    在标准 OLS 假设下，这些残差服从自由度为 $n - p - 1$ 的学生t分布。\n\n6.  **库克距离**：库克距离 $D_i$ 衡量当观测值 $i$ 从数据集中移除时，所有估计系数的总体变化。它是衡量一个观测值对模型拟合值的总体影响的度量。其计算公式为：\n    $$ D_i = \\frac{r_i^2}{p s^2} \\cdot \\frac{h_{ii}}{(1 - h_{ii})^2} $$\n    该公式结合了残差的大小（通过 $r_i^2$）和杠杆值（$h_{ii}$）来量化影响。\n\n7.  **强影响点的识别**：如果一个观测值满足两个常见诊断标准中的任何一个，则被标记为强影响点：\n    a.  其库克距离较大。一个常见的阈值是 $D_i  \\frac{4}{n}$。\n    b.  它同时具有高杠杆值和较大的残差。高杠杆值的一个常见阈值是 $h_{ii}  \\frac{2p}{n}$。当这种情况发生时，还会将其外学生化残差的绝对值与学生t分布的临界值进行比较。具体规则是 $|t_i|  t_{\\alpha/2}(n - p - 1)$，其中对于 $95\\%$ 的置信水平，$\\alpha=0.05$，因此我们使用 $0.975$ 分位数 $t_{0.975}(n - p - 1)$。\n\n该算法的流程是：将这些步骤应用于三个测试用例中的每一个，从提供的数据构建相应的 $X$ 和 $y$，计算 $h_{ii}$、$t_i$ 和 $D_i$ 的向量，然后应用决策规则来识别强影响点的索引。所有浮点结果均按要求四舍五入到六位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final results.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"discharge\": [80, 95, 110, 125, 140, 155, 170, 185],\n            \"temperature\": [10, 12, 11, 13, 15, 14, 16, 12],\n            \"load\": [255, 292, 327, 370, 418, 450, 491, 520],\n        },\n        {\n            \"discharge\": [80, 90, 100, 110, 120, 130, 140, 150, 350],\n            \"temperature\": [10, 11, 12, 13, 14, 12, 11, 13, 10],\n            \"load\": [218, 241, 266, 290, 315, 332, 351, 378, 812],\n        },\n        {\n            \"discharge\": [100, 110, 120, 130, 140, 150, 160, 170, 180, 140],\n            \"temperature\": [12, 13, 14, 12, 13, 15, 14, 16, 15, 13],\n            \"load\": [262, 284, 307, 322, 345, 370, 388, 415, 431, 420],\n        }\n    ]\n\n    all_results = []\n    \n    for case_data in test_cases:\n        discharge_vec = np.array(case_data[\"discharge\"])\n        temp_vec = np.array(case_data[\"temperature\"])\n        y = np.array(case_data[\"load\"])\n        n = len(y)\n        p = 3  # Intercept, discharge, temperature\n\n        # Construct the design matrix X\n        X = np.ones((n, p))\n        X[:, 1] = discharge_vec\n        X[:, 2] = temp_vec\n\n        # Calculate diagnostics\n        h_values, t_values, D_values, influential_indices = _calculate_diagnostics(X, y, n, p)\n        \n        # Format results for output\n        case_result = [\n            list(np.round(h_values, 6)),\n            list(np.round(t_values, 6)),\n            list(np.round(D_values, 6)),\n            influential_indices\n        ]\n        all_results.append(case_result)\n\n    # Final print statement in the exact required format.\n    # str() on a list creates a string like '[1, 2, 3]'.\n    # Joining these with commas and enclosing in brackets creates the desired format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\ndef _calculate_diagnostics(X, y, n, p):\n    \"\"\"\n    Calculate regression diagnostics for a given design matrix X and response y.\n    \n    Args:\n        X (np.ndarray): Design matrix of shape (n, p).\n        y (np.ndarray): Response vector of shape (n,).\n        n (int): Number of observations.\n        p (int): Number of parameters.\n        \n    Returns:\n        tuple: A tuple containing:\n            - h_values (np.ndarray): Leverage values.\n            - t_values (np.ndarray): Externally studentized residuals.\n            - D_values (np.ndarray): Cook's distances.\n            - influential_indices (list): List of zero-based indices of influential points.\n    \"\"\"\n    # OLS estimator: beta_hat = (X.T @ X)^-1 @ X.T @ y\n    try:\n        XTX_inv = np.linalg.inv(X.T @ X)\n    except np.linalg.LinAlgError:\n        # This case should not happen with the provided test data\n        return [], [], [], []\n\n    beta_hat = XTX_inv @ X.T @ y\n    \n    # Residuals: r = y - X @ beta_hat\n    residuals = y - X @ beta_hat\n    \n    # Hat matrix diagonal (leverages): H = X @ (X.T @ X)^-1 @ X.T\n    # Efficient calculation of the diagonal h_ii\n    h_values = np.sum((X @ XTX_inv) * X, axis=1)\n\n    # Residual variance estimate: s^2\n    df_residual = n - p\n    ssr = np.sum(residuals**2)\n    s2 = ssr / df_residual\n    \n    # Externally studentized residuals (t_i) and Cook's distance (D_i)\n    t_values = np.zeros(n)\n    D_values = np.zeros(n)\n    \n    # Small value to prevent division by zero in 1 - h_ii\n    epsilon = 1e-12 \n\n    for i in range(n):\n        # Leave-one-out mean squared error: s_(i)^2\n        s2_i = (df_residual * s2 - residuals[i]**2 / (1 - h_values[i] + epsilon)) / (df_residual - 1)\n        # Avoid sqrt of negative number if s2_i is slightly negative due to precision\n        if s2_i  0: s2_i = 0\n        \n        # Externally studentized residual: t_i\n        t_values[i] = residuals[i] / (np.sqrt(s2_i) * np.sqrt(1 - h_values[i] + epsilon))\n        \n        # Cook's distance: D_i\n        D_values[i] = (residuals[i]**2 / (p * s2)) * (h_values[i] / (1 - h_values[i] + epsilon)**2)\n\n    # Identify influential points\n    influential_indices = []\n    \n    # Rule 1 threshold\n    cook_threshold = 4 / n\n    \n    # Rule 2 thresholds\n    leverage_threshold = 2 * p / n\n    df_t = n - p - 1\n    if df_t > 0:\n        t_critical = t.ppf(0.975, df=df_t)\n    else: # Should not happen for valid n, p\n        t_critical = float('inf')\n\n    for i in range(n):\n        # Check rule 1\n        rule1_triggered = D_values[i] > cook_threshold\n        \n        # Check rule 2\n        rule2_triggered = (h_values[i] > leverage_threshold) and (np.abs(t_values[i]) > t_critical)\n        \n        if rule1_triggered or rule2_triggered:\n            influential_indices.append(i)\n            \n    return h_values, t_values, D_values, influential_indices\n\nsolve()\n```"
        },
        {
            "introduction": "环境建模中的一个常见挑战是残差方差不恒定（即异方差性），这违反了标准回归的一个关键假设。本练习将演示一种强大的技术——Box-Cox变换，用以稳定方差。通过系统地搜索最优变换参数，您可以学习如何修正模型以满足其基本假设，从而提高模型的有效性和预测性能。",
            "id": "3862126",
            "problem": "考虑一个以日降雨量为条件的建模设置，其中响应变量是仅在有降雨日的日降雨量。降雨量呈正偏态分布。您的任务是确定一个针对响应变量的最优 Box–Cox 族单调幂变换，以便在拟合一个带有一个预测变量的简单线性模型时，实现近似恒定的残差方差。Box-Cox 变换对正数据定义如下：对于参数 $\\lambda \\in \\mathbb{R}$ 和正标量 $y$，$$T_{\\lambda}(y) = \\begin{cases} \\dfrac{y^{\\lambda} - 1}{\\lambda},  \\lambda \\neq 0, \\\\ \\log(y),  \\lambda = 0. \\end{cases}$$ 您的程序必须为每个提供的测试用例实现以下任务：\n\n- 根据指定的预测变量 $x$ 和降雨量 $y$ 的生成模型生成合成数据，确保 $y$ 为正。对变换后的响应 $T_{\\lambda}(y)$ 与 $x$ 进行普通最小二乘（OLS）回归拟合；即拟合 $$T_{\\lambda}(y_i) = \\beta_0 + \\beta_1 x_i + \\varepsilon_i,$$ 其中 $\\varepsilon_i$ 是残差。\n- 对于一个从 -1.5 到 1.5（含）以 0.05 为步长的固定网格上的每个候选 $\\lambda$，计算两个异方差性诊断指标：\n  1. Breusch–Pagan (BP) 检验统计量及其 p 值，使用残差平方对拟合值的辅助回归。具体来说，对于拟合值 $\\hat{y}_i = \\beta_0 + \\beta_1 x_i$，将 $e_i^2$ 对截距项和 $\\hat{y}_i$ 进行回归，计算该辅助回归的决定系数 $R^2$，然后计算拉格朗日乘子统计量 $$LM = n R^2,$$ 其中 $n$ 是样本量。在同方差性的原假设下，$LM$ 渐近服从自由度为 $k$ 的 $\\chi^2$ 分布，其中 $k$ 是除截距项外的辅助回归量数量；这里 $k=1$。从此分布计算 p 值。\n  2. 一个基于分箱的方差比 $\\rho$，它代表了“残差-拟合值图”的可视化诊断。计算最低拟合值十分位数内和最高拟合值十分位数内 $e_i^2$ 的均值，并取其比率 $$\\rho = \\dfrac{\\overline{e^2 \\text{ in top decile}}}{\\overline{e^2 \\text{ in bottom decile}}}.$$ $\\rho$ 的值接近 1 表示近似同方差性，即残差方差在低拟合值和高拟合值之间是相似的。\n- 选择网格中使 BP 检验 p 值最大化的最优 $\\lambda$。如果 p 值出现相同（在数值容差范围内），则通过选择使 $|\\rho - 1|$ 最小化的 $\\lambda$ 来打破僵局。如果仍然存在平局，则选择最接近 0 的 $\\lambda$。\n- 对于所选的 $\\lambda$，报告一个列表，其中包含所选的 $\\lambda$（浮点数）、BP 检验 p 值（浮点数）、方差比 $\\rho$（浮点数），以及一个布尔值，该值指示两个诊断指标是否都根据以下阈值表明残差近似同方差：BP p 值 $\\geq 0.05$ 且 $\\rho \\in [0.8, 1.25]$。\n\n您必须确保生成模型的科学真实性。使用以下特意涵盖不同情境的测试套件：\n\n- 测试用例 A（乘性模型，中度偏斜；预期最优 $\\lambda$ 接近 0）：样本量 $n = 400$，随机种子 $20231101$，预测变量 $x_i \\sim \\mathcal{N}(0,1)$，乘性降雨模型 $$y_i = \\exp(2 + 0.7 x_i) \\cdot \\varepsilon_i,$$ 其中 $\\varepsilon_i \\sim \\text{Lognormal}(0, 0.5)$（$\\varepsilon_i$ 的对数服从 $\\mathcal{N}(0, 0.5^2)$）。降雨单位是毫米/天，但所有诊断和输出都是无量纲的。\n- 测试用例 B（加性模型，接近高斯分布；预期最优 $\\lambda$ 接近 1）：样本量 $n = 400$，随机种子 $20231102$，预测变量 $x_i \\sim \\mathcal{N}(0,1)$，加性降雨模型 $$y_i = 15 + 2.0 x_i + e_i,$$ 其中 $e_i \\sim \\mathcal{N}(0, 1)$。降雨单位是毫米/天，但所有诊断和输出都是无量纲的。\n- 测试用例 C（乘性模型，重度偏斜；预期最优 $\\lambda$ 接近 0）：样本量 $n = 400$，随机种子 $20231103$，预测变量 $x_i \\sim \\mathcal{N}(0,1)$，乘性降雨模型 $$y_i = \\exp(1.5 + 0.8 x_i) \\cdot \\varepsilon_i,$$ 其中 $\\varepsilon_i \\sim \\text{Lognormal}(0, 1.0)$。\n- 测试用例 D（乘性模型，中度偏斜，小样本；预期最优 $\\lambda$ 接近 0，但具有更高不确定性）：样本量 $n = 60$，随机种子 $20231104$，预测变量 $x_i \\sim \\mathcal{N}(0,1)$，乘性降雨模型 $$y_i = \\exp(1.0 + 0.5 x_i) \\cdot \\varepsilon_i,$$ 其中 $\\varepsilon_i \\sim \\text{Lognormal}(0, 0.6)$。\n\n您的程序必须生成单行输出，包含一个由方括号括起来的逗号分隔列表形式的结果，其中每个元素本身都是一个形式为 $[\\lambda, p\\_v, \\rho, b]$ 的列表，对应于 A、B、C、D 四个测试用例的顺序，其中 $p\\_v$ 是 Breusch–Pagan p 值，$\\rho$ 是方差比，而 $b$ 是如上定义的布尔值。例如，输出格式必须与以下模板完全一样（使用实际数字）：$$[[\\lambda\\_A, p\\_{v,A}, \\rho\\_A, b\\_A],[\\lambda\\_B, p\\_{v,B}, \\rho\\_B, b\\_B],[\\lambda\\_C, p\\_{v,C}, \\rho\\_C, b\\_C],[\\lambda\\_D, p\\_{v,D}, \\rho\\_D, b\\_D]].$$ 输出中不需要单位，因为所有报告的量都是无量纲的。",
            "solution": "该解决方案实现了一个系统性程序，用于在简单线性回归模型中识别最优的 Box-Cox 变换参数 $\\lambda$，以稳定残差方差。该问题被置于模拟日降雨量的背景下，日降雨量是严格为正且通常表现出右偏性，这使得方差稳定成为进行有效统计推断的关键任务。\n\n该方法的核心是基于 Box-Cox 变换，它对正响应变量 $y$ 和参数 $\\lambda \\in \\mathbb{R}$ 定义为：\n$$T_{\\lambda}(y) = \\begin{cases} \\dfrac{y^{\\lambda} - 1}{\\lambda},  \\text{if } \\lambda \\neq 0, \\\\ \\log(y),  \\text{if } \\lambda = 0. \\end{cases}$$\n$\\lambda = 0$ 的情况是当 $\\lambda \\to 0$ 时 $\\lambda \\neq 0$ 表达式的极限。我们寻求使模型残差近似同方差的 $\\lambda$ 值。\n\n对每个测试用例，该程序按如下方式执行：\n\n首先，根据指定的生成模型（例如，乘性或加性误差结构），使用固定的样本量 $n$ 和随机种子，为预测变量 $x$ 和响应变量 $y$ 生成合成数据。所有生成的响应值 $y_i$ 都被验证为正值，这是 Box-Cox 变换的先决条件。\n\n其次，在一个从 $-1.5$ 到 $1.5$（步长为 $0.05$）的预定义候选 $\\lambda$ 值网格上进行搜索。对于此网格中的每个 $\\lambda$，执行以下步骤：\n1.  将响应变量 $y$ 变换为 $T_{\\lambda}(y)$。\n2.  拟合普通最小二乘（OLS）线性模型：\n    $$T_{\\lambda}(y_i) = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$$\n    模型系数 $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1]^T$ 通过求解正规方程 $\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{X}^T\\mathbf{y}_{\\text{trans}}$ 来估计，其中 $\\mathbf{X}$ 是一个 $n \\times 2$ 的设计矩阵，包含一列 1 和预测变量向量，而 $\\mathbf{y}_{\\text{trans}}$ 是变换后响应的向量。\n3.  计算拟合值 $\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$ 和残差 $e_i = T_{\\lambda}(y_i) - \\hat{y}_i$。\n4.  基于这些残差计算两个异方差性诊断指标：\n    -   Breusch-Pagan (BP) 检验：此检验评估同方差性的原假设（$\\text{Var}(\\varepsilon_i) = \\sigma^2$）与异方差性的备择假设（方差与拟合值相关）。对残差平方 $e_i^2$ 与截距项和拟合值 $\\hat{y}_i$ 进行辅助回归。来自此辅助回归的决定系数 $R^2$ 用于计算拉格朗日乘子（$LM$）统计量，$LM = n R^2$。在原假设下，$LM$ 渐近服从自由度为 $k=1$ 的卡方分布（因为除了截距外只有一个回归量 $\\hat{y}_i$）。高 p 值（$p \\ge 0.05$）表明同方差性假设未被违反。\n    -   基于分箱的方差比 $\\rho$：这提供了一个直接、直观的方差差异度量。数据按其拟合值 $\\hat{y}_i$ 排序。对最低十分位数（最低 $10\\%$）的拟合值和最高十分位数（最高 $10\\%$）的拟合值，计算其残差平方的均值。然后比率 $\\rho$ 计算如下：\n        $$\\rho = \\dfrac{\\overline{e^2 \\text{ in top decile}}}{\\overline{e^2 \\text{ in bottom decile}}}$$\n        $\\rho$ 值接近 1 表示残差方差在拟合值范围内是平衡的，这在视觉上对应于“残差-拟合值图”中的平坦趋势。\n\n第三，根据旨在找到最具统计合理性和稳健性变换的层次化准则，从网格中选择最优的 $\\lambda$ 值：\n1.  主要目标是最大化 BP 检验的 p 值。这优先考虑那些正式统计检验为其同方差性提供最强证据的变换。\n2.  作为第一个决胜规则，如果多个 $\\lambda$ 值产生相同的最大 p 值（在数值精度范围内），则选择使方差比与 1 的绝对偏差 $|\\rho - 1|$ 最小化的那个。此步骤选择能最好地平衡模型预测极值处方差的变换。\n3.  作为第二个也是最后的决胜规则，如果仍然存在平局，则选择绝对值 $|\\lambda|$ 最小的 $\\lambda$。这偏好更简单或更易于解释的变换（即，更接近对数变换 $\\lambda=0$ 或无变换 $\\lambda=1$ 的变换）。\n\n最后，对于为每个测试用例确定的最优 $\\lambda$，构建一个列表，包含最优 $\\lambda$、其对应的 BP 检验 p 值、方差比 $\\rho$ 和一个布尔标志。如果所选变换满足近似同方差性的标准准则：BP 检验 p 值至少为 $0.05$ 且方差比 $\\rho$ 在区间 $[0.8, 1.25]$ 内，则此标志设置为 `True`。否则为 `False`。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef generate_data(n, seed, model_type):\n    \"\"\"\n    Generates synthetic data for a given test case.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    x = rng.normal(loc=0, scale=1, size=n)\n    \n    if model_type == 'A':\n        # y_i = exp(2 + 0.7 x_i) * epsilon_i, epsilon_i ~ Lognormal(0, 0.5)\n        epsilon = rng.lognormal(mean=0, sigma=0.5, size=n)\n        y = np.exp(2 + 0.7 * x) * epsilon\n    elif model_type == 'B':\n        # y_i = 15 + 2.0 x_i + e_i, e_i ~ N(0, 1)\n        e = rng.normal(loc=0, scale=1, size=n)\n        y = 15 + 2.0 * x + e\n    elif model_type == 'C':\n        # y_i = exp(1.5 + 0.8 x_i) * epsilon_i, epsilon_i ~ Lognormal(0, 1.0)\n        epsilon = rng.lognormal(mean=0, sigma=1.0, size=n)\n        y = np.exp(1.5 + 0.8 * x) * epsilon\n    elif model_type == 'D':\n        # y_i = exp(1.0 + 0.5 x_i) * epsilon_i, epsilon_i ~ Lognormal(0, 0.6)\n        epsilon = rng.lognormal(mean=0, sigma=0.6, size=n)\n        y = np.exp(1.0 + 0.5 * x) * epsilon\n    \n    return x, y\n\ndef solve_for_case(n, seed, model_type):\n    \"\"\"\n    Performs the full analysis for a single test case.\n    \"\"\"\n    x, y = generate_data(n, seed, model_type)\n\n    if not np.all(y > 0):\n        # This case is extremely unlikely given the problem parameters but is a safeguard.\n        raise ValueError(f\"Generated data for case {model_type} contains non-positive y values.\")\n    \n    lambda_grid = np.round(np.arange(-1.5, 1.5 + 0.05, 0.05), 2)\n    \n    case_diagnostics = []\n\n    for lam in lambda_grid:\n        # 1. Transform response variable\n        if lam == 0:\n            y_trans = np.log(y)\n        else:\n            y_trans = (y**lam - 1) / lam\n\n        # 2. Fit OLS model\n        X = np.vstack([np.ones(n), x]).T\n        try:\n            beta = np.linalg.solve(X.T @ X, X.T @ y_trans)\n        except np.linalg.LinAlgError:\n            continue  # Skip lambda if OLS fails\n            \n        y_fitted = X @ beta\n        residuals = y_trans - y_fitted\n        e_sq = residuals**2\n\n        # 3. Breusch-Pagan Test\n        Z = np.vstack([np.ones(n), y_fitted]).T\n        \n        try:\n            TSS_aux = np.sum((e_sq - np.mean(e_sq))**2)\n            if TSS_aux  1e-14:\n                R2_aux = 0.0\n            else:\n                gamma_aux = np.linalg.solve(Z.T @ Z, Z.T @ e_sq)\n                e_sq_pred = Z @ gamma_aux\n                RSS_aux = np.sum((e_sq - e_sq_pred)**2)\n                R2_aux = 1 - RSS_aux / TSS_aux\n        except np.linalg.LinAlgError:\n            # This can happen if y_fitted is constant, making Z singular.\n            R2_aux = 0.0\n\n        lm_stat = n * max(0, R2_aux) # R-squared can be slightly negative due to numerics\n        bp_p_value = chi2.sf(lm_stat, df=1)\n\n        # 4. Variance Ratio\n        n_decile = n // 10\n        if n_decile == 0:\n            rho = np.nan\n        else:\n            sorted_indices = np.argsort(y_fitted)\n            bottom_indices = sorted_indices[:n_decile]\n            top_indices = sorted_indices[-n_decile:]\n            \n            mean_sq_err_bottom = np.mean(e_sq[bottom_indices])\n            mean_sq_err_top = np.mean(e_sq[top_indices])\n\n            if mean_sq_err_bottom  1e-14:\n                rho = np.inf if mean_sq_err_top > 0 else 1.0\n            else:\n                rho = mean_sq_err_top / mean_sq_err_bottom\n        \n        case_diagnostics.append((lam, bp_p_value, rho))\n\n    # 5. Select optimal lambda using hierarchical criteria\n    sorted_diagnostics = sorted(case_diagnostics, key=lambda r: (-r[1], abs(r[2] - 1), abs(r[0])))\n    \n    opt_lambda, opt_p_val, opt_rho = sorted_diagnostics[0]\n    \n    # 6. Final check for homoscedasticity thresholds\n    is_homoscedastic = (opt_p_val >= 0.05) and (0.8 = opt_rho = 1.25)\n    \n    return [opt_lambda, opt_p_val, opt_rho, is_homoscedastic]\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        {'n': 400, 'seed': 20231101, 'model_type': 'A'},\n        {'n': 400, 'seed': 20231102, 'model_type': 'B'},\n        {'n': 400, 'seed': 20231103, 'model_type': 'C'},\n        {'n': 60,  'seed': 20231104, 'model_type': 'D'}\n    ]\n    \n    all_results = []\n    for case in test_cases:\n        result = solve_for_case(case['n'], case['seed'], case['model_type'])\n        all_results.append(result)\n        \n    # Format the final output as a comma-separated list of lists\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}