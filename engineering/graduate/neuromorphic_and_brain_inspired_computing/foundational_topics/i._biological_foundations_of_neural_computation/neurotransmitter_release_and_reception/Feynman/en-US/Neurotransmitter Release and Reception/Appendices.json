{
    "hands_on_practices": [
        {
            "introduction": "Neurotransmitter release is not a deterministic process but a probabilistic one, occurring in discrete packets called quanta. The binomial model provides a powerful yet simple framework for describing this stochasticity, forming a cornerstone of synaptic physiology. This exercise  challenges you to apply this model to a hypothetical neuromorphic synapse, calculating release probabilities and expected outcomes to build an intuition for the variability inherent in synaptic communication.",
            "id": "4053670",
            "problem": "A neuromorphic synapse circuit is designed to emulate probabilistic neurotransmitter release using an array of identical release sites. On each presynaptic spike, each site releases independently with probability $p$, and each successful release contributes a fixed quantal postsynaptic current amplitude $q$ that sums linearly across sites without saturation or interaction. Let the number of sites be $N$, and let the random variable $K$ denote the number of releases triggered by a single spike. Assume that releases at different sites are independent and identically distributed Bernoulli trials and that the postsynaptic current amplitude is $I = q K$. Using only these assumptions and the definitions of independence, combinatorial counting, and expectation, determine, for $N = 5$, $p = 0.3$, and $q = 10\\ \\mathrm{pA}$:\n1. The probability of observing exactly two quanta, i.e., $\\mathbb{P}(K = 2)$.\n2. The expected postsynaptic current amplitude $\\mathbb{E}[I]$.\nExpress the expected amplitude in picoamperes ($\\mathrm{pA}$). Round both numerical results to four significant figures. Provide the final answer as two entries in the order listed.",
            "solution": "The user wants me to solve the problem. I will now proceed with solving the problem. The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extract Givens**\n- Number of identical release sites: $N = 5$.\n- Probability of release for a single site per spike (independent): $p = 0.3$.\n- Quantal postsynaptic current amplitude per release: $q = 10\\ \\mathrm{pA}$.\n- The number of releases, $K$, is a random variable representing the count of successful releases from the $N$ sites.\n- Releases are independent and identically distributed Bernoulli trials.\n- The total postsynaptic current is $I = qK$.\n- The relationships are linear, with no saturation or interaction.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem describes the binomial model of synaptic transmission, a fundamental and well-established concept in neuroscience and biophysics. The parameters are physically plausible. It is scientifically sound.\n- **Well-Posed:** All necessary parameters ($N$, $p$, $q$) are provided. The questions are unambiguous and quantitative. A unique solution exists.\n- **Objective:** The problem is stated using precise, formal language from probability theory and neuroscience. It is free from subjective claims.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n**Solution Derivation**\n\nThe problem states that there are $N$ independent release sites, and each site has a probability $p$ of releasing a neurotransmitter in response to a presynaptic spike. The random variable $K$ represents the total number of sites that release. This scenario is a classic sequence of $N$ independent Bernoulli trials, where the \"success\" of a trial is a release event. Therefore, the random variable $K$ follows a binomial distribution, denoted as $K \\sim B(N, p)$.\n\nThe probability mass function (PMF) of a binomial distribution gives the probability of observing exactly $k$ successes in $N$ trials, and is defined as:\n$$\n\\mathbb{P}(K=k) = \\binom{N}{k} p^k (1-p)^{N-k}\n$$\nwhere $\\binom{N}{k} = \\frac{N!}{k!(N-k)!}$ is the binomial coefficient, representing the number of ways to choose $k$ successful sites from a total of $N$ sites.\n\n**Part 1: Probability of observing exactly two quanta**\n\nWe are asked to find the probability of observing exactly two quanta, which corresponds to $K=2$. We are given $N=5$ and $p=0.3$. We substitute these values into the PMF with $k=2$:\n$$\n\\mathbb{P}(K=2) = \\binom{5}{2} (0.3)^2 (1-0.3)^{5-2}\n$$\nFirst, we calculate the binomial coefficient:\n$$\n\\binom{5}{2} = \\frac{5!}{2!(5-2)!} = \\frac{5!}{2!3!} = \\frac{5 \\times 4 \\times 3 \\times 2 \\times 1}{(2 \\times 1)(3 \\times 2 \\times 1)} = \\frac{120}{12} = 10\n$$\nNext, we calculate the probability terms:\n$$\np^2 = (0.3)^2 = 0.09\n$$\n$$\n(1-p)^{N-k} = (1-0.3)^{5-2} = (0.7)^3 = 0.343\n$$\nNow, we multiply these components together to find the probability:\n$$\n\\mathbb{P}(K=2) = 10 \\times 0.09 \\times 0.343 = 0.3087\n$$\nThe problem requires rounding to four significant figures. The value $0.3087$ is already in this form.\n\n**Part 2: Expected postsynaptic current amplitude**\n\nWe are asked to find the expected postsynaptic current amplitude, $\\mathbb{E}[I]$. The current $I$ is defined as $I = qK$, where $q$ is a constant and $K$ is a random variable.\nUsing the property of linearity of expectation, we have:\n$$\n\\mathbb{E}[I] = \\mathbb{E}[qK]\n$$\nSince $q$ is a constant, it can be factored out of the expectation:\n$$\n\\mathbb{E}[I] = q \\mathbb{E}[K]\n$$\nTo find $\\mathbb{E}[I]$, we first need to determine the expected value of $K$, $\\mathbb{E}[K]$. For a binomially distributed random variable $K \\sim B(N, p)$, the expected value is given by the product of the number of trials and the probability of success:\n$$\n\\mathbb{E}[K] = Np\n$$\nThis can be shown from first principles by defining $K$ as the sum of $N$ independent Bernoulli random variables $X_i$, where $X_i=1$ with probability $p$ and $X_i=0$ with probability $1-p$.\n$$\nK = \\sum_{i=1}^{N} X_i\n$$\nThe expectation of each $X_i$ is $\\mathbb{E}[X_i] = 1 \\cdot p + 0 \\cdot (1-p) = p$. By linearity of expectation:\n$$\n\\mathbb{E}[K] = \\mathbb{E}\\left[\\sum_{i=1}^{N} X_i\\right] = \\sum_{i=1}^{N} \\mathbb{E}[X_i] = \\sum_{i=1}^{N} p = Np\n$$\nSubstituting the given values $N=5$ and $p=0.3$:\n$$\n\\mathbb{E}[K] = 5 \\times 0.3 = 1.5\n$$\nThis represents the average number of quanta released per spike. Now, we can calculate the expected current $\\mathbb{E}[I]$ using the given quantal amplitude $q = 10\\ \\mathrm{pA}$:\n$$\n\\mathbb{E}[I] = q \\mathbb{E}[K] = (10\\ \\mathrm{pA}) \\times 1.5 = 15\\ \\mathrm{pA}\n$$\nThe problem asks for this result to be expressed in picoamperes and rounded to four significant figures. The value is $15$, which is written as $15.00$ to indicate four significant figures.\n\nThe final answers are:\n1. $\\mathbb{P}(K=2) = 0.3087$\n2. $\\mathbb{E}[I] = 15.00\\ \\mathrm{pA}$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.3087 & 15.00\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The release probability $p$ from our previous model is not a fixed constant; it is dynamically and sensitively controlled by the concentration of presynaptic calcium, $[Ca^{2+}]$. This exercise  delves into this relationship using the Hill-Langmuir isotherm, a classic biophysical model for the cooperative binding of molecules to a receptor. Mastering this concept is key to understanding how synapses perform non-linear computations, acting as highly sensitive switches rather than simple linear relays.",
            "id": "4053681",
            "problem": "In a brain-inspired neuromorphic synapse, neurotransmitter release is modeled by cooperative binding of presynaptic cytosolic calcium ions to an effective sensor that triggers vesicle fusion. Assume fast binding and unbinding relative to fusion and a quasi-steady state in which the occupancy of the triggering state follows mass-action binding. For a single binding site, mass-action equilibrium implies a bound fraction $\\theta(c)=\\frac{c}{K_d+c}$, where $c$ denotes the free calcium concentration and $K_d$ is the dissociation constant. If the triggering state requires simultaneous occupancy of $n$ identical sites (an effective cooperativity), the fraction of sensors in the triggering state is modeled as the Hill-Langmuir isotherm\n$$\nf(c)=\\frac{c^{n}}{K_d^{n}+c^{n}}.\n$$\nLet the macroscopic neurotransmitter release rate be $R(c)=R_{\\max}\\,f(c)$, where $R_{\\max}$ is the saturation release rate. A neuromorphic synapse is configured with $n=4$ and $K_d=10\\ \\mu\\mathrm{M}$. Consider a step change in presynaptic calcium concentration from $c_1=5\\ \\mu\\mathrm{M}$ to $c_2=10\\ \\mu\\mathrm{M}$. Compute the relative change in release rate defined as\n$$\n\\Delta_{\\mathrm{rel}}=\\frac{R(c_2)-R(c_1)}{R(c_1)}.\n$$\nExpress your final answer as a dimensionless decimal number (no percentage sign). Provide the exact value.",
            "solution": "The problem is validated against the specified criteria before proceeding to a solution.\n\n### Step 1: Extract Givens\nThe givens are:\n- The fraction of sensors in the triggering state, $f(c)$, follows the Hill-Langmuir isotherm: $f(c)=\\frac{c^{n}}{K_d^{n}+c^{n}}$.\n- The macroscopic neurotransmitter release rate is $R(c)=R_{\\max}\\,f(c)$.\n- Cooperativity coefficient: $n=4$.\n- Dissociation constant: $K_d=10\\ \\mu\\mathrm{M}$.\n- Initial calcium concentration: $c_1=5\\ \\mu\\mathrm{M}$.\n- Final calcium concentration: $c_2=10\\ \\mu\\mathrm{M}$.\n- Definition of relative change in release rate: $\\Delta_{\\mathrm{rel}}=\\frac{R(c_2)-R(c_1)}{R(c_1)}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity:\n- **Scientifically Grounded**: The problem is well-grounded in biophysical and neuroscientific principles. The Hill-Langmuir equation is a standard model for cooperative binding, widely used in pharmacology and modeling of synaptic transmission. The relationship between binding fraction and a macroscopic rate is a common and valid assumption in such models. The parameters ($n=4$, $K_d=10\\ \\mu\\mathrm{M}$) are within the physiologically plausible range for calcium-dependent neurotransmitter release.\n- **Well-Posed**: The problem is well-posed. All required variables and constants ($n$, $K_d$, $c_1$, $c_2$) are provided. The quantity to be calculated, $\\Delta_{\\mathrm{rel}}$, is defined by a clear and unambiguous mathematical expression. A unique and meaningful solution can be determined.\n- **Objective**: The problem is stated in precise, objective language. It is free from subjective claims or ambiguities.\n\nThe problem does not exhibit any of the flaws listed for invalidation. It is scientifically sound, formally specified, complete, and well-structured.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be derived.\n\nThe relative change in release rate, $\\Delta_{\\mathrm{rel}}$, is defined as:\n$$\n\\Delta_{\\mathrm{rel}} = \\frac{R(c_2) - R(c_1)}{R(c_1)}\n$$\nThe release rate $R(c)$ is given by $R(c) = R_{\\max} f(c)$. Substituting this into the expression for $\\Delta_{\\mathrm{rel}}$:\n$$\n\\Delta_{\\mathrm{rel}} = \\frac{R_{\\max}f(c_2) - R_{\\max}f(c_1)}{R_{\\max}f(c_1)}\n$$\nThe constant $R_{\\max}$ cancels from the numerator and denominator, assuming $R_{\\max} \\neq 0$ and $f(c_1) \\neq 0$.\n$$\n\\Delta_{\\mathrm{rel}} = \\frac{f(c_2) - f(c_1)}{f(c_1)} = \\frac{f(c_2)}{f(c_1)} - 1\n$$\nThe function $f(c)$ is the Hill-Langmuir isotherm:\n$$\nf(c) = \\frac{c^{n}}{K_d^{n} + c^{n}}\n$$\nWe can rewrite this expression by dividing the numerator and denominator by $K_d^{n}$:\n$$\nf(c) = \\frac{(c/K_d)^{n}}{1 + (c/K_d)^{n}}\n$$\nThe problem provides the following values: $n=4$, $K_d=10\\ \\mu\\mathrm{M}$, $c_1=5\\ \\mu\\mathrm{M}$, and $c_2=10\\ \\mu\\mathrm{M}$.\n\nFirst, we calculate $f(c_1)$ for $c_1=5\\ \\mu\\mathrm{M}$:\nThe ratio of concentrations is $\\frac{c_1}{K_d} = \\frac{5\\ \\mu\\mathrm{M}}{10\\ \\mu\\mathrm{M}} = \\frac{1}{2}$.\nUsing $n=4$:\n$$\nf(c_1) = \\frac{(\\frac{1}{2})^{4}}{1 + (\\frac{1}{2})^{4}} = \\frac{\\frac{1}{16}}{1 + \\frac{1}{16}} = \\frac{\\frac{1}{16}}{\\frac{17}{16}} = \\frac{1}{17}\n$$\nNext, we calculate $f(c_2)$ for $c_2=10\\ \\mu\\mathrm{M}$:\nThe ratio of concentrations is $\\frac{c_2}{K_d} = \\frac{10\\ \\mu\\mathrm{M}}{10\\ \\mu\\mathrm{M}} = 1$.\nUsing $n=4$:\n$$\nf(c_2) = \\frac{(1)^{4}}{1 + (1)^{4}} = \\frac{1}{1 + 1} = \\frac{1}{2}\n$$\nNow, we substitute these values back into the expression for $\\Delta_{\\mathrm{rel}}$:\n$$\n\\Delta_{\\mathrm{rel}} = \\frac{f(c_2)}{f(c_1)} - 1 = \\frac{\\frac{1}{2}}{\\frac{1}{17}} - 1\n$$\nSimplifying the expression:\n$$\n\\Delta_{\\mathrm{rel}} = \\frac{17}{2} - 1 = 8.5 - 1 = 7.5\n$$\nThe relative change in release rate is $7.5$. This is a dimensionless value, as required.",
            "answer": "$$\n\\boxed{7.5}\n$$"
        },
        {
            "introduction": "While theoretical models provide deep insights, building effective brain-inspired systems requires grounding them in empirical data. This advanced practice  moves from theory to application, tasking you with a core problem in computational neuroscience: estimating model parameters from experimental observations. You will use the powerful method of Maximum Likelihood Estimation (MLE) to determine the transition rate of a stochastic release model, a scenario that realistically includes the challenge of right-censored data where an event is not observed. This exercise provides hands-on experience with the statistical techniques necessary to bridge the gap between biological experiments and neuromorphic design.",
            "id": "4053605",
            "problem": "You are modeling stochastic neurotransmitter release in a neuromorphic synapse using a Hidden Markov Model (HMM). The HMM has two states representing the vesicle docking status: $S=\\{\\text{primed},\\ \\text{fused}\\}$. The state $\\text{primed}$ is the release-ready state, and the state $\\text{fused}$ is the absorbing state that coincides with a release event. Under the assumption of a memoryless transition from $\\text{primed}$ to $\\text{fused}$, the waiting time from stimulus onset to fusion is the first-passage time in a continuous-time Markov chain with a constant hazard rate. You are given sets of release event times across trials. Some trials have no detected fusion within an observation window, which is to be treated as right-censoring. Your task is to estimate the continuous-time transition rate from $\\text{primed}$ to $\\text{fused}$ that best fits the observed event times under the memoryless assumption and then map that rate to a discrete-time HMM parameter appropriate for implementation with a fixed simulation time step.\n\nFundamental base to use:\n- The definition of a memoryless process implies an exponential waiting-time distribution governed by a constant hazard rate.\n- Right-censoring contributes survival terms to the likelihood.\n- Discrete-time sampling of a continuous-time Markov process with step size $dt$ yields a per-step transition probability related to the continuous rate.\n\nDefinitions and requirements:\n- Let $t_i$ denote the observed fusion time in milliseconds for trial $i$ when a release event is detected. If no event is observed within the observation window $T_{\\mathrm{obs}}$, then trial $i$ is right-censored at $T_{\\mathrm{obs}}$.\n- Let $\\lambda$ denote the continuous-time transition rate from $\\text{primed}$ to $\\text{fused}$ in units of $\\mathrm{ms}^{-1}$.\n- Let $p$ denote the per-step transition probability in a discrete-time HMM that uses a fixed time step $dt$ in milliseconds.\n- Define the continuous-time jitter as the standard deviation of the release times under the exponential waiting-time assumption, expressed in $\\mathrm{ms}$.\n- Define the discrete-time jitter as the standard deviation of the release times measured in discrete steps and then scaled by $dt$ to $\\mathrm{ms}$.\n\nDerive, from first principles and without using shortcut formulas, the likelihood for the observed data with right-censoring under the memoryless assumption. From this, obtain the maximum likelihood estimate of $\\lambda$ and then map $\\lambda$ to $p$ for a given $dt$. For each test case below, compute:\n- The estimated $\\lambda$ in $\\mathrm{ms}^{-1}$.\n- The corresponding $p$ for the provided $dt$.\n- The predicted continuous-time jitter in $\\mathrm{ms}$.\n- The predicted discrete-time jitter in $\\mathrm{ms}$.\n- A boolean indicating whether the predicted continuous-time jitter lies within the target range of $[0.2, 0.5]$ milliseconds inclusive.\n\nInput data (to be embedded in your program):\nEach test case is a tuple $(\\text{event\\_times}, T_{\\mathrm{obs}}, dt)$, where $\\text{event\\_times}$ is a list of fusion times in milliseconds with $\\text{None}$ indicating a right-censored trial at $T_{\\mathrm{obs}}$. Use the following test suite:\n- Case A: $\\text{event\\_times}=(0.12, 0.29, 0.31, 0.27, 0.42, 0.33, 0.24, 0.36)$, $T_{\\mathrm{obs}}=1.0\\ \\mathrm{ms}$, $dt=0.01\\ \\mathrm{ms}$.\n- Case B: $\\text{event\\_times}=(0.42, 0.58, 0.59, 0.50, 0.41)$, $T_{\\mathrm{obs}}=1.0\\ \\mathrm{ms}$, $dt=0.01\\ \\mathrm{ms}$.\n- Case C: $\\text{event\\_times}=(0.18, \\text{None}, 0.23, \\text{None}, \\text{None}, 0.19)$, $T_{\\mathrm{obs}}=0.3\\ \\mathrm{ms}$, $dt=0.05\\ \\mathrm{ms}$.\n- Case D: $\\text{event\\_times}=(0.18, 0.16, 0.22, 0.20, 0.19, 0.21, 0.17, 0.23, 0.18, 0.19)$, $T_{\\mathrm{obs}}=1.0\\ \\mathrm{ms}$, $dt=0.005\\ \\mathrm{ms}$.\n- Case E: $\\text{event\\_times}=(0.21)$, $T_{\\mathrm{obs}}=1.0\\ \\mathrm{ms}$, $dt=0.01\\ \\mathrm{ms}$.\n\nAngle units do not apply. Express $\\lambda$ in $\\mathrm{ms}^{-1}$ and all jitter values in $\\mathrm{ms}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is a list of the form $[[\\lambda_1,p_1,J_{\\mathrm{cont},1},J_{\\mathrm{disc},1},\\text{ok}_1],[\\lambda_2,p_2,J_{\\mathrm{cont},2},J_{\\mathrm{disc},2},\\text{ok}_2],\\dots]$.",
            "solution": "The problem statement has been analyzed and found to be valid. It is scientifically grounded, well-posed, objective, and self-contained, with no apparent contradictions or ambiguities. The underlying principles of continuous-time Markov chains, exponential waiting-time distributions, maximum likelihood estimation with censored data, and the discretization of continuous processes are standard and correctly applied. We may therefore proceed with a formal solution.\n\nThe task is to estimate a continuous-time transition rate $\\lambda$ from a set of event times, which includes right-censored data, and then to derive related parameters for a discrete-time model.\n\n### 1. The Likelihood Function for Censored Data\n\nThe problem states that the transition from the 'primed' to the 'fused' state is a memoryless process. A memoryless continuous-time process implies that the waiting time $T$ for the event (fusion) follows an exponential distribution. The probability density function (PDF) of this distribution is given by:\n$$ f(t; \\lambda) = \\lambda e^{-\\lambda t} \\quad \\text{for } t \\ge 0 $$\nwhere $\\lambda$ is the constant hazard rate, in this context, the transition rate from 'primed' to 'fused' in units of $\\mathrm{ms}^{-1}$.\n\nThe corresponding cumulative distribution function (CDF), which gives the probability of the event occurring by time $t$, is:\n$$ F(t; \\lambda) = \\int_0^t \\lambda e^{-\\lambda \\tau} d\\tau = \\left[ -e^{-\\lambda \\tau} \\right]_0^t = 1 - e^{-\\lambda t} $$\nThe survival function $S(t; \\lambda)$, which gives the probability that the event has *not* occurred by time $t$, is:\n$$ S(t; \\lambda) = 1 - F(t; \\lambda) = e^{-\\lambda t} $$\nThe given data consists of a set of trials. For each trial, we have either a detected fusion time $t_i$ or a right-censoring at the observation window time $T_{\\mathrm{obs}}$. Let the set of observed fusion times be $D = \\{t_1, t_2, \\dots, t_{N_D}\\}$ and the number of right-censored trials be $N_C$.\n\n- For a trial where the fusion is observed at time $t_i$, its contribution to the total likelihood of the parameter $\\lambda$ is the value of the PDF at $t_i$, i.e., $f(t_i; \\lambda)$.\n- For a trial that is right-censored at $T_{\\mathrm{obs}}$, we only know that the fusion time was greater than $T_{\\mathrm{obs}}$. The probability of this is given by the survival function evaluated at $T_{\\mathrm{obs}}$, i.e., $S(T_{\\mathrm{obs}}; \\lambda)$.\n\nAssuming independence between trials, the total likelihood function $L(\\lambda)$ is the product of these individual probabilities:\n$$ L(\\lambda) = \\left( \\prod_{i=1}^{N_D} f(t_i; \\lambda) \\right) \\cdot \\left( S(T_{\\mathrm{obs}}; \\lambda) \\right)^{N_C} $$\nSubstituting the expressions for the PDF and survival function:\n$$ L(\\lambda) = \\left( \\prod_{i=1}^{N_D} \\lambda e^{-\\lambda t_i} \\right) \\cdot \\left( e^{-\\lambda T_{\\mathrm{obs}}} \\right)^{N_C} $$\n$$ L(\\lambda) = \\lambda^{N_D} \\left( \\prod_{i=1}^{N_D} e^{-\\lambda t_i} \\right) \\cdot e^{-\\lambda N_C T_{\\mathrm{obs}}} $$\n$$ L(\\lambda) = \\lambda^{N_D} \\exp\\left(-\\lambda \\sum_{i=1}^{N_D} t_i\\right) \\exp\\left(-\\lambda N_C T_{\\mathrm{obs}}\\right) $$\n$$ L(\\lambda) = \\lambda^{N_D} \\exp\\left(-\\lambda \\left( \\sum_{i=1}^{N_D} t_i + N_C T_{\\mathrm{obs}} \\right)\\right) $$\n\n### 2. Maximum Likelihood Estimation of $\\lambda$\n\nTo find the value of $\\lambda$ that maximizes the likelihood function, it is mathematically more convenient to maximize the log-likelihood, $\\mathcal{L}(\\lambda) = \\ln L(\\lambda)$.\n$$ \\mathcal{L}(\\lambda) = \\ln\\left( \\lambda^{N_D} \\exp\\left(-\\lambda \\left( \\sum_{i=1}^{N_D} t_i + N_C T_{\\mathrm{obs}} \\right)\\right) \\right) $$\n$$ \\mathcal{L}(\\lambda) = N_D \\ln \\lambda - \\lambda \\left( \\sum_{i=1}^{N_D} t_i + N_C T_{\\mathrm{obs}} \\right) $$\nWe find the maximum by taking the derivative of $\\mathcal{L}(\\lambda)$ with respect to $\\lambda$ and setting it to zero:\n$$ \\frac{d\\mathcal{L}}{d\\lambda} = \\frac{N_D}{\\lambda} - \\left( \\sum_{i=1}^{N_D} t_i + N_C T_{\\mathrm{obs}} \\right) = 0 $$\nSolving for the maximum likelihood estimate $\\hat{\\lambda}$:\n$$ \\frac{N_D}{\\hat{\\lambda}} = \\sum_{i=1}^{N_D} t_i + N_C T_{\\mathrm{obs}} $$\n$$ \\hat{\\lambda} = \\frac{N_D}{\\sum_{i=1}^{N_D} t_i + N_C T_{\\mathrm{obs}}} $$\nThis estimator is intuitively interpreted as the number of observed events divided by the total time the system was observed to be in the 'primed' state.\n\n### 3. Mapping to Discrete-Time Probability $p$\n\nThe continuous-time process is to be approximated by a discrete-time HMM with a time step of $dt$. In the continuous model, the probability of remaining in the 'primed' state for a duration of at least $dt$ is given by the survival function $S(dt) = e^{-\\lambda dt}$. This corresponds to the probability of not transitioning to the 'fused' state in a single time step in the discrete model. Let $p$ be the per-step probability of transitioning from 'primed' to 'fused'. Then the probability of staying in 'primed' is $1-p$. Equating the two:\n$$ 1 - p = e^{-\\lambda dt} $$\nSolving for $p$ yields the mapping:\n$$ p = 1 - e^{-\\lambda dt} $$\nWe will use the estimated rate $\\hat{\\lambda}$ to calculate the estimated probability $\\hat{p}$.\n\n### 4. Continuous and Discrete Jitter Calculation\n\n**Continuous-Time Jitter ($J_{\\mathrm{cont}}$):**\nThe problem defines the continuous-time jitter as the standard deviation of the release times under the exponential waiting-time assumption. The waiting time $T$ is a random variable following the exponential distribution with rate $\\lambda$. The variance of such a distribution is $\\mathrm{Var}(T) = 1/\\lambda^2$. The standard deviation is the square root of the variance.\n$$ J_{\\mathrm{cont}} = \\sigma_T = \\sqrt{\\frac{1}{\\lambda^2}} = \\frac{1}{\\lambda} $$\n\n**Discrete-Time Jitter ($J_{\\mathrm{disc}}$):**\nIn the discrete-time model, the number of steps $K$ until a fusion event occurs follows a geometric distribution with success probability $p$. The probability mass function is $P(K=k) = (1-p)^{k-1}p$ for $k=1, 2, 3, \\dots$.\nThe variance of a geometric distribution is given by:\n$$ \\mathrm{Var}(K) = \\frac{1-p}{p^2} $$\nThe standard deviation of the number of steps is $\\sigma_K = \\sqrt{\\mathrm{Var}(K)} = \\frac{\\sqrt{1-p}}{p}$. The discrete-time jitter $J_{\\mathrm{disc}}$ is this standard deviation scaled by the time step $dt$ to convert it to units of time (ms).\n$$ J_{\\mathrm{disc}} = \\sigma_K \\cdot dt = \\frac{\\sqrt{1-p}}{p} dt $$\nUsing the relationship $1-p = e^{-\\lambda dt}$, this can also be written in terms of $\\lambda$:\n$$ J_{\\mathrm{disc}} = \\frac{\\sqrt{e^{-\\lambda dt}}}{1 - e^{-\\lambda dt}} dt = \\frac{e^{-\\lambda dt/2}}{1 - e^{-\\lambda dt}} dt $$\nAs $dt \\to 0$, $J_{\\mathrm{disc}}$ approaches $1/\\lambda$, which is $J_{\\mathrm{cont}}$.\n\n### 5. Final Computations\n\nFor each test case, the following quantities will be computed in order:\n1.  The estimated rate $\\hat{\\lambda}$ using the derived MLE formula.\n2.  The corresponding discrete probability $\\hat{p} = 1 - e^{-\\hat{\\lambda} dt}$.\n3.  The predicted continuous-time jitter $J_{\\mathrm{cont}} = 1/\\hat{\\lambda}$. If $\\hat{\\lambda}=0$, $J_{\\mathrm{cont}}$ is infinite.\n4.  The predicted discrete-time jitter $J_{\\mathrm{disc}} = \\frac{\\sqrt{1-\\hat{p}}}{\\hat{p}} dt$. If $\\hat{p}=0$, $J_{\\mathrm{disc}}$ is infinite.\n5.  A boolean flag indicating if $J_{\\mathrm{cont}}$ is within the range $[0.2, 0.5]$ inclusive.\n\nThese calculations are implemented in the provided Python code.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating parameters for a neuromorphic synapse model\n    based on stochastic neurotransmitter release, modeled as a continuous-time\n    Markov process with right-censored data.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        (\n            [0.12, 0.29, 0.31, 0.27, 0.42, 0.33, 0.24, 0.36],\n            1.0,  # T_obs in ms\n            0.01  # dt in ms\n        ),\n        # Case B\n        (\n            [0.42, 0.58, 0.59, 0.50, 0.41],\n            1.0,\n            0.01\n        ),\n        # Case C\n        (\n            [0.18, None, 0.23, None, None, 0.19],\n            0.3,\n            0.05\n        ),\n        # Case D\n        (\n            [0.18, 0.16, 0.22, 0.20, 0.19, 0.21, 0.17, 0.23, 0.18, 0.19],\n            1.0,\n            0.005\n        ),\n        # Case E\n        (\n            [0.21],\n            1.0,\n            0.01\n        ),\n    ]\n\n    results = []\n    for case in test_cases:\n        event_times, T_obs, dt = case\n\n        # Separate observed events from censored trials\n        observed_times = [t for t in event_times if t is not None]\n        \n        # Count number of observed (N_D) and censored (N_C) trials\n        N_D = len(observed_times)\n        N_C = len(event_times) - N_D\n\n        # Sum of observed event times\n        sum_t = sum(observed_times)\n        \n        # Calculate the denominator for the MLE of lambda\n        # This is the total observed time\n        total_time = sum_t + N_C * T_obs\n\n        # Step 1: Compute the Maximum Likelihood Estimate (MLE) of lambda\n        # lambda_hat = N_D / (sum of observed times + sum of censoring times)\n        if N_D == 0:\n            # If no events are observed, the MLE of lambda is 0.\n            # The likelihood function is monotonically decreasing.\n            lambda_est = 0.0\n        elif total_time == 0:\n            # This case (events at time 0, no censoring) leads to infinite rate.\n            # Not present in test data, but handled for robustness.\n            lambda_est = float('inf')\n        else:\n            lambda_est = N_D / total_time\n\n        # Step 2: Map lambda to the discrete-time probability p\n        # p = 1 - exp(-lambda * dt)\n        if np.isinf(lambda_est):\n            p_est = 1.0\n        else:\n            p_est = 1.0 - np.exp(-lambda_est * dt)\n\n        # Step 3: Compute the continuous-time jitter J_cont\n        # J_cont = 1 / lambda\n        if lambda_est == 0:\n            J_cont = float('inf')\n        else:\n            J_cont = 1.0 / lambda_est\n            \n        # Step 4: Compute the discrete-time jitter J_disc\n        # J_disc = std_dev(Geometric(p)) * dt = (sqrt(1-p)/p) * dt\n        if p_est == 0:\n            J_disc = float('inf')\n        elif p_est == 1:\n            J_disc = 0.0\n        else:\n            J_disc = (np.sqrt(1.0 - p_est) / p_est) * dt\n\n        # Step 5: Check if continuous-time jitter is within the target range\n        jitter_target_min = 0.2\n        jitter_target_max = 0.5\n        ok = (jitter_target_min <= J_cont <= jitter_target_max)\n\n        # Append the list of results for this case\n        results.append([lambda_est, p_est, J_cont, J_disc, ok])\n\n    # Final print statement in the exact required format.\n    # The str() conversion of the inner lists handles the formatting correctly.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}