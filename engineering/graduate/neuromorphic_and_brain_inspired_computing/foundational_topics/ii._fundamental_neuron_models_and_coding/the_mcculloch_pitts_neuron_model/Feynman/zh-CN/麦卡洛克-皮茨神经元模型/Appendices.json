{
    "hands_on_practices": [
        {
            "introduction": "单个MP神经元的功能受限于其只能解决线性可分问题。一个著名的反例便是异或（XOR）函数，它无法由单个MP神经元实现。本练习将指导你通过将多个神经元组合成一个多层网络来突破这一局限性，这是所有现代神经网络的一个基本思想。通过这个实践，你将学会如何设计网络，并分析其架构的规模（神经元总数）和深度（信号路径的最大层数）。",
            "id": "4065070",
            "problem": "考虑 McCulloch-Pitts 神经元模型，其中神经元通过应用线性阈值规则对布尔输入计算布尔值输出：对于输入 $x_{1},\\dots,x_{m} \\in \\{0,1\\}$，权重 $w_{1},\\dots,w_{m} \\in \\mathbb{R}$ 和阈值 $\\theta \\in \\mathbb{R}$，当且仅当 $\\sum_{i=1}^{m} w_{i} x_{i} \\ge \\theta$ 时，神经元输出 $1$，否则输出 $0$。允许使用负权重（表示抑制）。两位二进制数的异或（XOR）运算，记为 $\\mathrm{XOR}(x,y)$，其定义为：当 $x$ 或 $y$ 中恰好有一个为 $1$ 时，$\\mathrm{XOR}(x,y)=1$，否则为 $0$。$n$ 位奇偶校验函数定义为 $\\mathrm{PARITY}_{n}(x_{1},\\dots,x_{n})=\\mathrm{XOR}(x_{1},\\mathrm{XOR}(x_{2},\\dots,\\mathrm{XOR}(x_{n-1},x_{n})\\dots))$，等价于和 $\\sum_{i=1}^{n} x_{i}$ 模 $2$。\n\n设计一个 $\\mathrm{XOR}(x,y)$ 的实现，使用一个由隐藏层和输出层组成的双层 McCulloch-Pitts 子网络，其中隐藏层可以包含多个神经元，输出层包含一个神经元。然后，使用这些 $\\mathrm{XOR}$ 子网络构成的分层平衡二叉树来计算 $\\mathrm{PARITY}_{n}$，将网络深度定义为从任一输入位到最终输出神经元的任何路径上的最大神经元层数，将网络大小定义为所使用的 McCulloch-Pitts 神经元的总数（计算整个树中所有隐藏层和输出层神经元，不包括输入节点）。从第一性原理出发，推导该奇偶校验网络的深度和大小关于 $n$ 的闭式表达式。\n\n以单行排列的两个表达式形式提供你的最终答案，第一个条目等于深度，第二个条目等于大小。不需要数值近似或四舍五入。",
            "solution": "问题要求推导一个计算 $n$ 位奇偶校验函数 $\\mathrm{PARITY}_{n}$ 的网络的网络深度和大小的闭式表达式。该网络将由双层 McCulloch-Pitts (MP) 子网络构成的分层平衡二叉树构成，每个子网络实现双输入异或（$\\mathrm{XOR}$）函数。\n\n首先，我们必须使用 MP 神经元设计一个用于 $\\mathrm{XOR}(x_1, x_2)$ 的双层子网络。一个 MP 神经元，其输入为 $x_1, \\dots, x_m \\in \\{0, 1\\}$，权重为实数值 $w_1, \\dots, w_m$，阈值为实数值 $\\theta$，当其输入的加权和达到或超过阈值时，即 $\\sum_{i=1}^{m} w_i x_i \\ge \\theta$，输出 $y=1$，否则输出 $y=0$。\n\n$\\mathrm{XOR}$ 函数不是线性可分的，这意味着单个 MP 神经元无法实现它。因此，需要一个多层网络。问题指定了一个双层网络，由一个隐藏层和一个输出层组成。我们可以通过分解逻辑函数来构造一个 $\\mathrm{XOR}$ 门。一种这样的分解是 $\\mathrm{XOR}(x_1, x_2) = (x_1 \\lor x_2) \\land \\neg(x_1 \\land x_2)$。我们可以分配一个隐藏神经元来计算或（OR）子句，另一个来计算与非（NAND）子句（$\\neg(x_1 \\land x_2)$）。然后，输出神经元将计算这两个隐藏神经元输出的与（AND）运算。\n\n设输入为 $x_1, x_2 \\in \\{0, 1\\}$。设隐藏层由两个神经元 $H_1$ 和 $H_2$ 组成，输出层由一个神经元 $O$ 组成。\n\n**1. 隐藏神经元 $H_1$：计算 $x_1 \\lor x_2$。**\n函数 $x_1 \\lor x_2$ 在至少一个输入为 $1$ 时为 $1$，否则为 $0$。\n我们需要找到权重 $w_{11}, w_{12}$ 和阈值 $\\theta_1$，使得当且仅当 $x_1=1$ 或 $x_2=1$ 时，$w_{11}x_1 + w_{12}x_2 \\ge \\theta_1$。\n我们选择 $w_{11}=1$ 和 $w_{12}=1$。加权和为 $x_1+x_2$。\n- 如果 $(x_1, x_2)=(0,0)$，和为 $0$。\n- 如果 $(x_1, x_2)=(0,1)$ 或 $(1,0)$，和为 $1$。\n- 如果 $(x_1, x_2)=(1,1)$，和为 $2$。\n为了将 $(0,0)$ 的情况与其他情况分开，阈值 $\\theta_1$ 必须满足 $0  \\theta_1 \\le 1$。我们选择 $\\theta_1=1$。\n因此，$H_1$ 由权重 $w_{11}=1, w_{12}=1$ 和阈值 $\\theta_1=1$ 定义。\n\n**2. 隐藏神经元 $H_2$：计算 $\\mathrm{NAND}(x_1, x_2) = \\neg(x_1 \\land x_2)$。**\n函数 $\\mathrm{NAND}(x_1, x_2)$ 仅在两个输入都为 $1$ 时为 $0$，否则为 $1$。\n在这里使用抑制性（负）权重很方便。我们选择 $w_{21}=-1$ 和 $w_{22}=-1$。加权和为 $-x_1-x_2$。\n- 如果 $(x_1, x_2)=(0,0)$，和为 $0$。\n- 如果 $(x_1, x_2)=(0,1)$ 或 $(1,0)$，和为 $-1$。\n- 如果 $(x_1, x_2)=(1,1)$，和为 $-2$。\n我们希望神经元在除 $(1,1)$ 之外的所有情况下都激活。所以，条件 $w_{21}x_1 + w_{22}x_2 \\ge \\theta_2$ 必须对和为 $0$ 和 $-1$ 时为真，但对和为 $-2$ 时为假。这要求阈值 $\\theta_2$ 满足 $-2  \\theta_2 \\le -1$。我们选择 $\\theta_2=-1$。\n因此，$H_2$ 由权重 $w_{21}=-1, w_{22}=-1$ 和阈值 $\\theta_2=-1$ 定义。\n\n**3. 输出神经元 $O$：计算 $h_1 \\land h_2$。**\n输出神经元 $O$ 以隐藏神经元 $h_1$ 和 $h_2$ 的输出作为其输入。它必须计算 $h_1 \\land h_2$ 来实现最终的 $\\mathrm{XOR}$ 函数。\n我们来分析 $O$ 的输入：\n- 如果 $(x_1, x_2)=(0,0)$，则 $h_1=0$（OR 为假），$h_2=1$（NAND 为真）。最终输出应为 $0$。\n- 如果 $(x_1, x_2)=(0,1)$，则 $h_1=1$，$h_2=1$。最终输出应为 $1$。\n- 如果 $(x_1, x_2)=(1,0)$，则 $h_1=1$，$h_2=1$。最终输出应为 $1$。\n- 如果 $(x_1, x_2)=(1,1)$，则 $h_1=1$，$h_2=0$。最终输出应为 $0$。\n神经元 $O$ 必须仅在其输入 $(h_1, h_2)$ 为 $(1,1)$ 时输出 $1$。\n设 $O$ 的权重为 $w_{o1}=1, w_{o2}=1$。加权和为 $h_1+h_2$。\n- 如果 $(h_1, h_2)=(0,1)$ 或 $(1,0)$，和为 $1$。\n- 如果 $(h_1, h_2)=(1,1)$，和为 $2$。\n为了仅对 $(1,1)$ 激活，阈值 $\\theta_o$ 必须满足 $1  \\theta_o \\le 2$。我们选择 $\\theta_o=2$。\n因此，$O$ 由权重 $w_{o1}=1, w_{o2}=1$ 和阈值 $\\theta_o=2$ 定义。\n\n这样就完成了 $\\mathrm{XOR}$ 子网络的设计。\n- **$\\mathrm{XOR}$ 子网络的大小**：它包含 $2$ 个隐藏神经元和 $1$ 个输出神经元，总共 $3$ 个神经元。\n- **$\\mathrm{XOR}$ 子网络的深度**：信号路径从输入流经隐藏层（第一层神经元）到输出层（第二层神经元）。因此，深度为 $2$。\n\n接下来，我们分析整个 $\\mathrm{PARITY}_{n}$ 网络，它是由这些 $\\mathrm{XOR}$ 子网络构成的“分层平衡二叉树”。\n\n**网络大小的推导：**\n函数 $\\mathrm{PARITY}_{n}(x_1, \\dots, x_n)$ 等价于 $x_1 \\oplus x_2 \\oplus \\dots \\oplus x_n$，其中 $\\oplus$ 表示 $\\mathrm{XOR}$ 运算。计算一个包含 $n-1$ 个二元运算符的表达式，正好需要 $n-1$ 次该运算符的应用。平衡二叉树是安排这些运算的一种方式。例如，对于 $n=4$，我们计算 $\\mathrm{XOR}(\\mathrm{XOR}(x_1, x_2), \\mathrm{XOR}(x_3, x_4))$。这使用了 $3$（即 $4-1$）个 $\\mathrm{XOR}$ 运算。对于任何 $n$，这样的树形结构将需要 $n-1$ 个双输入 $\\mathrm{XOR}$ 函数。\n由于每个 $\\mathrm{XOR}$ 子网络由 $3$ 个神经元组成，$\\mathrm{PARITY}_{n}$ 网络中的神经元总数（其大小）为：\n$$ \\text{大小} = (\\text{XOR 子网络数量}) \\times (\\text{每个子网络的神经元数}) = (n-1) \\times 3 = 3(n-1) $$\n\n**网络深度的推导：**\n深度是从输入到最终输出的任何路径上的最大神经元层数。该网络是一个由 $\\mathrm{XOR}$ 模块组成的树。我们首先需要找出树中这些模块的层数。\n第一层 $\\mathrm{XOR}$ 模块接收 $n$ 个输入并产生 $\\lceil n/2 \\rceil$ 个输出。第二层将这 $\\lceil n/2 \\rceil$ 个信号作为输入，并产生 $\\lceil (\\lceil n/2 \\rceil)/2 \\rceil$ 个输出，以此类推。这个过程一直持续到只剩下一个输出。\n这个模块树中的层数，我们称之为 $L$，是从 $k=n$ 开始，重复应用函数 $f(k)=\\lceil k/2 \\rceil$ 直到结果为 $1$ 的次数。这等价于以 $2$ 为底的对数的上取整的定义。\n例如，如果 $n=8$，输入会按 $8 \\to 4 \\to 2 \\to 1$ 的方式减少（$3$ 层）。$\\lceil \\log_2 8 \\rceil = 3$。\n如果 $n=7$，输入会按 $7 \\to 4 \\to 2 \\to 1$ 的方式减少（$3$ 层）。$\\lceil \\log_2 7 \\rceil = 3$。\n所以，$\\mathrm{XOR}$ 子网络的层数是 $L = \\lceil \\log_2 n \\rceil$。\n从初始输入位到最终输出的最长路径将穿过这 $L$ 个层级中的每一层的一个 $\\mathrm{XOR}$ 子网络。由于每个 $\\mathrm{XOR}$ 子网络有 $2$ 个神经元层的深度，$\\mathrm{PARITY}_{n}$ 网络的总深度是：\n$$ \\text{深度} = (\\text{模块层数}) \\times (\\text{每个模块的深度}) = \\lceil \\log_2 n \\rceil \\times 2 = 2 \\lceil \\log_2 n \\rceil $$\n注意，对于边缘情况 $n=1$，$\\mathrm{PARITY}_1(x_1)=x_1$，这需要 $0$ 个神经元，深度为 $0$。我们的公式给出大小$=3(1-1)=0$ 和深度$=2\\lceil\\log_2 1\\rceil=0$，是一致的。\n\n推导出的闭式表达式为：深度是 $2 \\lceil \\log_2 n \\rceil$，大小是 $3(n-1)$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 \\lceil \\log_2 n \\rceil  3(n-1)\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在学会如何构建网络之后，下一步是理解它们在时间维度上的行为。本练习将探讨神经元更新的时间安排——是全部同时更新（同步）还是一次一个地更新（异步）——如何能够彻底改变一个循环网络的长期行为，导致不同的稳定状态或周期性模式。这个实践突显了更新机制在塑造网络动态中的关键作用。",
            "id": "4065112",
            "problem": "考虑McCulloch-Pitts神经元模型，其中每个神经元具有二元状态 $x_i(t) \\in \\{0,1\\}$，并根据加权和与随后的阈值非线性进行更新。神经元 $i$ 的状态更新由 $x_i(t+1) = H\\left(\\sum_{j} w_{ij} x_j(t) - \\theta_i\\right)$ 给出，其中 $H(\\cdot)$ 是赫维赛德阶跃函数（当其参数大于或等于 $0$ 时返回 $1$，否则返回 $0$），$w_{ij}$ 是从神经元 $j$ 到神经元 $i$ 的权重，$\\theta_i$ 是神经元 $i$ 的阈值。构建一个由 $n = 3$ 个标记为 $A$、$B$ 和 $C$ 的McCulloch-Pitts神经元组成的循环网络，该网络具有环形拓扑和以下意义上的复制动态：神经元 $A$ 复制神经元 $C$，神经元 $B$ 复制神经元 $A$，神经元 $C$ 复制神经元 $B$。将权重矩阵 $W$ 和阈值向量 $\\boldsymbol{\\theta}$ 正式指定为 $W = \\begin{bmatrix} 0  0  1 \\\\ 1  0  0 \\\\ 0  1  0 \\end{bmatrix}$ 和 $\\boldsymbol{\\theta} = \\begin{bmatrix} 0.5 \\\\ 0.5 \\\\ 0.5 \\end{bmatrix}$。这确保了更新规则简化为从环中的指定前驱进行逻辑复制。\n\n定义两种更新机制：\n- 同步更新：所有神经元根据当前网络状态 $\\mathbf{x}(t) = (x_A(t), x_B(t), x_C(t))$ 同时更新，在一个步骤中产生 $\\mathbf{x}(t+1)$。\n- 具有固定顺序调度的异步更新：在一个宏观步骤中，按固定顺序 $(A, B, C)$ 执行三个微观步骤。在每个微观步骤中，使用当前状态向量更新目标神经元，在进入下一个神经元之前立即提交新值。宏观步骤映射 $\\mathbf{x}(t) \\mapsto \\mathbf{x}(t+1)$ 是这三个微观步骤的复合。\n\n对于每种机制，考虑状态图，其顶点是所有 $2^3 = 8$ 个二元状态 $\\{0,1\\}^3$，其有向边表示由网络动态引起的一步（对于同步机制）或单宏观步骤（对于异步顺序机制）的转换。\n\n从上述基本定义出发，分析在该网络中异步更新如何导致与同步更新不同的极限环。通过构建完整的状态转换函数，计算两种机制的极限环并分析它们的吸引盆。将状态表示为3位二进制向量 $(x_A,x_B,x_C)$，通过 $x_A \\cdot 4 + x_B \\cdot 2 + x_C \\cdot 1$ 编码为 $[0,7]$ 中的整数。\n\n您的程序必须实现精确指定的网络和更新规则，并根据状态图生成以下输出：\n- 对于下面定义的测试套件中的每个初始状态，计算在同步更新和异步顺序更新下达到的极限环的长度。极限环的长度是环中不同状态的数量。如果达到不动点，则长度为 $1$。\n- 计算在同步状态图和异步顺序状态图中，遍历所有8个状态时，不同极限环的数量。\n- 计算同步机制和异步顺序机制的吸引盆大小的多重集。极限环的吸引盆大小是在相应更新映射的重复应用下最终达到该环的状态数量。\n\n测试套件：\n- 使用初始状态 $\\mathbf{x}(0)$ 分别等于 $(0,0,1)$、$(1,0,0)$、$(1,1,1)$、$(0,0,0)$ 和 $(0,1,1)$，它们分别编码为整数 $1$、$4$、$7$、$0$ 和 $3$。\n- 对于这些初始状态中的每一个，按前述方法计算同步和异步顺序极限环的长度。\n\n您的程序应生成单行输出，该行是包含在方括号中的逗号分隔列表。该行必须按顺序包含以下项目：\n- 一个包含 $5$ 个整数的列表，按顺序 $[1,4,7,0,3]$ 给出初始状态的同步极限环长度。\n- 一个包含 $5$ 个整数的列表，按顺序 $[1,4,7,0,3]$ 给出初始状态的异步顺序极限环长度。\n- 一个布尔值，指示在所有8个状态中，两种机制的极限环集合是否不同。\n- 一个整数，给出在所有8个状态中不同步极限环的数量。\n- 一个整数，给出在所有8个状态中不同异步顺序极限环的数量。\n- 一个整数列表，给出所有不同步极限环的吸引盆大小，按非递减顺序排序。\n- 一个整数列表，给出所有不同异步顺序极限环的吸引盆大小，按非递减顺序排序。\n\n您的程序不得读取任何输入，并且不得打印除指定的单行文本之外的任何其他文本。",
            "solution": "用户想要分析一个3神经元的McCulloch-Pitts网络，并比较其在同步和异步更新机制下的动态。\n\n### 步骤1：问题验证\n\n**1.1. 提取已知条件**\n- **模型**：McCulloch-Pitts神经元，状态为 $x_i(t) \\in \\{0,1\\}$，更新规则为 $x_i(t+1) = H\\left(\\sum_{j} w_{ij} x_j(t) - \\theta_i\\right)$。$H(\\cdot)$ 是赫维赛德阶跃函数：当 $z \\ge 0$ 时 $H(z) = 1$，当 $z  0$ 时 $H(z) = 0$。\n- **网络**：$n=3$ 个神经元，标记为 $A$、$B$、$C$。\n- **拓扑**：环形，具有复制动态：$A$ 复制 $C$，$B$ 复制 $A$，$C$ 复制 $B$。\n- **参数**：权重矩阵 $W = \\begin{bmatrix} 0  0  1 \\\\ 1  0  0 \\\\ 0  1  0 \\end{bmatrix}$ 和阈值向量 $\\boldsymbol{\\theta} = \\begin{bmatrix} 0.5 \\\\ 0.5 \\\\ 0.5 \\end{bmatrix}$。\n- **状态表示**：一个状态 $\\mathbf{x} = (x_A, x_B, x_C)$ 编码为整数 $k = x_A \\cdot 4 + x_B \\cdot 2 + x_C \\cdot 1$。状态空间为 $\\{0, 1, \\dots, 7\\}$。\n- **更新机制**：\n    1. **同步**：所有神经元同时更新。\n    2. **异步顺序**：神经元按固定顺序 $(A, B, C)$ 更新，每次更新立即生效。\n- **任务**：\n    1. 对每种更新机制，构建覆盖8个可能状态的状态转换图。\n    2. 对于给定的初始状态测试套件，计算每种机制下达到的极限环的长度。\n    3. 计算每种机制的不同极限环的数量。\n    4. 计算每种机制的吸引盆大小的多重集。\n- **测试套件**：初始状态编码为整数 $1, 4, 7, 0, 3$。\n- **输出格式**：单行、方括号内的逗号分隔列表，包含：\n    - 测试套件的同步环长度列表。\n    - 测试套件的异步环长度列表。\n    - 指示极限环集合是否不同的布尔值。\n    - 同步极限环的数量。\n    - 异步极限环的数量。\n    - 同步吸引盆大小的排序列表。\n    - 异步吸引盆大小的排序列表。\n\n**1.2. 使用提取的已知条件进行验证**\n- **科学依据**：该问题基于成熟的人工神经网络理论，特别是McCulloch-Pitts模型。在不同更新方案（同步与异步）下对网络动态的分析是循环网络和离散动力系统研究中的一个基本课题。\n- **良定性**：问题被完全指定。神经元模型、网络参数（$W, \\boldsymbol{\\theta}$）、状态空间和更新规则都得到了明确的定义。状态空间是有限的，这保证了动态最终会进入一个极限环（包括不动点）。所有要求的输出都是基于指定动态的确定性计算。\n- **客观性**：问题以精确的数学术语陈述，没有主观或模糊的语言。\n\n**1.3. 结论与行动**\n该问题具有科学合理性、良定性和客观性。它是有效的。我们继续进行求解。\n\n### 步骤2：推导与求解\n\n状态向量为 $\\mathbf{x}(t) = (x_A(t), x_B(t), x_C(t))$。神经元 $i$ 的更新规则是 $x_i(t+1) = H(\\mathbf{w}_i \\cdot \\mathbf{x}(t) - \\theta_i)$，其中 $\\mathbf{w}_i$ 是 $W$ 的第 $i$ 行。\n\n让我们验证对于所有 $i$，$\\theta_i = 0.5$ 时的“复制”动态。\n- 神经元 $A$（索引1）：输入为 $\\sum_j w_{Aj} x_j - \\theta_A = 1 \\cdot x_C - 0.5$。输出 $x_A(t+1) = H(x_C(t) - 0.5)$ 在 $x_C(t)=1$ 时为 $1$，在 $x_C(t)=0$ 时为 $0$。因此，$x_A(t+1) = x_C(t)$。\n- 神经元 $B$（索引2）：输入为 $\\sum_j w_{Bj} x_j - \\theta_B = 1 \\cdot x_A - 0.5$。输出 $x_B(t+1) = H(x_A(t) - 0.5)$ 在 $x_A(t)=1$ 时为 $1$，在 $x_A(t)=0$ 时为 $0$。因此，$x_B(t+1) = x_A(t)$。\n- 神经元 $C$（索引3）：输入为 $\\sum_j w_{Cj} x_j - \\theta_C = 1 \\cdot x_B - 0.5$。输出 $x_C(t+1) = H(x_B(t) - 0.5)$ 在 $x_B(t)=1$ 时为 $1$，在 $x_B(t)=0$ 时为 $0$。因此，$x_C(t+1) = x_B(t)$。\n\n参数正确地实现了所述的复制动态。我们现在分析这两种更新机制。\n\n**2.1. 同步更新机制**\n在此机制下，所有神经元根据时间 $t$ 的状态同时更新。新状态 $\\mathbf{x}(t+1) = (x_A(t+1), x_B(t+1), x_C(t+1))$ 由以下公式给出：\n$$ x_A(t+1) = x_C(t) $$\n$$ x_B(t+1) = x_A(t) $$\n$$ x_C(t+1) = x_B(t) $$\n因此，状态向量的转换为 $\\mathbf{x}(t+1) = (x_C(t), x_A(t), x_B(t))$。这是 $\\mathbf{x}(t)$ 分量的一个排列。我们为所有 $2^3=8$ 个状态构建状态转换图，使用整数编码 $k = 4x_A + 2x_B + 1x_C$。\n\n- $0=(0,0,0) \\to (0,0,0)=0$\n- $1=(0,0,1) \\to (1,0,0)=4$\n- $2=(0,1,0) \\to (0,0,1)=1$\n- $3=(0,1,1) \\to (1,0,1)=5$\n- $4=(1,0,0) \\to (0,1,0)=2$\n- $5=(1,0,1) \\to (1,1,0)=6$\n- $6=(1,1,0) \\to (0,1,1)=3$\n- $7=(1,1,1) \\to (1,1,1)=7$\n\n完整的状态转换映射是 $T_{sync}: \\{0 \\to 0, 1 \\to 4, 2 \\to 1, 3 \\to 5, 4 \\to 2, 5 \\to 6, 6 \\to 3, 7 \\to 7\\}$。\n该动态将状态空间划分为以下不相交的集合：\n- **不动点**：$\\{0\\}$。这是一个长度为1的极限环。其吸引盆是 $\\{0\\}$。大小：$1$。\n- **不动点**：$\\{7\\}$。这是一个长度为1的极限环。其吸引盆是 $\\{7\\}$。大小：$1$。\n- **环**：$1 \\to 4 \\to 2 \\to 1$。这是一个长度为3的极限环。其吸引盆是 $\\{1, 2, 4\\}$。大小：$3$。\n- **环**：$3 \\to 5 \\to 6 \\to 3$。这是一个长度为3的极限环。其吸引盆是 $\\{3, 5, 6\\}$。大小：$3$。\n\n**2.2. 异步顺序更新机制**\n在此机制下，神经元按固定顺序 $(A, B, C)$ 更新。设时间 $t$ 的状态为 $(x_A, x_B, x_C)$。宏观步骤包含三个微观步骤：\n1. 更新 $A$：$x'_A = x_C$。状态变为 $(x'_A, x_B, x_C)$。\n2. 更新 $B$：$x'_B = x'_A$。状态变为 $(x'_A, x'_B, x_C)$。\n3. 更新 $C$：$x'_C = x'_B$。状态变为 $(x'_A, x'_B, x'_C)$。\n\n一个宏观步骤后的最终状态是 $\\mathbf{x}(t+1) = (x'_A, x'_B, x'_C)$。通过代入：\n$$ x_A(t+1) = x_C(t) $$\n$$ x_B(t+1) = x_A(t+1) = x_C(t) $$\n$$ x_C(t+1) = x_B(t+1) = x_C(t) $$\n转换为 $\\mathbf{x}(t+1) = (x_C(t), x_C(t), x_C(t))$。下一个状态完全由神经元 $C$ 的当前状态决定。如果 $x_C(t)=0$，下一个状态是 $(0,0,0)=0$。如果 $x_C(t)=1$，下一个状态是 $(1,1,1)=7$。\n\n状态转换图是：\n- $x_C=0$ 的状态：$\\{0, 2, 4, 6\\}$。全部转换到状态 $0$。\n  - $0=(0,0,0) \\to (0,0,0)=0$\n  - $2=(0,1,0) \\to (0,0,0)=0$\n  - $4=(1,0,0) \\to (0,0,0)=0$\n  - $6=(1,1,0) \\to (0,0,0)=0$\n- $x_C=1$ 的状态：$\\{1, 3, 5, 7\\}$。全部转换到状态 $7$。\n  - $1=(0,0,1) \\to (1,1,1)=7$\n  - $3=(0,1,1) \\to (1,1,1)=7$\n  - $5=(1,0,1) \\to (1,1,1)=7$\n  - $7=(1,1,1) \\to (1,1,1)=7$\n\n完整的状态转换映射是 $T_{async}: \\{0 \\to 0, 1 \\to 7, 2 \\to 0, 3 \\to 7, 4 \\to 0, 5 \\to 7, 6 \\to 0, 7 \\to 7\\}$。\n该动态将状态空间划分为两个集合：\n- **不动点**：$\\{0\\}$。这是一个长度为1的极限环。其吸引盆是 $\\{0, 2, 4, 6\\}$。大小：$4$。\n- **不动点**：$\\{7\\}$。这是一个长度为1的极限环。其吸引盆是 $\\{1, 3, 5, 7\\}$。大小：$4$。\n\n**2.3. 计算最终结果**\n我们现在根据上述分析计算问题陈述所要求的具体量。\n测试套件由初始状态 $1, 4, 7, 0, 3$ 组成。\n\n- **同步极限环长度**：\n  - 状态 $1$：位于环 $\\{1, 4, 2\\}$ 中。长度为 $3$。\n  - 状态 $4$：位于环 $\\{1, 4, 2\\}$ 中。长度为 $3$。\n  - 状态 $7$：位于环 $\\{7\\}$ 中。长度为 $1$。\n  - 状态 $0$：位于环 $\\{0\\}$ 中。长度为 $1$。\n  - 状态 $3$：位于环 $\\{3, 5, 6\\}$ 中。长度为 $3$。\n  - 结果：`[3, 3, 1, 1, 3]`\n\n- **异步极限环长度**：\n  - 状态 $1$：转换到不动点 $7$。长度为 $1$。\n  - 状态 $4$：转换到不动点 $0$。长度为 $1$。\n  - 状态 $7$：是不动点 $\\{7\\}$。长度为 $1$。\n  - 状态 $0$：是不动点 $\\{0\\}$。长度为 $1$。\n  - 状态 $3$：转换到不动点 $7$。长度为 $1$。\n  - 结果：`[1, 1, 1, 1, 1]`\n\n- **极限环是否不同**：同步环的集合是 $\\{\\{0\\}, \\{7\\}, \\{1, 2, 4\\}, \\{3, 5, 6\\}\\}$。异步环的集合是 $\\{\\{0\\}, \\{7\\}\\}$。这些集合是不同的。结果：`True`。\n\n- **不同极限环的数量**：\n  - 同步：$4$ 个环。\n  - 异步：$2$ 个环。\n\n- **吸引盆大小（已排序）**：\n  - 同步：吸引盆大小为 $1, 1, 3, 3$。结果：`[1, 1, 3, 3]`。\n  - 异步：吸引盆大小为 $4, 4$。结果：`[4, 4]`。\n\n这些结果将由程序计算和格式化。",
            "answer": "[[3,3,1,1,3],[1,1,1,1,1],True,4,2,[1,1,3,3],[4,4]]"
        },
        {
            "introduction": "理想化的模型终究要面对现实世界中的不完美，例如噪声。本练习将深入探讨MP神经元的“脆弱性”，这一特性源于其硬阈值激活函数。通过计算单个输入错误导致输出翻转的概率，你将对模型的敏感性以及“间隔”（margin）对于稳健计算的重要性有一个定量的理解。",
            "id": "4065167",
            "problem": "考虑一个具有二进制输入、固定突触权重和硬阈值激活的McCulloch-Pitts神经元。设输入为 $x_{1}, x_{2}, \\dots, x_{n} \\in \\{0,1\\}$，突触权重为 $w_{1}, w_{2}, \\dots, w_{n} \\in \\mathbb{R}$，阈值为 $\\theta \\in \\mathbb{R}$。将神经元的输出定义为 $y = H\\!\\left(\\sum_{i=1}^{n} w_{i} x_{i} - \\theta\\right)$，其中 $H(\\cdot)$ 是Heaviside阶跃函数，当 $z \\ge 0$ 时 $H(z) = 1$，当 $z  0$ 时 $H(z) = 0$。在单比特噪声模型中，从 $\\{1, \\dots, n\\}$ 中均匀随机选择一个输入坐标 $j$，并将其翻转 $x_{j} \\mapsto 1 - x_{j}$。\n\n仅从这些核心定义出发，从概念上解释为什么硬阈值使得神经元在阈值附近对微小的输入扰动表现出脆弱性。然后，推导出翻转单个比特 $x_j$ 会导致输出 $y$ 翻转的充分必要条件，该条件需用带符号边界 $m = \\sum_{i=1}^{n} w_{i} x_{i} - \\theta$、权重 $w_{j}$ 和比特值 $x_{j}$ 来表示。你的推导不应假设 $n$、$\\theta$、$w_{i}$ 或 $x_{i}$ 的任何特定值。\n\n最后，将你得出的条件应用于一个具体实例：$n = 7$，权重为 $(w_{1}, \\dots, w_{7}) = (0.9, 1.6, -0.7, 1.1, 0.5, -1.2, 0.8)$，阈值为 $\\theta = 1.9$，输入为 $(x_{1}, \\dots, x_{7}) = (1, 1, 0, 1, 0, 1, 0)$。在翻转一个均匀随机输入坐标的单比特噪声模型下，计算输出翻转的确切概率。将最终概率表示为最简分数。不需要四舍五入，也不涉及单位。",
            "solution": "该问题要求对McCulloch-Pitts神经元进行三部分分析：对其脆弱性的概念性解释，在单比特噪声下输出翻转条件的普适性推导，以及针对给定实例翻转概率的具体计算。\n\n首先，我们解决概念性问题。McCulloch-Pitts神经元的输出由Heaviside阶跃函数 $y = H(m)$ 决定，其中 $m = \\sum_{i=1}^{n} w_{i} x_{i} - \\theta$ 是带符号边界。Heaviside函数 $H(z)$ 的决定性特征是其在 $z=0$ 处的间断性，其值从 $z0$ 时的 $0$ 跳跃到 $z \\ge 0$ 时的 $1$。这意味着，参数 $m$ 的一个跨越 $0$ 值的无穷小变化（例如，从一个任意小的负值 $-\\epsilon$ 变为一个任意小的非负值 $\\delta$），会导致神经元输出的最大变化，即从 $y=0$ 变为 $y=1$。输入扰动，例如翻转单个比特 $x_j$，会引起加权和 $\\sum w_i x_i$ 的变化，从而引起边界 $m$ 的变化。如果神经元的初始状态使得其边界 $m$ 非常接近阈值 $0$（即 $|m|$ 很小），那么即使是一个微小的输入扰动，只要其在 $m$ 中产生的变化幅度大于 $|m|$，就可能翻转边界的符号。这个符号的变化会迫使输出在 $0$ 和 $1$ 之间跳变。当神经元在其阈值附近（$m \\approx 0$）工作时，其输出对微小输入扰动的这种高敏感性，正是脆弱性的确切含义。\n\n接下来，我们推导输出翻转的充分必要条件。设初始输入向量为 $\\mathbf{x} = (x_1, \\dots, x_n)$，初始加权和为 $S = \\sum_{i=1}^{n} w_{i} x_{i}$，初始边界为 $m = S - \\theta$。初始输出为 $y = H(m)$。当单个输入比特 $x_j$ 被翻转为 $1-x_j$ 时，计算新的加权和 $S'$。\n如果 $x_j=0$ 被翻转为 $1$，新的和为 $S' = S + w_j$。新的边界为 $m' = m+w_j$。\n如果 $x_j=1$ 被翻转为 $0$，新的和为 $S' = S - w_j$。新的边界为 $m' = m-w_j$。\n当且仅当新输出 $y' = H(m')$ 与初始输出 $y = H(m)$ 不同时，才会发生输出翻转。翻转有两种可能性：\n1.  输出从 $y=0$ 翻转到 $y'=1$。这要求初始边界为负（$m  0$），新边界为非负（$m' \\ge 0$）。\n2.  输出从 $y=1$ 翻转到 $y'=0$。这要求初始边界为非负（$m \\ge 0$），新边界为负（$m'  0$）。\n\n我们根据被翻转比特 $x_j$ 的初始值来分析这些可能性。\n\n情况1：翻转 $x_j=0$。新边界为 $m' = m+w_j$。\n如果（$m0$ 且 $m+w_j \\ge 0$）或（$m \\ge 0$ 且 $m+w_j  0$），则发生翻转。\n对于第一个条件（$y=0 \\to y'=1$），我们有 $-w_j \\le m  0$。这仅在 $w_j>0$ 时可能。\n对于第二个条件（$y=1 \\to y'=0$），我们有 $0 \\le m  -w_j$。这仅在 $w_j0$ 时可能。\n\n情况2：翻转 $x_j=1$。新边界为 $m' = m-w_j$。\n如果（$m0$ 且 $m-w_j \\ge 0$）或（$m \\ge 0$ 且 $m-w_j  0$），则发生翻转。\n对于第一个条件（$y=0 \\to y'=1$），我们有 $w_j \\le m  0$。这仅在 $w_j0$ 时可能。\n对于第二个条件（$y=1 \\to y'=0$），我们有 $0 \\le m  w_j$。这仅在 $w_j>0$ 时可能。\n\n这四个条件是翻转比特 $x_j$ 时输出发生翻转的充分必要条件。\n\n最后，我们将这些条件应用于所提供的具体实例，并计算翻转的概率。\n参数为：$n=7$，权重 $(w_{1}, \\dots, w_{7}) = (0.9, 1.6, -0.7, 1.1, 0.5, -1.2, 0.8)$，阈值 $\\theta = 1.9$，以及输入向量 $\\mathbf{x} = (x_{1}, \\dots, x_{7}) = (1, 1, 0, 1, 0, 1, 0)$。\n\n首先，我们计算神经元的初始状态。\n加权和为 $S = \\sum_{i=1}^{7} w_{i} x_{i}$：\n$S = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + w_5 x_5 + w_6 x_6 + w_7 x_7$\n$S = (0.9)(1) + (1.6)(1) + (-0.7)(0) + (1.1)(1) + (0.5)(0) + (-1.2)(1) + (0.8)(0)$\n$S = 0.9 + 1.6 + 0 + 1.1 + 0 - 1.2 + 0 = 2.4$\n初始边界为 $m = S - \\theta = 2.4 - 1.9 = 0.5$。\n由于 $m = 0.5 \\ge 0$，初始输出为 $y = H(0.5) = 1$。\n\n只有当新输出为 $y'=0$ 时，输出才会发生翻转。这属于 $y=1 \\to y'=0$ 的情况。我们现在检查每个输入坐标 $j \\in \\{1, \\dots, 7\\}$，以确定翻转它是否会导致翻转。\n\n对于 $x_j=0$ 的 $j$（即 $j=3, 5, 7$）：\n翻转的条件是 $0 \\le m  -w_j$，这要求 $w_j  0$。\n- 对于 $j=3$：$x_3=0$，$w_3 = -0.7$。这里 $w_3  0$。我们检查条件：$0 \\le 0.5  -(-0.7) = 0.7$。该条件成立。翻转 $x_3$ 会导致翻转。\n- 对于 $j=5$：$x_5=0$，$w_5 = 0.5$。这里 $w_5$ 不是负数，因此不满足翻转条件。不发生翻转。\n- 对于 $j=7$：$x_7=0$，$w_7 = 0.8$。这里 $w_7$ 不是负数，因此不满足翻转条件。不发生翻转。\n\n对于 $x_j=1$ 的 $j$（即 $j=1, 2, 4, 6$）：\n翻转的条件是 $0 \\le m  w_j$，这要求 $w_j > 0$。\n- 对于 $j=1$：$x_1=1$，$w_1 = 0.9$。这里 $w_1 > 0$。我们检查条件：$0 \\le 0.5  0.9$。该条件成立。翻转 $x_1$ 会导致翻转。\n- 对于 $j=2$：$x_2=1$，$w_2 = 1.6$。这里 $w_2 > 0$。我们检查条件：$0 \\le 0.5  1.6$。该条件成立。翻转 $x_2$ 会导致翻转。\n- 对于 $j=4$：$x_4=1$，$w_4 = 1.1$。这里 $w_4 > 0$。我们检查条件：$0 \\le 0.5  1.1$。该条件成立。翻转 $x_4$ 会导致翻转。\n- 对于 $j=6$：$x_6=1$，$w_6 = -1.2$。这里 $w_6$ 不是正数，因此不满足翻转条件。不发生翻转。\n\n总而言之，当索引 $j \\in \\{1, 2, 3, 4\\}$ 时，翻转输入比特会导致输出翻转。共有 $4$ 个这样的索引。\n单比特噪声模型从 $\\{1, \\dots, 7\\}$ 中均匀随机选择一个输入坐标 $j$。可能的选择总数为 $n=7$。导致输出翻转的选择数量为 $4$。\n翻转的概率是导致翻转的结果数与总结果数的比值：\n$P(\\text{翻转}) = \\frac{\\text{导致翻转的坐标数}}{\\text{总坐标数}} = \\frac{4}{7}$。\n这个分数已经是最简形式。",
            "answer": "$$\\boxed{\\frac{4}{7}}$$"
        }
    ]
}