{
    "hands_on_practices": [
        {
            "introduction": "Neural computation is a metabolically demanding process, and understanding its energy budget starts at the molecular level with adenosine triphosphate (ATP), the universal energy currency of the cell. This first practice grounds the abstract concept of neural energy cost in fundamental physics. You will apply the First Law of Thermodynamics to a neuron to derive and calculate the rate of heat production directly from the rate of ATP hydrolysis, providing a concrete, quantitative link between cellular activity and its thermodynamic signature. ",
            "id": "4042918",
            "problem": "A cortical pyramidal neuron at temperature $T$ and approximately constant ambient pressure $p$ operates in steady state while engaging in massively parallel ionic signaling, where numerous adenosine triphosphate (ATP) hydrolysis events support ion pumping and synaptic transmission. From the First Law of Thermodynamics for an open, reactive system and the definition of enthalpy, at constant pressure the enthalpy change associated with a chemical reaction equals the heat exchanged with the environment, up to non-pressure–volume work. In a neuron, mechanical pressure–volume work is negligible and any non-pressure–volume work performed by adenosine triphosphate hydrolysis (e.g., moving ions across membranes) ultimately dissipates as heat in steady state. Hence, the rate of heat release from ATP turnover equals the rate at which reaction enthalpy is produced.\n\nAssume the neuron hydrolyzes ATP to adenosine diphosphate (ADP) and inorganic phosphate with a total consumption rate $\\nu_{\\text{ATP}}$ (molecules per second), and the molar enthalpy change of ATP hydrolysis under cytosolic conditions is $\\Delta H_{\\text{ATP}}$ (joules per mole), with $\\Delta H_{\\text{ATP}}  0$ for an exothermic reaction. Derive, from first principles, an expression for the rate of heat production $\\dot{Q}$ in terms of $\\nu_{\\text{ATP}}$, $\\Delta H_{\\text{ATP}}$, and the Avogadro constant $N_{\\mathrm{A}}$, and then compute its numerical value for the following measured parameters:\n$$\\nu_{\\text{ATP}} = 1.2 \\times 10^{9} \\ \\text{s}^{-1}, \\quad \\Delta H_{\\text{ATP}} = -25 \\times 10^{3} \\ \\text{J mol}^{-1}, \\quad N_{\\mathrm{A}} = 6.02214076 \\times 10^{23} \\ \\text{mol}^{-1}.$$\nExpress the final result as the positive rate of heat release to the environment in watts (W). Round your answer to three significant figures.",
            "solution": "The problem asks for a derivation of the rate of heat production, $\\dot{Q}$, by a neuron due to ATP hydrolysis, and for the calculation of its numerical value given a set of parameters.\n\nThe problem statement has been validated and is found to be scientifically grounded, well-posed, and objective. It is based on fundamental principles of thermodynamics as applied to cellular bioenergetics. The assumptions provided—steady state, negligible pressure-volume work, and the ultimate dissipation of all non-PV work as heat—are standard and appropriate for modeling the energy budget of a neuron. All necessary variables and constants are provided, and their values are physically realistic. The problem is therefore deemed valid and a solution will be constructed.\n\nAccording to the First Law of Thermodynamics, for a process occurring at constant pressure, the change in enthalpy, $\\Delta H$, is equal to the heat exchanged with the surroundings, $q_p$, plus any non-pressure-volume work, $w_{\\text{non-PV}}$, done by the system.\n$$ \\Delta H = q_p + w_{\\text{non-PV}} $$\nIn the context of the neuron, the problem specifies that in the steady state, any non-pressure-volume work performed by ATP hydrolysis (such as ion transport) ultimately dissipates as heat. This means that the work energy is returned to the system as thermal energy and then released to the environment. Consequently, the total rate of heat release to the environment, $\\dot{Q}$, must equal the rate at which enthalpy is changed by the chemical reaction of ATP hydrolysis.\n\nLet's define the quantities involved:\n- $\\nu_{\\text{ATP}}$ is the rate of ATP consumption in molecules per unit time, with units of $\\text{s}^{-1}$.\n- $\\Delta H_{\\text{ATP}}$ is the molar enthalpy change of ATP hydrolysis, with units of $\\text{J mol}^{-1}$. This value is negative for an exothermic reaction, indicating release of energy from the chemical bonds.\n- $N_{\\mathrm{A}}$ is the Avogadro constant, the number of constituent particles (molecules, in this case) per mole, with units of $\\text{mol}^{-1}$.\n\nFirst, we convert the molecular consumption rate, $\\nu_{\\text{ATP}}$, into a molar consumption rate, which we can denote as $\\dot{n}_{\\text{ATP}}$. This is achieved by dividing the number of molecules consumed per second by the number of molecules in a mole:\n$$ \\dot{n}_{\\text{ATP}} = \\frac{\\nu_{\\text{ATP}}}{N_{\\mathrm{A}}} $$\nThe units of this expression are $(\\text{s}^{-1}) / (\\text{mol}^{-1}) = \\text{mol s}^{-1}$, which is the correct unit for a molar rate.\n\nThe total rate of enthalpy change for the system is the product of the molar rate of reaction and the molar enthalpy change of the reaction:\n$$ \\text{Rate of Enthalpy Change} = \\dot{n}_{\\text{ATP}} \\cdot \\Delta H_{\\text{ATP}} = \\frac{\\nu_{\\text{ATP}} \\Delta H_{\\text{ATP}}}{N_{\\mathrm{A}}} $$\nThe units of this expression are $(\\text{mol s}^{-1}) \\cdot (\\text{J mol}^{-1}) = \\text{J s}^{-1}$. A rate of energy change of a joule per second is a watt ($1 \\ \\text{W} = 1 \\ \\text{J s}^{-1}$).\n\nThe problem asks for the rate of heat production, $\\dot{Q}$, defined as the positive rate of heat released *to* the environment. Since $\\Delta H_{\\text{ATP}}  0$ for this exothermic reaction, the rate of enthalpy change of the system is negative, signifying an energy decrease within the system. This decrease in the system's enthalpy corresponds to an equivalent amount of heat released to the surroundings. Therefore, the rate of heat release is the negative of the rate of the system's enthalpy change:\n$$ \\dot{Q} = -(\\text{Rate of Enthalpy Change}) $$\nSubstituting the expression derived above, we obtain the final symbolic expression for the rate of heat production:\n$$ \\dot{Q} = -\\frac{\\nu_{\\text{ATP}} \\Delta H_{\\text{ATP}}}{N_{\\mathrm{A}}} $$\n\nNow, we can compute the numerical value using the provided parameters:\n$$ \\nu_{\\text{ATP}} = 1.2 \\times 10^{9} \\ \\text{s}^{-1} $$\n$$ \\Delta H_{\\text{ATP}} = -25 \\times 10^{3} \\ \\text{J mol}^{-1} $$\n$$ N_{\\mathrm{A}} = 6.02214076 \\times 10^{23} \\ \\text{mol}^{-1} $$\n\nSubstituting these values into the derived expression for $\\dot{Q}$:\n$$ \\dot{Q} = -\\frac{(1.2 \\times 10^{9} \\ \\text{s}^{-1}) \\times (-25 \\times 10^{3} \\ \\text{J mol}^{-1})}{6.02214076 \\times 10^{23} \\ \\text{mol}^{-1}} $$\nThe two negative signs cancel, resulting in a positive value for heat release, as expected.\n$$ \\dot{Q} = \\frac{(1.2 \\times 25) \\times (10^{9} \\times 10^{3})}{6.02214076 \\times 10^{23}} \\ \\text{J s}^{-1} $$\n$$ \\dot{Q} = \\frac{30 \\times 10^{12}}{6.02214076 \\times 10^{23}} \\ \\text{W} $$\n$$ \\dot{Q} = \\frac{3.0 \\times 10^{13}}{6.02214076 \\times 10^{23}} \\ \\text{W} $$\n$$ \\dot{Q} \\approx 0.4981596 \\times 10^{-10} \\ \\text{W} $$\nTo express this in standard scientific notation, we adjust the decimal point:\n$$ \\dot{Q} \\approx 4.981596 \\times 10^{-11} \\ \\text{W} $$\nThe problem requires the answer to be rounded to three significant figures. The first three significant figures are $4$, $9$, and $8$. The fourth significant figure is $1$, which is less than $5$, so we round down (i.e., we truncate).\n$$ \\dot{Q} \\approx 4.98 \\times 10^{-11} \\ \\text{W} $$\nThis is the rate of heat release from the single neuron under the specified conditions.",
            "answer": "$$\\boxed{4.98 \\times 10^{-11}}$$"
        },
        {
            "introduction": "Beyond the energy needed for cellular maintenance, is there a fundamental, unavoidable cost to the act of computation itself? This exercise explores this question by guiding you through a derivation of Landauer's principle from first principles of statistical mechanics. You will demonstrate that erasing a single bit of information—a fundamental computational step—must dissipate a minimum amount of heat, $k_B T \\ln(2)$, into the environment. This reveals the profound and inescapable link between thermodynamics and information, setting the ultimate physical lower bound for energy-efficient computation. ",
            "id": "4042953",
            "problem": "Consider a nanoscale bistable molecular switch in a neuronal microdomain that encodes one logical bit. The switch is in contact with a large cytosolic environment modeled as an isothermal heat bath at temperature $T$, and the two logical states are encoded by two metastable macrostates with equal prior probabilities and negligible energy difference. A logical erasure operation deterministically resets the switch to one standard state regardless of its initial state. Starting only from the Second Law of Thermodynamics in the Clausius form and the statistical definition of entropy, derive an analytic expression for the minimum average heat that must be dissipated into the environment by such an erasure when the control protocol is quasistatic. Clearly articulate each physical assumption used in the derivation. Then evaluate the derived expression for $T=310\\,\\text{K}$ (typical mammalian physiological temperature). Use $k_{B}=1.380\\,649\\times 10^{-23}\\,\\text{J}\\,\\text{K}^{-1}$ and round your final numerical answer to four significant figures. Express the final energy in $\\text{J}$.",
            "solution": "The problem statement has been analyzed and is deemed valid. It is a well-posed problem in statistical thermodynamics applied to the physics of information, commonly known as Landauer's principle. The problem provides a clear objective, sufficient data, and is grounded in established scientific principles.\n\nThe task is to derive the minimum average heat dissipated during the erasure of one bit of information. This corresponds to a thermodynamically reversible, quasistatic process. We begin with the statistical definition of entropy and the Second Law of Thermodynamics.\n\nLet the system be the bistable molecular switch, which can exist in two logical states, '0' and '1'. The environment is a heat bath at a constant temperature $T$.\n\nFirst, we define the initial state of the system before erasure. The problem states that the two logical states have equal prior probabilities. Let $p_0$ and $p_1$ be the probabilities of the switch being in state '0' and state '1', respectively.\n$$ p_0 = \\frac{1}{2}, \\quad p_1 = \\frac{1}{2} $$\nThe statistical entropy of the system, according to the Boltzmann-Gibbs formula, is given by $S = -k_B \\sum_i p_i \\ln(p_i)$, where $k_B$ is the Boltzmann constant and the sum is over all accessible microstates. The initial entropy, $S_{initial}$, is therefore:\n$$ S_{initial} = -k_B \\left( p_0 \\ln(p_0) + p_1 \\ln(p_1) \\right) $$\n$$ S_{initial} = -k_B \\left( \\frac{1}{2} \\ln\\left(\\frac{1}{2}\\right) + \\frac{1}{2} \\ln\\left(\\frac{1}{2}\\right) \\right) = -k_B \\ln\\left(\\frac{1}{2}\\right) = k_B \\ln(2) $$\nThis initial state represents maximum uncertainty for a binary system.\n\nNext, we define the final state after the erasure operation. The erasure deterministically resets the switch to a single standard state, say state '0', regardless of its initial state. The probabilities for the final state are:\n$$ p'_0 = 1, \\quad p'_1 = 0 $$\nThe final entropy of the system, $S_{final}$, is:\n$$ S_{final} = -k_B \\left( p'_0 \\ln(p'_0) + p'_1 \\ln(p'_1) \\right) $$\nUsing the fact that $\\lim_{x\\to 0} x \\ln(x) = 0$, we have:\n$$ S_{final} = -k_B \\left( 1 \\ln(1) + 0 \\right) = 0 $$\nThis final state represents complete certainty.\n\nThe change in the entropy of the system (the switch) is:\n$$ \\Delta S_{system} = S_{final} - S_{initial} = 0 - k_B \\ln(2) = -k_B \\ln(2) $$\nThe entropy of the system decreases because information has been erased, reducing the phase space volume accessible to the system from two states to one.\n\nAccording to the Second Law of Thermodynamics, the total change in entropy of the universe (system + environment) must be greater than or equal to zero for any process:\n$$ \\Delta S_{total} = \\Delta S_{system} + \\Delta S_{environment} \\ge 0 $$\nTo find the minimum heat dissipated, we consider the limiting case of a thermodynamically reversible (quasistatic) process, for which the total entropy change is zero:\n$$ \\Delta S_{total} = \\Delta S_{system} + \\Delta S_{environment} = 0 $$\nThis implies that the change in the entropy of the environment must compensate for the change in the entropy of the system:\n$$ \\Delta S_{environment} = - \\Delta S_{system} = -(-k_B \\ln(2)) = k_B \\ln(2) $$\nThe environment is an isothermal heat bath at temperature $T$. From the Clausius form of the Second Law, the change in entropy of the heat bath is related to the heat $Q$ it absorbs by $\\Delta S_{environment} = \\frac{Q}{T}$. Here, $Q$ is the heat dissipated from the switch into the environment. The minimum heat dissipated, $Q_{min}$, corresponds to the reversible process.\n$$ \\Delta S_{environment} = \\frac{Q_{min}}{T} $$\nEquating the two expressions for $\\Delta S_{environment}$:\n$$ \\frac{Q_{min}}{T} = k_B \\ln(2) $$\nSolving for $Q_{min}$, we obtain the analytic expression for the minimum average heat dissipated:\n$$ Q_{min} = k_B T \\ln(2) $$\nThis result is known as the Landauer limit. The problem also states that the energy difference between the two states is negligible. This is an important assumption, as it implies the change in the system's internal energy $\\Delta U_{system}$ is zero. From the First Law of Thermodynamics, $\\Delta U_{system} = Q_{in} + W_{on}$, where $Q_{in}$ is heat transferred to the system and $W_{on}$ is work done on the system. With $\\Delta U_{system} = 0$, we have $W_{on} = -Q_{in} = Q_{out}$, where $Q_{out}$ is the heat dissipated to the environment. The work done on the system to compress its phase space is entirely converted into dissipated heat.\n\nThe key physical assumptions used in this derivation are:\n1. The system's entropy is described by the statistical (Gibbs) entropy formula.\n2. The erasure process is performed quasistatically, corresponding to a thermodynamically reversible transformation, which yields the minimum possible heat dissipation.\n3. The environment acts as an ideal isothermal heat bath at a constant temperature $T$.\n4. The two logical states of the switch are initially equally probable, representing one bit of information.\n5. The energy difference between the two logical states is negligible ($\\Delta U_{system}=0$).\n\nWe now evaluate this expression for the given values:\n$T = 310\\,\\text{K}$\n$k_B = 1.380649 \\times 10^{-23}\\,\\text{J}\\,\\text{K}^{-1}$\n\n$$ Q_{min} = (1.380649 \\times 10^{-23}\\,\\text{J}\\,\\text{K}^{-1}) \\times (310\\,\\text{K}) \\times \\ln(2) $$\n$$ Q_{min} \\approx (4.2799119 \\times 10^{-21}\\,\\text{J}) \\times (0.69314718...) $$\n$$ Q_{min} \\approx 2.966531 \\times 10^{-21}\\,\\text{J} $$\nRounding the result to four significant figures, as requested:\n$$ Q_{min} \\approx 2.967 \\times 10^{-21}\\,\\text{J} $$",
            "answer": "$$\\boxed{2.967 \\times 10^{-21}}$$"
        },
        {
            "introduction": "Biological circuits rarely operate at the absolute physical limits, instead navigating a complex landscape of trade-offs between energy, reliability, and speed. This final practice immerses you in a realistic design challenge that embodies this principle. You will write a program to engineer a parallel neuromorphic circuit that performs majority voting, a canonical computation, by optimizing redundancy, connectivity, and decision thresholds to minimize energy while guaranteeing a strict level of accuracy. This hands-on coding problem integrates probability theory and optimization, illustrating how parallelism can be strategically employed to build robust and energy-efficient computational systems. ",
            "id": "4042879",
            "problem": "Consider a parallel neuromorphic microcircuit that computes the strict majority of $M$ binary inputs under stochastic spiking, with the aim of minimizing energy while guaranteeing a bounded decision error. Each logical input channel is encoded by $r$ redundant, independent and identically distributed (i.i.d.) spiking neurons. In a decision window of duration $T$ seconds, each redundant neuron for an input channel spikes at most once. Conditional on the true input bit $b \\in \\{0,1\\}$ for its channel, a neuron spikes with probability $p_{\\text{on}}$ when $b=1$ and with probability $p_{\\text{off}}$ when $b=0$, with all spikes independent across neurons and channels. Each spike is transmitted to a single output decision unit through a synapse with independent transmission probability $p_c \\in \\{0.25,0.5,0.75,1.0\\}$ (connectivity). The output unit implements a threshold decision: it emits output $1$ if the total number of transmitted spikes within the window is greater than or equal to an integer threshold $\\theta$, and emits $0$ otherwise. The target function is the strict majority over the $M$ input bits: the correct output equals $1$ if and only if the number of input ones is strictly greater than $M/2$; ties (when $M$ is even and exactly $M/2$ ones are present) are defined to map to $0$.\n\nEnergy is accrued via three components per decision: spike generation, synaptic transmission, and background leak. Let $E_{\\text{spike}}$ be the energy cost in joules per presynaptic spike generated, $E_{\\text{syn}}$ be the energy cost in joules per synaptic transmission event, and $P_{\\text{leak}}$ be the leak power in joules per second. The expected energy for one decision window is modeled as the sum of the expected presynaptic spike energy, expected synaptic transmission energy, and leak energy over the window, i.e., $E_{\\text{total}} = E_{\\text{spike}} \\cdot \\mathbb{E}[N_{\\text{pre}}] + E_{\\text{syn}} \\cdot \\mathbb{E}[N_{\\text{post}}] + P_{\\text{leak}} \\cdot T$, where $\\mathbb{E}[N_{\\text{pre}}]$ is the expected total number of presynaptic spikes across all redundant neurons, and $\\mathbb{E}[N_{\\text{post}}]$ is the expected number of transmitted spikes to the output unit.\n\nDecision reliability is quantified by the maximum error probability across all possible configurations of input bits. For a given tuple $(M,r,p_c,\\theta)$ and given $(p_{\\text{on}},p_{\\text{off}})$, the error probability at a specific number of ones $m_1 \\in \\{0,1,\\dots,M\\}$ is defined from first principles: the number of transmitted spikes equals the sum of two independent binomial random variables $X \\sim \\mathrm{Binomial}(n_1=r \\cdot m_1, p_1 = p_{\\text{on}} \\cdot p_c)$ and $Y \\sim \\mathrm{Binomial}(n_0 = r \\cdot (M-m_1), p_0 = p_{\\text{off}} \\cdot p_c)$. The output emits $1$ if $X+Y \\ge \\theta$ and $0$ otherwise. For strict majority, the correct label is $1$ if $m_1 > M/2$ and $0$ otherwise. The error probability at $m_1$ is therefore the probability that $X+Y$ misclassifies the strict majority, obtained by convolving the binomial mass of $X$ with the binomial cumulative distribution of $Y$ in the appropriate tail. The design must ensure that the maximum of these error probabilities over all $m_1$ does not exceed a prescribed bound $\\varepsilon$.\n\nYour task is to write a complete, runnable program that, for each test case described below, searches over integer redundancy $r \\in \\{1,2,\\dots,R_{\\max}\\}$, connectivity $p_c \\in \\{0.25,0.5,0.75,1.0\\}$, and integer threshold $\\theta \\in \\{0,1,\\dots,r \\cdot M\\}$ to:\n1. Compute the maximum decision error probability across all $m_1 \\in \\{0,1,\\dots,M\\}$, using exact binomial probabilities derived from the foundational definition of independent Bernoulli spiking and synaptic transmission.\n2. If the maximum error is less than or equal to $\\varepsilon$, compute the expected energy $E_{\\text{total}}$ in joules for the worst-case input configuration (the configuration that maximizes $\\mathbb{E}[N_{\\text{pre}}]$ under given $p_{\\text{on}}$ and $p_{\\text{off}}$) using linearity of expectation.\n3. Select the design $(r,p_c,\\theta)$ that minimizes the expected energy among all feasible designs (those meeting the error bound). If multiple designs tie in energy, break ties by choosing the smallest $r$, then the smallest $p_c$, then the smallest $\\theta$.\n\nIf no feasible design exists for a test case, output the sentinel list $[-1,-1,-1,-1.0,-1.0]$ for that case.\n\nPhysical units: report energy values in joules. The final output for the program must be a single line containing the results as a comma-separated list enclosed in square brackets, with each test case’s result represented as a list $[r,p_c,\\theta,E_{\\text{total}},\\text{error}_{\\max}]$.\n\nTest Suite:\n- Case $1$: $M=9$, $p_{\\text{on}}=0.98$, $p_{\\text{off}}=0.02$, $\\varepsilon=10^{-4}$, $E_{\\text{spike}}=1.0 \\times 10^{-9}$ J, $E_{\\text{syn}}=2.0 \\times 10^{-10}$ J, $P_{\\text{leak}}=5.0 \\times 10^{-9}$ J/s, $T=0.01$ s, $R_{\\max}=8$.\n- Case $2$: $M=7$, $p_{\\text{on}}=0.85$, $p_{\\text{off}}=0.15$, $\\varepsilon=10^{-3}$, $E_{\\text{spike}}=1.5 \\times 10^{-9}$ J, $E_{\\text{syn}}=3.0 \\times 10^{-10}$ J, $P_{\\text{leak}}=1.0 \\times 10^{-8}$ J/s, $T=0.02$ s, $R_{\\max}=10$.\n- Case $3$: $M=2$, $p_{\\text{on}}=0.90$, $p_{\\text{off}}=0.10$, $\\varepsilon=10^{-3}$, $E_{\\text{spike}}=1.0 \\times 10^{-9}$ J, $E_{\\text{syn}}=1.0 \\times 10^{-10}$ J, $P_{\\text{leak}}=1.0 \\times 10^{-9}$ J/s, $T=0.005$ s, $R_{\\max}=6$.\n- Case $4$: $M=21$, $p_{\\text{on}}=0.95$, $p_{\\text{off}}=0.05$, $\\varepsilon=5 \\times 10^{-4}$, $E_{\\text{spike}}=2.0 \\times 10^{-9}$ J, $E_{\\text{syn}}=2.0 \\times 10^{-10}$ J, $P_{\\text{leak}}=2.0 \\times 10^{-8}$ J/s, $T=0.02$ s, $R_{\\max}=5$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[ [r_1,p_{c1},\\theta_1,E_1,\\text{err}_1], [r_2,p_{c2},\\theta_2,E_2,\\text{err}_2], \\dots ]$), where each $E_i$ is in joules and each $\\text{err}_i$ is a decimal probability.",
            "solution": "The user has provided a well-defined optimization problem in the domain of neuromorphic computing. I will first validate the problem statement and then proceed with a detailed solution.\n\n### Problem Validation\n\n#### Step 1: Extract Givens\n- **System**: A parallel neuromorphic microcircuit with $M$ binary inputs.\n- **Encoding**: Each input channel uses $r$ redundant, i.i.d. spiking neurons.\n- **Spiking Dynamics**: In a window $T$, each neuron spikes at most once. Spike probability is $p_{\\text{on}}$ for input bit $1$ and $p_{\\text{off}}$ for input bit $0$.\n- **Synaptic Transmission**: Spikes are transmitted to an output unit with probability $p_c \\in \\{0.25, 0.5, 0.75, 1.0\\}$.\n- **Decision Rule**: Output is $1$ if total transmitted spikes $\\ge \\theta$, and $0$ otherwise. $\\theta$ is an integer threshold.\n- **Target Function**: Strict majority over $M$ inputs. Output is $1$ iff the number of ones, $m_1$, is $ M/2$. Ties ($m_1=M/2$) map to output $0$.\n- **Energy Model**: $E_{\\text{total}} = E_{\\text{spike}} \\cdot \\mathbb{E}[N_{\\text{pre}}] + E_{\\text{syn}} \\cdot \\mathbb{E}[N_{\\text{post}}] + P_{\\text{leak}} \\cdot T$.\n- **Reliability Model**: The total number of transmitted spikes for an input with $m_1$ ones is $S=X+Y$, where $X \\sim \\mathrm{Binomial}(r \\cdot m_1, p_{\\text{on}} \\cdot p_c)$ and $Y \\sim \\mathrm{Binomial}(r \\cdot (M-m_1), p_{\\text{off}} \\cdot p_c)$. The error for input $m_1$ is the probability of misclassification. The maximum error over all $m_1 \\in \\{0, \\dots, M\\}$ must not exceed $\\varepsilon$.\n- **Objective**: Find the design $(r, p_c, \\theta)$ that minimizes the expected energy $E_{\\text{total}}$ for the worst-case input configuration (that which maximizes $\\mathbb{E}[N_{\\text{pre}}]$), subject to the maximum error constraint.\n- **Search Space**: $r \\in \\{1, \\dots, R_{\\max}\\}$, $p_c \\in \\{0.25, 0.5, 0.75, 1.0\\}$, $\\theta \\in \\{0, \\dots, r \\cdot M\\}$.\n- **Tie-breaking**: For designs with equal minimal energy, choose the one with the smallest $r$, then smallest $p_c$, then smallest $\\theta$.\n- **No Feasible Solution**: Output `[-1,-1,-1,-1.0,-1.0]`.\n- **Test Cases**: Four specific sets of parameters $(M, p_{\\text{on}}, p_{\\text{off}}, \\varepsilon, E_{\\text{spike}}, E_{\\text{syn}}, P_{\\text{leak}}, T, R_{\\max})$ are provided.\n\n#### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in established models of stochastic neural computation and energy consumption. It is mathematically well-posed, with a clearly defined objective function (energy minimization), a finite search space for the design parameters $(r, p_c, \\theta)$, a quantifiable constraint (error probability bound $\\varepsilon$), and an unambiguous tie-breaking rule. All terms are defined, and the necessary data is provided for each test case. The worst-case energy configuration is shown to be well-defined. The problem is self-contained, objective, and computationally tractable. There are no contradictions, ambiguities, or violations of scientific principles.\n\n#### Step 3: Verdict and Action\nThe problem is **valid**. I will proceed to develop a step-by-step solution.\n\n### Solution\n\nThe problem requires finding an optimal set of design parameters $(r, p_c, \\theta)$ for a neuromorphic circuit that minimizes energy consumption while satisfying a reliability constraint. This is a constrained optimization problem over a discrete parameter space, which we can solve by an exhaustive search. The solution methodology is structured as follows.\n\n#### 1. Optimization Framework\nThe core task is to search through all possible combinations of redundancy $r \\in \\{1, \\dots, R_{\\max}\\}$, connectivity $p_c \\in \\{0.25, 0.5, 0.75, 1.0\\}$, and decision threshold $\\theta \\in \\{0, \\dots, r \\cdot M\\}$. For each combination, we first determine if it is a \"feasible design\" by checking if its maximum error probability is within the bound $\\varepsilon$. Among all feasible designs, we then select the one that minimizes the worst-case expected energy $E_{\\text{total}}$.\n\nA variable `best_design` will store the parameters and performance metrics of the optimal design found so far, initialized to a null state. A variable `min_energy` will track the lowest energy, initialized to infinity.\n\n#### 2. Error Probability Calculation\nFor any given design $(r, p_c, \\theta)$ and a specific input configuration with $m_1$ ones and $m_0 = M-m_1$ zeros, the probability of error must be calculated.\n\nThe total number of neurons associated with '1' inputs is $n_1 = r \\cdot m_1$, and for '0' inputs is $n_0 = r \\cdot m_0$. A neuron associated with a '1' input generates a spike that is successfully transmitted with probability $p_1 = p_{\\text{on}} \\cdot p_c$. Similarly, for a '0' input, this probability is $p_0 = p_{\\text{off}} \\cdot p_c$.\n\nThe number of transmitted spikes from '1' inputs, $X$, follows a binomial distribution $X \\sim \\mathrm{Binomial}(n_1, p_1)$. The number of transmitted spikes from '0' inputs, $Y$, follows $Y \\sim \\mathrm{Binomial}(n_0, p_0)$. Since all spiking and transmission events are independent, the total number of transmitted spikes, $S = X+Y$, is a sum of independent binomial random variables. The probability mass function (PMF) of $S$, $P(S=k)$, is the discrete convolution of the PMFs of $X$ and $Y$:\n$$P(S=k) = \\sum_{i=0}^{k} P(X=i) \\cdot P(Y=k-i)$$\nThe support for $S$ is $\\{0, 1, \\dots, r \\cdot M\\}$.\n\nThe decision error for a given $m_1$ depends on the correct output. The strict majority rule dictates the correct output is $1$ if $m_1  M/2$ and $0$ otherwise.\n- If $m_1  M/2$ (correct output is 1), an error occurs if the circuit outputs 0, i.e., $S  \\theta$. The error probability is $P(\\text{error}|m_1) = P(S  \\theta) = \\sum_{k=0}^{\\theta-1} P(S=k)$.\n- If $m_1 \\le M/2$ (correct output is 0), an error occurs if the circuit outputs 1, i.e., $S \\ge \\theta$. The error probability is $P(\\text{error}|m_1) = P(S \\ge \\theta) = 1 - P(S  \\theta)$.\n\nThe maximum error for the design is $\\text{error}_{\\max} = \\max_{m_1 \\in \\{0, \\dots, M\\}} P(\\text{error}|m_1)$. A design is feasible if $\\text{error}_{\\max} \\le \\varepsilon$.\n\n#### 3. Energy Calculation\nFor each feasible design, we compute the expected energy for the worst-case input configuration. The problem states this is the configuration that maximizes $\\mathbb{E}[N_{\\text{pre}}]$. Let's analyze the total energy expression for a general input with $m_1$ ones:\n$$ \\mathbb{E}[N_{\\text{pre}}(m_1)] = r \\cdot m_1 \\cdot p_{\\text{on}} + r \\cdot (M - m_1) \\cdot p_{\\text{off}} $$\n$$ \\mathbb{E}[N_{\\text{post}}(m_1)] = r \\cdot m_1 \\cdot (p_{\\text{on}} \\cdot p_c) + r \\cdot (M - m_1) \\cdot (p_{\\text{off}} \\cdot p_c) $$\nThe total expected energy is:\n$$ E_{\\text{total}}(m_1) = E_{\\text{spike}} \\cdot \\mathbb{E}[N_{\\text{pre}}(m_1)] + E_{\\text{syn}} \\cdot \\mathbb{E}[N_{\\text{post}}(m_1)] + P_{\\text{leak}} \\cdot T $$\nSubstituting and rearranging terms, $E_{\\text{total}}(m_1)$ is a linear function of $m_1$:\n$$ E_{\\text{total}}(m_1) = m_1 \\cdot r \\cdot (p_{\\text{on}} - p_{\\text{off}})(E_{\\text{spike}} + E_{\\text{syn}}p_c) + \\text{constant terms} $$\nIn all test cases, $p_{\\text{on}}  p_{\\text{off}}$, and all energy and probability parameters are positive. Thus, the coefficient of $m_1$ is positive, and $E_{\\text{total}}(m_1)$ is maximized when $m_1$ is maximized, i.e., at $m_1 = M$. This confirms that the worst-case input configuration for energy is when all inputs are '1'.\n\nThe energy to be minimized is therefore:\n$$ E_{\\text{total}} = E_{\\text{spike}} \\cdot (r \\cdot M \\cdot p_{\\text{on}}) + E_{\\text{syn}} \\cdot (r \\cdot M \\cdot p_{\\text{on}} \\cdot p_c) + P_{\\text{leak}} \\cdot T $$\n$$ E_{\\text{total}} = r \\cdot M \\cdot p_{\\text{on}} (E_{\\text{spike}} + E_{\\text{syn}} \\cdot p_c) + P_{\\text{leak}} \\cdot T $$\n\n#### 4. Algorithm and Implementation\nThe algorithm iterates through all design parameters. For each candidate design, it calculates its feasibility. If feasible, its energy is calculated and compared against the best design found so far.\n\n1.  Initialize `min_energy = infinity` and `best_design = None`.\n2.  Loop `r` from $1$ to $R_{\\max}$.\n3.  Loop `pc` through $\\{0.25, 0.5, 0.75, 1.0\\}$.\n4.  Loop `theta` from $0$ to $r \\cdot M$.\n5.  Inside the loops, calculate `max_error` by iterating `m1` from $0$ to $M$.\n    a. For each `m1`, determine the parameters $(n_1, p_1)$ and $(n_0, p_0)$ for the two binomial distributions.\n    b. Use `scipy.stats.binom.pmf` to compute the PMFs for $X$ and $Y$.\n    c. Use `numpy.convolve` to get the PMF of their sum $S$.\n    d. Based on the correct label for `m1`, calculate the error probability and update `max_error`.\n6.  If `max_error` $\\le \\varepsilon$:\n    a. Calculate `current_energy` using the formula for $m_1=M$.\n    b. Compare `current_energy` with `min_energy`. If `current_energy` is lower, or if it's equal and the new design wins the tie-break (smaller $r$, then $p_c$, then $\\theta$), update `min_energy` and `best_design`.\n7.  After all loops complete, if `best_design` is still `None`, no feasible solution exists. Otherwise, `best_design` holds the optimal result.\n\nThis systematic approach guarantees finding the optimal design according to the problem's criteria.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import binom\n\ndef solve():\n    \"\"\"\n    Main function to solve all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1\n        {\"M\": 9, \"p_on\": 0.98, \"p_off\": 0.02, \"epsilon\": 1e-4, \"E_spike\": 1.0e-9, \"E_syn\": 2.0e-10, \"P_leak\": 5.0e-9, \"T\": 0.01, \"R_max\": 8},\n        # Case 2\n        {\"M\": 7, \"p_on\": 0.85, \"p_off\": 0.15, \"epsilon\": 1e-3, \"E_spike\": 1.5e-9, \"E_syn\": 3.0e-10, \"P_leak\": 1.0e-8, \"T\": 0.02, \"R_max\": 10},\n        # Case 3\n        {\"M\": 2, \"p_on\": 0.90, \"p_off\": 0.10, \"epsilon\": 1e-3, \"E_spike\": 1.0e-9, \"E_syn\": 1.0e-10, \"P_leak\": 1.0e-9, \"T\": 0.005, \"R_max\": 6},\n        # Case 4\n        {\"M\": 21, \"p_on\": 0.95, \"p_off\": 0.05, \"epsilon\": 5e-4, \"E_spike\": 2.0e-9, \"E_syn\": 2.0e-10, \"P_leak\": 2.0e-8, \"T\": 0.02, \"R_max\": 5},\n    ]\n\n    results = []\n    for case_params in test_cases:\n        result = find_optimal_design(**case_params)\n        results.append(result)\n    \n    # Format the final output string manually to avoid extra spaces.\n    inner_parts = []\n    for res_list in results:\n        inner_str = f\"[{','.join(map(str, res_list))}]\"\n        inner_parts.append(inner_str)\n    final_output = f\"[{','.join(inner_parts)}]\"\n    print(final_output)\n\ndef find_optimal_design(M, p_on, p_off, epsilon, E_spike, E_syn, P_leak, T, R_max):\n    \"\"\"\n    Searches for the optimal design (r, pc, theta) for a single test case.\n    \"\"\"\n    min_energy = float('inf')\n    best_design = None\n    pc_values = [0.25, 0.5, 0.75, 1.0]\n\n    for r in range(1, R_max + 1):\n        for pc in pc_values:\n            # Search space for theta is {0, 1, ..., r*M}\n            for theta in range(r * M + 1):\n                \n                # Step 1: Calculate maximum error for the current design (r, pc, theta)\n                max_error = 0.0\n                for m1 in range(M + 1):\n                    n1 = r * m1\n                    p1 = p_on * pc\n                    \n                    n0 = r * (M - m1)\n                    p0 = p_off * pc\n                    \n                    # PMF for spikes from '1' inputs\n                    pmf_X = binom.pmf(np.arange(n1 + 1), n1, p1)\n                    # PMF for spikes from '0' inputs\n                    pmf_Y = binom.pmf(np.arange(n0 + 1), n0, p0)\n                    \n                    # PMF of total spikes S = X + Y is the convolution of their PMFs\n                    pmf_S = np.convolve(pmf_X, pmf_Y)\n                    \n                    # Cumulative probability P(S  theta)\n                    # Ensure theta does not cause an index out of bounds\n                    cdf_val_at_theta_minus_1 = np.sum(pmf_S[:theta])\n                    \n                    # Strict majority: correct output is 1 if m1  M/2, else 0\n                    correct_label = 1 if m1  M / 2 else 0\n                    \n                    if correct_label == 1:\n                        # Error occurs if circuit outputs 0 (S  theta)\n                        error_m1 = cdf_val_at_theta_minus_1\n                    else: # correct_label == 0\n                        # Error occurs if circuit outputs 1 (S = theta)\n                        error_m1 = 1.0 - cdf_val_at_theta_minus_1\n                        \n                    max_error = max(max_error, error_m1)\n\n                # Step 2: Check if the design is feasible (error = epsilon)\n                if max_error = epsilon:\n                    # Step 3: Compute worst-case energy (m1=M)\n                    energy = r * M * p_on * (E_spike + E_syn * pc) + P_leak * T\n                    \n                    # Step 4: Update best design if energy is lower or tie-breaking rules apply\n                    if energy  min_energy:\n                        min_energy = energy\n                        best_design = [r, pc, theta, energy, max_error]\n                    elif energy == min_energy:\n                        if best_design is not None:\n                            # Tie-breaking rules: smallest r, then smallest pc, then smallest theta\n                            if r  best_design[0]:\n                                best_design = [r, pc, theta, energy, max_error]\n                            elif r == best_design[0] and pc  best_design[1]:\n                                best_design = [r, pc, theta, energy, max_error]\n                            elif r == best_design[0] and pc == best_design[1] and theta  best_design[2]:\n                                best_design = [r, pc, theta, energy, max_error]\n\n    if best_design is None:\n        return [-1, -1, -1, -1.0, -1.0]\n    else:\n        return best_design\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}