## 引言
随着对更大规模、更[高能效人工智能](@entry_id:1124466)的需求日益增长，传统的冯·诺依曼计算架构正面临着“内存墙”和“功耗墙”的严峻挑战。受人脑结构和功能启发的神经形态计算为突破这些瓶颈提供了有希望的途径。然而，要构建能够模拟大脑规模复杂性的系统，就必须将数亿甚至数十亿的神经元和突触集成到单个设备上，这一目标远超出了传统单芯片设计的能力范围。当芯片尺寸扩展到整个硅晶圆时，良率骤降、[互连延迟](@entry_id:1126583)剧增等根本性的物理限制成为了不可逾越的障碍。

本文旨在系统性地解决这一知识鸿沟，深入探讨如何通过晶圆级集成（Wafer-Scale Integration, WSI）和三维（3D）集成这两种前沿技术，来克服大规模集成的挑战，从而实现前所未有规模的类脑计算系统。我们将揭示这些技术背后的科学原理，并展示它们在实际工程中的应用与权衡。

在接下来的内容中，读者将首先在“**原理与机制**”一章中学习到支撑WSI和3D集成的基本物理约束、核心赋能技术以及架构范式。随后，在“**应用与跨学科连接**”一章中，我们将通过一系列实例，展示硬件与算法的协同设计思想如何应用于解决通信、散热、可靠性等系统级难题。最后，在“**动手实践**”部分，读者将有机会通过具体的计算问题，亲身体验和应用这些关键概念。通过这三章的学习，你将对构建未来大规模神经形态系统所需的多学科知识体系建立起一个坚实而全面的理解。

## 原理与机制

在介绍性章节之后，我们现在深入探讨构建晶圆级和三维（3D）神经形态系统所涉及的核心科学原理和工程机制。本章将系统地剖析支撑这些前沿集成技术的基本约束、关键赋能技术、核心架构范式以及重大的系统级工程挑战。我们的目标是建立一个严谨的框架，以理解为何以及如何将计算扩展到整个硅晶圆乃至垂直维度，从而实现前所未有规模的类脑计算。

### 大规模集成的基本动机

将神经形态系统扩展到晶圆尺寸并非仅仅是追求更大的规模，而是源于对传统芯片设计中根本性物理限制的应对。理解这些限制是领悟晶圆级集成（Wafer-Scale Integration, WSI）和三维集成设计理念的关键。

#### 单片集成设计的局限性

在传统的超大规模集成电路（VLSI）设计中，理想的方案是将整个系统集成在单片硅晶圆上，即所谓的**单片系统级芯片（monolithic System-on-Chip, SoC）**。然而，当系统规模增长到晶圆尺寸时，三大物理约束使得这一理想变得不切实际 。

首先是**[光刻](@entry_id:158096)限制**。[半导体制造](@entry_id:187383)中的[光刻](@entry_id:158096)工艺采用“步进-重复”（step-and-repeat）曝光方式。[光刻](@entry_id:158096)机通过一个被称为“掩模版”（reticle）的模板将电[路图](@entry_id:274599)案投影到晶圆上。这个掩模版的尺寸是有限的，通常只能覆盖晶圆的一小部分区域（例如，约 $26 \times 33$ 平方毫米）。因此，单次曝光无法对整个晶圆进行图案化。要制造大于掩模版视场（reticle field）的电路，必须进行多次曝光，并在视场边界处进行精确的拼接。这使得制造一个真正的、无缝的单片晶圆级电路在技术上面临巨大挑战。

其次是**良率约束**。芯片制造过程不可避免地会引入随机缺陷。这些缺陷可以被建模为一个均匀的泊松点过程，其单位面积的[缺陷密度](@entry_id:1123482)为 $D_0$。根据该模型，一个面积为 $A$ 的区域内存在缺陷的概率呈指数增长。具体来说，该区域没有任何关键缺陷的概率，即良率（Yield, $Y$），可以表示为：
$$ Y = \exp(-D_0 A) $$
这个公式揭示了一个严酷的现实：随着芯片面积 $A$ 的增大，其无缺陷的概率会呈指数级快速下降。对于一个掩模版大小的SoC，其良率可能已经是一个挑战（例如，50%）。而对于一个面积是其100倍的晶圆级芯片，其单片良率将是 $(0.5)^{100}$，一个几乎为零的数字。这种“面积的暴政”（tyranny of area）使得制造无缺陷的、单片晶圆大小的芯片在经济上和实践上都不可行。

最后是**互连约束**。随着芯片尺寸的增大，全局互连线的长度 $L$ 也随之增加。对于一根片上金属导线，其电阻 $R$ 和电容 $C$ 近似地与长度 $L$ 成正比（即 $R \propto L$，$C \propto L$）。信号在导线上传播的延迟关键取决于其电阻-电容（RC）时间常数 $\tau$。对于分布式RC线，其时间常数与总电阻和总电容的乘积成正比，因此：
$$ \tau \propto R \cdot C \propto L \cdot L = L^2 $$
信号延迟随导线长度的**超线性（superlinear）**增长（二次方关系）意味着，在大面积芯片上，跨越整个芯片的全局通信会变得极其缓慢且耗能。对于需要低延迟、高扇出通信的神经形态系统而言，这是一个致命的瓶颈。

#### 解决方案：晶圆级与三维集成

为克服上述限制，业界发展出了更为复杂的集成策略。一种是**多芯片组件（Multi-Chip Module, MCM）**，它将多个独立制造并测试好的小芯片（称为“裸片”或die）封装在一个共享的基板上，通过基板上的高密度布线实现互连。MCM通过筛选“已知合格裸片”（Known Good Dies, KGD）来保证系统级的整体良率。

**晶圆级集成（Wafer-Scale Integration, WSI）**则采取了另一种更高集成度的路径。它不是将晶圆切割成独立的芯片，而是在未切割的整片晶圆上构建一个完整的系统。为了规避良率灾难，WSI系统被设计成一个由许多较小的、可在掩模版范围内制造的重复单元（称为“瓦片”或tile）组成的阵列。这些瓦片通过专门设计的片上[互连网络](@entry_id:750720)连接起来。至关重要的是，WSI系统内置了**架构冗余（architectural redundancy）**和重构机制。系统可以检测并绕过有缺陷的瓦片，从而使得系统良率不再是所有瓦片良率的简单乘积，而是取决于冗余度和重构能力的组合函数，从而在晶圆尺度上实现了可接受的整体良率 。

**三维（3D）集成**则通过在垂直维度上堆叠多个硅片或裸片来解决互连问题。这种方法可以极大地缩短必须在二维平面上迂回布设的长导线的物理距离，从而有效降低通信延迟和功耗。然而，3D集成也引入了新的挑战，如散热和跨层良率的复合效应。

### 大规模集成的赋能技术

实现晶圆级和三维神经形态系统，依赖于一系列先进的制造与集成技术。这些技术直接解决了跨越掩模版边界的连接问题和进入第三维度的互连问题。

#### 平面互连：掩模版拼接的艺术

如前所述，WSI的核心挑战之一是如何在相邻的掩模版[视场](@entry_id:175690)之间建立连续的互连。这一过程称为**掩模版拼接（reticle stitching）**。在实践中，主要有两种设计策略来处理拼接边界 。

**光学拼接（Optical Stitching）** 试图在光刻层面实现几何上的无缝连接。设计师在相邻掩模版的边界处对齐图案，有时会故意留下一个微小的间隙，并依赖光学邻近效应（如[光的衍射](@entry_id:178265)和散射）以及[光刻胶](@entry_id:159022)的化学特性来“桥接”这个间隙，形成连续的导线。这种方法对[光刻](@entry_id:158096)工艺的控制精度和曝光场之间的**套刻精度（overlay accuracy）**要求极高。任何微小的套刻误差或剂量波动都可能导致连接处的导线变窄（“[颈缩](@entry_id:183657)”，necking）甚至断开（open circuit）。

**电气搭接（Electrical Abutment）** 则是一种更为稳健的策略。它不追求完美的几何连续性，而是以保证电气连接为首要目标。在这种设计中，来自相邻[视场](@entry_id:175690)的导线末端被设计成较大的“接触焊盘”（landing pads），并且这些焊盘在设计上有一定的重叠区域。只要两个视场之间的套刻误差小于设计的重叠裕量，两个焊盘就能可靠地物理接触，从而保证电气导通。这种方法对套刻误差的容忍度更高，但代价是占用更大的芯片面积，并且增大了的焊盘结构也可能捕获更多的随机缺陷。

为了定量理解这两种策略的可靠性，我们可以考虑一个统计模型。假设两个视场间的套刻误差是一个随机向量 $\boldsymbol{\Delta} = (\Delta_x, \Delta_y)$，其中分量是独立的零均值高斯[随机变量](@entry_id:195330)。对于光学拼接，要形成连接，纵[向错](@entry_id:161223)位 $|\Delta_x|$ 必须小于工艺能桥接的最大间隙 $\delta_x$。而对于电气搭接，则要求 $|\Delta_x|$ 小于设计的重叠裕量 $m$。在一个具体案例中 ，假设 $\delta_x = 20\,\mathrm{nm}$，而 $m = 400\,\mathrm{nm}$，且纵向套刻误差的标准差为 $\sigma_x = 25\,\mathrm{nm}$，电气搭接提供的[容错](@entry_id:142190)窗口远大于光学拼接，其连接成功的概率也从约 $0.59$ 提升至接近 $1.00$。这清晰地展示了通过设计（增加重叠焊盘）来换取制造鲁棒性的基本思想。

#### 垂直互连：进入第三维度

3D集成技术的核心是提供高密度、低延迟的垂直互连，将堆叠的芯片或晶圆连接成一个整体。主要技术包括硅通孔（TSV）、微凸点和混合键合 。

**硅通孔（Through-Silicon Via, TSV）** 是穿透整个硅衬底的[金属化](@entry_id:1127829)垂直通道。它像电梯一样，将芯片正面的信号直接传送到背面，从而连接到[上层](@entry_id:198114)或下层的芯片。TSV能够提供比传统封装级互连（如引线键合）短得多、密度高得多的连接。然而，由于其结构较长（例如，$50\,\mu\text{m}$），且被二氧化硅绝缘层包裹并嵌入硅衬底中，TSV表现出显著的[寄生电容](@entry_id:270891)，这会影响[信号速度](@entry_id:261601)和功耗。同时，它的导热路径也相对较长。

**微凸点（Micro-bump）** 是用于连接堆叠芯片的微小焊料球。它们被放置在每个芯片的连接焊盘上，通过加热回流形成冶金连接。芯片间的空隙通常由聚合物底部填充剂（underfill）填充以提供机械支撑。微凸点的[电阻率](@entry_id:143840)比铜高，且其周围的聚合物导热性极差，这使得其电气和热性能并非最优。

**混合键合（Hybrid Bonding）** 是目前最先进的3D互连技术。它在低温下将一片晶圆上的铜焊盘直接与另一片晶圆上的铜焊盘进行原子级别的键合。与此同时，焊盘周围的介电材料（如二氧化硅）也直接键合在一起，形成一个无缝、无间隙的界面，无需任何底部填充剂。

通过定量比较可以更清晰地看出三者的优劣 。以典型参数计算，单个垂直连接的电阻，混合键合（约 $1.1\,\text{m}\Omega$）远低于微凸点（约 $9.5\,\text{m}\Omega$）和TSV（约 $43\,\text{m}\Omega$）。同样，由于其极短的长度和紧凑的结构，混合键合的[寄生电容](@entry_id:270891)也是最低的。在导热性方面，混合键合的全铜路径提供了最低的热阻（约 $156\,\text{K/W}$），而微凸点（约 $1274\,\text{K/W}$）和TSV（约 $6378\,\text{K/W}$）的导热能力则相形见绌。最关键的是，混合键合技术支持的互连**间距（pitch）**可以达到微米甚至亚微米级别（例如，$p_{\text{hybrid}} \approx 5\,\mu\text{m}$），远比微凸点（$p_{\text{bump}} \approx 25\,\mu\text{m}$）和TSV（$p_{\text{TSV}} \approx 40\,\mu\text{m}$）更精细。这使得混合键合成为实现高密度三维神经形态集成的理想选择，因为它提供了最佳的电气、热学性能和最高的集成密度。

### 架构原理与范式

在坚实的硬件集成基础上，我们需要合适的计算和通信架构来有效利用这些资源。对于模拟大脑稀疏、事件驱动活动的神经形态系统尤其如此。

#### 神经形态通信范式：AER与NoW

神经形态系统中的通信以“脉冲”（spike）或“事件”（event）的形式发生。如何高效地在大量神经元之间传递这些事件，是[系统设计](@entry_id:755777)的核心问题。两种主流范式是地址事件表示（AER）和[片上网络](@entry_id:1128532)（NoW） 。

**地址事件表示（Address-Event Representation, AER）** 是一种极简的、受生物启发的通信协议。当一个神经元发放脉冲时，它将其唯一的**地址（address）**广播到一个共享的通信总线上。系统中的所有其他神经元（或神经元集群）都会监听这条总线。当一个地址出现时，那些以该地址神经元为突触前输入的目标神经元就会被激活。AER的核心思想是只传递事件的来源信息（“谁”发放了脉冲），而所有其他信息（如突触权重）都存储在接收端本地。通信通过简单的**请求-应答（request-acknowledge）**[异步握手协议](@entry_id:169056)来协调。在脉冲活动稀疏（即总线利用率 $\rho \ll 1$）的情况下，AER的排队延迟可以忽略不计，其延迟主要由[总线仲裁](@entry_id:173168)和信号在物理导线上的传播时间决定。其能耗主要用于驱动大电容的全局总线。

**分组交换片上网络（Packetized Network-on-Wafer, NoW）** 则采用了源于通用计算机网络的思想。每个脉冲事件被封装成一个**数据包（packet）**，包含目的地址、源地址以及可选的[元数据](@entry_id:275500)（如精确的时间戳）等信息。这些数据包通过一个由点对点链路和路由器组成的网络进行路由。数据包在网络中逐跳（hop-by-hop）传递，每一跳都会产生一定的处理和序列化延迟。NoW的延迟与数据包在网络中经过的跳数成正比，并且会随着网络负载的增加而因排队产生非线性增长。NoW的优势在于其出色的**[可扩展性](@entry_id:636611)（scalability）**。通过分布式路由，它避免了AER[共享总线](@entry_id:177993)的单一瓶颈，网络总带宽可以随着核心数量的增加而增加。

3D集成对这两种范式的影响也不同。对于AER，3D堆叠可以缩短全局总线的物理长度，从而降低[RC延迟](@entry_id:262267)和开关能耗，但其固有的仲裁瓶颈依然存在。对于NoW，3D集成则带来了拓扑上的优势：TSV可以作为垂直链路，极大地减少了层间通信的跳数，从而直接降低了延迟和能耗，进一步增强了其[可扩展性](@entry_id:636611) 。

#### 系统[可扩展性分析](@entry_id:266456)

评估一个大规模[并行系统](@entry_id:271105)的性能，离不开对可扩展性的形式化分析。

**连通性的扩展：[Rent法则](@entry_id:1130866)**
一个强大的经验模型是**[Rent法则](@entry_id:1130866)（Rent's rule）**，它描述了一个电路模块的引脚数 $T$ 与其内部组件数 $N$ 之间的幂律关系：
$$ T = k N^p $$
其中，$k$ 是Rent系数，反映了组件的平均引脚数；$p$ 是Rent指数（$0 < p < 1$），反映了布线的复杂性或通信的局部性。$p$ 值接近1表示全局通信占主导，而 $p$ 值较小则表示通信高度局部化。

我们可以运用[Rent法则](@entry_id:1130866)来分析WSI中的**布线拥塞（congestion）**问题 。考虑一个由许多瓦片拼接而成的系统，拥塞程度可以定义为瓦片边界上所需的连接数（需求）与边界上可用的布线资源（供给）之比。在一个二维方形瓦片系统中，瓦片面积与 $N$ 成正比，因此其边界长度（供给）与 $N^{1/2}$ 成正比。单位长度的布线需求（拥塞）则与 $\frac{T}{N^{1/2}} = \frac{kN^p}{N^{1/2}} = kN^{p-1/2}$ 成正比。这意味着，如果一个系统的Rent指数 $p > 1/2$，那么随着瓦片尺寸 $N$ 的增大，边界上的布线拥塞会恶化。这为**分层布线（hierarchical routing）**的必要性提供了理论依据。通过精心设计的分层架构，可以有效降低高层分区的Rent指数，从而控制长程布线的增长，避免拥塞。同样，在三维系统中，供给与 $N^{2/3}$ 成正比，拥塞是否恶化的[临界点](@entry_id:144653)则提高到 $p > 2/3$。如果架构设计能实现高度的通信局部性，使得外部连接的Rent指数 $p_{\text{ext}} < 1/2$（对于2D），那么拥塞会随规模增大而减小，简单的平面全局布线就可能足够了 。

**吞吐率的扩展：[Amdahl定律](@entry_id:137397)与Gustafson定律**
除了连通性，我们还关心系统的计算吞吐率如何随处理器核心数 $N$ 扩展。这通常通过**Amdahl定律**（固定问题规模）和**Gustafson定律**（扩展问题规模）来分析。在神经形态系统中，一个关键的复杂性在于，系统的非并行部分（串行瓶颈）并非一个固定的常数，而是会随着核心数 $N$ 的增加而变化，因为[通信开销](@entry_id:636355)会增加。一个更真实的模型可以表示为 $f_s(N) = f_0 + \alpha(1 - 1/N)$，其中 $f_0$ 是固定的串行开销（如主控制器），而 $\alpha$ 项则代表了随 $N$ 增加而增长的通信和仲裁开销 。

在这种模型下，[Amdahl定律](@entry_id:137397)预测的加速比为 $S_A(N) = \frac{1}{f_s(N) + (1-f_s(N))/N}$。由于 $f_s(N)$ 随着 $N$ 增大而增大，加速比会很快饱和。例如，在一个具有 $f_0=0.05$ 和 $\alpha=0.20$ 的平面WSI系统中，当 $N=256$ 时，加速比仅为约 $3.97\times$。而Gustafson定律预测的加速比为 $S_G(N) = f_s(N) + N(1-f_s(N))$。对于同样的系统，当 $N=256$ 时，加速比可达约 $192.45\times$。这个例子清晰地表明，WSI系统更适合于解决随硬件规模同步扩大的问题（[弱扩展性](@entry_id:167061)）。此外，它还量化了3D集成的优势：通过降低平均通信距离，3D集成可以减小 $\alpha$ 值（例如，从 $0.20$ 降至 $0.10$），从而在Amdahl和Gustafson两种情况下都获得更高的加速比（分别提升至 $6.54\times$ 和 $217.85\times$）。

### 核心组件与物理实现

大规模集成架构的性能最终取决于其基[本构建模](@entry_id:183370)块——神经元和突触——的物理实现。

#### 神经元电路：[亚阈值CMOS](@entry_id:1132622)设计

为了在模拟生物神经元极低能耗的同时实现大规模集成，神经形态工程师们常常采用工作在**亚阈值（subthreshold）**区的[CMOS晶体管](@entry_id:1122544)来构建神经元电路 。当晶体管的栅极电压低于其阈值电压时，它仍然会传导一个微小的漏电流，该电流与栅极电压呈指数关系。这种指数特性非常适合模拟生物[离子通道](@entry_id:170762)的电压依赖性电导，并且由于工作电流极低（纳安甚至皮安级别），功耗也极低。

这种设计有利有弊。优点是**高可调性**：由于指数关系，微小的偏置电压变化可以使电流（进而影响神经元的时间常数等）跨越数个数量级变化。缺点是**高敏感性**：同样的指数关系也放大了制造过程中不可避免的[器件失配](@entry_id:1123618)（mismatch）和温度变化的影响。温度变化会改变热电压 $U_T=kT/q$，直接影响电流大小。在3D堆叠中，由于层间散热不均，会产生显著的温度梯度，导致不同位置的神经元行为出现显著差异。因此，必须设计**补偿电路**，在每个区域或每层根据局部温度动态调整偏置电压，以维持系统行为的一致性 。

在电路实现上，简单的**漏积分-发放（Leaky Integrate-and-Fire, LIF）**神经元模型可以通过一个电容、一个漏电晶体管和一个比较器简洁地实现。而更复杂的**基于电导（conductance-based）**的模型（如Hodgkin-Huxley类型）则需要更复杂的电路来模拟多种电压依赖的[离子通道](@entry_id:170762)和不同的反转电位，因此具有更丰富的动力学行为和更高的参数可调性，但代价是更大的面积和更高的功耗。

#### 突触器件：新兴非易失性存储器

突触是神经形态系统的核心，其权重存储的密度和效率至关重要。新兴的非易失性存储器，特别是两端**[忆阻器](@entry_id:204379)件（memristive devices）**，为实现高密度、低功耗的片上突触阵列提供了希望。广义上，[忆阻器](@entry_id:204379)是指任何其电阻（或电导）依赖于其过去流经电荷或磁通历史的二端器件。其中，两种主要的技术路线是相变存储器（PCM）和阻变存储器（RRAM）。

**相变存储器（Phase-Change Memory, PCM）** 利用硫族化合物（如GST）在[晶态](@entry_id:193348)（低电阻）和非晶态（高电阻）之间的相变来存储信息。通过施加不同幅度和时长的电流脉冲，利用[焦耳热](@entry_id:150496)可以实现相变：高功率短脉冲实现“熔化-淬火”过程，形成非晶态（RESET）；低功率长脉冲则实现退火过程，形成晶态（SET）。通过控制非晶区的体积，可以实现多级电导值。PCM的主要缺点是编程能耗较高（例如，约 $20\,\text{pJ}$），且非晶态的电导会随时间**漂移（drift）**，即电导值会自发地缓慢下降，给长期权重存储带来挑战。

**阻变存储器（Resistive RAM, RRAM）** 则依赖于在绝缘氧化物（如HfO$_2$）中导电细丝（conductive filament）的形成和断裂来改变电阻状态。在外加电场驱动下，[氧空位](@entry_id:203783)等离子的迁移和[氧化还原反应](@entry_id:141625)可以形成或断裂这些细丝。RRAM的编程能耗通常远低于PCM（例如，约 $1\,\text{pJ}$），但其开关过程具有显著的**随机性（stochasticity）**，导致每次编程后的电导值都有较大的周期性涨落和器件间差异。

在3D集成背景下，器件的功耗和热特性变得尤为重要。一个包含 $2048 \times 2048$ 突触的PCM阵列，即使只有 $1\%$ 的突触在 $1\,\text{ms}$ 内进行一次更新，其产生的功率也足以使该层温升近 $1\,\text{K}$。在深层堆叠中，热量会逐层累积，导致严重的热问题。相比之下，能耗低20倍的RRAM产生的温升则微不足道。因此，尽管RRAM存在高变异性的问题（需要通过电路或算法层面进行补偿），但其优越的热学特性使其成为高密度3D神经形态集成的更有吸[引力](@entry_id:189550)的候选者 。

### 系统级工程挑战与解决方案

将所有组件集成为一个功能完备的晶圆级系统，还需应对两个关键的工程挑战：为整个系统稳定供电，以及确保系统在存在制造缺陷的情况下仍能工作。

#### 供电网络（PDN）设计

一个晶圆级系统可能需要数百安培的电流，而供电电压却低于1伏。如何在如此大的面积上以极低的[电压降](@entry_id:263648)（IR drop）分配如此大的电流，是一个巨大的挑战 。

一种简单的策略是从晶圆周边通过少数几个电源输入点进行**集中式供电**。然而，简单的计算表明这种方法是行不通的。例如，一个需要 $100\,\text{A}$ 电流的系统，即使通过4个输入点分流，每个电源主干也需要承载 $25\,\text{A}$ 的电流。在长达数厘米的片上导线上，即使导线[截面](@entry_id:154995)积已经相当大，其电阻导致的[电压降](@entry_id:263648)也可能高达1伏以上，这远远超过了通常允许的几十毫伏的预算，会导致芯片内部完全无法正常工作。尽管电流密度可能仍在[电迁移](@entry_id:141380)（electromigration）安全限制之内，但[电压降](@entry_id:263648)是决定性的失败因素。

因此，**分布式供电**成为必然选择。通过3D集成技术，我们可以在晶圆背面制作电源平面，并通过成百上千个TSV将电源“垂直”地输送到晶圆正面的各个区域。这种方法将长距离、大电流的分配问题，转化为了许多短距离、小电流的[分配问题](@entry_id:174209)。每个TSV及其局部网络只需服务一小片区域，其路径长度和电流都大大减小，从而将[电压降](@entry_id:263648)控制在允许范围内。当然，这种高密度的分布式PDN并非没有代价。它需要占用大量的顶层金属布线资源和宝贵的TSV通孔，这与信号线布线形成了[资源竞争](@entry_id:191325)，即**PDN粒度（granularity）**与**布线拥塞（routing congestion）**之间的权衡。设计者必须在供电质量和信号布线资源之间做出审慎的平衡。

#### 良率与可靠性：架构冗余

我们再次回到良率问题。即使采用了基于瓦片的WSI设计，单个瓦片内部或瓦片间的连接仍然可能出现缺陷。为了使整个晶圆级系统能够工作，必须引入**架构冗余（architectural redundancy）** 。这指的是在设计中有意加入额外的硬件资源和重构机制，以便在出现故障时能够替代或绕过失效的组件。

冗余策略的设计遵循一个核心原则：**修复机制的粒度应与故障模式的粒度相匹配**，以实现最高的效率。
-   对于**细粒度**的故障，如存储器阵列中的单个坏点（cell defect）或整行/整列失效（line fault），最有效的冗余是**备用行/列（spare rows/columns）**。通过简单的地址重映射，就可以用备用的好行/列替换掉有缺陷的行/列，成本低廉。
-   对于**中等粒度**的故障，如由[光刻](@entry_id:158096)缺陷导致的一整块（例如 $B \times B$ 大小）连续区域失效（clustered defect），使用行/列冗余来修复会非常浪费。此时，**块级备用（block-level sparing）**更为高效。系统可以禁用整个损坏的块，并启用一个备用的完好块来替代其功能。
-   对于**网络级**的故障，如连接瓦片的NoW链路或TSV失效（link/TSV fault），修复的方法是**动态重路由（dynamic rerouting）**。[网络路由](@entry_id:272982)器被设计成可以检测到失效的链路，并智能地选择另一条替代路径来发送数据包。这种方法利用了网络拓扑中固有的路径多样性来维持端到端的连通性，而无需增加额外的计算或存储备用资源。

通过这套从细到粗、覆盖不同层级的多层次冗余策略，WSI系统才能够克服制造过程中不可避免的缺陷，实现可接受的生产良率，并能在工作过程中容忍部分瞬态故障，最终将晶圆级的计算潜力转化为现实。