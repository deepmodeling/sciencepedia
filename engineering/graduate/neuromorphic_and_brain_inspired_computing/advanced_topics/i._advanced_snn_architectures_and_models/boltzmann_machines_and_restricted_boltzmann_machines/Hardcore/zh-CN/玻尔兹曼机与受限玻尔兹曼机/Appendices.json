{
    "hands_on_practices": [
        {
            "introduction": "理论与实践的第一步是深刻理解模型的基本构成。本练习将引导你剖析一个全连接玻尔兹曼机的核心参数结构 ()。通过推导，你将揭示为何权重矩阵的对称性和零对角线约束在不牺牲模型表达能力的前提下是合理的，并学会精确计算模型的独立参数数量，为后续理解模型容量和复杂度奠定坚实基础。",
            "id": "4038503",
            "problem": "考虑一个全连接玻尔兹曼机，它有 $n$ 个二元单元 $x_{i} \\in \\{0,1\\}$，成对相互作用权重由一个实数矩阵 $W \\in \\mathbb{R}^{n \\times n}$ 给出，偏置为 $b \\in \\mathbb{R}^{n}$。一个状态 $x \\in \\{0,1\\}^{n}$ 的概率由玻尔兹曼分布 $p(x) \\propto \\exp\\!\\big(-E(x)\\big)$ 给出，其中 $E(x)$ 是一个由成对相互作用和偏置导出的能量函数。假设只存在成对相互作用和单元偏置（没有高阶项）。施加物理一致性要求，即成对耦合能量对单元索引的重新标记是不变的，并且排除那些无法从状态空间中辨识的自相互作用项。\n\n仅使用这些基本假设，确定当强制 $W$ 为对称且对角线为零时，模型中独立参数的数量。明确计算独立的相互作用权重和独立的偏置数量，并给出一个关于 $n$ 的总独立参数数量的单一闭式表达式。在你的推理中，解释为什么施加 $W = W^{\\top}$ 和 $\\operatorname{diag}(W)=0$ 的约束，相对于允许任意实数 $W$ 和 $b$ 的情况，不会减少模型的表达族。\n\n以关于 $n$ 的单一闭式解析表达式的形式提供最终答案。不需要进行数值代入，也不需要四舍五入。",
            "solution": "该问题要求计算一个具有 $n$ 个二元单元的全连接玻尔兹曼机中独立参数的总数，其约束条件是权重矩阵 $W$ 对称且对角线为零。问题还要求解释为什么这些约束不会降低模型的表达能力。\n\n设系统的状态为一个向量 $x \\in \\{0, 1\\}^n$，其中每个单元 $x_i$（$i \\in \\{1, 2, \\dots, n\\}$）是一个二元变量，即 $x_i \\in \\{0, 1\\}$。对于一个只有成对相互作用和单元偏置的模型，其最通用的能量函数 $E'(x)$ 可以用一个通用的实值权重矩阵 $W' \\in \\mathbb{R}^{n \\times n}$ 和一个偏置向量 $b' \\in \\mathbb{R}^n$ 来表示。该能量由下式给出：\n$$E'(x) = - \\sum_{i=1}^n \\sum_{j=1}^n x_i W'_{ij} x_j - \\sum_{i=1}^n b'_i x_i$$\n一个状态 $x$ 的概率则由玻尔兹曼分布 $p(x) = \\frac{1}{Z} \\exp(-E(x))$ 给出，其中 $Z$ 是配分函数。由于 $p(x)$ 对 $E(x)$ 的依赖仅通过指数函数，任何两个对于所有状态 $x$ 仅相差一个常数偏移的能量函数都将产生相同的概率分布。此外，能量函数中任何可以在不改变任何状态 $x$ 的能量值的情况下被合并或消除的参数都不是独立的。我们现在将证明，一个由 $(W', b')$ 定义的任意模型都可以被重参数化为一个等价模型 $(W, b)$，其中 $W$ 是对称的（$W=W^\\top$）且对角线为零（$\\operatorname{diag}(W)=0$），而不会损失任何表达能力。\n\n首先，我们来分析权重矩阵 $W'$ 的对角项。我们可以将能量函数中的双重求和分解为对角部分和非对角部分：\n$$\\sum_{i=1}^n \\sum_{j=1}^n x_i W'_{ij} x_j = \\sum_{i \\neq j} x_i W'_{ij} x_j + \\sum_{i=1}^n x_i W'_{ii} x_i$$\n二元单元 $x_i \\in \\{0, 1\\}$ 的一个关键性质是 $x_i^2 = x_i$。将此性质应用于对角线求和，我们得到：\n$$\\sum_{i=1}^n x_i W'_{ii} x_i = \\sum_{i=1}^n W'_{ii} x_i^2 = \\sum_{i=1}^n W'_{ii} x_i$$\n将此代回 $E'(x)$ 的表达式中：\n$$E'(x) = - \\sum_{i \\neq j} x_i W'_{ij} x_j - \\sum_{i=1}^n W'_{ii} x_i - \\sum_{i=1}^n b'_i x_i$$\n我们可以合并这两个线性项：\n$$E'(x) = - \\sum_{i \\neq j} x_i W'_{ij} x_j - \\sum_{i=1}^n (b'_i + W'_{ii}) x_i$$\n这表明对角权重 $W'_{ii}$ 的效应与偏置 $b'_i$ 的效应是无法区分的。这些项不能被单独辨识。因此，我们可以定义一组新的参数：一个对角线为零的权重矩阵 $W''$ 和一个新的偏置向量 $b$。令 $W''_{ij} = W'_{ij}$（当 $i \\neq j$ 时），$W''_{ii} = 0$，以及 $b_i = b'_i + W'_{ii}$。对于每个状态 $x$，能量函数保持不变：\n$$E(x) = - \\sum_{i \\neq j} x_i W''_{ij} x_j - \\sum_{i=1}^n b_i x_i$$\n因此，我们可以施加 $\\operatorname{diag}(W) = 0$ 的约束，而不失一般性或降低模型的表达能力。这对应于问题中陈述的排除“无法从状态空间中辨识的自相互作用项”的要求。\n\n接下来，我们来处理权重矩阵的对称性问题。考虑非对角求和项 $\\sum_{i \\neq j} x_i W''_{ij} x_j$。由于索引 $i$ 和 $j$ 在乘积 $x_i x_j$ 中是对称的（即 $x_i x_j = x_j x_i$），我们可以将每个索引对 $(i, j)$（其中 $i \\neq j$）的项组合起来：\n$$x_i W''_{ij} x_j + x_j W''_{ji} x_i = (W''_{ij} + W''_{ji}) x_i x_j$$\n这表明能量函数仅依赖于和 $W''_{ij} + W''_{ji}$，而不依赖于 $W''_{ij}$ 和 $W''_{ji}$ 的单个值。我们可以定义一个新的对称权重矩阵 $W$，方法是将其元素设置为 $W''$ 及其转置中相应元素的平均值：\n$$W_{ij} = \\frac{W''_{ij} + W''_{ji}}{2}$$\n对于这个新的矩阵 $W$，我们有 $W_{ij} = W_{ji}$，所以它是对称的。并且，由于 $W''_{ii} = 0$，由此可知 $W_{ii} = \\frac{W''_{ii} + W''_{ii}}{2} = 0$，所以 $W$ 的对角线也为零。使用新矩阵 $W$ 时，对 $(i, j)$ 的能量分量是：\n$$\\sum_{k,l \\in \\{i,j\\}, k \\neq l} x_k W_{kl} x_l = x_i W_{ij} x_j + x_j W_{ji} x_i = 2 W_{ij} x_i x_j = (W''_{ij} + W''_{ji}) x_i x_j$$\n这与原始贡献完全相同。因此，用对称矩阵 $W$ 替换可能非对称的矩阵 $W''$ 不会改变任何状态 $x$ 的能量函数。这证明了施加约束 $W = W^\\top$ 的合理性。这也符合物理直觉，即两个单元之间的耦合能量应该由单个参数来描述。\n\n在证明了对称权重矩阵和零对角线的约束不会减少可表示的概率分布族之后，我们现在可以计算这种模型中独立参数的数量了。\n\n1.  **独立的相互作用权重：** 参数是 $n \\times n$ 矩阵 $W$ 的元素。约束 $\\operatorname{diag}(W) = 0$ 意味着所有 $n$ 个对角元素都固定为 $0$，不是自由参数。对称性约束 $W = W^\\top$ 意味着对于所有 $i, j$ 都有 $W_{ij} = W_{ji}$。因此，我们只需要指定矩阵上三角（或下三角）中的元素，因为其他元素随之确定。严格上三角（即 $i  j$）中的元素数量对应于从 $n$ 个索引中选择 $2$ 个不同索引的方式数，这由二项式系数 $\\binom{n}{2}$ 给出。\n    独立权重数 = $\\binom{n}{2} = \\frac{n(n-1)}{2}$。\n\n2.  **独立的偏置：** 偏置参数是向量 $b \\in \\mathbb{R}^n$ 的分量。$n$ 个单元中的每一个都有一个偏置参数 $b_i$。这些都是独立的。\n    独立偏置数 = $n$。\n\n3.  **独立参数总数：** 模型中独立参数的总数是独立权重数和独立偏置数的总和。\n    总参数 = (独立权重数) + (独立偏置数)\n    $$N_{\\text{params}} = \\frac{n(n-1)}{2} + n$$\n    化简此表达式：\n    $$N_{\\text{params}} = \\frac{n^2 - n}{2} + \\frac{2n}{2} = \\frac{n^2 - n + 2n}{2} = \\frac{n^2 + n}{2}$$\n    这可以写成一个更紧凑的闭式形式：\n    $$N_{\\text{params}} = \\frac{n(n+1)}{2}$$\n\n这个表达式表示了指定一个具有 $n$ 个二元单元和成对相互作用的通用玻尔兹曼机所需的自由参数总数。",
            "answer": "$$\n\\boxed{\\frac{n(n+1)}{2}}\n$$"
        },
        {
            "introduction": "从广义玻尔兹曼机过渡到更具实用性的受限玻尔兹曼机（RBM），其核心优势在于其独特的条件独立性。本练习通过一个微型RBM的具体算例，让你亲手验证这一关键特性 ()。通过枚举所有可能状态并计算其概率，你将直观地理解RBM的二分图结构如何简化了计算，并为高效的Gibbs采样等算法提供理论依据。",
            "id": "4038508",
            "problem": "考虑一个具有 $n_v=2$ 个可见单元和 $n_h=2$ 个隐藏单元的二值受限玻尔兹曼机 (RBM)。可见单元为 $v=(v_1,v_2)\\in\\{0,1\\}^2$，隐藏单元为 $h=(h_1,h_2)\\in\\{0,1\\}^2$，能量函数定义为\n$$\nE(v,h)=-\\sum_{i=1}^{2} a_i v_i-\\sum_{j=1}^{2} b_j h_j-\\sum_{i=1}^{2}\\sum_{j=1}^{2} v_i W_{ij} h_j.\n$$\n$(v,h)$ 上的联合分布由玻尔兹曼分布 $P(v,h)=\\exp(-E(v,h))/Z$ 给出，其中 $Z$ 是配分函数。\n\n设参数为\n$$\na=\\begin{pmatrix}0.3\\\\-0.1\\end{pmatrix},\\quad b=\\begin{pmatrix}0.2\\\\0.4\\end{pmatrix},\\quad W=\\begin{pmatrix}0.7  -0.5\\\\ -0.3  0.6\\end{pmatrix}.\n$$\n\n任务：\n1. 从玻尔兹曼分布和给定的能量函数出发，为任意的 $v\\in\\{0,1\\}^2$ 推导出条件分布 $P(h\\mid v)$ 的显式表达式，不预先假设任何特殊的因子分解形式。\n2. 仅使用能量函数中编码的二分图结构，从第一性原理证明在给定 $v$ 的条件下隐藏单元是条件独立的，并确定所得伯努利乘积形式的参数化。\n3. 枚举所有 $16$ 种配置 $(v,h)\\in\\{0,1\\}^2\\times\\{0,1\\}^2$ 并计算相应的能量 $E(v,h)$ 和未归一化的权重 $\\exp(-E(v,h))$。对于每个固定的 $v$，对四个隐藏状态 $h$ 进行显式归一化以获得 $P(h\\mid v)$，并验证其与任务 2 中得到的伯努利乘积形式相等。\n4. 对于特定的可见配置 $v=(1,0)$，计算 $P(h_1=1\\mid v)$ 的精确值。\n\n以指数函数的形式报告 $P(h_1=1\\mid v=(1,0))$ 的精确表达式作为你的最终答案。不要进行数值近似。无需单位。",
            "solution": "首先根据指定标准验证问题陈述。\n\n**问题验证**\n\n1.  **提取已知条件**：\n    -   一个具有 $n_v=2$ 个可见单元 $v=(v_1,v_2)\\in\\{0,1\\}^2$ 和 $n_h=2$ 个隐藏单元 $h=(h_1,h_2)\\in\\{0,1\\}^2$ 的受限玻尔兹曼机 (RBM)。\n    -   能量函数：$E(v,h)=-\\sum_{i=1}^{2} a_i v_i-\\sum_{j=1}^{2} b_j h_j-\\sum_{i=1}^{2}\\sum_{j=1}^{2} v_i W_{ij} h_j$。\n    -   联合分布：$P(v,h)=\\exp(-E(v,h))/Z$。\n    -   参数：$a=\\begin{pmatrix}0.3\\\\-0.1\\end{pmatrix}$, $b=\\begin{pmatrix}0.2\\\\0.4\\end{pmatrix}$, $W=\\begin{pmatrix}0.7  -0.5\\\\ -0.3  0.6\\end{pmatrix}$。\n    -   任务是推导 $P(h\\mid v)$，证明隐藏单元的条件独立性，通过枚举所有 16 个状态来验证此属性，并计算一个特定的条件概率。\n\n2.  **使用提取的已知条件进行验证**：\n    -   **科学依据**：该问题是 RBM 理论中的一个标准练习，RBM 理论是机器学习和计算神经科学的核心课题。其定义和模型都是标准的。\n    -   **良定性**：该问题已完全指定，包含所有必要的参数和定义。每个任务都陈述清晰，并能导出一个唯一的、可验证的解。\n    -   **客观性**：该问题使用精确的数学语言表达，不包含任何主观或模棱两可的陈述。\n    -   有效问题的所有其他标准均已满足。没有矛盾、缺失数据或不切实际的假设。\n\n3.  **结论与行动**：该问题被视为有效。将提供完整的解答。\n\n**解答**\n\n**任务1：推导条件分布 $P(h\\mid v)$**\n\n条件分布 $P(h\\mid v)$ 定义为 $P(h\\mid v) = \\frac{P(v,h)}{P(v)}$。联合概率为 $P(v,h) = \\frac{1}{Z}\\exp(-E(v,h))$，可见单元的边缘概率为 $P(v) = \\sum_{h'} P(v,h') = \\frac{1}{Z}\\sum_{h'} \\exp(-E(v,h'))$。\n将这些代入定义中可得：\n$$\nP(h\\mid v) = \\frac{\\frac{1}{Z}\\exp(-E(v,h))}{\\frac{1}{Z}\\sum_{h'} \\exp(-E(v,h'))} = \\frac{\\exp(-E(v,h))}{\\sum_{h'} \\exp(-E(v,h'))}\n$$\n能量函数为 $E(v,h) = -\\sum_{i} a_i v_i - \\sum_{j} b_j h_j - \\sum_{i,j} v_i W_{ij} h_j$。我们可以将其写为 $E(v,h) = E_v(v) + E_h(h) + E_{vh}(v,h)$，其中各项分别仅依赖于 $v$、仅依赖于 $h$ 以及同时依赖于两者。然而，对于此计算，一个更有用的划分是区分依赖于 $h$ 的项和不依赖于 $h$ 的项。\n让我们将能量函数代入 $P(h\\mid v)$ 的表达式中：\n$$\nP(h\\mid v) = \\frac{\\exp\\left(\\sum_{i} a_i v_i + \\sum_{j} b_j h_j + \\sum_{i,j} v_i W_{ij} h_j\\right)}{\\sum_{h'} \\exp\\left(\\sum_{i} a_i v_i + \\sum_{j} b_j h'_j + \\sum_{i,j} v_i W_{ij} h'_j\\right)}\n$$\n项 $\\exp(\\sum_{i} a_i v_i)$ 相对于分母中的求和变量 $h'$ 是一个常数。因此，可以将其从分子和分母中提出并约去：\n$$\nP(h\\mid v) = \\frac{\\exp(\\sum_{i} a_i v_i) \\exp\\left(\\sum_{j} b_j h_j + \\sum_{i,j} v_i W_{ij} h_j\\right)}{\\exp(\\sum_{i} a_i v_i) \\sum_{h'} \\exp\\left(\\sum_{j} b_j h'_j + \\sum_{i,j} v_i W_{ij} h'_j\\right)}\n$$\n这简化为条件分布的最终表达式：\n$$\nP(h\\mid v) = \\frac{\\exp\\left(\\sum_{j} b_j h_j + \\sum_{j} \\left(\\sum_{i} v_i W_{ij}\\right) h_j\\right)}{\\sum_{h'} \\exp\\left(\\sum_{j} b_j h'_j + \\sum_{j} \\left(\\sum_{i} v_i W_{ij}\\right) h'_j\\right)}\n$$\n\n**任务2：隐藏单元条件独立性的证明**\n\n能量函数的结构是关键。它没有任何形如 $h_j h_k$ ($j \\neq k$) 的项，这代表了 RBM 的二分图结构。我们可以利用这一点来证明条件独立性。从任务1的结果出发，我们来分析分子中的指数部分：\n$$\n\\sum_{j} b_j h_j + \\sum_{j} \\left(\\sum_{i} v_i W_{ij}\\right) h_j = \\sum_{j} \\left(b_j + \\sum_{i} v_i W_{ij}\\right) h_j\n$$\n该表达式是关于隐藏单元 $j$ 的总和，其中每一项只涉及单个 $h_j$。让我们为每个隐藏单元 $j$ 定义一个有效偏置，它依赖于可见层 $v$ 的状态：\n$$\n\\theta_j(v) = b_j + \\sum_{i=1}^{2} v_i W_{ij}\n$$\n指数中的表达式变为 $\\sum_{j=1}^{2} \\theta_j(v) h_j$。条件分布为：\n$$\nP(h\\mid v) = \\frac{\\exp\\left(\\sum_{j=1}^{2} \\theta_j(v) h_j\\right)}{\\sum_{h' \\in \\{0,1\\}^2} \\exp\\left(\\sum_{j=1}^{2} \\theta_j(v) h'_j\\right)}\n$$\n分子可以因子分解为对 $j$ 的乘积：$\\exp\\left(\\sum_{j} \\theta_j(v) h_j\\right) = \\prod_{j} \\exp(\\theta_j(v) h_j)$。\n分母是 $h'=(h'_1, h'_2)$ 所有 $2^2=4$ 个状态的总和。这个总和也可以进行因子分解：\n$$\n\\sum_{h'_1 \\in \\{0,1\\}} \\sum_{h'_2 \\in \\{0,1\\}} \\exp(\\theta_1(v) h'_1 + \\theta_2(v) h'_2) = \\sum_{h'_1, h'_2} \\exp(\\theta_1(v) h'_1) \\exp(\\theta_2(v) h'_2)\n$$\n$$\n= \\left( \\sum_{h'_1 \\in \\{0,1\\}} \\exp(\\theta_1(v) h'_1) \\right) \\left( \\sum_{h'_2 \\in \\{0,1\\}} \\exp(\\theta_2(v) h'_2) \\right) = \\prod_{j=1}^{2} \\left(\\sum_{h'_j \\in \\{0,1\\}} \\exp(\\theta_j(v) h'_j)\\right)\n$$\n这个乘积中的每一项是 $\\exp(\\theta_j(v) \\cdot 0) + \\exp(\\theta_j(v) \\cdot 1) = 1 + \\exp(\\theta_j(v))$。\n所以分母是 $\\prod_{j=1}^{2} (1 + \\exp(\\theta_j(v)))$。\n结合因子分解后的分子和分母：\n$$\nP(h\\mid v) = \\frac{\\prod_{j=1}^{2} \\exp(\\theta_j(v) h_j)}{\\prod_{j=1}^{2} (1 + \\exp(\\theta_j(v)))} = \\prod_{j=1}^{2} \\frac{\\exp(\\theta_j(v) h_j)}{1 + \\exp(\\theta_j(v))}\n$$\n这表明 $P(h\\mid v)$ 是每个隐藏单元分布的乘积，即 $P(h\\mid v) = P(h_1\\mid v) P(h_2\\mid v)$。这就是条件独立的定义。\n单个隐藏单元 $h_j$ 的项是：\n$$\nP(h_j\\mid v) = \\frac{\\exp(\\theta_j(v) h_j)}{1 + \\exp(\\theta_j(v))}\n$$\n对于 $h_j=1$，我们得到 $P(h_j=1\\mid v) = \\frac{\\exp(\\theta_j(v))}{1 + \\exp(\\theta_j(v))} = \\frac{1}{1 + \\exp(-\\theta_j(v))}$，这就是 logistic sigmoid 函数，$\\sigma(\\theta_j(v))$。\n对于 $h_j=0$，我们得到 $P(h_j=0\\mid v) = \\frac{1}{1 + \\exp(\\theta_j(v))} = 1 - \\sigma(\\theta_j(v))$。\n因此，每个隐藏单元 $h_j$ 都遵循参数为 $p_j = \\sigma(\\theta_j(v))$ 的伯努利分布。分布 $P(h\\mid v)$ 是这些伯努利分布的乘积。其参数化由 $p_j = \\sigma(b_j + \\sum_i v_i W_{ij})$ 给出，其中 $j=1,2$。\n\n**任务3：枚举与验证**\n\n我们计算能量 $E(v,h) = -(a_1 v_1 + a_2 v_2) - (b_1 h_1 + b_2 h_2) - (v_1W_{11}h_1 + v_1W_{12}h_2 + v_2W_{21}h_1 + v_2W_{22}h_2)$ 和所有 $16$ 种 $(v,h)$ 配置的未归一化概率质量 $\\exp(-E(v,h))$。\n\n首先，我们为每个 $v$ 计算有效偏置 $\\theta_j(v) = b_j + v_1 W_{1j} + v_2 W_{2j}$。\n-   $v=(0,0)$: $\\theta_1=b_1=0.2$, $\\theta_2=b_2=0.4$。\n-   $v=(0,1)$: $\\theta_1=b_1+W_{21}=0.2-0.3=-0.1$, $\\theta_2=b_2+W_{22}=0.4+0.6=1.0$。\n-   $v=(1,0)$: $\\theta_1=b_1+W_{11}=0.2+0.7=0.9$, $\\theta_2=b_2+W_{12}=0.4-0.5=-0.1$。\n-   $v=(1,1)$: $\\theta_1=b_1+W_{11}+W_{21}=0.2+0.7-0.3=0.6$, $\\theta_2=b_2+W_{12}+W_{22}=0.4-0.5+0.6=0.5$。\n\n现在，我们枚举所有 16 个状态。项 $-E(v,h)$ 等于 $a^T v + \\theta_1(v) h_1 + \\theta_2(v) h_2$。\n\n| $v_1$ | $v_2$ | $h_1$ | $h_2$ | $a^Tv$ | $\\theta_1 h_1+\\theta_2 h_2$ | $-E(v,h)$ | $E(v,h)$ | $\\exp(-E(v,h))$ |\n|---|---|---|---|---|---|---|---|---|\n| $0$ | $0$ | $0$ | $0$ | $0.0$ | $0.0$ | $0.0$ | $0.0$ | $\\exp(0.0) = 1$ |\n| $0$ | $0$ | $0$ | $1$ | $0.0$ | $0.4$ | $0.4$ | $-0.4$ | $\\exp(0.4)$ |\n| $0$ | $0$ | $1$ | $0$ | $0.0$ | $0.2$ | $0.2$ | $-0.2$ | $\\exp(0.2)$ |\n| $0$ | $0$ | $1$ | $1$ | $0.0$ | $0.6$ | $0.6$ | $-0.6$ | $\\exp(0.6)$ |\n| $0$ | $1$ | $0$ | $0$ | $-0.1$ | $0.0$ | $-0.1$ | $0.1$ | $\\exp(-0.1)$ |\n| $0$ | $1$ | $0$ | $1$ | $-0.1$ | $1.0$ | $0.9$ | $-0.9$ | $\\exp(0.9)$ |\n| $0$ | $1$ | $1$ | $0$ | $-0.1$ | $-0.1$ | $-0.2$ | $0.2$ | $\\exp(-0.2)$ |\n| $0$ | $1$ | $1$ | $1$ | $-0.1$ | $0.9$ | $0.8$ | $-0.8$ | $\\exp(0.8)$ |\n| $1$ | $0$ | $0$ | $0$ | $0.3$ | $0.0$ | $0.3$ | $-0.3$ | $\\exp(0.3)$ |\n| $1$ | $0$ | $0$ | $1$ | $0.3$ | $-0.1$ | $0.2$ | $-0.2$ | $\\exp(0.2)$ |\n| $1$ | $0$ | $1$ | $0$ | $0.3$ | $0.9$ | $1.2$ | $-1.2$ | $\\exp(1.2)$ |\n| $1$ | $0$ | $1$ | $1$ | $0.3$ | $0.8$ | $1.1$ | $-1.1$ | $\\exp(1.1)$ |\n| $1$ | $1$ | $0$ | $0$ | $0.2$ | $0.0$ | $0.2$ | $-0.2$ | $\\exp(0.2)$ |\n| $1$ | $1$ | $0$ | $1$ | $0.2$ | $0.5$ | $0.7$ | $-0.7$ | $\\exp(0.7)$ |\n| $1$ | $1$ | $1$ | $0$ | $0.2$ | $0.6$ | $0.8$ | $-0.8$ | $\\exp(0.8)$ |\n| $1$ | $1$ | $1$ | $1$ | $0.2$ | $1.1$ | $1.3$ | $-1.3$ | $\\exp(1.3)$ |\n\n对每个固定的 $v$ 进行验证：\n对于一个固定的 $v$，$P(h\\mid v) = \\frac{\\exp(-E(v,h))}{\\sum_{h'}\\exp(-E(v,h'))}$。我们来验证 $v=(1,0)$ 的情况。\n从表中可知，对于 $v=(1,0)$，未归一化的概率为 $\\exp(0.3)$、$\\exp(0.2)$、$\\exp(1.2)$、$\\exp(1.1)$。\n归一化常数为 $Z_{(1,0)} = \\exp(0.3) + \\exp(0.2) + \\exp(1.2) + \\exp(1.1)$。\n$P(h=(1,1)\\mid v=(1,0)) = \\frac{\\exp(1.1)}{\\exp(0.3) + \\exp(0.2) + \\exp(1.2) + \\exp(1.1)}$。\n根据任务2， $P(h\\mid v) = P(h_1\\mid v)P(h_2\\mid v)$，其中 $P(h_j=1\\mid v) = \\sigma(\\theta_j(v))$。对于 $v=(1,0)$，$\\theta_1=0.9, \\theta_2=-0.1$。\n因此，$P(h_1=1\\mid v)=\\sigma(0.9)$，$P(h_2=1\\mid v)=\\sigma(-0.1)$。\n$P(h_1=0\\mid v)=1-\\sigma(0.9)$，$P(h_2=0\\mid v)=1-\\sigma(-0.1)$。\n$P(h=(1,1)\\mid v=(1,0)) = \\sigma(0.9)\\sigma(-0.1) = \\left(\\frac{\\exp(0.9)}{1+\\exp(0.9)}\\right)\\left(\\frac{\\exp(-0.1)}{1+\\exp(-0.1)}\\right) = \\frac{\\exp(0.8)}{(1+\\exp(0.9))(1+\\exp(-0.1))}$。\n通过显式求和得到的分母是 $Z_{(1,0)} = \\exp(0.3)[1 + \\exp(-0.1) + \\exp(0.9) + \\exp(0.8)] = \\exp(0.3)[(1+\\exp(0.9))(1+\\exp(-0.1))]$。\n分子是 $\\exp(1.1) = \\exp(0.3)\\exp(0.8)$。\n所以，$P(h=(1,1)\\mid v=(1,0)) = \\frac{\\exp(0.3)\\exp(0.8)}{\\exp(0.3)(1+\\exp(0.9))(1+\\exp(-0.1))} = \\frac{\\exp(0.8)}{(1+\\exp(0.9))(1+\\exp(-0.1))}$。\n结果匹配。通过类似的计算，验证对所有其他 $(v,h)$ 组合均成立，从而证实了伯努利乘积形式。\n\n**任务4：计算 $P(h_1=1\\mid v=(1,0))$**\n\n我们需要为特定的可见配置 $v=(1,0)$ 计算 $P(h_1=1\\mid v)$。\n使用任务2中推导的公式：\n$$\nP(h_1=1\\mid v) = \\sigma\\left(b_1 + \\sum_{i=1}^{2} v_i W_{i1}\\right)\n$$\n对于 $v=(1,0)$，我们有 $v_1=1$ 和 $v_2=0$。\nsigmoid 函数的自变量为：\n$$\n\\theta_1(1,0) = b_1 + v_1 W_{11} + v_2 W_{21} = 0.2 + (1)(0.7) + (0)(-0.3) = 0.2 + 0.7 = 0.9\n$$\n将此值代入 sigmoid 函数中：\n$$\nP(h_1=1\\mid v=(1,0)) = \\sigma(0.9) = \\frac{1}{1 + \\exp(-0.9)}\n$$\n这就是最终的精确表达式。",
            "answer": "$$\n\\boxed{\\frac{1}{1 + \\exp(-0.9)}}\n$$"
        },
        {
            "introduction": "理论学习的最终目的是应用于实践并评估模型性能。本练习将指导你通过编程，实现对RBM模型校准度的量化分析 ()。你将学习如何利用自由能对模型的预测概率进行排序，并将其与测试数据的经验频率进行比较，从而评估模型所学到的概率分布与真实数据分布的契合程度，这是衡量生成模型质量的关键一步。",
            "id": "3170417",
            "problem": "考虑一个具有二元可见单元和二元隐藏单元的受限玻尔兹曼机（RBM）。令可见向量表示为 $v \\in \\{0,1\\}^D$，隐藏向量表示为 $h \\in \\{0,1\\}^H$。该RBM拥有连接可见单元与隐藏单元的权重矩阵 $W \\in \\mathbb{R}^{D \\times H}$，可见单元偏置 $b \\in \\mathbb{R}^D$，以及隐藏单元偏置 $c \\in \\mathbb{R}^H$。联合配置 $(v,h)$ 的能量由核心RBM能量函数定义\n$$\nE(v,h) = -b^\\top v - c^\\top h - v^\\top W h.\n$$\n可见向量 $v$ 的边缘概率为\n$$\nP(v) = \\frac{1}{Z} \\sum_{h \\in \\{0,1\\}^H} \\exp\\big(-E(v,h)\\big),\n$$\n其中 $Z$ 是对所有可见和隐藏配置求和的配分函数。可见向量 $v$ 的RBM自由能定义为\n$$\nF(v) = -b^\\top v - \\sum_{j=1}^H \\log\\big(1 + \\exp(c_j + W_{:,j}^\\top v)\\big),\n$$\n因此 $v$ 的边缘概率可以表示为\n$$\nP(v) = \\frac{\\exp\\big(-F(v)\\big)}{\\sum_{v' \\in \\{0,1\\}^D} \\exp\\big(-F(v')\\big)}.\n$$\n使用这些定义，可以通过按自由能 $F(v)$ 递增（等价于按 $\\exp(-F(v))$ 递减）的顺序对所有 $2^D$ 个可见配置进行排序，并根据 $P(v)$ 计算累积概率，从而得到一个可见状态上的累积分布。通过在累积概率为 $k/K$（其中 $k \\in \\{1,2,\\dots,K-1\\}$）处设置阈值，定义 $K$ 个分位数箱。在模型 $P(v)$ 下，如果测试样本独立地从 $P(v)$ 中抽取，那么落入每个分位数箱的测试样本的期望比例为 $1/K$，从而在各个箱之间产生均匀的期望。\n\n你的任务是实现一个程序，该程序能够：\n1. 枚举所有可见状态 $v \\in \\{0,1\\}^D$，从基本原理出发计算 $F(v)$ 和 $P(v)$，并通过按 $F(v)$ 递增的顺序对状态排序来构建累积分布函数。\n2. 根据每个可见状态的累积概率将其分配到一个分位数箱中（对于累积概率为 $r \\in (0,1]$ 的状态，其箱索引定义为 $\\min\\{\\lfloor K r \\rfloor, K-1\\}$）。\n3. 在几种模式下确定性地构建指定的测试数据集，然后计算测试样本在每个箱中的经验频率。\n4. 将经验频率与均匀期望 $1/K$ 进行比较，并为每个测试用例报告两个校准误差度量：平均绝对偏差（MAD）和最大绝对偏差（MAXDEV），两者均为实数。\n\n此问题中不涉及物理量，因此不需要物理单位。不出现角度。若有百分比，必须表示为小数。\n\n使用以下测试套件。每个用例指定了 $W$、$b$、$c$、箱数 $K$，以及一个确定性的测试数据集构建模式及其参数：\n\n用例1（一般情况，模型下的近似校准）：\n- $D = 4$, $H = 3$,\n- $W = \\begin{bmatrix} 0.8  -0.4  0.2 \\\\ 0.1  0.5  -0.3 \\\\ -0.6  0.7  0.4 \\\\ 0.3  -0.2  0.9 \\end{bmatrix}$,\n- $b = \\begin{bmatrix} 0.2 \\\\ -0.1 \\\\ 0.05 \\\\ 0.3 \\end{bmatrix}$,\n- $c = \\begin{bmatrix} 0.1 \\\\ -0.2 \\\\ 0.4 \\end{bmatrix}$,\n- $K = 5$,\n- 测试数据集模式：“approx_model”，总样本数为 $M = 200$。通过对 $M \\cdot P(v)$ 应用最大余数法，将每个可见状态 $v$ 确定性地复制整数次来构建数据集：使用 $\\lfloor M \\cdot P(v) \\rfloor$ 作为基础计数，并将剩余的 $M - \\sum_v \\lfloor M \\cdot P(v) \\rfloor$ 个样本按小数余数降序分配给各个状态。\n\n用例2（未校准，集中于最可能的状态）：\n- $D = 4$, $H = 2$,\n- $W = \\begin{bmatrix} 1.0  -0.5 \\\\ -0.7  0.3 \\\\ 0.2  0.8 \\\\ -0.4  -0.1 \\end{bmatrix}$,\n- $b = \\begin{bmatrix} 0.5 \\\\ -0.2 \\\\ 0.0 \\\\ 0.1 \\end{bmatrix}$,\n- $c = \\begin{bmatrix} 0.3 \\\\ -0.4 \\end{bmatrix}$,\n- $K = 5$,\n- 测试数据集模式：“top_states”，参数为 $T = 3$ 和 $R = 50$。通过选取具有最大 $P(v)$ 的前 $T$ 个可见状态，并将每个状态精确复制 $R$ 次来构建数据集，总样本数为 $M = T \\cdot R$。\n\n用例3（边缘情况，箱数多且测试覆盖均匀）：\n- $D = 4$, $H = 3$（与用例1参数相同），\n- $W = \\begin{bmatrix} 0.8  -0.4  0.2 \\\\ 0.1  0.5  -0.3 \\\\ -0.6  0.7  0.4 \\\\ 0.3  -0.2  0.9 \\end{bmatrix}$,\n- $b = \\begin{bmatrix} 0.2 \\\\ -0.1 \\\\ 0.05 \\\\ 0.3 \\end{bmatrix}$,\n- $c = \\begin{bmatrix} 0.1 \\\\ -0.2 \\\\ 0.4 \\end{bmatrix}$,\n- $K = 16$,\n- 测试数据集模式：“uniform_states”，参数为 $R = 6$。通过将每个可见状态精确复制 $R$ 次来构建数据集，总样本数为 $M = 2^D \\cdot R$。\n\n对于每个用例，计算两个校准度量：\n- $\\mathrm{MAD} = \\frac{1}{K} \\sum_{i=0}^{K-1} \\left| f_i - \\frac{1}{K} \\right|$，\n- $\\mathrm{MAXDEV} = \\max_{0 \\le i  K} \\left| f_i - \\frac{1}{K} \\right|$，\n其中 $f_i$ 是分配给箱 $i$ 的测试样本的经验频率。\n\n最终输出格式：你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个用例表示为一个双元素列表 $[\\mathrm{MAD},\\mathrm{MAXDEV}]$。输出中不得有任何空格。例如，输出应类似于 $[[x_1,y_1],[x_2,y_2],[x_3,y_3]]$，其中 $x_i$ 和 $y_i$ 是对应于用例 $i$ 的十进制数。",
            "solution": "已对用户提供的问题进行了分析和验证。\n\n### 步骤1：提取给定信息\n问题提供了受限玻尔兹曼机（RBM）的完整规范以及一个与模型校准相关的任务。给定信息包括：\n- **模型定义**：一个具有二元可见单元 $v \\in \\{0,1\\}^D$ 和二元隐藏单元 $h \\in \\{0,1\\}^H$ 的RBM。\n- **能量函数**：$E(v,h) = -b^\\top v - c^\\top h - v^\\top W h$。\n- **自由能函数**：$F(v) = -b^\\top v - \\sum_{j=1}^H \\log\\big(1 + \\exp(c_j + W_{:,j}^\\top v)\\big)$。\n- **概率分布**：$P(v) = \\frac{\\exp\\big(-F(v)\\big)}{\\sum_{v' \\in \\{0,1\\}^D} \\exp\\big(-F(v')\\big)}$。\n- **分位数分箱**：使用 $K$ 个箱。对于累积概率为 $r \\in (0,1]$ 的状态，其箱索引定义为 $\\min\\{\\lfloor K r \\rfloor, K-1\\}$。累积分布是通过按自由能 $F(v)$ 递增的顺序对状态排序来构建的。\n- **校准度量**：\n    - 平均绝对偏差 (MAD): $\\mathrm{MAD} = \\frac{1}{K} \\sum_{i=0}^{K-1} \\left| f_i - \\frac{1}{K} \\right|$。\n    - 最大绝对偏差 (MAXDEV): $\\mathrm{MAXDEV} = \\max_{0 \\le i  K} \\left| f_i - \\frac{1}{K} \\right|$。\n- **测试用例**：提供了三个完全指定的测试用例，每个用例都带有参数 $W, b, c$、维度 $D, H$、箱数 $K$ 以及用于构建测试数据集的确定性规则。\n    - **用例1**：$D=4, H=3, K=5$。测试集通过“approx_model”模式，使用最大余数法生成，总样本数为 $M=200$。\n    - **用例2**：$D=4, H=2, K=5$。测试集通过“top_states”模式生成，参数为 $T=3, R=50$。\n    - **用例3**：$D=4, H=3, K=16$。测试集通过“uniform_states”模式生成，参数为 $R=6$。\n\n### 步骤2：验证给定信息\n对问题进行了严格的验证检查。\n1.  **科学基础**：该问题基于受限玻尔兹曼机的标准数学框架，这是机器学习中一个成熟的课题。能量、自由能和概率的定义是正确且一致的。使用分位数箱并将经验频率与均匀理想值进行比较来评估模型校准是一种标准的统计实践。\n2.  **良态性 (Well-Posedness)**：问题是良态的。每个用例的所有参数和常数（$W, b, c, D, H, K$）都已明确提供。计算所有所需量（自由能、概率、箱索引）的程序都已明确定义。构建测试数据集的方法是确定性的，确保了唯一的解决方案。可见空间的维度较小（$D=4$），使得枚举所有 $2^{4}$ 个状态在计算上是可行的。\n3.  **客观性**：问题使用精确、客观的数学和算法语言陈述。没有主观或模糊的陈述。\n4.  **缺陷清单**：\n    -   **科学上不健全**：未发现违反科学或数学原理之处。RBM能量函数与给定的自由能函数之间的关系是标准且正确的。\n    -   **不可形式化**：问题是完全可形式化的。\n    -   **不完整或矛盾**：设置是完整且一致的。矩阵和向量的维度是兼容的。\n    -   **不切实际或不可行**：计算任务是可行的。\n    -   **病态或结构不良**：问题结构良好。虽然分箱规则 $\\min\\{\\lfloor K r \\rfloor, K-1\\}$ 不一定能在 $P(v)$ 下创建等概率质量的箱，但这是一个必须遵循的明确定义。问题要求根据均匀理想值来衡量校准度，这是定义校准测试的一种有效方法。\n    -   **琐碎或同义反复**：问题需要一个涉及非平凡概念的多步计算，不是同义反复。\n    -   **无法验证**：结果可以通过独立实现所描述的算法来完全验证。\n\n### 步骤3：结论与行动\n问题被判定为**有效**。将通过实现指定的程序来提供解决方案。\n\n### 算法解决方案\n对于每个测试用例，通过以下步骤序列获得解决方案：\n\n1.  **状态枚举**：生成所有 $2^D = 16$ 个可能的二元可见状态 $v \\in \\{0,1\\}^4$。\n\n2.  **自由能计算**：对于每个可见状态 $v$，使用提供的公式计算自由能 $F(v)$：\n    $$F(v) = -b^\\top v - \\sum_{j=1}^H \\log\\big(1 + \\exp(c_j + v^\\top W_{:,j})\\big)$$\n\n3.  **概率计算**：计算每个状态的概率 $P(v)$。为确保数值稳定性，首先计算相对于最小自由能的未归一化概率 $u(v) = \\exp(-F(v))$，然后进行归一化。\n    $$F_{\\min} = \\min_{v'} F(v')$$\n    $$P(v) = \\frac{\\exp(-(F(v) - F_{\\min}))}{\\sum_{v' \\in \\{0,1\\}^D} \\exp(-(F(v') - F_{\\min}))}$$\n\n4.  **排序与累积分布**：将 $2^D$ 个状态按其自由能 $F(v)$ 的升序排序。使用次要排序键（例如，二元向量的整数值）以确保在出现平局时有唯一、确定性的排序。然后在此排序的状态列表上计算累积分布函数（CDF）。对于排序序列中的第 $i$ 个状态 $v_i$，其累积概率为 $C_i = \\sum_{j=0}^{i} P(v_j)$。\n\n5.  **分箱分配**：每个可见状态 $v$ 被分配到 $K$ 个箱中的一个。具有累积概率 $C_i$ 的状态 $v_i$ 的箱索引根据指定规则计算：\n    $$\\text{bin\\_index}(v_i) = \\min\\{\\lfloor K \\cdot C_i \\rfloor, K-1\\}$$\n    创建一个映射来存储每个唯一状态向量的箱分配。\n\n6.  **测试数据集构建**：根据用例指定的模式确定性地构建测试数据集。这是通过计算 $2^D$ 个状态中每个状态在数据集中出现的次数来完成的。\n    - **approx_model**：通过对期望计数 $M \\cdot P(v)$ 应用最大余数法来确定每个状态 $v$ 的计数。\n    - **top_states**：具有最高概率 $P(v)$（即最低自由能）的 $T$ 个状态各包含 $R$ 次。所有其他状态的计数为零。\n    - **uniform_states**：$2^D$ 个状态中的每一个都包含 $R$ 次。\n\n7.  **经验频率计算**：统计测试样本总数 $M$ 和落入 $K$ 个箱中每个箱的样本数。然后计算每个箱 $i$ 的经验频率为 $f_i = (\\text{箱 } i \\text{ 的计数}) / M$。\n\n8.  **度量计算**：通过将经验频率 $f_i$ 与理想的均匀频率 $1/K$ 进行比较，计算两个校准误差度量：\n    -   $\\mathrm{MAD} = \\frac{1}{K} \\sum_{i=0}^{K-1} \\left| f_i - \\frac{1}{K} \\right|$\n    -   $\\mathrm{MAXDEV} = \\max_{0 \\le i  K} \\left| f_i - \\frac{1}{K} \\right|$\n\n对三个测试用例中的每一个重复此过程，并收集得到的 $(\\mathrm{MAD}, \\mathrm{MAXDEV})$ 对。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the solver for each, and print the final output.\n    \"\"\"\n    case1 = {\n        'W': np.array([\n            [0.8, -0.4, 0.2], [0.1, 0.5, -0.3], [-0.6, 0.7, 0.4], [0.3, -0.2, 0.9]\n        ]),\n        'b': np.array([0.2, -0.1, 0.05, 0.3]),\n        'c': np.array([0.1, -0.2, 0.4]),\n        'K': 5,\n        'mode': \"approx_model\",\n        'mode_params': {'M': 200}\n    }\n\n    case2 = {\n        'W': np.array([\n            [1.0, -0.5], [-0.7, 0.3], [0.2, 0.8], [-0.4, -0.1]\n        ]),\n        'b': np.array([0.5, -0.2, 0.0, 0.1]),\n        'c': np.array([0.3, -0.4]),\n        'K': 5,\n        'mode': \"top_states\",\n        'mode_params': {'T': 3, 'R': 50}\n    }\n\n    case3 = {\n        'W': case1['W'],\n        'b': case1['b'],\n        'c': case1['c'],\n        'K': 16,\n        'mode': \"uniform_states\",\n        'mode_params': {'R': 6}\n    }\n\n    test_cases = [case1, case2, case3]\n    results = [_solve_one_case(**case) for case in test_cases]\n    \n    case_strings = [f\"[{mad:.10f},{maxdev:.10f}]\" for mad, maxdev in results]\n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\ndef _solve_one_case(W, b, c, K, mode, mode_params):\n    \"\"\"\n    Solves a single RBM calibration test case.\n    \"\"\"\n    D, H = W.shape\n    num_states = 2**D\n\n    # 1. Enumerate states, calculate free energies and probabilities\n    state_data = []\n    for i in range(num_states):\n        v = np.array([int(bit) for bit in bin(i)[2:].zfill(D)])\n        vT_W = v @ W \n        log_terms = np.log(1 + np.exp(c + vT_W))\n        F_v = - (b @ v) - np.sum(log_terms)\n        state_data.append({'v_tuple': tuple(v), 'F': F_v, 'id': i})\n\n    free_energies = np.array([s['F'] for s in state_data])\n    F_min = np.min(free_energies)\n    unnormalized_probs = np.exp(-(free_energies - F_min))\n    Z_v = np.sum(unnormalized_probs)\n    probs = unnormalized_probs / Z_v\n    \n    for i in range(num_states):\n        state_data[i]['P'] = probs[i]\n\n    # 2. Sort states by increasing free energy for CDF computation\n    state_data.sort(key=lambda x: (x['F'], x['id']))\n\n    # 3. Compute CDF and assign bin indices to each state\n    id_to_bin_map = np.zeros(num_states, dtype=int)\n    cdf = 0.0\n    for s in state_data:\n        cdf += s['P']\n        r = cdf\n        # Clamp r to 1.0 to handle potential float precision issues causing r  1\n        r = min(r, 1.0)\n        bin_idx = int(min(np.floor(K * r), K - 1))\n        # Use state 'id' to map bin index back to original state order\n        id_to_bin_map[s['id']] = bin_idx\n\n    # 4. Construct test dataset based on mode (as counts per state)\n    state_data.sort(key=lambda x: x['id'])\n    \n    sample_counts = np.zeros(num_states, dtype=int)\n    total_samples = 0\n\n    if mode == \"approx_model\":\n        M = mode_params['M']\n        total_samples = M\n        current_probs = np.array([s['P'] for s in state_data])\n        \n        expected_counts = M * current_probs\n        base_counts = np.floor(expected_counts)\n        remainders = expected_counts - base_counts\n        \n        rem_to_distribute = M - int(np.sum(base_counts))\n        rem_indices = np.argsort(remainders)[::-1]\n        \n        sample_counts = base_counts.astype(int)\n        for i in range(rem_to_distribute):\n            sample_counts[rem_indices[i]] += 1\n            \n    elif mode == \"top_states\":\n        T, R = mode_params['T'], mode_params['R']\n        total_samples = T * R\n        state_data.sort(key=lambda x: (x['F'], x['id']))\n        top_states_ids = [s['id'] for s in state_data[:T]]\n        for state_id in top_states_ids:\n            sample_counts[state_id] = R\n        \n    elif mode == \"uniform_states\":\n        R = mode_params['R']\n        total_samples = num_states * R\n        sample_counts.fill(R)\n\n    # 5. Compute empirical frequencies per bin\n    bin_counts = np.zeros(K, dtype=int)\n    for i in range(num_states):\n        if sample_counts[i]  0:\n            bin_idx = id_to_bin_map[i]\n            bin_counts[bin_idx] += sample_counts[i]\n\n    if total_samples  0:\n        empirical_freqs = bin_counts / total_samples\n    else:\n        empirical_freqs = np.zeros(K)\n\n    # 6. Compute calibration metrics\n    expected_freq = 1.0 / K\n    abs_devs = np.abs(empirical_freqs - expected_freq)\n    \n    mad = np.mean(abs_devs)\n    maxdev = np.max(abs_devs)\n\n    return mad, maxdev\n\nsolve()\n```"
        }
    ]
}