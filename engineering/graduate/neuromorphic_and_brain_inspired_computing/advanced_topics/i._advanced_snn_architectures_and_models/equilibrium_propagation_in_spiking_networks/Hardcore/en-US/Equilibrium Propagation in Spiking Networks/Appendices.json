{
    "hands_on_practices": [
        {
            "introduction": "Equilibrium Propagation's elegance stems from its interpretation of network dynamics as a process of energy minimization. For networks with symmetric connections, the relaxation to a steady state is equivalent to gradient descent on an energy landscape. This first exercise guides you through deriving the precise form of this energy function for a simple rate-based network, making the abstract concept of an energy landscape tangible and calculable. ",
            "id": "4043234",
            "problem": "Consider a two-neuron spiking network under the mean-field filtered-spike approximation, where the continuous-time firing-rate vector $x \\in \\mathbb{R}^{2}$ obeys the Leaky Integrate-and-Fire (LIF) dynamics with time constant $\\tau$ and symmetric synaptic coupling matrix $W \\in \\mathbb{R}^{2 \\times 2}$ driven by external input $I \\in \\mathbb{R}^{2}$. Take as a fundamental base the first-order linear rate dynamics of LIF neurons,\n$$\n\\tau \\frac{d x}{d t} = - x + W x + I,\n$$\nand the Equilibrium Propagation (EP) energy-based requirement that there exists a scalar energy function $E(x,w)$ such that the autonomous relaxation dynamics are a gradient flow,\n$$\n\\tau \\frac{d x}{d t} = - \\nabla_{x} E(x,w).\n$$\nAssume $W$ is symmetric, $W = W^{\\top}$, and smooth in $x$. Using only these base facts, derive a valid energy function $E(x,w)$ up to an arbitrary additive constant that is consistent with the above dynamics. Then, for the specific two-neuron network with off-diagonal synapses $w_{12} = w_{21} = 0.4$ and zero self-couplings $w_{11} = w_{22} = 0$, leak time constant $\\tau = 10\\,\\mathrm{ms}$, filtered spikes $x = (0.3,\\,0.6)$, and input $I = (0.1,\\,0)$, evaluate $E(x,w)$ and compute the gradient components $\\frac{\\partial E}{\\partial x_{1}}$ and $\\frac{\\partial E}{\\partial x_{2}}$ at $x$. Finally, verify whether $\\nabla_{x} E$ vanishes at $x$ based on your computed gradient. Express your final answer as a row matrix $\\big(E(x,w),\\,\\frac{\\partial E}{\\partial x_{1}},\\,\\frac{\\partial E}{\\partial x_{2}}\\big)$. No rounding is required for the numerical values, and no physical units need be included for the energy.",
            "solution": "To derive the energy function $E(x,w)$, we equate the given dynamics with the gradient flow definition:\n$$\n-\\nabla_{x} E(x,w) = -x + Wx + I\n$$\n$$\n\\nabla_{x} E(x,w) = x - Wx - I = (I - W)x - I\n$$\nThis is a linear vector field in $x$. Since $W$ is symmetric, the matrix $I-W$ is also symmetric, which guarantees that this vector field is the gradient of a scalar potential function (the energy). We can find $E(x,w)$ by integrating this expression. For a general quadratic form $E(x) = \\frac{1}{2}x^\\top A x - b^\\top x + C_0$, the gradient is $\\nabla_x E = Ax - b$. By comparison, we identify $A = I - W$ and $b = I$. Choosing the integration constant $C_0=0$, we get:\n$$\nE(x,w) = \\frac{1}{2}x^\\top(I-W)x - I^\\top x\n$$\nIn index notation, this is:\n$$\nE(x,w) = \\frac{1}{2} \\sum_i x_i^2 - \\frac{1}{2} \\sum_{i,j} W_{ij} x_i x_j - \\sum_i I_i x_i\n$$\nThis is the required energy function.\n\nNow, we evaluate $E(x,w)$ and its gradient for the given values:\n- $x = (0.3, 0.6)^\\top$\n- $W = \\begin{pmatrix} 0  0.4 \\\\ 0.4  0 \\end{pmatrix}$\n- $I = (0.1, 0)^\\top$\n\nFirst, we calculate the energy $E(x,w)$:\n$$\nE(x,w) = \\frac{1}{2}(0.3^2 + 0.6^2) - \\frac{1}{2}(W_{12}x_1x_2 + W_{21}x_2x_1) - (I_1x_1)\n$$\n$$\nE(x,w) = \\frac{1}{2}(0.09 + 0.36) - \\frac{1}{2}(0.4 \\cdot 0.3 \\cdot 0.6 + 0.4 \\cdot 0.6 \\cdot 0.3) - (0.1 \\cdot 0.3)\n$$\n$$\nE(x,w) = \\frac{1}{2}(0.45) - \\frac{1}{2}(0.072 + 0.072) - 0.03\n$$\n$$\nE(x,w) = 0.225 - 0.072 - 0.03 = 0.123\n$$\nNext, we compute the gradient vector $\\nabla_x E$ at $x$:\n$$\n\\nabla_x E(x,w) = (I-W)x - I = \\begin{pmatrix} 1  -0.4 \\\\ -0.4  1 \\end{pmatrix} \\begin{pmatrix} 0.3 \\\\ 0.6 \\end{pmatrix} - \\begin{pmatrix} 0.1 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\nabla_x E(x,w) = \\begin{pmatrix} 1(0.3) - 0.4(0.6) \\\\ -0.4(0.3) + 1(0.6) \\end{pmatrix} - \\begin{pmatrix} 0.1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0.3 - 0.24 \\\\ -0.12 + 0.6 \\end{pmatrix} - \\begin{pmatrix} 0.1 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\nabla_x E(x,w) = \\begin{pmatrix} 0.06 \\\\ 0.48 \\end{pmatrix} - \\begin{pmatrix} 0.1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -0.04 \\\\ 0.48 \\end{pmatrix}\n$$\nThe gradient components are $\\frac{\\partial E}{\\partial x_1} = -0.04$ and $\\frac{\\partial E}{\\partial x_2} = 0.48$. Since the gradient is non-zero, the point $x$ is not an equilibrium point.\n\nThe final result requested is the row matrix $\\big(E(x,w),\\,\\frac{\\partial E}{\\partial x_{1}},\\,\\frac{\\partial E}{\\partial x_{2}}\\big)$, which is $(0.123, -0.04, 0.48)$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.123  -0.04  0.48 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The learning in Equilibrium Propagation happens by comparing two states: the 'free' equilibrium and a 'nudged' equilibrium. The nudged phase is created by introducing a small force that pushes the network's output towards a desired target. This practice demonstrates how to translate a high-level performance goal—in this case, a target spike count—into a concrete nudging current, which is the physical mechanism for propagating error information back into the network. ",
            "id": "4043232",
            "problem": "Consider a single-output neuron in a spiking network observed over a discrete time window indexed by $t \\in \\{1,2,\\dots,T\\}$ with spike train $s_k(t) \\in \\{0,1\\}$. Define a rate-based linear readout $y_k$ as\n$$\ny_k \\;=\\; \\sum_{t=1}^{T} \\kappa(t)\\, s_k(t),\n$$\nwith a rectangular normalized kernel $\\kappa(t) = \\frac{1}{T}$ for all $t \\in \\{1,\\dots,T\\}$. The spike-count loss for the target spike count $\\hat{n}_k$ is\n$$\n\\mathcal{L}_k \\;=\\; \\big(T\\,y_k - \\hat{n}_k\\big)^{2}.\n$$\nIn equilibrium propagation (EP), the second phase is obtained by adding small nudging currents to variables that are directly tied to the loss so that the system explores a slightly perturbed steady state. Starting only from the core EP principle that the nudging acts as a small external influence proportional to the negative gradient of the loss with respect to the variable being nudged, derive the nudging current applied to the readout variable associated with output neuron $k$ as a closed-form analytic expression in terms of $T$, $y_k$, $\\hat{n}_k$, and the small positive nudging strength $\\beta$. Then compute its value for the following concrete sample: $(\\hat{n}_k, T) = (10, 100)$, observed spikes at times $t \\in \\{5, 20, 35, 50, 65, 80, 95\\}$ (so that $s_k(t) = 1$ at those indices and $s_k(t) = 0$ otherwise), and $\\beta = 0.01$. Express the final current amplitude as a single real number with no units and do not round.",
            "solution": "The problem requires the derivation of a nudging current in the context of equilibrium propagation (EP) and its subsequent calculation for a specific numerical example.\n\nFirst, we establish the theoretical framework. The problem states that the nudging current, which we denote as $I_k^{\\text{nudge}}$, is a small external influence proportional to the negative gradient of the loss function $\\mathcal{L}_k$ with respect to the variable being nudged, which is the readout variable $y_k$. The constant of proportionality is given as the small positive nudging strength $\\beta$. This relationship is formalized as:\n$$\nI_k^{\\text{nudge}} = -\\beta \\frac{\\partial \\mathcal{L}_k}{\\partial y_k}\n$$\nThe loss function is given by:\n$$\n\\mathcal{L}_k = (T y_k - \\hat{n}_k)^2\n$$\nTo find the nudging current, we must compute the partial derivative of $\\mathcal{L}_k$ with respect to $y_k$. Using the chain rule for differentiation, we have:\n$$\n\\frac{\\partial \\mathcal{L}_k}{\\partial y_k} = \\frac{\\partial}{\\partial y_k} \\left[ (T y_k - \\hat{n}_k)^2 \\right]\n$$\nLetting $u = T y_k - \\hat{n}_k$, the expression becomes $\\mathcal{L}_k = u^2$. The chain rule gives:\n$$\n\\frac{\\partial \\mathcal{L}_k}{\\partial y_k} = \\frac{d\\mathcal{L}_k}{du} \\frac{\\partial u}{\\partial y_k} = 2u \\cdot \\frac{\\partial}{\\partial y_k}(T y_k - \\hat{n}_k)\n$$\nSubstituting $u$ back and performing the derivative with respect to $y_k$ (treating $T$ and $\\hat{n}_k$ as constants) yields:\n$$\n\\frac{\\partial \\mathcal{L}_k}{\\partial y_k} = 2(T y_k - \\hat{n}_k) \\cdot T = 2T(T y_k - \\hat{n}_k)\n$$\nNow, we substitute this gradient expression back into the formula for the nudging current:\n$$\nI_k^{\\text{nudge}} = -\\beta \\left[ 2T(T y_k - \\hat{n}_k) \\right] = -2\\beta T(T y_k - \\hat{n}_k)\n$$\nThis is the closed-form analytic expression for the nudging current in terms of the given variables $T$, $y_k$, $\\hat{n}_k$, and $\\beta$.\n\nFor further insight, we can analyze the term $T y_k$. The readout $y_k$ is defined as $y_k = \\sum_{t=1}^{T} \\kappa(t) s_k(t)$ with the kernel $\\kappa(t) = \\frac{1}{T}$. Substituting this gives:\n$$\nT y_k = T \\left( \\sum_{t=1}^{T} \\frac{1}{T} s_k(t) \\right) = \\sum_{t=1}^{T} s_k(t)\n$$\nSince $s_k(t)$ is either $0$ or $1$, the sum $\\sum_{t=1}^{T} s_k(t)$ is the total number of spikes observed in the time window $\\{1, \\dots, T\\}$. Let's denote this total spike count as $n_k$. Therefore, $T y_k = n_k$. The quantity $(T y_k - \\hat{n}_k)$ is simply the error between the observed spike count $n_k$ and the target spike count $\\hat{n}_k$. The nudging current can also be written as $I_k^{\\text{nudge}} = -2\\beta T(n_k - \\hat{n}_k)$.\n\nNext, we compute the numerical value for the given sample:\n- Target spike count: $\\hat{n}_k = 10$.\n- Time window duration: $T = 100$.\n- Nudging strength: $\\beta = 0.01$.\n- Spike times: $t \\in \\{5, 20, 35, 50, 65, 80, 95\\}$.\n\nFirst, we determine the observed total spike count, $n_k$. The provided set of spike times contains $7$ elements, so the neuron fired $7$ times.\n$$\nn_k = \\sum_{t=1}^{100} s_k(t) = 7\n$$\nNow we can compute the value of the readout variable $y_k$:\n$$\ny_k = \\frac{n_k}{T} = \\frac{7}{100} = 0.07\n$$\nFinally, we substitute all the numerical values into our derived expression for the nudging current:\n$$\nI_k^{\\text{nudge}} = -2\\beta T(T y_k - \\hat{n}_k)\n$$\n$$\nI_k^{\\text{nudge}} = -2(0.01)(100) \\left( (100)(0.07) - 10 \\right)\n$$\n$$\nI_k^{\\text{nudge}} = -2(1) \\left( 7 - 10 \\right)\n$$\n$$\nI_k^{\\text{nudge}} = -2(-3)\n$$\n$$\nI_k^{\\text{nudge}} = 6\n$$\nThe value of the nudging current applied to the readout variable is $6$.",
            "answer": "$$\n\\boxed{6}\n$$"
        },
        {
            "introduction": "While the theory of EP often deals with continuous variables like firing rates, physical and simulated networks operate with discrete spike events. A critical practical question is how to accurately estimate these theoretical variables from observable spike trains. This final exercise delves into this measurement problem, asking you to analyze the systematic error, or bias, that arises when using a low-pass filter to estimate activity over a finite time window, a crucial consideration for any robust implementation. ",
            "id": "4043214",
            "problem": "Consider a single neuron in a spiking network operating under equilibrium propagation, with two phases: a free phase indexed by $0$ and a nudged phase indexed by $\\beta$. In each phase, the neuron emits a spike train modeled as a realization of a stationary inhomogeneous point process whose conditional intensity is piecewise constant over the measurement window. Specifically, during the free phase the conditional intensity is $r^{0}$ and during the nudged phase it is $r^{\\beta}$, where $r^{0}$ and $r^{\\beta}$ are nonnegative constants. To measure activity from spikes, use a first-order exponential low-pass filter with time constant $\\tau_{f}  0$ applied to the spike train. The filter output $y(t)$ is defined as the solution of the linear time-invariant (LTI) differential equation\n$$\n\\frac{d y(t)}{d t} = -\\frac{1}{\\tau_{f}} y(t) + \\frac{1}{\\tau_{f}} s(t),\n$$\nwith initial condition $y(0) = 0$, where $s(t)$ is the spike train represented as a sum of Dirac delta functions located at spike times. In each phase, the filtered activity is averaged over a finite measurement window of duration $T  0$ to form the estimator\n$$\n\\hat{x} = \\frac{1}{T} \\int_{0}^{T} y(t) \\, d t.\n$$\nDefine a practical estimator for the equilibrium propagation gradient surrogate as\n$$\n\\hat{g} \\equiv \\frac{1}{\\beta} \\left( \\hat{x}^{\\beta} - \\hat{x}^{0} \\right),\n$$\nwhere the superscripts indicate quantities computed in the corresponding phase, each with the filter initialized at $y(0) = 0$. The target quantity is the infinite-time equilibrium difference\n$$\ng_{\\mathrm{true}} \\equiv \\frac{1}{\\beta} \\left( x^{\\beta} - x^{0} \\right),\n$$\nwith $x^{p} \\equiv \\lim_{t \\to \\infty} y^{p}(t)$ for phase $p \\in \\{0, \\beta\\}$.\n\nStarting from first principles for LTI filtering of point processes and the definition of conditional intensity, derive a closed-form expression for the expected bias of the estimator $\\hat{g}$ due to finite-time sampling and filter transients, defined as\n$$\n\\mathrm{Bias} \\equiv \\mathbb{E}[\\hat{g}] - g_{\\mathrm{true}},\n$$\nexpressed in terms of $\\beta$, $\\tau_{f}$, $T$, $r^{\\beta}$, and $r^{0}$. Assume stationarity within each measurement window, independence between the spike trains of the two phases, and that the conditional intensities $r^{0}$ and $r^{\\beta}$ are finite, strictly nonnegative constants. Present the final result as a single closed-form analytic expression. No numerical rounding is required, and no units should be included in your final answer.",
            "solution": "The objective is to compute the bias of the estimator $\\hat{g}$, defined as $\\mathrm{Bias} \\equiv \\mathbb{E}[\\hat{g}] - g_{\\mathrm{true}}$. This requires deriving expressions for the expected value of the estimator, $\\mathbb{E}[\\hat{g}]$, and the true target quantity, $g_{\\mathrm{true}}$. We will undertake this in several steps.\n\nFirst, we determine the expected response of the low-pass filter to a spike train. For any given phase (either free, $p=0$, or nudged, $p=\\beta$), the filter output $y^p(t)$ is governed by the linear time-invariant (LTI) differential equation:\n$$\n\\frac{d y^p(t)}{d t} + \\frac{1}{\\tau_{f}} y^p(t) = \\frac{1}{\\tau_{f}} s^p(t)\n$$\nwith initial condition $y^p(0) = 0$. The input $s^p(t)$ is a spike train modeled as a realization of a stationary Poisson process with constant rate $r^p$.\n\nThe solution to this differential equation can be found by convolving the input $s^p(t)$ with the system's impulse response $h(t)$. The impulse response is the solution to $\\frac{d h(t)}{d t} + \\frac{1}{\\tau_{f}} h(t) = \\frac{1}{\\tau_{f}} \\delta(t)$ with $h(t)=0$ for $t0$, which is $h(t) = \\frac{1}{\\tau_{f}} \\exp(-t/\\tau_{f})$ for $t \\ge 0$.\nGiven the initial condition $y^p(0)=0$, the output is given by the convolution integral:\n$$\ny^p(t) = \\int_{0}^{t} h(t-\\tau) s^p(\\tau) \\, d\\tau = \\int_{0}^{t} \\frac{1}{\\tau_{f}} \\exp\\left(-\\frac{t-\\tau}{\\tau_{f}}\\right) s^p(\\tau) \\, d\\tau\n$$\nTo find the expected value of the output, we take the expectation of the above expression. By linearity of expectation and Fubini's theorem, we can move the expectation operator inside the integral. The expectation of a stationary Poisson process $s^p(t)$ is its rate, $\\mathbb{E}[s^p(t)] = r^p$.\n$$\n\\mathbb{E}[y^p(t)] = \\int_{0}^{t} \\frac{1}{\\tau_{f}} \\exp\\left(-\\frac{t-\\tau}{\\tau_{f}}\\right) \\mathbb{E}[s^p(\\tau)] \\, d\\tau = \\int_{0}^{t} \\frac{1}{\\tau_{f}} \\exp\\left(-\\frac{t-\\tau}{\\tau_{f}}\\right) r^p \\, d\\tau\n$$\nLet's evaluate this integral. Let $u = t - \\tau$, so $du = -d\\tau$. The limits of integration change from $\\tau=0$ to $u=t$ and from $\\tau=t$ to $u=0$.\n$$\n\\mathbb{E}[y^p(t)] = \\frac{r^p}{\\tau_f} \\int_{t}^{0} \\exp(-u/\\tau_f) (-du) = \\frac{r^p}{\\tau_f} \\int_{0}^{t} \\exp(-u/\\tau_f) \\, du\n$$\n$$\n\\mathbb{E}[y^p(t)] = \\frac{r^p}{\\tau_f} \\left[ -\\tau_f \\exp(-u/\\tau_f) \\right]_{0}^{t} = -r^p \\left[ \\exp(-t/\\tau_f) - \\exp(0) \\right]\n$$\n$$\n\\mathbb{E}[y^p(t)] = r^p \\left(1 - \\exp(-t/\\tau_f)\\right)\n$$\nThis expression gives the expected filter output at time $t$, starting from zero initial conditions.\n\nNext, we compute the expected value of the estimator $\\hat{x}^p$, which is the time-average of $y^p(t)$ over the interval $[0, T]$.\n$$\n\\mathbb{E}[\\hat{x}^p] = \\mathbb{E}\\left[\\frac{1}{T} \\int_{0}^{T} y^p(t) \\, dt\\right] = \\frac{1}{T} \\int_{0}^{T} \\mathbb{E}[y^p(t)] \\, dt\n$$\nSubstituting the expression for $\\mathbb{E}[y^p(t)]$:\n$$\n\\mathbb{E}[\\hat{x}^p] = \\frac{1}{T} \\int_{0}^{T} r^p \\left(1 - \\exp(-t/\\tau_f)\\right) \\, dt = \\frac{r^p}{T} \\left[ t + \\tau_f \\exp(-t/\\tau_f) \\right]_{0}^{T}\n$$\n$$\n\\mathbb{E}[\\hat{x}^p] = \\frac{r^p}{T} \\left( \\left(T + \\tau_f \\exp(-T/\\tau_f)\\right) - \\left(0 + \\tau_f \\exp(0)\\right) \\right)\n$$\n$$\n\\mathbb{E}[\\hat{x}^p] = \\frac{r^p}{T} \\left( T - \\tau_f + \\tau_f \\exp(-T/\\tau_f) \\right) = r^p \\left( 1 - \\frac{\\tau_f}{T} \\left(1 - \\exp(-T/\\tau_f)\\right) \\right)\n$$\nAn alternative arrangement of the terms is:\n$$\n\\mathbb{E}[\\hat{x}^p] = r^p \\left( 1 + \\frac{\\tau_f}{T} \\left(\\exp(-T/\\tau_f) - 1\\right) \\right)\n$$\n\nNow we can compute the expected value of the gradient surrogate estimator, $\\mathbb{E}[\\hat{g}]$.\n$$\n\\mathbb{E}[\\hat{g}] = \\mathbb{E}\\left[\\frac{1}{\\beta} \\left( \\hat{x}^{\\beta} - \\hat{x}^{0} \\right)\\right] = \\frac{1}{\\beta} \\left( \\mathbb{E}[\\hat{x}^{\\beta}] - \\mathbb{E}[\\hat{x}^{0}] \\right)\n$$\nUsing the expression for $\\mathbb{E}[\\hat{x}^p]$ for both phases:\n$$\n\\mathbb{E}[\\hat{g}] = \\frac{1}{\\beta} \\left[ r^{\\beta} \\left( 1 + \\frac{\\tau_f}{T} (\\exp(-T/\\tau_f) - 1) \\right) - r^{0} \\left( 1 + \\frac{\\tau_f}{T} (\\exp(-T/\\tau_f) - 1) \\right) \\right]\n$$\nFactoring out the common term:\n$$\n\\mathbb{E}[\\hat{g}] = \\frac{r^{\\beta} - r^{0}}{\\beta} \\left( 1 + \\frac{\\tau_f}{T} \\left(\\exp(-T/\\tau_f) - 1\\right) \\right)\n$$\n\nThe next step is to determine the true target quantity, $g_{\\mathrm{true}}$. It is defined in terms of the infinite-time equilibrium activities, $x^p \\equiv \\lim_{t \\to \\infty} y^p(t)$. For a stochastic process, this limit is properly interpreted as the steady-state mean value.\n$$\nx^p = \\lim_{t \\to \\infty} \\mathbb{E}[y^p(t)] = \\lim_{t \\to \\infty} r^p \\left(1 - \\exp(-t/\\tau_f)\\right) = r^p\n$$\nTherefore, the true gradient is:\n$$\ng_{\\mathrm{true}} = \\frac{1}{\\beta} \\left( x^{\\beta} - x^{0} \\right) = \\frac{r^{\\beta} - r^{0}}{\\beta}\n$$\n\nFinally, we compute the bias by subtracting $g_{\\mathrm{true}}$ from $\\mathbb{E}[\\hat{g}]$.\n$$\n\\mathrm{Bias} = \\mathbb{E}[\\hat{g}] - g_{\\mathrm{true}} = \\frac{r^{\\beta} - r^{0}}{\\beta} \\left( 1 + \\frac{\\tau_f}{T} \\left(\\exp(-T/\\tau_f) - 1\\right) \\right) - \\frac{r^{\\beta} - r^{0}}{\\beta}\n$$\n$$\n\\mathrm{Bias} = \\frac{r^{\\beta} - r^{0}}{\\beta} \\left[ \\left( 1 + \\frac{\\tau_f}{T} \\left(\\exp(-T/\\tau_f) - 1\\right) \\right) - 1 \\right]\n$$\n$$\n\\mathrm{Bias} = \\frac{r^{\\beta} - r^{0}}{\\beta} \\left[ \\frac{\\tau_f}{T} \\left(\\exp(-T/\\tau_f) - 1\\right) \\right]\n$$\nThis gives the final closed-form expression for the bias. It arises from the combined effects of the filter's transient response and the finite averaging window, both of which prevent the estimator from converging to the true asymptotic value.\nWe can rearrange the expression slightly for the final answer.\n$$\n\\mathrm{Bias} = \\frac{(r^{\\beta} - r^{0})\\tau_{f}}{\\beta T} \\left( \\exp\\left(-\\frac{T}{\\tau_{f}}\\right) - 1 \\right)\n$$",
            "answer": "$$\n\\boxed{\\frac{(r^{\\beta} - r^{0})\\tau_{f}}{\\beta T} \\left( \\exp\\left(-\\frac{T}{\\tau_{f}}\\right) - 1 \\right)}\n$$"
        }
    ]
}