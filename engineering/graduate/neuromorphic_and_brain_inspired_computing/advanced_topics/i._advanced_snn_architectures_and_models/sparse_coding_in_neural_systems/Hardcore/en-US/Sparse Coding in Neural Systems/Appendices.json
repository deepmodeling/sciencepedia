{
    "hands_on_practices": [
        {
            "introduction": "The ubiquitous $\\ell_{1}$-regularized sparse coding objective often appears as a given, but its form is deeply rooted in probabilistic principles. This practice delves into these theoretical underpinnings by framing sparse coding as a Bayesian inference problem . By deriving the Maximum a Posteriori (MAP) estimator for a signal model with Gaussian noise and a sparsity-promoting Laplace prior on the coefficients, you will see how these assumptions naturally give rise to the familiar $\\ell_{1}$-regularized least squares cost function.",
            "id": "4058323",
            "problem": "In a neuromorphic sparse coding front-end, an input vector $\\mathbf{x} \\in \\mathbb{R}^{n}$ is modeled by a linear generative process with additive noise, $\\mathbf{x} = \\mathbf{D}\\mathbf{a} + \\boldsymbol{\\varepsilon}$, where $\\mathbf{D} \\in \\mathbb{R}^{n \\times m}$ is a fixed dictionary, $\\mathbf{a} \\in \\mathbb{R}^{m}$ is a coefficient vector, and $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^{2}\\mathbf{I}_{n})$ is zero-mean Gaussian noise with variance $\\sigma^{2}  0$. Assume a sparsity-promoting prior over coefficients in which components of $\\mathbf{a}$ are independent and identically distributed with a Laplace (double-exponential) distribution parameterized by $\\beta  0$, that is $p(\\mathbf{a}) \\propto \\exp\\!\\big(-\\beta \\lVert \\mathbf{a} \\rVert_{1}\\big)$. Using Bayes’ rule and only fundamental definitions of likelihoods and priors, derive the Maximum a Posteriori (MAP) estimator of $\\mathbf{a}$ given $\\mathbf{x}$ and show that it is equivalent, up to additive constants and multiplication by a positive scalar that does not change the minimizer, to minimizing an $\\ell_{1}$-regularized reconstruction error of the form\n$$\n\\frac{1}{2}\\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2} + \\lambda \\lVert \\mathbf{a} \\rVert_{1}.\n$$\nWhat is the closed-form analytic expression, in terms of $\\sigma$ and $\\beta$, for the regularization weight $\\lambda$ that yields this equivalence? Your final answer must be a single analytic expression and must not include units.",
            "solution": "The objective is to find the Maximum a Posteriori (MAP) estimator for the coefficient vector $\\mathbf{a}$ given the input vector $\\mathbf{x}$, and from this derivation, determine the expression for the regularization weight $\\lambda$.\n\nThe MAP estimate of $\\mathbf{a}$, denoted $\\hat{\\mathbf{a}}_{\\text{MAP}}$, is the value of $\\mathbf{a}$ that maximizes the posterior probability distribution $p(\\mathbf{a} | \\mathbf{x})$. According to Bayes’ rule, the posterior is given by:\n$$\np(\\mathbf{a} | \\mathbf{x}) = \\frac{p(\\mathbf{x} | \\mathbf{a}) p(\\mathbf{a})}{p(\\mathbf{x})}\n$$\nThe term $p(\\mathbf{x})$ is the marginal probability of the data, which does not depend on $\\mathbf{a}$. Therefore, maximizing the posterior $p(\\mathbf{a} | \\mathbf{x})$ with respect to $\\mathbf{a}$ is equivalent to maximizing the numerator, $p(\\mathbf{x} | \\mathbf{a}) p(\\mathbf{a})$.\n$$\n\\hat{\\mathbf{a}}_{\\text{MAP}} = \\arg\\max_{\\mathbf{a}} p(\\mathbf{a} | \\mathbf{x}) = \\arg\\max_{\\mathbf{a}} p(\\mathbf{x} | \\mathbf{a}) p(\\mathbf{a})\n$$\nSince the natural logarithm, $\\ln(\\cdot)$, is a strictly monotonically increasing function, maximizing a function is equivalent to maximizing its logarithm. This simplifies the product of probabilities into a sum of log-probabilities:\n$$\n\\hat{\\mathbf{a}}_{\\text{MAP}} = \\arg\\max_{\\mathbf{a}} \\ln\\big(p(\\mathbf{x} | \\mathbf{a}) p(\\mathbf{a})\\big) = \\arg\\max_{\\mathbf{a}} \\big(\\ln p(\\mathbf{x} | \\mathbf{a}) + \\ln p(\\mathbf{a})\\big)\n$$\nFurthermore, maximizing a function is equivalent to minimizing its negative. Thus, the MAP estimation problem can be expressed as a minimization problem:\n$$\n\\hat{\\mathbf{a}}_{\\text{MAP}} = \\arg\\min_{\\mathbf{a}} \\big(-\\ln p(\\mathbf{x} | \\mathbf{a}) - \\ln p(\\mathbf{a})\\big)\n$$\nWe now derive the two terms in this objective function, $-\\ln p(\\mathbf{x} | \\mathbf{a})$ and $-\\ln p(\\mathbf{a})$.\n\nFirst, we consider the likelihood term, $p(\\mathbf{x} | \\mathbf{a})$. The problem states the generative model is $\\mathbf{x} = \\mathbf{D}\\mathbf{a} + \\boldsymbol{\\varepsilon}$, where the noise $\\boldsymbol{\\varepsilon}$ is drawn from a zero-mean multivariate Gaussian distribution with a diagonal covariance matrix, $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^{2}\\mathbf{I}_{n})$. This implies that given $\\mathbf{a}$, the observation $\\mathbf{x}$ is Gaussian distributed with mean $\\mathbf{D}\\mathbf{a}$ and covariance $\\sigma^{2}\\mathbf{I}_{n}$. The probability density function (PDF) of the likelihood is:\n$$\np(\\mathbf{x} | \\mathbf{a}) = \\frac{1}{(2\\pi \\sigma^{2})^{n/2}} \\exp\\left( -\\frac{1}{2\\sigma^{2}} (\\mathbf{x} - \\mathbf{D}\\mathbf{a})^{T}(\\mathbf{x} - \\mathbf{D}\\mathbf{a}) \\right)\n$$\nThe term $(\\mathbf{x} - \\mathbf{D}\\mathbf{a})^{T}(\\mathbf{x} - \\mathbf{D}\\mathbf{a})$ is the squared Euclidean norm (or $\\ell_2$-norm) of the reconstruction error, $\\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2}$. So, the likelihood is:\n$$\np(\\mathbf{x} | \\mathbf{a}) = \\frac{1}{(2\\pi \\sigma^{2})^{n/2}} \\exp\\left( -\\frac{1}{2\\sigma^{2}} \\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2} \\right)\n$$\nThe negative log-likelihood is therefore:\n$$\n-\\ln p(\\mathbf{x} | \\mathbf{a}) = -\\ln\\left( \\frac{1}{(2\\pi \\sigma^{2})^{n/2}} \\right) - \\left( -\\frac{1}{2\\sigma^{2}} \\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2} \\right) = \\frac{n}{2}\\ln(2\\pi \\sigma^{2}) + \\frac{1}{2\\sigma^{2}} \\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2}\n$$\n\nNext, we consider the prior term, $p(\\mathbf{a})$. The problem states that the prior distribution over the coefficients is proportional to $\\exp(-\\beta \\lVert \\mathbf{a} \\rVert_{1})$, where $\\lVert \\mathbf{a} \\rVert_{1} = \\sum_{i=1}^{m} |a_{i}|$ is the $\\ell_1$-norm. We can write this as $p(\\mathbf{a}) = C \\exp(-\\beta \\lVert \\mathbf{a} \\rVert_{1})$, where $C$ is a normalization constant that does not depend on $\\mathbf{a}$. The negative log-prior is:\n$$\n-\\ln p(\\mathbf{a}) = -\\ln\\left( C \\exp(-\\beta \\lVert \\mathbf{a} \\rVert_{1}) \\right) = -\\ln(C) + \\beta \\lVert \\mathbf{a} \\rVert_{1}\n$$\n\nCombining the negative log-likelihood and negative log-prior, we obtain the MAP objective function to be minimized, $J(\\mathbf{a})$:\n$$\nJ(\\mathbf{a}) = -\\ln p(\\mathbf{x} | \\mathbf{a}) - \\ln p(\\mathbf{a}) = \\left(\\frac{1}{2\\sigma^{2}} \\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2} + \\frac{n}{2}\\ln(2\\pi \\sigma^{2})\\right) + \\left(\\beta \\lVert \\mathbf{a} \\rVert_{1} - \\ln(C)\\right)\n$$\nTo find the minimizer $\\hat{\\mathbf{a}}_{\\text{MAP}}$, we can drop any terms that are constant with respect to $\\mathbf{a}$. The terms $\\frac{n}{2}\\ln(2\\pi \\sigma^{2})$ and $-\\ln(C)$ are such constants. Thus, the minimization problem is equivalent to:\n$$\n\\hat{\\mathbf{a}}_{\\text{MAP}} = \\arg\\min_{\\mathbf{a}} \\left( \\frac{1}{2\\sigma^{2}} \\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2} + \\beta \\lVert \\mathbf{a} \\rVert_{1} \\right)\n$$\nThe problem asks to show that this is equivalent to minimizing an objective of the form $\\frac{1}{2}\\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2} + \\lambda \\lVert \\mathbf{a} \\rVert_{1}$. We can multiply our derived objective function by a positive scalar without changing the location of the minimum. Since $\\sigma^{2}  0$ is given, we can multiply by $\\sigma^{2}$:\n$$\n\\hat{\\mathbf{a}}_{\\text{MAP}} = \\arg\\min_{\\mathbf{a}} \\left[ \\sigma^{2} \\left( \\frac{1}{2\\sigma^{2}} \\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2} + \\beta \\lVert \\mathbf{a} \\rVert_{1} \\right) \\right]\n$$\n$$\n\\hat{\\mathbf{a}}_{\\text{MAP}} = \\arg\\min_{\\mathbf{a}} \\left( \\frac{1}{2} \\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2} + \\sigma^{2}\\beta \\lVert \\mathbf{a} \\rVert_{1} \\right)\n$$\nThis expression is now in the desired form. By comparing this to the target objective function $\\frac{1}{2}\\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2} + \\lambda \\lVert \\mathbf{a} \\rVert_{1}$, we can identify the regularization weight $\\lambda$.\nThe term $\\frac{1}{2}\\lVert \\mathbf{x} - \\mathbf{D}\\mathbf{a} \\rVert_{2}^{2}$ is the reconstruction error (data fidelity term), and the term $\\lambda \\lVert \\mathbf{a} \\rVert_{1}$ is the $\\ell_1$-regularization (sparsity-promoting) term.\nBy direct comparison, we find the relationship between $\\lambda$ and the parameters of the probabilistic model:\n$$\n\\lambda = \\sigma^{2}\\beta\n$$\nThis derivation shows that the MAP estimator for a linear generative model with Gaussian noise and a Laplace prior is equivalent to solving an $\\ell_1$-regularized least squares problem, which is also known as LASSO (Least Absolute Shrinkage and Selection Operator) or Basis Pursuit Denoising. The regularization parameter $\\lambda$ directly relates the variance of the noise, $\\sigma^2$, to the scale parameter of the sparsity-promoting prior, $\\beta$.",
            "answer": "$$\n\\boxed{\\sigma^{2}\\beta}\n$$"
        },
        {
            "introduction": "While the $\\ell_{1}$ norm effectively promotes sparsity, the $\\ell_{0}$ pseudo-norm directly measures it by counting non-zero elements, seeming to be a more direct choice. This exercise explores the critical trade-off between these two regularizers, focusing on the mathematical property of convexity and its profound implications for computational tractability . Understanding why the convex $\\ell_{1}$ norm is overwhelmingly preferred over the non-convex $\\ell_{0}$ form is essential for appreciating the design of practical, large-scale sparse coding systems.",
            "id": "4058361",
            "problem": "Consider the canonical sparse coding objective used to model efficient, low-activity neural representations in neuromorphic and brain-inspired systems. Given a signal $x \\in \\mathbb{R}^{m}$, a dictionary $D \\in \\mathbb{R}^{m \\times n}$, and a coefficient vector $a \\in \\mathbb{R}^{n}$, the cost takes the form\n$$\nF_{R}(a) \\;=\\; \\frac{1}{2}\\,\\lVert x - D a \\rVert_{2}^{2} \\;+\\; \\lambda\\, R(a),\n$$\nwhere $\\lambda \\ge 0$ controls the regularization strength and $R(a)$ is a sparsity-promoting penalty. Two canonical choices are $R(a) = \\lVert a \\rVert_{1}$ and $R(a) = \\lVert a \\rVert_{0}$, where $\\lVert a \\rVert_{1} = \\sum_{i=1}^{n} |a_{i}|$ and $\\lVert a \\rVert_{0}$ counts the number of nonzero entries in $a$.\n\nUse the following fundamental bases:\n- A function $f$ is convex if for all $u, v$ and all $\\theta \\in [0,1]$, $f(\\theta u + (1-\\theta) v) \\le \\theta f(u) + (1-\\theta) f(v)$.\n- A norm is convex, and the composition of a convex function with an affine mapping preserves convexity.\n- The sum of convex functions is convex.\n- The set of $k$-sparse vectors (vectors with at most $k$ nonzeros) can be represented as a finite union of subspaces, which is non-convex when $k \\ge 1$ and $n \\ge 2$.\n\nCompare the convexity properties and computational tractability of the corresponding optimization problems for $R(a)=\\lVert a \\rVert_{1}$ and $R(a)=\\lVert a \\rVert_{0}$ in the general case of arbitrary $D$, and explain mechanistically why $L_{1}$ is preferred in practice for large-scale sparse coding in neuromorphic and brain-inspired computing. Then answer the multiple-choice question.\n\nSelect all that apply:\n\nA. The objective with $R(a)=\\lVert a \\rVert_{1}$ is convex in $a$ for any $D$, hence admits globally optimal solutions via polynomial-time convex optimization; the objective with $R(a)=\\lVert a \\rVert_{0}$ is non-convex and, in general, solving it exactly is Nondeterministic Polynomial-time hard (NP-hard), because it entails a combinatorial search over supports of $a$. Therefore, $L_{1}$ is preferred as a convex surrogate that promotes sparsity and is computationally tractable with provable recovery guarantees under conditions such as the Restricted Isometry Property (RIP).\n\nB. Both $\\lVert a \\rVert_{1}$ and $\\lVert a \\rVert_{0}$ yield convex objectives; however, $\\lVert a \\rVert_{0}$ is computationally more expensive only because it is non-differentiable, whereas $\\lVert a \\rVert_{1}$ is differentiable and easy to optimize. Thus $L_{1}$ is preferred simply for differentiability.\n\nC. $\\lVert a \\rVert_{1}$ is non-convex but leads to sparse solutions via thresholding; $\\lVert a \\rVert_{0}$ is convex as it is the limit of $\\lVert a \\rVert_{p}$ as $p \\to 0^{+}$; hence $\\lVert a \\rVert_{0}$ is easier to optimize globally than $\\lVert a \\rVert_{1}$.\n\nD. The $L_{1}$ and $L_{0}$ objectives are equally hard in general; the only advantage of $L_{1}$ is that it yields denser solutions, which is preferred in neuromorphic hardware because it reduces switching activity.\n\nE. Although $\\lVert a \\rVert_{0}$ is non-convex in general, when $D$ is orthonormal the problem separates across coordinates and admits a closed-form solution via hard thresholding; nevertheless, $L_{1}$ is typically preferred because it remains convex for arbitrary $D$ and admits efficient algorithms such as proximal gradient methods based on soft thresholding.",
            "solution": "The user wants me to validate and solve a problem concerning the properties of sparse coding objective functions.\n\n### Step 1: Extract Givens\nThe problem statement provides the following information:\n- The sparse coding cost function is given by: $$F_{R}(a) \\;=\\; \\frac{1}{2}\\,\\lVert x - D a \\rVert_{2}^{2} \\;+\\; \\lambda\\, R(a)$$\n- Signal: $x \\in \\mathbb{R}^{m}$\n- Dictionary: $D \\in \\mathbb{R}^{m \\times n}$\n- Coefficient vector: $a \\in \\mathbb{R}^{n}$\n- Regularization strength: $\\lambda \\ge 0$\n- Sparsity-promoting penalties: $R(a) = \\lVert a \\rVert_{1}$ (the $L_1$ norm) or $R(a) = \\lVert a \\rVert_{0}$ (the $L_0$ \"norm\").\n- Definition of $L_1$ norm: $\\lVert a \\rVert_{1} = \\sum_{i=1}^{n} |a_{i}|$\n- Definition of $L_0$ \"norm\": $\\lVert a \\rVert_{0}$ counts the number of nonzero entries in $a$.\n- Fundamental bases for analysis:\n    1. A function $f$ is convex if for all $u, v$ and all $\\theta \\in [0,1]$, $f(\\theta u + (1-\\theta) v) \\le \\theta f(u) + (1-\\theta) f(v)$.\n    2. A norm is convex, and the composition of a convex function with an affine mapping preserves convexity.\n    3. The sum of convex functions is convex.\n    4. The set of $k$-sparse vectors is a non-convex union of subspaces for $k \\ge 1$ and $n \\ge 2$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is to be validated against the specified criteria.\n- **Scientifically Grounded:** The problem describes the standard mathematical formulation for sparse coding, a fundamental concept in signal processing, machine learning, and computational neuroscience. The definitions of the $L_1$ and $L_0$ penalties, the objective function, and the provided properties from convex analysis are all standard and correct. The problem is firmly grounded in established mathematical principles.\n- **Well-Posed:** The question asks for a comparison of two well-defined optimization problems based on their mathematical properties (convexity) and computational implications (tractability). The question is clear and has a definite, derivation-based answer.\n- **Objective:** The language is formal, mathematical, and free of any subjective or ambiguous terminology.\n- **Other Flaws:** The problem does not exhibit any of the listed flaws. It is not incomplete, contradictory, unrealistic, ill-posed, trivial, or unverifiable. It is a standard, non-trivial problem in the field of sparse representations.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. I will proceed with the detailed analysis and solution.\n\n### Derivation\nThe core of the problem is to analyze the convexity of the objective function $F_{R}(a)$ for two different choices of the regularization term $R(a)$. The objective function is a sum of two terms: the reconstruction error term, $f_{err}(a) = \\frac{1}{2} \\lVert x - D a \\rVert_{2}^{2}$, and the regularization term, $f_{reg}(a) = \\lambda R(a)$.\n\n**Analysis of the Reconstruction Error Term**\nLet $f_{err}(a) = \\frac{1}{2} \\lVert x - D a \\rVert_{2}^{2}$.\nThe mapping $a \\mapsto x - D a$ is an affine transformation. Let's call this $T(a) = x - D a$.\nThe function $g(y) = \\frac{1}{2} \\lVert y \\rVert_{2}^{2}$ is a convex function. Its Hessian is the identity matrix, which is positive definite.\nBased on the provided fundamental basis \"the composition of a convex function with an affine mapping preserves convexity,\" the function $f_{err}(a) = g(T(a))$ is convex in $a$ for any dictionary $D$.\n\n**Analysis of the Full Objective Function**\nAccording to the provided basis \"the sum of convex functions is convex,\" the convexity of the total objective function $F_{R}(a) = f_{err}(a) + \\lambda R(a)$ depends on the convexity of the regularization term $R(a)$, given that $\\lambda \\ge 0$.\n\n**Case 1: $L_1$ Regularization, $R(a) = \\lVert a \\rVert_{1}$**\nThe objective function is $F_{1}(a) = \\frac{1}{2} \\lVert x - D a \\rVert_{2}^{2} + \\lambda \\lVert a \\rVert_{1}$.\nThe $L_1$ norm $\\lVert a \\rVert_{1}$ is a norm. According to the provided basis \"A norm is convex,\" $\\lVert a \\rVert_{1}$ is a convex function.\nSince $\\lambda \\ge 0$, the term $\\lambda \\lVert a \\rVert_{1}$ is also convex.\nThe objective $F_{1}(a)$ is the sum of two convex functions ($f_{err}(a)$ and $\\lambda \\lVert a \\rVert_{1}$) and is therefore itself a **convex function**.\nMinimizing a convex function is a convex optimization problem. Such problems are computationally tractable, meaning a global minimum can be found efficiently (in polynomial time). This property holds for any dictionary $D$.\n\n**Case 2: $L_0$ Regularization, $R(a) = \\lVert a \\rVert_{0}$**\nThe objective function is $F_{0}(a) = \\frac{1}{2} \\lVert x - D a \\rVert_{2}^{2} + \\lambda \\lVert a \\rVert_{0}$.\nThe $L_0$ \"norm\" is not a true norm because it violates the homogeneity property ($\\lVert \\alpha a \\rVert_{0} \\neq |\\alpha| \\lVert a \\rVert_{0}$ for $\\alpha \\neq \\pm 1$). Let's check its convexity using the formal definition.\nLet $a_1 = (1, 0, \\dots, 0)^T$ and $a_2 = (0, 1, 0, \\dots, 0)^T$. Let $\\theta = 0.5$.\n$R(a_1) = \\lVert a_1 \\rVert_{0} = 1$.\n$R(a_2) = \\lVert a_2 \\rVert_{0} = 1$.\nThe convex combination is $a_{\\theta} = \\theta a_1 + (1-\\theta) a_2 = (0.5, 0.5, 0, \\dots, 0)^T$.\n$R(a_{\\theta}) = \\lVert a_{\\theta} \\rVert_{0} = 2$.\nThe convexity inequality requires $R(a_{\\theta}) \\le \\theta R(a_1) + (1-\\theta) R(a_2)$.\nPlugging in the values: $2 \\le 0.5 \\cdot 1 + 0.5 \\cdot 1 = 1$. This is false.\nTherefore, $\\lVert a \\rVert_{0}$ is a **non-convex function**.\nThe sum of the convex term $f_{err}(a)$ and the non-convex term $\\lambda \\lVert a \\rVert_{0}$ results in an objective function $F_{0}(a)$ that is, in general, **non-convex**.\nMinimizing a non-convex function is computationally hard. Finding the optimal set of non-zero coefficients for $a$ is a combinatorial problem. For a desired sparsity level $k$, one must check all $\\binom{n}{k}$ possible supports (subsets of indices for non-zero entries), which is computationally infeasible for even moderately sized $n$. This problem is known to be NP-hard.\n\n**Conclusion of Derivation**\nThe $L_1$-regularized problem is convex and computationally tractable, whereas the $L_0$-regularized problem is non-convex and NP-hard in the general case. The $L_1$ norm is the tightest convex relaxation of the $L_0$ \"norm\" and is widely used as a computationally feasible surrogate that still effectively promotes sparsity. This tractability is the primary reason for its preference in large-scale applications.\n\n### Option-by-Option Analysis\n\n**A. The objective with $R(a)=\\lVert a \\rVert_{1}$ is convex in $a$ for any $D$, hence admits globally optimal solutions via polynomial-time convex optimization; the objective with $R(a)=\\lVert a \\rVert_{0}$ is non-convex and, in general, solving it exactly is Nondeterministic Polynomial-time hard (NP-hard), because it entails a combinatorial search over supports of $a$. Therefore, $L_{1}$ is preferred as a convex surrogate that promotes sparsity and is computationally tractable with provable recovery guarantees under conditions such as the Restricted Isometry Property (RIP).**\n- This statement accurately summarizes the discussion above. The $L_1$ objective is convex for any $D$. The $L_0$ objective is non-convex and NP-hard. $L_1$ is a tractable convex surrogate for $L_0$. The mention of RIP correctly points to the theoretical guarantees associated with $L_1$ minimization in the field of compressed sensing and sparse recovery.\n- **Verdict: Correct**\n\n**B. Both $\\lVert a \\rVert_{1}$ and $\\lVert a \\rVert_{0}$ yield convex objectives; however, $\\lVert a \\rVert_{0}$ is computationally more expensive only because it is non-differentiable, whereas $\\lVert a \\rVert_{1}$ is differentiable and easy to optimize. Thus $L_{1}$ is preferred simply for differentiability.**\n- This statement contains multiple falsehoods. First, the objective with $\\lVert a \\rVert_{0}$ is not convex. Second, the reason for its difficulty is non-convexity, not just non-differentiability. Third, the $\\lVert a \\rVert_{1}$ norm is *not* differentiable at points where any component $a_i$ is zero. This non-differentiability is essential for its sparsity-promoting property.\n- **Verdict: Incorrect**\n\n**C. $\\lVert a \\rVert_{1}$ is non-convex but leads to sparse solutions via thresholding; $\\lVert a \\rVert_{0}$ is convex as it is the limit of $\\lVert a \\rVert_{p}$ as $p \\to 0^{+}$; hence $\\lVert a \\rVert_{0}$ is easier to optimize globally than $\\lVert a \\rVert_{1}$.**\n- This statement is incorrect on all points. $\\lVert a \\rVert_{1}$ is convex. $\\lVert a \\rVert_{0}$ is non-convex. The limit of a sequence of functions (the $L_p$ \"norms\" for $p \\to 0^{+}$) does not guarantee convexity of the limit function. And $\\lVert a \\rVert_{0}$ is much harder to optimize than $\\lVert a \\rVert_{1}$.\n- **Verdict: Incorrect**\n\n**D. The $L_{1}$ and $L_{0}$ objectives are equally hard in general; the only advantage of $L_{1}$ is that it yields denser solutions, which is preferred in neuromorphic hardware because it reduces switching activity.**\n- This is incorrect. The $L_1$ problem is convex and tractable, while the $L_0$ problem is NP-hard; they are not equally hard. The goal of sparse coding is to find sparse, not dense, solutions to promote low activity, which is generally associated with energy efficiency in both biological and neuromorphic systems. Denser solutions would imply *more* activity, not less.\n- **Verdict: Incorrect**\n\n**E. Although $\\lVert a \\rVert_{0}$ is non-convex in general, when $D$ is orthonormal the problem separates across coordinates and admits a closed-form solution via hard thresholding; nevertheless, $L_{1}$ is typically preferred because it remains convex for arbitrary $D$ and admits efficient algorithms such as proximal gradient methods based on soft thresholding.**\n- This statement correctly identifies a special case where the $L_0$ problem becomes tractable. If $D$ is orthonormal ($D^T D = I$), minimizing $\\frac{1}{2} \\lVert x - D a \\rVert_{2}^{2} + \\lambda \\lVert a \\rVert_{0}$ is equivalent to minimizing $\\frac{1}{2} \\lVert D^T x - a \\rVert_{2}^{2} + \\lambda \\lVert a \\rVert_{0}$. This problem is separable and the solution for each component $a_i$ is given by hard thresholding the corresponding component of $D^T x$. This part is correct. The statement then correctly argues that this is a special condition and that the key advantage of $L_1$ is its convexity and tractability for an *arbitrary* dictionary $D$, which is the more common scenario in practice. The mention of soft thresholding for $L_1$ is also accurate.\n- **Verdict: Correct**\n\nBoth options A and E provide correct and complementary explanations for the preference of $L_1$ optimization in sparse coding. Option A gives the main, overarching reason (convexity vs. NP-hardness). Option E provides a more nuanced view, acknowledging a tractable special case for $L_0$ but reinforcing the generality and robustness of the $L_1$ approach, which makes it preferable in practice where dictionaries are learned and not necessarily orthonormal. Therefore, both are correct selections.",
            "answer": "$$\\boxed{AE}$$"
        },
        {
            "introduction": "Having established a principled optimization objective, we now turn to its implementation in a dynamic, neurally plausible system. The Locally Competitive Algorithm (LCA) provides a continuous-time neural network model whose equilibrium states correspond to the solutions of the $\\ell_{1}$-regularized problem . This hands-on simulation guides you through a single computational step of the LCA, offering a concrete glimpse into how recurrent inhibition and thresholding dynamics cooperate to iteratively find a sparse representation of an input signal.",
            "id": "4058373",
            "problem": "Consider the Locally Competitive Algorithm (LCA) in sparse coding for a linear generative model with dictionary $D \\in \\mathbb{R}^{m \\times n}$ and input $x \\in \\mathbb{R}^{m}$. The LCA continuous-time membrane potential dynamics are defined by the ordinary differential equation\n$$\n\\tau \\,\\frac{d u}{d t} \\;=\\; -\\,u \\;+\\; D^{\\top} x \\;-\\; \\big(D^{\\top} D - I\\big)\\,a,\n$$\nwhere $u \\in \\mathbb{R}^{n}$ is the membrane potential vector, $a \\in \\mathbb{R}^{n}$ is the activity vector given by a component-wise soft-threshold nonlinearity $a_i \\,=\\, \\operatorname{sign}(u_i)\\max\\{|u_i|-\\lambda,\\,0\\}$ with threshold $\\lambda  0$, and $I$ is the $n \\times n$ identity matrix. Use a forward Euler discretization with time step $\\Delta t$ to simulate a single update from time $t$ to time $t+\\Delta t$:\n$$\nu^{t+1} \\;=\\; u^{t} \\;+\\; \\frac{\\Delta t}{\\tau}\\left(-\\,u^{t} \\;+\\; D^{\\top} x \\;-\\; \\big(D^{\\top} D - I\\big)\\,a^{t}\\right), \\quad a^{t} \\,=\\, \\operatorname{sign}(u^{t})\\max\\{|u^{t}|-\\lambda,\\,0\\}\\;\\text{(component-wise)}.\n$$\nLet the dictionary have $m=2$ and $n=3$ with columns\n$$\nd_{1} \\,=\\, \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix},\\quad\nd_{2} \\,=\\, \\begin{pmatrix} 0.8 \\\\ 0.6 \\end{pmatrix},\\quad\nd_{3} \\,=\\, \\begin{pmatrix} 0.6 \\\\ 0.8 \\end{pmatrix},\n$$\nso that $D \\,=\\, \\begin{pmatrix} 1  0.8  0.6 \\\\ 0  0.6  0.8 \\end{pmatrix}$. Let the input be $x \\,=\\, \\begin{pmatrix} 1.1 \\\\ 0.7 \\end{pmatrix}$, the current membrane potential be $u^{t} \\,=\\, \\begin{pmatrix} 0.9 \\\\ 0.2 \\\\ 0.4 \\end{pmatrix}$, the threshold be $\\lambda \\,=\\, 0.3$, the membrane time constant be $\\tau \\,=\\, 2$, and the step size be $\\Delta t \\,=\\, 0.5$. Compute the one-step update $u^{t+1}$ and the resulting activity $a^{t+1}$ using the definitions above. Express your final answer as a single row matrix listing the six entries in the order $(u^{t+1}_{1},\\,u^{t+1}_{2},\\,u^{t+1}_{3},\\,a^{t+1}_{1},\\,a^{t+1}_{2},\\,a^{t+1}_{3})$. Provide exact decimal values without rounding.",
            "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, objective, and complete. All necessary data and definitions for a single computational step of the Locally Competitive Algorithm (LCA) are provided, and there are no internal contradictions or ambiguities. We may therefore proceed with the solution.\n\nThe problem asks for a one-step update of the membrane potential vector $u$ and the corresponding activity vector $a$. The forward Euler discretization of the LCA dynamics is given by:\n$$u^{t+1} = u^{t} + \\frac{\\Delta t}{\\tau}\\left(-u^{t} + D^{\\top} x - \\left(D^{\\top} D - I\\right)a^{t}\\right)$$\nThe activities are related to the potentials via a soft-thresholding function:\n$$a_i = \\operatorname{sign}(u_i)\\max\\{|u_i|-\\lambda, 0\\}$$\nwhich is applied component-wise.\n\nThe given parameters are:\n- Dictionary $D = \\begin{pmatrix} 1  0.8  0.6 \\\\ 0  0.6  0.8 \\end{pmatrix}$\n- Input vector $x = \\begin{pmatrix} 1.1 \\\\ 0.7 \\end{pmatrix}$\n- Current membrane potential $u^{t} = \\begin{pmatrix} 0.9 \\\\ 0.2 \\\\ 0.4 \\end{pmatrix}$\n- Threshold $\\lambda = 0.3$\n- Time constant $\\tau = 2$\n- Time step $\\Delta t = 0.5$\n\nWe will compute the required quantities step by step.\n\n**Step 1: Compute the current activity vector $a^t$**\nUsing the component-wise soft-thresholding function with $u^t$ and $\\lambda = 0.3$:\n$$a_1^t = \\operatorname{sign}(u_1^t)\\max\\{|u_1^t|-\\lambda, 0\\} = \\operatorname{sign}(0.9)\\max\\{|0.9|-0.3, 0\\} = 1 \\cdot \\max\\{0.6, 0\\} = 0.6$$\n$$a_2^t = \\operatorname{sign}(u_2^t)\\max\\{|u_2^t|-\\lambda, 0\\} = \\operatorname{sign}(0.2)\\max\\{|0.2|-0.3, 0\\} = 1 \\cdot \\max\\{-0.1, 0\\} = 0$$\n$$a_3^t = \\operatorname{sign}(u_3^t)\\max\\{|u_3^t|-\\lambda, 0\\} = \\operatorname{sign}(0.4)\\max\\{|0.4|-0.3, 0\\} = 1 \\cdot \\max\\{0.1, 0\\} = 0.1$$\nThus, the current activity vector is $a^t = \\begin{pmatrix} 0.6 \\\\ 0 \\\\ 0.1 \\end{pmatrix}$.\n\n**Step 2: Compute the driving input term $D^\\top x$**\nThe transpose of the dictionary is $D^\\top = \\begin{pmatrix} 1  0 \\\\ 0.8  0.6 \\\\ 0.6  0.8 \\end{pmatrix}$.\n$$D^\\top x = \\begin{pmatrix} 1  0 \\\\ 0.8  0.6 \\\\ 0.6  0.8 \\end{pmatrix} \\begin{pmatrix} 1.1 \\\\ 0.7 \\end{pmatrix} = \\begin{pmatrix} (1)(1.1) + (0)(0.7) \\\\ (0.8)(1.1) + (0.6)(0.7) \\\\ (0.6)(1.1) + (0.8)(0.7) \\end{pmatrix} = \\begin{pmatrix} 1.1 \\\\ 0.88 + 0.42 \\\\ 0.66 + 0.56 \\end{pmatrix} = \\begin{pmatrix} 1.1 \\\\ 1.3 \\\\ 1.22 \\end{pmatrix}$$\n\n**Step 3: Compute the inhibitory matrix term $(D^\\top D - I)a^t$**\nFirst, we compute the Gram matrix $D^\\top D$:\n$$D^\\top D = \\begin{pmatrix} 1  0 \\\\ 0.8  0.6 \\\\ 0.6  0.8 \\end{pmatrix} \\begin{pmatrix} 1  0.8  0.6 \\\\ 0  0.6  0.8 \\end{pmatrix} = \\begin{pmatrix} 1  0.8  0.6 \\\\ 0.8  0.64+0.36  0.48+0.48 \\\\ 0.6  0.48+0.48  0.36+0.64 \\end{pmatrix} = \\begin{pmatrix} 1  0.8  0.6 \\\\ 0.8  1  0.96 \\\\ 0.6  0.96  1 \\end{pmatrix}$$\nThe inhibitory matrix is $G = D^\\top D - I$, where $I$ is the $3 \\times 3$ identity matrix:\n$$G = D^\\top D - I = \\begin{pmatrix} 1  0.8  0.6 \\\\ 0.8  1  0.96 \\\\ 0.6  0.96  1 \\end{pmatrix} - \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} = \\begin{pmatrix} 0  0.8  0.6 \\\\ 0.8  0  0.96 \\\\ 0.6  0.96  0 \\end{pmatrix}$$\nNow, we compute the inhibition term $Ga^t$:\n$$(D^\\top D - I)a^t = \\begin{pmatrix} 0  0.8  0.6 \\\\ 0.8  0  0.96 \\\\ 0.6  0.96  0 \\end{pmatrix} \\begin{pmatrix} 0.6 \\\\ 0 \\\\ 0.1 \\end{pmatrix} = \\begin{pmatrix} (0)(0.6) + (0.8)(0) + (0.6)(0.1) \\\\ (0.8)(0.6) + (0)(0) + (0.96)(0.1) \\\\ (0.6)(0.6) + (0.96)(0) + (0)(0.1) \\end{pmatrix} = \\begin{pmatrix} 0.06 \\\\ 0.48 + 0.096 \\\\ 0.36 \\end{pmatrix} = \\begin{pmatrix} 0.06 \\\\ 0.576 \\\\ 0.36 \\end{pmatrix}$$\n\n**Step 4: Compute the updated membrane potential $u^{t+1}$**\nWe assemble the terms for the update rule. The scaling factor is $\\frac{\\Delta t}{\\tau} = \\frac{0.5}{2} = 0.25$.\nThe expression in the parentheses is:\n$$-u^{t} + D^{\\top} x - (D^{\\top} D - I)a^{t} = -\\begin{pmatrix} 0.9 \\\\ 0.2 \\\\ 0.4 \\end{pmatrix} + \\begin{pmatrix} 1.1 \\\\ 1.3 \\\\ 1.22 \\end{pmatrix} - \\begin{pmatrix} 0.06 \\\\ 0.576 \\\\ 0.36 \\end{pmatrix} = \\begin{pmatrix} -0.9 + 1.1 - 0.06 \\\\ -0.2 + 1.3 - 0.576 \\\\ -0.4 + 1.22 - 0.36 \\end{pmatrix} = \\begin{pmatrix} 0.14 \\\\ 0.524 \\\\ 0.46 \\end{pmatrix}$$\nNow we perform the update:\n$$u^{t+1} = u^{t} + \\frac{\\Delta t}{\\tau} \\begin{pmatrix} 0.14 \\\\ 0.524 \\\\ 0.46 \\end{pmatrix} = \\begin{pmatrix} 0.9 \\\\ 0.2 \\\\ 0.4 \\end{pmatrix} + 0.25 \\begin{pmatrix} 0.14 \\\\ 0.524 \\\\ 0.46 \\end{pmatrix} = \\begin{pmatrix} 0.9 \\\\ 0.2 \\\\ 0.4 \\end{pmatrix} + \\begin{pmatrix} 0.035 \\\\ 0.131 \\\\ 0.115 \\end{pmatrix} = \\begin{pmatrix} 0.935 \\\\ 0.331 \\\\ 0.515 \\end{pmatrix}$$\n\n**Step 5: Compute the new activity vector $a^{t+1}$**\nUsing the updated potential $u^{t+1} = \\begin{pmatrix} 0.935 \\\\ 0.331 \\\\ 0.515 \\end{pmatrix}$ and the threshold $\\lambda = 0.3$:\n$$a_1^{t+1} = \\operatorname{sign}(0.935)\\max\\{|0.935|-0.3, 0\\} = 1 \\cdot \\max\\{0.635, 0\\} = 0.635$$\n$$a_2^{t+1} = \\operatorname{sign}(0.331)\\max\\{|0.331|-0.3, 0\\} = 1 \\cdot \\max\\{0.031, 0\\} = 0.031$$\n$$a_3^{t+1} = \\operatorname{sign}(0.515)\\max\\{|0.515|-0.3, 0\\} = 1 \\cdot \\max\\{0.215, 0\\} = 0.215$$\nThe new activity vector is $a^{t+1} = \\begin{pmatrix} 0.635 \\\\ 0.031 \\\\ 0.215 \\end{pmatrix}$.\n\nThe six values required for the final answer are:\n$u^{t+1}_{1} = 0.935$\n$u^{t+1}_{2} = 0.331$\n$u^{t+1}_{3} = 0.515$\n$a^{t+1}_{1} = 0.635$\n$a^{t+1}_{2} = 0.031$\n$a^{t+1}_{3} = 0.215$\nThese are to be presented as a single row matrix.",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.935  0.331  0.515  0.635  0.031  0.215 \\end{pmatrix}}$$"
        }
    ]
}