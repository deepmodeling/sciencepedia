## 引言
[脉冲神经网络](@entry_id:1132168)（SNN）作为一种受大脑启发的计算范式，因其事件驱动的特性和在处理时空信息方面的巨大潜力而备受关注。然而，随着SNN逐渐走向实际应用，其安全性和可靠性，特别是对抗精心设计的对抗攻击时的鲁棒性，成为了一个至关重要且亟待解决的问题。尽管SNN的生物学渊源和时空动态特性被认为可能赋予其内在的鲁棒性优势，但这些独特的性质同时也开辟了传统人工智能模型所不具备的新型攻击途径。因此，系统性地理解SNN的脆弱性来源并发展有效的防御机制，是推动神经形态计算发展的关键一步。

本文旨在为读者提供一个关于SNN[对抗鲁棒性](@entry_id:636207)的全面知识框架。在第一章“原理与机制”中，我们将从单个神经元的动力学出发，深入剖析SNN在面对扰动时的响应机制，并系统介绍攻击生成的[形式化方法](@entry_id:1125241)与核心防御理论。随后的“应用与交叉学科联系”一章将理论与实践相结合，探讨如何在考虑物理世界约束的条件下对SNN鲁棒性进行评估和验证，并揭示其与系统理论、贝叶斯推断及因果科学等前沿领域的深刻联系。最后，通过“动手实践”部分，读者将有机会通过具体的编程练习，将理论知识转化为解决实际问题的能力，从而在SNN对抗攻防这一前沿领域建立起坚实的理论基础和实践技能。

## 原理与机制

本章旨在深入探讨[脉冲神经网络](@entry_id:1132168)（SNN）[对抗鲁棒性](@entry_id:636207)的核心原理与机制。继引言之后，我们将从构成SNN的基本单元——单个神经元——出发，系统性地剖析其在面对[对抗性扰动](@entry_id:746324)时的动态响应。随后，我们将阐明[神经编码](@entry_id:263658)方式如何决定网络的“威胁平面”，并介绍不同类型的对抗攻击及其在物理世界中的可实现性。在此基础上，本章将进一步介绍用于量化和生成这些攻击的数学工具与模型，包括[脉冲序列度量](@entry_id:1132162)、梯度近似方法以及不同级别的威胁模型。最后，我们将转向防御策略，不仅涵盖基于[优化理论](@entry_id:144639)的[对抗训练](@entry_id:635216)和可验证鲁棒性等主流方法，还将探讨源于生物学的学习规则（如STDP和稳态可塑性）在增强[网络鲁棒性](@entry_id:146798)方面所扮演的独特角色。通过本章的学习，读者将能够建立一个关于SNN对抗攻防的系统性知识框架。

### [脉冲神经网络](@entry_id:1132168)对抗攻击的基础

对抗攻击旨在通过对输入施加精心设计的、通常难以察觉的微小扰动，来[诱导模](@entry_id:137976)型产生错误的输出。在SNN的背景下，输入和内部状态都是由离散的脉冲事件构成的[时空模式](@entry_id:203673)。因此，理解[对抗鲁棒性](@entry_id:636207)的第一步是探究扰动如何在这种独特的计算范式中发挥作用。

#### 单个神经元的易感性：从底层构建

SNN的鲁棒性根植于其最基本的计算单元——单个神经元的动力学特性。以广泛应用的渗漏整合发放（Leaky Integrate-and-Fire, LIF）模型为例，我们可以从第一性原理出发，分析其参数如何影响其对对抗性输入的易感性。[LIF神经元](@entry_id:1127215)的膜电位$V(t)$的亚阈值动力学由以下[微分](@entry_id:158422)方程描述：
$$
\tau_m \frac{dV(t)}{dt} = -(V(t) - V_{rest}) + R I(t)
$$
其中，$\tau_m$是[膜时间常数](@entry_id:168069)，$V_{rest}$是[静息电位](@entry_id:176014)，$R$是[膜电阻](@entry_id:174729)，$I(t)$是输入电流。当$V(t)$达到阈值$V_{th}$时，神经元发放一个脉冲，随后其电位被重置到$V_{reset}$，并进入一个持续时间为$\tau_{ref}$的不应期。

攻击者通过在良性输入电流$I_0(t)$上叠加一个扰动$\delta I(t)$来实施攻击。由于亚阈值动力学是线性的，由$\delta I(t)$引起的膜电位偏离$\delta v(t)$可以表示为：
$$
\delta v(t) = \frac{R}{\tau_m} \int_0^t \exp\left(-\frac{t-\tau'}{\tau_m}\right) \delta I(\tau') d\tau'
$$
这个公式揭示了神经元参数如何调节其对扰动的响应。

- **膜时间常数 $\tau_m$**：$\tau_m$决定了神经元对输入的“记忆”时长。它扮演着一个低通滤波器的角色。对于一个在能量（$L_2$范数）上受限的攻击，即$\int_0^T (\delta I(t))^2 dt \le \epsilon^2$，可以证明，能够造成的最大电位偏离在$T \to \infty$时与$\frac{1}{\sqrt{\tau_m}}$成正比。因此，**较大的$\tau_m$会平滑掉快速变化的输入扰动，从而降低神经元在$L_2$范数约束下的易感性**。

- **[膜电阻](@entry_id:174729) $R$**：$R$直接决定了从输入电流到膜电位的增益。从上述积分公式可以看出，$\delta v(t)$与$R$成正比。无论攻击者的扰动是以能量（$L_2$范数）还是振幅（$L_\infty$范数）来约束，**减小$R$都会直接降低神经元对任何电流扰动的响应幅度，从而提高其鲁棒性**。当然，这也意味着神经元对良性输入的敏感度会同时下降，这是一个典型的鲁棒性与性能之间的权衡。

- **阈值 $V_{th}$ 与重置电位 $V_{reset}$**：这两个参数共同定义了触发一次脉冲所需的电位变化量，即$V_{th} - V_{reset}$。**提高$V_{th}$会拉大当前电位与触发脉冲目标之间的差距，使得攻击者需要注入更大的扰动才能提前或额外地诱发脉冲**。相反，提高$V_{reset}$（使其更接近$V_{th}$）则会减小这一差距，使得神经元在发放一个脉冲后更容易被再次触发，从而降低了鲁棒性。

- **[不应期](@entry_id:152190) $\tau_{ref}$**：[不应期](@entry_id:152190)为神经元发放脉冲的最高频率设定了一个硬性上限。**增加$\tau_{ref}$会延长每次脉冲后的“静默”期，从而直接限制了在任何给定时间窗口内可能被诱发的最大脉冲数量**。这是一种有效的内在防御机制，可以抵抗旨在通过高速脉冲来破坏网络功能的攻击。

#### [神经编码](@entry_id:263658)与威胁平面

SNN的独特之处在于信息可以用多种方式编码在[脉冲序列](@entry_id:1132157)中。编码方案的选择直接定义了哪些信息是“有意义的”，从而决定了什么样的扰动是“有效的”，这塑造了我们所说的**威胁平面**（threat surface）。

- **速率编码 (Rate Coding)**：在这种编码方案中，信息由神经元在特定时间窗口内的**脉冲数量**或**平均发放频率**承载。对于一个采用速率编码的SNN，其决策对脉冲的精确时间不敏感。因此，仅仅改变[脉冲时间](@entry_id:1132155)的“[抖动](@entry_id:200248)”式攻击（jitter attack）如果不能改变总脉冲数，那么它就是无效的。有效的攻击必须通过**插入**或**删除**脉冲来直接改变发放率。

- **时间编码 (Temporal Coding)**：[时间编码](@entry_id:1132912)利用脉冲的**精确发放时刻**来承载信息。一个典型的例子是首次脉冲[延迟编码](@entry_id:1127087)（latency coding），其中信息被编码在神经元首次发放脉冲的时间$\ell_i(W)$中。在这种模式下，网络对时间的微小变化极其敏感。攻击者不再需要费力地增删脉冲，只需施加微小的扰动，轻微地**提前**或**延迟**一个脉冲的到达时间，就可能显著改变解码的特征，从而导致错误分类。

- **排序编码 (Rank-Order Coding)**：这种编码方式是[时间编码](@entry_id:1132912)的一个变种，它只关心神经元群体中首次发放脉冲的**相对顺序**（即排序），而不是它们的[绝对时间](@entry_id:265046)。例如，特征可以是神经元按$\ell_i(W)$升序排列后得到的排列$\pi(W)$。这种编码对所有脉冲的“公共模式”扰动具有内在的鲁棒性。例如，如果所有输入脉冲都被同等延迟，那么每个神经元的$\ell_i(W)$都会增加一个相同的常数，但它们的相对顺序$\pi(W)$保持不变。有效的攻击必须是**差分**的，即通过不对称地改变不同神经元的脉冲延迟，来诱导它们发放顺序的颠倒。

#### 扰动类型及其物理可实现性

抽象地讨论攻击是不够的，尤其是在旨在与物理世界交互的神经形态系统中。攻击的**物理可实现性**（physical plausibility）是一个关键考量。我们可以将SNN的扰动分为几类，并分析它们在现实硬件（如神经形态视觉传感器）中的约束。

- **加性电流扰动 (Additive Current Perturbations)**：这是最直接的攻击模型，即在神经元的输入电流上叠加一个扰动函数$\delta I(t)$。如果这种攻击发生在传感器层面，那么$\delta I(t)$必须是物理可生成的。例如，神经形态视觉传感器（如DVS）的模拟前端具有有限的**带宽 $B$**。任何通过该前端的物理信号（包括攻击信号）都将被低通滤波。因此，一个物理可实现的$\delta I(t)$其[频谱](@entry_id:276824)能量必须主要集中在带宽$B$之内，不能包含任意高频的分量。

- **脉冲插入/删除 (Spike Insertion/Deletion)**：这是对离散脉冲事件的直接操控。在传感器层面，插入一个脉冲并非易事。例如，在DVS中要在一个像素上插入一个脉冲，必须通过改变场景亮度来诱发一次真实的对数亮度变化，使其超过传感器的内置阈值$C$。此外，新插入的脉冲不能违反该像素的**[不应期](@entry_id:152190) $t_{ref}$** 和设备的最大事件率 $r_{max}$。同样，删除一个脉冲需要通过遮挡或衰减场景变化，使其不足以触发阈值。

- **[脉冲时间](@entry_id:1132155)[抖动](@entry_id:200248) (Spike-Time Jitter)**：这种攻击将一个已存在的脉冲从时间$t_k$移动到$t_k + \delta t_k$，而不改变总脉冲数。物理上，这种[抖动](@entry_id:200248)也受到严格限制。例如，将一个脉冲大幅提前（$\delta t_k \lt 0$）意味着底层的物理信号必须以更快的速率上升，这同样受限于传感器的**带宽 $B$** 和**延迟**。此外，[抖动](@entry_id:200248)后的[脉冲序列](@entry_id:1132157)仍必须满足**不应期**约束，即[抖动](@entry_id:200248)后的两个连续脉冲之间的时间间隔不能小于$t_{ref}$。

### [对抗性扰动](@entry_id:746324)的量化与生成

为了系统地研究和防御对抗攻击，我们需要能够精确地量化扰动的大小，并建立生成这些扰动的形式化模型。

#### 量化时序差异：[脉冲序列度量](@entry_id:1132162)

如何衡量两个[脉冲序列](@entry_id:1132157)之间的“距离”？这对于定义攻击的预算（即扰动的大小）至关重要。一个理想的度量应该能捕捉与[神经编码](@entry_id:263658)相关的时序差异。

一个重要且广泛应用的度量是**[van Rossum距离](@entry_id:1133705)** 。其核心思想是，先将离散的[脉冲序列](@entry_id:1132157)$s(t) = \sum_k \delta(t - t_k)$通过一个[模拟突触](@entry_id:1120995)后电流（post-synaptic current, PSC）的核函数$\kappa_\tau(t)$（如$\kappa_\tau(t) = \frac{1}{\tau} e^{-t/\tau} u(t)$）进行卷积，将其转换为一个连续的模拟信号$r(t) = (s * \kappa_\tau)(t)$。两个[脉冲序列](@entry_id:1132157)$S_1$和$S_2$之间的[van Rossum距离](@entry_id:1133705)的平方，被定义为它们对应的连续信号$r_1(t)$和$r_2(t)$之间差值的$L^2$范数的平方：
$$
d_{\mathrm{vR}}^2(S_1,S_2;\tau) = \int_{-\infty}^{\infty} \bigl((s_1 * \kappa_\tau)(t) - (s_2 * \kappa_\tau)(t)\bigr)^2 dt
$$
这个度量有一个非常直观的特性：时间常数$\tau$充当了一个可调参数，用于平衡对速率和时间的敏感度。
- 当$\tau$很**小**时，核函数衰减很快，度量对脉冲的**精确定时**极为敏感。这使其非常适合用于量化和检测旨在破坏[时间编码](@entry_id:1132912)的微小[抖动](@entry_id:200248)攻击。
- 当$\tau$很**大**时，核函数衰减很慢，度量主要反映的是两个[脉冲序列](@entry_id:1132157)在较长时间尺度上的平[均差](@entry_id:138238)异，更接近于**速率差异**。

另一个重要的度量是**[Victor-Purpura距离](@entry_id:1133806)**，它被定义为将一个[脉冲序列](@entry_id:1132157)变换为另一个所需的最少“编辑成本”。编辑操作包括以固定成本（例如，1）插入或删除一个脉冲，以及以与时间位移量$|\Delta t|$成正比的成本（例如，$\lambda |\Delta t|$）移动一个脉冲。

#### 攻击者的知识：威胁模型

根据攻击者所掌握的关于目标模型的信息和能力，我们可以将威胁模型分为三类。

- **白盒 (White-box) 模型**：这是最强的威胁模型，攻击者拥有关于目标SNN的**完全知识**。这包括[网络架构](@entry_id:268981)$\mathcal{A}$、所有参数$\theta$（权重、延迟、阈值等）、[损失函数](@entry_id:634569)$L$以及训练数据分布$\mathcal{D}$。攻击者可以观察到网络的所有内部状态，包括每一层的脉冲事件流。在这种“透明”的设定下，攻击者可以精确计算[损失函数](@entry_id:634569)关于输入的梯度$\nabla_{\mathbf{S}^{\mathrm{in}}} L$（通常通过替代梯度法），从而发动高效的基于优化的攻击。

- **黑盒 (Black-box) 模型**：这是最弱的威胁模型，攻击者对模型的内部结构一无所知。他们只能将输入提供给模型，并观察其最终输出（例如，类别标签或输出[脉冲序列](@entry_id:1132157)），就像一个**查询预言机**（query oracle）。攻击者无法直接计算梯度。因此，攻击必须依赖于其他策略，例如基于多次查询的[有限差分法](@entry_id:1124968)来估计梯度（零阶优化），或者训练一个代理模型来模仿目标模型的行为，然后对代理模型进行白盒攻击（迁移攻击）。

- **灰盒 (Gray-box) 模型**：该模型介于白盒和黑盒之间，攻击者拥有**部分信息**。一个常见的场景是，攻击者知道[网络架构](@entry_id:268981)$\mathcal{A}$，但不知道具体的权重参数$\theta$。在这种情况下，攻击者可以训练一个具有相同架构的**代理模型**（surrogate model），然后计算代理模型的梯度来生成攻击样本，并期望这些样本能成功“迁移”到目标模型上。

#### 生成攻击：梯度及其失配问题

在白盒设定下，[生成对](@entry_id:906691)抗样本最有效的方法是基于梯度。然而，SNN的脉冲发放机制是一个不连续的[阶跃函数](@entry_id:159192)（Heaviside step function），其导数在[几乎处处](@entry_id:146631)为零，在阈值处为无穷大（狄拉克$\delta$函数），这使得通过时间[反向传播](@entry_id:199535)（[BPTT](@entry_id:633900)）进行梯度计算变得不可能。

为了解决这个问题，研究者们引入了**替代梯度**（surrogate gradient）的方法。其核心思想是，在网络的[前向传播](@entry_id:193086)过程中，仍然使用不连续的硬阈值脉冲发放机制；但在[反向传播](@entry_id:199535)计算梯度时，将[阶跃函数](@entry_id:159192)的导数替换为一个连续可微的代理函数$\tilde{\sigma}'(u)$，例如一个在阈值附近有非零值的光滑“鼓包”函数。

这种做法虽然使得梯度计算成为可能，但也引入了一个根本性的问题——**梯度失配**（gradient mismatch）。攻击者基于替代梯度计算出的攻击方向，实际上是针对一个假想的、具有平滑[激活函数](@entry_id:141784)的网络的。而这个攻击最终被施加在真实的、具有不连续激活的SNN上。因此：
- 替代梯度提供了一个在阈值附近的“幻影”灵敏度，表明微小的输入变化可以导致损失的平滑变化。
- 真实SNN的损失地貌是分段常数的，只有当扰动大到足以使某个神经元的膜电位跨越阈值、从而翻转一个脉冲时，损失才会发生跳变。

这种失配意味着，基于替代梯度预测的攻击效果与攻击在真实SNN上的实际效果之间可能存在巨大差异。一个在替代模型上看起来很有效的攻击，在真实模型上可能完全无效，反之亦然。

#### 迁移攻击：从ANN到SNN的挑战

许多SNN是通过将预训练好的ANN进行转换而得到的，这引出了一类重要的攻击：将在ANN上制作的对抗样本“迁移”到转换后的SNN上。这种攻击的成功率并非百分之百，其核心障碍在于SNN的**脉冲发放和[时间积分](@entry_id:267413)过程所引入的[量化效应](@entry_id:198269)**。

考虑一个简单的ANN-to-SNN转换场景：一个ANN的[ReLU激活](@entry_id:166554)输出$a = \max\{0, z\}$（其中$z$是logit）被转换成驱动一个SNN神经元的恒定输入电流$I = \alpha a$。该神经元在时间$T$内发放的脉冲总数$N$可以被精确推导为：
$$
N = \left\lfloor \frac{T \cdot I}{V_{th}} \right\rfloor = \left\lfloor \frac{T \alpha \max\{0, z\}}{V_{th}} \right\rfloor
$$
这里的$\lfloor \cdot \rfloor$是向下[取整函数](@entry_id:265373)。这个公式清晰地揭示了[量化效应](@entry_id:198269)：
- 即使一个ANN的对抗样本成功地将logit从$z$改变为$z'$，只要$\lfloor K \cdot \max\{0, z\} \rfloor$和$\lfloor K \cdot \max\{0, z'\} \rfloor$的值相同（其中$K$是常数），SNN的输出脉冲数$N$就不会改变，攻击因此失败。SNN对那些不足以使其累积电位跨越下一个整数倍阈值的微小扰动具有内在的免疫力。
- 另一方面，如果攻击成功地将一个正的logit $z \gt 0$翻转为一个非正的logit $z' \le 0$，那么SNN的输入电流将从正值变为零，导致脉冲数从一个正数锐减到零。在这种情况下，攻击很可能成功迁移。

因此，从ANN到SNN的攻击迁移性受到SNN参数（如$T, V_{th}$）和扰动大小的共同影响，它既非必然成功，也非必然失败。

### 防御原理与鲁棒性分析

面对层出不穷的攻击手段，研究人员也发展了多种防御策略来增强SNN的鲁棒性。这些策略从基于优化的显式训练到利用生物学启发的内在机制，涵盖了多个层面。

#### [对抗训练](@entry_id:635216)：一个min-max优化框架

**[对抗训练](@entry_id:635216)**是目前最有效和最广泛应用的防御方法之一。其核心思想是将攻击过程显式地整合到训练流程中，迫使模型在学习识别良性样本的同时，也学会抵抗对抗样本。这在数学上被形式化为一个**min-max优化问题**。

给定一个训练样本$(S_i, y_i)$，标准的[经验风险最小化](@entry_id:633880)（ERM）目标是最小化模型在该样本上的损失$L(f_{\theta}(S_i), y_i)$。而在[对抗训练](@entry_id:635216)中，我们的目标是最小化**最坏情况下的损失**。这个最坏情况是在一个以$S_i$为中心、半径为$\epsilon$的“扰动球”内，由攻击者找到的能使损失最大化的对抗样本$S'$所对应的损失。因此，[对抗训练](@entry_id:635216)的总体[目标函数](@entry_id:267263)是：
$$
\min_{\theta} \frac{1}{N} \sum_{i=1}^{N} \left( \max_{S' : \, d(S', S_i) \le \epsilon} \, L\big(f_{\theta}(S'), y_i\big) \right)
$$
- **外层最小化 ($\min_{\theta}$)**：由模型训练者执行，旨在调整模型参数$\theta$以降低在最坏情况下的平均损失，从而使模型变得更加鲁棒。
- **内层最大化 ($\max_{S'}$)**：模拟攻击者的行为，对于当前固定的模型$\theta$，在给定的扰动预算$\epsilon$内（由某个[脉冲序列度量](@entry_id:1132162)$d$定义，如[Victor-Purpura距离](@entry_id:1133806)），寻找能使损失$L$最大化的对抗样本$S'$。

在实践中，这个min-max问题通常通过交替迭代的方式求解：在每一步训练中，首先通过多步梯度上升等方法近似求解内层的最大化问题以[生成对](@entry_id:906691)抗样本，然后用这些样本通过梯度下降来更新模型参数$\theta$。

#### 可验证鲁棒性：[利普希茨常数](@entry_id:146583)与保证边界

[对抗训练](@entry_id:635216)等经验性防御虽然有效，但通常无法提供**数学上可证明的**鲁棒性保证。**可验证鲁棒性**（Certified Robustness）旨在弥补这一不足，它为模型的预测在一定扰动范围内不会改变提供形式化的保证。一个强大的工具是**[利普希茨常数](@entry_id:146583)**（Lipschitz constant）。

对于一个SNN映射$f$，如果对于任意两个输入$x$和$x'$，都满足以下不等式：
$$
d_Y(f(x), f(x')) \le L \cdot d_X(x, x')
$$
那么我们称$f$是$L$-利普希茨的。这里$d_X$和$d_Y$分别是输入空间（如[van Rossum距离](@entry_id:1133705)）和输出空间（如logit向量的[无穷范数](@entry_id:637586)）的度量。[利普希茨常数](@entry_id:146583)$L$衡量了网络对输入扰动的最大敏感度。一个小的$L$值意味着即使输入有较大变化，输出的变化也会被限制在一个较小的范围内。

这个性质可以直接转化为一个鲁棒性保证。假设对于一个输入$x$，模型预测的类别为$\hat{y}(x)$，其**分类边界**（margin）为$m(x)$，即最可能的logit与第二可能的logit之差。可以证明，对于任何满足$d_X(x, x') \le \epsilon$的扰动输入$x'$，只要扰动预算$\epsilon$满足：
$$
\epsilon \lt \frac{m(x)}{2L}
$$
那么模型对$x'$的预测类别将不会改变。这个不等式提供了一个**可验证的鲁棒半径**：只要攻击者的扰动预算小于$\frac{m(x)}{2L}$，我们就可以保证模型的预测是稳定的。因此，计算或约束网络的[利普希茨常数](@entry_id:146583)成为了实现可验证鲁棒性的一个核心研究方向。

#### 生物学合理机制的角色：STDP与稳态可塑性

除了上述基于数学优化的方法，SNN的生物学渊源也为鲁棒性提供了新的视角。大脑中的神经元和突触本身就具备多种可塑性机制，这些机制在无监督或自监督的学习中，可能天然地促进了鲁棒性。

- **[脉冲时序依赖可塑性](@entry_id:1132141) (STDP)**：STDP是一种经典的Hebb学习规则，突触权重的变化取决于突触前后神经元脉冲发放的时间差$\Delta t$。通常，前神经元先于后神经元发放（因果关系）会导致[突触增强](@entry_id:171314)（长时程增强，LTP），反之则导致[突触减弱](@entry_id:181432)（[长时程抑制](@entry_id:154883)，LTD）。正因为STDP对$\Delta t$的精确值高度敏感，它也为时序攻击打开了方便之门。攻击者通过微调输入脉冲的时间，可以精确地操控$\Delta t$的值，甚至改变其符号，从而劫持学习过程，恶意地增强或削弱特定连接。

- **稳态可塑性 (Homeostatic Plasticity)**：与STDP这种快速、局部的学习规则不同，[稳态可塑性](@entry_id:151193)是一种缓慢的、全局性的[调节机制](@entry_id:926520)，旨在将神经元的活动（如平均发放率）维持在一个稳定、健康的设定点$r^*$。例如，**[突触缩放](@entry_id:174471)**（synaptic scaling）会根据神经元的整体活动水平，成比例地调整其所有输入突触的权重。如果一个神经元因为被攻击而变得过度兴奋，[突触缩放](@entry_id:174471)会下调其所有权重，从而抑制其活动。如果一个神经元变得沉寂，则会上调其权重。这种[负反馈机制](@entry_id:911944)能够**抑制极端的神经活动和权重值，防止网络进入对扰动异常敏感的不稳定状态**，从而在宏观尺度上为网络提供了对抗时序扰动的内在鲁棒性。

因此，虽然STDP本身可能引入脆弱性，但与稳态机制的结合，恰如生物大脑中的情形，可能共同作用，形成一个既能进行精细学习又能保持宏观稳定的鲁棒系统。