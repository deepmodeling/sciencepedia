{
    "hands_on_practices": [
        {
            "introduction": "神经形态视觉系统使用动态视觉传感器（DVS）来高效地捕捉场景中的变化，生成异步的事件流数据。要理解一个模型是如何处理这些独特数据的，关键在于能够将模型的决策追溯到具体的输入事件。这项练习将指导您为一个处理DVS数据的线性模型构建归因图，并使用一种基于扰动的方法来评估其解释的忠实度 ()。通过这个实践，您将掌握为事件基数据生成和验证解释的基本技术。",
            "id": "4044848",
            "problem": "在神经形态和受脑启发计算领域，您被赋予一个形式化的任务：通过计算沿运动补偿轨迹聚合事件贡献的归因图，并通过输出扰动评估这些图的忠实度，为动态视觉传感器（DVS）数据构建可解释的人工智能（AI）。目标是从线性系统理论和标准定义出发，推导并实现一个有原则的算法，并为指定的测试套件生成定量指标。\n\n基本原理和定义：\n- 动态视觉传感器（DVS）产生异步事件。设 DVS 输入为有限事件集 $\\mathcal{E} = \\{(t_i, x_i, y_i, p_i)\\}_{i=1}^N$，其中 $t_i \\in \\mathbb{R}$ 是时间，$x_i \\in \\{0,1,\\dots,N_x-1\\}$ 和 $y_i \\in \\{0,1,\\dots,N_y-1\\}$ 是以像素为单位的空间坐标，$p_i \\in \\{-1, +1\\}$ 是事件极性。设网格大小为 $N_x \\times N_y$。\n- 运动补偿使用恒定的全局光流 $\\mathbf{v} = (v_x, v_y) \\in \\mathbb{R}^2$ 和参考时间 $t_0 = \\max_i t_i$。事件 $i$ 的运动补偿位置为 $(x_i', y_i')$，定义为 $x_i' = x_i + v_x (t_0 - t_i)$ 和 $y_i' = y_i + v_y (t_0 - t_i)$。\n- 每个事件通过事件核宽度 $\\sigma_e > 0$ 的高斯核 $G_{\\sigma_e}(x,y;x_i',y_i') = \\exp\\!\\Big(-\\frac{(x-x_i')^2 + (y-y_i')^2}{2 \\sigma_e^2}\\Big)$ 渲染成一个连续值的事件图像。网格上的离散事件图像为\n$$\nI(x,y) = \\sum_{i=1}^N p_i \\, G_{\\sigma_e}(x,y;x_i',y_i') \\quad \\text{for} \\quad x \\in \\{0,\\dots,N_x-1\\},\\; y \\in \\{0,\\dots,N_y-1\\}.\n$$\n- 模型读出是一个空间权重图 $W(x,y)$，此处取为一个中心在 $(c_x,c_y) \\in \\mathbb{R}^2$ 且宽度为 $\\sigma_W > 0$ 的高斯函数 $W(x,y) = \\exp\\!\\Big(-\\frac{(x-c_x)^2 + (y-c_y)^2}{2 \\sigma_W^2}\\Big)$。\n- 模型输出由线性读出定义\n$$\nf = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} W(x,y)\\, I(x,y),\n$$\n这是一个经过充分测试的线性泛函，与线性系统的叠加原理一致。\n- 归因图由乘积定义\n$$\nA(x,y) = W(x,y)\\, I(x,y),\n$$\n对于这个线性模型，它等于积分后得到输出 $f$ 的贡献密度。\n- 通过输出扰动进行忠实度评估：定义总绝对归因质量\n$$\nM = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} |A(x,y)|.\n$$\n对于移除比例 $\\alpha \\in (0,1)$，构造一个二元掩码，将按 $|A(x,y)|$ 降序选择的像素 $(x,y)$ 的 $I(x,y)$ 值设为 $0$，直到移除的绝对归因总和至少达到 $\\alpha M$。设 $f_\\alpha$ 表示掩码应用后重新计算的模型输出。定义归一化输出下降\n$$\nD_\\alpha =\n\\begin{cases}\n\\frac{|f| - |f_\\alpha|}{|f|},  \\text{if } |f| > 0, \\\\\n0,  \\text{if } |f| = 0,\n\\end{cases}\n$$\n和在一组 $\\{\\alpha_j\\}_{j=1}^m$ 上的忠实度分数为\n$$\nS = \\frac{1}{m} \\sum_{j=1}^m D_{\\alpha_j}.\n$$\n使用绝对值确保了该度量对于事件极性流中常见的带符号输出和负归因是良定义的。\n\n算法要求：\n- 在离散网格上确定性地实现上述运动补偿、事件图像构建、归因计算和忠实度评估。\n- 当高斯中心 $(x_i',y_i')$ 位于网格之外时，使用相同的公式在网格上计算 $G_{\\sigma_e}$；对于距离较远的中心，其值自然会接近于零。\n- 严格按照定义使用参考时间 $t_0 = \\max_i t_i$。\n- 不涉及物理单位；所有量均为无量纲的网格和时间单位。不使用角度。\n- 程序必须以指定的单行输出格式生成最终结果。\n\n测试套件：\n您的程序必须使用移除比例 $\\alpha \\in \\{0.1, 0.25, 0.5\\}$（即 $m=3$）为以下四个测试用例计算 $S$。所有数字必须严格按照规定使用。\n\n- 用例 1：$N_x = 32$，$N_y = 32$，$\\sigma_e = 1.2$，$(c_x, c_y) = (16, 16)$，$\\sigma_W = 5$，$\\mathbf{v} = (1.0, 0.5)$，事件 $\\mathcal{E} = \\{(0,10,10,+1), (1,11,10,+1), (2,12,11,+1), (3,13,11,+1), (4,14,12,+1), (5,15,12,+1), (6,16,13,+1), (7,17,13,+1), (8,18,14,+1), (9,19,14,+1)\\}$。\n- 用例 2：$N_x = 32$，$N_y = 32$，$\\sigma_e = 1.0$，$(c_x, c_y) = (16, 16)$，$\\sigma_W = 4$，$\\mathbf{v} = (0.0, 0.0)$，事件 $\\mathcal{E} = \\{(0,2,2,+1), (1,3,2,-1), (2,4,3,+1), (3,5,3,-1), (4,6,4,+1)\\}$。\n- 用例 3：$N_x = 32$，$N_y = 32$，$\\sigma_e = 1.2$，$(c_x, c_y) = (24, 8)$，$\\sigma_W = 3$，$\\mathbf{v} = (5.0, 3.0)$，事件 $\\mathcal{E} = \\{(0,28,0,+1), (1,29,1,+1), (2,30,2,+1), (3,31,3,+1), (4,31,4,+1)\\}$。\n- 用例 4：$N_x = 32$，$N_y = 32$，$\\sigma_e = 1.5$，$(c_x, c_y) = (16, 16)$，$\\sigma_W = 6$，$\\mathbf{v} = (-0.5, 0.5)$，事件 $\\mathcal{E} = \\{(0,16,16,-1), (1,15,16,-1), (2,17,15,-1), (3,16,17,-1), (4,17,17,+1), (5,15,15,-1), (6,16,15,-1)\\}$。\n\n答案规格：\n- 对每个用例，计算所定义的忠实度分数 $S$。您的程序应生成单行输出，其中包含四个结果，形式为方括号内以逗号分隔的列表（例如，$[r_1,r_2,r_3,r_4]$），其中每个 $r_k$ 是一个浮点数。",
            "solution": "任务是为一个应用于处理动态视觉传感器（DVS）数据的线性模型的归因方法计算忠实度分数 $S$。解决方案通过实现一系列指定的数学运算来构建。\n\n首先，对每个测试用例，我们建立计算域和模型参数。计算域是一个大小为 $N_x \\times N_y$ 的离散网格，坐标为 $(x,y)$，其中 $x \\in \\{0, 1, \\dots, N_x-1\\}$ 且 $y \\in \\{0, 1, \\dots, N_y-1\\}$。给定的参数包括网格维度、事件核宽度 $\\sigma_e$、权重图中心 $(c_x, c_y)$ 和宽度 $\\sigma_W$、全局光流向量 $\\mathbf{v}=(v_x, v_y)$ 以及 DVS 事件集 $\\mathcal{E} = \\{(t_i, x_i, y_i, p_i)\\}_{i=1}^N$。\n\n初始步骤是对事件数据执行运动补偿。DVS 事件的异步特性意味着它们是在物体运动时于不同时间捕获的。为了创建一个单一、连贯的图像帧，我们将所有事件投影到一个共同的参考时间 $t_0$，该时间定义为最后一个事件的时间：$t_0 = \\max_i t_i$。每个事件 $i$ 的运动补偿位置 $(x_i', y_i')$ 使用所提供的恒定光流 $\\mathbf{v}$ 计算得出：\n$$x_i' = x_i + v_x (t_0 - t_i)$$\n$$y_i' = y_i + v_y (t_0 - t_i)$$\n这种变换将事件对齐，就好像它们都在 $t_0$ 时刻同时发生一样。\n\n接下来，我们通过将每个经过运动补偿的事件渲染到网格上来生成事件图像 $I(x,y)$。每个事件 $i$ 贡献一个以其补偿后位置 $(x_i', y_i')$ 为中心的高斯函数，其幅度按事件的极性 $p_i \\in \\{-1, +1\\}$ 进行缩放。最终图像 $I(x,y)$ 是所有这些贡献的线性叠加：\n$$I(x,y) = \\sum_{i=1}^N p_i \\, G_{\\sigma_e}(x,y;x_i',y_i')$$\n高斯核 $G_{\\sigma_e}$ 定义为：\n$$G_{\\sigma_e}(x,y;x_i',y_i') = \\exp\\!\\Big(-\\frac{(x-x_i')^2 + (y-y_i')^2}{2 \\sigma_e^2}\\Big)$$\n对网格上的每个像素 $(x,y)$ 都进行此求和计算。\n\n构建好事件图像 $I(x,y)$ 后，我们计算模型的输出。该模型是一个由空间权重图 $W(x,y)$ 定义的简单线性泛函，该权重图也是一个高斯分布：\n$$W(x,y) = \\exp\\!\\Big(-\\frac{(x-c_x)^2 + (y-c_y)^2}{2 \\sigma_W^2}\\Big)$$\n模型输出 $f$ 是图像 $I$ 和权重 $W$ 的点积，并在所有像素上求和：\n$$f = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} W(x,y)\\, I(x,y)$$\n对于这个线性模型，表示每个像素对总输出 $f$ 贡献的归因图 $A(x,y)$ 就是权重图和事件图像的逐点乘积：\n$$A(x,y) = W(x,y)\\, I(x,y)$$\n由此直接得出 $f = \\sum_{x,y} A(x,y)$。\n\n问题的核心是评估此归因图的忠实度。这是通过基于扰动的分析来实现的。其原理是，如果一个归因图是忠实的，那么移除具有高归因分数的输入特征（像素）应该会导致模型输出发生相应的大幅变化。\n该过程首先计算总绝对归因质量：\n$$M = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} |A(x,y)|$$\n对于集合 $\\{\\alpha_j\\}_{j=1}^m = \\{0.1, 0.25, 0.5\\}$ 中的每个指定移除比例 $\\alpha_j$，我们确定一组要“移除”的像素。这是通过将所有像素按其绝对归因 $|A(x,y)|$ 的降序排列来完成的。然后，我们从此列表的顶部选择像素，直到它们的绝对归因累积总和达到或超过目标移除质量 $\\alpha_j M$。\n\n一旦确定了要移除的像素，就通过将这些选定像素位置上 $I(x,y)$ 的值设置为 $0$ 来创建一个扰动后的事件图像 $I_{\\alpha_j}(x,y)$。然后使用这个扰动后的图像重新计算模型输出，得到 $f_{\\alpha_j}$：\n$$f_{\\alpha_j} = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} W(x,y)\\, I_{\\alpha_j}(x,y)$$\n这种移除的影响通过归一化输出下降 $D_{\\alpha_j}$ 来量化：\n$$D_{\\alpha_j} = \\frac{|f| - |f_{\\alpha_j}|}{|f|}, \\quad \\text{if } |f| > 0, \\quad \\text{and} \\quad D_{\\alpha_j}=0 \\text{ otherwise}$$\n该指标捕捉了模型输出幅度相对于其原始幅度的减小量。\n\n最后，对于给定的测试用例，总体忠实度分数 $S$ 是为每个移除比例计算的输出下降的平均值：\n$$S = \\frac{1}{m} \\sum_{j=1}^m D_{\\alpha_j}$$\n对所提供的四个测试用例中的每一个，都确定性地实现了此过程。该实现使用 `numpy` 库进行高效的基于数组的计算，确保包括带有平局处理的排序在内的所有步骤都得到一致的执行。最终输出是一个包含每个用例分数 $S$ 的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ... : Not needed for this problem.\n\ndef solve_case(Nx, Ny, sigma_e, c_xy, sigma_W, v_xy, events, alphas):\n    \"\"\"\n    Computes the faithfulness score S for a single test case.\n    \"\"\"\n    cx, cy = c_xy\n    vx, vy = v_xy\n\n    # Create coordinate grids. np.meshgrid with 'ij' indexing matches (y, x) -> (row, col)\n    # where x is columns and y is rows.\n    x_coords = np.arange(0, Nx)\n    y_coords = np.arange(0, Ny)\n    yy, xx = np.meshgrid(y_coords, x_coords, indexing='ij')\n\n    # Construct the event image I(x,y)\n    I = np.zeros((Ny, Nx), dtype=np.float64)\n    if events:\n        times = [e[0] for e in events]\n        t0 = max(times) if times else 0.0\n\n        for t_i, x_i, y_i, p_i in events:\n            # Motion compensation\n            x_prime = x_i + vx * (t0 - t_i)\n            y_prime = y_i + vy * (t0 - t_i)\n            \n            # Gaussian kernel contribution for the event\n            exponent = -((xx - x_prime)**2 + (yy - y_prime)**2) / (2.0 * sigma_e**2)\n            G = np.exp(exponent)\n            \n            # Add to event image, scaled by polarity\n            I += p_i * G\n\n    # Compute the weight map W(x,y)\n    exponent_W = -((xx - cx)**2 + (yy - cy)**2) / (2.0 * sigma_W**2)\n    W = np.exp(exponent_W)\n    \n    # Compute the attribution map A(x,y) and the original output f\n    A = W * I\n    f = np.sum(A)\n\n    # Prepare for faithfulness evaluation\n    abs_f = np.abs(f)\n    if abs_f == 0.0:\n        return 0.0\n\n    # Total absolute attribution mass M\n    M = np.sum(np.abs(A))\n    if M == 0.0:\n        # If no attribution, no change is possible. Drop is 0.\n        return 0.0\n\n    # Flatten attribution map and sort pixel indices by descending |A|\n    A_flat = A.flatten()\n    abs_A_flat = np.abs(A_flat)\n    \n    # Use 'mergesort' for a stable sort, ensuring deterministic tie-breaking.\n    # Sort in descending order by negating the values.\n    sorted_indices = np.argsort(-abs_A_flat, kind='mergesort')\n\n    # Loop over removal fractions alpha\n    output_drops = []\n    for alpha in alphas:\n        target_mass = alpha * M\n        \n        # Determine which pixels to remove\n        removed_mass = 0.0\n        pixels_to_remove_indices = []\n        for idx in sorted_indices:\n            if removed_mass >= target_mass:\n                break\n            removed_mass += abs_A_flat[idx]\n            pixels_to_remove_indices.append(idx)\n        \n        # Compute perturbed output f_alpha\n        # This can be done by summing the attributions of non-removed pixels\n        A_perturbed_flat = A_flat.copy()\n        A_perturbed_flat[pixels_to_remove_indices] = 0.0\n        f_alpha = np.sum(A_perturbed_flat)\n        \n        # Calculate normalized output drop D_alpha\n        abs_f_alpha = np.abs(f_alpha)\n        D_alpha = (abs_f - abs_f_alpha) / abs_f\n        output_drops.append(D_alpha)\n\n    # Compute final faithfulness score S\n    S = np.mean(output_drops)\n    \n    return S\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    alphas = [0.1, 0.25, 0.5]\n    \n    test_cases = [\n        {'Nx': 32, 'Ny': 32, 'sigma_e': 1.2, 'c_xy': (16, 16), 'sigma_W': 5, 'v_xy': (1.0, 0.5), 'events': [(0,10,10,1), (1,11,10,1), (2,12,11,1), (3,13,11,1), (4,14,12,1), (5,15,12,1), (6,16,13,1), (7,17,13,1), (8,18,14,1), (9,19,14,1)]},\n        {'Nx': 32, 'Ny': 32, 'sigma_e': 1.0, 'c_xy': (16, 16), 'sigma_W': 4, 'v_xy': (0.0, 0.0), 'events': [(0,2,2,1), (1,3,2,-1), (2,4,3,1), (3,5,3,-1), (4,6,4,1)]},\n        {'Nx': 32, 'Ny': 32, 'sigma_e': 1.2, 'c_xy': (24, 8), 'sigma_W': 3, 'v_xy': (5.0, 3.0), 'events': [(0,28,0,1), (1,29,1,1), (2,30,2,1), (3,31,3,1), (4,31,4,1)]},\n        {'Nx': 32, 'Ny': 32, 'sigma_e': 1.5, 'c_xy': (16, 16), 'sigma_W': 6, 'v_xy': (-0.5, 0.5), 'events': [(0,16,16,-1), (1,15,16,-1), (2,17,15,-1), (3,16,17,-1), (4,17,17,1), (5,15,15,-1), (6,16,15,-1)]}\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(\n            Nx=case['Nx'],\n            Ny=case['Ny'],\n            sigma_e=case['sigma_e'],\n            c_xy=case['c_xy'],\n            sigma_W=case['sigma_W'],\n            v_xy=case['v_xy'],\n            events=case['events'],\n            alphas=alphas\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "超越简单的线性模型，解释神经形态系统还需要我们深入理解其核心计算单元——动态脉冲神经元（如LIF模型）的行为。这项练习将引导您构建一种混合归因方法，它结合了简单的事件计数和基于代理梯度的更复杂的敏感性分析 ()。您还将评估该解释在不同输入发放模式下的稳定性，这是衡量解释方法鲁棒性的一个重要方面。",
            "id": "4044862",
            "problem": "给定一个单神经元模型，旨在模拟一个简单的神经形态处理单元。任务是构建一种混合归因方法，该方法结合了输入事件计数和基于代理的敏感度，然后评估其在不同发放机制下的稳定性。该神经元遵循漏积分-发放 (Leaky Integrate-and-Fire, LIF) 动力学，稳定性通过不同机制下的混合归因向量相对于基准机制的余弦相似度来定义。\n\n基本原理：\n- 离散时间漏积分-发放 (LIF) 神经元：对于每个时间步 $t \\in \\{0,1,\\dots,T-1\\}$，有 $N$ 个输入通道，膜电位 $u_t \\in \\mathbb{R}$ 根据以下公式演化\n$$u_{t+1} = \\lambda_m u_t + \\sum_{i=1}^{N} w_i a_i x_{i,t} - v_r z_t,$$\n其中 $z_t = H(u_t - \\theta)$ 使用 Heaviside 函数 $H(\\cdot)$ 来表示脉冲发放，$x_{i,t} \\in \\{0,1\\}$ 是通道 $i$ 在时间 $t$ 的输入事件，$w_i \\in \\mathbb{R}$ 是通道 $i$ 的突触权重，$a_i \\in \\mathbb{R}$ 是一个输入振幅缩放因子，$\\theta \\in \\mathbb{R}$ 是脉冲发放阈值，$v_r \\in \\mathbb{R}$ 是复位幅度，$\\lambda_m \\in (0,1)$ 是泄漏因子。\n\n- 代理脉冲激活：用一个平滑的代理激活函数替换不可微的脉冲指示函数 $H(u_t - \\theta)$\n$$\\sigma(u_t) = \\frac{1}{1 + \\exp\\left(-k \\cdot (u_t - \\theta)\\right)},$$\n其中斜率参数 $k > 0$，以构建代理脉冲计数\n$$Z_{\\text{sur}} = \\sum_{t=0}^{T-1} \\sigma(u_t)。$$\n\n混合归因：\n- 令 $c_i = \\sum_{t=0}^{T-1} x_{i,t}$ 为通道 $i$ 的事件计数。\n- 将通道 $i$ 相对于其振幅 $a_i$ 的基于代理的敏感度 $s_i$ 定义为代理脉冲计数的导数的对称有限差分近似：\n$$s_i \\approx \\frac{Z_{\\text{sur}}(a_i + \\varepsilon) - Z_{\\text{sur}}(a_i - \\varepsilon)}{2\\varepsilon},$$\n其中只有 $a_i$ 被 $\\pm \\varepsilon$ 扰动，而所有其他振幅 $a_j$（对于 $j \\neq i$）保持不变。\n- 对 $c_i$ 和 $s_i$ 进行归一化，以便在不同机制间进行有意义的组合：\n$$\\tilde{c}_i = \\frac{c_i}{\\sum_{j=1}^{N} c_j + \\eta}, \\quad \\tilde{s}_i = \\frac{|s_i|}{\\sum_{j=1}^{N} |s_j| + \\eta},$$\n其中 $\\eta > 0$ 是一个小的平滑常数，以防止除以零。\n- 通过凸组合定义混合归因向量 $h \\in \\mathbb{R}^N$\n$$h_i = \\alpha \\tilde{c}_i + (1 - \\alpha) \\tilde{s}_i,$$\n其中权重参数 $\\alpha \\in [0,1]$。\n\n稳定性评估：\n- 对于一组由 $r$ 索引的机制，计算混合归因向量 $h^{(r)}$。\n- 使用由 $r=0$ 索引的基准机制作为参考，并为每个机制 $r$ 计算余弦相似度：\n$$\\mathrm{sim}(r) = \\begin{cases}\n\\frac{\\langle h^{(r)}, h^{(0)} \\rangle}{\\|h^{(r)}\\|_2 \\cdot \\|h^{(0)}\\|_2},  \\text{若 } \\|h^{(r)}\\|_2 > 0 \\text{ 且 } \\|h^{(0)}\\|_2 > 0, \\\\\n0,  \\text{其他情况},\n\\end{cases}$$\n其中 $\\langle \\cdot, \\cdot \\rangle$ 是点积，$\\|\\cdot\\|_2$ 是欧几里得范数。\n\n实现规格：\n- 使用 $N = 3$ 个输入通道和 $T = 100$ 个时间步。\n- 使用 $\\lambda_m = 0.9$，$\\theta = 1.0$，$v_r = 1.0$，$k = 8.0$，$\\varepsilon = 10^{-3}$，$\\eta = 10^{-8}$，以及 $\\alpha = 0.5$。\n- 突触权重为 $w = [0.6, 0.4, -0.5]$，输入振幅为 $a = [1.0, 1.0, 1.0]$。\n- 初始化 $u_0 = 0$ 并随时间向前迭代动力学。\n- 在更新到 $u_{t+1}$ 之前，使用计算出的 $z_t = H(u_t - \\theta)$。\n\n测试机制套件：\n- 基准机制 ($r=0$)：使用固定的伪随机种子 $s = 0$，以每个时间步的概率 $p = [0.05, 0.03, 0.08]$ 生成伯努利事件。即，$x_{i,t} \\sim \\mathrm{Bernoulli}(p_i)$ 在 $t$ 和 $i$ 上独立同分布，种子为 $s$。\n- 低速率机制 ($r=1$)：伯努利分布，概率为 $p = [0.01, 0.01, 0.01]$，种子为 $s = 1$。\n- 高速率机制 ($r=2$)：伯努利分布，概率为 $p = [0.30, 0.30, 0.30]$，种子为 $s = 2$。\n- 静默机制 ($r=3$)：确定性静默，所有通道和时间步的 $x_{i,t} = 0$。\n- 爆发机制 ($r=4$)：确定性爆发，当 $t \\in \\{20,21,22,23,24\\}$ 时 $x_{1,t} = 1$，否则为 $0$；当 $t \\in \\{50,51,52\\}$ 时 $x_{2,t} = 1$，否则为 $0$；当 $t \\in \\{75,76,77,78,79\\}$ 时 $x_{3,t} = 1$，否则为 $0$。\n\n程序要求：\n- 使用上述定义，为每个机制 $r \\in \\{0,1,2,3,4\\}$ 构建混合归因 $h^{(r)}$。\n- 计算相对于基准 $r=0$ 的 $r \\in \\{1,2,3,4\\}$ 的余弦相似度值 $\\mathrm{sim}(r)$。\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起，顺序为 $[\\mathrm{sim}(1), \\mathrm{sim}(2), \\mathrm{sim}(3), \\mathrm{sim}(4)]$。输出值为无量纲浮点数，必须直接以此指定格式打印。",
            "solution": "该问题要求为单个漏积分-发放 (Leaky Integrate-and-Fire, LIF) 神经元模型构建并分析一种混合归因方法。目标是通过计算归因向量相对于基准机制的余弦相似度，来评估该归因方法在不同输入发放机制下的稳定性。\n\n解决方案的结构如下：\n1. 实现离散时间 LIF 神经元动力学。\n2. 为五个不同的操作机制生成输入脉冲序列。\n3. 为每个机制 $r$ 计算混合归因向量 $h^{(r)}$。这包括结合事件计数和基于代理的敏感度。\n4. 计算每个机制 $r \\in \\{1, 2, 3, 4\\}$ 的归因向量与基准机制向量 $h^{(0)}$ 之间的余弦相似度 $\\mathrm{sim}(r)$。\n\nLIF 模型定义为在 $T=100$ 个离散时间步长内有 $N=3$ 个输入通道。膜电位 $u_t$ 在时间 $t$ 的演化遵循：\n$$u_{t+1} = \\lambda_m u_t + \\sum_{i=1}^{N} w_i a_i x_{i,t} - v_r z_t$$\n其中 $u_0 = 0$。如果在时间 $t$ 时 $u_t \\ge \\theta$，则发放一个脉冲，记为 $z_t=1$，否则 $z_t=0$。这由 Heaviside 阶跃函数 $z_t = H(u_t - \\theta)$ 表示。给定的参数为：泄漏因子 $\\lambda_m = 0.9$，阈值 $\\theta = 1.0$，复位幅度 $v_r = 1.0$，突触权重 $w = [0.6, 0.4, -0.5]$，以及输入振幅 $a = [1.0, 1.0, 1.0]$。输入 $x_{i,t} \\in \\{0, 1\\}$ 表示来自通道 $i$ 在时间 $t$ 的脉冲事件。\n\n任务的核心是为每个机制计算混合归因向量 $h \\in \\mathbb{R}^N$。该向量是两个分量的凸组合：归一化事件计数 ($\\tilde{c}$) 和归一化基于代理的敏感度 ($\\tilde{s}$)。\n\n首先，对于给定的输入脉冲序列 $x = \\{x_{i,t}\\}_{i,t}$，我们计算每个通道 $i$ 的事件计数：\n$$c_i = \\sum_{t=0}^{T-1} x_{i,t}$$\n其次，我们计算敏感度 $s_i$。这需要一个神经元输出的可微版本。不可微的脉冲指示函数 $H(u_t - \\theta)$ 被一个平滑的代理函数——sigmoid 函数所取代：\n$$\\sigma(u_t) = \\frac{1}{1 + \\exp\\left(-k \\cdot (u_t - \\theta)\\right)}$$\n其斜率参数为 $k=8.0$。在仿真周期内的总代理脉冲计数为 $Z_{\\text{sur}} = \\sum_{t=0}^{T-1} \\sigma(u_t)$。敏感度 $s_i$ 被定义为 $Z_{\\text{sur}}$ 相对于输入振幅 $a_i$ 的近似偏导数，使用对称有限差分方案和小扰动 $\\varepsilon = 10^{-3}$ 计算：\n$$s_i \\approx \\frac{Z_{\\text{sur}}(a_i + \\varepsilon) - Z_{\\text{sur}}(a_i - \\varepsilon)}{2\\varepsilon}$$\n为了计算 $Z_{\\text{sur}}(a_i \\pm \\varepsilon)$，使用原始输入 $x$ 模拟整个 LIF 动力学，但第 $i$ 个振幅分量被扰动为 $a_i \\pm \\varepsilon$。\n\n第三，对原始事件计数 $c_i$ 和敏感度 $s_i$ 进行归一化，以确保它们在可比较的尺度上。在分母中加入一个小的常数 $\\eta=10^{-8}$ 以防止除以零。\n$$\\tilde{c}_i = \\frac{c_i}{\\sum_{j=1}^{N} c_j + \\eta}, \\quad \\tilde{s}_i = \\frac{|s_i|}{\\sum_{j=1}^{N} |s_j| + \\eta}$$\n最后，使用 $\\alpha=0.5$ 通过凸组合形成混合归因 $h_i$：\n$$h_i = \\alpha \\tilde{c}_i + (1 - \\alpha) \\tilde{s}_i$$\n\n对五个指定的机制中的每一个都执行此完整过程，从而产生五个归因向量 $h^{(0)}, h^{(1)}, h^{(2)}, h^{(3)}, h^{(4)}$。这些机制的输入脉冲序列 $x^{(r)}$ 是：\n- **基准 ($r=0$)**：从概率为 $p=[0.05, 0.03, 0.08]$ 的伯努利分布和固定的随机种子 $s=0$ 生成。\n- **低速率 ($r=1$)**：伯努利分布，概率为 $p=[0.01, 0.01, 0.01]$，种子为 $s=1$。\n- **高速率 ($r=2$)**：伯努利分布，概率为 $p=[0.30, 0.30, 0.30]$，种子为 $s=2$。\n- **静默 ($r=3$)**：确定性，所有 $i,t$ 的 $x_{i,t}=0$。\n- **爆发 ($r=4$)**：确定性，每个通道上都有模式化的爆发。\n\n通过使用余弦相似度比较每个机制 ($r \\in \\{1,2,3,4\\}$) 的归因向量与基准向量 $h^{(0)}$，来评估归因方法的稳定性：\n$$\\mathrm{sim}(r) = \\frac{\\langle h^{(r)}, h^{(0)} \\rangle}{\\|h^{(r)}\\|_2 \\cdot \\|h^{(0)}\\|_2}$$\n如果任一向量的范数为零（这在静默机制中发生），则相似度定义为 $0$。最终输出由 $r=1, 2, 3, 4$ 的计算出的相似度值组成。\n实现一个计算例程来执行这些步骤，遍历每个机制，根据需要模拟神经元动力学，计算归因向量，并最终计算所需的相似度分数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs a hybrid attribution method for a LIF neuron and assesses its stability.\n    \"\"\"\n    # Problem parameters\n    N = 3\n    T = 100\n    lamb_m = 0.9\n    theta = 1.0\n    v_r = 1.0\n    k = 8.0\n    epsilon = 1e-3\n    eta = 1e-8\n    alpha = 0.5\n    w = np.array([0.6, 0.4, -0.5])\n    a_base = np.array([1.0, 1.0, 1.0])\n    u_0 = 0.0\n\n    def simulate_lif(x, a, w, lamb_m, theta, v_r, u_0, T):\n        \"\"\"Simulates the LIF neuron dynamics and returns the membrane potential trace.\"\"\"\n        u_trace = np.zeros(T)\n        potential = u_0\n        for t in range(T):\n            u_trace[t] = potential\n            spike = 1.0 if potential >= theta else 0.0\n            input_current = np.dot(w * a, x[:, t])\n            potential = lamb_m * potential + input_current - v_r * spike\n        return u_trace\n\n    def calculate_Z_sur(u_trace, k, theta):\n        \"\"\"Calculates the surrogate spike count from a potential trace.\"\"\"\n        sigma = 1.0 / (1.0 + np.exp(-k * (u_trace - theta)))\n        return np.sum(sigma)\n\n    def calculate_h(x, a_base, w, N, T, lamb_m, theta, v_r, u_0, k, epsilon, eta, alpha):\n        \"\"\"Calculates the hybrid attribution vector for a given input.\"\"\"\n        # Step 1: Calculate event counts\n        c = np.sum(x, axis=1)\n\n        # Step 2: Calculate surrogate-based sensitivities\n        s = np.zeros(N)\n        for i in range(N):\n            # Perturb amplitude a_i positively\n            a_plus = a_base.copy()\n            a_plus[i] += epsilon\n            u_plus = simulate_lif(x, a_plus, w, lamb_m, theta, v_r, u_0, T)\n            Z_plus = calculate_Z_sur(u_plus, k, theta)\n\n            # Perturb amplitude a_i negatively\n            a_minus = a_base.copy()\n            a_minus[i] -= epsilon\n            u_minus = simulate_lif(x, a_minus, w, lamb_m, theta, v_r, u_0, T)\n            Z_minus = calculate_Z_sur(u_minus, k, theta)\n            \n            s[i] = (Z_plus - Z_minus) / (2.0 * epsilon)\n\n        # Step 3: Normalize counts and sensitivities\n        c_sum = np.sum(c)\n        c_norm = c / (c_sum + eta)\n        \n        s_abs = np.abs(s)\n        s_abs_sum = np.sum(s_abs)\n        s_norm = s_abs / (s_abs_sum + eta)\n\n        # Step 4: Compute hybrid attribution vector\n        h = alpha * c_norm + (1 - alpha) * s_norm\n        return h\n\n    # Generate input spike trains for all regimes\n    regime_inputs = []\n\n    # Regime 0: Baseline\n    rng0 = np.random.default_rng(seed=0)\n    p0 = np.array([0.05, 0.03, 0.08])\n    x0 = (rng0.random((N, T))  p0[:, np.newaxis]).astype(float)\n    regime_inputs.append(x0)\n\n    # Regime 1: Low-rate\n    rng1 = np.random.default_rng(seed=1)\n    p1 = np.array([0.01, 0.01, 0.01])\n    x1 = (rng1.random((N, T))  p1[:, np.newaxis]).astype(float)\n    regime_inputs.append(x1)\n\n    # Regime 2: High-rate\n    rng2 = np.random.default_rng(seed=2)\n    p2 = np.array([0.30, 0.30, 0.30])\n    x2 = (rng2.random((N, T))  p2[:, np.newaxis]).astype(float)\n    regime_inputs.append(x2)\n\n    # Regime 3: Silent\n    x3 = np.zeros((N, T))\n    regime_inputs.append(x3)\n\n    # Regime 4: Bursty\n    x4 = np.zeros((N, T))\n    x4[0, 20:25] = 1.0  # Burst for channel 1\n    x4[1, 50:53] = 1.0  # Burst for channel 2\n    x4[2, 75:80] = 1.0  # Burst for channel 3\n    regime_inputs.append(x4)\n\n    # Calculate hybrid attribution vector for each regime\n    h_vectors = []\n    for x in regime_inputs:\n        h = calculate_h(x, a_base, w, N, T, lamb_m, theta, v_r, u_0, k, epsilon, eta, alpha)\n        h_vectors.append(h)\n\n    # Compute cosine similarities relative to the baseline\n    h_baseline = h_vectors[0]\n    norm_h_baseline = np.linalg.norm(h_baseline)\n    \n    similarities = []\n    for r in range(1, 5):\n        h_r = h_vectors[r]\n        norm_h_r = np.linalg.norm(h_r)\n\n        if norm_h_r  0 and norm_h_baseline  0:\n            sim = np.dot(h_r, h_baseline) / (norm_h_r * norm_h_baseline)\n        else:\n            sim = 0.0\n        similarities.append(sim)\n\n    # Print the final result in the specified format\n    print(f\"[{','.join(map(str, similarities))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一个可解释的模型不仅应告诉我们它为什么做出某个预测，还应提供一个我们可以信赖的置信度。此项实践专注于量化脉冲分类器输出的可靠性，这是可解释性的一个关键组成部分 ()。您将学习如何通过计算期望校准误差（ECE）来评估模型的置信度是否与其经验准确率相符，并探索如何将脉冲输出解码为有意义的概率。",
            "id": "4044870",
            "problem": "您正在研究用于神经形态系统的可解释人工智能 (XAI)，重点是脉冲分类器的校准。在脉冲分类器中，一个离散时间观测窗口产生整数脉冲计数，这些计数被映射到类别概率。校准捕捉了预测置信度与经验准确率之间的一致性。为了可解释性，一个经过校准的脉冲分类器使其置信度值变得可解释：当一个模型输出的置信度为 $p$ 时，其在置信度接近 $p$ 的样本上的经验准确率也应接近 $p$。期望校准误差 (ECE) 量化了在各个置信度区间上，置信度与准确率之间的聚合差异。\n\n需要使用的基本原理：\n- 概率论：概率公理和贝叶斯法则。对于事件 $A$ 和 $B$，$P(B) \\neq 0$，贝叶斯法则表述为 $P(A \\mid B) = \\dfrac{P(B \\mid A) P(A)}{P(B)}$。\n- 泊松分布：对于一个表示脉冲计数的非负整数随机变量 $X$，其率参数为 $\\lambda$，且各通道之间相互独立，则似然由 $P(X=x) = e^{-\\lambda} \\dfrac{\\lambda^{x}}{x!}$ 给出，其中 $x \\in \\mathbb{N}$。\n\n必须实现两种概率解码方案来生成类别概率向量：\n- 基于率的解码：对于 $K$ 个类别，给定每个类别的脉冲计数 $s \\in \\mathbb{N}^{K}$，通过将 $s$ 归一化使其总和为 1 来输出类别概率向量 $p \\in [0,1]^{K}$。如果 $\\sum_{c=1}^{K} s_{c} = 0$，则将 $p$ 定义为均匀分布，即对所有 $c$ 都有 $p_{c} = \\dfrac{1}{K}$。\n- 使用独立泊松信道的贝叶斯解码：给定 $M$ 个神经元的脉冲向量 $x \\in \\mathbb{N}^{M}$，对于 $c \\in \\{0,1,\\dots,K-1\\}$ 的类别条件泊松率 $\\lambda_{c} \\in \\mathbb{R}_{+}^{M}$，以及类别先验 $\\pi \\in [0,1]^{K}$ 且 $\\sum_{c} \\pi_{c} = 1$，使用贝叶斯法则生成后验类别概率 $p(c \\mid x)$。此过程假设给定类别后各通道是独立的，并且每个通道都遵循泊松模型。\n\n校准计算：\n- 样本的置信度定义为 $q = \\max_{c} p_{c}$。\n- 预测类别定义为 $y^{\\text{pred}} = \\arg\\max_{c} p_{c}$，如果出现平局，则选择最小的类别索引。\n- 期望校准误差将 $[0,1]$ 区间根据置信度 $q$ 划分为 $B$ 个等宽的区间（bin），然后聚合每个区间内经验准确率与平均置信度之间的差异，并按该区间中样本的比例进行加权。空区间不计入其中。\n\n您的任务是编写一个完整、可运行的程序，该程序：\n1. 对每个测试用例，通过指定的解码方案（基于率的或贝叶斯的）计算类别概率向量。\n2. 计算每个样本的置信度 $q$、预测类别 $y^{\\text{pred}}$，并将其与真实标签 $y$ 进行比较，以衡量分类的正确性。\n3. 将置信度划分到 $B$ 个覆盖 $[0,1]$ 的等宽区间中；最右边的区间应包含置信度 $q=1$。使用区间索引 $b = \\min\\left(\\left\\lfloor q \\cdot B \\right\\rfloor, B-1\\right)$ 进行确定性分箱。\n4. 计算期望校准误差，遵循比较每个区间内的经验准确率与平均置信度、并按该区间样本比例加权的标准定义。\n5. 将每个测试用例的 ECE 作为浮点数输出。答案以小数点后六位的小数表示。\n\n测试套件规范：\n- 测试用例 1（基于率，理想校准情况）：\n  - 类别数 $K = 3$。\n  - 每个样本的脉冲计数（每行对应一个 $s \\in \\mathbb{N}^{K}$）：$[[5,0,0],[0,4,0],[0,0,3],[1,1,1],[1,1,1],[1,1,1]]$。\n  - 真实标签 $y$：$[0,1,2,0,1,2]$。\n  - 区间数 $B = 5$。\n  - 解码模式：基于率。\n- 测试用例 2（基于率，高置信度下未校准）：\n  - 类别数 $K = 3$。\n  - 每个样本的脉冲计数：$[[7,0,0],[6,0,0],[8,0,0],[5,0,0],[9,0,0],[4,0,0],[10,0,0],[3,0,0],[2,0,0],[1,0,0]]$。\n  - 真实标签 $y$：$[1,2,1,2,1,1,2,1,2,0]$。\n  - 区间数 $B = 5$。\n  - 解码模式：基于率。\n- 测试用例 3（使用独立泊松信道的贝叶斯解码）：\n  - 类别数 $K = 2$，神经元数 $M = 2$。\n  - 类别先验 $\\pi = [0.5, 0.5]$。\n  - 类别条件率 $\\lambda_{0} = [3.0, 1.0]$, $\\lambda_{1} = [1.0, 3.0]$。\n  - 每个样本的脉冲向量 $x$：$[[3,1],[1,3],[4,0],[0,4],[2,2],[2,1]]$。\n  - 真实标签 $y$：$[0,1,0,1,1,0]$。\n  - 区间数 $B = 10$。\n  - 解码模式：贝叶斯。\n- 测试用例 4（基于率，零计数和多区间的边界情况）：\n  - 类别数 $K = 3$。\n  - 每个样本的脉冲计数：$[[0,0,0],[0,0,0],[0,0,0]]$。\n  - 真实标签 $y$：$[0,1,2]$。\n  - 区间数 $B = 10$。\n  - 解码模式：基于率。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含四个测试用例的 ECE 结果。结果是一个以逗号分隔的列表，用方括号括起来，每个浮点数四舍五入到小数点后六位（例如，$[0.000000,0.900000,0.123456,0.000000]$）。",
            "solution": "该问题要求在两种不同的概率解码方案下，计算脉冲分类器的期望校准误差 (ECE)。校准是现代机器学习模型的一个关键属性，特别是在高风险领域，因为它能确保模型的输出置信度分数有意义且与其经验准确率保持一致。一个未校准的模型可能会对其错误预测抱有很高的置信度，从而导致不可靠的决策。ECE 提供了一个标准化的度量来量化这种一致性。我们应首先形式化所需的概率模型和 ECE 计算方法，然后将它们应用于具体的测试用例。\n\n核心任务是处理一组 $N$ 个样本。对于每个样本 $i$，我们都接收了输入数据（脉冲计数）和一个真实类别标签 $y^{(i)} \\in \\{0, 1, \\dots, K-1\\}$。第一步是使用两种指定方法之一计算类别概率向量 $p^{(i)} \\in [0,1]^K$。\n\n第一种方法是**基于率的解码**。此方案对按类别聚合的脉冲计数进行操作，表示为向量 $s \\in \\mathbb{N}^K$。类别 $c$ 的概率是通过将该类别的脉冲计数除以所有类别的总脉冲数来确定的。如果总脉冲数 $S = \\sum_{c=0}^{K-1} s_c$ 大于零，则概率向量 $p$ 由下式给出：\n$$p_c = \\frac{s_c}{S}$$\n在 $S=0$ 的特殊情况下，模型没有任何信息，概率被定义为在 $K$ 个类别上的均匀分布：\n$$p_c = \\frac{1}{K}$$\n\n第二种方法是使用独立泊松信道的**贝叶斯解码**。这里的输入是从 $M$ 个神经元记录的脉冲向量 $x \\in \\mathbb{N}^M$。我们得到了类别先验 $\\pi \\in [0,1]^K$（其中 $\\sum_{c=0}^{K-1} \\pi_c = 1$）和每个类别 $c$ 的类别条件脉冲率 $\\lambda_c \\in \\mathbb{R}_+^M$。目标是计算每个类别的后验概率 $p(c \\mid x)$。根据贝叶斯法则：\n$$p(c \\mid x) = \\frac{p(x \\mid c) \\pi_c}{p(x)}$$\n证据 $p(x) = \\sum_{j=0}^{K-1} p(x \\mid j) \\pi_j$ 作为归一化常数。似然 $p(x \\mid c)$ 源于一个假设：即给定类别 $c$ 时，来自每个神经元 $m$ 的脉冲计数 $x_m$ 是独立的，并遵循率参数为 $\\lambda_{c,m}$ 的泊松分布：\n$$p(x \\mid c) = \\prod_{m=0}^{M-1} P(X_m=x_m \\mid \\text{class } c) = \\prod_{m=0}^{M-1} \\frac{e^{-\\lambda_{c,m}} (\\lambda_{c,m})^{x_m}}{x_m!}$$\n为保持数值稳定性，标准做法是使用对数概率进行计算。对数似然为：\n$$\\log p(x \\mid c) = \\sum_{m=0}^{M-1} \\left( -\\lambda_{c,m} + x_m \\log \\lambda_{c,m} - \\log(x_m!) \\right)$$\n后验概率 $p_c = p(c \\mid x)$ 则是：\n$$p_c = \\frac{\\pi_c \\exp(\\log p(x \\mid c))}{\\sum_{j=0}^{K-1} \\pi_j \\exp(\\log p(x \\mid j))}$$\n请注意，对于给定的输入 $x$，$\\sum_m \\log(x_m!)$ 项对于所有类别 $j$ 都是常数。因此，它在归一化过程中会从分子和分母中抵消掉。因此，我们只需要为每个类别计算一个未归一化的对数后验概率：\n$$\\text{ULP}_c(x) = \\log \\pi_c + \\sum_{m=0}^{M-1} (x_m \\log \\lambda_{c,m} - \\lambda_{c,m})$$\n然后，使用 softmax 函数（通常通过 log-sum-exp 技巧实现以防止数值上溢/下溢）对这些对数后验概率进行归一化，从而得到最终的概率向量 $p$。\n\n一旦计算出每个样本 $i$ 的概率向量 $p^{(i)}$，我们就确定其**置信度** $q^{(i)}$ 和**预测类别** $y_{\\text{pred}}^{(i)}$：\n$$q^{(i)} = \\max_{c} p_c^{(i)}$$\n$$y_{\\text{pred}}^{(i)} = \\arg\\max_{c} p_c^{(i)}$$\n$\\arg\\max$ 中的平局通过选择最小的类别索引来解决。如果 $y_{\\text{pred}}^{(i)} = y^{(i)}$，则预测是正确的。\n\n最后，我们计算**期望校准误差 (ECE)**。置信度分数被划分到 $[0,1]$ 区间上的 $B$ 个等宽区间中。一个置信度分数 $q$ 根据规则 $b = \\min(\\lfloor q \\cdot B \\rfloor, B-1)$ 被分配到索引为 $b$ 的区间。这会将 $q=1$ 放入最后一个索引为 $B-1$ 的区间。\n对于每个包含至少一个样本的区间 $b \\in \\{0, 1, \\dots, B-1\\}$，我们计算其平均准确率 $\\text{acc}(b)$ 和平均置信度 $\\text{conf}(b)$。设 $I_b$ 是落入区间 $b$ 的样本索引集合，$n_b = |I_b|$ 是该区间中的样本数。\n$$\\text{acc}(b) = \\frac{1}{n_b} \\sum_{i \\in I_b} \\mathbf{1}(y_{\\text{pred}}^{(i)} = y^{(i)})$$\n$$\\text{conf}(b) = \\frac{1}{n_b} \\sum_{i \\in I_b} q^{(i)}$$\nECE 是所有区间准确率和置信度之间绝对差异的加权平均值：\n$$\\text{ECE} = \\sum_{b=0}^{B-1} \\frac{n_b}{N} |\\text{acc}(b) - \\text{conf}(b)|$$\n其中 $N$ 是样本总数。一个等价且计算上更简单的形式是：\n$$\\text{ECE} = \\frac{1}{N} \\sum_{b=0}^{B-1} \\left| \\sum_{i \\in I_b} \\mathbf{1}(y_{\\text{pred}}^{(i)} = y^{(i)}) - \\sum_{i \\in I_b} q^{(i)} \\right|$$\n将此过程应用于指定的四个测试用例，以得出它们各自的 ECE 值。",
            "answer": "```python\nimport numpy as np\nfrom math import log\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"decoding_mode\": \"rate-based\",\n            \"K\": 3,\n            \"s\": np.array([[5,0,0],[0,4,0],[0,0,3],[1,1,1],[1,1,1],[1,1,1]]),\n            \"y\": np.array([0,1,2,0,1,2]),\n            \"B\": 5\n        },\n        {\n            \"decoding_mode\": \"rate-based\",\n            \"K\": 3,\n            \"s\": np.array([[7,0,0],[6,0,0],[8,0,0],[5,0,0],[9,0,0],[4,0,0],[10,0,0],[3,0,0],[2,0,0],[1,0,0]]),\n            \"y\": np.array([1,2,1,2,1,1,2,1,2,0]),\n            \"B\": 5\n        },\n        {\n            \"decoding_mode\": \"Bayesian\",\n            \"K\": 2,\n            \"M\": 2,\n            \"pi\": np.array([0.5, 0.5]),\n            \"lambda\": np.array([[3.0, 1.0], [1.0, 3.0]]),\n            \"x\": np.array([[3,1],[1,3],[4,0],[0,4],[2,2],[2,1]]),\n            \"y\": np.array([0,1,0,1,1,0]),\n            \"B\": 10\n        },\n        {\n            \"decoding_mode\": \"rate-based\",\n            \"K\": 3,\n            \"s\": np.array([[0,0,0],[0,0,0],[0,0,0]]),\n            \"y\": np.array([0,1,2]),\n            \"B\": 10\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        ece = calculate_ece(case)\n        results.append(f\"{ece:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef rate_based_decoding(s_vectors, K):\n    \"\"\"Computes class probabilities using rate-based decoding.\"\"\"\n    probs = []\n    for s in s_vectors:\n        s_sum = np.sum(s)\n        if s_sum == 0:\n            probs.append(np.full(K, 1.0 / K))\n        else:\n            probs.append(s / s_sum)\n    return np.array(probs)\n\ndef bayesian_decoding(x_vectors, priors, lambdas, K):\n    \"\"\"Computes class probabilities using Bayesian decoding with Poisson assumption.\"\"\"\n    probs = []\n    log_priors = np.log(priors)\n    \n    for x in x_vectors:\n        ulps = np.zeros(K) # Unnormalized log posteriors\n        for c in range(K):\n            # sum over M neurons\n            log_likelihood = np.sum(x * np.log(lambdas[c]) - lambdas[c])\n            ulps[c] = log_priors[c] + log_likelihood\n        \n        # Log-sum-exp for stable softmax\n        max_ulp = np.max(ulps)\n        exp_ulps = np.exp(ulps - max_ulp)\n        p = exp_ulps / np.sum(exp_ulps)\n        probs.append(p)\n        \n    return np.array(probs)\n\ndef calculate_ece(case):\n    \"\"\"\n    Calculates the Expected Calibration Error for a given test case.\n    \"\"\"\n    mode = case['decoding_mode']\n    y_true = case['y']\n    B = case['B']\n    K = case['K']\n    \n    if mode == 'rate-based':\n        probs = rate_based_decoding(case['s'], K)\n    elif mode == 'Bayesian':\n        probs = bayesian_decoding(case['x'], case['pi'], case['lambda'], K)\n    else:\n        raise ValueError(\"Invalid decoding mode specified.\")\n\n    # Compute confidences, predictions, and correctness\n    confidences = np.max(probs, axis=1)\n    predictions = np.argmax(probs, axis=1) # argmax breaks ties with smallest index\n    correctness = (predictions == y_true).astype(float)\n    \n    N = len(y_true)\n    if N == 0:\n        return 0.0\n\n    # Assign each sample to a bin\n    bin_indices = np.minimum(np.floor(confidences * B), B - 1).astype(int)\n    \n    sum_conf_in_bin = np.zeros(B)\n    sum_correct_in_bin = np.zeros(B)\n    n_in_bin = np.zeros(B)\n    \n    for i in range(N):\n        bin_idx = bin_indices[i]\n        sum_conf_in_bin[bin_idx] += confidences[i]\n        sum_correct_in_bin[bin_idx] += correctness[i]\n        n_in_bin[bin_idx] += 1\n    \n    ece = 0.0\n    for b in range(B):\n        if n_in_bin[b] > 0:\n            abs_diff = np.abs(sum_correct_in_bin[b] - sum_conf_in_bin[b])\n            ece += abs_diff\n            \n    return ece / N\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}