{
    "hands_on_practices": [
        {
            "introduction": "Interpreting the sparse, asynchronous data from Dynamic Vision Sensors (DVS) is a key challenge in neuromorphic computing. This exercise provides a foundational approach to this problem by building an attribution map that connects input events to a model's decision . By starting with a tractable linear model, you will implement motion compensation to construct a coherent spatial representation and then directly compute the contribution of each pixel. More importantly, you will implement a perturbation-based faithfulness test, a critical technique for validating whether an explanation accurately reflects the model's reasoning process.",
            "id": "4044848",
            "problem": "You are given a formalized task in the domain of neuromorphic and brain-inspired computing to construct explainable Artificial Intelligence (AI) for Dynamic Vision Sensor (DVS) data by computing attribution maps that aggregate event contributions along motion-compensated trajectories and by evaluating the faithfulness of these maps through output perturbations. The goal is to derive and implement a principled algorithm starting from linear system theory and standard definitions, and to produce quantitative metrics for a specified test suite.\n\nFundamental base and definitions:\n- A Dynamic Vision Sensor (DVS) produces asynchronous events. Let the DVS input be the finite set of events $\\mathcal{E} = \\{(t_i, x_i, y_i, p_i)\\}_{i=1}^N$ where $t_i \\in \\mathbb{R}$ is time, $x_i \\in \\{0,1,\\dots,N_x-1\\}$ and $y_i \\in \\{0,1,\\dots,N_y-1\\}$ are spatial coordinates in pixel units, and $p_i \\in \\{-1, +1\\}$ is the event polarity. Let the grid size be $N_x \\times N_y$.\n- Motion compensation uses a constant global optical flow $\\mathbf{v} = (v_x, v_y) \\in \\mathbb{R}^2$ and a reference time $t_0 = \\max_i t_i$. The motion-compensated position of event $i$ is $(x_i', y_i')$ defined by $x_i' = x_i + v_x (t_0 - t_i)$ and $y_i' = y_i + v_y (t_0 - t_i)$.\n- Each event is rendered into a continuous-valued event image via a Gaussian kernel $G_{\\sigma_e}(x,y;x_i',y_i') = \\exp\\!\\Big(-\\frac{(x-x_i')^2 + (y-y_i')^2}{2 \\sigma_e^2}\\Big)$ with event kernel width $\\sigma_e  0$. The discrete event image on the grid is\n$$\nI(x,y) = \\sum_{i=1}^N p_i \\, G_{\\sigma_e}(x,y;x_i',y_i') \\quad \\text{for} \\quad x \\in \\{0,\\dots,N_x-1\\},\\; y \\in \\{0,\\dots,N_y-1\\}.\n$$\n- The model readout is a spatial weight map $W(x,y)$, taken here as a Gaussian $W(x,y) = \\exp\\!\\Big(-\\frac{(x-c_x)^2 + (y-c_y)^2}{2 \\sigma_W^2}\\Big)$ with center $(c_x,c_y) \\in \\mathbb{R}^2$ and width $\\sigma_W  0$.\n- The model output is defined by linear readout\n$$\nf = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} W(x,y)\\, I(x,y),\n$$\nwhich is a well-tested linear functional consistent with the superposition principle for linear systems.\n- The attribution map is defined by the product\n$$\nA(x,y) = W(x,y)\\, I(x,y),\n$$\nwhich, for this linear model, equals the contribution density that integrates to the output $f$.\n- Faithfulness evaluation by output perturbations: define the total absolute attribution mass\n$$\nM = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} |A(x,y)|.\n$$\nFor a removal fraction $\\alpha \\in (0,1)$, construct a binary mask that sets $I(x,y)$ to $0$ for pixels $(x,y)$ selected in descending order of $|A(x,y)|$ until the removed absolute attribution sum reaches at least $\\alpha M$. Let $f_\\alpha$ denote the model output recomputed after masking. Define the normalized output drop\n$$\nD_\\alpha =\n\\begin{cases}\n\\frac{|f| - |f_\\alpha|}{|f|},  \\text{if } |f|  0, \\\\\n0,  \\text{if } |f| = 0,\n\\end{cases}\n$$\nand the faithfulness score over a set $\\{\\alpha_j\\}_{j=1}^m$ by\n$$\nS = \\frac{1}{m} \\sum_{j=1}^m D_{\\alpha_j}.\n$$\nThe use of absolute values ensures that the measure is well-defined for signed outputs and negative attributions common in event-polarity streams.\n\nAlgorithmic requirements:\n- Implement the above motion compensation, event image construction, attribution computation, and faithfulness evaluation deterministically over the discrete grid.\n- When Gaussian centers $(x_i',y_i')$ lie outside the grid, compute $G_{\\sigma_e}$ over the grid using the same formula; values will naturally be near zero for distant centers.\n- Use the reference time $t_0 = \\max_i t_i$ exactly as defined.\n- No physical units are involved; all quantities are dimensionless grid and time units. Angles are not used.\n- The program must produce the final results in the specified single-line output format.\n\nTest suite:\nYour program must compute $S$ for each of the four test cases below using removal fractions $\\alpha \\in \\{0.1, 0.25, 0.5\\}$ (that is, $m = 3$). All numbers must be used exactly as specified.\n\n- Case $1$: $N_x = 32$, $N_y = 32$, $\\sigma_e = 1.2$, $(c_x, c_y) = (16, 16)$, $\\sigma_W = 5$, $\\mathbf{v} = (1.0, 0.5)$, events $\\mathcal{E} = \\{(0,10,10,+1), (1,11,10,+1), (2,12,11,+1), (3,13,11,+1), (4,14,12,+1), (5,15,12,+1), (6,16,13,+1), (7,17,13,+1), (8,18,14,+1), (9,19,14,+1)\\}$.\n- Case $2$: $N_x = 32$, $N_y = 32$, $\\sigma_e = 1.0$, $(c_x, c_y) = (16, 16)$, $\\sigma_W = 4$, $\\mathbf{v} = (0.0, 0.0)$, events $\\mathcal{E} = \\{(0,2,2,+1), (1,3,2,-1), (2,4,3,+1), (3,5,3,-1), (4,6,4,+1)\\}$.\n- Case $3$: $N_x = 32$, $N_y = 32$, $\\sigma_e = 1.2$, $(c_x, c_y) = (24, 8)$, $\\sigma_W = 3$, $\\mathbf{v} = (5.0, 3.0)$, events $\\mathcal{E} = \\{(0,28,0,+1), (1,29,1,+1), (2,30,2,+1), (3,31,3,+1), (4,31,4,+1)\\}$.\n- Case $4$: $N_x = 32$, $N_y = 32$, $\\sigma_e = 1.5$, $(c_x, c_y) = (16, 16)$, $\\sigma_W = 6$, $\\mathbf{v} = (-0.5, 0.5)$, events $\\mathcal{E} = \\{(0,16,16,-1), (1,15,16,-1), (2,17,15,-1), (3,16,17,-1), (4,17,17,+1), (5,15,15,-1), (6,16,15,-1)\\}$.\n\nAnswer specification:\n- For each case, compute the faithfulness score $S$ as defined. Your program should produce a single line of output containing the four results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4]$), where each $r_k$ is a floating-point number.",
            "solution": "The task is to compute a faithfulness score, $S$, for an attribution method applied to a linear model that processes Dynamic Vision Sensor (DVS) data. The solution is constructed by implementing a sequence of specified mathematical operations.\n\nFirst, for each test case, we establish the computational domain and model parameters. The domain is a discrete grid of size $N_x \\times N_y$ with coordinates $(x,y)$ where $x \\in \\{0, 1, \\dots, N_x-1\\}$ and $y \\in \\{0, 1, \\dots, N_y-1\\}$. The given parameters include the grid dimensions, the event kernel width $\\sigma_e$, the weight map center $(c_x, c_y)$ and width $\\sigma_W$, the global optical flow vector $\\mathbf{v}=(v_x, v_y)$, and the set of DVS events $\\mathcal{E} = \\{(t_i, x_i, y_i, p_i)\\}_{i=1}^N$.\n\nThe initial step is to perform motion compensation on the event data. The asynchronous nature of DVS events means they are captured at different times while an object is in motion. To create a single, coherent image frame, we project all events to a common reference time, $t_0$, defined as the time of the last event: $t_0 = \\max_i t_i$. The motion-compensated position $(x_i', y_i')$ for each event $i$ is calculated using the provided constant optical flow $\\mathbf{v}$:\n$$x_i' = x_i + v_x (t_0 - t_i)$$\n$$y_i' = y_i + v_y (t_0 - t_i)$$\nThis transformation aligns the events as if they all occurred simultaneously at $t_0$.\n\nNext, we generate the event image $I(x,y)$ by rendering each motion-compensated event onto the grid. Every event $i$ contributes a Gaussian function centered at its compensated position $(x_i', y_i')$, with its amplitude scaled by the event's polarity $p_i \\in \\{-1, +1\\}$. The final image $I(x,y)$ is the linear superposition of all such contributions:\n$$I(x,y) = \\sum_{i=1}^N p_i \\, G_{\\sigma_e}(x,y;x_i',y_i')$$\nThe Gaussian kernel $G_{\\sigma_e}$ is defined as:\n$$G_{\\sigma_e}(x,y;x_i',y_i') = \\exp\\!\\Big(-\\frac{(x-x_i')^2 + (y-y_i')^2}{2 \\sigma_e^2}\\Big)$$\nThis summation is computed for every pixel $(x,y)$ on the grid.\n\nWith the event image $I(x,y)$ constructed, we compute the model's output. The model is a simple linear functional defined by a spatial weight map, $W(x,y)$, which is also a Gaussian distribution:\n$$W(x,y) = \\exp\\!\\Big(-\\frac{(x-c_x)^2 + (y-c_y)^2}{2 \\sigma_W^2}\\Big)$$\nThe model output, $f$, is the dot product of the image $I$ and the weights $W$, summed over all pixels:\n$$f = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} W(x,y)\\, I(x,y)$$\nFor this linear model, the attribution map $A(x,y)$, which represents the contribution of each pixel to the total output $f$, is simply the pointwise product of the weight map and the event image:\n$$A(x,y) = W(x,y)\\, I(x,y)$$\nIt follows directly that $f = \\sum_{x,y} A(x,y)$.\n\nThe core of the problem is to evaluate the faithfulness of this attribution map. This is achieved by a perturbation-based analysis. The principle is that if an attribution map is faithful, removing input features (pixels) with high attribution scores should cause a correspondingly large change in the model's output.\nThe procedure begins by calculating the total absolute attribution mass:\n$$M = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} |A(x,y)|$$\nFor each specified removal fraction $\\alpha_j$ from the set $\\{\\alpha_j\\}_{j=1}^m = \\{0.1, 0.25, 0.5\\}$, we identify a set of pixels to be \"removed.\" This is done by sorting all pixels in descending order of their absolute attribution $|A(x,y)|$. We then select pixels from the top of this list until the cumulative sum of their absolute attributions reaches or exceeds the target removal mass $\\alpha_j M$.\n\nOnce the pixels for removal are identified, a perturbed event image $I_{\\alpha_j}(x,y)$ is created by setting the values of $I(x,y)$ at the locations of these selected pixels to $0$. The model output is then recomputed using this perturbed image, yielding $f_{\\alpha_j}$:\n$$f_{\\alpha_j} = \\sum_{x=0}^{N_x-1} \\sum_{y=0}^{N_y-1} W(x,y)\\, I_{\\alpha_j}(x,y)$$\nThe impact of this removal is quantified by the normalized output drop, $D_{\\alpha_j}$:\n$$D_{\\alpha_j} = \\frac{|f| - |f_{\\alpha_j}|}{|f|}, \\quad \\text{if } |f|  0, \\quad \\text{and} \\quad D_{\\alpha_j}=0 \\text{ otherwise}$$\nThis metric captures the reduction in the magnitude of the model output relative to its original magnitude.\n\nFinally, the overall faithfulness score, $S$, for a given test case is the average of the output drops calculated for each removal fraction:\n$$S = \\frac{1}{m} \\sum_{j=1}^m D_{\\alpha_j}$$\nThis procedure is implemented deterministically for each of the four test cases provided. The implementation uses the `numpy` library for efficient array-based computations, ensuring that all steps, including sorting with tie-breaking, are performed consistently. The final output is a list containing the score $S$ for each case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ... : Not needed for this problem.\n\ndef solve_case(Nx, Ny, sigma_e, c_xy, sigma_W, v_xy, events, alphas):\n    \"\"\"\n    Computes the faithfulness score S for a single test case.\n    \"\"\"\n    cx, cy = c_xy\n    vx, vy = v_xy\n\n    # Create coordinate grids. np.meshgrid with 'ij' indexing matches (y, x) -> (row, col)\n    # where x is columns and y is rows.\n    x_coords = np.arange(0, Nx)\n    y_coords = np.arange(0, Ny)\n    yy, xx = np.meshgrid(y_coords, x_coords, indexing='ij')\n\n    # Construct the event image I(x,y)\n    I = np.zeros((Ny, Nx), dtype=np.float64)\n    if events:\n        times = [e[0] for e in events]\n        t0 = max(times) if times else 0.0\n\n        for t_i, x_i, y_i, p_i in events:\n            # Motion compensation\n            x_prime = x_i + vx * (t0 - t_i)\n            y_prime = y_i + vy * (t0 - t_i)\n            \n            # Gaussian kernel contribution for the event\n            exponent = -((xx - x_prime)**2 + (yy - y_prime)**2) / (2.0 * sigma_e**2)\n            G = np.exp(exponent)\n            \n            # Add to event image, scaled by polarity\n            I += p_i * G\n\n    # Compute the weight map W(x,y)\n    exponent_W = -((xx - cx)**2 + (yy - cy)**2) / (2.0 * sigma_W**2)\n    W = np.exp(exponent_W)\n    \n    # Compute the attribution map A(x,y) and the original output f\n    A = W * I\n    f = np.sum(A)\n\n    # Prepare for faithfulness evaluation\n    abs_f = np.abs(f)\n    if abs_f  1e-12:\n        return 0.0\n\n    # Total absolute attribution mass M\n    M = np.sum(np.abs(A))\n    if M  1e-12:\n        # If no attribution, no change is possible. Drop is 0.\n        return 0.0\n\n    # Flatten attribution map and sort pixel indices by descending |A|\n    A_flat = A.flatten()\n    abs_A_flat = np.abs(A_flat)\n    \n    # Use 'mergesort' for a stable sort, ensuring deterministic tie-breaking.\n    # Sort in descending order by negating the values.\n    sorted_indices = np.argsort(-abs_A_flat, kind='mergesort')\n    sorted_abs_A = abs_A_flat[sorted_indices]\n    \n    # Cumulative sum of sorted absolute attributions\n    cum_abs_A = np.cumsum(sorted_abs_A)\n\n    # Loop over removal fractions alpha\n    output_drops = []\n    for alpha in alphas:\n        target_mass = alpha * M\n        \n        # Find number of pixels to remove to reach target mass\n        # 'searchsorted' finds the index where the element should be inserted to maintain order.\n        # This gives us the count of pixels to remove.\n        num_pixels_to_remove = np.searchsorted(cum_abs_A, target_mass, side='left') + 1\n        \n        # Get the indices of the pixels to remove\n        pixels_to_remove_indices = sorted_indices[:num_pixels_to_remove]\n        \n        # Compute perturbed output f_alpha\n        # A more efficient way is to subtract the removed attributions from the total f.\n        f_alpha = f - np.sum(A_flat[pixels_to_remove_indices])\n        \n        # Calculate normalized output drop D_alpha\n        abs_f_alpha = np.abs(f_alpha)\n        D_alpha = (abs_f - abs_f_alpha) / abs_f\n        output_drops.append(D_alpha)\n\n    # Compute final faithfulness score S\n    S = np.mean(output_drops)\n    \n    return S\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    alphas = [0.1, 0.25, 0.5]\n    \n    test_cases = [\n        {'Nx': 32, 'Ny': 32, 'sigma_e': 1.2, 'c_xy': (16, 16), 'sigma_W': 5, 'v_xy': (1.0, 0.5), 'events': [(0,10,10,1), (1,11,10,1), (2,12,11,1), (3,13,11,1), (4,14,12,1), (5,15,12,1), (6,16,13,1), (7,17,13,1), (8,18,14,1), (9,19,14,1)]},\n        {'Nx': 32, 'Ny': 32, 'sigma_e': 1.0, 'c_xy': (16, 16), 'sigma_W': 4, 'v_xy': (0.0, 0.0), 'events': [(0,2,2,1), (1,3,2,-1), (2,4,3,1), (3,5,3,-1), (4,6,4,1)]},\n        {'Nx': 32, 'Ny': 32, 'sigma_e': 1.2, 'c_xy': (24, 8), 'sigma_W': 3, 'v_xy': (5.0, 3.0), 'events': [(0,28,0,1), (1,29,1,1), (2,30,2,1), (3,31,3,1), (4,31,4,1)]},\n        {'Nx': 32, 'Ny': 32, 'sigma_e': 1.5, 'c_xy': (16, 16), 'sigma_W': 6, 'v_xy': (-0.5, 0.5), 'events': [(0,16,16,-1), (1,15,16,-1), (2,17,15,-1), (3,16,17,-1), (4,17,17,1), (5,15,15,-1), (6,16,15,-1)]}\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(\n            Nx=case['Nx'],\n            Ny=case['Ny'],\n            sigma_e=case['sigma_e'],\n            c_xy=case['c_xy'],\n            sigma_W=case['sigma_W'],\n            v_xy=case['v_xy'],\n            events=case['events'],\n            alphas=alphas\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While faithfulness confirms an explanation's correctness, its utility depends on its interpretability. For spiking neural networks, a good explanation is often a sparse one, highlighting a few key neurons firing in a narrow time window. This practice  challenges you to formalize and quantify this concept by designing a spatiotemporal sparsity metric. You will combine spatial and temporal sparsity, calculated using the Hoyer index on marginal distributions, to assess and compare the conciseness of different synthetic spike-based explanations.",
            "id": "4044866",
            "problem": "A spiking neural system explanation is represented as a nonnegative spatiotemporal saliency matrix $X \\in \\mathbb{R}_{\\ge 0}^{N \\times T}$, where $N$ is the number of neurons and $T$ is the number of discrete time bins. Interpretability in Explainable Artificial Intelligence (XAI) for Spiking Neural Networks (SNNs) often benefits from sparse explanations that focus on few neurons and brief time intervals. Design a sparsity metric that penalizes both spatial and temporal spread using only fundamental definitions (norms and probability distributions), and compute its value on a synthetic spike dataset.\n\nDefine the following for any nonnegative $X$:\n- The total saliency $S = \\sum_{n=1}^{N} \\sum_{t=1}^{T} X_{n,t}$.\n- The normalized spatiotemporal distribution $P_{n,t} = X_{n,t} / S$ if $S  0$, and $P_{n,t} = 0$ otherwise.\n- The spatial marginal $p_n = \\sum_{t=1}^{T} P_{n,t}$ for $n \\in \\{1,\\dots,N\\}$.\n- The temporal marginal $q_t = \\sum_{n=1}^{N} P_{n,t}$ for $t \\in \\{1,\\dots,T\\}$.\n\nUse the Hoyer sparsity index $s(u)$ for a nonnegative vector $u \\in \\mathbb{R}_{\\ge 0}^{k}$, defined by\n$$\ns(u) = \n\\begin{cases}\n\\frac{\\sqrt{k} - \\frac{\\|u\\|_1}{\\|u\\|_2}}{\\sqrt{k} - 1},  \\text{if } \\|u\\|_2  0, \\\\\n0,  \\text{if } \\|u\\|_2 = 0,\n\\end{cases}\n$$\nwhere $\\|u\\|_1 = \\sum_{i=1}^{k} u_i$ and $\\|u\\|_2 = \\left( \\sum_{i=1}^{k} u_i^2 \\right)^{1/2}$.\n\nPropose the spatiotemporal sparsity metric\n$$\nM(X;\\alpha) = \\alpha \\, s(p) + (1 - \\alpha) \\, s(q),\n$$\nwith weight $\\alpha \\in [0,1]$. This metric returns $1$ for perfectly localized explanations (one neuron and one time bin) and returns $0$ for uniformly spread explanations across neurons or time bins. If $S = 0$ (the explanation is identically zero), define $M(X;\\alpha) = 0$.\n\nConstruct a synthetic spike dataset with $N = 5$ neurons and $T = 10$ time bins. For each test case, the explanation matrix $X$ is specified by placing unit spikes (entries equal to $1$) at given neuron-time indices; all unspecified entries are $0$. The test suite is:\n\n- Case A (happy path, maximally sparse): One spike at neuron index $n = 3$ and time bin $t = 6$, i.e., $X_{3,6} = 1$.\n- Case B (spatially spread, temporally localized): Two spikes at time bin $t = 6$ for neurons $n = 2$ and $n = 4$, i.e., $X_{2,6} = 1$ and $X_{4,6} = 1$.\n- Case C (temporally spread, spatially localized): Three spikes at neuron $n = 3$ and time bins $t = 5,6,7$, i.e., $X_{3,5} = X_{3,6} = X_{3,7} = 1$.\n- Case D (maximally spread): All entries $X_{n,t} = 1$ for all $n \\in \\{1,\\dots,5\\}$ and $t \\in \\{1,\\dots,10\\}$.\n- Case E (degenerate zero explanation): All entries $X_{n,t} = 0$.\n- Case F (spread in both dimensions but still sparse): Two spikes at $(n,t) = (1,3)$ and $(n,t) = (5,9)$, i.e., $X_{1,3} = 1$, $X_{5,9} = 1$.\n\nUse $\\alpha = 0.5$ for all cases. Compute $M(X;\\alpha)$ for each case as a float.\n\nYour program should produce a single line of output containing the results as a comma-separated list of floats rounded to six decimal places, enclosed in square brackets (e.g., \"[resultA,resultB,resultC,resultD,resultE,resultF]\"). No physical units are involved; all quantities are dimensionless. The results must correspond to the cases in the order A, B, C, D, E, F.",
            "solution": "The problem is well-posed, scientifically grounded, and computationally verifiable. All necessary definitions and data are provided. We proceed with the solution.\n\nThe objective is to compute the spatiotemporal sparsity metric $M(X;\\alpha)$ for a series of synthetic saliency matrices $X \\in \\mathbb{R}_{\\ge 0}^{N \\times T}$. The metric is defined as a weighted sum of the spatial and temporal sparsities:\n$$\nM(X;\\alpha) = \\alpha \\, s(p) + (1 - \\alpha) \\, s(q)\n$$\nwhere $p$ and $q$ are the spatial and temporal marginal probability distributions derived from $X$, and $s(u)$ is the Hoyer sparsity index for a non-negative vector $u \\in \\mathbb{R}_{\\ge 0}^{k}$:\n$$\ns(u) = \n\\begin{cases}\n\\frac{\\sqrt{k} - \\frac{\\|u\\|_1}{\\|u\\|_2}}{\\sqrt{k} - 1},  \\text{if } \\|u\\|_2  0, \\\\\n0,  \\text{if } \\|u\\|_2 = 0.\n\\end{cases}\n$$\nThe problem specifies the system dimensions as $N=5$ neurons and $T=10$ time bins, with a weighting factor $\\alpha=0.5$.\n\nThe marginals $p$ and $q$ are derived from the normalized distribution $P_{n,t} = X_{n,t} / S$, where $S = \\sum_{n,t} X_{n,t}$ is the total saliency. By construction, if $S  0$, both $p$ and $q$ are probability distributions, meaning their elements sum to $1$. Consequently, their $L_1$ norms are $\\|p\\|_1 = \\sum_{n=1}^N p_n = 1$ and $\\|q\\|_1 = \\sum_{t=1}^T q_t = 1$. The sparsity index formulas for the marginals thus simplify to:\n$$\ns(p) = \\frac{\\sqrt{N} - 1/\\|p\\|_2}{\\sqrt{N} - 1} \\quad \\text{for } p \\in \\mathbb{R}_{\\ge 0}^{N}\n$$\n$$\ns(q) = \\frac{\\sqrt{T} - 1/\\|q\\|_2}{\\sqrt{T} - 1} \\quad \\text{for } q \\in \\mathbb{R}_{\\ge 0}^{T}\n$$\nThe metric to be computed is $M(X; 0.5) = 0.5 \\, s(p) + 0.5 \\, s(q)$. Note that neuron and time indices in the problem description are $1$-based, while numerical calculations will implicitly use $0$-based indexing.\n\nCase A: One spike at $(n,t) = (3,6)$.\n$X$ is a matrix of zeros except for $X_{3,6} = 1$. The total saliency is $S=1$. The normalized matrix $P$ is identical to $X$.\nThe spatial marginal $p$ has $p_3 = 1$ and $p_n=0$ for $n \\neq 3$. So, $p = [0,0,1,0,0]^T$.\nThe $L_2$ norm is $\\|p\\|_2 = \\sqrt{1^2} = 1$.\nThe spatial sparsity is $s(p) = \\frac{\\sqrt{5} - 1/1}{\\sqrt{5}-1} = 1$.\nThe temporal marginal $q$ has $q_6 = 1$ and $q_t=0$ for $t \\neq 6$. So, $q = [0,0,0,0,0,1,0,0,0,0]^T$.\nThe $L_2$ norm is $\\|q\\|_2 = \\sqrt{1^2} = 1$.\nThe temporal sparsity is $s(q) = \\frac{\\sqrt{10} - 1/1}{\\sqrt{10}-1} = 1$.\nThe final metric is $M_A = 0.5(1) + 0.5(1) = 1$.\n\nCase B: Spikes at $(n,t)=(2,6)$ and $(4,6)$.\n$X$ has two non-zero entries: $X_{2,6}=1$ and $X_{4,6}=1$. Total saliency $S=2$.\nThe normalized entries are $P_{2,6}=1/2$ and $P_{4,6}=1/2$.\nThe spatial marginal is $p = [0, 1/2, 0, 1/2, 0]^T$.\n$\\|p\\|_2 = \\sqrt{(1/2)^2 + (1/2)^2} = \\sqrt{1/4 + 1/4} = \\sqrt{1/2} = 1/\\sqrt{2}$.\n$s(p) = \\frac{\\sqrt{5} - 1/(1/\\sqrt{2})}{\\sqrt{5} - 1} = \\frac{\\sqrt{5} - \\sqrt{2}}{\\sqrt{5} - 1}$.\nThe temporal marginal has $q_6 = P_{2,6} + P_{4,6} = 1/2+1/2=1$ and $q_t=0$ otherwise.\n$\\|q\\|_2 = 1$, so $s(q)=1$.\n$M_B = 0.5 \\left( \\frac{\\sqrt{5} - \\sqrt{2}}{\\sqrt{5} - 1} \\right) + 0.5(1) \\approx 0.5(0.664898) + 0.5 = 0.832449$.\n\nCase C: Spikes at $(n,t)=(3,5)$, $(3,6)$, and $(3,7)$.\n$X$ has three non-zero entries: $X_{3,5}=1, X_{3,6}=1, X_{3,7}=1$. Total saliency $S=3$.\nNormalized entries are $P_{3,5}=1/3, P_{3,6}=1/3, P_{3,7}=1/3$.\nThe spatial marginal has $p_3 = P_{3,5}+P_{3,6}+P_{3,7} = 1$ and $p_n=0$ otherwise.\n$\\|p\\|_2=1$, so $s(p)=1$.\nThe temporal marginal is $q = [0,0,0,0,1/3,1/3,1/3,0,0,0]^T$.\n$\\|q\\|_2 = \\sqrt{(1/3)^2 + (1/3)^2 + (1/3)^2} = \\sqrt{3/9} = \\sqrt{1/3} = 1/\\sqrt{3}$.\n$s(q) = \\frac{\\sqrt{10} - 1/(1/\\sqrt{3})}{\\sqrt{10} - 1} = \\frac{\\sqrt{10} - \\sqrt{3}}{\\sqrt{10} - 1}$.\n$M_C = 0.5(1) + 0.5 \\left( \\frac{\\sqrt{10} - \\sqrt{3}}{\\sqrt{10} - 1} \\right) \\approx 0.5 + 0.5(0.661448) = 0.830724$.\n\nCase D: Maximally spread, all $X_{n,t}=1$.\nTotal saliency $S=N \\times T = 5 \\times 10 = 50$.\nNormalized entries are $P_{n,t} = 1/50$ for all $(n,t)$.\nThe spatial marginal is a uniform distribution: $p_n = \\sum_{t=1}^{10} (1/50) = 10/50 = 1/5$ for each $n$.\n$\\|p\\|_2 = \\sqrt{\\sum_{n=1}^5 (1/5)^2} = \\sqrt{5 \\cdot (1/25)} = \\sqrt{1/5} = 1/\\sqrt{5}$.\n$s(p) = \\frac{\\sqrt{5} - 1/(1/\\sqrt{5})}{\\sqrt{5} - 1} = \\frac{\\sqrt{5} - \\sqrt{5}}{\\sqrt{5} - 1} = 0$.\nThe temporal marginal is a uniform distribution: $q_t = \\sum_{n=1}^5 (1/50) = 5/50 = 1/10$ for each $t$.\n$\\|q\\|_2 = \\sqrt{\\sum_{t=1}^{10} (1/10)^2} = \\sqrt{10 \\cdot (1/100)} = \\sqrt{1/10} = 1/\\sqrt{10}$.\n$s(q) = \\frac{\\sqrt{10} - 1/(1/\\sqrt{10})}{\\sqrt{10} - 1} = \\frac{\\sqrt{10} - \\sqrt{10}}{\\sqrt{10} - 1} = 0$.\n$M_D = 0.5(0) + 0.5(0) = 0$.\n\nCase E: Degenerate zero explanation, all $X_{n,t}=0$.\nTotal saliency $S=0$. As per the problem definition, the metric is $M_E = 0$.\n\nCase F: Spikes at $(n,t)=(1,3)$ and $(5,9)$.\n$X_{1,3}=1, X_{5,9}=1$. Total saliency $S=2$.\nNormalized entries are $P_{1,3}=1/2, P_{5,9}=1/2$.\nThe spatial marginal is $p = [1/2, 0, 0, 0, 1/2]^T$.\n$\\|p\\|_2 = \\sqrt{(1/2)^2 + (1/2)^2} = 1/\\sqrt{2}$.\n$s(p) = \\frac{\\sqrt{5} - 1/(1/\\sqrt{2})}{\\sqrt{5} - 1} = \\frac{\\sqrt{5} - \\sqrt{2}}{\\sqrt{5} - 1}$. This is the same as in Case B.\nThe temporal marginal is $q = [0,0,1/2,0,0,0,0,0,1/2,0]^T$.\n$\\|q\\|_2 = \\sqrt{(1/2)^2 + (1/2)^2} = 1/\\sqrt{2}$.\n$s(q) = \\frac{\\sqrt{10} - 1/(1/\\sqrt{2})}{\\sqrt{10} - 1} = \\frac{\\sqrt{10} - \\sqrt{2}}{\\sqrt{10} - 1}$.\n$M_F = 0.5 \\left( \\frac{\\sqrt{5} - \\sqrt{2}}{\\sqrt{5} - 1} \\right) + 0.5 \\left( \\frac{\\sqrt{10} - \\sqrt{2}}{\\sqrt{10} - 1} \\right) \\approx 0.5(0.664898) + 0.5(0.808436) = 0.736667$.\n\nThe final results are computed programmatically to ensure precision.",
            "answer": "```python\nimport numpy as np\n\ndef hoyer_sparsity(u: np.ndarray) -> float:\n    \"\"\"\n    Computes the Hoyer sparsity index for a non-negative vector u.\n\n    The index is defined as:\n    s(u) = (sqrt(k) - ||u||_1 / ||u||_2) / (sqrt(k) - 1) for ||u||_2 > 0\n    s(u) = 0 for ||u||_2 = 0\n    where k is the length of the vector u.\n    \"\"\"\n    k = u.shape[0]\n\n    # The denominator (sqrt(k) - 1) is zero if k=1.\n    # The problem context ensures k > 1 (N=5, T=10), so this check is for robustness.\n    if k = 1:\n        # Sparsity is ill-defined or trivially 1 for a single-element vector.\n        # The formula yields 0/0 for a single-element probability vector [1].\n        # We return 0.0 as this case is not expected.\n        return 0.0\n\n    norm_2 = np.linalg.norm(u, 2)\n\n    # Per the problem definition, if ||u||_2 = 0, s(u) = 0.\n    # Use a small epsilon for floating point comparison.\n    if norm_2  1e-12:\n        return 0.0\n\n    norm_1 = np.linalg.norm(u, 1)\n    sqrt_k = np.sqrt(k)\n\n    return (sqrt_k - norm_1 / norm_2) / (sqrt_k - 1)\n\ndef compute_metric(X: np.ndarray, alpha: float) -> float:\n    \"\"\"\n    Computes the spatiotemporal sparsity metric M(X; alpha).\n\n    Args:\n        X (np.ndarray): The saliency matrix of shape (N, T).\n        alpha (float): The weighting factor between spatial and temporal sparsity.\n\n    Returns:\n        float: The computed metric value.\n    \"\"\"\n    S = np.sum(X)\n\n    # Per the problem definition, if S=0, the metric M is 0.\n    if S  1e-12:\n        return 0.0\n\n    # Normalize X to get the spatiotemporal probability distribution P.\n    P = X / S\n\n    # Calculate spatial marginal distribution p (vector of length N).\n    p = np.sum(P, axis=1)\n\n    # Calculate temporal marginal distribution q (vector of length T).\n    q = np.sum(P, axis=0)\n\n    # Compute Hoyer sparsity for each marginal.\n    s_p = hoyer_sparsity(p)\n    s_q = hoyer_sparsity(q)\n\n    # Compute the final weighted metric.\n    M = alpha * s_p + (1 - alpha) * s_q\n\n    return M\n\ndef solve():\n    \"\"\"\n    Solves the problem by computing the sparsity metric for all specified test cases.\n    \"\"\"\n    N = 5  # Number of neurons\n    T = 10 # Number of time bins\n    alpha = 0.5 # Weighting factor\n\n    # --- Construct the explanation matrix X for each test case ---\n    # Note: Problem uses 1-based indexing, Python uses 0-based.\n    \n    # Case A: One spike at neuron index 3 and time bin 6. Maximally sparse.\n    X_A = np.zeros((N, T))\n    X_A[2, 5] = 1.0\n\n    # Case B: Two spikes at time bin 6 for neurons 2 and 4. Spatially spread.\n    X_B = np.zeros((N, T))\n    X_B[1, 5] = 1.0\n    X_B[3, 5] = 1.0\n\n    # Case C: Three spikes at neuron 3 for time bins 5, 6, 7. Temporally spread.\n    X_C = np.zeros((N, T))\n    X_C[2, 4] = 1.0\n    X_C[2, 5] = 1.0\n    X_C[2, 6] = 1.0\n\n    # Case D: All entries are 1. Maximally spread.\n    X_D = np.ones((N, T))\n\n    # Case E: All entries are 0. Degenerate zero explanation.\n    X_E = np.zeros((N, T))\n\n    # Case F: Two spikes at (1,3) and (5,9). Spread in both dimensions.\n    X_F = np.zeros((N, T))\n    X_F[0, 2] = 1.0\n    X_F[4, 8] = 1.0\n\n    test_cases = [X_A, X_B, X_C, X_D, X_E, X_F]\n    \n    results = []\n    for X in test_cases:\n        result = compute_metric(X, alpha)\n        results.append(result)\n        \n    # Format the output as a comma-separated list of floats with 6 decimal places,\n    # enclosed in square brackets.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond explaining individual predictions, a truly trustworthy neuromorphic system must provide reliable confidence estimates. This practice shifts the focus from local attribution to a global property of the model: calibration, which measures the alignment between a model's confidence and its empirical accuracy . You will compute the Expected Calibration Error (ECE) for a spiking classifier by implementing both a simple rate-based decoding and a more sophisticated Bayesian decoding scheme. This exercise provides essential skills for quantifying the reliability of a model's probabilistic outputs, a critical component of explainable AI.",
            "id": "4044870",
            "problem": "You are studying Explainable Artificial Intelligence (XAI) for neuromorphic systems, focusing on the calibration of spiking classifiers. In a spiking classifier, a discrete-time observation window yields integer spike counts that are mapped to class probabilities. Calibration captures the alignment between predicted confidence and empirical accuracy. For explainability, a calibrated spiking classifier makes its confidence values interpretable: when a model outputs a confidence of $p$, its empirical accuracy on samples with confidence near $p$ should be close to $p$. The Expected Calibration Error (ECE) quantifies the discrepancy between confidence and accuracy aggregated across confidence intervals.\n\nFundamental bases to be used:\n- Probability theory: the axioms of probability and Bayes’ rule, which states $P(A \\mid B) = \\dfrac{P(B \\mid A) P(A)}{P(B)}$ for events $A$ and $B$ with $P(B) \\neq 0$.\n- The Poisson distribution: for a nonnegative integer random variable $X$ representing spike counts with rate parameter $\\lambda$ and independence across channels, the likelihood is given by $P(X=x) = e^{-\\lambda} \\dfrac{\\lambda^{x}}{x!}$ for $x \\in \\mathbb{N}$.\n\nTwo probabilistic decoding schemes must be implemented to produce class probability vectors:\n- Rate-based decoding: given spike counts per class $s \\in \\mathbb{N}^{K}$ for $K$ classes, output a class probability vector $p \\in [0,1]^{K}$ by normalizing $s$ to unit sum. If $\\sum_{c=1}^{K} s_{c} = 0$, define $p$ as uniform with $p_{c} = \\dfrac{1}{K}$ for all $c$.\n- Bayesian decoding with independent Poisson channels: given a spike vector $x \\in \\mathbb{N}^{M}$ over $M$ neurons, class-conditional Poisson rates $\\lambda_{c} \\in \\mathbb{R}_{+}^{M}$ for $c \\in \\{0,1,\\dots,K-1\\}$, and class priors $\\pi \\in [0,1]^{K}$ with $\\sum_{c} \\pi_{c} = 1$, use Bayes’ rule to produce posterior class probabilities $p(c \\mid x)$ under the assumption that channels are independent given the class and each channel follows a Poisson model.\n\nCalibration computation:\n- Confidence for a sample is defined as $q = \\max_{c} p_{c}$.\n- Predicted class is defined as $y^{\\text{pred}} = \\arg\\max_{c} p_{c}$, and in case of ties the smallest class index should be chosen.\n- The Expected Calibration Error aggregates, over $B$ equally sized bins partitioning $[0,1]$ based on confidence $q$, the discrepancy between the empirical accuracy and average confidence in each bin, weighted by the fraction of samples in that bin. Empty bins do not contribute.\n\nYour task is to write a complete, runnable program that:\n1. For each test case, computes class probability vectors via the specified decoding scheme (rate-based or Bayesian).\n2. Computes the confidences $q$, predicted classes $y^{\\text{pred}}$, and compares them to true labels $y$ to measure classification correctness for each sample.\n3. Partitions confidences into $B$ equal-width bins spanning $[0,1]$; the rightmost bin should include confidence $q=1$. Use bin index $b = \\min\\left(\\left\\lfloor q \\cdot B \\right\\rfloor, B-1\\right)$ for deterministic binning.\n4. Computes the Expected Calibration Error according to the standard definition that compares empirical accuracy to average confidence per bin, weighted by the fraction of samples in the bin.\n5. Outputs the ECE per test case as a float. Express answers as decimal fractions with six digits after the decimal point.\n\nTest suite specification:\n- Test Case $1$ (rate-based, happy path calibrated):\n  - Number of classes $K = 3$.\n  - Spike counts per sample (each row corresponds to $s \\in \\mathbb{N}^{K}$): $[[5,0,0],[0,4,0],[0,0,3],[1,1,1],[1,1,1],[1,1,1]]$.\n  - True labels $y$: $[0,1,2,0,1,2]$.\n  - Number of bins $B = 5$.\n  - Decoding mode: rate-based.\n- Test Case $2$ (rate-based, miscalibrated high confidence):\n  - Number of classes $K = 3$.\n  - Spike counts per sample: $[[7,0,0],[6,0,0],[8,0,0],[5,0,0],[9,0,0],[4,0,0],[10,0,0],[3,0,0],[2,0,0],[1,0,0]]$.\n  - True labels $y$: $[1,2,1,2,1,1,2,1,2,0]$.\n  - Number of bins $B = 5$.\n  - Decoding mode: rate-based.\n- Test Case $3$ (Bayesian decoding with independent Poisson channels):\n  - Number of classes $K = 2$ and number of neurons $M = 2$.\n  - Class priors $\\pi = [0.5, 0.5]$.\n  - Class-conditional rates $\\lambda_{0} = [3.0, 1.0]$, $\\lambda_{1} = [1.0, 3.0]$.\n  - Spike vectors per sample $x$: $[[3,1],[1,3],[4,0],[0,4],[2,2],[2,1]]$.\n  - True labels $y$: $[0,1,0,1,1,0]$.\n  - Number of bins $B = 10$.\n  - Decoding mode: Bayesian.\n- Test Case $4$ (rate-based, edge case with zero counts and many bins):\n  - Number of classes $K = 3$.\n  - Spike counts per sample: $[[0,0,0],[0,0,0],[0,0,0]]$.\n  - True labels $y$: $[0,1,2]$.\n  - Number of bins $B = 10$.\n  - Decoding mode: rate-based.\n\nFinal output format:\n- Your program should produce a single line of output containing the ECE results for the four test cases as a comma-separated list enclosed in square brackets, with each float rounded to six digits after the decimal point (for example, $[0.000000,0.900000,0.123456,0.000000]$).",
            "solution": "The problem requires the computation of the Expected Calibration Error (ECE) for a spiking classifier under two distinct probabilistic decoding schemes. Calibration is a critical property for modern machine learning models, particularly in high-stakes domains, as it ensures that the model's output confidence scores are meaningful and align with its empirical accuracy. An uncalibrated model might be highly confident in its incorrect predictions, leading to unreliable decision-making. The ECE provides a standardized metric to quantify this alignment. We shall first formalize the requisite probabilistic models and the ECE calculation before applying them to the specific test cases.\n\nThe core task involves processing a set of $N$ samples. For each sample $i$, we are given input data (spike counts) and a true class label $y^{(i)} \\in \\{0, 1, \\dots, K-1\\}$. The first step is to compute a class probability vector $p^{(i)} \\in [0,1]^K$ using one of two specified methods.\n\nThe first method is **rate-based decoding**. This scheme operates on spike counts aggregated per class, denoted by a vector $s \\in \\mathbb{N}^K$. The probability of class $c$ is determined by normalizing the spike count for that class by the total number of spikes across all classes. If the total number of spikes $S = \\sum_{c=0}^{K-1} s_c$ is greater than zero, the probability vector $p$ is given by:\n$$p_c = \\frac{s_c}{S}$$\nIn the specific case where $S=0$, the model has no information, and the probability is defined as a uniform distribution over the $K$ classes:\n$$p_c = \\frac{1}{K}$$\n\nThe second method is **Bayesian decoding** using independent Poisson channels. Here, the input is a spike vector $x \\in \\mathbb{N}^M$ recorded from $M$ neurons. We are provided with class priors $\\pi \\in [0,1]^K$ (where $\\sum_{c=0}^{K-1} \\pi_c = 1$) and class-conditional spike rates $\\lambda_c \\in \\mathbb{R}_+^M$ for each class $c$. The goal is to compute the posterior probability $p(c \\mid x)$ for each class. According to Bayes' rule:\n$$p(c \\mid x) = \\frac{p(x \\mid c) \\pi_c}{p(x)}$$\nThe evidence $p(x) = \\sum_{j=0}^{K-1} p(x \\mid j) \\pi_j$ serves as a normalization constant. The likelihood $p(x \\mid c)$ is derived from the assumption that, given the class $c$, the spike counts $x_m$ from each neuron $m$ are independent and follow a Poisson distribution with rate $\\lambda_{c,m}$:\n$$p(x \\mid c) = \\prod_{m=0}^{M-1} P(X_m=x_m \\mid \\text{class } c) = \\prod_{m=0}^{M-1} \\frac{e^{-\\lambda_{c,m}} (\\lambda_{c,m})^{x_m}}{x_m!}$$\nFor numerical stability, it is standard practice to work with log-probabilities. The log-likelihood is:\n$$\\log p(x \\mid c) = \\sum_{m=0}^{M-1} \\left( -\\lambda_{c,m} + x_m \\log \\lambda_{c,m} - \\log(x_m!) \\right)$$\nThe posterior probability $p_c = p(c \\mid x)$ is then:\n$$p_c = \\frac{\\pi_c \\exp(\\log p(x \\mid c))}{\\sum_{j=0}^{K-1} \\pi_j \\exp(\\log p(x \\mid j))}$$\nNotice that the term $\\sum_m \\log(x_m!)$ is constant across all classes $j$ for a given input $x$. It will thus cancel out from the numerator and denominator during normalization. Consequently, we only need to compute an unnormalized log-posterior for each class:\n$$\\text{ULP}_c(x) = \\log \\pi_c + \\sum_{m=0}^{M-1} (x_m \\log \\lambda_{c,m} - \\lambda_{c,m})$$\nThese log-posteriors are then normalized using the softmax function (often implemented with the log-sum-exp trick to prevent numerical overflow/underflow) to yield the final probability vector $p$.\n\nOnce the probability vector $p^{(i)}$ is computed for each sample $i$, we determine its **confidence** $q^{(i)}$ and **predicted class** $y_{\\text{pred}}^{(i)}$:\n$$q^{(i)} = \\max_{c} p_c^{(i)}$$\n$$y_{\\text{pred}}^{(i)} = \\arg\\max_{c} p_c^{(i)}$$\nTies in $\\arg\\max$ are broken by selecting the smallest class index. The prediction is correct if $y_{\\text{pred}}^{(i)} = y^{(i)}$.\n\nFinally, we compute the **Expected Calibration Error (ECE)**. The confidence scores are partitioned into $B$ equal-width bins on the interval $[0,1]$. A confidence score $q$ is assigned to bin index $b$ using the rule $b = \\min(\\lfloor q \\cdot B \\rfloor, B-1)$. This places $q=1$ into the last bin, indexed $B-1$.\nFor each bin $b \\in \\{0, 1, \\dots, B-1\\}$ that contains at least one sample, we calculate its average accuracy, $\\text{acc}(b)$, and its average confidence, $\\text{conf}(b)$. Let $I_b$ be the set of sample indices that fall into bin $b$, and let $n_b = |I_b|$ be the number of samples in that bin.\n$$\\text{acc}(b) = \\frac{1}{n_b} \\sum_{i \\in I_b} \\mathbf{1}(y_{\\text{pred}}^{(i)} = y^{(i)})$$\n$$\\text{conf}(b) = \\frac{1}{n_b} \\sum_{i \\in I_b} q^{(i)}$$\nThe ECE is the weighted average of the absolute difference between accuracy and confidence across all bins:\n$$\\text{ECE} = \\sum_{b=0}^{B-1} \\frac{n_b}{N} |\\text{acc}(b) - \\text{conf}(b)|$$\nwhere $N$ is the total number of samples. An equivalent and computationally simpler form is:\n$$\\text{ECE} = \\frac{1}{N} \\sum_{b=0}^{B-1} \\left| \\sum_{i \\in I_b} \\mathbf{1}(y_{\\text{pred}}^{(i)} = y^{(i)}) - \\sum_{i \\in I_b} q^{(i)} \\right|$$\nThis procedure is applied to each of the four test cases specified to derive their respective ECE values.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases and prints the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"decoding_mode\": \"rate-based\",\n            \"K\": 3,\n            \"s\": np.array([[5,0,0],[0,4,0],[0,0,3],[1,1,1],[1,1,1],[1,1,1]]),\n            \"y\": np.array([0,1,2,0,1,2]),\n            \"B\": 5\n        },\n        {\n            \"decoding_mode\": \"rate-based\",\n            \"K\": 3,\n            \"s\": np.array([[7,0,0],[6,0,0],[8,0,0],[5,0,0],[9,0,0],[4,0,0],[10,0,0],[3,0,0],[2,0,0],[1,0,0]]),\n            \"y\": np.array([1,2,1,2,1,1,2,1,2,0]),\n            \"B\": 5\n        },\n        {\n            \"decoding_mode\": \"Bayesian\",\n            \"K\": 2,\n            \"M\": 2,\n            \"pi\": np.array([0.5, 0.5]),\n            \"lambda\": np.array([[3.0, 1.0], [1.0, 3.0]]),\n            \"x\": np.array([[3,1],[1,3],[4,0],[0,4],[2,2],[2,1]]),\n            \"y\": np.array([0,1,0,1,1,0]),\n            \"B\": 10\n        },\n        {\n            \"decoding_mode\": \"rate-based\",\n            \"K\": 3,\n            \"s\": np.array([[0,0,0],[0,0,0],[0,0,0]]),\n            \"y\": np.array([0,1,2]),\n            \"B\": 10\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        ece = calculate_ece(case)\n        results.append(f\"{ece:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef rate_based_decoding(s_vectors, K):\n    \"\"\"Computes class probabilities using rate-based decoding.\"\"\"\n    probs = []\n    for s in s_vectors:\n        s_sum = np.sum(s)\n        if s_sum == 0:\n            probs.append(np.full(K, 1.0 / K))\n        else:\n            probs.append(s / s_sum)\n    return np.array(probs)\n\ndef bayesian_decoding(x_vectors, priors, lambdas, K):\n    \"\"\"Computes class probabilities using Bayesian decoding with Poisson assumption.\"\"\"\n    probs = []\n    # Use np.log on arrays where possible for efficiency\n    log_priors = np.log(priors)\n    log_lambdas = np.log(lambdas)\n    \n    for x in x_vectors:\n        # Calculate unnormalized log posteriors for all classes at once\n        # Using broadcasting: x (M,) * log_lambdas (K, M) -> (K, M)\n        log_likelihoods = np.sum(x * log_lambdas - lambdas, axis=1)\n        ulps = log_priors + log_likelihoods\n        \n        # Log-sum-exp for stable softmax\n        max_ulp = np.max(ulps)\n        exp_ulps = np.exp(ulps - max_ulp)\n        p = exp_ulps / np.sum(exp_ulps)\n        probs.append(p)\n        \n    return np.array(probs)\n\ndef calculate_ece(case):\n    \"\"\"\n    Calculates the Expected Calibration Error for a given test case.\n    \"\"\"\n    mode = case['decoding_mode']\n    y_true = case['y']\n    B = case['B']\n    K = case['K']\n    \n    if mode == 'rate-based':\n        probs = rate_based_decoding(case['s'], K)\n    elif mode == 'Bayesian':\n        probs = bayesian_decoding(case['x'], case['pi'], case['lambda'], K)\n    else:\n        raise ValueError(\"Invalid decoding mode specified.\")\n\n    # Compute confidences, predictions, and correctness\n    confidences = np.max(probs, axis=1)\n    predictions = np.argmax(probs, axis=1) # argmax breaks ties with smallest index\n    correctness = (predictions == y_true).astype(float)\n    \n    N = len(y_true)\n    if N == 0:\n        return 0.0\n\n    # Assign each sample to a bin\n    bin_indices = np.minimum(np.floor(confidences * B), B - 1).astype(int)\n    \n    ece = 0.0\n    for b in range(B):\n        # Create a boolean mask for the current bin\n        in_bin = (bin_indices == b)\n        n_b = np.sum(in_bin)\n        \n        if n_b > 0:\n            # Calculate accuracy and confidence for this bin\n            acc_b = np.mean(correctness[in_bin])\n            conf_b = np.mean(confidences[in_bin])\n            \n            # Add to ECE, weighted by the fraction of samples in the bin\n            ece += (n_b / N) * np.abs(acc_b - conf_b)\n            \n    return ece\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}