{
    "hands_on_practices": [
        {
            "introduction": "简单的数学模型可以为理解生物过程与精神症状之间的关系提供有力的洞见。本练习使用一个谐波振荡器来表示生物钟系统，并探讨其相位的微小变化如何影响情绪，这在双相情感障碍等疾病中是一个关键特征。这项实践将锻炼您在数学建模和运用近似技术方面的技能。",
            "id": "4039927",
            "problem": "一个旨在模拟视交叉上核 (SCN) 的神经形态昼夜节律模块被建模为一个单相振荡器，其可观测状态（昼夜节律唤醒的代理指标）由 $s(t) = A \\cos(\\omega t + \\phi)$ 给出，其中 $A$ 是振幅，$\\omega$ 是角频率，$t$ 是从当地午夜开始测量的时钟时间，$\\phi$ 是相位。在一个心境障碍严重程度的计算精神病学模型中，瞬时心境症状严重程度 $M(t)$ 在基线工作点附近通过一个仿射读出近似为 $M(t) \\approx M_{0} + \\alpha s(t)$，其中 $\\alpha$ 是一个将昼夜节律唤醒转换为严重程度单位的增益，$M_{0}$ 是一个基线项。系统在每天的固定测量时间 $t_{m}$ 被探测。\n\n一种基于光的授时因子干预在振荡器中引起一个小的相移 $\\Delta \\phi$，使得干预后状态变为 $s_{\\text{post}}(t) = A \\cos(\\omega t + \\phi_{0} + \\Delta \\phi)$，其中 $\\phi_{0}$ 是干预前的基线相位。假设 $\\Delta \\phi$ 足够小，使得围绕 $\\Delta \\phi = 0$ 的一阶近似有效。\n\n仅从关于谐振子和一阶泰勒展开的成熟事实出发，推导在测量时间 $t_{m}$ 时心境严重程度的线性化变化，定义为 $\\Delta M = M_{\\text{post}}(t_{m}) - M_{\\text{pre}}(t_{m})$，并用给定参数表示。然后，使用以下科学上合理的参数评估 $\\Delta M$：振幅 $A = 0.7$，增益 $\\alpha = 4.3$，角频率 $\\omega = \\frac{2\\pi}{24}$（弧度/小时），测量时间 $t_{m} = 8$（当地午夜后的小时数），基线相位 $\\phi_{0} = -\\frac{\\pi}{6}$（弧度），以及相移 $\\Delta \\phi = 0.27$（弧度）。将最终的 $\\Delta M$ 表示为一个无量纲量，并将您的答案四舍五入到四位有效数字。",
            "solution": "该问题要求推导在一个昼夜节律振荡器模型中，由小相移 $\\Delta \\phi$ 引起的心境严重程度的线性化变化 $\\Delta M$，然后用一组给定的参数来评估这个变化。\n\n首先，我们确立问题陈述中提供的定义。昼夜节律振荡器的状态由一个谐波函数给出：\n$$s(t) = A \\cos(\\omega t + \\phi)$$\n其中 $A$ 是振幅，$\\omega$ 是角频率，$t$ 是时间，$\\phi$ 是相位。\n\n瞬时心境症状严重程度 $M(t)$ 由振荡器状态的仿射变换给出：\n$$M(t) = M_{0} + \\alpha s(t)$$\n其中 $M_{0}$ 是基线严重程度，$\\alpha$ 是一个增益因子。\n\n每天在固定时间 $t_{m}$ 进行测量。此时的干预前心境严重程度 $M_{\\text{pre}}(t_{m})$ 基于初始相位 $\\phi_{0}$。\n干预前状态为 $s_{\\text{pre}}(t) = A \\cos(\\omega t + \\phi_{0})$。因此，测量时间点的干预前心境严重程度为：\n$$M_{\\text{pre}}(t_{m}) = M_{0} + \\alpha s_{\\text{pre}}(t_{m}) = M_{0} + \\alpha A \\cos(\\omega t_{m} + \\phi_{0})$$\n\n基于光的干预引起一个小的相移 $\\Delta \\phi$。干预后状态为 $s_{\\text{post}}(t) = A \\cos(\\omega t + \\phi_{0} + \\Delta \\phi)$。测量时间点的干预后心境严重程度为：\n$$M_{\\text{post}}(t_{m}) = M_{0} + \\alpha s_{\\text{post}}(t_{m}) = M_{0} + \\alpha A \\cos(\\omega t_{m} + \\phi_{0} + \\Delta \\phi)$$\n\n心境严重程度的变化 $\\Delta M$ 是测量时间 $t_{m}$ 时干预后和干预前心境严重程度之差：\n$$\\Delta M = M_{\\text{post}}(t_{m}) - M_{\\text{pre}}(t_{m})$$\n代入 $M_{\\text{post}}$ 和 $M_{\\text{pre}}$ 的表达式：\n$$\\Delta M = \\left( M_{0} + \\alpha A \\cos(\\omega t_{m} + \\phi_{0} + \\Delta \\phi) \\right) - \\left( M_{0} + \\alpha A \\cos(\\omega t_{m} + \\phi_{0}) \\right)$$\n基线项 $M_{0}$ 被消去：\n$$\\Delta M = \\alpha A \\left( \\cos(\\omega t_{m} + \\phi_{0} + \\Delta \\phi) - \\cos(\\omega t_{m} + \\phi_{0}) \\right)$$\n\n问题陈述指出 $\\Delta \\phi$ 很小，因此可以围绕 $\\Delta \\phi = 0$ 进行一阶泰勒展开。我们定义一个函数 $f(\\delta) = \\cos(C + \\delta)$，其中 $C = \\omega t_{m} + \\phi_{0}$ 是一个恒定的相角，$\\delta$ 是对应于 $\\Delta \\phi$ 的小扰动。$f(\\delta)$ 在 $\\delta = 0$ 附近的一阶泰勒展开为：\n$$f(\\delta) \\approx f(0) + f'(0) \\delta$$\n该函数及其导数为：\n$$f(\\delta) = \\cos(C + \\delta) \\implies f(0) = \\cos(C)$$\n$$f'(\\delta) = -\\sin(C + \\delta) \\implies f'(0) = -\\sin(C)$$\n因此，近似值为：\n$$\\cos(C + \\delta) \\approx \\cos(C) - \\delta \\sin(C)$$\n代入 $C = \\omega t_{m} + \\phi_{0}$ 和 $\\delta = \\Delta \\phi$，我们得到：\n$$\\cos(\\omega t_{m} + \\phi_{0} + \\Delta \\phi) \\approx \\cos(\\omega t_{m} + \\phi_{0}) - \\Delta \\phi \\sin(\\omega t_{m} + \\phi_{0})$$\n\n现在，我们将这个线性化表达式代回 $\\Delta M$ 的方程中：\n$$\\Delta M \\approx \\alpha A \\left( \\left( \\cos(\\omega t_{m} + \\phi_{0}) - \\Delta \\phi \\sin(\\omega t_{m} + \\phi_{0}) \\right) - \\cos(\\omega t_{m} + \\phi_{0}) \\right)$$\n项 $\\cos(\\omega t_{m} + \\phi_{0})$ 被消去，得到心境严重程度线性化变化的最终表达式：\n$$\\Delta M = - \\alpha A \\sin(\\omega t_{m} + \\phi_{0}) \\Delta \\phi$$\n这就完成了问题的推导部分。\n\n接下来，我们使用给定的参数评估 $\\Delta M$：\n$A = 0.7$\n$\\alpha = 4.3$\n$\\omega = \\frac{2\\pi}{24} = \\frac{\\pi}{12}$ 弧度/小时\n$t_{m} = 8$ 小时\n$\\phi_{0} = -\\frac{\\pi}{6}$ 弧度\n$\\Delta \\phi = 0.27$ 弧度\n\n首先，我们计算正弦函数的总相位角 $\\omega t_{m} + \\phi_{0}$：\n$$\\omega t_{m} + \\phi_{0} = \\left(\\frac{\\pi}{12} \\text{ rad/hr}\\right) \\times (8 \\text{ hr}) + \\left(-\\frac{\\pi}{6} \\text{ rad}\\right)$$\n$$\\omega t_{m} + \\phi_{0} = \\frac{8\\pi}{12} - \\frac{\\pi}{6} = \\frac{2\\pi}{3} - \\frac{\\pi}{6}$$\n为了进行减法，我们找到一个公分母：\n$$\\omega t_{m} + \\phi_{0} = \\frac{4\\pi}{6} - \\frac{\\pi}{6} = \\frac{3\\pi}{6} = \\frac{\\pi}{2} \\text{ 弧度}$$\n\n现在，我们计算这个角度的正弦值：\n$$\\sin(\\omega t_{m} + \\phi_{0}) = \\sin\\left(\\frac{\\pi}{2}\\right) = 1$$\n\n最后，我们将所有数值代入 $\\Delta M$ 的表达式中：\n$$\\Delta M = - \\alpha A \\sin(\\omega t_{m} + \\phi_{0}) \\Delta \\phi$$\n$$\\Delta M = - (4.3) \\times (0.7) \\times (1) \\times (0.27)$$\n$$\\Delta M = - (3.01) \\times (0.27)$$\n$$\\Delta M = -0.8127$$\n问题要求答案应四舍五入到四位有效数字。计算出的值 $-0.8127$ 已经有四位有效数字。假设心境严重程度标尺本身是一个无量纲分数，则该量是无量纲的，符合要求。",
            "answer": "$$\\boxed{-0.8127}$$"
        },
        {
            "introduction": "计算精神病学的一个重要方法是将大脑视为一个网络（即连接组），并分析其结构以寻找疾病的生物标志物。本练习将重点计算模块度（modularity），这是一个衡量网络分离为功能社群程度的关键指标。通过这个计算，您将能把一个量化指标与重度抑郁症中的脑功能失调解释联系起来。",
            "id": "4039887",
            "problem": "一个中尺度功能性脑网络由一个无向加权邻接矩阵 $\\mathbf{A} \\in \\mathbb{R}^{6 \\times 6}$ 表示，其节点对应于皮层区域。考虑以下经验上合理的连接性（权重为Fisher变换后的相关性），其网络内耦合较强，网络间耦合较弱：\n$$\n\\mathbf{A} \\;=\\;\n\\begin{pmatrix}\n0  & 3.0 & 2.5 & 0.3 & 0.4 & 0.2 \\\\\n3.0 & 0   & 2.0 & 0.5 & 0.3 & 0.4 \\\\\n2.5 & 2.0 & 0   & 0.2 & 0.4 & 0.3 \\\\\n0.3 & 0.5 & 0.2 & 0   & 3.2 & 2.8 \\\\\n0.4 & 0.3 & 0.4 & 3.2 & 0   & 3.1 \\\\\n0.2 & 0.4 & 0.3 & 2.8 & 3.1 & 0\n\\end{pmatrix}.\n$$\n假设一个双模块的社群划分，其中节点 $\\{1,2,3\\}$ 属于社群 $\\mathcal{C}_{1}$，节点 $\\{4,5,6\\}$ 属于社群 $\\mathcal{C}_{2}$。使用适用于无向加权网络、且采用保持强度的零模型的标准Newman–Girvan模块度。具体而言，将非对角线元素视为边权重，节点强度 $s_{i}$ 视为与节点 $i$ 相关联的权重之和，总边权重 $w$ 视为矩阵 $\\mathbf{A}$ 所有元素之和的一半。计算此划分的模块度 $Q$。\n\n将$Q$的最终数值四舍五入到四位有效数字。无需单位。\n\n计算出 $Q$ 后，用一句话简要说明，在重度抑郁症的背景下，降低的 $Q$ 值如何解释其与功能分离的关系。（您的解释不会被数字评分；只有 $Q$ 值将用于最终答案。）",
            "solution": "对于一个加权无向网络的划分，其模块度 $Q$ 由Newman–Girvan公式给出：\n$$ Q = \\frac{1}{2w} \\sum_{i,j} \\left[ A_{ij} - \\frac{s_i s_j}{2w} \\right] \\delta(c_i, c_j) $$\n其中$\\mathbf{A}$是邻接矩阵，其元素为$A_{ij}$，$s_i = \\sum_j A_{ij}$是节点$i$的强度，$w = \\frac{1}{2} \\sum_{i,j} A_{ij}$是网络中所有边的总权重，$c_i$是节点$i$所属的社群，而$\\delta(c_i, c_j)$是克罗内克δ函数，当节点$i$和$j$在同一社群时为$1$，否则为$0$。\n\n模块度方程一个计算上更方便的形式是：\n$$ Q = \\sum_{c=1}^{N_c} \\left[ \\frac{w_c}{w} - \\left(\\frac{S_c}{2w}\\right)^2 \\right] $$\n其中，求和是对$N_c$个社群进行的，$w_c = \\frac{1}{2} \\sum_{i,j \\in c} A_{ij}$是社群$c$内部连接的权重之和，$S_c = \\sum_{i \\in c} s_i$是社群$c$中节点的强度之和。\n\n首先，我们通过对给定邻接矩阵$\\mathbf{A}$的行求和，来计算每个节点的强度$s_i$：\n$$\n\\mathbf{A} \\;=\\;\n\\begin{pmatrix}\n0  & 3.0 & 2.5 & 0.3 & 0.4 & 0.2 \\\\\n3.0 & 0   & 2.0 & 0.5 & 0.3 & 0.4 \\\\\n2.5 & 2.0 & 0   & 0.2 & 0.4 & 0.3 \\\\\n0.3 & 0.5 & 0.2 & 0   & 3.2 & 2.8 \\\\\n0.4 & 0.3 & 0.4 & 3.2 & 0   & 3.1 \\\\\n0.2 & 0.4 & 0.3 & 2.8 & 3.1 & 0\n\\end{pmatrix}\n$$\n$s_1 = 3.0 + 2.5 + 0.3 + 0.4 + 0.2 = 6.4$\n$s_2 = 3.0 + 2.0 + 0.5 + 0.3 + 0.4 = 6.2$\n$s_3 = 2.5 + 2.0 + 0.2 + 0.4 + 0.3 = 5.4$\n$s_4 = 0.3 + 0.5 + 0.2 + 3.2 + 2.8 = 7.0$\n$s_5 = 0.4 + 0.3 + 0.4 + 3.2 + 3.1 = 7.4$\n$s_6 = 0.2 + 0.4 + 0.3 + 2.8 + 3.1 = 6.8$\n\n接下来，我们计算网络的总边权重$w$，即所有节点强度之和的一半：\n$$ w = \\frac{1}{2} \\sum_{i=1}^{6} s_i = \\frac{1}{2} (6.4 + 6.2 + 5.4 + 7.0 + 7.4 + 6.8) = \\frac{1}{2} (39.2) = 19.6 $$\n因此，项$2w$为$39.2$。\n\n现在，我们分析两个社群，$\\mathcal{C}_{1} = \\{1,2,3\\}$ 和 $\\mathcal{C}_{2} = \\{4,5,6\\}$。\n\n对于社群$\\mathcal{C}_{1}$：\n内部边权重之和$w_1$是连接节点$\\{1,2,3\\}$彼此的边的权重之和。\n$$ w_1 = A_{12} + A_{13} + A_{23} = 3.0 + 2.5 + 2.0 = 7.5 $$\n节点强度之和$S_1$为：\n$$ S_1 = s_1 + s_2 + s_3 = 6.4 + 6.2 + 5.4 = 18.0 $$\n\n对于社群$\\mathcal{C}_{2}$：\n内部边权重之和$w_2$是连接节点$\\{4,5,6\\}$彼此的边的权重之和。\n$$ w_2 = A_{45} + A_{46} + A_{56} = 3.2 + 2.8 + 3.1 = 9.1 $$\n节点强度之和$S_2$为：\n$$ S_2 = s_4 + s_5 + s_6 = 7.0 + 7.4 + 6.8 = 21.2 $$\n\n现在我们可以通过对每个社群的贡献求和来计算模块度$Q$：\n$$ Q = \\left[ \\frac{w_1}{w} - \\left(\\frac{S_1}{2w}\\right)^2 \\right] + \\left[ \\frac{w_2}{w} - \\left(\\frac{S_2}{2w}\\right)^2 \\right] $$\n代入计算出的值：\n$$ Q = \\left[ \\frac{7.5}{19.6} - \\left(\\frac{18.0}{39.2}\\right)^2 \\right] + \\left[ \\frac{9.1}{19.6} - \\left(\\frac{21.2}{39.2}\\right)^2 \\right] $$\n$$ Q = \\frac{7.5 + 9.1}{19.6} - \\left( \\frac{18.0^2}{39.2^2} + \\frac{21.2^2}{39.2^2} \\right) $$\n$$ Q = \\frac{16.6}{19.6} - \\frac{324 + 449.44}{1536.64} $$\n$$ Q = \\frac{16.6}{19.6} - \\frac{773.44}{1536.64} $$\n计算分数值：\n$$ Q \\approx 0.84693877... - 0.50334975... $$\n$$ Q \\approx 0.34358902... $$\n四舍五入到四位有效数字，我们得到 $Q \\approx 0.3436$。\n\n在重度抑郁症中，降低的模块度$Q$将被解释为功能分离的减少，反映了大脑典型社群结构的瓦解，形成了功能上区分度较低的模块。",
            "answer": "$$\\boxed{0.3436}$$"
        },
        {
            "introduction": "计算精神病学的一个核心目标，是将关于症状背后认知功能障碍的假设形式化并进行检验。这项高级实践要求您构建一个完整的模型比较流程。您将实现两个代表不同决策功能障碍理论的强化学习模型，并使用贝叶斯方法来确定哪个模型能更好地解释给定的行为数据。",
            "id": "4039932",
            "problem": "您的任务是在神经形态和类脑计算领域内，设计并实现一个完整的、自包含的计算精神病学模型比较流程。其目标是利用贝叶斯模型证据来评判两种关于患者决策的竞争性机制解释，并计算贝叶斯因子。您的程序必须是模型比较的一个完整的、可运行的实现，并按如下规定产生单行输出。\n\n需要比较的两种机制性解释如下：\n\n- 机制性解释 $\\mathcal{M}_1$ (非对称学习率)：一种神经形态强化学习策略，对正向和负向预测误差使用不同的学习率，以捕捉心境障碍中常见的负性偏见。学习率为 $(\\alpha_{+}, \\alpha_{-}) \\in [0,1]^2$。每个行动的潜在价值使用标准的时间差分规则进行更新，选择概率由神经形态价值单元上的 softmax 策略决定。\n\n- 机制性解释 $\\mathcal{M}_2$ (多巴胺能奖励衰减)：一种神经形态强化学习策略，具有单一学习率 $\\alpha \\in [0,1]$ 和一个奖励衰减参数 $\\lambda \\in [0,1]$，该参数在更新价值前对接收到的奖励进行缩放。这捕捉了奖励被感知为不那么显著的类快感缺乏机制。\n\n需要使用的基础和定义：\n\n- 贝叶斯模型比较基于概率论和贝叶斯定理。对于任何具有参数 $\\theta$ 和数据 $D$ 的模型 $\\mathcal{M}$，贝叶斯定理表述为 $p(\\theta \\mid D, \\mathcal{M}) \\propto p(D \\mid \\theta, \\mathcal{M}) p(\\theta \\mid \\mathcal{M})$。贝叶斯模型证据（也称为边缘似然）定义为\n$$p(D \\mid \\mathcal{M}) = \\int p(D \\mid \\theta, \\mathcal{M}) \\, p(\\theta \\mid \\mathcal{M}) \\, d\\theta.$$\n比较 $\\mathcal{M}_1$ 与 $\\mathcal{M}_2$ 的贝叶斯因子定义为\n$$\\mathrm{BF}_{1,2} = \\frac{p(D \\mid \\mathcal{M}_1)}{p(D \\mid \\mathcal{M}_2)}.$$\n\n- 神经形态强化学习策略使用 softmax 决策规则。对于具有当前价值估计 $(Q_0, Q_1)$ 和逆温度 $\\kappa > 0$ 的两个行动，在时间 $t$ 选择行动 $c_t \\in \\{0,1\\}$ 的概率为\n$$p(c_t \\mid Q_t, \\kappa) = \\frac{\\exp(\\kappa Q_{t, c_t})}{\\exp(\\kappa Q_{t, 0}) + \\exp(\\kappa Q_{t, 1})}.$$\n在观察到奖励 $r_t \\in [0,1]$ 后，所选行动的价值更新取决于机制性解释：\n- 对于 $\\mathcal{M}_1$：定义预测误差 $\\delta_t = r_t - Q_{t, c_t}$。如果 $\\delta_t \\ge 0$，则使用 $\\alpha_{+}$，否则使用 $\\alpha_{-}$，更新规则为\n$$Q_{t+1, c_t} = Q_{t, c_t} + \\alpha_{\\pm} \\, \\delta_t,$$\n未选择行动的价值保持不变，即 $Q_{t+1, \\text{other}} = Q_{t, \\text{other}}$。\n- 对于 $\\mathcal{M}_2$：计算衰减后的奖励 $r'_t = \\lambda \\, r_t$。然后预测误差为 $\\delta_t = r'_t - Q_{t, c_t}$，更新规则为\n$$Q_{t+1, c_t} = Q_{t, c_t} + \\alpha \\, \\delta_t,$$\n且 $Q_{t+1, \\text{other}} = Q_{t, \\text{other}}$。\n\n- 初始值为 $Q_{0,0} = 0$ 和 $Q_{0,1} = 0$。在所有情况和模型中，逆温度固定为 $\\kappa = 5.0$（无量纲）。以上所有量均为无量纲；不需要物理单位。\n\n- 先验：对于 $\\mathcal{M}_1$，对学习率使用独立的 Beta 先验：\n$$\\alpha_{+} \\sim \\mathrm{Beta}(2,2), \\quad \\alpha_{-} \\sim \\mathrm{Beta}(2,2).$$\n对于 $\\mathcal{M}_2$，使用独立的 Beta 先验\n$$\\alpha \\sim \\mathrm{Beta}(2,2), \\quad \\lambda \\sim \\mathrm{Beta}(3,2).$$\n对于 $x \\in (0,1)$，形状为 $(a,b)$ 的 Beta 密度为\n$$f(x \\mid a,b) = \\frac{x^{a-1}(1-x)^{b-1}}{B(a,b)},$$\n其中 $B(a,b)$ 是 Beta 函数。\n\n对于数据集 $D=\\{(c_t, r_t)\\}_{t=1}^T$ 的似然构建：\n\n- 对于给定模型的任何参数 $\\theta$，似然 $p(D \\mid \\theta, \\mathcal{M})$ 是在给定当前价值和 softmax 规则的情况下，所有试验的选择概率的乘积，\n$$p(D \\mid \\theta, \\mathcal{M}) = \\prod_{t=1}^T p(c_t \\mid Q_t(\\theta), \\kappa),$$\n其中 $Q_t(\\theta)$ 使用观察到的奖励 $r_t$ 根据模型的更新规则进行演变。\n\n数值评估要求：\n\n- 通过在参数域上进行数值积分，为每个模型计算贝叶斯模型证据 $p(D \\mid \\mathcal{M})$。每个参数维度在区间 $[\\epsilon, 1-\\epsilon]$ (其中 $\\epsilon = 10^{-6}$) 上使用一个包含 $N = 101$ 个点的均匀网格。离散近似为\n$$p(D \\mid \\mathcal{M}) \\approx \\sum_{i} \\sum_{j} \\cdots \\left( p(D \\mid \\theta_{i,j,\\ldots}, \\mathcal{M}) \\, p(\\theta_{i,j,\\ldots} \\mid \\mathcal{M}) \\right) \\prod_{d} \\Delta_d,$$\n其中 $\\Delta_d$ 是维度 $d$ 的网格步长。为保证数值稳定性，请使用 log-sum-exp 算子在对数域中计算总和。\n\n测试套件：\n\n为以下三个数据集提供结果（每个数据集都是一个包含 $T=8$ 次试验的序列）。每个数据集包含选择和奖励：\n- 用例 1 (混合奖励与选择)：选择 $[0,0,1,1,0,1,0,1]$，奖励 $[1,0,1,0,1,1,0,0]$。\n- 用例 2 (边界情况，零奖励)：选择 $[0,1,0,1,0,1,0,1]$，奖励 $[0,0,0,0,0,0,0,0]$。\n- 用例 3 (一个行动持续获得奖励，且主要选择该行动)：选择 $[0,0,0,0,1,0,0,0]$，奖励 $[1,1,1,1,0,1,1,1]$。\n\n您的程序必须：\n- 实现所述的两种机制性解释。\n- 对于每个数据集，通过基于网格的数值积分（$N=101, \\epsilon = 10^{-6}$）计算 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 的贝叶斯模型证据。\n- 为每个数据集计算贝叶斯因子 $\\mathrm{BF}_{1,2}$。\n\n最终输出格式：\n\n- 您的程序应生成单行输出，其中包含三个测试用例的贝叶斯因子，形式为方括号内的逗号分隔列表。每个贝叶斯因子必须是浮点数，四舍五入到六位小数，并按用例 $1, 2, 3$ 的顺序列出，例如 `[bf_1,bf_2,bf_3]`，其中每个 `bf_i` 是一个四舍五入到六位小数的十进制数。",
            "solution": "目标是执行贝叶斯模型比较，对比两种强化学习的机制性模型，即 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$。这两个模型代表了关于决策功能障碍的竞争性假设。比较通过贝叶斯因子 $\\mathrm{BF}_{1,2}$ 进行裁决，该因子量化了给定数据集 $D$ 支持 $\\mathcal{M}_1$ 相对于 $\\mathcal{M}_2$ 的证据。\n\n贝叶斯模型比较的核心是贝叶斯因子，定义为模型证据（或边缘似然）的比率：\n$$\n\\mathrm{BF}_{1,2} = \\frac{p(D \\mid \\mathcal{M}_1)}{p(D \\mid \\mathcal{M}_2)}\n$$\n这需要为每个模型计算模型证据 $p(D \\mid \\mathcal{M})$。证据是通过在整个参数空间 $\\theta$ 上对数据似然 $p(D \\mid \\theta, \\mathcal{M})$进行积分得到的，并由参数的先验概率 $p(\\theta \\mid \\mathcal{M})$ 进行加权：\n$$\np(D \\mid \\mathcal{M}) = \\int p(D \\mid \\theta, \\mathcal{M}) \\, p(\\theta \\mid \\mathcal{M}) \\, d\\theta\n$$\n对于本问题，被积函数的两个组成部分——似然和先验——都有明确的定义。\n\n似然函数 $p(D \\mid \\theta, \\mathcal{M})$ 源自智能体的决策过程。对于一个包含选择序列 $c_t$ 和奖励序列 $r_t$ 的数据集 $D = \\{(c_t, r_t)\\}_{t=1}^T$，总似然是每个单独选择概率的乘积，这些概率以截至该时间点的行动和奖励历史为条件。这个历史被封装在学习到的行动价值估计 $Q_t$ 中。\n$$\np(D \\mid \\theta, \\mathcal{M}) = \\prod_{t=1}^T p(c_t \\mid Q_t(\\theta), \\kappa)\n$$\n该似然的计算需要针对一组给定的参数 $\\theta$ 对智能体的学习过程进行逐次试验的模拟。过程如下：\n1. 将行动价值初始化为零：$Q_{0,0} = 0.0$ 和 $Q_{0,1} = 0.0$。\n2. 对于从 $1$ 到 $T$ 的每次试验 $t$：\n    a. 使用softmax函数计算智能体做出观察到的选择 $c_t$ 的概率，其中逆温度固定为 $\\kappa = 5.0$：\n    $$p(c_t \\mid Q_t, \\kappa) = \\frac{\\exp(\\kappa Q_{t, c_t})}{\\exp(\\kappa Q_{t, 0}) + \\exp(\\kappa Q_{t, 1})}$$\n    b. 所选行动的价值 $Q_{t, c_t}$ 根据特定模型 $\\mathcal{M}_1$ 或 $\\mathcal{M}_2$ 的规则进行更新。未选择行动的价值保持不变。\n\n两种模型在价值更新机制上有所不同：\n- **模型 $\\mathcal{M}_1$ (非对称学习率):** 该模型具有参数 $\\theta_1 = (\\alpha_+, \\alpha_-)$。预测误差为 $\\delta_t = r_t - Q_{t,c_t}$。更新规则为 $Q_{t+1, c_t} = Q_{t, c_t} + \\alpha_{\\pm} \\delta_t$，其中如果 $\\delta_t \\ge 0$ 则使用 $\\alpha_+$，否则使用 $\\alpha_-$。\n- **模型 $\\mathcal{M}_2$ (奖励衰减):** 该模型具有参数 $\\theta_2 = (\\alpha, \\lambda)$。首先对奖励进行衰减，$r'_t = \\lambda r_t$。然后预测误差为 $\\delta_t = r'_t - Q_{t,c_t}$，更新规则为 $Q_{t+1, c_t} = Q_{t, c_t} + \\alpha \\delta_t$。\n\n为了数值稳定性，所有似然计算都在对数域中执行。对于给定的 $\\theta$，总对数似然是每个选择的对数概率之和：$\\mathcal{L}(\\theta) = \\sum_{t=1}^T \\log p(c_t \\mid Q_t(\\theta), \\kappa)$。\n\n先验分布 $p(\\theta \\mid \\mathcal{M})$ 编码了我们在观察数据之前对参数的信念。问题为所有参数指定了 Beta 分布：\n- 对于 $\\mathcal{M}_1$：$\\alpha_+ \\sim \\mathrm{Beta}(2,2)$ 且 $\\alpha_- \\sim \\mathrm{Beta}(2,2)$。联合先验为 $p(\\theta_1 \\mid \\mathcal{M}_1) = p(\\alpha_+ \\mid a=2, b=2) p(\\alpha_- \\mid a=2, b=2)$。\n- 对于 $\\mathcal{M}_2$：$\\alpha \\sim \\mathrm{Beta}(2,2)$ 且 $\\lambda \\sim \\mathrm{Beta}(3,2)$。联合先验为 $p(\\theta_2 \\mid \\mathcal{M}_2) = p(\\alpha \\mid a=2, b=2) p(\\lambda \\mid a=3, b=2)$。\n\n模型证据积分在解析上是难解的，因此我们采用数值积分。每个模型的二维参数空间被离散化为一个 $N \\times N$ 的均匀网格，其中 $N=101$。每个参数的网格跨越区间 $[\\epsilon, 1-\\epsilon]$，其中 $\\epsilon = 10^{-6}$。该积分通过对所有网格点 $(\\theta_{ij})$ 求和来近似：\n$$p(D \\mid \\mathcal{M}) \\approx \\sum_{i=1}^N \\sum_{j=1}^N p(D \\mid \\theta_{ij}, \\mathcal{M}) p(\\theta_{ij} \\mid \\mathcal{M}) \\Delta^2$$\n其中 $\\Delta = (1 - 2\\epsilon) / (N-1)$ 是网格间距。为避免下溢和其他数值问题，此和在对数域中计算。对数证据为：\n$$\n\\log p(D \\mid \\mathcal{M}) \\approx \\log \\left( \\sum_{i,j} \\exp(\\mathcal{L}(\\theta_{ij}) + \\log p(\\theta_{ij} \\mid \\mathcal{M})) \\right) + 2\\log(\\Delta)\n$$\n求和项使用 log-sum-exp 算法计算，该算法提供了数值稳定性。\n\n算法实现遵循了这一原则性设计。一个主函数遍历提供的三个数据集。对于每个数据集，它为两个模型中的每一个调用一个专用函数 `calculate_log_evidence`。该函数构建参数网格，并为网格上的每个点计算对数先验（使用 `scipy.stats.beta.logpdf`）和对数似然。对数似然函数本身模拟了智能体的逐次试验行为。得到的对数后验项（对数似然加对数先验）使用 `scipy.special.logsumexp`进行聚合，以计算对数证据。最后，从对数证据计算出贝叶斯因子：$\\mathrm{BF}_{1,2} = \\exp(\\log p(D \\mid \\mathcal{M}_1) - \\log p(D \\mid \\mathcal{M}_2))$。然后将每个用例的结果按规定进行四舍五入和格式化。\n\n```python\nimport numpy as np\nfrom scipy.stats import beta\nfrom scipy.special import logsumexp\n\ndef calculate_log_likelihood_m1(data, params, kappa):\n    \"\"\"\n    Calculates the total log-likelihood for Model 1 (asymmetric learning rates).\n    \n    Args:\n        data (tuple): A tuple of (choices, rewards).\n        params (tuple): A tuple of (alpha_pos, alpha_neg).\n        kappa (float): The inverse temperature parameter.\n\n    Returns:\n        float: The total log-likelihood of the data given the parameters.\n    \"\"\"\n    alpha_pos, alpha_neg = params\n    choices, rewards = data\n    \n    Q = np.array([0.0, 0.0])\n    total_log_likelihood = 0.0\n\n    for t in range(len(choices)):\n        c_t, r_t = choices[t], rewards[t]\n        \n        # Calculate log-probability of the choice\n        kappa_Q = kappa * Q\n        log_softmax_den = logsumexp(kappa_Q)\n        log_prob_choice = kappa_Q[c_t] - log_softmax_den\n        total_log_likelihood += log_prob_choice\n        \n        # Update Q-value based on M1's rule\n        delta = r_t - Q[c_t]\n        alpha = alpha_pos if delta >= 0.0 else alpha_neg\n        Q[c_t] += alpha * delta\n        \n    return total_log_likelihood\n\ndef calculate_log_likelihood_m2(data, params, kappa):\n    \"\"\"\n    Calculates the total log-likelihood for Model 2 (reward attenuation).\n\n    Args:\n        data (tuple): A tuple of (choices, rewards).\n        params (tuple): A tuple of (alpha, lambda).\n        kappa (float): The inverse temperature parameter.\n\n    Returns:\n        float: The total log-likelihood of the data given the parameters.\n    \"\"\"\n    alpha, lam = params\n    choices, rewards = data\n    \n    Q = np.array([0.0, 0.0])\n    total_log_likelihood = 0.0\n\n    for t in range(len(choices)):\n        c_t, r_t = choices[t], rewards[t]\n        \n        # Calculate log-probability of the choice\n        kappa_Q = kappa * Q\n        log_softmax_den = logsumexp(kappa_Q)\n        log_prob_choice = kappa_Q[c_t] - log_softmax_den\n        total_log_likelihood += log_prob_choice\n        \n        # Update Q-value based on M2's rule\n        r_prime = lam * r_t\n        delta = r_prime - Q[c_t]\n        Q[c_t] += alpha * delta\n        \n    return total_log_likelihood\n\ndef compute_log_evidence(data, priors_ab, likelihood_func, n_grid, epsilon, kappa):\n    \"\"\"\n    Computes the log model evidence via grid-based numerical integration.\n\n    Args:\n        data (tuple): A tuple of (choices, rewards).\n        priors_ab (list): A list of [a,b] for the Beta priors of the two parameters.\n        likelihood_func (function): The function to compute log-likelihood.\n        n_grid (int): The number of points on the grid for each parameter.\n        epsilon (float): The small offset for the grid boundaries.\n        kappa (float): The inverse temperature.\n\n    Returns:\n        float: The log model evidence.\n    \"\"\"\n    grid_points = np.linspace(epsilon, 1.0 - epsilon, n_grid)\n    delta = (1.0 - 2.0 * epsilon) / (n_grid - 1.0)\n    log_delta = np.log(delta)\n\n    priors = [(priors_ab[0][0], priors_ab[0][1]), (priors_ab[1][0], priors_ab[1][1])]\n    \n    log_prior1_vals = beta.logpdf(grid_points, priors[0][0], priors[0][1])\n    log_prior2_vals = beta.logpdf(grid_points, priors[1][0], priors[1][1])\n    \n    p1_grid, p2_grid = np.meshgrid(grid_points, grid_points, indexing='ij')\n\n    log_prior_grid = log_prior1_vals[:, np.newaxis] + log_prior2_vals[np.newaxis, :]\n    \n    log_likelihood_grid = np.zeros_like(p1_grid)\n    for i in range(n_grid):\n        for j in range(n_grid):\n            params = (p1_grid[i, j], p2_grid[i, j])\n            log_likelihood_grid[i, j] = likelihood_func(data, params, kappa)\n\n    log_posterior_terms = log_likelihood_grid + log_prior_grid\n    \n    log_sum_evidence = logsumexp(log_posterior_terms)\n    log_evidence = log_sum_evidence + 2.0 * log_delta\n    \n    return log_evidence\n\ndef solve():\n    \"\"\"\n    Main function to run the model comparison pipeline for the test cases.\n    \"\"\"\n    KAPPA = 5.0\n    N_GRID = 101\n    EPSILON = 1e-6\n\n    test_cases = [\n        ((0,0,1,1,0,1,0,1), (1,0,1,0,1,1,0,0)),\n        ((0,1,0,1,0,1,0,1), (0,0,0,0,0,0,0,0)),\n        ((0,0,0,0,1,0,0,0), (1,1,1,1,0,1,1,1)),\n    ]\n\n    priors_m1 = [[2.0, 2.0], [2.0, 2.0]] # (alpha+, alpha-)\n    priors_m2 = [[2.0, 2.0], [3.0, 2.0]] # (alpha, lambda)\n\n    results = []\n    for data in test_cases:\n        choices, rewards = np.array(data[0]), np.array(data[1])\n        formatted_data = (choices, rewards)\n\n        log_evidence_m1 = compute_log_evidence(\n            formatted_data, priors_m1, calculate_log_likelihood_m1,\n            N_GRID, EPSILON, KAPPA\n        )\n\n        log_evidence_m2 = compute_log_evidence(\n            formatted_data, priors_m2, calculate_log_likelihood_m2,\n            N_GRID, EPSILON, KAPPA\n        )\n        \n        log_bf_12 = log_evidence_m1 - log_evidence_m2\n        bf_12 = np.exp(log_bf_12)\n        \n        results.append(f\"{bf_12:.6f}\")\n\n    # This print is for local execution, the final output will be returned.\n    # print(f\"[{','.join(results)}]\")\n    return f\"[{','.join(results)}]\"\n\n# The function call is commented out as this block is part of a larger document.\n# if __name__ == '__main__':\n#     solve()\n```",
            "answer": "[1.216601,1.000000,0.579477]"
        }
    ]
}