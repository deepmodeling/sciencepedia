{
    "hands_on_practices": [
        {
            "introduction": "The 'winner-take-all' functionality is not simply a given; it is an emergent property of a network's collective dynamics. This first exercise invites you to explore the very origin of this competitive behavior through the lens of dynamical systems theory. By analyzing a simple two-neuron circuit, you will determine the critical level of inhibition required to transition the system from a state of peaceful coexistence to one of fierce competition, a phenomenon known as a bifurcation .",
            "id": "4067988",
            "problem": "You are given a minimal continuous-time model of a two-unit Winner-Take-All (WTA) circuit, a central motif in neuromorphic and brain-inspired computing. The network comprises two nonnegative rate variables $x_1$ and $x_2$ that evolve according to a threshold-linear (rectified linear) dynamical system. The equations are\n$$\n\\frac{dx_i}{dt} \\;=\\; -\\,x_i \\;+\\; \\phi\\!\\left(w\\,x_i \\;-\\; g\\,x_j \\;+\\; b\\right),\n\\quad \\text{for } i \\in \\{1,2\\},\\; j \\neq i,\n$$\nwhere $\\phi(u) = \\max\\{0,\\,u\\}$ is the threshold-linear activation, $w \\in \\mathbb{R}$ is a self-excitation weight, $g \\in \\mathbb{R}_{\\ge 0}$ is a global inhibition gain that couples the units competitively, and $b \\in \\mathbb{R}$ is a constant bias common to both units. The phase space is restricted to $x_i \\in \\mathbb{R}_{\\ge 0}$ for $i \\in \\{1,2\\}$.\n\nUse the following standard base concepts from dynamical systems:\n- A fixed point is any $(x_1^\\star,x_2^\\star)$ such that $\\frac{dx_1}{dt}=\\frac{dx_2}{dt}=0$.\n- For any differentiable regime, the local stability of a fixed point is determined by the eigenvalues of the Jacobian matrix $J$ of the right-hand side of the dynamical system evaluated at that fixed point; a fixed point is locally asymptotically stable if and only if all eigenvalues of $J$ have negative real parts.\n\nDefine the critical inhibition gain $g^\\star$ as the smallest value of $g$ for which the network transitions from having a stable multi-active equilibrium (both $x_1$ and $x_2$ strictly positive in steady state) to exhibiting only single-winner attractors (steady states in which exactly one of $x_1$ or $x_2$ is strictly positive and the other is $0$). Assume $w \\in (0,1)$ and $b > 0$, so that the leaky dynamics are well-defined and the rectifying nonlinearity is operative.\n\nTask:\n- Starting from the fundamental definitions above, derive the condition for the loss of stability of the symmetric multi-active fixed point as $g$ increases, and use it to determine $g^\\star$ as a function of $w$ and $b$.\n- Implement this reasoning in a program that, for each test case listed below, computes $g^\\star$ as a floating-point number. Express each output value as a decimal rounded to $6$ decimal places.\n\nTest suite (each test case is a pair $(w,b)$):\n- Case $1$: $(w,b)=(0.5,\\,1.0)$\n- Case $2$: $(w,b)=(0.0,\\,0.7)$\n- Case $3$: $(w,b)=(0.8,\\,0.3)$\n- Case $4$: $(w,b)=(0.99,\\,1.0)$\n- Case $5$: $(w,b)=(0.2,\\,5.0)$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$) where $r_k$ is the computed $g^\\star$ for test case $k$. Each $r_k$ must be a decimal rounded to $6$ decimal places.",
            "solution": "The user wants me to solve a problem about a Winner-Take-All (WTA) circuit.\n\nHere's my plan:\n1.  **Validate the Problem**: I will meticulously check the problem statement against my validation criteria.\n    *   **Step 1: Extract Givens**: I'll list all the equations, definitions, and constraints.\n        *   Dynamical system: $\\frac{dx_i}{dt} = -x_i + \\phi(w\\,x_i - g\\,x_j + b)$ for $i,j \\in \\{1,2\\}, j \\neq i$.\n        *   Activation function: $\\phi(u) = \\max\\{0, u\\}$.\n        *   State variables: $x_1, x_2 \\in \\mathbb{R}_{\\ge 0}$.\n        *   Parameters: $w \\in \\mathbb{R}$, $g \\in \\mathbb{R}_{\\ge 0}$, $b \\in \\mathbb{R}$.\n        *   Fixed point definition: $\\frac{dx_1}{dt}=\\frac{dx_2}{dt}=0$.\n        *   Stability condition: All eigenvalues of the Jacobian matrix $J$ at the fixed point have negative real parts.\n        *   Definition of $g^\\star$: Smallest $g$ where the stable multi-active equilibrium (both $x_1, x_2 > 0$) is lost, leading to only single-winner attractors ($x_i > 0, x_j = 0$).\n        *   Assumptions for the task: $w \\in (0,1)$ and $b > 0$.\n    *   **Step 2: Validate**: I will evaluate the problem for scientific soundness, clarity, completeness, and objectivity.\n        *   **Scientific Groundedness**: The model is a standard simplified form of a rate-based neural network model, commonly used in computational neuroscience and neuromorphic engineering. The concepts of fixed points, Jacobian matrices, and eigenvalue analysis for stability are fundamental to dynamical systems theory. The model is a simplified but valid representation of competitive dynamics. It is scientifically sound.\n        *   **Well-Posed**: The problem asks for a specific value, $g^\\star$, as a function of other parameters. The derivation process is clearly outlined: find a specific fixed point, analyze its stability, and find the parameter value where stability is lost. This suggests a well-posed problem that should have a unique solution.\n        *   **Objective**: The language is precise and mathematical. \"Critical inhibition gain,\" \"multi-active equilibrium,\" and \"single-winner attractors\" are defined or standard terms in the field. The task is objective.\n        *   **Completeness**: The equations, definitions, and constraints ($w \\in (0,1)$, $b>0$) are all provided. The information seems sufficient to carry out the derivation. The assumption $w<1$ is crucial for the existence of a stable fixed point in the absence of inhibition. The assumption $b>0$ ensures that the neurons can become active. The phase space is defined. The problem seems complete.\n        *   **Consistency**: The definitions and constraints are not contradictory. For example, $g \\ge 0$ is consistent with its role as an inhibition gain.\n    *   **Step 3: Verdict**: The problem is valid. It's a standard exercise in dynamical systems analysis applied to a well-known neural circuit model.\n\n2.  **Solve the Problem (Derivation)**:\n    *   **Find the multi-active fixed point**:\n        *   A multi-active fixed point $(x_1^\\star, x_2^\\star)$ has $x_1^\\star > 0$ and $x_2^\\star > 0$.\n        *   By symmetry of the equations, it's reasonable to look for a symmetric fixed point where $x_1^\\star = x_2^\\star = x^\\star > 0$.\n        *   The fixed point condition is $\\frac{dx_i}{dt} = 0$.\n        *   For $i=1$: $0 = -x_1^\\star + \\phi(w\\,x_1^\\star - g\\,x_2^\\star + b)$.\n        *   For $i=2$: $0 = -x_2^\\star + \\phi(w\\,x_2^\\star - g\\,x_1^\\star + b)$.\n        *   Since we assume $x^\\star > 0$, the argument of $\\phi$ must be positive for the fixed point to be non-zero. That is, $w\\,x_1^\\star - g\\,x_2^\\star + b > 0$ and $w\\,x_2^\\star - g\\,x_1^\\star + b > 0$.\n        *   This allows us to drop the $\\phi$ function (i.e., $\\phi(u)=u$ in this regime).\n        *   The system becomes:\n            *   $x_1^\\star = w\\,x_1^\\star - g\\,x_2^\\star + b$\n            *   $x_2^\\star = w\\,x_2^\\star - g\\,x_1^\\star + b$\n        *   Let's substitute $x_1^\\star = x_2^\\star = x^\\star$:\n            *   $x^\\star = w\\,x^\\star - g\\,x^\\star + b$\n        *   Now, solve for $x^\\star$:\n            *   $x^\\star(1 - w + g) = b$\n            *   $x^\\star = \\frac{b}{1 - w + g}$\n        *   We need to verify the condition that the argument of $\\phi$ is positive.\n            *   $w\\,x^\\star - g\\,x^\\star + b = (w-g)x^\\star + b > 0$.\n            *   Substitute $x^\\star$: $(w-g)\\frac{b}{1-w+g} + b > 0$.\n            *   Since $b>0$, we can divide by $b$: $\\frac{w-g}{1-w+g} + 1 > 0$.\n            *   $\\frac{w-g + (1-w+g)}{1-w+g} > 0$.\n            *   $\\frac{1}{1-w+g} > 0$.\n            *   Since $w<1$ and $g \\ge 0$, the denominator $1-w+g$ is always positive. So this condition is always met for any valid parameters.\n        *   We also require $x^\\star > 0$. Since $b>0$ and $1-w+g > 0$, this is also always met.\n        *   So, a symmetric multi-active fixed point exists at $(x^\\star, x^\\star) = \\left(\\frac{b}{1-w+g}, \\frac{b}{1-w+g}\\right)$ for all valid parameter choices.\n\n    *   **Analyze the stability of this fixed point**:\n        *   The system of equations is:\n            *   $\\frac{dx_1}{dt} = F_1(x_1, x_2) = -x_1 + \\phi(w\\,x_1 - g\\,x_2 + b)$\n            *   $\\frac{dx_2}{dt} = F_2(x_1, x_2) = -x_2 + \\phi(w\\,x_2 - g\\,x_1 + b)$\n        *   The Jacobian matrix is $J = \\begin{pmatrix} \\frac{\\partial F_1}{\\partial x_1} & \\frac{\\partial F_1}{\\partial x_2} \\\\ \\frac{\\partial F_2}{\\partial x_1} & \\frac{\\partial F_2}{\\partial x_2} \\end{pmatrix}$.\n        *   We need the derivative of $\\phi(u) = \\max\\{0,u\\}$. The derivative is $\\phi'(u) = 1$ if $u>0$ and $0$ if $u<0$. It's undefined at $u=0$.\n        *   In the neighborhood of the multi-active fixed point $(x^\\star, x^\\star)$, we have $w\\,x_1 - g\\,x_2 + b > 0$ and $w\\,x_2 - g\\,x_1 + b > 0$.\n        *   So, in this regime, $\\phi'(u)=1$.\n        *   Let's compute the partial derivatives:\n            *   $\\frac{\\partial F_1}{\\partial x_1} = -1 + \\phi'(w\\,x_1 - g\\,x_2 + b) \\cdot w = -1 + w$.\n            *   $\\frac{\\partial F_1}{\\partial x_2} = \\phi'(w\\,x_1 - g\\,x_2 + b) \\cdot (-g) = -g$.\n            *   $\\frac{\\partial F_2}{\\partial x_1} = \\phi'(w\\,x_2 - g\\,x_1 + b) \\cdot (-g) = -g$.\n            *   $\\frac{\\partial F_2}{\\partial x_2} = -1 + \\phi'(w\\,x_2 - g\\,x_1 + b) \\cdot w = -1 + w$.\n        *   The Jacobian matrix is constant in this regime:\n            $$\n            J = \\begin{pmatrix} w-1 & -g \\\\ -g & w-1 \\end{pmatrix}\n            $$\n        *   Now, find the eigenvalues $\\lambda$ of $J$.\n            *   The characteristic equation is $\\det(J - \\lambda I) = 0$.\n            *   $\\det \\begin{pmatrix} w-1-\\lambda & -g \\\\ -g & w-1-\\lambda \\end{pmatrix} = 0$\n            *   $(w-1-\\lambda)^2 - (-g)(-g) = 0$\n            *   $(w-1-\\lambda)^2 - g^2 = 0$\n            *   $w-1-\\lambda = \\pm g$\n            *   $\\lambda = w - 1 \\mp g$\n        *   The two eigenvalues are:\n            *   $\\lambda_1 = w - 1 - g$\n            *   $\\lambda_2 = w - 1 + g$\n        *   The condition for local asymptotic stability is that both eigenvalues have negative real parts. Since they are real, we need $\\lambda_1 < 0$ and $\\lambda_2 < 0$.\n            *   $\\lambda_1 = w - 1 - g < 0$. Since $w<1$ and $g \\ge 0$, we have $w-1 < 0$ and $-g \\le 0$. Thus, $w-1-g$ is always negative. This condition is always satisfied.\n            *   $\\lambda_2 = w - 1 + g < 0$. This is the critical condition.\n        *   Stability is maintained as long as $w - 1 + g < 0$, which means $g < 1 - w$.\n        *   The fixed point loses its stability when this inequality is violated. The transition happens exactly when $\\lambda_2 = 0$.\n\n    *   **Determine $g^\\star$**:\n        *   The transition from a stable multi-active equilibrium to an unstable one (which then gives rise to the stable single-winner attractors via a pitchfork bifurcation) occurs when the second eigenvalue crosses zero.\n        *   The critical inhibition gain $g^\\star$ is the value of $g$ at which this happens.\n        *   $w - 1 + g^\\star = 0$\n        *   $g^\\star = 1 - w$\n        *   The problem defines $g^\\star$ as the *smallest* value of $g$ for which the stable multi-active equilibrium is lost. For $g < 1-w$, the equilibrium is stable. For $g \\ge 1-w$, it is unstable. The smallest value at which it is no longer stable is $g=1-w$.\n        *   Let's check the assumptions. We assumed $w \\in (0,1)$ and $b > 0$.\n        *   The formula $g^\\star = 1 - w$ only depends on $w$.\n        *   For $w \\in (0,1)$, we have $1-w \\in (0,1)$. This is a positive value, consistent with $g \\ge 0$.\n        *   The parameter $b$ determines the *value* of the fixed point coordinates ($x^\\star = b/(1-w+g)$), but not its stability boundary. This seems plausible. The stability of a linear system is independent of the constant input term, which is what $b$ acts as in the linear regime.\n        *   The question asks for $g^\\star$ as a function of $w$ and $b$. My result is $g^\\star = 1-w$. This is a function of $w$ but not $b$. This is not a contradiction; it just means the dependency on $b$ is trivial. Let me double check if I missed anything.\n        *   The derivation is based on the Jacobian, which is derived from the RHS of the ODE. The RHS is $F_i = -x_i + w x_i - g x_j + b$ in the linear regime. The Jacobian elements are $\\partial F_i / \\partial x_k$. The derivative of the constant $b$ with respect to any $x_k$ is zero. So $b$ correctly drops out of the Jacobian and thus the stability analysis.\n        *   The derivation seems solid. $g^\\star = 1-w$.\n\n3.  **Implement the Solution in Python**:\n    *   The task is to compute $g^\\star$ for several given pairs of $(w,b)$.\n    *   The formula is simply $g^\\star = 1 - w$.\n    *   I need to implement a function that takes $w$ and $b$, computes $g^\\star$, and returns it.\n    *   The main script will iterate through the test cases, call this function, and store the results.\n    *   The final output must be formatted as a comma-separated list in brackets, with each number rounded to 6 decimal places.\n\n    *   **Test Cases**:\n        *   Case 1: $(w,b)=(0.5,\\,1.0) \\implies g^\\star = 1 - 0.5 = 0.5$\n        *   Case 2: $(w,b)=(0.0,\\,0.7)$. The problem states $w \\in (0,1)$. Here $w=0.0$. Is this an invalid test case? The problem statement says \"Assume $w \\in (0,1)$...\". This might be a trick. Let me re-read. \"Assume $w \\in (0,1)$ and $b > 0$, so that the leaky dynamics are well-defined and the rectifying nonlinearity is operative.\" This is a global assumption for the derivation. A test case with $w=0.0$ violates this assumption.\n        *   Let's check the derivation if $w=0$.\n            *   $\\frac{dx_i}{dt} = -x_i + \\phi(-g x_j + b)$.\n            *   Symmetric fixed point: $x^\\star = \\phi(-g x^\\star + b)$.\n            *   For $x^\\star>0$, we need $x^\\star = -g x^\\star + b \\implies x^\\star(1+g)=b \\implies x^\\star = b/(1+g)$.\n            *   Condition for linearity: $-g x^\\star + b > 0 \\implies -g(b/(1+g)) + b > 0 \\implies b(-g/(1+g)+1)>0 \\implies b( (-g+1+g)/(1+g) ) > 0 \\implies b/(1+g) > 0$. Since $b>0, g \\ge 0$, this is always true.\n            *   So a symmetric fixed point exists.\n            *   Jacobian at this point:\n                *   $\\frac{\\partial F_1}{\\partial x_1} = -1 + \\phi'(w x_1 - g x_2 + b) \\cdot w = -1 + 1 \\cdot 0 = -1$.\n                *   $\\frac{\\partial F_1}{\\partial x_2} = \\phi'(\\dots) \\cdot (-g) = -g$.\n                *   $J = \\begin{pmatrix} -1 & -g \\\\ -g & -1 \\end{pmatrix}$.\n            *   Eigenvalues: $\\det \\begin{pmatrix} -1-\\lambda & -g \\\\ -g & -1-\\lambda \\end{pmatrix} = 0$.\n            *   $(-1-\\lambda)^2 - g^2 = 0 \\implies -1-\\lambda = \\pm g \\implies \\lambda = -1 \\mp g$.\n            *   $\\lambda_1 = -1-g$. Since $g \\ge 0$, this is always negative (or $-1$ if $g=0$).\n            *   $\\lambda_2 = -1+g$.\n            *   Stability condition: $\\lambda_2 < 0 \\implies -1+g < 0 \\implies g < 1$.\n            *   So, $g^\\star = 1$.\n            *   The formula $g^\\star = 1-w$ gives $g^\\star = 1-0 = 1$. It seems the formula holds even for $w=0$.\n            *   So the assumption $w \\in (0,1)$ was likely just to ensure $w$ is not too large (e.g., $w>1$), which would lead to unbounded activity even with no input. The edge case $w=0$ seems fine. So I'll proceed with the formula $g^\\star=1-w$.\n            *   Case 2 result: $g^\\star = 1 - 0.0 = 1.0$.\n\n        *   Case 3: $(w,b)=(0.8,\\,0.3) \\implies g^\\star = 1 - 0.8 = 0.2$\n        *   Case 4: $(w,b)=(0.99,\\,1.0) \\implies g^\\star = 1 - 0.99 = 0.01$\n        *   Case 5: $(w,b)=(0.2,\\,5.0) \\implies g^\\star = 1 - 0.2 = 0.8$\n\n    *   **Code Structure**:\n        ```python\n        import numpy as np # Not strictly needed, but good practice to include if the boilerplate has it.\n\n        def solve():\n            test_cases = [\n                (0.5, 1.0),\n                (0.0, 0.7),\n                (0.8, 0.3),\n                (0.99, 1.0),\n                (0.2, 5.0),\n            ]\n\n            results = []\n            for w, b in test_cases:\n                # Based on the derivation, g_star = 1 - w\n                g_star = 1.0 - w\n                # Format to 6 decimal places.\n                results.append(f\"{g_star:.6f}\")\n\n            # The final print statement in the exact required format.\n            print(f\"[{','.join(results)}]\")\n\n        solve()\n        ```\n        This looks correct and robust. The `numpy` import is not used, so I can remove it to be cleaner, even though the instructions say it's available. It's better to only import what's used. Wait, the shell boilerplate in the problem description includes it. I will keep it to adhere to the template. `from scipy import ...` is not needed.\n\n4.  **Final Review of the Solution write-up**:\n    *   The solution must be a step-by-step derivation.\n    *   Every mathematical entity must be in LaTeX.\n    *   No markdown headers.\n    *   The derivation should be clear and follow the steps I planned.\n    *   Start by defining the system.\n    *   Find the symmetric multi-active fixed point $(x^\\star, x^\\star)$.\n    *   Justify dropping the $\\phi$ nonlinearity by showing its argument is positive in the vicinity of this fixed point.\n    *   Compute the Jacobian matrix $J$ for the linearized system around the fixed point.\n    *   Calculate the eigenvalues of $J$.\n    *   State the stability condition (eigenvalues must have negative real parts).\n    *   Identify the specific eigenvalue and condition that determines the stability boundary.\n    *   Solve for $g$ at this boundary to find $g^\\star$.\n    *   Explain why $g^\\star$ is independent of $b$.\n    *   State the final formula for $g^\\star$.\n\n    The structure for the solution section:\n    *   **Introduction**: State the goal is to find the critical inhibition gain $g^\\star$ by analyzing the stability of the symmetric multi-active fixed point.\n    *   **Step 1: Finding the Symmetric Multi-Active Fixed Point**:\n        *   Write down the fixed point equations: $0 = -x_i^\\star + \\phi(w\\,x_i^\\star - g\\,x_j^\\star + b)$.\n        *   Assume a symmetric solution $x_1^\\star = x_2^\\star = x^\\star > 0$.\n        *   For $x^\\star > 0$, the argument of $\\phi$ must be positive, allowing us to linearize: $x^\\star = w\\,x^\\star - g\\,x^\\star + b$.\n        *   Solve for $x^\\star$: $x^\\star = \\frac{b}{1 - w + g}$.\n        *   Verify the positivity conditions $x^\\star > 0$ and $w\\,x^\\star - g\\,x^\\star + b > 0$, confirming the existence and location of this fixed point for the given parameter constraints ($w \\in (0,1)$, $b>0$, $g \\ge 0$).\n    *   **Step 2: Stability Analysis via Linearization**:\n        *   Define the right-hand side of the ODE system: $F_i(x_1, x_2) = -x_i + \\phi(w\\,x_i - g\\,x_j + b)$.\n        *   Compute the Jacobian matrix $J_{ij} = \\frac{\\partial F_i}{\\partial x_j}$.\n        *   In the neighborhood of the symmetric fixed point, the system is in its linear regime, so $\\phi'(u) = 1$.\n        *   Calculate the four entries of the Jacobian: $J_{11} = w-1$, $J_{12} = -g$, etc.\n        *   Write down the Jacobian matrix: $J = \\begin{pmatrix} w-1 & -g \\\\ -g & w-1 \\end{pmatrix}$.\n    *   **Step 3: Eigenvalue Calculation and Stability Condition**:\n        *   Find the eigenvalues $\\lambda$ by solving the characteristic equation $\\det(J - \\lambda I) = 0$.\n        *   Show the calculation: $(w-1-\\lambda)^2 - g^2 = 0$.\n        *   State the two eigenvalues: $\\lambda_1 = w - 1 - g$ and $\\lambda_2 = w - 1 + g$.\n        *   The condition for asymptotic stability is that the real parts of all eigenvalues are negative. Since the eigenvalues are real, we require $\\lambda_1 < 0$ and $\\lambda_2 < 0$.\n    *   **Step 4: Determining the Critical Gain $g^\\star$**:\n        *   Analyze the first condition: $\\lambda_1 = w - 1 - g < 0$. Show that this is always true given $w < 1$ and $g \\ge 0$.\n        *   Analyze the second condition: $\\lambda_2 = w - 1 + g < 0$. This is the critical condition that determines stability. The system is stable for $g < 1 - w$.\n        *   The stability of the symmetric fixed point is lost when $\\lambda_2$ crosses from negative to positive, which occurs at $\\lambda_2 = 0$.\n        *   Define $g^\\star$ as the value of $g$ that satisfies this transition point: $w - 1 + g^\\star = 0$.\n        *   Derive the final expression: $g^\\star = 1 - w$.\n        *   Note that this result is independent of the bias $b$, as $b$ is a constant term that vanishes upon differentiation when computing the Jacobian.\n    *   This detailed write-up follows the principles and is scientifically rigorous. All math will be in LaTeX. The final code will be placed in the `<final_answer>` tag.\n\nLet's double check the problem statement phrasing. \"smallest value of $g$ for which the network transitions from having a stable multi-active equilibrium ... to exhibiting only single-winner attractors\". This is consistent with finding the point where the symmetric equilibrium loses stability. This type of transition is a pitchfork bifurcation, where the stable symmetric fixed point becomes unstable, and two new stable asymmetric fixed points (the \"single-winner attractors\") emerge. My derivation correctly identifies the point of this bifurcation.\n\nThe logic is sound. I will now proceed to write the solution and the final code.\nThe constraints are $w \\in (0,1)$ and $b>0$.\nTest Case 1: $(w,b)=(0.5, 1.0)$. $w$ is in $(0,1)$, $b > 0$. Valid. $g^\\star = 1-0.5 = 0.5$.\nTest Case 2: $(w,b)=(0.0, 0.7)$. $w=0$, not in $(0,1)$. As analyzed, the formula $g^\\star=1-w$ still holds for this boundary case. I will treat it as a valid test case. It is common in such problems for test suites to include boundary conditions of the assumptions. $g^\\star = 1-0 = 1.0$.\nTest Case 3: $(w,b)=(0.8, 0.3)$. $w$ is in $(0,1)$, $b > 0$. Valid. $g^\\star = 1-0.8 = 0.2$.\nTest Case 4: $(w,b)=(0.99, 1.0)$. $w$ is in $(0,1)$, $b > 0$. Valid. $g^\\star = 1-0.99 = 0.01$.\nTest Case 5: $(w,b)=(0.2, 5.0)$. $w$ is in $(0,1)$, $b > 0$. Valid. $g^\\star = 1-0.2 = 0.8$.\nAll test cases are reasonable and can be solved with the derived formula.\nThe rounding to 6 decimal places will be handled by `f\"{value:.6f}\"`.\nExample: $g^\\star = 0.5$ becomes `\"0.500000\"`.\n$g^\\star = 1.0$ becomes `\"1.000000\"`.\n$g^\\star = 0.2$ becomes `\"0.200000\"`.\n$g^\\star = 0.01$ becomes `\"0.010000\"`.\n$g^\\star = 0.8$ becomes `\"0.800000\"`.\nThe final output will be `[0.500000,1.000000,0.200000,0.010000,0.800000]`.\nThe logic seems complete and correct. I am ready to write the solution.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Computes the critical inhibition gain g* for a set of test cases.\n    The derivation shows that g* = 1 - w, independent of b.\n    \"\"\"\n    # Define the test cases from the problem statement as pairs of (w, b).\n    test_cases = [\n        (0.5, 1.0),\n        (0.0, 0.7),\n        (0.8, 0.3),\n        (0.99, 1.0),\n        (0.2, 5.0),\n    ]\n\n    results = []\n    for w, b in test_cases:\n        # According to the derived formula, the critical inhibition gain g_star\n        # is given by 1 - w.\n        g_star = 1.0 - w\n        \n        # Format the result to 6 decimal places as a string.\n        # This formatting handles rounding and ensures the correct number of decimal places.\n        formatted_result = f\"{g_star:.6f}\"\n        results.append(formatted_result)\n\n    # Final print statement in the exact required format: [r_1,r_2,...]\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Ideal models provide crucial intuition, but real-world hardware is imperfect. This practice addresses the challenge of device mismatch, where tiny physical variations between transistors can disrupt a WTA circuit's decision. You will apply statistical principles to determine the minimum inhibitory strength needed to overcome this inherent randomness and ensure the correct winner is selected with high probability, bridging the gap between abstract theory and robust physical implementation .",
            "id": "4067903",
            "problem": "Consider a pool of $N$ identical linear-threshold neurons implementing a winner-take-all (WTA) circuit, modeled at steady state by a single active neuron (the winner) inhibiting all others equally. Let the deterministic input currents be ordered as $I_{1} > I_{2} \\geq I_{3} \\geq \\cdots \\geq I_{N} > 0$. Each neuron has an effective threshold uncertainty due to device mismatch modeled as an independent, identically distributed random offset $\\delta V_{T,i} \\sim \\mathcal{N}(0,\\sigma_{V_{T}}^{2})$, which linearly perturbs the effective input current by $-\\alpha\\,\\delta V_{T,i}$, where $\\alpha > 0$ converts threshold offset in volts to an equivalent current shift in amperes.\n\nAssume the following simplified steady-state interaction: if neuron $w$ with input $I_{1}$ is the winner, then its output equals its effective input, so its steady-state activity is $x_{w} = I_{1} - \\alpha\\,\\delta V_{T,1}$, and each loser $k \\neq w$ receives a net input $I_{k} - \\alpha\\,\\delta V_{T,k} - g\\,x_{w}$, where $g > 0$ is the uniform inhibitory gain. Correct winner selection means that all losers are suppressed, i.e., $I_{k} - \\alpha\\,\\delta V_{T,k} - g\\,(I_{1} - \\alpha\\,\\delta V_{T,1}) < 0$ for all $k \\geq 2$.\n\nTo guarantee correct winner selection with confidence $1-\\epsilon$ (that is, with probability at least $1-\\epsilon$ over the random threshold offsets), it suffices to enforce suppression of the strongest competitor $k=2$. Using only:\n- the independence and Gaussianity of $\\delta V_{T,1}$ and $\\delta V_{T,2}$,\n- the definition that if $X \\sim \\mathcal{N}(\\mu,\\sigma^{2})$ then $\\mathbb{P}[X > 0] = \\Phi\\!\\big(\\mu/\\sigma\\big)$ where $\\Phi(\\cdot)$ is the standard normal cumulative distribution function,\n\nderive a closed-form analytic expression for the minimal inhibitory gain $g_{\\min}$ as a function of $I_{1}$, $I_{2}$, $\\alpha$, $\\sigma_{V_{T}}$, and $\\epsilon$ that achieves $\\mathbb{P}[\\text{correct winner}] \\geq 1-\\epsilon$. Express your final answer in terms of the standard normal quantile $z_{1-\\epsilon}$ defined by $z_{1-\\epsilon} = \\Phi^{-1}(1-\\epsilon)$.\n\nYour final answer must be a single closed-form analytic expression for $g_{\\min}$ in terms of the given symbols. Do not introduce any numerical approximations or rounding. No units are required in the final answer. Ensure all symbols are clearly defined as above, and assume parameter values such that the expression is real and finite.",
            "solution": "The problem is assessed to be valid. It is scientifically grounded in the theory of neuromorphic circuits, well-posed with a clear objective and sufficient information, and free of contradictions or ambiguities.\n\nThe goal is to find the minimal inhibitory gain $g_{\\min}$ that ensures correct winner selection with a probability of at least $1-\\epsilon$. The problem states that neuron $1$ is the intended winner, as it receives the largest input current $I_{1}$. Correct winner selection requires all other neurons $k \\geq 2$ to be suppressed. The problem simplifies this by stating it is sufficient to enforce suppression for the strongest competitor, which is neuron $k=2$ with input current $I_{2}$.\n\nThe condition for the suppression of neuron $k=2$ is given as:\n$$I_{2} - \\alpha\\,\\delta V_{T,2} - g\\,(I_{1} - \\alpha\\,\\delta V_{T,1}) < 0$$\nwhere $g$ is the inhibitory gain, $\\alpha > 0$ is a conversion factor, and $\\delta V_{T,1}$ and $\\delta V_{T,2}$ are independent random variables representing threshold voltage offsets, drawn from a normal distribution $\\mathcal{N}(0, \\sigma_{V_{T}}^2)$.\n\nTo analyze this probabilistically, we define a random variable $Y$ representing the margin of suppression for neuron $2$. The condition for suppression is equivalent to $Y > 0$:\n$$Y = g\\,(I_{1} - \\alpha\\,\\delta V_{T,1}) - (I_{2} - \\alpha\\,\\delta V_{T,2})$$\nWe can rearrange $Y$ to separate the deterministic and random components:\n$$Y = (gI_{1} - I_{2}) + (\\alpha\\delta V_{T,2} - g\\alpha\\delta V_{T,1})$$\nThe variable $Y$ is a linear transformation of Gaussian random variables, and is therefore itself a Gaussian random variable. We find its mean $\\mu_Y$ and variance $\\sigma_Y^2$.\n\nThe mean of $Y$ is:\n$$\\mu_Y = \\mathbb{E}[Y] = \\mathbb{E}[(gI_{1} - I_{2}) + (\\alpha\\delta V_{T,2} - g\\alpha\\delta V_{T,1})]$$\nSince $\\mathbb{E}[\\delta V_{T,1}] = \\mathbb{E}[\\delta V_{T,2}] = 0$, the mean is:\n$$\\mu_Y = gI_{1} - I_{2}$$\nThe variance of $Y$ is:\n$$\\sigma_Y^2 = \\text{Var}[Y] = \\text{Var}[(gI_{1} - I_{2}) + (\\alpha\\delta V_{T,2} - g\\alpha\\delta V_{T,1})]$$\nThe deterministic part $(gI_{1} - I_{2})$ does not contribute to the variance. Due to the independence of $\\delta V_{T,1}$ and $\\delta V_{T,2}$, the variance of the sum is the sum of the variances:\n$$\\sigma_Y^2 = \\text{Var}[\\alpha\\delta V_{T,2}] + \\text{Var}[-g\\alpha\\delta V_{T,1}]$$\nUsing the property $\\text{Var}[aX] = a^2\\text{Var}[X]$:\n$$\\sigma_Y^2 = \\alpha^2\\text{Var}[\\delta V_{T,2}] + (-g\\alpha)^2\\text{Var}[\\delta V_{T,1}]$$\nGiven that $\\text{Var}[\\delta V_{T,1}] = \\text{Var}[\\delta V_{T,2}] = \\sigma_{V_{T}}^2$, we have:\n$$\\sigma_Y^2 = \\alpha^2\\sigma_{V_{T}}^2 + g^2\\alpha^2\\sigma_{V_{T}}^2 = \\alpha^2\\sigma_{V_{T}}^2(1+g^2)$$\nSo, the random variable $Y$ follows the distribution $Y \\sim \\mathcal{N}\\left(gI_{1} - I_{2}, \\alpha^2\\sigma_{V_{T}}^2(1+g^2)\\right)$.\n\nThe problem requires the probability of correct suppression to be at least $1-\\epsilon$:\n$$\\mathbb{P}[Y > 0] \\geq 1-\\epsilon$$\nUsing the provided formula for a Gaussian variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, $\\mathbb{P}[X > 0] = \\Phi(\\mu/\\sigma)$, where $\\Phi(\\cdot)$ is the standard normal cumulative distribution function (CDF), we can write:\n$$\\mathbb{P}[Y > 0] = \\Phi\\left(\\frac{\\mu_Y}{\\sigma_Y}\\right) = \\Phi\\left(\\frac{gI_{1} - I_{2}}{\\sqrt{\\alpha^2\\sigma_{V_{T}}^2(1+g^2)}}\\right) = \\Phi\\left(\\frac{gI_{1} - I_{2}}{\\alpha\\sigma_{V_{T}}\\sqrt{1+g^2}}\\right)$$\nThe condition becomes:\n$$\\Phi\\left(\\frac{gI_{1} - I_{2}}{\\alpha\\sigma_{V_{T}}\\sqrt{1+g^2}}\\right) \\geq 1-\\epsilon$$\nSince $\\Phi(\\cdot)$ is a strictly increasing function, we can apply its inverse, the quantile function $\\Phi^{-1}(\\cdot)$, to both sides of the inequality:\n$$\\frac{gI_{1} - I_{2}}{\\alpha\\sigma_{V_{T}}\\sqrt{1+g^2}} \\geq \\Phi^{-1}(1-\\epsilon)$$\nThe problem defines the standard normal quantile $z_{1-\\epsilon} = \\Phi^{-1}(1-\\epsilon)$. Thus:\n$$\\frac{gI_{1} - I_{2}}{\\alpha\\sigma_{V_{T}}\\sqrt{1+g^2}} \\geq z_{1-\\epsilon}$$\nTo find the minimal gain $g_{\\min}$, we solve for $g$ in the equality corresponding to the boundary of this condition. Let $C = \\alpha\\sigma_{V_{T}}z_{1-\\epsilon}$. The inequality is $gI_{1} - I_{2} \\geq C\\sqrt{1+g^2}$. For a non-trivial solution with high confidence (e.g., $\\epsilon < 0.5$), we have $z_{1-\\epsilon} > 0$ and thus $C > 0$. The right side is positive, which implies the left side must also be positive, $gI_{1} - I_{2} > 0$. Under this condition, we can square both sides:\n$$(gI_{1} - I_{2})^2 \\geq C^2(1+g^2)$$\n$$g^2I_{1}^2 - 2gI_{1}I_{2} + I_{2}^2 \\geq C^2 + C^2g^2$$\nRearranging the terms to form a quadratic inequality in $g$:\n$$(I_{1}^2 - C^2)g^2 - (2I_{1}I_{2})g + (I_{2}^2 - C^2) \\geq 0$$\nFor a minimal gain to exist, this quadratic in $g$ (which opens upwards, assuming $I_1^2 > C^2$) must be greater than or equal to $0$. The minimal gain $g_{\\min}$ will be the larger of the two roots of the corresponding equation $(I_{1}^2 - C^2)g^2 - (2I_{1}I_{2})g + (I_{2}^2 - C^2) = 0$.\nUsing the quadratic formula $g = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\nThe discriminant is $\\Delta = (-2I_{1}I_{2})^2 - 4(I_{1}^2 - C^2)(I_{2}^2 - C^2)$:\n$$\\Delta = 4I_{1}^2I_{2}^2 - 4(I_{1}^2I_{2}^2 - I_{1}^2C^2 - I_{2}^2C^2 + C^4)$$\n$$\\Delta = 4I_{1}^2C^2 + 4I_{2}^2C^2 - 4C^4 = 4C^2(I_{1}^2 + I_{2}^2 - C^2)$$\nThe roots are:\n$$g = \\frac{2I_{1}I_{2} \\pm \\sqrt{4C^2(I_{1}^2 + I_{2}^2 - C^2)}}{2(I_{1}^2 - C^2)} = \\frac{I_{1}I_{2} \\pm C\\sqrt{I_{1}^2 + I_{2}^2 - C^2}}{I_{1}^2 - C^2}$$\nThe minimal gain $g_{\\min}$ corresponds to the larger root (the one with the plus sign):\n$$g_{\\min} = \\frac{I_{1}I_{2} + C\\sqrt{I_{1}^2 + I_{2}^2 - C^2}}{I_{1}^2 - C^2}$$\nSubstituting back $C = \\alpha\\sigma_{V_{T}}z_{1-\\epsilon}$, we obtain the final expression for the minimal inhibitory gain:\n$$g_{\\min} = \\frac{I_{1}I_{2} + (\\alpha\\sigma_{V_{T}}z_{1-\\epsilon})\\sqrt{I_{1}^2 + I_{2}^2 - (\\alpha\\sigma_{V_{T}}z_{1-\\epsilon})^2}}{I_{1}^2 - (\\alpha\\sigma_{V_{T}}z_{1-\\epsilon})^2}$$\nThis expression is valid under the assumptions that the denominator and the term inside the square root are positive, which corresponds to the signal-to-noise ratio being sufficiently high for the desired confidence level. The problem statement guarantees this by asking to assume parameters such that the expression is real and finite.",
            "answer": "$$\\boxed{\\frac{I_{1}I_{2} + (\\alpha\\sigma_{V_{T}}z_{1-\\epsilon})\\sqrt{I_{1}^{2} + I_{2}^{2} - (\\alpha\\sigma_{V_{T}}z_{1-\\epsilon})^{2}}}{I_{1}^{2} - (\\alpha\\sigma_{V_{T}}z_{1-\\epsilon})^{2}}}$$"
        },
        {
            "introduction": "A functional circuit is only useful if it meets its performance and efficiency targets. This final exercise delves into the physical realities of implementing WTA circuits in subthreshold CMOS, the workhorse technology for ultra-low-power neuromorphic computing. By analyzing the relationships between operating current, power consumption, decision speed, and noise, you will uncover the fundamental trade-offs that every hardware designer must navigate to create efficient and effective brain-inspired systems .",
            "id": "4067974",
            "problem": "Consider a current-mode Winner-Take-All (WTA) circuit implemented in Complementary Metal-Oxide-Semiconductor (CMOS) operating strictly in the subthreshold regime at room temperature. The WTA has $N$ competing branches, each branch $i$ drawing a direct-current input-induced sink current $I_i$ to ground through a transconductance device biased so that its drain current is in the subthreshold exponential regime. The circuit is powered by a single supply of voltage $V_{DD}$, and the WTA operates under steady-state conditions with negligible switching activity. The only non-negligible power consumption is due to static conduction of the branch currents sourced from the supply through biasing and load elements and sunk to ground through the WTA branches. Assume that parasitic leakage outside the intended branch currents is negligible, and that branch currents are sufficiently small such that second-order effects like Drain-Induced Barrier Lowering and channel-length modulation do not disrupt the validity of Kirchhoff’s Current Law (KCL) at the supply node.\n\nStarting from the fundamental definitions of electrical power as the rate of energy transfer, the relation between voltage, current, and power at a supply, and Kirchhoff’s Current Law, derive a compact analytical expression for the total static power consumption of the WTA in terms of $V_{DD}$ and the set of branch currents $\\{I_i\\}_{i=1}^{N}$ under the stated assumptions.\n\nThen, using that expression, evaluate the total static power for a five-branch WTA with supply voltage $V_{DD} = 0.85$ V and branch currents:\n- $I_1 = 33$ nA,\n- $I_2 = 18$ nA,\n- $I_3 = 7$ nA,\n- $I_4 = 4$ nA,\n- $I_5 = 65$ nA.\n\nDiscuss, from first principles and without invoking unverified heuristic formulas, the trade-offs between static power, decision speed, and robustness to input and device noise in subthreshold WTA operation, grounding your reasoning in well-tested device relations for subthreshold conduction (e.g., the transconductance-current relationship $g_m \\approx \\frac{I}{n U_T}$, with $U_T = \\frac{k_B T}{q}$ and subthreshold slope factor $n$) and noise sources such as shot and thermal noise. Your discussion should clarify how increasing or decreasing the branch currents $\\{I_i\\}$ impacts settling time and noise susceptibility, and what assumptions are necessary for the derived power expression to remain accurate.\n\nRound your numerical power result to four significant figures, and express the final power in nW.",
            "solution": "The task is to derive an expression for the total static power consumption of a current-mode Winner-Take-All (WTA) circuit, use it for a numerical calculation, and discuss the operational trade-offs.\n\n**Part 1: Derivation of the Total Static Power Consumption Expression**\n\nThe fundamental definition of electrical power, $P$, delivered by a direct-current (DC) voltage source is the product of the voltage, $V$, across its terminals and the current, $I$, it supplies:\n$$P = V \\times I$$\nFor the WTA circuit in question, it is powered by a single supply with voltage $V_{DD}$. The total static power consumed by the circuit, $P_{total}$, is therefore the product of this supply voltage and the total DC current, $I_{total}$, drawn from the supply.\n$$P_{total} = V_{DD} \\times I_{total}$$\nThe problem states that the circuit is in a steady state and that the only non-negligible power consumption is due to the static conduction of the branch currents. There are $N$ branches, and each branch $i$ sinks a current $I_i$ to ground.\n\nTo determine $I_{total}$, we apply Kirchhoff’s Current Law (KCL). KCL states that the algebraic sum of currents entering any node (or, more generally, any closed boundary) must be zero. If we consider the entire WTA circuit as a single system, it has two terminals: one connected to the supply $V_{DD}$ and the other to ground. The current entering the system from the supply is $I_{total}$. The currents leaving the system to ground are the $N$ branch sink currents, $\\{I_i\\}_{i=1}^{N}$.\n\nThe problem specifies that parasitic leakage outside the intended branch currents is negligible. This crucial assumption means that the total current sourced by the supply must equal the sum of all currents sunk to ground through the defined circuit paths.\nThe total current sunk to ground, $I_{sunk}$, is the sum of the individual branch currents:\n$$I_{sunk} = \\sum_{i=1}^{N} I_i$$\nBy conservation of charge, as mandated by KCL applied to the whole circuit, the total current drawn from the supply must balance the total current sunk to ground:\n$$I_{total} = I_{sunk} = \\sum_{i=1}^{N} I_i$$\nSubstituting this expression for $I_{total}$ back into the power equation, we obtain the compact analytical expression for the total static power consumption:\n$$P_{total} = V_{DD} \\sum_{i=1}^{N} I_i$$\n\n**Part 2: Numerical Evaluation of Static Power**\n\nWe are given the following values for a specific $N=5$ branch WTA circuit:\n- Supply Voltage: $V_{DD} = 0.85$ V\n- Branch Currents: $I_1 = 33$ nA, $I_2 = 18$ nA, $I_3 = 7$ nA, $I_4 = 4$ nA, $I_5 = 65$ nA\n\nFirst, we calculate the total current, $I_{total}$, by summing the individual branch currents:\n$$I_{total} = \\sum_{i=1}^{5} I_i = I_1 + I_2 + I_3 + I_4 + I_5$$\n$$I_{total} = (33 + 18 + 7 + 4 + 65) \\, \\text{nA} = 127 \\, \\text{nA}$$\nThis corresponds to a total current of $127 \\times 10^{-9}$ A.\n\nNext, we calculate the total static power, $P_{total}$, using the derived formula:\n$$P_{total} = V_{DD} \\times I_{total}$$\n$$P_{total} = (0.85 \\, \\text{V}) \\times (127 \\times 10^{-9} \\, \\text{A})$$\n$$P_{total} = 107.95 \\times 10^{-9} \\, \\text{W} = 107.95 \\, \\text{nW}$$\nThe problem requests the result to be rounded to four significant figures.\n$$P_{total} \\approx 108.0 \\, \\text{nW}$$\n\n**Part 3: Discussion of Trade-offs and Assumptions**\n\nThe operation of a subthreshold WTA circuit embodies fundamental trade-offs between static power, decision speed (settling time), and robustness to noise. These can be analyzed from first principles.\n\n1.  **Static Power vs. Decision Speed**: The derived expression shows that static power is directly proportional to the sum of the branch currents, $P_{total} \\propto \\sum I_i$. The decision speed of the circuit is determined by how fast it can respond to its inputs to select a winner. This speed is limited by the charging and discharging of parasitic capacitances at the circuit's internal nodes. The rate of change of voltage at a node is $\\frac{dV}{dt} = \\frac{I_{net}}{C}$, where $I_{net}$ is the net current available to charge or discharge the capacitance $C$. This current is a function of the transconductance, $g_m$, of the transistors. For a MOSFET operating in the subthreshold regime, the transconductance is approximately proportional to its drain current $I_D$:\n    $$g_m = \\frac{\\partial I_D}{\\partial V_{GS}} \\approx \\frac{I_D}{n U_T}$$\n    where $U_T = \\frac{k_B T}{q}$ is the thermal voltage and $n \\ge 1$ is the subthreshold slope factor. A larger $g_m$ yields a faster circuit response. Therefore, increasing the branch currents $\\{I_i\\}$ increases the $g_m$ of the transistors, reducing the circuit's settling time and increasing its decision speed. This reveals a classic speed-power trade-off: higher speed requires larger currents, which results in higher static power consumption.\n\n2.  **Static Power vs. Noise Robustness**: Robustness is the circuit's ability to maintain correct functionality despite the presence of noise. In subthreshold circuits, dominant noise sources include shot noise and thermal noise. The power spectral density of shot noise is proportional to the DC current, $S_{shot}(f) = 2qI_D$. The RMS noise current, $\\sigma_{noise}$, integrated over a bandwidth $\\Delta f$, is proportional to the square root of the DC current, $\\sigma_{noise} \\propto \\sqrt{I_D}$. The signal, in this current-mode context, is the current $I_D$ itself. The signal-to-noise ratio (SNR) is therefore a primary figure of merit for robustness:\n    $$\\text{SNR} = \\frac{\\text{Signal Power}}{\\text{Noise Power}} \\propto \\frac{I_D^2}{I_D} = I_D \\quad \\text{or} \\quad \\text{SNR (amplitude)} = \\frac{\\text{Signal Amplitude}}{\\text{Noise Amplitude}} \\propto \\frac{I_D}{\\sqrt{I_D}} = \\sqrt{I_D}$$\n    In either definition, increasing the operating current $I_D$ improves the SNR. A higher SNR means the circuit can more reliably distinguish the \"winning\" current from competing currents in the face of random fluctuations. This establishes a power-robustness trade-off: achieving greater immunity to noise requires larger operating currents, which in turn leads to higher static power dissipation.\n\n3.  **Assumptions for Power Expression Accuracy**: The derived expression $P_{total} = V_{DD} \\sum I_i$ relies on several simplifying assumptions, the validity of which determines its accuracy:\n    - **Static Operation**: The expression calculates only static power dissipation. It neglects dynamic power, $P_{dyn} \\propto f C_{load} V_{DD}^2$, which arises from the switching activity of the circuit (i.e., changing inputs). If the WTA inputs change frequently, this dynamic component could be significant.\n    - **Negligible Leakage**: The model assumes that the only currents drawn from the supply are the $N$ specified branch currents. In real-world CMOS devices, especially in advanced technologies, other leakage currents (e.g., gate leakage, junction leakage, and subthreshold leakage in transistors intended to be off) can be substantial. These would add to $I_{total}$, making the derived expression a lower bound on the actual power consumption.\n    - **Ideal Biasing Network**: The derivation implicitly assumes that the auxiliary circuitry that generates and distributes the currents to the WTA branches (e.g., current mirrors) is perfectly efficient or its power consumption is already factored into the $\\{I_i\\}$. In practice, such biasing networks consume power themselves (e.g., through a reference current branch), which would contribute an additional term to the total power draw from $V_{DD}$.",
            "answer": "$$\\boxed{108.0}$$"
        }
    ]
}