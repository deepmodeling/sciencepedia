{
    "hands_on_practices": [
        {
            "introduction": "贝叶斯大脑的核心思想是整合先验知识与新的感官证据。这个练习提供了一个具体、亲身实践的机会来推导这一基本过程。通过这个练习，你将揭示一个优美的数学原理——精确度加权平均（precision-weighting），即更可靠的信息（更高的精确度）对我们的感知有更大的影响力。",
            "id": "4063569",
            "problem": "在贝叶斯大脑假说中，皮层计算通常被建模为一种概率推断，它将内部生成的预测（先验）与传入的感官证据（似然）相结合，其相对影响由精度（方差的倒数）调节。考虑一个用于单个潜变量 $s$ 的神经形态感官估计模块，其先验为 $p(s)=\\mathcal{N}(0,1)$，并有一个标量观测值 $x$，由条件概率 $p(x\\mid s)=\\mathcal{N}(s,0.25)$ 生成。仅从贝叶斯法则 $p(s\\mid x)\\propto p(x\\mid s)\\,p(s)$ 和精度是方差倒数的定义出发，通过对高斯乘积的指数部分进行显式配方，推导出后验分布 $p(s\\mid x)$。然后，计算给定 $x$ 时 $s$ 的后验均值和后验方差，并将后验均值解释为先验均值和观测值的精度加权平均。\n\n将您的最终答案表示为一个包含后验均值和后验方差的单行矩阵，以 $x$ 的精确符号函数形式表示。无需四舍五入。不涉及物理单位。",
            "solution": "该问题要求基于给定的先验 $p(s)$ 和似然 $p(x \\mid s)$，推导给定观测值 $x$ 时潜变量 $s$ 的后验分布 $p(s \\mid x)$。推导过程必须从贝叶斯法则出发，通过对高斯密度函数乘积的指数部分进行配方来完成。随后，计算并解释后验均值和方差。\n\n给定的分布是：\n1.  $s$ 的先验分布：$p(s) = \\mathcal{N}(\\mu_{prior}, \\sigma_{prior}^2)$，其中均值为 $\\mu_{prior} = 0$，方差为 $\\sigma_{prior}^2 = 1$。\n2.  给定 $s$ 时观测值 $x$ 的似然：$p(x \\mid s) = \\mathcal{N}(s, \\sigma_{like}^2)$，其中方差为 $\\sigma_{like}^2 = 0.25$。注意，该分布的均值是潜变量 $s$。\n\n一般高斯分布 $\\mathcal{N}(\\mu, \\sigma^2)$ 的概率密度函数 (PDF) 由 $f(y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right)$ 给出。\n因此，先验和似然的具体PDF为：\n$p(s) = \\frac{1}{\\sqrt{2\\pi(1)}} \\exp\\left(-\\frac{(s-0)^2}{2(1)}\\right) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{s^2}{2}\\right)$\n$p(x \\mid s) = \\frac{1}{\\sqrt{2\\pi(0.25)}} \\exp\\left(-\\frac{(x-s)^2}{2(0.25)}\\right) = \\frac{1}{\\sqrt{0.5\\pi}} \\exp\\left(-\\frac{(x-s)^2}{0.5}\\right)$\n\n根据贝叶斯法则，后验分布 $p(s \\mid x)$ 与似然和先验的乘积成正比：\n$p(s \\mid x) \\propto p(x \\mid s) p(s)$\n\n代入PDF的表达式，我们得到：\n$p(s \\mid x) \\propto \\left[ \\frac{1}{\\sqrt{0.5\\pi}} \\exp\\left(-\\frac{(x-s)^2}{0.5}\\right) \\right] \\left[ \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{s^2}{2}\\right) \\right]$\n\n由于我们处理的是正比关系，可以忽略常数归一化因子。后验分布与指数部分成正比：\n$p(s \\mid x) \\propto \\exp\\left(-\\frac{(x-s)^2}{0.5}\\right) \\exp\\left(-\\frac{s^2}{2}\\right) = \\exp\\left(-\\frac{(x-s)^2}{0.5} - \\frac{s^2}{2}\\right)$\n\n我们来分析指数部分，记为 $\\Phi(s)$：\n$\\Phi(s) = -\\left(\\frac{(s-x)^2}{0.5} + \\frac{s^2}{2}\\right) = -\\left(2(s-x)^2 + \\frac{s^2}{2}\\right)$\n\n为了确定后验分布的形式，我们展开指数中的项并合并 $s$ 的幂。形式为 $\\mathcal{N}(\\mu_{post}, \\sigma_{post}^2)$ 的高斯后验分布，其指数形式为 $-\\frac{(s-\\mu_{post})^2}{2\\sigma_{post}^2} + C$，其中 $C$ 是一个关于 $s$ 的常数。\n$\\Phi(s) = -\\left(2(s^2 - 2sx + x^2) + \\frac{s^2}{2}\\right)$\n$\\Phi(s) = -\\left(2s^2 - 4sx + 2x^2 + \\frac{s^2}{2}\\right)$\n$\\Phi(s) = -\\left(\\left(2 + \\frac{1}{2}\\right)s^2 - 4sx + 2x^2\\right)$\n$\\Phi(s) = -\\left(\\frac{5}{2}s^2 - 4sx + 2x^2\\right)$\n\n现在，我们对包含 $s$ 的项进行配方。一般形式为 $As^2+Bs+C$。我们从含 $s$ 的项中提出因子 $A$：$A(s^2 + \\frac{B}{A}s) + C = A\\left(s+\\frac{B}{2A}\\right)^2 + C - \\frac{B^2}{4A}$。\n在我们的表达式中，括号内的项是 $\\frac{5}{2}s^2 - 4sx + 2x^2$。这里，$A = \\frac{5}{2}$ 且 $B = -4x$。\n$\\frac{5}{2}s^2 - 4sx + 2x^2 = \\frac{5}{2}\\left(s^2 - \\frac{2}{5}(4x)s\\right) + 2x^2$\n$= \\frac{5}{2}\\left(s^2 - \\frac{8x}{5}s\\right) + 2x^2$\n$= \\frac{5}{2}\\left[\\left(s - \\frac{4x}{5}\\right)^2 - \\left(\\frac{4x}{5}\\right)^2\\right] + 2x^2$\n$= \\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 - \\frac{5}{2}\\left(\\frac{16x^2}{25}\\right) + 2x^2$\n$= \\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 - \\frac{8x^2}{5} + 2x^2$\n$= \\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 - \\frac{8x^2}{5} + \\frac{10x^2}{5}$\n$= \\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 + \\frac{2x^2}{5}$\n\n将此代回 $\\Phi(s)$ 的表达式中：\n$\\Phi(s) = -\\left(\\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 + \\frac{2x^2}{5}\\right) = -\\frac{5}{2}\\left(s - \\frac{4x}{5}\\right)^2 - \\frac{2x^2}{5}$\n\n因此，后验分布为：\n$p(s \\mid x) \\propto \\exp\\left(-\\frac{1}{2} \\cdot 5 \\left(s - \\frac{4x}{5}\\right)^2\\right) \\exp\\left(-\\frac{2x^2}{5}\\right)$\n\n项 $\\exp(-2x^2/5)$ 相对于 $s$ 是一个常数，可以被吸收到归一化常数中。剩余的表达式具有 $s$ 的高斯PDF形式：\n$p(s \\mid x) \\propto \\exp\\left(-\\frac{(s - \\mu_{post})^2}{2\\sigma_{post}^2}\\right)$\n\n通过将推导出的指数与一般形式进行比较，我们可以确定后验均值 $\\mu_{post}$ 和后验方差 $\\sigma_{post}^2$：\n$\\mu_{post} = \\frac{4x}{5}$\n$\\frac{1}{2\\sigma_{post}^2} = \\frac{5}{2} \\implies \\sigma_{post}^2 = \\frac{1}{5}$\n\n所以，后验分布是一个高斯分布：$p(s \\mid x) = \\mathcal{N}\\left(\\frac{4x}{5}, \\frac{1}{5}\\right)$。\n后验均值为 $\\mu_{post} = \\frac{4x}{5}$。\n后验方差为 $\\sigma_{post}^2 = \\frac{1}{5}$。\n\n为了将后验均值解释为精度加权平均，我们首先定义精度。精度 $\\lambda$ 是方差的倒数，即 $\\lambda = 1/\\sigma^2$。\n先验精度：$\\lambda_{prior} = 1/\\sigma_{prior}^2 = 1/1 = 1$。\n似然精度：$\\lambda_{like} = 1/\\sigma_{like}^2 = 1/0.25 = 4$。\n\n在高斯先验和高斯似然的情况下，后验均值 $\\mu_{post}$ 的通用公式是先验均值 $\\mu_{prior}$ 和数据 $x$（即在 $s=x$ 处评估的似然函数的均值）的精度加权平均：\n$\\mu_{post} = \\frac{\\lambda_{prior}\\mu_{prior} + \\lambda_{like}x}{\\lambda_{prior} + \\lambda_{like}}$\n后验精度是先验精度和似然精度的和：\n$\\lambda_{post} = \\lambda_{prior} + \\lambda_{like}$\n而后验方差是后验精度的倒数：\n$\\sigma_{post}^2 = \\frac{1}{\\lambda_{post}} = \\frac{1}{\\lambda_{prior} + \\lambda_{like}}$\n\n让我们用给定的值和这些通用公式来验证我们的结果：\n$\\mu_{prior} = 0$，$\\lambda_{prior} = 1$，$\\lambda_{like} = 4$。\n$\\mu_{post} = \\frac{(1)(0) + (4)x}{1 + 4} = \\frac{4x}{5}$\n$\\sigma_{post}^2 = \\frac{1}{1 + 4} = \\frac{1}{5}$\n\n结果完全匹配。其解释是，后验均值 $\\mu_{post}$ 是先验关于均值的信念 ($\\mu_{prior}=0$) 和感官证据 ($x$) 的加权平均。权重是它们各自的精度。数据精度为 $4$，而先验精度为 $1$，因此感官数据对最终估计的影响是先验信念的四倍。这可以通过将后验均值写为以下形式看出：\n$\\mu_{post} = \\left(\\frac{\\lambda_{prior}}{\\lambda_{prior}+\\lambda_{like}}\\right)\\mu_{prior} + \\left(\\frac{\\lambda_{like}}{\\lambda_{prior}+\\lambda_{like}}\\right)x = \\left(\\frac{1}{5}\\right)(0) + \\left(\\frac{4}{5}\\right)x = \\frac{4x}{5}$。\n\n最终答案要求将后验均值和后验方差放在一个单行矩阵中。\n后验均值：$\\frac{4x}{5}$\n后验方差：$\\frac{1}{5}$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{4x}{5}  \\frac{1}{5}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "大脑不仅仅是形成一次性的感知，它会随着时间的推移不断更新其信念。这个练习使用卡尔曼滤波器（Kalman filter）的框架来模拟这个动态过程。通过解决这个问题，你将看到贝叶斯更新如何被表达为一个误差校正的过程，而“精确度加权的预测误差”（precision-weighted prediction error）这一概念正是预测编码理论的基石。",
            "id": "4063550",
            "problem": "贝叶斯大脑假说（BBH）的一个核心原则是，皮层回路通过精确度加权的预测误差来近似贝叶斯法则，从而实现概率推断。考虑一个标量潜变量 $z$，一个神经元群体将其编码为高斯先验 $p(z)=\\mathcal{N}(m,P)$，以及一个由线性高斯生成模型 $p(x \\mid z)=\\mathcal{N}(C z, R)$ 生成的带噪声的感官观测值 $x$，其中 $C$ 是一个已知的标量观测矩阵， $R$ 是观测噪声的方差。假设大脑在接收到 $x$ 后，对其关于 $z$ 的信念进行一步贝叶斯更新，并利用该线性高斯结构获得一个高斯后验 $p(z \\mid x)=\\mathcal{N}(m^{+}, P^{+})$。从贝叶斯法则和高斯密度代数出发，推导后验均值 $m^{+}$ 和后验方差 $P^{+}$，用先验参数 $m$ 和 $P$、观测值 $x$、观测矩阵 $C$ 和观测方差 $R$ 来表示。然后，将精确度加权解释为卡尔曼滤波器（KF）增益 $K$ 乘以预测误差 $x - C m$，并计算在先验均值 $m=0$、先验方差 $P=1$、观测值 $x=1$、观测矩阵 $C=1$ 和观测方差 $R=0.5$ 的特定情况下的 $K$、$m^{+}$ 和 $P^{+}$ 的数值。请提供精确值，不要四舍五入。将你的最终答案表示为一个单行矩阵，其中依次包含卡尔曼增益 $K$、更新后的均值 $m^{+}$ 和更新后的方差 $P^{+}$。",
            "solution": "问题陈述已经过验证，被认为是合理的。它在科学上基于贝叶斯统计学及其在计算神经科学中的应用，问题提法得当且客观。它为解决一个可解问题提供了一个完整且一致的设置。\n\n问题的核心是在给定先验信念和新观测值的情况下，对一个标量潜变量 $z$ 执行一步贝叶斯更新。关于 $z$ 的先验信念被建模为高斯分布：\n$$p(z) = \\mathcal{N}(z; m, P) = \\frac{1}{\\sqrt{2\\pi P}} \\exp\\left(-\\frac{(z-m)^2}{2P}\\right)$$\n这里，$m$ 是先验均值，$P$ 是先验方差。\n\n观测值 $x$ 通过一个线性高斯生成模型与 $z$ 相关联，该模型充当似然函数：\n$$p(x \\mid z) = \\mathcal{N}(x; Cz, R) = \\frac{1}{\\sqrt{2\\pi R}} \\exp\\left(-\\frac{(x-Cz)^2}{2R}\\right)$$\n这里，$C$ 是一个将潜变量映射到观测空间的标量，$R$ 是观测噪声的方差。\n\n根据贝叶斯法则，给定观测值后潜变量的后验分布与似然和先验的乘积成正比：\n$$p(z \\mid x) = \\frac{p(x \\mid z) p(z)}{p(x)} \\propto p(x \\mid z) p(z)$$\n由于两个高斯函数的乘积是另一个（未归一化的）高斯函数，因此后验 $p(z \\mid x)$ 也将是高斯分布，我们将其表示为 $p(z \\mid x) = \\mathcal{N}(z; m^{+}, P^{+})$。我们的目标是找到后验均值 $m^{+}$ 和后验方差 $P^{+}$。\n\n为此，最方便的方法是处理后验概率的对数，因为高斯函数的指数会线性相加。\n$$\\ln p(z \\mid x) \\propto \\ln(p(x \\mid z) p(z)) = \\ln p(x \\mid z) + \\ln p(z)$$\n忽略归一化常数，我们有：\n$$\\ln p(z \\mid x) = -\\frac{(x-Cz)^2}{2R} - \\frac{(z-m)^2}{2P} + \\text{const.}$$\n我们展开二次项：\n$$\\ln p(z \\mid x) = -\\frac{1}{2}\\left(\\frac{x^2 - 2xCz + C^2z^2}{R} + \\frac{z^2 - 2zm + m^2}{P}\\right) + \\text{const.}$$\n为了找到后验高斯分布的参数，我们将表达式重新整理为关于 $z$ 的二次型：\n$$\\ln p(z \\mid x) = -\\frac{1}{2}\\left[ \\left(\\frac{C^2}{R} + \\frac{1}{P}\\right)z^2 - 2\\left(\\frac{xC}{R} + \\frac{m}{P}\\right)z \\right] + \\text{const.'}$$\n其中 `const.'` 吸收了所有不依赖于 $z$ 的项。\n\n根据定义，后验密度 $\\mathcal{N}(z; m^{+}, P^{+})$ 的对数为：\n$$\\ln p(z \\mid x) = -\\frac{(z-m^{+})^2}{2P^{+}} + \\text{const.} = -\\frac{1}{2}\\left( \\frac{z^2}{P^{+}} - \\frac{2m^{+}z}{P^{+}} + \\frac{(m^{+})^2}{P^{+}} \\right) + \\text{const.}$$\n通过比较 $\\ln p(z \\mid x)$ 的两个表达式中 $z^2$ 和 $z$ 的系数，我们可以确定 $P^{+}$ 和 $m^{+}$。\n\n比较 $z^2$ 项的系数：\n$$\\frac{1}{P^{+}} = \\frac{C^2}{R} + \\frac{1}{P}$$\n这个方程表明，后验精确度（方差的倒数）是先验精确度与从观测中获得的信息精确度之和。求解后验方差 $P^{+}$：\n$$P^{+} = \\left(\\frac{C^2}{R} + \\frac{1}{P}\\right)^{-1} = \\left(\\frac{PC^2 + R}{PR}\\right)^{-1} = \\frac{PR}{PC^2 + R}$$\n\n比较 $z$ 项的系数：\n$$\\frac{m^{+}}{P^{+}} = \\frac{xC}{R} + \\frac{m}{P}$$\n求解后验均值 $m^{+}$：\n$$m^{+} = P^{+}\\left(\\frac{xC}{R} + \\frac{m}{P}\\right)$$\n代入 $P^{+}$ 的表达式：\n$$m^{+} = \\frac{PR}{PC^2 + R} \\left(\\frac{xCP + mR}{PR}\\right) = \\frac{xCP + mR}{PC^2 + R}$$\n\n为了在卡尔曼滤波器的背景下解释这个结果，我们重新排列 $m^{+}$ 的表达式，以显示基于预测误差从先验均值 $m$ 进行的更新。预测误差是实际观测值 $x$ 与基于先验均值预测的观测值 $Cm$ 之间的差值。\n$$m^{+} = \\frac{mR + xCP}{PC^2 + R} = \\frac{m(PC^2 + R) - mPC^2 + xCP}{PC^2 + R}$$\n$$m^{+} = m + \\left(\\frac{PC}{PC^2 + R}\\right)(x - Cm)$$\n这是经典的卡尔曼滤波器更新方程。项 $K = \\frac{PC}{PC^2 + R}$ 是卡尔曼增益，它对预测误差 $(x - Cm)$ 进行最优加权。后验均值是通过精确度加权的预测误差调整后的先验均值。\n\n现在我们计算所提供特定情况下的数值：\n先验均值 $m=0$。\n先验方差 $P=1$。\n观测值 $x=1$。\n观测矩阵 $C=1$。\n观测方差 $R=0.5$。\n\n首先，我们计算卡尔曼增益 $K$：\n$$K = \\frac{PC}{PC^2 + R} = \\frac{(1)(1)}{(1)(1^2) + 0.5} = \\frac{1}{1 + 0.5} = \\frac{1}{1.5} = \\frac{1}{3/2} = \\frac{2}{3}$$\n\n接下来，我们计算后验均值 $m^{+}$：\n$$m^{+} = m + K(x - Cm) = 0 + \\frac{2}{3}(1 - (1)(0)) = \\frac{2}{3}(1) = \\frac{2}{3}$$\n\n最后，我们计算后验方差 $P^{+}$：\n$$P^{+} = \\frac{PR}{PC^2 + R} = \\frac{(1)(0.5)}{(1)(1^2) + 0.5} = \\frac{0.5}{1.5} = \\frac{1/2}{3/2} = \\frac{1}{3}$$\n或者，使用更新规则 $P^{+} = (1-KC)P$：\n$$P^{+} = \\left(1 - \\frac{2}{3}(1)\\right)(1) = \\left(1 - \\frac{2}{3}\\right) = \\frac{1}{3}$$\n结果是一致的。\n\n最终答案要求一个行矩阵，按顺序包含 $K$、$m^{+}$ 和 $P^{+}$。\n$$K = \\frac{2}{3}, \\quad m^{+} = \\frac{2}{3}, \\quad P^{+} = \\frac{1}{3}$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2}{3}  \\frac{2}{3}  \\frac{1}{3}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "抽象的贝叶斯推断数学原理如何由真实的神经元和神经回路实现？这个实践通过对一个简化的皮层回路进行建模来探讨这个问题。这个练习连接了理论与生物学，要求你推导出相互作用的“表征单元”（representation units）和“误差单元”（error units）的动力学，分析该系统的稳定性将让你深入理解神经反馈如何实现预测编码核心的误差校正计算。",
            "id": "4063576",
            "problem": "在贝叶斯大脑假说中，皮层回路通常被建模为实现预测编码，其中深层表示单元预测感觉输入，而浅层误差单元则发出失配信号。考虑一个针对单一潜在原因的最小层状预测编码回路，该回路基于线性高斯生成模型和变分自由能（VFE）上的梯度流。设生成模型为 $y = w x + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^{2})$，并有一个高斯先验 $x \\sim \\mathcal{N}(\\mu,\\pi^{-1})$。定义感觉精度 $\\rho = \\sigma^{-2}$ 和先验精度 $\\pi > 0$。在预测编码中，误差单元计算精度加权预测误差的估计值，并将反馈发送到深层表示单元。\n\n从上述模型和 VFE 定义（即预测误差和与先验均值偏差的二次能量）出发，推导一个最小的连续时间层状动力学系统，其中：\n- 浅层误差活动 $e$ 是一个泄漏积分器，以速率 $\\kappa > 0$ 向精度加权的预测误差松弛。\n- 深层表示活动 $x$ 由先验精度和来自误差单元的层状反馈驱动，反馈增益为 $g > 0$。\n假设时间已被重新标度，使得深层时间常数等于 $1$，并通过在没有外部驱动（$\\delta y = 0$）的情况下对动力学进行线性化，来分析不动点 $x^{\\star} = \\mu$, $y^{\\star} = w \\mu$ 周围的内部稳定性。\n\n从第一性原理出发，构建以偏差 $\\delta x$ 和 $\\delta e$ 表示的线性化二维动力学系统，并推导其雅可比矩阵。计算该雅可比矩阵的特征值，将其表示为反馈增益 $g$ 和参数 $\\pi$、$\\rho$、$\\kappa$ 和 $w$ 的函数。确定临界反馈增益 $g_{\\star}$，在该增益下特征值从实数转变为复数（即特征多项式的判别式等于零）。以 $\\pi$、$\\rho$、$\\kappa$ 和 $w$ 的单个闭式解析表达式形式提供您的最终答案。不需要进行数值计算，也不需要包含单位。",
            "solution": "该问题要求在一个最小预测编码回路模型中推导临界反馈增益 $g_{\\star}$。推导过程首先建立系统的连续时间动力学，然后围绕一个特定的不动点对其进行线性化，最后分析所得雅可比矩阵的特征值。\n\n首先，我们根据所提供的描述来形式化动力学系统。该系统由一个活动为 $e$ 的浅层误差单元和一个活动为 $x$ 的深层表示单元组成。\n\n误差单元活动 $e$ 被描述为一个泄漏积分器，以速率 $\\kappa > 0$ 向精度加权的预测误差 $\\rho(y-wx)$ 松弛。这可以转化为以下常微分方程（ODE）：\n$$\n\\frac{de}{dt} = \\kappa \\left( \\rho(y-wx) - e \\right)\n$$\n\n表示单元活动 $x$ 被描述为由两项驱动：来自误差单元的反馈和先验的影响。来自误差单元 $e$ 的反馈具有增益 $g > 0$，并由突触权重 $w$ 介导。先验的影响将 $x$ 拉向其均值 $\\mu$，其强度由先验精度 $\\pi > 0$ 决定。问题指出该单元的时间常数被重新标度为 $1$。这引出以下常微分方程：\n$$\n\\frac{dx}{dt} = gwe - \\pi(x-\\mu)\n$$\n在这里，项 $gwe$ 表示反馈驱动，项 $-\\pi(x-\\mu)$ 表示来自先验的驱动，这与在变分自由能 $F = \\frac{1}{2}\\rho(y-wx)^2 + \\frac{1}{2}\\pi(x-\\mu)^2$ 上进行梯度下降是一致的。\n\n因此，完整的动力学系统是：\n$$\n\\begin{cases}\n\\frac{dx}{dt} = gwe - \\pi(x-\\mu) \\\\\n\\frac{de}{dt} = \\kappa(\\rho(y-wx) - e)\n\\end{cases}\n$$\n\n接下来，我们确定要进行线性化的不动点 $(x^{\\star}, e^{\\star})$。问题指明该点对应于先验均值 $x^{\\star} = \\mu$，这在感觉输入为 $y^{\\star} = w\\mu$ 时发生。我们验证对于 $y = y^{\\star}$，$(x, e) = (\\mu, 0)$ 确实是一个不动点：\n设 $\\frac{dx}{dt} = 0$ 且 $\\frac{de}{dt} = 0$：\n$$\ngwe^{\\star} - \\pi(x^{\\star}-\\mu) = 0\n$$\n$$\n\\kappa(\\rho(y^{\\star}-wx^{\\star}) - e^{\\star}) = 0\n$$\n将 $x^{\\star} = \\mu$ 和 $y^{\\star} = w\\mu$ 代入第二个方程得到：\n$$\n\\kappa(\\rho(w\\mu - w\\mu) - e^{\\star}) = 0 \\implies \\kappa(-e^{\\star}) = 0 \\implies e^{\\star} = 0\n$$\n将 $x^{\\star} = \\mu$ 和 $e^{\\star} = 0$ 代入第一个方程得到：\n$$\ngw(0) - \\pi(\\mu-\\mu) = 0 \\implies 0 = 0\n$$\n条件得到满足，因此 $(x^{\\star}, e^{\\star}) = (\\mu, 0)$ 是正确的不动点。\n\n现在，我们围绕这个不动点对系统进行线性化。我们考虑小偏差 $\\delta x = x - x^{\\star}$ 和 $\\delta e = e - e^{\\star}$。分析是针对“内部稳定性”进行的，这意味着外部输入没有变化，因此 $\\delta y = 0$，即 $y$ 保持在 $y^{\\star} = w\\mu$ 恒定不变。\n偏差的系统为：\n$$ \\frac{d}{dt} \\begin{pmatrix} \\delta x \\\\ \\delta e \\end{pmatrix} = J \\begin{pmatrix} \\delta x \\\\ \\delta e \\end{pmatrix} $$\n其中 $J$ 是在不动点 $(x^{\\star}, e^{\\star}) = (\\mu, 0)$ 处求值的雅可比矩阵：\n$$\nJ = \\begin{pmatrix} \\frac{\\partial}{\\partial x}(\\frac{dx}{dt})  \\frac{\\partial}{\\partial e}(\\frac{dx}{dt}) \\\\ \\frac{\\partial}{\\partial x}(\\frac{de}{dt})  \\frac{\\partial}{\\partial e}(\\frac{de}{dt}) \\end{pmatrix}_{x=\\mu, e=0}\n$$\n偏导数是：\n$$\n\\frac{\\partial}{\\partial x}(gwe - \\pi(x-\\mu)) = -\\pi\n$$\n$$\n\\frac{\\partial}{\\partial e}(gwe - \\pi(x-\\mu)) = gw\n$$\n$$\n\\frac{\\partial}{\\partial x}(\\kappa(\\rho(y-wx) - e)) = -\\kappa \\rho w\n$$\n$$\n\\frac{\\partial}{\\partial e}(\\kappa(\\rho(y-wx) - e)) = -\\kappa\n$$\n这些导数是常数，因此雅可比矩阵是：\n$$\nJ = \\begin{pmatrix} -\\pi  gw \\\\ -\\kappa \\rho w  -\\kappa \\end{pmatrix}\n$$\n\n为了确定不动点的稳定性和性质，我们通过求解特征方程 $\\det(J - \\lambda I) = 0$ 来计算雅可比矩阵的特征值 $\\lambda$：\n$$\n\\det \\begin{pmatrix} -\\pi-\\lambda  gw \\\\ -\\kappa \\rho w  -\\kappa-\\lambda \\end{pmatrix} = 0\n$$\n$$\n(-\\pi-\\lambda)(-\\kappa-\\lambda) - (gw)(-\\kappa \\rho w) = 0\n$$\n$$\n(\\pi+\\lambda)(\\kappa+\\lambda) + g\\kappa\\rho w^2 = 0\n$$\n$$\n\\lambda^2 + (\\pi+\\kappa)\\lambda + (\\pi\\kappa + g\\kappa\\rho w^2) = 0\n$$\n这是一个关于 $\\lambda$ 的二次方程。其解由二次公式给出：\n$$\n\\lambda = \\frac{-(\\pi+\\kappa) \\pm \\sqrt{(\\pi+\\kappa)^2 - 4(\\pi\\kappa + g\\kappa\\rho w^2)}}{2}\n$$\n当特征多项式的判别式 $\\Delta = (\\pi+\\kappa)^2 - 4(\\pi\\kappa + g\\kappa\\rho w^2)$ 的符号从正变为负时，特征值从实数过渡到复数。临界点出现在判别式为零时。我们求解当 $\\Delta = 0$ 时的增益 $g = g_{\\star}$：\n$$\n(\\pi+\\kappa)^2 - 4(\\pi\\kappa + g_{\\star}\\kappa\\rho w^2) = 0\n$$\n展开平方项：\n$$\n\\pi^2 + 2\\pi\\kappa + \\kappa^2 - 4\\pi\\kappa - 4g_{\\star}\\kappa\\rho w^2 = 0\n$$\n化简关于 $\\pi$ 和 $\\kappa$ 的多项式：\n$$\n\\pi^2 - 2\\pi\\kappa + \\kappa^2 - 4g_{\\star}\\kappa\\rho w^2 = 0\n$$\n识别出完全平方：\n$$\n(\\pi-\\kappa)^2 - 4g_{\\star}\\kappa\\rho w^2 = 0\n$$\n现在，我们分离出 $g_{\\star}$：\n$$\n4g_{\\star}\\kappa\\rho w^2 = (\\pi - \\kappa)^2\n$$\n假设 $\\kappa, \\rho, w$ 不为零，我们可以解出 $g_{\\star}$：\n$$\ng_{\\star} = \\frac{(\\pi - \\kappa)^2}{4\\kappa\\rho w^2}\n$$\n这个表达式给出了系统特征值从实数转变为复数的临界反馈增益，标志着动力学从稳定节点到稳定螺线（阻尼振荡）的转变。",
            "answer": "$$\\boxed{\\frac{(\\pi - \\kappa)^{2}}{4\\kappa\\rho w^{2}}}$$"
        }
    ]
}