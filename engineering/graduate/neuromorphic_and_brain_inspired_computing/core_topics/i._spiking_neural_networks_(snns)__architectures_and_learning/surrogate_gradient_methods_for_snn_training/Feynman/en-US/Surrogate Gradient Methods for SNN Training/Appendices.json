{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a concrete, step-by-step walkthrough of the surrogate gradient calculation. By manually applying the chain rule through time (BPTT) for a simple two-step sequence, you will directly engage with the core mechanism of the Straight-Through Estimator (STE). This practice is crucial for demystifying how gradients are computed in SNNs and for building a solid intuition about the flow of learning signals through the non-differentiable spiking events .",
            "id": "4061967",
            "problem": "Consider a single-neuron Spiking Neural Network (SNN; Spiking Neural Network) using a discrete-time Leaky Integrate-and-Fire (LIF; Leaky Integrate-and-Fire) neuron without reset over a two-step input sequence. The membrane potential evolves according to the recurrence\n$$u_{t}=\\lambda\\,u_{t-1}+w\\,x_{t},$$\nwith initial condition $$u_{0}=0,$$ leak factor $$\\lambda=0.9,$$ synaptic weight $$w,$$ and inputs $$x_{1}=0.4,$$ $$x_{2}=0.7.$$ The spiking output at time $$t$$ is\n$$z_{t}=H(u_{t}-\\theta),$$\nwhere $$H(\\cdot)$$ is the Heaviside step function and the threshold is $$\\theta=1.$$ Training is performed with the Straight-Through Estimator (STE; Straight-Through Estimator), which uses the surrogate derivative\n$$\\tilde{H}'(u)=\\mathbf{1}_{|u-\\theta|<0.1},$$\nwhere $$\\mathbf{1}_{A}$$ denotes the indicator of event $$A.$$ The loss at the final time step is the mean squared error\n$$L=\\frac{1}{2}\\,(z_{2}-y)^{2},$$\nwith target $$y=0.$$\n\nLet the synaptic weight be fixed to\n$$w=\\frac{105}{106}.$$\nUnder these settings, the membrane potential crosses threshold only at time $$t=2.$$ Using the definitions above and first principles (discrete membrane dynamics, the chain rule, and the specified surrogate derivative), compute the gradient $$\\frac{\\partial L}{\\partial w}$$ as a single real number. Express the final answer as an exact value (no rounding).",
            "solution": "To compute the gradient $\\frac{\\partial L}{\\partial w}$, we first perform the forward pass to determine the neuron's activity and then apply the chain rule using the surrogate gradient for the backward pass.\n\n**Forward Pass**\nGiven the parameters $\\lambda=0.9$, $w=\\frac{105}{106}$, $x_{1}=0.4$, $x_{2}=0.7$, and $\\theta=1$.\nThe membrane potential at $t=1$ is:\n$$u_{1} = \\lambda u_{0} + w x_{1} = (0.9)(0) + \\left(\\frac{105}{106}\\right)(0.4) = \\frac{105}{106} \\cdot \\frac{4}{10} = \\frac{42}{106} = \\frac{21}{53}$$\nSince $u_1 \\approx 0.396  \\theta$, the neuron does not spike: $z_1 = H(u_1 - \\theta) = 0$.\n\nThe membrane potential at $t=2$ is:\n$$u_{2} = \\lambda u_{1} + w x_{2} = (0.9)\\left(\\frac{21}{53}\\right) + \\left(\\frac{105}{106}\\right)(0.7) = \\frac{9}{10} \\cdot \\frac{21}{53} + \\frac{105}{106} \\cdot \\frac{7}{10} = \\frac{189}{530} + \\frac{735}{1060} = \\frac{378}{1060} + \\frac{735}{1060} = \\frac{1113}{1060}$$\nSince $u_2 \\approx 1.05 > \\theta$, the neuron spikes: $z_2 = H(u_2 - \\theta) = 1$.\n\n**Backward Pass (Gradient Calculation)**\nThe loss is $L = \\frac{1}{2}(z_{2}-y)^{2}$. With target $y=0$, $L = \\frac{1}{2}z_{2}^{2}$.\nWe use the chain rule to find the gradient with respect to $w$:\n$$\\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial z_2} \\frac{\\partial z_2}{\\partial u_2} \\frac{d u_2}{d w}$$\nThe Straight-Through Estimator (STE) substitutes the derivative of the Heaviside function, so we use $\\frac{\\partial z_2}{\\partial u_2} \\approx \\tilde{H}'(u_2) = \\mathbf{1}_{|u_2-\\theta|0.1}$.\n\nThe three terms are:\n1.  **Gradient of Loss w.r.t. Output:**\n    $\\frac{\\partial L}{\\partial z_2} = z_2 - y = 1 - 0 = 1$.\n\n2.  **Surrogate Gradient:**\n    We check if the surrogate derivative is non-zero: $|u_2 - \\theta| = \\left|\\frac{1113}{1060} - 1\\right| = \\frac{53}{1060}$.\n    Since $0.1 = \\frac{1}{10} = \\frac{106}{1060}$, we have $\\frac{53}{1060}  \\frac{106}{1060}$. The condition is met.\n    Thus, $\\tilde{H}'(u_2) = 1$.\n\n3.  **Gradient of Potential w.r.t. Weight:**\n    We express $u_2$ as a function of $w$ by unrolling the recurrence:\n    $u_2 = \\lambda u_1 + w x_2 = \\lambda (w x_1) + w x_2 = w(\\lambda x_1 + x_2)$.\n    The total derivative is:\n    $\\frac{d u_2}{d w} = \\lambda x_1 + x_2 = (0.9)(0.4) + 0.7 = 0.36 + 0.7 = 1.06 = \\frac{53}{50}$.\n\nMultiplying the terms gives the final gradient:\n$$\\frac{\\partial L}{\\partial w} = (1)(1)\\left(\\frac{53}{50}\\right) = \\frac{53}{50}$$\nThe gradient of the loss with respect to the weight $w$ is $\\frac{53}{50}$.",
            "answer": "$$\\boxed{\\frac{53}{50}}$$"
        },
        {
            "introduction": "Moving from a specific numerical example to a more general case, this problem asks you to derive the analytical form of the gradients for a common SNN training scenario. You will work with a spike-count loss and a generic surrogate function, deriving closed-form expressions for the weight and threshold updates. This practice develops essential analytical skills and reveals the underlying mathematical structure of the learning rules, showing how error signals are modulated by the surrogate derivative and distributed across time and inputs .",
            "id": "4061964",
            "problem": "Consider a single spiking neuron observed over discrete time steps indexed by $t \\in \\{1,2,\\dots,T\\}$. At each time $t$, the neuron receives an input vector $\\mathbf{x}_t \\in \\mathbb{R}^{d}$ and forms a pre-threshold membrane potential $u_t = \\mathbf{w}^{\\top}\\mathbf{x}_t$, where $\\mathbf{w} \\in \\mathbb{R}^{d}$ is a trainable weight vector. The neuron has a trainable threshold $\\theta \\in \\mathbb{R}$. The neuron emits a spike $v_t \\in \\{0,1\\}$ according to a hard thresholding nonlinearity $v_t = H(u_t - \\theta)$, where $H(\\cdot)$ is the Heaviside step function.\n\nYou are given a smooth surrogate function $\\sigma_{\\beta}:\\mathbb{R}\\to[0,1]$ parameterized by a slope parameter $\\beta0$ that is used only for gradient computation. Define the surrogate spike probability $p_t = \\sigma_{\\beta}(u_t - \\theta)$ and denote its derivative by $\\sigma_{\\beta}'(\\cdot)$. The training objective is a spike-count mismatch loss\n$$\nL \\;=\\; \\frac{1}{2}\\bigl(s - \\hat{s}\\bigr)^{2}, \\quad \\text{where} \\quad s \\;=\\; \\sum_{t=1}^{T} v_t\n$$\nand $\\hat{s} \\in \\mathbb{R}$ is a given target spike count.\n\nAdopt the standard surrogate gradient approach: treat $v_t$ as non-differentiable in the forward computation of $s$, but in backpropagation use the chain rule with the surrogate derivative so that derivatives of $v_t$ with respect to its arguments are approximated by derivatives of $p_t$, i.e., for any parameter $\\phi$,\n$$\n\\frac{\\partial v_t}{\\partial \\phi} \\;\\approx\\; \\sigma_{\\beta}'(u_t - \\theta)\\,\\frac{\\partial (u_t - \\theta)}{\\partial \\phi}.\n$$\n\nStarting only from the chain rule and linearity of differentiation, derive closed-form expressions for the gradients $\\frac{\\partial L}{\\partial \\mathbf{w}}$ and $\\frac{\\partial L}{\\partial \\theta}$ in terms of $\\{u_t\\}_{t=1}^{T}$, $\\{\\mathbf{x}_t\\}_{t=1}^{T}$, $\\theta$, $\\sigma_{\\beta}'(\\cdot)$, $s$, and $\\hat{s}$. Express your final answer as analytic expressions. No numerical evaluation is required and no rounding is needed. Report both gradients.",
            "solution": "The objective is to derive the gradients of the loss function $L$ with respect to the weight vector $\\mathbf{w}$ and the threshold $\\theta$. The loss is given by $L = \\frac{1}{2}(s - \\hat{s})^2$, where $s = \\sum_{t=1}^{T} v_t$.\n\nWe use the chain rule and the surrogate gradient approximation: $\\frac{\\partial v_t}{\\partial \\phi} \\approx \\sigma_{\\beta}'(u_t - \\theta)\\,\\frac{\\partial (u_t - \\theta)}{\\partial \\phi}$ for any parameter $\\phi$. The first term of the chain rule for both gradients is the derivative of the loss with respect to the total spike count $s$:\n$$\n\\frac{\\partial L}{\\partial s} = \\frac{\\partial}{\\partial s} \\left[ \\frac{1}{2}(s - \\hat{s})^2 \\right] = s - \\hat{s}\n$$\n\n**Gradient with respect to weights, $\\frac{\\partial L}{\\partial \\mathbf{w}}$**\nApplying the chain rule:\n$$\n\\frac{\\partial L}{\\partial \\mathbf{w}} = \\frac{\\partial L}{\\partial s} \\frac{\\partial s}{\\partial \\mathbf{w}} = (s - \\hat{s}) \\sum_{t=1}^{T} \\frac{\\partial v_t}{\\partial \\mathbf{w}}\n$$\nWe find the derivative $\\frac{\\partial v_t}{\\partial \\mathbf{w}}$ using the surrogate approximation:\n$$\n\\frac{\\partial v_t}{\\partial \\mathbf{w}} \\approx \\sigma_{\\beta}'(u_t - \\theta)\\,\\frac{\\partial (u_t - \\theta)}{\\partial \\mathbf{w}}\n$$\nSince $u_t = \\mathbf{w}^{\\top}\\mathbf{x}_t$, the derivative of the argument is $\\frac{\\partial (\\mathbf{w}^{\\top}\\mathbf{x}_t - \\theta)}{\\partial \\mathbf{w}} = \\mathbf{x}_t$.\nSubstituting this back, we get $\\frac{\\partial v_t}{\\partial \\mathbf{w}} \\approx \\sigma_{\\beta}'(u_t - \\theta)\\,\\mathbf{x}_t$.\nThe full gradient for the weights is:\n$$\n\\frac{\\partial L}{\\partial \\mathbf{w}} \\approx (s - \\hat{s}) \\sum_{t=1}^{T} \\sigma_{\\beta}'(u_t - \\theta)\\,\\mathbf{x}_t\n$$\n\n**Gradient with respect to threshold, $\\frac{\\partial L}{\\partial \\theta}$**\nSimilarly, we apply the chain rule for the threshold:\n$$\n\\frac{\\partial L}{\\partial \\theta} = \\frac{\\partial L}{\\partial s} \\frac{\\partial s}{\\partial \\theta} = (s - \\hat{s}) \\sum_{t=1}^{T} \\frac{\\partial v_t}{\\partial \\theta}\n$$\nWe find the derivative $\\frac{\\partial v_t}{\\partial \\theta}$ using the surrogate approximation:\n$$\n\\frac{\\partial v_t}{\\partial \\theta} \\approx \\sigma_{\\beta}'(u_t - \\theta)\\,\\frac{\\partial (u_t - \\theta)}{\\partial \\theta}\n$$\nThe derivative of the argument is $\\frac{\\partial (\\mathbf{w}^{\\top}\\mathbf{x}_t - \\theta)}{\\partial \\theta} = -1$.\nSubstituting this back, we get $\\frac{\\partial v_t}{\\partial \\theta} \\approx -\\sigma_{\\beta}'(u_t - \\theta)$.\nThe full gradient for the threshold is:\n$$\n\\frac{\\partial L}{\\partial \\theta} \\approx -(s - \\hat{s}) \\sum_{t=1}^{T} \\sigma_{\\beta}'(u_t - \\theta)\n$$\nThese are the closed-form expressions for the gradients.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} (s - \\hat{s}) \\sum_{t=1}^{T} \\sigma_{\\beta}'(u_t - \\theta) \\mathbf{x}_t  -(s - \\hat{s}) \\sum_{t=1}^{T} \\sigma_{\\beta}'(u_t - \\theta) \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Our final practice delves into the theoretical underpinnings of surrogate gradients by examining their accuracy. Here, you will compare a popular 'fast-sigmoid' surrogate to a 'true' gradient derived from a noise-injection model, a technique that provides a smooth, differentiable activation function in expectation. By calculating the bias of the surrogate estimator at the critical near-threshold region, you will gain a deeper appreciation for the fact that surrogate gradients are principled approximations and understanding their properties is key to advancing SNN training techniques .",
            "id": "4062019",
            "problem": "Consider a single neuron in a Spiking Neural Network (SNN) whose spike output is the Heaviside step function $H(u - \\theta)$ of its membrane potential $u$ relative to a threshold $\\theta$. A trainable bias $b$ shifts the membrane potential additively, so the effective input to the nonlinearity is $u + b$. The training objective is the linear loss $L(s) = s$ in the spike $s$, so that $\\frac{\\partial L}{\\partial s} = 1$ and $\\frac{\\partial u}{\\partial b} = 1$. Two gradient computations with respect to $b$ are considered:\n\n1. A “true” gradient obtained by making $H$ differentiable through infinitesimal additive noise: inject additive noise $\\xi$ with a logistic distribution of scale $1/\\beta$, whose cumulative distribution function is $F(x) = \\sigma(\\beta x) = \\frac{1}{1 + \\exp(-\\beta x)}$. The expected spike probability is $p(u) = \\mathbb{E}_{\\xi}[H(u + b + \\xi - \\theta)] = \\sigma(\\beta(u + b - \\theta))$. The corresponding gradient with respect to $b$ is the derivative $g^{\\star}_{\\beta}(u + b - \\theta) = \\frac{d}{d b} p(u) = \\beta \\, \\sigma(z)\\bigl(1 - \\sigma(z)\\bigr)$ with $z = \\beta(u + b - \\theta)$.\n\n2. A surrogate gradient that replaces the distributional derivative of $H$ by the “fast-sigmoid” surrogate derivative\n$$\n\\tilde{H}'_{\\beta}(x) = \\frac{1}{\\bigl(1 + \\beta |x|\\bigr)^{2}}.\n$$\nUnder this surrogate, the backpropagated gradient with respect to $b$ is $\\tilde{g}_{\\beta}(u + b - \\theta) = \\tilde{H}'_{\\beta}(u + b - \\theta)$.\n\nDefine the bias of the surrogate gradient with respect to the noise-induced differentiable ground truth as\n$$\nB_{\\beta}(u + b - \\theta) \\equiv \\tilde{g}_{\\beta}(u + b - \\theta) - g^{\\star}_{\\beta}(u + b - \\theta).\n$$\nAssuming the neuron operates in the “near-threshold” regime, evaluate the limit $B_{\\beta}(0) = \\lim_{x \\to 0} B_{\\beta}(x)$ in closed form, and then provide its numerical value for $\\beta = 5$. Express the final numerical value as a pure number with no units. No rounding is required.",
            "solution": "The goal is to compute the bias of the surrogate gradient estimator at the firing threshold. The bias is defined as $B_{\\beta}(x) = \\tilde{g}_{\\beta}(x) - g^{\\star}_{\\beta}(x)$, where $x = u + b - \\theta$ is the effective membrane potential relative to the threshold. We need to evaluate the limit $B_{\\beta}(0) = \\lim_{x \\to 0} B_{\\beta}(x)$.\n\nThe bias function is:\n$$\nB_{\\beta}(x) = \\frac{1}{\\bigl(1 + \\beta |x|\\bigr)^{2}} - \\beta \\, \\sigma(\\beta x)\\bigl(1 - \\sigma(\\beta x)\\bigr)\n$$\nWe can find the limit by evaluating the limit of each term separately as $x \\to 0$.\n\n1.  **Limit of the Surrogate Gradient Term ($\\tilde{g}_{\\beta}$):**\n    The \"fast-sigmoid\" surrogate gradient is $\\tilde{g}_{\\beta}(x) = \\frac{1}{\\bigl(1 + \\beta |x|\\bigr)^{2}}$.\n    As this function is continuous at $x=0$, we can use direct substitution:\n    $$\n    \\lim_{x \\to 0} \\tilde{g}_{\\beta}(x) = \\frac{1}{\\bigl(1 + \\beta \\cdot 0\\bigr)^{2}} = \\frac{1}{1^2} = 1\n    $$\n\n2.  **Limit of the \"True\" Gradient Term ($g^{\\star}_{\\beta}$):**\n    The noise-induced gradient is $g^{\\star}_{\\beta}(x) = \\beta \\, \\sigma(\\beta x)\\bigl(1 - \\sigma(\\beta x)\\bigr)$.\n    The sigmoid function $\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$ is continuous. At $z=0$, $\\sigma(0) = \\frac{1}{1+1} = \\frac{1}{2}$.\n    As $x \\to 0$, the argument $\\beta x \\to 0$. We can again use direct substitution:\n    $$\n    \\lim_{x \\to 0} g^{\\star}_{\\beta}(x) = \\beta \\cdot \\sigma(0) \\cdot \\bigl(1 - \\sigma(0)\\bigr) = \\beta \\cdot \\frac{1}{2} \\cdot \\left(1 - \\frac{1}{2}\\right) = \\frac{\\beta}{4}\n    $$\n\n**Final Bias Calculation**\nBy combining the limits of the two terms, we find the bias at the threshold:\n$$\nB_{\\beta}(0) = \\lim_{x \\to 0} \\tilde{g}_{\\beta}(x) - \\lim_{x \\to 0} g^{\\star}_{\\beta}(x) = 1 - \\frac{\\beta}{4}\n$$\nThis is the closed-form expression for the bias.\n\nFor the specific case of $\\beta = 5$, the numerical value is:\n$$\nB_{5}(0) = 1 - \\frac{5}{4} = -\\frac{1}{4} = -0.25\n$$",
            "answer": "$$\n\\boxed{-\\frac{1}{4}}\n$$"
        }
    ]
}