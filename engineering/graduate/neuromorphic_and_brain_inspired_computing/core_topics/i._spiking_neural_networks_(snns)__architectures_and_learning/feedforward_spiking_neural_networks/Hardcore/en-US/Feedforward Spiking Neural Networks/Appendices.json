{
    "hands_on_practices": [
        {
            "introduction": "In feedforward spiking networks, the alpha function is a cornerstone for modeling the time course of postsynaptic potentials. To understand how neurons integrate information, we must first characterize the shape and dynamics of these fundamental input signals. This foundational exercise  has you derive the key properties of this kernel—its peak time $t_{\\text{peak}}$, peak value $\\kappa_{\\text{peak}}$, and total integrated area $A$—using basic calculus, solidifying your grasp of synaptic dynamics.",
            "id": "4045350",
            "problem": "In a feedforward Spiking Neural Network (SNN), the postsynaptic current in response to a single presynaptic spike at time $t=0$ is modeled as a causal alpha-function kernel\n$$\\kappa(t)=\\frac{t}{\\tau_s}\\exp\\!\\left(-\\frac{t}{\\tau_s}\\right)H(t),$$\nwhere $\\tau_s0$ is the synaptic time constant and $H(t)$ is the Heaviside step function defined by $H(t)=1$ for $t\\ge 0$ and $H(t)=0$ for $t0$. Treat the kernel as a linear time-invariant impulse response with no additional amplitude normalization.\n\nUsing only fundamental calculus and the definitions above, determine the following, all relative to the spike onset time $t=0$:\n- the time $t_{\\text{peak}}$ at which $\\kappa(t)$ attains its unique maximum (for $t\\ge 0$),\n- the peak value $\\kappa_{\\text{peak}}=\\kappa(t_{\\text{peak}})$,\n- the total area under the kernel $A=\\int_{-\\infty}^{\\infty}\\kappa(t)\\,dt$.\n\nExpress all answers in closed form in terms of $\\tau_s$ only. Present your final answers as a single row matrix $\\begin{pmatrix}t_{\\text{peak}}  \\kappa_{\\text{peak}}  A\\end{pmatrix}$. No rounding is required. Do not include units in your final answer.",
            "solution": "The problem asks for three properties of the alpha-function kernel $\\kappa(t) = \\frac{t}{\\tau_s}\\exp(-t/\\tau_s)$ for $t \\ge 0$: the time of its peak $t_{\\text{peak}}$, the value at its peak $\\kappa_{\\text{peak}}$, and its total area $A$. We derive each using basic calculus.\n\n**1. Peak Time ($t_{\\text{peak}}$)**\n\nTo find the time of the maximum, we compute the first derivative of $\\kappa(t)$ with respect to $t$ and set it to zero. Using the product rule:\n$$ \\frac{d\\kappa}{dt} = \\frac{d}{dt}\\left(\\frac{t}{\\tau_s}\\exp\\left(-\\frac{t}{\\tau_s}\\right)\\right) = \\frac{1}{\\tau_s}\\exp\\left(-\\frac{t}{\\tau_s}\\right) + \\frac{t}{\\tau_s}\\left(-\\frac{1}{\\tau_s}\\right)\\exp\\left(-\\frac{t}{\\tau_s}\\right) $$\n$$ \\frac{d\\kappa}{dt} = \\frac{1}{\\tau_s}\\exp\\left(-\\frac{t}{\\tau_s}\\right)\\left(1 - \\frac{t}{\\tau_s}\\right) $$\nThe derivative is zero when $1 - t/\\tau_s = 0$, since the exponential term is always positive. This yields:\n$$ t_{\\text{peak}} = \\tau_s $$\n(A second derivative test confirms this is a maximum).\n\n**2. Peak Value ($\\kappa_{\\text{peak}}$)**\n\nWe find the peak value by substituting $t_{\\text{peak}} = \\tau_s$ back into the kernel function:\n$$ \\kappa_{\\text{peak}} = \\kappa(\\tau_s) = \\frac{\\tau_s}{\\tau_s}\\exp\\left(-\\frac{\\tau_s}{\\tau_s}\\right) = 1 \\cdot \\exp(-1) = \\exp(-1) $$\n\n**3. Total Area ($A$)**\n\nThe total area is the integral of the causal kernel from $0$ to $\\infty$:\n$$ A = \\int_{0}^{\\infty} \\kappa(t) \\,dt = \\int_{0}^{\\infty} \\frac{t}{\\tau_s}\\exp\\left(-\\frac{t}{\\tau_s}\\right) dt $$\nWe solve this using integration by parts, $\\int u \\, dv = uv - \\int v \\, du$. Let:\n- $u = t \\implies du = dt$\n- $dv = \\frac{1}{\\tau_s}\\exp\\left(-\\frac{t}{\\tau_s}\\right) dt \\implies v = -\\exp\\left(-\\frac{t}{\\tau_s}\\right)$\n\n$$ A = \\left[ -t\\exp\\left(-\\frac{t}{\\tau_s}\\right) \\right]_{0}^{\\infty} - \\int_{0}^{\\infty} \\left(-\\exp\\left(-\\frac{t}{\\tau_s}\\right)\\right) dt $$\nThe boundary term $\\left[-t\\exp(-t/\\tau_s)\\right]$ evaluates to 0 at both $t=0$ and as $t\\to\\infty$ (by L'Hôpital's rule on $t/e^{t/\\tau_s}$). The integral becomes:\n$$ A = \\int_{0}^{\\infty} \\exp\\left(-\\frac{t}{\\tau_s}\\right) dt = \\left[ -\\tau_s \\exp\\left(-\\frac{t}{\\tau_s}\\right) \\right]_{0}^{\\infty} $$\n$$ A = (-\\tau_s \\cdot 0) - (-\\tau_s \\cdot e^0) = \\tau_s $$\n\nCombining these results, the final answer is $(\\tau_s, \\exp(-1), \\tau_s)$.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\tau_s  \\exp(-1)  \\tau_s \\end{pmatrix}}$$"
        },
        {
            "introduction": "Beyond receiving synaptic inputs, a neuron's computational behavior is critically defined by its integration and firing mechanism, particularly the reset rule applied after a spike. The choice between a \"hard\" reset to a fixed potential $V_r$ or a \"soft\" subtractive reset $V \\leftarrow V - \\Delta$ can significantly alter firing rates and sensitivity. This practice  challenges you to analyze and compare these two common schemes within the Leaky Integrate-and-Fire (LIF) model, revealing how subtle modeling details produce distinct functional consequences.",
            "id": "4045407",
            "problem": "Consider a single neuron in a feedforward Spiking Neural Network (SNN) modeled as a Leaky Integrate-and-Fire (LIF) unit. The LIF membrane dynamics are given by the Resistive-Capacitive (RC) circuit equation\n$$\nC \\frac{dV(t)}{dt} \\;=\\; -\\frac{V(t) - V_L}{R} \\;+\\; I(t),\n$$\nwhere $C$ is the membrane capacitance, $R$ is the membrane resistance, $V_L$ is the leak reversal potential, $V(t)$ is the membrane voltage, and $I(t)$ is the synaptic input current. Define the membrane time constant as $\\tau_m = R C$. A spike is emitted when $V(t)$ reaches the threshold $V_{\\mathrm{th}}$, followed by an absolute refractory period of duration $\\tau_{\\mathrm{ref}}$ during which $V(t)$ does not evolve. After the refractory period, the membrane voltage is instantaneously reset. Two canonical reset rules are considered:\n- Hard reset: $V \\leftarrow V_r$.\n- Soft reset: $V \\leftarrow V - \\Delta$.\n\nAssume a constant input $I(t) = I_0$ for $t \\ge 0$, and define the steady-state (infinitely long time) depolarized level $V_\\infty = V_L + R I_0$. Assume instantaneous threshold detection (no overshoot), so the spike occurs at $V(t_s) = V_{\\mathrm{th}}$. The neuron operates in the suprathreshold regime $V_\\infty  V_{\\mathrm{th}}$ so that repeated spiking is sustained.\n\nSelect all options that are correct about the inter-spike interval and the effect of hard versus soft reset on subsequent integration in feedforward neurons under these conditions.\n\nA. The inter-spike interval (including refractory) under hard reset is\n$$\nT_{\\mathrm{hard}} \\;=\\; \\tau_{\\mathrm{ref}} \\;+\\; \\tau_m \\ln\\!\\left(\\frac{V_\\infty - V_r}{V_\\infty - V_{\\mathrm{th}}}\\right),\n$$\nand under soft reset is\n$$\nT_{\\mathrm{soft}} \\;=\\; \\tau_{\\mathrm{ref}} \\;+\\; \\tau_m \\ln\\!\\left(\\frac{V_\\infty - (V_{\\mathrm{th}} - \\Delta)}{V_\\infty - V_{\\mathrm{th}}}\\right).\n$$\nMoreover, $T_{\\mathrm{soft}}  T_{\\mathrm{hard}}$ if and only if $\\Delta  V_{\\mathrm{th}} - V_r$.\n\nB. Under soft reset, the inter-spike interval is\n$$\nT_{\\mathrm{soft}} \\;=\\; \\tau_{\\mathrm{ref}} \\;+\\; \\tau_m \\ln\\!\\left(\\frac{V_\\infty - V_r}{V_\\infty - (V_{\\mathrm{th}} + \\Delta)}\\right),\n$$\nso that soft reset is equivalent to increasing the threshold by $\\Delta$.\n\nC. For constant current drive $I_0$, hard and soft reset yield identical steady firing rates for any $\\Delta$, because the subthreshold trajectory between spikes is memoryless.\n\nD. Soft reset always reduces the steady firing rate relative to hard reset, because it increases the effective threshold from $V_{\\mathrm{th}}$ to $V_{\\mathrm{th}} + \\Delta$.\n\nE. Immediately after the refractory period, the gap to threshold equals $V_{\\mathrm{th}} - V_r$ under hard reset and equals $\\Delta$ under soft reset (assuming the spike is detected at $V(t_s) = V_{\\mathrm{th}}$). Thus, for $\\Delta  V_{\\mathrm{th}} - V_r$, subsequent integration of incoming feedforward synaptic currents requires less depolarization under soft reset, making near-threshold post-synaptic inputs more effective at eliciting the next spike than under hard reset.\n\nF. If $\\Delta = V_{\\mathrm{th}} - V_r$, soft reset becomes exactly equivalent to hard reset in the ideal LIF model with instantaneous threshold detection and no spike overshoot, so they produce identical inter-spike intervals for all $I_0$ in the suprathreshold regime.",
            "solution": "The problem statement is evaluated for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n- **LIF model equation**: $C \\frac{dV(t)}{dt} = -\\frac{V(t) - V_L}{R} + I(t)$.\n- **Membrane time constant**: $\\tau_m = R C$.\n- **Spike condition**: $V(t)$ reaches the threshold $V_{\\mathrm{th}}$.\n- **Refractory period**: Absolute, duration $\\tau_{\\mathrm{ref}}$, during which $V(t)$ does not evolve.\n- **Reset rules**: After the refractory period, the voltage is instantaneously reset according to one of two rules:\n    - Hard reset: $V \\leftarrow V_r$.\n    - Soft reset: $V \\leftarrow V - \\Delta$.\n- **Input current**: Constant, $I(t) = I_0$ for $t \\ge 0$.\n- **Steady-state voltage**: $V_\\infty = V_L + R I_0$.\n- **Spike detection**: Instantaneous at $V(t_s) = V_{\\mathrm{th}}$.\n- **Operating regime**: Suprathreshold, $V_\\infty  V_{\\mathrm{th}}$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem describes the Leaky Integrate-and-Fire (LIF) model, a cornerstone of computational neuroscience and neuromorphic engineering. The RC circuit analogy and the definitions of parameters are standard and physically sound.\n2.  **Well-Posed**: The problem provides a first-order ordinary differential equation, initial conditions (defined by the reset rules), and a boundary condition (the threshold). This setup allows for the unique calculation of the inter-spike interval (ISI).\n3.  **Objective**: The language is precise, using established terminology from the field. No subjective or ambiguous statements are present.\n4.  **No Flaws**: The problem does not violate any scientific principles, is formalizable, complete, and well-structured. The assumptions (e.g., constant current, instantaneous reset) are idealizations common in theoretical analysis and serve to make the problem tractable.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. A solution will be derived.\n\n### Derivation of the Inter-Spike Interval (ISI)\n\nThe governing differential equation for the membrane potential $V(t)$ is:\n$$C \\frac{dV(t)}{dt} = -\\frac{V(t) - V_L}{R} + I_0$$\nUsing the definitions $\\tau_m = RC$ and $V_\\infty = V_L + RI_0$, we can rewrite the equation as:\n$$RC \\frac{dV}{dt} = -(V - V_L) + RI_0$$\n$$\\tau_m \\frac{dV}{dt} = -V + V_L + RI_0 = -(V - (V_L + RI_0))$$\n$$\\tau_m \\frac{dV}{dt} = V_\\infty - V(t)$$\nThis is a first-order linear ordinary differential equation. We can solve it by separating variables, for a time interval starting at $t_0$ with initial voltage $V(t_0) = V_0$:\n$$\\int_{V_0}^{V(t)} \\frac{dV'}{V_\\infty - V'} = \\int_{t_0}^{t} \\frac{dt'}{\\tau_m}$$\nNote that since the neuron is in the suprathreshold regime ($V_\\infty  V_{\\mathrm{th}}$) and the voltage evolves from a reset potential below threshold towards the threshold, we have $V(t)  V_{\\mathrm{th}}  V_\\infty$. Thus, the term $V_\\infty - V'$ is always positive.\n$$[-\\ln(V_\\infty - V')]_{V_0}^{V(t)} = \\frac{t - t_0}{\\tau_m}$$\n$$\\ln(V_\\infty - V_0) - \\ln(V_\\infty - V(t)) = \\frac{t - t_0}{\\tau_m}$$\n$$\\ln\\left(\\frac{V_\\infty - V_0}{V_\\infty - V(t)}\\right) = \\frac{t - t_0}{\\tau_m}$$\nLet $T_{\\mathrm{rise}}$ be the time it takes for the voltage to rise from the reset potential $V_0$ to the threshold $V_{\\mathrm{th}}$. The integration starts after the refractory period, so we can set $t_0 = 0$ for this phase. At $t = T_{\\mathrm{rise}}$, we have $V(T_{\\mathrm{rise}}) = V_{\\mathrm{th}}$.\n$$T_{\\mathrm{rise}} = \\tau_m \\ln\\left(\\frac{V_\\infty - V_0}{V_\\infty - V_{\\mathrm{th}}}\\right)$$\nThe total inter-spike interval (ISI), $T$, is the sum of the rise time and the absolute refractory period $\\tau_{\\mathrm{ref}}$:\n$$T = \\tau_{\\mathrm{ref}} + T_{\\mathrm{rise}} = \\tau_{\\mathrm{ref}} + \\tau_m \\ln\\left(\\frac{V_\\infty - V_0}{V_\\infty - V_{\\mathrm{th}}}\\right)$$\nNow we apply the specific reset rules to find the initial voltage $V_0$.\n\n**Hard Reset:** The voltage is reset to a fixed value $V_r$. So, $V_0 = V_r$.\nThe ISI is:\n$$T_{\\mathrm{hard}} = \\tau_{\\mathrm{ref}} + \\tau_m \\ln\\left(\\frac{V_\\infty - V_r}{V_\\infty - V_{\\mathrm{th}}}\\right)$$\n\n**Soft Reset:** The voltage is reduced by an amount $\\Delta$ from its value at the moment of the spike. Since the spike is detected exactly at $V(t_s) = V_{\\mathrm{th}}$, the reset potential is $V_0 = V_{\\mathrm{th}} - \\Delta$.\nThe ISI is:\n$$T_{\\mathrm{soft}} = \\tau_{\\mathrm{ref}} + \\tau_m \\ln\\left(\\frac{V_\\infty - (V_{\\mathrm{th}} - \\Delta)}{V_\\infty - V_{\\mathrm{th}}}\\right)$$\n\n### Option-by-Option Analysis\n\n**A. The inter-spike interval (including refractory) under hard reset is $T_{\\mathrm{hard}} = \\tau_{\\mathrm{ref}} + \\tau_m \\ln\\!\\left(\\frac{V_\\infty - V_r}{V_\\infty - V_{\\mathrm{th}}}\\right)$, and under soft reset is $T_{\\mathrm{soft}} = \\tau_{\\mathrm{ref}} + \\tau_m \\ln\\!\\left(\\frac{V_\\infty - (V_{\\mathrm{th}} - \\Delta)}{V_\\infty - V_{\\mathrm{th}}}\\right)$. Moreover, $T_{\\mathrm{soft}}  T_{\\mathrm{hard}}$ if and only if $\\Delta  V_{\\mathrm{th}} - V_r$.**\n\nThe derived expressions for $T_{\\mathrm{hard}}$ and $T_{\\mathrm{soft}}$ match exactly with those given in the option.\nNow, we test the inequality $T_{\\mathrm{soft}}  T_{\\mathrm{hard}}$:\n$$\\tau_{\\mathrm{ref}} + \\tau_m \\ln\\left(\\frac{V_\\infty - (V_{\\mathrm{th}} - \\Delta)}{V_\\infty - V_{\\mathrm{th}}}\\right)  \\tau_{\\mathrm{ref}} + \\tau_m \\ln\\left(\\frac{V_\\infty - V_r}{V_\\infty - V_{\\mathrm{th}}}\\right)$$\nSince $\\tau_m  0$ and the logarithm function $\\ln(x)$ is strictly increasing, this is equivalent to:\n$$\\frac{V_\\infty - (V_{\\mathrm{th}} - \\Delta)}{V_\\infty - V_{\\mathrm{th}}}  \\frac{V_\\infty - V_r}{V_\\infty - V_{\\mathrm{th}}}$$\nThe denominator $V_\\infty - V_{\\mathrm{th}}$ is positive under the suprathreshold condition, so we can multiply both sides by it without changing the inequality:\n$$V_\\infty - V_{\\mathrm{th}} + \\Delta  V_\\infty - V_r$$\n$$-V_{\\mathrm{th}} + \\Delta  -V_r$$\n$$\\Delta  V_{\\mathrm{th}} - V_r$$\nThe condition stated in the option is correct. Thus, the entire statement is correct.\n**Verdict: Correct.**\n\n**B. Under soft reset, the inter-spike interval is $T_{\\mathrm{soft}} = \\tau_{\\mathrm{ref}} + \\tau_m \\ln\\!\\left(\\frac{V_\\infty - V_r}{V_\\infty - (V_{\\mathrm{th}} + \\Delta)}\\right)$, so that soft reset is equivalent to increasing the threshold by $\\Delta$.**\n\nOur derived expression is $T_{\\mathrm{soft}} = \\tau_{\\mathrm{ref}} + \\tau_m \\ln\\left(\\frac{V_\\infty - (V_{\\mathrm{th}} - \\Delta)}{V_\\infty - V_{\\mathrm{th}}}\\right)$. This does not match the expression in the option. The option's formula incorrectly uses $V_r$ in the numerator and modifies the threshold term in the denominator. The interpretation that soft reset is equivalent to increasing the threshold to $V_{\\mathrm{th}} + \\Delta$ is also incorrect; soft reset modifies the reset potential to $V_{\\mathrm{th}} - \\Delta$.\n**Verdict: Incorrect.**\n\n**C. For constant current drive $I_0$, hard and soft reset yield identical steady firing rates for any $\\Delta$, because the subthreshold trajectory between spikes is memoryless.**\n\nSteady firing rate is the reciprocal of the ISI, $f = 1/T$. For the firing rates to be identical, the ISIs must be identical: $T_{\\mathrm{hard}} = T_{\\mathrm{soft}}$. From our analysis of option A, this equality holds if and only if $\\Delta = V_{\\mathrm{th}} - V_r$. For any other value of $\\Delta$, the ISIs are different. The claim that this holds \"for any $\\Delta$\" is false. The reasoning provided is also flawed; while the underlying differential equation is memoryless, the starting condition (the reset potential) differs between the two schemes, which affects the trajectory duration.\n**Verdict: Incorrect.**\n\n**D. Soft reset always reduces the steady firing rate relative to hard reset, because it increases the effective threshold from $V_{\\mathrm{th}}$ to $V_{\\mathrm{th}} + \\Delta$.**\n\nReducing the firing rate means increasing the ISI, so this option claims $T_{\\mathrm{soft}}  T_{\\mathrm{hard}}$ is always true. As shown in the analysis for option A, the relationship depends on the comparison between $\\Delta$ and $V_{\\mathrm{th}} - V_r$:\n- If $\\Delta  V_{\\mathrm{th}} - V_r$, then $T_{\\mathrm{soft}}  T_{\\mathrm{hard}}$ (higher firing rate).\n- If $\\Delta  V_{\\mathrm{th}} - V_r$, then $T_{\\mathrm{soft}}  T_{\\mathrm{hard}}$ (lower firing rate).\n- If $\\Delta = V_{\\mathrm{th}} - V_r$, then $T_{\\mathrm{soft}} = T_{\\mathrm{hard}}$ (same firing rate).\nTherefore, the claim that it *always* reduces the firing rate is false. The justification is also false, as soft reset does not increase the effective threshold.\n**Verdict: Incorrect.**\n\n**E. Immediately after the refractory period, the gap to threshold equals $V_{\\mathrm{th}} - V_r$ under hard reset and equals $\\Delta$ under soft reset (assuming the spike is detected at $V(t_s) = V_{\\mathrm{th}}$). Thus, for $\\Delta  V_{\\mathrm{th}} - V_r$, subsequent integration of incoming feedforward synaptic currents requires less depolarization under soft reset, making near-threshold post-synaptic inputs more effective at eliciting the next spike than under hard reset.**\n\nThe \"gap to threshold\" is the difference between the threshold voltage and the post-reset voltage, $V_{\\mathrm{th}} - V_0$.\n- For hard reset, $V_0 = V_r$. The gap is $V_{\\mathrm{th}} - V_r$. This is correct.\n- For soft reset, $V_0 = V_{\\mathrm{th}} - \\Delta$. The gap is $V_{\\mathrm{th}} - (V_{\\mathrm{th}} - \\Delta) = \\Delta$. This is correct.\nThe condition $\\Delta  V_{\\mathrm{th}} - V_r$ means the voltage gap to threshold is smaller for soft reset than for hard reset. A smaller voltage gap implies that the neuron is closer to its firing threshold. Consequently, it requires a smaller additional depolarization to reach threshold. This makes the neuron more sensitive or responsive to subsequent inputs, as a given input will have a greater relative effect. The physical interpretation is logically sound and follows directly from the mathematical result.\n**Verdict: Correct.**\n\n**F. If $\\Delta = V_{\\mathrm{th}} - V_r$, soft reset becomes exactly equivalent to hard reset in the ideal LIF model with instantaneous threshold detection and no spike overshoot, so they produce identical inter-spike intervals for all $I_0$ in the suprathreshold regime.**\n\nLet's examine the reset potential $V_0$ under soft reset with the condition $\\Delta = V_{\\mathrm{th}} - V_r$.\nThe soft reset potential is $V_0 = V_{\\mathrm{th}} - \\Delta$. Substituting the condition:\n$$V_0 = V_{\\mathrm{th}} - (V_{\\mathrm{th}} - V_r) = V_r$$\nThis shows that under this specific condition, the reset potential for soft reset is exactly equal to the reset potential for hard reset. Since the differential equation, threshold, and refractory period are identical for both cases, if their initial conditions (reset potentials) are also identical, their entire subsequent dynamics must be identical. This means a spike will be produced after the same amount of time, leading to identical inter-spike intervals, $T_{\\mathrm{soft}} = T_{\\mathrm{hard}}$, for any given suprathreshold input $I_0$. This is confirmed by substituting $\\Delta = V_{\\mathrm{th}} - V_r$ into the formula for $T_{\\mathrm{soft}}$ from option A, which makes it identical to the formula for $T_{\\mathrm{hard}}$.\n**Verdict: Correct.**",
            "answer": "$$\\boxed{AEF}$$"
        },
        {
            "introduction": "A key function of neural computation is transforming input patterns into precisely timed outputs. This requires tuning synaptic weights to control when a neuron fires. This final practice  frames this challenge as a constrained optimization problem, a crucial first step toward understanding supervised learning in SNNs. You will determine the most \"efficient\" weight configuration—the one with the minimum Euclidean norm—to elicit an output spike at a specific, desired time $t^*$.",
            "id": "4045396",
            "problem": "Consider a single neuron within a feedforward Spiking Neural Network (SNN), modeled by the Spike Response Model (SRM) with linear superposition and a static firing threshold. Let there be $N$ afferent synapses, each emitting exactly one input spike at known times $t_{1}, t_{2}, \\dots, t_{N}$, with all $t_{i}  t^{*}$. The postsynaptic response is governed by a fixed causal synaptic kernel $\\kappa(t)$ satisfying $\\kappa(t) = 0$ for $t  0$, which maps elapsed time since a presynaptic spike to a contribution to the membrane potential.\n\nUnder these assumptions, the membrane potential of the neuron at time $t$ is\n$$\nu(t) = \\sum_{i=1}^{N} w_{i}\\,\\kappa\\!\\big(t - t_{i}\\big),\n$$\nwhere $w_{i}$ is the synaptic weight associated with the $i$-th input. The neuron emits a spike when the membrane potential reaches the fixed threshold $\\vartheta  0$. You are to enforce only the equality constraint that the neuron spikes at the prescribed time $t^{*}$, i.e.,\n$$\nu(t^{*}) = \\sum_{i=1}^{N} w_{i}\\,\\kappa\\!\\big(t^{*} - t_{i}\\big) = \\vartheta,\n$$\nand do not impose any additional constraints on earlier threshold crossings or on the sign of the weights.\n\nAmong all weight vectors $\\boldsymbol{w} = (w_{1},\\dots,w_{N})$ that satisfy the above equality constraint, determine the unique weight vector of minimum Euclidean norm. Express your final result in closed form in terms of $\\kappa$, the input spike times $\\{t_{i}\\}$, the prescribed spike time $t^{*}$, and the threshold $\\vartheta$. Provide the final answer as a single analytical expression using the row-matrix format for the vector, and do not include units in the box.",
            "solution": "The problem as stated constitutes a valid and well-posed constrained optimization problem within the formal framework of the Spike Response Model (SRM) for a neuron. The givens are self-contained and scientifically sound, and the objective is clearly defined. The task is to find a weight vector $\\boldsymbol{w} = (w_{1}, \\dots, w_{N})$ that minimizes its Euclidean norm, $\\|\\boldsymbol{w}\\|$, subject to a linear constraint. Minimizing the norm is equivalent to minimizing its square, $\\|\\boldsymbol{w}\\|^2 = \\sum_{i=1}^{N} w_{i}^2$, which is computationally more convenient.\n\nThe problem can be formulated as follows:\nMinimize the objective function $f(\\boldsymbol{w}) = \\sum_{i=1}^{N} w_{i}^2$.\nSubject to the constraint $g(\\boldsymbol{w}) = \\sum_{i=1}^{N} w_{i}\\,\\kappa(t^{*} - t_{i}) - \\vartheta = 0$.\n\nThis is a classic optimization problem that can be solved using the method of Lagrange multipliers. We introduce a Lagrangian function $\\mathcal{L}(\\boldsymbol{w}, \\lambda)$ defined as:\n$$ \\mathcal{L}(\\boldsymbol{w}, \\lambda) = f(\\boldsymbol{w}) - \\lambda g(\\boldsymbol{w}) = \\sum_{i=1}^{N} w_{i}^2 - \\lambda \\left( \\sum_{i=1}^{N} w_{i}\\,\\kappa(t^{*} - t_{i}) - \\vartheta \\right) $$\nwhere $\\lambda$ is the Lagrange multiplier.\n\nTo find the minimum, we must find the critical points of $\\mathcal{L}$ by setting its partial derivatives with respect to each variable $w_{k}$ (for $k=1, \\dots, N$) and $\\lambda$ to zero.\n\nThe partial derivative with respect to an arbitrary weight component $w_{k}$ is:\n$$ \\frac{\\partial \\mathcal{L}}{\\partial w_{k}} = \\frac{\\partial}{\\partial w_{k}} \\left( \\sum_{i=1}^{N} w_{i}^2 \\right) - \\lambda \\frac{\\partial}{\\partial w_{k}} \\left( \\sum_{i=1}^{N} w_{i}\\,\\kappa(t^{*} - t_{i}) - \\vartheta \\right) $$\n$$ \\frac{\\partial \\mathcal{L}}{\\partial w_{k}} = 2w_{k} - \\lambda \\kappa(t^{*} - t_{k}) $$\nSetting this derivative to zero yields the condition for the optimal weights:\n$$ 2w_{k} - \\lambda \\kappa(t^{*} - t_{k}) = 0 \\implies w_{k} = \\frac{\\lambda}{2} \\kappa(t^{*} - t_{k}) $$\nThis equation holds for all $k \\in \\{1, \\dots, N\\}$. It indicates that each optimal weight $w_{k}$ is proportional to the corresponding value of the response kernel $\\kappa(t^{*} - t_{k})$.\n\nTo determine the value of the Lagrange multiplier $\\lambda$, we substitute this expression for $w_{k}$ back into the original constraint equation:\n$$ \\sum_{k=1}^{N} w_{k}\\,\\kappa(t^{*} - t_{k}) = \\vartheta $$\n$$ \\sum_{k=1}^{N} \\left( \\frac{\\lambda}{2} \\kappa(t^{*} - t_{k}) \\right) \\kappa(t^{*} - t_{k}) = \\vartheta $$\nWe can factor out the constant term $\\frac{\\lambda}{2}$:\n$$ \\frac{\\lambda}{2} \\sum_{k=1}^{N} \\left( \\kappa(t^{*} - t_{k}) \\right)^2 = \\vartheta $$\nNow, we can solve for the term $\\frac{\\lambda}{2}$:\n$$ \\frac{\\lambda}{2} = \\frac{\\vartheta}{\\sum_{k=1}^{N} \\left( \\kappa(t^{*} - t_{k}) \\right)^2} $$\nThis expression is well-defined provided that the denominator is non-zero. The term $\\left(\\kappa(t^{*} - t_{k})\\right)^2$ is non-negative for all $k$. For the sum to be zero, all terms must be zero, i.e., $\\kappa(t^{*} - t_{k})=0$ for all $k$. In that scenario, the constraint equation would become $0 = \\vartheta$, which contradicts the given condition $\\vartheta  0$. Therefore, we must have $\\sum_{k=1}^{N} \\left( \\kappa(t^{*} - t_{k}) \\right)^2  0$.\n\nFinally, we substitute the expression for $\\frac{\\lambda}{2}$ back into the equation for $w_{k}$:\n$$ w_{k} = \\left( \\frac{\\vartheta}{\\sum_{j=1}^{N} \\left( \\kappa(t^{*} - t_{j}) \\right)^2} \\right) \\kappa(t^{*} - t_{k}) $$\nHere, we use $j$ as the summation index to avoid confusion with the component index $k$.\n\nThis gives the expression for each component of the unique weight vector $\\boldsymbol{w}$ of minimum Euclidean norm. Geometrically, the constraint equation defines a hyperplane in the $N$-dimensional weight space, and the derived vector $\\boldsymbol{w}$ is the coordinate vector of the point on this hyperplane that is closest to the origin.\n\nThe final answer, expressed as a row vector $\\boldsymbol{w} = (w_{1}, \\dots, w_{N})$, can be written by factoring out the common scalar multiple:\n$$ \\boldsymbol{w} = \\frac{\\vartheta}{\\sum_{j=1}^{N} \\left(\\kappa(t^{*} - t_{j})\\right)^2} \\begin{pmatrix} \\kappa(t^{*} - t_{1})  \\kappa(t^{*} - t_{2})  \\dots  \\kappa(t^{*} - t_{N}) \\end{pmatrix} $$\nThis represents the complete solution in closed form as requested.",
            "answer": "$$ \\boxed{ \\frac{\\vartheta}{\\sum_{j=1}^{N} \\left(\\kappa(t^{*} - t_{j})\\right)^2} \\begin{pmatrix} \\kappa(t^{*} - t_{1})  \\kappa(t^{*} - t_{2})  \\dots  \\kappa(t^{*} - t_{N}) \\end{pmatrix} } $$"
        }
    ]
}