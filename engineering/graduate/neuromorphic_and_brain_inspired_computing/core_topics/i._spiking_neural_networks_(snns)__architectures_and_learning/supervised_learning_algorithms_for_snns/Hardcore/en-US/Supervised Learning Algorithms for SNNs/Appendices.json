{
    "hands_on_practices": [
        {
            "introduction": "A central challenge in training Spiking Neural Networks (SNNs) is the all-or-none nature of spikes, which makes the network's output non-differentiable with respect to its weights. This exercise  directly confronts this issue by asking you to compare the gradients derived from two different supervisory signals: a discrete spike count and a continuous, time-averaged membrane potential. By analyzing these two cases, you will gain a fundamental understanding of why naive approaches to SNN training fail and why techniques like surrogate gradients are essential.",
            "id": "4061639",
            "problem": "Consider a single postsynaptic Leaky Integrate-and-Fire (LIF) neuron receiving presynaptic spike trains. Let the membrane potential be denoted by $V(t)$, the membrane time constant by $\\tau_{\\mathrm{m}}$, and the input resistance by $R$. The subthreshold membrane dynamics on any interval between spikes satisfy the linear ordinary differential equation\n$$\\tau_{\\mathrm{m}} \\frac{dV(t)}{dt} = -V(t) + R \\sum_{j} w_j x_j(t),$$\nwhere $w_j$ are synaptic weights and $x_j(t)$ are synaptic currents obtained by convolving the presynaptic spike train $s_j(t) = \\sum_{m} \\delta\\!\\left(t - t^{(j)}_m\\right)$ with an exponential synaptic kernel $\\epsilon(t) = \\frac{1}{\\tau_{\\mathrm{s}}} e^{-t/\\tau_{\\mathrm{s}}} H(t)$, with synaptic time constant $\\tau_{\\mathrm{s}} > 0$ and Heaviside step function $H(t)$. When $V(t)$ reaches the threshold $V_{\\mathrm{th}}$, a spike is emitted and $V(t)$ is reset to $V_{\\mathrm{r}}$; assume an absolute refractory period that prevents immediate re-spiking.\n\nTwo supervised readouts are considered over a fixed window $[0, T]$:\n(i) the spike-count readout $r_{\\mathrm{sc}} = N(T)$, the total number of spikes emitted in $[0, T]$;\n(ii) the voltage-based readout $r_{\\mathrm{v}} = \\int_{0}^{T} V(t)\\, dt$.\n\nDefine a quadratic loss $L = \\frac{1}{2}\\left(r - r^{\\ast}\\right)^2$ for a target $r^{\\ast}$, with $r$ being either $r_{\\mathrm{sc}}$ or $r_{\\mathrm{v}}$. Consider infinitesimal perturbations of a single synaptic weight $w_k \\mapsto w_k + \\delta w$ around a baseline $w_k$ that yields a fixed spike sequence and fixed reset times within $[0, T]$.\n\nFrom the governing dynamics and the readout definitions, derive the gradient sensitivity $\\frac{\\partial L}{\\partial w_k}$ under the two readouts and compare their behavior for small perturbations $\\delta w$ that do not alter spike times. Then, identify the correct implications for the suitability of gradient-based supervised training in each case.\n\nWhich of the following statements are correct?\n\nA) Under the exact spiking nonlinearity, $\\frac{\\partial r_{\\mathrm{sc}}}{\\partial w_k} = 0$ for all perturbations $\\delta w$ that do not change the number of threshold crossings within $[0, T]$; therefore $\\frac{\\partial L}{\\partial w_k}$ for the spike-count readout vanishes almost everywhere in weight space, impeding standard gradient descent without additional techniques.\n\nB) For the voltage-based readout, $\\frac{\\partial L}{\\partial w_k} = \\left(r_{\\mathrm{v}} - r^{\\ast}\\right) \\int_{0}^{T} \\frac{\\partial V(t)}{\\partial w_k}\\, dt$, where $\\frac{\\partial V(t)}{\\partial w_k}$ solves the linear sensitivity equation $\\tau_{\\mathrm{m}} \\frac{d}{dt}\\left(\\frac{\\partial V(t)}{\\partial w_k}\\right) = -\\frac{\\partial V(t)}{\\partial w_k} + R\\, x_k(t)$ on each inter-spike interval with appropriate continuity across resets when spike times are fixed; hence the gradient exists, is bounded, and scales with the membrane and synaptic time constants, favoring stable gradient-based training.\n\nC) If the spike-generation nonlinearity is replaced by a differentiable surrogate $\\sigma\\!\\left(V(t) - V_{\\mathrm{th}}\\right)$ with nonzero slope near threshold, then the spike-count gradient becomes identical to the voltage-based gradient up to a constant multiplicative factor, implying both readouts have equivalent gradient stability.\n\nD) Voltage-based readouts inevitably suffer from exploding gradients due to reset-induced discontinuities in $V(t)$, making $\\frac{\\partial V(t)}{\\partial w_k}$ unbounded and rendering gradient descent unstable.\n\nE) For spike-count readouts, unbiased gradient estimates can be obtained by infinitesimal finite differences without surrogate smoothing, because the limit of the difference quotient equals the true nonzero derivative almost everywhere.\n\nSelect all correct options. Provide your answer as uppercase letters concatenated in ascending alphabetical order.",
            "solution": "The user wants a critical validation of the provided problem statement, followed by a full derivation and evaluation of the options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **Neuron Model**: Leaky Integrate-and-Fire (LIF).\n*   **State Variable**: Membrane potential, $V(t)$.\n*   **Parameters**: Membrane time constant $\\tau_{\\mathrm{m}}$, input resistance $R$, synaptic time constant $\\tau_{\\mathrm{s}}$, firing threshold $V_{\\mathrm{th}}$, reset potential $V_{\\mathrm{r}}$.\n*   **Subthreshold Dynamics**: $\\tau_{\\mathrm{m}} \\frac{dV(t)}{dt} = -V(t) + R \\sum_{j} w_j x_j(t)$.\n*   **Synaptic Input**: Synaptic current $x_j(t) = (s_j \\ast \\epsilon)(t)$, where $s_j(t) = \\sum_{m} \\delta\\!\\left(t - t^{(j)}_m\\right)$ is the presynaptic spike train and $\\epsilon(t) = \\frac{1}{\\tau_{\\mathrm{s}}} e^{-t/\\tau_{\\mathrm{s}}} H(t)$ is the synaptic kernel. $w_j$ are the synaptic weights.\n*   **Spiking and Reset**: When $V(t)$ reaches $V_{\\mathrm{th}}$, a spike is emitted, and $V(t)$ is reset to $V_{\\mathrm{r}}$. An absolute refractory period is assumed.\n*   **Observation Window**: $[0, T]$.\n*   **Readouts**:\n    *   (i) Spike-count readout: $r_{\\mathrm{sc}} = N(T)$, the total spike count in $[0, T]$.\n    *   (ii) Voltage-based readout: $r_{\\mathrm{v}} = \\int_{0}^{T} V(t)\\, dt$.\n*   **Loss Function**: $L = \\frac{1}{2}\\left(r - r^{\\ast}\\right)^2$, where $r \\in \\{r_{\\mathrm{sc}}, r_{\\mathrm{v}}\\}$.\n*   **Analytical Condition**: The analysis concerns infinitesimal perturbations of a single weight $w_k$ that do not alter the spike sequence or spike times within $[0, T]$.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientifically Grounded**: The problem is firmly rooted in computational neuroscience and neuromorphic computing. The LIF neuron, exponential synaptic model, and the formulation of a supervised learning task are standard and widely studied concepts. The core issue addressed—the non-differentiability of the spike generation event—is a central challenge in training Spiking Neural Networks (SNNs).\n*   **Well-Posed**: The problem is well-posed. The dynamics are described by a linear ordinary differential equation (ODE) between spikes. The readouts are well-defined functionals of the voltage trajectory. The question asks for the gradient of a loss function under a clearly stated (though simplifying) assumption of fixed spike times. This allows for a unique and meaningful derivation of the quantities of interest.\n*   **Objective**: The problem is stated in precise, objective mathematical language. All terms are standard and unambiguous within the field.\n\nThe problem statement has no scientific or factual unsoundness, is formalizable, is complete for the question asked, is not unrealistic within its theoretical context, is well-structured, and addresses a non-trivial issue. The assumption of fixed spike times is a deliberate simplification to expose the underlying properties of the gradients for different readouts, a common analytical technique.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. The analysis can proceed.\n\n### Derivation and Option Analysis\n\nThe gradient of the quadratic loss $L = \\frac{1}{2}(r - r^{\\ast})^2$ with respect to a synaptic weight $w_k$ is given by the chain rule:\n$$ \\frac{\\partial L}{\\partial w_k} = \\frac{\\partial L}{\\partial r} \\frac{\\partial r}{\\partial w_k} = (r - r^{\\ast}) \\frac{\\partial r}{\\partial w_k} $$\nThe core of the problem is to evaluate the term $\\frac{\\partial r}{\\partial w_k}$ for the two different readouts, $r_{\\mathrm{sc}}$ and $r_{\\mathrm{v}}$, under the stated assumption that infinitesimal weight perturbations do not change the spike times.\n\n**Case 1: Spike-Count Readout ($r = r_{\\mathrm{sc}}$)**\n\nThe spike-count readout is $r_{\\mathrm{sc}} = N(T)$, the total number of spikes in the interval $[0, T]$. By its nature, $N(T)$ is an integer-valued function. As a function of the weight $w_k$, $N(T; w_k)$ is a step function. It is constant over continuous ranges of $w_k$ and jumps discontinuously at specific values of $w_k$ where a change in weight causes a spike to be added or removed.\n\nThe problem explicitly assumes we are analyzing perturbations that \"do not alter spike times.\" This directly implies that the number of spikes, $N(T)$, remains constant for these perturbations. Therefore, for a small change $\\delta w$, the change in the readout is $\\delta r_{\\mathrm{sc}} = 0$.\n\nThe derivative is defined as the limit of the difference quotient:\n$$ \\frac{\\partial r_{\\mathrm{sc}}}{\\partial w_k} = \\lim_{\\delta w \\to 0} \\frac{N(T; w_k + \\delta w) - N(T; w_k)}{\\delta w} $$\nUnder the problem's assumption, the numerator is zero for any sufficiently small $\\delta w$ that does not cross a discontinuity. Consequently, the derivative is:\n$$ \\frac{\\partial r_{\\mathrm{sc}}}{\\partial w_k} = 0 $$\nThis holds for all $w_k$ except for a set of measure zero where the function is discontinuous. Accordingly, the loss gradient for the spike-count readout is:\n$$ \\frac{\\partial L}{\\partial w_k} = (r_{\\mathrm{sc}} - r^{\\ast}) \\cdot 0 = 0 \\quad (\\text{almost everywhere}) $$\nThis is the well-known \"vanishing gradient\" problem in SNNs trained on spike times or counts.\n\n**Case 2: Voltage-Based Readout ($r = r_{\\mathrm{v}}$)**\n\nThe voltage-based readout is $r_{\\mathrm{v}} = \\int_{0}^{T} V(t)\\, dt$. Its gradient with respect to $w_k$ is:\n$$ \\frac{\\partial r_{\\mathrm{v}}}{\\partial w_k} = \\frac{\\partial}{\\partial w_k} \\int_{0}^{T} V(t; w_k)\\, dt = \\int_{0}^{T} \\frac{\\partial V(t; w_k)}{\\partial w_k}\\, dt $$\nThe exchange of differentiation and integration is permissible here since the integration limits are fixed and $V(t)$ is a continuous function of $w_k$ between spikes. Let's define the voltage sensitivity as $S_k(t) = \\frac{\\partial V(t)}{\\partial w_k}$.\n\nTo find an equation for $S_k(t)$, we differentiate the subthreshold dynamics with respect to $w_k$:\n$$ \\frac{\\partial}{\\partial w_k} \\left( \\tau_{\\mathrm{m}} \\frac{dV(t)}{dt} = -V(t) + R \\sum_{j} w_j x_j(t) \\right) $$\nAssuming smoothness allows swapping derivatives, we get:\n$$ \\tau_{\\mathrm{m}} \\frac{d}{dt} \\left(\\frac{\\partial V(t)}{\\partial w_k}\\right) = -\\frac{\\partial V(t)}{\\partial w_k} + R \\frac{\\partial}{\\partial w_k}} \\left( \\sum_{j} w_j x_j(t) \\right) $$\nThe derivative of the sum is:\n$$ \\frac{\\partial}{\\partial w_k} \\left( \\sum_{j} w_j x_j(t) \\right) = \\sum_{j} \\frac{\\partial(w_j)}{\\partial w_k} x_j(t) = x_k(t) $$\nsince $x_j(t)$ does not depend on the postsynaptic weights $w_j$. Thus, the sensitivity $S_k(t)$ obeys the linear ODE:\n$$ \\tau_{\\mathrm{m}} \\frac{dS_k(t)}{dt} = -S_k(t) + R x_k(t) $$\nThis equation holds on every inter-spike interval. Now, consider the effect of a reset at a fixed spike time $t=t_f$. After the spike, the potential is reset to a constant value: $V(t_f^+) = V_{\\mathrm{r}}$. The sensitivity immediately after the reset is:\n$$ S_k(t_f^+) = \\frac{\\partial V(t_f^+)}{\\partial w_k} = \\frac{\\partial V_{\\mathrm{r}}}{\\partial w_k} = 0 $$\nsince $V_{\\mathrm{r}}$ is a fixed parameter. Therefore, at each spike time, the sensitivity $S_k(t)$ is reset to $0$. This acts as a stabilizing mechanism. The input $R x_k(t)$ is a sum of decaying exponentials and is bounded. The ODE for $S_k(t)$ is stable and is driven by a bounded input. The periodic resets to $0$ prevent $S_k(t)$ from growing without bound. Thus, $S_k(t)$ is a bounded function of time.\n\nThe integral $\\int_{0}^{T} S_k(t)\\, dt$ is therefore finite and well-defined. The loss gradient for the voltage-based readout is:\n$$ \\frac{\\partial L}{\\partial w_k} = (r_{\\mathrm{v}} - r^{\\ast}) \\int_{0}^{T} S_k(t)\\, dt $$\nThis gradient is continuous and non-zero in general, making it suitable for standard gradient-based optimization methods.\n\n### Evaluation of Options\n\n**A) Under the exact spiking nonlinearity, $\\frac{\\partial r_{\\mathrm{sc}}}{\\partial w_k} = 0$ for all perturbations $\\delta w$ that do not change the number of threshold crossings within $[0, T]$; therefore $\\frac{\\partial L}{\\partial w_k}$ for the spike-count readout vanishes almost everywhere in weight space, impeding standard gradient descent without additional techniques.**\n\nThis statement accurately reflects the derivation for the spike-count readout. The derivative of the integer-valued spike count is zero almost everywhere. Consequently, the loss gradient is also zero almost everywhere, which means standard gradient descent algorithms will fail to find a useful learning signal. To overcome this, additional techniques like surrogate gradients are required.\n**Verdict: Correct.**\n\n**B) For the voltage-based readout, $\\frac{\\partial L}{\\partial w_k} = \\left(r_{\\mathrm{v}} - r^{\\ast}\\right) \\int_{0}^{T} \\frac{\\partial V(t)}{\\partial w_k}\\, dt$, where $\\frac{\\partial V(t)}{\\partial w_k}$ solves the linear sensitivity equation $\\tau_{\\mathrm{m}} \\frac{d}{dt}\\left(\\frac{\\partial V(t)}{\\partial w_k}\\right) = -\\frac{\\partial V(t)}{\\partial w_k} + R\\, x_k(t)$ on each inter-spike interval with appropriate continuity across resets when spike times are fixed; hence the gradient exists, is bounded, and scales with the membrane and synaptic time constants, favoring stable gradient-based training.**\n\nThis statement correctly identifies the form of the gradient and the linear sensitivity equation. The phrase \"appropriate continuity across resets\" is slightly imprecise—the sensitivity $\\frac{\\partial V(t)}{\\partial w_k}$ is itself discontinuous, being reset to $0$. However, this reset condition is the \"appropriate\" way to handle the dynamics under the fixed spike time assumption, allowing the piecewise integration to proceed. The conclusion that the gradient exists, is bounded (due to the stable dynamics and resets), and is suitable for gradient-based training is correct. The scaling with time constants follows from the form of the ODEs.\n**Verdict: Correct.**\n\n**C) If the spike-generation nonlinearity is replaced by a differentiable surrogate $\\sigma\\!\\left(V(t) - V_{\\mathrm{th}}\\right)$ with nonzero slope near threshold, then the spike-count gradient becomes identical to the voltage-based gradient up to a constant multiplicative factor, implying both readouts have equivalent gradient stability.**\n\nIf we use a surrogate approach where the \"spike count\" is modeled as $r'_{\\mathrm{sc}} = \\int_0^T \\sigma(V(t)-V_{\\mathrm{th}}) dt$, its derivative with respect to $w_k$ is $\\frac{\\partial r'_{\\mathrm{sc}}}{\\partial w_k} = \\int_0^T \\sigma'(V(t)-V_{\\mathrm{th}}) \\frac{\\partial V(t)}{\\partial w_k} dt$. The derivative of the voltage-based readout is $\\frac{\\partial r_{\\mathrm{v}}}{\\partial w_k} = \\int_0^T \\frac{\\partial V(t)}{\\partial w_k} dt$. The term $\\sigma'(V(t)-V_{\\mathrm{th}})$ is a function of time because it depends on $V(t)$. It acts as a time-varying weighting factor inside the integral. Therefore, the two gradients are not identical up to a constant factor. The statement is mathematically false.\n**Verdict: Incorrect.**\n\n**D) Voltage-based readouts inevitably suffer from exploding gradients due to reset-induced discontinuities in $V(t)$, making $\\frac{\\partial V(t)}{\\partial w_k}$ unbounded and rendering gradient descent unstable.**\n\nThis is the opposite of the truth. While the voltage $V(t)$ is discontinuous, its sensitivity $\\frac{\\partial V(t)}{\\partial w_k}$ is not unbounded. As shown in our derivation, the reset mechanism, when applied to the sensitivity dynamics under the fixed spike time assumption, forces the sensitivity to $0$ at each spike. This periodic reset is a stabilizing feature that prevents the sensitivity from exploding.\n**Verdict: Incorrect.**\n\n**E) For spike-count readouts, unbiased gradient estimates can be obtained by infinitesimal finite differences without surrogate smoothing, because the limit of the difference quotient equals the true nonzero derivative almost everywhere.**\n\nThis statement contains a fundamental error. The limit of the difference quotient, which defines the derivative, is zero almost everywhere for a step function like the spike count. It is not \"nonzero almost everywhere.\" While a finite difference calculation would yield an unbiased estimate of this derivative, the estimate would be $0$ almost everywhere, providing no information for learning. The problem is not the estimation method but the nature of the true gradient itself.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{AB}$$"
        },
        {
            "introduction": "Having established the challenge of non-differentiability, we now turn to a powerful solution: the surrogate gradient method combined with a spike-timing-based loss function. This practice  guides you through the derivation of a learning rule for the van Rossum loss, a metric that measures the distance between filtered spike trains. You will apply the chain rule and the surrogate gradient approximation to arrive at a biologically plausible three-factor learning rule, revealing the mathematical machinery behind state-of-the-art supervised learning in SNNs.",
            "id": "4061662",
            "problem": "Consider a single-output neuron in a Spiking Neural Network (SNN). The neuron is modeled by the Spike Response Model (SRM) in discrete time with uniform sampling interval $\\Delta t$. Let the presynaptic spike train be $\\{S^{\\mathrm{pre}}_{t}\\}_{t=1}^{T}$, where $S^{\\mathrm{pre}}_{t} \\in \\{0,1\\}$ indicates a spike at time index $t$. The neuron's membrane potential is given by a linear synaptic response\n$$V_{t} = w\\,(\\epsilon * S^{\\mathrm{pre}})_{t},$$\nwhere $w \\in \\mathbb{R}$ is a synaptic weight, $(\\epsilon * S^{\\mathrm{pre}})_{t}$ denotes the discrete-time causal convolution $(\\epsilon * S^{\\mathrm{pre}})_{t} = \\sum_{j=0}^{t-1} \\epsilon_{j}\\,S^{\\mathrm{pre}}_{t-j}$, and $\\{\\epsilon_{j}\\}_{j \\ge 0}$ is a fixed synaptic kernel sequence. The neuron emits an output spike train $\\{S_{t}\\}_{t=1}^{T}$ according to the threshold relation $S_{t} = H(V_{t} - V_{\\theta})$, where $H(\\cdot)$ is the Heaviside step function and $V_{\\theta}$ is a fixed threshold. For supervised learning, a target spike train $\\{S^{\\mathrm{tar}}_{t}\\}_{t=1}^{T}$ is provided. The loss is the van Rossum loss defined by\n$$L = \\frac{1}{2} \\sum_{t=1}^{T} \\Big( (\\kappa * S)_{t} - (\\kappa * S^{\\mathrm{tar}})_{t} \\Big)^{2},$$\nwhere $(\\kappa * S)_{t} = \\sum_{j=0}^{t-1} \\kappa_{j}\\,S_{t-j}$ is a causal convolution with a fixed van Rossum kernel $\\{\\kappa_{j}\\}_{j \\ge 0}$, for example the discrete exponential kernel $\\kappa_{j} = \\frac{\\Delta t}{\\tau_{r}} \\exp\\!\\big(-\\frac{j\\,\\Delta t}{\\tau_{r}}\\big)$ for $j \\ge 0$ with time constant $\\tau_{r} > 0$. To enable gradient-based optimization, use a surrogate gradient for the spike nonlinearity: replace the ill-defined derivative $\\partial S_{t}/\\partial V_{t}$ by a prescribed surrogate function $\\phi(V_{t})$ that is nonzero in a neighborhood of $V_{\\theta}$ and zero otherwise.\n\nStarting only from the definitions of causal discrete convolution, the chain rule, and the above loss and neuron model, derive an explicit closed-form analytic expression for the gradient $\\partial L / \\partial w$ in terms of the sequences $\\{\\kappa_{j}\\}$, $\\{\\epsilon_{j}\\}$, $\\{S_{t}\\}$, $\\{S^{\\mathrm{tar}}_{t}\\}$, and $\\{S^{\\mathrm{pre}}_{t}\\}$. Your final expression must show the explicit dependence on a filtered error signal that arises from the van Rossum loss and the causal convolution structure. Express the final answer as a single analytic expression. Do not provide numerical values.",
            "solution": "The problem asks for the derivation of the gradient of the van Rossum loss function, $L$, with respect to a synaptic weight, $w$, for a neuron described by the Spike Response Model (SRM). The solution requires a rigorous application of the chain rule of calculus in the context of discrete-time signals and convolutions, incorporating the concept of a surrogate gradient for the non-differentiable spiking mechanism.\n\nLet us begin by restating the core definitions provided:\nThe membrane potential at time step $t$ is:\n$$\nV_{t} = w\\,(\\epsilon * S^{\\mathrm{pre}})_{t} = w \\sum_{j=0}^{t-1} \\epsilon_{j}\\,S^{\\mathrm{pre}}_{t-j}\n$$\nThe output spike at time step $t$ is generated by:\n$$\nS_{t} = H(V_{t} - V_{\\theta})\n$$\nwhere $H(\\cdot)$ is the Heaviside step function. The derivative of this function is ill-defined. As instructed, we use a surrogate gradient by making the substitution:\n$$\n\\frac{\\partial S_{t}}{\\partial V_{t}} \\approx \\phi(V_{t})\n$$\nwhere $\\phi(\\cdot)$ is a suitable function that approximates the derivative, for instance, a narrow pulse centered at the threshold.\n\nThe loss function is given by:\n$$\nL = \\frac{1}{2} \\sum_{k=1}^{T} \\Big( (\\kappa * S)_{k} - (\\kappa * S^{\\mathrm{tar}})_{k} \\Big)^{2}\n$$\nFor convenience, let us define the filtered spike trains as $s_{k} = (\\kappa * S)_{k}$ and $s^{\\mathrm{tar}}_{k} = (\\kappa * S^{\\mathrm{tar}})_{k}$. The loss can then be written as:\n$$\nL = \\frac{1}{2} \\sum_{k=1}^{T} (s_{k} - s^{\\mathrm{tar}}_{k})^{2}\n$$\nOur objective is to compute the gradient $\\frac{\\partial L}{\\partial w}$. The weight $w$ influences the membrane potentials $\\{V_{t}\\}$, which in turn determine the output spikes $\\{S_{t}\\}$, which are then filtered to produce $\\{s_{k}\\}$ that appear in the loss $L$. The chain of dependencies is $w \\rightarrow \\{V_{t}\\} \\rightarrow \\{S_{t}\\} \\rightarrow \\{s_{k}\\} \\rightarrow L$. We apply the multivariate chain rule, summing the influence of $w$ on $L$ through each spike $S_{t}$:\n$$\n\\frac{\\partial L}{\\partial w} = \\sum_{t=1}^{T} \\frac{\\partial L}{\\partial S_{t}} \\frac{\\partial S_{t}}{\\partial w}\n$$\nThis decomposition separates the problem into two parts:\n1.  Computing the derivative of a spike $S_{t}$ with respect to the weight $w$, which involves the neuron's dynamics.\n2.  Computing the derivative of the loss $L$ with respect to a spike $S_{t}$, which involves the structure of the loss function.\n\nLet us address the first part, $\\frac{\\partial S_{t}}{\\partial w}$. Using the chain rule for the neuron dynamics:\n$$\n\\frac{\\partial S_{t}}{\\partial w} = \\frac{\\partial S_{t}}{\\partial V_{t}} \\frac{\\partial V_{t}}{\\partial w}\n$$\nWe substitute the surrogate gradient for the first term: $\\frac{\\partial S_{t}}{\\partial V_{t}} \\approx \\phi(V_{t})$. For the second term, we differentiate the expression for $V_{t}$ with respect to $w$:\n$$\n\\frac{\\partial V_{t}}{\\partial w} = \\frac{\\partial}{\\partial w} \\left( w\\,(\\epsilon * S^{\\mathrm{pre}})_{t} \\right) = (\\epsilon * S^{\\mathrm{pre}})_{t}\n$$\nCombining these results gives the derivative of the spike with respect to the weight:\n$$\n\\frac{\\partial S_{t}}{\\partial w} = \\phi(V_{t}) \\, (\\epsilon * S^{\\mathrm{pre}})_{t}\n$$\nThis term couples the postsynaptic neuron's state (via $\\phi(V_{t})$) with the presynaptic input activity (via the filtered presynaptic spike train $(\\epsilon * S^{\\mathrm{pre}})_{t}$).\n\nNow, we address the second part, $\\frac{\\partial L}{\\partial S_{t}}$. The loss $L$ depends on $S_{t}$ through the filtered spike train $s_{k} = (\\kappa*S)_{k}$. We apply the chain rule again:\n$$\n\\frac{\\partial L}{\\partial S_{t}} = \\sum_{k=1}^{T} \\frac{\\partial L}{\\partial s_{k}} \\frac{\\partial s_{k}}{\\partial S_{t}}\n$$\nThe derivative of $L$ with respect to $s_{k}$ is straightforward:\n$$\n\\frac{\\partial L}{\\partial s_{k}} = \\frac{\\partial}{\\partial s_{k}} \\left[ \\frac{1}{2} \\sum_{m=1}^{T} (s_{m} - s^{\\mathrm{tar}}_{m})^{2} \\right] = s_{k} - s^{\\mathrm{tar}}_{k}\n$$\nNext, we compute the derivative of the convolution $s_{k}$ with respect to a single spike $S_{t}$:\n$$\ns_{k} = (\\kappa * S)_{k} = \\sum_{j=0}^{k-1} \\kappa_{j}\\,S_{k-j}\n$$\nThe derivative $\\frac{\\partial s_{k}}{\\partial S_{t}}$ is non-zero only if one of the terms in the sum contains $S_{t}$. This occurs when $k-j=t$, or $j=k-t$. For this to be a valid index in the sum, we must have $0 \\le k-t \\le k-1$, which simplifies to $t \\ge 1$ and $k \\ge t$. If this condition is met, the derivative is the coefficient of $S_{t}$, which is $\\kappa_{k-t}$.\n$$\n\\frac{\\partial s_{k}}{\\partial S_{t}} =\n\\begin{cases}\n\\kappa_{k-t} & \\text{if } k \\ge t \\\\\n0 & \\text{if } k < t\n\\end{cases}\n$$\nSubstituting these two derivatives back, we find the influence of a spike $S_{t}$ on the total loss:\n$$\n\\frac{\\partial L}{\\partial S_{t}} = \\sum_{k=t}^{T} (s_{k} - s^{\\mathrm{tar}}_{k}) \\kappa_{k-t} = \\sum_{k=t}^{T} \\Big( (\\kappa * S)_{k} - (\\kappa * S^{\\mathrm{tar}})_{k} \\Big) \\kappa_{k-t}\n$$\nThis term represents an error signal that is filtered and propagated backward in time from the future ($k \\ge t$) to the present ($t$). Let us denote this \"filtered error signal\" by $\\delta_{t}$:\n$$\n\\delta_{t} = \\sum_{k=t}^{T} \\kappa_{k-t} \\Big( (\\kappa * (S - S^{\\mathrm{tar}}))_{k} \\Big)\n$$\nFinally, we assemble the complete gradient $\\frac{\\partial L}{\\partial w}$ by substituting our results for $\\frac{\\partial S_{t}}{\\partial w}$ and $\\frac{\\partial L}{\\partial S_{t}}$ into the original sum:\n$$\n\\frac{\\partial L}{\\partial w} = \\sum_{t=1}^{T} \\delta_{t} \\frac{\\partial S_{t}}{\\partial w} = \\sum_{t=1}^{T} \\delta_{t} \\, \\phi(V_{t}) \\, (\\epsilon * S^{\\mathrm{pre}})_{t}\n$$\nTo obtain the final explicit expression as required, we substitute the full definitions for $\\delta_t$, $V_t$, and the convolutions. The filtered presynaptic input is $(\\epsilon * S^{\\mathrm{pre}})_{t} = \\sum_{j=0}^{t-1} \\epsilon_{j}\\,S^{\\mathrm{pre}}_{t-j}$. The membrane potential is $V_{t} = w \\sum_{j=0}^{t-1} \\epsilon_{j}\\,S^{\\mathrm{pre}}_{t-j}$. The filtered error signal contains the convolution difference $(\\kappa * S)_{k} - (\\kappa * S^{\\mathrm{tar}})_{k} = \\sum_{l=0}^{k-1} \\kappa_l (S_{k-l} - S^{\\mathrm{tar}}_{k-l})$.\n\nCombining everything yields the final analytic expression for the gradient:\n$$\n\\frac{\\partial L}{\\partial w} = \\sum_{t=1}^{T} \\phi\\left(w \\sum_{j=0}^{t-1} \\epsilon_{j}\\,S^{\\mathrm{pre}}_{t-j}\\right) \\left(\\sum_{j=0}^{t-1} \\epsilon_{j}\\,S^{\\mathrm{pre}}_{t-j}\\right) \\left( \\sum_{k=t}^{T} \\kappa_{k-t} \\left[ \\sum_{l=0}^{k-1} \\kappa_{l}(S_{k-l} - S^{\\mathrm{tar}}_{k-l}) \\right] \\right)\n$$\nThis expression conforms to the three-factor learning rule structure often found in neuroscience, where the weight update is proportional to the product of a presynaptic trace, a postsynaptic state-dependent term, and a future-dependent error signal.",
            "answer": "$$\n\\boxed{\\sum_{t=1}^{T} \\phi\\left(w \\sum_{j=0}^{t-1} \\epsilon_j S^{\\mathrm{pre}}_{t-j}\\right) \\left(\\sum_{j=0}^{t-1} \\epsilon_j S^{\\mathrm{pre}}_{t-j}\\right) \\left( \\sum_{k=t}^{T} \\kappa_{k-t} \\left[ \\sum_{l=0}^{k-1} \\kappa_l (S_{k-l} - S^{\\mathrm{tar}}_{k-l}) \\right] \\right)}\n$$"
        },
        {
            "introduction": "Deriving a learning rule is only the first step; implementing it efficiently is the next. Different algorithms for training SNNs, while mathematically related, can have vastly different computational and memory footprints. This exercise  asks you to perform a formal complexity analysis of two cornerstone algorithms: Backpropagation Through Time (BPTT) and Eligibility Propagation (e-prop). By quantifying how their memory and compute requirements scale with network size and simulation time, you will uncover the fundamental trade-offs that guide the design of large-scale neuromorphic systems.",
            "id": "4061601",
            "problem": "Consider a fully connected recurrent spiking neural network (SNN) with $N$ leaky integrate-and-fire neurons and discrete-time dynamics over $T$ steps. There is a synapse from every neuron to every neuron (including or excluding self-connections does not affect leading-order scaling), so the number of trainable synaptic weights is $M = N^{2}$. Assume that the per-synapse and per-neuron forward computations at each time step require a constant number of floating-point operations that does not depend on $N$ or $T$, and that storing any scalar state variable requires a constant number of machine words, independent of $N$ and $T$. Training uses supervised learning with a scalar loss that depends on network activity over time.\n\nTwo training algorithms are used:\n\n- Backpropagation Through Time (BPTT): Backpropagation Through Time (BPTT) stores the forward-pass neuron states needed to compute exact gradients via a reverse-time pass. Assume that BPTT does not maintain any per-synapse eligibility traces during the forward pass.\n\n- Eligibility Propagation (e-prop): Eligibility propagation (e-prop) updates gradients online using per-synapse eligibility traces that evolve forward in time. Assume that e-prop does not store past neuron states beyond what is needed to advance to the next time step.\n\nAdopt the following conventions to make the accounting unambiguous:\n\n- Count the peak algorithm-specific working memory as the additional memory beyond the storage of trainable parameters and their accumulated gradients. Thus, do not include the $M$ trainable weights, any optimizer states directly tied to those weights, or the final gradient tensors in the peak memory count; only include the extra temporal or per-synapse state that is specific to the algorithm’s mechanics.\n\n- Count the total arithmetic operations over the entire training pass (one forward and, where applicable, one backward sweep) as the compute complexity. Treat the per-synapse and per-neuron operation counts per time step as constants independent of $N$ and $T$.\n\nUnder these assumptions, derive the asymptotic scaling, in terms of $N$ and $T$, of the following four quantities:\n\n$1.$ Peak algorithm-specific working memory of BPTT.\n\n$2.$ Peak algorithm-specific working memory of e-prop.\n\n$3.$ Total arithmetic operation count of BPTT over the $T$-step sequence.\n\n$4.$ Total arithmetic operation count of e-prop over the $T$-step sequence.\n\nProvide the final answer as a single row matrix containing, in order, the four asymptotic expressions as functions of $N$ and $T$ using Big-O notation. Ignore constant factors and lower-order terms. No numerical rounding is required. Express the final result in exact symbolic form.",
            "solution": "The problem requires the derivation of the asymptotic scaling for peak working memory and total computational complexity for two supervised learning algorithms in a fully connected recurrent spiking neural network (SNN): Backpropagation Through Time (BPTT) and Eligibility Propagation (e-prop). The network consists of $N$ neurons and runs for $T$ discrete time steps. The number of synapses is $M = N^2$.\n\nLet us define the scope of the analysis based on the provided assumptions:\n- The network is fully connected, so there are $M = O(N^2)$ synaptic weights.\n- The arithmetic operations for updating a single neuron's state or a single synapse's contribution at each time step are constant, i.e., $O(1)$.\n- The memory required to store any single scalar state variable (e.g., membrane potential, eligibility trace value) is constant, i.e., $O(1)$.\n- \"Algorithm-specific working memory\" excludes the storage for the $M$ trainable weights and their accumulated gradients.\n- \"Total arithmetic operations\" covers the entire training pass (forward and backward, if applicable).\n\nWe will derive the four requested quantities in order.\n\n$1.$ **Peak algorithm-specific working memory of BPTT**\n\nThe BPTT algorithm functions in two passes: a forward pass and a backward pass. To compute the exact gradients of the loss function with respect to the network's parameters and states at a given time step $t$, the backward pass requires access to the neuron states computed during the forward pass at that same time step $t$ and potentially $t+1$. Therefore, the algorithm must store the history of neuron states throughout the forward pass.\n\nThe problem specifies that BPTT \"stores the forward-pass neuron states\". At each time step $t \\in \\{1, 2, ..., T\\}$, the state of each of the $N$ neurons must be saved. The state of a neuron (e.g., its membrane potential, spike output) can be represented by a constant number of scalar variables. Per the problem's assumption, storing these requires $O(1)$ memory per neuron.\n\n- Memory to store states for all $N$ neurons at a single time step: $N \\times O(1) = O(N)$.\n- To perform the full backward pass from $t=T$ to $t=1$, the states from all $T$ time steps must be available. The peak memory usage occurs at the end of the forward pass (at time $T$), when the entire history has been recorded.\n- Total memory required: (Number of time steps) $\\times$ (Memory per time step) $= T \\times O(N) = O(NT)$.\n\nThis memory is algorithm-specific as it is used to bridge the forward and backward passes, and it is distinct from the memory for parameters or final gradients. Thus, the peak algorithm-specific working memory for BPTT scales as $O(NT)$.\n\n$2.$ **Peak algorithm-specific working memory of e-prop**\n\nThe e-prop algorithm is designed to compute approximate gradients online, avoiding the need for a full backward pass through time. It achieves this by maintaining a \"per-synapse eligibility trace\". This trace, for each synapse, keeps a running track of the causal link between a synaptic weight and the eventual loss. The problem states that e-prop \"updates gradients online using per-synapse eligibility traces\" and \"does not store past neuron states beyond what is needed to advance to the next time step\".\n\nThe dominant algorithm-specific memory cost for e-prop is the storage of these eligibility traces.\n- Number of synapses in the network: $M = N^2$.\n- Each synapse requires an eligibility trace, which is a scalar or a small vector of constant size. The memory to store one trace is therefore $O(1)$.\n- Total memory for all eligibility traces: (Number of synapses) $\\times$ (Memory per trace) $= M \\times O(1) = O(N^2)$.\n\nSince e-prop is an online algorithm, these traces are updated at each time step, but the total number of traces remains constant throughout the process. The memory requirement does not grow with the number of time steps $T$. Therefore, the peak algorithm-specific working memory for e-prop scales as $O(N^2)$.\n\n$3.$ **Total arithmetic operation count of BPTT**\n\nThe total computation for BPTT is the sum of the operations in the forward pass and the backward pass.\n\n- **Forward Pass:** At each time step $t \\in \\{1, 2, ..., T\\}$, the state of each of the $N$ neurons is updated. This update depends on the inputs received from all other neurons.\n    - Each of the $M = N^2$ synapses contributes to a postsynaptic neuron's state. The computation per synapse is $O(1)$. Total synaptic computation per time step: $O(N^2)$.\n    - Each of the $N$ neurons also undergoes an internal state update (e.g., membrane potential decay), which is an $O(1)$ operation per neuron. Total neuron-specific computation per time step: $O(N)$.\n    - Total computation per time step: $O(N^2) + O(N) = O(N^2)$.\n    - Total forward pass computation over $T$ steps: $T \\times O(N^2) = O(N^2 T)$.\n\n- **Backward Pass:** The backward pass computes gradients by propagating error signals backward through the unrolled computation graph, from $t=T$ down to $t=1$. The structure of the computation graph for the backward pass is symmetric to the forward pass.\n    - At each time step $t$, the algorithm computes the gradient of the loss with respect to the neuron states and weights. This involves backpropagating errors across all $M = N^2$ synaptic connections.\n    - The computational cost per time step in the backward pass is also dominated by synaptic calculations, resulting in $O(N^2)$ operations.\n    - Total backward pass computation over $T$ steps: $T \\times O(N^2) = O(N^2 T)$.\n\n- **Total BPTT Computation:** (Forward Pass) + (Backward Pass) = $O(N^2 T) + O(N^2 T) = O(N^2 T)$.\n\n$4.$ **Total arithmetic operation count of e-prop**\n\nE-prop computes gradients in a single forward pass. At each time step, it must perform the standard forward dynamics simulation and additionally update its internal data structures for gradient estimation.\n\n- At each time step $t \\in \\{1, 2, ..., T\\}$:\n    - **Forward Dynamics:** This is identical to the BPTT forward pass. It involves computing the effect of $N^2$ synapses and updating $N$ neurons. The complexity is $O(N^2)$.\n    - **Eligibility Trace Update:** The algorithm must update the eligibility trace for each of the $M = N^2$ synapses. The update rule for a single trace is an $O(1)$ operation, depending on local pre- and post-synaptic quantities. The total computational cost for updating all traces is $O(N^2)$.\n    - **Gradient Accumulation:** Based on the eligibility traces and an error signal, the gradient for each of the $M = N^2$ weights is updated. This is also an $O(N^2)$ operation per time step.\n- **Total computation per time step:** (Forward Dynamics) + (Trace Update) + (Gradient Accumulation) = $O(N^2) + O(N^2) + O(N^2) = O(N^2)$.\n- **Total e-prop Computation:** The operations are repeated for $T$ time steps.\n    - Total computation: $T \\times (\\text{per-step computation}) = T \\times O(N^2) = O(N^2 T)$.\n\nIn summary, the four requested quantities have the following asymptotic scaling:\n1.  BPTT Memory: $O(NT)$\n2.  e-prop Memory: $O(N^2)$\n3.  BPTT Compute: $O(N^2 T)$\n4.  e-prop Compute: $O(N^2 T)$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nO(NT) & O(N^2) & O(N^2 T) & O(N^2 T)\n\\end{pmatrix}\n}\n$$"
        }
    ]
}