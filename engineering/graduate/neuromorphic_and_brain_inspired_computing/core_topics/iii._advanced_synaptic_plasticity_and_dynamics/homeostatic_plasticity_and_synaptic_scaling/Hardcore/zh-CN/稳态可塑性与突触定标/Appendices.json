{
    "hands_on_practices": [
        {
            "introduction": "我们从突触缩放最基本的计算开始我们的实践探索。这个练习  将指导你使用一个简单的线性模型，推导出将神经元放电率调整到特定目标所需的乘法因子。掌握这一核心原理是理解稳态机制如何维持网络稳定性的第一步。",
            "id": "4047498",
            "problem": "考虑一个神经形态系统中的单个神经元，它通过突触缩放实现稳态可塑性。该神经元接收来自$N$个突触前通道的输入，其平均输入速率为$\\bar{x}_{i}$，突触权重为$w_{i}$。在一个缓慢的稳态时间尺度上，其平均发放速率由线性速率方程$r=\\sum_{i=1}^{N}w_{i}\\bar{x}_{i}$建模。一个稳态控制器试图通过将所有突触权重乘以一个共同的正因子$\\alpha$来达到目标平均发放速率$r^{*}$，同时保持突触强度的比率。假设在控制器作用的时间尺度上，突触前平均速率$\\bar{x}_{i}$保持不变，并且在该工作区间内，神经元的传递函数可以很好地由一个线性映射来近似。\n\n仅从这些前提出发，推导出一个能够达到目标速率$r^{*}$的缩放因子$\\alpha$的解析表达式。然后，在$N=3$，突触前平均速率$\\bar{x}_{1}=5\\,\\text{Hz}$，$\\bar{x}_{2}=7\\,\\text{Hz}$，$\\bar{x}_{3}=3\\,\\text{Hz}$，突触权重$w_{1}=0.8$，$w_{2}=0.5$，$w_{3}=-0.2$，以及目标平均速率$r^{*}=10\\,\\text{Hz}$的特定情况下，计算$\\alpha$的值。将最终数值答案四舍五入到四位有效数字。最终答案应报告为$\\alpha$的单个值。",
            "solution": "该问题被认为是有效的，因为它科学地基于稳态可塑性的标准模型，具有明确的目标和足够的数据，是一个适定的问题，并以客观、可形式化的语言表述。\n\n神经元的初始平均发放速率，我们可将其表示为$r_{\\text{initial}}$，由以下线性速率方程给出：\n$$r_{\\text{initial}} = \\sum_{i=1}^{N} w_{i} \\bar{x}_{i}$$\n此处，$w_{i}$是初始突触权重，$\\bar{x}_{i}$是平均突触前输入速率。\n\n稳态可塑性通过调整突触权重来达到目标平均发放速率$r^{*}$。指定的机制是通过一个共同的正因子$\\alpha$对所有突触权重进行乘性缩放。因此，新的权重$w'_{i}$由下式给出：\n$$w'_{i} = \\alpha w_{i}$$\n问题陈述这种缩放应导致神经元的平均发放速率变为$r^{*}$。使用带有新权重的相同速率方程，我们得到：\n$$r^{*} = \\sum_{i=1}^{N} w'_{i} \\bar{x}_{i}$$\n将新权重$w'_{i}$的表达式代入此方程：\n$$r^{*} = \\sum_{i=1}^{N} (\\alpha w_{i}) \\bar{x}_{i}$$\n由于缩放因子$\\alpha$是求和中所有项的公共常数，因此可以将其提取出来：\n$$r^{*} = \\alpha \\left( \\sum_{i=1}^{N} w_{i} \\bar{x}_{i} \\right)$$\n括号中的项是初始平均发放速率$r_{\\text{initial}}$。因此，关系式为：\n$$r^{*} = \\alpha \\cdot r_{\\text{initial}}$$\n为了求得所需的缩放因子$\\alpha$，我们可以重排这个方程，假设$r_{\\text{initial}} \\neq 0$：\n$$\\alpha = \\frac{r^{*}}{r_{\\text{initial}}} = \\frac{r^{*}}{\\sum_{i=1}^{N} w_{i} \\bar{x}_{i}}$$\n这就是缩放因子$\\alpha$的通用解析表达式。\n\n现在，我们针对所提供的具体情况计算该表达式。已知条件如下：\n输入数量，$N=3$。\n突触前平均速率：$\\bar{x}_{1}=5\\,\\text{Hz}$，$\\bar{x}_{2}=7\\,\\text{Hz}$，$\\bar{x}_{3}=3\\,\\text{Hz}$。\n初始突触权重：$w_{1}=0.8$，$w_{2}=0.5$，$w_{3}=-0.2$。\n目标平均速率：$r^{*}=10\\,\\text{Hz}$。\n\n首先，我们计算初始发放速率$r_{\\text{initial}}$，它是我们$\\alpha$表达式中的分母：\n$$r_{\\text{initial}} = \\sum_{i=1}^{3} w_{i} \\bar{x}_{i} = w_{1}\\bar{x}_{1} + w_{2}\\bar{x}_{2} + w_{3}\\bar{x}_{3}$$\n代入数值：\n$$r_{\\text{initial}} = (0.8)(5) + (0.5)(7) + (-0.2)(3)$$\n$$r_{\\text{initial}} = 4.0 + 3.5 - 0.6 = 6.9\\,\\text{Hz}$$\n由于$r_{\\text{initial}} = 6.9 \\neq 0$，缩放因子$\\alpha$是良定的。\n\n现在，我们可以使用目标速率$r^{*}=10\\,\\text{Hz}$来计算$\\alpha$：\n$$\\alpha = \\frac{r^{*}}{r_{\\text{initial}}} = \\frac{10}{6.9}$$\n$$\\alpha \\approx 1.44927536...$$\n问题要求将最终数值答案四舍五入到四位有效数字。\n前四位有效数字是$1$、$4$、$4$和$9$。第五位数字是$2$，小于$5$，所以我们向下舍入（即，不改变第四位数字）。\n因此，$\\alpha$的值四舍五入到四位有效数字是$1.449$。",
            "answer": "$$\\boxed{1.449}$$"
        },
        {
            "introduction": "为什么乘法缩放是稳态可塑性的首选机制？这个练习  通过对比乘法更新与加法更新，深入探讨了这一关键问题。你将通过解析证明，只有乘法缩放能够保持突触间的相对强度，这一特性对于维持已学习的信息模式至关重要。",
            "id": "3989724",
            "problem": "考虑一个单一的基于电导的神经元，它从 $N$ 个兴奋性突触接收输入，这些突触由 $i \\in \\{1,\\dots,N\\}$ 索引，具有基线突触权重 $w_i \\ge 0$ 和固定的突触前发放率 $r_i \\ge 0$。假设突触驱动为线性求和，因此平均兴奋性驱动为 $I = \\sum_{i=1}^{N} w_i r_i$。一个稳态机制旨在全局调整所有突触权重，以匹配一个严格为正的目标平均驱动 $I^{\\star}  0$，同时最小化对相对突触效能的干扰。\n\n考虑两种全局更新类别：一种是乘性缩放，即对所有 $i$ 应用一个共同因子 $\\alpha \\in \\mathbb{R}$，使得 $w_i' = \\alpha w_i$；另一种是加性缩放，即对所有 $i$ 应用一个共同偏移量 $\\beta \\in \\mathbb{R}$，使得 $w_i' = w_i + \\beta$。对于这两种更新，都需满足以下期望性质：\n- 非负性：所有调整后的权重必须对所有 $i$ 满足 $w_i' \\ge 0$。\n- 比例保持性：相对效能比必须保持不变，即对于所有 $w_j  0$ 的 $i,j$，都有 $w_i'/w_j' = w_i/w_j$。\n\n从上述定义出发，并仅使用突触整合和稳态控制的基本建模假设，完成以下任务：\n1. 对于乘性缩放，推导 $\\alpha$ 同时满足非负性和比例保持性的充分必要条件（对于任意非负的 $\\{w_i\\}$）。对加性缩放重复此推导，得到 $\\beta$ 同时确保非负性和比例保持性的充分必要条件（对于任意非负的 $\\{w_i\\}$）。明确说明你识别出的任何退化情况。\n2. 在每种更新类别下，施加稳态目标 $\\sum_{i=1}^{N} w_i' r_i = I^{\\star}$，并以 $\\{w_i\\}$、$\\{r_i\\}$ 和 $I^{\\star}$ 的形式符号求解参数（乘性情况下的 $\\alpha$ 和加性情况下的 $\\beta$）。清楚说明你推导的解的存在性和唯一性所需的任何正则性条件。\n3. 通过分析每种更新对比例 $w_i'/w_j'$ 的影响，严格证明除了当 $\\beta = 0$ 时，加性缩放会扭曲通用权重配置下的这些比例；描述加性缩放不扭曲比例的任何非通用的、退化的 $\\{w_i\\}$ 集合。\n\n假设 $\\sum_{i=1}^{N} r_i  0$ 和 $\\sum_{i=1}^{N} w_i r_i  0$，因此基线驱动和总突触前驱动都严格为正。请提供你的推理和中间步骤。最后，报告能够达到目标 $I^{\\star}$ 同时满足上述期望性质的唯一乘性缩放因子 $\\alpha$ 的闭式解析表达式。最终答案必须是一个没有单位的单一闭式表达式。",
            "solution": "该问题陈述是计算神经科学领域一个有效的练习，它提出了一个定义明确且具有科学依据的场景，用于分析稳态突触可塑性。它是自洽的，提供了所有必要的定义和假设，以推导出唯一且有意义的解。该问题没有科学不准确、矛盾和歧义之处。因此，我们可以进行形式化求解。\n\n根据问题陈述的要求，分析分为三个部分，最后确定乘性缩放因子的最终表达式。\n\n**第一部分：期望性质的充分必要条件的推导**\n\n我们分析所提出的两种更新类别——乘性缩放和加性缩放——是否满足两个期望性质：非负性（$w_i' \\ge 0$）和比例保持性（对于 $w_j  0$，$w_i'/w_j' = w_i/w_j$）。这些条件必须对任意一组初始非负权重 $\\{w_i\\}$ 成立。\n\n**乘性缩放：**\n更新规则为 $w_i' = \\alpha w_i$，其中 $\\alpha \\in \\mathbb{R}$。\n\n1.  **非负性：** 条件是 $w_i' = \\alpha w_i \\ge 0$。由于这必须对任何初始权重集 $\\{w_i\\}$（其中 $w_i \\ge 0$）成立，我们可以考虑一个非退化情况，即至少有一个权重 $w_k  0$。对于这个权重，条件变为 $\\alpha w_k \\ge 0$，这意味着 $\\alpha \\ge 0$。这是一个必要条件。它也是充分条件，因为如果 $\\alpha \\ge 0$ 且对所有 $i \\in \\{1, \\dots, N\\}$ 都有 $w_i \\ge 0$，那么它们的乘积 $\\alpha w_i$ 保证是非负的。\n    因此，非负性的充分必要条件是 $\\alpha \\ge 0$。\n\n2.  **比例保持性：** 条件是对于任何 $w_j  0$ 的配对 $i, j$，$w_i'/w_j' = w_i/w_j$。代入更新规则，我们有：\n    $$ \\frac{\\alpha w_i}{\\alpha w_j} = \\frac{w_i}{w_j} $$\n    为了使这个方程有意义，且左边的分数是良定义的，分母 $\\alpha w_j$ 不能为零。由于我们考虑 $w_j  0$ 的情况，我们必须有 $\\alpha \\ne 0$。如果 $\\alpha \\ne 0$，我们可以约去分子和分母中的 $\\alpha$，得到恒等式 $w_i/w_j = w_i/w_j$，这总是成立的。因此，当且仅当 $\\alpha \\ne 0$ 时，比例才得以保持。如果所有 $w_i=0$，则出现退化情况，此时对于任何 $\\alpha$，该条件都空泛地满足，但问题假设基线驱动 $\\sum w_i r_i  0$ 是非平凡的，因此如果对应的 $r_i$ 为正，并非所有 $w_i$ 都能为零。\n\n3.  **同时满足的条件：** 要同时满足非负性（$\\alpha \\ge 0$）和比例保持性（$\\alpha \\ne 0$），缩放因子必须满足 $\\alpha  0$。\n\n**加性缩放：**\n更新规则为 $w_i' = w_i + \\beta$，其中 $\\beta \\in \\mathbb{R}$。\n\n1.  **非负性：** 条件是 $w_i' = w_i + \\beta \\ge 0$。这必须对所有 $w_i \\ge 0$ 成立。最严格的情况是对于最小的可能初始权重，即 $w_i = 0$。为了保持非负性，我们必须有 $0 + \\beta \\ge 0$，这意味着 $\\beta \\ge 0$。这是一个必要条件。它也是充分条件，因为如果 $\\beta \\ge 0$ 且 $w_i \\ge 0$，它们的和 $w_i + \\beta$ 总是非负的。\n    因此，非负性的充分必要条件是 $\\beta \\ge 0$。\n\n2.  **比例保持性：** 条件是对于 $w_j  0$，$w_i'/w_j' = w_i/w_j$。\n    $$ \\frac{w_i + \\beta}{w_j + \\beta} = \\frac{w_i}{w_j} $$\n    交叉相乘得到：\n    $$ w_j (w_i + \\beta) = w_i (w_j + \\beta) $$\n    $$ w_i w_j + \\beta w_j = w_i w_j + \\beta w_i $$\n    $$ \\beta w_j = \\beta w_i $$\n    $$ \\beta (w_j - w_i) = 0 $$\n    这个方程必须对任意一组非负权重 $\\{w_i\\}$ 成立。在一个通用配置中，我们可以选择权重 $w_i$ 和 $w_j$ 使得 $w_i \\ne w_j$。为了使方程在这种一般情况下成立，我们必须有 $\\beta = 0$。\n\n3.  **同时满足的条件：** 要同时满足非负性（$\\beta \\ge 0$）和比例保持性（$\\beta = 0$），加性偏移量的唯一可能值是 $\\beta = 0$。这对应于权重不发生改变的平凡更新。在一种退化情况下，即所有初始权重都相同，$w_i = c$ 对所有 $i$ 成立，此时对于任何 $\\beta \\ge 0$ 都能保持比例。在这种特定场景下，$w_j - w_i = 0$，条件 $\\beta(w_j-w_i)=0$ 对任何 $\\beta$ 都满足。\n\n**第二部分：求解缩放参数**\n\n我们现在施加稳态目标 $I' = \\sum_{i=1}^{N} w_i' r_i = I^{\\star}$。\n\n**乘性缩放：**\n目标方程为 $\\sum_{i=1}^{N} (\\alpha w_i) r_i = I^{\\star}$。将常数 $\\alpha$ 提取出来：\n$$ \\alpha \\sum_{i=1}^{N} w_i r_i = I^{\\star} $$\n求和项是基线驱动，$I = \\sum_{i=1}^{N} w_i r_i$。所以，$\\alpha I = I^{\\star}$。\n解出 $\\alpha$：\n$$ \\alpha = \\frac{I^{\\star}}{I} = \\frac{I^{\\star}}{\\sum_{i=1}^{N} w_i r_i} $$\n为了使该解存在且唯一，分母必须非零。问题明确假设基线驱动严格为正，即 $\\sum_{i=1}^{N} w_i r_i  0$。由于目标驱动 $I^{\\star}$ 也严格为正，得到的 $\\alpha$ 将严格为正（$\\alpha  0$）。这与第一部分中为满足两个期望性质而推导出的充分必要条件完全一致。\n\n**加性缩放：**\n目标方程为 $\\sum_{i=1}^{N} (w_i + \\beta) r_i = I^{\\star}$。展开求和：\n$$ \\sum_{i=1}^{N} w_i r_i + \\sum_{i=1}^{N} \\beta r_i = I^{\\star} $$\n$$ I + \\beta \\sum_{i=1}^{N} r_i = I^{\\star} $$\n解出 $\\beta$：\n$$ \\beta = \\frac{I^{\\star} - I}{\\sum_{i=1}^{N} r_i} = \\frac{I^{\\star} - \\sum_{i=1}^{N} w_i r_i}{\\sum_{i=1}^{N} r_i} $$\n为了使该解存在且唯一，分母必须非零。问题明确假设 $\\sum_{i=1}^{N} r_i  0$。因此，$\\beta$ 的唯一解总是存在的。然而，如第一部分所示，加性缩放仅在 $\\beta = 0$ 时才能保持通用权重的比例，这意味着 $I^{\\star} = I$。因此，加性缩放通常无法在不扭曲相对权重结构的情况下达到任意目标 $I^{\\star} \\ne I$。此外，为了非负性，我们需要 $\\beta \\ge 0$，这要求 $I^{\\star} \\ge I$。如果目标驱动低于当前驱动，加性缩放将需要使某些权重变为负值，从而对初始权重较小的突触违反了非负性约束。\n\n**第三部分：加性缩放对比例扭曲的分析**\n\n如第一部分所推导，加性缩放保持比例 $w_i/w_j$ 的条件是 $\\beta(w_j - w_i) = 0$。\n对于一个通用的权重集合 $\\{w_k\\}$，并非所有权重都相等。这意味着至少存在一对索引 $(i, j)$，使得 $w_i \\ne w_j$。对于这样的一对，项 $(w_j - w_i)$ 非零。因此，为了使方程 $\\beta(w_j - w_i) = 0$ 成立，必须有 $\\beta = 0$。\n因此，一个非零的加性位移（$\\beta \\ne 0$）将扭曲任何一对初始权重不同的突触之间的比例。设 $R_{ij} = w_i/w_j$。新的比例是 $R'_{ij} = (w_i+\\beta)/(w_j+\\beta)$。如果我们假设 $\\beta  0$ 且 $w_i  w_j  0$，那么我们可以证明 $R'_{ij}  R_{ij}$。该变换将比例压缩至趋近于 $1$。\n\n唯一一种非通用的、退化的权重集合 $\\{w_i\\}$，使得加性缩放对于任何 $\\beta$ 都能保持所有比例，是所有权重都相等的集合。\n设对所有 $i \\in \\{1, \\dots, N\\}$，有 $w_i = c$，其中常数 $c \\ge 0$。\n那么对于任何 $c0$ 的配对 $(i, j)$，初始比例为 $w_i/w_j = c/c = 1$。\n更新后的权重为 $w_i' = c+\\beta$。新的比例为 $w_i'/w_j' = (c+\\beta)/(c+\\beta) = 1$。\n比例得以保持。如果 $c=0$，所有权重都为零，比例的概念是无定义的。总而言之，加性缩放仅在完全均匀的权重分布这一高度非通用的情况下才是结构保持的。\n\n**结论与最终答案的构建：**\n分析严格证明了，只有使用因子 $\\alpha  0$ 的乘性缩放才能在严格保持权重非负性和所有突触相对效能的情况下，对任意初始权重分布达到稳态目标 $I^\\star$。实现这一目标的唯一缩放因子在第二部分中已推导得出。所要求的最终答案是该因子的闭式表达式。",
            "answer": "$$\n\\boxed{\\frac{I^{\\star}}{\\sum_{i=1}^{N} w_i r_i}}\n$$"
        },
        {
            "introduction": "为了连接理论与应用，我们最后的练习将探讨在物理硬件中实现突触缩放所面临的挑战。这个编程练习  要求你模拟并比较一个理想的缩放算法和一个更实用、对硬件更友好的替代方案，后者涉及周期性更新和量化。通过量化近似误差，你将深入了解构建神经形态系统时固有的工程权衡。",
            "id": "4047537",
            "problem": "考虑一个神经形态系统中稳态突触缩放的离散时间模型，其中神经元通过调节其传出突触权重的总和来维持稳定性。设时间 $t$ 的突触权重向量为 $w_t \\in \\mathbb{R}_{\\ge 0}^N$，加性局部可塑性更新为 $u_t \\in \\mathbb{R}^N$。理想的乘性突触缩放规则在每次加性更新后通过重新缩放来强制执行一个目标总和 $S^*  0$，从而使权重总和等于目标值。\n\n基本定义：\n- 稳态（Homeostasis）是系统在外部扰动下维持稳定内部状态的过程。在此背景下，被控制的量是突触权重的总和。\n- 突触缩放（Synaptic scaling）是一种乘性调整，它通过一个共同的因子重新缩放所有突触，以在保持相对差异的同时实现期望的聚合特性。\n- 时间 $t$ 的理想乘性缩放操作定义为映射 $T(x) = x \\cdot \\dfrac{S^*}{\\sum_i x_i}$，应用于更新后的向量 $x = w_{t-1} + u_t$。\n\n硬件友好的替代模型：\n为了降低硬件中连续重缩放的成本，使用每 $T \\in \\mathbb{N}$ 步进行一次周期性归一化，并结合定点量化和饱和来近似突触缩放。对于每个时间步 $t \\in \\{1, 2, \\dots, M\\}$：\n- 如果 $t$ 不是 $T$ 的倍数，则根据 $w_t^{\\mathrm{sur}} = \\operatorname{clip}\\!\\left(\\operatorname{quant}_\\delta\\!\\left(w_{t-1}^{\\mathrm{sur}} + u_t\\right), [w_{\\min}, w_{\\max}]\\right)$ 进行更新。\n- 如果 $t$ 是 $T$ 的倍数，则根据\n$$\nx_t = w_{t-1}^{\\mathrm{sur}} + u_t, \\quad\nw_t^{\\mathrm{sur}} = \\operatorname{clip}\\!\\left(\\operatorname{quant}_\\delta\\!\\left(x_t \\cdot \\frac{S^*}{\\sum_i x_{t,i}}\\right), [w_{\\min}, w_{\\max}]\\right)\n$$\n进行更新。\n此处，逐元素的定点量化算子为 $\\operatorname{quant}_\\delta(y) = \\delta \\cdot \\operatorname{round}(y/\\delta)$，其中量化步长 $\\delta  0$；$\\operatorname{clip}(y, [w_{\\min}, w_{\\max}])$ 将 $y$ 的每个元素饱和到区间 $[w_{\\min}, w_{\\max}]$ 内。\n\n理想乘性缩放基线：\n在每个时间步 $t \\in \\{1, 2, \\dots, M\\}$，定义\n$$\nx_t^{\\mathrm{ideal}} = w_{t-1}^{\\mathrm{ideal}} + u_t, \\quad\nw_t^{\\mathrm{ideal}} = x_t^{\\mathrm{ideal}} \\cdot \\frac{S^*}{\\sum_i x_{t,i}^{\\mathrm{ideal}}}.\n$$\n\n初始化与更新序列：\n- 将两个轨迹都初始化为 $w_0^{\\mathrm{sur}} = w_0^{\\mathrm{ideal}} = \\left[\\frac{S^*}{N}, \\dots, \\frac{S^*}{N}\\right] \\in \\mathbb{R}^N$。\n- 为了可复现性和科学真实性，让加性更新是确定性的、突触差异化的和有界的：\n$$\nu_t[i] = \\gamma \\cdot \\left(1 + \\frac{i}{N}\\right) \\cdot \\sin\\!\\left(\\frac{2\\pi t}{P} + \\frac{i}{N}\\right) + \\frac{\\gamma}{5} \\cdot \\frac{(-1)^i}{N}, \\quad i \\in \\{0,1,\\dots,N-1\\},\n$$\n其中振幅 $\\gamma \\ge 0$，整数周期 $P \\in \\mathbb{N}$ 的选择使得 $P$ 不是 $T$ 的倍数。\n\n用于量化替代模型相对于理想模型的近似质量的误差度量：\n- 终端分布误差：\n$$\n\\varepsilon_{\\mathrm{dist}} = \\frac{\\left\\|w_M^{\\mathrm{sur}} - w_M^{\\mathrm{ideal}}\\right\\|_2}{\\left\\|w_M^{\\mathrm{ideal}}\\right\\|_2},\n$$\n以小数形式表示。\n- 整个时间范围内的最坏情况归一化总和偏差：\n$$\n\\varepsilon_{\\mathrm{sum}} = \\max_{1 \\le t \\le M} \\frac{\\left|\\sum_i w_t^{\\mathrm{sur}} - S^*\\right|}{S^*},\n$$\n以小数形式表示。\n\n科学真实性约束：\n- 所有权重必须保持非负；替代模型通过使用 $w_{\\min} \\ge 0$ 的裁剪来强制实现非负性。\n- 缩放中的除以零是未定义的；如果 $\\sum_i x_{t,i} \\le 0$，则在该步骤中将缩放因子视为 $1$（不进行缩放）。\n\n您的任务：\n- 实现上述定义的两个轨迹 $w_t^{\\mathrm{ideal}}$ 和 $w_t^{\\mathrm{sur}}$。\n- 为每个测试用例计算 $\\varepsilon_{\\mathrm{dist}}$ 和 $\\varepsilon_{\\mathrm{sum}}$。\n- 生成单行输出，其中包含所有测试用例的结果，形式为用方括号括起来的逗号分隔列表。每个结果必须是一个包含两个浮点数的列表 $[\\varepsilon_{\\mathrm{dist}}, \\varepsilon_{\\mathrm{sum}}]$。\n\n测试套件：\n使用以下参数集，涵盖典型情况、一个与理想缩放非常接近的边界情况、粗糙量化、大归一化周期以及一个零更新的边缘情况。\n\n- 情况 1（典型）：$N = 8$，$M = 200$，$S^* = 1.0$，$T = 5$，$\\delta = 0.001$，$w_{\\min} = 0.0$，$w_{\\max} = 0.5$，$\\gamma = 0.01$，$P = 17$。\n- 情况 2（边界 $T=1$）：$N = 8$，$M = 200$，$S^* = 1.0$，$T = 1$，$\\delta = 0.001$，$w_{\\min} = 0.0$，$w_{\\max} = 0.5$，$\\gamma = 0.01$，$P = 17$。\n- 情况 3（粗糙量化和较大漂移）：$N = 8$，$M = 200$，$S^* = 1.0$，$T = 25$，$\\delta = 0.02$，$w_{\\min} = 0.0$，$w_{\\max} = 0.5$，$\\gamma = 0.02$，$P = 13$。\n- 情况 4（退化的单个突触）：$N = 1$，$M = 200$，$S^* = 1.0$，$T = 10$，$\\delta = 0.005$，$w_{\\min} = 0.0$，$w_{\\max} = 1.0$，$\\gamma = 0.01$，$P = 19$。\n- 情况 5（零更新）：$N = 8$，$M = 200$，$S^* = 1.0$，$T = 10$，$\\delta = 0.001$，$w_{\\min} = 0.0$，$w_{\\max} = 0.5$，$\\gamma = 0.0$，$P = 17$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含结果，形式为用方括号括起来的逗号分隔列表。每个元素本身是一个包含两个小数的列表 $[\\varepsilon_{\\mathrm{dist}}, \\varepsilon_{\\mathrm{sum}}]$，例如 $[[a,b],[c,d],[e,f],[g,h],[i,j]]$。",
            "solution": "问题陈述已经过仔细审查，并被确定为有效。它在科学上基于计算神经科学和神经形态工程的原理，特别是对稳态可塑性的建模。该问题定义明确，所有参数、初始条件、更新规则和目标函数都得到了清晰的界定。这是一个独立的、客观的、可形式化的任务，需要实现一个数值模拟。\n\n解决方案涉及在有限时间范围 $M$ 内模拟两种突触权重动态的离散时间模型：一个具有连续、完美稳态缩放的“理想”模型，以及一个使用硬件友好操作（如周期性归一化和定点算术）来近似此过程的“替代”模型。然后使用两个指定的误差度量来量化替代模型的近似质量。\n\n步骤如下：\n\n首先，我们为两个轨迹建立初始状态。权重向量 $w_t^{\\mathrm{ideal}}$ 和 $w_t^{\\mathrm{sur}}$ 的维度为 $N$。在时间 $t=0$ 时，两者都被初始化为满足目标总和约束的均匀分布：\n$$\nw_0^{\\mathrm{ideal}} = w_0^{\\mathrm{sur}} = \\begin{bmatrix} S^*/N,  S^*/N,  \\dots,  S^*/N \\end{bmatrix}^T\n$$\n其中 $S^*  0$ 是权重的目标总和，$N$ 是突触的数量。\n\n其次，为每个时间步 $t \\in \\{1, 2, \\dots, M\\}$ 计算预设的确定性加性更新序列 $u_t \\in \\mathbb{R}^N$。在时间 $t$ 时更新向量的第 $i$ 个分量由以下公式给出：\n$$\nu_t[i] = \\gamma \\cdot \\left(1 + \\frac{i}{N}\\right) \\cdot \\sin\\!\\left(\\frac{2\\pi t}{P} + \\frac{i}{N}\\right) + \\frac{\\gamma}{5} \\cdot \\frac{(-1)^i}{N}, \\quad \\text{for } i \\in \\{0, 1, \\dots, N-1\\}\n$$\n这些更新代表了局部的赫布或反赫布可塑性，为了计算效率，它们会在整个模拟时间范围内预先计算好。\n\n第三，我们从 $t=1$ 迭代到 $M$，在每个步骤中更新理想模型和替代模型的权重向量。\n\n对于理想模型，在每个时间步 $t$ 的更新规则是：\n1.  应用加性更新：$x_t^{\\mathrm{ideal}} = w_{t-1}^{\\mathrm{ideal}} + u_t$。\n2.  应用乘性缩放以完美恢复目标总和：\n    $$\n    w_t^{\\mathrm{ideal}} = x_t^{\\mathrm{ideal}} \\cdot \\frac{S^*}{\\sum_i x_{t,i}^{\\mathrm{ideal}}}\n    $$\n    在极少数情况下，如果 $\\sum_i x_{t,i}^{\\mathrm{ideal}} \\le 0$，缩放因子将被视为 $1$，因此 $w_t^{\\mathrm{ideal}} = x_t^{\\mathrm{ideal}}$。这确保了数值稳定性。根据其定义，权重总和 $\\sum_i w_t^{\\mathrm{ideal}}$ 始终等于 $S^*$（除非更新后权重的总和为非正数）。\n\n对于替代模型，更新规则取决于当前时间 $t$ 是否安排了归一化步骤：\n1.  首先，应用加性更新：$x_t = w_{t-1}^{\\mathrm{sur}} + u_t$。\n2.  如果 $t$ 是归一化周期 $T$ 的倍数（即 $t \\pmod T = 0$）：\n    权重被重新缩放、量化和裁剪。缩放因子的计算方式与理想模型相同。\n    $$\n    w_t^{\\mathrm{sur}} = \\operatorname{clip}\\!\\left(\\operatorname{quant}_\\delta\\!\\left(x_t \\cdot \\frac{S^*}{\\sum_i x_{t,i}}\\right), [w_{\\min}, w_{\\max}]\\right)\n    $$\n    对于 $\\sum_i x_{t,i} \\le 0$ 的情况，通过将缩放因子设为 $1$ 来处理。\n3.  如果 $t$ 不是 $T$ 的倍数：\n    权重仅被量化和裁剪，没有成本高昂的缩放操作。这允许权重总和偏离目标 $S^*$。\n    $$\n    w_t^{\\mathrm{sur}} = \\operatorname{clip}\\!\\left(\\operatorname{quant}_\\delta\\!\\left(x_t\\right), [w_{\\min}, w_{\\max}]\\right)\n    $$\n辅助函数是逐元素的定点量化算子 $\\operatorname{quant}_\\delta(y) = \\delta \\cdot \\operatorname{round}(y/\\delta)$ 和裁剪算子 $\\operatorname{clip}(y, [w_{\\min}, w_{\\max}])$，后者将每个权重限制在有效范围内。\n\n第四，在 $t=M$ 模拟完成后，我们计算两个误差度量来评估替代模型的性能。\n\n终端分布误差 $\\varepsilon_{\\mathrm{dist}}$ 衡量了两个模型最终权重分布之间的相对欧几里得距离：\n$$\n\\varepsilon_{\\mathrm{dist}} = \\frac{\\left\\|w_M^{\\mathrm{sur}} - w_M^{\\mathrm{ideal}}\\right\\|_2}{\\left\\|w_M^{\\mathrm{ideal}}\\right\\|_2}\n$$\n其中 $\\|\\cdot\\|_2$ 表示L2范数。\n\n最坏情况归一化总和偏差 $\\varepsilon_{\\mathrm{sum}}$ 衡量了在整个模拟过程中，替代模型的总权重和与目标 $S^*$ 的最大偏差：\n$$\n\\varepsilon_{\\mathrm{sum}} = \\max_{1 \\le t \\le M} \\frac{\\left|\\sum_i w_t^{\\mathrm{sur}} - S^*\\right|}{S^*}\n$$\n这需要存储每个时间步 $t$ 的替代权重总和 $\\sum_i w_t^{\\mathrm{sur}}$。\n\n整个过程使用NumPy库进行数值实现，以进行高效的基于数组的计算。对测试套件中提供的五个参数集中的每一个都重复此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function to run simulations for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1 (typical)\n        {'N': 8, 'M': 200, 'S_star': 1.0, 'T': 5, 'delta': 0.001, 'w_min': 0.0, 'w_max': 0.5, 'gamma': 0.01, 'P': 17},\n        # Case 2 (boundary T=1)\n        {'N': 8, 'M': 200, 'S_star': 1.0, 'T': 1, 'delta': 0.001, 'w_min': 0.0, 'w_max': 0.5, 'gamma': 0.01, 'P': 17},\n        # Case 3 (coarse quantization and larger drift)\n        {'N': 8, 'M': 200, 'S_star': 1.0, 'T': 25, 'delta': 0.02, 'w_min': 0.0, 'w_max': 0.5, 'gamma': 0.02, 'P': 13},\n        # Case 4 (degenerate single synapse)\n        {'N': 1, 'M': 200, 'S_star': 1.0, 'T': 10, 'delta': 0.005, 'w_min': 0.0, 'w_max': 1.0, 'gamma': 0.01, 'P': 19},\n        # Case 5 (zero updates)\n        {'N': 8, 'M': 200, 'S_star': 1.0, 'T': 10, 'delta': 0.001, 'w_min': 0.0, 'w_max': 0.5, 'gamma': 0.0, 'P': 17},\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_simulation(**params)\n        results.append(result)\n\n    # Format the final output string\n    # e.g., [[0.1, 0.2], [0.3, 0.4]]\n    # Using f-strings to control precision for consistent output\n    formatted_results = [f\"[{res[0]:.15f}, {res[1]:.15f}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef run_simulation(N, M, S_star, T, delta, w_min, w_max, gamma, P):\n    \"\"\"\n    Runs a single simulation for a given set of parameters.\n    \"\"\"\n\n    # Helper functions\n    def quant(y, d):\n        return d * np.round(y / d)\n\n    def clip(y, y_min, y_max):\n        return np.clip(y, y_min, y_max)\n\n    # Initialize weight vectors\n    w0 = np.full(N, S_star / N, dtype=np.float64)\n    w_ideal = w0.copy()\n    w_sur = w0.copy()\n\n    # Pre-compute additive updates u_t for t=1..M\n    t_vals = np.arange(1, M + 1, dtype=np.float64)[:, np.newaxis]\n    i_vals = np.arange(N, dtype=np.float64)[np.newaxis, :]\n    \n    term1 = gamma * (1 + i_vals / N) * np.sin(2 * np.pi * t_vals / P + i_vals / N)\n    term2 = (gamma / 5.0) * ((-1)**i_vals) / N\n    updates = term1 + term2\n\n    # Array to store sum of surrogate weights at each step\n    sur_sums = np.zeros(M, dtype=np.float64)\n\n    # Main simulation loop\n    for t_idx in range(M):\n        t = t_idx + 1\n        u_t = updates[t_idx]\n\n        # --- Ideal Model Update ---\n        x_ideal = w_ideal + u_t\n        sum_x_ideal = np.sum(x_ideal)\n        \n        scaling_factor_ideal = 1.0\n        if sum_x_ideal > 0:\n            scaling_factor_ideal = S_star / sum_x_ideal\n        w_ideal = x_ideal * scaling_factor_ideal\n        \n        # --- Surrogate Model Update ---\n        x_sur = w_sur + u_t\n        \n        if t % T == 0:\n            # Normalization, quantization, and clipping\n            sum_x_sur = np.sum(x_sur)\n            scaling_factor_sur = 1.0\n            if sum_x_sur > 0:\n                scaling_factor_sur = S_star / sum_x_sur\n            \n            scaled_x = x_sur * scaling_factor_sur\n            w_sur = clip(quant(scaled_x, delta), w_min, w_max)\n        else:\n            # Quantization and clipping only\n            w_sur = clip(quant(x_sur, delta), w_min, w_max)\n        \n        sur_sums[t_idx] = np.sum(w_sur)\n\n    # --- Error Metric Calculation ---\n    \n    # Terminal distribution error (eps_dist)\n    norm_w_ideal = np.linalg.norm(w_ideal)\n    if norm_w_ideal == 0:\n        eps_dist = 0.0 if np.linalg.norm(w_sur) == 0.0 else np.inf\n    else:\n        eps_dist = np.linalg.norm(w_sur - w_ideal) / norm_w_ideal\n\n    # Worst-case normalized sum deviation (eps_sum)\n    # S_star > 0 is a given constraint of the problem.\n    max_abs_deviation = np.max(np.abs(sur_sums - S_star))\n    eps_sum = max_abs_deviation / S_star\n        \n    return [eps_dist, eps_sum]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}