{
    "hands_on_practices": [
        {
            "introduction": "系统的总能耗是其基本操作能耗的累加。本练习将“单次推理能耗”这一抽象指标与构成尖峰神经网络动态功耗主要来源的、可计数的具体突触事件联系起来，帮助您直观地理解网络结构如何直接影响功耗。",
            "id": "4036973",
            "problem": "一个神经形态加速器使用事件驱动的突触操作来执行脉冲神经网络 (SNN) 的推理。请考虑以下测量设置和假设：\n\n- 每个突触事件产生的动态开关能耗为 $E_{\\text{syn}} = 10\\,\\text{pJ/event}$，该值由在标称电压和温度下的片上测量确定。\n- 在一个代表性数据集上，每次推理的平均突触活动为 $5 \\times 10^{6}$ 个事件，该值是在网络收敛后，并使用与精度基准测试相同的输入分布测得的。\n- 您可以忽略漏电（静态）能耗、神经元更新能耗和通信开销；仅考虑由突触事件产生的动态突触能耗。\n\n仅从每个离散开关事件的能量和事件计数的概念这些基本定义出发，推导每次推理的动态突触能耗的表达式并计算其值。用科学记数法表示最终的能量值（单位为焦耳），并将答案四舍五入到三位有效数字。\n\n然后，从第一性原理出发，论证在固定的脉冲统计特性下，神经元的扇入和扇出如何决定突触事件计数，以及在保持功能精度不变的情况下，这种影响如何传播到能耗和延迟指标。您的讨论应基于定义（例如，事件作为边沿触发的突触操作）和资源约束（例如，持续突触处理速率），而不引用任何未提供的捷径公式。",
            "solution": "该问题被验证为具有科学依据、问题明确且客观。所有必要数据均已提供，任务是进行计算并基于第一性原理提供概念性论证，这是一个有效的科学问题。所提出的模型是事件驱动神经形态硬件中能耗的一个标准、简化但物理上合理的表示。\n\n**第一部分：动态突触能耗的推导与计算**\n\n问题要求计算每次推理的动态突触能耗。规定该能量完全来自离散的突触事件。计算一组离散、独立过程总能量的基本原理是叠加原理。总能量是每个独立过程能量的总和。\n\n设 $E_{\\text{total}}$ 为每次推理的总动态突触能耗。\n设 $N_{\\text{events}}$ 为每次推理的突触事件总数。\n设 $E_{\\text{event}}$ 为单个突触事件所消耗的能量。\n\n假设每个突触事件的能耗相同，则总能量是事件数量与单位事件能量的乘积。\n$$E_{\\text{total}} = N_{\\text{events}} \\times E_{\\text{event}}$$\n\n根据问题陈述，我们已知：\n每次推理的平均突触活动，即事件数量：\n$$N_{\\text{events}} = 5 \\times 10^{6} \\text{ events}$$\n每个突触事件的动态开关能耗：\n$$E_{\\text{event}} = E_{\\text{syn}} = 10 \\text{ pJ/event}$$\n\n我们必须首先将单位事件的能量转换成国际单位制（SI）的基本单位焦耳 ($J$)。前缀“皮”（p）对应于因子 $10^{-12}$。\n$$E_{\\text{syn}} = 10 \\times 10^{-12} \\frac{\\text{J}}{\\text{event}}$$\n\n现在，我们可以将给定值代入我们推导出的总能量表达式中：\n$$E_{\\text{total}} = (5 \\times 10^{6} \\text{ events}) \\times \\left(10 \\times 10^{-12} \\frac{\\text{J}}{\\text{event}}\\right)$$\n\n进行乘法运算：\n$$E_{\\text{total}} = (5 \\times 10) \\times (10^{6} \\times 10^{-12}) \\text{ J}$$\n$$E_{\\text{total}} = 50 \\times 10^{-6} \\text{ J}$$\n\n为了用标准科学记数法（$a \\times 10^b$，其中 $1 \\le |a|  10$）表示，我们调整尾数和指数：\n$$E_{\\text{total}} = 5.0 \\times 10^{1} \\times 10^{-6} \\text{ J}$$\n$$E_{\\text{total}} = 5.0 \\times 10^{-5} \\text{ J}$$\n\n问题要求答案四舍五入到三位有效数字。\n$$E_{\\text{total}} = 5.00 \\times 10^{-5} \\text{ J}$$\n\n**第二部分：扇入和扇出作用的论证**\n\n我们被要求从第一性原理出发，论证在保持精度不变的情况下，神经元的扇入和扇出如何影响突触事件计数，并进而影响能耗和延迟。\n\n**第一性原理和定义：**\n1.  **脉冲神经网络 (SNN)** 由通过突触连接的神经元组成。\n2.  **脉冲** 是时间上的一个离散事件，代表来自突触前神经元的信号。\n3.  **突触事件** 是由一个突触前脉冲到达突触时触发的基本操作。此操作涉及检索突触权重并更新突触后神经元的状态。在一次推理过程中，此类事件的总数我们记为突触事件计数 $S$。\n4.  一个神经元的 **扇出** ($N_{\\text{out}}$) 是它投射到的突触后神经元的数量。它代表由这单个神经元发出的突触数量。\n5.  一个神经元的 **扇入** ($N_{\\text{in}}$) 是投射到它的突触前神经元的数量。它代表以这单个神经元为目标的突触数量。\n\n**扇出与突触事件计数 ($S$) 之间的关系：**\n考虑一个由索引 $i$ 标记的突触前神经元。当神经元 $i$ 产生一个脉冲时，该脉冲会传播到其所有的下游目标。根据定义，这些目标的数量就是它的扇出 $N_{\\text{out},i}$。因此，来自神经元 $i$ 的一个脉冲会精确地产生 $N_{\\text{out},i}$ 个突触事件。\n\n设 $k_i$ 为在单次推理中神经元 $i$ 发放脉冲的次数。由神经元 $i$ 产生的突触事件总数是 $k_i \\times N_{\\text{out},i}$ 的乘积。整个网络的总突触事件计数 $S$ 是网络中所有神经元产生的事件之和：\n$$S = \\sum_{i \\in \\text{neurons}} k_i \\cdot N_{\\text{out},i}$$\n\n问题陈述我们必须考虑“固定的脉冲统计特性”。这是一个关键约束，意味着在所比较的网络中，发放模式以及因此的数值集合 $\\{k_i\\}$ 保持不变。在此假设下，该方程表明 $S$ 是所有神经元扇出的加权和。如果平均扇出 $\\bar{N}_{\\text{out}}$ 增加，假设脉冲计数的分布保持不变，总突触事件计数 $S$ 将成比例增加。同样的逻辑也适用于扇入，因为网络中所有扇入的总和等于所有扇出的总和（即 $\\sum N_{\\text{in},j} = \\sum N_{\\text{out},i}$），两者都等于突触的总数。因此，对于固定数量的神经元和固定的脉冲统计特性，总突触事件计数 $S$ 与由扇入和扇出表征的平均网络连接度成正比。\n\n**对能耗的传导：**\n如第一部分所述，总动态突触能耗 ($E_{\\text{total}}$) 与总突触事件计数 ($S$) 成正比：\n$$E_{\\text{total}} = S \\times E_{\\text{syn}}$$\n由于我们已经证明 $S$ 与平均扇入/扇出成正比（在给定约束下），因此可以直接得出总能量也与平均扇入/扇出成正比。一个具有更高连接度的网络，在神经活动量相同的情况下，需要更多的突触操作，因此消耗更多的动态能量。\n\n**对延迟的传导：**\n延迟 ($T_{\\text{latency}}$) 是完成推理任务所需的时间。神经形态加速器处理突触事件的能力是有限的，由其最大持续突触处理速率 $R_{\\text{syn}}$ 定义，单位为每秒突触事件数 (SEPS)。该速率是一个硬件资源约束。\n因此，处理总共 $S$ 个突触事件所需的最短时间受此速率的限制：\n$$T_{\\text{latency}} \\ge \\frac{S}{R_{\\text{syn}}}$$\n这个下限代表了计算延迟。由于 $S$ 与平均扇入/扇出成正比，因此最小延迟也与平均扇入/扇出成正比：\n$$T_{\\text{latency}} \\propto S \\propto \\text{average fan-in/fan-out}$$\n因此，增加网络连接度（扇入/扇出）会增加总计算工作量 ($S$)，对于一个具有固定吞吐量 ($R_{\\text{syn}}$) 的处理器来说，这会导致更长的处理时间，即更高的延迟。\n\n**恒定精度的约束：**\n“在保持功能精度不变的情况下”这一条件并非无足轻重。扇入和扇出是网络拓扑的基本属性。改变它们会改变模型。为了保持精度，具有不同连接度的网络可能需要重新训练，这反过来又可能改变学习到的脉冲统计特性 $\\{k_i\\}$。因此，“固定的脉冲统计特性”的假设是一个强理想化，用于隔离连接度对工作负载的直接影响。在这种理想化情景中，如果两个具有不同连接度的网络能够以相同的发放模式达到相同的精度，那么具有更高扇入/扇出的网络将内在地具有更高的突触事件计数，从而导致更大的能耗和延迟。",
            "answer": "$$\\boxed{5.00 \\times 10^{-5}}$$"
        },
        {
            "introduction": "在理解了单个基准指标后，我们必须评估那些指标存在冲突的系统（例如，更低的能耗往往意味着更高的延迟）。本练习引入了“能量-延迟乘积”（$EDP$）这一标准复合指标来量化这种权衡，从而实现对不同软硬件配置的公平比较。",
            "id": "4036901",
            "problem": "一个神经形态脉冲分类器在五种硬件-软件配置下进行评估，索引为 $i=1,2,3,4,5$。对于每种配置 $i$，在相同的测试集上测量了其单次推理能耗 $E_i$（单位：焦耳）、单次推理延迟 $L_i$（单位：秒）和 top-$1$ 分类准确率 $A_i$（以小数表示）。在神经形态和类脑计算领域，标准的基准测试实践使用结合了能耗和延迟的复合指标来捕捉能耗-时间权衡。使用能量-延迟乘积（EDP）的标准定义，从第一性原理出发计算每种配置的 EDP，并确定最小化 EDP 的配置索引 $i$。然后，报告该配置对应的准确率 $A_i$。\n\n测量值如下：\n- 配置 $1$：$E_1=3.2\\times10^{-5}$，$L_1=8.0\\times10^{-3}$，$A_1=0.926$。\n- 配置 $2$：$E_2=2.5\\times10^{-5}$，$L_2=1.2\\times10^{-2}$，$A_2=0.913$。\n- 配置 $3$：$E_3=1.8\\times10^{-5}$，$L_3=9.0\\times10^{-3}$，$A_3=0.901$。\n- 配置 $4$：$E_4=1.6\\times10^{-5}$，$L_4=1.7\\times10^{-2}$，$A_4=0.934$。\n- 配置 $5$：$E_5=1.2\\times10^{-5}$，$L_5=1.1\\times10^{-2}$，$A_5=0.889$。\n\n从能耗和延迟的核心定义出发，论证 EDP 的计算过程，并确保单位的科学一致性。将最终答案表示为一个包含两个条目的行矩阵：最小化配置的索引 $i$ 及其准确率 $A_i$。将报告的准确率四舍五入到四位有效数字，并且最终答案中不包含任何物理单位。",
            "solution": "问题陈述已经过验证，被确定为是合理的。它具有科学依据，问题定义明确，客观，完整，且不包含内部矛盾或不切实际的数据。该任务是计算机体系结构和神经形态工程领域的标准计算。\n\n该问题要求计算一个神经形态脉冲分类器的五种不同硬件-软件配置的能量-延迟乘积（EDP）。目标是找出产生最小 EDP 的配置，并报告其对应的分类准确率。\n\n首先，我们定义所涉及的基本物理量。\n能量，用 $E$ 表示，是系统所做的功或产生的热量。在此背景下，它是神经形态硬件执行单个分类任务（一次推理）所消耗的总能量。其国际单位制（SI）单位是焦耳（$J$）。\n延迟，用 $L$ 表示，是过程从开始到完成之间的时间延迟。在这里，它代表执行单次推理所需的时间。其国际单位制（SI）单位是秒（$s$）。\n\n能量-延迟乘积（EDP）是用于评估计算系统效率的品质因数，它捕捉了性能（低延迟）和能耗之间的权衡。较低的 EDP 表示更高效的设计。从第一性原理出发，给定配置 $i$ 的 EDP 定义为单次操作消耗的能量与该操作的延迟的乘积。\n其公式为：\n$$\n\\text{EDP}_i = E_i \\times L_i\n$$\nEDP 的结果单位是焦耳-秒（$J \\cdot s$）。我们现在将计算给定的五种配置中每一种的 EDP。\n\n给定的数据如下：\n- 配置 $1$：$E_1 = 3.2 \\times 10^{-5} \\, J$，$L_1 = 8.0 \\times 10^{-3} \\, s$，$A_1 = 0.926$。\n- 配置 $2$：$E_2 = 2.5 \\times 10^{-5} \\, J$，$L_2 = 1.2 \\times 10^{-2} \\, s$，$A_2 = 0.913$。\n- 配置 $3$：$E_3 = 1.8 \\times 10^{-5} \\, J$，$L_3 = 9.0 \\times 10^{-3} \\, s$，$A_3 = 0.901$。\n- 配置 $4$：$E_4 = 1.6 \\times 10^{-5} \\, J$，$L_4 = 1.7 \\times 10^{-2} \\, s$，$A_4 = 0.934$。\n- 配置 $5$：$E_5 = 1.2 \\times 10^{-5} \\, J$，$L_5 = 1.1 \\times 10^{-2} \\, s$，$A_5 = 0.889$。\n\n每种配置的 EDP 计算如下：\n\n对于配置 $i=1$：\n$$\n\\text{EDP}_1 = E_1 \\times L_1 = (3.2 \\times 10^{-5}) \\times (8.0 \\times 10^{-3}) = 25.6 \\times 10^{-8} = 2.56 \\times 10^{-7} \\, J \\cdot s\n$$\n\n对于配置 $i=2$：\n$$\n\\text{EDP}_2 = E_2 \\times L_2 = (2.5 \\times 10^{-5}) \\times (1.2 \\times 10^{-2}) = 3.0 \\times 10^{-7} \\, J \\cdot s\n$$\n\n对于配置 $i=3$：\n$$\n\\text{EDP}_3 = E_3 \\times L_3 = (1.8 \\times 10^{-5}) \\times (9.0 \\times 10^{-3}) = 16.2 \\times 10^{-8} = 1.62 \\times 10^{-7} \\, J \\cdot s\n$$\n\n对于配置 $i=4$：\n$$\n\\text{EDP}_4 = E_4 \\times L_4 = (1.6 \\times 10^{-5}) \\times (1.7 \\times 10^{-2}) = 2.72 \\times 10^{-7} \\, J \\cdot s\n$$\n\n对于配置 $i=5$：\n$$\n\\text{EDP}_5 = E_5 \\times L_5 = (1.2 \\times 10^{-5}) \\times (1.1 \\times 10^{-2}) = 1.32 \\times 10^{-7} \\, J \\cdot s\n$$\n\n为了确定最优配置，我们比较计算出的 EDP 值：\n- $\\text{EDP}_1 = 2.56 \\times 10^{-7}$\n- $\\text{EDP}_2 = 3.00 \\times 10^{-7}$\n- $\\text{EDP}_3 = 1.62 \\times 10^{-7}$\n- $\\text{EDP}_4 = 2.72 \\times 10^{-7}$\n- $\\text{EDP}_5 = 1.32 \\times 10^{-7}$\n\n这些值中的最小值是 $\\text{EDP}_5 = 1.32 \\times 10^{-7} \\, J \\cdot s$。这对应于索引为 $i=5$ 的配置。\n\n问题要求报告最小化 EDP 的配置索引 $i$ 及其对应的准确率 $A_i$。最小化索引是 $i=5$。此配置的准确率是 $A_5 = 0.889$。问题规定准确率应四舍五入到四位有效数字。因此，$A_5 = 0.8890$。\n\n最终答案包含最小化配置的索引 $5$ 及其对应的准确率 $0.8890$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n5   0.8890\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "尽管能耗和延迟至关重要，但一个系统的效用最终取决于其准确性。然而，在处理现实世界中不平衡的数据时，标准的准确性指标可能具有欺骗性。本练习揭示了这一陷阱，并介绍了 $F_1$ 分数作为一种更可靠的性能衡量标准，确保我们不会为一个功能上表现不佳的模型评估其效率。",
            "id": "4036959",
            "problem": "一个部署在神经形态基底上的脉冲神经网络 (SNN) 在一个具有显著类别不平衡的多类别分类任务上进行评估。测试集包含 $10{,}000$ 个带标签的样本，分布在 $5$ 个类别中。评估产生以下混淆矩阵 $C \\in \\mathbb{N}^{5 \\times 5}$，其中行索引真实类别，列索引预测类别：\n$$\nC \\;=\\; \\begin{pmatrix}\n7400   200   150   150   100 \\\\\n500   150   80   40   30 \\\\\n420   100   120   40   20 \\\\\n200   30   30   25   15 \\\\\n140   20   20   10   10\n\\end{pmatrix}.\n$$\n使用多类别分类中的核心定义，计算总体准确率和宏平均 $F_1$ 分数。将每个类别的精确率视为该类别被正确预测的样本数占所有被预测为该类别的样本数的比例，将每个类别的召回率视为该类别被正确预测的样本数占该类别所有真实样本数的比例，并将每个类别的 $F_1$ 分数视为其精确率和召回率的调和平均值。宏平均 $F_1$ 分数是 $5$ 个类别各自 $F_1$ 值的未加权平均值。将这两个指标表示为无单位小数，并均四舍五入到四位有效数字。此外，基于这些定义的基本原理和所提供的数据，解释为什么在神经形态评估场景中，即使每次推理的延迟和能量消耗看似可接受，但当存在类别不平衡时，仅凭总体准确率可能会产生误导。最终的数值答案必须只包含所要求的两个指标。",
            "solution": "该问题要求根据给定的混淆矩阵计算两个分类指标——总体准确率和宏平均 $F_1$ 分数，并解释在类别不平衡的情况下，准确率指标可能具有误导性的原因。该问题定义明确且有科学依据。\n\n首先，我们从提供的混淆矩阵 $C$ 中确定所需的组成部分：\n$$\nC \\;=\\; \\begin{pmatrix}\n7400   200   150   150   100 \\\\\n500   150   80   40   30 \\\\\n420   100   120   40   20 \\\\\n200   30   30   25   15 \\\\\n140   20   20   10   10\n\\end{pmatrix}\n$$\n元素 $C_{ij}$ 表示来自真实类别 $i$ 但被预测为类别 $j$ 的样本数量。样本总数 $N$ 是矩阵中所有元素的总和：\n$N = \\sum_{i=1}^{5} \\sum_{j=1}^{5} C_{ij} = (7400+200+150+150+100) + (500+150+80+40+30) + (420+100+120+40+20) + (200+30+30+25+15) + (140+20+20+10+10) = 8000 + 800 + 700 + 300 + 200 = 10000$。\n这验证了给定的测试集总大小为 $10,000$ 个样本。\n\n**总体准确率的计算**\n\n总体准确率是正确分类的样本数与总样本数的比率。正确分类的样本对应于混淆矩阵的对角线元素（即 $C$ 的迹）。\n$$\n\\text{Accuracy} = \\frac{\\sum_{i=1}^{5} C_{ii}}{N} = \\frac{\\text{Tr}(C)}{N}\n$$\n对角线元素之和为：\n$$\n\\text{Tr}(C) = 7400 + 150 + 120 + 25 + 10 = 7705\n$$\n因此，总体准确率为：\n$$\n\\text{Accuracy} = \\frac{7705}{10000} = 0.7705\n$$\n该值已经表示为四位有效数字。\n\n**宏平均 $F_1$ 分数的计算**\n\n要计算宏平均 $F_1$ 分数，我们必须首先计算 $k=5$ 个类别中每个类别的精确率 ($P_i$)、召回率 ($R_i$) 和 $F_1$ 分数 ($F_{1,i}$)。\n\n对于每个类别 $i$，我们定义：\n- 真正例 ($TP_i$)：$C_{ii}$\n- 假正例 ($FP_i$)：$\\sum_{j=1, j\\neq i}^{k} C_{ji}$（第 $i$ 列的总和，不包括对角线元素）\n- 假反例 ($FN_i$)：$\\sum_{j=1, j\\neq i}^{k} C_{ij}$（第 $i$ 行的总和，不包括对角线元素）\n\n类别 $i$ 的精确率是 $P_i = \\frac{TP_i}{TP_i + FP_i}$，即类别 $i$ 的正确预测数除以对类别 $i$ 的总预测数。\n类别 $i$ 的召回率是 $R_i = \\frac{TP_i}{TP_i + FN_i}$，即类别 $i$ 的正确预测数除以类别 $i$ 中的实际总样本数。\n类别 $i$ 的 $F_1$ 分数是其精确率和召回率的调和平均值：$F_{1,i} = 2 \\frac{P_i R_i}{P_i + R_i}$。\n\n让我们为每个类别计算这些值：\n行总和（每个类别的实际总样本数）为：$S_{R,1}=8000$, $S_{R,2}=800$, $S_{R,3}=700$, $S_{R,4}=300$, $S_{R,5}=200$。\n列总和（每个类别的总预测样本数）为：\n$S_{C,1}=7400+500+420+200+140 = 8660$\n$S_{C,2}=200+150+100+30+20 = 500$\n$S_{C,3}=150+80+120+30+20 = 400$\n$S_{C,4}=150+40+40+25+10 = 265$\n$S_{C,5}=100+30+20+15+10 = 175$\n\n- **类别 1：**\n  $TP_1 = 7400$\n  $P_1 = \\frac{7400}{8660} \\approx 0.8545$\n  $R_1 = \\frac{7400}{8000} = 0.925$\n  $F_{1,1} = 2 \\frac{P_1 \\cdot R_1}{P_1 + R_1} \\approx 2 \\frac{0.8545 \\cdot 0.925}{0.8545 + 0.925} \\approx 0.8884$\n\n- **类别 2：**\n  $TP_2 = 150$\n  $P_2 = \\frac{150}{500} = 0.3$\n  $R_2 = \\frac{150}{800} = 0.1875$\n  $F_{1,2} = 2 \\frac{0.3 \\cdot 0.1875}{0.3 + 0.1875} \\approx 0.2308$\n\n- **类别 3：**\n  $TP_3 = 120$\n  $P_3 = \\frac{120}{400} = 0.3$\n  $R_3 = \\frac{120}{700} \\approx 0.1714$\n  $F_{1,3} = 2 \\frac{0.3 \\cdot 0.1714}{0.3 + 0.1714} \\approx 0.2182$\n\n- **类别 4：**\n  $TP_4 = 25$\n  $P_4 = \\frac{25}{265} \\approx 0.0943$\n  $R_4 = \\frac{25}{300} \\approx 0.0833$\n  $F_{1,4} = 2 \\frac{0.0943 \\cdot 0.0833}{0.0943 + 0.0833} \\approx 0.0885$\n\n- **类别 5：**\n  $TP_5 = 10$\n  $P_5 = \\frac{10}{175} \\approx 0.0571$\n  $R_5 = \\frac{10}{200} = 0.05$\n  $F_{1,5} = 2 \\frac{0.0571 \\cdot 0.05}{0.0571 + 0.05} \\approx 0.0533$\n\n宏平均 $F_1$ 分数是各个类别 $F_1$ 分数的未加权算术平均值：\n$$\nF_{1,\\text{macro}} = \\frac{1}{5} \\sum_{i=1}^{5} F_{1,i}\n$$\n$$\nF_{1,\\text{macro}} \\approx \\frac{1}{5} (0.8884 + 0.2308 + 0.2182 + 0.0885 + 0.0533)\n$$\n$$\nF_{1,\\text{macro}} \\approx \\frac{1}{5} (1.4792) \\approx 0.29584\n$$\n四舍五入到四位有效数字，宏平均 $F_1$ 分数为 $0.2958$。\n\n**关于类别不平衡下准确率误导性的解释**\n\n计算出的指标呈现出鲜明的对比：总体准确率是一个看似合理的 $0.7705$，而宏平均 $F_1$ 分数则是一个非常差的 $0.2958$。这种差异直接源于测试集中严重的类别不平衡以及这些指标的定义。\n\n总样本数为 $10,000$，类别 $1$ 到 $5$ 的样本分布分别为 $8000$、$800$、$700$、$300$ 和 $200$。类别 $1$ 占整个数据集的 $80\\%$。\n\n总体准确率是各类别性能的加权平均，其中权重是类别的大小。多数类别（类别1）的大量真正例（$TP_1 = 7400$）在准确率计算的分子（$\\sum TP_i = 7705$）中占主导地位。因此，总体准确率被模型在这个单一、过大的类别上的表现严重扭曲，从而对模型的能力给出了一个具有欺骗性的乐观景象。一个将每个样本都预测为“类别1”的简单模型仍能达到 $8000/10000 = 0.80$ 的准确率，这比该SNN的性能还要高，但在实践中毫无用处。\n\n相比之下，宏平均 $F_1$ 分数独立地计算每个类别的 $F_1$ 分数，然后取其未加权的平均值。这给予每个类别同等的重要性，无论其样本数量多少。四个少数类别（$0.2308$、$0.2182$、$0.0885$、$0.0533$）的 $F_1$ 分数都极低。这揭示了该 SNN 模型几乎没有实际能力来正确识别这些类别的样本。$0.2958$ 的低宏平均F1分数准确地反映了模型在少数类别上的糟糕表现，而总体准确率指标则完全掩盖了这一点。\n\n在神经形态评估中，如果只关注低延迟和单次推理低能耗等效率指标以及高总体准确率，将极具误导性。数据显示，该 SNN 可能仅仅通过学习一种偏向多数类别的简单策略来达到其高效率。该模型并未解决预期的分类问题，而是在解决一个有偏见的、更简单的问题版本。因此，为了对一个神经形态系统在不平衡任务上进行科学有效的评估，使用像宏平均 F1 分数这样对少数类别性能敏感的指标至关重要，以确保所报告的效率不是一个功能上无用的模型的副产品。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.7705  0.2958 \\end{pmatrix}}\n$$"
        }
    ]
}