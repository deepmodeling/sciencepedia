{
    "hands_on_practices": [
        {
            "introduction": "在将神经网络部署到神经形态硬件时，首要步骤是评估所需的资源。此练习聚焦于最基本的约束之一：存储空间。通过该练习，您将学习如何将抽象的网络属性（如神经元数量和连接密度）转化为在特定硬件数据格式（压缩稀疏行 (CSR)）下的具体存储需求估算 。这种估算能力对于快速判断一个给定网络是否适合目标硬件平台至关重要。",
            "id": "4050891",
            "problem": "一个神经形态系统使用源分区策略，将一个包含 $|V| = 10^5$ 个神经元的全循环网络层映射到 $P$ 个相同的计算核心上：每个核心被分配一个大小相等的、不相交的源神经元子集，并且对于每个分配的源神经元，该核心存储其所有的输出突触。网络的有向突触连接性被建模为顶点集 $V$ 上的一个 Erdős–Rényi 随机图，其边是独立的且无自环：对于任意有序的不同神经元对，突触存在的概率为 $\\rho \\in (0,1)$，且与其他神经元对的突触存在性无关。\n\n每个核心以压缩稀疏行 (CSR) 格式存储其分配到的网络层连接性子矩阵，该格式包括：\n- 一个行指针数组，其长度等于分配的源神经元数量加一，由 32 位无符号整型偏移量实现。\n- 一个列索引数组，其长度等于存储的突触数量，由 32 位无符号整型神经元标识符（范围在 $\\{0,1,\\dots,|V|-1\\}$ 内）实现。\n- 一个值数组，其长度等于存储的突触数量，由每个权重 $b_w$ 比特的定点突触权重实现。\n\n假设分区是完全平衡的，Erdős–Rényi 模型的独立性假设成立，并且除了所述数组之外的所有元数据开销都可以忽略不计。从 Erdős–Rényi 模型和压缩稀疏行表示法的基本定义出发，推导每个核心所需期望存储量（以比特为单位）的闭式解析表达式，该表达式是关于 $\\rho$、$P$ 和 $b_w$ 的函数。请用比特表示您的最终答案，并尽可能简化，将 $|V| = 10^5$ 精确代入。不要进行近似或四舍五入；请提供单一的闭式表达式。",
            "solution": "问题要求推导每个计算核心所需期望存储量（以比特为单位）的闭式解析表达式。设 $S_{\\text{core}}$ 为代表单个核心总存储量的随机变量。我们需要求其期望值 $E[S_{\\text{core}}]$。\n\n首先，我们定义问题陈述中提供的参数：\n- 神经元总数为 $|V|$，我们记为 $N$。给定 $N = 10^{5}$。\n- 相同计算核心的数量为 $P$。\n- 任意有序的不同神经元对之间存在突触的概率为 $\\rho \\in (0,1)$。\n- 突触权重的位宽为 $b_w$。\n\n映射采用源分区策略，其中 $N$ 个源神经元的集合被划分为 $P$ 个大小相等的、不相交的子集。由于分区是完全平衡的，每个核心被分配 $N_{\\text{c}} = N/P$ 个源神经元。对于这些源神经元中的每一个，核心会存储其所有的输出突触。\n\n每个核心上的存储采用压缩稀疏行 (CSR) 格式，该格式由三个数组组成。每个核心的总存储量 $S_{\\text{core}}$ 是这三个数组的存储量之和：\n1.  行指针数组 $S_{\\text{ptr}}$。\n2.  列索引数组 $S_{\\text{idx}}$。\n3.  值数组 $S_{\\text{val}}$。\n\n根据期望的线性性质，总的期望存储量为：\n$$E[S_{\\text{core}}] = E[S_{\\text{ptr}}] + E[S_{\\text{idx}}] + E[S_{\\text{val}}]$$\n我们现在将推导每一项的表达式。\n\n1.  **行指针数组的期望存储量 ($E[S_{\\text{ptr}}]$)**\n    行指针数组指明了其他两个数组中每个源神经元（行）对应数据的起始位置。对于 $N_{\\text{c}}$ 个源神经元，行指针数组的长度必须为 $N_{\\text{c}} + 1$。此数组中的每个条目都是一个 $32$ 位的无符号整数。\n    每个核心的源神经元数量为 $N_{\\text{c}} = N/P = 10^5/P$。\n    因此，行指针数组的长度为 $\\frac{10^5}{P} + 1$。\n    此数组所需的存储量是确定性的，不依赖于具体的随机连接性。\n    $$S_{\\text{ptr}} = \\left(\\frac{N}{P} + 1\\right) \\times 32 \\text{ bits}$$\n    由于 $S_{\\text{ptr}}$ 是一个常数，其期望值就是它本身：\n    $$E[S_{\\text{ptr}}] = 32\\left(\\frac{N}{P} + 1\\right)$$\n\n2.  **与突触相关的数组的期望存储量 ($E[S_{\\text{idx}}]$ 和 $E[S_{\\text{val}}]$)**\n    列索引数组和值数组的长度均等于分配给该核心的源神经元的总输出突触数。设这个数量为随机变量 $K_{\\text{core}}$。\n\n    为了求出这些数组的期望存储量，我们必须首先求出每个核心存储的期望突触数 $E[K_{\\text{core}}]$。\n    每个核心被分配了 $N_{\\text{c}} = N/P$ 个源神经元。\n    对于每个源神经元，由于不允许自环，有 $N-1$ 个可能的不同目标神经元。\n    分配给单个核心的神经元的潜在输出突触连接总数是分配的源神经元数量与每个神经元的可能目标数量的乘积：\n    $$\\text{潜在突触数} = N_{\\text{c}} \\times (N-1) = \\frac{N(N-1)}{P}$$\n    根据 Erdős–Rényi 模型，每个潜在突触都以概率 $\\rho$ 独立存在。因此，实际的突触总数 $K_{\\text{core}}$ 服从二项分布：\n    $$K_{\\text{core}} \\sim \\text{Binomial}\\left(\\frac{N(N-1)}{P}, \\rho\\right)$$\n    二项分布 $\\text{Binomial}(n, p)$ 的期望值（均值）为 $np$。因此，每个核心的期望突触数为：\n    $$E[K_{\\text{core}}] = \\frac{N(N-1)}{P} \\rho$$\n\n    现在我们可以计算剩下两个数组的期望存储量。\n    -   **列索引数组**：其长度为 $K_{\\text{core}}$，每个索引是一个 $32$ 位整数。存储量为 $S_{\\text{idx}} = 32 \\cdot K_{\\text{core}}$。期望存储量为：\n        $$E[S_{\\text{idx}}] = E[32 \\cdot K_{\\text{core}}] = 32 \\cdot E[K_{\\text{core}}] = 32 \\frac{N(N-1)}{P} \\rho$$\n    -   **值数组**：其长度为 $K_{\\text{core}}$，每个权重是一个 $b_w$ 位的定点数。存储量为 $S_{\\text{val}} = b_w \\cdot K_{\\text{core}}$。期望存储量为：\n        $$E[S_{\\text{val}}] = E[b_w \\cdot K_{\\text{core}}] = b_w \\cdot E[K_{\\text{core}}] = b_w \\frac{N(N-1)}{P} \\rho$$\n\n3.  **每个核心的总期望存储量**\n    我们将这三个部分的期望值相加：\n    $$E[S_{\\text{core}}] = E[S_{\\text{ptr}}] + E[S_{\\text{idx}}] + E[S_{\\text{val}}]$$\n    $$E[S_{\\text{core}}] = 32\\left(\\frac{N}{P} + 1\\right) + 32 \\frac{N(N-1)}{P} \\rho + b_w \\frac{N(N-1)}{P} \\rho$$\n    我们可以合并与突触相关的数组的项：\n    $$E[S_{\\text{core}}] = 32\\left(\\frac{N}{P} + 1\\right) + (32 + b_w) \\frac{N(N-1)}{P} \\rho$$\n    现在，我们展开并重新整理表达式以进行简化：\n    $$E[S_{\\text{core}}] = \\frac{32N}{P} + 32 + \\frac{N(N-1)(32 + b_w)}{P} \\rho$$\n    我们可以从依赖于 $P$ 的表达式部分中提取出因子 $1/P$：\n    $$E[S_{\\text{core}}] = \\frac{1}{P} \\left[ 32N + N(N-1)(32 + b_w)\\rho \\right] + 32$$\n    我们可以从方括号内的项中进一步提取出因子 $N$：\n    $$E[S_{\\text{core}}] = \\frac{N}{P} \\left[ 32 + (N-1)(32 + b_w)\\rho \\right] + 32$$\n    最后，我们代入给定值 $N = |V| = 10^5$：\n    $$E[S_{\\text{core}}] = \\frac{10^5}{P} \\left[ 32 + (10^5 - 1)(32 + b_w)\\rho \\right] + 32$$\n    执行减法 $10^5 - 1 = 99999$，我们得到最终的闭式表达式：\n    $$E[S_{\\text{core}}] = \\frac{10^5}{P} \\left[ 32 + 99999(32 + b_w)\\rho \\right] + 32$$\n    该表达式给出了每个核心的期望存储量（以比特为单位），其是核心数 $P$、突触连接概率 $\\rho$ 和突触权重位宽 $b_w$ 的函数。",
            "answer": "$$\\boxed{\\frac{10^5}{P} \\left[ 32 + 99999(32 + b_w)\\rho \\right] + 32}$$"
        },
        {
            "introduction": "了解网络规模后，下一个挑战是如何将其有效划分到多个计算核心上，以最小化核间通信，因为通信常常是性能和能耗的瓶颈。本练习将带您亲手实践一种经典的图划分启发式算法——Fiduccia-Mattheyses (FM) 算法。您将执行一个优化步骤，以理解移动单个神经元如何影响总连接成本，并学会处理核心容量等实际约束 。",
            "id": "4050853",
            "problem": "考虑将一个脉冲神经网络（SNN）映射到两个神经形态核心上，目标是通过划分网络来最小化核心间的通信，同时遵守每个核心的容量限制。假设标记为 $\\{1,2,3,4,5,6\\}$ 的神经元的有效无向耦合权重由对称邻接矩阵 $W \\in \\mathbb{R}^{6 \\times 6}$ 表示：\n$$\nW \\;=\\;\n\\begin{pmatrix}\n0  2  1  3  0  0 \\\\\n2  0  2  1  1  0 \\\\\n1  2  0  4  2  1 \\\\\n3  1  4  0  2  1 \\\\\n0  1  2  2  0  3 \\\\\n0  0  1  1  3  0\n\\end{pmatrix}.\n$$\n假设一个初始的双向划分将神经元分配到核心 $A$ 和 $B$ 上，定义为 $P_A = \\{1,2,3\\}$ 和 $P_B = \\{4,5,6\\}$。每个核心的神经元容量为 $N_{\\mathrm{cap}}^A = 3$ 和 $N_{\\mathrm{cap}}^B = 3$。映射目标使用标量惩罚系数 $\\lambda = 2$ 对容量溢出进行惩罚，该系数的单位与切割权重相同。定义总切割权重为所有跨越划分的边的权重之和，并定义将单个神经元 $v$ 从其当前核心移动到另一个核心的 Fiduccia–Mattheyses (FM) 增益为该移动所引起的切割权重的减少量。为了纳入容量约束，定义移动一个神经元 $v$ 的有效增益为 FM 增益减去容量溢出惩罚，其中惩罚是 $\\lambda$ 乘以移动后正溢出之和，即\n$$\n\\lambda \\left( \\max\\{0,\\,N_A^{\\mathrm{after}} - N_{\\mathrm{cap}}^A\\} + \\max\\{0,\\,N_B^{\\mathrm{after}} - N_{\\mathrm{cap}}^B\\} \\right),\n$$\n其中 $N_A^{\\mathrm{after}}$ 和 $N_B^{\\mathrm{after}}$ 表示移动后核心 $A$ 和 $B$ 上的神经元数量。\n\n在一次 FM 优化的迭代中，计算将神经元 3 从核心 $A$ 移动到核心 $B$ 的有效增益，结果表示为单个实数。最终答案以不带单位的实数表示。无需四舍五入。",
            "solution": "这个问题是良构的，并包含计算唯一解所需的所有必要信息。我们被要求计算将神经元 3 从核心 A 移动到核心 B 的有效增益。移动神经元 $v$ 的有效增益 $G_{\\mathrm{eff}}(v)$ 定义为 Fiduccia–Mattheyses (FM) 增益 $G_{\\mathrm{FM}}(v)$ 减去容量溢出惩罚 $P_{\\mathrm{cap}}$。\n$$\nG_{\\mathrm{eff}}(v) = G_{\\mathrm{FM}}(v) - P_{\\mathrm{cap}}\n$$\n\n首先，我们计算移动神经元 3 的 FM 增益 $G_{\\mathrm{FM}}(3)$。FM 增益定义为总切割权重的减少量。这可以计算为从该神经元到目标划分（外部连接）的连接权重之和，减去从该神经元到其源划分中其他神经元（内部连接）的连接权重之和。\n\n要移动的神经元是 $v=3$。其初始划分是核心 $A$，由神经元集合 $P_A = \\{1, 2, 3\\}$ 定义。目标划分是核心 $B$，其神经元为 $P_B = \\{4, 5, 6\\}$。\n\n连接的权重由邻接矩阵 $W$ 给出：\n$$\nW \\;=\\;\n\\begin{pmatrix}\n0  2  1  3  0  0 \\\\\n2  0  2  1  1  0 \\\\\n1  2  0  4  2  1 \\\\\n3  1  4  0  2  1 \\\\\n0  1  2  2  0  3 \\\\\n0  0  1  1  3  0\n\\end{pmatrix}\n$$\n\n神经元 3 的内部连接是它到划分 $P_A$ 中其他神经元（即神经元 1 和 2）的连接。这些内部连接的权重之和 $I_3$ 为：\n$$\nI_3 = W_{31} + W_{32} = 1 + 2 = 3\n$$\n神经元 3 的外部连接是它到划分 $P_B$ 中所有神经元（即神经元 4、5 和 6）的连接。这些外部连接的权重之和 $E_3$ 为：\n$$\nE_3 = W_{34} + W_{35} + W_{36} = 4 + 2 + 1 = 7\n$$\n移动神经元 3 的 FM 增益是外部连接权重与内部连接权重之差：\n$$\nG_{\\mathrm{FM}}(3) = E_3 - I_3 = 7 - 3 = 4\n$$\n这个值表示如果移动神经元 3，切割权重的减少量。\n\n接下来，我们计算容量溢出惩罚 $P_{\\mathrm{cap}}$。该惩罚由以下公式给出：\n$$\nP_{\\mathrm{cap}} = \\lambda \\left( \\max\\{0,\\,N_A^{\\mathrm{after}} - N_{\\mathrm{cap}}^A\\} + \\max\\{0,\\,N_B^{\\mathrm{after}} - N_{\\mathrm{cap}}^B\\} \\right)\n$$\n其中 $\\lambda = 2$ 是惩罚系数。\n\n划分的初始状态是：\n- 核心 $A$：$P_A = \\{1, 2, 3\\}$，因此神经元数量为 $N_A^{\\mathrm{initial}} = |P_A| = 3$。\n- 核心 $B$：$P_B = \\{4, 5, 6\\}$，因此神经元数量为 $N_B^{\\mathrm{initial}} = |P_B| = 3$。\n\n每个核心的容量给出为 $N_{\\mathrm{cap}}^A = 3$ 和 $N_{\\mathrm{cap}}^B = 3$。\n\n当我们将神经元 3 从核心 $A$ 移动到核心 $B$ 时，每个核心中的神经元数量会发生变化：\n- 移动后核心 $A$：$N_A^{\\mathrm{after}} = N_A^{\\mathrm{initial}} - 1 = 3 - 1 = 2$。\n- 移动后核心 $B$：$N_B^{\\mathrm{after}} = N_B^{\\mathrm{initial}} + 1 = 3 + 1 = 4$。\n\n现在，我们可以计算每个核心的溢出量：\n- 核心 $A$ 的溢出量：$\\max\\{0,\\, N_A^{\\mathrm{after}} - N_{\\mathrm{cap}}^A\\} = \\max\\{0,\\, 2 - 3\\} = \\max{0, -1} = 0$。\n- 核心 $B$ 的溢出量：$\\max\\{0,\\, N_B^{\\mathrm{after}} - N_{\\mathrm{cap}}^B\\} = \\max\\{0,\\, 4 - 3\\} = \\max{0, 1} = 1$。\n\n总溢出量是每个核心上溢出量之和，即 $0 + 1 = 1$。\n那么，容量溢出惩罚为：\n$$\nP_{\\mathrm{cap}} = \\lambda \\times (\\text{总溢出量}) = 2 \\times 1 = 2\n$$\n\n最后，我们通过从 FM 增益中减去容量惩罚来计算移动神经元 3 的有效增益：\n$$\nG_{\\mathrm{eff}}(3) = G_{\\mathrm{FM}}(3) - P_{\\mathrm{cap}} = 4 - 2 = 2\n$$\n有效增益为 $2$。",
            "answer": "$$\n\\boxed{2}\n$$"
        },
        {
            "introduction": "除了存储和连接性，能耗是神经形态系统，尤其是边缘计算应用中的一个关键性能指标。一个优秀的映射算法必须考虑其决策对能量消耗的影响。本练习将指导您为一个基于片上网络（NoC）的系统构建一个自下而上的能量模型，您将学习如何将底层的硬件事件（如神经元更新和数据包路由）与网络层的总能耗联系起来 。掌握这项技能对于设计和评估节能的映射策略至关重要。",
            "id": "4050840",
            "problem": "考虑一个前馈脉冲神经网络（SNN）层，该层被映射到一个二维网格结构的片上网络（NoC）上。该NoC由 $K \\times K$ 个相同的路由单元组成，这些单元排列在整数坐标 $(x,y)$ 上，其中 $x,y \\in \\{1,2,\\dots,K\\}$，数据包沿最短曼哈顿路径穿过链路。源神经元产生的每个脉冲都通过NoC的路由逻辑被复制成独立的单播数据包，发送给其突触后目标。每个神经元脉冲事件在其源单元处消耗能量 $E_{\\text{neuron}}$。每个数据包的路由器处理步骤（在路由器注入或转发）每个数据包每个路由器消耗 $E_{\\text{router}}$ 的能量，每个数据包的链路遍历每跳消耗 $E_{\\text{link}}$ 的能量。假设链路和路由器是相同的，它们的能量成本不依赖于负载。根据一种映射策略，每个源神经元的目标在所有单元（不包括源单元）中独立且均匀随机地选择，并且路由为每个单播数据包使用独立的最短曼哈顿路径。\n\n令 $m$ 表示一个脉冲的多播度（该脉冲的目标目的地数量），令 $\\ell$ 表示该脉冲的总跳数（所有 $m$ 个单播路径上的链路跳数之和）。将 $m$ 个单播路径视为到均匀随机选择的目的地的独立最短路径。由神经元 $i$ 以速率 $r_i$ 发出的脉冲被建模为在时间窗口 $T$ 内的泊松过程，并且来自不同神经元的脉冲是独立的。设该层有 $N$ 个神经元，每个神经元被独立且均匀随机地分配到一个单元。\n\n仅从独立事件能量的可加性及以上定义出发：\n\n1. 推导单个脉冲的期望总跳数 $\\mathbb{E}[\\ell \\mid m,K]$ 的闭式表达式，该表达式是 $m$ 和 $K$ 的函数。\n2. 使用能量可加性，推导每个脉冲的期望能量的符号表达式，用 $E_{\\text{neuron}}$、$E_{\\text{router}}$、$E_{\\text{link}}$、$m$ 和 $K$ 表示。\n3. 综合结果，得到该层在时间窗口 $T$ 内的总期望能量的闭式表达式（单位为焦耳），用 $E_{\\text{neuron}}$、$E_{\\text{router}}$、$E_{\\text{link}}$、$K$、$T$、$\\{r_i\\}_{i=1}^{N}$ 以及该层脉冲的平均多播度 $\\bar{m}$ 表示。假设多播度独立于脉冲时序，并且在所有神经元中同分布，具有有限均值 $\\bar{m}$。\n\n将您的最终答案表示为单个解析表达式。如果需要单位，请以焦耳表示能量。不需要数值近似或四舍五入。",
            "solution": "问题陈述已经过分析，并被认为是有效的。它在科学上基于神经形态计算、计算机体系结构和概率论的原理。该问题提法恰当、客观，并包含足够的信息来推导出唯一解。该模型虽然经过简化，但本身是自洽的，没有违反任何基本定律。\n\n按照问题陈述的要求，解答分为三部分推导。\n\n### 第一部分：期望总跳数\n\n令 $\\ell$ 为多播度为 $m$ 的单个脉冲的总跳数。它是 $m$ 个单播数据包各自跳数 $h_j$ 的总和：\n$$\n\\ell = \\sum_{j=1}^{m} h_j\n$$\n根据期望的线性性质，期望总跳数为：\n$$\n\\mathbb{E}[\\ell \\mid m, K] = \\mathbb{E}\\left[\\sum_{j=1}^{m} h_j \\mid m, K\\right] = \\sum_{j=1}^{m} \\mathbb{E}[h_j \\mid m, K]\n$$\n问题陈述指出，$m$ 个目标目的地是在所有单元（不包括源单元）中独立且均匀随机选择的。这意味着对于所有数据包 $j \\in \\{1, \\dots, m\\}$，其跳数 $h_j$ 的分布是相同的。令 $\\mathbb{E}[h]$ 表示这个共同的期望跳数。那么，\n$$\n\\mathbb{E}[\\ell \\mid m, K] = m \\, \\mathbb{E}[h]\n$$\n为了求得 $\\mathbb{E}[h]$，我们必须计算在 $K \\times K$ 网格上均匀随机选择的两个不同单元之间的期望曼哈顿距离。设源单元的坐标为 $(x_s, y_s)$，目的单元的坐标为 $(x_d, y_d)$，其中 $x_s, y_s, x_d, y_d \\in \\{1, 2, \\dots, K\\}$。最短曼哈顿路径的跳数（距离）为 $h = |x_s - x_d| + |y_s - y_d|$。\n\n根据期望的线性性质，$\\mathbb{E}[h] = \\mathbb{E}[|x_s - x_d|] + \\mathbb{E}[|y_s - y_d|]$。由于网格的对称性，$\\mathbb{E}[|x_s - x_d|] = \\mathbb{E}[|y_s - y_d|]$。我们需要计算这个值，即在所有可能的不同源和目的单元对上取平均。\n\n单元对的总数为 $K^4$。不同单元对（源 $\\neq$ 目的）的数量为 $K^2(K^2 - 1)$。一维距离 $|x_s - x_d|$ 的期望是 $|x_s - x_d|$ 在所有不同源/目的单元对上的总和，再除以这种对的数量。\n$$\n\\mathbb{E}[|x_s - x_d|] = \\frac{\\sum_{\\text{source } s \\neq \\text{dest } d} |x_s - x_d|}{K^2(K^2 - 1)}\n$$\n分子中的求和可以展开为：\n$$\n\\sum_{s \\neq d} |x_s - x_d| = \\sum_{s} \\sum_{d \\neq s} |x_s - x_d|\n$$\n由于 $|x_s - x_s| = 0$，我们可以写成 $\\sum_{d \\neq s} |x_s - x_d| = \\sum_{d} |x_s - x_d|$。\n$$\n\\sum_{s} \\sum_{d} |x_s - x_d| = \\sum_{(x_s, y_s)} \\sum_{(x_d, y_d)} |x_s - x_d| = K^2 \\sum_{x_s=1}^K \\sum_{x_d=1}^K |x_s - x_d|\n$$\n这个一维求和是一个标准结果：\n$$\n\\sum_{i=1}^K \\sum_{j=1}^K |i - j| = \\frac{K(K^2 - 1)}{3}\n$$\n将其代回，沿x轴的所有一维距离的总和为：\n$$\n\\sum_{s \\neq d} |x_s - x_d| = K^2 \\cdot \\frac{K(K^2 - 1)}{3} = \\frac{K^3(K^2 - 1)}{3}\n$$\n因此，期望的一维距离为：\n$$\n\\mathbb{E}[|x_s - x_d|] = \\frac{K^3(K^2 - 1) / 3}{K^2(K^2 - 1)} = \\frac{K}{3}\n$$\n那么，期望的曼哈顿距离为：\n$$\n\\mathbb{E}[h] = \\mathbb{E}[|x_s - x_d|] + \\mathbb{E}[|y_s - y_d|] = \\frac{K}{3} + \\frac{K}{3} = \\frac{2K}{3}\n$$\n最后，多播度为 $m$ 的脉冲的期望总跳数为：\n$$\n\\mathbb{E}[\\ell \\mid m, K] = m \\frac{2K}{3}\n$$\n\n### 第二部分：每个脉冲的期望能量\n\n单个脉冲事件的总能量 $E_{\\text{spike}}$ 是神经元脉冲能量与其 $m$ 个数据包的通信能量之和。\n$$\nE_{\\text{spike}} = E_{\\text{neuron}} + E_{\\text{comm}}\n$$\n通信能量 $E_{\\text{comm}}$ 是所有 $m$ 个单播数据包的能量总和。对于一个穿过 $h_j$ 跳路径的单个数据包，它会经过 $h_j$ 条链路，并被 $h_j+1$ 个路由器处理（一次注入、 $h_j-1$ 次转发步骤和一次吸收，我们假设吸收也属于路由器处理的定义范畴）。数据包 $j$ 的能量为：\n$$\nE_{\\text{packet}, j} = h_j E_{\\text{link}} + (h_j + 1) E_{\\text{router}}\n$$\n该脉冲的总通信能量为：\n$$\nE_{\\text{comm}} = \\sum_{j=1}^m E_{\\text{packet}, j} = \\sum_{j=1}^m (h_j E_{\\text{link}} + (h_j + 1) E_{\\text{router}})\n$$\n我们寻求以 $m$ 和 $K$ 为条件的每个脉冲的期望能量。利用期望的线性性质：\n$$\n\\mathbb{E}[E_{\\text{spike}} \\mid m, K] = E_{\\text{neuron}} + \\mathbb{E}\\left[\\sum_{j=1}^m (h_j E_{\\text{link}} + (h_j + 1) E_{\\text{router}}) \\mid m, K\\right]\n$$\n$$\n\\mathbb{E}[E_{\\text{spike}} \\mid m, K] = E_{\\text{neuron}} + \\sum_{j=1}^m \\mathbb{E}[h_j E_{\\text{link}} + (h_j + 1) E_{\\text{router}} \\mid m, K]\n$$\n由于 $E_{\\text{link}}$ 和 $E_{\\text{router}}$ 是常数，且对于所有的 $j$ 都有 $\\mathbb{E}[h_j] = \\mathbb{E}[h] = \\frac{2K}{3}$：\n$$\n\\mathbb{E}[E_{\\text{spike}} \\mid m, K] = E_{\\text{neuron}} + \\sum_{j=1}^m \\left( \\mathbb{E}[h] E_{\\text{link}} + (\\mathbb{E}[h] + 1) E_{\\text{router}} \\right)\n$$\n$$\n\\mathbb{E}[E_{\\text{spike}} \\mid m, K] = E_{\\text{neuron}} + m \\left( \\frac{2K}{3} E_{\\text{link}} + \\left(\\frac{2K}{3} + 1\\right) E_{\\text{router}} \\right)\n$$\n\n### 第三部分：时间 T 内的期望总能量\n\n总能量 $E_{\\text{total}}$ 是在时间窗口 $T$ 内发生的所有脉冲的能量之和。设 $S$ 为该窗口内所有 $N$ 个神经元产生的脉冲总数。第 $k$ 个脉冲的能量为 $E_{\\text{spike}, k}$。\n$$\nE_{\\text{total}} = \\sum_{k=1}^S E_{\\text{spike}, k}\n$$\n来自神经元 $i$ 的脉冲数 $S_i$ 服从均值为 $r_i T$ 的泊松分布。总脉冲数 $S = \\sum_{i=1}^N S_i$ 也是一个泊松随机变量（独立泊松变量之和），其均值为 $\\mathbb{E}[S] = \\sum_{i=1}^N r_i T = T \\sum_{i=1}^N r_i$。\n\n每个脉冲的能量是一个随机变量，取决于其多播度 $m$。问题陈述指出，多播度独立于脉冲时序，并且同分布，均值为 $\\bar{m}$。这意味着每个脉冲的能量 $E_{\\text{spike}, k}$ 是一个独立同分布的随机变量，其值与总脉冲数 $S$ 无关。因此，我们可以应用瓦尔德等式（Wald's identity）：\n$$\n\\mathbb{E}[E_{\\text{total}}] = \\mathbb{E}[S] \\cdot \\mathbb{E}[E_{\\text{spike}}]\n$$\n我们需要每个脉冲的无条件期望能量 $\\mathbb{E}[E_{\\text{spike}}]$。这可以通过对第二部分的结果在 $m$ 的分布上取期望来求得：\n$$\n\\mathbb{E}[E_{\\text{spike}}] = \\mathbb{E}_m[\\mathbb{E}[E_{\\text{spike}} \\mid m, K]] = \\mathbb{E}_m\\left[ E_{\\text{neuron}} + m \\left( \\frac{2K}{3} E_{\\text{link}} + \\left(\\frac{2K}{3} + 1\\right) E_{\\text{router}} \\right) \\right]\n$$\n利用期望的线性性质和 $\\mathbb{E}[m] = \\bar{m}$：\n$$\n\\mathbb{E}[E_{\\text{spike}}] = E_{\\text{neuron}} + \\bar{m} \\left( \\frac{2K}{3} E_{\\text{link}} + \\left(\\frac{2K}{3} + 1\\right) E_{\\text{router}} \\right)\n$$\n综合这些结果，时间窗口 $T$ 内的期望总能量为：\n$$\n\\mathbb{E}[E_{\\text{total}}] = \\left(T \\sum_{i=1}^N r_i\\right) \\left[ E_{\\text{neuron}} + \\bar{m} \\left( \\left(\\frac{2K}{3} + 1\\right) E_{\\text{router}} + \\frac{2K}{3} E_{\\text{link}} \\right) \\right]\n$$\n这就是期望总能量的最终闭式表达式。",
            "answer": "$$ \\boxed{ T \\left( \\sum_{i=1}^{N} r_i \\right) \\left[ E_{\\text{neuron}} + \\bar{m} \\left( \\left( \\frac{2K}{3} + 1 \\right) E_{\\text{router}} + \\frac{2K}{3} E_{\\text{link}} \\right) \\right] } $$"
        }
    ]
}