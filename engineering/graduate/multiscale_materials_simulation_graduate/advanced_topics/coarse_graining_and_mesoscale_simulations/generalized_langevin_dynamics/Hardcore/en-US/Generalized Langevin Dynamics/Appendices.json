{
    "hands_on_practices": [
        {
            "introduction": "The Fluctuation-Dissipation Theorem (FDT) is the cornerstone of the Generalized Langevin Equation, establishing a deep connection between the microscopic random force $R(t)$ that drives a particle and the macroscopic memory kernel $\\Gamma(t)$ that dissipates its energy. This practice provides a direct calculation to verify this theorem for a common physical model, the Debye kernel. By working through the Fourier analysis, you will solidify your understanding of how the noise power spectrum and the memory kernel are intimately linked in any system at thermal equilibrium .",
            "id": "3811520",
            "problem": "Consider the Generalized Langevin Equation (GLE) for a single tagged particle in equilibrium at temperature $T$:\n$$m\\,\\dot{v}(t)=-\\int_{0}^{t}\\Gamma(t-s)\\,v(s)\\,\\mathrm{d}s+R(t),$$\nwhere $m$ is the particle mass, $v(t)$ is its velocity, $\\Gamma(t)$ is a causal memory kernel, and $R(t)$ is a stationary, zero-mean random force. At equilibrium, the Fluctuation-Dissipation Theorem (FDT) states that the random force autocorrelation $C_{RR}(t)\\equiv\\langle R(t)R(0)\\rangle$ is related to the memory kernel by $C_{RR}(t)=k_{B}T\\,\\Gamma(|t|)$, where $k_{B}$ is Boltzmann’s constant. For a stationary process, the Wiener-Khinchin theorem asserts that the noise power spectrum $S_{RR}(\\omega)$ is the Fourier transform of $C_{RR}(t)$:\n$$S_{RR}(\\omega)=\\int_{-\\infty}^{\\infty}C_{RR}(t)\\,\\exp(i\\omega t)\\,\\mathrm{d}t,$$\nwhere $\\omega$ is the angular frequency. Let the memory kernel be a Debye-type exponential,\n$$\\Gamma(t)=\\gamma\\,\\exp\\!\\left(-\\frac{t}{\\tau}\\right)\\quad\\text{for }t\\geq 0,$$\nwith $\\gamma0$ and $\\tau0$ material parameters. Define the one-sided Fourier transform of the kernel\n$$\\tilde{\\Gamma}(\\omega)=\\int_{0}^{\\infty}\\Gamma(t)\\,\\exp(i\\omega t)\\,\\mathrm{d}t.$$\nStarting from the stated principles and definitions, compute the noise power spectrum $S_{RR}(\\omega)$ for this kernel using the Wiener-Khinchin theorem. Then, by explicit calculation of $\\tilde{\\Gamma}(\\omega)$, demonstrate the relationship between the spectrum and the one-sided transform that is implied by equilibrium statistical mechanics. Express your final spectrum in base International System of Units (SI) as a symbolic function of $\\omega$, $k_{B}$, $T$, $\\gamma$, and $\\tau$. No numerical evaluation is required, and no rounding is needed. The boxed final answer must be the single closed-form expression for $S_{RR}(\\omega)$; do not include units inside the box.",
            "solution": "The problem is valid. It is scientifically grounded in the principles of statistical mechanics, specifically the theory of Brownian motion and linear response. It is well-posed, self-contained, and all terms are formally defined.\n\nThe primary goal is to compute the noise power spectrum $S_{RR}(\\omega)$ for a given memory kernel $\\Gamma(t)$. We will do this via two routes as requested by the problem: first, by direct computation using the Wiener-Khinchin theorem, and second, by relating it to the one-sided Fourier transform of the kernel, $\\tilde{\\Gamma}(\\omega)$, to demonstrate their connection.\n\nFirst, we compute the spectrum $S_{RR}(\\omega)$ directly. The Wiener-Khinchin theorem states that the spectrum is the Fourier transform of the autocorrelation function $C_{RR}(t)$:\n$$S_{RR}(\\omega)=\\int_{-\\infty}^{\\infty}C_{RR}(t)\\,\\exp(i\\omega t)\\,\\mathrm{d}t$$\nThe Fluctuation-Dissipation Theorem (FDT) provides the link between the autocorrelation function of the random force, $C_{RR}(t)$, and the memory kernel, $\\Gamma(t)$:\n$$C_{RR}(t) = k_{B}T\\,\\Gamma(|t|)$$\nSubstituting the FDT into the Wiener-Khinchin theorem gives:\n$$S_{RR}(\\omega) = \\int_{-\\infty}^{\\infty} k_{B}T\\,\\Gamma(|t|)\\,\\exp(i\\omega t)\\,\\mathrm{d}t = k_{B}T\\int_{-\\infty}^{\\infty}\\Gamma(|t|)\\,\\exp(i\\omega t)\\,\\mathrm{d}t$$\nThe problem specifies a Debye-type memory kernel:\n$$\\Gamma(t)=\\gamma\\,\\exp\\!\\left(-\\frac{t}{\\tau}\\right)\\quad\\text{for }t\\geq 0$$\nSince the kernel is causal, $\\Gamma(t)=0$ for $t0$. The term $\\Gamma(|t|)$ is therefore:\n$$\\Gamma(|t|) = \\gamma\\,\\exp\\!\\left(-\\frac{|t|}{\\tau}\\right)$$\nWe can now substitute this specific form into the integral for $S_{RR}(\\omega)$:\n$$S_{RR}(\\omega) = k_{B}T\\,\\gamma\\int_{-\\infty}^{\\infty}\\exp\\!\\left(-\\frac{|t|}{\\tau}\\right)\\exp(i\\omega t)\\,\\mathrm{d}t$$\nTo evaluate this integral, we split the domain at $t=0$:\n$$S_{RR}(\\omega) = k_{B}T\\,\\gamma\\left[ \\int_{-\\infty}^{0}\\exp\\!\\left(\\frac{t}{\\tau}\\right)\\exp(i\\omega t)\\,\\mathrm{d}t + \\int_{0}^{\\infty}\\exp\\!\\left(-\\frac{t}{\\tau}\\right)\\exp(i\\omega t)\\,\\mathrm{d}t \\right]$$\nWe evaluate each integral separately. For the first integral:\n$$\\int_{-\\infty}^{0}\\exp\\!\\left(t\\left(\\frac{1}{\\tau} + i\\omega\\right)\\right)\\,\\mathrm{d}t = \\left[\\frac{\\exp\\!\\left(t\\left(\\frac{1}{\\tau} + i\\omega\\right)\\right)}{\\frac{1}{\\tau} + i\\omega}\\right]_{-\\infty}^{0} = \\frac{1}{\\frac{1}{\\tau} + i\\omega} - 0 = \\frac{\\tau}{1+i\\omega\\tau}$$\nFor the second integral:\n$$\\int_{0}^{\\infty}\\exp\\!\\left(t\\left(-\\frac{1}{\\tau} + i\\omega\\right)\\right)\\,\\mathrm{d}t = \\left[\\frac{\\exp\\!\\left(t\\left(-\\frac{1}{\\tau} + i\\omega\\right)\\right)}{-\\frac{1}{\\tau} + i\\omega}\\right]_{0}^{\\infty} = 0 - \\frac{1}{-\\frac{1}{\\tau} + i\\omega} = \\frac{1}{\\frac{1}{\\tau} - i\\omega} = \\frac{\\tau}{1-i\\omega\\tau}$$\nSubstituting these results back into the expression for $S_{RR}(\\omega)$:\n$$S_{RR}(\\omega) = k_{B}T\\,\\gamma\\left( \\frac{\\tau}{1+i\\omega\\tau} + \\frac{\\tau}{1-i\\omega\\tau} \\right)$$\nTo simplify, we find a common denominator:\n$$S_{RR}(\\omega) = k_{B}T\\,\\gamma\\tau\\left( \\frac{(1-i\\omega\\tau) + (1+i\\omega\\tau)}{(1+i\\omega\\tau)(1-i\\omega\\tau)} \\right) = k_{B}T\\,\\gamma\\tau\\left( \\frac{2}{1 - (i\\omega\\tau)^{2}} \\right)$$\n$$S_{RR}(\\omega) = k_{B}T\\,\\gamma\\tau\\left( \\frac{2}{1 + \\omega^{2}\\tau^{2}} \\right) = \\frac{2k_{B}T\\gamma\\tau}{1+\\omega^{2}\\tau^{2}}$$\nThis is the closed-form expression for the noise power spectrum.\n\nNext, we demonstrate the relationship between $S_{RR}(\\omega)$ and the one-sided Fourier transform of the kernel, $\\tilde{\\Gamma}(\\omega)$. The problem defines this transform as:\n$$\\tilde{\\Gamma}(\\omega)=\\int_{0}^{\\infty}\\Gamma(t)\\,\\exp(i\\omega t)\\,\\mathrm{d}t$$\nUsing the Debye kernel, we have:\n$$\\tilde{\\Gamma}(\\omega) = \\int_{0}^{\\infty}\\gamma\\,\\exp\\!\\left(-\\frac{t}{\\tau}\\right)\\exp(i\\omega t)\\,\\mathrm{d}t = \\gamma\\int_{0}^{\\infty}\\exp\\!\\left(t\\left(-\\frac{1}{\\tau} + i\\omega\\right)\\right)\\,\\mathrm{d}t$$\nThis is the same as the second integral we evaluated earlier, multiplied by $\\gamma$. Thus:\n$$\\tilde{\\Gamma}(\\omega) = \\gamma\\left(\\frac{\\tau}{1-i\\omega\\tau}\\right) = \\frac{\\gamma\\tau}{1-i\\omega\\tau}$$\nTo relate this to $S_{RR}(\\omega)$, let's go back to the general integral form:\n$$S_{RR}(\\omega) = k_{B}T\\int_{-\\infty}^{\\infty}\\Gamma(|t|)\\,\\exp(i\\omega t)\\,\\mathrm{d}t = k_{B}T\\left[\\int_{-\\infty}^{0}\\Gamma(-t)\\exp(i\\omega t)\\,\\mathrm{d}t + \\int_{0}^{\\infty}\\Gamma(t)\\exp(i\\omega t)\\,\\mathrm{d}t\\right]$$\nThe second term is $k_{B}T\\,\\tilde{\\Gamma}(\\omega)$. For the first term, we perform a change of variables $s=-t$, so $\\mathrm{d}t=-\\mathrm{d}s$:\n$$\\int_{-\\infty}^{0}\\Gamma(-t)\\exp(i\\omega t)\\,\\mathrm{d}t = \\int_{\\infty}^{0}\\Gamma(s)\\exp(-i\\omega s)(-\\mathrm{d}s) = \\int_{0}^{\\infty}\\Gamma(s)\\exp(-i\\omega s)\\,\\mathrm{d}s$$\nThis integral is the definition of $\\tilde{\\Gamma}(-\\omega)$. Therefore, we have established the general relationship:\n$$S_{RR}(\\omega) = k_{B}T\\left[\\tilde{\\Gamma}(-\\omega) + \\tilde{\\Gamma}(\\omega)\\right]$$\nSince the kernel $\\Gamma(t)$ is a real-valued function, $\\tilde{\\Gamma}(-\\omega) = \\tilde{\\Gamma}(\\omega)^{*}$, where the asterisk denotes complex conjugation. The relationship can also be written as:\n$$S_{RR}(\\omega) = k_{B}T\\left[\\tilde{\\Gamma}(\\omega)^{*} + \\tilde{\\Gamma}(\\omega)\\right] = 2k_{B}T\\,\\text{Re}\\left[\\tilde{\\Gamma}(\\omega)\\right]$$\nLet's verify this for our specific kernel. We found $\\tilde{\\Gamma}(\\omega) = \\frac{\\gamma\\tau}{1-i\\omega\\tau}$. To find its real part, we multiply the numerator and denominator by the complex conjugate of the denominator:\n$$\\tilde{\\Gamma}(\\omega) = \\frac{\\gamma\\tau(1+i\\omega\\tau)}{(1-i\\omega\\tau)(1+i\\omega\\tau)} = \\frac{\\gamma\\tau + i\\gamma\\tau^{2}\\omega}{1+\\omega^{2}\\tau^{2}} = \\frac{\\gamma\\tau}{1+\\omega^{2}\\tau^{2}} + i\\frac{\\gamma\\tau^{2}\\omega}{1+\\omega^{2}\\tau^{2}}$$\nThe real part is:\n$$\\text{Re}\\left[\\tilde{\\Gamma}(\\omega)\\right] = \\frac{\\gamma\\tau}{1+\\omega^{2}\\tau^{2}}$$\nUsing the general relationship, the spectrum is:\n$$S_{RR}(\\omega) = 2k_{B}T\\,\\text{Re}\\left[\\tilde{\\Gamma}(\\omega)\\right] = 2k_{B}T\\left(\\frac{\\gamma\\tau}{1+\\omega^{2}\\tau^{2}}\\right) = \\frac{2k_{B}T\\gamma\\tau}{1+\\omega^{2}\\tau^{2}}$$\nThis result is identical to the one obtained by direct computation, which demonstrates the connection implied by equilibrium statistical mechanics. The final expression for the noise power spectrum is a Lorentzian function of the frequency $\\omega$.",
            "answer": "$$\\boxed{\\frac{2k_{B}T\\gamma\\tau}{1+\\omega^{2}\\tau^{2}}}$$"
        },
        {
            "introduction": "A central task in multiscale modeling is to construct an effective coarse-grained model, like the GLE, from data generated by a more detailed simulation. The Velocity Autocorrelation Function (VACF) is a key observable quantity that can be readily computed from atomistic trajectories. This exercise guides you through the essential \"inverse problem\": given a model for the VACF, you will derive the corresponding memory kernel $\\Gamma(t)$ that reproduces these dynamics, a fundamental skill for parameterizing GLE models in practical research .",
            "id": "3811501",
            "problem": "Consider a scalar coarse-grained velocity $v(t)$ of a tagged particle embedded in a dense material, modeled within multiscale materials simulation by the Generalized Langevin Equation (GLE). Assume the system is in thermal equilibrium at absolute temperature $T$, with mass $m$, and the dynamics of $v(t)$ are described by the GLE with a memory kernel $\\Gamma(t)$ and a zero-mean stationary random force $R(t)$ that satisfies the Fluctuation-Dissipation Theorem (FDT). Define the Velocity Autocorrelation Function (VACF) as $C_{v}(t) = \\langle v(t)v(0)\\rangle$, where $\\langle \\cdot \\rangle$ denotes an equilibrium ensemble average. In a particular coarse-grained model, atomistic simulations produce a VACF that is well-represented by a bi-exponential form\n$$\nC_{v}(t) = \\frac{k_{B}T}{m}\\left[a\\exp(-\\lambda_{1}t) + (1-a)\\exp(-\\lambda_{2}t)\\right],\n$$\nwhere $0a1$, and $\\lambda_{1}0$, $\\lambda_{2}0$ are distinct relaxation rates, and $k_{B}$ is the Boltzmann constant. Starting only from Newton’s second law applied to the coarse-grained degree of freedom, the definition of the GLE, stationarity and time-translational invariance of equilibrium correlation functions, and the generalized Kubo relation that links response functions to equilibrium correlation functions, perform the following:\n\n1. Derive an analytical expression for the memory kernel $\\Gamma(t)$ in the time domain that is consistent with the given VACF. Your derivation must proceed from first principles of the GLE and equilibrium correlations without invoking pre-stated shortcut formulas.\n2. Under equilibrium, use the Fluctuation-Dissipation Theorem to formulate a force-based estimate of dissipation and check its consistency with your derived $\\Gamma(t)$ by verifying that the zero-frequency mobility extracted from the VACF equals the inverse of the integrated memory kernel. Clearly state any intermediate definitions used, such as the Laplace transform of a function and the meaning of the Dirac delta distribution.\n\nProvide the final answer as the closed-form analytical expression for $\\Gamma(t)$. No numerical evaluation is required.",
            "solution": "The problem statement is scientifically grounded, well-posed, and objective. It provides a complete and consistent set of givens within the established theoretical framework of the Generalized Langevin Equation (GLE) and equilibrium statistical mechanics. The requested tasks are standard derivations in this field. Therefore, the problem is valid and a solution will be provided.\n\nThe problem asks for the derivation of the memory kernel $\\Gamma(t)$ consistent with a given bi-exponential velocity autocorrelation function (VACF), $C_v(t)$, and a subsequent consistency check using the Fluctuation-Dissipation Theorem (FDT).\n\nThe starting point is the Generalized Langevin Equation for the scalar velocity $v(t)$ of a particle of mass $m$:\n$$\nm \\frac{d v(t)}{dt} = -\\int_{0}^{t} \\Gamma(t-t') v(t') dt' + R(t)\n$$\nHere, $\\Gamma(t)$ is the memory kernel, and $R(t)$ is the random force, which is a stationary process with zero mean, $\\langle R(t) \\rangle = 0$. A fundamental property stemming from the projection operator formalism, which formally derives the GLE, is that the random force at time $t  0$ is uncorrelated with the initial velocity $v(0)$. This is expressed as $\\langle R(t) v(0) \\rangle = 0$ for $t  0$.\n\nTo find the equation governing the VACF, $C_v(t) = \\langle v(t) v(0) \\rangle$, we multiply the GLE by $v(0)$ and take the equilibrium ensemble average:\n$$\nm \\left\\langle \\frac{d v(t)}{dt} v(0) \\right\\rangle = -\\left\\langle \\left( \\int_{0}^{t} \\Gamma(t-t') v(t') dt' \\right) v(0) \\right\\rangle + \\langle R(t) v(0) \\rangle\n$$\nUsing the stationarity of equilibrium averages, the left-hand side can be written as $m \\frac{d}{dt} \\langle v(t) v(0) \\rangle = m \\frac{dC_v(t)}{dt}$. The random force term vanishes, $\\langle R(t) v(0) \\rangle = 0$. By linearity, the average can be moved inside the integral in the friction term. This yields the Volterra integro-differential equation for $C_v(t)$:\n$$\nm \\frac{dC_v(t)}{dt} = -\\int_{0}^{t} \\Gamma(t-t') C_v(t') dt'\n$$\n\nThis equation is most readily solved in the Laplace domain. We define the Laplace transform of a function $f(t)$ as $\\hat{f}(s) = \\mathcal{L}\\{f(t)\\} = \\int_{0}^{\\infty} \\exp(-st) f(t) dt$. The Laplace transform of a derivative is $\\mathcal{L}\\{f'(t)\\} = s\\hat{f}(s) - f(0)$, and the Laplace transform of a convolution is $\\mathcal{L}\\{\\int_0^t g(t-\\tau)h(\\tau)d\\tau\\} = \\hat{g}(s)\\hat{h}(s)$. Applying the Laplace transform to the equation for $C_v(t)$ gives:\n$$\nm \\left( s\\hat{C}_v(s) - C_v(0) \\right) = - \\hat{\\Gamma}(s) \\hat{C}_v(s)\n$$\nWe can rearrange this algebraic equation to solve for the memory kernel in the Laplace domain, $\\hat{\\Gamma}(s)$:\n$$\n\\hat{\\Gamma}(s) \\hat{C}_v(s) = m C_v(0) - m s \\hat{C}_v(s)\n$$\n$$\n\\hat{\\Gamma}(s) = \\frac{m C_v(0)}{\\hat{C}_v(s)} - m s\n$$\nThe problem provides the VACF:\n$$\nC_v(t) = \\frac{k_{B}T}{m}\\left[a\\exp(-\\lambda_{1}t) + (1-a)\\exp(-\\lambda_{2}t)\\right]\n$$\nThe value at $t=0$ is $C_v(0) = \\frac{k_{B}T}{m}(a + (1-a)) = \\frac{k_{B}T}{m}$, which is consistent with the equipartition theorem, $\\frac{1}{2}m\\langle v^2 \\rangle = \\frac{1}{2}k_B T$.\nNext, we find the Laplace transform $\\hat{C}_v(s)$:\n$$\n\\hat{C}_v(s) = \\mathcal{L}\\left\\{ \\frac{k_{B}T}{m}\\left[a\\exp(-\\lambda_{1}t) + (1-a)\\exp(-\\lambda_{2}t)\\right] \\right\\} = \\frac{k_{B}T}{m} \\left( \\frac{a}{s+\\lambda_1} + \\frac{1-a}{s+\\lambda_2} \\right)\n$$\nCombining the terms gives:\n$$\n\\hat{C}_v(s) = \\frac{k_{B}T}{m} \\frac{a(s+\\lambda_2) + (1-a)(s+\\lambda_1)}{(s+\\lambda_1)(s+\\lambda_2)} = \\frac{k_{B}T}{m} \\frac{s + (1-a)\\lambda_1 + a\\lambda_2}{(s+\\lambda_1)(s+\\lambda_2)}\n$$\nSubstituting this and $C_v(0)$ into the expression for $\\hat{\\Gamma}(s)$:\n$$\n\\hat{\\Gamma}(s) = \\frac{m \\left(\\frac{k_B T}{m}\\right)}{\\frac{k_{B}T}{m} \\frac{s + (1-a)\\lambda_1 + a\\lambda_2}{(s+\\lambda_1)(s+\\lambda_2)}} - m s = m \\frac{(s+\\lambda_1)(s+\\lambda_2)}{s + (1-a)\\lambda_1 + a\\lambda_2} - m s\n$$\nExpanding the numerator and combining terms over a common denominator:\n$$\n\\hat{\\Gamma}(s) = \\frac{m (s^2 + (\\lambda_1+\\lambda_2)s + \\lambda_1\\lambda_2) - m s (s + (1-a)\\lambda_1 + a\\lambda_2)}{s + (1-a)\\lambda_1 + a\\lambda_2}\n$$\n$$\n\\hat{\\Gamma}(s) = \\frac{m s^2 + m(\\lambda_1+\\lambda_2)s + m\\lambda_1\\lambda_2 - m s^2 - m((1-a)\\lambda_1 + a\\lambda_2)s}{s + (1-a)\\lambda_1 + a\\lambda_2}\n$$\nThe $ms^2$ terms cancel. The coefficient of the linear $s$ term in the numerator simplifies to $m(\\lambda_1+\\lambda_2 - ((1-a)\\lambda_1 + a\\lambda_2)) = m(a\\lambda_1 + (1-a)\\lambda_2)$.\nSo,\n$$\n\\hat{\\Gamma}(s) = \\frac{m(a\\lambda_1 + (1-a)\\lambda_2)s + m\\lambda_1\\lambda_2}{s + (1-a)\\lambda_1 + a\\lambda_2}\n$$\nTo perform the inverse Laplace transform, we use polynomial long division. Let $P = m(a\\lambda_1 + (1-a)\\lambda_2)$ and $Q = (1-a)\\lambda_1 + a\\lambda_2$. The expression is $\\frac{Ps + m\\lambda_1\\lambda_2}{s+Q}$.\n$$\n\\frac{Ps + m\\lambda_1\\lambda_2}{s+Q} = \\frac{P(s+Q) - PQ + m\\lambda_1\\lambda_2}{s+Q} = P + \\frac{m\\lambda_1\\lambda_2 - PQ}{s+Q}\n$$\nThe constant term simplifies significantly:\n$PQ = m(a\\lambda_1 + (1-a)\\lambda_2)((1-a)\\lambda_1 + a\\lambda_2)$\n$PQ = m[a(1-a)\\lambda_1^2 + a^2\\lambda_1\\lambda_2 + (1-a)^2\\lambda_1\\lambda_2 + a(1-a)\\lambda_2^2]$\n$PQ = m[a(1-a)(\\lambda_1^2+\\lambda_2^2) + (a^2+(1-a)^2)\\lambda_1\\lambda_2]$\nThe term in the numerator becomes:\n$m\\lambda_1\\lambda_2 - PQ = m[\\lambda_1\\lambda_2 - a(1-a)(\\lambda_1^2+\\lambda_2^2) - (2a^2-2a+1)\\lambda_1\\lambda_2]$\n$= m[(1 - (2a^2-2a+1))\\lambda_1\\lambda_2 - a(1-a)(\\lambda_1^2+\\lambda_2^2)]$\n$= m[(-2a^2+2a)\\lambda_1\\lambda_2 - a(1-a)(\\lambda_1^2+\\lambda_2^2)]$\n$= m[2a(1-a)\\lambda_1\\lambda_2 - a(1-a)(\\lambda_1^2+\\lambda_2^2)]$\n$= -ma(1-a)(\\lambda_1^2-2\\lambda_1\\lambda_2+\\lambda_2^2) = -ma(1-a)(\\lambda_1-\\lambda_2)^2$\nSubstituting this back into the expression for $\\hat{\\Gamma}(s)$:\n$$\n\\hat{\\Gamma}(s) = m(a\\lambda_1 + (1-a)\\lambda_2) - \\frac{ma(1-a)(\\lambda_1-\\lambda_2)^2}{s + (1-a)\\lambda_1 + a\\lambda_2}\n$$\nThis is the Laplace transform of the memory kernel. Taking the inverse Laplace transform, using $\\mathcal{L}^{-1}\\{C\\} = C\\delta(t)$ where $\\delta(t)$ is the Dirac delta distribution and $\\mathcal{L}^{-1}\\{1/(s+k)\\} = \\exp(-kt)$, yields the time-domain memory kernel $\\Gamma(t)$:\n$$\n\\Gamma(t) = m(a\\lambda_1 + (1-a)\\lambda_2)\\delta(t) - ma(1-a)(\\lambda_1 - \\lambda_2)^2 \\exp(-((1-a)\\lambda_1 + a\\lambda_2)t)\n$$\n\nFor the second part of the problem, we must verify consistency using the Fluctuation-Dissipation Theorem. The FDT connects dissipation (represented by the friction) to fluctuations (represented by the correlation function). Specifically, the zero-frequency mobility $\\mu_0$ must equal the inverse of the total friction $\\gamma_{tot}$.\nThe \"force-based estimate\" of dissipation refers to the Green-Kubo relation for mobility:\n$$\n\\mu_0 = \\frac{1}{k_B T} \\int_0^\\infty C_v(t) dt = \\frac{1}{k_B T} \\hat{C}_v(s=0)\n$$\nThe total friction is the time integral of the memory kernel:\n$$\n\\gamma_{tot} = \\int_0^\\infty \\Gamma(t) dt = \\hat{\\Gamma}(s=0)\n$$\nThe consistency requirement is $\\mu_0 = 1/\\gamma_{tot}$, which is equivalent to checking if $\\hat{C}_v(0) / (k_B T) = 1/\\hat{\\Gamma}(0)$, or $\\hat{\\Gamma}(0)\\hat{C}_v(0) = k_B T$.\nThis relationship is a direct consequence of the GLE itself, without needing to calculate the integrals explicitly. We return to the Laplace-domain equation for the VACF:\n$$\nm \\left( s\\hat{C}_v(s) - C_v(0) \\right) = - \\hat{\\Gamma}(s) \\hat{C}_v(s)\n$$\nSetting $s=0$ yields:\n$$\nm (0 - C_v(0)) = - \\hat{\\Gamma}(0) \\hat{C}_v(0)\n$$\n$$\nm C_v(0) = \\hat{\\Gamma}(0) \\hat{C}_v(0)\n$$\nSince equilibrium at temperature $T$ implies $C_v(0) = \\frac{k_B T}{m}$, we substitute this in:\n$$\nm \\left( \\frac{k_B T}{m} \\right) = \\hat{\\Gamma}(0) \\hat{C}_v(0)\n$$\nThis directly proves that $\\hat{\\Gamma}(0) \\hat{C}_v(0) = k_B T$, confirming the consistency of the framework. The derived kernel $\\Gamma(t)$ is therefore consistent with the FDT as formulated.\n\nThe primary result of the derivation is the functional form of $\\Gamma(t)$.",
            "answer": "$$\n\\boxed{m\\left(a\\lambda_1 + (1-a)\\lambda_2\\right)\\delta(t) - ma(1-a)\\left(\\lambda_1 - \\lambda_2\\right)^2 \\exp\\left(-\\left((1-a)\\lambda_1 + a\\lambda_2\\right)t\\right)}\n$$"
        },
        {
            "introduction": "The memory integral in the GLE poses a significant computational challenge, as its cost scales linearly with the memory length $M$. This makes simulations of systems with long-ranged memory prohibitively expensive. This hands-on coding practice demonstrates how to implement an efficient Fast Fourier Transform (FFT) based algorithm to reduce the per-step complexity from $\\mathcal{O}(M)$ to a nearly-constant $\\mathcal{O}(\\log M)$. Mastering this technique is essential for performing large-scale GLE simulations of complex materials .",
            "id": "3811483",
            "problem": "Consider a one-dimensional Generalized Langevin Equation (GLE) memory term arising in multiscale materials simulation. The memory term at discrete time index $n$ is defined as the discrete convolution\n$$\n\\mathcal{M}_n \\equiv \\sum_{k=0}^{M-1} \\gamma_k \\, v_{n-k},\n$$\nwhere $v_n$ is the discrete velocity history, $\\gamma_k$ are memory kernel weights generated from a stationary kernel, $M$ is the finite memory length, and $n \\in \\{0,1,\\dots,N-1\\}$ denotes the current step. Assume $v_{n-k} = 0$ for $n-k  0$. This convolution appears in explicit time discretizations of the GLE when the kernel is stationary and truncated to a finite horizon. Starting from the following fundamental bases: (i) Newton’s second law stating that rate of change of momentum equals the total force, (ii) definition of convolution as a weighted sum, and (iii) the Discrete Fourier Transform (DFT) convolution theorem, derive the algorithmic strategy to reduce the amortized per-step complexity of computing $\\mathcal{M}_n$ from $\\mathcal{O}(M)$ to $\\mathcal{O}(\\log M)$ by exploiting stationarity of $\\gamma_k$.\n\nYour derivation must begin from the definition of the discrete memory force as a convolution and use the Discrete Fourier Transform’s property that convolution in time is multiplication in frequency. Explain the necessity of linear convolution (not circular) and how to achieve it using overlap-save with zero-padding. Explicitly justify how precomputing the Fourier transform of the zero-padded kernel constitutes precomputation of convolution weights for a stationary kernel. Show how to choose a block size $B$ and an FFT length $L$ such that $L$ is the next power of two greater than or equal to $B + M - 1$, how to process the signal in blocks with an overlap of $M-1$, and how discarding $M-1$ transient samples per block achieves correct linear convolution. Provide a simple operation-count model to argue that the amortized per-step complexity scales like $\\mathcal{O}(\\log M)$ when $B$ is chosen proportional to $M$.\n\nThen implement a program that:\n- Precomputes the Fourier-domain kernel weights once per test case by zero-padding $\\gamma_k$ to length $L$ and computing its DFT.\n- Implements an overlap-save Fast Fourier Transform (FFT)-based convolution to compute $\\mathcal{M}_n$ for $n \\in \\{0,\\dots,N-1\\}$.\n- Computes a reference result using direct convolution.\n- Reports for each test case two quantities: the maximum absolute error between the FFT-based result and the direct result, and a theoretical per-step cost ratio defined as\n$$\n\\mathcal{R} \\equiv \\frac{M}{\\frac{2 L \\log_2 L + L}{B}},\n$$\nwhich compares the naive per-step operation count (taken proportional to $M$) to the amortized FFT cost per step with one forward FFT, one inverse FFT, and one pointwise complex multiplication per block.\n\nTest suite:\n- Case $1$: $N=64$, $M=17$, stationary exponential kernel $\\gamma_k = \\exp(-k/\\tau)$ with $\\tau=5$; $v_n$ is independent and identically distributed standard normal with a fixed seed; block size $B=M$.\n- Case $2$: $N=64$, $M=1$, $\\gamma_0 = 1$ and no other terms; $v_n$ is independent and identically distributed standard normal with a fixed seed; $B=M$.\n- Case $3$: $N=96$, $M=33$, power-law kernel $\\gamma_k = (k+1)^{-p}$ with $p=1.5$; $v_n$ is independent and identically distributed standard normal with a fixed seed; $B=M$.\n- Case $4$: $N=10$, $M=8$, zero kernel $\\gamma_k = 0$ for all $k$; $v_n$ is independent and identically distributed standard normal with a fixed seed; $B=M$.\n- Case $5$: $N=32$, $M=5$, triangular kernel $\\gamma_k = (M-k)/M$; deterministic ramp signal $v_n = n$; $B=M$.\n\nYour program must output a single line containing a list of pairs for these cases, where each pair is $[\\text{max\\_abs\\_error}, \\mathcal{R}]$ as floating-point numbers. The required output format is a single line containing a JSON-like list, for example, \n\"[ [error1,ratio1],[error2,ratio2],... ]\".",
            "solution": "The task is to derive and implement an efficient algorithm for computing the discrete memory term in the Generalized Langevin Equation (GLE), reducing its per-step complexity from $\\mathcal{O}(M)$ to $\\mathcal{O}(\\log M)$. The derivation must be based on fundamental principles including Newton's second law (by context of GLE), the definition of convolution, and the Discrete Fourier Transform (DFT) convolution theorem.\n\nThe memory term $\\mathcal{M}_n$ at a discrete time step $n$ is defined as a sum over the past velocity history $v$:\n$$\n\\mathcal{M}_n \\equiv \\sum_{k=0}^{M-1} \\gamma_k \\, v_{n-k}\n$$\nHere, $\\gamma_k$ are the weights of a stationary memory kernel with a finite length of $M$, $v_j$ is the velocity at time step $j$, and we assume $v_j = 0$ for $j  0$. The equation is evaluated for $n \\in \\{0, 1, \\dots, N-1\\}$.\n\nA direct computation of $\\mathcal{M}_n$ for each time step $n$ requires $M$ multiplications and $M-1$ additions. A simulation over $N$ time steps would thus have a total computational cost for the memory term proportional to $\\mathcal{O}(NM)$. For simulations where the memory length $M$ is large, this cost can become prohibitive.\n\nThe expression for $\\mathcal{M}_n$ is a discrete linear convolution of the kernel sequence $\\gamma = \\{\\gamma_k\\}_{k=0}^{M-1}$ and the velocity history $v = \\{v_j\\}$. We can write this as $\\mathcal{M}_n = (\\gamma * v)_n$. The convolution theorem for the Discrete Fourier Transform (DFT) provides an avenue for accelerating this computation. The theorem states that for two sequences $a$ and $b$ of length $L$, the DFT of their circular convolution is the element-wise product of their individual DFTs:\n$$\n\\text{DFT}(a \\circledast b) = \\text{DFT}(a) \\cdot \\text{DFT}(b)\n$$\nwhere $\\circledast$ denotes circular convolution and $\\cdot$ denotes element-wise multiplication. An inverse DFT then recovers the convolved sequence in the time domain: $a \\circledast b = \\text{IDFT}(\\text{DFT}(a) \\cdot \\text{DFT}(b))$.\n\nHowever, the memory term $\\mathcal{M}_n$ is a *linear* convolution. A direct application of the DFT convolution theorem on sequences of length $M$ would yield a *circular* convolution, which incorrectly wraps the sequence around, producing aliasing errors. To compute a linear convolution using DFTs, we must embed the problem in a larger space. A linear convolution of a sequence of length $M$ and a sequence of length $B$ results in a sequence of length $M+B-1$. Therefore, to avoid wrap-around effects, the DFTs must be performed on sequences of length $L \\ge M+B-1$. This is achieved by padding the original sequences with zeros to length $L$.\n\nThe high cost of direct convolution stems from recomputing sums for each time step. Since the kernel $\\gamma_k$ is stationary (time-invariant), its contribution to the convolution can be precomputed. The strategy is to use a block-based fast convolution algorithm, such as the overlap-save method. This method amortizes the cost of the fast Fourier transforms (FFTs)—efficient algorithms for computing DFTs—over many time steps.\n\nThe overlap-save algorithm proceeds as follows:\n1.  **Selection of Parameters**: Choose a block size $B$ for processing the velocity signal $v$. Let the kernel size be $M$. The FFT length $L$ must satisfy $L \\ge M+B-1$. For optimal FFT performance, $L$ is typically chosen to be the next power of two greater than or equal to $M+B-1$.\n2.  **Kernel Precomputation**: The kernel sequence $\\gamma = [\\gamma_0, \\gamma_1, \\dots, \\gamma_{M-1}]$ is padded with zeros to length $L$. Its DFT, denoted $\\hat{\\gamma} = \\text{DFT}([\\gamma_0, \\dots, \\gamma_{M-1}, 0, \\dots, 0])$, is then computed. Since $\\gamma$ is stationary, this is a one-time precomputation for the entire simulation, representing the precomputed convolution weights in the frequency domain.\n3.  **Signal Blocking and Processing**: The velocity signal $v$ is processed in overlapping blocks. Each block of data to be transformed has length $L$. It is constructed by taking $M-1$ samples from the end of the previous data segment and appending $B$ new samples from the velocity signal.\n4.  **Per-Block Convolution**: For each data block $v_{\\text{block}}$ of length $L$:\n    a. Compute its DFT, $\\hat{v}_{\\text{block}} = \\text{DFT}(v_{\\text{block}})$.\n    b. Perform element-wise multiplication in the frequency domain: $\\hat{\\mathcal{M}}_{\\text{block}} = \\hat{\\gamma} \\cdot \\hat{v}_{\\text{block}}$.\n    c. Compute the inverse DFT to return to the time domain: $\\mathcal{M}_{\\text{block}} = \\text{IDFT}(\\hat{\\mathcal{M}}_{\\text{block}})$.\n5.  **Overlap-Save**: The resulting sequence $\\mathcal{M}_{\\text{block}}$ is the $L$-point circular convolution of the zero-padded kernel and the data block. The initial $M-1$ points of $\\mathcal{M}_{\\text{block}}$ are corrupted by aliasing effects from the circular convolution, as they depend on the wrap-around portion of the data block. These $M-1$ points are discarded. The subsequent $B$ points are identical to the result of a linear convolution and are retained as the valid output for the current block of $B$ time steps.\n6.  **Concatenation**: The valid $B$-point segments from each block are concatenated to form the complete memory term history $\\mathcal{M}_0, \\mathcal{M}_1, \\dots, \\mathcal{M}_{N-1}$. The initial condition $v_j=0$ for $j0$ is handled by prepending the velocity signal with $M-1$ zeros before the first block is processed.\n\n**Amortized Complexity Analysis**:\nThe computational cost of an FFT of length $L$ is $\\mathcal{O}(L \\log L)$. For each block, we perform one forward FFT, one inverse FFT, and $L$ complex multiplications. The total cost per block is thus dominated by the FFTs, amounting to $\\mathcal{O}(L \\log L)$. Each block produces $B$ valid output points. The amortized cost per time step is therefore $\\frac{\\mathcal{O}(L \\log L)}{B}$.\n\nTo analyze the scaling, let us choose a block size $B$ proportional to the memory length $M$, for example, $B=M$. Then, we need an FFT length $L \\ge M+B-1 = 2M-1$. Choosing $L$ as the next power of two makes $L$ proportional to $M$ (i.e., $L \\approx 2M$). The amortized cost per step becomes:\n$$\n\\text{Cost per step} \\propto \\frac{L \\log L}{B} \\propto \\frac{M \\log M}{M} = \\mathcal{O}(\\log M)\n$$\nThis demonstrates a significant reduction from the $\\mathcal{O}(M)$ complexity of direct convolution.\n\nThe theoretical per-step cost ratio $\\mathcal{R}$ compares the direct method's operation count (proportional to $M$) to the amortized FFT method's count. Approximating the operation count for an FFT of size $L$ as $L \\log_2 L$, the cost for one block (one forward FFT, one inverse FFT, and $L$ pointwise multiplications) is $2L \\log_2 L + L$. Amortized over $B$ steps, the cost per step is $\\frac{2L \\log_2 L + L}{B}$. The ratio is thus:\n$$\n\\mathcal{R} \\equiv \\frac{M}{\\frac{2 L \\log_2 L + L}{B}}\n$$\nThis ratio quantifies the theoretical speedup achieved by the FFT-based algorithm over the direct summation.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all specified test cases.\n    It computes the memory term using both direct convolution and\n    an overlap-save FFT-based method, then reports the maximum\n    absolute error and a theoretical cost ratio.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: Exponential kernel, random velocity\n        {\n            'N': 64, 'M': 17, 'B': 17,\n            'gamma_gen': lambda M: np.exp(-np.arange(M) / 5.0),\n            'v_gen': lambda N, seed: np.random.RandomState(seed).standard_normal(N)\n        },\n        # Case 2: Delta kernel (M=1), random velocity\n        {\n            'N': 64, 'M': 1, 'B': 1,\n            'gamma_gen': lambda M: np.array([1.0]),\n            'v_gen': lambda N, seed: np.random.RandomState(seed).standard_normal(N)\n        },\n        # Case 3: Power-law kernel, random velocity\n        {\n            'N': 96, 'M': 33, 'B': 33,\n            'gamma_gen': lambda M: (np.arange(M) + 1.0)**(-1.5),\n            'v_gen': lambda N, seed: np.random.RandomState(seed).standard_normal(N)\n        },\n        # Case 4: Zero kernel, random velocity\n        {\n            'N': 10, 'M': 8, 'B': 8,\n            'gamma_gen': lambda M: np.zeros(M),\n            'v_gen': lambda N, seed: np.random.RandomState(seed).standard_normal(N)\n        },\n        # Case 5: Triangular kernel, deterministic ramp velocity\n        {\n            'N': 32, 'M': 5, 'B': 5,\n            'gamma_gen': lambda M: (M - np.arange(M)) / M if M  0 else np.array([]),\n            'v_gen': lambda N, seed: np.arange(N, dtype=float)\n        }\n    ]\n\n    results = []\n\n    for i, case in enumerate(test_cases):\n        N, M, B = case['N'], case['M'], case['B']\n        \n        # Generate kernel gamma\n        gamma = case['gamma_gen'](M)\n        \n        # Generate velocity v with a fixed seed for each case\n        v = case['v_gen'](N, seed=i)\n\n        # --- Direct Convolution (Reference) ---\n        # np.convolve in 'full' mode computes the linear convolution.\n        # The result has length N + M - 1. We take the first N points.\n        if N == 0:\n            m_direct = np.array([])\n        elif M == 0:\n            m_direct = np.zeros(N)\n        else:\n            m_direct = np.convolve(v, gamma, mode='full')[:N]\n\n        # --- Overlap-Save FFT Convolution ---\n        if N == 0:\n            m_fft = np.array([])\n        elif M == 0:\n            m_fft = np.zeros(N)\n        else:\n            # Determine FFT length L\n            L_min = M + B - 1\n            if L_min = 0:\n                L = 1\n            else:\n                L = 1  (L_min - 1).bit_length()\n\n            # Precompute FFT of zero-padded kernel\n            gamma_padded = np.zeros(L)\n            gamma_padded[:M] = gamma\n            gamma_fft = np.fft.fft(gamma_padded)\n\n            # Pad velocity signal at the start with M-1 zeros\n            # to handle boundary conditions v_{n0}=0\n            v_padded = np.pad(v, (M - 1, 0), 'constant')\n            \n            num_blocks = int(np.ceil(N / B))\n            fft_results = []\n            \n            for j in range(num_blocks):\n                start_idx = j * B\n                end_idx = start_idx + L\n                \n                block_v = np.zeros(L)\n                # Take a slice of v_padded, pad with zeros if it's too short\n                v_slice = v_padded[start_idx:end_idx]\n                block_v[:len(v_slice)] = v_slice\n\n                # Convolution in frequency domain\n                block_v_fft = np.fft.fft(block_v)\n                conv_block_fft = gamma_fft * block_v_fft\n                conv_block = np.fft.ifft(conv_block_fft).real\n\n                # Discard M-1 transient samples and save the valid part\n                valid_part = conv_block[M - 1 : M - 1 + B]\n                fft_results.append(valid_part)\n\n            m_fft = np.concatenate(fft_results)[:N]\n\n        # --- Calculate Metrics ---\n        # Maximum absolute error\n        if N  0:\n            max_abs_error = np.max(np.abs(m_direct - m_fft))\n        else:\n            max_abs_error = 0.0\n\n        # Theoretical per-step cost ratio\n        L_min_for_R = M + B - 1\n        if L_min_for_R = 0:\n            L_for_R = 1\n        else:\n             L_for_R = 1  (L_min_for_R - 1).bit_length()\n        \n        if B == 0 or M == 0:\n            cost_ratio = float('inf') if M  0 else 0.0\n        else:\n            amortized_fft_cost = (2 * L_for_R * np.log2(L_for_R) + L_for_R) / B\n            if amortized_fft_cost > 0:\n                cost_ratio = M / amortized_fft_cost\n            else:\n                cost_ratio = float('inf') # Avoid division by zero if cost is somehow zero\n\n        results.append([max_abs_error, cost_ratio])\n\n    # Format the final output string\n    output_str = \"[\" + \",\".join(f\"[{e},{r}]\" for e, r in results) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}