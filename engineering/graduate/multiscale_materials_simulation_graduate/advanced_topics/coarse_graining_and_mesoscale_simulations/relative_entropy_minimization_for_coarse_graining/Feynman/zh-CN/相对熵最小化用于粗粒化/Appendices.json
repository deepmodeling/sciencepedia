{
    "hands_on_practices": [
        {
            "introduction": "在深入研究复杂的计算问题之前，通过一个简单的、可解析求解的案例来理解相对熵最小化 (REM) 的原理至关重要。本练习将作为一个基础性的推导，引导你完成一个连续系统的粗粒化过程。通过这个实践，你将揭示在坐标变换中雅可比行列式 ($J(\\xi)$) 的关键作用，并看到当粗粒化模型的形式选择恰当时，REM 如何精确地确定最优参数。",
            "id": "3838743",
            "problem": "考虑一个位于$d$维欧几里得空间$\\mathbb{R}^{d}$中的单个粒子，其位置向量为$\\mathbf{r} \\in \\mathbb{R}^{d}$，细粒度正则系综概率密度函数（PDF）为$P(\\mathbf{r}) \\propto \\exp(-\\beta U(\\mathbf{r}))$。其中，$\\beta = 1/(k_{B}T)$是逆热能，$k_{B}$是玻尔兹曼常数，$T$是绝对温度，势能为$U(\\mathbf{r}) = \\frac{\\kappa}{2}\\|\\mathbf{r}\\|^{2}$，$\\kappa > 0$为固定的刚度。定义一个粗粒度映射算子$M:\\mathbb{R}^{d} \\to \\mathbb{R}_{+}$，由$\\xi = M(\\mathbf{r}) = \\|\\mathbf{r}\\|$给出，即径向坐标。粗粒度参考概率密度函数$p_{\\text{ref}}(\\xi)$是通过对细粒度$P(\\mathbf{r})$积分掉角自由度得到的。从笛卡尔坐标到超球坐标的变换会引入一个雅可比因子$J(\\xi)$。\n\n您将使用一个参数化的粗粒度势$U_{\\text{cg}}(\\xi; k) = \\frac{k}{2}\\xi^{2} - (d-1)k_{B}T \\ln \\xi$，在$\\xi$上构建一个具有平坦测度$\\mathrm{d}\\xi$的一维粗粒度模型，其中$k > 0$是一个待确定的未知刚度参数。模型概率密度函数为$p_{\\theta}(\\xi) \\propto \\exp\\big(-\\beta U_{\\text{cg}}(\\xi; k)\\big)$。\n\n从玻尔兹曼分布和库尔贝克-莱布勒散度（KLD）（也称为相对熵）的定义出发：\n$$D_{\\text{KL}}(p_{\\text{ref}} \\| p_{\\theta}) = \\int_{0}^{\\infty} p_{\\text{ref}}(\\xi)\\,\\ln\\left(\\frac{p_{\\text{ref}}(\\xi)}{p_{\\theta}(\\xi)}\\right)\\,\\mathrm{d}\\xi,$$\n请从第一性原理出发，完成以下任务：\n- 推导与映射$M(\\mathbf{r}) = \\|\\mathbf{r}\\|$相关的雅可比因子$J(\\xi)$，并用$J(\\xi)$、$\\beta$和$\\kappa$表示$p_{\\text{ref}}(\\xi)$。\n- 用$\\beta$、$k$和$\\xi$表示$p_{\\theta}(\\xi)$。\n- 显式写出$D_{\\text{KL}}(p_{\\text{ref}} \\| p_{\\theta})$的表达式。\n- 确定使$D_{\\text{KL}}(p_{\\text{ref}} \\| p_{\\theta})$最小化的刚度参数$k$。\n\n将使表达式最小化的参数$k$以给定量的单个闭式解析表达式的形式给出最终结果。无需进行舍入。",
            "solution": "首先确认该问题在科学上是合理的、适定的和客观的。这是一个统计力学和粗粒度理论中的标准问题，利用了玻尔兹曼分布和相对熵最小化等既定原理。所有必需的信息都已提供，问题没有矛盾或含糊之处。\n\n该问题要求通过四个部分的推导来确定粗粒度模型的最优刚度参数$k$。我们将系统地处理每个部分。\n\n**第1部分：雅可比因子$J(\\xi)$和参考PDF $p_{\\text{ref}}(\\xi)$的推导**\n\n细粒度系统由位置向量为$\\mathbf{r} \\in \\mathbb{R}^{d}$的粒子的正则系综概率密度函数（PDF）$P(\\mathbf{r})$描述。该PDF由玻尔兹曼分布给出：\n$$P(\\mathbf{r}) = C_{FG} \\exp(-\\beta U(\\mathbf{r}))$$\n其中$C_{FG}$是归一化常数，$\\beta = 1/(k_{B}T)$是逆热能，势能是一个$d$维谐振子势阱，$U(\\mathbf{r}) = \\frac{\\kappa}{2}\\|\\mathbf{r}\\|^{2}$。\n\n粗粒度变量是径向坐标$\\xi = \\|\\mathbf{r}\\|$。为了求出$\\xi$的PDF，我们必须从笛卡尔坐标$\\mathbf{r}$变换到超球坐标。超球坐标中的体积元是$\\mathrm{d}^d\\mathbf{r} = \\xi^{d-1} \\mathrm{d}\\xi \\mathrm{d}\\Omega_{d-1}$，其中$\\mathrm{d}\\Omega_{d-1}$是$d$维空间中的立体角元。\n\n在无穷小体积元$\\mathrm{d}^d\\mathbf{r}$中找到该粒子的概率是$P(\\mathbf{r})\\mathrm{d}^d\\mathbf{r}$。用超球坐标表示，这变为：\n$$P(\\xi) \\xi^{d-1} \\mathrm{d}\\xi \\mathrm{d}\\Omega_{d-1} = C_{FG} \\exp\\left(-\\frac{\\beta\\kappa}{2}\\xi^2\\right) \\xi^{d-1} \\mathrm{d}\\xi \\mathrm{d}\\Omega_{d-1}$$\n参考粗粒度PDF $p_{\\text{ref}}(\\xi)$是通过对所有角自由度积分得到的：\n$$p_{\\text{ref}}(\\xi)\\mathrm{d}\\xi = \\left( \\int_{\\Omega_{d-1}} C_{FG} \\exp\\left(-\\frac{\\beta\\kappa}{2}\\xi^2\\right) \\xi^{d-1} \\mathrm{d}\\Omega_{d-1} \\right) \\mathrm{d}\\xi$$\n被积函数与角变量无关。$\\mathrm{d}\\Omega_{d-1}$在整个立体角上的积分是单位$(d-1)$维球面的表面积，记为$S_{d} = \\frac{2\\pi^{d/2}}{\\Gamma(d/2)}$，其中$\\Gamma$是伽马函数。\n$$p_{\\text{ref}}(\\xi)\\mathrm{d}\\xi = C_{FG} S_{d} \\xi^{d-1} \\exp\\left(-\\frac{\\beta\\kappa}{2}\\xi^2\\right) \\mathrm{d}\\xi$$\n因此，参考PDF为：\n$$p_{\\text{ref}}(\\xi) = C_{\\text{ref}} \\xi^{d-1} \\exp\\left(-\\frac{\\beta\\kappa}{2}\\xi^2\\right)$$\n其中$C_{\\text{ref}} = C_{FG} S_{d}$是粗粒度分布的新归一化常数。\n\n问题中指出了一个与映射相关的“雅可比因子”$J(\\xi)$。该因子代表了由降维引起的对测度的几何贡献。根据上述推导，$\\xi$的概率密度正比于在半径$\\xi$处计算的细粒度密度乘以半径为$\\xi$的超球面的表面积，而后者正比于$\\xi^{d-1}$。因此，雅可比因子的函数形式为$J(\\xi) \\propto \\xi^{d-1}$。\n\n**第2部分：模型PDF $p_{\\theta}(\\xi)$的表达式**\n\n粗粒度模型由势能$U_{\\text{cg}}(\\xi; k) = \\frac{k}{2}\\xi^{2} - (d-1)k_{B}T \\ln \\xi$定义。相应的模型PDF $p_{\\theta}(\\xi)$正比于$\\exp(-\\beta U_{\\text{cg}}(\\xi; k))$：\n$$p_{\\theta}(\\xi) \\propto \\exp\\left(-\\beta \\left[ \\frac{k}{2}\\xi^{2} - (d-1)k_{B}T \\ln \\xi \\right]\\right)$$\n使用恒等式$\\beta k_B T = 1$，我们可以简化指数部分：\n$$-\\beta U_{\\text{cg}}(\\xi; k) = -\\frac{\\beta k}{2}\\xi^{2} + \\beta(d-1)k_{B}T \\ln \\xi = -\\frac{\\beta k}{2}\\xi^{2} + (d-1) \\ln \\xi$$\n将此代回$p_{\\theta}(\\xi)$的表达式中：\n$$p_{\\theta}(\\xi) \\propto \\exp\\left(-\\frac{\\beta k}{2}\\xi^{2} + (d-1) \\ln \\xi\\right) = \\exp\\left(-\\frac{\\beta k}{2}\\xi^{2}\\right) \\exp\\left(\\ln \\xi^{d-1}\\right)$$\n这可以简化为：\n$$p_{\\theta}(\\xi) = C_{\\theta}(k) \\xi^{d-1} \\exp\\left(-\\frac{\\beta k}{2}\\xi^2\\right)$$\n其中$C_{\\theta}(k)$是模型PDF的归一化常数，它依赖于参数$k$。\n\n**第3部分：$D_{\\text{KL}}(p_{\\text{ref}} \\| p_{\\theta})$的显式表达式**\n\n库尔贝克-莱布勒散度的定义为：\n$$D_{\\text{KL}}(p_{\\text{ref}} \\| p_{\\theta}) = \\int_{0}^{\\infty} p_{\\text{ref}}(\\xi)\\,\\ln\\left(\\frac{p_{\\text{ref}}(\\xi)}{p_{\\theta}(\\xi)}\\right)\\,\\mathrm{d}\\xi$$\n我们首先计算对数项：\n$$\\frac{p_{\\text{ref}}(\\xi)}{p_{\\theta}(\\xi)} = \\frac{C_{\\text{ref}} \\xi^{d-1} \\exp(-\\frac{\\beta\\kappa}{2}\\xi^2)}{C_{\\theta}(k) \\xi^{d-1} \\exp(-\\frac{\\beta k}{2}\\xi^2)} = \\frac{C_{\\text{ref}}}{C_{\\theta}(k)} \\exp\\left(\\frac{\\beta}{2}(k-\\kappa)\\xi^2\\right)$$\n$$\\ln\\left(\\frac{p_{\\text{ref}}(\\xi)}{p_{\\theta}(\\xi)}\\right) = \\ln\\left(\\frac{C_{\\text{ref}}}{C_{\\theta}(k)}\\right) + \\frac{\\beta}{2}(k-\\kappa)\\xi^2$$\n将此代入KLD表达式：\n$$D_{\\text{KL}}(k) = \\int_{0}^{\\infty} p_{\\text{ref}}(\\xi) \\left[ \\ln\\left(\\frac{C_{\\text{ref}}}{C_{\\theta}(k)}\\right) + \\frac{\\beta}{2}(k-\\kappa)\\xi^2 \\right] \\mathrm{d}\\xi$$\n$$D_{\\text{KL}}(k) = \\ln\\left(\\frac{C_{\\text{ref}}}{C_{\\theta}(k)}\\right) \\int_{0}^{\\infty} p_{\\text{ref}}(\\xi) \\mathrm{d}\\xi + \\frac{\\beta}{2}(k-\\kappa) \\int_{0}^{\\infty} \\xi^2 p_{\\text{ref}}(\\xi) \\mathrm{d}\\xi$$\n由于$p_{\\text{ref}}$的归一化，第一个积分为$1$。第二个积分是期望值$\\langle \\xi^2 \\rangle_{p_{\\text{ref}}}$。\n$$D_{\\text{KL}}(k) = \\ln\\left(\\frac{C_{\\text{ref}}}{C_{\\theta}(k)}\\right) + \\frac{\\beta}{2}(k-\\kappa) \\langle \\xi^2 \\rangle_{p_{\\text{ref}}}$$\n为了继续，我们需要归一化常数的比值和$\\langle \\xi^2 \\rangle_{p_{\\text{ref}}}$。我们使用定积分公式$\\int_{0}^{\\infty} x^n \\exp(-ax^2) \\mathrm{d}x = \\frac{\\Gamma((n+1)/2)}{2a^{(n+1)/2}}$。\n归一化常数由$\\int_0^\\infty p(\\xi) d\\xi = 1$求得：\n$$C_{\\text{ref}}^{-1} = \\int_{0}^{\\infty} \\xi^{d-1} \\exp(-\\frac{\\beta\\kappa}{2}\\xi^2)\\mathrm{d}\\xi = \\frac{\\Gamma(d/2)}{2(\\beta\\kappa/2)^{d/2}}$$\n$$C_{\\theta}(k)^{-1} = \\int_{0}^{\\infty} \\xi^{d-1} \\exp(-\\frac{\\beta k}{2}\\xi^2)\\mathrm{d}\\xi = \\frac{\\Gamma(d/2)}{2(\\beta k/2)^{d/2}}$$\n该比值为$\\frac{C_{\\text{ref}}}{C_{\\theta}(k)} = \\left(\\frac{\\kappa}{k}\\right)^{d/2}$，因此$\\ln\\left(\\frac{C_{\\text{ref}}}{C_{\\theta}(k)}\\right) = \\frac{d}{2}\\ln\\left(\\frac{\\kappa}{k}\\right)$。\n\n接下来，我们计算期望值：\n$$\\langle \\xi^2 \\rangle_{p_{\\text{ref}}} = C_{\\text{ref}} \\int_{0}^{\\infty} \\xi^{d+1} \\exp(-\\frac{\\beta\\kappa}{2}\\xi^2) \\mathrm{d}\\xi$$\n该积分为$\\frac{\\Gamma((d+2)/2)}{2(\\beta\\kappa/2)^{(d+2)/2}} = \\frac{(d/2)\\Gamma(d/2)}{2(\\beta\\kappa/2)^{d/2+1}}$。\n$$\\langle \\xi^2 \\rangle_{p_{\\text{ref}}} = \\frac{2(\\beta\\kappa/2)^{d/2}}{\\Gamma(d/2)} \\cdot \\frac{(d/2)\\Gamma(d/2)}{2(\\beta\\kappa/2)^{d/2}(\\beta\\kappa/2)} = \\frac{d/2}{\\beta\\kappa/2} = \\frac{d}{\\beta\\kappa}$$\n这个结果与能量均分定理一致。将这些代入$D_{\\text{KL}}$的表达式：\n$$D_{\\text{KL}}(k) = \\frac{d}{2}\\ln\\left(\\frac{\\kappa}{k}\\right) + \\frac{\\beta}{2}(k-\\kappa) \\frac{d}{\\beta\\kappa} = \\frac{d}{2}\\ln\\left(\\frac{\\kappa}{k}\\right) + \\frac{d(k-\\kappa)}{2\\kappa}$$\n这就是KLD作为$k$的函数的显式表达式：\n$$D_{\\text{KL}}(k) = \\frac{d}{2}(\\ln\\kappa - \\ln k) + \\frac{d}{2\\kappa}k - \\frac{d}{2}$$\n\n**第4部分：最优参数$k$的确定**\n\n为了找到使$D_{\\text{KL}}(k)$最小的$k$值，我们对$k$求导并令结果为零：\n$$\\frac{\\mathrm{d}}{\\mathrm{d}k} D_{\\text{KL}}(k) = \\frac{\\mathrm{d}}{\\mathrm{d}k} \\left[ \\frac{d}{2}(\\ln\\kappa - \\ln k) + \\frac{d}{2\\kappa}k - \\frac{d}{2} \\right]$$\n$$\\frac{\\mathrm{d}}{\\mathrm{d}k} D_{\\text{KL}}(k) = \\frac{d}{2}\\left(-\\frac{1}{k}\\right) + \\frac{d}{2\\kappa} = \\frac{d}{2}\\left(\\frac{1}{\\kappa} - \\frac{1}{k}\\right)$$\n将导数设为零（对于$d>0$）：\n$$\\frac{1}{\\kappa} - \\frac{1}{k} = 0 \\implies \\frac{1}{k} = \\frac{1}{\\kappa} \\implies k = \\kappa$$\n为了确认这是一个最小值，我们检查二阶导数：\n$$\\frac{\\mathrm{d}^2}{\\mathrm{d}k^2} D_{\\text{KL}}(k) = \\frac{\\mathrm{d}}{\\mathrm{d}k} \\left[ \\frac{d}{2}\\left(\\frac{1}{\\kappa} - \\frac{1}{k}\\right) \\right] = \\frac{d}{2k^2}$$\n由于$d>0$且$k>0$，二阶导数严格为正，这证实了$k=\\kappa$是一个全局最小值。这个结果是符合预期的，因为当模型分布$p_{\\theta}(\\xi)$与参考分布$p_{\\text{ref}}(\\xi)$完全相同时，KL散度达到最小值（值为$0$），而这正是在$k=\\kappa$时发生。\n\n使库尔贝克-莱布勒散度最小化的刚度参数是$k=\\kappa$。",
            "answer": "$$\\boxed{\\kappa}$$"
        },
        {
            "introduction": "在掌握了分析推导的基础后，我们将转向 REM 的计算核心。大多数现实世界中的 REM 问题都需要通过基于梯度的数值优化方法来求解。本练习聚焦于推导并实现优化过程中的关键要素——相对熵的梯度 ($\\nabla_{\\boldsymbol{\\theta}} D_{\\mathrm{KL}}$) 和 Hessian 矩阵 ($\\nabla^2_{\\boldsymbol{\\theta}} D_{\\mathrm{KL}}$)——这适用于一类常见的离散粗粒化模型。掌握这一步骤是构建高效 REM 工作流程的关键。",
            "id": "3838736",
            "problem": "考虑一个材料的粗粒化模型，其中微观构型已被映射到由 $i \\in \\{1,\\dots,N\\}$ 索引的有限离散粗粒化状态集。每个粗粒化状态 $i$ 由一个特征向量 $\\boldsymbol{\\phi}_i \\in \\mathbb{R}^d$ 描述。定义一个参数化粗粒化势为 $U_{\\boldsymbol{\\theta}}(i) = \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_i$，其中 $\\boldsymbol{\\theta} \\in \\mathbb{R}^d$ 是待优化的参数。在逆温度 $\\beta = 1/(k_{\\mathrm{B}} T)$ 下，粗粒化状态上的模型分布是 Boltzmann 分布 $p_{\\boldsymbol{\\theta}}(i) = \\exp(-\\beta U_{\\boldsymbol{\\theta}}(i)) / Z(\\boldsymbol{\\theta})$，其配分函数为 $Z(\\boldsymbol{\\theta}) = \\sum_{j=1}^N \\exp(-\\beta U_{\\boldsymbol{\\theta}}(j))$。这些状态上的目标分布 $q(i)$ 是通过原子模拟的统计稳健映射获得的，在此被视为给定。优化目标是相对熵最小化 (REM)，即最小化 Kullback-Leibler 散度 $D_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}})$。\n\n从 Boltzmann 分布、配分函数和 Kullback-Leibler 散度的基本定义出发：\n- $p_{\\boldsymbol{\\theta}}(i) = \\exp(-\\beta U_{\\boldsymbol{\\theta}}(i)) / Z(\\boldsymbol{\\theta})$,\n- $Z(\\boldsymbol{\\theta}) = \\sum_{j=1}^N \\exp(-\\beta U_{\\boldsymbol{\\theta}}(j))$,\n- $D_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}}) = \\sum_{i=1}^N q(i) \\log\\left( \\frac{q(i)}{p_{\\boldsymbol{\\theta}}(i)} \\right)$,\n请从第一性原理出发，推导梯度 $\\nabla_{\\boldsymbol{\\theta}} D_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}})$ 和 Hessian 矩阵 $\\nabla^2_{\\boldsymbol{\\theta}} D_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}})$ 的表达式，并用关于 $q$ 和 $p_{\\boldsymbol{\\theta}}$ 的期望来表示。推导过程必须仅依赖于这些定义以及微分和对数的标准性质；不要假定或调用任何快捷公式。\n\n然后，实现一个程序，使用推导出的公式为下述每个测试用例计算 $D_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}})$ 的梯度和 Hessian 矩阵。对于大的 $\\beta$，通过对指数项进行适当的归一化，使用数值稳定的方法计算 $p_{\\boldsymbol{\\theta}}$。输出中无需报告物理单位；所有量都是无量纲的。\n\n测试套件：\n- 测试用例 1 (一般情况)：\n  - $N = 5$, $d = 3$,\n  - $\\Phi = \\begin{bmatrix}\n  0.1  0.5  -0.3 \\\\\n  0.0  -0.2  0.8 \\\\\n  1.2  0.7  0.4 \\\\\n  -0.6  0.9  -1.1 \\\\\n  0.3  -0.4  0.2\n  \\end{bmatrix}$,\n  - $\\boldsymbol{q} = \\begin{bmatrix}0.05 \\\\ 0.15 \\\\ 0.40 \\\\ 0.30 \\\\ 0.10 \\end{bmatrix}$,\n  - $\\beta = 2.0$,\n  - $\\boldsymbol{\\theta} = \\begin{bmatrix}0.7 \\\\ -0.3 \\\\ 0.5 \\end{bmatrix}$。\n\n- 测试用例 2 (边界情况，共线特征导致协方差矩阵秩亏)：\n  - $N = 4$, $d = 2$,\n  - $\\Phi = \\begin{bmatrix}\n  1.0  2.0 \\\\\n  2.0  4.0 \\\\\n  3.0  6.0 \\\\\n  4.0  8.0\n  \\end{bmatrix}$,\n  - $\\boldsymbol{q} = \\begin{bmatrix}0.25 \\\\ 0.25 \\\\ 0.25 \\\\ 0.25 \\end{bmatrix}$,\n  - $\\beta = 1.0$,\n  - $\\boldsymbol{\\theta} = \\begin{bmatrix}0.0 \\\\ 0.0 \\end{bmatrix}$。\n\n- 测试用例 3 (边缘情况，大 $\\beta$ 导致 $p_{\\boldsymbol{\\theta}}$ 集中)：\n  - $N = 6$, $d = 2$,\n  - $\\Phi = \\begin{bmatrix}\n  -1.0  0.5 \\\\\n  0.2  -0.1 \\\\\n  0.0  0.0 \\\\\n  0.8  1.2 \\\\\n  -0.5  2.0 \\\\\n  1.5  -1.0\n  \\end{bmatrix}$,\n  - $\\boldsymbol{q} = \\begin{bmatrix}0.10 \\\\ 0.20 \\\\ 0.10 \\\\ 0.10 \\\\ 0.30 \\\\ 0.20 \\end{bmatrix}$,\n  - $\\beta = 50.0$,\n  - $\\boldsymbol{\\theta} = \\begin{bmatrix}0.05 \\\\ -0.02 \\end{bmatrix}$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。顶层列表的每个元素对应一个测试用例，并且必须是一个浮点数列表。对于一个给定的特征维度为 $d$ 的测试用例，该列表必须按以下顺序包含 $d + d^2$ 个数字：\n- 梯度 $\\nabla_{\\boldsymbol{\\theta}} D_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}})$ 的 $d$ 个分量，\n- 接着是按行主序展开的 Hessian 矩阵 $\\nabla^2_{\\boldsymbol{\\theta}} D_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}})$ 的 $d^2$ 个分量。\n\n例如，如果一个测试用例的 $d = 2$，则该用例的列表必须有 $2 + 4 = 6$ 个数字：$[\\text{grad}_1, \\text{grad}_2, \\text{H}_{11}, \\text{H}_{12}, \\text{H}_{21}, \\text{H}_{22}]$。打印的输出必须是包含上述三个测试用例的此类列表的列表，并按给定顺序排列。",
            "solution": "我们从粗粒化统计模型的定义元素开始。粗粒化势为 $U_{\\boldsymbol{\\theta}}(i) = \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_i$，其中 $\\boldsymbol{\\theta} \\in \\mathbb{R}^d$ 且 $\\boldsymbol{\\phi}_i \\in \\mathbb{R}^d$。在逆温度 $\\beta$ 下，离散集 $\\{1,\\dots,N\\}$ 上的 Boltzmann 分布为\n$$\np_{\\boldsymbol{\\theta}}(i) = \\frac{\\exp\\left(-\\beta U_{\\boldsymbol{\\theta}}(i)\\right)}{Z(\\boldsymbol{\\theta})}\n= \\frac{\\exp\\left(-\\beta \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_i\\right)}{\\sum_{j=1}^N \\exp\\left(-\\beta \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_j\\right)},\n$$\n其配分函数为\n$$\nZ(\\boldsymbol{\\theta}) = \\sum_{j=1}^N \\exp\\left(-\\beta \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_j\\right).\n$$\n从目标分布 $q$ 到模型的 Kullback-Leibler 散度（相对熵）为\n$$\nD_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}}) = \\sum_{i=1}^N q(i) \\log\\left(\\frac{q(i)}{p_{\\boldsymbol{\\theta}}(i)}\\right).\n$$\n\n我们使用 $p_{\\boldsymbol{\\theta}}$ 的定义展开 $D_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}})$。首先，注意到\n$$\n\\log p_{\\boldsymbol{\\theta}}(i) = -\\beta \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_i - \\log Z(\\boldsymbol{\\theta}).\n$$\n因此，\n\\begin{align*}\nD_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}})\n= \\sum_{i=1}^N q(i) \\log q(i) - \\sum_{i=1}^N q(i) \\log p_{\\boldsymbol{\\theta}}(i) \\\\\n= \\sum_{i=1}^N q(i) \\log q(i) - \\sum_{i=1}^N q(i)\\left(-\\beta \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_i - \\log Z(\\boldsymbol{\\theta})\\right) \\\\\n= \\underbrace{\\sum_{i=1}^N q(i) \\log q(i)}_{\\text{关于 } \\boldsymbol{\\theta} \\text{ 的常数}} + \\beta \\sum_{i=1}^N q(i)\\,\\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_i + \\bigg(\\sum_{i=1}^N q(i)\\bigg)\\log Z(\\boldsymbol{\\theta}).\n\\end{align*}\n因为 $\\sum_{i=1}^N q(i) = 1$，这可以简化为\n$$\nD_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}}) = \\text{const} + \\beta\\, \\boldsymbol{\\theta} \\cdot \\mathbb{E}_{q}[\\boldsymbol{\\phi}] + \\log Z(\\boldsymbol{\\theta}),\n$$\n其中 $\\mathbb{E}_{q}[\\boldsymbol{\\phi}] = \\sum_{i=1}^N q(i)\\,\\boldsymbol{\\phi}_i$。\n\n我们现在计算关于 $\\boldsymbol{\\theta}$ 的梯度。常数项的导数为零，线性项的导数就是\n$$\n\\nabla_{\\boldsymbol{\\theta}} \\left( \\beta\\, \\boldsymbol{\\theta} \\cdot \\mathbb{E}_{q}[\\boldsymbol{\\phi}] \\right)\n= \\beta\\, \\mathbb{E}_{q}[\\boldsymbol{\\phi}].\n$$\n对于配分函数项，我们使用关于 $\\log Z(\\boldsymbol{\\theta})$ 梯度的标准恒等式：\n\\begin{align*}\n\\nabla_{\\boldsymbol{\\theta}} \\log Z(\\boldsymbol{\\theta})\n= \\frac{1}{Z(\\boldsymbol{\\theta})} \\nabla_{\\boldsymbol{\\theta}} Z(\\boldsymbol{\\theta})\n= \\frac{1}{Z(\\boldsymbol{\\theta})} \\sum_{j=1}^N \\nabla_{\\boldsymbol{\\theta}} \\exp\\left(-\\beta \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_j\\right) \\\\\n= \\frac{1}{Z(\\boldsymbol{\\theta})} \\sum_{j=1}^N \\left(-\\beta \\boldsymbol{\\phi}_j\\right)\\exp\\left(-\\beta \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_j\\right)\n= -\\beta \\sum_{j=1}^N p_{\\boldsymbol{\\theta}}(j)\\,\\boldsymbol{\\phi}_j \\\\\n= -\\beta\\, \\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}].\n\\end{align*}\n结合这些结果，得到梯度\n$$\n\\nabla_{\\boldsymbol{\\theta}} D_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}})\n= \\beta\\, \\mathbb{E}_{q}[\\boldsymbol{\\phi}] - \\beta\\, \\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}]\n= \\beta\\left(\\mathbb{E}_{q}[\\boldsymbol{\\phi}] - \\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}]\\right).\n$$\n\n对于 Hessian 矩阵，我们对梯度进行微分。因为 $q$ 是固定的，所以项 $\\beta\\, \\mathbb{E}_{q}[\\boldsymbol{\\phi}]$ 关于 $\\boldsymbol{\\theta}$ 是常数，其导数为零。我们必须对 $- \\beta\\, \\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}]$ 关于 $\\boldsymbol{\\theta}$ 求导。让我们逐分量地计算二阶导数矩阵。用 $\\phi_{i,k}$ 表示 $\\boldsymbol{\\phi}_i$ 的第 $k$ 个分量。$\\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}]$ 的第 $k$ 个分量是 $\\sum_{i=1}^N p_{\\boldsymbol{\\theta}}(i) \\phi_{i,k}$。它关于 $\\theta_\\ell$ 的导数是\n\\begin{align*}\n\\frac{\\partial}{\\partial \\theta_\\ell} \\left( \\sum_{i=1}^N p_{\\boldsymbol{\\theta}}(i) \\phi_{i,k} \\right)\n= \\sum_{i=1}^N \\phi_{i,k} \\frac{\\partial p_{\\boldsymbol{\\theta}}(i)}{\\partial \\theta_\\ell}.\n\\end{align*}\n根据定义，\n$$\np_{\\boldsymbol{\\theta}}(i) = \\frac{\\exp(-\\beta \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_i)}{Z(\\boldsymbol{\\theta})},\n$$\n我们有\n\\begin{align*}\n\\frac{\\partial p_{\\boldsymbol{\\theta}}(i)}{\\partial \\theta_\\ell}\n= \\frac{-\\beta \\phi_{i,\\ell}\\exp(-\\beta \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_i)}{Z(\\boldsymbol{\\theta})}\n- \\frac{\\exp(-\\beta \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_i)}{Z(\\boldsymbol{\\theta})^2}\n\\frac{\\partial Z(\\boldsymbol{\\theta})}{\\partial \\theta_\\ell} \\\\\n= -\\beta \\phi_{i,\\ell} p_{\\boldsymbol{\\theta}}(i)\n- p_{\\boldsymbol{\\theta}}(i)\\left( -\\beta \\sum_{j=1}^N p_{\\boldsymbol{\\theta}}(j)\\phi_{j,\\ell} \\right) \\\\\n= -\\beta p_{\\boldsymbol{\\theta}}(i)\\left( \\phi_{i,\\ell} - \\sum_{j=1}^N p_{\\boldsymbol{\\theta}}(j)\\phi_{j,\\ell} \\right).\n\\end{align*}\n因此，\n\\begin{align*}\n\\frac{\\partial}{\\partial \\theta_\\ell} \\left( \\sum_{i=1}^N p_{\\boldsymbol{\\theta}}(i) \\phi_{i,k} \\right)\n= \\sum_{i=1}^N \\phi_{i,k} \\left[ -\\beta p_{\\boldsymbol{\\theta}}(i)\\left( \\phi_{i,\\ell} - \\sum_{j=1}^N p_{\\boldsymbol{\\theta}}(j)\\phi_{j,\\ell} \\right) \\right] \\\\\n= -\\beta \\left[ \\sum_{i=1}^N p_{\\boldsymbol{\\theta}}(i) \\phi_{i,k} \\phi_{i,\\ell} - \\left( \\sum_{i=1}^N p_{\\boldsymbol{\\theta}}(i) \\phi_{i,k} \\right)\\left( \\sum_{j=1}^N p_{\\boldsymbol{\\theta}}(j)\\phi_{j,\\ell} \\right) \\right].\n\\end{align*}\n这是 $\\beta$ 乘以 $\\boldsymbol{\\phi}$ 在 $p_{\\boldsymbol{\\theta}}$ 分布下的协方差的 $(k,\\ell)$ 分量的负值。因此，Hessian 矩阵是\n$$\n\\nabla^2_{\\boldsymbol{\\theta}} D_{\\mathrm{KL}}(q \\| p_{\\boldsymbol{\\theta}})\n= \\beta^2\\, \\mathrm{Cov}_{p_{\\boldsymbol{\\theta}}}(\\boldsymbol{\\phi}),\n$$\n其中\n$$\n\\mathrm{Cov}_{p_{\\boldsymbol{\\theta}}}(\\boldsymbol{\\phi}) = \\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}\\boldsymbol{\\phi}^\\top] - \\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}]\\, \\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}]^\\top.\n$$\n\n计算的算法设计：\n- 使用类似 softmax 的数值稳定变换来计算模型概率 $p_{\\boldsymbol{\\theta}}(i)$。具体来说，令 $s_i = -\\beta\\, \\boldsymbol{\\theta} \\cdot \\boldsymbol{\\phi}_i$。从所有 $s_i$ 中减去 $\\max_i s_i$ 以防止溢出，然后取指数得到未归一化的权重，再除以它们的和进行归一化。\n- 计算 $\\mathbb{E}_{q}[\\boldsymbol{\\phi}] = \\sum_{i=1}^N q(i)\\,\\boldsymbol{\\phi}_i$ 和 $\\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}] = \\sum_{i=1}^N p_{\\boldsymbol{\\theta}}(i)\\,\\boldsymbol{\\phi}_i$。\n- 构建梯度 $\\boldsymbol{g} = \\beta (\\mathbb{E}_{q}[\\boldsymbol{\\phi}] - \\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}])$。\n- 计算二阶矩 $\\mathbb{E}_{p_{\\boldsymbol{\\theta}}}[\\boldsymbol{\\phi}\\boldsymbol{\\phi}^\\top] = \\sum_{i=1}^N p_{\\boldsymbol{\\theta}}(i)\\,\\boldsymbol{\\phi}_i \\boldsymbol{\\phi}_i^\\top$ 和协方差 $\\mathrm{Cov}_{p_{\\boldsymbol{\\theta}}}(\\boldsymbol{\\phi})$，然后计算 Hessian 矩阵 $\\boldsymbol{H} = \\beta^2 \\mathrm{Cov}_{p_{\\boldsymbol{\\theta}}}(\\boldsymbol{\\phi})$。\n- 将 Hessian 矩阵按行主序展开，并将其连接在梯度之后，形成长度为 $d + d^2$ 的每个用例的输出列表。\n\n数值稳定性考虑：\n- 对于大的 $\\beta$，未归一化的权重 $\\exp(s_i)$ 可能极小或极大。通过将 $s_i$ 减去它们的最大值来平移，可以确保最大的指数变为 $\\exp(0) = 1$，而其他指数都 $\\le 1$，从而防止溢出并保持比率。\n- 在特征完全共线的边界情况下，协方差（以及 Hessian 矩阵）是秩亏的；这是预期的，代表了目标函数中曲率为零的方向。\n\n实现直接遵循这些推导出的表达式，并为每个测试用例生成所需格式的梯度和 Hessian 矩阵分量。无需物理单位，因为在这个离散统计设定中，所有量本质上都是无量纲的。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef stable_boltzmann_probs(beta: float, theta: np.ndarray, Phi: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Compute p_theta(i) proportional to exp(-beta * theta dot phi_i) in a numerically stable way.\n    Phi: shape (N, d)\n    theta: shape (d,)\n    Returns p: shape (N,)\n    \"\"\"\n    # s_i = -beta * (theta · phi_i)\n    s = -beta * (Phi @ theta)\n    # Shift by max for numerical stability\n    s_shift = s - np.max(s)\n    w = np.exp(s_shift)\n    Z = np.sum(w)\n    # Normalize to get probabilities\n    p = w / Z\n    return p\n\ndef grad_hess_rem(beta: float, theta: np.ndarray, Phi: np.ndarray, q: np.ndarray):\n    \"\"\"\n    Compute gradient and Hessian of D_KL(q || p_theta) for discrete states with features Phi.\n    beta: scalar\n    theta: (d,)\n    Phi: (N, d)\n    q: (N,)\n    Returns:\n      grad: (d,)\n      hess: (d, d)\n    \"\"\"\n    # Model probabilities\n    p = stable_boltzmann_probs(beta, theta, Phi)\n    # Expectations under q and p\n    # E_q[phi] and E_p[phi]\n    E_q_phi = Phi.T @ q  # shape (d,)\n    E_p_phi = Phi.T @ p  # shape (d,)\n    # Gradient\n    grad = beta * (E_q_phi - E_p_phi)\n    # Second moment under p: sum_i p_i * phi_i phi_i^T\n    # Compute weighted outer products efficiently\n    # Shape (d, d)\n    # Use broadcasting: (N, d) * (N, 1) -> (N, d), then Phi.T @ (weighted Phi) to obtain sum_i p_i phi_i phi_i^T\n    weighted_Phi = Phi * p[:, None]\n    E_p_phi_phiT = Phi.T @ weighted_Phi\n    # Covariance under p\n    cov_p = E_p_phi_phiT - np.outer(E_p_phi, E_p_phi)\n    # Hessian\n    hess = (beta ** 2) * cov_p\n    return grad, hess\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (beta, theta, Phi, q)\n    test_cases = []\n\n    # Test Case 1\n    beta1 = 2.0\n    theta1 = np.array([0.7, -0.3, 0.5], dtype=float)\n    Phi1 = np.array([\n        [0.1, 0.5, -0.3],\n        [0.0, -0.2, 0.8],\n        [1.2, 0.7, 0.4],\n        [-0.6, 0.9, -1.1],\n        [0.3, -0.4, 0.2]\n    ], dtype=float)\n    q1 = np.array([0.05, 0.15, 0.40, 0.30, 0.10], dtype=float)\n\n    test_cases.append((beta1, theta1, Phi1, q1))\n\n    # Test Case 2 (collinear features, rank-deficient covariance)\n    beta2 = 1.0\n    theta2 = np.array([0.0, 0.0], dtype=float)\n    Phi2 = np.array([\n        [1.0, 2.0],\n        [2.0, 4.0],\n        [3.0, 6.0],\n        [4.0, 8.0]\n    ], dtype=float)\n    q2 = np.array([0.25, 0.25, 0.25, 0.25], dtype=float)\n\n    test_cases.append((beta2, theta2, Phi2, q2))\n\n    # Test Case 3 (large beta)\n    beta3 = 50.0\n    theta3 = np.array([0.05, -0.02], dtype=float)\n    Phi3 = np.array([\n        [-1.0,  0.5],\n        [ 0.2, -0.1],\n        [ 0.0,  0.0],\n        [ 0.8,  1.2],\n        [-0.5,  2.0],\n        [ 1.5, -1.0]\n    ], dtype=float)\n    q3 = np.array([0.10, 0.20, 0.10, 0.10, 0.30, 0.20], dtype=float)\n\n    test_cases.append((beta3, theta3, Phi3, q3))\n\n    results = []\n    for beta, theta, Phi, q in test_cases:\n        grad, hess = grad_hess_rem(beta, theta, Phi, q)\n        # Flatten result: gradient components followed by Hessian flattened row-major.\n        per_case = grad.tolist() + hess.flatten(order='C').tolist()\n        results.append(per_case)\n\n    # Final print statement in the exact required format.\n    # Print a single top-level list of per-case lists.\n    print(f\"[{','.join('[' + ','.join(map(str, case)) + ']' for case in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "相对熵最小化是众多“自上而下”粗粒化策略中的一种。为了培养对方法选择的批判性思维，本练习将 REM 与另一种流行的方法——力匹配 (Force Matching, FM)——进行了直接比较。你将通过一个具体的例子发现，不同的优化准则会如何导致不同的模型参数，尤其是在处理复杂的潜在力场时。这有助于你更深刻地理解如何根据具体的科学问题选择最合适的粗粒化方法。",
            "id": "3456643",
            "problem": "考虑一个一维粗粒化变量 $q$，该变量已经无量纲化，因此 $q$ 的原子级参考平衡分布是标准正态玻尔兹曼分布 $p_{\\mathrm{ref}}(q) = (2\\pi)^{-1/2} \\exp(-q^{2}/2)$，对应的参考势为 $U_{\\mathrm{ref}}(q) = q^{2}/2$。您需要寻找一个具有非线性四次势 $U_{\\theta}(q) = \\theta\\, q^{4}$ 的自顶向下粗粒化模型。\n\n两种常见的自顶向下参数估计准则是相对熵最小化 (REM) 和力匹配 (FM)。在 REM 中，需要最小化从参考玻尔兹曼分布到模型玻尔兹曼分布 $p_{\\theta}(q) \\propto \\exp(-U_{\\theta}(q))$ 的 Kullback–Leibler 散度。在 FM 中，需要最小化模型力与从参考动力学中采样的含噪瞬时力之间的均方差。假设瞬时力数据服从随机模型\n$$\n\\mathcal{F}(q) \\equiv -\\frac{\\partial U_{\\mathrm{ref}}}{\\partial q}(q) + s\\, q^{3} + \\varepsilon = -q + s\\, q^{3} + \\varepsilon,\n$$\n其中 $s$ 是一个固定的无量纲振幅，用于捕捉由消除的自由度产生的状态依赖（异方差）噪声，而 $\\varepsilon$ 是一个零均值残差，满足 $\\mathbb{E}[\\varepsilon \\mid q] = 0$，且独立于 $q$ 并具有有限方差。FM 的目标是在参考分布下的均方误差，\n$$\nJ(\\theta) = \\mathbb{E}_{p_{\\mathrm{ref}}}\\!\\left[\\left(-\\frac{\\partial U_{\\theta}}{\\partial q}(q) - \\mathcal{F}(q)\\right)^{2}\\right].\n$$\n\n仅从上述定义和高斯分布 $p_{\\mathrm{ref}}(q)$ 的标准性质出发，完成以下任务：\n\n1. 推导 $\\theta$ 的 REM 一阶最优性条件，并精确求解以获得 $\\theta_{\\mathrm{REM}}$。\n2. 在给定的含噪力模型下，推导 $\\theta$ 的 FM 正规方程，并精确求解以获得作为 $s$ 函数的 $\\theta_{\\mathrm{FM}}$。\n\n您必须明确地进行所有必要的积分，并从第一性原理出发论证每一步。请以单行矩阵的形式提供您的最终答案，其中包含两个优化后的参数值 $\\theta_{\\mathrm{REM}}$ 和 $\\theta_{\\mathrm{FM}}$ 的精确解析形式。不需要进行数值取整，也不需要单位，因为根据设定，所有量都是无量纲的。",
            "solution": "本题要求使用两种不同的方法：相对熵最小化 (REM) 和力匹配 (FM)，来为粗粒化势 $U_{\\theta}(q) = \\theta q^4$ 找到最优参数 $\\theta$。参考系统由一个标准正态玻尔兹曼分布描述。\n\n### 步骤 1：问题验证\n\n**1. 提取已知条件：**\n-   参考平衡分布：$p_{\\mathrm{ref}}(q) = (2\\pi)^{-1/2} \\exp(-q^{2}/2)$，即标准正态分布 $N(0, 1)$。\n-   参考势：$U_{\\mathrm{ref}}(q) = q^{2}/2$。分布由 $p_{\\mathrm{ref}}(q) \\propto \\exp(-U_{\\mathrm{ref}}(q))$ 给出。\n-   模型粗粒化势：$U_{\\theta}(q) = \\theta\\, q^{4}$。\n-   模型玻尔兹曼分布：$p_{\\theta}(q) \\propto \\exp(-U_{\\theta}(q))$。\n-   REM 准则：最小化从 $p_{\\mathrm{ref}}$ 到 $p_{\\theta}$ 的 Kullback-Leibler (KL) 散度，即 $S_{\\mathrm{KL}}(p_{\\mathrm{ref}} || p_{\\theta})$。\n-   FM 的瞬时力模型：$\\mathcal{F}(q) = -q + s\\, q^{3} + \\varepsilon$，其中 $s$ 是一个常数，$\\varepsilon$ 是一个随机变量，其在给定 $q$ 下的条件期望为零，$\\mathbb{E}[\\varepsilon \\mid q] = 0$。\n-   FM 目标函数：$J(\\theta) = \\mathbb{E}_{p_{\\mathrm{ref}}}\\!\\left[\\left(-\\frac{\\partial U_{\\theta}}{\\partial q}(q) - \\mathcal{F}(q)\\right)^{2}\\right]$。\n\n**2. 使用提取的已知条件进行验证：**\n-   **科学依据：** 该问题设置在统计力学和分子动力学粗粒化的既定理论框架内。相对熵最小化和力匹配是标准的、有据可查的技术。所使用的势和分布是常见的模型。\n-   **适定性：** 两个优化问题（REM 和 FM）都是适定的。它们涉及最小化参数 $\\theta$（或 $\\theta$ 的函数）的凸函数或二次函数，这会导出唯一解。问题是自洽的。\n-   **客观性：** 问题使用精确的数学语言和定义进行陈述，没有歧义或主观性。\n\n**3. 结论：**\n该问题是有效的，因为它是科学合理的、适定的和客观的。\n\n### 步骤 2：推导与求解\n\n#### 第 1 部分：相对熵最小化 (REM)\n\n目标是找到参数 $\\theta_{\\mathrm{REM}}$，以最小化从参考分布 $p_{\\mathrm{ref}}$ 到模型分布 $p_{\\theta}$ 的相对熵（或 Kullback-Leibler 散度）。相对熵定义为：\n$$\nS_{\\mathrm{KL}}(p_{\\mathrm{ref}} || p_{\\theta}) = \\int_{-\\infty}^{\\infty} p_{\\mathrm{ref}}(q) \\ln\\left(\\frac{p_{\\mathrm{ref}}(q)}{p_{\\theta}(q)}\\right) dq\n$$\n我们可以展开对数：\n$$\nS_{\\mathrm{KL}}(p_{\\mathrm{ref}} || p_{\\theta}) = \\int_{-\\infty}^{\\infty} p_{\\mathrm{ref}}(q) \\ln(p_{\\mathrm{ref}}(q)) dq - \\int_{-\\infty}^{\\infty} p_{\\mathrm{ref}}(q) \\ln(p_{\\theta}(q)) dq\n$$\n第一项 $\\int p_{\\mathrm{ref}}(q) \\ln(p_{\\mathrm{ref}}(q)) dq$ 是参考分布的负熵，相对于模型参数 $\\theta$ 是一个常数。因此，最小化 $S_{\\mathrm{KL}}$ 等价于最大化第二项 $\\int p_{\\mathrm{ref}}(q) \\ln(p_{\\theta}(q)) dq$。\n\n模型分布为 $p_{\\theta}(q) = \\frac{1}{Z_{\\theta}} \\exp(-U_{\\theta}(q))$，其中 $Z_{\\theta} = \\int_{-\\infty}^{\\infty} \\exp(-U_{\\theta}(q')) dq'$ 是配分函数。因此，$\\ln(p_{\\theta}(q)) = -U_{\\theta}(q) - \\ln(Z_{\\theta})$。\n最大化 $\\int p_{\\mathrm{ref}}(q) \\ln(p_{\\theta}(q)) dq$ 等价于最小化其负值：\n$$\nL(\\theta) = -\\int_{-\\infty}^{\\infty} p_{\\mathrm{ref}}(q) \\ln(p_{\\theta}(q)) dq = \\int_{-\\infty}^{\\infty} p_{\\mathrm{ref}}(q) [U_{\\theta}(q) + \\ln(Z_{\\theta})] dq\n$$\n$$\nL(\\theta) = \\mathbb{E}_{p_{\\mathrm{ref}}}[U_{\\theta}(q)] + \\ln(Z_{\\theta})\n$$\n代入 $U_{\\theta}(q) = \\theta q^{4}$：\n$$\nL(\\theta) = \\mathbb{E}_{p_{\\mathrm{ref}}}[\\theta q^{4}] + \\ln\\left(\\int_{-\\infty}^{\\infty} \\exp(-\\theta (q')^{4}) dq'\\right) = \\theta \\langle q^{4} \\rangle_{p_{\\mathrm{ref}}} + \\ln(Z_{\\theta})\n$$\n一阶最优性条件通过将 $L(\\theta)$ 对 $\\theta$ 的导数设为零来找到：\n$$\n\\frac{dL}{d\\theta} = \\langle q^{4} \\rangle_{p_{\\mathrm{ref}}} + \\frac{1}{Z_{\\theta}} \\frac{dZ_{\\theta}}{d\\theta} = 0\n$$\n我们计算配分函数的导数：\n$$\n\\frac{dZ_{\\theta}}{d\\theta} = \\frac{d}{d\\theta} \\int_{-\\infty}^{\\infty} \\exp(-\\theta q^{4}) dq = \\int_{-\\infty}^{\\infty} (-q^{4}) \\exp(-\\theta q^{4}) dq\n$$\n除以 $Z_{\\theta}$ 得到 $-q^{4}$ 相对于模型分布 $p_{\\theta}$ 的期望值：\n$$\n\\frac{1}{Z_{\\theta}} \\frac{dZ_{\\theta}}{d\\theta} = -\\frac{\\int_{-\\infty}^{\\infty} q^{4} \\exp(-\\theta q^{4}) dq}{\\int_{-\\infty}^{\\infty} \\exp(-\\theta q^{4}) dq} = -\\langle q^{4} \\rangle_{p_{\\theta}}\n$$\n因此，最优性条件简化为矩匹配条件：\n$$\n\\langle q^{4} \\rangle_{p_{\\mathrm{ref}}} - \\langle q^{4} \\rangle_{p_{\\theta}} = 0 \\implies \\langle q^{4} \\rangle_{p_{\\mathrm{ref}}} = \\langle q^{4} \\rangle_{p_{\\theta}}\n$$\n我们现在计算这两个期望值。\n对于参考分布 $p_{\\mathrm{ref}}(q)$，即标准正态分布 $N(0, 1)$，第 $n$ 阶矩 $\\langle q^n \\rangle$ 可以通过高斯随机变量 $X \\sim N(0, \\sigma^2)$ 的性质 $\\mathbb{E}[X^{2k}] = (2k-1)!! \\sigma^{2k}$ 求得。这里，$\\sigma=1$ 且我们需要第 4 阶矩（$k=2$）：\n$$\n\\langle q^{4} \\rangle_{p_{\\mathrm{ref}}} = (2 \\cdot 2 - 1)!! = 3!! = 3 \\times 1 = 3\n$$\n对于模型分布 $p_{\\theta}(q)$，期望为：\n$$\n\\langle q^{4} \\rangle_{p_{\\theta}} = \\frac{\\int_{-\\infty}^{\\infty} q^{4} \\exp(-\\theta q^{4}) dq}{\\int_{-\\infty}^{\\infty} \\exp(-\\theta q^{4}) dq}\n$$\n这些积分可以使用伽马函数积分公式 $\\int_{0}^{\\infty} x^{n-1} e^{-ax^k} dx = \\frac{1}{k} a^{-n/k} \\Gamma(n/k)$ 求解。由于被积函数是偶函数，我们可以写成 $\\int_{-\\infty}^{\\infty} (\\cdot) dq = 2 \\int_{0}^{\\infty} (\\cdot) dq$。\n分子：$2 \\int_{0}^{\\infty} q^{4} \\exp(-\\theta q^{4}) dq$。这里，$n-1=4 \\Rightarrow n=5$，$k=4$，$a=\\theta$。\n$$\n\\int_{-\\infty}^{\\infty} q^{4} \\exp(-\\theta q^{4}) dq = 2 \\left( \\frac{1}{4} \\theta^{-5/4} \\Gamma(5/4) \\right) = \\frac{1}{2} \\theta^{-5/4} \\Gamma(5/4)\n$$\n分母：$2 \\int_{0}^{\\infty} q^{0} \\exp(-\\theta q^{4}) dq$。这里，$n-1=0 \\Rightarrow n=1$，$k=4$，$a=\\theta$。\n$$\n\\int_{-\\infty}^{\\infty} \\exp(-\\theta q^{4}) dq = 2 \\left( \\frac{1}{4} \\theta^{-1/4} \\Gamma(1/4) \\right) = \\frac{1}{2} \\theta^{-1/4} \\Gamma(1/4)\n$$\n期望是这两个结果的比值：\n$$\n\\langle q^{4} \\rangle_{p_{\\theta}} = \\frac{\\frac{1}{2} \\theta^{-5/4} \\Gamma(5/4)}{\\frac{1}{2} \\theta^{-1/4} \\Gamma(1/4)} = \\theta^{-1} \\frac{\\Gamma(5/4)}{\\Gamma(1/4)}\n$$\n使用性质 $\\Gamma(z+1)=z\\Gamma(z)$，我们有 $\\Gamma(5/4) = \\Gamma(1/4 + 1) = \\frac{1}{4}\\Gamma(1/4)$。\n$$\n\\langle q^{4} \\rangle_{p_{\\theta}} = \\theta^{-1} \\frac{\\frac{1}{4}\\Gamma(1/4)}{\\Gamma(1/4)} = \\frac{1}{4\\theta}\n$$\n将这些期望值代入最优性条件：\n$$\n3 = \\frac{1}{4\\theta_{\\mathrm{REM}}} \\implies \\theta_{\\mathrm{REM}} = \\frac{1}{12}\n$$\n\n#### 第 2 部分：力匹配 (FM)\n\nFM 的目标是找到 $\\theta_{\\mathrm{FM}}$，以最小化模型力与瞬时力之间的均方误差，该误差在参考分布上取平均：\n$$\nJ(\\theta) = \\mathbb{E}_{p_{\\mathrm{ref}}}\\!\\left[\\left(-\\frac{\\partial U_{\\theta}}{\\partial q}(q) - \\mathcal{F}(q)\\right)^{2}\\right]\n$$\n模型力为 $F_{\\theta}(q) = -\\frac{\\partial U_{\\theta}}{\\partial q}(q) = -\\frac{d}{dq}(\\theta q^{4}) = -4\\theta q^{3}$。\n瞬时力为 $\\mathcal{F}(q) = -q + s\\, q^{3} + \\varepsilon$。\n将这些代入目标函数：\n$$\nJ(\\theta) = \\mathbb{E}_{p_{\\mathrm{ref}}}\\!\\left[\\left(-4\\theta q^{3} - (-q + s q^{3} + \\varepsilon)\\right)^{2}\\right] = \\mathbb{E}_{p_{\\mathrm{ref}}}\\!\\left[\\left(q - (4\\theta + s) q^{3} - \\varepsilon\\right)^{2}\\right]\n$$\n为了最小化 $J(\\theta)$，我们将其关于 $\\theta$ 的导数设为零（正规方程）：\n$$\n\\frac{dJ}{d\\theta} = \\frac{d}{d\\theta} \\mathbb{E}_{p_{\\mathrm{ref}}}\\!\\left[\\left(q - (4\\theta + s) q^{3} - \\varepsilon\\right)^{2}\\right] = 0\n$$\n交换期望和微分的顺序：\n$$\n\\frac{dJ}{d\\theta} = \\mathbb{E}_{p_{\\mathrm{ref}}}\\!\\left[ \\frac{d}{d\\theta} \\left(q - (4\\theta + s) q^{3} - \\varepsilon\\right)^{2} \\right]\n$$\n使用链式法则：\n$$\n\\frac{dJ}{d\\theta} = \\mathbb{E}_{p_{\\mathrm{ref}}}\\!\\left[ 2 \\left(q - (4\\theta + s) q^{3} - \\varepsilon\\right) \\cdot (-4 q^{3}) \\right] = 0\n$$\n忽略常数因子 $-8$，正规方程为：\n$$\n\\mathbb{E}_{p_{\\mathrm{ref}}}\\!\\left[ \\left(q - (4\\theta + s) q^{3} - \\varepsilon\\right) q^{3} \\right] = 0\n$$\n利用期望的线性性质：\n$$\n\\mathbb{E}_{p_{\\mathrm{ref}}}\\![q^{4}] - (4\\theta + s) \\mathbb{E}_{p_{\\mathrm{ref}}}\\![q^{6}] - \\mathbb{E}_{p_{\\mathrm{ref}}}\\![\\varepsilon q^{3}] = 0\n$$\n我们计算包含 $\\varepsilon$ 的期望。使用全期望定律和给定条件 $\\mathbb{E}[\\varepsilon \\mid q] = 0$：\n$$\n\\mathbb{E}_{p_{\\mathrm{ref}}}\\![\\varepsilon q^{3}] = \\mathbb{E}_{p_{\\mathrm{ref}}}\\![\\mathbb{E}[\\varepsilon q^{3} \\mid q]] = \\mathbb{E}_{p_{\\mathrm{ref}}}\\![q^{3} \\mathbb{E}[\\varepsilon \\mid q]] = \\mathbb{E}_{p_{\\mathrm{ref}}}\\![q^{3} \\cdot 0] = 0\n$$\n正规方程简化为：\n$$\n\\langle q^{4} \\rangle_{p_{\\mathrm{ref}}} - (4\\theta_{\\mathrm{FM}} + s) \\langle q^{6} \\rangle_{p_{\\mathrm{ref}}} = 0\n$$\n我们已经求得 $\\langle q^{4} \\rangle_{p_{\\mathrm{ref}}} = 3$。我们需要计算第六阶矩 $\\langle q^{6} \\rangle_{p_{\\mathrm{ref}}}$。对于标准正态分布，当 $k=3$ 时：\n$$\n\\langle q^{6} \\rangle_{p_{\\mathrm{ref}}} = (2 \\cdot 3 - 1)!! = 5!! = 5 \\times 3 \\times 1 = 15\n$$\n将矩值代入方程：\n$$\n3 - (4\\theta_{\\mathrm{FM}} + s) \\cdot 15 = 0\n$$\n求解 $\\theta_{\\mathrm{FM}}$：\n$$\n3 = 15(4\\theta_{\\mathrm{FM}} + s)\n$$\n$$\n\\frac{3}{15} = 4\\theta_{\\mathrm{FM}} + s\n$$\n$$\n\\frac{1}{5} = 4\\theta_{\\mathrm{FM}} + s\n$$\n$$\n4\\theta_{\\mathrm{FM}} = \\frac{1}{5} - s\n$$\n$$\n\\theta_{\\mathrm{FM}} = \\frac{1}{4} \\left(\\frac{1}{5} - s\\right) = \\frac{1 - 5s}{20}\n$$\n两个优化后的参数值为 $\\theta_{\\mathrm{REM}} = \\frac{1}{12}$ 和 $\\theta_{\\mathrm{FM}} = \\frac{1-5s}{20}$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{12} & \\frac{1 - 5s}{20}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}