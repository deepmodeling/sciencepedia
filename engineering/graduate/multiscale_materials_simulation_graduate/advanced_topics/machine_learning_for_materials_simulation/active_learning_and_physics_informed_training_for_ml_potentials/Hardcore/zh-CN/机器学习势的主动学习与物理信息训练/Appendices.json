{
    "hands_on_practices": [
        {
            "introduction": "构建一个稳健的机器学习（ML）势函数通常需要整合来自不同来源的数据。然而，不同的量子化学计算可能具有不一致的能量零点，使得直接比较能量变得不可能。本练习  探讨了对齐这些能量的物理原理和实用程序，这是构建一个统一且热力学一致的训练数据集的关键第一步。",
            "id": "3789397",
            "problem": "一个研究小组正在训练一种机器学习（ML）原子间势，用于多尺度材料模拟。训练数据包括多组分材料构型的总能量、原子间力和应力，这些数据是通过两个独立的密度泛函理论（DFT）工作流收集的，这两个工作流使用了不同的赝势和设置。假设数据集由 $d \\in \\{1,2\\}$ 索引，构型由 $i$ 索引，每个构型的组分由物种集合 $\\mathcal{S}$ 中物种 $s$ 的化学计量数 $n_s^{(i)}$ 给出。将报告的总能量记为 $E_d^{(i)}$，原子位置记为 $\\mathbf{R}^{(i)}$，力记为 $\\mathbf{F}_d^{(i)}$，Cauchy 应力记为 $\\boldsymbol{\\sigma}_d^{(i)}$。ML 势预测能量为 $\\hat{E}(\\mathbf{R},\\boldsymbol{\\theta})$（参数为 $\\boldsymbol{\\theta}$），力为 $\\hat{\\mathbf{F}}(\\mathbf{R},\\boldsymbol{\\theta})=-\\nabla_{\\mathbf{R}}\\hat{E}(\\mathbf{R},\\boldsymbol{\\theta})$，应力为 $\\hat{\\boldsymbol{\\sigma}}(\\mathbf{R},\\boldsymbol{\\theta}) = \\frac{1}{V}\\frac{\\partial \\hat{E}(\\mathbf{R},\\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\varepsilon}}$（对于小均匀应变 $\\boldsymbol{\\varepsilon}$ 和体积 $V$）。在物理信息训练和主动学习中，该小组希望混合这些数据集以改善相空间的覆盖范围，同时保持跨不同组分的热力学一致性。\n\n众所周知，来自不同电子结构代码或设置的绝对总能量可能因数据集特定的恒定偏移和依赖于物种的参考选择（例如，孤立原子或体相参考相的不同能量零点）而不同。考虑当混合数据集时，这些偏移如何影响训练中的物理相关量，以及如何构建一个一致的通用能量参考。\n\n选择所有提出物理上一致的推理和有效程序的选项，这些程序用于对齐来自不同代码或设置的数据集之间的能量，适用于物理信息 ML 势训练和主动学习，并证明这样做是重要的。\n\nA. 因为力定义为 $\\mathbf{F}=-\\nabla_{\\mathbf{R}}E$，应力定义为 $\\boldsymbol{\\sigma}=\\frac{1}{V}\\frac{\\partial E}{\\partial \\boldsymbol{\\varepsilon}}$，所以将数据集特定的常数 $b_d$ 加到数据集 $d$ 中的所有能量上，会使 $\\mathbf{F}$ 和 $\\boldsymbol{\\sigma}$ 保持不变，但会使任何使用 $E$ 的损失项产生偏差。可以通过引入每物种参考能量 $\\mu_s$ 和每数据集标量偏移 $b_d$ 来获得一致的对齐，并通过对化学计量进行最小二乘拟合来估计它们，该拟合强制形成能具有共同的零点，并带有一个规范固定约束（例如，固定一个 $b_{d^\\star}=0$）。对齐后，使用 $\\left(E_d^{(i)}-\\sum_{s\\in\\mathcal{S}} n_s^{(i)}\\mu_s - b_d\\right)$ 以及力和应力进行训练。\n\nB. 为了消除数据集之间的系统性差异，减去每个构型的平均每原子能量，即用 $E_d^{(i)} - \\frac{E_d^{(i)}}{N^{(i)}}$ 替换 $E_d^{(i)}$，其中 $N^{(i)}=\\sum_{s\\in\\mathcal{S}} n_s^{(i)}$。这可以均衡不同代码之间的尺度并保留所有相关的热力学性质，从而无需显式对齐。\n\nC. 由于恒定的能量偏移不影响 $\\mathbf{F}$ 或 $\\boldsymbol{\\sigma}$，因此丢弃所有能量标签，仅对力和应力进行训练。这保证了即使在混合具有不同能量零点的数据集时，跨组分的正确热力学性质（例如，形成能和相稳定性）。\n\nD. 使用由力不确定性驱动的主动学习来选择新构型，并且在混合数据集时，通过匹配力来为每个 $E_d^{(i)}$ 确定一个逐构型的偏移量 $c^{(i)}$：设置 $E_d^{(i)} \\mapsto E_d^{(i)} - c^{(i)}$，以使 $\\hat{\\mathbf{F}}(\\mathbf{R}^{(i)},\\boldsymbol{\\theta})$ 与 $\\mathbf{F}_d^{(i)}$ 一致。这强制使用一个通用的能量参考，并避免了逐物种的校正。\n\nE. 在每个数据集中，使用该数据集自己的一致元素参考能量 $E_{d,s}^{\\mathrm{ref}}$（例如，在相同 DFT 设置中，体相标准态或孤立原子的每原子能量）来计算形成能，即 $E_{d,\\mathrm{form}}^{(i)} = E_d^{(i)} - \\sum_{s\\in\\mathcal{S}} n_s^{(i)} E_{d,s}^{\\mathrm{ref}}$。然后，通过使用跨数据集的重叠或名义上等效的结构，为每个数据集估计一个单一的标量偏移 $b_d$，并锚定一个数据集（例如 $b_{d^\\star}=0$）。使用 $E_{d,\\mathrm{form}}^{(i)}-b_d$ 以及 $\\mathbf{F}$ 和 $\\boldsymbol{\\sigma}$ 进行训练，以确保跨代码的通用热力学尺度。",
            "solution": "用户要求对问题陈述进行严格验证，然后提供详细的解决方案并评估所有提供的选项。\n\n### 问题验证\n\n**第1步：提取已知信息**\n-   数据集由 $d \\in \\{1, 2\\}$ 索引，代表两个独立的密度泛函理论（DFT）工作流。\n-   构型由 $i$ 索引。\n-   构型 $i$ 的组分由物种 $s$ 在集合 $\\mathcal{S}$ 中的化学计量数 $n_s^{(i)}$ 给出。\n-   来自数据集 $d$ 的构型 $i$ 的报告总能量为 $E_d^{(i)}$。\n-   构型 $i$ 的原子位置为 $\\mathbf{R}^{(i)}$。\n-   来自数据集 $d$ 的构型 $i$ 的力为 $\\mathbf{F}_d^{(i)}$。\n-   来自数据集 $d$ 的构型 $i$ 的 Cauchy 应力为 $\\boldsymbol{\\sigma}_d^{(i)}$。\n-   机器学习（ML）势预测能量为 $\\hat{E}(\\mathbf{R}, \\boldsymbol{\\theta})$，参数为 $\\boldsymbol{\\theta}$。\n-   ML 势预测力为 $\\hat{\\mathbf{F}}(\\mathbf{R}, \\boldsymbol{\\theta}) = -\\nabla_{\\mathbf{R}}\\hat{E}(\\mathbf{R}, \\boldsymbol{\\theta})$。\n-   ML 势预测应力为 $\\hat{\\boldsymbol{\\sigma}}(\\mathbf{R}, \\boldsymbol{\\theta}) = \\frac{1}{V}\\frac{\\partial \\hat{E}(\\mathbf{R}, \\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\varepsilon}}$，对于小均匀应变 $\\boldsymbol{\\varepsilon}$ 和体积 $V$。\n-   目标是混合数据集进行训练，这需要保持热力学一致性。\n-   陈述中提到，绝对总能量可能因数据集特定的恒定偏移和依赖于物种的参考能量选择而不同。\n-   问题是确定所有用于对齐这些数据集之间能量的有效且物理上一致的程序。\n\n**第2步：使用提取的已知信息进行验证**\n-   **科学依据：** 该问题牢固地植根于计算材料科学和原子间势的发展。来自不同电子结构代码（或同一代码内的不同设置，例如赝势、k点网格、截断能）的绝对总能量不能直接比较，这是一个基本且实际的问题。将力和应力定义为能量的导数是正确的。使用形成能来建立一个通用的热力学参考是标准做法。该问题在科学上是合理的。\n-   **良态问题：** 这是一个良态问题。它清楚地阐述了一个常见的挑战，并要求找到一种有效的方法来解决它。其目标——实现一个一致的通用能量参考——足够具体，可以确定一组有效的解决方案。\n-   **客观性：** 该问题以精确、客观和技术的语言陈述。诸如“化学计量数”、“Cauchy 应力”和“赝势”等术语在该领域有明确的定义。没有歧义或主观性。\n\n**第3步：结论与行动**\n-   **结论：** 问题陈述是**有效的**。它在科学上合理，是良态的，并且是客观的，描述了多尺度材料模拟中的一个真实挑战。\n-   **行动：** 继续推导解决方案并分析给定的选项。\n\n### 解决方案推导\n\n基本原理是，在量子力学中，只有能量差是物理可观测量。总能量的绝对值是任意的，取决于所选的能量标度的零点。对于具有多种化学物种的系统，当比较来自不同来源的数据（例如，具有不同设置的 DFT 代码）时，这种模糊性主要以两种方式表现出来：\n$1$. 依赖于物种的偏移：每种原子物种 $s$ 的参考能量（例如，孤立原子或体相元素相的能量）可能不同。\n$2$. 全局常数偏移：由于数值约定或设置，可能对来自给定数据集的所有能量施加一个额外的常数偏移。\n\n因此，来自数据集 $d$ 的构型 $i$（原子数为 $n_s^{(i)}$）的总能量 $E_d^{(i)}$ 可以与一个假设的、一致的基础能量 $E_{\\text{consistent}}^{(i)}$ 建立如下模型关系：\n$$E_d^{(i)} \\approx E_{\\text{consistent}}^{(i)} + \\sum_{s \\in \\mathcal{S}} n_s^{(i)} \\alpha_{d,s} + \\beta_d$$\n其中 $\\alpha_{d,s}$ 表示在数据集 $d$ 的特定设置中物种 $s$ 的参考能量，而 $\\beta_d$ 是数据集 $d$ 的一个常数偏移。为了训练一个单一的 ML 势 $\\hat{E}(\\mathbf{R}, \\boldsymbol{\\theta})$，使其在所有组分上都具有预测性并且热力学一致，它必须在独立于数据集 $d$ 的目标能量上进行训练。这需要找到并移除依赖于数据集的偏移。\n\n至关重要的是，力和应力分别是能量对原子位置 $\\mathbf{R}$ 和应变 $\\boldsymbol{\\varepsilon}$ 的导数。偏移项 $\\sum_s n_s^{(i)} \\alpha_{d,s} + \\beta_d$ 是原子数 $n_s^{(i)}$ 的函数，但与具体的原子坐标 $\\mathbf{R}^{(i)}$ 或晶胞应变 $\\boldsymbol{\\varepsilon}$ 无关。因此，其导数为零：\n$$\\nabla_{\\mathbf{R}} \\left( \\sum_{s \\in \\mathcal{S}} n_s^{(i)} \\alpha_{d,s} + \\beta_d \\right) = \\mathbf{0}$$\n$$\\frac{\\partial}{\\partial \\boldsymbol{\\varepsilon}} \\left( \\sum_{s \\in \\mathcal{S}} n_s^{(i)} \\alpha_{d,s} + \\beta_d \\right) = \\mathbf{0}$$\n这意味着来自不同数据集的力 $\\mathbf{F}_d^{(i)}$ 和应力 $\\boldsymbol{\\sigma}_d^{(i)}$ 已经处于一个共同的物理基础上，可以无需任何对齐直接用于训练。挑战仅限于能量值 $E_d^{(i)}$。\n\n一个有效的程序必须提出一种方法来估计和减去这些偏移（这些偏移是化学计量数 $n_s^{(i)}$ 的线性函数加上一个常数），以为 ML 模型创建一组一致的能量目标。\n\n### 逐项分析\n\n**A. 因为力定义为 $\\mathbf{F}=-\\nabla_{\\mathbf{R}}E$，应力定义为 $\\boldsymbol{\\sigma}=\\frac{1}{V}\\frac{\\partial E}{\\partial \\boldsymbol{\\varepsilon}}$，所以将数据集特定的常数 $b_d$ 加到数据集 $d$ 中的所有能量上，会使 $\\mathbf{F}$ 和 $\\boldsymbol{\\sigma}$ 保持不变，但会使任何使用 $E$ 的损失项产生偏差。可以通过引入每物种参考能量 $\\mu_s$ 和每数据集标量偏移 $b_d$ 来获得一致的对齐，并通过对化学计量进行最小二乘拟合来估计它们，该拟合强制形成能具有共同的零点，并带有一个规范固定约束（例如，固定一个 $b_{d^\\star}=0$）。对齐后，使用 $\\left(E_d^{(i)}-\\sum_{s\\in\\mathcal{S}} n_s^{(i)}\\mu_s - b_d\\right)$ 以及力和应力进行训练。**\n\n该选项描述了一个稳健且广泛使用的程序。它正确地指出，对于所讨论的能量偏移类型，力和应力是不变的。它建议将每个数据点 $(i, d)$ 所需的能量校正建模为其化学计量的线性函数 $\\sum_s n_s^{(i)}\\mu_s$ 加上一个数据集特定的常数 $b_d$。这些参数 $(\\mu_s, b_d)$ 可以通过线性最小二乘拟合来确定，通常在训练 ML 势参数 $\\boldsymbol{\\theta}$ 的过程中迭代进行。能量的损失函数旨在最小化以下形式的差异：\n$$L_E = \\sum_{d, i} \\left\\| \\hat{E}(\\mathbf{R}^{(i)}, \\boldsymbol{\\theta}) - \\left( E_d^{(i)} - \\sum_{s \\in \\mathcal{S}} n_s^{(i)}\\mu_s - b_d \\right) \\right\\|^2$$\n其中 $\\hat{E}$、$\\mu_s$ 和 $b_d$ 都被优化。这个关于线性参数 $(\\mu_s, b_d)$ 的方程组是退化的（具有规范自由度），该提议正确地指出了需要一个规范固定约束，例如设置一个偏移 $b_{d^\\star}=0$。整个程序在物理上是合理的，并且是该领域的标准做法。\n\n**结论：正确**\n\n**B. 为了消除数据集之间的系统性差异，减去每个构型的平均每原子能量，即用 $E_d^{(i)} - \\frac{E_d^{(i)}}{N^{(i)}}$ 替换 $E_d^{(i)}$，其中 $N^{(i)}=\\sum_{s\\in\\mathcal{S}} n_s^{(i)}$。这可以均衡不同代码之间的尺度并保留所有相关的热力学性质，从而无需显式对齐。**\n\n这个程序在物理上是不正确的。总能量 $E$ 是一个广延性质，意味着对于一个均匀系统，它与系统大小 $N$ 成线性关系。每原子能量 $E/N$ 是一个强度性质。提议的变换 $E \\to E' = E - E/N = E(1 - 1/N)$ 创建了一个不再具有广延性的新量 $E'$。例如，如果我们将两个相同的晶胞组合使系统大小加倍，能量 $E$ 和原子数 $N$ 都加倍，但变换后的能量 $E'$ 不会：$E'_{\\text{double}} = 2E(1 - 1/(2N)) = 2E - E/N$，这不等于 $2E' = 2E(1-1/N) = 2E - 2E/N$。这种对广延性的违反使得由此产生的能量无法用于任何热力学计算，如依赖于正确能量平衡的形成能或反应能。声称这“保留所有相关的热力学性质”是错误的。\n\n**结论：不正确**\n\n**C. 由于恒定的能量偏移不影响 $\\mathbf{F}$ 或 $\\boldsymbol{\\sigma}$，因此丢弃所有能量标签，仅对力和应力进行训练。这保证了即使在混合具有不同能量零点的数据集时，跨组分的正确热力学性质（例如，形成能和相稳定性）。**\n\n前提部分正确：仅在力和应力上训练（一种“力匹配”方法）可以规避能量对齐问题。然而，结论是致命的缺陷。势能面 $E$ 在数学上是力 $\\mathbf{F}$ 的积分。积分力可以确定势能面的形状，但它使构型空间中每个不连通部分的积分常数不确定。这意味着模型将没有关于不同相、化学计量或分子结构（例如，反应物与产物）之间相对能量的信息。预测相稳定性需要比较竞争相的能量（或自由能），例如，如果 $E_A  E_B$，则相 A 比 B 更稳定。通过丢弃所有能量数据，预测任何依赖于不同构型之间能量差异的热力学性质的能力都将丧失。因此，这种方法不能“保证正确的热力学性质”。\n\n**结论：不正确**\n\n**D. 使用由力不确定性驱动的主动学习来选择新构型，并且在混合数据集时，通过匹配力来为每个 $E_d^{(i)}$ 确定一个逐构型的偏移量 $c^{(i)}$：设置 $E_d^{(i)} \\mapsto E_d^{(i)} - c^{(i)}$，以使 $\\hat{\\mathbf{F}}(\\mathbf{R}^{(i)},\\boldsymbol{\\theta})$ 与 $\\mathbf{F}_d^{(i)}$ 一致。这强制使用一个通用的能量参考，并避免了逐物种的校正。**\n\n这个提议在概念上不连贯，在方法上不健全。首先，为每个能量数据点引入一个单独的拟合参数 $c^{(i)}$ 会提供过度的灵活性，这将导致对训练数据的完美拟合，但预测能力为零（过拟合）。模型不会学到任何基础物理。其次，提议的确定 $c^{(i)}$ 的机制是循环论证且毫无意义的。对目标能量 $E_d^{(i)}$ 的标量偏移 $c^{(i)}$ 对目标力 $\\mathbf{F}_d^{(i)}$ 没有影响，后者是由 DFT 提供的。力 $\\mathbf{F}_d^{(i)}$ 是训练过程中的固定输入。ML 力 $\\hat{\\mathbf{F}}$ 依赖于我们正在尝试训练的 ML 势 $\\hat{E}$。不能通过偏移 $c^{(i)}$ 来调整能量目标 $E_d^{(i)}$ 以使力匹配，因为能量偏移不会改变力。这个逻辑是自相矛盾的。\n\n**结论：不正确**\n\n**E. 在每个数据集中，使用该数据集自己的一致元素参考能量 $E_{d,s}^{\\mathrm{ref}}$（例如，在相同 DFT 设置中，体相标准态或孤立原子的每原子能量）来计算形成能，即 $E_{d,\\mathrm{form}}^{(i)} = E_d^{(i)} - \\sum_{s\\in\\mathcal{S}} n_s^{(i)} E_{d,s}^{\\mathrm{ref}}$。然后，通过使用跨数据集的重叠或名义上等效的结构，为每个数据集估计一个单一的标量偏移 $b_d$，并锚定一个数据集（例如 $b_{d^\\star}=0$）。使用 $E_{d,\\mathrm{form}}^{(i)}-b_d$ 以及 $\\mathbf{F}$ 和 $\\boldsymbol{\\sigma}$ 进行训练，以确保跨代码的通用热力学尺度。**\n\n这描述了一个有效的、物理意义清晰的两步程序。第一步是在其原生数据集 $d$ 内为每个构型计算形成能 $E_{d,\\mathrm{form}}^{(i)}$。这正确地移除了主要的、依赖于物种的参考能量偏移。由于力和应力不受减去一个原子数线性项的影响，原始的 $\\mathbf{F}_d^{(i)}$ 和 $\\boldsymbol{\\sigma}_d^{(i)}$ 仍然是正确的训练目标。第二步处理数据集形成能标度之间任何剩余的常数偏移 $b_d$。估计这些偏移，例如通过比较存在于多个数据集中的相同结构的形成能，是一种标准技术。锚定一个数据集（$b_{d^\\star}=0$）是必要的规范固定。在对齐后的形成能 $E_{d,\\mathrm{form}}^{(i)}-b_d$ 上训练 ML 势，会产生一个具有一致热力学参考标度的模型。这个程序是选项 A 中描述的同步拟合的一个行之有效的替代方案。\n\n**结论：正确**",
            "answer": "$$\\boxed{AE}$$"
        },
        {
            "introduction": "一个训练良好的势函数不仅应准确预测能量和力，还应准确预测一系列物理性质。一个简单的误差度量可能与这些下游任务的性能没有直接关联。本练习  将指导您设计一个具有物理依据的验证分数，该分数根据误差对重要材料性质的敏感性进行加权，从而确保训练过程与实际应用目标保持一致。",
            "id": "3789405",
            "problem": "您正在为一种晶体合金训练机器学习原子间势，该势将部署于多尺度材料模拟工作流中。驱动模型需求的下游任务包括：(i) 预测在温度 $T$ 下的空位扩散系数 $D(T)$，(ii) 从小应变应力-应变计算中提取体积模量 $K$，以及 (iii) 通过对力学稳定构型进行谐波分析得到声子谱。主动学习将使用单一标量验证分数来决定何时查询新数据以及选择模型。\n\n控制这些下游任务的基础物理关系包括：\n- 扩散的 Arrhenius 动力学：$D(T) = D_0 \\exp\\!\\left(-E_a/(k_B T)\\right)$，其中 $E_a$ 是活化能垒，$k_B$ 是玻尔兹曼常数。\n- 小应变极限下的线弹性：对于静水加载，$\\sigma = K \\,\\varepsilon$，其中 $\\sigma$ 是静水应力，$\\varepsilon$ 是体积应变；在实践中，$K$ 是通过在小应变窗口内斜率 $d\\sigma/d\\varepsilon$ 来估计的。\n- 谐振声子：对于一个由一维谐振子近似的模式，$\\omega^2 = k/m$，其中 $\\omega$ 是角频率，$k$ 是模式刚度（势能面的曲率），$m$ 是有效质量。平衡点附近的瞬时力为 $F \\approx -k x$，其中 $x$ 是位移。\n\n您的验证数据集提供了每个构型的能量值 $\\{E_j\\}$、每个原子的力分量 $\\{F_{i\\alpha}\\}$ 和 Cauchy 应力张量 $\\{\\sigma_{j}\\}$，以及来自高保真度计算的相应参考值。为了构建一个既无量纲又能预测下游性能的标量验证分数，您考虑使用平均绝对误差 (MAE)、均方根误差 (RMSE) 和相对误差，并可能结合反映 $D(T)$、$K$ 和 $\\omega$ 对 $E$、$F$ 和 $\\sigma$ 中误差敏感度的权重。\n\n在主动学习和物理知识驱动的训练中，以下哪种组合验证分数定义在物理上最为合理？其合理性体现在它使用无量纲归一化以及从下游任务的线性化敏感度推导出的权重来汇总能量、力和应力的误差。\n\nA. 将标量分数定义为\n$$S_A = \\frac{1}{3}\\left(\\mathrm{MAE}(E) + \\mathrm{MAE}(F) + \\mathrm{MAE}(\\sigma)\\right),$$\n通过对能量（单位为电子伏特）、力（单位为电子伏特每埃）和应力（单位为吉帕斯卡）在其原生单位下的绝对误差进行平均计算，不进行归一化或加权。\n\nB. 将标量分数定义为\n$$S_B = \\alpha_E \\frac{\\mathrm{RMSE}(E)}{|E_0|} + \\alpha_F \\frac{\\mathrm{RMSE}(F)}{\\max\\limits_{i,\\alpha}|F_{i\\alpha}|} + \\alpha_\\sigma \\frac{\\mathrm{RMSE}(\\sigma)}{P},$$\n其中 $E_0$ 是每个原子的基态能量，$P$ 是验证集中的静水压力大小，$\\alpha_E$、$\\alpha_F$、$\\alpha_\\sigma$ 分别是与能量、力和应力样本数量成正比的权重。\n\nC. 将标量分数定义为\n$$S_C = \\underbrace{\\frac{1}{k_B T}}_{\\text{$\\ln D$ 的敏感度}} \\underbrace{\\frac{\\mathrm{RMSE}(E)}{E_a}}_{\\text{相对能量误差}} \\;+\\; \\underbrace{\\frac{1}{2}}_{\\frac{\\partial \\ln \\omega}{\\partial \\ln k}} \\underbrace{\\frac{\\mathrm{RMSE}(F)}{k_{\\mathrm{eff}}\\, x_{\\mathrm{rms}}}}_{\\text{通过 } \\delta k \\approx \\delta F/x_{\\mathrm{rms}} \\text{ 的相对刚度误差}} \\;+\\; \\underbrace{\\frac{1}{\\Delta \\varepsilon}}_{\\text{有限差分敏感度}} \\underbrace{\\frac{\\mathrm{RMSE}(\\sigma)}{K}}_{\\text{相对应力误差}},$$\n其中 $E_a$ 是扩散任务的代表性活化能垒，$k_{\\mathrm{eff}}$ 是从数据集中提取的平衡点附近势的特征曲率（刚度），$x_{\\mathrm{rms}} = \\sqrt{k_B T/k_{\\mathrm{eff}}}$ 是谐波近似下的热均方根位移，$\\Delta \\varepsilon$ 是用于从 $d\\sigma/d\\varepsilon$ 估计 $K$ 的小应变窗口。\n\nD. 将标量分数定义为\n$$S_D = \\frac{\\mathrm{RMSE}(E)}{k_B T} + \\frac{\\mathrm{RMSE}(F)}{m v_{\\mathrm{th}}/\\Delta t} + \\frac{\\mathrm{RMSE}(\\sigma)}{K},$$\n其中 $v_{\\mathrm{th}} = \\sqrt{k_B T/m}$ 是热速度，$m$ 是原子质量，$\\Delta t$ 是分子动力学时间步长；所有三项均未加权并直接相加。\n\n选择唯一最佳选项，并准备好使用第一性原理和上述物理依赖关系来证明您的选择，包括 MAE、RMSE 和相对误差的定义，以及下游属性的线性响应所隐含的误差传播。",
            "solution": "问题的核心是构建一个损失函数（验证分数），该函数应满足以下条件：\n1.  **无量纲性：** 每一项都应该是一个纯数。\n2.  **物理动机：** 归一化和加权应与感兴趣的下游属性相关。\n3.  **反映敏感度：** 权重应与下游属性（$D$, $K$, $\\omega$）对基本量（$E$, $F$, $\\sigma$）中误差的敏感程度成正比。\n\n让我们分析每个下游属性对机器学习原子间势预测误差的敏感度。\n\n**1. 扩散系数 $D(T)$**\n- 属性：$D(T) = D_0 \\exp(-E_a/(k_B T))$\n- 依赖性：主要取决于活化能 $E_a$。活化能是两个能量之差：过渡态的能量（$E_{ts}$）和初始态的能量（$E_{is}$）。因此，$E_a = E_{ts} - E_{is}$。\n- 敏感度分析：设 $\\delta E$ 为能量预测中的典型误差。活化能的误差 $\\delta E_a$ 将与 $\\delta E$ 处于同一量级。我们想看看误差 $\\delta E_a$ 如何影响 $D(T)$。通常查看对数的误差更为有用。\n    - $\\ln D(T) = \\ln D_0 - E_a / (k_B T)$\n    - 由 $E_a$ 的变化引起的 $\\ln D$ 的变化是：\n        $\\delta(\\ln D) = -\\frac{\\delta E_a}{k_B T}$\n    - $\\ln D$ 对 $E_a$ 的敏感度是 $\\frac{\\partial (\\ln D)}{\\partial E_a} = -\\frac{1}{k_B T}$。其大小为 $\\frac{1}{k_B T}$。\n- 分数中能量部分的良好误差度量应与此敏感度成正比。误差本身应为与能量相关的无量纲量。一个自然的选择是能量的相对误差，如 $\\delta E / E_a$。\n- 因此，分数中的一项可以写成：（敏感度） * （无量纲误差） $\\propto \\frac{1}{k_B T} \\cdot \\frac{\\mathrm{Error}(E)}{E_a}$。\n    - 这里，Error($E$) 可以是 RMSE($E$) 或 MAE($E$)。它们的单位是能量。\n    - 项 $\\frac{\\mathrm{RMSE}(E)}{E_a}$ 是活化能垒相对误差的无量纲度量。\n    - 权重 $\\frac{1}{k_B T}$ 正确地捕捉了扩散系数对能量垒误差的指数敏感性。在低温下，这种敏感性非常大。\n\n**2. 体积模量 $K$**\n- 属性：$K$ 是通过 $\\sigma$ vs. $\\varepsilon$ 的斜率来估计的，即在小应变窗口 $\\Delta \\varepsilon$ 上 $K \\approx \\frac{\\Delta \\sigma}{\\Delta \\varepsilon}$。\n- 依赖性：取决于应力张量 $\\sigma$。\n- 敏感度分析：体积模量的误差 $\\delta K$ 将与应力误差 $\\delta \\sigma$ 相关。\n    - $\\delta K \\approx \\frac{\\delta(\\Delta \\sigma)}{\\Delta \\varepsilon}$。应力差的误差 $\\delta(\\Delta \\sigma)$ 将与典型应力误差 $\\delta \\sigma$ 处于同一量级。因此，$\\delta K \\approx \\frac{\\delta \\sigma}{\\Delta \\varepsilon}$。\n- 让我们看看 $K$ 的相对误差：$\\frac{\\delta K}{K} \\approx \\frac{\\delta \\sigma / \\Delta \\varepsilon}{K}$。\n- 分数中应力部分的良好误差度量应与此相对误差成正比。\n- 应力的一个无量纲误差项可以是 $\\frac{\\delta \\sigma}{K}$。这在物理上是有意义的：它将应力误差与模量本身进行比较。对于某些金属，$K \\sim 100$ GPa。1 GPa 的应力误差将是 1% 的相对误差。\n- $K$ 对 $\\sigma$ 的敏感度大约是 $1/\\Delta\\varepsilon$。\n- 所以分数中的一个潜在项可以是：（敏感度） * （无量纲误差） $\\propto \\frac{1}{\\Delta \\varepsilon} \\cdot \\frac{\\mathrm{Error}(\\sigma)}{K}$。\n    - 这里，Error($\\sigma$) 是 RMSE($\\sigma$) 或 MAE($\\sigma$)。\n    - 项 $\\frac{\\mathrm{RMSE}(\\sigma)}{K}$ 是相对于所计算属性的应力误差的无量纲度量。\n    - 权重 $\\frac{1}{\\Delta \\varepsilon}$ 来自于导数的有限差分近似。\n\n**3. 声子谱 $\\omega$**\n- 属性：$\\omega^2 = k/m$。声子频率取决于刚度 $k$，它是势能相对于原子位移的二阶导数。$k = \\frac{\\partial^2 U}{\\partial x^2}$。\n- 依赖性：$k$ 如何与训练数据（$E, F, \\sigma$）相关？力是能量的一阶导数：$F = -\\frac{\\partial U}{\\partial x}$。刚度 $k$ 是力的导数：$k = -\\frac{\\partial F}{\\partial x}$。\n- 敏感度分析：力的误差 $\\delta F$ 将传播到刚度的误差 $\\delta k$。如果我们通过不同位移下的力来估计 $k$（例如，通过力的有限差分，或通过拟合 $F \\approx -kx$），在位移尺度 $x$ 上的误差 $\\delta F$ 将导致误差 $\\delta k \\approx \\delta F / x$。\n- 现在，让我们看看 $\\delta k$ 如何影响 $\\omega$。\n    - $\\omega = (k/m)^{1/2}$。\n    - 对于幂律，使用对数导数最简单：$\\ln \\omega = \\frac{1}{2} \\ln k - \\frac{1}{2} \\ln m$。\n    - $\\frac{\\delta \\omega}{\\omega} = \\frac{1}{2} \\frac{\\delta k}{k}$。\n    - 相对频率误差对相对刚度误差的敏感度是 $\\frac{\\partial (\\ln \\omega)}{\\partial (\\ln k)} = \\frac{1}{2}$。\n- 现在我们来构建一个无量纲误差项。我们有 $\\delta k \\approx \\delta F / x_{\\text{char}}$，其中 $x_{\\text{char}}$ 是一个特征位移尺度。在温度 $T$ 的热模拟中，一个自然的尺度是原子的均方根位移 $x_{\\mathrm{rms}} = \\sqrt{\\langle x^2 \\rangle}$。根据谐振子的能量均分定理，$\\frac{1}{2}k \\langle x^2 \\rangle = \\frac{1}{2} k_B T$，所以 $x_{\\mathrm{rms}} = \\sqrt{k_B T / k}$。特征力尺度为 $F_{\\text{char}} \\approx k \\cdot x_{\\text{char}}$。\n- 一个无量纲的力误差可以是 $\\frac{\\delta F}{F_{\\text{char}}} = \\frac{\\delta F}{k \\cdot x_{\\mathrm{rms}}}$。这是力的相对误差。\n- 刚度的相对误差是 $\\frac{\\delta k}{k} \\approx \\frac{\\delta F / x_{\\mathrm{rms}}}{k} = \\frac{\\delta F}{k \\cdot x_{\\mathrm{rms}}}$。因此，刚度的相对误差与物理归一化的力误差直接相关。\n- 将其组合成分数：（敏感度） * （无量纲误差）\n    - 力的无量纲误差项应表示刚度的相对误差，即 $\\frac{\\delta k}{k} \\approx \\frac{\\delta F}{k \\cdot x_{\\mathrm{rms}}}$。将 $\\delta F$ 替换为 RMSE($F$)，并将 $k$ 替换为特征刚度 $k_{\\text{eff}}$，这变成 $\\frac{\\mathrm{RMSE}(F)}{k_{\\mathrm{eff}} \\cdot x_{\\mathrm{rms}}}$。\n    - 敏感度是来自 $\\frac{\\delta \\omega}{\\omega} = \\frac{1}{2} \\frac{\\delta k}{k}$ 的因子 $\\frac{1}{2}$。\n    - 因此该项为 $\\frac{1}{2} \\frac{\\mathrm{RMSE}(F)}{k_{\\mathrm{eff}} \\cdot x_{\\mathrm{rms}}}$。\n\n**理想分数的总结**\n\n基于以上分析，一个物理上合理的分数 $S$ 将是三项之和，每一项都是一个敏感度因子和一个无量纲误差的乘积：\n\n$S = w_E \\left( \\frac{1}{k_B T} \\frac{\\mathrm{RMSE}(E)}{E_a} \\right) + w_F \\left( \\frac{1}{2} \\frac{\\mathrm{RMSE}(F)}{k_{\\mathrm{eff}} x_{\\mathrm{rms}}} \\right) + w_\\sigma \\left( \\frac{1}{\\Delta \\varepsilon} \\frac{\\mathrm{RMSE}(\\sigma)}{K} \\right)$\n\n其中 $w_E, w_F, w_\\sigma$ 是一些额外的可选权重，用以平衡三个任务的重要性。问题要求的是物理上最合理的定义，这意味着权重本身就是从敏感度推导出来的。选项中的定义似乎将敏感度和误差项合并为一个。让我们将我们推导出的形式与选项进行比较。\n\n**逐项分析**\n\n**A. $S_A = \\frac{1}{3}\\left(\\mathrm{MAE}(E) + \\mathrm{MAE}(F) + \\mathrm{MAE}(\\sigma)\\right)$**\n\n- **分析：** 这个分数是能量、力和应力的平均绝对误差的简单平均值。\n- **量纲性：** 这是一个主要缺陷。这些项不是无量纲的。$\\mathrm{MAE}(E)$ 的单位是 eV，$\\mathrm{MAE}(F)$ 的单位是 eV/Å，$\\mathrm{MAE}(\\sigma)$ 的单位是 GPa。将具有不同物理单位的量相加是量纲不一致的，并且在物理上没有意义。结果完全取决于单位的任意选择。\n- **物理合理性：** 它完全缺乏物理合理性。没有进行归一化来创建无量纲量。权重是均匀的（$1/3$），并没有反映下游属性（$D$, $K$, $\\omega$）对（$E, F, \\sigma$）中误差的敏感度。$D$ 对 $E_a$ 的指数依赖性被完全忽略了。\n- **结论：****不正确**。它在量纲上有缺陷，并且在物理上是任意的。\n\n**B. $S_B = \\alpha_E \\frac{\\mathrm{RMSE}(E)}{|E_0|} + \\alpha_F \\frac{\\mathrm{RMSE}(F)}{\\max\\limits_{i,\\alpha}|F_{i\\alpha}|} + \\alpha_\\sigma \\frac{\\mathrm{RMSE}(\\sigma)}{P}$**\n\n- **分析：** 这个分数试图通过使用数据集中的特征值进行归一化来创建无量纲项。\n- **量纲性：** 这些项是无量纲的，这比 A 有所改进。\n- **物理合理性：** 归一化因子的选择是临时的，与下游任务没有很好的关联。\n    - **能量项：** 用每个原子的基态能量 $|E_0|$ 进行归一化是不正确的。与扩散相关的能量尺度是活化能垒 $E_a$，它是一个能量*差值*，而不是与内聚能相关的绝对能量。\n    - **力项：** 用数据集中的最大力进行归一化是一种糟糕的启发式方法。它没有捕捉到谐振声子的物理原理，后者取决于平衡点附近的势能曲率（刚度），而平衡点附近的力可能很小。\n    - **应力项：** 用静水压力大小 $P$ 进行归一化也是任意的。体积模量 $K$ 的相关尺度是 $K$ 本身，这提供了一个稳定且物理上有意义的相对误差。\n    - **权重：** 权重 $\\alpha_E, \\alpha_F, \\alpha_\\sigma$ 与样本数量成正比是一种统计上的考虑，而不是基于任务敏感度的物理考虑。\n- **结论：****不正确**。虽然是无量纲的，但其归一化和权重没有通过下游任务得到物理上的合理解释。\n\n**D. $S_D = \\frac{\\mathrm{RMSE}(E)}{k_B T} + \\frac{\\mathrm{RMSE}(F)}{m v_{\\mathrm{th}}/\\Delta t} + \\frac{\\mathrm{RMSE}(\\sigma)}{K}$**\n\n- **分析：** 这个分数是无量纲的，因为每一项的分母都与分子具有相同的单位。\n- **物理合理性：**\n    - **应力项：** $\\frac{\\mathrm{RMSE}(\\sigma)}{K}$ 是一个物理上有意义的无量纲相对误差，但它缺少与 $K$ 的有限差分计算相关的敏感度因子 $1/\\Delta\\varepsilon$。\n    - **能量项：** $\\frac{\\mathrm{RMSE}(E)}{k_B T}$ 是一个合理的无量纲项，代表 Arrhenius 指数中的误差 $\\delta E_a / (k_B T)$。这正确地捕捉了低温 $T$ 下的高敏感性。\n    - **力项：** 对于所述任务，$\\frac{\\mathrm{RMSE}(F)}{m v_{\\mathrm{th}}/\\Delta t}$ 在物理上是不合理的。分母是从分子动力学参数（$m, v_{\\text{th}}, \\Delta t$）导出的力尺度。声子分析基于静态势能面的曲率（$k = -\\partial F/\\partial x$），而不是动力学。引入时间步长 $\\Delta t$ 尤其不恰当，因为物理属性（及其误差度量）不应依赖于时间积分的数值算法参数。\n- **结论：****不正确**。它包含一个物理上错误的力误差项，使其不适合指导声子计算的训练。\n\n**C. $S_C = \\underbrace{\\frac{1}{k_B T}}_{\\text{$\\ln D$ 的敏感度}} \\underbrace{\\frac{\\mathrm{RMSE}(E)}{E_a}}_{\\text{相对能量误差}} \\;+\\; \\underbrace{\\frac{1}{2}}_{\\frac{\\partial \\ln \\omega}{\\partial \\ln k}} \\underbrace{\\frac{\\mathrm{RMSE}(F)}{k_{\\mathrm{eff}}\\, x_{\\mathrm{rms}}}}_{\\text{通过 } \\delta k \\approx \\delta F/x_{\\mathrm{rms}} \\text{ 的相对刚度误差}} \\;+\\; \\underbrace{\\frac{1}{\\Delta \\varepsilon}}_{\\text{有限差分敏感度}} \\underbrace{\\frac{\\mathrm{RMSE}(\\sigma)}{K}}_{\\text{相对应力误差}}$**\n\n- **分析：** 此选项明确地将每一项分解为一个物理推导的敏感度因子和一个相对误差项，如下方大括号的注释所示。这种结构正是物理知识驱动的分数所需要的。\n- **物理合理性：**\n    - **能量：** $\\ln D$ 的敏感度被正确地确定为 $\\propto 1/(k_B T)$。相对能量误差被活化能垒 $E_a$ 正确归一化，这是扩散的相关能量尺度。\n    - **力：** 相对声子频率对相对刚度的敏感度 $\\partial(\\ln\\omega)/\\partial(\\ln k)$ 被正确地确定为 $1/2$。无量纲力误差 $\\mathrm{RMSE}(F)/(k_{\\text{eff}} x_{\\mathrm{rms}})$ 在物理上是合理的。分母 $k_{\\text{eff}}x_{\\mathrm{rms}}$ 代表了谐振势阱中的一个特征力尺度，它正确地将力误差与刚度 $k$ 的误差联系起来。\n    - **应力：** 有限差分导数的敏感度被正确地确定为 $1/\\Delta\\varepsilon$。相对应力误差被体积模量 $K$ 正确归一化。\n- **量纲性：** 按其写法，这个和是量纲不一致的。第一项的单位是能量的倒数，而第二和第三项是无量纲的（$\\Delta\\varepsilon$ 是无量纲应变）。这是表达式中的一个形式错误。然而，问题要求的是“物理上最合理”的定义。每个组成部分的*理据*，如下方大括号中详述，在物理上是无可挑剔的，并且优于所有其他选项。缺陷在于最终的求和，而不在于各组成部分的物理推理。选项 A、B 和 D 中的错误是物理原理上的根本错误（量纲上的无稽之谈、临时的归一化，或依赖于非物理参数）。C 中的错误是一个形式上的错误，可能是一个笔误（例如，第一项应为 $\\frac{E_a}{k_B T} \\frac{\\mathrm{RMSE}(E)}{E_a} = \\frac{\\mathrm{RMSE}(E)}{k_B T}$ 以使其无量纲），但其潜在的物理模型是最合理的。\n- **结论：****正确**。尽管最终求和在形式上存在量纲不一致，但该选项是唯一一个其每个组成部分——每个归一化因子和每个敏感度权重——都直接且正确地从控制下游任务的物理原理中推导出来的。这使其定义在物理上最为合理。",
            "answer": "$$\n\\boxed{C}\n$$"
        },
        {
            "introduction": "为了系统地改进机器学习势函数，我们必须智能地选择新的数据点进行标记，这一过程称为主动学习。本练习  介绍了最大最小距离采样法，这是一种探索广阔构型空间的强大策略。您将实现一个算法，以识别与现有训练数据最不相似的候选结构，从而最大化每次新计算所带来的信息增益。",
            "id": "3789380",
            "problem": "考虑在多尺度材料模拟中为机器学习（ML）原子间势进行主动学习的任务。在分子动力学（MD）中，每一帧都可以由一组嵌入在有限维欧几里得空间中的原子描述符向量表示。设每个描述符向量为元素 $x \\in \\mathbb{R}^d$，其中 $d$ 是描述符维度。假设我们有一个当前的已标记帧集 $\\mathcal{S} = \\{ S_1, S_2, \\dots, S_m \\}$ 和一个未标记的候选帧批次 $\\mathcal{C} = \\{ C_1, C_2, \\dots, C_k \\}$。每一帧 $S_i$ 或 $C_j$ 分别是一个有限的描述符向量集，$S_i = \\{ s_{i,1},\\dots,s_{i,n_i} \\} \\subset \\mathbb{R}^d$ 和 $C_j = \\{ c_{j,1},\\dots,c_{j,p_j} \\} \\subset \\mathbb{R}^d$。\n\n我们通过由一个半正定度量矩阵诱导的高斯径向基函数（RBF）核来定义相似性。设 $M \\in \\mathbb{R}^{d \\times d}$ 是对称半正定矩阵，$\\ell  0$ 是一个长度尺度。两个描述符向量 $x,y \\in \\mathbb{R}^d$ 之间的核函数为\n$$\nk(x,y) = \\exp\\!\\left( - \\frac{1}{2 \\ell^2} (x-y)^\\top M (x-y) \\right).\n$$\n该核在再生核希尔伯特空间（RKHS）中诱导了一个内积，一帧 $A = \\{ a_1,\\dots,a_{n_A} \\}$ 的核均值嵌入是经验均值元素 $\\mu_A = \\frac{1}{n_A} \\sum_{i=1}^{n_A} \\phi(a_i)$，其中 $\\phi(\\cdot)$ 是与 $k(\\cdot,\\cdot)$ 相关联的特征映射。均值嵌入之间的平方距离是有偏平方最大均值差异（MMD），\n$$\n\\operatorname{MMD}^2_{\\text{biased}}(A,B) = \\left\\| \\mu_A - \\mu_B \\right\\|_{\\mathcal{H}}^2\n= \\frac{1}{n_A^2} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_A} k(a_i,a_j)\n+ \\frac{1}{n_B^2} \\sum_{i=1}^{n_B} \\sum_{j=1}^{n_B} k(b_i,b_j)\n- \\frac{2}{n_A n_B} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_B} k(a_i,b_j),\n$$\n对于任何 $n_A \\ge 1$ 和 $n_B \\ge 1$ 都有良好定义。\n\n描述符空间中的最大最小距离采样选择候选帧 $C^* \\in \\mathcal{C}$，使其与当前集 $\\mathcal{S}$ 的最小距离最大化，其中帧之间的距离是均值嵌入之差的 RKHS 范数。具体来说，定义\n$$\nd(C,\\mathcal{S}) = \\min_{S \\in \\mathcal{S}} \\sqrt{ \\operatorname{MMD}^2_{\\text{biased}}(C,S) }.\n$$\n最大最小选择是\n$$\nC^* = \\arg\\max_{C \\in \\mathcal{C}} d(C,\\mathcal{S}).\n$$\n当多个候选者达到 $d(C,\\mathcal{S})$ 的相同最大值时，必须通过返回最小的候选者索引来解决平局问题（即，使得 $C_j$ 达到最大值的最小 $j$）。\n\n您的任务是编写一个完整的程序，该程序：\n- 实现由 $M$ 和 $\\ell$ 参数化的 RBF 核 $k(x,y)$。\n- 对任意两帧 $A,B$ 计算 $\\operatorname{MMD}^2_{\\text{biased}}(A,B)$。\n- 对每个测试用例，为所有候选者 $C_j$ 计算 $d(C_j,\\mathcal{S})$，根据最大最小规则选择 $C^*$，并以整数形式返回 $C^*$ 的索引。\n\n本问题不涉及物理单位；所有量纲均为无量纲。不使用角度。不使用百分比。\n\n测试套件：\n对于每个测试用例，您将获得 $d$、$M$、$\\ell$、当前集 $\\mathcal{S}$ 和候选集 $\\mathcal{C}$。所有描述符向量都以分量列表的形式明确提供。您的程序必须处理以下四种情况：\n\n- 情况 1（理想路径，各向同性度量）：\n  - $d = 2$, $M = I_2$, $\\ell = 1.0$。\n  - $\\mathcal{S}$:\n    - $S_1 = \\{ (0.0, 0.0), (1.0, 0.0), (0.5, 0.5) \\}$,\n    - $S_2 = \\{ (2.0, 2.0), (2.5, 2.0) \\}$.\n  - $\\mathcal{C}$:\n    - $C_1 = \\{ (3.0, 3.0), (2.8, 3.2) \\}$,\n    - $C_2 = \\{ (0.9, 0.1), (0.6, 0.4) \\}$,\n    - $C_3 = \\{ (-1.0, -1.0), (-0.5, -0.2) \\}$.\n\n- 情况 2（候选者与当前帧相同，各向同性度量，不同长度尺度）：\n  - $d = 2$, $M = I_2$, $\\ell = 0.8$。\n  - $\\mathcal{S}$:\n    - $S_1 = \\{ (0.0, 0.0), (1.0, 0.0) \\}$.\n  - $\\mathcal{C}$:\n    - $C_1 = \\{ (0.0, 0.0), (1.0, 0.0) \\}$,\n    - $C_2 = \\{ (3.0, 0.0), (3.5, 0.5) \\}$,\n    - $C_3 = \\{ (1.2, 0.1), (1.1, -0.1) \\}$.\n\n- 情况 3（各向异性度量，更高维度）：\n  - $d = 3$, $M = \\operatorname{diag}(2.0, 1.0, 0.5)$, $\\ell = 1.5$。\n  - $\\mathcal{S}$:\n    - $S_1 = \\{ (0.0, 0.0, 0.0), (0.2, -0.1, 0.0) \\}$,\n    - $S_2 = \\{ (1.0, 0.0, 0.0), (1.1, 0.1, -0.1) \\}$.\n  - $\\mathcal{C}$:\n    - $C_1 = \\{ (0.9, 0.0, 0.0), (1.2, -0.2, 0.2) \\}$,\n    - $C_2 = \\{ (-1.0, 0.0, 0.0), (-1.2, 0.2, -0.1) \\}$,\n    - $C_3 = \\{ (0.0, 1.0, 0.0), (0.0, 1.2, 0.2) \\}$.\n\n- 情况 4（单描述符帧，各向同性度量，小长度尺度）：\n  - $d = 2$, $M = I_2$, $\\ell = 0.5$。\n  - $\\mathcal{S}$:\n    - $S_1 = \\{ (0.0, 0.0) \\}$,\n    - $S_2 = \\{ (0.2, 0.2) \\}$.\n  - $\\mathcal{C}$:\n    - $C_1 = \\{ (0.0, 0.1) \\}$,\n    - $C_2 = \\{ (1.0, 1.0) \\}$,\n    - $C_3 = \\{ (0.25, 0.25) \\}$.\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，例如 $[r_1,r_2,r_3,r_4]$，其中每个 $r_i$ 是情况 $i$ 的所选候选者索引的整数形式。在每种情况下，索引都是相对于 $\\mathcal{C} = \\{ C_1, C_2, \\dots \\}$ 的 1-based 索引。",
            "solution": "我们提出一种在描述符空间中使用核诱导度量进行最大最小距离采样的原则性推导和算法，适用于机器学习（ML）原子间势的主动学习。其目标是选择一个候选 MD 帧，该帧在物理上有意义的描述符方面与当前已标记的帧最大程度地不相似，同时尊重由核编码的对称性和不变性。\n\n步骤1：核诱导的相似性与度量。设 $x,y \\in \\mathbb{R}^d$ 为描述符向量。具有各向异性度量矩阵 $M \\in \\mathbb{R}^{d \\times d}$ 和正长度尺度 $\\ell$ 的高斯径向基函数（RBF）核定义为\n$$\nk(x,y) = \\exp\\!\\left( - \\frac{1}{2 \\ell^2} (x-y)^\\top M (x-y) \\right).\n$$\n如果 $M$ 是对称半正定的，则量 $(x-y)^\\top M (x-y)$ 是一个有效的平方半范数，且 $k(x,y)$ 是正定的。这确保了再生核希尔伯特空间（RKHS）$\\mathcal{H}$ 和特征映射 $\\phi : \\mathbb{R}^d \\to \\mathcal{H}$ 的存在，使得 $k(x,y) = \\langle \\phi(x), \\phi(y) \\rangle_{\\mathcal{H}}$。在物理上，$M$ 可以编码跨描述符维度的各向异性缩放，反映了基于物理信息的描述符分量加权（例如，沿某些不变特征增强敏感性）。\n\n步骤2：帧的均值嵌入。对于一帧 $A = \\{ a_1,\\dots,a_{n_A} \\}$，将其在 $\\mathcal{H}$ 中的经验均值元素定义为\n$$\n\\mu_A = \\frac{1}{n_A} \\sum_{i=1}^{n_A} \\phi(a_i).\n$$\n这种构造将每个原子的信息聚合成一个帧级别的表示，保留了由核捕获的对称性。RKHS 范数 $||\\mu_A - \\mu_B||_{\\mathcal{H}}$ 通过其描述符的分布来衡量帧 $A$ 和 $B$ 之间的距离。\n\n步骤3：平方最大均值差异（MMD）。均值嵌入之间的平方距离是\n$$\n\\left\\| \\mu_A - \\mu_B \\right\\|_{\\mathcal{H}}^2\n= \\left\\langle \\mu_A, \\mu_A \\right\\rangle_{\\mathcal{H}}\n+ \\left\\langle \\mu_B, \\mu_B \\right\\rangle_{\\mathcal{H}}\n- 2 \\left\\langle \\mu_A, \\mu_B \\right\\rangle_{\\mathcal{H}},\n$$\n并且，根据再生性质，\n$$\n\\left\\langle \\mu_A, \\mu_A \\right\\rangle_{\\mathcal{H}}\n= \\left\\langle \\frac{1}{n_A} \\sum_{i=1}^{n_A} \\phi(a_i), \\frac{1}{n_A} \\sum_{j=1}^{n_A} \\phi(a_j) \\right\\rangle_{\\mathcal{H}}\n= \\frac{1}{n_A^2} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_A} \\left\\langle \\phi(a_i), \\phi(a_j) \\right\\rangle_{\\mathcal{H}}\n= \\frac{1}{n_A^2} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_A} k(a_i,a_j).\n$$\n类似地，\n$$\n\\left\\langle \\mu_B, \\mu_B \\right\\rangle_{\\mathcal{H}} = \\frac{1}{n_B^2} \\sum_{i=1}^{n_B} \\sum_{j=1}^{n_B} k(b_i,b_j),\n\\quad\n\\left\\langle \\mu_A, \\mu_B \\right\\rangle_{\\mathcal{H}} = \\frac{1}{n_A n_B} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_B} k(a_i,b_j).\n$$\n因此，\n$$\n\\operatorname{MMD}^2_{\\text{biased}}(A,B)\n= \\frac{1}{n_A^2} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_A} k(a_i,a_j)\n+ \\frac{1}{n_B^2} \\sum_{i=1}^{n_B} \\sum_{j=1}^{n_B} k(b_i,b_j)\n- \\frac{2}{n_A n_B} \\sum_{i=1}^{n_A} \\sum_{j=1}^{n_B} k(a_i,b_j).\n$$\n这个有偏估计量等于经验均值嵌入之间的平方 RKHS 距离，并且对于任何 $n_A \\ge 1$ 和 $n_B \\ge 1$ 都有定义，这对于包含单个描述符向量的帧至关重要。\n\n步骤4：最大最小距离选择。对于一个候选者 $C$ 和一个当前集 $\\mathcal{S} = \\{ S_1, \\dots, S_m \\}$，定义候选者到集合的距离\n$$\nd(C,\\mathcal{S}) = \\min_{S \\in \\mathcal{S}} \\sqrt{ \\operatorname{MMD}^2_{\\text{biased}}(C,S) }.\n$$\n最大最小采样选择\n$$\nC^* = \\arg\\max_{C \\in \\mathcal{C}} d(C,\\mathcal{S}).\n$$\n该规则通过优先选择与最近的当前帧最大程度不相似（在 RKHS 均值嵌入距离上）的候选者来促进探索。从基于物理信息的角度来看，这通过确保新帧占据描述符空间中代表性不足的区域，同时尊重编码在 $M$ 中的各向异性缩放和特征长度 $\\ell$，从而降低了外推风险。\n\n步骤5：算法实现。\n- 通过以下方式计算成对核矩阵 $K_{AA}$、$K_{BB}$ 和 $K_{AB}$\n$$\nK_{ij}^{AB} = k(a_i,b_j) = \\exp\\!\\left( - \\frac{1}{2 \\ell^2} (a_i-b_j)^\\top M (a_i-b_j) \\right).\n$$\n高效的评估使用恒等式\n$$\n(a-b)^\\top M (a-b) = a^\\top M a + b^\\top M b - 2 a^\\top M b,\n$$\n对所有对预先计算 $a^\\top M a$、$b^\\top M b$ 和 $a^\\top M b$。\n- 如上计算 $\\operatorname{MMD}^2_{\\text{biased}}(A,B)$。\n- 对每个候选者 $C_j$，评估 $d(C_j,\\mathcal{S}) = \\min_{S_i \\in \\mathcal{S}} \\sqrt{\\operatorname{MMD}^2_{\\text{biased}}(C_j,S_i)}$。\n- 通过在 $j$ 上最大化 $d(C_j,\\mathcal{S})$ 来选择 $C^*$。通过最小的 $j$（遇到的第一个最大值）来解决平局。\n\n步骤6：边界情况与数值考量。\n- 由于 $\\operatorname{MMD}^2_{\\text{biased}}(A,B)$ 在构造上是非负的，数值舍入误差可能会产生微小的负值；在取平方根之前，通过将其下限钳位在 $0$ 来强制非负性。\n- 当候选者与当前帧完全匹配时，核矩阵产生 $\\operatorname{MMD}^2_{\\text{biased}}(C,S) = 0$，因此 $d(C,\\mathcal{S}) = 0$，算法会正确地避免选择该候选者，除非所有候选者都同样接近。\n\n步骤7：输出规范。对于四个测试用例中的每一个，以整数形式返回所选候选者的 1-based 索引。将这四个整数汇总成单行，格式为 $[r_1,r_2,r_3,r_4]$。\n\n所提供的程序遵循此推导，实现了核和 MMD 计算，为每个测试用例应用了最大最小规则，并打印了所需的单行输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef rbf_kernel_matrix(X: np.ndarray, Y: np.ndarray, M: np.ndarray, ell: float) - np.ndarray:\n    \"\"\"\n    Compute the Gaussian RBF kernel matrix K between two sets of descriptor vectors X and Y\n    using an anisotropic metric M and length scale ell.\n\n    k(x,y) = exp( - (1/(2*ell^2)) * (x - y)^T M (x - y) )\n\n    Parameters:\n        X: shape (n_x, d)\n        Y: shape (n_y, d)\n        M: shape (d, d), symmetric positive semidefinite\n        ell: positive float\n\n    Returns:\n        K: shape (n_x, n_y)\n    \"\"\"\n    # Precompute terms using quadratic form identity:\n    # (x - y)^T M (x - y) = x^T M x + y^T M y - 2 x^T M y\n    X_M = X @ M           # shape (n_x, d)\n    Y_M = Y @ M           # shape (n_y, d)\n\n    xMx = np.einsum('ij,ij-i', X, X_M)  # shape (n_x,)\n    yMy = np.einsum('ij,ij-i', Y, Y_M)  # shape (n_y,)\n\n    cross = X @ M @ Y.T                   # shape (n_x, n_y)\n\n    # Broadcast to form pairwise metric distances squared\n    dist2 = xMx[:, None] + yMy[None, :] - 2.0 * cross\n\n    # Numerical safety: ensure non-negative due to PSD M\n    dist2 = np.maximum(dist2, 0.0)\n\n    K = np.exp(-0.5 * dist2 / (ell ** 2))\n    return K\n\ndef mmd2_biased(A: np.ndarray, B: np.ndarray, M: np.ndarray, ell: float) - float:\n    \"\"\"\n    Compute the biased squared MMD between two frames A and B (sets of descriptors),\n    using the Gaussian RBF kernel with metric M and length scale ell.\n\n    MMD^2_biased(A,B) = (1/n_A^2) sum_{i,j} k(a_i,a_j)\n                      + (1/n_B^2) sum_{i,j} k(b_i,b_j)\n                      - (2/(n_A n_B)) sum_{i,j} k(a_i,b_j)\n    \"\"\"\n    nA = A.shape[0]\n    nB = B.shape[0]\n\n    KA = rbf_kernel_matrix(A, A, M, ell)\n    KB = rbf_kernel_matrix(B, B, M, ell)\n    KAB = rbf_kernel_matrix(A, B, M, ell)\n\n    term_A = np.sum(KA) / (nA ** 2)\n    term_B = np.sum(KB) / (nB ** 2)\n    term_AB = (2.0 * np.sum(KAB)) / (nA * nB)\n\n    mmd2 = term_A + term_B - term_AB\n\n    # Clamp small negative due to numerical roundoff\n    if mmd2  0.0 and mmd2  -1e-12:\n        mmd2 = 0.0\n\n    return float(mmd2)\n\ndef maximin_candidate_index(current_frames, candidate_frames, M, ell):\n    \"\"\"\n    Given a list of current frames and candidate frames (each a numpy array of shape (n_i, d)),\n    return the 1-based index of the candidate that maximizes the minimum sqrt(MMD^2_biased)\n    to the current frames. Ties are broken by smallest index (np.argmax behavior).\n    \"\"\"\n    min_distances = []\n    for C in candidate_frames:\n        # Compute distance to each current frame\n        dists = []\n        for S in current_frames:\n            mmd2 = mmd2_biased(C, S, M, ell)\n            # Ensure non-negative before sqrt\n            dists.append(np.sqrt(max(mmd2, 0.0)))\n        # Candidate-to-set distance is min over current frames\n        min_distances.append(min(dists))\n\n    # Select the candidate with maximum min-distance; 1-based index\n    # np.argmax returns first occurrence in case of ties - smallest index tie-break\n    best_idx = int(np.argmax(min_distances)) + 1\n    return best_idx\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    test_cases = []\n\n    # Case 1\n    d1 = 2\n    M1 = np.eye(d1)\n    ell1 = 1.0\n    S1_1 = np.array([[0.0, 0.0],\n                     [1.0, 0.0],\n                     [0.5, 0.5]])\n    S1_2 = np.array([[2.0, 2.0],\n                     [2.5, 2.0]])\n    C1_1 = np.array([[3.0, 3.0],\n                     [2.8, 3.2]])\n    C1_2 = np.array([[0.9, 0.1],\n                     [0.6, 0.4]])\n    C1_3 = np.array([[-1.0, -1.0],\n                     [-0.5, -0.2]])\n    test_cases.append(( [S1_1, S1_2], [C1_1, C1_2, C1_3], M1, ell1 ))\n\n    # Case 2\n    d2 = 2\n    M2 = np.eye(d2)\n    ell2 = 0.8\n    S2_1 = np.array([[0.0, 0.0],\n                     [1.0, 0.0]])\n    C2_1 = np.array([[0.0, 0.0],\n                     [1.0, 0.0]])  # identical to S2_1\n    C2_2 = np.array([[3.0, 0.0],\n                     [3.5, 0.5]])\n    C2_3 = np.array([[1.2, 0.1],\n                     [1.1, -0.1]])\n    test_cases.append(( [S2_1], [C2_1, C2_2, C2_3], M2, ell2 ))\n\n    # Case 3\n    d3 = 3\n    M3 = np.diag([2.0, 1.0, 0.5])\n    ell3 = 1.5\n    S3_1 = np.array([[0.0, 0.0, 0.0],\n                     [0.2, -0.1, 0.0]])\n    S3_2 = np.array([[1.0, 0.0, 0.0],\n                     [1.1, 0.1, -0.1]])\n    C3_1 = np.array([[0.9, 0.0, 0.0],\n                     [1.2, -0.2, 0.2]])\n    C3_2 = np.array([[-1.0, 0.0, 0.0],\n                     [-1.2, 0.2, -0.1]])\n    C3_3 = np.array([[0.0, 1.0, 0.0],\n                     [0.0, 1.2, 0.2]])\n    test_cases.append(( [S3_1, S3_2], [C3_1, C3_2, C3_3], M3, ell3 ))\n\n    # Case 4\n    d4 = 2\n    M4 = np.eye(d4)\n    ell4 = 0.5\n    S4_1 = np.array([[0.0, 0.0]])\n    S4_2 = np.array([[0.2, 0.2]])\n    C4_1 = np.array([[0.0, 0.1]])\n    C4_2 = np.array([[1.0, 1.0]])\n    C4_3 = np.array([[0.25, 0.25]])\n    test_cases.append(( [S4_1, S4_2], [C4_1, C4_2, C4_3], M4, ell4 ))\n\n    results = []\n    for current_frames, candidate_frames, M, ell in test_cases:\n        idx = maximin_candidate_index(current_frames, candidate_frames, M, ell)\n        results.append(idx)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}