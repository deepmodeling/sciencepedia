{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of multiscale modeling is the ability to predict macroscopic properties from the fundamental interactions at the microscale. This first practice provides a concrete example of this \"bottom-up\" approach by bridging the atomistic and continuum realms. By applying the Cauchy-Born rule, which postulates that a macroscopic strain field directly governs the deformation of the underlying atomic lattice, you will derive the continuum elastic tensor from a simple pair potential, gaining insight into how continuum material parameters emerge from discrete atomic physics .",
            "id": "3799940",
            "problem": "Consider a two-dimensional triangular Bravais lattice with one atom per primitive cell and nearest-neighbor separation $a$. Under the Cauchy-Born assumption, a homogeneous small strain $\\,\\boldsymbol{\\varepsilon}\\,$ maps each reference bond vector $\\mathbf{R}$ to $\\mathbf{r} = (\\mathbf{I} + \\boldsymbol{\\varepsilon}) \\mathbf{R}$, where $\\mathbf{I}$ is the identity tensor. The per-atom energy is modeled by a central pair potential $\\phi(r)$, with the total energy per atom given by the sum over all distinct neighbor bonds. Assume only the six nearest neighbors contribute and adopt the harmonic form $\\phi(r) = \\tfrac{1}{2} k (r - a)^{2}$, where $k$ is a bond stiffness parameter inferred from a data-driven regression on atomistic simulations.\n\nLet the coordinate axes be chosen so that one of the six nearest-neighbor directions is aligned with the $x$-axis. The six unit direction vectors are\n$$\n\\mathbf{n}_{1} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix},\\quad\n\\mathbf{n}_{2} = \\begin{pmatrix}\\tfrac{1}{2} \\\\ \\tfrac{\\sqrt{3}}{2}\\end{pmatrix},\\quad\n\\mathbf{n}_{3} = \\begin{pmatrix}-\\tfrac{1}{2} \\\\ \\tfrac{\\sqrt{3}}{2}\\end{pmatrix},\\quad\n\\mathbf{n}_{4} = \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix},\\quad\n\\mathbf{n}_{5} = \\begin{pmatrix}-\\tfrac{1}{2} \\\\ -\\tfrac{\\sqrt{3}}{2}\\end{pmatrix},\\quad\n\\mathbf{n}_{6} = \\begin{pmatrix}\\tfrac{1}{2} \\\\ -\\tfrac{\\sqrt{3}}{2}\\end{pmatrix}.\n$$\nEach reference bond is $\\mathbf{R}_{m} = a\\,\\mathbf{n}_{m}$ for $m = 1,\\dots,6$. The primitive cell area is $A_{0} = \\tfrac{\\sqrt{3}}{2} a^{2}$, so the atomic number density is $\\rho_{\\mathrm{atom}} = \\tfrac{1}{A_{0}} = \\tfrac{2}{\\sqrt{3}\\,a^{2}}$.\n\nStarting from the definition of strain energy density and the Cauchy-Born mapping, derive the continuum elastic tensor $C_{ijkl}$ in terms of lattice sums over the nearest-neighbor directions and fundamental quantities. Then, using the provided directions, evaluate $C_{1111}$ explicitly.\n\nFinally, given the data-driven parameter $k = 45\\,\\text{N/m}$ and $a = 2.50 \\times 10^{-10}\\,\\text{m}$, compute the numerical value of $C_{1111}$ for this lattice. Express your final answer in $\\text{N/m}$ and round to four significant figures.",
            "solution": "The starting point is the strain energy density per unit area, $W(\\boldsymbol{\\varepsilon})$, obtained from the per-atom energy under the Cauchy-Born assumption. For a central pair potential $\\phi(r)$ and a homogeneous small strain $\\boldsymbol{\\varepsilon}$, each reference bond vector $\\mathbf{R}$ of magnitude $a$ and unit direction $\\mathbf{n}$ is mapped to\n$$\n\\mathbf{r} = (\\mathbf{I} + \\boldsymbol{\\varepsilon}) \\mathbf{R} = a\\,(\\mathbf{I} + \\boldsymbol{\\varepsilon}) \\mathbf{n}.\n$$\nTo leading order in $\\boldsymbol{\\varepsilon}$, the stretched bond length is\n$$\nr = \\|\\mathbf{r}\\| = a\\,\\left\\|(\\mathbf{I} + \\boldsymbol{\\varepsilon}) \\mathbf{n}\\right\\| \\approx a \\left( 1 + \\mathbf{n}^{\\mathsf{T}} \\boldsymbol{\\varepsilon}\\, \\mathbf{n} \\right),\n$$\nso the first-order change in bond length is\n$$\n\\delta r \\equiv r - a \\approx a\\,\\mathbf{n}^{\\mathsf{T}} \\boldsymbol{\\varepsilon}\\, \\mathbf{n} = a\\, n_{i}\\,\\varepsilon_{ij}\\,n_{j},\n$$\nwhere the Einstein summation convention is used.\n\nThe per-atom energy for a pair potential is\n$$\nE_{\\mathrm{atom}} = \\tfrac{1}{2}\\sum_{m} \\phi(r_{m}),\n$$\nwhere the factor $\\tfrac{1}{2}$ prevents double counting of pairs. For the harmonic $\\phi(r) = \\tfrac{1}{2}k (r - a)^{2}$ and small strain, the change in per-atom energy to second order is\n$$\n\\Delta E_{\\mathrm{atom}} = \\tfrac{1}{2} \\sum_{m} \\tfrac{1}{2} k\\, (\\delta r_{m})^{2}\n= \\tfrac{k}{4} \\sum_{m} \\left( a\\, n^{(m)}_{i}\\,\\varepsilon_{ij}\\,n^{(m)}_{j} \\right)^{2}\n= \\tfrac{k a^{2}}{4} \\sum_{m} \\varepsilon_{ij}\\,\\varepsilon_{kl}\\, n^{(m)}_{i} n^{(m)}_{j} n^{(m)}_{k} n^{(m)}_{l}.\n$$\nMultiplying by the atomic number density $\\rho_{\\mathrm{atom}}$ gives the strain energy density per unit area:\n$$\n\\Delta W(\\boldsymbol{\\varepsilon}) = \\rho_{\\mathrm{atom}}\\,\\Delta E_{\\mathrm{atom}}\n= \\tfrac{k a^{2}}{4}\\,\\rho_{\\mathrm{atom}} \\sum_{m} \\varepsilon_{ij}\\,\\varepsilon_{kl}\\, n^{(m)}_{i} n^{(m)}_{j} n^{(m)}_{k} n^{(m)}_{l}.\n$$\nBy definition of the elastic tensor,\n$$\n\\Delta W(\\boldsymbol{\\varepsilon}) = \\tfrac{1}{2} C_{ijkl}\\, \\varepsilon_{ij}\\, \\varepsilon_{kl}.\n$$\nMatching coefficients of $\\varepsilon_{ij}\\varepsilon_{kl}$, we obtain\n$$\nC_{ijkl} = \\tfrac{k a^{2}}{2}\\,\\rho_{\\mathrm{atom}} \\sum_{m} n^{(m)}_{i} n^{(m)}_{j} n^{(m)}_{k} n^{(m)}_{l}.\n$$\n\nWe now evaluate $C_{1111}$ for the triangular lattice using the six given unit vectors. Writing $n_{1}^{(m)}$ for the $x$-component of $\\mathbf{n}_{m}$, we have\n$$\nC_{1111} = \\tfrac{k a^{2}}{2}\\,\\rho_{\\mathrm{atom}} \\sum_{m=1}^{6} \\left(n_{1}^{(m)}\\right)^{4}.\n$$\nThe six $x$-components are $1,\\,\\tfrac{1}{2},\\,-\\tfrac{1}{2},\\,-1,\\,-\\tfrac{1}{2},\\,\\tfrac{1}{2}$, so\n$$\n\\sum_{m=1}^{6} \\left(n_{1}^{(m)}\\right)^{4} = 1^{4} + \\left(\\tfrac{1}{2}\\right)^{4} + \\left(-\\tfrac{1}{2}\\right)^{4} + (-1)^{4} + \\left(-\\tfrac{1}{2}\\right)^{4} + \\left(\\tfrac{1}{2}\\right)^{4}\n= 2 + 4 \\times \\tfrac{1}{16} = 2 + \\tfrac{1}{4} = \\tfrac{9}{4}.\n$$\nThe atomic number density is\n$$\n\\rho_{\\mathrm{atom}} = \\tfrac{1}{A_{0}} = \\tfrac{2}{\\sqrt{3}\\,a^{2}}.\n$$\nTherefore,\n$$\nC_{1111} = \\tfrac{k a^{2}}{2} \\cdot \\tfrac{2}{\\sqrt{3}\\,a^{2}} \\cdot \\tfrac{9}{4} = \\tfrac{9}{4\\sqrt{3}}\\,k.\n$$\n\nSubstituting $k = 45\\,\\text{N/m}$ and $a = 2.50 \\times 10^{-10}\\,\\text{m}$ (which cancels, as shown), we obtain\n$$\nC_{1111} = \\tfrac{9}{4\\sqrt{3}} \\times 45 \\,\\text{N/m}.\n$$\nUsing $\\sqrt{3} \\approx 1.7320508076$,\n$$\n\\tfrac{9}{4\\sqrt{3}} \\approx \\tfrac{9}{6.9282032303} \\approx 1.299038105,\n$$\nand thus\n$$\nC_{1111} \\approx 1.299038105 \\times 45 \\,\\text{N/m} \\approx 58.4567147 \\,\\text{N/m}.\n$$\nRounded to four significant figures and expressed in $\\text{N/m}$, the result is $58.46\\,\\text{N/m}$.",
            "answer": "$$\\boxed{58.46}$$"
        },
        {
            "introduction": "While perfect crystals provide a clean theoretical link between scales, most engineering materials are heterogeneous, with properties that vary in space. This raises a critical question: what is the minimum volume of material—the Representative Volume Element (RVE)—that statistically captures the behavior of the bulk? This exercise guides you through a numerical experiment to answer this question, where you will use statistical mechanics to quantify how the variance of the effective modulus decreases with sample size, providing a rigorous method for determining the RVE .",
            "id": "3799899",
            "problem": "A representative volume element (RVE) is a minimal volume that statistically represents a heterogeneous material’s properties. Consider a one-dimensional heterogeneous linear elastic bar subject to uniform macroscopic strain boundary conditions. The local stress at position $x$ is given by Hooke’s law $\\sigma(x) = E(x)\\,\\epsilon$, where $E(x)$ is the spatially varying Young’s modulus and $\\epsilon$ is the imposed uniform strain. The effective modulus $E_{\\mathrm{eff}}$ under uniform strain boundary conditions is defined by the ratio of the volume-averaged stress to the applied strain, which reduces to the volume average of $E(x)$ under these conditions. Discretize the bar into $N$ equal cells with local moduli $\\{E_i\\}_{i=1}^N$, and define the discrete effective modulus as $E_{\\mathrm{eff}}(N) = \\frac{1}{N}\\sum_{i=1}^N E_i$. Assume the logarithm of the local modulus $X_i = \\ln(E_i)$ is a stationary Gaussian random field with mean $\\mu$, variance $\\sigma^2$, and an exponential covariance function $\\mathrm{Cov}(X_i, X_j) = \\sigma^2 \\exp\\!\\left(-\\frac{|i-j|\\Delta}{\\ell}\\right)$, where $\\Delta$ is the cell size (set $\\Delta=1$ without loss of generality) and $\\ell$ is the correlation length in cells. Let the target mean modulus be $m = \\mathbb{E}[E_i]$ in $\\mathrm{GPa}$.\n\nYour task is to design and implement a numerical experiment that, for specified parameters $(m,\\sigma,\\ell)$ and a coefficient of variation threshold $\\tau$, computes the smallest RVE size $N$ (as an integer number of cells) for which the coefficient of variation of $E_{\\mathrm{eff}}(N)$, defined as $\\mathrm{CoV}(N) = \\sqrt{\\mathrm{Var}(E_{\\mathrm{eff}}(N))}/\\mathbb{E}[E_{\\mathrm{eff}}(N)]$, is strictly less than the prescribed threshold $\\tau$. The numerical experiment must start from the definitions and fundamental laws provided and should treat the effective modulus as a data-driven quantity obtained from the statistical characterization of the microstructure. The program must search $N$ over a specified interval $[N_{\\min}, N_{\\max}]$ and report the smallest $N$ satisfying the threshold if it exists; otherwise, report a sentinel value indicating that the threshold was not met within the search range.\n\nYou must:\n- Use the discretized definition $E_{\\mathrm{eff}}(N) = \\frac{1}{N}\\sum_{i=1}^{N} E_i$ and the given stationary Gaussian model for $X_i = \\ln(E_i)$ to derive an explicit computable expression for $\\mathrm{Var}(E_{\\mathrm{eff}}(N))$, using only the fundamental properties of Gaussian and lognormal random variables and the definition of variance of a mean with correlated entries. Do not use any external data or fit shortcuts.\n- Convert the target mean modulus $m$ to parameters $(\\mu,\\sigma^2)$ of the Gaussian field of $\\ln(E)$ using only the fundamental definitions. Express modulus in $\\mathrm{GPa}$, and the variance in $(\\mathrm{GPa})^2$. The coefficient of variation is unitless and must be compared to the unitless threshold $\\tau$.\n- Compute, for each candidate $N$, the variance $\\mathrm{Var}(E_{\\mathrm{eff}}(N))$ in $(\\mathrm{GPa})^2$ and $\\mathrm{CoV}(N)$, and determine the smallest $N$ such that $\\mathrm{CoV}(N) < \\tau$.\n\nDesign a test suite that evaluates different facets of the behavior:\n- Case A (typical heterogeneity and moderate correlation): $m = 70$ $\\mathrm{GPa}$, $\\sigma = 0.3$, $\\ell = 3$ cells, $\\tau = 0.05$, $N_{\\min} = 1$, $N_{\\max} = 400$.\n- Case B (strong heterogeneity and long correlation): $m = 70$ $\\mathrm{GPa}$, $\\sigma = 0.5$, $\\ell = 50$ cells, $\\tau = 0.10$, $N_{\\min} = 1$, $N_{\\max} = 500$.\n- Case C (weak heterogeneity and very short correlation): $m = 70$ $\\mathrm{GPa}$, $\\sigma = 0.2$, $\\ell = 0.1$ cells, $\\tau = 0.01$, $N_{\\min} = 1$, $N_{\\max} = 1000$.\n- Case D (stringent threshold possibly unattainable): $m = 70$ $\\mathrm{GPa}$, $\\sigma = 0.6$, $\\ell = 100$ cells, $\\tau = 0.002$, $N_{\\min} = 1$, $N_{\\max} = 500$.\n\nFor each case, your program must compute the smallest $N$ satisfying the threshold within $[N_{\\min}, N_{\\max}]$. If such an $N$ exists, output a list containing three values: the integer $N$, the float $\\mathrm{Var}(E_{\\mathrm{eff}}(N))$ in $(\\mathrm{GPa})^2$, and the float $\\mathrm{CoV}(N)$. If no such $N$ exists, output a list containing the integer $-1$, followed by the float $\\mathrm{Var}(E_{\\mathrm{eff}}(N_{\\max}))$ in $(\\mathrm{GPa})^2$, and the float $\\mathrm{CoV}(N_{\\max})$.\n\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, with each test case’s result enclosed in its own square brackets. For example, the output should look like $[[N_1,Var_1,CoV_1],[N_2,Var_2,CoV_2],...]$ but with no spaces anywhere in the string. Ensure that all values are numerically computed, and that the result uses $\\mathrm{GPa}$ for modulus and $(\\mathrm{GPa})^2$ for variance where applicable.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and all necessary parameters and definitions are provided for a unique solution. The concepts involved, such as the Representative Volume Element (RVE), homogenization under uniform strain boundary conditions, and modeling material properties with a stationary Gaussian random field, are standard in multiscale materials modeling.\n\nThe solution is developed through a principle-based design in three main steps:\n1.  Derivation of the statistical properties of the effective modulus.\n2.  Formulation of the condition for the RVE size.\n3.  Design of a numerical algorithm to find the RVE size.\n\n**1. Derivation of Statistical Properties**\n\nThe problem specified a one-dimensional bar where the logarithm of the local Young's modulus, $X_i = \\ln(E_i)$, follows a stationary Gaussian random field. This implies that the local modulus, $E_i = e^{X_i}$, follows a lognormal distribution.\n\n**Relationship between Lognormal and Gaussian Parameters:**\nLet $X_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$. The problem provides the mean of the local modulus, $m = \\mathbb{E}[E_i]$, and the standard deviation of the underlying Gaussian field, $\\sigma$. The mean of a lognormal variable $E_i = e^{X_i}$ is given by:\n$$m = \\mathbb{E}[E_i] = \\exp\\left(\\mu + \\frac{\\sigma^2}{2}\\right)$$\nWe can solve for the mean $\\mu$ of the Gaussian field:\n$$\\ln(m) = \\mu + \\frac{\\sigma^2}{2} \\implies \\mu = \\ln(m) - \\frac{\\sigma^2}{2}$$\nThe parameter $\\sigma^2$ is directly given. These two parameters, $\\mu$ and $\\sigma^2$, completely define the underlying Gaussian field.\n\n**Expectation of the Effective Modulus:**\nThe effective modulus $E_{\\mathrm{eff}}(N)$ for a system of size $N$ is defined as the arithmetic mean of the local moduli:\n$$E_{\\mathrm{eff}}(N) = \\frac{1}{N}\\sum_{i=1}^N E_i$$\nBy linearity of expectation, the mean of the effective modulus is:\n$$\\mathbb{E}[E_{\\mathrm{eff}}(N)] = \\mathbb{E}\\left[\\frac{1}{N}\\sum_{i=1}^N E_i\\right] = \\frac{1}{N}\\sum_{i=1}^N \\mathbb{E}[E_i]$$\nSince the random field is stationary, $\\mathbb{E}[E_i] = m$ for all $i = 1, \\dots, N$. Thus,\n$$\\mathbb{E}[E_{\\mathrm{eff}}(N)] = \\frac{1}{N} \\sum_{i=1}^N m = m$$\nThe expected effective modulus is independent of the RVE size $N$ and is equal to the mean local modulus $m$.\n\n**Variance of the Effective Modulus:**\nThe variance of $E_{\\mathrm{eff}}(N)$ is found using the properties of the variance of a sum of correlated random variables:\n$$\\mathrm{Var}(E_{\\mathrm{eff}}(N)) = \\mathrm{Var}\\left(\\frac{1}{N}\\sum_{i=1}^N E_i\\right) = \\frac{1}{N^2} \\mathrm{Var}\\left(\\sum_{i=1}^N E_i\\right) = \\frac{1}{N^2} \\sum_{i=1}^N \\sum_{j=1}^N \\mathrm{Cov}(E_i, E_j)$$\nThe covariance $\\mathrm{Cov}(E_i, E_j)$ for two jointly lognormal random variables is related to the covariance of the underlying Gaussian variables $X_i$ and $X_j$ by:\n$$\\mathrm{Cov}(E_i, E_j) = \\mathbb{E}[E_i]\\mathbb{E}[E_j] \\left(\\exp(\\mathrm{Cov}(X_i, X_j)) - 1\\right)$$\nGiven $\\mathbb{E}[E_i] = m$ and $\\mathrm{Cov}(X_i, X_j) = \\sigma^2 \\exp\\left(-\\frac{|i-j|}{\\ell}\\right)$ (with $\\Delta=1$), we have:\n$$\\mathrm{Cov}(E_i, E_j) = m^2 \\left(\\exp\\left[\\sigma^2 \\exp\\left(-\\frac{|i-j|}{\\ell}\\right)\\right] - 1\\right)$$\nNote that for $i=j$, $|i-j|=0$, giving $\\mathrm{Cov}(X_i, X_i) = \\mathrm{Var}(X_i) = \\sigma^2$. The covariance expression correctly reduces to the variance of a single cell: $\\mathrm{Var}(E_i) = m^2 \\left(\\exp(\\sigma^2) - 1\\right)$.\n\nSubstituting the covariance into the variance expression for $E_{\\mathrm{eff}}(N)$ and exploiting the stationarity (covariance only depends on distance $k = |i-j|$):\n$$\\mathrm{Var}(E_{\\mathrm{eff}}(N)) = \\frac{1}{N^2} \\left( N \\cdot \\mathrm{Var}(E_1) + 2 \\sum_{k=1}^{N-1} (N-k) \\mathrm{Cov}(E_i, E_{i+k}) \\right)$$\n$$\\mathrm{Var}(E_{\\mathrm{eff}}(N)) = \\frac{m^2}{N^2} \\left( N(\\exp(\\sigma^2) - 1) + 2 \\sum_{k=1}^{N-1} (N-k) \\left(\\exp\\left[\\sigma^2 \\exp\\left(-\\frac{k}{\\ell}\\right)\\right] - 1\\right) \\right)$$\nThis provides a computable formula for the variance of the effective modulus.\n\n**2. Formulation of the RVE Condition**\n\nThe RVE size $N$ is determined by the coefficient of variation, $\\mathrm{CoV}(N)$, falling below a threshold $\\tau$.\n$$\\mathrm{CoV}(N) = \\frac{\\sqrt{\\mathrm{Var}(E_{\\mathrm{eff}}(N))}}{\\mathbb{E}[E_{\\mathrm{eff}}(N)]} < \\tau$$\nSubstituting the expressions for the mean and variance:\n$$\\mathrm{CoV}(N) = \\frac{\\sqrt{\\frac{m^2}{N^2} \\left[ N(\\exp(\\sigma^2) - 1) + 2 \\sum_{k=1}^{N-1} (N-k) \\left(\\exp\\left[\\sigma^2 \\exp\\left(-\\frac{k}{\\ell}\\right)\\right] - 1\\right) \\right]}}{m}$$\nThe term $m$ cancels, yielding an expression for $\\mathrm{CoV}(N)$ that depends only on the RVE size $N$ and the statistical parameters of the microstructure, $\\sigma$ and $\\ell$:\n$$\\mathrm{CoV}(N) = \\frac{1}{N} \\sqrt{N(\\exp(\\sigma^2) - 1) + 2 \\sum_{k=1}^{N-1} (N-k) \\left(\\exp\\left[\\sigma^2 \\exp\\left(-\\frac{k}{\\ell}\\right)\\right] - 1\\right)}$$\nThe task is to find the smallest integer $N \\in [N_{\\min}, N_{\\max}]$ that satisfies $\\mathrm{CoV}(N) < \\tau$.\n\n**3. Numerical Algorithm Design**\n\nThe function $\\mathrm{CoV}(N)$ is a monotonically decreasing function of $N$. Therefore, we can find the smallest integer $N$ satisfying the RVE condition by performing a linear search starting from $N_{\\min}$.\n\nThe algorithm for a given set of parameters $(m, \\sigma, \\ell, \\tau, N_{\\min}, N_{\\max})$ is as follows:\n1.  Initiate a loop for $N$ from $N_{\\min}$ to $N_{\\max}$.\n2.  For each $N$, compute $\\mathrm{CoV}(N)$ using the derived formula. This involves calculating a sum over $k$ from $1$ to $N-1$.\n3.  Check if the condition $\\mathrm{CoV}(N) < \\tau$ is met.\n4.  If the condition is met, this $N$ is the smallest RVE size. Calculate the corresponding variance $\\mathrm{Var}(E_{\\mathrm{eff}}(N)) = m^2 \\cdot \\mathrm{CoV}(N)^2$. Return the triplet $[N, \\mathrm{Var}(E_{\\mathrm{eff}}(N)), \\mathrm{CoV}(N)]$ and terminate the search for this case.\n5.  If the loop completes without finding an adequate $N$, the threshold is not met within the specified range. In this case, calculate $\\mathrm{Var}(E_{\\mathrm{eff}}(N_{\\max}))$ and $\\mathrm{CoV}(N_{\\max})$. Return the triplet $[-1, \\mathrm{Var}(E_{\\mathrm{eff}}(N_{\\max})), \\mathrm{CoV}(N_{\\max})]$.\n\nThis procedure is implemented for each test case to generate the final result. The use of NumPy allows for efficient, vectorized computation of the summation term for each $N$.",
            "answer": "```python\nimport numpy as np\n\ndef find_rve_size(m, sigma, ell, tau, N_min, N_max):\n    \"\"\"\n    Computes the smallest RVE size N for which CoV(N) < tau.\n\n    Args:\n        m (float): Target mean modulus in GPa.\n        sigma (float): Standard deviation of the underlying Gaussian field ln(E).\n        ell (float): Correlation length in cells.\n        tau (float): Coefficient of variation threshold.\n        N_min (int): Minimum RVE size to search.\n        N_max (int): Maximum RVE size to search.\n\n    Returns:\n        list: A list containing [N, Var(E_eff(N)), CoV(N)] if a solution\n              is found, or [-1, Var(E_eff(N_max)), CoV(N_max)] otherwise.\n    \"\"\"\n    sigma_sq = sigma**2\n\n    # Loop through N to find the smallest size that meets the threshold\n    for N in range(N_min, N_max + 1):\n        # Calculate the summation term for CoV^2\n        if N == 1:\n            sum_val = 0.0\n        else:\n            k_vals = np.arange(1, N, dtype=np.float64)\n            # A_k = exp(sigma^2 * exp(-k/ell)) - 1\n            A_k_vals = np.exp(sigma_sq * np.exp(-k_vals / ell)) - 1.0\n            sum_val = np.sum((N - k_vals) * A_k_vals)\n\n        # Calculate CoV^2(N)\n        # CoV^2 = (1/N^2) * [ N*(exp(sigma^2)-1) + 2 * sum_val ]\n        first_term = N * (np.exp(sigma_sq) - 1.0)\n        cov_sq = (first_term + 2.0 * sum_val) / (N**2)\n        \n        # Ensure non-negativity before sqrt\n        if cov_sq < 0:\n            cov_sq = 0\n\n        cov = np.sqrt(cov_sq)\n\n        if cov < tau:\n            var_eff = (m**2) * cov_sq\n            return [N, var_eff, cov]\n\n    # If the loop finishes, no N was found in the range.\n    # We must report the values at N_max.\n    if N_max == 1:\n        sum_val_max = 0.0\n    else:\n        k_vals_max = np.arange(1, N_max, dtype=np.float64)\n        A_k_vals_max = np.exp(sigma_sq * np.exp(-k_vals_max / ell)) - 1.0\n        sum_val_max = np.sum((N_max - k_vals_max) * A_k_vals_max)\n\n    first_term_max = N_max * (np.exp(sigma_sq) - 1.0)\n    cov_sq_max = (first_term_max + 2.0 * sum_val_max) / (N_max**2)\n    \n    if cov_sq_max < 0:\n        cov_sq_max = 0\n\n    cov_max = np.sqrt(cov_sq_max)\n    var_eff_max = (m**2) * cov_sq_max\n\n    return [-1, var_eff_max, cov_max]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        # (m, sigma, ell, tau, N_min, N_max)\n        (70.0, 0.3, 3.0, 0.05, 1, 400),\n        (70.0, 0.5, 50.0, 0.10, 1, 500),\n        (70.0, 0.2, 0.1, 0.01, 1, 1000),\n        (70.0, 0.6, 100.0, 0.002, 1, 500),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = find_rve_size(*case)\n        results.append(result)\n\n    result_strings = [f\"[{res[0]},{res[1]},{res[2]}]\" for res in results]\n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "The previous practices focused on using microscale information to inform or parameterize a continuum model. This final exercise introduces a paradigm shift in computational mechanics, where problems can be solved directly from raw material data without ever formulating an explicit constitutive law. You will implement a Data-Driven Computational Mechanics (DDCM) solver that finds a state satisfying both physical laws and the provided data, giving you a hands-on experience with a powerful, emerging approach that places data at the center of the simulation workflow .",
            "id": "3799898",
            "problem": "Consider a one-dimensional bar in tension discretized into three serial subdomains (elements) with given lengths and cross-sectional areas. The bar is subjected to a prescribed end displacement under displacement control. You are given a finite set of experimental strain-stress pairs that define the available material data. The task is to implement a Data-Driven Computational Mechanics (DDCM) solver that, for each test case, computes the equilibrium solution under the displacement control and reports the indices of the selected experimental data pairs for each element at convergence.\n\nUse the following foundational principles:\n- Equilibrium in a one-dimensional bar in series requires a uniform stress across all elements, that is, $\\,\\sigma_e = \\sigma\\,$ for all elements $\\,e\\,$.\n- Kinematic compatibility in a one-dimensional bar under an end displacement $\\,u\\,$ requires that the elongations sum to the prescribed displacement, that is, $\\,\\sum_{e=1}^{n} \\varepsilon_e L_e = u\\,$ where $\\,\\varepsilon_e\\,$ is the strain in element $\\,e\\,$ and $\\,L_e\\,$ is its length.\n- The Data-Driven Computational Mechanics (DDCM) approach seeks the state closest to the material data set while satisfying equilibrium and compatibility in a metric that is physically grounded. Use a metric weighted by a reference modulus $\\,E_0\\,$ such that the squared distance for each element $\\,e\\,$ is $\\,E_0 (\\varepsilon_e - \\varepsilon_i)^2 + \\frac{1}{E_0} (\\sigma_e - \\sigma_i)^2\\,$ for any candidate data point $\\,(\\varepsilon_i, \\sigma_i)\\,$.\n\nDefine the geometry and material reference:\n- Number of elements: $\\,n = 3\\,$.\n- Lengths: $\\,L = [0.4, 0.3, 0.3]\\,\\text{m}\\,$.\n- Cross-sectional areas: $\\,A = [1.0 \\times 10^{-4}, 1.0 \\times 10^{-4}, 8.0 \\times 10^{-5}]\\,\\text{m}^2\\,$.\n- Reference modulus: $\\,E_0 = 2.0 \\times 10^{11}\\,\\text{Pa}\\,$.\n- Element weights: use $\\,w_e = A_e L_e\\,$ to account for the contribution of each element to the metric.\n\nMaterial data set (available experimental pairs used identically for all elements):\n- Indices $\\,i = 0, 1, 2, 3, 4, 5, 6\\,$ with pairs $\\,(\\varepsilon_i, \\sigma_i)\\,$ given by:\n  - $\\,i=0:\\,(\\,-1.0 \\times 10^{-3},\\,-2.0 \\times 10^{8}\\,)\\,$\n  - $\\,i=1:\\,(\\,0.0,\\,0.0\\,)\\,$\n  - $\\,i=2:\\,(\\,5.0 \\times 10^{-4},\\,1.0 \\times 10^{8}\\,)\\,$\n  - $\\,i=3:\\,(\\,1.0 \\times 10^{-3},\\,2.0 \\times 10^{8}\\,)\\,$\n  - $\\,i=4:\\,(\\,1.5 \\times 10^{-3},\\,2.05 \\times 10^{8}\\,)\\,$\n  - $\\,i=5:\\,(\\,2.0 \\times 10^{-3},\\,2.10 \\times 10^{8}\\,)\\,$\n  - $\\,i=6:\\,(\\,3.0 \\times 10^{-3},\\,2.20 \\times 10^{8}\\,)\\,$\nAll stresses are in Pascals ($\\,\\text{Pa}\\,$), all strains are dimensionless.\n\nAlgorithmic requirements:\n- Implement an alternating projection algorithm:\n  1. Projection onto the constraint set $\\,\\mathcal{C}\\,$ defined by equilibrium ($\\,\\sigma_e = \\sigma\\,$ for all $\\,e\\,$) and compatibility ($\\,\\sum_e \\varepsilon_e L_e = u\\,$), minimizing the weighted metric with weights $\\,w_e\\,$ and scaling by $\\,E_0\\,$.\n  2. Projection onto the data set $\\,\\mathcal{D}\\,$ for each element, selecting the data pair $\\,(\\varepsilon_i, \\sigma_i)\\,$ that minimizes the metric $\\,E_0 (\\varepsilon_e - \\varepsilon_i)^2 + \\frac{1}{E_0} (\\sigma - \\sigma_i)^2\\,$ for the current element state $\\,(\\varepsilon_e, \\sigma)\\,$.\n  3. Repeat until the selected indices stabilize. If multiple data points have equal distance, select the one with the smallest index.\n- Initialize the algorithm by selecting, for each element, the data point closest to the initial guess $\\,(\\varepsilon^{(0)}, \\sigma^{(0)})\\,$ where $\\,\\varepsilon^{(0)} = u / L_{\\text{tot}}\\,$ and $\\,\\sigma^{(0)} = E_0 \\varepsilon^{(0)}\\,$, with $\\,L_{\\text{tot}} = \\sum_e L_e\\,$.\n\nTest suite:\n- Prescribed displacements $\\,u\\,$ (in meters):\n  - $\\,u_1 = 0.0\\,$\n  - $\\,u_2 = 1.0 \\times 10^{-5}\\,$\n  - $\\,u_3 = 1.0 \\times 10^{-3}\\,$\n  - $\\,u_4 = 3.0 \\times 10^{-3}\\,$\nThese cover a compatibility boundary case, a very small displacement case where data sparsity may lead to zero-strain selection, a typical tension loading near a well-populated data point, and a higher loading case testing selection at the upper end of the data set.\n\nOutput specification:\n- For each prescribed displacement $\\,u_k\\,$, your program must return a list of $\\,n\\,$ integers representing the indices of the selected experimental data pairs for elements $\\,e = 1,2,3\\,$ at convergence.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry corresponds to one test case and is itself a list of three integers (e.g., [[i_{1,1},i_{1,2},i_{1,3}],[i_{2,1},i_{2,2},i_{2,3}],[i_{3,1},i_{3,2},i_{3,3}],[i_{4,1},i_{4,2},i_{4,3}]]).\n\nUnits:\n- Displacement $\\,u\\,$ must be in meters ($\\,\\text{m}\\,$).\n- Stress $\\,\\sigma\\,$ must be in Pascals ($\\,\\text{Pa}\\,$).\n- Strain $\\,\\varepsilon\\,$ is dimensionless.\n\nYour implementation must be purely numerical and must not rely on external solvers beyond standard numerical computations. The test suite is fixed and must be embedded in your program.",
            "solution": "The problem is valid. It is scientifically grounded in the principles of solid mechanics and computational physics, well-posed with a clear objective and constraints, and provides all necessary data for a unique numerical solution. The following is a complete, reasoned solution.\n\nThe core of the Data-Driven Computational Mechanics (DDCM) problem is to find a mechanical state $(\\boldsymbol{\\varepsilon}, \\boldsymbol{\\sigma})$, where $\\boldsymbol{\\varepsilon} = \\{\\varepsilon_e\\}_{e=1}^n$ and $\\boldsymbol{\\sigma} = \\{\\sigma_e\\}_{e=1}^n$, that simultaneously satisfies a set of physical laws (the constraint set $\\mathcal{C}$) and is as close as possible to a set of material data points (the data set $\\mathcal{D}$). The state $(\\boldsymbol{\\varepsilon}^*, \\boldsymbol{\\sigma}^*)$, where $(\\varepsilon_e^*, \\sigma_e^*) \\in \\mathcal{D}$ for each element $e$, represents the chosen data points.\n\nThe problem is formulated as minimizing a total distance functional, $J$, subject to these two sets of constraints:\n$$\n\\min_{(\\boldsymbol{\\varepsilon}, \\boldsymbol{\\sigma}) \\in \\mathcal{C}, (\\boldsymbol{\\varepsilon}^*, \\boldsymbol{\\sigma}^*) \\in \\mathcal{D}^n} J(\\boldsymbol{\\varepsilon}, \\boldsymbol{\\sigma}, \\boldsymbol{\\varepsilon}^*, \\boldsymbol{\\sigma}^*) = \\sum_{e=1}^{n} w_e \\left[ E_0 (\\varepsilon_e - \\varepsilon_e^*)^2 + \\frac{1}{E_0} (\\sigma_e - \\sigma_e^*)^2 \\right]\n$$\nHere, $n=3$ is the number of elements, $w_e = A_e L_e$ is the volume-based weight for element $e$, and $E_0$ is a reference modulus. The constraint set $\\mathcal{C}$ enforces:\n1.  **Equilibrium**: The stress $\\sigma$ is uniform across all elements, i.e., $\\sigma_e = \\sigma$ for $e=1, \\dots, n$.\n2.  **Compatibility**: The total elongation equals the prescribed displacement $u$, i.e., $\\sum_{e=1}^{n} \\varepsilon_e L_e = u$.\n\nThe data set $\\mathcal{D}$ consists of a finite number of discrete strain-stress pairs $(\\varepsilon_i, \\sigma_i)$.\n\nThis minimization problem is solved using an alternating projection algorithm, which iteratively projects the current state onto the constraint set $\\mathcal{C}$ and the data set $\\mathcal{D}$ until convergence.\n\n### Algorithm Description\n\n**1. Initialization**\nFor a given prescribed displacement $u$, an initial guess for the state is formed based on a homogeneous linear elastic assumption.\n- The total length of the bar is $L_{\\text{tot}} = \\sum_{e=1}^n L_e$.\n- The average strain is $\\varepsilon^{(0)} = u / L_{\\text{tot}}$.\n- The initial stress is $\\sigma^{(0)} = E_0 \\varepsilon^{(0)}$.\nThe algorithm begins with a projection of this initial state $(\\varepsilon^{(0)}, \\sigma^{(0)})$ onto the data set $\\mathcal{D}$. For each element $e$, we find the data point $(\\varepsilon_i, \\sigma_i) \\in \\mathcal{D}$ that minimizes the distance metric $d_i^2 = E_0 (\\varepsilon^{(0)} - \\varepsilon_i)^2 + \\frac{1}{E_0} (\\sigma^{(0)} - \\sigma_i)^2$. This gives an initial set of data points $(\\boldsymbol{\\varepsilon}^{*(0)}, \\boldsymbol{\\sigma}^{*(0)})$ and their corresponding indices, which we denote as $\\text{indices}^{(0)}$.\n\n**2. Iterative Projections**\nThe algorithm proceeds in a loop, indexed by $k=0, 1, 2, \\dots$. Each iteration consists of two steps.\n\n**Step A: Projection onto the Constraint Set $\\mathcal{C}$**\nGiven the state from the data set $(\\boldsymbol{\\varepsilon}^{*(k)}, \\boldsymbol{\\sigma}^{*(k)})$, we find the state $(\\boldsymbol{\\varepsilon}^{(k+1/2)}, \\boldsymbol{\\sigma}^{(k+1/2)}) \\in \\mathcal{C}$ that minimizes the weighted sum of squared distances. Incorporating the equilibrium constraint $\\sigma_e = \\sigma$, the minimization problem is:\n$$\n\\min_{\\varepsilon_1, \\dots, \\varepsilon_n, \\sigma} \\sum_{e=1}^{n} w_e \\left[ E_0 (\\varepsilon_e - \\varepsilon_e^{*(k)})^2 + \\frac{1}{E_0} (\\sigma - \\sigma_e^{*(k)})^2 \\right] \\quad \\text{subject to} \\quad \\sum_{e=1}^{n} \\varepsilon_e L_e - u = 0\n$$\nWe solve this using the method of Lagrange multipliers. The Lagrangian is:\n$$\n\\mathcal{L}(\\boldsymbol{\\varepsilon}, \\sigma, \\lambda) = \\sum_{e=1}^{n} \\left( w_e E_0 (\\varepsilon_e - \\varepsilon_e^{*(k)})^2 + w_e \\frac{1}{E_0} (\\sigma - \\sigma_e^{*(k)})^2 \\right) + \\lambda \\left( \\sum_{e=1}^{n} \\varepsilon_e L_e - u \\right)\n$$\nThe first-order necessary conditions for a minimum are $\\frac{\\partial \\mathcal{L}}{\\partial \\varepsilon_e} = 0$, $\\frac{\\partial \\mathcal{L}}{\\partial \\sigma} = 0$, and $\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = 0$.\n\nFrom $\\frac{\\partial \\mathcal{L}}{\\partial \\sigma} = \\sum_{e=1}^{n} 2 w_e \\frac{1}{E_0} (\\sigma - \\sigma_e^{*(k)}) = 0$, we solve for the projected stress $\\sigma^{(k+1/2)}$:\n$$\n\\sigma^{(k+1/2)} = \\frac{\\sum_{e=1}^{n} w_e \\sigma_e^{*(k)}}{\\sum_{e=1}^{n} w_e}\n$$\nThis is a weighted average of the stresses from the current data points.\n\nFrom $\\frac{\\partial \\mathcal{L}}{\\partial \\varepsilon_e} = 2 w_e E_0 (\\varepsilon_e - \\varepsilon_e^{*(k)}) + \\lambda L_e = 0$, we find $\\varepsilon_e = \\varepsilon_e^{*(k)} - \\frac{\\lambda L_e}{2 w_e E_0}$. Substituting this into the compatibility constraint $\\sum_{e=1}^{n} \\varepsilon_e L_e = u$ allows us to solve for the Lagrange multiplier $\\lambda$. With $w_e = A_e L_e$, we get:\n$$\n\\sum_{e=1}^{n} \\left( \\varepsilon_e^{*(k)} - \\frac{\\lambda L_e}{2 (A_e L_e) E_0} \\right) L_e = u \\implies \\sum_{e=1}^{n} \\varepsilon_e^{*(k)} L_e - \\frac{\\lambda}{2 E_0} \\sum_{e=1}^{n} \\frac{L_e}{A_e} = u\n$$\nSolving for $\\lambda$ and substituting back into the expression for $\\varepsilon_e$ yields the projected strains $\\varepsilon_e^{(k+1/2)}$:\n$$\n\\varepsilon_e^{(k+1/2)} = \\varepsilon_e^{*(k)} - \\frac{1}{A_e} \\frac{\\sum_{j=1}^{n} \\varepsilon_j^{*(k)} L_j - u}{\\sum_{j=1}^{n} (L_j/A_j)}\n$$\n\n**Step B: Projection onto the Data Set $\\mathcal{D}$**\nGiven the state $(\\boldsymbol{\\varepsilon}^{(k+1/2)}, \\sigma^{(k+1/2)})$ from Step A, we project it back onto the material data set $\\mathcal{D}$. This is done independently for each element. For each element $e$, we find the index $i_e$ of the data point $(\\varepsilon_i, \\sigma_i) \\in \\mathcal{D}$ that minimizes the unweighted squared distance:\n$$\nd_i^2 = E_0 (\\varepsilon_e^{(k+1/2)} - \\varepsilon_i)^2 + \\frac{1}{E_0} (\\sigma^{(k+1/2)} - \\sigma_i)^2\n$$\nIn case of a tie where multiple data points have the same minimum distance, the one with the smallest index $i$ is chosen. The new state from the data set is then $(\\varepsilon_e^{*(k+1)}, \\sigma_e^{*(k+1)}) = (\\varepsilon_{i_e}, \\sigma_{i_e})$, and we obtain the new list of indices, $\\text{indices}^{(k+1)}$.\n\n**3. Convergence**\nThe iterative process continues until the selected indices no longer change, i.e., $\\text{indices}^{(k+1)} = \\text{indices}^{(k)}$. At this point, the algorithm has converged, and the final list of indices is the solution. A maximum number of iterations is included as a failsafe.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Data-Driven Computational Mechanics (DDCM) solver\n    for a 1D bar and reports the indices of selected data points.\n    \"\"\"\n    # Define geometry and material reference from the problem statement\n    L = np.array([0.4, 0.3, 0.3])  # m\n    A = np.array([1.0e-4, 1.0e-4, 8.0e-5])  # m^2\n    E0 = 2.0e11  # Pa\n    n_elements = 3\n\n    # Define the material data set D = {(strain_i, stress_i)}\n    material_data = np.array([\n        [-1.0e-3, -2.0e8],  # i=0\n        [0.0, 0.0],          # i=1\n        [5.0e-4, 1.0e8],   # i=2\n        [1.0e-3, 2.0e8],   # i=3\n        [1.5e-3, 2.05e8],  # i=4\n        [2.0e-3, 2.10e8],  # i=5\n        [3.0e-3, 2.20e8]   # i=6\n    ])\n\n    # Prescribed displacements for the test suite\n    test_cases = [0.0, 1.0e-5, 1.0e-3, 3.0e-3]\n\n    # Pre-compute constants for the iterative solver\n    L_tot = np.sum(L)\n    w = A * L\n    sum_w = np.sum(w)\n    sum_L_div_A = np.sum(L / A)\n    \n    def run_ddcm_solver(u):\n        \"\"\"\n        Executes the alternating projection algorithm for a given displacement u.\n        \"\"\"\n        # --- Initialization ---\n        # Initial guess based on average strain and reference modulus\n        eps0 = u / L_tot\n        sig0 = E0 * eps0\n        \n        # Initial projection to the data set D\n        initial_state = np.array([eps0, sig0])\n        strains_data = material_data[:, 0]\n        stresses_data = material_data[:, 1]\n        \n        distances_sq = E0 * (initial_state[0] - strains_data)**2 + \\\n                       (1/E0) * (initial_state[1] - stresses_data)**2\n        \n        min_dist_sq = np.min(distances_sq)\n        # Handle ties by choosing the smallest index\n        tied_indices = np.where(np.isclose(distances_sq, min_dist_sq))[0]\n        initial_index = np.min(tied_indices)\n\n        prev_indices = np.full(n_elements, initial_index, dtype=int)\n        \n        eps_star = material_data[prev_indices, 0]\n        sig_star = material_data[prev_indices, 1]\n\n        max_iterations = 100\n        for _ in range(max_iterations):\n            # --- Step A: Projection onto the constraint set C ---\n            # Equilibrium (uniform stress)\n            sig_proj = np.sum(w * sig_star) / sum_w\n            \n            # Compatibility (strain distribution)\n            numerator = np.sum(eps_star * L) - u\n            eps_proj = eps_star - (1/A) * (numerator / sum_L_div_A)\n\n            # --- Step B: Projection onto the data set D ---\n            new_indices = np.zeros(n_elements, dtype=int)\n            for e in range(n_elements):\n                current_state_e = np.array([eps_proj[e], sig_proj])\n                \n                # Calculate squared distances to all data points\n                distances_sq = E0 * (current_state_e[0] - strains_data)**2 + \\\n                               (1/E0) * (current_state_e[1] - stresses_data)**2\n                \n                # Find minimum distance and handle ties\n                min_dist_sq = np.min(distances_sq)\n                tied_indices = np.where(np.isclose(distances_sq, min_dist_sq))[0]\n                best_index = np.min(tied_indices)\n                new_indices[e] = best_index\n            \n            # --- Check for convergence ---\n            if np.array_equal(new_indices, prev_indices):\n                return new_indices.tolist()\n\n            prev_indices = new_indices\n            eps_star = material_data[prev_indices, 0]\n            sig_star = material_data[prev_indices, 1]\n            \n        # Return last state if max iterations are reached (should not happen for this problem)\n        return prev_indices.tolist()\n\n    results = []\n    for u_case in test_cases:\n        converged_indices = run_ddcm_solver(u_case)\n        results.append(converged_indices)\n    \n    # Format the results into a string as per the output specification\n    # e.g., \"[[1,1,1],[1,1,1],[3,3,3],[6,6,6]]\"\n    result_str = str(results).replace(\" \", \"\")\n    print(result_str)\n\nsolve()\n```"
        }
    ]
}