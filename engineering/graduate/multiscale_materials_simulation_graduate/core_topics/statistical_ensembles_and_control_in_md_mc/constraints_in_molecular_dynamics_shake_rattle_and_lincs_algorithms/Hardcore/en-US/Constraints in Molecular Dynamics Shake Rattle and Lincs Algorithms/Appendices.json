{
    "hands_on_practices": [
        {
            "introduction": "Before implementing any constraint algorithm, one must first master the translation of physical constraints into their mathematical representation. This exercise provides foundational practice in deriving the core matrices used by algorithms like SHAKE, RATTLE, and LINCS from first principles. By manually constructing the constraint Jacobian $G$ and the coupling matrix $A = G M^{-1} G^{\\top}$ for a simple triatomic system, you will bridge the gap between the physical concept of fixed bond lengths and the linear algebraic structures that underpin modern molecular dynamics simulations .",
            "id": "3798260",
            "problem": "Consider a classical Molecular Dynamics (MD) system of $N$ atoms with holonomic constraints of fixed bond lengths between selected atom pairs, enforced by Lagrange multipliers within position- and velocity-projection schemes such as the SHAKE algorithm and the RATTLE algorithm. Let the constraint set be defined by functions $c_{k}(\\mathbf{q})=0$, where $\\mathbf{q}\\in\\mathbb{R}^{3N}$ stacks all Cartesian coordinates as $\\mathbf{q}=\\left(x_{1},y_{1},z_{1},\\dots,x_{N},y_{N},z_{N}\\right)$, and each bond-length constraint takes the form $c_{ij}(\\mathbf{q})=\\|\\mathbf{r}_{j}-\\mathbf{r}_{i}\\|^{2}-d_{ij}^{2}=0$ for atoms $i$ and $j$ with target bond length $d_{ij}$. Define the constraint Jacobian $G(\\mathbf{q})$ with rows $G_{k}(\\mathbf{q})=\\nabla_{\\mathbf{q}}c_{k}(\\mathbf{q})$, and let the diagonal mass matrix be $M=\\mathrm{diag}(m_{1},m_{1},m_{1},\\dots,m_{N},m_{N},m_{N})$. The Linear Constraint Solver (LINCS) algorithm and related projection methods solve for Lagrange multipliers via the symmetric positive-definite matrix $A(\\mathbf{q})=G(\\mathbf{q})M^{-1}G(\\mathbf{q})^{\\top}$.\n\nStarting from Newton’s second law and the definition of holonomic constraints, derive $G(\\mathbf{q})$ for bond-length constraints using only fundamental laws and core definitions. Explain how to assemble $A(\\mathbf{q})$ efficiently in sparse form by exploiting the locality of bond constraints, without invoking any pre-derived implementation “shortcuts.”\n\nThen, consider the specific three-atom configuration with $N=3$ and two bond-length constraints:\n- Atom $1$ at $\\mathbf{r}_{1}=(0,0,0)$,\n- Atom $2$ at $\\mathbf{r}_{2}=(a,0,0)$,\n- Atom $3$ at $\\mathbf{r}_{3}=(a,b,0)$,\nwith target bond lengths $d_{12}=a$ between atoms $1$ and $2$, and $d_{23}=b$ between atoms $2$ and $3$. Let the coordinate ordering be $\\mathbf{q}=(x_{1},y_{1},z_{1},x_{2},y_{2},z_{2},x_{3},y_{3},z_{3})$, and choose masses $m_{1}=12$, $m_{2}=1$, $m_{3}=16$. Take $a=1$ and $b=1$.\n\nConstruct $G(\\mathbf{q})$ explicitly for these two constraints, construct $A(\\mathbf{q})=G(\\mathbf{q})M^{-1}G(\\mathbf{q})^{\\top}$, and compute the determinant $\\det A(\\mathbf{q})$. Express the numerical value of the determinant in $\\mathrm{nm}^{4}/\\mathrm{amu}^{2}$. No rounding is required; provide the exact value.",
            "solution": "The fundamental base is Newton’s second law, which in Cartesian coordinates reads $m_{i}\\ddot{\\mathbf{r}}_{i}=\\mathbf{F}_{i}+\\mathbf{f}_{i}^{\\mathrm{c}}$, where $\\mathbf{f}_{i}^{\\mathrm{c}}$ are constraint forces ensuring the holonomic constraints $c_{k}(\\mathbf{q})=0$ remain satisfied. For holonomic constraints, the constraint forces are linear combinations of the constraint gradients: $\\mathbf{f}^{\\mathrm{c}}=G(\\mathbf{q})^{\\top}\\boldsymbol{\\lambda}$, where $\\boldsymbol{\\lambda}$ is the vector of Lagrange multipliers and $G(\\mathbf{q})$ is the Jacobian with rows $G_{k}(\\mathbf{q})=\\nabla_{\\mathbf{q}}c_{k}(\\mathbf{q})$.\n\nFor bond-length constraints between atoms $i$ and $j$, define $c_{ij}(\\mathbf{q})=\\|\\mathbf{r}_{j}-\\mathbf{r}_{i}\\|^{2}-d_{ij}^{2}$. We compute the gradient via the chain rule. Let $\\mathbf{r}_{i}=(x_{i},y_{i},z_{i})$ and $\\mathbf{r}_{j}=(x_{j},y_{j},z_{j})$. Then\n$$\nc_{ij}(\\mathbf{q})=(x_{j}-x_{i})^{2}+(y_{j}-y_{i})^{2}+(z_{j}-z_{i})^{2}-d_{ij}^{2}.\n$$\nIts partial derivatives are\n$$\n\\frac{\\partial c_{ij}}{\\partial \\mathbf{r}_{i}}=2(\\mathbf{r}_{i}-\\mathbf{r}_{j}),\\quad \\frac{\\partial c_{ij}}{\\partial \\mathbf{r}_{j}}=2(\\mathbf{r}_{j}-\\mathbf{r}_{i}),\n$$\nand zero with respect to coordinates of all other atoms. Therefore, the row $G_{ij}(\\mathbf{q})=\\nabla_{\\mathbf{q}}c_{ij}(\\mathbf{q})$ is a $1\\times 3N$ vector with $3$-component blocks\n$$\n[G_{ij}]_{i}=2(\\mathbf{r}_{i}-\\mathbf{r}_{j}),\\quad [G_{ij}]_{j}=2(\\mathbf{r}_{j}-\\mathbf{r}_{i}),\n$$\nand zeros elsewhere.\n\nTo obtain the linear system for $\\boldsymbol{\\lambda}$ used in SHAKE, RATTLE, and the Linear Constraint Solver (LINCS), we consider the mass-weighted projection of constraint violations. Under a small position correction $\\delta\\mathbf{q}$ or velocity correction $\\delta\\dot{\\mathbf{q}}$, the constraints linearize as $G(\\mathbf{q})\\,\\delta\\mathbf{q}=\\mathbf{r}$ or $G(\\mathbf{q})\\,\\delta\\dot{\\mathbf{q}}=\\mathbf{r}_{v}$, with residuals $\\mathbf{r}$ or $\\mathbf{r}_{v}$. Mass-weighted corrections driven by constraint forces satisfy $M\\,\\delta\\ddot{\\mathbf{q}}=G(\\mathbf{q})^{\\top}\\boldsymbol{\\lambda}$, yielding (after eliminating $\\delta\\mathbf{q}$ or $\\delta\\dot{\\mathbf{q}}$ in the linearized projection) the symmetric positive-definite “constraint coupling” matrix\n$$\nA(\\mathbf{q})=G(\\mathbf{q})M^{-1}G(\\mathbf{q})^{\\top},\n$$\nwhose $(k,\\ell)$ entry aggregates contributions only from atoms appearing in both constraints $k$ and $\\ell$:\n$$\nA_{k\\ell}=\\sum_{p=1}^{N}\\frac{1}{m_{p}}\\,[G_{k}]_{p}^{\\top}[G_{\\ell}]_{p}.\n$$\n\nEfficient sparse assembly of $A(\\mathbf{q})$ exploits the locality of bond constraints: each constraint $c_{ij}$ touches only atoms $i$ and $j$, so $G_{ij}$ has exactly two nonzero $3$-blocks and $A_{k\\ell}$ is nonzero only if constraints $k$ and $\\ell$ share at least one atom. A practical assembly strategy is:\n1. Precompute for each constraint $c_{ij}$ the gradients $[G_{ij}]_{i}=2(\\mathbf{r}_{i}-\\mathbf{r}_{j})$ and $[G_{ij}]_{j}=2(\\mathbf{r}_{j}-\\mathbf{r}_{i})$.\n2. Build an adjacency mapping from constraints to atoms and from atoms to incident constraints.\n3. For each constraint $k$ involving atoms $i$ and $j$, accumulate the diagonal contribution\n$$\nA_{kk}\\,\\mathrel{+}=\\,\\frac{[G_{k}]_{i}^{\\top}[G_{k}]_{i}}{m_{i}}+\\frac{[G_{k}]_{j}^{\\top}[G_{k}]_{j}}{m_{j}}.\n$$\n4. For each atom $p$ shared by constraints $k$ and $\\ell$ (from the atom-to-constraints adjacency), accumulate the off-diagonal contribution\n$$\nA_{k\\ell}\\,\\mathrel{+}=\\,\\frac{[G_{k}]_{p}^{\\top}[G_{\\ell}]_{p}}{m_{p}},\n$$\nand symmetrically set $A_{\\ell k}=A_{k\\ell}$.\n5. Store $A$ in a compressed sparse row or compressed sparse column structure; the per-constraint work is constant (two atoms, up to six coordinates per constraint in three dimensions), leading to linear-time assembly in the number of constraints and linear memory in the constraint graph bandwidth.\n\nNow apply this to the specified three-atom configuration with $a=1$ and $b=1$. The coordinates are\n$$\n\\mathbf{r}_{1}=(0,0,0),\\quad \\mathbf{r}_{2}=(1,0,0),\\quad \\mathbf{r}_{3}=(1,1,0),\n$$\nwith constraints $c_{12}$ and $c_{23}$ at target lengths $d_{12}=1$ and $d_{23}=1$. Using the ordering $\\mathbf{q}=(x_{1},y_{1},z_{1},x_{2},y_{2},z_{2},x_{3},y_{3},z_{3})$, we compute the constraint gradients.\n\nFor $c_{12}$,\n$$\n[G_{12}]_{1}=2(\\mathbf{r}_{1}-\\mathbf{r}_{2})=2(-1,0,0)=(-2,0,0),\\quad [G_{12}]_{2}=2(\\mathbf{r}_{2}-\\mathbf{r}_{1})=2(1,0,0)=(2,0,0),\n$$\nand zeros at atom $3$. Thus the row $G_{12}$ is\n$$\nG_{12}=\\big(-2,\\,0,\\,0,\\,2,\\,0,\\,0,\\,0,\\,0,\\,0\\big).\n$$\nFor $c_{23}$,\n$$\n[G_{23}]_{2}=2(\\mathbf{r}_{2}-\\mathbf{r}_{3})=2(0,-1,0)=(0,-2,0),\\quad [G_{23}]_{3}=2(\\mathbf{r}_{3}-\\mathbf{r}_{2})=2(0,1,0)=(0,2,0),\n$$\nand zeros at atom $1$. Thus the row $G_{23}$ is\n$$\nG_{23}=\\big(0,\\,0,\\,0,\\,0,\\,-2,\\,0,\\,0,\\,2,\\,0\\big).\n$$\n\nThe mass matrix inverse is $M^{-1}=\\mathrm{diag}\\big(\\frac{1}{12},\\frac{1}{12},\\frac{1}{12},1,1,1,\\frac{1}{16},\\frac{1}{16},\\frac{1}{16}\\big)$ from $m_{1}=12$, $m_{2}=1$, $m_{3}=16$.\n\nWe now compute $A=G M^{-1} G^{\\top}$. Since we have two constraints, $A$ is $2\\times 2$ with entries\n$$\nA_{11}=G_{12}M^{-1}G_{12}^{\\top},\\quad A_{22}=G_{23}M^{-1}G_{23}^{\\top},\\quad A_{12}=G_{12}M^{-1}G_{23}^{\\top}.\n$$\nFor $A_{11}$, only coordinates at $(x_{1},x_{2})$ contribute:\n$$\nA_{11}=(-2)^{2}\\cdot\\frac{1}{12}+(2)^{2}\\cdot 1=\\frac{4}{12}+4=\\frac{1}{3}+4=\\frac{13}{3}.\n$$\nFor $A_{22}$, only coordinates at $(y_{2},y_{3})$ contribute:\n$$\nA_{22}=(-2)^{2}\\cdot 1+(2)^{2}\\cdot\\frac{1}{16}=4+\\frac{4}{16}=4+\\frac{1}{4}=\\frac{17}{4}.\n$$\nFor $A_{12}$, the support of $G_{12}$ is on $x$ components, and the support of $G_{23}$ is on $y$ components, so they do not overlap in any coordinate, yielding\n$$\nA_{12}=0.\n$$\nTherefore,\n$$ A = \\begin{pmatrix} \\frac{13}{3} & 0 \\\\ 0 & \\frac{17}{4} \\end{pmatrix} $$\nThe determinant is\n$$\n\\det A=\\frac{13}{3}\\cdot\\frac{17}{4}=\\frac{221}{12}.\n$$\nInterpreting positions in nanometers and masses in atomic mass units, $\\det A$ is expressed in $\\mathrm{nm}^{4}/\\mathrm{amu}^{2}$; the exact value is $\\frac{221}{12}$ with no rounding required.",
            "answer": "$$\\boxed{\\frac{221}{12}}$$"
        },
        {
            "introduction": "Moving from theory to practice, this exercise guides you through the implementation of a single correction step of the highly efficient Linear Constraint Solver (LINCS) algorithm. A key to the speed of LINCS is its use of a series expansion to approximate the inverse of the coupling matrix, avoiding a costly direct inversion. This coding challenge demystifies this process by having you apply the first-order approximation to correct atomic positions in a small molecule, offering a concrete look into the algorithm's inner workings .",
            "id": "3798215",
            "problem": "You are asked to implement a single correction step of the Linear Constraint Solver (LINCS) for a triatomic molecule with two holonomic bond-length constraints. Begin from the following base: Newtonian mechanics with holonomic constraints, the definition of constraint functions, and linearization of constraints via a Jacobian. Your implementation must construct the constraint Jacobian, assemble the constraint coupling matrix, form a first-order approximation to its inverse using a Neumann-series-inspired preconditioner, and apply the mass-weighted minimal-norm correction to the predicted positions.\n\nThe system is a molecule with three atoms labeled $A$, $B$, and $C$, having masses $m_A$, $m_B$, and $m_C$ (in unified atomic mass units). There are two bond-length constraints: between $A$ and $B$ with target length $d_1$ (in angstroms), and between $B$ and $C$ with target length $d_2$ (in angstroms). Let the predicted (unconstrained) positions after an integration step be $\\mathbf{r}^* = (\\mathbf{r}_A^*, \\mathbf{r}_B^*, \\mathbf{r}_C^*)$ in angstroms, where each $\\mathbf{r}_i^* \\in \\mathbb{R}^3$.\n\nDefine the constraint functions using squared distances:\n- For the $A$–$B$ constraint: $\\sigma_1(\\mathbf{r}) = \\|\\mathbf{r}_A - \\mathbf{r}_B\\|^2 - d_1^2$.\n- For the $B$–$C$ constraint: $\\sigma_2(\\mathbf{r}) = \\|\\mathbf{r}_B - \\mathbf{r}_C\\|^2 - d_2^2$.\n\nLet the constraint Jacobian be $B = \\frac{\\partial \\boldsymbol{\\sigma}}{\\partial \\mathbf{q}}$ evaluated at $\\mathbf{r}^*$, where $\\boldsymbol{\\sigma} = (\\sigma_1,\\sigma_2)$ and $\\mathbf{q}$ is the $9$-vector formed by stacking $(\\mathbf{r}_A,\\mathbf{r}_B,\\mathbf{r}_C)$. The mass matrix is diagonal $M = \\mathrm{diag}(m_A I_3, m_B I_3, m_C I_3)$, with $I_3$ the $3 \\times 3$ identity.\n\nYour program must:\n1. Construct $B$ at $\\mathbf{r}^*$ using the definition of $\\sigma_k$ above and first principles for gradients.\n2. Compute $G = B M^{-1} B^\\top$ and the constraint violation vector $\\boldsymbol{\\sigma}(\\mathbf{r}^*)$.\n3. Form a first-order approximate inverse of $G$ by:\n   - Letting $D = \\mathrm{diag}(G)$ and $S = D^{-1/2} G D^{-1/2}$.\n   - Approximating $S^{-1} \\approx 2 I - S$ (one Neumann-series iteration around the identity).\n   - Setting $G^{-1}_{\\mathrm{approx}} = D^{-1/2} (2 I - S) D^{-1/2}$.\n4. Compute the mass-weighted minimal-norm correction $\\Delta \\mathbf{q} = - M^{-1} B^\\top G^{-1}_{\\mathrm{approx}} \\, \\boldsymbol{\\sigma}(\\mathbf{r}^*)$, and define the corrected positions $\\mathbf{r}^{\\mathrm{corr}} = \\mathbf{r}^* + \\Delta \\mathbf{q}$.\n5. Evaluate the post-correction constraint residuals $\\boldsymbol{\\sigma}(\\mathbf{r}^{\\mathrm{corr}})$ and report, for each test case, the maximum absolute residual value $\\max_k |\\sigma_k(\\mathbf{r}^{\\mathrm{corr}})|$.\n\nPhysical units: all positions and bond lengths must be treated in angstroms, masses in unified atomic mass units, and the reported residuals must be in square angstroms. Angles do not appear in this problem. The final outputs must be floats (not percentages), representing the maximum absolute residual value per test case, in square angstroms.\n\nImplement your solution as a single, complete, and runnable program that evaluates the following test suite:\n\n- Test case $1$ (general case): $m_A = 12.0$, $m_B = 1.0$, $m_C = 16.0$; $d_1 = 1.1$, $d_2 = 1.4$; $\\mathbf{r}_A^* = (0.0, 0.0, 0.0)$, $\\mathbf{r}_B^* = (1.15, 0.02, -0.01)$, $\\mathbf{r}_C^* = (2.52, -0.01, 0.03)$.\n- Test case $2$ (heavy central mass and large violations): $m_A = 1.0$, $m_B = 1000.0$, $m_C = 1.0$; $d_1 = 1.0$, $d_2 = 1.0$; $\\mathbf{r}_A^* = (0.0, 0.0, 0.0)$, $\\mathbf{r}_B^* = (0.5, 0.0, 0.0)$, $\\mathbf{r}_C^* = (0.8, 0.8, 0.0)$.\n- Test case $3$ (nearly colinear, small violations): $m_A = 16.0$, $m_B = 16.0$, $m_C = 16.0$; $d_1 = 1.2$, $d_2 = 1.2$; $\\mathbf{r}_A^* = (0.0, 0.0, 0.0)$, $\\mathbf{r}_B^* = (1.22, 0.001, 0.0)$, $\\mathbf{r}_C^* = (2.40, 0.0025, 0.0)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\text{result}_3]$), where each $\\text{result}_i$ is the maximum absolute post-correction constraint residual for test case $i$, expressed in square angstroms as a decimal number.",
            "solution": "The problem requires the implementation of a single corrective step of the Linear Constraint Solver (LINCS) algorithm for a triatomic molecule. The solution is derived from first principles of Newtonian mechanics under holonomic constraints, following the specific algorithmic steps provided.\n\nThe system consists of three atoms $A$, $B$, and $C$ with masses $m_A$, $m_B$, and $m_C$. The state of the system is described by the concatenated position vector $\\mathbf{q} \\in \\mathbb{R}^9$, where $\\mathbf{q} = (\\mathbf{r}_A^T, \\mathbf{r}_B^T, \\mathbf{r}_C^T)^T$ and $\\mathbf{r}_i \\in \\mathbb{R}^3$ is the position of atom $i$. The mass matrix $M$ is a $9 \\times 9$ diagonal matrix $M = \\mathrm{diag}(m_A I_3, m_B I_3, m_C I_3)$, where $I_3$ is the $3 \\times 3$ identity matrix. Its inverse $M^{-1}$ is a diagonal matrix with entries $1/m_i$.\n\nThere are two bond-length constraints defined by the functions $\\sigma_1$ and $\\sigma_2$:\n$$\n\\sigma_1(\\mathbf{q}) = \\|\\mathbf{r}_A - \\mathbf{r}_B\\|^2 - d_1^2 = 0\n$$\n$$\n\\sigma_2(\\mathbf{q}) = \\|\\mathbf{r}_B - \\mathbf{r}_C\\|^2 - d_2^2 = 0\n$$\nwhere $d_1$ and $d_2$ are the target bond lengths. These can be written in vector form as $\\boldsymbol{\\sigma}(\\mathbf{q}) = \\mathbf{0}$.\n\nGiven a set of predicted positions $\\mathbf{q}^* = (\\mathbf{r}_A^{*T}, \\mathbf{r}_B^{*T}, \\mathbf{r}_C^{*T})^T$ from an unconstrained integration step, we seek a correction $\\Delta \\mathbf{q}$ such that the corrected positions $\\mathbf{q}^{\\mathrm{corr}} = \\mathbf{q}^* + \\Delta \\mathbf{q}$ satisfy the constraints. The LINCS algorithm finds this correction by first linearizing the constraints around $\\mathbf{q}^*$:\n$$\n\\boldsymbol{\\sigma}(\\mathbf{q}^* + \\Delta \\mathbf{q}) \\approx \\boldsymbol{\\sigma}(\\mathbf{q}^*) + B \\Delta \\mathbf{q} = \\mathbf{0}\n$$\nHere, $B = \\frac{\\partial \\boldsymbol{\\sigma}}{\\partial \\mathbf{q}}\\big|_{\\mathbf{q}^*}$ is the $2 \\times 9$ constraint Jacobian matrix. The minimal mass-weighted norm solution for $\\Delta\\mathbf{q}$ is given by:\n$$\n\\Delta \\mathbf{q} = -M^{-1} B^T (B M^{-1} B^T)^{-1} \\boldsymbol{\\sigma}(\\mathbf{q}^*)\n$$\nWe follow the prescribed steps to compute this correction.\n\n1.  **Construct the Jacobian Matrix $B$**\n    The rows of $B$ are the gradients of the constraint functions. For $\\sigma_1$, the non-zero gradients are $\\nabla_{\\mathbf{r}_A}\\sigma_1 = 2(\\mathbf{r}_A - \\mathbf{r}_B)$ and $\\nabla_{\\mathbf{r}_B}\\sigma_1 = -2(\\mathbf{r}_A - \\mathbf{r}_B)$. For $\\sigma_2$, they are $\\nabla_{\\mathbf{r}_B}\\sigma_2 = 2(\\mathbf{r}_B - \\mathbf{r}_C)$ and $\\nabla_{\\mathbf{r}_C}\\sigma_2 = -2(\\mathbf{r}_B - \\mathbf{r}_C)$. Evaluated at $\\mathbf{q}^*$, the Jacobian is:\n    $$\n    B = 2 \\begin{pmatrix}\n    (\\mathbf{r}_A^* - \\mathbf{r}_B^*)^T & -(\\mathbf{r}_A^* - \\mathbf{r}_B^*)^T & \\mathbf{0}^T \\\\\n    \\mathbf{0}^T & (\\mathbf{r}_B^* - \\mathbf{r}_C^*)^T & -(\\mathbf{r}_B^* - \\mathbf{r}_C^*)^T\n    \\end{pmatrix}\n    $$\n\n2.  **Compute the Matrix $G = B M^{-1} B^T$ and Violation Vector $\\boldsymbol{\\sigma}(\\mathbf{q}^*)$**\n    $G$ is a $2 \\times 2$ matrix. Its elements $G_{ij} = B_i M^{-1} B_j^T$, where $B_i$ is the $i$-th row of $B$.\n    $G_{11} = 4(\\frac{1}{m_A} + \\frac{1}{m_B})\\|\\mathbf{r}_A^* - \\mathbf{r}_B^*\\|^2$\n    $G_{22} = 4(\\frac{1}{m_B} + \\frac{1}{m_C})\\|\\mathbf{r}_B^* - \\mathbf{r}_C^*\\|^2$\n    $G_{12} = G_{21} = -\\frac{4}{m_B}(\\mathbf{r}_A^* - \\mathbf{r}_B^*) \\cdot (\\mathbf{r}_B^* - \\mathbf{r}_C^*)$\n    The constraint violation vector is computed directly: $\\boldsymbol{\\sigma}(\\mathbf{q}^*) = (\\|\\mathbf{r}_A^* - \\mathbf{r}_B^*\\|^2 - d_1^2, \\|\\mathbf{r}_B^* - \\mathbf{r}_C^*\\|^2 - d_2^2)^T$.\n\n3.  **Form the Approximate Inverse $G_{\\mathrm{approx}}^{-1}$**\n    The core of LINCS's efficiency lies in approximating the inverse of $G$. We define $D = \\mathrm{diag}(G_{11}, G_{22})$ and a scaled matrix $S = D^{-1/2} G D^{-1/2}$. The inverse of $S$ is approximated by the first-order Neumann series expansion $S^{-1} \\approx 2I - S$. This leads to the approximate inverse for $G$:\n    $$\n    G_{\\mathrm{approx}}^{-1} = D^{-1/2} (2I - S) D^{-1/2}\n    $$\n    After matrix multiplications, this simplifies to:\n    $$\n    G_{\\mathrm{approx}}^{-1} = \\begin{pmatrix} 1/G_{11} & -G_{12}/(G_{11}G_{22}) \\\\ -G_{12}/(G_{11}G_{22}) & 1/G_{22} \\end{pmatrix}\n    $$\n\n4.  **Compute the Position Correction $\\Delta \\mathbf{q}$**\n    The vector of Lagrange multipliers is $\\boldsymbol{\\mu} = G_{\\mathrm{approx}}^{-1} \\boldsymbol{\\sigma}(\\mathbf{q}^*)$. The total correction is then $\\Delta \\mathbf{q} = -M^{-1} B^T \\boldsymbol{\\mu}$. This can be broken down into corrections for each atom's position vector:\n    $$\n    \\Delta \\mathbf{r}_A = -\\frac{2\\mu_1}{m_A}(\\mathbf{r}_A^* - \\mathbf{r}_B^*)\n    $$\n    $$\n    \\Delta \\mathbf{r}_B = \\frac{2\\mu_1}{m_B}(\\mathbf{r}_A^* - \\mathbf{r}_B^*) - \\frac{2\\mu_2}{m_B}(\\mathbf{r}_B^* - \\mathbf{r}_C^*)\n    $$\n    $$\n    \\Delta \\mathbf{r}_C = \\frac{2\\mu_2}{m_C}(\\mathbf{r}_B^* - \\mathbf{r}_C^*)\n    $$\n    where $\\boldsymbol{\\mu} = (\\mu_1, \\mu_2)^T$.\n\n5.  **Evaluate Post-Correction Residuals**\n    The corrected positions are calculated as $\\mathbf{r}_i^{\\mathrm{corr}} = \\mathbf{r}_i^* + \\Delta \\mathbf{r}_i$. The final step is to evaluate the constraint functions at these new positions, $\\boldsymbol{\\sigma}(\\mathbf{q}^{\\mathrm{corr}})$, and find the maximum absolute value of the residual components, $\\max_{k} |\\sigma_k(\\mathbf{q}^{\\mathrm{corr}})|$. This value quantifies the remaining constraint violation after one correction step.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the LINCS correction for the provided test cases.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"masses\": (12.0, 1.0, 16.0),\n            \"d\": (1.1, 1.4),\n            \"r_star\": (\n                np.array([0.0, 0.0, 0.0]),\n                np.array([1.15, 0.02, -0.01]),\n                np.array([2.52, -0.01, 0.03])\n            )\n        },\n        {\n            \"masses\": (1.0, 1000.0, 1.0),\n            \"d\": (1.0, 1.0),\n            \"r_star\": (\n                np.array([0.0, 0.0, 0.0]),\n                np.array([0.5, 0.0, 0.0]),\n                np.array([0.8, 0.8, 0.0])\n            )\n        },\n        {\n            \"masses\": (16.0, 16.0, 16.0),\n            \"d\": (1.2, 1.2),\n            \"r_star\": (\n                np.array([0.0, 0.0, 0.0]),\n                np.array([1.22, 0.001, 0.0]),\n                np.array([2.40, 0.0025, 0.0])\n            )\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_lincs_residual(case[\"masses\"], case[\"d\"], case[\"r_star\"])\n        results.append(result)\n\n    # Format the final output as a comma-separated list in brackets.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\ndef calculate_lincs_residual(masses, d, r_star):\n    \"\"\"\n    Performs a single LINCS correction step and returns the max absolute residual.\n    \n    Args:\n        masses (tuple): A tuple of three floats (m_A, m_B, m_C).\n        d (tuple): A tuple of two floats (d_1, d_2), the target bond lengths.\n        r_star (tuple): A tuple of three numpy arrays representing the predicted\n                        positions (r_A*, r_B*, r_C*).\n                        \n    Returns:\n        float: The maximum absolute post-correction constraint residual.\n    \"\"\"\n    m_A, m_B, m_C = masses\n    d1, d2 = d\n    rA_star, rB_star, rC_star = r_star\n\n    # Step 1: Calculate bond vectors and initial constraint violations\n    rAB_star = rA_star - rB_star\n    rBC_star = rB_star - rC_star\n\n    norm_rAB_sq = np.dot(rAB_star, rAB_star)\n    norm_rBC_sq = np.dot(rBC_star, rBC_star)\n\n    sigma1_star = norm_rAB_sq - d1**2\n    sigma2_star = norm_rBC_sq - d2**2\n    sigma_vec = np.array([sigma1_star, sigma2_star])\n\n    # Step 2: Compute the G = B M^-1 B^T matrix\n    G11 = 4.0 * (1.0/m_A + 1.0/m_B) * norm_rAB_sq\n    G22 = 4.0 * (1.0/m_B + 1.0/m_C) * norm_rBC_sq\n    G12 = -4.0 / m_B * np.dot(rAB_star, rBC_star)\n    \n    # Step 3: Form the first-order approximate inverse of G\n    # G_inv_approx = D^-1/2 * (2I - S) * D^-1/2\n    # This simplifies to the following matrix:\n    G_inv_approx = np.array([\n        [1.0 / G11,     -G12 / (G11 * G22)],\n        [-G12 / (G11 * G22),     1.0 / G22]\n    ])\n\n    # Step 4: Compute Lagrange multipliers and position corrections\n    # mu = G_inv_approx * sigma\n    mu = G_inv_approx @ sigma_vec\n    mu1, mu2 = mu[0], mu[1]\n\n    # delta_r = - M^-1 B^T mu\n    drA = (-2.0 * mu1 / m_A) * rAB_star\n    drB = (2.0 * mu1 / m_B) * rAB_star - (2.0 * mu2 / m_B) * rBC_star\n    drC = (2.0 * mu2 / m_C) * rBC_star\n\n    # Apply corrections to get new positions\n    rA_corr = rA_star + drA\n    rB_corr = rB_star + drB\n    rC_corr = rC_star + drC\n\n    # Step 5: Evaluate post-correction residuals\n    rAB_corr = rA_corr - rB_corr\n    rBC_corr = rB_corr - rC_corr\n\n    sigma1_corr = np.dot(rAB_corr, rAB_corr) - d1**2\n    sigma2_corr = np.dot(rBC_corr, rBC_corr) - d2**2\n    \n    return max(abs(sigma1_corr), abs(sigma2_corr))\n\nsolve()\n```"
        },
        {
            "introduction": "A robust simulation code must gracefully handle non-ideal scenarios, such as linearly dependent or redundant constraints, which render the system of equations for Lagrange multipliers singular. This advanced practice addresses this critical issue of numerical stability. You will implement a professional-grade diagnostic tool using Singular Value Decomposition (SVD) to detect rank deficiency in the constraint matrix and develop a greedy algorithm to systematically remove redundant constraints, ensuring your solver remains stable and reliable .",
            "id": "3798262",
            "problem": "You are given the task of analyzing the constraint coupling matrix arising in constrained Molecular Dynamics (MD) methods such as SHAKE, RATTLE, and Linear Constraint Solver (LINCS). In these methods, holonomic constraints are enforced by solving for Lagrange multipliers in a linear system whose coefficient matrix must be of full rank to yield a unique solution. Consider a set of $m$ holonomic constraints applied to a system with $n$ generalized coordinates and masses. Let the constraint functions be $c_i(\\mathbf{q}) = 0$ for $i \\in \\{1,\\dots,m\\}$, where $\\mathbf{q}$ are coordinates. Define the Jacobian $J$ with rows $\\nabla c_i(\\mathbf{q})$, and a diagonal mass matrix $M$. The mass-weighted constraint Jacobian is $A = J M^{-1/2}$, and the constraint Gram matrix is $G = A A^\\top$. In the constrained update for SHAKE, RATTLE, and Linear Constraint Solver (LINCS), the solvability and numerical stability of the Lagrange multipliers rely on the matrix $G$ being full rank.\n\nYou must implement a program that performs the following for each test case:\n- Compute the Singular Value Decomposition (SVD) of $G$, i.e., $G = U \\Sigma V^\\top$, and use the singular values to detect rank deficiency using a relative threshold $\\tau = r \\cdot s_{\\max}$, where $s_{\\max}$ is the largest singular value of $G$ and $r$ is a given positive scalar in the test case. If $s_k < \\tau$ for any singular value $s_k$, declare $G$ rank-deficient.\n- Propose a modification to the constraint set to restore full rank by removing a minimal set of constraints, identified by analyzing the singular vectors associated with singular values below the threshold. For each singular value $s_k$ with $s_k < \\tau$, consider the corresponding left singular vector $\\mathbf{u}_k$ and greedily select the constraint index with the largest absolute component in $\\mathbf{u}_k$ to remove. If that index is already selected, choose the next largest component. Apply these removals, recompute the SVD of the reduced $G$, and continue until the reduced matrix is full rank under the same threshold. If all constraints must be removed to restore full rank, return the indices of all constraints.\n- Report two items per test case: a boolean indicating whether the original $G$ was full rank, and a list of integer indices of constraints to remove to achieve full rank. Indices must be zero-based.\n\nUse only purely mathematical constructs and ensure scientific realism by constructing $G$ as $A A^\\top$ from a given $A$ matrix representing mass-weighted constraints. No physical units are required since the computation is dimensionless in mass-weighted coordinates. Angles are not involved.\n\nYour program must process the following test suite, where each case is a pair $(A, r)$:\n- Case $1$ (independent constraints, happy path): $A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$, $r = 10^{-12}$.\n- Case $2$ (redundant constraints, exact dependency): $A = \\begin{bmatrix} 1 & 0 \\\\ 1 & 0 \\end{bmatrix}$, $r = 10^{-12}$.\n- Case $3$ (near dependency, ill-conditioned): $A = \\begin{bmatrix} 1 & 0 \\\\ 1 & 10^{-6} \\end{bmatrix}$, $r = 10^{-5}$.\n- Case $4$ (overdetermined, one dependent constraint): $A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{bmatrix}$, $r = 10^{-12}$.\n- Case $5$ (degenerate constraint row): $A = \\begin{bmatrix} 0 & 0 \\\\ 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$, $r = 10^{-12}$.\n\nFor each case, compute $G = A A^\\top$, perform the detection as above, and propose indices to remove. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is a two-element list $[b, L]$ with $b$ a boolean reflecting whether the original $G$ was full rank (true means full rank), and $L$ a list of zero-based integer indices of constraints to remove to restore full rank. For example, the output must have the format $[[b_1, L_1],[b_2, L_2],\\dots]$ with no spaces in the printed line.",
            "solution": "The problem requires an analysis of the constraint Gram matrix, denoted as $G$, which arises in the numerical solution of holonomic constraints in molecular dynamics simulations. A unique solution for the Lagrange multipliers, which enforce the constraints, is contingent upon the invertibility, or full rank, of this matrix. We are tasked with diagnosing rank deficiency in $G$ and proposing a minimal set of constraints to remove to restore its full rank.\n\nThe foundation of this problem lies in linear algebra and its application to constrained mechanical systems. A set of $m$ holonomic constraints is given by $c_i(\\mathbf{q}) = 0$ for $i \\in \\{1, \\dots, m\\}$. In methods like SHAKE and RATTLE, these constraints are enforced at the level of positions and velocities. The update equations lead to a linear system for the Lagrange multipliers, $\\boldsymbol{\\lambda}$. The coefficient matrix of this system is the Gram matrix, $G$.\n\nThe Gram matrix is defined as $G = A A^\\top$, where $A$ is the $m \\times n$ mass-weighted constraint Jacobian matrix. The matrix $A$ is itself defined as $A = J M^{-1/2}$, where $J$ is the $m \\times n$ Jacobian matrix of the constraint functions (its rows are $\\nabla c_i(\\mathbf{q})$) and $M$ is the diagonal $n \\times n$ mass matrix. The matrix $G$ is therefore an $m \\times m$ symmetric and positive semi-definite matrix. For a unique solution for the $m$ Lagrange multipliers to exist, $G$ must be invertible, which requires it to be of full rank, i.e., $\\text{rank}(G) = m$.\n\nA rank deficiency in $G$ (i.e., $\\text{rank}(G) < m$) implies that its rows (and columns) are linearly dependent. Since the rows of $G$ are linear combinations of the rows of $A$, this directly corresponds to a linear dependence among the constraint gradients represented by the rows of $A$. Physically, this means that at least one constraint is redundant, as its effect can be reproduced by a combination of other constraints.\n\nThe Singular Value Decomposition (SVD) is the most robust numerical method for determining the rank of a matrix. For our $m \\times m$ matrix $G$, the SVD is $G = U \\Sigma V^\\top$, where $U$ and $V$ are $m \\times m$ orthogonal matrices and $\\Sigma$ is a diagonal matrix containing the singular values, $s_1 \\ge s_2 \\ge \\dots \\ge s_m \\ge 0$. The rank of $G$ is the number of its non-zero singular values. In numerical computations, due to floating-point arithmetic, we check for rank deficiency by identifying singular values that are \"close\" to zero. The problem specifies a relative threshold, $\\tau = r \\cdot s_{\\max}$, where $s_{\\max} = s_1$ is the largest singular value and $r$ is a given small positive scalar. The matrix $G$ is considered rank-deficient if any singular value $s_k$ satisfies $s_k < \\tau$.\n\nIf rank deficiency is detected, we must identify and remove the constraints causing it. A small singular value, $s_k \\approx 0$, implies the existence of a vector in the near-null space of $G$. The columns of $U$, denoted $\\mathbf{u}_k$, are the left singular vectors. For a symmetric matrix like $G$, the left and right singular vectors are the same (up to a sign), and they are the eigenvectors of $G$. The SVD equation $G V = U \\Sigma$ gives $G \\mathbf{v}_k = s_k \\mathbf{u}_k$. Since $G$ is symmetric, $U=V$, so $G \\mathbf{u}_k = s_k \\mathbf{u}_k$. If $s_k \\approx 0$, then $G \\mathbf{u}_k \\approx \\mathbf{0}$. This equation, $\\sum_{j=1}^{m} G_{ij} u_{jk} \\approx 0$ for all $i$, shows that the vector $\\mathbf{u}_k$ defines a linear combination of the columns (and rows) of $G$ that is approximately zero. The magnitude of a component, $|u_{ik}|$, indicates the weight of the $i$-th constraint's gradient in this linear dependency. A large $|u_{ik}|$ suggests that the $i$-th constraint is a primary contributor to the redundancy.\n\nThe prescribed algorithm is a greedy, iterative procedure to restore full rank:\n$1$. For a given set of active constraints, construct the corresponding reduced Gram matrix, $G_{red}$.\n$2$. Compute its SVD and determine if it is rank-deficient using the threshold $\\tau$.\n$3$. If it is full rank, the process terminates.\n$4$. If it is rank-deficient, for each singular value $s_k < \\tau$, analyze its corresponding left singular vector $\\mathbf{u}_k$.\n$5$. In a greedy fashion, identify the constraint to remove. For each $\\mathbf{u}_k$, we find the component with the largest absolute value, $|u_{ik}|$. The index $i$ points to the most influential constraint in that specific dependency. This constraint is flagged for removal. To avoid removing the same constraint twice based on different near-null vectors in the same iteration, we ensure each flagged constraint is unique. If the first choice is already flagged, we proceed to the component with the next-largest magnitude in the same vector $\\mathbf{u}_k$.\n$6$. The flagged constraints are removed, and the process repeats from step $1$ with a smaller set of active constraints.\n\nWe first assess the rank of the original matrix $G$ to determine the initial status. Then, we apply the iterative removal process until the reduced Gram matrix is of full rank. The final output is a boolean indicating the initial status and a list of the zero-based indices of all constraints removed.\n\nFor test case $1$, $A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$, $G = I_2$. The singular values are $s_1=1$, $s_2=1$. With $r=10^{-12}$, $\\tau=10^{-12}$. Neither $s_k < \\tau$, so it is full rank. No removals are needed.\n\nFor test case $2$, $A = \\begin{bmatrix} 1 & 0 \\\\ 1 & 0 \\end{bmatrix}$, $G = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}$. The singular values are $s_1=2, s_2=0$. With $r=10^{-12}$, $\\tau=2 \\cdot 10^{-12}$. Since $s_2 < \\tau$, it is rank-deficient. The left singular vector for $s_2=0$ is approximately $[0.707, -0.707]^\\top$. Both components have equal magnitude. We can remove either constraint $0$ or $1$ to break the dependency.\n\nFor test case $3$, $A = \\begin{bmatrix} 1 & 0 \\\\ 1 & 10^{-6} \\end{bmatrix}$, $G = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1+10^{-12} \\end{bmatrix}$. This matrix is nearly singular. Its singular values are approximately $2$ and $0.5 \\cdot 10^{-12}$. With $r=10^{-5}$, $\\tau \\approx 2 \\cdot 10^{-5}$. The smallest singular value is well below $\\tau$, so it is rank-deficient. The associated singular vector is again close to $[0.707, -0.707]^\\top$, leading to the removal of one of the two nearly-collinear constraints.\n\nFor test case $4$, $A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{bmatrix}$, the third row is the sum of the first two. This creates an exact rank-deficiency in the $3 \\times 3$ matrix $G$. The null-space vector will have non-zero components for all three constraints, e.g., proportional to $[1, 1, -1]^\\top$, leading to the removal of one of them.\n\nFor test case $5$, $A = \\begin{bmatrix} 0 & 0 \\\\ 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$, the first row is a zero vector, a degenerate constraint. This creates a zero row and column in $G$, leading to a singular value of $0$. The corresponding singular vector is $[1, 0, 0]^\\top$, unambiguously identifying constraint $0$ for removal.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes constraint coupling matrices for rank deficiency and proposes\n    a minimal set of constraints to remove to restore full rank.\n    \"\"\"\n    test_cases = [\n        (np.array([[1.0, 0.0], [0.0, 1.0]]), 1e-12),\n        (np.array([[1.0, 0.0], [1.0, 0.0]]), 1e-12),\n        (np.array([[1.0, 0.0], [1.0, 1e-6]]), 1e-5),\n        (np.array([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]]), 1e-12),\n        (np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0]]), 1e-12),\n    ]\n\n    all_results = []\n\n    for A, r in test_cases:\n        m, _ = A.shape\n        original_indices = list(range(m))\n\n        # Step 1: Check if the original G is full rank\n        if m == 0:\n            is_original_full_rank = True\n        else:\n            G_orig = A @ A.T\n            s_orig = np.linalg.svd(G_orig, compute_uv=False)\n            s_max_orig = s_orig[0] if s_orig.size > 0 else 0.0\n            tau_orig = r * s_max_orig\n            is_original_full_rank = not np.any(s_orig  tau_orig)\n\n        # Step 2: Iteratively remove constraints to restore full rank\n        removed_indices = set()\n        current_indices = list(original_indices)\n\n        while True:\n            num_current_constraints = len(current_indices)\n            if num_current_constraints == 0:\n                break\n            \n            A_reduced = A[current_indices, :]\n            G_reduced = A_reduced @ A_reduced.T\n            \n            U_red, s_red, _ = np.linalg.svd(G_reduced)\n            \n            s_max_red = s_red[0] if s_red.size > 0 else 0.0\n            tau_red = r * s_max_red\n\n            # Find indices of singular values below the threshold\n            small_sv_indices = np.where(s_red  tau_red)[0]\n            \n            if small_sv_indices.size == 0:\n                # Matrix is now full rank\n                break\n            \n            # Identify constraints to remove in this iteration\n            to_remove_this_iteration = set()\n            for k in small_sv_indices:\n                u_k = U_red[:, k]\n                # Sort components of the singular vector by absolute magnitude, in descending order\n                sorted_local_indices = np.argsort(np.abs(u_k))[::-1]\n                \n                # Find the first available constraint to remove\n                for local_idx in sorted_local_indices:\n                    original_idx = current_indices[local_idx]\n                    if original_idx not in removed_indices and original_idx not in to_remove_this_iteration:\n                        to_remove_this_iteration.add(original_idx)\n                        break\n            \n            if not to_remove_this_iteration:\n                # This may happen if all candidates are already removed or if there's a logic issue.\n                # In this problem's context, if all constraints are causing issues,\n                # the loop will continue until all are removed.\n                # If no progress is made, break to prevent infinite loop.\n                break\n\n            removed_indices.update(to_remove_this_iteration)\n            current_indices = [i for i in original_indices if i not in removed_indices]\n\n        final_removed_list = sorted(list(removed_indices))\n        all_results.append((is_original_full_rank, final_removed_list))\n\n    # Format the final output string as per requirements\n    formatted_items = []\n    for b, L in all_results:\n        l_str = f\"[{','.join(map(str, L))}]\"\n        # The problem asks for a boolean b. Python's str(True) is 'True'.\n        # We convert to lowercase 'true'/'false' for standard data representation.\n        formatted_items.append(f\"[{str(b).lower()},{l_str}]\")\n\n    output_str = f\"[{','.join(formatted_items)}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}