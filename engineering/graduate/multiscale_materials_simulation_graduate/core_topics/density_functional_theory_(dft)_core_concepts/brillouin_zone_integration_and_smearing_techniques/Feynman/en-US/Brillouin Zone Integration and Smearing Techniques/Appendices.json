{
    "hands_on_practices": [
        {
            "introduction": "This exercise grounds the abstract concept of Brillouin zone integration in a concrete numerical task. By implementing a simple grid-based integration for a test function, you will directly explore the relationship between grid density and accuracy, a fundamental aspect of all computational materials science simulations. ",
            "id": "3793467",
            "problem": "You are asked to implement a program that computes a numerical Brillouin Zone (BZ) average and estimates its quadrature error for a smooth, periodic test function in reciprocal space. The Brillouin Zone (BZ) of a simple cubic lattice of unit lattice constant is the cube defined by $[-\\pi,\\pi]^3$ in reciprocal space.\n\nStarting from fundamental definitions, the BZ average of a function $g(\\mathbf{k})$ is the normalized integral\n$$\n\\langle g \\rangle \\equiv \\frac{1}{V_{\\mathrm{BZ}}} \\int_{-\\pi}^{\\pi} \\int_{-\\pi}^{\\pi} \\int_{-\\pi}^{\\pi} g(k_x,k_y,k_z)\\, \\mathrm{d}k_x\\, \\mathrm{d}k_y\\, \\mathrm{d}k_z,\n$$\nwhere $V_{\\mathrm{BZ}}$ is the BZ volume. For the simple cubic BZ considered here, $V_{\\mathrm{BZ}}= (2\\pi)^3$.\n\nThe test function is $g(\\mathbf{k}) = \\cos(k_x) + \\cos(k_y) + \\cos(k_z)$, with all cosine arguments in radians.\n\nYou must approximate $\\langle g \\rangle$ using a uniform grid with $N$ points per dimension on $[-\\pi,\\pi]$, including both endpoints for $N>1$. Specifically, for $N>1$, the one-dimensional grid points are\n$$\nk_i = -\\pi + i \\frac{2\\pi}{N-1}, \\quad i \\in \\{0,1,\\dots,N-1\\},\n$$\nand for the boundary case $N=1$, define the degenerate grid point as $k_0 = 0$. The three-dimensional grid is the Cartesian product of the one-dimensional grids for $k_x$, $k_y$, and $k_z$. The numerical BZ average is defined as the arithmetic mean of $g(\\mathbf{k})$ over all grid points,\n$$\n\\langle g \\rangle_N \\equiv \\frac{1}{N^3} \\sum_{i=0}^{N-1} \\sum_{j=0}^{N-1} \\sum_{l=0}^{N-1} g(k_i,k_j,k_l).\n$$\n\nDefine the quadrature error for a given $N$ as the absolute difference between the numerical average and the exact analytical average,\n$$\nE(N) \\equiv \\left| \\langle g \\rangle_N - \\langle g \\rangle \\right|.\n$$\n\nUsing the above, implement a program that:\n- Computes $\\langle g \\rangle_N$ for each specified $N$.\n- Uses the fact that the exact analytical average $\\langle g \\rangle$ can be determined from fundamental properties of the cosine function over symmetric intervals to compute $E(N)$.\n- Estimates the empirical convergence rate $p$ of the quadrature error with respect to $N$ by fitting the model $E(N) \\approx C N^{-p}$ using a least-squares fit on $\\log E(N)$ versus $\\log N$ over all test cases with strictly positive error values. If fewer than two strictly positive error values are available, set $p$ to $0$.\n\nAngle units must be radians. All outputs are dimensionless real numbers.\n\nTest Suite:\nUse the following grid densities (points per dimension): $[1,2,3,4,5,6,7,8,10,13]$.\n\nRequired Final Output Format:\nYour program should produce a single line of output containing a comma-separated list enclosed in square brackets, where the first $10$ entries are the quadrature errors $E(N)$ for the test suite in the given order, and the last entry is the empirical convergence rate $p$ estimated as described. For example, the output format must be exactly\n$[\\text{E}(1),\\text{E}(2),\\text{E}(3),\\text{E}(4),\\text{E}(5),\\text{E}(6),\\text{E}(7),\\text{E}(8),\\text{E}(10),\\text{E}(13),p]$.",
            "solution": "The problem requires the calculation of a numerical Brillouin Zone (BZ) average for a given test function, the determination of the quadrature error against the exact analytical average, and an estimation of the error's convergence rate.\n\nFirst, I shall validate the problem statement. The givens are:\n- The Brillouin Zone (BZ) is the cube defined by $[-\\pi,\\pi]^3$.\n- The BZ volume is $V_{\\mathrm{BZ}}= (2\\pi)^3$.\n- The analytical BZ average of a function $g(\\mathbf{k})$ is $\\langle g \\rangle \\equiv \\frac{1}{V_{\\mathrm{BZ}}} \\int_{\\mathrm{BZ}} g(\\mathbf{k})\\, \\mathrm{d}^3k$.\n- The test function is $g(\\mathbf{k}) = \\cos(k_x) + \\cos(k_y) + \\cos(k_z)$.\n- The numerical grid for dimension $N > 1$ consists of points $k_i = -\\pi + i \\frac{2\\pi}{N-1}$ for $i \\in \\{0,1,\\dots,N-1\\}$. For $N=1$, the grid is a single point $k_0 = 0$.\n- The numerical BZ average is $\\langle g \\rangle_N \\equiv \\frac{1}{N^3} \\sum_{i,j,l=0}^{N-1} g(k_i,k_j,k_l)$.\n- The quadrature error is $E(N) \\equiv \\left| \\langle g \\rangle_N - \\langle g \\rangle \\right|$.\n- The convergence rate $p$ is estimated from the model $E(N) \\approx C N^{-p}$ via a least-squares fit on $\\log E(N)$ versus $\\log N$ for all cases where $E(N) > 0$. If fewer than two such points exist, $p=0$.\n- The test suite for $N$ is $[1,2,3,4,5,6,7,8,10,13]$.\n\nThe problem is scientifically grounded in solid-state physics and numerical analysis, making it a standard exercise in computational materials science. All terms are defined with mathematical precision, and no information is missing or contradictory. The problem is well-posed, objective, and its solution is verifiable. Therefore, the problem is deemed valid.\n\nThe solution process consists of three main parts:\n1.  Calculation of the exact analytical average $\\langle g \\rangle$.\n2.  Calculation of the numerical average $\\langle g \\rangle_N$ and the error $E(N)$.\n3.  Estimation of the convergence rate $p$.\n\n**1. Analytical BZ Average $\\langle g \\rangle$**\n\nThe exact average $\\langle g \\rangle$ is given by:\n$$\n\\langle g \\rangle = \\frac{1}{(2\\pi)^3} \\int_{-\\pi}^{\\pi} \\int_{-\\pi}^{\\pi} \\int_{-\\pi}^{\\pi} \\left( \\cos(k_x) + \\cos(k_y) + \\cos(k_z) \\right) \\, \\mathrm{d}k_x\\, \\mathrm{d}k_y\\, \\mathrm{d}k_z\n$$\nDue to the linearity of the integral, we can separate the terms:\n$$\n\\langle g \\rangle = \\frac{1}{(2\\pi)^3} \\left( \\int_{\\mathrm{BZ}} \\cos(k_x)\\, \\mathrm{d}^3k + \\int_{\\mathrm{BZ}} \\cos(k_y)\\, \\mathrm{d}^3k + \\int_{\\mathrm{BZ}} \\cos(k_z)\\, \\mathrm{d}^3k \\right)\n$$\nLet us evaluate the first term. The integrals over $k_y$ and $k_z$ are separable:\n$$\n\\int_{\\mathrm{BZ}} \\cos(k_x)\\, \\mathrm{d}^3k = \\left( \\int_{-\\pi}^{\\pi} \\cos(k_x) \\, \\mathrm{d}k_x \\right) \\left( \\int_{-\\pi}^{\\pi} \\mathrm{d}k_y \\right) \\left( \\int_{-\\pi}^{\\pi} \\mathrm{d}k_z \\right)\n$$\nThe integral of the cosine function over a symmetric interval $[-\\pi, \\pi]$ is:\n$$\n\\int_{-\\pi}^{\\pi} \\cos(k_x) \\, \\mathrm{d}k_x = [\\sin(k_x)]_{-\\pi}^{\\pi} = \\sin(\\pi) - \\sin(-\\pi) = 0 - 0 = 0\n$$\nSince this integral is $0$, the entire first term is $0$. By symmetry, the other two terms involving $\\cos(k_y)$ and $\\cos(k_z)$ are also $0$.\nThus, the exact analytical average is $\\langle g \\rangle = 0$.\n\n**2. Numerical BZ Average $\\langle g \\rangle_N$ and Quadrature Error $E(N)$**\n\nThe numerical average is defined as:\n$$\n\\langle g \\rangle_N = \\frac{1}{N^3} \\sum_{i=0}^{N-1} \\sum_{j=0}^{N-1} \\sum_{l=0}^{N-1} \\left( \\cos(k_i) + \\cos(k_j) + \\cos(k_l) \\right)\n$$\nBy linearity of summation, this can be simplified. Let's analyze the sum over $\\cos(k_i)$:\n$$\n\\sum_{i=0}^{N-1} \\sum_{j=0}^{N-1} \\sum_{l=0}^{N-1} \\cos(k_i) = \\left( \\sum_{i=0}^{N-1} \\cos(k_i) \\right) \\left( \\sum_{j=0}^{N-1} 1 \\right) \\left( \\sum_{l=0}^{N-1} 1 \\right) = N^2 \\sum_{i=0}^{N-1} \\cos(k_i)\n$$\nSince the grids for $k_x$, $k_y$, and $k_z$ are identical, the sums over $\\cos(k_j)$ and $\\cos(k_l)$ have the same value. Let $S_N = \\sum_{i=0}^{N-1} \\cos(k_i)$. The expression for the average becomes:\n$$\n\\langle g \\rangle_N = \\frac{1}{N^3} \\left( N^2 S_N + N^2 S_N + N^2 S_N \\right) = \\frac{3 N^2 S_N}{N^3} = \\frac{3 S_N}{N}\n$$\nNow, we must evaluate the sum $S_N$.\n\nCase $N=1$: The grid is $k_0=0$. $S_1 = \\cos(0) = 1$.\n$\\langle g \\rangle_1 = \\frac{3(1)}{1} = 3$.\n\nCase $N=2$: The grid is $\\{-\\pi, \\pi\\}$. $S_2 = \\cos(-\\pi) + \\cos(\\pi) = -1 + (-1) = -2$.\n$\\langle g \\rangle_2 = \\frac{3(-2)}{2} = -3$.\n\nCase $N \\ge 3$: The grid points are $k_i = -\\pi + i d$ with step $d = \\frac{2\\pi}{N-1}$. The sum is $S_N = \\sum_{i=0}^{N-1} \\cos(-\\pi + i\\,\\frac{2\\pi}{N-1})$. This is a standard sum which can be evaluated using the formula for the sum of cosines in an arithmetic progression: $\\sum_{i=0}^{n-1} \\cos(a+id) = \\frac{\\cos(a+(n-1)d/2)\\sin(nd/2)}{\\sin(d/2)}$.\nHere, $a=-\\pi$, $d=\\frac{2\\pi}{N-1}$, and $n=N$. This is applicable for $d/2 \\neq m\\pi$ (for integer $m$), which holds for $N>2$.\nThe numerator's cosine term argument is $a + (n-1)d/2 = -\\pi + (N-1)\\frac{\\pi}{N-1} = 0$. So $\\cos(0)=1$.\nThe numerator's sine term argument is $nd/2 = N\\frac{\\pi}{N-1} = \\frac{(N-1+1)\\pi}{N-1} = \\pi + \\frac{\\pi}{N-1}$.\nSo $\\sin(N\\frac{\\pi}{N-1}) = \\sin(\\pi + \\frac{\\pi}{N-1}) = -\\sin(\\frac{\\pi}{N-1})$.\nThe sum becomes $S_N = \\frac{1 \\cdot (-\\sin(\\frac{\\pi}{N-1}))}{\\sin(\\frac{\\pi}{N-1})} = -1$.\nSo, for all $N \\ge 3$, $S_N = -1$.\nThis gives $\\langle g \\rangle_N = \\frac{3(-1)}{N} = -\\frac{3}{N}$ for $N \\ge 3$.\n\nThe quadrature error is $E(N) = |\\langle g \\rangle_N - \\langle g \\rangle| = |\\langle g \\rangle_N - 0| = |\\langle g \\rangle_N|$.\n- For $N=1$: $E(1) = |\\langle g \\rangle_1| = |3| = 3$.\n- For $N=2$: $E(2) = |\\langle g \\rangle_2| = |-3| = 3$.\n- For $N \\ge 3$: $E(N) = |-\\frac{3}{N}| = \\frac{3}{N}$.\n\n**3. Estimation of the Convergence Rate $p$**\n\nThe model is $E(N) \\approx C N^{-p}$. Taking the natural logarithm gives $\\ln E(N) \\approx \\ln C - p \\ln N$. This is a linear relation of the form $y \\approx b + mx$, where $y=\\ln E(N)$, $x=\\ln N$, the slope is $m=-p$, and the intercept is $b=\\ln C$. We need to perform a least-squares linear regression on the points $(\\ln N, \\ln E(N))$ for all $N$ in the test suite, since all calculated a priori errors are strictly positive.\n\nThe test suite is $N \\in [1, 2, 3, 4, 5, 6, 7, 8, 10, 13]$. All $10$ points will be used for the fit. We will compute the pairs $(\\ln N, \\ln E(N))$ and find the slope $m$ of the best-fit line. The convergence rate will then be $p = -m$. A standard numerical library function, such as `numpy.polyfit`, will be used for the regression.\n\nThe algorithmic plan is as follows:\n1.  Create a list of the test values for $N$.\n2.  For each $N$, calculate $E(N)$ using the analytical formulas derived above: $E(1)=3$, $E(2)=3$, and $E(N)=3/N$ for $N \\ge 3$. Store these errors.\n3.  Since all errors are positive, prepare two lists for the linear fit: one with $\\ln N$ for all $N$ in the test suite, and one with $\\ln E(N)$.\n4.  Use `numpy.polyfit` with degree $1$ on these lists to find the slope $m$.\n5.  Calculate $p = -m$.\n6.  Construct and print the final output string containing the list of errors followed by the calculated value of $p$.\n\nThis approach is computationally efficient and exact, fully adhering to the problem's requirements.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes Brillouin Zone integration errors and the empirical convergence rate.\n    \"\"\"\n    # Define the test suite of grid densities per dimension.\n    test_suite_N = [1, 2, 3, 4, 5, 6, 7, 8, 10, 13]\n\n    errors = []\n    log_fit_data = []\n\n    # The exact analytical average <g> is 0.\n    # The quadrature error E(N) = |<g>_N - <g>| = |<g>_N|.\n    # Through analysis of the sum, we found exact formulas for <g>_N:\n    # <g>_1 = 3\n    # <g>_2 = -3\n    # <g>_N = -3/N for N >= 3.\n    # Therefore, E(1)=3, E(2)=3, and E(N)=3/N for N>=3.\n\n    for N in test_suite_N:\n        if N == 1:\n            error_N = 3.0\n        elif N == 2:\n            error_N = 3.0\n        else: # N >= 3\n            error_N = 3.0 / N\n        \n        errors.append(error_N)\n\n        # The problem requires fitting on strictly positive error values.\n        # All our calculated errors are > 0, so all points are used.\n        if error_N > 0:\n            log_fit_data.append((np.log(N), np.log(error_N)))\n\n    # Estimate the convergence rate p.\n    # The model is E(N) ~ C * N^(-p), which is log(E) ~ log(C) - p*log(N).\n    # This is a linear fit of log(E) vs log(N) with slope -p.\n    \n    # Per the problem statement, if fewer than two positive error values are\n    # available, p is set to 0.\n    if len(log_fit_data) < 2:\n        p = 0.0\n    else:\n        # Unzip the data into separate lists for the fit.\n        log_N_vals, log_E_vals = zip(*log_fit_data)\n        \n        # Convert to numpy arrays for polyfit.\n        x_fit = np.array(log_N_vals)\n        y_fit = np.array(log_E_vals)\n        \n        # Perform a least-squares polynomial fit of degree 1 (linear fit).\n        # np.polyfit returns the coefficients [slope, intercept].\n        slope, intercept = np.polyfit(x_fit, y_fit, 1)\n        \n        # The convergence rate p is the negative of the slope.\n        p = -slope\n        \n    # Combine the error list and the convergence rate for the final output.\n    final_results = errors + [p]\n\n    # Format the output as a comma-separated list in square brackets.\n    # Using a general formatter to handle floating point numbers cleanly.\n    output_str = f\"[{','.join(f'{val:.10g}' for val in final_results)}]\"\n    \n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "A brute-force summation over thousands of k-points is computationally wasteful. This practice demonstrates the power of symmetry in reducing the computational workload by orders of magnitude, a cornerstone of efficient electronic structure calculations. By analyzing a simple Monkhorst-Pack grid for an FCC lattice, you will learn to identify symmetrically equivalent k-points and determine the irreducible set and their corresponding weights. ",
            "id": "3793500",
            "problem": "Consider a nonmagnetic crystalline solid with a face-centered cubic lattice and space group $Fm\\bar{3}m$, whose crystallographic point group is the full octahedral group $O_{h}$. For Brillouin zone integration in multiscale materials simulation, a uniform discrete approximation is constructed using the Monkhorst–Pack (MP) scheme. In the MP construction, an $N\\times N\\times N$ grid in reciprocal space is defined by points with Cartesian components\n$$\nk_{\\alpha}=\\frac{2r_{\\alpha}-N-1}{2N},\\quad r_{\\alpha}\\in\\{1,2,\\dots,N\\},\\quad \\alpha\\in\\{x,y,z\\},\n$$\nwhere the axes are aligned with the conventional cubic axes of the lattice. Symmetry reduction to the irreducible Brillouin zone uses the crystallographic point group $O_{h}$ acting on reciprocal vectors, together with translational periodicity of reciprocal space; assume time-reversal symmetry is present and there is no spin–orbit induced magnetism.\n\nStarting from first principles—namely the definition of the MP grid, the action of a point group on reciprocal space, and the identification of orbits (stars) of $\\mathbf{k}$-points under $O_{h}$—derive how many irreducible $\\mathbf{k}$-points exist for the case $N=2$, and determine the corresponding normalized integration weight(s) assigned to each irreducible representative by symmetry reduction. The normalization convention is that the sum of all irreducible weights equals $1$.\n\nExpress your final result as a single row matrix using the LaTeX $\\mathrm{pmatrix}$ environment, with the first entry equal to the total number of irreducible $\\mathbf{k}$-points and the second entry equal to the normalized weight of each irreducible representative. No rounding is required, and the entries are dimensionless.",
            "solution": "The problem requires the determination of the number of irreducible $\\mathbf{k}$-points and their corresponding normalized integration weights for a Monkhorst-Pack (MP) grid with parameters $N=2$ for a face-centered cubic (FCC) lattice. The symmetry of the crystal is described by the space group $Fm\\bar{3}m$, which has the crystallographic point group $O_h$.\n\nFirst, we must generate the full set of $\\mathbf{k}$-points in the MP grid. The components of the $\\mathbf{k}$-vectors are given by the formula:\n$$\nk_{\\alpha}=\\frac{2r_{\\alpha}-N-1}{2N}\n$$\nwhere $\\alpha \\in \\{x,y,z\\}$ and $r_{\\alpha} \\in \\{1, 2, \\dots, N\\}$. The coordinates are dimensionless, defined with respect to the basis vectors of the reciprocal space aligned with the conventional cubic axes.\n\nFor the specific case $N=2$, the possible values for $r_{\\alpha}$ are $1$ and $2$. We calculate the corresponding component values $k_{\\alpha}$:\nFor $r_{\\alpha} = 1$:\n$$\nk_{\\alpha} = \\frac{2(1)-2-1}{2(2)} = \\frac{2-3}{4} = -\\frac{1}{4}\n$$\nFor $r_{\\alpha} = 2$:\n$$\nk_{\\alpha} = \\frac{2(2)-2-1}{2(2)} = \\frac{4-3}{4} = \\frac{1}{4}\n$$\nThus, each Cartesian component of a $\\mathbf{k}$-vector in the grid can be either $-\\frac{1}{4}$ or $\\frac{1}{4}$. The total number of $\\mathbf{k}$-points in the grid is $N \\times N \\times N = 2^3 = 8$. The complete set of $\\mathbf{k}$-points is:\n$$\n\\left\\{ \\left(\\pm\\frac{1}{4}, \\pm\\frac{1}{4}, \\pm\\frac{1}{4}\\right) \\right\\}\n$$\nExplicitly, the 8 points are:\n$\n\\mathbf{k}_1 = (\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4})\n$, \n$\n\\mathbf{k}_2 = (\\frac{1}{4}, \\frac{1}{4}, -\\frac{1}{4})\n$, \n$\n\\mathbf{k}_3 = (\\frac{1}{4}, -\\frac{1}{4}, \\frac{1}{4})\n$, \n$\n\\mathbf{k}_4 = (-\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4})\n$, \n$\n\\mathbf{k}_5 = (\\frac{1}{4}, -\\frac{1}{4}, -\\frac{1}{4})\n$, \n$\n\\mathbf{k}_6 = (-\\frac{1}{4}, \\frac{1}{4}, -\\frac{1}{4})\n$, \n$\n\\mathbf{k}_7 = (-\\frac{1}{4}, -\\frac{1}{4}, \\frac{1}{4})\n$, \n$\n\\mathbf{k}_8 = (-\\frac{1}{4}, -\\frac{1}{4}, -\\frac{1}{4})\n$.\n\nNext, we must reduce this set of points to the irreducible set by identifying points that are equivalent under the symmetry operations of the lattice. The equivalences arise from:\n1.  Translational periodicity of reciprocal space: Two points $\\mathbf{k}$ and $\\mathbf{k}'$ are equivalent if $\\mathbf{k}' = \\mathbf{k} + \\mathbf{G}$, where $\\mathbf{G}$ is a reciprocal lattice vector. For an FCC lattice, the reciprocal lattice is body-centered cubic (BCC). In the chosen coordinate system (scaled by a factor of $2\\pi/a$, where $a$ is the conventional lattice constant), the reciprocal lattice vectors $\\mathbf{G}=(G_x, G_y, G_z)$ are those where the integer components $G_x, G_y, G_z$ are either all even or all odd. The difference between any two points in our grid has components that can be $0$, $\\pm\\frac{1}{2}$. For example, $\\mathbf{k}_1-\\mathbf{k}_8 = (\\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2})$. None of these difference vectors correspond to a non-zero reciprocal lattice vector $\\mathbf{G}$, as the components of $\\mathbf{G}$ must be integers. Therefore, all $8$ points are inequivalent with respect to lattice translations.\n\n2.  Point group symmetry: Two points $\\mathbf{k}$ and $\\mathbf{k}'$ are equivalent if $\\mathbf{k}' = g\\mathbf{k}$ for some operation $g$ in the crystal's point group, $O_h$. The set of all points $g\\mathbf{k}$ for a given $\\mathbf{k}$ forms an orbit, or a \"star\" of $\\mathbf{k}$. The group $O_h$ consists of $48$ symmetry operations, which include all permutations of the coordinates $(x,y,z)$ and all possible sign changes $(\\pm x, \\pm y, \\pm z)$.\n\n3.  Time-reversal symmetry: For a nonmagnetic material, $\\mathbf{k}$ is equivalent to $-\\mathbf{k}$. The point group $O_h$ is centrosymmetric, meaning it contains the inversion operation $i$, where $i\\mathbf{k} = -\\mathbf{k}$. Therefore, time-reversal symmetry does not introduce any new equivalences beyond those already imposed by the point group $O_h$.\n\nLet us find the orbits of the 8 grid points under the action of $O_h$. We can start with an arbitrary point, for example $\\mathbf{k}_A = (\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4})$. Let us apply the operations of $O_h$ to this point.\n-   Permutations of coordinates: Since $k_x=k_y=k_z=\\frac{1}{4}$, any permutation of the coordinates leaves the point $\\mathbf{k}_A$ unchanged. For example, swapping $x$ and $y$ coordinates results in $(\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4})$.\n-   Sign changes: Applying all possible combinations of sign changes to the components of $\\mathbf{k}_A$ generates the set of points $(\\pm\\frac{1}{4}, \\pm\\frac{1}{4}, \\pm\\frac{1}{4})$. This is exactly the entire set of 8 points in our MP grid.\n\nThis demonstrates that all 8 points in the $N=2$ MP grid belong to a single orbit (a single star). Consequently, all 8 points are symmetrically equivalent, and the set of unique, irreducible $\\mathbf{k}$-points in the irreducible Brillouin zone (IBZ) consists of only one point. The number of irreducible $\\mathbf{k}$-points is $1$.\n\nAs a representative for this single orbit, we can choose any of the 8 points. A conventional choice is a point lying within the standard definition of the IBZ for $O_h$ symmetry, e.g., the region defined by $k_x \\ge k_y \\ge k_z \\ge 0$. The point $\\mathbf{k}_{irrep} = (\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4})$ satisfies this condition.\n\nFinally, we need to determine the normalized integration weight assigned to this irreducible representative. The weight, $W_i$, of an irreducible point $\\mathbf{k}_i$ is proportional to the number of points in its star, $S_i = |\\text{Star}(\\mathbf{k}_i)|$. The problem specifies that the sum of the weights of all irreducible points must be $1$.\n$$\n\\sum_{i \\in \\text{IBZ}} W_i = 1\n$$\nThe weight for each irreducible point is given by the formula:\n$$\nW_i = \\frac{S_i}{\\sum_{j \\in \\text{IBZ}} S_j}\n$$\nThe sum in the denominator, $\\sum_{j \\in \\text{IBZ}} S_j$, is the sum of the sizes of all distinct orbits, which must equal the total number of points in the original grid, $N^3$.\n$$\nW_i = \\frac{S_i}{N^3}\n$$\nIn our case, there is only one irreducible point ($i=1$), so the sum $\\sum W_i$ has only one term, $W_1$, which must be equal to $1$.\nLet's verify this with the formula. The star of our single irreducible point contains all $8$ points of the grid, so its size is $S_1 = 8$. The total number of points in the grid is $N^3 = 2^3 = 8$.\nThe weight is therefore:\n$$\nW_1 = \\frac{S_1}{N^3} = \\frac{8}{8} = 1\n$$\nSo, for the $N=2$ Monkhorst-Pack grid, there is only one irreducible $\\mathbf{k}$-point, and its normalized weight is $1$.\n\nThe final result is the number of irreducible $\\mathbf{k}$-points, which is $1$, and the weight of each, which is $1$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 & 1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Calculating properties of metallic systems presents a unique challenge due to the sharp Fermi-Dirac distribution at zero temperature. This practice dives into the advanced technique of smearing extrapolation, a crucial method for obtaining high-precision forces and stresses by systematically removing errors introduced by the necessary smearing. You will implement a protocol based on the known analytical scaling of these errors, moving from approximate results to the true zero-smearing limit. ",
            "id": "3793477",
            "problem": "You are tasked with implementing a protocol to extrapolate atomic forces and stress components to the zero-smearing limit in metallic systems by combining calculations at multiple electronic smearing widths. The extrapolation must be grounded in the analyticity of Brillouin zone integrals and the low-temperature expansion of Fermi-Dirac and related smearing distributions. The foundational base is that in Mermin finite-temperature Density Functional Theory (DFT), integrals of analytic functions of energy weighted by occupation factors admit a Sommerfeld-type expansion in even powers of the electronic temperature, which is proportional to the smearing width. Consequently, for sufficiently small smearing width $\\sigma$, observables such as energy-derived quantities (forces and stresses) can be modeled as an even-power series in $\\sigma$, with the leading exponent depending on the choice of smearing scheme.\n\nSpecifically, assume the following leading error scalings for three widely used smearing schemes:\n- Fermi-Dirac smearing: leading correction scales as $\\sigma^{2}$, so the model includes terms up to $\\sigma^{4}$.\n- Marzari-Vanderbilt cold smearing: leading correction scales as $\\sigma^{4}$, so the model includes terms up to $\\sigma^{6}$.\n- Methfessel-Paxton smearing of order $p$: leading correction scales as $\\sigma^{2p+2}$, so for $p=1$ the model includes terms up to $\\sigma^{6}$.\n\nYou must implement a program that, for each test case, performs a linear regression of the measured observable $y(\\sigma)$ against the appropriate basis of even powers of $\\sigma$ for the specified smearing scheme, and returns the extrapolated zero-smearing value $y_{0}$ (the coefficient of the $\\sigma^{0}$ term). Use the minimal polynomial basis consistent with the known leading scaling and include one higher even-power term to capture subleading corrections. The extrapolation must be executed independently for the force component and for the stress component in each case.\n\nAll physical units must be handled explicitly:\n- Forces are provided and must be returned in $\\mathrm{eV}/\\AA$.\n- Stresses are provided and must be returned in $\\mathrm{GPa}$.\n- Smearing widths $\\sigma$ are provided in $\\mathrm{eV}$.\n\nYour program must implement the following test suite. For each case, perform two regressions, one for the force component and one for the stress, using the specified smearing exponents inferred from the scheme. The measured values are noiseless and consistent with an even-power model:\n\n- Case A (Fermi-Dirac smearing):\n  - Basis exponents: $\\{0,2,4\\}$.\n  - Smearing widths: $\\sigma \\in \\{0.05, 0.10, 0.15\\}\\,\\mathrm{eV}$.\n  - Force measurements in $\\mathrm{eV}/\\AA$: $y_{F}(\\sigma) \\in \\{0.253996875, 0.26595, 0.285746875\\}$.\n  - Stress measurements in $\\mathrm{GPa}$: $y_{S}(\\sigma) \\in \\{4.925625, 4.71, 4.376\\}$.\n\n- Case B (Marzari-Vanderbilt cold smearing):\n  - Basis exponents: $\\{0,4,6\\}$.\n  - Smearing widths: $\\sigma \\in \\{0.05, 0.12, 0.20\\}\\,\\mathrm{eV}$.\n  - Force measurements in $\\mathrm{eV}/\\AA$: $y_{F}(\\sigma) \\in \\{-0.109980015625, -0.109339433984, -0.104944\\}$.\n  - Stress measurements in $\\mathrm{GPa}$: $y_{S}(\\sigma) \\in \\{-1.50012421875, -1.5039979008, -1.5288\\}$.\n\n- Case C (Methfessel-Paxton smearing of order $p=1$):\n  - Basis exponents: $\\{0,4,6\\}$.\n  - Smearing widths: $\\sigma \\in \\{0.0, 0.06, 0.12\\}\\,\\mathrm{eV}$.\n  - Force measurements in $\\mathrm{eV}/\\AA$: $y_{F}(\\sigma) \\in \\{0.035, 0.035012983328, 0.035208852992\\}$.\n  - Stress measurements in $\\mathrm{GPa}$: $y_{S}(\\sigma) \\in \\{0.25, 0.2525733376, 0.2902776064\\}$.\n\nAlgorithmic requirements:\n- For each case, construct a design matrix $X$ whose entries are $X_{ij} = \\sigma_{i}^{e_{j}}$, where $\\{\\sigma_{i}\\}$ are the smearing widths and $\\{e_{j}\\}$ are the basis exponents specified by the smearing scheme.\n- Solve the linear system in the least-squares sense to obtain the coefficient vector $\\mathbf{c} = (c_{0}, c_{e_{1}}, c_{e_{2}})^{\\top}$ that best fits $y(\\sigma) \\approx \\sum_{j} c_{e_{j}} \\sigma^{e_{j}}$.\n- The extrapolated zero-smearing value is $y_0 = c_0$.\n\nOutput specification:\n- Your program must produce a single line of output containing the extrapolated zero-smearing values in the following order: [$F_A, S_A, F_B, S_B, F_C, S_C$], where $F_{\\cdot}$ are forces in $\\mathrm{eV}/\\AA$ and $S_{\\cdot}$ are stresses in $\\mathrm{GPa}$.\n- Each entry must be a floating-point number.\n- No additional text or lines may be printed.\n\nYour program must be self-contained, must not require any user input, and must run under a Python $3.12$ environment using only the NumPy library and the Python standard library. The final outputs must be expressed in their respective units as specified and printed exactly in the required aggregated format.",
            "solution": "The user has requested a protocol for extrapolating atomic forces and stresses in metallic systems, calculated using Density Functional Theory (DFT), to the zero-smearing limit. This process is grounded in the well-established theoretical properties of Brillouin zone integration at finite electronic temperatures.\n\nThe fundamental principle is derived from Mermin's finite-temperature DFT and the Sommerfeld expansion. In electronic structure calculations for metals, the occupation of electronic states is described by a smearing function, most commonly the Fermi-Dirac distribution, $f((\\epsilon - \\mu)/\\sigma)$, where $\\epsilon$ is the state energy, $\\mu$ is the chemical potential, and $\\sigma$ is the smearing width, which is proportional to the electronic temperature ($T$). Physical observables, such as the total free energy $F$, atomic forces $\\mathbf{F} = -\\nabla_{\\mathbf{R}} F$, and the stress tensor $\\mathbf{\\tau} = (1/V) \\partial F / \\partial \\boldsymbol{\\epsilon}$, are computed by integrating over the Brillouin zone. These integrals involve sums over states weighted by the occupation function.\n\nFor a general observable $Y$ derived from an integral involving the occupation function, the Sommerfeld expansion dictates that for small smearing widths $\\sigma$, $Y(\\sigma)$ can be expressed as a power series in even powers of $\\sigma$:\n$$\nY(\\sigma) = Y_0 + c_2 \\sigma^2 + c_4 \\sigma^4 + c_6 \\sigma^6 + \\mathcal{O}(\\sigma^8)\n$$\nThe value $Y_0$ represents the true ground-state observable, corresponding to the limit $\\sigma \\to 0$ (or zero electronic temperature). The coefficients $c_{2n}$ depend on the specific observable and the details of the electronic band structure. The leading error term in this expansion depends on the specific smearing function used. The problem statement specifies the following behaviors:\n-   **Fermi-Dirac (FD) smearing**: The leading error is proportional to $\\sigma^2$. A suitable model includes terms up to $\\sigma^4$: $Y(\\sigma) \\approx c_0 + c_2\\sigma^2 + c_4\\sigma^4$.\n-   **Marzari-Vanderbilt (MV) cold smearing**: This \"cold smearing\" technique is designed to cancel the $\\sigma^2$ term, resulting in a leading error proportional to $\\sigma^4$. The model includes the next higher-order term: $Y(\\sigma) \\approx c_0 + c_4\\sigma^4 + c_6\\sigma^6$.\n-   **Methfessel-Paxton (MP) smearing of order $p=1$**: This method also cancels lower-order errors. For order $p=1$, the leading error is proportional to $\\sigma^{2p+2} = \\sigma^4$. The model is identical to the MV case: $Y(\\sigma) \\approx c_0 + c_4\\sigma^4 + c_6\\sigma^6$.\n\nThe task is to determine the extrapolated value $Y_0 = c_0$ by performing a linear regression on a set of calculated data points $\\{(\\sigma_i, y_i)\\}$. For each case, we are given $3$ data points and a model with $3$ unknown coefficients. This constitutes an exactly determined linear system of equations.\n\nLet the model for a given case be $y(\\sigma) = \\sum_{j=0}^{n-1} c_{e_j} \\sigma^{e_j}$, where $\\{e_j\\}$ is the set of specified exponents (e.g., $\\{0, 2, 4\\}$ for FD). For a set of $m=n$ measurements $(y_i, \\sigma_i)$, we can write the system of linear equations in matrix form as:\n$$\n\\mathbf{y} = X\\mathbf{c}\n$$\nwhere:\n-   $\\mathbf{y} = [y_1, y_2, \\dots, y_m]^\\top$ is the vector of measured observable values.\n-   $\\mathbf{c} = [c_{e_0}, c_{e_1}, \\dots, c_{e_{n-1}}]^\\top$ is the vector of unknown coefficients. The desired extrapolated value is $c_{e_0}$, which corresponds to the exponent $e_0=0$.\n-   $X$ is the $m \\times n$ design matrix, with entries $X_{ij} = \\sigma_i^{e_j}$.\n\nFor each test case in the problem, we have $3$ data points and a $3$-parameter model, so the design matrix $X$ is a square $3 \\times 3$ matrix.\n$$\n\\begin{pmatrix}\ny_1 \\\\\ny_2 \\\\\ny_3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\sigma_1^{e_0} & \\sigma_1^{e_1} & \\sigma_1^{e_2} \\\\\n\\sigma_2^{e_0} & \\sigma_2^{e_1} & \\sigma_2^{e_2} \\\\\n\\sigma_3^{e_0} & \\sigma_3^{e_1} & \\sigma_3^{e_2}\n\\end{pmatrix}\n\\begin{pmatrix}\nc_{e_0} \\\\\nc_{e_1} \\\\\nc_{e_2}\n\\end{pmatrix}\n$$\nSince the provided $\\sigma_i$ values are distinct for each case, the matrix $X$ is non-singular, and the system has a unique solution for the coefficient vector $\\mathbf{c}$. This solution can be found by solving the linear system, for example using `numpy.linalg.solve`. The extrapolated zero-smearing value is the first element of the resulting solution vector $\\mathbf{c}$, corresponding to the coefficient of the $\\sigma^0$ term.\n\nThis procedure is applied independently to each of the six sub-problems (force and stress for cases A, B, and C). For Case C, where one of the data points is given at $\\sigma_3=0$, the corresponding row in the design matrix becomes $(1, 0, 0)$ because $0^0=1$ and $0^k=0$ for $k>0$. This correctly yields $c_{e_0} = y_3$, confirming that if a measurement at zero smearing is available, it is by definition the extrapolated value. The algorithm must handle this correctly.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef extrapolate_to_zero_smearing(sigmas, values, exponents):\n    \"\"\"\n    Performs a linear regression to extrapolate an observable to zero smearing width.\n\n    The function sets up and solves a system of linear equations y = Xc, where y are\n    the observable values, X is the design matrix derived from smearing widths and\n    model exponents, and c are the model coefficients. The extrapolated value is\n    the coefficient corresponding to the zero-power term.\n\n    Args:\n        sigmas (list or np.ndarray): A sequence of smearing widths, σ.\n        values (list or np.ndarray): A sequence of corresponding observable values, y(σ).\n        exponents (list or np.ndarray): The powers of sigma to use in the polynomial model.\n\n    Returns:\n        float: The extrapolated value at σ = 0, which is the coefficient c_0.\n    \"\"\"\n    num_points = len(sigmas)\n    num_coeffs = len(exponents)\n\n    # For the problem as specified, the number of data points equals the\n    # number of model coefficients, resulting in an exactly determined system.\n    if num_points != num_coeffs:\n        raise ValueError(\n            \"The number of data points must equal the number of model parameters for this problem.\"\n        )\n\n    # Construct the design matrix X, where X[i, j] = sigmas[i]**exponents[j].\n    # In Python, 0.0**0 is correctly evaluated as 1.0.\n    X = np.zeros((num_points, num_coeffs))\n    for i in range(num_points):\n        for j in range(num_coeffs):\n            X[i, j] = sigmas[i] ** exponents[j]\n\n    # Convert the values list to a NumPy column vector for the solver.\n    y = np.array(values)\n\n    # Solve the linear system X * c = y for the coefficients c.\n    # np.linalg.solve is appropriate for square, non-singular systems.\n    coefficients = np.linalg.solve(X, y)\n\n    # The first exponent is specified as 0, so the first coefficient\n    # is the extrapolated value at sigma=0.\n    zero_smearing_value = coefficients[0]\n    \n    return zero_smearing_value\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the extrapolation for each,\n    and print the aggregated results in the specified format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Fermi-Dirac smearing\n        {\n            \"exponents\": [0, 2, 4],\n            \"sigmas\": [0.05, 0.10, 0.15],\n            \"forces\": [0.253996875, 0.26595, 0.285746875],   # eV/Angstrom\n            \"stresses\": [4.925625, 4.71, 4.376],           # GPa\n        },\n        # Case B: Marzari-Vanderbilt cold smearing\n        {\n            \"exponents\": [0, 4, 6],\n            \"sigmas\": [0.05, 0.12, 0.20],\n            \"forces\": [-0.109980015625, -0.109339433984, -0.104944],\n            \"stresses\": [-1.50012421875, -1.5039979008, -1.5288],\n        },\n        # Case C: Methfessel-Paxton smearing of order p=1\n        {\n            \"exponents\": [0, 4, 6],\n            \"sigmas\": [0.0, 0.06, 0.12],\n            \"forces\": [0.035, 0.035012983328, 0.035208852992],\n            \"stresses\": [0.25, 0.2525733376, 0.2902776064],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        # Extrapolate the force component\n        force_extrapolated = extrapolate_to_zero_smearing(\n            case[\"sigmas\"], case[\"forces\"], case[\"exponents\"]\n        )\n        results.append(force_extrapolated)\n\n        # Extrapolate the stress component\n        stress_extrapolated = extrapolate_to_zero_smearing(\n            case[\"sigmas\"], case[\"stresses\"], case[\"exponents\"]\n        )\n        results.append(stress_extrapolated)\n\n    # The final print statement must produce only the specified single-line format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}