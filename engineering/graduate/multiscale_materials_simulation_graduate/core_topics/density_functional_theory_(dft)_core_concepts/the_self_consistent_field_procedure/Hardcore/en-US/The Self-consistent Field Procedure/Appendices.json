{
    "hands_on_practices": [
        {
            "introduction": "The Hartree-Fock-Roothaan equations present a generalized eigenvalue problem, $\\mathbf{F}\\mathbf{C} = \\mathbf{S}\\mathbf{C}\\mathbf{E}$, because the atomic orbital basis functions are typically non-orthogonal. To utilize standard, efficient eigensolvers, we must first transform this into a standard eigenvalue problem. This practice focuses on symmetric orthogonalization, an elegant method for this transformation that involves constructing the matrix $\\mathbf{S}^{-1/2}$ to create an orthonormal basis . Mastering this step is fundamental to implementing any SCF code.",
            "id": "215564",
            "problem": "In the Hartree-Fock-Roothaan self-consistent field (SCF) method, the electronic structure problem is formulated as a generalized eigenvalue problem:\n$$ \\mathbf{F}\\mathbf{C} = \\mathbf{S}\\mathbf{C}\\mathbf{E} $$\nHere, $\\mathbf{F}$ is the Fock matrix, $\\mathbf{C}$ is the matrix of molecular orbital coefficients, $\\mathbf{S}$ is the overlap matrix of the non-orthogonal atomic orbital basis functions, and $\\mathbf{E}$ is a diagonal matrix of orbital energies.\n\nTo solve this equation using standard numerical algorithms for eigenvalue problems, it must first be transformed into a standard eigenvalue problem of the form $\\mathbf{F}'\\mathbf{C}' = \\mathbf{C}'\\mathbf{E}$. A common way to achieve this is via symmetric orthogonalization, also known as LÃ¶wdin orthogonalization. This method introduces a transformation matrix $\\mathbf{X} = \\mathbf{S}^{-1/2}$, which is used to transform the basis functions and the Fock matrix.\n\nConsider a simple model for a linear, symmetric triatomic molecule A-B-A described by a minimal basis set consisting of one s-type atomic orbital on each atom, denoted $\\phi_1$, $\\phi_2$, and $\\phi_3$. The overlap matrix $\\mathbf{S}$ in this basis is given by:\n$$ \\mathbf{S} = \\begin{pmatrix} 1 & s & 0 \\\\ s & 1 & s \\\\ 0 & s & 1 \\end{pmatrix} $$\nwhere $s$ is the overlap integral between adjacent atomic orbitals, and the overlap between the terminal atoms is assumed to be zero. The parameter $s$ is a real number satisfying $0 < s < 1/\\sqrt{2}$ to ensure that the overlap matrix is positive definite.\n\nYour task is to calculate the off-diagonal matrix element $X_{12}$ of the symmetric orthogonalization matrix $\\mathbf{X} = \\mathbf{S}^{-1/2}$.",
            "solution": "We wish to compute the off-diagonal element $X_{12}$ of \n\n$$\n\\mathbf X = \\mathbf S^{-1/2},\n\\qquad\n\\mathbf S = \\begin{pmatrix}1 & s & 0\\\\s & 1 & s\\\\0 & s & 1\\end{pmatrix}.\n$$\n\n1. Diagonalize $\\mathbf S$ by an orthonormal matrix $U$:\n\n$$\n\\mathbf S = U\\,\\Lambda\\,U^T,\n\\qquad\n\\Lambda = \\diag(\\lambda_1,\\lambda_2,\\lambda_3).\n$$\n\nFor a linear chain of three orbitals the eigenvalues are\n\n$$\n\\lambda_k=1+2s\\cos\\frac{k\\pi}{4},\n\\quad k=1,2,3,\n$$\n\nso\n\n$$\n\\lambda_1=1+\\sqrt2\\,s,\\quad\n\\lambda_2=1,\\quad\n\\lambda_3=1-\\sqrt2\\,s.\n$$\n\n\n2. The (unnormalized) eigenvectors have components \n\n$$\nu_{j k}=\\sin\\!\\bigl(jk\\pi/4\\bigr),\n\\quad j=1,2,3,\n$$\n\nand are normalized by\n$\\sum_{j=1}^3\\sin^2(jk\\pi/4)=2$. Hence\n\n$$\nU_{jk}=\\frac{\\sin(jk\\pi/4)}{\\sqrt2}.\n$$\n\n\n3. The symmetric orthogonalizer is\n\n$$\n\\mathbf X=\\mathbf S^{-1/2}\n=U\\,\\Lambda^{-1/2}\\,U^T,\n$$\n\nso each element\n\n$$\nX_{12}\n=\\sum_{k=1}^3U_{1k}\\,U_{2k}\\,\\frac1{\\sqrt{\\lambda_k}}.\n$$\n\nSince $U_{12}U_{22}=0$, only $k=1,3$ contribute.  We have\n\n$$\nU_{11}U_{21}\n=\\frac{\\sin(\\pi/4)\\sin(2\\pi/4)}{2}\n=\\frac{1}{2\\sqrt2},\n\\quad\nU_{13}U_{23}\n=\\frac{\\sin(3\\pi/4)\\sin(6\\pi/4)}{2}\n=-\\frac{1}{2\\sqrt2}.\n$$\n\nThus\n\n$$\nX_{12}\n=\\frac{1}{2\\sqrt2}\\Bigl(\\frac1{\\sqrt{1+\\sqrt2\\,s}}\n-\\frac1{\\sqrt{1-\\sqrt2\\,s}}\\Bigr).\n$$",
            "answer": "$$\\boxed{\\frac{1}{2\\sqrt{2}}\\Bigl(\\frac{1}{\\sqrt{1+\\sqrt{2}\\,s}}-\\frac{1}{\\sqrt{1-\\sqrt{2}\\,s}}\\Bigr)}$$"
        },
        {
            "introduction": "Solving the SCF equations is an iterative process, but simple iteration does not guarantee convergence. Depending on the system and the mixing scheme, the process can stall, oscillate, or diverge, preventing a self-consistent solution from being found. This exercise explores the dynamics of a simple mixing scheme within a minimal model, revealing how to find a mixing parameter that induces a persistent, non-convergent oscillation . Understanding these failure modes is crucial for appreciating the necessity of more robust convergence acceleration techniques.",
            "id": "2465523",
            "problem": "A closed-shell system with $2$ electrons is described in an orthonormal atomic-orbital basis $\\{\\chi_1,\\chi_2\\}$ by a $2 \\times 2$ Fock matrix functional depending on the off-diagonal density matrix element $p \\equiv P_{12}$:\n$$\nF[p] \\;=\\; \\begin{pmatrix}\n\\epsilon & -\\gamma\\, p \\\\\n-\\gamma\\, p & -\\epsilon\n\\end{pmatrix},\n$$\nwhere $\\epsilon>0$ and $\\gamma>0$ are constants. In a Self-Consistent Field (SCF) procedure, starting from a guess $p_0$, one iteration is defined as follows: given $p_n$, form $F[p_n]$, diagonalize to obtain the lowest-energy molecular orbital with normalized coefficient vector $\\mathbf{C}^{(n)} = \\big(C^{(n)}_1, C^{(n)}_2\\big)^{\\mathrm{T}}$, build the updated off-diagonal density $p_{\\mathrm{new}} = 2\\,C^{(n)}_1 C^{(n)}_2$, and apply simple linear mixing with mixing parameter $\\lambda \\in \\mathbb{R}$:\n$$\np_{n+1} \\;=\\; (1-\\lambda)\\,p_n \\;+\\; \\lambda\\, p_{\\mathrm{new}}.\n$$\nAssume $|\\gamma|>|\\epsilon|$ so that a nonzero fixed point $p^{\\ast}\\neq 0$ exists for the straight update $p\\mapsto p_{\\mathrm{new}}$. Determine the value of the mixing parameter $\\lambda$ such that the linearized simple-mixing iteration about $p^{\\ast}$ has a multiplier of $-1$, resulting in an undamped, nonconvergent oscillation of the occupied-orbital eigenvalue in successive SCF iterations. Express your final answer as a closed-form analytic expression in terms of $\\epsilon$ and $\\gamma$ only.",
            "solution": "The system is a closed-shell $2$-electron system in an orthonormal basis of two atomic orbitals, $\\{ \\chi_1, \\chi_2 \\}$. The SCF procedure is defined by the Fock matrix functional:\n$$\nF[p] = \\begin{pmatrix}\n\\epsilon & -\\gamma p \\\\\n-\\gamma p & -\\epsilon\n\\end{pmatrix}\n$$\nwhere $p$ is the off-diagonal element $P_{12}$ of the density matrix, and $\\epsilon, \\gamma$ are positive constants.\n\nAn SCF iteration consists of updating the density element $p$. First, given a density $p_n$, we define the straight update map $p_{\\mathrm{new}} = g(p_n)$. This requires diagonalizing $F[p_n]$ to find the lowest-energy (occupied) molecular orbital. The eigenvalues $\\omega$ of $F[p]$ are the roots of the characteristic equation $\\det(F[p] - \\omega I) = 0$:\n$$\n(\\epsilon - \\omega)(-\\epsilon - \\omega) - (-\\gamma p)^2 = 0\n$$\n$$\n\\omega^2 - \\epsilon^2 - \\gamma^2 p^2 = 0\n$$\nThe eigenvalues are $\\omega_{\\pm} = \\pm\\sqrt{\\epsilon^2 + \\gamma^2 p^2}$. The lowest-energy orbital corresponds to the eigenvalue $\\omega_{-} = -\\sqrt{\\epsilon^2 + \\gamma^2 p^2}$.\n\nNext, we find the corresponding normalized eigenvector $\\mathbf{C} = (C_1, C_2)^{\\mathrm{T}}$ by solving $(F[p] - \\omega_{-} I)\\mathbf{C} = \\mathbf{0}$:\n$$\n\\begin{pmatrix}\n\\epsilon - \\omega_{-} & -\\gamma p \\\\\n-\\gamma p & -\\epsilon - \\omega_{-}\n\\end{pmatrix}\n\\begin{pmatrix}\nC_1 \\\\ C_2\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0 \\\\ 0\n\\end{pmatrix}\n$$\nThe first row gives the relation $(\\epsilon - \\omega_{-})C_1 - \\gamma p C_2 = 0$. Substituting $\\omega_{-}$:\n$$\n(\\epsilon + \\sqrt{\\epsilon^2 + \\gamma^2 p^2}) C_1 = \\gamma p C_2\n$$\nThe updated density element is $p_{\\mathrm{new}} = 2 C_1 C_2$. From the relation above, we can express this product as:\n$$\np_{\\mathrm{new}} = 2 C_1 C_2 = 2 C_1^2 \\frac{\\epsilon + \\sqrt{\\epsilon^2 + \\gamma^2 p^2}}{\\gamma p}\n$$\nThe normalization condition is $C_1^2 + C_2^2 = 1$. Substituting $C_2 = \\frac{(\\epsilon + \\sqrt{\\epsilon^2 + \\gamma^2 p^2})}{\\gamma p} C_1$:\n$$\nC_1^2 \\left( 1 + \\frac{(\\epsilon + \\sqrt{\\epsilon^2 + \\gamma^2 p^2})^2}{(\\gamma p)^2} \\right) = 1\n$$\nSolving for $C_1^2$ and simplifying the expression in the parenthesis:\n$$\nC_1^2 \\frac{(\\gamma p)^2 + \\epsilon^2 + 2\\epsilon\\sqrt{\\epsilon^2 + \\gamma^2 p^2} + \\epsilon^2 + \\gamma^2 p^2}{(\\gamma p)^2} = 1\n$$\n$$\nC_1^2 \\frac{2(\\epsilon^2 + \\gamma^2 p^2) + 2\\epsilon\\sqrt{\\epsilon^2 + \\gamma^2 p^2}}{(\\gamma p)^2} = 1\n$$\n$$\nC_1^2 \\frac{2\\sqrt{\\epsilon^2 + \\gamma^2 p^2}(\\sqrt{\\epsilon^2 + \\gamma^2 p^2} + \\epsilon)}{(\\gamma p)^2} = 1\n$$\nWe can now substitute the expression for $C_1^2$ into the equation for $p_{\\mathrm{new}}$:\n$$\np_{\\mathrm{new}} = 2 \\left( \\frac{(\\gamma p)^2}{2\\sqrt{\\epsilon^2 + \\gamma^2 p^2}(\\sqrt{\\epsilon^2 + \\gamma^2 p^2} + \\epsilon)} \\right) \\frac{\\epsilon + \\sqrt{\\epsilon^2 + \\gamma^2 p^2}}{\\gamma p}\n$$\nCanceling terms yields the straight update map $g(p)$:\n$$\np_{\\mathrm{new}} = g(p) = \\frac{\\gamma p}{\\sqrt{\\epsilon^2 + \\gamma^2 p^2}}\n$$\nThe non-trivial fixed point $p^*$ of this map is found by solving $p^*=g(p^*)$ for $p^* \\neq 0$:\n$$\np^* = \\frac{\\gamma p^*}{\\sqrt{\\epsilon^2 + \\gamma^2 (p^*)^2}} \\implies 1 = \\frac{\\gamma}{\\sqrt{\\epsilon^2 + \\gamma^2 (p^*)^2}}\n$$\n$$\n\\sqrt{\\epsilon^2 + \\gamma^2 (p^*)^2} = \\gamma \\implies \\epsilon^2 + \\gamma^2 (p^*)^2 = \\gamma^2\n$$\nThis gives $(p^*)^2 = \\frac{\\gamma^2 - \\epsilon^2}{\\gamma^2}$. The existence of a real, non-zero $p^*$ is guaranteed by the given condition $\\gamma > \\epsilon$. Let's choose the positive root $p^* = \\frac{\\sqrt{\\gamma^2 - \\epsilon^2}}{\\gamma}$.\n\nThe full SCF iteration with simple linear mixing is given by the map $h(p)$:\n$$\np_{n+1} = h(p_n) = (1-\\lambda) p_n + \\lambda g(p_n)\n$$\nThe convergence behavior near the fixed point $p^*$ is determined by the multiplier, which is the derivative $h'(p^*)$.\n$$\nh'(p) = \\frac{d}{dp} \\left[ (1-\\lambda) p + \\lambda g(p) \\right] = 1-\\lambda + \\lambda g'(p)\n$$\nWe must compute the derivative of $g(p)$:\n$$\ng'(p) = \\frac{d}{dp} \\left( \\frac{\\gamma p}{(\\epsilon^2 + \\gamma^2 p^2)^{1/2}} \\right)\n$$\nUsing the quotient rule, we find:\n$$\ng'(p) = \\frac{\\gamma(\\epsilon^2 + \\gamma^2 p^2)^{1/2} - \\gamma p \\cdot \\frac{1}{2}(\\epsilon^2 + \\gamma^2 p^2)^{-1/2}(2\\gamma^2 p)}{\\epsilon^2 + \\gamma^2 p^2}\n$$\n$$\ng'(p) = \\frac{\\gamma(\\epsilon^2 + \\gamma^2 p^2) - \\gamma^3 p^2}{(\\epsilon^2 + \\gamma^2 p^2)^{3/2}} = \\frac{\\gamma\\epsilon^2}{(\\epsilon^2 + \\gamma^2 p^2)^{3/2}}\n$$\nNow, we evaluate this derivative at the fixed point $p^*$. At $p^*$, we have the relation $\\epsilon^2 + \\gamma^2 (p^*)^2 = \\gamma^2$.\n$$\ng'(p^*) = \\frac{\\gamma\\epsilon^2}{(\\gamma^2)^{3/2}} = \\frac{\\gamma\\epsilon^2}{\\gamma^3} = \\frac{\\epsilon^2}{\\gamma^2}\n$$\nThe multiplier of the mixed iteration at the fixed point is:\n$$\nh'(p^*) = 1 - \\lambda + \\lambda g'(p^*) = 1 - \\lambda + \\lambda \\frac{\\epsilon^2}{\\gamma^2}\n$$\nThe problem requires finding $\\lambda$ such that the iteration has a multiplier of $-1$, which corresponds to undamped oscillation.\n$$\nh'(p^*) = -1\n$$\n$$\n1 - \\lambda + \\lambda \\frac{\\epsilon^2}{\\gamma^2} = -1\n$$\nWe solve this equation for $\\lambda$:\n$$\n2 = \\lambda - \\lambda \\frac{\\epsilon^2}{\\gamma^2}\n$$\n$$\n2 = \\lambda \\left( 1 - \\frac{\\epsilon^2}{\\gamma^2} \\right)\n$$\n$$\n2 = \\lambda \\left( \\frac{\\gamma^2 - \\epsilon^2}{\\gamma^2} \\right)\n$$\n$$\n\\lambda = \\frac{2\\gamma^2}{\\gamma^2 - \\epsilon^2}\n$$\nThis is the value of the mixing parameter $\\lambda$ that results in a multiplier of $-1$ for the linearized iteration around the non-trivial fixed point $p^*$.",
            "answer": "$$ \\boxed{\\frac{2\\gamma^2}{\\gamma^2 - \\epsilon^2}} $$"
        },
        {
            "introduction": "To overcome the convergence issues seen with simple mixing, modern SCF programs employ acceleration techniques like the Direct Inversion in the Iterative Subspace (DIIS) method. DIIS intelligently uses information from a subspace of previous iterations to extrapolate a much better guess for the next Fock matrix, dramatically speeding up or enabling convergence where simpler methods fail. This problem provides a hands-on calculation of a DIIS-extrapolated Fock matrix, demonstrating how to combine previous steps to minimize the error and guide the calculation towards self-consistency .",
            "id": "215588",
            "problem": "In the context of the Hartree-Fock Self-Consistent Field (SCF) procedure, the Direct Inversion in the Iterative Subspace (DIIS) method is a powerful technique for accelerating convergence. The core idea is to find an optimal Fock matrix for the next iteration, $F_{DIIS}$, by forming a linear combination of Fock matrices from $m$ previous iterations:\n$$ F_{DIIS} = \\sum_{i=1}^{m} c_i F^{(i)} $$\nThe coefficients $c_i$ are determined by minimizing the norm of a corresponding linear combination of error vectors, $e^{(i)}$, subject to the constraint that the coefficients sum to one, $\\sum_i c_i = 1$. The error vector for a given iteration is typically constructed from the commutator of the Fock matrix $F$ and the density matrix $D$ in an orthonormal basis, $e = [F, D] = FD - DF$.\n\nThis constrained minimization leads to a system of linear equations for the coefficients $c_i$ and a Lagrange multiplier $\\lambda$:\n$$ \\begin{pmatrix}\nB_{11} & \\dots & B_{1m} & -1 \\\\\n\\vdots & \\ddots & \\vdots & \\vdots \\\\\nB_{m1} & \\dots & B_{mm} & -1 \\\\\n-1 & \\dots & -1 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\nc_1 \\\\\n\\vdots \\\\\nc_m \\\\\n\\lambda\n\\end{pmatrix} =\n\\begin{pmatrix}\n0 \\\\\n\\vdots \\\\\n0 \\\\\n-1\n\\end{pmatrix}\n$$\nwhere the matrix elements $B_{ij}$ are given by the trace of the product of error vectors: $B_{ij} = \\text{Tr}(e^{(i)\\dagger} e^{(j)})$.\n\nConsider an SCF calculation for a three-level system described in an orthonormal basis. After two iterations, we have the following real, symmetric Fock matrices:\n$$ F^{(1)} = \\begin{pmatrix} A & D & 0 \\\\ D & B & E \\\\ 0 & E & C \\end{pmatrix}, \\quad F^{(2)} = \\begin{pmatrix} A' & D' & 0 \\\\ D' & B' & E' \\\\ 0 & E' & C' \\end{pmatrix} $$\nThe corresponding real, anti-symmetric error vectors are given by:\n$$ e^{(1)} = \\begin{pmatrix} 0 & \\alpha & 0 \\\\ -\\alpha & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}, \\quad e^{(2)} = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 0 & \\beta \\\\ 0 & -\\beta & 0 \\end{pmatrix} $$\nwhere $\\alpha$ and $\\beta$ are non-zero real constants.\n\nUsing the two most recent iterations (i.e., $m=2$), calculate the DIIS-extrapolated Fock matrix $F_{DIIS}$. Express your answer as a single matrix whose elements are in terms of the given symbolic constants.",
            "solution": "1. Define the Frobenius inner products\n$$B_{ij} = \\sum_{m,n} e^{(i)}_{mn}\\,e^{(j)}_{mn}\\,. $$\n\n2. Compute the nonzero entries of the error matrices:\ne^{(1)} has entries $e^{(1)}_{12}=\\alpha,\\;e^{(1)}_{21}=-\\alpha$, so\n$$B_{11} = \\alpha^2 + (-\\alpha)^2 = 2\\alpha^2\\,. $$\ne^{(2)} has entries $e^{(2)}_{23}=\\beta,\\;e^{(2)}_{32}=-\\beta$, so\n$$B_{22} = \\beta^2 + (-\\beta)^2 = 2\\beta^2\\,. $$\nThere is no overlap of nonzero entries between $e^{(1)}$ and $e^{(2)}$, hence\n$$B_{12}=B_{21}=0\\,. $$\n\n3. The DIIS linear system for $m=2$ is\n$$\n\\begin{pmatrix}\n2\\alpha^2 & 0 & -1\\\\\n0 & 2\\beta^2 & -1\\\\\n-1 & -1 & 0\n\\end{pmatrix}\n\\begin{pmatrix}c_1\\\\c_2\\\\\\lambda\\end{pmatrix}\n=\n\\begin{pmatrix}0\\\\0\\\\-1\\end{pmatrix}.\n$$\nThis yields the equations\n\n$$\n2\\alpha^2\\,c_1 \\;=\\;\\lambda,\\quad\n2\\beta^2\\,c_2 \\;=\\;\\lambda,\\quad\nc_1+c_2=1.\n$$\n\n4. Solve for $\\lambda$ and the coefficients:\n\n$$\nc_1 = \\frac{\\lambda}{2\\alpha^2},\\quad\nc_2 = \\frac{\\lambda}{2\\beta^2},\\quad\n\\frac{\\lambda}{2\\alpha^2} + \\frac{\\lambda}{2\\beta^2} =1\n\\;\\Longrightarrow\\;\n\\lambda = \\frac{2\\alpha^2\\beta^2}{\\alpha^2+\\beta^2}.\n$$\n\nHence\n\n$$\nc_1 = \\frac{\\beta^2}{\\alpha^2+\\beta^2},\\qquad\nc_2 = \\frac{\\alpha^2}{\\alpha^2+\\beta^2}.\n$$\n\n\n5. Form the DIIS-extrapolated Fock matrix\n$$\nF_{DIIS} = c_1\\,F^{(1)} + c_2\\,F^{(2)}\n= \\frac{1}{\\alpha^2+\\beta^2}\n\\Bigl(\\beta^2\\,F^{(1)} + \\alpha^2\\,F^{(2)}\\Bigr).\n$$\nExpanding,\n\n$$\nF_{DIIS} = \\frac{1}{\\alpha^2+\\beta^2}\n\\begin{pmatrix}\n\\beta^2 A + \\alpha^2 A' & \\beta^2 D + \\alpha^2 D' & 0\\\\\n\\beta^2 D + \\alpha^2 D' & \\beta^2 B + \\alpha^2 B' & \\beta^2 E + \\alpha^2 E'\\\\\n0 & \\beta^2 E + \\alpha^2 E' & \\beta^2 C + \\alpha^2 C'\n\\end{pmatrix}.\n$$",
            "answer": "$$\n\\boxed{\nF_{DIIS}\n=\\frac{1}{\\alpha^2+\\beta^2}\n\\begin{pmatrix}\n\\beta^2 A + \\alpha^2 A' & \\beta^2 D + \\alpha^2 D' & 0\\\\\n\\beta^2 D + \\alpha^2 D' & \\beta^2 B + \\alpha^2 B' & \\beta^2 E + \\alpha^2 E'\\\\\n0 & \\beta^2 E + \\alpha^2 E' & \\beta^2 C + \\alpha^2 C'\n\\end{pmatrix}\n}\n$$"
        }
    ]
}