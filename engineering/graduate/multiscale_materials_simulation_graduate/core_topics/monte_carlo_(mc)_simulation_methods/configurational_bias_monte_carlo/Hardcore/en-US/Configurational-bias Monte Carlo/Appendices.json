{
    "hands_on_practices": [
        {
            "introduction": "The effectiveness of a Configurational-Bias Monte Carlo move hinges on the intelligent selection of trial configurations based on their energetic favorability. This practice challenges you to define the precise \"local energy\" used to calculate the Boltzmann-like weights for these trials. By correctly identifying all relevant bonded and non-bonded energy contributions that depend on a new segment's placement, you will solidify your understanding of the physical basis for the CBMC biasing scheme .",
            "id": "3797247",
            "problem": "A linear polymer is simulated at fixed temperature $T$ using Configurational-Bias Monte Carlo (CBMC). The intramolecular energy is composed of bonded terms $u_{\\text{bond}}(r)$, $u_{\\text{angle}}(\\theta)$, and $u_{\\text{dihedral}}(\\phi)$ that depend on bond lengths $r$, bond angles $\\theta$, and dihedral angles $\\phi$, respectively, plus nonbonded interactions $u_{\\text{nb}}(r)$ that act between pairs of sites not otherwise bonded. The nonbonded potential is pairwise additive, truncated and shifted at a cutoff $r_c$ so that $u_{\\text{nb}}(r\\ge r_c)=0$, and neighbor lists are maintained so that only pairs within $r_c$ are considered.\n\nIn a regrowth step, a single new site $i$ is attached to site $i-1$, and $k$ trial conformations $\\{\\mathbf{q}_\\ell\\}_{\\ell=1}^k$ are generated for the local degrees of freedom that determine $r_{i,i-1}$, $\\theta_{i,i-1,i-2}$, $\\phi_{i,i-1,i-2,i-3}$, and the distances $r_{ij}$ between the new site $i$ and surrounding sites $j$. CBMC chooses one of the $k$ trials with a probability proportional to a Boltzmann factor of a local energy $U_{\\text{loc}}(\\mathbf{q}_\\ell)$, and uses the corresponding Rosenbluth weight to ensure detailed balance in the canonical ensemble.\n\nStarting from the canonical distribution $p(\\mathbf{x}) \\propto \\exp(-\\beta U(\\mathbf{x}))$ with $\\beta = 1/(k_{\\text{B}} T)$, and the definition of detailed balance for trial selection, identify which expression correctly specifies the local energy $U_{\\text{loc}}$ to be used in the trial weights for this regrowth step, and which justification correctly explains why distant interactions can be neglected under neighbor lists in this context. Assume a standard force-field convention in which nonbonded interactions excluded by bonding topology (such as $1$-$2$ and $1$-$3$ pairs) are not included in $u_{\\text{nb}}$, and that any $1$-$4$ scaling is already built into $u_{\\text{dihedral}}$ or $u_{\\text{nb}}$ as appropriate.\n\nChoose the single best option.\n\nA. $U_{\\text{loc}}$ equals the sum of the bonded contributions for the newly formed local geometry, $u_{\\text{bond}}(r_{i,i-1}) + u_{\\text{angle}}(\\theta_{i,i-1,i-2}) + u_{\\text{dihedral}}(\\phi_{i,i-1,i-2,i-3})$, plus the sum of nonbonded interactions between the new site $i$ and all sites $j$ in its neighbor list within the cutoff, $\\sum_{j \\in \\mathcal{N}(i)} u_{\\text{nb}}(r_{ij})$. Distant interactions can be neglected because the truncated-and-shifted $u_{\\text{nb}}$ is exactly zero for $r \\ge r_c$, so contributions from pairs beyond $r_c$ are independent of the trial and cancel in the relative trial probabilities.\n\nB. $U_{\\text{loc}}$ includes only bonded terms $u_{\\text{bond}}(r_{i,i-1}) + u_{\\text{angle}}(\\theta_{i,i-1,i-2}) + u_{\\text{dihedral}}(\\phi_{i,i-1,i-2,i-3})$, while nonbonded terms are excluded because neighbor lists already reduce computational cost and nonbonded interactions are independent of the chosen trial conformation.\n\nC. $U_{\\text{loc}}$ is the full-system energy difference $U_{\\text{after}} - U_{\\text{before}}$, summing all bonded and nonbonded interactions in the polymer, because detailed balance requires accounting for long-range electrostatics even when neighbor lists are used; distant interactions must be included.\n\nD. $U_{\\text{loc}}$ is the sum of bonded and nonbonded interactions of the new site $i$ with all atoms in the system, $\\sum_{j} u_{\\text{nb}}(r_{ij})$ without any cutoff, because truncation of pair potentials would violate detailed balance; therefore, interactions beyond $r_c$ cannot be neglected.\n\nE. $U_{\\text{loc}}$ equals the bonded terms plus nonbonded interactions with neighbor-list partners, but a mean-field background energy density must be subtracted to compensate for neglected distant atoms; this mean-field correction is necessary to preserve unbiased trial selection.",
            "solution": "The problem statement is submitted to validation.\n\n**Step 1: Extract Givens**\n- **Simulation Method:** Configurational-Bias Monte Carlo (CBMC) at fixed temperature $T$.\n- **System:** A linear polymer.\n- **Ensemble:** Canonical, with probability distribution $p(\\mathbf{x}) \\propto \\exp(-\\beta U(\\mathbf{x}))$, where $\\beta = 1/(k_{\\text{B}} T)$.\n- **Intramolecular Potential:** Composed of bonded terms: $u_{\\text{bond}}(r)$, $u_{\\text{angle}}(\\theta)$, and $u_{\\text{dihedral}}(\\phi)$.\n- **Nonbonded Potential:** $u_{\\text{nb}}(r)$, pairwise additive, truncated and shifted such that $u_{\\text{nb}}(r \\ge r_c) = 0$.\n- **Computational Details:** Neighbor lists are used to consider pairs within the cutoff $r_c$.\n- **CBMC Move:** A regrowth step where a new site $i$ is attached to site $i-1$.\n- **Trial Generation:** $k$ trial conformations $\\{\\mathbf{q}_\\ell\\}_{\\ell=1}^k$ are generated for the local degrees of freedom ($r_{i,i-1}$, $\\theta_{i,i-1,i-2}$, $\\phi_{i,i-1,i-2,i-3}$).\n- **Trial Selection:** One trial $\\ell$ is chosen with probability proportional to a Boltzmann-like weight, $\\exp(-\\beta U_{\\text{loc}}(\\mathbf{q}_\\ell))$.\n- **Detailed Balance:** The overall procedure uses a Rosenbluth weight to satisfy detailed balance.\n- **Force-Field Convention:** Nonbonded interactions are excluded for $1$-$2$ and $1$-$3$ pairs.\n- **Question:** Identify the correct expression for the local energy $U_{\\text{loc}}$ used in the trial weights and the correct justification for neglecting distant interactions.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem describes the standard CBMC algorithm applied to polymer chains, a cornerstone technique in molecular simulation. The use of bonded and nonbonded potentials, potential truncation, neighbor lists, and the concepts of Rosenbluth weights and detailed balance are all fundamental and correctly represented.\n- **Well-Posed:** The question asks for the definition of a specific term, $U_{\\text{loc}}$, within the CBMC algorithm under the specified conditions. This is a clearly defined question with a unique and meaningful answer derivable from the principles of statistical mechanics.\n- **Objective:** The problem is stated in precise, technical language common to the field of computational physics and chemistry. There are no subjective or ambiguous terms.\n\n**Step 3: Verdict and Action**\nThe problem statement is scientifically sound, well-posed, and objective. It is a valid problem. The solution process may proceed.\n\n**Derivation of the Solution**\n\nThe objective of a Monte Carlo simulation in the canonical ensemble is to generate a sequence of configurations $\\mathbf{x}$ such that their probability of occurrence follows the Boltzmann distribution, $p(\\mathbf{x}) \\propto \\exp(-\\beta U(\\mathbf{x}))$. This is achieved by constructing moves that satisfy the detailed balance condition.\n\nThe Configurational-Bias Monte Carlo (CBMC) method is an advanced technique that enhances sampling efficiency, particularly for chain molecules. In a regrowth step, rather than generating a single random trial position for a new site and accepting or rejecting it, CBMC generates a set of $k$ trial positions and intelligently selects one.\n\nLet the state of the system before adding site $i$ be $\\mathbf{x}_{\\text{old}}$, with total energy $U(\\mathbf{x}_{\\text{old}})$. A new site $i$ is to be grown from site $i-1$. For each of the $k$ trial conformations, $\\mathbf{q}_\\ell$, which define the position $\\mathbf{r}_i^{(\\ell)}$ of the new site, a corresponding \"new\" system configuration $\\mathbf{x}_{\\text{new}}^{(\\ell)}$ is defined. The total energy of this new configuration would be $U(\\mathbf{x}_{\\text{new}}^{(\\ell)})$.\n\nThe energy change upon adding site $i$ in trial conformation $\\ell$ is:\n$$\n\\Delta U^{(\\ell)} = U(\\mathbf{x}_{\\text{new}}^{(\\ell)}) - U(\\mathbf{x}_{\\text{old}})\n$$\nThis energy change can be attributed entirely to the interactions involving the newly added site $i$. It comprises the new intramolecular (bonded) interactions and the new nonbonded interactions of site $i$ with all other sites $j$ in the system.\n$$\n\\Delta U^{(\\ell)} = \\left[ u_{\\text{bond}}(r_{i,i-1}^{(\\ell)}) + u_{\\text{angle}}(\\theta_{i,i-1,i-2}^{(\\ell)}) + u_{\\text{dihedral}}(\\phi_{i,i-1,i-2,i-3}^{(\\ell)}) \\right] + \\sum_{j} u_{\\text{nb}}(r_{ij}^{(\\ell)})\n$$\nThe sum over $j$ includes all other sites in the system with which site $i$ has a nonbonded interaction, according to the force-field rules (e.g., excluding sites $i-1$, $i-2$, $i-3$).\n\nIn CBMC, we bias the selection of the trial conformation. Instead of choosing one of the $k$ trials uniformly, we select trial $\\ell$ with a probability $P_{\\text{select}}(\\ell)$ that is proportional to a weight $w_\\ell$. To improve sampling, this weight is chosen to favor low-energy conformations. The standard choice is a Boltzmann factor of some \"local energy\" $U_{\\text{loc}}(\\mathbf{q}_\\ell)$:\n$$\nw_\\ell = \\exp(-\\beta U_{\\text{loc}}(\\mathbf{q}_\\ell))\n$$\nThe probability of selecting trial $\\ell$ is then:\n$$\nP_{\\text{select}}(\\ell) = \\frac{w_\\ell}{\\sum_{m=1}^k w_m} = \\frac{\\exp(-\\beta U_{\\text{loc}}(\\mathbf{q}_\\ell))}{\\sum_{m=1}^k \\exp(-\\beta U_{\\text{loc}}(\\mathbf{q}_m))}\n$$\nThe term $W = \\sum_{m=1}^k w_m$ is the Rosenbluth factor, which is used in the final acceptance step to correct for the bias introduced in this selection step, thereby ensuring detailed balance is globally satisfied.\n\nThe crucial question is the definition of $U_{\\text{loc}}$. To make the biasing effective, $U_{\\text{loc}}$ should include all the energy terms that depend on the specific trial position of site $i$. This is precisely the total energy change $\\Delta U^{(\\ell)}$ calculated above. Any energy term not involving site $i$ is constant with respect to the choice of trial $\\ell$ and would cancel out from the relative probabilities $w_\\ell/w_m$. Therefore, the ideal choice for the local energy is the interaction energy of the new particle with the rest of the system.\n$$\nU_{\\text{loc}}(\\mathbf{q}_\\ell) = \\left[ u_{\\text{bond}}(r_{i,i-1}^{(\\ell)}) + u_{\\text{angle}}(\\theta_{i,i-1,i-2}^{(\\ell)}) + u_{\\text{dihedral}}(\\phi_{i,i-1,i-2,i-3}^{(\\ell)}) \\right] + \\sum_{j} u_{\\text{nb}}(r_{ij}^{(\\ell)})\n$$\nNow, we must consider the nature of the nonbonded potential $u_{\\text{nb}}(r)$. The problem states it is truncated and shifted, so $u_{\\text{nb}}(r \\ge r_c) = 0$. This has a critical consequence for the summation $\\sum_{j} u_{\\text{nb}}(r_{ij}^{(\\ell)})$. Any term for which the distance $r_{ij}^{(\\ell)}$ is greater than or equal to the cutoff $r_c$ contributes exactly zero to the sum. Thus, the sum can be restricted to sites $j$ for which $r_{ij}^{(\\ell)} < r_c$ without any loss of accuracy.\n$$\n\\sum_{j} u_{\\text{nb}}(r_{ij}^{(\\ell)}) = \\sum_{j \\text{ where } r_{ij}^{(\\ell)} < r_c} u_{\\text{nb}}(r_{ij}^{(\\ell)})\n$$\nThis is precisely where neighbor lists are useful; they provide a pre-compiled list of particles that are potentially within the cutoff radius of a given region, drastically reducing the computational cost of finding these interacting pairs.\n\nTherefore, the appropriate local energy $U_{\\text{loc}}$ consists of the new bonded energy terms plus the sum of nonbonded interactions between the new site $i$ and all other sites $j$ within the cutoff distance $r_c$. The neglect of interactions with distant atoms (beyond $r_c$) is not an approximation for this potential model; it is an exact result of the potential being defined as zero for $r \\ge r_c$.\n\n**Evaluation of Options**\n\n**A. $U_{\\text{loc}}$ equals the sum of the bonded contributions for the newly formed local geometry, $u_{\\text{bond}}(r_{i,i-1}) + u_{\\text{angle}}(\\theta_{i,i-1,i-2}) + u_{\\text{dihedral}}(\\phi_{i,i-1,i-2,i-3})$, plus the sum of nonbonded interactions between the new site $i$ and all sites $j$ in its neighbor list within the cutoff, $\\sum_{j \\in \\mathcal{N}(i)} u_{\\text{nb}}(r_{ij})$. Distant interactions can be neglected because the truncated-and-shifted $u_{\\text{nb}}$ is exactly zero for $r \\ge r_c$, so contributions from pairs beyond $r_c$ are independent of the trial and cancel in the relative trial probabilities.**\n- The expression for $U_{\\text{loc}}$ is correct. It includes all the new bonded and nonbonded interactions that depend on the trial position of site $i$, considering the cutoff.\n- The justification is correct. For a truncated potential, interactions beyond the cutoff are strictly zero, not merely neglected or approximated. This means their contribution to the energy is zero, and they do not affect the relative probabilities of the trials.\n- **Verdict: Correct.**\n\n**B. $U_{\\text{loc}}$ includes only bonded terms $u_{\\text{bond}}(r_{i,i-1}) + u_{\\text{angle}}(\\theta_{i,i-1,i-2}) + u_{\\text{dihedral}}(\\phi_{i,i-1,i-2,i-3})$, while nonbonded terms are excluded because neighbor lists already reduce computational cost and nonbonded interactions are independent of the chosen trial conformation.**\n- The expression for $U_{\\text{loc}}$ is incorrect. A key purpose of CBMC is to avoid generating trial positions with severe steric clashes, which arise from nonbonded interactions. Excluding these from the biasing energy $U_{\\text{loc}}$ would defeat this purpose and make the algorithm highly inefficient.\n- The justification is incorrect on two counts. First, while neighbor lists reduce cost, that is not a reason to omit nonbonded energies from the bias. Second, the nonbonded interaction energy $u_{\\text{nb}}(r_{ij})$ is strongly dependent on the trial conformation, as the distance $r_{ij}$ changes with the choice of trial.\n- **Verdict: Incorrect.**\n\n**C. $U_{\\text{loc}}$ is the full-system energy difference $U_{\\text{after}} - U_{\\text{before}}$, summing all bonded and nonbonded interactions in the polymer, because detailed balance requires accounting for long-range electrostatics even when neighbor lists are used; distant interactions must be included.**\n- The expression for $U_{\\text{loc}}$ is subtly confused. While $U_{\\text{loc}}$ should be equal to the change in system energy for the chosen trial, $\\Delta U^{(\\ell)}$, the phrasing \"full-system energy difference\" is ambiguous. More importantly, the justification is incorrect. The problem explicitly states a truncated-and-shifted potential is used, which has no long-range component by definition. Mentioning \"long-range electrostatics\" contradicts the given potential form.\n- **Verdict: Incorrect.**\n\n**D. $U_{\\text{loc}}$ is the sum of bonded and nonbonded interactions of the new site $i$ with all atoms in the system, $\\sum_{j} u_{\\text{nb}}(r_{ij})$ without any cutoff, because truncation of pair potentials would violate detailed balance; therefore, interactions beyond $r_c$ cannot be neglected.**\n- The justification is fundamentally incorrect. The use of a truncated potential does not violate detailed balance. A Monte Carlo simulation can perfectly satisfy detailed balance for *any* well-defined potential energy function $U(\\mathbf{x})$. Truncating the potential simply defines a new energy function and thus a new physical model. The simulation correctly samples the ensemble for this new model.\n- Because the justification is false, the conclusion to not use a cutoff is also based on a false premise (within the context of simulating the truncated model).\n- **Verdict: Incorrect.**\n\n**E. $U_{\\text{loc}}$ equals the bonded terms plus nonbonded interactions with neighbor-list partners, but a mean-field background energy density must be subtracted to compensate for neglected distant atoms; this mean-field correction is necessary to preserve unbiased trial selection.**\n- The inclusion of a mean-field correction in the microscopic energy calculation for an MC move is incorrect. Such corrections (tail corrections) are sometimes applied to ensemble averages of observables (like total energy or pressure) to estimate the properties of a system with a non-truncated potential, based on a simulation using a truncated one. They are not part of the potential energy $U(\\mathbf{x})$ used to generate and accept configurations. Furthermore, since the model is defined by the truncated potential, no compensation is needed.\n- The justification is also incorrect. The trial selection is inherently *biased*; the Rosenbluth factor in the acceptance step is what ensures the overall move is correct (unbiased in the long run). The mean-field term is not related to this process.\n- **Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "When regrowing a polymer segment of multiple beads, it is crucial to compute the *incremental* energy change at each step, not the total energy of the already-grown portion. This practice addresses a common implementation pitfall where interactions within the regrown segment are inadvertently double-counted, violating the principles of energy calculation. By analyzing the mathematical effect of this error on the Rosenbluth weight, you will develop a deeper appreciation for the meticulous book-keeping required for a correct CBMC implementation .",
            "id": "3745218",
            "problem": "In Configurational Bias Monte Carlo (CBMC), a contiguous segment of a polymer chain of length $S$ is regrown bead-by-bead, and at each growth step $i \\in \\{1,\\dots,S\\}$ a set of $K$ trial placements indexed by $j \\in \\{1,\\dots,K\\}$ is generated. For each trial $j$ at step $i$, the incremental energy change $\\Delta U_i^{(j)}$ is evaluated and used to bias the selection among the $K$ trials at that step. The system is sampled in the canonical ensemble, so the probability density of a microscopic state with energy $U$ is proportional to $\\exp(-\\beta U)$, where $\\beta = 1/(k_{\\mathrm{B}} T)$ is the inverse thermal energy. The set of already placed regrown beads at step $i$ is $\\{1,\\dots,i-1\\}$, and the rest of the system (the nonregrown portion of the chain and any external field) is the environment. Let $u_{\\mathrm{nb}}(p,q)$ denote the nonbonded pair interaction between beads $p$ and $q$ within the regrown segment, and let the bonding terms that depend on bead $i$ be included in the incremental energy. A common implementation pitfall is to compute $\\Delta U_i^{(j)}$ by summing all nonbonded interactions among the beads $\\{1,\\dots,i\\}$ within the regrown segment at every step, rather than restricting to the new interactions introduced by placing bead $i$, thereby double-counting nonbonded interactions internal to the regrown segment across steps.\n\nWhich option correctly identifies the error, states the correct form of the incremental energy to avoid double-counting, and expresses the resulting impact of the bug on the Rosenbluth weight $W$ for the regrowth of $S$ beads?\n\nA. The incremental energy at step $i$ must include only interactions introduced by adding bead $i$: bonding terms that depend on bead $i$, nonbonded interactions between bead $i$ and the already placed regrown beads $\\{1,\\dots,i-1\\}$, and nonbonded interactions between bead $i$ and the environment; it must exclude nonbonded interactions among the previously placed beads $\\{1,\\dots,i-1\\}$ because those do not depend on trial $j$. If the buggy implementation adds the constant $$U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1) \\equiv \\sum_{1 \\le m  n \\le i-1} u_{\\mathrm{nb}}(m,n)$$ to every $\\Delta U_i^{(j)}$, then the per-step normalization factor is multiplied by $\\exp(-\\beta U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1))$, and the full Rosenbluth weight is $$W_{\\mathrm{bug}} = \\left[\\prod_{i=1}^{S} e^{-\\beta U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1)}\\right] \\, W_{\\mathrm{true}},$$ which biases acceptance unless corrected.\n\nB. Because adding the same constant to all $\\Delta U_i^{(j)}$ at a given step $i$ does not change the normalized trial-selection probabilities, the bug cancels exactly at each step, giving $$W_{\\mathrm{bug}} = W_{\\mathrm{true}},$$ so acceptance is unaffected.\n\nC. To correct double-counting, one should divide $\\Delta U_i^{(j)}$ by $i$ at each step to reweight the repeated interactions; under the buggy implementation, the Rosenbluth weight becomes the geometric mean of the true weights: $$W_{\\mathrm{bug}} = \\left(W_{\\mathrm{true}}\\right)^{1/S}.$$\n\nD. To preserve detailed balance, interactions among previously placed beads must be counted twice (once when each of the two beads is placed), so the correct incremental energy includes all nonbonded interactions within $\\{1,\\dots,i\\}$; the resulting Rosenbluth weight under the buggy implementation is $$W_{\\mathrm{bug}} = \\left(W_{\\mathrm{true}}\\right)^{2}.$$",
            "solution": "The problem statement describes a common implementation error in the Configurational Bias Monte Carlo (CBMC) algorithm for regrowing a polymer segment. I shall first validate the problem statement and then proceed to a full solution, including an analysis of each option.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n-   **Algorithm**: Configurational Bias Monte Carlo (CBMC).\n-   **Ensemble**: Canonical ensemble, with probability density proportional to $\\exp(-\\beta U)$, where $\\beta = 1/(k_{\\mathrm{B}} T)$.\n-   **Process**: A contiguous polymer segment of length $S$ is regrown bead-by-bead.\n-   **Growth Step**: For each step $i \\in \\{1,\\dots,S\\}$, $K$ trial placements (indexed by $j \\in \\{1,\\dots,K\\}$) are generated for the new bead $i$.\n-   **Incremental Energy**: For each trial $j$ at step $i$, an incremental energy change $\\Delta U_i^{(j)}$ is evaluated.\n-   **Definitions**:\n    -   Set of already placed regrown beads at step $i$: $\\{1,\\dots,i-1\\}$.\n    -   $u_{\\mathrm{nb}}(p,q)$: nonbonded pair interaction between beads $p$ and $q$.\n    -   Bonding terms dependent on bead $i$ are included in $\\Delta U_i^{(j)}$.\n-   **The Bug**: A common pitfall is described where $\\Delta U_i^{(j)}$ is computed by \"summing all nonbonded interactions among the beads $\\{1,\\dots,i\\}$\". This leads to double-counting.\n-   **Question**: The task is to identify the option that correctly states the error, the correct form of the incremental energy, and the resulting impact on the Rosenbluth weight $W$.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded**: The problem is well-grounded in the field of statistical mechanics and computational simulation. CBMC is a standard and widely used algorithm. The description of the algorithm, the canonical ensemble, energy terms, and the Rosenbluth weight are all consistent with established principles. The described bug is a realistic and conceptually important implementation error.\n-   **Well-Posed**: The problem is well-posed. It defines a specific algorithm and a specific, well-described error. The question asks for a derivable consequence of this error on a key quantity (the Rosenbluth weight). This structure allows for a unique and meaningful solution.\n-   **Objective**: The language is technical, precise, and objective. It avoids any ambiguity or subjective statements.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It is scientifically sound, well-posed, and objective. I will now proceed with the derivation of the solution.\n\n**Derivation**\n\nThe core of the CBMC method is the biased growth of a molecular chain, where the bias is removed exactly through a correction factor known as the Rosenbluth weight, $W$. This ensures that the algorithm correctly samples from the desired statistical ensemble (in this case, the canonical ensemble).\n\n**1. Correct Formulation**\nAt each growth step $i$, we are placing bead $i$ given that beads $\\{1, \\dots, i-1\\}$ have already been placed. The incremental energy change, $\\Delta U_{i, \\mathrm{true}}^{(j)}$, for a trial placement $j$ of bead $i$, must represent the change in the total system energy upon the addition of bead $i$. This change consists of:\n-   All bonding interactions involving bead $i$ (e.g., bond, angle, dihedral terms).\n-   All nonbonded interactions between bead $i$ and all other particles in the system. These other particles can be divided into two groups:\n    1.  The beads of the segment that have already been placed: $\\{1, \\dots, i-1\\}$.\n    2.  All other particles in the system, which we can call the \"environment\".\n\nTherefore, the correct incremental energy for trial $j$ at step $i$ is:\n$$ \\Delta U_{i, \\mathrm{true}}^{(j)} = U_{\\mathrm{bond}}^{(j)}(i) + \\sum_{m=1}^{i-1} u_{\\mathrm{nb}}(i^{(j)}, m) + U_{\\mathrm{env}}^{(j)}(i) $$\nwhere $U_{\\mathrm{bond}}^{(j)}(i)$ represents bonding terms involving bead $i$'s trial position, the summation is the nonbonded energy with previously placed beads of the segment, and $U_{\\mathrm{env}}^{(j)}(i)$ is the nonbonded energy with the environment. Interactions among the beads $\\{1, \\dots, i-1\\}$ are *not* included, as their energy contribution was accounted for in previous steps and does not change with the trial placement of bead $i$.\n\nThe one-step Rosenbluth factor at step $i$ is the sum of Boltzmann factors over all $K$ trials:\n$$ w_{i, \\mathrm{true}} = \\sum_{j=1}^{K} \\exp\\left(-\\beta \\Delta U_{i, \\mathrm{true}}^{(j)}\\right) $$\nThe total Rosenbluth weight for the $S$-bead segment is the product of these one-step factors:\n$$ W_{\\mathrm{true}} = \\prod_{i=1}^{S} w_{i, \\mathrm{true}} $$\n\n**2. Analysis of the Buggy Implementation**\nThe problem states the bug is to compute $\\Delta U_i^{(j)}$ by \"summing all nonbonded interactions among the beads $\\{1,\\dots,i\\}$\". This means the buggy code calculates the total nonbonded energy internal to the segment of length $i$ at step $i$ and includes it in the incremental energy. The total internal nonbonded energy for beads $\\{1, \\dots, i\\}$ is:\n$$ U_{\\mathrm{nb}}^{\\mathrm{total}}(i) = \\sum_{1 \\le m  n \\le i} u_{\\mathrm{nb}}(m,n) = \\left( \\sum_{m=1}^{i-1} u_{\\mathrm{nb}}(i,m) \\right) + \\left( \\sum_{1 \\le m  n \\le i-1} u_{\\mathrm{nb}}(m,n) \\right) $$\nThe first term on the right-hand side depends on the position of bead $i$ and is part of the correct incremental energy. The second term, let's call it $U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1)$, is the sum of nonbonded interactions among the beads that were already placed in previous steps. This term is constant for all $K$ trial placements at step $i$.\n\nThe buggy incremental energy, $\\Delta U_{i, \\mathrm{bug}}^{(j)}$, therefore includes this extra constant term:\n$$ \\Delta U_{i, \\mathrm{bug}}^{(j)} = \\Delta U_{i, \\mathrm{true}}^{(j)} + U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1) $$\nwhere $U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1) = \\sum_{1 \\le m  n \\le i-1} u_{\\mathrm{nb}}(m,n)$. For $i=1$, $U_{\\mathrm{nb}}^{\\mathrm{prev}}(0) = 0$.\n\n**3. Impact on Rosenbluth Weight**\nThe buggy one-step Rosenbluth factor, $w_{i, \\mathrm{bug}}$, is:\n$$ w_{i, \\mathrm{bug}} = \\sum_{j=1}^{K} \\exp\\left(-\\beta \\Delta U_{i, \\mathrm{bug}}^{(j)}\\right) = \\sum_{j=1}^{K} \\exp\\left(-\\beta \\left( \\Delta U_{i, \\mathrm{true}}^{(j)} + U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1) \\right)\\right) $$\nSince $\\exp(-\\beta U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1))$ is a constant factor with respect to the summation index $j$:\n$$ w_{i, \\mathrm{bug}} = \\exp\\left(-\\beta U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1)\\right) \\sum_{j=1}^{K} \\exp\\left(-\\beta \\Delta U_{i, \\mathrm{true}}^{(j)}\\right) $$\n$$ w_{i, \\mathrm{bug}} = \\exp\\left(-\\beta U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1)\\right) \\, w_{i, \\mathrm{true}} $$\nThe total buggy Rosenbluth weight, $W_{\\mathrm{bug}}$, is the product of these buggy one-step factors:\n$$ W_{\\mathrm{bug}} = \\prod_{i=1}^{S} w_{i, \\mathrm{bug}} = \\prod_{i=1}^{S} \\left( \\exp\\left(-\\beta U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1)\\right) \\, w_{i, \\mathrm{true}} \\right) $$\n$$ W_{\\mathrm{bug}} = \\left( \\prod_{i=1}^{S} \\exp\\left(-\\beta U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1)\\right) \\right) \\left( \\prod_{i=1}^{S} w_{i, \\mathrm{true}} \\right) $$\n$$ W_{\\mathrm{bug}} = \\left( \\prod_{i=1}^{S} e^{-\\beta U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1)} \\right) \\, W_{\\mathrm{true}} $$\nThis explicitly shows how the bug modifies the true Rosenbluth weight.\n\n**Option-by-Option Analysis**\n\n**A.** This option states that the incremental energy must only include interactions newly introduced by bead $i$ and must exclude interactions among previously placed beads $\\{1,\\dots,i-1\\}$. This is the correct definition of $\\Delta U_{i, \\mathrm{true}}^{(j)}$. It correctly identifies the erroneously added term as $U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1) \\equiv \\sum_{1 \\le m  n \\le i-1} u_{\\mathrm{nb}}(m,n)$. It then derives the impact on the full Rosenbluth weight as $W_{\\mathrm{bug}} = \\left[\\prod_{i=1}^{S} e^{-\\beta U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1)}\\right] W_{\\mathrm{true}}$. This matches our derivation perfectly. The conclusion that this biases acceptance is also correct, as the acceptance probability depends on the ratio of Rosenbluth weights for the new and old configurations, and the error terms generally do not cancel.\n**Verdict: Correct.**\n\n**B.** This option correctly notes that adding a constant energy $U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1)$ to all $\\Delta U_i^{(j)}$ at step $i$ does not alter the normalized probabilities for selecting among the $K$ trials. This is because the constant factor $\\exp(-\\beta U_{\\mathrm{nb}}^{\\mathrm{prev}}(i-1))$ cancels from the numerator and denominator of the selection probability $p_i(k) = \\exp(-\\beta \\Delta U_{i, \\mathrm{bug}}^{(k)}) / \\sum_j \\exp(-\\beta \\Delta U_{i, \\mathrm{bug}}^{(j)})$. However, it incorrectly concludes that this leads to $W_{\\mathrm{bug}} = W_{\\mathrm{true}}$ and that acceptance is unaffected. As derived above, the Rosenbluth weight itself is modified by a multiplicative factor at each step, and these factors do not cancel out from the overall move acceptance probability.\n**Verdict: Incorrect.**\n\n**C.** This option suggests correcting the error by dividing $\\Delta U_i^{(j)}$ by $i$. This is an arbitrary and physically baseless procedure. The error is an additive energy term, not a scaling issue. The proposed formula $W_{\\mathrm{bug}} = (W_{\\mathrm{true}})^{1/S}$ is mathematically inconsistent with the effect of the bug, which involves a product of exponential factors, not a geometric mean or a root.\n**Verdict: Incorrect.**\n\n**D.** This option makes the false claim that detailed balance requires double-counting interactions. This is a fundamental misunderstanding of energy calculation and detailed balance. In a valid Monte Carlo scheme, the total energy of any given configuration must be unique and well-defined, with each pairwise interaction counted exactly once. The CBMC algorithm is constructed precisely to satisfy detailed balance when using the correct incremental energies that sum to the correct total energy. The formula $W_{\\mathrm{bug}} = (W_{\\mathrm{true}})^{2}$ is baseless.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The Rosenbluth weight, a sum of exponential terms given by $W = \\sum_j \\exp(-\\beta \\Delta U_j)$, is the cornerstone for correcting the bias in CBMC. However, direct computation of this sum is highly susceptible to numerical floating-point errors like overflow and underflow, which can silently invalidate simulation results. This coding exercise guides you through deriving and implementing the \"log-sum-exp\" technique, a numerically robust method essential for reliably calculating partition functions and weights in statistical mechanics .",
            "id": "3745270",
            "problem": "Consider a polymer growth step in Configurational Bias Monte Carlo (CBMC), where a monomer is to be placed by sampling from $k$ trial positions. For trial $j$ at segment $i$, let the incremental energy change be $\\Delta U_i^{(j)}$, measured in units of thermal energy so that it is dimensionless multiples of Boltzmann’s constant times temperature $k_{\\mathrm{B}} T$ and therefore the inverse thermal energy is $\\beta = 1$. The Rosenbluth sum (also called Rosenbluth factor) for segment $i$ is defined as $w_i = \\sum_{j=1}^{k} \\exp\\!\\left(-\\beta \\,\\Delta U_i^{(j)}\\right)$, and the corresponding normalized sampling probability for trial $j$ is $p_i^{(j)} = \\exp\\!\\left(-\\beta \\,\\Delta U_i^{(j)}\\right) / w_i$. In multiscale modeling and analysis, CBMC relies on correct evaluation of $w_i$ for acceptance decisions and bias corrections. From statistical mechanics, use the Boltzmann weighting principle that the relative weight of a configuration is proportional to $\\exp\\!\\left(-\\beta U\\right)$ to justify the form of $w_i$ and $p_i^{(j)}$ from first principles. Then analyze the floating-point pitfalls that occur for large-magnitude $\\Delta U_i^{(j)}$, focusing on underflow when $\\Delta U_i^{(j)}$ is large and positive (making $\\exp\\!\\left(-\\beta \\,\\Delta U_i^{(j)}\\right)$ extremely small) and overflow when $\\Delta U_i^{(j)}$ is large and negative (making $\\exp\\!\\left(-\\beta \\,\\Delta U_i^{(j)}\\right)$ extremely large). Derive a numerically stable expression for $\\log w_i$ using the log-sum-exp identity. Starting from $x_j = -\\beta \\,\\Delta U_i^{(j)}$, show how to compute\n$$\n\\log w_i = m + \\log\\!\\left(\\sum_{j=1}^{k} \\exp(x_j - m)\\right), \\quad \\text{where } m = \\max_{1 \\le j \\le k} x_j,\n$$\nand explain why computing $\\log w_i$ this way avoids overflow and underflow in the intermediate exponentials. Explain how to recover $w_i$ from $\\log w_i$ and how to detect when $w_i$ itself cannot be represented in double-precision floating-point because $\\log w_i$ exceeds the threshold at which $\\exp(\\log w_i)$ overflows. Use these derivations to design an algorithm that, given a list of trial energy differences $\\Delta U_i^{(j)}$ (dimensionless, measured in units of $k_{\\mathrm{B}} T$ so that $\\beta = 1$), produces for each set:\n- The stabilized Rosenbluth sum $w_i$ computed via $\\log w_i$; if $\\log w_i$ is larger than the natural logarithm of the maximum representable floating-point number, return $+\\infty$ for $w_i$.\n- The stabilized logarithm $\\log w_i$.\n- A boolean indicating whether direct naive summation of $\\sum_j \\exp\\!\\left(-\\beta \\,\\Delta U_i^{(j)}\\right)$ matches the stabilized $w_i$ within a relative tolerance of $10^{-12}$, or both are $+\\infty$, or both are exactly $0.0$.\n\nYour program must implement this algorithm and apply it to the following test suite of trial energy difference lists, each list expressed as values of $\\Delta U$ in units of $k_{\\mathrm{B}} T$ (dimensionless):\n- Case $1$ (moderate values, happy path): $\\left[ -0.1, 0.0, 0.2, 0.5 \\right]$.\n- Case $2$ (underflow of individual terms but finite sum): $\\left[ 100.0, 800.0, 1000.0 \\right]$.\n- Case $3$ (overflow in naive exponentials): $\\left[ -800.0, -1000.0, -1200.0 \\right]$.\n- Case $4$ (mixed extremes): $\\left[ -1000.0, 0.0, 1000.0 \\right]$.\n- Case $5$ (single trial boundary): $\\left[ 0.0 \\right]$.\n- Case $6$ (large set spanning negative to positive): a list of $100$ values linearly spaced from $-50.0$ to $50.0$ inclusive.\n- Case $7$ (extreme negative values): $\\left[ -1500.0, -1400.0 \\right]$.\n\nThe final output format must be a single line consisting of a comma-separated list enclosed in square brackets. Each element corresponds to one test case and must itself be a list of the form $\\left[ w_i, \\log w_i, \\text{eq} \\right]$, where $w_i$ and $\\log w_i$ are floating-point numbers (with $+\\infty$ represented as Python’s string $\\texttt{inf}$ if overflow is detected), and $\\text{eq}$ is a boolean. For example, the overall output should look like $\\left[ [\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot],\\ldots \\right]$ with no additional whitespace outside of commas. Angles are not involved in this problem; no angle units are required. Because all energies are given in units of $k_{\\mathrm{B}} T$, the outputs are dimensionless and require no physical units.\n\nYour task is to produce a complete, runnable program that carries out these computations exactly for the given test suite and prints only the single-line output in the format described.",
            "solution": "The foundation for Configurational Bias Monte Carlo (CBMC) is the Boltzmann distribution from statistical mechanics, which states that the relative probability of a microstate with energy $U$ at inverse temperature $\\beta$ is proportional to $\\exp\\!\\left(-\\beta U\\right)$. In CBMC polymer growth, at segment $i$ we propose $k$ trial positions with incremental energy changes $\\Delta U_i^{(j)}$ relative to some reference. The unnormalized weight for trial $j$ follows directly as $\\exp\\!\\left(-\\beta \\Delta U_i^{(j)}\\right)$ by the Boltzmann principle. Normalizing across the $k$ options gives the sampling probability\n$$\np_i^{(j)} = \\frac{\\exp\\!\\left(-\\beta \\Delta U_i^{(j)}\\right)}{\\sum_{\\ell=1}^{k} \\exp\\!\\left(-\\beta \\Delta U_i^{(\\ell)}\\right)},\n$$\nwhere the denominator is the Rosenbluth sum\n$$\nw_i = \\sum_{j=1}^{k} \\exp\\!\\left(-\\beta \\Delta U_i^{(j)}\\right).\n$$\nThis definition is a direct consequence of the well-tested Boltzmann weighting principle and ensures detailed balance when combined with appropriate acceptance criteria for regrowth moves in multiscale modeling.\n\nWhen implementing $w_i$, naive evaluation can fail numerically:\n- If $\\Delta U_i^{(j)}$ is large and positive, then $-\\beta \\Delta U_i^{(j)}$ is large and negative, so $\\exp\\!\\left(-\\beta \\Delta U_i^{(j)}\\right)$ may underflow to $0.0$ in double precision.\n- If $\\Delta U_i^{(j)}$ is large and negative, then $-\\beta \\Delta U_i^{(j)}$ is large and positive, so $\\exp\\!\\left(-\\beta \\Delta U_i^{(j)}\\right)$ may overflow to $+\\infty$.\n\nUnderflow or overflow of individual terms can invalidate $w_i$ if the sum is computed directly as a sum of exponentials. To stabilize the computation, define $x_j = -\\beta \\,\\Delta U_i^{(j)}$ and let $m = \\max_j x_j$. Then factor out $\\exp(m)$ from the sum:\n$$\nw_i = \\sum_{j=1}^{k} \\exp(x_j) = \\exp(m) \\sum_{j=1}^{k} \\exp(x_j - m).\n$$\nTaking the natural logarithm on both sides yields the log-sum-exp identity:\n$$\n\\log w_i = m + \\log\\!\\left(\\sum_{j=1}^{k} \\exp(x_j - m)\\right).\n$$\nThis expression is numerically stable for two reasons. First, all exponents $(x_j - m)$ are $\\le 0$, so $\\exp(x_j - m) \\in (0,1]$, eliminating overflow in the inner exponentials. Second, terms that would underflow in the naive computation become tiny but are accumulated safely inside the sum before taking the logarithm. The only remaining risk is when $\\log w_i$ itself is so large that $\\exp(\\log w_i)$ cannot be represented in double precision when converting back to $w_i$.\n\nTo recover $w_i$ from $\\log w_i$, compute $w_i = \\exp(\\log w_i)$ if $\\log w_i$ is below the overflow threshold. For IEEE $754$ double precision, the largest finite floating-point number is approximately $1.7976931348623157 \\times 10^{308}$, and the threshold for the exponential function is around $\\log(1.7976931348623157 \\times 10^{308}) \\approx 709.782712893384$. Therefore, if $\\log w_i  \\log(\\text{max float})$, we should return $+\\infty$ to indicate overflow when representing $w_i$ even though $\\log w_i$ is finite.\n\nAlgorithm design:\n1. Inputs are lists of $\\Delta U_i^{(j)}$, all dimensionless in units of $k_{\\mathrm{B}} T$, implying $\\beta = 1$.\n2. For each list, compute $x_j = -\\beta \\,\\Delta U_i^{(j)}$ so that $x_j = -\\Delta U_i^{(j)}$.\n3. Compute $m = \\max_j x_j$, then evaluate $s = \\sum_j \\exp(x_j - m)$ in double precision. Compute $\\log w_i = m + \\log(s)$.\n4. If $\\log w_i$ exceeds the threshold $\\log(\\text{max float})$, set $w_i = +\\infty$; otherwise set $w_i = \\exp(\\log w_i)$.\n5. For comparison, compute the naive sum $w_i^{\\text{naive}} = \\sum_j \\exp(x_j)$, which may be $0.0$, finite, or $+\\infty$ due to underflow or overflow in individual terms.\n6. Define an equivalence check:\n   - If both $w_i$ and $w_i^{\\text{naive}}$ are $+\\infty$, return true.\n   - Else if both are exactly $0.0$, return true.\n   - Else if both are finite, check relative agreement $\\left|w_i - w_i^{\\text{naive}}\\right| / \\max(1.0, |w_i|, |w_i^{\\text{naive}}|) \\le 10^{-12}$ and return true if satisfied.\n   - Otherwise return false.\n7. Output, for each test case, the triplet $\\left[w_i, \\log w_i, \\text{eq}\\right]$.\n8. Aggregate all triplets into a single list printed as one line in the required format with commas and no extraneous whitespace.\n\nTest suite analysis:\n- Case $1$: Moderate values produce a well-conditioned sum; naive and stabilized agree.\n- Case $2$: Some exponentials underflow to zero individually (e.g., $\\exp(-800)$ and $\\exp(-1000)$), but the largest term $\\exp(-100)$ is finite; stabilized and naive agree, demonstrating that underflow of small contributions does not break the sum if the dominant term is representable.\n- Case $3$: Extremely negative $\\Delta U$ yield exponents like $\\exp(800)$ which overflow; naive sum returns $+\\infty$. The stabilized $\\log w_i$ is finite (near $800$), but $w_i$ must be reported as $+\\infty$ because $\\exp(\\log w_i)$ cannot be represented; equivalence is true since both are $+\\infty$.\n- Case $4$: Mixed extremes include both overflow and underflow in naive exponentials; stabilized treatment yields finite $\\log w_i$ and $w_i = +\\infty$; equivalence holds.\n- Case $5$: Single element gives $w_i = \\exp(0) = 1.0$ exactly.\n- Case $6$: The range from $-50.0$ to $50.0$ produces a large but finite sum; stabilized and naive agree.\n- Case $7$: More extreme negatives ensure overflow in naive exponentials and $w_i = +\\infty$; stabilized $\\log w_i$ is finite and large; equivalence holds.\n\nThis procedure adheres to first principles via Boltzmann weighting, uses a well-tested numerical stabilization strategy, and produces deterministic outputs for the specified test suite.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef log_sum_exp(x: np.ndarray) - float:\n    \"\"\"\n    Compute log(sum(exp(x))) in a numerically stable manner.\n    Returns a Python float.\n    \"\"\"\n    # Handle empty input defensively (not expected in this problem)\n    if x.size == 0:\n        return -np.inf\n    # Use max trick\n    m = np.max(x)\n    # If m is -inf (all entries -inf), then sum exp(x - m) is 0 - log is -inf\n    if not np.isfinite(m):\n        # If any finite exists, np.max would be finite; here m is -inf = all -inf\n        return -np.inf\n    # Compute the sum of exponentials of shifted values\n    s = np.sum(np.exp(x - m))\n    # s should be = 1.0 if at least one finite term exists\n    return float(m + np.log(s))\n\ndef stable_rosenbluth(dU: np.ndarray, beta: float = 1.0):\n    \"\"\"\n    Given an array of Delta U values (dimensionless, in units of k_B T),\n    compute the stabilized Rosenbluth sum w and its logarithm log_w.\n    Also compute the naive sum for comparison.\n    \"\"\"\n    # Convert to exponent arguments x = -beta * dU\n    x = -beta * dU\n    # Stabilized log-sum-exp\n    log_w = log_sum_exp(x)\n    # Determine overflow threshold for exp\n    log_max = np.log(np.finfo(np.float64).max)\n    if log_w  log_max:\n        w = float('inf')\n    else:\n        w = float(np.exp(log_w))\n    # Naive sum (may underflow/overflow)\n    with np.errstate(over='ignore'):\n        exp_x = np.exp(x)\n    naive_w = float(np.sum(exp_x))\n    return w, log_w, naive_w\n\ndef compare_w(w: float, naive_w: float, rtol: float = 1e-12) - bool:\n    \"\"\"\n    Compare stabilized w with naive w using relative tolerance,\n    accounting for infinities and exact zeros.\n    \"\"\"\n    if np.isinf(w) and np.isinf(naive_w):\n        return True\n    if w == 0.0 and naive_w == 0.0:\n        return True\n    if np.isfinite(w) and np.isfinite(naive_w):\n        # Use a safe denominator for relative error calculation\n        denom = max(1.0, abs(w), abs(naive_w))\n        rel_err = abs(w - naive_w) / denom\n        return rel_err = rtol\n    return False\n\ndef format_value(val):\n    \"\"\"\n    Format a value (float, bool, list/tuple) without spaces, as required.\n    \"\"\"\n    if isinstance(val, (list, tuple)):\n        return \"[\" + \",\".join(format_value(v) for v in val) + \"]\"\n    if isinstance(val, (np.floating, float)):\n        if np.isinf(val):\n            return \"inf\"\n        # Use repr for a compact precise representation\n        return repr(float(val))\n    if isinstance(val, (np.bool_, bool)):\n        return \"True\" if bool(val) else \"False\"\n    # Fallback for integers if any appear\n    if isinstance(val, (np.integer, int)):\n        return str(int(val))\n    # Fallback: convert to string\n    return str(val)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # All energies are dimensionless in units of k_B T (beta = 1).\n    test_cases = [\n        [-0.1, 0.0, 0.2, 0.5],               # Case 1\n        [100.0, 800.0, 1000.0],              # Case 2\n        [-800.0, -1000.0, -1200.0],          # Case 3\n        [-1000.0, 0.0, 1000.0],              # Case 4\n        [0.0],                               # Case 5\n        list(np.linspace(-50.0, 50.0, 100)), # Case 6\n        [-1500.0, -1400.0],                  # Case 7\n    ]\n\n    beta = 1.0  # energies are in k_B T units\n    results = []\n    for case in test_cases:\n        dU = np.array(case, dtype=np.float64)\n        w, log_w, naive_w = stable_rosenbluth(dU, beta=beta)\n        eq = compare_w(w, naive_w, rtol=1e-12)\n        results.append([w, log_w, eq])\n\n    # Final print statement in the exact required format: single line, no extra spaces.\n    print(format_value(results))\n\n# Execute the main function\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}