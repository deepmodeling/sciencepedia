{
    "hands_on_practices": [
        {
            "introduction": "在编写模拟代码之前，对不同算法策略的计算复杂性进行分析是明智之举。这项练习将指导你进行“餐巾纸背面”式的计算，比较朴素扫描实现与使用邻居列表的优化实现之间的性能，这是任何计算科学家都应具备的关键技能。通过这种分析，我们可以为模拟大型稠密系统做出明智的设计选择，并理解性能优化的必要性。",
            "id": "3797238",
            "problem": "考虑在多尺度材料模拟中，嵌入在稠密原子环境中的聚合物链的构象偏置蒙特卡罗（CBMC）再生长过程。一个再生长移动通过为每个链段采样 $K$ 个试探构象来重构一个包含 $m$ 个链段的链，并根据玻尔兹曼权重为每个链段选择一个试探构象。设对相互作用能在截断距离 $r_c$ 内的邻近粒子上是可加的，并设一个试探构象的玻尔兹曼权重为 $\\exp(-\\beta U)$，其中 $\\beta$ 是逆热能，$U$ 是通过对 $r_c$ 内的邻近粒子的对势求和计算出的相互作用能。假设 $r_c$ 内的平均邻近粒子数为 $z$，环境粒子总数为 $N$。\n\n考虑两种用于评估试探构象能量的实现策略：\n1. 对每次试探，朴素地扫描所有 $N$ 个粒子，每个粒子的距离检查成本为 $c_d$，$r_c$ 内每个邻近粒子的对势评估成本为 $c_v$。\n2. 邻近列表加速法，该方法预先计算一个平均长度为 $z$ 的邻近列表，每个粒子的重建成本为 $c_b$，该成本通过每 $M$ 次再生长移动重建一次来均摊。遍历邻近列表时，每个邻近粒子的遍历成本为 $c_t$，$r_c$ 内每个邻近粒子的对势评估成本为 $c_v$。\n\n在两种策略中，生成一个试探构象（例如，键角和二面角提议）的成本为每次试探 $c_g$。假设在再生长移动过程中 $N$ 和 $z$ 保持不变。从CBMC权重和加性相互作用的第一性原理出发，推导在朴素扫描和邻近列表加速下，每次再生长移动的预期总浮点运算次数（FLOPs）的表达式，并确定复杂度对 $m$ 和 $K$ 的主要依赖关系。\n\n然后，对于以下参数：\n- $m = 50$,\n- $N = 100000$,\n- $z = 150$,\n- $M = 10$,\n- $c_g = 200$ FLOPs/次试探,\n- $c_d = 0.5$ FLOPs/次距离检查,\n- $c_v = 20$ FLOPs/次对势计算,\n- $c_t = 5$ FLOPs/次邻近粒子遍历,\n- $c_b = 5000$ FLOPs/粒子（用于邻近列表重建）,\n计算盈亏平衡点，即每个链段的试探次数 $K_{\\star}$，在该点，使用邻近列表加速的每次再生长移动的总FLOPs等于朴素扫描的总FLOPs。\n\n将您的 $K_{\\star}$ 最终数值四舍五入到四位有效数字。将 $K_{\\star}$ 表示为一个无量纲量。",
            "solution": "在尝试求解之前，将首先对问题陈述进行严格的验证过程。\n\n### 步骤1：提取给定条件\n- 链重构长度：$m$ 个链段\n- 每个链段的试探构象数：$K$\n- 截断距离 $r_c$ 内的平均邻近粒子数：$z$\n- 环境粒子总数：$N$\n- 邻近列表重建频率：每 $M$ 次再生长移动\n- 朴素扫描成本：\n    - 每个粒子的距离检查成本：$c_d$\n    - 每个邻近粒子的对势评估成本：$c_v$\n- 邻近列表加速成本：\n    - 每个粒子的邻近列表重建成本：$c_b$\n    - 每个邻近粒子的遍历成本：$c_t$\n    - 每个邻近粒子的对势评估成本：$c_v$\n- 公共成本：\n    - 每次试探的试探构象生成成本：$c_g$\n- 数值参数：\n    - $m = 50$\n    - $N = 100000$\n    - $z = 150$\n    - $M = 10$\n    - $c_g = 200$ FLOPs\n    - $c_d = 0.5$ FLOPs\n    - $c_v = 20$ FLOPs\n    - $c_t = 5$ FLOPs\n    - $c_b = 5000$ FLOPs\n\n### 步骤2：使用提取的给定条件进行验证\n根据所需标准对问题进行评估：\n- **科学依据**：该问题基于构象偏置蒙特卡洛（CBMC），这是计算材料科学中一个标准且有据可查的算法。朴素粒子扫描与基于邻近列表的方法之间的效率比较是模拟算法分析中的一个典型问题。这些概念在事实上是合理的。\n- **问题定义良好**：问题提出了一个明确的目标：推导成本表达式并计算一个盈亏平衡点。所有必要的变量和成本参数都已定义，并且假设（例如，固定的 $N$ 和 $z$）也已明确说明。可以获得一个唯一的、有意义的解。\n- **客观性**：语言是技术性的、精确的。问题是定量的，没有主观或基于意见的断言。\n\n该问题没有表现出任何无效性缺陷。这是一个在应用于分子模拟的计算复杂度分析中定义良好、科学合理的问题。邻近列表成本的模型是对实际实现（例如，Verlet列表与单元列表相结合）的简化，但对于本分析的目的而言，它是一个自洽且可形式化的模型。\n\n### 步骤3：结论与行动\n该问题被判定为**有效**。将提供完整解答。\n\n### 求解推导\n\n目标是推导在两种不同实现策略下，一次完整的聚合物链再生长移动的总计算成本（以浮点运算次数FLOPs为单位）的表达式。一次再生长移动包括向链中顺序添加 $m$ 个链段。对于每个链段，会生成 $K$ 个试探构象并评估其能量。\n\n**1. 朴素扫描策略的成本 ($C_{naive}$)**\n\n在此策略中，每个试探链段的相互作用能是通过扫描环境中的所有 $N$ 个粒子来计算的。\n一次再生长移动期间评估的试探构象总数是链段数 $m$ 和每个链段的试探次数 $K$ 的乘积，即 $mK$。\n\n单个试探构象的成本是其生成成本和能量评估成本的总和。\n- 每次试探的生成成本：$c_g$。\n- 每次试探的能量评估成本：为了评估能量，我们必须识别邻近粒子。朴素算法检查与所有 $N$ 个环境粒子的距离，每个粒子的成本为 $c_d$。这给出的总距离检查成本为 $N c_d$。在这些粒子中，平均有 $z$ 个被发现在截断半径 $r_c$ 内。对这 $z$ 个邻近粒子中的每一个评估对势，每个邻近粒子的成本为 $c_v$。这给出的势能评估成本为 $z c_v$。\n    每次试探的总能量评估成本为 $N c_d + z c_v$。\n\n因此，每次试探的总成本为 $c_g + N c_d + z c_v$。\n由于在一次完整的再生长移动中有 $mK$ 次这样的试探，朴素扫描的总成本为：\n$$C_{\\text{naive}} = mK (c_g + N c_d + z c_v)$$\n该复杂度对 $m$ 和 $K$ 的主要依赖关系在两者上都是线性的，成本随 $O(mKN)$ 缩放，因为 $N$ 通常是最大的参数。\n\n**2. 邻近列表加速策略的成本 ($C_{NL}$)**\n\n该策略涉及一个高成本的预计算步骤（构建邻近列表），然后将其成本摊销到多个移动中。\n每次再生长移动的总成本是均摊的重建成本和评估所有试探的成本之和。\n\n- **均摊重建成本**：为所有 $N$ 个粒子重建邻近列表，每个粒子的成本为 $c_b$，总重建成本为 $N c_b$。该成本分布在 $M$ 次再生长移动中。因此，每次移动的均摊成本为 $\\frac{N c_b}{M}$。\n\n- **试探评估成本**：如前所述，总共有 $mK$ 次试探。\n    - 每次试探的生成成本：$c_g$。\n    - 每次试探的能量评估成本：有了预先计算的邻近列表，算法不需要扫描所有 $N$ 个粒子。问题陈述中说，遍历一个试探链段的邻近列表，每个邻近粒子的成本为 $c_t$，评估对势的成本为每个邻近粒子 $c_v$。给定平均 $z$ 个邻近粒子，每次试探的总能量评估成本为 $z c_t + z c_v = z(c_t + c_v)$。\n\n因此，每次试探的总成本为 $c_g + z(c_t + c_v)$。\n移动中 $mK$ 次试探的总成本为 $mK(c_g + z(c_t + c_v))$。\n\n邻近列表加速策略的总成本是均摊成本和每次试探成本的总和：\n$$C_{\\text{NL}} = \\frac{N c_b}{M} + mK (c_g + z c_t + z c_v)$$\n该复杂度对 $m$ 和 $K$ 的主要依赖关系是 $O(\\frac{N}{M} + mKz)$。此方法的优点是从每次试探的成本项中消除了对粒子总数 $N$ 的依赖。\n\n**3. 盈亏平衡点 ($K_{\\star}$)**\n\n每个链段的盈亏平衡试探次数 $K_{\\star}$ 是指两种策略具有相等计算成本时的 $K$ 值，即 $C_{\\text{naive}} = C_{\\text{NL}}$。\n\n$$m K_{\\star} (c_g + N c_d + z c_v) = \\frac{N c_b}{M} + m K_{\\star} (c_g + z c_t + z c_v)$$\n\n我们可以展开这些项：\n$$m K_{\\star} c_g + m K_{\\star} N c_d + m K_{\\star} z c_v = \\frac{N c_b}{M} + m K_{\\star} c_g + m K_{\\star} z c_t + m K_{\\star} z c_v$$\n\n$m K_{\\star} c_g$ 和 $m K_{\\star} z c_v$ 这两项在等式两边都存在，可以消去。\n$$m K_{\\star} N c_d = \\frac{N c_b}{M} + m K_{\\star} z c_t$$\n\n现在，我们组合包含 $K_{\\star}$ 的项来求解它：\n$$m K_{\\star} N c_d - m K_{\\star} z c_t = \\frac{N c_b}{M}$$\n$$K_{\\star} (m N c_d - m z c_t) = \\frac{N c_b}{M}$$\n$$K_{\\star} \\cdot m (N c_d - z c_t) = \\frac{N c_b}{M}$$\n\n分离 $K_{\\star}$ 得到最终的符号表达式：\n$$K_{\\star} = \\frac{N c_b}{M m (N c_d - z c_t)}$$\n\n现在，我们代入给定的数值：\n- $m = 50$\n- $N = 100000$\n- $z = 150$\n- $M = 10$\n- $c_d = 0.5$\n- $c_t = 5$\n- $c_b = 5000$\n\n首先，计算分母括号内的项：\n- $N c_d = 100000 \\times 0.5 = 50000$\n- $z c_t = 150 \\times 5 = 750$\n- $N c_d - z c_t = 50000 - 750 = 49250$\n\n接下来，计算完整的分母：\n- $M m (N c_d - z c_t) = 10 \\times 50 \\times 49250 = 500 \\times 49250 = 24625000$\n\n接下来，计算分子：\n- $N c_b = 100000 \\times 5000 = 500000000$\n\n最后，计算 $K_{\\star}$：\n$$K_{\\star} = \\frac{500000000}{24625000} = \\frac{500}{24.625} \\approx 20.30456954$$\n\n按要求四舍五入到四位有效数字：\n$$K_{\\star} \\approx 20.30$$\n这意味着对于这个特定的系统和计算成本集，如果每个链段生长步骤采样的试探位点超过大约20个，邻近列表策略将比朴素扫描更有效率。",
            "answer": "$$\\boxed{20.30}$$"
        },
        {
            "introduction": "CBMC中使用的公式，例如罗森布鲁斯因子，涉及到对指数项的求和，这在数值计算中很容易因浮点数的精度限制而出现上溢或下溢问题。本练习将解决这一关键的实现挑战，介绍“log-sum-exp”技巧，这是一种在处理玻尔兹曼权重时保持数值稳定性的标准技术。掌握这种方法对于编写健壮且准确的模拟代码至关重要。",
            "id": "3745270",
            "problem": "考虑构型偏置蒙特卡罗（CBMC）中的一个聚合物增长步骤，其中一个单体将通过从 $k$ 个试验位置中采样来放置。对于链段 $i$ 的试验 $j$，设增量能量变化为 $\\Delta U_i^{(j)}$，以热能为单位进行测量，因此它是玻尔兹曼常数乘以温度 $k_{\\mathrm{B}} T$ 的无量纲倍数，从而逆热能为 $\\beta = 1$。链段 $i$ 的罗森布鲁斯和（也称为罗森布鲁斯因子）定义为 $w_i = \\sum_{j=1}^{k} \\exp\\!\\left(-\\beta \\,\\Delta U_i^{(j)}\\right)$，而试验 $j$ 对应的归一化采样概率为 $p_i^{(j)} = \\exp\\!\\left(-\\beta \\,\\Delta U_i^{(j)}\\right) / w_i$。在多尺度建模和分析中，CBMC 依赖于对 $w_i$ 的正确评估来进行接受决策和偏差校正。根据统计力学中的玻尔兹曼权重原理，从第一性原理出发推导 $w_i$ 和 $p_i^{(j)}$ 的形式。然后分析当 $\\Delta U_i^{(j)}$ 的量级很大时出现的浮点数陷阱，重点关注当 $\\Delta U_i^{(j)}$ 为大正数时（使得 $\\exp\\!\\left(-\\beta \\,\\Delta U_i^{(j)}\\right)$ 极小）发生的下溢，以及当 $\\Delta U_i^{(j)}$ 为大负数时（使得 $\\exp\\!\\left(-\\beta \\,\\Delta U_i^{(j)}\\right)$ 极大）发生的上溢。使用 log-sum-exp 恒等式推导出一个数值稳定的 $\\log w_i$ 表达式。从 $x_j = -\\beta \\,\\Delta U_i^{(j)}$ 出发，展示如何计算\n$$\n\\log w_i = m + \\log\\!\\left(\\sum_{j=1}^{k} \\exp(x_j - m)\\right), \\quad \\text{其中 } m = \\max_{1 \\le j \\le k} x_j,\n$$\n并解释为什么用这种方式计算 $\\log w_i$ 可以避免中间指数项的上溢和下溢。解释如何从 $\\log w_i$ 恢复 $w_i$，以及如何检测何时 $w_i$ 本身无法用双精度浮点数表示，因为 $\\log w_i$ 超过了使 $\\exp(\\log w_i)$ 上溢的阈值。利用这些推导设计一个算法，给定一个试验能量差列表 $\\Delta U_i^{(j)}$（无量纲，以 $k_{\\mathrm{B}} T$ 为单位，因此 $\\beta = 1$），为每组数据生成：\n- 通过 $\\log w_i$ 计算的稳定化的 Rosenbluth 和 $w_i$；如果 $\\log w_i$ 大于最大可表示浮点数的自然对数，则为 $w_i$ 返回 $+\\infty$。\n- 稳定化的对数 $\\log w_i$。\n- 一个布尔值，指示 $\\sum_j \\exp\\!\\left(-\\beta \\,\\Delta U_i^{(j)}\\right)$ 的直接朴素求和是否在 $10^{-12}$ 的相对容差内与稳定化的 $w_i$ 匹配，或者两者均为 $+\\infty$，或者两者均为 $0.0$。\n\n您的程序必须实现此算法，并将其应用于以下试验能量差列表的测试套件，每个列表都表示为以 $k_{\\mathrm{B}} T$ 为单位的 $\\Delta U$ 值（无量纲）：\n- 情况 1（中等值，正常路径）：$\\left[ -0.1, 0.0, 0.2, 0.5 \\right]$。\n- 情况 2（单个项下溢但和为有限值）：$\\left[ 100.0, 800.0, 1000.0 \\right]$。\n- 情况 3（朴素指数计算中上溢）：$\\left[ -800.0, -1000.0, -1200.0 \\right]$。\n- 情况 4（混合极端值）：$\\left[ -1000.0, 0.0, 1000.0 \\right]$。\n- 情况 5（单次试验边界情况）：$\\left[ 0.0 \\right]$。\n- 情况 6（跨越负值到正值的大集合）：一个包含 100 个从 -50.0 到 50.0（含两端）线性间隔的值的列表。\n- 情况 7（极端负值）：$\\left[ -1500.0, -1400.0 \\right]$。\n\n最终输出格式必须是单行，由方括号括起并以逗号分隔的列表组成。每个元素对应一个测试用例，并且本身必须是 $\\left[ w_i, \\log w_i, \\text{eq} \\right]$ 形式的列表，其中 $w_i$ 和 $\\log w_i$ 是浮点数（如果检测到上溢，则 $+\\infty$ 表示为`inf`字符串），$\\text{eq}$ 是一个布尔值。例如，整体输出应类似于 $\\left[ [\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot],\\ldots \\right]$，除了逗号之外没有额外的空白字符。此问题不涉及角度；不需要角度单位。因为所有能量都以 $k_{\\mathrm{B}} T$ 为单位给出，所以输出是无量纲的，不需要物理单位。\n\n您的任务是生成一个完整、可运行的程序，对给定的测试套件精确执行这些计算，并仅按所述格式打印单行输出。",
            "solution": "构型偏置蒙特卡罗（CBMC）的基础是统计力学中的玻尔兹曼分布，该分布指出，在逆温 $\\beta$ 下，能量为 $U$ 的微观状态的相对概率与 $\\exp\\!\\left(-\\beta U\\right)$ 成正比。在 CBMC 聚合物增长中，对于链段 $i$，我们相对于某个参考提出 $k$ 个试验位置，其增量能量变化为 $\\Delta U_i^{(j)}$。根据玻尔兹曼原理，试验 $j$ 的未归一化权重直接得出为 $\\exp\\!\\left(-\\beta \\Delta U_i^{(j)}\\right)$。对 $k$ 个选项进行归一化，得到采样概率\n$$\np_i^{(j)} = \\frac{\\exp\\!\\left(-\\beta \\Delta U_i^{(j)}\\right)}{\\sum_{\\ell=1}^{k} \\exp\\!\\left(-\\beta \\Delta U_i^{(\\ell)}\\right)},\n$$\n其中分母是罗森布鲁斯和\n$$\nw_i = \\sum_{j=1}^{k} \\exp\\!\\left(-\\beta \\Delta U_i^{(j)}\\right).\n$$\n这个定义是经过充分检验的玻尔兹曼权重原理的直接结果，并且在与多尺度建模中重增长移动的适当接受准则相结合时，确保了细致平衡。\n\n在实现 $w_i$ 时，朴素的评估可能会在数值上失败：\n- 如果 $\\Delta U_i^{(j)}$ 是一个大的正数，那么 $-\\beta \\Delta U_i^{(j)}$ 是一个大的负数，因此 $\\exp\\!\\left(-\\beta \\Delta U_i^{(j)}\\right)$ 在双精度下可能会下溢到 $0.0$。\n- 如果 $\\Delta U_i^{(j)}$ 是一个大的负数，那么 $-\\beta \\Delta U_i^{(j)}$ 是一个大的正数，因此 $\\exp\\!\\left(-\\beta \\Delta U_i^{(j)}\\right)$ 可能会上溢到 $+\\infty$。\n\n如果将和直接计算为指数的和，那么单个项的下溢或上溢可能会使 $w_i$ 无效。为了稳定计算，定义 $x_j = -\\beta \\,\\Delta U_i^{(j)}$ 并设 $m = \\max_j x_j$。然后从和中提出因子 $\\exp(m)$：\n$$\nw_i = \\sum_{j=1}^{k} \\exp(x_j) = \\exp(m) \\sum_{j=1}^{k} \\exp(x_j - m).\n$$\n两边取自然对数，得到 log-sum-exp 恒等式：\n$$\n\\log w_i = m + \\log\\!\\left(\\sum_{j=1}^{k} \\exp(x_j - m)\\right).\n$$\n这个表达式在数值上是稳定的，原因有二。首先，所有的指数 $(x_j - m)$ 都 $\\le 0$，因此 $\\exp(x_j - m) \\in (0,1]$，从而消除了内部指数项的上溢。其次，在朴素计算中会下溢的项变得非常小，但在取对数之前被安全地累加在和中。唯一剩下的风险是当 $\\log w_i$ 本身太大，以至于在转换回 $w_i$ 时，$\\exp(\\log w_i)$ 无法用双精度表示。\n\n要从 $\\log w_i$ 恢复 $w_i$，如果 $\\log w_i$ 低于上溢阈值，则计算 $w_i = \\exp(\\log w_i)$。对于 IEEE 754 双精度，最大的有限浮点数约为 $1.7976931348623157 \\times 10^{308}$，指数函数的阈值约为 $\\log(1.7976931348623157 \\times 10^{308}) \\approx 709.782712893384$。因此，如果 $\\log w_i  \\log(\\text{max float})$，我们应返回 $+\\infty$ 来表示在表示 $w_i$ 时发生了上溢，即使 $\\log w_i$ 是有限的。\n\n算法设计：\n1. 输入是 $\\Delta U_i^{(j)}$ 的列表，全部是无量纲的，以 $k_{\\mathrm{B}} T$ 为单位，这意味着 $\\beta = 1$。\n2. 对每个列表，计算 $x_j = -\\beta \\,\\Delta U_i^{(j)}$，因此 $x_j = -\\Delta U_i^{(j)}$。\n3. 计算 $m = \\max_j x_j$，然后以双精度计算 $s = \\sum_j \\exp(x_j - m)$。计算 $\\log w_i = m + \\log(s)$。\n4. 如果 $\\log w_i$ 超过阈值 $\\log(\\text{max float})$，则设置 $w_i = +\\infty$；否则设置 $w_i = \\exp(\\log w_i)$。\n5. 为了比较，计算朴素和 $w_i^{\\text{naive}} = \\sum_j \\exp(x_j)$，由于单个项的下溢或上溢，它可能是 $0.0$、有限值或 $+\\infty$。\n6. 定义一个等价性检查：\n   - 如果 $w_i$ 和 $w_i^{\\text{naive}}$ 都是 $+\\infty$，返回 true。\n   - 否则，如果两者都恰好是 $0.0$，返回 true。\n   - 否则，如果两者都是有限值，检查相对一致性 $\\left|w_i - w_i^{\\text{naive}}\\right| / \\max(1.0, |w_i|, |w_i^{\\text{naive}}|) \\le 10^{-12}$ 如果满足则返回 true。\n   - 否则返回 false。\n7. 对每个测试用例，输出三元组 $\\left[w_i, \\log w_i, \\text{eq}\\right]$。\n8. 将所有三元组聚合到一个列表中，并按照要求的格式（用逗号分隔且无多余空格）打印为一行。\n\n测试套件分析：\n- 情况 1：中等值产生一个良态的和；朴素方法和稳定化方法结果一致。\n- 情况 2：一些指数项会单独下溢为零（例如，$\\exp(-800)$ 和 $\\exp(-1000)$），但最大的项 $\\exp(-100)$ 是有限的；稳定化方法和朴素方法结果一致，表明如果主导项是可表示的，那么小贡献项的下溢不会破坏求和。\n- 情况 3：极端的负 $\\Delta U$ 产生像 $\\exp(800)$ 这样的指数，这会上溢；朴素求和返回 $+\\infty$。稳定化的 $\\log w_i$ 是有限的（接近 $800$），但 $w_i$ 必须报告为 $+\\infty$，因为 $\\exp(\\log w_i)$ 无法表示；由于两者都是 $+\\infty$，等价性为真。\n- 情况 4：混合极端值在朴素指数计算中同时包含上溢和下溢；稳定化处理产生有限的 $\\log w_i$ 和 $w_i = +\\infty$；等价性成立。\n- 情况 5：单个元素给出 $w_i = \\exp(0) = 1.0$。\n- 情况 6：从 $-50.0$ 到 $50.0$ 的范围产生一个大但有限的和；稳定化方法和朴素方法结果一致。\n- 情况 7：更极端的负值确保朴素指数计算中发生上溢，且 $w_i = +\\infty$；稳定化的 $\\log w_i$ 是有限且很大的；等价性成立。\n\n此过程通过玻尔兹曼权重遵循第一性原理，使用经过充分测试的数值稳定策略，并为指定的测试套件生成确定性输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef log_sum_exp(x: np.ndarray) - float:\n    \"\"\"\n    Compute log(sum(exp(x))) in a numerically stable manner.\n    Returns a Python float.\n    \"\"\"\n    # Handle empty input defensively (not expected in this problem)\n    if x.size == 0:\n        return -np.inf\n    # Use max trick\n    m = np.max(x)\n    # If m is -inf (all entries -inf), then sum exp(x - m) is 0 - log is -inf\n    if not np.isfinite(m):\n        # If any finite exists, np.max would be finite; here m is -inf = all -inf\n        return -np.inf\n    # Compute the sum of exponentials of shifted values\n    s = np.sum(np.exp(x - m))\n    # s should be = 1.0 if at least one finite term exists\n    return float(m + np.log(s))\n\ndef stable_rosenbluth(dU: np.ndarray, beta: float = 1.0):\n    \"\"\"\n    Given an array of Delta U values (dimensionless, in units of k_B T),\n    compute the stabilized Rosenbluth sum w and its logarithm log_w.\n    Also compute the naive sum for comparison.\n    \"\"\"\n    # Convert to exponent arguments x = -beta * dU\n    x = -beta * dU\n    # Stabilized log-sum-exp\n    log_w = log_sum_exp(x)\n    # Determine overflow threshold for exp\n    log_max = np.log(np.finfo(np.float64).max)\n    if log_w  log_max:\n        w = float('inf')\n    else:\n        w = float(np.exp(log_w))\n    # Naive sum (may underflow/overflow)\n    with np.errstate(over='ignore'):\n        exp_x = np.exp(x)\n    naive_w = float(np.sum(exp_x))\n    return w, log_w, naive_w\n\ndef compare_w(w: float, naive_w: float, rtol: float = 1e-12) - bool:\n    \"\"\"\n    Compare stabilized w with naive w using relative tolerance,\n    accounting for infinities and exact zeros.\n    \"\"\"\n    if np.isinf(w) and np.isinf(naive_w):\n        return True\n    if w == 0.0 and naive_w == 0.0:\n        return True\n    if np.isfinite(w) and np.isfinite(naive_w):\n        denom = max(1.0, abs(w), abs(naive_w))\n        rel_err = abs(w - naive_w) / denom\n        return rel_err = rtol\n    return False\n\ndef format_value(val):\n    \"\"\"\n    Format a value (float, bool, list/tuple) without spaces, as required.\n    \"\"\"\n    if isinstance(val, (list, tuple)):\n        return \"[\" + \",\".join(format_value(v) for v in val) + \"]\"\n    if isinstance(val, (np.floating, float)):\n        if np.isinf(val):\n            return \"inf\"\n        # Use repr for a compact precise representation\n        return repr(float(val))\n    if isinstance(val, (np.bool_, bool)):\n        return \"True\" if bool(val) else \"False\"\n    # Fallback for integers if any appear\n    if isinstance(val, (np.integer, int)):\n        return str(int(val))\n    # Fallback: convert to string\n    return str(val)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # All energies are dimensionless in units of k_B T (beta = 1).\n    test_cases = [\n        [-0.1, 0.0, 0.2, 0.5],               # Case 1\n        [100.0, 800.0, 1000.0],              # Case 2\n        [-800.0, -1000.0, -1200.0],          # Case 3\n        [-1000.0, 0.0, 1000.0],              # Case 4\n        [0.0],                               # Case 5\n        list(np.linspace(-50.0, 50.0, 100)), # Case 6\n        [-1500.0, -1400.0],                  # Case 7\n    ]\n\n    beta = 1.0  # energies are in k_B T units\n    results = []\n    for case in test_cases:\n        dU = np.array(case, dtype=np.float64)\n        w, log_w, naive_w = stable_rosenbluth(dU, beta=beta)\n        eq = compare_w(w, naive_w, rtol=1e-12)\n        results.append([w, log_w, eq])\n\n    # Final print statement in the exact required format: single line, no extra spaces.\n    print(format_value(results))\n\nsolve()\n```"
        },
        {
            "introduction": "一个程序可能在运行时不报错，但如果其底层算法违背了基本的统计力学原理，它仍然会产生物理上不正确的结果。最后一个练习提供了一种方法，用于数值验证你的CBMC实现是否满足细致平衡条件，从而确保它能正确地从目标统计分布中抽样。对于任何马尔可夫链蒙特卡洛（MCMC）模拟而言，这都是一种强大的正确性验证技术。",
            "id": "3745237",
            "problem": "考虑一个方形晶格上的两步聚合物链，其步长限制在集合 $\\{\\text{U},\\text{R}\\}$ 中。一个链构型是两步的序列，产生四种可能的状态：$\\text{UU}$、$\\text{UR}$、$\\text{RU}$ 和 $\\text{RR}$。状态 $x$ 的链能量 $U(x)$ 定义为每一步的方向能量与施加在第二步上的弯曲惩罚之和。具体来说，设第一步的方向能量为 $\\varepsilon_{\\text{U}} = 0$ 和 $\\varepsilon_{\\text{R}} = 0.5$。对于第二步，如果第二步与第一步相同，则增加一个为 $0$ 的弯曲惩罚；如果不同，则为 $1$。总能量则为\n$$\nU(x) = \\varepsilon_{d_1} + \\varepsilon_{d_2} + \\text{bend}(d_1,d_2),\n$$\n其中 $x = (d_1,d_2)$，$d_1,d_2 \\in \\{\\text{U},\\text{R}\\}$，并且如果 $d_2 = d_1$，则 $\\text{bend}(d_1,d_2) = 0$，否则为 $1$。\n\n设目标平稳分布为逆温度 $\\beta$ 下的正则玻尔兹曼分布，其定义（不考虑归一化常数 $Z$）为\n$$\n\\pi(x) = \\frac{1}{Z}\\exp\\big(-\\beta U(x)\\big).\n$$\n使用马尔可夫链蒙特卡洛（MCMC）算法，通过一种受构型偏置蒙特卡洛（CBMC）启发的再生长移动，从 $\\pi(x)$ 中进行采样。CBMC 提议使用 Rosenbluth 加权分两个阶段生长链：\n- 第一步，以与 $\\exp\\big(-\\beta \\varepsilon_{d_1}\\big)$ 成正比的概率抽取 $d_1 \\in \\{\\text{U},\\text{R}\\}$，归一化因子为\n$$\nW_1 = \\exp\\big(-\\beta \\varepsilon_{\\text{U}}\\big) + \\exp\\big(-\\beta \\varepsilon_{\\text{R}}\\big).\n$$\n- 第二步，给定 $d_1$，以与 $\\exp\\big(-\\beta(\\varepsilon_{d_2} + \\text{bend}(d_1,d_2))\\big)$ 成正比的概率抽取 $d_2 \\in \\{\\text{U},\\text{R}\\}$，归一化因子为\n$$\nW_2(d_1) = \\exp\\big(-\\beta(\\varepsilon_{\\text{U}} + \\text{bend}(d_1,\\text{U}))\\big) + \\exp\\big(-\\beta(\\varepsilon_{\\text{R}} + \\text{bend}(d_1,\\text{R}))\\big).\n$$\n这产生一个提议分布 $q(x)$，它与 $\\exp\\big(-\\beta U(x)\\big)/(W_1 W_2(d_1))$ 成正比。\n\n使用 Metropolis-Hastings 原理，推导一个接受概率，在给定上述 CBMC 提议结构的情况下，确保相对于 $\\pi(x)$ 的细致平衡。然后通过估计比率来实现细致平衡的数值验证\n$$\nR(x,x') = \\frac{\\pi(x) P(x \\to x')}{\\pi(x') P(x' \\to x)},\n$$\n其中 $P(x \\to x')$ 是在构建的马尔可夫链下的一步转移概率。该估计必须从长时间模拟中采样的转移中获得。您必须：\n- 精确地实现所描述的 CBMC 提议机制。\n- 在四个状态 $\\{\\text{UU},\\text{UR},\\text{RU},\\text{RR}\\}$ 上的离散时间马尔可夫链中，使用推导出的接受概率执行再生长移动。\n- 从采样的转移中，将 $P(x \\to x')$ 估计为从状态 $x$ 到状态 $x'$ 的接受转移次数与在状态 $x$ 时所做提议次数的分数。为确保稳健性，请使用 Jeffreys 平滑估计器\n$$\n\\widehat{P}(x \\to x') = \\frac{K(x \\to x') + 0.5}{N(x) + 1},\n$$\n其中 $N(x)$ 是链处于状态 $x$ 时尝试的提议次数，$K(x \\to x')$ 是从 $x$ 到 $x'$ 的接受转移次数。\n- 构建经验比率\n$$\n\\widehat{R}(x,x') = \\frac{\\pi(x) \\widehat{P}(x \\to x')}{\\pi(x') \\widehat{P}(x' \\to x)} = \\exp\\big(-\\beta(U(x) - U(x'))\\big)\\cdot \\frac{\\widehat{P}(x \\to x')}{\\widehat{P}(x' \\to x)}.\n$$\n- 使用 delta 方法对二项比例进行近似，将 $\\log \\widehat{P}$ 视为近似正态分布，为 $\\log \\widehat{R}(x,x')$ 构建一个 $95\\%$ 的置信区间：\n$$\n\\operatorname{Var}\\big(\\log \\widehat{P}(x \\to x')\\big) \\approx \\frac{1 - \\widehat{P}(x \\to x')}{\\widehat{P}(x \\to x')\\cdot (N(x) + 1)}.\n$$\n假设正向和反向估计之间相互独立，并将方差相加以近似 $\\operatorname{Var}\\big(\\log \\widehat{R}(x,x')\\big)$。然后将置信区间转换回原始尺度，以检验是否包含 $1$。\n\n您的程序必须运行三个测试用例，它们在逆温度 $\\beta$、样本长度和状态对 $(x,x')$ 上有所不同：\n- 测试用例 1：$\\beta = 1.0$，提议次数 $N_{\\text{sim}} = 200000$，配对 $(x,x') = (\\text{UU},\\text{UR})$。\n- 测试用例 2：$\\beta = 0.1$，提议次数 $N_{\\text{sim}} = 100000$，配对 $(x,x') = (\\text{RR},\\text{RU})$。\n- 测试用例 3：$\\beta = 3.0$，提议次数 $N_{\\text{sim}} = 150000$，配对 $(x,x') = (\\text{UU},\\text{RR})$。\n\n对于每个测试用例，返回一个布尔值，指示 $\\widehat{R}(x,x')$ 的 $95\\%$ 置信区间是否包含 $1$。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，“[true,false,true]”，但使用 Python 布尔值大写形式），并严格按照上面列出的测试用例的顺序。不涉及物理单位；所有量纲均为无量纲。不使用角度。不得使用百分比；所有分数量必须表示为小数。",
            "solution": "该问题要求为构型偏置蒙特卡洛（CBMC）再生长移动推导 Metropolis-Hastings 接受概率，并随后对细致平衡条件进行数值验证。\n\n首先，我们建立理论基础。马尔可夫链蒙特卡洛（MCMC）模拟的目标是生成一系列从正则玻尔兹曼分布 $\\pi(x) \\propto \\exp(-\\beta U(x))$ 中抽样的状态 $x$，其中 $U(x)$ 是状态 $x$ 的能量，$\\beta$ 是逆温度。链的平稳分布为 $\\pi(x)$ 的一个充分条件是细致平衡原理，该原理指出对于任何两个状态 $x$ 和 $x'$，稳态转移速率必须相等：\n$$\n\\pi(x) P(x \\to x') = \\pi(x') P(x' \\to x)\n$$\n在这里，$P(x \\to x')$ 是从状态 $x$ 到 $x'$ 的一步转移概率。在 Metropolis-Hastings 算法中，此转移概率是提议概率 $q(x \\to x')$ 和接受概率 $A(x \\to x')$ 的乘积：$P(x \\to x') = q(x \\to x') A(x \\to x')$。接受概率旨在强制实现细致平衡，其公式为：\n$$\nA(x \\to x') = \\min\\left(1, \\frac{\\pi(x') q(x' \\to x)}{\\pi(x) q(x \\to x')}\\right)\n$$\n\n该系统由一个两步聚合物链组成，步长方向为 $d_1, d_2 \\in \\{\\text{U}, \\text{R}\\}$。四种可能的状态是 $x_{\\text{UU}}=(\\text{U},\\text{U})$、$x_{\\text{UR}}=(\\text{U},\\text{R})$、$x_{\\text{RU}}=(\\text{R},\\text{U})$ 和 $x_{\\text{RR}}=(\\text{R},\\text{R})$。能量函数为 $U(x) = \\varepsilon_{d_1} + \\varepsilon_{d_2} + \\text{bend}(d_1,d_2)$，其中 $\\varepsilon_{\\text{U}}=0$，$\\varepsilon_{\\text{R}}=0.5$，弯曲惩罚 $\\text{bend}(d_1, d_2)$ 在 $d_1 \\neq d_2$ 时为 $1$，否则为 $0$。这四种状态的能量为：\n- $U(x_{\\text{UU}}) = \\varepsilon_{\\text{U}} + \\varepsilon_{\\text{U}} + \\text{bend}(\\text{U},\\text{U}) = 0 + 0 + 0 = 0$\n- $U(x_{\\text{UR}}) = \\varepsilon_{\\text{U}} + \\varepsilon_{\\text{R}} + \\text{bend}(\\text{U},\\text{R}) = 0 + 0.5 + 1 = 1.5$\n- $U(x_{\\text{RU}}) = \\varepsilon_{\\text{R}} + \\varepsilon_{\\text{U}} + \\text{bend}(\\text{R},\\text{U}) = 0.5 + 0 + 1 = 1.5$\n- $U(x_{\\text{RR}}) = \\varepsilon_{\\text{R}} + \\varepsilon_{\\text{R}} + \\text{bend}(\\text{R},\\text{R}) = 0.5 + 0.5 + 0 = 1.0$\n\n提议机制是链的完全再生长。这意味着提议状态 $x'$ 是从头开始生成的，独立于当前状态 $x$。因此，提议分布 $q(x \\to x')$ 仅是提议状态 $x'$ 的函数，我们称之为 $g(x')$。生成特定新链 $x'=(d'_1, d'_2)$ 的概率是选择每一步的概率的乘积，由 CBMC 过程定义：\n$$\ng(x') = \\left( \\frac{\\exp(-\\beta \\varepsilon_{d'_1})}{W_1} \\right) \\left( \\frac{\\exp(-\\beta(\\varepsilon_{d'_2} + \\text{bend}(d'_1, d'_2)))}{W_2(d'_1)} \\right)\n$$\n其中 $W_1$ 和 $W_2(d'_1)$ 分别是第一和第二生长阶段的 Rosenbluth 权重。合并各项，我们得到 $g(x') = \\frac{\\exp(-\\beta U(x'))}{W_1 W_2(d'_1)}$。让我们将生成构型 $x'=(d'_1, d'_2)$ 的总 Rosenbluth 权重定义为 $W(x') = W_1 W_2(d'_1)$。因此，提议概率为 $g(x') = \\exp(-\\beta U(x')) / W(x')$。\n\n对于此独立采样器，$q(x \\to x') = g(x')$ 且反向提议概率为 $q(x' \\to x) = g(x)$。将这些以及 $\\pi(x) \\propto \\exp(-\\beta U(x))$ 代入 Metropolis-Hastings 接受规则：\n$$\nA(x \\to x') = \\min\\left(1, \\frac{\\exp(-\\beta U(x')) g(x)}{\\exp(-\\beta U(x)) g(x')}\\right) = \\min\\left(1, \\frac{\\exp(-\\beta U(x')) [\\exp(-\\beta U(x))/W(x)]}{\\exp(-\\beta U(x)) [\\exp(-\\beta U(x'))/W(x')]}\\right)\n$$\n$$\nA(x \\to x') = \\min\\left(1, \\frac{W(x')}{W(x)}\\right)\n$$\n这是 CBMC 完全再生长移动的标准接受概率。构型 $x=(d_1, d_2)$ 的 Rosenbluth 权重为 $W(x) = W_1 W_2(d_1)$。\n$W_1 = \\exp(-\\beta \\varepsilon_{\\text{U}}) + \\exp(-\\beta \\varepsilon_{\\text{R}}) = 1 + \\exp(-0.5\\beta)$。\n第二阶段权重 $W_2(d_1)$ 取决于第一步 $d_1$：\n- 对于 $d_1 = \\text{U}$：$W_2(\\text{U}) = \\exp(-\\beta(\\varepsilon_{\\text{U}} + 0)) + \\exp(-\\beta(\\varepsilon_{\\text{R}} + 1)) = 1 + \\exp(-\\beta(0.5+1)) = 1 + \\exp(-1.5\\beta)$。\n- 对于 $d_1 = \\text{R}$：$W_2(\\text{R}) = \\exp(-\\beta(\\varepsilon_{\\text{U}} + 1)) + \\exp(-\\beta(\\varepsilon_{\\text{R}} + 0)) = \\exp(-\\beta) + \\exp(-0.5\\beta)$。\n由于 $W(x')/W(x) = (W_1 W_2(d'_1))/(W_1 W_2(d_1)) = W_2(d'_1)/W_2(d_1)$，接受概率简化为：\n$$\nA(x \\to x') = \\min\\left(1, \\frac{W_2(d'_1)}{W_2(d_1)}\\right)\n$$\n其中 $d_1$ 是旧状态 $x$ 的第一步，$d'_1$ 是提议状态 $x'$ 的第一步。\n\n为了数值验证细致平衡，我们对马尔可夫链进行大量步数 $N_{\\text{sim}}$ 的模拟。我们记录从每个状态 $x$ 提出提议的次数，记为 $N(x)$，以及从 $x$ 到 $x'$ 的接受转移次数，记为 $K(x \\to x')$。转移概率 $P(x \\to x')$ 使用 Jeffreys 平滑估计器进行估计：\n$$\n\\widehat{P}(x \\to x') = \\frac{K(x \\to x') + 0.5}{N(x) + 1}\n$$\n细致平衡要求 $\\pi(x) P(x \\to x') = \\pi(x') P(x' \\to x)$，或者等效地，比率 $R(x,x') = \\frac{\\pi(x) P(x \\to x')}{\\pi(x') P(x' \\to x)}$ 必须等于 $1$。我们通过构建经验比率来检验这一点：\n$$\n\\widehat{R}(x,x') = \\frac{\\pi(x) \\widehat{P}(x \\to x')}{\\pi(x') \\widehat{P}(x' \\to x)} = \\frac{\\exp(-\\beta U(x)) \\widehat{P}(x \\to x')}{\\exp(-\\beta U(x')) \\widehat{P}(x' \\to x)} = \\exp\\big(-\\beta(U(x) - U(x'))\\big)\\cdot \\frac{\\widehat{P}(x \\to x')}{\\widehat{P}(x' \\to x)}\n$$\n我们在对数空间中分析这个比率，因为这将乘积转换为和，从而简化了方差计算。对数比率为 $\\log\\widehat{R}(x,x') = -\\beta(U(x) - U(x')) + \\log\\widehat{P}(x \\to x') - \\log\\widehat{P}(x' \\to x)$。我们在 $0.95$ 的置信水平上为 $\\log\\widehat{R}(x,x')$ 构建一个置信区间。概率估计器对数的方差使用 delta 方法近似，具体如下：\n$$\n\\operatorname{Var}\\big(\\log \\widehat{P}(x \\to x')\\big) \\approx \\frac{1 - \\widehat{P}(x \\to x')}{\\widehat{P}(x \\to x')\\cdot (N(x) + 1)}\n$$\n假设正向和反向转移估计是独立的，它们的方差相加：$\\operatorname{Var}(\\log \\widehat{R}) \\approx \\operatorname{Var}(\\log \\widehat{P}(x \\to x')) + \\operatorname{Var}(\\log \\widehat{P}(x' \\to x))$。$\\log\\widehat{R}$ 的置信区间为 $[\\log\\widehat{R} - z_{0.975} \\sigma_{\\log\\widehat{R}}, \\log\\widehat{R} + z_{0.975} \\sigma_{\\log\\widehat{R}}]$，其中 $\\sigma_{\\log\\widehat{R}}$ 是标准差，$z_{0.975} \\approx 1.96$ 是标准正态分布的临界值。如果此区间包含 $0$，则认为细致平衡得到验证，这等效于 $\\widehat{R}$ 的置信区间包含 $1$。\n\n实现过程将首先为这 4 个状态设置常量。然后，对于每个测试用例，它将运行 MCMC 模拟。在每一步中，通过两阶段 CBMC 生长过程提出一个新状态，使用 $W_2$ 权重的比率计算接受概率，并接受或拒绝该移动。相应地更新 $N(x)$ 和 $K(x \\to x')$ 的计数器。模拟结束后，对指定的配对 $(x, x')$ 进行统计分析，以确定对数比率的置信区间是否包含 $0$。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the problem by running simulations for three test cases\n    and checking the detailed balance condition.\n    \"\"\"\n    test_cases = [\n        (1.0, 200000, ('UU', 'UR')),\n        (0.1, 100000, ('RR', 'RU')),\n        (3.0, 150000, ('UU', 'RR')),\n    ]\n\n    results = []\n    for beta, n_sim, pair in test_cases:\n        result = run_and_analyze_case(beta, n_sim, pair)\n        results.append(result)\n\n    # Format the final output as a string with Python boolean capitalization.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_and_analyze_case(beta, n_sim, pair):\n    \"\"\"\n    Runs a single test case simulation and performs the statistical analysis.\n    \"\"\"\n    # State mapping and properties\n    states_map = {'UU': 0, 'UR': 1, 'RU': 2, 'RR': 3}\n    energies = np.array([0.0, 1.5, 1.5, 1.0])\n    first_steps = ['U', 'U', 'R', 'R']  # d_1 for each state index\n\n    # Pre-calculate values dependent on beta\n    exp_m05b = np.exp(-0.5 * beta)\n    exp_m10b = np.exp(-1.0 * beta)\n    exp_m15b = np.exp(-1.5 * beta)\n    \n    # Rosenbluth weights for the second step\n    w2_vals = {\n        'U': 1.0 + exp_m15b,\n        'R': exp_m10b + exp_m05b\n    }\n\n    # Proposal probabilities for CBMC regrowth\n    p_d1_U = 1.0 / (1.0 + exp_m05b)\n    p_d2_U_given_d1_U = 1.0 / w2_vals['U']\n    p_d2_U_given_d1_R = exp_m10b / w2_vals['R']\n\n    def propose_new_state():\n        # Step 1: Propose d1\n        d1_prime = 'U' if np.random.rand()  p_d1_U else 'R'\n        \n        # Step 2: Propose d2\n        if d1_prime == 'U':\n            d2_prime = 'U' if np.random.rand()  p_d2_U_given_d1_U else 'R'\n        else:  # d1_prime == 'R'\n            d2_prime = 'U' if np.random.rand()  p_d2_U_given_d1_R else 'R'\n            \n        return states_map[d1_prime + d2_prime]\n\n    # MCMC Simulation\n    # Start at an arbitrary state (e.g., UU)\n    current_state_idx = states_map['UU']\n    # N(x): number of proposals from state x\n    N_counts = np.zeros(4, dtype=np.int64)\n    # K(x -> x'): number of accepted transitions\n    K_counts = np.zeros((4, 4), dtype=np.int64)\n\n    for _ in range(n_sim):\n        old_state_idx = current_state_idx\n        N_counts[old_state_idx] += 1\n\n        proposed_state_idx = propose_new_state()\n        \n        # Acceptance probability: min(1, W2(d'_1) / W2(d_1))\n        d1_old = first_steps[old_state_idx]\n        d1_new = first_steps[proposed_state_idx]\n        \n        w2_old = w2_vals[d1_old]\n        w2_new = w2_vals[d1_new]\n\n        acceptance_prob = min(1.0, w2_new / w2_old)\n\n        if np.random.rand()  acceptance_prob:\n            # Accept the move\n            current_state_idx = proposed_state_idx\n            K_counts[old_state_idx, proposed_state_idx] += 1\n        else:\n            # Reject the move, stay in the same state\n            K_counts[old_state_idx, old_state_idx] += 1\n            # current_state_idx remains old_state_idx\n\n    # Post-simulation analysis for the specified pair (x, x')\n    x_name, xp_name = pair\n    x_idx, xp_idx = states_map[x_name], states_map[xp_name]\n\n    # Jeffreys smoothed estimators for transition probabilities\n    N_x = N_counts[x_idx]\n    N_xp = N_counts[xp_idx]\n    \n    K_x_to_xp = K_counts[x_idx, xp_idx]\n    K_xp_to_x = K_counts[xp_idx, x_idx]\n    \n    # +1 ensures no division by zero if a state is never visited (unlikely for large n_sim)\n    p_hat_fwd = (K_x_to_xp + 0.5) / (N_x + 1)\n    p_hat_rev = (K_xp_to_x + 0.5) / (N_xp + 1)\n    \n    # Log of the empirical ratio R_hat\n    U_x = energies[x_idx]\n    U_xp = energies[xp_idx]\n    log_R_hat = -beta * (U_x - U_xp) + np.log(p_hat_fwd) - np.log(p_hat_rev)\n\n    # Variance of log_R_hat using the provided formula\n    var_log_p_fwd = (1.0 - p_hat_fwd) / (p_hat_fwd * (N_x + 1.0))\n    var_log_p_rev = (1.0 - p_hat_rev) / (p_hat_rev * (N_xp + 1.0))\n    \n    var_log_R_hat = var_log_p_fwd + var_log_p_rev\n    std_log_R_hat = np.sqrt(var_log_R_hat)\n    \n    # Construct 95% CI for log(R_hat)\n    z_score = norm.ppf(0.975)  # for 95% confidence\n    ci_lower = log_R_hat - z_score * std_log_R_hat\n    ci_upper = log_R_hat + z_score * std_log_R_hat\n    \n    # Check if the CI for log(R) contains 0 (which means CI for R contains 1)\n    return (ci_lower = 0) and (ci_upper >= 0)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}