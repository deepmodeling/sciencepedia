{
    "hands_on_practices": [
        {
            "introduction": "To build a solid understanding of any numerical integrator, it is essential to first analyze its behavior on a simple, solvable system. This exercise challenges you to apply the velocity Verlet algorithm to the simple harmonic oscillator, a foundational model in physics. By deriving the explicit $2 \\times 2$ matrix that propagates the system's state in phase space, you will translate the sequence of algorithmic steps into the language of linear algebra, providing a clear and exact picture of how the integrator advances position and velocity over a single timestep .",
            "id": "3852924",
            "problem": "In multiscale materials simulation, time-reversible and symplectic integrators such as the Verlet family are used to advance atomistic and coarse-grained dynamical variables while controlling long-time drift in conserved quantities. Consider a single coarse mode modeled as a harmonic oscillator with mass $m$ and stiffness $k$, governed by Newton’s second law $m\\,\\ddot{x}(t)=-k\\,x(t)$. Let the discrete time-step be $\\Delta t>0$, and define the force $F(x)=-k\\,x$ and the acceleration $a(x)=F(x)/m$.\n\nStarting from the phase-space state $(x_n,v_n)$ at time $t_n$, advance the system by one step using the velocity Verlet algorithm, defined by the following sequence applied over one step of size $\\Delta t$:\n- position update: $x_{n+1}=x_n+\\Delta t\\,v_n+\\tfrac{1}{2}(\\Delta t)^2\\,a(x_n)$,\n- acceleration refresh: $a(x_{n+1})=a(x)$ evaluated at $x=x_{n+1}$,\n- velocity update: $v_{n+1}=v_n+\\tfrac{1}{2}\\Delta t\\left[a(x_n)+a(x_{n+1})\\right]$.\n\nUsing only the definitions above and Newton’s second law, derive explicit closed-form expressions for $x_{n+1}$ and $v_{n+1}$ in terms of $x_n$, $v_n$, $m$, $k$, and $\\Delta t$. Then collect these into a single linear map written as a $2\\times 2$ matrix $A(\\Delta t)$ such that\n$$\n\\begin{pmatrix}\nx_{n+1}\\\\\nv_{n+1}\n\\end{pmatrix}\n=A(\\Delta t)\n\\begin{pmatrix}\nx_n\\\\\nv_n\n\\end{pmatrix}.\n$$\nExpress your final matrix in terms of the natural frequency $\\omega=\\sqrt{k/m}$ and $\\Delta t$, simplified as much as possible. Provide only the matrix $A(\\Delta t)$ as your final answer. No numerical evaluation is required, and no rounding is needed.",
            "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It provides a complete and consistent set of definitions for the velocity Verlet algorithm applied to a harmonic oscillator and asks for a specific, derivable result. All necessary information is provided, and the task is a standard exercise in computational physics. Therefore, the problem is valid, and a solution will be derived.\n\nThe objective is to find the $2 \\times 2$ matrix $A(\\Delta t)$ that represents the one-step propagator for the velocity Verlet algorithm applied to a simple harmonic oscillator. The state vector at step $n$ is given by $\\begin{pmatrix} x_n \\\\ v_n \\end{pmatrix}$. The updated state vector is $\\begin{pmatrix} x_{n+1} \\\\ v_{n+1} \\end{pmatrix} = A(\\Delta t) \\begin{pmatrix} x_n \\\\ v_n \\end{pmatrix}$.\n\nThe governing equation of motion for the harmonic oscillator is Newton's second law:\n$$m\\,\\ddot{x}(t) = -k\\,x(t)$$\nThe force is $F(x) = -k\\,x$, and the acceleration is $a(x) = F(x)/m = -k\\,x/m$.\nWe define the natural frequency of the oscillator as $\\omega = \\sqrt{k/m}$, so the acceleration can be written as:\n$$a(x) = -\\omega^2 x$$\nThis implies that the accelerations at times $t_n$ and $t_{n+1}$ are $a(x_n) = a_n = -\\omega^2 x_n$ and $a(x_{n+1}) = a_{n+1} = -\\omega^2 x_{n+1}$, respectively.\n\nThe velocity Verlet algorithm is defined by the following sequence of updates:\n1.  Position update: $x_{n+1} = x_n + \\Delta t\\,v_n + \\frac{1}{2}(\\Delta t)^2\\,a_n$\n2.  Velocity update: $v_{n+1} = v_n + \\frac{1}{2}\\Delta t\\left[a_n + a_{n+1}\\right]$\n\nWe will now derive explicit expressions for $x_{n+1}$ and $v_{n+1}$ in terms of $x_n$ and $v_n$.\n\nFirst, we find the expression for $x_{n+1}$. We substitute $a_n = -\\omega^2 x_n$ into the position update equation:\n$$x_{n+1} = x_n + \\Delta t\\,v_n + \\frac{1}{2}(\\Delta t)^2 (-\\omega^2 x_n)$$\nGrouping terms by $x_n$ and $v_n$:\n$$x_{n+1} = \\left(1 - \\frac{1}{2}\\omega^2 (\\Delta t)^2\\right) x_n + (\\Delta t) v_n$$\nThis equation gives the first row of the matrix $A(\\Delta t)$. The components are:\n$$A_{11} = 1 - \\frac{1}{2}\\omega^2 (\\Delta t)^2$$\n$$A_{12} = \\Delta t$$\n\nNext, we find the expression for $v_{n+1}$. We substitute the expressions for acceleration, $a_n = -\\omega^2 x_n$ and $a_{n+1} = -\\omega^2 x_{n+1}$, into the velocity update equation:\n$$v_{n+1} = v_n + \\frac{1}{2}\\Delta t\\left[-\\omega^2 x_n - \\omega^2 x_{n+1}\\right]$$\n$$v_{n+1} = v_n - \\frac{1}{2}\\omega^2 \\Delta t (x_n + x_{n+1})$$\nThis expression for $v_{n+1}$ currently depends on $x_{n+1}$. To obtain an expression solely in terms of the state at time $t_n$, $(x_n, v_n)$, we must substitute the previously derived expression for $x_{n+1}$:\n$$v_{n+1} = v_n - \\frac{1}{2}\\omega^2 \\Delta t \\left[ x_n + \\left( \\left(1 - \\frac{1}{2}\\omega^2 (\\Delta t)^2\\right) x_n + (\\Delta t) v_n \\right) \\right]$$\nNow, we simplify the term in the square brackets:\n$$x_n + \\left(1 - \\frac{1}{2}\\omega^2 (\\Delta t)^2\\right) x_n + (\\Delta t) v_n = \\left(2 - \\frac{1}{2}\\omega^2 (\\Delta t)^2\\right) x_n + (\\Delta t) v_n$$\nSubstituting this back into the equation for $v_{n+1}$:\n$$v_{n+1} = v_n - \\frac{1}{2}\\omega^2 \\Delta t \\left[ \\left(2 - \\frac{1}{2}\\omega^2 (\\Delta t)^2\\right) x_n + (\\Delta t) v_n \\right]$$\nDistribute the term $-\\frac{1}{2}\\omega^2 \\Delta t$ across the bracket:\n$$v_{n+1} = v_n - \\left( \\frac{1}{2}\\omega^2 \\Delta t \\cdot 2 - \\frac{1}{2}\\omega^2 \\Delta t \\cdot \\frac{1}{2}\\omega^2 (\\Delta t)^2 \\right) x_n - \\left( \\frac{1}{2}\\omega^2 \\Delta t \\cdot \\Delta t \\right) v_n$$\n$$v_{n+1} = v_n - \\left( \\omega^2 \\Delta t - \\frac{1}{4}\\omega^4 (\\Delta t)^3 \\right) x_n - \\frac{1}{2}\\omega^2 (\\Delta t)^2 v_n$$\nFinally, we group terms by $x_n$ and $v_n$:\n$$v_{n+1} = \\left( -\\omega^2 \\Delta t + \\frac{1}{4}\\omega^4 (\\Delta t)^3 \\right) x_n + \\left( 1 - \\frac{1}{2}\\omega^2 (\\Delta t)^2 \\right) v_n$$\nThis equation gives the second row of the matrix $A(\\Delta t)$. The components are:\n$$A_{21} = -\\omega^2 \\Delta t + \\frac{1}{4}\\omega^4 (\\Delta t)^3 = -\\omega^2 \\Delta t \\left(1 - \\frac{1}{4}\\omega^2 (\\Delta t)^2\\right)$$\n$$A_{22} = 1 - \\frac{1}{2}\\omega^2 (\\Delta t)^2$$\nThe expression for $A_{21}$ is simplified by factoring out $-\\omega^2 \\Delta t$.\n\nCombining these results, the linear map is:\n$$\n\\begin{pmatrix}\nx_{n+1}\\\\\nv_{n+1}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 - \\frac{1}{2}\\omega^2 (\\Delta t)^2 & \\Delta t \\\\\n-\\omega^2 \\Delta t \\left(1 - \\frac{1}{4}\\omega^2 (\\Delta t)^2\\right) & 1 - \\frac{1}{2}\\omega^2 (\\Delta t)^2\n\\end{pmatrix}\n\\begin{pmatrix}\nx_n\\\\\nv_n\n\\end{pmatrix}\n$$\nThus, the matrix $A(\\Delta t)$ is:\n$$\nA(\\Delta t) =\n\\begin{pmatrix}\n1 - \\frac{1}{2}\\omega^2 (\\Delta t)^2 & \\Delta t \\\\\n-\\omega^2 \\Delta t \\left(1 - \\frac{1}{4}\\omega^2 (\\Delta t)^2\\right) & 1 - \\frac{1}{2}\\omega^2 (\\Delta t)^2\n\\end{pmatrix}\n$$\nThis is the final, simplified form of the matrix expressed in terms of $\\omega$ and $\\Delta t$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 - \\frac{1}{2}\\omega^{2} (\\Delta t)^{2} & \\Delta t \\\\\n-\\omega^{2} \\Delta t \\left(1 - \\frac{1}{4}\\omega^{2} (\\Delta t)^{2}\\right) & 1 - \\frac{1}{2}\\omega^{2} (\\Delta t)^{2}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A key reason for the Verlet family's success in molecular dynamics is its excellent long-term stability, which stems from properties like time-reversibility. This hands-on coding practice moves beyond linear systems to the nonlinear pendulum, where you will numerically verify this crucial property . By simulating the pendulum's motion forward in time and then reversing the process, you can directly observe the algorithm's ability to return to the initial state with high precision, building intuition for why it is so robust for complex, long-duration simulations.",
            "id": "2420944",
            "problem": "You are to study the undamped, nonlinear simple pendulum with angular displacement $\\theta(t)$ governed by the second-order ordinary differential equation $\\ddot{\\theta}(t) + \\dfrac{g}{L}\\sin(\\theta(t)) = 0$, where $g$ is the gravitational acceleration and $L$ is the pendulum length. Angles must be expressed in radians, time in seconds, and angular velocity $\\dot{\\theta}$ in radians per second. The task is to demonstrate the time-reversibility of a symplectic, second-order update scheme by evolving the system from an initial state forward in time for a fixed number of steps and then evolving backward to return to the initial state, and to quantify the deviation from the initial state after the forward-then-backward evolution.\n\nDefine the following:\n- The state is $(\\theta,\\dot{\\theta})$ with $\\theta \\in \\mathbb{R}$ and $\\dot{\\theta} \\in \\mathbb{R}$.\n- The angular acceleration function is $a(\\theta) = -\\dfrac{g}{L}\\sin(\\theta)$.\n- The forward evolution consists of $N$ discrete time steps of size $\\Delta t$, where $N$ is a positive integer and $T = N\\,\\Delta t$ is the total simulated time.\n- The backward evolution consists of $N$ steps that exactly reverse the forward evolution in the sense of time-reversal symmetry: from the terminal state $(\\theta_T,\\dot{\\theta}_T)$ of the forward evolution, reverse the velocity to $-\\dot{\\theta}_T$, then apply the same $N$ steps and finally re-reverse the velocity to compare with the initial state $(\\theta_0,\\dot{\\theta}_0)$.\n\nMeasure the final deviation using a dimensionless error defined as follows. Let $\\omega_0 = \\sqrt{g/L}$ be the small-angle natural frequency. Let $\\Delta \\theta$ be the principal-value angular difference between the recovered angle and the initial angle, reduced to $(-\\pi,\\pi]$ by adding an integer multiple of $2\\pi$ if necessary. Let $\\Delta \\dot{\\theta}$ be the difference between the recovered angular velocity and the initial angular velocity. Define the dimensionless error\n$$\nE = \\sqrt{(\\Delta \\theta)^2 + \\left(\\dfrac{\\Delta \\dot{\\theta}}{\\omega_0}\\right)^2}.\n$$\nAngles must be in radians, angular velocities in radians per second, $\\omega_0$ in radians per second, so that $E$ is dimensionless. Your program must compute $E$ for each test case listed below.\n\nTest suite. For each test case, use the parameters $(g, L, \\theta_0, \\dot{\\theta}_0, T, \\Delta t)$ as specified, all in International System of Units (SI) and with angles in radians. For every test, $T/\\Delta t$ is an integer.\n- Test 1 (small-angle, typical step): $g = 9.81\\ \\mathrm{m/s^2}$, $L = 1.0\\ \\mathrm{m}$, $\\theta_0 = 0.2\\ \\mathrm{rad}$, $\\dot{\\theta}_0 = 0.0\\ \\mathrm{rad/s}$, $T = 10.0\\ \\mathrm{s}$, $\\Delta t = 0.005\\ \\mathrm{s}$.\n- Test 2 (large-angle near the upright, fine step): $g = 9.81\\ \\mathrm{m/s^2}$, $L = 1.0\\ \\mathrm{m}$, $\\theta_0 = 2.9\\ \\mathrm{rad}$, $\\dot{\\theta}_0 = 0.0\\ \\mathrm{rad/s}$, $T = 10.0\\ \\mathrm{s}$, $\\Delta t = 0.001\\ \\mathrm{s}$.\n- Test 3 (nonzero initial velocity): $g = 9.81\\ \\mathrm{m/s^2}$, $L = 0.7\\ \\mathrm{m}$, $\\theta_0 = 0.0\\ \\mathrm{rad}$, $\\dot{\\theta}_0 = 1.5\\ \\mathrm{rad/s}$, $T = 12.0\\ \\mathrm{s}$, $\\Delta t = 0.002\\ \\mathrm{s}$.\n- Test 4 (coarse step near linear stability boundary): $g = 9.81\\ \\mathrm{m/s^2}$, $L = 2.0\\ \\mathrm{m}$, $\\theta_0 = 0.01\\ \\mathrm{rad}$, $\\dot{\\theta}_0 = 0.0\\ \\mathrm{rad/s}$, $T = 18.0\\ \\mathrm{s}$, $\\Delta t = 0.9\\ \\mathrm{s}$.\n\nYour program must:\n- Implement the undamped nonlinear pendulum dynamics as stated.\n- Perform for each test: forward evolution for $N = T/\\Delta t$ steps, then backward evolution as described, then compute the dimensionless error $E$ defined above.\n- Aggregate the results as a single line of output containing the list of errors for the tests in the order given above, rounded to $12$ significant digits and printed as decimal numbers in scientific notation.\n\nFinal output format. Your program should produce a single line containing the results as a comma-separated list enclosed in square brackets, for example, $\"[e_1,e_2,e_3,e_4]\"$, where each $e_k$ is the dimensionless error for test $k$ as defined above and formatted in scientific notation with $12$ significant digits.",
            "solution": "The problem statement is valid. It describes a well-posed numerical experiment in computational physics, grounded in the standard principles of classical mechanics and numerical analysis.\n\nThe physical system under consideration is the simple nonlinear pendulum, whose motion is governed by the second-order ordinary differential equation:\n$$\n\\ddot{\\theta}(t) + \\frac{g}{L}\\sin(\\theta(t)) = 0\n$$\nwhere $\\theta(t)$ is the angular displacement, $g$ is the acceleration due to gravity, and $L$ is the length of the pendulum. This equation can be written as a system of two first-order equations by defining the state vector $(\\theta, \\dot{\\theta})$:\n$$\n\\begin{cases}\n\\frac{d\\theta}{dt} = \\dot{\\theta} \\\\\n\\frac{d\\dot{\\theta}}{dt} = -\\frac{g}{L}\\sin(\\theta)\n\\end{cases}\n$$\nThis system describes motion in a two-dimensional phase space. It is a Hamiltonian system, meaning its dynamics conserve a quantity, the specific energy (energy per unit mass), given by $E = \\frac{1}{2}L^2\\dot{\\theta}^2 - gL\\cos(\\theta)$. Numerical methods for integrating such systems should ideally preserve the geometric properties of the flow in phase space. Symplectic integrators are designed for this purpose. They do not necessarily conserve energy exactly, but they do conserve a nearby \"shadow\" Hamiltonian, which prevents long-term drift in energy and ensures the preservation of phase space volume. A key property of many symplectic integrators is time-reversibility. An algorithm is time-reversible if evolving forward by one time step from state $(\\theta_n, \\dot{\\theta}_n)$ to $(\\theta_{n+1}, \\dot{\\theta}_{n+1})$, and then evolving forward by one time step from a time-reversed state $(\\theta_{n+1}, -\\dot{\\theta}_{n+1})$, results in the state $(\\theta_n, -\\dot{\\theta}_n)$.\n\nThe problem requires the use of a second-order, symplectic update scheme. The Velocity Verlet algorithm is a standard and appropriate choice. It is a member of the Verlet integration family, known for its good stability and symplectic nature when applied to Hamiltonian systems of the form $\\ddot{\\mathbf{q}} = \\mathbf{F}(\\mathbf{q})$. For our pendulum system with state $(\\theta, \\dot{\\theta})$ and acceleration $a(\\theta) = -\\frac{g}{L}\\sin(\\theta)$, a single integration step from time $t_n$ to $t_{n+1} = t_n + \\Delta t$ proceeds as follows:\n$1$. First, compute the velocity at the midpoint of the time interval:\n$$\n\\dot{\\theta}_{n+1/2} = \\dot{\\theta}_n + a(\\theta_n) \\frac{\\Delta t}{2}\n$$\n$2$. Next, update the position using this midpoint velocity:\n$$\n\\theta_{n+1} = \\theta_n + \\dot{\\theta}_{n+1/2} \\, \\Delta t\n$$\n$3$. Finally, update the velocity to the end of the interval using the new position $\\theta_{n+1}$:\n$$\n\\dot{\\theta}_{n+1} = \\dot{\\theta}_{n+1/2} + a(\\theta_{n+1}) \\frac{\\Delta t}{2}\n$$\nThis algorithm is explicitly time-reversible and second-order accurate in $\\Delta t$.\n\nTo demonstrate the time-reversibility of the numerical simulation, the following procedure is implemented for each test case:\n$1$. **Forward Evolution:** The system is evolved from the initial state $(\\theta_0, \\dot{\\theta}_0)$ for a total time $T$ using $N = T/\\Delta t$ steps of the Velocity Verlet algorithm. This yields the final state $(\\theta_T, \\dot{\\theta}_T)$.\n$2$. **Backward Evolution:** To reverse the process, we begin from the state $(\\theta_T, -\\dot{\\theta}_T)$—note the reversal of velocity. We then apply the *same* Velocity Verlet algorithm for another $N$ steps. This produces a state $(\\theta'_{\\text{rec}}, \\dot{\\theta}'_{\\text{rec}})$.\n$3$. **Final State Recovery:** The final velocity is reversed again to obtain the recovered state $(\\theta_{\\text{rec}}, \\dot{\\theta}_{\\text{rec}}) = (\\theta'_{\\text{rec}}, -\\dot{\\theta}'_{\\text{rec}})$. In exact arithmetic, due to the time-reversibility of the algorithm, we would have $(\\theta_{\\text{rec}}, \\dot{\\theta}_{\\text{rec}}) = (\\theta_0, \\dot{\\theta}_0)$. In practice, floating-point round-off errors will cause a small deviation.\n\nThe deviation is quantified by the dimensionless error $E$:\n$$\nE = \\sqrt{(\\Delta \\theta)^2 + \\left(\\frac{\\Delta \\dot{\\theta}}{\\omega_0}\\right)^2}\n$$\nwhere $\\omega_0 = \\sqrt{g/L}$ is the natural frequency of small-angle oscillations. The differences are $\\Delta \\dot{\\theta} = \\dot{\\theta}_{\\text{rec}} - \\dot{\\theta}_0$ and $\\Delta \\theta$, which is the principal-value angular difference, calculated as $\\Delta\\theta_{\\text{raw}} = \\theta_{\\text{rec}} - \\theta_0$ and then mapped to the interval $(-\\pi, \\pi]$. This is robustly computed using the two-argument arctangent function: $\\Delta\\theta = \\text{atan2}(\\sin(\\Delta\\theta_{\\text{raw}}), \\cos(\\Delta\\theta_{\\text{raw}}))$.\n\nThe implementation follows these steps precisely for each of the provided test cases. The resulting error $E$ is a measure of the accumulated floating-point inaccuracies, which are expected to be small, confirming the excellent numerical stability and reversibility of the symplectic integrator. The final program implements this complete procedure. For each test case, it sets up the parameters, runs the forward-then-backward simulation, calculates the error, and formats the result as specified. A function implementing the Velocity Verlet steps is created. It is called twice for each test case: once for the forward evolution and once for the backward evolution. The calculated errors for all test cases are collected and printed in the required format. The numerical values obtained should be very small, confirming that the deviation from perfect time-reversal is on the order of machine precision, as expected for a correctly implemented time-reversible algorithm.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the time-reversibility error for the nonlinear pendulum simulation\n    using a symplectic Velocity Verlet integrator.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (g, L, theta_0, v_theta_0, T, dt)\n        # Test 1\n        (9.81, 1.0, 0.2, 0.0, 10.0, 0.005),\n        # Test 2\n        (9.81, 1.0, 2.9, 0.0, 10.0, 0.001),\n        # Test 3\n        (9.81, 0.7, 0.0, 1.5, 12.0, 0.002),\n        # Test 4\n        (9.81, 2.0, 0.01, 0.0, 18.0, 0.9),\n    ]\n\n    results = []\n\n    def run_simulation(theta_init, v_theta_init, g, L, dt, N):\n        \"\"\"\n        Evolves the pendulum state for N steps using the Velocity Verlet algorithm.\n        \n        Args:\n            theta_init (float): Initial angle in radians.\n            v_theta_init (float): Initial angular velocity in rad/s.\n            g (float): Gravitational acceleration in m/s^2.\n            L (float): Pendulum length in m.\n            dt (float): Time step in s.\n            N (int): Number of steps.\n\n        Returns:\n            tuple[float, float]: Final angle and angular velocity.\n        \"\"\"\n        theta = theta_init\n        v_theta = v_theta_init\n        accel_factor = -g / L\n\n        for _ in range(N):\n            # Velocity Verlet half-step for velocity\n            v_theta_half = v_theta + 0.5 * dt * accel_factor * np.sin(theta)\n            # Full-step for position\n            theta = theta + dt * v_theta_half\n            # Second half-step for velocity, using the updated position\n            v_theta = v_theta_half + 0.5 * dt * accel_factor * np.sin(theta)\n        \n        return theta, v_theta\n\n    for case in test_cases:\n        g, L, theta_0, v_theta_0, T, dt = case\n        \n        # Number of steps. The problem guarantees T/dt is an integer.\n        N = int(round(T / dt))\n\n        # 1. Forward evolution from initial state (theta_0, v_theta_0)\n        theta_T, v_theta_T = run_simulation(theta_0, v_theta_0, g, L, dt, N)\n\n        # 2. Backward evolution\n        # Initial state for backward run: reverse velocity at the end of forward run\n        theta_B0 = theta_T\n        v_theta_B0 = -v_theta_T\n        \n        # Evolve \"forward\" in time from this new state\n        theta_rec_raw, v_theta_rec_raw = run_simulation(theta_B0, v_theta_B0, g, L, dt, N)\n        \n        # The true recovered state is obtained by re-reversing the final velocity\n        theta_rec = theta_rec_raw\n        v_theta_rec = -v_theta_rec_raw\n\n        # 3. Calculate dimensionless error E\n        omega_0 = np.sqrt(g / L)\n        \n        # Calculate deviation from initial state\n        delta_v_theta = v_theta_rec - v_theta_0\n        \n        # Calculate raw angular difference. Angle can wrap around many times.\n        delta_theta_raw = theta_rec - theta_0\n        \n        # Normalize angular difference to the principal-value interval (-pi, pi]\n        delta_theta = np.arctan2(np.sin(delta_theta_raw), np.cos(delta_theta_raw))\n        \n        # Calculate dimensionless error\n        E = np.sqrt(delta_theta**2 + (delta_v_theta / omega_0)**2)\n        results.append(E)\n\n    # Format output as specified: a list of errors in scientific notation with 12 significant digits.\n    # The format specifier {:.11e} gives 1 digit before the decimal and 11 after,\n    # totaling 12 significant digits for a normalized scientific number.\n    formatted_results = [\"{:.11e}\".format(r) for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "In modern multiscale simulations, computational performance is as important as algorithmic correctness. This advanced practice explores the practical challenges of implementing the velocity Verlet integrator efficiently on high-performance hardware like multicore CPUs and GPUs . You are asked to analyze different implementation strategies, weighing trade-offs between data layout, memory access patterns, and synchronization to maximize performance while strictly preserving the mathematical invariants that guarantee physical fidelity. This exercise bridges the gap between numerical theory and the real-world demands of large-scale scientific computing.",
            "id": "3852918",
            "problem": "You are implementing the velocity Verlet integrator for large-scale conservative molecular dynamics in the context of multiscale materials simulation on both a Central Processing Unit (CPU) and a Graphics Processing Unit (GPU). The system consists of particles with positions $\\mathbf{r}_i$, velocities $\\mathbf{v}_i$, masses $m_i$, and forces $\\mathbf{f}_i(\\{\\mathbf{r}\\})$ derived from a time-independent potential, so that Newton’s second law applies, $m_i \\, d\\mathbf{v}_i/dt = \\mathbf{f}_i(\\{\\mathbf{r}\\})$, and the kinematic definition $d\\mathbf{r}_i/dt = \\mathbf{v}_i$ holds. The velocity Verlet algorithm is defined by a symmetric half-step–drift–half-step splitting that preserves time reversibility and symplectic structure when forces are evaluated at consistent positions at times $t$ and $t+\\Delta t$.\n\nYou are given a neighbor list with a cut-off and a buffer (skin), where the neighborhood of particle $i$ is stored in a compressed sparse row layout with a head array $\\text{head}[i]$ and a contiguous list $\\text{nl}[k]$ of neighbor indices, so that the neighbors of $i$ are in $\\text{nl}[k]$ for $k \\in [\\text{head}[i], \\text{head}[i+1})$. You must choose a loop structure and data layout that are cache-friendly on a CPU and GPU-friendly on a Single Instruction Multiple Threads (SIMT) architecture, while minimizing global memory traffic and preserving the algorithmic invariants of velocity Verlet. You may assume that the potential is pairwise and depends only on positions, and that the neighbor list is valid over several steps.\n\nWhich option best outlines such a loop structure and memory layout, together with the reasoning about memory traffic minimization and preservation of invariants?\n\nA. Use a Structure of Arrays (SoA) layout for particle data, with arrays $\\text{x}[\\cdot], \\text{y}[\\cdot], \\text{z}[\\cdot], \\text{vx}[\\cdot], \\text{vy}[\\cdot], \\text{vz}[\\cdot], \\text{fx}[\\cdot], \\text{fy}[\\cdot], \\text{fz}[\\cdot]$. On the GPU, launch $N$ threads and execute $2$ kernels per time step: Kernel $1$ performs, for each $i$, the half-kick and drift, reading $\\mathbf{f}_i(t)$, $\\mathbf{v}_i(t)$, $\\mathbf{r}_i(t)$ and writing $\\mathbf{v}_i(t+\\tfrac{\\Delta t}{2})$ and $\\mathbf{r}_i(t+\\Delta t)$. Kernel $2$ reads $\\mathbf{r}_i(t+\\Delta t)$ into registers, loops over $j \\in \\mathcal{N}(i)$ from the full neighbor list (each pair is visited twice, once as $(i,j)$ and once as $(j,i)$), loads $\\mathbf{r}_j(t+\\Delta t)$ via a read-only cache, accumulates $\\mathbf{f}_i(t+\\Delta t)$ in registers without any writes or atomics inside the inner loop, then completes the second half-kick $\\mathbf{v}_i(t+\\Delta t) = \\mathbf{v}_i(t+\\tfrac{\\Delta t}{2}) + \\tfrac{\\Delta t}{2 m_i}\\,\\mathbf{f}_i(t+\\Delta t)$ and finally writes $\\mathbf{f}_i(t+\\Delta t)$ for the next step. The kernel boundary provides a global synchronization, ensuring that all $\\mathbf{r}_i(t+\\Delta t)$ are consistent before force evaluation, preserving the integrator’s invariants. The SoA layout coalesces loads/stores of $\\mathbf{r}$ and $\\mathbf{v}$ across threads, the full neighbor list avoids atomic updates and scattered writes, and holding $\\mathbf{f}_i$ in registers until the end minimizes global memory traffic to a single write per particle for $\\mathbf{f}_i$ and avoids per-pair stores. On the CPU, use the same two-pass ordering with SoA to exploit spatial locality of $\\text{nl}[\\cdot]$ and hardware prefetching.\n\nB. Fuse all stages in a single GPU kernel to reduce kernel launch overhead. For each thread (particle $i$), read $\\mathbf{f}_i(t)$, $\\mathbf{v}_i(t)$, $\\mathbf{r}_i(t)$, perform the half-kick and drift to get $\\mathbf{r}_i(t+\\Delta t)$, then immediately loop over neighbors $j \\in \\mathcal{N}(i)$ to compute and accumulate $\\mathbf{f}_i(t+\\Delta t)$. Use only block-level synchronization (e.g., $\\_\\_syncthreads$) between the drift and force loops; finish with the second half-kick and write back $\\mathbf{v}_i(t+\\Delta t)$ and $\\mathbf{f}_i(t+\\Delta t)$. The neighbor list is a half-list (each pair stored once) to halve the arithmetic, and forces on $j$ are applied with atomic adds to $\\mathbf{f}_j$ in global memory to enforce Newton’s third law.\n\nC. To maximize arithmetic intensity, move the second half-kick inside the inner neighbor loop on the GPU: after computing a pair force $\\mathbf{f}_{ij}$ for the current $(i,j)$, immediately update $\\mathbf{v}_i$ by $\\tfrac{\\Delta t}{2 m_i}\\,\\mathbf{f}_{ij}$, and update $\\mathbf{v}_j$ by $-\\tfrac{\\Delta t}{2 m_j}\\,\\mathbf{f}_{ij}$ using atomic adds; at the end of the loop, write $\\mathbf{f}_i(t+\\Delta t)$ accumulated so far. Use an Array of Structures (AoS) layout to keep $\\{\\mathbf{r}_i,\\mathbf{v}_i,\\mathbf{f}_i\\}$ adjacent in memory for each particle, reducing pointer arithmetic.\n\nD. On the CPU, interleave position updates and force computation in a single pass over $i$: for each $i$, perform the half-kick and drift to compute $\\mathbf{r}_i(t+\\Delta t)$, then loop over $j \\in \\mathcal{N}(i)$ and compute pair forces using whichever of $\\mathbf{r}_i$ or $\\mathbf{r}_j$ are most recently updated (so some pairs use $\\mathbf{r}(t)$ for one particle and $\\mathbf{r}(t+\\Delta t)$ for the other), writing $\\mathbf{f}_i$ and $\\mathbf{f}_j$ to memory after each pair. Use AoS to improve locality for per-particle data, and use a full neighbor list to avoid atomics.",
            "solution": "The user requires a critical evaluation of a molecular dynamics implementation problem, focusing on the velocity Verlet algorithm for CPU and GPU architectures. The primary task is to validate the problem statement and then, if valid, identify the best implementation strategy among the given options.\n\n### Problem Validation\n\nFirst, I will deconstruct and validate the problem statement.\n\n**Step 1: Extract Givens**\n\n*   **Algorithm**: Velocity Verlet integrator for a conservative molecular dynamics system.\n*   **Equations of Motion**: $m_i \\frac{d\\mathbf{v}_i}{dt} = \\mathbf{f}_i(\\{\\mathbf{r}\\})$ and $\\frac{d\\mathbf{r}_i}{dt} = \\mathbf{v}_i$.\n*   **Potential**: Time-independent, pairwise, and position-dependent.\n*   **System**: Particles with positions $\\mathbf{r}_i$, velocities $\\mathbf{v}_i$, and masses $m_i$.\n*   **Velocity Verlet Properties**: Described as a symmetric half-step–drift–half-step splitting that preserves time reversibility and symplectic structure.\n*   **Force Evaluation Constraint**: Forces must be evaluated at consistent positions at times $t$ and $t+\\Delta t$.\n*   **Hardware Targets**: Central Processing Unit (CPU) and Graphics Processing Unit (GPU) with a Single Instruction Multiple Threads (SIMT) architecture.\n*   **Data Structures**: A neighbor list with a cut-off and buffer skin, stored in a compressed sparse row (CSR) format ($\\text{head}[i]$, $\\text{nl}[k]$).\n*   **Optimization Goals**:\n    1.  Cache-friendly on CPU.\n    2.  GPU-friendly (SIMT).\n    3.  Minimize global memory traffic.\n    4.  Preserve algorithmic invariants of velocity Verlet.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientific Groundedness**: The problem statement is firmly rooted in the principles of classical mechanics and computational physics. The velocity Verlet algorithm is a standard, robust numerical integrator for Newton's equations of motion. The hardware considerations (CPU/GPU, SoA/AoS, memory coalescing, atomics) are central topics in high-performance scientific computing. The description is scientifically and technically sound.\n*   **Well-Posedness**: The problem is well-posed. It presents a clear objective: identify the best implementation strategy from a set of options, based on a combination of correctness (preserving invariants) and performance (cache-friendliness, memory traffic, architectural suitability). The criteria for \"best\" are clearly specified.\n*   **Objectivity**: The language is precise and unbiased. All terms used, such as \"symplectic structure,\" \"time reversibility,\" \"SoA,\" \"SIMT,\" and \"global memory traffic,\" have objective, well-defined meanings in the relevant fields.\n\nThe problem statement does not exhibit any of the invalidity flaws:\n1.  **Scientific or Factual Unsoundness**: No violations of physics or computer science principles are present.\n2.  **Non-Formalizable or Irrelevant**: The problem is directly and technically relevant to the implementation of multiscale materials simulations.\n3.  **Incomplete or Contradictory Setup**: The setup is complete and self-consistent. The constraints and goals are clearly defined.\n4.  **Unrealistic or Infeasible**: The scenario is highly realistic and represents a standard problem faced by developers of simulation software like LAMMPS, GROMACS, or OpenMM.\n5.  **Ill-Posed or Poorly Structured**: The terminology is standard and unambiguous.\n6.  **Pseudo-Profound, Trivial, or Tautological**: The problem addresses complex and non-trivial trade-offs in algorithm implementation for high-performance computing.\n7.  **Outside Scientific Verifiability**: The claims in the options are verifiable through implementation, profiling, and numerical analysis.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. I will proceed to derive the solution and evaluate the options.\n\n### Derivation and Option Analysis\n\nThe velocity Verlet algorithm has a strict sequential and symmetric structure that must be respected to maintain its desirable properties (time-reversibility, symplecticity, and long-term energy conservation for conservative systems). The standard form is:\n\n1.  **Velocity Half-Kick**: Update velocities by a half-step using forces at time $t$.\n    $$ \\mathbf{v}_i(t + \\tfrac{\\Delta t}{2}) = \\mathbf{v}_i(t) + \\frac{\\mathbf{f}_i(t)}{2m_i} \\Delta t $$\n2.  **Position Drift**: Update positions by a full step using the new half-step velocities.\n    $$ \\mathbf{r}_i(t + \\Delta t) = \\mathbf{r}_i(t) + \\mathbf{v}_i(t + \\tfrac{\\Delta t}{2}) \\Delta t $$\n3.  **Synchronization**: A critical, implicit step. ALL particle positions $\\{\\mathbf{r}_i(t + \\Delta t)\\}$ must be known before proceeding.\n4.  **Force Calculation**: Compute new forces $\\mathbf{f}_i(t + \\Delta t)$ using the fully updated set of positions $\\{\\mathbf{r}_k(t + \\Delta t)\\}$.\n5.  **Velocity Half-Kick**: Complete the velocity update using the new forces.\n    $$ \\mathbf{v}_i(t + \\Delta t) = \\mathbf{v}_i(t + \\tfrac{\\Delta t}{2}) + \\frac{\\mathbf{f}_i(t+\\Delta t)}{2m_i} \\Delta t $$\n\nA key invariant is that the force calculation in step $4$ must operate on a globally consistent state where every particle's position corresponds to time $t+\\Delta t$. Any implementation that violates this by using a mixture of positions from times $t$ and $t+\\Delta t$ will break the algorithm's invariants. On a massively parallel architecture like a GPU, this necessitates a global synchronization barrier between the position update phase (step $2$) and the force calculation phase (step $4$). A kernel launch boundary provides such a barrier.\n\n**Option-by-Option Analysis**\n\n**A. Use a Structure of Arrays (SoA) layout... launch $N$ threads and execute $2$ kernels per time step...**\n\n*   **Data Layout**: Structure of Arrays (SoA) ($\\text{x}[\\cdot]$, $\\text{y}[\\cdot]$, etc.) is specified. For a GPU's SIMT architecture, where adjacent threads (e.g., threads $0, 1, 2, ..., 31$) process adjacent particles (particles $0, 1, 2, ..., 31$), accessing a single component like $\\text{x}[\\cdot]$ results in contiguous memory access. This allows the hardware to \"coalesce\" these multiple small reads into a single, wide memory transaction, which is the most efficient way to access global memory. This is an optimal choice for GPUs and also benefits CPU vectorization (SIMD).\n*   **Loop Structure**: Two kernels are used. Kernel $1$ performs the first half-kick and the full drift. Kernel $2$ performs the force calculation and the second half-kick. The boundary between these two kernels provides the **essential global synchronization**. It guarantees that all threads have completed writing the new positions $\\mathbf{r}_i(t+\\Delta t)$ before any thread begins to read them for force calculation. This correctly preserves the integrator's invariants.\n*   **Force Calculation**: A full neighbor list is used. This means each pair interaction $(i,j)$ is computed twice (once by thread $i$ and once by thread $j$). While computationally redundant, it means that thread $i$ only needs to read neighbor data and only ever writes to its own force accumulator, $\\mathbf{f}_i$. This accumulator can be held in fast registers during the neighbor loop, and the final result is written to global memory only once. This strategy completely avoids the need for slow,-contention-inducing atomic operations on forces.\n*   **Memory Traffic**: The combination of SoA for coalescing, register accumulation of forces, and a two-kernel structure that minimizes writes constitutes a state-of-the-art, memory-efficient design.\n*   **Verdict**: This option correctly identifies and respects the algorithmic invariants. It proposes a data layout and loop structure that are optimal for both performance (memory coalescing, minimized traffic, avoidance of atomics) and correctness on the target architectures. **Correct**.\n\n**B. Fuse all stages in a single GPU kernel to reduce kernel launch overhead... Use only block-level synchronization...**\n\n*   **Synchronization**: This option explicitly mentions using only block-level synchronization (`__syncthreads`). This type of synchronization only works for threads within the same execution block (typically $32-1024$ threads). It does *not* synchronize threads across different blocks. Therefore, a thread in block $0$ calculating forces has no guarantee that a particle whose data is handled by a thread in block $1$ has finished its position update. This leads to forces being computed on a mixture of old and new positions, which fatally violates the symplectic and time-reversible nature of the velocity Verlet algorithm. The energy of the system will not be conserved.\n*   **Force Calculation**: The use of a half-list and atomic adds is a valid implementation pattern but cannot salvage the fundamental flaw in synchronization.\n*   **Verdict**: The proposed loop fusion with inadequate synchronization breaks the algorithm. **Incorrect**.\n\n**C. To maximize arithmetic intensity, move the second half-kick inside the inner neighbor loop... Use an Array of Structures (AoS) layout...**\n\n*   **Algorithmic Structure**: This option proposes updating the velocity $\\mathbf{v}_i$ immediately after each pairwise force $\\mathbf{f}_{ij}$ is computed. The second half-kick requires the *total* force on particle $i$, $\\mathbf{f}_i(t+\\Delta t) = \\sum_j \\mathbf{f}_{ij}$. Applying partial updates from individual pair forces breaks the symmetric structure of the Verlet integrator. This is mathematically incorrect.\n*   **Data Layout**: It suggests an Array of Structures (AoS) layout. For GPUs, this is highly inefficient. When adjacent threads access, for example, the x-component of position, they access memory locations separated by the size of the entire structure (e.g., `particle[i].x`, `particle[i+1].x`, etc.). This strided access pattern defeats memory coalescing and leads to poor performance.\n*   **Verdict**: This option proposes an algorithm that is mathematically incorrect and a data layout that is ill-suited for the target GPU architecture. **Incorrect**.\n\n**D. On the CPU, interleave position updates and force computation in a single pass... using whichever of $\\mathbf{r}_i$ or $\\mathbf{r}_j$ are most recently updated...**\n\n*   **Algorithmic Structure**: This explicitly describes a \"mixed-timestep\" force calculation. When computing the force between particles $i$ and $j$, if the loop has already processed $i$ but not yet $j$, the calculation would use $\\mathbf{r}_i(t+\\Delta t)$ and $\\mathbf{r}_j(t)$. As explained for option B, this violates the requirement of a consistent state for the force evaluation and breaks the conservation properties of the integrator. This is sometimes known as a Gauss-Seidel-type update, which is not appropriate for conservative NVE simulations.\n*   **Memory Traffic**: It also suggests writing forces to memory after each pair interaction. This would result in an enormous number of small memory writes, leading to extremely poor performance, orders of magnitude worse than accumulating in registers and writing once per particle.\n*   **Verdict**: This option describes a method that is both algorithmically incorrect for this context and highly inefficient. **Incorrect**.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}