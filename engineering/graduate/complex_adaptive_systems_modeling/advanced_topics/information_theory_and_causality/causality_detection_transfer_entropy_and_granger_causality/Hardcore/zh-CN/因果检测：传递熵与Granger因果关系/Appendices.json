{
    "hands_on_practices": [
        {
            "introduction": "在应用格兰杰因果关系（Granger Causality）和传递熵（Transfer Entropy）等因果发现方法之前，一个关键的前提是确保我们的模型描述了一个平稳过程。对于向量自回归（VAR）模型，系统的稳定性决定了其是否具有平稳分布，这可以通过分析其伴随矩阵的特征值来检验。本练习将指导您从第一性原理出发，构建VAR($p$)过程的伴随矩阵，并利用其谱半径来评估模型稳定性，这是任何基于VAR的因果分析中必不可少的第一步。",
            "id": "4116835",
            "problem": "给定一组向量自回归模型，您必须通过构建和分析块伴随矩阵的特征值来判断它们的稳定性，此过程需使用基于线性系统概念的原则性推导。其背景是复杂自适应系统建模，其中格兰杰因果关系（Granger causality, GC）和传递熵（transfer entropy, TE）等因果检测方法依赖于底层多元时间序列存在平稳分布。一个$k$维过程的$p$阶向量自回归（Vector Autoregression, VAR）由基本关系 $X_t = \\sum_{i=1}^{p} A_i X_{t-i} + \\varepsilon_t$ 定义，其中 $X_t \\in \\mathbb{R}^k$ 是状态， $A_i \\in \\mathbb{R}^{k \\times k}$ 是系数矩阵，而 $\\varepsilon_t$ 是零均值白噪声。在一个通过状态增广获得的稳定线性时不变（LTI）实现中，状态转移矩阵的所有特征值都严格位于复平面的单位圆内。您的任务是，对每个给定的模型，从第一性原理出发推导并构建相应的块伴随矩阵，然后计算其特征值以评估稳定性。根据以下基于谱半径的规则对每个模型进行分类：如果特征值的最大模严格小于$1$，则分类为稳定；如果在容差$\\tau$范围内等于$1$，则分类为临界；如果大于$1$，则分类为不稳定。与$1$比较时，使用$\\tau = 10^{-10}$的数值比较容差。每个测试用例的最终输出必须是一个包含两项的列表，其中包括一个整数分类代码和一个浮点数谱半径，其中稳定编码为$1$，临界编码为$0$，不稳定编码为$-1$。谱半径必须四舍五入到$6$位小数。\n\n实现算法以：\n- 根据VAR$(p)$定义构建块伴随矩阵$C \\in \\mathbb{R}^{kp \\times kp}$，\n- 计算$C$的所有特征值，\n- 计算谱半径，即这些特征值模的最大值，\n- 使用上述相对于单位圆的阈值规则对稳定性进行分类。\n\n测试套件：\n- 情况$1$（理想情况，VAR$(1)$，明显稳定）：$k = 2$, $p = 1$, $A_1 = \\begin{bmatrix} 0.5  0.0 \\\\ 0.0  0.3 \\end{bmatrix}$。\n- 情况$2$（临界，单位根恰好在单位圆上）：$k = 2$, $p = 2$, $A_1 = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  0.2 \\end{bmatrix}$, $A_2 = \\begin{bmatrix} 0.0  0.0 \\\\ 0.0  0.0 \\end{bmatrix}$。\n- 情况$3$（不稳定，单位圆外）：$k = 2$, $p = 2$, $A_1 = \\begin{bmatrix} 1.1  0.0 \\\\ 0.0  0.9 \\end{bmatrix}$, $A_2 = \\begin{bmatrix} 0.0  0.0 \\\\ 0.0  0.0 \\end{bmatrix}$。\n- 情况$4$（具有交叉滞后相互作用和复数特征值的边界情况，预期为稳定）：$k = 3$, $p = 2$, $A_1 = \\begin{bmatrix} 0.5  0.1  0.0 \\\\ 0.0  0.4  0.2 \\\\ 0.0  0.0  0.3 \\end{bmatrix}$, $A_2 = \\begin{bmatrix} -0.1  0.0  0.0 \\\\ 0.0  -0.2  0.0 \\\\ 0.0  0.0  -0.1 \\end{bmatrix}$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个元素对应一个测试用例，并且本身是一个两项列表 $[c, r]$，其中 $c \\in \\{-1, 0, 1\\}$ 是分类代码，$r$ 是四舍五入到$6$位小数的谱半径。例如，总体输出的结构应类似于 $[[c_1, r_1],[c_2, r_2],[c_3, r_3],[c_4, r_4]]$。\n\n本问题不涉及物理单位。也不涉及角度。",
            "solution": "该问题要求评估几个向量自回归（VAR）模型的稳定性。如果一个VAR过程是协方差平稳的，那么它就是稳定的。这一性质对于格兰杰因果关系和传递熵等因果检测方法的有效应用至关重要，因为这些方法依赖于底层时间序列存在平稳分布。VAR($p$)过程的稳定性由其关联的块伴随矩阵的特征值决定。当且仅当该矩阵的所有特征值都严格位于复平面的单位圆内时，该过程是稳定的。\n\n我们的任务是从第一性原理出发推导这个伴随矩阵的结构，为每个给定的模型构建它，计算其特征值，确定谱半径（最大特征值模），并根据该半径是小于、等于还是大于$1$来对模型的稳定性进行分类。\n\n**1. 块伴随矩阵的推导**\n\n一个$k$维的$p$阶VAR过程，记为VAR($p$)，由以下线性递推关系定义：\n$$\nX_t = \\sum_{i=1}^{p} A_i X_{t-i} + \\varepsilon_t\n$$\n其中 $X_t \\in \\mathbb{R}^k$ 是时间$t$的状态向量，$A_i \\in \\mathbb{R}^{k \\times k}$ 是系数矩阵，$\\varepsilon_t \\in \\mathbb{R}^k$ 是一个零均值白噪声项的向量。\n\n通过增广状态向量以包含过去的值，这个$p$阶系统可以转换为一个等价的一阶系统（一个VAR(1)过程）。让我们定义一个新的增广状态向量 $Y_t \\in \\mathbb{R}^{kp}$，它堆叠了当前状态 $X_t$ 及其最近的 $p-1$ 个滞后值：\n$$\nY_t = \\begin{bmatrix}\nX_t \\\\\nX_{t-1} \\\\\n\\vdots \\\\\nX_{t-p+1}\n\\end{bmatrix}\n$$\n我们的目标是找到一个状态转移矩阵 $C$，使得 $Y_t$ 遵循一阶递推关系 $Y_t = C Y_{t-1} + E_t$，其中 $E_t$ 是一个相应的噪声向量。向量 $Y_{t-1}$ 是：\n$$\nY_{t-1} = \\begin{bmatrix}\nX_{t-1} \\\\\nX_{t-2} \\\\\n\\vdots \\\\\nX_{t-p}\n\\end{bmatrix}\n$$\n现在我们可以构建 $Y_t$ 和 $Y_{t-1}$ 之间的关系：\n\n- $Y_t$ 的第一个块行是 $X_t$。根据VAR($p$)的定义，我们有：\n  $X_t = A_1 X_{t-1} + A_2 X_{t-2} + \\dots + A_p X_{t-p} + \\varepsilon_t$。这个方程将 $Y_t$ 的前 $k$ 个分量表示为 $Y_{t-1}$ 分量的线性组合。\n\n- $Y_t$ 的第二个块行是 $X_{t-1}$。根据定义，这正是 $Y_{t-1}$ 的第一个块行。因此，$X_{t-1} = I_k X_{t-1}$，其中 $I_k$ 是 $k \\times k$ 的单位矩阵。\n\n- $Y_t$ 的第三个块行是 $X_{t-2}$，这是 $Y_{t-1}$ 的第二个块行。\n\n- 这个模式一直持续到 $Y_t$ 的最后一个块行，即 $X_{t-p+1}$，它对应于 $Y_{t-1}$ 的第 $(p-1)$ 个块行。\n\n将这些关系合并成一个单一的矩阵方程，我们得到：\n$$\n\\begin{bmatrix}\nX_t \\\\\nX_{t-1} \\\\\nX_{t-2} \\\\\n\\vdots \\\\\nX_{t-p+1}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nA_1  A_2  \\dots  A_{p-1}  A_p \\\\\nI_k  0_k  \\dots  0_k  0_k \\\\\n0_k  I_k  \\dots  0_k  0_k \\\\\n\\vdots  \\vdots  \\ddots  \\vdots  \\vdots \\\\\n0_k  0_k  \\dots  I_k  0_k\n\\end{bmatrix}\n\\begin{bmatrix}\nX_{t-1} \\\\\nX_{t-2} \\\\\nX_{t-3} \\\\\n\\vdots \\\\\nX_{t-p}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\varepsilon_t \\\\\n0 \\\\\n0 \\\\\n\\vdots \\\\\n0\n\\end{bmatrix}\n$$\n这个方程的形式为 $Y_t = C Y_{t-1} + E_t$，其中 $C$ 是 $kp \\times kp$ 的块伴随矩阵：\n$$\nC = \\begin{bmatrix}\nA_1  A_2  \\dots  A_{p-1}  A_p \\\\\nI_k  0_k  \\dots  0_k  0_k \\\\\n0_k  I_k  \\dots  0_k  0_k \\\\\n\\vdots  \\vdots  \\ddots  \\vdots  \\vdots \\\\\n0_k  0_k  \\dots  I_k  0_k\n\\end{bmatrix}\n$$\n并且 $0_k$ 是 $k \\times k$ 的零矩阵。\n\n**2. 稳定性判据和算法**\n\n原始VAR($p$)过程的稳定性等价于这个增广VAR(1)系统的稳定性。一个离散时间线性时不变系统是稳定的，当且仅当其状态转移矩阵的所有特征值的模严格小于$1$。伴随矩阵 $C$ 的特征值是特征多项式 $\\det(\\lambda^p I_k - \\sum_{i=1}^p \\lambda^{p-i} A_i) = 0$ 的根。\n\n谱半径 $\\rho(C)$ 定义为 $C$ 的所有特征值中的最大模。稳定性条件可以简洁地表述为：\n- 如果 $\\rho(C)  1$，系统是**稳定**的。\n- 如果 $\\rho(C) = 1$，系统处于稳定性的**临界**状态（拥有一个单位根）。\n- 如果 $\\rho(C) > 1$，系统是**不稳定**的。\n\n解决每个测试用例问题的算法如下：\n1.  根据给定的参数 $k$、$p$ 和系数矩阵列表 $\\{A_1, A_2, \\dots, A_p\\}$，构建 $kp \\times kp$ 的块伴随矩阵 $C$。\n    - $C$ 的前 $k$ 行由水平拼接矩阵 $A_1, \\dots, A_p$ 形成。\n    - 对于从$1$到$p-1$的每个块行$j$，在第$j$行和第$j-1$列的块位置（使用基于$0$的块索引）放置一个$k \\times k$的单位矩阵$I_k$。\n2.  使用标准的数值线性代数程序计算矩阵 $C$ 的 $kp$ 个特征值。\n3.  计算每个特征值的模（绝对值）。\n4.  通过找到这些模的最大值来确定谱半径 $\\rho(C)$。\n5.  根据 $\\rho(C)$ 和一个容差 $\\tau = 10^{-10}$ 对模型的稳定性进行分类：\n    - 如果 $|\\rho(C) - 1.0| \\le \\tau$，分类为**临界**（代码 $0$）。\n    - 如果 $\\rho(C)  1.0$，分类为**稳定**（代码 $1$）。\n    - 如果 $\\rho(C) > 1.0$，分类为**不稳定**（代码 $-1$）。\n6.  将输出格式化为一个包含整数分类代码和四舍五入到$6$位小数的谱半径的列表。\n\n此程序将应用于每个给定的测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the VAR model stability problem for a given suite of test cases.\n    \"\"\"\n\n    def check_var_stability(k, p, a_matrices):\n        \"\"\"\n        Constructs the companion matrix for a VAR(p) model and checks its stability.\n\n        Args:\n            k (int): The dimensionality of the time series.\n            p (int): The order of the VAR model.\n            a_matrices (list of np.ndarray): A list of coefficient matrices [A_1, ..., A_p].\n\n        Returns:\n            list: A list containing [classification_code, spectral_radius].\n                  - classification_code: 1 for stable, 0 for boundary, -1 for unstable.\n                  - spectral_radius: The spectral radius rounded to 6 decimal places.\n        \"\"\"\n        # A VAR(1) model's companion matrix is simply the coefficient matrix itself.\n        if p == 1:\n            companion_matrix = a_matrices[0]\n        else:\n            # General construction for VAR(p) models where p > 1\n            kp_dim = k * p\n            companion_matrix = np.zeros((kp_dim, kp_dim))\n            \n            # The first block row consists of the concatenated A_i matrices.\n            companion_matrix[:k, :] = np.hstack(a_matrices)\n            \n            # The sub-diagonal blocks are identity matrices.\n            # This populates the blocks that propagate the lagged variables.\n            # C[(i+1)k:(i+2)k, ik:(i+1)k] = I_k for i in 0..p-2\n            identity_block = np.eye(k)\n            for i in range(p - 1):\n                row_start = (i + 1) * k\n                row_end = row_start + k\n                col_start = i * k\n                col_end = col_start + k\n                companion_matrix[row_start:row_end, col_start:col_end] = identity_block\n\n        # Compute eigenvalues of the companion matrix\n        eigenvalues = np.linalg.eigvals(companion_matrix)\n\n        # Compute the spectral radius (maximum of the magnitudes of the eigenvalues)\n        spectral_radius = np.max(np.abs(eigenvalues))\n        \n        # Classify stability based on the spectral radius\n        # Use a tolerance tau for comparison with 1.0\n        tolerance = 1e-10\n        if np.abs(spectral_radius - 1.0) = tolerance:\n            # Boundary case\n            classification_code = 0\n        elif spectral_radius  1.0:\n            # Stable case\n            classification_code = 1\n        else: # spectral_radius > 1.0\n            # Unstable case\n            classification_code = -1\n            \n        return [classification_code, round(spectral_radius, 6)]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: k=2, p=1, A_1\n        (2, 1, [np.array([[0.5, 0.0], [0.0, 0.3]])]),\n        \n        # Case 2: k=2, p=2, A_1, A_2\n        (2, 2, [np.array([[1.0, 0.0], [0.0, 0.2]]), \n                np.array([[0.0, 0.0], [0.0, 0.0]])]),\n        \n        # Case 3: k=2, p=2, A_1, A_2\n        (2, 2, [np.array([[1.1, 0.0], [0.0, 0.9]]), \n                np.array([[0.0, 0.0], [0.0, 0.0]])]),\n\n        # Case 4: k=3, p=2, A_1, A_2\n        (3, 2, [np.array([[0.5, 0.1, 0.0], [0.0, 0.4, 0.2], [0.0, 0.0, 0.3]]), \n                np.array([[-0.1, 0.0, 0.0], [0.0, -0.2, 0.0], [0.0, 0.0, -0.1]])])\n    ]\n\n    results = []\n    for k, p, a_mats in test_cases:\n        result = check_var_stability(k, p, a_mats)\n        results.append(result)\n\n    # Format the final output list as a string.\n    # e.g., [[1, 0.5], [0, 1.0], ...] -> \"[[1, 0.500000],[0, 1.000000],...]\"\n    # The float formatting ensures 6 decimal places.\n    result_strings = [f\"[{res[0]}, {res[1]:.6f}]\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在因果推断中，一个常见的陷阱是由共同驱动因素或混杂变量（confounder）导致的伪因果关系。当两个看似无关的变量同时受到一个未被观测到的第三方变量影响时，它们之间可能表现出虚假的统计关联。本练习通过一个模拟场景，生动地展示了一个共同的季节性驱动因素如何在两个独立的时序之间制造出虚假的格兰杰因果关系，并演示了如何通过在模型中恰当地引入季节性项来消除这一假象，从而揭示真实的因果结构。",
            "id": "4116757",
            "problem": "您必须编写一个完整、可运行的程序，构建一个模拟场景。在该场景中，被忽略的季节性会产生伪格兰杰因果关系，然后展示包含季节性项如何消除这种人为现象。此任务必须从复杂自适应系统建模的第一性原理出发解决，使用基于线性自回归和嵌套模型比较的因果关系检测方法。\n\n假设有两个标量随机时间序列 $\\{X_t\\}$ 和 $\\{Y_t\\}$，在整数时间 $t \\in \\{0,1,\\dots,T-1\\}$ 进行采样。存在一个未观测到的季节性驱动因素 $\\{Z_t\\}$，它是确定性的，周期为 $S$，由 $Z_t = \\sin\\!\\left(2\\pi t / S\\right)$ 给出。数据生成过程为\n$$\nX_t = a_x\\, Z_t + \\varepsilon_{x,t},\\qquad Y_t = a_y\\, Z_{t-\\delta} + \\varepsilon_{y,t},\n$$\n其中 $\\varepsilon_{x,t} \\sim \\mathcal{N}(0,\\sigma_x^2)$ 和 $\\varepsilon_{y,t} \\sim \\mathcal{N}(0,\\sigma_y^2)$ 在时间和序列上是独立的，并且从 $\\{X_t\\}$ 到 $\\{Y_t\\}$ 没有直接的因果影响。因此，当忽略 $Z$ 时，$X$ 对 $Y$ 的任何预测能力都必然是由于共同的季节性驱动因素而产生的伪关系。\n\n从 $\\{X_t\\}$ 到 $\\{Y_t\\}$ 的滞后阶数为 $p$ 的格兰杰因果关系定义如下：如果 $\\{X_t\\}$ 的过去值在 $\\{Y_t\\}$ 的过去值之外为 $\\{Y_t\\}$ 提供了统计上显著的增量预测能力，则称 $\\{X_t\\}$ 格兰杰导致 $\\{Y_t\\}$。通过比较在 $t \\in \\{p,\\dots,T-1\\}$ 上关于 $Y_t$ 的两个嵌套线性模型来操作化此定义：\n- 一个受限模型，仅使用 $Y_t$ 的最高 $p$ 阶内生滞后项（以及一个截距），如果包含季节性回归量，则可选择性地用其增强。\n- 一个无约束模型，在受限模型的基础上增加了 $X_t$ 的最高 $p$ 阶滞后项。\n\n使用普通最小二乘法拟合这两个模型，并使用经典的嵌套模型检验，基于增加 $X_t$ 的 $p$ 个滞后预测变量所带来的残差平方和的减少量来构建检验统计量。使用显著性水平 $\\alpha$ 将检验统计量转换为布尔决策：检测到 $X \\to Y$ 或未检测到。您必须使用线性代数和一个在原假设下检验统计量的著名连续参考分布来实现该检验，不得依赖任何外部时间序列库。\n\n您必须运行以下测试套件，其中包含三组参数集，分别用于测试典型情况、滞后阶数的边界条件以及无季节性的边缘情况。对于每种情况，使用给定的参数模拟 $\\{X_t\\}$ 和 $\\{Y_t\\}$，固定一个全局随机种子以确保结果是确定性的，并执行两次从 $X$到 $Y$ 的格兰杰因果关系检验：\n- 一项检验，在受限和无约束模型中都忽略季节性项。\n- 第二项检验，在受限和无约束模型中都包含季节性项，使用基本谐波 $\\sin(2\\pi t/S)$ 和 $\\cos(2\\pi t/S)$ 作为外生回归量。\n\n对于每种情况，产生两个布尔输出：\n- $b_1$：当忽略季节性时，在水平 $\\alpha$ 上是否检测到从 $X$ 到 $Y$ 的格兰杰因果关系。\n- $b_2$：当包含季节性项时，在水平 $\\alpha$ 上是否未检测到从 $X$ 到 $Y$ 的格兰杰因果关系，这表明人为现象已被消除。\n\n使用以下测试套件，其中所有数学常数均已指定：\n- 情况 1：$T=1000$, $S=24$, $a_x=5.0$, $a_y=5.0$, $\\delta=1$, $\\sigma_x=0.3$, $\\sigma_y=0.3$, $p=1$, $\\alpha=0.01$。\n- 情况 2：$T=1000$, $S=24$, $a_x=5.0$, $a_y=5.0$, $\\delta=3$, $\\sigma_x=0.5$, $\\sigma_y=0.5$, $p=1$, $\\alpha=0.01$。\n- 情况 3：$T=1000$, $S=24$, $a_x=0.0$, $a_y=0.0$, $\\delta=1$, $\\sigma_x=1.0$, $\\sigma_y=1.0$, $p=1$, $\\alpha=0.01$。\n\n您的程序必须：\n- 为指定的参数实现数据生成。\n- 实现普通最小二乘法拟合和用于检验滞后阶数 $p$ 的格兰杰因果关系的嵌套模型假设检验，包括有和没有季节性回归量 $\\sin(2\\pi t/S)$ 和 $\\cos(2\\pi t/S)$ 的情况。\n- 使用固定的随机种子以使输出具有确定性。\n- 对于每种情况，返回如上定义的配对 $[b_1,b_2]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须为上述每种情况包含一个双元素列表，按顺序排列。例如，打印的行必须具有“[[b1_case1,b2_case1],[b1_case2,b2_case2],[b1_case3,b2_case3]]”的形式，并使用布尔字面量。",
            "solution": "该问题要求对因果关系检测中的一个关键人为现象进行实证演示：由于未观测到的共同驱动因素（特别是季节性分量）而产生的伪格兰杰因果关系。我们将模拟两个时间序列 $\\{X_t\\}$ 和 $\\{Y_t\\}$，它们之间没有因果联系，但都受到一个共享的正弦信号的影响。然后，我们将展示当此信号从模型中省略时，标准的格兰杰因果关系检验会错误地检测到从 $X$ 到 $Y$ 的因果联系。随后，我们将证明通过在回归模型中适当地包含确定性季节性项，这种伪因果推断会被正确地消除。\n\n### 数据生成过程\n两个标量随机时间序列 $\\{X_t\\}$ 和 $\\{Y_t\\}$（其中 $t \\in \\{0, 1, \\dots, T-1\\}$）根据以下过程生成：\n$$\nZ_t = \\sin\\left(\\frac{2\\pi t}{S}\\right)\n$$\n$$\nX_t = a_x Z_t + \\varepsilon_{x,t}\n$$\n$$\nY_t = a_y Z_{t-\\delta} + \\varepsilon_{y,t}\n$$\n其中 $\\{Z_t\\}$ 是一个周期为 $S$ 的确定性季节性驱动因素。$\\varepsilon_{x,t}$ 和 $\\varepsilon_{y,t}$ 项是独立同分布的高斯白噪声过程，均值为 0，方差分别为 $\\sigma_x^2$ 和 $\\sigma_y^2$。关键在于，该结构规定了从 $\\{X_t\\}$ 到 $\\{Y_t\\}$ 没有直接的因果影响；它们的统计关联完全源于 $\\{Z_t\\}$ 的共同影响。\n\n### 格兰杰因果关系检验公式\n格兰杰因果关系是一种统计假设检验，用于确定一个时间序列是否有助于预测另一个时间序列。我们评估 $\\{X_t\\}$ 的过去值是否包含有助于预测 $\\{Y_t\\}$ 的信息，而这些信息超出了 $\\{Y_t\\}$ 过去值中已包含的信息。这通过使用 F 检验比较两个嵌套的线性自回归模型来形式化。\n\n对于滞后阶数 $p$，模型定义在时间范围 $t \\in \\{p, \\dots, T-1\\}$ 上。\n\n1.  **受限模型 ($M_R$):** 该模型仅将 $Y_t$ 对其自身的过去值（以及一个截距）进行回归。\n    $$\n    Y_t = c + \\sum_{i=1}^{p} \\beta_i Y_{t-i} + \\epsilon_{R,t}\n    $$\n\n2.  **无约束模型 ($M_U$):** 该模型将 $X_t$ 的过去值作为额外的预测变量加入。\n    $$\n    Y_t = c + \\sum_{i=1}^{p} \\beta_i Y_{t-i} + \\sum_{i=1}^{p} \\gamma_i X_{t-i} + \\epsilon_{U,t}\n    $$\n\n该检验的原假设 ($H_0$) 是 $\\{X_t\\}$ 不格兰杰导致 $\\{Y_t\\}$，这对应于滞后的 $X_t$ 变量的所有系数都为零：\n$$\nH_0: \\gamma_1 = \\gamma_2 = \\dots = \\gamma_p = 0\n$$\n\n### 参数估计与假设检验\n两个模型的系数都使用普通最小二乘法 (OLS) 进行估计。对于一个给定的模型 $y = \\mathbf{A}\\boldsymbol{\\theta} + \\boldsymbol{\\epsilon}$，其中 $\\mathbf{y}$ 是因变量的观测向量，$\\mathbf{A}$ 是预测变量的设计矩阵，$\\boldsymbol{\\theta}$ 是系数向量，OLS 估计值为 $\\hat{\\boldsymbol{\\theta}} = (\\mathbf{A}^T\\mathbf{A})^{-1}\\mathbf{A}^T\\mathbf{y}$。\n\n每个模型的拟合优度通过其残差平方和 (RSS) 来衡量，定义为 $RSS = \\sum_{t=p}^{T-1} (Y_t - \\hat{Y}_t)^2$，其中 $\\hat{Y}_t$ 是拟合模型的预测值。设 $RSS_R$ 和 $RSS_U$ 分别为受限模型和无约束模型的 RSS。\n\n构建 F 统计量以检验从 $M_R$ 转换到 $M_U$ 时 RSS 的减少是否显著：\n$$\nF = \\frac{(RSS_R - RSS_U) / q}{RSS_U / (n - k)}\n$$\n其中：\n- $n = T-p$ 是回归中使用的观测数量。\n- $q = p$ 是无约束模型中额外预测变量的数量（即 $H_0$下的约束数量）。\n- $k$ 是无约束模型中预测变量的总数（包括截距）。\n\n在原假设下，该统计量服从自由度为 $q$ 和 $n-k$ 的 F 分布，即 $F(q, n-k)$。我们计算与观测到的 F 统计量相关的 p 值。如果此 p 值小于所选的显著性水平 $\\alpha$，我们拒绝 $H_0$ 并得出结论：$\\{X_t\\}$ 格兰杰导致 $\\{Y_t\\}$。\n\n### 伪因果关系及其修正\n**1. 忽略季节性：**\n当季节性驱动因素被忽略时，$X$ 的过去值，即 $X_{t-i} = a_x Z_{t-i} + \\varepsilon_{x, t-i}$，充当了未观测到的季节性项 $Z_{t-i}$ 的代理变量。由于 $Y_t$ 由 $Z_{t-\\delta}$ 驱动，且不同滞后的正弦波是相关的，因此 $X_{t-i}$ 将与 $Y_t$ 相关。即使在考虑了 $Y$ 的过去值 $Y_{t-i}$ 之后，这种相关性也可能持续存在。因此，向模型中添加滞后的 $X$ 值会显著降低 RSS ($RSS_U \\ll RSS_R$)，导致 F 统计量较大而 p 值较小。这会导致错误地检测到因果关系 ($b_1 = \\text{True}$)。\n\n**2. 包含季节性：**\n为了修正这一点，我们用明确捕捉季节性模式的外生回归量来增强受限和无约束模型。一个周期为 $S$ 的正弦信号可以完全由 $\\sin(2\\pi t/S)$ 和 $\\cos(2\\pi t/S)$ 的线性组合来描述。\n增强后的受限模型变为：\n$$\nY_t = c + \\sum_{i=1}^{p} \\beta_i Y_{t-i} + s_1 \\sin\\left(\\frac{2\\pi t}{S}\\right) + s_2 \\cos\\left(\\frac{2\\pi t}{S}\\right) + \\epsilon'_{R,t}\n$$\n该模型现在可以直接解释来自 $Z_{t-\\delta}$ 的季节性影响，因为 $Z_{t-\\delta} = \\sin(2\\pi(t-\\delta)/S)$ 是 $\\sin$ 和 $\\cos$ 回归量的线性组合。一旦在受限模型中正确地对这种效应进行建模，滞后的 $X_t$ 值（它们是同一季节性信号的含噪版本）将不提供显著的额外预测能力。因此，$RSS_R \\approx RSS_U$，F 统计量很小，p 值很大，我们正确地未能拒绝原假设 ($b_2 = \\text{True}$)。\n\n### 算法实现\n解决方案按以下方式实现：\n1.  **数据生成**：对于每组参数，根据指定的数据生成过程 (DGP) 生成长度为 $T=1000$ 的时间序列 $\\{X_t\\}$ 和 $\\{Y_t\\}$，使用固定的随机种子以保证可复现性。\n2.  **模型设定**：定义两种测试配置：一种不含季节性项，另一种以 $\\sin(2\\pi t/S)$ 和 $\\cos(2\\pi t/S)$ 作为外生回归量。\n3.  **格兰杰因果关系检验**：对于每种配置：\n    a.  构建响应向量 $\\mathbf{y} = [Y_p, \\dots, Y_{T-1}]^T$。\n    b.  基于滞后序列和任何季节性回归量，为受限和无约束模型构建设计矩阵 $\\mathbf{A}_R$ 和 $\\mathbf{A}_U$。\n    c.  使用 `numpy.linalg.lstsq` 找到每个模型的 OLS 系数。\n    d.  手动计算每个模型的 RSS 以确保稳健性。\n    e.  使用 `scipy.stats.f` 的生存函数 (`sf`) 计算 F 统计量及其对应的 p 值。\n    f.  将 p 值与 $\\alpha$ 进行比较，以确定是否检测到因果关系。\n4.  **输出汇编**：对于每个测试用例，将两个布尔结果（$b_1$：无季节性项时检测到因果关系；$b_2$：有季节性项时未检测到因果关系）编译成一个列表。最终输出是这些列表的列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import f\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation and Granger causality tests\n    for the specified test cases.\n    \"\"\"\n    # Fix the random seed for reproducibility.\n    RANDOM_SEED = 42\n    np.random.seed(RANDOM_SEED)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Typical case with seasonality\n        {'T': 1000, 'S': 24, 'a_x': 5.0, 'a_y': 5.0, 'delta': 1, 'sigma_x': 0.3, 'sigma_y': 0.3, 'p': 1, 'alpha': 0.01},\n        # Case 2: Boundary condition with larger lag in seasonal driver\n        {'T': 1000, 'S': 24, 'a_x': 5.0, 'a_y': 5.0, 'delta': 3, 'sigma_x': 0.5, 'sigma_y': 0.5, 'p': 1, 'alpha': 0.01},\n        # Case 3: Edge case with no seasonality (pure noise)\n        {'T': 1000, 'S': 24, 'a_x': 0.0, 'a_y': 0.0, 'delta': 1, 'sigma_x': 1.0, 'sigma_y': 1.0, 'p': 1, 'alpha': 0.01},\n    ]\n\n    final_results = []\n    for params in test_cases:\n        case_results = perform_single_case(**params)\n        final_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\".replace(\"True\", \"true\").replace(\"False\", \"false\"))\n\ndef generate_data(T, S, a_x, a_y, delta, sigma_x, sigma_y):\n    \"\"\"\n    Generates two time series X and Y based on the specified DGP.\n    \"\"\"\n    t = np.arange(T)\n    # Seasonal driver Z_t for X and Z_{t-delta} for Y\n    Z_x = a_x * np.sin(2 * np.pi * t / S)\n    Z_y = a_y * np.sin(2 * np.pi * (t - delta) / S)\n    \n    # Gaussian white noise\n    eps_x = np.random.normal(0, sigma_x, size=T)\n    eps_y = np.random.normal(0, sigma_y, size=T)\n    \n    # Final time series\n    X = Z_x + eps_x\n    Y = Z_y + eps_y\n    \n    return X, Y\n\ndef ols_fit_and_rss(y, A):\n    \"\"\"\n    Performs OLS regression and returns the Residual Sum of Squares (RSS).\n    \"\"\"\n    # Use np.linalg.lstsq for robust OLS solution\n    coeffs, _, _, _ = np.linalg.lstsq(A, y, rcond=None)\n    \n    # Calculate residuals and RSS manually for clarity and robustness\n    predictions = A @ coeffs\n    residuals = y - predictions\n    rss = np.sum(residuals**2)\n    \n    return rss\n\ndef run_granger_test(X, Y, p, S, alpha, include_seasonality):\n    \"\"\"\n    Performs a Granger causality test from X to Y.\n\n    Returns:\n        bool: True if Granger causality is detected at significance alpha.\n    \"\"\"\n    T = len(X)\n    n = T - p  # Number of observations for regression\n\n    # Target variable for regression: Y_t for t in {p, ..., T-1}\n    y_target = Y[p:]\n\n    # --- Construct predictor matrices ---\n\n    # Intercept\n    intercept = np.ones((n, 1))\n\n    # Lags of Y\n    lags_Y_list = [Y[p-i:T-i] for i in range(1, p + 1)]\n    lags_Y = np.vstack(lags_Y_list).T\n\n    # Lags of X\n    lags_X_list = [X[p-i:T-i] for i in range(1, p + 1)]\n    lags_X = np.vstack(lags_X_list).T\n\n    # --- Restricted Model (Y's lags only) ---\n    A_R_components = [intercept, lags_Y]\n    if include_seasonality:\n        t_reg = np.arange(p, T)\n        sin_term = np.sin(2 * np.pi * t_reg / S).reshape(-1, 1)\n        cos_term = np.cos(2 * np.pi * t_reg / S).reshape(-1, 1)\n        A_R_components.extend([sin_term, cos_term])\n    \n    A_R = np.hstack(A_R_components)\n    \n    # --- Unrestricted Model (Y's lags + X's lags) ---\n    A_U = np.hstack([A_R, lags_X])\n\n    # --- Calculate RSS for both models ---\n    RSS_R = ols_fit_and_rss(y_target, A_R)\n    RSS_U = ols_fit_and_rss(y_target, A_U)\n\n    # --- Perform F-test ---\n    k = A_U.shape[1] # Total number of parameters in the unrestricted model\n    q = p            # Number of restrictions (coefficients of lagged X)\n    \n    df1 = q\n    df2 = n - k\n\n    # Ensure df2 is positive\n    if df2 = 0:\n        # This case is unlikely with the given parameters but is good practice\n        return False\n\n    F_statistic = ((RSS_R - RSS_U) / df1) / (RSS_U / df2)\n    \n    p_value = f.sf(F_statistic, df1, df2)\n\n    return p_value  alpha\n\ndef perform_single_case(T, S, a_x, a_y, delta, sigma_x, sigma_y, p, alpha):\n    \"\"\"\n    Runs both Granger causality tests for a single set of parameters.\n    \"\"\"\n    # 1. Generate data\n    X, Y = generate_data(T, S, a_x, a_y, delta, sigma_x, sigma_y)\n\n    # 2. Test without seasonal terms\n    # b1: True if Granger causality IS detected\n    gc_detected_no_season = run_granger_test(X, Y, p, S, alpha, include_seasonality=False)\n    b1 = gc_detected_no_season\n\n    # 3. Test with seasonal terms\n    # b2: True if Granger causality IS NOT detected\n    gc_detected_with_season = run_granger_test(X, Y, p, S, alpha, include_seasonality=True)\n    b2 = not gc_detected_with_season\n\n    return [b1, b2]\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "真实世界系统中的因果链条往往比简单的直接作用更为复杂，常常涉及中介变量（mediator）。区分直接因果（$X \\to Y$）与通过中介变量的间接因果（$X \\to Z \\to Y$）对于理解系统的内在机制至关重要。本练习将探讨一个经典场景：双变量分析错误地暗示了$X$和$Y$之间的直接联系，而一旦我们将中介变量$Z$纳入考量，进行条件因果分析，就能揭示出其背后真实的间接传导路径。",
            "id": "4116778",
            "problem": "考虑一个带有中介变量的复杂自适应系统中的三个离散时间随机过程，对于整数时间索引 $t$ 定义如下：\n$$\nX_t = \\varepsilon^X_t,\\quad Z_t = c\\,X_{t-1} + \\varepsilon^Z_t,\\quad Y_t = d\\,Z_{t-1} + \\varepsilon^Y_t,\n$$\n其中 $\\varepsilon^X_t$、$\\varepsilon^Z_t$ 和 $\\varepsilon^Y_t$ 是相互独立的零均值高斯白噪声新息，其方差分别为 $\\sigma_X^{2}$、$\\sigma_Z^{2}$ 和 $\\sigma_Y^{2}$。假设除了通过中介变量 $Z$ 之外，$X$ 对 $Y$ 没有直接影响。该设定与三元系统 $(X_t,Z_t,Y_t)$ 的一阶向量自回归（VAR）模型一致，并在二元系统 $(X_t,Y_t)$ 中引出了 $X$ 和 $Y$ 之间一个明显的滞后2阶关系。\n\n仅使用基本定义，即Granger因果关系的定义为：包含驱动变量的过去是否能在目标变量自身过去的基础上进一步减少目标变量的均方预测误差；而传递熵（TE）的定义为：在给定目标变量的过去的情况下，从驱动变量的过去到目标变量的现在的条件互信息。请回答以下问题：\n\n1. 从模型结构层面解释，为什么在简化的 $(X_t,Y_t)$ 系统中可以检测到从 $X$ 到 $Y$ 的滞后2阶的二元Granger因果关系，尽管不存在直接的 $X\\to Y$ 边；以及为什么在完整的 $(X_t,Z_t,Y_t)$ 系统中以中介变量 $Z$ 在滞后1阶上为条件会消除这层明显的 $X\\to Y$ Granger因果关系。\n\n2. 对于参数选择 $c=1, d=1, \\sigma_X^{2}=1, \\sigma_Z^{2}=1, \\sigma_Y^{2}=1$，计算简化系统 $(X_t,Y_t)$ 中从 $X$ 到 $Y$ 的滞后2阶的二元传递熵，结果以奈特（nats）为单位。请提供最终的精确解析表达式，不要进行四舍五入。",
            "solution": "该随机过程系统定义如下：\n$$\n\\begin{cases}\nX_t = \\varepsilon^X_t \\\\\nZ_t = c\\,X_{t-1} + \\varepsilon^Z_t \\\\\nY_t = d\\,Z_{t-1} + \\varepsilon^Y_t\n\\end{cases}\n$$\n其中 $\\varepsilon^X_t$、$\\varepsilon^Z_t$ 和 $\\varepsilon^Y_t$ 是相互独立的零均值高斯白噪声过程，其方差分别为 $\\sigma_X^{2}$、$\\sigma_Z^{2}$ 和 $\\sigma_Y^{2}$。\n\n**第一部分：Granger因果关系分析**\n\n从过程 $X$ 到过程 $Y$ 的Granger因果关系存在，条件是 $X$ 的过去包含了有助于预测 $Y$ 的现在的信息，且该信息超出了 $Y$ 自身过去已包含的信息。这可以通过均方预测误差的减少来量化。\n\n首先，我们建立 $Y_t$ 与 $X$ 的过去之间的关系。通过将 $Z_{t-1}$ 的表达式代入 $Y_t$ 的方程，我们得到：\n$$\nY_t = d\\,(c\\,X_{t-2} + \\varepsilon^Z_{t-1}) + \\varepsilon^Y_t = dc\\,X_{t-2} + d\\,\\varepsilon^Z_{t-1} + \\varepsilon^Y_t\n$$\n这个方程揭示了 $Y_t$ 直接受到 $X_{t-2}$ 的影响，从而建立了一个由 $Z$ 介导的、滞后2个时间步的因果联系。\n\n_在 $(X_t, Y_t)$ 系统中的二元Granger因果关系：_\n\n为了评估二元Granger因果关系，我们将仅基于 $Y_t$ 自身过去 $\\mathbf{Y}_{past} = \\{Y_{t-1}, Y_{t-2}, \\dots\\}$ 的预测，与同时基于其自身过去和 $X$ 的过去 $\\mathbf{X}_{past} = \\{X_{t-1}, X_{t-2}, \\dots\\}$ 的预测进行比较。\n仅使用 $Y_t$ 自身过去的最优线性预测器会存在一定的残差。现在，考虑将 $X$ 的过去加入到预测变量集中。从方程 $Y_t = dc\\,X_{t-2} + d\\,\\varepsilon^Z_{t-1} + \\varepsilon^Y_t$ 中，我们看到 $X_{t-2}$ 是 $Y_t$ 的一个分量。为了确定 $X_{t-2}$ 是否提供了 $\\mathbf{Y}_{past}$ 中尚未存在的新信息，我们考察过去 $Y$ 值的构成。例如，\n$$\nY_{t-1} = dc\\,X_{t-3} + d\\,\\varepsilon^Z_{t-2} + \\varepsilon^Y_{t-1}\n$$\n$Y$ 的过去包含了关于 $X$ 在滞后3阶及以上（即 $X_{t-3}, X_{t-4}, \\dots$）的过去的信息，但不包含关于 $X_{t-2}$ 的信息。项 $X_{t-2}$ 相对于 $Y$ 的整个过去历史 $\\mathbf{Y}_{past}$ 是一个独立的随机变量。因此，将 $X_{t-2}$（它是 $\\mathbf{X}_{past}$ 的一部分）包含在 $Y_t$ 的预测模型中，必然会减少预测误差。仅基于 $\\mathbf{Y}_{past}$ 的残差包含了项 $dc\\,X_{t-2}$，通过将 $X_{t-2}$ 作为预测变量，可以从误差项中消除其方差。因此，在二元系统中，$X$ Granger导致 $Y$。依赖关系 $Y_t \\propto X_{t-2}$ 解释了为什么这种因果关系在滞后2阶被检测到。\n\n_在 $(X_t, Z_t, Y_t)$ 系统中的条件Granger因果关系：_\n\n现在，我们以中介过程 $Z$ 为条件。我们评估在 $\\mathbf{Y}_{past}$ 和 $\\mathbf{Z}_{past} = \\{Z_{t-1}, Z_{t-2}, \\dots\\}$ 提供的信息之外，$\\mathbf{X}_{past}$ 是否有助于预测 $Y_t$。$Y_t$ 的控制方程是 $Y_t = d\\,Z_{t-1} + \\varepsilon^Y_t$。这个方程表明，在给定 $Z_{t-1}$ 的情况下，$Y_t$ 的值在新息噪声 $\\varepsilon^Y_t$ 的范围内被确定。由于 $\\varepsilon^Y_t$ 独立于 $X, Y, Z$ 的所有过去值，因此在给定所有三个变量的完整过去历史的情况下，$Y_t$ 的最佳可能线性预测是 $\\hat{Y}_t = d\\,Z_{t-1}$。相应的预测误差就是 $\\varepsilon^Y_t$，其均方误差为 $\\sigma_Y^2$。关键的是，在给定 $Z_{t-1}$ 的条件下，过程 $Y_t$ 与 $X$ 的过去（以及其自身的过去）是条件独立的。即 $p(Y_t | \\mathbf{Y}_{past}, \\mathbf{Z}_{past}, \\mathbf{X}_{past}) = p(Y_t | Z_{t-1})$。\n因为一旦 $\\mathbf{Z}_{past}$（特别是 $Z_{t-1}$）已知，包含 $\\mathbf{X}_{past}$ 并不能为预测 $Y_t$ 提供任何额外信息，所以预测误差不会减少。因此，在给定 $Z$ 的条件下，从 $X$到 $Y$ 的条件Granger因果关系为零。中介变量 $Z$ “屏蔽”了 $X$ 对 $Y$ 的影响，使得当 $Z$ 被观测到时，从 $X$ 到 $Y$ 的直接因果联系（在Granger意义上）为空。\n\n**第二部分：传递熵计算**\n\n给定参数值为 $c=1, d=1, \\sigma_X^{2}=1, \\sigma_Z^{2}=1, \\sigma_Y^{2}=1$。\n系统方程变为：\n$$\n\\begin{cases}\nX_t = \\varepsilon^X_t \\\\\nZ_t = X_{t-1} + \\varepsilon^Z_t \\\\\nY_t = Z_{t-1} + \\varepsilon^Y_t\n\\end{cases}\n$$\n复合关系为 $Y_t = X_{t-2} + \\varepsilon^Z_{t-1} + \\varepsilon^Y_t$。\n\n从 $X$ 到 $Y$ 的传递熵（TE）是条件互信息 $TE_{X \\to Y} = I(Y_t; \\mathbf{X}_{past} | \\mathbf{Y}_{past})$。根据模型结构，$\\mathbf{X}_{past}$ 中唯一携带关于 $Y_t$ 信息的项是 $X_{t-2}$。因此，表达式简化为 $TE_{X \\to Y} = I(Y_t; X_{t-2} | \\mathbf{Y}_{past})$。\n\n对于高斯过程，传递熵可以写成条件方差的形式：\n$$\nTE_{X \\to Y} = \\frac{1}{2} \\ln \\frac{\\text{Var}(Y_t | \\mathbf{Y}_{past})}{\\text{Var}(Y_t | \\mathbf{Y}_{past}, X_{t-2})}\n$$\n让我们分析过程 $Y_t$ 的统计特性。新息 $\\{\\varepsilon^X_t, \\varepsilon^Z_t, \\varepsilon^Y_t\\}$ 对所有时间滞后都是相互独立的。过程 $Y_t = X_{t-2} + \\varepsilon^Z_{t-1} + \\varepsilon^Y_t$ 是独立白噪声过程的和，每个过程都处于唯一的时间滞后。我们来计算 $Y_t$ 在滞后 $k \\ge 1$ 时的自协方差：\n$$\n\\text{Cov}(Y_t, Y_{t-k}) = E[Y_t Y_{t-k}] = E[(X_{t-2} + \\varepsilon^Z_{t-1} + \\varepsilon^Y_t) (X_{t-2-k} + \\varepsilon^Z_{t-1-k} + \\varepsilon^Y_{t-k})]\n$$\n由于所有新息过程都是白噪声且相互独立，该期望中的每个交叉项都为零。例如，因为 $k \\ge 1$，所以 $E[X_{t-2} X_{t-2-k}]=0$。类似地，由于所有新息都是独立的，所以 $E[X_{t-2} \\varepsilon^Z_{t-1-k}]=0$。因此，对于所有 $k \\ge 1$，$\\text{Cov}(Y_t, Y_{t-k}) = 0$。这意味着 $Y_t$ 本身就是一个白噪声过程。\n\n因此，$Y$ 的过去 $\\mathbf{Y}_{past}$ 与其现在 $Y_t$ 是独立的。此外，构成 $\\mathbf{Y}_{past}$ 的新息集合与构成对 $(Y_t, X_{t-2})$ 的新息集合是不相交的。因此，$\\mathbf{Y}_{past}$ 与 $(Y_t, X_{t-2})$ 是独立的。这使得在传递熵表达式中以 $\\mathbf{Y}_{past}$ 为条件是无意义的：\n$$\nTE_{X \\to Y} = I(Y_t; X_{t-2} | \\mathbf{Y}_{past}) = I(Y_t; X_{t-2})\n$$\n问题简化为计算 $Y_t$ 和 $X_{t-2}$ 之间的标准互信息。对于高斯变量，这等于：\n$$\nI(Y_t; X_{t-2}) = \\frac{1}{2} \\ln \\frac{\\text{Var}(Y_t)}{\\text{Var}(Y_t | X_{t-2})}\n$$\n我们计算所需的方差：\n1.  $Y_t$ 的无条件方差：\n    $$\n    \\text{Var}(Y_t) = \\text{Var}(X_{t-2} + \\varepsilon^Z_{t-1} + \\varepsilon^Y_t)\n    $$\n    由于各分量是独立的，该方差是它们方差的和：\n    $$\n    \\text{Var}(Y_t) = \\text{Var}(X_{t-2}) + \\text{Var}(\\varepsilon^Z_{t-1}) + \\text{Var}(\\varepsilon^Y_t) = \\sigma_X^2 + \\sigma_Z^2 + \\sigma_Y^2 = 1 + 1 + 1 = 3\n    $$\n2.  给定 $X_{t-2}$ 时 $Y_t$ 的条件方差。给定 $X_{t-2}$ 时 $Y_t$ 的最优线性预测器是 $E[Y_t|X_{t-2}]$。\n    $$\n    E[Y_t | X_{t-2}] = E[X_{t-2} + \\varepsilon^Z_{t-1} + \\varepsilon^Y_t | X_{t-2}] = E[X_{t-2}|X_{t-2}] + E[\\varepsilon^Z_{t-1}|X_{t-2}] + E[\\varepsilon^Y_t|X_{t-2}]\n    $$\n    由于新息是零均值且独立于 $X_{t-2}$，后两项为零。因此，$E[Y_t | X_{t-2}] = X_{t-2}$。预测残差为：\n    $$\n    Y_t - E[Y_t | X_{t-2}] = (X_{t-2} + \\varepsilon^Z_{t-1} + \\varepsilon^Y_t) - X_{t-2} = \\varepsilon^Z_{t-1} + \\varepsilon^Y_t\n    $$\n    条件方差是该残差的方差：\n    $$\n    \\text{Var}(Y_t | X_{t-2}) = \\text{Var}(\\varepsilon^Z_{t-1} + \\varepsilon^Y_t) = \\text{Var}(\\varepsilon^Z_{t-1}) + \\text{Var}(\\varepsilon^Y_t) = \\sigma_Z^2 + \\sigma_Y^2 = 1+1=2\n    $$\n最后，我们将这些方差代回到传递熵的公式中：\n$$\nTE_{X \\to Y} = \\frac{1}{2} \\ln \\left( \\frac{\\text{Var}(Y_t)}{\\text{Var}(Y_t | X_{t-2})} \\right) = \\frac{1}{2} \\ln \\left( \\frac{3}{2} \\right)\n$$\n结果以奈特（nats）为单位，因为使用了自然对数。",
            "answer": "$$\n\\boxed{\\frac{1}{2} \\ln\\left(\\frac{3}{2}\\right)}\n$$"
        }
    ]
}