{
    "hands_on_practices": [
        {
            "introduction": "To truly understand Particle Swarm Optimization (PSO), we must first grasp the mechanics of how a single particle moves through the search space. This exercise provides a concrete, step-by-step calculation of one iteration of the PSO algorithm, breaking down the core update rules into their constituent parts: inertia, cognitive influence, and social influence. By manually computing a particle's new velocity and position, you will gain an intuitive feel for how these forces combine to guide the search process .",
            "id": "4145975",
            "problem": "Consider a one-dimensional minimization of the scalar objective function $f(x) = x^{2}$ using Particle Swarm Optimization (PSO). Particle Swarm Optimization (PSO) is a complex adaptive system of interacting agents that move under the combined influence of inertia, self-referential memory, and socially shared information. In a synchronous update at discrete time step $t$, each particle first updates its velocity based on these influences given coefficients and random draws, and then updates its position by adding the new velocity to its current position. The personal best position of a particle at time $t$ is the best position it has visited up to and including time $t$, and the global best at time $t$ is the best personal best among all particles at time $t$. There is no velocity clamping or boundary handling in this scenario.\n\nYou are given a swarm of two particles in a one-dimensional search space with the following initial conditions at time $t=0$:\n- Particle $1$: position $x_{1}(0) = 2$, velocity $v_{1}(0) = -1$, personal best $\\hat{x}_{1}(0) = 2$.\n- Particle $2$: position $x_{2}(0) = -1$, velocity $v_{2}(0) = \\frac{1}{2}$, personal best $\\hat{x}_{2}(0) = -1$.\n\nThe control parameters are inertia weight $w = \\frac{1}{2}$, cognitive coefficient $c_{1} = \\frac{3}{4}$, and social coefficient $c_{2} = 2$. The random draws for the cognitive and social components at time $t=0$ are deterministic and given as follows:\n- For particle $1$: $r_{11} = \\frac{3}{5}$ and $r_{12} = \\frac{1}{4}$.\n- For particle $2$: $r_{21} = \\frac{2}{3}$ and $r_{22} = \\frac{2}{5}$.\n\nAssume the synchronous update rule: compute the updated velocities of both particles using the canonical inertia-weight PSO formulation with the given parameters and random draws at time $t=0$ based on the personal bests and the global best determined from the personal bests at time $t=0$, and then update positions via the new velocities. Use the definition of global best $\\hat{g}(0)$ as the personal best position that minimizes $f(x)$ among $\\{\\hat{x}_{1}(0), \\hat{x}_{2}(0)\\}$.\n\nCompute one full iteration to obtain $v_{1}(1)$, $x_{1}(1)$, $v_{2}(1)$, and $x_{2}(1)$. Express your final result as a single row matrix in the order $[v_{1}(1), x_{1}(1), v_{2}(1), x_{2}(1)]$. No rounding is required, and there are no physical units involved.",
            "solution": "The problem is well-defined and provides all necessary information to compute one iteration of the Particle Swarm Optimization (PSO) algorithm. The solution proceeds by first determining the global best position at the initial time step and then applying the canonical PSO update equations for velocity and position for each particle.\n\nThe canonical velocity update equation for a particle $i$ in a one-dimensional search space at discrete time step $t$ is given by:\n$$v_{i}(t+1) = w v_{i}(t) + c_{1} r_{i1} (\\hat{x}_{i}(t) - x_{i}(t)) + c_{2} r_{i2} (\\hat{g}(t) - x_{i}(t))$$\nThe position is subsequently updated using the new velocity:\n$$x_{i}(t+1) = x_{i}(t) + v_{i}(t+1)$$\nHere, $w$ is the inertia weight, $c_{1}$ and $c_{2}$ are the cognitive and social coefficients, respectively. For a given particle $i$, $r_{i1}$ and $r_{i2}$ are random numbers drawn from a uniform distribution on $[0,1]$, which are provided deterministically in this problem. $\\hat{x}_{i}(t)$ is the personal best position of particle $i$ up to time $t$, and $\\hat{g}(t)$ is the global best position found by any particle in the swarm up to time $t$.\n\nFirst, we must determine the global best position at time $t=0$, denoted as $\\hat{g}(0)$. This is defined as the personal best position among all particles that yields the minimum value for the objective function $f(x) = x^{2}$. The personal best positions at $t=0$ are given as $\\hat{x}_{1}(0) = 2$ and $\\hat{x}_{2}(0) = -1$.\n\nWe evaluate the objective function at these positions:\nFor particle $1$: $f(\\hat{x}_{1}(0)) = f(2) = 2^{2} = 4$.\nFor particle $2$: $f(\\hat{x}_{2}(0)) = f(-1) = (-1)^{2} = 1$.\n\nSince $f(\\hat{x}_{2}(0))  f(\\hat{x}_{1}(0))$, the global best position at $t=0$ is that of particle $2$:\n$$\\hat{g}(0) = \\hat{x}_{2}(0) = -1$$\n\nWith $\\hat{g}(0)$ established, we can now compute the velocity and position updates for each particle for the step from $t=0$ to $t=1$. The given parameters are $w = \\frac{1}{2}$, $c_{1} = \\frac{3}{4}$, and $c_{2} = 2$.\n\nFor Particle $1$:\nThe initial conditions are $x_{1}(0) = 2$, $v_{1}(0) = -1$, and $\\hat{x}_{1}(0) = 2$. The specified random numbers are $r_{11} = \\frac{3}{5}$ and $r_{12} = \\frac{1}{4}$.\n\nThe velocity update for particle $1$ is:\n$$v_{1}(1) = w v_{1}(0) + c_{1} r_{11} (\\hat{x}_{1}(0) - x_{1}(0)) + c_{2} r_{12} (\\hat{g}(0) - x_{1}(0))$$\nSubstituting the numerical values:\n$$v_{1}(1) = \\left(\\frac{1}{2}\\right) (-1) + \\left(\\frac{3}{4}\\right) \\left(\\frac{3}{5}\\right) (2 - 2) + (2) \\left(\\frac{1}{4}\\right) (-1 - 2)$$\n$$v_{1}(1) = -\\frac{1}{2} + \\left(\\frac{9}{20}\\right) (0) + \\left(\\frac{1}{2}\\right) (-3)$$\n$$v_{1}(1) = -\\frac{1}{2} + 0 - \\frac{3}{2} = -\\frac{4}{2} = -2$$\nThe new position for particle $1$ is:\n$$x_{1}(1) = x_{1}(0) + v_{1}(1) = 2 + (-2) = 0$$\n\nFor Particle $2$:\nThe initial conditions are $x_{2}(0) = -1$, $v_{2}(0) = \\frac{1}{2}$, and $\\hat{x}_{2}(0) = -1$. The specified random numbers are $r_{21} = \\frac{2}{3}$ and $r_{22} = \\frac{2}{5}$.\n\nThe velocity update for particle $2$ is:\n$$v_{2}(1) = w v_{2}(0) + c_{1} r_{21} (\\hat{x}_{2}(0) - x_{2}(0)) + c_{2} r_{22} (\\hat{g}(0) - x_{2}(0))$$\nNote that for particle $2$, its current position is the same as its personal best, which is also the global best: $x_{2}(0) = \\hat{x}_{2}(0) = \\hat{g}(0) = -1$. This simplifies the cognitive and social terms.\nSubstituting the numerical values:\n$$v_{2}(1) = \\left(\\frac{1}{2}\\right) \\left(\\frac{1}{2}\\right) + \\left(\\frac{3}{4}\\right) \\left(\\frac{2}{3}\\right) (-1 - (-1)) + (2) \\left(\\frac{2}{5}\\right) (-1 - (-1))$$\n$$v_{2}(1) = \\frac{1}{4} + \\left(\\frac{1}{2}\\right) (0) + \\left(\\frac{4}{5}\\right) (0)$$\n$$v_{2}(1) = \\frac{1}{4} + 0 + 0 = \\frac{1}{4}$$\nThe new position for particle $2$ is:\n$$x_{2}(1) = x_{2}(0) + v_{2}(1) = -1 + \\frac{1}{4} = -\\frac{3}{4}$$\n\nThus, after one full iteration, the new states for the two particles are:\n$v_{1}(1) = -2$\n$x_{1}(1) = 0$\n$v_{2}(1) = \\frac{1}{4}$\n$x_{2}(1) = -\\frac{3}{4}$\n\nThe final result is expressed as a row matrix $[v_{1}(1), x_{1}(1), v_{2}(1), x_{2}(1)]$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-2  0  \\frac{1}{4}  -\\frac{3}{4}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Moving from the behavior of a single agent to the dynamics of the collective, this practice explores the emergent properties of Ant Colony Optimization (ACO). The essence of ACO lies in how the shared pheromone environment evolves over time. This analytical exercise uses the tools of dynamical systems theory to investigate the stability of the pheromone system, revealing the critical phenomenon of symmetry breaking, where the colony transitions from exploring all paths equally to converging on a single, optimal solution .",
            "id": "4145940",
            "problem": "Consider a minimal model of Ant Colony Optimization (ACO) pheromone dynamics in a homogeneous two-edge choice. Let there be two edges, labeled $A$ and $B$, with pheromone levels $\\tau_{A}(t)$ and $\\tau_{B}(t)$ at discrete time $t \\in \\mathbb{Z}_{\\ge 0}$. Assume the environment is symmetric, with no heuristic bias and identical path quality, so that ant choices depend only on the current pheromone levels. The evaporation-reinforcement update is modeled by the widely used discrete-time rule\n$$\n\\tau_{i}(t+1) \\;=\\; (1-\\rho)\\,\\tau_{i}(t) \\;+\\; R\\,p_{i}(t),\n$$\nwhere $i \\in \\{A,B\\}$, the evaporation rate satisfies $\\rho \\in (0,1)$, the reinforcement magnitude per unit time satisfies $R0$, and the choice probabilities follow the normalized power-law sensitivity\n$$\np_{i}(t) \\;=\\; \\frac{\\tau_{i}(t)^{\\alpha}}{\\tau_{A}(t)^{\\alpha} + \\tau_{B}(t)^{\\alpha}},\n$$\nwith sensitivity exponent $\\alpha0$. Starting from these definitions and without introducing any additional shortcut formulas, proceed as follows:\n1. Use symmetry considerations to identify the fixed point $(\\tau_{A},\\tau_{B}) = (\\tau^{\\star},\\tau^{\\star})$ of the coupled map implied by the update rule.\n2. Linearize the two-dimensional map in a neighborhood of $(\\tau^{\\star},\\tau^{\\star})$ by computing the Jacobian matrix $J$ of the one-step update with respect to $(\\tau_{A},\\tau_{B})$ at the fixed point.\n3. Derive the eigenvalues of $J$ in closed form and, from these, compute the spectral radius $\\rho(J)$ of the Jacobian as a closed-form analytic expression that depends only on $\\rho$ and $\\alpha$ (the dependence on $R$ should cancel in the process under the stated symmetry).\n\nExpress your final answer as the single closed-form expression for $\\rho(J)$ in terms of $\\rho$ and $\\alpha$. Do not round your answer.",
            "solution": "The problem asks for the derivation of the spectral radius of the Jacobian matrix for a simplified Ant Colony Optimization (ACO) model at its symmetric fixed point. We shall proceed in three main steps as delineated in the problem statement.\n\nThe dynamical system is defined by the coupled update rules for the pheromone levels $\\tau_{A}(t)$ and $\\tau_{B}(t)$ on two edges, $A$ and $B$:\n$$\n\\tau_{i}(t+1) = (1-\\rho)\\,\\tau_{i}(t) + R\\,p_{i}(t), \\quad i \\in \\{A,B\\}\n$$\nwhere the choice probability $p_{i}(t)$ is given by:\n$$\np_{i}(t) = \\frac{\\tau_{i}(t)^{\\alpha}}{\\tau_{A}(t)^{\\alpha} + \\tau_{B}(t)^{\\alpha}}\n$$\nThe parameters are the evaporation rate $\\rho \\in (0,1)$, the reinforcement magnitude $R0$, and the sensitivity exponent $\\alpha0$.\n\n**1. Identification of the Symmetric Fixed Point**\n\nA fixed point of the system is a state $(\\tau_{A}^{\\star}, \\tau_{B}^{\\star})$ such that $\\tau_{i}(t+1) = \\tau_{i}(t) = \\tau_{i}^{\\star}$ for all $i$. We are tasked with finding the symmetric fixed point, where $\\tau_{A}^{\\star} = \\tau_{B}^{\\star} = \\tau^{\\star}$.\n\nAt this symmetric point, the choice probabilities for the two edges become equal:\n$$\np_{A} = p_{B} = \\frac{(\\tau^{\\star})^{\\alpha}}{(\\tau^{\\star})^{\\alpha} + (\\tau^{\\star})^{\\alpha}} = \\frac{(\\tau^{\\star})^{\\alpha}}{2(\\tau^{\\star})^{\\alpha}} = \\frac{1}{2}\n$$\nSubstituting this into the update rule for either edge (e.g., edge $A$) at the fixed point gives:\n$$\n\\tau^{\\star} = (1-\\rho)\\,\\tau^{\\star} + R\\,p_{A}\n$$\n$$\n\\tau^{\\star} = (1-\\rho)\\,\\tau^{\\star} + R\\left(\\frac{1}{2}\\right)\n$$\nWe can solve for $\\tau^{\\star}$:\n$$\n\\tau^{\\star} - (1-\\rho)\\tau^{\\star} = \\frac{R}{2}\n$$\n$$\n\\tau^{\\star}\\left(1 - (1-\\rho)\\right) = \\frac{R}{2}\n$$\n$$\n\\rho\\tau^{\\star} = \\frac{R}{2}\n$$\nThis yields the value of the pheromone at the symmetric fixed point:\n$$\n\\tau^{\\star} = \\frac{R}{2\\rho}\n$$\nThe symmetric fixed point of the system is therefore $(\\tau^{\\star},\\tau^{\\star}) = (\\frac{R}{2\\rho}, \\frac{R}{2\\rho})$.\n\n**2. Computation of the Jacobian Matrix**\n\nTo analyze the stability of this fixed point, we linearize the system by computing the Jacobian matrix $J$. Let the two-dimensional map be denoted by $\\vec{F}(\\tau_A, \\tau_B) = (F_A(\\tau_A, \\tau_B), F_B(\\tau_A, \\tau_B))$, where:\n$$\nF_A(\\tau_A, \\tau_B) = (1-\\rho)\\tau_A + R \\frac{\\tau_A^{\\alpha}}{\\tau_A^{\\alpha} + \\tau_B^{\\alpha}}\n$$\n$$\nF_B(\\tau_A, \\tau_B) = (1-\\rho)\\tau_B + R \\frac{\\tau_B^{\\alpha}}{\\tau_A^{\\alpha} + \\tau_B^{\\alpha}}\n$$\nThe Jacobian matrix is given by:\n$$\nJ = \\begin{pmatrix} \\frac{\\partial F_A}{\\partial \\tau_A}  \\frac{\\partial F_A}{\\partial \\tau_B} \\\\ \\frac{\\partial F_B}{\\partial \\tau_A}  \\frac{\\partial F_B}{\\partial \\tau_B} \\end{pmatrix}\n$$\nWe compute the necessary partial derivatives. Let $p_A = \\frac{\\tau_A^{\\alpha}}{\\tau_A^{\\alpha} + \\tau_B^{\\alpha}}$.\n$$\n\\frac{\\partial p_A}{\\partial \\tau_A} = \\frac{(\\alpha\\tau_A^{\\alpha-1})(\\tau_A^{\\alpha} + \\tau_B^{\\alpha}) - \\tau_A^{\\alpha}(\\alpha\\tau_A^{\\alpha-1})}{(\\tau_A^{\\alpha} + \\tau_B^{\\alpha})^2} = \\frac{\\alpha\\tau_A^{\\alpha-1}\\tau_B^{\\alpha}}{(\\tau_A^{\\alpha} + \\tau_B^{\\alpha})^2}\n$$\n$$\n\\frac{\\partial p_A}{\\partial \\tau_B} = \\frac{0 - \\tau_A^{\\alpha}(\\alpha\\tau_B^{\\alpha-1})}{(\\tau_A^{\\alpha} + \\tau_B^{\\alpha})^2} = -\\frac{\\alpha\\tau_A^{\\alpha}\\tau_B^{\\alpha-1}}{(\\tau_A^{\\alpha} + \\tau_B^{\\alpha})^2}\n$$\nThe derivatives of the map components are:\n$$\n\\frac{\\partial F_A}{\\partial \\tau_A} = 1-\\rho + R \\frac{\\partial p_A}{\\partial \\tau_A} = 1-\\rho + R\\frac{\\alpha\\tau_A^{\\alpha-1}\\tau_B^{\\alpha}}{(\\tau_A^{\\alpha} + \\tau_B^{\\alpha})^2}\n$$\n$$\n\\frac{\\partial F_A}{\\partial \\tau_B} = R \\frac{\\partial p_A}{\\partial \\tau_B} = -R\\frac{\\alpha\\tau_A^{\\alpha}\\tau_B^{\\alpha-1}}{(\\tau_A^{\\alpha} + \\tau_B^{\\alpha})^2}\n$$\nBy symmetry, swapping indices $A$ and $B$, we obtain the other two derivatives:\n$$\n\\frac{\\partial F_B}{\\partial \\tau_B} = 1-\\rho + R\\frac{\\alpha\\tau_B^{\\alpha-1}\\tau_A^{\\alpha}}{(\\tau_A^{\\alpha} + \\tau_B^{\\alpha})^2}\n$$\n$$\n\\frac{\\partial F_B}{\\partial \\tau_A} = -R\\frac{\\alpha\\tau_B^{\\alpha}\\tau_A^{\\alpha-1}}{(\\tau_A^{\\alpha} + \\tau_B^{\\alpha})^2}\n$$\nNext, we evaluate these derivatives at the fixed point $(\\tau^{\\star}, \\tau^{\\star})$:\n$$\n\\left.\\frac{\\partial F_A}{\\partial \\tau_A}\\right|_{(\\tau^{\\star}, \\tau^{\\star})} = 1-\\rho + R\\frac{\\alpha(\\tau^{\\star})^{\\alpha-1}(\\tau^{\\star})^{\\alpha}}{((\\tau^{\\star})^{\\alpha} + (\\tau^{\\star})^{\\alpha})^2} = 1-\\rho + R\\frac{\\alpha(\\tau^{\\star})^{2\\alpha-1}}{4(\\tau^{\\star})^{2\\alpha}} = 1-\\rho + \\frac{R\\alpha}{4\\tau^{\\star}}\n$$\n$$\n\\left.\\frac{\\partial F_A}{\\partial \\tau_B}\\right|_{(\\tau^{\\star}, \\tau^{\\star})} = -R\\frac{\\alpha(\\tau^{\\star})^{\\alpha}(\\tau^{\\star})^{\\alpha-1}}{(2(\\tau^{\\star})^{\\alpha})^2} = -R\\frac{\\alpha(\\tau^{\\star})^{2\\alpha-1}}{4(\\tau^{\\star})^{2\\alpha}} = -\\frac{R\\alpha}{4\\tau^{\\star}}\n$$\nSubstituting $\\tau^{\\star} = \\frac{R}{2\\rho}$:\n$$\n\\frac{R\\alpha}{4\\tau^{\\star}} = \\frac{R\\alpha}{4(R/2\\rho)} = \\frac{2R\\alpha\\rho}{4R} = \\frac{\\alpha\\rho}{2}\n$$\nThe elements of the Jacobian matrix at the fixed point are:\n$$\nJ_{11} = J_{22} = 1-\\rho + \\frac{\\alpha\\rho}{2}\n$$\n$$\nJ_{12} = J_{21} = -\\frac{\\alpha\\rho}{2}\n$$\nThus, the Jacobian matrix is:\n$$\nJ = \\begin{pmatrix} 1-\\rho + \\frac{\\alpha\\rho}{2}  -\\frac{\\alpha\\rho}{2} \\\\ -\\frac{\\alpha\\rho}{2}  1-\\rho + \\frac{\\alpha\\rho}{2} \\end{pmatrix}\n$$\nAs anticipated, the dependence on $R$ has been eliminated.\n\n**3. Eigenvalues and Spectral Radius**\n\nThe Jacobian matrix has the symmetric form $\\begin{pmatrix} a  b \\\\ b  a \\end{pmatrix}$, with $a = 1-\\rho + \\frac{\\alpha\\rho}{2}$ and $b = -\\frac{\\alpha\\rho}{2}$. The eigenvalues $\\lambda$ of such a matrix are $\\lambda_1 = a+b$ and $\\lambda_2 = a-b$.\n\nWe compute these eigenvalues:\n$$\n\\lambda_1 = a+b = \\left(1-\\rho + \\frac{\\alpha\\rho}{2}\\right) + \\left(-\\frac{\\alpha\\rho}{2}\\right) = 1-\\rho\n$$\n$$\n\\lambda_2 = a-b = \\left(1-\\rho + \\frac{\\alpha\\rho}{2}\\right) - \\left(-\\frac{\\alpha\\rho}{2}\\right) = 1-\\rho + \\alpha\\rho\n$$\nThe eigenvalues of the Jacobian at the symmetric fixed point are $\\lambda_1 = 1-\\rho$ and $\\lambda_2 = 1-\\rho + \\alpha\\rho$.\n\nThe spectral radius, $\\rho(J)$, is the maximum of the absolute values of the eigenvalues:\n$$\n\\rho(J) = \\max(|\\lambda_1|, |\\lambda_2|) = \\max(|1-\\rho|, |1-\\rho + \\alpha\\rho|)\n$$\nWe analyze these values under the given constraints $\\rho \\in (0,1)$ and $\\alpha  0$.\nSince $\\rho \\in (0,1)$, it follows that $0  1-\\rho  1$, so $|1-\\rho| = 1-\\rho$.\nSince $\\alpha  0$ and $\\rho  0$, the product $\\alpha\\rho$ is strictly positive. Therefore, $1-\\rho + \\alpha\\rho  1-\\rho$.\nGiven that $1-\\rho$ is positive, $1-\\rho + \\alpha\\rho$ must also be positive. Thus, $|1-\\rho + \\alpha\\rho| = 1-\\rho + \\alpha\\rho$.\nComparing the two positive eigenvalues, we have:\n$$\n1-\\rho + \\alpha\\rho  1-\\rho\n$$\nThe maximum of their absolute values is therefore $|1-\\rho + \\alpha\\rho|$.\n$$\n\\rho(J) = 1-\\rho + \\alpha\\rho\n$$\nThis expression provides the spectral radius as a function of only $\\rho$ and $\\alpha$. The symmetric fixed point becomes unstable when $\\rho(J)  1$, which occurs if $1-\\rho + \\alpha\\rho  1$, simplifying to $\\alpha\\rho  \\rho$, or $\\alpha  1$. This is a classic result in the analysis of ACO dynamics concerning symmetry breaking.",
            "answer": "$$\\boxed{1 - \\rho + \\alpha \\rho}$$"
        },
        {
            "introduction": "The ultimate test of understanding is the ability to translate theory into a functional application. This comprehensive practice challenges you to implement both Particle Swarm Optimization and Ant Colony Optimization from the ground up as agent-based models. This task goes beyond simply coding the update rules; it requires you to define and monitor macroscopic observables, such as swarm diversity and pheromone entropy, to track the system's progress and determine convergence, bridging the crucial gap between abstract algorithms and practical optimization tools .",
            "id": "4145969",
            "problem": "You are to design and implement two agent-based models whose local interaction rules yield global optimization behavior: one for Particle Swarm Optimization (PSO) and one for Ant Colony Optimization (ACO). For each model, you must define agent state variables, specify and implement local rules grounded in fundamental principles, and implement a macroscale observable that signals convergence. Your final program must execute the specified test suite and return a single line containing the aggregated boolean results. No user input is allowed.\n\nFundamental base and modeling requirements:\n- Work from the principle that agent-based models are collections of agents with local state $s_i(t)$ and local rules that govern state transitions $s_i(t) \\mapsto s_i(t+1)$, where global behavior emerges from repeated local interactions under stochasticity and feedback. Use well-tested, widely accepted principles for swarm optimization: consensus-seeking with stochastic acceleration for Particle Swarm Optimization (PSO) and reinforcement-based stigmergy for Ant Colony Optimization (ACO).\n- Model the objective landscape as a function $f:\\mathbb{R}^d \\to \\mathbb{R}$ for continuous optimization and as a tour-length function $L(\\pi)$ over permutations $\\pi$ for the traveling salesperson problem (TSP) instance in the discrete setting.\n\nAgent-based model specifications to implement:\n1. Particle Swarm Optimization (PSO).\n   - Agents (particles) possess state variables position $x_i(t) \\in \\mathbb{R}^d$, velocity $v_i(t) \\in \\mathbb{R}^d$, and personal best $p_i(t) \\in \\mathbb{R}^d$ with respect to the objective function $f$.\n   - Local interaction rules are derived from consensus dynamics and stochastic sampling: each agent moves by combining an inertial tendency and stochastic accelerations directed toward attractors derived from its own experience (personal best) and social information (global best). All random coefficients per dimension must be independently sampled from the uniform distribution over $[0,1]$ at each step.\n   - Positions are confined within a given hypercube $[\\ell,u]^d$ using clamping. Velocities are bounded in magnitude per coordinate by a prescribed $v_{\\max}$ using clamping. The model should initialize $x_i(0)$ uniformly in $[\\ell,u]^d$ and $v_i(0)$ uniformly in $[-v_{\\max},v_{\\max}]^d$.\n   - Macroscale observable for convergence in PSO: define the diversity of positions at time $t$ as\n     $$D_t = \\frac{1}{N} \\sum_{i=1}^N \\left\\| x_i(t) - \\bar{x}(t) \\right\\|_2 \\, , \\quad \\bar{x}(t) = \\frac{1}{N}\\sum_{i=1}^N x_i(t) \\, ,$$\n     and the moving-average improvement magnitude over a window of $W$ iterations as\n     $$\\Delta^{\\mathrm{MA}}_t = \\frac{1}{W-1} \\sum_{k=t-W+2}^{t} \\left| f^\\ast(k) - f^\\ast(k-1) \\right| \\, , \\quad f^\\ast(t) = \\min_{1 \\leq i \\leq N} f\\big(p_i(t)\\big) \\, .$$\n     Convergence is signaled when two conditions simultaneously hold: $D_t \\leq \\delta_D$ and $\\Delta^{\\mathrm{MA}}_t \\leq \\varepsilon_{\\mathrm{MA}}$.\n   - Success criterion for a PSO test case: the final best objective value $f^\\ast(t_{\\max})$ is less than or equal to a tolerance $\\tau_f$ and the macroscale convergence conditions hold at the end of the run.\n\n2. Ant Colony Optimization (ACO).\n   - Agents (ants) possess a tour construction policy based on a shared pheromone matrix $\\mathbf{T}(t)$ with entries $T_{ij}(t)$ (edge pheromones) and a static heuristic $\\eta_{ij} = 1 / d_{ij}$ derived from the distance matrix $\\mathbf{D}$ of the TSP graph (with $d_{ii} = 0$ and $d_{ij}  0$ for $i \\neq j$).\n   - Local interaction rules are derived from reinforcement and Bayesian-like sampling: each ant constructs a tour by iteratively selecting the next node from the unvisited set using a probability proportional to $T_{ij}(t)^\\alpha \\eta_{ij}^\\beta$, with independent random sampling at each choice. Each ant completes a Hamiltonian cycle and its tour length $L$ is computed. Pheromone evaporation reduces $T_{ij}(t)$ multiplicatively, after which pheromone deposits add an amount proportional to $Q/L$ on edges traversed by each ant.\n   - Initialization uses a uniform pheromone $T_{ij}(0) = \\tau_0$ for $i \\neq j$ and $T_{ii}(0) = 0$. Each ant starts at a randomly chosen node at each iteration. Distances are derived from given coordinates, with Euclidean distance in the plane.\n   - Macroscale observable for convergence in ACO: define the normalized Shannon entropy of the pheromone field at time $t$ by\n     $$\\mathcal{H}_t = \\frac{ - \\sum_{ij} p_{ij}(t) \\log p_{ij}(t) }{ \\log M } \\, , \\quad p_{ij}(t) = \\frac{T_{ij}(t)}{ \\sum_{ab} T_{ab}(t) } \\, , \\quad M = \\frac{n(n-1)}{2} \\, ,$$\n     where $n$ is the number of nodes. Also define the moving-average improvement magnitude over a window of $W$ iterations for the best tour length $L^\\ast(t)$ analogously to PSO:\n     $$\\Delta^{\\mathrm{MA}}_t = \\frac{1}{W-1} \\sum_{k=t-W+2}^{t} \\left| L^\\ast(k) - L^\\ast(k-1) \\right| \\, , \\quad L^\\ast(t) = \\min \\text{ tour length seen up to } t \\, .$$\n     Convergence is signaled when two conditions simultaneously hold: $\\mathcal{H}_t \\leq \\delta_H$ and $\\Delta^{\\mathrm{MA}}_t \\leq \\varepsilon_{\\mathrm{MA}}$.\n   - Success criterion for an ACO test case: the final best tour length $L^\\ast(t_{\\max})$ is within an absolute tolerance $\\tau_L$ of a known optimal tour length $L^\\star$ and the macroscale convergence conditions hold at the end of the run.\n\nObjective functions and TSP instances:\n- Continuous optimization functions for PSO:\n  1. Sphere function: for dimension $d$, $$f(x) = \\sum_{j=1}^{d} x_j^2 \\, .$$\n  2. Rastrigin function: for dimension $d$, $$f(x) = 10 d + \\sum_{j=1}^{d} \\left( x_j^2 - 10 \\cos\\left(2\\pi x_j\\right) \\right) \\, .$$\n- TSP instances for ACO:\n  1. $n=5$ nodes placed on the unit circle in the plane at equally spaced angles $\\theta_k = 2\\pi k / 5$ for $k \\in \\{0,1,2,3,4\\}$, with coordinates $(\\cos \\theta_k, \\sin \\theta_k)$. Angles are in radians. The known optimal tour is the polygonal cycle in order of increasing $\\theta_k$, with optimal length $$L^\\star = \\sum_{k=0}^{4} \\left\\| p_k - p_{(k+1) \\bmod 5} \\right\\|_2 \\, ,$$ where $p_k$ is the coordinate of node $k$.\n  2. $n=8$ nodes placed on the unit circle at angles $\\theta_k = 2\\pi k / 8$ for $k \\in \\{0,1,\\dots,7\\}$, with coordinates $(\\cos \\theta_k, \\sin \\theta_k)$, angles in radians. The known optimal tour is the polygonal cycle in order of increasing $\\theta_k$, with optimal length $$L^\\star = \\sum_{k=0}^{7} \\left\\| p_k - p_{(k+1) \\bmod 8} \\right\\|_2 \\, .$$\n\nTest suite and parameters:\n- You must implement the following four test cases exactly, using the specified seeds to ensure reproducibility:\n\n  1. PSO on Sphere:\n     - Dimension $d = 5$, bounds $[\\ell,u] = [-5.12, 5.12]$, swarm size $N = 40$.\n     - Parameters: inertia $w = 0.7298$, cognitive coefficient $c_1 = 1.49618$, social coefficient $c_2 = 1.49618$, velocity bound $v_{\\max} = 0.5 (u-\\ell)$ per coordinate.\n     - Iterations $t_{\\max} = 300$.\n     - Macros: window $W = 25$, diversity threshold $\\delta_D = 10^{-3}$, improvement threshold $\\varepsilon_{\\mathrm{MA}} = 10^{-8}$.\n     - Success tolerance: $\\tau_f = 10^{-6}$.\n     - Seed: $42$.\n\n  2. PSO on Rastrigin:\n     - Dimension $d = 8$, bounds $[\\ell,u] = [-5.12, 5.12]$, swarm size $N = 60$.\n     - Parameters: inertia $w = 0.7298$, cognitive coefficient $c_1 = 1.49618$, social coefficient $c_2 = 1.49618$, velocity bound $v_{\\max} = 0.5 (u-\\ell)$ per coordinate.\n     - Iterations $t_{\\max} = 600$.\n     - Macros: window $W = 30$, diversity threshold $\\delta_D = 10^{-3}$, improvement threshold $\\varepsilon_{\\mathrm{MA}} = 10^{-6}$.\n     - Success tolerance: $\\tau_f = 1.0$.\n     - Seed: $123$.\n\n  3. ACO on 5-node unit circle TSP:\n     - Ant count $M = 25$.\n     - Pheromone parameters: $\\alpha = 1.0$, $\\beta = 3.0$, evaporation rate $\\rho = 0.5$, deposit constant $Q = 1.0$, initial pheromone $\\tau_0 = 1.0$.\n     - Iterations $t_{\\max} = 200$.\n     - Macros: window $W = 30$, entropy threshold $\\delta_H = 0.4$, improvement threshold $\\varepsilon_{\\mathrm{MA}} = 10^{-8}$.\n     - Success tolerance: $\\tau_L = 0.02$ (absolute distance from $L^\\star$).\n     - Seed: $21$.\n\n  4. ACO on 8-node unit circle TSP:\n     - Ant count $M = 40$.\n     - Pheromone parameters: $\\alpha = 1.0$, $\\beta = 3.0$, evaporation rate $\\rho = 0.5$, deposit constant $Q = 1.0$, initial pheromone $\\tau_0 = 1.0$.\n     - Iterations $t_{\\max} = 300$.\n     - Macros: window $W = 40$, entropy threshold $\\delta_H = 0.5$, improvement threshold $\\varepsilon_{\\mathrm{MA}} = 10^{-8}$.\n     - Success tolerance: $\\tau_L = 0.10$ (absolute distance from $L^\\star$).\n     - Seed: $31$.\n\nProgram output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"), where each result is a boolean indicating whether the corresponding test case both reached the success tolerance and satisfied the convergence macro conditions at the final iteration.\n\nScientific realism and constraints:\n- All stochastic components must use the specified seeds. All random coefficients are drawn independently as specified. Distances are Euclidean and angles are in radians. No physical units are involved beyond these specifications.\n- Implementations must avoid division by zero in probability computations by excluding self-edges in TSP and by safeguarding denominators with appropriate checks for positivity.",
            "solution": "The problem requires the design, implementation, and testing of two fundamental swarm intelligence algorithms, Particle Swarm Optimization (PSO) and Ant Colony Optimization (ACO), framed as agent-based models. The problem statement is scientifically sound, well-posed, and provides all necessary parameters and criteria for a complete implementation.\n\n### 1. Particle Swarm Optimization (PSO)\n\nThe PSO algorithm models a population, or swarm, of candidate solutions, termed particles, moving in the search space of a continuous optimization problem. The global optimization behavior emerges from local interactions governed by principles of consensus-seeking and stochastic exploration.\n\n#### 1.1. Agent-Based Model Formulation\n\nEach agent (particle) $i$ is characterized by a state $s_i(t) = (x_i(t), v_i(t), p_i(t))$ at time step $t$, where:\n-   $x_i(t) \\in \\mathbb{R}^d$ is the particle's current position in the $d$-dimensional search space.\n-   $v_i(t) \\in \\mathbb{R}^d$ is the particle's current velocity.\n-   $p_i(t) \\in \\mathbb{R}^d$ is the particle's personal best position found so far, i.e., the position corresponding to the lowest objective function value $f(p_i(t))$ it has achieved.\n\nThe state transition rule $s_i(t) \\mapsto s_i(t+1)$ is defined by the following equations for each dimension $j \\in \\{1, \\dots, d\\}$:\n$$\nv_{ij}(t+1) = w v_{ij}(t) + c_1 r_{1j}(t) (p_{ij}(t) - x_{ij}(t)) + c_2 r_{2j}(t) (g_j(t) - x_{ij}(t))\n$$\n$$\nx_i(t+1) = x_i(t) + v_i(t+1)\n$$\nHere, $w$ is the inertia weight, $c_1$ is the cognitive coefficient, and $c_2$ is the social coefficient. The vector $g(t)$ represents the global best position found by any particle in the entire swarm up to time $t$. The terms $r_{1j}(t)$ and $r_{2j}(t)$ are stochastic coefficients independently sampled from a uniform distribution $U(0, 1)$ at each time step for each dimension. This update rule combines the particle's inertia, its tendency to return to its personal best location (cognitive component), and its tendency to move toward the swarm's best-known location (social component).\n\nThe personal best is updated at each step:\n$$\np_i(t+1) =\n\\begin{cases}\n  x_i(t+1)  \\text{if } f(x_i(t+1))  f(p_i(t)) \\\\\n  p_i(t)    \\text{otherwise}\n\\end{cases}\n$$\nThe positions $x_i$ and velocities $v_i$ are clamped to stay within the problem-defined bounds $[\\ell, u]^d$ and $[-v_{\\max}, v_{\\max}]^d$, respectively.\n\n#### 1.2. Macroscale Observables for Convergence\n\nConvergence of the swarm is monitored through two macroscopic quantities:\n1.  **Position Diversity ($D_t$):** This measures the average Euclidean distance of particles from the swarm's centroid, quantifying spatial cohesion.\n    $$\n    D_t = \\frac{1}{N} \\sum_{i=1}^N \\left\\| x_i(t) - \\bar{x}(t) \\right\\|_2 , \\quad \\text{where } \\bar{x}(t) = \\frac{1}{N}\\sum_{i=1}^N x_i(t)\n    $$\n    A low diversity $D_t \\leq \\delta_D$ indicates the swarm has aggregated in a small region of the search space.\n\n2.  **Moving-Average Improvement ($\\Delta^{\\mathrm{MA}}_t$):** This measures the rate of improvement in the global best solution over a recent window of $W$ iterations, quantifying algorithmic stagnation.\n    $$\n    \\Delta^{\\mathrm{MA}}_t = \\frac{1}{W-1} \\sum_{k=t-W+2}^{t} \\left| f^\\ast(k) - f^\\ast(k-1) \\right|\n    $$\n    where $f^\\ast(t) = f(g(t))$ is the global best value at time $t$. A low value $\\Delta^{\\mathrm{MA}}_t \\leq \\varepsilon_{\\mathrm{MA}}$ indicates that the search has stalled.\n\nSimultaneous satisfaction of both conditions signals convergence.\n\n### 2. Ant Colony Optimization (ACO)\n\nACO is a metaheuristic inspired by the foraging behavior of ants, which deposit pheromones to communicate attractive paths. It is particularly well-suited for discrete combinatorial optimization problems, such as the Traveling Salesperson Problem (TSP). The global discovery of an optimal tour emerges from local, probabilistic decisions reinforced by a shared memory mechanism (stigmergy).\n\n#### 2.1. Agent-Based Model Formulation\n\nIn contrast to PSO, the \"state\" in ACO is primarily environmental and shared among all agents (ants). This state is the pheromone matrix $\\mathbf{T}(t)$, where $T_{ij}(t)$ represents the pheromone intensity on the edge connecting nodes $i$ and $j$.\n\nAn agent (ant) $k$ constructs a solution (a TSP tour) probabilistically. The local rule for selecting the next node $j$ from the current node $i$, given the set of unvisited nodes $\\mathcal{N}_k$, is given by the transition probability:\n$$\nP_{ij}^k(t) = \\frac{ [T_{ij}(t)]^\\alpha [\\eta_{ij}]^\\beta }{ \\sum_{l \\in \\mathcal{N}_k} [T_{il}(t)]^\\alpha [\\eta_{il}]^\\beta } \\quad \\text{for } j \\in \\mathcal{N}_k\n$$\nwhere $\\alpha$ and $\\beta$ are parameters that control the relative influence of the pheromone trail and the static heuristic information, respectively. The heuristic $\\eta_{ij}$ provides a priori problem knowledge, defined as $\\eta_{ij} = 1/d_{ij}$, where $d_{ij}$ is the Euclidean distance between nodes $i$ and $j$.\n\nAfter all $m$ ants have constructed their tours in an iteration, the shared pheromone matrix is updated. This involves two steps:\n1.  **Evaporation:** All pheromone trails are reduced to simulate decay.\n    $$\n    T_{ij}(t+1) = (1-\\rho) T_{ij}(t)\n    $$\n    where $\\rho \\in (0, 1]$ is the evaporation rate.\n2.  **Deposition:** Ants deposit new pheromone on the edges they traversed, with the amount being inversely proportional to their tour length.\n    $$\n    T_{ij}(t+1) \\leftarrow T_{ij}(t+1) + \\sum_{k=1}^m \\Delta T_{ij}^k(t), \\quad \\text{where } \\Delta T_{ij}^k(t) = \\begin{cases} Q/L_k  \\text{if ant } k \\text{ used edge } (i, j) \\\\ 0  \\text{otherwise} \\end{cases}\n    $$\n    Here, $L_k$ is the length of the tour constructed by ant $k$, and $Q$ is a constant.\n\nThis feedback loop reinforces shorter paths, guiding subsequent ants toward better solutions.\n\n#### 2.2. Macroscale Observables for Convergence\n\nConvergence in ACO is assessed by monitoring the structure of the pheromone matrix and the improvement in the best-found solution.\n1.  **Normalized Shannon Entropy ($\\mathcal{H}_t$):** This measures the uniformity of the pheromone distribution.\n    $$\n    \\mathcal{H}_t = \\frac{ - \\sum_{ij} p_{ij}(t) \\log p_{ij}(t) }{ \\log M }\n    $$\n    where $p_{ij}(t) = T_{ij}(t) / \\sum_{ab} T_{ab}(t)$ is the normalized pheromone on edge $(i, j)$ and $M = n(n-1)/2$ is the total number of unique edges. A low entropy $\\mathcal{H}_t \\leq \\delta_H$ indicates that the search has converged to a small set of preferred paths. A special case is made for $p\\log p$ where $p=0$, which evaluates to $0$.\n\n2.  **Moving-Average Improvement ($\\Delta^{\\mathrm{MA}}_t$):** Analogous to PSO, this measures the stagnation in finding better tours.\n    $$\n    \\Delta^{\\mathrm{MA}}_t = \\frac{1}{W-1} \\sum_{k=t-W+2}^{t} \\left| L^\\ast(k) - L^\\ast(k-1) \\right|\n    $$\n    where $L^\\ast(t)$ is the length of the shortest tour found by any ant up to iteration $t$. A low value $\\Delta^{\\mathrm{MA}}_t \\leq \\varepsilon_{\\mathrm{MA}}$ indicates stagnation.\n\nSimultaneous satisfaction of both conditions signals convergence.\n\n### 3. Test Cases\n\nThe specified test suite evaluates the implemented algorithms against standard benchmark functions and TSP instances with precisely defined parameters and success criteria, ensuring a rigorous and reproducible assessment of their performance. The final boolean result for each test case indicates whether the algorithm not only found a solution of sufficient quality (within tolerance $\\tau_f$ or $\\tau_L$) but also exhibited the specified macroscopic convergence behavior.",
            "answer": "```python\nimport numpy as np\n\n# --- Objective Functions for PSO ---\ndef sphere_func(x):\n    \"\"\"Sphere function for optimization.\"\"\"\n    return np.sum(x**2)\n\ndef rastrigin_func(x):\n    \"\"\"Rastrigin function for optimization.\"\"\"\n    d = len(x)\n    return 10 * d + np.sum(x**2 - 10 * np.cos(2 * np.pi * x))\n\n# --- PSO Implementation ---\ndef run_pso(params):\n    \"\"\"Executes the Particle Swarm Optimization algorithm for a given test case.\"\"\"\n    np.random.seed(params['seed'])\n    \n    # Unpack parameters\n    d, bounds, N = params['d'], params['bounds'], params['N']\n    w, c1, c2, vmax = params['w'], params['c1'], params['c2'], params['vmax']\n    t_max, W = params['t_max'], params['W']\n    delta_D, epsilon_MA, tau_f = params['delta_D'], params['epsilon_MA'], params['tau_f']\n    \n    l_bound, u_bound = bounds\n    \n    # Select objective function\n    obj_func = sphere_func if params['func'] == 'Sphere' else rastrigin_func\n\n    # Initialize swarm\n    positions = np.random.uniform(l_bound, u_bound, (N, d))\n    velocities = np.random.uniform(-vmax, vmax, (N, d))\n    \n    personal_best_pos = np.copy(positions)\n    personal_best_vals = np.array([obj_func(p) for p in personal_best_pos])\n    \n    global_best_idx = np.argmin(personal_best_vals)\n    global_best_pos = personal_best_pos[global_best_idx]\n    global_best_val = personal_best_vals[global_best_idx]\n    \n    best_val_history = np.zeros(t_max)\n\n    # Main optimization loop\n    for t in range(t_max):\n        for i in range(N):\n            # Update velocity\n            r1 = np.random.rand(d)\n            r2 = np.random.rand(d)\n            cognitive_comp = c1 * r1 * (personal_best_pos[i] - positions[i])\n            social_comp = c2 * r2 * (global_best_pos - positions[i])\n            velocities[i] = w * velocities[i] + cognitive_comp + social_comp\n            \n            # Clamp velocity\n            velocities[i] = np.clip(velocities[i], -vmax, vmax)\n            \n            # Update position\n            positions[i] += velocities[i]\n            \n            # Clamp position\n            positions[i] = np.clip(positions[i], l_bound, u_bound)\n            \n            # Evaluate new position\n            current_val = obj_func(positions[i])\n            \n            # Update personal best\n            if current_val  personal_best_vals[i]:\n                personal_best_vals[i] = current_val\n                personal_best_pos[i] = positions[i]\n\n        # Update global best\n        current_best_idx = np.argmin(personal_best_vals)\n        if personal_best_vals[current_best_idx]  global_best_val:\n            global_best_val = personal_best_vals[current_best_idx]\n            global_best_pos = personal_best_pos[current_best_idx]\n\n        best_val_history[t] = global_best_val\n\n    # --- Post-run analysis for convergence ---\n    # 1. Diversity D_t\n    mean_pos = np.mean(positions, axis=0)\n    diversity = np.mean(np.linalg.norm(positions - mean_pos, axis=1))\n\n    # 2. Moving-average improvement Delta_MA_t\n    if t_max = W  1:\n        improvement_history = np.abs(np.diff(best_val_history[t_max-W:]))\n        # Note: The problem defines the sum over t-W+2..t, which is W-1 terms\n        # np.diff(...) of a W-length slice gives W-1 differences\n        delta_ma = np.mean(improvement_history)\n    else: # Should not happen with given params, but for robustness\n        delta_ma = float('inf')\n\n    # --- Success Criteria ---\n    final_f_star = best_val_history[-1]\n    \n    solution_quality_ok = final_f_star = tau_f\n    diversity_ok = diversity = delta_D\n    improvement_ok = delta_ma = epsilon_MA\n    \n    return solution_quality_ok and diversity_ok and improvement_ok\n\n# --- ACO Helper Functions ---\ndef get_tsp_instance(n):\n    \"\"\"Generates node coordinates for the unit circle TSP instances.\"\"\"\n    coords = np.zeros((n, 2))\n    for k in range(n):\n        angle = 2 * np.pi * k / n\n        coords[k] = [np.cos(angle), np.sin(angle)]\n    return coords\n\ndef get_distance_matrix(coords):\n    \"\"\"Calculates the Euclidean distance matrix.\"\"\"\n    n = coords.shape[0]\n    dist_matrix = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i + 1, n):\n            dist = np.linalg.norm(coords[i] - coords[j])\n            dist_matrix[i, j] = dist_matrix[j, i] = dist\n    return dist_matrix\n\ndef calculate_tour_length(tour, dist_matrix):\n    \"\"\"Calculates the length of a given tour.\"\"\"\n    length = 0.0\n    for i in range(len(tour)):\n        length += dist_matrix[tour[i], tour[(i + 1) % len(tour)]]\n    return length\n\ndef get_optimal_tour_length(coords):\n    \"\"\"Calculates the known optimal tour length for the circle TSP.\"\"\"\n    n = coords.shape[0]\n    return calculate_tour_length(list(range(n)), get_distance_matrix(coords))\n\n# --- ACO Implementation ---\ndef run_aco(params):\n    \"\"\"Executes the Ant Colony Optimization algorithm for a given test case.\"\"\"\n    np.random.seed(params['seed'])\n\n    # Unpack parameters\n    n, M = params['n'], params['ant_count']\n    alpha, beta, rho, Q, tau0 = params['alpha'], params['beta'], params['rho'], params['Q'], params['tau0']\n    t_max, W = params['t_max'], params['W']\n    delta_H, epsilon_MA, tau_L = params['delta_H'], params['epsilon_MA'], params['tau_L']\n\n    # Setup TSP\n    coords = get_tsp_instance(n)\n    dist_matrix = get_distance_matrix(coords)\n    L_star_optimal = get_optimal_tour_length(coords)\n    \n    # Heuristic matrix (eta)\n    eta = np.zeros((n, n))\n    # Handle division by zero for d_ii\n    non_zero_dists = dist_matrix != 0\n    eta[non_zero_dists] = 1.0 / dist_matrix[non_zero_dists]\n\n    # Initialize pheromones\n    pheromones = np.full((n, n), tau0)\n    np.fill_diagonal(pheromones, 0)\n    \n    best_tour = None\n    best_tour_length = float('inf')\n    best_len_history = np.zeros(t_max)\n\n    # Main optimization loop\n    for t in range(t_max):\n        all_tours = []\n        all_lengths = []\n        \n        for k in range(M):\n            # Choose a random starting node for the ant\n            current_node = np.random.randint(n)\n            tour = [current_node]\n            unvisited = list(range(n))\n            unvisited.remove(current_node)\n            \n            while unvisited:\n                # Calculate transition probabilities\n                tau_alpha = pheromones[current_node, unvisited]**alpha\n                eta_beta = eta[current_node, unvisited]**beta\n                \n                probs = tau_alpha * eta_beta\n                \n                sum_probs = np.sum(probs)\n                if sum_probs == 0:\n                    # If stuck (all paths have 0 prob), choose randomly\n                    next_node_idx = np.random.randint(len(unvisited))\n                    next_node = unvisited[next_node_idx]\n                else:\n                    probs /= sum_probs\n                    next_node = np.random.choice(unvisited, p=probs)\n                \n                tour.append(next_node)\n                unvisited.remove(next_node)\n                current_node = next_node\n            \n            tour_length = calculate_tour_length(tour, dist_matrix)\n            all_tours.append(tour)\n            all_lengths.append(tour_length)\n            \n            if tour_length  best_tour_length:\n                best_tour_length = tour_length\n                best_tour = tour\n        \n        # Pheromone update\n        pheromones *= (1 - rho) # Evaporation\n        \n        delta_pheromones = np.zeros((n, n))\n        for tour, length in zip(all_tours, all_lengths):\n            deposit_amount = Q / length\n            for i in range(n):\n                node1, node2 = tour[i], tour[(i + 1) % n]\n                delta_pheromones[node1, node2] += deposit_amount\n                delta_pheromones[node2, node1] += deposit_amount\n        pheromones += delta_pheromones\n        \n        best_len_history[t] = best_tour_length\n\n    # --- Post-run analysis for convergence ---\n    # 1. Pheromone Entropy H_t\n    upper_triangle_indices = np.triu_indices(n, k=1)\n    T_ij_sum = np.sum(pheromones[upper_triangle_indices])\n    \n    if T_ij_sum  0:\n        p_ij = pheromones[upper_triangle_indices] / T_ij_sum\n        p_ij_log_p_ij = p_ij[p_ij  0] * np.log(p_ij[p_ij  0])\n        entropy_sum = -np.sum(p_ij_log_p_ij)\n        \n        num_edges_M = n * (n - 1) / 2\n        \n        # Denominator log(M) can be 0 if M=1 (e.g., n=2).\n        if num_edges_M  1:\n            entropy = entropy_sum / np.log(num_edges_M)\n        else:\n            entropy = 0 # Conventionally, H=0 for a single-state system\n    else:\n        entropy = 1.0 # Max entropy if all pheromones are zero\n\n    # 2. Moving-average improvement Delta_MA_t\n    if t_max = W  1:\n        improvement_history = np.abs(np.diff(best_len_history[t_max-W:]))\n        delta_ma = np.mean(improvement_history)\n    else:\n        delta_ma = float('inf')\n        \n    # --- Success Criteria ---\n    final_L_star = best_len_history[-1]\n    \n    solution_quality_ok = abs(final_L_star - L_star_optimal) = tau_L\n    entropy_ok = entropy = delta_H\n    improvement_ok = delta_ma = epsilon_MA\n    \n    return solution_quality_ok and entropy_ok and improvement_ok\n\n# --- Main Execution Block ---\ndef solve():\n    \"\"\"Defines and runs the test suite.\"\"\"\n    test_cases = [\n        # 1. PSO on Sphere\n        {\n            'algo': 'PSO', 'func': 'Sphere', 'd': 5, 'bounds': [-5.12, 5.12], 'N': 40,\n            'w': 0.7298, 'c1': 1.49618, 'c2': 1.49618, 'vmax': 0.5 * (5.12 - (-5.12)),\n            't_max': 300, 'W': 25, 'delta_D': 1e-3, 'epsilon_MA': 1e-8, 'tau_f': 1e-6,\n            'seed': 42\n        },\n        # 2. PSO on Rastrigin\n        {\n            'algo': 'PSO', 'func': 'Rastrigin', 'd': 8, 'bounds': [-5.12, 5.12], 'N': 60,\n            'w': 0.7298, 'c1': 1.49618, 'c2': 1.49618, 'vmax': 0.5 * (5.12 - (-5.12)),\n            't_max': 600, 'W': 30, 'delta_D': 1e-3, 'epsilon_MA': 1e-6, 'tau_f': 1.0,\n            'seed': 123\n        },\n        # 3. ACO on 5-node TSP\n        {\n            'algo': 'ACO', 'n': 5, 'ant_count': 25,\n            'alpha': 1.0, 'beta': 3.0, 'rho': 0.5, 'Q': 1.0, 'tau0': 1.0,\n            't_max': 200, 'W': 30, 'delta_H': 0.4, 'epsilon_MA': 1e-8, 'tau_L': 0.02,\n            'seed': 21\n        },\n        # 4. ACO on 8-node TSP\n        {\n            'algo': 'ACO', 'n': 8, 'ant_count': 40,\n            'alpha': 1.0, 'beta': 3.0, 'rho': 0.5, 'Q': 1.0, 'tau0': 1.0,\n            't_max': 300, 'W': 40, 'delta_H': 0.5, 'epsilon_MA': 1e-8, 'tau_L': 0.10,\n            'seed': 31\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['algo'] == 'PSO':\n            result = run_pso(case)\n        elif case['algo'] == 'ACO':\n            result = run_aco(case)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}