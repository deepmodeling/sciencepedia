{
    "hands_on_practices": [
        {
            "introduction": "模型的可靠性取决于严格的验证。此练习要求您为一个土地利用变化模型设计一个验证方案，以应对空间自相关这一常见陷阱。通过理解如何创建真正独立的测试数据集，您将为任何耦合自然-人类系统的空间建模建立一项基本技能。",
            "id": "3803146",
            "problem": "开发了一个土地利用变化模型，用于预测在 $30 \\ \\text{m}$ 的空间分辨率下，森林向农业转变的年概率。该模型使用遥感预测变量（海拔、来自数字高程模型的坡度、归一化植被指数 (NDVI) 和到道路的距离）以及社会经济驱动因素（人口密度、市场可达性）。该模型将用于一个综合评估建模工作流中，以评估影响人类—自然耦合系统和生态系统服务的政策情景。研究区域大约为 $300 \\ \\text{km} \\times 200 \\ \\text{km}$。响应变量是在 $t \\in [2018, 2019]$ 时期内土地转变的二元指标，而预测变量可从 $t \\in [2010, 2020]$ 每年获取。对一个初始广义可加模型拟合的残差进行的探索性分析表明，存在空间自相关，可以用一个指数半变异函数来表示，其块金值 $c_0 = 0.2$、偏基台值 $c = 0.8$、变程参数 $a = 8 \\ \\text{km}$，形式如下\n$$\n\\gamma(h) = c_0 + c \\left(1 - e^{-h/a}\\right),\n$$\n其空间相关分量所对应的相关函数为\n$$\n\\rho(h) = e^{-h/a}\n$$\n。该团队希望区分校准与验证，并设计一种样本分割协议，通过使用对空间自相关具有稳健性的空间分块方法，来产生一个独立的验证集。\n\n仅使用统计独立性、空间自相关和指数相关函数性质的基本定义（不假设任何专门的验证捷径），从以下协议中找出能够正确区分校准和验证，并能在给定的自相关结构下确保验证集独立性的协议。请注意相关性衰减的影响、避免特征构建中信息泄漏的必要性，以及距离和像素之间的转换。\n\n哪个选项是正确的？\n\nA. 定义边长至少为有效变程 $h_{0.95}$ 的正方形空间块，其中 $h_{0.95}$ 是通过求解 $e^{-h/a} = 0.05$ 得到的 $\\rho(h) \\approx 0.05$ 时的距离；将整个块分配给校准或验证折；在校准数据中排除验证块周围宽度至少为 $h_{0.95}$ 的缓冲区；并通过内部空间 $K$ 折程序，仅使用校准块执行所有参数估计和超参数调整。使用 $t \\leq 2018$ 的预测变量来预测 $[2018, 2019]$ 的转变。仅在留出的验证块上报告验证性能。当 $a = 8 \\ \\text{km}$ 且像素大小为 $0.03 \\ \\text{km}$ 时，使用的块边长和缓冲区宽度至少为 $24 \\ \\text{km}$，即至少 $800$ 像素。\n\nB. 将单个像素以 $70\\%/30\\%$ 的比例随机分割为校准集和验证集，不进行空间分块，因为研究区域足够大，空间依赖性会平均掉。使用截至 $t = 2019$ 的所有可用预测变量，以最大化对 $[2018, 2019]$ 响应的预测能力。使用校准和验证数据进行超参数调整以避免欠拟合。将校准定义为评估模型准确性的过程，将验证定义为拟合模型参数的过程。\n\nC. 将区域划分为边长等于变异函数变程参数 $a = 8 \\ \\text{km}$ 的块，并将块分配给校准和验证，不设置任何缓冲区，因为在指数模型下，相距 $a$ 的点实际上是不相关的。使用 $t \\leq 2019$ 的预测变量来预测 $[2018, 2019]$ 的响应，因为它们反映了同期条件。仅在校准块内部进行超参数调整，并在验证块上报告准确性。\n\nD. 仅使用基于时间的分割：使用 $[2010, 2017]$ 的响应数据在所有像素上校准模型，并在 $[2018, 2019]$ 上进行验证，忽略空间分块，因为时间上的分离已经足够。使用 $t \\leq 2020$ 的预测变量以确保信息最完整。将校准定义为使用所有数据选择最佳模型的任何步骤，将验证定义为同样但仅限于后期年份的步骤。\n\n选择一个选项。",
            "solution": "首先对问题陈述进行验证协议审查。\n\n### 第1步：提取给定信息\n- **任务**：开发一个土地利用变化模型，以预测森林向农业转变的年概率。\n- **空间分辨率**：$30 \\ \\text{m}$。\n- **研究区域**：大约 $300 \\ \\text{km} \\times 200 \\ \\text{km}$。\n- **响应变量**：$t \\in [2018, 2019]$ 时期内土地转变的二元指标。\n- **预测变量**：海拔、坡度、归一化植被指数 (NDVI)、到道路的距离、人口密度、市场可达性。\n- **预测变量可用性**：从 $t \\in [2010, 2020]$ 每年可用。\n- **空间自相关模型**：探索性分析表明存在一个指数半变异函数，$\\gamma(h) = c_0 + c \\left(1 - e^{-h/a}\\right)$。\n- **参数**：块金值 $c_0 = 0.2$，偏基台值 $c = 0.8$，变程参数 $a = 8 \\ \\text{km}$。\n- **对应的相关函数**：空间相关分量为 $\\rho(h) = e^{-h/a}$。\n- **目标**：设计一种使用空间分块的样本分割（校准/验证）协议，该协议对指定的空间自相关具有稳健性，以产生一个独立的验证集。\n\n### 第2步：使用提取的给定信息进行验证\n该问题具有科学依据、提法明确且客观。\n- **科学依据**：该问题属于遥感、环境建模和地统计学等成熟领域。土地利用变化建模、使用广义可加模型、分析残差的空间自相关性、使用指数半变异函数模型以及空间交叉验证（分块）都是标准且合理的科学实践。所使用的预测变量是此类模型的典型变量。\n- **提法明确**：问题定义清晰。它提供了一个特定的空间自相关结构，并要求从一组选项中选择正确的验证协议。所提供的信息（相关函数、变程参数）足以确定一个稳健验证方案的必要特征。基于统计学原理，存在一个唯一的正确答案。\n- **客观性**：该问题使用精确的定量语言（例如，半变异函数的数值参数、特定的时间间隔、空间分辨率）。它没有主观或模糊的术语。\n\n### 第3步：结论与行动\n问题陈述有效。这是一个在应用空间统计学领域中表述良好的问题。现在开始求解过程。\n\n### 基于原理的推导\n主要目标是创建一个在统计上独立于校准数据集的验证数据集。在空间背景下，这意味着要确保验证集中的观测值与校准集中的观测值没有空间相关性。若未能做到这一点，将导致数据泄漏，即验证集的信息会隐式地影响模型训练，从而导致对模型在新的、未见过的数据上的性能评估产生乐观的偏差且不可靠。\n\n1.  **量化空间自相关**：问题明确指出，空间相关性随距离 $h$ 按指数函数 $\\rho(h) = e^{-h/a}$ 衰减，变程参数 $a = 8 \\ \\text{km}$。在距离 $h=a$ 处，相关性为 $\\rho(a) = e^{-1} \\approx 0.368$，这是相当大的相关性。\n\n2.  **通过有效变程定义独立性**：真正的统计独立性要求 $\\rho(h) = 0$。对于指数模型，这只在 $h \\to \\infty$ 时发生。因此，必须建立一个“有效变程”，定义为相关性可被视为忽略不计的距离。一个常用且严格的可忽略性阈值是 $\\rho(h) \\approx 0.05$。我们可以求解这个距离，称之为 $h_{0.05}$：\n    $$ \\rho(h_{0.05}) = e^{-h_{0.05}/a} = 0.05 $$\n    对两边取自然对数：\n    $$ -\\frac{h_{0.05}}{a} = \\ln(0.05) $$\n    $$ h_{0.05} = -a \\ln(0.05) $$\n    代入 $a = 8 \\ \\text{km}$：\n    $$ h_{0.05} \\approx -8 \\ \\text{km} \\times (-2.9957) \\approx 23.97 \\ \\text{km} $$\n    因此，需要大约 $24 \\ \\text{km}$ 的有效距离来确保数据点之间的近似独立性。\n\n3.  **空间分块和缓冲**：将像素简单随机分割为校准集和验证集是不合适的。这会使许多验证像素与校准像素非常接近，从而违反了独立性假设。正确的方法是空间分块，即将研究区域划分为连续的块，并将整个块分配给校准或验证。为了强制执行所需的 $h_{0.05} \\approx 24 \\ \\text{km}$ 的分离距离，必须实施一个缓冲区。任何距离验证块小于 $h_{0.05}$ 的数据都必须从校准集中排除。这意味着该协议应包括将块分配给不同的折，然后从训练数据中移除验证块周围至少 $24 \\ \\text{km}$ 缓冲区内的数据。块本身的大小应足够大，与此有效变程相当，以便捕获相关的空间模式并最小化因缓冲区而损失的相对面积。\n\n4.  **时间数据泄漏**：该模型旨在预测 $t \\in [2018, 2019]$ 时期内的土地利用变化。预测模型必须只使用在做出预测*之前*就可获得的信息。因此，所有预测变量必须来自时间 $t \\leq 2018$。使用来自 $t=2019$ 或 $t=2020$ 的预测变量将构成“窥探未来”或使用同期信息，而这些信息可能是转变的结果而非原因。这是一种关键的数据泄漏形式，会使模型在任何实际预测应用中失效。\n\n5.  **校准与验证的区别**：\n    - **校准（训练）**：此阶段包含所有模型拟合和选择过程。它包括估计模型参数（例如，系数）和调整超参数（例如，项的复杂度、正则化强度）。所有这些活动都必须*仅*使用校准数据集来执行。在校准集内进行嵌套交叉验证（例如，空间K折）是执行超参数调整的稳健方法。\n    - **验证（测试）**：这是最后一步，在此步骤中，来自校准阶段的单一最终模型在留出的、独立的验证数据集上进行评估。该数据集绝不能在模型训练或调整期间以任何方式使用。在此数据集上的性能提供了模型泛化误差的无偏估计。\n\n6.  **距离到像素的转换**：所需的分离距离为 $h_{0.05} \\approx 24 \\ \\text{km}$。像素大小为 $30 \\ \\text{m} = 0.03 \\ \\text{km}$。相应的像素数为：\n    $$ \\frac{24 \\ \\text{km}}{0.03 \\ \\text{km/pixel}} = 800 \\ \\text{pixels} $$\n    因此，缓冲区和最小块维度应至少为 $800$ 像素。\n\n### 逐项分析选项\n\n**A. 定义边长至少为有效变程 $h_{0.95}$ 的正方形空间块，其中 $h_{0.95}$ 是通过求解 $e^{-h/a} = 0.05$ 得到的 $\\rho(h) \\approx 0.05$ 时的距离；将整个块分配给校准或验证折；在校准数据中排除验证块周围宽度至少为 $h_{0.95}$ 的缓冲区；并通过内部空间 $K$ 折程序，仅使用校准块执行所有参数估计和超参数调整。使用 $t \\leq 2018$ 的预测变量来预测 $[2018, 2019]$ 的转变。仅在留出的验证块上报告验证性能。当 $a = 8 \\ \\text{km}$ 且像素大小为 $0.03 \\ \\text{km}$ 时，使用的块边长和缓冲区宽度至少为 $24 \\ \\text{km}$，即至少 $800$ 像素。**\n\n- 该选项正确地指出了基于有效变程进行空间分块的必要性。尽管它使用了符号 $h_{0.95}$，但它通过方程 $e^{-h/a} = 0.05$ 正确地定义了它，这对应于相关性降至 $0.05$ 时的距离。\n- 它正确地计算出该距离约为 $24 \\ \\text{km}$，并将其转换为 $800$ 像素。\n- 它正确地规定了将整个块分配给不同的折。\n- 至关重要的是，它包含了在验证块周围设置此有效变程宽度的必要缓冲区，并将缓冲区内的点从校准数据中排除。\n- 它正确地将校准/调整与验证分开，将所有模型拟合限制在校准块内。\n- 它通过使用 $t \\leq 2018$ 的预测变量，正确地避免了时间数据泄漏。\n- 该协议的所有方面都与为稳健空间验证所推导的原则相一致。\n- **结论：正确**\n\n**B. 将单个像素以 $70\\%/30\\%$ 的比例随机分割为校准集和验证集，不进行空间分块，因为研究区域足够大，空间依赖性会平均掉。使用截至 $t = 2019$ 的所有可用预测变量，以最大化对 $[2018, 2019]$ 响应的预测能力。使用校准和验证数据进行超参数调整以避免欠拟合。将校准定义为评估模型准确性的过程，将验证定义为拟合模型参数的过程。**\n\n- 随机像素分割（“不进行空间分块”）的提议存在根本性缺陷，因为它忽略了已说明的空间自相关，会导致有偏差的性能估计。其理由（“空间依赖性会平均掉”）是不正确的。\n- 使用截至 $t=2019$ 的预测变量构成了时间数据泄漏。\n- 使用验证数据进行超参数调整违反了模型验证的原则。\n- 校准和验证的定义被颠倒了，并且是不正确的。\n- **结论：不正确**\n\n**C. 将区域划分为边长等于变异函数变程参数 $a = 8 \\ \\text{km}$ 的块，并将块分配给校准和验证，不设置任何缓冲区，因为在指数模型下，相距 $a$ 的点实际上是不相关的。使用 $t \\leq 2019$ 的预测变量来预测 $[2018, 2019]$ 的响应，因为它们反映了同期条件。仅在校准块内部进行超参数调整，并在验证块上报告准确性。**\n\n- “相距 $a=8 \\ \\text{km}$ 的点‘实际上不相关’”的说法是错误的；相关性为 $e^{-1} \\approx 0.37$。因此，块大小太小。\n- 在校准块和验证块之间省略缓冲区是一个关键缺陷，无法确保块边界处的独立性。\n- 使用 $t \\leq 2019$ 的预测变量会引入时间数据泄漏。\n- **结论：不正确**\n\n**D. 仅使用基于时间的分割：使用 $[2010, 2017]$ 的响应数据在所有像素上校准模型，并在 $[2018, 2019]$ 上进行验证，忽略空间分块，因为时间上的分离已经足够。使用 $t \\leq 2020$ 的预测变量以确保信息最完整。将校准定义为使用所有数据选择最佳模型的任何步骤，将验证定义为同样但仅限于后期年份的步骤。**\n\n- 该协议忽略了对*空间*自相关结构具有稳健性的明确要求。虽然基于时间的分割是一种有效的技术，但如果空间过程随时间持续存在（这是常见情况），它本身并不能保证独立性。\n- 使用 $t \\leq 2020$ 的预测变量来预测 $[2018, 2019]$ 的事件是严重的时间数据泄漏，使模型不具备预测性。\n- 所提供的定义模糊且不标准。\n- **结论：不正确**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "耦合系统模型常用于指导政策制定，但未来充满了深度不确定性。本练习将指导您实施稳健决策（RDM）框架，以识别在各种可能的未来情景下都表现良好的策略。您将把情景、策略和遗憾等概念转化为一种计算算法，为一个风格化的水资源系统寻找稳健的政策。",
            "id": "4129008",
            "problem": "你的任务是实现一个在深度不确定性下的鲁棒决策 (RDM) 算法，该算法用于一个程式化的自然-人类耦合水系统。该耦合系统由一个人类需求部分和一个自然供给部分组成，它们的相互作用决定了实际消耗量和社会福祉。不确定性由探索性情景表示，你必须根据给定的参数范围来构建这些情景。然后，你必须评估一组有限的候选策略，并选择在所有情景中能够最小化最大遗憾值的策略。\n\n你推导算法所必须依据的基本基础由以下定义和广泛使用的建模原语给出：\n\n- 在一个情景下一个策略的遗憾值定义为：该情景下可实现的最佳福祉与该策略在该情景下实现的福祉之差。\n- 最小最大遗憾策略是指能在所有情景中最小化最大遗憾值的策略。\n\n对该自然-人类耦合系统，使用以下程式化且科学上合理的模型：\n\n- 情景参数（深度不确定性）：\n  - 气候干旱参数 $a \\in [0,1]$ 会减少可再生水供应。\n  - 经济需求增长参数 $g$，它会以乘法方式缩放基准需求。\n  - 行为价格弹性参数 $e \\ge 0$，它控制需求对定价策略的敏感度。\n\n- 策略向量 $(x,u)$：\n  - 价格乘数 $x \\ge 0$ 增加有效价格（无量纲）。\n  - 供应增强投资 $u \\ge 0$ 以边际效益递减的方式增加供应，并产生类似二次方的成本。\n\n- 基准常数（无量纲）：\n  - 基准需求 $d_0$，基准供应 $s_0$，效益参数 $\\alpha$ 和 $\\beta$，稀缺性损害系数 $\\phi$，增强效能 $r$ 和投资成本系数 $c_u$。\n\n- 需求函数：\n  $$D(d_0,g,e,x) = d_0 \\,(1+g)\\,\\max\\left(0,\\,1 - e\\,x\\right).$$\n\n- 供应增强的边际效益递减供应函数：\n  $$S(s_0,a,r,u) = s_0\\,(1 - a) + r\\,\\sqrt{u}.$$\n\n- 实际消耗量（受可用供应限制）：\n  $$Q(D,S) = \\min\\left(D,\\,S\\right).$$\n\n- 稀缺量（未满足的需求）：\n  $$\\Delta(D,S) = \\max\\left(0,\\,D - S\\right).$$\n\n- 福祉函数（无量纲），结合了凹性的消耗效益、凸性的稀缺性损害和投资成本：\n  $$W(\\alpha,\\beta,\\phi,c_u; Q, \\Delta, u) = \\alpha\\,Q - \\frac{1}{2}\\,\\beta\\,Q^2 - \\phi\\,\\Delta^2 - c_u\\,u.$$\n\n- 在情景 $\\theta = (a,g,e)$ 下，策略 $\\pi = (x,u)$ 的遗憾值：\n  $$R(\\theta,\\pi) = W^*(\\theta) - W(\\theta,\\pi),$$\n  其中\n  $$W^*(\\theta) = \\max_{\\pi' \\in \\Pi} W(\\theta,\\pi')$$\n  且 $\\Pi$ 是候选策略的有限集合。\n\n你的程序必须为每个测试用例执行以下操作：\n- 通过对 $a$、$g$ 和 $e$ 的指定离散值取笛卡尔积来构建情景集。\n- 对于给定的策略集 $\\Pi$ 中的每个情景 $\\theta$ 和策略 $\\pi$，评估 $W(\\theta,\\pi)$。\n- 计算所有 $\\theta \\in \\Theta$ 和 $\\pi \\in \\Pi$ 的 $R(\\theta,\\pi)$，其中 $\\Theta$ 是情景集。\n- 计算每个策略的最大遗憾值：\n  $$R_{\\max}(\\pi) = \\max_{\\theta \\in \\Theta} R(\\theta,\\pi).$$\n- 选择最小最大遗憾策略：\n  $$\\pi^{\\text{MMR}} = \\arg\\min_{\\pi \\in \\Pi} R_{\\max}(\\pi).$$\n  如果出现平局，选择所提供策略列表中索引最小的策略来打破平局。\n\n对于每个测试用例，返回最小最大遗憾策略的索引（第一个策略的索引为 $0$）及其最大遗憾值 $R_{\\max}$。\n\n所有量都是无量纲的。不需要物理单位。不涉及角度。所有数值输出必须是浮点数或整数。每个测试用例的最终输出必须是一个包含两个项目的列表 $[i, r]$，其中 $i$ 是一个整数策略索引，而 $r$ 是一个等于 $R_{\\max}$ 并四舍五入到六位小数的浮点数。\n\n你的程序应该生成单行输出，其中包含用方括号括起来的、以逗号分隔的列表形式的结果，其中每个元素对应一个测试用例，并且是一个包含两个项目的列表 $[i, r]$。例如：$[[0,0.000000],[2,0.123456],[1,0.654321]]$。\n\n测试套件：\n\n- 测试用例 $1$（正常路径，多个情景和策略）：\n  - 常数：$d_0 = 1.0$, $s_0 = 1.0$, $\\alpha = 1.6$, $\\beta = 0.9$, $\\phi = 1.2$, $r = 0.6$, $c_u = 0.4$。\n  - 策略（按顺序索引）：\n    - $0$: $(x,u) = (0.0,\\,0.0)$\n    - $1$: $(x,u) = (0.3,\\,0.0)$\n    - $2$: $(x,u) = (0.6,\\,0.0)$\n    - $3$: $(x,u) = (0.2,\\,0.25)$\n    - $4$: $(x,u) = (0.4,\\,0.25)$\n  - 情景（笛卡尔积）：\n    - $a \\in \\{0.1,\\,0.3,\\,0.5\\}$\n    - $g \\in \\{0.0,\\,0.3\\}$\n    - $e \\in \\{0.4,\\,0.8\\}$\n\n- 测试用例 $2$（边界情况：单个情景；最佳策略的遗憾值为零）：\n  - 常数：$d_0 = 1.0$, $s_0 = 1.0$, $\\alpha = 1.5$, $\\beta = 1.0$, $\\phi = 1.0$, $r = 0.5$, $c_u = 0.3$。\n  - 策略（按顺序索引）：\n    - $0$: $(x,u) = (0.0,\\,0.0)$\n    - $1$: $(x,u) = (0.3,\\,0.0)$\n    - $2$: $(x,u) = (0.0,\\,0.2)$\n  - 情景：\n    - 单个情景，$a = 0.2$，$g = 0.0$，$e = 0.5$。\n\n- 测试用例 $3$（边缘情况：极端干旱和高增长；展示权衡）：\n  - 常数：$d_0 = 1.0$, $s_0 = 1.0$, $\\alpha = 1.7$, $\\beta = 1.0$, $\\phi = 1.3$, $r = 0.7$, $c_u = 0.5$。\n  - 策略（按顺序索引）：\n    - $0$: $(x,u) = (0.0,\\,0.0)$\n    - $1$: $(x,u) = (0.4,\\,0.0)$\n    - $2$: $(x,u) = (0.2,\\,0.3)$\n    - $3$: $(x,u) = (0.4,\\,0.3)$\n    - $4$: $(x,u) = (0.2,\\,0.5)$\n    - $5$: $(x,u) = (0.4,\\,0.5)$\n  - 情景（笛卡尔积）：\n    - $a \\in \\{0.6,\\,0.8\\}$\n    - $g \\in \\{0.4,\\,0.6\\}$\n    - $e \\in \\{0.2\\}$\n\n实现要求：\n- 完全按照上面的定义计算 $Q$、$\\Delta$ 和 $W$。\n- 使用遗憾值和最小最大遗憾值的定义来选择策略。\n- 将每个报告的 $R_{\\max}$ 四舍五入到六位小数。\n- 无用户输入；仅使用给定的测试套件。\n- 最终输出格式：单行包含一个 Python 风格的列表，该列表有三个元素（每个测试用例一个），其中每个元素是一个包含两项的列表 $[i, r]$，$i$ 是一个整数，$r$ 是一个四舍五入到六位小数的浮点数，例如 $[[0,0.000000],[2,0.123456],[1,0.654321]]$。",
            "solution": "用户提供了一个问题陈述，要求为一个程式化的自然-人类耦合水系统实现一个鲁棒决策（RDM）算法。核心任务是确定一个策略，该策略在一系列不确定的未来情景中能最小化最大遗憾值。\n\n首先根据指定标准对问题进行验证。\n\n### 问题验证\n\n**步骤 1：提取已知信息**\n\n问题提供了以下定义、模型和数据：\n\n- **情景参数（不确定性）$\\theta = (a,g,e)$**：\n  - 气候干旱参数：$a \\in [0,1]$\n  - 经济需求增长参数：$g$\n  - 行为价格弹性参数：$e \\ge 0$\n\n- **策略向量 $\\pi = (x,u)$**：\n  - 价格乘数：$x \\ge 0$\n  - 供应增强投资：$u \\ge 0$\n\n- **基准常数**：$d_0$, $s_0$, $\\alpha$, $\\beta$, $\\phi$, $r$, $c_u$。\n\n- **系统模型方程**：\n  - 需求函数：$D(d_0,g,e,x) = d_0 \\,(1+g)\\,\\max\\left(0,\\,1 - e\\,x\\right)$\n  - 供应函数：$S(s_0,a,r,u) = s_0\\,(1 - a) + r\\,\\sqrt{u}$\n  - 实际消耗量：$Q(D,S) = \\min\\left(D,\\,S\\right)$\n  - 稀缺量：$\\Delta(D,S) = \\max\\left(0,\\,D - S\\right)$\n  - 福祉函数：$W(\\alpha,\\beta,\\phi,c_u; Q, \\Delta, u) = \\alpha\\,Q - \\frac{1}{2}\\,\\beta\\,Q^2 - \\phi\\,\\Delta^2 - c_u\\,u$\n\n- **决策框架定义**：\n  - 遗憾值：$R(\\theta,\\pi) = W^*(\\theta) - W(\\theta,\\pi)$\n  - 每个情景的最佳福祉：$W^*(\\theta) = \\max_{\\pi' \\in \\Pi} W(\\theta,\\pi')$，其中 $\\Pi$ 是候选策略的有限集合。\n  - 每个策略的最大遗憾值：$R_{\\max}(\\pi) = \\max_{\\theta \\in \\Theta} R(\\theta,\\pi)$，其中 $\\Theta$ 是情景的有限集合。\n  - 最小最大遗憾策略：$\\pi^{\\text{MMR}} = \\arg\\min_{\\pi \\in \\Pi} R_{\\max}(\\pi)$。\n  - 平局打破规则：如果多个策略共享相同的最小最大遗憾值，则选择索引最低的那个。\n\n- **测试用例**：提供了三个不同的测试用例，每个用例都有一套完整的常数、候选策略和用于情景参数的离散值。\n\n**步骤 2：使用提取的已知信息进行验证**\n\n- **科学性基础**：该问题根植于复杂自适应系统建模这一成熟领域，具体涉及自然-人类耦合系统。该模型虽然是程式化的，但使用了标准的经济学和水文学原语：需求弹性、边际效益递减的供应增强、受供需最小值限制的消耗量，以及由凹性效益和凸性损害组成的福祉函数。利用最小最大遗憾值的RDM框架是在深度不确定性下进行决策的标准且备受推崇的方法。该模型在科学上是合理的。\n- **适定性**：该问题是适定的。任务涉及从一个有限的、明确列出的集合 $\\Pi$ 中搜索最优策略。不确定性集合 $\\Theta$ 也是有限的，通过离散参数值的笛卡尔积构建。这种结构保证了每个策略-情景对都存在一个福祉值，每个情景都存在一个最大福祉 $W^*$，每个策略都存在一个最大遗憾值 $R_{\\max}$，并且这些最大遗憾值中存在一个最小值。平局打破规则确保了解决方案的唯一性。\n- **客观性**：问题以精确、客观和数学化的语言表述。所有函数都有明确定义，并且为测试用例提供了所有参数。没有主观或模棱两可的陈述。\n- **缺陷清单**：该问题没有违反任何指定的缺陷条件。它是科学合理的、可形式化的、完整的、内部一致的，并且需要大量的计算来解决。\n\n**步骤 3：结论与行动**\n\n问题是**有效的**。将根据提供的规范来开发解决方案。\n\n### 算法解决方案\n\n该解决方案是鲁棒决策（RDM）工作流的一个实现。对于每个测试用例，我们系统地评估一组候选策略，以应对一组合理的未来情景，从而找到根据最小最大遗憾标准定义的最具不确定性鲁棒性的策略。\n\n对于每个测试用例，算法按以下步骤进行：\n\n1.  **情景生成**：通过对参数 $a$、$g$ 和 $e$ 的给定离散值进行笛卡尔积运算，构建不确定情景集合 $\\Theta$。如果 $N_a$、$N_g$ 和 $N_e$ 分别是每个参数的值的数量，则情景总数为 $N_\\theta = N_a \\times N_g \\times N_e$。\n\n2.  **福祉矩阵计算**：构建一个“支付”或福祉矩阵，记为 $\\mathbf{W}$。该矩阵的行对应于情景 $\\theta \\in \\Theta$，列对应于策略 $\\pi \\in \\Pi$。矩阵的每个元素 $W_{ij}$ 表示在情景 $\\theta_i$ 下实施策略 $\\pi_j$ 时实现的福祉。\n    为了计算 $W_{ij}$，我们首先为给定的情景 $\\theta_i = (a_i, g_i, e_i)$ 和策略 $\\pi_j = (x_j, u_j)$ 计算中间量：\n    -   需求：$D_{ij} = d_0 \\,(1+g_i)\\,\\max\\left(0,\\,1 - e_i\\,x_j\\right)$\n    -   供应：$S_{ij} = s_0\\,(1 - a_i) + r\\,\\sqrt{u_j}$\n    -   消耗量：$Q_{ij} = \\min\\left(D_{ij},\\,S_{ij}\\right)$\n    -   稀缺量：$\\Delta_{ij} = \\max\\left(0,\\,D_{ij} - S_{ij}\\right)$\n    -   福祉：$W_{ij} = \\alpha\\,Q_{ij} - \\frac{1}{2}\\,\\beta\\,Q_{ij}^2 - \\phi\\,\\Delta_{ij}^2 - c_u\\,u_j$\n\n3.  **遗憾矩阵计算**：首先，对于每个情景 $\\theta_i$（即福祉矩阵 $\\mathbf{W}$ 的每一行），我们找到最大可能福祉 $W_i^*$。这是在该情景下，给定可用策略选项可实现的最佳结果：\n    $$W_i^* = \\max_j W_{ij}$$\n    接下来，计算一个与 $\\mathbf{W}$ 维度相同的遗憾矩阵 $\\mathbf{R}$。每个元素 $R_{ij}$ 是策略 $\\pi_j$ 在情景 $\\theta_i$ 下的遗憾值，定义为与最佳可能结果的差距：\n    $$R_{ij} = W_i^* - W_{ij}$$\n\n4.  **最小最大遗憾策略选择**：对于每个策略 $\\pi_j$（即遗憾矩阵 $\\mathbf{R}$ 的每一列），我们通过找到它在所有情景中产生的最大遗憾值来确定其最坏情况下的表现：\n    $$R_{\\max}(\\pi_j) = \\max_i R_{ij}$$\n    这会产生一个最大遗憾值的向量，每个策略对应一个值。RDM 算法指导我们选择最小化这个最大遗憾值的策略。因此，最小最大遗憾策略 $\\pi^{\\text{MMR}}$ 是：\n    $$\\pi^{\\text{MMR}} = \\arg\\min_j R_{\\max}(\\pi_j)$$\n    记录该策略的索引及其相关的最小最大遗憾值 $R_{\\max}(\\pi^{\\text{MMR}})$。根据问题的平局打破规则，如果多个策略产生相同的最小最大遗憾值，则选择索引最小的那个。\n\n5.  **输出格式化**：每个测试用例的最终结果是一个包含两项的列表，其中包括所选策略 $\\pi^{\\text{MMR}}$ 的整数索引及其对应的最大遗憾值（四舍五入到六位小数）。\n\n整个过程被封装在一个程序中，该程序遍历提供的测试用例，并生成一个单行的列表之列表作为最终输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to execute the Robust Decision Making (RDM) algorithm\n    for all test cases and print the results.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1: happy path, multiple scenarios and policies\n        {\n            \"constants\": (1.0, 1.0, 1.6, 0.9, 1.2, 0.6, 0.4), # d0, s0, alpha, beta, phi, r, cu\n            \"policies\": [(0.0, 0.0), (0.3, 0.0), (0.6, 0.0), (0.2, 0.25), (0.4, 0.25)], # (x, u)\n            \"scenario_params\": ({0.1, 0.3, 0.5}, {0.0, 0.3}, {0.4, 0.8}) # a, g, e\n        },\n        # Test Case 2: boundary case: single scenario; best policy has zero regret\n        {\n            \"constants\": (1.0, 1.0, 1.5, 1.0, 1.0, 0.5, 0.3), # d0, s0, alpha, beta, phi, r, cu\n            \"policies\": [(0.0, 0.0), (0.3, 0.0), (0.0, 0.2)], # (x, u)\n            \"scenario_params\": ({0.2}, {0.0}, {0.5}) # a, g, e\n        },\n        # Test Case 3: edge case: extreme dryness and high growth\n        {\n            \"constants\": (1.0, 1.0, 1.7, 1.0, 1.3, 0.7, 0.5), # d0, s0, alpha, beta, phi, r, cu\n            \"policies\": [(0.0, 0.0), (0.4, 0.0), (0.2, 0.3), (0.4, 0.3), (0.2, 0.5), (0.4, 0.5)], # (x, u)\n            \"scenario_params\": ({0.6, 0.8}, {0.4, 0.6}, {0.2}) # a, g, e\n        }\n    ]\n\n    final_results = []\n    for case in test_cases:\n        result_pair = run_rdm_analysis(\n            case[\"constants\"], case[\"policies\"], case[\"scenario_params\"]\n        )\n        # Append the [index, value] pair, with value rounded as required.\n        final_results.append([result_pair[0], round(result_pair[1], 6)])\n\n    # Print the final result in the exact specified format.\n    print(str(final_results).replace(\" \", \"\"))\n\ndef run_rdm_analysis(constants, policies, scenario_params):\n    \"\"\"\n    Performs the RDM calculation for a single test case.\n\n    Args:\n        constants (tuple): A tuple of the baseline constants.\n        policies (list): A list of policy tuples (x, u).\n        scenario_params (tuple): A tuple of sets for a, g, and e values.\n\n    Returns:\n        list: A two-item list [policy_index, min_max_regret].\n    \"\"\"\n    d0, s0, alpha, beta, phi, r_const, cu = constants\n    a_vals, g_vals, e_vals = scenario_params\n\n    # Step 1: Generate scenarios from the Cartesian product of parameter values\n    scenarios = []\n    for a in sorted(list(a_vals)):\n        for g in sorted(list(g_vals)):\n            for e in sorted(list(e_vals)):\n                scenarios.append((a, g, e))\n\n    num_scenarios = len(scenarios)\n    num_policies = len(policies)\n\n    # Step 2: Compute the welfare matrix\n    welfare_matrix = np.zeros((num_scenarios, num_policies))\n\n    for i, (a, g, e) in enumerate(scenarios):\n        for j, (x, u) in enumerate(policies):\n            # Demand calculation\n            demand = d0 * (1 + g) * max(0, 1 - e * x)\n            # Supply calculation\n            supply = s0 * (1 - a) + r_const * np.sqrt(u)\n            \n            # Consumption and scarcity\n            Q = min(demand, supply)\n            Delta = max(0, demand - supply)\n\n            # Welfare calculation\n            welfare = alpha * Q - 0.5 * beta * Q**2 - phi * Delta**2 - cu * u\n            welfare_matrix[i, j] = welfare\n\n    # Step 3: Compute the regret matrix\n    # Find the maximum welfare for each scenario (row)\n    w_star_per_scenario = np.max(welfare_matrix, axis=1)\n\n    # Regret is the difference between optimal welfare and actual welfare.\n    # We use broadcasting to subtract the w_star vector from each column.\n    regret_matrix = w_star_per_scenario[:, np.newaxis] - welfare_matrix\n\n    # Step 4: Find the minimax regret policy\n    # Find the maximum regret for each policy (column)\n    max_regret_per_policy = np.max(regret_matrix, axis=0)\n\n    # Find the policy that minimizes the maximum regret\n    min_max_regret = np.min(max_regret_per_policy)\n    # np.argmin() breaks ties by returning the first (lowest) index\n    best_policy_index = np.argmin(max_regret_per_policy)\n\n    return [int(best_policy_index), min_max_regret]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "没有模型是完美的，一项关键的实践是识别其局限性。本练习介绍贝叶斯后验预测检验，将其作为一种强大的模型批判工具。通过从您拟合的模型中模拟数据并将其与观测数据进行比较，您将学会诊断特定的结构性缺陷，例如遗漏变量或错误的误差假设，从而确保对模型能力进行更诚实的评估。",
            "id": "4129002",
            "problem": "您的任务是为一个简化的、耦合的自然-人类渔业系统的线性高斯模型执行贝叶斯后验预测检验。观测结果是捕捞量的对数，记为 $y_t$，它由人类捕捞努力度 $H_t$ 和一个自然环境指数 $N_t$ 驱动。该模型对预测变量是线性的，具有高斯噪声，并且系数服从高斯先验。您的程序必须通过从后验预测分布中生成重复数据，并计算用于诊断模型与观测值之间系统性失配来源的差异度量，来实现后验预测检验。目标是识别是否存在方差失配、残差自相关以及被忽略的延迟人类响应。\n\n基本假设：\n- 观测模型是线性-高斯模型：对于时间 $t = 1, \\dots, T$，数据满足\n$$ y_t = \\beta_0 + \\beta_1 H_t + \\beta_2 N_t + \\varepsilon_t, \\quad \\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2), $$\n其中 $H_t$ 代表人类捕捞努力度（单位：船-天），$N_t$ 代表自然驱动因素（无量纲指数），$y_t$ 是捕捞量的对数（单位：吨的自然对数）。三角函数中使用的角度以弧度为单位。\n- 系数的先验是高斯分布：$$ \\boldsymbol{\\beta} \\sim \\mathcal{N}(\\mathbf{0}, \\tau^2 \\mathbf{I}_3), $$ 其中 $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\beta_2)^\\top$ 且 $\\mathbf{I}_3$ 是 $3 \\times 3$ 单位矩阵。\n- 方差 $\\sigma^2$ 和先验方差 $\\tau^2$ 是已知的。\n\n后验预测检验：\n- 给定设计矩阵 $\\mathbf{X} \\in \\mathbb{R}^{T \\times 3}$，其行向量为 $\\mathbf{x}_t = (1, H_t, N_t)$，似然函数为 $p(\\mathbf{y} | \\boldsymbol{\\beta}) = \\mathcal{N}(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I}_T)$，先验分布为 $p(\\boldsymbol{\\beta}) = \\mathcal{N}(\\mathbf{0}, \\tau^2 \\mathbf{I}_3)$。后验分布是高斯分布。从后验分布中抽取样本 $\\boldsymbol{\\beta}^{(m)}$，其中 $m = 1, \\dots, M$，并为每次抽取生成一个后验预测重复值\n$$ \\mathbf{y}_{\\text{rep}}^{(m)} = \\mathbf{X} \\boldsymbol{\\beta}^{(m)} + \\boldsymbol{\\varepsilon}^{(m)}, \\quad \\boldsymbol{\\varepsilon}^{(m)} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I}_T). $$\n- 定义以下差异函数：\n    1. 方差差异：\n    $$ s^2(\\mathbf{y}) = \\frac{1}{T-1} \\sum_{t=1}^{T} \\left(y_t - \\bar{y}\\right)^2, \\quad \\bar{y} = \\frac{1}{T} \\sum_{t=1}^T y_t. $$\n    2. 残差一阶滞后自相关差异：\n    $$ a_1(\\mathbf{r}) = \\text{corr}(r_{2:T}, r_{1:(T-1)}), \\quad \\mathbf{r} = \\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}, $$\n    对观测残差和重复残差分别计算，使用相同的后验抽取样本 $\\boldsymbol{\\beta}^{(m)}$。\n    3. 残差与滞后人类努力度的相关性差异：\n    $$ r_{H\\text{lag}}(\\mathbf{r}, \\mathbf{H}) = \\text{corr}(r_{2:T}, H_{1:(T-1)}). $$\n- 使用蒙特卡洛方法估计贝叶斯尾部概率（贝叶斯 $p$-值）：\n    - 方差：$$ p_{\\text{var}} = \\frac{1}{M} \\sum_{m=1}^M \\mathbb{I}\\left\\{ s^2\\left(\\mathbf{y}_{\\text{rep}}^{(m)}\\right) \\ge s^2(\\mathbf{y}) \\right\\}. $$\n    - 残差自相关：$$ p_{\\text{acf1}} = \\frac{1}{M} \\sum_{m=1}^M \\mathbb{I}\\left\\{ a_1\\left(\\mathbf{r}_{\\text{rep}}^{(m)}\\right) \\ge a_1(\\mathbf{r}^{(m)}) \\right\\}. $$\n    - 残差-滞后努力度：$$ p_{\\text{reslag}} = \\frac{1}{M} \\sum_{m=1}^M \\mathbb{I}\\left\\{ r_{H\\text{lag}}\\left(\\mathbf{r}_{\\text{rep}}^{(m)}, \\mathbf{H}\\right) \\ge r_{H\\text{lag}}(\\mathbf{r}^{(m)}, \\mathbf{H}) \\right\\}. $$\n- 如果对应的贝叶斯 $p$-值是极端的：$p \\le 0.1$ 或 $p \\ge 0.9$（用小数表示的双尾极端性准则），则标记该差异为失配。\n\n测试套件和模型配置：\n实现以下三个测试案例，以探查模型充分性的不同方面。对每个案例，使用指定的系数和种子生成 $\\mathbf{H}$、$\\mathbf{N}$ 和 $\\mathbf{y}$。三角函数必须使用弧度。在所有案例中，用截距、$\\mathbf{H}$ 和 $\\mathbf{N}$ 构建 $\\mathbf{X}$。\n\n- 案例 A（良定，“理想路径”）：\n    - 长度：$T = 30$。\n    - 随机种子：将生成器种子设置为 $123$。\n    - 努力度：$$ H_t = 2 + 0.3\\frac{t}{T} + 0.5 \\sin\\left(\\frac{2\\pi t}{12}\\right) + \\eta_t, \\quad \\eta_t \\sim \\mathcal{N}(0, 0.2^2). $$\n    - 自然驱动因素：$$ N_t = 0.8 \\sin\\left(\\frac{2\\pi t}{6}\\right) + \\xi_t, \\quad \\xi_t \\sim \\mathcal{N}(0, 0.2^2). $$\n    - 用于生成观测数据的系数：$\\beta_0 = 1.0$, $\\beta_1 = 0.8$, $\\beta_2 = 0.5$。\n    - 观测噪声：$\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$，其中 $\\sigma^2 = 0.3^2$。\n    - 先验方差：$\\tau^2 = 10$。\n- 案例 B（忽略延迟的人类响应和过度离散）：\n    - 长度：$T = 30$。\n    - 随机种子：将生成器种子设置为 $456$。\n    - 努力度：形式与案例 A 相同，具有独立的 $\\eta_t \\sim \\mathcal{N}(0, 0.2^2)$。\n    - 自然驱动因素：形式与案例 A 相同，具有独立的 $\\xi_t \\sim \\mathcal{N}(0, 0.2^2)$。\n    - 用于生成观测数据的系数：$\\beta_0 = 1.0$, $\\beta_1 = 0.8$, $\\beta_2 = 0.5$，外加一个延迟的努力度效应 $\\gamma = 0.8$，其中\n    $$ y_t = \\beta_0 + \\beta_1 H_t + \\beta_2 N_t + \\gamma H_{t-1} + \\varepsilon_t, \\quad \\text{for } t \\ge 2, $$\n    并且对于 $t=1$，使用 $y_1 = \\beta_0 + \\beta_1 H_1 + \\beta_2 N_1 + \\varepsilon_1$。\n    - 观测噪声：$\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$，其中 $\\sigma^2 = 0.6^2$（相对于模型的过度离散）。\n    - 先验方差：$\\tau^2 = 10$。\n- 案例 C（来自自然-人类动态的残差自相关）：\n    - 长度：$T = 20$。\n    - 随机种子：将生成器种子设置为 $789$。\n    - 努力度和自然驱动因素：形式与案例 A 相同，具有独立的 $\\eta_t \\sim \\mathcal{N}(0, 0.2^2)$ 和 $\\xi_t \\sim \\mathcal{N}(0, 0.2^2)$。\n    - 用于生成观测数据的系数：$\\beta_0 = 1.0$, $\\beta_1 = 0.8$, $\\beta_2 = 0.5$。\n    - 观测噪声：1阶自回归（AR(1)），参数为 $\\phi = 0.7$，新息为 $u_t \\sim \\mathcal{N}(0, 0.25^2)$，\n    $$ \\varepsilon_t = \\phi \\varepsilon_{t-1} + u_t, \\quad \\varepsilon_1 = u_1, $$\n    因此模型的独立误差假设被违反了。\n    - 在拟合的模型中，设置 $\\sigma^2 = 0.25^2$ 和先验方差 $\\tau^2 = 10$。\n\n后验抽样细节：\n- 通过配方法计算 $\\boldsymbol{\\beta}$ 的高斯后验分布，该方法由贝叶斯法则引出。设 $\\mathbf{X} \\in \\mathbb{R}^{T \\times 3}$ 且 $\\mathbf{y} \\in \\mathbb{R}^T$。后验协方差和均值为\n$$ \\mathbf{S} = \\left( \\frac{1}{\\sigma^2} \\mathbf{X}^\\top \\mathbf{X} + \\frac{1}{\\tau^2} \\mathbf{I}_3 \\right)^{-1}, \\quad \\mathbf{m} = \\mathbf{S} \\left( \\frac{1}{\\sigma^2} \\mathbf{X}^\\top \\mathbf{y} \\right). $$\n- 抽取 $M$ 个样本 $\\boldsymbol{\\beta}^{(m)} \\sim \\mathcal{N}(\\mathbf{m}, \\mathbf{S})$，并为每次抽取生成一个重复值 $\\mathbf{y}_{\\text{rep}}^{(m)}$。\n\n实现要求：\n- 每个测试案例使用 $M = 2000$ 次后验抽取和重复。\n- 所有三角计算均使用弧度单位的角度。\n- 对于相关性计算，使用带无偏样本中心化的皮尔逊相关系数；如果方差在数值上为零，则使用一个小的常数进行正则化（例如，在分母上加上 $10^{-12}$）。\n- 您的程序应生成单行输出，其中按顺序包含案例 A、案例 B、案例 C 的三个差异（方差、残差一阶滞后自相关、残差-滞后努力度相关）的失配标志，形式为方括号内以逗号分隔的列表。每个标志必须是布尔值。要求的最终输出格式为：\n\"[caseA_var_flag,caseA_acf1_flag,caseA_reslag_flag,caseB_var_flag,caseB_acf1_flag,caseB_reslag_flag,caseC_var_flag,caseC_acf1_flag,caseC_reslag_flag]\"。",
            "solution": "该问题要求为一个简化的渔业系统线性高斯模型实现贝叶斯后验预测检验。首先评估问题陈述的有效性。\n\n### 问题验证\n\n**步骤 1：提取给定信息**\n\n*   **观测模型**: $y_t = \\beta_0 + \\beta_1 H_t + \\beta_2 N_t + \\varepsilon_t$，其中 $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$，对于 $t = 1, \\dots, T$。\n*   **先验分布**: $\\boldsymbol{\\beta} \\sim \\mathcal{N}(\\mathbf{0}, \\tau^2 \\mathbf{I}_3)$，其中 $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\beta_2)^\\top$。\n*   **已知参数**: 对于要拟合的模型，误差方差 $\\sigma^2$ 和先验方差 $\\tau^2$ 是已知的。\n*   **设计矩阵**: $\\mathbf{X} \\in \\mathbb{R}^{T \\times 3}$ 的行向量为 $\\mathbf{x}_t = (1, H_t, N_t)$。\n*   **后验分布**: $\\boldsymbol{\\beta}$ 的后验分布是高斯分布，$\\mathcal{N}(\\mathbf{m}, \\mathbf{S})$，其均值为 $\\mathbf{m} = \\mathbf{S} ( \\frac{1}{\\sigma^2} \\mathbf{X}^\\top \\mathbf{y} )$，协方差为 $\\mathbf{S} = ( \\frac{1}{\\sigma^2} \\mathbf{X}^\\top \\mathbf{X} + \\frac{1}{\\tau^2} \\mathbf{I}_3 )^{-1}$。\n*   **后验预测重复**: 对于一个后验样本 $\\boldsymbol{\\beta}^{(m)}$，生成一个重复值 $\\mathbf{y}_{\\text{rep}}^{(m)} = \\mathbf{X} \\boldsymbol{\\beta}^{(m)} + \\boldsymbol{\\varepsilon}^{(m)}$，其中 $\\boldsymbol{\\varepsilon}^{(m)} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I}_T)$。将使用 $M = 2000$ 个样本。\n*   **差异度量**：\n    1.  方差：$s^2(\\mathbf{y}) = \\frac{1}{T-1} \\sum_{t=1}^{T} (y_t - \\bar{y})^2$。\n    2.  残差一阶滞后自相关：$a_1(\\mathbf{r}) = \\text{corr}(r_{2:T}, r_{1:(T-1)})$，对于残差 $\\mathbf{r} = \\mathbf{y} - \\mathbf{X} \\boldsymbol{\\beta}$。\n    3.  残差与滞后人类努力度的相关性：$r_{H\\text{lag}}(\\mathbf{r}, \\mathbf{H}) = \\text{corr}(r_{2:T}, H_{1:(T-1)})$。\n*   **贝叶斯 P-值**：\n    1.  $p_{\\text{var}} = \\frac{1}{M} \\sum_{m=1}^M \\mathbb{I}\\{ s^2(\\mathbf{y}_{\\text{rep}}^{(m)}) \\ge s^2(\\mathbf{y}) \\}$.\n    2.  $p_{\\text{acf1}} = \\frac{1}{M} \\sum_{m=1}^M \\mathbb{I}\\{ a_1(\\mathbf{r}_{\\text{rep}}^{(m)}) \\ge a_1(\\mathbf{r}^{(m)}) \\}$.\n    3.  $p_{\\text{reslag}} = \\frac{1}{M} \\sum_{m=1}^M \\mathbb{I}\\{ r_{H\\text{lag}}(\\mathbf{r}_{\\text{rep}}^{(m)}, \\mathbf{H}) \\ge r_{H\\text{lag}}(\\mathbf{r}^{(m)}, \\mathbf{H}) \\}$.\n*   **失配准则**: 如果贝叶斯p值 $p$ 满足 $p \\le 0.1$ 或 $p \\ge 0.9$，则标记为失配。\n*   **测试案例**: 定义了三个案例（A、B、C），具有特定的种子、数据生成过程和模型参数。\n    *   **案例 A**: $T = 30$，种子=$123$，良定模型，用于数据生成和模型拟合的 $\\sigma^2 = 0.3^2$，$\\tau^2 = 10$。\n    *   **案例 B**: $T = 30$，种子=$456$，数据由一个被忽略的预测变量（$H_{t-1}$）和更大的噪声方差（$\\sigma^2_{\\text{true}} = 0.6^2$）生成。拟合的模型是简单的线性模型。模型假设的 $\\sigma^2$ 没有明确说明。\n    *   **案例 C**: $T = 20$，种子=$789$，数据由 AR(1) 误差（$\\phi=0.7$，新息方差 $0.25^2$）生成，而模型假设误差是独立同分布（i.i.d.）的，其方差为 $\\sigma^2 = 0.25^2$，且 $\\tau^2 = 10$。\n*   **实现注意**: 使用皮尔逊相关系数，分母正则化值为 $10^{-12}$。\n\n**步骤 2：使用提取的已知信息进行验证**\n\n该问题具有科学依据，采用标准的贝叶斯方法进行模型检验。它是一个良构问题，提供了足够的细节以获得唯一的、可计算的解。语言客观而精确。\n\n案例 B 中存在一个微小的歧义，即没有明确指定拟合模型的观测噪声方差，而真实数据生成的方差给定为 $\\sigma^2_{\\text{true}} = 0.6^2$。案例 A 对数据生成和模型拟合使用相同的 $\\sigma^2$。案例 C 则明确地将它们解耦。案例 B 的意图似乎是测试一个在两方面存在设定错误的模型：一个被忽略的预测变量和一个关于误差方差的不正确假设（数据相对于模型存在过度离散）。在这种情况下，最合乎逻辑和标准的解释是，案例 B 中测试的模型与案例 A 的“基础”模型相同，即假设 $\\sigma^2 = 0.3^2$。这一假设使案例 B 成为一个对模型不充分性的良定义测试。\n\n**步骤 3：结论与行动**\n\n在对案例 B 的模型规范进行合理解释的前提下，该问题是**有效的**。将通过实施指定的程序来求解。\n\n### 解决方案\n\n对每个测试案例，该过程包括三个主要阶段：(1) 根据特定案例的过程生成合成观测数据；(2) 在给定这些数据的情况下，推导模型参数的后验分布；(3) 通过从模型中模拟重复数据，并使用指定的差异度量将其与观测数据进行比较，来执行后验预测检验。\n\n**1. 理论框架**\n\n分析的基础是贝叶斯定理，它将参数的先验分布 $p(\\boldsymbol{\\beta})$ 与给定参数下数据的似然 $p(\\mathbf{y}|\\boldsymbol{\\beta})$ 相结合，得到后验分布 $p(\\boldsymbol{\\beta}|\\mathbf{y})$。\n$$\np(\\boldsymbol{\\beta}|\\mathbf{y}, \\mathbf{X}, \\sigma^2, \\tau^2) \\propto p(\\mathbf{y}|\\boldsymbol{\\beta}, \\mathbf{X}, \\sigma^2) \\, p(\\boldsymbol{\\beta}|\\tau^2)\n$$\n给定高斯似然 $\\mathbf{y} \\sim \\mathcal{N}(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2\\mathbf{I}_T)$ 和高斯先验 $\\boldsymbol{\\beta} \\sim \\mathcal{N}(\\mathbf{0}, \\tau^2\\mathbf{I}_3)$，得到的后验分布也是高斯分布，$\\boldsymbol{\\beta}|\\mathbf{y} \\sim \\mathcal{N}(\\mathbf{m}, \\mathbf{S})$。后验均值 $\\mathbf{m}$ 和协方差 $\\mathbf{S}$ 由下式给出：\n$$\n\\mathbf{S} = \\left( \\frac{1}{\\sigma^2} \\mathbf{X}^\\top \\mathbf{X} + \\frac{1}{\\tau^2} \\mathbf{I}_3 \\right)^{-1}\n$$\n$$\n\\mathbf{m} = \\mathbf{S} \\left( \\frac{1}{\\sigma^2} \\mathbf{X}^\\top \\mathbf{y} \\right)\n$$\n这些方程表示在观测到数据 $\\mathbf{y}$ 后，关于参数 $\\boldsymbol{\\beta}$ 的知识更新状态。\n\n**2. 后验预测检验**\n\n后验预测检验是一种评估模型拟合度的方法，它通过检验模型能否生成与我们实际观测到的数据相似的数据来进行。一个后验预测重复值 $\\mathbf{y}_{\\text{rep}}$ 是从后验预测分布中生成的模拟数据集，\n$$\np(\\mathbf{y}_{\\text{rep}} | \\mathbf{y}) = \\int p(\\mathbf{y}_{\\text{rep}} | \\boldsymbol{\\beta}) \\, p(\\boldsymbol{\\beta} | \\mathbf{y}) \\, d\\boldsymbol{\\beta}\n$$\n在操作上，我们首先从后验分布 $\\mathcal{N}(\\mathbf{m}, \\mathbf{S})$ 中抽取一个参数向量 $\\boldsymbol{\\beta}^{(m)}$。然后，我们通过使用该参数值从似然函数中抽样来生成一个重复数据集：$\\mathbf{y}_{\\text{rep}}^{(m)} \\sim \\mathcal{N}(\\mathbf{X}\\boldsymbol{\\beta}^{(m)}, \\sigma^2\\mathbf{I}_T)$。\n\n然后我们定义差异度量 $T(\\mathbf{y}, \\boldsymbol{\\beta})$，它们是数据和（可能地）参数的函数。选择这些度量是为了探查模型的特定潜在缺陷。我们将对重复数据计算的差异分布 $T(\\mathbf{y}_{\\text{rep}}, \\boldsymbol{\\beta})$ 与对观测数据计算的差异 $T(\\mathbf{y}, \\boldsymbol{\\beta})$ 进行比较。这两个分布之间的系统性差异表明模型存在失配。贝叶斯 p-值量化了这种比较。\n\n**3. 各案例的实现**\n\n对三个测试案例中的每一个，执行以下操作序列。\n\n**阶段 A：数据生成**\n使用特定案例的种子初始化一个随机数生成器。生成人类努力度 $H_t$ 和自然驱动因素 $N_t$ 的时间序列。然后，根据该案例特定的线性模型生成观测结果 $y_t$，该模型可能包含拟合模型中所没有的结构性设定错误。\n\n*   **案例 A（良定）**：数据从将要拟合的精确模型生成，其中 $\\sigma^2 = 0.3^2$。\n*   **案例 B（忽略变量和过度离散）**：数据在生成时包含一个额外的滞后努力度项 $\\gamma H_{t-1}$，并具有更大的误差方差 $\\sigma^2_{\\text{true}} = 0.6^2$。将要拟合的模型是简单的模型（忽略滞后项），并且如前所述，将假设 $\\sigma^2 = 0.3^2$。\n*   **案例 C（自相关误差）**：数据由 AR(1) 误差生成，违反了模型的独立性假设。将拟合一个假设误差为独立同分布（i.i.d.）的模型，其方差 $\\sigma^2 = 0.25^2$ 等于真实 AR(1) 过程的新息方差。\n\n**阶段 B：后验抽样**\n从 $H_t$ 和 $N_t$ 构建设计矩阵 $\\mathbf{X}$。使用生成的数据 $\\mathbf{y}$ 和为每个案例指定的拟合模型参数（$\\sigma^2$, $\\tau^2$），计算后验均值 $\\mathbf{m}$ 和协方差 $\\mathbf{S}$。然后，从该后验分布 $\\mathcal{N}(\\mathbf{m}, \\mathbf{S})$ 中抽取 $M=2000$ 个 $\\boldsymbol{\\beta}^{(m)}$ 样本。\n\n**阶段 C：差异计算和 P-值估计**\n循环运行 $m = 1, \\dots, M$ 次。在每次迭代中：\n1.  使用抽取的 $\\boldsymbol{\\beta}^{(m)}$ 生成一个后验预测重复值 $\\mathbf{y}_{\\text{rep}}^{(m)}$。\n2.  计算差异度量。请注意，对于基于残差的差异（$a_1$ 和 $r_{H\\text{lag}}$），“观测”值通过残差 $\\mathbf{r}^{(m)} = \\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta}^{(m)}$ 依赖于当前的参数抽取 $\\boldsymbol{\\beta}^{(m)}$。\n    *   将 $s^2(\\mathbf{y}_{\\text{rep}}^{(m)})$ 与固定值 $s^2(\\mathbf{y})$ 进行比较。\n    *   将 $a_1(\\mathbf{r}_{\\text{rep}}^{(m)})$ 与 $a_1(\\mathbf{r}^{(m)})$ 进行比较。\n    *   将 $r_{H\\text{lag}}(\\mathbf{r}_{\\text{rep}}^{(m)}, \\mathbf{H})$ 与 $r_{H\\text{lag}}(\\mathbf{r}^{(m)}, \\mathbf{H})$ 进行比较。\n3.  根据这些比较递增指示函数。\n\n循环结束后，通过将指示函数的总和除以 $M$ 来计算贝叶斯 p-值（$p_{\\text{var}}$, $p_{\\text{acf1}}$, $p_{\\text{reslag}}$）。最后，根据极端性准则（$p \\le 0.1$ 或 $p \\ge 0.9$）检查每个 p-值，以确定布尔失配标志。然后将三个案例的九个标志合并到最终输出中。\n\n实现了一个自定义的皮尔逊相关函数来处理数值稳定性所需的正则化。\n这个全面的过程允许在不同条件下对模型的充分性进行严格诊断，突出显示了假设的模型结构未能很好地捕捉数据的哪些方面。",
            "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef custom_corr(x, y, reg=1e-12):\n    \"\"\"\n    Computes the Pearson correlation coefficient with a regularization term.\n    \"\"\"\n    if x.ndim != 1 or y.ndim != 1 or len(x) != len(y):\n        raise ValueError(\"Inputs must be 1D arrays of the same length.\")\n\n    x_mean, y_mean = np.mean(x), np.mean(y)\n    x_c, y_c = x - x_mean, y - y_mean\n    \n    numerator = np.sum(x_c * y_c)\n    \n    denom_x_sq = np.sum(x_c**2)\n    denom_y_sq = np.sum(y_c**2)\n    \n    denominator = np.sqrt(denom_x_sq * denom_y_sq) + reg\n    \n    if denominator == 0:\n        return 0.0\n    \n    return numerator / denominator\n\ndef run_posterior_predictive_check(case_params):\n    \"\"\"\n    Runs the full posterior predictive check for a given test case.\n    \"\"\"\n    \n    T = case_params['T']\n    seed = case_params['seed']\n    gen_coeffs = case_params['gen_coeffs']\n    model_sigma2 = case_params['model_sigma2']\n    tau2 = case_params['tau2']\n    M = case_params['M']\n    \n    rng = np.random.default_rng(seed)\n\n    # Stage 1: Generate synthetic data\n    t_vals = np.arange(1, T + 1)\n    \n    # Generate predictors H and N\n    eta = rng.normal(0, np.sqrt(0.2**2), T)\n    H_t = 2 + 0.3 * (t_vals / T) + 0.5 * np.sin(2 * np.pi * t_vals / 12) + eta\n    \n    xi = rng.normal(0, np.sqrt(0.2**2), T)\n    N_t = 0.8 * np.sin(2 * np.pi * t_vals / 6) + xi\n    \n    # Design matrix\n    X = np.vstack([np.ones(T), H_t, N_t]).T\n    \n    # Generate observed outcome y_t based on case\n    # Case A: Well-specified\n    if case_params['name'] == 'A':\n        gen_sigma2 = 0.3**2\n        eps = rng.normal(0, np.sqrt(gen_sigma2), T)\n        y_obs = X @ gen_coeffs + eps\n    \n    # Case B: Omitted variable and overdispersion\n    elif case_params['name'] == 'B':\n        gen_sigma2 = 0.6**2\n        gamma = 0.8\n        H_lag = np.roll(H_t, 1)\n        H_lag[0] = 0 # No lagged effect for t=1\n        eps = rng.normal(0, np.sqrt(gen_sigma2), T)\n        \n        y_obs = X @ gen_coeffs + gamma * H_lag + eps\n        \n    # Case C: Autocorrelated errors\n    elif case_params['name'] == 'C':\n        phi = 0.7\n        u = rng.normal(0, np.sqrt(0.25**2), T)\n        eps = np.zeros(T)\n        eps[0] = u[0]\n        for t in range(1, T):\n            eps[t] = phi * eps[t-1] + u[t]\n        y_obs = X @ gen_coeffs + eps\n\n    # Stage 2: Compute posterior distribution\n    # S = (1/sigma^2 * X.T @ X + 1/tau^2 * I)^-1\n    # m = S @ (1/sigma^2 * X.T @ y)\n    S_inv = (1 / model_sigma2) * (X.T @ X) + (1 / tau2) * np.identity(3)\n    S_post = np.linalg.inv(S_inv)\n    m_post = S_post @ ((1 / model_sigma2) * (X.T @ y_obs))\n\n    # Stage 3: Posterior predictive checks\n    beta_samples = rng.multivariate_normal(m_post, S_post, size=M)\n    \n    # Discrepancy for observed data that does not depend on beta\n    s2_obs = np.var(y_obs, ddof=1)\n    \n    # Placeholders for counts\n    var_count = 0\n    acf1_count = 0\n    reslag_count = 0\n    \n    for m in range(M):\n        beta_m = beta_samples[m]\n        \n        # Generate replicated data\n        eps_rep = rng.normal(0, np.sqrt(model_sigma2), T)\n        y_rep = X @ beta_m + eps_rep\n        \n        # 1. Variance discrepancy\n        s2_rep = np.var(y_rep, ddof=1)\n        if s2_rep >= s2_obs:\n            var_count += 1\n            \n        # Residuals depend on beta_m\n        r_obs_m = y_obs - X @ beta_m\n        r_rep_m = y_rep - X @ beta_m\n        \n        # 2. Residual lag-1 autocorrelation discrepancy\n        a1_obs_m = custom_corr(r_obs_m[1:], r_obs_m[:-1])\n        a1_rep_m = custom_corr(r_rep_m[1:], r_rep_m[:-1])\n        if a1_rep_m >= a1_obs_m:\n            acf1_count += 1\n            \n        # 3. Residual lagged human effort correlation discrepancy\n        H_lag_pred = H_t[:-1]\n        r_obs_m_sliced = r_obs_m[1:]\n        r_rep_m_sliced = r_rep_m[1:]\n        \n        rh_lag_obs_m = custom_corr(r_obs_m_sliced, H_lag_pred)\n        rh_lag_rep_m = custom_corr(r_rep_m_sliced, H_lag_pred)\n        if rh_lag_rep_m >= rh_lag_obs_m:\n            reslag_count += 1\n            \n    # Compute Bayesian p-values\n    p_var = var_count / M\n    p_acf1 = acf1_count / M\n    p_reslag = reslag_count / M\n    \n    # Determine flags based on p-values\n    var_flag = p_var <= 0.1 or p_var >= 0.9\n    acf1_flag = p_acf1 <= 0.1 or p_acf1 >= 0.9\n    reslag_flag = p_reslag <= 0.1 or p_reslag >= 0.9\n    \n    return [var_flag, acf1_flag, reslag_flag]\n\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    base_params = {\n        'tau2': 10.0,\n        'M': 2000,\n    }\n    \n    case_A_params = {\n        'name': 'A',\n        'T': 30,\n        'seed': 123,\n        'gen_coeffs': np.array([1.0, 0.8, 0.5]),\n        'model_sigma2': 0.3**2,\n        **base_params\n    }\n    \n    case_B_params = {\n        'name': 'B',\n        'T': 30,\n        'seed': 456,\n        'gen_coeffs': np.array([1.0, 0.8, 0.5]),\n        'model_sigma2': 0.3**2, # Model assumes this, but data has 0.6^2\n        **base_params\n    }\n    \n    case_C_params = {\n        'name': 'C',\n        'T': 20,\n        'seed': 789,\n        'gen_coeffs': np.array([1.0, 0.8, 0.5]),\n        'model_sigma2': 0.25**2, # Model assumes this, true process is AR(1)\n        **base_params\n    }\n\n    results = []\n    \n    results.extend(run_posterior_predictive_check(case_A_params))\n    results.extend(run_posterior_predictive_check(case_B_params))\n    results.extend(run_posterior_predictive_check(case_C_params))\n    \n    # Format the boolean results for printing\n    formatted_results = [str(r).lower() for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}