{
    "hands_on_practices": [
        {
            "introduction": "Many complex phenomena, from coordinated decision-making to phase transitions, can be understood by studying their behavior near a critical point. This practice analyzes the canonical model for a continuous, symmetric transition: the supercritical pitchfork bifurcation . By working through this foundational exercise, you will develop the core skills of identifying equilibrium states, determining their stability through linearization, and understanding how underlying symmetries constrain the system's dynamics.",
            "id": "4115580",
            "problem": "Consider a minimal, one-dimensional, symmetry-preserving coordination model for a collective variable $x$ in Complex Adaptive Systems (CAS), where the time evolution is given by the ordinary differential equation $\\dot{x} = \\mu x - x^3$. The parameter $\\mu$ represents a slowly varying control drive (e.g., net gain in alignment), and the state $x$ encodes a global order parameter invariant under sign inversion, i.e., the dynamics is equivariant with respect to the $\\mathbb{Z}_{2}$ group action $x\\mapsto -x$. Starting from first principles, and using only core definitions and well-tested facts (equilibrium points, linearization for stability in one dimension, and the concept of gradient dynamics), do the following:\n\n1. Derive all equilibrium points $x^{\\ast}$ as functions of the control parameter $\\mu$ by solving $\\dot{x}=0$.\n\n2. Classify the linear stability of each equilibrium $x^{\\ast}$ as a function of $\\mu$ using the one-dimensional linearization criterion based on $\\frac{d}{dx}(\\mu x - x^{3})$ evaluated at each equilibrium. Justify the classification from first principles.\n\n3. Explain, using the invariance under $x\\mapsto -x$ and the structure of the lowest-order odd nonlinearity compatible with this symmetry, how the $\\mathbb{Z}_{2}$ symmetry constrains the bifurcation to take the pitchfork form and why the branches emerging at the bifurcation are symmetric.\n\n4. As a succinct quantitative summary of the stability landscape, construct a scalar potential $V(x;\\mu)$ such that the dynamics is a gradient flow $\\dot{x}=-\\frac{\\partial V}{\\partial x}$. Choose the additive constant so that $V(0;\\mu)=0$. Provide your final answer as a single closed-form analytic expression for $V(x;\\mu)$, with no units. No rounding is required.",
            "solution": "The problem statement is a standard and well-posed exercise in elementary bifurcation theory, specifically concerning the analysis of a supercritical pitchfork bifurcation. It is scientifically grounded, internally consistent, and requires the application of fundamental principles of dynamical systems. The problem is therefore deemed valid.\n\nThe dynamical system is described by the one-dimensional ordinary differential equation:\n$$\n\\dot{x} = \\frac{dx}{dt} = f(x; \\mu) = \\mu x - x^{3}\n$$\nwhere $x$ is the state variable and $\\mu$ is a control parameter.\n\n1. Derivation of Equilibrium Points\n\nEquilibrium points, denoted by $x^{\\ast}$, are the states where the system does not change in time, i.e., $\\dot{x} = 0$. To find them, we solve the algebraic equation $f(x^{\\ast}; \\mu) = 0$.\n$$\n\\mu x^{\\ast} - (x^{\\ast})^{3} = 0\n$$\nFactoring out $x^{\\ast}$, we obtain:\n$$\nx^{\\ast} (\\mu - (x^{\\ast})^{2}) = 0\n$$\nThis equation has two possibilities for solutions.\n\nCase 1: $x^{\\ast} = 0$.\nThis gives a trivial equilibrium point, $x^{\\ast}_{0} = 0$. This equilibrium exists for all values of the parameter $\\mu$.\n\nCase 2: $\\mu - (x^{\\ast})^{2} = 0$.\nThis gives $(x^{\\ast})^{2} = \\mu$. For real-valued solutions for $x^{\\ast}$ to exist, we must have $\\mu \\ge 0$. When this condition is met, we find two additional equilibrium points:\n$$\nx^{\\ast}_{\\pm} = \\pm\\sqrt{\\mu}\n$$\nThese two non-trivial equilibrium points emerge at $\\mu=0$ and exist only for $\\mu \\ge 0$.\n\nIn summary, the equilibrium points as a function of $\\mu$ are:\n- For $\\mu  0$: one equilibrium point, $x^{\\ast}_{0} = 0$.\n- For $\\mu \\ge 0$: three equilibrium points, $x^{\\ast}_{0} = 0$ and $x^{\\ast}_{\\pm} = \\pm\\sqrt{\\mu}$.\n\n2. Linear Stability Analysis of Equilibria\n\nThe stability of a one-dimensional equilibrium point $x^{\\ast}$ is determined by the sign of the derivative of the vector field, $f'(x) = \\frac{df}{dx}$, evaluated at $x^{\\ast}$. If $f'(x^{\\ast})  0$, small perturbations decay, and the equilibrium is stable (an attractor). If $f'(x^{\\ast}) > 0$, small perturbations grow, and the equilibrium is unstable (a repellor). If $f'(x^{\\ast}) = 0$, the equilibrium is non-hyperbolic, and linear analysis is inconclusive.\n\nFirst, we compute the derivative of $f(x; \\mu) = \\mu x - x^{3}$:\n$$\nf'(x; \\mu) = \\frac{d}{dx}(\\mu x - x^{3}) = \\mu - 3x^{2}\n$$\nNow, we evaluate this derivative at each equilibrium point.\n\nStability of $x^{\\ast}_{0} = 0$:\n$$\nf'(0; \\mu) = \\mu - 3(0)^{2} = \\mu\n$$\n- If $\\mu  0$, $f'(0; \\mu)  0$, so the equilibrium $x^{\\ast}_{0}=0$ is stable.\n- If $\\mu > 0$, $f'(0; \\mu) > 0$, so the equilibrium $x^{\\ast}_{0}=0$ is unstable.\n- At $\\mu = 0$, $f'(0; 0) = 0$. The stability changes at this point, which is the bifurcation point.\n\nStability of $x^{\\ast}_{\\pm} = \\pm\\sqrt{\\mu}$ (for $\\mu > 0$):\nWe evaluate the derivative at these points:\n$$\nf'(\\pm\\sqrt{\\mu}; \\mu) = \\mu - 3(\\pm\\sqrt{\\mu})^{2} = \\mu - 3\\mu = -2\\mu\n$$\nSince these equilibria only exist for $\\mu > 0$, the derivative $f'(\\pm\\sqrt{\\mu}; \\mu) = -2\\mu$ is always negative for $\\mu > 0$. Therefore, the two non-trivial equilibrium branches $x^{\\ast}_{\\pm} = \\pm\\sqrt{\\mu}$ are stable whenever they exist. At $\\mu=0$, they merge with the trivial branch and their stability is also non-hyperbolic.\n\nThe overall behavior is a transfer of stability from the trivial branch $x^{\\ast}_{0}=0$ to the two new stable branches $x^{\\ast}_{\\pm}=\\pm\\sqrt{\\mu}$ as the parameter $\\mu$ increases through $0$. This is the hallmark of a supercritical pitchfork bifurcation.\n\n3. Role of $\\mathbb{Z}_{2}$ Symmetry\n\nThe dynamics $\\dot{x} = f(x, \\mu)$ is stated to be equivariant with respect to the $\\mathbb{Z}_{2}$ group action $x\\mapsto -x$. This property imposes a constraint on the functional form of $f(x, \\mu)$. Specifically, if $x(t)$ is a solution, then $-x(t)$ must also be a solution. Let $y(t) = -x(t)$, so $\\dot{y} = -\\dot{x} = -f(x, \\mu)$. For $y(t)$ to be a solution, it must satisfy $\\dot{y} = f(y, \\mu)$. Substituting $y=-x$, we get $\\dot{y} = f(-x, \\mu)$. Equating the two expressions for $\\dot{y}$ gives the symmetry condition:\n$$\nf(-x, \\mu) = -f(x, \\mu)\n$$\nThis means that the function $f(x, \\mu)$ must be an odd function of $x$. The given function $f(x, \\mu) = \\mu x - x^{3}$ satisfies this condition, as $f(-x, \\mu) = \\mu(-x) - (-x)^{3} = -\\mu x + x^{3} = -(\\mu x - x^{3}) = -f(x, \\mu)$.\n\nThis symmetry has profound consequences for the bifurcation structure.\nFirst, if $x^{\\ast}$ is an equilibrium point (i.e., $f(x^{\\ast}, \\mu) = 0$), then $f(-x^{\\ast}, \\mu) = -f(x^{\\ast}, \\mu) = -0 = 0$. Thus, $-x^{\\ast}$ must also be an equilibrium point. This guarantees that any non-zero equilibria must appear in symmetric pairs $(\\pm x^{\\ast})$. The trivial equilibrium $x^{\\ast}=0$ is its own symmetric counterpart.\n\nSecond, consider a Taylor series expansion of an arbitrary odd function $f(x)$ around $x=0$:\n$$\nf(x) = c_{1}x + c_{3}x^{3} + c_{5}x^{5} + \\dots\n$$\nThe bifurcation occurs when the linear stability of the $x=0$ solution changes, which happens when the linear coefficient $c_{1}$ passes through zero. The problem's dynamics represents the simplest, or \"normal form\", model of this phenomenon by truncating the series and identifying the linear coefficient with the control parameter, i.e., $c_1 = \\mu$. The term $-x^3$ is the lowest-order odd *nonlinearity*. Its negative sign ensures that for $\\mu>0$, it counteracts the linear growth away from $x=0$, creating new stable equilibria. The fact that the first non-trivial term is of odd power (cubic) is a direct consequence of the $\\mathbb{Z}_{2}$ symmetry. This structure, where a single equilibrium branch loses stability and gives rise to a symmetric pair of new branches, is by definition a pitchfork bifurcation. The symmetric emergence of the branches is a direct consequence of the underlying $\\mathbb{Z}_{2}$ symmetry of the system.\n\n4. Construction of the Potential Function $V(x;\\mu)$\n\nThe problem asks for a scalar potential $V(x; \\mu)$ such that the dynamics can be written as a gradient flow, $\\dot{x} = -\\frac{\\partial V}{\\partial x}$.\nWe are given $\\dot{x} = \\mu x - x^{3}$. Therefore, we must solve:\n$$\n-\\frac{\\partial V}{\\partial x} = \\mu x - x^{3}\n$$\nMultiplying by $-1$, we get:\n$$\n\\frac{\\partial V}{\\partial x} = x^{3} - \\mu x\n$$\nTo find $V(x; \\mu)$, we integrate the expression on the right with respect to $x$, holding $\\mu$ constant:\n$$\nV(x; \\mu) = \\int (x^{3} - \\mu x) \\, dx = \\frac{x^{4}}{4} - \\mu \\frac{x^{2}}{2} + C(\\mu)\n$$\nwhere $C(\\mu)$ is an arbitrary integration \"constant\" that may depend on the parameter $\\mu$ but not on the state variable $x$.\nThe problem provides a condition to fix this constant: $V(0; \\mu) = 0$. We apply this condition to our general solution for $V(x; \\mu)$:\n$$\nV(0; \\mu) = \\frac{(0)^{4}}{4} - \\mu \\frac{(0)^{2}}{2} + C(\\mu) = 0\n$$\nThis implies that $C(\\mu) = 0$.\nSubstituting this back into the expression for the potential, we obtain the unique potential function satisfying the given constraints:\n$$\nV(x;\\mu) = \\frac{1}{4}x^{4} - \\frac{1}{2}\\mu x^{2}\n$$\nThe local minima of this potential correspond to the stable equilibrium points of the system, and the local maxima correspond to the unstable ones. For $\\mu  0$, $V(x)$ has a single minimum at $x=0$. For $\\mu > 0$, the origin $x=0$ becomes a local maximum, and two new symmetric minima appear at $x = \\pm\\sqrt{\\mu}$, which perfectly matches the stability analysis performed in part 2.",
            "answer": "$$\n\\boxed{\\frac{1}{4}x^{4} - \\frac{1}{2}\\mu x^{2}}\n$$"
        },
        {
            "introduction": "Real-world systems rarely exist in isolation; their dynamics unfold in high-dimensional state spaces. The center manifold theorem provides a rigorous tool to simplify this complexity near a bifurcation, revealing that the essential dynamics are often low-dimensional. This practice  guides you through the process of deriving a center manifold to reduce a two-dimensional system, demonstrating how the universal 'normal form' from our first exercise can emerge from a more complex model.",
            "id": "4115598",
            "problem": "Consider the two-dimensional parameterized dynamical system in the plane near the origin, given by the ordinary differential equations\n$$\n\\dot{x} = \\mu x - xy, \\qquad \\dot{y} = -y + x^2,\n$$\nwhere $\\mu$ is a real-valued bifurcation parameter held constant in time. Work in a neighborhood of the equilibrium at $(x,y)=(0,0)$ for small $|\\mu|$. The relevant foundational base includes the linearization of the vector field, the spectrum of the Jacobian, and the invariance characterization of a center manifold as an embedded graph tangent to the center eigenspace, such that the full vector field is tangent to this graph.\n\nUsing only these base principles, and without invoking pre-packaged normal form formulas, perform the following:\n1. Identify the spectral decomposition of the linearization at the origin for $\\mu$ near $0$ and justify the existence of a one-dimensional center manifold $y=h(x,\\mu)$ through $(0,0)$ for $\\mu$ sufficiently small.\n2. Derive the center manifold up to and including all terms of total degree three in $(x,\\mu)$ by solving the invariance equation for $h(x,\\mu)$ with a general multivariate Taylor ansatz that includes all symmetry-allowed monomials of total degree at most three.\n3. Substitute the resulting $y=h(x,\\mu)$ into the $\\dot{x}$-equation to obtain the reduced one-dimensional normal form on the center manifold, truncated consistently to total degree three in $(x,\\mu)$.\n\nAnswer specification:\n- Provide the final answer as a single row containing two expressions: the cubic-order approximation of $h(x,\\mu)$ as the first entry, and the cubic-order reduced scalar vector field (the right-hand side $\\dot{x}=F(x,\\mu)$) as the second entry.\n- Do not include any remainder or big-$O$ notation in the final answer.\n- No numerical rounding is required.",
            "solution": "The problem is well-posed and scientifically sound. It is a standard exercise in center manifold theory, a cornerstone of bifurcation analysis in dynamical systems. We will proceed with the solution.\n\nThe dynamical system is given by the set of ordinary differential equations:\n$$\n\\dot{x}=\\mu x - x y\n$$\n$$\n\\dot{y}=-y + x^2\n$$\nThe system has an equilibrium point at $(x,y) = (0,0)$ for any value of the parameter $\\mu$, as substituting $(x,y)=(0,0)$ into the equations yields $(\\dot{x}, \\dot{y}) = (0,0)$. We are interested in the behavior of the system near this equilibrium for small $|\\mu|$.\n\n**1. Spectral Analysis and Justification for the Center Manifold**\n\nFirst, we linearize the system around the equilibrium $(x,y)=(0,0)$. The vector field is $f(x,y,\\mu) = (\\mu x - xy, -y + x^2)^T$. The Jacobian matrix is:\n$$\nJ(x,y) = \\frac{\\partial f}{\\partial(x,y)} = \\begin{pmatrix} \\frac{\\partial \\dot{x}}{\\partial x}  \\frac{\\partial \\dot{x}}{\\partial y} \\\\ \\frac{\\partial \\dot{y}}{\\partial x}  \\frac{\\partial \\dot{y}}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} \\mu - y  -x \\\\ 2x  -1 \\end{pmatrix}\n$$\nEvaluating the Jacobian at the equilibrium $(0,0)$:\n$$\nJ(0,0) = \\begin{pmatrix} \\mu  0 \\\\ 0  -1 \\end{pmatrix}\n$$\nThe eigenvalues of this matrix are $\\lambda_1 = \\mu$ and $\\lambda_2 = -1$. A bifurcation occurs when an eigenvalue's real part crosses zero. This happens for $\\lambda_1$ when $\\mu=0$. We analyze the system at this critical parameter value.\nFor $\\mu=0$, the Jacobian at the origin is:\n$$\nJ(0,0)|_{\\mu=0} = \\begin{pmatrix} 0  0 \\\\ 0  -1 \\end{pmatrix}\n$$\nThe eigenvalues are $\\lambda_1=0$ and $\\lambda_2=-1$. Since there is one eigenvalue with zero real part and all other eigenvalues have non-zero real parts (here, just one with a negative real part), the Center Manifold Theorem applies.\n\nThe eigenspace corresponding to the center eigenvalue $\\lambda_1=0$ is the center eigenspace, $E^c$. It is the kernel of $J(0,0)|_{\\mu=0}$:\n$$\n\\begin{pmatrix} 0  0 \\\\ 0  -1 \\end{pmatrix} \\begin{pmatrix} v_x \\\\ v_y \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\implies v_y=0\n$$\nThus, $E^c = \\text{span}\\left\\{\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\right\\}$, which is the $x$-axis.\n\nThe eigenspace corresponding to the stable eigenvalue $\\lambda_2=-1$ is the stable eigenspace, $E^s$. It is the kernel of $(J(0,0)|_{\\mu=0} - \\lambda_2 I)$:\n$$\n\\begin{pmatrix} 0-(-1)  0 \\\\ 0  -1-(-1) \\end{pmatrix} \\begin{pmatrix} v_x \\\\ v_y \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} v_x \\\\ v_y \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} \\implies v_x=0\n$$\nThus, $E^s = \\text{span}\\left\\{\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\\right\\}$, which is the $y$-axis.\n\nThe Center Manifold Theorem guarantees the existence, in a neighborhood of the origin for $\\mu$ sufficiently small, of a one-dimensional, locally invariant center manifold, $W^c$. This manifold is tangent to the center eigenspace $E^c$ at the origin $(x,y,\\mu)=(0,0,0)$. Since $E^c$ is the $x$-axis, the manifold can be represented locally as the graph of a function $y=h(x,\\mu)$. The tangency condition implies that $h(0,\\mu)=0$ and $\\frac{\\partial h}{\\partial x}(0,\\mu)=0$ for small $\\mu$.\n\n**2. Derivation of the Center Manifold Approximation**\n\nThe invariance of the manifold $y=h(x,\\mu)$ means that any trajectory starting on it remains on it. This imposes a condition on the vector field. If a solution is parameterized by time $t$ as $(x(t), y(t)) = (x(t), h(x(t),\\mu))$, its velocity vector must be tangent to the manifold. By the chain rule, we must have $\\dot{y} = \\frac{d}{dt}h(x(t),\\mu) = \\frac{\\partial h}{\\partial x}\\dot{x}$. Substituting the system's equations for $\\dot{x}$ and $\\dot{y}$, and replacing $y$ with $h(x,\\mu)$, we obtain the invariance equation:\n$$\n-h(x,\\mu) + x^2 = \\frac{\\partial h}{\\partial x} \\left( \\mu x - x h(x,\\mu) \\right)\n$$\nWe need to solve this equation for $h(x,\\mu)$ up to total degree three in the variables $(x, \\mu)$.\n\nThe system exhibits a symmetry. If we apply the transformation $(x,t) \\to (-x, t)$, the equations become:\n$\\dot{(-x)} = -\\dot{x} = \\mu(-x) - (-x)y = -(\\mu x - xy)$\n$\\dot{y} = -y + (-x)^2 = -y + x^2$\nThe system of equations is equivariant with respect to the symmetry $(x,y) \\to (-x,y)$. This implies that the center manifold must be an even function of $x$, i.e., $h(-x, \\mu) = h(x, \\mu)$.\n\nBased on the tangency conditions $h(0,0)=0, \\frac{\\partial h}{\\partial x}(0,0)=0, \\frac{\\partial h}{\\partial \\mu}(0,0)=0$, and the even symmetry in $x$, the Taylor expansion ansatz for $h(x,\\mu)$ up to total degree three contains only monomials with even powers of $x$:\n$$\nh(x,\\mu) = A x^2 + C \\mu^2 + E x^2 \\mu + G \\mu^3 + \\mathcal{O}(\\|(x,\\mu)\\|^4)\n$$\nThe derivative with respect to $x$ is:\n$$\n\\frac{\\partial h}{\\partial x} = 2 A x + 2 E x \\mu + \\mathcal{O}(\\|(x,\\mu)\\|^3)\n$$\nSubstituting these into the invariance equation:\n$$\n-(A x^2 + C \\mu^2 + E x^2 \\mu + \\dots) + x^2 = (2Ax + 2Ex\\mu + \\dots) \\left( \\mu x - x (A x^2 + \\dots) \\right)\n$$\nWe expand both sides and equate coefficients of monomials of the same total degree.\n\nLeft-Hand Side (LHS):\n$$\n\\text{LHS} = (1-A)x^2 - C\\mu^2 - Ex^2\\mu - G\\mu^3 + \\mathcal{O}(4)\n$$\n\nRight-Hand Side (RHS): We expand the product and collect terms up to total degree three.\n$$\n\\text{RHS} = (2Ax + 2Ex\\mu + \\dots) (\\mu x - Ax^3 - \\dots)\n$$\nThe term with the lowest total degree on the RHS comes from multiplying the lowest degree terms of each factor: $(2Ax)(\\mu x) = 2Ax^2\\mu$. This term has total degree $3$. There are no terms of degree $2$ on the RHS.\n\nNow, we match coefficients order by order.\n\n- **Total Degree 2:**\nOn the LHS, we have $(1-A)x^2 - C\\mu^2$. On the RHS, there are no degree $2$ terms. Equating them to zero gives:\nCoefficient of $x^2$: $1-A = 0 \\implies A=1$.\nCoefficient of $\\mu^2$: $-C = 0 \\implies C=0$.\n\n- **Total Degree 3:**\nWith $A=1$, the RHS has the term $2(1)x^2\\mu = 2x^2\\mu$.\nOn the LHS, we have $-Ex^2\\mu - G\\mu^3$. Equating the degree $3$ terms from both sides:\n$$\n-Ex^2\\mu - G\\mu^3 = 2x^2\\mu\n$$\nEquating coefficients of the monomials:\nCoefficient of $x^2\\mu$: $-E = 2 \\implies E=-2$.\nCoefficient of $\\mu^3$: $-G = 0 \\implies G=0$.\n\nSubstituting these coefficients back into the ansatz, we find the approximation for the center manifold up to total degree three:\n$$\nh(x,\\mu) = (1)x^2 + (0)\\mu^2 + (-2)x^2\\mu + (0)\\mu^3 = x^2 - 2x^2\\mu\n$$\n\n**3. Derivation of the Reduced Flow**\n\nThe dynamics on the center manifold are governed by the $\\dot{x}$ equation, with $y$ substituted by $h(x,\\mu)$. This gives the reduced one-dimensional system $\\dot{x} = F(x,\\mu)$.\n$$\n\\dot{x} = \\mu x - x y = \\mu x - x h(x,\\mu)\n$$\nSubstitute the derived expression for $h(x,\\mu)$:\n$$\n\\dot{x} = \\mu x - x (x^2 - 2x^2\\mu) = \\mu x - x^3 + 2x^3\\mu\n$$\nWe must truncate this expression to include only terms of total degree three or less.\n- $\\mu x$ is of total degree $1+1=2$.\n- $-x^3$ is of total degree $3$.\n- $2x^3\\mu$ is of total degree $3+1=4$.\n\nTruncating at degree three, we discard the term $2x^3\\mu$, obtaining the reduced equation of motion on the center manifold:\n$$\n\\dot{x} = \\mu x - x^3\n$$\nThis is the normal form for a supercritical pitchfork bifurcation.\n\nThe two expressions required for the final answer are the center manifold approximation $h(x,\\mu)$ and the reduced vector field $F(x,\\mu)$.\n\nFirst entry: $h(x,\\mu) = x^2 - 2x^2\\mu$.\nSecond entry: $\\dot{x} = F(x,\\mu) = \\mu x - x^3$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nx^2 - 2x^2\\mu  \\mu x - x^3\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Theoretical knowledge of bifurcations becomes profoundly practical when used to anticipate real-world tipping points from observational data. This computational exercise  bridges that gap, tasking you with detecting an imminent bifurcation in a noisy, non-stationary time series. You will implement a method to measure 'critical slowing down'—a hallmark of an approaching transition—by tracking the system's autocorrelation, providing hands-on experience with the powerful concept of early warning signals.",
            "id": "4115535",
            "problem": "Consider the stochastic differential equation for a one-dimensional state variable $x(t)$ with a slowly drifting control parameter $\\mu(t)$ and additive Gaussian white noise,\n$$\\dot{x}(t) = \\mu(t) - x(t)^2 + \\sigma \\,\\eta(t),$$\nwhere $\\eta(t)$ is standard Gaussian white noise, $\\sigma \\ge 0$ is the noise amplitude, and $\\mu(t)$ drifts linearly according to\n$$\\mu(t) = \\mu_0 + v\\,t,$$\nwith $\\mu_0 \\in \\mathbb{R}$ and $v \\in \\mathbb{R}$. The deterministic component $\\dot{x}=\\mu - x^2$ has a saddle-node bifurcation at $\\mu=0$. As $\\mu(t)$ approaches $0$ from the positive side, the system exhibits critical slowing down, which in the presence of noise often manifests as an increasing lag-$1$ autocorrelation in the time series $x(t)$. Early warning indicators for tipping points in complex adaptive systems aim to detect such trends.\n\nStarting from first principles and well-tested numerical procedures:\n- Discretize the stochastic differential equation using the Euler–Maruyama scheme. For time step $\\Delta t  0$ and discrete times $t_n = n\\,\\Delta t$ with $n \\in \\{0,1,\\dots,N-1\\}$ and $N=\\lfloor T/\\Delta t \\rfloor$, approximate\n$$x_{n+1} = x_n + \\left(\\mu_n - x_n^2\\right)\\Delta t + \\sigma \\sqrt{\\Delta t}\\,\\xi_n,$$\nwhere $\\mu_n = \\mu_0 + v\\,t_n$ and $\\xi_n \\sim \\mathcal{N}(0,1)$ are independent and identically distributed standard normal random variables.\n- Estimate the lag-$1$ autocorrelation within moving windows of the simulated discrete-time series, after removing local linear trends. For a windowed segment $\\{x_{k}, x_{k+1},\\dots,x_{k+W-1}\\}$ of length $W$, fit a linear model $x_i \\approx a + b\\,i$ for $i \\in \\{k,\\dots,k+W-1\\}$ and compute residuals $r_i = x_i - (a + b\\,i)$. Define the sample lag-$1$ autocorrelation in that window by\n$$\\rho_1 = \\frac{\\sum_{i=k+1}^{k+W-1} \\left(r_i - \\bar{r}\\right)\\left(r_{i-1} - \\bar{r}\\right)}{\\sum_{i=k}^{k+W-1} \\left(r_i - \\bar{r}\\right)^2},$$\nwhere $\\bar{r} = \\frac{1}{W}\\sum_{i=k}^{k+W-1} r_i$.\n- Test for a statistically significant increasing trend in the sequence of windowed lag-$1$ autocorrelations using a nonparametric rank-based trend test. Specifically, compute Kendall rank correlation (Kendall $\\tau$) between window index and the corresponding $\\rho_1$ values, and declare an increasing trend if $\\tau > 0$ and the associated $p$-value is below a significance level $\\alpha$.\n\nYour task is to implement a complete program that:\n1. Simulates the time series using the Euler–Maruyama method for each parameter set in the test suite below.\n2. Computes the moving-window lag-$1$ autocorrelation of detrended residuals for each simulated time series.\n3. Applies Kendall rank correlation to test for a statistically significant increasing trend with significance level $\\alpha = 0.01$.\n4. Produces a boolean result for each test case indicating whether a significant increasing trend was detected.\n\nUse the following test suite of parameter values to ensure coverage of different scenarios. Each test case is specified as a tuple $(\\mu_0, v, \\sigma, \\Delta t, T, W, S, \\text{seed})$ with the following meanings: initial control parameter $\\mu_0$, drift rate $v$, noise amplitude $\\sigma$, time step $\\Delta t$, total simulation time $T$, window length $W$ (in number of samples), stride $S$ (in number of samples) for window advancement, and random number generator seed for reproducibility.\n\n- Test case $1$ (approaching tipping): $(\\mu_0, v, \\sigma, \\Delta t, T, W, S, \\text{seed}) = (0.5, -0.001, 0.05, 0.01, 400.0, 2000, 1000, 123)$.\n- Test case $2$ (no drift): $(\\mu_0, v, \\sigma, \\Delta t, T, W, S, \\text{seed}) = (0.5, 0.0, 0.05, 0.01, 400.0, 2000, 1000, 456)$.\n- Test case $3$ (drifting away from tipping): $(\\mu_0, v, \\sigma, \\Delta t, T, W, S, \\text{seed}) = (0.1, 0.001, 0.05, 0.01, 400.0, 2000, 1000, 789)$.\n- Test case $4$ (high noise while approaching tipping): $(\\mu_0, v, \\sigma, \\Delta t, T, W, S, \\text{seed}) = (0.5, -0.001, 0.30, 0.01, 400.0, 2000, 1000, 321)$.\n\nAlgorithmic and numerical requirements:\n- Set the initial condition $x_0 = \\sqrt{\\max(\\mu_0, 0)}$.\n- Use the specified random seeds for reproducibility.\n- When computing lag-$1$ autocorrelation in a window, if the denominator is zero, define the autocorrelation as $0$ for that window.\n- Use significance level $\\alpha = 0.01$ for the trend test.\n- Angles do not appear in this problem; no angle unit is required. No physical units are required; treat time and state variables as dimensionless.\n\nFinal output format:\n- Your program should produce a single line of output containing the boolean results for the four test cases as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4]$ where each $r_i$ is either $True$ or $False$). Produce exactly one line of output in this format and no other text.",
            "solution": "The problem requires the implementation of a numerical and statistical procedure to detect an early warning signal for a tipping point in a stochastic dynamical system. The system is described by a one-dimensional stochastic differential equation (SDE) with a slowly drifting parameter, which models a saddle-node bifurcation. The early warning signal is a statistically significant increasing trend in the lag-$1$ autocorrelation of the system's state variable, a phenomenon known as critical slowing down.\n\nThe solution is developed in three principal stages:\n1.  Numerical simulation of the SDE using the Euler–Maruyama method.\n2.  Calculation of lag-$1$ autocorrelation in moving windows on the simulated time series.\n3.  Statistical testing for a monotonic trend in the sequence of autocorrelation values using Kendall's rank correlation.\n\n**1. System Dynamics and Numerical Simulation**\n\nThe evolution of the state variable $x(t)$ is governed by the SDE:\n$$\n\\dot{x}(t) = \\mu(t) - x(t)^2 + \\sigma \\,\\eta(t)\n$$\nThe deterministic part of the dynamics, $f(x, \\mu) = \\mu - x^2$, defines the potential landscape. For a fixed $\\mu > 0$, the system has a stable equilibrium at $x = \\sqrt{\\mu}$ and an unstable equilibrium at $x = -\\sqrt{\\mu}$. As the control parameter $\\mu$ approaches the bifurcation point $\\mu_c = 0$, these equilibria merge and annihilate. For $\\mu  0$, no equilibria exist, and the system state is driven towards $-\\infty$. The parameter $\\mu(t)$ drifts linearly with time as $\\mu(t) = \\mu_0 + v\\,t$. If the drift rate $v$ is negative, the system is driven towards the tipping point. The term $\\sigma \\,\\eta(t)$ represents additive Gaussian white noise with amplitude $\\sigma$.\n\nTo simulate the system's trajectory, we discretize the SDE using the Euler–Maruyama scheme. For a time step $\\Delta t$, the state $x_{n+1}$ at time $t_{n+1} = (n+1)\\Delta t$ is approximated from the state $x_n$ at time $t_n = n\\Delta t$ as:\n$$\nx_{n+1} = x_n + (\\mu_n - x_n^2)\\Delta t + \\sigma \\sqrt{\\Delta t}\\,\\xi_n\n$$\nHere, $\\mu_n = \\mu_0 + v\\,t_n$ is the control parameter at time $t_n$, and $\\xi_n$ are independent random variables drawn from a standard normal distribution, $\\mathcal{N}(0,1)$. The simulation starts from the initial condition $x_0 = \\sqrt{\\max(\\mu_0, 0)}$, which places the system at the stable equilibrium at $t=0$ if one exists. A full time series $\\{x_0, x_1, \\dots, x_{N-1}\\}$ is generated, where $N = \\lfloor T/\\Delta t \\rfloor$.\n\n**2. Moving Window Autocorrelation Analysis**\n\nAs the system approaches the bifurcation point $\\mu=0$ from above, the basin of attraction around the stable equilibrium $x = \\sqrt{\\mu}$ flattens. This leads to a phenomenon called critical slowing down, where the system's return time to equilibrium after a small perturbation diverges. In a stochastic system, this manifests as an increase in temporal correlation, as the influence of past states on the current state persists for longer.\n\nTo detect this change, we analyze the time series $\\{x_n\\}$ using a moving window approach. The series is divided into overlapping segments of length $W$ samples. These windows advance along the time series with a stride of $S$ samples. For each window, we compute the lag-$1$ autocorrelation, $\\rho_1$.\n\nA crucial preliminary step within each window is detrending. The drifting parameter $\\mu(t)$ makes the time series non-stationary, which can itself induce spurious correlations. To isolate the correlation arising from the intrinsic dynamics, we remove a local linear trend from the data in each window. For a segment $\\{x_k, \\dots, x_{k+W-1}\\}$, we perform an ordinary least squares fit to find coefficients $a$ and $b$ for the model $x_i \\approx a + b\\,i$ where $i \\in \\{k, \\dots, k+W-1\\}$. The analysis then proceeds with the residuals, $r_i = x_i - (a + b\\,i)$.\n\nThe sample lag-$1$ autocorrelation $\\rho_1$ for the window is then calculated from these residuals using the specified formula:\n$$\n\\rho_1 = \\frac{\\sum_{i=k+1}^{k+W-1} (r_i - \\bar{r})(r_{i-1} - \\bar{r})}{\\sum_{i=k}^{k+W-1} (r_i - \\bar{r})^2}\n$$\nwhere $\\bar{r}$ is the mean of the residuals in the window, $\\bar{r} = \\frac{1}{W}\\sum_{i=k}^{k+W-1} r_i$. This calculation yields a sequence of $\\rho_1$ values, one for each window.\n\n**3. Statistical Trend Detection**\n\nThe final step is to determine if the sequence of computed $\\rho_1$ values exhibits a statistically significant increasing trend, which would serve as the early warning signal. For this, we use the Kendall rank correlation test, a non-parametric method that assesses the strength of the monotonic relationship between two variables. Here, the variables are the window index (an ordinal representing time) and the corresponding $\\rho_1$ value.\n\nThe test computes the Kendall's $\\tau$ statistic, which ranges from $-1$ (perfectly decreasing trend) to $+1$ (perfectly increasing trend), and an associated $p$-value. The $p$-value represents the probability of observing a trend at least as strong as the one measured, under the null hypothesis of no trend.\n\nAccording to the problem's criteria, an early warning signal is detected if and only if both conditions are met:\n1.  The correlation coefficient $\\tau > 0$, indicating a positive (increasing) trend.\n2.  The $p$-value is less than the specified significance level, $p  \\alpha$, where $\\alpha = 0.01$. This indicates that the observed increasing trend is statistically significant.\n\nThis complete procedure is applied to each test case, yielding a boolean outcome indicating whether a significant trend was detected.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import kendalltau\n\ndef solve():\n    \"\"\"\n    Implements the full pipeline to detect early warning signals for tipping points\n    in a stochastic dynamical system, based on the problem specification.\n    \"\"\"\n    # Test cases: (mu0, v, sigma, dt, T, W, S, seed)\n    test_cases = [\n        (0.5, -0.001, 0.05, 0.01, 400.0, 2000, 1000, 123),\n        (0.5, 0.0, 0.05, 0.01, 400.0, 2000, 1000, 456),\n        (0.1, 0.001, 0.05, 0.01, 400.0, 2000, 1000, 789),\n        (0.5, -0.001, 0.30, 0.01, 400.0, 2000, 1000, 321),\n    ]\n\n    results = []\n    alpha = 0.01\n\n    for case in test_cases:\n        mu0, v, sigma, dt, T, W, S, seed = case\n\n        # --- 1. SDE Simulation (Euler-Maruyama) ---\n        rng = np.random.default_rng(seed)\n        t = np.arange(0, T, dt)\n        N = len(t)\n        mu = mu0 + v * t\n        \n        x = np.zeros(N)\n        x[0] = np.sqrt(max(mu0, 0.0))\n        \n        # Generate all random numbers at once for efficiency\n        xi = rng.standard_normal(N - 1)\n        \n        sqrt_dt = np.sqrt(dt)\n        for n in range(N - 1):\n            drift_term = (mu[n] - x[n]**2) * dt\n            diffusion_term = sigma * sqrt_dt * xi[n]\n            x[n+1] = x[n] + drift_term + diffusion_term\n\n        # --- 2. Moving Window Autocorrelation ---\n        autocorrelations = []\n        window_starts = np.arange(0, N - W + 1, S)\n        window_indices = np.arange(W)\n\n        for k in window_starts:\n            x_window = x[k : k + W]\n            \n            # Detrending: fit a linear model x_i ~ a + b*i\n            # np.polyfit returns [slope, intercept] for degree 1\n            slope, intercept = np.polyfit(window_indices, x_window, 1)\n            trend = slope * window_indices + intercept\n            residuals = x_window - trend\n            \n            # Calculate lag-1 autocorrelation from residuals\n            r_mean = np.mean(residuals)\n            centered_residuals = residuals - r_mean\n            \n            # Sum of squared centered residuals (denominator)\n            denominator = np.sum(centered_residuals**2)\n            \n            rho_1 = 0.0\n            if denominator > 0:\n                # Sum of products of lagged centered residuals (numerator)\n                numerator = np.sum(centered_residuals[1:] * centered_residuals[:-1])\n                rho_1 = numerator / denominator\n            \n            autocorrelations.append(rho_1)\n\n        # --- 3. Trend Detection (Kendall's Tau) ---\n        # Ensure there are enough points for a meaningful trend test\n        if len(autocorrelations)  3:\n             is_significant_trend = False\n        else:\n            tau, p_value = kendalltau(\n                np.arange(len(autocorrelations)), \n                autocorrelations\n            )\n            \n            # A significant increasing trend is detected if tau > 0 and p  alpha\n            is_significant_trend = (tau > 0) and (p_value  alpha)\n        \n        results.append(is_significant_trend)\n\n    # Final output formatting\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}