{
    "hands_on_practices": [
        {
            "introduction": "This first practice introduces the fundamental mechanics of cascading failures in interdependent systems. You will simulate a discrete, step-by-step failure propagation between two coupled networks, learning how the loss of a single node can trigger a catastrophic, system-wide collapse through a chain reaction of connectivity and dependency failures. This exercise builds a foundational intuition for the non-local and often counter-intuitive nature of systemic risk in modern infrastructure .",
            "id": "4266384",
            "problem": "Consider two undirected networks $A$ and $B$ that are interdependent via bidirectional one-to-one dependency pairs. Let the node sets be $A=\\{a_1,a_2,a_3,a_4,a_5,a_6\\}$ and $B=\\{b_1,b_2,b_3,b_4,b_5,b_6,b_7\\}$. The edge sets are\n$$\nE_A=\\{(a_1,a_2),(a_2,a_3),(a_3,a_4),(a_1,a_3),(a_5,a_6)\\}\n$$\nand\n$$\nE_B=\\{(b_1,b_2),(b_2,b_3),(b_1,b_3),(b_4,b_5),(b_5,b_6),(b_6,b_7)\\}.\n$$\nInterdependence is specified by the bidirectional dependency set\n$$\nD=\\{(a_1,b_2),(a_2,b_3),(a_3,b_1),(a_4,b_4),(a_5,b_5),(a_6,b_6)\\},\n$$\nso that for each $(a_i,b_j)\\in D$ there is a corresponding $(b_j,a_i)\\in D$. The node $b_7$ has no dependency partner and is autonomous.\n\nCascading failure dynamics are defined as follows, starting from an initial removal in network $A$. A node is functional at a given stage if and only if both of the following conditions hold: it belongs to the largest connected component (LCC) of its own network’s currently active subgraph, and, if it has a dependency partner in the other network, that partner is also functional. The process is monotone: once a node becomes nonfunctional, it remains nonfunctional. Define $S_A^{(t)}$ and $S_B^{(t)}$ as the sets of functional nodes in networks $A$ and $B$ after $t$ complete cascade rounds, with $t\\in\\mathbb{N}_0$. Initialization is $S_A^{(0)}=A\\setminus R$ and $S_B^{(0)}=B$, where the initial removal set is $R=\\{a_2\\}$. One complete cascade round consists of the following sequence:\n- Compute the LCC of the subgraph induced by $S_A^{(t)}$ in $A$; remove all nodes of $A$ not in this LCC, yielding an intermediate active set $S_{A,\\mathrm{LCC}}^{(t)}$.\n- Propagate dependencies to $B$: remove from $S_B^{(t)}$ any node in $B$ whose dependency partner in $A$ is not in $S_{A,\\mathrm{LCC}}^{(t)}$, yielding $S_{B,\\mathrm{dep}}^{(t)}$.\n- Compute the LCC of the subgraph induced by $S_{B,\\mathrm{dep}}^{(t)}$ in $B$; remove all nodes of $B$ not in this LCC, yielding $S_B^{(t+1)}$.\n- Propagate dependencies to $A$: remove from $S_{A,\\mathrm{LCC}}^{(t)}$ any node in $A$ whose dependency partner in $B$ is not in $S_B^{(t+1)}$, and then take the LCC of the remaining subgraph in $A$; the result is $S_A^{(t+1)}$.\n\nAssume ties in the size of the largest connected component are broken deterministically by selecting the component whose node labels have the smallest sum under the mappings $a_i\\mapsto i$ and $b_j\\mapsto j$. Perform exactly $2$ complete cascade rounds starting from $R=\\{a_2\\}$ as specified. Report the cardinalities $|S_A^{(2)}|$ and $|S_B^{(2)}|$ as your final answer, formatted as a row matrix. No rounding is required.",
            "solution": "The problem describes a cascading failure process on two interdependent networks, $A$ and $B$. We are asked to simulate this process for two complete rounds and determine the number of surviving nodes in each network.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- Network $A$ node set: $A=\\{a_1, a_2, a_3, a_4, a_5, a_6\\}$\n- Network $A$ edge set: $E_A=\\{(a_1,a_2),(a_2,a_3),(a_3,a_4),(a_1,a_3),(a_5,a_6)\\}$\n- Network $B$ node set: $B=\\{b_1,b_2,b_3,b_4,b_5,b_6,b_7\\}$\n- Network $B$ edge set: $E_B=\\{(b_1,b_2),(b_2,b_3),(b_1,b_3),(b_4,b_5),(b_5,b_6),(b_6,b_7)\\}$\n- Bidirectional dependency set: $D=\\{(a_1,b_2),(a_2,b_3),(a_3,b_1),(a_4,b_4),(a_5,b_5),(a_6,b_6)\\}$\n- Autonomous node: $b_7$\n- Initial removal set: $R=\\{a_2\\}$\n- Initial functional sets: $S_A^{(0)}=A\\setminus R$ and $S_B^{(0)}=B$.\n- Cascade dynamics: A sequence of four operations defines one complete round from time $t$ to $t+1$:\n  1. Find the largest connected component (LCC) of the subgraph induced by $S_A^{(t)}$, yielding $S_{A,\\mathrm{LCC}}^{(t)}$.\n  2. Remove nodes from $S_B^{(t)}$ whose dependency partners are not in $S_{A,\\mathrm{LCC}}^{(t)}$, yielding $S_{B,\\mathrm{dep}}^{(t)}$.\n  3. Find the LCC of the subgraph induced by $S_{B,\\mathrm{dep}}^{(t)}$, yielding $S_B^{(t+1)}$.\n  4. Remove nodes from $S_{A,\\mathrm{LCC}}^{(t)}$ whose dependency partners are not in $S_B^{(t+1)}$, then find the LCC of the remaining subgraph, yielding $S_A^{(t+1)}$.\n- Tie-breaking rule for LCC: Select the component with the smallest sum of node indices.\n- Task: Report $|S_A^{(2)}|$ and $|S_B^{(2)}|$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, describing a well-known model from network science. It is well-posed, with all components (networks, dependencies, initial conditions, dynamics, and tie-breaking rule) clearly and unambiguously defined, ensuring a unique, deterministic outcome. The problem is objective and formalizable. The setup is complete and consistent, without any contradictions or missing information. It requires a procedural simulation, making it non-trivial.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n### Solution\nWe will simulate the cascading failure process step-by-step for two rounds.\n\n**Initial State ($t=0$)**\nThe process starts with the removal of node $a_2$ from network $A$.\nThe initial set of functional nodes in network $A$ is $S_A^{(0)} = A \\setminus \\{a_2\\} = \\{a_1, a_3, a_4, a_5, a_6\\}$.\nThe initial set of functional nodes in network $B$ is $S_B^{(0)} = B = \\{b_1, b_2, b_3, b_4, b_5, b_6, b_7\\}$.\n\n**Cascade Round 1 ($t=0 \\to t=1$)**\n1.  **LCC in Network A:** We consider the subgraph of $A$ induced by $S_A^{(0)} = \\{a_1, a_3, a_4, a_5, a_6\\}$. The edges from $E_A$ within this subgraph are $(a_1, a_3)$, $(a_3, a_4)$, and $(a_5, a_6)$. This subgraph has two connected components: $C_{A,1} = \\{a_1, a_3, a_4\\}$ of size $3$ and $C_{A,2} = \\{a_5, a_6\\}$ of size $2$. The largest connected component (LCC) is $C_{A,1}$. Therefore, nodes outside this component fail. The intermediate set of functional nodes in $A$ is $S_{A,\\mathrm{LCC}}^{(0)} = \\{a_1, a_3, a_4\\}$.\n\n2.  **Dependency Propagation to Network B:** A node in $B$ fails if its dependency partner in $A$ is no longer functional. The set of all failed nodes in $A$ is now $\\{a_2\\}$ (initial removal) and $\\{a_5, a_6\\}$ (from LCC isolation). Their dependency partners in $B$ are $\\{b_3\\}$, $\\{b_5\\}$, and $\\{b_6\\}$, respectively. We remove these nodes from $S_B^{(0)}$.\n    The intermediate set of functional nodes in $B$ is $S_{B,\\mathrm{dep}}^{(0)} = S_B^{(0)} \\setminus \\{b_3, b_5, b_6\\} = \\{b_1, b_2, b_4, b_7\\}$.\n\n3.  **LCC in Network B:** We find the LCC of the subgraph of $B$ induced by $S_{B,\\mathrm{dep}}^{(0)} = \\{b_1, b_2, b_4, b_7\\}$. The only edge from $E_B$ within this subgraph is $(b_1, b_2)$. This forms three connected components: $C_{B,1}=\\{b_1, b_2\\}$ of size $2$, $C_{B,2}=\\{b_4\\}$ of size $1$, and $C_{B,3}=\\{b_7\\}$ of size $1$. The LCC is $C_{B,1}$. This defines the functional set for the next round: $S_B^{(1)} = \\{b_1, b_2\\}$.\n\n4.  **Dependency Propagation to Network A and Final LCC:** We start with the set $S_{A,\\mathrm{LCC}}^{(0)} = \\{a_1, a_3, a_4\\}$ and remove any node whose dependency partner is not in $S_B^{(1)} = \\{b_1, b_2\\}$.\n    - The partner of $a_1$ is $b_2$, and $b_2 \\in S_B^{(1)}$. So, $a_1$ is kept.\n    - The partner of $a_3$ is $b_1$, and $b_1 \\in S_B^{(1)}$. So, $a_3$ is kept.\n    - The partner of $a_4$ is $b_4$, and $b_4 \\notin S_B^{(1)}$. So, $a_4$ fails.\n    The remaining set of nodes is $\\{a_1, a_3\\}$. We must now find the LCC of the subgraph induced by these nodes. Since the edge $(a_1, a_3) \\in E_A$, this subgraph is connected. Thus, its LCC is the set itself.\n    This defines the functional set for the next round: $S_A^{(1)} = \\{a_1, a_3\\}$.\n\nAt the end of round $1$, the functional sets are $S_A^{(1)} = \\{a_1, a_3\\}$ and $S_B^{(1)} = \\{b_1, b_2\\}$.\n\n**Cascade Round 2 ($t=1 \\to t=2$)**\nWe begin with the functional sets $S_A^{(1)} = \\{a_1, a_3\\}$ and $S_B^{(1)} = \\{b_1, b_2\\}$.\n\n1.  **LCC in Network A:** The subgraph induced by $S_A^{(1)}$ is connected due to the edge $(a_1, a_3)$. The LCC is the set itself. So, $S_{A,\\mathrm{LCC}}^{(1)} = \\{a_1, a_3\\}$.\n\n2.  **Dependency Propagation to Network B:** We check the dependency partners of nodes in $S_B^{(1)} = \\{b_1, b_2}\\}$.\n    - The partner of $b_1$ is $a_3$, which is in $S_{A,\\mathrm{LCC}}^{(1)}$. So, $b_1$ is kept.\n    - The partner of $b_2$ is $a_1$, which is in $S_{A,\\mathrm{LCC}}^{(1)}$. So, $b_2$ is kept.\n    No nodes fail due to dependency. The intermediate set is $S_{B,\\mathrm{dep}}^{(1)} = \\{b_1, b_2\\}$.\n\n3.  **LCC in Network B:** The subgraph induced by $S_{B,\\mathrm{dep}}^{(1)} = \\{b_1, b_2\\}$ is connected due to the edge $(b_1, b_2)$. The LCC is the set itself. Thus, $S_B^{(2)} = \\{b_1, b_2\\}$.\n\n4.  **Dependency Propagation to Network A and Final LCC:** We start with $S_{A,\\mathrm{LCC}}^{(1)} = \\{a_1, a_3\\}$ and check dependencies against $S_B^{(2)} = \\{b_1, b_2\\}$.\n    - The partner of $a_1$ is $b_2 \\in S_B^{(2)}$. So, $a_1$ is kept.\n    - The partner of $a_3$ is $b_1 \\in S_B^{(2)}$. So, $a_3$ is kept.\n    No nodes fail due to dependency. The remaining set is $\\{a_1, a_3\\}$. The subgraph induced by this set is connected, so its LCC is the set itself.\n    Thus, $S_A^{(2)} = \\{a_1, a_3\\}$.\n\nAfter two rounds, the system has stabilized with $S_A^{(2)} = S_A^{(1)} = \\{a_1, a_3\\}$ and $S_B^{(2)} = S_B^{(1)} = \\{b_1, b_2\\}$.\nThe cardinalities are $|S_A^{(2)}| = 2$ and $|S_B^{(2)}| = 2$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 2 & 2 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Moving from abstract topological models to a physics-based simulation, this practice challenges you to model a cascade on an electrical power grid. You will implement the linearized DC load flow approximation to calculate power flows, identify overloaded lines, and simulate the consequences of their removal. This hands-on exercise demonstrates how local failures redistribute load according to physical laws, potentially leading to network fragmentation and widespread blackouts, providing a tangible link between network science and critical infrastructure engineering .",
            "id": "4266617",
            "problem": "Consider a network of $N$ nodes and $E$ undirected lines, each line connecting a pair of nodes. The network is modeled using the linearized Direct Current (DC) load flow approximation. Let the net power injection vector be $P \\in \\mathbb{R}^N$, where $P_i$ is positive for generation and negative for load at node $i$, and let each line $e$ have a positive susceptance $b_e$ and a thermal capacity limit $C_e > 0$. The DC model posits that the active power flow $f_e$ on line $e$ is proportional to the difference of voltage phase angles across its endpoints, and that nodal power balance is enforced by Kirchhoff's Current Law. You will compute flows, detect overloads, remove overloaded lines by a specific rule, and simulate the resulting cascade until a stable state is reached.\n\nFundamental base for modeling:\n- Kirchhoff's Current Law: The algebraic sum of flows incident to node $i$ equals the net injection $P_i$.\n- Linearized DC load flow relation: For any line $e = (u,v)$, the active power flow satisfies $f_e = b_e \\left(\\theta_u - \\theta_v\\right)$, where $\\theta_i$ is the voltage phase angle at node $i$.\n- Incidence-based formulation: With an oriented incidence matrix $A \\in \\mathbb{R}^{E \\times N}$, defined by $A_{e,u} = +1$ and $A_{e,v} = -1$ for a line $e=(u,v)$ oriented from node $u$ to node $v$ (and zeros elsewhere), Kirchhoff's Current Law becomes $A^\\top f = P$, and the linearized DC relation becomes $f = \\operatorname{diag}(b) \\, A \\, \\theta$, leading to the weighted Laplacian system $A^\\top \\operatorname{diag}(b) A \\, \\theta = P$ on each connected component, after fixing a reference phase angle. The weighted Laplacian is singular unless one reference (slack) angle per component is fixed.\n\nCascade procedure to implement:\n1. Compute line flows $f_e$ by solving $A^\\top \\operatorname{diag}(b) A \\, \\theta = P$ on each connected component, with a slack bus chosen as the node with the smallest index in that component and its angle fixed to zero. When a component has only one node, there are no flows in that component.\n2. Define the utilization ratio $r_e = \\left|f_e\\right| / C_e$ for each active line $e$.\n3. If there exists any line with $r_e > 1$, remove exactly one line: the line with the largest $r_e$. If multiple lines tie for the largest $r_e$, remove the one with the smallest line index. Recompute connected components, and repeat from step $1$.\n4. Terminate when all remaining lines satisfy $r_e \\le 1$, or no lines remain. The final state is considered stable.\n\nHandling islanding:\n- The removal of lines may disconnect the network into multiple connected components (islands). In each island, define a slack bus as the node with the smallest index within that island. The slack absorbs any aggregate power imbalance in that island by adjusting its net injection implicitly via the fixed reference angle, which yields a solvable reduced Laplacian system for the other angles. This approach is purely mathematical and does not constrain slack capacity.\n\nYour program must implement this cascade simulation exactly and return, for each test case, the triple $[k, R, M]$ where:\n- $k$ is the integer number of lines removed until the final stable state,\n- $R$ is the final maximum utilization ratio across all remaining lines, defined as $R = \\max_e r_e$ with $r_e = \\left|f_e\\right| / C_e$, expressed as a real number rounded to six decimal places,\n- $M$ is the integer number of connected components (including isolated nodes) in the final network.\n\nUse the following test suite of parameter values. In all cases, nodes are labeled by integers starting at $0$, each line is specified by its $(u,v)$ endpoints, susceptance $b_e$, and capacity $C_e$, and the orientation for $A$ is from the first endpoint $u$ to the second endpoint $v$.\n\nTest case $1$ (ring with a chord):\n- $N = 4$\n- Lines: $e_0 = (0,1,b_0=5,C_0=8)$, $e_1 = (1,2,b_1=5,C_1=8)$, $e_2 = (2,3,b_2=5,C_2=8)$, $e_3 = (3,0,b_3=5,C_3=8)$, $e_4 = (1,3,b_4=5,C_4=6)$\n- Net injections: $P = [3,-1,-2,0]$\n\nTest case $2$ (star with one tight limit):\n- $N = 5$\n- Lines: $e_0 = (0,1,b_0=4,C_0=4)$, $e_1 = (0,2,b_1=4,C_1=4)$, $e_2 = (0,3,b_2=4,C_2=4)$, $e_3 = (0,4,b_3=4,C_3=0.5)$\n- Net injections: $P = [4,-1,-1,-1,-1]$\n\nTest case $3$ (triangle, generous limits):\n- $N = 3$\n- Lines: $e_0 = (0,1,b_0=10,C_0=100)$, $e_1 = (1,2,b_1=10,C_1=100)$, $e_2 = (0,2,b_2=10,C_2=100)$\n- Net injections: $P = [1,-0.5,-0.5]$\n\nTest case $4$ (chain at exact limit):\n- $N = 3$\n- Lines: $e_0 = (0,1,b_0=10,C_0=5)$, $e_1 = (1,2,b_1=10,C_1=5)$\n- Net injections: $P = [5,0,-5]$\n\nTest case $5$ (chain with tie-breaking on overload):\n- $N = 4$\n- Lines: $e_0 = (0,1,b_0=10,C_0=3)$, $e_1 = (1,2,b_1=10,C_1=2)$, $e_2 = (2,3,b_2=10,C_2=100)$\n- Net injections: $P = [6,-2,-2,-2]$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sub-list $[k,R,M]$. For example, the output must look like $[[k_1,R_1,M_1],[k_2,R_2,M_2],\\dots]$ with $R_i$ rounded to six decimal places.",
            "solution": "The problem requires the simulation of a cascading failure in an electrical power network, modeled using the linearized Direct Current (DC) load flow approximation. The simulation proceeds in discrete steps, where at each step, power flows are calculated, and the most overloaded transmission line is removed, potentially leading to network fragmentation (islanding) and further redistributions of flow until a stable state is reached.\n\nThe core of the simulation rests upon solving the DC power flow equations for each connected component of the network. The governing equation is a linear system derived from Kirchhoff's Current Law and an Ohm's Law-like relationship for active power.\n\nLet the network have $N$ nodes and $E$ lines. We define an oriented incidence matrix $A \\in \\mathbb{R}^{E \\times N}$, where for a line $e$ oriented from node $u$ to node $v$, $A_{e,u} = 1$ and $A_{e,v} = -1$, with all other entries in that row being $0$. Let $\\theta \\in \\mathbb{R}^N$ be the vector of nodal voltage phase angles, $P \\in \\mathbb{R}^N$ be the vector of net power injections, $b \\in \\mathbb{R}^E$ be the vector of line susceptances, and $f \\in \\mathbb{R}^E$ be the vector of power flows on the lines.\n\nThe model is defined by two fundamental relationships:\n1.  The flow $f_e$ on a line $e=(u,v)$ with susceptance $b_e$ is given by $f_e = b_e(\\theta_u - \\theta_v)$. In matrix form, this is $f = \\mathrm{diag}(b) A \\theta$.\n2.  The sum of power flows entering or leaving any node must balance the net power injection at that node. This is Kirchhoff's Current Law (KCL), expressed as $A^\\top f = P$.\n\nSubstituting the first equation into the second yields the system equation for the phase angles:\n$$\nA^\\top \\left( \\mathrm{diag}(b) A \\theta \\right) = P\n$$\n$$\n(A^\\top \\mathrm{diag}(b) A) \\theta = P\n$$\nThis is often written as $L \\theta = P$, where $L = A^\\top \\mathrm{diag}(b) A$ is the weighted Laplacian matrix of the network. The Laplacian matrix for any graph is singular, reflecting the physical reality that only phase angle *differences* determine power flow, not their absolute values. To obtain a unique solution, we must establish a reference.\n\nThe problem specifies a procedure to handle this singularity and the potential fragmentation of the network:\n1.  **Identify Connected Components**: The network is partitioned into its connected components using a graph traversal algorithm such as Breadth-First Search (BFS) or Depth-First Search (DFS). Each component is treated as an independent sub-problem.\n\n2.  **Solve for Each Component**: For each connected component $\\mathcal{C}$ with node set $\\mathcal{V}_\\mathcal{C}$ and line set $\\mathcal{E}_\\mathcal{C}$:\n    - If $|\\mathcal{V}_\\mathcal{C}| \\le 1$, there are no lines within the component, so no flows are calculated.\n    - If $|\\mathcal{V}_\\mathcal{C}| > 1$, a reference or \"slack\" node must be chosen. The problem mandates selecting the node with the smallest index within $\\mathcal{V}_\\mathcal{C}$ as the slack node, $s$. Its phase angle is fixed to $\\theta_s = 0$.\n    - Let $\\mathcal{V'}_\\mathcal{C} = \\mathcal{V}_\\mathcal{C} \\setminus \\{s\\}$ be the set of non-slack nodes in the component. We construct a reduced linear system $L' \\theta' = P'$ to solve for the angles $\\theta'$ of the non-slack nodes.\n    - $L'$ is the submatrix of the component's Laplacian $L_\\mathcal{C}$ obtained by removing the row and column corresponding to the slack node $s$. This reduced matrix $L'$ is invertible for a connected component.\n    - $P'$ is the subvector of the power injection vector $P$ corresponding to the non-slack nodes $\\mathcal{V'}_\\mathcal{C}$. The power imbalance in the component, $\\sum_{i \\in \\mathcal{V}_\\mathcal{C}} P_i$, is implicitly absorbed by the slack node.\n    - The non-slack angles are found by solving the linear system: $\\theta' = (L')^{-1} P'$.\n    - With all nodal angles $\\theta$ for the component determined (including $\\theta_s=0$), the flow $f_e$ on each line $e=(u,v)$ within that component is calculated: $f_e = b_e(\\theta_u - \\theta_v)$.\n\nThe overall simulation proceeds as a loop:\n\n**Step I: Initialization**\n- The simulation starts with the full set of lines. The number of removed lines, $k$, is initialized to $0$.\n\n**Step II: Iterative Cascade**\nThe simulation enters a loop that continues until no lines are overloaded.\n- **a) Flow Calculation**: For the current network topology, the procedure described above (component identification and per-component linear system solution) is executed to compute all line flows $f_e$.\n- **b) Overload Assessment**: For each line $e$ with capacity $C_e$, the utilization ratio is calculated: $r_e = |f_e| / C_e$. The maximum ratio, $r_{\\max} = \\max_e r_e$, is identified. If no lines remain, $r_{\\max}$ is taken to be $0$.\n- **c) Stability Check**: If $r_{\\max} \\le 1$, the network is stable. The simulation terminates.\n- **d) Line Removal**: If $r_{\\max} > 1$, the network is unstable. A single line must be removed. The line $e^*$ to be removed is the one with the maximum utilization ratio $r_{e^*} = r_{\\max}$. If there is a tie, the line with the smallest original index is chosen. The line $e^*$ is removed from the network, $k$ is incremented by $1$, and the loop repeats from Step II-a.\n\n**Step III: Final Output**\nUpon termination, the final state is characterized by:\n- $k$: The total number of lines removed during the cascade.\n- $R$: The final maximum utilization ratio, $r_{\\max}$, rounded to six decimal places.\n- $M$: The number of connected components in the final, stable network graph.\n\nThis comprehensive algorithm deterministically simulates the cascading failure process as specified. Its implementation requires robust graph algorithms for component finding and numerical linear algebra routines to solve the matrix equations.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef find_components(num_nodes, active_lines_indices, lines_def):\n    \"\"\"Finds connected components in the graph using BFS.\"\"\"\n    if num_nodes == 0:\n        return 0, []\n        \n    adj = [[] for _ in range(num_nodes)]\n    for line_idx in active_lines_indices:\n        u, v, _, _, _ = lines_def[line_idx]\n        adj[u].append(v)\n        adj[v].append(u)\n\n    visited = [False] * num_nodes\n    components = []\n    for i in range(num_nodes):\n        if not visited[i]:\n            component_nodes = set()\n            q = [i]\n            visited[i] = True\n            head = 0\n            while head < len(q):\n                u = q[head]\n                head += 1\n                component_nodes.add(u)\n                for v in adj[u]:\n                    if not visited[v]:\n                        visited[v] = True\n                        q.append(v)\n            components.append(sorted(list(component_nodes)))\n    return len(components), components\n\ndef solve_cascade(num_nodes, lines, power_injections):\n    \"\"\"\n    Simulates the cascading failure process.\n    \"\"\"\n    lines_def = [(u, v, b, c, idx) for idx, (u, v, b, c) in enumerate(lines)]\n    active_lines_indices = set(range(len(lines_def)))\n    \n    removed_lines_count = 0\n\n    while True:\n        if not active_lines_indices:\n            num_components, _ = find_components(num_nodes, active_lines_indices, lines_def)\n            return removed_lines_count, 0.0, num_components\n\n        num_components, components = find_components(num_nodes, active_lines_indices, lines_def)\n\n        flows = {}  # Using dict to store flows by line index\n\n        for comp_nodes in components:\n            if len(comp_nodes) <= 1:\n                continue\n\n            # Map component-local indices to global node indices\n            node_map = {node_idx: i for i, node_idx in enumerate(comp_nodes)}\n            \n            comp_lines = []\n            for line_idx in active_lines_indices:\n                u, v, _, _, _ = lines_def[line_idx]\n                if u in comp_nodes and v in comp_nodes:\n                    comp_lines.append(line_idx)\n            \n            if not comp_lines:\n                continue\n\n            comp_size = len(comp_nodes)\n            laplacian = np.zeros((comp_size, comp_size))\n\n            # Build weighted Laplacian for the component\n            for line_idx in comp_lines:\n                u, v, b, _, _ = lines_def[line_idx]\n                u_comp, v_comp = node_map[u], node_map[v]\n                laplacian[u_comp, u_comp] += b\n                laplacian[v_comp, v_comp] += b\n                laplacian[u_comp, v_comp] -= b\n                laplacian[v_comp, u_comp] -= b\n            \n            # Select slack bus (smallest index in component)\n            slack_node_global = comp_nodes[0]\n            slack_node_comp = node_map[slack_node_global]\n            \n            non_slack_indices_comp = [i for i in range(comp_size) if i != slack_node_comp]\n            non_slack_indices_global = [node for node in comp_nodes if node != slack_node_global]\n            \n            # Reduced system\n            reduced_laplacian = laplacian[np.ix_(non_slack_indices_comp, non_slack_indices_comp)]\n            reduced_p = np.array([power_injections[i] for i in non_slack_indices_global])\n\n            # Solve for non-slack angles\n            try:\n                non_slack_thetas = np.linalg.solve(reduced_laplacian, reduced_p)\n            except np.linalg.LinAlgError:\n                # This can happen if a component is just a line, making L' singular.\n                # It's an issue with how the problem is defined, but we must handle it.\n                # A better approach would be pseudo-inverse, but we stick to the problem.\n                # For safety, use pinv if solve fails.\n                non_slack_thetas = np.linalg.pinv(reduced_laplacian) @ reduced_p\n\n            # Reconstruct full theta vector for the component\n            thetas_comp = np.zeros(comp_size)\n            thetas_comp[non_slack_indices_comp] = non_slack_thetas\n            \n            thetas_global = {comp_nodes[i]: thetas_comp[i] for i in range(comp_size)}\n\n            # Calculate flows for lines in this component\n            for line_idx in comp_lines:\n                u, v, b, _, _ = lines_def[line_idx]\n                flow = b * (thetas_global[u] - thetas_global[v])\n                flows[line_idx] = flow\n\n        # Assess overload\n        max_ratio = -1.0\n        line_to_remove = -1\n\n        ratios = []\n        for line_idx in sorted(list(active_lines_indices)):\n            u, v, b, c, _ = lines_def[line_idx]\n            flow_val = flows.get(line_idx, 0.0)\n            ratio = abs(flow_val) / c if c > 0 else float('inf')\n            ratios.append((ratio, line_idx))\n\n        if not ratios:\n            # This case is handled at the loop start, but as a safeguard\n            max_ratio_val = 0.0\n        else:\n            # Sort by ratio (desc), then line index (asc)\n            ratios.sort(key=lambda x: (-x[0], x[1]))\n            max_ratio_val = ratios[0][0]\n            line_to_remove = ratios[0][1]\n\n        if max_ratio_val <= 1.0:\n            final_max_ratio = max_ratio_val if ratios else 0.0\n            return removed_lines_count, final_max_ratio, num_components\n        else:\n            active_lines_indices.remove(line_to_remove)\n            removed_lines_count += 1\n\ndef solve():\n    test_cases = [\n        {\n            \"N\": 4,\n            \"lines\": [(0, 1, 5, 8), (1, 2, 5, 8), (2, 3, 5, 8), (3, 0, 5, 8), (1, 3, 5, 6)],\n            \"P\": [3, -1, -2, 0]\n        },\n        {\n            \"N\": 5,\n            \"lines\": [(0, 1, 4, 4), (0, 2, 4, 4), (0, 3, 4, 4), (0, 4, 4, 0.5)],\n            \"P\": [4, -1, -1, -1, -1]\n        },\n        {\n            \"N\": 3,\n            \"lines\": [(0, 1, 10, 100), (1, 2, 10, 100), (0, 2, 10, 100)],\n            \"P\": [1, -0.5, -0.5]\n        },\n        {\n            \"N\": 3,\n            \"lines\": [(0, 1, 10, 5), (1, 2, 10, 5)],\n            \"P\": [5, 0, -5]\n        },\n        {\n            \"N\": 4,\n            \"lines\": [(0, 1, 10, 3), (1, 2, 10, 2), (2, 3, 10, 100)],\n            \"P\": [6, -2, -2, -2]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        k, R, M = solve_cascade(case[\"N\"], case[\"lines\"], case[\"P\"])\n        # Format the result with R rounded to 6 decimal places\n        results.append(f\"[{k},{R:.6f},{M}]\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "After learning to simulate cascades, a critical question arises: what is the worst-case vulnerability of a network? This practice tackles this complex optimization problem by challenging you to find the specific set of initial node removals that maximizes the total cascade size. By requiring an exhaustive search, you will directly confront the computational difficulty of this problem and gain insight into why simple greedy strategies can fail due to synergistic effects, a concept related to the mathematical property of submodularity .",
            "id": "4266579",
            "problem": "You are given a finite, weighted, undirected network represented by a graph $G = (V, E)$ with $|V| = n$, a nonnegative base-load vector $\\ell \\in \\mathbb{R}_{\\ge 0}^{n}$, a nonnegative capacity vector $c \\in \\mathbb{R}_{\\ge 0}^{n}$, and a nonnegative, symmetric adjacency-weight matrix $W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$, where $W_{ij} = W_{ji}$ for all $i,j \\in V$, and $W_{ii} = 0$ for all $i \\in V$. For any node $i \\in V$, define its set of neighbors as $N(i) = \\{ j \\in V : W_{ij} > 0 \\}$. Consider a discrete-time load-redistribution cascade with the following mechanics:\n\n- Loads evolve in rounds and are held in a vector $L \\in \\mathbb{R}_{\\ge 0}^{n}$; initially $L = \\ell$.\n- A targeted removal strategy is a subset $S \\subseteq V$ with $|S| = k$. At round $t = 0$, all nodes in $S$ are failed (removed), and each such node’s current load is redistributed to its surviving neighbors proportionally to the edge weights.\n- More precisely, when a node $i$ fails at the start of a round, compute the set of surviving neighbors $N_{\\text{surv}}(i) = \\{ j \\in N(i) : j \\text{ is not failed at the start of this round} \\}$. Let $\\sigma(i) = \\sum_{j \\in N_{\\text{surv}}(i)} W_{ij}$. If $\\sigma(i) > 0$, each surviving neighbor $j \\in N_{\\text{surv}}(i)$ receives an added load of $L_i \\cdot \\frac{W_{ij}}{\\sigma(i)}$ in that round; if $\\sigma(i) = 0$, the load $L_i$ is dropped (lost).\n- After redistributions for all nodes failing in the current round are computed and applied to $L$, those failing nodes are removed permanently and do not receive further load. A surviving node $j$ fails in the next round whenever $L_j > c_j$. This synchronous update repeats until no further failures occur.\n- Define the cascade size function $f(S)$ as the total number of nodes that eventually fail (including those in $S$), starting from the initial removal set $S$.\n\nThe objective is to construct a worst-case targeted removal strategy $S^{\\star}$ of a given cardinality $k$ that maximizes the cascade size $f(S)$ under the stated load-redistribution rule, and to justify the optimality of your construction using either submodularity arguments or by providing counterexamples where submodularity fails and explaining why exhaustive search is required for exact optimality in such cases.\n\nYour program must implement the above cascade model and, for each test case below, compute the exact worst-case removal set $S^{\\star}$ and the corresponding maximum cascade size $f(S^{\\star})$ by searching all subsets $S \\subseteq V$ of size $k$. Ties in $f(S)$ should be broken by choosing the lexicographically smallest set $S$ when node indices are sorted in ascending order. All node indices are integers starting from $0$.\n\nAll answers are purely mathematical and unitless. Angles and physical units do not appear in this problem.\n\nTest Suite Specification:\n\nProvide results for the following test cases. In each case, the network is specified by listing nonzero symmetric edges and their weights, along with base loads $\\ell$, capacities $c$, and removal budget $k$.\n\n- Test Case $1$ (happy path star cascade):\n  - Nodes: $n = 5$, labeled $0, 1, 2, 3, 4$.\n  - Nonzero symmetric edges and weights: $(0,1)$ with weight $1$, $(0,2)$ with weight $1$, $(0,3)$ with weight $1$, $(0,4)$ with weight $1$.\n  - Base loads: $\\ell = [0.80, 0.31, 0.31, 0.31, 0.31]$.\n  - Capacities: $c = [1.20, 0.50, 0.50, 0.50, 0.50]$.\n  - Budget: $k = 1$.\n\n- Test Case $2$ (boundary, no removals):\n  - Nodes: $n = 4$, labeled $0, 1, 2, 3$.\n  - Nonzero symmetric edges and weights: $(0,1)$ with weight $1$, $(1,2)$ with weight $1$, $(2,3)$ with weight $1$.\n  - Base loads: $\\ell = [0.20, 0.20, 0.20, 0.20]$.\n  - Capacities: $c = [0.50, 0.50, 0.50, 0.50]$.\n  - Budget: $k = 0$.\n\n- Test Case $3$ (edge-case synergy and submodularity counterexample):\n  - Nodes: $n = 5$, labeled $0, 1, 2, 3, 4$.\n  - Nonzero symmetric edges and weights: $(0,2)$ with weight $1$, $(1,2)$ with weight $1$, $(2,3)$ with weight $1$, $(2,4)$ with weight $1$.\n  - Base loads: $\\ell = [0.50, 0.50, 0.60, 0.40, 0.40]$.\n  - Capacities: $c = [0.60, 0.60, 1.20, 0.50, 0.50]$.\n  - Budget: $k = 2$.\n\nRequired Final Output Format:\n\nYour program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets. Each result must be a two-element list containing the maximum cascade size (an integer) and the corresponding lexicographically smallest maximizing set $S^{\\star}$ (a list of integers). For example, the output should look like $[[f_1, S_1],[f_2, S_2],[f_3, S_3]]$ where $f_i$ is the maximum cascade size for test case $i$ and $S_i$ is the maximizing set.\n\nYour program must not read any input and must not print any additional text beyond the single required output line.",
            "solution": "The provided problem statement is a valid, well-posed problem in the domain of network science and complex systems. It concerns the maximization of a cascade size function over a network by selecting an optimal initial set of failed nodes.\n\nThe problem is scientifically grounded, being a formal representation of load-based cascading failures, a phenomenon studied in contexts such as electrical power grids and financial networks. The dynamics are deterministic and defined with mathematical precision, ensuring that the cascade size function $f(S)$ is well-defined for any initial set of failures $S$. Given the finite number of nodes $n$ and a fixed removal budget $k$, an optimal set $S^{\\star}$ that maximizes $f(S)$ is guaranteed to exist. The problem is complete, providing all necessary parameters and rules, and contains no internal contradictions or ambiguities. The request to find an exact solution by exhaustive search is computationally feasible for the small network sizes specified in the test cases.\n\nWe will proceed by first formalizing the cascade model, then discussing the optimization approach and its justification, and finally outlining the algorithm for implementation.\n\n**1. The Cascade Model**\n\nThe state of the network at any discrete time step $t \\ge 0$ can be described by the load vector $L^{(t)} \\in \\mathbb{R}_{\\ge 0}^{n}$ and the set of failed nodes, let's call it $\\mathcal{F}^{(t)} \\subseteq V$.\n\n*   **Initialization ($t=0$):**\n    A set of nodes $S \\subseteq V$ with $|S|=k$ is selected for initial removal. The set of all failed nodes is initialized as $\\mathcal{F}^{(0)} = S$. The initial load vector is the base-load vector, $L = \\ell$. However, the problem specifies that the nodes in $S$ are the first to fail and redistribute their load. We can model this as a sequence of rounds. Let $\\mathcal{F}_{\\text{total}}$ be the set of all nodes that have failed up to the current point, initialized to $S$. Let $F_0 = S$ be the set of nodes failing in round $0$.\n\n*   **Cascade Rounds ($t=0, 1, 2, \\dots$):**\n    The cascade proceeds in synchronous rounds. In each round $t$, a set of nodes $F_t$ fails.\n\n    1.  If $F_t = \\emptyset$, the cascade has terminated. The process stops.\n    2.  An intermediate load increment vector, $\\Delta L^{(t)} \\in \\mathbb{R}_{\\ge 0}^{n}$, is initialized to all zeros.\n    3.  For each node $i \\in F_t$ that is failing in the current round, its load $L_i$ must be redistributed. The set of its neighbors that have not yet failed is $N_{\\text{surv}}(i) = N(i) \\setminus \\mathcal{F}_{\\text{total}}$.\n    4.  The sum of weights to these surviving neighbors is $\\sigma(i) = \\sum_{j \\in N_{\\text{surv}}(i)} W_{ij}$.\n    5.  If $\\sigma(i) > 0$, each surviving neighbor $j \\in N_{\\text{surv}}(i)$ receives an additional load. The increment for node $j$ due to the failure of $i$ is $L_i \\cdot \\frac{W_{ij}}{\\sigma(i)}$. This value is added to $\\Delta L_j^{(t)}$. If $\\sigma(i)=0$, the load $L_i$ is lost.\n    6.  After computing the load increments from all nodes in $F_t$, the loads of the surviving nodes are updated synchronously: $L_j \\leftarrow L_j + \\Delta L_j^{(t)}$ for all $j \\notin \\mathcal{F}_{\\text{total}}$. Note that the loads of failing nodes themselves are not updated further.\n    7.  The set of all failed nodes is updated: $\\mathcal{F}_{\\text{total}} \\leftarrow \\mathcal{F}_{\\text{total}} \\cup F_t$.\n    8.  A new set of nodes, $F_{t+1}$, is identified to fail in the next round. These are the nodes that are not yet failed but whose new load exceeds their capacity:\n        $$F_{t+1} = \\{ j \\in V \\setminus \\mathcal{F}_{\\text{total}} : L_j > c_j \\}$$\n    9.  The process repeats for round $t+1$ with the set $F_{t+1}$.\n\nThe total size of the cascade for an initial set $S$ is given by the function $f(S) = |\\mathcal{F}_{\\text{final}}|$, where $\\mathcal{F}_{\\text{final}}$ is the set $\\mathcal{F}_{\\text{total}}$ when the process terminates.\n\n**2. Optimization and Justification**\n\nThe objective is to find a set $S^{\\star}$ that solves the following optimization problem:\n$$ S^{\\star} = \\underset{S \\subseteq V, |S|=k}{\\text{argmax}} \\; f(S) $$\nwith ties broken by selecting the lexicographically smallest set $S$.\n\nThis is a combinatorial optimization problem. For many such problems, if the objective function $f(S)$ is submodular, a simple greedy algorithm can provide a solution with a performance guarantee. A set function $f$ is submodular if it exhibits a \"diminishing returns\" property. Formally, for any sets $A \\subseteq B \\subseteq V$ and any element $v \\in V \\setminus B$, it must hold that:\n$$ f(A \\cup \\{v\\}) - f(A) \\ge f(B \\cup \\{v\\}) - f(B) $$\nHowever, cascade size functions in threshold models are often not submodular. The problem statement correctly alludes to this possibility. We can use Test Case 3 to demonstrate the failure of submodularity.\n\nLet $f$ be the cascade size function for Test Case 3.\n-   Let $A = \\{0\\}$ and $B = \\emptyset$. Note that $B \\subset A$. Let's evaluate the marginal gain of adding node $\\{1\\}$.\n-   $f(\\emptyset) = 0$, as no nodes are initially overloaded.\n-   $f(\\{0\\})$: Node $0$ fails. Its load $L_0=0.5$ is transferred to its only neighbor, node $2$. Node $2$'s load becomes $L_2' = 0.6 + 0.5 = 1.1$. This is less than its capacity $c_2 = 1.2$. The cascade stops. Thus, $f(\\{0\\}) = 1$.\n-   $f(\\{1\\})$: By symmetry with node $0$, node $1$'s failure also does not trigger a cascade. Thus, $f(\\{1\\}) = 1$.\n-   $f(\\{0, 1\\})$: Nodes $0$ and $1$ fail simultaneously. Both redistribute their loads ($L_0=0.5, L_1=0.5$) to their common neighbor, node $2$. Node $2$'s load becomes $L_2' = 0.6 + 0.5 + 0.5 = 1.6$. This exceeds its capacity $c_2 = 1.2$, so node $2$ fails in the next round. When node $2$ fails, its new load of $1.6$ is redistributed to its surviving neighbors $\\{3, 4\\}$, which receive $0.8$ each. Their loads become $L_3' = 0.4+0.8=1.2 > c_3=0.5$ and $L_4' = 0.4+0.8=1.2 > c_4=0.5$. They both fail. The entire network collapses. Thus, $f(\\{0, 1\\}) = 5$.\n\nNow, let's check the submodularity inequality with $A = \\{0\\}$ and $B = \\emptyset$ (so $B \\subseteq A$) and element $v = 1$. The inequality requires $f(B \\cup \\{v\\}) - f(B) \\ge f(A \\cup \\{v\\}) - f(A)$.\n-   Marginal gain of adding node $1$ to the empty set $B$: $f(\\{1\\}) - f(\\emptyset) = 1 - 0 = 1$.\n-   Marginal gain of adding node $1$ to the set $A=\\{0\\}$: $f(\\{0,1\\}) - f(\\{0\\}) = 5 - 1 = 4$.\n\nWe have $1 < 4$, which means $f(B \\cup \\{v\\}) - f(B) < f(A \\cup \\{v\\}) - f(A)$. This violates the submodularity condition. The function exhibits synergy, or increasing returns, where the combined effect of failing two nodes is greater than the sum of their individual effects. Due to this lack of submodularity, greedy algorithms are not guaranteed to find the optimal solution. Therefore, an exhaustive search of all $\\binom{n}{k}$ possible initial sets is necessary to guarantee optimality, as required by the problem statement.\n\n**3. Algorithmic Approach**\n\nThe algorithm will consist of a main loop that orchestrates the search and a core function that simulates the cascade for a given initial set.\n\n1.  **Main Routine:** For each test case $(n, W, \\ell, c, k)$:\n    a. Initialize `max_cascade_size = -1` and `optimal_set = []`.\n    b. Generate all unique subsets $S$ of nodes of size $k$. The `itertools.combinations` function is suitable as it generates these subsets in lexicographical order.\n    c. For each subset $S$:\n        i. Call a simulation function, `simulate_cascade(S, n, W, l, c)`, which returns the final cascade size $f(S)$.\n        ii. If the returned size is greater than `max_cascade_size`, update `max_cascade_size` to this new size and set `optimal_set` to the current $S$. Because we are iterating through sets in lexicographical order, the first set that achieves the maximum possible size will be the correct one according to the tie-breaking rule.\n    d. Store the final (`max_cascade_size`, `optimal_set`) pair for the test case.\n\n2.  **`simulate_cascade(S, n, W, l, c)` Function:**\n    a. Initialize `loads = copy(l)`, `total_failed = set(S)`, and `newly_failed = set(S)`.\n    b. Enter a `while` loop that continues as long as `newly_failed` is not empty.\n    c. Inside the loop, let `failing_this_round = newly_failed`. Reset `newly_failed` to an empty set.\n    d. Initialize `load_increments = zeros(n)`.\n    e. For each node $i$ in `failing_this_round`:\n        i. Determine the set of surviving neighbors $N_{\\text{surv}}(i) = \\{ j \\mid W_{ij}>0 \\text{ and } j \\notin \\text{total\\_failed} \\}$.\n        ii. Calculate $\\sigma(i) = \\sum_{j \\in N_{\\text{surv}}(i)} W_{ij}$.\n        iii. If $\\sigma(i) > 0$, for each $j \\in N_{\\text{surv}}(i)$, add $loads[i] \\cdot \\frac{W_{ij}}{\\sigma(i)}$ to `load_increments[j]`.\n    f. After iterating through all nodes in `failing_this_round`, update the main `loads` vector: `loads += load_increments`.\n    g. Update the set of failed nodes: `total_failed.update(failing_this_round)`.\n    h. Iterate through all nodes $j \\in \\{0, \\dots, n-1\\}$. If $j \\notin \\text{total\\_failed}$ and $loads[j] > c[j]$, add $j$ to the `newly_failed` set.\n    i. The loop continues.\n    j. Once the loop terminates, return `len(total_failed)`.\n\nThis design faithfully implements the specified model and performs the required exhaustive search to find the exact optimal solution for each test case.",
            "answer": "```python\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Solves the cascading failure problem for a set of predefined test cases.\n    It finds the initial removal set of size k that maximizes the total cascade size.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1 (happy path star cascade)\n        {\n            \"n\": 5,\n            \"edges\": [(0, 1, 1), (0, 2, 1), (0, 3, 1), (0, 4, 1)],\n            \"l\": [0.80, 0.31, 0.31, 0.31, 0.31],\n            \"c\": [1.20, 0.50, 0.50, 0.50, 0.50],\n            \"k\": 1,\n        },\n        # Test Case 2 (boundary, no removals)\n        {\n            \"n\": 4,\n            \"edges\": [(0, 1, 1), (1, 2, 1), (2, 3, 1)],\n            \"l\": [0.20, 0.20, 0.20, 0.20],\n            \"c\": [0.50, 0.50, 0.50, 0.50],\n            \"k\": 0,\n        },\n        # Test Case 3 (edge-case synergy and submodularity counterexample)\n        {\n            \"n\": 5,\n            \"edges\": [(0, 2, 1), (1, 2, 1), (2, 3, 1), (2, 4, 1)],\n            \"l\": [0.50, 0.50, 0.60, 0.40, 0.40],\n            \"c\": [0.60, 0.60, 1.20, 0.50, 0.50],\n            \"k\": 2,\n        },\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        n = case[\"n\"]\n        edges = case[\"edges\"]\n        l_vec = np.array(case[\"l\"], dtype=float)\n        c_vec = np.array(case[\"c\"], dtype=float)\n        k = case[\"k\"]\n\n        # Build the weighted adjacency matrix W\n        W = np.zeros((n, n), dtype=float)\n        for i, j, w in edges:\n            W[i, j] = w\n            W[j, i] = w\n\n        max_cascade_size = -1\n        best_s = []\n\n        # Generate all subsets of nodes of size k.\n        # itertools.combinations generates them in lexicographical order.\n        initial_sets = itertools.combinations(range(n), k)\n        \n        for s_tuple in initial_sets:\n            initial_failures = set(s_tuple)\n            \n            # Run the cascade simulation for the current set S\n            loads = np.copy(l_vec)\n            total_failed = set(initial_failures)\n            newly_failed = set(initial_failures)\n\n            while newly_failed:\n                failing_this_round = set(newly_failed)\n                newly_failed = set()\n                \n                # Update total failed set before calculating redistributions\n                # from this round's failures. This is to ensure a node failing\n                # in the same round doesn't receive load from another.\n                current_round_total_failed = total_failed.union(failing_this_round)\n                \n                load_increments = np.zeros(n)\n\n                for i in failing_this_round:\n                    surviving_neighbors = []\n                    weight_sum_surv = 0.0\n                    \n                    # Find surviving neighbors and sum of weights\n                    for j in range(n):\n                        if W[i, j] > 0 and j not in current_round_total_failed:\n                            surviving_neighbors.append(j)\n                            weight_sum_surv += W[i, j]\n\n                    # Redistribute load\n                    if weight_sum_surv > 0:\n                        for j in surviving_neighbors:\n                            load_increments[j] += loads[i] * (W[i, j] / weight_sum_surv)\n                \n                # Synchronous update of loads\n                loads += load_increments\n                \n                # Update total failed set after redistributions are calculated\n                total_failed.update(failing_this_round)\n\n                # Identify nodes failing in the next round\n                for j in range(n):\n                    if j not in total_failed and loads[j] > c_vec[j]:\n                        newly_failed.add(j)\n\n            current_cascade_size = len(total_failed)\n            \n            # Update best result found so far.\n            # Due to lexicographical order of combinations, the first set\n            # that achieves the max size will be the lexicographically smallest.\n            if current_cascade_size > max_cascade_size:\n                max_cascade_size = current_cascade_size\n                best_s = list(s_tuple)\n        \n        # Handle k=0 case which results in no loops\n        if k == 0 and max_cascade_size == -1:\n             max_cascade_size = 0\n             best_s = []\n\n        final_results.append([max_cascade_size, best_s])\n    \n    # Format the final output string exactly as specified.\n    result_str = \",\".join([f\"[{size},{s}]\" for size, s in final_results])\n    print(f\"[{result_str}]\".replace(\" \", \"\"))\n\n\nsolve()\n```"
        }
    ]
}