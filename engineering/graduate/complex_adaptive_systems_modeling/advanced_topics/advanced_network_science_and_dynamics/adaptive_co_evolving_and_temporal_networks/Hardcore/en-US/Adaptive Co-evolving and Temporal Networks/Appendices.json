{
    "hands_on_practices": [
        {
            "introduction": "Understanding how temporal networks evolve requires building and analyzing generative models. This first practice challenges you to work with a classic model of network growth—preferential attachment—augmented with a crucial temporal feature: aging. By deriving the expected degree of a node, you will develop proficiency in the mean-field analysis techniques that are essential for predicting the macroscopic behavior of complex systems from microscopic rules .",
            "id": "4112746",
            "problem": "Consider a growing temporal network in continuous time where one node is introduced per unit time. Upon its introduction at time $t$, the new node creates $m$ undirected edges to existing nodes. Let $t_i$ denote the introduction time of node $i$, and let $k_i(t)$ denote its degree at time $t$. The network evolves by linear preferential attachment (PA), with the instantaneous probability that a new edge at time $t$ connects to node $i$ being proportional to its aged attractiveness $w_i(t)$, defined by $w_i(t) = \\exp(-\\mu (t - t_i))\\,k_i(t)$, where $\\mu > 0$ is the aging rate. The expected rate of change of the degree of node $i$ is therefore given by the total number of edges introduced per unit time multiplied by the normalized attachment probability.\n\nAssume the continuous-time mean-field limit and a long-time regime in which the age-structured degree profile becomes stationary with respect to the age variable $a = t - t_0$ (where $t_0$ is the introduction time of a focal node). Let $\\Phi(t) = \\sum_{j} \\exp(-\\mu (t - t_j))\\,k_j(t)$ denote the total aged attractiveness at time $t$, and assume that in the long-time regime $\\Phi(t)$ approaches a constant $\\Phi^{\\ast}$. Starting only from these core definitions and assumptions, derive the explicit closed-form expression for the expected degree $k(t; t_0)$ of a node introduced at time $t_0$ as a function of $m$, $\\mu$, $t$, and $t_0$.\n\nExpress your final answer as a single analytic expression. No rounding is required and no units are necessary.",
            "solution": "The problem requires the derivation of the expected degree $k(t; t_0)$ for a node introduced at time $t_0$ in a growing temporal network with an aging mechanism. The derivation will proceed by setting up and solving a differential equation based on the provided dynamics, using a self-consistency argument to determine an unknown normalization factor.\n\nLet $k(t; t_0)$ be the expected degree of a node introduced at time $t_0$ as a function of the current time $t$. According to the problem statement, the instantaneous probability that a new edge formed at time $t$ connects to a pre-existing node $i$ (introduced at time $t_i  t$) is proportional to its aged attractiveness, $w_i(t) = \\exp(-\\mu(t - t_i)) k_i(t)$. The normalized probability is therefore given by:\n$$\n\\Pi_i(t) = \\frac{w_i(t)}{\\sum_{j} w_j(t)} = \\frac{\\exp(-\\mu(t - t_i)) k_i(t)}{\\Phi(t)}\n$$\nwhere $\\Phi(t) = \\sum_{j} \\exp(-\\mu(t - t_j)) k_j(t)$ is the total aged attractiveness of all nodes in the network at time $t$.\n\nThe problem states that at each time step, one new node is introduced, and it forms $m$ edges. Thus, the rate at which new edges are added to the network is $m$. The expected rate of change of the degree of a specific node $i$ is this rate multiplied by the probability of attachment to that node. For our focal node introduced at $t_0$, this gives the following differential equation for its expected degree $k(t; t_0)$ for $t > t_0$:\n$$\n\\frac{d k(t; t_0)}{dt} = m \\cdot \\Pi_0(t) = m \\frac{\\exp(-\\mu(t - t_0)) k(t; t_0)}{\\Phi(t)}\n$$\nThe problem specifies that in the long-time regime, we can assume $\\Phi(t)$ approaches a constant value, which we denote as $\\Phi^{\\ast}$. This simplifies the differential equation to:\n$$\n\\frac{d k(t; t_0)}{dt} = \\frac{m}{\\Phi^{\\ast}} \\exp(-\\mu(t - t_0)) k(t; t_0)\n$$\nThis is a first-order linear ordinary differential equation. It is separable and can be solved by integration.\n$$\n\\frac{1}{k(t; t_0)} dk(t; t_0) = \\frac{m}{\\Phi^{\\ast}} \\exp(-\\mu(t - t_0)) dt\n$$\nThe initial condition for a node introduced at time $t_0$ is that its degree at that time is $m$, because it is introduced by forming $m$ edges. So, $k(t_0; t_0) = m$. We integrate both sides from the introduction time $t_0$ to a later time $t$:\n$$\n\\int_{k(t_0; t_0)}^{k(t; t_0)} \\frac{1}{k'} dk' = \\int_{t_0}^{t} \\frac{m}{\\Phi^{\\ast}} \\exp(-\\mu(\\tau - t_0)) d\\tau\n$$\n$$\n\\left[ \\ln(k') \\right]_{m}^{k(t; t_0)} = \\frac{m}{\\Phi^{\\ast}} \\left[ \\frac{\\exp(-\\mu(\\tau - t_0))}{-\\mu} \\right]_{t_0}^{t}\n$$\n$$\n\\ln(k(t; t_0)) - \\ln(m) = -\\frac{m}{\\mu \\Phi^{\\ast}} \\left( \\exp(-\\mu(t - t_0)) - \\exp(0) \\right)\n$$\n$$\n\\ln\\left(\\frac{k(t; t_0)}{m}\\right) = \\frac{m}{\\mu \\Phi^{\\ast}} \\left( 1 - \\exp(-\\mu(t - t_0)) \\right)\n$$\nExponentiating both sides yields the solution for $k(t; t_0)$ in terms of the unknown constant $\\Phi^{\\ast}$:\n$$\nk(t; t_0) = m \\exp\\left( \\frac{m}{\\mu \\Phi^{\\ast}} \\left( 1 - \\exp(-\\mu(t - t_0)) \\right) \\right)\n$$\nTo find $\\Phi^{\\ast}$, we use a self-consistency condition. In the continuous-time limit where one node is introduced per unit time (i.e., the density of node introduction times is $\\rho(t')=1$), the sum for $\\Phi(t)$ becomes an integral over all introduction times $t'$ from the start of the network (let's assume $t=0$) up to the current time $t$:\n$$\n\\Phi(t) = \\int_{0}^{t} \\exp(-\\mu(t - t')) k(t; t') dt'\n$$\nIn the long-time limit ($t \\to \\infty$), $\\Phi(t) \\to \\Phi^{\\ast}$.\n$$\n\\Phi^{\\ast} = \\lim_{t \\to \\infty} \\int_{0}^{t} \\exp(-\\mu(t - t')) k(t; t') dt'\n$$\nLet's change the integration variable to the age of the node, $a = t - t'$, which gives $dt' = -da$. The limits of integration change from $t'=0 \\implies a=t$ and $t'=t \\implies a=0$.\n$$\n\\Phi^{\\ast} = \\lim_{t \\to \\infty} \\int_{t}^{0} \\exp(-\\mu a) k(t; t-a) (-da) = \\lim_{t \\to \\infty} \\int_{0}^{t} \\exp(-\\mu a) k(t; t-a) da\n$$\nThe problem assumes a stationary age-structured degree profile, which means $k(t; t-a)$ depends only on the age $a$. In our derived form, $k(t; t_0) = k(t - t_0)$. So $k(t; t-a)$ is a function of $t-(t-a)=a$, which is consistent. We can write $k(a) = m \\exp\\left( \\frac{m}{\\mu \\Phi^{\\ast}} (1 - \\exp(-\\mu a)) \\right)$. Substituting this into the integral for $\\Phi^{\\ast}$:\n$$\n\\Phi^{\\ast} = \\int_{0}^{\\infty} \\exp(-\\mu a) m \\exp\\left( \\frac{m}{\\mu \\Phi^{\\ast}} \\left( 1 - \\exp(-\\mu a) \\right) \\right) da\n$$\nLet $C = \\frac{m}{\\mu \\Phi^{\\ast}}$. The integral is:\n$$\n\\Phi^{\\ast} = m \\int_{0}^{\\infty} \\exp(-\\mu a) \\exp\\left( C (1 - \\exp(-\\mu a)) \\right) da\n$$\nWe perform a substitution. Let $x = \\exp(-\\mu a)$. Then $dx = -\\mu \\exp(-\\mu a) da$, so $\\exp(-\\mu a) da = -dx/\\mu$. The limits are $a=0 \\implies x=1$ and $a \\to \\infty \\implies x \\to 0$.\n$$\n\\Phi^{\\ast} = m \\int_{1}^{0} \\exp(C(1-x)) \\left(-\\frac{dx}{\\mu}\\right) = \\frac{m}{\\mu} \\int_{0}^{1} \\exp(C) \\exp(-Cx) dx\n$$\n$$\n\\Phi^{\\ast} = \\frac{m}{\\mu} \\exp(C) \\int_{0}^{1} \\exp(-Cx) dx = \\frac{m}{\\mu} \\exp(C) \\left[ \\frac{\\exp(-Cx)}{-C} \\right]_{0}^{1}\n$$\n$$\n\\Phi^{\\ast} = \\frac{m}{\\mu} \\exp(C) \\left( -\\frac{\\exp(-C)}{C} + \\frac{1}{C} \\right) = \\frac{m}{C\\mu} \\exp(C) (1 - \\exp(-C)) = \\frac{m}{C\\mu} (\\exp(C) - 1)\n$$\nNow, substitute back $C = \\frac{m}{\\mu \\Phi^{\\ast}}$.\n$$\n\\Phi^{\\ast} = \\frac{m}{(\\frac{m}{\\mu \\Phi^{\\ast}})\\mu} \\left( \\exp\\left(\\frac{m}{\\mu \\Phi^{\\ast}}\\right) - 1 \\right)\n$$\n$$\n\\Phi^{\\ast} = \\Phi^{\\ast} \\left( \\exp\\left(\\frac{m}{\\mu \\Phi^{\\ast}}\\right) - 1 \\right)\n$$\nAssuming $\\Phi^{\\ast} \\neq 0$ (which must be true for a growing network with non-zero degree nodes), we can divide by $\\Phi^{\\ast}$:\n$$\n1 = \\exp\\left(\\frac{m}{\\mu \\Phi^{\\ast}}\\right) - 1 \\implies 2 = \\exp\\left(\\frac{m}{\\mu \\Phi^{\\ast}}\\right)\n$$\nTaking the natural logarithm of both sides gives:\n$$\n\\ln(2) = \\frac{m}{\\mu \\Phi^{\\ast}}\n$$\nThis determines the value of the constant group $m/(\\mu \\Phi^{\\ast})$. We can now substitute this back into our expression for $k(t; t_0)$:\n$$\nk(t; t_0) = m \\exp\\left( \\ln(2) \\left( 1 - \\exp(-\\mu(t - t_0)) \\right) \\right)\n$$\nUsing the identity $\\exp(a \\ln b) = b^a$, we can write the final expression as:\n$$\nk(t; t_0) = m \\left( \\exp(\\ln(2)) \\right)^{1 - \\exp(-\\mu(t-t_0))}\n$$\n$$\nk(t; t_0) = m \\cdot 2^{1 - \\exp(-\\mu(t - t_0))}\n$$\nThis is the final closed-form expression for the expected degree of a node introduced at time $t_0$.",
            "answer": "$$\n\\boxed{m \\cdot 2^{1 - \\exp(-\\mu(t - t_0))}}\n$$"
        },
        {
            "introduction": "A central question in co-evolving systems is whether the network's structure is actively adapting to the states of its nodes. This exercise moves from theoretical modeling to statistical inference, providing a framework for testing such adaptive coupling in observed data. You will use a Generalized Linear Model (GLM) to formulate competing hypotheses and derive a likelihood ratio test statistic, a powerful and widely used method for model selection and hypothesis testing in empirical network science .",
            "id": "4112754",
            "problem": "Consider a single dyad $\\{i,j\\}$ observed over discrete times $t \\in \\{1,2,\\dots,T\\}$ with $T \\geq 10$. Let $A_{ij}(t) \\in \\{0,1\\}$ denote the adjacency indicator for the dyad at time $t$, and let $x(t) \\in \\mathbb{R}$ be an observed, time-varying dyad-level covariate derived from the node states (for example, a state difference). To capture exogenous temporal variation that is not driven by $x(t)$ and short-term edge persistence, you will model the conditional edge formation probability with a Bernoulli Generalized Linear Model (GLM) using a logit link, a low-dimensional temporal basis $\\mathbf{b}(t) \\in \\mathbb{R}^{K}$ with known basis functions, and a first-order Markov dependence on the lagged edge $A_{ij}(t-1)$.\n\nAssume the following conditional independence structure: conditional on the history $\\mathcal{H}_{t-1} = \\{A_{ij}(s): s \\leq t-1\\}$ and on covariates $\\{x(s), \\mathbf{b}(s): s \\leq t\\}$, the outcomes $\\{A_{ij}(t)\\}_{t=2}^{T}$ are independent with $A_{ij}(t) \\sim \\mathrm{Bernoulli}(p(t))$.\n\nYou wish to test the presence of adaptive coupling to $x(t)$ beyond exogenous time dependence, by comparing:\n- Null model $\\mathcal{M}_{0}$ (exogenous-only): $\\mathrm{logit}\\big(p_{0}(t)\\big) = \\boldsymbol{\\gamma}^{\\top} \\mathbf{b}(t) + \\phi \\, A_{ij}(t-1)$.\n- Alternative model $\\mathcal{M}_{1}$ (adaptive coupling): $\\mathrm{logit}\\big(p_{1}(t)\\big) = \\beta \\, x(t) + \\boldsymbol{\\gamma}^{\\top} \\mathbf{b}(t) + \\phi \\, A_{ij}(t-1)$.\n\nHere, $\\beta \\in \\mathbb{R}$, $\\boldsymbol{\\gamma} \\in \\mathbb{R}^{K}$, and $\\phi \\in \\mathbb{R}$ are unknown parameters. The initial condition $A_{ij}(1)$ is treated as given.\n\nFormulate a hypothesis test of $H_{0}: \\beta = 0$ against $H_{1}: \\beta \\neq 0$ based on the generalized likelihood ratio. Derive an explicit expression for the generalized likelihood ratio test statistic $T$ in terms of the observed sequence $\\{A_{ij}(t)\\}_{t=2}^{T}$ and the fitted probabilities under the two models, $\\{\\hat{p}_{0}(t)\\}_{t=2}^{T}$ and $\\{\\hat{p}_{1}(t)\\}_{t=2}^{T}$, where $\\hat{p}_{0}(t)$ and $\\hat{p}_{1}(t)$ are the maximum likelihood fitted probabilities under $\\mathcal{M}_{0}$ and $\\mathcal{M}_{1}$, respectively. Your final answer should be a single, closed-form analytic expression for $T$.\n\nIf you introduce any additional estimands or intermediate quantities, clearly define them. Do not assume any special functional form beyond what is specified above. Do not use any pre-derived test formulas; derive the statistic from first principles of likelihood for Bernoulli observations with a logit link. Express the final result only in terms of $\\{A_{ij}(t)\\}_{t=2}^{T}$ and $\\{\\hat{p}_{0}(t), \\hat{p}_{1}(t)\\}_{t=2}^{T}$. No numerical values are required, and no rounding is needed. The final answer must be a single closed-form expression with no units.",
            "solution": "The objective is to derive the generalized likelihood ratio test statistic for the hypothesis test $H_{0}: \\beta = 0$ against $H_{1}: \\beta \\neq 0$. The models $\\mathcal{M}_0$ and $\\mathcal{M}_1$ are nested, as $\\mathcal{M}_0$ is a special case of $\\mathcal{M}_1$ with the parameter $\\beta$ constrained to zero.\n\nThe generalized likelihood ratio test statistic, which we will denote as $T_{stat}$ to avoid confusion with the time horizon $T$, is defined as $T_{stat} = -2 \\ln \\Lambda$, where $\\Lambda$ is the ratio of the maximized likelihood under the null hypothesis to the maximized likelihood under the alternative hypothesis.\n$$ \\Lambda = \\frac{\\sup_{\\boldsymbol{\\theta} \\in \\Theta_0} L(\\boldsymbol{\\theta})}{\\sup_{\\boldsymbol{\\theta} \\in \\Theta_1} L(\\boldsymbol{\\theta})} $$\nHere, $\\Theta_1$ is the parameter space for model $\\mathcal{M}_1$, with parameter vector $\\boldsymbol{\\theta}_1 = (\\beta, \\boldsymbol{\\gamma}, \\phi)$, and $\\Theta_0$ is the parameter space for model $\\mathcal{M}_0$, where $\\beta=0$.\n\nBased on the conditional independence assumption, the likelihood function for the observed sequence $\\{A_{ij}(t)\\}_{t=2}^{T}$ is the product of the probabilities of each observation, conditional on the past. The probability mass function for a single observation $A_{ij}(t) \\sim \\mathrm{Bernoulli}(p(t))$ is given by:\n$$ P(A_{ij}(t) | \\mathcal{H}_{t-1}, x(t), \\mathbf{b}(t); p(t)) = p(t)^{A_{ij}(t)} (1 - p(t))^{1 - A_{ij}(t)} $$\nThe total conditional likelihood function $L(\\boldsymbol{\\theta})$ over the observation period $t=2, \\dots, T$ is:\n$$ L(\\boldsymbol{\\theta}) = \\prod_{t=2}^{T} p(t)^{A_{ij}(t)} (1 - p(t))^{1 - A_{ij}(t)} $$\nIt is more convenient to work with the log-likelihood function, $\\ell(\\boldsymbol{\\theta}) = \\ln L(\\boldsymbol{\\theta})$:\n$$ \\ell(\\boldsymbol{\\theta}) = \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln p(t) + (1 - A_{ij}(t)) \\ln(1 - p(t)) \\right] $$\n\nThe problem provides the maximum likelihood fitted probabilities under both models.\n- Under $\\mathcal{M}_1$, the maximized log-likelihood, $\\hat{\\ell}_1$, is obtained by evaluating $\\ell(\\boldsymbol{\\theta})$ at the maximum likelihood estimates of the parameters, which yield the fitted probabilities $\\{\\hat{p}_1(t)\\}_{t=2}^{T}$.\n$$ \\hat{\\ell}_1 = \\sup_{\\boldsymbol{\\theta} \\in \\Theta_1} \\ell(\\boldsymbol{\\theta}) = \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln \\hat{p}_1(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_1(t)) \\right] $$\n- Similarly, under $\\mathcal{M}_0$, the maximized log-likelihood, $\\hat{\\ell}_0$, is obtained using the fitted probabilities $\\{\\hat{p}_0(t)\\}_{t=2}^{T}$.\n$$ \\hat{\\ell}_0 = \\sup_{\\boldsymbol{\\theta} \\in \\Theta_0} \\ell(\\boldsymbol{\\theta}) = \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln \\hat{p}_0(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_0(t)) \\right] $$\n\nThe likelihood ratio $\\Lambda$ is therefore:\n$$ \\Lambda = \\frac{L(\\hat{\\boldsymbol{\\theta}}_0)}{L(\\hat{\\boldsymbol{\\theta}}_1)} = \\frac{\\exp(\\hat{\\ell}_0)}{\\exp(\\hat{\\ell}_1)} = \\exp(\\hat{\\ell}_0 - \\hat{\\ell}_1) $$\nThe test statistic (denoted by $T$ in the problem statement) is derived as follows:\n$$ T = -2 \\ln \\Lambda = -2 \\ln(\\exp(\\hat{\\ell}_0 - \\hat{\\ell}_1)) = -2(\\hat{\\ell}_0 - \\hat{\\ell}_1) = 2(\\hat{\\ell}_1 - \\hat{\\ell}_0) $$\nSubstituting the expressions for $\\hat{\\ell}_1$ and $\\hat{\\ell}_0$:\n$$ T = 2 \\left( \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln \\hat{p}_1(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_1(t)) \\right] - \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln \\hat{p}_0(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_0(t)) \\right] \\right) $$\nWe can combine the two summations into a single sum:\n$$ T = 2 \\sum_{t=2}^{T} \\left( \\left[ A_{ij}(t) \\ln \\hat{p}_1(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_1(t)) \\right] - \\left[ A_{ij}(t) \\ln \\hat{p}_0(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_0(t)) \\right] \\right) $$\nNow, we group the terms by the observed outcome $A_{ij}(t)$:\n$$ T = 2 \\sum_{t=2}^{T} \\left( A_{ij}(t) \\left[ \\ln \\hat{p}_1(t) - \\ln \\hat{p}_0(t) \\right] + (1 - A_{ij}(t)) \\left[ \\ln(1 - \\hat{p}_1(t)) - \\ln(1 - \\hat{p}_0(t)) \\right] \\right) $$\nUsing the property of logarithms $\\ln a - \\ln b = \\ln(a/b)$, we can simplify the expression:\n$$ T = 2 \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln\\left(\\frac{\\hat{p}_1(t)}{\\hat{p}_0(t)}\\right) + (1 - A_{ij}(t)) \\ln\\left(\\frac{1 - \\hat{p}_1(t)}{1 - \\hat{p}_0(t)}\\right) \\right] $$\nThis is the final expression for the generalized likelihood ratio test statistic $T$ in terms of the observed data and fitted probabilities, as required. This statistic is also known as the difference in deviances between the two models. Under the null hypothesis $H_0$, this statistic asymptotically follows a chi-squared distribution $\\chi^2_d$, where $d$ is the difference in the number of free parameters between $\\mathcal{M}_1$ and $\\mathcal{M}_0$. In this case, $d=1$ since only the parameter $\\beta$ is added.",
            "answer": "$$\n\\boxed{2 \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln\\left(\\frac{\\hat{p}_1(t)}{\\hat{p}_0(t)}\\right) + (1 - A_{ij}(t)) \\ln\\left(\\frac{1 - \\hat{p}_1(t)}{1 - \\hat{p}_0(t)}\\right) \\right]}\n$$"
        },
        {
            "introduction": "Beyond global dynamics, the significance of local structural patterns, or motifs, offers deep insights into a network's function. However, to claim a pattern is significant, we must compare its observed frequency to a baseline. This practice introduces the fundamental concept of a temporal null model, which you will use to calculate the expected number of a specific motif—the reciprocal pair—from first principles, honing your ability to distinguish meaningful structure from random chance .",
            "id": "4112785",
            "problem": "You are given a finite set of nodes $\\mathcal{V}$ and a temporal activity sequence for each node $u \\in \\mathcal{V}$, consisting of the times at which $u$ initiates an interaction. A temporal network realization is constructed by assigning, independently for each initiation by node $u$ at time $t$, a partner $v \\in \\mathcal{V} \\setminus \\{u\\}$ according to a uniform distribution over the $|\\mathcal{V}| - 1$ possible partners. All partner choices are independent across initiations, and self-loops are disallowed. The activity times of initiations by each node are preserved exactly as given.\n\nConsider the temporal motif defined as a reciprocal pair within a window: a motif instance is an ordered pair of initiations $(u \\to v, t)$ and $(v \\to u, t')$ such that $u, v \\in \\mathcal{V}$ with $u \\neq v$, the earlier time is $t$, the later time is $t'$, and $0  t' - t \\le \\Delta$, where $\\Delta  0$ is a given window size.\n\nTasks:\n- Starting from first principles of probability, linearity of expectation, and the above null model definition (preserving per-node initiation-time sequences and randomizing partner selection uniformly and independently), derive an exact analytic expression for the expected number of reciprocal-pair motif instances as a function of the activity sequences, the window $\\Delta$, and the number of nodes $|\\mathcal{V}|$.\n- Then evaluate this expression for the specific case $\\mathcal{V} = \\{1, 2, 3, 4\\}$ with activity sequences:\n  - Node $1$: initiation times $\\{1, 5\\}$,\n  - Node $2$: initiation times $\\{2, 6\\}$,\n  - Node $3$: initiation times $\\{3\\}$,\n  - Node $4$: initiation times $\\{4, 7\\}$,\n  and window $\\Delta = 2$.\n  \nReport the expected number of reciprocal-pair motif instances under the null model as a single exact number with no rounding. The answer is unitless.",
            "solution": "The problem asks for the expected number of reciprocal-pair motif instances in a temporal network generated by a specific null model. We will first derive a general analytic expression for this expectation and then evaluate it for the given specific case. The derivation will be based on first principles, primarily the linearity of expectation.\n\nLet $\\mathcal{V}$ be the set of nodes, and let $N_{nodes} = |\\mathcal{V}|$ be the total number of nodes. For each node $u \\in \\mathcal{V}$, we are given a set of initiation times, denoted by $A_u$. The total set of all initiations in the network is $\\mathcal{E} = \\{(u, t) \\mid u \\in \\mathcal{V}, t \\in A_u\\}$. The null model specifies that for any initiation by a node $u$ at time $t$, the partner $v$ is chosen uniformly at random from the set $\\mathcal{V} \\setminus \\{u\\}$. All such choices are independent. The probability of choosing any specific partner $v \\neq u$ is thus $p = \\frac{1}{N_{nodes} - 1}$.\n\nA reciprocal-pair motif instance is defined as an ordered pair of realized temporal edges, $(u \\to v, t)$ and $(v \\to u, t')$, such that $u \\neq v$ and the time difference satisfies $0  t' - t \\le \\Delta$. This means there was an initiation by node $u$ at time $t$ where $v$ was chosen as the partner, and an initiation by node $v$ at time $t'$ where $u$ was chosen as the partner.\n\nLet $N$ be the random variable representing the total number of reciprocal-pair motif instances. To find the expected value of $N$, denoted $E[N]$, we can use the principle of linearity of expectation. We can express $N$ as a sum of indicator random variables, where each indicator corresponds to a potential motif instance.\n\nA potential motif instance is defined by an ordered pair of initiations, $((u, t), (v, t'))$, where $(u, t) \\in \\mathcal{E}$ and $(v, t') \\in \\mathcal{E}$, satisfying the conditions $u \\neq v$ and $0  t' - t \\le \\Delta$. Let $\\mathcal{P}$ be the set of all such potential motif instances.\nFor each element $((u, t), (v, t')) \\in \\mathcal{P}$, let $X_{(u,t),(v,t')}$ be an indicator random variable such that:\n$X_{(u,t),(v,t')} = 1$ if node $u$ chooses partner $v$ at time $t$ AND node $v$ chooses partner $u$ at time $t'$.\n$X_{(u,t),(v,t')} = 0$ otherwise.\n\nThe total number of realized motifs is the sum of these indicator variables over all potential instances:\n$$N = \\sum_{((u,t),(v,t')) \\in \\mathcal{P}} X_{(u,t),(v,t')}$$\nBy linearity of expectation, the expected number of motifs is:\n$$E[N] = E\\left[\\sum_{((u,t),(v,t')) \\in \\mathcal{P}} X_{(u,t),(v,t')}\\right] = \\sum_{((u,t),(v,t')) \\in \\mathcal{P}} E[X_{(u,t),(v,t')}]$$\nThe expectation of an indicator variable is the probability of the event it indicates.\n$$E[X_{(u,t),(v,t')}] = P(\\text{u chooses v at t} \\text{ and } \\text{v chooses u at t'})$$\nAccording to the null model, partner choices for different initiations are independent events. The initiation by $u$ at time $t$ is distinct from the initiation by $v$ at time $t'$. Therefore:\n$$E[X_{(u,t),(v,t')}] = P(\\text{u chooses v at t}) \\times P(\\text{v chooses u at t'})$$\nThe probability for $u$ to choose $v$ (where $v \\neq u$) from $N_{nodes} - 1$ possible partners is $\\frac{1}{N_{nodes} - 1}$. Similarly, the probability for $v$ to choose $u$ is $\\frac{1}{N_{nodes} - 1}$.\nThus, for any potential instance in $\\mathcal{P}$, the probability of it being realized is:\n$$E[X_{(u,t),(v,t')}] = \\frac{1}{N_{nodes} - 1} \\times \\frac{1}{N_{nodes} - 1} = \\frac{1}{(N_{nodes} - 1)^2}$$\nSince this probability is constant for all potential instances, the total expected number of motifs is this probability multiplied by the total number of potential instances, $|\\mathcal{P}|$.\n$$E[N] = |\\mathcal{P}| \\times \\frac{1}{(N_{nodes} - 1)^2}$$\nThe number of potential instances, $|\\mathcal{P}|$, is the count of ordered pairs of initiations $((u, t), (v, t'))$ from the given activity sequences such that $u \\neq v$ and $0  t' - t \\le \\Delta$. We can express this count as a sum:\n$$|\\mathcal{P}| = \\sum_{u \\in \\mathcal{V}} \\sum_{v \\in \\mathcal{V}, v \\neq u} \\sum_{t \\in A_u} \\sum_{t' \\in A_v, 0  t' - t \\le \\Delta} 1$$\nThis can be written more compactly as:\n$$|\\mathcal{P}| = \\sum_{u \\in \\mathcal{V}} \\sum_{v \\in \\mathcal{V}, v \\neq u} \\sum_{t \\in A_u} |\\{ t' \\in A_v \\mid t  t' \\le t+\\Delta \\}|$$\nCombining these results, the exact analytic expression for the expected number of reciprocal-pair motif instances is:\n$$E[N] = \\frac{1}{(|\\mathcal{V}| - 1)^2} \\sum_{u \\in \\mathcal{V}} \\sum_{v \\in \\mathcal{V}, v \\neq u} \\sum_{t \\in A_u} |\\{ t' \\in A_v \\mid t  t' \\le t+\\Delta \\}|$$\n\nNow, we evaluate this expression for the specific case provided.\nThe givens are:\n- Node set is $\\mathcal{V} = \\{1, 2, 3, 4\\}$, so $|\\mathcal{V}| = 4$.\n- The probability factor is $\\frac{1}{(4-1)^2} = \\frac{1}{3^2} = \\frac{1}{9}$.\n- The time window is $\\Delta = 2$.\n- The activity sequences are: $A_1 = \\{1, 5\\}$, $A_2 = \\{2, 6\\}$, $A_3 = \\{3\\}$, $A_4 = \\{4, 7\\}$.\n\nWe need to compute $|\\mathcal{P}|$, the total count of potential instances. We calculate this by summing the counts for each ordered pair of distinct nodes $(u, v)$. Let $C_{uv} = \\sum_{t \\in A_u} |\\{ t' \\in A_v \\mid t  t' \\le t+2 \\}|$.\n\n- For $(u,v) = (1, 2)$: $t=1 \\in A_1 \\implies t' \\in (1, 3]$. $A_2$ has $\\{2\\}$. Count is $1$.\n$t=5 \\in A_1 \\implies t' \\in (5, 7]$. $A_2$ has $\\{6\\}$. Count is $1$.\n$C_{12} = 1 + 1 = 2$.\n- For $(u,v) = (1, 3)$: $t=1 \\in A_1 \\implies t' \\in (1, 3]$. $A_3$ has $\\{3\\}$. Count is $1$.\n$t=5 \\in A_1 \\implies t' \\in (5, 7]$. $A_3$ has none. Count is $0$.\n$C_{13} = 1 + 0 = 1$.\n- For $(u,v) = (1, 4)$: $t=1 \\in A_1 \\implies t' \\in (1, 3]$. $A_4$ has none. Count is $0$.\n$t=5 \\in A_1 \\implies t' \\in (5, 7]$. $A_4$ has $\\{7\\}$. Count is $1$.\n$C_{14} = 0 + 1 = 1$.\n\n- For $(u,v) = (2, 1)$: $t=2 \\in A_2 \\implies t' \\in (2, 4]$. $A_1$ has none. Count is $0$.\n$t=6 \\in A_2 \\implies t' \\in (6, 8]$. $A_1$ has none. Count is $0$.\n$C_{21} = 0 + 0 = 0$.\n- For $(u,v) = (2, 3)$: $t=2 \\in A_2 \\implies t' \\in (2, 4]$. $A_3$ has $\\{3\\}$. Count is $1$.\n$t=6 \\in A_2 \\implies t' \\in (6, 8]$. $A_3$ has none. Count is $0$.\n$C_{23} = 1 + 0 = 1$.\n- For $(u,v) = (2, 4)$: $t=2 \\in A_2 \\implies t' \\in (2, 4]$. $A_4$ has $\\{4\\}$. Count is $1$.\n$t=6 \\in A_2 \\implies t' \\in (6, 8]$. $A_4$ has $\\{7\\}$. Count is $1$.\n$C_{24} = 1 + 1 = 2$.\n\n- For $(u,v) = (3, 1)$: $t=3 \\in A_3 \\implies t' \\in (3, 5]$. $A_1$ has $\\{5\\}$. Count is $1$.\n$C_{31} = 1$.\n- For $(u,v) = (3, 2)$: $t=3 \\in A_3 \\implies t' \\in (3, 5]$. $A_2$ has none. Count is $0$.\n$C_{32} = 0$.\n- For $(u,v) = (3, 4)$: $t=3 \\in A_3 \\implies t' \\in (3, 5]$. $A_4$ has $\\{4\\}$. Count is $1$.\n$C_{34} = 1$.\n\n- For $(u,v) = (4, 1)$: $t=4 \\in A_4 \\implies t' \\in (4, 6]$. $A_1$ has $\\{5\\}$. Count is $1$.\n$t=7 \\in A_4 \\implies t' \\in (7, 9]$. $A_1$ has none. Count is $0$.\n$C_{41} = 1 + 0 = 1$.\n- For $(u,v) = (4, 2)$: $t=4 \\in A_4 \\implies t' \\in (4, 6]$. $A_2$ has $\\{6\\}$. Count is $1$.\n$t=7 \\in A_4 \\implies t' \\in (7, 9]$. $A_2$ has none. Count is $0$.\n$C_{42} = 1 + 0 = 1$.\n- For $(u,v) = (4, 3)$: $t=4 \\in A_4 \\implies t' \\in (4, 6]$. $A_3$ has none. Count is $0$.\n$t=7 \\in A_4 \\implies t' \\in (7, 9]$. $A_3$ has none. Count is $0$.\n$C_{43} = 0 + 0 = 0$.\n\nThe total number of potential instances is the sum of these counts:\n$|\\mathcal{P}| = C_{12} + C_{13} + C_{14} + C_{21} + C_{23} + C_{24} + C_{31} + C_{32} + C_{34} + C_{41} + C_{42} + C_{43}$\n$|\\mathcal{P}| = 2 + 1 + 1 + 0 + 1 + 2 + 1 + 0 + 1 + 1 + 1 + 0 = 11$.\n\nFinally, we calculate the expected number of motifs:\n$$E[N] = |\\mathcal{P}| \\times \\frac{1}{(|\\mathcal{V}| - 1)^2} = 11 \\times \\frac{1}{(4 - 1)^2} = 11 \\times \\frac{1}{9} = \\frac{11}{9}$$\nThe expected number of reciprocal-pair motif instances is $\\frac{11}{9}$.",
            "answer": "$$\\boxed{\\frac{11}{9}}$$"
        }
    ]
}