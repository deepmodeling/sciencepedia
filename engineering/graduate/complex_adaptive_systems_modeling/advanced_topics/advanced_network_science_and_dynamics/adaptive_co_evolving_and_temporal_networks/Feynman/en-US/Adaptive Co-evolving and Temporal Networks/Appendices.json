{
    "hands_on_practices": [
        {
            "introduction": "This first practice is a foundational computational exercise that addresses how we trace influence or flow through a network that changes in time. You will design an algorithm to count time-respecting paths in a raw event stream, a crucial first step for analyzing causality, information propagation, and higher-order network structures. This exercise bridges the gap between the abstract concept of a temporal path and its concrete implementation, while also prompting you to consider the computational efficiency of your approach. ",
            "id": "4112748",
            "problem": "You are given a temporal event stream representing a directed temporal network. Each event is a triplet $(u_i,v_i,t_i)$ with $u_i \\in \\mathbb{N}$ a source node, $v_i \\in \\mathbb{N}$ a target node, and $t_i \\in \\mathbb{Z}$ a discrete time stamp. Let $M$ denote the total number of events. A time-respecting $k$-path is a sequence of $k$ distinct events $(e_{i_1}, e_{i_2}, \\dots, e_{i_k})$ such that the head of each event matches the tail of the next and the times are strictly increasing, i.e., $v_{i_j} = u_{i_{j+1}}$ and $t_{i_j}  t_{i_{j+1}}$ for all $j \\in \\{1,\\dots,k-1\\}$. We define the event out-degree of a node $x$ as the number of events in the stream with source $x$, and we set $\\Delta$ to be the maximum event out-degree across all nodes. Consider that the temporal network may be adaptive and co-evolving, meaning nodes and interactions can appear and disappear over time; you must operate only on the provided event lists.\n\nTask: Construct a programmatic algorithm that, for each supplied test case, counts the total number of time-respecting $k$-paths in the event stream. In addition, derive a worst-case upper bound on the number of steps required by a straightforward enumeration strategy in terms of $M$ and $\\Delta$; report the numeric value of that bound for each case. The analysis must start from core definitions of time-respecting paths and standard graph traversal reasoning (e.g., Breadth-First Search (BFS)), without relying on pre-derived shortcut formulas.\n\nThe event times $t_i$ are discrete and unitless for the purposes of this problem. Angle units and physical units do not apply. Your algorithm must enforce strictly increasing times within a path.\n\nTest Suite:\nFor each tuple below, the first element is the list of events $(u,v,t)$, and the second element is the path length $k$ to be counted.\n\n1. Case A (general branching):\n   - Events: $[(0,1,1),(1,2,2),(2,3,3),(1,3,3)]$\n   - $k = 3$\n2. Case B (boundary $k=1$):\n   - Events: $[(0,1,5),(2,3,5),(1,4,9)]$\n   - $k = 1$\n3. Case C (simultaneous times and strict increases):\n   - Events: $[(0,1,1),(1,2,1),(2,3,2),(1,3,2)]$\n   - $k = 2$\n4. Case D (high event-degree hub):\n   - Events: $[(0,1,1),(0,2,1),(0,3,1),(1,4,2),(2,4,2),(3,4,2)]$\n   - $k = 2$\n5. Case E (path length exceeds event count):\n   - Events: $[(0,1,1),(1,0,2),(0,1,3),(1,2,4)]$\n   - $k = 5$\n\nFor each case, compute:\n- The exact count of time-respecting $k$-paths as an integer.\n- A worst-case upper bound derived from $M$ and $\\Delta$ for enumerating all such $k$-paths, reported as an integer.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must itself be a two-element list of integers $[C,B]$ where $C$ is the count of time-respecting $k$-paths and $B$ is the computed bound value for that case. For example, the final output format should be like $[[C_1,B_1],[C_2,B_2],\\dots]$ with no spaces.",
            "solution": "The problem requires us to develop an algorithm to count the total number of time-respecting $k$-paths in a given temporal event stream and to derive a worst-case upper bound for a straightforward enumeration of these paths. A time-respecting $k$-path is a sequence of $k$ distinct events, $ (e_{i_1}, e_{i_2}, \\dots, e_{i_k}) $, where each event is a triplet $(u_j, v_j, t_j)$, such that for any adjacent pair of events $(e_{i_l}, e_{i_{l+1}})$ in the sequence, the target node of the first event matches the source node of the second, and the timestamp of the first is strictly less than the timestamp of the second. Formally, $v_{i_l} = u_{i_{l+1}}$ and $t_{i_l}  t_{i_{l+1}}$ for $l \\in \\{1, \\dots, k-1\\}$.\n\n### Part 1: Algorithmic Design for Path Counting\n\nThe problem can be modeled as a pathfinding problem on a directed acyclic graph (DAG) where the nodes are the events themselves. A directed edge exists from event $e_a = (u_a, v_a, t_a)$ to event $e_b = (u_b, v_b, t_b)$ if and only if $v_a = u_b$ and $t_a  t_b$. The task is then to count all paths of length $k-1$ in this \"event graph,\" which corresponds to $k$-paths of events.\n\nA direct approach is to use a recursive search, specifically a depth-first search (DFS), augmented with memoization to avoid recomputing results for the same subproblems. This is equivalent to a dynamic programming approach. Let $C(i, \\ell)$ be the number of time-respecting paths of length $\\ell$ that start with event $e_i$.\n\nThe total number of $k$-paths is the sum of paths of length $k$ starting from any possible event: $\\sum_{i=0}^{M-1} C(i, k)$, where $M$ is the total number of events.\n\nThe recursive formulation for $C(i, \\ell)$ is:\n- **Base Case**: If $\\ell=1$, a path of length $1$ starting with event $e_i$ is just the event itself. Thus, $C(i, 1) = 1$.\n- **Recursive Step**: For $\\ell  1$, a path of length $\\ell$ starting with $e_i$ consists of $e_i$ followed by a path of length $\\ell-1$ starting with a valid successor event $e_j$. An event $e_j = (u_j, v_j, t_j)$ is a valid successor to $e_i = (u_i, v_i, t_i)$ if $u_j = v_i$ and $t_j  t_i$.\nThe recurrence relation is:\n$$ C(i, \\ell) = \\sum_{j \\in \\text{Successors}(i)} C(j, \\ell-1) $$\nwhere $\\text{Successors}(i)$ is the set of indices of all events that can follow event $e_i$ in a time-respecting path.\n\nTo implement this efficiently, we first preprocess the event list. An ideal data structure is a dictionary (hash map) that maps each source node $u$ to a list of its outgoing events. Each list should be sorted by time to enable efficient searching for successors. For a given event $e_i = (u_i, v_i, t_i)$, we look up the node $v_i$ in our structure and search its sorted list for all events with timestamps greater than $t_i$. Due to the sorted nature, this search can be done efficiently using binary search (e.g., `bisect_right` in Python) to find the starting index of valid successors, followed by iteration.\n\nThe state for memoization is the tuple `(event_index, path_length_remaining)`. The algorithm computes the total count by summing the results of the recursive function for each event as a starting point and a required length of $k$.\n\nSpecial cases: if $k  M$, it is impossible to form a path of $k$ distinct events, so the count is $0$. If $k=0$, the problem is not well-defined, but we assume $k \\ge 1$. If $k=1$, the number of paths is simply $M$. Our recursive algorithm naturally handles the $k=1$ case.\n\n### Part 2: Derivation of the Worst-Case Upper Bound\n\nWe are asked to derive a worst-case upper bound on the number of steps for a \"straightforward enumeration strategy,\" based on first principles and graph traversal, in terms of $M$ (total number of events) and $\\Delta$ (maximum event out-degree). The number of paths itself provides such a bound. We can imagine constructing paths layer by layer, as in a Breadth-First Search (BFS).\n\nLet $\\mathcal{P}_\\ell$ be the set of all time-respecting paths of length $\\ell$. We seek an upper bound for $|\\mathcal{P}_k|$.\n\n1.  **Paths of length 1**: A path of length $\\ell=1$ is just a single event. There are $M$ events in the stream.\n    $$ |\\mathcal{P}_1| = M $$\n\n2.  **Paths of length 2**: A path of length $\\ell=2$, $(e_1, e_2)$, is formed by taking a path of length $1$, $e_1$, and appending a valid successor event $e_2$. Let $e_1 = (u_1, v_1, t_1)$. A successor $e_2 = (u_2, v_2, t_2)$ must satisfy $u_2 = v_1$ and $t_2  t_1$. The number of events originating from any node is, by definition, its event out-degree. This value is bounded by $\\Delta$, the maximum event out-degree over all nodes. Therefore, for any given $e_1$, there are at most $\\Delta$ possible choices for $e_2$.\n    The total number of paths of length $2$ is bounded by the number of choices for $e_1$ multiplied by the maximum number of choices for $e_2$:\n    $$ |\\mathcal{P}_2| \\le |\\mathcal{P}_1| \\times \\Delta = M\\Delta $$\n\n3.  **Paths of length $\\ell$**: We can generalize this by induction. Assume we have an upper bound for paths of length $\\ell-1$, $|\\mathcal{P}_{\\ell-1}|$. Any path of length $\\ell$ is formed by extending a path of length $\\ell-1$ with one more event. Let a path of length $\\ell-1$ be $(e_1, \\dots, e_{\\ell-1})$. The last event is $e_{\\ell-1} = (u_{\\ell-1}, v_{\\ell-1}, t_{\\ell-1})$. The next event, $e_\\ell$, must have its source node equal to $v_{\\ell-1}$. The number of events originating from $v_{\\ell-1}$ is at most $\\Delta$.\n    Thus, every path in $\\mathcal{P}_{\\ell-1}$ can be extended in at most $\\Delta$ ways.\n    $$ |\\mathcal{P}_\\ell| \\le |\\mathcal{P}_{\\ell-1}| \\times \\Delta $$\n\n4.  **Final Bound for length k**: By unrolling the recurrence, we get:\n    $$ |\\mathcal{P}_k| \\le |\\mathcal{P}_{k-1}|\\Delta \\le (|\\mathcal{P}_{k-2}|\\Delta)\\Delta \\le \\dots \\le |\\mathcalP_1|\\Delta^{k-1} $$\n    Substituting $|\\mathcal{P}_1| = M$, we arrive at the worst-case upper bound $B$ for the number of time-respecting $k$-paths:\n    $$ B = M \\Delta^{k-1} $$\nThis formula represents the number of leaves in a hypothetical search tree of depth $k-1$, where the root has $M$ children (the initial events) and every other node has $\\Delta$ children. A naive enumeration algorithm would explore this tree, so its number of steps is bounded by the size of this tree. The number of paths, $M\\Delta^{k-1}$, serves as a simple and standard upper bound. This formula holds for $k \\ge 1$. For $k=1$, it correctly gives $B = M\\Delta^0 = M$.\n\n### Summary of Computations for Each Case\nFor each test case, we compute two values:\n- $C$: The exact count of $k$-paths, determined by the recursive algorithm.\n- $B$: The upper bound, calculated as $B = M \\Delta^{k-1}$, where $M$ is the number of events and $\\Delta$ is the maximum event out-degree found in the event list.\nAll results must be integers.\n\n- **Case A**: Events: $[(0,1,1),(1,2,2),(2,3,3),(1,3,3)]$, $k=3$.\n  $M=4$. Out-degrees: $d(0)=1, d(1)=2, d(2)=1$. $\\Delta=2$.\n  $C=1$ (path: $((0,1,1), (1,2,2), (2,3,3))$).\n  $B = 4 \\cdot 2^{3-1} = 16$. Result: $[1, 16]$.\n\n- **Case B**: Events: $[(0,1,5),(2,3,5),(1,4,9)]$, $k=1$.\n  $M=3$. Out-degrees: $d(0)=1, d(1)=1, d(2)=1$. $\\Delta=1$.\n  $C=3$ (each event is a path of length $1$).\n  $B = 3 \\cdot 1^{1-1} = 3$. Result: $[3, 3]$.\n\n- **Case C**: Events: $[(0,1,1),(1,2,1),(2,3,2),(1,3,2)]$, $k=2$.\n  $M=4$. Out-degrees: $d(0)=1, d(1)=2, d(2)=1$. $\\Delta=2$.\n  $C=2$ (paths: $((0,1,1),(1,3,2))$ and $((1,2,1),(2,3,2))$).\n  $B = 4 \\cdot 2^{2-1} = 8$. Result: $[2, 8]$.\n\n- **Case D**: Events: $[(0,1,1),(0,2,1),(0,3,1),(1,4,2),(2,4,2),(3,4,2)]$, $k=2$.\n  $M=6$. Out-degrees: $d(0)=3, d(1)=1, d(2)=1, d(3)=1$. $\\Delta=3$.\n  $C=3$ (paths: $((0,1,1),(1,4,2))$, $((0,2,1),(2,4,2))$, $((0,3,1),(3,4,2))$).\n  $B = 6 \\cdot 3^{2-1} = 18$. Result: $[3, 18]$.\n\n- **Case E**: Events: $[(0,1,1),(1,0,2),(0,1,3),(1,2,4)]$, $k=5$.\n  $M=4$. Out-degrees: $d(0)=2, d(1)=2$. $\\Delta=2$.\n  $C=0$ (since $k  M$, no path of $5$ distinct events is possible from a pool of $4$).\n  $B = 4 \\cdot 2^{5-1} = 64$. Result: $[0, 64]$.\n\nThe programmatic implementation will follow this logic.",
            "answer": "```python\nimport numpy as np\nfrom collections import defaultdict\nfrom bisect import bisect_right\n\ndef solve():\n    \"\"\"\n    Solves the temporal path counting problem for a suite of test cases.\n    For each case, it calculates:\n    1. C: The exact count of time-respecting k-paths.\n    2. B: A worst-case upper bound on enumeration steps.\n    \"\"\"\n\n    test_cases = [\n        # Case A (general branching)\n        ([(0,1,1),(1,2,2),(2,3,3),(1,3,3)], 3),\n        # Case B (boundary k=1)\n        ([(0,1,5),(2,3,5),(1,4,9)], 1),\n        # Case C (simultaneous times and strict increases)\n        ([(0,1,1),(1,2,1),(2,3,2),(1,3,2)], 2),\n        # Case D (high event-degree hub)\n        ([(0,1,1),(0,2,1),(0,3,1),(1,4,2),(2,4,2),(3,4,2)], 2),\n        # Case E (path length exceeds event count)\n        ([(0,1,1),(1,0,2),(0,1,3),(1,2,4)], 5),\n    ]\n\n    results = []\n    for events, k in test_cases:\n        M = len(events)\n        \n        # --- Calculate Upper Bound B ---\n        if M == 0:\n            Delta = 0\n        else:\n            out_degrees = defaultdict(int)\n            for u, v, t in events:\n                out_degrees[u] += 1\n            Delta = max(out_degrees.values()) if out_degrees else 0\n        \n        # B = M * Delta^(k-1)\n        # This formula works for k=1. Python's 0**0 is 1, which is correct for k=1.\n        bound = M * (Delta ** (k - 1))\n\n        # --- Calculate Exact Count C ---\n        count = 0\n        if k == 0 or M == 0 or k  M:\n            count = 0\n        else:\n            # Pre-process events for efficient successor lookup\n            # adj: u - sorted list of (t, v, event_idx)\n            adj = defaultdict(list)\n            for i, (u, v, t) in enumerate(events):\n                adj[u].append((t, v, i))\n            \n            for u_node in adj:\n                adj[u_node].sort()\n\n            # Memoization table for the recursive DFS\n            memo = {}\n\n            def count_paths_recursive(event_idx, length_rem):\n                \"\"\"\n                Counts time-respecting paths of length `length_rem` starting\n                from the event at `event_idx`.\n                \"\"\"\n                state = (event_idx, length_rem)\n                if state in memo:\n                    return memo[state]\n\n                # Base case: A path of one event is found.\n                if length_rem == 1:\n                    return 1\n\n                # Recursive step\n                _, last_v, last_t = events[event_idx]\n                sub_count = 0\n\n                if last_v in adj:\n                    potential_successors = adj[last_v]\n                    \n                    # Efficiently find the first valid successor using binary search.\n                    # We need to find the first event with time  last_t.\n                    # bisect_right on a list of times gives the insertion point.\n                    times = [e[0] for e in potential_successors]\n                    start_pos = bisect_right(times, last_t)\n                    \n                    for i in range(start_pos, len(potential_successors)):\n                        next_t, next_v, next_event_idx = potential_successors[i]\n                        sub_count += count_paths_recursive(next_event_idx, length_rem - 1)\n                \n                memo[state] = sub_count\n                return sub_count\n\n            # Sum the counts of paths starting from each possible event\n            total_count = 0\n            for i in range(M):\n                total_count += count_paths_recursive(i, k)\n            count = total_count\n\n        results.append([count, bound])\n    \n    # Format the final output string\n    # e.g., [[C1,B1],[C2,B2]]\n    output_str = f\"[{','.join([f'[{c},{b}]' for c, b in results])}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Having learned to count specific patterns, the next critical step is to assess their statistical significance, which requires a baseline for comparison. This practice guides you through the formulation of a temporal null model to determine if an observed frequency of a simple motif—a reciprocal pair—is more than what would be expected from random chance. Mastering this skill is fundamental to distinguishing meaningful network organization from stochastic effects. ",
            "id": "4112785",
            "problem": "You are given a finite set of nodes $\\mathcal{V}$ and a temporal activity sequence for each node $u \\in \\mathcal{V}$, consisting of the times at which $u$ initiates an interaction. A temporal network realization is constructed by assigning, independently for each initiation by node $u$ at time $t$, a partner $v \\in \\mathcal{V} \\setminus \\{u\\}$ according to a uniform distribution over the $|\\mathcal{V}| - 1$ possible partners. All partner choices are independent across initiations, and self-loops are disallowed. The activity times of initiations by each node are preserved exactly as given.\n\nConsider the temporal motif defined as a reciprocal pair within a window: a motif instance is an ordered pair of initiations $(u \\to v, t)$ and $(v \\to u, t')$ such that $u, v \\in \\mathcal{V}$ with $u \\neq v$, the earlier time is $t$, the later time is $t'$, and $0  t' - t \\le \\Delta$, where $\\Delta  0$ is a given window size.\n\nTasks:\n- Starting from first principles of probability, linearity of expectation, and the above null model definition (preserving per-node initiation-time sequences and randomizing partner selection uniformly and independently), derive an exact analytic expression for the expected number of reciprocal-pair motif instances as a function of the activity sequences, the window $\\Delta$, and the number of nodes $|\\mathcal{V}|$.\n- Then evaluate this expression for the specific case $\\mathcal{V} = \\{1, 2, 3, 4\\}$ with activity sequences:\n  - Node $1$: initiation times $\\{1, 5\\}$,\n  - Node $2$: initiation times $\\{2, 6\\}$,\n  - Node $3$: initiation times $\\{3\\}$,\n  - Node $4$: initiation times $\\{4, 7\\}$,\n  and window $\\Delta = 2$.\n  \nReport the expected number of reciprocal-pair motif instances under the null model as a single exact number with no rounding. The answer is unitless.",
            "solution": "The problem asks for the expected number of reciprocal-pair motif instances in a temporal network generated by a specific null model. We will first derive a general analytic expression for this expectation and then evaluate it for the given specific case. The derivation will be based on first principles, primarily the linearity of expectation.\n\nLet $\\mathcal{V}$ be the set of nodes, and let $N_{nodes} = |\\mathcal{V}|$ be the total number of nodes. For each node $u \\in \\mathcal{V}$, we are given a set of initiation times, denoted by $A_u$. The total set of all initiations in the network is $\\mathcal{E} = \\{(u, t) \\mid u \\in \\mathcal{V}, t \\in A_u\\}$. The null model specifies that for any initiation by a node $u$ at time $t$, the partner $v$ is chosen uniformly at random from the set $\\mathcal{V} \\setminus \\{u\\}$. All such choices are independent. The probability of choosing any specific partner $v \\neq u$ is thus $p = \\frac{1}{N_{nodes} - 1}$.\n\nA reciprocal-pair motif instance is defined as an ordered pair of realized temporal edges, $(u \\to v, t)$ and $(v \\to u, t')$, such that $u \\neq v$ and the time difference satisfies $0  t' - t \\le \\Delta$. This means there was an initiation by node $u$ at time $t$ where $v$ was chosen as the partner, and an initiation by node $v$ at time $t'$ where $u$ was chosen as the partner.\n\nLet $N$ be the random variable representing the total number of reciprocal-pair motif instances. To find the expected value of $N$, denoted $E[N]$, we can use the principle of linearity of expectation. We can express $N$ as a sum of indicator random variables, where each indicator corresponds to a potential motif instance.\n\nA potential motif instance is defined by an ordered pair of initiations, $((u, t), (v, t'))$, where $(u, t) \\in \\mathcal{E}$ and $(v, t') \\in \\mathcal{E}$, satisfying the conditions $u \\neq v$ and $0  t' - t \\le \\Delta$. Let $\\mathcal{P}$ be the set of all such potential motif instances.\nFor each element $((u,t),(v,t')) \\in \\mathcal{P}$, let $X_{(u,t),(v,t')}$ be an indicator random variable such that:\n$X_{(u,t),(v,t')} = 1$ if node $u$ chooses partner $v$ at time $t$ AND node $v$ chooses partner $u$ at time $t'$.\n$X_{(u,t),(v,t')} = 0$ otherwise.\n\nThe total number of realized motifs is the sum of these indicator variables over all potential instances:\n$$N = \\sum_{((u,t),(v,t')) \\in \\mathcal{P}} X_{(u,t),(v,t')}$$\nBy linearity of expectation, the expected number of motifs is:\n$$E[N] = E\\left[\\sum_{((u,t),(v,t')) \\in \\mathcal{P}} X_{(u,t),(v,t')}\\right] = \\sum_{((u,t),(v,t')) \\in \\mathcal{P}} E[X_{(u,t),(v,t')}]$$\nThe expectation of an indicator variable is the probability of the event it indicates.\n$$E[X_{(u,t),(v,t')}] = P(\\text{u chooses v at t} \\text{ and } \\text{v chooses u at t'})$$\nAccording to the null model, partner choices for different initiations are independent events. The initiation by $u$ at time $t$ is distinct from the initiation by $v$ at time $t'$. Therefore:\n$$E[X_{(u,t),(v,t')}] = P(\\text{u chooses v at t}) \\times P(\\text{v chooses u at t'})$$\nThe probability for $u$ to choose $v$ (where $v \\neq u$) from $N_{nodes} - 1$ possible partners is $\\frac{1}{N_{nodes} - 1}$. Similarly, the probability for $v$ to choose $u$ is $\\frac{1}{N_{nodes} - 1}$.\nThus, for any potential instance in $\\mathcal{P}$, the probability of it being realized is:\n$$E[X_{(u,t),(v,t')}] = \\frac{1}{N_{nodes} - 1} \\times \\frac{1}{N_{nodes} - 1} = \\frac{1}{(N_{nodes} - 1)^2}$$\nSince this probability is constant for all potential instances, the total expected number of motifs is this probability multiplied by the total number of potential instances, $|\\mathcal{P}|$.\n$$E[N] = |\\mathcal{P}| \\times \\frac{1}{(N_{nodes} - 1)^2}$$\nThe number of potential instances, $|\\mathcal{P}|$, is the count of ordered pairs of initiations $((u, t), (v, t'))$ from the given activity sequences such that $u \\neq v$ and $0  t' - t \\le \\Delta$. We can express this count as a sum:\n$$|\\mathcal{P}| = \\sum_{u \\in \\mathcal{V}} \\sum_{v \\in \\mathcal{V}, v \\neq u} \\sum_{t \\in A_u} \\sum_{t' \\in A_v, 0  t' - t \\le \\Delta} 1$$\nThis can be written more compactly as:\n$$|\\mathcal{P}| = \\sum_{u \\in \\mathcal{V}} \\sum_{v \\in \\mathcal{V}, v \\neq u} \\sum_{t \\in A_u} |\\{ t' \\in A_v \\mid t  t' \\le t+\\Delta \\}|$$\nCombining these results, the exact analytic expression for the expected number of reciprocal-pair motif instances is:\n$$E[N] = \\frac{1}{(|\\mathcal{V}| - 1)^2} \\sum_{u \\in \\mathcal{V}} \\sum_{v \\in \\mathcal{V}, v \\neq u} \\sum_{t \\in A_u} |\\{ t' \\in A_v \\mid t  t' \\le t+\\Delta \\}|$$\n\nNow, we evaluate this expression for the specific case provided.\nThe givens are:\n- Node set is $\\mathcal{V} = \\{1, 2, 3, 4\\}$, so $|\\mathcal{V}| = 4$.\n- The probability factor is $\\frac{1}{(4-1)^2} = \\frac{1}{3^2} = \\frac{1}{9}$.\n- The time window is $\\Delta = 2$.\n- The activity sequences are: $A_1 = \\{1, 5\\}$, $A_2 = \\{2, 6\\}$, $A_3 = \\{3\\}$, $A_4 = \\{4, 7\\}$.\n\nWe need to compute $|\\mathcal{P}|$, the total count of potential instances. We calculate this by summing the counts for each ordered pair of distinct nodes $(u, v)$. Let $C_{uv} = \\sum_{t \\in A_u} |\\{ t' \\in A_v \\mid t  t' \\le t+2 \\}|$.\n\n- For $(u,v) = (1, 2)$: $t=1 \\in A_1 \\implies t' \\in (1, 3]$. $A_2$ has $\\{2\\}$. Count is $1$.\n$t=5 \\in A_1 \\implies t' \\in (5, 7]$. $A_2$ has $\\{6\\}$. Count is $1$.\n$C_{12} = 1 + 1 = 2$.\n- For $(u,v) = (1, 3)$: $t=1 \\in A_1 \\implies t' \\in (1, 3]$. $A_3$ has $\\{3\\}$. Count is $1$.\n$t=5 \\in A_1 \\implies t' \\in (5, 7]$. $A_3$ has none. Count is $0$.\n$C_{13} = 1 + 0 = 1$.\n- For $(u,v) = (1, 4)$: $t=1 \\in A_1 \\implies t' \\in (1, 3]$. $A_4$ has none. Count is $0$.\n$t=5 \\in A_1 \\implies t' \\in (5, 7]$. $A_4$ has $\\{7\\}$. Count is $1$.\n$C_{14} = 0 + 1 = 1$.\n\n- For $(u,v) = (2, 1)$: $t=2 \\in A_2 \\implies t' \\in (2, 4]$. $A_1$ has none. Count is $0$.\n$t=6 \\in A_2 \\implies t' \\in (6, 8]$. $A_1$ has none. Count is $0$.\n$C_{21} = 0 + 0 = 0$.\n- For $(u,v) = (2, 3)$: $t=2 \\in A_2 \\implies t' \\in (2, 4]$. $A_3$ has $\\{3\\}$. Count is $1$.\n$t=6 \\in A_2 \\implies t' \\in (6, 8]$. $A_3$ has none. Count is $0$.\n$C_{23} = 1 + 0 = 1$.\n- For $(u,v) = (2, 4)$: $t=2 \\in A_2 \\implies t' \\in (2, 4]$. $A_4$ has $\\{4\\}$. Count is $1$.\n$t=6 \\in A_2 \\implies t' \\in (6, 8]$. $A_4$ has $\\{7\\}$. Count is $1$.\n$C_{24} = 1 + 1 = 2$.\n\n- For $(u,v) = (3, 1)$: $t=3 \\in A_3 \\implies t' \\in (3, 5]$. $A_1$ has $\\{5\\}$. Count is $1$.\n$C_{31} = 1$.\n- For $(u,v) = (3, 2)$: $t=3 \\in A_3 \\implies t' \\in (3, 5]$. $A_2$ has none. Count is $0$.\n$C_{32} = 0$.\n- For $(u,v) = (3, 4)$: $t=3 \\in A_3 \\implies t' \\in (3, 5]$. $A_4$ has $\\{4\\}$. Count is $1$.\n$C_{34} = 1$.\n\n- For $(u,v) = (4, 1)$: $t=4 \\in A_4 \\implies t' \\in (4, 6]$. $A_1$ has $\\{5\\}$. Count is $1$.\n$t=7 \\in A_4 \\implies t' \\in (7, 9]$. $A_1$ has none. Count is $0$.\n$C_{41} = 1 + 0 = 1$.\n- For $(u,v) = (4, 2)$: $t=4 \\in A_4 \\implies t' \\in (4, 6]$. $A_2$ has $\\{6\\}$. Count is $1$.\n$t=7 \\in A_4 \\implies t' \\in (7, 9]$. $A_2$ has none. Count is $0$.\n$C_{42} = 1 + 0 = 1$.\n- For $(u,v) = (4, 3)$: $t=4 \\in A_4 \\implies t' \\in (4, 6]$. $A_3$ has none. Count is $0$.\n$t=7 \\in A_4 \\implies t' \\in (7, 9]$. $A_3$ has none. Count is $0$.\n$C_{43} = 0 + 0 = 0$.\n\nThe total number of potential instances is the sum of these counts:\n$|\\mathcal{P}| = C_{12} + C_{13} + C_{14} + C_{21} + C_{23} + C_{24} + C_{31} + C_{32} + C_{34} + C_{41} + C_{42} + C_{43}$\n$|\\mathcal{P}| = 2 + 1 + 1 + 0 + 1 + 2 + 1 + 0 + 1 + 1 + 1 + 0 = 11$.\n\nFinally, we calculate the expected number of motifs:\n$$E[N] = |\\mathcal{P}| \\times \\frac{1}{(|\\mathcal{V}| - 1)^2} = 11 \\times \\frac{1}{(4 - 1)^2} = 11 \\times \\frac{1}{9} = \\frac{11}{9}$$\nThe expected number of reciprocal-pair motif instances is $\\frac{11}{9}$.",
            "answer": "$$\\boxed{\\frac{11}{9}}$$"
        },
        {
            "introduction": "This final practice elevates our analysis from pattern detection to mechanistic inference, directly addressing the core theme of adaptive networks. You will construct a formal statistical test to determine if the formation of a network tie is coupled to a time-varying property of the nodes, while controlling for other sources of temporal variation. By deriving a generalized likelihood ratio test statistic from first principles, you will gain hands-on experience with a powerful framework for testing specific hypotheses about co-evolutionary dynamics. ",
            "id": "4112754",
            "problem": "Consider a single dyad $\\{i,j\\}$ observed over discrete times $t \\in \\{1,2,\\dots,T\\}$ with $T \\geq 10$. Let $A_{ij}(t) \\in \\{0,1\\}$ denote the adjacency indicator for the dyad at time $t$, and let $x(t) \\in \\mathbb{R}$ be an observed, time-varying dyad-level covariate derived from the node states (for example, a state difference). To capture exogenous temporal variation that is not driven by $x(t)$ and short-term edge persistence, you will model the conditional edge formation probability with a Bernoulli Generalized Linear Model (GLM) using a logit link, a low-dimensional temporal basis $\\mathbf{b}(t) \\in \\mathbb{R}^{K}$ with known basis functions, and a first-order Markov dependence on the lagged edge $A_{ij}(t-1)$.\n\nAssume the following conditional independence structure: conditional on the history $\\mathcal{H}_{t-1} = \\{A_{ij}(s): s \\leq t-1\\}$ and on covariates $\\{x(s), \\mathbf{b}(s): s \\leq t\\}$, the outcomes $\\{A_{ij}(t)\\}_{t=2}^{T}$ are independent with $A_{ij}(t) \\sim \\mathrm{Bernoulli}(p(t))$.\n\nYou wish to test the presence of adaptive coupling to $x(t)$ beyond exogenous time dependence, by comparing:\n- Null model $\\mathcal{M}_{0}$ (exogenous-only): $\\mathrm{logit}\\big(p_{0}(t)\\big) = \\boldsymbol{\\gamma}^{\\top} \\mathbf{b}(t) + \\phi \\, A_{ij}(t-1)$.\n- Alternative model $\\mathcal{M}_{1}$ (adaptive coupling): $\\mathrm{logit}\\big(p_{1}(t)\\big) = \\beta \\, x(t) + \\boldsymbol{\\gamma}^{\\top} \\mathbf{b}(t) + \\phi \\, A_{ij}(t-1)$.\n\nHere, $\\beta \\in \\mathbb{R}$, $\\boldsymbol{\\gamma} \\in \\mathbb{R}^{K}$, and $\\phi \\in \\mathbb{R}$ are unknown parameters. The initial condition $A_{ij}(1)$ is treated as given.\n\nFormulate a hypothesis test of $H_{0}: \\beta = 0$ against $H_{1}: \\beta \\neq 0$ based on the generalized likelihood ratio. Derive an explicit expression for the generalized likelihood ratio test statistic $T$ in terms of the observed sequence $\\{A_{ij}(t)\\}_{t=2}^{T}$ and the fitted probabilities under the two models, $\\{\\hat{p}_{0}(t)\\}_{t=2}^{T}$ and $\\{\\hat{p}_{1}(t)\\}_{t=2}^{T}$, where $\\hat{p}_{0}(t)$ and $\\hat{p}_{1}(t)$ are the maximum likelihood fitted probabilities under $\\mathcal{M}_{0}$ and $\\mathcal{M}_{1}$, respectively. Your final answer should be a single, closed-form analytic expression for $T$.\n\nIf you introduce any additional estimands or intermediate quantities, clearly define them. Do not assume any special functional form beyond what is specified above. Do not use any pre-derived test formulas; derive the statistic from first principles of likelihood for Bernoulli observations with a logit link. Express the final result only in terms of $\\{A_{ij}(t)\\}_{t=2}^{T}$ and $\\{\\hat{p}_{0}(t), \\hat{p}_{1}(t)\\}_{t=2}^{T}$. No numerical values are required, and no rounding is needed. The final answer must be a single closed-form expression with no units.",
            "solution": "The objective is to derive the generalized likelihood ratio test statistic for the hypothesis test $H_{0}: \\beta = 0$ against $H_{1}: \\beta \\neq 0$. The models $\\mathcal{M}_0$ and $\\mathcal{M}_1$ are nested, as $\\mathcal{M}_0$ is a special case of $\\mathcal{M}_1$ with the parameter $\\beta$ constrained to zero.\n\nThe generalized likelihood ratio test statistic, which we will denote as $T_{stat}$ to avoid confusion with the time horizon $T$, is defined as $T_{stat} = -2 \\ln \\Lambda$, where $\\Lambda$ is the ratio of the maximized likelihood under the null hypothesis to the maximized likelihood under the alternative hypothesis.\n$$ \\Lambda = \\frac{\\sup_{\\boldsymbol{\\theta} \\in \\Theta_0} L(\\boldsymbol{\\theta})}{\\sup_{\\boldsymbol{\\theta} \\in \\Theta_1} L(\\boldsymbol{\\theta})} $$\nHere, $\\Theta_1$ is the parameter space for model $\\mathcal{M}_1$, with parameter vector $\\boldsymbol{\\theta}_1 = (\\beta, \\boldsymbol{\\gamma}, \\phi)$, and $\\Theta_0$ is the parameter space for model $\\mathcal{M}_0$, where $\\beta=0$.\n\nBased on the conditional independence assumption, the likelihood function for the observed sequence $\\{A_{ij}(t)\\}_{t=2}^{T}$ is the product of the probabilities of each observation, conditional on the past. The probability mass function for a single observation $A_{ij}(t) \\sim \\mathrm{Bernoulli}(p(t))$ is given by:\n$$ P(A_{ij}(t) | \\mathcal{H}_{t-1}, x(t), \\mathbf{b}(t); p(t)) = p(t)^{A_{ij}(t)} (1 - p(t))^{1 - A_{ij}(t)} $$\nThe total conditional likelihood function $L(\\boldsymbol{\\theta})$ over the observation period $t=2, \\dots, T$ is:\n$$ L(\\boldsymbol{\\theta}) = \\prod_{t=2}^{T} p(t)^{A_{ij}(t)} (1 - p(t))^{1 - A_{ij}(t)} $$\nIt is more convenient to work with the log-likelihood function, $\\ell(\\boldsymbol{\\theta}) = \\ln L(\\boldsymbol{\\theta})$:\n$$ \\ell(\\boldsymbol{\\theta}) = \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln p(t) + (1 - A_{ij}(t)) \\ln(1 - p(t)) \\right] $$\n\nThe problem provides the maximum likelihood fitted probabilities under both models.\n- Under $\\mathcal{M}_1$, the maximized log-likelihood, $\\hat{\\ell}_1$, is obtained by evaluating $\\ell(\\boldsymbol{\\theta})$ at the maximum likelihood estimates of the parameters, which yield the fitted probabilities $\\{\\hat{p}_1(t)\\}_{t=2}^{T}$.\n$$ \\hat{\\ell}_1 = \\sup_{\\boldsymbol{\\theta} \\in \\Theta_1} \\ell(\\boldsymbol{\\theta}) = \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln \\hat{p}_1(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_1(t)) \\right] $$\n- Similarly, under $\\mathcal{M}_0$, the maximized log-likelihood, $\\hat{\\ell}_0$, is obtained using the fitted probabilities $\\{\\hat{p}_0(t)\\}_{t=2}^{T}$.\n$$ \\hat{\\ell}_0 = \\sup_{\\boldsymbol{\\theta} \\in \\Theta_0} \\ell(\\boldsymbol{\\theta}) = \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln \\hat{p}_0(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_0(t)) \\right] $$\n\nThe likelihood ratio $\\Lambda$ is therefore:\n$$ \\Lambda = \\frac{L(\\hat{\\boldsymbol{\\theta}}_0)}{L(\\hat{\\boldsymbol{\\theta}}_1)} = \\frac{\\exp(\\hat{\\ell}_0)}{\\exp(\\hat{\\ell}_1)} = \\exp(\\hat{\\ell}_0 - \\hat{\\ell}_1) $$\nThe test statistic (denoted by $T$ in the problem statement) is derived as follows:\n$$ T = -2 \\ln \\Lambda = -2 \\ln(\\exp(\\hat{\\ell}_0 - \\hat{\\ell}_1)) = -2(\\hat{\\ell}_0 - \\hat{\\ell}_1) = 2(\\hat{\\ell}_1 - \\hat{\\ell}_0) $$\nSubstituting the expressions for $\\hat{\\ell}_1$ and $\\hat{\\ell}_0$:\n$$ T = 2 \\left( \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln \\hat{p}_1(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_1(t)) \\right] - \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln \\hat{p}_0(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_0(t)) \\right] \\right) $$\nWe can combine the two summations into a single sum:\n$$ T = 2 \\sum_{t=2}^{T} \\left( \\left[ A_{ij}(t) \\ln \\hat{p}_1(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_1(t)) \\right] - \\left[ A_{ij}(t) \\ln \\hat{p}_0(t) + (1 - A_{ij}(t)) \\ln(1 - \\hat{p}_0(t)) \\right] \\right) $$\nNow, we group the terms by the observed outcome $A_{ij}(t)$:\n$$ T = 2 \\sum_{t=2}^{T} \\left( A_{ij}(t) \\left[ \\ln \\hat{p}_1(t) - \\ln \\hat{p}_0(t) \\right] + (1 - A_{ij}(t)) \\left[ \\ln(1 - \\hat{p}_1(t)) - \\ln(1 - \\hat{p}_0(t)) \\right] \\right) $$\nUsing the property of logarithms $\\ln a - \\ln b = \\ln(a/b)$, we can simplify the expression:\n$$ T = 2 \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln\\left(\\frac{\\hat{p}_1(t)}{\\hat{p}_0(t)}\\right) + (1 - A_{ij}(t)) \\ln\\left(\\frac{1 - \\hat{p}_1(t)}{1 - \\hat{p}_0(t)}\\right) \\right] $$\nThis is the final expression for the generalized likelihood ratio test statistic $T$ in terms of the observed data and fitted probabilities, as required. This statistic is also known as the difference in deviances between the two models. Under the null hypothesis $H_0$, this statistic asymptotically follows a chi-squared distribution $\\chi^2_d$, where $d$ is the difference in the number of free parameters between $\\mathcal{M}_1$ and $\\mathcal{M}_0$. In this case, $d=1$ since only the parameter $\\beta$ is added.",
            "answer": "$$\n\\boxed{2 \\sum_{t=2}^{T} \\left[ A_{ij}(t) \\ln\\left(\\frac{\\hat{p}_1(t)}{\\hat{p}_0(t)}\\right) + (1 - A_{ij}(t)) \\ln\\left(\\frac{1 - \\hat{p}_1(t)}{1 - \\hat{p}_0(t)}\\right) \\right]}\n$$"
        }
    ]
}