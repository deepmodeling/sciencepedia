{
    "hands_on_practices": [
        {
            "introduction": "本练习是真实空间重整化群的一个经典实例。对于像二维伊辛模型这样的系统，精确的重整化变换通常难以处理，因此我们需要依赖近似方法。通过应用Migdal-Kadanoff键移动近似，我们可以推导出一个可解的重整化群流方程，这为了解相变和临界现象提供了深刻的洞察。这项实践将指导你推导耦合常数的重整化过程，并通过计算来探索重整化流及其非平凡不动点的性质 。",
            "id": "4139880",
            "problem": "您的任务是实现二维铁磁伊辛模型的粗粒化步骤，该步骤使用Kadanoff块自旋平均，并推导相应的重整化最近邻耦合。二维伊辛模型定义在一个方格点阵上，其自旋变量为 $s_i \\in \\{-1,+1\\}$，哈密顿量为\n$$\nH(s) = - J \\sum_{\\langle i,j \\rangle} s_i s_j,\n$$\n其中 $J \\ge 0$ 是无量纲铁磁耦合，求和遍及所有最近邻对 $\\langle i,j \\rangle$。一个构型 $s$ 的平衡概率由玻尔兹曼分布 $P(s) \\propto \\exp(-H(s))$ 给出。\n\n重整化群(RG)变换将微观自旋粗粒化为块自旋，此处通过将 $2 \\times 2$ 的自旋组合成一个块，并使用多数原则指定块自旋 $S_B = \\mathrm{sign}\\left(\\sum_{i \\in B} s_i\\right)$。为了将粗粒化点阵上的有效理论近似为另一个具有哈密顿量\n$$\nH'(S) = - J' \\sum_{\\langle B,B' \\rangle} S_B S_{B'}\n$$\n的最近邻伊辛模型，必须在保持点阵配位结构的同时对微观自旋进行求迹。一种在保持可处理性的同时强制执行此条件的标准近似是Migdal-Kadanoff (MK) 键移动构造，在该构造中，键被重新分配并沿着连接相邻块的路径进行组合，然后对中间自旋进行求迹。在这些假设下，忽略高阶多自旋耦合的产生，粗粒化产生一个函数关系 $J' = f(J)$。\n\n您的任务是：\n\n1) 从伊辛哈密顿量和玻尔兹曼权重出发，通过对连接两个粗粒化块自旋的单条双键链进行精确求迹，得到沿该路径的有效双自旋相互作用。然后应用适用于空间维度 $d=2$ 和块尺寸 $b=2$ 的MK键移动因子，以闭合形式推导RG映射 $J' = f(J)$。推导必须从上述定义开始，通过使对齐与反对齐的边界自旋的玻尔兹曼权重之比相等来进行，并逻辑地应用MK重标度因子 $b^{d-1}$ 以在粗粒化下保持连通性。\n\n2) 实现一个程序，该程序：\n- 对于给定的输入 $J$ 计算 $f(J)$。\n- 计算导数 $f'(J)$。\n- 找到满足 $f(J^*) = J^*$ 且 $J \\in (0, +\\infty)$ 的非平凡不动点 $J^*$，绝对容差在 $10^{-12}$ 以内。\n所有量都是无量纲的，并且必须表示为实数。不需要物理单位。\n\n3) 使用以下测试套件来检验您的实现：\n- 情况A（边界）：$J = 0.0$。返回 $f(0.0)$。\n- 情况B（小耦合展开）：$J = 0.05$。返回 $f(0.05)$，以及与领先的小-$J$展开式的绝对偏差，即 $\\left|f(0.05) - 2 \\cdot (0.05)^2\\right|$。\n- 情况C（不动点附近的典型值）：$J = 0.62$。返回 $f(0.62)$。\n- 情况D（不动点）：返回 $J^*$ 和 $f'(J^*)$。\n- 情况E（单调性检查）：返回谓词 $f(0.4)  f(0.6)$ 的布尔值。\n- 情况F（对中等耦合进行两步RG）：返回 $f(f(0.3))$。\n- 情况G（强耦合行为）：$J = 5.0$。返回 $f(5.0)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序必须严格如下：\n$$\n\\left[f(0.0),\\, f(0.05),\\, \\left|f(0.05) - 2 \\cdot (0.05)^2\\right|,\\, f(0.62),\\, J^*,\\, f'(J^*),\\, \\text{单调性布尔值},\\, f(f(0.3)),\\, f(5.0)\\right].\n$$\n每个数值条目必须是浮点数。单调性条目必须是布尔值。此问题不涉及角度或物理单位；所有量都是无量纲实数。",
            "solution": "我们从二维伊辛模型开始，其哈密顿量为\n$$\nH(s) = -J \\sum_{\\langle i,j \\rangle} s_i s_j,\n$$\n其中 $J \\ge 0$ 且 $s_i \\in \\{-1,+1\\}$，玻尔兹曼权重为 $P(s) \\propto \\exp\\left(J \\sum_{\\langle i,j \\rangle} s_i s_j\\right)$。\n\n在采用 $2 \\times 2$ 块的Kadanoff块自旋平均下，粗粒化变量 $S_B$ 由多数原则定义。为了推导相邻块自旋之间的有效最近邻耦合 $J'$，我们考虑在空间维度 $d=2$ 中，标度因子 $b=2$ 的Migdal-Kadanoff (MK) 键移动近似。在MK近似中，移动键以在粗粒化后保持点阵的配位结构，并且通过对中间微观自旋求迹，来组合沿块自旋之间路径的相互作用。这个过程以近似忽略多自旋相互作用为代价，保留了最近邻伊辛形式。\n\n考虑两个相邻的块，它们通过一条由两个强度为 $J$ 的相同键串联组成的路径相连：末端的自旋 $s_0$ 和 $s_2$（代表与块自旋对齐的边界自旋）以及一个中间自旋 $s_1$。对 $s_1$ 求迹后的部分玻尔兹曼权重为\n$$\nW(s_0, s_2) = \\sum_{s_1 = \\pm 1} \\exp\\left[J s_0 s_1 + J s_1 s_2\\right] = \\sum_{s_1 = \\pm 1} \\exp\\left[J s_1 (s_0 + s_2)\\right] = 2 \\cosh\\left(J(s_0 + s_2)\\right).\n$$\n当 $s_0 = s_2$ (对齐) 时，我们有 $s_0 + s_2 = \\pm 2$，且 $W_{\\mathrm{aligned}} = 2 \\cosh(2J)$。当 $s_0 = -s_2$ (反对齐) 时，我们有 $s_0 + s_2 = 0$，且 $W_{\\mathrm{anti}} = 2 \\cosh(0) = 2$。如果我们寻求一个伊辛形式 $\\exp\\left[J_{\\mathrm{series}} s_0 s_2\\right]$ 的有效双自旋相互作用，那么对齐与反对齐的权重之比必须与玻尔兹曼因子之比相匹配：\n$$\n\\frac{W_{\\mathrm{aligned}}}{W_{\\mathrm{anti}}} = \\frac{\\exp(J_{\\mathrm{series}} \\cdot (+1))}{\\exp(J_{\\mathrm{series}} \\cdot (-1))} = \\exp(2 J_{\\mathrm{series}}).\n$$\n因此，\n$$\n\\exp(2 J_{\\mathrm{series}}) = \\frac{2 \\cosh(2J)}{2} = \\cosh(2J),\n$$\n这给出\n$$\nJ_{\\mathrm{series}} = \\frac{1}{2} \\ln\\left(\\cosh(2J)\\right).\n$$\n\n在 $d=2$ 维度下，块尺寸 $b=2$ 的Migdal-Kadanoff键移动步骤为有效耦合引入了一个乘法因子 $b^{d-1} = 2$，以在粗粒化下保持连通性。因此，一步RG变换后的重整化最近邻耦合为\n$$\nJ' = f(J) = 2 J_{\\mathrm{series}} = \\ln\\left(\\cosh(2J)\\right).\n$$\n等价地，使用双曲恒等式，\n$$\nf(J) = 2 \\operatorname{artanh}\\!\\left(\\tanh^2 J\\right),\n$$\n因为\n$$\n\\operatorname{artanh}(x) = \\frac{1}{2} \\ln\\left(\\frac{1+x}{1-x}\\right), \\quad \\frac{1+\\tanh^2 J}{1-\\tanh^2 J} = \\cosh(2J).\n$$\n两种形式是相同的；对数形式在数值计算上更方便：\n$$\nf(J) = \\ln\\left(\\cosh(2J)\\right).\n$$\n\n$f(J)$ 的导数可以直接得出：\n$$\nf'(J) = \\frac{d}{dJ} \\ln\\left(\\cosh(2J)\\right) = \\frac{2 \\sinh(2J)}{\\cosh(2J)} = 2 \\tanh(2J).\n$$\n\n小耦合展开提供了一致性检验。使用 $\\cosh x = 1 + \\frac{x^2}{2} + \\mathcal{O}(x^4)$，对于小的 $J$ 我们有\n$$\n\\cosh(2J) = 1 + \\frac{(2J)^2}{2} + \\mathcal{O}(J^4) = 1 + 2J^2 + \\mathcal{O}(J^4),\n$$\n所以\n$$\nf(J) = \\ln\\left(1 + 2J^2 + \\mathcal{O}(J^4)\\right) = 2J^2 + \\mathcal{O}(J^4),\n$$\n证实了当 $J \\to 0$ 时的主导行为 $f(J) \\approx 2J^2$。\n\n不动点 $J^*$ 满足\n$$\nJ^* = f(J^*) = \\ln\\left(\\cosh(2J^*)\\right).\n$$\n在数值上，这可以通过对函数 $g(J) = f(J) - J$ 在诸如 $J \\in [0, 2]$ 的区间上使用稳健的一维求根器来求解。在不动点处的导数为\n$$\nf'(J^*) = 2 \\tanh(2J^*),\n$$\n该值大于一，反映了在此RG映射下非平凡不动点的不稳定性。$f(J)$ 对于 $J \\ge 0$ 的单调性可从 $f'(J) = 2 \\tanh(2J) \\ge 0$ 得出，且对于 $J > 0$ 是严格递增的。\n\n程序的算法规划：\n- 使用标准库函数实现 $f(J) = \\ln(\\cosh(2J))$。\n- 实现 $f'(J) = 2 \\tanh(2J)$。\n- 使用求根器找到解 $f(J) - J = 0$ 的 $J^*$，容差为 $10^{-12}$。\n- 按指定顺序计算测试输出：\n  1. $f(0.0)$,\n  2. $f(0.05)$,\n  3. $\\left|f(0.05) - 2 \\cdot (0.05)^2\\right|$,\n  4. $f(0.62)$,\n  5. $J^*$,\n  6. $f'(J^*)$,\n  7. 布尔值 $f(0.4)  f(0.6)$,\n  8. $f(f(0.3))$,\n  9. $f(5.0)$。\n这些都是无量纲的。程序打印单行，其中包含一个用方括号括起来的逗号分隔列表，顺序与上述完全一致。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import root_scalar\n\ndef f(J: float) - float:\n    \"\"\"\n    Renormalization group map under Migdal-Kadanoff (MK) with b=2 in d=2:\n    J' = ln(cosh(2J)).\n    \"\"\"\n    return float(np.log(np.cosh(2.0 * J)))\n\ndef f_prime(J: float) - float:\n    \"\"\"\n    Derivative of the RG map: f'(J) = 2 * tanh(2J).\n    \"\"\"\n    return float(2.0 * np.tanh(2.0 * J))\n\ndef find_fixed_point(tol: float = 1e-12) - float:\n    \"\"\"\n    Find J* satisfying f(J*) = J* using a robust bracketing method.\n    \"\"\"\n    # The function g(J) = f(J) - J crosses zero from negative to positive at the\n    # non-trivial fixed point J*. A suitable bracket is [0.3, 1.2], since\n    # g(0.3)  0 and g(1.2) > 0.\n    def g(J):\n        return f(J) - J\n    \n    bracket = [0.3, 1.2]\n    sol = root_scalar(g, bracket=bracket, xtol=tol, rtol=tol, method='brentq')\n    \n    if not sol.converged:\n        raise RuntimeError(\"Root finding did not converge.\")\n    return float(sol.root)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # We will compute the outputs in the exact required order:\n    # [f(0.0), f(0.05), |f(0.05) - 2*(0.05)^2|, f(0.62), J_star, f'(J_star), monotonicity_boolean, f(f(0.3)), f(5.0)]\n    \n    # Compute required values\n    f_A = f(0.0)\n    f_B = f(0.05)\n    small_J_approx = 2.0 * (0.05 ** 2)\n    small_J_error = abs(f_B - small_J_approx)\n    f_C = f(0.62)\n    J_star = find_fixed_point(tol=1e-12)\n    fprime_at_Jstar = f_prime(J_star)\n    monotonicity_boolean = f(0.4)  f(0.6)\n    f_F_inner = f(0.3)\n    f_F = f(f_F_inner)\n    f_G = f(5.0)\n\n    results = [\n        f_A,\n        f_B,\n        small_J_error,\n        f_C,\n        J_star,\n        fprime_at_Jstar,\n        monotonicity_boolean,\n        f_F,\n        f_G\n    ]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了执行重整化变换的基本方法后，我们来探讨其一个深刻的后果：普适性。重整化群变换通常是多对一的映射，这意味着不同的微观模型可以“流向”同一个有效的宏观理论。本练习将通过一个简单的自旋链模型，具体展示普适性的这一基本原理，证明不同的微观参数集如何产生完全相同的粗粒化行为，并量化由此导致的可分辨性损失 。",
            "id": "4139877",
            "problem": "考虑一个在复杂自适应系统中常用的二元态相互作用模型：三个自旋 $s_1, s_2, s_3 \\in \\{-1, +1\\}$ 在一条链上线性耦合。微观哈密顿量为 $H(s_1, s_2, s_3 \\mid K_1, K_2) = - K_1 s_1 s_2 - K_2 s_2 s_3$，其中 $K_1$ 和 $K_2$ 是微观耦合参数。微观分布是 Boltzmann 分布 $P(s_1, s_2, s_3 \\mid K_1, K_2) \\propto \\exp(-H)$。\n\n通过单步重整化群 (RG) 变换进行的粗粒化过程，是对中间自旋 $s_2$ 进行边际化，从而得到一个关于 $(s_1, s_3)$ 的二自旋有效模型，其形式为 $P_{\\text{eff}}(s_1, s_3 \\mid K'(K_1, K_2)) \\propto \\exp(K'(K_1, K_2)\\, s_1 s_3)$，其中 $K'(K_1, K_2)$ 是抽取（decimation）后的有效耦合，而不依赖于 $(s_1, s_3)$ 的总因子被吸收到归一化常数中。在复杂自适应系统的统计模型中，这一 RG 步骤是一种标准的粗粒化操作，其基础原理是宏观统计量是通过对微观自由度进行积分（或求和）得到的。\n\n仅使用上述基本定义，完成以下任务：\n\n1. 通过对 $s_2$ 进行边际化，推导有效耦合 $K'(K_1, K_2)$ 的显式表达式。\n2. 证明映射 $(K_1, K_2) \\mapsto K'(K_1, K_2)$ 是多对一的，方法是构造两组不同的微观参数对 $(K_1, K_2)$ 和 $(\\tilde{K}_1, \\tilde{K}_2)$，它们能产生相同的有效耦合。具体地，考虑目标值 $K' = \\tfrac{1}{2} \\ln 2$。提供两对参数：\n   - 参数对 $\\mathcal{A}$：$K_1 = K_2 = \\tfrac{1}{2} \\operatorname{arccosh}(2)$。\n   - 参数对 $\\mathcal{B}$：$K_1 = \\tfrac{1}{2}\\left(\\operatorname{arccosh}(3) + \\operatorname{arccosh}\\!\\left(\\tfrac{3}{2}\\right)\\right)$ 和 $K_2 = \\tfrac{1}{2}\\left(\\operatorname{arccosh}(3) - \\operatorname{arccosh}\\!\\left(\\tfrac{3}{2}\\right)\\right)$。\n   验证这两对参数都产生相同的 $K'$。\n3. 通过考虑由粗粒化层面的观测所导出的微观参数上的 Fisher 信息矩阵 (FIM)，分析其对（统计）推断的影响。对于有效二自旋模型 $P_{\\text{eff}}(s_1, s_3 \\mid K') \\propto \\exp(K' s_1 s_3)$，$K'$ 的单样本 Fisher 信息定义为 $I(K') = \\mathbb{E}\\left[\\left(\\partial_{K'} \\ln P_{\\text{eff}}(s_1, s_3 \\mid K')\\right)^{2}\\right]$。$(K_1, K_2)$ 上的拉回 FIM 为 $F(K_1, K_2) = I(K') \\nabla K'(K_1, K_2)\\, \\nabla K'(K_1, K_2)^{\\top}$，其唯一的非零特征值为 $\\lambda(K_1, K_2) = I(K') \\|\\nabla K'(K_1, K_2)\\|^{2}$。\n\n计算映射到相同有效耦合 $K' = \\tfrac{1}{2} \\ln 2$ 的两组微观参数对 $\\mathcal{A}$ 和 $\\mathcal{B}$ 处非零特征值的比值 $R$，即，\n$$\nR \\equiv \\frac{\\lambda(K_1, K_2)\\big|_{\\mathcal{B}}}{\\lambda(K_1, K_2)\\big|_{\\mathcal{A}}}.\n$$\n\n将你的最终答案表示为最简分数。无需四舍五入。本问题不涉及物理单位。",
            "solution": "问题要求对一个简单的含三个自旋的一维 Ising 模型中的粗粒化过程进行三部分分析。在验证问题陈述之后，我们将按顺序处理每个部分。问题在科学上是合理的、良定的且自洽的。该模型是统计物理学中的一个标准构造，所描述的重整化群 (RG) 步骤是抽取（decimation）的一个典型例子。使用 Fisher 信息矩阵 (FIM) 来分析参数敏感性是信息几何中的一种标准技术。因此，该问题是有效的。\n\n### 第一部分：有效耦合 $K'$ 的推导\n\n三个自旋 $s_1, s_2, s_3 \\in \\{-1, +1\\}$ 的微观分布由 Boltzmann 分布给出：\n$$P(s_1, s_2, s_3 \\mid K_1, K_2) \\propto \\exp(-H(s_1, s_2, s_3 \\mid K_1, K_2)) = \\exp(K_1 s_1 s_2 + K_2 s_2 s_3)$$\nRG 变换包括对中间自旋 $s_2$ 进行边际化，以获得剩余自旋 $s_1$ 和 $s_3$ 的有效分布。\n$$P_{\\text{eff}}(s_1, s_3) = \\sum_{s_2 \\in \\{-1, +1\\}} P(s_1, s_2, s_3)$$\n代入概率表达式，并将不依赖于 $s_2$ 的项提取出来，我们得到：\n$$P_{\\text{eff}}(s_1, s_3) \\propto \\sum_{s_2 \\in \\{-1, +1\\}} \\exp(s_2(K_1 s_1 + K_2 s_3))$$\n对 $s_2$ 的求和可以明确写出：\n$$P_{\\text{eff}}(s_1, s_3) \\propto \\exp(K_1 s_1 + K_2 s_3) + \\exp(-(K_1 s_1 + K_2 s_3))$$\n这是双曲余弦函数的定义，乘以一个因子 $2$：\n$$P_{\\text{eff}}(s_1, s_3) \\propto 2 \\cosh(K_1 s_1 + K_2 s_3)$$\n由于我们只关心比例关系，因子 $2$ 可以被吸收到归一化常数中。\n$$P_{\\text{eff}}(s_1, s_3) \\propto \\cosh(K_1 s_1 + K_2 s_3)$$\n我们使用双曲恒等式 $\\cosh(a+b) = \\cosh(a)\\cosh(b) + \\sinh(a)\\sinh(b)$。由于 $s_1$ 和 $s_3$ 是二元变量 $\\{-1, +1\\}$，我们有 $s_1^2 = 1$ 和 $s_3^2=1$，这意味着 $\\cosh(K_1 s_1) = \\cosh(K_1)$ 和 $\\sinh(K_1 s_1) = s_1 \\sinh(K_1)$（对 $s_3$ 也类似）。因此，我们可以将表达式展开为：\n$$\n\\begin{align*}\n\\cosh(K_1 s_1 + K_2 s_3) = \\cosh(K_1 s_1)\\cosh(K_2 s_3) + \\sinh(K_1 s_1)\\sinh(K_2 s_3) \\\\\n= \\cosh(K_1)\\cosh(K_2) + s_1 s_3 \\sinh(K_1)\\sinh(K_2)\n\\end{align*}\n$$\n问题陈述有效分布具有形式 $P_{\\text{eff}}(s_1, s_3) \\propto \\exp(K' s_1 s_3)$。我们也可以利用 $(s_1 s_3)^2 = 1$ 这一事实展开这个指数形式：\n$$\\exp(K' s_1 s_3) = \\cosh(K') + s_1 s_3 \\sinh(K')$$\n为了使两种形式的有效分布成比例，它们对 $s_1 s_3$ 的函数依赖关系必须匹配。比较这两个表达式：\n$$A + B s_1 s_3 \\propto C + D s_1 s_3$$\n其中 $A = \\cosh(K_1)\\cosh(K_2)$，$B = \\sinh(K_1)\\sinh(K_2)$，$C=\\cosh(K')$，以及 $D=\\sinh(K')$。这要求系数之比相等：\n$$\\frac{B}{A} = \\frac{D}{C}$$\n$$\\frac{\\sinh(K_1)\\sinh(K_2)}{\\cosh(K_1)\\cosh(K_2)} = \\frac{\\sinh(K')}{\\cosh(K')}$$\n这可以简化为：\n$$\\tanh(K_1)\\tanh(K_2) = \\tanh(K')$$\n对 $K'$ 求解，我们得到 RG 映射：\n$$K'(K_1, K_2) = \\operatorname{arctanh}(\\tanh(K_1)\\tanh(K_2))$$\n\n### 第二部分：参数对的验证\n\n我们被要求证明两组不同的微观参数对 $\\mathcal{A}$ 和 $\\mathcal{B}$ 映射到相同的有效耦合 $K' = \\frac{1}{2} \\ln 2$。\n首先，让我们找到与目标 $K'$ 对应的 $\\tanh(K')$ 的值：\n$$\\tanh(K') = \\tanh\\left(\\frac{1}{2} \\ln 2\\right)$$\n使用 tanh 的指数定义：\n$$\\tanh\\left(\\frac{1}{2} \\ln 2\\right) = \\frac{\\exp(\\frac{1}{2} \\ln 2) - \\exp(-\\frac{1}{2} \\ln 2)}{\\exp(\\frac{1}{2} \\ln 2) + \\exp(-\\frac{1}{2} \\ln 2)} = \\frac{\\sqrt{2} - 1/\\sqrt{2}}{\\sqrt{2} + 1/\\sqrt{2}} = \\frac{2-1}{2+1} = \\frac{1}{3}$$\n所以，我们必须验证对于两对参数，都有 $\\tanh(K_1)\\tanh(K_2) = 1/3$。\n\n**参数对 $\\mathcal{A}$:** $K_1 = K_2 = \\frac{1}{2} \\operatorname{arccosh}(2)$。\n设 $K_{\\mathcal{A}} = K_1 = K_2$。我们需要证明 $\\tanh^2(K_{\\mathcal{A}}) = 1/3$。\n从给定的 $K_{\\mathcal{A}}$，我们有 $2K_{\\mathcal{A}} = \\operatorname{arccosh}(2)$，这意味着 $\\cosh(2K_{\\mathcal{A}}) = 2$。\n使用恒等式 $\\cosh(2x) = \\frac{1+\\tanh^2(x)}{1-\\tanh^2(x)}$，我们有：\n$$2 = \\frac{1+\\tanh^2(K_{\\mathcal{A}})}{1-\\tanh^2(K_{\\mathcal{A}})}$$\n设 $t^2 = \\tanh^2(K_{\\mathcal{A}})$。那么 $2(1-t^2) = 1+t^2 \\implies 2-2t^2=1+t^2 \\implies 1=3t^2 \\implies t^2=1/3$。\n因此，对于参数对 $\\mathcal{A}$，有 $\\tanh(K_1)\\tanh(K_2) = 1/3$。\n\n**参数对 $\\mathcal{B}$:** $K_1 = \\frac{1}{2}(\\operatorname{arccosh}(3) + \\operatorname{arccosh}(\\frac{3}{2}))$ 且 $K_2 = \\frac{1}{2}(\\operatorname{arccosh}(3) - \\operatorname{arccosh}(\\frac{3}{2}))$。\n设 $u = \\operatorname{arccosh}(3)$ 且 $v = \\operatorname{arccosh}(\\frac{3}{2})$。则 $K_1 = (u+v)/2$ 且 $K_2 = (u-v)/2$。\n我们需要计算 $\\tanh(K_1)\\tanh(K_2)$。一个有用的恒等式是 $\\tanh(x)\\tanh(y) = \\frac{\\cosh(x+y)-\\cosh(x-y)}{\\cosh(x+y)+\\cosh(x-y)}$。\n设 $x=K_1$ 和 $y=K_2$。则 $x+y = K_1+K_2 = u = \\operatorname{arccosh}(3)$ 且 $x-y = K_1-K_2 = v = \\operatorname{arccosh}(\\frac{3}{2})$。\n根据定义，$\\cosh(u)=3$ 且 $\\cosh(v)=3/2$。将其代入恒等式：\n$$\\tanh(K_1)\\tanh(K_2) = \\frac{\\cosh(u) - \\cosh(v)}{\\cosh(u) + \\cosh(v)} = \\frac{3 - 3/2}{3 + 3/2} = \\frac{3/2}{9/2} = \\frac{3}{9} = \\frac{1}{3}$$\n因此，对于参数对 $\\mathcal{B}$，同样有 $\\tanh(K_1)\\tanh(K_2) = 1/3$。\n两对参数都映射到 $K' = \\operatorname{arctanh}(1/3) = \\frac{1}{2} \\ln 2$。\n\n### 第三部分：特征值比值的计算\n\n需要计算的比值 $R$ 是：\n$$R = \\frac{\\lambda(K_1, K_2)\\big|_{\\mathcal{B}}}{\\lambda(K_1, K_2)\\big|_{\\mathcal{A}}}$$\n其中 $\\lambda(K_1, K_2) = I(K') \\|\\nabla K'(K_1, K_2)\\|^{2}$。\n由于参数对 $\\mathcal{A}$ 和 $\\mathcal{B}$ 都映射到相同的有效耦合 $K'$，因子 $I(K')$ 在分子和分母中是相同的，因此可以消去。\n$$R = \\frac{\\|\\nabla K'(K_1, K_2)\\|^{2} \\big|_{\\mathcal{B}}}{\\|\\nabla K'(K_1, K_2)\\|^{2} \\big|_{\\mathcal{A}}}$$\n我们需要计算 $K'(K_1, K_2) = \\operatorname{arctanh}(\\tanh(K_1)\\tanh(K_2))$ 的梯度。\n设 $t_1 = \\tanh(K_1)$ 且 $t_2 = \\tanh(K_2)$。则 $K'=\\operatorname{arctanh}(t_1 t_2)$。\n偏导数为：\n$$\\frac{\\partial K'}{\\partial K_1} = \\frac{1}{1-(t_1 t_2)^2} \\cdot \\frac{\\partial(t_1 t_2)}{\\partial K_1} = \\frac{(1-t_1^2) t_2}{1-t_1^2 t_2^2}$$\n$$\\frac{\\partial K'}{\\partial K_2} = \\frac{1}{1-(t_1 t_2)^2} \\cdot \\frac{\\partial(t_1 t_2)}{\\partial K_2} = \\frac{t_1 (1-t_2^2)}{1-t_1^2 t_2^2}$$\n梯度的平方范数是 $\\|\\nabla K'\\|^2 = (\\frac{\\partial K'}{\\partial K_1})^2 + (\\frac{\\partial K'}{\\partial K_2})^2$:\n$$\\|\\nabla K'\\|^2 = \\frac{(1-t_1^2)^2 t_2^2 + t_1^2 (1-t_2^2)^2}{(1-t_1^2 t_2^2)^2} = \\frac{t_2^2-2t_1^2t_2^2+t_1^4t_2^2 + t_1^2-2t_1^2t_2^2+t_1^2t_2^4}{(1-t_1^2 t_2^2)^2}$$\n$$ = \\frac{t_1^2+t_2^2 - 4(t_1t_2)^2 + (t_1t_2)^2(t_1^2+t_2^2)}{(1-(t_1t_2)^2)^2}$$\n设 $S = t_1^2+t_2^2$ 且 $P=t_1 t_2$。表达式变为：\n$$\\|\\nabla K'\\|^2 = \\frac{S - 4P^2 + P^2 S}{(1-P^2)^2} = \\frac{S(1+P^2) - 4P^2}{(1-P^2)^2}$$\n对于两对参数，我们都有 $P = t_1 t_2 = 1/3$ 和 $P^2=1/9$。\n$\\|\\nabla K'\\|^2$ 的表达式简化为 $S$ 的函数：\n$$\\|\\nabla K'\\|^2 = \\frac{S(1+1/9) - 4/9}{(1-1/9)^2} = \\frac{S(10/9) - 4/9}{(8/9)^2} = \\frac{(10S-4)/9}{64/81} = \\frac{9(10S-4)}{64} = \\frac{9(5S-2)}{32}$$\n因此，比值 $R$ 是：\n$$R = \\frac{\\frac{9(5S_{\\mathcal{B}}-2)}{32}}{\\frac{9(5S_{\\mathcal{A}}-2)}{32}} = \\frac{5S_{\\mathcal{B}}-2}{5S_{\\mathcal{A}}-2}$$\n其中 $S_{\\mathcal{A}}$ 和 $S_{\\mathcal{B}}$ 分别是参数对 $\\mathcal{A}$ 和 $\\mathcal{B}$ 的 $S=t_1^2+t_2^2$ 的值。\n\n**对于参数对 $\\mathcal{A}$:** $K_1=K_2$。我们已经求得 $t_1^2=\\tanh^2(K_1)=1/3$ 且 $t_2^2=\\tanh^2(K_2)=1/3$。\n$$S_{\\mathcal{A}} = t_1^2+t_2^2 = \\frac{1}{3} + \\frac{1}{3} = \\frac{2}{3}$$\n**对于参数对 $\\mathcal{B}$:** 设 $u = \\operatorname{arccosh}(3)$ 和 $v = \\operatorname{arccosh}(3/2)$。\n$\\cosh(u)=3 \\implies \\sinh(u)=\\sqrt{\\cosh^2(u)-1}=\\sqrt{8}=2\\sqrt{2}$。所以 $\\tanh(u) = 2\\sqrt{2}/3$。\n$\\cosh(v)=3/2 \\implies \\sinh(v)=\\sqrt{(3/2)^2-1}=\\sqrt{5/4}=\\sqrt{5}/2$。所以 $\\tanh(v) = \\sqrt{5}/3$。\n我们有 $K_1+K_2 = u$ 和 $K_1-K_2 = v$。\n$t_1 = \\tanh(K_1)$ 且 $t_2 = \\tanh(K_2)$。\n使用 tanh 的和差恒等式：\n$\\tanh(u) = \\tanh(K_1+K_2) = \\frac{t_1+t_2}{1+t_1t_2} \\implies \\frac{2\\sqrt{2}}{3} = \\frac{t_1+t_2}{1+1/3} \\implies t_1+t_2 = \\frac{4}{3} \\frac{2\\sqrt{2}}{3} = \\frac{8\\sqrt{2}}{9}$。\n$\\tanh(v) = \\tanh(K_1-K_2) = \\frac{t_1-t_2}{1-t_1t_2} \\implies \\frac{\\sqrt{5}}{3} = \\frac{t_1-t_2}{1-1/3} \\implies t_1-t_2 = \\frac{2}{3} \\frac{\\sqrt{5}}{3} = \\frac{2\\sqrt{5}}{9}$。\n我们需要 $S_{\\mathcal{B}} = t_1^2+t_2^2$。我们使用恒等式 $2(t_1^2+t_2^2)=(t_1+t_2)^2+(t_1-t_2)^2$。\n$$2S_{\\mathcal{B}} = \\left(\\frac{8\\sqrt{2}}{9}\\right)^2 + \\left(\\frac{2\\sqrt{5}}{9}\\right)^2 = \\frac{64 \\cdot 2}{81} + \\frac{4 \\cdot 5}{81} = \\frac{128+20}{81} = \\frac{148}{81}$$\n$$S_{\\mathcal{B}} = \\frac{148}{2 \\cdot 81} = \\frac{74}{81}$$\n现在，我们计算比值 $R$：\n$$R = \\frac{5S_{\\mathcal{B}}-2}{5S_{\\mathcal{A}}-2} = \\frac{5\\left(\\frac{74}{81}\\right)-2}{5\\left(\\frac{2}{3}\\right)-2} = \\frac{\\frac{370}{81}-\\frac{162}{81}}{\\frac{10}{3}-\\frac{6}{3}} = \\frac{208/81}{4/3}$$\n$$R = \\frac{208}{81} \\cdot \\frac{3}{4} = \\frac{52}{27}$$\n这是一个最简分数，因为 $52 = 4 \\times 13$ 且 $27=3^3$。",
            "answer": "$$\\boxed{\\frac{52}{27}}$$"
        },
        {
            "introduction": "接下来，我们转向一种为处理强非均匀性系统而设计的不同重整化范式。强无序重整化群 (SDRG) 是一种强大的非微扰方法，它通过迭代地消除网络中最强的相互作用来对系统进行粗粒化。这种方法对于理解无序系统（如自旋玻璃和随机场模型）的低能物理至关重要。本练习要求你推导SDRG的更新规则，并实现其算法来研究一个无序系统的粗粒化过程 。",
            "id": "4139836",
            "problem": "考虑一个由 $N$ 个节点组成的对称加权网络，其非负成对耦合由一个实对称矩阵 $J \\in \\mathbb{R}^{N \\times N}$ 表示，其中对所有 $i \\ne j$ 都有 $J_{ij} \\ge 0$，且对所有 $i$ 都有 $J_{ii} = 0$。假设该网络模型是一个无序铁磁相互作用系统，其能量由 Ising 哈密顿量 $H = -\\sum_{ij} J_{ij} s_i s_j$ 描述。\n\n强无序重整化群 (SDRG) 过程通过迭代地“抽取”最强的相互作用来对系统进行粗粒化。具体步骤如下：\n1. 找到网络中最强的耦合 $J_{uv} = \\max_{ij} J_{ij}$。\n2. 如果此最大耦合不大于某个预设阈值 $\\lambda_{\\text{min}}$ (即，$J_{uv} \\le \\lambda_{\\text{min}}$)，则停止该过程。\n3. 如果存在多个相同的最大耦合，则选择具有词典序最小索引对 $(u, v)$ (其中 $u  v$) 的那个。\n4. “抽取”最强的相互作用，这在物理上对应于将节点 $v$ 合并到节点 $u$ 中。这强制了自旋 $s_u$ 和 $s_v$ 在低温下锁定在一起，形成一个复合自旋。合并后的节点（仍标记为 $u$）与任何其他节点 $k$ 的新有效耦合由原始耦合之和给出：$J'_{uk} = J_{uk} + J_{vk}$。所有其他耦合 $J'_{ik}$ ($i,k \\neq u,v$) 保持不变。\n5. 更新网络，有效地移除节点 $v$ 及其所有连接，并将它的连接“重定向”到节点 $u$。\n6. 重复此过程，直到满足停止条件。\n\n**任务：**\n实现一个函数，该函数接收初始耦合矩阵 $J$ 和阈值 $\\lambda_{\\text{min}}$ 作为输入，并返回 SDRG 过程终止时的最终有效耦合矩阵。\n\n**测试用例：**\n为以下四种情况运行您的实现：\n1. $N=4$, $\\lambda_{\\text{min}}=1.5$, $J = [[0, 3, 0.5, 0], [3, 0, 1, 0.2], [0.5, 1, 0, 2], [0, 0.2, 2, 0]]$\n2. $N=3$, $\\lambda_{\\text{min}}=1.5$, $J = [[0, 2, 2], [2, 0, 1], [2, 1, 0]]$\n3. $N=4$, $\\lambda_{\\text{min}}=0.5$, $J = [[0, 0.4, 0.3, 0.2], [0.4, 0, 0.1, 0.2], [0.3, 0.1, 0, 0.3], [0.2, 0.2, 0.3, 0]]$\n4. $N=5$, $\\lambda_{\\text{min}}=1.0$, $J = [[0, 1, 1, 1, 1], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0], [1, 0, 0, 0, 0]]$\n\n**输出格式：**\n您的程序应生成一个单行字符串，其中包含一个用方括号括起来的、由逗号分隔的列表。列表中的每个元素都是一个最终矩阵，表示为一个嵌套列表。例如：`[[[0.0,1.7],[1.7,0.0]],[[0.0]]]`",
            "solution": "该问题要求为无序铁磁Ising模型实现强无序重整化群 (SDRG) 算法。这是一个定义明确的计算任务，其基础是统计物理学中用于研究无序系统的既定方法。\n\n### SDRG 算法概述\n\n该算法通过迭代简化一个耦合网络来运作。在每一步中，它识别并消除系统中最强的相互作用，从而有效地降低自由度。该过程持续进行，直到所有剩余的相互作用都低于某个能量（或温度）尺度，该尺度由阈值 $\\lambda_{\\textmin}$ 定义。\n\n算法的具体步骤如下：\n\n1.  **初始化**：从一个 $N \\times N$ 的耦合矩阵 $J$ 开始。\n\n2.  **迭代循环**：只要网络的节点数大于1，就重复以下操作：\n    a. **找到最强耦合**：在矩阵的上三角部分（为避免重复并确保 $u  v$）找到最大值 $J_{uv} = \\max_{ij} J_{ij}$。\n    b. **应用停止条件**：如果 $J_{uv} \\le \\lambda_{\\text{min}}$，则当前网络中的所有相互作用都被认为是“弱”的。该过程终止，并返回当前的耦合矩阵 $J$。\n    c. **决胜规则**：如果存在多个值等于 $J_{uv}$ 的耦合，选择具有词典序最小索引对 $(u, v)$ 的那个。\n    d. **重整化/合并**：将节点 $v$ 合并到节点 $u$ 中。这意味着节点 $u$ 现在继承了节点 $v$ 的所有连接。对于任何其他节点 $k$（$k \\ne u, v$），新的耦合 $J'_{uk}$ 计算如下：\n    $$\n    J'_{uk} = J_{uk} + J_{vk}\n    $$\n    由于矩阵是对称的，我们也有 $J'_{ku} = J'_{uk}$。\n    e. **矩阵缩减**：通过删除与节点 $v$ 对应的行和列来更新耦合矩阵，从而将网络的大小从 $M$ 减小到 $M-1$。\n\n### 示例：案例1的演化\n\n让我们手动演算第一个测试用例，以说明该过程：\n- **初始状态**:\n  $N=4$, $\\lambda_{\\text{min}}=1.5$\n  $J = \\begin{pmatrix} 0  3.0  0.5  0 \\\\ 3.0  0  1.0  0.2 \\\\ 0.5  1.0  0  2.0 \\\\ 0  0.2  2.0  0 \\end{pmatrix}$\n\n- **第1步**:\n  - 最强耦合是 $J_{01} = 3.0$。\n  - $3.0 > \\lambda_{\\text{min}} = 1.5$，所以继续。\n  - 合并节点 1 到节点 0。\n  - 新耦合:\n    $J'_{02} = J_{02} + J_{12} = 0.5 + 1.0 = 1.5$\n    $J'_{03} = J_{03} + J_{13} = 0.0 + 0.2 = 0.2$\n  - 移除节点1，得到一个3x3矩阵（节点为旧的0, 2, 3）：\n  $J^{(1)} = \\begin{pmatrix} 0  1.5  0.2 \\\\ 1.5  0  2.0 \\\\ 0.2  2.0  0 \\end{pmatrix}$ (索引重排为 0, 1, 2)\n\n- **第2步**:\n  - 最强耦合是 $J^{(1)}_{12} = 2.0$ (对应原始节点 2 和 3)。\n  - $2.0 > \\lambda_{\\text{min}} = 1.5$，所以继续。\n  - 合并节点 2 到节点 1。\n  - 新耦合: $J''_{10} = J^{(1)}_{10} + J^{(1)}_{20} = 1.5 + 0.2 = 1.7$。\n  - 移除节点2，得到一个2x2矩阵（节点为旧的0, {2,3}）：\n  $J^{(2)} = \\begin{pmatrix} 0  1.7 \\\\ 1.7  0 \\end{pmatrix}$ (索引重排为 0, 1)\n\n- **第3步**:\n  - 最强耦合是 $J^{(2)}_{01} = 1.7$。\n  - $1.7 > \\lambda_{\\text{min}} = 1.5$，所以继续。\n  - 合并节点 1 到节点 0。\n  - 移除节点1，得到一个1x1矩阵：\n  $J^{(3)} = \\begin{pmatrix} 0 \\end{pmatrix}$\n\n- **终止**:\n  - 此时网络中只剩一个节点。`while J.shape[0] > 1` 条件为假，循环终止。\n  - 返回的最终矩阵是 `[[0.0]]`。\n\n此逻辑将应用于所有测试用例，以生成最终的有效耦合矩阵。该算法的实现将遵循此分步过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef sdrg_procedure(J_initial, lambda_min):\n    \"\"\"\n    Performs the Strong-Disorder Renormalization Group (SDRG) procedure.\n    \n    Args:\n        J_initial (np.ndarray): The initial symmetric coupling matrix.\n        lambda_min (float): The minimum coupling threshold for stopping.\n        \n    Returns:\n        np.ndarray: The final effective coupling matrix.\n    \"\"\"\n    # Use a copy to avoid modifying the original input matrix\n    J = np.copy(J_initial)\n    \n    while J.shape[0]  1:\n        # Consider only the upper triangle to find the max coupling and its unique index\n        J_upper = np.triu(J, k=1)\n        max_val = np.max(J_upper)\n        \n        # Stopping condition: max coupling is not greater than the threshold\n        if max_val = lambda_min:\n            break\n            \n        # Find the location of the max coupling.\n        # np.argwhere finds all occurrences; it scans row-by-row, so the first\n        # result corresponds to the lexicographically smallest (u, v) pair.\n        indices = np.argwhere(J_upper == max_val)\n        u, v = indices[0] # u  v is guaranteed by using np.triu\n\n        # Renormalize couplings: merge node v into node u\n        # The new coupling from the merged node u to any other node k\n        # is the sum of the old couplings J_uk + J_vk.\n        # This can be efficiently done by adding row/column v to row/column u.\n        \n        # Update row u and column u\n        J[u, :] += J[v, :]\n        J[:, u] = J[u, :]\n        \n        # The diagonal element J[u, u] will become non-zero after the sum.\n        # It must be reset to 0, consistent with J_ii = 0.\n        J[u, u] = 0.0\n        \n        # Reduce the matrix by deleting the row and column for the merged node v.\n        J = np.delete(J, v, axis=0) # Delete row v\n        J = np.delete(J, v, axis=1) # Delete column v\n        \n    return J\n\ndef solve():\n    \"\"\"\n    Defines and solves the test cases provided in the problem statement.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (4, np.array([\n            [0.0, 3.0, 0.5, 0.0],\n            [3.0, 0.0, 1.0, 0.2],\n            [0.5, 1.0, 0.0, 2.0],\n            [0.0, 0.2, 2.0, 0.0]\n        ]), 1.5),\n        # Case 2\n        (3, np.array([\n            [0.0, 2.0, 2.0],\n            [2.0, 0.0, 1.0],\n            [2.0, 1.0, 0.0]\n        ]), 1.5),\n        # Case 3\n        (4, np.array([\n            [0.0, 0.4, 0.3, 0.2],\n            [0.4, 0.0, 0.1, 0.2],\n            [0.3, 0.1, 0.0, 0.3],\n            [0.2, 0.2, 0.3, 0.0]\n        ]), 0.5),\n        # Case 4\n        (5, np.array([\n            [0.0, 1.0, 1.0, 1.0, 1.0],\n            [1.0, 0.0, 0.0, 0.0, 0.0],\n            [1.0, 0.0, 0.0, 0.0, 0.0],\n            [1.0, 0.0, 0.0, 0.0, 0.0],\n            [1.0, 0.0, 0.0, 0.0, 0.0]\n        ]), 1.0)\n    ]\n\n    results = []\n    for N, J, lambda_min in test_cases:\n        final_J = sdrg_procedure(J, lambda_min)\n        # Convert the final numpy array to a nested list of floats\n        results.append(final_J.tolist())\n\n    # The string representation of a list of lists of floats adds spaces.\n    # To create a compact string, we process it.\n    results_str = [str(res).replace(\" \", \"\") for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        }
    ]
}