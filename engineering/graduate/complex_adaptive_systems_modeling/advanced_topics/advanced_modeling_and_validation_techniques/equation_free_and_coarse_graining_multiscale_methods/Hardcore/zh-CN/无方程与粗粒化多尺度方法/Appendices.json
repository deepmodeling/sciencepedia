{
    "hands_on_practices": [
        {
            "introduction": "“无方程”方法的核心在于连接微观模拟器和宏观（粗粒度）层面，而这需要一套算子在不同尺度间传递信息。本练习将通过一个基础但至关重要的任务来帮助你掌握这一核心技能：为空间扩展系统实现限制与提升算子。你将学习如何通过块平均（block averaging）来“限制”一个精细场以获得其粗粒度表示，以及如何通过求解一个约束插值问题来“提升”粗粒度数据，从而重建一个与之兼容且在物理上合理的精细场。",
            "id": "4121742",
            "problem": "考虑一个一维周期性晶格，有 $N$ 个格点，索引为 $j \\in \\{0,1,\\ldots,N-1\\}$，晶格间距设为无量纲值。设微观场由向量 $u \\in \\mathbb{R}^N$ 表示，其中 $u_j$ 表示格点 $j$ 处的场。一次粗粒化划分将晶格分为 $K$ 个大小统一为 $m$ 的连续、不重叠的块，因此 $N = K m$，且第 $i$ 个块为 $B_i = \\{i m, i m + 1, \\ldots, (i+1)m - 1\\}$，其中周期性索引按模 $N$ 理解。\n\n限制（Restriction）定义为块平均：粗粒化变量向量 $\\bar{u} \\in \\mathbb{R}^K$ 的分量为\n$$\n\\bar{u}_i = \\frac{1}{m} \\sum_{j \\in B_i} u_j, \\quad i = 0,1,\\ldots,K-1.\n$$\n提升（Lifting）定义为一个约束插值问题的解：给定目标块平均值 $\\bar{u} \\in \\mathbb{R}^K$，重构一个细粒度场 $u \\in \\mathbb{R}^N$，该场在满足粗粒化约束的条件下最小化一个光滑度泛函。设离散二阶差分算子（环上的离散拉普拉斯算子）作用为\n$$\n(\\Delta u)_j = u_{j+1} - 2 u_j + u_{j-1}, \\quad j \\in \\{0,1,\\ldots,N-1\\},\n$$\n其中周期性边界条件为 $u_{-1} = u_{N-1}$ 和 $u_N = u_0$。提升 $u^\\star$ 是曲率能量\n$$\nE(u) = \\sum_{j=0}^{N-1} \\left((\\Delta u)_j\\right)^2\n$$\n在块平均约束\n$$\n\\sum_{j \\in B_i} u_j = m \\, \\bar{u}_i, \\quad i = 0,1,\\ldots,K-1\n$$\n下的最小化子。\n三角函数内部出现的角度必须以弧度为单位解释。\n\n你的任务是：\n- 实现如上定义的通过块平均的限制算子。\n- 通过求解约束插值问题来实现提升算子：在所有满足给定块平均约束的 $u \\in \\mathbb{R}^N$ 中，选择使 $E(u)$ 最小化的那一个。\n- 通过计算提升后的 $u^\\star$ 的粗粒化平均值并将其与给定的 $\\bar{u}$进行比较，来验证提升的一致性。使用各块上的最大绝对偏差作为一致性度量。\n- 对于每个测试用例，报告一个布尔值，指示一致性度量是否超过规定的容差，最大绝对偏差本身，以及曲率能量 $E(u^\\star)$。\n\n使用的基本原理：\n- 如上所述的通过块平均的限制和通过约束插值的提升的定义。\n- 如上所述的周期性离散二阶差分算子。\n- 线性等式约束下的约束最小化原理，以及最小能量解存在且唯一，不计由约束移除的零空间模态。\n\n数值和算法要求：\n- 按模 $N$ 处理索引以强制周期性。\n- 确保 $N$ 和 $m$ 满足 $N = K m$，其中 $K$ 为整数。\n- 对一致性布尔值使用固定容差 $\\varepsilon = 10^{-10}$。\n- 三角测试场内的角度以弧度为单位。\n- 不涉及物理单位；所有量均为无量纲。\n\n测试套件：\n- 情况 A：$N = 128$，$m = 8$，$u_j = \\sin\\!\\left(2\\pi \\cdot 3 \\cdot \\frac{j}{N}\\right) + 0.25 \\cos\\!\\left(2\\pi \\cdot 7 \\cdot \\frac{j}{N}\\right) + 0.05 \\frac{j}{N}$。\n- 情况 B：$N = 64$，$m = 1$，$u_j = \\sin\\!\\left(2\\pi \\cdot 5 \\cdot \\frac{j}{N}\\right)$。\n- 情况 C：$N = 96$，$m = 24$，$u_j = \\sin\\!\\left(2\\pi \\cdot 10 \\cdot \\frac{j}{N}\\right) + 0.1 \\cos\\!\\left(2\\pi \\cdot 12 \\cdot \\frac{j}{N}\\right)$。\n- 情况 D：$N = 72$，$m = 9$，$u_j$ 是分段常数：对于 $0 \\le j  N/3$，$u_j = 1$；对于 $N/3 \\le j  2N/3$，$u_j = -0.5$；对于 $2N/3 \\le j  N$，$u_j = 0$。\n\n对于每种情况，通过对指定的 $u$ 应用限制来计算 $\\bar{u}$，执行提升以获得与 $\\bar{u}$ 一致的 $u^\\star$，然后计算：\n-布尔值 $b$，指示是否 $\\max_i \\left| \\bar{u}^\\star_i - \\bar{u}_i \\right| \\le \\varepsilon$，其中 $\\bar{u}^\\star$ 表示 $u^\\star$ 的限制，且 $\\varepsilon = 10^{-10}$。\n- 最大绝对偏差 $d = \\max_i \\left| \\bar{u}^\\star_i - \\bar{u}_i \\right|$。\n- 曲率能量 $E(u^\\star)$ 的定义。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是 $[b, d, E]$ 形式的列表。因此，最后一行必须看起来像 $[\\,[b_A, d_A, E_A], [b_B, d_B, E_B], [b_C, d_C, E_C], [b_D, d_D, E_D]\\,]$，并替换为指定的值。",
            "solution": "用户提出了一个来自多尺度建模领域的有效问题，具体涉及无方程方法和粗粒化方法。任务是实现并测试一对算子：一个将细尺度场粗粒化的**限制（restriction）**算子，以及一个从粗粒度数据重构细尺度场的**提升（lifting）**算子。\n\n该问题是一个适定的约束优化问题。核心任务是找到一个细粒度场 $u^\\star \\in \\mathbb{R}^N$，它能在满足一组由给定块平均施加的线性约束的同时，最小化一个“曲率能量”泛函 $E(u)$。这种方法论在各种科学计算环境中用于耦合不同尺度的模型，是标准做法。\n\n在此，我将详细说明解决此问题的数学表述和后续的算法方法。\n\n### 1. 数学表述\n\n设微观场为一个向量 $u \\in \\mathbb{R}^N$。问题要求解以下约束最小化问题：\n$$\n\\text{minimize} \\quad E(u) = \\sum_{j=0}^{N-1} \\left((\\Delta u)_j\\right)^2 \\quad \\text{subject to} \\quad \\sum_{j \\in B_i} u_j = m \\bar{u}_i, \\quad \\text{for } i=0, \\ldots, K-1.\n$$\n这里，$\\Delta$ 是离散周期性拉普拉斯算子，$B_i$ 是粗粒化块。\n\n这个问题可以用矩阵-向量表示法优雅地表达。\n目标函数是一个二次型：\n$$\nE(u) = \\|L u\\|_2^2 = u^T L^T L u\n$$\n其中 $L$ 是表示离散周期性拉普拉斯算子 $\\Delta$ 的 $N \\times N$ 矩阵。对于一维周期性晶格，这是一个对称循环矩阵，主对角线上为-2，两条相邻对角线上为1（由于周期性，角上也有）。由于 $L$ 是对称的，$L^T=L$，目标函数变为 $u^T L^2 u$。矩阵 $L^2$ 代表离散双调和算子 $\\Delta^2$。\n\n约束是一组 $K$ 个线性方程。我们可以定义一个 $K \\times N$ 的“求和”矩阵 $C$，其中如果格点 $j$ 在块 $B_i$ 中，则 $C_{ij} = 1$，否则 $C_{ij}=0$。约束则由以下系统给出：\n$$\nC u = m \\bar{u}\n$$\n其中 $\\bar{u} \\in \\mathbb{R}^K$ 是给定的粗粒化平均值向量。\n\n### 2. 拉格朗日乘子法\n\n这个约束二次规划问题可以使用拉格朗日乘子法求解。我们引入一个拉格朗日乘子向量 $\\lambda \\in \\mathbb{R}^K$ 并构造拉格朗日函数：\n$$\n\\mathcal{L}(u, \\lambda) = u^T L^2 u - \\lambda^T (C u - m \\bar{u})\n$$\n为了找到最小值，我们通过将其关于 $u$ 和 $\\lambda$ 的梯度置零来寻求 $\\mathcal{L}$ 的驻点。\n\n关于 $u$ 的梯度是：\n$$\n\\nabla_u \\mathcal{L} = 2 L^2 u - C^T \\lambda = 0\n$$\n关于 $\\lambda$ 的梯度恢复了约束条件：\n$$\n\\nabla_\\lambda \\mathcal{L} = -(C u - m \\bar{u}) = 0 \\implies C u = m \\bar{u}\n$$\n\n### 3. Karush-Kuhn-Tucker (KKT) 系统\n\n这两个方程构成一个单一、更大的线性系统，称为 Karush-Kuhn-Tucker (KKT) 系统。以分块矩阵形式，它是：\n$$\n\\begin{pmatrix}\n2 L^2  -C^T \\\\\nC  0_{K \\times K}\n\\end{pmatrix}\n\\begin{pmatrix}\nu^\\star \\\\\n\\lambda\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0_{N \\times 1} \\\\\nm\\bar{u}\n\\end{pmatrix}\n$$\n其中 $u^\\star$ 是我们寻求的最优提升场。这是一个大小为 $(N+K) \\times (N+K)$ 的稀疏、对称不定线性系统。只要约束能恰当地移除目标函数的海森矩阵（$L^2$）的零空间，KKT 矩阵就是可逆的。$L^2$ 的零空间是常数场，而约束 $C u = m \\bar{u}$ 通常与常数 $u$ 不相容，除非所有 $\\bar{u}_i$ 都相等，从而确保解的唯一性。\n\n### 4. 算法实现\n\n对于每个测试用例，求解过程如下：\n1.  **初始化**：给定参数 $N$ 和 $m$，计算 $K = N/m$。根据提供的公式构造初始细尺度场 $u \\in \\mathbb{R}^N$。\n\n2.  **限制**：通过块平均计算粗尺度场 $\\bar{u} \\in \\mathbb{R}^K$。一种数值上高效的实现方法是将 $N$ 元素向量 $u$ 重塑为一个 $K \\times m$ 的矩阵，然后计算每行的平均值。\n\n3.  **提升构造**：构造矩阵 $L$ 和 $C$。矩阵 $L$ 是一个大小为 $N \\times N$ 的循环矩阵。矩阵 $C$ 是一个大小为 $K \\times N$ 的稀疏矩阵。KKT 系统由这些构件（$L^2$、$C$、$C^T$）组装而成，并使用计算出的 $\\bar{u}$ 构成右侧向量。\n\n4.  **提升求解**：求解 $(N+K) \\times (N+K)$ 的 KKT 线性系统，得到包含 $u^\\star$ 和 $\\lambda$ 的复合向量。解向量的前 $N$ 个分量构成了所需的提升场 $u^\\star \\in \\mathbb{R}^N$。\n\n5.  **验证与分析**：\n    *   为验证一致性，将限制算子应用于计算出的提升场 $u^\\star$，得到新的粗粒度场 $\\bar{u}^\\star$。计算最大绝对偏差 $d = \\max_i |\\bar{u}^\\star_i - \\bar{u}_i|$。\n    *   如果 $d \\le \\varepsilon = 10^{-10}$，则一致性布尔值 $b$ 为真。\n    *   计算提升场的曲率能量 $E(u^\\star) = \\| L u^\\star \\|_2^2$。\n\n此过程基于约束优化的基本原理，用于为每个指定的测试用例确定所需的输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and tests restriction and lifting operators for a 1D periodic lattice.\n    The lifting operator is found by solving a constrained minimization problem\n    to find the smoothest field consistent with given coarse-grain averages.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'N': 128, 'm': 8, 'u_func': 'trig_linear', 'params': (3, 7, 0.25, 0.05)},\n        {'N': 64,  'm': 1, 'u_func': 'trig', 'params': (5,)},\n        {'N': 96,  'm': 24, 'u_func': 'trig_cosine', 'params': (10, 12, 0.1)},\n        {'N': 72,  'm': 9, 'u_func': 'piecewise', 'params': None}\n    ]\n\n    epsilon = 1e-10\n    results = []\n\n    for case in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        N = case['N']\n        m = case['m']\n        K = N // m\n        \n        # Generate the initial fine-grained field u\n        j = np.arange(N)\n        u_func = case['u_func']\n        params = case['params']\n        \n        if u_func == 'trig_linear':\n            k1, k2, c2, c3 = params\n            u = np.sin(2 * np.pi * k1 * j / N) + c2 * np.cos(2 * np.pi * k2 * j / N) + c3 * j / N\n        elif u_func == 'trig':\n            k1, = params\n            u = np.sin(2 * np.pi * k1 * j / N)\n        elif u_func == 'trig_cosine':\n            k1, k2, c2 = params\n            u = np.sin(2 * np.pi * k1 * j / N) + c2 * np.cos(2 * np.pi * k2 * j / N)\n        elif u_func == 'piecewise':\n            u = np.zeros(N)\n            n_third = N // 3\n            u[0:n_third] = 1.0\n            u[n_third : 2 * n_third] = -0.5\n            u[2 * n_third : N] = 0.0\n\n        # 1. Restriction: Compute coarse field ubar by block averaging\n        ubar = u.reshape((K, m)).mean(axis=1)\n\n        # 2. Lifting: Solve the constrained minimization problem via KKT system\n        \n        # Construct L, the N x N matrix for the periodic discrete Laplacian (Delta)\n        L = -2 * np.eye(N) + np.roll(np.eye(N), 1, axis=1) + np.roll(np.eye(N), -1, axis=1)\n        \n        # Construct L2, the N x N matrix for the biharmonic operator (Delta^2)\n        L2 = L @ L\n        \n        # Construct C, the K x N constraint matrix for block summation\n        C = np.zeros((K, N))\n        for i in range(K):\n            C[i, i*m:(i+1)*m] = 1.0\n        \n        # Assemble the (N+K) x (N+K) KKT matrix A and right-hand side vector b_vec\n        A_top = np.hstack([2 * L2, -C.T])\n        A_bot = np.hstack([C, np.zeros((K, K))])\n        A = np.vstack([A_top, A_bot])\n        \n        b_vec = np.concatenate([np.zeros(N), m * ubar])\n        \n        # Solve the linear system A * x = b_vec for x = [u_star, lambda]^T\n        x = np.linalg.solve(A, b_vec)\n        u_star = x[:N]\n\n        # 3. Verify consistency\n        # Restrict the lifted field u_star to get ubar_star\n        ubar_star = u_star.reshape((K, m)).mean(axis=1)\n        \n        # Compute the maximum absolute discrepancy d\n        d = np.max(np.abs(ubar_star - ubar))\n        \n        # Check if the discrepancy is within the tolerance epsilon\n        b_consistency = d = epsilon\n        \n        # 4. Calculate curvature energy E(u_star)\n        delta_u_star = L @ u_star\n        E = np.sum(delta_u_star**2)\n\n        results.append([bool(b_consistency), d, E])\n\n    # Final print statement in the exact required format.\n    formatted_results = ','.join(map(str, results))\n    print(f\"[{formatted_results}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "掌握了在不同尺度间转换信息的能力后，我们便可以构建一个“粗粒度时间步进器”（coarse time-stepper），在宏观层面模拟系统演化，而无需推导显式的粗粒度方程。然而，从粗粒度变量“提升”到微观状态时，我们通常无法完美地将系统置于其慢流形（slow manifold）上。本练习将通过一个计算实验，让你深入探究“愈合时间”（healing time）这一关键概念，理解它如何修正初始提升不一致性所带来的误差，并确保粗粒度预测的准确性。",
            "id": "4121758",
            "problem": "您的任务是实现一个无方程粗粒化计算实验，以分离愈合时间参数 $ \\tau_h $ 对粗粒度预测的影响。考虑一个具有两个时间尺度的无量纲确定性微观模型，由以下常微分方程（ODE）系统定义\n$$\n\\frac{dx}{dt} = -x + 0.5\\,y,\\quad\n\\frac{dy}{dt} = \\frac{1}{\\varepsilon}\\left(-y + x^2\\right),\n$$\n其中 $ x $ 是一个慢变量，$ y $ 是一个快变量，$ \\varepsilon $ 是一个控制时间尺度分离的小的正参数。所有量均为无量纲。无方程（EF）粗粒化的目的是为粗粒度变量 $ U = x $ 近似一个粗粒度时间步进器 $ M_{\\Delta t} $，而无需推导闭合形式的粗粒度方程。带有愈合时间的 EF 粗粒度时间步进器定义为\n$$\nM_{\\Delta t}^{(\\tau_h)}(U) \\equiv \\left(R \\circ S_{\\tau_h+\\Delta t} \\circ L\\right)(U),\n$$\n其中 $ L $（提升）通过选择 $ x = U $ 和 $ y = y_{\\text{lift}} $ 将 $ U $ 映射到微观状态，其中 $ y_{\\text{lift}} $ 在下面指定；$ S_t $ 是将 ODE 推进时间 $ t $ 的微观模拟器；$ R(x,y) = x $ 是限制操作。愈合时间 $ \\tau_h $ 是快变量向慢流形弛豫的时间间隔，用于在粗粒度报告时域 $ \\Delta t $ 之前减轻提升不一致性。\n\n使用以下规范实现 EF 粗粒度时间步进器：\n- 对所有提升操作使用 $ y_{\\text{lift}} = 0 $，以故意引入与慢流形 $ y \\approx x^2 $ 的初始不一致性，从而揭示 $ \\tau_h $ 的作用。\n- 使用四阶定步长显式龙格-库塔方法（经典 RK4）确定性地积分微观 ODE。使用时间步长 $ h = \\min\\{0.001,\\; 0.05\\,\\varepsilon\\} $。\n- 定义参考愈合时间 $ \\tau_{\\text{ref}} = 5.0 $，并通过绝对差来衡量粗粒度预测的敏感性\n$$\nD(U_0,\\Delta t,\\varepsilon,\\tau_h) = \\left|M_{\\Delta t}^{(\\tau_h)}(U_0) - M_{\\Delta t}^{(\\tau_{\\text{ref}})}(U_0)\\right|.\n$$\n\n您的程序必须为以下测试套件中的每个受控测试用例，计算其指定列表中每个 $ \\tau_h $ 对应的 $ D(U_0,\\Delta t,\\varepsilon,\\tau_h) $ 值。每个测试用例指定了 $ (U_0,\\Delta t,\\varepsilon) $ 和一个 $ \\tau_h $ 值列表：\n- 测试用例 $ 1 $（理想路径，强分离）：$ U_0 = 0.7 $，$ \\Delta t = 1.0 $，$ \\varepsilon = 0.05 $，$ \\tau_h \\in \\{0.0, 0.1, 0.5, 1.0\\} $。\n- 测试用例 $ 2 $（边界情况：愈合时间等于报告时间）：$ U_0 = 0.2 $，$ \\Delta t = 0.2 $，$ \\varepsilon = 0.05 $，$ \\tau_h \\in \\{0.0, 0.2\\} $。\n- 测试用例 $ 3 $（较弱分离）：$ U_0 = -0.5 $，$ \\Delta t = 1.0 $，$ \\varepsilon = 0.3 $，$ \\tau_h \\in \\{0.0, 0.5, 1.0\\} $。\n- 测试用例 $ 4 $（小报告时域）：$ U_0 = 1.0 $，$ \\Delta t = 0.01 $，$ \\varepsilon = 0.05 $，$ \\tau_h \\in \\{0.0, 0.01, 0.1\\} $。\n- 测试用例 $ 5 $（长报告时域）：$ U_0 = 0.0 $，$ \\Delta t = 2.0 $，$ \\varepsilon = 0.05 $，$ \\tau_h \\in \\{0.0, 0.5, 1.0, 2.0\\} $。\n\n所有量均为无量纲。您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。列表中的每个元素对应一个测试用例，其本身是一个浮点数（绝对差）列表，顺序与所列的 $ \\tau_h $ 值相同。例如，输出格式必须为 $ [[d_{1,1},d_{1,2},\\dots],[d_{2,1},\\dots],\\dots] $ 的形式，不得包含其他文本。每个 $ d_{i,j} $ 必须是一个浮点数。",
            "solution": "该问题是有效的，因为它在科学上是合理的、良构的，并为多尺度建模领域的标准计算练习提供了一套完整、无歧义的规范。\n\n其目标是实现一个无方程（EF）粗粒化模拟，以分析愈合时间参数 $\\tau_h$ 对粗粒度预测准确性的影响。这是通过测量使用给定 $\\tau_h$ 所做预测与使用一个长的、推测上足够的愈合时间 $\\tau_{\\text{ref}}$ 所做参考预测之间的偏差来实现的。\n\n问题的核心是一个由两个耦合常微分方程（ODE）系统描述的微观模型：\n$$\n\\frac{dx}{dt} = -x + 0.5\\,y \\\\\n\\frac{dy}{dt} = \\frac{1}{\\varepsilon}\\left(-y + x^2\\right)\n$$\n这里，$x(t)$ 是慢变量，$y(t)$ 是快变量。参数 $\\varepsilon \\ll 1$ 控制着时间尺度的分离。$1/\\varepsilon$ 项导致 $y$ 的演化速度远快于 $x$。对于很小的 $\\varepsilon$，快变量 $y$ 会迅速弛豫到由慢变量 $x$ 决定的准稳态。通过设置 $dy/dt \\approx 0$，我们发现系统的动力学被吸引到一个慢流形上，这是状态空间中的一个不变或近不变的低维曲面，近似由关系式 $y \\approx x^2$ 描述。\n\n无方程（EF）方法提供了一种模拟粗粒度变量（此处为 $U=x$）演化的方法，而无需推导其动力学的显式闭合方程。其演化由一个粗粒度时间步进器 $M_{\\Delta t}$ 捕获，该步进器将粗粒度状态推进一个时间步长 $\\Delta t$。问题定义了该算子的一种包含愈合时间 $\\tau_h$ 的特定形式：\n$$\nM_{\\Delta t}^{(\\tau_h)}(U) \\equiv \\left(R \\circ S_{\\tau_h+\\Delta t} \\circ L\\right)(U)\n$$\n这个复合算子分三个阶段工作：\n\n1.  **提升 ($L$)：** 将粗粒度状态 $U_0$ 映射到完整的微观状态 $(x_0, y_0)$。问题指定的提升规则为 $L(U_0) = (x_0, y_0) = (U_0, 0)$。这个选择是故意“不一致”的，因为对于一个泛型 $U_0 \\neq 0$，提升点 $(U_0, 0)$ 并不在慢流形 $y \\approx x^2$ 上。这种不一致性引入了一个初始瞬态误差。\n\n2.  **模拟 ($S_t$)：** 从提升的初始条件 $(x_0, y_0)$ 开始，在时间上向前数值积分微观 ODE 系统，总时长为 $t = \\tau_h + \\Delta t$。此模拟的初始阶段，即持续时间为 $\\tau_h$ 的阶段，是“愈合”期。在此期间，快变量 $y$ 从其不一致的初始值（$y_0=0$）迅速收敛到慢流形。愈合之后，在“报告时域” $\\Delta t$ 上的后续演化被假定为代表真实的粗粒度动力学。\n\n3.  **限制 ($R$)：** 在总模拟时间结束后，将得到的微观状态 $(x_f, y_f)$ 映射回一个粗粒度状态。问题指定的限制算子为 $R(x, y) = x$。因此，新的粗粒度状态就是模拟结束时慢变量的值，$U_f = x_f$。\n\n微观 ODE 的数值积分必须使用经典的四阶龙格-库塔（RK4）方法，并采用固定时间步长 $h = \\min\\{0.001, 0.05\\,\\varepsilon\\}$。对于一个向量形式的 ODE 系统 $\\frac{d\\vec{z}}{dt} = \\vec{f}(t, \\vec{z})$，其中 $\\vec{z} = [x, y]^T$，从时间步 $n$ 到 $n+1$ 的 RK4 更新为：\n$$\n\\vec{z}_{n+1} = \\vec{z}_n + \\frac{h}{6}(\\vec{k}_1 + 2\\vec{k}_2 + 2\\vec{k}_3 + \\vec{k}_4)\n$$\n其中中间斜率计算如下：\n$$\n\\vec{k}_1 = \\vec{f}(t_n, \\vec{z}_n) \\\\\n\\vec{k}_2 = \\vec{f}(t_n + h/2, \\vec{z}_n + h/2 \\cdot \\vec{k}_1) \\\\\n\\vec{k}_3 = \\vec{f}(t_n + h/2, \\vec{z}_n + h/2 \\cdot \\vec{k}_2) \\\\\n\\vec{k}_4 = \\vec{f}(t_n + h, \\vec{z}_n + h \\cdot \\vec{k}_3)\n$$\n对于总模拟时长 $T = \\tau_h + \\Delta t$，总积分步数 $N$ 必须足以覆盖此周期，即 $N = \\lceil T/h \\rceil$。\n\n粗粒度预测对 $\\tau_h$ 选择的敏感性由绝对差 $D$ 来量化：\n$$\nD(U_0,\\Delta t,\\varepsilon,\\tau_h) = \\left|M_{\\Delta t}^{(\\tau_h)}(U_0) - M_{\\Delta t}^{(\\tau_{\\text{ref}})}(U_0)\\right|\n$$\n其中 $\\tau_{\\text{ref}} = 5.0$ 是一个参考愈合时间，假定其足够长以使初始瞬态完全消散。对于每个由 $(U_0, \\Delta t, \\varepsilon)$ 定义的测试用例，我们首先计算参考结果 $U_{\\text{ref}} = M_{\\Delta t}^{(\\tau_{\\text{ref}})}(U_0)$。然后，对于指定列表中的每个 $\\tau_h$，我们计算测试结果 $U_{\\text{test}} = M_{\\Delta t}^{(\\tau_h)}(U_0)$，并计算差值 $|U_{\\text{test}} - U_{\\text{ref}}|$。每个测试用例的这些差值的集合构成了最终结果。",
            "answer": "```python\nimport numpy as np\n# scipy is not used as the problem requires a custom RK4 implementation.\n\ndef get_derivatives(state, epsilon):\n    \"\"\"\n    Computes the derivatives for the microscopic ODE system.\n\n    Args:\n        state (np.ndarray): A 1D array [x, y] representing the current state.\n        epsilon (float): The time-scale separation parameter.\n\n    Returns:\n        np.ndarray: A 1D array [dx/dt, dy/dt].\n    \"\"\"\n    x, y = state\n    dx_dt = -x + 0.5 * y\n    dy_dt = (1.0 / epsilon) * (-y + x**2)\n    return np.array([dx_dt, dy_dt])\n\ndef rk4_step(state, h, epsilon):\n    \"\"\"\n    Performs a single step of the classical Runge-Kutta 4th order method.\n\n    Args:\n        state (np.ndarray): The current state vector [x, y].\n        h (float): The time step size.\n        epsilon (float): The time-scale separation parameter.\n\n    Returns:\n        np.ndarray: The state vector [x, y] at the next time step.\n    \"\"\"\n    k1 = get_derivatives(state, epsilon)\n    k2 = get_derivatives(state + 0.5 * h * k1, epsilon)\n    k3 = get_derivatives(state + 0.5 * h * k2, epsilon)\n    k4 = get_derivatives(state + h * k3, epsilon)\n    return state + (h / 6.0) * (k1 + 2.0 * k2 + 2.0 * k3 + k4)\n\ndef coarse_stepper(U0, delta_t, tau_h, epsilon):\n    \"\"\"\n    Implements the Equation-Free coarse time-stepper M.\n\n    Args:\n        U0 (float): The initial coarse state.\n        delta_t (float): The coarse reporting horizon.\n        tau_h (float): The healing time.\n        epsilon (float): The time-scale separation parameter.\n\n    Returns:\n        float: The coarse state after one coarse time step.\n    \"\"\"\n    # Lifting: Map coarse state U0 to a microscopic state (x, y)\n    state = np.array([U0, 0.0])\n\n    # Simulation: Integrate the microscopic ODEs\n    # Determine the microscopic time step\n    h = min(0.001, 0.05 * epsilon)\n    \n    # Determine total simulation time and number of steps\n    total_time = tau_h + delta_t\n    if total_time == 0:\n        return U0\n\n    num_steps = int(np.ceil(total_time / h))\n\n    # Run the microscopic simulation\n    for _ in range(num_steps):\n        state = rk4_step(state, h, epsilon)\n\n    # Restriction: Return the slow variable x\n    return state[0]\n\ndef solve():\n    \"\"\"\n    Runs the full computational experiment for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (U0, delta_t, epsilon, list_of_tau_h)\n        (0.7, 1.0, 0.05, [0.0, 0.1, 0.5, 1.0]),\n        (0.2, 0.2, 0.05, [0.0, 0.2]),\n        (-0.5, 1.0, 0.3, [0.0, 0.5, 1.0]),\n        (1.0, 0.01, 0.05, [0.0, 0.01, 0.1]),\n        (0.0, 2.0, 0.05, [0.0, 0.5, 1.0, 2.0]),\n    ]\n    \n    tau_ref = 5.0\n    all_results = []\n\n    for U0, delta_t, epsilon, tau_h_list in test_cases:\n        # Calculate the reference coarse prediction using tau_ref\n        U_ref = coarse_stepper(U0, delta_t, tau_ref, epsilon)\n        \n        case_results = []\n        for tau_h in tau_h_list:\n            # Calculate the test coarse prediction\n            U_test = coarse_stepper(U0, delta_t, tau_h, epsilon)\n            \n            # Compute the absolute difference\n            diff = abs(U_test - U_ref)\n            case_results.append(diff)\n            \n        all_results.append(case_results)\n\n    # Format the final output string as a list of lists of floats.\n    inner_strings = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output_string = f\"[{','.join(inner_strings)}]\"\n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "简单的粗粒度时间步进器虽然实用，但其背后隐含了一个强假设：粗粒度动力学是马尔可夫的，即系统的未来只依赖于当前状态。然而，由于忽略了大量快速变化的微观自由度，真实的粗粒度动力学往往具有“记忆效应”。本练习将引导你分析这种记忆效应对系统稳定性和分岔预测的影响，并量化忽略记忆所引入的系统性偏差，从而更深刻地理解无方程方法背后的理论基础与潜在挑战。",
            "id": "4121738",
            "problem": "考虑一个粗粒度变量 $x(t)$，它是在无方程 (EF) 方法中对更高维微观描述的限制。在存在未解析的自由度时，精确的粗粒度动力学是非马尔可夫的，并且可以用一个带有记忆核的线性广义朗之万方程 (GLE) 来表示。假设以下线性沃尔泰拉积分微分方程描述了粗粒度动力学：\n$$\n\\frac{dx}{dt} = \\mu\\, x(t) + \\int_{0}^{\\infty} K(s)\\, x(t - s)\\, ds,\n$$\n其中控制参数为 $ \\mu \\in \\mathbb{R} $，记忆核为指数型，\n$$\nK(s) = \\kappa\\, e^{-s/\\tau},\n$$\n其中 $ \\kappa \\in \\mathbb{R} $ 且 $ \\tau  0 $。通过引入一个辅助变量，可以将此记忆核嵌入到一个有限维马尔可夫系统中\n$$\ny(t) = \\int_{0}^{\\infty} e^{-s/\\tau}\\, x(t - s)\\, ds,\n$$\n该变量满足\n$$\n\\frac{dy}{dt} = \\frac{1}{\\tau}\\left(x(t) - y(t)\\right),\n$$\n并得到二维线性系统\n$$\n\\frac{d}{dt}\\begin{bmatrix} x \\\\ y \\end{bmatrix} = \n\\begin{bmatrix}\n\\mu  \\kappa \\\\\n\\frac{1}{\\tau}  -\\frac{1}{\\tau}\n\\end{bmatrix}\n\\begin{bmatrix} x \\\\ y \\end{bmatrix}.\n$$\n令该矩阵记为 $A(\\mu,\\kappa,\\tau)$。\n\n在 EF 粗粒度时间步进器中，一个提升算子从粗粒度变量值构造一个一致的微观状态。为模拟对记忆的忽略，假设每当从 $x(0)$ 初始化时，提升算子都设置 $y(0)=0$。对于持续时间为 $\\Delta t0$ 的短时脉冲模拟，定义由该二维线性系统计算的粗粒度映射 $x(0) \\mapsto x(\\Delta t)$，并通过有限差分估计量来估计马尔可夫粗粒度增长率\n$$\n\\hat{\\lambda}(\\Delta t) = \\frac{x(\\Delta t)-x(0)}{\\Delta t\\, x(0)},\n$$\n其中采用固定的提升 $x(0)=1$ 和 $y(0)=0$。\n\n基于这些基础，完成以下分析和计算任务：\n\n1. 计算 $A(\\mu,\\kappa,\\tau)$ 的主导（最大实部）特征值 $\\lambda_{\\text{true}}$，它在存在记忆的情况下控制着粗粒度稳定性。\n2. 将忽略记忆的朴素马尔可夫预测定义为 $\\lambda_{\\text{naive}}=\\mu$，朴素临界阈值定义为 $\\mu_{c,\\text{naive}}=0$（即马尔可夫模型 $\\frac{dx}{dt}=\\mu x$ 改变稳定性的值）。\n3. 推导真实临界阈值 $\\mu_{c,\\text{true}}$，在该阈值处 $A(\\mu,\\kappa,\\tau)$ 的一个特征值穿过零点，并对给定参数进行数值计算。\n4. 量化以下偏差：\n   - 由忽略记忆引起的特征值偏差：$\\Delta\\lambda = \\lambda_{\\text{true}} - \\lambda_{\\text{naive}}$。\n   - 由忽略记忆引起的临界阈值偏差：$\\Delta\\mu_c = \\mu_{c,\\text{true}} - \\mu_{c,\\text{naive}}$。\n   - 相对于真实主导特征值的 EF 短时脉冲估计量偏差：$\\Delta\\lambda_{\\text{EF}} = \\hat{\\lambda}(\\Delta t) - \\lambda_{\\text{true}}$。\n所有量都必须作为实数计算。\n\n您的程序必须对下面的测试套件精确地实现这些计算，所有计算都使用线性二维嵌入动力学进行。对于每个测试用例，EF 短时脉冲估计量使用 $x(0)=1$ 和 $y(0)=0$。不需要物理单位。所有角度（如果出现）都应以弧度为单位；然而，此问题中没有角度。\n\n测试套件（每个测试用例是一个元组 $(\\mu,\\kappa,\\tau,\\Delta t)$）：\n- 案例1（相对于朴素稳定性，记忆具有去稳定作用的常规路径）：$(-0.05,\\,0.10,\\,2.0,\\,0.5)$。\n- 案例2（相对于朴素不稳定性，记忆具有稳定作用的常规路径）：$(0.05,\\,-0.20,\\,1.0,\\,0.5)$。\n- 案例3（无记忆的边界情况）：$(-0.10,\\,0.0,\\,1.0,\\,0.5)$。\n- 案例4（长记忆，弱耦合）：$(-0.10,\\,0.09,\\,10.0,\\,1.0)$。\n- 案例5（小 $\\Delta t$ 的边缘情况）：$(0.15,\\,0.10,\\,0.2,\\,0.05)$。\n- 案例6（大 $\\Delta t$ 的边缘情况）：$(-0.01,\\,0.02,\\,5.0,\\,2.0)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的列表。每个测试用例的结果必须是包含三个浮点数的列表 $[\\Delta\\lambda,\\,\\Delta\\mu_c,\\,\\Delta\\lambda_{\\text{EF}}]$，因此最终输出是根据测试用例顺序排列的列表的列表，例如：\n$$\n\\big[[\\Delta\\lambda_1,\\,\\Delta\\mu_{c,1},\\,\\Delta\\lambda_{\\text{EF},1}],\\dots,[\\Delta\\lambda_6,\\,\\Delta\\mu_{c,6},\\,\\Delta\\lambda_{\\text{EF},6}]\\big].\n$$",
            "solution": "出发点是认识到，从未解析的微观变量中推导出的粗粒度动力学是非马尔可夫的。Mori–Zwanzig (MZ) 投影算子形式理论和广义朗之万方程 (GLE) 为这类记忆效应提供了系统性基础。对于指数型记忆核 $K(s)=\\kappa e^{-s/\\tau}$，非局域项可以由一个辅助变量表示，从而得到一个有限维的马尔可夫嵌入。具体来说，定义\n$$\ny(t)=\\int_0^\\infty e^{-s/\\tau}\\, x(t-s)\\, ds,\n$$\n其满足\n$$\n\\frac{dy}{dt} = \\frac{1}{\\tau}\\left(x(t)-y(t)\\right).\n$$\n将此代入动力学方程，得到线性系统\n$$\n\\frac{d}{dt}\\begin{bmatrix}x\\\\y\\end{bmatrix} = \n\\begin{bmatrix}\n\\mu  \\kappa \\\\\n\\frac{1}{\\tau}  -\\frac{1}{\\tau}\n\\end{bmatrix}\n\\begin{bmatrix}x\\\\y\\end{bmatrix} \\equiv A(\\mu,\\kappa,\\tau)\\begin{bmatrix}x\\\\y\\end{bmatrix}.\n$$\n该系统是原始带有指数记忆核的 GLE 的一个数学上一致的表示。\n\n粗粒度稳定性由 $A(\\mu,\\kappa,\\tau)$ 的特征值决定。主导（最大实部）特征值，记为 $\\lambda_{\\text{true}}$，在 $y(t)$ 是嵌入动力学一部分时，控制着 $x(t)$ 的长时间行为。相反，忽略记忆对应于朴素马尔可夫模型\n$$\n\\frac{dx}{dt} = \\mu\\, x(t),\n$$\n其特征值就是 $\\lambda_{\\text{naive}}=\\mu$，稳定性阈值为 $\\mu_{c,\\text{naive}}=0$。\n\n为推导真实临界阈值 $\\mu_{c,\\text{true}}$，考虑 $A$ 的特征多项式：\n$$\np(\\lambda) = \\det\\left(\\lambda I - A\\right) = \\lambda^2 - \\left(\\mu - \\frac{1}{\\tau}\\right)\\lambda - \\frac{\\mu+\\kappa}{\\tau}.\n$$\n当 $\\lambda=0$ 是一个特征值时，会通过实特征值穿越零点而丧失稳定性，这要求\n$$\np(0) = -\\frac{\\mu+\\kappa}{\\tau} = 0 \\quad \\Rightarrow \\quad \\mu + \\kappa = 0.\n$$\n因此，真实临界阈值为\n$$\n\\mu_{c,\\text{true}} = -\\kappa,\n$$\n在此嵌入中与 $\\tau$ 无关。这立即可量化因忽略记忆而产生的阈值偏差\n$$\n\\Delta\\mu_c = \\mu_{c,\\text{true}} - \\mu_{c,\\text{naive}} = -\\kappa - 0 = -\\kappa.\n$$\n\n特征值偏差 $\\Delta\\lambda$ 定义为\n$$\n\\Delta\\lambda = \\lambda_{\\text{true}} - \\lambda_{\\text{naive}} = \\lambda_{\\text{true}} - \\mu,\n$$\n其中 $\\lambda_{\\text{true}}$ 是通过数值计算得出的 $A(\\mu,\\kappa,\\tau)$ 的主导特征值。\n\n为了与无方程 (EF) 粗粒度时间步进器联系起来，我们指定一个忽略记忆的提升方法，即通过将辅助变量初始值设为零：\n$$\nx(0)=1,\\quad y(0)=0.\n$$\n将嵌入的动力学在一个持续时间为 $\\Delta t0$ 的短时脉冲内演化，得到\n$$\n\\begin{bmatrix}x(\\Delta t)\\\\y(\\Delta t)\\end{bmatrix} = e^{A\\Delta t}\\begin{bmatrix}1\\\\0\\end{bmatrix},\n$$\n其中 $e^{A\\Delta t}$ 是矩阵指数。于是，对于马尔可夫粗粒度增长率的 EF 短时脉冲估计量为\n$$\n\\hat{\\lambda}(\\Delta t) = \\frac{x(\\Delta t)-x(0)}{\\Delta t\\, x(0)} = \\frac{x(\\Delta t)-1}{\\Delta t}.\n$$\n该估计量混合了瞬时漂移 $\\mu$ 和记忆 $y(t)$ 的瞬态累积，因此相对于真实主导特征值存在偏差。EF 估计量偏差为\n$$\n\\Delta\\lambda_{\\text{EF}} = \\hat{\\lambda}(\\Delta t) - \\lambda_{\\text{true}}.\n$$\n\n对每个测试用例 $(\\mu,\\kappa,\\tau,\\Delta t)$ 的算法步骤：\n1. 构建矩阵\n$$\nA = \\begin{bmatrix}\n\\mu  \\kappa \\\\\n\\frac{1}{\\tau}  -\\frac{1}{\\tau}\n\\end{bmatrix}.\n$$\n2. 计算 $A$ 的特征值，并将 $\\lambda_{\\text{true}}$ 设为具有最大实部的特征值。\n3. 设置 $\\lambda_{\\text{naive}}=\\mu$ 和 $\\mu_{c,\\text{naive}}=0$。\n4. 计算真实阈值 $\\mu_{c,\\text{true}}=-\\kappa$，得到 $\\Delta\\mu_c=-\\kappa$。\n5. 计算 $e^{A\\Delta t}$，然后从 $[x(\\Delta t),y(\\Delta t)]^\\top = e^{A\\Delta t}[1,0]^\\top$ 计算出 $x(\\Delta t)$。再计算 $\\hat{\\lambda}(\\Delta t) = (x(\\Delta t)-1)/\\Delta t$。\n6. 计算偏差：$\\Delta\\lambda = \\lambda_{\\text{true}} - \\mu$ 和 $\\Delta\\lambda_{\\text{EF}} = \\hat{\\lambda}(\\Delta t) - \\lambda_{\\text{true}}$。\n7. 汇总三个浮点数 $[\\Delta\\lambda,\\,\\Delta\\mu_c,\\,\\Delta\\lambda_{\\text{EF}}]$ 作为输出。\n\n针对整个测试套件的解释：\n- 案例1中 $\\mu0$ 但 $\\kappa0$，因此 $\\mu+\\kappa0$，预计真实主导特征值为正（不稳定），表明忽略记忆可以推翻稳定性结论。\n- 案例2中 $\\mu0$ 但 $\\kappa0$，使得 $\\mu+\\kappa0$；真实主导特征值可以为负（稳定），再次推翻朴素结论。\n- 案例3设置 $\\kappa=0$（无记忆），使得所有偏差均为零。\n- 案例4探究了长记忆（$\\tau$ 大）和弱耦合的情况，强调了当记忆缓慢建立时，EF 估计量对有限 $\\Delta t$ 的敏感性。\n- 案例5使用小 $\\Delta t$，此时 EF 估计量接近瞬时漂移，因此可能减小 $\\Delta\\lambda_{\\text{EF}}$。\n- 案例6使用大 $\\Delta t$，突显了 EF 估计量由于对瞬态记忆效应进行了平均，可能会有更大的偏差。\n\n程序将实现这些计算，并为给定的测试套件打印单行的嵌套列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef dominant_real_eigenvalue(A: np.ndarray) - float:\n    \"\"\"Return the eigenvalue of A with the largest real part.\"\"\"\n    eigvals = np.linalg.eigvals(A)\n    # Select by largest real part\n    real_parts = np.real(eigvals)\n    idx = np.argmax(real_parts)\n    return real_parts[idx]\n\ndef ef_short_burst_estimator(A: np.ndarray, dt: float) - float:\n    \"\"\"\n    Compute the EF short-burst estimator hat{lambda}(dt)\n    with lifting x(0)=1, y(0)=0 for the 2D linear system dx/dt = A @ [x;y].\n    \"\"\"\n    v0 = np.array([1.0, 0.0], dtype=float)\n    M = expm(A * dt)\n    x_dt = (M @ v0)[0]\n    hat_lambda = (x_dt - 1.0) / dt\n    return hat_lambda\n\ndef compute_biases(mu: float, kappa: float, tau: float, dt: float):\n    \"\"\"\n    Compute [Delta_lambda, Delta_mu_c, Delta_lambda_EF]\n    for parameters (mu, kappa, tau, dt).\n    \"\"\"\n    # Build the 2x2 system matrix A\n    A = np.array([[mu, kappa], [1.0 / tau, -1.0 / tau]], dtype=float)\n    # True dominant eigenvalue\n    lam_true = dominant_real_eigenvalue(A)\n    # Naive eigenvalue neglecting memory\n    lam_naive = mu\n    # True and naive thresholds\n    mu_c_true = -kappa\n    mu_c_naive = 0.0\n    # Biases\n    delta_lambda = lam_true - lam_naive\n    delta_mu_c = mu_c_true - mu_c_naive\n    # EF short-burst estimator bias relative to true dominant eigenvalue\n    hat_lambda = ef_short_burst_estimator(A, dt)\n    delta_lambda_EF = hat_lambda - lam_true\n    return [float(delta_lambda), float(delta_mu_c), float(delta_lambda_EF)]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (-0.05,  0.10, 2.0, 0.5),  # Case 1\n        ( 0.05, -0.20, 1.0, 0.5),  # Case 2\n        (-0.10,  0.00, 1.0, 0.5),  # Case 3\n        (-0.10,  0.09,10.0, 1.0),  # Case 4\n        ( 0.15,  0.10, 0.2, 0.05), # Case 5\n        (-0.01,  0.02, 5.0, 2.0),  # Case 6\n    ]\n\n    results = []\n    for mu, kappa, tau, dt in test_cases:\n        result = compute_biases(mu, kappa, tau, dt)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Print as a single line list of lists\n    def format_list_of_lists(lst):\n        inner = []\n        for sub in lst:\n            inner.append(\"[\" + \",\".join(f\"{x:.12g}\" for x in sub) + \"]\")\n        return \"[\" + \",\".join(inner) + \"]\"\n\n    print(format_list_of_lists(results))\n\nsolve()\n```"
        }
    ]
}