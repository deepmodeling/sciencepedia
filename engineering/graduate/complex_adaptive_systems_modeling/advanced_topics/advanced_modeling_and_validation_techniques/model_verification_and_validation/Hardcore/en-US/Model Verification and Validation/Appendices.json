{
    "hands_on_practices": [
        {
            "introduction": "A crucial step in model validation is understanding the sources of uncertainty. The law of total variance is a powerful tool for creating an \"uncertainty budget,\" allowing us to analytically partition the total output variance of a model into components from different sources. This practice  will guide you through a derivation to determine how much uncertainty in specific model parameters contributes to overall output uncertainty, a key skill for prioritizing validation and calibration efforts.",
            "id": "4127760",
            "problem": "Consider a complex adaptive system model with stochastic output $Y$ that depends on a vector of uncertain parameters $X = (X_{S}, X_{T})$, where $X_{S}$ is a subset of parameters selected for possible targeted validation and $X_{T}$ denotes the remaining parameters. Assume the following fundamental bases: the definition of variance $\\operatorname{Var}(Y) = \\mathbb{E}\\!\\left[(Y - \\mathbb{E}[Y])^{2}\\right]$, conditional expectation and variance $\\mathbb{E}[Y \\mid X_{S}]$ and $\\operatorname{Var}(Y \\mid X_{S})$, and the law of total variance $\\operatorname{Var}(Y) = \\mathbb{E}\\!\\left[\\operatorname{Var}(Y \\mid X_{S})\\right] + \\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)$.\n\nYou are provided a scientifically sound verification scenario: a large, converged ensemble of simulation runs yields an empirically stable estimate of the total output variance $\\operatorname{Var}(Y) = 4.50 \\times 10^{2}$. Independent validation experiments constrain the conditional variance across a calibrated credible set $\\mathcal{C}$ for $X_{S}$ with $\\mathbb{P}(X_{S} \\in \\mathcal{C}) = 1$, and establish that for every $x_{s} \\in \\mathcal{C}$, the conditional variance satisfies $v_{\\min} \\leq \\operatorname{Var}(Y \\mid X_{S} = x_{s}) \\leq v_{\\max}$ with $v_{\\min} = 1.40 \\times 10^{2}$ and $v_{\\max} = 2.20 \\times 10^{2}$.\n\nStarting only from these fundamental bases, derive rigorous lower and upper bounds on the variance contribution attributable to $X_{S}$, quantified by $\\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)$, and then express the corresponding bounds on the fractional contribution of $X_{S}$ to the total output variance, defined as\n$$F_{S} \\equiv \\frac{\\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)}{\\operatorname{Var}(Y)}.$$\nCompute the resulting two numerical bounds for $F_{S}$ using the given values, and round your results to four significant figures. Express the two bounds as a row matrix using the LaTeX $\\mathrm{pmatrix}$ environment. Finally, briefly interpret how these bounds inform targeted validation decisions for $X_{S}$ in terms of potential reduction of output uncertainty. The interpretation is part of your reasoning but is not part of the final answer output specification.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and contains all necessary information for a unique solution. The premises are based on the fundamental law of total variance, a standard theorem in probability theory, and the scenario described is a conventional application in the field of uncertainty quantification and model validation. Therefore, the problem is valid, and we proceed with its solution.\n\nOur starting point is the law of total variance, which decomposes the total variance of a random variable $Y$ based on a conditioning variable, in this case, the parameter vector subset $X_{S}$. The law is given as:\n$$\n\\operatorname{Var}(Y) = \\mathbb{E}\\!\\left[\\operatorname{Var}(Y \\mid X_{S})\\right] + \\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)\n$$\nThe term $\\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)$ represents the portion of the variance in the output $Y$ that is explained by the uncertainty in the parameters $X_{S}$. This is the quantity of interest. We can isolate it by rearranging the equation:\n$$\n\\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right) = \\operatorname{Var}(Y) - \\mathbb{E}\\!\\left[\\operatorname{Var}(Y \\mid X_{S})\\right]\n$$\nWe are given the total variance $\\operatorname{Var}(Y) = 4.50 \\times 10^{2}$. To find bounds on $\\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)$, we must first establish bounds for the term $\\mathbb{E}\\!\\left[\\operatorname{Var}(Y \\mid X_{S})\\right]$.\n\nThe problem states that independent validation experiments have established that for any realization $x_{s}$ of the random vector $X_{S}$ within its credible set $\\mathcal{C}$ (where $\\mathbb{P}(X_{S} \\in \\mathcal{C}) = 1$), the conditional variance $\\operatorname{Var}(Y \\mid X_{S} = x_{s})$ is bounded. The random variable $Z \\equiv \\operatorname{Var}(Y \\mid X_{S})$ thus satisfies the inequality:\n$$\nv_{\\min} \\leq Z \\leq v_{\\max}\n$$\nalmost surely. The values for these bounds are given as $v_{\\min} = 1.40 \\times 10^{2}$ and $v_{\\max} = 2.20 \\times 10^{2}$.\n\nThe expectation operator is monotone. If a random variable $A$ is bounded by constants $c_{1}$ and $c_{2}$ such that $\\mathbb{P}(c_{1} \\leq A \\leq c_{2}) = 1$, then its expectation is bounded by the same constants: $c_{1} \\leq \\mathbb{E}[A] \\leq c_{2}$. Applying this property to the random variable $Z = \\operatorname{Var}(Y \\mid X_{S})$, we obtain bounds on its expectation:\n$$\n\\mathbb{E}[v_{\\min}] \\leq \\mathbb{E}\\!\\left[\\operatorname{Var}(Y \\mid X_{S})\\right] \\leq \\mathbb{E}[v_{\\max}]\n$$\nSince $v_{\\min}$ and $v_{\\max}$ are constants, their expectations are simply their own values. Therefore:\n$$\nv_{\\min} \\leq \\mathbb{E}\\!\\left[\\operatorname{Var}(Y \\mid X_{S})\\right] \\leq v_{\\max}\n$$\nNow we can substitute these bounds back into our expression for $\\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)$.\nTo obtain the lower bound on $\\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)$, we must subtract the largest possible value of $\\mathbb{E}\\!\\left[\\operatorname{Var}(Y \\mid X_{S})\\right]$, which is $v_{\\max}$:\n$$\n\\left(\\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)\\right)_{\\min} = \\operatorname{Var}(Y) - v_{\\max}\n$$\nTo obtain the upper bound, we must subtract the smallest possible value of $\\mathbb{E}\\!\\left[\\operatorname{Var}(Y \\mid X_{S})\\right]$, which is $v_{\\min}$:\n$$\n\\left(\\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)\\right)_{\\max} = \\operatorname{Var}(Y) - v_{\\min}\n$$\nThis establishes the rigorous inequality for the variance contribution from $X_{S}$:\n$$\n\\operatorname{Var}(Y) - v_{\\max} \\leq \\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right) \\leq \\operatorname{Var}(Y) - v_{\\min}\n$$\nThe problem asks for bounds on the fractional contribution, $F_{S}$, defined as:\n$$\nF_{S} \\equiv \\frac{\\operatorname{Var}\\!\\left(\\mathbb{E}[Y \\mid X_{S}]\\right)}{\\operatorname{Var}(Y)}\n$$\nSince $\\operatorname{Var}(Y)$ is a positive constant, we can divide the entire inequality by it without changing the direction of the inequalities:\n$$\n\\frac{\\operatorname{Var}(Y) - v_{\\max}}{\\operatorname{Var}(Y)} \\leq F_{S} \\leq \\frac{\\operatorname{Var}(Y) - v_{\\min}}{\\operatorname{Var}(Y)}\n$$\nThis simplifies to:\n$$\n1 - \\frac{v_{\\max}}{\\operatorname{Var}(Y)} \\leq F_{S} \\leq 1 - \\frac{v_{\\min}}{\\operatorname{Var}(Y)}\n$$\nNow, we substitute the provided numerical values:\n$\\operatorname{Var}(Y) = 4.50 \\times 10^{2} = 450$\n$v_{\\min} = 1.40 \\times 10^{2} = 140$\n$v_{\\max} = 2.20 \\times 10^{2} = 220$\n\nThe lower bound for $F_{S}$ is:\n$$\n(F_{S})_{\\min} = 1 - \\frac{220}{450} = 1 - \\frac{22}{45} = \\frac{23}{45} \\approx 0.51111...\n$$\nRounding to four significant figures, we get $(F_{S})_{\\min} = 0.5111$.\n\nThe upper bound for $F_{S}$ is:\n$$\n(F_{S})_{\\max} = 1 - \\frac{140}{450} = 1 - \\frac{14}{45} = \\frac{31}{45} \\approx 0.68888...\n$$\nRounding to four significant figures, we get $(F_{S})_{\\max} = 0.6889$.\n\nTherefore, the fractional contribution of the parameters $X_S$ to the total output variance lies within the interval $[0.5111, 0.6889]$.\n\nInterpretation: The bounds on $F_S$ provide a quantitative assessment of the importance of the parameter subset $X_S$. The results indicate that the uncertainty in $X_S$ is responsible for at least $51.11\\%$ and at most $68.89\\%$ of the total output variance. This is a substantial contribution. If one were to perfectly determine the true values of the parameters in $X_S$ through validation experiments, the total variance of the model's output would be reduced by an amount within this range. This provides strong justification for prioritizing further experimental and validation resources to reduce the uncertainty in the parameters $X_S$, as doing so is guaranteed to significantly reduce the overall model uncertainty.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.5111  0.6889\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "When validating a model against empirical data, a key question is: \"how many simulation runs or experiments do I need?\" This question is answered by statistical power analysis, but the emergent time series from complex systems introduce a complication: autocorrelation. This hands-on exercise  involves developing a program to compute statistical power correctly for autocorrelated data, ensuring your validation studies are adequately designed to detect meaningful discrepancies.",
            "id": "4127738",
            "problem": "You are tasked with developing a program to compute statistical power for detecting a specified discrepancy in an emergent time series and to justify the sample size requirements for validation experiments under complex adaptive systems modeling. The emergent observation per experimental run is a time series $\\{Y_{r,t}\\}_{t=1}^{T}$, where $r \\in \\{1,\\ldots,R\\}$ indexes independent runs. Each series is assumed to be generated as $Y_{r,t} = \\mu + \\varepsilon_{r,t}$, where $\\{\\varepsilon_{r,t}\\}$ is a stationary Gaussian autoregressive process of order one (AR(1)) with marginal standard deviation $\\sigma$ and autocorrelation parameter $\\rho \\in (-1,1)$. The validation experiment aims to detect a discrepancy $\\delta$ in the long-run mean level between a reference model and empirical data, formalized by the hypothesis test on the difference in grand means across two conditions. Assume that runs in the two conditions are independent and identically distributed with the same $\\sigma$, $\\rho$, and $T$. Use a two-sided test at significance level $\\alpha$.\n\nStarting from fundamental definitions of covariance and the Central Limit Theorem (CLT), treat the per-run time-average $\\bar{Y}_{r} = \\frac{1}{T}\\sum_{t=1}^{T}Y_{r,t}$ as the basic estimator for the mean in a run. Use the fact that, for a stationary process, the variance of the time-average can be expressed via the autocovariance function, and for AR(1) with marginal variance $\\sigma^{2}$ and autocorrelation parameter $\\rho$, the autocovariance between lagged terms satisfies $\\operatorname{Cov}(\\varepsilon_{r,t},\\varepsilon_{r,t+k}) = \\sigma^{2}\\rho^{|k|}$. Consequently, the variance of the time-average must incorporate the autocorrelation structure. The grand mean across $R$ independent runs is $\\bar{M} = \\frac{1}{R}\\sum_{r=1}^{R}\\bar{Y}_{r}$. Under the two-condition comparison, consider the difference of grand means, and derive an expression for the statistical power under the alternative where the true mean difference is $\\delta \\neq 0$.\n\nYour program must:\n- Compute the variance of the per-run time-average $\\bar{Y}_{r}$ for AR(1) using the covariance summation identity.\n- Compute the variance of the difference of grand means across two conditions, using independence across runs and conditions.\n- Compute the statistical power (expressed as a decimal fraction, not a percentage) of the two-sided test at level $\\alpha$ for a specified discrepancy $\\delta$, given $(\\sigma,\\rho,T,R)$.\n- Compute the minimal integer number of independent runs $R_{\\min}$ (with $T$ fixed) required to achieve at least a target power $p_{\\star}$ for detecting $\\delta$ at level $\\alpha$.\n\nExpress all power values in decimal units (for example, $0.8$), not percentages. No physical units are involved, and no angles are involved.\n\nTest Suite:\nUse the following parameter sets, each represented as $(\\delta,\\sigma,\\rho,T,R,\\alpha,p_{\\star})$:\n1. $(0.5, 1.0, 0.3, 200, 10, 0.05, 0.8)$\n2. $(0.5, 1.0, 0.8, 10, 10, 0.05, 0.8)$\n3. $(0.1, 1.0, 0.95, 1000, 20, 0.05, 0.9)$\n4. $(0.2, 1.0, 0.0, 100, 5, 0.05, 0.8)$\n5. $(0.01, 1.0, 0.5, 10000, 50, 0.01, 0.9)$\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must be a two-element list $[\\text{power}, R_{\\min}]$, where $\\text{power}$ is a float for the given $R$ and $R_{\\min}$ is the minimal integer number of runs needed to achieve at least $p_{\\star}$ for the same $(\\delta,\\sigma,\\rho,T,\\alpha)$. Format the output line as, for example, $[[0.812345,9],[0.123456,87],\\ldots]$, where each power is rounded to six decimal places.",
            "solution": "The goal is to compute statistical power for detecting a discrepancy in the emergent mean of a time series from a complex adaptive system, with a justification for the sample size in terms of the number of independent runs. We begin with fundamental bases: the definition of covariance in stationary processes and the Central Limit Theorem (CLT), then derive the variance of the run-level time-average, construct the variance for the difference of grand means across two conditions, and finally deduce the statistical power under the alternative hypothesis.\n\nConsider a single run $r$ with time series $Y_{r,t} = \\mu + \\varepsilon_{r,t}$ for $t = 1,\\ldots,T$, where $\\{\\varepsilon_{r,t}\\}$ is a stationary Gaussian autoregressive process of order one (AR(1)) with marginal variance $\\sigma^{2}$ and autocorrelation parameter $\\rho \\in (-1,1)$. The per-run time-average is $\\bar{Y}_{r} = \\frac{1}{T}\\sum_{t=1}^{T}Y_{r,t}$. Since $\\varepsilon_{r,t}$ has zero mean, $\\mathbb{E}[\\bar{Y}_{r}] = \\mu$, and the variance of $\\bar{Y}_{r}$ depends on the autocovariance structure. The variance identity for a stationary process states\n$$\n\\operatorname{Var}(\\bar{Y}_{r}) \\;=\\; \\operatorname{Var}\\left(\\frac{1}{T}\\sum_{t=1}^{T}Y_{r,t}\\right) \\;=\\; \\frac{1}{T^{2}} \\sum_{i=1}^{T} \\sum_{j=1}^{T} \\operatorname{Cov}(Y_{r,i}, Y_{r,j}).\n$$\nBecause $Y_{r,t}$ differs from $\\varepsilon_{r,t}$ only by a constant offset $\\mu$, the covariance comes entirely from $\\varepsilon_{r,t}$. For AR(1) with marginal variance $\\sigma^{2}$, the autocovariance at lag $k$ is $\\operatorname{Cov}(\\varepsilon_{r,t},\\varepsilon_{r,t+k}) = \\sigma^{2}\\rho^{|k|}$. Using the symmetry of covariances and grouping by lag, we obtain\n$$\n\\operatorname{Var}(\\bar{Y}_{r}) \\;=\\; \\frac{1}{T^{2}} \\left( T \\cdot \\sigma^{2} + 2 \\sum_{k=1}^{T-1} (T - k) \\cdot \\sigma^{2} \\rho^{k} \\right)\n\\;=\\; \\frac{\\sigma^{2}}{T}\\left( 1 + 2 \\sum_{k=1}^{T-1}\\left(1 - \\frac{k}{T}\\right)\\rho^{k} \\right).\n$$\nThis identity shows how autocorrelation inflates the variance of the time-average relative to the independent case (which corresponds to $\\rho = 0$ and yields $\\operatorname{Var}(\\bar{Y}_{r}) = \\sigma^{2}/T$).\n\nLet there be two conditions, denoted $A$ and $B$, each with $R$ independent runs of length $T$, and suppose the long-run mean in condition $B$ differs by $\\delta$ from condition $A$ so that $\\mu_{B} = \\mu_{A} + \\delta$. Within each condition, the grand mean across runs is\n$$\n\\bar{M}_{A} = \\frac{1}{R}\\sum_{r=1}^{R}\\bar{Y}^{(A)}_{r}, \\qquad \\bar{M}_{B} = \\frac{1}{R}\\sum_{r=1}^{R}\\bar{Y}^{(B)}_{r}.\n$$\nBy independence of runs, $\\operatorname{Var}(\\bar{M}_{A}) = \\operatorname{Var}(\\bar{Y}_{r})/R$ and $\\operatorname{Var}(\\bar{M}_{B}) = \\operatorname{Var}(\\bar{Y}_{r})/R$ when both conditions share the same $\\sigma$, $\\rho$, and $T$. The difference of grand means, $\\hat{\\Delta} = \\bar{M}_{B} - \\bar{M}_{A}$, has variance\n$$\n\\operatorname{Var}(\\hat{\\Delta}) \\;=\\; \\operatorname{Var}(\\bar{M}_{B}) + \\operatorname{Var}(\\bar{M}_{A})\n\\;=\\; \\frac{2}{R}\\operatorname{Var}(\\bar{Y}_{r})\n\\;=\\; \\frac{2\\sigma^{2}}{R T}\\left( 1 + 2 \\sum_{k=1}^{T-1}\\left(1 - \\frac{k}{T}\\right)\\rho^{k} \\right).\n$$\nUnder the alternative hypothesis where the true mean difference is $\\delta \\neq 0$, the standardized statistic based on $\\hat{\\Delta}$ and its standard deviation is approximately normal by the Central Limit Theorem (CLT) for averages of weakly dependent sequences across independent runs. Denote the standard deviation by\n$$\ns_{\\Delta} \\;=\\; \\sqrt{\\operatorname{Var}(\\hat{\\Delta})},\n$$\nand the noncentrality parameter by\n$$\n\\lambda \\;=\\; \\frac{|\\delta|}{s_{\\Delta}}.\n$$\nUsing a two-sided test at level $\\alpha$, the critical value for the standard normal test is $z_{1-\\alpha/2}$ (the $(1-\\alpha/2)$-quantile of the standard normal distribution). Under the alternative, the standardized statistic $Z$ is approximately $\\mathcal{N}(\\lambda,1)$, so the statistical power (probability of rejecting the null under the alternative) is\n$$\n\\text{Power} \\;=\\; \\mathbb{P}\\left(|Z|  z_{1-\\alpha/2}\\right)\n\\;=\\; \\Phi\\left(-z_{1-\\alpha/2} - \\lambda\\right) + \\left(1 - \\Phi\\left(z_{1-\\alpha/2} - \\lambda\\right)\\right),\n$$\nwhere $\\Phi(\\cdot)$ is the cumulative distribution function of the standard normal distribution. This form follows directly from the definition of a two-sided rejection region and the distribution of $Z$ under the alternative.\n\nTo justify sample size in terms of the number of independent runs, observe that $s_{\\Delta}$ decreases monotonically in $R$ (specifically like $R^{-1/2}$), so the power is monotonically increasing in $R$. Therefore, for a fixed $(\\delta,\\sigma,\\rho,T,\\alpha)$ and target power $p_{\\star}$, there exists a minimal integer $R_{\\min}$ such that the computed power at $R_{\\min}$ is at least $p_{\\star}$. We compute $R_{\\min}$ efficiently by:\n- Evaluating power at $R = 1$ and doubling $R$ until the power exceeds $p_{\\star}$ or a preset large upper bound is reached (exponential search to find an interval that brackets the solution).\n- Performing a binary search on the bracketed interval to find the smallest integer $R$ such that the power is at least $p_{\\star}$.\n\nAlgorithmic steps implemented in the program:\n1. Compute $\\operatorname{Var}(\\bar{Y}_{r})$ using the AR(1) covariance summation formula:\n   $$\n   \\operatorname{Var}(\\bar{Y}_{r}) \\;=\\; \\frac{\\sigma^{2}}{T}\\left( 1 + 2 \\sum_{k=1}^{T-1}\\left(1 - \\frac{k}{T}\\right)\\rho^{k} \\right).\n   $$\n2. Compute $\\operatorname{Var}(\\hat{\\Delta}) = \\frac{2}{R}\\operatorname{Var}(\\bar{Y}_{r})$ and $s_{\\Delta} = \\sqrt{\\operatorname{Var}(\\hat{\\Delta})}$.\n3. Compute $\\lambda = \\frac{|\\delta|}{s_{\\Delta}}$ and $z_{1-\\alpha/2}$, then evaluate power via\n   $$\n   \\text{Power} \\;=\\; \\Phi\\left(-z_{1-\\alpha/2} - \\lambda\\right) + \\left(1 - \\Phi\\left(z_{1-\\alpha/2} - \\lambda\\right)\\right).\n   $$\n4. For each test case, compute the power at the given $R$, and compute $R_{\\min}$ by exponential search followed by binary search as described. The monotonicity of power in $R$ guarantees the algorithmâ€™s correctness.\n5. Output the list of results $[\\text{power}, R_{\\min}]$ for all test cases on a single line, with each power rounded to six decimal places.\n\nThis procedure is grounded in standard properties of stationary Gaussian AR(1) processes, the covariance-based variance formula for time-averages, and the Central Limit Theorem (CLT), yielding scientifically sound and numerically stable computations suitable for model verification and validation in complex adaptive systems.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef var_mean_ar1(T: int, rho: float, sigma: float) - float:\n    \"\"\"\n    Compute Var(bar{Y}_r) for an AR(1) process with marginal std sigma and autocorrelation rho.\n    Var(bar{Y}_r) = (sigma^2 / T) * [1 + 2 * sum_{k=1}^{T-1} (1 - k/T) * rho^k]\n    \"\"\"\n    if T = 0:\n        raise ValueError(\"T must be a positive integer\")\n    if abs(rho) = 1.0:\n        raise ValueError(\"rho must be in (-1,1) for stationarity\")\n    # Sum the weighted autocorrelation terms\n    if T == 1:\n        # No autocovariance terms when only one observation\n        return (sigma ** 2) / T\n    k = np.arange(1, T, dtype=np.float64)\n    weights = 1.0 - k / T\n    # Use power with float for stability\n    rho_powers = rho ** k\n    s = np.sum(weights * rho_powers)\n    return (sigma ** 2 / T) * (1.0 + 2.0 * s)\n\ndef two_sided_power(delta: float, sigma: float, rho: float, T: int, R: int, alpha: float) - float:\n    \"\"\"\n    Compute the two-sided normal-approx power at significance alpha for discrepancy delta,\n    given AR(1) parameters (sigma, rho), time length T, and number of runs R.\n    \"\"\"\n    vmean = var_mean_ar1(T, rho, sigma)\n    vdiff = 2.0 * vmean / float(R)\n    sd = np.sqrt(vdiff)\n    lam = abs(delta) / sd if sd  0 else np.inf\n    z = norm.ppf(1.0 - alpha / 2.0)\n    # Power = P(|Z|  z) with Z ~ N(lam, 1)\n    power = norm.cdf(-z - lam) + (1.0 - norm.cdf(z - lam))\n    return float(power)\n\ndef minimal_R_for_power(delta: float, sigma: float, rho: float, T: int, alpha: float, target_power: float,\n                        Rmax: int = 1_000_000) - int:\n    \"\"\"\n    Find the minimal integer R such that two_sided_power(...) = target_power,\n    using exponential search to bracket and then binary search to refine.\n    \"\"\"\n    # Handle degenerate case: if delta is zero, power equals alpha; require Rmin as 1 if target = alpha else Rmax\n    # However, we follow the general algorithm; as R grows, lam grows ~ sqrt(R), power increases.\n    # Exponential search to find an upper bound where power = target_power.\n    upper = 1\n    p_upper = two_sided_power(delta, sigma, rho, T, upper, alpha)\n    if p_upper = target_power:\n        return upper\n    while p_upper  target_power and upper  Rmax:\n        upper *= 2\n        p_upper = two_sided_power(delta, sigma, rho, T, upper, alpha)\n    if p_upper  target_power and upper = Rmax:\n        # Could not achieve target within Rmax; return Rmax as a conservative cap.\n        return Rmax\n    lower = upper // 2\n    if lower  1:\n        lower = 1\n    # Binary search for minimal R in [lower, upper]\n    rmin = upper\n    while lower = upper:\n        mid = (lower + upper) // 2\n        p_mid = two_sided_power(delta, sigma, rho, T, mid, alpha)\n        if p_mid = target_power:\n            rmin = mid\n            upper = mid - 1\n        else:\n            lower = mid + 1\n    return int(rmin)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case is (delta, sigma, rho, T, R, alpha, p_star)\n    test_cases = [\n        (0.5, 1.0, 0.3, 200, 10, 0.05, 0.8),\n        (0.5, 1.0, 0.8, 10, 10, 0.05, 0.8),\n        (0.1, 1.0, 0.95, 1000, 20, 0.05, 0.9),\n        (0.2, 1.0, 0.0, 100, 5, 0.05, 0.8),\n        (0.01, 1.0, 0.5, 10000, 50, 0.01, 0.9),\n    ]\n\n    results = []\n    for case in test_cases:\n        delta, sigma, rho, T, R, alpha, p_star = case\n        power = two_sided_power(delta, sigma, rho, T, R, alpha)\n        Rmin = minimal_R_for_power(delta, sigma, rho, T, alpha, p_star)\n        results.append((power, Rmin))\n\n    # Format the final result exactly as required: [[power,Rmin],...], with power rounded to 6 decimals.\n    formatted_results = \"[\" + \",\".join(\"[\" + f\"{p:.6f},\" + f\"{r}\" + \"]\" for p, r in results) + \"]\"\n    print(formatted_results)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Validation often involves comparing model outputs to observational data, which can be fraught with hidden biases. A naive comparison might mislead us into rejecting a good model or accepting a flawed one due to confounding variables or selection effects within the data. This advanced practice  delves into the domain of causal inference to construct a sensitivity analysis, allowing you to quantify how severely an unmeasured confounder would need to impact the system to alter your validation conclusions.",
            "id": "4127742",
            "problem": "Consider the validation of Complex Adaptive Systems (CAS) models, where agent-level interactions generate system-level outcomes. In this context, confounding and selection bias pertain to how data used to validate the model may distort causal effect estimates of an intervention. Confounding arises when an unmeasured variable influences both intervention assignment and outcomes, while selection bias arises when the observed validation sample is not representative of the target population because inclusion depends on variables related to the intervention or outcomes. Formalize these biases in a binary causal model and derive a sensitivity analysis that quantitatively evaluates how unmeasured confounding and selection impact the validation metric of the causal effect.\n\nAssume a binary treatment $A \\in \\{0,1\\}$ applied to agents, a binary outcome $Y \\in \\{0,1\\}$, and a binary unmeasured confounder $U \\in \\{0,1\\}$ with prevalence $\\mathbb{P}(U=1)=\\pi$. The target estimand is the Average Treatment Effect (ATE) defined on the population as $\\text{ATE} = \\mathbb{E}[Y(1) - Y(0)]$, where $Y(a)$ denotes the potential outcome under treatment level $a$. Let the outcome model be a linear probability model with interaction,\n$$\\mu(a,u) = \\eta_0 + \\eta_A a + \\eta_U u + \\eta_{AU} a u,$$\nwith parameters constrained such that $0 \\le \\mu(a,u) \\le 1$ for all $a \\in \\{0,1\\}$ and $u \\in \\{0,1\\}$. The treatment assignment depends on $U$ via\n$$\\mathbb{P}(A=1\\mid U=u) = \\alpha_0 + \\alpha_U u,$$\nwith $0 \\le \\alpha_0 \\le 1$ and $0 \\le \\alpha_0 + \\alpha_U \\le 1$. The inclusion indicator $S \\in \\{0,1\\}$ denotes whether an agent is observed in the validation dataset. The selection mechanism depends on $A$, $U$, and $Y$ via the expected inclusion probability\n$$\\bar{s}(a,u) = s_0 + s_A a + s_U u + s_Y \\mu(a,u),$$\nwith parameters constrained such that $0 \\le \\bar{s}(a,u) \\le 1$ for all $a \\in \\{0,1\\}$ and $u \\in \\{0,1\\}$.\n\nStarting from the Fundamental Laws of Probability (law of total probability and Bayes' rule), and the core causal definitions of potential outcomes and the Average Treatment Effect (ATE), derive expressions for the following quantities as functions of $(\\pi, \\alpha_0, \\alpha_U, \\eta_0, \\eta_A, \\eta_U, \\eta_{AU}, s_0, s_A, s_U, s_Y)$:\n- The true population $\\text{ATE}$, defined as $\\mathbb{E}[Y(1) - Y(0)]$.\n- The naive difference in means ignoring selection, $\\Delta_{\\text{naive,noSel}} = \\mathbb{E}[Y \\mid A=1] - \\mathbb{E}[Y \\mid A=0]$, where expectations are over the full population distribution.\n- The naive difference in means within the selected sample, $\\Delta_{\\text{naive,Sel}} = \\mathbb{E}[Y \\mid A=1,S=1] - \\mathbb{E}[Y \\mid A=0,S=1]$.\n- The total bias under confounding and selection, $\\text{Bias}_{\\text{total}} = \\Delta_{\\text{naive,Sel}} - \\text{ATE}$.\n\nYour program must implement these derived expressions exactly, without simulation, and compute the quantities above for each parameter set in the test suite below. All probabilities must be expressed as decimals, not percentages.\n\nTest suite parameter sets:\n- Case $1$ (general confounding and selection): $\\pi=0.3$, $\\alpha_0=0.2$, $\\alpha_U=0.5$, $\\eta_0=0.05$, $\\eta_A=0.2$, $\\eta_U=0.15$, $\\eta_{AU}=0.1$, $s_0=0.4$, $s_A=0.1$, $s_U=0.1$, $s_Y=0.2$.\n- Case $2$ (no confounding, selection depends on outcome and treatment): $\\pi=0.5$, $\\alpha_0=0.6$, $\\alpha_U=0.0$, $\\eta_0=0.1$, $\\eta_A=0.3$, $\\eta_U=0.0$, $\\eta_{AU}=0.0$, $s_0=0.5$, $s_A=0.1$, $s_U=0.0$, $s_Y=0.3$.\n- Case $3$ (confounding only, no selection bias): $\\pi=0.4$, $\\alpha_0=0.3$, $\\alpha_U=0.4$, $\\eta_0=0.02$, $\\eta_A=0.25$, $\\eta_U=0.2$, $\\eta_{AU}=0.0$, $s_0=0.9$, $s_A=0.0$, $s_U=0.0$, $s_Y=0.0$.\n- Case $4$ (rare confounder with strong effects, moderate selection): $\\pi=0.01$, $\\alpha_0=0.05$, $\\alpha_U=0.9$, $\\eta_0=0.01$, $\\eta_A=0.05$, $\\eta_U=0.5$, $\\eta_{AU}=0.0$, $s_0=0.2$, $s_A=0.2$, $s_U=0.2$, $s_Y=0.2$.\n- Case $5$ (ubiquitous confounder, strong treatment effect, selection depends on outcome): $\\pi=0.99$, $\\alpha_0=0.05$, $\\alpha_U=0.8$, $\\eta_0=0.05$, $\\eta_A=0.35$, $\\eta_U=0.1$, $\\eta_{AU}=0.0$, $s_0=0.3$, $s_A=0.0$, $s_U=0.0$, $s_Y=0.6$.\n\nScientific realism requires verifying that each parameter set yields $0 \\le \\mu(a,u) \\le 1$ and $0 \\le \\bar{s}(a,u) \\le 1$ for all $a \\in \\{0,1\\}$ and $u \\in \\{0,1\\}$, and that denominators in Bayes conditioning are nonzero.\n\nYour program should produce a single line of output containing the results as a comma-separated list of lists enclosed in square brackets, where each inner list corresponds to a case and contains four floats rounded to six decimal places in the order $[\\text{ATE}, \\Delta_{\\text{naive,noSel}}, \\Delta_{\\text{naive,Sel}}, \\text{Bias}_{\\text{total}}]$. For example, the overall format must be like $[[x_{11},x_{12},x_{13},x_{14}],[x_{21},x_{22},x_{23},x_{24}],\\dots]$.",
            "solution": "The problem requires the derivation of expressions for several causal quantities within a specified binary causal model that includes an unmeasured confounder and a selection mechanism. The goal is to quantify confounding and selection bias. The derivation will proceed step-by-step from the fundamental principles of probability and causal inference.\n\nFirst, we establish the probabilistic structure of the data generating process based on the given parameters: $(\\pi, \\alpha_0, \\alpha_U, \\eta_0, \\eta_A, \\eta_U, \\eta_{AU}, s_0, s_A, s_U, s_Y)$.\n\n**1. Component Probabilities and Expectations**\n\nThe model is built upon several base probabilities and conditional expectations, which we define first.\n-   Prevalence of the unmeasured confounder $U$:\n    $$ \\mathbb{P}(U=1) = \\pi, \\quad \\mathbb{P}(U=0) = 1-\\pi $$\n-   Conditional probability of treatment assignment $A$ given $U$:\n    $$ \\mathbb{P}(A=1 \\mid U=u) = \\alpha_0 + \\alpha_U u $$\n    This implies:\n    $$ \\mathbb{P}(A=1 \\mid U=1) = \\alpha_0 + \\alpha_U $$\n    $$ \\mathbb{P}(A=1 \\mid U=0) = \\alpha_0 $$\n    $$ \\mathbb{P}(A=0 \\mid U=u) = 1 - (\\alpha_0 + \\alpha_U u) $$\n-   Conditional expectation of the potential outcome $Y(a)$ given $U$, which defines the outcome model:\n    $$ \\mathbb{E}[Y(a) \\mid U=u] = \\mathbb{P}(Y(a)=1 \\mid U=u) = \\mu(a,u) = \\eta_0 + \\eta_A a + \\eta_U u + \\eta_{AU} a u $$\n-   Conditional probability of selection into the sample ($S=1$) given $A$ and $U$:\n    $$ \\mathbb{P}(S=1 \\mid A=a, U=u) = \\bar{s}(a,u) = s_0 + s_A a + s_U u + s_Y \\mu(a,u) $$\n    This definition implies that, conditional on an agent's treatment status $A$ and their type $U$, their selection probability depends on their *expected* outcome $\\mu(a,u)$, not their realized outcome $Y$. This implies conditional independence: $S \\perp Y \\mid (A, U)$.\n\n**2. Derivation of the True Average Treatment Effect (ATE)**\n\nThe ATE is defined as the expected difference in potential outcomes over the entire population.\n$$ \\text{ATE} = \\mathbb{E}[Y(1) - Y(0)] = \\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)] $$\nUsing the Law of Total Expectation, we can marginalize over the confounder $U$:\n$$ \\mathbb{E}[Y(a)] = \\mathbb{E}_U[\\mathbb{E}[Y(a) \\mid U]] = \\mathbb{E}[Y(a) \\mid U=1]\\mathbb{P}(U=1) + \\mathbb{E}[Y(a) \\mid U=0]\\mathbb{P}(U=0) $$\nSubstituting the definitions for $\\mu(a,u)$ and $\\pi$:\n$$ \\mathbb{E}[Y(a)] = \\mu(a,1)\\pi + \\mu(a,0)(1-\\pi) $$\nFor $a=1$:\n$$ \\mathbb{E}[Y(1)] = (\\eta_0 + \\eta_A + \\eta_U + \\eta_{AU})\\pi + (\\eta_0 + \\eta_A)(1-\\pi) = \\eta_0 + \\eta_A + (\\eta_U + \\eta_{AU})\\pi $$\nFor $a=0$:\n$$ \\mathbb{E}[Y(0)] = (\\eta_0 + \\eta_U)\\pi + \\eta_0(1-\\pi) = \\eta_0 + \\eta_U\\pi $$\nThe ATE is the difference:\n$$ \\text{ATE} = (\\eta_0 + \\eta_A + (\\eta_U + \\eta_{AU})\\pi) - (\\eta_0 + \\eta_U\\pi) = \\eta_A + \\eta_{AU}\\pi $$\n\n**3. Derivation of the Naive Difference in Means (Ignoring Selection)**\n\nThis quantity, $\\Delta_{\\text{naive,noSel}}$, is the associational difference in means in the full population, which is biased by confounding.\n$$ \\Delta_{\\text{naive,noSel}} = \\mathbb{E}[Y \\mid A=1] - \\mathbb{E}[Y \\mid A=0] $$\nWe calculate each term using the Law of Total Expectation, conditioning on $U$. A key assumption is consistency ($Y=Y(A)$) and conditional unconfoundedness ($Y(a) \\perp A \\mid U$), which implies $\\mathbb{E}[Y \\mid A=a, U=u] = \\mathbb{E}[Y(a) \\mid A=a, U=u] = \\mathbb{E}[Y(a) \\mid U=u] = \\mu(a,u)$.\n$$ \\mathbb{E}[Y \\mid A=a] = \\sum_{u \\in \\{0,1\\}} \\mathbb{E}[Y \\mid A=a, U=u] \\mathbb{P}(U=u \\mid A=a) = \\sum_{u \\in \\{0,1\\}} \\mu(a,u) \\mathbb{P}(U=u \\mid A=a) $$\nWe need $\\mathbb{P}(U=u \\mid A=a)$, which we find using Bayes' rule: $\\mathbb{P}(U=u \\mid A=a) = \\frac{\\mathbb{P}(A=a \\mid U=u)\\mathbb{P}(U=u)}{\\mathbb{P}(A=a)}$. First, we find the marginal probability of treatment, $\\mathbb{P}(A=a)$:\n$$ \\mathbb{P}(A=1) = \\mathbb{P}(A=1 \\mid U=1)\\pi + \\mathbb{P}(A=1 \\mid U=0)(1-\\pi) = (\\alpha_0 + \\alpha_U)\\pi + \\alpha_0(1-\\pi) = \\alpha_0 + \\alpha_U\\pi $$\n$$ \\mathbb{P}(A=0) = 1 - \\mathbb{P}(A=1) = 1 - \\alpha_0 - \\alpha_U\\pi $$\nNow we can express the conditional probabilities $\\mathbb{P}(U=u \\mid A=a)$:\n$$ \\mathbb{P}(U=1 \\mid A=1) = \\frac{(\\alpha_0+\\alpha_U)\\pi}{\\alpha_0+\\alpha_U\\pi} \\quad \\text{and} \\quad \\mathbb{P}(U=0 \\mid A=1) = \\frac{\\alpha_0(1-\\pi)}{\\alpha_0+\\alpha_U\\pi} $$\n$$ \\mathbb{P}(U=1 \\mid A=0) = \\frac{(1-\\alpha_0-\\alpha_U)\\pi}{1-\\alpha_0-\\alpha_U\\pi} \\quad \\text{and} \\quad \\mathbb{P}(U=0 \\mid A=0) = \\frac{(1-\\alpha_0)(1-\\pi)}{1-\\alpha_0-\\alpha_U\\pi} $$\nSubstituting these into the expression for $\\mathbb{E}[Y \\mid A=a]$:\n$$ \\mathbb{E}[Y \\mid A=1] = \\mu(1,1)\\frac{(\\alpha_0+\\alpha_U)\\pi}{\\alpha_0+\\alpha_U\\pi} + \\mu(1,0)\\frac{\\alpha_0(1-\\pi)}{\\alpha_0+\\alpha_U\\pi} $$\n$$ \\mathbb{E}[Y \\mid A=0] = \\mu(0,1)\\frac{(1-\\alpha_0-\\alpha_U)\\pi}{1-\\alpha_0-\\alpha_U\\pi} + \\mu(0,0)\\frac{(1-\\alpha_0)(1-\\pi)}{1-\\alpha_0-\\alpha_U\\pi} $$\n$\\Delta_{\\text{naive,noSel}}$ is the difference between these two quantities.\n\n**4. Derivation of the Naive Difference in Means (in the Selected Sample)**\n\nThis estimator, $\\Delta_{\\text{naive,Sel}}$, is what one would compute from the observed validation data, which is subject to both confounding and selection bias.\n$$ \\Delta_{\\text{naive,Sel}} = \\mathbb{E}[Y \\mid A=1,S=1] - \\mathbb{E}[Y \\mid A=0,S=1] $$\nWe compute $\\mathbb{E}[Y \\mid A=a, S=1]$ using the Law of Total Expectation, conditioning on $U$:\n$$ \\mathbb{E}[Y \\mid A=a,S=1] = \\sum_{u \\in \\{0,1\\}} \\mathbb{E}[Y \\mid A=a,S=1,U=u] \\mathbb{P}(U=u \\mid A=a,S=1) $$\nDue to the assumption $S \\perp Y \\mid (A,U)$, we have $\\mathbb{E}[Y \\mid A=a,S=1,U=u] = \\mathbb{E}[Y \\mid A=a,U=u] = \\mu(a,u)$. Thus:\n$$ \\mathbb{E}[Y \\mid A=a,S=1] = \\sum_{u \\in \\{0,1\\}} \\mu(a,u) \\mathbb{P}(U=u \\mid A=a,S=1) $$\nWe find $\\mathbb{P}(U=u \\mid A=a, S=1)$ using Bayes' rule:\n$$ \\mathbb{P}(U=u \\mid A=a,S=1) = \\frac{\\mathbb{P}(S=1 \\mid A=a,U=u)\\mathbb{P}(U=u \\mid A=a)}{\\mathbb{P}(S=1 \\mid A=a)} $$\nThe denominator is $\\mathbb{P}(S=1 \\mid A=a) = \\sum_{u' \\in \\{0,1\\}} \\mathbb{P}(S=1 \\mid A=a,U=u')\\mathbb{P}(U=u' \\mid A=a)$.\nSubstituting $\\bar{s}(a,u) = \\mathbb{P}(S=1 \\mid A=a, U=u)$ and the previously derived $\\mathbb{P}(U=u \\mid A=a)$:\n$$ \\mathbb{E}[Y \\mid A=a,S=1] = \\frac{\\sum_{u \\in \\{0,1\\}} \\mu(a,u) \\bar{s}(a,u) \\mathbb{P}(U=u \\mid A=a)}{\\sum_{u \\in \\{0,1\\}} \\bar{s}(a,u) \\mathbb{P}(U=u \\mid A=a)} $$\nLet $P_{u|a} = \\mathbb{P}(U=u \\mid A=a)$. The expressions for the two treatment groups are:\n$$ \\mathbb{E}[Y \\mid A=1,S=1] = \\frac{\\mu(1,1)\\bar{s}(1,1)P_{1|1} + \\mu(1,0)\\bar{s}(1,0)P_{0|1}}{\\bar{s}(1,1)P_{1|1} + \\bar{s}(1,0)P_{0|1}} $$\n$$ \\mathbb{E}[Y \\mid A=0,S=1] = \\frac{\\mu(0,1)\\bar{s}(0,1)P_{1|0} + \\mu(0,0)\\bar{s}(0,0)P_{0|0}}{\\bar{s}(0,1)P_{1|0} + \\bar{s}(0,0)P_{0|0}} $$\n$\\Delta_{\\text{naive,Sel}}$ is the difference between these two quantities.\n\n**5. Derivation of Total Bias**\n\nThe total bias, $\\text{Bias}_{\\text{total}}$, is the difference between the estimand computed on the selected sample and the true population ATE.\n$$ \\text{Bias}_{\\text{total}} = \\Delta_{\\text{naive,Sel}} - \\text{ATE} $$\nThis expression captures the aggregate error from both confounding (differences between the treated and untreated groups due to $U$) and selection (systematic differences between the selected sample and the full population).\n\nThese derived formulae are exact under the assumed model and can be implemented directly to perform the required sensitivity analysis.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the causal bias analysis problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general confounding and selection)\n        {\"pi\": 0.3, \"alpha_0\": 0.2, \"alpha_U\": 0.5, \"eta_0\": 0.05, \"eta_A\": 0.2, \"eta_U\": 0.15, \"eta_AU\": 0.1, \"s_0\": 0.4, \"s_A\": 0.1, \"s_U\": 0.1, \"s_Y\": 0.2},\n        # Case 2 (no confounding, selection depends on outcome and treatment)\n        {\"pi\": 0.5, \"alpha_0\": 0.6, \"alpha_U\": 0.0, \"eta_0\": 0.1, \"eta_A\": 0.3, \"eta_U\": 0.0, \"eta_AU\": 0.0, \"s_0\": 0.5, \"s_A\": 0.1, \"s_U\": 0.0, \"s_Y\": 0.3},\n        # Case 3 (confounding only, no selection bias)\n        {\"pi\": 0.4, \"alpha_0\": 0.3, \"alpha_U\": 0.4, \"eta_0\": 0.02, \"eta_A\": 0.25, \"eta_U\": 0.2, \"eta_AU\": 0.0, \"s_0\": 0.9, \"s_A\": 0.0, \"s_U\": 0.0, \"s_Y\": 0.0},\n        # Case 4 (rare confounder with strong effects, moderate selection)\n        {\"pi\": 0.01, \"alpha_0\": 0.05, \"alpha_U\": 0.9, \"eta_0\": 0.01, \"eta_A\": 0.05, \"eta_U\": 0.5, \"eta_AU\": 0.0, \"s_0\": 0.2, \"s_A\": 0.2, \"s_U\": 0.2, \"s_Y\": 0.2},\n         # Case 5 (ubiquitous confounder, strong treatment effect, selection depends on outcome)\n        {\"pi\": 0.99, \"alpha_0\": 0.05, \"alpha_U\": 0.8, \"eta_0\": 0.05, \"eta_A\": 0.35, \"eta_U\": 0.1, \"eta_AU\": 0.0, \"s_0\": 0.3, \"s_A\": 0.0, \"s_U\": 0.0, \"s_Y\": 0.6}\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = calculate_metrics(params)\n        all_results.append(result)\n\n    # Format the output as specified in the problem\n    formatted_cases = []\n    for case_results in all_results:\n        formatted_nums = [f\"{x:.6f}\" for x in case_results]\n        formatted_cases.append(f\"[{','.join(formatted_nums)}]\")\n    final_string = f\"[{','.join(formatted_cases)}]\"\n    print(final_string)\n\n\ndef calculate_metrics(p):\n    \"\"\"\n    Calculates ATE, naive differences, and bias based on the derived formulas.\n    p is a dictionary of parameters.\n    \"\"\"\n    # Unpack parameters for clarity\n    pi, alpha_0, alpha_U = p['pi'], p['alpha_0'], p['alpha_U']\n    eta_0, eta_A, eta_U, eta_AU = p['eta_0'], p['eta_A'], p['eta_U'], p['eta_AU']\n    s_0, s_A, s_U, s_Y = p['s_0'], p['s_A'], p['s_U'], p['s_Y']\n\n    # 1. Calculate potential outcome probabilities mu(a, u)\n    mu_00 = eta_0\n    mu_01 = eta_0 + eta_U\n    mu_10 = eta_0 + eta_A\n    mu_11 = eta_0 + eta_A + eta_U + eta_AU\n    mus = [mu_00, mu_01, mu_10, mu_11]\n    \n    # 2. Calculate selection probabilities s_bar(a, u)\n    s_bar_00 = s_0 + s_Y * mu_00\n    s_bar_01 = s_0 + s_U + s_Y * mu_01\n    s_bar_10 = s_0 + s_A + s_Y * mu_10\n    s_bar_11 = s_0 + s_A + s_U + s_Y * mu_11\n    s_bars = [s_bar_00, s_bar_01, s_bar_10, s_bar_11]\n\n    # Parameter validation\n    alpha_probs = [alpha_0, alpha_0+alpha_U]\n    if not all(0 = v = 1 for v in alpha_probs + mus + s_bars):\n        # This case would be invalid per problem statement.\n        # For this implementation, we assume test cases are pre-validated.\n        raise ValueError(\"Invalid parameters: probabilities not in [0,1]\")\n\n    # 3. Calculate ATE\n    ate = eta_A + eta_AU * pi\n\n    # 4. Calculate Delta_naive_noSel\n    prob_A1 = alpha_0 + alpha_U * pi\n    prob_A0 = 1.0 - prob_A1\n\n    if prob_A1 == 0 or prob_A0 == 0:\n        raise ValueError(\"Division by zero: P(A=a) is zero.\")\n        \n    prob_U1_given_A1 = ((alpha_0 + alpha_U) * pi) / prob_A1\n    prob_U0_given_A1 = (alpha_0 * (1 - pi)) / prob_A1\n    \n    prob_U1_given_A0 = ((1 - (alpha_0 + alpha_U)) * pi) / prob_A0\n    prob_U0_given_A0 = ((1 - alpha_0) * (1 - pi)) / prob_A0\n    \n    exp_Y_given_A1 = mu_11 * prob_U1_given_A1 + mu_10 * prob_U0_given_A1\n    exp_Y_given_A0 = mu_01 * prob_U1_given_A0 + mu_00 * prob_U0_given_A0\n    \n    delta_naive_noSel = exp_Y_given_A1 - exp_Y_given_A0\n\n    # 5. Calculate Delta_naive_Sel\n    # Denominators: P(S=1|A=a)\n    prob_S1_given_A1 = s_bar_11 * prob_U1_given_A1 + s_bar_10 * prob_U0_given_A1\n    prob_S1_given_A0 = s_bar_01 * prob_U1_given_A0 + s_bar_00 * prob_U0_given_A0\n    \n    if prob_S1_given_A1 == 0 or prob_S1_given_A0 == 0:\n         raise ValueError(\"Division by zero: P(S=1|A=a) is zero.\")\n        \n    # Numerators for E[Y|A=a, S=1]\n    num_exp_Y_sel_A1 = mu_11 * s_bar_11 * prob_U1_given_A1 + mu_10 * s_bar_10 * prob_U0_given_A1\n    num_exp_Y_sel_A0 = mu_01 * s_bar_01 * prob_U1_given_A0 + mu_00 * s_bar_00 * prob_U0_given_A0\n\n    exp_Y_given_A1_S1 = num_exp_Y_sel_A1 / prob_S1_given_A1\n    exp_Y_given_A0_S1 = num_exp_Y_sel_A0 / prob_S1_given_A0\n    \n    delta_naive_Sel = exp_Y_given_A1_S1 - exp_Y_given_A0_S1\n\n    # 6. Calculate total bias\n    bias_total = delta_naive_Sel - ate\n\n    return [ate, delta_naive_noSel, delta_naive_Sel, bias_total]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}