{
    "hands_on_practices": [
        {
            "introduction": "我们模型的参数通常是通过数据拟合得到的，因此本身就带有不确定性。一个核心问题是，这些参数的不确定性如何传递到模型的输出或我们关心的性能指标上？本练习将引导你使用德尔塔方法（delta method），这是一种基于泰勒展开的强大技术，用于近似计算参数函数（即模型的衍生量）的方差，并构建其置信区间。通过这个练习 ，你将掌握将参数估计的不确定性量化为模型预测不确定性的关键技能。",
            "id": "4150972",
            "problem": "考虑一个复杂传染的基于主体的模型，其中每个主体的激活风险取决于两个参数：内在激活倾向 $\\alpha$ 和社会影响敏感性 $\\beta$。假设我们使用最大似然估计（MLE）方法将此模型拟合到大量独立的模拟批次。在标准正则性条件下，并根据中心极限定理（CLT），MLE $\\hat{\\theta} = (\\hat{\\alpha}, \\hat{\\beta})^{\\top}$ 是一致的，并允许渐近正态近似。您对系统的一个非线性性能泛函——级联放大因子——进行不确定性量化感兴趣，其定义为\n$$\ng(\\alpha, \\beta) \\equiv \\frac{\\exp(\\beta)}{1 - \\alpha \\beta^{2}}.\n$$\n从 MLE 的渐近正态性出发，仅使用第一性原理和关于大样本理论的成熟事实，通过 delta 方法推导 $g(\\hat{\\theta})$ 的渐近分布，明确地用 $\\theta$ 和 $\\hat{\\theta}$ 的协方差表示极限均值和方差。然后，对于以下拟合值和估计的协方差，\n$$\n\\hat{\\alpha} = 0.3, \\quad \\hat{\\beta} = 0.8, \\quad \\widehat{\\mathrm{Cov}}(\\hat{\\theta}) = \\begin{pmatrix} 0.0016 & -0.0003 \\\\ -0.0003 & 0.0025 \\end{pmatrix},\n$$\n通过将 $\\hat{\\theta}$ 和 $\\widehat{\\mathrm{Cov}}(\\hat{\\theta})$ 代入您的渐近分布，并使用标准正态分位数作为置信水平，计算 $g(\\theta)$ 的一个近似双侧 $95\\%$ 置信区间。将置信区间的两个端点四舍五入到四位有效数字。使用 pmatrix 环境将您的最终答案表示为一个行向量，其中第一个条目是下端点，第二个条目是上端点。级联放大因子 $g(\\theta)$ 是无量纲的，因此不需要物理单位。",
            "solution": "该问题具有科学依据，提法恰当且完整。我们可以开始求解。任务是首先推导最大似然估计量（MLEs）函数​​的渐近分布，然后利用此结果计算一个置信区间。完成此任务的核心理论工具是多元 delta 方法。\n\n设参数向量为 $\\theta = (\\alpha, \\beta)^{\\top}$。MLE 为 $\\hat{\\theta} = (\\hat{\\alpha}, \\hat{\\beta})^{\\top}$。问题陈述，在标准条件下，MLE 是渐近正态的。这通常表示为 $\\sqrt{n}(\\hat{\\theta} - \\theta) \\xrightarrow{d} \\mathcal{N}(0, \\Sigma)$，其中 $\\Sigma$ 是渐近协方差矩阵。对于大样本量 $n$，这意味着 $\\hat{\\theta}$ 的近似分布为 $\\mathcal{N}(\\theta, \\text{Cov}(\\hat{\\theta}))$，其中 $\\text{Cov}(\\hat{\\theta})$ 是特定样本量的协方差矩阵，由 $\\widehat{\\text{Cov}}(\\hat{\\theta})$ 估计。\n\n性能泛函由 $g(\\theta) = g(\\alpha, \\beta) = \\frac{\\exp(\\beta)}{1 - \\alpha \\beta^{2}}$ 给出。我们感兴趣的是 $g(\\hat{\\theta})$ 的分布。delta 方法为随机变量函数的方差提供了一阶泰勒近似。如果 $\\hat{\\theta}$ 近似服从 $\\mathcal{N}(\\theta, \\text{Cov}(\\hat{\\theta}))$，那么对于一个可微函数 $g$，随机变量 $g(\\hat{\\theta})$ 近似服从正态分布，其均值为 $g(\\theta)$，方差为 $\\nabla g(\\theta)^{\\top} \\text{Cov}(\\hat{\\theta}) \\nabla g(\\theta)$。\n因此，$g(\\hat{\\theta}) \\stackrel{\\cdot}{\\sim} \\mathcal{N}\\left(g(\\theta), \\nabla g(\\theta)^{\\top} \\text{Cov}(\\hat{\\theta}) \\nabla g(\\theta)\\right)$。\n极限均值为 $g(\\theta)$，极限方差为 $\\sigma_g^2 = \\nabla g(\\theta)^{\\top} \\text{Cov}(\\hat{\\theta}) \\nabla g(\\theta)$。\n\n要应用此方法，我们必须首先计算 $g(\\alpha, \\beta)$ 的梯度，即 $\\nabla g = \\left(\\frac{\\partial g}{\\partial \\alpha}, \\frac{\\partial g}{\\partial \\beta}\\right)^{\\top}$。\n\n关于 $\\alpha$ 的偏导数是：\n$$\n\\frac{\\partial g}{\\partial \\alpha} = \\frac{\\partial}{\\partial \\alpha} \\left( \\exp(\\beta) (1 - \\alpha \\beta^2)^{-1} \\right) = \\exp(\\beta) \\left( -1 \\cdot (1 - \\alpha \\beta^2)^{-2} \\cdot (-\\beta^2) \\right) = \\frac{\\beta^2 \\exp(\\beta)}{(1 - \\alpha \\beta^2)^2}\n$$\n\n关于 $\\beta$ 的偏导数是使用商法则求得的：\n$$\n\\frac{\\partial g}{\\partial \\beta} = \\frac{(\\frac{d}{d\\beta}\\exp(\\beta))(1 - \\alpha \\beta^2) - \\exp(\\beta)(\\frac{d}{d\\beta}(1 - \\alpha \\beta^2))}{(1 - \\alpha \\beta^2)^2} = \\frac{\\exp(\\beta)(1 - \\alpha \\beta^2) - \\exp(\\beta)(-2 \\alpha \\beta)}{(1 - \\alpha \\beta^2)^2} = \\frac{\\exp(\\beta)(1 - \\alpha \\beta^2 + 2 \\alpha \\beta)}{(1 - \\alpha \\beta^2)^2}\n$$\n\n因此，梯度向量是：\n$$\n\\nabla g(\\theta) = \\begin{pmatrix} \\frac{\\beta^2 \\exp(\\beta)}{(1 - \\alpha \\beta^2)^2} \\\\ \\frac{\\exp(\\beta)(1 + 2 \\alpha \\beta - \\alpha \\beta^2)}{(1 - \\alpha \\beta^2)^2} \\end{pmatrix}\n$$\n$g(\\hat{\\theta})$ 的渐近方差由二次型 $\\sigma_g^2 = \\nabla g(\\theta)^{\\top} \\text{Cov}(\\hat{\\theta}) \\nabla g(\\theta)$ 给出。这完成了问题的第一部分。\n\n对于第二部分，我们计算 $g(\\theta)$ 的 $95\\%$ 置信区间。$g(\\theta)$ 的一个近似 $(1 - \\gamma) \\times 100\\%$ 置信区间构造为 $g(\\hat{\\theta}) \\pm z_{\\gamma/2} \\widehat{\\text{SE}}(g(\\hat{\\theta}))$。标准误 $\\widehat{\\text{SE}}(g(\\hat{\\theta})) = \\sqrt{\\widehat{\\text{Var}}(g(\\hat{\\theta}))}$ 是通过将 MLEs 代入方差公式来估计的：\n$$\n\\widehat{\\text{Var}}(g(\\hat{\\theta})) = \\nabla g(\\hat{\\theta})^{\\top} \\widehat{\\text{Cov}}(\\hat{\\theta}) \\nabla g(\\hat{\\theta})\n$$\n对于 $95\\%$ 的置信水平，$\\gamma = 0.05$，所以 $\\gamma/2 = 0.025$。相应的标准正态分位数为 $z_{0.025} \\approx 1.96$。\n\n我们已知拟合值和估计的协方差：\n$$\n\\hat{\\alpha} = 0.3, \\quad \\hat{\\beta} = 0.8, \\quad \\widehat{\\mathrm{Cov}}(\\hat{\\theta}) = \\begin{pmatrix} 0.0016 & -0.0003 \\\\ -0.0003 & 0.0025 \\end{pmatrix}\n$$\n设 $\\hat{\\sigma}_\\alpha^2 = 0.0016$，$\\hat{\\sigma}_\\beta^2 = 0.0025$ 和 $\\hat{\\sigma}_{\\alpha\\beta} = -0.0003$。\n\n首先，我们计算点估计 $g(\\hat{\\theta})$：\n$$\ng(\\hat{\\alpha}, \\hat{\\beta}) = \\frac{\\exp(0.8)}{1 - (0.3)(0.8)^2} = \\frac{\\exp(0.8)}{1 - 0.3(0.64)} = \\frac{\\exp(0.8)}{1 - 0.192} = \\frac{\\exp(0.8)}{0.808} \\approx 2.754382\n$$\n\n接下来，我们在点估计 $(\\hat{\\alpha}, \\hat{\\beta})$ 处计算梯度：\n梯度分量的分母是 $(1 - \\hat{\\alpha}\\hat{\\beta}^2)^2 = (0.808)^2 \\approx 0.652864$。\n$$\n\\frac{\\partial g}{\\partial \\alpha}\\bigg|_{\\hat{\\theta}} = \\frac{(0.8)^2 \\exp(0.8)}{(0.808)^2} = \\frac{0.64 \\exp(0.8)}{0.652864} \\approx 2.181650\n$$\n$$\n\\frac{\\partial g}{\\partial \\beta}\\bigg|_{\\hat{\\theta}} = \\frac{\\exp(0.8)(1 + 2(0.3)(0.8) - (0.3)(0.8)^2)}{(0.808)^2} = \\frac{\\exp(0.8)(1 + 0.48 - 0.192)}{0.652864} = \\frac{\\exp(0.8)(1.288)}{0.652864} \\approx 4.392342\n$$\n因此，$\\nabla g(\\hat{\\theta}) \\approx \\begin{pmatrix} 2.181650 \\\\ 4.392342 \\end{pmatrix}$。\n\n现在，我们计算 $g(\\hat{\\theta})$ 的估计方差：\n$$\n\\widehat{\\text{Var}}(g(\\hat{\\theta})) = \\begin{pmatrix} 2.181650 & 4.392342 \\end{pmatrix} \\begin{pmatrix} 0.0016 & -0.0003 \\\\ -0.0003 & 0.0025 \\end{pmatrix} \\begin{pmatrix} 2.181650 \\\\ 4.392342 \\end{pmatrix}\n$$\n$$\n\\widehat{\\text{Var}}(g(\\hat{\\theta})) = \\left(\\frac{\\partial g}{\\partial \\alpha}\\right)^2 \\hat{\\sigma}_\\alpha^2 + \\left(\\frac{\\partial g}{\\partial \\beta}\\right)^2 \\hat{\\sigma}_\\beta^2 + 2\\left(\\frac{\\partial g}{\\partial \\alpha}\\right)\\left(\\frac{\\partial g}{\\partial \\beta}\\right)\\hat{\\sigma}_{\\alpha\\beta}\n$$\n$$\n\\widehat{\\text{Var}}(g(\\hat{\\theta})) \\approx (2.181650)^2(0.0016) + (4.392342)^2(0.0025) + 2(2.181650)(4.392342)(-0.0003)\n$$\n$$\n\\widehat{\\text{Var}}(g(\\hat{\\theta})) \\approx (4.75959)(0.0016) + (19.29266)(0.0025) - 2(9.58281)(0.0003)\n$$\n$$\n\\widehat{\\text{Var}}(g(\\hat{\\theta})) \\approx 0.0076153 + 0.0482317 - 0.0057497 \\approx 0.0500973\n$$\n\n估计的标准误是方差的平方根：\n$$\n\\widehat{\\text{SE}}(g(\\hat{\\theta})) = \\sqrt{0.0500973} \\approx 0.2238243\n$$\n\n$95\\%$ 置信区间的误差范围是 $z_{0.025} \\times \\widehat{\\text{SE}}(g(\\hat{\\theta}))$：\n$$\n\\text{ME} \\approx 1.959964 \\times 0.2238243 \\approx 0.438686\n$$\n\n最后，$g(\\theta)$ 的 $95\\%$ 置信区间是：\n下界：$g(\\hat{\\theta}) - \\text{ME} \\approx 2.754382 - 0.438686 = 2.315696$\n上界：$g(\\hat{\\theta}) + \\text{ME} \\approx 2.754382 + 0.438686 = 3.193068$\n\n将两个端点四舍五入到四位有效数字：\n下界：$2.316$\n上界：$3.193$\n\n置信区间表示为一个行向量。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2.316 & 3.193 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "在理解复杂系统时，我们不仅想知道输出的不确定性有多大，还想知道哪个输入因素是造成这种不确定性的主要“元凶”。全局敏感性分析（Global Sensitivity Analysis）正是为此而生的工具，它能帮助我们量化不同输入对输出方差的贡献。本练习  将带你处理一个更贴近现实的挑战：当输入变量因资源或物理约束而相互依赖时，如何准确计算索博尔指数（Sobol' indices）。这个实践将揭示约束条件如何深刻地改变我们对系统敏感性的理解。",
            "id": "4150979",
            "problem": "考虑一个程式化的复杂适应系统，其中有两个相互作用的智能体，其可控输入由随机向量 $\\mathbf{X} = (X_1, X_2)$ 表示。可行的联合适应受硬资源约束的限制，该约束建模为三角形域 $D = \\{(x_1,x_2) \\in \\mathbb{R}^2 : x_1 \\ge 0,\\, x_2 \\ge 0,\\, x_1 + x_2 \\le 1\\}$。假设系统在 $D$ 上均匀采样适应，即联合密度在 $D$ 上为常数，在其他地方为零。\n\n令标量系统输出为 $Y = f(X_1,X_2) = X_1 + X_2$。你需要通过推导和评估关于 $D$ 上约束输入律的一阶基于方差的敏感度指数（通常称为 Sobol' 指数），来量化硬约束如何改变对 $X_1$ 的基于方差的敏感度分配。\n\n仅从方差、条件期望、条件方差的核心定义，一阶基于方差的敏感度指数的定义，\n$$\nS_1 \\equiv \\frac{\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right)}{\\mathrm{Var}(Y)},\n$$\n以及 $D$ 上均匀测度的几何解释出发，完成以下任务：\n\n1. 推导由 $D$ 上的均匀分布导出的 $X_1$ 的边缘密度，以及在硬约束确定的可行区间上 $X_2 \\mid X_1 = x_1$ 的条件密度。\n2. 仅使用这些基本事实，在 $D$ 上的约束输入律下，推导 $\\mathbb{E}[Y \\mid X_1]$、$\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right)$ 和 $\\mathrm{Var}(Y)$。\n3. 根据推导出的量构造 $S_1$。提供其精确值。\n\n另外（最终数值无需计算），通过使用条件分布 $X_2 \\mid X_1 = x_1$ 在给定 $X_1$ 的情况下对条件独立副本对 $(Y, Y')$ 进行采样，提出一个在 $D$ 上的约束律下对 $\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right)$ 的无偏蒙特卡洛（Monte Carlo, MC）估计量。明确指出你的估计量需要哪些条件分布和边缘分布。\n\n提供 $S_1$ 的精确值作为你的最终答案。不要四舍五入。不需要单位。",
            "solution": "用户希望解决一个*复杂模型中的不确定性量化*领域的问题，这是*复杂适应系统建模*中的一个主题。\n\n### 步骤 1：提取已知条件\n-   **随机输入**: $\\mathbf{X} = (X_1, X_2)$\n-   **可行域**: $D = \\{(x_1,x_2) \\in \\mathbb{R}^2 : x_1 \\ge 0,\\, x_2 \\ge 0,\\, x_1 + x_2 \\le 1\\}$\n-   **输入分布**: 在域 $D$ 上均匀分布。联合概率密度函数（PDF），$p(x_1, x_2)$，在 $D$ 上为常数，在其他地方为 0。\n-   **系统输出**: $Y = f(X_1,X_2) = X_1 + X_2$\n-   **目标量**: 一阶基于方差的敏感度指数，$S_1 = \\frac{\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right)}{\\mathrm{Var}(Y)}$。\n-   **任务 1**: 推导 $X_1$ 的边缘密度 $p(x_1)$ 和给定 $X_1$ 时 $X_2$ 的条件密度 $p(x_2 \\mid x_1)$。\n-   **任务 2**: 使用基本定义推导 $\\mathbb{E}[Y \\mid X_1]$、$\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right)$ 和 $\\mathrm{Var}(Y)$。\n-   **任务 3**: 构造 $S_1$ 的精确值。\n-   **任务 4**: 提出一个基于条件独立副本的对 $\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right)$ 的无偏蒙特卡洛估计量。\n\n### 步骤 2：使用提取的已知条件进行验证\n这是概率论和全局敏感度分析中的一个标准问题。\n-   **科学依据**：该问题基于概率论和 Sobol' 敏感度指数的成熟数学框架。该模型虽然是程式化的，但在数学上是合理的。\n-   **适定性**：域、概率分布和输出函数都已明确定义。待推导的量是标准的统计度量。存在唯一且稳定的解。\n-   **客观性**：问题以精确、形式化的数学语言陈述，没有歧义或主观性陈述。\n该问题不违反任何无效性标准。它是一个适定的、自洽的、科学上有效的应用概率练习。\n\n### 步骤 3：结论与行动\n问题是**有效的**。将提供完整解答。\n\n### 解答推导\n\n分析首先定义输入 $(X_1, X_2)$ 的联合概率密度函数（PDF）。输入在域 $D$ 上均匀分布，该域是一个顶点为 $(0,0)$、$(1,0)$ 和 $(0,1)$ 的直角三角形。该三角形的面积为 $\\text{Area}(D) = \\frac{1}{2} \\times \\text{base} \\times \\text{height} = \\frac{1}{2} \\times 1 \\times 1 = \\frac{1}{2}$。\n由于分布是均匀的，联合 PDF $p(x_1, x_2)$ 在 $D$ 内的任何点都是 $D$ 面积的倒数，在其他地方则为 0。\n$$\np(x_1, x_2) =\n\\begin{cases}\n\\frac{1}{\\text{Area}(D)} = 2, & \\text{if } x_1 \\ge 0, x_2 \\ge 0, x_1+x_2 \\le 1 \\\\\n0, & \\text{otherwise}\n\\end{cases}\n$$\n\n**1. 边缘密度和条件密度的推导**\n\n为了求出 $X_1$ 的边缘密度 $p(x_1)$，我们将联合 PDF 对所有可能的 $x_2$ 值进行积分。对于给定的 $x_1 \\in [0, 1]$，变量 $x_2$ 被约束在区间 $[0, 1-x_1]$ 内。\n$$\np(x_1) = \\int_{-\\infty}^{\\infty} p(x_1, x_2) \\,dx_2 = \\int_0^{1-x_1} 2 \\,dx_2 = 2[x_2]_0^{1-x_1} = 2(1-x_1) \\quad \\text{for } x_1 \\in [0, 1]\n$$\n对于 $x_1$ 在 $[0, 1]$ 之外， $p(x_1)=0$。\n\n条件密度 $p(x_2 \\mid x_1)$ 由公式 $p(x_2 \\mid x_1) = \\frac{p(x_1, x_2)}{p(x_1)}$ 定义，其中 $p(x_1) > 0$。这对于 $x_1 \\in [0, 1)$ 是有效的。\n$$\np(x_2 \\mid x_1) = \\frac{2}{2(1-x_1)} = \\frac{1}{1-x_1} \\quad \\text{for } x_2 \\in [0, 1-x_1]\n$$\n这表明对于给定的值 $X_1=x_1$，随机变量 $X_2$ 在区间 $[0, 1-x_1]$ 上均匀分布。\n\n**2. 方差分量的推导**\n\n我们现在推导 $S_1$ 所需的量。\n\n首先，我们计算给定 $X_1$ 时 $Y$ 的条件期望。\n$$\n\\mathbb{E}[Y \\mid X_1 = x_1] = \\mathbb{E}[X_1 + X_2 \\mid X_1 = x_1] = x_1 + \\mathbb{E}[X_2 \\mid X_1 = x_1]\n$$\n由于以 $X_1=x_1$ 为条件的 $X_2$ 在 $[0, 1-x_1]$ 上均匀分布，其期望是该区间的中点：\n$$\n\\mathbb{E}[X_2 \\mid X_1 = x_1] = \\frac{0 + (1-x_1)}{2} = \\frac{1-x_1}{2}\n$$\n将其代回，我们得到：\n$$\n\\mathbb{E}[Y \\mid X_1 = x_1] = x_1 + \\frac{1-x_1}{2} = \\frac{2x_1 + 1 - x_1}{2} = \\frac{x_1+1}{2}\n$$\n量 $\\mathbb{E}[Y \\mid X_1]$ 是一个随机变量，它是 $X_1$ 的函数：$\\mathbb{E}[Y \\mid X_1] = \\frac{X_1+1}{2}$。\n\n接下来，我们计算其方差 $\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right)$。\n$$\n\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right) = \\mathrm{Var}\\!\\left(\\frac{X_1+1}{2}\\right) = \\mathrm{Var}\\!\\left(\\frac{1}{2}X_1 + \\frac{1}{2}\\right) = \\left(\\frac{1}{2}\\right)^2 \\mathrm{Var}(X_1) = \\frac{1}{4}\\mathrm{Var}(X_1)\n$$\n为了求出 $\\mathrm{Var}(X_1)$，我们首先需要 $\\mathbb{E}[X_1]$ 和 $\\mathbb{E}[X_1^2]$。使用边缘密度 $p(x_1)=2(1-x_1)$：\n$$\n\\mathbb{E}[X_1] = \\int_0^1 x_1 p(x_1) \\,dx_1 = \\int_0^1 x_1 \\cdot 2(1-x_1) \\,dx_1 = 2 \\int_0^1 (x_1 - x_1^2) \\,dx_1 = 2 \\left[\\frac{x_1^2}{2} - \\frac{x_1^3}{3}\\right]_0^1 = 2\\left(\\frac{1}{2} - \\frac{1}{3}\\right) = \\frac{1}{3}\n$$\n$$\n\\mathbb{E}[X_1^2] = \\int_0^1 x_1^2 p(x_1) \\,dx_1 = \\int_0^1 x_1^2 \\cdot 2(1-x_1) \\,dx_1 = 2 \\int_0^1 (x_1^2 - x_1^3) \\,dx_1 = 2 \\left[\\frac{x_1^3}{3} - \\frac{x_1^4}{4}\\right]_0^1 = 2\\left(\\frac{1}{3} - \\frac{1}{4}\\right) = \\frac{1}{6}\n$$\n现在我们计算 $X_1$ 的方差：\n$$\n\\mathrm{Var}(X_1) = \\mathbb{E}[X_1^2] - (\\mathbb{E}[X_1])^2 = \\frac{1}{6} - \\left(\\frac{1}{3}\\right)^2 = \\frac{1}{6} - \\frac{1}{9} = \\frac{3-2}{18} = \\frac{1}{18}\n$$\n因此，一阶条件方差为：\n$$\n\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right) = \\frac{1}{4}\\mathrm{Var}(X_1) = \\frac{1}{4} \\cdot \\frac{1}{18} = \\frac{1}{72}\n$$\n最后，我们计算总方差 $\\mathrm{Var}(Y)$。我们使用全方差公式：$\\mathrm{Var}(Y) = \\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right) + \\mathbb{E}\\left[\\mathrm{Var}(Y \\mid X_1)\\right]$。我们需要第二项。\n$$\n\\mathrm{Var}(Y \\mid X_1=x_1) = \\mathrm{Var}(x_1 + X_2 \\mid X_1=x_1) = \\mathrm{Var}(X_2 \\mid X_1=x_1)\n$$\n这是在 $[0, 1-x_1]$ 上均匀分布的方差。在 $[a,b]$ 上均匀分布的方差是 $\\frac{(b-a)^2}{12}$。\n$$\n\\mathrm{Var}(Y \\mid X_1=x_1) = \\frac{(1-x_1 - 0)^2}{12} = \\frac{(1-x_1)^2}{12}\n$$\n现在我们对这个量关于 $X_1$ 取期望：\n$$\n\\mathbb{E}\\left[\\mathrm{Var}(Y \\mid X_1)\\right] = \\mathbb{E}\\left[\\frac{(1-X_1)^2}{12}\\right] = \\frac{1}{12}\\mathbb{E}[(1-X_1)^2] = \\frac{1}{12}\\mathbb{E}[1 - 2X_1 + X_1^2]\n$$\n利用期望的线性性质以及我们先前得到的 $\\mathbb{E}[X_1]$ 和 $\\mathbb{E}[X_1^2]$ 的结果：\n$$\n\\mathbb{E}\\left[\\mathrm{Var(Y \\mid X_1)}\\right] = \\frac{1}{12}\\left(1 - 2\\mathbb{E}[X_1] + \\mathbb{E}[X_1^2]\\right) = \\frac{1}{12}\\left(1 - 2\\left(\\frac{1}{3}\\right) + \\frac{1}{6}\\right) = \\frac{1}{12}\\left(1 - \\frac{2}{3} + \\frac{1}{6}\\right) = \\frac{1}{12}\\left(\\frac{6-4+1}{6}\\right) = \\frac{1}{12}\\left(\\frac{3}{6}\\right) = \\frac{1}{24}\n$$\n总方差是：\n$$\n\\mathrm{Var}(Y) = \\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right) + \\mathbb{E}\\left[\\mathrm{Var}(Y \\mid X_1)\\right] = \\frac{1}{72} + \\frac{1}{24} = \\frac{1+3}{72} = \\frac{4}{72} = \\frac{1}{18}\n$$\n\n**3. 敏感度指数 $S_1$ 的构造**\n\n我们现在可以使用推导出的量来构造 Sobol' 指数 $S_1$。\n$$\nS_1 = \\frac{\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right)}{\\mathrm{Var}(Y)} = \\frac{1/72}{1/18} = \\frac{1}{72} \\times \\frac{18}{1} = \\frac{18}{72} = \\frac{1}{4}\n$$\n\n**4. 建议的蒙特卡洛估计量**\n\n为了构造 $V_1 = \\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right)$ 的无偏蒙特卡洛估计量，我们使用性质 $V_1 = \\mathrm{Cov}(Y, Y')$，其中 $Y = f(X_1, X_2)$ 和 $Y' = f(X_1, X'_2)$，而 $X_2$ 和 $X'_2$ 是从条件分布 $p(x_2 \\mid x_1)$ 中抽取的独立同分布样本。对于来自 $N$ 对样本 $(a_i, b_i)$ 的两个随机变量 $A$ 和 $B$，其协方差的无偏估计量是样本协方差：\n$$\n\\widehat{\\mathrm{Cov}}(A, B) = \\frac{1}{N-1} \\sum_{i=1}^N (a_i - \\bar{a})(b_i - \\bar{b})\n$$\n估计步骤如下：\n1.  对于 $i=1, \\dots, N$：\n    a. 从 $x_1 \\in [0, 1]$ 的边缘分布 $p(x_1) = 2(1-x_1)$ 中抽取一个样本 $x_1^{(i)}$。\n    b. 从条件分布 $p(x_2 \\mid X_1=x_1^{(i)})$（即在 $[0, 1-x_1^{(i)}]$ 上的均匀分布）中抽取两个独立样本 $x_2^{(i)}$ 和 $x_2^{\\prime(i)}$。\n    c. 计算模型输出 $y^{(i)} = f(x_1^{(i)}, x_2^{(i)})$ 和 $y^{\\prime(i)} = f(x_1^{(i)}, x_2^{\\prime(i)})$。\n\n2.  计算样本均值 $\\bar{y} = \\frac{1}{N} \\sum_{i=1}^N y^{(i)}$ 和 $\\bar{y}' = \\frac{1}{N} \\sum_{i=1}^N y^{\\prime(i)}$。\n\n3.  $V_1$ 的无偏估计量即为两组输出之间的样本协方差：\n$$\n\\hat{V}_1 = \\frac{1}{N-1} \\sum_{i=1}^N (y^{(i)} - \\bar{y})(y^{\\prime(i)} - \\bar{y}')\n$$\n该估计量对于 $\\mathrm{Var}\\!\\left(\\mathbb{E}[Y \\mid X_1]\\right)$ 是无偏的，并且依赖于能够从边缘分布 $p(x_1)$ 和条件分布 $p(x_2 \\mid x_1)$ 中进行采样，这些分布已在问题的第一部分中推导得出。",
            "answer": "$$\\boxed{\\frac{1}{4}}$$"
        },
        {
            "introduction": "贝叶斯推断是复杂模型不确定性量化的一个主流框架，而马尔可夫链蒙特卡洛（MCMC）方法是实现它的核心引擎。然而，MCMC本质上是一种模拟算法，我们必须审慎地评估其输出的可靠性，以确保我们得到的后验分布是可信的。本练习  将指导你亲手实现Gelman-Rubin诊断（也称为$\\hat{R}$统计量），这是检验MCMC收敛性的黄金标准。通过这个编码实践，你将学会如何判断模拟是否已经“收敛”，这是任何MCMC实践者都必须具备的关键诊断技能。",
            "id": "4150998",
            "problem": "您的任务是构建一个程序，为用于近似复杂自适应系统建模中参数后验的多个独立马尔可夫链计算单变量Gelman-Rubin收敛诊断（Gelman-Rubin也称为潜在尺度缩减因子）。您的目标是从第一性原理推导该诊断，并实现两个版本：经典Gelman-Rubin统计量和分割链Gelman-Rubin统计量。您还必须解释这两种诊断的可靠性阈值。\n\n从以下基本基础开始：样本均值和样本方差作为独立同分布抽样的期望值和方差的估计量，以及全方差定律。假设有 $N$ 条独立的链，每条链的长度为 $M$，其值为 $\\{x_{j,t}\\}$，其中 $j \\in \\{1,\\dots,N\\}$ 是链的索引，$t \\in \\{1,\\dots,M\\}$ 是时间的索引。令链特定样本均值为 $m_{j} = \\frac{1}{M}\\sum_{t=1}^{M} x_{j,t}$，链特定样本方差为 $s_{j}^{2} = \\frac{1}{M-1}\\sum_{t=1}^{M} (x_{j,t} - m_{j})^{2}$，合并均值为 $\\bar{m} = \\frac{1}{N}\\sum_{j=1}^{N} m_{j}$。链间方差定义为\n$$\nB = \\frac{M}{N-1} \\sum_{j=1}^{N} (m_{j} - \\bar{m})^{2},\n$$\n链内方差为\n$$\nW = \\frac{1}{N} \\sum_{j=1}^{N} s_{j}^{2}.\n$$\n边际后验方差估计量为\n$$\n\\widehat{\\operatorname{Var}}^{+} = \\frac{M-1}{M}W + \\frac{1}{M}B,\n$$\n经典Gelman-Rubin统计量为\n$$\n\\hat{R} = \\sqrt{\\frac{\\widehat{\\operatorname{Var}}^{+}}{W}}.\n$$\n分割链Gelman-Rubin统计量，记为 $\\hat{R}_{\\mathrm{split}}$，通过将每条链分成长度为 $M/2$ 的两半（假设 $M$ 为偶数），得到 $2N$ 条链，然后应用相同的公式，将 $M$ 替换为 $M/2$，将 $N$ 替换为 $2N$ 来计算 $\\hat{R}_{\\mathrm{split}}$。\n\n您必须实现 $\\hat{R}$ 和 $\\hat{R}_{\\mathrm{split}}$，并解释用于不确定性估计的两个可靠性阈值：\n- 一个常规阈值 $\\tau_{1} = 1.05$，以及\n- 一个严格阈值 $\\tau_{2} = 1.01$。\n对于每个测试用例，报告 $\\hat{R}$ 和 $\\hat{R}_{\\mathrm{split}}$ 以及两个布尔指示符：$\\hat{R}_{\\mathrm{split}} \\le \\tau_{1}$ 是否成立和 $\\hat{R}_{\\mathrm{split}} \\le \\tau_{2}$ 是否成立，您应将其解释为在相应阈值水平上，不确定性估计足够可靠。\n\n构建以下包含5个案例的确定性测试套件。对于所有案例，使用从零开始的时间索引 $t \\in \\{0,1,\\dots,M-1\\}$，并通过以下公式定义链值\n$$\nx_{j,t} = \\mu_{j} + A_{j} \\sin\\!\\left(2\\pi \\frac{k\\, t}{M} + \\phi_{j}\\right) + D_{j}\\left(2\\frac{t}{M} - 1\\right),\n$$\n参数 $(\\mu_{j}, A_{j}, \\phi_{j}, D_{j})$ 如下指定。角度以弧度为单位。所有整数计数和常量必须完全按照给定的方式使用。\n\n测试套件：\n- 案例1：$N=4$, $M=200$, $k=5$。相位 $\\phi_{j} \\in \\{0, \\frac{\\pi}{8}, \\frac{\\pi}{4}, \\frac{3\\pi}{8}\\}$ 按链索引顺序排列。对于所有链，$\\mu_{j}=0$, $A_{j}=1$, $D_{j}=0$。\n- 案例2：$N=4$, $M=200$, $k=5$。相位如案例1所示。对于链 $j \\in \\{1,2,3\\}$，$\\mu_{j}=0$, $A_{j}=1$, $D_{j}=0$。对于链 $j=4$，$\\mu_{4}=1.5$, $A_{4}=1$, $D_{4}=0$。\n- 案例3：$N=4$, $M=200$, $k=5$。链：\n  - $j=1$：$\\mu_{1}=0$, $A_{1}=1$, $\\phi_{1}=0$, $D_{1}=0$；\n  - $j=2$：$\\mu_{2}=0$, $A_{2}=1$, $\\phi_{2}=\\frac{\\pi}{3}$, $D_{2}=0$；\n  - $j=3$：$\\mu_{3}=0$, $A_{3}=0.5$, $\\phi_{3}=\\frac{\\pi}{7}$, $D_{3}=0.9$；\n  - $j=4$：$\\mu_{4}=0$, $A_{4}=0.5$, $\\phi_{4}=\\frac{\\pi}{5}$, $D_{4}=-0.9$。\n- 案例4：$N=4$, $M=10$, $k=1$。相位 $\\phi_{j} \\in \\{0, \\frac{\\pi}{8}, \\frac{\\pi}{4}, \\frac{3\\pi}{8}\\}$。对于所有链，$\\mu_{j}=0$, $A_{j}=1$, $D_{j}=0$。\n- 案例5：$N=4$, $M=200$, $k=5$。相位如案例1所示。链 $j \\in \\{1,2\\}$ 使用 $A_{j}=1$，链 $j \\in \\{3,4\\}$ 使用 $A_{j}=3$。对于所有链，$\\mu_{j}=0$, $D_{j}=0$。\n\n计算和输出要求：\n- 对于每个案例，计算经典Gelman-Rubin统计量 $\\hat{R}$、分割链统计量 $\\hat{R}_{\\mathrm{split}}$，以及两个布尔值，分别表示 $\\hat{R}_{\\mathrm{split}} \\le \\tau_{1}$ 和 $\\hat{R}_{\\mathrm{split}} \\le \\tau_{2}$ 是否成立，其中 $\\tau_{1} = 1.05$ 和 $\\tau_{2} = 1.01$。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的扁平列表，其顺序为 $[\\hat{R}_{1}, \\hat{R}_{\\mathrm{split},1}, b_{1}^{(1.05)}, b_{1}^{(1.01)}, \\hat{R}_{2}, \\hat{R}_{\\mathrm{split},2}, b_{2}^{(1.05)}, b_{2}^{(1.01)}, \\dots, \\hat{R}_{5}, \\hat{R}_{\\mathrm{split},5}, b_{5}^{(1.05)}, b_{5}^{(1.01)}]$，其中 $\\hat{R}_{i}$ 和 $\\hat{R}_{\\mathrm{split},i}$ 是浮点数，$b_{i}^{(1.05)}$ 和 $b_{i}^{(1.01)}$ 是布尔值。\n- 此问题不涉及物理单位。",
            "solution": "在尝试解决方案之前，需要对问题进行验证。\n\n### 第一步：提取已知条件\n\n- **目标**：计算经典Gelman-Rubin统计量（$\\hat{R}$）和分割链Gelman-Rubin统计量（$\\hat{R}_{\\mathrm{split}}$）。\n- **输入**：$N$ 条独立的马尔可夫链，每条链的长度为 $M$。一条链的数据为 $\\{x_{j,t}\\}$，其中链索引 $j \\in \\{1,\\dots,N\\}$，时间索引 $t \\in \\{1,\\dots,M\\}$。\n- **定义**：\n  - 链特定样本均值：$m_{j} = \\frac{1}{M}\\sum_{t=1}^{M} x_{j,t}$\n  - 链特定样本方差：$s_{j}^{2} = \\frac{1}{M-1}\\sum_{t=1}^{M} (x_{j,t} - m_{j})^{2}$\n  - 合并均值：$\\bar{m} = \\frac{1}{N}\\sum_{j=1}^{N} m_{j}$\n- **公式**：\n  - 链间方差：$B = \\frac{M}{N-1} \\sum_{j=1}^{N} (m_{j} - \\bar{m})^{2}$\n  - 链内方差：$W = \\frac{1}{N} \\sum_{j=1}^{N} s_{j}^{2}$\n  - 边际后验方差估计量：$\\widehat{\\operatorname{Var}}^{+} = \\frac{M-1}{M}W + \\frac{1}{M}B$\n  - 经典Gelman-Rubin统计量：$\\hat{R} = \\sqrt{\\frac{\\widehat{\\operatorname{Var}}^{+}}{W}}$\n- **分割链统计量（$\\hat{R}_{\\mathrm{split}}$）**：将每条长度为 $M$ 的链分成长度为 $M/2$ 的两半（假设 $M$ 为偶数）。这将产生 $2N$ 条链。然后用 $N$ 替换为 $2N$，$M$ 替换为 $M/2$ 来应用相同的公式。\n- **可靠性阈值**：\n  - 常规阈值：$\\tau_{1} = 1.05$\n  - 严格阈值：$\\tau_{2} = 1.01$\n- **链数据生成**：\n  - 时间索引：$t \\in \\{0,1,\\dots,M-1\\}$\n  - 公式：$x_{j,t} = \\mu_{j} + A_{j} \\sin\\!\\left(2\\pi \\frac{k\\, t}{M} + \\phi_{j}\\right) + D_{j}\\left(2\\frac{t}{M} - 1\\right)$\n- **测试套件**：\n  - 案例1：$N=4$, $M=200$, $k=5$。$\\phi_{j} \\in \\{0, \\frac{\\pi}{8}, \\frac{\\pi}{4}, \\frac{3\\pi}{8}\\}$。对于所有链，$\\mu_{j}=0$, $A_{j}=1$, $D_{j}=0$。\n  - 案例2：$N=4$, $M=200$, $k=5$。$\\phi_{j}$ 如案例1所示。对于 $j \\in \\{1,2,3\\}$：$\\mu_{j}=0, A_{j}=1, D_{j}=0$。对于 $j=4$：$\\mu_{4}=1.5, A_{4}=1, D_{4}=0$。\n  - 案例3：$N=4$, $M=200$, $k=5$。\n    - $j=1$：$\\mu_{1}=0, A_{1}=1, \\phi_{1}=0, D_{1}=0$。\n    - $j=2$：$\\mu_{2}=0, A_{2}=1, \\phi_{2}=\\frac{\\pi}{3}, D_{2}=0$。\n    - $j=3$：$\\mu_{3}=0, A_{3}=0.5, \\phi_{3}=\\frac{\\pi}{7}, D_{3}=0.9$。\n    - $j=4$：$\\mu_{4}=0, A_{4}=0.5, \\phi_{4}=\\frac{\\pi}{5}, D_{4}=-0.9$。\n  - 案例4：$N=4$, $M=10$, $k=1$。$\\phi_{j}$ 如案例1所示。对于所有链，$\\mu_{j}=0, A_{j}=1, D_{j}=0$。\n  - 案例5：$N=4$, $M=200$, $k=5$。$\\phi_{j}$ 如案例1所示。对于 $j \\in \\{1,2\\}$：$A_{j}=1$。对于 $j \\in \\{3,4\\}$：$A_{j}=3$。对于所有链，$\\mu_{j}=0, D_{j}=0$。\n- **输出要求**：一个单行、逗号分隔的扁平列表：$[\\hat{R}_{1}, \\hat{R}_{\\mathrm{split},1}, b_{1}^{(1.05)}, b_{1}^{(1.01)}, \\dots]$，其中 $b$ 是 $\\hat{R}_{\\mathrm{split}} \\le \\tau$ 的布尔值。\n\n### 第二步：使用提取的已知条件进行验证\n\n根据验证标准对问题进行审查。\n\n1.  **科学或事实不健全性**：Gelman-Rubin诊断是贝叶斯统计中评估马尔可夫链蒙特卡洛（MCMC）模拟收敛性的标准、成熟方法。提供的 $W$、$B$、$\\widehat{\\operatorname{Var}}^{+}$ 和 $\\hat{R}$ 的公式是正确的，直接取自统计文献。使用确定性的正弦测试数据代替随机的MCMC输出是一种抽象，但它有助于创建一个定义明确的数值问题来测试算法的实现。这不违反任何科学原理；它仅仅是为了练习的目的简化了数据生成过程。\n2.  **非形式化或不相关**：该问题高度形式化，并直接涉及不确定性量化，这是复杂系统建模的核心主题。Gelman-Rubin统计量是确保从MCMC获得的后验分布可靠性的关键工具，这些后验分布用于量化参数不确定性。\n3.  **不完整或矛盾的设置**：计算所需的所有参数、常量和公式都已明确提供。测试用例已完全指定。没有矛盾之处。\n4.  **不现实或不可行**：计算在数值上是可行的。参数在合理的计算范围内。\n5.  **不适定或结构不良**：该问题是适定的。对于给定的确定性输入，存在唯一的数值解。定义明确。\n6.  **伪深刻、琐碎或同义反复**：该问题要求仔细并正确地实现一个非平凡的统计算法。它涉及基于既定理论的几个不同计算步骤，使其成为一项实质性任务。\n7.  **超出科学可验证性范围**：结果在数值上是确定性的，可以独立验证。\n\n### 第三步：结论与行动\n\n问题是**有效的**。这是一个定义明确、有科学依据的计算问题。将提供完整的解决方案。\n\n### 基于原理的解决方案设计\n\nGelman-Rubin收敛诊断，或称潜在尺度缩减因子（$\\hat{R}$），是评估多个马尔可夫链是否收敛到一个共同平稳分布的基本工具。其基本原理是比较各条链内部的方差与链之间的方差。\n\n假设有 $N$ 条并行链，每条链有 $M$ 个预热后的样本 $\\{x_{j,t}\\}$，其中 $j$ 是链的索引（$1, \\dots, N$），$t$ 是样本的索引（$1, \\dots, M$）。\n\n1.  **链内方差（$W$）**：我们首先计算每条链内部的方差。第 $j$ 条链的样本方差由 $s_{j}^{2} = \\frac{1}{M-1}\\sum_{t=1}^{M} (x_{j,t} - m_{j})^{2}$ 给出，其中 $m_{j}$ 是第 $j$ 条链的均值。链内方差 $W = \\frac{1}{N} \\sum_{j=1}^{N} s_{j}^{2}$ 是这些单独方差的平均值。在模拟的早期阶段，当链尚未完全探索目标分布时，$W$ 往往会低估真实的后验方差。\n\n2.  **链间方差（$B$）**：接下来，我们计算各链均值之间的方差。使用合并均值 $\\bar{m} = \\frac{1}{N}\\sum_{j=1}^{N} m_{j}$，链间方差为 $B = \\frac{M}{N-1} \\sum_{j=1}^{N} (m_{j} - \\bar{m})^{2}$。因子 $M$ 对 $B$ 进行缩放，使其与 $W$ 具有可比性。如果链尚未收敛，它们的均值 $m_j$ 将会分散，导致 $B$ 的值很大。当它们收敛到同一分布时，它们的均值将相互接近，$B$ 将趋近于零。\n\n3.  **后验方差估计量（$\\widehat{\\operatorname{Var}}^{+}$）**：通过组合 $W$ 和 $B$ 来构建参数的边际后验方差的估计值：$\\widehat{\\operatorname{Var}}^{+} = \\frac{M-1}{M}W + \\frac{1}{M}B$。这是链内方差和链间方差的加权平均。如果链从一个过度分散的分布开始，$\\widehat{\\operatorname{Var}}^{+}$ 会高估真实方差，这纠正了仅由 $W$ 提供的低估。\n\n4.  **潜在尺度缩减因子（$\\hat{R}$）**：Gelman-Rubin统计量是高估方差与低估方差之比：$\\hat{R} = \\sqrt{\\frac{\\widehat{\\operatorname{Var}}^{+}}{W}}$。随着模拟收敛，链之间的差异消失，导致 $B$ 变小。因此，$\\widehat{\\operatorname{Var}}^{+}$ 接近 $W$，$\\hat{R}$ 接近 $1$。$\\hat{R}$ 值远大于 $1$ 表示链内方差和链间方差不同，表明未收敛。\n\n5.  **分割链统计量（$\\hat{R}_{\\mathrm{split}}$）**：此变体解决了链内潜在的非平稳性问题。将 $N$ 条长度为 $M$ 的链中的每一条都分割成两个不重叠的一半，从而创建一个新的包含 $2N$ 条链的集合，每条链的长度为 $M/2$。然后为这个新的链集合计算 $\\hat{R}$ 统计量。$\\hat{R}_{\\mathrm{split}}$ 的值接近 $1$ 表明链的前半部分和后半部分在统计上是相似的，为平稳性提供了证据。\n\n### 算法实现\n\n将设计一个辅助函数，用于计算给定链集合（表示为二维数组）的 $\\hat{R}$。对于每个测试用例，此函数将被调用两次：一次使用原始链计算 $\\hat{R}$，一次使用分割后的链计算 $\\hat{R}_{\\mathrm{split}}$。\n\n对于每个测试用例，将首先根据指定的确定性公式生成链数据 $x_{j,t}$。主循环将遍历五个测试用例，对每个用例执行以下步骤：\n1.  生成链数据的 $N \\times M$ 矩阵。\n2.  使用完整矩阵计算 $\\hat{R}$。\n3.  将矩阵分成两半，创建一个 $2N \\times (M/2)$ 的矩阵。\n4.  使用分割后的矩阵计算 $\\hat{R}_{\\mathrm{split}}$。\n5.  评估布尔条件 $\\hat{R}_{\\mathrm{split}} \\le \\tau_{1}$（其中 $\\tau_1=1.05$）和 $\\hat{R}_{\\mathrm{split}} \\le \\tau_{2}$（其中 $\\tau_2=1.01$）。\n6.  收集四个结果值：$\\hat{R}$、$\\hat{R}_{\\mathrm{split}}$ 和两个布尔值。\n\n所有测试用例的最终结果列表将被扁平化并格式化为所需的输出字符串。所有计算将使用 `numpy` 库以确保效率和正确性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes Gelman-Rubin diagnostics for a deterministic test suite.\n    \"\"\"\n\n    def _calculate_r_hat(chains: np.ndarray) -> float:\n        \"\"\"\n        Calculates the Gelman-Rubin statistic for a set of chains.\n\n        Args:\n            chains: A 2D numpy array of shape (N, M) where N is the number of\n                    chains and M is the length of each chain.\n\n        Returns:\n            The Gelman-Rubin statistic R-hat.\n        \"\"\"\n        if chains.ndim != 2:\n            raise ValueError(\"Input `chains` must be a 2D array.\")\n        \n        N, M = chains.shape\n        \n        if N < 2:\n            # Cannot compute between-chain variance with fewer than 2 chains.\n            # In a converged state, R-hat should be 1.\n            return 1.0\n\n        # Calculate chain-specific means\n        m_j = np.mean(chains, axis=1)\n\n        # Calculate chain-specific sample variances (ddof=1 for sample variance)\n        s_j_sq = np.var(chains, axis=1, ddof=1)\n\n        # Calculate within-chain variance W\n        W = np.mean(s_j_sq)\n\n        # If W is zero, all chains are constant.\n        if W == 0:\n            # If all chain means are also equal, B is 0, converged.\n            if np.all(m_j == m_j[0]):\n                return 1.0\n            # Otherwise, chains are at different constants, not converged.\n            else:\n                return np.inf\n\n        # Calculate pooled mean\n        m_bar = np.mean(m_j)\n\n        # Calculate between-chain variance B\n        B = (M / (N - 1)) * np.sum((m_j - m_bar)**2)\n        \n        # Calculate marginal posterior variance estimator\n        var_plus = ((M - 1) / M) * W + (1 / M) * B\n\n        # Calculate Gelman-Rubin statistic R-hat\n        r_hat = np.sqrt(var_plus / W)\n\n        return r_hat\n\n    # Define the reliability thresholds\n    tau1 = 1.05\n    tau2 = 1.01\n\n    # Define the 5 test cases\n    test_cases = [\n        # Case 1\n        {\n            \"N\": 4, \"M\": 200, \"k\": 5,\n            \"params\": [\n                {\"mu\": 0, \"A\": 1, \"phi\": 0 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0, \"A\": 1, \"phi\": 1 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0, \"A\": 1, \"phi\": 2 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0, \"A\": 1, \"phi\": 3 * np.pi / 8, \"D\": 0},\n            ]\n        },\n        # Case 2\n        {\n            \"N\": 4, \"M\": 200, \"k\": 5,\n            \"params\": [\n                {\"mu\": 0,   \"A\": 1, \"phi\": 0 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0,   \"A\": 1, \"phi\": 1 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0,   \"A\": 1, \"phi\": 2 * np.pi / 8, \"D\": 0},\n                {\"mu\": 1.5, \"A\": 1, \"phi\": 3 * np.pi / 8, \"D\": 0},\n            ]\n        },\n        # Case 3\n        {\n            \"N\": 4, \"M\": 200, \"k\": 5,\n            \"params\": [\n                {\"mu\": 0, \"A\": 1.0, \"phi\": 0 * np.pi/7, \"D\":  0.0},\n                {\"mu\": 0, \"A\": 1.0, \"phi\": 1 * np.pi/3, \"D\":  0.0},\n                {\"mu\": 0, \"A\": 0.5, \"phi\": 1 * np.pi/7, \"D\":  0.9},\n                {\"mu\": 0, \"A\": 0.5, \"phi\": 1 * np.pi/5, \"D\": -0.9},\n            ]\n        },\n        # Case 4\n        {\n            \"N\": 4, \"M\": 10, \"k\": 1,\n            \"params\": [\n                {\"mu\": 0, \"A\": 1, \"phi\": 0 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0, \"A\": 1, \"phi\": 1 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0, \"A\": 1, \"phi\": 2 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0, \"A\": 1, \"phi\": 3 * np.pi / 8, \"D\": 0},\n            ]\n        },\n        # Case 5\n        {\n            \"N\": 4, \"M\": 200, \"k\": 5,\n            \"params\": [\n                {\"mu\": 0, \"A\": 1, \"phi\": 0 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0, \"A\": 1, \"phi\": 1 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0, \"A\": 3, \"phi\": 2 * np.pi / 8, \"D\": 0},\n                {\"mu\": 0, \"A\": 3, \"phi\": 3 * np.pi / 8, \"D\": 0},\n            ]\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        N, M, k = case[\"N\"], case[\"M\"], case[\"k\"]\n        params = case[\"params\"]\n        \n        # Generate chain data\n        t = np.arange(M)\n        chains = np.zeros((N, M))\n        for j in range(N):\n            p = params[j]\n            mu_j, A_j, phi_j, D_j = p[\"mu\"], p[\"A\"], p[\"phi\"], p[\"D\"]\n            chains[j, :] = mu_j + A_j * np.sin(2 * np.pi * k * t / M + phi_j) \\\n                           + D_j * (2 * t / M - 1)\n\n        # Calculate classical R-hat\n        r_hat = _calculate_r_hat(chains)\n        \n        # Calculate split-chain R-hat\n        if M % 2 != 0:\n            raise ValueError(f\"M must be even for split-chain analysis. M={M}\")\n        \n        M_half = M // 2\n        chains_split1 = chains[:, :M_half]\n        chains_split2 = chains[:, M_half:]\n        split_chains = np.vstack((chains_split1, chains_split2))\n        \n        r_hat_split = _calculate_r_hat(split_chains)\n        \n        # Perform threshold checks\n        b1 = r_hat_split <= tau1\n        b2 = r_hat_split <= tau2\n        \n        # Append results for this case\n        results.extend([r_hat, r_hat_split, b1, b2])\n\n    # Format output string\n    formatted_results = [f\"{x:.10f}\" if isinstance(x, float) else str(x) for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}