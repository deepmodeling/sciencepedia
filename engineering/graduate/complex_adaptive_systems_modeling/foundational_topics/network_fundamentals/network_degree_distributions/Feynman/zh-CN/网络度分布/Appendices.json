{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握网络科学中的概念，必须从其最基本的模型开始。第一个练习将带您回到随机图论的基石——Erdős–Rényi (ER) 模型。通过直接从模型的概率定义推导度分布的均值和方差，您将为在网络环境中使用随机变量和期望建立基础技能 。这项练习对于理解更复杂网络模型所偏离的基线行为至关重要。",
            "id": "4132834",
            "problem": "考虑由 Erdős–Rényi 模型 $G(N,p)$ 生成的无向简单随机图：图中存在 $N$ 个已标记的节点，并且 $\\binom{N}{2}$ 条可能的边中的每一条都以概率 $p$ 独立地被包含，其中 $0  p  1$。\n对于图中的一个固定节点 $i$，推导其度 $k_i$ 的一阶矩 $\\langle k_i \\rangle$、二阶矩 $\\langle k_i^2 \\rangle$ 和方差 $\\operatorname{Var}(k_i)$ 的精确符号表达式。",
            "solution": "该问题陈述经核实具有科学依据、问题明确且客观。这是随机图理论中的一个标准问题，所有必要的参数都已定义。我们可以开始求解。\n\n问题要求计算 Erdős–Rényi 图 $G(N, p)$ 中一个固定节点 $i$ 的度 $k_i$ 的一阶矩 $\\langle k_i \\rangle$、二阶矩 $\\langle k_i^2 \\rangle$ 和方差 $\\operatorname{Var}(k_i)$。该图有 $N$ 个节点，任何一对不同的节点都以独立的概率 $p$ 通过一条边相连。\n\n设节点集为 $V = \\{1, 2, \\dots, N\\}$。对于一个固定节点 $i \\in V$，其度 $k_i$ 是与它关联的边的数量。节点 $i$ 可以与其他 $N-1$ 个节点相连。设这些其他节点用 $j \\in V \\setminus \\{i\\}$ 来索引。\n\n为使问题形式化，我们使用指示随机变量。对于每个 $j \\in V$ 且 $j \\neq i$，令 $X_{ij}$ 为节点 $i$ 和节点 $j$ 之间存在边的事件的指示随机变量。根据 $G(N,p)$ 模型的定义：\n$$\nX_{ij} =\n\\begin{cases}\n1  \\text{如果 } i \\text{ 和 } j \\text{ 之间存在边（概率为 } p\\text{）} \\\\\n0  \\text{如果 } i \\text{ 和 } j \\text{ 之间不存在边（概率为 } 1-p\\text{）}\n\\end{cases}\n$$\n节点 $i$ 的度 $k_i$ 是对所有可能的邻居的这些指示变量求和：\n$$\nk_i = \\sum_{j \\in V, j \\neq i} X_{ij}\n$$\n该和包含 $N-1$ 项。\n\n首先，我们计算单个指示随机变量 $X_{ij}$ 的期望：\n$$\nE[X_{ij}] = 1 \\cdot P(X_{ij}=1) + 0 \\cdot P(X_{ij}=0) = 1 \\cdot p + 0 \\cdot (1-p) = p\n$$\n\n现在，我们可以推导度分布的一阶矩（均值），即 $\\langle k_i \\rangle = E[k_i]$。利用期望的线性性：\n$$\n\\langle k_i \\rangle = E[k_i] = E\\left[\\sum_{j \\neq i} X_{ij}\\right] = \\sum_{j \\neq i} E[X_{ij}]\n$$\n由于和中有 $N-1$ 项，且对于所有 $j \\neq i$ 都有 $E[X_{ij}] = p$，我们得到：\n$$\n\\langle k_i \\rangle = \\sum_{j \\neq i} p = (N-1)p\n$$\n\n接下来，我们推导二阶矩 $\\langle k_i^2 \\rangle = E[k_i^2]$。我们首先对 $k_i$ 的表达式进行平方：\n$$\nk_i^2 = \\left(\\sum_{j \\neq i} X_{ij}\\right)^2 = \\left(\\sum_{j \\neq i} X_{ij}\\right)\\left(\\sum_{l \\neq i} X_{il}\\right) = \\sum_{j \\neq i} \\sum_{l \\neq i} X_{ij}X_{il}\n$$\n我们可以将双重求和拆分为两种情况：当索引相同时（$j=l$）和当索引不同时（$j \\neq l$）。\n$$\nk_i^2 = \\sum_{j \\neq i} X_{ij}^2 + \\sum_{j \\neq i} \\sum_{l \\neq i, l \\neq j} X_{ij}X_{il}\n$$\n现在，我们对这个表达式取期望。利用期望的线性性：\n$$\n\\langle k_i^2 \\rangle = E[k_i^2] = E\\left[\\sum_{j \\neq i} X_{ij}^2\\right] + E\\left[\\sum_{j \\neq i} \\sum_{l \\neq i, l \\neq j} X_{ij}X_{il}\\right] = \\sum_{j \\neq i} E[X_{ij}^2] + \\sum_{j \\neq i} \\sum_{l \\neq i, l \\neq j} E[X_{ij}X_{il}]\n$$\n我们需要计算 $j \\neq l$ 时的期望 $E[X_{ij}^2]$ 和 $E[X_{ij}X_{il}]$。\n对于第一项，由于 $X_{ij}$ 是一个指示变量，它只能取值 $0$ 或 $1$。因此，$X_{ij}^2 = X_{ij}$。\n$$\nE[X_{ij}^2] = E[X_{ij}] = p\n$$\n对于第二项，其中涉及 $j \\neq l$ 时的 $X_{ij}$ 和 $X_{il}$，边 $(i,j)$ 和 $(i,l)$ 是不同的。根据问题定义，每条边的存在是一个独立事件。因此，随机变量 $X_{ij}$ 和 $X_{il}$ 是独立的。它们的乘积的期望等于它们各自期望的乘积：\n$$\nE[X_{ij}X_{il}] = E[X_{ij}] E[X_{il}] = p \\cdot p = p^2\n$$\n现在我们可以计算这些和。第一个和有 $N-1$ 项，每一项都等于 $p$：\n$$\n\\sum_{j \\neq i} E[X_{ij}^2] = (N-1)p\n$$\n第二个双重求和对应于来自集合 $V \\setminus \\{i\\}$ 的不同节点的有序对 $(j,l)$。这样的对的数量是 $(N-1)(N-2)$。这个和中的每一项都是 $p^2$：\n$$\n\\sum_{j \\neq i} \\sum_{l \\neq i, l \\neq j} E[X_{ij}X_{il}] = (N-1)(N-2)p^2\n$$\n综合这些结果，我们得到二阶矩的表达式：\n$$\n\\langle k_i^2 \\rangle = (N-1)p + (N-1)(N-2)p^2\n$$\n\n最后，我们使用标准公式 $\\operatorname{Var}(k_i) = \\langle k_i^2 \\rangle - \\langle k_i \\rangle^2$ 计算度的方差 $\\operatorname{Var}(k_i)$：\n$$\n\\operatorname{Var}(k_i) = \\left[(N-1)p + (N-1)(N-2)p^2\\right] - \\left[(N-1)p\\right]^2\n$$\n$$\n\\operatorname{Var}(k_i) = (N-1)p + (N-1)(N-2)p^2 - (N-1)^2p^2\n$$\n我们可以提出公因式 $(N-1)p$：\n$$\n\\operatorname{Var}(k_i) = (N-1)p \\left[1 + (N-2)p - (N-1)p\\right]\n$$\n$$\n\\operatorname{Var}(k_i) = (N-1)p \\left[1 + Np - 2p - Np + p\\right]\n$$\n$$\n\\operatorname{Var}(k_i) = (N-1)p \\left[1 - p\\right]\n$$\n这个结果与以下事实一致：$k_i$ 是 $N-1$ 次独立同分布的伯努利试验的和，这意味着 $k_i$ 服从参数为 $n=N-1$ 和 $p$ 的二项分布 $B(n, p)$。这种分布的方差确实是 $np(1-p)$。\n\n问题要求给出 $\\langle k_i \\rangle$、$\\langle k_i^2 \\rangle$ 和 $\\operatorname{Var}(k_i)$ 的最终精确符号表达式。\n推导出的表达式如下：\n$\\langle k_i \\rangle = (N-1)p$\n$\\langle k_i^2 \\rangle = (N-1)p + (N-1)(N-2)p^2$\n$\\operatorname{Var}(k_i) = (N-1)p(1-p)$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} (N-1)p,  (N-1)p + (N-1)(N-2)p^2,  (N-1)p(1-p) \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "真实世界的网络不仅仅是具有特定度的节点的集合；这些节点之间的连接方式至关重要。这个练习从单个节点的属性转向探索度相关性，这是网络拓扑学中一个被称为“同配性”的关键特征 。通过从给定的度分布和联合度分布计算同配性系数，您将学习如何量化一个网络是表现出同配性（高度数节点连接到高度数节点）还是异配性混合。",
            "id": "4132898",
            "problem": "考虑一个从稳态系综中抽取的大型、无向、简单网络。设其度分布为 $P(k)$，其中 $k \\in \\{1,2,3,4\\}$，具体值为 $P(1)=0.15$，$P(2)=0.35$，$P(3)=0.30$ 和 $P(4)=0.20$。令 $P(k,k')$ 表示一条均匀随机选择的边的两端节点的度分别为 $k$ 和 $k'$ 的概率（即联合端点度分布），该分布在 $k$ 和 $k'$ 上是对称的，并且满足 $\\sum_{k,k'} P(k,k')=1$。假设 $P(k,k')$ 由以下数值指定\n$P(1,1)=\\frac{1}{102}$，$P(1,2)=\\frac{4}{102}$，$P(1,3)=\\frac{1}{102}$，$P(1,4)=0$，$P(2,2)=\\frac{6}{102}$，$P(2,3)=\\frac{10}{102}$，$P(2,4)=\\frac{8}{102}$，$P(3,3)=\\frac{12}{102}$，$P(3,4)=\\frac{13}{102}$，以及 $P(4,4)=\\frac{11}{102}$，对于所有非对角线项，都有 $P(k',k)=P(k,k')$。\n\n仅使用以下基本定义：\n- 在一条均匀随机选择的边的端点上观察到的度的分布 $q_k$ 为 $q_k = \\frac{k P(k)}{\\langle k \\rangle}$，其中 $\\langle k \\rangle = \\sum_{k} k P(k)$。\n- 一条均匀随机选择的边的两端节点的度之间的皮尔逊相关系数，记为 $r$，定义为在联合分布 $P(k,k')$下，代表端点度的随机变量之间的相关性。\n\n从第一性原理出发，计算该网络的度同配系数 $r$。请用精确分数表示你的答案（不要四舍五入）。然后，根据 $r$ 的符号解释度的相关性（同配混合或异配混合）。该解释不影响最终数值答案的形式。",
            "solution": "题目要求计算一个给定度分布 $P(k)$ 和联合端点度分布 $P(k,k')$ 的网络的同配系数 $r$。同配系数定义为一条均匀随机选择的边的两端节点的度之间的皮尔逊相关系数。\n\n设 $K_1$ 和 $K_2$ 是表示一条随机选择的边的两个端点的度的随机变量。它们的联合分布是 $P(k,k')$。根据定义，皮尔逊相关系数 $r$ 为：\n$$ r = \\frac{\\operatorname{Cov}(K_1, K_2)}{\\sqrt{\\operatorname{Var}(K_1) \\operatorname{Var}(K_2)}} $$\n由于网络是无向的，$P(k,k')$ 是对称的，所以 $K_1$ 和 $K_2$ 的边缘分布是相同的。设这个边缘分布为 $q_k = P(K_1=k) = \\sum_{k'} P(k,k')$。因此，$\\operatorname{Var}(K_1) = \\operatorname{Var}(K_2) = \\sigma_q^2$，并且 $\\operatorname{Cov}(K_1, K_2) = E[K_1 K_2] - (E[K_1])^2$。\n公式简化为：\n$$ r = \\frac{E[K_1 K_2] - \\mu_q^2}{\\sigma_q^2} = \\frac{\\sum_{k,k'} k k' P(k,k') - \\left( \\sum_k k q_k \\right)^2}{\\sum_k k^2 q_k - \\left( \\sum_k k q_k \\right)^2} $$\n\n**第1步：验证并计算边缘分布 $q_k$**\n\n根据问题陈述，边缘分布 $q_k = \\frac{k P(k)}{\\langle k \\rangle}$。我们首先计算平均度 $\\langle k \\rangle$：\n$$ \\langle k \\rangle = \\sum_k k P(k) = 1(0.15) + 2(0.35) + 3(0.30) + 4(0.20) = 0.15 + 0.70 + 0.90 + 0.80 = 2.55 = \\frac{51}{20} $$\n现在我们可以计算 $q_k$：\n- $q_1 = \\frac{1 \\times 0.15}{2.55} = \\frac{15}{255} = \\frac{1}{17} = \\frac{6}{102}$\n- $q_2 = \\frac{2 \\times 0.35}{2.55} = \\frac{0.70}{2.55} = \\frac{70}{255} = \\frac{14}{51} = \\frac{28}{102}$\n- $q_3 = \\frac{3 \\times 0.30}{2.55} = \\frac{0.90}{2.55} = \\frac{90}{255} = \\frac{18}{51} = \\frac{36}{102}$\n- $q_4 = \\frac{4 \\times 0.20}{2.55} = \\frac{0.80}{2.55} = \\frac{80}{255} = \\frac{16}{51} = \\frac{32}{102}$\n$\\sum_k q_k = \\frac{6+28+36+32}{102} = \\frac{102}{102} = 1$。分布有效。\n\n**第2步：计算 $q_k$ 的均值 $\\mu_q$ 和方差 $\\sigma_q^2$**\n\n$q_k$ 的均值 $\\mu_q$ 是：\n$$ \\mu_q = E[K_1] = \\sum_k k q_k = 1\\left(\\frac{6}{102}\\right) + 2\\left(\\frac{28}{102}\\right) + 3\\left(\\frac{36}{102}\\right) + 4\\left(\\frac{32}{102}\\right) = \\frac{6 + 56 + 108 + 128}{102} = \\frac{298}{102} = \\frac{149}{51} $$\n为了计算方差，我们首先计算 $E[K_1^2]$：\n$$ E[K_1^2] = \\sum_k k^2 q_k = 1^2\\left(\\frac{6}{102}\\right) + 2^2\\left(\\frac{28}{102}\\right) + 3^2\\left(\\frac{36}{102}\\right) + 4^2\\left(\\frac{32}{102}\\right) = \\frac{6 + 112 + 324 + 512}{102} = \\frac{954}{102} = \\frac{159}{17} $$\n方差 $\\sigma_q^2$ 是：\n$$ \\sigma_q^2 = E[K_1^2] - \\mu_q^2 = \\frac{159}{17} - \\left(\\frac{149}{51}\\right)^2 = \\frac{159 \\cdot 3 \\cdot 51 - 149^2}{51^2} = \\frac{24327 - 22201}{2601} = \\frac{2126}{2601} $$\n\n**第3步：计算 $E[K_1 K_2]$**\n\n$$ E[K_1 K_2] = \\sum_{k,k'} k k' P(k,k') = \\sum_k k^2 P(k,k) + 2 \\sum_{kk'} k k' P(k,k') $$\n使用给定的 $P(k,k')$ 值：\n$$ E[K_1 K_2] = \\frac{1}{102} \\left( 1^2 \\cdot 1 + 2^2 \\cdot 6 + 3^2 \\cdot 12 + 4^2 \\cdot 11 \\right) + \\frac{2}{102} \\left( 1 \\cdot 2 \\cdot 4 + 1 \\cdot 3 \\cdot 1 + 2 \\cdot 3 \\cdot 10 + 2 \\cdot 4 \\cdot 8 + 3 \\cdot 4 \\cdot 13 \\right) $$\n$$ E[K_1 K_2] = \\frac{1}{102} \\left( 1 + 24 + 108 + 176 \\right) + \\frac{2}{102} \\left( 8 + 3 + 60 + 64 + 156 \\right) $$\n$$ E[K_1 K_2] = \\frac{309}{102} + \\frac{2 \\cdot 291}{102} = \\frac{309 + 582}{102} = \\frac{891}{102} = \\frac{297}{34} $$\n\n**第4步：计算同配系数 $r$**\n\n$$ r = \\frac{E[K_1 K_2] - \\mu_q^2}{\\sigma_q^2} = \\frac{\\frac{297}{34} - \\left(\\frac{149}{51}\\right)^2}{\\frac{2126}{2601}} $$\n计算分子（协方差）：\n$$ \\operatorname{Cov}(K_1, K_2) = \\frac{297}{34} - \\frac{22201}{2601} $$\n公共分母是 $\\operatorname{lcm}(34, 2601) = \\operatorname{lcm}(2 \\cdot 17, 51^2) = 2 \\cdot 51^2 = 5202$。\n$$ \\operatorname{Cov}(K_1, K_2) = \\frac{297 \\cdot 153 - 22201 \\cdot 2}{5202} = \\frac{45441 - 44402}{5202} = \\frac{1039}{5202} $$\n现在计算 $r$：\n$$ r = \\frac{1039/5202}{2126/2601} = \\frac{1039}{5202} \\cdot \\frac{2601}{2126} = \\frac{1039}{2 \\cdot 2601} \\cdot \\frac{2601}{2126} = \\frac{1039}{2 \\cdot 2126} = \\frac{1039}{4252} $$\n\n由于 $r = \\frac{1039}{4252} > 0$，网络表现出**同配性**（assortative mixing），意味着高度数节点倾向于连接其他高度数节点。",
            "answer": "$$\\boxed{\\frac{1039}{4252}}$$"
        },
        {
            "introduction": "网络度分布的结构对其整体功能和弹性有着巨大的影响。最后一个练习将演示网络科学中最著名的结果之一：无标度网络在面对蓄意攻击时的脆弱性 。您将计算摧毁网络巨型连通分量所需移除的高度数节点的临界比例，从而在微观特征（幂律度分布）和宏观属性（网络鲁棒性）之间建立起强大的定量联系。",
            "id": "4132896",
            "problem": "考虑一个由配置模型（Configuration Model, CM）生成的大型稀疏网络，该网络代表一个复杂的自适应系统，其节点度独立地从一个连续的幂律度分布中抽取。度分布由 $P(k) = C k^{-\\gamma}$ 给出，其中 $k \\geq k_{\\min}$，$\\gamma = 4$ 且 $k_{\\min} = \\frac{3}{2}$，$C$ 是归一化常数。一次目标性攻击移除了所有度严格大于选定截断值 $k_c$ 的节点，而保留了剩余的节点及其连接。假设网络足够大且局部呈树状，因此分支过程的论证适用。\n\n使用CM的基本定义以及具有独立度的随机图中巨大连通分支出现的一般条件，确定通过目标性攻击（即通过选择 $k_c$）必须移除的节点的最小比例 $p_c$，以使剩余网络中没有巨大连通分支。您的推导应明确地：\n- 对 $P(k)$ 进行归一化，\n- 通过对 $P(k)$ 的尾部进行积分，用截断值 $k_c$ 表示移除的比例 $p$，\n- 对在 $[k_{\\min}, k_c]$ 上的截断度分布进行再归一化，\n- 计算再归一化度分布的一阶矩和二阶矩，\n- 施加巨大连通分支消失的临界条件，并求解截断值 $k_c$ 以及由此得到的 $p_c$。\n\n将 $p_c$ 的最终答案表示为一个精确的数值。无需四舍五入。答案中不要包含单位。",
            "solution": "我们首先对在 $[k_{\\min}, \\infty)$ 上的幂律度分布 $P(k) = C k^{-\\gamma}$ 进行归一化，其中 $\\gamma = 4$ 且 $k_{\\min} = \\frac{3}{2}$。归一化常数 $C$ 满足\n$$\n\\int_{k_{\\min}}^{\\infty} C k^{-\\gamma} \\, dk = 1.\n$$\n当 $\\gamma = 4$ 时，我们计算\n$$\n\\int_{k_{\\min}}^{\\infty} k^{-4} \\, dk = \\left[ -\\frac{1}{3} k^{-3} \\right]_{k_{\\min}}^{\\infty} = \\frac{1}{3} k_{\\min}^{-3}.\n$$\n因此 $C \\cdot \\frac{1}{3} k_{\\min}^{-3} = 1$，这意味着\n$$\nC = 3 k_{\\min}^{3}.\n$$\n\n一次目标性攻击移除了所有度 $k > k_c$ 的节点。被移除的比例是尾部概率\n$$\np = \\int_{k_c}^{\\infty} P(k) \\, dk = \\int_{k_c}^{\\infty} C k^{-4} \\, dk = C \\left[ -\\frac{1}{3} k^{-3} \\right]_{k_c}^{\\infty} = \\frac{C}{3} k_c^{-3}.\n$$\n代入 $C = 3 k_{\\min}^{3}$ 可得\n$$\np = \\frac{3 k_{\\min}^{3}}{3} k_c^{-3} = \\left( \\frac{k_{\\min}}{k_c} \\right)^{3}.\n$$\n因此，剩余的比例是 $1 - p$，在 $[k_{\\min}, k_c]$ 上的截断、再归一化的度分布是\n$$\nP_r(k) = \\frac{P(k)}{1-p} = \\frac{C k^{-4}}{1-p}, \\quad k \\in [k_{\\min}, k_c].\n$$\n\n我们计算再归一化分布的一阶矩和二阶矩。一阶矩是\n$$\n\\langle k \\rangle_r = \\int_{k_{\\min}}^{k_c} k \\, P_r(k) \\, dk = \\frac{C}{1-p} \\int_{k_{\\min}}^{k_c} k^{-3} \\, dk = \\frac{C}{1-p} \\left[ -\\frac{1}{2} k^{-2} \\right]_{k_{\\min}}^{k_c} = \\frac{C}{1-p} \\cdot \\frac{1}{2} \\left( k_{\\min}^{-2} - k_c^{-2} \\right).\n$$\n二阶矩是\n$$\n\\langle k^{2} \\rangle_r = \\int_{k_{\\min}}^{k_c} k^{2} \\, P_r(k) \\, dk = \\frac{C}{1-p} \\int_{k_{\\min}}^{k_c} k^{-2} \\, dk = \\frac{C}{1-p} \\left[ -k^{-1} \\right]_{k_{\\min}}^{k_c} = \\frac{C}{1-p} \\left( k_{\\min}^{-1} - k_c^{-1} \\right).\n$$\n\n对于一个局部呈树状的CM网络，巨大连通分支的出现由Molloy-Reed准则（MRC）决定，该准则可以从分支过程的论证中推导出来：当且仅当平均超额度超过1时，存在巨大连通分支，这等价于\n$$\n\\frac{\\langle k(k-1) \\rangle}{\\langle k \\rangle}  1.\n$$\n由于 $\\langle k(k-1) \\rangle = \\langle k^{2} \\rangle - \\langle k \\rangle$，该不等式等价于\n$$\n\\frac{\\langle k^{2} \\rangle}{\\langle k \\rangle}  2.\n$$\n巨大连通分支的消失恰好发生在临界点，此时\n$$\n\\frac{\\langle k^{2} \\rangle_r}{\\langle k \\rangle_r} = 2.\n$$\n\n我们将为截断分布计算的比率设为 $2$：\n$$\n\\frac{\\langle k^{2} \\rangle_r}{\\langle k \\rangle_r} = \\frac{ \\frac{C}{1-p} \\left( k_{\\min}^{-1} - k_c^{-1} \\right) }{ \\frac{C}{1-p} \\cdot \\frac{1}{2} \\left( k_{\\min}^{-2} - k_c^{-2} \\right) } = 2 \\cdot \\frac{ k_{\\min}^{-1} - k_c^{-1} }{ k_{\\min}^{-2} - k_c^{-2} }.\n$$\n将其设为 $2$：\n$$\n2 \\cdot \\frac{ k_{\\min}^{-1} - k_c^{-1} }{ k_{\\min}^{-2} - k_c^{-2} } = 2.\n$$\n从两边消去因子 $2$ 得到\n$$\n\\frac{ k_{\\min}^{-1} - k_c^{-1} }{ k_{\\min}^{-2} - k_c^{-2} } = 1.\n$$\n我们简化左边。注意到\n$$\nk_{\\min}^{-1} - k_c^{-1} = \\frac{k_c - k_{\\min}}{k_{\\min} k_c}, \\quad k_{\\min}^{-2} - k_c^{-2} = \\frac{k_c^{2} - k_{\\min}^{2}}{k_{\\min}^{2} k_c^{2}} = \\frac{(k_c - k_{\\min})(k_c + k_{\\min})}{k_{\\min}^{2} k_c^{2}}.\n$$\n因此\n$$\n\\frac{ k_{\\min}^{-1} - k_c^{-1} }{ k_{\\min}^{-2} - k_c^{-2} } = \\frac{ \\frac{k_c - k_{\\min}}{k_{\\min} k_c} }{ \\frac{(k_c - k_{\\min})(k_c + k_{\\min})}{k_{\\min}^{2} k_c^{2}} } = \\frac{ k_{\\min} k_c }{ k_c + k_{\\min} }.\n$$\n因此，临界方程简化为\n$$\n\\frac{ k_{\\min} k_c }{ k_c + k_{\\min} } = 1.\n$$\n求解 $k_c$ 可得\n$$\nk_{\\min} k_c = k_c + k_{\\min} \\quad \\Longrightarrow \\quad k_c (k_{\\min} - 1) = k_{\\min} \\quad \\Longrightarrow \\quad k_c = \\frac{k_{\\min}}{k_{\\min} - 1}.\n$$\n\n当 $k_{\\min} = \\frac{3}{2}$ 时，我们发现\n$$\nk_c = \\frac{ \\frac{3}{2} }{ \\frac{3}{2} - 1 } = \\frac{ \\frac{3}{2} }{ \\frac{1}{2} } = 3.\n$$\n在临界点对应的被移除比例是\n$$\np_c = \\left( \\frac{k_{\\min}}{k_c} \\right)^{3} = \\left( \\frac{ \\frac{3}{2} }{ 3 } \\right)^{3} = \\left( \\frac{1}{2} \\right)^{3} = \\frac{1}{8}.\n$$\n因此，通过目标性攻击必须移除以消除巨大连通分支的节点的最小比例恰好是 $\\frac{1}{8}$。",
            "answer": "$$\\boxed{\\frac{1}{8}}$$"
        }
    ]
}