{
    "hands_on_practices": [
        {
            "introduction": "At the core of many agent-based models are simple, deterministic rules that dictate an agent's state based on its local neighborhood. This exercise provides a concrete example of this principle, using a system of agents arranged on a ring network where interactions are strictly local. By manually calculating the next state of the system based on a given threshold rule, you will gain a fundamental appreciation for how local interactions drive the model's overall dynamics and give rise to emergent patterns .",
            "id": "4113515",
            "problem": "Consider an Agent-Based Modeling (ABM) system on a ring network with $n$ agents, where $n$ is fixed at $n=10$. Each agent has a binary state $x_i(t) \\in \\{0,1\\}$ at discrete time $t \\in \\mathbb{N}$. The network is a one-dimensional ring: indices are taken modulo $n$, so that for any index $i \\in \\{1,\\dots,n\\}$, the predecessor of $1$ is $n$ and the successor of $n$ is $1$. For each agent $i$, the neighborhood $N(i)$ consists of the two nearest neighbors on each side, specifically $N(i)=\\{i-2,i-1,i+1,i+2\\}$ with indices interpreted modulo $n$. The synchronous update rule is defined by the indicator function\n$$\nx_i(t+1) \\;=\\; \\mathbb{I}\\left\\{\\sum_{j \\in N(i)} x_j(t) \\;\\geq\\; \\theta \\right\\},\n$$\nwhere $\\theta$ is a fixed threshold applied uniformly to all agents.\n\nYou are given the initial configuration at time $t=0$ as\n$$\nx(0) \\;=\\; \\bigl(x_1(0),x_2(0),x_3(0),x_4(0),x_5(0),x_6(0),x_7(0),x_8(0),x_9(0),x_{10}(0)\\bigr)\n\\;=\\; (1,0,1,1,0,0,1,0,1,0),\n$$\nand the threshold $\\theta=3$.\n\nUsing only the definitions above and the stated synchronous update rule, compute the next state vector $x(1)$. Express your final answer as a single row matrix containing the components in order $\\bigl(x_1(1),x_2(1),\\dots,x_{10}(1)\\bigr)$. No rounding is required, and no units apply.",
            "solution": "The problem statement is validated as being scientifically grounded, well-posed, objective, complete, and consistent. It describes a standard discrete-time dynamical system, specifically a type of one-dimensional cellular automaton on a ring, for which all necessary parameters and initial conditions are provided to compute the subsequent state. The problem is a formalizable exercise in applying a defined rule set and is directly pertinent to the field of agent-based modeling. Therefore, a solution can be derived.\n\nThe problem asks for the state vector $x(1)$ at time $t=1$, given the initial state vector $x(0)$ at time $t=0$. The system consists of $n=10$ agents on a ring. The state of each agent $i$ is binary, $x_i(t) \\in \\{0,1\\}$. The update rule for each agent $i$ is synchronous and determined by its neighbors' states at the previous time step. The neighborhood of agent $i$ is $N(i)=\\{i-2, i-1, i+1, i+2\\}$, with indices taken modulo $n$. The update rule is given by the indicator function:\n$$x_i(t+1) = \\mathbb{I}\\left\\{\\sum_{j \\in N(i)} x_j(t) \\geq \\theta \\right\\}$$\nwhere $\\mathbb{I}\\{\\cdot\\}$ is the indicator function, which equals $1$ if its argument is true and $0$ otherwise. The threshold is given as $\\theta=3$. The initial state vector at $t=0$ is:\n$$x(0) = (x_1(0), \\dots, x_{10}(0)) = (1,0,1,1,0,0,1,0,1,0)$$\nWe must compute $x_i(1)$ for each agent $i \\in \\{1, 2, \\dots, 10\\}$. This involves calculating the sum of the states of the four neighbors for each agent and comparing it to the threshold $\\theta=3$. The indices are interpreted modulo $10$, where the set of indices is $\\{1, 2, \\dots, 10\\}$. For example, for agent $i=1$, the neighbor $i-1=0$ corresponds to agent $10$, and $i-2=-1$ corresponds to agent $9$.\n\nFor agent $i=1$:\nThe neighborhood is $N(1) = \\{9, 10, 2, 3\\}$.\nThe sum of neighbors' states is $S_1 = x_9(0) + x_{10}(0) + x_2(0) + x_3(0) = 1 + 0 + 0 + 1 = 2$.\nSince $S_1=2 < \\theta=3$, the new state is $x_1(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=2$:\nThe neighborhood is $N(2) = \\{10, 1, 3, 4\\}$.\nThe sum of neighbors' states is $S_2 = x_{10}(0) + x_1(0) + x_3(0) + x_4(0) = 0 + 1 + 1 + 1 = 3$.\nSince $S_2=3 \\geq \\theta=3$, the new state is $x_2(1) = \\mathbb{I}\\{3 \\geq 3\\} = 1$.\n\nFor agent $i=3$:\nThe neighborhood is $N(3) = \\{1, 2, 4, 5\\}$.\nThe sum of neighbors' states is $S_3 = x_1(0) + x_2(0) + x_4(0) + x_5(0) = 1 + 0 + 1 + 0 = 2$.\nSince $S_3=2 < \\theta=3$, the new state is $x_3(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=4$:\nThe neighborhood is $N(4) = \\{2, 3, 5, 6\\}$.\nThe sum of neighbors' states is $S_4 = x_2(0) + x_3(0) + x_5(0) + x_6(0) = 0 + 1 + 0 + 0 = 1$.\nSince $S_4=1 < \\theta=3$, the new state is $x_4(1) = \\mathbb{I}\\{1 \\geq 3\\} = 0$.\n\nFor agent $i=5$:\nThe neighborhood is $N(5) = \\{3, 4, 6, 7\\}$.\nThe sum of neighbors' states is $S_5 = x_3(0) + x_4(0) + x_6(0) + x_7(0) = 1 + 1 + 0 + 1 = 3$.\nSince $S_5=3 \\geq \\theta=3$, the new state is $x_5(1) = \\mathbb{I}\\{3 \\geq 3\\} = 1$.\n\nFor agent $i=6$:\nThe neighborhood is $N(6) = \\{4, 5, 7, 8\\}$.\nThe sum of neighbors' states is $S_6 = x_4(0) + x_5(0) + x_7(0) + x_8(0) = 1 + 0 + 1 + 0 = 2$.\nSince $S_6=2 < \\theta=3$, the new state is $x_6(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=7$:\nThe neighborhood is $N(7) = \\{5, 6, 8, 9\\}$.\nThe sum of neighbors' states is $S_7 = x_5(0) + x_6(0) + x_8(0) + x_9(0) = 0 + 0 + 0 + 1 = 1$.\nSince $S_7=1 < \\theta=3$, the new state is $x_7(1) = \\mathbb{I}\\{1 \\geq 3\\} = 0$.\n\nFor agent $i=8$:\nThe neighborhood is $N(8) = \\{6, 7, 9, 10\\}$.\nThe sum of neighbors' states is $S_8 = x_6(0) + x_7(0) + x_9(0) + x_{10}(0) = 0 + 1 + 1 + 0 = 2$.\nSince $S_8=2 < \\theta=3$, the new state is $x_8(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=9$:\nThe neighborhood is $N(9) = \\{7, 8, 10, 1\\}$.\nThe sum of neighbors' states is $S_9 = x_7(0) + x_8(0) + x_{10}(0) + x_1(0) = 1 + 0 + 0 + 1 = 2$.\nSince $S_9=2 < \\theta=3$, the new state is $x_9(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=10$:\nThe neighborhood is $N(10) = \\{8, 9, 1, 2\\}$.\nThe sum of neighbors' states is $S_{10} = x_8(0) + x_9(0) + x_1(0) + x_2(0) = 0 + 1 + 1 + 0 = 2$.\nSince $S_{10}=2 < \\theta=3$, the new state is $x_{10}(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nCombining these results, the state vector at time $t=1$ is:\n$$x(1) = \\bigl(x_1(1), x_2(1), x_3(1), x_4(1), x_5(1), x_6(1), x_7(1), x_8(1), x_9(1), x_{10}(1)\\bigr) = (0, 1, 0, 0, 1, 0, 0, 0, 0, 0)$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Beyond defining the rules agents follow, a crucial design choice in any ABM is the update schedule—the order and timing of agent actions. This choice can dramatically affect a model's behavior and the emergent phenomena observed. This practice directly contrasts two common schemes: synchronous updates, where all agents act simultaneously based on the previous state, and sequential updates, where agents act one after another within the same time step. By tracing the trajectories of a simple two-agent system , you will see firsthand how this single modeling decision can lead to profoundly different outcomes.",
            "id": "4113495",
            "problem": "Consider an Agent-Based Model (ABM) in the domain of complex adaptive systems modeling with two agents labeled $i \\in \\{1,2\\}$ on an undirected network consisting of a single edge connecting the two agents. Each agent has a binary state $x_i(t) \\in \\{0,1\\}$ at discrete time $t \\in \\mathbb{Z}_{\\ge 0}$. The ABM employs a deterministic threshold decision rule: an agent becomes active at the next time step if and only if the fraction of its neighbors that are active meets or exceeds its threshold. Formally, for any agent $i$, let $N_i$ denote the set of neighbors of $i$, and let $m_i(\\tau) = \\frac{1}{|N_i|} \\sum_{j \\in N_i} x_j(\\tau)$ be the fraction of neighbors active at an update reference time $\\tau$. The threshold parameter for agent $i$ is $\\theta_i \\in [0,1]$, and the individual update rule is\n$$\nx_i(\\text{next}) = \n\\begin{cases}\n1, & \\text{if } m_i(\\tau) \\ge \\theta_i, \\\\\n0, & \\text{if } m_i(\\tau) < \\theta_i.\n\\end{cases}\n$$\nTwo update regimes are considered:\n\n- Synchronous update: Both agents compute $m_i(t)$ using the states at time $t$ and simultaneously set $x_i(t+1)$ according to the threshold rule.\n- Sequential update with fixed order $(1,2)$: Agent $1$ updates first using $m_1(t)$ to set $x_1(t+1)$, and then agent $2$ updates using $m_2(t+1)$, where $m_2(t+1)$ is computed from the latest available neighbor state after agent $1$ has updated.\n\nSuppose the initial condition is $x_1(0) = 0$ and $x_2(0) = 1$, and the thresholds are $\\theta_1 = \\frac{1}{2}$ and $\\theta_2 = 1$. Because the network has a single edge, each agent’s $m_i(\\tau)$ equals the neighbor’s state at the specified reference time. Define the trajectory difference over a finite horizon $T$ as the cumulative Hamming distance between the two regime trajectories,\n$$\nD(T) = \\sum_{t=0}^{T} \\left( \\left| x_1^{\\text{sync}}(t) - x_1^{\\text{seq}}(t) \\right| + \\left| x_2^{\\text{sync}}(t) - x_2^{\\text{seq}}(t) \\right| \\right),\n$$\nwhere $x_i^{\\text{sync}}(t)$ and $x_i^{\\text{seq}}(t)$ denote the state of agent $i$ at time $t$ under synchronous and sequential updating, respectively.\n\nCompute $D(T)$ for the horizon $T = 10$. Provide your final answer as a single real number. No rounding instruction is necessary for this problem.",
            "solution": "The problem is well-posed, scientifically grounded in the theory of Agent-Based Models (ABMs) and Complex Adaptive Systems, and contains all necessary information for a unique solution. The validation criteria are met.\n\nThe task is to compute the cumulative Hamming distance, $D(T)$, between the state trajectories of a two-agent system under synchronous and sequential update regimes for a time horizon of $T=10$. We begin by analyzing the agent update rules, then simulate the trajectories for both regimes, and finally compute the required sum.\n\nFirst, we formalize the update rules for agent $i \\in \\{1, 2\\}$ with thresholds $\\theta_1 = \\frac{1}{2}$ and $\\theta_2 = 1$. The network consists of a single edge connecting the two agents, so the set of neighbors for agent $1$ is $N_1 = \\{2\\}$ and for agent $2$ is $N_2 = \\{1\\}$. The fraction of active neighbors for agent $i$ is $m_i(\\tau) = \\frac{1}{|N_i|} \\sum_{j \\in N_i} x_j(\\tau)$. This simplifies to $m_1(\\tau) = x_2(\\tau)$ and $m_2(\\tau) = x_1(\\tau)$.\n\nThe individual update rule is $x_i(\\text{next}) = 1$ if $m_i(\\tau) \\ge \\theta_i$ and $x_i(\\text{next}) = 0$ otherwise. Given the binary state space $x_i \\in \\{0, 1\\}$, the rules for each agent become:\n- For agent $1$: $x_1(\\text{next}) = 1$ if and only if $x_2(\\tau) \\ge \\theta_1 = \\frac{1}{2}$. This means $x_1(\\text{next}) = 1$ only if $x_2(\\tau)=1$. Thus, the rule is $x_1(\\text{next}) = x_2(\\tau)$.\n- For agent $2$: $x_2(\\text{next}) = 1$ if and only if $x_1(\\tau) \\ge \\theta_2 = 1$. This means $x_2(\\text{next}) = 1$ only if $x_1(\\tau)=1$. Thus, the rule is $x_2(\\text{next}) = x_1(\\tau)$.\n\nNow we generate the trajectories for both update regimes starting from the initial condition $(x_1(0), x_2(0)) = (0, 1)$.\n\n**1. Synchronous Update Trajectory**\nUnder synchronous updating, both agents' next states are computed based on the current state of the system at time $t$. The rules are:\n$$\n\\begin{cases}\nx_1^{\\text{sync}}(t+1) = x_2^{\\text{sync}}(t) \\\\\nx_2^{\\text{sync}}(t+1) = x_1^{\\text{sync}}(t)\n\\end{cases}\n$$\nWe compute the state vector $(x_1^{\\text{sync}}(t), x_2^{\\text{sync}}(t))$ for $t \\in \\{0, 1, \\dots, 10\\}$:\n- $t=0$: $(0, 1)$ (Initial condition)\n- $t=1$: $(x_1(1), x_2(1)) = (x_2(0), x_1(0)) = (1, 0)$\n- $t=2$: $(x_1(2), x_2(2)) = (x_2(1), x_1(1)) = (0, 1)$\n- $t=3$: $(x_1(3), x_2(3)) = (x_2(2), x_1(2)) = (1, 0)$\nThe system oscillates with a period of $2$. The state is $(0, 1)$ for even values of $t$ and $(1, 0)$ for odd values of $t$.\n\n**2. Sequential Update Trajectory (Order 1, 2)**\nUnder sequential updating with order $(1, 2)$, agent $1$ first updates its state for time $t+1$ based on states at time $t$. Then, agent $2$ updates its state for time $t+1$ using the most recent states, which includes the newly updated state of agent $1$.\nThe rules for one time step from $t$ to $t+1$ are:\n$$\n\\begin{cases}\nx_1^{\\text{seq}}(t+1) = x_2^{\\text{seq}}(t) \\\\\nx_2^{\\text{seq}}(t+1) = x_1^{\\text{seq}}(t+1)\n\\end{cases}\n$$\nWe compute the state vector $(x_1^{\\text{seq}}(t), x_2^{\\text{seq}}(t))$ for $t \\in \\{0, 1, \\dots, 10\\}$:\n- $t=0$: $(0, 1)$ (Initial condition)\n- $t=1$:\n  - Agent $1$ updates: $x_1^{\\text{seq}}(1) = x_2^{\\text{seq}}(0) = 1$.\n  - Agent $2$ updates: $x_2^{\\text{seq}}(1) = x_1^{\\text{seq}}(1) = 1$.\n  - The state at $t=1$ is $(1, 1)$.\n- $t=2$:\n  - Agent $1$ updates: $x_1^{\\text{seq}}(2) = x_2^{\\text{seq}}(1) = 1$.\n  - Agent $2$ updates: $x_2^{\\text{seq}}(2) = x_1^{\\text{seq}}(2) = 1$.\n  - The state at $t=2$ is $(1, 1)$.\nThe system reaches a fixed point $(1, 1)$ at $t=1$. Therefore, for all $t \\ge 1$, the state is $(x_1^{\\text{seq}}(t), x_2^{\\text{seq}}(t)) = (1, 1)$.\n\n**3. Compute the Trajectory Difference $D(10)$**\nThe trajectory difference is defined as $D(T) = \\sum_{t=0}^{T} d(t)$, where the per-step Hamming distance is $d(t) = |x_1^{\\text{sync}}(t) - x_1^{\\text{seq}}(t)| + |x_2^{\\text{sync}}(t) - x_2^{\\text{seq}}(t)|$. We calculate $d(t)$ for each $t$ from $0$ to $10$.\n\n- For $t=0$:\n  - $x^{\\text{sync}}(0) = (0, 1)$ and $x^{\\text{seq}}(0) = (0, 1)$.\n  - $d(0) = |0-0| + |1-1| = 0$.\n\n- For $t \\ge 1$:\n  - The sequential trajectory is fixed: $x^{\\text{seq}}(t) = (1, 1)$.\n  - The synchronous trajectory alternates.\n  - For odd $t \\in \\{1, 3, 5, 7, 9\\}$:\n    - $x^{\\text{sync}}(t) = (1, 0)$.\n    - $d(t) = |1-1| + |0-1| = 0 + 1 = 1$.\n  - For even $t \\in \\{2, 4, 6, 8, 10\\}$:\n    - $x^{\\text{sync}}(t) = (0, 1)$.\n    - $d(t) = |0-1| + |1-1| = 1 + 0 = 1$.\n\nSo, we have $d(0)=0$ and $d(t)=1$ for all $t \\in \\{1, 2, \\dots, 10\\}$.\n\nFinally, we sum these values to find $D(10)$:\n$$\nD(10) = \\sum_{t=0}^{10} d(t) = d(0) + \\sum_{t=1}^{10} d(t)\n$$\n$$\nD(10) = 0 + (d(1) + d(2) + \\dots + d(10))\n$$\n$$\nD(10) = 0 + \\sum_{t=1}^{10} 1 = 10 \\times 1 = 10\n$$\nThe cumulative Hamming distance over the horizon $T=10$ is $10$.",
            "answer": "$$\n\\boxed{10}\n$$"
        },
        {
            "introduction": "Agents in an ABM often inhabit and interact with a dynamic environment, which they can both influence and be influenced by. A common and important environmental process is diffusion, which governs the spread of resources, chemical signals, or information across space. This exercise  will guide you through the numerical simulation of diffusion on a two-dimensional grid, using a finite difference method to approximate the continuous process. Mastering this technique is essential for building models where agents and their environment co-evolve.",
            "id": "4113501",
            "problem": "A two-dimensional toroidal lattice (periodic boundaries in both directions) represents a diffusing resource field in an Agent-Based Modeling (ABM) system. The resource density field $u(x,y,t)$ obeys the diffusion equation $\\frac{\\partial u}{\\partial t} = D \\nabla^{2} u$, where $D$ is the diffusion coefficient. Consider a discrete $4 \\times 4$ grid with spatial spacing $\\Delta x = \\Delta y = 1$, and simulate the diffusion using one explicit time step of size $\\Delta t = 0.25$ with diffusion coefficient $D = 0.4$. The five-point stencil arises from second-order central differences for the Laplacian. The initial resource map at time step $n = 0$ is\n$$\nU^{(0)} = \\begin{pmatrix}\n1 & 3 & 0 & 2 \\\\\n4 & 1 & 5 & 0 \\\\\n2 & 2 & 1 & 3 \\\\\n0 & 1 & 4 & 2\n\\end{pmatrix}.\n$$\nAssuming periodic boundary conditions (the grid is topologically a torus; neighbors of boundary cells wrap around), derive from the governing diffusion equation and the finite difference approximation the explicit update for one time step, and then compute the updated value at the cell with indices $(i,j)=(1,1)$ after this single step. Express your final answer as an exact decimal and do not include any units. No rounding is required.",
            "solution": "The problem asks for the updated value of a resource density at a specific cell on a discrete lattice after one time step, governed by the diffusion equation. The solution requires deriving the explicit finite difference update rule and then applying it using the given initial conditions and parameters.\n\nThe governing partial differential equation for the resource density field $u(x,y,t)$ is the two-dimensional diffusion equation:\n$$\n\\frac{\\partial u}{\\partial t} = D \\nabla^{2} u = D \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} \\right)\n$$\nwhere $D$ is the diffusion coefficient.\n\nTo solve this numerically, we discretize the equation in both space and time. Let $U_{i,j}^{(n)}$ be the resource density at the grid cell with indices $(i,j)$ at time step $n$. The spatial coordinates are $x = i\\Delta x$, $y = j\\Delta y$, and time is $t = n\\Delta t$.\n\nWe approximate the time derivative on the left-hand side using a first-order forward difference (an explicit time-stepping scheme):\n$$\n\\frac{\\partial u}{\\partial t} \\approx \\frac{U_{i,j}^{(n+1)} - U_{i,j}^{(n)}}{\\Delta t}\n$$\n\nThe spatial second derivatives comprising the Laplacian, $\\nabla^2 u$, are approximated using a second-order central difference stencil (the five-point stencil):\n$$\n\\frac{\\partial^2 u}{\\partial x^2} \\approx \\frac{U_{i+1,j}^{(n)} - 2U_{i,j}^{(n)} + U_{i-1,j}^{(n)}}{(\\Delta x)^2}\n$$\n$$\n\\frac{\\partial^2 u}{\\partial y^2} \\approx \\frac{U_{i,j+1}^{(n)} - 2U_{i,j}^{(n)} + U_{i,j-1}^{(n)}}{(\\Delta y)^2}\n$$\n\nSubstituting these discrete approximations into the continuous diffusion equation yields the finite difference equation:\n$$\n\\frac{U_{i,j}^{(n+1)} - U_{i,j}^{(n)}}{\\Delta t} = D \\left( \\frac{U_{i+1,j}^{(n)} - 2U_{i,j}^{(n)} + U_{i-1,j}^{(n)}}{(\\Delta x)^2} + \\frac{U_{i,j+1}^{(n)} - 2U_{i,j}^{(n)} + U_{i,j-1}^{(n)}}{(\\Delta y)^2} \\right)\n$$\n\nWe are given that the spatial spacing is uniform with $\\Delta x = \\Delta y = 1$. This simplifies the equation. We can now solve for the updated value $U_{i,j}^{(n+1)}$:\n$$\nU_{i,j}^{(n+1)} = U_{i,j}^{(n)} + D \\Delta t \\left( U_{i+1,j}^{(n)} - 2U_{i,j}^{(n)} + U_{i-1,j}^{(n)} + U_{i,j+1}^{(n)} - 2U_{i,j}^{(n)} + U_{i,j-1}^{(n)} \\right)\n$$\nCombining terms related to $U_{i,j}^{(n)}$ gives:\n$$\nU_{i,j}^{(n+1)} = U_{i,j}^{(n)} + D \\Delta t \\left( (U_{i+1,j}^{(n)} + U_{i-1,j}^{(n)} + U_{i,j+1}^{(n)} + U_{i,j-1}^{(n)}) - 4U_{i,j}^{(n)} \\right)\n$$\nLet's define the dimensionless constant $\\alpha = D \\Delta t$. The equation can be rearranged into the final form for the explicit update rule:\n$$\nU_{i,j}^{(n+1)} = (1 - 4\\alpha)U_{i,j}^{(n)} + \\alpha\\left(U_{i+1,j}^{(n)} + U_{i-1,j}^{(n)} + U_{i,j+1}^{(n)} + U_{i,j-1}^{(n)}\\right)\n$$\n\nNow, we substitute the specified parameter values: $D = 0.4$ and $\\Delta t = 0.25$.\n$$\n\\alpha = D \\Delta t = (0.4)(0.25) = 0.1\n$$\nThe numerical coefficients in the update rule are:\n$$\n1 - 4\\alpha = 1 - 4(0.1) = 1 - 0.4 = 0.6\n$$\nSo, the specific update rule for this problem is:\n$$\nU_{i,j}^{(n+1)} = 0.6 \\, U_{i,j}^{(n)} + 0.1 \\left(U_{i+1,j}^{(n)} + U_{i-1,j}^{(n)} + U_{i,j+1}^{(n)} + U_{i,j-1}^{(n)}\\right)\n$$\n\nWe are asked to compute the updated value at the cell $(i,j)=(1,1)$ for the first time step, i.e., $U_{1,1}^{(1)}$. We assume standard 1-based matrix indexing, where $(1,1)$ denotes the top-left element of the grid. The grid is a $4 \\times 4$ lattice, so the indices for $i$ and $j$ range from $1$ to $4$.\nThe update for $U_{1,1}^{(1)}$ is:\n$$\nU_{1,1}^{(1)} = 0.6 \\, U_{1,1}^{(0)} + 0.1 \\left(U_{2,1}^{(0)} + U_{0,1}^{(0)} + U_{1,2}^{(0)} + U_{1,0}^{(0)}\\right)\n$$\nThe problem specifies periodic boundary conditions. This means the grid wraps around. For a $4 \\times 4$ grid:\n- The neighbor \"above\" cell $(1,j)$ is cell $(4,j)$, so $U_{0,j}^{(n)}$ is equivalent to $U_{4,j}^{(n)}$.\n- The neighbor \"to the left of\" cell $(i,1)$ is cell $(i,4)$, so $U_{i,0}^{(n)}$ is equivalent to $U_{i,4}^{(n)}$.\nApplying these conditions to our equation for $U_{1,1}^{(1)}$:\n$$\nU_{1,1}^{(1)} = 0.6 \\, U_{1,1}^{(0)} + 0.1 \\left(U_{2,1}^{(0)} + U_{4,1}^{(0)} + U_{1,2}^{(0)} + U_{1,4}^{(0)}\\right)\n$$\n\nThe initial resource map $U^{(0)}$ is given as:\n$$\nU^{(0)} = \\begin{pmatrix}\n1 & 3 & 0 & 2 \\\\\n4 & 1 & 5 & 0 \\\\\n2 & 2 & 1 & 3 \\\\\n0 & 1 & 4 & 2\n\\end{pmatrix}\n$$\nFrom this matrix, we extract the necessary values:\n- The central cell value: $U_{1,1}^{(0)} = 1$.\n- The neighbor below: $U_{2,1}^{(0)} = 4$.\n- The neighbor above (wrapped): $U_{4,1}^{(0)} = 0$.\n- The neighbor to the right: $U_{1,2}^{(0)} = 3$.\n- The neighbor to the left (wrapped): $U_{1,4}^{(0)} = 2$.\n\nSubstituting these values into the update equation:\n$$\nU_{1,1}^{(1)} = 0.6 \\times (1) + 0.1 \\times (4 + 0 + 3 + 2)\n$$\n$$\nU_{1,1}^{(1)} = 0.6 + 0.1 \\times (9)\n$$\n$$\nU_{1,1}^{(1)} = 0.6 + 0.9\n$$\n$$\nU_{1,1}^{(1)} = 1.5\n$$\nThe updated value at cell $(1,1)$ after one time step is $1.5$.",
            "answer": "$$\\boxed{1.5}$$"
        }
    ]
}