{
    "hands_on_practices": [
        {
            "introduction": "在构建基于主体的模型时，一个看似微小但至关重要的设计决策是更新机制的选择。是让所有主体同时（同步）根据旧状态计算并更新，还是让他们按一定顺序（序贯）逐个更新，并立即将新状态反馈给系统？这个练习将通过一个简单的双主体系统，清晰地揭示同步与序贯更新机制如何导致截然不同的系统轨迹，从而帮助你建立对模型动态如何受更新方案影响的直观理解。",
            "id": "4113495",
            "problem": "考虑一个复杂自适应系统建模领域中的基于主体的模型（Agent-Based Model, ABM），该模型包含两个主体，标记为 $i \\in \\{1,2\\}$，位于一个由连接这两个主体的单条边组成的无向网络上。每个主体在离散时间 $t \\in \\mathbb{Z}_{\\ge 0}$ 具有一个二元状态 $x_i(t) \\in \\{0,1\\}$。该ABM采用确定性阈值决策规则：一个主体在下一个时间步变为活跃状态，当且仅当其邻居中活跃主体的比例达到或超过其阈值。形式上，对于任何主体 $i$，令 $N_i$ 表示 $i$ 的邻居集合，并令 $m_i(\\tau) = \\frac{1}{|N_i|} \\sum_{j \\in N_i} x_j(\\tau)$ 为更新参考时间 $\\tau$ 时活跃邻居的比例。主体 $i$ 的阈值参数为 $\\theta_i \\in [0,1]$，个体更新规则为\n$$\nx_i(\\text{next}) = \n\\begin{cases}\n1,  &\\text{if } m_i(\\tau) \\ge \\theta_i, \\\\\n0,  &\\text{if } m_i(\\tau)  \\theta_i.\n\\end{cases}\n$$\n考虑两种更新机制：\n\n- 同步更新：两个主体都使用时间 $t$ 的状态计算 $m_i(t)$，并根据阈值规则同时设置 $x_i(t+1)$。\n- 固定顺序 $(1,2)$ 的序贯更新：主体1首先使用 $m_1(t)$ 更新以设置 $x_1(t+1)$，然后主体2使用 $m_2(t+1)$ 进行更新，其中 $m_2(t+1)$ 是在主体1更新后根据最新的可用邻居状态计算的。\n\n假设初始条件为 $x_1(0) = 0$ 和 $x_2(0) = 1$，阈值为 $\\theta_1 = \\frac{1}{2}$ 和 $\\theta_2 = 1$。由于网络只有一条边，每个主体的 $m_i(\\tau)$ 等于其邻居在指定参考时间的状态。定义在有限时间域 $T$ 上的轨迹差异为两种机制下轨迹之间的累积汉明距离，\n$$\nD(T) = \\sum_{t=0}^{T} \\left( \\left| x_1^{\\text{sync}}(t) - x_1^{\\text{seq}}(t) \\right| + \\left| x_2^{\\text{sync}}(t) - x_2^{\\text{seq}}(t) \\right| \\right),\n$$\n其中 $x_i^{\\text{sync}}(t)$ 和 $x_i^{\\text{seq}}(t)$ 分别表示在同步和序贯更新下，主体 $i$ 在时间 $t$ 的状态。\n\n计算时间域 $T = 10$ 时的 $D(T)$。请以单个实数形式提供最终答案。本题无需进行四舍五入。",
            "solution": "该问题陈述清晰，科学上基于基于主体的模型（ABM）和复杂自适应系统的理论，并包含了获得唯一解所需的所有信息。验证标准已满足。\n\n任务是计算一个双主体系统在同步和序贯更新机制下，时间域 $T=10$ 内状态轨迹之间的累积汉明距离 $D(T)$。我们首先分析主体的更新规则，然后模拟两种机制下的轨迹，最后计算所需的总和。\n\n首先，我们形式化主体 $i \\in \\{1, 2\\}$ 的更新规则，其阈值分别为 $\\theta_1 = \\frac{1}{2}$ 和 $\\theta_2 = 1$。网络由连接两个主体的一条边组成，因此主体1的邻居集合是 $N_1 = \\{2\\}$，主体2的邻居集合是 $N_2 = \\{1\\}$。主体 $i$ 的活跃邻居比例为 $m_i(\\tau) = \\frac{1}{|N_i|} \\sum_{j \\in N_i} x_j(\\tau)$。这可以简化为 $m_1(\\tau) = x_2(\\tau)$ 和 $m_2(\\tau) = x_1(\\tau)$。\n\n个体更新规则是：如果 $m_i(\\tau) \\ge \\theta_i$，则 $x_i(\\text{next}) = 1$，否则 $x_i(\\text{next}) = 0$。鉴于二元状态空间 $x_i \\in \\{0, 1\\}$，每个主体的规则变为：\n- 对于主体1：$x_1(\\text{next}) = 1$ 当且仅当 $x_2(\\tau) \\ge \\theta_1 = \\frac{1}{2}$。这意味着只有当 $x_2(\\tau)=1$ 时，$x_1(\\text{next}) = 1$。因此，规则是 $x_1(\\text{next}) = x_2(\\tau)$。\n- 对于主体2：$x_2(\\text{next}) = 1$ 当且仅当 $x_1(\\tau) \\ge \\theta_2 = 1$。这意味着只有当 $x_1(\\tau)=1$ 时，$x_2(\\text{next}) = 1$。因此，规则是 $x_2(\\text{next}) = x_1(\\tau)$。\n\n现在我们从初始条件 $(x_1(0), x_2(0)) = (0, 1)$ 开始，生成两种更新机制下的轨迹。\n\n**1. 同步更新轨迹**\n在同步更新下，两个主体的下一状态都是基于系统在时间 $t$ 的当前状态计算的。规则如下：\n$$\n\\begin{cases}\nx_1^{\\text{sync}}(t+1) = x_2^{\\text{sync}}(t) \\\\\nx_2^{\\text{sync}}(t+1) = x_1^{\\text{sync}}(t)\n\\end{cases}\n$$\n我们计算 $t \\in \\{0, 1, \\dots, 10\\}$ 的状态向量 $(x_1^{\\text{sync}}(t), x_2^{\\text{sync}}(t))$：\n- $t=0$: $(0, 1)$ (初始条件)\n- $t=1$: $(x_1(1), x_2(1)) = (x_2(0), x_1(0)) = (1, 0)$\n- $t=2$: $(x_1(2), x_2(2)) = (x_2(1), x_1(1)) = (0, 1)$\n- $t=3$: $(x_1(3), x_2(3)) = (x_2(2), x_1(2)) = (1, 0)$\n系统以周期为2进行振荡。当 $t$ 为偶数时，状态为 $(0, 1)$；当 $t$ 为奇数时，状态为 $(1, 0)$。\n\n**2. 序贯更新轨迹（顺序1, 2）**\n在顺序为 $(1, 2)$ 的序贯更新下，主体1首先基于时间 $t$ 的状态更新其在时间 $t+1$ 的状态。然后，主体2使用最新的状态（包括主体1已更新的状态）来更新其在时间 $t+1$ 的状态。\n从 $t$ 到 $t+1$ 的一个时间步的规则是：\n$$\n\\begin{cases}\nx_1^{\\text{seq}}(t+1) = x_2^{\\text{seq}}(t) \\\\\nx_2^{\\text{seq}}(t+1) = x_1^{\\text{seq}}(t+1)\n\\end{cases}\n$$\n我们计算 $t \\in \\{0, 1, \\dots, 10\\}$ 的状态向量 $(x_1^{\\text{seq}}(t), x_2^{\\text{seq}}(t))$：\n- $t=0$: $(0, 1)$ (初始条件)\n- $t=1$:\n  - 主体1更新：$x_1^{\\text{seq}}(1) = x_2^{\\text{seq}}(0) = 1$。\n  - 主体2更新：$x_2^{\\text{seq}}(1) = x_1^{\\text{seq}}(1) = 1$。\n  - $t=1$ 时的状态是 $(1, 1)$。\n- $t=2$:\n  - 主体1更新：$x_1^{\\text{seq}}(2) = x_2^{\\text{seq}}(1) = 1$。\n  - 主体2更新：$x_2^{\\text{seq}}(2) = x_1^{\\text{seq}}(2) = 1$。\n  - $t=2$ 时的状态是 $(1, 1)$。\n系统在 $t=1$ 时达到不动点 $(1, 1)$。因此，对于所有 $t \\ge 1$，状态为 $(x_1^{\\text{seq}}(t), x_2^{\\text{seq}}(t)) = (1, 1)$。\n\n**3. 计算轨迹差异 $D(10)$**\n轨迹差异定义为 $D(T) = \\sum_{t=0}^{T} d(t)$，其中每步的汉明距离为 $d(t) = |x_1^{\\text{sync}}(t) - x_1^{\\text{seq}}(t)| + |x_2^{\\text{sync}}(t) - x_2^{\\text{seq}}(t)|$。我们计算从 $t=0$到$10$的每个$t$的$d(t)$。\n\n- 对于 $t=0$:\n  - $x^{\\text{sync}}(0) = (0, 1)$ 且 $x^{\\text{seq}}(0) = (0, 1)$。\n  - $d(0) = |0-0| + |1-1| = 0$。\n\n- 对于 $t \\ge 1$:\n  - 序贯轨迹是固定的：$x^{\\text{seq}}(t) = (1, 1)$。\n  - 同步轨迹是交替的。\n  - 对于奇数 $t \\in \\{1, 3, 5, 7, 9\\}$:\n    - $x^{\\text{sync}}(t) = (1, 0)$。\n    - $d(t) = |1-1| + |0-1| = 0 + 1 = 1$。\n  - 对于偶数 $t \\in \\{2, 4, 6, 8, 10\\}$:\n    - $x^{\\text{sync}}(t) = (0, 1)$。\n    - $d(t) = |0-1| + |1-1| = 1 + 0 = 1$。\n\n因此，我们有 $d(0)=0$ 且对于所有 $t \\in \\{1, 2, \\dots, 10\\}$，$d(t)=1$。\n\n最后，我们将这些值相加来求 $D(10)$：\n$$\nD(10) = \\sum_{t=0}^{10} d(t) = d(0) + \\sum_{t=1}^{10} d(t)\n$$\n$$\nD(10) = 0 + (d(1) + d(2) + \\dots + d(10))\n$$\n$$\nD(10) = 0 + \\sum_{t=1}^{10} 1 = 10 \\times 1 = 10\n$$\n在时间域 $T=10$ 上的累积汉明距离是 $10$。",
            "answer": "$$\n\\boxed{10}\n$$"
        },
        {
            "introduction": "在主体做出决策时，我们常常需要一种既能体现理性（偏好高收益选项）又能包含随机性（允许探索或体现有限理性）的模型。Softmax选择规则，源于统计物理学中的最大熵原理，为此提供了一个强大而优雅的框架。通过这个练习，你将推导并应用softmax函数，掌握在ABM中为agent赋予基于效用的随机决策能力的核心方法。",
            "id": "4113475",
            "problem": "考虑一个嵌入在复杂适应性系统中的基于主体的建模（Agent-Based Modeling, ABM）环境里的单个决策主体 $i$。该主体通过选择一个在 $\\mathcal{A}$ 上的随机策略 $\\pi_i(a)$，从有限行动集 $\\mathcal{A}=\\{A,B,C,D\\}$ 中选择一个行动 $a$。假设该主体遵循最大香农熵原理，并受制于统计决策中常见的约束条件：归一化 $\\sum_{a\\in\\mathcal{A}}\\pi_i(a)=1$，以及一个固定的期望效用 $\\sum_{a\\in\\mathcal{A}}\\pi_i(a)\\,U_i(a)$，该期望效用由一个逆温度参数 $\\beta0$ 控制，其中较大的 $\\beta$ 值对应于相对于熵而言更重视效用。\n\n从香农熵的定义 $H(\\pi_i)=-\\sum_{a\\in\\mathcal{A}}\\pi_i(a)\\,\\ln\\!\\big(\\pi_i(a)\\big)$ 和上述约束条件出发，推导该主体将执行的规范选择分布 $\\pi_i(a)$。然后，对于给定的具体效用值\n$$\nU_i(A)=\\ln(2),\\quad U_i(B)=\\ln(3),\\quad U_i(C)=-\\ln(4),\\quad U_i(D)=0,\n$$\n以及逆温度 $\\beta=1$，计算选择概率 $\\pi_i(A)$、$\\pi_i(B)$、$\\pi_i(C)$ 和 $\\pi_i(D)$。将每个概率四舍五入到四位有效数字，并以十进制形式的单行向量表示您的最终数值答案。无需单位。此外，请简要说明为什么将同一个常数 $c$ 加到所有效用 $U_i(a)$ 上，计算出的概率保持不变。",
            "solution": "首先通过提取已知条件并评估其科学性和结构完整性来验证问题陈述。\n\n**步骤1：提取已知条件**\n- **系统**：一个基于主体的建模（ABM）环境中的单个决策主体 $i$。\n- **行动集**：一个有限集 $\\mathcal{A}=\\{A,B,C,D\\}$。\n- **策略**：一个随机策略 $\\pi_i(a)$，表示选择行动 $a \\in \\mathcal{A}$ 的概率。\n- **目标函数**：最大化香农熵，$H(\\pi_i)=-\\sum_{a\\in\\mathcal{A}}\\pi_i(a)\\,\\ln\\!\\big(\\pi_i(a)\\big)$。\n- **约束1（归一化）**：$\\sum_{a\\in\\mathcal{A}}\\pi_i(a)=1$。\n- **约束2（期望效用）**：$\\sum_{a\\in\\mathcal{A}}\\pi_i(a)\\,U_i(a)$ 是一个固定值，由逆温度参数 $\\beta0$ 控制。\n- **具体效用**：$U_i(A)=\\ln(2)$, $U_i(B)=\\ln(3)$, $U_i(C)=-\\ln(4)$, $U_i(D)=0$。\n- **具体逆温度**：$\\beta=1$。\n- **任务1**：推导规范选择分布 $\\pi_i(a)$。\n- **任务2**：根据给定的效用和 $\\beta$ 计算数值概率，并四舍五入到四位有效数字。\n- **任务3**：说明为什么将一个常数 $c$ 加到所有效用 $U_i(a)$ 上，概率保持不变。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题具有科学依据。最大熵原理是统计力学、信息论和概率建模中的一个基本概念，是推导像玻尔兹曼分布这样的规范分布的基础。该问题是此原理在不确定性下决策的标准应用，这是计算社会科学、经济学（例如，离散选择模型）和强化学习中的常用方法。问题提法严谨，提供了所有必要信息——目标函数（熵）、约束条件（归一化和期望效用）、行动集以及具体的参数值——以推导出唯一且有意义的解。语言精确客观。问题自成一体且内部一致。\n\n**步骤3：结论与行动**\n该问题被认定为有效。将提供完整解答。\n\n规范选择分布 $\\pi_i(a)$ 的推导是一个约束优化问题。我们必须在归一化和期望效用约束下最大化香农熵 $H(\\pi_i)$。使用拉格朗日乘数法是处理这个问题的最佳方法。这个问题的拉格朗日函数 $\\mathcal{L}$ 是：\n$$\n\\mathcal{L}(\\pi_i, \\lambda_0, \\beta) = H(\\pi_i) - \\lambda_0 \\left( \\sum_{a \\in \\mathcal{A}} \\pi_i(a) - 1 \\right) - \\beta \\left( \\sum_{a \\in \\mathcal{A}} \\pi_i(a) U_i(a) - \\langle U \\rangle \\right)\n$$\n这里，$\\lambda_0$ 和 $\\beta$ 分别是归一化和期望效用约束的拉格朗日乘数。问题陈述本身已将 $\\beta$ 定义为逆温度参数。期望效用表示为 $\\langle U \\rangle$。\n代入熵 $H(\\pi_i)$ 的定义：\n$$\n\\mathcal{L} = -\\sum_{a \\in \\mathcal{A}} \\pi_i(a) \\ln(\\pi_i(a)) - \\lambda_0 \\left( \\sum_{a \\in \\mathcal{A}} \\pi_i(a) - 1 \\right) - \\beta \\left( \\sum_{a \\in \\mathcal{A}} \\pi_i(a) U_i(a) - \\langle U \\rangle \\right)\n$$\n为了找到使 $\\mathcal{L}$ 最大化的分布 $\\pi_i(a)$，我们对任意行动 $a' \\in \\mathcal{A}$ 的 $\\pi_i(a')$ 求偏导数，并令其为零。\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\pi_i(a')} = \\frac{\\partial}{\\partial \\pi_i(a')} \\left( -\\pi_i(a') \\ln(\\pi_i(a')) - \\lambda_0 \\pi_i(a') - \\beta \\pi_i(a') U_i(a') \\right) = 0\n$$\n$$\n-\\left(1 \\cdot \\ln(\\pi_i(a')) + \\pi_i(a') \\cdot \\frac{1}{\\pi_i(a')}\\right) - \\lambda_0 - \\beta U_i(a') = 0\n$$\n$$\n-\\ln(\\pi_i(a')) - 1 - \\lambda_0 - \\beta U_i(a') = 0\n$$\n求解 $\\ln(\\pi_i(a'))$：\n$$\n\\ln(\\pi_i(a')) = -1 - \\lambda_0 - \\beta U_i(a')\n$$\n对两边取指数，得到概率的形式：\n$$\n\\pi_i(a') = \\exp(-1 - \\lambda_0 - \\beta U_i(a')) = \\exp(-1 - \\lambda_0) \\exp(-\\beta U_i(a'))\n$$\n问题陈述指出，较大的 $\\beta$ 对应于更重视效用。其标准形式涉及 $\\exp(\\beta U_i(a))$，这对应于在给定效用下限的情况下最大化熵，或最小化成本函数。这意味着拉格朗日乘数应为正，因为给定 $\\beta  0$。此处选择的符号约定导致了 $\\exp(-\\beta U_i(a))$。拉格朗日函数的不同符号约定，例如加上 $\\beta(\\sum \\pi U - \\langle U \\rangle)$，会使符号反转。我们采用能直接产生标准 softmax/Boltzmann 形式的约定。设拉格朗日函数为 $\\mathcal{L} = H - \\lambda_0(\\sum\\pi - 1) + \\beta(\\sum\\pi U - \\langle U \\rangle)$。\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\pi_i(a')} = -\\ln(\\pi_i(a')) - 1 - \\lambda_0 + \\beta U_i(a') = 0\n$$\n$$\n\\ln(\\pi_i(a')) = \\beta U_i(a') - (1+\\lambda_0)\n$$\n$$\n\\pi_i(a') = \\exp(\\beta U_i(a') - (1+\\lambda_0)) = \\exp(-(1+\\lambda_0)) \\exp(\\beta U_i(a'))\n$$\n为了确定包含第一个乘数 $\\lambda_0$ 的项，我们应用归一化约束 $\\sum_{a \\in \\mathcal{A}} \\pi_i(a) = 1$：\n$$\n\\sum_{a \\in \\mathcal{A}} \\exp(-(1+\\lambda_0)) \\exp(\\beta U_i(a)) = 1\n$$\n$$\n\\exp(-(1+\\lambda_0)) \\sum_{a \\in \\mathcal{A}} \\exp(\\beta U_i(a)) = 1\n$$\n$$\n\\exp(-(1+\\lambda_0)) = \\frac{1}{\\sum_{a \\in \\mathcal{A}} \\exp(\\beta U_i(a))}\n$$\n将此结果代回 $\\pi_i(a')$ 的表达式中，我们得到规范选择分布，通常称为吉布斯-玻尔兹曼分布或 softmax 函数：\n$$\n\\pi_i(a) = \\frac{\\exp(\\beta U_i(a))}{\\sum_{a' \\in \\mathcal{A}} \\exp(\\beta U_i(a'))}\n$$\n分母 $Z = \\sum_{a' \\in \\mathcal{A}} \\exp(\\beta U_i(a'))$ 被称为配分函数。\n\n接下来，我们根据给定的效用和 $\\beta=1$ 计算具体概率。\n效用值为 $U_i(A)=\\ln(2)$, $U_i(B)=\\ln(3)$, $U_i(C)=-\\ln(4)$ 和 $U_i(D)=0$。逆温度为 $\\beta=1$。\n首先，计算配分函数 $Z$：\n$$\nZ = \\sum_{a \\in \\{A,B,C,D\\}} \\exp(1 \\cdot U_i(a))\n$$\n$$\nZ = \\exp(U_i(A)) + \\exp(U_i(B)) + \\exp(U_i(C)) + \\exp(U_i(D))\n$$\n$$\nZ = \\exp(\\ln(2)) + \\exp(\\ln(3)) + \\exp(-\\ln(4)) + \\exp(0)\n$$\n使用性质 $\\exp(\\ln(x))=x$ 和 $\\exp(-\\ln(x)) = \\exp(\\ln(x^{-1})) = x^{-1}$：\n$$\nZ = 2 + 3 + 4^{-1} + 1 = 6 + \\frac{1}{4} = \\frac{24}{4} + \\frac{1}{4} = \\frac{25}{4}\n$$\n现在，我们计算每个行动 $a$ 的概率：\n$$\n\\pi_i(A) = \\frac{\\exp(U_i(A))}{Z} = \\frac{2}{25/4} = \\frac{8}{25} = 0.32\n$$\n$$\n\\pi_i(B) = \\frac{\\exp(U_i(B))}{Z} = \\frac{3}{25/4} = \\frac{12}{25} = 0.48\n$$\n$$\n\\pi_i(C) = \\frac{\\exp(U_i(C))}{Z} = \\frac{1/4}{25/4} = \\frac{1}{25} = 0.04\n$$\n$$\n\\pi_i(D) = \\frac{\\exp(U_i(D))}{Z} = \\frac{1}{25/4} = \\frac{4}{25} = 0.16\n$$\n按要求将这些值四舍五入到四位有效数字：\n$\\pi_i(A) = 0.3200$\n$\\pi_i(B) = 0.4800$\n$\\pi_i(C) = 0.04000$\n$\\pi_i(D) = 0.1600$\n总和为 $0.3200 + 0.4800 + 0.04000 + 0.1600 = 1.0000$，验证了归一化。\n\n最后，我们说明为什么将一个常数 $c$ 加到所有效用上，概率会保持不变。设新的效用为 $U'_i(a) = U_i(a) + c$。新的概率分布 $\\pi'_i(a)$ 由下式给出：\n$$\n\\pi'_i(a) = \\frac{\\exp(\\beta U'_i(a))}{\\sum_{a' \\in \\mathcal{A}} \\exp(\\beta U'_i(a'))}\n$$\n代入 $U'_i(a) = U_i(a) + c$：\n$$\n\\pi'_i(a) = \\frac{\\exp(\\beta (U_i(a) + c))}{\\sum_{a' \\in \\mathcal{A}} \\exp(\\beta (U_i(a') + c))}\n$$\n使用恒等式 $\\exp(x+y) = \\exp(x)\\exp(y)$：\n$$\n\\pi'_i(a) = \\frac{\\exp(\\beta U_i(a)) \\exp(\\beta c)}{\\sum_{a' \\in \\mathcal{A}} [\\exp(\\beta U_i(a')) \\exp(\\beta c)]}\n$$\n因为 $\\exp(\\beta c)$ 是分母求和中每一项的常数因子，所以可以将其提取出来：\n$$\n\\pi'_i(a) = \\frac{\\exp(\\beta U_i(a)) \\exp(\\beta c)}{\\exp(\\beta c) \\sum_{a' \\in \\mathcal{A}} \\exp(\\beta U_i(a'))}\n$$\n因子 $\\exp(\\beta c)$ 非零，可以从分子和分母中约去：\n$$\n\\pi'_i(a) = \\frac{\\exp(\\beta U_i(a))}{\\sum_{a' \\in \\mathcal{A}} \\exp(\\beta U_i(a'))} = \\pi_i(a)\n$$\n这证明了选择概率在效用的一致平移下是不变的。这个性质的产生是因为该模型对选择之间的效用*差异*敏感，而不是它们的绝对值。对所有效用加上一个常数偏移量不会改变这些差异。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.3200  0.4800  0.04000  0.1600\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "基于主体的模型不仅包含主体本身，还包括它们所处的环境。这个环境通常不是静态的，而是动态演变的，例如信息素的挥发、资源的扩散等。本练习将指导你如何使用有限差分法来模拟一个由偏微分方程（扩散方程）描述的动态环境场，这是将连续环境过程离散化以便在ABM中实现的一项基本技能。",
            "id": "4113501",
            "problem": "一个二维环形晶格（双向均为周期性边界）代表了基于代理的建模（ABM）系统中的一个扩散资源场。资源密度场 $u(x,y,t)$ 服从扩散方程 $\\frac{\\partial u}{\\partial t} = D \\nabla^{2} u$，其中 $D$ 是扩散系数。考虑一个空间间距为 $\\Delta x = \\Delta y = 1$ 的离散 $4 \\times 4$ 网格，并使用大小为 $\\Delta t = 0.25$ 的一个显式时间步和扩散系数 $D = 0.4$ 来模拟扩散过程。五点模板源于拉普拉斯算子的二阶中心差分。在时间步 $n = 0$ 时的初始资源图为\n$$\nU^{(0)} = \\begin{pmatrix}\n1  3  0  2 \\\\\n4  1  5  0 \\\\\n2  2  1  3 \\\\\n0  1  4  2\n\\end{pmatrix}.\n$$\n假设采用周期性边界条件（该网格在拓扑上是一个环面；边界单元的邻居会回绕），请从控制扩散方程和有限差分近似中推导出一个时间步的显式更新规则，然后计算经过这单步之后，索引为 $(i,j)=(1,1)$ 的单元格的更新值。请将您的最终答案表示为精确的小数，且不包含任何单位。无需四舍五入。",
            "solution": "该问题要求计算在一个离散晶格上，由扩散方程控制的特定单元格中的资源密度经过一个时间步后的更新值。解答过程需要推导显式的有限差分更新规则，然后使用给定的初始条件和参数来应用它。\n\n资源密度场 $u(x,y,t)$ 的控制偏微分方程是二维扩散方程：\n$$\n\\frac{\\partial u}{\\partial t} = D \\nabla^{2} u = D \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} \\right)\n$$\n其中 $D$ 是扩散系数。\n\n为了数值求解该方程，我们在空间和时间上对其进行离散化。设 $U_{i,j}^{(n)}$ 为在时间步 $n$ 时，索引为 $(i,j)$ 的网格单元处的资源密度。空间坐标为 $x = i\\Delta x$，$y = j\\Delta y$，时间为 $t = n\\Delta t$。\n\n我们使用一阶向前差分（一种显式时间步进格式）来近似左手边的时间导数：\n$$\n\\frac{\\partial u}{\\partial t} \\approx \\frac{U_{i,j}^{(n+1)} - U_{i,j}^{(n)}}{\\Delta t}\n$$\n\n构成拉普拉斯算子 $\\nabla^2 u$ 的空间二阶导数，使用二阶中心差分模板（五点模板）来近似：\n$$\n\\frac{\\partial^2 u}{\\partial x^2} \\approx \\frac{U_{i+1,j}^{(n)} - 2U_{i,j}^{(n)} + U_{i-1,j}^{(n)}}{(\\Delta x)^2}\n$$\n$$\n\\frac{\\partial^2 u}{\\partial y^2} \\approx \\frac{U_{i,j+1}^{(n)} - 2U_{i,j}^{(n)} + U_{i,j-1}^{(n)}}{(\\Delta y)^2}\n$$\n\n将这些离散近似代入连续扩散方程，得到有限差分方程：\n$$\n\\frac{U_{i,j}^{(n+1)} - U_{i,j}^{(n)}}{\\Delta t} = D \\left( \\frac{U_{i+1,j}^{(n)} - 2U_{i,j}^{(n)} + U_{i-1,j}^{(n)}}{(\\Delta x)^2} + \\frac{U_{i,j+1}^{(n)} - 2U_{i,j}^{(n)} + U_{i,j-1}^{(n)}}{(\\Delta y)^2} \\right)\n$$\n\n给定空间间距是均匀的，$\\Delta x = \\Delta y = 1$。这简化了方程。我们现在可以求解更新值 $U_{i,j}^{(n+1)}$：\n$$\nU_{i,j}^{(n+1)} = U_{i,j}^{(n)} + D \\Delta t \\left( U_{i+1,j}^{(n)} - 2U_{i,j}^{(n)} + U_{i-1,j}^{(n)} + U_{i,j+1}^{(n)} - 2U_{i,j}^{(n)} + U_{i,j-1}^{(n)} \\right)\n$$\n合并与 $U_{i,j}^{(n)}$ 相关的项，得到：\n$$\nU_{i,j}^{(n+1)} = U_{i,j}^{(n)} + D \\Delta t \\left( (U_{i+1,j}^{(n)} + U_{i-1,j}^{(n)} + U_{i,j+1}^{(n)} + U_{i,j-1}^{(n)}) - 4U_{i,j}^{(n)} \\right)\n$$\n我们定义无量纲常数 $\\alpha = D \\Delta t$。该方程可以重排为显式更新规则的最终形式：\n$$\nU_{i,j}^{(n+1)} = (1 - 4\\alpha)U_{i,j}^{(n)} + \\alpha\\left(U_{i+1,j}^{(n)} + U_{i-1,j}^{(n)} + U_{i,j+1}^{(n)} + U_{i,j-1}^{(n)}\\right)\n$$\n\n现在，我们代入指定的参数值：$D = 0.4$ 和 $\\Delta t = 0.25$。\n$$\n\\alpha = D \\Delta t = (0.4)(0.25) = 0.1\n$$\n更新规则中的数值系数是：\n$$\n1 - 4\\alpha = 1 - 4(0.1) = 1 - 0.4 = 0.6\n$$\n所以，针对此问题的特定更新规则是：\n$$\nU_{i,j}^{(n+1)} = 0.6 \\, U_{i,j}^{(n)} + 0.1 \\left(U_{i+1,j}^{(n)} + U_{i-1,j}^{(n)} + U_{i,j+1}^{(n)} + U_{i,j-1}^{(n)}\\right)\n$$\n\n我们被要求计算在第一个时间步后，单元格 $(i,j)=(1,1)$ 的更新值，即 $U_{1,1}^{(1)}$。我们假设采用标准的基于1的矩阵索引，其中 $(1,1)$ 表示网格的左上角元素。该网格是一个 $4 \\times 4$ 的晶格，所以 $i$ 和 $j$ 的索引范围是从 $1$ 到 $4$。\n$U_{1,1}^{(1)}$ 的更新公式是：\n$$\nU_{1,1}^{(1)} = 0.6 \\, U_{1,1}^{(0)} + 0.1 \\left(U_{2,1}^{(0)} + U_{0,1}^{(0)} + U_{1,2}^{(0)} + U_{1,0}^{(0)}\\right)\n$$\n题目指定了周期性边界条件。这意味着网格是回绕的。对于一个 $4 \\times 4$ 的网格：\n- 单元格 $(1,j)$ “上方”的邻居是单元格 $(4,j)$，所以 $U_{0,j}^{(n)}$ 等同于 $U_{4,j}^{(n)}$。\n- 单元格 $(i,1)$ “左侧”的邻居是单元格 $(i,4)$，所以 $U_{i,0}^{(n)}$ 等同于 $U_{i,4}^{(n)}$。\n将这些条件应用于我们关于 $U_{1,1}^{(1)}$ 的方程：\n$$\nU_{1,1}^{(1)} = 0.6 \\, U_{1,1}^{(0)} + 0.1 \\left(U_{2,1}^{(0)} + U_{4,1}^{(0)} + U_{1,2}^{(0)} + U_{1,4}^{(0)}\\right)\n$$\n\n初始资源图 $U^{(0)}$ 如下所示：\n$$\nU^{(0)} = \\begin{pmatrix}\n1  3  0  2 \\\\\n4  1  5  0 \\\\\n2  2  1  3 \\\\\n0  1  4  2\n\\end{pmatrix}\n$$\n从这个矩阵中，我们提取所需的值：\n- 中心单元格的值：$U_{1,1}^{(0)} = 1$。\n- 下方的邻居：$U_{2,1}^{(0)} = 4$。\n- 上方的邻居（回绕）：$U_{4,1}^{(0)} = 0$。\n- 右侧的邻居：$U_{1,2}^{(0)} = 3$。\n- 左侧的邻居（回绕）：$U_{1,4}^{(0)} = 2$。\n\n将这些值代入更新方程：\n$$\nU_{1,1}^{(1)} = 0.6 \\times (1) + 0.1 \\times (4 + 0 + 3 + 2)\n$$\n$$\nU_{1,1}^{(1)} = 0.6 + 0.1 \\times (9)\n$$\n$$\nU_{1,1}^{(1)} = 0.6 + 0.9\n$$\n$$\nU_{1,1}^{(1)} = 1.5\n$$\n经过一个时间步后，单元格 $(1,1)$ 的更新值为 $1.5$。",
            "answer": "$$\\boxed{1.5}$$"
        }
    ]
}