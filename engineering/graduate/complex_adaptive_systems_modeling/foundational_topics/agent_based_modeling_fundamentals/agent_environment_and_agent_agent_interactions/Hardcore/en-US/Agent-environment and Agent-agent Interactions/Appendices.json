{
    "hands_on_practices": [
        {
            "introduction": "We begin by exploring one of the foundational models of agent-agent interaction: the Hawk-Dove game. This exercise guides you through the process of translating strategic choices into a mathematical framework and predicting the long-term composition of a population using replicator dynamics. By analyzing the stability of different population states , you will gain direct insight into how the balance between the value of a resource, $V$, and the cost of conflict, $C$, determines whether a population evolves to a single aggressive strategy or a stable mix of aggressive and passive agents.",
            "id": "4113883",
            "problem": "Consider a large, well-mixed population of agents with two pure strategies, Hawk ($H$) and Dove ($D$), engaged in pairwise contests for a resource of benefit $V>0$. If two Hawks meet, each receives an expected payoff of $(V-C)/2$ due to the probability of injury with cost $C>0$. If a Hawk meets a Dove, the Hawk obtains $V$ and the Dove obtains $0$. If two Doves meet, each receives $V/2$. Let $x \\in [0,1]$ denote the fraction of Hawks in the population. Assume selection dynamics follow the replicator equation derived from evolutionary game theory, where the growth rate of a strategy is proportional to its payoff advantage over the population average.\n\nStarting from the core definitions of expected payoff under random matching and the replicator dynamics, derive the one-dimensional ordinary differential equation for $x(t)$ and use it to compute all fixed points. Analyze the linear stability of each fixed point explicitly in terms of $V$ and $C$. Identify the parameter regime in which a mixed interior equilibrium exists and determine its local stability. Interpret your results in the context of agent-agent interactions in a complex adaptive system, explaining how interaction payoffs shape the population composition.\n\nYour final reported quantity must be the analytic expression for the interior fixed point fraction of Hawks $x^{\\ast}$ as a function of $V$ and $C$, in the parameter regime where it exists. Express your final answer as a closed-form expression and do not include any units. No rounding is required.",
            "solution": "The problem statement has been validated and found to be self-contained, scientifically grounded in evolutionary game theory, and well-posed. We may proceed with the solution.\n\nThe problem describes the Hawk-Dove game. Let $H$ denote the Hawk strategy and $D$ denote the Dove strategy. The payoffs for pairwise contests are given. We can represent these payoffs in a matrix $A$, where the entry $A_{ij}$ is the payoff to a player using strategy $i$ when playing against a player using strategy $j$. Let the first row/column correspond to Hawk and the second to Dove.\nThe payoffs are:\n- Hawk vs. Hawk: Each receives $\\frac{V-C}{2}$. Thus, $A_{HH} = \\frac{V-C}{2}$.\n- Hawk vs. Dove: Hawk receives $V$, Dove receives $0$. Thus, $A_{HD} = V$ and $A_{DH} = 0$.\n- Dove vs. Dove: Each receives $\\frac{V}{2}$. Thus, $A_{DD} = \\frac{V}{2}$.\n\nThe payoff matrix is therefore:\n$$ A = \\begin{pmatrix} \\frac{V-C}{2} & V \\\\ 0 & \\frac{V}{2} \\end{pmatrix} $$\nThe population consists of a fraction $x$ of Hawks and a fraction $1-x$ of Doves, where $x \\in [0,1]$. We assume random matching. The expected payoff for a Hawk, $E_H(x)$, is its payoff against a Hawk weighted by the probability of meeting a Hawk ($x$), plus its payoff against a Dove weighted by the probability of meeting a Dove ($1-x$):\n$$ E_H(x) = x \\cdot A_{HH} + (1-x) \\cdot A_{HD} = x \\left(\\frac{V-C}{2}\\right) + (1-x)V $$\n$$ E_H(x) = \\frac{Vx}{2} - \\frac{Cx}{2} + V - Vx = V - \\frac{Cx}{2} - \\frac{Vx}{2} $$\nSimilarly, the expected payoff for a Dove, $E_D(x)$, is:\n$$ E_D(x) = x \\cdot A_{DH} + (1-x) \\cdot A_{DD} = x(0) + (1-x)\\frac{V}{2} = \\frac{V}{2} - \\frac{Vx}{2} $$\nThe replicator equation describes the evolution of the fraction $x$ of Hawks. The growth rate of a strategy's population share is proportional to the difference between its expected payoff and the average payoff of the population, $\\bar{E}(x)$. The equation is:\n$$ \\frac{dx}{dt} = x(E_H(x) - \\bar{E}(x)) $$\nwhere $\\bar{E}(x) = x E_H(x) + (1-x) E_D(x)$. A more convenient form of the replicator equation is:\n$$ \\frac{dx}{dt} = x(1-x)(E_H(x) - E_D(x)) $$\nLet's compute the difference in expected payoffs:\n$$ E_H(x) - E_D(x) = \\left(V - \\frac{Cx}{2} - \\frac{Vx}{2}\\right) - \\left(\\frac{V}{2} - \\frac{Vx}{2}\\right) = V - \\frac{Cx}{2} - \\frac{V}{2} = \\frac{V}{2} - \\frac{Cx}{2} = \\frac{1}{2}(V-Cx) $$\nSubstituting this into the replicator equation gives the one-dimensional ordinary differential equation for $x(t)$:\n$$ \\frac{dx}{dt} = \\frac{1}{2} x(1-x)(V-Cx) $$\nFixed points, denoted by $x^*$, are solutions to $\\frac{dx}{dt} = 0$.\n$$ \\frac{1}{2} x^*(1-x^*)(V-Cx^*) = 0 $$\nThis equation yields three potential fixed points:\n1. $x^*_1 = 0$ (a pure Dove population)\n2. $x^*_2 = 1$ (a pure Hawk population)\n3. $x^*_3 = \\frac{V}{C}$ (an interior, or mixed, population)\n\nTo analyze the stability of these fixed points, we examine the sign of the derivative of the right-hand side of the ODE, which we denote as $f(x) = \\frac{1}{2} x(1-x)(V-Cx)$. A fixed point $x^*$ is locally stable if $f'(x^*)  0$ and unstable if $f'(x^*) > 0$.\nLet's compute $f'(x)$ using the product rule:\n$$f(x) = \\frac{1}{2} (x-x^2)(V-Cx)$$\n$$f'(x) = \\frac{1}{2} \\left[ (1-2x)(V-Cx) + (x-x^2)(-C) \\right]$$\n\nNow, we evaluate $f'(x)$ at each fixed point:\n- Stability of $x^*_1 = 0$:\n$$ f'(0) = \\frac{1}{2} \\left[ (1-0)(V-0) + (0-0)(-C) \\right] = \\frac{1}{2}V $$\nSince $V>0$ is given, $f'(0) > 0$. Thus, the fixed point $x^*_1=0$ is **unstable**. This means that if a small number of Hawks are introduced into a Dove population, their fraction will grow.\n\n- Stability of $x^*_2 = 1$:\n$$ f'(1) = \\frac{1}{2} \\left[ (1-2)(V-C) + (1-1)(-C) \\right] = \\frac{1}{2} (-1)(V-C) = \\frac{1}{2}(C-V) $$\nThe stability depends on the relative values of $C$ and $V$.\n  - If $V > C$, then $C-V  0$, so $f'(1)  0$. The fixed point $x^*_2=1$ is **stable**.\n  - If $C > V$, then $C-V > 0$, so $f'(1) > 0$. The fixed point $x^*_2=1$ is **unstable**.\n\n- Stability of the interior fixed point $x^*_3 = V/C$:\nThis fixed point is biologically meaningful only if it lies within the interval $(0, 1)$. Since $V>0$ and $C>0$, $x^*_3 > 0$ is always true. The condition $x^*_3  1$ requires $\\frac{V}{C}  1$, which implies $C > V$. Therefore, a mixed interior equilibrium exists only in the parameter regime where the cost of injury is greater than the value of the resource, i.e., $C > V$.\n\nLet's analyze its stability in this regime ($C > V$):\n$$ f'\\left(\\frac{V}{C}\\right) = \\frac{1}{2} \\left[ \\left(1-2\\frac{V}{C}\\right)\\left(V-C\\frac{V}{C}\\right) + \\left(\\frac{V}{C}-\\left(\\frac{V}{C}\\right)^2\\right)(-C) \\right] $$\nThe term $(V-C\\frac{V}{C})$ is $(V-V)=0$.\n$$ f'\\left(\\frac{V}{C}\\right) = \\frac{1}{2} \\left[ 0 + \\left(\\frac{V}{C}-\\frac{V^2}{C^2}\\right)(-C) \\right] = \\frac{1}{2} \\left[ \\frac{V}{C}\\left(1-\\frac{V}{C}\\right)(-C) \\right] = -\\frac{V}{2}\\left(1-\\frac{V}{C}\\right) $$\nIn the regime where this fixed point exists, $C > V$, which means $\\frac{V}{C}  1$, so $1 - \\frac{V}{C} > 0$. Since $V>0$ is given, all terms in the expression for the derivative are positive, except for the leading minus sign.\nTherefore, $f'(V/C)  0$. The interior fixed point $x^*_3 = V/C$ is **locally stable** whenever it exists.\n\nInterpretation in the context of agent-agent interactions:\nThe model shows how population-level structure emerges from simple, local interaction rules (the payoffs).\n- **If $V > C$**: The benefit of the resource outweighs the cost of conflict. Aggressive (Hawk) behavior is always favored. The system evolves to a monoculture of Hawks ($x=1$). The interactions drive out cooperative/non-aggressive (Dove) agents.\n- **If $C > V$**: The cost of conflict is high. While a pure Hawk population is unstable (a mutant Dove would not suffer from costly fights and would invade), a pure Dove population is also unstable (a mutant Hawk would easily exploit the Doves). The system self-organizes to a stable polymorphic state where both Hawks and Doves coexist. The fraction of Hawks, $x^* = V/C$, is precisely balanced such that the expected payoffs for both strategies are equal ($E_H(x^*) = E_D(x^*)$). This stable mixed state is an example of an evolutionarily stable state, a central concept in complex adaptive systems where agent strategies are subject to selection. The local agent-agent interactions (payoffs) dynamically regulate the global population composition, maintaining diversity.\n\nThe problem asks for the analytic expression for the interior fixed point fraction of Hawks, $x^*$, in the parameter regime where it exists. This fixed point is $x^*_3 = V/C$, and it exists in the regime $C > V$.",
            "answer": "$$\\boxed{\\frac{V}{C}}$$"
        },
        {
            "introduction": "Real-world interactions are rarely one-shot encounters. This practice moves beyond static games to the richer domain of repeated interactions, using the classic Prisoner's Dilemma as a stage. You will investigate the conditions under which the famous Tit-for-Tat (TFT) strategy can sustain mutual cooperation, introducing the crucial concepts of future discounting and subgame perfect equilibrium . This analysis reveals how the \"shadow of the future,\" represented by the discount factor $\\delta$, can incentivize cooperative behavior even when defection is profitable in the short term.",
            "id": "4113889",
            "problem": "Consider two agents engaged in an infinitely repeated Prisoner’s Dilemma stage game with standard payoffs: mutual cooperation yields reward payoff $R$, unilateral defection yields the defector the temptation payoff $T$ and the cooperator the sucker payoff $S$, and mutual defection yields punishment payoff $P$, with $T > R > P > S$ and $2R > T + S$. The environment introduces additive shocks to payoffs: in each period $t$, each player’s realized stage payoff is $\\pi(a_{t}^{i}, a_{t}^{-i}) + \\eta_{t}$, where $\\pi(\\cdot)$ denotes the baseline Prisoner’s Dilemma payoff, and $\\{\\eta_{t}\\}_{t \\geq 1}$ are independent and identically distributed shocks with $\\mathbb{E}[\\eta_{t}] = 0$, finite variance, independent of actions and histories. Players are risk-neutral and maximize the expected discounted sum of realized payoffs with common discount factor $\\delta \\in (0,1)$.\n\nBoth players use the memory-one reactive strategy tit-for-tat (TFT): cooperate in period $t=1$, and for $t \\geq 2$ play the opponent’s last realized action. Actions are perfectly observed each period, and shocks do not affect action execution or observation.\n\nStarting from foundational definitions of subgame perfect equilibrium and the one-shot deviation principle in dynamic games, derive the set of incentive constraints at on-path and off-path histories that must hold for tit-for-tat to be a subgame perfect equilibrium under the described noisy environment. Then, analytically determine the closed-form expression for the cooperative-history threshold $\\delta_{C}$, defined as the minimum discount factor that weakly deters a one-shot deviation to defection at a history where both players have just cooperated and the strategy prescribes continued cooperation. Express $\\delta_{C}$ as a function of $T$, $R$, $P$, and $S$.\n\nNo rounding is required. The final expression should be exact and simplified.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is a standard problem in repeated game theory, a topic central to the study of agent-agent interactions in complex adaptive systems. All parameters and strategic rules are clearly defined. I will proceed with the solution.\n\nThe agents are risk-neutral and seek to maximize the expected discounted sum of their realized payoffs. Let $V^i$ be the value function for player $i$. The objective is to maximize:\n$$\nV^i = \\mathbb{E}\\left[ \\sum_{t=1}^{\\infty} \\delta^{t-1} \\left( \\pi(a_{t}^{i}, a_{t}^{-i}) + \\eta_{t} \\right) \\right]\n$$\nwhere $a_t^i$ is the action of player $i$ at time $t$, $a_t^{-i}$ is the action of the other player, $\\pi(\\cdot)$ is the standard Prisoner's Dilemma payoff, $\\delta \\in (0,1)$ is the common discount factor, and $\\eta_t$ are i.i.d. noise terms with $\\mathbb{E}[\\eta_t] = 0$.\n\nBy the linearity of expectation, the value function can be split:\n$$\nV^i = \\mathbb{E}\\left[ \\sum_{t=1}^{\\infty} \\delta^{t-1} \\pi(a_{t}^{i}, a_{t}^{-i}) \\right] + \\mathbb{E}\\left[ \\sum_{t=1}^{\\infty} \\delta^{t-1} \\eta_{t} \\right]\n$$\nThe second term simplifies to:\n$$\n\\sum_{t=1}^{\\infty} \\delta^{t-1} \\mathbb{E}[\\eta_{t}] = \\sum_{t=1}^{\\infty} \\delta^{t-1} (0) = 0\n$$\nTherefore, the agents' strategic problem is to maximize the expected discounted sum of standard payoffs, $V^i = \\mathbb{E}\\left[ \\sum_{t=1}^{\\infty} \\delta^{t-1} \\pi(a_{t}^{i}, a_{t}^{-i}) \\right]$. The additive, zero-mean payoff shocks are irrelevant to the decision-making of risk-neutral players. Since actions are perfectly observed and non-stochastic, the problem reduces to a standard analysis of a repeated game without noise.\n\nTo verify if the Tit-for-Tat (TFT) strategy profile is a Subgame Perfect Equilibrium (SPE), we use the one-shot deviation principle. We must check that for any possible history, no player has an incentive to deviate from the TFT strategy for one period and then revert to it. With the memory-one TFT strategy, the relevant history is defined by the outcome of the previous period. There are four classes of subgames to check, corresponding to the previous outcome being $(C,C)$, $(C,D)$, $(D,C)$, or $(D,D)$.\n\nLet C denote cooperation and D denote defection. The payoffs are denoted by $T > R > P > S$.\n\n**1. Derivation of Incentive Constraints for SPE**\n\n**Case 1: History where the previous outcome was $(C,C)$.**\nThis is the on-path history after mutual cooperation.\n- **TFT Prescription**: Both players cooperate. The expected sequence of outcomes is $(C,C)$ in perpetuity.\n- **Value of Cooperating (staying on path)**: The payoff is $R$ in every period. The discounted value is:\n  $$ V_{C|CC} = R + \\delta R + \\delta^2 R + \\dots = \\frac{R}{1-\\delta} $$\n- **Value of a One-Shot Deviation**: Player $i$ deviates to D for one period.\n  - In the current period, player $i$ plays D while player $j$ plays C. The outcome is $(D,C)$, and player $i$'s payoff is $T$.\n  - In the next period, the previous outcome was $(D,C)$. Player $i$'s TFT rule is to play C (opponent's last move). Player $j$'s TFT rule is to play D (opponent's last move). The outcome is $(C,D)$, and player $i$'s payoff is $S$.\n  - In the period after, the previous outcome was $(C,D)$. Player $i$ plays D, player $j$ plays C. The outcome is $(D,C)$, and player $i$'s payoff is $T$.\n  - The payoff stream following the deviation is $T, S, T, S, \\dots$. The discounted value is:\n  $$ V_{D|CC} = T + \\delta S + \\delta^2 T + \\delta^3 S + \\dots = (T + \\delta S)(1 + \\delta^2 + \\delta^4 + \\dots) = \\frac{T + \\delta S}{1-\\delta^2} $$\n- **Incentive Constraint 1 (IC1)**: To prevent deviation, we must have $V_{C|CC} \\ge V_{D|CC}$.\n  $$ \\frac{R}{1-\\delta} \\ge \\frac{T + \\delta S}{1-\\delta^2} \\implies R(1+\\delta) \\ge T + \\delta S \\implies \\delta(R-S) \\ge T-R $$\n\n**Case 2: History where the previous outcome was $(D,C)$ (Player $i$ defected, Player $j$ cooperated).**\nThis is an off-path history.\n- **TFT Prescription**: Player $i$ plays C, player $j$ plays D. The outcome is $(C,D)$, yielding payoff $S$ for player $i$. The play will then alternate between $(D,C)$ and $(C,D)$.\n- **Value of Following TFT**: The payoff stream is $S, T, S, T, \\dots$. The discounted value is:\n  $$ V_{C|DC} = S + \\delta T + \\delta^2 S + \\dots = \\frac{S + \\delta T}{1-\\delta^2} $$\n- **Value of a One-Shot Deviation**: Player $i$ deviates to D. Player $j$ plays D as prescribed.\n  - The outcome is $(D,D)$, and player $i$'s payoff is $P$.\n  - In all subsequent periods, the previous outcome is $(D,D)$, so both players play D. The payoff is $P$ in perpetuity.\n  - The value is: $V_{D|DC} = P + \\delta P + \\dots = \\frac{P}{1-\\delta}$.\n- **Incentive Constraint 2 (IC2)**: To prevent deviation, $V_{C|DC} \\ge V_{D|DC}$.\n  $$ \\frac{S + \\delta T}{1-\\delta^2} \\ge \\frac{P}{1-\\delta} \\implies S + \\delta T \\ge P(1+\\delta) \\implies \\delta(T-P) \\ge P-S $$\n\n**Case 3: History where the previous outcome was $(C,D)$ (Player $i$ cooperated, Player $j$ defected).**\nThis is an off-path history, symmetric to Case 2 for player $i$.\n- **TFT Prescription**: Player $i$ plays D, player $j$ plays C. The outcome is $(D,C)$, yielding $T$ to player $i$. The play will then alternate.\n- **Value of Following TFT**: The payoff stream is $T, S, T, S, \\dots$. The discounted value is:\n  $$ V_{D|CD} = T + \\delta S + \\delta^2 T + \\dots = \\frac{T + \\delta S}{1-\\delta^2} $$\n- **Value of a One-Shot Deviation**: Player $i$ deviates to C. Player $j$ plays C as prescribed.\n  - The outcome is $(C,C)$, and player $i$'s payoff is $R$.\n  - This restores mutual cooperation, which continues forever. The total value of deviating is: $V_{C|CD} = R + \\delta R + \\dots = \\frac{R}{1-\\delta}$.\n- **Incentive Constraint 3 (IC3)**: To prevent this \"forgiveness\" deviation, $V_{D|CD} \\ge V_{C|CD}$.\n  $$ \\frac{T + \\delta S}{1-\\delta^2} \\ge \\frac{R}{1-\\delta} \\implies T + \\delta S \\ge R(1+\\delta) \\implies T-R \\ge \\delta(R-S) $$\n\n**Case 4: History where the previous outcome was $(D,D)$.**\nThis is an off-path history.\n- **TFT Prescription**: Both players play D. The outcome is $(D,D)$ in perpetuity.\n- **Value of Following TFT**: The payoff is $P$ forever. The value is:\n  $$ V_{D|DD} = P + \\delta P + \\dots = \\frac{P}{1-\\delta} $$\n- **Value of a One-Shot Deviation**: Player $i$ deviates to C. Player $j$ plays D.\n  - The outcome is $(C,D)$, payoff $S$. Play then alternates.\n  - The value is: $V_{C|DD} = S + \\delta T + \\delta^2 S + \\dots = \\frac{S + \\delta T}{1-\\delta^2}$.\n- **Incentive Constraint 4 (IC4)**: To prevent this \"repentance\" deviation, $V_{D|DD} \\ge V_{C|DD}$.\n  $$ \\frac{P}{1-\\delta} \\ge \\frac{S + \\delta T}{1-\\delta^2} \\implies P(1+\\delta) \\ge S + \\delta T \\implies P-S \\ge \\delta(T-P) $$\n\nThe complete set of incentive constraints for TFT to be a subgame perfect equilibrium is therefore:\n1.  From a $(C,C)$ history: $\\delta(R-S) \\ge T-R$\n2.  From a $(D,C)$ history: $\\delta(T-P) \\ge P-S$\n3.  From a $(C,D)$ history: $T-R \\ge \\delta(R-S)$\n4.  From a $(D,D)$ history: $P-S \\ge \\delta(T-P)$\n\n**2. Determination of the Cooperative-History Threshold $\\delta_C$**\n\nThe problem defines $\\delta_C$ as the minimum discount factor that weakly deters a one-shot deviation to defection at a history where both players have just cooperated. This corresponds precisely to the incentive constraint derived in Case 1.\n\nThe constraint is:\n$$ \\delta(R-S) \\ge T-R $$\nGiven the payoff structure $T > R > S$, both $(R-S)$ and $(T-R)$ are positive quantities. We can solve for $\\delta$ by dividing by $(R-S)$:\n$$ \\delta \\ge \\frac{T-R}{R-S} $$\nThe cooperative-history threshold, $\\delta_C$, is the minimum value of $\\delta$ that satisfies this inequality. This occurs when the inequality is binding:\n$$ \\delta_C = \\frac{T-R}{R-S} $$\nThe problem provides the condition $2R > T+S$, which can be rewritten as $R-S > T-R$. Since $R-S>0$, this implies $\\frac{T-R}{R-S}  1$. Also, since $T>R$, $\\delta_C > 0$. Thus, this threshold value lies within the valid range for a discount factor, $\\delta_C \\in (0,1)$.",
            "answer": "$$\\boxed{\\frac{T-R}{R-S}}$$"
        },
        {
            "introduction": "Agent interactions are not isolated; they are embedded within environments that respond to and influence their aggregate behavior, often with inherent delays. This exercise explores the profound impact of time lags in agent-environment feedback loops using the tools of dynamical systems. By analyzing a linear delay-differential equation , you will derive from first principles how a simple, stable system can be pushed into a state of persistent oscillation, a phenomenon known as a Hopf bifurcation. This practice demonstrates how systemic properties, like information latency, can be a primary driver of complex emergent dynamics.",
            "id": "4113902",
            "problem": "Consider a large population of interacting agents coupled to a shared environment. Let the macroscopic deviation of the population’s aggregate state from an equilibrium be denoted by $x(t)$, and let an environmental actuation signal $u(t)$ be determined by a policy map $\\pi(\\cdot)$ applied to a delayed observation of the aggregate state, $u(t)=\\pi\\!\\left(x(t-\\tau)\\right)$, where $\\tau>0$ is a sensing-and-execution delay arising from agent-environment and agent-agent information-processing latencies. Suppose that near the equilibrium $x^{\\ast}=0$ the joint agent-environment dynamics can be linearized to\n$$x'(t)=\\alpha\\,x(t)+\\beta\\,u(t)$$\nand the policy can be linearized to\n$u(t)\\approx k\\,x(t-\\tau)$\nwith constant coefficients $\\alpha,\\beta,k\\in\\mathbb{R}$ determined by the micro-to-macro closure (for example, $\\alpha$ encodes intrinsic agent relaxation, $\\beta$ the environment-to-agent gain, and $k=\\pi'(0)$ the local policy slope). Assume that this linearization is valid and that a Hopf bifurcation is the relevant local instability mechanism, defined by the crossing of a complex-conjugate pair of characteristic roots through the imaginary axis.\n\nStarting only from the linearized delay-coupled system and the definition of a Hopf bifurcation, derive the necessary condition for a pair of purely imaginary characteristic roots and obtain the smallest positive critical delay $\\tau_{c}$ at which the equilibrium $x^{\\ast}=0$ loses stability through a Hopf bifurcation, expressed in terms of $\\alpha$, $\\beta$, and $k$. Your derivation must proceed from first principles by positing exponential solutions and separating real and imaginary parts, and it must identify any nondegeneracy condition required for the existence of purely imaginary roots.\n\nThen, for the specific high-gain negative feedback case with $\\alpha=-0.4\\,\\text{s}^{-1}$, $\\beta=1.0\\,\\text{s}^{-1}$, and $k=-1.0$ (so that $u(t)\\approx -x(t-\\tau)$), compute the numerical value of the smallest positive $\\tau_{c}$ in seconds. Express all angles in radians. Round your final numerical answer to $4$ significant figures and report it in seconds.",
            "solution": "The problem as stated is formally sound and well-posed within the framework of dynamical systems theory. It presents a standard analysis of a linear delay-differential equation, a valid and widely used model in many STEM fields. All given parameters and definitions are clear, consistent, and scientifically grounded. Therefore, proceeding to a solution is warranted.\n\nThe linearized system is described by two equations:\n$$x'(t) = \\alpha\\,x(t) + \\beta\\,u(t)$$\n$$u(t) = k\\,x(t-\\tau)$$\n\nSubstituting the second equation into the first yields a single linear delay-differential equation (DDE) for the aggregate state deviation $x(t)$:\n$$\nx'(t) = \\alpha\\,x(t) + \\beta k\\,x(t-\\tau)\n$$\nTo analyze the stability of the equilibrium $x(t) = 0$, we seek solutions of the form $x(t) = C e^{\\lambda t}$, where $\\lambda \\in \\mathbb{C}$ is a characteristic root and $C$ is a non-zero constant. Substituting this ansatz into the DDE gives:\n$$\n\\lambda C e^{\\lambda t} = \\alpha C e^{\\lambda t} + \\beta k C e^{\\lambda(t-\\tau)}\n$$\nDividing by $C e^{\\lambda t}$ yields the characteristic equation for the roots $\\lambda$:\n$$\n\\lambda = \\alpha + \\beta k e^{-\\lambda \\tau}\n$$\nA Hopf bifurcation occurs when a pair of complex-conjugate roots crosses the imaginary axis as a parameter (here, the delay $\\tau$) is varied. At the bifurcation point, there exists a purely imaginary root $\\lambda = i\\omega_c$, where $\\omega_c \\in \\mathbb{R}$ and $\\omega_c \\neq 0$. Without loss of generality, we take $\\omega_c > 0$ to represent the oscillatory frequency at the onset of instability.\n\nSubstituting $\\lambda = i\\omega_c$ into the characteristic equation:\n$$\ni\\omega_c = \\alpha + \\beta k e^{-i\\omega_c \\tau}\n$$\nUsing Euler's formula, $e^{-i\\theta} = \\cos(\\theta) - i\\sin(\\theta)$, we expand the exponential term:\n$$\ni\\omega_c = \\alpha + \\beta k (\\cos(\\omega_c \\tau) - i\\sin(\\omega_c \\tau))\n$$\n$$\ni\\omega_c = (\\alpha + \\beta k \\cos(\\omega_c \\tau)) - i(\\beta k \\sin(\\omega_c \\tau))\n$$\nFor this equality to hold, the real and imaginary parts on both sides of the equation must be equal.\n\nEquating the real parts:\n$$\n0 = \\alpha + \\beta k \\cos(\\omega_c \\tau) \\quad \\implies \\quad \\cos(\\omega_c \\tau) = -\\frac{\\alpha}{\\beta k}\n$$\nEquating the imaginary parts:\n$$\n\\omega_c = - \\beta k \\sin(\\omega_c \\tau) \\quad \\implies \\quad \\sin(\\omega_c \\tau) = -\\frac{\\omega_c}{\\beta k}\n$$\nFor these equations to be consistent, the delay $\\tau$ must be such that these two conditions are met simultaneously for some $\\omega_c > 0$. We can eliminate $\\tau$ by using the fundamental trigonometric identity $\\cos^2(\\theta) + \\sin^2(\\theta) = 1$ with $\\theta = \\omega_c \\tau$:\n$$\n\\left(-\\frac{\\alpha}{\\beta k}\\right)^2 + \\left(-\\frac{\\omega_c}{\\beta k}\\right)^2 = 1\n$$\n$$\n\\frac{\\alpha^2}{(\\beta k)^2} + \\frac{\\omega_c^2}{(\\beta k)^2} = 1\n$$\n$$\n\\alpha^2 + \\omega_c^2 = (\\beta k)^2\n$$\nSolving for $\\omega_c^2$:\n$$\n\\omega_c^2 = (\\beta k)^2 - \\alpha^2\n$$\nFor a Hopf bifurcation to occur, we require a non-zero real frequency $\\omega_c$, which means $\\omega_c^2 > 0$. This leads to the necessary nondegeneracy condition:\n$$\n(\\beta k)^2 > \\alpha^2 \\quad \\text{or equivalently} \\quad |\\beta k| > |\\alpha|\n$$\nIf this condition holds, the frequency of the emergent oscillations at the bifurcation point is:\n$$\n\\omega_c = \\sqrt{(\\beta k)^2 - \\alpha^2}\n$$\nNow we solve for the critical delay $\\tau_c$. We have the system:\n$$\n\\cos(\\omega_c \\tau) = -\\frac{\\alpha}{\\beta k} \\quad \\text{and} \\quad \\sin(\\omega_c \\tau) = -\\frac{\\omega_c}{\\beta k}\n$$\nThe value of $\\omega_c \\tau$ is determined by these two equations. Let $\\theta_0 = \\arccos\\left(-\\frac{\\alpha}{\\beta k}\\right)$, where the range of $\\arccos$ is $[0, \\pi]$. This angle has a non-negative sine, $\\sin(\\theta_0) \\geq 0$. We must match the sign of $\\sin(\\omega_c \\tau) = - \\omega_c / (\\beta k)$.\n\nCase 1: $\\beta k  0$. In this case, $-\\frac{\\omega_c}{\\beta k} > 0$. This matches the sign of $\\sin(\\theta_0)$. Thus, the set of possible angles is $\\omega_c \\tau = \\theta_0 + 2n\\pi$ for $n \\in \\mathbb{Z}$. The smallest positive delay $\\tau_c$ corresponds to $n=0$:\n$$\n\\tau_c = \\frac{1}{\\omega_c} \\arccos\\left(-\\frac{\\alpha}{\\beta k}\\right) \\quad \\text{for} \\quad \\beta k  0\n$$\nCase 2: $\\beta k > 0$. In this case, $-\\frac{\\omega_c}{\\beta k}  0$. This requires an angle with a negative sine. The smallest positive angle is $2\\pi - \\theta_0$. Thus, $\\omega_c \\tau = 2\\pi - \\theta_0 + 2n\\pi$. The smallest positive delay $\\tau_c$ corresponds to $n=0$:\n$$\n\\tau_c = \\frac{1}{\\omega_c} \\left(2\\pi - \\arccos\\left(-\\frac{\\alpha}{\\beta k}\\right)\\right) \\quad \\text{for} \\quad \\beta k > 0\n$$\nThese are the general expressions for the smallest positive critical delay.\n\nNow, we apply this to the specific case provided: $\\alpha = -0.4\\,\\text{s}^{-1}$, $\\beta = 1.0\\,\\text{s}^{-1}$, and $k = -1.0$.\n\nFirst, compute the product $\\beta k$:\n$$\n\\beta k = (1.0\\,\\text{s}^{-1})(-1.0) = -1.0\\,\\text{s}^{-1}\n$$\nSince $\\beta k  0$, we will use the formula from Case 1.\n\nNext, check the nondegeneracy condition $|\\beta k| > |\\alpha|$:\n$$\n|\\beta k| = |-1.0\\,\\text{s}^{-1}| = 1.0\\,\\text{s}^{-1}\n$$\n$$\n|\\alpha| = |-0.4\\,\\text{s}^{-1}| = 0.4\\,\\text{s}^{-1}\n$$\nThe condition $1.0 > 0.4$ is satisfied. A Hopf bifurcation is therefore possible.\n\nCalculate the critical frequency $\\omega_c$:\n$$\n\\omega_c = \\sqrt{(\\beta k)^2 - \\alpha^2} = \\sqrt{(-1.0)^2 - (-0.4)^2} = \\sqrt{1.0 - 0.16} = \\sqrt{0.84}\\,\\text{s}^{-1}\n$$\nNow, calculate the argument of the arccosine function:\n$$\n-\\frac{\\alpha}{\\beta k} = -\\frac{-0.4}{-1.0} = -0.4\n$$\nUsing the formula for $\\tau_c$ when $\\beta k  0$:\n$$\n\\tau_c = \\frac{1}{\\omega_c} \\arccos\\left(-\\frac{\\alpha}{\\beta k}\\right) = \\frac{1}{\\sqrt{0.84}} \\arccos(-0.4)\n$$\nWe now compute the numerical value. Angles must be in radians.\n$$\n\\arccos(-0.4) \\approx 1.98231368 \\text{ rad}\n$$\n$$\n\\sqrt{0.84} \\approx 0.916515139 \\text{ s}^{-1}\n$$\n$$\n\\tau_c \\approx \\frac{1.98231368}{0.916515139} \\text{ s} \\approx 2.1628731 \\text{ s}\n$$\nRounding the result to $4$ significant figures, we get:\n$$\n\\tau_c \\approx 2.163 \\text{ s}\n$$",
            "answer": "$$\n\\boxed{2.163}\n$$"
        }
    ]
}