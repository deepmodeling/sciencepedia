{
    "hands_on_practices": [
        {
            "introduction": "A defining characteristic of chaotic systems is their sensitive dependence on initial conditions, where tiny initial uncertainties grow exponentially. The Largest Lyapunov Exponent (LLE), denoted by $\\lambda$, provides a precise measure of this rate of divergence. This exercise  offers a direct, hands-on application of this concept by asking you to calculate the predictability horizon—the finite time beyond which the system's state becomes practically unpredictable. By connecting the abstract LLE to a tangible forecast limit, you will gain a deeper appreciation for the practical implications of living in and modeling a world with chaotic dynamics.",
            "id": "4135136",
            "problem": "Consider a high-dimensional agent-based ecological network with adaptive interactions in which macroscopic observables are coarse-grained to a one-dimensional effective flow. The system is operating near the edge of chaos, where the largest Lyapunov exponent (LLE) is positive but modest, indicating sensitive dependence on initial conditions without complete disorder. The largest Lyapunov exponent $\\lambda$ for the effective coarse-grained flow is defined by\n$$\n\\lambda \\equiv \\lim_{t \\to \\infty} \\frac{1}{t} \\ln \\frac{\\|\\delta \\mathbf{x}(t)\\|}{\\|\\delta \\mathbf{x}(0)\\|},\n$$\nfor trajectories starting with an infinitesimal separation $\\delta \\mathbf{x}(0)$ in state space and evolving under the same dynamics. Assume the separation dynamics are sufficiently smooth that, for small enough uncertainty $\\delta_0 \\equiv \\|\\delta \\mathbf{x}(0)\\|$, the separation magnitude evolves approximately exponentially at rate $\\lambda$ until it reaches a tolerable macroscopic error threshold $\\Delta$ in the coarse-grained observable.\n\nStarting from the definition above and the assumption of exponential error growth governed by the largest Lyapunov exponent, derive an expression for the predictability horizon time $T$ (the time at which the initial uncertainty $\\delta_0$ reaches the threshold $\\Delta$), and then compute $T$ for the following scenario:\n- The measured largest Lyapunov exponent is $\\lambda = 0.35$ $\\text{min}^{-1}$.\n- The initial uncertainty is $\\delta_0 = 2.5 \\times 10^{-6}$ (in the chosen state-space units).\n- The tolerable macroscopic error is $\\Delta = 5.0 \\times 10^{-3}$ (in the same state-space units).\n\nExpress your final answer for $T$ in minutes and round your numerical result to four significant figures.",
            "solution": "The problem requires the derivation of an expression for the predictability horizon time, $T$, for a system exhibiting chaotic dynamics, and a subsequent calculation of its value given specific parameters. The analysis begins with the definition of the largest Lyapunov exponent (LLE), $\\lambda$, which quantifies the average rate of exponential divergence of nearby trajectories in a state space.\n\nThe formal definition of the LLE is provided as:\n$$\n\\lambda \\equiv \\lim_{t \\to \\infty} \\frac{1}{t} \\ln \\frac{\\|\\delta \\mathbf{x}(t)\\|}{\\|\\delta \\mathbf{x}(0)\\|}\n$$\nwhere $\\|\\delta \\mathbf{x}(t)\\|$ is the magnitude of the separation between two infinitesimally close trajectories at time $t$, and $\\|\\delta \\mathbf{x}(0)\\|$ is their initial separation.\n\nThe problem states that for a sufficiently small initial separation, the evolution of this separation can be approximated by a purely exponential growth at the rate $\\lambda$. Let the initial uncertainty be denoted by $\\delta_0 \\equiv \\|\\delta \\mathbf{x}(0)\\|$. The separation at a later time $t$ can be expressed as:\n$$\n\\|\\delta \\mathbf{x}(t)\\| \\approx \\delta_0 \\exp(\\lambda t)\n$$\nThis equation describes how an small initial error grows over time in a chaotic system.\n\nThe predictability horizon, $T$, is defined as the time at which the initial uncertainty, $\\delta_0$, grows to a specified tolerable macroscopic error threshold, $\\Delta$. To derive an expression for $T$, we set the separation at time $T$ equal to the threshold $\\Delta$:\n$$\n\\|\\delta \\mathbf{x}(T)\\| = \\Delta\n$$\nSubstituting this into our exponential growth model, we obtain:\n$$\n\\Delta = \\delta_0 \\exp(\\lambda T)\n$$\nOur goal is to solve this equation for $T$. We begin by isolating the exponential term by dividing both sides of the equation by $\\delta_0$ (which is non-zero):\n$$\n\\frac{\\Delta}{\\delta_0} = \\exp(\\lambda T)\n$$\nTo solve for the exponent $\\lambda T$, we take the natural logarithm ($\\ln$) of both sides. The natural logarithm is the inverse function of the exponential function, i.e., $\\ln(\\exp(x)) = x$.\n$$\n\\ln\\left(\\frac{\\Delta}{\\delta_0}\\right) = \\ln(\\exp(\\lambda T))\n$$\n$$\n\\ln\\left(\\frac{\\Delta}{\\delta_0}\\right) = \\lambda T\n$$\nFinally, by dividing by the largest Lyapunov exponent $\\lambda$ (which is stated to be positive), we arrive at the general expression for the predictability horizon time $T$:\n$$\nT = \\frac{1}{\\lambda} \\ln\\left(\\frac{\\Delta}{\\delta_0}\\right)\n$$\nThis derived formula provides the time it takes for an initial error to grow by a factor of $\\frac{\\Delta}{\\delta_0}$ in a system characterized by an LLE of $\\lambda$.\n\nNext, we must compute the numerical value of $T$ for the specific scenario provided:\n- Largest Lyapunov exponent: $\\lambda = 0.35 \\, \\text{min}^{-1}$\n- Initial uncertainty: $\\delta_0 = 2.5 \\times 10^{-6}$\n- Tolerable macroscopic error: $\\Delta = 5.0 \\times 10^{-3}$\n\nThe units for $\\delta_0$ and $\\Delta$ are identical, so their ratio will be a dimensionless quantity. First, we calculate this ratio:\n$$\n\\frac{\\Delta}{\\delta_0} = \\frac{5.0 \\times 10^{-3}}{2.5 \\times 10^{-6}} = \\frac{5.0}{2.5} \\times 10^{-3 - (-6)} = 2.0 \\times 10^{3} = 2000\n$$\nNow we substitute this ratio and the value of $\\lambda$ into our expression for $T$:\n$$\nT = \\frac{1}{0.35} \\ln(2000)\n$$\nThe unit of $\\lambda$ is $\\text{min}^{-1}$, so the unit of $T = 1/\\lambda$ will be minutes, which is consistent with the problem's requirement. We now evaluate the expression numerically:\n$$\n\\ln(2000) \\approx 7.60090246\n$$\n$$\nT \\approx \\frac{7.60090246}{0.35} \\, \\text{min} \\approx 21.71686417 \\, \\text{min}\n$$\nThe problem explicitly requests that the final answer be rounded to four significant figures. Applying this rounding rule, we get:\n$$\nT \\approx 21.72 \\, \\text{min}\n$$\nThis is the predictability horizon for the specified system.",
            "answer": "$$\n\\boxed{21.72}\n$$"
        },
        {
            "introduction": "Having explored how to quantify chaos, we now turn to the question of how complex systems transition between ordered and chaotic behavior. Random Boolean Networks (RBNs) serve as canonical models for understanding such phase transitions in systems like genetic networks or neural circuits. This practice  introduces Langton’s $\\lambda$ parameter, an elegant structural measure used to predict a system's dynamics. You will then move from this simple heuristic to a rigorous derivation of the criticality condition for the \"edge of chaos\" using the powerful annealed approximation, linking a rule's local structure to the network's global dynamical fate.",
            "id": "4135119",
            "problem": "Consider an ensemble of Random Boolean Networks (RBN), where each node receives exactly $K=3$ inputs and updates synchronously based on an identical local Boolean rule. Interpret the system as a Cellular Automaton (CA) with a quiescent state defined as $0$. Langton’s parameter $\\lambda$ is defined as the fraction of rule table outputs that are non-quiescent (i.e., not equal to the quiescent state). You will quantify $\\lambda$ for the given local rule and then use a first-principles annealed approximation to derive the edge-of-chaos criticality condition separating ordered from chaotic dynamics.\n\nThe local update rule is specified by its output for each of the $2^{3}$ input triplets (listed in lexicographic order). The mapping is:\n$000 \\mapsto 0$, $001 \\mapsto 1$, $010 \\mapsto 0$, $011 \\mapsto 1$, $100 \\mapsto 0$, $101 \\mapsto 1$, $110 \\mapsto 0$, $111 \\mapsto 0$.\n\nTasks:\n1. Compute Langton’s parameter $\\lambda$ for this rule as the fraction of non-quiescent outputs in the rule table.\n2. Starting from the definition of sensitivity to small perturbations and the annealed approximation (i.e., considering outputs for neighboring inputs as independent draws with fixed bias determined by $\\lambda$), derive the condition for marginal stability of infinitesimal perturbations, and solve it to obtain the critical value(s) $\\lambda_{c}$ for $K=3$.\n3. Let $\\Delta$ be the signed difference between the computed $\\lambda$ and the lower critical value $\\lambda_{c}^{(\\text{lower})}$. Provide $\\Delta$ as a single closed-form analytic expression. Do not approximate numerically; give the exact expression.\n\nYour final answer must be a single closed-form expression for $\\Delta$ without units. If any numerical approximation is performed, round the final result to four significant figures; however, an exact closed-form is preferred and acceptable.",
            "solution": "The problem is evaluated and found to be valid, well-posed, and scientifically grounded within the domain of complex systems theory. The solution proceeds in three parts as requested.\n\nFirst, we compute Langton’s parameter, $\\lambda$, for the specified local Boolean rule. The system has a connectivity of $K=3$, meaning the rule table has $2^K = 2^3 = 8$ entries. The quiescent state is defined as $0$. Langton's parameter $\\lambda$ is the fraction of outputs in the rule table that are non-quiescent, i.e., equal to $1$.\n\nThe given rule table is:\n$000 \\mapsto 0$\n$001 \\mapsto 1$\n$010 \\mapsto 0$\n$011 \\mapsto 1$\n$100 \\mapsto 0$\n$101 \\mapsto 1$\n$110 \\mapsto 0$\n$111 \\mapsto 0$\n\nBy counting the number of non-quiescent outputs ($1$), we find there are $3$ such instances. The total number of possible input configurations is $8$. Therefore, Langton's parameter for this specific rule is the ratio of non-quiescent outputs to the total number of outputs:\n$$\n\\lambda = \\frac{3}{8}\n$$\n\nSecond, we derive the critical value(s) of Langton's parameter, $\\lambda_c$, that mark the transition between ordered and chaotic dynamics for a network with connectivity $K=3$. This derivation is based on the annealed approximation, which analyzes the propagation of small perturbations through the network.\n\nLet $d(t)$ be the normalized Hamming distance between the states of two identical networks at time $t$, differing initially by an infinitesimal perturbation. $d(t)$ represents the fraction of nodes in different states. We seek to find the condition under which this perturbation is marginally stable, i.e., $d(t+1) \\approx d(t)$ for small $d(t)$.\n\nA node $i$ at time $t+1$ will be in a different state in the two networks if and only if the inputs it receives at time $t$ cause its Boolean function $f$ to produce different outputs. In the annealed approximation, we assume the inputs to a node are chosen randomly and independently. The probability that any given input to a node differs between the two networks is $d(t)$.\n\nFor a node with $K$ inputs, the number of differing inputs, $m$, follows a binomial distribution $B(K, d(t))$. The inputs to the node are identical in both networks ($m=0$) with probability $(1-d(t))^K$. In this case, the output will also be identical. The inputs differ ($m > 0$) with probability $1 - (1-d(t))^K$.\n\nThe crucial step in the annealed approximation is to assume that the Boolean rule $f$ is chosen randomly from an ensemble of rules with a fixed bias $\\lambda$. Under this assumption, the outputs for any two distinct input vectors are statistically independent. If the input vectors for the two networks, $I_A$ and $I_B$, are different, the probability that their outputs are different is:\n$$\nP(f(I_A) \\neq f(I_B)) = P(f(I_A)=1, f(I_B)=0) + P(f(I_A)=0, f(I_B)=1)\n$$\nBy definition of $\\lambda$, $P(f(\\cdot)=1) = \\lambda$ and $P(f(\\cdot)=0) = 1-\\lambda$. Due to independence, this becomes:\n$$\nP(f(I_A) \\neq f(I_B)) = \\lambda(1-\\lambda) + (1-\\lambda)\\lambda = 2\\lambda(1-\\lambda)\n$$\nThis quantity is the probability of a differing output, given that the inputs differ. The probability that a node's state will differ at time $t+1$ is the product of the probability that its inputs differ and the conditional probability that this leads to a different output:\n$$\nd(t+1) = P(\\text{inputs differ}) \\times P(\\text{output differs | inputs differ})\n$$\n$$\nd(t+1) = [1 - (1-d(t))^K] \\times [2\\lambda(1-\\lambda)]\n$$\nTo find the condition for marginal stability, we analyze the behavior for infinitesimal perturbations, where $d(t) \\to 0$. We linearize the expression for $d(t+1)$ around $d(t)=0$. Using the binomial expansion for small $d(t)$, $(1-d(t))^K \\approx 1 - K d(t)$.\nSubstituting this into the equation for $d(t+1)$:\n$$\nd(t+1) \\approx [1 - (1 - K d(t))] \\times [2\\lambda(1-\\lambda)] = K d(t) \\times 2\\lambda(1-\\lambda)\n$$\nThe perturbation is marginally stable when the amplification factor is unity, i.e., $\\frac{d(t+1)}{d(t)} = 1$. The criticality condition is therefore:\n$$\n2K \\lambda_c (1-\\lambda_c) = 1\n$$\nwhere $\\lambda_c$ denotes the critical value of $\\lambda$. This is a quadratic equation for $\\lambda_c$:\n$$\n2K\\lambda_c^2 - 2K\\lambda_c + 1 = 0\n$$\nUsing the quadratic formula, $\\lambda_c = \\frac{-b \\pm \\sqrt{b^2-4ac}}{2a}$, with $a=2K$, $b=-2K$, and $c=1$:\n$$\n\\lambda_c = \\frac{2K \\pm \\sqrt{(-2K)^2 - 4(2K)(1)}}{2(2K)} = \\frac{2K \\pm \\sqrt{4K^2 - 8K}}{4K} = \\frac{1}{2} \\pm \\frac{\\sqrt{K^2-2K}}{2K}\n$$\nFor the given connectivity $K=3$:\n$$\n\\lambda_c = \\frac{1}{2} \\pm \\frac{\\sqrt{3^2 - 2(3)}}{2(3)} = \\frac{1}{2} \\pm \\frac{\\sqrt{9 - 6}}{6} = \\frac{1}{2} \\pm \\frac{\\sqrt{3}}{6}\n$$\nThis yields two critical values, which define the boundaries of the chaotic regime. The lower critical value is:\n$$\n\\lambda_c^{(\\text{lower})} = \\frac{1}{2} - \\frac{\\sqrt{3}}{6}\n$$\n\nThird, we compute $\\Delta$, the signed difference between the calculated $\\lambda$ for the specific rule and the lower critical value $\\lambda_c^{(\\text{lower})}$.\n$$\n\\Delta = \\lambda - \\lambda_c^{(\\text{lower})} = \\frac{3}{8} - \\left(\\frac{1}{2} - \\frac{\\sqrt{3}}{6}\\right)\n$$\n$$\n\\Delta = \\frac{3}{8} - \\frac{1}{2} + \\frac{\\sqrt{3}}{6}\n$$\nTo combine the terms, we find a common denominator. For the rational part, the common denominator is $8$:\n$$\n\\Delta = \\frac{3}{8} - \\frac{4}{8} + \\frac{\\sqrt{3}}{6} = -\\frac{1}{8} + \\frac{\\sqrt{3}}{6}\n$$\nTo express this as a single fraction, we use the least common multiple of $8$ and $6$, which is $24$:\n$$\n\\Delta = -\\frac{3}{24} + \\frac{4\\sqrt{3}}{24} = \\frac{4\\sqrt{3} - 3}{24}\n$$\nThis is the required single closed-form analytic expression for $\\Delta$.",
            "answer": "$$\n\\boxed{\\frac{4\\sqrt{3} - 3}{24}}\n$$"
        },
        {
            "introduction": "Theory provides us with tools like Lyapunov exponents and criticality conditions, but how do we verify these dynamical regimes in practice? This final computational exercise  challenges you to empirically distinguish between ordered, critical (edge of chaos), and fully chaotic systems by analyzing their temporal \"memory.\" By implementing a program to measure the decay of correlations for canonical one-dimensional maps, you will generate data that reveals the distinct statistical fingerprints of each phase, bridging the gap between abstract mathematical theory and concrete data analysis in complex systems.",
            "id": "4135139",
            "problem": "You are tasked with designing and implementing a complete, runnable program that empirically evaluates the decay of correlations for discrete-time one-dimensional maps that are canonical in complex adaptive systems modeling. The scientific objective is to estimate the correlation function $$C(n) = \\mathbb{E}\\left[g(x_{k+n}) h(x_k)\\right] - \\mathbb{E}[g] \\,\\mathbb{E}[h],$$ interpret its decay as either exponential or algebraic, and draw conclusions about mixing properties associated with order, chaos, and the edge of chaos. The mathematical expectations are taken with respect to the invariant measure of the map, and the computational estimation must rely on time averages justified by the Glivenko–Cantelli principle and the Birkhoff Ergodic Theorem. Your program must implement the following requirements.\n\nFundamental base for the derivation:\n- Use the definition of the correlation function $C(n)$ for a stationary discrete-time process $\\{x_k\\}_{k \\ge 0}$ driven by a deterministic map $T$, where $x_{k+1} = T(x_k)$ and $\\mathbb{E}[\\cdot]$ denotes expectation with respect to an invariant ergodic measure $\\mu$ of $T$.\n- Use the Birkhoff Ergodic Theorem, which states that for $\\mu$-integrable $f$, $$\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} f(x_k) = \\int f \\, d\\mu,$$ for $\\mu$-almost every initial condition. This justifies replacing ensemble expectations by time averages for long trajectories.\n\nDefinitions:\n- A map $T$ is mixing if for integrable observables $g$ and $h$ with zero mean, $$\\lim_{n \\to \\infty} C(n) = 0;$$ strong mixing often implies an exponential rate, while intermittency near a neutral fixed point can lead to algebraic rates.\n- Exponential decay corresponds to the empirical fit $$|C(n)| \\approx A \\exp(-\\lambda n)$$ with $A > 0$ and $\\lambda > 0$, while algebraic decay corresponds to $$|C(n)| \\approx B n^{-\\beta}$$ with $B > 0$ and $\\beta > 0$.\n\nYour program must:\n1. Generate a single long trajectory $\\{x_k\\}$ for each specified map $T$ with a prescribed initial condition strategy and burn-in length where needed, then compute empirical means and correlations using time averages over a trajectory segment of length $N$.\n2. Use the observables $g(x) = x$ and $h(x) = \\cos(2\\pi x)$ for all test cases.\n3. For each map, compute $$\\widehat{C}(n) = \\frac{1}{N-n} \\sum_{k=0}^{N-n-1} g(x_{k+n}) \\, h(x_k) - \\left(\\frac{1}{N} \\sum_{k=0}^{N-1} g(x_k)\\right) \\left(\\frac{1}{N} \\sum_{k=0}^{N-1} h(x_k)\\right),$$ for lags $n = 1, 2, \\dots, n_{\\max}$.\n4. Fit $\\log(|\\widehat{C}(n)|)$ versus $n$ to detect exponential decay, and fit $\\log(|\\widehat{C}(n)|)$ versus $\\log(n)$ to detect algebraic decay. Use linear regression in both cases and the coefficient of determination $R^2$ to assess which model better explains the decay. Reject points where $|\\widehat{C}(n)|$ is numerically indistinguishable from zero to avoid instability of the logarithm.\n5. Classify the decay type based on the regression fits and slope signs, returning:\n   - $2$ if exponential decay is strongly supported,\n   - $1$ if algebraic decay is strongly supported,\n   - $0$ if neither fit is adequate (no mixing or undetermined).\n\nMaps and parameterizations:\n- Map A (chaotic, expanding): the logistic map $T(x) = r x (1-x)$ with $r = 4$. To sample from the invariant measure without burn-in, use the conjugacy $x = \\sin^2(\\pi \\theta)$ with $\\theta$ uniformly distributed in $[0,1)$ at the initial step, then iterate $T$ thereafter to generate the trajectory. Use $N = 200000$ and $n_{\\max} = 50$.\n- Map B (intermittent, edge of chaos): the Pomeau–Manneville map $T(x) = x + x^{1+\\alpha} \\bmod 1$ with $\\alpha = 0.5$. Use a uniform initial condition $x_0 \\in [0,1)$, apply a burn-in of $B = 5000$, then accumulate $N = 200000$ iterates to evaluate correlations with $n_{\\max} = 50$.\n- Map C (ordered, non-mixing): the circle rotation $T(x) = x + \\varphi \\bmod 1$ with $\\varphi = (\\sqrt{5}-1)/2$. Use a uniform initial condition $x_0 \\in [0,1)$, apply a burn-in of $B = 5000$, then accumulate $N = 200000$ iterates to evaluate correlations with $n_{\\max} = 50$.\n\nAngle units and physical units:\n- No physical units are involved.\n- All angles for the cosine function use radians, i.e., $h(x) = \\cos(2\\pi x)$ with $2\\pi$ in radians.\n\nTest suite:\n- Test Case $1$: Map A with $r = 4$, $N = 200000$, $n_{\\max} = 50$.\n- Test Case $2$: Map B with $\\alpha = 0.5$, $B = 5000$, $N = 200000$, $n_{\\max} = 50$.\n- Test Case $3$: Map C with $\\varphi = (\\sqrt{5}-1)/2$, $B = 5000$, $N = 200000$, $n_{\\max} = 50$.\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $$[2,1,0],$$ where each entry corresponds to the classification code for the respective test case in the order specified above. The entries must be integers, with $2$ indicating exponential decay, $1$ indicating algebraic decay, and $0$ indicating neither.",
            "solution": "The problem posed is a well-defined computational exercise in the field of dynamical systems and complex adaptive systems modeling. It is scientifically grounded, internally consistent, and requires the application of established theoretical principles and numerical methods. The objective is to empirically investigate the mixing properties of three canonical one-dimensional maps, each representing a distinct class of dynamical behavior: chaotic (Logistic map), intermittent at the edge of chaos (Pomeau-Manneville map), and ordered/quasiperiodic (Circle rotation). The validation confirms that all necessary data, definitions, and procedures are provided, allowing for a unique and verifiable solution. We may therefore proceed with the derivation and implementation.\n\nOur task is to classify the long-term behavior of these systems by analyzing the decay of the correlation function, $C(n)$. For a stationary discrete-time process generated by a map $T$ such that $x_{k+1} = T(x_k)$, and for two observables $g(x)$ and $h(x)$, the correlation function is defined as:\n$$\nC(n) = \\mathbb{E}\\left[g(x_{k+n}) h(x_k)\\right] - \\mathbb{E}[g] \\, \\mathbb{E}[h]\n$$\nHere, $\\mathbb{E}[\\cdot]$ denotes the expectation with respect to the map's invariant measure, $\\mu$. A system is considered mixing if $C(n) \\to 0$ as the time lag $n \\to \\infty$. The rate of this decay is a critical indicator of the system's dynamics.\n\nThe Birkhoff Ergodic Theorem provides the theoretical justification for our computational approach. It states that for an ergodic system, the time average of an observable along a typical trajectory converges to the ensemble average (the expectation with respect to the invariant measure):\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} f(x_k) = \\int f(x) \\, d\\mu(x) = \\mathbb{E}[f]\n$$\nThis allows us to estimate the expectations in $C(n)$ using averages over a single long trajectory of length $N$. The estimator for the correlation function, $\\widehat{C}(n)$, is given by:\n$$\n\\widehat{C}(n) = \\frac{1}{N-n} \\sum_{k=0}^{N-n-1} g(x_{k+n}) \\, h(x_k) - \\left(\\frac{1}{N} \\sum_{k=0}^{N-1} g(x_k)\\right) \\left(\\frac{1}{N} \\sum_{k=0}^{N-1} h(x_k)\\right)\n$$\nWe compute this for lags $n = 1, 2, \\dots, n_{\\max}$. The specific observables are $g(x) = x$ and $h(x) = \\cos(2\\pi x)$.\n\nThe classification of the decay is based on fitting the computed $|\\widehat{C}(n)|$ to two models:\n1.  **Exponential Decay**: Characteristic of strongly chaotic, mixing systems. The model is $|\\widehat{C}(n)| \\approx A \\exp(-\\lambda n)$ for constants $A, \\lambda > 0$. Taking the natural logarithm linearizes this relationship: $\\log(|\\widehat{C}(n)|) \\approx \\log(A) - \\lambda n$. We perform a linear regression of $\\log(|\\widehat{C}(n)|)$ against $n$. A good fit with a negative slope ($-\\lambda$) indicates exponential decay.\n2.  **Algebraic (Power-Law) Decay**: Often observed in systems with intermittency, poised at the \"edge of chaos\". The model is $|\\widehat{C}(n)| \\approx B n^{-\\beta}$ for constants $B, \\beta > 0$. This is linearized by taking the logarithm on both sides: $\\log(|\\widehat{C}(n)|) \\approx \\log(B) - \\beta \\log(n)$. We perform a linear regression of $\\log(|\\widehat{C}(n)|)$ against $\\log(n)$. A good fit with a negative slope ($-\\beta$) suggests algebraic decay.\n\nThe decision on the decay type is made by comparing the coefficient of determination, $R^2$, from both linear regressions. A higher $R^2$ value (closer to $1$) signifies a better fit. A threshold, such as $R^2 > 0.9$, is used to ensure the fit is statistically significant. The sign of the slope must be negative, corresponding to decay. If neither model provides a strong fit, or if correlations do not decay, the system is classified as non-mixing or undetermined.\n\nThe computational procedure for each test case is as follows:\n\n**Step 1: Trajectory Generation**\nFor each map, generate a trajectory $\\{x_k\\}_{k=0}^{N-1}$ of length $N=200000$, after applying a burn-in period $B$ where specified. The interval is $[0,1)$.\n-   **Map A (Logistic)**: $T(x) = 4x(1-x)$. An initial condition $x_0$ is drawn from the invariant arcsine distribution using the conjugacy $x_0 = \\sin^2(\\pi \\theta)$ with $\\theta \\sim U[0,1)$. No burn-in is needed. This map is expected to be strongly mixing.\n-   **Map B (Pomeau-Manneville)**: $T(x) = x + x^{1+\\alpha} \\pmod 1$ with $\\alpha = 0.5$. A random initial condition $x_0 \\sim U[0,1)$ is used, followed by a burn-in of $B=5000$ iterations to let the trajectory settle near the attractor. This map exhibits intermittency and is expected to show algebraic decay.\n-   **Map C (Circle Rotation)**: $T(x) = x + \\varphi \\pmod 1$ with $\\varphi = (\\sqrt{5}-1)/2$. A random initial condition $x_0 \\sim U[0,1)$ is used, followed by a burn-in of $B=5000$. This irrational rotation is ergodic but not mixing; correlations are not expected to decay to zero.\n\n**Step 2: Correlation Calculation**\nFor each trajectory, compute the time series for the observables $g(x_k)=x_k$ and $h(x_k) = \\cos(2\\pi x_k)$. Calculate their means over the full length $N$. Then, for each lag $n$ from $1$ to $n_{\\max}=50$, compute $\\widehat{C}(n)$ using the provided formula.\n\n**Step 3: Fitting and Classification**\nFor the set of computed correlations $\\{\\widehat{C}(n)\\}_{n=1}^{n_{\\max}}$:\n-   Filter out any points where $|\\widehat{C}(n)|$ is numerically indistinguishable from zero to prevent errors in the logarithm.\n-   Perform a linear regression of $\\log(|\\widehat{C}(n)|)$ versus $n$ to get the slope $s_{exp}$ and coefficient of determination $R^2_{exp}$.\n-   Perform a linear regression of $\\log(|\\widehat{C}(n)|)$ versus $\\log(n)$ to get the slope $s_{alg}$ and coefficient of determination $R^2_{alg}$.\n-   Apply the classification logic:\n    -   If $R^2_{exp} > 0.9$ and $s_{exp} < 0$, and additionally $R^2_{exp} > R^2_{alg}$, classify as exponential decay (code $2$).\n    -   If $R^2_{alg} > 0.9$ and $s_{alg} < 0$, and additionally $R^2_{alg} > R^2_{exp}$, classify as algebraic decay (code $1$).\n    -   In all other cases (poor fits, non-decaying correlations evidenced by $s \\ge 0$, or ambiguity), classify as undetermined (code $0$).\n\nThis structured, principle-based approach ensures a robust and reproducible analysis of the dynamical properties of the given maps, providing a clear empirical distinction between order, chaos, and the edge of chaos.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        {\n            \"map_type\": \"A\",\n            \"params\": {\"r\": 4.0},\n            \"N\": 200000,\n            \"B\": 0,\n            \"n_max\": 50,\n        },\n        {\n            \"map_type\": \"B\",\n            \"params\": {\"alpha\": 0.5},\n            \"N\": 200000,\n            \"B\": 5000,\n            \"n_max\": 50,\n        },\n        {\n            \"map_type\": \"C\",\n            \"params\": {\"phi\": (np.sqrt(5) - 1) / 2},\n            \"N\": 200000,\n            \"B\": 5000,\n            \"n_max\": 50,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        classification = analyze_map(\n            case[\"map_type\"],\n            case[\"params\"],\n            case[\"N\"],\n            case[\"B\"],\n            case[\"n_max\"],\n        )\n        results.append(classification)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef generate_trajectory(map_type, params, N, B):\n    \"\"\"\n    Generates a time series for a given map.\n    \n    Args:\n        map_type (str): 'A', 'B', or 'C'.\n        params (dict): Dictionary of map parameters.\n        N (int): Length of the trajectory for analysis.\n        B (int): Length of the burn-in period.\n        \n    Returns:\n        np.ndarray: The generated trajectory of length N.\n    \"\"\"\n    x = np.zeros(B + N)\n    \n    # Initial condition\n    if map_type == 'A':\n        # For logistic map r=4, use conjugacy to start on the attractor\n        theta0 = np.random.uniform(0.0, 1.0)\n        x[0] = np.sin(np.pi * theta0)**2\n    else:\n        # Uniform initial condition for other maps\n        x[0] = np.random.uniform(0.0, 1.0)\n\n    # Map definitions\n    if map_type == 'A':\n        r = params['r']\n        def T(val): return r * val * (1.0 - val)\n    elif map_type == 'B':\n        alpha = params['alpha']\n        def T(val): return (val + val**(1.0 + alpha)) % 1.0\n    elif map_type == 'C':\n        phi = params['phi']\n        def T(val): return (val + phi) % 1.0\n    else:\n        raise ValueError(\"Unknown map type\")\n\n    # Iterate map\n    for i in range(B + N - 1):\n        x[i+1] = T(x[i])\n        \n    return x[B:]\n\ndef analyze_map(map_type, params, N, B, n_max):\n    \"\"\"\n    Performs the full correlation analysis for a single map.\n    \n    Args:\n        map_type (str): The map identifier.\n        params (dict): Map-specific parameters.\n        N (int): Trajectory length.\n        B (int): Burn-in length.\n        n_max (int): Maximum lag for correlation.\n\n    Returns:\n        int: Classification code (2 for exponential, 1 for algebraic, 0 for other).\n    \"\"\"\n    \n    # Step 1: Generate trajectory\n    x_series = generate_trajectory(map_type, params, N, B)\n    \n    # Step 2: Compute observables and their means\n    g_series = x_series\n    h_series = np.cos(2.0 * np.pi * x_series)\n    \n    mean_g = np.mean(g_series)\n    mean_h = np.mean(h_series)\n    \n    # Step 3: Compute empirical correlation function C(n)\n    lags = np.arange(1, n_max + 1)\n    correlations = np.zeros_like(lags, dtype=float)\n    \n    for i, n in enumerate(lags):\n        # Estimator for E[g(x_{k+n})h(x_k)]\n        cross_term_est = np.mean(g_series[n:] * h_series[:-n])\n        correlations[i] = cross_term_est - mean_g * mean_h\n\n    # Step 4: Fit decay models\n    abs_corr = np.abs(correlations)\n    \n    # Filter out numerically zero correlations to avoid log(0)\n    valid_indices = abs_corr > np.finfo(float).eps * 10\n    if np.sum(valid_indices) < 2: # Need at least 2 points for regression\n        return 0\n\n    lags_fit = lags[valid_indices]\n    abs_corr_fit = abs_corr[valid_indices]\n    log_abs_corr_fit = np.log(abs_corr_fit)\n\n    # --- Exponential fit: log|C(n)| vs n ---\n    try:\n        slope_exp, _, r_exp, _, _ = stats.linregress(lags_fit, log_abs_corr_fit)\n        r2_exp = r_exp**2\n    except ValueError:\n        slope_exp, r2_exp = 0.0, 0.0\n\n    # --- Algebraic fit: log|C(n)| vs log(n) ---\n    try:\n        slope_alg, _, r_alg, _, _ = stats.linregress(np.log(lags_fit), log_abs_corr_fit)\n        r2_alg = r_alg**2\n    except ValueError:\n        slope_alg, r2_alg = 0.0, 0.0\n    \n    # Step 5: Classify based on fits\n    R2_THRESHOLD = 0.90\n    \n    is_exp_good = r2_exp > R2_THRESHOLD and slope_exp < 0\n    is_alg_good = r2_alg > R2_THRESHOLD and slope_alg < 0\n\n    if is_exp_good and is_alg_good:\n        if r2_exp > r2_alg:\n            return 2  # Exponential\n        else:\n            return 1  # Algebraic\n    elif is_exp_good:\n        return 2  # Exponential\n    elif is_alg_good:\n        return 1  # Algebraic\n    else:\n        return 0  # Undetermined / No decay\n\nsolve()\n```"
        }
    ]
}