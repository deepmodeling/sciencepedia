{
    "hands_on_practices": [
        {
            "introduction": "Linearization is an indispensable tool for analyzing complex systems, but its validity is fundamentally limited by nonlinearity. This first practice provides the theoretical bedrock for our exploration, asking you to rigorously quantify the error inherent in a linear approximation. By deriving the error bound from first principles , you will develop a deep appreciation for the conditions under which linearization is justified and how the strength of nonlinearity, measured by curvature, determines the domain of its accuracy.",
            "id": "4134441",
            "problem": "Consider a Complex Adaptive System (CAS) in which a macroscopic response function $f:\\mathbb{R}\\to\\mathbb{R}$ maps a scalar control variable $x$ to an observable system-level output. Nonlinearity in this response arises from heterogeneous agent interactions and feedbacks and is captured locally by the curvature $f''$. Let $x_0\\in\\mathbb{R}$ be a chosen operating point and define the first-order Taylor linearization at $x_0$ by $L(x)=f(x_0)+f'(x_0)(x-x_0)$.\n\nAssume $f$ is twice continuously differentiable on an interval $I=[x_0-\\rho,x_0+\\rho]$ with $\\rho0$, and suppose there exists a finite constant $M$ such that $|f''(\\xi)|\\leq M$ for all $\\xi\\in I$. Starting only from the Fundamental Theorem of Calculus and the Mean Value Theorem (and basic properties of integrals and absolute values), derive a bound on the local linearization error $R_1(x)=f(x)-L(x)$ in terms of $M$ and $|x-x_0|$ for any $x\\in I$.\n\nDefine accuracy relative to a tolerance $\\varepsilon0$ as follows: the linearization $L$ is said to be accurate on radius $\\delta$ around $x_0$ if $|f(x)-L(x)|\\leq \\varepsilon$ for all $x$ with $|x-x_0|\\leq \\delta$ and $x\\in I$. Derive the largest such radius $\\delta^\\star$ as a closed-form analytic expression in terms of $\\varepsilon$ and $M$. Your final answer must be a single closed-form expression for $\\delta^\\star$.",
            "solution": "The problem statement is a well-posed and mathematically sound exercise in elementary real analysis, specifically the derivation of the error bound for a first-order Taylor expansion and its application. All provided information is self-contained, consistent, and scientifically grounded. The problem is therefore deemed valid.\n\nThe objective is to derive a bound on the local linearization error $R_1(x) = f(x) - L(x)$ and then find the largest radius $\\delta^\\star$ around $x_0$ for which the linearization is accurate to within a tolerance $\\varepsilon  0$. The derivation must proceed from the Fundamental Theorem of Calculus (FTC) and the Mean Value Theorem (MVT).\n\nLet the linearization error be defined as $R_1(x) = f(x) - L(x)$, where $L(x) = f(x_0) + f'(x_0)(x-x_0)$.\n$$R_1(x) = f(x) - f(x_0) - f'(x_0)(x-x_0)$$\nBy the Fundamental Theorem of Calculus, we can express the difference $f(x) - f(x_0)$ as an integral of its derivative:\n$$f(x) - f(x_0) = \\int_{x_0}^{x} f'(t) dt$$\nSubstituting this into the expression for $R_1(x)$ yields:\n$$R_1(x) = \\int_{x_0}^{x} f'(t) dt - f'(x_0)(x-x_0)$$\nThe second term can also be written as an integral: $f'(x_0)(x-x_0) = f'(x_0) \\int_{x_0}^{x} 1 \\, dt = \\int_{x_0}^{x} f'(x_0) dt$.\nCombining the two terms, we obtain the error term in integral form:\n$$R_1(x) = \\int_{x_0}^{x} (f'(t) - f'(x_0)) dt$$\nNow, we analyze the integrand, $g(t) = f'(t) - f'(x_0)$. Since $f$ is twice continuously differentiable on the interval $I$, the function $f'$ is continuously differentiable on $I$. We can apply the Mean Value Theorem to $f'$ on the interval with endpoints $x_0$ and $t$. For any $t \\in I$, there exists a number $\\xi$ strictly between $x_0$ and $t$ such that:\n$$\\frac{f'(t) - f'(x_0)}{t-x_0} = f''(\\xi)$$\nThis gives an expression for the integrand: $f'(t) - f'(x_0) = f''(\\xi)(t-x_0)$.\n\nWe can now bound the error $R_1(x)$. Taking the absolute value of the integral expression for $R_1(x)$:\n$$|R_1(x)| = \\left| \\int_{x_0}^{x} (f'(t) - f'(x_0)) dt \\right|$$\nUsing the MVT result:\n$$|R_1(x)| = \\left| \\int_{x_0}^{x} f''(\\xi_t)(t-x_0) dt \\right|$$\nwhere for each $t$, $\\xi_t$ is some value between $x_0$ and $t$.\nUsing the triangle inequality for integrals, which states that $|\\int_a^b g(u) du| \\leq |\\int_a^b |g(u)| du|$, we get:\n$$|R_1(x)| \\leq \\left| \\int_{x_0}^{x} |f''(\\xi_t)(t-x_0)| dt \\right| = \\left| \\int_{x_0}^{x} |f''(\\xi_t)| |t-x_0| dt \\right|$$\nThe problem states that for all $\\zeta \\in I$, $|f''(\\zeta)| \\leq M$. Since $x \\in I$ and $t$ is between $x_0$ and $x$, the value $\\xi_t$ (which lies between $x_0$ and $t$) must also be in $I$. Thus, $|f''(\\xi_t)| \\leq M$.\n$$|R_1(x)| \\leq \\left| \\int_{x_0}^{x} M |t-x_0| dt \\right|$$\nWe evaluate this integral.\nCase 1: $x \\ge x_0$. In this case, the integration interval is $[x_0, x]$, and for $t \\in [x_0, x]$, $|t-x_0| = t-x_0$.\n$$|R_1(x)| \\leq \\int_{x_0}^{x} M (t-x_0) dt = M \\left[ \\frac{(t-x_0)^2}{2} \\right]_{x_0}^{x} = M \\frac{(x-x_0)^2}{2}$$\nCase 2: $x  x_0$. The integration interval is $[x, x_0]$, and for $t \\in [x, x_0]$, $|t-x_0| = -(t-x_0) = x_0-t$. The integral is:\n$$|R_1(x)| \\leq \\left| \\int_{x_0}^{x} M (x_0-t) dt \\right| = \\left| - \\int_{x}^{x_0} M(x_0-t) dt \\right| = \\int_{x}^{x_0} M(x_0-t) dt$$\n$$|R_1(x)| \\leq M \\left[ -\\frac{(x_0-t)^2}{2} \\right]_{x}^{x_0} = M \\left( 0 - \\left( -\\frac{(x_0-x)^2}{2} \\right) \\right) = M \\frac{(x-x_0)^2}{2}$$\nIn both cases, we obtain the same bound on the linearization error:\n$$|f(x) - L(x)| \\leq \\frac{M}{2}(x-x_0)^2$$\n\nNext, we seek the largest radius $\\delta^\\star$ such that for all $x$ with $|x-x_0| \\leq \\delta^\\star$, the accuracy condition $|f(x) - L(x)| \\leq \\varepsilon$ is satisfied.\nUsing our derived bound, a sufficient condition for the accuracy requirement to hold is:\n$$\\frac{M}{2}(x-x_0)^2 \\leq \\varepsilon$$\nWe must consider two scenarios for the constant $M \\geq 0$.\nIf $M=0$, then $f''(\\xi)=0$ for all $\\xi \\in I$, which implies that $f$ is a linear function on the interval $I$. In this case, the linearization $L(x)$ is identical to $f(x)$, so the error is $R_1(x) = 0$. The condition $0 \\leq \\varepsilon$ is always true since $\\varepsilon0$. The linearization is perfectly accurate for all $x \\in I$. The largest radius of accuracy is thus $\\delta^\\star = \\rho$, the radius of the interval $I$.\nIf $M0$, we can rearrange the inequality:\n$$(x-x_0)^2 \\leq \\frac{2\\varepsilon}{M}$$\n$$|x-x_0| \\leq \\sqrt{\\frac{2\\varepsilon}{M}}$$\nThis inequality defines a range of $x$ values around $x_0$ for which the linearization is guaranteed to be accurate. We want to find the largest radius $\\delta$ such that the accuracy condition $|f(x)-L(x)| \\le \\varepsilon$ holds for all $x$ satisfying $|x-x_0| \\le \\delta$.\nFrom our error bound, the error $|f(x)-L(x)|$ is at most $\\frac{M}{2}(x-x_0)^2$. For all $x$ in the interval $[x_0-\\delta, x_0+\\delta]$, the maximum value of this bound occurs at the endpoints, where $|x-x_0|=\\delta$. This maximum value is $\\frac{M}{2}\\delta^2$. To guarantee accuracy for all $x$ in this range, we require this maximum possible error to be no more than $\\varepsilon$:\n$$\\frac{M}{2}\\delta^2 \\leq \\varepsilon \\implies \\delta \\leq \\sqrt{\\frac{2\\varepsilon}{M}}$$\nThe largest such $\\delta$ is therefore $\\sqrt{\\frac{2\\varepsilon}{M}}$.\n\nHowever, our entire derivation relies on the assumption that $x \\in I = [x_0-\\rho, x_0+\\rho]$, which means $|x-x_0| \\leq \\rho$. For the accuracy condition to be established over a radius $\\delta$, we must have $\\delta \\leq \\rho$. Thus, the most complete answer is $\\delta^\\star = \\min\\left(\\rho, \\sqrt{\\frac{2\\varepsilon}{M}}\\right)$.\n\nThe problem, however, explicitly asks for an expression for $\\delta^\\star$ solely in terms of $\\varepsilon$ and $M$. This is a directive to provide the radius of accuracy as determined by the intrinsic properties of the function (its nonlinearity, captured by $M$) and the desired tolerance ($\\varepsilon$), under the implicit assumption that the domain of validity (defined by $\\rho$) is large enough not to be the limiting factor. This is a standard perspective in local analysis. We therefore report the radius of accuracy that arises from the error bound itself.\n\n$$ \\delta^\\star = \\sqrt{\\frac{2\\varepsilon}{M}} $$\nThis expression captures the core consequence of nonlinearity: the radius of accurate linearization shrinks with increasing curvature $M$ and grows with increasing error tolerance $\\varepsilon$.",
            "answer": "$$\\boxed{\\sqrt{\\frac{2\\varepsilon}{M}}}$$"
        },
        {
            "introduction": "Having established the local nature of linear approximations, we now investigate what happens at the boundary of their validity. This exercise guides you through the analysis of the pitchfork bifurcation, a canonical example where nonlinearity orchestrates the birth of new, stable solutions from a trivial state. Working through the stability analysis of the system's equilibria  provides a core skill set for understanding how complex systems undergo fundamental, qualitative changes in behavior as parameters are varied.",
            "id": "4134416",
            "problem": "Consider a symmetric complex adaptive system near a collective-symmetry breaking transition, where the slow order parameter $x$ (e.g., a signed consensus level) evolves on a one-dimensional center manifold. Assume the reduced dynamics have been derived from first principles (symmetry and smoothness) via standard center manifold and equivariant bifurcation arguments, leading to the normal-form Ordinary Differential Equation (ODE)\n$$\n\\dot{x} \\;=\\; \\mu\\,x \\;-\\; \\gamma\\,x^{3},\n$$\nwith small control parameter $|\\mu|\\ll 1$ and nonzero nonlinear coefficient $\\gamma\\neq 0$. Your tasks are:\n\n1. Starting from the definition of equilibrium for a continuous-time dynamical system ($\\dot{x}=0$), determine all equilibria as functions of $\\mu$ and $\\gamma$ and specify the parameter conditions under which the nontrivial equilibria exist.\n\n2. Using linearization (the Jacobian of the vector field at the equilibrium in one dimension), analyze the local stability of each equilibrium branch. Explicitly compute the linearization eigenvalue at an equilibrium $x^{\\ast}$ and deduce its sign in terms of $\\mu$ and $\\gamma$.\n\n3. Based on the existence and stability of the equilibrium branches, determine the parameter conditions distinguishing a supercritical pitchfork bifurcation from a subcritical pitchfork bifurcation in the given normal form, providing a clear, logically justified classification tied to the signs of $\\mu$ and $\\gamma$.\n\n4. Report, as your final answer, the exact simplified expression for the linearization eigenvalue along the nontrivial equilibrium branches $x^{\\ast}(\\mu,\\gamma)$, expressed purely in terms of $\\mu$ and $\\gamma$. No numerical approximation is needed, and no units are required.\n\nDo not use any shortcut formulas for classification; derive your conclusions from the fundamental definitions of equilibrium and linearization stability, together with the stated ODE. The final answer must be a single closed-form analytic expression.",
            "solution": "The problem requires a complete analysis of the dynamical system described by the ordinary differential equation (ODE) $\\dot{x} = \\mu x - \\gamma x^3$, which is the normal form for a pitchfork bifurcation. The analysis will proceed in three steps as requested: finding the equilibria, determining their stability, and classifying the bifurcation.\n\n**1. Determination of Equilibria**\nEquilibrium points, denoted by $x^{\\ast}$, are solutions to the equation $\\dot{x} = 0$. For the given system, we must solve:\n$$\n\\mu x^{\\ast} - \\gamma (x^{\\ast})^3 = 0\n$$\nThis equation can be factored as:\n$$\nx^{\\ast} (\\mu - \\gamma (x^{\\ast})^2) = 0\n$$\nFrom this factored form, we identify two sets of solutions.\n\nThe first solution is the **trivial equilibrium**:\n$$\nx^{\\ast}_{0} = 0\n$$\nThis equilibrium point exists for all values of the parameters $\\mu$ and $\\gamma$.\n\nThe second set of solutions, the **nontrivial equilibria**, are found by setting the second factor to zero:\n$$\n\\mu - \\gamma (x^{\\ast})^2 = 0\n$$\nSolving for $x^{\\ast}$ yields:\n$$\n(x^{\\ast})^2 = \\frac{\\mu}{\\gamma}\n$$\nThis gives two nontrivial solutions, provided the right-hand side is non-negative:\n$$\nx^{\\ast}_{\\pm} = \\pm\\sqrt{\\frac{\\mu}{\\gamma}}\n$$\nFor these solutions to be real-valued, the condition $\\frac{\\mu}{\\gamma} \\ge 0$ must be met. Since the problem states $\\gamma \\neq 0$, and the bifurcation point is at $\\mu = 0$, the nontrivial equilibria exist as distinct real roots when $\\frac{\\mu}{\\gamma}  0$. This means that $\\mu$ and $\\gamma$ must have the same sign.\n\n**2. Local Stability Analysis**\nThe local stability of an equilibrium $x^{\\ast}$ is determined by the eigenvalue of the Jacobian of the vector field $f(x) = \\mu x - \\gamma x^3$ evaluated at $x^{\\ast}$. For a one-dimensional system, this is simply the derivative $\\lambda = f'(x^{\\ast})$. A negative eigenvalue ($\\lambda  0$) implies local stability, while a positive eigenvalue ($\\lambda  0$) implies instability.\n\nFirst, we compute the derivative of $f(x)$:\n$$\nf'(x) = \\frac{d}{dx}(\\mu x - \\gamma x^3) = \\mu - 3\\gamma x^2\n$$\nNow we evaluate this expression at each equilibrium.\n\n- **Stability of the trivial equilibrium ($x^{\\ast}_{0} = 0$)**:\nThe eigenvalue $\\lambda_0$ at the trivial equilibrium is:\n$$\n\\lambda_0 = f'(0) = \\mu - 3\\gamma (0)^2 = \\mu\n$$\nThe stability of the trivial branch is thus governed by the sign of $\\mu$: it is stable for $\\mu  0$ and unstable for $\\mu  0$. At $\\mu=0$, the eigenvalue is zero, confirming it as the bifurcation point.\n\n- **Stability of the nontrivial equilibria ($x^{\\ast}_{\\pm} = \\pm\\sqrt{\\mu/\\gamma}$)**:\nThese branches exist for $\\mu/\\gamma  0$. We substitute $(x^{\\ast}_{\\pm})^2 = \\frac{\\mu}{\\gamma}$ into the expression for the eigenvalue:\n$$\n\\lambda_{\\pm} = f'(x^{\\ast}_{\\pm}) = \\mu - 3\\gamma (x^{\\ast}_{\\pm})^2 = \\mu - 3\\gamma \\left(\\frac{\\mu}{\\gamma}\\right)\n$$\nSince $\\gamma \\neq 0$, the expression simplifies to:\n$$\n\\lambda_{\\pm} = \\mu - 3\\mu = -2\\mu\n$$\nThe stability of these nontrivial branches depends on the sign of $\\mu$. Because they exist only when $\\mu$ and $\\gamma$ have the same sign, we can deduce their stability.\nIf $\\mu  0$ (which implies $\\gamma  0$), then $\\lambda_{\\pm} = -2\\mu  0$, making the nontrivial branches stable.\nIf $\\mu  0$ (which implies $\\gamma  0$), then $\\lambda_{\\pm} = -2\\mu  0$, making the nontrivial branches unstable.\n\n**3. Bifurcation Classification**\nThe classification depends on the sign of the nonlinear coefficient $\\gamma$.\n\n- **Supercritical Pitchfork Bifurcation ($\\gamma  0$)**:\nFor $\\mu  0$, the only real equilibrium is $x^{\\ast}_{0} = 0$, which is stable ($\\lambda_0 = \\mu  0$). As $\\mu$ increases through $0$, the trivial equilibrium becomes unstable ($\\lambda_0 = \\mu  0$). Simultaneously, for $\\mu  0$, the two nontrivial equilibria $x^{\\ast}_{\\pm} = \\pm\\sqrt{\\mu/\\gamma}$ emerge. As established above, when $\\mu  0$ and $\\gamma  0$, these new branches are stable ($\\lambda_{\\pm} = -2\\mu  0$). This scenario, where a stable equilibrium loses stability and gives rise to two new stable equilibria, defines a **supercritical** pitchfork bifurcation. The condition for this is $\\gamma  0$.\n\n- **Subcritical Pitchfork Bifurcation ($\\gamma  0$)**:\nFor this case, we consider $\\mu$ increasing from negative values. For $\\mu  0$ (which implies $\\gamma  0$ for existence of nontrivial roots), there are three equilibria: the stable trivial equilibrium $x^{\\ast}_{0} = 0$ ($\\lambda_0 = \\mu  0$) and the two unstable nontrivial equilibria $x^{\\ast}_{\\pm} = \\pm\\sqrt{\\mu/\\gamma}$ ($\\lambda_{\\pm} = -2\\mu  0$). As $\\mu$ approaches $0$ from below, the two unstable branches move toward the origin and merge with the stable trivial branch. For $\\mu  0$, the nontrivial solutions are no longer real, and the trivial solution becomes unstable ($\\lambda_0 = \\mu  0$). This scenario, where two unstable branches merge with a stable branch, leading to a single unstable branch, defines a **subcritical** pitchfork bifurcation. The condition for this is $\\gamma  0$.\n\n**4. Final Answer Derivation**\nThe question asks for the simplified expression for the linearization eigenvalue along the nontrivial equilibrium branches, $x^{\\ast}_{\\pm}(\\mu,\\gamma)$, expressed in terms of $\\mu$ and $\\gamma$. As derived in the stability analysis (Part 2), this eigenvalue is:\n$$\n\\lambda_{\\pm} = -2\\mu\n$$\nThis is the final analytical expression required.",
            "answer": "$$\\boxed{-2\\mu}$$"
        },
        {
            "introduction": "Our final practice bridges the gap from idealized deterministic models to the noisy reality of observational data. It explores \"critical slowing down,\" a key phenomenon revealing the profound interplay between nonlinearity and stochastic fluctuations near a bifurcation. By deriving how statistical measures like recovery time, variance, and autocorrelation behave as a system approaches a tipping point , you will learn to recognize the universal warning signs of an impending critical transition in complex adaptive systems.",
            "id": "4134472",
            "problem": "Consider a $1$-dimensional continuous-time stochastic dynamical system driven by small observational noise, modeled as a stochastic differential equation (SDE) \n$$\n\\mathrm{d}x_t \\;=\\; f(x_t;\\mu)\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_t,\n$$\nwhere $x_t \\in \\mathbb{R}$ is the system state, $\\mu \\in \\mathbb{R}$ is a control parameter, $\\sigma  0$ is a constant noise amplitude, and $W_t$ is a standard Wiener process (Gaussian Brownian motion) with independent increments. Assume there exists a stable equilibrium $x^\\ast(\\mu)$ for all $\\mu  \\mu_c$, and that stability is lost at $\\mu=\\mu_c$ through a local bifurcation so that the leading linear stability exponent $\\lambda(\\mu) := \\partial_x f(x^\\ast(\\mu);\\mu)$ satisfies $\\lambda(\\mu)  0$ for $\\mu  \\mu_c$ and $\\lambda(\\mu) \\to 0^{-}$ as $\\mu \\to \\mu_c^{-}$. You observe a stationary time series generated near the equilibrium for $\\mu\\mu_c$ and fixed $\\sigma$.\n\nUsing only the linearization of the dynamics about $x^\\ast(\\mu)$ and the defining properties of Gaussian white noise as the time derivative of $W_t$, derive from first principles how the deterministic recovery from a small perturbation behaves, and how the lag-$\\Delta$ autocorrelation and stationary variance of the observed fluctuations depend on $\\lambda(\\mu)$ and $\\sigma$ for fixed finite $\\Delta0$. Then, based on your derivation, identify which of the following statements are correct as $\\mu \\to \\mu_c^{-}$:\n\nA. The characteristic recovery time back to equilibrium after a small perturbation diverges like $1/|\\lambda(\\mu)|$.\n\nB. For any fixed lag $\\Delta0$, the autocorrelation at lag $\\Delta$ of the stationary fluctuations increases toward $1$.\n\nC. For fixed $\\sigma$, the stationary variance of the fluctuations diverges and scales proportionally to $\\sigma^2/(-\\lambda(\\mu))$.\n\nD. For fixed $\\sigma$, the lag-$\\Delta$ autocorrelation decreases toward $0$ because the system becomes less stable near the bifurcation.\n\nE. If $\\sigma$ is held constant, the stationary variance remains bounded while only the mean shifts; divergence of the variance requires $\\sigma \\to \\infty$.\n\nSelect all that apply.",
            "solution": "The problem statement describes a canonical model for studying systems near a bifurcation point, a fundamental concept in nonlinear dynamics and statistical physics. The linearization of a stochastic differential equation (SDE) near a stable equilibrium leads to the Ornstein-Uhlenbeck process, which is a cornerstone of stochastic modeling. The phenomenon described is known as critical slowing down. The problem is well-posed and scientifically sound.\n\nThe analysis proceeds by linearizing the SDE around the stable equilibrium $x^\\ast(\\mu)$. Let $y_t = x_t - x^\\ast(\\mu)$ be the fluctuation around the equilibrium. For small fluctuations, the dynamics are governed by the linearized SDE, also known as the Ornstein-Uhlenbeck (OU) process:\n$$\n\\mathrm{d}y_t = \\lambda(\\mu) y_t \\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t\n$$\nwhere $\\lambda(\\mu)  0$ is the stability exponent.\n\n**1. Deterministic Recovery Time**\nThe deterministic part of the dynamics is $\\frac{\\mathrm{d}y_t}{\\mathrm{d}t} = \\lambda(\\mu) y_t$. The solution is $y(t) = y_0 e^{\\lambda(\\mu) t}$. The characteristic recovery time, $\\tau$, is the time it takes for a perturbation to decay to $1/e$ of its initial value, which implies $\\lambda(\\mu) \\tau = -1$. Since $\\lambda(\\mu)  0$, the recovery time is $\\tau = -1/\\lambda(\\mu) = 1/|\\lambda(\\mu)|$. As the system approaches the bifurcation point ($\\mu \\to \\mu_c^{-}$), the stability exponent approaches zero ($\\lambda(\\mu) \\to 0^{-}$), so the recovery time $\\tau$ diverges.\n\n**2. Stationary Variance**\nFor an OU process, the stationary variance can be calculated using ItÃ´ isometry. The result is:\n$$\n\\text{Var}(y_t) = \\frac{-\\sigma^2}{2\\lambda(\\mu)}\n$$\nAs $\\mu \\to \\mu_c^{-}$, $\\lambda(\\mu) \\to 0^{-}$, so the denominator approaches zero from the negative side, causing the variance to diverge to $+\\infty$. The variance scales proportionally to $1/(-\\lambda(\\mu))$.\n\n**3. Lag-$\\Delta$ Autocorrelation**\nThe autocorrelation function for a stationary OU process is given by:\n$$\nC(\\Delta) = \\frac{\\text{Cov}(y_t, y_{t+\\Delta})}{\\text{Var}(y_t)} = e^{\\lambda(\\mu)\\Delta}\n$$\nFor any fixed time lag $\\Delta > 0$, as the system approaches the bifurcation point ($\\mu \\to \\mu_c^{-}$), we have $\\lambda(\\mu) \\to 0^{-}$. Therefore, the exponent $\\lambda(\\mu)\\Delta \\to 0$, and the autocorrelation approaches $e^0 = 1$. The system's \"memory\" increases, meaning its state at a given time becomes more correlated with its state at a later time.\n\n### Option-by-Option Analysis\n\n**A. The characteristic recovery time back to equilibrium after a small perturbation diverges like $1/|\\lambda(\\mu)|$.**\nOur derivation shows $\\tau = 1/|\\lambda(\\mu)|$. As $\\mu \\to \\mu_c^{-}$, $|\\lambda(\\mu)| \\to 0^{+}$, so $\\tau$ diverges with the stated scaling. This statement is **correct**.\n\n**B. For any fixed lag $\\Delta0$, the autocorrelation at lag $\\Delta$ of the stationary fluctuations increases toward $1$.**\nOur derivation shows $C(\\Delta) = e^{\\lambda(\\mu)\\Delta}$. As $\\mu \\to \\mu_c^{-}$, $\\lambda(\\mu)$ increases towards $0$, so the exponent $\\lambda(\\mu)\\Delta$ increases towards $0$. Thus, $C(\\Delta)$ increases toward $1$. This statement is **correct**.\n\n**C. For fixed $\\sigma$, the stationary variance of the fluctuations diverges and scales proportionally to $\\sigma^2/(-\\lambda(\\mu))$.**\nOur derivation shows $\\text{Var}(y_t) = \\frac{\\sigma^2}{2(-\\lambda(\\mu))}$. As $\\mu \\to \\mu_c^{-}$, $(-\\lambda(\\mu)) \\to 0^{+}$, so the variance diverges. The scaling is proportional to $\\sigma^2/(-\\lambda(\\mu))$. This statement is **correct**.\n\n**D. For fixed $\\sigma$, the lag-$\\Delta$ autocorrelation decreases toward $0$ because the system becomes less stable near the bifurcation.**\nThis contradicts our finding that the autocorrelation increases toward $1$. The reasoning is also incorrect; reduced stability leads to longer memory, hence higher correlation over a fixed lag. This statement is **incorrect**.\n\n**E. If $\\sigma$ is held constant, the stationary variance remains bounded while only the mean shifts; divergence of the variance requires $\\sigma \\to \\infty$.**\nThis contradicts our finding that the variance diverges for any fixed $\\sigma > 0$ as $\\lambda(\\mu) \\to 0$. The divergence is an intrinsic property of the system's dynamics near the bifurcation (critical slowing down), not a property of the noise amplitude. This statement is **incorrect**.",
            "answer": "$$\\boxed{ABC}$$"
        }
    ]
}