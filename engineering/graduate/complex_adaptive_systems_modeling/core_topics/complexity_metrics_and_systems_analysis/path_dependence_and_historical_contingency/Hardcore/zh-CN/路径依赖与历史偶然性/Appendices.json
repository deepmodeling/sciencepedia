{
    "hands_on_practices": [
        {
            "introduction": "波利亚瓮（Pólya urn）是理解路径依赖中“回报递增”或“富者愈富”动态的经典范例。这个练习旨在通过形式化一个表面上非马尔可夫的过程，揭示其潜在的马尔可夫结构，这需要我们巧妙地增广状态空间以囊括所有相关的历史信息。掌握这一技巧对于为历史起作用的复杂系统建立严谨的动态模型至关重要。",
            "id": "4136085",
            "problem": "考虑一个经典的Pólya瓮，其中有两种颜色的球：红球和蓝球。在时间 $t=0$ 时，瓮中装有 $r_{0} \\in \\mathbb{N}$ 个红球和 $b_{0} \\in \\mathbb{N}$ 个蓝球。在每个离散时间步 $t \\mapsto t+1$，从瓮中均匀随机地抽取一个球，观察其颜色，然后将该球放回瓮中，并额外加入一个同色的球。令 $X_{t} \\in \\{\\text{红}, \\text{蓝}\\}$ 表示在时间 $t$ 抽出的球的颜色，令 $R_{t}$ 和 $B_{t}$ 分别表示在时间 $t$ 抽球之前瓮中红球和蓝球的数量。\n\n你需要使用马尔可夫性质来形式化该过程的路径依赖和历史偶然性。从马尔可夫性质的标准定义和瓮的抽样规则出发，确定一个最小充分的增广状态过程 $S_{t} = \\varphi\\!\\left(X_{0}, X_{1}, \\dots, X_{t}\\right)$，使得 $\\{S_{t}\\}_{t \\ge 0}$ 是一个时齐马尔可夫链，其一步转移概率不显式地依赖于 $t$。从业已发生的历史中，能够使动态过程变为时齐马尔可夫过程的最小信息量这一角度，来论证其最小充分性。\n\n然后，推导这个增广状态上的一步转移概率：对于一个泛指状态 $(r,b)$，其中 $r \\in \\mathbb{N}$ 且 $b \\in \\mathbb{N}$，将转移到两个可能的下一状态，即 $(r+1,b)$ 和 $(r,b+1)$ 的概率，写成关于 $r$ 和 $b$ 的精确代数表达式。\n\n你的最终答案必须是一个单行矩阵，其两个元素按顺序对应这两个转移概率。不要对任何量进行近似。",
            "solution": "所述问题具有科学依据，提法恰当，客观且内部一致。它描述了经典的Pólya瓮模型，这是一个基础的随机过程，用于阐释强化和路径依赖等概念。所有必要的信息都已提供，足以形式化该过程并推导其转移概率。因此，该问题是有效的。\n\n问题的核心是在马尔可夫链的框架内，形式化Pólya瓮过程的路径依赖特性。路径依赖意味着事件的历史会影响未来的结果。相比之下，马尔可夫过程是无记忆的：其未来的演化仅依赖于当前状态，而与到达该状态的路径无关。解决方法在于定义一个能够完全封装所有过去相关信息的状态变量。\n\n设系统在时间 $t \\geq 0$ 的状态由数对 $S_t = (R_t, B_t)$ 定义，其中 $R_t$ 和 $B_t$ 分别为在时间 $t$ 抽球之前瓮中红球和蓝球的数量。初始状态为 $S_0 = (r_0, b_0)$。\n\n状态 $S_t$ 是抽球历史 $\\{X_0, X_1, \\dots, X_{t-1}\\}$ 的函数。具体来说，对于 $t \\ge 1$，红球的数量 $R_t$ 是初始数量 $r_0$ 加上在前 $t$ 步中抽到红球的次数。类似的逻辑也适用于蓝球。形式上：\n$$R_t = r_0 + \\sum_{i=0}^{t-1} \\mathbb{I}(X_i = \\text{红})$$\n$$B_t = b_0 + \\sum_{i=0}^{t-1} \\mathbb{I}(X_i = \\text{蓝})$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。状态 $S_t=(R_t, B_t)$ 是累积了历史信息的“增广状态”。不同的抽球序列（路径）可能导致不同的状态 $(R_t, B_t)$，这一事实是该模型中历史偶然性的本质。在时间 $t$ 的总球数为 $N_t = R_t + B_t = r_0 + b_0 + t$。\n\n我们现在必须证明过程 $\\{S_t\\}_{t \\geq 0}$ 是一个时齐马尔可夫链，并且 $S_t$ 是一个最小充分状态。\n\n**1. 马尔可夫性质与时齐性**\n\n为证明马尔可夫性质，我们必须表明下一状态 $S_{t+1}$ 的条件概率仅依赖于当前状态 $S_t$，而不依赖于任何过去的状态 $S_{t-1}, \\dots, S_0$。\n从 $S_t$到 $S_{t+1}$ 的状态转移是通过在时间 $t$ 的抽球实现的。设当前状态为 $S_t = (R_t, B_t) = (r, b)$。总球数为 $r+b$。\n在时间 $t$ 抽到红球的概率为：\n$$P(X_t = \\text{红} | S_t=(r,b), S_{t-1}, \\dots, S_0) = \\frac{r}{r+b}$$\n这个概率仅依赖于当前状态 $S_t=(r,b)$ 的分量。如果抽到红球，下一步瓮中的组成为 $(r+1, b)$。因此，下一状态是 $S_{t+1}=(r+1, b)$。\n抽到蓝球的概率为：\n$$P(X_t = \\text{蓝} | S_t=(r,b), S_{t-1}, \\dots, S_0) = \\frac{b}{r+b}$$\n这也仅依赖于 $S_t$。如果抽到蓝球，下一状态是 $S_{t+1}=(r, b+1)$。\n\n从状态 $(r,b)$ 出发的一步转移概率为：\n$$P(S_{t+1}=(r+1, b) | S_t=(r,b)) = \\frac{r}{r+b}$$\n$$P(S_{t+1}=(r, b+1) | S_t=(r,b)) = \\frac{b}{r+b}$$\n由于这些概率仅依赖于当前状态 $(r,b)$ 而不依赖于时间索引 $t$，因此过程 $\\{S_t\\}_{t \\geq 0}$ 是一个时齐马尔可夫链。\n\n**2. 最小充分性**\n\n要论证 $S_t=(R_t, B_t)$ 是一个最小充分状态，我们必须证明没有更小的信息集可以定义一个时齐马尔可夫过程。转移概率从根本上取决于红球占总球数的比例 $R_t/(R_t+B_t)$ 和蓝球占总球数的比例 $B_t/(R_t+B_t)$。要计算这些比例，需要同时知道 $R_t$ 和 $B_t$。\n- 如果状态仅由 $R_t$ 定义，那么在不知道 $t$ 或 $B_t$ 的情况下，我们无法计算分母 $R_t+B_t$。\n- 如果状态仅由总球数 $N_t = R_t+B_t = r_0+b_0+t$ 定义（这等价于知道时间 $t$），我们无法计算分子 $R_t$ 或 $B_t$。\n- 如果状态是红球的比例 $P_t=R_t/(R_t+B_t)$，那么到下一个比例的转移将取决于总球数 $N_t$，由于 $N_t$ 随时间确定性地变化，这将使过程成为非时齐的。\n因此，数对 $(R_t, B_t)$ 是在不显式引用时间 $t$ 的情况下指定转移概率所必需的历史信息的最小表示。\n\n**3. 转移概率的推导**\n\n现在，我们为泛指状态 $(r,b)$ 推导所要求的转移概率，其中 $r \\in \\mathbb{N}$ 且 $b \\in \\mathbb{N}$。瓮中含有 $r$ 个红球和 $b$ 个蓝球，总共 $r+b$ 个球。\n\n第一个可能的下一状态是 $(r+1, b)$。当且仅当抽到红球时，才会达到此状态。此事件的概率是红球数量除以总球数。\n$$P((r,b) \\to (r+1,b)) = \\frac{r}{r+b}$$\n\n第二个可能的下一状态是 $(r, b+1)$。当且仅当抽到蓝球时，才会达到此状态。此事件的概率是蓝球数量除以总球数。\n$$P((r,b) \\to (r,b+1)) = \\frac{b}{r+b}$$\n\n这是从状态 $(r,b)$ 出发的仅有的两种可能的一步转移。它们的和为 $\\frac{r}{r+b} + \\frac{b}{r+b} = \\frac{r+b}{r+b} = 1$，这符合后续状态的完整概率分布的要求。\n\n最终答案要求将这两个概率放在一个行矩阵中。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{r}{r+b}  \\frac{b}{r+b} \\end{pmatrix} } $$"
        },
        {
            "introduction": "本练习转向连续时间随机动力学，以一个双阱势能系统为背景，探讨“历史偶然性”如何导致系统被“锁定”在某个长期状态。通过运用克莱默斯速率理论（Kramers’ rate theory）来估算系统在噪声驱动下逃离一个势阱的期望时间，您将能够量化分析能量壁垒与随机扰动如何共同决定了系统状态的持久性以及关键性转变事件的发生概率。这个模型清晰地展示了微小的随机事件如何能够产生巨大且持久的后果。",
            "id": "4136056",
            "problem": "考虑一个过阻尼的基于智能体的聚合体，其在介观尺度上由单一状态变量 $x_t \\in \\mathbb{R}$ 表示，并在一个双阱势下演化。该粗粒化动力学由过阻尼朗之万随机微分方程（SDE）建模，定义如下：\n$$\ndx_t \\;=\\; -V'(x_t)\\,dt \\;+\\; \\sqrt{2\\,\\varepsilon}\\,dW_t,\n$$\n其中，$W_t$ 是一个标准维纳过程，$\\varepsilon  0$ 是一个小的无量纲噪声强度，$V(x)$ 是势能景观。该势函数为：\n$$\nV(x) \\;=\\; \\frac{\\alpha}{4}\\,x^{4} \\;-\\; \\frac{\\beta}{2}\\,x^{2},\n$$\n参数为 $\\alpha = 1$ 和 $\\beta = 3$。时间 $t$ 的单位为秒。假设系统从左势阱中靠近局部极小值 $x = -\\sqrt{\\beta/\\alpha}$ 的位置开始，且 $\\varepsilon = 0.2$。在小噪声机制下，从一个势阱逃逸到另一个势阱是稀有事件，其期望时间尺度由能垒和噪声驱动的激活所决定。\n\n从梯度流、亚稳态之间的势垒以及过阻尼福克-普朗克动力学的准静态分布等基本定义出发，根据第一性原理推导出能垒 $\\Delta V$，然后使用过阻尼极限下的经典 Kramers 速率来估计从左势阱越过中心鞍点的期望逃逸时间。通过解释为什么稀有的早期逃逸事件能将系统在长期视界内锁定在另一个吸引盆中，将计算结果与路径依赖和历史偶然性的概念联系起来。\n\n计算期望逃逸时间的数值，并以秒为单位表示最终答案。将最终数值四舍五入至四位有效数字。",
            "solution": "此问题已经过验证。\n\n**第1步：提取给定信息**\n- **SDE:** $dx_t = -V'(x_t)\\,dt + \\sqrt{2\\,\\varepsilon}\\,dW_t$\n- **状态变量:** $x_t \\in \\mathbb{R}$\n- **噪声项:** $W_t$ 是一个标准维纳过程\n- **噪声强度:** $\\varepsilon = 0.2$ (无量纲)\n- **势函数:** $V(x) = \\frac{\\alpha}{4}\\,x^{4} - \\frac{\\beta}{2}\\,x^{2}$\n- **势参数:** $\\alpha = 1$，$\\beta = 3$\n- **时间单位:** 秒\n- **初始条件:** 系统从左势阱中靠近局部极小值 $x = -\\sqrt{\\beta/\\alpha}$ 的位置开始。\n- **目标:** 推导能垒 $\\Delta V$，使用 Kramers 速率估计期望逃逸时间 $\\tau$，将结果与路径依赖和历史偶然性联系起来，并计算 $\\tau$ 的数值，四舍五入到四位有效数字。\n\n**第2步：使用提取的给定信息进行验证**\n- **科学依据:** 该问题牢固地植根于成熟的随机过程理论，特别是朗之万方程和 Kramers 逃逸速率理论在双稳态系统中的应用。双阱势是物理学、化学和复杂系统研究中用于研究噪声诱导相变的典范模型。所有概念都是标准的并且科学上是合理的。\n- **适定性:** 该问题是适定的。所有必要的参数（$\\alpha$, $\\beta$, $\\varepsilon$）和势函数 $V(x)$ 的形式都已给出。目标陈述清晰，可以从给定信息中推导出期望逃逸时间的唯一且有意义的解。\n- **客观性:** 该问题以精确、客观的数学和物理语言陈述，没有任何主观性或歧义。\n\n**第3步：结论与行动**\n该问题有效。它满足了所有关于科学性、适定性和客观性的标准。没有可识别的缺陷。将提供完整解答。\n\n**推导与求解**\n\n系统的动力学由势能景观 $V(x)$ 上的梯度流决定，并受到一个随机项的扰动。势函数由下式给出：\n$$\nV(x) = \\frac{\\alpha}{4}x^{4} - \\frac{\\beta}{2}x^{2}\n$$\n动力学的确定性部分由力 $F(x) = -V'(x)$ 驱动。系统的平衡点对应于该力为零的位置，即势梯度为零的位置：\n$$\nV'(x) = \\frac{d}{dx}\\left(\\frac{\\alpha}{4}x^{4} - \\frac{\\beta}{2}x^{2}\\right) = \\alpha x^{3} - \\beta x = 0\n$$\n对表达式进行因式分解得到 $x(\\alpha x^2 - \\beta) = 0$，这产生三个平衡点：\n$x_1 = 0$\n$x_2 = \\sqrt{\\frac{\\beta}{\\alpha}}$\n$x_3 = -\\sqrt{\\frac{\\beta}{\\alpha}}$\n\n为了确定这些点的稳定性，我们考察势函数的二阶导数 $V''(x)$：\n$$\nV''(x) = \\frac{d}{dx}(\\alpha x^{3} - \\beta x) = 3\\alpha x^{2} - \\beta\n$$\n- 在 $x_1 = 0$ 处：$V''(0) = -\\beta$。由于 $\\beta = 3  0$，因此 $V''(0)  0$。这表明 $x=0$ 是一个局部极大值，对应于一个不稳定平衡（鞍点或势垒峰）。\n- 在 $x_{2,3} = \\pm\\sqrt{\\frac{\\beta}{\\alpha}}$ 处：$V''\\left(\\pm\\sqrt{\\frac{\\beta}{\\alpha}}\\right) = 3\\alpha\\left(\\frac{\\beta}{\\alpha}\\right) - \\beta = 3\\beta - \\beta = 2\\beta$。由于 $\\beta=30$，因此 $V''(\\pm\\sqrt{\\beta/\\alpha})  0$。这表明这两点是局部极小值，对应于稳定平衡态（势阱的底部）。\n\n问题陈述系统从左势阱开始，这是稳定极小值 $x_{\\text{min}} = -\\sqrt{\\beta/\\alpha}$ 的吸引盆。为了使系统逃逸到右势阱（在 $x=+\\sqrt{\\beta/\\alpha}$ 附近），它必须越过位于鞍点 $x_{\\text{saddle}} = 0$ 处的势垒。\n\n能垒 $\\Delta V$ 是鞍点与初始势阱极小值之间的势能差：\n$$\n\\Delta V = V(x_{\\text{saddle}}) - V(x_{\\text{min}}) = V(0) - V\\left(-\\sqrt{\\frac{\\beta}{\\alpha}}\\right)\n$$\n我们计算这些点的势能：\n$V(0) = \\frac{\\alpha}{4}(0)^{4} - \\frac{\\beta}{2}(0)^{2} = 0$\n$V\\left(-\\sqrt{\\frac{\\beta}{\\alpha}}\\right) = \\frac{\\alpha}{4}\\left(-\\sqrt{\\frac{\\beta}{\\alpha}}\\right)^4 - \\frac{\\beta}{2}\\left(-\\sqrt{\\frac{\\beta}{\\alpha}}\\right)^2 = \\frac{\\alpha}{4}\\left(\\frac{\\beta^2}{\\alpha^2}\\right) - \\frac{\\beta}{2}\\left(\\frac{\\beta}{\\alpha}\\right) = \\frac{\\beta^2}{4\\alpha} - \\frac{\\beta^2}{2\\alpha} = -\\frac{\\beta^2}{4\\alpha}$\n因此，能垒为：\n$$\n\\Delta V = 0 - \\left(-\\frac{\\beta^2}{4\\alpha}\\right) = \\frac{\\beta^2}{4\\alpha}\n$$\n期望逃逸时间 $\\tau$ 可以使用过阻尼极限下的 Kramers 速率公式来估计。逃逸速率 $k$（单位时间内发生逃逸事件的概率）由下式给出：\n$$\nk = \\frac{\\sqrt{V''(x_{\\text{min}}) |V''(x_{\\text{saddle}})|}}{2\\pi} \\exp\\left(-\\frac{\\Delta V}{\\varepsilon}\\right)\n$$\n在这里，我们将给定的 SDE 中的噪声项 $\\varepsilon$ 与标准物理学公式中的热能标度 $k_B T$ 等同起来，并且摩擦系数被隐式设为 $\\gamma=1$。\n我们有：\n$V''(x_{\\text{min}}) = V''(-\\sqrt{\\beta/\\alpha}) = 2\\beta$\n$V''(x_{\\text{saddle}}) = V''(0) = -\\beta$，所以 $|V''(x_{\\text{saddle}})| = \\beta$。\n\n将这些代入速率公式：\n$$\nk = \\frac{\\sqrt{(2\\beta)(\\beta)}}{2\\pi} \\exp\\left(-\\frac{\\beta^2}{4\\alpha\\varepsilon}\\right) = \\frac{\\sqrt{2\\beta^2}}{2\\pi} \\exp\\left(-\\frac{\\beta^2}{4\\alpha\\varepsilon}\\right) = \\frac{\\beta\\sqrt{2}}{2\\pi} \\exp\\left(-\\frac{\\beta^2}{4\\alpha\\varepsilon}\\right)\n$$\n期望逃逸时间 $\\tau$ 是速率 $k$ 的倒数：\n$$\n\\tau = \\frac{1}{k} = \\frac{2\\pi}{\\beta\\sqrt{2}} \\exp\\left(\\frac{\\beta^2}{4\\alpha\\varepsilon}\\right) = \\frac{\\pi\\sqrt{2}}{\\beta} \\exp\\left(\\frac{\\beta^2}{4\\alpha\\varepsilon}\\right)\n$$\n该表达式给出了从左势阱到右势阱的平均首达时间。\n\n**与路径依赖和历史偶然性的联系**\n这个模型清晰地展示了路径依赖和历史偶然性。\n1.  **路径依赖:** 系统的长期状态依赖于其历史。初始条件将系统置于左势阱中。由于能垒 $\\Delta V$ 和小噪声强度 $\\varepsilon$，系统将被困在这个势阱中很长时间，平均持续时间为 $\\tau$。在任何时间 $t \\ll \\tau$，系统极大概率处于左势阱中。因此，未来的状态表现出对其过去轨迹的强烈依赖。\n2.  **历史偶然性:** 从左势阱到右势阱的转变是一个稀有的、随机的事件。逃逸的确切时刻是不可预测的；它是一个“偶然”事件。如果偶然地，一系列足够大的噪声涨落累积起来，在早期将系统推过势垒（一个“历史偶然事件”），那么系统的命运将发生巨大改变。它将被“锁定”在右势阱的吸引盆中，并将在那里再次停留很长时间（平均来说，又是一个 $\\tau$ 的周期）。因此，系统的长期历史不是预先注定的，而是取决于这个稀有逃逸事件的随机发生。一个在这样的转换发生很久之后观察系统的观察者可能无法推断出其原始状态，因为系统现在看起来自然地属于右势阱。\n\n**数值计算**\n我们将给定的值 $\\alpha = 1$，$\\beta = 3$ 和 $\\varepsilon = 0.2$ 代入 $\\tau$ 的表达式中。\n首先，我们计算指数的参数：\n$$\n\\frac{\\Delta V}{\\varepsilon} = \\frac{\\beta^2}{4\\alpha\\varepsilon} = \\frac{3^2}{4(1)(0.2)} = \\frac{9}{0.8} = 11.25\n$$\n现在，我们计算指前因子：\n$$\n\\frac{\\pi\\sqrt{2}}{\\beta} = \\frac{\\pi\\sqrt{2}}{3}\n$$\n将所有部分组合起来：\n$$\n\\tau = \\frac{\\pi\\sqrt{2}}{3} \\exp(11.25)\n$$\n我们现在计算数值：\n$$\n\\tau \\approx \\frac{3.14159 \\times 1.41421}{3} \\times \\exp(11.25) \\approx \\frac{4.44288}{3} \\times 76878.56 \\approx 1.48096 \\times 76878.56\n$$\n$$\n\\tau \\approx 113851.34\n$$\n问题要求将最终答案四舍五入到四位有效数字。\n$$\n\\tau \\approx 113900 \\text{ s}\n$$\n这可以用科学记数法表示为 $1.139 \\times 10^5$ 秒。",
            "answer": "$$\\boxed{1.139 \\times 10^{5}}$$"
        },
        {
            "introduction": "Kauffman $N\\text{-}K$ 模型是研究相互作用（上位性）如何塑造复杂系统“崎岖景观”的基石，这直接导致了演化或搜索过程中的路径依赖。此练习要求您推导景观自相关性与系统内部耦合度（参数 $K$）之间的解析关系，从而深刻理解为何增加组件间的相互依赖性会使得系统更容易陷入次优的局部最优解。这解释了在生物演化、技术创新和组织适应等领域中，最终结果为何高度依赖于起始点和演化路径。",
            "id": "4136136",
            "problem": "考虑一个适应度景观的 Kauffman $N\\text{-}K$ 模型 (NK)，其中基因型是一个二进制字符串 $x \\in \\{0,1\\}^{N}$，基因型 $x$ 的适应度定义为 $W(x) = \\frac{1}{N} \\sum_{i=1}^{N} f_{i}(x_{i}, x_{i_{1}}, \\dots, x_{i_{K}})$，其中对每个索引 $i$，局部适应度贡献 $f_{i}$ 取决于位点 $i$ 和其他 $K$ 个位点 $i_{1}, \\dots, i_{K}$ 的状态，并满足以下假设：(i) 对每个 $i$，其邻域 $\\{i, i_{1}, \\dots, i_{K}\\}$ 是从 $\\{1, \\dots, N\\}$ 中无放回地均匀随机选取的，满足条件 $|\\{i, i_{1}, \\dots, i_{K}\\}| = K+1$；(ii) 在给定其输入的情况下，$f_{i}$ 对于所有输入配置都是一个独立同分布的随机变量，其均值为 $0$，方差为 $\\sigma^{2}$；以及 (iii) 给定它们的输入，不同索引的适应度贡献是相互独立的。设两个基因型 $x$ 和 $y$ 之间的汉明距离为 $h = \\sum_{j=1}^{N} \\mathbf{1}\\{x_{j} \\neq y_{j}\\}$。\n\n定义汉明距离为 $h$ 时的归一化自相关函数为\n$$\n\\rho(h) = \\frac{\\operatorname{Cov}(W(X), W(Y_{h}))}{\\operatorname{Var}(W(X))},\n$$\n其中 $X$ 在 $\\{0,1\\}^{N}$ 中均匀随机，而 $Y_{h}$ 在与 $X$ 的汉明距离为 $h$ 的所有基因型中均匀随机。仅使用模型定义以及标准的概率和协方差规则，推导 $\\rho(h)$ 作为 $N$、$K$ 和 $h$ 的精确函数。\n\n接下来，定义自相关长度 $\\ell$ 为满足\n$$\n\\rho(1) = \\exp\\!\\left(-\\frac{1}{\\ell}\\right),\n$$\n的正实数，它可作为一个粗糙度度量。明确地推导 $\\ell$ 作为关于 $N$ 和 $K$ 的解析闭式表达式，然后解析地证明，增加 $K$（视为区间 $[0, N-1]$ 上的实数参数）会使 $\\ell$ 严格递减。最后，讨论相关长度的缩短如何意味着景观上局部搜索轨迹的路径依赖性更强，但最终数值结果仅提供 $\\ell(N,K)$ 的闭式表达式。无需数值舍入，也不涉及单位。你的最终答案必须是单个闭式表达式。",
            "solution": "该问题陈述是复杂适应系统领域内一个有效的理论练习，具体涉及 Kauffman $N\\text-K$ 适应度景观的统计特性。所有定义都是标准的，前提在科学上和数学上都是合理的。我们将着手进行推导。\n\n我们的目标是首先推导归一化自相关函数 $\\rho(h)$，然后由此推导出自相关长度 $\\ell$。自相关函数定义为\n$$\n\\rho(h) = \\frac{\\operatorname{Cov}(W(X), W(Y_{h}))}{\\operatorname{Var}(W(X))}\n$$\n其中 $W(x) = \\frac{1}{N} \\sum_{i=1}^{N} f_{i}(x)$ 是基因型 $x$ 的适应度，期望是在基因型 $X \\in \\{0,1\\}^N$ 和 $Y_h$（一个与 $X$ 的汉明距离为 $h$ 的基因型）的均匀分布上计算的，并且也对随机适应度景观的系综进行计算。\n\n首先，我们计算分母 $\\operatorname{Var}(W(X))$。$W(X)$ 的期望是\n$$\n\\mathbb{E}[W(X)] = \\mathbb{E}\\left[\\frac{1}{N} \\sum_{i=1}^{N} f_{i}(X)\\right] = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{E}[f_{i}(X)]\n$$\n根据假设 (ii)，对于任何特定的输入配置，局部适应度贡献 $f_i$ 的均值为 $0$。由于 $X$ 是一个均匀随机的基因型，其各位是对 $f_i$ 的均匀随机输入。对所有可能的输入求平均，期望 $\\mathbb{E}[f_i(X)]$ 为 $0$。因此，$\\mathbb{E}[W(X)] = 0$。\n\n那么方差为 $\\operatorname{Var}(W(X)) = \\mathbb{E}[W(X)^2] - (\\mathbb{E}[W(X)])^2 = \\mathbb{E}[W(X)^2]$。\n$$\n\\mathbb{E}[W(X)^2] = \\mathbb{E}\\left[\\left(\\frac{1}{N} \\sum_{i=1}^{N} f_{i}(X)\\right)^2\\right] = \\frac{1}{N^2} \\mathbb{E}\\left[\\sum_{i=1}^{N} \\sum_{j=1}^{N} f_{i}(X) f_{j}(X)\\right] = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\mathbb{E}[f_{i}(X) f_{j}(X)]\n$$\n由于假设 (iii)，对于 $i \\neq j$，适应度贡献 $f_i$ 和 $f_j$ 是独立的。因此，对于 $i \\neq j$，$\\mathbb{E}[f_{i}(X) f_{j}(X)] = \\mathbb{E}[f_{i}(X)]\\mathbb{E}[f_{j}(X)] = 0 \\cdot 0 = 0$。该和简化为 $i=j$ 的对角项：\n$$\n\\operatorname{Var}(W(X)) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\mathbb{E}[f_i(X)^2]\n$$\n根据假设 (ii)，对于任何输入，随机变量 $f_i$ 的均值为 $0$，方差为 $\\sigma^2$。其平方的期望，对所有可能的输入（由随机基因型 $X$ 决定）求平均，就是其方差：$\\mathbb{E}[f_i(X)^2] = \\sigma^2$。\n$$\n\\operatorname{Var}(W(X)) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sigma^2 = \\frac{N\\sigma^2}{N^2} = \\frac{\\sigma^2}{N}\n$$\n\n接下来，我们计算分子 $\\operatorname{Cov}(W(X), W(Y_h))$。由于 $\\mathbb{E}[W(X)]=0$ 且 $\\mathbb{E}[W(Y_h)]=0$（因为 $Y_h$ 在所有基因型上也具有均匀的边缘分布），协方差简化为\n$$\n\\operatorname{Cov}(W(X), W(Y_h)) = \\mathbb{E}[W(X)W(Y_h)] = \\mathbb{E}\\left[\\left(\\frac{1}{N} \\sum_{i=1}^{N} f_i(X)\\right)\\left(\\frac{1}{N} \\sum_{j=1}^{N} f_j(Y_h)\\right)\\right] = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\mathbb{E}[f_i(X)f_j(Y_h)]\n$$\n同样，对于 $i \\neq j$，由于独立性，这些项为零。我们只剩下对角项：\n$$\n\\operatorname{Cov}(W(X), W(Y_h)) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\mathbb{E}[f_i(X)f_i(Y_h)]\n$$\n期望 $\\mathbb{E}[f_i(X)f_i(Y_h)]$ 仅在 $X$ 和 $Y_h$ 提供给 $f_i$ 的输入相同时才非零。设从基因型 $z$ 到 $f_i$ 的输入为 $z_{\\mathcal{N}_i}$，其中 $\\mathcal{N}_i$ 是 $i$ 的邻域（一个包含 $K+1$ 个位点的集合）。根据假设 (ii)，$f_i$ 对不同输入的值是不相关的。因此，$\\mathbb{E}[f_i(u)f_i(v)] = \\sigma^2 \\delta_{u,v}$，其中 $\\delta_{u,v}$ 是克罗内克δ函数。对基因型和景观求期望得到\n$$\n\\mathbb{E}[f_i(X)f_i(Y_h)] = \\sigma^2 P(X_{\\mathcal{N}_i} = (Y_h)_{\\mathcal{N}_i})\n$$\n输入 $X_{\\mathcal{N}_i}$ 和 $(Y_h)_{\\mathcal{N}_i}$ 相同，当且仅当 $X$ 和 $Y_h$ 之间不同的 $h$ 个位点中没有一个落入邻域 $\\mathcal{N}_i$。差异位点的集合 $S_h$ 是从 $\\{1, \\dots, N\\}$ 中均匀随机选取的、大小为 $h$ 的子集。邻域 $\\mathcal{N}_i$ 是一个包含 $K+1$ 个位点的集合。随机抽取 $h$ 个位点与一个固定的 $K+1$ 位点集合不相交的概率由超几何分布给出。我们从 $N$ 个位点中选择 $h$ 个，并希望从 $\\mathcal{N}_i$ 中的 $K+1$ 个位点中选出 $0$ 个，从 $\\mathcal{N}_i$ 之外的 $N-(K+1)$ 个位点中选出 $h$ 个。\n$$\nP(X_{\\mathcal{N}_i} = (Y_h)_{\\mathcal{N}_i}) = P(S_h \\cap \\mathcal{N}_i = \\emptyset) = \\frac{\\binom{K+1}{0} \\binom{N-(K+1)}{h}}{\\binom{N}{h}} = \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}}\n$$\n这个概率对于所有 $i$ 都是相同的。将其代入协方差表达式中：\n$$\n\\operatorname{Cov}(W(X), W(Y_h)) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sigma^2 \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}} = \\frac{N\\sigma^2}{N^2} \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}} = \\frac{\\sigma^2}{N} \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}}\n$$\n现在我们可以计算 $\\rho(h)$：\n$$\n\\rho(h) = \\frac{\\frac{\\sigma^2}{N} \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}}}{\\frac{\\sigma^2}{N}} = \\frac{\\binom{N-K-1}{h}}{\\binom{N}{h}}\n$$\n这是自相关函数的精确表达式。此式在 $h \\le N-K-1$ 时有效；当 $h  N-K-1$ 时，$\\rho(h)=0$。\n\n接下来，我们推导自相关长度 $\\ell$，其定义为 $\\rho(1) = \\exp(-1/\\ell)$。我们计算 $\\rho(h)$ 在 $h=1$ 时的值：\n$$\n\\rho(1) = \\frac{\\binom{N-K-1}{1}}{\\binom{N}{1}} = \\frac{N-K-1}{N} = 1 - \\frac{K+1}{N}\n$$\n使用 $\\ell$ 的定义：\n$$\n\\exp\\left(-\\frac{1}{\\ell}\\right) = 1 - \\frac{K+1}{N}\n$$\n对两边取自然对数求解 $\\ell$：\n$$\n-\\frac{1}{\\ell} = \\ln\\left(1 - \\frac{K+1}{N}\\right)\n$$\n$$\n\\ell = -\\frac{1}{\\ln\\left(1 - \\frac{K+1}{N}\\right)}\n$$\n这就是 $\\ell$ 关于 $N$ 和 $K$ 的闭式表达式。\n\n最后，我们必须证明 $\\ell$ 是 $K$ 的严格递减函数，将 $K$ 视为区间 $[0, N-1)$ 上的实数参数。我们计算导数 $\\frac{d\\ell}{dK}$：\n令 $u(K) = 1 - \\frac{K+1}{N}$。则 $\\frac{du}{dK} = -\\frac{1}{N}$。\n$\\ell$ 的表达式为 $\\ell(K) = -(\\ln(u(K)))^{-1}$。使用链式法则：\n$$\n\\frac{d\\ell}{dK} = -(-1)(\\ln(u(K)))^{-2} \\cdot \\frac{d}{dK}(\\ln(u(K))) = (\\ln(u(K)))^{-2} \\cdot \\frac{1}{u(K)} \\cdot \\frac{du}{dK}\n$$\n代入 $u(K)$ 及其导数的表达式：\n$$\n\\frac{d\\ell}{dK} = \\frac{1}{\\left(\\ln\\left(1 - \\frac{K+1}{N}\\right)\\right)^2} \\cdot \\frac{1}{1 - \\frac{K+1}{N}} \\cdot \\left(-\\frac{1}{N}\\right)\n$$\n我们分析当 $K \\in [0, N-1)$ 时每一项的符号：\n1. 对于 $K \\in [0, N-1)$，我们有 $1 \\le K+1  N$，所以 $0  \\frac{K+1}{N}  1$。\n2. 这意味着 $0  1 - \\frac{K+1}{N}  1$。\n3. 一个在 $0$ 和 $1$ 之间的数的对数是负的，所以 $\\ln\\left(1 - \\frac{K+1}{N}\\right)  0$。其平方是正的：$\\left(\\ln\\left(1 - \\frac{K+1}{N}\\right)\\right)^2  0$。\n4. $1 - \\frac{K+1}{N}$ 这一项是正的。它的倒数也是正的。\n5. 最后一项 $-\\frac{1}{N}$ 是负的，因为 $N \\ge 1$。\n综合起来，$\\frac{d\\ell}{dK}$ 是两个正项和一个负项的乘积。因此，对于所有 $K \\in [0, N-1)$，$\\frac{d\\ell}{dK}  0$。这证明了 $\\ell$ 是 $K$ 的严格递减函数。\n\n随着上位性 $K$ 的增加，相关长度 $\\ell$ 的减小标志着适应度景观变得更加“崎岖”。较小的 $\\ell$ 意味着基因型的适应度值随汉明距离的增加而更快地去相关。在崎岖的景观上，适应性行走（例如局部爬山法）更有可能被困在次优的局部适应度峰值上。最终达到的具体峰值对起始基因型和突变序列高度敏感。最终状态对历史轨迹的这种强烈依赖性是路径依赖的本质。因此，增加 $K$ 会增加景观的崎嶇度，从而导致进化动力学中更强的路径依赖性。",
            "answer": "$$\n\\boxed{-\\frac{1}{\\ln\\left(1 - \\frac{K+1}{N}\\right)}}\n$$"
        }
    ]
}