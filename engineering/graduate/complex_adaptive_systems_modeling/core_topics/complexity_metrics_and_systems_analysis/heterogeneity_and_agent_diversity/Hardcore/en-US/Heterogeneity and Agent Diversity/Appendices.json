{
    "hands_on_practices": [
        {
            "introduction": "A central challenge in modeling complex systems is bridging the gap between heterogeneous agent behavior and aggregate, system-level outcomes. This exercise demonstrates a powerful analytical approach where, under specific but insightful assumptions, this aggregation can be performed exactly. By working through a classic asset-pricing model, you will derive the market-level demand for a risky asset by integrating the optimal choices of individual agents, each with a different level of risk aversion . This practice reveals how properties of the heterogeneity distribution directly map onto parameters of the aggregate model, a foundational concept in fields from economics to ecology.",
            "id": "4125499",
            "problem": "Consider a one-period economy populated by a continuum of agents of total mass $M0$. Each agent $i$ chooses a risky-asset position $y_i \\in \\mathbb{R}$ to maximize expected utility over end-of-period consumption $c_i$. Agent preferences are constant absolute risk aversion (CARA; Constant Absolute Risk Aversion), given by $u_i(c) = -\\exp(-\\rho_i c)$, where the agent-specific absolute risk aversion parameter $\\rho_i$ is heterogeneous across agents. The risky asset has a random end-of-period payoff $X$ that is normally distributed with mean $\\mu$ and variance $\\sigma^{2}$, written $X \\sim \\mathcal{N}(\\mu,\\sigma^{2})$. The risk-free asset has a gross return $R_f  0$. The risky asset is traded at price $P  0$ at the beginning of the period.\n\nEach agent $i$ has initial wealth $W_i  0$ and allocates $y_i$ units to the risky asset, financing the purchase at price $P$ and placing remaining wealth into the risk-free asset. End-of-period consumption for agent $i$ is\n$$\nc_i \\;=\\; R_f\\,(W_i - P y_i) \\;+\\; y_i X.\n$$\nAgents choose $y_i$ to maximize $\\mathbb{E}[u_i(c_i)]$.\n\nAgent heterogeneity is captured by a distribution over $\\rho_i$: the $\\rho_i$ values are independently drawn from a Gamma distribution with shape parameter $g1$ and rate parameter $\\lambda0$, with probability density function\n$$\np(\\rho) \\;=\\; \\frac{\\lambda^{g}}{\\Gamma(g)}\\,\\rho^{g-1}\\,\\exp(-\\lambda \\rho), \\quad \\rho0,\n$$\nwhere $\\Gamma(\\cdot)$ denotes the Gamma function.\n\nUsing only fundamental definitions of expected utility maximization, properties of the normal distribution, and the CARA utility specification, derive the aggregate demand $Y(P)$ for the risky asset by integrating the individual optimal $y_i$ over the distribution $p(\\rho)$ and aggregating across the mass $M$ of agents. Express your final answer as a single closed-form analytic expression in terms of $M$, $\\mu$, $\\sigma^{2}$, $P$, $R_f$, $g$, and $\\lambda$. No numerical approximation or rounding is required. Do not include units in the final expression.",
            "solution": "The agent’s problem is to choose $y_i$ to maximize $\\mathbb{E}\\big[-\\exp(-\\rho_i c_i)\\big]$, where $c_i = R_f(W_i - P y_i) + y_i X$ and $X \\sim \\mathcal{N}(\\mu,\\sigma^{2})$. Because $c_i$ is an affine function of $X$ and $X$ is normal, $c_i$ is also normally distributed. Let us characterize $\\mathbb{E}[\\exp(-\\rho_i c_i)]$ using the moment generating function of the normal distribution.\n\nWrite $c_i$ as\n$$\nc_i \\;=\\; R_f W_i \\;+\\; y_i \\mu \\;-\\; R_f P y_i \\;+\\; y_i (X - \\mu).\n$$\nSince $X - \\mu \\sim \\mathcal{N}(0,\\sigma^{2})$, we have that $c_i$ is normal with mean\n$$\n\\mathbb{E}[c_i] \\;=\\; R_f W_i \\;+\\; y_i \\mu \\;-\\; R_f P y_i\n$$\nand variance\n$$\n\\mathrm{Var}(c_i) \\;=\\; y_i^{2}\\,\\sigma^{2}.\n$$\nFor a normal random variable $Z \\sim \\mathcal{N}(m,s^{2})$, the expectation $\\mathbb{E}[\\exp(t Z)] = \\exp\\!\\big(t m + \\tfrac{1}{2} t^{2} s^{2}\\big)$ for any real $t$. Applying this with $t=-\\rho_i$ and $Z=c_i$, we obtain\n$$\n\\mathbb{E}\\big[\\exp(-\\rho_i c_i)\\big] \\;=\\; \\exp\\!\\Big(-\\rho_i\\,\\mathbb{E}[c_i] \\;+\\; \\tfrac{1}{2}\\,\\rho_i^{2}\\,\\mathrm{Var}(c_i)\\Big)\n\\;=\\; \\exp\\!\\Big(-\\rho_i\\big(R_f W_i + y_i \\mu - R_f P y_i\\big) + \\tfrac{1}{2}\\rho_i^{2} y_i^{2} \\sigma^{2}\\Big).\n$$\nTherefore the expected utility is\n$$\n\\mathbb{E}\\big[u_i(c_i)\\big] \\;=\\; -\\,\\exp\\!\\Big(-\\rho_i\\big(R_f W_i + y_i \\mu - R_f P y_i\\big) + \\tfrac{1}{2}\\rho_i^{2} y_i^{2} \\sigma^{2}\\Big).\n$$\nMaximizing $\\mathbb{E}[u_i(c_i)]$ over $y_i$ is equivalent to minimizing the exponent\n$$\nB_i(y_i) \\;=\\; -\\rho_i\\big(R_f W_i + y_i \\mu - R_f P y_i\\big) \\;+\\; \\tfrac{1}{2}\\rho_i^{2} y_i^{2} \\sigma^{2},\n$$\nbecause the function $-\\exp(\\cdot)$ is strictly decreasing in its argument. The derivative of $B_i(y_i)$ with respect to $y_i$ is\n$$\n\\frac{d B_i}{d y_i} \\;=\\; -\\rho_i(\\mu - R_f P) \\;+\\; \\rho_i^{2}\\,\\sigma^{2}\\, y_i.\n$$\nSetting the first-order condition to zero yields\n$$\n-\\rho_i(\\mu - R_f P) \\;+\\; \\rho_i^{2}\\,\\sigma^{2}\\, y_i^{\\ast} \\;=\\; 0\n\\quad \\Longrightarrow \\quad\ny_i^{\\ast} \\;=\\; \\frac{\\mu - R_f P}{\\rho_i\\,\\sigma^{2}}.\n$$\nNote that $W_i$ drops out of the optimal choice because CARA preferences with normal risks yield wealth-independent risky demand.\n\nAggregate demand $Y(P)$ is the integral of individual demands over the population, scaled by the total mass $M$. With heterogeneity only in $\\rho_i$, we have\n$$\nY(P) \\;=\\; M \\int_{0}^{\\infty} \\frac{\\mu - R_f P}{\\rho\\,\\sigma^{2}}\\, p(\\rho)\\, d\\rho\n\\;=\\; \\frac{M(\\mu - R_f P)}{\\sigma^{2}} \\int_{0}^{\\infty} \\frac{1}{\\rho}\\, p(\\rho)\\, d\\rho\n\\;=\\; \\frac{M(\\mu - R_f P)}{\\sigma^{2}}\\,\\mathbb{E}\\!\\left[\\frac{1}{\\rho}\\right].\n$$\nFor $\\rho \\sim \\text{Gamma}(g,\\lambda)$ with shape $g1$ and rate $\\lambda0$,\n$$\np(\\rho) \\;=\\; \\frac{\\lambda^{g}}{\\Gamma(g)}\\,\\rho^{g-1}\\,\\exp(-\\lambda \\rho), \\quad \\rho0,\n$$\nand a standard property of the Gamma distribution is\n$$\n\\mathbb{E}\\!\\left[\\frac{1}{\\rho}\\right] \\;=\\; \\frac{\\lambda}{g-1},\n\\quad \\text{valid for } g1.\n$$\nSubstituting this into the aggregate demand expression gives\n$$\nY(P) \\;=\\; \\frac{M(\\mu - R_f P)}{\\sigma^{2}}\\,\\frac{\\lambda}{g-1}\n\\;=\\; \\frac{M\\,\\lambda\\,(\\mu - R_f P)}{\\sigma^{2}\\,(g-1)}.\n$$\nThis is a closed-form aggregate demand function obtained by integrating the first-order conditions across the heterogeneous distribution of absolute risk aversion.",
            "answer": "$$\\boxed{\\frac{M\\,\\lambda\\,(\\mu - R_f P)}{\\sigma^{2}\\,(g-1)}}$$"
        },
        {
            "introduction": "While analytical aggregation is powerful, the most interesting dynamics in complex systems often arise from non-linear interactions that defy closed-form solutions, requiring us to turn to simulation. This practice challenges you to implement a computational model of diffusion, where the spread of a behavior depends on a population's heterogeneous adoption thresholds . By simulating the dynamics under a bimodal threshold distribution, you will gain hands-on experience with how the specific shape of agent diversity can generate complex phenomena like critical mass effects and stalled cascades, building intuition that is difficult to obtain from equations alone.",
            "id": "4125496",
            "problem": "Consider a population of measure $1$ composed of heterogeneous agents, each characterized by an individual adoption threshold $\\theta \\in [0,1]$. Time is discrete, indexed by $t \\in \\{0,1,2,\\dots\\}$. Let $x_t \\in [0,1]$ denote the fraction of adopters at time $t$. An agent adopts at time $t+1$ if and only if the observed exposure level (assumed to equal the global adoption fraction $x_t$ under a well-mixed approximation) exceeds her threshold. Adoption is absorbing: once an agent adopts, she remains an adopter. The threshold distribution in the population is heterogeneous and modeled as a bimodal mixture of two Beta distributions defined on $[0,1]$.\n\nThe mixture model is parameterized by mode positions $m_1 \\in (0,1)$ and $m_2 \\in (0,1)$, concentration parameters $c_1  0$ and $c_2  0$, and mixing weight $w \\in [0,1]$. For each component $i \\in \\{1,2\\}$, define the Beta shape parameters $\\alpha_i = 1 + m_i c_i$ and $\\beta_i = 1 + (1 - m_i) c_i$, which guarantees that the mode of the Beta distribution is located at $m_i$ for $\\alpha_i  1$ and $\\beta_i  1$. Let $F_i(x)$ denote the cumulative distribution function (CDF) of the Beta distribution with parameters $(\\alpha_i, \\beta_i)$. The population threshold CDF is the mixture\n$$\nG(x) = w \\, F_1(x) + (1 - w) \\, F_2(x),\n$$\nwhich captures agent diversity through the positions and weights of the modes and their concentrations.\n\nUnder the well-mixed threshold adoption assumption, the fraction of adopters evolves as a monotonically non-decreasing process given by\n$$\nx_{t+1} = \\max\\{x_t, G(x_t)\\},\n$$\nwith initial adoption fraction $x_0 \\in [0,1]$. Define the speed of diffusion operationally as the earliest iteration index at which $x_t$ reaches given target adoption levels $a \\in (0,1)$, specifically $a = 0.5$ and $a = 0.9$; denote these times by $\\tau_{0.5}$ and $\\tau_{0.9}$. Define the extent of diffusion as the limit $x^{*} = \\lim_{t \\to \\infty} x_t$, which is a fixed point satisfying $x^{*} = G(x^{*})$ under the monotone absorbing dynamics.\n\nStarting from fundamental definitions of threshold adoption and cumulative distribution functions, implement a deterministic simulation that:\n- Computes the mixture CDF $G(x)$ for given parameters $m_1$, $m_2$, $c_1$, $c_2$, and $w$ as described above.\n- Iterates the update rule $x_{t+1} = \\max\\{x_t, G(x_t)\\}$ until convergence to a fixed point within a tolerance $\\varepsilon = 10^{-10}$ or until a maximum iteration cap $T_{\\max} = 1000$ is reached.\n- Records $\\tau_{0.5}$ and $\\tau_{0.9}$ as the smallest $t$ for which $x_t \\geq 0.5$ and $x_t \\geq 0.9$, respectively; if these targets are not reached within $T_{\\max}$ iterations, record $-1$ for the corresponding time.\n- Reports the extent $x^{*}$ as the final $x_t$ at convergence (or at $T_{\\max}$ if convergence is not achieved within the cap).\n\nAll quantities are unitless fractions expressed as decimals in $[0,1]$. Times are integers counting iterations.\n\nUse the following test suite of parameter sets, each specified as a tuple $(m_1, c_1, m_2, c_2, w, x_0)$:\n1. $(0.10, 80, 0.80, 80, 0.70, 0.05)$\n2. $(0.05, 20, 0.90, 20, 0.30, 0.02)$\n3. $(0.40, 50, 0.60, 50, 0.50, 0.05)$\n4. $(0.20, 100, 0.50, 10, 1.00, 0.01)$\n5. $(0.50, 10, 0.95, 100, 0.00, 0.05)$\n6. $(0.15, 30, 0.85, 30, 0.50, 0.20)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s result must be a list of the form $[x^{*}, \\tau_{0.5}, \\tau_{0.9}]$, where $x^{*}$ is a float and $\\tau_{0.5}, \\tau_{0.9}$ are integers, so the final output is a list of lists ordered according to the test suite, for example, $[[x^{*}_1, \\tau_{0.5,1}, \\tau_{0.9,1}], \\dots, [x^{*}_6, \\tau_{0.5,6}, \\tau_{0.9,6}]]$.",
            "solution": "The problem statement has been critically validated and is deemed scientifically sound, well-posed, and complete. It describes a classic threshold model of diffusion within a population of heterogeneous agents, a topic of central importance in the study of complex adaptive systems. The formulation is mathematically precise and computationally tractable.\n\nThe problem requires the simulation of a deterministic process of social diffusion. We consider a population of agents, each with a personal threshold $\\theta$ for adopting a behavior or innovation. The heterogeneity in the population is captured by a distribution of these thresholds. An agent adopts if the fraction of existing adopters, $x_t$, exceeds their personal threshold $\\theta$.\n\n**1. Model Formulation**\n\nThe core of the model is the interplay between the population state and the distribution of agent characteristics.\n\n**Agent Heterogeneity and Threshold Distribution:**\nThe diversity of agent thresholds is modeled by a probability distribution. The cumulative distribution function (CDF), denoted $G(x)$, gives the fraction of the population with a threshold $\\theta \\le x$. The problem specifies a bimodal distribution for thresholds, constructed as a mixture of two Beta distributions. This is a flexible choice suitable for modeling populations with distinct clusters of agents, for example, \"early adopters\" and \"late majority\".\n\nThe population's threshold CDF is given by:\n$$\nG(x) = w \\cdot F_1(x) + (1 - w) \\cdot F_2(x)\n$$\nwhere $F_1(x)$ and $F_2(x)$ are the CDFs of the two component Beta distributions, and $w \\in [0,1]$ is the mixing weight.\n\n**Beta Distribution Parameterization:**\nEach component Beta distribution is defined on the interval $[0,1]$. A Beta distribution is typically parameterized by two shape parameters, $\\alpha$ and $\\beta$. The problem provides an intuitive parameterization based on the mode (most frequent threshold) $m_i \\in (0,1)$ and a concentration parameter $c_i  0$ for each component $i \\in \\{1,2\\}$. The shape parameters are derived as follows:\n$$\n\\alpha_i = 1 + m_i c_i\n$$\n$$\n\\beta_i = 1 + (1 - m_i) c_i\n$$\nThis formulation ensures that $\\alpha_i  1$ and $\\beta_i  1$, which is the condition for a unique, interior mode. The mode of a Beta($\\alpha_i, \\beta_i$) distribution is given by $(\\alpha_i - 1) / (\\alpha_i + \\beta_i - 2)$. Substituting the expressions for $\\alpha_i$ and $\\beta_i$ confirms that the mode is indeed $m_i$:\n$$\n\\text{Mode} = \\frac{(1 + m_i c_i) - 1}{(1 + m_i c_i) + (1 + (1 - m_i) c_i) - 2} = \\frac{m_i c_i}{m_i c_i + (1 - m_i) c_i} = \\frac{m_i c_i}{c_i} = m_i\n$$\nThe CDF $F_i(x)$ for a Beta distribution with parameters $(\\alpha_i, \\beta_i)$ is the regularized incomplete beta function, $I_x(\\alpha_i, \\beta_i)$.\n\n**Adoption Dynamics:**\nThe fraction of adopters evolves over discrete time steps $t=0, 1, 2, \\dots$. At any time $t$, the fraction of agents who are willing to adopt is the fraction whose thresholds are met or exceeded by the current adoption level, i.e., all agents with $\\theta \\le x_t$. This fraction is precisely $G(x_t)$.\nThe problem states that adoption is absorbing, meaning an agent who adopts never reverts. This implies the fraction of adopters, $x_t$, cannot decrease. The dynamics are therefore captured by the following iterative map, starting from an initial adoption fraction $x_0$:\n$$\nx_{t+1} = \\max\\{x_t, G(x_t)\\}\n$$\nThis equation ensures that the sequence $\\{x_t\\}$ is monotonically non-decreasing and bounded above by $1$. By the Monotone Convergence Theorem, the sequence is guaranteed to converge to a limit, which we denote as the extent of diffusion, $x^* = \\lim_{t \\to \\infty} x_t$. This limit $x^*$ will be the smallest value $y \\ge x_0$ that satisfies the condition $y \\ge G(y)$, representing a stable equilibrium of the system.\n\n**2. Algorithmic Implementation**\n\nThe task is to simulate these dynamics for a given set of parameters $(m_1, c_1, m_2, c_2, w, x_0)$ and report the diffusion extent $x^*$ and the speed, measured by the time $\\tau$ to reach specific adoption levels.\n\n**Simulation Procedure:**\nThe algorithm proceeds as follows for each test case:\n1.  **Initialization**:\n    -   Set the time step $t=0$.\n    -   Set the initial adoption fraction $x_t$ to the given $x_0$.\n    -   Initialize the target times $\\tau_{0.5} = -1$ and $\\tau_{0.9} = -1$, indicating they have not yet been reached.\n    -   Define the maximum number of iterations $T_{\\max} = 1000$ and the convergence tolerance $\\varepsilon = 10^{-10}$.\n\n2.  **Iteration Loop**:\n    -   The simulation iterates from $t=0$ to $T_{\\max}-1$. In each step:\n        a. Calculate the Beta shape parameters $\\alpha_1, \\beta_1, \\alpha_2, \\beta_2$ from the given mode and concentration parameters.\n        b. Evaluate the mixture CDF $G(x_t)$ at the current adoption level $x_t$. This requires computing the Beta CDFs $F_1(x_t)$ and $F_2(x_t)$, which is done using a numerical library function (e.g., `scipy.stats.beta.cdf`).\n        c. Compute the next state $x_{t+1} = \\max\\{x_t, G(x_t)\\}$.\n        d. Check if adoption thresholds are crossed for the first time:\n           - If $x_{t+1} \\geq 0.5$ and $\\tau_{0.5}$ is still $-1$, set $\\tau_{0.5} = t+1$.\n           - If $x_{t+1} \\geq 0.9$ and $\\tau_{0.9}$ is still $-1$, set $\\tau_{0.9} = t+1$.\n        e. Check for convergence: If $|x_{t+1} - x_t|  \\varepsilon$, the system has reached a stable state. The loop is terminated, and $x^*$ is set to $x_{t+1}$.\n        f. Update the state for the next iteration: $x_t \\leftarrow x_{t+1}$.\n\n3.  **Termination and Output**:\n    -   If the loop completes by reaching $T_{\\max}$ without convergence, $x^*$ is taken as the final value of $x_t$.\n    -   The final results for the test case are $[x^*, \\tau_{0.5}, \\tau_{0.9}]$.\n\nThis algorithm provides a complete, deterministic, and verifiable solution to the problem. It will be implemented in Python, leveraging the `scipy` library for the required statistical functions.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import beta\n\ndef solve():\n    \"\"\"\n    Solves the bimodal threshold diffusion problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # (m1, c1, m2, c2, w, x0)\n        (0.10, 80, 0.80, 80, 0.70, 0.05),\n        (0.05, 20, 0.90, 20, 0.30, 0.02),\n        (0.40, 50, 0.60, 50, 0.50, 0.05),\n        (0.20, 100, 0.50, 10, 1.00, 0.01),\n        (0.50, 10, 0.95, 100, 0.00, 0.05),\n        (0.15, 30, 0.85, 30, 0.50, 0.20),\n    ]\n\n    T_max = 1000\n    epsilon = 1e-10\n    \n    all_results = []\n\n    for case in test_cases:\n        m1, c1, m2, c2, w, x0 = case\n\n        # Calculate Beta distribution parameters\n        alpha1 = 1 + m1 * c1\n        beta1 = 1 + (1 - m1) * c1\n        alpha2 = 1 + m2 * c2\n        beta2 = 1 + (1 - m2) * c2\n\n        # Initialize simulation variables\n        x_t = x0\n        tau_05 = -1\n        tau_09 = -1\n        \n        # Main simulation loop\n        for t in range(T_max):\n            # Calculate the mixture CDF G(x_t)\n            cdf1 = beta.cdf(x_t, alpha1, beta1)\n            cdf2 = beta.cdf(x_t, alpha2, beta2)\n            G_xt = w * cdf1 + (1 - w) * cdf2\n            \n            # Apply the update rule\n            x_t_plus_1 = max(x_t, G_xt)\n\n            # Check for reaching targets for the first time\n            if x_t_plus_1 = 0.5 and tau_05 == -1:\n                tau_05 = t + 1\n            if x_t_plus_1 = 0.9 and tau_09 == -1:\n                tau_09 = t + 1\n            \n            # Check for convergence\n            if abs(x_t_plus_1 - x_t)  epsilon:\n                x_t = x_t_plus_1\n                break\n            \n            # Update state\n            x_t = x_t_plus_1\n        \n        # Store the results for this case\n        x_star = x_t\n        all_results.append([x_star, tau_05, tau_09])\n    \n    # Format the final output string to be a list of lists without spaces\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n\n```"
        },
        {
            "introduction": "After building a model, whether analytical or computational, the crucial final step is to connect it to empirical reality by estimating its parameters from data. This task is often difficult for agent-based models, as their likelihood functions are typically intractable. This exercise introduces you to synthetic likelihood, a modern and widely-used simulation-based inference technique that bypasses this problem . You will first derive the form of the synthetic log-likelihood and then apply it to a concrete numerical example, providing you with a foundational skill for calibrating complex models against real-world summary statistics.",
            "id": "4125483",
            "problem": "Consider an Agent-Based Model (ABM) of $N$ agents with heterogeneous individual parameters $\\{\\phi_{i}\\}_{i=1}^{N}$, where each $\\phi_{i}$ is drawn independently from a distribution parameterized by a population-level parameter vector $\\theta \\in \\mathbb{R}^{p}$. Let $X(\\theta)$ denote the random system state generated by running the ABM at fixed $\\theta$, and let $s(X(\\theta)) \\in \\mathbb{R}^{d}$ be a $d$-dimensional vector of summary statistics encoding aggregate outcomes shaped by agent heterogeneity (for example, cross-agent mean and cross-agent dispersion of an outcome of interest). Assume the following foundations:\n- By the Central Limit Theorem (CLT) for dependent but weakly dependent aggregates, for sufficiently large $N$ and fixed $\\theta$, the distribution of $s(X(\\theta))$ is well-approximated by a multivariate Gaussian with mean $\\mu_{\\theta} \\in \\mathbb{R}^{d}$ and covariance $\\Sigma_{\\theta} \\in \\mathbb{R}^{d \\times d}$.\n- Independent simulation replications at the same $\\theta$ are independent and identically distributed draws from the distribution of $s(X(\\theta))$.\n- The unbiased sample covariance uses the factor $1/(S-1)$ when aggregating over $S$ independent replications.\n\nYou are given an observed summary vector $s_{\\text{obs}} \\in \\mathbb{R}^{d}$ computed from empirical data generated by an unknown ground-truth heterogeneity parameter $\\theta^{\\star}$. Synthetic likelihood approximates the intractable likelihood $p(s_{\\text{obs}} \\mid \\theta)$ by replacing $(\\mu_{\\theta}, \\Sigma_{\\theta})$ with the empirical estimators $(\\widehat{\\mu}_{\\theta}, \\widehat{\\Sigma}_{\\theta})$ computed from $S$ independent simulations at $\\theta$, yielding a plug-in Gaussian likelihood in the space of summary statistics.\n\nTask 1 (derivation): Starting from the definition of a likelihood for $s_{\\text{obs}}$ under the Gaussian approximation, derive the closed-form expression of the plug-in synthetic log-likelihood $\\widetilde{\\ell}_{\\text{SL}}(\\theta; s_{\\text{obs}})$ in terms of $d$, $\\widehat{\\mu}_{\\theta}$, and $\\widehat{\\Sigma}_{\\theta}$, where\n$$\n\\widehat{\\mu}_{\\theta} \\equiv \\frac{1}{S} \\sum_{r=1}^{S} s^{(r)}(\\theta), \n\\quad\n\\widehat{\\Sigma}_{\\theta} \\equiv \\frac{1}{S-1} \\sum_{r=1}^{S} \\left(s^{(r)}(\\theta) - \\widehat{\\mu}_{\\theta}\\right)\\left(s^{(r)}(\\theta) - \\widehat{\\mu}_{\\theta}\\right)^{\\top},\n$$\nand $s^{(r)}(\\theta)$ denotes the $r$-th independent simulation draw of the summary vector at parameter $\\theta$.\n\nTask 2 (evaluation): For $d = 2$ and $S = 5$, suppose the five independent simulated summary vectors at a fixed $\\theta$ are\n$$\ns^{(1)}(\\theta) = \\begin{pmatrix} 0.8 \\\\ 1.7 \\end{pmatrix}, \\quad\ns^{(2)}(\\theta) = \\begin{pmatrix} 1.2 \\\\ 2.3 \\end{pmatrix}, \\quad\ns^{(3)}(\\theta) = \\begin{pmatrix} 1.1 \\\\ 2.1 \\end{pmatrix}, \\quad\ns^{(4)}(\\theta) = \\begin{pmatrix} 0.9 \\\\ 1.9 \\end{pmatrix}, \\quad\ns^{(5)}(\\theta) = \\begin{pmatrix} 1.0 \\\\ 2.0 \\end{pmatrix}.\n$$\nThe observed summary is\n$$\ns_{\\text{obs}} = \\begin{pmatrix} 1.05 \\\\ 2.15 \\end{pmatrix}.\n$$\nUsing the result of Task $1$, compute the numerical value of the plug-in synthetic log-likelihood $\\widetilde{\\ell}_{\\text{SL}}(\\theta; s_{\\text{obs}})$ for these data. Round your final numerical answer to four significant figures. No units are required.",
            "solution": "The user has provided a well-posed and scientifically grounded problem statement that requires a two-part solution: a derivation followed by a numerical evaluation.\n\n### Task 1: Derivation of the Plug-in Synthetic Log-Likelihood\n\nThe problem specifies that the distribution of the summary statistics vector $s(X(\\theta))$ is approximated by a multivariate Gaussian distribution, $\\mathcal{N}(\\mu_{\\theta}, \\Sigma_{\\theta})$. The synthetic likelihood approach replaces the true, unknown parameters $(\\mu_{\\theta}, \\Sigma_{\\theta})$ with their empirical estimates $(\\widehat{\\mu}_{\\theta}, \\widehat{\\Sigma}_{\\theta})$ computed from $S$ independent simulations.\n\nThe probability density function (PDF) of a $d$-dimensional multivariate Gaussian distribution for a vector $x$ with mean $\\mu$ and covariance matrix $\\Sigma$ is given by:\n$$\np(x \\mid \\mu, \\Sigma) = \\frac{1}{(2\\pi)^{d/2} \\det(\\Sigma)^{1/2}} \\exp\\left(-\\frac{1}{2}(x-\\mu)^{\\top}\\Sigma^{-1}(x-\\mu)\\right)\n$$\nIn the context of synthetic likelihood, we evaluate this PDF at the observed summary statistics $s_{\\text{obs}}$, using the sample estimates $\\widehat{\\mu}_{\\theta}$ and $\\widehat{\\Sigma}_{\\theta}$ in place of $\\mu$ and $\\Sigma$. This gives the plug-in synthetic likelihood, $\\widetilde{L}_{\\text{SL}}(\\theta; s_{\\text{obs}})$:\n$$\n\\widetilde{L}_{\\text{SL}}(\\theta; s_{\\text{obs}}) = p(s_{\\text{obs}} \\mid \\widehat{\\mu}_{\\theta}, \\widehat{\\Sigma}_{\\theta}) = \\frac{1}{(2\\pi)^{d/2} \\det(\\widehat{\\Sigma}_{\\theta})^{1/2}} \\exp\\left(-\\frac{1}{2}(s_{\\text{obs}}-\\widehat{\\mu}_{\\theta})^{\\top}\\widehat{\\Sigma}_{\\theta}^{-1}(s_{\\text{obs}}-\\widehat{\\mu}_{\\theta})\\right)\n$$\nThe plug-in synthetic log-likelihood, $\\widetilde{\\ell}_{\\text{SL}}(\\theta; s_{\\text{obs}})$, is the natural logarithm of this expression:\n$$\n\\widetilde{\\ell}_{\\text{SL}}(\\theta; s_{\\text{obs}}) = \\ln\\left( \\widetilde{L}_{\\text{SL}}(\\theta; s_{\\text{obs}}) \\right)\n$$\nApplying the properties of logarithms, $\\ln(a/b) = \\ln(a) - \\ln(b)$ and $\\ln(\\exp(x)) = x$, we get:\n$$\n\\widetilde{\\ell}_{\\text{SL}}(\\theta; s_{\\text{obs}}) = \\ln(1) - \\ln\\left((2\\pi)^{d/2} \\det(\\widehat{\\Sigma}_{\\theta})^{1/2}\\right) - \\frac{1}{2}(s_{\\text{obs}}-\\widehat{\\mu}_{\\theta})^{\\top}\\widehat{\\Sigma}_{\\theta}^{-1}(s_{\\text{obs}}-\\widehat{\\mu}_{\\theta})\n$$\nSince $\\ln(1) = 0$ and using the property $\\ln(ab) = \\ln(a) + \\ln(b)$, the expression simplifies to:\n$$\n\\widetilde{\\ell}_{\\text{SL}}(\\theta; s_{\\text{obs}}) = -\\left( \\ln\\left((2\\pi)^{d/2}\\right) + \\ln\\left(\\det(\\widehat{\\Sigma}_{\\theta})^{1/2}\\right) \\right) - \\frac{1}{2}(s_{\\text{obs}}-\\widehat{\\mu}_{\\theta})^{\\top}\\widehat{\\Sigma}_{\\theta}^{-1}(s_{\\text{obs}}-\\widehat{\\mu}_{\\theta})\n$$\nUsing the property $\\ln(a^b) = b\\ln(a)$, we arrive at the final closed-form expression:\n$$\n\\widetilde{\\ell}_{\\text{SL}}(\\theta; s_{\\text{obs}}) = -\\frac{d}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln(\\det(\\widehat{\\Sigma}_{\\theta})) - \\frac{1}{2}(s_{\\text{obs}}-\\widehat{\\mu}_{\\theta})^{\\top}\\widehat{\\Sigma}_{\\theta}^{-1}(s_{\\text{obs}}-\\widehat{\\mu}_{\\theta})\n$$\nThis expression defines the synthetic log-likelihood in terms of the data dimension $d$, the sample mean $\\widehat{\\mu}_{\\theta}$, and the sample covariance matrix $\\widehat{\\Sigma}_{\\theta}$.\n\n### Task 2: Numerical Evaluation\n\nWe are given the following data:\n- Dimension $d=2$\n- Number of simulations $S=5$\n- Simulated summary vectors:\n$$\ns^{(1)}(\\theta) = \\begin{pmatrix} 0.8 \\\\ 1.7 \\end{pmatrix}, \\quad s^{(2)}(\\theta) = \\begin{pmatrix} 1.2 \\\\ 2.3 \\end{pmatrix}, \\quad s^{(3)}(\\theta) = \\begin{pmatrix} 1.1 \\\\ 2.1 \\end{pmatrix}, \\quad s^{(4)}(\\theta) = \\begin{pmatrix} 0.9 \\\\ 1.9 \\end{pmatrix}, \\quad s^{(5)}(\\theta) = \\begin{pmatrix} 1.0 \\\\ 2.0 \\end{pmatrix}\n$$\n- Observed summary vector:\n$$\ns_{\\text{obs}} = \\begin{pmatrix} 1.05 \\\\ 2.15 \\end{pmatrix}\n$$\n\n**Step 1: Compute the sample mean $\\widehat{\\mu}_{\\theta}$**\n$$\n\\widehat{\\mu}_{\\theta} = \\frac{1}{S} \\sum_{r=1}^{S} s^{(r)}(\\theta) = \\frac{1}{5} \\left( \\begin{pmatrix} 0.8 \\\\ 1.7 \\end{pmatrix} + \\begin{pmatrix} 1.2 \\\\ 2.3 \\end{pmatrix} + \\begin{pmatrix} 1.1 \\\\ 2.1 \\end{pmatrix} + \\begin{pmatrix} 0.9 \\\\ 1.9 \\end{pmatrix} + \\begin{pmatrix} 1.0 \\\\ 2.0 \\end{pmatrix} \\right)\n$$\n$$\n\\widehat{\\mu}_{\\theta} = \\frac{1}{5} \\begin{pmatrix} 0.8+1.2+1.1+0.9+1.0 \\\\ 1.7+2.3+2.1+1.9+2.0 \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} 5.0 \\\\ 10.0 \\end{pmatrix} = \\begin{pmatrix} 1.0 \\\\ 2.0 \\end{pmatrix}\n$$\n\n**Step 2: Compute the sample covariance matrix $\\widehat{\\Sigma}_{\\theta}$**\nFirst, we compute the centered vectors $s^{(r)}(\\theta) - \\widehat{\\mu}_{\\theta}$:\n$s^{(1)}-\\widehat{\\mu}_{\\theta} = \\begin{pmatrix} -0.2 \\\\ -0.3 \\end{pmatrix}$, $s^{(2)}-\\widehat{\\mu}_{\\theta} = \\begin{pmatrix} 0.2 \\\\ 0.3 \\end{pmatrix}$, $s^{(3)}-\\widehat{\\mu}_{\\theta} = \\begin{pmatrix} 0.1 \\\\ 0.1 \\end{pmatrix}$, $s^{(4)}-\\widehat{\\mu}_{\\theta} = \\begin{pmatrix} -0.1 \\\\ -0.1 \\end{pmatrix}$, $s^{(5)}-\\widehat{\\mu}_{\\theta} = \\begin{pmatrix} 0.0 \\\\ 0.0 \\end{pmatrix}$.\nNow, we compute the sum of the outer products:\n$$\n\\sum_{r=1}^{5} (s^{(r)}-\\widehat{\\mu}_{\\theta})(s^{(r)}-\\widehat{\\mu}_{\\theta})^{\\top} =\n\\begin{pmatrix} 0.04  0.06 \\\\ 0.06  0.09 \\end{pmatrix} +\n\\begin{pmatrix} 0.04  0.06 \\\\ 0.06  0.09 \\end{pmatrix} +\n\\begin{pmatrix} 0.01  0.01 \\\\ 0.01  0.01 \\end{pmatrix} +\n\\begin{pmatrix} 0.01  0.01 \\\\ 0.01  0.01 \\end{pmatrix} +\n\\begin{pmatrix} 0.00  0.00 \\\\ 0.00  0.00 \\end{pmatrix}\n= \\begin{pmatrix} 0.10  0.14 \\\\ 0.14  0.20 \\end{pmatrix}\n$$\nThe unbiased sample covariance is:\n$$\n\\widehat{\\Sigma}_{\\theta} = \\frac{1}{S-1} \\sum_{r=1}^{S} (s^{(r)}-\\widehat{\\mu}_{\\theta})(s^{(r)}-\\widehat{\\mu}_{\\theta})^{\\top} = \\frac{1}{4} \\begin{pmatrix} 0.10  0.14 \\\\ 0.14  0.20 \\end{pmatrix} = \\begin{pmatrix} 0.025  0.035 \\\\ 0.035  0.050 \\end{pmatrix}\n$$\n\n**Step 3: Compute the terms of the log-likelihood**\nThe log-likelihood expression to evaluate is:\n$$\n\\widetilde{\\ell}_{\\text{SL}} = -\\frac{2}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln(\\det(\\widehat{\\Sigma}_{\\theta})) - \\frac{1}{2}(s_{\\text{obs}}-\\widehat{\\mu}_{\\theta})^{\\top}\\widehat{\\Sigma}_{\\theta}^{-1}(s_{\\text{obs}}-\\widehat{\\mu}_{\\theta})\n$$\nTerm 1: Constant term\n$$\n-\\ln(2\\pi) \\approx -1.837877\n$$\nTerm 2: Log-determinant term\n$$\n\\det(\\widehat{\\Sigma}_{\\theta}) = (0.025)(0.050) - (0.035)^2 = 0.00125 - 0.001225 = 0.000025 = 2.5 \\times 10^{-5}\n$$\n$$\n-\\frac{1}{2}\\ln(\\det(\\widehat{\\Sigma}_{\\theta})) = -\\frac{1}{2}\\ln(2.5 \\times 10^{-5}) \\approx -\\frac{1}{2}(-10.596635) \\approx 5.298317\n$$\nTerm 3: Mahalanobis distance term\nFirst, compute the inverse covariance matrix $\\widehat{\\Sigma}_{\\theta}^{-1}$:\n$$\n\\widehat{\\Sigma}_{\\theta}^{-1} = \\frac{1}{\\det(\\widehat{\\Sigma}_{\\theta})} \\begin{pmatrix} 0.050  -0.035 \\\\ -0.035  0.025 \\end{pmatrix} = \\frac{1}{0.000025} \\begin{pmatrix} 0.050  -0.035 \\\\ -0.035  0.025 \\end{pmatrix} = 40000 \\begin{pmatrix} 0.050  -0.035 \\\\ -0.035  0.025 \\end{pmatrix} = \\begin{pmatrix} 2000  -1400 \\\\ -1400  1000 \\end{pmatrix}\n$$\nNext, compute the deviation vector $s_{\\text{obs}}-\\widehat{\\mu}_{\\theta}$:\n$$\n\\Delta s = s_{\\text{obs}}-\\widehat{\\mu}_{\\theta} = \\begin{pmatrix} 1.05 \\\\ 2.15 \\end{pmatrix} - \\begin{pmatrix} 1.0 \\\\ 2.0 \\end{pmatrix} = \\begin{pmatrix} 0.05 \\\\ 0.15 \\end{pmatrix}\n$$\nNow, compute the quadratic form $(\\Delta s)^{\\top}\\widehat{\\Sigma}_{\\theta}^{-1}(\\Delta s)$:\n$$\n(\\Delta s)^{\\top}\\widehat{\\Sigma}_{\\theta}^{-1}(\\Delta s) = \\begin{pmatrix} 0.05  0.15 \\end{pmatrix} \\begin{pmatrix} 2000  -1400 \\\\ -1400  1000 \\end{pmatrix} \\begin{pmatrix} 0.05 \\\\ 0.15 \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} 0.05(2000) + 0.15(-1400)  0.05(-1400) + 0.15(1000) \\end{pmatrix} \\begin{pmatrix} 0.05 \\\\ 0.15 \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} 100 - 210  -70 + 150 \\end{pmatrix} \\begin{pmatrix} 0.05 \\\\ 0.15 \\end{pmatrix} = \\begin{pmatrix} -110  80 \\end{pmatrix} \\begin{pmatrix} 0.05 \\\\ 0.15 \\end{pmatrix}\n$$\n$$\n= (-110)(0.05) + (80)(0.15) = -5.5 + 12.0 = 6.5\n$$\nThe third term is $-\\frac{1}{2}(6.5) = -3.25$.\n\n**Step 4: Sum the terms**\n$$\n\\widetilde{\\ell}_{\\text{SL}}(\\theta; s_{\\text{obs}}) \\approx -1.837877 + 5.298317 - 3.25 = 0.21044\n$$\nRounding the result to four significant figures gives $0.2104$.",
            "answer": "$$\n\\boxed{0.2104}\n$$"
        }
    ]
}