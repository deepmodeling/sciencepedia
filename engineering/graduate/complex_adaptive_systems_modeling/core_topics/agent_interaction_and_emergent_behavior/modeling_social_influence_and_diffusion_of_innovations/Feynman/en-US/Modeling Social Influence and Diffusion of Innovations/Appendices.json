{
    "hands_on_practices": [
        {
            "introduction": "Understanding how a simple innovation can spread to a macroscopic fraction of a population is a central question in diffusion modeling. This practice explores this phenomenon on networks generated by the Configuration Model, where node degrees are drawn from a specified distribution $P(k)$. You will use the powerful generating function formalism to derive the final size of a cascade, which is equivalent to the size of the giant connected component (GCC), linking a microscopic network property to a macroscopic outcome. ",
            "id": "4129714",
            "problem": "Consider a very large social network generated by the Configuration Model (CM), in which each node’s degree is an independent draw from a given degree distribution $P(k)$. Assume the network is locally tree-like in the large-size limit. A simple contagion represents an innovation that adopts deterministically along each social tie once exposed, with transmission probability equal to $1$ and with an infinitesimal, randomly scattered initial seed such that any macroscopic adoption arises only from the network’s connectivity structure. The asymptotic fraction of adopters is therefore equal to the fraction of nodes in the giant connected component of the underlying CM network.\n\nLet the degree distribution be supported on the set $\\{0,1,2,5,10\\}$ with probabilities\n$P(0)=0.05$, $P(1)=0.15$, $P(2)=0.25$, $P(5)=0.30$, and $P(10)=0.25$. Define the node-degree generating function (generating function (GF)) $G_{0}(x)=\\sum_{k=0}^{\\infty}P(k)x^{k}$ and the excess-degree generating function $G_{1}(x)=\\sum_{k=1}^{\\infty}\\frac{kP(k)}{\\langle k\\rangle}x^{k-1}$, where $\\langle k\\rangle=\\sum_{k}kP(k)$ is the mean degree.\n\nStarting from first principles that are standard for CM networks and locally tree-like spreading (probability conservation, independence across branches at tree-like neighborhoods, and the equivalence to a Galton–Watson branching process for neighborhood exploration), derive the self-consistency relation for the probability that following a uniformly random edge enters only a finite subtree, and the corresponding expression for the asymptotic adopter fraction in terms of $G_{0}$ and $G_{1}$. Then compute the numerical value of the asymptotic adopter fraction for the given $P(k)$. Round your final answer to four significant figures. No physical units are required for the final answer.",
            "solution": "The asymptotic fraction of adopters in this model is equivalent to the relative size of the giant connected component (GCC) of the network. We will first derive the general expressions for the GCC size using generating functions and then apply them to the specific degree distribution provided.\n\n### Derivation of the Self-Consistency Equations\n\nLet $S$ be the fraction of nodes in the giant connected component (GCC). It is often easier to first calculate the fraction of nodes *not* in the GCC, which we denote by $u$. Then, $S = 1 - u$. A node is not in the GCC if it belongs to a finite component.\n\nWe introduce two probabilities:\n1.  $u$: The probability that a randomly chosen node belongs to a finite component.\n2.  $v$: The probability that following a randomly chosen edge leads to a node that belongs to a finite component.\n\nThe assumption that the network is large and locally tree-like allows us to model the exploration of the network as a Galton-Watson branching process.\n\nFirst, let's derive the self-consistency relation for $v$. Consider a randomly chosen edge. It leads to some node, let's call it node $A$. The probability that this edge leads to a node of degree $k$ is given by $\\frac{k P(k)}{\\langle k \\rangle}$. For node $A$ to be part of a finite component when viewed from our arrival edge, all of its $k-1$ other sub-branches must also be finite. The probability that any one of these other edges leads to a finite component is, by definition, $v$. Due to the local tree-like assumption, the fates of these $k-1$ branches are independent. Thus, the probability that all $k-1$ branches are finite is $v^{k-1}$.\n\nTo get the total probability $v$, we must average over all possible degrees $k$ of the destination node $A$:\n$$v = \\sum_{k=1}^{\\infty} \\left( \\frac{k P(k)}{\\langle k \\rangle} \\right) v^{k-1}$$\nThe term in the summation is exactly the definition of the excess-degree generating function, $G_1(x)$, evaluated at $x=v$. This gives the first self-consistency relation:\n$$v = G_1(v)$$\n\nNext, we derive the expression for $u$. A randomly chosen node belongs to a finite component if and only if all of its edges lead into finite components. A randomly chosen node has degree $k$ with probability $P(k)$. If it has degree $k$, it has $k$ edges. The probability that a single one of these edges leads to a finite component is $v$. Since the branches are independent, the probability that all $k$ edges lead to finite components is $v^k$.\n\nTo find the total probability $u$, we average this over all possible degrees $k$ of the initial node:\n$$u = \\sum_{k=0}^{\\infty} P(k) v^k$$\nThis sum is the definition of the node-degree generating function, $G_0(x)$, evaluated at $x=v$. So, we have:\n$$u = G_0(v)$$\n\nCombining these results, the fraction of adopters, $S$, which is the size of the GCC, is given by:\n$$S = 1 - u = 1 - G_0(v)$$\nwhere $v$ is the smallest non-negative solution to the equation $v = G_1(v)$. A solution $v=1$ always exists. A non-trivial solution $v < 1$ exists if and only if a GCC exists, which is guaranteed if $G_1'(1) > 1$.\n\n### Numerical Computation\n\n**1. Calculate Mean Degree and Generating Functions**\nThe degree distribution is $P(0)=0.05$, $P(1)=0.15$, $P(2)=0.25$, $P(5)=0.30$, and $P(10)=0.25$.\nThe mean degree $\\langle k \\rangle$ is:\n$$\\langle k \\rangle = \\sum_{k} k P(k) = (0)(0.05) + (1)(0.15) + (2)(0.25) + (5)(0.30) + (10)(0.25)$$\n$$\\langle k \\rangle = 0 + 0.15 + 0.50 + 1.50 + 2.50 = 4.65$$\nThe node-degree generating function is:\n$$G_0(x) = 0.05 + 0.15x + 0.25x^2 + 0.30x^5 + 0.25x^{10}$$\nThe excess-degree generating function is:\n$$G_1(x) = \\frac{1}{\\langle k \\rangle} \\sum_{k=1}^{\\infty} k P(k) x^{k-1}$$\n$$G_1(x) = \\frac{1}{4.65} \\left( (1)(0.15)x^0 + (2)(0.25)x^1 + (5)(0.30)x^4 + (10)(0.25)x^9 \\right)$$\n$$G_1(x) = \\frac{1}{4.65} \\left( 0.15 + 0.5x + 1.5x^4 + 2.5x^9 \\right)$$\n\n**2. Solve for v**\nWe must find the smallest non-negative root of $v = G_1(v)$. We can solve this by fixed-point iteration, $v_{n+1} = G_1(v_n)$, starting with $v_0 = 0$.\n$v_0 = 0$\n$v_1 = G_1(v_0) = \\frac{1}{4.65} (0.15) \\approx 0.03225806$\n$v_2 = G_1(v_1) = \\frac{1}{4.65} \\left( 0.15 + 0.5(0.03225806) + 1.5(0.03225806)^4 + \\dots \\right) \\approx 0.03572669$\n$v_3 = G_1(v_2) = \\frac{1}{4.65} \\left( 0.15 + 0.5(0.03572669) + \\dots \\right) \\approx 0.03610029$\n$v_4 = G_1(v_3) \\approx 0.03614002$\n$v_5 = G_1(v_4) \\approx 0.03614449$\n$v_6 = G_1(v_5) \\approx 0.03614499$\n$v_7 = G_1(v_6) \\approx 0.03614505$\nThe iteration converges rapidly. Let's take $v \\approx 0.03614505$.\n\n**3. Calculate Adopter Fraction S**\nNow we compute the adopter fraction $S = 1 - G_0(v)$.\n$$S = 1 - (0.05 + 0.15v + 0.25v^2 + 0.30v^5 + 0.25v^{10})$$\nUsing $v \\approx 0.03614505$:\n- $0.15v \\approx 0.15 \\times 0.03614505 = 0.0054217575$\n- $0.25v^2 \\approx 0.25 \\times (0.03614505)^2 = 0.25 \\times 0.0013064646 \\approx 0.0003266162$\n- $0.30v^5 \\approx 0.30 \\times (0.03614505)^5 = 0.30 \\times 6.104 \\times 10^{-8} \\approx 1.831 \\times 10^{-8}$\nThe term with $v^{10}$ is negligibly small.\n$$G_0(v) \\approx 0.05 + 0.0054217575 + 0.0003266162 + 1.831 \\times 10^{-8} \\approx 0.05574839$$\n$$S = 1 - G_0(v) \\approx 1 - 0.05574839 = 0.94425161$$\nRounding the result to four significant figures gives $0.9443$.",
            "answer": "$$\\boxed{0.9443}$$"
        },
        {
            "introduction": "While degree distribution is a powerful predictor for simple contagions, many social phenomena, from adopting costly technologies to joining social movements, behave as complex contagions requiring reinforcement from multiple sources. This exercise demonstrates that network structure beyond the degree sequence, specifically local clustering, is critical for such processes. By comparing two networks with identical degrees but different numbers of triangles, you will develop a sharp intuition for why complex contagions are highly sensitive to social reinforcement embedded in clustered ties. ",
            "id": "4129695",
            "problem": "Consider two simple, undirected graphs that both have the same degree sequence but differ in local clustering. The population consists of $12$ agents, each represented by a node, and each agent has exactly $4$ neighbors. Adoption of an innovation proceeds via a deterministic threshold rule: at discrete time $t=0,1,2,\\dots$, a node adopts permanently at time $t+1$ if and only if at least a fraction $\\phi$ of its neighbors had adopted by time $t$. Assume $1/4<\\phi\\le 1/2$, so that at least $2$ adopted neighbors are required for adoption when the degree is $4$. The initial seed consists of exactly $2$ adjacent nodes chosen uniformly at random from the set of edges.\n\nDefine the two networks explicitly:\n\n- High-clustering network $\\mathcal{H}$: Nodes are labeled $0,1,\\dots,11$ and edges are between $i$ and $(i\\pm 1)\\bmod 12$, and between $i$ and $(i\\pm 2)\\bmod 12$. Each node has degree $4$. Because neighbors-of-neighbors are often themselves neighbors, this graph contains many triangles.\n\n- Low-clustering network $\\mathcal{L}$: Partition the $12$ nodes into two sets $L=\\{L_0,L_1,\\dots,L_5\\}$ and $R=\\{R_0,R_1,\\dots,R_5\\}$. For each $i\\in\\{0,1,\\dots,5\\}$, include edges from $L_i$ to $R_i$, $R_{(i+1)\\bmod 6}$, $R_{(i+2)\\bmod 6}$, and $R_{(i+3)\\bmod 6}$. Each node has degree $4$, and the graph is bipartite, so there are no triangles.\n\nUsing only fundamental definitions of the threshold adoption rule and basic consequences of graph structure (e.g., the absence of triangles in a bipartite graph), reason about the qualitative difference in cascade probabilities under the specified regime $1/4<\\phi\\le 1/2$ and adjacent-pair seeding. Which of the following statements are correct?\n\nA. For $1/4<\\phi\\le 1/2$, an adjacent seed pair in $\\mathcal{H}$ triggers a global cascade with probability $1$, whereas in $\\mathcal{L}$ the process stalls immediately and the probability of a global cascade is $0$.\n\nB. Because both networks have identical degree sequences, their cascade probabilities must be identical for any $\\phi$ and any seeding.\n\nC. For $1/4<\\phi\\le 1/2$, an adjacent seed pair in $\\mathcal{L}$ yields a higher cascade probability than in $\\mathcal{H}$ because lower clustering increases exposure diversity.\n\nD. For $1/4<\\phi\\le 1/2$, an adjacent seed pair cannot trigger a cascade on either network because no nonseed node has at least $2$ active neighbors at time $t=0$.",
            "solution": "The problem requires comparing cascade dynamics on two networks with the same degree sequence but different clustering, under a complex contagion threshold rule. The key is to determine how local network structure (specifically, the presence or absence of triangles) affects the start of a cascade.\n\nThe adoption threshold is $\\phi$, where $1/4 < \\phi \\le 1/2$. For a node with degree $k=4$, the number of adopted neighbors required to trigger its own adoption is $\\lceil k\\phi \\rceil = \\lceil 4\\phi \\rceil$. Given the range of $\\phi$, we have $1 < 4\\phi \\le 2$, which means an inactive node must have at least $2$ adopted neighbors to adopt.\n\nThe process starts at time $t=0$ with a seed of two adjacent nodes, let's call them $u$ and $v$. At time $t=1$, we examine all other currently inactive nodes. For a cascade to begin, at least one inactive node, say $w$, must adopt. According to the rule, node $w$ must have at least $2$ neighbors that were adopted by time $t=0$. Since the only adopted nodes at $t=0$ are $u$ and $v$, node $w$ must be a neighbor of both $u$ and $v$.\n\nThe condition for the cascade to propagate beyond the initial seed is the existence of a common neighbor to the seed nodes $u$ and $v$. If such a node $w$ exists, then the edges $(u,v)$, $(v,w)$, and $(w,u)$ must all be present in the graph. This set of three nodes and three edges forms a triangle, or a $3$-cycle.\n\nLet's analyze the two networks in this context.\n\n**Analysis of Network $\\mathcal{L}$ (Low-clustering):**\nThe network $\\mathcal{L}$ is explicitly constructed to be bipartite. A fundamental property of bipartite graphs is that they do not contain any odd-length cycles. As a triangle is a cycle of length $3$, network $\\mathcal{L}$ contains no triangles.\n\nTherefore, for any adjacent seed pair $(u,v)$ in $\\mathcal{L}$, there cannot be a common neighbor $w$. If such a $w$ existed, $\\{u,v,w\\}$ would form a triangle, which is impossible in $\\mathcal{L}$. This means that at $t=0$, no inactive node has more than one neighbor in the adopted set $\\{u,v\\}$. Since the threshold for adoption is $2$, no new node will adopt at $t=1$. The process stalls immediately. The probability of a global cascade is therefore $0$.\n\n**Analysis of Network $\\mathcal{H}$ (High-clustering):**\nThe network $\\mathcal{H}$ is constructed on nodes $\\{0, 1, \\dots, 11\\}$ with edges connecting node $i$ to $(i\\pm 1)\\bmod 12$ and $(i\\pm 2)\\bmod 12$. We must verify that for any adjacent seed pair, at least one common neighbor exists. Edges in this graph can be classified by the distance between their endpoints: distance-$1$ edges like $(i, i+1)$ and distance-$2$ edges like $(i, i+2)$.\n\n1.  **Seed is a distance-$1$ edge**: Let the seed be the adjacent pair $(0,1)$.\n    - Neighbors of $0$: $N(0) = \\{11, 1, 2, 10\\}$.\n    - Neighbors of $1$: $N(1) = \\{0, 2, 3, 11\\}$.\n    - The set of common neighbors is $N(0) \\cap N(1) = \\{2, 11\\}$. Both nodes $2$ and $11$ have $2$ adopted neighbors and will adopt at $t=1$, initiating a cascade.\n\n2.  **Seed is a distance-$2$ edge**: Let the seed be the adjacent pair $(0,2)$.\n    - Neighbors of $0$: $N(0) = \\{11, 1, 2, 10\\}$.\n    - Neighbors of $2$: $N(2) = \\{0, 1, 3, 4\\}$.\n    - The set of common neighbors is $N(0) \\cap N(2) = \\{1\\}$. Node $1$ has $2$ adopted neighbors and will adopt at $t=1$, initiating a cascade.\n\nSince the graph $\\mathcal{H}$ is edge-transitive and any edge chosen as a seed has common neighbors, any seed pair will trigger a cascade. The probability of a global cascade in $\\mathcal{H}$ is $1$.\n\n**Option-by-Option Analysis**\n\n**A. For $1/4<\\phi\\le 1/2$, an adjacent seed pair in $\\mathcal{H}$ triggers a global cascade with probability $1$, whereas in $\\mathcal{L}$ the process stalls immediately and the probability of a global cascade is $0$.**\nThis statement accurately summarizes our derivation. In $\\mathcal{H}$, the high number of triangles ensures a cascade starts. In $\\mathcal{L}$, the absence of triangles prevents it. This statement is **Correct**.\n\n**B. Because both networks have identical degree sequences, their cascade probabilities must be identical for any $\\phi$ and any seeding.**\nThis is incorrect. Our analysis shows that higher-order structures (clustering) beyond the degree sequence are crucial for complex contagion dynamics.\n\n**C. For $1/4<\\phi\\le 1/2$, an adjacent seed pair in $\\mathcal{L}$ yields a higher cascade probability than in $\\mathcal{H}$ because lower clustering increases exposure diversity.**\nThis is incorrect. The cascade probability is $0$ in $\\mathcal{L}$ and $1$ in $\\mathcal{H}$. The justification (exposure diversity) is relevant for simple, not complex, contagions.\n\n**D. For $1/4<\\phi\\le 1/2$, an adjacent seed pair cannot trigger a cascade on either network because no nonseed node has at least $2$ active neighbors at time $t=0$.**\nThis is incorrect. It is true for $\\mathcal{L}$, but false for $\\mathcal{H}$, where common neighbors to the seed pair always exist.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Static network models provide a simplified snapshot, but real-world interactions unfold over time. This practice introduces the essential concept of temporal networks, where connections are timestamped events, fundamentally constraining the pathways of diffusion. You will develop and implement an algorithm to identify all nodes reachable from a seed through 'time-respecting paths'—causally valid sequences of contacts—providing hands-on experience with a foundational tool for analyzing dynamic social systems. ",
            "id": "4129747",
            "problem": "Consider a temporal network representing the flow of social influence for diffusion of an innovation. The network is specified as a finite list of timestamped directed contacts, each contact being a triple $(i,j,t)$ that denotes that agent $i$ influences agent $j$ at absolute time $t$. Time is measured in seconds, and contacts occur at discrete times. Assume instantaneous transmission along a contact, negligible processing delays, and that influence cannot propagate backward in time. The diffusion process is initiated by a single seed agent $s$ at time $0$ that is already influenced at time $0$.\n\nDefine a time-respecting path from $s$ to a node $v$ as a finite sequence of contacts $((v_0,v_1,t_1), (v_1,v_2,t_2), \\ldots, (v_{k-1},v_k,t_k))$ with $v_0 = s$, $v_k = v$, $t_1 \\le t_2 \\le \\cdots \\le t_k$, and $t_1 \\ge 0$. A node $v$ is temporally reachable from $s$ within the window $[0,T]$ if there exists at least one time-respecting path from $s$ to $v$ whose last timestamp $t_k$ satisfies $t_k \\le T$. The temporal reachability of the seed $s$ is the set $R(T)$ of all nodes $v \\neq s$ that are temporally reachable within $[0,T]$.\n\nStarting from the fundamental principle of causality and time-ordering in temporal networks, and using only the assumption that influence can traverse a contact $(i,j,t)$ if and only if agent $i$ is already influenced by time $t$, derive an algorithm that computes $R(T)$ from a given contact list and seed $s$ for any finite $T \\ge 0$. The algorithm should produce the cardinality $|R(T)|$, an integer count of temporally reachable nodes excluding the seed. The derivation must not rely on shortcut formulas and must justify correctness from first principles.\n\nYour program must implement this algorithm and apply it to the following test suite (times are in seconds):\n\n- Test case $1$: contacts $[(0,1,1),(1,2,2),(2,3,3)]$, seed $s=0$, window $T=3$. Expected behavior: a straightforward chain with strictly increasing times.\n- Test case $2$: contacts $[(0,1,2),(1,2,2)]$, seed $s=0$, window $T=2$. Expected behavior: equality at the boundary $t=T$ is allowed.\n- Test case $3$: contacts $[(0,1,1),(1,2,1),(2,3,1)]$, seed $s=0$, window $T=1$. Expected behavior: simultaneous timestamps allow instantaneous chaining with non-decreasing times.\n- Test case $4$: contacts $[(1,0,1)]$, seed $s=0$, window $T=10$. Expected behavior: reversed direction prevents outward diffusion from the seed.\n- Test case $5$: contacts $[(0,1,5),(1,0,6),(1,2,7),(0,2,10)]$, seed $s=0$, window $T=8$. Expected behavior: cycles and multiple paths; only those concluding by $T$ contribute.\n\nEach test case is defined solely by the list of contacts, the seed $s$, and the window $T$. The required output is a single line containing a comma-separated list of the integer cardinalities $|R(T)|$ for the test cases in the order listed above, enclosed in square brackets. For example, the program must output a string of the form $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5]$.\n\nTime values are in seconds; the output counts are unitless integers. No angles or percentages are involved. The program must be self-contained and require no input. The final output line must contain only the specified list format without any additional text.",
            "solution": "The problem asks for an algorithm to compute the size of the set of temporally reachable nodes, $|R(T)|$, from a seed node $s$ within a time window $[0, T]$. The derivation must be based on the fundamental principles of causality and time-ordering.\n\nThe core principle is causality: an agent $j$ can be influenced by an agent $i$ via a contact $(i,j,t)$ only if agent $i$ is itself already influenced at or before time $t$. The goal is to find all nodes that can be reached from the seed $s$ through sequences of such causally-ordered events. This is equivalent to finding the earliest possible time that each node can be influenced.\n\nLet $\\tau(v)$ be the earliest time at which agent $v$ can become influenced. The problem specifies that the seed agent $s$ is influenced at time $0$, so we have the initial condition:\n$$ \\tau(s) = 0 $$\nFor any other agent $v \\neq s$, it is initially not influenced. We can represent this state by setting its earliest influence time to infinity:\n$$ \\tau(v) = \\infty \\quad \\forall v \\neq s $$\n\nThe diffusion process unfolds as a series of discrete events, which are the contacts. A time-respecting path is defined by a sequence of contacts with non-decreasing timestamps. This non-decreasing time constraint is the mathematical formalization of causality and time-ordering. An algorithm that respects this structure will be correct.\n\nThe most direct way to model the flow of time is to process events in the order they occur. Therefore, the first step of our algorithm must be to sort the list of all contacts, $C$, by their timestamp $t$ in non-decreasing order. Let this sorted list be $C_{\\text{sorted}}$.\n\nWe can now iterate through $C_{\\text{sorted}}$ and update the earliest influence times, $\\tau(v)$, for all nodes. For each contact $(i, j, t) \\in C_{\\text{sorted}}$, we apply the causal condition: if the source agent $i$ has been influenced at or before time $t$, i.e., if $\\tau(i) \\le t$, then influence can propagate to agent $j$. Since transmission is instantaneous, agent $j$ can become influenced at time $t$. This provides a new potential influence time for $j$. Because we seek the *earliest* such time, we must update $\\tau(j)$ only if this new time $t$ is smaller than the current known value of $\\tau(j)$. This leads to the update rule:\n$$ \\text{If } \\tau(i) \\le t, \\text{ then } \\tau(j) := \\min(\\tau(j), t) $$\n\nA single pass through the time-sorted contacts is sufficient to find the earliest influence time for all nodes. Because our algorithm processes contacts in the same non-decreasing temporal order as any valid time-respecting path, it is guaranteed to correctly propagate influence. By induction, when processing a contact that is part of a valid path, the source node's earliest influence time will have already been correctly computed by prior contacts in the path.\n\nAfter iterating through all contacts in $C_{\\text{sorted}}$, the array or map of $\\tau$ values will hold the earliest possible influence time for every node reachable from $s$.\n\nThe final step is to compute the desired quantity, $|R(T)|$. The set $R(T)$ consists of all nodes $v \\neq s$ that are temporally reachable within the window $[0, T]$. A node $v$ is reachable within this window if and only if its earliest influence time is less than or equal to $T$. Therefore, we count the number of nodes $v$ that satisfy the two conditions: $v \\neq s$ and $\\tau(v) \\le T$.\n\nThe complete algorithm is as follows:\n\n1.  Gather the set of all unique agent identifiers, $V$, from the contact list.\n2.  Initialize a data structure, `influence_times`, to store $\\tau(v)$ for each $v \\in V$. Set $\\tau(s) = 0$ and $\\tau(v) = \\infty$ for all $v \\in V, v \\neq s$.\n3.  Sort the contact list $C$ by timestamp in non-decreasing order to get $C_{\\text{sorted}}$.\n4.  For each contact $(i, j, t)$ in $C_{\\text{sorted}}$:\n    a. Check if the source agent $i$ could have been influenced by time $t$: $\\tau(i) \\le t$.\n    b. If so, update the target agent's earliest influence time: $\\tau(j) = \\min(\\tau(j), t)$.\n5.  After the loop, initialize a counter `reachable_count` to $0$.\n6.  Iterate through all agents $v \\in V$:\n    a. If $v \\neq s$ and $\\tau(v) \\le T$, increment `reachable_count`.\n7.  The final result is `reachable_count`.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the temporal reachability problem for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"contacts\": [(0, 1, 1), (1, 2, 2), (2, 3, 3)],\n            \"s\": 0,\n            \"T\": 3\n        },\n        {\n            \"contacts\": [(0, 1, 2), (1, 2, 2)],\n            \"s\": 0,\n            \"T\": 2\n        },\n        {\n            \"contacts\": [(0, 1, 1), (1, 2, 1), (2, 3, 1)],\n            \"s\": 0,\n            \"T\": 1\n        },\n        {\n            \"contacts\": [(1, 0, 1)],\n            \"s\": 0,\n            \"T\": 10\n        },\n        {\n            \"contacts\": [(0, 1, 5), (1, 0, 6), (1, 2, 7), (0, 2, 10)],\n            \"s\": 0,\n            \"T\": 8\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        contacts = case[\"contacts\"]\n        s = case[\"s\"]\n        T = case[\"T\"]\n\n        # 1. Gather all unique nodes from the contact list.\n        nodes = set()\n        for i, j, t in contacts:\n            nodes.add(i)\n            nodes.add(j)\n        if not nodes:\n            results.append(0)\n            continue\n        nodes.add(s) # Ensure the seed node is included.\n\n        # 2. Initialize influence times.\n        # tau[v] stores the earliest time agent v can be influenced.\n        # Initialize seed at time 0, others at infinity.\n        influence_times = {node: np.inf for node in nodes}\n        influence_times[s] = 0\n\n        # 3. Sort contacts by timestamp in non-decreasing order.\n        # The key to this algorithm, processing events as they occur in time.\n        sorted_contacts = sorted(contacts, key=lambda x: x[2])\n\n        # 4. Iterate through sorted contacts and propagate influence.\n        for i, j, t in sorted_contacts:\n            # Causal condition: If agent 'i' was influenced at or before time 't',\n            # influence can propagate.\n            # We use .get() to be safe, though 'i' should always be in the dict.\n            if influence_times.get(i, np.inf) = t:\n                # Update agent 'j's influence time if this path is faster.\n                current_time_j = influence_times.get(j, np.inf)\n                influence_times[j] = min(current_time_j, t)\n        \n        # 5. Count reachable nodes within the time window T.\n        # According to the problem, the set R(T) excludes the seed s.\n        reachable_count = 0\n        for node, time in influence_times.items():\n            if node != s and time = T:\n                reachable_count += 1\n        \n        results.append(reachable_count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}