{
    "hands_on_practices": [
        {
            "introduction": "本练习是理解大规模网络扩散的基础。它将网络的宏观统计特性（即度分布）与其全局连通性直接联系起来，并借此推断简单传染过程可能达到的最大范围。 在这个实践中，我们将运用生成函数这一强大的数学工具，从第一性原理出发，推导出巨型连通组件的大小，这是衡量创新能否实现广泛传播的关键指标。",
            "id": "4129714",
            "problem": "考虑一个由组态模型（CM）生成的非常大的社交网络，其中每个节点的度都是从给定的度分布 $P(k)$ 中独立抽取的。假设网络在巨大规模的极限下是局部树状的。一种简单传染代表了一项创新，一旦暴露，它就会沿着每条社交关系以等于 $1$ 的传播概率确定性地采纳，并伴有无穷小的、随机散布的初始种子，因此任何宏观规模的采纳都仅源于网络的连通性结构。因此，采纳者的渐近比例等于底层组态模型网络中巨连通分量中节点的比例。\n\n设度分布支持在集合 $\\{0,1,2,5,10\\}$ 上，其概率为\n$P(0)=0.05$、$P(1)=0.15$、$P(2)=0.25$、$P(5)=0.30$ 和 $P(10)=0.25$。定义节点度生成函数 (GF) $G_{0}(x)=\\sum_{k=0}^{\\infty}P(k)x^{k}$ 和剩余度生成函数 $G_{1}(x)=\\sum_{k=1}^{\\infty}\\frac{kP(k)}{\\langle k\\rangle}x^{k-1}$，其中 $\\langle k\\rangle=\\sum_{k}kP(k)$ 是平均度。\n\n从组态模型网络和局部树状传播的标准基本原理（概率守恒、树状邻域中各分支的独立性，以及邻域探索等效于一个高尔顿-沃森分支过程）出发，推导出一个沿着均匀随机选择的边仅进入有限子树的概率的自洽关系，以及用 $G_{0}$ 和 $G_{1}$ 表示的采纳者渐近比例的相应表达式。然后，计算给定 $P(k)$ 下采纳者渐近比例的数值。将最终答案四舍五入至四位有效数字。最终答案不需要物理单位。",
            "solution": "用户希望在一个组态模型（CM）网络上，找到一个简单传染模型中采纳者的渐近比例。问题陈述明确地将此比例等同于网络中巨连通分量（GCC）的相对大小。我们将首先使用生成函数推导 GCC 大小的一般表达式，然后将其应用于给定的特定度分布。\n\n### 步骤 1：问题验证\n\n**1.1. 提取给定信息**\n- 网络模型：组态模型（CM），非常大，局部树状。\n- 度分布：节点的度 $k$ 是从一个分布 $P(k)$ 中独立抽取的。\n- 传染模型：简单传染，传播概率为 $1$。\n- 初始条件：无穷小的随机种子。\n- 采纳者比例：采纳者的渐近比例等于 GCC 中节点的比例。\n- 特定度分布：\n  - $P(0) = 0.05$\n  - $P(1) = 0.15$\n  - $P(2) = 0.25$\n  - $P(5) = 0.30$\n  - $P(10) = 0.25$\n- 定义：\n  - 节点度生成函数：$G_0(x) = \\sum_{k=0}^{\\infty} P(k) x^k$\n  - 剩余度生成函数：$G_1(x) = \\sum_{k=1}^{\\infty} \\frac{k P(k)}{\\langle k \\rangle} x^{k-1}$\n  - 平均度：$\\langle k \\rangle = \\sum_k k P(k)$\n\n**1.2. 使用提取的信息进行验证**\n- **科学依据**：该问题使用了网络科学中标准的、成熟的概念，包括组态模型、度分布的生成函数，以及用于寻找巨分量大小的分支过程形式化方法。这些方法是复杂网络研究的基础。该问题在科学上是合理的。\n- **适定性**：该问题是适定的。度分布被完全指定，待推导的量有明确定义，最终的数值计算是明确的。物理过程（传染）与网络结构属性（GCC 大小）之间的明确联系已经给出，确保了唯一且有意义的解的存在。\n- **客观性**：该问题以精确、客观的数学语言陈述。\n\n**1.3. 结论与行动**\n该问题是有效的。它具有科学依据，是适定的、客观的。没有可识别的缺陷。我们继续进行求解。\n\n### 步骤 2：自洽方程的推导\n\n令 $S$ 为巨连通分量（GCC）中节点的比例。问题要求计算这个值。通常，首先计算*不*在 GCC 中的节点比例会更容易，我们将其表示为 $u$。那么，$S = 1 - u$。如果一个节点属于一个有限分量，那么它就不在 GCC 中。\n\n我们引入两个概率：\n1. $u$：随机选择的节点属于有限分量的概率。\n2. $v$：沿着一条随机选择的边所到达的节点属于有限分量的概率。\n\n网络是巨大的且局部树状的这一假设至关重要。它意味着一个节点的邻域是树状的，我们可以将从一个节点分叉出的路径视为独立的。这使我们能够将网络探索建模为高尔顿-沃森分支过程。\n\n首先，我们来推导 $v$ 的自洽关系。考虑一条随机选择的边。它通向某个节点，我们称之为节点 $A$。这条边进入一个有限分量的概率是 $v$。要使其为真，节点 $A$ 本身以及从其*其他*边可达的整个分量都必须是有限的。\n\n一条随机选择的边通向一个度为 $k$ 的节点的概率由 $\\frac{k P(k)}{\\langle k \\rangle}$ 给出。这是因为一个度为 $k$ 的节点有 $k$ 个“末端”或边端，因此通过跟随一条边被选中的概率是度为 $1$ 的节点的 $k$ 倍。分母 $\\langle k \\rangle = \\sum_j j P(j)$ 确保了归一化。\n\n如果这个目标节点 $A$ 的度为 $k$，那么除了我们到达时所用的那条边之外，它还有 $k-1$ 条其他的边。要使节点 $A$ 从我们到达的边看来是有限分量的一部分，其所有 $k-1$ 个其他子分支也必须是有限的。根据定义，这些其他边中的任何一条通向有限分量的概率是 $v$。由于局部树状的假设，这 $k-1$ 个分支的命运是独立的。因此，所有 $k-1$ 个分支都是有限的概率是 $v^{k-1}$。\n\n为了得到总概率 $v$，我们必须对目标节点 $A$ 的所有可能度 $k$ 进行平均：\n$$v = \\sum_{k=1}^{\\infty} \\left( \\frac{k P(k)}{\\langle k \\rangle} \\right) v^{k-1}$$\n求和项中的表达式正是剩余度生成函数 $G_1(x)$ 在 $x=v$ 处的定义。这给出了第一个自洽关系：\n$$v = G_1(v)$$\n\n接下来，我们推导 $u$ 的表达式。一个随机选择的节点属于有限分量，当且仅当它的所有边都通向有限分量。一个随机选择的节点有 $P(k)$ 的概率度为 $k$。如果它的度是 $k$，它就有 $k$ 条边。其中任何一条边通向有限分量的概率是 $v$。由于各分支是独立的，所有 $k$ 条边都通向有限分量的概率是 $v^k$。\n\n为了找到总概率 $u$，我们对初始节点的所有可能度 $k$ 进行平均：\n$$u = \\sum_{k=0}^{\\infty} P(k) v^k$$\n这个和式是节点度生成函数 $G_0(x)$ 在 $x=v$ 处的定义。因此，我们有：\n$$u = G_0(v)$$\n\n结合这些结果，采纳者的比例 $S$，即 GCC 的大小，由以下公式给出：\n$$S = 1 - u = 1 - G_0(v)$$\n其中 $v$ 是方程 $v = G_1(v)$ 的最小非负解。一个解 $v=1$ 总是存在的。一个非平凡解 $v  1$ 存在的充要条件是存在一个 GCC，而如果 $G_1'(1) > 1$，则 GCC 的存在是有保证的。\n\n### 步骤 3：数值计算\n\n**3.1. 计算平均度和生成函数**\n度分布为 $P(0)=0.05$、$P(1)=0.15$、$P(2)=0.25$、$P(5)=0.30$ 和 $P(10)=0.25$。\n平均度 $\\langle k \\rangle$ 是：\n$$\\langle k \\rangle = \\sum_{k} k P(k) = (0)(0.05) + (1)(0.15) + (2)(0.25) + (5)(0.30) + (10)(0.25)$$\n$$\\langle k \\rangle = 0 + 0.15 + 0.50 + 1.50 + 2.50 = 4.65$$\n节点度生成函数是：\n$$G_0(x) = 0.05 + 0.15x + 0.25x^2 + 0.30x^5 + 0.25x^{10}$$\n剩余度生成函数是：\n$$G_1(x) = \\frac{1}{\\langle k \\rangle} \\sum_{k=1}^{\\infty} k P(k) x^{k-1}$$\n$$G_1(x) = \\frac{1}{4.65} \\left( (1)(0.15)x^0 + (2)(0.25)x^1 + (5)(0.30)x^4 + (10)(0.25)x^9 \\right)$$\n$$G_1(x) = \\frac{1}{4.65} \\left( 0.15 + 0.5x + 1.5x^4 + 2.5x^9 \\right)$$\n\n**3.2. 求解 v**\n我们必须找到 $v = G_1(v)$ 的最小非负根。我们可以通过不动点迭代法来求解，即 $v_{n+1} = G_1(v_n)$，从 $v_0 = 0$ 开始。\n$v_0 = 0$\n$v_1 = G_1(v_0) = \\frac{1}{4.65} (0.15) \\approx 0.03225806$\n$v_2 = G_1(v_1) = \\frac{1}{4.65} \\left( 0.15 + 0.5(0.03225806) + 1.5(0.03225806)^4 + \\dots \\right) \\approx 0.03572669$\n$v_3 = G_1(v_2) = \\frac{1}{4.65} \\left( 0.15 + 0.5(0.03572669) + \\dots \\right) \\approx 0.03610029$\n$v_4 = G_1(v_3) \\approx 0.03614002$\n$v_5 = G_1(v_4) \\approx 0.03614449$\n$v_6 = G_1(v_5) \\approx 0.03614499$\n$v_7 = G_1(v_6) \\approx 0.03614505$\n迭代收敛得很快。我们取 $v \\approx 0.03614505$。\n\n**3.3. 计算采纳者比例 S**\n现在我们计算采纳者比例 $S = 1 - G_0(v)$。\n$$S = 1 - (0.05 + 0.15v + 0.25v^2 + 0.30v^5 + 0.25v^{10})$$\n使用 $v \\approx 0.03614505$：\n- $0.15v \\approx 0.15 \\times 0.03614505 = 0.0054217575$\n- $0.25v^2 \\approx 0.25 \\times (0.03614505)^2 = 0.25 \\times 0.0013064646 \\approx 0.0003266162$\n- $0.30v^5 \\approx 0.30 \\times (0.03614505)^5 = 0.30 \\times 6.104 \\times 10^{-8} \\approx 1.831 \\times 10^{-8}$\n包含 $v^{10}$ 的项小到可以忽略不计。\n$$G_0(v) \\approx 0.05 + 0.0054217575 + 0.0003266162 + 1.831 \\times 10^{-8} \\approx 0.05574839$$\n$$S = 1 - G_0(v) \\approx 1 - 0.05574839 = 0.94425161$$\n将结果四舍五入到四位有效数字，得到 $0.9443$。",
            "answer": "$$\\boxed{0.9443}$$"
        },
        {
            "introduction": "虽然度分布至关重要，但许多现实世界的扩散过程，特别是那些涉及高成本或高风险创新的采纳，需要社会强化。本练习通过一个精心设计的思想实验，展示了局部聚类（一种无法仅由度序列决定的网络属性）如何成为决定“复杂传染”传播或消亡的关键因素。 通过对比两个具有相同度序列但聚类特性截然不同的网络，我们将揭示网络微观结构在驱动需要多重信号源的社会动态中的决定性作用。",
            "id": "4129695",
            "problem": "考虑两个简单无向图，它们具有相同的度序列，但局部聚类系数不同。群体由 $12$ 个代理组成，每个代理由一个节点表示，且每个代理恰好有 $4$ 个邻居。一项创新的采纳遵循一个确定性的阈值规则：在离散时间 $t=0,1,2,\\dots$，一个节点在时间 $t+1$ 将会永久采纳，当且仅当在时间 $t$ 其邻居中至少有比例为 $\\phi$ 的节点已经采纳。假设 $1/4  \\phi \\le 1/2$，因此当度为 $4$ 时，采纳需要至少 $2$ 个已采纳的邻居。初始种子由从所有边的集合中均匀随机选择的恰好 $2$ 个相邻节点组成。\n\n明确定义这两个网络：\n\n- 高聚类网络 $\\mathcal{H}$：节点标记为 $0,1,\\dots,11$，边连接于节点 $i$ 与 $(i\\pm 1)\\bmod 12$ 之间，以及节点 $i$ 与 $(i\\pm 2)\\bmod 12$ 之间。每个节点的度为 $4$。因为邻居的邻居通常本身也是邻居，所以这个图包含许多三角形。\n\n- 低聚类网络 $\\mathcal{L}$：将 $12$ 个节点划分为两个集合 $L=\\{L_0,L_1,\\dots,L_5\\}$ 和 $R=\\{R_0,R_1,\\dots,R_5\\}$。对于每个 $i\\in\\{0,1,\\dots,5\\}$，包含从 $L_i$ 到 $R_i$、$R_{(i+1)\\bmod 6}$、$R_{(i+2)\\bmod 6}$ 和 $R_{(i+3)\\bmod 6}$ 的边。每个节点的度为 $4$，且该图是二分图，因此没有三角形。\n\n仅使用阈值采纳规则的基本定义和图结构的基本推论（例如，二分图中不存在三角形），在指定的 $1/4  \\phi \\le 1/2$ 条件和以相邻对为种子的情况下，推断级联概率的定性差异。以下哪个陈述是正确的？\n\nA. 对于 $1/4  \\phi \\le 1/2$ 的情况，$\\mathcal{H}$ 中的一个相邻种子对会以概率 $1$ 引发全局级联，而在 $\\mathcal{L}$ 中，该过程会立即停止，全局级联的概率为 $0$。\n\nB. 因为两个网络具有相同的度序列，所以对于任何 $\\phi$ 和任何种子设定，它们的级联概率必须相同。\n\nC. 对于 $1/4  \\phi \\le 1/2$ 的情况，$\\mathcal{L}$ 中的一个相邻种子对产生的级联概率高于 $\\mathcal{H}$，因为较低的聚类系数增加了接触多样性。\n\nD. 对于 $1/4  \\phi \\le 1/2$ 的情况，一个相邻种子对无法在任一网络上引发级联，因为在时间 $t=0$ 时，没有非种子节点拥有至少 $2$ 个活跃邻居。",
            "solution": "用户希望我解决一个问题。我需要以特定格式输出我的答案。\n\n**问题验证**\n\n**第1步：提取已知条件**\n- **图**：两个简单无向图 $\\mathcal{H}$ 和 $\\mathcal{L}$，均具有相同的度序列。\n- **群体**：$12$ 个代理（节点）。\n- **度**：每个节点的度为 $k=4$。\n- **采纳规则**：确定性阈值规则。一个节点在时间 $t+1$ 永久采纳，当且仅当在时间 $t$ 其邻居中至少有比例为 $\\phi$ 的节点已经采纳。时间 $t=0,1,2,\\dots$。\n- **阈值**：$1/4  \\phi \\le 1/2$。对于度 $k=4$，所需的已采纳邻居数量为 $\\lceil k\\phi \\rceil = \\lceil 4\\phi \\rceil$。由于 $1  4\\phi \\le 2$，所以所需的已采纳邻居数量为 $2$。\n- **初始种子**：从边的集合中均匀随机选择的恰好 $2$ 个相邻节点。\n- **网络 $\\mathcal{H}$ (高聚类)**：\n    - 节点：$\\{0, 1, \\dots, 11\\}$。\n    - 节点 $i$ 的边：$(i, (i \\pm 1) \\pmod{12})$ 和 $(i, (i \\pm 2) \\pmod{12})$。\n    - 属性：包含许多三角形。\n- **网络 $\\mathcal{L}$ (低聚类)**：\n    - 节点：划分为 $L=\\{L_0, \\dots, L_5\\}$ 和 $R=\\{R_0, \\dots, R_5\\}$。\n    - 节点 $L_i$ 的边：$(L_i, R_i)$、$(L_i, R_{(i+1)\\pmod 6})$、$(L_i, R_{(i+2)\\pmod 6})$ 和 $(L_i, R_{(i+3)\\pmod 6})$，其中 $i \\in \\{0, 1, \\dots, 5\\}$。\n    - 属性：二分图，无三角形。\n\n**第2步：使用提取的已知条件进行验证**\n- **科学依据**：该问题采用了网络扩散中成熟的阈值模型，这是复杂系统和网络科学中的一个标准课题。图 $\\mathcal{H}$ 和 $\\mathcal{L}$ 是明确定义的数学对象（$12$ 个顶点上的 $4$-正则图）。其前提在科学上和数学上都是合理的。\n- **适定性**：采纳规则是确定性的，种子设定是在一个明确定义的集合上的概率性事件。问题要求对级联概率进行定性比较，这可以从给定的参数和网络结构中推导出来。存在唯一且有意义的解。\n- **客观性**：问题以精确、形式化的语言陈述。“高聚类”和“低聚类”的描述由明确的图构造来证明，这些构造分别保证了三角形的存在与否。该问题是客观的。\n- **缺陷检查表**：该问题没有违反任何指定的无效标准。它是自洽的、一致的，并且可以科学地形式化。\n\n**第3步：结论与行动**\n- 问题是**有效的**。现在开始解答过程。\n\n**推导**\n\n这个问题的核心在于理解局部网络结构如何与采纳阈值相互作用。采纳阈值为 $\\phi$，其中 $1/4  \\phi \\le 1/2$。对于一个度为 $k=4$ 的节点，触发其自身采纳所需的已采纳邻居数量为 $\\lceil k\\phi \\rceil = \\lceil 4\\phi \\rceil$。在给定的 $\\phi$ 范围内，我们有 $1  4\\phi \\le 2$，这意味着一个未采纳的节点必须至少有 $2$ 个已采纳的邻居才能采纳。\n\n过程在时间 $t=0$ 开始，种子是两个相邻的节点，我们称之为 $u$ 和 $v$。在时间 $t=1$，我们检查所有其他当前未采纳的节点。要开始级联，至少有一个未采纳的节点（比如说 $w$）必须采纳。根据规则，节点 $w$ 必须至少有 $2$ 个在时间 $t=0$ 时已经采纳的邻居。由于在 $t=0$ 时仅有的采纳节点是 $u$ 和 $v$，所以节点 $w$ 必须同时是 $u$ 和 $v$ 的邻居。\n\n级联传播超出初始种子的条件是种子节点 $u$ 和 $v$ 存在一个共同的邻居。如果存在这样的节点 $w$，那么边 $(u,v)$、$(v,w)$ 和 $(w,u)$ 必须都存在于图中。这三个节点和三条边构成一个三角形，或称 $3$-环。\n\n让我们在这种背景下分析这两个网络。\n\n**网络 $\\mathcal{L}$ (低聚类) 的分析：**\n网络 $\\mathcal{L}$ 被明确地构造为二分图，节点划分为 $L=\\{L_0, L_1, \\dots, L_5\\}$ 和 $R=\\{R_0, R_1, \\dots, R_5\\}$。$\\mathcal{L}$ 中的所有边都连接 $L$ 中的一个节点和 $R$ 中的一个节点。根据定义，二分图是指其顶点可以分为两个不相交的集合，使得每条边都连接第一个集合中的一个顶点和第二个集合中的一个顶点。二分图的一个基本性质是它们不包含任何奇数长度的环。由于三角形是长度为 $3$ 的环，因此网络 $\\mathcal{L}$ 不包含三角形。\n\n因此，对于 $\\mathcal{L}$ 中的任何相邻种子对 $(u,v)$，不可能存在一个共同的邻居 $w$。如果存在这样的 $w$，那么 $\\{u,v,w\\}$ 将形成一个三角形，这在 $\\mathcal{L}$ 中是不可能的。这意味着在 $t=0$ 时，没有一个未采纳的节点在已采纳集合 $\\{u,v\\}$ 中拥有超过一个邻居。由于采纳的阈值是 $2$，所以在 $t=1$ 时不会有新节点采纳。该过程会立即停止，采纳节点的集合将永久固定为 $\\{u,v\\}$。“全局级联”（定义为超出初始种子的采纳，通常指网络中相当大一部分的采纳）不会发生。因此，全局级联的概率为 $0$。\n\n**网络 $\\mathcal{H}$ (高聚类) 的分析：**\n网络 $\\mathcal{H}$ 是在节点 $\\{0, 1, \\dots, 11\\}$ 上构建的，边连接节点 $i$ 与 $(i\\pm 1)\\bmod 12$ 和 $(i\\pm 2)\\bmod 12$。问题陈述该图有许多三角形。我们必须验证对于任何相邻的种子对，都至少存在一个共同的邻居。此图中的边可以按其端点之间的距离进行分类：距离为 $1$ 的边，如 $(i, i+1)$，和距离为 $2$ 的边，如 $(i, i+2)$。\n\n1.  **种子是距离为 $1$ 的边**：设种子是相邻对 $(0,1)$。我们确定它们的共同邻居。\n    - $0$ 的邻居：$N(0) = \\{11, 1, 2, 10\\}$。\n    - $1$ 的邻居：$N(1) = \\{0, 2, 3, 11\\}$。\n    - 共同邻居的集合是 $N(0) \\cap N(1) = \\{2, 11\\}$。\n    由于节点 $2$ 和 $11$ 都连接到初始采纳者 $0$ 和 $1$，它们都满足了拥有 $2$ 个已采纳邻居的阈值。在 $t=1$ 时，节点 $2$ 和 $11$ 将会采纳。采纳者集合变为 $\\{0, 1, 2, 11\\}$。这将引发一个级联，通过进一步的逐步分析可以表明，最终将导致所有 $12$ 个节点的采纳。\n\n2.  **种子是距离为 $2$ 的边**：设种子是相邻对 $(0,2)$。我们确定它们的共同邻居。\n    - $0$ 的邻居：$N(0) = \\{11, 1, 2, 10\\}$。\n    - $2$ 的邻居：$N(2) = \\{0, 1, 3, 4\\}$。\n    - 共同邻居的集合是 $N(0) \\cap N(2) = \\{1\\}$。\n    节点 $1$ 连接到初始采纳者 $0$ 和 $2$。它满足阈值并将在 $t=1$ 时采纳。采纳者集合变为 $\\{0,1,2\\}$。这个更大的活跃集合足以触发进一步的采纳（例如，节点 $3$ 和 $11$ 将在 $t=2$ 时采纳），从而导致全局级联。\n\n由于图 $\\mathcal{H}$ 在这两种类型的边上是边传递的，并且两种类型的边都能引发全局级联，因此任何随机选择的边作为种子都会引发全局级联。在 $\\mathcal{H}$ 中，全局级联的概率为 $1$。\n\n**逐项分析**\n\n**A. 对于 $1/4  \\phi \\le 1/2$ 的情况，$\\mathcal{H}$ 中的一个相邻种子对会以概率 $1$ 引发全局级联，而在 $\\mathcal{L}$ 中，该过程会立即停止，全局级联的概率为 $0$。**\n该陈述准确地总结了我们推导的结果。在 $\\mathcal{H}$ 中，大量的三角形确保了任何种子边都能提供启动级联所需的冗余连接，然后级联会全局传播。概率为 $1$。在 $\\mathcal{L}$ 中，三角形的缺失阻止了级联的发生。概率为 $0$。\n结论：**正确**。\n\n**B. 因为两个网络具有相同的度序列，所以对于任何 $\\phi$ 和任何种子设定，它们的级联概率必须相同。**\n这种说法是网络分析中一个常见的谬误。度序列是一阶属性，不足以确定像级联这样的动态过程。正如我们的分析所示，像聚类（三角形）这样的高阶结构至关重要，即使度序列相同，也会导致截然不同的结果（级联概率为 $1$ 对比 $0$）。\n结论：**不正确**。\n\n**C. 对于 $1/4  \\phi \\le 1/2$ 的情况，$\\mathcal{L}$ 中的一个相邻种子对产生的级联概率高于 $\\mathcal{H}$，因为较低的聚类系数增加了接触多样性。**\n我们的分析表明，在 $\\mathcal{L}$ 中级联概率为 $0$，而在 $\\mathcal{H}$ 中为 $1$。该陈述提出了相反的主张。其理由“较低的聚类系数增加了接触多样性”是一个概念（与 Granovetter 的“弱关系的力量”相关），适用于简单传染或信息传播，即单次接触就足够了。对于阈值大于 $1$ 的复杂传染，来自高聚类（冗余连接）的社会强化是必需的。这个逻辑被错误地应用于此情境中。\n结论：**不正确**。\n\n**D. 对于 $1/4  \\phi \\le 1/2$ 的情况，一个相邻种子对无法在任一网络上引发级联，因为在时间 $t=0$ 时，没有非种子节点拥有至少 $2$ 个活跃邻居。**\n这个陈述正确地描述了网络 $\\mathcal{L}$ 中的情况，但对于网络 $\\mathcal{H}$ 则不成立。在 $\\mathcal{H}$ 中，对于任何相邻的种子对，至少有一个非种子节点同时是两个种子节点的邻居（即，在 $t=0$ 时有 $2$ 个活跃邻居）。因此，在 $\\mathcal{H}$ 中会引发级联。由于该陈述声称这适用于“任一网络”，所以它是错误的。\n结论：**不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "我们将焦点从二元状态（采纳/未采纳）的传播转移到通过社会学习进行的连续信念演化。本练习深入探讨了社会影响中一个关键而微妙的方面：个体如何处理来自同伴的信息。 它将一个简化的启发式学习模型（DeGroot模型）与一个完全理性的贝叶斯基准进行对比，以量化当信息源相关时，群体在整合信息时可能产生的系统性偏差，例如过度自信。",
            "id": "4129757",
            "problem": "考虑一个由三名代理人组成的群体，他们参与社会学习，以了解一项新创新的未知质量 $\\,\\theta\\,$。这些代理人在一个全连接网络上互动，并使用 DeGroot 社会影响模型所描述的线性意见池，重复地对其邻居的当前信念进行平均。行随机交互矩阵为\n$$\nW \\;=\\; \\begin{pmatrix}\n\\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\\\\n\\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\\\\n\\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3}\n\\end{pmatrix},\n$$\n且初始信念就是代理人的私人信号。两名代理人（代理人 $\\,1\\,$ 和 $\\,2\\,$）阅读了同一份专家报告，因此共享一个共同的信息成分，而第三名代理人（代理人 $\\,3\\,$）使用的来源与该专家报告无关。形式上，以 $\\,\\theta\\,$ 为条件，私人信号由以下方式生成\n$$\nx_1 \\;=\\; \\theta \\;+\\; u \\;+\\; \\epsilon_1, \\qquad\nx_2 \\;=\\; \\theta \\;+\\; u \\;+\\; \\epsilon_2, \\qquad\nx_3 \\;=\\; \\theta \\;+\\; \\epsilon_3,\n$$\n其中 $\\,u \\sim \\mathcal{N}(0,\\tau^2)\\,$ 是影响代理人 $\\,1\\,$ 和 $\\,2\\,$ 的共同来源成分，而 $\\,\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\,$ 是相互独立的特异性噪声，且独立于 $\\,u\\,$。所有随机变量均为联合高斯分布，且 $\\,\\tau^2  0\\,$ 和 $\\,\\sigma^2  0\\,$ 是已知的。\n\n假设代理人是天真的，即在 DeGroot 平均收敛后，他们评估自己关于 $\\,\\theta\\,$ 的后验时，就好像三个信号在给定 $\\,\\theta\\,$ 的条件下是条件独立的，并且具有相同的方差 $\\,\\sigma^2\\,$。相比之下，一个完全理性的贝叶斯聚合器知道 $\\,x=(x_1,x_2,x_3)^\\top\\,$ 的真实联合分布，并基于 $\\,x\\,$ 计算 $\\,\\theta\\,$ 的最小方差无偏线性估计及其相关的后验精度。\n\n从联合高斯噪声下的线性无偏估计的基本定义以及行随机网络上重复平均下的共识定义出发，从第一性原理推导出由下式定义的后验精度夸大因子\n$$\nf \\;\\equiv\\; \\frac{\\text{天真后验精度}}{\\text{完全贝叶斯后验精度}} \\;-\\; 1,\n$$\n使其成为一个关于 $\\,\\tau^2\\,$ 和 $\\,\\sigma^2\\,$ 的闭式解析表达式。你的最终答案必须是一个单一的解析表达式。不要使用任何四舍五入。",
            "solution": "问题要求计算后验精度夸大因子 $f$，该因子量化了忽略其信息信号中相关性的天真代理人的过度自信。该因子定义为：\n$$\nf \\equiv \\frac{\\text{天真后验精度}}{\\text{完全贝叶斯后验精度}} - 1\n$$\n为了推导出 $f$，我们必须计算两个量：天真后验精度和完全贝叶斯后验精度。\n\n### 1. 天真后验精度\n\n天真的代理人在一个不正确的假设下评估他们关于质量 $\\theta$ 的后验信念，即他们的私人信号 $x_1$、$x_2$ 和 $x_3$ 在给定 $\\theta$ 的条件下是条件独立的。具体来说，他们将信号建模为来自均值为 $\\theta$、公共方差为 $\\sigma^2$ 的高斯分布的独立抽样：\n$$\nx_i | \\theta \\sim \\mathcal{N}(\\theta, \\sigma^2) \\quad \\text{对于 } i \\in \\{1, 2, 3\\}, \\text{ 假设独立}\n$$\n在这个（不正确的）模型下，并假设 $\\theta$ 服从无信息平坦先验，$\\theta$ 的后验分布由似然函数导出。观测到信号 $x = (x_1, x_2, x_3)^\\top$ 的似然函数为：\n$$\np(x | \\theta) = \\prod_{i=1}^{3} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x_i - \\theta)^2}{2\\sigma^2}\\right) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{3} (x_i - \\theta)^2\\right)\n$$\n后验概率密度 $p(\\theta | x)$ 与似然函数成正比，$p(\\theta | x) \\propto p(x | \\theta)$。因此，对数后验为：\n$$\n\\ln p(\\theta | x) = C - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{3} (x_i - \\theta)^2\n$$\n其中 $C$ 是一个常数。我们可以对指数中的 $\\theta$ 进行配方。令 $\\bar{x} = \\frac{1}{3}\\sum_{i=1}^{3} x_i$ 为信号的样本均值。\n$$\n\\sum_{i=1}^{3} (x_i - \\theta)^2 = \\sum_{i=1}^{3} (x_i - \\bar{x} + \\bar{x} - \\theta)^2 = \\sum_{i=1}^{3} (x_i - \\bar{x})^2 + \\sum_{i=1}^{3} (\\bar{x} - \\theta)^2 = \\sum_{i=1}^{3} (x_i - \\bar{x})^2 + 3(\\bar{x} - \\theta)^2\n$$\n第一项不依赖于 $\\theta$，因此可以被吸收到常数中。对数后验变为：\n$$\n\\ln p(\\theta | x) = C' - \\frac{3(\\theta - \\bar{x})^2}{2\\sigma^2} = C' - \\frac{(\\theta - \\bar{x})^2}{2(\\sigma^2/3)}\n$$\n这是 $\\theta$ 的高斯概率密度函数的对数，其均值为 $\\bar{x}$，方差为 $\\sigma^2/3$。在天真假设下的后验分布为 $\\theta | x \\sim \\mathcal{N}(\\bar{x}, \\sigma^2/3)$。\n\n问题陈述代理人使用 DeGroot 模型，收敛到一个共识信念 $b_{\\infty} = \\frac{1}{3}x_1 + \\frac{1}{3}x_2 + \\frac{1}{3}x_3 = \\bar{x}$。这与他们的后验均值是一致的。\n\n天真后验精度是天真后验方差的倒数：\n$$\n\\text{天真后验精度} = \\frac{1}{\\text{Var}_{\\text{天真}}(\\theta|x)} = \\frac{1}{\\sigma^2/3} = \\frac{3}{\\sigma^2}\n$$\n\n### 2. 完全贝叶斯后验精度\n\n一个完全理性的贝叶斯聚合器使用信号的真实联合分布。信号由以下公式给出：\n$$\nx_1 = \\theta + u + \\epsilon_1\n$$\n$$\nx_2 = \\theta + u + \\epsilon_2\n$$\n$$\nx_3 = \\theta + \\epsilon_3\n$$\n其中 $u \\sim \\mathcal{N}(0, \\tau^2)$ 和 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$ 是独立的噪声项。\n我们可以将其表示为线性模型 $x = \\mathbf{1}\\theta + v$ 的形式，其中 $x=(x_1, x_2, x_3)^\\top$，$\\mathbf{1}=(1, 1, 1)^\\top$，而 $v$ 是一个零均值噪声项的向量 $v = (x_1-\\theta, x_2-\\theta, x_3-\\theta)^\\top$。\n$$\nv_1 = u + \\epsilon_1, \\quad v_2 = u + \\epsilon_2, \\quad v_3 = \\epsilon_3\n$$\n噪声向量 $v$ 的协方差矩阵，记为 $\\Sigma_x$，通过计算协方差 $E[v_i v_j]$ 得到：\n$$\n\\text{Var}(v_1) = E[(u+\\epsilon_1)^2] = E[u^2] + E[\\epsilon_1^2] = \\tau^2 + \\sigma^2\n$$\n$$\n\\text{Var}(v_2) = E[(u+\\epsilon_2)^2] = E[u^2] + E[\\epsilon_2^2] = \\tau^2 + \\sigma^2\n$$\n$$\n\\text{Var}(v_3) = E[\\epsilon_3^2] = \\sigma^2\n$$\n$$\n\\text{Cov}(v_1, v_2) = E[(u+\\epsilon_1)(u+\\epsilon_2)] = E[u^2] = \\tau^2\n$$\n$$\n\\text{Cov}(v_1, v_3) = E[(u+\\epsilon_1)\\epsilon_3] = 0\n$$\n$$\n\\text{Cov}(v_2, v_3) = E[(u+\\epsilon_2)\\epsilon_3] = 0\n$$\n因此，协方差矩阵为：\n$$\n\\Sigma_x = \\begin{pmatrix} \\tau^2+\\sigma^2  \\tau^2  0 \\\\ \\tau^2  \\tau^2+\\sigma^2  0 \\\\ 0  0  \\sigma^2 \\end{pmatrix}\n$$\n对于一个线性高斯模型 $x \\sim \\mathcal{N}(\\mathbf{1}\\theta, \\Sigma_x)$，$\\theta$ 的后验精度（在平坦先验下）由对数似然函数中的二次项给出，这等价于最小方差无偏线性估计器的精度。该精度由 $\\mathbf{1}^\\top \\Sigma_x^{-1} \\mathbf{1}$ 给出。\n\n我们必须首先计算 $\\Sigma_x$ 的逆矩阵。由于 $\\Sigma_x$ 是块对角矩阵，我们可以分别对块进行求逆。左上角的 $2 \\times 2$ 块是 $M = \\begin{pmatrix} \\tau^2+\\sigma^2  \\tau^2 \\\\ \\tau^2  \\tau^2+\\sigma^2 \\end{pmatrix}$。\n行列式为 $\\det(M) = (\\tau^2+\\sigma^2)^2 - (\\tau^2)^2 = \\tau^4 + 2\\tau^2\\sigma^2 + \\sigma^4 - \\tau^4 = \\sigma^2(2\\tau^2+\\sigma^2)$。\n其逆矩阵为：\n$$\nM^{-1} = \\frac{1}{\\sigma^2(2\\tau^2+\\sigma^2)} \\begin{pmatrix} \\tau^2+\\sigma^2  -\\tau^2 \\\\ -\\tau^2  \\tau^2+\\sigma^2 \\end{pmatrix}\n$$\n完整协方差矩阵的逆矩阵为：\n$$\n\\Sigma_x^{-1} = \\begin{pmatrix} M^{-1}  \\mathbf{0} \\\\ \\mathbf{0}^\\top  1/\\sigma^2 \\end{pmatrix} = \\frac{1}{\\sigma^2(2\\tau^2+\\sigma^2)} \\begin{pmatrix} \\tau^2+\\sigma^2  -\\tau^2  0 \\\\ -\\tau^2  \\tau^2+\\sigma^2  0 \\\\ 0  0  2\\tau^2+\\sigma^2 \\end{pmatrix}\n$$\n完全贝叶斯后验精度是 $\\Sigma_x^{-1}$ 所有元素的总和，因为 $\\mathbf{1}^\\top \\Sigma_x^{-1} \\mathbf{1} = \\sum_{i,j} (\\Sigma_x^{-1})_{ij}$：\n$$\n\\text{完全贝叶斯后验精度} = \\frac{1}{\\sigma^2(2\\tau^2+\\sigma^2)} [(\\tau^2+\\sigma^2) - \\tau^2 - \\tau^2 + (\\tau^2+\\sigma^2) + (2\\tau^2+\\sigma^2)]\n$$\n$$\n= \\frac{1}{\\sigma^2(2\\tau^2+\\sigma^2)} [2\\sigma^2 + 2\\tau^2 + \\sigma^2] = \\frac{2\\tau^2+3\\sigma^2}{\\sigma^2(2\\tau^2+\\sigma^2)}\n$$\n\n### 3. 后验精度夸大因子\n\n现在我们计算因子 $f$：\n$$\nf = \\frac{\\text{天真后验精度}}{\\text{完全贝叶斯后验精度}} - 1\n$$\n$$\nf = \\frac{3/\\sigma^2}{\\frac{2\\tau^2+3\\sigma^2}{\\sigma^2(2\\tau^2+\\sigma^2)}} - 1\n$$\n$$\nf = \\frac{3}{\\sigma^2} \\cdot \\frac{\\sigma^2(2\\tau^2+\\sigma^2)}{2\\tau^2+3\\sigma^2} - 1\n$$\n$$\nf = \\frac{3(2\\tau^2+\\sigma^2)}{2\\tau^2+3\\sigma^2} - 1\n$$\n将所有项通分：\n$$\nf = \\frac{3(2\\tau^2+\\sigma^2) - (2\\tau^2+3\\sigma^2)}{2\\tau^2+3\\sigma^2}\n$$\n$$\nf = \\frac{6\\tau^2+3\\sigma^2 - 2\\tau^2-3\\sigma^2}{2\\tau^2+3\\sigma^2}\n$$\n$$\nf = \\frac{4\\tau^2}{2\\tau^2+3\\sigma^2}\n$$\n这就是后验精度夸大因子的最终闭式表达式。",
            "answer": "$$\\boxed{\\frac{4\\tau^2}{2\\tau^2+3\\sigma^2}}$$"
        }
    ]
}