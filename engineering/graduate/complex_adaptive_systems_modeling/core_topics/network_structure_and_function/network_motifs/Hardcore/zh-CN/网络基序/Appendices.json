{
    "hands_on_practices": [
        {
            "introduction": "该练习旨在解决模体分析中的一个关键概念：统计显著性。简单地对模体进行计数可能会产生误导，因为高度节点（“枢纽”）天然会参与到更多各种类型的子图中。此练习  将引导您首先理解这种源于度序列的偏差，然后推导出一个能够解释这种偏差的归一化方案，从而对模体的结构重要性进行更有意义的评估。",
            "id": "4134009",
            "problem": "考虑一个称为前馈环的有向网络基序，它定义在不同的节点 $i,j,k$ 上，由有向边 $i \\rightarrow j$、$j \\rightarrow k$ 和 $i \\rightarrow k$ 的存在来定义。在稀疏网络的有向配置模型 (Chung–Lu) 中，假设从节点 $u$ 到节点 $v$ 的边的基准期望概率由 $p_{uv} = k_{u}^{\\mathrm{out}} k_{v}^{\\mathrm{in}} / m$ 给出，其中 $k_{u}^{\\mathrm{out}}$ 是节点 $u$ 的出度，$k_{v}^{\\mathrm{in}}$ 是节点 $v$ 的入度，$m$ 是总边数。在边出现事件独立的近似下进行计算。\n\n给定一个包含节点 $a,b,c,d,e$ 的有向网络，其边如下：\n$a \\rightarrow b$、$a \\rightarrow c$、$a \\rightarrow d$、$a \\rightarrow e$、$b \\rightarrow c$、$b \\rightarrow d$、$b \\rightarrow e$、$c \\rightarrow d$、$c \\rightarrow e$、$d \\rightarrow e$。\n\n仅使用基本定义和所述基准，首先从基本原理出发，论证为什么在此基准下，具有较大 $k^{\\mathrm{out}}$ 或较大 $k^{\\mathrm{in}}$ 的节点会倾向于夸大原始前馈环的计数。然后，推导一种归一化方法，其中每个观测到的 $(i,j,k)$ 上的前馈环被赋予一个权重，该权重等于其三条边的基准边概率乘积的倒数。将归一化基序得分 $S$ 定义为给定网络中所有观测到的前馈环的这些权重之和。\n\n计算该网络 $S$ 的精确值。请用精确值表示最终答案，无需四舍五入。最终答案中不要包含任何单位。",
            "solution": "该问题已经过验证。\n\n### 步骤1：提取已知条件\n- **基序定义**：前馈环 (FFL) 定义在不同的节点 $i,j,k$ 上，由有向边 $i \\rightarrow j$、$j \\rightarrow k$ 和 $i \\rightarrow k$ 的存在来定义。\n- **网络模型**：稀疏网络的有向配置模型 (Chung–Lu)。\n- **基准边概率**：从节点 $u$ 到节点 $v$ 的边的概率为 $p_{uv} = k_{u}^{\\mathrm{out}} k_{v}^{\\mathrm{in}} / m$。\n- **模型参数**：$k_{u}^{\\mathrm{out}}$ 是节点 $u$ 的出度，$k_{v}^{\\mathrm{in}}$ 是节点 $v$ 的入度，$m$ 是总边数。\n- **近似**：边的出现被视为独立事件。\n- **网络规格**：节点为 $\\{a,b,c,d,e\\}$。边为 $a \\rightarrow b$、$a \\rightarrow c$、$a \\rightarrow d$、$a \\rightarrow e$、$b \\rightarrow c$、$b \\rightarrow d$、$b \\rightarrow e$、$c \\rightarrow d$、$c \\rightarrow e$、$d \\rightarrow e$。\n- **任务1**：从基本原理出发，论证为什么具有较大 $k^{\\mathrm{out}}$ 或 $k^{\\mathrm{in}}$ 的节点在此基准下会夸大原始 FFL 计数。\n- **任务2**：定义一个归一化基序得分 $S$，其中每个观测到的 $(i,j,k)$ 上的 FFL 被赋予一个权重，该权重等于其三条组成边的基准概率乘积的倒数。$S$ 是这些权重之和。\n- **任务3**：计算给定网络 $S$ 的精确值。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据**：该问题在网络科学和复杂系统领域具有坚实的科学基础。前馈环是一种经典的网络基序。有向配置模型（或 Chung-Lu 模型）是用于基序显著性分析的标准零模型。通过零模型概率的倒数进行归一化的方法是一种有效且成熟的技术。\n- **良定性**：该问题是良定的。网络结构已明确给出，零模型已定义，待计算的量 ($S$) 由清晰的数学步骤指定。所有必要信息都已提供，可以计算出唯一解。\n- **客观性**：问题陈述是客观的，使用了精确、正式的定义，避免了任何歧义或主观语言。\n\n### 步骤3：结论与行动\n该问题是有效的，因为它科学上合理、良定且客观。将提供完整的解答。\n\n### 解题推导\n\n解题过程分三个阶段：首先，对基序计数被夸大的原因进行基于原理的论证；其次，详细分析给定网络以确定其属性并识别所有前馈环；第三，计算归一化得分 $S$。\n\n**第1部分：原始计数夸大的论证**\n\n不同节点 $(i,j,k)$ 上的前馈环 (FFL) 由边 $i \\rightarrow j$、$j \\rightarrow k$ 和 $i \\rightarrow k$ 组成。在指定的 Chung-Lu 基准模型中，每个潜在边的出现是一个独立的概率事件。从节点 $u$ 到节点 $v$ 的边的概率由 $p_{uv} = k_{u}^{\\mathrm{out}} k_{v}^{\\mathrm{in}} / m$ 给出。\n\n在此模型生成的随机网络中，FFL 的期望数量 $N_{\\mathrm{FFL}}^{\\mathrm{exp}}$ 是在所有不同节点三元组 $(i,j,k)$ 上，该三元组形成一个 FFL 的概率之和。由于独立性假设，这个概率是各个边概率的乘积：\n$$P(\\text{FFL on } i,j,k) = p_{ij} p_{jk} p_{ik}$$\n代入给定的基准概率公式：\n$$P(\\text{FFL on } i,j,k) = \\left(\\frac{k_{i}^{\\mathrm{out}} k_{j}^{\\mathrm{in}}}{m}\\right) \\left(\\frac{k_{j}^{\\mathrm{out}} k_{k}^{\\mathrm{in}}}{m}\\right) \\left(\\frac{k_{i}^{\\mathrm{out}} k_{k}^{\\mathrm{in}}}{m}\\right) = \\frac{(k_{i}^{\\mathrm{out}})^{2} k_{j}^{\\mathrm{in}} k_{j}^{\\mathrm{out}} (k_{k}^{\\mathrm{in}})^{2}}{m^{3}}$$\nFFL 的总期望数量是这些概率在所有可能的三元组上的总和：\n$$N_{\\mathrm{FFL}}^{\\mathrm{exp}} = \\sum_{i \\neq j \\neq k \\neq i} \\frac{(k_{i}^{\\mathrm{out}})^{2} k_{j}^{\\mathrm{in}} k_{j}^{\\mathrm{out}} (k_{k}^{\\mathrm{in}})^{2}}{m^{3}}$$\n该表达式从基本原理上表明，FFL 的期望数量在所有网络结构中并非均匀分布，而是高度依赖于度序列。具体来说，任何涉及节点 $i, j, k$ 的潜在 FFL 对期望计数的贡献，与源节点 $i$ 的出度的平方、汇节点 $k$ 的入度的平方以及中间节点 $j$ 的入度和出度的乘积成正比。因此，度数大的节点（中心节点）会不成比例地增加 FFL 的期望数量。因此，在一个观测到的网络中，FFL 的原始计数会因为高度节点的存在而被“夸大”，因为无论是否存在任何更高阶的结构组织，这个基准期望值本身就很高。需要进行归一化，以将度序列的贡献与真实的结构性过表达分离开来。\n\n**第2部分：网络分析与前馈环识别**\n\n给定网络有 $5$ 个节点 $\\{a,b,c,d,e\\}$ 和 $10$ 条边。总边数 $m=10$。我们首先计算每个节点的入度 ($k^{\\mathrm{in}}$) 和出度 ($k^{\\mathrm{out}}$)。\n- 节点 $a$：$k_{a}^{\\mathrm{in}} = 0$，$k_{a}^{\\mathrm{out}} = 4$\n- 节点 $b$：$k_{b}^{\\mathrm{in}} = 1$，$k_{b}^{\\mathrm{out}} = 3$\n- 节点 $c$：$k_{c}^{\\mathrm{in}} = 2$，$k_{c}^{\\mathrm{out}} = 2$\n- 节点 $d$：$k_{d}^{\\mathrm{in}} = 3$，$k_{d}^{\\mathrm{out}} = 1$\n- 节点 $e$：$k_{e}^{\\mathrm{in}} = 4$，$k_{e}^{\\mathrm{out}} = 0$\n度数之和为 $\\sum k^{\\mathrm{in}} = 10$ 和 $\\sum k^{\\mathrm{out}} = 10$，与 $m=10$ 一致。\n\n接下来，我们系统地识别网络中所有的前馈环 $(i,j,k)$。一个前馈环需要一条长度为二的路径 ($i \\rightarrow j \\rightarrow k$) 和一条直接的“捷径”边 ($i \\rightarrow k$)。\n1. FFL $(a,b,c)$：路径 $a \\rightarrow b \\rightarrow c$ 存在。捷径 $a \\rightarrow c$ 存在。\n2. FFL $(a,b,d)$：路径 $a \\rightarrow b \\rightarrow d$ 存在。捷径 $a \\rightarrow d$ 存在。\n3. FFL $(a,b,e)$：路径 $a \\rightarrow b \\rightarrow e$ 存在。捷径 $a \\rightarrow e$ 存在。\n4. FFL $(a,c,d)$：路径 $a \\rightarrow c \\rightarrow d$ 存在。捷径 $a \\rightarrow d$ 存在。\n5. FFL $(a,c,e)$：路径 $a \\rightarrow c \\rightarrow e$ 存在。捷径 $a \\rightarrow e$ 存在。\n6. FFL $(a,d,e)$：路径 $a \\rightarrow d \\rightarrow e$ 存在。捷径 $a \\rightarrow e$ 存在。\n7. FFL $(b,c,d)$：路径 $b \\rightarrow c \\rightarrow d$ 存在。捷径 $b \\rightarrow d$ 存在。\n8. FFL $(b,c,e)$：路径 $b \\rightarrow c \\rightarrow e$ 存在。捷径 $b \\rightarrow e$ 存在。\n9. FFL $(b,d,e)$：路径 $b \\rightarrow d \\rightarrow e$ 存在。捷径 $b \\rightarrow e$ 存在。\n10. FFL $(c,d,e)$：路径 $c \\rightarrow d \\rightarrow e$ 存在。捷径 $c \\rightarrow e$ 存在。\n网络中总共有 $10$ 个前馈环。\n\n**第3部分：归一化得分S的计算**\n\n归一化得分 $S$ 是所有观测到的 FFL 的权重之和。对于节点 $(i,j,k)$ 上的一个 FFL，其权重 $w_{ijk}$ 是其组成边的基准概率乘积的倒数：\n$$w_{ijk} = \\frac{1}{p_{ij} p_{jk} p_{ik}} = \\frac{1}{\\frac{(k_{i}^{\\mathrm{out}})^{2} k_{j}^{\\mathrm{in}} k_{j}^{\\mathrm{out}} (k_{k}^{\\mathrm{in}})^{2}}{m^{3}}} = \\frac{m^{3}}{(k_{i}^{\\mathrm{out}})^{2} k_{j}^{\\mathrm{in}} k_{j}^{\\mathrm{out}} (k_{k}^{\\mathrm{in}})^{2}}$$\n我们使用 $m=10$（因此 $m^3=1000$）和之前计算的度值，为 10 个已识别的 FFL 中的每一个计算这个权重。\n\n- $w_{abc} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{b}^{\\mathrm{in}} k_{b}^{\\mathrm{out}} (k_{c}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(1)(3)(2)^{2}} = \\frac{1000}{192}$\n- $w_{abd} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{b}^{\\mathrm{in}} k_{b}^{\\mathrm{out}} (k_{d}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(1)(3)(3)^{2}} = \\frac{1000}{432}$\n- $w_{abe} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{b}^{\\mathrm{in}} k_{b}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(1)(3)(4)^{2}} = \\frac{1000}{768}$\n- $w_{acd} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{c}^{\\mathrm{in}} k_{c}^{\\mathrm{out}} (k_{d}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(2)(2)(3)^{2}} = \\frac{1000}{576}$\n- $w_{ace} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{c}^{\\mathrm{in}} k_{c}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(2)(2)(4)^{2}} = \\frac{1000}{1024}$\n- $w_{ade} = \\frac{1000}{(k_{a}^{\\mathrm{out}})^{2} k_{d}^{\\mathrm{in}} k_{d}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(4)^{2}(3)(1)(4)^{2}} = \\frac{1000}{768}$\n- $w_{bcd} = \\frac{1000}{(k_{b}^{\\mathrm{out}})^{2} k_{c}^{\\mathrm{in}} k_{c}^{\\mathrm{out}} (k_{d}^{\\mathrm{in}})^{2}} = \\frac{1000}{(3)^{2}(2)(2)(3)^{2}} = \\frac{1000}{324}$\n- $w_{bce} = \\frac{1000}{(k_{b}^{\\mathrm{out}})^{2} k_{c}^{\\mathrm{in}} k_{c}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(3)^{2}(2)(2)(4)^{2}} = \\frac{1000}{576}$\n- $w_{bde} = \\frac{1000}{(k_{b}^{\\mathrm{out}})^{2} k_{d}^{\\mathrm{in}} k_{d}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(3)^{2}(3)(1)(4)^{2}} = \\frac{1000}{432}$\n- $w_{cde} = \\frac{1000}{(k_{c}^{\\mathrm{out}})^{2} k_{d}^{\\mathrm{in}} k_{d}^{\\mathrm{out}} (k_{e}^{\\mathrm{in}})^{2}} = \\frac{1000}{(2)^{2}(3)(1)(4)^{2}} = \\frac{1000}{192}$\n\n总分 $S$ 是这 10 个权重的和：\n$$S = 1000 \\left( \\frac{2}{192} + \\frac{2}{432} + \\frac{2}{768} + \\frac{2}{576} + \\frac{1}{1024} + \\frac{1}{324} \\right)$$\n$$S = 1000 \\left( \\frac{1}{96} + \\frac{1}{216} + \\frac{1}{384} + \\frac{1}{288} + \\frac{1}{1024} + \\frac{1}{324} \\right)$$\n为了对这些分数求和，我们找到分母的最小公倍数：\n$96 = 2^5 \\times 3^1$、$216 = 2^3 \\times 3^3$、$384 = 2^7 \\times 3^1$、$288 = 2^5 \\times 3^2$、$1024 = 2^{10}$、$324 = 2^2 \\times 3^4$。\n最小公倍数是 $2^{10} \\times 3^4 = 1024 \\times 81 = 82944$。\n将每个分数用这个公分母表示：\n$$S = 1000 \\left( \\frac{864}{82944} + \\frac{384}{82944} + \\frac{216}{82944} + \\frac{288}{82944} + \\frac{81}{82944} + \\frac{256}{82944} \\right)$$\n$$S = 1000 \\left( \\frac{864+384+216+288+81+256}{82944} \\right) = 1000 \\left( \\frac{2089}{82944} \\right)$$\n$$S = \\frac{2089000}{82944}$$\n这个分数可以通过约去公因子8来化简：\n$$S = \\frac{2089000 \\div 8}{82944 \\div 8} = \\frac{261125}{10368}$$\n由于2089是素数，且10368的素因子是2和3，因此该分数为最简形式。\n这是归一化基序得分的精确值。",
            "answer": "$$\\boxed{\\frac{261125}{10368}}$$"
        },
        {
            "introduction": "网络模体常被描述为复杂网络的“构建模块”，这意味着它们具有特定的功能。本实践  将超越静态模式的计数，深入探讨相干1型前馈环（C1-FFL）的动态功能，这是一种在基因调控网络中常见的模体。通过使用常微分方程对该系统进行建模，您将揭示这种特定的连接方式如何能充当一个持久性检测器，过滤掉短暂的噪声信号，仅对持续的输入做出响应。",
            "id": "4366055",
            "problem": "考虑一个被称为1型相干前馈环（C1-FFL）的基因调控网络基序，其中转录因子$X$激活一个中间基因产物$Y$，而$X$和$Y$共同正向调控一个下游基因产物$Z$。在系统生物医学中，此类基序使用一级生产和降解动力学以及用于转录激活的希尔（Hill）型输入输出关系进行建模。作用于靶标的输入$U$的标准激活希尔函数定义为 $f(U) = \\dfrac{U^{n}}{K^{n} + U^{n}}$，其中$n$是希尔系数，$K$是激活常数。假设在没有激活输入时，基础表达可忽略不计。\n\n基于这些核心定义：\n\n1) 推导$Y$和$Z$的常微分方程，这些方程应符合一级降解以及由$X$和$Y$进行的希尔型激活，并假设$Z$对其两个输入实现一个“与”逻辑门。分别使用符号$\\alpha_Y$、$\\alpha_Z$表示最大生产速率，$\\beta_Y$、$\\beta_Z$表示降解速率，并使用独立的希尔函数$f_X(X)$、$g_X(X)$和$h_Y(Y)$分别表示$X$对$Y$、$X$对$Z$以及$Y$对$Z$的调控效应。\n\n2) 为分析符号敏感延迟，请考虑以下协议和参数体系：\n- 所有调控环节的希尔系数均为$n=1$。\n- 输入$X(t)$是一个阶跃函数：当$t < 0$时，$X(t) = 0$；当$t \\ge 0$时，$X(t) = X_{0}$。\n- 初始条件为$Y(0)=0$和$Z(0)=0$。\n- $Z$处的“与”门由乘积$g_X(X)\\,h_Y(Y)$实现。\n- 生产项$h_Y(Y)$处于$Y$的弱激活区域，即$Y(t) \\ll K_{Y}$，因此$h_Y(Y) \\approx \\dfrac{Y}{K_{Y}}$。\n- $Y$和$Z$的降解速率相等：$\\beta_Y = \\beta_Z = \\beta > 0$。\n- 当$X=0$时没有生产，即$f_X(0)=0$和$g_X(0)=0$。\n\n在这些假设下：\n(a) 当$X$从$0$阶跃到$X_{0}$并保持恒定时，推导$t \\ge 0$时的$Z(t)$。\n(b) 定义无量纲的开启半衰期$\\theta_{\\mathrm{on}} = \\beta\\,t_{\\mathrm{on}}$，其中$t_{\\mathrm{on}}$是$t=0$之后$Z(t)$首次达到其在恒定$X_{0}$下的稳态水平一半的时间，并以闭合形式求解$\\theta_{\\mathrm{on}}$。\n(c) 假设系统在$X=X_{0}$下已达到稳态，然后在稍后的时间$t=T_{\\mathrm{off}}$，$X$瞬时切换为$0$。定义无量纲的关闭半衰期$\\theta_{\\mathrm{off}} = \\beta\\,(t_{\\mathrm{off}}-T_{\\mathrm{off}})$为关闭后$Z$衰减到其先前稳态水平一半所需的时间，并以闭合形式求解$\\theta_{\\mathrm{off}}$。\n(d) 使用(b)和(c)部分的结果，计算无量纲的延迟差$\\Delta \\theta = \\theta_{\\mathrm{on}} - \\theta_{\\mathrm{off}}$，给出一个单一的闭合形式解析表达式。\n\n在您的推导中解释为什么“与”逻辑门、可忽略的基础活性以及$X \\to Y \\to Z$的时间顺序共同作用，导致该基序产生符号敏感延迟（开启慢，关闭快）。最终答案必须仅为$\\Delta \\theta$的表达式。不需要进行数值计算，最终答案中也不应包含单位。",
            "solution": "用户提供的问题被评估为有效，因为它在科学上基于生物化学动力学和系统生物学的原理，问题阐述清晰，定义和约束条件完整，并以客观、形式化的语言表达。\n\n### 第1部分：常微分方程（ODE）的推导\n\n基因产物$Y$和$Z$的浓度动态由平衡生产和降解的一阶常微分方程建模。\n\n$Y$的浓度（表示为$[Y]$）的变化率由$X$激活的生产速率减去其一级降解速率给出。激活由希尔函数$f_X(X)$描述，最大生产速率为$\\alpha_Y$，降解速率为$\\beta_Y$。因此，$Y$的ODE为：\n$$ \\frac{d[Y]}{dt} = \\alpha_Y f_X([X]) - \\beta_Y [Y] $$\n为简化起见，我们将浓度$[X]$、$[Y]$和$[Z]$表示为$X$、$Y$和$Z$。\n$$ \\frac{dY}{dt} = \\alpha_Y f_X(X) - \\beta_Y Y $$\n\n$Z$的生产由$X$和$Y$共同激活。问题指出该调控实现了一个“与”逻辑门，模型化为各个希尔函数$g_X(X)$和$h_Y(Y)$的乘积。$Z$的最大生产速率为$\\alpha_Z$，其降解速率为$\\beta_Z$。因此，$Z$的ODE为：\n$$ \\frac{dZ}{dt} = \\alpha_Z g_X(X) h_Y(Y) - \\beta_Z Z $$\n\n### 第2部分：符号敏感延迟的分析\n\n我们现在应用为分析所提供的具体假设。\n\n#### (a) 开启响应中$Z(t)$的推导\n\n假设如下：\n- 希尔系数$n=1$，因此希尔函数为$f(U) = \\frac{U}{K+U}$。\n- 对于$t \\ge 0$，输入$X(t) = X_0$。\n- 初始条件$Y(0)=0$和$Z(0)=0$。\n- “与”门生产项为$\\alpha_Z g_X(X) h_Y(Y)$。\n- $Y$的弱激活：$Y(t) \\ll K_Y$，因此$h_Y(Y) = \\frac{Y}{K_Y+Y} \\approx \\frac{Y}{K_Y}$。\n- 相等的降解速率：$\\beta_Y = \\beta_Z = \\beta > 0$。\n\n首先，我们求解$Y(t)$。$Y$的ODE变为：\n$$ \\frac{dY}{dt} = \\alpha_Y \\frac{X_0}{K_X + X_0} - \\beta Y $$\n其中$K_X$是$X \\to Y$环节的激活常数。\n这是一个线性一阶常微分方程。设恒定生产项为$S_Y = \\alpha_Y \\frac{X_0}{K_X + X_0}$。方程为$\\frac{dY}{dt} + \\beta Y = S_Y$。在初始条件$Y(0)=0$下的解为：\n$$ Y(t) = \\frac{S_Y}{\\beta} (1 - \\exp(-\\beta t)) = Y_{ss} (1 - \\exp(-\\beta t)) $$\n其中$Y_{ss} = S_Y/\\beta$是$Y$的稳态浓度。\n\n接下来，我们求解$Z(t)$。$Z$的ODE为：\n$$ \\frac{dZ}{dt} = \\alpha_Z \\left( \\frac{X_0}{K'_X + X_0} \\right) \\left( \\frac{Y(t)}{K_Y} \\right) - \\beta Z $$\n其中$K'_X$和$K_Y$分别是$X \\to Z$和$Y \\to Z$环节的激活常数。我们将常数项归为一个生产常数$S_Z = \\frac{\\alpha_Z}{K_Y} \\frac{X_0}{K'_X+X_0}$。\nODE变为：\n$$ \\frac{dZ}{dt} + \\beta Z = S_Z Y(t) = S_Z Y_{ss} (1 - \\exp(-\\beta t)) $$\n这是一个线性一阶非齐次常微分方程。我们使用积分因子$\\mu(t) = \\exp(\\int \\beta dt) = \\exp(\\beta t)$来求解。\n$$ \\frac{d}{dt}(Z \\exp(\\beta t)) = S_Z Y_{ss} (1 - \\exp(-\\beta t)) \\exp(\\beta t) = S_Z Y_{ss} (\\exp(\\beta t) - 1) $$\n从$0$到$t$积分：\n$$ Z(t)\\exp(\\beta t) - Z(0)\\exp(0) = \\int_0^t S_Z Y_{ss} (\\exp(\\beta \\tau) - 1) d\\tau $$\n使用$Z(0)=0$：\n$$ Z(t)\\exp(\\beta t) = S_Z Y_{ss} \\left[ \\frac{1}{\\beta}\\exp(\\beta \\tau) - \\tau \\right]_0^t = S_Z Y_{ss} \\left( (\\frac{1}{\\beta}\\exp(\\beta t) - t) - (\\frac{1}{\\beta} - 0) \\right) $$\n$$ Z(t) = S_Z Y_{ss} \\left( \\frac{1}{\\beta} - t \\exp(-\\beta t) - \\frac{1}{\\beta}\\exp(-\\beta t) \\right) $$\n$Z$的稳态值为$Z_{ss} = \\lim_{t\\to\\infty} Z(t) = \\frac{S_Z Y_{ss}}{\\beta}$。\n将其代回，我们得到$Z(t)$的表达式：\n$$ Z(t) = Z_{ss} (1 - \\exp(-\\beta t) - \\beta t \\exp(-\\beta t)) $$\n\n#### (b) 无量纲开启半衰期$\\theta_{\\mathrm{on}}$的推导\n\n开启半衰期$t_{\\mathrm{on}}$是$Z(t_{\\mathrm{on}}) = \\frac{1}{2}Z_{ss}$的时间点。\n$$ \\frac{1}{2} Z_{ss} = Z_{ss} (1 - \\exp(-\\beta t_{\\mathrm{on}}) - \\beta t_{\\mathrm{on}} \\exp(-\\beta t_{\\mathrm{on}})) $$\n$$ \\frac{1}{2} = 1 - (1 + \\beta t_{\\mathrm{on}}) \\exp(-\\beta t_{\\mathrm{on}}) $$\n$$ (1 + \\beta t_{\\mathrm{on}}) \\exp(-\\beta t_{\\mathrm{on}}) = \\frac{1}{2} $$\n设$\\theta_{\\mathrm{on}} = \\beta t_{\\mathrm{on}}$。方程变为：\n$$ (1 + \\theta_{\\mathrm{on}}) \\exp(-\\theta_{\\mathrm{on}}) = \\frac{1}{2} $$\n这是一个超越方程，其解可以用朗伯W函数$W(z)$表示，$W(z)$被定义为$z = W(z) \\exp(W(z))$的解。为了将我们的方程转换成这种形式，设$u = -(1 + \\theta_{\\mathrm{on}})$。则$\\theta_{\\mathrm{on}} = -u-1$。\n$$ (-u) \\exp(-(-u-1)) = \\frac{1}{2} \\implies -u \\exp(u+1) = \\frac{1}{2} \\implies u \\exp(u) = -\\frac{1}{2e} $$\n解为$u = W_k(-\\frac{1}{2e})$，其中$k$是分支指数。由于$\\theta_{\\mathrm{on}} = \\beta t_{\\mathrm{on}}$必须是一个正实数，我们需要$\\theta_{\\mathrm{on}} = -u-1 > 0$，这意味着$u < -1$。参数$-\\frac{1}{2e}$在区间$[-\\frac{1}{e}, 0)$内，对于该区间，朗伯W函数存在两个实数分支，$W_0$和$W_{-1}$。主分支$W_0$的范围是$[-1, \\infty)$，而$W_{-1}$分支的范围是$(-\\infty, -1]$。为了满足$u < -1$，我们必须选择$k=-1$分支。\n$$ u = W_{-1}\\left(-\\frac{1}{2e}\\right) $$\n因此，无量纲的开启半衰期为：\n$$ \\theta_{\\mathrm{on}} = -1 - u = -1 - W_{-1}\\left(-\\frac{1}{2e}\\right) $$\n\n#### (c) 无量纲关闭半衰期$\\theta_{\\mathrm{off}}$的推导\n\n对于关闭响应，系统从稳态开始（$Y(T_{\\mathrm{off}}) = Y_{ss}$，$Z(T_{\\mathrm{off}})=Z_{ss}$），在时间$t=T_{\\mathrm{off}}$时，输入切换为$X=0$。由于$f_X(0)=0$和$g_X(0)=0$，所有生产都停止了。对于时间$t' = t - T_{\\mathrm{off}} \\ge 0$，$Z$的ODE为：\n$$ \\frac{dZ}{dt'} = -\\beta Z $$\n初始条件为$Z(t'=0) = Z_{ss}$。解是简单的指数衰减：\n$$ Z(t') = Z_{ss} \\exp(-\\beta t') $$\n关闭半衰期$t'_{\\mathrm{off}} = t_{\\mathrm{off}} - T_{\\mathrm{off}}$是$Z(t'_{\\mathrm{off}}) = \\frac{1}{2}Z_{ss}$的时间点。\n$$ \\frac{1}{2} Z_{ss} = Z_{ss} \\exp(-\\beta t'_{\\mathrm{off}}) $$\n$$ \\frac{1}{2} = \\exp(-\\beta t'_{\\mathrm{off}}) $$\n两边取自然对数：\n$$ \\ln\\left(\\frac{1}{2}\\right) = -\\beta t'_{\\mathrm{off}} \\implies -\\ln(2) = -\\beta t'_{\\mathrm{off}} $$\n无量纲的关闭半衰期是$\\theta_{\\mathrm{off}} = \\beta t'_{\\mathrm{off}}$，这给出：\n$$ \\theta_{\\mathrm{off}} = \\ln(2) $$\n\n#### (d) 无量纲延迟差$\\Delta\\theta$的计算\n\n无量纲的延迟差为$\\Delta\\theta = \\theta_{\\mathrm{on}} - \\theta_{\\mathrm{off}}$。\n$$ \\Delta\\theta = \\left(-1 - W_{-1}\\left(-\\frac{1}{2e}\\right)\\right) - \\ln(2) $$\n\n### 符号敏感延迟的解释\n\n具有“与”逻辑的C1-FFL固有地产生符号敏感延迟，其特征是开启响应慢而关闭响应快。\n**关闭响应快**是因为$Z$的生产需要$X$和$Y$同时存在。当输入信号$X$被关闭时，$Z$的生产项$\\alpha_Z g_X(X) h_Y(Y)$立即降为零，因为$g_X(0)=0$。然后$Z$的浓度以速率常数$\\beta$指数衰减，这是一个快速的过程。系统不需要等待$Y$衰减；关闭过程直接由$X$门控。\n**开启响应慢**是由于中间产物$Y$积累的延迟。当$X$被开启时，$Z$的生产不能立即以最大速率开始。尽管来自$X \\to Z$路径的输入存在，但来自$Y \\to Z$路径的输入最初为零（$Y(0)=0$）。只有当$Y$自身被生产并积累时，$Z$的生产才会逐渐增加。这种两步激活级联（$X \\to Y$和$(X,Y) \\to Z$）产生了一个滞后。在数学上，这种滞后是显而易见的，因为$Z$在$t=0$时的时间导数为零：$\\frac{dZ}{dt}|_{t=0} = S_Z Y(0) - \\beta Z(0) = 0$。这与简单的单输入系统形成对比，后者的初始生产速率将是最大的。由此产生的$Z(t)$响应曲线是S形的，反映了在较快上升之前的初始滞后阶段。这种机制使该基序能够作为*持续性检测器*，滤除那些不足以使$Y$充分积累的短暂输入脉冲。\n差异$\\Delta \\theta$量化了响应时间上的这种不对称性。由于$\\theta_{\\mathrm{on}} \\approx 1.678$（来自符号结果的数值评估）而$\\theta_{\\mathrm{off}} = \\ln(2) \\approx 0.693$，因此开启时间显著长于关闭时间。",
            "answer": "$$\n\\boxed{-1 - W_{-1}\\left(-\\frac{1}{2e}\\right) - \\ln(2)}\n$$"
        },
        {
            "introduction": "模体的重要性也可以在单个节点的层面上进行分析，以表征它们在网络中的功能角色。一个节点的功能与其帮助形成的局部网络结构密切相关。这个综合性的计算练习  将引导您完成一个完整的分析流程：从计算一个节点在不同模体中的参与度，到将这些计数与一个零模型进行比较，最后利用得到的统计档案（例如$z$分数）将节点分类为不同的功能类别，如“团簇导向型”或“中介导向型”。",
            "id": "4291115",
            "problem": "给定由邻接矩阵表示的无向简单图。您的任务是为每个节点计算节点级模体参与概况，并利用这些概况将节点分类为不同的功能角色。所考虑的模体是3节点三角形和3节点楔形（以一个节点为中心的开放三元组）。分类必须从第一性原理出发进行计算，并且是确定性的。\n\n基本定义和约束：\n- 图由一个对称邻接矩阵 $A \\in \\{0,1\\}^{n \\times n}$ 表示，其中对所有 $i$ 都有 $A_{ii} = 0$，$n$ 是节点数。\n- 对于节点 $i$，令 $N(i) = \\{j \\in \\{1,\\dots,n\\} \\mid A_{ij} = 1\\}$ 表示其邻居集合，而 $d_i = |N(i)|$ 表示其度。\n- 节点 $i$ 参与的三角形定义为 $N(i)$ 中满足 $A_{jk}=1$ 的任意一个无序对 $\\{j,k\\}$。节点级三角形计数为\n$$\nT_i = \\sum_{\\{j,k\\} \\subset N(i),\\, j < k} A_{jk}\n$$\n- 节点 $i$ 参与的楔形定义为 $N(i)$ 中不满足 $A_{jk}=1$ 的任意一个无序对 $\\{j,k\\}$。节点级楔形计数为\n$$\nW_i = \\binom{d_i}{2} - T_i\n$$\n- 零模型：度保持随机化。零模型系综通过对原始图执行大量的度保持双边互换来生成。你的分析必须使用一个由 $R=200$ 个随机网络组成的系综，每个网络都是通过对原始图执行 $S=400$ 次成功的度保持交换生成的。\n- 显著性得分：对于每个节点 $i$ 和每种模体类型（$T$ 或 $W$），计算其 $z$-分数：\n$$\nz_{T,i} = \\frac{T_i - \\mu_{T,i}}{\\sigma_{T,i}}, \\quad z_{W,i} = \\frac{W_i - \\mu_{W,i}}{\\sigma_{W,i}}\n$$\n其中 $\\mu$ 和 $\\sigma$ 分别是零模型系综中的均值和样本标准差。如果 $\\sigma=0$，则相应的 $z$-分数应定义为0。\n- 功能角色分类：对于每个节点 $i$，根据以下确定性规则分配一个角色：\n  - 角色 0（外围节点）：如果 $d_i < 2$。\n  - 角色 1（团簇导向型）：如果 $d_i \\ge 2$ 且 $z_{T,i} \\ge z_{W,i}$。\n  - 角色 2（中介导向型）：如果 $d_i \\ge 2$ 且 $z_{T,i} < z_{W,i}$。\n\n最终解决方案必须是一个名为 `solve` 的 Python 函数，该函数不接受任何参数，并打印出包含三个测试用例结果的列表的列表。这三个测试用例是：\n1. `n=6`，边 `[(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(0,4),(4,5)]`，随机数种子 `202311`。\n2. `n=6`，边 `[(0,1),(1,2),(2,3),(3,4),(4,5),(5,0)]`，随机数种子 `202312`。\n3. `n=6`，边 `[(0,1),(0,2),(0,3),(0,4),(0,5)]`，随机数种子 `202313`。\n\n输出必须是打印到标准输出的一行文本，不含空格，格式为 `[[r1_1,...,r1_n],[r2_1,...,r2_n],[r3_1,...,r3_n]]`，其中 `r_ij` 是第 `i` 个测试用例中节点 `j` 的角色。",
            "solution": "我们从无向简单图的基本表示法开始，即一个对角线为零的对称邻接矩阵 $A \\in \\{0,1\\}^{n \\times n}$。对于每个节点 $i$，其邻居集合 $N(i)$ 和度 $d_i$ 定义为 $N(i) = \\{j \\mid A_{ij} = 1\\}$ 和 $d_i = |N(i)|$。\n\n所考虑的节点级模体是三角形和楔形（以该节点为中心的开放三元组）。三角形计数 $T_i$ 计算了 $N(i)$ 中相互连接的无序邻居对 $\\{j,k\\}$ 的数量，而楔形计数 $W_i$ 则计算了不相互连接的无序邻居对的数量。形式上，\n$$\nT_i = \\sum_{\\{j,k\\} \\subset N(i),\\, j < k} A_{jk} \\quad \\text{and} \\quad W_i = \\binom{d_i}{2} - T_i\n$$\n\n为了评估这些计数的统计显著性，我们将其与一个零模型进行比较，该模型保留了每个节点的度，但除此之外是随机的。这通常通过双边互换方法实现，即随机选择两条不共享节点的边 $(u,v)$ 和 $(x,y)$，并将它们重新连接为 $(u,x)$ 和 $(v,y)$（或 $(u,y)$ 和 $(v,x)$），前提是新边不存在。\n\n问题要求我们为每个节点计算其在三角形和楔形参与度上的 $z$-分数。为此，我们：\n1. 计算原始图中每个节点的观测计数 $T_i$ 和 $W_i$。\n2. 生成一个包含 $R=200$ 个随机图的系综。每个随机图都是通过对原始图执行 $S=400$ 次成功的度保持边交换生成的。\n3. 对于每个随机图，我们计算每个节点的 $T_i$ 和 $W_i$。这将为每个节点和每种模体类型生成200个样本。\n4. 基于这些样本，我们计算每个节点的均值 $\\mu_{T,i}, \\mu_{W,i}$ 和样本标准差 $\\sigma_{T,i}, \\sigma_{W,i}$。\n5. 使用这些统计数据计算最终的 $z$-分数 $z_{T,i}$ 和 $z_{W,i}$。\n\n最后，根据问题中提供的确定性规则将节点分类为角色0、1或2。\n\n下面的Python代码实现了这个完整的流程。`randomize_graph` 函数通过执行指定数量的成功交换来生成一个随机图。`classify_roles` 函数协调整个过程，从计数到 $z$-分数计算再到最终分类。`solve` 函数运行给定的三个测试用例并以指定格式打印结果。该代码确定性地遵循问题中定义的所有步骤。\n\nThe Python code below implements this by performing $S$ successful swaps for each of the $R$ randomized replicates, with a safeguard to limit the total number of attempts. This ensures that each randomized graph is separated from the original by the same number of rewiring steps.",
            "answer": "```python\nimport numpy as np\n\ndef build_adjacency(n, edges):\n    \"\"\"Build symmetric adjacency matrix for an undirected simple graph.\"\"\"\n    A = np.zeros((n, n), dtype=int)\n    for u, v in edges:\n        if u == v:\n            continue\n        A[u, v] = 1\n        A[v, u] = 1\n    np.fill_diagonal(A, 0)\n    return A\n\ndef neighbors_of(A, i):\n    \"\"\"Return neighbors of node i.\"\"\"\n    return np.where(A[i] == 1)[0]\n\ndef count_triangles_wedges_per_node(A):\n    \"\"\"Count triangles and wedges per node.\"\"\"\n    n = A.shape[0]\n    triangles = np.zeros(n, dtype=int)\n    wedges = np.zeros(n, dtype=int)\n    for i in range(n):\n        nbrs = neighbors_of(A, i)\n        k = len(nbrs)\n        if k < 2:\n            continue\n        # count unordered pairs among neighbors\n        for a in range(k):\n            for b in range(a + 1, k):\n                u, v = nbrs[a], nbrs[b]\n                if A[u, v] == 1:\n                    triangles[i] += 1\n                else:\n                    wedges[i] += 1\n    return triangles, wedges\n\ndef get_edge_list(A):\n    \"\"\"Return list of undirected edges (u,v) with u < v.\"\"\"\n    n = A.shape[0]\n    edges = []\n    for u in range(n):\n        for v in range(u + 1, n):\n            if A[u, v] == 1:\n                edges.append((u, v))\n    return edges\n\ndef attempt_swap(A, rng):\n    \"\"\"Attempt a single degree-preserving edge swap; return True if performed.\"\"\"\n    edges = get_edge_list(A)\n    m = len(edges)\n    if m < 2:\n        return False\n    # choose two distinct edges uniformly at random\n    idx = rng.choice(m, size=2, replace=False)\n    (u, v) = edges[idx[0]]\n    (x, y) = edges[idx[1]]\n    # ensure all endpoints distinct\n    if len({u, v, x, y}) < 4:\n        return False\n    # choose one of two rewiring options at random\n    if rng.random() < 0.5:\n        a, b = u, y\n        c, d = x, v\n    else:\n        a, b = u, x\n        c, d = v, y\n    # avoid self-loops and existing edges\n    if A[a, b] == 1 or A[c, d] == 1:\n        return False\n    # perform swap: remove original edges, add new edges\n    A[u, v] = A[v, u] = 0\n    A[x, y] = A[y, x] = 0\n    A[a, b] = A[b, a] = 1\n    A[c, d] = A[d, c] = 1\n    return True\n\ndef randomize_graph(A, S_successful, rng):\n    \"\"\"Return a randomized graph via S_successful degree-preserving swaps.\"\"\"\n    Ar = A.copy()\n    successes = 0\n    # Use a generous attempt limit to avoid infinite loops\n    max_attempts = S_successful * 100\n    attempts = 0\n    while successes < S_successful and attempts < max_attempts:\n        if attempt_swap(Ar, rng):\n            successes += 1\n        attempts += 1\n    return Ar\n\ndef null_stats(A, R, S, rng):\n    \"\"\"Compute null model mean and std for triangles and wedges per node.\"\"\"\n    n = A.shape[0]\n    tri_samples = np.zeros((R, n), dtype=float)\n    wed_samples = np.zeros((R, n), dtype=float)\n    for r in range(R):\n        Ar = randomize_graph(A, S, rng)\n        T, W = count_triangles_wedges_per_node(Ar)\n        tri_samples[r] = T\n        wed_samples[r] = W\n    mu_T = tri_samples.mean(axis=0)\n    mu_W = wed_samples.mean(axis=0)\n    if R > 1:\n        sigma_T = tri_samples.std(axis=0, ddof=1)\n        sigma_W = wed_samples.std(axis=0, ddof=1)\n    else:\n        sigma_T = np.zeros(n, dtype=float)\n        sigma_W = np.zeros(n, dtype=float)\n    return mu_T, sigma_T, mu_W, sigma_W\n\ndef classify_roles(A, R, S, seed):\n    \"\"\"Classify nodes into roles 0,1,2 based on node-level motif z-scores.\"\"\"\n    rng = np.random.default_rng(seed)\n    degrees = A.sum(axis=1)\n    T_obs, W_obs = count_triangles_wedges_per_node(A)\n    mu_T, sigma_T, mu_W, sigma_W = null_stats(A, R, S, rng)\n    \n    z_T = np.zeros_like(mu_T)\n    z_W = np.zeros_like(mu_W)\n    np.divide(T_obs - mu_T, sigma_T, out=z_T, where=sigma_T>0)\n    np.divide(W_obs - mu_W, sigma_W, out=z_W, where=sigma_W>0)\n    \n    roles = []\n    for i in range(A.shape[0]):\n        if degrees[i] < 2:\n            roles.append(0)  # peripheral\n        else:\n            if z_T[i] >= z_W[i]:\n                roles.append(1)  # clique-oriented\n            else:\n                roles.append(2)  # broker-oriented\n    return roles\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, edges, R, S, seed)\n        (6, [(0,1),(0,2),(0,3),(1,2),(1,3),(2,3),(0,4),(4,5)], 200, 400, 202311),\n        (6, [(0,1),(1,2),(2,3),(3,4),(4,5),(5,0)], 200, 400, 202312),\n        (6, [(0,1),(0,2),(0,3),(0,4),(0,5)], 200, 400, 202313),\n    ]\n\n    results = []\n    for n, edges, R, S, seed in test_cases:\n        A = build_adjacency(n, edges)\n        roles = classify_roles(A, R, S, seed)\n        results.append(roles)\n\n    # Format the output as a single line with no spaces: [[...],[...],[...]]\n    formatted = \"[\" + \",\".join(\"[\" + \",\".join(map(str, r)) + \"]\" for r in results) + \"]\"\n    print(formatted)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}