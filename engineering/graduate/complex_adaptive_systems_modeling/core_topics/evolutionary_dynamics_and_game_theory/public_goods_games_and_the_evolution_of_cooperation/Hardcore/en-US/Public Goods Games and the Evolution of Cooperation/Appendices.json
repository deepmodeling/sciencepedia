{
    "hands_on_practices": [
        {
            "introduction": "To begin our hands-on exploration, we first need to analytically solidify the core conflict inherent in public goods games. This exercise challenges you to quantify the \"tragedy of the commons\" by comparing the outcome driven by individual self-interest (the Nash Equilibrium) with the outcome that is best for the group as a whole (the Social Optimum). By deriving both results from first principles in a model with quadratic costs, you will gain a precise understanding of why cooperation is fundamentally difficult to sustain and how the severity of this social dilemma scales with group size.",
            "id": "4137988",
            "problem": "Consider a homogeneous group of $N$ agents engaged in a one-shot public goods game. Each agent $i \\in \\{1,\\dots,N\\}$ chooses a nonnegative contribution $x_i \\ge 0$ to a public project. The individual payoff to agent $i$ is given by\n$$\n\\pi_i(x_i,\\mathbf{x}_{-i}) \\;=\\; r \\,\\frac{\\sum_{j=1}^{N} x_j}{N} \\;-\\; \\frac{1}{2}\\,a\\,x_i^{2},\n$$\nwhere $r0$ is the linear per-capita return from the public good, $a0$ is the curvature parameter of quadratic cost, and $\\mathbf{x}_{-i}$ denotes the vector of contributions of the other agents.\n\nStarting from the formal definitions that (i) a Nash equilibrium is a profile in which each agent’s contribution maximizes her own payoff given the contributions of the others, and (ii) the social optimum is the contribution profile that maximizes the aggregate payoff $\\sum_{i=1}^{N} \\pi_i$, assume the equilibrium and social optimum are symmetric and interior (i.e., $x_i=x$ for all $i$ and $x0$), and derive the symmetric Nash equilibrium contribution per agent $x^{\\mathrm{NE}}$ and the symmetric social optimum contribution per agent $x^{\\mathrm{SO}}$ from first principles. Then provide, as your final answer, the closed-form expression for the ratio $x^{\\mathrm{NE}}/x^{\\mathrm{SO}}$ as a function of $N$ only. No numerical rounding is required and no units are associated with the answer.",
            "solution": "The problem is valid as it is scientifically grounded in the economic theory of public goods, is well-posed, objective, and internally consistent. We will proceed with the derivation.\n\nThe goal is to derive the symmetric Nash equilibrium contribution per agent, $x^{\\mathrm{NE}}$, and the symmetric social optimum contribution per agent, $x^{\\mathrm{SO}}$, and then to compute their ratio.\n\nFirst, we determine the symmetric Nash equilibrium contribution, $x^{\\mathrm{NE}}$. A Nash equilibrium is a strategy profile where each agent's choice is a best response to the choices of all other agents. This means that for each agent $i \\in \\{1, \\dots, N\\}$, their contribution $x_i$ must maximize their individual payoff $\\pi_i$, given the contributions $\\mathbf{x}_{-i}$ of the other agents.\n\nThe payoff function for agent $i$ is:\n$$\n\\pi_i(x_i, \\mathbf{x}_{-i}) = r \\frac{\\sum_{j=1}^{N} x_j}{N} - \\frac{1}{2} a x_i^2\n$$\nTo find the optimal contribution for agent $i$, we treat the contributions of other agents, $\\sum_{j \\neq i}x_j$, as fixed and maximize $\\pi_i$ with respect to $x_i$. We can rewrite the payoff function to isolate the terms dependent on $x_i$:\n$$\n\\pi_i(x_i, \\mathbf{x}_{-i}) = r \\frac{x_i + \\sum_{j \\neq i} x_j}{N} - \\frac{1}{2} a x_i^2 = \\frac{r}{N} x_i + \\frac{r}{N}\\sum_{j \\neq i} x_j - \\frac{1}{2} a x_i^2\n$$\nTo find the maximum, we take the first-order condition (FOC) by differentiating $\\pi_i$ with respect to $x_i$ and setting the result to zero:\n$$\n\\frac{\\partial \\pi_i}{\\partial x_i} = \\frac{\\partial}{\\partial x_i} \\left( \\frac{r}{N} x_i + \\frac{r}{N}\\sum_{j \\neq i} x_j - \\frac{1}{2} a x_i^2 \\right) = \\frac{r}{N} - a x_i\n$$\nSetting the derivative to zero gives the best response for agent $i$:\n$$\n\\frac{r}{N} - a x_i = 0 \\quad \\implies \\quad x_i = \\frac{r}{aN}\n$$\nTo confirm this is a maximum, we check the second-order condition (SOC):\n$$\n\\frac{\\partial^2 \\pi_i}{\\partial x_i^2} = -a\n$$\nSince $a0$, the second derivative is negative, indicating that the payoff function is strictly concave in $x_i$, and thus $x_i = \\frac{r}{aN}$ is indeed a unique maximum.\n\nThe problem asks for a symmetric Nash equilibrium, where $x_i = x$ for all $i$. The best-response function derived above, $x_i = \\frac{r}{aN}$, is independent of the other agents' contributions. Therefore, in a symmetric equilibrium, every agent will choose this level of contribution. Thus, the symmetric Nash equilibrium contribution per agent is:\n$$\nx^{\\mathrm{NE}} = \\frac{r}{aN}\n$$\nSince $r0$, $a0$, and $N \\ge 1$, we have $x^{\\mathrm{NE}}  0$, satisfying the condition for an interior solution.\n\nNext, we determine the symmetric social optimum contribution, $x^{\\mathrm{SO}}$. The social optimum is the contribution profile that maximizes the aggregate payoff of all agents, $\\Pi = \\sum_{i=1}^{N} \\pi_i$.\nThe aggregate payoff is:\n$$\n\\Pi(\\mathbf{x}) = \\sum_{i=1}^{N} \\pi_i(\\mathbf{x}) = \\sum_{i=1}^{N} \\left( r \\frac{\\sum_{j=1}^{N} x_j}{N} - \\frac{1}{2} a x_i^2 \\right)\n$$\nLet $X = \\sum_{j=1}^{N} x_j$ be the total contribution. The aggregate payoff simplifies to:\n$$\n\\Pi(\\mathbf{x}) = \\sum_{i=1}^{N} \\left( \\frac{rX}{N} \\right) - \\sum_{i=1}^{N} \\left( \\frac{1}{2} a x_i^2 \\right) = N \\left(\\frac{rX}{N}\\right) - \\frac{1}{2} a \\sum_{i=1}^{N} x_i^2 = r \\sum_{j=1}^{N} x_j - \\frac{1}{2} a \\sum_{i=1}^{N} x_i^2\n$$\nThe problem states we are looking for a symmetric social optimum, where $x_i = x$ for all $i$. Under this assumption, the total contribution is $X = Nx$, and the sum of squared contributions is $\\sum_{i=1}^{N} x_i^2 = Nx^2$. Substituting these into the aggregate payoff function gives a function of the single variable $x$:\n$$\n\\Pi(x) = r(Nx) - \\frac{1}{2} a (Nx^2) = Nrx - \\frac{N}{2} a x^2\n$$\nTo find the value of $x$ that maximizes this aggregate payoff, we take the first-order condition with respect to $x$:\n$$\n\\frac{d\\Pi}{dx} = \\frac{d}{dx} \\left( Nrx - \\frac{N}{2} a x^2 \\right) = Nr - Nax\n$$\nSetting the derivative to zero:\n$$\nNr - Nax = 0 \\quad \\implies \\quad x = \\frac{Nr}{Na} = \\frac{r}{a}\n$$\nTo confirm this is a maximum, we check the second-order condition:\n$$\n\\frac{d^2\\Pi}{dx^2} = -Na\n$$\nSince $N \\ge 1$ and $a0$, the second derivative is negative, confirming that $x = \\frac{r}{a}$ corresponds to a maximum. Thus, the symmetric social optimum contribution per agent is:\n$$\nx^{\\mathrm{SO}} = \\frac{r}{a}\n$$\nSince $r0$ and $a0$, we have $x^{\\mathrm{SO}}  0$, satisfying the condition for an interior solution.\n\nFinally, we compute the ratio $x^{\\mathrm{NE}}/x^{\\mathrm{SO}}$.\n$$\n\\frac{x^{\\mathrm{NE}}}{x^{\\mathrm{SO}}} = \\frac{\\frac{r}{aN}}{\\frac{r}{a}}\n$$\nSimplifying the expression:\n$$\n\\frac{x^{\\mathrm{NE}}}{x^{\\mathrm{SO}}} = \\frac{r}{aN} \\cdot \\frac{a}{r} = \\frac{1}{N}\n$$\nThe ratio depends only on the number of agents, $N$.",
            "answer": "$$\n\\boxed{\\frac{1}{N}}\n$$"
        },
        {
            "introduction": "Having established the fundamental tension between individual and collective interests , we now turn to the dynamics of how cooperation can evolve. This practice moves beyond static analysis by introducing the replicator equation, a cornerstone of evolutionary game theory, to model how the frequency of cooperators changes over time. You will analyze a system where cooperation is buttressed by peer punishment, a common mechanism for enforcing social norms, and determine the stability of different outcomes, thereby exploring how specific mechanisms can overcome the free-rider problem.",
            "id": "4138004",
            "problem": "Consider an infinite, well-mixed population engaged in a Public Goods Game (PGG) with peer punishment. A fraction $x(t)$ of the population are cooperators and the rest are defectors. Groups of size $n$ are formed uniformly at random. Each cooperator pays a cost $c$ to contribute to a public pool; total contributions in a group with $k$ cooperators are multiplied by a return factor $r$ and then divided equally among all group members. Peer punishment operates as follows: each cooperator punishes each defector at a cost $\\gamma$ to the cooperator, imposing a fine $\\beta$ on the defector.\n\nYou may assume the following foundational elements:\n- Replicator dynamics for two strategies are defined by the ordinary differential equation (ODE) $\\dot{x} = x(\\pi_{C} - \\bar{\\pi})$, where $\\pi_{C}$ is the expected payoff of cooperators, $\\pi_{D}$ is the expected payoff of defectors, and $\\bar{\\pi} = x \\pi_{C} + (1-x) \\pi_{D}$ is the mean payoff.\n- For two strategies, the replicator dynamics reduce to $\\dot{x} = x(1-x)(\\pi_{C} - \\pi_{D})$.\n- In an infinite, well-mixed population with random group formation, the number $K$ of other cooperators among the $n-1$ co-players is distributed as $\\mathrm{Binomial}(n-1, x)$, hence $\\mathbb{E}[K] = (n-1)x$.\n- Payoffs in a group with $k$ cooperators are: $P_{C}(k) = r \\frac{k c}{n} - c - \\gamma (n-k)$ for a cooperator and $P_{D}(k) = r \\frac{k c}{n} - \\beta k$ for a defector.\n\nUsing only these definitions and facts, derive the one-dimensional replicator ODE for $x(t)$ for the parameter values $n = 5$, $c = 1$, $r = 3$, $\\beta = 0.5$, and $\\gamma = 0.1$. Identify all fixed points in $[0,1]$ and compute the Jacobian eigenvalue (which equals $\\frac{d}{dx}\\dot{x}$ for this one-dimensional system) at each fixed point. Express each eigenvalue in exact rational form. Present the final answer as a single row matrix $\\begin{pmatrix} \\lambda_{0}  \\lambda_{*}  \\lambda_{1} \\end{pmatrix}$, corresponding respectively to the equilibria $x=0$, the interior equilibrium $x^{*}$ (if it exists in $(0,1)$), and $x=1$. No units are required in your final answer. Do not round; provide exact rational values.",
            "solution": "The user wants me to analyze a public goods game with peer punishment using replicator dynamics.\n\n### Step 1: Problem Validation\n\nFirst, I must meticulously validate the problem statement.\n\n#### Extracted Givens\n-   **Model**: Replicator dynamics for a Public Goods Game (PGG) with peer punishment in an infinite, well-mixed population.\n-   **Population structure**: A fraction $x(t)$ of the population are cooperators, and $1-x(t)$ are defectors.\n-   **Game structure**: Groups of size $n$ are formed uniformly at random.\n-   **Cooperator's action**: Pay cost $c$ to contribute.\n-   **Public good**: Total contributions in a group with $k$ cooperators are multiplied by a factor $r$ and divided equally among all $n$ members.\n-   **Punishment structure**: Each cooperator punishes each defector at a cost $\\gamma$ to the cooperator, inflicting a fine $\\beta$ on the defector.\n-   **Replicator ODE**: $\\dot{x} = x(\\pi_{C} - \\bar{\\pi})$, which simplifies to $\\dot{x} = x(1-x)(\\pi_{C} - \\pi_{D})$. $\\pi_{C}$ is the expected payoff for cooperators, $\\pi_{D}$ for defectors.\n-   **Co-player distribution**: The number of cooperators $K$ among $n-1$ co-players follows a Binomial distribution, $K \\sim \\mathrm{Binomial}(n-1, x)$, with expectation $\\mathbb{E}[K] = (n-1)x$.\n-   **Payoff functions (in a group with $k$ cooperators out of $n$ members)**:\n    -   Payoff for a cooperator: $P_{C}(k) = r \\frac{k c}{n} - c - \\gamma (n-k)$.\n    -   Payoff for a defector: $P_{D}(k) = r \\frac{k c}{n} - \\beta k$.\n-   **Parameter values**: $n = 5$, $c = 1$, $r = 3$, $\\beta = 0.5$, $\\gamma = 0.1$.\n\n#### Validation using Extracted Givens\n1.  **Scientific Grounding**: The problem is well-grounded in the established theory of evolutionary game theory and the study of cooperation. The replicator equation and the PGG with punishment are canonical models in this field.\n2.  **Well-Posedness**: The problem provides all necessary definitions, equations, and parameter values to uniquely determine the replicator ODE, its fixed points, and their stability. The task is specific and answerable.\n3.  **Objectivity**: The language is precise, mathematical, and free of subjective or ambiguous terminology.\n4.  **Consistency**: The payoff functions are consistent with the description of the game. For a cooperator in a group with $k$ cooperators and $n-k$ defectors, the payoff is: (share of public good) - (cost of contribution) - (cost of punishing all defectors), which is $r\\frac{kc}{n} - c - \\gamma(n-k)$. For a defector in a group with $k$ cooperators, the payoff is: (share of public good) - (fine from all cooperators), which is $r\\frac{kc}{n} - \\beta k$. The provided functions are correct. The model is self-consistent and contains no contradictions.\n\n#### Verdict\nThe problem is valid as it is scientifically sound, self-contained, and well-posed. I will proceed with the solution.\n\n### Step 2: Solution Derivation\n\nThe analysis begins by determining the expected payoffs, $\\pi_{C}$ and $\\pi_{D}$, as a function of the fraction of cooperators, $x$.\n\nThe expected payoff for a strategy is the average of the payoffs received over all possible group compositions, weighted by their probabilities. A focal individual is randomly selected. Its $n-1$ co-players are drawn from the infinite population, so the number of cooperators among them, $K$, is a random variable following the Binomial distribution $\\mathrm{Binomial}(n-1, x)$.\n\nThe payoff functions, $P_C(k)$ and $P_D(k)$, are linear functions of the number of cooperators, $k$. Specifically, letting $k$ be the total number of cooperators in a group:\n$P_{C}(k) = (\\frac{rc}{n} + \\gamma)k - (c + n\\gamma)$\n$P_{D}(k) = (\\frac{rc}{n} - \\beta)k$\nDue to this linearity, the expected payoff can be found by substituting the expected number of cooperators, $\\mathbb{E}[k]$, into the payoff function.\n\nFor a focal cooperator, the group consists of this individual plus $K$ other cooperators and $(n-1)-K$ defectors. The total number of cooperators in the group is $k = K+1$. The expected total number of cooperators is:\n$$ \\mathbb{E}[k] = \\mathbb{E}[K+1] = \\mathbb{E}[K] + 1 = (n-1)x + 1 $$\nThe expected payoff for a cooperator, $\\pi_C$, is therefore:\n$$ \\pi_{C} = P_{C}(\\mathbb{E}[k]) = r \\frac{c((n-1)x + 1)}{n} - c - \\gamma (n - ((n-1)x + 1)) $$\n$$ \\pi_{C} = r \\frac{c((n-1)x + 1)}{n} - c - \\gamma (n-1 - (n-1)x) = r \\frac{c((n-1)x + 1)}{n} - c - \\gamma (n-1)(1-x) $$\n\nFor a focal defector, the group consists of this individual plus $K$ cooperators and $(n-1)-K$ defectors. The total number of cooperators in the group is $k = K$. The expected total number of cooperators is:\n$$ \\mathbb{E}[k] = \\mathbb{E}[K] = (n-1)x $$\nThe expected payoff for a defector, $\\pi_D$, is:\n$$ \\pi_{D} = P_{D}(\\mathbb{E}[k]) = r \\frac{c((n-1)x)}{n} - \\beta ((n-1)x) $$\n\nThe replicator dynamics are driven by the difference in expected payoffs, $\\pi_C - \\pi_D$:\n$$ \\pi_{C} - \\pi_{D} = \\left( r \\frac{c((n-1)x + 1)}{n} - c - \\gamma (n-1)(1-x) \\right) - \\left( r \\frac{c(n-1)x}{n} - \\beta (n-1)x \\right) $$\n$$ \\pi_{C} - \\pi_{D} = \\left( r \\frac{c(n-1)x}{n} + \\frac{rc}{n} - c - \\gamma(n-1) + \\gamma(n-1)x \\right) - \\left( r \\frac{c(n-1)x}{n} - \\beta(n-1)x \\right) $$\nThe term $r \\frac{c(n-1)x}{n}$ cancels out.\n$$ \\pi_{C} - \\pi_{D} = \\frac{rc}{n} - c - \\gamma(n-1) + \\gamma(n-1)x + \\beta(n-1)x $$\n$$ \\pi_{C} - \\pi_{D} = \\left( \\frac{rc}{n} - c - \\gamma(n-1) \\right) + \\left( (n-1)(\\gamma + \\beta) \\right)x $$\nThis payoff difference is a linear function of $x$.\n\nNow, we substitute the given parameter values: $n=5$, $c=1$, $r=3$, $\\beta=0.5=\\frac{1}{2}$, and $\\gamma=0.1=\\frac{1}{10}$.\n$$ \\pi_{C} - \\pi_{D} = \\left( \\frac{3 \\cdot 1}{5} - 1 - \\frac{1}{10}(5-1) \\right) + \\left( (5-1)\\left(\\frac{1}{10} + \\frac{1}{2}\\right) \\right)x $$\n$$ \\pi_{C} - \\pi_{D} = \\left( \\frac{3}{5} - 1 - \\frac{4}{10} \\right) + \\left( 4\\left(\\frac{1+5}{10}\\right) \\right)x $$\n$$ \\pi_{C} - \\pi_{D} = \\left( \\frac{6}{10} - \\frac{10}{10} - \\frac{4}{10} \\right) + \\left( 4 \\cdot \\frac{6}{10} \\right)x $$\n$$ \\pi_{C} - \\pi_{D} = -\\frac{8}{10} + \\frac{24}{10}x = -\\frac{4}{5} + \\frac{12}{5}x $$\n\nThe replicator ODE is $\\dot{x} = f(x) = x(1-x)(\\pi_C - \\pi_D)$.\n$$ \\dot{x} = f(x) = x(1-x)\\left(-\\frac{4}{5} + \\frac{12}{5}x\\right) $$\nFixed points (equilibria) occur where $\\dot{x} = 0$. This condition is satisfied if $x=0$, $x=1$, or $-\\frac{4}{5} + \\frac{12}{5}x = 0$.\nThe fixed points are:\n1.  $x_0 = 0$\n2.  $x_1 = 1$\n3.  $-\\frac{4}{5} + \\frac{12}{5}x^* = 0 \\implies \\frac{12}{5}x^* = \\frac{4}{5} \\implies x^* = \\frac{4}{12} = \\frac{1}{3}$.\n\nThe three fixed points in the interval $[0,1]$ are $x_0=0$, $x^*=\\frac{1}{3}$, and $x_1=1$.\n\nTo determine the stability of these fixed points, we compute the Jacobian eigenvalue, which for a one-dimensional system is $\\lambda = \\frac{d\\dot{x}}{dx} = f'(x)$, evaluated at each fixed point.\nLet's expand $f(x)$:\n$$ f(x) = \\frac{1}{5} x(1-x)(-4+12x) = \\frac{1}{5}(x-x^2)(-4+12x) = \\frac{1}{5}(-4x + 12x^2 + 4x^2 - 12x^3) $$\n$$ f(x) = \\frac{1}{5}(-12x^3 + 16x^2 - 4x) $$\nNow, we compute the derivative $f'(x)$:\n$$ f'(x) = \\frac{1}{5}(-36x^2 + 32x - 4) $$\n\nWe evaluate this derivative at each fixed point to find the corresponding eigenvalues:\n1.  At the fixed point $x_0 = 0$:\n$$ \\lambda_0 = f'(0) = \\frac{1}{5}(-36(0)^2 + 32(0) - 4) = -\\frac{4}{5} $$\n2.  At the interior fixed point $x^* = \\frac{1}{3}$:\n$$ \\lambda_* = f'\\left(\\frac{1}{3}\\right) = \\frac{1}{5}\\left(-36\\left(\\frac{1}{3}\\right)^2 + 32\\left(\\frac{1}{3}\\right) - 4\\right) $$\n$$ \\lambda_* = \\frac{1}{5}\\left(-36\\left(\\frac{1}{9}\\right) + \\frac{32}{3} - 4\\right) = \\frac{1}{5}\\left(-4 + \\frac{32}{3} - 4\\right) $$\n$$ \\lambda_* = \\frac{1}{5}\\left(-8 + \\frac{32}{3}\\right) = \\frac{1}{5}\\left(\\frac{-24+32}{3}\\right) = \\frac{1}{5}\\left(\\frac{8}{3}\\right) = \\frac{8}{15} $$\n3.  At the fixed point $x_1 = 1$:\n$$ \\lambda_1 = f'(1) = \\frac{1}{5}(-36(1)^2 + 32(1) - 4) = \\frac{1}{5}(-36+32-4) = \\frac{1}{5}(-8) = -\\frac{8}{5} $$\n\nThe eigenvalues corresponding to the fixed points $x=0$, $x=1/3$, and $x=1$ are $-\\frac{4}{5}$, $\\frac{8}{15}$, and $-\\frac{8}{5}$, respectively. The negative eigenvalues at $x=0$ and $x=1$ indicate that these are stable equilibria, while the positive eigenvalue at $x=1/3$ indicates it is an unstable equilibrium (a repellor).\n\nThe required answer is the row matrix $\\begin{pmatrix} \\lambda_{0}  \\lambda_{*}  \\lambda_{1} \\end{pmatrix}$.\n$$ \\begin{pmatrix} -\\frac{4}{5}  \\frac{8}{15}  -\\frac{8}{5} \\end{pmatrix} $$",
            "answer": "$$ \\boxed{\n\\begin{pmatrix}\n-\\frac{4}{5}  \\frac{8}{15}  -\\frac{8}{5}\n\\end{pmatrix}\n} $$"
        },
        {
            "introduction": "Our final practice refines the evolutionary perspective by shifting from the deterministic, infinite-population view of the replicator equation  to a stochastic, individual-based model. Here, you will explore strategy updating in a finite population through a pairwise comparison process governed by the Fermi imitation rule, a widely used model for social learning. Deriving the expected change in cooperator frequency will provide you with a powerful tool for understanding how random fluctuations and the intensity of selection interact to shape the evolution of cooperation at a microscopic level.",
            "id": "4137981",
            "problem": "Consider a finite, well-mixed population of size $N$ engaged in a repeated public goods game (PGG) with two strategies: cooperation and defection. Let $x \\in [0,1]$ denote the fraction of cooperators in the population at a given time step. Individuals accrue payoffs from the PGG, and denote by $\\pi_{C}$ and $\\pi_{D}$ the expected payoffs to a cooperator and a defector, respectively, at the current population composition; define the payoff difference $\\Delta \\pi \\equiv \\pi_{C} - \\pi_{D}$. Strategy updating proceeds via pairwise comparison: at each time step, choose a focal individual uniformly at random and choose a role model uniformly at random from the population. If the focal and role model have different strategies, the focal may adopt the role model’s strategy according to a Fermi imitation rule with selection intensity $\\beta  0$. If they have the same strategy, no change occurs.\n\nUsing only first principles from stochastic evolutionary dynamics and the definition of the Fermi imitation rule, perform the following:\n\n- Provide a formal definition of a Fermi imitation rule with selection intensity $\\beta$ for the pairwise comparison process described above, in terms of the focal payoff $\\pi_{i}$ and the role model payoff $\\pi_{j}$.\n- Derive the expected change in the cooperator frequency per time step, denoted $\\Delta x$, as a function of $x$, $N$, $\\beta$, and $\\Delta \\pi$, under the described update mechanism.\n\nExpress the final answer for $\\Delta x$ as a single closed-form analytic expression. No numerical approximation is required, and no rounding is needed. Do not include any units in your final expression.",
            "solution": "The user wants me to first provide a formal definition for a specific process and then derive an equation. The provided problem statement is a standard setup in evolutionary game theory and is scientifically sound, well-posed, and objective. It contains all the necessary information to proceed with the derivation.\n\nThe problem is valid. I will proceed with the solution.\n\nThe first task is to provide a formal definition of the Fermi imitation rule as described. The rule specifies the probability that a focal individual, let's label it $i$ with an associated payoff $\\pi_i$, adopts the strategy of a role model, labeled $j$ with payoff $\\pi_j$. The probability of this adoption event, which we denote $P_{i \\leftarrow j}$, is given by a logistic function of the payoff difference between the role model and the focal individual, weighted by the selection intensity $\\beta$. Formally, this is:\n$$\nP_{i \\leftarrow j} = \\frac{1}{1 + \\exp(-\\beta (\\pi_j - \\pi_i))}\n$$\nHere, $\\beta  0$ is the selection intensity. For $\\beta \\to 0$, the update is random ($P_{i \\leftarrow j} \\to 1/2$). For $\\beta \\to \\infty$, the update becomes deterministic: individual $i$ adopts the strategy of $j$ with certainty if $\\pi_j  \\pi_i$ and never adopts it if $\\pi_j  \\pi_i$.\n\nThe second task is to derive the expected change in the cooperator frequency per time step, $\\Delta x$. The population has a size $N$, and the fraction of cooperators is $x$. Therefore, the number of cooperators is $N_C = Nx$ and the number of defectors is $N_D = N(1-x)$. A \"time step\" is defined as a single pairwise comparison event. If a strategy switch occurs, the number of cooperators changes by $+1$ or $-1$, which in turn changes the frequency $x$ by $+1/N$ or $-1/N$, respectively.\n\nThe expected change in the cooperator frequency, $\\Delta x$, is the sum of the possible changes in $x$ weighted by their probabilities:\n$$\n\\Delta x = E[x_{t+1} - x_t] = \\left(\\frac{1}{N}\\right) P(\\text{increase}) + \\left(-\\frac{1}{N}\\right) P(\\text{decrease}) + (0) P(\\text{no change})\n$$\nwhere $P(\\text{increase})$ is the probability that the number of cooperators increases by $1$ in one time step, and $P(\\text{decrease})$ is the probability that it decreases by $1$.\n\nAn increase in cooperators occurs if a defector (D) is chosen as the focal individual, a cooperator (C) is chosen as the role model, and the defector adopts the cooperator's strategy. Let's calculate the probability of this sequence of events.\nThe probability of choosing a defector as the focal individual is $P(\\text{focal=D}) = \\frac{N_D}{N} = 1-x$.\nThe probability of choosing a cooperator as the role model is $P(\\text{model=C}) = \\frac{N_C}{N} = x$.\nThe focal and role model are chosen independently. Thus, the probability of selecting a (D, C) pair is $P(\\text{focal=D, model=C}) = (1-x)x$.\n\nGiven this pair, the defector (focal) has expected payoff $\\pi_D$ and the cooperator (role model) has expected payoff $\\pi_C$. The probability that the defector adopts the cooperator's strategy is given by the Fermi rule:\n$$\nP(\\text{D adopts C}) = \\frac{1}{1 + \\exp(-\\beta(\\pi_C - \\pi_D))}\n$$\nUsing the problem's definition $\\Delta \\pi = \\pi_C - \\pi_D$, this becomes:\n$$\nP(\\text{D adopts C}) = \\frac{1}{1 + \\exp(-\\beta \\Delta \\pi)}\n$$\nTherefore, the total probability of an increase in the number of cooperators in one time step is:\n$$\nP(\\text{increase}) = P(\\text{focal=D, model=C}) \\times P(\\text{D adopts C}) = x(1-x) \\frac{1}{1 + \\exp(-\\beta \\Delta \\pi)}\n$$\n\nA decrease in cooperators occurs if a cooperator is chosen as the focal individual, a defector is chosen as the role model, and the cooperator adopts the defector's strategy.\nThe probability of selecting a (C, D) pair is $P(\\text{focal=C, model=D}) = \\frac{N_C}{N} \\frac{N_D}{N} = x(1-x)$.\nGiven this pair, the cooperator (focal) has payoff $\\pi_C$ and the defector (role model) has payoff $\\pi_D$. The probability that the cooperator adopts the defector's strategy is:\n$$\nP(\\text{C adopts D}) = \\frac{1}{1 + \\exp(-\\beta(\\pi_D - \\pi_C))} = \\frac{1}{1 + \\exp(-\\beta(-\\Delta \\pi))} = \\frac{1}{1 + \\exp(\\beta \\Delta \\pi)}\n$$\nTherefore, the total probability of a decrease in the number of cooperators in one time step is:\n$$\nP(\\text{decrease}) = P(\\text{focal=C, model=D}) \\times P(\\text{C adopts D}) = x(1-x) \\frac{1}{1 + \\exp(\\beta \\Delta \\pi)}\n$$\n\nNow we can compute the expected change in frequency, $\\Delta x$:\n$$\n\\Delta x = \\frac{1}{N} [P(\\text{increase}) - P(\\text{decrease})]\n$$\n$$\n\\Delta x = \\frac{1}{N} \\left[ x(1-x) \\frac{1}{1 + \\exp(-\\beta \\Delta \\pi)} - x(1-x) \\frac{1}{1 + \\exp(\\beta \\Delta \\pi)} \\right]\n$$\nFactoring out the common term $\\frac{x(1-x)}{N}$:\n$$\n\\Delta x = \\frac{x(1-x)}{N} \\left[ \\frac{1}{1 + \\exp(-\\beta \\Delta \\pi)} - \\frac{1}{1 + \\exp(\\beta \\Delta \\pi)} \\right]\n$$\nLet's simplify the expression in the brackets. Let $A = \\beta \\Delta \\pi$. The expression is $\\frac{1}{1 + \\exp(-A)} - \\frac{1}{1 + \\exp(A)}$.\nThe first term can be rewritten as $\\frac{1}{1 + 1/\\exp(A)} = \\frac{\\exp(A)}{\\exp(A) + 1}$.\nSo the expression becomes:\n$$\n\\frac{\\exp(A)}{\\exp(A) + 1} - \\frac{1}{\\exp(A) + 1} = \\frac{\\exp(A) - 1}{\\exp(A) + 1}\n$$\nThis is the definition of the hyperbolic tangent function, $\\tanh(A/2)$. To see this:\n$$\n\\frac{\\exp(A) - 1}{\\exp(A) + 1} = \\frac{\\exp(A/2)(\\exp(A/2) - \\exp(-A/2))}{\\exp(A/2)(\\exp(A/2) + \\exp(-A/2))} = \\frac{\\exp(A/2) - \\exp(-A/2)}{\\exp(A/2) + \\exp(-A/2)} = \\tanh\\left(\\frac{A}{2}\\right)\n$$\nSubstituting $A = \\beta \\Delta \\pi$ back into this result, the bracketed term simplifies to $\\tanh\\left(\\frac{\\beta \\Delta \\pi}{2}\\right)$.\n\nFinally, substituting this simplified term back into the equation for $\\Delta x$, we obtain the final expression for the expected change in the cooperator frequency per time step:\n$$\n\\Delta x = \\frac{x(1-x)}{N} \\tanh\\left(\\frac{\\beta \\Delta \\pi}{2}\\right)\n$$\nThis expression describes the direction and magnitude of selection pressure on the frequency of cooperators for the given population structure and update rule.",
            "answer": "$$\n\\boxed{\\frac{x(1-x)}{N} \\tanh\\left(\\frac{\\beta \\Delta \\pi}{2}\\right)}\n$$"
        }
    ]
}