{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of any reliable plane-wave Density Functional Theory calculation is ensuring the convergence of the total energy and related properties with respect to the basis set size. This size is controlled by the kinetic energy cutoff, $E_{\\text{cut}}$, which truncates the infinite plane-wave basis. This practice  provides a hands-on opportunity to explore this convergence behavior by implementing a physically-motivated surrogate model that captures how residual forces on atoms decrease as $E_{\\text{cut}}$ increases, allowing you to determine the minimum cutoff required for a desired level of accuracy for different alloy compositions.",
            "id": "3737531",
            "problem": "Consider a plane-wave Density Functional Theory (DFT) ground-state calculation of a chemically disordered high-entropy alloy, where the Kohn–Sham equations are solved variationally within a truncated plane-wave basis characterized by the plane-wave kinetic-energy cutoff $E_{\\text{cut}}$ (in eV). In a relaxation, the $T=0$ K ground-state is approximated at finite $E_{\\text{cut}}$, which leads to a residual force norm $\\|\\mathbf{F}\\|$ (in eV/Å) due to basis-set incompleteness. Starting from the Hohenberg–Kohn theorems, the Kohn–Sham variational principle, and the Rayleigh–Ritz approach for basis truncation, justify a composition-dependent convergence law for the residual ionic force norm as a function of $E_{\\text{cut}}$ that is consistent with the following properties:\n\n- The residual force norm $\\|\\mathbf{F}\\|(E_{\\text{cut}})$ is non-negative and decreases as $E_{\\text{cut}}$ increases.\n- The decay has a dominant algebraic component that depends on an effective composition-dependent hardness metric and a secondary exponentially decaying component controlled by the evanescent character of high-frequency plane waves.\n\nDefine an effective composition hardness $H$ as\n$$\nH \\equiv \\sum_{i} x_i\\, s_i,\n$$\nwhere $x_i$ is the atomic fraction of element $i$ and $s_i$ is a species-dependent hardness parameter. For the purposes of this problem, use the following species parameters:\n- $\\text{Al}: s_{\\text{Al}} = 1.0$\n- $\\text{Ni}: s_{\\text{Ni}} = 2.0$\n- $\\text{Co}: s_{\\text{Co}} = 2.1$\n- $\\text{Cr}: s_{\\text{Cr}} = 2.5$\n- $\\text{Fe}: s_{\\text{Fe}} = 2.0$\n- $\\text{Mn}: s_{\\text{Mn}} = 2.3$\n- $\\text{Ti}: s_{\\text{Ti}} = 3.0$\n- $\\text{V}: s_{\\text{V}} = 3.0$\n- $\\text{Mo}: s_{\\text{Mo}} = 3.2$\n- $\\text{W}: s_{\\text{W}} = 3.5$\n\nAssume a surrogate convergence law for the residual force norm given by\n$$\n\\|\\mathbf{F}\\|(E_{\\text{cut}}; H) \\equiv \\frac{A(H)}{E_{\\text{cut}}^{\\,p(H)}} + B(H)\\,\\exp\\!\\big(-\\gamma \\sqrt{E_{\\text{cut}}}\\big),\n$$\nwith the following parametric forms motivated by the variational scaling of basis-set errors:\n$$\nA(H) = a_0\\, H^{1.2}, \\quad p(H) = p_0 + \\beta \\ln(1+H), \\quad B(H) = b_0\\, H, \\quad \\gamma > 0,\n$$\nwhere $a_0$, $p_0$, $\\beta$, $b_0$, and $\\gamma$ are positive constants. For numerical realization, use\n$$\na_0 = 30, \\quad p_0 = 1.5, \\quad \\beta = 0.3, \\quad b_0 = 10^{-3}, \\quad \\gamma = 0.08,\n$$\nwith $E_{\\text{cut}}$ in eV and $\\|\\mathbf{F}\\|$ in eV/Å. These values are chosen to reflect typical scales of plane-wave convergence for common projector-augmented/pseudopotential representations in metallic systems.\n\nYour task is to write a complete program that, for each test case below, computes the residual force norm $\\|\\mathbf{F}\\|(E_{\\text{cut}})$ at each specified $E_{\\text{cut}}$ and returns the minimal $E_{\\text{cut}}$ that achieves\n$$\n\\|\\mathbf{F}\\|(E_{\\text{cut}}; H) < 10^{-3} \\text{ eV/Å}.\n$$\nIf no provided $E_{\\text{cut}}$ value achieves the strict inequality, return $-1.0$ for that test case.\n\nThe compositions and energy-cutoff grids to be tested are:\n\n- Test Case 1 (general high-entropy alloy):\n  - Composition: $\\{(\\text{Ni}, 0.2), (\\text{Co}, 0.2), (\\text{Cr}, 0.2), (\\text{Fe}, 0.2), (\\text{Mn}, 0.2)\\}$\n  - $E_{\\text{cut}}$ grid (eV): $[300, 350, 400, 450, 500, 550, 600, 650, 700]$\n\n- Test Case 2 (soft alloy):\n  - Composition: $\\{(\\text{Al}, 0.8), (\\text{Ni}, 0.2)\\}$\n  - $E_{\\text{cut}}$ grid (eV): $[350, 400, 450, 500, 550, 600]$\n\n- Test Case 3 (hard refractory alloy):\n  - Composition: $\\{(\\text{Ti}, 0.2), (\\text{V}, 0.2), (\\text{Cr}, 0.2), (\\text{Mo}, 0.2), (\\text{W}, 0.2)\\}$\n  - $E_{\\text{cut}}$ grid (eV): $[450, 500, 550, 600, 650, 700, 750, 800]$\n\n- Test Case 4 (insufficient grid for very hard alloy):\n  - Composition: $\\{(\\text{W}, 0.6), (\\text{Mo}, 0.4)\\}$\n  - $E_{\\text{cut}}$ grid (eV): $[300, 350, 400, 450, 500]$\n\n- Test Case 5 (already converged at the first grid point):\n  - Composition: $\\{(\\text{Al}, 1.0)\\}$\n  - $E_{\\text{cut}}$ grid (eV): $[600, 650, 700]$\n\nNumerical requirements and output specification:\n- All calculations must be performed in the units stated above: $E_{\\text{cut}}$ in eV and $\\|\\mathbf{F}\\|$ in eV/Å.\n- The strict inequality $\\|\\mathbf{F}\\|<10^{-3}$ must be enforced; values equal to $10^{-3}$ do not qualify.\n- Your program should produce a single line of output containing the results for the five test cases as a comma-separated list enclosed in square brackets. Each entry must be a floating-point number representing the minimal cutoff in eV for that test case, or $-1.0$ if not achieved. For example, an output could look like \"[500.0,600.0,-1.0,700.0,650.0]\" but must reflect the actual computed values for the test suite specified above.",
            "solution": "The problem statement has been analyzed and is determined to be valid. It is scientifically grounded within the established framework of Density Functional Theory (DFT), well-posed with a complete and consistent set of definitions and parameters, and objectively formulated. The task is to implement a given semi-empirical model for the convergence of residual ionic forces with respect to the plane-wave energy cutoff, and to apply this model to several test cases representing different high-entropy alloys.\n\nThe theoretical context for this problem originates from the fundamental principles of quantum mechanics as applied to many-electron systems. The Hohenberg-Kohn theorems establish that the ground-state properties of a system are a unique functional of the ground-state electron density, $n(\\mathbf{r})$. The Kohn-Sham (KS) formulation of DFT provides a practical method for finding this ground-state by mapping the interacting electron problem onto a tractable system of non-interacting electrons moving in an effective potential, $v_{\\text{eff}}(\\mathbf{r})$. The KS equations, which have the form of single-particle Schrödinger equations, are typically solved self-consistently.\n\nIn solid-state physics, particularly for crystalline materials, the KS orbitals, $\\psi_i(\\mathbf{r})$, are expanded in a basis set. For plane-wave basis sets, an orbital is expressed as a Fourier series:\n$$\n\\psi_{i,\\mathbf{k}}(\\mathbf{r}) = \\frac{1}{\\sqrt{\\Omega}} \\sum_{\\mathbf{G}} c_{i,\\mathbf{k}+\\mathbf{G}} e^{i(\\mathbf{k}+\\mathbf{G})\\cdot\\mathbf{r}},\n$$\nwhere $\\Omega$ is the cell volume, $\\mathbf{k}$ is a wavevector in the first Brillouin zone, and $\\mathbf{G}$ are reciprocal lattice vectors. For computational feasibility, this infinite sum is truncated. The standard truncation criterion includes only plane waves with a kinetic energy less than a specified cutoff energy, $E_{\\text{cut}}$:\n$$\n\\frac{\\hbar^2}{2m_e} |\\mathbf{k}+\\mathbf{G}|^2 \\le E_{\\text{cut}}.\n$$\nAccording to the Rayleigh-Ritz variational principle, the total energy $E(E_{\\text{cut}})$ calculated with a finite basis set is an upper bound to the true ground-state energy (for the given exchange-correlation functional and pseudopotentials) and converges monotonically from above as $E_{\\text{cut}} \\to \\infty$.\n\nIonic forces are calculated as the negative gradient of the total energy with respect to the nuclear coordinates, $\\mathbf{F}_I = -\\nabla_{\\mathbf{R}_I} E$. Due to the dependency of the basis set itself on the ionic positions (in some formulations) and, more generally, the incompleteness of the basis set for any finite $E_{\\text{cut}}$, a non-zero residual force, often termed a Pulay force, exists even when the ions are at their theoretically perfect ground-state positions. This residual force, $\\|\\mathbf{F}\\|$, systematically decreases to zero as the basis set approaches completeness, i.e., as $E_{\\text{cut}} \\to \\infty$.\n\nThe rate of this convergence is dictated by the smoothness of the KS wavefunctions. The use of pseudopotentials removes the singular behavior of the all-electron potential near the nucleus and the rapid oscillations of the core electron wavefunctions, resulting in smoother pseudo-wavefunctions that can be represented by a much smaller plane-wave basis. However, the \"hardness\" of the pseudopotential—a qualitative measure related to how rapidly the potential and wavefunction vary—differs between chemical species. Elements with deep, localized valence states (e.g., transition metals like W, Mo, or first-row elements like N, O) are \"harder\" and require a higher $E_{\\text{cut}}$ for accurate force calculations compared to \"softer\" elements like Al. The problem formalizes this concept through a composition-averaged hardness metric, $H = \\sum_{i} x_i s_i$.\n\nThe surrogate convergence law provided in the problem,\n$$\n\\|\\mathbf{F}\\|(E_{\\text{cut}}; H) \\equiv \\frac{A(H)}{E_{\\text{cut}}^{\\,p(H)}} + B(H)\\,\\exp\\!\\big(-\\gamma \\sqrt{E_{\\text{cut}}}\\big),\n$$\nis a physically motivated fitting function. The dominant algebraic term, $A(H) E_{\\text{cut}}^{-p(H)}$, captures the power-law decay of errors expected from basis-set expansion of functions with finite differentiability. The exponent $p(H)$ and amplitude $A(H)$ are made dependent on the alloy's effective hardness $H$, reflecting that harder systems converge more slowly. The secondary exponential term, $B(H)\\exp(-\\gamma \\sqrt{E_{\\text{cut}}})$, accounts for the faster decay of Fourier coefficients for smoother, more analytic-like parts of the pseudo-wavefunctions, with the $\\sqrt{E_{\\text{cut}}}$ dependency arising from the relationship between the energy cutoff and the magnitude of the wavevector, $G_{\\text{max}} \\propto \\sqrt{E_{\\text{cut}}}$.\n\nThe computational procedure to solve the problem is as follows:\n1.  Define all fixed numerical constants: the species-dependent hardness parameters $s_i$, and the model coefficients $a_0 = 30$, $p_0 = 1.5$, $\\beta = 0.3$, $b_0 = 10^{-3}$, and $\\gamma = 0.08$. The force convergence threshold is $10^{-3} \\text{ eV/Å}$.\n2.  For each of the five test cases provided:\n    a.  Parse the alloy composition $\\{ ( \\text{element}_i, x_i ) \\}$ and the grid of energy cutoffs $\\{ E_{\\text{cut}, j} \\}$.\n    b.  Calculate the effective composition hardness $H = \\sum_i x_i s_i$.\n    c.  Using the value of $H$, compute the composition-dependent parameters for the convergence law:\n        $$A(H) = a_0\\, H^{1.2}$$\n        $$p(H) = p_0 + \\beta \\ln(1+H)$$\n        $$B(H) = b_0\\, H$$\n    d.  Iterate through the provided $E_{\\text{cut}}$ grid, which is sorted in ascending order. For each value of $E_{\\text{cut}}$:\n        i.  Calculate the residual force norm $\\|\\mathbf{F}\\|$ using the full surrogate model.\n        ii. Check if the condition $\\|\\mathbf{F}\\| < 10^{-3}$ is met.\n    e.  If the condition is met, the current $E_{\\text{cut}}$ is the minimal value from the grid that achieves the desired force convergence. This value is recorded as the result for the test case, and the iteration for this case terminates.\n    f.  If the loop completes without the condition ever being met, it signifies that convergence was not achieved on the given grid. In this scenario, the result for the test case is defined as $-1.0$.\n3.  Collect the results from all five test cases into a list and format them into the specified output string.\n\nThis systematic procedure ensures that for each alloy composition, the corresponding convergence behavior is correctly modeled, and the required energy cutoff is determined precisely according to the problem's criteria.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the minimal energy cutoff to achieve a target residual force norm\n    for various high-entropy alloys based on a surrogate convergence model.\n    \"\"\"\n    # Define species-dependent hardness parameters\n    species_hardness = {\n        'Al': 1.0, 'Ni': 2.0, 'Co': 2.1, 'Cr': 2.5, 'Fe': 2.0,\n        'Mn': 2.3, 'Ti': 3.0, 'V': 3.0, 'Mo': 3.2, 'W': 3.5\n    }\n\n    # Define model constants\n    a0 = 30.0\n    p0 = 1.5\n    beta = 0.3\n    b0 = 1e-3\n    gamma = 0.08\n    force_threshold = 1e-3\n\n    # Define the test cases\n    test_cases = [\n        {\n            \"composition\": [('Ni', 0.2), ('Co', 0.2), ('Cr', 0.2), ('Fe', 0.2), ('Mn', 0.2)],\n            \"ecut_grid\": [300, 350, 400, 450, 500, 550, 600, 650, 700]\n        },\n        {\n            \"composition\": [('Al', 0.8), ('Ni', 0.2)],\n            \"ecut_grid\": [350, 400, 450, 500, 550, 600]\n        },\n        {\n            \"composition\": [('Ti', 0.2), ('V', 0.2), ('Cr', 0.2), ('Mo', 0.2), ('W', 0.2)],\n            \"ecut_grid\": [450, 500, 550, 600, 650, 700, 750, 800]\n        },\n        {\n            \"composition\": [('W', 0.6), ('Mo', 0.4)],\n            \"ecut_grid\": [300, 350, 400, 450, 500]\n        },\n        {\n            \"composition\": [('Al', 1.0)],\n            \"ecut_grid\": [600, 650, 700]\n        }\n    ]\n\n    results = []\n\n    for case in test_cases:\n        composition = case[\"composition\"]\n        ecut_grid = case[\"ecut_grid\"]\n\n        # Step 1: Calculate effective composition hardness H\n        H = sum(fraction * species_hardness[element] for element, fraction in composition)\n\n        # Step 2: Calculate composition-dependent parameters A(H), p(H), B(H)\n        A_H = a0 * (H ** 1.2)\n        p_H = p0 + beta * np.log(1 + H)\n        B_H = b0 * H\n\n        # Step 3: Iterate through E_cut grid to find the minimal cutoff\n        min_ecut_found = -1.0\n        \n        # The grids are already sorted, so the first one to meet the criterion is the minimal one\n        for ecut in ecut_grid:\n            # Calculate the residual force norm\n            algebraic_term = A_H / (ecut ** p_H)\n            exponential_term = B_H * np.exp(-gamma * np.sqrt(ecut))\n            force_norm = algebraic_term + exponential_term\n\n            # Check for strict inequality\n            if force_norm < force_threshold:\n                min_ecut_found = float(ecut)\n                break  # Found the minimal cutoff, move to the next test case\n        \n        results.append(min_ecut_found)\n\n    # Final output formatting\n    # The map(str, ...) is used to correctly format the floats, including the -1.0 cases.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Accurately modeling metallic systems like high-entropy alloys presents a unique challenge due to the presence of a sharp Fermi surface, which can lead to numerical instabilities in Brillouin zone integration. This practice  delves into the concept of electronic smearing, a technique used to smooth the electronic occupations around the Fermi level. You will optimize a model that captures the essential trade-off: a larger smearing width $\\sigma$ improves convergence but can introduce unphysical thermal artifacts, allowing you to determine the optimal value that balances accuracy and computational efficiency.",
            "id": "3737495",
            "problem": "You are tasked with designing a program that determines an optimal electronic smearing width for a metallic High-Entropy Alloy (HEA) within ground-state calculations in Density Functional Theory (DFT), based on a principled model of how smearing affects numerical convergence and thermal broadening artifacts. The fundamental basis is the Kohn-Sham formulation of electronic structure and its finite-temperature generalization by Mermin, where the occupation numbers are broadened by a Fermi-Dirac distribution. The program must be purely mathematical and perform the following optimization on a surrogate model calibrated by physically plausible scaling. Throughout this problem, denote the smearing width by $\\sigma$ and express it in electron-volts (eV). Numerical quantities must be returned as floats with six digits after the decimal point.\n\nBackground and definitions:\n- In metallic systems, small $\\sigma$ can lead to poor sampling of the Fermi surface, resulting in noisy forces and stress. This convergence-related noise decreases as $\\sigma$ increases due to the smoothing of the occupancy near the chemical potential.\n- Conversely, large $\\sigma$ introduces thermal broadening artifacts in the ground-state forces and stress. In the Mermin extension of Kohn-Sham DFT, the finite electronic temperature shifts the free energy relative to the zero-temperature ground-state energy. By the Sommerfeld expansion, leading-order corrections scale with $(k_B T)^2$, and identifying $k_B T$ with $\\sigma$ (measured in eV) yields a bias term that grows approximately as $\\sigma^2$ for small $\\sigma$.\n\nModel to be optimized:\n- For a given HEA and numerical setup (fixed $k$-point mesh and plane-wave cutoffs), assume that a combined scalar metric for the total error can be represented as\n$$\nM(\\sigma) \\equiv A\\,\\sigma^{-p} + C\\,\\sigma^2,\n$$\nwhere $A > 0$ quantifies the amplitude of convergence-related noise (aggregating the force and stress contributions under fixed weights), $p > 0$ controls how strongly the numerical noise decays with increasing $\\sigma$, and $C > 0$ quantifies the strength of thermal broadening artifacts in the forces/stress through a quadratic scaling in $\\sigma$. This functional form is consistent with a decrease of Fermi-surface integration error and the quadratic leading-order bias from the Sommerfeld expansion.\n- The physically acceptable smearing is restricted to a closed interval $[\\sigma_{\\min}, \\sigma_{\\max}]$ in eV, and the optimal smearing width is the minimizer of $M(\\sigma)$ over this interval.\n\nYour task:\n- For each test case in the suite below, compute the optimal $\\sigma^\\star$ that minimizes $M(\\sigma)$ subject to the bound constraint $\\sigma \\in [\\sigma_{\\min}, \\sigma_{\\max}]$. Return $\\sigma^\\star$ in eV. If the unconstrained minimizer falls outside the interval, select the nearest boundary ($\\sigma_{\\min}$ or $\\sigma_{\\max}$). Express each result as a float rounded to six digits after the decimal point.\n\nTest suite:\n- Use the following parameter sets $(A, p, C, \\sigma_{\\min}, \\sigma_{\\max})$, all in consistent units so that $M(\\sigma)$ is dimensionless and $\\sigma$ is in eV:\n  - Case $1$: $A = 0.08$, $p = 1.0$, $C = 12.0$, $\\sigma_{\\min} = 0.01$ eV, $\\sigma_{\\max} = 0.25$ eV.\n  - Case $2$: $A = 0.00001$, $p = 1.0$, $C = 20.0$, $\\sigma_{\\min} = 0.01$ eV, $\\sigma_{\\max} = 0.20$ eV.\n  - Case $3$: $A = 2.0$, $p = 1.0$, $C = 1.0$, $\\sigma_{\\min} = 0.01$ eV, $\\sigma_{\\max} = 0.25$ eV.\n  - Case $4$: $A = 0.20$, $p = 1.5$, $C = 8.0$, $\\sigma_{\\min} = 0.01$ eV, $\\sigma_{\\max} = 0.30$ eV.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the four cases as a comma-separated list enclosed in square brackets, in the order given above, with each value rounded to six digits after the decimal point. For example, the format must be\n$[x_1,x_2,x_3,x_4]$\nwhere each $x_i$ is the optimal $\\sigma^\\star$ in eV for the corresponding case.",
            "solution": "The user has requested the design of a program to determine the optimal electronic smearing width, denoted by $\\sigma$, for ground-state Density Functional Theory (DFT) calculations on a metallic High-Entropy Alloy (HEA). The optimization is based on a surrogate model for a combined total error metric, $M(\\sigma)$, which is a function of the smearing width $\\sigma$.\n\nThe problem states that the total error metric is given by the function:\n$$\nM(\\sigma) = A\\,\\sigma^{-p} + C\\,\\sigma^2\n$$\nwhere the parameters $A > 0$, $p > 0$, and $C > 0$ are provided constants. This model represents a physically motivated trade-off: the term $A\\,\\sigma^{-p}$ models the numerical noise associated with Fermi surface integration, which decreases with increasing $\\sigma$, while the term $C\\,\\sigma^2$ models the bias introduced by thermal broadening artifacts, which increases with $\\sigma$. The parameter $\\sigma$ is measured in electron-volts (eV). The task is to find the value of $\\sigma$, let's call it $\\sigma^\\star$, that minimizes $M(\\sigma)$ within a specified closed interval $[\\sigma_{\\min}, \\sigma_{\\max}]$.\n\nThe problem is a constrained one-dimensional optimization problem. The function $M(\\sigma)$ is continuous and differentiable for $\\sigma > 0$, which is the physically relevant domain. The minimum of a continuous function on a closed, bounded interval is guaranteed to exist and is located either at a critical point inside the interval (where the first derivative is zero) or at one of the boundaries of the interval.\n\nFirst, we locate the unconstrained minimum by finding the critical points of $M(\\sigma)$. This involves computing the first derivative of $M(\\sigma)$ with respect to $\\sigma$ and setting it to zero.\nThe first derivative is:\n$$\n\\frac{dM}{d\\sigma} = \\frac{d}{d\\sigma} (A\\sigma^{-p} + C\\sigma^2) = -pA\\sigma^{-p-1} + 2C\\sigma\n$$\nTo assess the nature of the extremum, we compute the second derivative:\n$$\n\\frac{d^2M}{d\\sigma^2} = \\frac{d}{d\\sigma} (-pA\\sigma^{-p-1} + 2C\\sigma) = (-p)(-p-1)A\\sigma^{-p-2} + 2C = p(p+1)A\\sigma^{-p-2} + 2C\n$$\nGiven the problem constraints that $A > 0$, $p > 0$, and $C > 0$, the second derivative $\\frac{d^2M}{d\\sigma^2}$ is strictly positive for all $\\sigma > 0$. This proves that $M(\\sigma)$ is a strictly convex function on its domain. Therefore, any critical point corresponds to a unique global minimum.\n\nWe find the unconstrained minimizer, which we will denote as $\\sigma_0$, by setting $\\frac{dM}{d\\sigma} = 0$:\n$$\n-pA\\sigma_0^{-p-1} + 2C\\sigma_0 = 0\n$$\nAssuming $\\sigma_0 > 0$, we can rearrange the equation:\n$$\n2C\\sigma_0 = pA\\sigma_0^{-p-1}\n$$\nMultiplying both sides by $\\sigma_0^{p+1}$ yields:\n$$\n2C\\sigma_0^{p+2} = pA\n$$\nFinally, solving for $\\sigma_0$:\n$$\n\\sigma_0 = \\left( \\frac{pA}{2C} \\right)^{\\frac{1}{p+2}}\n$$\nThis $\\sigma_0$ is the value of the smearing width that minimizes the error metric without any constraints.\n\nThe solution to the constrained problem, $\\sigma^\\star$, must lie in the interval $[\\sigma_{\\min}, \\sigma_{\\max}]$. The convexity of $M(\\sigma)$ implies that the function is decreasing for $\\sigma < \\sigma_0$ and increasing for $\\sigma > \\sigma_0$. Thus, the minimizer on the interval $[\\sigma_{\\min}, \\sigma_{\\max}]$ is determined as follows:\n1.  If $\\sigma_0 < \\sigma_{\\min}$, then $M(\\sigma)$ is increasing over the entire interval $[\\sigma_{\\min}, \\sigma_{\\max}]$. The minimum must therefore occur at the left boundary: $\\sigma^\\star = \\sigma_{\\min}$.\n2.  If $\\sigma_0 > \\sigma_{\\max}$, then $M(\\sigma)$ is decreasing over the entire interval $[\\sigma_{\\min}, \\sigma_{\\max}]$. The minimum must occur at the right boundary: $\\sigma^\\star = \\sigma_{\\max}$.\n3.  If $\\sigma_{\\min} \\le \\sigma_0 \\le \\sigma_{\\max}$, the unconstrained minimum a priori lies within the feasible region, so it is the constrained minimum as well: $\\sigma^\\star = \\sigma_0$.\n\nThis logic is equivalent to clamping the value of $\\sigma_0$ to the interval $[\\sigma_{\\min}, \\sigma_{\\max}]$, which can be expressed as $\\sigma^\\star = \\max(\\sigma_{\\min}, \\min(\\sigma_0, \\sigma_{\\max}))$.\n\nWe now apply this procedure to the provided test cases.\n\n**Case 1:** $A = 0.08$, $p = 1.0$, $C = 12.0$, $\\sigma_{\\min} = 0.01$ eV, $\\sigma_{\\max} = 0.25$ eV.\n$$ \\sigma_0 = \\left( \\frac{(1.0)(0.08)}{2(12.0)} \\right)^{\\frac{1}{1.0+2}} = \\left( \\frac{0.08}{24} \\right)^{\\frac{1}{3}} \\approx 0.14938016 \\text{ eV} $$\nSince $0.01 \\le \\sigma_0 \\le 0.25$, the optimal value is $\\sigma^\\star_1 = \\sigma_0$. Rounded to six decimal places, this is $0.149380$.\n\n**Case 2:** $A = 0.00001$, $p = 1.0$, $C = 20.0$, $\\sigma_{\\min} = 0.01$ eV, $\\sigma_{\\max} = 0.20$ eV.\n$$ \\sigma_0 = \\left( \\frac{(1.0)(0.00001)}{2(20.0)} \\right)^{\\frac{1}{1.0+2}} = \\left( \\frac{10^{-5}}{40} \\right)^{\\frac{1}{3}} \\approx 0.00629961 \\text{ eV} $$\nSince $\\sigma_0 < 0.01$, the optimal value is clipped to the lower bound: $\\sigma^\\star_2 = \\sigma_{\\min} = 0.01$. As a float with six decimal places, this is $0.010000$.\n\n**Case 3:** $A = 2.0$, $p = 1.0$, $C = 1.0$, $\\sigma_{\\min} = 0.01$ eV, $\\sigma_{\\max} = 0.25$ eV.\n$$ \\sigma_0 = \\left( \\frac{(1.0)(2.0)}{2(1.0)} \\right)^{\\frac{1}{1.0+2}} = (1.0)^{\\frac{1}{3}} = 1.0 \\text{ eV} $$\nSince $\\sigma_0 > 0.25$, the optimal value is clipped to the upper bound: $\\sigma^\\star_3 = \\sigma_{\\max} = 0.25$. As a float with six decimal places, this is $0.250000$.\n\n**Case 4:** $A = 0.20$, $p = 1.5$, $C = 8.0$, $\\sigma_{\\min} = 0.01$ eV, $\\sigma_{\\max} = 0.30$ eV.\n$$ \\sigma_0 = \\left( \\frac{(1.5)(0.20)}{2(8.0)} \\right)^{\\frac{1}{1.5+2}} = \\left( \\frac{0.3}{16} \\right)^{\\frac{1}{3.5}} \\approx 0.22279580 \\text{ eV} $$\nSince $0.01 \\le \\sigma_0 \\le 0.30$, the optimal value is $\\sigma^\\star_4 = \\sigma_0$. Rounded to six decimal places, this is $0.222796$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the optimal electronic smearing width for a series of test cases\n    based on a surrogate model for total error in DFT calculations.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (A, p, C, sigma_min, sigma_max)\n    test_cases = [\n        (0.08, 1.0, 12.0, 0.01, 0.25),\n        (0.00001, 1.0, 20.0, 0.01, 0.20),\n        (2.0, 1.0, 1.0, 0.01, 0.25),\n        (0.20, 1.5, 8.0, 0.01, 0.30),\n    ]\n\n    results = []\n    for case in test_cases:\n        A, p, C, sigma_min, sigma_max = case\n\n        # Calculate the unconstrained minimizer, sigma_0.\n        # The formula is sigma_0 = (p*A / (2*C))**(1 / (p + 2)).\n        # We ensure all constants are floats for the division and exponentiation.\n        # A, p, C are guaranteed to be positive.\n        base = (p * A) / (2.0 * C)\n        exponent = 1.0 / (p + 2.0)\n        sigma_0 = base ** exponent\n\n        # The optimal sigma_star is the unconstrained minimizer clipped to the\n        # allowed interval [sigma_min, sigma_max].\n        # This is due to the convexity of the error function M(sigma).\n        sigma_star = np.clip(sigma_0, sigma_min, sigma_max)\n        \n        results.append(sigma_star)\n\n    # Format the results as strings with six decimal places.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\n# Self-contained execution\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Once a ground-state energy is accurately computed, a key next step is to calculate thermodynamic properties that predict material stability, such as the formation energy, $E_f$. This property quantifies the energy change when forming an alloy from its constituent elements and is fundamental to designing new materials. This exercise  guides you through calculating $E_f$ and highlights a critical aspect of post-processing: ensuring the use of correct elemental ground-state references and correcting for the common use of computationally convenient but metastable reference phases.",
            "id": "3737564",
            "problem": "You are given a computational task grounded in Density Functional Theory (DFT) for ground-state properties within the context of high-entropy alloys and complex materials modeling. From first principles, the ground-state total energy functional is minimized by the ground-state electron density, and the energy per atom in a solid solution depends on the composition and the elemental chemical potentials chosen as references. When elemental references are not the true ground-state phases (i.e., metastable structures are used), the computed formation energies are systematically shifted. Your task is to formalize this as a mathematical derivation and implement a program that quantifies the effect, then corrects the formation energies using stable elemental references.\n\nFormally define the formation energy per atom of a multicomponent solid solution in terms of the ground-state total energy per atom, the composition fractions, and the elemental chemical potentials, starting from the variational principle of DFT for the ground-state. Using that base, derive the expression showing how formation energies computed with metastable elemental references differ from those computed with stable ground-state references. Clearly identify the correction term in terms of the composition and the differences between metastable and stable elemental reference energies. Use this derivation to design an algorithm that, for each case in the test suite, computes two quantities:\n- The uncorrected formation energy per atom using metastable elemental references.\n- The corrected formation energy per atom using stable elemental references.\n\nAll energies are to be expressed in electronvolts per atom (eV/atom). The composition fractions must be treated as dimensionless numbers that sum to one. No angles are involved. All outputs must be numerical floats.\n\nTest Suite (each case provides the alloy energy per atom, the composition fractions, and arrays of metastable and stable elemental reference energies in eV/atom, aligned by element order):\n\n- Case 1 (happy path): Ternary alloy with equiatomic composition.\n  - Elements: Ni, Co, Cr\n  - Alloy energy per atom: $E_{\\text{alloy}} = -207.7063333333$ eV/atom\n  - Composition: $\\mathbf{x} = [\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}]$\n  - Stable references: $\\boldsymbol{\\mu} = [-204.789, -206.650, -211.590]$ eV/atom\n  - Metastable references: $\\tilde{\\boldsymbol{\\mu}} = [-204.777, -206.625, -211.572]$ eV/atom\n\n- Case 2 (boundary: pure element): Single-component solid.\n  - Elements: Co\n  - Alloy energy per atom: $E_{\\text{alloy}} = -206.650$ eV/atom\n  - Composition: $\\mathbf{x} = [1.0]$\n  - Stable references: $\\boldsymbol{\\mu} = [-206.650]$ eV/atom\n  - Metastable references: $\\tilde{\\boldsymbol{\\mu}} = [-206.625]$ eV/atom\n\n- Case 3 (edge: metastable equals stable for one element, nonzero for another; also demonstrates sign flip):\n  - Elements: Ni, Co\n  - Alloy energy per atom: $E_{\\text{alloy}} = -205.7095$ eV/atom\n  - Composition: $\\mathbf{x} = [0.5, 0.5]$\n  - Stable references: $\\boldsymbol{\\mu} = [-204.789, -206.650]$ eV/atom\n  - Metastable references: $\\tilde{\\boldsymbol{\\mu}} = [-204.789, -206.625]$ eV/atom\n\n- Case 4 (edge: no correction needed because metastable equals stable for all elements):\n  - Elements: Fe, Ni, Cr\n  - Alloy energy per atom: $E_{\\text{alloy}} = -208.468$ eV/atom\n  - Composition: $\\mathbf{x} = [\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}]$\n  - Stable references: $\\boldsymbol{\\mu} = [-208.980, -204.789, -211.590]$ eV/atom\n  - Metastable references: $\\tilde{\\boldsymbol{\\mu}} = [-208.980, -204.789, -211.590]$ eV/atom\n\nYour program must:\n- For each case, compute the uncorrected formation energy per atom using metastable references and the corrected formation energy per atom using stable references, both in eV/atom.\n- Aggregate the results into a single line of output containing a list of lists, where each inner list is of the form $[E^{\\text{uncorr}}, E^{\\text{corr}}]$, both as floats in eV/atom, in the same order as the test cases.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The items are the four inner lists corresponding to the four cases, each itself a comma-separated pair of floats, for example: `[[e11,e12],[e21,e22],[e31,e32],[e41,e42]]`. All numeric values implicitly carry the unit eV/atom as specified above.",
            "solution": "The problem requires the derivation and implementation of a correction for formation energies in multicomponent alloys when computed using metastable, rather than stable, elemental reference energies. The foundation of this problem lies in the variational principle of Density Functional Theory (DFT), which states that the ground-state total energy of a system is a unique functional of the ground-state electron density and is minimized by it.\n\nFirst, we formalize the definition of the formation energy per atom, $E_f$, for an $N$-component solid solution. Let the alloy be described by a set of composition fractions $\\mathbf{x} = \\{x_1, x_2, \\dots, x_N\\}$, where $\\sum_{i=1}^N x_i = 1$. The total energy per atom of the alloy, as computed from first principles (e.g., via DFT), is denoted as $E_{\\text{alloy}}$.\n\nThe formation energy represents the change in energy upon forming the alloy from its constituent elements in their standard reference states. The standard reference state for an element $i$ is typically its thermodynamic ground-state crystal structure at zero temperature and pressure (e.g., face-centered cubic for Ni, body-centered cubic for Cr). The chemical potential, $\\mu_i$, for element $i$ is defined as the ground-state total energy per atom of this stable reference phase.\n\nThe formation energy per atom computed with respect to these stable elemental references, which we will denote as the corrected formation energy, $E^{\\text{corr}}$, is defined as:\n$$\nE^{\\text{corr}} = E_{\\text{alloy}} - \\sum_{i=1}^{N} x_i \\mu_i\n$$\nHere, $\\boldsymbol{\\mu} = \\{\\mu_1, \\mu_2, \\dots, \\mu_N\\}$ represents the vector of energies per atom for the elements in their stable ground-state phases.\n\nIn computational practice, it is sometimes convenient or necessary to use elemental references that are not the true ground states. For instance, to maintain structural consistency in a study of FCC alloys, one might use an FCC structure for an element like Cr, even though its ground state is BCC. Such a reference is metastable, meaning its energy is higher than the true ground state. Let us denote the vector of these metastable reference energies as $\\tilde{\\boldsymbol{\\mu}} = \\{\\tilde{\\mu}_1, \\tilde{\\mu}_2, \\dots, \\tilde{\\mu}_N\\}$.\n\nThe formation energy computed using these metastable references, which we will call the uncorrected formation energy, $E^{\\text{uncorr}}$, is given by an analogous expression:\n$$\nE^{\\text{uncorr}} = E_{\\text{alloy}} - \\sum_{i=1}^{N} x_i \\tilde{\\mu}_i\n$$\n\nOur objective is to derive the relationship between $E^{\\text{corr}}$ and $E^{\\text{uncorr}}$ and identify the correction term. We can express $E_{\\text{alloy}}$ from the second equation:\n$$\nE_{\\text{alloy}} = E^{\\text{uncorr}} + \\sum_{i=1}^{N} x_i \\tilde{\\mu}_i\n$$\nNow, we substitute this expression for $E_{\\text{alloy}}$ into the equation for the corrected formation energy, $E^{\\text{corr}}$:\n$$\nE^{\\text{corr}} = \\left( E^{\\text{uncorr}} + \\sum_{i=1}^{N} x_i \\tilde{\\mu}_i \\right) - \\sum_{i=1}^{N} x_i \\mu_i\n$$\nBy combining the summation terms, we arrive at the final relationship:\n$$\nE^{\\text{corr}} = E^{\\text{uncorr}} + \\sum_{i=1}^{N} x_i (\\tilde{\\mu}_i - \\mu_i)\n$$\nThis equation reveals that the corrected formation energy is equal to the uncorrected formation energy plus a correction term, $\\Delta E_{\\text{corr}}$. This correction term is the composition-weighted average of the energy differences between the metastable and stable elemental references. For each element $i$, the term $(\\tilde{\\mu}_i - \\mu_i)$ represents the energy penalty for using a metastable structure instead of the stable ground state. Since $\\tilde{\\mu}_i \\ge \\mu_i$ by definition of the ground state, this difference is always non-negative.\n\nThe algorithm to solve the problem is a direct implementation of these derived formulas. For each test case, we are given $E_{\\text{alloy}}$, the composition vector $\\mathbf{x}$, the stable reference energies $\\boldsymbol{\\mu}$, and the metastable reference energies $\\tilde{\\boldsymbol{\\mu}}$.\n\nThe algorithm proceeds as follows for each case:\n1.  Compute the composition-weighted average of the metastable reference energies: $\\sum_{i} x_i \\tilde{\\mu}_i$. This can be performed efficiently using a dot product, $\\mathbf{x} \\cdot \\tilde{\\boldsymbol{\\mu}}$.\n2.  Calculate the uncorrected formation energy: $E^{\\text{uncorr}} = E_{\\text{alloy}} - \\mathbf{x} \\cdot \\tilde{\\boldsymbol{\\mu}}$.\n3.  Compute the composition-weighted average of the stable reference energies: $\\sum_{i} x_i \\mu_i$, or $\\mathbf{x} \\cdot \\boldsymbol{\\mu}$.\n4.  Calculate the corrected formation energy: $E^{\\text{corr}} = E_{\\text{alloy}} - \\mathbf{x} \\cdot \\boldsymbol{\\mu}$.\n5.  Return the pair $[E^{\\text{uncorr}}, E^{\\text{corr}}]$.\n\nThis procedure is applied to all provided test cases.\n\nFor Case 1:\n- $E_{\\text{alloy}} = -207.7063333333$ eV/atom\n- $\\mathbf{x} = [\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}]$\n- $\\boldsymbol{\\mu} = [-204.789, -206.650, -211.590]$ eV/atom\n- $\\tilde{\\boldsymbol{\\mu}} = [-204.777, -206.625, -211.572]$ eV/atom\nThe weighted metastable average is $\\mathbf{x} \\cdot \\tilde{\\boldsymbol{\\mu}} = \\frac{1}{3}(-204.777 - 206.625 - 211.572) = -207.658$.\n$E^{\\text{uncorr}} = -207.7063333333 - (-207.658) \\approx -0.04833333$.\nThe weighted stable average is $\\mathbf{x} \\cdot \\boldsymbol{\\mu} = \\frac{1}{3}(-204.789 - 206.650 - 211.590) \\approx -207.67633333$.\n$E^{\\text{corr}} = -207.7063333333 - (-207.6763333333) = -0.03$.\n\nFor Case 2 (pure element):\n- $E_{\\text{alloy}} = -206.650$ eV/atom (which is equal to $\\mu_1$)\n- $\\mathbf{x} = [1.0]$\n- $\\boldsymbol{\\mu} = [-206.650]$ eV/atom\n- $\\tilde{\\boldsymbol{\\mu}} = [-206.625]$ eV/atom\n$E^{\\text{uncorr}} = -206.650 - (1.0 \\times -206.625) = -0.025$.\n$E^{\\text{corr}} = -206.650 - (1.0 \\times -206.650) = 0.0$. This is expected, as the formation energy of a pure element from itself is zero.\n\nThis method is general and robust, accurately handling multicomponent systems, pure elements, and cases where some or all reference energies are identical between the two sets.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates uncorrected and corrected formation energies for a series of alloys.\n\n    The problem defines the formation energy of an alloy as the difference between\n    the alloy's total energy per atom and the composition-weighted average of the\n    elemental chemical potentials (reference energies).\n\n    - Uncorrected formation energy (E_uncorr) uses metastable elemental references.\n    - Corrected formation energy (E_corr) uses stable ground-state elemental references.\n\n    The derivation is as follows:\n    E_uncorr = E_alloy - sum(x_i * mu_metastable_i)\n    E_corr   = E_alloy - sum(x_i * mu_stable_i)\n\n    The code implements these two formulas for each test case.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (E_alloy, composition_x, stable_refs_mu, metastable_refs_tilde_mu)\n    # All energies are in eV/atom. Compositions are dimensionless fractions.\n    test_cases = [\n        # Case 1: Ternary alloy\n        (\n            -207.7063333333,\n            [1/3, 1/3, 1/3],\n            [-204.789, -206.650, -211.590],\n            [-204.777, -206.625, -211.572]\n        ),\n        # Case 2: Pure element\n        (\n            -206.650,\n            [1.0],\n            [-206.650],\n            [-206.625]\n        ),\n        # Case 3: Binary alloy with one element's refs being equal\n        (\n            -205.7095,\n            [0.5, 0.5],\n            [-204.789, -206.650],\n            [-204.789, -206.625]\n        ),\n        # Case 4: No correction needed as all refs are equal\n        (\n            -208.468,\n            [1/3, 1/3, 1/3],\n            [-208.980, -204.789, -211.590],\n            [-208.980, -204.789, -211.590]\n        ),\n    ]\n\n    results = []\n    for case in test_cases:\n        e_alloy, x, mu_stable, mu_metastable = case\n        \n        # Convert lists to numpy arrays for efficient vector operations\n        x_np = np.array(x)\n        mu_stable_np = np.array(mu_stable)\n        mu_metastable_np = np.array(mu_metastable)\n\n        # Calculate the composition-weighted average of reference energies\n        # using the dot product.\n        weighted_mu_stable = np.dot(x_np, mu_stable_np)\n        weighted_mu_metastable = np.dot(x_np, mu_metastable_np)\n\n        # Calculate the uncorrected formation energy using metastable references\n        e_uncorr = e_alloy - weighted_mu_metastable\n\n        # Calculate the corrected formation energy using stable references\n        e_corr = e_alloy - weighted_mu_stable\n        \n        results.append([e_uncorr, e_corr])\n\n    # Format the final output string exactly as required.\n    # The string must be in the format: [[val1,val2],[val3,val4],...]\n    inner_strings = [f\"[{res[0]},{res[1]}]\" for res in results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}