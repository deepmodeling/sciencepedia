{
    "hands_on_practices": [
        {
            "introduction": "The heart of the Metropolis Monte Carlo algorithm lies in proposing small, local changes to the system and deciding whether to accept them. For an alloy model based on a pairwise Hamiltonian, the most fundamental step is calculating the energy change, $\\Delta E$, that results from altering the chemical identity of a single atom. This exercise walks you through this essential calculation, connecting the abstract Hamiltonian to the concrete numerical operation that drives the simulation's evolution towards thermodynamic equilibrium .",
            "id": "3752126",
            "problem": "Consider an equiatomic five-component high-entropy alloy on a face-centered cubic (fcc) lattice with coordination number $z=12$. The system’s energy is modeled by a nearest-neighbor pair Hamiltonian\n$$\nH=\\sum_{\\langle i,j\\rangle} J_{\\sigma_i \\sigma_j},\n$$\nwhere $\\langle i,j\\rangle$ denotes unique nearest-neighbor pairs, $\\sigma_i \\in \\{A,B,C,D,E\\}$ is the chemical species at lattice site $i$, and $J_{\\alpha\\beta}=J_{\\beta\\alpha}$ are pairwise interaction energies. In a single-site trial of the Metropolis algorithm from Monte Carlo (MC) methods, site $i$ initially occupied by species $A$ is proposed to change to species $D$. Only interactions involving site $i$ can change during this move.\n\nThe twelve nearest neighbors of site $i$ have the following species counts: $n_A=2$, $n_B=3$, $n_C=3$, $n_D=1$, and $n_E=3$. The non-redundant symmetric pair interaction energies $J_{\\alpha\\beta}$ (in $\\mathrm{meV}$ per pair) are:\n$$\nJ_{AA}=-5,\\quad J_{AB}=1,\\quad J_{AC}=3,\\quad J_{AD}=-2,\\quad J_{AE}=0,\n$$\n$$\nJ_{BB}=-4,\\quad J_{BC}=2,\\quad J_{BD}=5,\\quad J_{BE}=-1,\n$$\n$$\nJ_{CC}=-6,\\quad J_{CD}=4,\\quad J_{CE}=1,\n$$\n$$\nJ_{DD}=-3,\\quad J_{DE}=2,\\quad J_{EE}=-7,\n$$\nwith $J_{\\alpha\\beta}=J_{\\beta\\alpha}$ for all species $\\alpha,\\beta\\in\\{A,B,C,D,E\\}$.\n\nStarting from the definition of the Hamiltonian and basic principles of the Metropolis method in the canonical ensemble, derive the expression for the local energy change $\\Delta E$ associated with this single-site transmutation from $A$ to $D$ and evaluate it for the given neighbor identities and interaction energies. Express the final energy change in $\\mathrm{meV}$. No rounding is required.",
            "solution": "The energy change $\\Delta E$ for a single-site transmutation trial move from an initial state (species $\\sigma_i$ at site $i$) to a final state (species $\\sigma'_i$ at site $i$) is the difference in the energies of the final and initial configurations, $E_{final} - E_{initial}$. Since only interactions involving site $i$ are affected, we only need to consider the change in the local energy contribution from that site.\n\nThe Hamiltonian is a sum over nearest-neighbor pairs, $H=\\sum_{\\langle i,j\\rangle} J_{\\sigma_i \\sigma_j}$. The local energy contribution associated with site $i$ is the sum of interaction energies with its nearest neighbors:\n$$ E_i = \\sum_{j \\in \\text{nn}(i)} J_{\\sigma_i \\sigma_j} $$\nwhere $\\text{nn}(i)$ denotes the set of nearest neighbors of site $i$.\n\n**1. Calculate the initial local energy ($E_{initial, i}$):**\nInitially, site $i$ is occupied by species $A$ ($\\sigma_i = A$). The neighbors are specified as $n_A=2$, $n_B=3$, $n_C=3$, $n_D=1$, and $n_E=3$. The initial local energy is the sum of pair interactions with these neighbors:\n$$ E_{initial, i} = \\sum_{j \\in \\text{nn}(i)} J_{A \\sigma_j} = n_A J_{AA} + n_B J_{AB} + n_C J_{AC} + n_D J_{AD} + n_E J_{AE} $$\nSubstituting the given interaction energies (in meV):\n$$ E_{initial, i} = 2(-5) + 3(1) + 3(3) + 1(-2) + 3(0) $$\n$$ E_{initial, i} = -10 + 3 + 9 - 2 + 0 = 0 \\, \\mathrm{meV} $$\n\n**2. Calculate the final local energy ($E_{final, i}$):**\nIn the final state, site $i$ is occupied by species $D$ ($\\sigma'_i = D$). The neighbors remain the same. The final local energy is:\n$$ E_{final, i} = \\sum_{j \\in \\text{nn}(i)} J_{D \\sigma_j} = n_A J_{DA} + n_B J_{DB} + n_C J_{DC} + n_D J_{DD} + n_E J_{DE} $$\nUsing the symmetry $J_{\\alpha\\beta}=J_{\\beta\\alpha}$ and substituting the values:\n$$ E_{final, i} = 2(J_{AD}) + 3(J_{BD}) + 3(J_{CD}) + 1(J_{DD}) + 3(J_{DE}) $$\n$$ E_{final, i} = 2(-2) + 3(5) + 3(4) + 1(-3) + 3(2) $$\n$$ E_{final, i} = -4 + 15 + 12 - 3 + 6 = 26 \\, \\mathrm{meV} $$\n\n**3. Calculate the total energy change ($\\Delta E$):**\nThe total energy change for the trial move is the difference between the final and initial local energies:\n$$ \\Delta E = E_{final, i} - E_{initial, i} = 26 \\, \\mathrm{meV} - 0 \\, \\mathrm{meV} = 26 \\, \\mathrm{meV} $$\nThe energy change is 26 meV.",
            "answer": "$$\n\\boxed{26}\n$$"
        },
        {
            "introduction": "Simulations at a fixed composition (the canonical ensemble) are valuable, but to study phase stability and compositional ordering, we must allow the alloy's composition to fluctuate in response to chemical driving forces. This is achieved by working in the semi-grand canonical (SGC) ensemble, where chemical potential differences, $\\mu_i$, are specified. This practice demonstrates how the standard Metropolis acceptance criterion is generalized for the SGC ensemble by incorporating these chemical potentials into a new thermodynamic potential, guiding you to derive and apply the correct acceptance probability .",
            "id": "3752153",
            "problem": "Consider a multi-component high-entropy alloy with species indexed by $i \\in \\{A,B,C,D,E\\}$ occupying a fixed number of lattice sites in volume $V$. A microstate $X$ is characterized by its energy $E(X)$ and composition $\\{N_i(X)\\}$, where $N_i(X)$ is the number of atoms of species $i$ in microstate $X$. In the semi-grand canonical ensemble (SGC) at fixed temperature $T$ and fixed chemical potentials $\\{\\mu_i\\}$, the equilibrium probability of $X$ is proportional to the Boltzmann factor built from the semi-grand canonical potential, which is defined by the combination $E(X)-\\sum_i \\mu_i N_i(X)$. A Markov Chain Monte Carlo (MCMC) simulation employs trial moves $X \\to X'$ that change both $E$ and $\\{N_i\\}$ (for example, single-site species transmutations). Assume a symmetric proposal mechanism in which the probability to propose $X \\to X'$ equals that of proposing $X' \\to X$.\n\n(a) Starting from the detailed balance condition and the Boltzmann weight appropriate to the semi-grand canonical ensemble, derive the acceptance probability function $p_{\\mathrm{acc}}(X \\to X')$ for a generic trial move that changes energy and composition. Your derivation must begin from core statistical mechanics principles: the equilibrium weight proportional to $\\exp(-\\beta \\,\\text{potential})$ with $\\beta = 1/(k_B T)$, and the detailed balance condition for MCMC transitions.\n\n(b) Consider a specific single-site transmutation in an $A$-$B$-$C$-$D$-$E$ alloy at temperature $T = 1200 \\,\\mathrm{K}$ where the species at the chosen site changes from $B$ to $E$. Suppose the energy change for the trial move is $\\Delta E = +0.12 \\,\\mathrm{eV}$, and the chemical potentials are $\\mu_A = 0 \\,\\mathrm{eV}$, $\\mu_B = +0.025 \\,\\mathrm{eV}$, $\\mu_C = -0.030 \\,\\mathrm{eV}$, $\\mu_D = +0.015 \\,\\mathrm{eV}$, $\\mu_E = -0.035 \\,\\mathrm{eV}$. For this transmutation, the composition changes are $\\Delta N_B = -1$, $\\Delta N_E = +1$, and $\\Delta N_i = 0$ for all other species. Use the Boltzmann constant $k_B = 8.617333262145 \\times 10^{-5} \\,\\mathrm{eV/K}$. Compute the acceptance probability for this trial move. Express the final acceptance probability as a dimensionless decimal number rounded to four significant figures.",
            "solution": "Part (a): Derivation of the Acceptance Probability\n\nThe objective is to derive the acceptance probability $p_{\\mathrm{acc}}(X \\to X')$ for a trial move in a Markov Chain Monte Carlo (MCMC) simulation within the semi-grand canonical (SGC) ensemble. The derivation begins from the principle of detailed balance, which is a sufficient condition for the Markov chain to converge to the desired equilibrium distribution.\n\nThe detailed balance condition states that for any two microstates $X$ and $X'$, the rate of transitions from $X$ to $X'$ must equal the rate of transitions from $X'$ to $X$ at equilibrium:\n$$\nP_{eq}(X) W(X \\to X') = P_{eq}(X') W(X' \\to X)\n$$\nwhere $P_{eq}(X)$ is the equilibrium probability of microstate $X$, and $W(X \\to X')$ is the total transition probability from $X$ to $X'$.\n\nThe total transition probability is the product of two factors: the proposal probability $g(X \\to X')$ of generating the trial move from $X$ to $X'$, and the acceptance probability $p_{\\mathrm{acc}}(X \\to X')$ of accepting that move.\n$$\nW(X \\to X') = g(X \\to X') p_{\\mathrm{acc}}(X \\to X')\n$$\nSubstituting this into the detailed balance equation gives:\n$$\nP_{eq}(X) g(X \\to X') p_{\\mathrm{acc}}(X \\to X') = P_{eq}(X') g(X' \\to X) p_{\\mathrm{acc}}(X' \\to X)\n$$\nWe can rearrange this to find a ratio of the acceptance probabilities:\n$$\n\\frac{p_{\\mathrm{acc}}(X \\to X')}{p_{\\mathrm{acc}}(X' \\to X)} = \\frac{P_{eq}(X')}{P_{eq}(X)} \\frac{g(X' \\to X)}{g(X \\to X')}\n$$\nThe problem specifies a symmetric proposal mechanism, which means $g(X \\to X') = g(X' \\to X)$. Therefore, the ratio of proposal probabilities is unity:\n$$\n\\frac{g(X' \\to X)}{g(X \\to X')} = 1\n$$\nThis simplifies the acceptance probability ratio to:\n$$\n\\frac{p_{\\mathrm{acc}}(X \\to X')}{p_{\\mathrm{acc}}(X' \\to X)} = \\frac{P_{eq}(X')}{P_{eq}(X)}\n$$\nIn the semi-grand canonical ensemble, the equilibrium probability of a microstate $X$ is given by the Boltzmann weight of its SGC potential, $\\Phi_{SGC}(X) = E(X) - \\sum_i \\mu_i N_i(X)$.\n$$\nP_{eq}(X) \\propto \\exp\\left(-\\beta \\Phi_{SGC}(X)\\right)\n$$\nwhere $\\beta = 1/(k_B T)$. The ratio of equilibrium probabilities is therefore:\n$$\n\\frac{P_{eq}(X')}{P_{eq}(X)} = \\frac{\\exp\\left(-\\beta \\Phi_{SGC}(X')\\right)}{\\exp\\left(-\\beta \\Phi_{SGC}(X)\\right)} = \\exp\\left(-\\beta [\\Phi_{SGC}(X') - \\Phi_{SGC}(X)]\\right) = \\exp\\left(-\\beta \\Delta \\Phi_{SGC}\\right)\n$$\nThe change in the SGC potential, $\\Delta \\Phi_{SGC}$, is given by:\n$$\n\\Delta \\Phi_{SGC} = \\Phi_{SGC}(X') - \\Phi_{SGC}(X) = \\left(E(X') - \\sum_i \\mu_i N_i(X')\\right) - \\left(E(X) - \\sum_i \\mu_i N_i(X)\\right)\n$$\n$$\n\\Delta \\Phi_{SGC} = [E(X') - E(X)] - \\sum_i \\mu_i [N_i(X') - N_i(X)] = \\Delta E - \\sum_i \\mu_i \\Delta N_i\n$$\nThe Metropolis-Hastings algorithm provides a specific choice for $p_{\\mathrm{acc}}$ that satisfies the detailed balance condition. For the symmetric proposal case (often called the Metropolis algorithm), the acceptance probability is given by:\n$$\np_{\\mathrm{acc}}(X \\to X') = \\min\\left(1, \\frac{P_{eq}(X')}{P_{eq}(X)}\\right)\n$$\nSubstituting our expression for the ratio of probabilities, we arrive at the final form for the acceptance probability in the SGC ensemble:\n$$\np_{\\mathrm{acc}}(X \\to X') = \\min\\left(1, \\exp\\left(-\\beta \\Delta \\Phi_{SGC}\\right)\\right) = \\min\\left(1, \\exp\\left(-\\beta \\left[\\Delta E - \\sum_i \\mu_i \\Delta N_i\\right]\\right)\\right)\n$$\n\nPart (b): Calculation of the Acceptance Probability\n\nWe are asked to compute the acceptance probability for a specific single-site transmutation from species $B$ to $E$. The given values are:\nTemperature, $T = 1200 \\,\\mathrm{K}$.\nEnergy change, $\\Delta E = +0.12 \\,\\mathrm{eV}$.\nBoltzmann constant, $k_B = 8.617333262145 \\times 10^{-5} \\,\\mathrm{eV/K}$.\nChemical potentials: $\\mu_B = +0.025 \\,\\mathrm{eV}$ and $\\mu_E = -0.035 \\,\\mathrm{eV}$.\nThe trial move involves changing one atom of species $B$ to species $E$. Thus, the changes in the number of atoms of each species are:\n$\\Delta N_B = -1$, $\\Delta N_E = +1$, and $\\Delta N_i = 0$ for all other species ($i \\in \\{A, C, D\\}$).\n\nFirst, we calculate the change in the SGC potential, $\\Delta \\Phi_{SGC} = \\Delta E - \\sum_i \\mu_i \\Delta N_i$. The sum $\\sum_i \\mu_i \\Delta N_i$ simplifies:\n$$\n\\sum_i \\mu_i \\Delta N_i = \\mu_B \\Delta N_B + \\mu_E \\Delta N_E = (+0.025 \\,\\mathrm{eV})(-1) + (-0.035 \\,\\mathrm{eV})(+1) = -0.025 \\,\\mathrm{eV} - 0.035 \\,\\mathrm{eV} = -0.060 \\,\\mathrm{eV}\n$$\nNow, we can compute $\\Delta \\Phi_{SGC}$:\n$$\n\\Delta \\Phi_{SGC} = \\Delta E - \\sum_i \\mu_i \\Delta N_i = +0.12 \\,\\mathrm{eV} - (-0.060 \\,\\mathrm{eV}) = +0.180 \\,\\mathrm{eV}\n$$\nNext, we calculate the argument of the exponential term, $-\\beta \\Delta \\Phi_{SGC} = -\\frac{\\Delta \\Phi_{SGC}}{k_B T}$:\n$$\nk_B T = (8.617333262145 \\times 10^{-5} \\,\\mathrm{eV/K}) \\times (1200 \\,\\mathrm{K}) \\approx 0.103408 \\,\\mathrm{eV}\n$$\nThe argument is:\n$$\n-\\frac{\\Delta \\Phi_{SGC}}{k_B T} = -\\frac{0.180 \\,\\mathrm{eV}}{0.103407999174 \\,\\mathrm{eV}} \\approx -1.740667\n$$\nThe acceptance probability is then:\n$$\np_{\\mathrm{acc}} = \\min(1, \\exp(-1.740667))\n$$\nSince the argument is negative, the exponential will be less than $1$.\n$$\np_{\\mathrm{acc}} = \\exp(-1.740667) \\approx 0.175402\n$$\nRounding this result to four significant figures gives $0.1754$.",
            "answer": "$$\\boxed{0.1754}$$"
        },
        {
            "introduction": "Generating data from a Monte Carlo simulation is only half the battle; correctly analyzing it to produce statistically meaningful results is paramount. Because successive states in a Markov chain are correlated, naively applying standard statistical formulas for independent data leads to a severe underestimation of the true uncertainty. This exercise introduces the blocking method, an indispensable technique for analyzing correlated time-series data, ensuring that you can compute reliable averages and scientifically rigorous error bars for your thermodynamic observables .",
            "id": "3752115",
            "problem": "You are analyzing a time series of an extensive observable $O_t$ (for example, per-atom energy or a Warren–Cowley short-range order parameter) measured every Monte Carlo (MC) sweep in a semi-grand-canonical simulation of an equiatomic quinary high-entropy alloy on a face-centered cubic lattice. The Markov chain is stationary and ergodic, and you have recorded $N$ successive values $O_1,\\dots,O_N$ with $N \\gg 1$. Empirically, the normalized autocorrelation function $\\rho(t)$ decays approximately exponentially, with a decay time $\\tau_{\\exp}$ such that $\\rho(t) \\approx \\exp(-t/\\tau_{\\exp})$. You wish to estimate the uncertainty (standard error) of the sample mean $\\bar{O} = (1/N)\\sum_{t=1}^N O_t$ in the presence of serial correlation using blocking analysis.\n\nStarting from the definition of the autocovariance function $C(t) = \\mathrm{Cov}(O_s,O_{s+t})$ for a stationary process, and the expression for the variance of a mean of correlated data constructed from $C(t)$, justify the basic idea of blocking analysis and explain how the choice of block size $b$ should relate to the integrated autocorrelation time $\\tau_{\\mathrm{int}}$ to obtain a reliable uncertainty estimate. Consider the practical case $N = 10^5$ and $\\tau_{\\exp} \\approx 10^2$. Which option best describes a scientifically sound blocking procedure and the correct relation between $b$ and $\\tau_{\\mathrm{int}}$?\n\nA. Divide the series into contiguous, non-overlapping blocks of length $b$, compute the block means $\\{M_k\\}$, and estimate $\\mathrm{Var}(\\bar{O})$ as the sample variance of the $\\{M_k\\}$ divided by the number of blocks $n_b \\approx N/b$. As a function of $b$, this estimator rises from the naive underestimation and reaches a plateau once $b \\gtrsim \\mathrm{few}\\times \\tau_{\\mathrm{int}}$; choose $b$ in that plateau while keeping $n_b$ reasonably large (for instance $n_b \\gtrsim 20$). With $N=10^5$ and $\\tau_{\\exp}\\approx 10^2$, acceptable choices are $b$ in the range $10^3$–$5\\times 10^3$, provided a plateau is observed.\n\nB. Choose $b \\approx \\tau_{\\mathrm{int}}$ so that successive block means are exactly uncorrelated; if $b$ is increased beyond $\\tau_{\\mathrm{int}}$, the variance estimator becomes systematically biased high. The estimated error should monotonically decrease with $b$, and its first minimum identifies $\\tau_{\\mathrm{int}}$.\n\nC. Randomly permute the $N$ samples to eliminate correlations and then compute the standard error as the sample standard deviation divided by $\\sqrt{N}$. In this case, $b$ is irrelevant because the permutation renders the data independent and identically distributed.\n\nD. To avoid any bias from residual correlations, choose $b=N$ so that there is a single block. The variance of this block mean equals the variance of $\\bar{O}$ exactly, so no further analysis is needed.\n\nE. Discard data by decimation: keep every $b$-th sample and drop the rest, then compute the standard error as the sample standard deviation of the retained data divided by $\\sqrt{N/b}$. Set $b=\\tau_{\\mathrm{int}}$ to guarantee independence of retained samples. This gives the same answer as blocking, with better statistics because the retained samples are independent.",
            "solution": "### Justification of Blocking Analysis\nLet $\\{O_t\\}_{t=1}^N$ be a time series from a stationary stochastic process with mean $\\mu = \\mathrm{E}[O_t]$ and variance $\\sigma^2 = \\mathrm{Var}(O_t)$. The sample mean is $\\bar{O} = \\frac{1}{N}\\sum_{t=1}^N O_t$. The variance of this estimator, $\\mathrm{Var}(\\bar{O})$, is given by:\n$$ \\mathrm{Var}(\\bar{O}) = \\frac{1}{N^2} \\sum_{t=1}^N \\sum_{s=1}^N \\mathrm{Cov}(O_t, O_s) = \\frac{\\sigma^2}{N} \\left[ 1 + 2 \\sum_{\\tau=1}^{N-1} \\left(1 - \\frac{\\tau}{N}\\right) \\rho(\\tau) \\right] $$\nwhere $\\rho(\\tau)$ is the normalized autocorrelation function. For $N \\gg \\tau_{\\mathrm{int}}$, where $\\tau_{\\mathrm{int}} = \\sum_{\\tau=1}^{\\infty} \\rho(\\tau)$ is the integrated autocorrelation time, this simplifies to:\n$$ \\mathrm{Var}(\\bar{O}) \\approx \\frac{\\sigma^2}{N} (1 + 2\\tau_{\\mathrm{int}}) = \\frac{\\sigma^2}{N_{\\mathrm{eff}}} $$\nHere, $N_{\\mathrm{eff}} = N / (1+2\\tau_{\\mathrm{int}})$ is the effective number of independent samples. For correlated data ($\\tau_{\\mathrm{int}} > 0$), the naive uncertainty estimate, which assumes independent data and calculates variance as $\\sigma^2/N$, is a significant underestimation.\n\nThe principle of blocking analysis is to group the correlated data into larger blocks that are approximately uncorrelated. The data series is divided into $n_b$ contiguous, non-overlapping blocks, each of length $b$. The mean of each block, $M_k$, is calculated. If the block size $b$ is chosen to be much larger than the integrated autocorrelation time ($b \\gg \\tau_{\\mathrm{int}}$), then the block means $\\{M_k\\}$ will be approximately independent and identically distributed (i.i.d.) random variables. For such i.i.d. variables, the variance of their mean (which is the overall mean $\\bar{O}$) can be estimated using the standard formula:\n$$ \\mathrm{Var}(\\bar{O}) \\approx \\frac{\\mathrm{Var}(M_k)}{n_b} $$\nWe estimate $\\mathrm{Var}(M_k)$ using the sample variance of the block means, $\\hat{\\sigma}_M^2$. The standard error of $\\bar{O}$ is then $\\sqrt{\\hat{\\sigma}_M^2 / n_b}$.\n\nThe choice of block size $b$ is critical.\n- If $b$ is too small ($b \\lesssim \\tau_{\\mathrm{int}}$), the block means are still correlated, and the variance estimate will be too low.\n- As $b$ increases, the estimate for $\\mathrm{Var}(\\bar{O})$ increases and converges to a plateau value once $b \\gg \\tau_{\\mathrm{int}}$. This plateau represents the correct variance estimate.\n- If $b$ is too large, the number of blocks $n_b = N/b$ becomes small, leading to a statistically unreliable (noisy) estimate of the variance. A rule of thumb is to keep at least $n_b \\gtrsim 20$ blocks.\n\n### Option-by-Option Analysis\n\n**A. Correct.** This option accurately describes the blocking procedure, the behavior of the variance estimator as a function of block size (rising to a plateau), and the correct criteria for selecting a good block size: $b$ must be large enough to ensure block independence ($b \\gtrsim \\text{few} \\times \\tau_{\\mathrm{int}}$) but small enough to retain a statistically significant number of blocks ($n_b \\gtrsim 20$). The numerical example is sound: with $\\tau_{\\mathrm{int}} \\approx \\tau_{\\exp} = 100$, a block size of $b=1000$ gives $b=10\\tau_{\\mathrm{int}}$ and $n_b=100$, which is excellent. A block size of $b=5000$ gives $b=50\\tau_{\\mathrm{int}}$ and $n_b=20$, which is also acceptable.\n\n**B. Incorrect.** Choosing $b \\approx \\tau_{\\mathrm{int}}$ is insufficient to make block means uncorrelated; one needs $b \\gg \\tau_{\\mathrm{int}}$. Increasing $b$ beyond $\\tau_{\\mathrm{int}}$ does not cause a high bias; it reduces the bias from correlation but increases statistical noise. The estimated error *increases* with $b$ until it plateaus, it does not decrease.\n\n**C. Incorrect.** Randomly permuting the data destroys the time-series correlations. The uncertainty of the mean of a physically generated time series depends crucially on this temporal order. This procedure calculates the uncertainty for a different, unrelated statistical problem.\n\n**D. Incorrect.** Using a single block ($b=N, n_b=1$) makes it impossible to estimate the variance, as variance is a measure of spread among multiple samples. The sample variance formula involves division by $n_b-1=0$.\n\n**E. Incorrect.** This describes subsampling (decimation), which is statistically inefficient as it throws away most of the data. Blocking uses all the data and provides a more precise estimate of both the mean and its uncertainty for the same computational effort. The claim of \"better statistics\" is false.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}