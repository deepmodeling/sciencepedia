{
    "hands_on_practices": [
        {
            "introduction": "Effective machine learning models in materials science are often built upon physically-grounded features, or \"descriptors,\" rather than raw compositional data alone. This exercise focuses on one of the most fundamental descriptors in alloy design, the atomic size mismatch ($\\delta$), which quantifies the lattice strain induced by substitutional atoms of varying sizes. By calculating this parameter , you will gain hands-on experience with a key metric that underpins classic solid-state physics principles and helps predict the propensity for solid solution formation in complex alloys.",
            "id": "3747160",
            "problem": "In the inverse design of High-Entropy Alloys (HEAs) and complex concentrated alloys, a key mechanistic descriptor of solid solution propensity is the composition-weighted atomic size mismatch, which quantifies how substitutional disorder perturbs the host lattice. Starting from linear elasticity for small strains and the definition of a composition-weighted average radius, construct a dimensionless mismatch metric that is the square root of a composition-weighted mean square of relative radius deviations. Using this metric as a physically grounded feature, explain why, at fixed temperature, increasing the mismatch introduces a rising elastic enthalpic penalty that competes with the configurational entropy, thereby producing a monotonic relationship between mismatch and the likelihood of single-phase solid solution formation in machine learning classifiers.\n\nThen compute the mismatch metric for the equiatomic refractory HEA candidate $\\mathrm{Ti}$–$\\mathrm{Zr}$–$\\mathrm{Hf}$–$\\mathrm{Nb}$–$\\mathrm{Ta}$ with metallic radii (assumed for twelvefold coordination) $r_{\\mathrm{Ti}}=147\\ \\text{pm}$, $r_{\\mathrm{Zr}}=160\\ \\text{pm}$, $r_{\\mathrm{Hf}}=159\\ \\text{pm}$, $r_{\\mathrm{Nb}}=146\\ \\text{pm}$, and $r_{\\mathrm{Ta}}=146\\ \\text{pm}$, and mole fractions $x_i=0.2$ for each element. Define the composition-weighted mean radius as $\\bar r=\\sum_i x_i r_i$, the relative deviation for species $i$ as $1-\\frac{r_i}{\\bar r}$, and the mismatch metric as the square root of the composition-weighted mean square of these deviations. Round your final value to four significant figures. Express the final answer as a dimensionless number.",
            "solution": "The goal is to connect a physically motivated descriptor to solid solution formation and then to compute it for a specified equiatomic alloy.\n\nFundamental base:\n1. For small elastic strains, linear elasticity applies, and the elastic energy density scales as the square of strain. For a homogeneous isotropic solid, the elastic energy density can be written as a quadratic form in strain with moduli such as the bulk modulus and shear modulus. When substitutional atoms differ in radius from a mean matrix radius, they induce local dilatational (volumetric) and shear strains in the lattice.\n2. The composition-weighted mean atomic radius is defined as $\\bar r=\\sum_i x_i r_i$. Deviations from this mean, normalized by $\\bar r$, define a nondimensional misfit strain, $\\epsilon_i = (r_i-\\bar r)/\\bar r$. The relative deviation used in the metric, $1-r_i/\\bar r$, is equal to $-\\epsilon_i$.\n3. Because elastic enthalpy contributions scale quadratically with strain, a natural scalar descriptor of the aggregate mismatch in a random substitutional alloy is the composition-weighted root-mean-square of these normalized deviations:\n$$\n\\delta=\\sqrt{\\sum_i x_i\\left(1-\\frac{r_i}{\\bar r}\\right)^{2}}\n$$\nThis $\\delta$ is dimensionless and measures the typical relative size misfit in the alloy.\n\nWhy $\\delta$ correlates with single-phase solid solution formation:\n- The Helmholtz free energy per atom can be viewed schematically as $F=H-T S$, where $H$ contains the elastic enthalpy penalty from size mismatch and other interaction terms, and $S$ includes the configurational entropy. For a random substitutional alloy with $n$ components at mole fractions $\\{x_i\\}$, the configurational entropy per atom is $S_{\\mathrm{conf}}= -k_{B}\\sum_i x_i \\ln x_i$ and is independent of the atomic radii $\\{r_i\\}$ for fixed composition.\n- The elastic part of the enthalpy increases with the square of the misfit strain, and at a coarse-grained level scales as a modulus times $\\sum_i x_i \\epsilon_i^{2}$; hence, the enthalpic penalty is monotonically increasing in $\\delta^{2}$. For fixed $T$ and $\\{x_i\\}$, a larger $\\delta$ raises $H$ without increasing $S_{\\mathrm{conf}}$, thereby increasing $F$ and making the single-phase random solid solution less favorable relative to phase separation or intermetallic formation.\n- Therefore, in supervised machine learning classifiers or probabilistic models that take physically motivated features, a monotonic negative relationship between $\\delta$ and the probability of single-phase solid solution formation is expected, with other features (e.g., mixing enthalpy, electronegativity differences, valence electron concentration) providing additional modulation. In inverse design, minimizing $\\delta$ subject to target property constraints reduces elastic mismatch penalties and increases the likelihood of single-phase solutions.\n\nCompute $\\delta$ for the given HEA:\n- Given equiatomic fractions $x_i=0.2$ for each of the five elements and metallic radii\n$\nr_{\\mathrm{Ti}}=147\\ \\text{pm},\\quad\nr_{\\mathrm{Zr}}=160\\ \\text{pm},\\quad\nr_{\\mathrm{Hf}}=159\\ \\text{pm},\\quad\nr_{\\mathrm{Nb}}=146\\ \\text{pm},\\quad\nr_{\\mathrm{Ta}}=146\\ \\text{pm}.\n$\nFirst compute the mean radius:\n$$\n\\bar r=\\sum_i x_i r_i\n=0.2\\,(147+160+159+146+146)\\ \\text{pm}\n=0.2\\times 758\\ \\text{pm}\n=151.6\\ \\text{pm}.\n$$\nCompute the normalized deviations $1-\\frac{r_i}{\\bar r}$ for each element:\n$$\n1-\\frac{r_{\\mathrm{Ti}}}{\\bar r}=1-\\frac{147}{151.6}\\approx 1-0.9697=0.0303,\n$$\n$$\n1-\\frac{r_{\\mathrm{Zr}}}{\\bar r}=1-\\frac{160}{151.6}\\approx 1-1.0554=-0.0554,\n$$\n$$\n1-\\frac{r_{\\mathrm{Hf}}}{\\bar r}=1-\\frac{159}{151.6}\\approx 1-1.0488=-0.0488,\n$$\n$$\n1-\\frac{r_{\\mathrm{Nb}}}{\\bar r}=1-\\frac{146}{151.6}\\approx 1-0.9630=0.0370,\n$$\n$$\n1-\\frac{r_{\\mathrm{Ta}}}{\\bar r}=1-\\frac{146}{151.6}\\approx 1-0.9630=0.0370.\n$$\nForm the composition-weighted mean square and take the square root:\n$$\n\\delta=\\sqrt{\\sum_i x_i\\left(1-\\frac{r_i}{\\bar r}\\right)^{2}}\n=\\sqrt{0.2\\left(0.0303^{2}+(-0.0554)^{2}+(-0.0488)^{2}+0.0370^{2}+0.0370^{2}\\right)}.\n$$\nEvaluate the inside:\n$$\n0.0303^{2}\\approx 9.18\\times 10^{-4},\\quad\n(-0.0554)^{2}\\approx 3.07\\times 10^{-3},\\quad\n(-0.0488)^{2}\\approx 2.38\\times 10^{-3},\\quad\n0.0370^{2}\\approx 1.37\\times 10^{-3}.\n$$\nSum:\n$$\n9.18\\times 10^{-4}+3.07\\times 10^{-3}+2.38\\times 10^{-3}+1.37\\times 10^{-3}+1.37\\times 10^{-3}\n\\approx 9.104\\times 10^{-3}.\n$$\nMultiply by $0.2$:\n$$\n0.2\\times 9.104\\times 10^{-3}\\approx 1.8208\\times 10^{-3}.\n$$\nTake the square root:\n$$\n\\delta\\approx \\sqrt{1.8208\\times 10^{-3}}\\approx 0.04267.\n$$\nRounded to four significant figures and expressed as a dimensionless number, the mismatch metric is $0.04267$. By the energetic argument above, this relatively small value is consistent with increased likelihood of single-phase solid solution formation compared to alloys with larger mismatch, when considered alongside other thermodynamic and electronic descriptors in machine learning models for inverse design.",
            "answer": "$$\\boxed{0.04267}$$"
        },
        {
            "introduction": "A core task in a materials design loop is to rapidly evaluate candidate compositions using a predictive model. This practice simulates this step by taking the output from a hypothetical machine learning surrogate model—pairwise interaction parameters ($\\Omega_{ij}$)—and using them within a classic thermodynamic framework. You will calculate the Gibbs free energy of mixing ($\\Delta G_{\\mathrm{mix}}$) to assess whether a candidate high-entropy alloy is thermodynamically favored to form a single-phase solid solution .",
            "id": "3747189",
            "problem": "An inverse design workflow for high-entropy alloys (HEAs) uses a machine learning surrogate to predict pairwise interaction parameters between species in a quinary equiatomic alloy. Consider a candidate quinary equiatomic alloy with species labeled $A$, $B$, $C$, $D$, and $E$ at temperature $T = 1200$ K. The model assumes a symmetric pairwise regular-solution form for the enthalpy of mixing per mole, and ideal configurational entropy for the disordered single-phase solid solution. Neglect vibrational, electronic, and magnetic contributions beyond these terms. The machine learning surrogate predicts the following symmetric pairwise interaction parameters $\\Omega_{ij}$ (molar basis) for $i \\neq j$:\n- $\\Omega_{AB} = -2.0$ kJ mol$^{-1}$, $\\Omega_{AC} = -1.5$ kJ mol$^{-1}$, $\\Omega_{AD} = 0.5$ kJ mol$^{-1}$, $\\Omega_{AE} = 1.0$ kJ mol$^{-1}$,\n- $\\Omega_{BC} = -0.2$ kJ mol$^{-1}$, $\\Omega_{BD} = 0.8$ kJ mol$^{-1}$, $\\Omega_{BE} = 0.3$ kJ mol$^{-1}$,\n- $\\Omega_{CD} = -0.7$ kJ mol$^{-1}$, $\\Omega_{CE} = 1.2$ kJ mol$^{-1}$,\n- $\\Omega_{DE} = -0.4$ kJ mol$^{-1}$.\n\nTake the universal gas constant as $R = 8.314462618$ J mol$^{-1}$ K$^{-1}$. Starting from the definition of the molar Gibbs free energy of mixing as the enthalpy of mixing minus temperature times the entropy of mixing, and using the ideal multicomponent configurational entropy together with a composition-dependent regular-solution enthalpy, compute the molar Gibbs free energy of mixing $\\Delta G_{\\mathrm{mix}}(\\{x_i\\},T)$ at equiatomic composition $x_A = x_B = x_C = x_D = x_E = 1/5$. Express your final numerical answer in kJ mol$^{-1}$, rounded to four significant figures. Also, based on the sign of $\\Delta G_{\\mathrm{mix}}$, assess whether a single-phase random solid solution is thermodynamically favored within this model at the specified temperature. Your final reported answer must be only the value of $\\Delta G_{\\mathrm{mix}}$ as instructed; provide the stability assessment within your working, not in the final answer.",
            "solution": "The molar Gibbs free energy of mixing, $\\Delta G_{\\mathrm{mix}}$, is defined as:\n$$\n\\Delta G_{\\mathrm{mix}} = \\Delta H_{\\mathrm{mix}} - T \\Delta S_{\\mathrm{mix}}\n$$\nwhere $\\Delta H_{\\mathrm{mix}}$ is the molar enthalpy of mixing, $T$ is the absolute temperature, and $\\Delta S_{\\mathrm{mix}}$ is the molar entropy of mixing. We will calculate each term separately.\n\nFirst, we address the molar enthalpy of mixing, $\\Delta H_{\\mathrm{mix}}$. For a multicomponent regular solution containing $N$ components, $\\Delta H_{\\mathrm{mix}}$ is given by the sum of pairwise interaction energies:\n$$\n\\Delta H_{\\mathrm{mix}} = \\sum_{i=1}^{N} \\sum_{j=i+1}^{N} \\Omega_{ij} x_i x_j\n$$\nIn this problem, we have a quinary alloy ($N=5$) with species $A, B, C, D, E$. The composition is equiatomic, which means the mole fraction $x_i$ for each component is $x_i = \\frac{1}{5}$. Since the composition is uniform, the product $x_i x_j$ is constant for all pairs $(i, j)$ with $i \\neq j$:\n$$\nx_i x_j = \\left(\\frac{1}{5}\\right) \\left(\\frac{1}{5}\\right) = \\frac{1}{25}\n$$\nThe enthalpy of mixing can thus be simplified to:\n$$\n\\Delta H_{\\mathrm{mix}} = \\frac{1}{25} \\sum_{ij} \\Omega_{ij}\n$$\nThe pairwise interaction parameters $\\Omega_{ij}$ are given in units of kJ mol$^{-1}$:\n$\\Omega_{AB} = -2.0$, $\\Omega_{AC} = -1.5$, $\\Omega_{AD} = 0.5$, $\\Omega_{AE} = 1.0$,\n$\\Omega_{BC} = -0.2$, $\\Omega_{BD} = 0.8$, $\\Omega_{BE} = 0.3$,\n$\\Omega_{CD} = -0.7$, $\\Omega_{CE} = 1.2$,\n$\\Omega_{DE} = -0.4$.\n\nWe sum these values:\n$$\n\\sum_{ij} \\Omega_{ij} = (-2.0) + (-1.5) + (0.5) + (1.0) + (-0.2) + (0.8) + (0.3) + (-0.7) + (1.2) + (-0.4) \\, \\text{kJ mol}^{-1}\n$$\n$$\n\\sum_{ij} \\Omega_{ij} = (-2.0 - 1.5 - 0.2 - 0.7 - 0.4) + (0.5 + 1.0 + 0.8 + 0.3 + 1.2) \\, \\text{kJ mol}^{-1}\n$$\n$$\n\\sum_{ij} \\Omega_{ij} = (-4.8) + (3.8) = -1.0 \\, \\text{kJ mol}^{-1}\n$$\nNow, we can calculate $\\Delta H_{\\mathrm{mix}}$:\n$$\n\\Delta H_{\\mathrm{mix}} = \\frac{1}{25} (-1.0 \\, \\text{kJ mol}^{-1}) = -0.04 \\, \\text{kJ mol}^{-1}\n$$\n\nNext, we calculate the molar entropy of mixing, $\\Delta S_{\\mathrm{mix}}$. The problem specifies using the ideal configurational entropy for a multicomponent system, which is given by:\n$$\n\\Delta S_{\\mathrm{mix}} = -R \\sum_{i=1}^{N} x_i \\ln(x_i)\n$$\nwhere $R$ is the universal gas constant. For the quinary equiatomic alloy ($N=5$, $x_i = \\frac{1}{5}$ for all $i$):\n$$\n\\Delta S_{\\mathrm{mix}} = -R \\sum_{i=1}^{5} \\frac{1}{5} \\ln\\left(\\frac{1}{5}\\right) = -R \\cdot 5 \\cdot \\left(\\frac{1}{5} \\ln\\left(\\frac{1}{5}\\right)\\right) = -R \\ln\\left(\\frac{1}{5}\\right) = R \\ln(5)\n$$\nThe entropic contribution to the Gibbs free energy is $-T \\Delta S_{\\mathrm{mix}}$:\n$$\n-T \\Delta S_{\\mathrm{mix}} = -T R \\ln(5)\n$$\nThe problem provides $T = 1200$ K and $R = 8.314462618$ J mol$^{-1}$ K$^{-1}$. To maintain consistent units (kJ mol$^{-1}$), we use $R = 0.008314462618$ kJ mol$^{-1}$ K$^{-1}$.\n$$\n-T \\Delta S_{\\mathrm{mix}} = -(1200 \\, \\text{K}) \\times (0.008314462618 \\, \\text{kJ mol}^{-1} \\text{K}^{-1}) \\times \\ln(5)\n$$\n$$\n-T \\Delta S_{\\mathrm{mix}} \\approx -(1200) \\times (0.008314462618) \\times (1.609437912) \\, \\text{kJ mol}^{-1}\n$$\n$$\n-T \\Delta S_{\\mathrm{mix}} \\approx -16.05833 \\, \\text{kJ mol}^{-1}\n$$\n\nFinally, we combine the enthalpic and entropic terms to find the total Gibbs free energy of mixing:\n$$\n\\Delta G_{\\mathrm{mix}} = \\Delta H_{\\mathrm{mix}} - T \\Delta S_{\\mathrm{mix}} = (-0.04) + (-16.05833) \\, \\text{kJ mol}^{-1}\n$$\n$$\n\\Delta G_{\\mathrm{mix}} \\approx -16.09833 \\, \\text{kJ mol}^{-1}\n$$\nThe problem requires the final answer to be rounded to four significant figures.\n$$\n\\Delta G_{\\mathrm{mix}} \\approx -16.10 \\, \\text{kJ mol}^{-1}\n$$\n\nBased on the sign of $\\Delta G_{\\mathrm{mix}}$, we can assess the thermodynamic stability of the single-phase solid solution. Since $\\Delta G_{\\mathrm{mix}} = -16.10$ kJ mol$^{-1}$ is negative, the formation of a random solid solution from the pure constituent elements is a thermodynamically favorable process at $T=1200$ K. The mixed state has a lower Gibbs free energy than the unmixed components, indicating a driving force for mixing and suggesting that the single-phase solid solution is stable against decomposition into multiple phases or segregation of pure elements under these conditions and within the assumptions of the model.",
            "answer": "$$\\boxed{-16.10}$$"
        },
        {
            "introduction": "Real-world materials design is a multi-objective challenge, requiring a balance between conflicting goals such as maximizing strength, ensuring stability, and minimizing cost. This advanced practice places you at the heart of this optimization process by implementing the selection mechanism of the Non-dominated Sorting Genetic Algorithm II (NSGA-II) . By sorting candidates into Pareto fronts and evaluating their diversity, you will learn how to systematically identify a set of optimal, trade-off solutions from a large design space.",
            "id": "3747209",
            "problem": "You are given a toy inverse-design task for High-Entropy Alloys (HEAs) in the setting of multi-objective optimization with a surrogate Machine Learning model. Consider compositions of an equiatomic five-component HEA based on the elements Iron (Fe), Cobalt (Co), Nickel (Ni), Chromium (Cr), and Manganese (Mn). A composition is a vector $\\mathbf{x} = (x_1, x_2, x_3, x_4, x_5)$ of atomic fractions with $x_i \\ge 0$ and $\\sum_{i=1}^{5} x_i = 1$. Define three surrogate objective functions to be minimized, derived from widely used mixture rules and solid-solution strengthening principles:\n\n- Objective $g_1(\\mathbf{x}) = -\\sigma_y(\\mathbf{x})$, where the surrogate yield strength $\\sigma_y(\\mathbf{x})$ in megapascals is modeled by\n$$\n\\sigma_y(\\mathbf{x}) = \\sigma_0 + k_{\\mathrm{ss}} \\sqrt{\\sum_{i=1}^{5} x_i \\left(\\frac{r_i - \\bar{r}}{\\bar{r}}\\right)^2} + k_E \\bar{E},\n$$\nwith $\\bar{r} = \\sum_{i=1}^{5} x_i r_i$ the average metallic radius in angstroms, $\\bar{E} = \\sum_{i=1}^{5} x_i E_i$ the mixture-rule Young's modulus in gigapascals, baseline strength $\\sigma_0$, solid-solution strengthening coefficient $k_{\\mathrm{ss}}$, and modulus contribution coefficient $k_E$.\n\n- Objective $g_2(\\mathbf{x}) = -S_{\\mathrm{conf}}(\\mathbf{x})$, where the configurational mixing entropy $S_{\\mathrm{conf}}(\\mathbf{x})$ in joules per mole-kelvin is given by the classical formula\n$$\nS_{\\mathrm{conf}}(\\mathbf{x}) = - R \\sum_{i=1}^{5} x_i \\ln(x_i),\n$$\nwith $R$ the ideal gas constant. Interpret the term $x \\ln(x)$ as $0$ when $x = 0$ (the limit as $x \\to 0^+$).\n\n- Objective $g_3(\\mathbf{x}) = \\sum_{i=1}^{5} x_i c_i$, the estimated cost in dollars per kilogram using a linear mixture rule.\n\nUse the following element property vectors (all entries are constants and are scientifically plausible approximations for common data):\n$$\n\\mathbf{r} = (1.26, 1.25, 1.24, 1.28, 1.27) \\text{ angstroms},\n$$\n$$\n\\mathbf{E} = (211, 210, 200, 279, 198) \\text{ gigapascals},\n$$\n$$\n\\mathbf{c} = (0.5, 40, 18, 10, 2.5) \\text{ dollars per kilogram},\n$$\nand coefficients\n$$\n\\sigma_0 = 150 \\text{ megapascals}, \\quad k_{\\mathrm{ss}} = 850 \\text{ megapascals}, \\quad k_E = 0.5 \\text{ megapascals per gigapascal}, \\quad R = 8.314 \\text{ joules per mole-kelvin}.\n$$\n\nYour task is to implement the selection step of the Non-dominated Sorting Genetic Algorithm II (NSGA-II), which uses nondominated sorting to produce Pareto fronts and crowding distance to preserve diversity. Specifically:\n\n- Implement minimization-based Pareto dominance on $\\mathbf{g}(\\mathbf{x}) = (g_1(\\mathbf{x}), g_2(\\mathbf{x}), g_3(\\mathbf{x}))$, where a candidate $\\mathbf{x}^{(a)}$ dominates $\\mathbf{x}^{(b)}$ if and only if $g_m(\\mathbf{x}^{(a)}) \\le g_m(\\mathbf{x}^{(b)})$ for all objectives $m \\in \\{1,2,3\\}$ and $g_m(\\mathbf{x}^{(a)})  g_m(\\mathbf{x}^{(b)})$ for at least one objective $m$.\n\n- Perform nondominated sorting to partition the population into fronts $F_1, F_2, \\ldots$ by rank. The first front $F_1$ contains all nondominated candidates, the second front $F_2$ contains candidates only dominated by candidates in $F_1$, and so on.\n\n- Compute the NSGA-II crowding distance within each front on the objective values, using objective-wise sorting and normalized nearest-neighbor differences.\n\n- Select the next generation of size $K$ by taking whole fronts in increasing rank order until the next front would exceed $K$. For the final partially included front, select the top crowding-distance candidates (larger distance preferred). Resolve any ties deterministically by increasing index order.\n\nThe final output format must be a single line containing a comma-separated list of the results for the provided test cases, enclosed in square brackets. Each result must be a list of zero-based indices of the selected candidates, in the exact order of selection. No physical units are required in the program output, and angles are not applicable.\n\nTest suite. For each case, the program must compute objectives from the given compositions and apply NSGA-II selection to return the next generation indices:\n\n- Case $1$: $N = 12$, $K = 6$, compositions\n$\n\\begin{aligned}\n[0.2, 0.2, 0.2, 0.2, 0.2],\\; [0.4, 0.1, 0.1, 0.2, 0.2],\\; [0.1, 0.4, 0.2, 0.1, 0.2],\\; [0.05, 0.05, 0.6, 0.15, 0.15],\\\\\n[0.3, 0.3, 0.1, 0.2, 0.1],\\; [0.1, 0.2, 0.3, 0.1, 0.3],\\; [0.25, 0.25, 0.25, 0.15, 0.10],\\; [0.5, 0.2, 0.1, 0.1, 0.1],\\\\\n[0.1, 0.1, 0.1, 0.6, 0.1],\\; [0.05, 0.5, 0.1, 0.15, 0.2],\\; [0.05, 0.05, 0.05, 0.05, 0.8],\\; [0.2, 0.1, 0.5, 0.1, 0.1]\n\\end{aligned}\n$.\n\n- Case $2$: $N = 8$, $K = 4$, compositions\n$\n\\begin{aligned}\n[0.2, 0.2, 0.2, 0.2, 0.2],\\; [0.2, 0.2, 0.2, 0.2, 0.2],\\; [0.1, 0.2, 0.3, 0.2, 0.2],\\; [0.3, 0.2, 0.1, 0.2, 0.2],\\\\\n[0.01, 0.29, 0.3, 0.2, 0.2],\\; [0.4, 0.1, 0.2, 0.1, 0.2],\\; [0.45, 0.1, 0.15, 0.1, 0.2],\\; [0.1, 0.1, 0.4, 0.2, 0.2]\n\\end{aligned}\n$.\n\n- Case $3$: $N = 10$, $K = 9$, compositions\n$\n\\begin{aligned}\n[0.22, 0.18, 0.20, 0.20, 0.20],\\; [0.18, 0.22, 0.20, 0.20, 0.20],\\; [0.30, 0.10, 0.25, 0.20, 0.15],\\; [0.10, 0.30, 0.25, 0.20, 0.15],\\\\\n[0.26, 0.24, 0.10, 0.20, 0.20],\\; [0.12, 0.28, 0.20, 0.25, 0.15],\\; [0.28, 0.12, 0.20, 0.25, 0.15],\\; [0.05, 0.35, 0.30, 0.20, 0.10],\\\\\n[0.35, 0.05, 0.30, 0.20, 0.10],\\; [0.20, 0.20, 0.20, 0.20, 0.20]\n\\end{aligned}\n$.\n\n- Case $4$: $N = 5$, $K = 5$, compositions\n$\n\\begin{aligned}\n[0.24, 0.19, 0.19, 0.19, 0.19],\\; [0.19, 0.24, 0.19, 0.19, 0.19],\\; [0.19, 0.19, 0.24, 0.19, 0.19],\\; [0.19, 0.19, 0.19, 0.24, 0.19],\\\\\n[0.20, 0.20, 0.20, 0.20, 0.20]\n\\end{aligned}\n$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[result_1, result_2, result_3, result_4]$), where each $result_k$ is a list of zero-based indices of selected candidates for case $k$ in the exact NSGA-II selection order.",
            "solution": "The solution is structured as follows: First, we will formalize the objective functions based on the provided physical models. Second, we will describe the implementation of the NSGA-II selection procedure, which involves three key steps: nondominated sorting, crowding distance calculation, and elitist selection.\n\n**1. Objective Functions**\n\nThe problem defines three objective functions, $g_1$, $g_2$, and $g_3$, to be minimized for a given alloy composition vector $\\mathbf{x} = (x_1, x_2, x_3, x_4, x_5)$, where $x_i$ is the atomic fraction of element $i$ in a $5$-element system. The elements are Iron (Fe), Cobalt (Co), Nickel (Ni), Chromium (Cr), and Manganese (Mn), indexed from $1$ to $5$ respectively.\n\nThe required physical constants are:\n- Atomic radii: $\\mathbf{r} = (1.26, 1.25, 1.24, 1.28, 1.27)$ Angstroms\n- Young's moduli: $\\mathbf{E} = (211, 210, 200, 279, 198)$ Gigapascals\n- Cost vector: $\\mathbf{c} = (0.5, 40, 18, 10, 2.5)$ dollars per kilogram\n- Model coefficients: $\\sigma_0 = 150$ MPa, $k_{\\mathrm{ss}} = 850$ MPa, $k_E = 0.5$ MPa/GPa, and the ideal gas constant $R = 8.314$ J/(mol·K).\n\n- **Objective $g_1(\\mathbf{x})$: Yield Strength**\nThis objective aims to maximize the yield strength, $\\sigma_y$, which is equivalent to minimizing its negative, $g_1(\\mathbf{x}) = -\\sigma_y(\\mathbf{x})$. The surrogate model for yield strength is given by:\n$$\n\\sigma_y(\\mathbf{x}) = \\sigma_0 + k_{\\mathrm{ss}} \\sqrt{\\sum_{i=1}^{5} x_i \\left(\\frac{r_i - \\bar{r}}{\\bar{r}}\\right)^2} + k_E \\bar{E}\n$$\nThis model incorporates a baseline strength $\\sigma_0$, a solid-solution strengthening term proportional to the atomic size mismatch (the term under the square root), and a term reflecting the contribution of the average alloy stiffness $\\bar{E}$. The average properties are calculated using a linear rule of mixtures:\n- Average atomic radius: $\\bar{r} = \\sum_{i=1}^{5} x_i r_i$\n- Average Young's modulus: $\\bar{E} = \\sum_{i=1}^{5} x_i E_i$\n\n- **Objective $g_2(\\mathbf{x})$: Configurational Entropy**\nThis objective aims to maximize the configurational entropy of mixing, $S_{\\mathrm{conf}}$, which is equivalent to minimizing $g_2(\\mathbf{x}) = -S_{\\mathrm{conf}}(\\mathbf{x})$. High configurational entropy is a defining feature of HEAs, promoting the formation of stable single-phase solid solutions. The entropy is given by the Boltzmann formula for an ideal mixture:\n$$\nS_{\\mathrm{conf}}(\\mathbf{x}) = - R \\sum_{i=1}^{5} x_i \\ln(x_i)\n$$\nTherefore, the objective function to be minimized is:\n$$\ng_2(\\mathbf{x}) = - \\left(- R \\sum_{i=1}^{5} x_i \\ln(x_i) \\right) = R \\sum_{i=1}^{5} x_i \\ln(x_i)\n$$\nThe problem specifies that for any $x_i = 0$, the term $x_i \\ln(x_i)$ is taken to be $0$, which is consistent with the limit $\\lim_{x \\to 0^+} x \\ln(x) = 0$.\n\n- **Objective $g_3(\\mathbf{x})$: Material Cost**\nThis objective seeks to minimize the material cost, estimated by a linear mixture rule based on atomic fractions:\n$$\ng_3(\\mathbf{x}) = \\sum_{i=1}^{5} x_i c_i\n$$\n\n**2. NSGA-II Selection Algorithm**\n\nThe core of the task is to implement the selection mechanism of NSGA-II. Given a population of $N$ candidate compositions, the goal is to select the $K$ most promising candidates to form the next generation. This process is deterministic and consists of the following steps.\n\n**2.1. Nondominated Sorting**\nFirst, the entire population is partitioned into a set of \"fronts\" ($F_1, F_2, \\dots$) based on Pareto dominance. For a minimization problem, a solution $\\mathbf{x}^{(a)}$ dominates a solution $\\mathbf{x}^{(b)}$ if it is better or equal in all objectives and strictly better in at least one objective. Formally:\n$$\n\\mathbf{x}^{(a)} \\text{ dominates } \\mathbf{x}^{(b)} \\iff \\forall m \\in \\{1,2,3\\}, g_m(\\mathbf{x}^{(a)}) \\le g_m(\\mathbf{x}^{(b)}) \\land \\exists m' \\in \\{1,2,3\\}, g_m(\\mathbf{x}^{(a)})  g_m(\\mathbf{x}^{(b)})\n$$\nThe sorting algorithm proceeds as follows:\n1.  For each individual $p$, calculate two values: $n_p$, the number of individuals that dominate $p$, and $S_p$, a set of individuals that $p$ dominates.\n2.  The first front, $F_1$, is composed of all individuals for which $n_p = 0$. These are the non-dominated solutions in the entire population.\n3.  To find the second front, $F_2$, we visit each individual $p \\in F_1$. For each individual $q \\in S_p$, we decrement its domination count, $n_q$. If $n_q$ becomes $0$, then $q$ is added to the second front $F_2$.\n4.  This process is repeated iteratively, generating fronts $F_3, F_4, \\dots$ until all individuals have been assigned to a front. Each individual is assigned a rank equal to its front number (e.g., rank $1$ for $p \\in F_1$).\n\n**2.2. Crowding Distance Calculation**\nWithin each front, a crowding distance is calculated for each individual. This metric estimates the density of solutions surrounding that individual in the objective space. The goal is to prefer individuals in sparser regions to maintain diversity in the population. The calculation for a given front $F$ is:\n1.  Initialize the distance for all individuals in $F$ to $0$. Let the size of the front be $L = |F|$.\n2.  For each objective $m \\in \\{1,2,3\\}$:\n    a. Sort the individuals in $F$ based on their value for objective $g_m$.\n    b. Assign an infinite crowding distance to the two boundary individuals (those with the minimum and maximum objective values). This ensures they are always preserved.\n    c. For each interior individual $j$ in the sorted list, update its distance:\n       $$\n       d_j \\leftarrow d_j + \\frac{g_m(\\text{individual } j+1) - g_m(\\text{individual } j-1)}{g_m^{\\text{max}} - g_m^{\\text{min}}}\n       $$\n       where $g_m^{\\text{max}}$ and $g_m^{\\text{min}}$ are the maximum and minimum values of objective $m$ within the front $F$. If $g_m^{\\text{max}} = g_m^{\\text{min}}$, this term's contribution is $0$.\nThe total crowding distance for an individual is the sum of these normalized distances over all objectives.\n\n**2.3. Elitist Selection**\nThe final step is to build the next generation of size $K$.\n1.  Individuals are selected front by front, in order of rank ($F_1$, then $F_2$, etc.).\n2.  Whole fronts are added to the next generation until adding the next front would exceed the desired population size $K$. Let's say fronts $F_1, \\dots, F_{i-1}$ have been added, and the current next-generation size is $K_{\\text{current}}  K$.\n3.  If $K_{\\text{current}} + |F_i|  K$, the front $F_i$ must be partially included. The individuals within this front $F_i$ are sorted in descending order of their crowding distance. To ensure a deterministic outcome, any ties in crowding distance are broken by selecting the individual with the lower original index in the input population.\n4.  The top $K - K_{\\text{current}}$ individuals from the sorted front $F_i$ are added to complete the next generation.\n5.  To satisfy the problem's requirement for outputting indices \"in the exact order of selection,\" individuals from fully included fronts are added sorted by their original index, followed by the individuals from the partially included front, sorted by crowding distance and index as described above.\n\nThis procedure guarantees that the best-ranked solutions (elitism) are passed on, and among solutions of the same rank, diversity is promoted.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the NSGA-II selection problem for the given test cases.\n    \"\"\"\n    # Define physical and model constants\n    R_CONST = 8.314  # J/(mol·K)\n    SIGMA_0 = 150.0  # MPa\n    K_SS = 850.0  # MPa\n    K_E = 0.5  # MPa/GPa\n    \n    # Element properties (Fe, Co, Ni, Cr, Mn)\n    r_vec = np.array([1.26, 1.25, 1.24, 1.28, 1.27])  # Angstroms\n    E_vec = np.array([211.0, 210.0, 200.0, 279.0, 198.0])  # GPa\n    c_vec = np.array([0.5, 40.0, 18.0, 10.0, 2.5])  # $/kg\n\n    # Test case definitions\n    test_cases = [\n        {\"K\": 6, \"compositions\": np.array([\n            [0.2, 0.2, 0.2, 0.2, 0.2], [0.4, 0.1, 0.1, 0.2, 0.2], [0.1, 0.4, 0.2, 0.1, 0.2],\n            [0.05, 0.05, 0.6, 0.15, 0.15], [0.3, 0.3, 0.1, 0.2, 0.1], [0.1, 0.2, 0.3, 0.1, 0.3],\n            [0.25, 0.25, 0.25, 0.15, 0.10], [0.5, 0.2, 0.1, 0.1, 0.1], [0.1, 0.1, 0.1, 0.6, 0.1],\n            [0.05, 0.5, 0.1, 0.15, 0.2], [0.05, 0.05, 0.05, 0.05, 0.8], [0.2, 0.1, 0.5, 0.1, 0.1]\n        ])},\n        {\"K\": 4, \"compositions\": np.array([\n            [0.2, 0.2, 0.2, 0.2, 0.2], [0.2, 0.2, 0.2, 0.2, 0.2], [0.1, 0.2, 0.3, 0.2, 0.2],\n            [0.3, 0.2, 0.1, 0.2, 0.2], [0.01, 0.29, 0.3, 0.2, 0.2], [0.4, 0.1, 0.2, 0.1, 0.2],\n            [0.45, 0.1, 0.15, 0.1, 0.2], [0.1, 0.1, 0.4, 0.2, 0.2]\n        ])},\n        {\"K\": 9, \"compositions\": np.array([\n            [0.22, 0.18, 0.20, 0.20, 0.20], [0.18, 0.22, 0.20, 0.20, 0.20], [0.30, 0.10, 0.25, 0.20, 0.15],\n            [0.10, 0.30, 0.25, 0.20, 0.15], [0.26, 0.24, 0.10, 0.20, 0.20], [0.12, 0.28, 0.20, 0.25, 0.15],\n            [0.28, 0.12, 0.20, 0.25, 0.15], [0.05, 0.35, 0.30, 0.20, 0.10], [0.35, 0.05, 0.30, 0.20, 0.10],\n            [0.20, 0.20, 0.20, 0.20, 0.20]\n        ])},\n        {\"K\": 5, \"compositions\": np.array([\n            [0.24, 0.19, 0.19, 0.19, 0.19], [0.19, 0.24, 0.19, 0.19, 0.19], [0.19, 0.19, 0.24, 0.19, 0.19],\n            [0.19, 0.19, 0.19, 0.24, 0.19], [0.20, 0.20, 0.20, 0.20, 0.20]\n        ])}\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        K = case[\"K\"]\n        population = case[\"compositions\"]\n        N = population.shape[0]\n\n        # --- 1. Calculate Objectives for all individuals ---\n        objectives = np.zeros((N, 3))\n        for i, x in enumerate(population):\n            # Objective g1: -Yield Strength\n            r_bar = np.sum(x * r_vec)\n            E_bar = np.sum(x * E_vec)\n            size_mismatch_sq = ((r_vec - r_bar) / r_bar)**2\n            delta_sq_sum = np.sum(x * size_mismatch_sq)\n            sigma_y = SIGMA_0 + K_SS * np.sqrt(delta_sq_sum) + K_E * E_bar\n            g1 = -sigma_y\n            \n            # Objective g2: -Configurational Entropy\n            # Using np.where to handle x_i = 0 case\n            x_log_x = np.where(x > 0, x * np.log(x), 0)\n            g2 = R_CONST * np.sum(x_log_x)\n            \n            # Objective g3: Cost\n            g3 = np.sum(x * c_vec)\n            \n            objectives[i] = [g1, g2, g3]\n\n        # --- 2. Nondominated Sorting ---\n        dominates = [[] for _ in range(N)]\n        dominated_by_count = np.zeros(N, dtype=int)\n        \n        for p in range(N):\n            for q in range(p + 1, N):\n                obj_p = objectives[p]\n                obj_q = objectives[q]\n                \n                p_dominates_q = np.all(obj_p = obj_q) and np.any(obj_p  obj_q)\n                q_dominates_p = np.all(obj_q = obj_p) and np.any(obj_q  obj_p)\n                \n                if p_dominates_q:\n                    dominates[p].append(q)\n                    dominated_by_count[q] += 1\n                elif q_dominates_p:\n                    dominates[q].append(p)\n                    dominated_by_count[p] += 1\n        \n        fronts = []\n        current_front = list(np.where(dominated_by_count == 0)[0])\n        while current_front:\n            fronts.append(current_front)\n            next_front = []\n            for p in current_front:\n                for q in dominates[p]:\n                    dominated_by_count[q] -= 1\n                    if dominated_by_count[q] == 0:\n                        next_front.append(q)\n            current_front = sorted(next_front) # Sort for determinism\n\n        # --- 3. Crowding Distance Calculation and Selection ---\n        next_gen_indices = []\n        front_num = 0\n        \n        while front_num  len(fronts) and len(next_gen_indices) + len(fronts[front_num]) = K:\n            # Add full front, sorted by original index for deterministic order\n            next_gen_indices.extend(sorted(fronts[front_num]))\n            front_num += 1\n\n        if len(next_gen_indices)  K:\n            last_front_indices = fronts[front_num]\n            num_remaining = K - len(next_gen_indices)\n            \n            # Crowding distance assignment for the last front\n            num_individuals_in_front = len(last_front_indices)\n            crowding_distances = {idx: 0.0 for idx in last_front_indices}\n\n            for m in range(objectives.shape[1]):\n                # Sort by objective m, then index to break ties\n                sorted_front = sorted(last_front_indices, key=lambda idx: (objectives[idx, m], idx))\n                \n                obj_min = objectives[sorted_front[0], m]\n                obj_max = objectives[sorted_front[-1], m]\n                obj_range = obj_max - obj_min\n\n                crowding_distances[sorted_front[0]] = np.inf\n                crowding_distances[sorted_front[-1]] = np.inf\n\n                if obj_range > 0:\n                    for i in range(1, num_individuals_in_front - 1):\n                        prev_idx = sorted_front[i-1]\n                        next_idx = sorted_front[i+1]\n                        numerator = objectives[next_idx, m] - objectives[prev_idx, m]\n                        crowding_distances[sorted_front[i]] += numerator / obj_range\n\n            # Sort the last front by crowding distance (desc) and index (asc)\n            sorted_last_front = sorted(last_front_indices, key=lambda idx: (-crowding_distances[idx], idx))\n            \n            next_gen_indices.extend(sorted_last_front[:num_remaining])\n        \n        all_results.append(next_gen_indices)\n\n    # Print the final output in the required format\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}