{
    "hands_on_practices": [
        {
            "introduction": "The spatial arrangement of atomic species in an alloy is a fundamental determinant of its properties. To capture this information quantitatively, we often represent the alloy on a lattice and use correlation functions to describe the degree of chemical short-range order. This exercise provides foundational practice in this approach by asking you to compute the nearest-neighbor pair correlation for a specific binary alloy configuration, connecting an abstract mathematical descriptor to the physical concept of atomic ordering preference. ",
            "id": "3741480",
            "problem": "Consider a binary alloy on a body-centered cubic (bcc) lattice, where the body-centered cubic (bcc) lattice is bipartite: every nearest neighbor bond connects one site on the corner sublattice and one site on the body-center sublattice. The alloy is represented by Ising spins $\\sigma_i \\in \\{-1,1\\}$, with $\\sigma_i=+1$ denoting species $\\mathrm{A}$ and $\\sigma_i=-1$ denoting species $\\mathrm{B}$. Work with a periodic $2\\times 2\\times 2$ conventional-cell supercell, which contains $N=16$ lattice sites and has nearest neighbor coordination number $z=8$ for each site. Define the nearest-neighbor pair correlation as\n$$\n\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}} \\equiv \\frac{1}{N_{\\mathrm{nn}}} \\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j,\n$$\nwhere the sum runs over all unique nearest-neighbor pairs and $N_{\\mathrm{nn}}$ is the total number of such pairs in the supercell.\n\nConsider the following configuration with periodic boundary conditions: all $8$ body-center sublattice sites have $\\sigma_i=+1$, while the $8$ corner sublattice sites are split evenly with $4$ having $\\sigma_i=+1$ and $4$ having $\\sigma_i=-1$ (their specific positions are arbitrary). Compute the scalar value of $\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}}$ for this configuration. Then, interpret the sign and magnitude of the computed value in terms of short-range ordering and its role as a feature for high-entropy alloy modeling. Express your final numerical answer as an exact number with no units. No rounding is required.",
            "solution": "The problem statement is critically validated before attempting a solution.\n\n### Step 1: Extract Givens\n-   **System**: A binary alloy on a body-centered cubic (bcc) lattice.\n-   **Representation**: Ising spins $\\sigma_i \\in \\{-1, 1\\}$, where $\\sigma_i=+1$ is species A and $\\sigma_i=-1$ is species B.\n-   **Lattice Structure**: The bcc lattice is bipartite, consisting of a corner sublattice and a body-center sublattice. Nearest neighbors are always between these two sublattices.\n-   **Supercell**: A periodic $2 \\times 2 \\times 2$ conventional-cell supercell.\n-   **System Size**: Total number of lattice sites, $N=16$.\n-   **Coordination**: Nearest-neighbor coordination number, $z=8$.\n-   **Definition**: The nearest-neighbor pair correlation is defined as $\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}} \\equiv \\frac{1}{N_{\\mathrm{nn}}} \\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j$, where the sum is over unique nearest-neighbor pairs and $N_{\\mathrm{nn}}$ is the total number of such pairs.\n-   **Configuration**:\n    -   All $8$ body-center sublattice sites have $\\sigma_i=+1$.\n    -   The $8$ corner sublattice sites are split: $4$ sites have $\\sigma_i=+1$ and $4$ sites have $\\sigma_i=-1$. The specific arrangement of these spins on the corner sublattice is arbitrary.\n-   **Tasks**:\n    1.  Compute the scalar value of $\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}}$.\n    2.  Interpret the result in the context of short-range ordering and feature engineering for alloy modeling.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem uses the Ising model on a bcc lattice, a standard and fundamental framework in condensed matter physics and materials science for describing order-disorder phenomena in alloys. All concepts are well-established.\n-   **Well-Posed**: The problem provides a completely specified atomic configuration within a well-defined supercell geometry and asks for the calculation of a precisely defined quantity. The necessary information is present to yield a unique solution.\n-   **Objective**: The problem is stated using precise, formal language and definitions. It is free of ambiguity or subjective claims. A conventional bcc cell contains $2$ atoms. A $2 \\times 2 \\times 2$ supercell thus contains $2^3 \\times 2 = 16$ atoms, which is consistent with the given $N=16$. The coordination number $z=8$ is correct for the bcc lattice. The description of the configuration is unambiguous.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is scientifically sound, fully specified, and mathematically well-posed. The solution process may proceed.\n\n### Solution and Interpretation\n\nThe primary task is to compute the nearest-neighbor pair correlation, $\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}}$, for the given configuration. The formula is:\n$$\n\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}} = \\frac{1}{N_{\\mathrm{nn}}} \\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j\n$$\n\nFirst, we must determine the total number of unique nearest-neighbor pairs, $N_{\\mathrm{nn}}$, in the supercell. In a lattice with $N$ sites and coordination number $z$, each site participates in $z$ bonds. To count the total number of unique bonds, we sum the bonds for all sites and divide by $2$ to correct for double counting.\n$$\nN_{\\mathrm{nn}} = \\frac{N z}{2}\n$$\nGiven $N=16$ and $z=8$, we have:\n$$\nN_{\\mathrm{nn}} = \\frac{16 \\times 8}{2} = 64\n$$\nThere are $64$ unique nearest-neighbor pairs in the supercell.\n\nNext, we evaluate the sum $\\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j$. The bcc lattice is bipartite, meaning it can be divided into two sublattices, which we will call the corner sublattice ($C$) and the body-center sublattice ($B$), such that all nearest neighbors of a site on one sublattice lie on the other. In our $N=16$ atom supercell, there are $8$ sites on sublattice $C$ and $8$ sites on sublattice $B$.\n\nA key property of the specified $2 \\times 2 \\times 2$ periodic supercell of bcc conventional cells is that every site on the corner sublattice is a nearest neighbor to *every* site on the body-center sublattice. Let's confirm this. A site $i \\in C$ can be placed at the origin $(0,0,0)$. Its $8$ nearest neighbors are at positions $\\frac{a}{2}(\\pm 1, \\pm 1, \\pm 1)$, where $a$ is the conventional lattice constant. In the $2 \\times 2 \\times 2$ supercell (with lattice constant $2a$), these $8$ neighbor positions correspond precisely to the $8$ distinct body-center sites. Due to translational symmetry, this holds for any site on sublattice $C$.\n\nTherefore, the sum over nearest-neighbor pairs $\\langle i,j \\rangle$ can be written as a sum over all pairs with one site from each sublattice:\n$$\n\\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j = \\sum_{i \\in C} \\sum_{j \\in B} \\sigma_i \\sigma_j\n$$\nBecause the terms $\\sigma_i$ and $\\sigma_j$ are independent in this double summation, we can factor the sum:\n$$\n\\sum_{i \\in C} \\sum_{j \\in B} \\sigma_i \\sigma_j = \\left( \\sum_{i \\in C} \\sigma_i \\right) \\left( \\sum_{j \\in B} \\sigma_j \\right)\n$$\nNow, we compute the sum of spins for each sublattice based on the given configuration.\n\nFor the body-center sublattice $B$, all $8$ sites are occupied by species A ($\\sigma_j = +1$):\n$$\n\\sum_{j \\in B} \\sigma_j = \\sum_{j=1}^{8} (+1) = 8\n$$\nFor the corner sublattice $C$, $4$ sites are occupied by species A ($\\sigma_i = +1$) and $4$ sites are occupied by species B ($\\sigma_i = -1$). The statement that their specific positions are arbitrary is inconsequential for this calculation due to the full connectivity between sublattices.\n$$\n\\sum_{i \\in C} \\sigma_i = \\left( 4 \\times (+1) \\right) + \\left( 4 \\times (-1) \\right) = 4 - 4 = 0\n$$\nSubstituting these results back into the factored sum:\n$$\n\\sum_{\\langle i,j \\rangle} \\sigma_i \\sigma_j = (0) \\times (8) = 0\n$$\nFinally, we compute the nearest-neighbor pair correlation:\n$$\n\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}} = \\frac{0}{64} = 0\n$$\n\n### Interpretation\n\nThe computed value of the nearest-neighbor pair correlation is $\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}} = 0$. This result has a clear physical meaning regarding the chemical short-range order (SRO) of the alloy configuration.\n\n1.  **Significance of the Value**: The pair correlation $\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}}$ quantifies the preference for forming like (A-A, B-B) versus unlike (A-B) nearest-neighbor pairs.\n    -   A positive value ($\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}} > 0$) indicates a preference for like pairs, corresponding to clustering or a tendency toward phase separation.\n    -   A negative value ($\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}}  0$) indicates a preference for unlike pairs, corresponding to chemical ordering.\n    -   A value of zero ($\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}} = 0$) signifies that there is no net preference; the number of like nearest-neighbor pairs equals the number of unlike nearest-neighbor pairs.\n\n    In our specific case, the nearest neighbors are always between a corner site and a body-center site. All body-center sites are species A ($\\sigma_j=+1$). Therefore, a \"like\" pair can only be A-A, occurring when the corner site is A ($\\sigma_i \\sigma_j = (+1)(+1) = +1$). An \"unlike\" pair can only be B-A, occurring when the corner site is B ($\\sigma_i \\sigma_j = (-1)(+1) = -1$). There are $4$ corner sites of type A, each forming $8$ bonds with the A-type body-center sites, giving $4 \\times 8 = 32$ A-A pairs. There are $4$ corner sites of type B, each forming $8$ bonds, giving $4 \\times 8 = 32$ B-A pairs. The sum $\\sum \\sigma_i \\sigma_j$ is correctly $32 \\times (+1) + 32 \\times (-1) = 0$. The value of zero indicates a perfect balance between ordering (A-B) and clustering-like (A-A) tendencies at the nearest-neighbor distance. This is the state of zero short-range order as measured by this correlator.\n\n2.  **Role as a Feature for Alloy Modeling**: In the computational modeling of materials, especially complex systems like high-entropy alloys, it is essential to represent the atomic structure with a set of quantitative descriptors, or *features*. These features serve as the input for machine learning models that predict material properties (e.g., energy, stability, mechanical strength). The set of pair correlations $\\{\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}}, \\langle \\sigma_i \\sigma_k \\rangle_{\\mathrm{nnn}}, \\dots\\}$ for successive neighbor shells forms a powerful and systematically improvable basis for describing the chemical order. This is the foundation of the widely used cluster expansion method.\n\n    The nearest-neighbor correlation $\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}}$ is the most fundamental of these features. It captures the dominant SRO, which often has the strongest impact on the alloy's energy and properties. By calculating this single scalar value, we can quantitatively distinguish the given configuration from others with the same overall composition ($75\\%$ A, $25\\%$ B). For instance, a fully ordered structure or a phase-separated structure would have non-zero values for this feature. A machine learning model can learn the relationship between the value of $\\langle \\sigma_i \\sigma_j \\rangle_{\\mathrm{nn}}$ and a target property, allowing it to predict the behavior of new, unseen configurations. The value of zero for this feature signifies a specific structural state that is distinct from, say, a random solid solution, and would be mapped to a corresponding point in the property space by a trained model.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "While atomic structure is crucial, the electronic structure ultimately governs bonding, stability, and reactivity. The electronic density of states (DOS) provides a complete picture, but its high dimensionality makes it unwieldy as a direct model input. This practice demonstrates how to distill the essential information from a DOS curve into a few powerful features—its statistical moments—which serve as robust descriptors for the position (band center) and spread (band width) of electronic states. ",
            "id": "3741512",
            "problem": "An equiatomic quinary high-entropy alloy is characterized by its spin-averaged Kohn–Sham electronic density of states (DOS), denoted by $n(\\varepsilon)$, where $\\varepsilon$ is the energy referenced to the Fermi level. In feature engineering for alloy systems, DOS-derived statistical moments are used to represent the central tendency and dispersion of the electronic structure and to enable compositional and structural transferability in complex materials modeling. Starting from the definition of a density function and its statistical moments, derive the discrete expressions for the first moment (mean) and the second centered moment (variance) of the DOS when $n(\\varepsilon)$ is sampled on a uniform energy grid. Then, using those expressions, compute the moments from the following discretized DOS sampled at energies $\\varepsilon_j$ with corresponding DOS values $n_j \\equiv n(\\varepsilon_j)$:\n$\\varepsilon_1=-4.0\\,\\mathrm{eV}$ with $n_1=1.2$,\n$\\varepsilon_2=-2.5\\,\\mathrm{eV}$ with $n_2=3.8$,\n$\\varepsilon_3=-1.2\\,\\mathrm{eV}$ with $n_3=6.0$,\n$\\varepsilon_4=-0.3\\,\\mathrm{eV}$ with $n_4=5.5$,\n$\\varepsilon_5=0.7\\,\\mathrm{eV}$ with $n_5=4.9$,\n$\\varepsilon_6=1.5\\,\\mathrm{eV}$ with $n_6=3.6$,\n$\\varepsilon_7=2.8\\,\\mathrm{eV}$ with $n_7=2.4$,\n$\\varepsilon_8=4.2\\,\\mathrm{eV}$ with $n_8=1.1$.\nInterpret the physical meaning of the computed first and second centered moments as features for alloy representations. Finally, define a composite scalar descriptor\n$$\\Phi \\equiv \\mu_1 + \\sqrt{\\mu_2},$$\nwhere $\\mu_1$ is the first DOS moment and $\\mu_2$ is the second centered DOS moment you derived and computed. Report the value of $\\Phi$ in electronvolts. Round your final answer to four significant figures. Express the final energy in $\\mathrm{eV}$.",
            "solution": "The problem requires the derivation and computation of the first and second centered moments of a discretized electronic density of states (DOS), followed by a physical interpretation and the calculation of a composite descriptor.\n\n**Problem Validation**\n\nFirst, a critical examination of the problem statement is necessary. The problem states that the DOS, $n(\\varepsilon)$, is \"sampled on a uniform energy grid\". However, the provided energy values, $\\varepsilon_j$, are palpably not uniformly spaced. The differences $\\Delta\\varepsilon_j = \\varepsilon_{j+1} - \\varepsilon_j$ are not constant:\n$\\varepsilon_2 - \\varepsilon_1 = 1.5\\,\\mathrm{eV}$, $\\varepsilon_3 - \\varepsilon_2 = 1.3\\,\\mathrm{eV}$, $\\varepsilon_4 - \\varepsilon_3 = 0.9\\,\\mathrm{eV}$, etc.\nThis constitutes a direct contradiction between a premise and the supplied data.\n\nHowever, this does not render the problem fundamentally invalid. The task is to first derive the expressions for the moments assuming a uniform grid, and then apply them to the data. As we shall see, the derivation for a uniform grid leads to expressions where the grid spacing, $\\Delta\\varepsilon$, algebraically cancels. The resulting formulas are equivalent to those for a discrete weighted distribution, where the DOS values $n_j$ act as weights for the energy values $\\varepsilon_j$. This is a standard and physically meaningful interpretation for feature extraction from sampled DOS data in materials modeling. Thus, we may proceed by noting this textual inconsistency and applying the derived formulas, which are fortunately robust to this specific flaw in the problem's wording.\n\n**Part 1: Derivation of Discrete Moment Expressions**\n\nThe $k$-th raw moment of a continuous DOS distribution $n(\\varepsilon)$ is defined as:\n$$ \\langle\\varepsilon^k\\rangle = \\frac{\\int_{-\\infty}^{\\infty} \\varepsilon^k n(\\varepsilon) \\, d\\varepsilon}{\\int_{-\\infty}^{\\infty} n(\\varepsilon) \\, d\\varepsilon} $$\nThe denominator represents the total number of electronic states, $N_{tot} = \\int n(\\varepsilon) \\, d\\varepsilon$.\n\nThe first moment, $\\mu_1$, is the mean of the distribution:\n$$ \\mu_1 = \\langle\\varepsilon^1\\rangle = \\frac{\\int \\varepsilon n(\\varepsilon) \\, d\\varepsilon}{\\int n(\\varepsilon) \\, d\\varepsilon} $$\n\nThe second centered moment, $\\mu_2$, is the variance of the distribution:\n$$ \\mu_2 = \\langle(\\varepsilon - \\mu_1)^2\\rangle = \\frac{\\int (\\varepsilon - \\mu_1)^2 n(\\varepsilon) \\, d\\varepsilon}{\\int n(\\varepsilon) \\, d\\varepsilon} $$\nUsing the property $\\sigma^2 = E[X^2] - (E[X])^2$, the variance can also be expressed in terms of raw moments:\n$$ \\mu_2 = \\langle\\varepsilon^2\\rangle - \\mu_1^2 = \\frac{\\int \\varepsilon^2 n(\\varepsilon) \\, d\\varepsilon}{\\int n(\\varepsilon) \\, d\\varepsilon} - \\left( \\frac{\\int \\varepsilon n(\\varepsilon) \\, d\\varepsilon}{\\int n(\\varepsilon) \\, d\\varepsilon} \\right)^2 $$\n\nTo obtain the discrete expressions for a DOS sampled on a uniform energy grid with points $\\varepsilon_j$ and spacing $\\Delta\\varepsilon$, we approximate the integrals using a Riemann sum. The integral $\\int f(x) \\, dx$ is approximated by $\\sum_j f(x_j) \\Delta x$.\nApplying this to the moment definitions:\n$$ \\int \\varepsilon^k n(\\varepsilon) \\, d\\varepsilon \\approx \\sum_j \\varepsilon_j^k n(\\varepsilon_j) \\Delta\\varepsilon = \\Delta\\varepsilon \\sum_j \\varepsilon_j^k n_j $$\nwhere $n_j \\equiv n(\\varepsilon_j)$.\n\nSubstituting this approximation into the expression for the first moment $\\mu_1$:\n$$ \\mu_1 \\approx \\frac{\\sum_j \\varepsilon_j n_j \\Delta\\varepsilon}{\\sum_j n_j \\Delta\\varepsilon} = \\frac{\\Delta\\varepsilon \\sum_j \\varepsilon_j n_j}{\\Delta\\varepsilon \\sum_j n_j} = \\frac{\\sum_j \\varepsilon_j n_j}{\\sum_j n_j} $$\nAnd for the second centered moment $\\mu_2$:\n$$ \\mu_2 \\approx \\frac{\\sum_j \\varepsilon_j^2 n_j \\Delta\\varepsilon}{\\sum_j n_j \\Delta\\varepsilon} - \\mu_1^2 = \\frac{\\sum_j \\varepsilon_j^2 n_j}{\\sum_j n_j} - \\mu_1^2 $$\n\nAs observed, the constant grid spacing $\\Delta\\varepsilon$ cancels from the numerator and denominator in both expressions. Therefore, these formulas can be applied to the provided dataset despite its non-uniform sampling, by interpreting the problem as finding the moments of a discrete distribution defined by the pairs $(\\varepsilon_j, n_j)$.\n\n**Part 2: Computation of Moments**\n\nThe provided data consist of $N=8$ points $(\\varepsilon_j, n_j)$:\n$(\\varepsilon_1, n_1) = (-4.0, 1.2)$, $(\\varepsilon_2, n_2) = (-2.5, 3.8)$, $(\\varepsilon_3, n_3) = (-1.2, 6.0)$, $(\\varepsilon_4, n_4) = (-0.3, 5.5)$, $(\\varepsilon_5, n_5) = (0.7, 4.9)$, $(\\varepsilon_6, n_6) = (1.5, 3.6)$, $(\\varepsilon_7, n_7) = (2.8, 2.4)$, $(\\varepsilon_8, n_8) = (4.2, 1.1)$.\nThe units of energy are electronvolts ($\\mathrm{eV}$), and the DOS values are given in arbitrary units (typically states/eV/atom).\n\nFirst, we compute the sum of the DOS values, which serves as the normalization factor:\n$$ \\sum_{j=1}^{8} n_j = 1.2 + 3.8 + 6.0 + 5.5 + 4.9 + 3.6 + 2.4 + 1.1 = 28.5 $$\n\nNext, we calculate the sum for the first moment's numerator:\n$$ \\sum_{j=1}^{8} \\varepsilon_j n_j = (-4.0)(1.2) + (-2.5)(3.8) + (-1.2)(6.0) + (-0.3)(5.5) + (0.7)(4.9) + (1.5)(3.6) + (2.8)(2.4) + (4.2)(1.1) $$\n$$ \\sum_{j=1}^{8} \\varepsilon_j n_j = -4.8 - 9.5 - 7.2 - 1.65 + 3.43 + 5.4 + 6.72 + 4.62 = -2.98 $$\nThe first moment is then:\n$$ \\mu_1 = \\frac{\\sum \\varepsilon_j n_j}{\\sum n_j} = \\frac{-2.98}{28.5} \\approx -0.1045614\\,\\mathrm{eV} $$\n\nFor the second centered moment, we first compute the sum for the second raw moment's numerator:\n$$ \\sum_{j=1}^{8} \\varepsilon_j^2 n_j = (-4.0)^2(1.2) + (-2.5)^2(3.8) + (-1.2)^2(6.0) + (-0.3)^2(5.5) + (0.7)^2(4.9) + (1.5)^2(3.6) + (2.8)^2(2.4) + (4.2)^2(1.1) $$\n$$ \\sum_{j=1}^{8} \\varepsilon_j^2 n_j = (16.0)(1.2) + (6.25)(3.8) + (1.44)(6.0) + (0.09)(5.5) + (0.49)(4.9) + (2.25)(3.6) + (7.84)(2.4) + (17.64)(1.1) $$\n$$ \\sum_{j=1}^{8} \\varepsilon_j^2 n_j = 19.2 + 23.75 + 8.64 + 0.495 + 2.401 + 8.1 + 18.816 + 19.404 = 100.806 $$\nThe second raw moment is:\n$$ \\langle\\varepsilon^2\\rangle = \\frac{\\sum \\varepsilon_j^2 n_j}{\\sum n_j} = \\frac{100.806}{28.5} \\approx 3.5370526\\,\\mathrm{eV}^2 $$\nThe second centered moment is:\n$$ \\mu_2 = \\langle\\varepsilon^2\\rangle - \\mu_1^2 \\approx 3.5370526 - (-0.1045614)^2 \\approx 3.5370526 - 0.0109331 \\approx 3.5261195\\,\\mathrm{eV}^2 $$\n\n**Part 3: Physical Interpretation**\n\nThe computed statistical moments serve as powerful, low-dimensional features representing the complex electronic structure of the alloy.\n1.  **First Moment ($\\mu_1 \\approx -0.105\\,\\mathrm{eV}$)**: This value represents the weighted-average energy of the electronic states relative to the Fermi level ($\\varepsilon_F = 0\\,\\mathrm{eV}$). It is colloquially known as the \"band center\". In transition metal alloys, it often corresponds to the *d-band center*. A negative value indicates that the center of the electronic states lies below the Fermi level. The position of the band center is a critical indicator of interatomic bonding strength and chemical reactivity. A lower (more negative) band center generally correlates with stronger bonding and lower surface reactivity.\n2.  **Second Centered Moment ($\\mu_2 \\approx 3.526\\,\\mathrm{eV}^2$)**: This is the variance of the DOS, measuring its energetic spread or \"width\". The square root of the variance, $\\sqrt{\\mu_2} \\approx 1.878\\,\\mathrm{eV}$, is the standard deviation, which provides a more direct measure of the band width. A wider band (larger $\\mu_2$) signifies a greater degree of hybridization between atomic orbitals, which is typically associated with stronger covalent interactions and increased cohesive energy in the material.\n\n**Part 4: Calculation of the Composite Descriptor $\\Phi$**\n\nThe problem defines a composite scalar descriptor $\\Phi$ as:\n$$ \\Phi \\equiv \\mu_1 + \\sqrt{\\mu_2} $$\nThis descriptor combines information about the band's central position and its width. Using the computed values for $\\mu_1$ and $\\mu_2$:\n$$ \\Phi \\approx -0.1045614\\,\\mathrm{eV} + \\sqrt{3.5261195\\,\\mathrm{eV}^2} $$\n$$ \\Phi \\approx -0.1045614\\,\\mathrm{eV} + 1.8777964\\,\\mathrm{eV} $$\n$$ \\Phi \\approx 1.773235\\,\\mathrm{eV} $$\nRounding the final answer to four significant figures as requested:\n$$ \\Phi \\approx 1.773\\,\\mathrm{eV} $$",
            "answer": "$$ \\boxed{1.773} $$"
        },
        {
            "introduction": "Building a predictive model is not just about crafting good features; it's also about validating it correctly to ensure it can generalize to new, unseen materials. In materials science, datasets often have a hidden group structure where samples from the same alloy system are highly correlated, violating the independent and identically distributed (IID) assumption of standard cross-validation. This exercise guides you through the implementation of a group-aware validation split, a critical technique for obtaining a statistically sound and realistic assessment of your model's performance on truly novel compositions. ",
            "id": "3741478",
            "problem": "You are given a fixed dataset of synthetic High-Entropy Alloy (HEA) compositions designed to reflect common feature engineering practices where each sample is represented as a vector of elemental fractions that sum to $1$. Let the element set be $\\{\\mathrm{Fe}, \\mathrm{Ni}, \\mathrm{Co}, \\mathrm{Cr}, \\mathrm{Mn}, \\mathrm{Al}, \\mathrm{Cu}, \\mathrm{Ti}\\}$. Each sample $i$ has an identifier $u_i$ and a composition vector $x_i \\in \\mathbb{R}^d$ with $d = 8$, where the fraction $x_{i,e}$ is the proportion of element $e$ in the alloy and $\\sum_{e} x_{i,e} = 1$. You must implement a validation split that groups samples by alloy system or base element to prevent information leakage and justify its statistical soundness for generalization assessment.\n\nFundamental definitions and assumptions:\n- Empirical Risk Minimization (ERM) seeks to minimize the empirical loss $\\hat{L}_{\\text{train}} = \\frac{1}{n_{\\text{train}}} \\sum_{i \\in \\mathcal{I}_{\\text{train}}} \\ell(f(x_i), y_i)$, where $\\ell$ is a loss function, $f$ is a learned predictor, and $y_i$ is the target property. Generalization assessment estimates $\\hat{L}_{\\text{val}} = \\frac{1}{n_{\\text{val}}} \\sum_{i \\in \\mathcal{I}_{\\text{val}}} \\ell(f(x_i), y_i)$.\n- In compositional materials data, samples sharing a common alloy system or base element often violate independent and identically distributed (IID) assumptions due to shared latent structure; thus, group-aware validation prevents information leakage by ensuring that the validation set contains groups not present in the training set.\n\nGroup definitions:\n- Alloy system grouping for sample $i$: define $S_i = \\{ e \\mid x_{i,e}  0 \\}$ as the unordered set of elements present with strictly positive fraction. All samples with identical $S_i$ belong to the same group.\n- Base element grouping for sample $i$: define $b_i = \\operatorname{argmax}_e x_{i,e}$ as the element with the largest fraction; in case of ties, break ties by ascending lexicographic order of element names.\n\nValidation split requirement:\n- Implement a $K$-fold group-aware split. Let $\\mathcal{G}$ be the set of unique groups under the chosen grouping rule. Partition $\\mathcal{G}$ into $K$ folds without splitting any group across folds. For a specified validation fold index $k \\in \\{0, 1, \\dots, K-1\\}$ (zero-based indexing), let $\\mathcal{I}_{\\text{val}}$ be the union of indices belonging to groups in fold $k$, and $\\mathcal{I}_{\\text{train}}$ be the union of indices from all other folds.\n\nStatistical soundness check:\n- Compute the leakage indicator $\\lambda = \\mathbf{1}\\left[ \\left(\\mathcal{G}_{\\text{train}} \\cap \\mathcal{G}_{\\text{val}} \\right) \\neq \\emptyset \\right]$, where $\\mathcal{G}_{\\text{train}}$ and $\\mathcal{G}_{\\text{val}}$ are the sets of groups in the training and validation partitions, respectively.\n- Compute the group intersection count $\\eta = \\left| \\mathcal{G}_{\\text{train}} \\cap \\mathcal{G}_{\\text{val}} \\right|$.\n- Compute the validation group count $\\gamma = \\left| \\mathcal{G}_{\\text{val}} \\right|$ and the validation sample count $\\nu = \\left| \\mathcal{I}_{\\text{val}} \\right|$.\n- Compute the Group Independence Coefficient (GIC) defined as the Jaccard index $J = \\frac{\\left| \\mathcal{G}_{\\text{train}} \\cap \\mathcal{G}_{\\text{val}} \\right|}{\\left| \\mathcal{G}_{\\text{train}} \\cup \\mathcal{G}_{\\text{val}} \\right|}$.\n\nYou must use a deterministic, explicit algorithm to assign groups to folds that aims to balance the number of samples per fold by greedily assigning larger groups first to the currently smallest fold.\n\nDataset specification:\nThere are $14$ samples with identifiers $u_1$ through $u_{14}$ and the following compositions (all unspecified element fractions are $0$):\n- $u_1$: $\\mathrm{Fe}=0.25$, $\\mathrm{Ni}=0.25$, $\\mathrm{Co}=0.25$, $\\mathrm{Cr}=0.25$.\n- $u_2$: $\\mathrm{Fe}=0.30$, $\\mathrm{Ni}=0.20$, $\\mathrm{Co}=0.25$, $\\mathrm{Cr}=0.25$.\n- $u_3$: $\\mathrm{Fe}=0.22$, $\\mathrm{Ni}=0.28$, $\\mathrm{Co}=0.25$, $\\mathrm{Cr}=0.25$.\n- $u_4$: $\\mathrm{Fe}=0.27$, $\\mathrm{Ni}=0.23$, $\\mathrm{Co}=0.25$, $\\mathrm{Cr}=0.25$.\n- $u_5$: $\\mathrm{Fe}=0.25$, $\\mathrm{Ni}=0.25$, $\\mathrm{Mn}=0.25$, $\\mathrm{Cr}=0.25$.\n- $u_6$: $\\mathrm{Fe}=0.40$, $\\mathrm{Ni}=0.20$, $\\mathrm{Mn}=0.20$, $\\mathrm{Cr}=0.20$.\n- $u_7$: $\\mathrm{Fe}=0.20$, $\\mathrm{Ni}=0.30$, $\\mathrm{Mn}=0.25$, $\\mathrm{Cr}=0.25$.\n- $u_8$: $\\mathrm{Al}=0.30$, $\\mathrm{Co}=0.20$, $\\mathrm{Cr}=0.25$, $\\mathrm{Ni}=0.25$.\n- $u_9$: $\\mathrm{Al}=0.25$, $\\mathrm{Co}=0.25$, $\\mathrm{Cr}=0.25$, $\\mathrm{Ni}=0.25$.\n- $u_{10}$: $\\mathrm{Cu}=0.25$, $\\mathrm{Ni}=0.25$, $\\mathrm{Co}=0.25$, $\\mathrm{Fe}=0.25$.\n- $u_{11}$: $\\mathrm{Cu}=0.35$, $\\mathrm{Ni}=0.15$, $\\mathrm{Co}=0.25$, $\\mathrm{Fe}=0.25$.\n- $u_{12}$: $\\mathrm{Cu}=0.20$, $\\mathrm{Ni}=0.30$, $\\mathrm{Co}=0.25$, $\\mathrm{Fe}=0.25$.\n- $u_{13}$: $\\mathrm{Ti}=0.25$, $\\mathrm{Al}=0.25$, $\\mathrm{Ni}=0.25$, $\\mathrm{Co}=0.25$.\n- $u_{14}$: $\\mathrm{Ti}=0.30$, $\\mathrm{Al}=0.20$, $\\mathrm{Ni}=0.25$, $\\mathrm{Co}=0.25$.\n\nTest suite:\nImplement your program to execute the following three test cases, each returning the tuple $(\\lambda, \\eta, \\gamma, \\nu, J)$ for the specified parameters:\n- Case $1$: grouping by alloy system $S_i$, $K=4$, validation fold index $k=2$.\n- Case $2$: grouping by base element $b_i$, $K=3$, validation fold index $k=1$.\n- Case $3$ (edge case): grouping by alloy system $S_i$, $K=9$, validation fold index $k=8$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where the list is the concatenation of the $5$ values for Case $1$, then Case $2$, then Case $3$. For example, the output must look like $\\left[ \\text{Case 1 value 1}, \\dots, \\text{Case 1 value 5}, \\text{Case 2 value 1}, \\dots, \\text{Case 3 value 5} \\right]$. There are no physical units or angles in this problem; all outputs are dimensionless. All booleans must be printed as either $\\text{True}$ or $\\text{False}$, and all integers and floats must be printed in their standard textual representation on a single line.",
            "solution": "We begin from the principle that generalization assessment requires an unbiased estimate of the loss on unseen data under the independence assumptions inherent in Empirical Risk Minimization (ERM). The empirical loss on validation is $\\hat{L}_{\\text{val}} = \\frac{1}{n_{\\text{val}}} \\sum_{i \\in \\mathcal{I}_{\\text{val}}} \\ell(f(x_i), y_i)$, which is unbiased for the population risk under Independent and Identically Distributed (IID) assumptions if the validation data are exchangeable with unseen data. In compositional materials, samples that share a common alloy system or base element exhibit hierarchical dependence: they often share latent features due to common elemental sets or dominant chemistry, which violates the IID assumption if such samples appear in both training and validation splits.\n\nTo prevent information leakage, we must ensure that the grouping unit, defined at a level that captures shared latent structure, is held out wholly from training when assigned to validation. Two grouping rules are considered: alloy system grouping $S_i = \\{ e \\mid x_{i,e}  0 \\}$ and base element grouping $b_i = \\operatorname{argmax}_e x_{i,e}$ with lexicographic tie-breaking. For a chosen grouping rule, we derive the set of unique groups $\\mathcal{G}$ and their associated sample indices. A group-aware $K$-fold split assigns each group $g \\in \\mathcal{G}$ to exactly one fold, such that no group is split across training and validation. The validation indices for fold $k$ are $\\mathcal{I}_{\\text{val}} = \\bigcup_{g \\in \\mathcal{G}_k} \\mathcal{I}_g$, while the training indices are $\\mathcal{I}_{\\text{train}} = \\bigcup_{j \\neq k} \\bigcup_{g \\in \\mathcal{G}_j} \\mathcal{I}_g$. This construction ensures $\\mathcal{G}_{\\text{train}} \\cap \\mathcal{G}_{\\text{val}} = \\emptyset$ by design, eliminating direct group overlap and thus reducing leakage.\n\nTo make the fold assignment deterministic and approximately balanced in sample counts per fold, we implement a greedy algorithm grounded in load balancing: sort groups by descending size $\\left| \\mathcal{I}_g \\right|$, then iteratively assign each group to the fold with the current minimum total sample count. This heuristic minimizes imbalance by mimicking a greedy partition of weighted items into bins, a well-established approach in combinatorial optimization. While not guaranteed to be perfectly balanced, it deterministically approximates the minimization of maximum fold load and is adequate for validation splitting.\n\nFor statistical soundness metrics, we compute:\n- The leakage indicator $\\lambda = \\mathbf{1}\\left[ \\left(\\mathcal{G}_{\\text{train}} \\cap \\mathcal{G}_{\\text{val}} \\right) \\neq \\emptyset \\right]$, which must be $0$ (printed as $\\text{False}$) under proper group-aware splitting.\n- The intersection count $\\eta = \\left| \\mathcal{G}_{\\text{train}} \\cap \\mathcal{G}_{\\text{val}} \\right|$, which should be $0$.\n- The validation group count $\\gamma = \\left| \\mathcal{G}_{\\text{val}} \\right|$ and validation sample count $\\nu = \\left| \\mathcal{I}_{\\text{val}} \\right|$, which reflect fold allocation properties and edge cases (e.g., empty folds when $K  \\left| \\mathcal{G} \\right|$).\n- The Group Independence Coefficient (GIC) via the Jaccard index $J = \\frac{\\left| \\mathcal{G}_{\\text{train}} \\cap \\mathcal{G}_{\\text{val}} \\right|}{\\left| \\mathcal{G}_{\\text{train}} \\cup \\mathcal{G}_{\\text{val}} \\right|}$, which equals $0$ when there is no overlap, indicating perfect separation of groups.\n\nEdge case analysis: when $K  \\left| \\mathcal{G} \\right|$, some folds will be empty. In this case, for an empty validation fold $k$, we have $\\gamma = 0$ and $\\nu = 0$; the leakage indicator $\\lambda$ remains $0$ and the Jaccard index $J$ remains $0$ as the intersection is empty. This is statistically sound as a degenerate validation case that does not introduce leakage but may not be informative for performance estimation due to $n_{\\text{val}} = 0$.\n\nAlgorithmic steps implemented:\n- Compute the group label for each sample under the chosen grouping rule.\n- Map each group to its sample indices, yielding a dictionary $g \\mapsto \\mathcal{I}_g$.\n- Sort groups by descending $\\left| \\mathcal{I}_g \\right|$ and assign each group to one of $K$ folds using the greedy load balancing rule.\n- Derive $\\mathcal{I}_{\\text{val}}$ and $\\mathcal{I}_{\\text{train}}$, then compute $\\lambda$, $\\eta$, $\\gamma$, $\\nu$, and $J$.\n\nThis procedure ensures no group appears in both training and validation, thereby removing a principal source of information leakage and providing a more conservative but statistically meaningful estimate of generalization to unseen alloy systems or base-element regimes. Under the assumption that future samples are drawn from groups not represented in training (a common deployment scenario in materials discovery), this validation design aligns with the target distribution for generalization, improving the external validity of $\\hat{L}_{\\text{val}}$ compared to random splits that mix groups.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_dataset():\n    # Elements index order for consistency\n    elements = [\"Fe\", \"Ni\", \"Co\", \"Cr\", \"Mn\", \"Al\", \"Cu\", \"Ti\"]\n    # Define compositions for 14 samples u1..u14.\n    # Represent each sample as a dict of element-fraction. Missing elements are 0.\n    samples = [\n        {\"id\": \"u1\",  \"comp\": {\"Fe\":0.25,\"Ni\":0.25,\"Co\":0.25,\"Cr\":0.25}},\n        {\"id\": \"u2\",  \"comp\": {\"Fe\":0.30,\"Ni\":0.20,\"Co\":0.25,\"Cr\":0.25}},\n        {\"id\": \"u3\",  \"comp\": {\"Fe\":0.22,\"Ni\":0.28,\"Co\":0.25,\"Cr\":0.25}},\n        {\"id\": \"u4\",  \"comp\": {\"Fe\":0.27,\"Ni\":0.23,\"Co\":0.25,\"Cr\":0.25}},\n        {\"id\": \"u5\",  \"comp\": {\"Fe\":0.25,\"Ni\":0.25,\"Mn\":0.25,\"Cr\":0.25}},\n        {\"id\": \"u6\",  \"comp\": {\"Fe\":0.40,\"Ni\":0.20,\"Mn\":0.20,\"Cr\":0.20}},\n        {\"id\": \"u7\",  \"comp\": {\"Fe\":0.20,\"Ni\":0.30,\"Mn\":0.25,\"Cr\":0.25}},\n        {\"id\": \"u8\",  \"comp\": {\"Al\":0.30,\"Co\":0.20,\"Cr\":0.25,\"Ni\":0.25}},\n        {\"id\": \"u9\",  \"comp\": {\"Al\":0.25,\"Co\":0.25,\"Cr\":0.25,\"Ni\":0.25}},\n        {\"id\": \"u10\", \"comp\": {\"Cu\":0.25,\"Ni\":0.25,\"Co\":0.25,\"Fe\":0.25}},\n        {\"id\": \"u11\", \"comp\": {\"Cu\":0.35,\"Ni\":0.15,\"Co\":0.25,\"Fe\":0.25}},\n        {\"id\": \"u12\", \"comp\": {\"Cu\":0.20,\"Ni\":0.30,\"Co\":0.25,\"Fe\":0.25}},\n        {\"id\": \"u13\", \"comp\": {\"Ti\":0.25,\"Al\":0.25,\"Ni\":0.25,\"Co\":0.25}},\n        {\"id\": \"u14\", \"comp\": {\"Ti\":0.30,\"Al\":0.20,\"Ni\":0.25,\"Co\":0.25}},\n    ]\n    # Normalize compositions to ensure sum to 1 for any potential floating differences\n    for s in samples:\n        total = sum(s[\"comp\"].values())\n        if not np.isclose(total, 1.0):\n            # Normalize to sum 1\n            for k in list(s[\"comp\"].keys()):\n                s[\"comp\"][k] = s[\"comp\"][k] / total\n    return elements, samples\n\ndef group_label(comp, mode, elements_order):\n    \"\"\"\n    mode: 'system' or 'base'\n    For 'system': return frozenset of elements with positive fraction\n    For 'base': return the element name with max fraction; tie-break lexicographically\n    \"\"\"\n    if mode == \"system\":\n        present = [e for e, v in comp.items() if v  0.0]\n        return frozenset(sorted(present))  # sorted for consistent representation\n    elif mode == \"base\":\n        # Build full vector including missing elements as 0; ensure consistent tie-breaking\n        # Choose argmax by value, break ties by lexicographic element name.\n        # elements_order is the canonical list used for tie-breaking.\n        max_val = -1.0\n        max_elems = []\n        for e in elements_order:\n            v = comp.get(e, 0.0)\n            if v  max_val:\n                max_val = v\n                max_elems = [e]\n            elif np.isclose(v, max_val):\n                max_elems.append(e)\n        # Lexicographic tie-break\n        base = sorted(max_elems)[0]\n        return base\n    else:\n        raise ValueError(\"Unknown mode\")\n\ndef build_groups(samples, mode, elements_order):\n    # Map group label to list of sample indices\n    group_to_indices = {}\n    for idx, s in enumerate(samples):\n        g = group_label(s[\"comp\"], mode, elements_order)\n        group_to_indices.setdefault(g, []).append(idx)\n    return group_to_indices\n\ndef greedy_group_kfold(group_to_indices, K):\n    \"\"\"\n    Deterministic greedy bin packing to balance sample counts across K folds.\n    Returns: list of lists of group labels per fold: folds_groups[k] - [group_label, ...]\n    \"\"\"\n    # Initialize folds\n    folds_groups = [[] for _ in range(K)]\n    folds_sizes = [0 for _ in range(K)]\n    # Sort groups by descending size, then by stringified label for determinism\n    # Represent label for sorting\n    def label_key(g):\n        if isinstance(g, frozenset):\n            return \"{\" + \",\".join(sorted(list(g))) + \"}\"\n        else:\n            return str(g)\n    groups_sorted = sorted(group_to_indices.items(),\n                           key=lambda kv: (-len(kv[1]), label_key(kv[0])))\n    for g, idxs in groups_sorted:\n        # Choose fold with smallest current size; in ties, lowest index\n        min_size = min(folds_sizes)\n        candidate_folds = [i for i, sz in enumerate(folds_sizes) if sz == min_size]\n        k = candidate_folds[0]\n        folds_groups[k].append(g)\n        folds_sizes[k] += len(idxs)\n    return folds_groups\n\ndef compute_metrics(folds_groups, group_to_indices, val_fold_idx):\n    # Build group sets for train and val\n    K = len(folds_groups)\n    val_groups = set(folds_groups[val_fold_idx]) if (0 = val_fold_idx  K) else set()\n    train_groups = set()\n    for k in range(K):\n        if k == val_fold_idx:\n            continue\n        for g in folds_groups[k]:\n            train_groups.add(g)\n    # Leakage metrics\n    intersection = train_groups.intersection(val_groups)\n    leakage_present = len(intersection)  0\n    intersection_count = len(intersection)\n    val_group_count = len(val_groups)\n    # Build index sets\n    val_indices = []\n    for g in val_groups:\n        val_indices.extend(group_to_indices[g])\n    train_indices = []\n    for g in train_groups:\n        train_indices.extend(group_to_indices[g])\n    val_sample_count = len(val_indices)\n    # Jaccard (Group Independence Coefficient)\n    union = train_groups.union(val_groups)\n    union_count = len(union)\n    if union_count == 0:\n        jaccard = 0.0\n    else:\n        jaccard = intersection_count / union_count\n    return leakage_present, intersection_count, val_group_count, val_sample_count, float(np.round(jaccard, 6))\n\ndef solve():\n    elements, samples = build_dataset()\n    # Define the test cases from the problem statement.\n    # Each case: (grouping_mode, K, val_fold_idx)\n    test_cases = [\n        (\"system\", 4, 2),  # Case 1\n        (\"base\",   3, 1),  # Case 2\n        (\"system\", 9, 8),  # Case 3 (edge case)\n    ]\n\n    results = []\n    for mode, K, val_fold_idx in test_cases:\n        group_to_indices = build_groups(samples, mode, elements)\n        folds_groups = greedy_group_kfold(group_to_indices, K)\n        metrics = compute_metrics(folds_groups, group_to_indices, val_fold_idx)\n        # Append metrics in order: lambda, eta, gamma, nu, J\n        leakage_present, intersection_count, val_group_count, val_sample_count, jaccard = metrics\n        results.extend([leakage_present, intersection_count, val_group_count, val_sample_count, jaccard])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}