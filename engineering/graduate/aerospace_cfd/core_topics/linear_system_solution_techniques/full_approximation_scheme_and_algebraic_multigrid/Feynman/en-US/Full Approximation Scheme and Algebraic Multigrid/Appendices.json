{
    "hands_on_practices": [
        {
            "introduction": "The effectiveness of any multigrid solver hinges on its smoother, the component responsible for damping high-frequency error. To build robust solvers, we must be able to quantify this performance. This first practice introduces Local Fourier Analysis (LFA), a powerful theoretical tool for analyzing how relaxation schemes like Red-Black Gauss-Seidel (RBGS) behave, providing a foundational skill for understanding and predicting the behavior of multigrid methods on idealized problems like the Poisson equation. ",
            "id": "3961529",
            "problem": "Consider the pressure Poisson subproblem that arises in projection methods for incompressible flow within aerospace computational fluid dynamics (CFD). On a uniform two-dimensional Cartesian mesh with grid spacing $h$, discretize the negative Laplacian using the standard five-point stencil to obtain a linear system $A_h u = b$ with $$\\left(A_h u\\right)_{i,j} = \\frac{1}{h^2}\\left(4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}\\right).$$ In an Algebraic Multigrid (AMG) framework embedded within the Full Approximation Scheme (FAS) for nonlinear problems, Red–Black Gauss–Seidel (RBGS) is used as a pre-relaxation smoother. Assume periodic boundary conditions and analyze the RBGS error-propagation by Local Fourier Analysis (LFA), where error modes are taken as complex exponentials $e_{i,j} = \\exp\\!\\left(\\mathrm{i}\\left(\\theta_x i + \\theta_y j\\right)\\right)$ with $\\theta_x,\\theta_y \\in [-\\pi,\\pi]$ (angles in radians).\n\nDefine one RBGS sweep as an update of all red points followed by an update of all black points, with each point update using the $4$-point neighbor average implied by the discrete operator. Let the smoothing factor $\\mu$ be the supremum (over the set of high-frequency Fourier modes) of the magnitude of the error-amplification factor associated with one full RBGS sweep. Take the coarse grid to have spacing $2h$, and define the high-frequency set as the complement of the low-frequency set $[-\\pi/2,\\pi/2]^2$ in $[-\\pi,\\pi]^2$.\n\nStarting from the discrete operator and the definition of RBGS, use Local Fourier Analysis to derive the symbol of the RBGS error-propagation operator and compute the exact value of the smoothing factor $\\mu$ as the supremum of the magnitude of the error-amplification factor over the high-frequency set. Interpret the result in terms of attenuation of high-frequency error modes in the AMG-FAS context. The final answer must be the value of $\\mu$ (dimensionless). No rounding is required.",
            "solution": "The user wants to find the smoothing factor of Red-Black Gauss-Seidel for the 2D Poisson equation using Local Fourier Analysis.\n\n### Step 1: Problem Validation\n\nThe problem is subjected to a rigorous validation process.\n\n**1.1. Extract Givens:**\n- **Equation**: Pressure Poisson subproblem.\n- **Operator**: Discrete negative Laplacian on a uniform 2D grid with spacing $h$, given by the five-point stencil:\n$$ (A_h u)_{i,j} = \\frac{1}{h^2}(4 u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1}) $$\n- **Smoother**: Red-Black Gauss-Seidel (RBGS), defined as an update of all red points (where $i+j$ is even) followed by an update of all black points (where $i+j$ is odd).\n- **Analysis Method**: Local Fourier Analysis (LFA).\n- **Boundary Conditions**: Periodic.\n- **Error Modes**: $e_{i,j} = \\exp(\\mathrm{i}(\\theta_x i + \\theta_y j))$ with $\\theta_x, \\theta_y \\in [-\\pi, \\pi]$.\n- **Coarsening**: Standard coarsening from grid spacing $h$ to $2h$.\n- **Frequency Sets**:\n    - Low-frequency set $\\Omega_L = [-\\frac{\\pi}{2}, \\frac{\\pi}{2}]^2$.\n    - High-frequency set $\\Omega_H = [-\\pi, \\pi]^2 \\setminus [-\\frac{\\pi}{2}, \\frac{\\pi}{2}]^2$.\n- **Target Quantity**: The smoothing factor $\\mu = \\sup_{\\theta \\in \\Omega_H} |g(\\theta)|$, where $g(\\theta)$ is the error-amplification factor for one full RBGS sweep.\n\n**1.2. Validate Using Extracted Givens:**\n- **Scientifically Grounded**: The problem is a cornerstone of classical multigrid theory. The 5-point Laplacian, Red-Black Gauss-Seidel, and Local Fourier Analysis are all standard, well-established concepts in numerical analysis for partial differential equations. The application context (aerospace CFD) is appropriate. The problem is scientifically and mathematically sound.\n- **Well-Posed**: The problem is precisely defined. It requests the derivation of a specific quantity ($\\mu$) using a standard analytical technique (LFA) under clear definitions and constraints. A unique, meaningful solution exists.\n- **Objective**: The problem is stated in precise, formal, and unbiased language.\n\n**1.3. Verdict and Action:**\nThe problem is deemed **valid**. The solution process will now proceed.\n\n### Step 2: Derivation of the RBGS Amplification Factor\n\nWe analyze the propagation of a Fourier error mode through one full RBGS sweep. For the homogeneous error equation $A_h e = 0$, the update at a grid point $(i,j)$ is an averaging of its neighbors:\n$$ e_{i,j}^{\\text{new}} = \\frac{1}{4} (e_{i-1,j} + e_{i+1,j} + e_{i,j-1} + e_{i,j+1}) $$\nThe values on the right-hand side depend on whether they have already been updated in the current sweep.\n\nA single Fourier mode $e_{i,j} = \\exp(\\mathrm{i}(\\theta_x i + \\theta_y j))$ is not an eigenfunction of the RBGS operator. The red-black ordering couples the mode $\\theta = (\\theta_x, \\theta_y)$ with the mode $\\theta' = (\\theta_x+\\pi, \\theta_y+\\pi)$. Therefore, the error is represented as a linear combination of these two modes:\n$$ e_{i,j} = v_1 \\exp(\\mathrm{i} \\theta \\cdot \\mathbf{x}_{i,j}) + v_2 \\exp(\\mathrm{i} \\theta' \\cdot \\mathbf{x}_{i,j}) $$\nwhere $\\mathbf{x}_{i,j}=(i,j)$. The LFA analysis consists of finding the $2 \\times 2$ amplification matrix $G(\\theta)$ that maps the vector of amplitudes $v = [v_1, v_2]^T$ to $v' = G(\\theta) v$ after one full sweep. The error-amplification factor for the mode $\\theta$ is the spectral radius of $G(\\theta)$.\n\nA full RBGS sweep consists of a red pass ($S_R$) followed by a black pass ($S_B$).\nLet $J_h$ be the point-Jacobi iteration operator, which updates a point using the average of its four neighbors, all taken from the previous iteration level. The symbol of $J_h$ is:\n$$ \\tilde{J_h}(\\theta) = \\frac{1}{4} (\\exp(\\mathrm{i}\\theta_x) + \\exp(-\\mathrm{i}\\theta_x) + \\exp(\\mathrm{i}\\theta_y) + \\exp(-\\mathrm{i}\\theta_y)) = \\frac{1}{2}(\\cos\\theta_x + \\cos\\theta_y) $$\nLet $\\rho(\\theta) = \\tilde{J_h}(\\theta)$. Note that $\\rho(\\theta') = \\rho(\\theta_x+\\pi, \\theta_y+\\pi) = \\frac{1}{2}(-\\cos\\theta_x - \\cos\\theta_y) = -\\rho(\\theta)$.\nThe symbol of the Jacobi operator acting on the two-mode vector space is a diagonal matrix:\n$$ \\tilde{J}(\\theta) = \\begin{pmatrix} \\rho(\\theta) & 0 \\\\ 0 & \\rho(\\theta') \\end{pmatrix} = \\begin{pmatrix} \\rho(\\theta) & 0 \\\\ 0 & -\\rho(\\theta) \\end{pmatrix} $$\nThe red and black passes can be described using projection operators $P_R$ and $P_B$. Their symbols are $\\tilde{P}_R = \\frac{1}{2}\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix}$ and $\\tilde{P}_B = \\frac{1}{2}\\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix}$.\n\nThe red pass updates red points using old values (which live on black points) and leaves black points unchanged: $e^{k+1/2} = P_R (J_h e^k) + P_B e^k$. The symbol is $\\tilde{S}_R = \\tilde{P}_R \\tilde{J} + \\tilde{P}_B$.\n$$ \\tilde{S}_R = \\frac{1}{2}\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} \\rho & 0 \\\\ 0 & -\\rho \\end{pmatrix} + \\frac{1}{2}\\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix} 1+\\rho & -1-\\rho \\\\ -1+\\rho & 1-\\rho \\end{pmatrix} $$\nThe black pass updates black points using the newly computed red values: $e^{k+1} = P_B (J_h e^{k+1/2}) + P_R e^{k+1/2}$. The symbol is $\\tilde{S}_B = \\tilde{P}_B \\tilde{J} + \\tilde{P}_R$.\n$$ \\tilde{S}_B = \\frac{1}{2}\\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix} \\begin{pmatrix} \\rho & 0 \\\\ 0 & -\\rho \\end{pmatrix} + \\frac{1}{2}\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix} 1+\\rho & 1+\\rho \\\\ 1-\\rho & 1-\\rho \\end{pmatrix} $$\nThe amplification matrix for the full sweep is $G(\\theta) = \\tilde{S}_B \\tilde{S}_R$:\n$$ G(\\theta) = \\frac{1}{4} \\begin{pmatrix} 1+\\rho & 1+\\rho \\\\ 1-\\rho & 1-\\rho \\end{pmatrix} \\begin{pmatrix} 1+\\rho & -(1+\\rho) \\\\ \\rho-1 & 1-\\rho \\end{pmatrix} $$\n$$ G(\\theta) = \\frac{1}{4} \\begin{pmatrix} (1+\\rho)^2+(1+\\rho)(\\rho-1) & -(1+\\rho)^2+(1+\\rho)(1-\\rho) \\\\ (1-\\rho)(1+\\rho)+(1-\\rho)(\\rho-1) & -(1-\\rho)(1+\\rho)+(1-\\rho)^2 \\end{pmatrix} $$\n$$ G(\\theta) = \\frac{1}{4} \\begin{pmatrix} (1+\\rho)(1+\\rho+\\rho-1) & (1+\\rho)(-1-\\rho+1-\\rho) \\\\ (1-\\rho)(1+\\rho+\\rho-1) & (1-\\rho)(-1-\\rho+1-\\rho) \\end{pmatrix} $$\n$$ G(\\theta) = \\frac{1}{4} \\begin{pmatrix} (1+\\rho)(2\\rho) & (1+\\rho)(-2\\rho) \\\\ (1-\\rho)(2\\rho) & (1-\\rho)(-2\\rho) \\end{pmatrix} = \\begin{pmatrix} \\frac{\\rho(1+\\rho)}{2} & -\\frac{\\rho(1+\\rho)}{2} \\\\ \\frac{\\rho(1-\\rho)}{2} & -\\frac{\\rho(1-\\rho)}{2} \\end{pmatrix} $$\nThe eigenvalues $\\lambda$ of $G(\\theta)$ are found from the characteristic equation $\\lambda^2 - \\text{Tr}(G)\\lambda + \\det(G) = 0$.\nThe trace is $\\text{Tr}(G) = \\frac{\\rho(1+\\rho)}{2} - \\frac{\\rho(1-\\rho)}{2} = \\frac{\\rho}{2}(1+\\rho-1+\\rho) = \\rho^2$.\nThe determinant is $\\det(G) = -\\frac{\\rho^2(1+\\rho)(1-\\rho)}{4} + \\frac{\\rho^2(1+\\rho)(1-\\rho)}{4} = 0$.\nThe characteristic equation is $\\lambda^2 - \\rho^2 \\lambda = 0$, which gives eigenvalues $\\lambda_1 = 0$ and $\\lambda_2 = \\rho^2$.\n\nThe error-amplification factor $g(\\theta)$ is the spectral radius of $G(\\theta)$:\n$$ g(\\theta) = \\max(|\\lambda_1|, |\\lambda_2|) = |\\rho(\\theta)|^2 = \\left[ \\frac{1}{2}(\\cos\\theta_x + \\cos\\theta_y) \\right]^2 $$\n\n### Step 3: Computation of the Smoothing Factor $\\mu$\n\nThe smoothing factor $\\mu$ is the supremum of the amplification factor over the set of high-frequency modes $\\Omega_H = [-\\pi, \\pi]^2 \\setminus [-\\frac{\\pi}{2}, \\frac{\\pi}{2}]^2$.\n$$ \\mu = \\sup_{(\\theta_x, \\theta_y) \\in \\Omega_H} \\left[ \\frac{1}{2}(\\cos\\theta_x + \\cos\\theta_y) \\right]^2 $$\nLet $X = \\cos\\theta_x$ and $Y = \\cos\\theta_y$. The domain for $(\\theta_x, \\theta_y)$ is $[-\\pi, \\pi]^2$, which maps to $(X,Y) \\in [-1, 1]^2$. The low-frequency domain $\\Omega_L$ corresponds to $\\theta_x, \\theta_y \\in [-\\pi/2, \\pi/2]$, which maps to a domain where $X, Y \\in [0, 1]$. The high-frequency domain $\\Omega_H$ corresponds to the domain for $(X,Y)$ being $[-1, 1]^2 \\setminus [0, 1]^2$. This means that at least one of $X$ or $Y$ must be in the range $[-1, 0)$.\n\nWe need to find the supremum of the function $f(X,Y) = \\frac{1}{4}(X+Y)^2$ on the domain $D' = ([-1,1]\\times[-1,1]) \\setminus [0,1]^2$.\nThe function $(X+Y)^2$ is non-negative and its value is determined by the magnitude of the sum $X+Y$. We need to find the maximum possible value of $|X+Y|$ on $D'$.\nThe domain $D'$ can be written as the union of three disjoint sets:\n1. $X \\in [-1, 0)$ and $Y \\in [-1, 0)$\n2. $X \\in [-1, 0)$ and $Y \\in [0, 1]$\n3. $X \\in [0, 1]$ and $Y \\in [-1, 0)$\n\nIn case 1, where both $X$ and $Y$ are negative, the sum $X+Y$ is in the range $(-2, 0)$. The maximum value of $|X+Y|$ is approached as $X\\to -1$ and $Y\\to -1$, where $|X+Y| \\to 2$.\nIn cases 2 and 3, one variable is non-positive and the other is non-negative. The sum $X+Y$ is in the range $[-1, 1]$. The maximum value of $|X+Y|$ is $1$.\n\nComparing the cases, the supremum of $|X+Y|$ over the entire domain $D'$ is $2$. This supremum is attained at the point $(X,Y) = (-1, -1)$. This point corresponds to Fourier modes where $\\cos\\theta_x = -1$ and $\\cos\\theta_y = -1$, for instance, $(\\theta_x, \\theta_y) = (\\pi, \\pi)$. This mode is in the high-frequency set $\\Omega_H$ since $|\\pi| = \\pi > \\pi/2$.\n\nAt this point, the amplification factor is:\n$$ g(\\pi, \\pi) = \\left[ \\frac{1}{2}(\\cos\\pi + \\cos\\pi) \\right]^2 = \\left[ \\frac{1}{2}(-1 - 1) \\right]^2 = (-1)^2 = 1 $$\nThus, the supremum of the amplification factor over the high-frequency domain is $1$.\n\n$$ \\mu = 1 $$\n\n### Step 4: Interpretation\n\nThe calculated smoothing factor is $\\mu=1$. A value of $1$ indicates that there is at least one high-frequency error mode that is not damped at all by the smoother. In this case, it is the highest frequency mode, $(\\theta_x, \\theta_y) = (\\pi, \\pi)$, which corresponds to the checkerboard pattern $e_{i,j} = C(-1)^{i+j}$.\n\nAt first glance, this result seems to suggest that RBGS is a poor smoother. However, its effectiveness is understood in the context of the entire multigrid cycle. The problematic high-frequency mode $(\\pi, \\pi)$ is a special case because it is an alias of the zero-frequency mode $(0,0)$ on the coarse grid (with spacing $2h$). That is, sampling the fine-grid checkerboard mode only on coarse-grid points yields a constant value.\nThe coarse-grid correction step of the multigrid algorithm is specifically designed to eliminate low-frequency errors, which includes the constant mode $(0,0)$. Therefore, the error component that the RBGS smoother fails to damp is effectively handled by the coarse-grid correction.\n\nFor all other high-frequency modes (those not aliasing to the zero-frequency mode), the RBGS amplification factor is strictly less than $1$. For instance, for modes on the boundary of the high-frequency domain, like $(\\pi/2, 0)$, the factor is $g(\\pi/2, 0) = [\\frac{1}{2}(0+1)]^2 = 1/4$. For a mode like $(\\pi, 2\\pi/3)$, the factor is $g(\\pi, 2\\pi/3) = [\\frac{1}{2}(-1 - 1/2)]^2 = 9/16$. The ability of RBGS to effectively damp this broad range of high-frequency modes, combined with its computational efficiency and parallelizability, makes it an excellent and widely-used smoother in practice, despite its theoretical smoothing factor being unity. The single undamped mode is not a bottleneck for the overall multigrid convergence.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "A good smoother is necessary but not sufficient for multigrid convergence, especially in the presence of strong anisotropy common in aerospace applications like boundary layers. The multigrid hierarchy itself—the coarse grids, restriction, and prolongation operators—must correctly represent the underlying physics. This exercise provides a stark, hands-on counterexample demonstrating how a \"naive\" coarsening strategy that ignores anisotropy leads to a complete failure of the solver, underscoring why the \"algebraic\" nature of AMG is so critical for practical problems. ",
            "id": "3961548",
            "problem": "Consider a linear subproblem arising in an implicit compressible flow solver where an anisotropic diffusion operator models wall-normal thermal conduction in a high-Reynolds-number boundary layer. On the unit square with homogeneous Dirichlet boundary conditions, discretize the anisotropic operator $-\\partial_{x}(\\alpha\\,\\partial_{x} u)-\\partial_{y}(\\beta\\,\\partial_{y} u)$ on a uniform fine grid with $N_{x}=N_{y}=2$ interior points, so $h_{x}=h_{y}=1/3$. Let $\\alpha=1$ and $\\beta=\\varepsilon$ with $\\varepsilon=10^{-6}$. Use the standard five-point finite-difference stencil to assemble the $4\\times 4$ fine-grid matrix $A$ ordering unknowns as $(i,j)=(1,1),(2,1),(1,2),(2,2)$.\n\nApply Algebraic Multigrid (AMG) using the Galerkin definition of the coarse operator, $A_{c}=R\\,A\\,P$. Construct a naive coarsening that aggregates all four fine-grid unknowns into a single coarse unknown, with restriction and prolongation that ignore anisotropy: define restriction as the simple average $R=\\frac{1}{4}\\,[\\,1\\;\\;1\\;\\;1\\;\\;1\\,]$ and prolongation as piecewise-constant interpolation $P=[\\,1\\;\\;1\\;\\;1\\;\\;1\\,]^{\\top}$. Consider a two-grid cycle with zero smoothing steps, i.e., only one coarse-grid correction is applied to the fine-grid error.\n\nStarting from first principles of the finite-difference discretization and the Galerkin coarse-grid construction, derive the resulting two-grid error-propagation operator for this setup and determine its spectral radius. Express the final spectral radius as a dimensionless number and round your answer to four significant figures.",
            "solution": "The user has asked for the derivation of the spectral radius of a two-grid error-propagation operator for a specific anisotropic diffusion problem.\n\n### Step 1: Problem Validation\n\n**1. Extract Givens:**\n- **Operator:** $-\\partial_{x}(\\alpha\\,\\partial_{x} u)-\\partial_{y}(\\beta\\,\\partial_{y} u)$\n- **Domain:** Unit square $[0,1] \\times [0,1]$\n- **Boundary Conditions:** Homogeneous Dirichlet ($u=0$ on the boundary).\n- **Discretization:** Uniform fine grid, standard five-point finite-difference stencil.\n- **Grid Size:** $N_{x}=2$ and $N_{y}=2$ interior points.\n- **Grid Spacing:** $h_{x} = h_{y} = h = 1/3$.\n- **Anisotropy Parameters:** $\\alpha = 1$, $\\beta = \\varepsilon = 10^{-6}$.\n- **Unknown Ordering:** The $4$ unknowns are ordered as $(i,j)=(1,1),(2,1),(1,2),(2,2)$.\n- **AMG Setup:**\n  - **Coarsening:** All four fine-grid unknowns aggregated into a single coarse unknown.\n  - **Restriction Operator ($R$):** $R = \\frac{1}{4}\\begin{pmatrix} 1 & 1 & 1 & 1 \\end{pmatrix}$.\n  - **Prolongation Operator ($P$):** $P = \\begin{pmatrix} 1 & 1 & 1 & 1 \\end{pmatrix}^{\\top}$.\n  - **Coarse Operator Definition:** Galerkin operator, $A_{c} = R\\,A\\,P$.\n- **Two-Grid Cycle:** Zero pre- and post-smoothing steps.\n- **Task:** Derive the two-grid error-propagation operator and determine its spectral radius, rounded to four significant figures.\n\n**2. Validate Using Extracted Givens:**\n- **Scientifically Grounded:** The problem is a standard exercise in the field of numerical analysis, specifically concerning multigrid methods for solving partial differential equations. The setup is based on established principles of finite-difference methods and algebraic multigrid.\n- **Well-Posed:** The problem is clearly defined with all necessary components (PDE, domain, boundary conditions, discretization, multigrid operators) specified. It leads to a unique, determinable result.\n- **Objective:** The language is precise and mathematical. All terms are standard in the field.\n\n**3. Verdict and Action:**\nThe problem is deemed **valid**. It is a well-posed, scientifically sound problem in numerical analysis. The solution process can proceed.\n\n### Step 2: Derivation and Solution\n\n**1. Discretization and Fine-Grid Operator ($A$)**\n\nThe given anisotropic diffusion operator is $L(u) = -\\alpha \\frac{\\partial^2 u}{\\partial x^2} - \\beta \\frac{\\partial^2 u}{\\partial y^2}$. Using a central finite-difference scheme on a uniform grid with spacing $h = h_x = h_y$, the operator at an interior grid point $(x_i, y_j)$ is approximated as:\n$$\nL_h u_{ij} = -\\alpha \\frac{u_{i+1,j} - 2u_{ij} + u_{i-1,j}}{h^2} - \\beta \\frac{u_{i,j+1} - 2u_{ij} + u_{i,j-1}}{h^2}\n$$\nRearranging terms, we get the stencil equation:\n$$\n(L_h u)_{ij} = \\frac{1}{h^2} \\left[ (2\\alpha + 2\\beta)u_{ij} - \\alpha u_{i-1,j} - \\alpha u_{i+1,j} - \\beta u_{i,j-1} - \\beta u_{i,j+1} \\right]\n$$\nThe problem specifies $N_x=N_y=2$ interior points, so $h=1/3$. The interior points are $(1/3, 1/3)$, $(2/3, 1/3)$, $(1/3, 2/3)$, and $(2/3, 2/3)$. The unknowns are ordered as $u_1 = u_{11}$, $u_2 = u_{21}$, $u_3 = u_{12}$, $u_4 = u_{22}$. We apply the stencil equation at each of the four points, incorporating the homogeneous Dirichlet boundary conditions ($u_{0j}=u_{3j}=u_{i0}=u_{i3}=0$ for $i,j \\in \\{1,2\\}$).\n\n- For $u_1 = u_{11}$:\n$\\frac{1}{h^2} [ (2\\alpha + 2\\beta)u_{11} - \\alpha u_{21} - \\beta u_{12} ]$\n- For $u_2 = u_{21}$:\n$\\frac{1}{h^2} [ (2\\alpha + 2\\beta)u_{21} - \\alpha u_{11} - \\beta u_{22} ]$\n- For $u_3 = u_{12}$:\n$\\frac{1}{h^2} [ (2\\alpha + 2\\beta)u_{12} - \\alpha u_{22} - \\beta u_{11} ]$\n- For $u_4 = u_{22}$:\n$\\frac{1}{h^2} [ (2\\alpha + 2\\beta)u_{22} - \\alpha u_{12} - \\beta u_{21} ]$\n\nThese equations form the linear system $A\\mathbf{u}=\\mathbf{f}$. The fine-grid matrix $A$ is:\n$$\nA = \\frac{1}{h^2}\n\\begin{pmatrix}\n2\\alpha+2\\beta & -\\alpha & -\\beta & 0 \\\\\n-\\alpha & 2\\alpha+2\\beta & 0 & -\\beta \\\\\n-\\beta & 0 & 2\\alpha+2\\beta & -\\alpha \\\\\n0 & -\\beta & -\\alpha & 2\\alpha+2\\beta\n\\end{pmatrix}\n$$\n\n**2. Coarse-Grid Operator ($A_c$)**\n\nThe coarse-grid operator is constructed using the Galerkin formula $A_c = R A P$. The given restriction and prolongation operators are:\n$$\nR = \\frac{1}{4}\\begin{pmatrix} 1 & 1 & 1 & 1 \\end{pmatrix}, \\quad P = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\nFirst, we compute the product $AP$:\n$$\nAP = \\frac{1}{h^2}\n\\begin{pmatrix}\n2\\alpha+2\\beta & -\\alpha & -\\beta & 0 \\\\\n-\\alpha & 2\\alpha+2\\beta & 0 & -\\beta \\\\\n-\\beta & 0 & 2\\alpha+2\\beta & -\\alpha \\\\\n0 & -\\beta & -\\alpha & 2\\alpha+2\\beta\n\\end{pmatrix}\n\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n= \\frac{1}{h^2}\n\\begin{pmatrix}\n\\alpha+\\beta \\\\ \\alpha+\\beta \\\\ \\alpha+\\beta \\\\ \\alpha+\\beta\n\\end{pmatrix}\n= \\frac{\\alpha+\\beta}{h^2}\n\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\nNow, we pre-multiply by $R$:\n$$\nA_c = R (AP) = \\frac{1}{4}\\begin{pmatrix} 1 & 1 & 1 & 1 \\end{pmatrix} \\left( \\frac{\\alpha+\\beta}{h^2} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\right) = \\frac{\\alpha+\\beta}{4h^2} (1+1+1+1) = \\frac{\\alpha+\\beta}{h^2}\n$$\n$A_c$ is a scalar (a $1 \\times 1$ matrix), and its inverse is $A_c^{-1} = \\frac{h^2}{\\alpha+\\beta}$.\n\n**3. Two-Grid Error-Propagation Operator ($M_{TG}$)**\n\nA two-grid cycle with zero pre- and post-smoothing steps consists only of the coarse-grid correction. The error $e_{k}$ is transformed to $e_{k+1}$ according to the relation $e_{k+1} = (I - P A_c^{-1} R A) e_k$. The error-propagation operator is therefore:\n$$\nM_{TG} = I - P A_c^{-1} R A\n$$\nLet's compute the coarse-grid correction part, $K = P A_c^{-1} R A$.\nFirst, we form the product $P A_c^{-1} R$:\n$$\nP A_c^{-1} R = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} \\left( \\frac{h^2}{\\alpha+\\beta} \\right) \\frac{1}{4}\\begin{pmatrix} 1 & 1 & 1 & 1 \\end{pmatrix} = \\frac{h^2}{4(\\alpha+\\beta)}\n\\begin{pmatrix}\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1\n\\end{pmatrix}\n$$\nLet $J$ be the $4 \\times 4$ matrix of all ones. Then $P A_c^{-1} R = \\frac{h^2}{4(\\alpha+\\beta)} J$.\nNow, we compute $K = (P A_c^{-1} R) A$:\n$$\nK = \\frac{h^2}{4(\\alpha+\\beta)} J A\n$$\nThe product $JA$ is a matrix where each row is the sum of all rows of $A$. Summing the columns of $A$ gives the elements of this row vector:\n$$\n\\sum_{i} A_{i1} = \\frac{1}{h^2}( (2\\alpha+2\\beta) - \\alpha - \\beta ) = \\frac{\\alpha+\\beta}{h^2} \\\\\n\\sum_{i} A_{i2} = \\frac{1}{h^2}( -\\alpha + (2\\alpha+2\\beta) - \\beta ) = \\frac{\\alpha+\\beta}{h^2} \\\\\n\\sum_{i} A_{i3} = \\frac{1}{h^2}( -\\beta + (2\\alpha+2\\beta) - \\alpha ) = \\frac{\\alpha+\\beta}{h^2} \\\\\n\\sum_{i} A_{i4} = \\frac{1}{h^2}( -\\beta - \\alpha + (2\\alpha+2\\beta) ) = \\frac{\\alpha+\\beta}{h^2}\n$$\nSo, $JA = \\frac{\\alpha+\\beta}{h^2} J$.\nSubstituting this back into the expression for $K$:\n$$\nK = \\frac{h^2}{4(\\alpha+\\beta)} \\left( \\frac{\\alpha+\\beta}{h^2} J \\right) = \\frac{1}{4} J = \\frac{1}{4}\n\\begin{pmatrix}\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1\n\\end{pmatrix}\n$$\nThe error-propagation operator is:\n$$\nM_{TG} = I - K = I - \\frac{1}{4}J =\n\\begin{pmatrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{pmatrix}\n- \\frac{1}{4}\n\\begin{pmatrix} 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\end{pmatrix}\n= \\frac{1}{4}\n\\begin{pmatrix} 3 & -1 & -1 & -1 \\\\ -1 & 3 & -1 & -1 \\\\ -1 & -1 & 3 & -1 \\\\ -1 & -1 & -1 & 3 \\end{pmatrix}\n$$\nNotably, the operator $M_{TG}$ is independent of the parameters $\\alpha$, $\\beta$, and $h$. This is a consequence of the chosen naive restriction and prolongation operators, which are aligned with the constant vector, an eigenvector of the discrete operator $A$.\n\n**4. Spectral Radius of $M_{TG}$**\n\nThe spectral radius $\\rho(M_{TG})$ is the maximum of the absolute values of the eigenvalues of $M_{TG}$. The eigenvalues of $M_{TG} = I - \\frac{1}{4}J$ can be found from the eigenvalues of $J$.\nThe matrix $J$ has rank $1$. Its characteristic polynomial is $\\det(J - \\lambda I)$. The vector $\\mathbf{1} = \\begin{pmatrix} 1 & 1 & 1 & 1 \\end{pmatrix}^{\\top}$ is an eigenvector, since $J\\mathbf{1} = 4\\mathbf{1}$. Thus, one eigenvalue of $J$ is $\\lambda_1 = 4$. Since $\\mathrm{rank}(J) = 1$, the null space of $J$ has dimension $4-1=3$. This means the eigenvalue $\\lambda=0$ has a multiplicity of $3$. The eigenvalues of $J$ are $\\{4, 0, 0, 0\\}$.\n\nThe eigenvalues of $M_{TG}$, denoted $\\mu$, are related to the eigenvalues of $J$ by $\\mu = 1 - \\frac{1}{4}\\lambda$.\n- For $\\lambda=4$: $\\mu = 1 - \\frac{1}{4}(4) = 0$.\n- For $\\lambda=0$: $\\mu = 1 - \\frac{1}{4}(0) = 1$. This eigenvalue has multiplicity $3$.\n\nThe eigenvalues of $M_{TG}$ are $\\{1, 1, 1, 0\\}$.\nThe spectral radius is the maximum of the absolute values of these eigenvalues:\n$$\n\\rho(M_{TG}) = \\max\\{|1|, |0|\\} = 1\n$$\nThis result indicates that the two-grid method with this specific setup does not converge, as error components in the space corresponding to the eigenvalue $1$ are not attenuated. This is a classic example of why AMG operators must be chosen carefully to match the properties (e.g., anisotropy) of the system matrix $A$.\n\nRounding the spectral radius to four significant figures gives $1.000$.",
            "answer": "$$\\boxed{1.000}$$"
        },
        {
            "introduction": "Moving from idealized examples to real-world scenarios, this final practice puts you in the role of a CFD practitioner tasked with debugging a failing solver. In complex, nonlinear systems, AMG convergence can break down for subtle reasons related to the interplay of its many parameters. By analyzing diagnostic data from a realistic aerospace simulation, you will learn to interpret key performance indicators, identify the root cause of divergence, and propose scientifically justified fixes—a critical skill for developing and using advanced FAS-AMG methods in production environments. ",
            "id": "3961628",
            "problem": "A team is solving a steady compressible Navier–Stokes system in a two-dimensional boundary layer around a slender airfoil within Computational Fluid Dynamics (CFD). The flow is at Mach number $M=2$ and Reynolds number $Re=10^{6}$. The discrete nonlinear residual is driven to zero by a Full Approximation Scheme (FAS) multigrid, while each nonlinear FAS level uses Algebraic Multigrid (AMG) to precondition a Krylov method on the linearized system. The dominant stiffness arises from highly stretched elements in the wall-normal direction with aspect ratio $\\alpha=10^{3}$, producing a convection–diffusion operator whose discrete matrix has strong anisotropy: entries coupling wall-parallel neighbors are of magnitude comparable to the diagonal, while wall-normal couplings are much weaker away from the immediate wall vicinity.\n\nThe linearized system at a representative Newton step can be modeled as $\\mathbf{A}\\mathbf{u}=\\mathbf{b}$, where $\\mathbf{A}$ is an $M$-matrix with nonpositive off-diagonals. A pointwise relaxation damps high-frequency error effectively, with measured high-frequency smoothing factor $\\mu_{s}\\approx 0.25$ for one pre- and one post-relaxation, indicating adequate smoothing. However, the AMG-preconditioned Krylov method diverges in the FAS cycle. To diagnose the cause, the team performs controlled parameter scans of three AMG design components:\n- The strength-of-connection threshold $\\theta$ used in the classical definition, where index $j$ is strongly connected to $i$ if $-a_{ij}\\ge \\theta \\max_{k\\ne i}(-a_{ik})$.\n- The coarsening strategy, varied between standard classical coarsening and an aggressive coarsening that halves the fine-grid degrees of freedom per level.\n- The interpolation truncation parameter $\\tau$, where interpolation weights with magnitude less than $\\tau$ times the maximum weight are dropped.\n\nThey record the following observations on a representative subdomain aligned with the wall:\n1. Baseline configuration with $\\theta=0.25$, aggressive coarsening, and $\\tau=0.10$ yields two-grid spectral radius $\\rho_{TG}\\approx 1.20$ (divergent), compatible relaxation indicator $\\mu_{CR}\\approx 0.85$ (poor coarse representation), and average number of strong neighbors per fine node $n_{s}\\approx 6$, with strong neighbors distributed isotropically rather than aligned with the wall.\n2. With $\\theta$ increased to $\\theta=0.70$ while keeping aggressive coarsening and $\\tau=0.10$ unchanged, the measures become $\\rho_{TG}\\approx 0.35$, $\\mu_{CR}\\approx 0.20$, and $n_{s}\\approx 2$, with strong connections predominantly aligned along the wall, and FAS-AMG converges.\n3. With standard classical coarsening instead of aggressive while keeping $\\theta=0.25$ and $\\tau=0.10$, the measures are $\\rho_{TG}\\approx 1.10$, $\\mu_{CR}\\approx 0.80$, and $n_{s}\\approx 6$, and FAS-AMG still diverges.\n4. With interpolation truncation disabled ($\\tau=0$) while keeping $\\theta=0.25$ and aggressive coarsening, the measures are $\\rho_{TG}\\approx 1.15$, $\\mu_{CR}\\approx 0.82$, and $n_{s}\\approx 6$, and FAS-AMG still diverges.\n\nAssume that for convergence of multigrid, coarse-grid correction must efficiently reduce algebraically smooth error, characterized by error components $\\mathbf{e}$ with $\\mathbf{A}\\mathbf{e}\\approx \\mathbf{0}$, and that compatible relaxation $\\mu_{CR}$ near zero indicates a coarse variable set that well represents these components. Also assume that adequate smoothing (small $\\mu_{s}$) is already available. Based on these first principles and the observed data, identify the primary root cause among the three candidates and select the option that correctly diagnoses it and proposes scientifically justified fixes that are most likely to resolve the divergence in this anisotropic aerospace CFD case.\n\nA. The strength-of-connection threshold $\\theta$ is too low, causing the strong-connection graph to include many weak, isotropic neighbors and fail to represent the anisotropy, which yields a poor coarse variable set. Fix by increasing $\\theta$ to emphasize truly strong, anisotropic couplings, or by adopting a directionally scaled strength measure tied to wall-parallel couplings; leave coarsening and interpolation truncation unchanged.\n\nB. The coarsening is too aggressive, resulting in an insufficient coarse-grid density that cannot represent algebraically smooth error. Fix by switching to standard classical coarsening or by adding intermediate levels; no change to $\\theta$ or $\\tau$ is needed.\n\nC. Interpolation truncation is overly severe, discarding essential weak connections that are necessary to represent smooth error. Fix by setting $\\tau$ close to zero or using energy-minimizing interpolation with no truncation; $\\theta$ and coarsening need not change.\n\nD. The pointwise smoother is mismatched to the anisotropy and fails to damp high-frequency error along stretched directions. Fix by replacing pointwise relaxation with line or block relaxation aligned with the wall-normal grid lines; the AMG hierarchy parameters need not change.",
            "solution": "The starting point is that the Full Approximation Scheme (FAS) requires each nonlinear level to provide a coarse-grid correction that effectively reduces algebraically smooth error components. These error components, denoted by $\\mathbf{e}$, satisfy $\\mathbf{A}\\mathbf{e}\\approx \\mathbf{0}$ and are not reduced efficiently by relaxation but should be removed by coarse-grid correction. The quality of coarse-grid correction depends on three intertwined elements: (i) how strong connections are identified to build the coarse variable set, (ii) how coarsening chooses coarse points to cover the strong graph, and (iii) how interpolation transfers algebraically smooth modes between grids. Compatible relaxation provides a first-principles indicator of whether the chosen coarse variables adequately represent the algebraically smooth error; values of $\\mu_{CR}$ near zero indicate good representation, while values closer to one indicate poor representation.\n\nGiven the operator anisotropy, a correct strength-of-connection graph must emphasize the physically strong couplings (here, those aligned wall-parallel) and de-emphasize weak couplings (here, wall-normal away from the wall). If the strength threshold $\\theta$ is too low, many weak couplings are flagged as strong, creating an almost isotropic strong graph. This tends to corrupt the coarse variable selection, leading to a coarse set that does not span the correct algebraically smooth error. Conversely, increasing $\\theta$ filters weak connections, leaving only truly strong, anisotropic connections, thereby improving the alignment between the coarse space and the error modes. The two-grid spectral radius $\\rho_{TG}$ provides a direct measure of the error-propagation operator; $\\rho_{TG}<1$ indicates contraction, while $\\rho_{TG}>1$ indicates divergence.\n\nWe analyze the observations step by step:\n\nBaseline (observation $1$): $\\theta=0.25$ with aggressive coarsening and $\\tau=0.10$ yields $\\rho_{TG}\\approx 1.20$ and $\\mu_{CR}\\approx 0.85$. The high-frequency smoothing factor is already good, $\\mu_{s}\\approx 0.25$, so relaxation is not the bottleneck. The compatible relaxation value near one signals that the coarse variables do not represent the algebraically smooth error well. Additionally, the average strong neighbor count $n_{s}\\approx 6$ and their isotropic distribution indicate that the strength graph is not aligned with the physical anisotropy. This points toward a problem in how strength is defined or thresholded.\n\nChanging only $\\theta$ (observation $2$): With $\\theta$ increased to $\\theta=0.70$, all else fixed, $\\rho_{TG}\\approx 0.35$ and $\\mu_{CR}\\approx 0.20$. The strong neighbor count reduces to $n_{s}\\approx 2$ and aligns along the wall. This isolated change transforms divergence into robust convergence without altering coarsening or truncation. From first principles, this indicates that the coarse space now spans the algebraically smooth error due to a corrected strong graph, confirming that the strength threshold was the key deficiency.\n\nChanging only coarsening (observation $3$): Switching to standard classical coarsening with $\\theta=0.25$ leaves $\\rho_{TG}\\approx 1.10$ and $\\mu_{CR}\\approx 0.80$, still poor. This demonstrates that coarsening density alone cannot fix the misrepresentation of the anisotropic strong graph; if the strong graph itself is wrong, the choice of $C$ points will remain misaligned.\n\nChanging only interpolation truncation (observation $4$): Disabling truncation ($\\tau=0$) with $\\theta=0.25$ yields $\\rho_{TG}\\approx 1.15$ and $\\mu_{CR}\\approx 0.82$, which remains divergent. While truncation can degrade interpolation in some cases by removing weights needed to represent smooth error, here removing truncation does not materially improve the coarse-grid correction, indicating truncation is not the root cause.\n\nFinally, we consider the smoother (option $D$). The measured high-frequency smoothing factor $\\mu_{s}\\approx 0.25$ already indicates adequate damping of high-frequency components. In such a case, multigrid failure arises from an inability to represent and correct low-frequency (in the algebraic sense) error, not from smoothing inefficiency. Thus, changing the smoother would not address the core issue.\n\nPutting these pieces together, the only parameter change that resolves divergence while leaving other settings intact is the increase of the strength threshold $\\theta$, which filters weak connections and recovers the anisotropic strong graph. From first principles, this improves the coarse-space’s ability to represent $\\mathbf{A}$-smooth error and yields a small $\\mu_{CR}$ and $\\rho_{TG}<1$.\n\nOption-by-option analysis:\n\n- Option A: It asserts that $\\theta$ is too low, causing an isotropic strong graph and poor coarse variable sets; it proposes increasing $\\theta$ or using a directionally scaled strength measure. This matches observation $1$ (isotropic strong neighbor distribution, large $n_{s}$, poor $\\mu_{CR}$) and observation $2$ (increasing $\\theta$ fixes convergence and improves $\\mu_{CR}$). The proposed fixes are consistent with the physics of anisotropy and with AMG theory regarding strength graphs and coarse-space quality. Verdict: Correct.\n\n- Option B: It blames aggressive coarsening and suggests standard coarsening or more levels as a fix. Observation $3$ shows that moving to standard coarsening while keeping $\\theta=0.25$ does not resolve divergence; $\\rho_{TG}$ remains greater than one and $\\mu_{CR}$ stays high. Without correcting the strong graph, coarsening density cannot align the coarse space to the anisotropy. Verdict: Incorrect.\n\n- Option C: It blames interpolation truncation and suggests reducing $\\tau$ or using energy-minimizing interpolation. Observation $4$ demonstrates that disabling truncation does not fix divergence; the key indicators barely change. Therefore truncation is not the root cause in this case. Verdict: Incorrect.\n\n- Option D: It blames the smoother and suggests line or block relaxation. However, $\\mu_{s}\\approx 0.25$ indicates that high-frequency error is already well damped, and the failure mode is the coarse-grid correction of algebraically smooth error. Changing the smoother will not align the coarse space with anisotropy and thus will not fix the observed poor $\\mu_{CR}$. Verdict: Incorrect.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}