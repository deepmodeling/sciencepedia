{
    "hands_on_practices": [
        {
            "introduction": "To truly understand the Successive Over-Relaxation (SOR) method, we must begin with its fundamental components. This first exercise guides you through the process of constructing the SOR iteration matrix, $T_{\\omega}$, from the ground up for a simple system. By manually calculating the matrix and its spectral radius, $\\rho(T_{\\omega})$, you will gain a concrete understanding of how the relaxation parameter $\\omega$ directly influences the operator that governs the convergence of the iteration .",
            "id": "3581656",
            "problem": "Consider the linear system $A x = b$ with \n$$\nA=\\begin{pmatrix}2  -1 \\\\ -1  2\\end{pmatrix}, \n\\qquad \nb=\\begin{pmatrix}1 \\\\ 0\\end{pmatrix},\n\\qquad \n\\omega=\\frac{3}{2}.\n$$\nStarting from the decomposition of $A$ into its diagonal part, strictly lower triangular part, and strictly upper triangular part, and from the definition of the Successive Over-Relaxation (SOR) method as a stationary iteration obtained by applying a relaxation parameter to the Gauss–Seidel update, derive the iteration in the affine form $x^{k+1}=T_{\\omega}\\,x^{k}+c_{\\omega}$, identify the SOR iteration matrix $T_{\\omega}$ for the given $A$ and $\\omega$, and determine its spectral radius (the maximum absolute value of its eigenvalues). Your final reported answer must be the spectral radius as a single exact number. Do not round.",
            "solution": "The problem statement is first subjected to validation.\n\n**Step 1: Extract Givens**\n- The linear system is $A x = b$.\n- The matrix $A$ is given as $A=\\begin{pmatrix}2  -1 \\\\ -1  2\\end{pmatrix}$.\n- The vector $b$ is given as $b=\\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$.\n- The relaxation parameter $\\omega$ is given as $\\omega=\\frac{3}{2}$.\n- The task is to derive the Successive Over-Relaxation (SOR) iteration matrix $T_{\\omega}$ and compute its spectral radius, $\\rho(T_{\\omega})$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is a standard exercise in numerical linear algebra concerning stationary iterative methods, specifically the SOR method. It is based on well-established mathematical principles.\n- **Well-Posed**: The problem is well-posed. The matrix $A$ and the parameter $\\omega$ are explicitly defined. The task of finding the SOR iteration matrix and its spectral radius is a uniquely defined mathematical procedure. The matrix $A$ is symmetric and positive definite (its eigenvalues are $1$ and $3$), which guarantees that the SOR method converges for any $\\omega \\in (0, 2)$. The given value $\\omega = \\frac{3}{2}$ lies within this interval.\n- **Objective**: The problem is stated using precise, objective mathematical language.\n- **Completeness**: All necessary information to determine the iteration matrix $T_{\\omega}$ and its spectral radius is provided. The vector $b$ is not required for this specific task, but its presence does not create a contradiction.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid** as it is scientifically grounded, well-posed, and complete. A full solution will be provided.\n\nThe Successive Over-Relaxation (SOR) method is a stationary iterative method for solving a linear system $A x = b$. The matrix $A$ is first decomposed into its diagonal component $D$, its strictly lower triangular component $-L$, and its strictly upper triangular component $-U$, such that $A = D - L - U$.\n\nFor the given matrix $A = \\begin{pmatrix}2  -1 \\\\ -1  2\\end{pmatrix}$, the decomposition is:\n$$D = \\begin{pmatrix}2  0 \\\\ 0  2\\end{pmatrix}, \\quad L = \\begin{pmatrix}0  0 \\\\ 1  0\\end{pmatrix}, \\quad U = \\begin{pmatrix}0  1 \\\\ 0  0\\end{pmatrix}$$\n\nThe SOR iteration is defined by the equation:\n$$(D - \\omega L) x^{k+1} = \\big((1-\\omega)D + \\omega U\\big) x^{k} + \\omega b$$\nThis can be written in the affine form $x^{k+1} = T_{\\omega} x^{k} + c_{\\omega}$, where the iteration matrix $T_{\\omega}$ is given by:\n$$T_{\\omega} = (D - \\omega L)^{-1} \\big((1-\\omega)D + \\omega U\\big)$$\nand the constant vector $c_{\\omega}$ is given by $c_{\\omega} = \\omega (D - \\omega L)^{-1} b$. Our goal is to find the spectral radius of $T_{\\omega}$.\n\nWe are given $\\omega = \\frac{3}{2}$. First, we compute the matrix $(D - \\omega L)$:\n$$D - \\omega L = \\begin{pmatrix}2  0 \\\\ 0  2\\end{pmatrix} - \\frac{3}{2}\\begin{pmatrix}0  0 \\\\ 1  0\\end{pmatrix} = \\begin{pmatrix}2  0 \\\\ -\\frac{3}{2}  2\\end{pmatrix}$$\n\nNext, we find the inverse of this matrix, $(D - \\omega L)^{-1}$:\n$$(D - \\omega L)^{-1} = \\frac{1}{(2)(2) - (0)(-\\frac{3}{2})} \\begin{pmatrix}2  0 \\\\ \\frac{3}{2}  2\\end{pmatrix} = \\frac{1}{4} \\begin{pmatrix}2  0 \\\\ \\frac{3}{2}  2\\end{pmatrix} = \\begin{pmatrix}\\frac{1}{2}  0 \\\\ \\frac{3}{8}  \\frac{1}{2}\\end{pmatrix}$$\n\nNow, we compute the matrix $\\big((1-\\omega)D + \\omega U\\big)$. Since $\\omega = \\frac{3}{2}$, the term $(1-\\omega)$ is $1 - \\frac{3}{2} = -\\frac{1}{2}$.\n$$(1-\\omega)D + \\omega U = -\\frac{1}{2}\\begin{pmatrix}2  0 \\\\ 0  2\\end{pmatrix} + \\frac{3}{2}\\begin{pmatrix}0  1 \\\\ 0  0\\end{pmatrix} = \\begin{pmatrix}-1  0 \\\\ 0  -1\\end{pmatrix} + \\begin{pmatrix}0  \\frac{3}{2} \\\\ 0  0\\end{pmatrix} = \\begin{pmatrix}-1  \\frac{3}{2} \\\\ 0  -1\\end{pmatrix}$$\n\nFinally, we compute the SOR iteration matrix $T_{\\omega}$ by multiplying the two resulting matrices:\n$$T_{\\omega} = (D - \\omega L)^{-1} \\big((1-\\omega)D + \\omega U\\big) = \\begin{pmatrix}\\frac{1}{2}  0 \\\\ \\frac{3}{8}  \\frac{1}{2}\\end{pmatrix} \\begin{pmatrix}-1  \\frac{3}{2} \\\\ 0  -1\\end{pmatrix}$$\n$$T_{\\omega} = \\begin{pmatrix} (\\frac{1}{2})(-1) + (0)(0)  (\\frac{1}{2})(\\frac{3}{2}) + (0)(-1) \\\\ (\\frac{3}{8})(-1) + (\\frac{1}{2})(0)  (\\frac{3}{8})(\\frac{3}{2}) + (\\frac{1}{2})(-1) \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2}  \\frac{3}{4} \\\\ -\\frac{3}{8}  \\frac{9}{16} - \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2}  \\frac{3}{4} \\\\ -\\frac{3}{8}  \\frac{1}{16} \\end{pmatrix}$$\n\nTo find the spectral radius $\\rho(T_{\\omega})$, we need to find the eigenvalues of $T_{\\omega}$ by solving the characteristic equation $\\det(T_{\\omega} - \\lambda I) = 0$.\n$$\\det\\begin{pmatrix} -\\frac{1}{2} - \\lambda  \\frac{3}{4} \\\\ -\\frac{3}{8}  \\frac{1}{16} - \\lambda \\end{pmatrix} = 0$$\n$$\\left(-\\frac{1}{2} - \\lambda\\right)\\left(\\frac{1}{16} - \\lambda\\right) - \\left(\\frac{3}{4}\\right)\\left(-\\frac{3}{8}\\right) = 0$$\n$$-\\frac{1}{32} + \\frac{1}{2}\\lambda - \\frac{1}{16}\\lambda + \\lambda^2 + \\frac{9}{32} = 0$$\n$$\\lambda^2 + \\left(\\frac{8}{16} - \\frac{1}{16}\\right)\\lambda + \\left(\\frac{9}{32} - \\frac{1}{32}\\right) = 0$$\n$$\\lambda^2 + \\frac{7}{16}\\lambda + \\frac{8}{32} = 0$$\n$$\\lambda^2 + \\frac{7}{16}\\lambda + \\frac{1}{4} = 0$$\n\nWe solve this quadratic equation for $\\lambda$ using the quadratic formula, $\\lambda = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n$$\\lambda = \\frac{-\\frac{7}{16} \\pm \\sqrt{\\left(\\frac{7}{16}\\right)^2 - 4(1)\\left(\\frac{1}{4}\\right)}}{2(1)} = \\frac{-\\frac{7}{16} \\pm \\sqrt{\\frac{49}{256} - 1}}{2}$$\n$$\\lambda = \\frac{-\\frac{7}{16} \\pm \\sqrt{\\frac{49 - 256}{256}}}{2} = \\frac{-\\frac{7}{16} \\pm i\\frac{\\sqrt{207}}{16}}{2}$$\nThe two eigenvalues are a complex conjugate pair:\n$$\\lambda_{1,2} = -\\frac{7}{32} \\pm i\\frac{\\sqrt{207}}{32}$$\n\nThe spectral radius $\\rho(T_{\\omega})$ is the maximum absolute value (modulus) of the eigenvalues. Since the eigenvalues are a complex conjugate pair, their moduli are equal. We calculate the modulus squared of one of the eigenvalues:\n$$|\\lambda|^2 = \\left(-\\frac{7}{32}\\right)^2 + \\left(\\frac{\\sqrt{207}}{32}\\right)^2 = \\frac{49}{1024} + \\frac{207}{1024} = \\frac{49 + 207}{1024} = \\frac{256}{1024} = \\frac{1}{4}$$\nThe modulus is the square root of this value:\n$$|\\lambda| = \\sqrt{\\frac{1}{4}} = \\frac{1}{2}$$\nBoth eigenvalues have a modulus of $\\frac{1}{2}$. Therefore, the spectral radius of $T_{\\omega}$ is:\n$$\\rho(T_{\\omega}) = \\max(|\\lambda_1|, |\\lambda_2|) = \\frac{1}{2}$$",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        },
        {
            "introduction": "The efficiency of the SOR method hinges on the choice of the relaxation parameter, $\\omega$. For an important class of matrices that are symmetric, positive-definite, and possess a property known as \"consistent ordering,\" it is possible to analytically determine the optimal parameter, $\\omega_{\\mathrm{opt}}$, that yields the fastest convergence. This practice demonstrates how to calculate this value by leveraging its relationship with the spectral radius of the simpler Jacobi iteration matrix, moving our understanding from mere convergence to optimized performance .",
            "id": "2207379",
            "problem": "A researcher is modeling a system of coupled oscillators, which leads to a system of linear equations $Ax=b$. The interaction matrix $A$ is given by:\n$$A = \\begin{pmatrix} 3  -2  0 \\\\ -2  3  -2 \\\\ 0  -2  3 \\end{pmatrix}$$\nTo solve this system numerically, the researcher decides to use the Successive Over-Relaxation (SOR) method, an iterative technique that depends on a relaxation parameter $\\omega$. The full name for SOR is Successive Over-Relaxation. Your task is to find the optimal relaxation parameter, $\\omega_{opt}$, that yields the fastest rate of convergence for this specific matrix $A$. The optimal parameter is defined as the value of $\\omega$, typically in the interval $(0, 2)$, that minimizes the spectral radius of the SOR iteration matrix.\n\nCalculate the exact numerical value of $\\omega_{opt}$.",
            "solution": "For the Successive Over-Relaxation method applied to a symmetric positive definite and consistently ordered matrix, the optimal relaxation parameter is given in terms of the Jacobi iteration matrix spectral radius by\n$$\n\\omega_{\\text{opt}}=\\frac{2}{1+\\sqrt{1-\\rho(G_{J})^{2}}},\n$$\nwhere $G_{J}$ is the Jacobi iteration matrix.\n\nWrite the splitting $A=D-L-U$ with $D=\\operatorname{diag}(A)$ and use the identity $G_{J}=I-D^{-1}A$. For the given\n$$\nA=\\begin{pmatrix}\n3  -2  0\\\\\n-2  3  -2\\\\\n0  -2  3\n\\end{pmatrix},\n\\quad D=3I,\n$$\nso\n$$\nG_{J}=I-D^{-1}A=I-\\frac{1}{3}A\n=\\begin{pmatrix}\n0  \\frac{2}{3}  0\\\\\n\\frac{2}{3}  0  \\frac{2}{3}\\\\\n0  \\frac{2}{3}  0\n\\end{pmatrix}.\n$$\nThis is a tridiagonal Toeplitz matrix with zero diagonal and constant off-diagonal $c=\\frac{2}{3}$. Its eigenvalues are\n$$\n\\lambda_{k}=2c\\cos\\!\\left(\\frac{k\\pi}{n+1}\\right),\\quad k=1,2,3,\\; n=3,\n$$\nthat is,\n$$\n\\lambda_{k}=\\frac{4}{3}\\cos\\!\\left(\\frac{k\\pi}{4}\\right)\\in\\left\\{\\frac{2\\sqrt{2}}{3},\\,0,\\,-\\frac{2\\sqrt{2}}{3}\\right\\}.\n$$\nHence\n$$\n\\rho(G_{J})=\\frac{2\\sqrt{2}}{3},\\qquad \\rho(G_{J})^{2}=\\frac{8}{9}.\n$$\nSubstituting into the optimal SOR formula,\n$$\n\\omega_{\\text{opt}}=\\frac{2}{1+\\sqrt{1-\\frac{8}{9}}}\n=\\frac{2}{1+\\sqrt{\\frac{1}{9}}}\n=\\frac{2}{1+\\frac{1}{3}}\n=\\frac{2}{\\frac{4}{3}}\n=\\frac{3}{2}.\n$$\nThis value lies in $(0,2)$ and minimizes the spectral radius of the SOR iteration matrix for the given $A$.",
            "answer": "$$\\boxed{\\frac{3}{2}}$$"
        },
        {
            "introduction": "A critical aspect of applying any numerical method is understanding its limitations. The convergence guarantee for SOR is strongest for symmetric positive-definite matrices, but many advanced problems in CFD, such as those involving the Helmholtz equation, produce indefinite systems. This practice provides a computational framework to investigate what happens as a matrix loses its positive-definiteness, revealing how the spectral radius $\\rho(T_{\\mathrm{SOR}})$ can exceed unity and cause the method to fail, a crucial lesson for diagnosing and selecting solvers in complex simulations .",
            "id": "3198971",
            "problem": "Consider the one-dimensional Helmholtz-type linear system on a uniform grid with Dirichlet boundary conditions. The continuous operator is the Helmholtz operator, and the discretization yields a matrix of the form $A = -\\Delta - k^2 I$, where $-\\Delta$ denotes the discrete negative Laplacian and $k^2$ is a nonnegative scalar shift. Using a second-order central difference approximation on the interval $[0,1]$ with $n$ interior points and uniform spacing $h = \\frac{1}{n+1}$, the matrix $A \\in \\mathbb{R}^{n \\times n}$ is tridiagonal with diagonal entries $a_{ii} = \\frac{2}{h^2} - k^2$ and off-diagonal entries $a_{i,i\\pm 1} = -\\frac{1}{h^2}$.\n\nYour tasks are:\n1. Starting from the standard splitting of a matrix for stationary iterations, write the Successive Over-Relaxation (SOR) iteration in matrix form for solving $A x = b$. Define the splitting $A = D - L - U$, where $D$ is the diagonal of $A$, $L$ is the strictly lower triangular part with appropriate sign, and $U$ is the strictly upper triangular part with appropriate sign. From this, derive the SOR iteration as a linear iteration $x^{(m+1)} = T_{\\mathrm{SOR}} x^{(m)} + c$ and identify the SOR iteration matrix $T_{\\mathrm{SOR}}$ as a function of $D$, $L$, $U$, and the relaxation parameter $\\omega$.\n2. Explain, using the eigenstructure of $A$, why increasing $k$ can lead to indefiniteness of $A$ (i.e., $A$ has both positive and negative eigenvalues). Connect this indefiniteness to the behavior of the spectral radius $\\rho(T_{\\mathrm{SOR}})$ and the convergence or divergence of the SOR iteration.\n3. Implement a program that, for each given test case, constructs $A$ as described, forms $T_{\\mathrm{SOR}}$, computes $\\rho(T_{\\mathrm{SOR}})$, and returns it as a floating-point number rounded to six decimal places. Use the definition $\\rho(M) = \\max_i |\\lambda_i(M)|$ for the spectral radius of a matrix $M$.\n\nIn your program, the smallest eigenvalue of $-\\Delta$ under Dirichlet boundary conditions on the uniform grid should be computed using the well-tested discrete formula\n$$\n\\lambda_{\\min}(-\\Delta) = \\frac{4}{h^2} \\sin^2\\left(\\frac{\\pi}{2(n+1)}\\right),\n$$\nand then set $k = \\sqrt{r \\, \\lambda_{\\min}(-\\Delta)}$ so that $k^2 = r \\, \\lambda_{\\min}(-\\Delta)$ for a prescribed ratio $r$. This choice provides controlled proximity to the indefiniteness threshold of $A$.\n\nDesign decisions:\n- Define the Successive Over-Relaxation (SOR) method (with acronym given on first use) precisely and construct the SOR iteration matrix directly from the splitting, without using shortcut formulas not justified from the splitting definition.\n- The program must compute the spectral radius numerically.\n- No physical units or angles are involved; all outputs are pure numbers.\n- Express all outputs as floats rounded to six decimal places.\n\nTest suite:\nUse the following test cases, each given as a triple $(n, \\omega, r)$:\n- Case $1$: $(n, \\omega, r) = (50, 1.2, 0.0)$.\n- Case $2$: $(n, \\omega, r) = (50, 1.2, 0.5)$.\n- Case $3$: $(n, \\omega, r) = (50, 1.2, 0.99)$.\n- Case $4$: $(n, \\omega, r) = (50, 1.2, 1.01)$.\n- Case $5$: $(n, \\omega, r) = (50, 1.2, 2.0)$.\n- Case $6$: $(n, \\omega, r) = (50, 1.8, 0.5)$.\n- Case $7$: $(n, \\omega, r) = (10, 1.2, 1.01)$.\n- Case $8$: $(n, \\omega, r) = (100, 1.2, 1.01)$.\n- Case $9$: $(n, \\omega, r) = (100, 1.0, 1.01)$.\n\nCoverage rationale:\n- Cases $1$–$3$ are the \"happy path\" where $A$ is symmetric positive definite and SOR should converge, with spectral radius less than $1$.\n- Case $4$ is just beyond the indefiniteness threshold and is expected to show $\\rho(T_{\\mathrm{SOR}})$ at or above $1$.\n- Case $5$ tests a stronger indefinite regime.\n- Case $6$ varies the relaxation parameter $\\omega$ near the upper end but still within the theoretically acceptable range for positive definite matrices.\n- Cases $7$–$9$ test size sensitivity and different $\\omega$ values under indefiniteness.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases, with each entry equal to the computed spectral radius $\\rho(T_{\\mathrm{SOR}})$ rounded to six decimal places. For example, the format must be exactly like $[x_1,x_2,\\dots,x_9]$ with each $x_i$ a decimal number to six places.",
            "solution": "The problem is valid as it is scientifically grounded in numerical linear algebra, well-posed with all necessary parameters defined, and objectively stated. It presents a standard but non-trivial exercise in computational science.\n\n### 1. Derivation of the Successive Over-Relaxation (SOR) Iteration Matrix\n\nThe goal is to solve the linear system $Ax = b$ using an iterative method. The Successive Over-Relaxation (SOR) method is a stationary iterative method derived from the splitting of the matrix $A$.\n\nThe matrix $A$ is decomposed into its diagonal, strictly lower triangular, and strictly upper triangular parts:\n$$\nA = D - L - U\n$$\nwhere $D$ is a diagonal matrix containing the diagonal entries of $A$, $L$ is a strictly lower triangular matrix containing the negative of the strictly lower triangular entries of $A$, and $U$ is a strictly upper triangular matrix containing the negative of the strictly upper triangular entries of $A$.\n\nThe system $Ax = b$ can be written as $(D - L - U)x = b$, or rearranged as $Dx = (L+U)x + b$.\n\nThe Gauss-Seidel iteration is defined by using the most recently computed components of the vector $x^{(m+1)}$ within the same iteration step $m+1$:\n$$\nD x^{(m+1)} = L x^{(m+1)} + U x^{(m)} + b\n$$\n\nThe SOR method introduces a relaxation parameter, $\\omega$, to accelerate convergence. The new iterate $x^{(m+1)}$ is a weighted average of the previous iterate $x^{(m)}$ and the current Gauss-Seidel update. For each component $x_i$, the update is:\n$$\nx_i^{(m+1)} = (1-\\omega) x_i^{(m)} + \\frac{\\omega}{a_{ii}} \\left( b_i - \\sum_{ji} a_{ij} x_j^{(m+1)} - \\sum_{ji} a_{ij} x_j^{(m)} \\right)\n$$\nTo write this in matrix form, we can rearrange the equation for the $i$-th component:\n$$\na_{ii} x_i^{(m+1)} = (1-\\omega) a_{ii} x_i^{(m)} + \\omega b_i - \\omega \\sum_{ji} a_{ij} x_j^{(m+1)} - \\omega \\sum_{ji} a_{ij} x_j^{(m)}\n$$\nMoving all terms with $x^{(m+1)}$ to the left-hand side:\n$$\na_{ii} x_i^{(m+1)} + \\omega \\sum_{ji} a_{ij} x_j^{(m+1)} = (1-\\omega) a_{ii} x_i^{(m)} - \\omega \\sum_{ji} a_{ij} x_j^{(m)} + \\omega b_i\n$$\nRecognizing the matrix components in this expression:\n- The left-hand side corresponds to the $i$-th component of $(D - \\omega L)x^{(m+1)}$.\n- The terms on the right-hand side involving $x^{(m)}$ correspond to the $i$-th component of $((1-\\omega)D + \\omega U)x^{(m)}$.\n\nThus, the full system in matrix form is:\n$$\n(D - \\omega L) x^{(m+1)} = ((1-\\omega)D + \\omega U) x^{(m)} + \\omega b\n$$\nSolving for $x^{(m+1)}$ yields the SOR iteration:\n$$\nx^{(m+1)} = (D - \\omega L)^{-1} ((1-\\omega)D + \\omega U) x^{(m)} + \\omega (D - \\omega L)^{-1} b\n$$\nThis is a linear iteration of the form $x^{(m+1)} = T_{\\mathrm{SOR}} x^{(m)} + c$, where the SOR iteration matrix $T_{\\mathrm{SOR}}$ is:\n$$\nT_{\\mathrm{SOR}} = (D - \\omega L)^{-1} ((1-\\omega)D + \\omega U)\n$$\nand the constant vector is $c = \\omega (D - \\omega L)^{-1} b$.\n\n### 2. Indefiniteness and SOR Convergence\n\nThe convergence of the SOR method is determined by the spectral radius, $\\rho(T_{\\mathrm{SOR}})$, of the iteration matrix. The method converges if and only if $\\rho(T_{\\mathrm{SOR}})  1$.\n\nThe matrix in question is $A = -\\Delta - k^2 I$, where $-\\Delta$ is the discrete negative Laplacian on a uniform grid with Dirichlet boundary conditions. The eigenvalues of $A$, denoted $\\mu_j$, are related to the eigenvalues of $-\\Delta$, denoted $\\lambda_j(-\\Delta)$, by a simple shift:\n$$\n\\mu_j = \\lambda_j(-\\Delta) - k^2\n$$\nThe eigenvalues of $-\\Delta$ are all real and positive. The smallest of these is given by the formula:\n$$\n\\lambda_{\\min}(-\\Delta) = \\frac{4}{h^2} \\sin^2\\left(\\frac{\\pi}{2(n+1)}\\right)\n$$\nA matrix is symmetric positive definite (SPD) if and only if all its eigenvalues are positive. For matrix $A$, this requires $\\mu_j > 0$ for all $j$. This condition is satisfied if and only if the smallest eigenvalue is positive:\n$$\n\\mu_{\\min} = \\lambda_{\\min}(-\\Delta) - k^2 > 0 \\implies k^2  \\lambda_{\\min}(-\\Delta)\n$$\nThe problem defines $k^2$ in terms of a ratio $r$: $k^2 = r \\cdot \\lambda_{\\min}(-\\Delta)$. Substituting this into the inequality gives:\n$$\nr \\cdot \\lambda_{\\min}(-\\Delta)  \\lambda_{\\min}(-\\Delta) \\implies r  1\n$$\nTherefore, the matrix $A$ is SPD for $r  1$. For an SPD matrix, it is a well-established theorem that the SOR method converges (i.e., $\\rho(T_{\\mathrm{SOR}})  1$) for any relaxation parameter $\\omega$ in the range $0  \\omega  2$.\n\nWhen $r \\ge 1$, the condition for positive definiteness is violated.\n- If $r = 1$, then $\\mu_{\\min} = 0$, and the matrix $A$ is singular and positive semi-definite.\n- If $r > 1$, then $\\mu_{\\min}  0$. Since the largest eigenvalue of $-\\Delta$, $\\lambda_{\\max}(-\\Delta)$, is significantly larger than $\\lambda_{\\min}(-\\Delta)$, the largest eigenvalue of $A$, $\\mu_{\\max} = \\lambda_{\\max}(-\\Delta) - k^2$, will remain positive for moderate values of $r$. Thus, for $r>1$, $A$ possesses both positive and negative eigenvalues, making it an indefinite matrix.\n\nWhen $A$ is not SPD, the convergence guarantee for SOR with $\\omega \\in (0, 2)$ is lost. The theory of SOR for indefinite matrices is substantially more complex, but in this common physical setting, transitioning from a positive definite to an indefinite matrix typically leads to the divergence of the SOR iteration. We, therefore, expect to find $\\rho(T_{\\mathrm{SOR}}) \\ge 1$ for the test cases where $r > 1$. The test suite is designed to explore this exact behavior by varying $r$ across the threshold $r=1$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by constructing the SOR iteration matrix for several\n    test cases and computing its spectral radius.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, omega, r)\n        (50, 1.2, 0.0),\n        (50, 1.2, 0.5),\n        (50, 1.2, 0.99),\n        (50, 1.2, 1.01),\n        (50, 1.2, 2.0),\n        (50, 1.8, 0.5),\n        (10, 1.2, 1.01),\n        (100, 1.2, 1.01),\n        (100, 1.0, 1.01),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, omega, r = case\n\n        # 1. Calculate grid parameters\n        h = 1.0 / (n + 1)\n\n        # 2. Calculate k^2 based on the smallest eigenvalue of the discrete Laplacian\n        lambda_min_laplacian = (4.0 / h**2) * np.sin(np.pi / (2.0 * (n + 1)))**2\n        k_squared = r * lambda_min_laplacian\n\n        # 3. Construct the matrix A for the Helmholtz-type system\n        # A = -Delta - k^2 * I\n        diag_val = (2.0 / h**2) - k_squared\n        offdiag_val = -1.0 / h**2\n        \n        A = np.diag(np.full(n, diag_val))\n        A += np.diag(np.full(n - 1, offdiag_val), k=1)\n        A += np.diag(np.full(n - 1, offdiag_val), k=-1)\n\n        # 4. Decompose A into D, L, and U for the splitting A = D - L - U\n        # D is the diagonal of A\n        D = np.diag(np.diag(A))\n        # L is the strictly lower triangular part of A, with sign flipped\n        L = -np.tril(A, k=-1)\n        # U is the strictly upper triangular part of A, with sign flipped\n        U = -np.triu(A, k=1)\n\n        # 5. Construct the SOR iteration matrix T_SOR\n        # T_SOR = inv(D - omega*L) * ((1-omega)*D + omega*U)\n        P = D - omega * L\n        Q = (1.0 - omega) * D + omega * U\n        \n        try:\n            P_inv = np.linalg.inv(P)\n            T_SOR = P_inv @ Q\n        except np.linalg.LinAlgError:\n            # This should not happen for the given test cases as D-omega*L is invertible.\n            # D is diagonal with positive entries, L is strictly lower.\n            # The determinant of a triangular matrix is the product of its diagonal elements.\n            # det(P) = det(D) != 0.\n            results.append(float('nan'))\n            continue\n\n        # 6. Compute the spectral radius of T_SOR\n        # rho(M) = max(|lambda_i(M)|)\n        eigenvalues = np.linalg.eigvals(T_SOR)\n        spectral_radius = np.max(np.abs(eigenvalues))\n        \n        results.append(spectral_radius)\n\n    # Final print statement in the exact required format.\n    # Each value must be represented as a float with 6 decimal places.\n    formatted_results = [\"{:.6f}\".format(res) for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}