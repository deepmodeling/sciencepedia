{
    "hands_on_practices": [
        {
            "introduction": "理论学习之后，最好的方式莫过于亲手实践。这个练习将引导你直接实现并比较雅可比（Jacobi）和高斯-赛德尔（Gauss-Seidel）这两种经典的迭代方法。通过对几个明确定义的线性系统进行固定次数的迭代，你将直观地感受到它们在收敛速度上的差异，并为高斯-赛德尔方法通常更快的收敛速度找到经验证据 。",
            "id": "2406968",
            "problem": "设 $A \\in \\mathbb{R}^{n \\times n}$ 分解为 $A = D + L + U$，其中 $D$ 是 $A$ 的对角部分，$L$ 是 $A$ 的严格下三角部分，$U$ 是 $A$ 的严格上三角部分。对于给定的右端项 $b \\in \\mathbb{R}^n$ 和初始迭代向量 $x^{(0)} \\in \\mathbb{R}^n$，定义 Jacobi 迭代法如下\n$$\nx^{(k+1)} = D^{-1}\\bigl(b - (L + U)x^{(k)}\\bigr),\n$$\n以及 Gauss–Seidel 迭代法如下\n$$\nx^{(k+1)} = (D + L)^{-1}\\bigl(b - U x^{(k)}\\bigr).\n$$\n对下方的每个线性系统，使用相同的初始向量 $x^{(0)} = 0$（零向量），并对每种方法精确执行 $10$ 次迭代，以获得 $x_{\\mathrm{J}}^{(10)}$ 和 $x_{\\mathrm{GS}}^{(10)}$。令 $x^\\star$ 表示 $A x = b$ 的精确解。对每个测试用例，计算以下两个量：\n1. 两个迭代结果之差的欧几里得范数，$d = \\lVert x_{\\mathrm{J}}^{(10)} - x_{\\mathrm{GS}}^{(10)} \\rVert_2$，四舍五入到六位小数。\n2. Gauss–Seidel 迭代结果在欧几里得范数下是否比 Jacobi 迭代结果更接近精确解的布尔值，即判断 $\\lVert x_{\\mathrm{GS}}^{(10)} - x^\\star \\rVert_2  \\lVert x_{\\mathrm{J}}^{(10)} - x^\\star \\rVert_2$ 是否成立。\n\n所有运算都在实数域上进行。不涉及物理单位。\n\n测试套件（每个测试用例均为一对 $\\{A, b\\}$）：\n- 测试用例 $1$ ($n=3$)：\n$$\nA = \\begin{bmatrix}\n4  -1  0\\\\\n-1  4  -1\\\\\n0  -1  3\n\\end{bmatrix},\\quad\nb = \\begin{bmatrix}\n15\\\\\n10\\\\\n10\n\\end{bmatrix}.\n$$\n- 测试用例 $2$ ($n=2$)：\n$$\nA = \\begin{bmatrix}\n1.001  1.0\\\\\n1.0  1.001\n\\end{bmatrix},\\quad\nb = \\begin{bmatrix}\n2.0\\\\\n2.0\n\\end{bmatrix}.\n$$\n- 测试用例 $3$ ($n=3$)：\n$$\nA = \\begin{bmatrix}\n5  -2  1\\\\\n1  6  -2\\\\\n0.5  -1  4\n\\end{bmatrix},\\quad\nb = \\begin{bmatrix}\n12\\\\\n-1\\\\\n3\n\\end{bmatrix}.\n$$\n- 测试用例 $4$ ($n=4$)：\n$$\nA = \\begin{bmatrix}\n2  -1  0  0\\\\\n-1  2  -1  0\\\\\n0  -1  2  -1\\\\\n0  0  -1  2\n\\end{bmatrix},\\quad\nb = \\begin{bmatrix}\n1\\\\\n0\\\\\n0\\\\\n1\n\\end{bmatrix}.\n$$\n\n最终输出格式：您的程序应生成单行输出，其中包含一个由方括号括起来的、以逗号分隔的各测试用例结果对列表。每对结果必须是一个形式为 $[d,\\ t]$ 的双元素列表，其中 $d$ 是上文定义的四舍五入后的浮点数，$t$ 是上文定义的布尔值。例如，总体格式必须为\n$$\n\\bigl[[d_1,\\ t_1],[d_2,\\ t_2],[d_3,\\ t_3],[d_4,\\ t_4]\\bigr].\n$$",
            "solution": "问题陈述经过严格审查，被认定为有效。它在数值线性代数领域具有科学依据，问题设定良好，数据充分且一致，表述客观。所提供的所有矩阵都是非奇异的（具体来说，它们是严格或不可约对角占优的），这保证了 Jacobi 和 Gauss–Seidel 方法均收敛到唯一解。任务是实现这两种迭代方法，执行指定次数的迭代，并计算明确定义的比较指标。\n\n目标是使用两种迭代方案求解线性系统 $Ax = b$：Jacobi 方法和 Gauss–Seidel 方法。对于所提供的 4 个测试用例中的每一个，我们都必须从零向量 $x^{(0)} = 0$ 的初始猜测开始，并精确执行 $k_{\\max} = 10$ 次迭代。随后，我们计算所得迭代结果之差的欧几里得范数 $d = \\lVert x_{\\mathrm{J}}^{(10)} - x_{\\mathrm{GS}}^{(10)} \\rVert_2$，并判断 Gauss–Seidel 迭代结果是否比 Jacobi 迭代结果更接近精确解 $x^\\star$，即 $\\lVert x_{\\mathrm{GS}}^{(10)} - x^\\star \\rVert_2  \\lVert x_{\\mathrm{J}}^{(10)} - x^\\star \\rVert_2$ 是否成立。\n\n这两种方法的核心在于将矩阵 $A$ 分解为其对角部分 ($D$)、严格下三角部分 ($L$) 和严格上三角部分 ($U$)，使得 $A = D + L + U$。系统 $Ax=b$ 可以重写为 $(D + L + U)x = b$。\n\n**Jacobi 方法**\n\nJacobi 迭代法通过将系统重排为 $Dx = b - (L+U)x$ 推导得出。假设 $D$ 可逆（即没有零对角元素），迭代公式为：\n$$\nx^{(k+1)} = D^{-1}\\bigl(b - (L + U)x^{(k)}\\bigr)\n$$\n这个更新规则是显式的：新迭代向量 $x^{(k+1)}$ 的每个分量都可以仅使用前一个迭代向量 $x^{(k)}$ 的分量同时计算得出。实现时将首先计算矩阵 $D^{-1}$ 和 $L+U$。然后，一个循环将运行 10 次迭代，应用上述矩阵-向量公式来更新解向量 $x_{\\mathrm{J}}$。\n\n**Gauss–Seidel 方法**\n\nGauss–Seidel 方法通过使用最新计算出的可用信息来修改更新过程。系统被重排为 $(D+L)x = b - Ux$，从而得到迭代公式：\n$$\nx^{(k+1)} = (D + L)^{-1}\\bigl(b - U x^{(k)}\\bigr)\n$$\n这等价于在每次迭代 $k$ 中，求解下三角系统 $(D + L)x^{(k+1)} = b - U x^{(k)}$ 以得到 $x^{(k+1)}$。这个系统可以使用前向替换法高效求解。实现时将计算矩阵 $D+L$ 和 $U$。在 10 次迭代的每一次中，首先计算右端向量 $v^{(k)} = b - U x_{\\mathrm{GS}}^{(k)}$。然后，求解下三角系统 $(D+L)x_{\\mathrm{GS}}^{(k+1)} = v^{(k)}$ 以找到下一个迭代向量 $x_{\\mathrm{GS}}^{(k+1)}$。这是通过使用一个专门的三角系统求解器 `scipy.linalg.solve_triangular` 来完成的。\n\n**所需量的计算**\n\n对于每个测试用例，在获得第十次迭代结果 $x_{\\mathrm{J}}^{(10)}$ 和 $x_{\\mathrm{GS}}^{(10)}$ 后，我们按以下步骤操作：\n1.  使用一个标准的高精度线性求解器，特别是 `numpy.linalg.solve(A, b)`，直接求解 $Ax=b$ 来计算精确解 $x^\\star$。\n2.  量 $d$ 计算为差向量的欧几里得范数：$d = \\lVert x_{\\mathrm{J}}^{(10)} - x_{\\mathrm{GS}}^{(10)} \\rVert_2$。结果按要求四舍五入到 6 位小数。\n3.  布尔值 $t$ 通过比较每种方法的误差向量的欧几里得范数来确定。令 $e_{\\mathrm{J}} = \\lVert x_{\\mathrm{J}}^{(10)} - x^\\star \\rVert_2$ 和 $e_{\\mathrm{GS}} = \\lVert x_{\\mathrm{GS}}^{(10)} - x^\\star \\rVert_2$。布尔值 $t$ 是比较 $e_{\\mathrm{GS}}  e_{\\mathrm{J}}$ 的结果。\n\n此过程将系统地应用于问题陈述中定义的 4 个测试用例中的每一个。最终输出将通过将每个测试用例的对 $[d, t]$ 收集到一个列表中来构建。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_triangular\n\ndef solve():\n    \"\"\"\n    Solves the given problem by implementing Jacobi and Gauss-Seidel iterations\n    for a suite of test cases and computing specified comparison metrics.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([[4, -1, 0], [-1, 4, -1], [0, -1, 3]], dtype=float),\n            np.array([15, 10, 10], dtype=float)\n        ),\n        (\n            np.array([[1.001, 1.0], [1.0, 1.001]], dtype=float),\n            np.array([2.0, 2.0], dtype=float)\n        ),\n        (\n            np.array([[5, -2, 1], [1, 6, -2], [0.5, -1, 4]], dtype=float),\n            np.array([12, -1, 3], dtype=float)\n        ),\n        (\n            np.array([[2, -1, 0, 0], [-1, 2, -1, 0], [0, -1, 2, -1], [0, 0, -1, 2]], dtype=float),\n            np.array([1, 0, 0, 1], dtype=float)\n        )\n    ]\n\n    results = []\n    num_iterations = 10\n\n    for A, b in test_cases:\n        n = A.shape[0]\n\n        # Initialize solution vectors\n        x_J = np.zeros(n, dtype=float)\n        x_GS = np.zeros(n, dtype=float)\n\n        # Decompose matrix A\n        D = np.diag(np.diag(A))\n        L = np.tril(A, k=-1)\n        U = np.triu(A, k=1)\n\n        # --- Jacobi Iteration ---\n        D_inv = np.diag(1 / np.diag(A))\n        L_plus_U = L + U\n        for _ in range(num_iterations):\n            x_J = D_inv @ (b - L_plus_U @ x_J)\n\n        # --- Gauss-Seidel Iteration ---\n        D_plus_L = D + L\n        for _ in range(num_iterations):\n            v = b - U @ x_GS\n            x_GS = solve_triangular(D_plus_L, v, lower=True)\n            \n        # --- Compute Exact Solution ---\n        x_star = np.linalg.solve(A, b)\n\n        # --- Calculate required quantities ---\n        # 1. Norm of the difference between iterates\n        d = np.linalg.norm(x_J - x_GS)\n        d_rounded = round(d, 6)\n        \n        # 2. Boolean comparison of errors\n        error_J = np.linalg.norm(x_J - x_star)\n        error_GS = np.linalg.norm(x_GS - x_star)\n        is_GS_closer = error_GS  error_J\n        \n        results.append([d_rounded, is_GS_closer])\n\n    # Final print statement in the exact required format.\n    # Format: [[d1, t1], [d2, t2], ...] with lowercase booleans\n    output_parts = []\n    for d_val, t_val in results:\n        t_str = 'true' if t_val else 'false'\n        output_parts.append(f\"[{d_val},{t_str}]\")\n    \n    print(f\"[{','.join(output_parts)}]\")\n\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了基本实现后，我们来探讨一个更深层次的问题：迭代方法的收敛性并非理所当然，它严重依赖于系统矩阵的性质。这个练习  设计了一个巧妙的思想实验，它展示了如何通过一个简单的方程重排（即行置换），将一个发散的雅可比迭代过程转变为一个收敛的过程。这揭示了对角占优性的重要性，并强调了在求解实际问题时，问题本身的构建与预处理是何等关键。",
            "id": "2406931",
            "problem": "在计算工程学中，用于求解线性系统的雅可比迭代法的收敛性取决于从系统矩阵派生出的迭代矩阵。考虑参数化线性系统族 $A(t)\\,x=b$，其中\n$$\nA(t) \\;=\\; \\begin{pmatrix}\nt  5  0\\\\\n0  t  5\\\\\n5  0  t\n\\end{pmatrix}, \n\\qquad\nb \\;=\\; \\begin{pmatrix}\n1\\\\\n1\\\\\n1\n\\end{pmatrix},\n$$\n其中 $t$ 是一个正实数参数。设行置换矩阵\n$$\nP \\;=\\; \\begin{pmatrix}\n0  0  1\\\\\n1  0  0\\\\\n0  1  0\n\\end{pmatrix}\n$$\n被应用于获得置换后的系统 $P\\,A(t)\\,x = P\\,b$。取 $t=4$。从基本原理出发，分析原始系统和置换后系统的雅可比方法，包括它们的迭代矩阵和收敛性质。\n\n计算当 $t=4$ 时，置换后系统的雅可比迭代矩阵的谱半径。将你的答案四舍五入到四位有效数字。",
            "solution": "验证问题陈述是第一步，也是最关键的一步。\n\n**步骤1：提取已知条件**\n- 一个参数化线性系统族定义为 $A(t)\\,x=b$。\n- 系统矩阵为 $A(t) = \\begin{pmatrix} t  5  0\\\\ 0  t  5\\\\ 5  0  t \\end{pmatrix}$。\n- 右侧向量为 $b = \\begin{pmatrix} 1\\\\ 1\\\\ 1 \\end{pmatrix}$。\n- 参数 $t$ 是一个正实数。\n- 给定一个行置换矩阵：$P = \\begin{pmatrix} 0  0  1\\\\ 1  0  0\\\\ 0  1  0 \\end{pmatrix}$。\n- 置换后的系统为 $P\\,A(t)\\,x = P\\,b$。\n- 具体的参数值为 $t=4$。\n- 任务是分析当 $t=4$ 时原始系统和置换后系统的雅可比方法，并计算置换后系统的雅可比迭代矩阵的谱半径。\n- 数值结果必须四舍五入到四位有效数字。\n\n**步骤2：验证结论**\n该问题具有科学依据，涉及数值线性代数中的标准主题——特别是雅可比迭代法、收敛准则以及矩阵性质（如对角占优性）的影响。这是一个适定的问题，为求得唯一解提供了所有必要的数据。语言客观且明确。因此，该问题被认为是**有效的**。\n\n接下来进行求解。\n\n雅可比方法是求解线性方程组 $M x = c$ 的一种迭代过程。矩阵 $M$ 被分解为 $M = D + L + U$，其中 $D$ 是 $M$ 的对角部分，$L$ 是 $M$ 的严格下三角部分，$U$ 是 $M$ 的严格上三角部分。迭代公式定义为：\n$$ x^{(k+1)} = -D^{-1}(L+U) x^{(k)} + D^{-1}c $$\n矩阵 $T_J = -D^{-1}(L+U)$ 是雅可比迭代矩阵。对于任意初始向量 $x^{(0)}$，迭代过程收敛的充要条件是 $T_J$ 的谱半径（记为 $\\rho(T_J)$）严格小于1。谱半径是 $T_J$ 所有特征值中绝对值的最大值。\n\n**原始系统分析**\n对于参数值 $t=4$，原始系统矩阵为：\n$$ A(4) = \\begin{pmatrix} 4  5  0\\\\ 0  4  5\\\\ 5  0  4 \\end{pmatrix} $$\n该矩阵不是严格对角占优的。例如，在第一行中，对角元素的绝对值 $|4|$ 不大于非对角元素绝对值之和 $|5| + |0| = 5$。这种非对角占优性表明雅可比方法可能不收敛。\n\n我们将 $A(4)$ 分解为其分量 $D$、$-L$ 和 $-U$（根据定义 $A = D-L-U$，所以 $L$ 和 $U$ 的符号取决于约定，此处遵循 $A = D+L_{s}+U_{s}$，$L_{s}$ 是严格下三角，$U_{s}$ 是严格上三角的约定，迭代矩阵为 $-D^{-1}(L_{s}+U_{s})$）：\n$$ D = \\begin{pmatrix} 4  0  0\\\\ 0  4  0\\\\ 0  0  4 \\end{pmatrix}, \\quad L_s = \\begin{pmatrix} 0  0  0\\\\ 0  0  0\\\\ 5  0  0 \\end{pmatrix}, \\quad U_s = \\begin{pmatrix} 0  5  0\\\\ 0  0  5\\\\ 0  0  0 \\end{pmatrix} $$\n原始系统的雅可比迭代矩阵 $T_{J,A}$ 为 $T_{J,A} = -D^{-1}(L_s+U_s)$。\n$$ T_{J,A} = -\\begin{pmatrix} \\frac{1}{4}  0  0\\\\ 0  \\frac{1}{4}  0\\\\ 0  0  \\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} 0  5  0\\\\ 0  0  5\\\\ 5  0  0 \\end{pmatrix} = \\begin{pmatrix} 0  -\\frac{5}{4}  0\\\\ 0  0  -\\frac{5}{4}\\\\ -\\frac{5}{4}  0  0 \\end{pmatrix} $$\n$T_{J,A}$ 的特征值 $\\lambda$ 可通过特征方程 $\\det(T_{J,A} - \\lambda I) = 0$ 求得：\n$$ \\det \\begin{pmatrix} -\\lambda  -\\frac{5}{4}  0\\\\ 0  -\\lambda  -\\frac{5}{4}\\\\ -\\frac{5}{4}  0  -\\lambda \\end{pmatrix} = 0 $$\n展开行列式得到：\n$$ -\\lambda^3 - \\left(\\frac{5}{4}\\right)^3 = 0 \\implies \\lambda^3 = -\\left(\\frac{5}{4}\\right)^3 $$\n每个特征值 $\\lambda$ 的模由 $|\\lambda|^3 = |-\\left(\\frac{5}{4}\\right)^3| = \\left(\\frac{5}{4}\\right)^3$ 给出，这意味着 $|\\lambda| = \\frac{5}{4}$。\n因此，谱半径为 $\\rho(T_{J,A}) = \\frac{5}{4} = 1.25$。由于 $\\rho(T_{J,A}) > 1$，原始系统的雅可比方法是发散的。\n\n**置换后系统分析**\n置换后的系统由矩阵 $A' = P A(4)$ 表征：\n$$ A' = P A(4) = \\begin{pmatrix} 0  0  1\\\\ 1  0  0\\\\ 0  1  0 \\end{pmatrix} \\begin{pmatrix} 4  5  0\\\\ 0  4  5\\\\ 5  0  4 \\end{pmatrix} = \\begin{pmatrix} 5  0  4\\\\ 4  5  0\\\\ 0  4  5 \\end{pmatrix} $$\n我们检查 $A'$ 的对角占优性。对于每一行 $i$，我们检查是否满足 $|a'_{ii}| > \\sum_{j \\neq i} |a'_{ij}|$。\n- 第1行：$|5| > |0| + |4| \\implies 5 > 4$。\n- 第2行：$|5| > |4| + |0| \\implies 5 > 4$。\n- 第3行：$|5| > |0| + |4| \\implies 5 > 4$。\n矩阵 $A'$ 是严格对角占优的。这是雅可比方法收敛的一个充分条件。我们现在计算谱半径以确认收敛并量化其收敛速率。\n\n我们将 $A'$ 分解为 $A' = D' + L'_s + U'_s$：\n$$ D' = \\begin{pmatrix} 5  0  0\\\\ 0  5  0\\\\ 0  0  5 \\end{pmatrix}, \\quad L'_s = \\begin{pmatrix} 0  0  0\\\\ 4  0  0\\\\ 0  4  0 \\end{pmatrix}, \\quad U'_s = \\begin{pmatrix} 0  0  4\\\\ 0  0  0\\\\ 0  0  0 \\end{pmatrix} $$\n置换后系统的雅可比迭代矩阵 $T_{J,A'}$ 为：\n$$ T_{J,A'} = -(D')^{-1}(L'_s+U'_s) = -\\begin{pmatrix} \\frac{1}{5}  0  0\\\\ 0  \\frac{1}{5}  0\\\\ 0  0  \\frac{1}{5} \\end{pmatrix} \\begin{pmatrix} 0  0  4\\\\ 4  0  0\\\\ 0  4  0 \\end{pmatrix} = \\begin{pmatrix} 0  0  -\\frac{4}{5}\\\\ -\\frac{4}{5}  0  0\\\\ 0  -\\frac{4}{5}  0 \\end{pmatrix} $$\n$T_{J,A'}$ 的特征值 $\\lambda'$ 是特征方程 $\\det(T_{J,A'} - \\lambda' I) = 0$ 的根：\n$$ \\det \\begin{pmatrix} -\\lambda'  0  -\\frac{4}{5}\\\\ -\\frac{4}{5}  -\\lambda'  0\\\\ 0  -\\frac{4}{5}  -\\lambda' \\end{pmatrix} = 0 $$\n展开此行列式得到：\n$$ -(\\lambda')^3 + \\left(-\\frac{4}{5}\\right) \\left(-\\frac{4}{5}\\right) \\left(-\\frac{4}{5}\\right) = 0 \\implies -(\\lambda')^3 - \\left(\\frac{4}{5}\\right)^3 = 0 \\implies (\\lambda')^3 = -\\left(\\frac{4}{5}\\right)^3 $$\n每个特征值 $\\lambda'$ 的模为 $|\\lambda'|^3 = |-\\left(\\frac{4}{5}\\right)^3| = \\left(\\frac{4}{5}\\right)^3$，这意味着 $|\\lambda'| = \\frac{4}{5}$。\n置换后系统的雅可比迭代矩阵的谱半径为 $\\rho(T_{J,A'}) = \\max_i |\\lambda'_i| = \\frac{4}{5} = 0.8$。\n由于 $\\rho(T_{J,A'})  1$，雅可比方法对置换后的系统收敛，这与严格对角占优的性质是一致的。\n\n问题要求将此谱半径的数值四舍五入到四位有效数字。\n该值为 $0.8$。表示为四位有效数字，即为 $0.8000$。",
            "answer": "$$\\boxed{0.8000}$$"
        },
        {
            "introduction": "现在，我们将这些迭代求解器应用于计算流体力学（CFD）的核心问题之一：求解拉普拉斯方程，该方程可用于模拟势流或热传导等物理现象。这个综合性练习  将抽象的线性代数方法与实际的偏微分方程（PDE）求解联系起来。你不仅会应用雅可比和高斯-赛德尔方法，还将实现一种专为并行计算设计的“红黑”着色排序高斯-赛德尔法，这是现代高性能计算中的一项关键优化技术。",
            "id": "2406990",
            "problem": "你需要使用三种方法为单位正方形上的离散二维拉普拉斯方程实现迭代求解器，并对实现进行检测，以评估用于并行化 Gauss–Seidel 方法的红黑棋盘格排序的效果。\n\n其数学基础如下。考虑在单位正方形上的拉普拉斯方程，其带有 Dirichlet 边界条件，即偏微分方程 $\\nabla^2 u(x,y) = 0$ 在 $(x,y) \\in (0,1)\\times(0,1)$ 上成立，以及在边界上给定的 $u$ 值。使用一个均匀的笛卡尔网格来离散化此方程，该网格在 $x$ 方向有 $N_x$ 个内部点，在 $y$ 方向有 $N_y$ 个内部点。网格间距为 $h_x = 1/(N_x+1)$ 和 $h_y = 1/(N_y+1)$。用整数 $i = 1,\\dots,N_y$ 和 $j = 1,\\dots,N_x$ 对内部点进行索引，并在所有边上包含一个单点厚的边界层。假设在左、右和底边上为齐次 Dirichlet 边界条件，即 $u(0,y)=0$、$u(1,y)=0$ 和 $u(x,0)=0$，并在顶边上为非齐次 Dirichlet 边界条件，由 $u(x,1)=g(x)$ 给出。函数 $g(x)$ 在下面指定；角度必须以弧度为单位解释。\n\n通过对拉普拉斯算子进行标准的二阶有限差分法离散，可以通过强制使 $\\nabla^2 u$ 的五点模板近似等于零，来得到每个内部点 $(i,j)$ 处的离散方程，这会导出一个线性系统 $A \\mathbf{u} = \\mathbf{b}$，其中 $A$ 是一个稀疏对称正定矩阵。你可以假定这个基本构造，并从中推导出你需要的任何迭代不动点更新。不要引入绕过此推导的捷径。\n\n你的任务是：\n\n- 实现应用于离散拉普拉斯方程的 Jacobi 方法。\n- 实现应用于同一方程的字典序 Gauss–Seidel 方法。\n- 实现红黑 Gauss–Seidel 方法，该方法对网格应用双色棋盘格排序。这种排序是有效的，因为每个内部点仅与其四个轴对齐的邻居耦合，从而形成一个二分图。在这种排序中，所有一种颜色的点可以同时从相反颜色的点更新，然后更新另一种颜色的点，以模拟数据并行更新。\n- 使用离散残差的无穷范数作为停止准则。在一个内部点 $(i,j)$ 处，离散残差是应用于当前近似解的五点有限差分拉普拉斯算子的值。将无穷范数计算为所有内部点上残差绝对值的最大值。当这个无穷范数小于给定容差 $tol$ 时，停止迭代方法。\n- 对每种方法，计算完整迭代的次数。对于 Jacobi 方法，一次完整迭代是一次产生新迭代值的全局扫描。对于字典序 Gauss–Seidel 方法，一次完整迭代是一次对所有内部点的扫描。对于红黑 Gauss–Seidel 方法，一次完整迭代包括一次红色扫描和一次黑色扫描。\n\n边界数据说明如下。使用 $g(x) = \\sin(\\pi x)$，其中 $x$ 以弧度为单位，因此 $g(0)=0$ 和 $g(1)=0$。这个选择确保了在角点处与左、右两侧的齐次边界值的兼容性。\n\n数值细节：\n\n- 将内部值初始化为零。\n- 始终保持边界值固定。\n- 使用如上定义的离散残差无穷范数来测试收敛性。\n- 使用最大迭代次数 $k_{\\max}$；如果在达到 $k_{\\max}$ 前未满足容差，则声明为不收敛。\n\n设计一个包含四个案例的测试套件，以检验实现的不同方面：\n\n- 案例 1（方形网格，偶数计数）：$N_x = 8$，$N_y = 8$，$tol = 10^{-6}$，$k_{\\max} = 50000$。\n- 案例 2（方形网格，奇数计数）：$N_x = 7$，$N_y = 7$，$tol = 10^{-6}$，$k_{\\max} = 50000$。\n- 案例 3（矩形网格）：$N_x = 8$，$N_y = 12$，$tol = 10^{-6}$，$k_{\\max} = 50000$。\n- 案例 4（最小内部）：$N_x = 1$，$N_y = 1$，$tol = 10^{-12}$，$k_{\\max} = 50000$。\n\n对于每个测试案例，你的程序必须计算以下四个值：\n\n- Jacobi 方法满足容差所需的整数迭代次数，如果在此限制内不收敛则为 $k_{\\max}$。\n- 红黑 Gauss–Seidel 方法满足容差所需的整数迭代次数，如果在此限制内不收敛则为 $k_{\\max}$。\n- 字典序 Gauss–Seidel 方法满足容差所需的整数迭代次数，如果在此限制内不收敛则为 $k_{\\max}$。\n- 一个布尔值，指示收敛的红黑 Gauss–Seidel 解与收敛的字典序 Gauss–Seidel 解之差的无穷范数是否小于 $10^{-10}$。\n\n最终输出格式：\n\n- 你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。该列表应包含四个子列表，每个测试案例一个，按案例 1 到 4 的顺序排列。每个子列表必须为 $[n_J, n_{RBGS}, n_{GS}, ok]$ 的形式，其中 $n_J$、$n_{RBGS}$ 和 $n_{GS}$ 是整数，而 $ok$ 是布尔值。例如：$[[12,8,7,true],[...],...]$。\n\n角度必须以弧度为单位。此问题不需要物理单位。你的推导和实现中的所有数值都应作为实数处理。",
            "solution": "所提出的问题是一个有效、适定的计算工程练习。它要求实现并比较三种经典迭代方法，用于求解由二维拉普拉斯方程的有限差分法离散化所产生的线性系统。问题陈述在科学上是合理的、内容是完整的且客观的。我将继续进行推导和求解。\n\n控制偏微分方程是单位正方形上的拉普拉斯方程：\n$$ \\nabla^2 u(x,y) = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} = 0 \\quad \\text{for} \\quad (x,y) \\in (0,1) \\times (0,1) $$\n带有指定的狄利克雷边界条件：\n$$ u(x,0) = 0, \\quad u(x,1) = g(x) = \\sin(\\pi x), \\quad u(0,y) = 0, \\quad u(1,y) = 0 $$\n该域使用均匀笛卡尔网格进行离散化，在 $x$ 方向有 $N_x$ 个内部点，在 $y$ 方向有 $N_y$ 个内部点。网格间距为 $h_x = 1/(N_x+1)$ 和 $h_y = 1/(N_y+1)$。解 $u(x,y)$ 在网格点 $(x_j, y_i)$ 处由离散值 $u_{i,j}$ 近似，其中 $x_j = j h_x$ 和 $y_i = i h_y$。内部点的索引为 $i \\in \\{1, \\dots, N_y\\}$ 和 $j \\in \\{1, \\dots, N_x\\}$。完整网格包括边界点，其索引为 $i \\in \\{0, \\dots, N_y+1\\}$ 和 $j \\in \\{0, \\dots, N_x+1\\}$。\n\n二阶偏导数使用中心有限差分进行近似：\n$$ \\frac{\\partial^2 u}{\\partial x^2}\\bigg|_{(i,j)} \\approx \\frac{u_{i,j-1} - 2u_{i,j} + u_{i,j+1}}{h_x^2} $$\n$$ \\frac{\\partial^2 u}{\\partial y^2}\\bigg|_{(i,j)} \\approx \\frac{u_{i-1,j} - 2u_{i,j} + u_{i+1,j}}{h_y^2} $$\n将这些代入拉普拉斯方程，得到每个内部网格点 $(i,j)$ 的五点模板方程：\n$$ \\frac{u_{i,j-1} - 2u_{i,j} + u_{i,j+1}}{h_x^2} + \\frac{u_{i-1,j} - 2u_{i,j} + u_{i+1,j}}{h_y^2} = 0 $$\n为了形成不动点迭代，我们求解 $u_{i,j}$：\n$$ 2 \\left( \\frac{1}{h_x^2} + \\frac{1}{h_y^2} \\right) u_{i,j} = \\frac{u_{i,j-1} + u_{i,j+1}}{h_x^2} + \\frac{u_{i-1,j} + u_{i+1,j}}{h_y^2} $$\n这可以重新排列成迭代更新形式：\n$$ u_{i,j} = C_x (u_{i,j-1} + u_{i,j+1}) + C_y (u_{i-1,j} + u_{i+1,j}) $$\n其中系数定义为：\n$$ C_x = \\frac{h_y^2}{2(h_x^2 + h_y^2)} \\quad \\text{and} \\quad C_y = \\frac{h_x^2}{2(h_x^2 + h_y^2)} $$\n这个单一的更新公式是所有三种所需迭代方法的基础。\n\n设 $U^{(k)}$ 为第 $k$ 次迭代时的解值矩阵。\n\n1.  **雅可比方法**：雅可比方法完全基于当前状态 $U^{(k)}$ 中的值来计算所有内部点的下一个状态 $U^{(k+1)}$。需要一个网格的临时副本。\n    $$ u_{i,j}^{(k+1)} = C_x (u_{i,j-1}^{(k)} + u_{i,j+1}^{(k)}) + C_y (u_{i-1,j}^{(k)} + u_{i+1,j}^{(k)}) $$\n\n2.  **字典序高斯-赛德尔方法**：此方法就地更新网格值，使用同一次迭代中最新计算出的值。“字典序”排序指的是顺序扫描，例如，逐行然后逐列。对于 $i$ 和 $j$ 递增的扫描：\n    $$ u_{i,j}^{(k+1)} = C_x (u_{i,j-1}^{(k+1)} + u_{i,j+1}^{(k)}) + C_y (u_{i-1,j}^{(k+1)} + u_{i+1,j}^{(k)}) $$\n\n3.  **红黑高斯-赛德尔方法**：此方法将网格点划分为“红色”和“黑色”两个集合，类似于棋盘格模式。如果 $i+j$ 是偶数，则点 $(i,j)$ 为红色；如果 $i+j$ 是奇数，则为黑色。五点模板确保了红色点的所有邻居都是黑色的，反之亦然。一次迭代包括两个阶段：\n    a.  **红色扫描**：更新所有红色点。由于它们的更新仅依赖于黑色点，因此可以使用迭代开始时的值同时计算所有红色点。\n    b.  **黑色扫描**：更新所有黑色点。它们的更新使用其红色邻居新计算出的值。所有黑色点都可以同时计算。\n    这种结构特别适合并行化。一次完整迭代包括一次红色扫描和一次黑色扫描。\n\n停止准则基于离散残差向量的无穷范数 $\\|r\\|_\\infty$。在内部点 $(i,j)$ 处的残差 $r_{i,j}$ 是对当前近似解 $\\tilde{U}$ 应用离散拉普拉斯算子的结果：\n$$ r_{i,j} = \\frac{\\tilde{u}_{i,j-1} - 2\\tilde{u}_{i,j} + \\tilde{u}_{i,j+1}}{h_x^2} + \\frac{\\tilde{u}_{i-1,j} - 2\\tilde{u}_{i,j} + \\tilde{u}_{i+1,j}}{h_y^2} $$\n当 $\\max_{i,j} |r_{i,j}|  tol$（对于给定的容差 $tol$）时，或者当迭代次数达到最大限制 $k_{\\max}$ 时，迭代终止。\n\n数值实现过程如下：\n对于由 $N_x$、$N_y$、$tol$ 和 $k_{\\max}$ 定义的每个测试案例：\n1.  一个 $(N_y+2) \\times (N_x+2)$ 的网格被初始化为 $0$。\n2.  设置狄利克雷边界条件。在 $i=N_y+1$ 处的顶边界 $u(x,1)$ 用值 $g(x_j) = \\sin(\\pi x_j)$ 填充，其中 $j \\in \\{1, \\dots, N_x\\}$。其他边界为 $0$。\n3.  从零初始化的内部网格开始，执行三种迭代求解器中的每一种。\n4.  每个求解器循环执行，进行更新并检查残差范数，直到达到收敛或达到 $k_{\\max}$。记录迭代次数。\n5.  在高斯-赛德尔的变体收敛后，计算它们最终解网格之间差值的无穷范数 $\\|U_{\\text{RBGS}} - U_{\\text{GS}}\\|_\\infty$，并与阈值 $10^{-10}$ 进行比较，以验证它们产生一致的结果。\n然后将四个指定测试案例的结果汇总成所需的输出格式。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef setup_grid(Nx, Ny):\n    \"\"\"\n    Initializes the grid and applies boundary conditions.\n    Uses 'standard' indexing where grid row i corresponds to y-coordinate.\n    i=0 is bottom (y=0), i=Ny+1 is top (y=1).\n    \"\"\"\n    U = np.zeros((Ny + 2, Nx + 2))\n    hx = 1.0 / (Nx + 1)\n    \n    # Left, right, bottom boundaries are already zero.\n    \n    # Top boundary: u(x,1) = g(x) = sin(pi*x)\n    # This corresponds to row index Ny+1\n    x = np.linspace(0, 1, Nx + 2)\n    g = np.sin(np.pi * x)\n    U[Ny + 1, :] = g\n    return U\n\ndef calculate_residual_norm(U, hx, hy):\n    \"\"\"Calculates the infinity norm of the discrete residual.\"\"\"\n    Nx = U.shape[1] - 2\n    Ny = U.shape[0] - 2\n    if Nx == 0 or Ny == 0:\n        return 0.0\n    \n    # Slices for interior and neighbor points\n    U_int = U[1:-1, 1:-1]\n    U_left = U[1:-1, :-2]\n    U_right = U[1:-1, 2:]\n    U_down = U[:-2, 1:-1]\n    U_up = U[2:, 1:-1]\n    \n    # Discrete Laplacian operator\n    res_grid = (U_left - 2 * U_int + U_right) / (hx**2) + \\\n               (U_down - 2 * U_int + U_up) / (hy**2)\n               \n    return np.max(np.abs(res_grid))\n\ndef jacobi_solver(Nx, Ny, tol, k_max):\n    \"\"\"Solves the Laplace equation using the Jacobi method.\"\"\"\n    hx = 1.0 / (Nx + 1)\n    hy = 1.0 / (Ny + 1)\n    U = setup_grid(Nx, Ny)\n    U_old = U.copy()\n\n    Cx = hy**2 / (2 * (hx**2 + hy**2))\n    Cy = hx**2 / (2 * (hx**2 + hy**2))\n\n    for k in range(1, k_max + 1):\n        U_old[1:-1, 1:-1] = U[1:-1, 1:-1]\n\n        # Vectorized update using values from U_old\n        U[1:-1, 1:-1] = Cx * (U_old[1:-1, :-2] + U_old[1:-1, 2:]) + \\\n                        Cy * (U_old[:-2, 1:-1] + U_old[2:, 1:-1])\n\n        residual_norm = calculate_residual_norm(U, hx, hy)\n        if residual_norm  tol:\n            return k, U\n    return k_max, U\n\ndef gs_solver(Nx, Ny, tol, k_max):\n    \"\"\"Solves the Laplace equation using the lexicographic Gauss-Seidel method.\"\"\"\n    hx = 1.0 / (Nx + 1)\n    hy = 1.0 / (Ny + 1)\n    U = setup_grid(Nx, Ny)\n\n    Cx = hy**2 / (2 * (hx**2 + hy**2))\n    Cy = hx**2 / (2 * (hx**2 + hy**2))\n\n    for k in range(1, k_max + 1):\n        # In-place update with lexicographic sweep\n        for i in range(1, Ny + 1):\n            for j in range(1, Nx + 1):\n                U[i, j] = Cx * (U[i, j-1] + U[i, j+1]) + \\\n                          Cy * (U[i-1, j] + U[i+1, j])\n\n        residual_norm = calculate_residual_norm(U, hx, hy)\n        if residual_norm  tol:\n            return k, U\n    return k_max, U\n\ndef rbgs_solver(Nx, Ny, tol, k_max):\n    \"\"\"Solves the Laplace equation using the red-black Gauss-Seidel method.\"\"\"\n    hx = 1.0 / (Nx + 1)\n    hy = 1.0 / (Ny + 1)\n    U = setup_grid(Nx, Ny)\n\n    Cx = hy**2 / (2 * (hx**2 + hy**2))\n    Cy = hx**2 / (2 * (hx**2 + hy**2))\n    \n    for k in range(1, k_max + 1):\n        # A full iteration consists of one red sweep and one black sweep.\n        # Red sweep: update points where (i+j) is even\n        for i in range(1, Ny + 1):\n            for j in range(1, Nx + 1):\n                if (i + j) % 2 == 0:\n                    U[i, j] = Cx * (U[i, j-1] + U[i, j+1]) + \\\n                              Cy * (U[i-1, j] + U[i+1, j])\n        # Black sweep: update points where (i+j) is odd\n        for i in range(1, Ny + 1):\n            for j in range(1, Nx + 1):\n                if (i + j) % 2 != 0:\n                    U[i, j] = Cx * (U[i, j-1] + U[i, j+1]) + \\\n                              Cy * (U[i-1, j] + U[i+1, j])\n\n        residual_norm = calculate_residual_norm(U, hx, hy)\n        if residual_norm  tol:\n            return k, U\n    return k_max, U\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (Nx, Ny, tol, k_max)\n        (8, 8, 1e-6, 50000),\n        (7, 7, 1e-6, 50000),\n        (8, 12, 1e-6, 50000),\n        (1, 1, 1e-12, 50000),\n    ]\n\n    results = []\n    for case in test_cases:\n        Nx, Ny, tol, k_max = case\n        \n        n_J, U_J = jacobi_solver(Nx, Ny, tol, k_max)\n        n_RBGS, U_RBGS = rbgs_solver(Nx, Ny, tol, k_max)\n        n_GS, U_GS = gs_solver(Nx, Ny, tol, k_max)\n        \n        # Check if the solutions from GS and RBGS are close\n        diff_norm = np.max(np.abs(U_RBGS - U_GS))\n        ok = bool(diff_norm  1e-10)\n        \n        results.append([n_J, n_RBGS, n_GS, ok])\n\n    # Final print statement in the exact required format.\n    output_parts = []\n    for res in results:\n        ok_str = 'true' if res[3] else 'false'\n        output_parts.append(f\"[{res[0]},{res[1]},{res[2]},{ok_str}]\")\n    print(f\"[{','.join(output_parts)}]\")\n\n\nsolve()\n```"
        }
    ]
}