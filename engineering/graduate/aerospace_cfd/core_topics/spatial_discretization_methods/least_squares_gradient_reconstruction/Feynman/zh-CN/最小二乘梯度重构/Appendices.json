{
    "hands_on_practices": [
        {
            "introduction": "在数值方法中，“补丁测试”(patch test)是一项基本且至关重要的验证步骤。本练习将指导您实现一个补丁测试，以确保您的最小二乘梯度重构代码能够精确地再现线性标量场，这是保证计算精度的必要条件。通过这个过程，您还将学会如何诊断由邻域单元几何布局不当引起的秩亏问题 ()。",
            "id": "3972768",
            "problem": "您的任务是在航空航天计算流体力学 (Aerospace CFD) 的背景下，为仿射标量场设计并实现一个最小二乘梯度重构的网格片检验。其目的是验证当几何采样足够丰富时，该重构方法在一个以单元为中心的网格片上能够精确再现仿射场的梯度，并能诊断出由秩亏或实现错误导致的失效。该检验必须完全以纯数学术语构建和执行，不涉及任何物理单位。\n\n背景与基本原理：一个在 $d$ 维空间中的仿射标量场定义为 $u(\\mathbf{x}) = \\alpha + \\mathbf{g}^{\\top} \\mathbf{x}$，其中 $\\alpha \\in \\mathbb{R}$ 和 $\\mathbf{g} \\in \\mathbb{R}^{d}$ 是常系数，$\\mathbf{x} \\in \\mathbb{R}^{d}$ 表示空间坐标。对于一个中心点 $\\mathbf{x}_{0}$，精确的仿射关系意味着对于任意邻近点 $\\mathbf{x}_{j}$，都有 $u(\\mathbf{x}_{j}) - u(\\mathbf{x}_{0}) = \\mathbf{g}^{\\top} (\\mathbf{x}_{j} - \\mathbf{x}_{0})$。在一个邻近点数量多于未知梯度分量数量的一般网格片中，可以通过最小化差值与其线性预测值之间的加权残差平方和来确定 $\\mathbf{g}$，从而在满秩采样的条件下确保无偏重构。\n\n任务：编写一个完整的程序，对下述的每个测试用例执行以下步骤：\n1. 根据提供的仿射场和几何信息，构建设计偏移量 $\\Delta \\mathbf{x}_{j} = \\mathbf{x}_{j} - \\mathbf{x}_{0}$ 和响应差 $\\Delta u_{j} = u(\\mathbf{x}_{j}) - u(\\mathbf{x}_{0})$。\n2. 建立并求解加权最小二乘问题，该问题旨在使用一种数值稳定的线性代数方法，在 $\\mathbf{g} \\in \\mathbb{R}^{d}$ 上最小化目标函数 $\\sum_{j=1}^{m} w_{j} \\left(\\mathbf{g}^{\\top} \\Delta \\mathbf{x}_{j} - \\Delta u_{j}\\right)^{2}$。不要先验地假设任何专用公式；该方法必须从最小二乘最小化原理推导得出。\n3. 使用奇异值分解和相对容差 $r_{\\mathrm{tol}} = 10^{-12}$ 来确定加权设计矩阵的数值秩。如果数值秩严格小于 $d$，则就该测试用例而言，声明系统为秩亏。\n4. 计算重构梯度 $\\mathbf{g}_{\\mathrm{rec}}$ 与真实梯度 $\\mathbf{g}_{\\mathrm{true}}$ 之间的欧几里得误差范数 $\\lVert \\mathbf{g}_{\\mathrm{rec}} - \\mathbf{g}_{\\mathrm{true}} \\rVert_{2}$。\n5. 按照下文指定的格式，生成一个单行输出，汇总所有测试用例的结果。\n\n科学真实性要求：对于一个精确的仿射场和一个列满秩的网格片，在精确算术中，重构必须产生零误差；在浮点算术中，必须产生一个由舍入误差界定的接近零的误差。未能达到接近零的误差表明存在秩亏或实现错误。\n\n本问题不涉及角度单位。不涉及任何物理单位；所有量均为无量纲。\n\n测试套件：实现以下五个测试用例。在每个用例中，$d$ 表示空间维度，$\\mathbf{x}_{0}$ 是中心点，列出了邻近点的坐标，提供了仿射场系数 $(\\alpha, \\mathbf{g}_{\\mathrm{true}})$ 使得 $u(\\mathbf{x}) = \\alpha + \\mathbf{g}_{\\mathrm{true}}^{\\top} \\mathbf{x}$，并指定了正权重 $w_{j}$。所有点和系数都是精确的实数。\n\n- 用例 $1$ (正常路径, $2$-D, 均匀权重): $d = 2$, $\\mathbf{x}_{0} = (0, 0)$, 邻近点 $\\{(1, 0), (0, 1), (-1, 0), (0, -1), (1, 1)\\}$, 仿射场系数 $\\alpha = 2$, $\\mathbf{g}_{\\mathrm{true}} = (3, -4)$, 权重 $w_{j} = 1$ 对所有 $j$。\n- 用例 $2$ (秩亏几何, $2$-D, 共线邻近点): $d = 2$, $\\mathbf{x}_{0} = (0, 0)$, 邻近点 $\\{(1, 0), (2, 0), (-1, 0)\\}$, 仿射场系数 $\\alpha = 2$, $\\mathbf{g}_{\\mathrm{true}} = (3, -4)$, 权重 $w_{j} = 1$ 对所有 $j$。\n- 用例 $3$ (正常路径, $3$-D, 均匀权重): $d = 3$, $\\mathbf{x}_{0} = (0, 0, 0)$, 邻近点 $\\{(1, 0, 0), (0, 1, 0), (0, 0, 1), (-1, 1, 1)\\}$, 仿射场系数 $\\alpha = -1$, $\\mathbf{g}_{\\mathrm{true}} = (0.5, 1.5, -2)$, 权重 $w_{j} = 1$ 对所有 $j$。\n- 用例 $4$ (近奇异几何, $2$-D, 均匀权重): $d = 2$, $\\mathbf{x}_{0} = (0, 0)$, 邻近点 $\\{(1, 0), (2, 10^{-8}), (-1, -10^{-8})\\}$, 仿射场系数 $\\alpha = 2$, $\\mathbf{g}_{\\mathrm{true}} = (3, -4)$, 权重 $w_{j} = 1$ 对所有 $j$。\n- 用例 $5$ (正常路径, $2$-D, 非均匀正权重): $d = 2$, $\\mathbf{x}_{0} = (0, 0)$, 邻近点 $\\{(1, 0), (0, 1), (-1, 0), (0, -1), (1, 1)\\}$, 仿射场系数 $\\alpha = 2$, $\\mathbf{g}_{\\mathrm{true}} = (3, -4)$, 权重 $(1, 2, 3, 4, 5)$ 与邻近点顺序匹配。\n\n数值秩检测：令 $\\sigma_{\\max}$ 和 $\\sigma_{\\min}$ 分别表示加权设计矩阵的最大和最小奇异值。将数值秩计算为满足 $\\sigma \\ge r_{\\mathrm{tol}} \\, \\sigma_{\\max}$（其中 $r_{\\mathrm{tol}} = 10^{-12}$）的奇异值 $\\sigma$ 的数量。如果此数值秩小于 $d$，则声明为秩亏。\n\n最终输出规范：对于按顺序从 1 到 5 的每个测试用例，向输出列表中追加两项：首先是浮点误差范数 $\\lVert \\mathbf{g}_{\\mathrm{rec}} - \\mathbf{g}_{\\mathrm{true}} \\rVert_{2}$，然后是一个指示秩亏的布尔值（使用语言原生的布尔值表示 true 和 false）。您的程序应生成一行输出，其中包含结果，格式为方括号括起来的逗号分隔列表，例如 $[e_{1},b_{1},e_{2},b_{2},\\dots,e_{5},b_{5}]$，其中 $e_{k}$ 是一个浮点值，$b_{k}$ 是一个布尔值。不允许有其他任何输出。",
            "solution": "该问题旨在为最小二乘梯度重构算法创建一个网格片检验。这涉及到验证对于给定的仿射标量场，只要采样点的几何排列是充分的，该算法就能精确地重构场的梯度。该任务要求从第一性原理推导解法，进行数值实现，并诊断秩亏的情况。\n\n一个在 $d$ 维空间 $\\mathbb{R}^d$ 中的仿射标量场由以下函数给出：\n$$\nu(\\mathbf{x}) = \\alpha + \\mathbf{g}_{\\mathrm{true}}^{\\top} \\mathbf{x}\n$$\n其中 $\\alpha \\in \\mathbb{R}$ 是一个标量偏移，$\\mathbf{g}_{\\mathrm{true}} \\in \\mathbb{R}^d$ 是恒定的真实梯度向量，$\\mathbf{x} \\in \\mathbb{R}^d$ 是位置向量。\n\n对于一个中心点 $\\mathbf{x}_{0}$ 和一组 $m$ 个邻近点 $\\{\\mathbf{x}_{j}\\}_{j=1}^{m}$，标量场值的差异与位置的差异呈线性关系：\n$$\n\\Delta u_{j} = u(\\mathbf{x}_{j}) - u(\\mathbf{x}_{0}) = (\\alpha + \\mathbf{g}_{\\mathrm{true}}^{\\top} \\mathbf{x}_{j}) - (\\alpha + \\mathbf{g}_{\\mathrm{true}}^{\\top} \\mathbf{x}_{0}) = \\mathbf{g}_{\\mathrm{true}}^{\\top} (\\mathbf{x}_{j} - \\mathbf{x}_{0})\n$$\n令 $\\Delta \\mathbf{x}_{j} = \\mathbf{x}_{j} - \\mathbf{x}_{0}$。该关系式为 $\\Delta u_{j} = \\mathbf{g}_{\\mathrm{true}}^{\\top} \\Delta \\mathbf{x}_{j}$。\n\n目标是仅使用 $\\Delta u_{j}$ 和 $\\Delta \\mathbf{x}_{j}$ 的已知值来重构梯度的近似值 $\\mathbf{g}_{\\mathrm{rec}}$。这被构建为一个加权最小二乘问题，我们寻求能使加权残差平方和最小化的向量 $\\mathbf{g}$：\n$$\nJ(\\mathbf{g}) = \\sum_{j=1}^{m} w_{j} \\left( (\\Delta \\mathbf{x}_{j})^{\\top} \\mathbf{g} - \\Delta u_{j} \\right)^{2}\n$$\n此处，$w_{j} > 0$ 是为每个邻近点 $j$ 给定的权重。\n\n为了解决这个最小化问题，我们首先用矩阵表示法来表达它。令 $A$ 为 $m \\times d$ 的设计矩阵，其中第 $j$ 行为 $(\\Delta \\mathbf{x}_{j})^{\\top}$。令 $\\mathbf{b}$ 为 $m \\times 1$ 的响应向量，其中第 $j$ 个元素为 $\\Delta u_{j}$。对于所有邻近点的方程组理想情况下是 $A\\mathbf{g} = \\mathbf{b}$。目标函数可以写成一个加权残差向量的平方范数。令 $W$ 为一个 $m \\times m$ 的对角矩阵，其对角线元素为 $W_{jj} = \\sqrt{w_j}$。目标函数为：\n$$\nJ(\\mathbf{g}) = \\| W(A\\mathbf{g} - \\mathbf{b}) \\|_2^2\n$$\n令 $\\tilde{A} = WA$ 和 $\\tilde{\\mathbf{b}} = W\\mathbf{b}$。问题转化为最小化 $J(\\mathbf{g}) = \\| \\tilde{A}\\mathbf{g} - \\tilde{\\mathbf{b}} \\|_2^2$。\n我们展开平方范数：\n$$\nJ(\\mathbf{g}) = (\\tilde{A}\\mathbf{g} - \\tilde{\\mathbf{b}})^{\\top}(\\tilde{A}\\mathbf{g} - \\tilde{\\mathbf{b}}) = \\mathbf{g}^{\\top}\\tilde{A}^{\\top}\\tilde{A}\\mathbf{g} - 2\\mathbf{g}^{\\top}\\tilde{A}^{\\top}\\tilde{\\mathbf{b}} + \\tilde{\\mathbf{b}}^{\\top}\\tilde{\\mathbf{b}}\n$$\n为求最小值，我们求 $J(\\mathbf{g})$ 关于 $\\mathbf{g}$ 的梯度，并令其为零向量：\n$$\n\\nabla_{\\mathbf{g}} J(\\mathbf{g}) = 2\\tilde{A}^{\\top}\\tilde{A}\\mathbf{g} - 2\\tilde{A}^{\\top}\\tilde{\\mathbf{b}} = \\mathbf{0}\n$$\n这就得到了加权最小二乘问题的正规方程组：\n$$\n(\\tilde{A}^{\\top}\\tilde{A})\\mathbf{g} = \\tilde{A}^{\\top}\\tilde{\\mathbf{b}}\n$$\n如果矩阵 $\\tilde{A}^{\\top}\\tilde{A}$ 是可逆的（即，如果 $\\tilde{A}$ 是列满秩的），则重构梯度 $\\mathbf{g}_{\\mathrm{rec}}$ 存在唯一解。由于 $W$ 是可逆的，$\\tilde{A} = WA$ 的秩与 $A$ 的秩相同。因此，当且仅当位移向量集合 $\\{\\Delta \\mathbf{x}_{j}\\}$ 能张成 $\\mathbb{R}^d$ 时，唯一解存在。\n\n如果 $\\tilde{A}$ 是病态的，直接求解正规方程组可能数值不稳定。一种更稳健的方法是使用加权设计矩阵 $\\tilde{A}$ 的奇异值分解（SVD）。设 $\\tilde{A}$ 的 SVD 为 $\\tilde{A} = U\\Sigma V^{\\top}$，其中 $U$ 是一个 $m \\times m$ 的正交矩阵，$\\Sigma$ 是一个包含奇异值 $\\sigma_i$ 的 $m \\times d$ 对角矩阵，$V$ 是一个 $d \\times d$ 的正交矩阵。最小二乘解由下式给出：\n$$\n\\mathbf{g}_{\\mathrm{rec}} = V \\Sigma^{+} U^{\\top} \\tilde{\\mathbf{b}}\n$$\n其中 $\\Sigma^{+}$ 是 $\\Sigma$ 的 Moore-Penrose 伪逆。即使对于病态或秩亏的系统，这种方法在数值上也是稳定的。\n\n$\\tilde{A}$ 的数值秩由其奇异值确定。给定相对容差 $r_{\\mathrm{tol}} = 10^{-12}$，秩是满足 $\\sigma_i \\geq r_{\\mathrm{tol}} \\sigma_{\\max}$ 的奇异值 $\\sigma_i$ 的数量，其中 $\\sigma_{\\max}$ 是最大的奇异值。如果此数值秩小于空间维度 $d$，则系统被声明为秩亏。对于此类系统，几何采样不足以唯一确定梯度的所有分量。\n\n实现将通过遍历五个测试用例来进行。对于每个用例：\n1.  构建位移向量 $\\Delta \\mathbf{x}_{j}$ 和标量差 $\\Delta u_j = \\mathbf{g}_{\\mathrm{true}}^{\\top} \\Delta \\mathbf{x}_j$。\n2.  构成设计矩阵 $A$、响应向量 $\\mathbf{b}$ 和权重矩阵 $W$。\n3.  计算加权矩阵 $\\tilde{A} = WA$ 和加权向量 $\\tilde{\\mathbf{b}} = W\\mathbf{b}$。\n4.  计算 $\\tilde{A}$ 的 SVD 以确定其奇异值和数值秩。如果秩小于 $d$，则设置一个布尔标志。\n5.  使用一个内部采用 SVD 的稳定最小二乘求解器，通过求解 $\\tilde{A}\\mathbf{g} = \\tilde{\\mathbf{b}}$ 来找到 $\\mathbf{g}_{\\mathrm{rec}}$。\n6.  计算欧几里得误差范数 $\\|\\mathbf{g}_{\\mathrm{rec}} - \\mathbf{g}_{\\mathrm{true}}\\|_2$。\n\n对于满秩的测试用例，由于响应数据 $\\Delta u_j$ 是从仿射场精确推导出来的，重构梯度 $\\mathbf{g}_{\\mathrm{rec}}$ 应在浮点精度范围内等于 $\\mathbf{g}_{\\mathrm{true}}$。对于秩亏的情况，重构将无法恢复 $\\mathbf{g}_{\\mathrm{true}}$，从而导致一个非零误差。对于近奇异的情况，系统技术上是满秩的，但数值舍入误差可能会被放大，导致一个虽小但非零的重构误差。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to execute the least-squares gradient reconstruction patch test\n    for all specified test cases.\n    \"\"\"\n    # Define the test cases as a list of dictionaries.\n    test_cases = [\n        {\n            \"d\": 2, \"x0\": np.array([0., 0.]),\n            \"neighbors\": np.array([[1., 0.], [0., 1.], [-1., 0.], [0., -1.], [1., 1.]]),\n            \"alpha\": 2., \"g_true\": np.array([3., -4.]),\n            \"weights\": np.array([1., 1., 1., 1., 1.])\n        },\n        {\n            \"d\": 2, \"x0\": np.array([0., 0.]),\n            \"neighbors\": np.array([[1., 0.], [2., 0.], [-1., 0.]]),\n            \"alpha\": 2., \"g_true\": np.array([3., -4.]),\n            \"weights\": np.array([1., 1., 1.])\n        },\n        {\n            \"d\": 3, \"x0\": np.array([0., 0., 0.]),\n            \"neighbors\": np.array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.], [-1., 1., 1.]]),\n            \"alpha\": -1., \"g_true\": np.array([0.5, 1.5, -2.]),\n            \"weights\": np.array([1., 1., 1., 1.])\n        },\n        {\n            \"d\": 2, \"x0\": np.array([0., 0.]),\n            \"neighbors\": np.array([[1., 0.], [2., 1e-8], [-1., -1e-8]]),\n            \"alpha\": 2., \"g_true\": np.array([3., -4.]),\n            \"weights\": np.array([1., 1., 1.])\n        },\n        {\n            \"d\": 2, \"x0\": np.array([0., 0.]),\n            \"neighbors\": np.array([[1., 0.], [0., 1.], [-1., 0.], [0., -1.], [1., 1.]]),\n            \"alpha\": 2., \"g_true\": np.array([3., -4.]),\n            \"weights\": np.array([1., 2., 3., 4., 5.])\n        }\n    ]\n\n    r_tol = 1e-12\n    results = []\n\n    for case in test_cases:\n        d = case[\"d\"]\n        x0 = case[\"x0\"]\n        neighbors = case[\"neighbors\"]\n        g_true = case[\"g_true\"]\n        weights = case[\"weights\"]\n        # alpha is not needed for gradient reconstruction, as it cancels out.\n        # u(x) = alpha + g_true.T @ x\n\n        # 1. Construct design offsets and response differences.\n        # delta_x_j = x_j - x_0\n        # A is the design matrix, with rows being delta_x_j.T\n        A = neighbors - x0\n        \n        # delta_u_j = u(x_j) - u(x_0) = g_true.T @ (x_j - x_0)\n        # b is the response vector with elements delta_u_j\n        b = A @ g_true\n\n        # 2. Formulate the weighted least-squares problem.\n        # Create diagonal weight matrix W with sqrt(w_j) on diagonal\n        W = np.diag(np.sqrt(weights))\n        \n        # Weighted design matrix and response vector\n        A_tilde = W @ A\n        b_tilde = W @ b\n\n        # 3. Determine the numerical rank of the weighted design matrix.\n        # Compute singular values of A_tilde\n        try:\n            singular_values = np.linalg.svd(A_tilde, compute_uv=False)\n            s_max = singular_values[0] if len(singular_values) > 0 else 0\n            \n            # Compute numerical rank based on the tolerance\n            numerical_rank = np.sum(singular_values >= r_tol * s_max)\n            is_rank_deficient = numerical_rank  d\n        except np.linalg.LinAlgError:\n            # In an empty or otherwise invalid case\n            numerical_rank = 0\n            is_rank_deficient = True\n            \n        # 4. Solve for the reconstructed gradient and compute the error.\n        # Use a numerically stable least-squares solver\n        g_rec, _, _, _ = np.linalg.lstsq(A_tilde, b_tilde, rcond=None)\n        \n        # Compute the Euclidean error norm\n        error_norm = np.linalg.norm(g_rec - g_true)\n        \n        # 5. Append results for this case to the list.\n        results.append(error_norm)\n        results.append(is_rank_deficient)\n\n    # Final print statement in the exact required format.\n    # str(True) -> 'True', str(False) -> 'False'\n    # The problem asks for \"language-native boolean values\", which these are.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在通过补丁测试验证了代码的基本正确性后，下一个自然的步骤是评估其在更真实的非线性场上的表现。本练习使用一个光滑的“人造解”(manufactured solution)，旨在量化分析不同的邻域模板（stencil）和权重策略对重构精度的影响 ()。这为设计稳健的数值格式提供了宝贵的实践经验和直观理解。",
            "id": "3972721",
            "problem": "考虑一个二维、以单元为中心的有限体积重构问题，这是航空航天计算流体力学 (CFD) 中的典型问题。其目标是使用邻近单元的值来估算给定单元中心的平滑标量场的梯度。设该标量场由一个人造解定义，该解足够平滑，其精确梯度可以解析地求出。估算必须从第一性原理出发，使用以下基本事实：梯度在光滑函数的泰勒展开中作为线性项的定义，以及来自微积分和线性代数中通过最小化加权残差平方和来拟合参数的最小二乘法原理。\n\n设人造解为标量场，由下式给出：\n$$\\phi(x,y) = \\sin(\\alpha x) + \\beta \\cos(\\gamma y) + \\delta x y,$$\n其中常数设置为 $\\,\\alpha = 1.6\\,$, $\\,\\beta = 0.5\\,$, $\\,\\gamma = 0.9\\,$, $\\,\\delta = 0.3\\,$。重构点（单元中心）位于 $(x_0,y_0)$，其中 $\\,x_0 = 0.27\\,$ 且 $\\,y_0 = -0.19\\,$。设 $\\,h = 0.05\\,$ 为特征邻域偏移尺度。所有量均为无量纲，不涉及物理单位。角度必须以弧度解释。\n\n为了估算 $(x_0,y_0)$ 处的梯度，请使用一个以 $(x_0,y_0)$ 为中心的线性函数来近似 $\\,\\phi\\,$ 的局部行为，并通过在给定的邻居偏移模板上最小化加权残差平方和来确定梯度向量 $\\,\\nabla \\phi(x_0,y_0)\\,$。对于每个邻居偏移 $\\,(d_{x,i}, d_{y,i})\\,$，邻居坐标为 $\\,(x_0 + d_{x,i}, y_0 + d_{y,i})\\,$，相应的标量值为 $\\,\\phi(x_0 + d_{x,i}, y_0 + d_{y,i})\\,$。对于一个候选梯度 $\\,\\mathbf{g} = (g_x,g_y)\\,$，其残差是 $\\,\\phi(x_0 + d_{x,i}, y_0 + d_{y,i})\\,$ 与线性预测 $\\,\\phi(x_0,y_0) + g_x d_{x,i} + g_y d_{y,i}\\,$ 之间的差值。$\\,\\mathbf{g}\\,$ 的加权最小二乘估计被定义为残差平方和的最小化子，其中每个邻居都分配有权重 $\\,w_i \\ge 0\\,$。您必须通用地处理此问题，不假设除给定的偏移和权重之外的任何特殊结构。\n\n您必须在使用相同人造解的情况下，比较不同模板和权重下最小二乘梯度的估算误差。误差必须量化为数值梯度与 $(x_0,y_0)$ 处精确解析梯度之差的欧几里得范数，即\n$$E = \\left\\| \\nabla \\phi_{\\text{numerical}}(x_0,y_0) - \\nabla \\phi_{\\text{exact}}(x_0,y_0) \\right\\|_2.$$\n\n使用以下三种邻居偏移模板，它们代表了实践中遇到的不同几何配置：\n\n模板 $\\,\\mathcal{S}_1\\,$（八个邻居组成的近似各向同性环）：\n$$\\{(h,0),(-h,0),(0,h),(0,-h),(h,h),(-h,h),(h,-h),(-h,-h)\\}.$$\n\n模板 $\\,\\mathcal{S}_2\\,$（强 $\\,x\\,$ 偏置，带有轻微的 $\\,y\\,$ 向抖动以避免精确认共线，八个邻居）：\n$$\\{(-3h,0.002h),(-2h,-0.002h),(-h,0.001h),(h,-0.001h),(2h,0.002h),(3h,-0.002h),(-0.5h,0.0015h),(0.5h,-0.0015h)\\}.$$\n\n模板 $\\,\\mathcal{S}_3\\,$（沿斜向近似共线的邻居，带有微小的角度扰动，八个邻居）：\n设 $\\,\\theta = \\pi/6\\,$，扰动为 $\\,\\{\\varepsilon_k\\} = \\{0, 0.001, -0.001, 0.002, -0.002, 0.003, -0.003, 0.004\\}\\,$。设半径为 $\\,\\{r_k\\} = \\{h,1.25h,1.5h,1.75h,2h,2.25h,2.5h,2.75h\\}\\,$。偏移量定义为\n$$d_{x,k} = r_k \\cos(\\theta + \\varepsilon_k), \\quad d_{y,k} = r_k \\sin(\\theta + \\varepsilon_k), \\quad k = 1,\\dots,8.$$\n\n对于每个模板，使用以下三种作用于残差的权重策略中的每一种来计算最小二乘梯度：\n\n权重 $\\,\\mathcal{W}_1\\,$（均匀权重）：对所有邻居 $\\,w_i = 1\\,$。\n\n权重 $\\,\\mathcal{W}_2\\,$（反距离权重）：$\\,w_i = 1 / \\sqrt{d_{x,i}^2 + d_{y,i}^2}\\,$。\n\n权重 $\\,\\mathcal{W}_3\\,$（反距离平方权重）：$\\,w_i = 1 / (d_{x,i}^2 + d_{y,i}^2)\\,$。\n\n对于每个模板-权重对，通过加权最小二乘重构评估数值梯度，并计算如上定义的误差 $\\,E\\,$。人造解在中心的精确梯度必须根据 $\\,\\phi\\,$ 的定义解析地求出。\n\n测试套件和答案规范：\n对三个模板 $\\,\\mathcal{S}_1\\,$, $\\,\\mathcal{S}_2\\,$, $\\,\\mathcal{S}_3\\,$ 和三种权重策略 $\\,\\mathcal{W}_1\\,$, $\\,\\mathcal{W}_2\\,$, $\\,\\mathcal{W}_3\\,$ 进行计算，产生 $\\,9\\,$ 个误差值。您的程序应生成一行输出，其中包含用方括号括起来的、以逗号分隔的结果列表，并按模板分组。每个内部列表对应一个模板，且必须按 $\\,\\mathcal{W}_1\\,$, $\\,\\mathcal{W}_2\\,$, $\\,\\mathcal{W}_3\\,$ 的顺序包含三个权重策略的误差值。最终输出格式必须是\n$$[\\,[E_{1,1},E_{1,2},E_{1,3}],\\,[E_{2,1},E_{2,2},E_{2,3}],\\,[E_{3,1},E_{3,2},E_{3,3}]\\,],$$\n其中 $\\,E_{s,w}\\,$ 表示模板 $\\,s\\,$ 和权重 $\\,w\\,$ 下的误差。不应打印其他文本。",
            "solution": "用户提供了一个需要验证的问题陈述。\n\n### 步骤 1：提取给定信息\n- **标量场：** $\\phi(x,y) = \\sin(\\alpha x) + \\beta \\cos(\\gamma y) + \\delta x y$\n- **常数：** $\\alpha = 1.6$, $\\beta = 0.5$, $\\gamma = 0.9$, $\\delta = 0.3$。\n- **重构点：** $(x_0,y_0) = (0.27, -0.19)$。\n- **特征尺度：** $h = 0.05$。\n- **目标：** 使用加权最小二乘法估算梯度 $\\nabla \\phi(x_0,y_0)$。\n- **近似：** 一个线性函数 $\\phi(x_0 + d_{x,i}, y_0 + d_{y,i}) \\approx \\phi(x_0,y_0) + g_x d_{x,i} + g_y d_{y,i}$。\n- **残差：** $R_i = \\phi(x_0 + d_{x,i}, y_0 + d_{y,i}) - (\\phi(x_0,y_0) + g_x d_{x,i} + g_y d_{y,i})$。\n- **最小化目标：** 加权残差平方和 $\\sum_i w_i R_i^2$。\n- **误差度量：** 欧几里得范数 $E = \\left\\| \\nabla \\phi_{\\text{numerical}}(x_0,y_0) - \\nabla \\phi_{\\text{exact}}(x_0,y_0) \\right\\|_2$。\n- **模板：**\n    - $\\mathcal{S}_1$: $\\{(h,0),(-h,0),(0,h),(0,-h),(h,h),(-h,h),(h,-h),(-h,-h)\\}$。\n    - $\\mathcal{S}_2$: $\\{(-3h,0.002h),(-2h,-0.002h),(-h,0.001h),(h,-0.001h),(2h,0.002h),(3h,-0.002h),(-0.5h,0.0015h),(0.5h,-0.0015h)\\}$。\n    - $\\mathcal{S}_3$: 偏移量 $(d_{x,k}, d_{y,k})$ 由 $d_{x,k} = r_k \\cos(\\theta + \\varepsilon_k), d_{y,k} = r_k \\sin(\\theta + \\varepsilon_k)$ 定义，其中 $k = 1,\\dots,8$, $\\theta = \\pi/6$，半径 $\\{r_k\\} = h \\cdot \\{1,1.25,1.5,1.75,2,2.25,2.5,2.75\\}$，扰动 $\\{\\varepsilon_k\\} = \\{0, 0.001, -0.001, 0.002, -0.002, 0.003, -0.003, 0.004\\}$。\n- **权重策略：**\n    - $\\mathcal{W}_1$: $w_i = 1$。\n    - $\\mathcal{W}_2$: $w_i = 1 / \\sqrt{d_{x,i}^2 + d_{y,i}^2}$。\n    - $\\mathcal{W}_3$: $w_i = 1 / (d_{x,i}^2 + d_{y,i}^2)$。\n- **要求输出：** 一个 $3 \\times 3$ 的误差值集合，对应每个模板-权重对，格式化为列表的列表。\n\n### 步骤 2：使用提取的给定信息进行验证\n该问题具有科学依据，是在计算科学与工程中应用的一种标准数值方法（最小二乘梯度重构），尤其是在用于CFD的有限体积法中。该问题是适定的；给定的模板旨在避免会导致所得线性系统奇异的共线性问题，从而确保存在唯一解。该问题是客观的，所有术语、常数和程序都经过数学和明确的定义。该问题是自洽的，提供了所有必要信息。该问题并非平凡，因为它需要推导和实现一个著名的数值算法，并理解模板几何形状和权重如何影响精度。该问题可通过直接计算进行验证。\n\n### 步骤 3：结论与行动\n此问题有效。将提供详细的解答。\n\n---\n\n该问题要求根据一组邻近位置的场值，来估算一个标量场 $\\nabla\\phi$ 在单元中心 $(x_0, y_0)$ 处的梯度。这是有限体积法中的一个经典重构问题。所选用的方法是最小二乘法原理，该方法旨在找到能够以线性方式最佳拟合邻居数据的梯度分量。\n\n令 $(x_0, y_0)$ 处的未知梯度向量表示为 $\\mathbf{g} = (g_x, g_y)$。根据泰勒定理，对于一个光滑函数 $\\phi(x,y)$，其在邻近点 $(x_i, y_i)$ 的值可以通过在 $(x_0, y_0)$ 周围的线性展开来近似：\n$$ \\phi(x_i, y_i) \\approx \\phi(x_0, y_0) + \\left. \\frac{\\partial\\phi}{\\partial x} \\right|_{(x_0,y_0)} (x_i - x_0) + \\left. \\frac{\\partial\\phi}{\\partial y} \\right|_{(x_0,y_0)} (y_i - y_0) $$\n令 $\\mathbf{d}_i = (d_{x,i}, d_{y,i}) = (x_i-x_0, y_i-y_0)$ 为从中心到第 $i$ 个邻居的偏移向量。该近似可以用未知梯度 $\\mathbf{g}$ 写成：\n$$ \\phi(x_i, y_i) \\approx \\phi(x_0, y_0) + g_x d_{x,i} + g_y d_{y,i} $$\n令 $\\Delta\\phi_i = \\phi(x_i, y_i) - \\phi(x_0, y_0)$，则线性模型为 $\\Delta\\phi_i \\approx g_x d_{x,i} + g_y d_{y,i}$。对于给定的候选梯度 $\\mathbf{g}$，第 $i$ 个邻居的残差或误差为：\n$$ R_i(\\mathbf{g}) = \\Delta\\phi_i - (g_x d_{x,i} + g_y d_{y,i}) $$\n加权最小二乘法旨在找到梯度 $\\mathbf{g}$，使得模板中所有 $N$ 个邻居的加权残差平方和最小：\n$$ J(\\mathbf{g}) = J(g_x, g_y) = \\sum_{i=1}^{N} w_i R_i^2 = \\sum_{i=1}^{N} w_i \\left( \\Delta\\phi_i - g_x d_{x,i} - g_y d_{y,i} \\right)^2 $$\n为求最小值，我们对 $J$ 关于 $g_x$ 和 $g_y$ 求偏导数，并令其为零。\n$$ \\frac{\\partial J}{\\partial g_x} = \\sum_{i=1}^{N} 2 w_i (\\Delta\\phi_i - g_x d_{x,i} - g_y d_{y,i})(-d_{x,i}) = 0 $$\n$$ \\frac{\\partial J}{\\partial g_y} = \\sum_{i=1}^{N} 2 w_i (\\Delta\\phi_i - g_x d_{x,i} - g_y d_{y,i})(-d_{y,i}) = 0 $$\n整理这两个方程，我们得到一个由两个线性方程组成的方程组，称为正规方程组：\n$$ \\left( \\sum_{i=1}^{N} w_i d_{x,i}^2 \\right) g_x + \\left( \\sum_{i=1}^{N} w_i d_{x,i} d_{y,i} \\right) g_y = \\sum_{i=1}^{N} w_i \\Delta\\phi_i d_{x,i} $$\n$$ \\left( \\sum_{i=1}^{N} w_i d_{x,i} d_{y,i} \\right) g_x + \\left( \\sum_{i=1}^{N} w_i d_{y,i}^2 \\right) g_y = \\sum_{i=1}^{N} w_i \\Delta\\phi_i d_{y,i} $$\n该方程组可以写成矩阵形式 $A\\mathbf{g} = \\mathbf{b}$，其中 $\\mathbf{g} = \\begin{pmatrix} g_x \\\\ g_y \\end{pmatrix}$，且\n$$ A = \\begin{pmatrix} \\sum w_i d_{x,i}^2  \\sum w_i d_{x,i} d_{y,i} \\\\ \\sum w_i d_{x,i} d_{y,i}  \\sum w_i d_{y,i}^2 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} \\sum w_i \\Delta\\phi_i d_{x,i} \\\\ \\sum w_i \\Delta\\phi_i d_{y,i} \\end{pmatrix} $$\n矩阵 $A$ 是一个对称的 $2 \\times 2$ 矩阵。只要邻居点不全部共线，$A$ 就是可逆的，梯度的最小二乘估计由 $\\mathbf{g}_{\\text{numerical}} = A^{-1}\\mathbf{b}$ 给出。\n\n为了评估此数值梯度的准确性，我们将其与从人造解 $\\phi(x,y) = \\sin(\\alpha x) + \\beta \\cos(\\gamma y) + \\delta xy$ 推导出的精确梯度进行比较。精确的偏导数为：\n$$ \\frac{\\partial \\phi}{\\partial x} = \\alpha \\cos(\\alpha x) + \\delta y $$\n$$ \\frac{\\partial \\phi}{\\partial y} = -\\beta\\gamma \\sin(\\gamma y) + \\delta x $$\n我们在中心点 $(x_0, y_0) = (0.27, -0.19)$ 处，使用指定的常数 $\\alpha = 1.6$, $\\beta = 0.5$, $\\gamma = 0.9$, $\\delta = 0.3$ 来计算这些表达式，从而得到 $\\nabla\\phi_{\\text{exact}}(x_0, y_0)$。\n\n对于 $9$ 个测试案例（3 个模板 $\\times$ 3 种权重）中的每一个，流程如下：\n1.  为给定的模板定义邻居偏移向量集合 $\\{ \\mathbf{d}_i \\}$。\n2.  计算中心点的标量值 $\\phi_0 = \\phi(x_0, y_0)$。\n3.  对于每个邻居 $i$，计算其坐标 $(x_i, y_i) = (x_0+d_{x,i}, y_0+d_{y,i})$ 和标量值 $\\phi_i = \\phi(x_i, y_i)$，然后求出 $\\Delta\\phi_i = \\phi_i - \\phi_0$。\n4.  根据指定的权重策略确定权重集合 $\\{ w_i \\}$。\n5.  通过对所有邻居求和来构建矩阵 $A$ 和向量 $\\mathbf{b}$ 的元素。\n6.  求解线性方程组 $A\\mathbf{g} = \\mathbf{b}$ 以找到数值梯度 $\\mathbf{g}_{\\text{numerical}}$。\n7.  使用差值的欧几里得范数计算误差 $E$：$E = \\left\\| \\mathbf{g}_{\\text{numerical}} - \\nabla\\phi_{\\text{exact}}(x_0, y_0) \\right\\|_2$。\n\n对每个模板和权重的组合执行这个系统性过程，以生成所需的误差值集合。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the least-squares gradient estimation error for a manufactured solution\n    across different stencils and weighting strategies.\n    \"\"\"\n    # Define constants and problem parameters\n    alpha = 1.6\n    beta = 0.5\n    gamma = 0.9\n    delta = 0.3\n    x0, y0 = 0.27, -0.19\n    h = 0.05\n\n    def phi(x, y):\n        \"\"\"The manufactured scalar field solution.\"\"\"\n        return np.sin(alpha * x) + beta * np.cos(gamma * y) + delta * x * y\n\n    def grad_phi_exact(x, y):\n        \"\"\"The exact analytical gradient of the scalar field.\"\"\"\n        gx = alpha * np.cos(alpha * x) + delta * y\n        gy = -beta * gamma * np.sin(gamma * y) + delta * x\n        return np.array([gx, gy])\n\n    def define_stencils(h_val):\n        \"\"\"Defines the three neighbor offset stencils.\"\"\"\n        # Stencil S1: Isotropic ring\n        s1 = np.array([\n            [h_val, 0], [-h_val, 0], [0, h_val], [0, -h_val],\n            [h_val, h_val], [-h_val, h_val], [h_val, -h_val], [-h_val, -h_val]\n        ])\n\n        # Stencil S2: Strongly x-biased\n        s2 = h_val * np.array([\n            [-3.0, 0.002], [-2.0, -0.002], [-1.0, 0.001],\n            [1.0, -0.001], [2.0, 0.002], [3.0, -0.002],\n            [-0.5, 0.0015], [0.5, -0.0015]\n        ])\n\n        # Stencil S3: Nearly collinear along an oblique direction\n        theta = np.pi / 6.0\n        epsilons = np.array([0, 0.001, -0.001, 0.002, -0.002, 0.003, -0.003, 0.004])\n        radii = h_val * np.array([1.0, 1.25, 1.5, 1.75, 2.0, 2.25, 2.5, 2.75])\n        angles = theta + epsilons\n        dx_s3 = radii * np.cos(angles)\n        dy_s3 = radii * np.sin(angles)\n        s3 = np.column_stack((dx_s3, dy_s3))\n        \n        return [s1, s2, s3]\n\n    def get_weights(offsets, strategy_id):\n        \"\"\"Computes weights based on the specified strategy.\"\"\"\n        if strategy_id == 1:  # W1: Uniform\n            return np.ones(len(offsets))\n        \n        distances_sq = np.sum(offsets**2, axis=1)\n        \n        if strategy_id == 2:  # W2: Inverse-distance\n            return 1.0 / np.sqrt(distances_sq)\n        elif strategy_id == 3:  # W3: Inverse-square-distance\n            return 1.0 / distances_sq\n        else:\n            raise ValueError(\"Invalid weighting strategy ID.\")\n\n    def compute_gradient_lsq(offsets, weights, phi_0):\n        \"\"\"\n        Computes the numerical gradient using weighted least squares.\n        \n        Args:\n            offsets (np.ndarray): Array of neighbor offset vectors.\n            weights (np.ndarray): Array of weights for each neighbor.\n            phi_0 (float): Scalar value at the central point (x0, y0).\n\n        Returns:\n            np.ndarray: The computed numerical gradient vector [gx, gy].\n        \"\"\"\n        neighbor_coords = np.array([x0, y0]) + offsets\n        phi_neighbors = phi(neighbor_coords[:, 0], neighbor_coords[:, 1])\n        delta_phi = phi_neighbors - phi_0\n        \n        dx = offsets[:, 0]\n        dy = offsets[:, 1]\n        \n        # Assemble the normal equation matrix A\n        A11 = np.sum(weights * dx**2)\n        A12 = np.sum(weights * dx * dy)\n        A22 = np.sum(weights * dy**2)\n        A = np.array([[A11, A12], [A12, A22]])\n        \n        # Assemble the right-hand side vector b\n        b1 = np.sum(weights * delta_phi * dx)\n        b2 = np.sum(weights * delta_phi * dy)\n        b = np.array([b1, b2])\n\n        # Solve the linear system A*g = b for the gradient g\n        grad_num = np.linalg.solve(A, b)\n        \n        return grad_num\n\n    # Main execution logic\n    stencils = define_stencils(h)\n    exact_grad = grad_phi_exact(x0, y0)\n    phi0_val = phi(x0, y0)\n    \n    all_errors = []\n    \n    for stencil in stencils:\n        stencil_errors = []\n        for weight_strategy_id in [1, 2, 3]:\n            # Calculate weights for the current strategy\n            current_weights = get_weights(stencil, weight_strategy_id)\n            \n            # Compute numerical gradient\n            numerical_grad = compute_gradient_lsq(stencil, current_weights, phi0_val)\n            \n            # Compute and store the error\n            error = np.linalg.norm(numerical_grad - exact_grad)\n            stencil_errors.append(error)\n        \n        all_errors.append(stencil_errors)\n\n    # Format the final output string as specified\n    inner_strings = [f\"[{','.join(f'{err:.16e}' for err in sublist)}]\" for sublist in all_errors]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "本练习将探讨一个在计算流体力学中普遍存在的挑战：在歪斜或非结构网格上由非正交性引起的误差。您将不仅仅是应用标准方法，而是需要设计并实现一种定制的权重方案，以专门应对并减小这种误差 ()。这个实践旨在展示如何根据特定的几何挑战来调整和优化数值方法，从而提高通量计算的准确性。",
            "id": "3972776",
            "problem": "考虑一个计算流体动力学 (CFD) 中的二维、以单元为中心的有限体积法场景，其中标量场的梯度在每个单元中心使用最小二乘法 (LS) 和相邻单元的值进行重构。该重构使用与目标单元共享一个面的相邻单元。当连接单元中心的线与面法线不对齐时，会产生非正交性误差，这会对计算通量所需的梯度法向分量的估计产生偏差。您的任务是在最小二乘法公式中设计并实现一种加权策略，该策略优先考虑与面法线对齐的相邻单元，并在通过对笛卡尔网格进行仿射变换而生成的人工扭曲网格上对其进行验证。\n\n从以下基本定义开始：\n- 标量场是一个在物理空间上定义的光滑函数 $u(x,y)$。其在某一点的梯度为 $\\nabla u(x,y) = \\left[\\partial u/\\partial x, \\ \\partial u/\\partial y\\right]$。\n- 对于中心位于 $(x_i,y_i)$ 的目标单元和一个中心位于 $(x_j,y_j)$ 的相邻单元 $j$，定义位移 $\\Delta \\boldsymbol{x}_{ij} = \\boldsymbol{x}_j - \\boldsymbol{x}_i$ 和值差 $\\Delta u_{ij} = u(\\boldsymbol{x}_j) - u(\\boldsymbol{x}_i)$。\n- 最小二乘梯度重构旨在寻找一个向量 $\\boldsymbol{g}_i$，以最小化加权残差平方和 $\\sum_j w_{ij} \\left(\\Delta u_{ij} - \\boldsymbol{g}_i \\cdot \\Delta \\boldsymbol{x}_{ij} \\right)^2$，其中求和涵盖所有共享面的相邻单元 $j$，$w_{ij}  0$ 是权重。\n\n为了优先考虑与面法线的对齐，请设计权重 $w_{ij}$，使其依赖于与面法线 $\\boldsymbol{n}_{ij}$ 的对齐因子。其中，$\\boldsymbol{n}_{ij}$ 是单元 $i$ 和 $j$ 之间共享面的单位法向量，其方向从第一个单元一致地指向第二个单元。这种对齐应奖励那些其单元中心到中心向量 $\\Delta \\boldsymbol{x}_{ij}$ 与 $\\boldsymbol{n}_{ij}$ 更对齐的相邻单元。此外，权重必须以物理上合理的方式反映距离，以保持数值稳定性。\n\n通过对一个轴对齐的顶点网格应用仿射变换来构造人工网格：\n1. 从一个方形域上的均匀顶点网格开始，该网格具有整数坐标，尺寸为 $N_x \\times N_y$ 个顶点。\n2. 对每个顶点应用一个参数为 $s$ 的剪切变换，然后旋转一个角度 $\\theta$（以弧度为单位），以获得物理坐标。\n3. 将每个单元定义为由四个相邻的变换后顶点形成的四边形，其中心定义为其四个顶点的平均值。\n4. 将每个共享面的面法线定义为垂直于该面线段的单位向量，其方向从“左/下”单元指向“右/上”单元。\n\n使用以下标量场：\n- $u(x,y) = \\sin(x) + \\frac{1}{2} y^2 + 0.3 x y$。\n- 其精确梯度为 $\\nabla u(x,y) = \\left[\\cos(x) + 0.3 y, \\ y + 0.3 x \\right]$。\n\n在内部单元（即拥有所有四个共享面的相邻单元的单元）上实现两种最小二乘重构：\n- 基准权重：$w^{\\mathrm{base}}_{ij} = 1/\\|\\Delta \\boldsymbol{x}_{ij}\\|^2$。\n- 提出的对齐感知权重：$w^{\\mathrm{align}}_{ij}$，它随对齐因子 $a_{ij} = \\frac{|\\Delta \\boldsymbol{x}_{ij} \\cdot \\boldsymbol{n}_{ij}|}{\\|\\Delta \\boldsymbol{x}_{ij}\\|}$ 的增加而增加，并包含一个距离缩放。选择一个光滑、严格为正且能反映这些原则并适用于最小二乘法的函数形式。\n\n对于每个网格，通过内部面上法向导数的均方根 (RMS) 误差来量化性能。对于单元 $i$ 和 $j$ 之间的一个面，其单位法向量为 $\\boldsymbol{n}_{ij}$，面中心为 $\\boldsymbol{x}_f$，定义：\n- 使用单元梯度重构的法向导数为 $\\partial_n u|_{\\mathrm{rec}} = \\left( \\frac{\\boldsymbol{g}_i + \\boldsymbol{g}_j}{2} \\right) \\cdot \\boldsymbol{n}_{ij}$。\n- 精确的法向导数为 $\\partial_n u|_{\\mathrm{exact}} = \\nabla u(\\boldsymbol{x}_f) \\cdot \\boldsymbol{n}_{ij}$。\n计算在所有内部面上差值 $\\partial_n u|_{\\mathrm{rec}} - \\partial_n u|_{\\mathrm{exact}}$ 的均方根。报告比率 $R = E_{\\mathrm{align}} / E_{\\mathrm{base}}$，其中 $E_{\\mathrm{align}}$ 和 $E_{\\mathrm{base}}$ 分别是对齐感知重构和基准重构的均方根误差。\n\n角度单位说明：所有角度 $\\theta$ 必须以弧度为单位。\n\n测试套件和参数：\n- 在所有测试中，基础网格使用 $N_x = 30$，$N_y = 30$ 个顶点。\n- 测试用例：\n  1. 中等扭曲：剪切 $s = 0.3$，旋转 $\\theta = 0.2$。\n  2. 强扭曲：剪切 $s = 0.8$，旋转 $\\theta = 0.5$。\n  3. 正交参考：剪切 $s = 0.0$，旋转 $\\theta = 0.0$。\n\n您的程序应为每个测试用例计算 $R$，并生成一行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，“[r1,r2,r3]”）。每个 $r_k$ 必须是一个浮点数。不需要单位，因为所有量根据构造都是无量纲的。",
            "solution": "所提出的问题具有坚实的科学基础、自成体系且算法明确。它构成了计算流体动力学中一个有效且有趣的数值实验。因此，我将着手提供一个完整的解决方案。\n\n问题的核心在于计算网格上标量场梯度的最小二乘 (LS) 重构。对于目标单元 `$i$`，我们寻求一个梯度向量 `$\\boldsymbol{g}_i$`，以最佳地解释单元 `$i$` 与其共享面的相邻单元 `$j$` 之间标量值 `$u$` 的差异。一阶泰勒级数展开 `$\\Delta u_{ij} = u(\\boldsymbol{x}_j) - u(\\boldsymbol{x}_i) \\approx \\nabla u(\\boldsymbol{x}_i) \\cdot (\\boldsymbol{x}_j - \\boldsymbol{x}_i) = \\boldsymbol{g}_i \\cdot \\Delta \\boldsymbol{x}_{ij}$` 构成了此重构的基础。\n\n为了找到 `$\\boldsymbol{g}_i = [g_x, g_y]^T$`，我们对所有 `$N$` 个邻居最小化加权残差平方和：\n$$\n\\text{minimize} \\sum_{j=1}^{N} w_{ij} \\left( \\Delta u_{ij} - \\boldsymbol{g}_i \\cdot \\Delta \\boldsymbol{x}_{ij} \\right)^2\n$$\n这是一个标准的加权线性最小二乘问题。其解可以用矩阵形式表示。令 `$A$` 为一个 `$N \\times 2$` 矩阵，其行是位移向量 `$\\Delta \\boldsymbol{x}_{ij}^T$`，令 `$\\boldsymbol{b}$` 为一个 `$N \\times 1$` 的标量差向量 `$\\Delta u_{ij}$`，并令 `$W$` 为一个包含权重 `$w_{ij}$` 的 `$N \\times N$` 对角矩阵。问题变为找到使 `$\\| A \\boldsymbol{g}_i - \\boldsymbol{b} \\|_W^2$` 最小化的 `$\\boldsymbol{g}_i$`。正规方程提供了其解：\n$$\n(A^T W A) \\boldsymbol{g}_i = A^T W \\boldsymbol{b}\n$$\n然后通过求解这个 `$2 \\times 2$` 的线性系统来找到梯度：\n$$\n\\boldsymbol{g}_i = (A^T W A)^{-1} A^T W \\boldsymbol{b}\n$$\n\n该问题要求通过对均匀笛卡尔顶点网格应用仿射变换来构造人工扭曲网格。该变换包括一个剪切变换和一个随后的旋转变换。基础网格上的一个顶点 `$\\boldsymbol{v} = [x, y]^T$` 通过变换矩阵 `$T$` 映射到物理坐标 `$\\boldsymbol{v}'$`：\n$$\n\\boldsymbol{v}' = T \\boldsymbol{v} = R(\\theta) S(s) \\boldsymbol{v} = \\begin{pmatrix} \\cos\\theta  -\\sin\\theta \\\\ \\sin\\theta  \\cos\\theta \\end{pmatrix} \\begin{pmatrix} 1  s \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix}\n$$\n其中 `$s$` 是剪切参数，`$\\theta$` 是旋转角度（以弧度为单位）。单元中心被定义为其四个顶点坐标的算术平均值。面法线 `$\\boldsymbol{n}_{ij}$` 是垂直于面线段的单位向量，其方向一致地从索引较小的单元 `$(i,j)$` 指向索引较大的单元（例如，从 `$(i,j)$` 到 `$(i+1,j)$`）。\n\n将比较两种加权策略。\n1.  **基准权重**：`$w^{\\mathrm{base}}_{ij} = 1/\\|\\Delta \\boldsymbol{x}_{ij}\\|^2$`。这是一种常见的距离平方反比加权法，它给予较近的邻居更大的影响。\n\n2.  **对齐感知权重**：问题要求设计权重 `$w^{\\mathrm{align}}_{ij}$`，该权重严格为正，包含距离缩放，并优先考虑其中心到中心向量 `$\\Delta \\boldsymbol{x}_{ij}$` 与相应面法线 `$\\boldsymbol{n}_{ij}$` 良好对齐的邻居。对齐程度由因子 `$a_{ij} = \\frac{|\\Delta \\boldsymbol{x}_{ij} \\cdot \\boldsymbol{n}_{ij}|}{\\|\\Delta \\boldsymbol{x}_{ij}\\|} = |\\cos(\\phi)|$` 来量化，其中 `$\\phi$` 是两个向量之间的夹角。为满足这些要求，我们可以通过一个奖励对齐的指数因子来修改基准权重：\n    $$\n    w^{\\mathrm{align}}_{ij} = \\frac{\\exp(a_{ij})}{\\|\\Delta \\boldsymbol{x}_{ij}\\|^2}\n    $$\n    由于 `$\\exp(a_{ij})  0$`，此形式是严格为正的。它保留了距离平方反比缩放。当对齐因子 `$a_{ij}$` 接近其最大值 `$1$`（完美对齐）时，指数函数会平滑且显著地增加权重，而对于对齐度差的情况（`$a_{ij} \\to 0$`），则会减小权重。对于正交网格，所有邻居的 `$a_{ij}=1$`。对齐感知权重变为 `$w^{\\mathrm{align}}_{ij} = \\exp(1) \\cdot w^{\\mathrm{base}}_{ij}$`。由于将所有权重乘以一个常数不会改变最小二乘解，因此两种方法将如预期般产生相同的梯度。\n\n每种方法的性能通过内部面上法向导数的均方根 (RMS) 误差来评估。内部面是分隔两个内部单元（即不位于域边界上的单元）的面。对于每个这样的面，其中心为 `$\\boldsymbol{x}_f$`，单位法向量为 `$\\boldsymbol{n}_{ij}$`（从单元 `$i$` 指向单元 `$j$`），我们计算：\n-   重构的法向导数：`$\\partial_n u|_{\\mathrm{rec}} = \\left( \\frac{\\boldsymbol{g}_i + \\boldsymbol{g}_j}{2} \\right) \\cdot \\boldsymbol{n}_{ij}$`，其中 `$\\boldsymbol{g}_i$` 和 `$\\boldsymbol{g}_j$` 是相邻单元中重构的梯度。\n-   精确的法向导数：`$\\partial_n u|_{\\mathrm{exact}} = \\nabla u(\\boldsymbol{x}_f) \\cdot \\boldsymbol{n}_{ij}$`，使用给定的 `$u(x,y)$` 的解析梯度。\n\n均方根误差 `$E$` 在所有 `$N_f$` 个内部面上计算：\n$$\nE = \\sqrt{\\frac{1}{N_f} \\sum_{f=1}^{N_f} \\left(\\partial_n u|_{\\mathrm{rec}} - \\partial_n u|_{\\mathrm{exact}}\\right)^2}\n$$\n对基准（`$E_{\\mathrm{base}}$`）和对齐感知（`$E_{\\mathrm{align}}$`）加权方案都执行此计算。最终输出是比率 `$R = E_{\\mathrm{align}} / E_{\\mathrm{base}}$`。比率 `$R1$` 表示对齐感知加权策略提高了法向导数重构的准确性。\n\n标量场及其精确梯度由下式给出：\n- `$u(x,y) = \\sin(x) + \\frac{1}{2} y^2 + 0.3 x y$`\n- `$\\nabla u(x,y) = \\left[\\cos(x) + 0.3 y, \\ y + 0.3 x \\right]$`\n\n计算过程包括生成指定的网格，识别内部单元和面，通过求解 `$2 \\times 2$` 的最小二乘系统为两种加权方案计算每个内部单元的梯度，然后计算各自的均方根误差以求得比率 `$R$`。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef u_func(p: np.ndarray) - np.ndarray:\n    \"\"\"Computes the scalar field u at given points.\"\"\"\n    x, y = p[:, 0], p[:, 1]\n    return np.sin(x) + 0.5 * y**2 + 0.3 * x * y\n\ndef grad_u_func(p: np.ndarray) - np.ndarray:\n    \"\"\"Computes the exact gradient of u at given points.\"\"\"\n    x, y = p[:, 0], p[:, 1]\n    gx = np.cos(x) + 0.3 * y\n    gy = y + 0.3 * x\n    return np.stack([gx, gy], axis=-1)\n\ndef compute_gradients(vertices: np.ndarray, centers: np.ndarray, weight_type: str) - np.ndarray:\n    \"\"\"Computes gradients at interior cell centers using LS.\"\"\"\n    Nx_v, Ny_v, _ = vertices.shape\n    Ncx, Ncy, _ = centers.shape # Ncx = Nx_v - 1, Ncy = Ny_v - 1\n    \n    gradients = np.zeros_like(centers)\n\n    for i in range(1, Ncx - 1):\n        for j in range(1, Ncy - 1): # Iterate over interior cells\n            center_i = centers[i, j]\n            val_i = u_func(center_i.reshape(1, 2))[0]\n            \n            neighbor_indices = [(i - 1, j), (i + 1, j), (i, j - 1), (i, j + 1)]\n            \n            A = np.zeros((4, 2))\n            b = np.zeros(4)\n            W_diag = np.zeros(4)\n\n            for k, (ni, nj) in enumerate(neighbor_indices):\n                center_j = centers[ni, nj]\n                delta_x_vec = center_j - center_i\n                \n                A[k, :] = delta_x_vec\n                b[k] = u_func(center_j.reshape(1, 2))[0] - val_i\n\n                dist_sq = np.dot(delta_x_vec, delta_x_vec)\n                if dist_sq  1e-12: dist_sq = 1e-12\n\n                if weight_type == 'baseline':\n                    W_diag[k] = 1.0 / dist_sq\n                elif weight_type == 'aligned':\n                    # Determine face vertices\n                    if ni == i - 1: # Left neighbor\n                        v1, v2 = vertices[i, j], vertices[i, j + 1]\n                    elif ni == i + 1: # Right neighbor\n                        v1, v2 = vertices[i + 1, j], vertices[i + 1, j + 1]\n                    elif nj == j - 1: # Bottom neighbor\n                        v1, v2 = vertices[i, j], vertices[i + 1, j]\n                    else: # Top neighbor\n                        v1, v2 = vertices[i, j + 1], vertices[i + 1, j + 1]\n\n                    face_vec = v2 - v1\n                    n_vec = np.array([face_vec[1], -face_vec[0]])\n                    n_norm = np.linalg.norm(n_vec)\n                    if n_norm  1e-12: n_norm = 1e-12\n                    n_unit = n_vec / n_norm\n\n                    if np.dot(n_unit, delta_x_vec)  0.0:\n                        n_unit = -n_unit\n                    \n                    dist = np.sqrt(dist_sq)\n                    alignment_factor = np.abs(np.dot(delta_x_vec, n_unit)) / dist\n                    W_diag[k] = np.exp(alignment_factor) / dist_sq\n            \n            M = A.T @ np.diag(W_diag) @ A\n            rhs = A.T @ (W_diag * b)\n            \n            try:\n                grad = np.linalg.solve(M, rhs)\n            except np.linalg.LinAlgError:\n                # Fallback to unweighted if weighted system is singular\n                grad = np.linalg.lstsq(A, b, rcond=None)[0]\n                \n            gradients[i, j, :] = grad\n            \n    return gradients\n\ndef compute_rms_error(gradients: np.ndarray, vertices: np.ndarray, centers: np.ndarray) - float:\n    \"\"\"Computes RMS error of the normal derivative on interior faces.\"\"\"\n    Ncx, Ncy, _ = centers.shape\n    total_sq_error = 0.0\n    num_faces = 0\n\n    # Interior vertical faces (between (i,j) and (i+1,j))\n    for i in range(1, Ncx - 2):\n        for j in range(1, Ncy - 1):\n            cell1_idx, cell2_idx = (i, j), (i + 1, j)\n            v1, v2 = vertices[i + 1, j], vertices[i + 1, j + 1]\n            \n            face_center = 0.5 * (v1 + v2)\n            face_vec = v2 - v1\n            n_vec = np.array([face_vec[1], -face_vec[0]])\n            n_norm = np.linalg.norm(n_vec)\n            if n_norm  1e-12: n_norm = 1e-12\n            n_unit = n_vec / n_norm\n\n            disp_vec = centers[cell2_idx] - centers[cell1_idx]\n            if np.dot(n_unit, disp_vec)  0.0:\n                n_unit = -n_unit\n\n            avg_grad = 0.5 * (gradients[cell1_idx] + gradients[cell2_idx])\n            deriv_rec = np.dot(avg_grad, n_unit)\n            \n            exact_grad = grad_u_func(face_center.reshape(1, 2))[0]\n            deriv_exact = np.dot(exact_grad, n_unit)\n\n            total_sq_error += (deriv_rec - deriv_exact)**2\n            num_faces += 1\n\n    # Interior horizontal faces (between (i,j) and (i,j+1))\n    for i in range(1, Ncx - 1):\n        for j in range(1, Ncy - 2):\n            cell1_idx, cell2_idx = (i, j), (i, j + 1)\n            v1, v2 = vertices[i, j + 1], vertices[i + 1, j + 1]\n\n            face_center = 0.5 * (v1 + v2)\n            face_vec = v2 - v1\n            n_vec = np.array([face_vec[1], -face_vec[0]])\n            n_norm = np.linalg.norm(n_vec)\n            if n_norm  1e-12: n_norm = 1e-12\n            n_unit = n_vec / n_norm\n\n            disp_vec = centers[cell2_idx] - centers[cell1_idx]\n            if np.dot(n_unit, disp_vec)  0.0:\n                n_unit = -n_unit\n\n            avg_grad = 0.5 * (gradients[cell1_idx] + gradients[cell2_idx])\n            deriv_rec = np.dot(avg_grad, n_unit)\n\n            exact_grad = grad_u_func(face_center.reshape(1, 2))[0]\n            deriv_exact = np.dot(exact_grad, n_unit)\n            \n            total_sq_error += (deriv_rec - deriv_exact)**2\n            num_faces += 1\n\n    return np.sqrt(total_sq_error / num_faces) if num_faces > 0 else 0.0\n\ndef run_case(Nx, Ny, s, theta):\n    \"\"\"Generates mesh, computes gradients, errors, and the ratio R.\"\"\"\n    # 1. Generate Mesh\n    x_v, y_v = np.arange(Nx), np.arange(Ny)\n    xv, yv = np.meshgrid(x_v, y_v, indexing='ij')\n    base_vertices = np.stack([xv, yv], axis=-1)\n\n    rot_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n    shear_matrix = np.array([[1, s], [0, 1]])\n    trans_matrix = rot_matrix @ shear_matrix\n    \n    physical_vertices = (base_vertices.reshape(-1, 2) @ trans_matrix.T).reshape(Nx, Ny, 2)\n    \n    Ncx, Ncy = Nx - 1, Ny - 1\n    cell_centers = 0.25 * (physical_vertices[:Ncx, :Ncy] +\n                           physical_vertices[1:Nx, :Ncy] +\n                           physical_vertices[1:Nx, 1:Ny] +\n                           physical_vertices[:Ncx, 1:Ny])\n\n    # 2. Compute Gradients and Errors\n    grad_base = compute_gradients(physical_vertices, cell_centers, 'baseline')\n    error_base = compute_rms_error(grad_base, physical_vertices, cell_centers)\n\n    grad_align = compute_gradients(physical_vertices, cell_centers, 'aligned')\n    error_align = compute_rms_error(grad_align, physical_vertices, cell_centers)\n\n    if error_base  1e-12:\n        return 1.0\n\n    return error_align / error_base\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (30, 30, 0.3, 0.2), # Moderate skew\n        (30, 30, 0.8, 0.5), # Strong skew\n        (30, 30, 0.0, 0.0), # Orthogonal reference\n    ]\n\n    results = []\n    for Nx, Ny, s, theta in test_cases:\n        ratio = run_case(Nx, Ny, s, theta)\n        results.append(ratio)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}