{
    "hands_on_practices": [
        {
            "introduction": "This exercise grounds our study in the fundamental mathematics of curvilinear coordinates. Before we can control a grid, we must be able to measure its properties; here, we focus on orthogonality, a primary indicator of a high-quality mesh that can reduce numerical error in simulations. By deriving the condition for orthogonality from first principles , you will develop a concrete understanding of the geometric quantities, like the metric tensor components, that govern grid structure.",
            "id": "3313536",
            "problem": "Consider a smooth, bijective planar mapping from the computational domain with coordinates $\\xi$ and $\\eta$ to the physical domain with coordinates $x$ and $y$, defined by the position vector $\\mathbf{r}(\\xi,\\eta) = \\big(x(\\xi,\\eta), y(\\xi,\\eta)\\big)$. In elliptic grid generation with Poisson equations, one constructs such mappings by solving elliptic partial differential equations of the form $x_{\\xi\\xi} + x_{\\eta\\eta} = P(\\xi,\\eta)$ and $y_{\\xi\\xi} + y_{\\eta\\eta} = Q(\\xi,\\eta)$, where $P$ and $Q$ are smooth control functions chosen to regulate grid smoothness and spacing. Starting from the Euclidean inner product in $\\mathbb{R}^{2}$ and the definition of covariant base vectors for curvilinear coordinates, derive a necessary and sufficient condition for the coordinate lines $\\xi=\\text{constant}$ and $\\eta=\\text{constant}$ to be orthogonal in the physical plane, expressed purely in terms of the partial derivatives of $x(\\xi,\\eta)$ and $y(\\xi,\\eta)$. Then, for the specific mapping $x(\\xi,\\eta) = \\xi$ and $y(\\xi,\\eta) = \\eta^{2}$, compute the orthogonality diagnostic obtained from your derived condition at a general point $(\\xi,\\eta)$ to assess whether orthogonality is preserved or lost. The final answer must be the computed diagnostic value as a single real number or a single closed-form expression, with no units and no rounding required.",
            "solution": "The problem requires the derivation of a necessary and sufficient condition for the orthogonality of coordinate lines in a planar mapping and the subsequent application of this condition to a specific transformation.\n\nFirst, we derive the general condition for orthogonality. The mapping from the computational domain, with curvilinear coordinates $(\\xi, \\eta)$, to the physical domain, with Cartesian coordinates $(x, y)$, is defined by the position vector $\\mathbf{r}(\\xi, \\eta) = x(\\xi, \\eta)\\mathbf{i} + y(\\xi, \\eta)\\mathbf{j}$. In component form, we write $\\mathbf{r} = \\big(x(\\xi, \\eta), y(\\xi, \\eta)\\big)$.\n\nThe coordinate lines in the physical plane are the images of the lines $\\xi = \\text{constant}$ and $\\eta = \\text{constant}$ from the computational plane.\nA tangent vector to the curve corresponding to $\\eta = \\text{constant}$ is obtained by differentiating the position vector $\\mathbf{r}$ with respect to $\\xi$. This vector is the covariant base vector $\\mathbf{g}_{\\xi}$:\n$$\n\\mathbf{g}_{\\xi} = \\frac{\\partial \\mathbf{r}}{\\partial \\xi} = \\left(\\frac{\\partial x}{\\partial \\xi}, \\frac{\\partial y}{\\partial \\xi}\\right) = (x_{\\xi}, y_{\\xi})\n$$\nSimilarly, a tangent vector to the curve corresponding to $\\xi = \\text{constant}$ is obtained by differentiating $\\mathbf{r}$ with respect to $\\eta$. This vector is the covariant base vector $\\mathbf{g}_{\\eta}$:\n$$\n\\mathbf{g}_{\\eta} = \\frac{\\partial \\mathbf{r}}{\\partial \\eta} = \\left(\\frac{\\partial x}{\\partial \\eta}, \\frac{\\partial y}{\\partial \\eta}\\right) = (x_{\\eta}, y_{\\eta})\n$$\nIn a Euclidean plane, two vectors are orthogonal if and only if their inner product (dot product) is zero. Thus, the necessary and sufficient condition for the coordinate lines to be orthogonal at a point is that their tangent vectors at that point are orthogonal. This is expressed as:\n$$\n\\mathbf{g}_{\\xi} \\cdot \\mathbf{g}_{\\eta} = 0\n$$\nSubstituting the component expressions for the base vectors, we obtain the orthogonality condition expressed in terms of the partial derivatives of the mapping functions:\n$$\n(x_{\\xi}, y_{\\xi}) \\cdot (x_{\\eta}, y_{\\eta}) = x_{\\xi}x_{\\eta} + y_{\\xi}y_{\\eta} = 0\n$$\nThe expression $x_{\\xi}x_{\\eta} + y_{\\xi}y_{\\eta}$ serves as the \"orthogonality diagnostic\" requested in the problem. Its value determines whether orthogonality is maintained. This term corresponds to the off-diagonal elements, $g_{12}$ and $g_{21}$, of the metric tensor of the transformation. A diagonal metric tensor ($g_{12}=g_{21}=0$) signifies an orthogonal coordinate system.\n\nNext, we apply this condition to the specific mapping provided:\n$$\nx(\\xi, \\eta) = \\xi\n$$\n$$\ny(\\xi, \\eta) = \\eta^{2}\n$$\nWe must first compute the four first-order partial derivatives of $x$ and $y$ with respect to $\\xi$ and $\\eta$:\n$$\nx_{\\xi} = \\frac{\\partial}{\\partial \\xi}(\\xi) = 1\n$$\n$$\nx_{\\eta} = \\frac{\\partial}{\\partial \\eta}(\\xi) = 0\n$$\n$$\ny_{\\xi} = \\frac{\\partial}{\\partial \\xi}(\\eta^{2}) = 0\n$$\n$$\ny_{\\eta} = \\frac{\\partial}{\\partial \\eta}(\\eta^{2}) = 2\\eta\n$$\nNow, we substitute these derivatives into the orthogonality diagnostic expression:\n$$\nx_{\\xi}x_{\\eta} + y_{\\xi}y_{\\eta} = (1)(0) + (0)(2\\eta)\n$$\nEvaluating this expression, we find:\n$$\n0 + 0 = 0\n$$\nThe value of the orthogonality diagnostic is identically $0$ for all points $(\\xi, \\eta)$ in the domain. This indicates that the coordinate lines for this specific mapping are orthogonal everywhere. Geometrically, lines of constant $\\xi$ map to vertical lines $x = \\text{constant}$, while lines of constant $\\eta$ map to horizontal lines $y = (\\text{constant})^{2}$. A grid of vertical and horizontal lines is, by definition, an orthogonal grid.\n\nThe final answer is the computed value of the orthogonality diagnostic expression.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "The true power of elliptic grid generation lies in its ability to produce smooth grids with fine control over cell distribution, but this power comes with a risk: aggressive clustering can cause grid lines to cross, rendering the mesh invalid. This hands-on coding practice tackles this central challenge by having you implement an adaptive algorithm . You will build a Poisson grid generator that monitors the Jacobian determinant—the mathematical test for grid folding—and automatically weakens the clustering-control functions to guarantee a valid, high-quality mesh.",
            "id": "3956885",
            "problem": "You are tasked with designing and implementing an algorithmic check within the framework of elliptic grid generation using Poisson equations that enforces a strictly positive minimal Jacobian, denoted as $J_{\\min} > 0$, by adaptively rescaling the Poisson control functions $P$ and $Q$ during the iterative solve. The computational setting and all mathematics are to be expressed purely and universally, with no reliance on any external files or particular physical units.\n\nBegin from the following foundational base: elliptic grid generation defines a smooth mapping $(x(\\xi,\\eta), y(\\xi,\\eta))$ from a rectangular computational domain $(\\xi,\\eta) \\in [0,1] \\times [0,1]$ to a physical domain via the pair of Poisson equations\n$$\nx_{\\xi\\xi} + x_{\\eta\\eta} = P(\\xi,\\eta), \\qquad y_{\\xi\\xi} + y_{\\eta\\eta} = Q(\\xi,\\eta).\n$$\nThe Jacobian determinant of the transformation is defined by\n$$\nJ(\\xi,\\eta) = x_{\\xi} y_{\\eta} - x_{\\eta} y_{\\xi},\n$$\nand the non-folding requirement of a valid grid is that $J(\\xi,\\eta) > 0$ everywhere, with $J_{\\min} = \\min_{\\xi,\\eta} J(\\xi,\\eta)$ strictly positive. The control functions $P(\\xi,\\eta)$ and $Q(\\xi,\\eta)$ may be used to cluster grid points according to a monitor function $M(\\xi,\\eta)$, but aggressive clustering can drive $J_{\\min}$ negative unless regulated.\n\nYour task is to:\n- Derive from first principles a finite-difference iterative scheme for the Poisson system on a uniform computational lattice with $N_x \\times N_y$ points, spacings $\\Delta \\xi = 1/(N_x-1)$ and $\\Delta \\eta = 1/(N_y-1)$, subject to fixed Dirichlet boundary conditions that map the computational edges to a physical domain whose top boundary is given by $y(\\xi,1) = 1 + 0.2 \\sin(2\\pi \\xi)$ and side boundaries remain vertical, namely $x(0,\\eta) = 0$, $x(1,\\eta) = 1$, $y(0,\\eta) = \\eta$, $y(1,\\eta) = \\eta$, and bottom boundary $y(\\xi,0) = 0$, $x(\\xi,0) = \\xi$, $x(\\xi,1) = \\xi$.\n- Define a smooth monitor function $M(\\xi,\\eta) = 1 + \\kappa \\exp\\left(-\\frac{(\\xi-\\xi_c)^2 + (\\eta-\\eta_c)^2}{\\sigma^2}\\right)$ with fixed center $(\\xi_c,\\eta_c) = (0.5,0.85)$, width $\\sigma > 0$, and strength $\\kappa > 0$. Use the control functions $P(\\xi,\\eta) = A \\frac{\\partial M}{\\partial \\xi}$ and $Q(\\xi,\\eta) = B \\frac{\\partial M}{\\partial \\eta}$ with amplitudes $A$ and $B$ that you will adaptively rescale to enforce $J_{\\min} > 0$.\n- Formulate and implement an algorithmic check that measures $J_{\\min}$ after blocks of iterations of the discrete Poisson solve, and if $J_{\\min} \\le \\tau$ for a prescribed threshold $\\tau > 0$, multiplicatively rescales $(A,B) \\leftarrow (\\alpha A, \\alpha B)$ with a fixed factor $\\alpha \\in (0,1)$, then continues the iterative solve with the weakened $P$ and $Q$. This adaptive rescaling must be monotone in the sense that repeated violations will continue to reduce $(A,B)$ until $J_{\\min} > \\tau$ is achieved or the control functions become negligible (in which case the system reduces toward the Laplace equations).\n- Use the following finite-difference discretization for interior points $(i,j)$ with $i = 1,\\ldots,N_x-2$ and $j=1,\\ldots,N_y-2$:\n$$\n\\frac{x_{i+1,j} - 2 x_{i,j} + x_{i-1,j}}{\\Delta \\xi^2} + \\frac{x_{i,j+1} - 2 x_{i,j} + x_{i,j-1}}{\\Delta \\eta^2} = P_{i,j},\n$$\n$$\n\\frac{y_{i+1,j} - 2 y_{i,j} + y_{i-1,j}}{\\Delta \\xi^2} + \\frac{y_{i,j+1} - 2 y_{i,j} + y_{i,j-1}}{\\Delta \\eta^2} = Q_{i,j},\n$$\nand derive the corresponding pointwise Gauss–Seidel update for $x_{i,j}$ and $y_{i,j}$ in terms of neighboring values and the current $P_{i,j}$ and $Q_{i,j}$. Compute $J_{i,j}$ by central differences,\n$$\nx_{\\xi}\\big|_{i,j} \\approx \\frac{x_{i+1,j}-x_{i-1,j}}{2\\Delta \\xi}, \\quad x_{\\eta}\\big|_{i,j} \\approx \\frac{x_{i,j+1}-x_{i,j-1}}{2\\Delta \\eta},\n$$\n$$\ny_{\\xi}\\big|_{i,j} \\approx \\frac{y_{i+1,j}-y_{i-1,j}}{2\\Delta \\xi}, \\quad y_{\\eta}\\big|_{i,j} \\approx \\frac{y_{i,j+1}-y_{i,j-1}}{2\\Delta \\eta},\n$$\nand then $J_{i,j} = x_{\\xi}\\big|_{i,j}\\, y_{\\eta}\\big|_{i,j} - x_{\\eta}\\big|_{i,j}\\, y_{\\xi}\\big|_{i,j}$, with $J_{\\min}$ taken over interior points.\n\nImplement the above in a single program that runs four test cases forming a test suite. Each test case supplies $(N_x,N_y)$, $(A_0,B_0)$ amplitudes for the initial control functions, the threshold $\\tau$, the rescaling factor $\\alpha$, the monitor width $\\sigma$, the monitor strength $\\kappa$, the number of inner Gauss–Seidel iterations per adaptive cycle $N_{\\text{inner}}$, and the maximum number of adaptive cycles $N_{\\text{outer}}$. The program must:\n- Initialize the grid and boundary conditions as specified.\n- Compute the derivatives $\\frac{\\partial M}{\\partial \\xi}$ and $\\frac{\\partial M}{\\partial \\eta}$ on the computational lattice and use them to form $P$ and $Q$ via the current $(A,B)$.\n- Perform the iterative Gauss–Seidel solve, periodically checking $J_{\\min}$ and applying the adaptive rescaling $(A,B) \\leftarrow (\\alpha A,\\alpha B)$ if $J_{\\min} \\le \\tau$, up to $N_{\\text{outer}}$ adaptive cycles. If positivity is not achieved, fall back to $(A,B)=(0,0)$ and perform one last inner solve to approach the harmonic mapping.\n- Return two quantities per test case: the final minimal Jacobian $J_{\\min}$ and the integer count of rescalings actually applied.\n\nUse the following test suite:\n- Case $1$: $(N_x,N_y)=(32,32)$, $(A_0,B_0)=(1.0,1.0)$, $\\tau=0.02$, $\\alpha=0.7$, $\\sigma=0.18$, $\\kappa=2.0$, $N_{\\text{inner}}=400$, $N_{\\text{outer}}=8$.\n- Case $2$: $(N_x,N_y)=(32,32)$, $(A_0,B_0)=(10.0,10.0)$, $\\tau=0.05$, $\\alpha=0.6$, $\\sigma=0.18$, $\\kappa=3.0$, $N_{\\text{inner}}=600$, $N_{\\text{outer}}=10$.\n- Case $3$: $(N_x,N_y)=(18,18)$, $(A_0,B_0)=(20.0,20.0)$, $\\tau=0.08$, $\\alpha=0.5$, $\\sigma=0.12$, $\\kappa=4.0$, $N_{\\text{inner}}=700$, $N_{\\text{outer}}=12$.\n- Case $4$: $(N_x,N_y)=(32,32)$, $(A_0,B_0)=(0.0,0.0)$, $\\tau=0.02$, $\\alpha=0.7$, $\\sigma=0.18$, $\\kappa=2.0$, $N_{\\text{inner}}=300$, $N_{\\text{outer}}=5$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with entries alternating between the final minimal Jacobian $J_{\\min}$ (as a floating-point number) and the rescale count (as an integer) for each case, in the order of the cases given. For example, the output format must be of the form $[J_{\\min}^{(1)},n_{\\text{rescale}}^{(1)},J_{\\min}^{(2)},n_{\\text{rescale}}^{(2)},J_{\\min}^{(3)},n_{\\text{rescale}}^{(3)},J_{\\min}^{(4)},n_{\\text{rescale}}^{(4)}]$.",
            "solution": "The problem requires the design and implementation of an adaptive algorithm for elliptic grid generation. The core task is to solve a system of Poisson equations on a computational domain, mapping it to a physical domain, while ensuring the grid does not fold. This non-folding constraint is enforced by maintaining a strictly positive Jacobian determinant, $J(\\xi,\\eta) > 0$, throughout the domain. This is achieved by adaptively adjusting the control functions, $P(\\xi,\\eta)$ and $Q(\\xi,\\eta)$, which influence the grid point distribution.\n\nThe foundation of the method is the system of two Poisson equations for the physical coordinates $(x, y)$ as functions of the computational coordinates $(\\xi, \\eta)$:\n$$\nx_{\\xi\\xi} + x_{\\eta\\eta} = P(\\xi,\\eta)\n$$\n$$\ny_{\\xi\\xi} + y_{\\eta\\eta} = Q(\\xi,\\eta)\n$$\nwhere $(\\xi, \\eta)$ are defined on the unit square $[0,1] \\times [0,1]$. A valid grid transformation requires that the Jacobian determinant, $J = x_{\\xi} y_{\\eta} - x_{\\eta} y_{\\xi}$, remains positive.\n\nWe will first derive the numerical scheme for solving these equations, then formulate the adaptive control algorithm, and finally detail the implementation steps.\n\n**1. Finite Difference Discretization and Gauss-Seidel Scheme**\n\nThe computational domain is discretized into a uniform lattice of $N_x \\times N_y$ points, with indices $(i,j)$, where $i \\in \\{0, 1, \\dots, N_x-1\\}$ and $j \\in \\{0, 1, \\dots, N_y-1\\}$. The corresponding computational coordinates are $\\xi_i = i \\cdot \\Delta\\xi$ and $\\eta_j = j \\cdot \\Delta\\eta$, with uniform spacings $\\Delta\\xi = 1/(N_x-1)$ and $\\Delta\\eta = 1/(N_y-1)$.\n\nThe second partial derivatives in the Poisson equations are approximated at interior grid points $(i,j)$ (for $i \\in [1, N_x-2]$ and $j \\in [1, N_y-2]$) using a second-order central difference formula:\n$$\n\\frac{\\partial^2 x}{\\partial \\xi^2} \\bigg|_{i,j} \\approx \\frac{x_{i+1,j} - 2x_{i,j} + x_{i-1,j}}{\\Delta\\xi^2}\n$$\n$$\n\\frac{\\partial^2 x}{\\partial \\eta^2} \\bigg|_{i,j} \\approx \\frac{x_{i,j+1} - 2x_{i,j} + x_{i,j-1}}{\\Delta\\eta^2}\n$$\nSubstituting these into the Poisson equation for $x$ yields the discrete equation:\n$$\n\\frac{x_{i+1,j} - 2x_{i,j} + x_{i-1,j}}{\\Delta\\xi^2} + \\frac{x_{i,j+1} - 2x_{i,j} + x_{i,j-1}}{\\Delta\\eta^2} = P_{i,j}\n$$\nTo derive the iterative update rule for the Gauss-Seidel method, we solve for the central point $x_{i,j}$:\n$$\nx_{i,j} \\left( \\frac{2}{\\Delta\\xi^2} + \\frac{2}{\\Delta\\eta^2} \\right) = \\frac{x_{i+1,j} + x_{i-1,j}}{\\Delta\\xi^2} + \\frac{x_{i,j+1} + x_{i,j-1}}{\\Delta\\eta^2} - P_{i,j}\n$$\n$$\nx_{i,j} = \\frac{1}{2\\left(\\frac{1}{\\Delta\\xi^2} + \\frac{1}{\\Delta\\eta^2}\\right)} \\left( \\frac{x_{i+1,j} + x_{i-1,j}}{\\Delta\\xi^2} + \\frac{x_{i,j+1} + x_{i,j-1}}{\\Delta\\eta^2} - P_{i,j} \\right)\n$$\nFor computational efficiency, we can simplify this expression. Let $\\beta = (\\Delta\\eta / \\Delta\\xi)^2$. Multiplying the numerator and denominator by $\\Delta\\eta^2$ gives:\n$$\nx_{i,j} = \\frac{\\Delta\\eta^2}{2(1 + \\beta)} \\left( \\frac{\\beta}{\\Delta\\eta^2}(x_{i+1,j} + x_{i-1,j}) + \\frac{1}{\\Delta\\eta^2}(x_{i,j+1} + x_{i,j-1}) - P_{i,j} \\right)\n$$\n$$\nx_{i,j} = \\frac{1}{2(1 + \\beta)} \\left( \\beta(x_{i+1,j} + x_{i-1,j}) + (x_{i,j+1} + x_{i,j-1}) - \\Delta\\eta^2 P_{i,j} \\right)\n$$\nThe Gauss-Seidel method updates $x_{i,j}$ and $y_{i,j}$ at each interior grid point in a sequential sweep, using the most recently computed values of neighboring points. The update equations for an iteration step are:\n$$\nx_{i,j}^{\\text{new}} = \\frac{1}{2(1 + \\beta)} \\left( \\beta(x_{i+1,j}^{\\text{old}} + x_{i-1,j}^{\\text{new}}) + (x_{i,j+1}^{\\text{old}} + x_{i,j-1}^{\\text{new}}) - \\Delta\\eta^2 P_{i,j} \\right)\n$$\n$$\ny_{i,j}^{\\text{new}} = \\frac{1}{2(1 + \\beta)} \\left( \\beta(y_{i+1,j}^{\\text{old}} + y_{i-1,j}^{\\text{new}}) + (y_{i,j+1}^{\\text{old}} + y_{i,j-1}^{\\text{new}}) - \\Delta\\eta^2 Q_{i,j} \\right)\n$$\nThis process is repeated for a specified number of iterations, $N_{\\text{inner}}$, until the solution for $x$ and $y$ converges toward the solution of the discrete Poisson system.\n\n**2. Grid Quality Control: Jacobian and Adaptive Control Functions**\n\nThe Jacobian determinant $J=x_\\xi y_\\eta - x_\\eta y_\\xi$ is a measure of the local mapping from computational to physical space. A negative or zero Jacobian indicates a folding of the grid, which is physically and numerically unacceptable.\n\nThe first derivatives are approximated at interior points $(i,j)$ using central differences:\n$$\nx_{\\xi}\\big|_{i,j} \\approx \\frac{x_{i+1,j}-x_{i-1,j}}{2\\Delta \\xi}, \\qquad x_{\\eta}\\big|_{i,j} \\approx \\frac{x_{i,j+1}-x_{i,j-1}}{2\\Delta \\eta}\n$$\nand similarly for $y_{\\xi}|_{i,j}$ and $y_{\\eta}|_{i,j}$. The discrete Jacobian is then:\n$$\nJ_{i,j} = \\left(\\frac{x_{i+1,j}-x_{i-1,j}}{2\\Delta \\xi}\\right) \\left(\\frac{y_{i,j+1}-y_{i,j-1}}{2\\Delta \\eta}\\right) - \\left(\\frac{x_{i,j+1}-x_{i,j-1}}{2\\Delta \\eta}\\right) \\left(\\frac{y_{i+1,j}-y_{i-1,j}}{2\\Delta \\xi}\\right)\n$$\nThe minimum Jacobian over the interior of the grid, $J_{\\min} = \\min_{i,j} J_{i,j}$, serves as the primary metric for grid quality.\n\nThe control functions $P$ and $Q$ are used to cluster grid lines. They are defined in terms of a monitor function $M(\\xi,\\eta)$:\n$$\nP(\\xi,\\eta) = A \\frac{\\partial M}{\\partial \\xi}, \\qquad Q(\\xi,\\eta) = B \\frac{\\partial M}{\\partial \\eta}\n$$\nThe specified monitor function is a Gaussian distribution:\n$$\nM(\\xi,\\eta) = 1 + \\kappa \\exp\\left(-\\frac{(\\xi-\\xi_c)^2 + (\\eta-\\eta_c)^2}{\\sigma^2}\\right)\n$$\nIts partial derivatives are:\n$$\n\\frac{\\partial M}{\\partial \\xi} = -\\frac{2\\kappa(\\xi-\\xi_c)}{\\sigma^2}\\exp\\left(-\\frac{(\\xi-\\xi_c)^2 + (\\eta-\\eta_c)^2}{\\sigma^2}\\right)\n$$\n$$\n\\frac{\\partial M}{\\partial \\eta} = -\\frac{2\\kappa(\\eta-\\eta_c)}{\\sigma^2}\\exp\\left(-\\frac{(\\xi-\\xi_c)^2 + (\\eta-\\eta_c)^2}{\\sigma^2}\\right)\n$$\nLarge values of the amplitudes $A$ and $B$ can lead to aggressive grid clustering, which in turn may cause $J_{\\min}$ to become non-positive.\n\n**3. The Adaptive Rescaling Algorithm**\n\nThe algorithm iteratively solves the Poisson system while monitoring $J_{\\min}$ and adjusting the control function amplitudes $A$ and $B$ to prevent grid folding. The procedure is as follows:\n\n1.  **Initialization**:\n    *   Discretize the computational domain and initialize the physical grid arrays $x$ and $y$.\n    *   Set the prescribed Dirichlet boundary conditions.\n    *   Provide an initial guess for the interior points of $x$ and $y$, typically by linear interpolation from the boundaries.\n    *   Compute the arrays for $\\frac{\\partial M}{\\partial \\xi}$ and $\\frac{\\partial M}{\\partial \\eta}$ over the grid.\n    *   Initialize the control amplitudes to their starting values, $(A,B) = (A_0, B_0)$, and set the rescale counter to $0$.\n\n2.  **Adaptive Outer Loop**: Iterate for a maximum of $N_{\\text{outer}}$ cycles. In each cycle:\n    *   a. **Update Control Functions**: Recalculate the source term arrays $P_{i,j}$ and $Q_{i,j}$ using the current values of $A$ and $B$.\n    *   b. **Iterative Solve (Inner Loop)**: Perform $N_{\\text{inner}}$ iterations of the Gauss-Seidel scheme to update the interior grid points $(x_{i,j}, y_{i,j})$.\n    *   c. **Jacobian Check**: Compute the Jacobian matrix $J_{i,j}$ over the interior grid and find its minimum value, $J_{\\min}$.\n    *   d. **Rescale**: If $J_{\\min} \\le \\tau$ (where $\\tau > 0$ is a safety threshold), the grid quality is insufficient. The control functions are too strong. We weaken them by a multiplicative factor $\\alpha \\in (0,1)$:\n       $$\n       (A, B) \\leftarrow (\\alpha A, \\alpha B)\n       $$\n       The count of rescalings is incremented. If $J_{\\min} > \\tau$, the amplitudes $(A,B)$ are kept for the next cycle.\n\n3.  **Fallback Mechanism**: After the $N_{\\text{outer}}$ cycles are complete, a final check is performed on the last computed $J_{\\min}$. If it is still less than or equal to $\\tau$, it signifies that the adaptive procedure failed to achieve the desired grid quality within the given constraints. In this case, a fallback to a harmonic grid is triggered:\n    *   Set $(A,B) = (0,0)$, which makes $P=0$ and $Q=0$. The system reduces to Laplace's equations.\n    *   Perform one final block of $N_{\\text{inner}}$ Gauss-Seidel iterations.\n    *   Recompute the final $J_{\\min}$. A harmonic map (solution to Laplace's equation) on a domain with non-self-intersecting boundaries is guaranteed to be non-folding, thus ensuring a positive Jacobian.\n\n4.  **Output**: For each test case, the final $J_{\\min}$ and the total number of multiplicative rescalings are reported.\n\nThis algorithm provides a robust method for generating grids that adapt to features specified by a monitor function while systematically preventing the grid-folding failures common with strong grid clustering.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_case(Nx, Ny, A0, B0, tau, alpha, sigma, kappa, N_inner, N_outer, xi_c, eta_c):\n    \"\"\"\n    Solves the elliptic grid generation problem for a single test case.\n    \"\"\"\n    # 1. Initialization\n    dxi = 1.0 / (Nx - 1)\n    deta = 1.0 / (Ny - 1)\n    xi = np.linspace(0.0, 1.0, Nx)\n    eta = np.linspace(0.0, 1.0, Ny)\n    XI, ETA = np.meshgrid(xi, eta, indexing='ij')\n\n    x = np.zeros((Nx, Ny))\n    y = np.zeros((Nx, Ny))\n\n    # 2. Set Boundary Conditions\n    # Bottom boundary (eta=0, j=0)\n    x[:, 0] = xi\n    y[:, 0] = 0.0\n    # Top boundary (eta=1, j=Ny-1)\n    x[:, Ny-1] = xi\n    y[:, Ny-1] = 1.0 + 0.2 * np.sin(2.0 * np.pi * xi)\n    # Left boundary (xi=0, i=0)\n    x[0, :] = 0.0\n    y[0, :] = eta\n    # Right boundary (xi=1, i=Nx-1)\n    x[Nx-1, :] = 1.0\n    y[Nx-1, :] = eta\n\n    # Initial guess for interior points (linear interpolation)\n    for j in range(1, Ny - 1):\n        for i in range(1, Nx - 1):\n            x[i, j] = x[i, 0] + ETA[i, j] * (x[i, Ny-1] - x[i, 0])\n            y[i, j] = y[0, j] + XI[i, j] * (y[Nx-1, j] - y[0, j])\n\n    # 3. Pre-compute monitor function derivatives\n    M_arg = -((XI - xi_c)**2 + (ETA - eta_c)**2) / (sigma**2)\n    M_exp = np.exp(M_arg)\n    dM_dxi = -2.0 * kappa * (XI - xi_c) / (sigma**2) * M_exp\n    dM_deta = -2.0 * kappa * (ETA - eta_c) / (sigma**2) * M_exp\n\n    # 4. Adaptive Rescaling Algorithm\n    A, B = A0, B0\n    rescale_count = 0\n    beta = (deta / dxi)**2\n    C = 1.0 / (2.0 * (1.0 + beta))\n    deta2 = deta**2\n\n    final_J_min = 0.0\n\n    for _ in range(N_outer):\n        # Update control functions P and Q\n        P = A * dM_dxi\n        Q = B * dM_deta\n\n        # Inner Gauss-Seidel iterations\n        for _ in range(N_inner):\n            x_old = x.copy()\n            y_old = y.copy()\n            for i in range(1, Nx - 1):\n                for j in range(1, Ny - 1):\n                    x[i, j] = C * (beta * (x_old[i+1, j] + x[i-1, j]) +\n                                   (x_old[i, j+1] + x[i, j-1]) -\n                                   deta2 * P[i, j])\n                    y[i, j] = C * (beta * (y_old[i+1, j] + y[i-1, j]) +\n                                   (y_old[i, j+1] + y[i, j-1]) -\n                                   deta2 * Q[i, j])\n        \n        # Jacobian calculation at interior points\n        x_xi = (x[2:, 1:-1] - x[:-2, 1:-1]) / (2 * dxi)\n        x_eta = (x[1:-1, 2:] - x[1:-1, :-2]) / (2 * deta)\n        y_xi = (y[2:, 1:-1] - y[:-2, 1:-1]) / (2 * dxi)\n        y_eta = (y[1:-1, 2:] - y[1:-1, :-2]) / (2 * deta)\n        \n        J = x_xi * y_eta - x_eta * y_xi\n        J_min = np.min(J)\n        final_J_min = J_min\n\n        # Adaptive step\n        if J_min <= tau:\n            A *= alpha\n            B *= alpha\n            rescale_count += 1\n            \n    # 5. Fallback Mechanism if positivity is not achieved\n    if final_J_min <= tau:\n        A, B = 0.0, 0.0\n        P = A * dM_dxi # Now zero\n        Q = B * dM_deta # Now zero\n        # Final inner solve for Laplace's equation\n        for _ in range(N_inner):\n            x_old = x.copy()\n            y_old = y.copy()\n            for i in range(1, Nx - 1):\n                for j in range(1, Ny - 1):\n                    x[i, j] = C * (beta * (x_old[i+1, j] + x[i-1, j]) +\n                                   (x_old[i, j+1] + x[i, j-1]) -\n                                   deta2 * P[i, j])\n                    y[i, j] = C * (beta * (y_old[i+1, j] + y[i-1, j]) +\n                                   (y_old[i, j+1] + y[i, j-1]) -\n                                   deta2 * Q[i, j])\n        \n        # Re-compute final Jacobian\n        x_xi = (x[2:, 1:-1] - x[:-2, 1:-1]) / (2 * dxi)\n        x_eta = (x[1:-1, 2:] - x[1:-1, :-2]) / (2 * deta)\n        y_xi = (y[2:, 1:-1] - y[:-2, 1:-1]) / (2 * dxi)\n        y_eta = (y[1:-1, 2:] - y[1:-1, :-2]) / (2 * deta)\n        \n        J = x_xi * y_eta - x_eta * y_xi\n        final_J_min = np.min(J)\n        \n    return final_J_min, rescale_count\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {'Nx': 32, 'Ny': 32, 'A0': 1.0, 'B0': 1.0, 'tau': 0.02, 'alpha': 0.7,\n         'sigma': 0.18, 'kappa': 2.0, 'N_inner': 400, 'N_outer': 8},\n        # Case 2\n        {'Nx': 32, 'Ny': 32, 'A0': 10.0, 'B0': 10.0, 'tau': 0.05, 'alpha': 0.6,\n         'sigma': 0.18, 'kappa': 3.0, 'N_inner': 600, 'N_outer': 10},\n        # Case 3\n        {'Nx': 18, 'Ny': 18, 'A0': 20.0, 'B0': 20.0, 'tau': 0.08, 'alpha': 0.5,\n         'sigma': 0.12, 'kappa': 4.0, 'N_inner': 700, 'N_outer': 12},\n        # Case 4\n        {'Nx': 32, 'Ny': 32, 'A0': 0.0, 'B0': 0.0, 'tau': 0.02, 'alpha': 0.7,\n         'sigma': 0.18, 'kappa': 2.0, 'N_inner': 300, 'N_outer': 5},\n    ]\n\n    results = []\n    monitor_center = (0.5, 0.85)\n\n    for case in test_cases:\n        J_min, n_rescale = run_case(\n            Nx=case['Nx'], Ny=case['Ny'],\n            A0=case['A0'], B0=case['B0'],\n            tau=case['tau'], alpha=case['alpha'],\n            sigma=case['sigma'], kappa=case['kappa'],\n            N_inner=case['N_inner'], N_outer=case['N_outer'],\n            xi_c=monitor_center[0], eta_c=monitor_center[1]\n        )\n        results.append(f\"{J_min:.8f}\")\n        results.append(str(n_rescale))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "In real-world fluid dynamics simulations, the treatment of boundaries is critical, and the grid must conform to the physics being modeled. This exercise explores the practical impact of boundary conditions on grid structure, focusing on the use of Neumann conditions often employed at outflow boundaries in CFD. By numerically solving the Laplace equations for different outflow specifications , you will gain direct insight into how boundary data propagates into the domain, affecting local grid orthogonality and spacing, which are crucial for solution accuracy.",
            "id": "3956912",
            "problem": "You are asked to analyze the near-boundary behavior of an elliptic grid generated by Poisson equations in the context of Computational Fluid Dynamics (CFD). Consider a smooth mapping from a computational domain to a physical domain, defined by two scalar fields $x(\\xi,\\eta)$ and $y(\\xi,\\eta)$, where $(\\xi,\\eta) \\in [0,1] \\times [0,1]$ are dimensionless computational coordinates and $(x,y)$ are physical coordinates in meters. The physical domain is a rectangle of width $L_x$ and height $L_y$. The grid is generated by solving the Poisson form of elliptic grid generation equations with zero control functions, namely\n$$\nx_{\\xi\\xi} + x_{\\eta\\eta} = 0, \\quad y_{\\xi\\xi} + y_{\\eta\\eta} = 0,\n$$\nsubject to Dirichlet boundary conditions on three sides and Neumann boundary conditions on the outflow boundary:\n- Bottom boundary ($\\eta=0$): $x(\\xi,0) = L_x \\,\\xi$, $y(\\xi,0) = 0$.\n- Left boundary ($\\xi=0$): $x(0,\\eta) = 0$, $y(0,\\eta) = L_y \\,\\eta$.\n- Right boundary ($\\xi=1$): $x(1,\\eta) = L_x$, $y(1,\\eta) = L_y \\,\\eta$.\n- Outflow boundary (top, $\\eta=1$): constant Neumann data $x_\\eta(\\xi,1) = s_x$, $y_\\eta(\\xi,1) = s_y$, where $s_x$ and $s_y$ are prescribed constants.\n\nYour task is to:\n1. Solve the above boundary value problem numerically using a finite difference discretization on a uniform grid with $N_\\xi$ points in the $\\xi$ direction and $N_\\eta$ points in the $\\eta$ direction. Use Successive Over-Relaxation for iterative solution until a convergence criterion is met.\n2. Compute the near-boundary orthogonality metric and spacing metric along the first interior row beneath the outflow boundary:\n   - Define the metric vectors $ \\mathbf{g}_\\xi = (x_\\xi, y_\\xi)$ and $ \\mathbf{g}_\\eta = (x_\\eta, y_\\eta)$, approximating derivatives with central differences.\n   - Orthogonality metric at a grid point is\n     $$\n     \\mathcal{O} = \\frac{\\left| \\mathbf{g}_\\xi \\cdot \\mathbf{g}_\\eta \\right|}{\\lVert \\mathbf{g}_\\xi \\rVert \\,\\lVert \\mathbf{g}_\\eta \\rVert},\n     $$\n     which lies in $[0,1]$ and equals $0$ for perfectly orthogonal coordinate lines.\n   - Spacing metric is the mean value of $\\lVert \\mathbf{g}_\\eta \\rVert$ in meters along the same interior row, which quantifies average physical spacing of adjacent $\\eta$-coordinate lines.\n3. For each test case, output the mean orthogonality metric $\\overline{\\mathcal{O}}$ and mean spacing $\\overline{s}$ computed across all interior points on the row immediately below the outflow boundary (i.e., at $\\eta = 1 - \\Delta \\eta$). The spacing must be expressed in meters.\n\nUse the following fixed physical and numerical parameters across all test cases:\n- Physical dimensions: $L_x = 1.0$ meters, $L_y = 0.5$ meters.\n- Grid resolution: $N_\\xi = 31$, $N_\\eta = 31$.\n- Relaxation parameter: $\\omega = 1.8$.\n- Convergence tolerance: maximum absolute change per iteration less than $10^{-10}$.\n- Maximum iterations: $8000$.\n- Discrete Neumann enforcement at the outflow boundary: for interior $i$, impose $x(i,N_\\eta-1) = x(i,N_\\eta-2) + s_x \\,\\Delta \\eta$ and $y(i,N_\\eta-1) = y(i,N_\\eta-2) + s_y \\,\\Delta \\eta$, where $\\Delta \\eta = 1/(N_\\eta-1)$, while corner points at $(\\xi=0,\\eta=1)$ and $(\\xi=1,\\eta=1)$ retain Dirichlet values.\n\nTest suite:\n- Case 1 (baseline orthogonality and spacing): $s_x = 0.0$ meters, $s_y = L_y$ meters.\n- Case 2 (intentional skew for reduced orthogonality): $s_x = 0.2\\,L_x$ meters, $s_y = L_y$ meters.\n- Case 3 (compressed spacing near outflow): $s_x = 0.0$ meters, $s_y = 0.5\\,L_y$ meters.\n- Case 4 (expanded spacing near outflow): $s_x = 0.0$ meters, $s_y = 1.5\\,L_y$ meters.\n\nFinal output specification:\n- Your program should produce a single line of output containing eight comma-separated floating-point numbers enclosed in square brackets, corresponding to $[\\overline{\\mathcal{O}}_1,\\overline{s}_1,\\overline{\\mathcal{O}}_2,\\overline{s}_2,\\overline{\\mathcal{O}}_3,\\overline{s}_3,\\overline{\\mathcal{O}}_4,\\overline{s}_4]$, where indices refer to the test cases in the order listed above. The spacing values must be in meters. Round each value to six decimal places.",
            "solution": "The problem requires the numerical solution of a pair of Laplace equations, $x_{\\xi\\xi} + x_{\\eta\\eta} = 0$ and $y_{\\xi\\xi} + y_{\\eta\\eta} = 0$, on a computational unit square domain $(\\xi, \\eta) \\in [0,1] \\times [0,1]$. These equations map the computational grid to a physical grid $(x,y)$. The solution is subject to mixed Dirichlet and Neumann boundary conditions. The goal is to compute grid quality metrics for different outflow conditions.\n\nFirst, we discretize the governing partial differential equations (PDEs) using a finite difference method. The computational domain is covered by a uniform grid with $N_\\xi = 31$ and $N_\\eta = 31$ points. The grid spacings in the computational domain are $\\Delta\\xi = 1/(N_\\xi-1)$ and $\\Delta\\eta = 1/(N_\\eta-1)$. Since $N_\\xi = N_\\eta$, we have $\\Delta\\xi = \\Delta\\eta$. Let $x_{i,j} = x(i\\Delta\\xi, j\\Delta\\eta)$ and $y_{i,j} = y(i\\Delta\\xi, j\\Delta\\eta)$ be the physical coordinates at grid node $(i,j)$.\n\nThe second partial derivatives are approximated using a second-order central difference formula. For a generic function $f(\\xi,\\eta)$, the derivatives at grid point $(i,j)$ are:\n$$\nf_{\\xi\\xi}\\Big|_{i,j} \\approx \\frac{f_{i+1,j} - 2f_{i,j} + f_{i-1,j}}{(\\Delta\\xi)^2}\n$$\n$$\nf_{\\eta\\eta}\\Big|_{i,j} \\approx \\frac{f_{i,j+1} - 2f_{i,j} + f_{i,j-1}}{(\\Delta\\eta)^2}\n$$\nSubstituting these into the Laplace equation for $x$ (and similarly for $y$), we obtain:\n$$\n\\frac{x_{i+1,j} - 2x_{i,j} + x_{i-1,j}}{(\\Delta\\xi)^2} + \\frac{x_{i,j+1} - 2x_{i,j} + x_{i,j-1}}{(\\Delta\\eta)^2} = 0\n$$\nSince $\\Delta\\xi = \\Delta\\eta$, this equation simplifies upon solving for $x_{i,j}$, yielding the classic 5-point stencil average for the Laplacian:\n$$\nx_{i,j} = \\frac{1}{4} (x_{i+1,j} + x_{i-1,j} + x_{i,j+1} + x_{i,j-1})\n$$\nThis linear algebraic equation relates the value at each interior grid point to its four nearest neighbors. A similar equation holds for $y_{i,j}$.\n\nThis system of linear equations is solved iteratively using the Successive Over-Relaxation (SOR) method. Let $x_{i,j}^{(k)}$ be the value at iteration $k$. The update for iteration $k+1$ proceeds in two steps. First, a provisional Gauss-Seidel value, $\\tilde{x}_{i,j}$, is calculated using the most recently updated values:\n$$\n\\tilde{x}_{i,j}^{(k+1)} = \\frac{1}{4} \\left(x_{i+1,j}^{(k)} + x_{i-1,j}^{(k+1)} + x_{i,j+1}^{(k)} + x_{i,j-1}^{(k+1)}\\right)\n$$\nwhere we assume a standard row-by-row, column-by-column sweep. Then, this value is blended with the value from the previous iteration using the relaxation parameter $\\omega = 1.8$:\n$$\nx_{i,j}^{(k+1)} = (1-\\omega)x_{i,j}^{(k)} + \\omega \\tilde{x}_{i,j}^{(k+1)}\n$$\nThe procedure is identical for $y_{i,j}$.\n\nThe boundary conditions are applied as follows:\n- On the Dirichlet boundaries (bottom: $\\eta=0$; left: $\\xi=0$; right: $\\xi=1$), the values of $x_{i,j}$ and $y_{i,j}$ are fixed for all iterations according to the problem specification: $x(\\xi,0) = L_x \\xi$, $y(\\xi,0) = 0$; $x(0,\\eta) = 0$, $y(0,\\eta) = L_y \\eta$; $x(1,\\eta) = L_x$, $y(1,\\eta) = L_y \\eta$.\n- On the Neumann boundary (top: $\\eta=1$), the condition on the normal derivative is enforced. For $x_\\eta(\\xi,1) = s_x$, we use a first-order forward difference approximation at the boundary nodes $j = N_\\eta-1$:\n$$\n\\frac{x_{i, N_\\eta-1} - x_{i, N_\\eta-2}}{\\Delta\\eta} = s_x\n$$\nThis gives an update rule for the boundary values, $x_{i, N_\\eta-1} = x_{i, N_\\eta-2} + s_x \\Delta\\eta$, which is applied for all interior points $i \\in [1, N_\\xi-2]$ within each SOR iteration. A similar rule applies for $y$. As specified, corner points retain their Dirichlet values.\n\nThe iterative process continues until the maximum absolute change in any grid coordinate between successive iterations falls below a tolerance of $10^{-10}$, i.e., $\\max(|x^{(k+1)}-x^{(k)}|, |y^{(k+1)}-y^{(k)}|) < 10^{-10}$.\n\nUpon convergence, we compute the grid quality metrics on the first interior row below the outflow boundary, i.e., at $\\eta = 1-\\Delta\\eta$ (grid index $j = N_\\eta-2$), for all interior points $i \\in [1, N_\\xi-2]$. The metric vectors $\\mathbf{g}_\\xi = (x_\\xi, y_\\xi)$ and $\\mathbf{g}_\\eta = (x_\\eta, y_\\eta)$ are computed using second-order central differences:\n$$\nx_\\xi\\Big|_{i,j} = \\frac{x_{i+1,j} - x_{i-1,j}}{2\\Delta\\xi}, \\quad y_\\xi\\Big|_{i,j} = \\frac{y_{i+1,j} - y_{i-1,j}}{2\\Delta\\xi}\n$$\n$$\nx_\\eta\\Big|_{i,j} = \\frac{x_{i,j+1} - x_{i,j-1}}{2\\Delta\\eta}, \\quad y_\\eta\\Big|_{i,j} = \\frac{y_{i,j+1} - y_{i,j-1}}{2\\Delta\\eta}\n$$\nThe orthogonality metric $\\mathcal{O}$ and spacing metric (norm of $\\mathbf{g}_\\eta$) at each point are:\n$$\n\\mathcal{O}_{i,j} = \\frac{\\left| \\mathbf{g}_\\xi \\cdot \\mathbf{g}_\\eta \\right|}{\\lVert \\mathbf{g}_\\xi \\rVert \\,\\lVert \\mathbf{g}_\\eta \\rVert} = \\frac{|x_\\xi x_\\eta + y_\\xi y_\\eta|}{\\sqrt{x_\\xi^2+y_\\xi^2}\\sqrt{x_\\eta^2+y_\\eta^2}}, \\quad s_{i,j} = \\lVert \\mathbf{g}_\\eta \\rVert = \\sqrt{x_\\eta^2 + y_\\eta^2}\n$$\nThe final reported values, $\\overline{\\mathcal{O}}$ and $\\overline{s}$, are the arithmetic means of $\\mathcal{O}_{i,j}$ and $s_{i,j}$ respectively, averaged over the interior points $i \\in [1, N_\\xi-2]$ on the row $j = N_\\eta-2$. This procedure is repeated for each of the four test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_grid_and_get_metrics(Lx, Ly, N_xi, N_eta, sx, sy, omega, tol, max_iter):\n    \"\"\"\n    Solves the elliptic grid generation problem and computes metrics.\n    \"\"\"\n    # 1. Grid Setup\n    d_xi = 1.0 / (N_xi - 1)\n    d_eta = 1.0 / (N_eta - 1)\n    \n    xi = np.linspace(0, 1, N_xi)\n    eta = np.linspace(0, 1, N_eta)\n\n    x = np.zeros((N_eta, N_xi))\n    y = np.zeros((N_eta, N_xi))\n\n    # 2. Boundary Conditions\n    # Dirichlet BCs on bottom, left, and right boundaries\n    x[0, :] = Lx * xi\n    y[0, :] = 0.0\n    \n    x[:, 0] = 0.0\n    y[:, 0] = Ly * eta\n    \n    x[:, N_xi - 1] = Lx\n    y[:, N_xi - 1] = Ly * eta\n\n    # 3. Iterative Solver (SOR)\n    # The coefficient for the simplified 5-point stencil is 0.25 since d_xi = d_eta\n    stencil_coeff = 0.25\n\n    for k in range(max_iter):\n        x_old = x.copy()\n        y_old = y.copy()\n\n        # Update interior points (j from 1 to N_eta-2, i from 1 to N_xi-2)\n        for j in range(1, N_eta - 1):\n            for i in range(1, N_xi - 1):\n                # Gauss-Seidel intermediate value calculation\n                x_gs = stencil_coeff * (x[j, i+1] + x[j, i-1] + x[j+1, i] + x[j-1, i])\n                y_gs = stencil_coeff * (y[j, i+1] + y[j, i-1] + y[j+1, i] + y[j-1, i])\n                \n                # SOR update\n                x[j, i] = (1 - omega) * x_old[j, i] + omega * x_gs\n                y[j, i] = (1 - omega) * y_old[j, i] + omega * y_gs\n        \n        # Update top Neumann boundary (interior nodes: i from 1 to N_xi-2)\n        for i in range(1, N_xi - 1):\n            x[N_eta - 1, i] = x[N_eta - 2, i] + sx * d_eta\n            y[N_eta - 1, i] = y[N_eta - 2, i] + sy * d_eta\n            \n        # Check for convergence\n        max_change = max(np.max(np.abs(x - x_old)), np.max(np.abs(y - y_old)))\n        \n        if max_change < tol:\n            break\n\n    # 4. Metric Calculation\n    # Metrics are computed on the interior row just below the outflow (j = N_eta - 2)\n    j_row = N_eta - 2\n    ortho_metrics = []\n    spacing_metrics = []\n\n    # Iterate over interior points of that row (i from 1 to N_xi-2)\n    for i in range(1, N_xi - 1):\n        # Central differences for derivatives\n        x_xi = (x[j_row, i+1] - x[j_row, i-1]) / (2 * d_xi)\n        y_xi = (y[j_row, i+1] - y[j_row, i-1]) / (2 * d_xi)\n        x_eta = (x[j_row+1, i] - x[j_row-1, i]) / (2 * d_eta)\n        y_eta = (y[j_row+1, i] - y[j_row-1, i]) / (2 * d_eta)\n\n        # Metric vector components\n        g_xi_dot_g_eta = x_xi * x_eta + y_xi * y_eta\n        norm_g_xi = np.sqrt(x_xi**2 + y_xi**2)\n        norm_g_eta = np.sqrt(x_eta**2 + y_eta**2)\n\n        # Orthogonality metric\n        if norm_g_xi > 1e-12 and norm_g_eta > 1e-12: # Avoid division by zero\n            ortho = np.abs(g_xi_dot_g_eta) / (norm_g_xi * norm_g_eta)\n        else:\n            ortho = 0.0 # Define as 0 for degenerate cases\n        ortho_metrics.append(ortho)\n        \n        # Spacing metric is the norm of g_eta\n        spacing_metrics.append(norm_g_eta)\n\n    # Compute mean values\n    mean_ortho = np.mean(ortho_metrics)\n    mean_spacing = np.mean(spacing_metrics)\n\n    return mean_ortho, mean_spacing\n\n\ndef solve():\n    # Define the fixed physical and numerical parameters from the problem statement.\n    Lx = 1.0\n    Ly = 0.5\n    N_xi = 31\n    N_eta = 31\n    omega = 1.8\n    tol = 1e-10\n    max_iter = 8000\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (s_x, s_y)\n        (0.0, Ly),                  # Case 1\n        (0.2 * Lx, Ly),             # Case 2\n        (0.0, 0.5 * Ly),            # Case 3\n        (0.0, 1.5 * Ly)             # Case 4\n    ]\n\n    results = []\n    for sx, sy in test_cases:\n        mean_ortho, mean_spacing = solve_grid_and_get_metrics(Lx, Ly, N_xi, N_eta, sx, sy, omega, tol, max_iter)\n        results.extend([mean_ortho, mean_spacing])\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{v:.6f}\" for v in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}