{
    "hands_on_practices": [
        {
            "introduction": "To build robust numerical solvers, we must first understand the structure of the equations we aim to solve. This exercise takes us back to first principles, where we will explicitly construct the nonlinear residual for a cell from the governing conservation laws and a chosen numerical flux. By then linearizing this residual around a constant state, you will derive the local Jacobian matrix, which is the fundamental building block of the large linear systems solved in implicit methods, and verify a key property of conservative schemes.",
            "id": "3973376",
            "problem": "Consider the compressible Euler equations in one spatial dimension for an ideal gas with ratio of specific heats $\\gamma$. Let the conservative state vector be $U = (\\rho, \\rho u, \\rho E)^{\\mathsf{T}}$, where $\\rho$ is density, $u$ is velocity, and $E$ is specific total energy. The pressure is given by the ideal-gas relation $p = (\\gamma - 1)\\left(\\rho E - \\tfrac{1}{2}\\rho u^{2}\\right)$. The physical flux function is $F(U) = \\left(\\rho u, \\rho u^{2} + p, u(\\rho E + p)\\right)^{\\mathsf{T}}$. On a uniform mesh of cells indexed by $i$ with spacing $\\Delta x$, define the semi-discrete finite-volume residual for cell $i$ as $R_{i}(U) = \\frac{1}{\\Delta x}\\left(\\hat{F}_{i+\\tfrac{1}{2}} - \\hat{F}_{i-\\tfrac{1}{2}}\\right)$, where $\\hat{F}_{i+\\tfrac{1}{2}}$ is a consistent numerical flux computed from left and right states at the interface $i+\\tfrac{1}{2}$. Use the Local Lax–Friedrichs (LLF) upwind numerical flux for the Euler equations, defined for an interface with left state $U_{L}$ and right state $U_{R}$ by\n$$\n\\hat{F}(U_{L}, U_{R}) = \\frac{1}{2}\\left(F(U_{L}) + F(U_{R})\\right) - \\frac{1}{2}\\alpha(U_{L}, U_{R})\\left(U_{R} - U_{L}\\right),\n$$\nwhere $\\alpha(U_{L}, U_{R})$ is any upper bound on the spectral radius of the flux Jacobian evaluated at $(U_{L}, U_{R})$, for example $\\alpha(U_{L}, U_{R}) = \\max\\left(|u_{L}| + a_{L}, |u_{R}| + a_{R}\\right)$ with sound speed $a = \\sqrt{\\gamma p / \\rho}$. \n\nTasks:\n- Starting from conservation form and the LLF flux definition, write $R_{i}(U)$ explicitly in terms of $(U_{i-1}, U_{i}, U_{i+1})$, $F(\\cdot)$, and $\\alpha(\\cdot,\\cdot)$ on the uniform mesh.\n- Perform a first-order linearization of $R_{i}(U)$ about a uniform constant state $U^{\\ast}$ (i.e., $U_{j} \\equiv U^{\\ast}$ for all $j$), assuming the dissipation coefficient is frozen at its constant value $\\alpha^{\\ast} = \\alpha(U^{\\ast}, U^{\\ast})$. Denote the physical flux Jacobian at $U^{\\ast}$ by $A^{\\ast} = \\partial F/\\partial U \\big|_{U^{\\ast}}$. Derive the block tridiagonal Jacobian contributions $\\partial R_{i}/\\partial U_{i-1}$, $\\partial R_{i}/\\partial U_{i}$, and $\\partial R_{i}/\\partial U_{i+1}$ in terms of $A^{\\ast}$, $\\alpha^{\\ast}$, and $\\Delta x$, and verify the discrete conservation property for constant perturbations.\n- Evaluate $R_{i}(U^{\\ast})$ for the uniform constant state $U^{\\ast}$, and provide the result as a single $3$-component row matrix using the $\\mathrm{pmatrix}$ environment. \n\nNo numerical substitution is required. This problem is situated within Computational Fluid Dynamics (CFD) practice and aims to connect conservation laws to linearization of nonlinear residuals. Your final answer must be the evaluated residual vector $R_{i}(U^{\\ast})$ expressed symbolically as requested, with no units.",
            "solution": "The problem presents three tasks concerning the semi-discrete finite-volume residual for the one-dimensional compressible Euler equations. We will address each task sequentially.\n\n**Task 1: Explicit form of the residual $R_i(U)$**\n\nThe semi-discrete residual for a cell indexed by $i$ on a uniform mesh with spacing $\\Delta x$ is defined as:\n$$\nR_{i}(U) = \\frac{1}{\\Delta x}\\left(\\hat{F}_{i+\\tfrac{1}{2}} - \\hat{F}_{i-\\tfrac{1}{2}}\\right)\n$$\nFor a first-order spatial scheme, the numerical flux $\\hat{F}_{i+\\frac{1}{2}}$ at the interface between cells $i$ and $i+1$ is a function of the cell-average states $U_i$ and $U_{i+1}$. Similarly, the flux $\\hat{F}_{i-\\frac{1}{2}}$ at the interface between cells $i-1$ and $i$ is a function of $U_{i-1}$ and $U_i$.\n\nThe provided Local Lax–Friedrichs (LLF) numerical flux is defined as:\n$$\n\\hat{F}(U_{L}, U_{R}) = \\frac{1}{2}\\left(F(U_{L}) + F(U_{R})\\right) - \\frac{1}{2}\\alpha(U_{L}, U_{R})\\left(U_{R} - U_{L}\\right)\n$$\nwhere $F(\\cdot)$ is the physical flux function and $\\alpha(\\cdot, \\cdot)$ is a dissipation coefficient.\n\nFor the interface at $i+\\frac{1}{2}$, the left and right states are $U_L = U_i$ and $U_R = U_{i+1}$. The corresponding numerical flux is:\n$$\n\\hat{F}_{i+\\tfrac{1}{2}} = \\hat{F}(U_i, U_{i+1}) = \\frac{1}{2}\\left(F(U_i) + F(U_{i+1})\\right) - \\frac{1}{2}\\alpha(U_i, U_{i+1})\\left(U_{i+1} - U_i\\right)\n$$\nFor the interface at $i-\\frac{1}{2}$, the left and right states are $U_L = U_{i-1}$ and $U_R = U_i$. The corresponding numerical flux is:\n$$\n\\hat{F}_{i-\\tfrac{1}{2}} = \\hat{F}(U_{i-1}, U_i) = \\frac{1}{2}\\left(F(U_{i-1}) + F(U_i)\\right) - \\frac{1}{2}\\alpha(U_{i-1}, U_i)\\left(U_i - U_{i-1}\\right)\n$$\nSubstituting these expressions into the definition of the residual $R_i(U)$, we obtain its explicit form as a function of the states in the three-cell stencil $(U_{i-1}, U_i, U_{i+1})$:\n$$\nR_{i}(U) = \\frac{1}{\\Delta x} \\left[ \\left(\\frac{1}{2}\\left(F(U_i) + F(U_{i+1})\\right) - \\frac{1}{2}\\alpha(U_i, U_{i+1})\\left(U_{i+1} - U_i\\right)\\right) - \\left(\\frac{1}{2}\\left(F(U_{i-1}) + F(U_i)\\right) - \\frac{1}{2}\\alpha(U_{i-1}, U_i)\\left(U_i - U_{i-1}\\right)\\right) \\right]\n$$\nThis expression can be rearranged to highlight the centered difference and dissipation terms:\n$$\nR_{i}(U) = \\frac{F(U_{i+1}) - F(U_{i-1})}{2\\Delta x} - \\frac{1}{2\\Delta x} \\left[ \\alpha_{i+1/2}\\left(U_{i+1} - U_i\\right) - \\alpha_{i-1/2}\\left(U_i - U_{i-1}\\right) \\right]\n$$\n\n**Task 2: Linearization of $R_i(U)$ and verification of conservation**\n\nWe now linearize $R_i(U)$ about a uniform constant state $U^*$, where $U_j \\equiv U^*$ for all cell indices $j$. The problem specifies that the dissipation coefficient $\\alpha$ should be \"frozen\" at its constant value for this uniform state: $\\alpha(U_L, U_R) \\approx \\alpha(U^*, U^*) \\equiv \\alpha^*$. This means derivatives of $\\alpha$ are not considered. Let $A^* = \\frac{\\partial F}{\\partial U}\\big|_{U^*}$ be the physical flux Jacobian at state $U^*$.\n\nWe compute the partial derivatives of $R_i$ with respect to $U_{i-1}$, $U_i$, and $U_{i+1}$ by differentiating the numerical fluxes.\nThe derivative of the residual $R_i = \\frac{1}{\\Delta x}(\\hat{F}_{i+1/2} - \\hat{F}_{i-1/2})$ with respect to $U_{i-1}$ only involves the term $\\hat{F}_{i-1/2}$.\n$$\n\\frac{\\partial R_i}{\\partial U_{i-1}}\\bigg|_{U^*} = -\\frac{1}{\\Delta x} \\frac{\\partial \\hat{F}_{i-1/2}}{\\partial U_{i-1}}\\bigg|_{U^*} = -\\frac{1}{\\Delta x} \\left( \\frac{1}{2}A^* - \\frac{1}{2}\\alpha^*(-I) \\right) = \\frac{1}{2\\Delta x}(-A^* - \\alpha^*I)\n$$\nThe derivative with respect to $U_{i+1}$ only involves $\\hat{F}_{i+1/2}$.\n$$\n\\frac{\\partial R_i}{\\partial U_{i+1}}\\bigg|_{U^*} = \\frac{1}{\\Delta x} \\frac{\\partial \\hat{F}_{i+1/2}}{\\partial U_{i+1}}\\bigg|_{U^*} = \\frac{1}{\\Delta x} \\left( \\frac{1}{2}A^* - \\frac{1}{2}\\alpha^*(I) \\right) = \\frac{1}{2\\Delta x}(A^* - \\alpha^*I)\n$$\nThe derivative with respect to $U_i$ involves both fluxes.\n$$\n\\frac{\\partial R_i}{\\partial U_i}\\bigg|_{U^*} = \\frac{1}{\\Delta x}\\left(\\frac{\\partial \\hat{F}_{i+1/2}}{\\partial U_i} - \\frac{\\partial \\hat{F}_{i-1/2}}{\\partial U_i}\\right) = \\frac{1}{\\Delta x}\\left( \\left(\\frac{1}{2}A^* - \\frac{1}{2}\\alpha^*(-I)\\right) - \\left(\\frac{1}{2}A^* - \\frac{1}{2}\\alpha^*(I)\\right) \\right) = \\frac{1}{\\Delta x}\\left(\\frac{\\alpha^*}{2}I + \\frac{\\alpha^*}{2}I\\right) = \\frac{\\alpha^*}{\\Delta x}I\n$$\nTo verify the discrete conservation property for constant perturbations, we sum the Jacobian contributions for cell $i$ over its stencil:\n$$\n\\sum_{j} \\frac{\\partial R_i}{\\partial U_j} = \\frac{\\partial R_i}{\\partial U_{i-1}} + \\frac{\\partial R_i}{\\partial U_i} + \\frac{\\partial R_i}{\\partial U_{i+1}}\n$$\n$$\n= \\frac{1}{2\\Delta x} \\left( -A^* - \\alpha^* I \\right) + \\frac{2\\alpha^*}{2\\Delta x} I + \\frac{1}{2\\Delta x} \\left( A^* - \\alpha^* I \\right)\n$$\n$$\n= \\frac{1}{2\\Delta x} \\left[ (-A^* + A^*) + (-\\alpha^* + 2\\alpha^* - \\alpha^*)I \\right] = 0\n$$\nThe sum is the zero matrix, which confirms the discrete conservation property. This property ensures that a constant perturbation to the solution does not change the sum of residuals over the domain.\n\n**Task 3: Evaluation of $R_i(U^*)$**\n\nFinally, we evaluate the residual $R_i(U)$ for the uniform constant state $U^*$, where $U_{j} = U^*$ for $j \\in \\{i-1, i, i+1\\}$.\nWe start with the definition:\n$$\nR_i(U^*) = \\frac{1}{\\Delta x}\\left(\\hat{F}_{i+\\tfrac{1}{2}} - \\hat{F}_{i-\\tfrac{1}{2}}\\right)\n$$\nThe numerical flux at interface $i+\\frac{1}{2}$ has identical left and right states, $U_L=U_R=U^*$:\n$$\n\\hat{F}_{i+\\tfrac{1}{2}} = \\hat{F}(U^*, U^*) = \\frac{1}{2}\\left(F(U^*) + F(U^*)\\right) - \\frac{1}{2}\\alpha(U^*, U^*)\\left(U^* - U^*\\right)\n$$\n$$\n\\hat{F}_{i+\\tfrac{1}{2}} = \\frac{1}{2}\\left(2F(U^*)\\right) - 0 = F(U^*)\n$$\nThis is the consistency property of the numerical flux: $\\hat{F}(U, U) = F(U)$.\nBy the same logic, the numerical flux at interface $i-\\frac{1}{2}$ is also $F(U^*)$:\n$$\n\\hat{F}_{i-\\tfrac{1}{2}} = \\hat{F}(U^*, U^*) = F(U^*)\n$$\nSubstituting these back into the residual expression:\n$$\nR_i(U^*) = \\frac{1}{\\Delta x} \\left[ F(U^*) - F(U^*) \\right] = \\frac{1}{\\Delta x} (0) = 0\n$$\nThe result is the zero vector of dimension $3$. This is a fundamental consistency requirement known as freestream preservation: a uniform flow must yield a zero residual, indicating it is a steady-state solution of the discrete equations. The result, expressed as a $3$-component row matrix, is $(0, 0, 0)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0 & 0 & 0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The theoretical convergence rate of Newton's method is a powerful concept, but its practical realization depends entirely on the accuracy of the Jacobian matrix. This computational practice moves from theory to application, asking you to implement a Newton solver for a simplified transonic flow problem and observe the results. By experimenting with exact, approximate, and frozen Jacobians, you will directly witness how the quality of the linearization impacts the solver's convergence speed, providing tangible insight into the trade-offs between computational cost and performance.",
            "id": "3973418",
            "problem": "Consider steady, inviscid, isentropic, compressible flow along a thin streamtube wrapped around an airfoil in a transonic regime. In Computational Fluid Dynamics (CFD), the discretized residual for such a flow can be constructed from the area–Mach number relation obtained from conservation of mass and isentropic thermodynamics. Starting from the fundamental laws, conservation of mass for a steady one-dimensional streamtube implies that $ \\rho U A = \\text{constant} $, where $ \\rho $ is the density, $ U $ is the axial velocity, and $ A $ is the local cross-sectional area. Under isentropic conditions, the pressure–density relation $ p/\\rho^\\gamma = \\text{constant} $ holds, where $ \\gamma $ is the ratio of specific heats. Combining these yields the compressible area–Mach relation,\n$$\n\\frac{A}{A^\\ast}(M) \\;=\\; \\frac{1}{M}\\left(\\frac{2}{\\gamma+1}\\left(1+\\frac{\\gamma-1}{2}M^2\\right)\\right)^{\\frac{\\gamma+1}{2(\\gamma-1)}},\n$$\nwhere $ M $ is the Mach number and $ A^\\ast $ is the sonic area. This relation is valid for $ M > 0 $ and has a minimum at $ M = 1 $ with $ A/A^\\ast = 1 $, producing two branches (subsonic and supersonic) for $ A/A^\\ast > 1 $. In a transonic airfoil case, a smooth field of Mach numbers $ M(s) $ along the surface coordinate $ s \\in [0,1] $ will cross near $ M \\approx 1 $.\n\nDefine the nonlinear residual for a vector of nodal Mach numbers $ \\mathbf{m} = (m_1,\\dots,m_N) $ at uniformly spaced nodes $ s_i \\in [0,1] $ as\n$$\nR_i(\\mathbf{m}) \\;=\\; \\frac{A}{A^\\ast}(m_i) \\;-\\; \\frac{A}{A^\\ast}(M_{\\text{true}}(s_i)),\n$$\nwhere $ M_{\\text{true}}(s) $ is a prescribed smooth transonic target field,\n$$\nM_{\\text{true}}(s) \\;=\\; 0.8 \\;+\\; 0.4 \\exp\\!\\left(-\\frac{(s-0.6)^2}{(0.05)^2}\\right),\n$$\nand $ \\gamma = 1.4 $. By construction, the exact solution of $ R_i(\\mathbf{m})=0 $ is $ m_i = M_{\\text{true}}(s_i) $. Let the initial guess be\n$$\nm_i^{(0)} \\;=\\; M_{\\text{true}}(s_i) \\;+\\; \\delta \\sin(2\\pi s_i), \\quad \\delta = 0.02.\n$$\n\nNewton’s method updates $ \\mathbf{m}^{(k+1)} = \\mathbf{m}^{(k)} - \\mathbf{J}(\\mathbf{m}^{(k)})^{-1}\\mathbf{R}(\\mathbf{m}^{(k)}) $, where $ \\mathbf{J} $ is the Jacobian matrix with entries $ J_{ij} = \\partial R_i / \\partial m_j $. Because $ R_i $ depends only on $ m_i $, $ \\mathbf{J} $ is diagonal with $ J_{ii} = \\frac{d}{dM}\\left(\\frac{A}{A^\\ast}(M)\\right)\\big|_{M=m_i} $. The linearization accuracy can be varied by replacing the exact derivative with approximations:\n- Exact Jacobian: $ J_{ii} = \\left(\\frac{A}{A^\\ast}\\right)^\\prime(m_i^{(k)}) $.\n- Finite-difference Jacobian: $ J_{ii} \\approx \\dfrac{\\frac{A}{A^\\ast}(m_i^{(k)}+\\epsilon) - \\frac{A}{A^\\ast}(m_i^{(k)})}{\\epsilon} $ with specified $ \\epsilon > 0 $.\n- Frozen Jacobian: $ J_{ii} $ is computed once at $ m_i^{(0)} $ and held fixed for all iterations.\n\nDefine the global error at iteration $ k $ as the infinity norm\n$$\ne^{(k)} \\;=\\; \\left\\|\\mathbf{m}^{(k)} - \\mathbf{M}_{\\text{true}}\\right\\|_\\infty.\n$$\nEstimate the observed convergence rate $ p $ using three consecutive errors via\n$$\np \\;\\approx\\; \\frac{\\ln\\!\\left(e^{(k+1)}/e^{(k)}\\right)}{\\ln\\!\\left(e^{(k)}/e^{(k-1)}\\right)},\n$$\ncomputed from the last three iterations after a fixed number of total iterations.\n\nYour task is to implement a program that:\n1. Constructs $ N = 200 $ nodes $ s_i $ uniformly in $ [0,1] $.\n2. Builds $ M_{\\text{true}}(s_i) $, the residual $ R_i(\\mathbf{m}) $, and initializes $ \\mathbf{m}^{(0)} $ as above.\n3. Runs Newton iterations for a fixed number of iterations (use $ 8 $ iterations) using each of the following Jacobian linearization strategies:\n   - Exact Jacobian.\n   - Finite-difference Jacobian with $ \\epsilon = 10^{-6} $.\n   - Finite-difference Jacobian with $ \\epsilon = 10^{-3} $.\n   - Frozen Jacobian taken from the initial guess.\n4. For each strategy, computes the observed convergence rate $ p $ using the last three errors $ e^{(k)} $.\n5. Aggregates the four $ p $ values into a single list.\n\nTest Suite:\n- Case $ 1 $: Exact Jacobian.\n- Case $ 2 $: Finite-difference Jacobian with $ \\epsilon = 10^{-6} $.\n- Case $ 3 $: Finite-difference Jacobian with $ \\epsilon = 10^{-3} $.\n- Case $ 4 $: Frozen Jacobian from the initial guess.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $ [p_1,p_2,p_3,p_4] $). All numbers in the output must be plain floating-point values without units. No physical units are required for this problem, and all quantities are dimensionless. Angles do not appear in this problem, and no percentages are used.",
            "solution": "This problem investigates the practical convergence of Newton's method under different Jacobian linearization strategies for a nonlinear system derived from a transonic flow model.\n\n**1. Physical and Mathematical Model**\nThe problem is based on the one-dimensional, isentropic area-Mach number relation, which is a fundamental result in compressible fluid dynamics. The nonlinear system to be solved is a set of $N$ decoupled equations for the Mach numbers $m_i$ at discrete nodes:\n$$ R_i(\\mathbf{m}) = \\frac{A}{A^\\ast}(m_i) - C_i = 0 $$\nwhere $C_i = \\frac{A}{A^\\ast}(M_{\\text{true}}(s_i))$ is a constant for each node. The solution to this system is, by construction, $m_i = M_{\\text{true}}(s_i)$.\n\n**2. Newton's Method and the Jacobian**\nNewton's method solves for the root of each equation $R_i(m_i)=0$ iteratively. Since the equations are uncoupled, the Jacobian matrix $\\mathbf{J}$ is diagonal, and we can consider each nodal update independently:\n$$ m_i^{(k+1)} = m_i^{(k)} - \\frac{R_i(m_i^{(k)})}{J_{ii}(m_i^{(k)})} $$\nwhere $J_{ii} = \\frac{dR_i}{dm_i} = \\frac{d}{dM}\\left(\\frac{A}{A^\\ast}\\right)\\big|_{M=m_i}$. The analytical derivative is:\n$$ \\left(\\frac{A}{A^\\ast}\\right)'(M) = \\frac{A}{A^\\ast}(M) \\frac{M^2-1}{M(1+\\frac{\\gamma-1}{2}M^2)} $$\n\n**3. Convergence Rate Analysis**\nThe theoretical convergence rate of Newton's method depends on the properties of the function and its derivatives at the root.\n- **Quadratic Convergence ($p=2$)**: This is expected when using an exact Jacobian and when the derivative at the root, $J_{ii}(m_i^*)$, is non-zero.\n- **Linear Convergence ($p=1$)**: This occurs when an approximate Jacobian is used (e.g., finite-difference or frozen) or if the Jacobian at the root is singular ($J_{ii}(m_i^*)=0$).\n\nA key feature of this problem is the transonic nature of the true solution $M_{\\text{true}}(s)$, which passes through $M=1$. At the sonic point $M=1$, the derivative $(A/A^\\ast)'(M)$ is zero. This means that for nodes where the solution is $m_i^* \\approx 1$, the Jacobian is singular. This singularity degrades the local convergence from quadratic to linear. Since the global error is measured by the infinity norm, it is governed by the slowest-converging node. Therefore, even for the \"Exact Jacobian\" case, the observed global convergence rate $p$ is expected to be approximately $1$, not $2$. The other cases, which use inherently linearizing approximations, are also expected to yield $p \\approx 1$.\n\n**4. Implementation**\nThe provided Python code implements the following logic:\n1.  **Setup**: It defines the physical constants, discretizes the domain, and creates functions for the area-Mach relation and its derivative.\n2.  **Initialization**: It computes the true Mach field $M_{\\text{true}}$ and the perturbed initial guess $m^{(0)}$.\n3.  **Iteration Loop**: For each of the four specified strategies, it runs Newton's method for 8 iterations.\n    - Inside the loop, it calculates the residual vector $R$.\n    - It computes the diagonal Jacobian vector $J$ according to the current strategy (exact analytical derivative, finite difference, or a pre-computed frozen value). A small regularization is applied to the Jacobian to prevent division by zero at the sonic point.\n    - It performs the Newton update $m \\leftarrow m - R/J$.\n    - It calculates and stores the infinity-norm error $\\|m - M_{\\text{true}}\\|_\\infty$.\n4.  **Rate Calculation**: After the iterations, it uses the errors from the last three steps ($k=6, 7, 8$) to estimate the convergence rate $p$ for each strategy.\n5.  **Output**: The four computed rates are aggregated and printed in the specified list format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the nonlinear residual problem for transonic flow using Newton's method\n    with different Jacobian approximations and computes the observed convergence rates.\n    \"\"\"\n    \n    # --- 1. Problem Setup ---\n    N = 200\n    GAMMA = 1.4\n    DELTA = 0.02\n    NUM_ITER = 8\n    \n    # Spatial domain discretization\n    s = np.linspace(0, 1, N)\n\n    # --- 2. Core Physical and Mathematical Functions ---\n    \n    def A_A_star(M, gamma=GAMMA):\n        \"\"\"\n        Calculates the compressible area-Mach number relation A/A*.\n        Vectorized to operate on numpy arrays.\n        \"\"\"\n        # Ensure M is positive to avoid numerical issues\n        M_safe = np.maximum(M, 1e-9)\n\n        gp1 = gamma + 1.0\n        gm1 = gamma - 1.0\n        \n        term1 = 2.0 / gp1\n        term2 = 1.0 + (gm1 / 2.0) * M_safe**2\n        exponent = gp1 / (2.0 * gm1)\n        \n        return (1.0 / M_safe) * (term1 * term2)**exponent\n\n    def dA_A_star_dM(M, gamma=GAMMA):\n        \"\"\"\n        Calculates the exact derivative of the A/A* function with respect to M.\n        Vectorized to operate on numpy arrays.\n        \"\"\"\n        M_safe = np.maximum(M, 1e-9)\n        \n        gm1 = gamma - 1.0\n        \n        # A/A*(M) value is needed for the derivative formula\n        val_A_A_star = A_A_star(M_safe, gamma)\n        \n        numerator = M_safe**2 - 1.0\n        denominator = M_safe * (1.0 + (gm1 / 2.0) * M_safe**2)\n        \n        # Avoid division by zero\n        denominator[np.abs(denominator)  1e-12] = 1e-12\n        \n        return val_A_A_star * (numerator / denominator)\n\n    def M_true_func(s_val):\n        \"\"\"\n        Calculates the prescribed true Mach number distribution.\n        \"\"\"\n        return 0.8 + 0.4 * np.exp(-((s_val - 0.6)**2) / (0.05**2))\n\n    # Static computations\n    M_true = M_true_func(s)\n    m0 = M_true + DELTA * np.sin(2 * np.pi * s)\n    A_A_star_true = A_A_star(M_true)\n\n    # --- 3. Strategies and Solver ---\n    \n    strategies = [\n        {'type': 'exact'},\n        {'type': 'fd', 'epsilon': 1e-6},\n        {'type': 'fd', 'epsilon': 1e-3},\n        {'type': 'frozen'}\n    ]\n    \n    convergence_rates = []\n\n    for strategy in strategies:\n        m = m0.copy()\n        errors = []\n\n        # Calculate initial error e^(0)\n        initial_error = np.linalg.norm(m - M_true, ord=np.inf)\n        errors.append(initial_error)\n        \n        # Pre-compute frozen Jacobian if needed\n        if strategy['type'] == 'frozen':\n            J_frozen = dA_A_star_dM(m)\n            # Regularize to prevent division by zero at sonic points\n            mask = np.abs(J_frozen)  1e-12\n            J_frozen[mask] = np.sign(J_frozen[mask]) * 1e-12\n\n        # Newton iteration loop\n        for _ in range(NUM_ITER):\n            # Calculate residual R(m)\n            R = A_A_star(m) - A_A_star_true\n            \n            # Calculate Jacobian J(m) based on strategy\n            if strategy['type'] == 'exact':\n                J = dA_A_star_dM(m)\n            elif strategy['type'] == 'fd':\n                epsilon = strategy['epsilon']\n                J = (A_A_star(m + epsilon) - A_A_star(m)) / epsilon\n            elif strategy['type'] == 'frozen':\n                J = J_frozen\n            \n            # Regularize Jacobian to prevent division by very small numbers near M=1\n            mask = np.abs(J)  1e-12\n            J[mask] = np.sign(J[mask]) * 1e-12\n\n            # Newton update step\n            delta_m = -R / J\n            m = m + delta_m\n            \n            # Store error e^(k)\n            error = np.linalg.norm(m - M_true, ord=np.inf)\n            errors.append(error)\n\n        # --- 4. Convergence Rate Calculation ---\n        # The convergence rate p is estimated using the last three errors: e^6, e^7, e^8.\n        # This corresponds to indices 6, 7, and 8 in the 'errors' list.\n        # Formula: p = log(e_{k+1}/e_k) / log(e_k/e_{k-1}) with k=7.\n        \n        e_k_minus_1 = errors[6]\n        e_k = errors[7]\n        e_k_plus_1 = errors[8]\n        \n        # Handle cases where error reduction stops, to avoid log(0) or division by zero\n        ratio_num = e_k_plus_1 / e_k if e_k > 0 else 0.0\n        ratio_den = e_k / e_k_minus_1 if e_k_minus_1 > 0 else 0.0\n\n        log_term_num = np.log(ratio_num) if ratio_num > 0 else -np.inf\n        log_term_den = np.log(ratio_den) if ratio_den > 0 else -np.inf\n\n        if np.isclose(log_term_den, 0.0) or log_term_den == -np.inf:\n            # If convergence has stalled or was immediate, rate is ill-defined.\n            # A rate of 1.0 is a reasonable default for stalled linear convergence.\n            p = 1.0\n        else:\n            p = log_term_num / log_term_den\n\n        convergence_rates.append(p)\n\n    # --- 5. Output ---\n    # Format the results into the required string format\n    result_str = \",\".join(map(str, convergence_rates))\n    print(f\"[{result_str}]\")\n\n\nsolve()\n```"
        },
        {
            "introduction": "In complex CFD codes, it is common to use approximations for the full Jacobian to save computational cost, but this can have subtle and detrimental effects on convergence. This exercise provides a focused look at one common simplification: neglecting the Jacobian contribution from boundary conditions. Using a simplified but physically representative model of a nozzle outlet, you will derive and compute the error introduced into the Newton update by this approximation, directly linking a specific implementation choice to the degradation of the solver's efficiency.",
            "id": "3973353",
            "problem": "Consider a one-dimensional, compressible nozzle outlet treated in characteristic-normal variables at the right boundary. Let the nonlinear residual for the last control volume be decomposed as the sum of an interior contribution and a boundary-condition contribution, written as $R(U) = R_{\\text{int}}(U) + R_{\\text{bc}}(U)$, where $U$ denotes the state vector. A Newton step for solving $R(U) = 0$ uses the linearization $J \\Delta U = -R$, where $J = \\partial R/\\partial U$ is the Jacobian. Suppose that in the characteristic basis at the outlet, the interior-Jacobian and the boundary-condition-Jacobian are modeled as diagonal operators\n$$\nJ_{\\text{int}} = \\operatorname{diag}(\\sigma_1,\\sigma_2,\\sigma_3), \\quad J_{\\text{bc}} = \\operatorname{diag}(\\kappa,0,0) \\text{ if } \\lambda_1 \\le 0, \\text{ and } J_{\\text{bc}} = \\operatorname{diag}(0,0,0) \\text{ otherwise},\n$$\nwith the characteristic speeds defined by\n$$\n\\lambda_1 = u - a, \\quad \\lambda_2 = u, \\quad \\lambda_3 = u + a,\n$$\nwhere $u$ is the flow speed at the outlet, $a$ is the speed of sound, and the characteristic strengths are\n$$\n\\sigma_i = |\\lambda_i| + \\varepsilon, \\quad i \\in \\{1,2,3\\},\n$$\nwith a small regularization $\\varepsilon  0$. Let the Mach number at the outlet be $M$, and take $a = 1$ (non-dimensional speed of sound), so that $u = M a = M$. The scalar $\\kappa \\ge 0$ represents the linearized boundary-pressure enforcement strength projected onto the single incoming characteristic at a subsonic outlet, which is physically justified by the fact that only one characteristic enters the domain when $M  1$.\n\nAssume that the exact Newton step $\\Delta U^{\\star}$ solves $(J_{\\text{int}} + J_{\\text{bc}})\\Delta U^{\\star} = -R$ while the approximated-Newton step $\\widetilde{\\Delta U}$ neglects the boundary Jacobian and solves $J_{\\text{int}} \\widetilde{\\Delta U} = -R$. Define the Newton update error caused by neglecting $\\partial R_{\\text{bc}}/\\partial U$ as $\\Delta U_{\\text{err}} = \\widetilde{\\Delta U} - \\Delta U^{\\star}$. Starting from the Newton linearization and the decomposition of the residual, derive from first principles a formula for the ratio\n$$\n\\eta = \\frac{\\|\\Delta U_{\\text{err}}\\|_2}{\\|\\Delta U^{\\star}\\|_2}\n$$\nin terms of $J_{\\text{int}}$ and $J_{\\text{bc}}$. Relate this ratio to the worst-case one-step residual reduction factor when using the approximate Newton step that omits $J_{\\text{bc}}$, namely\n$$\n\\rho = \\left\\|I - J J_{\\text{int}}^{-1}\\right\\|_2, \\quad \\text{with } J = J_{\\text{int}} + J_{\\text{bc}}.\n$$\nThen, specialize your expressions to the above diagonal model in the characteristic basis, using $a = 1$, $u = M$, and $\\varepsilon = 10^{-4}$. In this model, the condition for an incoming characteristic at the outlet is $\\lambda_1 \\le 0$, i.e., $M \\le 1$. If $M  1$, then $J_{\\text{bc}}$ must be identically the zero matrix.\n\nYour program must compute, for each test case below, the two scalars $\\eta$ and $\\rho$ as floating-point numbers. The program must implement the derivations and definitions above, constructing $J_{\\text{int}}$ and $J_{\\text{bc}}$ from the given parameters and using the spectral (operator $2$-norm) for matrix norms. The final result must aggregate the outputs for all test cases into a single line as a comma-separated list enclosed in square brackets. For each test case, you must emit the two numbers in the order $\\eta$ then $\\rho$, producing a flat list in the order of the test cases.\n\nUse the following test suite, which exercises representative subsonic, supersonic, near-sonic, weak, and strong boundary-condition sensitivities. All quantities are non-dimensional.\n\nTest cases are tuples $(M,\\kappa)$:\n1. $(0.5, 0.3)$\n2. $(1.5, 0.3)$\n3. $(1.0, 0.3)$\n4. $(0.5, 1.0)$\n5. $(0.2, 0.05)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[$\\text{result}_1,\\text{result}_2,\\ldots$]\"). The list must contain, for each test case in the order above, first the value of $\\eta$ followed by the value of $\\rho$, both as floating-point numbers.",
            "solution": "This problem analyzes the error introduced by approximating the Jacobian matrix in a Newton solver, specifically by neglecting the contribution from boundary conditions. The goal is to derive and compute two key metrics: the relative error in the Newton update, $\\eta$, and the convergence factor of the resulting iterative method, $\\rho$.\n\n**1. Derivation of Error Formulas**\nThe problem defines the exact and approximate Newton systems:\n1.  Exact step: $(J_{\\text{int}} + J_{\\text{bc}}) \\Delta U^{\\star} = -R$\n2.  Approximate step: $J_{\\text{int}} \\widetilde{\\Delta U} = -R$\n\nBy equating the right-hand sides, we relate the two steps: $J_{\\text{int}} \\widetilde{\\Delta U} = (J_{\\text{int}} + J_{\\text{bc}}) \\Delta U^{\\star}$. Since $J_{\\text{int}}$ is invertible (its diagonal entries $\\sigma_i$ are strictly positive due to $\\varepsilon > 0$), we can write:\n$$\n\\widetilde{\\Delta U} = J_{\\text{int}}^{-1} (J_{\\text{int}} + J_{\\text{bc}}) \\Delta U^{\\star} = (I + J_{\\text{int}}^{-1} J_{\\text{bc}}) \\Delta U^{\\star}\n$$\nThe error in the Newton update is $\\Delta U_{\\text{err}} = \\widetilde{\\Delta U} - \\Delta U^{\\star}$. Substituting the expression for $\\widetilde{\\Delta U}$:\n$$\n\\Delta U_{\\text{err}} = (I + J_{\\text{int}}^{-1} J_{\\text{bc}}) \\Delta U^{\\star} - \\Delta U^{\\star} = (J_{\\text{int}}^{-1} J_{\\text{bc}}) \\Delta U^{\\star}\n$$\nThe relative error $\\eta$ is the worst-case ratio of the error norm to the exact step norm, which corresponds to the spectral norm (2-norm) of the transformation matrix:\n$$\n\\eta = \\sup_{\\Delta U^{\\star} \\neq 0} \\frac{\\|\\Delta U_{\\text{err}}\\|_2}{\\|\\Delta U^{\\star}\\|_2} = \\|J_{\\text{int}}^{-1} J_{\\text{bc}}\\|_2\n$$\nThe convergence factor $\\rho$ is defined as $\\rho = \\|I - J J_{\\text{int}}^{-1}\\|_2$. Substituting $J = J_{\\text{int}} + J_{\\text{bc}}$:\n$$\n\\rho = \\|I - (J_{\\text{int}} + J_{\\text{bc}})J_{\\text{int}}^{-1}\\|_2 = \\|I - (I + J_{\\text{bc}}J_{\\text{int}}^{-1})\\|_2 = \\|-J_{\\text{bc}}J_{\\text{int}}^{-1}\\|_2 = \\|J_{\\text{bc}}J_{\\text{int}}^{-1}\\|_2\n$$\nSince the matrices $J_{\\text{int}}$ and $J_{\\text{bc}}$ are diagonal, they commute, meaning $J_{\\text{int}}^{-1} J_{\\text{bc}} = J_{\\text{bc}} J_{\\text{int}}^{-1}$. Therefore, the two norms are identical: $\\eta = \\rho$.\n\n**2. Specialization to the Diagonal Model**\nWe now apply this result to the specific model provided.\n- If the outlet is supersonic ($M > 1$), then $\\lambda_1 = u-a = M-1 > 0$. The model states that $J_{\\text{bc}}$ is the zero matrix. Consequently, $\\eta = \\rho = \\| \\text{zero matrix} \\|_2 = 0$. This physically means that for a supersonic outlet, no information propagates upstream, so the boundary condition does not affect the interior, and neglecting its Jacobian introduces no error.\n- If the outlet is subsonic or sonic ($M \\le 1$), then $\\lambda_1 \\le 0$ and $J_{\\text{bc}} = \\operatorname{diag}(\\kappa, 0, 0)$. The matrix product is:\n$$\nJ_{\\text{int}}^{-1} J_{\\text{bc}} = \\operatorname{diag}\\left(\\frac{1}{\\sigma_1}, \\frac{1}{\\sigma_2}, \\frac{1}{\\sigma_3}\\right) \\operatorname{diag}(\\kappa, 0, 0) = \\operatorname{diag}\\left(\\frac{\\kappa}{\\sigma_1}, 0, 0\\right)\n$$\nThe 2-norm of a diagonal matrix is the maximum absolute value of its diagonal entries. Given $\\kappa \\ge 0$ and $\\sigma_1 > 0$:\n$$\n\\eta = \\rho = \\left\\|\\operatorname{diag}\\left(\\frac{\\kappa}{\\sigma_1}, 0, 0\\right)\\right\\|_2 = \\frac{\\kappa}{\\sigma_1}\n$$\nThe term $\\sigma_1$ is defined as $|\\lambda_1| + \\varepsilon = |M-1| + \\varepsilon$. Since $M \\le 1$, this simplifies to $(1-M) + \\varepsilon$. The final formula is:\n$$\n\\eta = \\rho = \\frac{\\kappa}{(1-M) + \\varepsilon}\n$$\n\n**3. Implementation**\nThe provided Python code implements this derived logic. It iterates through each test case $(M, \\kappa)$, checks if $M > 1$ or $M \\le 1$, and applies the corresponding formula to compute the value for $\\eta$ and $\\rho$. These values are then collected into a list and printed in the required format.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to a specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the error ratio eta and residual reduction factor rho for a series of test cases\n    based on a simplified model of a CFD boundary condition treatment.\n    \"\"\"\n    # Define the test cases from the problem statement as tuples of (M, kappa).\n    # M is the Mach number, kappa is the boundary condition strength.\n    test_cases = [\n        (0.5, 0.3),  # Subsonic, weak BC\n        (1.5, 0.3),  # Supersonic, weak BC\n        (1.0, 0.3),  # Transonic, weak BC\n        (0.5, 1.0),  # Subsonic, strong BC\n        (0.2, 0.05), # Low-speed subsonic, very weak BC\n    ]\n\n    # Regularization parameter epsilon from the problem statement.\n    epsilon = 1e-4\n\n    results = []\n    for M, kappa in test_cases:\n        # The derivation shows that for the given diagonal, commuting matrices, eta = rho.\n        # We compute this single value and append it twice to the results list.\n        \n        # Case 1: Supersonic outlet (M > 1)\n        # The problem states that for M > 1, J_bc is the zero matrix.\n        # This implies that the error matrix J_int^{-1} J_bc is also zero,\n        # and so its norm (eta and rho) is 0.\n        if M > 1:\n            eta = 0.0\n            rho = 0.0\n        # Case 2: Subsonic or sonic outlet (M = 1)\n        # The derived formula is kappa / (|M-1| + epsilon).\n        # Since M = 1, |M-1| simplifies to 1-M.\n        else:\n            # The value is the same for both eta and rho\n            value = kappa / ((1.0 - M) + epsilon)\n            eta = value\n            rho = value\n            \n        results.append(eta)\n        results.append(rho)\n\n    # The final print statement must produce a single line containing a\n    # comma-separated list of floating-point numbers enclosed in square brackets.\n    # The format is [eta1, rho1, eta2, rho2, ...].\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}