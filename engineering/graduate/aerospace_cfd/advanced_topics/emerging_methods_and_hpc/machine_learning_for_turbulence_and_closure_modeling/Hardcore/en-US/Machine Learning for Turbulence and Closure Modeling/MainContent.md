## Introduction
The accurate prediction of turbulent flows is a persistent challenge in computational fluid dynamics (CFD), underpinning progress in fields from aerospace engineering to climate science. While traditional models based on the Reynolds-Averaged Navier-Stokes (RANS) equations have been workhorses for decades, their underlying assumptions limit their accuracy in complex, real-world scenarios. This creates a critical knowledge gap where classical theories fail to capture essential physics, leading to unreliable predictions. Machine learning presents a transformative opportunity to overcome these limitations by learning directly from high-fidelity data, paving the way for more robust and predictive turbulence [closures](@entry_id:747387).

This article provides a comprehensive overview of this rapidly evolving field. In the following chapters, we will first delve into the **Principles and Mechanisms**, uncovering the origin of the turbulence closure problem and the fundamental physical laws, such as invariance and realizability, that must guide any data-driven model. Next, we will explore a wide range of **Applications and Interdisciplinary Connections**, showcasing how these advanced modeling techniques are being deployed to solve critical problems in combustion, plasma physics, and atmospheric science. Finally, a series of **Hands-On Practices** will offer the opportunity to apply these concepts, solidifying the bridge between theory and practical implementation.

## Principles and Mechanisms

The formulation of predictive models for turbulence is a central challenge in computational fluid dynamics (CFD). As established in the introduction, [direct numerical simulation](@entry_id:149543) (DNS) of the Navier-Stokes equations is computationally prohibitive for most engineering applications. Consequently, a simplified description of the flow is sought by averaging or filtering the governing equations. This process, however, is not without consequence; it introduces new, unclosed terms that represent the effects of unresolved turbulent motions on the resolved flow. This chapter delineates the origin of this "closure problem" and explores the fundamental principles and mechanisms that guide the development of turbulence models, from classical theories to modern machine learning frameworks.

### The Origin of the Closure Problem: Averaging and Filtering

The incompressible Navier-Stokes equations describe the evolution of the velocity field $u_i(\mathbf{x}, t)$ and pressure $p(\mathbf{x}, t)$. The nonlinearity resides in the convective acceleration term, $u_j \partial_j u_i$. It is this term that gives rise to the closure problem when an averaging or filtering operator, denoted by $\overline{(\cdot)}$, is applied.

In the context of **Reynolds-Averaged Navier-Stokes (RANS)**, the [instantaneous velocity](@entry_id:167797) is decomposed into a mean component $\overline{u}_i$ and a fluctuating component $u_i'$, such that $u_i = \overline{u}_i + u_i'$ and by definition $\overline{u_i'} = 0$. The averaging operator can be an ensemble average over many realizations of the flow or, for statistically stationary flows, a long-time average . This operator is linear, meaning $\overline{a+b} = \overline{a} + \overline{b}$, and commutes with differentiation under standard regularity assumptions, e.g., $\overline{\partial_j u_i} = \partial_j \overline{u}_i$. However, the operator is not multiplicative for correlated quantities: $\overline{ab} \neq \overline{a} \overline{b}$.

Applying the Reynolds averaging operator to the incompressible Navier-Stokes equations, the convective term becomes:
$$ \overline{u_j \partial_j u_i} = \overline{(\overline{u}_j + u_j') \partial_j (\overline{u}_i + u_i')} = \overline{u}_j \partial_j \overline{u}_i + \overline{u_j' \partial_j u_i'} $$
Using the continuity equation for the fluctuations, $\partial_j u_j' = 0$, the second term can be rewritten as $\partial_j(\overline{u_i' u_j'})$. The averaged momentum equation thus takes the form:
$$ \frac{\partial \overline{u}_i}{\partial t} + \overline{u}_j \frac{\partial \overline{u}_i}{\partial x_j} = -\frac{1}{\rho}\frac{\partial \overline{p}}{\partial x_i} + \nu \frac{\partial^2 \overline{u}_i}{\partial x_j \partial x_j} - \frac{\partial}{\partial x_j} (\overline{u_i' u_j'}) $$
The system of equations for the mean quantities $\overline{u}_i$ and $\overline{p}$ is not closed because it now contains a new unknown, the **Reynolds stress tensor**, $R_{ij} \equiv \overline{u_i' u_j'}$. This symmetric second-order tensor represents the transport of mean momentum by turbulent fluctuations and is not a known function of the mean fields . To obtain a solvable system, a "closure model" is required to express $R_{ij}$ in terms of the mean velocity field $\overline{u}_i$ and its gradients.

This closure problem is not a one-time issue. If one attempts to derive an exact transport equation for $R_{ij}$, new, higher-order correlations appear, such as triple velocity correlations ($\overline{u_i' u_j' u_k'}$) and pressure-strain correlations. This leads to an infinite, unclosed hierarchy of [moment equations](@entry_id:149666), necessitating that the hierarchy be truncated and modeled at some level .

A parallel situation arises in **Large-Eddy Simulation (LES)**, where the operator is a low-pass spatial filter, typically a convolution with a kernel $G_\Delta$ of characteristic width $\Delta$ . Applying this filter to the Navier-Stokes equations yields:
$$ \frac{\partial \overline{u}_i}{\partial t} + \frac{\partial}{\partial x_j} (\overline{u_i u_j}) = -\frac{1}{\rho}\frac{\partial \overline{p}}{\partial x_i} + \nu \frac{\partial^2 \overline{u}_i}{\partial x_j \partial x_j} $$
Here, the filtered product $\overline{u_i u_j}$ is not equal to the product of the filtered velocities, $\overline{u}_i \overline{u}_j$. Their difference defines the **subgrid-scale (SGS) stress tensor**, $\tau_{ij} \equiv \overline{u_i u_j} - \overline{u}_i \overline{u}_j$. The filtered momentum equation can be rewritten with this term explicitly:
$$ \frac{\partial \overline{u}_i}{\partial t} + \overline{u}_j \frac{\partial \overline{u}_i}{\partial x_j} = -\frac{1}{\rho}\frac{\partial \overline{p}}{\partial x_i} + \nu \frac{\partial^2 \overline{u}_i}{\partial x_j \partial x_j} - \frac{\partial \tau_{ij}}{\partial x_j} $$
As in RANS, the SGS stress $\tau_{ij}$ is an unknown quantity that depends on unresolved scales and must be modeled. The goal of LES is to choose the filter width $\Delta$ to be larger than the smallest turbulent scales (the Kolmogorov microscale, $\eta$) but small enough to resolve the large, energy-containing eddies. This reduces computational cost compared to DNS, which must resolve all scales down to $\eta$ .

For compressible flows, where density $\rho$ also fluctuates, standard Reynolds averaging leads to complex correlation terms involving density. To simplify the mean-flow equations, **Favre (density-weighted) averaging** is commonly used. The Favre average of a quantity $a$ is $\widetilde{a} = \overline{\rho a} / \overline{\rho}$. Using this definition, the unclosed stress tensor in the compressible RANS equations naturally emerges as $-\overline{\rho}\widetilde{u_i'' u_j''}$, where $u_i''$ is the Favre fluctuation. The choice of averaging dictates the precise definition of the quantity that a machine learning model must be trained to predict .

### Classical Approaches to Closure Modeling

The earliest and most widely used closure models are based on the **Boussinesq hypothesis**, which posits an analogy between the turbulent stresses and the viscous stresses in a Newtonian fluid . This hypothesis proposes a linear relationship between the deviatoric (anisotropic) part of the Reynolds stress tensor and the mean [rate-of-strain tensor](@entry_id:260652), $S_{ij} = \frac{1}{2}(\partial_j \overline{u}_i + \partial_i \overline{u}_j)$:
$$ -\rho R_{ij}^{\text{dev}} = -\rho\left(\overline{u_i'u_j'} - \frac{2}{3}k\delta_{ij}\right) \approx 2\mu_t S_{ij} $$
Here, $k = \frac{1}{2}\overline{u_i'u_i'}$ is the [turbulent kinetic energy](@entry_id:262712), $\mu_t$ is the **turbulent viscosity** (or eddy viscosity), and $\delta_{ij}$ is the Kronecker delta. The full Reynolds stress tensor is then modeled as:
$$ -\rho\overline{u_i'u_j'} \approx 2\mu_t S_{ij} - \frac{2}{3}\rho k \delta_{ij} $$
This is a **functional closure**, as it aims to represent the net effect ([momentum transfer](@entry_id:147714)) of the unresolved scales through a parameterized relation, rather than modeling the detailed structure of the stress tensor itself . A crucial consequence of this linear model is that the principal axes of the Reynolds stress [anisotropy tensor](@entry_id:746467) are forced to be aligned with the principal axes of the mean strain-rate tensor. While this is a reasonable approximation for [simple shear](@entry_id:180497) flows, it is a major deficiency in complex flows with strong [streamline](@entry_id:272773) curvature, rotation, or separation, where significant misalignment between [stress and strain](@entry_id:137374) is observed . Such models famously fail to predict important phenomena like curvature-induced [secondary flows](@entry_id:754609).

To use the Boussinesq hypothesis, one needs a model for the eddy viscosity $\mu_t$. **Two-equation models** accomplish this by solving transport equations for two turbulence quantities that can be combined on dimensional grounds to yield $\mu_t$. The most famous example is the standard **[k-epsilon model](@entry_id:260873)**, which solves transport equations for the turbulent kinetic energy ($k$) and its dissipation rate ($\epsilon$) . The modeled transport equation for $k$ represents a balance of convection, diffusion, production ($P_k$), and dissipation ($\epsilon$):
$$ \frac{\partial (\rho k)}{\partial t} + \frac{\partial (\rho \overline{u}_j k)}{\partial x_j} = \frac{\partial}{\partial x_j} \left[ \left( \mu + \frac{\mu_t}{\sigma_k} \right) \frac{\partial k}{\partial x_j} \right] + P_k - \rho \epsilon $$
The transport equation for $\epsilon$ is more phenomenological, balancing convection, diffusion, and modeled [source and sink](@entry_id:265703) terms:
$$ \frac{\partial (\rho \epsilon)}{\partial t} + \frac{\partial (\rho \overline{u}_j \epsilon)}{\partial x_j} = \frac{\partial}{\partial x_j} \left[ \left( \mu + \frac{\mu_t}{\sigma_{\epsilon}} \right) \frac{\partial \epsilon}{\partial x_j} \right] + C_{\epsilon 1} \frac{\epsilon}{k} P_k - C_{\epsilon 2} \rho \frac{\epsilon^2}{k} $$
The eddy viscosity is then computed as $\mu_t = \rho C_\mu \frac{k^2}{\epsilon}$. The coefficients ($C_\mu, \sigma_k, \sigma_\epsilon, C_{\epsilon 1}, C_{\epsilon 2}$) are empirical constants. Alternative models, like the **[k-omega model](@entry_id:275971)**, solve for $k$ and the [specific dissipation rate](@entry_id:755157) $\omega \propto \epsilon/k$. The $k-\omega$ model has different transport equations and is known for its more [robust performance](@entry_id:274615) in the [near-wall region](@entry_id:1128462), where it can be integrated directly to the wall, whereas the standard $k-\epsilon$ model requires special "wall functions" .

### Fundamental Principles for Advanced and Data-Driven Closures

Any physically admissible closure model, whether derived from phenomenological arguments or learned from data, must adhere to certain fundamental principles dictated by the laws of physics. Machine learning models that neglect these principles may perform well on their training data but are unlikely to generalize to new flow conditions.

#### Invariance Principles

The governing Navier-Stokes equations are invariant under a change of observer. This means the laws of physics do not depend on the observer's (constant) velocity or orientation. This property must be inherited by any closure model.

**Galilean invariance** requires that the model's prediction is independent of a uniform, constant-velocity translation of the coordinate system. An observer moving at a constant velocity $\mathbf{U}_0$ relative to another will measure a different [instantaneous velocity](@entry_id:167797) field ($\mathbf{u}' = \mathbf{u} + \mathbf{U}_0$), but the physics of the turbulence should be identical. This has a profound implication: a closure model cannot depend on the absolute velocity $\mathbf{u}$ or absolute position $\mathbf{x}$. Instead, it must be a function of velocity *gradients* or other quantities that are independent of such a "boost" .

**Frame indifference** (or objectivity) is a stricter condition requiring that the model be invariant under arbitrary time-dependent rotations and translations (superposed [rigid-body motion](@entry_id:265795)). For a tensor-valued model like a stress closure, this means that if the coordinate system is rotated by a matrix $\mathbf{Q}(t)$, the predicted stress tensor $\boldsymbol{\tau}$ must transform according to $\boldsymbol{\tau}' = \mathbf{Q}(t) \boldsymbol{\tau} \mathbf{Q}(t)^\top$. This constraint dictates which kinematic quantities can be used as inputs. For example, the [rate-of-strain tensor](@entry_id:260652) $\mathbf{S}$ is objective, but the [vorticity tensor](@entry_id:189621) $\mathbf{\Omega}$ is not, as it picks up a term related to the observer's spin. Thus, a model cannot depend on $\mathbf{\Omega}$ alone, but only on specific objective combinations of $\mathbf{S}$ and $\mathbf{\Omega}$ .

#### Realizability

The Reynolds stress tensor $R_{ij} = \overline{u_i' u_j'}$ is, by its definition, a covariance matrix of velocity fluctuations. A fundamental mathematical property of any covariance matrix is that it must be **symmetric and positive semi-definite (PSD)**. This physical constraint is known as **[realizability](@entry_id:193701)** . Positive semi-definiteness means that for any real vector $\mathbf{a}$, the quadratic form $a_i R_{ij} a_j \ge 0$. Physically, this ensures that the turbulent normal stress in any direction, $\overline{(u' \cdot \mathbf{a})^2}$, is non-negative. Furthermore, the trace of the tensor must correspond to a non-negative turbulent kinetic energy, $k = \frac{1}{2} R_{ii} \ge 0$.

Many classical models, including the Boussinesq hypothesis, do not inherently satisfy realizability for all flow conditions. For example, in regions of strong [extensional strain](@entry_id:183817), a linear [eddy viscosity model](@entry_id:1124145) can predict negative [normal stresses](@entry_id:260622), which is unphysical. Therefore, a key task in developing modern data-driven models is to build the [realizability](@entry_id:193701) constraint directly into the model architecture or output.

### A Modern Framework for Data-Driven Closure Modeling

Machine learning offers a powerful paradigm to move beyond the limitations of classical models. Instead of postulating a simple linear relationship, ML can learn complex, nonlinear mappings from high-fidelity DNS data. However, to be physically robust, this learning must be guided by the principles of invariance and [realizability](@entry_id:193701).

#### Modeling the Anisotropy Tensor

A more physically sound approach than modeling the entire Reynolds stress tensor directly is to decompose it into its isotropic and deviatoric parts. The deviatoric part, when normalized by the turbulent kinetic energy, is known as the **Reynolds stress [anisotropy tensor](@entry_id:746467)**, $b_{ij}$:
$$ b_{ij} = \frac{\overline{u_i'u_j'}}{2k} - \frac{1}{3}\delta_{ij} $$
This tensor is symmetric and, by construction, traceless ($\mathrm{tr}(\mathbf{b}) = 0$). It captures the shape and orientation of the Reynolds stress [ellipsoid](@entry_id:165811), representing the departure of the turbulence from a purely isotropic state (where $b_{ij}=0$). The closure problem can be reframed as modeling two separate quantities: the scalar [turbulent kinetic energy](@entry_id:262712) $k$ (often via a transport equation) and the tensor $b_{ij}$ .

#### Enforcing Invariance through Tensor Representation Theory

To ensure Galilean invariance, the [anisotropy tensor](@entry_id:746467) $b_{ij}$ must be modeled as an objective function of the mean velocity gradients. As established by [representation theory](@entry_id:137998), any objective [symmetric tensor](@entry_id:144567)-valued function of the mean strain-rate $S_{ij}$ and rotation-rate $\Omega_{ij}$ can be expressed as a linear combination of a finite **tensor basis** :
$$ b_{ij} = \sum_{n=1}^{10} G_n(\lambda_1, \dots, \lambda_5) T^{(n)}_{ij}(S, \Omega) $$
The basis tensors $\{T^{(n)}\}$ are constructed from products of $S_{ij}$ and $\Omega_{ij}$ (e.g., $T^{(1)}=S$, $T^{(2)}=S\Omega-\Omega S$, $T^{(3)}=S^2 - \frac{1}{3}\mathrm{tr}(S^2)I$, etc.) and are designed to be symmetric and traceless. The coefficients $G_n$ are scalar functions of a minimal set of five independent **[scalar invariants](@entry_id:193787)** built from $S$ and $\Omega$ (e.g., $\lambda_1=\mathrm{tr}(S^2), \lambda_2=\mathrm{tr}(\Omega^2)$, etc.).

This framework provides a systematic way to embed physical invariance into a machine learning model. The role of the ML model becomes learning the ten unknown scalar functions $G_n$ that map the five [scalar invariants](@entry_id:193787) to the basis coefficients. This ensures that the resulting closure is, by construction, frame-invariant.

#### Enforcing Realizability: The Lumley Triangle

The realizability constraint (PSD of $R_{ij}$) imposes strict bounds on the eigenvalues $(\lambda_1, \lambda_2, \lambda_3)$ of the [anisotropy tensor](@entry_id:746467) $b_{ij}$. Specifically, [realizability](@entry_id:193701) requires that $-\frac{1}{3} \le \lambda_i(b) \le \frac{2}{3}$ for all $i=1,2,3$ .

These constraints can be visualized geometrically. The state of anisotropy can be mapped to a point in a two-dimensional space whose coordinates are derived from the second and third invariants of $b_{ij}$. The set of all realizable states forms a triangular domain known as the **Lumley triangle** or **barycentric map** . The vertices of this triangle represent the limiting states of turbulence:
*   **One-component (1C) turbulence:** All turbulent energy is in one direction (e.g., a [simple shear](@entry_id:180497) layer).
*   **Two-component (2C) [isotropic turbulence](@entry_id:199323):** Turbulence is isotropic in a plane, with no fluctuations normal to it (e.g., strongly rotating or [stratified flows](@entry_id:265379)).
*   **Three-component (3C) [isotropic turbulence](@entry_id:199323):** Fluctuations are equal in all directions.

Any point inside this triangle corresponds to a physically realizable Reynolds stress tensor. This provides a powerful enforcement mechanism for ML models: a model can predict the [anisotropy tensor](@entry_id:746467), which is then mapped to the barycentric triangle. If the predicted point lies outside the triangle, it can be projected back onto the boundary to ensure the resulting stress tensor is realizable. Other robust enforcement strategies include parameterizing the Reynolds stress via a Cholesky-like factorization ($R_{ij} = L_{ik}L_{jk}$), which guarantees positive semi-definiteness by construction, or directly clipping the negative eigenvalues of a predicted stress tensor .

### Evaluation of Turbulence Models

Once a closure model is developed, it must be rigorously evaluated. This evaluation occurs in two distinct stages .

**A-priori evaluation** is an "offline" assessment where the model's predictions are directly compared to ground-truth data from DNS, without running a full simulation. For a given DNS velocity field, one can compute both the true unclosed term (e.g., $R_{ij}$) and the inputs to the model (e.g., $\overline{u}_i$ and its gradients). The model's prediction, $R_{ij}^{\text{model}}$, can then be compared directly to the true $R_{ij}^{\text{DNS}}$. Key metrics include correlation coefficients, normalized [mean-squared error](@entry_id:175403), and measures of tensor alignment. This stage is crucial for initial model development and for verifying that physical constraints like [realizability](@entry_id:193701) and energy dissipation properties are correctly captured  .

**A-posteriori evaluation** is an "online" assessment where the closure model is embedded into a RANS or LES solver, and a full simulation is executed. The quality of the model is then judged by its impact on the final, physically relevant outputs of the simulation. This includes comparing predicted mean velocity profiles, wall friction coefficients, aerodynamic forces (lift and drag), and turbulent energy spectra against DNS or experimental benchmarks. This stage is the ultimate test of a model, as it assesses not only its accuracy but also its numerical stability and its behavior in a dynamic system where errors can accumulate or dissipate over time . A model with excellent a-priori performance may still fail in a-posteriori tests, highlighting the necessity of both evaluation paradigms.