{
    "hands_on_practices": [
        {
            "introduction": "Before optimizing an algorithm, it is crucial to understand the fundamental resource limits of the hardware. This first exercise guides you through a derivation of GPU occupancy, a key metric for how effectively a kernel utilizes the streaming multiprocessors. By modeling the constraints imposed by register files and shared memory, you will develop a foundational understanding of how a kernel's resource footprint dictates its ability to saturate the machine, a critical first step in performance analysis. ",
            "id": "3940860",
            "problem": "Consider a compressible Navier–Stokes solver for aerospace Computational Fluid Dynamics (CFD) that advances face-normal fluxes on a Graphics Processing Unit (GPU). The solver uses a Single Instruction, Multiple Threads (SIMT) execution model with cooperative thread arrays, where each thread block stages face and cell data into shared memory to compute convective and diffusive flux contributions for a tile of the mesh. The kernel is designed for a Streaming Multiprocessor (SM) with a register file and a shared memory pool that are partitioned among concurrently resident thread blocks.\n\nAssume each thread in the kernel requires $r$ architectural registers, each thread block launches $T_b$ threads, and each thread block allocates $s$ bytes of shared memory. The SM exposes $R_{\\text{SM}}$ total registers and $S_{\\text{SM}}$ total shared memory bytes that can be distributed among resident blocks. The maximum resident threads per SM is $T_{\\text{SM}}$, the warp size is $W$, and occupancy is defined as the ratio of active warps to the hardware maximum warps resident per SM.\n\nStarting only from the following foundational facts:\n1. Registers and shared memory are conserved resources on an SM; a resident block consumes $r T_b$ registers and $s$ shared bytes, and multiple resident blocks sum their consumption.\n2. Warps are the unit of scheduling; a block with $T_b$ threads contains $\\lceil T_b / W \\rceil$ warps, and the hardware maximum resident warps per SM equals $T_{\\text{SM}} / W$.\n3. Occupancy equals the number of active warps divided by the hardware maximum resident warps.\n\nDerive, from first principles, a closed-form analytic expression for the occupancy upper bound imposed solely by limited registers and shared memory (ignore all other constraints such as per-SM maximum blocks and per-SM maximum threads beyond their role in normalizing occupancy). Express your final result as a single analytic expression in terms of $r$, $s$, $T_b$, $R_{\\text{SM}}$, $S_{\\text{SM}}$, $T_{\\text{SM}}$, and $W$. No numerical evaluation is required. No units are required.",
            "solution": "The problem requires the derivation of a closed-form analytic expression for the occupancy upper bound on a Graphics Processing Unit (GPU) Streaming Multiprocessor (SM), considering only the constraints imposed by register and shared memory resources. Occupancy, which we shall denote by $O$, is a key metric of hardware utilization.\n\nFirst, we begin with the provided definition of occupancy (foundational fact 3):\n$$\nO = \\frac{\\text{Number of Active Warps}}{\\text{Maximum Possible Resident Warps}}\n$$\n\nThe denominator, the maximum possible number of resident warps on an SM, is a fixed hardware characteristic. Based on foundational fact 2, this maximum is the total number of threads an SM can support, $T_{\\text{SM}}$, divided by the number of threads in a warp, $W$. Let us denote this maximum as $W_{\\text{max}}$.\n$$\nW_{\\text{max}} = \\frac{T_{\\text{SM}}}{W}\n$$\nThe problem specifies that a warp is the fundamental unit of scheduling, so this ratio correctly represents the maximum warp capacity.\n\nNext, we must determine the numerator: the number of active warps. This quantity is not fixed but depends on the kernel's resource requirements. The number of active warps, $W_{\\text{active}}$, is the product of the number of thread blocks that can be concurrently resident on the SM, which we denote as $N_b$, and the number of warps per thread block, denoted as $W_b$.\n$$\nW_{\\text{active}} = N_b \\times W_b\n$$\n\nThe number of warps per block, $W_b$, is determined by the number of threads per block, $T_b$, and the warp size, $W$. Since threads are grouped into discrete warps, any partial warp still requires the allocation of a full warp. Therefore, we must use the ceiling function. From foundational fact 2, we have:\n$$\nW_b = \\left\\lceil \\frac{T_b}{W} \\right\\rceil\n$$\n\nThe crucial step is to find an expression for $N_b$, the maximum number of concurrently resident blocks. The problem statement dictates that this is limited *solely* by register and shared memory availability. According to foundational fact 1, these resources are conserved and partitioned among resident blocks.\n\nLet us first consider the constraint imposed by the register file. The SM has a total of $R_{\\text{SM}}$ registers. Each thread requires $r$ registers, and a thread block contains $T_b$ threads. Thus, the total number of registers consumed by a single thread block is $r T_b$. The maximum number of blocks that can be accommodated by the register file, $N_{b,R}$, is the total available registers divided by the registers consumed per block. Since blocks are indivisible entities, we must take the floor of this ratio.\n$$\nN_{b,R} = \\left\\lfloor \\frac{R_{\\text{SM}}}{r T_b} \\right\\rfloor\n$$\n\nSecond, we consider the constraint imposed by shared memory. The SM has a total of $S_{\\text{SM}}$ bytes of shared memory. Each thread block allocates $s$ bytes. The maximum number of blocks that can be accommodated by the available shared memory, $N_{b,S}$, is the total shared memory divided by the amount consumed per block. Again, we must use the floor function.\n$$\nN_{b,S} = \\left\\lfloor \\frac{S_{\\text{SM}}}{s} \\right\\rfloor\n$$\n\nFor a thread block to be launched and become resident on the SM, there must be sufficient resources of *both* registers and shared memory. Therefore, the actual maximum number of resident blocks, $N_b$, is governed by the more restrictive of these two constraints. This is found by taking the minimum of the two calculated limits.\n$$\nN_b = \\min(N_{b,R}, N_{b,S}) = \\min\\left(\\left\\lfloor \\frac{R_{\\text{SM}}}{r T_b} \\right\\rfloor, \\left\\lfloor \\frac{S_{\\text{SM}}}{s} \\right\\rfloor\\right)\n$$\n\nWe now have all the components to construct the final expression for occupancy, $O$. Substituting the expressions for $W_{\\text{active}}$ and $W_{\\text{max}}$ into the initial definition of occupancy:\n$$\nO = \\frac{W_{\\text{active}}}{W_{\\text{max}}} = \\frac{N_b \\times W_b}{T_{\\text{SM}} / W}\n$$\nSubstituting our derived expressions for $N_b$ and $W_b$:\n$$\nO = \\frac{\\min\\left(\\left\\lfloor \\frac{R_{\\text{SM}}}{r T_b} \\right\\rfloor, \\left\\lfloor \\frac{S_{\\text{SM}}}{s} \\right\\rfloor\\right) \\times \\left\\lceil \\frac{T_b}{W} \\right\\rceil}{\\frac{T_{\\text{SM}}}{W}}\n$$\nRearranging this expression into its final, closed-form analytic state gives the upper bound on occupancy as a function of the specified parameters.\n$$\nO = \\frac{W}{T_{\\text{SM}}} \\min\\left(\\left\\lfloor \\frac{R_{\\text{SM}}}{r T_b} \\right\\rfloor, \\left\\lfloor \\frac{S_{\\text{SM}}}{s} \\right\\rfloor\\right) \\left\\lceil \\frac{T_b}{W} \\right\\rceil\n$$\nThis expression represents the theoretical occupancy ceiling imposed by the kernel's register and shared memory footprint, derived strictly from the provided first principles.",
            "answer": "$$\\boxed{\\frac{W}{T_{\\text{SM}}} \\min\\left(\\left\\lfloor \\frac{R_{\\text{SM}}}{r T_b} \\right\\rfloor, \\left\\lfloor \\frac{S_{\\text{SM}}}{s} \\right\\rfloor\\right) \\left\\lceil \\frac{T_b}{W} \\right\\rceil}$$"
        },
        {
            "introduction": "The Roofline model is an indispensable tool for diagnosing performance bottlenecks, revealing whether an algorithm is bound by memory bandwidth or peak computational throughput. This practice challenges you to apply the Roofline model to a representative CFD kernel, allowing you to quantitatively predict the performance gains from two powerful optimization strategies: data layout transformation and kernel fusion. Mastering this analysis is key to directing optimization efforts where they will have the most impact. ",
            "id": "3940816",
            "problem": "A finite-volume compressible Navier–Stokes residual kernel on an unstructured mesh is mapped to a Graphics Processing Unit (GPU) accelerator. For this kernel, you have measured the arithmetic intensity, defined as the ratio of floating-point operations to off-chip data movement, $I \\equiv \\frac{\\text{FLOPs}}{\\text{bytes}}$, to be $I_{0} = 0.60\\,\\text{FLOP/byte}$ for the current array-of-structures data layout. The target accelerator has a peak floating-point throughput $P_{\\text{peak}}$ and a sustained off-chip memory bandwidth $B$, taken as $P_{\\text{peak}} = 19.5\\times 10^{12}\\,\\text{FLOP/s}$ and $B = 1.6\\times 10^{12}\\,\\text{byte/s}$, respectively. Assume the Roofline performance model applies with arithmetic intensity measured at the High Bandwidth Memory (HBM) level. \n\nTwo accelerator-aware parallelization and data movement strategies are considered:\n1. A structure-of-arrays (SoA) data layout that reduces off-chip data traffic by $25\\%$ for the same floating-point work (that is, the off-chip bytes become $0.75$ times the baseline), with no change in the floating-point operation count.\n2. Kernel fusion of $s$ successive physics updates (e.g., flux and source term applications) that multiplies the floating-point operation count by $s$ while perfectly reusing the same off-chip data once loaded (that is, the off-chip bytes remain unchanged relative to the unfused case).\n\nUse only the following fundamental bases:\n- The definition of arithmetic intensity $I = \\frac{\\text{FLOPs}}{\\text{bytes}}$.\n- The definition of performance $P = \\frac{\\text{FLOPs}}{t}$ and bandwidth-limited time $t_{\\text{mem}} \\ge \\frac{\\text{bytes}}{B}$, and compute-limited time $t_{\\text{comp}} \\ge \\frac{\\text{FLOPs}}{P_{\\text{peak}}}$.\n- The Roofline upper bound $P_{\\text{roof}} = \\min\\!\\big(P_{\\text{peak}},\\, I\\,B\\big)$.\n\nTasks:\n- Compute the expected sustained performance in $\\text{GFLOP/s}$ for the following four scenarios using the Roofline model: baseline, SoA-only, fusion-only with $s=3$, and SoA-plus-fusion with $s=3$. \n- Then, determine the minimum positive integer fusion factor $s_{\\min}$ such that after applying the SoA optimization, the kernel becomes compute-bound under the Roofline model, i.e., $I_{\\text{SoA}\\,+\\,s_{\\min}}\\,B \\ge P_{\\text{peak}}$.\n\nExpress the four performances in $\\text{GFLOP/s}$ and round them to four significant figures. Report your final answer as a row vector $\\big[P_{\\text{base}},\\,P_{\\text{SoA}},\\,P_{\\text{fuse}},\\,P_{\\text{SoA+fuse}},\\,s_{\\min}\\big]$. Recall that $1\\,\\text{GFLOP/s} = 10^{9}\\,\\text{FLOP/s}$ and $1\\,\\text{TB/s} = 10^{12}\\,\\text{byte/s}$.",
            "solution": "This solution involves applying the Roofline model, $P_{\\text{roof}} = \\min(P_{\\text{peak}}, I \\cdot B)$, to each specified scenario. The core of the problem is to determine how each optimization strategy affects the arithmetic intensity $I = \\text{FLOPs}/\\text{bytes}$.\n\nFirst, we calculate the critical arithmetic intensity, or \"ridge point\" $I_{\\text{crit}}$, of the accelerator. This is the value of $I$ for which the memory performance ceiling equals the peak computational performance.\n$$I_{\\text{crit}} = \\frac{P_{\\text{peak}}}{B} = \\frac{19.5 \\times 10^{12}\\,\\text{FLOP/s}}{1.6 \\times 10^{12}\\,\\text{byte/s}} = 12.1875\\,\\text{FLOP/byte}$$\nIf a kernel's arithmetic intensity $I$ is less than $I_{\\text{crit}}$, its performance is limited by memory bandwidth ($P = I \\cdot B$). If $I \\ge I_{\\text{crit}}$, its performance is limited by the peak computational throughput ($P = P_{\\text{peak}}$).\n\nLet the baseline number of floating-point operations be $\\text{FLOPs}_0$ and the baseline bytes of data moved be $\\text{bytes}_0$. The baseline arithmetic intensity is $I_0 = \\frac{\\text{FLOPs}_0}{\\text{bytes}_0} = 0.60\\,\\text{FLOP/byte}$.\n\n**Scenario 1: Baseline**\nThe arithmetic intensity is given as $I_{\\text{base}} = I_0 = 0.60\\,\\text{FLOP/byte}$.\nSince $I_{\\text{base}} = 0.60  12.1875 = I_{\\text{crit}}$, the kernel is memory-bound.\nThe expected performance $P_{\\text{base}}$ is:\n$$P_{\\text{base}} = I_{\\text{base}} \\cdot B = 0.60\\,\\text{FLOP/byte} \\times 1.6 \\times 10^{12}\\,\\text{byte/s} = 0.96 \\times 10^{12}\\,\\text{FLOP/s}$$\nConverting to $\\text{GFLOP/s}$ ($1\\,\\text{GFLOP/s} = 10^9\\,\\text{FLOP/s}$):\n$$P_{\\text{base}} = 0.96 \\times 10^3\\,\\text{GFLOP/s} = 960\\,\\text{GFLOP/s}$$\nRounded to four significant figures, this is $960.0\\,\\text{GFLOP/s}$.\n\n**Scenario 2: SoA-only**\nThe structure-of-arrays (SoA) data layout reduces data traffic by $25\\%$ while the FLOP count remains the same.\n$$\\text{FLOPs}_{\\text{SoA}} = \\text{FLOPs}_0 \\quad ; \\quad \\text{bytes}_{\\text{SoA}} = 0.75 \\cdot \\text{bytes}_0$$\nThe new arithmetic intensity $I_{\\text{SoA}}$ is:\n$$I_{\\text{SoA}} = \\frac{\\text{FLOPs}_{\\text{SoA}}}{\\text{bytes}_{\\text{SoA}}} = \\frac{\\text{FLOPs}_0}{0.75 \\cdot \\text{bytes}_0} = \\frac{1}{0.75} I_0 = \\frac{4}{3} I_0 = \\frac{4}{3} \\cdot 0.60 = 0.80\\,\\text{FLOP/byte}$$\nSince $I_{\\text{SoA}} = 0.80  I_{\\text{crit}}$, the kernel remains memory-bound.\n$$P_{\\text{SoA}} = I_{\\text{SoA}} \\cdot B = 0.80\\,\\text{FLOP/byte} \\times 1.6 \\times 10^{12}\\,\\text{byte/s} = 1.28 \\times 10^{12}\\,\\text{FLOP/s}$$\nIn $\\text{GFLOP/s}$:\n$$P_{\\text{SoA}} = 1.28 \\times 10^3\\,\\text{GFLOP/s} = 1280\\,\\text{GFLOP/s}$$\n\n**Scenario 3: Fusion-only ($s=3$)**\nKernel fusion with a factor $s=3$ triples the FLOP count for the same amount of data transferred.\n$$\\text{FLOPs}_{\\text{fuse}} = 3 \\cdot \\text{FLOPs}_0 \\quad ; \\quad \\text{bytes}_{\\text{fuse}} = \\text{bytes}_0$$\nThe new arithmetic intensity $I_{\\text{fuse}}$ is:\n$$I_{\\text{fuse}} = \\frac{3 \\cdot \\text{FLOPs}_0}{\\text{bytes}_0} = 3 \\cdot I_0 = 3 \\cdot 0.60 = 1.80\\,\\text{FLOP/byte}$$\nSince $I_{\\text{fuse}} = 1.80  I_{\\text{crit}}$, the kernel is still memory-bound.\n$$P_{\\text{fuse}} = I_{\\text{fuse}} \\cdot B = 1.80\\,\\text{FLOP/byte} \\times 1.6 \\times 10^{12}\\,\\text{byte/s} = 2.88 \\times 10^{12}\\,\\text{FLOP/s}$$\nIn $\\text{GFLOP/s}$:\n$$P_{\\text{fuse}} = 2.88 \\times 10^3\\,\\text{GFLOP/s} = 2880\\,\\text{GFLOP/s}$$\n\n**Scenario 4: SoA-plus-fusion ($s=3$)**\nBoth optimizations are applied. FLOPs are tripled, and data traffic is reduced by $25\\%$.\n$$\\text{FLOPs}_{\\text{SoA+fuse}} = 3 \\cdot \\text{FLOPs}_0 \\quad ; \\quad \\text{bytes}_{\\text{SoA+fuse}} = 0.75 \\cdot \\text{bytes}_0$$\nThe new arithmetic intensity $I_{\\text{SoA+fuse}}$ is:\n$$I_{\\text{SoA+fuse}} = \\frac{3 \\cdot \\text{FLOPs}_0}{0.75 \\cdot \\text{bytes}_0} = \\frac{3}{0.75} I_0 = 4 \\cdot I_0 = 4 \\cdot 0.60 = 2.40\\,\\text{FLOP/byte}$$\nSince $I_{\\text{SoA+fuse}} = 2.40  I_{\\text{crit}}$, the kernel remains memory-bound.\n$$P_{\\text{SoA+fuse}} = I_{\\text{SoA+fuse}} \\cdot B = 2.40\\,\\text{FLOP/byte} \\times 1.6 \\times 10^{12}\\,\\text{byte/s} = 3.84 \\times 10^{12}\\,\\text{FLOP/s}$$\nIn $\\text{GFLOP/s}$:\n$$P_{\\text{SoA+fuse}} = 3.84 \\times 10^3\\,\\text{GFLOP/s} = 3840\\,\\text{GFLOP/s}$$\n\n**Task 2: Minimum fusion factor $s_{\\min}$**\nWe need to find the minimum positive integer $s$ such that the kernel with SoA and fusion becomes compute-bound. The condition for being compute-bound is $I \\ge I_{\\text{crit}}$.\nThe arithmetic intensity for the combined SoA and fusion with a general factor $s$ is:\n$$I_{\\text{SoA}+s} = \\frac{s \\cdot \\text{FLOPs}_0}{0.75 \\cdot \\text{bytes}_0} = \\frac{s}{0.75} I_0 = \\frac{4s}{3} I_0$$\nSet this to be greater than or equal to the critical intensity:\n$$\\frac{4s}{3} I_0 \\ge I_{\\text{crit}}$$\nNow we solve for $s$:\n$$s \\ge \\frac{3 \\cdot I_{\\text{crit}}}{4 \\cdot I_0}$$\nSubstituting the numerical values:\n$$s \\ge \\frac{3 \\cdot 12.1875}{4 \\cdot 0.60} = \\frac{36.5625}{2.4} = 15.234375$$\nSince the fusion factor $s$ must be a positive integer, the minimum value $s_{\\min}$ that satisfies this inequality is the smallest integer greater than or equal to $15.234375$.\n$$s_{\\min} = \\lceil 15.234375 \\rceil = 16$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n960.0  1280  2880  3840  16\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "In SIMT architectures, performance is not just about FLOPs and bytes; it is also about control flow. This final exercise delves into the critical issue of warp divergence, a common performance limiter in CFD codes where different physical conditions require different computations. You will quantitatively compare two classic strategies for handling conditional logic—branching and predication—by modeling their respective costs in terms of instruction throughput and lane utilization, equipping you with the analytical tools to choose the right control-flow strategy for maximizing warp efficiency. ",
            "id": "3940886",
            "problem": "Consider a warp-level implementation of inviscid face fluxes for the compressible Euler equations in a Graphics Processing Unit (GPU) Single Instruction Multiple Threads (SIMT) execution model applied to Aerospace Computational Fluid Dynamics (CFD). Let the face-normal flux on a single face be determined by a Riemann-type decision that depends on the sign and magnitude of the face-normal Mach number. Each face is categorized into one of four mutually exclusive paths: supersonic positive, supersonic negative, subsonic, or solid wall. The face-normal Mach number is defined as $M_n = \\dfrac{\\boldsymbol{u} \\cdot \\hat{\\boldsymbol{n}}}{a}$ where $\\boldsymbol{u}$ is the velocity vector, $\\hat{\\boldsymbol{n}}$ is the unit normal vector, and $a$ is the local speed of sound. The four flux paths are:\n- Supersonic positive ($M_n \\geq 1$): upwind from the left state.\n- Supersonic negative ($M_n \\leq -1$): upwind from the right state.\n- Subsonic ($|M_n|  1$): a central Riemann flux with upwind bias.\n- Solid wall: a no-penetration flux based on projection of velocity onto the normal.\n\nLet a warp have size $W = 32$ lanes. Let there be $P = 4$ possible paths indexed by $i \\in \\{0,1,2,3\\}$ corresponding to supersonic positive, supersonic negative, subsonic, and solid wall, respectively. Let the arithmetic instruction lengths for each path be $L_0 = 16$, $L_1 = 16$, $L_2 = 48$, and $L_3 = 20$ instructions, representing plausible floating-point operation counts for the corresponding flux computations. Assume a branch reconvergence/control-flow overhead of $\\beta = 4$ instructions per additional divergent path in the warp when using branch-based control flow. Assume predicate-evaluation and mask-application overheads of $p = 2$ and $m = 1$ instructions per path, respectively, when using predication (predicate-based selection) to eliminate branch divergence.\n\nYou must construct a warp-aware flux computation that replaces branch divergence with predicate evaluation. To do so, define binary predicates $\\Pi_i \\in \\{0,1\\}$ per lane that select the flux path according to the face category, and compute the final flux as the masked sum $F = \\sum_{i=0}^{3} \\Pi_i F_i$ where $F_i$ is the flux computed along path $i$. In the branch-based approach, the warp executes only the paths present among its lanes, with serialization across the divergent paths.\n\nStarting only from the definitions above and the SIMT execution model (one instruction issued per warp with possible inactive lanes masked during divergent paths), derive formulas for the following quantities as functions of the face mix $\\{n_i\\}_{i=0}^{3}$, where $n_i$ is the number of lanes in the warp that require path $i$ and $\\sum_{i=0}^{3} n_i = W$:\n1. The total issued arithmetic instruction count per warp for branch-based control, $I_{\\text{branch}}$, given that the warp serializes over the set of paths present $S = \\{i \\mid n_i  0\\}$ and incurs reconvergence overhead per additional path.\n2. The average active-lane fraction during arithmetic instructions in the branch-based approach, $\\phi_{\\text{branch}}$, defined as the weighted average of active lanes across the arithmetic instructions issued on the paths taken.\n3. The total issued arithmetic instruction count per warp for predication, $I_{\\text{pred}}$, given that all paths are computed in all lanes with predicate masks and incurring the predicate and mask overheads.\n4. The average active-lane fraction during arithmetic instructions in the predication approach, $\\phi_{\\text{pred}}$, under the assumption that predication eliminates control-flow divergence at issue time.\n5. The extra issued arithmetic instructions $\\Delta I = I_{\\text{pred}} - I_{\\text{branch}}$ and the reduction in divergence $\\Delta \\phi = \\phi_{\\text{pred}} - \\phi_{\\text{branch}}$.\n6. An estimated relative time metric per warp $T \\propto I / \\phi$ under both approaches, and a boolean decision that predication is beneficial if $I_{\\text{pred}} / \\phi_{\\text{pred}}  I_{\\text{branch}} / \\phi_{\\text{branch}}$.\n\nImplement these formulas in a single, complete, runnable program that takes no input and evaluates the following test suite of face mixes, expressed as ordered quadruples $\\left[n_0,n_1,n_2,n_3\\right]$ in lanes:\n- Test $1$: $\\left[32,0,0,0\\right]$ (all supersonic positive).\n- Test $2$: $\\left[16,16,0,0\\right]$ (even split between supersonic positive and supersonic negative).\n- Test $3$: $\\left[8,8,16,0\\right]$ (skewed mix, subsonic dominates).\n- Test $4$: $\\left[8,8,8,8\\right]$ (uniform mix across all paths).\n- Test $5$: $\\left[0,0,32,0\\right]$ (all subsonic).\n- Test $6$: $\\left[0,0,0,32\\right]$ (all solid wall).\n\nYour program must compute, for each test case, and in this order:\n- $I_{\\text{branch}}$,\n- $I_{\\text{pred}}$,\n- $\\phi_{\\text{branch}}$,\n- $\\phi_{\\text{pred}}$,\n- $\\Delta I$,\n- $\\Delta \\phi$,\n- a boolean indicating whether predication is beneficial under the $T \\propto I/\\phi$ model.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a bracketed comma-separated list representing the seven metrics for one test case in the order specified. For example, the overall format should be $\\left[[x_1,x_2,x_3,x_4,x_5,x_6,x_7],[\\dots],\\dots\\right]$ with no spaces.",
            "solution": "Let $\\{n_i\\}_{i=0}^3$ be the distribution of faces across the $P=4$ paths for a single warp of size $W=32$. Let the set of active paths in the warp be $S = \\{i \\mid n_i  0\\}$. Let $|S|$ denote the cardinality of this set. The instruction length for path $i$ is $L_i$.\n\n1.  **Total Issued Instructions for Branch-Based Control, $I_{\\text{branch}}$**\n    In a branch-based SIMT model, the warp hardware issues instructions for each active path sequentially. The total number of instructions is the sum of instruction lengths for all active paths, plus overhead for managing the divergence.\n    - The sum of arithmetic instructions for all active paths is $\\sum_{i \\in S} L_i$.\n    - The control-flow overhead is $\\beta$ instructions per additional divergent path, so the total overhead is $\\beta \\cdot \\max(0, |S|-1)$.\n    Combining these, the total issued instruction count is:\n    $$I_{\\text{branch}} = \\left( \\sum_{i \\in S} L_i \\right) + \\beta \\cdot \\max(0, |S| - 1)$$\n\n2.  **Average Active-Lane Fraction for Branching, $\\phi_{\\text{branch}}$**\n    This metric quantifies the utilization of the warp during the execution of arithmetic instructions. It is the total number of active lane-instructions divided by the total number of possible lane-instructions during arithmetic computation.\n    - For a specific active path $j \\in S$, there are $L_j$ instructions issued, during which $n_j$ lanes are active, contributing $n_j L_j$ active lane-instructions.\n    - The total number of active lane-instructions is $\\sum_{j \\in S} n_j L_j$.\n    - The total number of issued arithmetic instructions is $\\sum_{k \\in S} L_k$.\n    The average active-lane fraction is the ratio:\n    $$\\phi_{\\text{branch}} = \\frac{\\sum_{i \\in S} n_i L_i}{W \\sum_{i \\in S} L_i}$$\n\n3.  **Total Issued Instructions for Predication, $I_{\\text{pred}}$**\n    Predication avoids branch divergence by computing all possible paths and selecting the correct result using a predicate mask. The instruction count is constant, regardless of the lane distribution.\n    - Arithmetic instructions for all $P=4$ paths are executed: $\\sum_{i=0}^{3} L_i$.\n    - An overhead of $p=2$ instructions for predicate evaluation and $m=1$ instruction for mask application is incurred for each of the $P$ paths, totaling $P \\cdot (p+m)$.\n    The total predication instruction count is:\n    $$I_{\\text{pred}} = \\left(\\sum_{i=0}^{3} L_i\\right) + P \\cdot (p + m)$$\n    Substituting the given values:\n    $$I_{\\text{pred}} = (16 + 16 + 48 + 20) + 4(2+1) = 100 + 12 = 112$$\n\n4.  **Average Active-Lane Fraction for Predication, $\\phi_{\\text{pred}}$**\n    Predication eliminates control-flow divergence at issue time, meaning all $W$ lanes of the warp are active from the scheduler's perspective.\n    $$\\phi_{\\text{pred}} = 1.0$$\n\n5.  **Instruction and Divergence Deltas, $\\Delta I$ and $\\Delta \\phi$**\n    These quantities measure the change when moving from the branch-based to the predicated approach.\n    - Extra instructions issued: $\\Delta I = I_{\\text{pred}} - I_{\\text{branch}}$\n    - Increase in average lane activity: $\\Delta \\phi = \\phi_{\\text{pred}} - \\phi_{\\text{branch}}$\n\n6.  **Relative Time Metric and Benefit Decision**\n    The execution time $T$ is proportional to $I / \\phi$.\n    - Relative time for branching: $T_{\\text{branch}} \\propto I_{\\text{branch}} / \\phi_{\\text{branch}}$.\n    - Relative time for predication: $T_{\\text{pred}} \\propto I_{\\text{pred}} / \\phi_{\\text{pred}} = I_{\\text{pred}}$.\n    Predication is beneficial if $T_{\\text{pred}}  T_{\\text{branch}}$, which translates to the boolean condition: $I_{\\text{pred}}  \\frac{I_{\\text{branch}}}{\\phi_{\\text{branch}}}$.",
            "answer": "[[16,112,1.0,1.0,96,0.0,False],[36,112,0.5,1.0,76,0.5,False],[88,112,0.4,1.0,24,0.6,True],[112,112,0.25,1.0,0,0.75,True],[48,112,1.0,1.0,64,0.0,False],[20,112,1.0,1.0,92,0.0,False]]"
        }
    ]
}