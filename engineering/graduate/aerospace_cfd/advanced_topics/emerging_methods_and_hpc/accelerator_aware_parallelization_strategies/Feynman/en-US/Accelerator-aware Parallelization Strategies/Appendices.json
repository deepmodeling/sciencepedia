{
    "hands_on_practices": [
        {
            "introduction": "Effective parallelization on accelerators like GPUs begins with a firm grasp of the underlying hardware constraints. A primary goal is to maximize \"occupancy,\" which measures how effectively the hardware's parallel processing units are kept busy. This exercise challenges you to derive the theoretical occupancy limit from first principles, revealing how a kernel's demand for finite resources—specifically registers and shared memory—directly governs the number of thread blocks that can run concurrently on a Streaming Multiprocessor (SM).",
            "id": "3940860",
            "problem": "Consider a compressible Navier–Stokes solver for aerospace Computational Fluid Dynamics (CFD) that advances face-normal fluxes on a Graphics Processing Unit (GPU). The solver uses a Single Instruction, Multiple Threads (SIMT) execution model with cooperative thread arrays, where each thread block stages face and cell data into shared memory to compute convective and diffusive flux contributions for a tile of the mesh. The kernel is designed for a Streaming Multiprocessor (SM) with a register file and a shared memory pool that are partitioned among concurrently resident thread blocks.\n\nAssume each thread in the kernel requires $r$ architectural registers, each thread block launches $T_b$ threads, and each thread block allocates $s$ bytes of shared memory. The SM exposes $R_{\\text{SM}}$ total registers and $S_{\\text{SM}}$ total shared memory bytes that can be distributed among resident blocks. The maximum resident threads per SM is $T_{\\text{SM}}$, the warp size is $W$, and occupancy is defined as the ratio of active warps to the hardware maximum warps resident per SM.\n\nStarting only from the following foundational facts:\n1. Registers and shared memory are conserved resources on an SM; a resident block consumes $r T_b$ registers and $s$ shared bytes, and multiple resident blocks sum their consumption.\n2. Warps are the unit of scheduling; a block with $T_b$ threads contains $\\lceil T_b / W \\rceil$ warps, and the hardware maximum resident warps per SM equals $T_{\\text{SM}} / W$.\n3. Occupancy equals the number of active warps divided by the hardware maximum resident warps.\n\nDerive, from first principles, a closed-form analytic expression for the occupancy upper bound imposed solely by limited registers and shared memory (ignore all other constraints such as per-SM maximum blocks and per-SM maximum threads beyond their role in normalizing occupancy). Express your final result as a single analytic expression in terms of $r$, $s$, $T_b$, $R_{\\text{SM}}$, $S_{\\text{SM}}$, $T_{\\text{SM}}$, and $W$. No numerical evaluation is required. No units are required.",
            "solution": "The problem requires the derivation of a closed-form analytic expression for the occupancy upper bound on a Graphics Processing Unit (GPU) Streaming Multiprocessor (SM), considering only the constraints imposed by register and shared memory resources. Occupancy, which we shall denote by $O$, is a key metric of hardware utilization.\n\nFirst, we begin with the provided definition of occupancy (foundational fact 3):\n$$\nO = \\frac{\\text{Number of Active Warps}}{\\text{Maximum Possible Resident Warps}}\n$$\n\nThe denominator, the maximum possible number of resident warps on an SM, is a fixed hardware characteristic. Based on foundational fact 2, this maximum is the total number of threads an SM can support, $T_{\\text{SM}}$, divided by the number of threads in a warp, $W$. Let us denote this maximum as $W_{\\text{max}}$.\n$$\nW_{\\text{max}} = \\frac{T_{\\text{SM}}}{W}\n$$\nThe problem specifies that a warp is the fundamental unit of scheduling, so this ratio correctly represents the maximum warp capacity.\n\nNext, we must determine the numerator: the number of active warps. This quantity is not fixed but depends on the kernel's resource requirements. The number of active warps, $W_{\\text{active}}$, is the product of the number of thread blocks that can be concurrently resident on the SM, which we denote as $N_b$, and the number of warps per thread block, denoted as $W_b$.\n$$\nW_{\\text{active}} = N_b \\times W_b\n$$\n\nThe number of warps per block, $W_b$, is determined by the number of threads per block, $T_b$, and the warp size, $W$. Since threads are grouped into discrete warps, any partial warp still requires the allocation of a full warp. Therefore, we must use the ceiling function. From foundational fact 2, we have:\n$$\nW_b = \\left\\lceil \\frac{T_b}{W} \\right\\rceil\n$$\n\nThe crucial step is to find an expression for $N_b$, the maximum number of concurrently resident blocks. The problem statement dictates that this is limited *solely* by register and shared memory availability. According to foundational fact 1, these resources are conserved and partitioned among resident blocks.\n\nLet us first consider the constraint imposed by the register file. The SM has a total of $R_{\\text{SM}}$ registers. Each thread requires $r$ registers, and a thread block contains $T_b$ threads. Thus, the total number of registers consumed by a single thread block is $r T_b$. The maximum number of blocks that can be accommodated by the register file, $N_{b,R}$, is the total available registers divided by the registers consumed per block. Since blocks are indivisible entities, we must take the floor of this ratio.\n$$\nN_{b,R} = \\left\\lfloor \\frac{R_{\\text{SM}}}{r T_b} \\right\\rfloor\n$$\n\nSecond, we consider the constraint imposed by shared memory. The SM has a total of $S_{\\text{SM}}$ bytes of shared memory. Each thread block allocates $s$ bytes. The maximum number of blocks that can be accommodated by the available shared memory, $N_{b,S}$, is the total shared memory divided by the amount consumed per block. Again, we must use the floor function.\n$$\nN_{b,S} = \\left\\lfloor \\frac{S_{\\text{SM}}}{s} \\right\\rfloor\n$$\n\nFor a thread block to be launched and become resident on the SM, there must be sufficient resources of *both* registers and shared memory. Therefore, the actual maximum number of resident blocks, $N_b$, is governed by the more restrictive of these two constraints. This is found by taking the minimum of the two calculated limits.\n$$\nN_b = \\min(N_{b,R}, N_{b,S}) = \\min\\left(\\left\\lfloor \\frac{R_{\\text{SM}}}{r T_b} \\right\\rfloor, \\left\\lfloor \\frac{S_{\\text{SM}}}{s} \\right\\rfloor\\right)\n$$\n\nWe now have all the components to construct the final expression for occupancy, $O$. Substituting the expressions for $W_{\\text{active}}$ and $W_{\\text{max}}$ into the initial definition of occupancy:\n$$\nO = \\frac{W_{\\text{active}}}{W_{\\text{max}}} = \\frac{N_b \\times W_b}{T_{\\text{SM}} / W}\n$$\nSubstituting our derived expressions for $N_b$ and $W_b$:\n$$\nO = \\frac{\\min\\left(\\left\\lfloor \\frac{R_{\\text{SM}}}{r T_b} \\right\\rfloor, \\left\\lfloor \\frac{S_{\\text{SM}}}{s} \\right\\rfloor\\right) \\times \\left\\lceil \\frac{T_b}{W} \\right\\rceil}{\\frac{T_{\\text{SM}}}{W}}\n$$\nRearranging this expression into its final, closed-form analytic state gives the upper bound on occupancy as a function of the specified parameters.\n$$\nO = \\frac{W}{T_{\\text{SM}}} \\min\\left(\\left\\lfloor \\frac{R_{\\text{SM}}}{r T_b} \\right\\rfloor, \\left\\lfloor \\frac{S_{\\text{SM}}}{s} \\right\\rfloor\\right) \\left\\lceil \\frac{T_b}{W} \\right\\rceil\n$$\nThis expression represents the theoretical occupancy ceiling imposed by the kernel's register and shared memory footprint, derived strictly from the provided first principles.",
            "answer": "$$\\boxed{\\frac{W}{T_{\\text{SM}}} \\min\\left(\\left\\lfloor \\frac{R_{\\text{SM}}}{r T_b} \\right\\rfloor, \\left\\lfloor \\frac{S_{\\text{SM}}}{s} \\right\\rfloor\\right) \\left\\lceil \\frac{T_b}{W} \\right\\rceil}$$"
        },
        {
            "introduction": "Beyond maximizing hardware occupancy, achieving high performance requires understanding whether your algorithm is limited by memory bandwidth or computational throughput. The Roofline model provides an insightful visual framework for diagnosing these bottlenecks and predicting the impact of optimizations. In this practice, you will apply the Roofline model to a CFD kernel, quantifying how crucial strategies like changing data layouts (to Structure-of-Arrays) and kernel fusion can increase arithmetic intensity and push performance towards the processor's peak computational capability.",
            "id": "3940816",
            "problem": "A finite-volume compressible Navier–Stokes residual kernel on an unstructured mesh is mapped to a Graphics Processing Unit (GPU) accelerator. For this kernel, you have measured the arithmetic intensity, defined as the ratio of floating-point operations to off-chip data movement, $I \\equiv \\frac{\\text{FLOPs}}{\\text{bytes}}$, to be $I_{0} = 0.60\\,\\text{FLOP/byte}$ for the current array-of-structures data layout. The target accelerator has a peak floating-point throughput $P_{\\text{peak}}$ and a sustained off-chip memory bandwidth $B$, taken as $P_{\\text{peak}} = 19.5\\times 10^{12}\\,\\text{FLOP s}^{-1}$ and $B = 1.6\\times 10^{12}\\,\\text{byte s}^{-1}$, respectively. Assume the Roofline performance model applies with arithmetic intensity measured at the High Bandwidth Memory (HBM) level. \n\nTwo accelerator-aware parallelization and data movement strategies are considered:\n1. A structure-of-arrays (SoA) data layout that reduces off-chip data traffic by $25\\%$ for the same floating-point work (that is, the off-chip bytes become $0.75$ times the baseline), with no change in the floating-point operation count.\n2. Kernel fusion of $s$ successive physics updates (e.g., flux and source term applications) that multiplies the floating-point operation count by $s$ while perfectly reusing the same off-chip data once loaded (that is, the off-chip bytes remain unchanged relative to the unfused case).\n\nUse only the following fundamental bases:\n- The definition of arithmetic intensity $I = \\frac{\\text{FLOPs}}{\\text{bytes}}$.\n- The definition of performance $P = \\frac{\\text{FLOPs}}{t}$ and bandwidth-limited time $t_{\\text{mem}} \\ge \\frac{\\text{bytes}}{B}$, and compute-limited time $t_{\\text{comp}} \\ge \\frac{\\text{FLOPs}}{P_{\\text{peak}}}$.\n- The Roofline upper bound $P_{\\text{roof}} = \\min\\!\\big(P_{\\text{peak}},\\, I\\,B\\big)$.\n\nTasks:\n- Compute the expected sustained performance in $\\text{GFLOP s}^{-1}$ for the following four scenarios using the Roofline model: baseline, SoA-only, fusion-only with $s=3$, and SoA-plus-fusion with $s=3$. \n- Then, determine the minimum positive integer fusion factor $s_{\\min}$ such that after applying the SoA optimization, the kernel becomes compute-bound under the Roofline model, i.e., $I_{\\text{SoA}\\,+\\,s_{\\min}}\\,B \\ge P_{\\text{peak}}$.\n\nExpress the four performances in $\\text{GFLOP s}^{-1}$ and round them to four significant figures. Report your final answer as a row vector $\\big[P_{\\text{base}},\\,P_{\\text{SoA}},\\,P_{\\text{fuse}},\\,P_{\\text{SoA+fuse}},\\,s_{\\min}\\big]$. Recall that $1\\,\\text{GFLOP s}^{-1} = 10^{9}\\,\\text{FLOP s}^{-1}$ and $1\\,\\text{TB s}^{-1} = 10^{12}\\,\\text{byte s}^{-1}$.",
            "solution": "This problem requires applying the Roofline performance model to four scenarios and determining a condition for becoming compute-bound. The core of the analysis is to calculate the arithmetic intensity ($I$) for each case and compare it to the accelerator's performance limits.\n\n**Step 1: Determine the Accelerator's Ridge Point**\nThe Roofline model is defined by $P_{\\text{sustained}} = \\min(P_{\\text{peak}}, I \\cdot B)$. The \"ridge point,\" or critical intensity $I_{\\text{crit}}$, is where the memory performance ceiling intersects the compute ceiling.\n$$I_{\\text{crit}} = \\frac{P_{\\text{peak}}}{B} = \\frac{19.5 \\times 10^{12}\\,\\text{FLOP s}^{-1}}{1.6 \\times 10^{12}\\,\\text{byte s}^{-1}} = 12.1875\\,\\text{FLOP/byte}$$\nAny kernel with $I < I_{\\text{crit}}$ is memory-bound, with performance $P = I \\cdot B$. Any kernel with $I \\ge I_{\\text{crit}}$ is compute-bound, with performance $P = P_{\\text{peak}}$.\n\n**Step 2: Analyze Each Scenario**\nLet the baseline FLOPs and bytes be $\\text{FLOPs}_0$ and $\\text{bytes}_0$. The baseline intensity is $I_0 = \\frac{\\text{FLOPs}_0}{\\text{bytes}_0} = 0.60\\,\\text{FLOP/byte}$.\n\n*   **Baseline:**\n    $I_{\\text{base}} = 0.60\\,\\text{FLOP/byte}$. Since $0.60 < 12.1875$, it's memory-bound.\n    $P_{\\text{base}} = I_{\\text{base}} \\cdot B = 0.60 \\times 1.6 \\times 10^{12} = 9.6 \\times 10^{11}\\,\\text{FLOP/s} = 960.0\\,\\text{GFLOP/s}$.\n\n*   **SoA-only:** Bytes are reduced by 25% ($\\times 0.75$).\n    $I_{\\text{SoA}} = \\frac{\\text{FLOPs}_0}{0.75 \\cdot \\text{bytes}_0} = \\frac{I_0}{0.75} = \\frac{0.60}{0.75} = 0.80\\,\\text{FLOP/byte}$. Still memory-bound.\n    $P_{\\text{SoA}} = I_{\\text{SoA}} \\cdot B = 0.80 \\times 1.6 \\times 10^{12} = 1.28 \\times 10^{12}\\,\\text{FLOP/s} = 1280\\,\\text{GFLOP/s}$.\n\n*   **Fusion-only ($s=3$):** FLOPs are tripled.\n    $I_{\\text{fuse}} = \\frac{3 \\cdot \\text{FLOPs}_0}{\\text{bytes}_0} = 3 \\cdot I_0 = 3 \\times 0.60 = 1.80\\,\\text{FLOP/byte}$. Still memory-bound.\n    $P_{\\text{fuse}} = I_{\\text{fuse}} \\cdot B = 1.80 \\times 1.6 \\times 10^{12} = 2.88 \\times 10^{12}\\,\\text{FLOP/s} = 2880\\,\\text{GFLOP/s}$.\n\n*   **SoA-plus-fusion ($s=3$):** FLOPs tripled, bytes reduced by 25%.\n    $I_{\\text{SoA+fuse}} = \\frac{3 \\cdot \\text{FLOPs}_0}{0.75 \\cdot \\text{bytes}_0} = \\frac{3}{0.75} \\cdot I_0 = 4 \\times 0.60 = 2.40\\,\\text{FLOP/byte}$. Still memory-bound.\n    $P_{\\text{SoA+fuse}} = I_{\\text{SoA+fuse}} \\cdot B = 2.40 \\times 1.6 \\times 10^{12} = 3.84 \\times 10^{12}\\,\\text{FLOP/s} = 3840\\,\\text{GFLOP/s}$.\n\n**Step 3: Calculate Minimum Fusion Factor $s_{\\min}$**\nWe need to find the minimum integer $s$ that makes the SoA-optimized kernel compute-bound. The intensity for this case is $I(s) = \\frac{s \\cdot I_0}{0.75} = \\frac{4s}{3}I_0$. The condition is $I(s) \\ge I_{\\text{crit}}$.\n$$\\frac{4s}{3} \\cdot 0.60 \\ge 12.1875$$\n$$0.8s \\ge 12.1875$$\n$$s \\ge \\frac{12.1875}{0.8} = 15.234375$$\nSince $s$ must be an integer, the minimum value is $s_{\\min} = \\lceil 15.234375 \\rceil = 16$.\n\nThe final results are collected into the required vector format.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n960.0 & 1280 & 2880 & 3840 & 16\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Achieving high theoretical performance via the Roofline model can be undermined by practical issues like control-flow divergence within a SIMT warp. When threads in a warp take different execution paths, the paths are serialized, reducing effective parallelism and performance. This problem presents a common CFD scenario—computing fluxes with different logic for supersonic, subsonic, and wall-boundary faces—to quantitatively analyze the trade-off between standard branching and using predication to create a single, divergence-free execution path.",
            "id": "3940886",
            "problem": "Consider a warp-level implementation of inviscid face fluxes for the compressible Euler equations in a Graphics Processing Unit (GPU) Single Instruction Multiple Threads (SIMT) execution model applied to Aerospace Computational Fluid Dynamics (CFD). Let the face-normal flux on a single face be determined by a Riemann-type decision that depends on the sign and magnitude of the face-normal Mach number. Each face is categorized into one of four mutually exclusive paths: supersonic positive, supersonic negative, subsonic, or solid wall. The face-normal Mach number is defined as $M_n = \\dfrac{\\boldsymbol{u} \\cdot \\hat{\\boldsymbol{n}}}{a}$ where $\\boldsymbol{u}$ is the velocity vector, $\\hat{\\boldsymbol{n}}$ is the unit normal vector, and $a$ is the local speed of sound. The four flux paths are:\n- Supersonic positive ($M_n \\geq 1$): upwind from the left state.\n- Supersonic negative ($M_n \\leq -1$): upwind from the right state.\n- Subsonic ($|M_n| &lt; 1$): a central Riemann flux with upwind bias.\n- Solid wall: a no-penetration flux based on projection of velocity onto the normal.\n\nLet a warp have size $W = 32$ lanes. Let there be $P = 4$ possible paths indexed by $i \\in \\{0,1,2,3\\}$ corresponding to supersonic positive, supersonic negative, subsonic, and solid wall, respectively. Let the arithmetic instruction lengths for each path be $L_0 = 16$, $L_1 = 16$, $L_2 = 48$, and $L_3 = 20$ instructions, representing plausible floating-point operation counts for the corresponding flux computations. Assume a branch reconvergence/control-flow overhead of $\\beta = 4$ instructions per additional divergent path in the warp when using branch-based control flow. Assume predicate-evaluation and mask-application overheads of $p = 2$ and $m = 1$ instructions per path, respectively, when using predication (predicate-based selection) to eliminate branch divergence.\n\nYou must construct a warp-aware flux computation that replaces branch divergence with predicate evaluation. To do so, define binary predicates $\\Pi_i \\in \\{0,1\\}$ per lane that select the flux path according to the face category, and compute the final flux as the masked sum $F = \\sum_{i=0}^{3} \\Pi_i F_i$ where $F_i$ is the flux computed along path $i$. In the branch-based approach, the warp executes only the paths present among its lanes, with serialization across the divergent paths.\n\nStarting only from the definitions above and the SIMT execution model (one instruction issued per warp with possible inactive lanes masked during divergent paths), derive formulas for the following quantities as functions of the face mix $\\{n_i\\}_{i=0}^{3}$, where $n_i$ is the number of lanes in the warp that require path $i$ and $\\sum_{i=0}^{3} n_i = W$:\n1. The total issued arithmetic instruction count per warp for branch-based control, $I_{\\text{branch}}$, given that the warp serializes over the set of paths present $S = \\{i \\mid n_i &gt; 0\\}$ and incurs reconvergence overhead per additional path.\n2. The average active-lane fraction during arithmetic instructions in the branch-based approach, $\\phi_{\\text{branch}}$, defined as the weighted average of active lanes across the arithmetic instructions issued on the paths taken.\n3. The total issued arithmetic instruction count per warp for predication, $I_{\\text{pred}}$, given that all paths are computed in all lanes with predicate masks and incurring the predicate and mask overheads.\n4. The average active-lane fraction during arithmetic instructions in the predication approach, $\\phi_{\\text{pred}}$, under the assumption that predication eliminates control-flow divergence at issue time.\n5. The extra issued arithmetic instructions $\\Delta I = I_{\\text{pred}} - I_{\\text{branch}}$ and the reduction in divergence $\\Delta \\phi = \\phi_{\\text{pred}} - \\phi_{\\text{branch}}$.\n6. An estimated relative time metric per warp $T \\propto I / \\phi$ under both approaches, and a boolean decision that predication is beneficial if $I_{\\text{pred}} / \\phi_{\\text{pred}} &lt; I_{\\text{branch}} / \\phi_{\\text{branch}}$.\n\nImplement these formulas in a single, complete, runnable program that takes no input and evaluates the following test suite of face mixes, expressed as ordered quadruples $\\left[n_0,n_1,n_2,n_3\\right]$ in lanes:\n- Test $1$: $\\left[32,0,0,0\\right]$ (all supersonic positive).\n- Test $2$: $\\left[16,16,0,0\\right]$ (even split between supersonic positive and supersonic negative).\n- Test $3$: $\\left[8,8,16,0\\right]$ (skewed mix, subsonic dominates).\n- Test $4$: $\\left[8,8,8,8\\right]$ (uniform mix across all paths).\n- Test $5$: $\\left[0,0,32,0\\right]$ (all subsonic).\n- Test $6$: $\\left[0,0,0,32\\right]$ (all solid wall).\n\nYour program must compute, for each test case, and in this order:\n- $I_{\\text{branch}}$,\n- $I_{\\text{pred}}$,\n- $\\phi_{\\text{branch}}$,\n- $\\phi_{\\text{pred}}$,\n- $\\Delta I$,\n- $\\Delta \\phi$,\n- a boolean indicating whether predication is beneficial under the $T \\propto I/\\phi$ model.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a bracketed comma-separated list representing the seven metrics for one test case in the order specified. For example, the overall format should be $\\left[[x_1,x_2,x_3,x_4,x_5,x_6,x_7],[\\dots],\\dots\\right]$ with no spaces.",
            "solution": "This problem requires a quantitative comparison between branch-based and predicate-based control flow in a SIMT execution model. We will derive the formulas for instruction count and lane utilization for both approaches, then apply them to the test cases.\n\nLet $\\{n_i\\}$ be the number of lanes in a warp of size $W$ taking path $i$, where $i \\in \\{0, 1, 2, 3\\}$. Let $L_i$ be the instruction length of path $i$. Let $S = \\{i \\mid n_i > 0\\}$ be the set of active paths in the warp, and $|S|$ be its size.\n\n**1. Branch-Based Approach ($I_{\\text{branch}}, \\phi_{\\text{branch}}$)**\nThe hardware serializes execution over the active paths.\n*   **Instruction Count ($I_{\\text{branch}}$):** The total instructions are the sum of lengths of all active paths, plus a divergence overhead for each additional path. The overhead is $\\beta$ for each divergence point, so $\\beta \\cdot (|S|-1)$ for $|S|>1$.\n    $$I_{\\text{branch}} = \\left( \\sum_{i \\in S} L_i \\right) + \\beta \\cdot \\max(0, |S| - 1)$$\n*   **Active-Lane Fraction ($\\phi_{\\text{branch}}$):** This measures utilization during *arithmetic* instructions. For a given active path $i$, $n_i$ lanes are active for $L_i$ instructions. The average fraction is the total number of active lane-instructions divided by the total possible lane-instructions for the arithmetic portion.\n    $$\\phi_{\\text{branch}} = \\frac{\\sum_{i \\in S} n_i L_i}{W \\sum_{i \\in S} L_i}$$\n    If $|S|=1$ (no divergence), $\\phi_{\\text{branch}} = 1$.\n\n**2. Predication-Based Approach ($I_{\\text{pred}}, \\phi_{\\text{pred}}$)**\nThis approach executes all paths and uses masks to select the correct result, avoiding control-flow divergence.\n*   **Instruction Count ($I_{\\text{pred}}$):** The total instructions are the sum of lengths of *all* paths, plus overheads for evaluating predicates ($p$ per path) and applying masks ($m$ per path).\n    $$I_{\\text{pred}} = \\left(\\sum_{i=0}^{3} L_i\\right) + P \\cdot p + P \\cdot m = (16+16+48+20) + 4(2+1) = 112$$\n    This is constant for all test cases.\n*   **Active-Lane Fraction ($\\phi_{\\text{pred}}$):** Since divergence is eliminated at the instruction issue stage, all $W$ lanes are considered active for every issued instruction.\n    $$\\phi_{\\text{pred}} = 1.0$$\n\n**3. Comparison Metrics**\n*   The change in instruction count is $\\Delta I = I_{\\text{pred}} - I_{\\text{branch}}$.\n*   The change in lane utilization is $\\Delta \\phi = \\phi_{\\text{pred}} - \\phi_{\\text{branch}}$.\n*   The performance model is $T \\propto I/\\phi$. Predication is beneficial if $T_{\\text{pred}} < T_{\\text{branch}}$, which simplifies to:\n    $$I_{\\text{pred}} < \\frac{I_{\\text{branch}}}{\\phi_{\\text{branch}}}$$\n\nThese formulas are implemented in the provided program to calculate the results for each test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the GPU warp performance modeling problem for different face mixes.\n    \"\"\"\n    \n    # --- Givens from the problem statement ---\n    W = 32  # Warp size in lanes\n    L = [16, 16, 48, 20]  # Instruction lengths for paths 0, 1, 2, 3\n    BETA = 4  # Branch reconvergence overhead per additional path\n    P_OVERHEAD = 2  # Predicate-evaluation overhead per path\n    M_OVERHEAD = 1  # Mask-application overhead per path\n    P = 4  # Total number of paths\n\n    # --- Test suite of face mixes [n0, n1, n2, n3] ---\n    test_cases = [\n        [32, 0, 0, 0],   # Test 1: All supersonic positive (coherent)\n        [16, 16, 0, 0],  # Test 2: 50/50 split supersonic +/-\n        [8, 8, 16, 0],   # Test 3: Skewed mix, subsonic dominates\n        [8, 8, 8, 8],    # Test 4: Uniform mix across all paths\n        [0, 0, 32, 0],   # Test 5: All subsonic (coherent)\n        [0, 0, 0, 32],   # Test 6: All solid wall (coherent)\n    ]\n\n    all_results = []\n\n    for n_mix in test_cases:\n        # --- Intermediate Quantities for Branching ---\n        \n        # S_cardinality is |S|, the number of active paths (where n_i > 0)\n        S_cardinality = sum(1 for count in n_mix if count > 0)\n        \n        # L_S is the sum of instruction lengths for active paths: sum_{i in S} L_i\n        L_S = sum(L[i] for i, count in enumerate(n_mix) if count > 0)\n        \n        # A_S is the total number of active lane-instructions: sum_{i in S} n_i * L_i\n        A_S = sum(n_mix[i] * L[i] for i, count in enumerate(n_mix) if count > 0)\n\n        # --- Metric 1: I_branch ---\n        # I_branch = (sum_{i in S} L_i) + beta * max(0, |S| - 1)\n        I_branch = L_S + BETA * max(0, S_cardinality - 1)\n\n        # --- Metric 2: I_pred ---\n        # I_pred = (sum_{i=0..3} L_i) + P * (p + m)\n        # This is a constant value for all test cases.\n        I_pred = sum(L) + P * (P_OVERHEAD + M_OVERHEAD)\n\n        # --- Metric 3: phi_branch ---\n        # phi_branch = (sum_{i in S} n_i*L_i) / (W * sum_{i in S} L_i)\n        # If L_S is 0 (not possible for these tests), it would imply no active paths.\n        # In a coherent case (|S|=1), A_S = W*L_k and L_S = L_k, so phi_branch = 1.\n        if L_S > 0:\n            phi_branch = A_S / (W * L_S)\n        else:\n            phi_branch = 1.0 # No divergence if no paths are taken.\n        \n        # --- Metric 4: phi_pred ---\n        # Predication eliminates divergence, so all lanes are active.\n        phi_pred = 1.0\n\n        # --- Metric 5: Delta I ---\n        # Delta I = I_pred - I_branch\n        delta_I = I_pred - I_branch\n\n        # --- Metric 6: Delta phi ---\n        # Delta phi = phi_pred - phi_branch\n        delta_phi = phi_pred - phi_branch\n\n        # --- Metric 7: Predication Benefit ---\n        # Beneficial if T_pred < T_branch => I_pred/phi_pred < I_branch/phi_branch\n        # Since phi_pred = 1, this is I_pred < I_branch / phi_branch.\n        # phi_branch cannot be zero for the given test cases, so division is safe.\n        is_beneficial = I_pred < (I_branch / phi_branch)\n\n        current_results = [\n            I_branch,\n            I_pred,\n            phi_branch,\n            phi_pred,\n            delta_I,\n            delta_phi,\n            is_beneficial\n        ]\n        all_results.append(current_results)\n    \n    # --- Format the Final Output String ---\n    # The requirement is a very specific, space-free format.\n    # e.g., [[val1,val2,...],[val1,val2,...]]\n    case_strings = []\n    for res in all_results:\n        # Format floats to a reasonable precision if needed, but str() is generally fine.\n        # str() of a boolean is 'True' or 'False', which is acceptable.\n        # map(str, res) converts each item in the list to its string representation.\n        # ','.join(...) creates the comma-separated content.\n        case_str = '[' + ','.join(map(str, res)) + ']'\n        case_strings.append(case_str)\n    \n    final_output = '[' + ','.join(case_strings) + ']'\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}