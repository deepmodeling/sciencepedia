{
    "hands_on_practices": [
        {
            "introduction": "理论只有通过实践才能真正内化。本章提供了一系列动手练习，旨在巩固您对并行计算和区域分解核心概念的理解。这些练习将引导您分析、建模并实现并行算法，从而将抽象的理论转化为解决实际问题的能力。\n\n### 建模通信开销\n\n在设计可扩展的并行程序时，性能建模是一项至关重要的技能。它使我们能够预测算法在不同规模的计算资源上的表现，而不是依赖昂贵的反复试验。这个练习将引导您使用一个基础的性能模型来量化并行计算中不可避免的通信开销。\n\n我们将应用经典的延迟-带宽模型（$T = \\alpha + \\beta m$）来分析三维块状分解中的晕轮交换（halo exchange）。通过推导总通信时间的封闭形式表达式，您将亲身体会到通信成本如何受网格尺寸、处理器布局和计算模板宽度的影响，为优化并行性能提供理论依据。",
            "id": "3983349",
            "problem": "考虑一个三维结构化有限体积计算流体力学 (CFD) 求解器，该求解器在具有 $N_{x} \\times N_{y} \\times N_{z}$ 个控制体的均匀笛卡尔网格上求解可压缩纳维-斯托克斯方程。并行化使用跨越 $P$ 个 Message Passing Interface (MPI; 消息传递接口) 进程的块状域分解，这些进程排列成大小为 $P_{x} \\times P_{y} \\times P_{z}$ 的逻辑处理器网格，其中 $P = P_{x} P_{y} P_{z}$。并假设 $N_{x}$、$N_{y}$ 和 $N_{z}$ 分别可被 $P_{x}$、$P_{y}$ 和 $P_{z}$ 整除。每个进程拥有一个大小为 $n_{x} \\times n_{y} \\times n_{z}$ 个单元的子域，其中 $n_{x} = N_{x}/P_{x}$，$n_{y} = N_{y}/P_{y}$，$n_{z} = N_{z}/P_{z}$。使用宽度为 $w$ 的模板，这意味着厚度为 $w$ 的光环层必须沿三个坐标方向中的每一个与面相邻的邻居交换。假设：\n- 沿子域面的每次光环交换都作为包含该面 $w$ 层的单条消息执行（不为边或角发送单独的消息）。\n- 为每个光环单元交换一个包含 $q$ 个标量分量的守恒状态向量。\n- 单条消息的通信时间由标准延迟-带宽关系 $T_{\\text{msg}} = \\alpha + \\beta m$ 建模，其中 $\\alpha$ 是延迟，$\\beta$ 是逆带宽（每个标量数据项的时间），$m$ 是消息中标量数据项的数量。\n- 只计算进程间交换；物理边界条件不会产生 MPI 通信。\n\n在一个完整的光环交换步骤（即所有三个方向）中，对所有有向的进程间面消息使用模型 $T = \\sum_{\\text{faces}} \\left( \\alpha + \\beta m_{\\text{face}} \\right)$，推导总光环交换时间 $T_{\\text{total}}$ 的闭式表达式，用 $N_{x}$、$N_{y}$、$N_{z}$、$P_{x}$、$P_{y}$、$P_{z}$、$w$、$q$、$\\alpha$ 和 $\\beta$ 表示。将最终结果表示为以秒为单位的单个解析表达式。无需进行数值计算。",
            "solution": "我们从 Message Passing Interface (MPI; 消息传递接口) 的标准延迟-带宽通信模型开始，该模型指出，发送包含 $m$ 个标量数据项的消息所需的时间为 $T_{\\text{msg}} = \\alpha + \\beta m$，其中 $\\alpha$ 是延迟，$\\beta$ 是每个标量数据项的时间。对于结构化块分解，光环交换在面相邻的子域之间执行，在每个共享面上双向发送 $w$ 层单元。\n\n在一次完整的所有三个坐标方向的交换过程中，整个处理器网格上的总光环交换时间 $T_{\\text{total}}$ 是对所有有向面消息的消息时间 $T_{\\text{msg}}$ 求和得出的。因此，我们必须确定：\n1. 每个方向上有向的进程间面消息的数量。\n2. 每条此类消息的大小 $m_{\\text{face}}$，用网格和分解参数表示。\n\n首先，考虑大小为 $P_{x} \\times P_{y} \\times P_{z}$ 的处理器网格。沿 $x$ 方向，有 $P_{y} P_{z}$ 条处理器线，每条线包含 $P_{x}$ 个进程。沿 $x$ 方向的进程间接口数量是这些线中的内部边界数量，即每条线有 $\\left( P_{x} - 1 \\right)$ 个。因此，沿 $x$ 方向的无向接口总数为 $\\left( P_{x} - 1 \\right) P_{y} P_{z}$。由于光环交换是双向的（每个接口在两个方向上都产生一次发送），沿 $x$ 方向的有向消息数量为 $2 \\left( P_{x} - 1 \\right) P_{y} P_{z}$。\n\n类似的推理也适用于 $y$ 和 $z$ 方向，分别得出 $2 \\left( P_{y} - 1 \\right) P_{x} P_{z}$ 和 $2 \\left( P_{z} - 1 \\right) P_{x} P_{y}$ 条有向消息。\n\n其次，我们确定每个方向上面消息的大小 $m_{\\text{face}}$。每个子域的尺寸为 $n_{x} \\times n_{y} \\times n_{z}$ 个单元，其中 $n_{x} = N_{x}/P_{x}$，$n_{y} = N_{y}/P_{y}$，$n_{z} = N_{z}/P_{z}$。一个垂直于 $x$ 方向的面的面积为 $n_{y} \\times n_{z}$ 个单元，并且厚度为 $w$ 层的单元在 $x$ 方向上作为单条消息传输。因此，每条消息由此面贡献的光环单元数量为 $w \\, n_{y} \\, n_{z}$。由于每个单元包含 $q$ 个标量分量，消息中的标量项数量为\n$$\nm_{x} = w \\, n_{y} \\, n_{z} \\, q = w \\, q \\, \\frac{N_{y}}{P_{y}} \\, \\frac{N_{z}}{P_{z}}.\n$$\n根据对称性，对于垂直于 $y$ 方向的面，\n$$\nm_{y} = w \\, n_{x} \\, n_{z} \\, q = w \\, q \\, \\frac{N_{x}}{P_{x}} \\, \\frac{N_{z}}{P_{z}},\n$$\n对于垂直于 $z$ 方向的面，\n$$\nm_{z} = w \\, n_{x} \\, n_{y} \\, q = w \\, q \\, \\frac{N_{x}}{P_{x}} \\, \\frac{N_{y}}{P_{y}}.\n$$\n\n使用延迟-带宽模型，一个 $x$ 面上单条消息的时间为 $\\alpha + \\beta m_{x}$，对于 $y$ 面和 $z$ 面也类似。对所有有向的进程间面消息求和，总时间为\n$$\nT_{\\text{total}} = 2 \\left( P_{x} - 1 \\right) P_{y} P_{z} \\left( \\alpha + \\beta m_{x} \\right) + 2 \\left( P_{y} - 1 \\right) P_{x} P_{z} \\left( \\alpha + \\beta m_{y} \\right) + 2 \\left( P_{z} - 1 \\right) P_{x} P_{y} \\left( \\alpha + \\beta m_{z} \\right).\n$$\n代入 $m_{x}$、$m_{y}$ 和 $m_{z}$ 的表达式，我们得到闭式解析表达式：\n$$\nT_{\\text{total}} = 2 \\left( P_{x} - 1 \\right) P_{y} P_{z} \\left( \\alpha + \\beta \\, w \\, q \\, \\frac{N_{y}}{P_{y}} \\, \\frac{N_{z}}{P_{z}} \\right) + 2 \\left( P_{y} - 1 \\right) P_{x} P_{z} \\left( \\alpha + \\beta \\, w \\, q \\, \\frac{N_{x}}{P_{x}} \\, \\frac{N_{z}}{P_{z}} \\right) + 2 \\left( P_{z} - 1 \\right) P_{x} P_{y} \\left( \\alpha + \\beta \\, w \\, q \\, \\frac{N_{x}}{P_{x}} \\, \\frac{N_{y}}{P_{y}} \\right).\n$$\n如果 $\\alpha$ 的单位是秒，$\\beta$ 的单位是秒/标量数据项，则此表达式的单位是秒。它计算了一次完整的三坐标方向光环交换步骤中所有有向的进程间面消息，并假设光环交换按面聚合，边和角不单独发送，并且只有内部接口对 MPI 通信时间有贡献。",
            "answer": "$$\\boxed{2\\left(P_{x}-1\\right)P_{y}P_{z}\\left(\\alpha+\\beta\\,w\\,q\\,\\frac{N_{y}}{P_{y}}\\,\\frac{N_{z}}{P_{z}}\\right)+2\\left(P_{y}-1\\right)P_{x}P_{z}\\left(\\alpha+\\beta\\,w\\,q\\,\\frac{N_{x}}{P_{x}}\\,\\frac{N_{z}}{P_{z}}\\right)+2\\left(P_{z}-1\\right)P_{x}P_{y}\\left(\\alpha+\\beta\\,w\\,q\\,\\frac{N_{x}}{P_{x}}\\,\\frac{N_{y}}{P_{y}}\\right)}$$"
        },
        {
            "introduction": "### 分析通信拓扑\n\n在上一个练习中，我们关注了单次通信消息的成本。然而，一个并行应用的整体通信性能还取决于通信发生的模式或拓扑结构。不同的区域分解策略——例如一维（“板”状）、二维（“铅笔”状）或三维（“块”状）分解——会产生截然不同的处理器通信图。\n\n本练习将指导您量化不同分解策略对通信复杂性的影响。您将计算每种情况下每个处理器需要与之通信的邻居数量，并分析总的通信连接数。这个过程揭示了在实现简单性与最小化通信伙伴数量之间的关键权衡，这是并行算法设计中的一个核心考量。",
            "id": "3983415",
            "problem": "考虑一个在均匀笛卡尔网格上使用有限体积离散法实现的可压缩 Navier–Stokes 求解器，该网格在所有三个方向上都具有周期性边界条件。全局域包含 $N_{x} \\times N_{y} \\times N_{z}$ 个控制体，并使用消息传递接口 (MPI) 分布在 $P$ 个进程上。该求解器执行显式时间积分，并在每个子步中跨所有子域的面交换宽度为 $w=1$ 个单元的 halo 数据；不执行边和角的交换。考虑三种区域分解策略：\n\n- 板状分解：沿单个坐标的一维分区，其中 $(P_{x},P_{y},P_{z})=(1,1,P)$。\n- 笔状分解：沿两个坐标的二维分区，其中 $(P_{x},P_{y},P_{z})=(1,P_{y},P_{z})$ 且 $P_{y}P_{z}=P$。\n- 块状分解：沿所有坐标的三维分区，其中 $(P_{x},P_{y},P_{z})$ 满足 $P_{x}P_{y}P_{z}=P$。\n\n定义每个进程的邻居数 $d$ 为与给定进程的子域共享一个面（在周期性边界条件下）的不同进程的数量。定义通信模式复杂度度量 $C$ 为所有 $P$ 个进程中唯一的无向面邻接对的总数，即由于面共享而在每个子步中交换 halo 消息的不同进程对的数量。\n\n从上述定义以及笛卡尔分区和周期性邻接的基本性质出发，计算：\n\n1. 板状、笔状和块状分解下每个进程的邻居数 $d$。\n2. 板状、笔状和块状分解下的通信模式复杂度 $C$，用 $P$ （以及在适用情况下，用满足 $P_{x}P_{y}P_{z}=P$ 的 $(P_{x},P_{y},P_{z})$）表示。\n3. 板状、笔状和块状分解下的归一化复杂度 $C/P$。\n\n使用 $\\mathrm{pmatrix}$ 环境将您的最终答案表示为一个单行矩阵，其中依次包含 $d_{\\mathrm{slab}}$、 $d_{\\mathrm{pencil}}$、 $d_{\\mathrm{block}}$、 $C_{\\mathrm{slab}}$、 $C_{\\mathrm{pencil}}$、 $C_{\\mathrm{block}}$、 $C_{\\mathrm{slab}}/P$、 $C_{\\mathrm{pencil}}/P$ 和 $C_{\\mathrm{block}}/P$。无需四舍五入。",
            "solution": "### 解题推导\n\n该问题等价于分析通信图的拓扑性质，其中 $P$ 个 MPI 进程是顶点，如果对应的子域共享一个面，则两个顶点之间存在一条边。该域是一个具有周期性边界条件的三维笛卡尔网格，分区也是笛卡尔式的。最终的处理器拓扑是循环图的笛卡尔积，$C_{P_x} \\times C_{P_y} \\times C_{P_z}$。\n\n每个进程的邻居数 $d$ 是此图中一个顶点的度。由于周期性边界条件，该图是顶点传递的，这意味着每个进程都有相同数量的邻居。通信复杂度 $C$ 是此图中的总边数。\n\n在给定维度 $i$ 中的邻居数量取决于该维度中的分区数 $P_i$。\n- 如果 $P_i=1$，一个进程是它自己的邻居，而不是一个*不同*的进程，因此有 $0$ 个邻居。\n- 如果 $P_i=2$，由于周期性，一个进程在两个方向（正向和负向）上都有一个不同的邻居（另一个进程）。\n- 如果 $P_i>2$，一个进程有两个不同的邻居。\n\n对于大规模并行计算，一个标准且合理的简化假设是，对于任何被分区的维度 $i$（即 $P_i>1$），分区数大于 $2$（即 $P_i > 2$）。这避免了对 $P_i=2$ 的特殊情况处理，因为这种情况代表了一种最小且通常效率不高的分区。我们将在此假设下进行，这与航空航天 CFD 的典型背景相符。\n\n在对于任何 $P_i>1$ 都有 $P_i>2$ 的假设下：\n\n**1. 通信复杂度 ($C$) 的推导**\n总邻接数 $C$ 是每个分区维度中邻接数的总和。\n让我们考虑 $x$ 方向的邻接。$P_x \\times P_y \\times P_z$ 的处理器网格可以看作是 $P_y P_z$ 个与 $x$ 轴对齐的处理器“笔”。每个“笔”是一个由 $P_x$ 个处理器组成的环。对于 $P_x > 1$，$P_x$ 个处理器的环有 $P_x$ 个邻接。因此，$x$ 方向的邻接数是 $C_x = (P_y P_z) \\times P_x = P$（如果 $P_x > 1$），而 $C_x = 0$（如果 $P_x=1$）。\n类似地，$C_y = P$（如果 $P_y > 1$）且为 $0$（如果 $P_y=1$）。\n并且 $C_z = P$（如果 $P_z > 1$）且为 $0$（如果 $P_z=1$）。\n总复杂度 $C$ 是 $C_x + C_y + C_z$。\n\n- **板状分解**：$(P_x, P_y, P_z) = (1, 1, P)$。我们假设 $P>2$。\n  只有 $z$ 维被分区（$P_z > 1$）。\n  $$C_{\\mathrm{slab}} = 0 + 0 + P = P$$\n\n- **笔状分解**：$(P_x, P_y, P_z) = (1, P_y, P_z)$，其中 $P_y P_z = P$。我们假设 $P_y>1$ 且 $P_z>1$。\n  $y$ 和 $z$ 维被分区。\n  $$C_{\\mathrm{pencil}} = 0 + P + P = 2P$$\n\n- **块状分解**：$(P_x, P_y, P_z)$，其中 $P_x P_y P_z = P$。我们假设 $P_x>1$，$P_y>1$ 且 $P_z>1$。\n  所有三个维度都被分区。\n  $$C_{\\mathrm{block}} = P + P + P = 3P$$\n\n**2. 每个进程的邻居数 ($d$) 的推导**\n图中边的总数与其顶点度数之和通过握手引理相关联：$\\sum_{v} \\text{degree}(v) = 2 \\times (\\text{number of edges})$。\n在我们的例子中，对于所有 $P$ 个进程，度数都是一个常数 $d$。因此，$\\sum \\text{degree}(v) = P \\times d$。边的数量是 $C$。\n$$P d = 2C \\implies d = \\frac{2C}{P}$$\n\n- **板状分解**：\n  $$d_{\\mathrm{slab}} = \\frac{2 C_{\\mathrm{slab}}}{P} = \\frac{2P}{P} = 2$$\n\n- **笔状分解**：\n  $$d_{\\mathrm{pencil}} = \\frac{2 C_{\\mathrm{pencil}}}{P} = \\frac{2(2P)}{P} = 4$$\n\n- **块状分解**：\n  $$d_{\\mathrm{block}} = \\frac{2 C_{\\mathrm{block}}}{P} = \\frac{2(3P)}{P} = 6$$\n\n**3. 归一化复杂度 ($C/P$) 的推导**\n这是通过将 $C$ 的表达式除以 $P$ 得到的。\n\n- **板状分解**：\n  $$C_{\\mathrm{slab}}/P = \\frac{P}{P} = 1$$\n\n- **笔状分解**：\n  $$C_{\\mathrm{pencil}}/P = \\frac{2P}{P} = 2$$\n\n- **块状分解**：\n  $$C_{\\mathrm{block}}/P = \\frac{3P}{P} = 3$$\n\n我们已经在任何分区维度都有超过两个划分的标准假设下，计算了所有九个所需的量。\n\n最终结果是：\n- $d_{\\mathrm{slab}} = 2$\n- $d_{\\mathrm{pencil}} = 4$\n- $d_{\\mathrm{block}} = 6$\n- $C_{\\mathrm{slab}} = P$\n- $C_{\\mathrm{pencil}} = 2P$\n- $C_{\\mathrm{block}} = 3P$\n- $C_{\\mathrm{slab}}/P = 1$\n- $C_{\\mathrm{pencil}}/P = 2$\n- $C_{\\mathrm{block}}/P = 3$\n\n这些将按要求排列在一个单行矩阵中。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 & 4 & 6 & P & 2P & 3P & 1 & 2 & 3\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "### 实现无死锁的晕轮交换\n\n在掌握了通信成本建模和拓扑分析之后，我们转向并行编程的实践核心：确保算法的正确性。使用非阻塞MPI（消息传递接口）操作是实现计算与通信重叠、隐藏延迟的关键技术，但如果使用不当，它也可能引入死锁等棘手的并发问题。\n\n在这个综合性练习中，您不仅需要从第一性原理出发，推导出一个正确的、无死锁的晕轮交换算法序列，还需要构建一个模拟器来验证您的设计并探索常见的编程陷阱。通过亲手实现和测试，您将深刻理解为什么“先收后发”（post-receives-before-sends）等模式对于编写健壮的并行代码至关重要，并直观地看到违反通信协议（如标签不匹配）所导致的后果。",
            "id": "3806415",
            "problem": "考虑一个用于计算海洋学的无源示踪物输运方程的三维有限体积离散化，其中计算域被分解为排列在笛卡尔网格上的多个子域。每个子域被分配给一个独立的进程，这些进程通过消息传递接口（MPI）进行通信。为了使用依赖于最近邻的模板更新通量，每个进程必须与其最多 $6$ 个面相邻的邻居（在 $+\\hat{x}$、$-\\hat{x}$、$+\\hat{y}$、$-\\hat{y}$、$+\\hat{z}$、$-\\hat{z}$ 方向上）交换晕轮厚度为 $1$ 个单元的晕轮数据。您需要从第一性原理出发，推导出一个正确且无死锁的非阻塞 MPI 操作序列，以实现三维晕轮交换，同时重叠计算与通信，并形式化地描述在违反顺序时可能发生死锁的条件。\n\n您的推导必须基于以下基本考虑：\n- $3\\text{D}$ 域分解定义了一组以维度为 $(N_x,N_y,N_z)$ 的网格排列的进程，其中每个进程的坐标为 $(i,j,k)$，满足 $0 \\le i < N_x$、 $0 \\le j < N_y$ 和 $0 \\le k < N_z$。面相邻的邻居关系由网格邻接性决定。\n- 非阻塞 MPI 操作，如 $\\mathrm{Irecv}$ 和 $\\mathrm{Isend}$，会启动通信而不会阻塞调用者。完成通信需要一个匹配的对等操作，并通过 $\\mathrm{Wait}$ 或 $\\mathrm{Waitall}$ 来检测。\n- 在海洋模型模板中，不需要晕轮值的内部更新可以在晕轮消息传输过程中进行计算，从而实现通信和计算的重叠。\n- MPI 中的匹配由通信子、源或目标进程号以及消息标签决定；正确性要求在这些方面达成对称约定。\n\n您的推导必须：\n- 明确定义每个进程以 $\\mathrm{Irecv}$、$\\mathrm{Isend}$ 和 $\\mathrm{Waitall}$ 表示的操作序列，并论证为何在发送前发布接收足以避免死锁，同时还能实现计算和通信的重叠。\n- 陈述在违反顺序或匹配规则（如循环等待和标签不匹配）时可能发生死锁的条件。\n- 提供对邻居集合和标签的正式描述，该描述足以让一个模拟器判断给定的全局调度是否能完成。\n\n然后，实现一个在逻辑层面（无实际 MPI 调用）上模拟此非阻塞晕轮交换的模拟器。模拟器将进程表示为排列在大小为 $(N_x,N_y,N_z)$ 的网格中，每个进程根据选定的调度策略发布一组非阻塞操作。模拟器必须通过匹配已发布的发送和接收来推进通信；一个 $\\mathrm{Waitall}$ 只有在该进程发布的所有操作都匹配成功时才能成功。如果因未匹配的操作而导致进程停滞，且有部分进程正在等待，则系统处于死锁状态。\n\n定义以下调度策略：\n- \"recv_then_send\"：一个进程向其所有存在的面邻居发布所有 $\\mathrm{Irecv}$，然后发布所有 $\\mathrm{Isend}$，对内部单元执行重叠计算，最后对所有已发布的操作调用 $\\mathrm{Waitall}$。\n- \"send_then_wait_no_recv\"：一个进程向所有存在的面邻居发布 $\\mathrm{Isend}$，并立即调用 $\\mathrm{Waitall}$，而从不发布任何 $\\mathrm{Irecv}$。\n- \"recv_then_send_tag_mismatch_X\"：类似于 \"recv_then_send\"，但进程在 $x$ 面上的消息使用不正确的标签（从而违反了这些面上的标签匹配规则）；在 $y$ 和 $z$ 面上使用正确的标签。\n\n假设：\n- 消息仅在发送方和接收方就对等进程号和轴标签（$x$、$y$ 或 $z$）达成一致时才匹配。方向 $+\\hat{x}$ 或 $-\\hat{x}$ 映射到轴标签 $x$，对于 $y$ 和 $z$ 也类似。\n- 非阻塞发送在匹配的接收被发布之前不会完成；一个对未匹配操作调用 $\\mathrm{Waitall}$ 的进程将保持等待状态。\n\n您的程序必须模拟以下测试套件，并为每个案例输出一个布尔值，指示全局执行是否无死锁（即所有进程都完成了它们的 $\\mathrm{Waitall}$）。测试套件是：\n\n- 案例 1：$(N_x,N_y,N_z) = (2,2,2)$，所有进程使用 \"recv_then_send\"。\n- 案例 2：$(N_x,N_y,N_z) = (2,1,1)$，所有进程使用 \"send_then_wait_no_recv\"。\n- 案例 3：$(N_x,N_y,N_z) = (2,2,1)$，除位于 $(0,0,0)$ 的进程使用 \"recv_then_send_tag_mismatch_X\" 外，所有进程均使用 \"recv_then_send\"。\n- 案例 4：$(N_x,N_y,N_z) = (1,1,1)$，所有进程使用 \"recv_then_send\"。\n\n最终输出规范：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[result_1,result_2,result_3,result_4]$），其中每个 $result_i$ 是一个布尔值，如果该案例无死锁则为 $\\mathrm{True}$，否则为 $\\mathrm{False}$。\n\n不涉及物理单位。不使用角度。不使用百分比。",
            "solution": "### 无死锁晕轮交换算法的推导\n\n**1. 系统形式化**\n设进程集合为 $P = \\{ p_{i,j,k} \\mid 0 \\le i < N_x, 0 \\le j < N_y, 0 \\le k < N_z \\}$。每个进程 $p_{i,j,k}$ 都有一个唯一的进程号，可以通过映射计算得出，例如 $r(i,j,k) = i + j \\cdot N_x + k \\cdot N_x \\cdot N_y$。\n\n一个进程 $p_{i,j,k}$ 最多有 $6$ 个邻居。例如，它在 $+\\hat{x}$ 方向的邻居是 $p_{i+1,j,k}$，前提是 $i+1 < N_x$。与该邻居的通信沿 $x$ 轴进行。我们为每个轴分配唯一的整数标签，例如，标签 $0$ 用于 $x$ 轴，标签 $1$ 用于 $y$ 轴，标签 $2$ 用于 $z$ 轴。\n\n为了更新子域边界上的单元值，一个进程需要来自其邻居的数据。这是通过交换“晕轮”或“幽灵”单元来实现的。对于厚度为 $1$ 的晕轮，每个进程将其边界单元的一层发送给其邻居，并接收相应的一层到其晕轮区域。\n\n**2. “先接收后发送”策略**\n使用非阻塞操作 $\\mathrm{Irecv}$ 和 $\\mathrm{Isend}$ 是性能的关键。它们允许程序启动一个通信操作并继续执行其他工作，如计算，而数据传输在后台进行。$\\mathrm{Waitall}$ 操作用于确保在程序继续使用接收到的数据之前，所有已启动的通信都已完成。\n\n一个健壮且被广泛采用的无死锁晕轮交换策略是**在发布任何发送之前发布所有接收**。每个进程的序列如下：\n\n1.  **发布所有接收：** 对于期望接收数据的每个邻居进程，发布一个非阻塞接收操作：$\\mathrm{Irecv}(source\\_rank, tag, ...)$。这通知 MPI 运行时库，该进程已准备好将传入数据接收到指定的缓冲区中。\n2.  **发布所有发送：** 对于必须发送数据的每个邻居进程，发布一个非阻塞发送操作：$\\mathrm{Isend}(destination\\_rank, tag, ...)$。由于相应的 $\\mathrm{Irecv}$ 已被邻居发布（因为所有进程都遵循相同的算法），MPI 库可以立即开始数据传输。\n3.  **重叠计算：** 在本地子域的*内部*执行计算。这些计算不依赖于当前正在传输的晕轮数据。这是性能增益的来源，因为计算与通信重叠了。\n4.  **等待完成：** 对已发布的 $\\mathrm{Irecv}$ 和 $\\mathrm{Isend}$ 操作的所有请求句柄集合调用 $\\mathrm{Waitall}$。此调用将阻塞，直到调用进程的所有发送和接收都完成。\n5.  **边界计算：** 一旦 $\\mathrm{Waitall}$ 返回，晕轮区域就填充了新数据。现在，进程可以安全地对其子域的边界单元执行计算，这些计算依赖于此晕轮数据。\n\n该策略足以避免死锁的原因是它打破了任何潜在的资源依赖性循环。在简单的阻塞通信方案中（甚至在重负载下的非阻塞方案中），死锁的一个常见原因是两个进程都试图同时向对方发送。如果系统缓冲区有限，两个发送都可能阻塞，等待对方发布一个接收，但对方永远不会这样做，因为它也阻塞在发送上。通过首先发布所有接收，每个进程都表明其准备好接收数据，确保后续的发送总能找到一个已发布的匹配接收，从而保证通信可以进行。\n\n**3. 死锁的条件**\n当形成一个循环依赖，其中一组进程都在等待一个只能由同一组内另一个进程触发的事件时，就会发生死锁。在 MPI 晕轮交换的背景下，这主要通过两种方式发生：\n\n*   **不正确的操作顺序（循环等待）：** 考虑一个策略，其中进程先发布发送，然后等待它们完成，再发布接收。例如，进程 $p_A$ 执行 $\\mathrm{Isend}(p_B); \\mathrm{Wait}(...)$，进程 $p_B$ 执行 $\\mathrm{Isend}(p_A); \\mathrm{Wait}(...)$。从 $p_A$ 到 $p_B$ 的 `Isend` 在 $p_B$ 发布匹配的 `Irecv` 之前不会完成。然而，$p_B$ 被阻塞在其自己的 `Wait` 调用中，等待其到 $p_A$ 的发送完成，永远不会到达发布接收的点。$p_A$ 处于对称的情况。这造成了死锁。`\"send_then_wait_no_recv\"` 策略是这个缺陷的完美例子；由于没有任何进程发布接收，任何发送都无法完成，所有进程都将无限期等待。\n\n*   **参数不匹配：** MPI 要求发送和接收操作的参数精确匹配才能配对。源进程号、目标进程号或消息标签的不匹配将导致匹配引擎忽略这些操作。例如，假设进程 $p_A$ 想与 $p_B$ 沿 $x$ 轴（标签 $0$）通信。\n    -   $p_A$ 发布 $\\mathrm{Irecv}(source=p_B, tag=0)$。\n    -   $p_B$ 发布 $\\mathrm{Isend}(dest=p_A, tag=99)$。\n    标签不匹配。来自 $p_B$ 的发送和来自 $p_A$ 的接收虽然是针对同一对进程的，但被认为是无关的通信。如果两个进程随后都调用 $\\mathrm{Waitall}$，它们将永远阻塞。$p_A$ 等待一个来自 $p_B$ 且标签为 $0$ 的消息，但该消息永远不会被发送；而 $p_B$ 等待其发送的标签为 $99$ 的消息被接收，但 $p_A$ 并不期望接收该标签的消息。`\"recv_then_send_tag_mismatch_X\"` 策略模拟了这种情况。\n\n**4. 模拟的形式化描述**\n模拟器可以通过跟踪已发布操作的状态来模拟此系统。\n-   **进程和进程号：** 创建一个 $N_x \\times N_y \\times N_z$ 的进程网格。每个进程 $(i,j,k)$ 被分配一个唯一的进程号 $r$。\n-   **操作：** 通信操作表示为包含其基本匹配信息的对象或元组：`(type, rank, peer_rank, tag)`，其中 `type` 是 `SEND` 或 `RECV`。\n-   **执行模型：**\n    1.  **操作发布：** 根据每个进程指定的策略，生成所有预期的操作（`Irecv` 和 `Isend`）并放入两个全局列表：`pending_sends` 和 `pending_recvs`。策略的顺序（例如，所有 `Irecv` 在任何 `Isend` 之前发布）得到遵守。\n    2.  **匹配引擎：** 模拟器重复扫描 `pending_sends` 和 `pending_recvs` 列表。如果找到一个发送操作 `(SEND, r1, r2, tag)` 和一个接收操作 `(RECV, r2, r1, tag)`，这构成一个匹配。两个匹配的操作从各自的列表中移除。此过程持续进行，直到在对列表的完整遍历中再也找不到匹配项。\n    3.  **死锁检测：** 匹配引擎终止后，系统处于稳定状态。如果 `pending_sends` 和 `pending_recvs` 列表都为空，则意味着每个发布的发送都与相应的接收匹配。因此，所有进程都可以成功完成其 `Waitall` 调用。系统是无死锁的。如果任一列表不为空，则意味着存在永远不会被匹配的未完成通信操作。发布这些操作的进程将在 `Waitall` 中无限期阻塞，系统处于死锁状态。",
            "answer": "```python\nimport numpy as np\nfrom collections import namedtuple\n\n# Define a simple structure for communication operations\nOperation = namedtuple('Operation', ['type', 'rank', 'peer', 'tag'])\n\ndef get_neighbors(coords, dims):\n    \"\"\"Finds face-adjacent neighbors for a process.\"\"\"\n    i, j, k = coords\n    Nx, Ny, Nz = dims\n    neighbors = []\n    # Directions: +x, -x, +y, -y, +z, -z\n    # Corresponding axes/tags: 0, 0, 1, 1, 2, 2\n    directions = [(1, 0, 0), (-1, 0, 0), (0, 1, 0), (0, -1, 0), (0, 0, 1), (0, 0, -1)]\n    tags = [0, 0, 1, 1, 2, 2]\n\n    for idx, (di, dj, dk) in enumerate(directions):\n        ni, nj, nk = i + di, j + dj, k + dk\n        if 0 <= ni < Nx and 0 <= nj < Ny and 0 <= nk < Nz:\n            neighbors.append({\n                'coords': (ni, nj, nk),\n                'tag': tags[idx]\n            })\n    return neighbors\n\ndef simulate_halo_exchange(dims, policies):\n    \"\"\"\n    Simulates the MPI halo exchange and detects deadlocks.\n\n    Args:\n        dims (tuple): Grid dimensions (Nx, Ny, Nz).\n        policies (dict): A mapping from process coordinates to policy strings.\n\n    Returns:\n        bool: True if the exchange is deadlock-free, False otherwise.\n    \"\"\"\n    Nx, Ny, Nz = dims\n    num_procs = Nx * Ny * Nz\n    if num_procs == 0:\n        return True\n\n    # Map coordinates to a unique rank and back\n    coord_to_rank = {\n        (i, j, k): i + j * Nx + k * Nx * Ny\n        for k in range(Nz) for j in range(Ny) for i in range(Nx)\n    }\n\n    # Global pools of posted operations\n    pending_recvs = []\n    pending_sends = []\n\n    # --- Step 1: Post Receives ---\n    # According to the \"recv_then_send\" logic, post all receives first.\n    for k in range(Nz):\n        for j in range(Ny):\n            for i in range(Nx):\n                coords = (i, j, k)\n                rank = coord_to_rank[coords]\n                policy = policies[coords]\n\n                if policy in [\"recv_then_send\", \"recv_then_send_tag_mismatch_X\"]:\n                    neighbors = get_neighbors(coords, dims)\n                    for neighbor in neighbors:\n                        peer_coords = neighbor['coords']\n                        peer_rank = coord_to_rank[peer_coords]\n                        tag = neighbor['tag']\n                        pending_recvs.append(Operation('RECV', rank, peer_rank, tag))\n\n    # --- Step 2: Post Sends ---\n    # Now, all processes post their sends.\n    for k in range(Nz):\n        for j in range(Ny):\n            for i in range(Nx):\n                coords = (i, j, k)\n                rank = coord_to_rank[coords]\n                policy = policies[coords]\n\n                if policy in [\"recv_then_send\", \"send_then_wait_no_recv\", \"recv_then_send_tag_mismatch_X\"]:\n                    neighbors = get_neighbors(coords, dims)\n                    for neighbor in neighbors:\n                        peer_coords = neighbor['coords']\n                        peer_rank = coord_to_rank[peer_coords]\n                        tag = neighbor['tag']\n                        \n                        # Apply tag mismatch if the policy requires it\n                        if policy == \"recv_then_send_tag_mismatch_X\" and tag == 0: # tag 0 is x-axis\n                            tag = 99 # Mismatched tag\n\n                        pending_sends.append(Operation('SEND', rank, peer_rank, tag))\n\n    # --- Step 3: Matching Engine ---\n    # Repeatedly scan and match sends and receives until no more matches can be found.\n    while True:\n        matched_in_pass = False\n        \n        # To allow removing items while iterating, we iterate over a copy of one list\n        # and search the other.\n        sends_to_remove = set()\n        recvs_to_remove = set()\n        \n        # Use indices to handle list removal properly\n        recv_indices = list(range(len(pending_recvs)))\n        recv_matched = [False] * len(pending_recvs)\n\n        for i, s_op in enumerate(pending_sends):\n            for j_idx, r_op in enumerate(pending_recvs):\n                # Check if recv is already matched in this pass\n                if recv_matched[j_idx]:\n                    continue\n                \n                # Check for a match: sender peer == receiver and receiver peer == sender and tags match\n                if (s_op.peer == r_op.rank and s_op.rank == r_op.peer and s_op.tag == r_op.tag):\n                    sends_to_remove.add(i)\n                    recvs_to_remove.add(j_idx)\n                    recv_matched[j_idx] = True\n                    matched_in_pass = True\n                    break # A send can only match one receive\n        \n        if not matched_in_pass:\n            break\n\n        # Remove matched items from the lists in reverse index order to avoid shifting issues\n        for i in sorted(list(sends_to_remove), reverse=True):\n            del pending_sends[i]\n        for j in sorted(list(recvs_to_remove), reverse=True):\n            del pending_recvs[j]\n\n    # --- Step 4: Deadlock Detection ---\n    # If any operations remain unmatched, it's a deadlock.\n    # All policies imply a Waitall, so any pending op causes a block.\n    return len(pending_sends) == 0 and len(pending_recvs) == 0\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for the specified test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1: (2,2,2), all processes use \"recv_then_send\".\n        {\n            \"dims\": (2, 2, 2),\n            \"default_policy\": \"recv_then_send\",\n            \"exceptions\": {}\n        },\n        # Case 2: (2,1,1), all processes use \"send_then_wait_no_recv\".\n        {\n            \"dims\": (2, 1, 1),\n            \"default_policy\": \"send_then_wait_no_recv\",\n            \"exceptions\": {}\n        },\n        # Case 3: (2,2,1), all processes use \"recv_then_send\" except (0,0,0).\n        {\n            \"dims\": (2, 2, 1),\n            \"default_policy\": \"recv_then_send\",\n            \"exceptions\": { (0, 0, 0): \"recv_then_send_tag_mismatch_X\" }\n        },\n        # Case 4: (1,1,1), all processes use \"recv_then_send\".\n        {\n            \"dims\": (1, 1, 1),\n            \"default_policy\": \"recv_then_send\",\n            \"exceptions\": {}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        dims = case[\"dims\"]\n        Nx, Ny, Nz = dims\n        \n        # Build the policy map for the current case\n        policies = {}\n        for k in range(Nz):\n            for j in range(Ny):\n                for i in range(Nx):\n                    coords = (i, j, k)\n                    if coords in case[\"exceptions\"]:\n                        policies[coords] = case[\"exceptions\"][coords]\n                    else:\n                        policies[coords] = case[\"default_policy\"]\n\n        is_deadlock_free = simulate_halo_exchange(dims, policies)\n        results.append(is_deadlock_free)\n\n    # Format the final output string\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}