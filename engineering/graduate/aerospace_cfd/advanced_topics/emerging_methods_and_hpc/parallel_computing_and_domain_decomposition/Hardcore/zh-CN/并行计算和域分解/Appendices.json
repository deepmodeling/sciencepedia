{
    "hands_on_practices": [
        {
            "introduction": "在设计并行算法时，性能预测是至关重要的一环。本练习提供了一个量化通信开销的基础模型。通过推导总体的“光环”交换时间 ，您将学习如何将计算域大小、处理器布局等抽象参数与具体的性能指标联系起来，这是理解和优化并行计算性能的第一步。",
            "id": "3983349",
            "problem": "考虑一个求解可压缩 Navier–Stokes 方程的三维结构化有限体积计算流体动力学 (CFD) 求解器，该求解器运行在具有 $N_{x} \\times N_{y} \\times N_{z}$ 个控制体积的均匀笛卡尔网格上。其并行化采用块状区域分解方法，分解到 $P$ 个消息传递接口 (MPI; Message Passing Interface) 进程上。这些进程排列成一个大小为 $P_{x} \\times P_{y} \\times P_{z}$ 的逻辑处理器网格，其中 $P = P_{x} P_{y} P_{z}$。假设 $N_{x}$、$N_{y}$ 和 $N_{z}$ 分别可以被 $P_{x}$、$P_{y}$ 和 $P_{z}$ 整除。每个进程拥有一个大小为 $n_{x} \\times n_{y} \\times n_{z}$ 个网格单元的子区域，其中 $n_{x} = N_{x}/P_{x}$，$n_{y} = N_{y}/P_{y}$，$n_{z} = N_{z}/P_{z}$。使用宽度为 $w$ 的模板，这意味着必须沿三个坐标方向与面相邻的邻居交换厚度为 $w$ 的晕环层。假设：\n- 沿子区域面的每次晕环交换都作为一条包含该面 $w$ 个层级的单条消息执行（不为边或角发送单独的消息）。\n- 每个晕环单元交换一个包含 $q$ 个标量分量的守恒状态向量。\n- 单条消息的通信时间由标准延迟-带宽关系 $T_{\\text{msg}} = \\alpha + \\beta m$ 建模，其中 $\\alpha$ 是延迟，$\\beta$ 是逆带宽（每个标量数据项的时间），$m$ 是消息中的标量数据项数量。\n- 只计算进程间的交换；物理边界条件不产生 MPI 通信。\n\n使用模型 $T = \\sum_{\\text{faces}} \\left( \\alpha + \\beta m_{\\text{face}} \\right)$，对一次完整晕环交换步骤（即所有三个方向）中所有定向的进程间面消息进行求和，推导出总晕环交换时间 $T_{\\text{total}}$ 关于 $N_{x}$、$N_{y}$、$N_{z}$、$P_{x}$、$P_{y}$、$P_{z}$、$w$、$q$、$\\alpha$ 和 $\\beta$ 的闭式表达式。将最终结果以秒为单位表示为单个解析表达式。无需进行数值计算。",
            "solution": "我们从消息传递接口 (MPI; Message Passing Interface) 的标准延迟-带宽通信模型开始，该模型指出发送一条包含 $m$ 个标量数据项的消息所需的时间为 $T_{\\text{msg}} = \\alpha + \\beta m$，其中 $\\alpha$ 是延迟，$\\beta$ 是每个标量数据项所需的时间。对于结构化块分解，晕环交换在面相邻的子区域之间执行，沿每个共享面双向发送 $w$ 层网格单元。\n\n在一次完整的三坐标方向交换过程中，整个处理器网格的总晕环交换时间 $T_{\\text{total}}$ 可通过对所有定向面消息的通信时间 $T_{\\text{msg}}$ 求和得到。因此，我们必须确定：\n1. 每个方向上定向的进程间面消息的数量。\n2. 每条此类消息的大小 $m_{\\text{face}}$，用网格和分解参数表示。\n\n首先，考虑大小为 $P_{x} \\times P_{y} \\times P_{z}$ 的处理器网格。沿 $x$ 方向，有 $P_{y} P_{z}$ 条处理器行，每行包含 $P_{x}$ 个进程。沿 $x$ 方向的进程间接口数量是这些行中内部边界的数量，即每行 $\\left( P_{x} - 1 \\right)$ 个。因此，沿 $x$ 方向的无向接口总数为 $\\left( P_{x} - 1 \\right) P_{y} P_{z}$。由于晕环交换是双向的（每个接口都会在两个方向上产生一次发送），沿 $x$ 方向的定向消息数量为 $2 \\left( P_{x} - 1 \\right) P_{y} P_{z}$。\n\n类似的推理适用于 $y$ 方向和 $z$ 方向，分别得到 $2 \\left( P_{y} - 1 \\right) P_{x} P_{z}$ 和 $2 \\left( P_{z} - 1 \\right) P_{x} P_{y}$ 条定向消息。\n\n其次，我们确定每个方向上面消息的大小 $m_{\\text{face}}$。每个子区域的尺寸为 $n_{x} \\times n_{y} \\times n_{z}$ 个网格单元，其中 $n_{x} = N_{x}/P_{x}$，$n_{y} = N_{y}/P_{y}$，$n_{z} = N_{z}/P_{z}$。一个法线方向为 $x$ 方向的面，其面积为 $n_{y} \\times n_{z}$ 个网格单元，并且 $x$ 方向上厚度为 $w$ 的层级作为单条消息传输。因此，每条消息中由该面贡献的晕环单元数量为 $w \\, n_{y} \\, n_{z}$。由于每个单元包含 $q$ 个标量分量，消息中的标量项数量为\n$$\nm_{x} = w \\, n_{y} \\, n_{z} \\, q = w \\, q \\, \\frac{N_{y}}{P_{y}} \\, \\frac{N_{z}}{P_{z}}.\n$$\n根据对称性，对于法线方向为 $y$ 方向的面，\n$$\nm_{y} = w \\, n_{x} \\, n_{z} \\, q = w \\, q \\, \\frac{N_{x}}{P_{x}} \\, \\frac{N_{z}}{P_{z}},\n$$\n对于法线方向为 $z$ 方向的面，\n$$\nm_{z} = w \\, n_{x} \\, n_{y} \\, q = w \\, q \\, \\frac{N_{x}}{P_{x}} \\, \\frac{N_{y}}{P_{y}}.\n$$\n\n使用延迟-带宽模型，一个 $x$ 方向面上的单条消息的时间为 $\\alpha + \\beta m_{x}$，对于 $y$ 方向和 $z$ 方向的面也是如此。对所有定向的进程间面消息求和，总时间为\n$$\nT_{\\text{total}} = 2 \\left( P_{x} - 1 \\right) P_{y} P_{z} \\left( \\alpha + \\beta m_{x} \\right) + 2 \\left( P_{y} - 1 \\right) P_{x} P_{z} \\left( \\alpha + \\beta m_{y} \\right) + 2 \\left( P_{z} - 1 \\right) P_{x} P_{y} \\left( \\alpha + \\beta m_{z} \\right).\n$$\n代入 $m_{x}$、$m_{y}$ 和 $m_{z}$ 的表达式，我们得到闭式解析表达式：\n$$\nT_{\\text{total}} = 2 \\left( P_{x} - 1 \\right) P_{y} P_{z} \\left( \\alpha + \\beta \\, w \\, q \\, \\frac{N_{y}}{P_{y}} \\, \\frac{N_{z}}{P_{z}} \\right) + 2 \\left( P_{y} - 1 \\right) P_{x} P_{z} \\left( \\alpha + \\beta \\, w \\, q \\, \\frac{N_{x}}{P_{x}} \\, \\frac{N_{z}}{P_{z}} \\right) + 2 \\left( P_{z} - 1 \\right) P_{x} P_{y} \\left( \\alpha + \\beta \\, w \\, q \\, \\frac{N_{x}}{P_{x}} \\, \\frac{N_{y}}{P_{y}} \\right).\n$$\n如果 $\\alpha$ 的单位是秒，$\\beta$ 的单位是秒/标量数据项，则此表达式的单位是秒。它计算了一次完整的三坐标方向晕环交换步骤中所有定向的进程间面消息，并假设晕环交换是按面聚合的，边和角不单独发送，并且只有内部接口产生 MPI 通信时间。",
            "answer": "$$\\boxed{2\\left(P_{x}-1\\right)P_{y}P_{z}\\left(\\alpha+\\beta\\,w\\,q\\,\\frac{N_{y}}{P_{y}}\\,\\frac{N_{z}}{P_{z}}\\right)+2\\left(P_{y}-1\\right)P_{x}P_{z}\\left(\\alpha+\\beta\\,w\\,q\\,\\frac{N_{x}}{P_{x}}\\,\\frac{N_{z}}{P_{z}}\\right)+2\\left(P_{z}-1\\right)P_{x}P_{y}\\left(\\alpha+\\beta\\,w\\,q\\,\\frac{N_{x}}{P_{x}}\\,\\frac{N_{y}}{P_{y}}\\right)}$$"
        },
        {
            "introduction": "在建立了通信成本模型之后，下一步是分析不同的设计选择如何影响该成本。本练习  比较了一维（板状）、二维（带状）和三维（块状）分解策略。它揭示了并行计算中的一个基本权衡：增加分解的维度会改变通信拓扑，从而同时影响消息的数量和大小，这对于实现大规模可扩展性至关重要。",
            "id": "3983415",
            "problem": "考虑一个在均匀笛卡尔网格上通过有限体积法离散实现的、在所有三个方向上均采用周期性边界条件的可压缩纳维–斯托克斯求解器。全局域包含 $N_{x} \\times N_{y} \\times N_{z}$ 个控制体积，并使用消息传递接口（MPI）分布在 $P$ 个进程上。该求解器执行显式时间积分，并在每个子步中跨所有子域面交换宽度为 $w=1$ 个单元的光环数据；不执行边和角的交换。考虑三种区域分解策略：\n\n- 板状分解：沿单一坐标的一维划分，其中 $(P_{x},P_{y},P_{z})=(1,1,P)$。\n- 笔状分解：沿两个坐标的二维划分，其中 $(P_{x},P_{y},P_{z})=(1,P_{y},P_{z})$ 且 $P_{y}P_{z}=P$。\n- 块状分解：沿所有坐标的三维划分，其中 $(P_{x},P_{y},P_{z})$ 满足 $P_{x}P_{y}P_{z}=P$。\n\n定义每个进程的邻居数 $d$ 为与给定进程的子域共享一个面（在周期性边界下）的不同进程的数量。定义通信模式复杂度度量 $C$ 为所有 $P$ 个进程中唯一的无向面邻接对的总数，即由于面共享而在每个子步交换光环消息的不同进程对的数量。\n\n从上述定义以及笛卡尔划分和周期性邻接的基本性质出发，计算：\n\n1. 板状、笔状和块状分解中每个进程的邻居数 $d$。\n2. 板状、笔状和块状分解的通信模式复杂度 $C$，用 $P$（以及在适用情况下，满足 $P_{x}P_{y}P_{z}=P$ 的 $(P_{x},P_{y},P_{z})$）表示。\n3. 板状、笔状和块状分解的归一化复杂度 $C/P$。\n\n请使用 $\\mathrm{pmatrix}$ 环境将您的最终答案表示为一个单行矩阵，其中依次包含 $d_{\\mathrm{slab}}$、$d_{\\mathrm{pencil}}$、$d_{\\mathrm{block}}$、$C_{\\mathrm{slab}}$、$C_{\\mathrm{pencil}}$、$C_{\\mathrm{block}}$、$C_{\\mathrm{slab}}/P$、$C_{\\mathrm{pencil}}/P$ 和 $C_{\\mathrm{block}}/P$。无需四舍五入。",
            "solution": "该问题等价于分析通信图的拓扑性质，其中 $P$ 个 MPI 进程是顶点，如果相应的子域共享一个面，则在两个顶点之间存在一条边。该区域是一个具有周期性边界条件的三维笛卡尔网格，划分也是笛卡尔式的。最终的处理器拓扑是循环图的笛卡尔积，即 $C_{P_x} \\times C_{P_y} \\times C_{P_z}$。\n\n每个进程的邻居数 $d$ 是此图中一个顶点的度。由于周期性边界条件，该图是顶点传递的，这意味着每个进程都有相同数量的邻居。通信复杂度 $C$ 是该图中边的总数。\n\n在给定维度 $i$ 中的邻居数量取决于该维度上的分区数 $P_i$。\n- 如果 $P_i=1$，一个进程是自身的邻居，而不是一个*不同*的进程，因此有 $0$ 个邻居。\n- 如果 $P_i=2$，由于周期性，一个进程在两个方向（正向和负向）上都有一个不同的邻居（即另一个进程）。\n- 如果 $P_i>2$，一个进程有两个不同的邻居。\n\n对于大规模并行计算，一个标准且合理的简化假设是，对于任何被划分的维度 $i$（即 $P_i>1$），其分区数都大于 2（即 $P_i > 2$）。这样可以避免对 $P_i=2$ 进行特殊处理，因为这种情况代表了一种最小且通常效率不高的划分方式。我们将在此假设下进行推导，这符合航空航天 CFD 的典型情景。\n\n在任何 $P_i>1$ 都满足 $P_i>2$ 的假设下：\n\n**1. 通信复杂度 ($C$) 的推导**\n总邻接数 $C$ 是每个划分维度中邻接数的总和。\n我们来考虑 $x$ 方向的邻接关系。$P_x \\times P_y \\times P_z$ 的处理器网格可以看作是 $P_y P_z$ 个沿 $x$ 轴排列的处理器“笔”。每个“笔”是一个由 $P_x$ 个处理器组成的环。对于 $P_x > 2$，一个由 $P_x$ 个处理器组成的环有 $P_x$ 个邻接关系。如果 $P_x=1$，则有 $0$ 个邻接关系。\n$x$ 方向的邻接数为 $C_x = (P_y P_z) \\times P_x = P$（如果 $P_x > 1$），且 $C_x = 0$（如果 $P_x=1$）。\n类似地，$C_y = P$（如果 $P_y > 1$）且为 $0$（如果 $P_y=1$）。并且 $C_z = P$（如果 $P_z > 1$）且为 $0$（如果 $P_z=1$）。\n总复杂度 $C$ 是 $C_x + C_y + C_z$。\n\n- **板状分解**：$(P_x, P_y, P_z) = (1, 1, P)$。我们假设 $P>2$。\n  只有 $z$ 维度被划分（$P_z > 1$）。\n  $$C_{\\mathrm{slab}} = 0 + 0 + P = P$$\n\n- **笔状分解**：$(P_x, P_y, P_z) = (1, P_y, P_z)$，其中 $P_y P_z = P$。我们假设 $P_y>2$ 且 $P_z>2$。\n  $y$ 和 $z$ 维度被划分。\n  $$C_{\\mathrm{pencil}} = 0 + P + P = 2P$$\n\n- **块状分解**：$(P_x, P_y, P_z)$，其中 $P_x P_y P_z = P$。我们假设 $P_x>2$、$P_y>2$ 且 $P_z>2$。\n  所有三个维度都被划分。\n  $$C_{\\mathrm{block}} = P + P + P = 3P$$\n\n**2. 每个进程的邻居数 ($d$) 的推导**\n图中边的总数与顶点的度之和通过握手引理相关联：$\\sum_{v} \\text{degree}(v) = 2 \\times (\\text{边的数量})$。\n在我们的情况中，所有 $P$ 个进程的度都是一个常数 $d$。因此，$\\sum \\text{degree}(v) = P \\times d$。边的数量是 $C$。\n$$P d = 2C \\implies d = \\frac{2C}{P}$$\n\n- **板状分解**：\n  $$d_{\\mathrm{slab}} = \\frac{2 C_{\\mathrm{slab}}}{P} = \\frac{2P}{P} = 2$$\n\n- **笔状分解**：\n  $$d_{\\mathrm{pencil}} = \\frac{2 C_{\\mathrm{pencil}}}{P} = \\frac{2(2P)}{P} = 4$$\n\n- **块状分解**：\n  $$d_{\\mathrm{block}} = \\frac{2 C_{\\mathrm{block}}}{P} = \\frac{2(3P)}{P} = 6$$\n\n**3. 归一化复杂度 ($C/P$) 的推导**\n这通过将 $C$ 的表达式除以 $P$ 来得到。\n\n- **板状分解**：\n  $$C_{\\mathrm{slab}}/P = \\frac{P}{P} = 1$$\n\n- **笔状分解**：\n  $$C_{\\mathrm{pencil}}/P = \\frac{2P}{P} = 2$$\n\n- **块状分解**：\n  $$C_{\\mathrm{block}}/P = \\frac{3P}{P} = 3$$\n\n我们已经在“任何被划分的维度都有超过两个分区”这一标准假设下，计算了所有九个所需的量。\n\n最终结果是：\n- $d_{\\mathrm{slab}} = 2$\n- $d_{\\mathrm{pencil}} = 4$\n- $d_{\\mathrm{block}} = 6$\n- $C_{\\mathrm{slab}} = P$\n- $C_{\\mathrm{pencil}} = 2P$\n- $C_{\\mathrm{block}} = 3P$\n- $C_{\\mathrm{slab}}/P = 1$\n- $C_{\\mathrm{pencil}}/P = 2$\n- $C_{\\mathrm{block}}/P = 3$\n\n这些结果将按要求排列在一个单行矩阵中。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  4  6  P  2P  3P  1  2  3\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "从理论模型转向实际应用，即使选择了理论上最优的分解策略，不正确的实现也可能导致灾难性的失败，例如死锁。本练习  将带您进入代码和逻辑的领域。您将面临挑战，需要设计并模拟一种使用非阻塞通信的无死锁“光环”交换算法，这是任何并行程序员都必须掌握的关键技能。",
            "id": "3806415",
            "problem": "考虑一个用于计算海洋学的被动示踪剂输运方程的三维有限体积离散化，其中计算域被分解为排列在笛卡尔网格上的多个子域。每个子域被分配给一个独立的进程，这些进程通过消息传递接口 (MPI) 进行通信。为了使用依赖于最近邻的模板更新通量，每个进程必须与多达$6$个面相邻的邻居（方向为$+\\hat{x}$, $-\\hat{x}$, $+\\hat{y}$, $-\\hat{y}$, $+\\hat{z}$, $-\\hat{z}$）交换光环厚度为$1$个单元的光环数据。要求您从第一性原理出发，推导出一个正确且无死锁的非阻塞 MPI 操作序列，以实现$3\\text{D}$光环交换，同时重叠计算与通信，并形式化描述在违反顺序时可能发生死锁的条件。\n\n您的推导必须基于以下基本考虑：\n- $3\\text{D}$域分解定义了一组以维度为$(N_x,N_y,N_z)$的网格排列的进程，其中每个进程的坐标为$(i,j,k)$，满足$0 \\le i  N_x$，$0 \\le j  N_y$，$0 \\le k  N_z$。面相邻的邻居关系由网格邻接性确定。\n- 非阻塞 MPI 操作（如$\\mathrm{Irecv}$和$\\mathrm{Isend}$）会启动通信而不会阻塞调用者。其完成需要一个匹配的对等操作，并通过$\\mathrm{Wait}$或$\\mathrm{Waitall}$进行检测。\n- 在海洋模型模板中，不需要光环值的内部更新可以在光环消息传输过程中进行计算，从而实现通信与计算的重叠。\n- MPI 中的匹配由通信器、源或目标进程号以及消息标签决定；正确性要求双方在这些参数上对称一致。\n\n您的推导必须：\n- 明确定义每个进程在$\\mathrm{Irecv}$、$\\mathrm{Isend}$和$\\mathrm{Waitall}$方面的操作序列，并论证为什么先发布接收再发布发送足以避免死锁，同时还能实现计算与通信的重叠。\n- 陈述在违反顺序或匹配规则（如循环等待和标签不匹配）时可能发生死锁的条件。\n- 提供邻居集合和标签的形式化描述，该描述足以让一个模拟器判断给定的全局调度是否能完成。\n\n然后，实现一个模拟器，在逻辑层面（无实际 MPI 调用）对此非阻塞光环交换进行建模。模拟器表示排列在大小为$(N_x,N_y,N_z)$的网格中的进程，每个进程根据选定的调度策略发布一组非阻塞操作。模拟器必须通过匹配已发布的发送和接收来推进通信；一个$\\mathrm{Waitall}$只有在该进程发布的所有操作都匹配成功时才能成功。如果因存在未匹配的操作而导致进程停滞，且某些进程正在等待，则系统处于死锁状态。\n\n定义以下调度策略：\n- \"recv_then_send\"：一个进程向其所有存在的面邻居发布所有$\\mathrm{Irecv}$，然后发布所有$\\mathrm{Isend}$，对内部单元执行重叠计算，最后对所有已发布的操作调用$\\mathrm{Waitall}$。\n- \"send_then_wait_no_recv\"：一个进程向其所有存在的面邻居发布$\\mathrm{Isend}$，并立即调用$\\mathrm{Waitall}$，而从不发布$\\mathrm{Irecv}$。\n- \"recv_then_send_tag_mismatch_X\"：类似于\"recv_then_send\"，但该进程在$x$面上的消息使用不正确的标签（从而违反了这些面上的标签匹配规则）；在$y$面和$z$面上使用正确的标签。\n\n假设：\n- 消息仅在发送方和接收方就对等进程号和轴标签（$x$、$y$或$z$）达成一致时才匹配。方向$+\\hat{x}$或$-\\hat{x}$映射到轴标签$x$，对于$y$和$z$也类似。\n- 一个非阻塞发送直到匹配的接收被发布后才算完成；一个进程对未匹配的操作调用$\\mathrm{Waitall}$会保持等待状态。\n\n您的程序必须模拟以下测试套件，并为每个案例输出一个布尔值，指示全局执行是否无死锁（即所有进程都完成了它们的$\\mathrm{Waitall}$）。测试套件是：\n\n- 案例 1：$(N_x,N_y,N_z) = (2,2,2)$，所有进程使用 \"recv_then_send\"。\n- 案例 2：$(N_x,N_y,N_z) = (2,1,1)$，所有进程使用 \"send_then_wait_no_recv\"。\n- 案例 3：$(N_x,N_y,N_z) = (2,2,1)$，除位于$(0,0,0)$的进程使用 \"recv_then_send_tag_mismatch_X\" 外，所有进程均使用 \"recv_then_send\"。\n- 案例 4：$(N_x,N_y,N_z) = (1,1,1)$，所有进程使用 \"recv_then_send\"。\n\n最终输出规范：\n- 您的程序应产生单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[result_1,result_2,result_3,result_4]$），其中每个$result_i$是布尔值$\\mathrm{True}$（如果该案例无死锁）或$\\mathrm{False}$（否则）。\n\n不涉及物理单位。不使用角度。不使用百分比。",
            "solution": "该问题要求从第一性原理推导一种使用非阻塞消息传递接口 (MPI) 操作的无死锁光环交换算法，分析死锁条件，并实现一个模拟器来验证不同通信策略的行为。\n\n### 无死锁光环交换算法的推导\n\n**1. 形式化系统**\n设进程集合为 $P = \\{ p_{i,j,k} \\mid 0 \\le i  N_x, 0 \\le j  N_y, 0 \\le k  N_z \\}$。每个进程 $p_{i,j,k}$ 都有一个唯一的进程号，可以通过映射计算得出，例如 $r(i,j,k) = i + j \\cdot N_x + k \\cdot N_x \\cdot N_y$。\n\n一个进程 $p_{i,j,k}$ 最多有 $6$ 个邻居。例如，它在 $+\\hat{x}$ 方向的邻居是 $p_{i+1,j,k}$，前提是 $i+1  N_x$。与该邻居的通信沿 $x$ 轴进行。我们为每个轴分配唯一的整数标签，例如，标签 $0$ 用于 $x$ 轴，标签 $1$ 用于 $y$ 轴，标签 $2$ 用于 $z$ 轴。\n\n为了更新子域边界上的单元值，进程需要来自其邻居的数据。这通过交换“光环”或“幽灵”单元来实现。对于厚度为 $1$ 的光环，每个进程将其边界单元的一层发送给其邻居，并接收相应的一层到其光环区域。\n\n**2. “先接收后发送”策略**\n使用非阻塞操作 $\\mathrm{Irecv}$ 和 $\\mathrm{Isend}$ 是性能的关键。它们允许程序启动通信操作后继续执行其他工作，如计算，而数据传输在后台进行。$\\mathrm{Waitall}$ 操作用于确保所有已启动的通信都完成后，程序才能继续使用接收到的数据。\n\n一种稳健且被广泛采用的、能在执行光环交换时避免死锁的策略是**在发布任何发送操作之前发布所有接收操作**。每个进程的序列如下：\n\n1.  **发布所有接收 (Post All Receives)：** 对每个期望接收数据的邻居进程，发布一个非阻塞接收操作：$\\mathrm{Irecv}(source\\_rank, tag, ...)$。这通知 MPI 运行时库，该进程已准备好将传入数据接收到指定的缓冲区中。\n2.  **发布所有发送 (Post All Sends)：** 对每个必须发送数据的邻居进程，发布一个非阻塞发送操作：$\\mathrm{Isend}(destination\\_rank, tag, ...)$。由于所有进程都遵循相同的算法，相应的 $\\mathrm{Irecv}$ 已经被邻居进程发布，因此 MPI 库可以立即开始数据传输。\n3.  **重叠计算 (Overlap Computation)：** 在本地子域的*内部*执行计算。这些计算不依赖于当前正在传输的光环数据。这一步是性能提升的来源，因为计算与通信重叠了。\n4.  **等待完成 (Wait for Completion)：** 对已发布的 $\\mathrm{Irecv}$ 和 $\\mathrm{Isend}$ 操作的所有请求句柄集合调用 $\\mathrm{Waitall}$。此调用将阻塞，直到调用进程的所有发送和接收都完成。\n5.  **边界计算 (Boundary Computation)：** 一旦 $\\mathrm{Waitall}$ 返回，光环区域就充满了新的数据。进程现在可以安全地在其子域的边界单元上执行计算，这些计算依赖于此光环数据。\n\n该策略足以避免死锁的原因是它打破了任何潜在的资源依赖循环。在更简单的阻塞通信方案中（甚至在重负载下的非阻塞方案中），一个常见的死锁原因是当两个进程都试图同时向对方发送数据。如果系统缓冲区有限，两个发送操作可能都会阻塞，等待对方发布一个接收，但对方永远不会这样做，因为它也阻塞在发送操作上。通过首先发布所有接收，每个进程都表明自己已准备好接收数据，确保后续的发送总能找到一个已发布的匹配接收，从而保证通信可以进行。\n\n**3. 死锁的条件**\n当形成一个循环依赖，其中一组进程都在等待一个只能由该组内另一个进程触发的事件时，就会发生死锁。在 MPI 光环交换的背景下，这主要通过两种方式发生：\n\n*   **不正确的操作顺序（循环等待）：** 考虑一种策略，其中进程先发布发送，然后等待其完成，再发布接收。例如，进程 $p_A$ 执行 $\\mathrm{Isend}(p_B); \\mathrm{Wait}(...)$，进程 $p_B$ 执行 $\\mathrm{Isend}(p_A); \\mathrm{Wait}(...)$。从 $p_A$ 到 $p_B$ 的 `Isend` 直到 $p_B$ 发布匹配的 `Irecv` 后才能完成。然而，$p_B$ 被阻塞在它自己的 `Wait` 调用中，等待它向 $p_A$ 的发送完成，永远不会到达发布接收的步骤。$p_A$ 处于对称的情况。这就造成了死锁。`\"send_then_wait_no_recv\"` 策略是此缺陷的完美例子；由于没有任何进程发布接收，任何发送都无法完成，所有进程都将无限期等待。\n\n*   **参数不匹配 (Parameter Mismatch)：** MPI 要求发送和接收操作的参数精确匹配才能配对。源进程号、目标进程号或消息标签的不匹配将导致匹配引擎忽略这些操作。例如，假设进程 $p_A$ 希望与 $p_B$ 沿 $x$ 轴（标签 $0$）通信。\n    -   $p_A$ 发布 $\\mathrm{Irecv}(source=p_B, tag=0)$。\n    -   $p_B$ 发布 $\\mathrm{Isend}(dest=p_A, tag=99)$。\n    标签不匹配。来自 $p_B$ 的发送和来自 $p_A$ 的接收虽然针对同一对进程，但被视为不相关的通信。如果两个进程随后都调用 $\\mathrm{Waitall}$，它们将永远阻塞。$p_A$ 等待一个来自 $p_B$ 且标签为 $0$ 的消息，该消息永远不会被发送；而 $p_B$ 等待其已发送的标签为 $99$ 的消息被接收，但 $p_A$ 并不期望接收该标签的消息。`\"recv_then_send_tag_mismatch_X\"` 策略模拟了这种情况。\n\n**4. 模拟的形式化描述**\n模拟器可以通过跟踪已发布操作的状态来对该系统建模。\n-   **进程和进程号 (Processes and Ranks)：** 创建一个 $N_x \\times N_y \\times N_z$ 的进程网格。每个进程 $(i,j,k)$ 被分配一个唯一的进程号 $r$。\n-   **操作 (Operations)：** 通信操作表示为持有其基本匹配信息的对象或元组：`(type, rank, peer_rank, tag)`，其中 `type` 是 `SEND` 或 `RECV`。\n-   **执行模型 (Execution Model)：**\n    1.  **操作发布 (Operation Posting)：** 根据为每个进程指定的策略，生成所有预期的操作（`Irecv` 和 `Isend`），并放入两个全局列表：`pending_sends` 和 `pending_recvs`。策略的顺序（例如，所有 `Irecv` 在任何 `Isend` 之前发布）得到遵守。\n    2.  **匹配引擎 (Matching Engine)：** 模拟器重复扫描 `pending_sends` 和 `pending_recvs` 列表。如果找到一个发送操作 `(SEND, r1, r2, tag)` 和一个接收操作 `(RECV, r2, r1, tag)`，则构成一次匹配。这两个匹配的操作将从各自的列表中移除。此过程持续进行，直到在对列表的完整遍历中再也找不到匹配项为止。\n    3.  **死锁检测 (Deadlock Detection)：** 匹配引擎终止后，系统处于稳定状态。如果 `pending_sends` 和 `pending_recvs` 列表都为空，则意味着每个发布的发送都与相应的接收匹配。因此，所有进程都可以成功完成其 `Waitall` 调用。系统是无死锁的。如果任一列表非空，则意味着存在永远不会被匹配的未完成通信操作。发布这些操作的进程将在 `Waitall` 中无限期阻塞，系统处于死锁状态。",
            "answer": "```python\nimport numpy as np\nfrom collections import namedtuple\n\n# Define a simple structure for communication operations\nOperation = namedtuple('Operation', ['type', 'rank', 'peer', 'tag'])\n\ndef get_neighbors(coords, dims):\n    \"\"\"Finds face-adjacent neighbors for a process.\"\"\"\n    i, j, k = coords\n    Nx, Ny, Nz = dims\n    neighbors = []\n    # Directions: +x, -x, +y, -y, +z, -z\n    # Corresponding axes/tags: 0, 0, 1, 1, 2, 2\n    directions = [(1, 0, 0), (-1, 0, 0), (0, 1, 0), (0, -1, 0), (0, 0, 1), (0, 0, -1)]\n    tags = [0, 0, 1, 1, 2, 2]\n\n    for idx, (di, dj, dk) in enumerate(directions):\n        ni, nj, nk = i + di, j + dj, k + dk\n        if 0 = ni  Nx and 0 = nj  Ny and 0 = nk  Nz:\n            neighbors.append({\n                'coords': (ni, nj, nk),\n                'tag': tags[idx]\n            })\n    return neighbors\n\ndef simulate_halo_exchange(dims, policies):\n    \"\"\"\n    Simulates the MPI halo exchange and detects deadlocks.\n\n    Args:\n        dims (tuple): Grid dimensions (Nx, Ny, Nz).\n        policies (dict): A mapping from process coordinates to policy strings.\n\n    Returns:\n        bool: True if the exchange is deadlock-free, False otherwise.\n    \"\"\"\n    Nx, Ny, Nz = dims\n    num_procs = Nx * Ny * Nz\n    if num_procs == 0:\n        return True\n\n    # Map coordinates to a unique rank and back\n    coord_to_rank = {\n        (i, j, k): i + j * Nx + k * Nx * Ny\n        for k in range(Nz) for j in range(Ny) for i in range(Nx)\n    }\n\n    # Global pools of posted operations\n    pending_recvs = []\n    pending_sends = []\n\n    # --- Step 1: Post Receives ---\n    # According to the \"recv_then_send\" logic, post all receives first.\n    for k in range(Nz):\n        for j in range(Ny):\n            for i in range(Nx):\n                coords = (i, j, k)\n                rank = coord_to_rank[coords]\n                policy = policies[coords]\n\n                if policy in [\"recv_then_send\", \"recv_then_send_tag_mismatch_X\"]:\n                    neighbors = get_neighbors(coords, dims)\n                    for neighbor in neighbors:\n                        peer_coords = neighbor['coords']\n                        peer_rank = coord_to_rank[peer_coords]\n                        tag = neighbor['tag']\n                        pending_recvs.append(Operation('RECV', rank, peer_rank, tag))\n\n    # --- Step 2: Post Sends ---\n    # Now, all processes post their sends.\n    for k in range(Nz):\n        for j in range(Ny):\n            for i in range(Nx):\n                coords = (i, j, k)\n                rank = coord_to_rank[coords]\n                policy = policies[coords]\n\n                if policy in [\"recv_then_send\", \"send_then_wait_no_recv\", \"recv_then_send_tag_mismatch_X\"]:\n                    neighbors = get_neighbors(coords, dims)\n                    for neighbor in neighbors:\n                        peer_coords = neighbor['coords']\n                        peer_rank = coord_to_rank[peer_coords]\n                        tag = neighbor['tag']\n                        \n                        # Apply tag mismatch if the policy requires it\n                        if policy == \"recv_then_send_tag_mismatch_X\" and tag == 0: # tag 0 is x-axis\n                            tag = 99 # Mismatched tag\n\n                        pending_sends.append(Operation('SEND', rank, peer_rank, tag))\n\n    # --- Step 3: Matching Engine ---\n    # Repeatedly scan and match sends and receives until no more matches can be found.\n    while True:\n        matched_in_pass = False\n        \n        # To allow removing items while iterating, we iterate over a copy of one list\n        # and search the other.\n        sends_to_remove = set()\n        recvs_to_remove = set()\n        \n        # Use indices to handle list removal properly\n        recv_indices = list(range(len(pending_recvs)))\n        recv_matched = [False] * len(pending_recvs)\n\n        for i, s_op in enumerate(pending_sends):\n            for j_idx, r_op in enumerate(pending_recvs):\n                # Check if recv is already matched in this pass\n                if recv_matched[j_idx]:\n                    continue\n                \n                # Check for a match: sender-peer == receiver and receiver-peer == sender and tags match\n                if (s_op.peer == r_op.rank and s_op.rank == r_op.peer and s_op.tag == r_op.tag):\n                    sends_to_remove.add(i)\n                    recvs_to_remove.add(j_idx)\n                    recv_matched[j_idx] = True\n                    matched_in_pass = True\n                    break # A send can only match one receive\n        \n        if not matched_in_pass:\n            break\n\n        # Remove matched items from the lists in reverse index order to avoid shifting issues\n        for i in sorted(list(sends_to_remove), reverse=True):\n            del pending_sends[i]\n        for j in sorted(list(recvs_to_remove), reverse=True):\n            del pending_recvs[j]\n\n    # --- Step 4: Deadlock Detection ---\n    # If any operations remain unmatched, it's a deadlock.\n    # All policies imply a Waitall, so any pending op causes a block.\n    return len(pending_sends) == 0 and len(pending_recvs) == 0\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for the specified test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1: (2,2,2), all processes use \"recv_then_send\".\n        {\n            \"dims\": (2, 2, 2),\n            \"default_policy\": \"recv_then_send\",\n            \"exceptions\": {}\n        },\n        # Case 2: (2,1,1), all processes use \"send_then_wait_no_recv\".\n        {\n            \"dims\": (2, 1, 1),\n            \"default_policy\": \"send_then_wait_no_recv\",\n            \"exceptions\": {}\n        },\n        # Case 3: (2,2,1), all processes use \"recv_then_send\" except (0,0,0).\n        {\n            \"dims\": (2, 2, 1),\n            \"default_policy\": \"recv_then_send\",\n            \"exceptions\": { (0, 0, 0): \"recv_then_send_tag_mismatch_X\" }\n        },\n        # Case 4: (1,1,1), all processes use \"recv_then_send\".\n        {\n            \"dims\": (1, 1, 1),\n            \"default_policy\": \"recv_then_send\",\n            \"exceptions\": {}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        dims = case[\"dims\"]\n        Nx, Ny, Nz = dims\n        \n        # Build the policy map for the current case\n        policies = {}\n        for k in range(Nz):\n            for j in range(Ny):\n                for i in range(Nx):\n                    coords = (i, j, k)\n                    if coords in case[\"exceptions\"]:\n                        policies[coords] = case[\"exceptions\"][coords]\n                    else:\n                        policies[coords] = case[\"default_policy\"]\n\n        is_deadlock_free = simulate_halo_exchange(dims, policies)\n        results.append(is_deadlock_free)\n\n    # Format the final output string\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}