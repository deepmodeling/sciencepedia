{
    "hands_on_practices": [
        {
            "introduction": "实践始于基本功的练习。此练习要求为两种基础图结构——路径图和环形图——计算度分配性系数。通过这个过程，你将直接应用分配性系数的定义式，并学习如何处理因节点度完全相同而导致分母为零的正则图的特殊情况 。这项实践旨在构建对网络拓扑如何转化为标量指标的基本直觉，并探索其在大型网络中的渐近行为。",
            "id": "4262697",
            "problem": "考虑具有 $n$ 个节点的简单无向连通图：圈图 $C_{n}$ 和路图 $P_{n}$。令 $M$ 表示边的数量，并令 $\\{(j_{e},k_{e})\\}_{e=1}^{M}$ 表示每条边 $e$ 两端的有序度数对的多重集。度相关性系数 $r$ 定义为边集中端点度数之间的皮尔逊相关系数，即取值为 $\\{j_{e}\\}$ 和 $\\{k_{e}\\}$ 且边权重相等的两个随机变量 $J$ 和 $K$ 的相关性。\n\n从两个实值随机变量的皮尔逊相关系数的定义（协方差除以其标准差的乘积）出发，推导出一个用 $\\{(j_{e},k_{e})\\}_{e=1}^{M}$ 上的和表示的 $r$ 的精确表达式，并用它来计算 $C_{n}$ 和 $P_{n}$ 的 $r$ 值，其中对于路图，处理 $n\\geq 3$ 的情况。在 $C_{n}$ 的端点度方差为零的退化情况下，使用基于离散度类同配混合概念的连续性论证，来确定当所有实现的边都连接等度顶点时 $r$ 的极限值。\n\n然后，通过提取 $r(C_{n})$ 和 $r(P_{n})$ 的主导渐近行为，比较当 $n\\to\\infty$ 时 $r$ 的有限尺寸标度。\n\n无需四舍五入。将最终答案表示为一个单行矩阵中的两个无量纲值，第一个条目为 $r(C_{n})$，第二个条目为 $r(P_{n})$（表示为 $n$ 的闭式函数）。",
            "solution": "该问题要求推导圈图 $C_n$ 和路图 $P_n$（对于 $n \\geq 3$）的度相关性系数 $r$。推导必须从皮尔逊相关系数的定义开始。\n\n### 第一步：问题验证\n\n首先，我将验证问题陈述。\n\n#### 提取的已知条件\n- **图**：简单无向连通图：圈图 $C_{n}$ 和路图 $P_{n}$。\n- **节点**：节点数量为 $n$。\n- **边**：边的数量为 $M$。\n- **度数对**：每条边两端的有序度数对的多重集为 $\\{(j_{e},k_{e})\\}_{e=1}^{M}$。\n- **相关性定义**：度相关性系数 $r$ 是端点度数的皮尔逊相关系数，由从边的均匀随机抽样中得到的取值为 $\\{j_e\\}$ 和 $\\{k_e\\}$ 的随机变量 $J$ 和 $K$ 表示。\n- **约束条件**：对于路图，$n \\geq 3$。\n- **特殊说明**：\n    1. 从皮尔逊相关系数的定义推导 $r$ 的精确表达式。\n    2. 对于 $C_n$，使用基于同配混合的连续性论证来处理方差为零的退化情况，并赋予一个极限值。\n    3. 比较当 $n \\to \\infty$ 时 $r$ 对于 $C_n$ 和 $P_n$ 的有限尺寸标度。\n- **最终答案格式**：一个包含 $r(C_n)$ 和 $r(P_n)$ 的单行矩阵。\n\n#### 验证与结论\n该问题在科学和数学上是合理的。这是一个网络科学中的标准问题，将一个明确定义的度量（相关性系数）应用于基本的图结构（$C_n$ 和 $P_n$）。这些概念植根于图论和统计学。问题陈述清晰，提供了所有必要的定义和约束。对于正则图 $C_n$，使用极限论证的指令表明了对皮尔逊系数公式在方差为零时可能出现的不确定性的正确理解。该问题是客观、形式化的，并要求实质性的推导和分析。它没有违反任何无效性标准。\n因此，该问题是**有效的**。\n\n### 第二步：求解推导\n\n#### 相关性系数 $r$ 的通用公式\n两个随机变量 $J$ 和 $K$ 的皮尔逊相关系数 $r$ 定义为：\n$$ r = \\frac{\\text{Cov}(J, K)}{\\sigma_{J}\\sigma_{K}} $$\n其中 $\\text{Cov}(J, K) = E[JK] - E[J]E[K]$ 是协方差，$\\sigma_{J} = \\sqrt{E[J^2] - (E[J])^2}$ 和 $\\sigma_{K} = \\sqrt{E[K^2] - (E[K])^2}$ 是标准差。\n\n随机变量 $J$ 和 $K$ 代表随机选择的边的两端顶点的度。由于图是无向的，选择哪一端是“第一端”（对于 $J$）和哪一端是“第二端”（对于 $K$）是任意的。我们可以将样本空间定义为 $M$ 条边的集合，每条边被选择的概率为 $1/M$。对于边 $e$，$J$ 和 $K$ 的取值为 $j_e$ 和 $k_e$。\n\n期望值通过对所有边求和来计算：\n$$ E[J] = \\frac{1}{M} \\sum_{e=1}^{M} j_e $$\n$$ E[K] = \\frac{1}{M} \\sum_{e=1}^{M} k_e $$\n$$ E[JK] = \\frac{1}{M} \\sum_{e=1}^{M} j_e k_e $$\n$$ E[J^2] = \\frac{1}{M} \\sum_{e=1}^{M} j_e^2 $$\n$$ E[K^2] = \\frac{1}{M} \\sum_{e=1}^{M} k_e^2 $$\n对于无向图，边一端的度数多重集 $\\{j_e\\}_{e=1}^M$ 与另一端的度数多重集 $\\{k_e\\}_{e=1}^M$ 是相同的。这意味着 $E[J] = E[K]$ 且 $E[J^2] = E[K^2]$，进而意味着 $\\sigma_J = \\sigma_K$。\n\n将这些代入 $r$ 的公式：\n$$ r = \\frac{E[JK] - E[J]E[K]}{\\sqrt{E[J^2] - (E[J])^2} \\sqrt{E[K^2] - (E[K])^2}} = \\frac{E[JK] - (E[J])^2}{E[J^2] - (E[J])^2} $$\n现在，代入求和式：\n$$ r = \\frac{\\frac{1}{M} \\sum_{e=1}^{M} j_e k_e - \\left(\\frac{1}{M} \\sum_{e=1}^{M} j_e\\right)^2}{\\frac{1}{M} \\sum_{e=1}^{M} j_e^2 - \\left(\\frac{1}{M} \\sum_{e=1}^{M} j_e\\right)^2} $$\n将分子和分母乘以 $M^2$，得到度相关性系数的标准公式：\n$$ r = \\frac{M \\sum_{e=1}^{M} j_e k_e - \\left(\\sum_{e=1}^{M} j_e\\right)^2}{M \\sum_{e=1}^{M} j_e^2 - \\left(\\sum_{e=1}^{M} j_e\\right)^2} $$\n\n#### 圈图 $C_n$ 的相关性\n对于 $n \\geq 3$ 的圈图 $C_n$，每个节点的度都为 $2$。该图是 $2$-正则图。\n- 节点数：$n$。\n- 边数：$M = n$。\n- 对于每条边 $e$，其端点的度为 $(j_e, k_e) = (2, 2)$。\n\n我们计算公式所需的各项和：\n- $\\sum_{e=1}^{n} j_e k_e = \\sum_{e=1}^{n} (2 \\times 2) = \\sum_{e=1}^{n} 4 = 4n$。\n- $\\sum_{e=1}^{n} j_e = \\sum_{e=1}^{n} 2 = 2n$。\n- $\\sum_{e=1}^{n} j_e^2 = \\sum_{e=1}^{n} 2^2 = \\sum_{e=1}^{n} 4 = 4n$。\n\n将这些代入 $r$ 的公式：\n$$ r(C_n) = \\frac{n(4n) - (2n)^2}{n(4n) - (2n)^2} = \\frac{4n^2 - 4n^2}{4n^2 - 4n^2} = \\frac{0}{0} $$\n这个表达式是不确定的。分母对应于端点度分布的方差，由于所有端点度都相同，因此分母为零。\n\n根据问题陈述，我们必须使用连续性论证。相关性系数衡量节点连接到其他相似度数节点的偏好。在正则图中，每条边都连接两个度完全相同的节点。这代表了完全同配的状态。如果一个网络有多个度类，并且边只连接相同度数的节点（例如，度为 $k_1$ 的节点连接到度为 $k_1$ 的节点，度为 $k_2$ 的节点连接到度为 $k_2$ 的节点，等等），那么对于所有边 $e$ 都有 $j_e = k_e$。在这种情况下，$r$ 的公式的分子和分母变得相同，从而得到 $r=1$（前提是方差不为零）。正则图是这种情况的极限，即只有一个度类。因此，根据连续性或作为一种极限情况，相关性是最大的。我们赋值 $r=1$。\n\n因此，$r(C_n) = 1$。\n\n#### 路图 $P_n$ 的相关性\n对于 $n \\geq 3$ 的路图 $P_n$：\n- 节点数：$n$。\n- 边数：$M = n-1$。\n- 节点度数：\n    - 两个端点节点的度为 $1$。\n    - $n-2$ 个内部节点的度为 $2$。\n\n设节点标记为 $v_1, v_2, \\dots, v_n$，其度为 $d(v_1)=1$，$d(v_n)=1$，以及对于 $i \\in \\{2, \\dots, n-1\\}$ 有 $d(v_i)=2$。边是 $e_i = (v_i, v_{i+1})$，其中 $i \\in \\{1, \\dots, n-1\\}$。边 $e_i$ 的度数对是 $(d(v_i), d(v_{i+1}))$。\n\n这些和是在 $M=n-1$ 条边上计算的：\n- $\\sum_{e=1}^{M} j_e = \\sum_{i=1}^{n-1} d(v_i) = d(v_1) + \\sum_{i=2}^{n-1} d(v_i) = 1 + (n-2) \\times 2 = 2n - 3$。\n- $\\sum_{e=1}^{M} j_e^2 = \\sum_{i=1}^{n-1} d(v_i)^2 = d(v_1)^2 + \\sum_{i=2}^{n-1} d(v_i)^2 = 1^2 + (n-2) \\times 2^2 = 1 + 4(n-2) = 4n - 7$。\n- $\\sum_{e=1}^{M} j_e k_e = \\sum_{i=1}^{n-1} d(v_i)d(v_{i+1}) = d(v_1)d(v_2) + \\sum_{i=2}^{n-2} d(v_i)d(v_{i+1}) + d(v_{n-1})d(v_n)$。这个分解对于 $n \\geq 4$ 是有效的。\n对于 $n=3$，和为 $d(v_1)d(v_2) + d(v_2)d(v_3) = 1 \\times 2 + 2 \\times 1 = 4$。\n对于 $n \\geq 4$，和为 $(1 \\times 2) + \\sum_{i=2}^{n-2} (2 \\times 2) + (2 \\times 1) = 2 + 4(n-3) + 2 = 4n - 8$。\n公式 $4n-8$ 在 $n=3$ 时给出 $4(3)-8=4$，因此它对所有 $n \\geq 3$ 都成立。\n\n现在我们将这些和与 $M=n-1$ 代入 $r$ 的公式：\n$$ r(P_n) = \\frac{M \\sum j_e k_e - (\\sum j_e)^2}{M \\sum j_e^2 - (\\sum j_e)^2} = \\frac{(n-1)(4n-8) - (2n-3)^2}{(n-1)(4n-7) - (2n-3)^2} $$\n分子：\n$$ (n-1)(4n-8) - (2n-3)^2 = 4(n-1)(n-2) - (4n^2 - 12n + 9) $$\n$$ = 4(n^2 - 3n + 2) - 4n^2 + 12n - 9 = 4n^2 - 12n + 8 - 4n^2 + 12n - 9 = -1 $$\n分母：\n$$ (n-1)(4n-7) - (2n-3)^2 = (4n^2 - 11n + 7) - (4n^2 - 12n + 9) $$\n$$ = 4n^2 - 11n + 7 - 4n^2 + 12n - 9 = n - 2 $$\n因此，路图的相关性系数为：\n$$ r(P_n) = \\frac{-1}{n-2} $$\n\n#### 渐近行为\n- 对于 $C_n$，$r(C_n) = 1$，这是一个常数。当 $n \\to \\infty$ 时，$r(C_n) \\to 1$。\n- 对于 $P_n$，$r(P_n) = -\\frac{1}{n-2}$。当 $n \\to \\infty$ 时，$r(P_n) \\to 0$。主导渐近行为是 $r(P_n) \\sim -n^{-1}$。\n\n在 $n$ 很大时，圈图保持完全同配。路图渐近地变为中性（$r \\to 0$），因为两个度为 $1$ 的节点的边界效应与大量度为 $2$ 的节点相比变得可以忽略不计，使其在结构上类似于圈图。负号表示对于任何有限的 $n$，存在轻微的异配趋势，这是由低度端点连接到高度内部节点所驱动的。\n\n### 最终答案总结\n- 对于圈图 $C_n$，$r(C_n) = 1$。\n- 对于路图 $P_n$ ($n \\geq 3$)，$r(P_n) = -\\frac{1}{n-2}$。",
            "answer": "$$ \\boxed{\\begin{pmatrix} 1  -\\frac{1}{n-2} \\end{pmatrix}} $$"
        },
        {
            "introduction": "分配性的概念不仅限于度，它可以推广到任何分类节点属性。本练习将分配性系数的应用从度扩展到通用的分类标签，并探讨了在一个理想化的二分网络中的表现 。你将推导在一个所有连边都连接不同类型节点的网络中，当各类别的边端点分布均衡时，为何分类分配性系数达到其理论最小值 $-1$。这个练习有助于加深对分配性作为同配性通用度量的理解，并揭示其与二分性等基本网络结构之间的深刻联系。",
            "id": "4262725",
            "problem": "考虑一个简单的无向网络，其节点具有一个分类属性，该属性有两个值，记为 $A$ 和 $B$。设 $m$ 为边的总数。定义归一化混合矩阵 $e_{ij}$ 为在有序边端点上的分布，使得 $e_{ij}$ 是一个随机选择的有序边连接类别为 $i \\in \\{A,B\\}$ 的端点和类别为 $j \\in \\{A,B\\}$ 的端点的概率。设 $q_{i} = \\sum_{j} e_{ij}$ 表示从所有有序边端点中均匀随机选择一个端点，其类别为 $i$ 的边际概率。假设网络是二分的，即每条边都连接一个 $A$ 类节点和一个 $B$ 类节点；也就是说，没有 $A$–$A$ 或 $B$–$B$ 的边。再假设边端点的分布是均衡的，即 $q_{A} = q_{B} = \\frac{1}{2}$。\n\n从上述联合分布 $e_{ij}$ 及其边际分布 $q_{i}$ 的定义出发，并将名义类别的同配系数解释为在一条边的两个端点上观察到的类别之间经过适当归一化的相关性，计算该网络的分类同配系数 $r$。不需要近似计算；给出精确值。请说明为什么在均衡的二分情况下，所得到的 $r$ 达到了其下界。最终答案应表示为一个没有单位的纯数。",
            "solution": "首先验证问题，以确保其具有科学依据、自洽且定义明确。\n\n### 步骤1：提取已知条件\n- 网络：简单的，无向的。\n- 属性：分类属性，有两个值 $A$ 和 $B$。\n- 总边数：$m$。\n- 混合矩阵：$e_{ij}$ 是一个随机选择的有序边连接类别为 $i \\in \\{A,B\\}$ 的节点和类别为 $j \\in \\{A,B\\}$ 的节点的概率。\n- 边际概率：$q_{i} = \\sum_{j} e_{ij}$ 是一个随机选择的边端点类别为 $i$ 的概率。\n- 网络结构：二分的，即每条边连接一个 $A$ 类节点和一个 $B$ 类节点。没有 $A-A$ 或 $B-B$ 的边。\n- 边端点分布：均衡的，即 $q_{A} = q_{B} = \\frac{1}{2}$。\n- 任务：计算分类同配系数 $r$ 并解释为何它达到了下界。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题在网络科学领域内是定义明确的。简单无向网络、分类属性、混合矩阵（$e_{ij}$）、边际概率（$q_i$）和同配系数（$r$）等概念都是标准概念。“二分”和“均衡”的条件是定义明确且不矛盾的。一个在每个划分中具有相等数量边端点的二分网络，在物理上和数学上都是一种一致的情形。因此，该问题具有科学依据、客观且定义明确。\n\n### 步骤3：结论与行动\n问题有效。将提供完整的解答。\n\n### 求解过程\n\n对于具有名义属性的网络，其分类同配系数 $r$ 由以下公式定义：\n$$ r = \\frac{\\sum_{i} e_{ii} - \\sum_{i} q_i^2}{1 - \\sum_{i} q_i^2} $$\n该系数类似于 Cohen 的 kappa 统计量。项 $\\sum_{i} e_{ii}$ 表示同配（连接相同类别节点）边的比例，而项 $\\sum_{i} q_i^2$ 表示在连接是随机的但边端点的边际分布 $q_i$ 保持不变的网络中，这类边的期望比例。\n\n给定两个类别 $i \\in \\{A, B\\}$。$r$ 的公式展开为：\n$$ r = \\frac{(e_{AA} + e_{BB}) - (q_A^2 + q_B^2)}{1 - (q_A^2 + q_B^2)} $$\n\n问题指出网络是**二分的**，这意味着每条边都连接一个类别为 $A$ 的节点和一个类别为 $B$ 的节点。这意味着没有连接两个类别为 $A$ 的节点的边，也没有连接两个类别为 $B$ 的节点的边。\n就描述连接类别 $i$ 和 $j$ 的边的概率的混合矩阵 $e_{ij}$ 而言，这种结构约束意味着：\n$$ e_{AA} = 0 $$\n$$ e_{BB} = 0 $$\n因此，同配边的比例为 $\\sum_{i} e_{ii} = e_{AA} + e_{BB} = 0 + 0 = 0$。\n\n接下来，我们使用边端点分布是**均衡的**这一条件。该条件为：\n$$ q_A = q_B = \\frac{1}{2} $$\n我们现在可以计算项 $\\sum_{i} q_i^2$：\n$$ \\sum_{i} q_i^2 = q_A^2 + q_B^2 = \\left(\\frac{1}{2}\\right)^2 + \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{4} + \\frac{1}{4} = \\frac{1}{2} $$\n\n现在，我们将这些值代入同配系数 $r$ 的公式中。\n分子是：\n$$ \\sum_{i} e_{ii} - \\sum_{i} q_i^2 = 0 - \\frac{1}{2} = -\\frac{1}{2} $$\n分母是：\n$$ 1 - \\sum_{i} q_i^2 = 1 - \\frac{1}{2} = \\frac{1}{2} $$\n最后，同配系数是：\n$$ r = \\frac{-1/2}{1/2} = -1 $$\n\n### 关于下界的推理\n\n同配系数 $r$ 的一般结构为 $r = (p_o - p_e) / (1 - p_e)$，其中 $p_o = \\sum_i e_{ii}$ 是观察到的同配边比例，而 $p_e = \\sum_i q_i^2$ 是在随机零模型下的期望比例。\n\n$r$ 的值受网络结构（决定 $e_{ij}$）和类别的整体分布（决定 $q_i$）两方面的影响。\n对于一组固定的边际概率 $q_i$，$r$ 的值在分子 $\\sum_i e_{ii} - \\sum_i q_i^2$ 最小化时达到最小值。由于 $\\sum_i q_i^2$ 是固定的，这发生在 $\\sum_i e_{ii}$ 最小化时。由于 $e_{ii}$ 代表一个概率（或边的比例），$e_{ii} \\ge 0$，因此它们的和的最小可能值为 $\\sum_i e_{ii} = 0$。这个最小值在没有同配边的网络中实现——即一个完全异配或多分网络。问题的“二分”条件确保了达到这个最小值。\n\n因此，网络是二分的这一条件保证了对于给定的边际概率 $q_i$，$r$ 达到了其可能的最小值。这个最小值为：\n$$ r_{\\text{min}} = \\frac{0 - \\sum_i q_i^2}{1 - \\sum_i q_i^2} = - \\frac{\\sum_i q_i^2}{1 - \\sum_i q_i^2} $$\n第二个条件，即边端点分布是“均衡的”（$q_A=q_B=1/2$），这是一组特定的边际概率，决定了这个下界的数值。正如我们计算的，对于这些边际概率，$\\sum_i q_i^2 = 1/2$。将此值代入最小同配系数的表达式中，得到：\n$$ r = - \\frac{1/2}{1 - 1/2} = -1 $$\n这个值 $-1$ 是分类同配系数 $r$ 的绝对理论最小值。函数 $f(S) = -S/(1-S)$（其中 $S=\\sum_i q_i^2$）的最小值在 $S$ 最小时出现。对于两个类别，$S = q_A^2 + (1-q_A)^2$，当 $q_A = 1/2$ 时，其最小值为 $S=1/2$。因此，完全异配的结构（二分）和最大程度均衡的边际分布（$q_A=q_B=1/2$）相结合，迫使同配系数达到其最极端的负值 $-1$。",
            "answer": "$$\\boxed{-1}$$"
        },
        {
            "introduction": "在真实世界中，网络是动态演化的，每次微小变化后都从头重新计算全局属性是极其低效的。这项实践挑战你推导并实现一个用于计算分配性系数的在线更新算法 。你需要分析单个边的插入或删除如何仅通过局部信息来更新计算所需的全局统计量，从而避免对整个网络进行遍历。这项任务将理论理解与实用的计算思维相结合，展示了为动态网络设计高效分析算法的关键技能，这在当代网络科学中至关重要。",
            "id": "4262715",
            "problem": "给定一个有限、无向、简单的图，没有自环，也没有多重边。令 $V$ 表示节点集合，$E$ 表示边集合，其中 $|V| = n$ 且 $|E| = M$。对于一条边 $e = \\{u,v\\} \\in E$，定义 $j_e = d_u$ 和 $k_e = d_v$，其中 $d_x$ 是节点 $x$ 的度。图的度匹配系数（degree assortativity coefficient）$\\hat r$ 定义为：从 $E$ 中均匀随机选择一条边，并读取其两个端点的度，由此得到的随机变量 $J$ 和 $K$ 之间的样本皮尔逊相关系数（sample Pearson correlation coefficient）。使用样本皮尔逊相关系数的这一定义，并从关于样本均值、方差和协方差的第一性原理出发，推导出一个实现，该实现支持在边的插入和删除操作下对计算 $\\hat r$ 所需的充分统计量进行在线更新。在线更新的运行时间必须仅依赖于被修改边的端点的度及其邻居集合，并且必须避免对所有边进行重新计算。\n\n你的任务包含两个部分：\n1. 从上述基本定义出发，推导在单条边 $\\{u,v\\}$ 插入和单条边 $\\{u,v\\}$ 删除后，计算 $\\hat r$ 所需的充分统计量的显式在线更新表达式。这些表达式应根据变化前 $u$ 和 $v$ 的度及邻居集合来表示。你的推导应从样本皮尔逊相关系数的定义和求和的线性性质开始，不应调用任何关于匹配系数的现成公式。明确描述每个充分统计量如何变化，并证明这些变化仅依赖于 $u$ 和 $v$ 周围的局部量。\n\n2. 实现一个完整的、可运行的程序，该程序：\n   - 维护图以及计算 $\\hat r$ 所需的充分统计量。\n   - 使用你推导出的表达式支持边的插入和删除的在线更新。\n   - 每次更新后，仅使用维护的统计量计算 $\\hat r$。\n   - 每次更新后，通过从头开始的批量重新计算来计算 $\\hat r$。\n   - 验证在线更新的结果与批量重新计算的结果在 $10^{-12}$ 的数值公差范围内相等，并为每个测试用例返回一个布尔值，指示该用例中的所有更新是否都满足相等性检查。\n\n如果在任何时候边的数量 $M = 0$，或者皮尔逊相关系数分母中所需的样本方差等于 $0$（例如，在所有度都相等的正则图中），则按照惯例将 $\\hat r$ 定义为实数 $0.0$。\n\n使用以下测试套件。每个测试用例由 $(n, E_0, \\mathcal{O})$ 指定，其中 $n$ 是标记为 $0,1,\\dots,n-1$ 的节点数，$E_0$ 是初始边集，$\\mathcal{O}$ 是一个有序的操作列表，每个操作的形式为 $\\text{insert}(u,v)$ 或 $\\text{delete}(u,v)$：\n- 测试用例 1 (一般情况):\n  - $n = 5$\n  - $E_0 = \\{(0,1),(1,2),(2,3),(3,4)\\}$\n  - $\\mathcal{O} = [\\text{insert}(0,4), \\text{delete}(1,2), \\text{insert}(1,4)]$\n- 测试用例 2 (涉及空图转换的边界情况):\n  - $n = 3$\n  - $E_0 = \\emptyset$\n  - $\\mathcal{O} = [\\text{insert}(0,1), \\text{insert}(1,2), \\text{delete}(0,1), \\text{delete}(1,2)]$\n- 测试用例 3 (从正则图到非正则图的转换):\n  - $n = 6$\n  - $E_0 = \\{(0,1),(1,2),(2,3),(3,4),(4,5),(5,0)\\}$\n  - $\\mathcal{O} = [\\text{insert}(0,3), \\text{delete}(2,3)]$\n- 测试用例 4 (通过星形图和局部重连实现高度异构性):\n  - $n = 7$\n  - $E_0 = \\{(0,1),(0,2),(0,3),(0,4),(0,5),(0,6)\\}$\n  - $\\mathcal{O} = [\\text{delete}(0,6), \\text{insert}(1,2), \\text{insert}(2,3), \\text{delete}(0,1)]$\n\n你的程序应产生单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，\"[result1,result2,result3,result4]\"）。每个结果必须是一个布尔值，指示对于该测试用例，在线更新和批量重新计算是否在 $\\mathcal{O}$ 中的每个操作上都在指定的公差范围内达成一致。不涉及物理单位或角度单位。所有数值输出必须是指定的小数或布尔值。",
            "solution": "该问题要求为度匹配系数 $\\hat{r}$ 的充分统计量推导在线更新规则，并实现一个程序来验证这些规则。我将首先从第一性原理出发进行推导。\n\n度匹配系数 $\\hat{r}$ 定义为图中所有边上相邻节点度的样本皮尔逊相关系数。设图为 $G=(V, E)$，有 $n=|V|$ 个节点和 $M=|E|$ 条边。对于一条边 $\\{u,v\\} \\in E$，其端点的度分别为 $d_u$ 和 $d_v$。\n\n为了为相关系数构建一个定义明确的样本，我们将每条无向边 $\\{u,v\\}$ 视为两条有向边 $(u,v)$ 和 $(v,u)$。这样就创建了一个包含 $N=2M$ 个度对的样本。令 $J$ 和 $K$ 为随机选择的一条有向边的源节点和目标节点的度所代表的随机变量。样本由 $i=1, \\dots, 2M$ 的度对 $(J_i, K_i)$ 组成。对于一条边 $\\{u,v\\} \\in E$，我们在样本中加入两个度对：$(d_u, d_v)$ 和 $(d_v, d_u)$。\n\n样本皮尔逊相关系数 $\\hat{r}$ 由以下公式给出：\n$$\n\\hat{r} = \\frac{ \\sum_{i=1}^{N} (J_i - \\bar{J})(K_i - \\bar{K}) }{ \\sqrt{ \\sum_{i=1}^{N} (J_i - \\bar{J})^2 \\sum_{i=1}^{N} (K_i - \\bar{K})^2 } }\n$$\n一个计算上更方便的形式是：\n$$\n\\hat{r} = \\frac{N \\sum J_i K_i - (\\sum J_i)(\\sum K_i)}{\\sqrt{[N \\sum J_i^2 - (\\sum J_i)^2][N \\sum K_i^2 - (\\sum K_i)^2]}}\n$$\n由于我们样本的对称构造，$\\sum J_i = \\sum K_i$ 且 $\\sum J_i^2 = \\sum K_i^2$，因此分母得以简化。我们根据图结构上的和定义四个充分统计量：\n1. 有向边的数量，$N = 2M$。\n2. 每条有向边起点的度之和：$\\sum J_i = \\sum_{\\{u,v\\}\\in E} (d_u + d_v) = \\sum_{w \\in V} d_w^2$。我们将此和表示为 $S_2$。\n3. 每条有向边起点的度的平方和：$\\sum J_i^2 = \\sum_{\\{u,v\\}\\in E} (d_u^2 + d_v^2) = \\sum_{w \\in V} d_w \\cdot d_w^2 = \\sum_{w \\in V} d_w^3$。我们将其表示为 $S_3$。\n4. 每条有向边的度之积的和：$\\sum J_i K_i = \\sum_{\\{u,v\\}\\in E} (d_u d_v + d_v d_u) = 2 \\sum_{\\{u,v\\}\\in E} d_u d_v$。我们记 $S_{jk} = \\sum_{\\{u,v\\}\\in E} d_u d_v$。\n\n将这些代入 $\\hat{r}$ 的公式中：\n$$\n\\hat{r} = \\frac{(2M)(2 S_{jk}) - (S_2)(S_2)}{\\sqrt{[(2M)S_3 - S_2^2][(2M)S_3 - S_2^2]}} = \\frac{4M S_{jk} - S_2^2}{2M S_3 - S_2^2}\n$$\n如果 $M=0$ 或分母 $2M S_3 - S_2^2 = 0$（这在正则图中会发生），则 $\\hat{r}$ 定义为 $0.0$。\n为了执行在线更新，我们必须推导在插入或删除边时，$M$, $S_2$, $S_3$ 和 $S_{jk}$ 如何变化。令更新前的量不带撇号（例如，$d_w$），更新后的量带撇号（例如，$d'_w$）。更新公式中的所有度都是更新前的度。\n\n**插入边 $\\{u,v\\}$**\n一条边 $\\{u,v\\}$ 被添加到 $E$ 中。我们假设 $\\{u,v\\} \\notin E$。\n-   $M' = M+1$。\n-   节点 $u$ 和 $v$ 的度各增加一：$d'_u = d_u+1, d'_v = d_v+1$。对于任何其他节点 $w \\neq u,v$，$d'_w = d_w$。\n-   **$S_2 = \\sum_{w \\in V} d_w^2$ 的更新**：\n    $S'_2 = \\sum_{w \\in V} (d'_w)^2 = \\left(\\sum_{w \\neq u,v} d_w^2\\right) + (d'_u)^2 + (d'_v)^2 = (S_2 - d_u^2 - d_v^2) + (d_u+1)^2 + (d_v+1)^2 = S_2 + 2(d_u+d_v) + 2$。\n    变化量为 $\\Delta S_2 = 2(d_u+d_v+1)$。\n-   **$S_3 = \\sum_{w \\in V} d_w^3$ 的更新**：\n    $S'_3 = \\sum_{w \\in V} (d'_w)^3 = (S_3 - d_u^3 - d_v^3) + (d_u+1)^3 + (d_v+1)^3 = S_3 + 3(d_u^2+d_v^2) + 3(d_u+d_v) + 2$。\n    变化量为 $\\Delta S_3 = 3(d_u^2+d_v^2) + 3(d_u+d_v) + 2$。\n-   **$S_{jk} = \\sum_{\\{a,b\\}\\in E} d_a d_b$ 的更新**：\n    $S'_{jk} = \\sum_{\\{a,b\\} \\in E \\cup \\{\\{u,v\\}\\}} d'_a d'_b = \\sum_{\\{a,b\\} \\in E} d'_a d'_b + d'_u d'_v$。\n    对现有边集 $E$ 的求和的变化，源于 $u$ 和 $v$ 的度变化。对于一条边 $\\{a,b\\} \\in E$，仅当其端点之一是 $u$ 或 $v$ 时，项 $d_a d_b$ 才会改变。\n    - 对于每个邻居 $w \\in N(u)$，边 $\\{u,w\\}$ 的项从 $d_u d_w$ 变为 $d'_u d'_w = (d_u+1)d_w$。增加量为 $d_w$。\n    - 对于每个邻居 $w \\in N(v)$，边 $\\{v,w\\}$ 的项从 $d_v d_w$ 变为 $d'_v d'_w = (d_v+1)d_w$。增加量为 $d_w$。\n    现有边上的总变化量为 $\\sum_{w \\in N(u)} d_w + \\sum_{w \\in N(v)} d_w$。新边 $\\{u,v\\}$ 增加了一个项 $d'_u d'_v = (d_u+1)(d_v+1)$。\n    因此，$S'_{jk} = S_{jk} + \\left( \\sum_{w \\in N(u)} d_w + \\sum_{w \\in N(v)} d_w \\right) + (d_u+1)(d_v+1)$。\n    变化量 $\\Delta S_{jk} = \\sum_{w \\in N(u)} d_w + \\sum_{w \\in N(v)} d_w + (d_u+1)(d_v+1)$。\n\n**删除边 $\\{u,v\\}$**\n一条边 $\\{u,v\\}$ 从 $E$ 中被移除。\n-   $M' = M-1$。\n-   度发生变化：$d'_u = d_u-1, d'_v = d_v-1$。其他节点的度保持不变。\n-   **$S_2$ 的更新**：\n    $S'_2 = (S_2 - d_u^2 - d_v^2) + (d_u-1)^2 + (d_v-1)^2 = S_2 - 2(d_u+d_v) + 2$。\n    变化量为 $\\Delta S_2 = -2(d_u+d_v-1)$。\n-   **$S_3$ 的更新**：\n    $S'_3 = (S_3 - d_u^3 - d_v^3) + (d_u-1)^3 + (d_v-1)^3 = S_3 - (3(d_u^2+d_v^2) - 3(d_u+d_v) + 2)$。\n    变化量为 $\\Delta S_3 = -[3(d_u^2+d_v^2) - 3(d_u+d_v) + 2]$。\n-   **$S_{jk}$ 的更新**：\n    $S'_{jk} = \\sum_{\\{a,b\\}\\in E\\setminus\\{\\{u,v\\}\\}} d'_a d'_b$。我们计算变化量 $S'_{jk} - S_{jk}$。\n    $S_{jk} = \\sum_{\\{a,b\\}\\in E\\setminus\\{\\{u,v\\}\\}} d_a d_b + d_u d_v$。\n    $S'_{jk} - S_{jk} = \\left(\\sum_{\\{a,b\\}\\in E\\setminus\\{\\{u,v\\}\\}} d'_a d'_b\\right) - \\left(\\sum_{\\{a,b\\}\\in E\\setminus\\{\\{u,v\\}\\}} d_a d_b + d_u d_v\\right) = \\sum_{\\{a,b\\}\\in E\\setminus\\{\\{u,v\\}\\}} (d'_a d'_b - d_a d_b) - d_u d_v$。\n    - 对于一条边 $\\{u,w\\}$，其中 $w \\in N(u)\\setminus\\{v\\}$，其项的变化为 $(d_u-1)d_w - d_u d_w = -d_w$。\n    - 对于一条边 $\\{v,w\\}$，其中 $w \\in N(v)\\setminus\\{u\\}$，相应的变化为 $-d_w$。\n    $S_{jk}$ 的总变化量是 $\\Delta S_{jk} = - \\left(d_u d_v + \\sum_{w \\in N(u)\\setminus\\{v\\}} d_w + \\sum_{w \\in N(v)\\setminus\\{u\\}} d_w \\right)$。\n\n所有推导出的更新规则仅依赖于修改前边端点 $u, v$ 的度及其邻居。这证实了复杂度为 $O(d_u+d_v)$ 的在线更新是可行的。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of verifying online updates for the degree assortativity coefficient.\n    \"\"\"\n\n    class DynamicAssortativity:\n        \"\"\"\n        Maintains graph sufficient statistics for online assortativity calculation.\n        \"\"\"\n        def __init__(self, n, initial_edges):\n            self.n = n\n            self.adj = [set() for _ in range(n)]\n            self.degrees = np.zeros(n, dtype=np.int64)\n            \n            num_edges = 0\n            for u, v in initial_edges:\n                self.adj[u].add(v)\n                self.adj[v].add(u)\n                self.degrees[u] += 1\n                self.degrees[v] += 1\n                num_edges += 1\n            \n            # Initialize sufficient statistics from the initial graph state\n            self.M = np.int64(num_edges)\n            self.S2 = np.sum(self.degrees**2, dtype=np.int64)\n            self.S3 = np.sum(self.degrees**3, dtype=np.int64)\n            s_jk = np.int64(0)\n            for u in range(self.n):\n                for v in self.adj[u]:\n                    if u  v:\n                        s_jk += self.degrees[u] * self.degrees[v]\n            self.S_jk = s_jk\n            \n        def get_r_online(self):\n            \"\"\"Computes assortativity from maintained statistics.\"\"\"\n            if self.M == 0:\n                return 0.0\n            \n            numerator = 4 * self.M * self.S_jk - self.S2**2\n            denominator = 2 * self.M * self.S3 - self.S2**2\n            \n            if abs(denominator)  1e-12: # Handle zero variance\n                return 0.0\n            \n            return float(numerator) / float(denominator)\n\n        def get_r_batch(self):\n            \"\"\"Computes assortativity by recomputing stats from scratch.\"\"\"\n            current_M = np.sum(self.degrees) // 2\n            if current_M == 0:\n                return 0.0\n            \n            current_S2 = np.sum(self.degrees**2)\n            current_S3 = np.sum(self.degrees**3)\n            \n            current_S_jk = 0\n            for u in range(self.n):\n                for v in self.adj[u]:\n                    if u  v:\n                        current_S_jk += self.degrees[u] * self.degrees[v]\n\n            numerator = 4 * current_M * current_S_jk - current_S2**2\n            denominator = 2 * current_M * current_S3 - current_S2**2\n\n            if abs(denominator)  1e-12:\n                return 0.0\n            \n            return float(numerator) / float(denominator)\n\n        def insert_edge(self, u, v):\n            \"\"\"Online update for edge insertion.\"\"\"\n            du, dv = self.degrees[u], self.degrees[v]\n\n            # Update S_jk\n            sum_deg_nu = np.sum(self.degrees[list(self.adj[u])]) if self.adj[u] else 0\n            sum_deg_nv = np.sum(self.degrees[list(self.adj[v])]) if self.adj[v] else 0\n            self.S_jk += sum_deg_nu + sum_deg_nv + (du + 1) * (dv + 1)\n            \n            # Update S2\n            self.S2 += 2 * (du + dv + 1)\n            \n            # Update S3\n            self.S3 += 3 * (du**2 + dv**2) + 3 * (du + dv) + 2\n            \n            # Update M\n            self.M += 1\n\n            # Update graph state\n            self.adj[u].add(v)\n            self.adj[v].add(u)\n            self.degrees[u] += 1\n            self.degrees[v] += 1\n\n        def delete_edge(self, u, v):\n            \"\"\"Online update for edge deletion.\"\"\"\n            du, dv = self.degrees[u], self.degrees[v]\n\n            # Update S_jk\n            sum_deg_nu_minus_v = np.sum(self.degrees[list(self.adj[u] - {v})]) if len(self.adj[u]) > 1 else 0\n            sum_deg_nv_minus_u = np.sum(self.degrees[list(self.adj[v] - {u})]) if len(self.adj[v]) > 1 else 0\n            self.S_jk -= du * dv + sum_deg_nu_minus_v + sum_deg_nv_minus_u\n\n            # Update S2\n            self.S2 -= 2 * (du + dv - 1)\n            \n            # Update S3\n            self.S3 -= 3 * (du**2 + dv**2) - 3 * (du + dv) + 2\n            \n            # Update M\n            self.M -= 1\n\n            # Update graph state\n            self.adj[u].remove(v)\n            self.adj[v].remove(u)\n            self.degrees[u] -= 1\n            self.degrees[v] -= 1\n\n    test_cases = [\n        (5, [(0,1),(1,2),(2,3),(3,4)], [(\"insert\", (0,4)), (\"delete\", (1,2)), (\"insert\", (1,4))]),\n        (3, [], [(\"insert\", (0,1)), (\"insert\", (1,2)), (\"delete\", (0,1)), (\"delete\", (1,2))]),\n        (6, [(0,1),(1,2),(2,3),(3,4),(4,5),(5,0)], [(\"insert\", (0,3)), (\"delete\", (2,3))]),\n        (7, [(0,1),(0,2),(0,3),(0,4),(0,5),(0,6)], [(\"delete\", (0,6)), (\"insert\", (1,2)), (\"insert\", (2,3)), (\"delete\", (0,1))])\n    ]\n\n    results = []\n    for n, e0, ops in test_cases:\n        graph_manager = DynamicAssortativity(n, list(e0))\n        all_updates_correct = True\n        \n        for op_type, edge in ops:\n            if op_type == \"insert\":\n                graph_manager.insert_edge(edge[0], edge[1])\n            elif op_type == \"delete\":\n                graph_manager.delete_edge(edge[0], edge[1])\n\n            r_online = graph_manager.get_r_online()\n            r_batch = graph_manager.get_r_batch()\n            \n            if not np.isclose(r_online, r_batch, atol=1e-12, rtol=0):\n                all_updates_correct = False\n                break\n        \n        results.append(all_updates_correct)\n\n    print(f\"[{','.join(str(r).lower() for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}