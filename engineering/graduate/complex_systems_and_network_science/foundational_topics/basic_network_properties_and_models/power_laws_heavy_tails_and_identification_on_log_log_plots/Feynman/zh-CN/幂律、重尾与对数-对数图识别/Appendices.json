{
    "hands_on_practices": [
        {
            "introduction": "在我们能够识别现实世界中的幂律分布之前，我们必须首先理解其基本的数学性质。这个练习  深入探讨了作为幂律分布原型的帕累托（Pareto）分布。通过从第一性原理出发推导其关键的统计量，并比较均值与中位数，我们将对重尾现象标志性的极端右偏性有一个定量的理解。",
            "id": "4297927",
            "problem": "一位研究大型技术网络的研究人员发现，在超过某个截断度 $x_{\\min}$ 后的几个数量级范围内，节点度的互补累积分布函数（CCDF）在对数-对数图上近似为线性。受此启发，假设度分布在 $x_{\\min}$ 以上遵循帕累托（I型）分布，其尺度参数为 $x_{\\min} > 0$，形状参数为 $\\alpha > 0$，概率密度函数 $f(x)$ 的定义域为 $x \\ge x_{\\min}$。仅从概率密度函数 $f(x)$、累积分布函数 $F(x)$ 以及中位数和均值的定义出发，完成以下任务：\n\n- 使用 $f(x) = \\alpha x_{\\min}^{\\alpha} x^{-(\\alpha+1)}$（当 $x \\ge x_{\\min}$ 时）和 $f(x) = 0$（其他情况），推导累积分布函数 $F(x)$。\n- 使用中位数 $m$ 满足 $F(m) = \\tfrac{1}{2}$ 的定义，求解 $m$ 关于 $x_{\\min}$ 和 $\\alpha$ 的表达式。\n- 假设 $\\alpha > 1$ 以确保均值存在，从第一性原理计算均值 $\\mu$，然后给出比值 $\\mu/m$ 作为 $\\alpha$ 的函数的精确表达式。\n\n你的最终答案必须是 $\\mu/m$ 关于 $\\alpha$ 的单个闭式解析表达式。不要近似或四舍五入。不要包含单位。仅使用上述基本定义解释每个推导步骤。最后用一句话简要说明，对于在对数-对数图上观察到的重尾数据，当 $\\alpha > 1$ 时，$\\mu/m$ 的值如何反映其右偏性。",
            "solution": "本题要求从第一性原理出发，推导帕累托（I型）分布的均值与中位数的比值。该问题提法明确，科学上合理，并包含了获得唯一解所需的所有信息。\n\n首先，我们从给定的概率密度函数（PDF）$f(x) = \\alpha x_{\\min}^{\\alpha} x^{-(\\alpha+1)}$（当 $x \\ge x_{\\min}$ 时）推导累积分布函数（CDF）$F(x)$。CDF 定义为 $F(x) = \\int_{-\\infty}^{x} f(t) dt$。由于该分布的支撑集为 $[x_{\\min}, \\infty)$，因此对于 $t  x_{\\min}$，PDF 为零。所以，对于任意 $x \\ge x_{\\min}$，CDF 由以下积分给出：\n$$F(x) = \\int_{x_{\\min}}^{x} f(t) dt = \\int_{x_{\\min}}^{x} \\alpha x_{\\min}^{\\alpha} t^{-(\\alpha+1)} dt$$\n我们可以将相对于积分变量 $t$ 的常数提取出来：\n$$F(x) = \\alpha x_{\\min}^{\\alpha} \\int_{x_{\\min}}^{x} t^{-(\\alpha+1)} dt$$\n$t^n$ 的积分是 $\\frac{t^{n+1}}{n+1}$。此处，指数是 $-(\\alpha+1)$，所以积分计算结果为：\n$$F(x) = \\alpha x_{\\min}^{\\alpha} \\left[ \\frac{t^{-(\\alpha+1)+1}}{-(\\alpha+1)+1} \\right]_{x_{\\min}}^{x} = \\alpha x_{\\min}^{\\alpha} \\left[ \\frac{t^{-\\alpha}}{-\\alpha} \\right]_{x_{\\min}}^{x}$$\n在积分上下限处计算表达式的值：\n$$F(x) = \\alpha x_{\\min}^{\\alpha} \\left( \\frac{x^{-\\alpha}}{-\\alpha} - \\frac{x_{\\min}^{-\\alpha}}{-\\alpha} \\right) = -x_{\\min}^{\\alpha} (x^{-\\alpha} - x_{\\min}^{-\\alpha})$$\n$$F(x) = -x_{\\min}^{\\alpha} x^{-\\alpha} + x_{\\min}^{\\alpha} x_{\\min}^{-\\alpha} = - \\left(\\frac{x_{\\min}}{x}\\right)^{\\alpha} + 1$$\n所以，对于 $x \\ge x_{\\min}$，累积分布函数为：\n$$F(x) = 1 - \\left(\\frac{x_{\\min}}{x}\\right)^{\\alpha}$$\n对于 $x  x_{\\min}$，$F(x) = 0$。\n\n接下来，我们求中位数 $m$。根据定义，中位数是使 $F(x) = \\frac{1}{2}$ 的 $x$ 值。由于 $\\alpha > 0$ 且 $x_{\\min} > 0$，CDF 从 $F(x_{\\min}) = 0$ 严格递增到 $\\lim_{x \\to \\infty} F(x) = 1$，因此存在唯一的中位数且大于 $x_{\\min}$。我们令 $F(m) = \\frac{1}{2}$：\n$$1 - \\left(\\frac{x_{\\min}}{m}\\right)^{\\alpha} = \\frac{1}{2}$$\n重新整理各项以求解 $m$：\n$$\\left(\\frac{x_{\\min}}{m}\\right)^{\\alpha} = 1 - \\frac{1}{2} = \\frac{1}{2}$$\n对两边取 $\\alpha$ 次方根：\n$$\\frac{x_{\\min}}{m} = \\left(\\frac{1}{2}\\right)^{1/\\alpha} = 2^{-1/\\alpha}$$\n解得 $m$：\n$$m = \\frac{x_{\\min}}{2^{-1/\\alpha}} = x_{\\min} 2^{1/\\alpha}$$\n\n现在，我们计算分布的均值 $\\mu$。均值是随机变量 $X$ 的期望值，定义为 $\\mu = E[X] = \\int_{-\\infty}^{\\infty} x f(x) dx$。题目规定我们假设 $\\alpha > 1$，这是均值有限的必要条件。\n$$\\mu = \\int_{x_{\\min}}^{\\infty} x \\left( \\alpha x_{\\min}^{\\alpha} x^{-(\\alpha+1)} \\right) dx$$\n合并包含 $x$ 的项：\n$$\\mu = \\alpha x_{\\min}^{\\alpha} \\int_{x_{\\min}}^{\\infty} x \\cdot x^{-(\\alpha+1)} dx = \\alpha x_{\\min}^{\\alpha} \\int_{x_{\\min}}^{\\infty} x^{-\\alpha} dx$$\n我们对 $x^{-\\alpha}$ 进行积分：\n$$\\mu = \\alpha x_{\\min}^{\\alpha} \\left[ \\frac{x^{-\\alpha+1}}{-\\alpha+1} \\right]_{x_{\\min}}^{\\infty}$$\n上限需要计算 $\\lim_{x \\to \\infty} x^{1-\\alpha}$。由于我们假设了 $\\alpha > 1$，指数 $(1-\\alpha)$ 为负，所以这个极限是 $0$。\n$$\\mu = \\frac{\\alpha x_{\\min}^{\\alpha}}{1-\\alpha} \\left( 0 - x_{\\min}^{1-\\alpha} \\right) = \\frac{\\alpha x_{\\min}^{\\alpha}}{-(\\alpha-1)} (-x_{\\min}^{1-\\alpha})$$\n$$\\mu = \\frac{\\alpha}{\\alpha-1} x_{\\min}^{\\alpha} x_{\\min}^{1-\\alpha} = \\frac{\\alpha}{\\alpha-1} x_{\\min}^{\\alpha+1-\\alpha}$$\n这可以简化为均值的表达式：\n$$\\mu = \\frac{\\alpha}{\\alpha-1} x_{\\min}$$\n\n最后，我们求均值与中位数的比值 $\\mu/m$。\n$$\\frac{\\mu}{m} = \\frac{\\frac{\\alpha}{\\alpha-1} x_{\\min}}{x_{\\min} 2^{1/\\alpha}}$$\n参数 $x_{\\min}$ 被消去，得到最终只含 $\\alpha$ 的函数表达式：\n$$\\frac{\\mu}{m} = \\frac{\\alpha}{(\\alpha-1) 2^{1/\\alpha}}$$\n\n对于 $\\alpha > 1$，比值 $\\mu/m$ 总是大于 $1$，这证实了分布的右偏性，即均值被重右尾拉高到中位数之上。",
            "answer": "$$\\boxed{\\frac{\\alpha}{(\\alpha-1) 2^{1/\\alpha}}}$$"
        },
        {
            "introduction": "在对数-对数坐标图上呈现出一条直线，是幂律分布的经典标志，但正确地绘制这张图并非易事。这个练习  旨在解决一个常见且具有误导性的陷阱：朴素的直方图分箱。通过推导对数分箱的数学原理，你将理解为什么直接绘制原始计数是错误的，以及如何正确地对数据进行归一化，从而揭示真实的潜在缩放指数 $\\alpha$。",
            "id": "4297931",
            "problem": "考虑一个支撑集为 $[x_{\\min}, \\infty)$ 的正随机变量 $X$，其尾部服从指数为 $\\alpha>1$ 的连续幂律概率密度函数 $p(x)$，\n$$\np(x) = (\\alpha - 1)\\, x_{\\min}^{\\alpha - 1}\\, x^{-\\alpha}, \\quad x \\ge x_{\\min}.\n$$\n一位研究人员从 $X$ 中抽取 $n$ 个独立同分布的样本，并使用对数间隔的组元构建直方图。组元的边界为 $\\{b_i\\}_{i=0}^{K}$，满足 $b_0 = x_{\\min}$ 和 $b_{i+1} = r\\, b_i$，其中比率 $r>1$ 为固定值。令 $N_i$ 表示落入第 $i$ 个组元（即 $[b_i, b_{i+1})$）的样本数，令 $m_i$ 表示几何组元中点 $m_i = \\sqrt{b_i b_{i+1}}$。\n\n考虑以下两种对数-对数图：\n\n1. 一张原始计数 $N_i$ 相对于 $m_i$ 的朴素图。研究人员在该图的 $(\\ln m_i, \\ln N_i)$ 坐标下通过普通最小二乘法拟合一条直线，并得到斜率 $s_{\\mathrm{naive}}$。\n\n2. 一张校正图，通过用 $x$ 轴上的组元宽度 $\\Delta x_i = b_{i+1} - b_i$ 来重新缩放原始计数，从而估计概率密度，即 $\\hat{p}_i = \\frac{N_i}{n\\, \\Delta x_i}$。研究人员在 $(\\ln m_i, \\ln \\hat{p}_i)$ 坐标下拟合一条直线，并得到斜率 $s_{\\mathrm{corr}}$。\n\n从“期望组元计数等于 $n$ 乘以该组元内的概率质量”这一定义，以及“基于直方图的密度估计量定义为计数除以组元宽度”这一定义出发，推导在 $r$固定的情况下，$N_i$ 和 $\\hat{p}_i$ 对 $b_i$ 的期望依赖关系。利用这些标度关系来展示朴素斜率在对数-对数坐标轴上的偏差，以及在对数组元中通过密度重新缩放所提供的校正。将真实指数 $\\alpha$ 表示为 $s_{\\mathrm{naive}}$ 和 $s_{\\mathrm{corr}}$ 的闭式解析函数。\n\n您的最终答案必须是一个解析表达式。如果您提供两种关系式，请使用 LaTeX 的 $\\texttt{pmatrix}$ 环境将它们一起写成一个行矩阵。不需要进行数值近似。",
            "solution": "问题要求分析两种从分组数据中估计幂律概率密度函数 $p(x) = (\\alpha - 1) x_{\\min}^{\\alpha - 1} x^{-\\alpha}$（其中 $x \\ge x_{\\min}$）的指数 $\\alpha$ 的方法。我们将推导每种方法的期望标度行为，以找出测量斜率 $s_{\\mathrm{naive}}$ 和 $s_{\\mathrm{corr}}$ 与真实指数 $\\alpha$ 之间的关系。该分析将基于每个组元中计数的期望值，这忽略了有限样本的波动，并揭示了每种估计量的系统性质。\n\n令 $P_i$ 为单个样本 $X$ 落入第 $i$ 个组元 $[b_i, b_{i+1})$ 的概率，其中 $b_{i+1} = r b_i$ 且比率 $r > 1$ 为常数。该概率是概率密度函数 $p(x)$ 在该组元区间上的积分。\n令 $C = (\\alpha - 1) x_{\\min}^{\\alpha - 1}$ 为归一化常数。由于 $\\alpha > 1$，积分为：\n$$\nP_i = \\int_{b_i}^{b_{i+1}} p(x) \\, dx = C \\int_{b_i}^{r b_i} x^{-\\alpha} \\, dx\n$$\n$$\nP_i = C \\left[ \\frac{x^{1-\\alpha}}{1-\\alpha} \\right]_{b_i}^{r b_i} = \\frac{C}{1-\\alpha} \\left( (r b_i)^{1-\\alpha} - b_i^{1-\\alpha} \\right)\n$$\n代入 $C = (\\alpha - 1) x_{\\min}^{\\alpha - 1} = -(1-\\alpha) x_{\\min}^{\\alpha - 1}$：\n$$\nP_i = \\frac{-(1-\\alpha) x_{\\min}^{\\alpha - 1}}{1-\\alpha} b_i^{1-\\alpha} (r^{1-\\alpha} - 1) = -x_{\\min}^{\\alpha - 1} b_i^{1-\\alpha} (r^{1-\\alpha} - 1)\n$$\n$$\nP_i = x_{\\min}^{\\alpha - 1} (1 - r^{1-\\alpha}) b_i^{1-\\alpha}\n$$\n对于总共 $n$ 个独立样本，第 $i$ 个组元中的期望计数 $E[N_i]$ 是该概率的 $n$ 倍：\n$$\nE[N_i] = n P_i = n x_{\\min}^{\\alpha - 1} (1 - r^{1-\\alpha}) b_i^{1-\\alpha}\n$$\n\n**朴素方法的分析**\n\n朴素方法涉及原始计数 $N_i$ 相对于几何组元中点 $m_i = \\sqrt{b_i b_{i+1}}$ 的对数-对数图。我们分析 $\\ln E[N_i]$ 和 $\\ln m_i$ 之间的期望关系。\n首先，将 $m_i$ 用 $b_i$ 表示：\n$$\nm_i = \\sqrt{b_i (r b_i)} = \\sqrt{r} b_i\n$$\n取自然对数：\n$$\n\\ln m_i = \\ln(\\sqrt{r}) + \\ln b_i = \\frac{1}{2}\\ln r + \\ln b_i \\implies \\ln b_i = \\ln m_i - \\frac{1}{2}\\ln r\n$$\n现在，对期望计数 $E[N_i]$ 取自然对数：\n$$\n\\ln E[N_i] = \\ln\\left( n x_{\\min}^{\\alpha - 1} (1 - r^{1-\\alpha}) \\right) + (1-\\alpha) \\ln b_i\n$$\n对数中的项是一个常数。我们代入 $\\ln b_i$ 的表达式：\n$$\n\\ln E[N_i] = \\ln\\left( n x_{\\min}^{\\alpha - 1} (1 - r^{1-\\alpha}) \\right) + (1-\\alpha) \\left(\\ln m_i - \\frac{1}{2}\\ln r\\right)\n$$\n$$\n\\ln E[N_i] = (1-\\alpha) \\ln m_i + \\left[ \\ln\\left( n x_{\\min}^{\\alpha - 1} (1 - r^{1-\\alpha}) \\right) - \\frac{1-\\alpha}{2}\\ln r \\right]\n$$\n这是一个形如 $y = s x + c$ 的直线方程，其中 $y = \\ln E[N_i]$ 且 $x = \\ln m_i$。这条线的斜率 $s_{\\mathrm{naive}}$ 是 $\\ln m_i$ 的系数。\n$$\ns_{\\mathrm{naive}} = 1 - \\alpha\n$$\n这个结果显示了朴素方法中偏差的来源。计数 $N_i$ 不仅与密度 $p(x)$ 成正比，还与随 $x$ 增加而增加的组元宽度 $\\Delta x_i$ 成正比。这个不断增加的宽度为标度关系贡献了一个因子 $b_i^1$，将指数从 $-\\alpha$ 移位到 $1-\\alpha$。对 $\\alpha$ 求解，得到第一个所需的关系式：\n$$\n\\alpha = 1 - s_{\\mathrm{naive}}\n$$\n\n**校正方法的分析**\n\n校正方法通过用总样本数 $n$ 和组元宽度 $\\Delta x_i$ 对计数 $N_i$ 进行归一化来估计概率密度。组元宽度为：\n$$\n\\Delta x_i = b_{i+1} - b_i = r b_i - b_i = (r-1) b_i\n$$\n第 $i$ 个组元的密度估计量为 $\\hat{p}_i = \\frac{N_i}{n \\Delta x_i}$。其期望值为：\n$$\nE[\\hat{p}_i] = \\frac{E[N_i]}{n \\Delta x_i} = \\frac{n P_i}{n \\Delta x_i} = \\frac{P_i}{\\Delta x_i}\n$$\n代入 $P_i$ 和 $\\Delta x_i$ 的表达式：\n$$\nE[\\hat{p}_i] = \\frac{x_{\\min}^{\\alpha - 1} (1 - r^{1-\\alpha}) b_i^{1-\\alpha}}{(r-1) b_i} = \\left( \\frac{x_{\\min}^{\\alpha - 1} (1 - r^{1-\\alpha})}{r-1} \\right) b_i^{-\\alpha}\n$$\n这个校正后的量 $E[\\hat{p}_i]$ 现在与 $b_i^{-\\alpha}$ 成标度关系，正确地反映了底层概率密度函数的标度关系。\n为了找到 $\\hat{p}_i$ 相对于 $m_i$ 的对数-对数图上的斜率，我们对 $E[\\hat{p}_i]$ 取对数：\n$$\n\\ln E[\\hat{p}_i] = \\ln\\left( \\frac{x_{\\min}^{\\alpha - 1} (1 - r^{1-\\alpha})}{r-1} \\right) - \\alpha \\ln b_i\n$$\n再次代入 $\\ln b_i = \\ln m_i - \\frac{1}{2}\\ln r$：\n$$\n\\ln E[\\hat{p}_i] = \\ln\\left( \\frac{x_{\\min}^{\\alpha - 1} (1 - r^{1-\\alpha})}{r-1} \\right) - \\alpha \\left(\\ln m_i - \\frac{1}{2}\\ln r\\right)\n$$\n$$\n\\ln E[\\hat{p}_i] = -\\alpha \\ln m_i + \\left[ \\ln\\left( \\frac{x_{\\min}^{\\alpha - 1} (1 - r^{1-\\alpha})}{r-1} \\right) + \\frac{\\alpha}{2}\\ln r \\right]\n$$\n这同样是一个直线方程 $y=sx+c$，其中 $y = \\ln E[\\hat{p}_i]$ 且 $x = \\ln m_i$。斜率 $s_{\\mathrm{corr}}$ 是 $\\ln m_i$ 的系数。\n$$\ns_{\\mathrm{corr}} = -\\alpha\n$$\n这种方法消除了由变化的组元宽度引入的偏差。对 $\\alpha$ 求解，得到第二个所需的关系式：\n$$\n\\alpha = -s_{\\mathrm{corr}}\n$$\n\n总而言之，在对数-对数尺度上绘制原始计数相对于组元中心的图，所得到的斜率并不是幂律指数，而是由于对数组元的宽度线性增加而产生了 $+1$ 的偏移。用组元宽度对计数进行归一化可以校正这种人为效应，并且在对数-对数图上得到的斜率，在期望意义上，是负指数 $-\\alpha$ 的一个无偏估计量。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1 - s_{\\mathrm{naive}}  -s_{\\mathrm{corr}} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "一旦我们从视觉上识别出潜在的幂律关系，下一步就是对其指数 $\\alpha$ 进行严谨的定量估计。这个练习  将介绍完成此任务的黄金标准——最大似然估计（Maximum Likelihood Estimation, MLE）方法。你将从第一性原理出发，推导出最广泛使用的连续帕累托分布指数估计量，这是对任何重尾数据进行定量分析的基本工具。",
            "id": "4297975",
            "problem": "一位研究人员研究了通信网络中节点强度的重尾分布，并使用连续帕累托（I型）定律对上尾部进行建模。令 $x_{\\min} > 0$ 为一个已知的下截断值，并假设当 $x \\geq x_{\\min}$ 时，尾部由生存函数 $P(X \\geq x) = \\left(\\frac{x_{\\min}}{x}\\right)^{\\alpha}$ 描述，其中 $\\alpha > 0$ 是未知的尾部指数。该研究人员从该尾部分布中收集了一个独立同分布的样本 $\\{x_{i}\\}_{i=1}^{n}$，其中每个观测值都满足 $x_{i} \\geq x_{\\min}$。\n\n仅从生存函数的定义和最大似然估计原理出发，推导尾部指数 $\\alpha$ 的闭式最大似然估计量，并在标准正则性条件下确定此估计量的渐近方差。将您的最终结果表示为包含 $n$、$x_{\\min}$ 和样本 $\\{x_{i}\\}_{i=1}^{n}$ 的解析表达式。无需进行数值计算。如果您提供多个表达式，请将它们以矩阵形式列在同一行中。最终表达式中不应包含任何单位。",
            "solution": "### 最大似然估计量（MLE）的推导\n\n推导过程如下：首先从给定的生存函数求出概率密度函数（PDF），然后为样本构建对数似然函数，最后对该函数关于参数 $\\alpha$ 进行最大化。\n\n1.  **概率密度函数（PDF）：**\n    累积分布函数（CDF）为 $F(x) = P(X \\leq x) = 1 - P(X > x)$。由于分布是连续的，因此 $P(X>x) = P(X\\geq x)$。所以，对于 $x \\geq x_{\\min}$，CDF 为：\n    $$F(x; \\alpha) = 1 - S(x) = 1 - \\left(\\frac{x_{\\min}}{x}\\right)^{\\alpha}$$\n    PDF $p(x; \\alpha)$ 是 CDF 关于 $x$ 的导数：\n    $$p(x; \\alpha) = \\frac{d}{dx} F(x; \\alpha) = \\frac{d}{dx} \\left(1 - x_{\\min}^{\\alpha}x^{-\\alpha}\\right) = -x_{\\min}^{\\alpha} (-\\alpha) x^{-\\alpha-1}$$\n    这可以简化为帕累托I型分布的PDF：\n    $$p(x; \\alpha) = \\frac{\\alpha x_{\\min}^{\\alpha}}{x^{\\alpha+1}} \\quad \\text{for } x \\geq x_{\\min}$$\n\n2.  **似然函数与对数似然函数：**\n    给定一个独立同分布样本 $\\{x_{i}\\}_{i=1}^{n}$，似然函数 $L(\\alpha; \\{x_i\\})$ 是观测到该组数据的联合概率：\n    $$L(\\alpha; \\{x_i\\}) = \\prod_{i=1}^{n} p(x_i; \\alpha) = \\prod_{i=1}^{n} \\frac{\\alpha x_{\\min}^{\\alpha}}{x_i^{\\alpha+1}}$$\n    为了简化最大化过程，我们使用对数似然函数 $\\ell(\\alpha) = \\ln(L(\\alpha))$：\n    $$\\ell(\\alpha; \\{x_i\\}) = \\ln\\left( \\prod_{i=1}^{n} \\frac{\\alpha x_{\\min}^{\\alpha}}{x_i^{\\alpha+1}} \\right) = \\sum_{i=1}^{n} \\ln\\left( \\frac{\\alpha x_{\\min}^{\\alpha}}{x_i^{\\alpha+1}} \\right)$$\n    $$\\ell(\\alpha) = \\sum_{i=1}^{n} \\left[ \\ln(\\alpha) + \\alpha \\ln(x_{\\min}) - (\\alpha+1) \\ln(x_i) \\right]$$\n    $$\\ell(\\alpha) = n \\ln(\\alpha) + n\\alpha \\ln(x_{\\min}) - (\\alpha+1) \\sum_{i=1}^{n} \\ln(x_i)$$\n\n3.  **最大化：**\n    为了求得 MLE $\\hat{\\alpha}_{ML}$，我们将 $\\ell(\\alpha)$ 对 $\\alpha$ 求导，并令结果为零（一阶条件）：\n    $$\\frac{d\\ell}{d\\alpha} = \\frac{n}{\\alpha} + n \\ln(x_{\\min}) - \\sum_{i=1}^{n} \\ln(x_i) = 0$$\n    对 $\\alpha$ 求解得到估计量 $\\hat{\\alpha}_{ML}$：\n    $$\\frac{n}{\\hat{\\alpha}_{ML}} = \\sum_{i=1}^{n} \\ln(x_i) - n \\ln(x_{\\min}) = \\sum_{i=1}^{n} \\left( \\ln(x_i) - \\ln(x_{\\min}) \\right)$$\n    $$\\frac{n}{\\hat{\\alpha}_{ML}} = \\sum_{i=1}^{n} \\ln\\left(\\frac{x_i}{x_{\\min}}\\right)$$\n    因此，$\\alpha$ 的闭式 MLE 为：\n    $$\\hat{\\alpha}_{ML} = \\frac{n}{\\sum_{i=1}^{n} \\ln\\left(\\frac{x_i}{x_{\\min}}\\right)}$$\n    为确认这是一个最大值，我们检查二阶导数：\n    $$\\frac{d^2\\ell}{d\\alpha^2} = -\\frac{n}{\\alpha^2}$$\n    由于 $n>0$ 且 $\\alpha^2>0$，二阶导数恒为负，这确认了对数似然函数是凹函数，并且该驻点是一个全局最大值。\n\n### 渐近方差的推导\n\nMLE 的渐近方差由费雪信息量的逆给出。\n\n1.  **费雪信息量：**\n    样本大小为 $n$ 的费雪信息量 $I(\\alpha)$ 是单个观测值的费雪信息量 $I_1(\\alpha)$ 的 $n$ 倍。对于单参数情况，$I_1(\\alpha)$ 可以计算为：\n    $$I_1(\\alpha) = -E\\left[ \\frac{d^2}{d\\alpha^2} \\ln(p(x; \\alpha)) \\right]$$\n    根据我们前面的工作，单个观测值的对数PDF为 $\\ln(p(x; \\alpha)) = \\ln(\\alpha) + \\alpha \\ln(x_{\\min}) - (\\alpha+1) \\ln(x)$。\n    关于 $\\alpha$ 的二阶导数为：\n    $$\\frac{d^2}{d\\alpha^2} \\ln(p(x; \\alpha)) = \\frac{d}{d\\alpha} \\left(\\frac{1}{\\alpha} + \\ln(x_{\\min}) - \\ln(x)\\right) = -\\frac{1}{\\alpha^2}$$\n    由于该表达式不依赖于随机变量 $x$，其期望就是该表达式本身：\n    $$E\\left[ \\frac{d^2}{d\\alpha^2} \\ln(p(x; \\alpha)) \\right] = -\\frac{1}{\\alpha^2}$$\n    因此，单个观测值的费雪信息量为：\n    $$I_1(\\alpha) = - \\left(-\\frac{1}{\\alpha^2}\\right) = \\frac{1}{\\alpha^2}$$\n    样本大小为 $n$ 的总费雪信息量为：\n    $$I(\\alpha) = n I_1(\\alpha) = \\frac{n}{\\alpha^2}$$\n\n2.  **渐近方差：**\n    在标准正则性条件下，MLE $\\hat{\\alpha}_{ML}$ 是渐近正态分布的，其方差等于克拉默-拉奥下界，即费雪信息量的逆。\n    $$\\text{Var}(\\hat{\\alpha}_{ML}) \\approx [I(\\alpha)]^{-1} = \\frac{\\alpha^2}{n}$$\n    这是估计量的理论渐近方差，它依赖于真实的未知参数 $\\alpha$。问题要求最终结果用样本数据来表示。通过用 MLE $\\hat{\\alpha}_{ML}$ 替换真实参数 $\\alpha$，可以得到渐近方差的一个相合估计量：\n    $$\\widehat{\\text{Var}}(\\hat{\\alpha}_{ML}) = \\frac{\\hat{\\alpha}_{ML}^2}{n} = \\frac{1}{n} \\left( \\frac{n}{\\sum_{i=1}^{n} \\ln\\left(\\frac{x_i}{x_{\\min}}\\right)} \\right)^2 = \\frac{n}{\\left( \\sum_{i=1}^{n} \\ln\\left(\\frac{x_i}{x_{\\min}}\\right) \\right)^2}$$\n    该表达式提供了基于样本数据估计的渐近方差。\n\n所需的两个表达式是估计量 $\\hat{\\alpha}_{ML}$ 及其估计的渐近方差。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{n}{\\sum_{i=1}^{n} \\ln\\left(\\frac{x_i}{x_{\\min}}\\right)}  \\frac{n}{\\left(\\sum_{i=1}^{n} \\ln\\left(\\frac{x_i}{x_{\\min}}\\right)\\right)^2}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}