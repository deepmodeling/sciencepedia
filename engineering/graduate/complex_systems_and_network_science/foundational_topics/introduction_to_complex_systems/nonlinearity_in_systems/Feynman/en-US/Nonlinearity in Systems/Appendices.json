{
    "hands_on_practices": [
        {
            "introduction": "Many nonlinear systems, from mechanical switches to ecological populations, can be understood as relaxing to the minima of an effective potential energy landscape. This exercise explores a classic bistable potential, where nonlinearity creates two stable equilibrium states. By analyzing how this landscape tilts under an external force, you will derive the conditions for abrupt state transitions and explain the phenomenon of hysteresis, a fundamental form of system memory. ",
            "id": "4293615",
            "problem": "Consider a single-degree-of-freedom overdamped gradient system with state variable $x \\in \\mathbb{R}$ evolving slowly enough that it remains at (or adiabatically tracks) local minima of an effective potential. The intrinsic potential is $V(x)=\\frac{1}{4}x^{4}-\\frac{1}{2}a x^{2}$ with $a0$. A quasi-static external generalized force $F \\in \\mathbb{R}$ couples linearly to $x$, so that the effective potential is $U(x;F)=V(x)-F x$. In the quasi-static limit, equilibria are defined as stationary points of $U$, and local stability is defined by positive curvature of $U$.\n\nUsing only these principles, do the following:\n\n(a) Derive the equilibrium condition for $x$ as a function of $F$ by imposing the stationarity of $U(x;F)$ with respect to $x$. Do not solve the resulting polynomial explicitly; instead, express the implicit relation that $x$ must satisfy.\n\n(b) Determine the local stability criterion for an equilibrium in terms of $x$ and $a$ by examining the curvature of $U(x;F)$.\n\n(c) Identify the condition under which a stable and an unstable equilibrium coalesce and annihilate each other under variation of $F$ (a saddle-node event). Using this condition, derive analytically the magnitude of the critical forcing $F_{c}$ at which this disappearance occurs, in closed form in terms of $a$.\n\n(d) Explain, in words supported by the above derivations, how a slow cyclic sweep of $F$ from a large negative value to a large positive value and back generates a hysteresis loop when tracking $x$ versus $F$. Your explanation should connect the existence of multiple equilibria, their stability, and the saddle-node events.\n\nProvide, as your final answer, the exact analytic expression you obtain for the critical forcing magnitude $F_{c}$. No numerical approximation is required and no units are necessary.",
            "solution": "The effective potential for the system is given by $U(x;F) = V(x) - Fx$, where the intrinsic potential is $V(x) = \\frac{1}{4}x^{4} - \\frac{1}{2}ax^{2}$ with the parameter $a > 0$. Therefore, the effective potential is:\n$$\nU(x;F) = \\frac{1}{4}x^{4} - \\frac{1}{2}ax^{2} - Fx\n$$\n\n(a) The equilibrium condition is found by identifying the stationary points of the effective potential $U(x;F)$ with respect to the state variable $x$. This is achieved by setting the first derivative of $U$ with respect to $x$ equal to zero.\n$$\n\\frac{\\partial U}{\\partial x} = \\frac{\\partial}{\\partial x} \\left( \\frac{1}{4}x^{4} - \\frac{1}{2}ax^{2} - Fx \\right) = x^{3} - ax - F\n$$\nSetting this derivative to zero, $\\frac{\\partial U}{\\partial x} = 0$, yields the implicit relation that defines the equilibrium value(s) of $x$ for a given forcing $F$:\n$$\nx^{3} - ax - F = 0\n$$\nThis equation can be expressed as $F = x^{3} - ax$, which defines the equilibrium manifold in the $(x, F)$ plane.\n\n(b) The local stability of an equilibrium point is determined by the curvature of the potential at that point. A stable equilibrium corresponds to a local minimum of the potential, which requires the second derivative of $U(x;F)$ with respect to $x$ to be positive. We calculate this second derivative:\n$$\n\\frac{\\partial^{2} U}{\\partial x^{2}} = \\frac{\\partial}{\\partial x} (x^{3} - ax - F) = 3x^{2} - a\n$$\nFor an equilibrium to be locally stable, we must have $\\frac{\\partial^{2} U}{\\partial x^{2}} > 0$. This gives the stability criterion:\n$$\n3x^{2} - a > 0\n$$\nThis inequality can be solved for $x$ to determine the regions of stability:\n$$\nx^{2} > \\frac{a}{3} \\quad \\text{or equivalently} \\quad |x| > \\sqrt{\\frac{a}{3}}\n$$\nEquilibria are stable if they are located at positions $x$ that satisfy $|x| > \\sqrt{a/3}$. Conversely, equilibria are unstable if $|x|  \\sqrt{a/3}$, where the curvature is negative.\n\n(c) A saddle-node event occurs when a stable and an unstable equilibrium coalesce and annihilate each other. This happens at the margin of stability, precisely where the curvature of the potential is zero. This corresponds to the condition:\n$$\n\\frac{\\partial^{2} U}{\\partial x^{2}} = 3x^{2} - a = 0\n$$\nSolving for the critical positions $x_{c}$ where this occurs, we find:\n$$\nx_{c}^{2} = \\frac{a}{3} \\implies x_{c} = \\pm \\sqrt{\\frac{a}{3}}\n$$\nThese critical positions are the locations of the saddle-node bifurcations. To find the corresponding critical forcing values, we substitute these $x_{c}$ values back into the equilibrium condition from part (a), $F = x^{3} - ax$.\nFor the critical point $x_{c} = -\\sqrt{\\frac{a}{3}}$:\n$$\nF = \\left(-\\sqrt{\\frac{a}{3}}\\right)^{3} - a\\left(-\\sqrt{\\frac{a}{3}}\\right) = -\\left(\\frac{a}{3}\\right)\\sqrt{\\frac{a}{3}} + a\\sqrt{\\frac{a}{3}} = \\sqrt{\\frac{a}{3}}\\left(a - \\frac{a}{3}\\right) = \\sqrt{\\frac{a}{3}}\\left(\\frac{2a}{3}\\right) = \\frac{2a\\sqrt{a}}{3\\sqrt{3}}\n$$\nFor the critical point $x_{c} = +\\sqrt{\\frac{a}{3}}$:\n$$\nF = \\left(\\sqrt{\\frac{a}{3}}\\right)^{3} - a\\left(\\sqrt{\\frac{a}{3}}\\right) = \\left(\\frac{a}{3}\\right)\\sqrt{\\frac{a}{3}} - a\\sqrt{\\frac{a}{3}} = \\sqrt{\\frac{a}{3}}\\left(\\frac{a}{3} - a\\right) = \\sqrt{\\frac{a}{3}}\\left(-\\frac{2a}{3}\\right) = -\\frac{2a\\sqrt{a}}{3\\sqrt{3}}\n$$\nThe problem asks for the magnitude of the critical forcing, denoted $F_{c}$. This is the absolute value of the forces calculated above:\n$$\nF_{c} = \\left|\\pm\\frac{2a\\sqrt{a}}{3\\sqrt{3}}\\right| = \\frac{2a\\sqrt{a}}{3\\sqrt{3}}\n$$\n\n(d) The existence of multiple equilibria in a specific range of $F$ and their annihilation at critical points gives rise to hysteresis. In the range of forcing $|F|  F_{c}$, there are three equilibrium solutions for $x$: two are stable (outer branches where $|x| > \\sqrt{a/3}$) and one is unstable (middle branch where $|x|  \\sqrt{a/3}$). The system, by assumption, tracks a stable equilibrium (a local minimum of $U$).\n\nLet's trace a slow cyclic sweep of $F$:\n1.  Start at a large negative force, $F \\ll -F_{c}$. There is only one minimum of $U(x;F)$, located at a large negative $x$. The system state is on this lower stable branch.\n2.  Slowly increase $F$. The system state $x$ increases, following this lower stable branch. Even as $F$ enters the bistable region $(-F_{c}, F_{c})$, the system remains on this branch.\n3.  When $F$ reaches the critical value $+F_{c}$, the lower stable equilibrium (at $x_c = +\\sqrt{a/3}$) coalesces with the central unstable equilibrium and they both vanish.\n4.  With its local minimum gone, the system must undergo a catastrophic jump to the only remaining stable equilibrium, which is on the upper branch at a positive value of $x$.\n5.  Now, sweep $F$ back down from a large positive value. The system starts on the upper stable branch (large positive $x$).\n6.  As $F$ is decreased, the system tracks this upper branch, with $x$ decreasing.\n7.  When $F$ falls to the other critical value, $-F_{c}$, the upper stable equilibrium (at $x_c = -\\sqrt{a/3}$) coalesces with the unstable equilibrium and vanishes.\n8.  The system must then jump down to the only available stable state, which is on the lower branch at a negative $x$.\n\nThe path of $x$ as $F$ is increased is different from the path as $F$ is decreased. This state-dependence on the history of the control parameter $F$ is hysteresis. The plot of $x$ versus $F$ forms a loop, with upward and downward jumps occurring at two different force values, $+F_{c}$ and $-F_{c}$, which are the saddle-node bifurcation points.",
            "answer": "$$\\boxed{\\frac{2a\\sqrt{a}}{3\\sqrt{3}}}$$"
        },
        {
            "introduction": "Analyzing the intricate geometry of a chaotic attractor in continuous time can be daunting. The method of Poincaré sections provides a brilliant simplification, reducing the high-dimensional flow to a lower-dimensional discrete map. In this computational practice, you will implement this technique for the famous Rössler system, constructing a first-return map that reveals the elegant stretching-and-folding action at the heart of its chaotic dynamics. ",
            "id": "4293629",
            "problem": "You are given the three-dimensional Rössler dynamical system defined by the ordinary differential equation (ODE) system\n$$\n\\dot{x} = -y - z,\\quad \\dot{y} = x + a y,\\quad \\dot{z} = b + z(x - c),\n$$\nwhere $x$, $y$, and $z$ are state variables and $a$, $b$, and $c$ are parameters. A Poincaré section is constructed by considering the set of points on the plane $\\Sigma: x=0$ where the flow crosses in the direction $\\dot{x}  0$. The first-return map $f$ associated with the section maps each intersection value $z_n$ to the next intersection value $z_{n+1}$.\n\nStarting from the fundamental definitions of a deterministic continuous-time dynamical system and a Poincaré section, design a program that, for a given parameter triplet $(a,b,c)$, performs the following:\n- Numerically integrates the Rössler system using a fixed-step fourth-order Runge–Kutta method with step size $\\Delta t$ to approximate the flow $\\phi_t$.\n- Detects crossings of the Poincaré section $\\Sigma$ by identifying transitions where $x$ changes sign from negative to nonnegative and the direction condition $\\dot{x}0$ holds, and records the linearly interpolated intersection value $z$ at the crossing.\n- After discarding an initial transient of $N_{\\mathrm{discard}}$ intersections, constructs the first-return map by forming ordered pairs $(z_n,z_{n+1})$ from the next $N_{\\mathrm{map}}$ intersections.\n- Quantifies structural indicators of stretching and folding in the first-return map using:\n    1. The dynamic range $R = \\max(z_n) - \\min(z_n)$.\n    2. The maximum absolute slope $S_{\\max}$ computed from the sorted map via finite differences, that is,\n       $$S_i = \\frac{z_{n+1}^{(i+1)} - z_{n+1}^{(i)}}{z_n^{(i+1)} - z_n^{(i)}},\\quad S_{\\max} = \\max_i |S_i|,$$\n       where superscripts indicate the ordering by $z_n$.\n    3. The number of slope sign changes $\\sigma$, defined as the count of adjacent $S_i$ whose signs differ.\n    4. The number of diagonal crossings $\\kappa$, defined as the count of adjacent indices where $\\operatorname{sign}(z_{n+1}^{(i)} - z_n^{(i)})$ changes.\n- Declares that the first-return map reveals chaotic dynamics if and only if the following decision rule holds:\n    $$\\text{chaotic} \\iff \\left(R  10^{-3}\\right)\\ \\land\\ \\left(S_{\\max}  1.1\\right)\\ \\land\\ \\left(\\sigma \\ge 1\\right)\\ \\land\\ \\left(\\kappa \\ge 2\\right),$$\n  and otherwise declares non-chaotic.\n\nNumerical integration details and units:\n- Use $\\Delta t = 0.01$ and fixed-step fourth-order Runge–Kutta integration over a sufficiently long time to collect intersections. Time is dimensionless in this mathematical model.\n- Use linear interpolation between successive numerical states to estimate the intersection point on $\\Sigma$.\n- The initial condition must be $(x_0,y_0,z_0)=(1,1,1)$.\n- Use $N_{\\mathrm{discard}}=100$ and $N_{\\mathrm{map}}=300$.\n\nTest suite:\n- Case $1$: $a=0.2$, $b=0.2$, $c=5.7$ (canonical chaotic regime).\n- Case $2$: $a=0.2$, $b=0.2$, $c=4.0$ (periodic regime).\n- Case $3$: $a=0.2$, $b=0.2$, $c=4.5$ (near transition).\n\nEdge conditions and coverage requirements:\n- Ensure robustness by requiring at least $50$ first-return pairs; if fewer are obtained, return a non-chaotic decision for that case.\n- Handle near-grazing crossings where $x$ changes sign with very small increments by rejecting crossings when $|x_{n+1} - x_n|  10^{-12}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the boolean results for the three test cases as a comma-separated list enclosed in square brackets (e.g., \"[True,False,True]\").",
            "solution": "The Rössler system is a continuous-time deterministic dynamical system governed by the ordinary differential equation (ODE) flow\n$$\n\\dot{\\mathbf{x}} = \\mathbf{F}(\\mathbf{x}),\\quad \\mathbf{x} = (x,y,z),\\quad \\mathbf{F}(x,y,z) = \\left(-y-z,\\ x+a y,\\ b+z(x-c)\\right).\n$$\nA Poincaré section reduces the dimensionality by considering intersections of trajectories with a codimension-one manifold (here, the plane $\\Sigma: x=0$) under a directional constraint (here $\\dot{x} > 0$). The first-return map $f$ maps an intersection coordinate $z_n$ to the next intersection $z_{n+1}$, yielding a one-dimensional discrete-time representation of the continuous flow restricted to the section. Chaotic dynamics in such systems are revealed in the first-return map through stretching and folding, which can be detected by slopes exceeding unity and non-monotonicity.\n\nPrinciple-based construction and algorithm:\n1. Foundational definitions:\n   - A deterministic ODE defines a flow $\\phi_t$ satisfying $\\frac{d}{dt}\\phi_t(\\mathbf{x}_0) = \\mathbf{F}(\\phi_t(\\mathbf{x}_0))$ with initial condition $\\phi_0(\\mathbf{x}_0) = \\mathbf{x}_0$.\n   - A Poincaré section with plane $\\Sigma: x=0$ records the sequence of states $\\{\\mathbf{x}(t_n)\\}$ such that $x(t_n) = 0$ and $\\dot{x}(t_n) > 0$, producing intersection coordinates $\\{z_n\\}$.\n   - The first-return map $f$ is built from successive intersections: $f(z_n) = z_{n+1}$, justified by the recurrence induced by the continuous flow and the section.\n\n2. Numerical integration:\n   - Use fixed-step fourth-order Runge–Kutta (RK4), a well-tested method that approximates the flow by\n     $$\n     \\begin{aligned}\n     \\mathbf{k}_1 = \\mathbf{F}(\\mathbf{x}_n),\\\\\n     \\mathbf{k}_2 = \\mathbf{F}(\\mathbf{x}_n + \\tfrac{\\Delta t}{2}\\mathbf{k}_1),\\\\\n     \\mathbf{k}_3 = \\mathbf{F}(\\mathbf{x}_n + \\tfrac{\\Delta t}{2}\\mathbf{k}_2),\\\\\n     \\mathbf{k}_4 = \\mathbf{F}(\\mathbf{x}_n + \\Delta t\\,\\mathbf{k}_3),\\\\\n     \\mathbf{x}_{n+1} = \\mathbf{x}_n + \\tfrac{\\Delta t}{6}\\left(\\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4\\right).\n     \\end{aligned}\n     $$\n   - The step size $\\Delta t$ is set to $\\Delta t = 0.01$, and integration continues until a sufficient number of section crossings are collected.\n\n3. Poincaré section detection:\n   - A crossing with correct direction is detected when $x_n  0$, $x_{n+1} \\ge 0$, and the directional constraint $\\dot{x} = -y - z > 0$ is satisfied (evaluated at the post-step state for simplicity).\n   - The intersection on $\\Sigma$ is approximated by linear interpolation between successive states:\n     $$\n     \\alpha = \\frac{-x_n}{x_{n+1} - x_n},\\quad z_\\text{cross} = z_n + \\alpha (z_{n+1} - z_n),\n     $$\n     with an analogous expression for $y$ if needed. Reject crossings with $|x_{n+1} - x_n|  10^{-12}$ to avoid numerical artifacts.\n\n4. First-return map construction:\n   - Discard the first $N_{\\mathrm{discard}} = 100$ intersections to eliminate transients.\n   - Use the next $N_{\\mathrm{map}} = 300$ intersections to form ordered pairs $(z_n, z_{n+1})$.\n\n5. Indicators of stretching and folding:\n   - Sort the pairs by $z_n$ to parameterize the map along its domain. Let $\\{(z_n^{(i)}, z_{n+1}^{(i)})\\}_{i=1}^M$ denote the sorted sequence, where $M = N_{\\mathrm{map}} - 1$.\n   - Compute finite-difference slopes\n     $$\n     S_i = \\frac{z_{n+1}^{(i+1)} - z_{n+1}^{(i)}}{z_n^{(i+1)} - z_n^{(i)}},\n     $$\n     skipping indices with $|z_n^{(i+1)} - z_n^{(i)}|$ below a small tolerance to avoid division by zero.\n   - The maximum absolute slope $S_{\\max} = \\max_i |S_i|$ indicates local stretching; $S_{\\max} > 1$ is a classical indicator that the map amplifies nearby distances.\n   - The number of slope sign changes\n     $$\n     \\sigma = \\#\\left\\{i : \\operatorname{sign}(S_i) \\ne \\operatorname{sign}(S_{i+1})\\right\\}\n     $$\n     indicates folding (non-monotonicity).\n   - The number of diagonal crossings\n     $$\n     \\kappa = \\#\\left\\{i : \\operatorname{sign}(z_{n+1}^{(i)} - z_n^{(i)}) \\ne \\operatorname{sign}(z_{n+1}^{(i+1)} - z_n^{(i+1)})\\right\\}\n     $$\n     captures how often the map crosses the identity line $z_{n+1} = z_n$, a proxy for multiple fixed points and complex return dynamics.\n   - The dynamic range $R = \\max(z_n) - \\min(z_n)$ ensures that trivial near-constant maps (typical of a simple limit cycle) are not misclassified due to numerical noise.\n\n6. Decision rule and justification:\n   - Declare chaos when $R > 10^{-3}$, $S_{\\max} > 1.1$, $\\sigma \\ge 1$, and $\\kappa \\ge 2$. This rule embodies the core qualitative features of chaotic one-dimensional maps derived from Poincaré sections: sufficient spread (nontrivial dynamics), stretching beyond unity (sensitive dependence), and folding with repeated identity crossings (complex recurrence).\n   - For the canonical parameters $a=0.2$, $b=0.2$, $c=5.7$, the Rössler system is known empirically to exhibit chaos; the first-return map is typically unimodal with a steep slope exceeding unity and clear folding, satisfying the decision rule.\n   - For $a=0.2$, $b=0.2$, $c=4.0$, the system settles into a periodic orbit; the section intersections collapse near a single value, yielding small $R$ and slopes near zero or ill-defined but filtered, thus failing the decision rule.\n   - For $a=0.2$, $b=0.2$, $c=4.5$, behavior is near a transition; the indicators quantify whether stretching and folding are already strong enough.\n\n7. Output:\n   - The program applies the above procedure to the three specified parameter sets and prints a single line with the boolean decisions in the format \"[True,False,True]\". The underlying computations adhere to the principle-based detection rooted in the structure of the Poincaré first-return map and do not rely on shortcut formulas.\n\nThis approach integrates mechanistic definitions from dynamical systems theory with a numerically stable algorithm and quantifiable criteria, enabling reproducible detection of chaotic dynamics using the first-return map of the Poincaré section.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef rossler_deriv(state, a, b, c):\n    \"\"\"Compute the Rössler derivatives at a given state.\"\"\"\n    x, y, z = state\n    dx = -y - z\n    dy = x + a * y\n    dz = b + z * (x - c)\n    return np.array([dx, dy, dz], dtype=float)\n\ndef rk4_step(state, dt, a, b, c):\n    \"\"\"Perform one fixed-step RK4 update for the Rössler system.\"\"\"\n    k1 = rossler_deriv(state, a, b, c)\n    k2 = rossler_deriv(state + 0.5 * dt * k1, a, b, c)\n    k3 = rossler_deriv(state + 0.5 * dt * k2, a, b, c)\n    k4 = rossler_deriv(state + dt * k3, a, b, c)\n    return state + (dt / 6.0) * (k1 + 2*k2 + 2*k3 + k4)\n\ndef simulate_intersections(a, b, c, dt=0.01, max_steps=250000, discard=100, need_after_discard=300):\n    \"\"\"\n    Simulate the Rössler system and collect z-values at intersections\n    with the Poincaré section x=0, crossing with increasing x (dx/dt  0).\n    Uses linear interpolation between successive RK4 states.\n    \"\"\"\n    state = np.array([1.0, 1.0, 1.0], dtype=float)  # initial condition\n    x_prev, y_prev, z_prev = state\n    intersections = []\n\n    # Warm-up few steps to move away from initial condition if needed\n    for _ in range(100):\n        state = rk4_step(state, dt, a, b, c)\n    x_prev, y_prev, z_prev = state\n\n    for _ in range(max_steps):\n        state_next = rk4_step(state, dt, a, b, c)\n        x_next, y_next, z_next = state_next\n\n        # Directional condition: crossing from x0 to x=0 and dx/dt  0\n        # Reject extremely small denominators to avoid numerical artifacts.\n        denom = x_next - x_prev\n        if x_prev  0.0 and x_next = 0.0 and abs(denom)  1e-12:\n            dx_next = -y_next - z_next\n            if dx_next  0.0:\n                # Linear interpolation to find intersection on x=0\n                alpha = -x_prev / denom\n                # Interpolate z at crossing\n                z_cross = z_prev + alpha * (z_next - z_prev)\n                intersections.append(z_cross)\n\n        # Advance\n        state = state_next\n        x_prev, y_prev, z_prev = state\n\n        # Early exit if enough intersections collected\n        if len(intersections) = discard + need_after_discard + 5:\n            # Collect a few extra beyond need_after_discard for robust pairing\n            break\n\n    # If not enough intersections collected, return empty list\n    if len(intersections)  discard + need_after_discard:\n        return []\n\n    # Discard transients and keep needed intersections\n    return intersections[discard:discard + need_after_discard]\n\ndef analyze_first_return(z_list):\n    \"\"\"\n    Analyze first-return map pairs (z_n, z_{n+1}) and compute chaos indicators:\n    dynamic range R, maximum absolute slope S_max, slope sign changes sigma,\n    diagonal crossings kappa. Apply decision rule to return boolean.\n    \"\"\"\n    if len(z_list)  2:\n        return False\n\n    z = np.array(z_list, dtype=float)\n    R = float(np.max(z) - np.min(z))\n\n    # Form pairs (z_n, z_{n+1})\n    z_n = z[:-1]\n    z_np1 = z[1:]\n    M = len(z_n)\n    if M  50:\n        return False  # Not enough data for robust analysis\n\n    # Sort by z_n to parameterize the map\n    order = np.argsort(z_n)\n    z_sorted = z_n[order]\n    znext_sorted = z_np1[order]\n\n    # Compute finite-difference slopes, skipping near-zero delta z\n    slopes = []\n    for i in range(M - 1):\n        dz = z_sorted[i + 1] - z_sorted[i]\n        if abs(dz)  1e-10:\n            continue\n        s = (znext_sorted[i + 1] - znext_sorted[i]) / dz\n        slopes.append(s)\n    if len(slopes) == 0:\n        S_max = 0.0\n        slope_sign_changes = 0\n    else:\n        slopes = np.array(slopes, dtype=float)\n        S_max = float(np.max(np.abs(slopes)))\n        # Compute slope sign changes (ignore zeros by using sign of nonzero values)\n        signs = np.sign(slopes)\n        # Filter out zeros by keeping nonzero signs\n        nz = signs[signs != 0.0]\n        if len(nz)  2:\n            slope_sign_changes = 0\n        else:\n            slope_sign_changes = int(np.sum(nz[1:] * nz[:-1]  0.0))\n\n    # Compute diagonal crossings: sign changes of (z_next - z) along sorted map\n    d = znext_sorted - z_sorted\n    d_sign = np.sign(d)\n    # Remove zeros for robust count\n    d_nz = d_sign[d_sign != 0.0]\n    if len(d_nz)  2:\n        kappa = 0\n    else:\n        kappa = int(np.sum(d_nz[1:] * d_nz[:-1]  0.0))\n\n    # Decision rule\n    chaotic = (R  1e-3) and (S_max  1.1) and (slope_sign_changes = 1) and (kappa = 2)\n    return chaotic\n\ndef solve():\n    # Define the test cases from the problem statement: (a, b, c)\n    test_cases = [\n        (0.2, 0.2, 5.7),  # canonical chaotic\n        (0.2, 0.2, 4.0),  # periodic regime\n        (0.2, 0.2, 4.5),  # near transition\n    ]\n\n    dt = 0.01\n    max_steps = 250000\n    discard = 100\n    need_after_discard = 300\n\n    results = []\n    for a, b, c in test_cases:\n        z_intersections = simulate_intersections(\n            a=a, b=b, c=c,\n            dt=dt, max_steps=max_steps,\n            discard=discard, need_after_discard=need_after_discard\n        )\n        result = analyze_first_return(z_intersections)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "While Poincaré maps provide a powerful visual intuition for chaos, a quantitative diagnosis requires a more rigorous metric. This is the role of the Largest Lyapunov Exponent ($LLE$), which measures the average exponential rate at which nearby trajectories separate. In this exercise, you will derive the formula for the $LLE$ from its fundamental definition and then write a program to estimate it for the logistic map, providing a definitive tool to distinguish between predictable periodic behavior and sensitive dependence on initial conditions. ",
            "id": "4293679",
            "problem": "Consider the one-dimensional iterative map defined by $x_{n+1} = T(x_n)$ on the interval $[0,1]$, where $T$ is continuously differentiable. The largest Lyapunov exponent (LLE) quantifies the average exponential rate of separation of nearby trajectories and is defined fundamentally by the long-time limit\n$$\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\frac{|\\delta x_n|}{|\\delta x_0|},$$\nwhere $\\delta x_n$ is the infinitesimal separation between two trajectories after $n$ iterations, evolved under the linearization induced by $T$.\n\nYour tasks are:\n\n1) Starting from the fundamental definition above and the chain rule for compositions of differentiable functions, derive an expression for the largest Lyapunov exponent of a one-dimensional differentiable map in terms of the long-time average of the logarithm of the absolute value of the derivative of $T$ evaluated along a typical trajectory. State clearly all assumptions you use to justify the derivation.\n\n2) Specialize your result to the logistic map $T(x) = r x (1 - x)$ with parameter $r \\in (0,4]$. Provide the explicit expression for the per-iterate contribution to the finite-time estimator of the largest Lyapunov exponent for this map, expressed as a function of $r$ and the current state $x_n$.\n\n3) Implement a program to estimate the largest Lyapunov exponent numerically using the finite-time estimator\n$$\\hat{\\lambda}_{N,M}(x_0) = \\frac{1}{N} \\sum_{n=1}^{N} \\ln \\left| T'(x_{M+n-1}) \\right|,$$\nwhere $M$ is a burn-in (transient) length, $N$ is the number of averaged iterates, $x_0$ is the initial condition, and $\\ln$ denotes the natural logarithm. Your implementation must be robust to the nonlinearity-induced singular events that can occur in the logistic map, such as encountering a point where $|T'(x)| = 0$ or rounding into the endpoints of the interval:\n- Before evaluating any logarithm at iteration index $n$, if $|1 - 2 x_{M+n-1}|  \\varepsilon_{\\text{crit}}$ or $x_{M+n-1} \\notin [0,1]$ or $x_{M+n-1}$ lies within $\\varepsilon_{\\text{end}}$ of either endpoint, replace $x_{M+n-1}$ by $x_{M+n-1} + \\operatorname{sign}(0.5 - x_{M+n-1}) \\, \\varepsilon_{\\text{jit}}$ and then clamp it into the closed interval $[\\varepsilon_{\\text{end}}, 1 - \\varepsilon_{\\text{end}}]$.\n- Use $\\varepsilon_{\\text{crit}} = 10^{-14}$, $\\varepsilon_{\\text{jit}} = 10^{-12}$, and $\\varepsilon_{\\text{end}} = 10^{-15}$.\n- After each map iteration $x \\mapsto T(x)$, clamp the result into $[\\varepsilon_{\\text{end}}, 1 - \\varepsilon_{\\text{end}}]$ to avoid spurious rounding into the endpoints.\n\n4) Use your program to evaluate the estimator for the following test suite. For each case, report a single floating-point value equal to $\\hat{\\lambda}_{N,M}(x_0)$ rounded to $6$ decimal places:\n- Case A (fully developed chaos, typical initial condition): $r = 4.0$, $x_0 = 0.123456789$, $M = 1000$, $N = 200000$.\n- Case B (critical point initial condition requiring regularization): $r = 4.0$, $x_0 = 0.5$, $M = 1000$, $N = 200000$.\n- Case C (periodic window): $r = 3.2$, $x_0 = 0.1$, $M = 1000$, $N = 200000$.\n- Case D (onset of chaos near the Feigenbaum point): $r = 3.569945672$, $x_0 = 0.1$, $M = 2000$, $N = 200000$.\n- Case E (chaotic banded attractor): $r = 3.75$, $x_0 = 0.1$, $M = 1000$, $N = 200000$.\n\nInterpret a positive value of the estimated largest Lyapunov exponent as an indicator of sensitive dependence on initial conditions (chaos) and a negative value as an indicator of asymptotic periodicity. You do not need to output this interpretation; it guides your understanding.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each value rounded to $6$ decimal places, in the order [Case A, Case B, Case C, Case D, Case E]. For example, a valid output line has the form \"[0.693147,0.693147,-0.000001,0.000000,0.500000]\". Do not print any other text.",
            "solution": "The user's request is to derive an expression for the largest Lyapunov exponent (LLE) of a one-dimensional map, specialize it to the logistic map, and implement a numerical estimator to calculate it for several test cases.\n\n### Task 1: Derivation of the Lyapunov Exponent Expression\n\nThe largest Lyapunov exponent, $\\lambda$, quantifies the average rate of exponential separation of infinitesimally close trajectories. For a one-dimensional map $x_{n+1} = T(x_n)$, the fundamental definition is given as:\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\frac{|\\delta x_n|}{|\\delta x_0|}\n$$\nHere, $\\delta x_0$ is the initial infinitesimal separation between two starting points, $x_0$ and $x_0' = x_0 + \\delta x_0$. The separation after $n$ iterations is $\\delta x_n = x_n' - x_n$, where $x_n = T^n(x_0)$ and $x_n' = T^n(x_0')$.\n\nWe proceed with the derivation step-by-step.\nLet the two trajectories be initialized at $x_0$ and $x_0' = x_0 + \\delta x_0$.\nAfter one iteration, their states are $x_1 = T(x_0)$ and $x_1' = T(x_0 + \\delta x_0)$.\nThe separation becomes $\\delta x_1 = x_1' - x_1 = T(x_0 + \\delta x_0) - T(x_0)$.\nSince the initial separation $\\delta x_0$ is infinitesimal and the map $T$ is assumed to be continuously differentiable, we can use a first-order Taylor series expansion for $T(x_0 + \\delta x_0)$ around $x_0$:\n$$\nT(x_0 + \\delta x_0) \\approx T(x_0) + T'(x_0) \\delta x_0\n$$\nwhere $T'(x_0)$ is the derivative of $T$ evaluated at $x_0$.\nSubstituting this into the expression for $\\delta x_1$ yields:\n$$\n\\delta x_1 \\approx (T(x_0) + T'(x_0) \\delta x_0) - T(x_0) = T'(x_0) \\delta x_0\n$$\nThis shows that the initial separation $\\delta x_0$ is stretched or contracted by a factor of $|T'(x_0)|$ after one iteration.\n\nNow, we consider the evolution of the separation over $n$ iterations. After the second iteration, the separation is $\\delta x_2 \\approx T'(x_1) \\delta x_1$. Substituting the expression for $\\delta x_1$, we get:\n$$\n\\delta x_2 \\approx T'(x_1) \\left( T'(x_0) \\delta x_0 \\right) = T'(x_1) T'(x_0) \\delta x_0\n$$\nBy induction, after $n$ iterations, the separation $\\delta x_n$ is related to the initial separation $\\delta x_0$ by:\n$$\n\\delta x_n \\approx \\left( \\prod_{k=0}^{n-1} T'(x_k) \\right) \\delta x_0\n$$\nwhere $x_k = T^k(x_0)$ is the state of the primary trajectory at iteration $k$. The product term is precisely the derivative of the $n$-th iterate of the map, $T^n(x_0)$, by the chain rule: $(T^n)'(x_0) = T'(x_{n-1}) \\cdots T'(x_1) T'(x_0)$.\n\nWe substitute this result into the definition of $\\lambda$:\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\frac{|\\left( \\prod_{k=0}^{n-1} T'(x_k) \\right) \\delta x_0|}{|\\delta x_0|}\n$$\nThe term $|\\delta x_0|$ cancels out:\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\left| \\prod_{k=0}^{n-1} T'(x_k) \\right|\n$$\nUsing the property of logarithms that $\\ln(\\prod a_i) = \\sum \\ln(a_i)$, we arrive at the final expression:\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\sum_{k=0}^{n-1} \\ln |T'(x_k)|\n$$\nThis expression represents the largest Lyapunov exponent as the long-time average of the logarithm of the absolute value of the map's derivative, evaluated along a trajectory.\n\nThe derivation relies on the following key assumptions:\n1.  **Differentiability**: The map $T(x)$ must be at least continuously differentiable ($C^1$) on its domain, allowing for the use of Taylor series expansion and the chain rule.\n2.  **Infinitesimal Separation**: The entire derivation is based on the linearization of the map's dynamics, which is only valid for infinitesimally small separations. The Lyapunov exponent characterizes the growth rate of such infinitesimal perturbations.\n3.  **Ergodicity**: This is a critical assumption for the practical utility of the derived formula. We assume the system is ergodic on its attractor. This means that for almost all initial conditions $x_0$ within a basin of attraction, the time average along the resulting trajectory is equivalent to the spatial average over the attractor's natural invariant measure. Consequently, the limit exists and is independent of the specific choice of the typical initial condition $x_0$.\n\n### Task 2: Specialization to the Logistic Map\n\nThe logistic map is defined as $T(x) = r x (1 - x)$.\nTo apply the derived formula, we first need to compute its derivative, $T'(x)$:\n$$\nT'(x) = \\frac{d}{dx} \\left( rx - rx^2 \\right) = r - 2rx = r(1-2x)\n$$\nThe per-iterate contribution to the finite-time estimator for the LLE at step $n$ is the term inside the summation, $\\ln|T'(x_n)|$. For the logistic map, this term is explicitely:\n$$\n\\ln|T'(x_n)| = \\ln|r(1-2x_n)|\n$$\n\n### Tasks 3  4: Numerical Estimation and Implementation\n\nThe problem provides a finite-time estimator for the LLE:\n$$\n\\hat{\\lambda}_{N,M}(x_0) = \\frac{1}{N} \\sum_{n=1}^{N} \\ln \\left| T'(x_{M+n-1}) \\right|\n$$\nHere, $M$ is the number of \"burn-in\" iterations to let the trajectory settle onto the attractor, and $N$ is the number of subsequent iterations over which the average is computed.\n\nThe numerical implementation follows a precise algorithm to ensure robustness, particularly against singularities. The logistic map's derivative $T'(x) = r(1-2x)$ becomes zero at the critical point $x=0.5$, which would cause the logarithm to diverge to $-\\infty$. The endpoints $x=0$ and $x=1$ can also be problematic.\n\nThe implemented algorithm proceeds as follows:\n1.  Initialize the state $x$ with the initial condition $x_0$.\n2.  Perform the burn-in phase: Iterate the map $M$ times. In each iteration, update the state $x \\leftarrow r x (1 - x)$ and then clamp the result into the interval $[\\varepsilon_{\\text{end}}, 1 - \\varepsilon_{\\text{end}}]$ to prevent the state from landing exactly on the endpoints due to floating-point rounding.\n3.  Initialize an accumulator, `lyapunov_sum`, to $0.0$.\n4.  Perform the averaging phase for $N$ iterations:\n    a. Let the current state be $x_{current}$. Before using it, check for numerical instability. A state is deemed unstable if it is too close to the critical point $0.5$ (i.e., $|1 - 2x_{current}|  \\varepsilon_{\\text{crit}}$) or if it is at or too close to the interval endpoints.\n    b. If the state is unstable, it is perturbed (replaced) by adding a small jitter $\\pm\\varepsilon_{\\text{jit}}$. The sign of the jitter is chosen to push the state away from the center of the interval. The perturbed state is then clamped into $[\\varepsilon_{\\text{end}}, 1 - \\varepsilon_{\\text{end}}]$. This new, safe state replaces the old one for all subsequent calculations in the current step.\n    c. Calculate the derivative term $\\ln|r(1-2x)|$ using the (potentially perturbed) state and add it to `lyapunov_sum`.\n    d. Iterate the map for the next step, $x \\leftarrow r x (1 - x)$, using the (potentially perturbed) state as input.\n    e. Clamp the result of the map iteration into $[\\varepsilon_{\\text{end}}, 1 - \\varepsilon_{\\text{end}}]$.\n5. After the loop, the LLE estimate is calculated as $\\hat{\\lambda} = \\text{lyapunov\\_sum} / N$.\n6. This procedure is applied to each of the five test cases specified, and the results are rounded to $6$ decimal places.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the largest Lyapunov exponent for the logistic map\n    for a suite of test cases and prints the results in the specified format.\n    \"\"\"\n    # Define constants for numerical stability from the problem statement.\n    EPS_CRIT = 1.0e-14\n    EPS_JIT = 1.0e-12\n    EPS_END = 1.0e-15\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (fully developed chaos)\n        {'r': 4.0, 'x0': 0.123456789, 'M': 1000, 'N': 200000},\n        # Case B (critical point initial condition)\n        {'r': 4.0, 'x0': 0.5, 'M': 1000, 'N': 200000},\n        # Case C (periodic window)\n        {'r': 3.2, 'x0': 0.1, 'M': 1000, 'N': 200000},\n        # Case D (onset of chaos)\n        {'r': 3.569945672, 'x0': 0.1, 'M': 2000, 'N': 200000},\n        # Case E (chaotic banded attractor)\n        {'r': 3.75, 'x0': 0.1, 'M': 1000, 'N': 200000},\n    ]\n\n    def calculate_lle(r, x0, M, N):\n        \"\"\"\n        Estimates the Largest Lyapunov Exponent (LLE) for the logistic map.\n\n        Args:\n            r (float): The parameter of the logistic map.\n            x0 (float): The initial condition.\n            M (int): The number of burn-in (transient) iterations.\n            N (int): The number of iterations for averaging.\n\n        Returns:\n            float: The estimated LLE.\n        \"\"\"\n        x = float(x0)\n\n        # Burn-in phase to allow the trajectory to settle on the attractor.\n        # After each map iteration, the state is clamped to avoid rounding\n        # into exact endpoints.\n        for _ in range(M):\n            x = r * x * (1.0 - x)\n            x = max(EPS_END, min(1.0 - EPS_END, x))\n\n        lyapunov_sum = 0.0\n\n        # Averaging phase to compute the LLE.\n        for _ in range(N):\n            # Check for singular or near-singular conditions before evaluation.\n            # This includes being too close to the critical point (x=0.5)\n            # or the interval endpoints.\n            if (abs(1.0 - 2.0 * x)  EPS_CRIT) or \\\n               (x = EPS_END) or (x = 1.0 - EPS_END):\n                \n                # Perturb the state to avoid singularity.\n                # The sign of the jitter is chosen to push the state away\n                # from the center (0.5).\n                sign_val = np.sign(0.5 - x)\n                if sign_val == 0.0:\n                    sign_val = 1.0  # Handle exact x=0.5 case by picking a direction.\n                \n                x += sign_val * EPS_JIT\n                \n                # Clamp the perturbed state back into the safe interval.\n                x = max(EPS_END, min(1.0 - EPS_END, x))\n\n            # Add the log of the absolute value of the derivative to the sum.\n            # This uses the (potentially perturbed) state x.\n            lyapunov_sum += np.log(abs(r * (1.0 - 2.0 * x)))\n\n            # Iterate the map for the next step using the (potentially perturbed) state.\n            x = r * x * (1.0 - x)\n            \n            # Clamp the result of the map iteration to stay within the safe interval.\n            x = max(EPS_END, min(1.0 - EPS_END, x))\n\n        # The LLE is the average of the logged values.\n        return lyapunov_sum / N\n\n    results = []\n    for case in test_cases:\n        lle = calculate_lle(case['r'], case['x0'], case['M'], case['N'])\n        # Format the result to 6 decimal places as a string.\n        results.append(f\"{lle:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}