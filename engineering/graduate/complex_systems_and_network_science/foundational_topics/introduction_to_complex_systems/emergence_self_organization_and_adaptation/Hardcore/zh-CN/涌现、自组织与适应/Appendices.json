{
    "hands_on_practices": [
        {
            "introduction": "同步现象，例如萤火虫的同步闪烁或音乐会后观众的同步鼓掌，是如何在没有中央指挥的情况下自发产生的？Kuramoto 模型是理解这种集体行为的关键理论工具，它优雅地描述了大量相互作用的振子如何自发地达到一致的节奏。 这项练习将引导您运用自洽平均场分析，推导出同步现象首次出现的临界耦合强度 $K_c$。通过这个推导，您将亲身体验如何应用统计物理方法来揭示集体自组织的数学基础。",
            "id": "4274111",
            "problem": "考虑一个由 $N$ 个相位振子组成的群体，其固有频率 $\\{\\omega_i\\}_{i=1}^{N}$ 从一个归一化的、单峰的、偶函数的概率密度函数 (PDF) $g(\\omega)$ 中独立抽取。该函数在 $\\omega=0$ 处连续，并满足 $\\int_{-\\infty}^{\\infty} g(\\omega)\\,d\\omega = 1$。根据 Kuramoto 模型，振子在全局正弦耦合下演化：\n$$\n\\frac{d\\theta_i}{dt} \\;=\\; \\omega_i \\;+\\; \\frac{K}{N} \\sum_{j=1}^{N} \\sin\\!\\big(\\theta_j - \\theta_i\\big),\n$$\n其中 $\\theta_i(t)\\in \\mathbb{R}$ 是振子 $i$ 的相位，$K\\ge 0$ 是均匀耦合强度。定义复序参量\n$$\nz(t) \\;=\\; r(t)\\,\\exp\\!\\big(i\\psi(t)\\big) \\;=\\; \\frac{1}{N} \\sum_{j=1}^{N} \\exp\\!\\big(i\\theta_j(t)\\big),\n$$\n其中相干性为 $r(t)\\in[0,1]$，平均相位为 $\\psi(t)\\in\\mathbb{R}$。在热力学极限 $N\\to\\infty$ 下，采用连续统描述，引入具有频率 $\\omega$ 的振子的相位密度 $f(\\theta,\\omega,t)$，它对每个 $\\omega$ 满足 $\\int_{0}^{2\\pi} f(\\theta,\\omega,t)\\,d\\theta = 1$，并服从与耦合产生的确定性速度场相关的连续性方程。\n\n运用自洽平均场分析，并从上述基本定义和定律出发，推导临界耦合强度 $K_c$ 的显式闭式解析表达式。在此临界点，$r=0$ 的非相干态失去稳定性，非零相干性 $r>0$ 首次连续出现。最终答案仅用 $g(0)$ 表示。无需进行数值近似或四舍五入，最终表达式中也不应包含物理单位。清晰陈述推导过程中对 $g(\\omega)$ 使用的任何正则性假设，并论证临界分析中涉及的任何极限过程的合理性。",
            "solution": "出发点是描述 $N$ 个振子群体的 Kuramoto 模型，由以下方程给出：\n$$\n\\frac{d\\theta_i}{dt} \\;=\\; \\omega_i \\;+\\; \\frac{K}{N} \\sum_{j=1}^{N} \\sin(\\theta_j - \\theta_i)\n$$\n复序参量 $z(t) = r(t)e^{i\\psi(t)}$ 定义为 $z(t) = \\frac{1}{N} \\sum_{j=1}^{N} e^{i\\theta_j(t)}$。我们可以用这个定义来重写正弦项。\n对 $j$ 的求和为 $\\sum_{j=1}^{N} \\sin(\\theta_j - \\theta_i) = \\sum_{j=1}^{N} \\text{Im}[e^{i(\\theta_j - \\theta_i)}] = \\text{Im}[e^{-i\\theta_i} \\sum_{j=1}^{N} e^{i\\theta_j}] = \\text{Im}[e^{-i\\theta_i} N z(t)]$。\n代入 $z(t) = r(t)e^{i\\psi(t)}$，这变为 $N \\cdot \\text{Im}[e^{-i\\theta_i} r(t)e^{i\\psi(t)}] = N r(t) \\sin(\\psi(t) - \\theta_i)$。\n因此，单个振子的运动方程等效地耦合到由 $r(t)$ 和 $\\psi(t)$ 代表的平均场：\n$$\n\\frac{d\\theta_i}{dt} \\;=\\; \\omega_i \\;+\\; K r(t) \\sin(\\psi(t) - \\theta_i)\n$$\n在热力学极限 $N\\to\\infty$下，我们用一个概率密度函数 $f(\\theta, \\omega, t)$ 来描述系统，它表示固有频率为 $\\omega$ 的振子在时间 $t$ 具有相位 $\\theta$ 的概率密度。任何频率为 $\\omega$ 的振子的动力学都由相同的平均场方程控制：\n$$\n\\frac{d\\theta}{dt} \\;=\\; v(\\theta, \\omega, t) \\;=\\; \\omega \\;+\\; K r(t) \\sin(\\psi(t) - \\theta)\n$$\n序参量现在由一个对所有频率和相位的积分给出：\n$$\nr(t)e^{i\\psi(t)} \\;=\\; \\int_{-\\infty}^{\\infty} g(\\omega) \\left[ \\int_{0}^{2\\pi} f(\\theta, \\omega, t) e^{i\\theta} d\\theta \\right] d\\omega\n$$\n我们寻找一个稳态解，其中相干性 $r$ 是常数，平均相位 $\\psi$ 以恒定频率 $\\Omega$ 旋转，即 $\\psi(t) = \\Omega t + \\psi_0$。由于系统的旋转对称性，我们可以通过定义一个新的相位变量 $\\phi = \\theta - \\psi(t)$ 来转换到共转参考系。在这个参考系中，平均相位为 0。不失一般性地，我们可以通过对所有 $\\omega_i$ 进行适当的平移，假设总平均频率为零。由于给定的频率分布 $g(\\omega)$ 是偶函数，其均值已经为零，这意味着对于稳态同步态，$\\Omega=0$。因此，我们可以设置 $\\psi(t)=0$ 并寻找一个不依赖于时间的解（静态解）。\n\n稳态速度场为 $v(\\theta, \\omega) = \\omega - K r \\sin(\\theta)$。相位密度 $f(\\theta, \\omega)$ 必须满足稳态连续性方程 $\\frac{\\partial}{\\partial \\theta}[f \\cdot v] = 0$。这意味着 $f(\\theta, \\omega) \\cdot (\\omega - Kr\\sin\\theta)$ 是一个关于 $\\theta$ 的常数。为了使密度在周期域 $[0, 2\\pi]$ 上可归一化，这个常数必须为零。这导致两种类型的解：\n1.  锁定振子：对于这些振子，$v(\\theta, \\omega) = 0$ 发生在一个稳定相位 $\\theta_s$。这要求 $|\\omega| \\le Kr$。稳定不动点是 $\\theta_s = \\arcsin(\\omega / (Kr))$。其密度是一个狄拉克δ函数：$f(\\theta, \\omega) = \\delta(\\theta - \\arcsin(\\omega/(Kr)))$。\n2.  漂移振子：对于这些振子，$|\\omega| > Kr$，速度 $\\omega - Kr\\sin\\theta$ 永远不会变为零。振子以非均匀速率在圆上漂移。它们的稳态分布是 $f(\\theta, \\omega) = \\frac{C}{\\omega - Kr\\sin\\theta}$，其中 $C$ 是由 $\\int_0^{2\\pi} f(\\theta, \\omega)d\\theta=1$ 确定的归一化常数。这给出 $f(\\theta, \\omega) = \\frac{\\sqrt{\\omega^2 - (Kr)^2}}{2\\pi(\\omega - Kr\\sin\\theta)}$。\n\n序参量 $r$ 的自洽方程可以通过将这些稳态分布代回到 $r$ 的定义中得到（其中 $\\psi=0$，因此 $z=r$ 是实数）：\n$$\nr \\;=\\; \\int_{-\\infty}^{\\infty} g(\\omega) \\left[ \\int_{0}^{2\\pi} f(\\theta, \\omega) \\cos\\theta \\, d\\theta \\right] d\\omega\n$$\n该积分分解为锁定子群（$|\\omega| \\le Kr$）和漂移子群（$|\\omega|>Kr$）的贡献。\n我们关心的是临界耦合强度 $K_c$，在该点非相干态（$r=0$）失去稳定性，而相干态（$r>0$）连续出现。这对应于分岔点，我们可以通过分析对于任意小的 $r>0$ 的自洽方程来找到它。\n\n对于 $r \\to 0^+$，锁定振子的区间 $[-Kr, Kr]$ 变得无穷小。\n锁定振子对序参量的贡献是：\n$$\nr_{\\text{locked}} = \\int_{-Kr}^{Kr} g(\\omega) \\left[ \\int_0^{2\\pi} \\delta\\left(\\theta - \\arcsin\\left(\\frac{\\omega}{Kr}\\right)\\right) \\cos\\theta \\, d\\theta \\right] d\\omega\n$$\n$$\nr_{\\text{locked}} = \\int_{-Kr}^{Kr} g(\\omega) \\cos\\left(\\arcsin\\left(\\frac{\\omega}{Kr}\\right)\\right) d\\omega = \\int_{-Kr}^{Kr} g(\\omega) \\sqrt{1 - \\left(\\frac{\\omega}{Kr}\\right)^2} \\, d\\omega\n$$\n可以证明，漂移振子的贡献是 $O(r^3)$ 或更高阶的，因此在分岔点附近与锁定振子的贡献相比可以忽略不计。我们做出标准假设，即当 $r \\to 0$ 时，这一贡献比 $r$ 更快地消失。\n\n分析 $r \\to 0^+$ 时锁定的贡献：积分范围 $[-Kr, Kr]$ 非常窄。由于 $g(\\omega)$ 在 $\\omega=0$ 处连续（给定条件），我们可以在此区间内近似 $g(\\omega) \\approx g(0)$。\n$$\nr \\approx g(0) \\int_{-Kr}^{Kr} \\sqrt{1 - \\left(\\frac{\\omega}{Kr}\\right)^2} \\, d\\omega\n$$\n我们进行变量替换：令 $u = \\omega / (Kr)$，则 $d\\omega = Kr \\, du$。积分上下限变为 $-1$ 和 $1$。\n$$\nr \\approx g(0) (Kr) \\int_{-1}^{1} \\sqrt{1 - u^2} \\, du\n$$\n积分 $\\int_{-1}^{1} \\sqrt{1 - u^2} \\, du$ 表示半径为 1 的半圆面积，即 $\\frac{1}{2}\\pi(1)^2 = \\frac{\\pi}{2}$。\n将此值代回：\n$$\nr \\approx g(0) (Kr) \\frac{\\pi}{2}\n$$\n这个方程有两个关于 $r$ 的解。一个是平凡的非相干解，$r=0$。如果我们可以用 $r$ 除方程两边，则存在一个非平凡解 $r>0$：\n$$\n1 \\approx \\frac{K \\pi g(0)}{2}\n$$\n这个关系必须在非零解首次出现的临界点 $K=K_c$ 处成立。因此，在分岔点我们有精确的等式：\n$$\n1 = \\frac{K_c \\pi g(0)}{2}\n$$\n求解临界耦合强度 $K_c$：\n$$\nK_c = \\frac{2}{\\pi g(0)}\n$$\n这个推导依赖于 $g(\\omega)$ 在 $\\omega=0$ 处连续的假设，这是已知的条件。$g(\\omega)$ 的偶函数性质确保了稳态不会漂移，从而简化了分析。单峰性是典型性质，但对于这个具体计算并非严格必需，只要该分布在原点处表现良好即可。",
            "answer": "$$\\boxed{\\frac{2}{\\pi g(0)}}$$"
        },
        {
            "introduction": "在生物学、经济学和社会科学中，个体策略的演化驱动着群体的适应。一个群体是如何在多种竞争策略中达到稳定的行为组合的？演化博弈论通过“演化稳定策略”（Evolutionarily Stable Strategy, ESS）这一核心概念为我们提供了答案。 本练习要求您从基本定义出发，利用复制子动态方程推导出混合策略ESS存在的条件。您将看到频率依赖性选择如何通过个体间的微观互动，涌现出宏观层面上的、能够抵御突变策略入侵的稳定适应状态。",
            "id": "4274006",
            "problem": "考虑一个无限大、充分混合的种群，该种群进行重复、随机的配对互动，此互动由一个对称的 $2\\times 2$ 博弈描述，其支付矩阵为 $A=\\begin{pmatrix}a & b\\\\ c & d\\end{pmatrix}$，其中 $a$、$b$、$c$ 和 $d$ 是实数参数。设种群状态为策略 $1$ 的频率 $x\\in[0,1]$（策略 $2$ 的频率则为 $1-x$）。假设适应过程通过演化博弈论中的复制动态进行，其中一个策略频率的增长率与其相对于种群平均支付的支付优势成正比。一个演化稳定策略（ESS）是一种种群构成 $x^{\\ast}$，使得当几乎所有个体都按照 $x^{\\ast}$ 行动时，任何足够小比例的突变者所获得的期望支付都严格较低。\n\n从期望支付和复制动态的定义出发，并且不使用任何现成的公式，完成以下任务：\n\n1. 推导每种策略的期望支付作为 $x$ 的函数，并写出决定 $x(t)$ 的一维复制动态方程。\n2. 证明混合ESS的内部候选点必须满足等支付条件，并求解内部不动点 $x^{\\ast}$ 的闭式解。\n3. 在复制动态下推导内部不动点的稳定性条件，并将其转化为关于 $(a,b,c,d)$ 的条件。将此条件与可行性要求 $x^{\\ast}\\in(0,1)$ 相结合，以获得存在混合ESS时 $(a,b,c,d)$ 需满足的充分必要条件。\n\n以 $a$、$b$、$c$ 和 $d$ 表示，将策略 $1$ 的混合策略概率 $x^{\\ast}$ 报告为单个闭式解析表达式。如果不存在混合ESS，您的推导过程应清楚地说明这一点，但您最终报告的表达式应为假设满足混合ESS可行性和稳定性条件下的闭式解 $x^{\\ast}$。不需要进行数值计算。请以精确形式（不进行四舍五入）表达您的最终答案。",
            "solution": "问题要求在复制动态下，为一个对称 $2 \\times 2$ 博弈推导演化稳定策略（ESS）的混合策略概率 $x^{\\ast}$。我们将首先推导复制动态方程，然后找到其内部不动点，最后建立该不动点对应于一个稳定的混合ESS的条件。\n\n设两种策略分别表示为 $1$ 和 $2$。种群的状态由采用策略 $1$ 的个体频率 $x \\in [0,1]$ 给出，因此采用策略 $2$ 的个体频率为 $1-x$。互动由对称支付矩阵 $A$ 决定，其中条目 $A_{ij}$ 是采用策略 $i$ 的参与者对抗采用策略 $j$ 的对手时获得的支付。\n$$\nA = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}\n$$\n\n**1. 期望支付与复制动态方程**\n\n首先，我们确定在一个状态为 $x$ 的种群中，采用每种纯策略的个体所获得的期望支付。一个采用策略 $1$ 的个体将以概率 $x$ 遇到另一个采用策略 $1$ 的参与者（获得支付 $a$），并以概率 $1-x$ 遇到一个采用策略 $2$ 的参与者（获得支付 $b$）。因此，策略 $1$ 的期望支付，记为 $E_1(x)$，是：\n$$\nE_1(x) = a \\cdot x + b \\cdot (1-x)\n$$\n类似地，策略 $2$ 的期望支付，记为 $E_2(x)$，是：\n$$\nE_2(x) = c \\cdot x + d \\cdot (1-x)\n$$\n整个种群的平均支付 $\\bar{E}(x)$ 是两种策略支付的加权平均值：\n$$\n\\bar{E}(x) = x E_1(x) + (1-x) E_2(x)\n$$\n问题陈述中提到，复制动态描述了频率 $x$ 的演化。一个策略频率的增长率与其相对于种群平均支付的支付优势成正比。对于策略 $1$，这可以写作：\n$$\n\\frac{dx}{dt} = kx(E_1(x) - \\bar{E}(x))\n$$\n其中 $k$ 是一个正常数比例因子，通过重新调整时间单位，我们可以将其设为 $1$。代入 $\\bar{E}(x)$ 的表达式：\n$$\n\\frac{dx}{dt} = x(E_1(x) - [x E_1(x) + (1-x) E_2(x)])\n$$\n$$\n\\frac{dx}{dt} = x(E_1(x)(1-x) - E_2(x)(1-x))\n$$\n$$\n\\frac{dx}{dt} = x(1-x)(E_1(x) - E_2(x))\n$$\n这是一维复制动态方程。为了完成其推导，我们代入 $E_1(x)$ 和 $E_2(x)$ 的表达式：\n$$\nE_1(x) - E_2(x) = (ax + b(1-x)) - (cx + d(1-x)) = (a-c)x - (d-b)(1-x) = (a-c)x - (d-b) + (d-b)x\n$$\n$$\nE_1(x) - E_2(x) = (a-c+d-b)x + (b-d)\n$$\n因此，决定频率 $x(t)$ 的复制动态方程是：\n$$\n\\frac{dx}{dt} = x(1-x)[(a-b-c+d)x + (b-d)]\n$$\n\n**2. 内部不动点与等支付条件**\n\n动态系统的不动点是种群状态 $x^{\\ast}$，在这些状态下 $\\frac{dx}{dt} = 0$。从上述方程可知，不动点可以出现在：\n- $x^{\\ast} = 0$（类型 $2$ 的纯策略种群）\n- $x^{\\ast} = 1$（类型 $1$ 的纯策略种群）\n- 一个内部不动点 $x^{\\ast} \\in (0,1)$，此时方括号中的项为零：$(a-b-c+d)x^{\\ast} + (b-d) = 0$。\n\n这最后一个条件等价于 $E_1(x^{\\ast}) - E_2(x^{\\ast}) = 0$，即 $E_1(x^{\\ast}) = E_2(x^{\\ast})$。这就是等支付条件。一个内部混合ESS候选点必须满足此条件。如果支付不相等，比如说 $E_1(x^{\\ast}) > E_2(x^{\\ast})$，那么在一个采用混合策略 $x^{\\ast}$ 的种群中，任何个体转换到纯策略 $1$ 都会获得更高的收益。该混合策略将不能抵抗个体偏离，而抵抗个体偏离是ESS的一个必要条件。因此，要使一个内部混合策略成为ESS的候选者，两种纯策略必须产生相同的期望支付。\n\n求解等支付条件以得到 $x^{\\ast}$：\n$$\n(a-b-c+d)x^{\\ast} = d-b\n$$\n假设 $a-b-c+d \\neq 0$，我们找到内部不动点：\n$$\nx^{\\ast} = \\frac{d-b}{a-b-c+d}\n$$\n\n**3. 稳定性与可行性条件**\n\n要使 $x^{\\ast}$ 成为一个稳定的混合ESS，必须满足两组条件：\n1.  **可行性**：$x^{\\ast}$ 必须是一个有效的概率，即 $0  x^{\\ast}  1$。\n2.  **稳定性**：不动点 $x^{\\ast}$ 必须是动态稳定的。对 $x^{\\ast}$ 的微小扰动应衰减并回到 $x^{\\ast}$。\n\n我们先来分析稳定性。对于动态系统 $\\frac{dx}{dt} = f(x)$，其不动点 $x^{\\ast}$ 是局部稳定的，如果 $f'(x^{\\ast})  0$。设 $f(x) = x(1-x)[(a-b-c+d)x + (b-d)]$。\n设 $g(x) = (a-b-c+d)x + (b-d)$。那么 $f(x) = x(1-x)g(x)$。\n其导数为 $f'(x) = (1-2x)g(x) + x(1-x)g'(x)$。\n在内部不动点 $x^{\\ast}$ 处，根据定义，$g(x^{\\ast})=0$。所以第一项消失：\n$$\nf'(x^{\\ast}) = x^{\\ast}(1-x^{\\ast})g'(x^{\\ast})\n$$\n$g(x)$ 的导数是 $g'(x) = a-b-c+d$。\n由于 $x^{\\ast} \\in (0,1)$，项 $x^{\\ast}(1-x^{\\ast})$ 严格为正。因此，$f'(x^{\\ast})$ 的符号由 $g'(x^{\\ast})$ 的符号决定。稳定性条件 $f'(x^{\\ast})  0$ 因而要求：\n$$\na-b-c+d  0\n$$\n这个条件也等价于静态ESS的第二个要求：在被入侵的种群中，均衡策略 $x^{\\ast}$ 对抗任何突变策略所获得的支付，要高于突变策略对抗自身所获得的支付。\n\n现在，我们将这个稳定性条件与可行性要求 $0  x^{\\ast}  1$ 结合起来。\n使用 $x^{\\ast} = \\frac{d-b}{a-b-c+d}$：\n\n-   **条件 $x^{\\ast} > 0$**：\n    我们有 $\\frac{d-b}{a-b-c+d} > 0$。由于稳定性条件要求分母 $(a-b-c+d)$ 为负，为了使分数为正，分子 $(d-b)$ 也必须为负。\n    $d-b  0 \\implies b > d$。\n\n-   **条件 $x^{\\ast}  1$**：\n    我们有 $\\frac{d-b}{a-b-c+d}  1$。由于分母为负，两边同乘以它会反转不等号：\n    $d-b > a-b-c+d$\n    $0 > a-c \\implies a  c$。\n\n总结来说，要存在一个稳定的混合ESS，支付必须满足 $a  c$ 和 $b > d$。这些是鹰鸽博弈（Hawk-Dove game）结构的条件，其中每种纯策略都是对另一种纯策略的最佳回应，这阻止了任何一种策略占据整个种群，从而导致稳定的共存。\n\n问题要求给出 $x^{\\ast}$ 的闭式表达式，我们已经推导出来了。该表达式在充分必要条件 $a  c$ 和 $b > d$ 下有效。\n\n在混合ESS中，策略 $1$ 的概率是：\n$$\nx^{\\ast} = \\frac{d-b}{a-b-c+d}\n$$",
            "answer": "$$\n\\boxed{\\frac{d-b}{a-b-c+d}}\n$$"
        },
        {
            "introduction": "我们经常在自然界和社會中觀察到各種模式，並稱之為“有組織的”，但我們如何確定這些模式並非僅僅源於隨機因素？在複雜網絡科學中，零模型（null model）提供了一個關鍵的統計基準，用以判斷觀測到的結構是否超越了純粹的隨機性。 這項計算實踐要求您實現一個嚴格的統計檢驗，以判斷網絡中的結構（例如高聚類特性）是否是自組織的結果。通過將觀測網絡的結構與其隨機化對應版本进行比較，您將學會如何科學地驗證一個模式是否是真正意義上的湧現秩序的標誌。",
            "id": "4274115",
            "problem": "您的任务是形式化并检验一种论断，即网络中观测到的宏观模式需要自组织才能形成，而非源于随机聚集。考虑一个无自环的无向简单图，由一个对称且对角线为零的邻接矩阵 $A \\in \\{0,1\\}^{n \\times n}$ 表示。节点由 $\\{0,1,\\dots,n-1\\}$ 索引，边是 $i \\neq j$ 的无序对 $\\{i,j\\}$。度序列为 $k_i = \\sum_{j=0}^{n-1} A_{ij}$。\n\n您的推导必须基于以下标准定义：\n- 三角形是由三个节点 $\\{i,j,\\ell\\}$ 组成的集合，且这三个节点之间的三条边全部存在。$A$ 中的三角形总数是 $T = \\frac{1}{6} \\mathrm{tr}(A^3)$。\n- 连通三元组（也称为楔形）是以一个节点为中心、长度为二的路径。对于节点 $i$，其数量为 $\\binom{k_i}{2}$。连通三元组的总数为 $W = \\sum_{i=0}^{n-1} \\binom{k_i}{2} = \\frac{1}{2} \\sum_{i=0}^{n-1} k_i (k_i - 1)$。\n- 全局聚类系数（也称为传递性）定义为 $C = \\frac{3T}{W}$，并约定如果 $W = 0$，则 $C = 0$。\n\n为检验观测到的宏观模式（此处为增高的聚类）是否需要自组织，需构建一个零模型，该模型仅匹配平凡的统计量，但缺乏相互作用机制。使用度保持随机边交换模型（也称为 Maslov–Sneppen 重连）从与观测网络具有相同度序列的简单图空间中均匀采样随机图。此零模型保持了度序列和边数，但通过重复交换随机选择的边对的端点来消除局部相互作用结构，同时禁止自环和重边。\n\n对于每个观测网络，通过从零模型中生成 $R$ 个独立样本来估计 $C$ 的经验零分布，并计算：\n- 经验 $p$ 值 $p = \\frac{1 + \\sum_{r=1}^R \\mathbf{1}\\{C^{(r)} \\ge C^{\\mathrm{obs}}\\}}{R + 1}$，其中 $C^{(r)}$ 是第 $r$ 个零样本的聚类系数，$C^{\\mathrm{obs}}$ 是观测到的聚类系数。\n- 标准化效应大小 $z = \\frac{C^{\\mathrm{obs}} - \\mu}{\\sigma}$，其中 $\\mu$ 和 $\\sigma$ 分别是 $C$ 的零分布的均值和标准差。如果 $\\sigma = 0$，则当 $C^{\\mathrm{obs}} > \\mu$ 时定义 $z = +\\infty$，否则定义 $z = -\\infty$。\n\n决策规则：当且仅当 $p  \\alpha$ 且 $z \\ge z_{\\mathrm{thr}}$ 时，判定该宏观模式需要自组织，其中 $\\alpha = 0.05$ 且 $z_{\\mathrm{thr}} = 2$。\n\n为观测网络实现以下生成过程（所有图均为无向、简单且无权的）：\n- 环状格点：对于参数 $(n,k)$（其中 $k$ 为偶数且 $k \\ll n$），将每个节点 $i$ 与其在环上两侧的 $k/2$ 个最近邻居相连，生成边 $(i,(i+d)\\bmod n)$，其中 $d = 1,2,\\dots,k/2$。\n- 度保持随机化：从具有相同 $(n,k)$ 的环状格点开始，执行重复的度保持边交换，以消除局部结构，同时保持度序列。\n- 偏好连接树：初始化时在两个节点间设置一条边。对每个新加入的节点，直到总节点数达到 $n$，将其连接到一个现有节点上，该节点的选择概率与其当前度成正比，从而生成一棵树（参数 $m=1$ 的 Barabási–Albert 模型）。\n- 带对角线的二维网格：对于参数 $(s_x,s_y)$，构建一个包含 $n = s_x s_y$ 个节点的矩形格点，节点之间有水平和垂直邻居的连边，并添加每个单元格的对角线边以创建三角形（例如，在有效的情况下，添加从 $(x,y)$ 到 $(x+1,y+1)$ 的边）。\n\n您的程序必须实现：\n- 对任何给定的 $A$ 进行 $T$、$W$ 和 $C$ 的精确计算。\n- 从观测到的 $A$ 开始，通过度保持边交换进行零模型采样。每个零样本使用 $S$ 次交换，其中 $S$ 与边数 $m$ 成正比（例如，$S = 10m$）。\n- 经验 $p$ 值和 $z$ 分数的计算以及上述指定的决策规则。\n\n测试套件。对于以下每个参数集，构建相应的观测网络，使用 $R = 64$ 个样本、$ \\alpha = 0.05$、$z_{\\mathrm{thr}} = 2$ 以及每个零样本 $S = 10m$ 次交换来运行零模型检验，并输出一个布尔值，指示是否需要自组织：\n- 情况 $1$（通过局部聚类自组织）：环状格点，参数为 $(n,k) = (60,4)$。\n- 情况 $2$（匹配度下的随机聚集）：对情况 $1$ 中的环状格点进行度保持随机化，使用 $S = 20m$ 次交换来生成观测网络。\n- 情况 $3$（无三元闭包的稀疏树）：偏好连接树，参数为 $n = 60$，$m = 1$。\n- 情况 $4$（局部聚类的平面结构）：带对角线的二维网格，参数为 $(s_x,s_y) = (7,7)$，因此 $n = 49$。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表，按情况 $1$ 到 $4$ 的顺序排列结果，例如 $[r_1,r_2,r_3,r_4]$，其中每个 $r_i$ 是根据决策规则计算出的布尔值。",
            "solution": "该问题要求我们形式化并应用一种统计假设检验，以确定一个观测到的网络模式（特别是高聚类性）是自组织的结果，还是可能源于一个仅受基本网络属性约束的随机过程。这是复杂系统中的一个基本问题，其中，涌现的宏观模式通常通过与一个合适的零模型进行比较，来与平凡的聚集区分开来。\n\n该方法论的核心是假设检验。零假设 $H_0$ 假定，观测到的网络是从一个图集合中的一次随机实现，该集合中的所有图都与观测网络具有相同的度序列。备择假设 $H_1$ 则认为，网络拥有额外的结构——在此例中为显著更高的聚类——而这无法仅由度序列解释。这种额外的结构被解释为自组织的标志，即存在非随机的相互作用规则。\n\n选定的检验统计量是全局聚类系数 $C$，它量化了节点形成三角形的趋势。它被定义为“闭合”三元组（即三角形）与所有连通三元组（即楔形）的比率。\n- 三角形数量 $T$ 由 $T = \\frac{1}{6} \\mathrm{tr}(A^3)$ 给出，其中 $A$ 是邻接矩阵。$A^3_{ii}$ 项计算了从节点 $i$ 出发回到自身的长度为 3 的路径数量。每个涉及节点 $i$ 的三角形都会贡献两条这样的路径（一条顺时针，一条逆时针）。由于这对三角形中的 3 个节点都进行了计数，并且迹是对这些计数求和，因此我们需要除以 $3 \\times 2 = 6$。\n- 以节点 $i$ 为中心的连通三元组（或楔形）数量 $W$ 是连接到 $i$ 的边对的数量，即 $\\binom{k_i}{2}$，其中 $k_i$ 是节点 $i$ 的度。对所有节点求和，即可得到楔形总数：$W = \\sum_{i=0}^{n-1} \\binom{k_i}{2}$。\n- 全局聚类系数则为 $C = \\frac{3T}{W}$。因子 $3$ 对该比率进行了归一化，因为一个三角形包含三个闭合的楔形。\n\n为检验零假设，我们生成统计量 $C$ 的一个零分布。这是通过使用度保持随机边交换模型（Maslov–Sneppen 重连）完成的。该过程从观测网络开始，重复交换两个随机选择的边（例如 $\\{i, j\\}$ 和 $\\{u, v\\}$）的端点，以形成新边 $\\{i, v\\}$ 和 $\\{u, j\\}$，前提是这些新边不存在且不产生自环。这个过程在保持每个节点度数不变的同时，将网络的拓扑随机化，从而创建了一个精确匹配观测网络度序列的随机图集合。这一点至关重要，因为许多网络属性（包括聚类）都受到度序列的强烈影响。通过保持度序列，我们分离出了度之外的更高阶相关性的影响。\n\n对于通过此过程生成的 $R$ 个随机图中的每一个，我们计算其聚类系数 $C^{(r)}$。这个值的集合 $\\{C^{(1)}, C^{(2)}, \\dots, C^{(R)}\\}$ 构成了一个经验零分布。然后，我们使用两个度量将观测到的聚类系数 $C^{\\text{obs}}$ 与此分布进行比较：\n\n1.  **经验 $p$ 值**：$p = \\frac{1 + \\sum_{r=1}^R \\mathbf{1}\\{C^{(r)} \\ge C^{\\mathrm{obs}}\\}}{R + 1}$。这衡量了在零假设下，观测到至少与 $C^{\\text{obs}}$ 一样大的聚类系数的概率。`+1` 项是一种标准校正，用于避免 $p=0$ 并将观测样本本身考虑在内。一个小的 $p$ 值表明观测到的聚类异常地高。\n2.  **标准化效应大小（$z$ 分数）**：$z = \\frac{C^{\\mathrm{obs}} - \\mu}{\\sigma}$，其中 $\\mu$ 和 $\\sigma$ 是零分布的均值和标准差。$z$ 分数衡量观测值与零分布均值相差多少个标准差。一个大的正 $z$ 分数表示效应量很大。\n\n决策规则是，如果一个模式同时具有统计显著性（$p  \\alpha$）和足够大的效应大小（$z \\ge z_{\\mathrm{thr}}$），则判定其为自组织的结果，给定的阈值为 $\\alpha=0.05$ 和 $z_{\\mathrm{thr}}=2$。\n\n我们实现了一个计算框架来测试四种不同的网络模型：\n- **情况 1：环状格点 $(n=60, k=4)$**：每个节点都与其在环上的最近邻和次近邻相连。这创造了一种规则的、局部有序的结构。我们预期相邻的邻居之间会形成三角形（例如，节点 $i$、$i+1$、$i+2$ 不会形成三角形，但如果节点 $i-1$ 和 $i-2$ 相连，则 $i$、$i-1$、$i-2$ 会形成三角形），从而导致较高的 $C^{\\text{obs}}$。这种结构在具有相同度的随机图中是不期望出现的，因此我们预期会拒绝零假设（结果：`True`）。\n- **情况 2：随机化的环状格点**：该网络是通过对情况 1 中的环状格点进行大量度保持交换来明确构建的。根据其构造方式，它本身就是零模型集合中的一个样本。因此，其 $C^{\\text{obs}}$ 对于零分布来说应该是典型的，从而导致较高的 $p$ 值和接近 0 的 $z$ 分数。我们预期无法拒绝零假设（结果：`False`）。\n- **情况 3：偏好连接树 $(n=60, m=1)$**：这将生成一个树结构，根据定义，树没有环路，因此也没有三角形。所以 $T^{\\text{obs}}=0$ 且 $C^{\\text{obs}}=0$。而具有相同异构度序列的零模型图，几乎肯定会包含一些偶然形成的三角形。因此，对于所有零样本，$C^{(r)}$ 很可能都大于 $C^{\\text{obs}}$，导致 $p \\approx 1$ 和一个负的 $z$ 分数。我们预期无法拒绝零假设（结果：`False`）。\n- **情况 4：带对角线的二维网格 $((s_x,s_y)=(7,7))$**：该网络模拟了一个具有局部连接的空间嵌入系统。带有对角线的网格结构创造了高密度的三角形。例如，在一个网格单元中添加一条连接节点 $(x,y)$ 和 $(x+1,y+1)$ 的边，会产生两个三角形：$((x,y), (x+1,y), (x+1,y+1))$ 和 $((x,y), (x,y+1), (x+1,y+1))$。这种高度聚类的结构是自组织的一种形式（基于空间邻近性），并且不期望从随机重连过程中产生。我们预期会拒绝零假设（结果：`True`）。\n\n实现的步骤是首先为每种情况生成邻接矩阵。然后，对于每个矩阵，一个测试函数会计算其观测聚类系数 $C^{\\text{obs}}$，通过重连生成 $R=64$ 个零模型样本，计算 $C$ 的零分布，并最终计算 $p$ 值和 $z$ 分数以应用决策规则。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to run the four test cases and print the results.\n    \"\"\"\n    np.random.seed(42)  # For reproducibility\n\n    # Define test case parameters\n    alpha = 0.05\n    z_thr = 2.0\n    R = 64\n    S_multiplier_null = 10\n\n    results = []\n\n    # Case 1: Ring-lattice\n    n1, k1 = 60, 4\n    A1 = generate_ring_lattice(n1, k1)\n    res1 = run_null_model_test(A1, R, alpha, z_thr, S_multiplier_null)\n    results.append(res1)\n\n    # Case 2: Randomized ring-lattice\n    m2 = (n1 * k1) // 2\n    S_randomize = 20 * m2\n    A2 = degree_preserving_swap(A1.copy(), S_randomize)\n    res2 = run_null_model_test(A2, R, alpha, z_thr, S_multiplier_null)\n    results.append(res2)\n\n    # Case 3: Preferential attachment tree\n    n3 = 60\n    A3 = generate_pa_tree(n3)\n    res3 = run_null_model_test(A3, R, alpha, z_thr, S_multiplier_null)\n    results.append(res3)\n\n    # Case 4: 2D grid with diagonals\n    sx4, sy4 = 7, 7\n    A4 = generate_grid_with_diagonals(sx4, sy4)\n    res4 = run_null_model_test(A4, R, alpha, z_thr, S_multiplier_null)\n    results.append(res4)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef calculate_c(A):\n    \"\"\"\n    Calculates the global clustering coefficient C for a graph with adjacency matrix A.\n    \"\"\"\n    if A.shape[0]  3:\n        return 0.0\n        \n    # Using np.linalg.matrix_power for A^3\n    A_cubed = np.linalg.matrix_power(A.astype(np.float64), 3)\n    T = np.trace(A_cubed) / 6.0\n    \n    k = A.sum(axis=1)\n    # Filter degrees less than 2, as they don't contribute to wedges\n    k_ge_2 = k[k >= 2]\n    W = np.sum(k_ge_2 * (k_ge_2 - 1.0)) / 2.0\n    \n    if W == 0:\n        return 0.0\n    \n    return (3.0 * T) / W\n\ndef degree_preserving_swap(A, num_swaps):\n    \"\"\"\n    Performs degree-preserving random edge swaps (Maslov-Sneppen rewiring).\n    \"\"\"\n    n = A.shape[0]\n    A_rewired = A.copy()\n    \n    # Get edge set for efficient lookups and modification\n    # Use tuples with sorted nodes to have a canonical representation\n    edge_set = {tuple(sorted(edge)) for edge in np.argwhere(np.triu(A_rewired))}\n\n    if not edge_set or len(edge_set)  2:\n        return A_rewired\n\n    edges_list = list(edge_set)\n    m = len(edges_list)\n    \n    swaps_done = 0\n    attempts = 0\n    max_attempts = num_swaps * 10 # To avoid infinite loops in dense graphs\n\n    while swaps_done  num_swaps and attempts  max_attempts:\n        attempts += 1\n        \n        # Choose two distinct edges\n        idx1, idx2 = np.random.choice(m, 2, replace=False)\n        e1 = edges_list[idx1]\n        e2 = edges_list[idx2]\n        \n        i, j = e1\n        u, v = e2\n\n        # Ensure all four nodes are distinct\n        if len({i, j, u, v}) != 4:\n            continue\n\n        # Propose new edges (i,v) and (u,j). Sorting for canonical check.\n        new_e1 = tuple(sorted((i, v)))\n        new_e2 = tuple(sorted((u, j)))\n\n        # Check if new edges would create multi-edges\n        if new_e1 in edge_set or new_e2 in edge_set:\n            continue\n        \n        # Perform the swap\n        # Remove old edges from matrix and set\n        A_rewired[i, j] = A_rewired[j, i] = 0\n        A_rewired[u, v] = A_rewired[v, u] = 0\n        edge_set.remove(e1)\n        edge_set.remove(e2)\n        \n        # Add new edges to matrix and set\n        A_rewired[i, v] = A_rewired[v, i] = 1\n        A_rewired[u, j] = A_rewired[j, u] = 1\n        edge_set.add(new_e1)\n        edge_set.add(new_e2)\n        \n        # Update the list from which we sample\n        edges_list[idx1] = new_e1\n        edges_list[idx2] = new_e2\n\n        swaps_done += 1\n        \n    return A_rewired\n\n\ndef run_null_model_test(A_obs, R, alpha, z_thr):\n    \"\"\"\n    Runs the null model test and returns the decision.\n    \"\"\"\n    C_obs = calculate_c(A_obs)\n    \n    m = np.sum(np.triu(A_obs))\n    num_swaps = int(S_multiplier * m)\n\n    C_null_dist = []\n    for _ in range(R):\n        A_rewired = degree_preserving_swap(A_obs.copy(), num_swaps)\n        C_null = calculate_c(A_rewired)\n        C_null_dist.append(C_null)\n        \n    C_null_dist = np.array(C_null_dist)\n    \n    # Calculate p-value\n    ge_count = np.sum(C_null_dist >= C_obs)\n    p_value = (1.0 + ge_count) / (R + 1.0)\n    \n    # Calculate z-score\n    mu = np.mean(C_null_dist)\n    sigma = np.std(C_null_dist)\n    \n    if sigma == 0:\n        if C_obs > mu:\n            z_score = np.inf\n        else: # Covers C_obs = mu\n            z_score = -np.inf\n    else:\n        z_score = (C_obs - mu) / sigma\n\n    # Decision rule\n    return p_value  alpha and z_score >= z_thr\n\n# --- Graph Generation Functions ---\n\ndef generate_ring_lattice(n, k):\n    A = np.zeros((n, n), dtype=int)\n    for i in range(n):\n        for d in range(1, k // 2 + 1):\n            j = (i + d) % n\n            A[i, j] = A[j, i] = 1\n    return A\n\ndef generate_pa_tree(n):\n    A = np.zeros((n, n), dtype=int)\n    if n  2:\n        return A\n    \n    # Initial state: edge between node 0 and 1\n    A[0, 1] = A[1, 0] = 1\n    edge_endpoints = [0, 1]\n    \n    for i in range(2, n):\n        target_node = np.random.choice(edge_endpoints)\n        A[i, target_node] = A[target_node, i] = 1\n        edge_endpoints.extend([i, target_node])\n        \n    return A\n\ndef generate_grid_with_diagonals(sx, sy):\n    n = sx * sy\n    A = np.zeros((n, n), dtype=int)\n    \n    for y in range(sy):\n        for x in range(sx):\n            i = x + y * sx\n            \n            # Horizontal neighbor\n            if x  sx - 1:\n                j_h = (x + 1) + y * sx\n                A[i, j_h] = A[j_h, i] = 1\n                \n            # Vertical neighbor\n            if y  sy - 1:\n                j_v = x + (y + 1) * sx\n                A[i, j_v] = A[j_v, i] = 1\n            \n            # Diagonal neighbor: (x,y) to (x+1,y+1)\n            if x  sx - 1 and y  sy - 1:\n                j_d = (x + 1) + (y + 1) * sx\n                A[i, j_d] = A[j_d, i] = 1\n                \n    return A\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}