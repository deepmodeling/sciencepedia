{
    "hands_on_practices": [
        {
            "introduction": "One of the defining features of a complex system is emergence, where macroscopic patterns arise from simple microscopic rules. This practice explores bistability, a fundamental emergent property where a system can rest in one of two distinct stable states. By analyzing the fixed points and the underlying potential landscape of a canonical one-dimensional system, you will develop the foundational analytical skills needed to understand how nonlinearity gives rise to complex behaviors .",
            "id": "4271109",
            "problem": "Consider the one-dimensional ordinary differential equation (ODE) $\\frac{dx}{dt} = a x - b x^{3}$ with $a>0$ and $b>0$. Using the fundamental definitions in dynamical systems, define a fixed point $x^{\\ast}$ by the condition $f(x^{\\ast})=0$ where $f(x)=a x - b x^{3}$, and define linear stability of a fixed point by the sign of the derivative $f'(x^{\\ast})$ in one dimension. In complex systems, bistability refers to the coexistence of two asymptotically stable fixed points with distinct basins of attraction, separated by an unstable fixed point. Starting from these definitions and without invoking pre-derived shortcut formulas, perform the following:\n- Determine all fixed points of the system in terms of $a$ and $b$.\n- Linearize the system about each fixed point to determine its stability and thereby establish the presence of bistability for suitable positive parameters $a$ and $b$.\n- Interpret the system as a gradient flow by identifying a scalar potential $U(x)$ such that $\\frac{dx}{dt} = -\\frac{dU}{dx}$, and fix the additive constant of $U(x)$ by requiring $U(0)=0$.\n- Define the bistable barrier height as the difference in the potential between the unstable fixed point that separates the basins of attraction and either of the stable fixed points. Compute this barrier height exactly in terms of $a$ and $b$.\n\nProvide your final answer as a single closed-form analytic expression. No rounding is required. Do not include any units in your final expression.",
            "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and self-contained. It presents a standard problem in dynamical systems theory without any apparent flaws, contradictions, or ambiguities. We may therefore proceed with the solution.\n\nThe one-dimensional ordinary differential equation (ODE) is given by $\\frac{dx}{dt} = f(x)$, where $f(x) = a x - b x^{3}$, and the parameters $a$ and $b$ are positive real numbers, i.e., $a>0$ and $b>0$.\n\nFirst, we determine the fixed points, denoted by $x^{\\ast}$, by solving the equation $f(x^{\\ast})=0$.\n$$a x^{\\ast} - b (x^{\\ast})^{3} = 0$$\nFactoring out $x^{\\ast}$, we get:\n$$x^{\\ast} (a - b (x^{\\ast})^{2}) = 0$$\nThis equation yields three distinct real solutions since $a>0$ and $b>0$:\n1. $x^{\\ast}_{1} = 0$\n2. $a - b (x^{\\ast})^{2} = 0 \\implies (x^{\\ast})^{2} = \\frac{a}{b} \\implies x^{\\ast} = \\pm\\sqrt{\\frac{a}{b}}$\n\nThus, the three fixed points of the system are $x^{\\ast}_{1} = 0$, $x^{\\ast}_{2} = \\sqrt{\\frac{a}{b}}$, and $x^{\\ast}_{3} = -\\sqrt{\\frac{a}{b}}$.\n\nNext, we analyze the linear stability of each fixed point. The stability is determined by the sign of the derivative $f'(x) = \\frac{df}{dx}$ evaluated at the fixed point $x^{\\ast}$.\nFirst, we compute the derivative of $f(x)$:\n$$f'(x) = \\frac{d}{dx}(a x - b x^{3}) = a - 3 b x^{2}$$\nNow, we evaluate this derivative at each of the three fixed points:\n- For $x^{\\ast}_{1} = 0$:\n  $$f'(0) = a - 3 b (0)^{2} = a$$\n  Since we are given $a>0$, $f'(0)>0$. A positive derivative indicates that the fixed point is unstable.\n- For $x^{\\ast}_{2} = \\sqrt{\\frac{a}{b}}$:\n  $$f'\\left(\\sqrt{\\frac{a}{b}}\\right) = a - 3 b \\left(\\sqrt{\\frac{a}{b}}\\right)^{2} = a - 3 b \\left(\\frac{a}{b}\\right) = a - 3a = -2a$$\n  Since we are given $a>0$, $f'(\\sqrt{\\frac{a}{b}}) = -2a < 0$. A negative derivative indicates that the fixed point is asymptotically stable.\n- For $x^{\\ast}_{3} = -\\sqrt{\\frac{a}{b}}$:\n  $$f'\\left(-\\sqrt{\\frac{a}{b}}\\right) = a - 3 b \\left(-\\sqrt{\\frac{a}{b}}\\right)^{2} = a - 3 b \\left(\\frac{a}{b}\\right) = a - 3a = -2a$$\n  Similarly, since $a>0$, $f'(-\\sqrt{\\frac{a}{b}}) = -2a < 0$. This fixed point is also asymptotically stable.\n\nThe system possesses two stable fixed points, $x^{\\ast}_{2} = \\sqrt{\\frac{a}{b}}$ and $x^{\\ast}_{3} = -\\sqrt{\\frac{a}{b}}$, which are separated by an unstable fixed point, $x^{\\ast}_{1} = 0$. This confirms the presence of bistability as defined in the problem statement.\n\nNow, we interpret the system as a gradient flow by finding a potential function $U(x)$ such that $\\frac{dx}{dt} = -\\frac{dU}{dx}$.\nWe equate the given dynamics to this condition:\n$$a x - b x^{3} = -\\frac{dU}{dx}$$\nThis implies:\n$$\\frac{dU}{dx} = -a x + b x^{3}$$\nTo find $U(x)$, we integrate the expression for $\\frac{dU}{dx}$ with respect to $x$:\n$$U(x) = \\int (-a x + b x^{3}) \\, dx = -a \\frac{x^{2}}{2} + b \\frac{x^{4}}{4} + C$$\nwhere $C$ is the constant of integration. We are given the condition $U(0)=0$ to fix this constant.\n$$U(0) = -a \\frac{0^{2}}{2} + b \\frac{0^{4}}{4} + C = 0 \\implies C = 0$$\nTherefore, the potential function is:\n$$U(x) = -\\frac{a x^{2}}{2} + \\frac{b x^{4}}{4}$$\nThe stable fixed points correspond to local minima of the potential $U(x)$, while the unstable fixed point corresponds to a local maximum.\n\nFinally, we compute the bistable barrier height, defined as the difference in potential between the unstable fixed point and either of the stable fixed points. Let $\\Delta U$ denote this barrier height.\nThe unstable fixed point is $x^{\\ast}_{\\text{unstable}} = 0$. The potential at this point is:\n$$U(x^{\\ast}_{\\text{unstable}}) = U(0) = 0$$\nThe stable fixed points are $x^{\\ast}_{\\text{stable}} = \\pm\\sqrt{\\frac{a}{b}}$. Due to the even symmetry of the potential function ($U(x) = U(-x)$), the potential value is the same at both stable points. Let's calculate it for $x = \\sqrt{\\frac{a}{b}}$:\n$$U\\left(\\sqrt{\\frac{a}{b}}\\right) = -\\frac{a}{2}\\left(\\sqrt{\\frac{a}{b}}\\right)^{2} + \\frac{b}{4}\\left(\\sqrt{\\frac{a}{b}}\\right)^{4}$$\n$$U\\left(\\sqrt{\\frac{a}{b}}\\right) = -\\frac{a}{2}\\left(\\frac{a}{b}\\right) + \\frac{b}{4}\\left(\\frac{a^{2}}{b^{2}}\\right)$$\n$$U\\left(\\sqrt{\\frac{a}{b}}\\right) = -\\frac{a^{2}}{2b} + \\frac{a^{2}}{4b} = -\\frac{2a^{2}}{4b} + \\frac{a^{2}}{4b} = -\\frac{a^{2}}{4b}$$\nThe barrier height $\\Delta U$ is the difference between the potential at the unstable saddle point and the potential at the stable minima:\n$$\\Delta U = U(x^{\\ast}_{\\text{unstable}}) - U(x^{\\ast}_{\\text{stable}})$$\n$$\\Delta U = U(0) - U\\left(\\sqrt{\\frac{a}{b}}\\right) = 0 - \\left(-\\frac{a^{2}}{4b}\\right) = \\frac{a^{2}}{4b}$$\nThis is the required bistable barrier height.",
            "answer": "$$\n\\boxed{\\frac{a^{2}}{4b}}\n$$"
        },
        {
            "introduction": "Beyond multiple stable states, complex systems can exhibit chaosâ€”aperiodic, unpredictable behavior in a deterministic system. This exercise provides a hands-on computational approach to one of the most famous models of chaos, the logistic map. You will write a program to estimate the Lyapunov exponent, the definitive quantitative measure of sensitive dependence on initial conditions, and learn to interpret its sign as a signature of chaos .",
            "id": "4271118",
            "problem": "You are to write a complete program that estimates the largest Lyapunov exponent for the one-dimensional logistic map and uses it to interpret the presence of chaos as a defining feature of complex systems. The logistic map is the discrete-time dynamical system given by the recurrence $x_{t+1} = f_r(x_t)$ with $f_r(x) = r x (1 - x)$, where $r \\in [0,4]$ is a real parameter and $x_t \\in [0,1]$ is the state at discrete time $t \\in \\{0,1,2,\\dots\\}$. The largest Lyapunov exponent $\\lambda$ for a one-dimensional map is defined fundamentally as the long-time growth rate of an infinitesimal perturbation under the linearization of the map along a typical trajectory, that is,\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\sum_{t=0}^{n-1} \\ln \\left| f_r'(x_t) \\right|,\n$$\nwhere $f_r'(x) = \\frac{d}{dx} f_r(x)$ is the derivative. For the logistic map, $f_r'(x) = r(1-2x)$. The sign of $\\lambda$ determines the exponential divergence or convergence of nearby trajectories: if $\\lambda > 0$, then typical nearby trajectories diverge exponentially fast, indicating sensitive dependence on initial conditions (chaos); if $\\lambda < 0$, trajectories converge to a stable periodic orbit or fixed point; if $\\lambda = 0$, the system is at a bifurcation threshold.\n\nYour program must implement the following tasks based strictly on the above fundamental definition and the derivative of the logistic map:\n- For a given parameter $r$, initial condition $x_0 \\in (0,1)$, a transient length $n_{\\mathrm{trans}} \\in \\mathbb{N}$ to discard initial steps, and a measurement length $n \\in \\mathbb{N}$, compute an estimator\n$$\n\\hat{\\lambda}(r; x_0, n_{\\mathrm{trans}}, n) = \\frac{1}{n} \\sum_{t=n_{\\mathrm{trans}}}^{n_{\\mathrm{trans}} + n - 1} \\ln \\left( \\left| r \\left( 1 - 2 x_t \\right) \\right| + \\varepsilon \\right),\n$$\nwhere $\\varepsilon = 10^{-12}$ is a fixed numerical safeguard to avoid taking the logarithm of zero. The state sequence $\\{x_t\\}$ is generated by iterating $x_{t+1} = r x_t (1 - x_t)$ starting from $x_0$.\n- Interpret the presence of chaos by returning a boolean $c$ defined by a decision rule with a tolerance $\\tau = 10^{-4}$: set $c = \\mathrm{True}$ if $\\hat{\\lambda} > \\tau$ and $c = \\mathrm{False}$ otherwise. This rule encodes the interpretation that a strictly positive Lyapunov exponent indicates sustained sensitive dependence, with a small tolerance for finite-time estimation error.\n\nUse the following test suite of parameter values $(r, x_0, n_{\\mathrm{trans}}, n)$:\n- Case $1$: $r = 0.5$, $x_0 = 0.123456789$, $n_{\\mathrm{trans}} = 10000$, $n = 200000$.\n- Case $2$: $r = 2.5$, $x_0 = 0.123456789$, $n_{\\mathrm{trans}} = 10000$, $n = 200000$.\n- Case $3$: $r = 3.2$, $x_0 = 0.123456789$, $n_{\\mathrm{trans}} = 10000$, $n = 200000$.\n- Case $4$: $r = 3.5$, $x_0 = 0.123456789$, $n_{\\mathrm{trans}} = 10000$, $n = 200000$.\n- Case $5$: $r = 3.56995$, $x_0 = 0.123456789$, $n_{\\mathrm{trans}} = 10000$, $n = 200000$.\n- Case $6$: $r = 3.7$, $x_0 = 0.123456789$, $n_{\\mathrm{trans}} = 10000$, $n = 200000$.\n- Case $7$: $r = 3.83$, $x_0 = 0.123456789$, $n_{\\mathrm{trans}} = 10000$, $n = 200000$.\n- Case $8$: $r = 4.0$, $x_0 = 0.123456789$, $n_{\\mathrm{trans}} = 10000$, $n = 200000$.\n\nFor each case, compute the pair consisting of the rounded Lyapunov estimate and the chaos flag. Round each $\\hat{\\lambda}$ to $6$ decimal places using standard rounding rules.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a two-element list of the form $[\\hat{\\lambda}, c]$. For example, an output for three cases would look like $[[0.123456,\\mathrm{True}],[-0.000789,\\mathrm{False}],[0.693147,\\mathrm{True}]]$.\n- No additional text or whitespace is permitted beyond the single required line.\n- There are no physical units involved in this problem.",
            "solution": "The problem statement is evaluated as valid. It is scientifically grounded in the well-established theory of dynamical systems and chaos, specifically concerning the logistic map, which is a canonical model in the field. The problem is well-posed, providing a complete and unambiguous set of definitions, equations, and parameters required for a unique numerical solution. The language is objective and mathematically precise. The provided methodology for estimating the Lyapunov exponent is a standard numerical technique.\n\nThe solution will be developed by first implementing a function to simulate the logistic map and compute the largest Lyapunov exponent estimator, $\\hat{\\lambda}$, as defined. This will be followed by applying the specified decision rule to classify the dynamics as chaotic or non-chaotic.\n\nThe logistic map is a discrete-time dynamical system described by the recurrence relation:\n$$\nx_{t+1} = f_r(x_t) = r x_t (1 - x_t)\n$$\nwhere $x_t \\in [0,1]$ is the state of the system at time step $t$, and $r \\in [0,4]$ is a control parameter.\n\nThe largest Lyapunov exponent, $\\lambda$, quantifies the average exponential rate of divergence or convergence of nearby trajectories. A positive exponent, $\\lambda > 0$, is a defining characteristic of chaos, indicating sensitive dependence on initial conditions. It is formally defined as:\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\sum_{t=0}^{n-1} \\ln \\left| f_r'(x_t) \\right|\n$$\nwhere $f_r'(x)$ is the derivative of the map function. For the logistic map, this derivative is $f_r'(x) = r(1-2x)$. The term $\\ln |f_r'(x_t)|$ represents the local, or instantaneous, logarithmic rate of expansion or contraction of an infinitesimal perturbation at state $x_t$. The Lyapunov exponent is the long-term average of these local rates over a typical trajectory.\n\nThe algorithmic procedure to estimate $\\lambda$ for a given set of parameters $(r, x_0, n_{\\mathrm{trans}}, n)$ is as follows:\n\n1.  **Initialization**: Start with the initial condition $x_0$.\n\n2.  **Transient Discard**: Iterate the map for $n_{\\mathrm{trans}}$ steps. The state $x_t$ is updated according to $x_{t+1} = r x_t (1 - x_t)$ for $t = 0, 1, \\dots, n_{\\mathrm{trans}}-1$. This initial phase allows the system's trajectory to settle onto its attractor (e.g., a fixed point, a periodic orbit, or a strange attractor). By discarding these transient states, the subsequent calculation of $\\lambda$ reflects the intrinsic dynamics of the attractor, independent of the specific choice of $x_0$ (excluding a set of measure zero of initial conditions).\n\n3.  **Lyapunov Summation**: After the transient phase, perform an additional $n$ iterations. During this measurement phase, for each step $t$ from $n_{\\mathrm{trans}}$ to $n_{\\mathrm{trans}} + n - 1$, calculate the derivative term $f_r'(x_t) = r(1-2x_t)$ and accumulate the sum of its logarithmic magnitude. The problem specifies the computation of the estimator $\\hat{\\lambda}$ using a summation:\n    $$\n    S = \\sum_{t=n_{\\mathrm{trans}}}^{n_{\\mathrm{trans}} + n - 1} \\ln \\left( \\left| r \\left( 1 - 2 x_t \\right) \\right| + \\varepsilon \\right)\n    $$\n    The small constant $\\varepsilon = 10^{-12}$ is a numerical safeguard to prevent an error from `log(0)`, which would occur if a trajectory point $x_t$ hits the critical point $x_c = 0.5$, where $f_r'(0.5) = 0$. After computing the local term, the state is updated to $x_{t+1}$ for the next iteration.\n\n4.  **Averaging**: The estimator $\\hat{\\lambda}$ is the average of the accumulated sum over the $n$ measurement steps:\n    $$\n    \\hat{\\lambda} = \\frac{S}{n}\n    $$\n    This value is an approximation of the true Lyapunov exponent $\\lambda$. The quality of the approximation improves as $n \\to \\infty$.\n\n5.  **Chaos Classification**: The sign of the Lyapunov exponent determines the stability of the system. The problem defines a decision rule to classify the dynamics, using a tolerance $\\tau = 10^{-4}$ to account for finite-time numerical estimation errors, especially near bifurcation points where $\\lambda$ may be close to zero. The boolean flag for chaos, $c$, is determined as:\n    $$\n    c = \\begin{cases} \\mathrm{True} & \\text{if } \\hat{\\lambda} > \\tau \\\\ \\mathrm{False} & \\text{if } \\hat{\\lambda} \\le \\tau \\end{cases}\n    $$\n    A value of $c = \\mathrm{True}$ indicates that the system exhibits sensitive dependence on initial conditions (chaos), while $c = \\mathrm{False}$ indicates non-chaotic behavior (convergence to a stable fixed point or periodic orbit).\n\nFinally, the computed estimator $\\hat{\\lambda}$ is rounded to $6$ decimal places for reporting purposes. The program will execute this procedure for each of the specified test cases and format the results as a list of pairs $[\\hat{\\lambda}_{\\text{rounded}}, c]$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the largest Lyapunov exponent for the logistic map for a suite of\n    test cases and classifies the dynamics as chaotic or not.\n    \"\"\"\n\n    test_cases = [\n        # (r, x0, n_trans, n)\n        (0.5, 0.123456789, 10000, 200000),\n        (2.5, 0.123456789, 10000, 200000),\n        (3.2, 0.123456789, 10000, 200000),\n        (3.5, 0.123456789, 10000, 200000),\n        (3.56995, 0.123456789, 10000, 200000),\n        (3.7, 0.123456789, 10000, 200000),\n        (3.83, 0.123456789, 10000, 200000),\n        (4.0, 0.123456789, 10000, 200000),\n    ]\n\n    # Constants defined in the problem\n    epsilon = 1e-12\n    tau = 1e-4\n\n    results = []\n    \n    for r, x0, n_trans, n in test_cases:\n        # Initial state\n        x = x0\n\n        # Discard transient iterations to let the trajectory settle on the attractor\n        for _ in range(n_trans):\n            x = r * x * (1.0 - x)\n\n        # Measurement phase: compute the sum for the Lyapunov exponent\n        lyapunov_sum = 0.0\n        for _ in range(n):\n            # The derivative of the logistic map is f'(x) = r*(1-2x)\n            derivative = r * (1.0 - 2.0 * x)\n            # Add the local contribution to the sum, with a numerical safeguard\n            lyapunov_sum += np.log(np.abs(derivative) + epsilon)\n            # Iterate the map to the next state\n            x = r * x * (1.0 - x)\n\n        # Compute the estimator for the Lyapunov exponent\n        lambda_hat = lyapunov_sum / n\n\n        # Round the result to 6 decimal places for output\n        rounded_lambda = round(lambda_hat, 6)\n\n        # Apply the decision rule to classify chaos\n        is_chaotic = lambda_hat > tau\n        \n        results.append([rounded_lambda, is_chaotic])\n\n    # Format the final output according to the specified format\n    # The str() representation of a Python list and boolean matches the required format.\n    output_string = f\"[{','.join(map(str, results))}]\"\n    \n    print(output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "Complexity often arises from the interactions among many individual components or agents. This practice shifts focus from single-entity dynamics to collective behavior in a multi-agent system, drawing connections between game theory, reinforcement learning, and statistical physics. You will analyze how a population of interacting agents reaches a collective equilibrium distribution, and how this outcome is shaped by the level of randomness, or \"temperature,\" in their decision-making process .",
            "id": "4271082",
            "problem": "Consider a system of $N$ interacting agents on an undirected weighted network represented by a symmetric weight matrix $W \\in \\mathbb{R}^{N \\times N}$ with $W_{ij} = W_{ji}$ and $W_{ii} = 0$, and agent-specific biases $H \\in \\mathbb{R}^{N}$. Each agent $i \\in \\{1,\\dots,N\\}$ chooses a binary action $a_i \\in \\{0,1\\}$, and the joint action profile is $a = (a_1,\\dots,a_N) \\in \\{0,1\\}^N$. The utility of agent $i$ under profile $a$ is defined as\n$$\nu_i(a) = \\sum_{j \\neq i} W_{ij} \\cdot \\mathbf{1}\\{a_i = a_j\\} + H_i \\cdot \\mathbf{1}\\{a_i = 1\\},\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ denotes the indicator function. Define the potential function\n$$\n\\Phi(a) = \\sum_{1 \\leq i < j \\leq N} W_{ij} \\cdot \\mathbf{1}\\{a_i = a_j\\} + \\sum_{i=1}^{N} H_i \\cdot \\mathbf{1}\\{a_i = 1\\}.\n$$\nThis specification yields a potential game in the sense that unilateral deviations by any agent $i$ produce changes in $u_i$ equal to changes in $\\Phi$.\n\nAgents update their actions asynchronously using the softmax rule typical of Multi-Agent Reinforcement Learning (MARL), also known as logit choice. At a given temperature parameter $\\tau > 0$, when agent $i$ updates given fixed $a_{-i}$, the probability of choosing action $x \\in \\{0,1\\}$ is\n$$\n\\mathbb{P}\\big(a_i = x \\mid a_{-i}\\big) = \\frac{\\exp\\big(u_i(x,a_{-i})/\\tau\\big)}{\\exp\\big(u_i(0,a_{-i})/\\tau\\big) + \\exp\\big(u_i(1,a_{-i})/\\tau\\big)}.\n$$\nUnder this asynchronous log-linear learning dynamics, the induced Markov chain over $\\{0,1\\}^N$ has a unique stationary distribution given by the Gibbs measure\n$$\n\\pi(a) = \\frac{\\exp\\left(\\Phi(a)/\\tau\\right)}{Z(\\tau)}, \\quad \\text{where} \\quad Z(\\tau) = \\sum_{s \\in \\{0,1\\}^N} \\exp\\left(\\Phi(s)/\\tau\\right).\n$$\n\nA pure-strategy Nash equilibrium (NE) is a profile $a^\\star$ such that for every agent $i$,\n$$\nu_i(a^\\star_i, a^\\star_{-i}) \\geq u_i(1 - a^\\star_i, a^\\star_{-i}).\n$$\nA tie is permitted; that is, equality satisfies the NE condition.\n\nYour task is to write a complete, runnable program that, for each of the specified test cases below, computes the stationary distribution $\\pi(a)$ over all $2^N$ profiles and returns, for that test case, the total probability mass of all pure-strategy Nash equilibria, defined as\n$$\nP_{\\mathrm{NE}}(\\tau) = \\sum_{a \\in \\mathcal{E}} \\pi(a),\n$$\nwhere $\\mathcal{E}$ is the set of all pure-strategy Nash equilibria.\n\nThe program must:\n- Enumerate all $2^N$ profiles $a \\in \\{0,1\\}^N$.\n- Compute $\\Phi(a)$ for each profile using the provided $W$ and $H$.\n- Compute $\\pi(a)$ by normalizing $\\exp(\\Phi(a)/\\tau)$ over all profiles. For numerical stability, use any standard technique that preserves exactness of the final normalized probabilities.\n- Identify the set $\\mathcal{E}$ of pure-strategy Nash equilibria under the provided $u_i$.\n- Compute $P_{\\mathrm{NE}}(\\tau)$ as a floating-point number.\n\nTest Suite:\nFor each test case, use the given parameters $(N, W, H, \\tau)$.\n\n1. Case 1 (coordination, low temperature):\n   - $N = 4$\n   - $W = \\begin{bmatrix}\n   0 & 1.0 & 1.0 & 1.0 \\\\\n   1.0 & 0 & 1.0 & 1.0 \\\\\n   1.0 & 1.0 & 0 & 1.0 \\\\\n   1.0 & 1.0 & 1.0 & 0\n   \\end{bmatrix}$\n   - $H = \\begin{bmatrix}0.2,\\,0.2,\\,0.2,\\,0.2\\end{bmatrix}$\n   - $\\tau = 0.1$\n\n2. Case 2 (coordination, medium temperature):\n   - $N = 4$\n   - $W$ and $H$ as in Case 1\n   - $\\tau = 1.0$\n\n3. Case 3 (coordination, high temperature):\n   - $N = 4$\n   - $W$ and $H$ as in Case 1\n   - $\\tau = 10.0$\n\n4. Case 4 (mixed couplings on a chain, low temperature):\n   - $N = 5$\n   - $W = \\begin{bmatrix}\n   0 & 1.0 & 0 & 0 & 0 \\\\\n   1.0 & 0 & -1.5 & 0 & 0 \\\\\n   0 & -1.5 & 0 & 1.0 & 0 \\\\\n   0 & 0 & 1.0 & 0 & -1.5 \\\\\n   0 & 0 & 0 & -1.5 & 0\n   \\end{bmatrix}$\n   - $H = \\begin{bmatrix}0.1,\\,0.1,\\,0.1,\\,0.1,\\,0.1\\end{bmatrix}$\n   - $\\tau = 0.2$\n\n5. Case 5 (no interactions, high temperature):\n   - $N = 5$\n   - $W = \\mathbf{0}_{5 \\times 5}$ (all entries zero)\n   - $H = \\begin{bmatrix}0.1,\\,0.1,\\,0.1,\\,0.1,\\,0.1\\end{bmatrix}$\n   - $\\tau = 10.0$\n\nFinal Output Format:\nYour program should produce a single line of output containing the results for the five test cases as a comma-separated list enclosed in square brackets, with each floating-point result rounded to six decimal places, in the order of the cases listed above. For example, an output of the form\n$$\n[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5]\n$$\nmust be printed exactly as a single line of text, where each $\\text{result}_k$ is a decimal formatted to six places.",
            "solution": "The problem requires the computation of the total probability mass of all pure-strategy Nash Equilibria (NE) for a system of $N$ interacting agents. The system is defined as a potential game, and the agents' asynchronous updates follow a logit choice model, leading to a Gibbs-Boltzmann stationary distribution over the space of all possible joint action profiles.\n\nThe solution proceeds through a rigorous, step-by-step computational approach for each test case provided. The small size of the agent population ($N=4$ and $N=5$) makes it computationally feasible to enumerate the entire state space of joint profiles, which consists of $2^N$ possibilities.\n\nThe procedural steps are as follows:\n\n1.  **State Space Enumeration**: The set of all possible joint action profiles is $\\{0,1\\}^N$. We generate every profile $a = (a_1, \\dots, a_N)$ by iterating through all integers from $0$ to $2^N - 1$ and using their $N$-bit binary representations. Each bit corresponds to an agent's action.\n\n2.  **Potential Function Calculation**: For each profile $a \\in \\{0,1\\}^N$, we compute its potential, $\\Phi(a)$, according to the given formula:\n    $$\n    \\Phi(a) = \\sum_{1 \\leq i < j \\leq N} W_{ij} \\cdot \\mathbf{1}\\{a_i = a_j\\} + \\sum_{i=1}^{N} H_i \\cdot a_i\n    $$\n    Here, $\\mathbf{1}\\{\\cdot\\}$ is the indicator function, which equals $1$ if its argument is true and $0$ otherwise. The term $H_i \\cdot \\mathbf{1}\\{a_i=1\\}$ is equivalent to $H_i \\cdot a_i$ since $a_i \\in \\{0,1\\}$. This calculation is performed for all $2^N$ profiles, and the resulting potential values are stored.\n\n3.  **Identification of Pure-Strategy Nash Equilibria**: A profile $a^\\star$ is a pure-strategy Nash Equilibrium if no agent has a unilateral incentive to change their action. This is formally stated as:\n    $$\n    u_i(a^\\star_i, a^\\star_{-i}) \\geq u_i(1 - a^\\star_i, a^\\star_{-i}) \\quad \\forall i \\in \\{1, \\dots, N\\}\n    $$\n    The utility function $u_i(a)$ is given by:\n    $$\n    u_i(a) = \\sum_{j \\neq i} W_{ij} \\cdot \\mathbf{1}\\{a_i = a_j\\} + H_i \\cdot a_i\n    $$\n    For each of the $2^N$ profiles, we iterate through all $N$ agents. For each agent $i$, we calculate their utility $u_i(a)$ with their current action $a_i$ and the hypothetical utility $u_i(1-a_i, a_{-i})$ they would receive by switching to action $1-a_i$. If for any agent this switch is strictly profitable (i.e., the inequality is violated), the profile is not an NE. If the condition holds for all $N$ agents, the profile is classified as a pure-strategy NE. We maintain a boolean list to mark which profiles are NEs.\n\n4.  **Stationary Distribution Calculation**: The stationary probability of observing a profile $a$ is given by the Gibbs measure:\n    $$\n    \\pi(a) = \\frac{\\exp\\left(\\Phi(a)/\\tau\\right)}{Z(\\tau)}, \\quad \\text{where} \\quad Z(\\tau) = \\sum_{s \\in \\{0,1\\}^N} \\exp\\left(\\Phi(s)/\\tau\\right)\n    $$\n    Direct computation of $\\exp(\\Phi(a)/\\tau)$ can lead to numerical overflow if the argument $\\Phi(a)/\\tau$ is large. To ensure numerical stability, we use the log-sum-exp trick. Let $\\phi_a = \\Phi(a)/\\tau$. We find the maximum value $\\phi_{\\max} = \\max_{s \\in \\{0,1\\}^N} \\phi_s$. The probability $\\pi(a)$ can be rewritten as:\n    $$\n    \\pi(a) = \\frac{\\exp(\\phi_a - \\phi_{\\max})}{\\sum_{s \\in \\{0,1\\}^N} \\exp(\\phi_s - \\phi_{\\max})}\n    $$\n    This transformation ensures that the arguments to the exponential function are all non-positive, preventing overflow while preserving the exactness of the final normalized probabilities. We calculate $\\pi(a)$ for all $2^N$ profiles.\n\n5.  **Aggregation of NE Probabilities**: The final quantity to be computed is the total probability mass of the set of all pure-strategy Nash Equilibria, $\\mathcal{E}$. This is given by:\n    $$\n    P_{\\mathrm{NE}}(\\tau) = \\sum_{a \\in \\mathcal{E}} \\pi(a)\n    $$\n    We sum the probabilities $\\pi(a)$ for all profiles $a$ that were identified as NEs in Step 3. This sum gives the final result for one test case.\n\nThis entire procedure is encapsulated and executed for each of the five test cases specified in the problem statement, with the corresponding parameters for $N$, $W$, $H$, and $\\tau$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all specified test cases.\n    It sets up each test case's parameters and calls the core solver function,\n    then formats and prints the results as required.\n    \"\"\"\n\n    def solve_case(N, W, H, tau):\n        \"\"\"\n        Computes the total probability mass of pure-strategy Nash equilibria for a single test case.\n\n        Args:\n            N (int): The number of agents.\n            W (np.ndarray): The symmetric weight matrix (N x N).\n            H (np.ndarray): The agent-specific bias vector (N).\n            tau (float): The temperature parameter.\n\n        Returns:\n            float: The total probability mass of all pure-strategy NEs.\n        \"\"\"\n        num_profiles = 1 << N  # Equivalent to 2**N\n        profiles = []\n        # Step 1: Enumerate all 2^N profiles\n        for i in range(num_profiles):\n            profile = np.array([int(bit) for bit in bin(i)[2:].zfill(N)])\n            profiles.append(profile)\n\n        potentials = np.zeros(num_profiles, dtype=float)\n        is_ne = np.zeros(num_profiles, dtype=bool)\n\n        for idx, a in enumerate(profiles):\n            # Step 2: Calculate Potential Phi(a)\n            phi_a = 0.0\n            # Interaction term: sum_{1 <= i < j <= N} W_ij * 1{a_i = a_j}\n            for i in range(N):\n                for j in range(i + 1, N):\n                    if a[i] == a[j]:\n                        phi_a += W[i, j]\n            # Bias term: sum_{i=1 to N} H_i * a_i\n            phi_a += np.dot(H, a)\n            potentials[idx] = phi_a\n\n            # Step 3: Identify if 'a' is a Pure-Strategy Nash Equilibrium\n            ne_flag = True\n            for i in range(N):\n                # Utility of current action a_i\n                u_current = 0.0\n                for j in range(N):\n                    if i == j: continue\n                    if a[i] == a[j]:\n                        u_current += W[i, j]\n                if a[i] == 1:\n                    u_current += H[i]\n\n                # Utility of alternative action 1 - a_i\n                alt_action = 1 - a[i]\n                u_alternative = 0.0\n                for j in range(N):\n                    if i == j: continue\n                    if alt_action == a[j]:\n                        u_alternative += W[i, j]\n                if alt_action == 1:\n                    u_alternative += H[i]\n                \n                # Check for profitable deviation\n                if u_current < u_alternative:\n                    ne_flag = False\n                    break  # This profile is not an NE\n            \n            if ne_flag:\n                is_ne[idx] = True\n\n        # Step 4: Compute stationary distribution pi(a)\n        scaled_potentials = potentials / tau\n        # Use log-sum-exp trick for numerical stability\n        max_scaled_potential = np.max(scaled_potentials)\n        exp_terms = np.exp(scaled_potentials - max_scaled_potential)\n        partition_function = np.sum(exp_terms)\n        \n        pi = exp_terms / partition_function\n        \n        # Step 5: Compute P_NE by summing probabilities of all NE profiles\n        p_ne = np.sum(pi[is_ne])\n        \n        return p_ne\n\n    # --- Test Suite Definition ---\n\n    # Case 1, 2, 3 parameters\n    W1 = np.array([\n        [0.0, 1.0, 1.0, 1.0],\n        [1.0, 0.0, 1.0, 1.0],\n        [1.0, 1.0, 0.0, 1.0],\n        [1.0, 1.0, 1.0, 0.0]\n    ])\n    H1 = np.array([0.2, 0.2, 0.2, 0.2])\n    \n    # Case 4 parameters\n    W4 = np.array([\n        [0.0,  1.0,  0.0,  0.0,  0.0],\n        [1.0,  0.0, -1.5,  0.0,  0.0],\n        [0.0, -1.5,  0.0,  1.0,  0.0],\n        [0.0,  0.0,  1.0,  0.0, -1.5],\n        [0.0,  0.0,  0.0, -1.5,  0.0]\n    ])\n    H4 = np.array([0.1, 0.1, 0.1, 0.1, 0.1])\n    \n    # Case 5 parameters\n    W5 = np.zeros((5, 5))\n    H5 = np.array([0.1, 0.1, 0.1, 0.1, 0.1])\n    \n    test_cases = [\n        # Case 1: N=4, coordination, low temperature\n        {'N': 4, 'W': W1, 'H': H1, 'tau': 0.1},\n        # Case 2: N=4, coordination, medium temperature\n        {'N': 4, 'W': W1, 'H': H1, 'tau': 1.0},\n        # Case 3: N=4, coordination, high temperature\n        {'N': 4, 'W': W1, 'H': H1, 'tau': 10.0},\n        # Case 4: N=5, mixed couplings, low temperature\n        {'N': 5, 'W': W4, 'H': H4, 'tau': 0.2},\n        # Case 5: N=5, no interactions, high temperature\n        {'N': 5, 'W': W5, 'H': H5, 'tau': 10.0}\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(case['N'], case['W'], case['H'], case['tau'])\n        results.append(result)\n\n    # Format and print the final output\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}