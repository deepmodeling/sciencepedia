{
    "hands_on_practices": [
        {
            "introduction": "Understanding how individual-level strategic interactions scale up to population-level dynamics is the cornerstone of evolutionary game theory. This first exercise guides you through the fundamental derivation of the replicator equation for the simplest non-trivial case: a two-strategy game. By starting from the definitions of expected payoffs and assuming a well-mixed population, you will construct the differential equation that governs the evolution of strategy frequencies and find its internal equilibrium .",
            "id": "4275508",
            "problem": "Consider a symmetric two-strategy game played on a large, well-mixed population so that interactions are random and the mean-field description applies. The payoff matrix is given by $$A=\\begin{pmatrix}a  b \\\\ c  d\\end{pmatrix},$$ where $a$, $b$, $c$, and $d$ are real constants. Let $x \\in [0,1]$ denote the fraction of the population playing strategy $1$, and $1-x$ the fraction playing strategy $2$. The expected payoff to each strategy is determined by the linear combination of payoffs against the current population state. The population evolves according to the continuous-time replicator dynamics, which equate the growth rate of a strategy’s frequency to its payoff advantage over the population mean.\n\nStarting from these definitions and the mean-field assumption, derive the one-dimensional ordinary differential equation for $x(t)$ under replicator dynamics, expressed solely in terms of $x$, $a$, $b$, $c$, and $d$. Then, assuming $a-b-c+d \\neq 0$, determine the fraction $x^{*}\\in(0,1)$ corresponding to an interior equilibrium of the dynamics. Provide the final expression for $x^{*}$ as your answer. No numerical evaluation is required, and no rounding is needed.",
            "solution": "The problem requires the derivation of the replicator dynamics equation for a symmetric two-strategy game and the subsequent identification of the interior equilibrium point. The analysis will proceed from first principles as defined in the problem statement.\n\nLet $x$ be the fraction of the population adopting strategy $1$, and $1-x$ be the fraction adopting strategy $2$, where $x \\in [0, 1]$. The game is defined by the payoff matrix:\n$$A = \\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}$$\nHere, $a$ is the payoff for a strategy $1$ player meeting another strategy $1$ player, $b$ is the payoff for a strategy $1$ player meeting a strategy $2$ player, $c$ is for strategy $2$ vs. $1$, and $d$ is for strategy $2$ vs. $2$.\n\nFirst, we determine the expected payoff for an individual playing each strategy in a population with state $x$. Let $E_1(x)$ and $E_2(x)$ be the expected payoffs for strategy $1$ and strategy $2$, respectively. Under the mean-field assumption, individuals interact randomly.\nThe expected payoff for a strategy $1$ player is:\n$$E_1(x) = x \\cdot a + (1-x) \\cdot b$$\nThe expected payoff for a strategy $2$ player is:\n$$E_2(x) = x \\cdot c + (1-x) \\cdot d$$\n\nNext, we calculate the average payoff of the entire population, denoted by $\\bar{E}(x)$. This is the weighted average of the individual strategy payoffs:\n$$\\bar{E}(x) = x E_1(x) + (1-x) E_2(x)$$\n\nThe continuous-time replicator dynamics states that the growth rate of a strategy's frequency is equal to its payoff advantage over the population mean. For the fraction $x$ of strategy $1$ players, this is expressed as:\n$$\\frac{dx}{dt} = x \\left( E_1(x) - \\bar{E}(x) \\right)$$\n\nTo simplify this equation, we can express the payoff advantage term $E_1(x) - \\bar{E}(x)$ more directly.\n$$E_1(x) - \\bar{E}(x) = E_1(x) - \\left(x E_1(x) + (1-x) E_2(x)\\right)$$\n$$= (1-x) E_1(x) - (1-x) E_2(x)$$\n$$= (1-x) \\left( E_1(x) - E_2(x) \\right)$$\nSubstituting this back into the replicator equation gives:\n$$\\frac{dx}{dt} = x(1-x) \\left( E_1(x) - E_2(x) \\right)$$\nThis form of the equation is standard and intuitive: the rate of change of $x$ is proportional to the current proportions of both strategies, $x$ and $1-x$, and the difference in their expected payoffs.\n\nNow we compute the difference $E_1(x) - E_2(x)$:\n$$E_1(x) - E_2(x) = \\left(ax + b(1-x)\\right) - \\left(cx + d(1-x)\\right)$$\n$$= ax + b - bx - cx - d + dx$$\nGrouping terms with $x$:\n$$= (a - b - c + d)x + (b - d)$$\n\nSubstituting this expression back into the replicator equation yields the full one-dimensional ordinary differential equation for $x(t)$:\n$$\\frac{dx}{dt} = x(1-x) \\left[ (a - b - c + d)x + (b - d) \\right]$$\nThis completes the first part of the task.\n\nThe second part is to find the interior equilibrium point, $x^*$, defined as a steady-state solution where $x^* \\in (0,1)$. An equilibrium point is a value of $x$ for which the population composition does not change, i.e., $\\frac{dx}{dt} = 0$.\nSetting the replicator equation to zero:\n$$x^*(1-x^*) \\left[ (a - b - c + d)x^* + (b - d) \\right] = 0$$\nThis equation has three possible solutions for $x^*$:\n1. $x^* = 0$ (a pure strategy $2$ population)\n2. $x^* = 1$ (a pure strategy $1$ population)\n3. The value of $x^*$ that makes the term in the square brackets zero.\n\nThe interior equilibrium is the solution that is not on the boundaries of the interval $[0,1]$. Thus, we solve for the third case:\n$$(a - b - c + d)x^* + (b - d) = 0$$\n$$(a - b - c + d)x^* = d - b$$\nThe problem states that we must assume $a - b - c + d \\neq 0$, which allows us to divide by this term to find a unique solution for $x^*$:\n$$x^* = \\frac{d - b}{a - b - c + d}$$\nThis is the expression for the fraction of strategy $1$ players at the interior equilibrium point. The condition that $x^* \\in (0,1)$ implies certain relationships between the payoff parameters $a, b, c, d$, but the problem only asks for the algebraic expression for $x^*$.",
            "answer": "$$\\boxed{\\frac{d-b}{a-b-c+d}}$$"
        },
        {
            "introduction": "While two-strategy games provide essential insights, many real-world systems involve a wider array of behaviors. This practice extends our analysis to a three-strategy game, where the dynamics unfold on a two-dimensional simplex. You will derive and apply the necessary condition for an interior equilibrium—that all coexisting strategies must yield identical payoffs—and solve for the stationary population state using linear algebra .",
            "id": "4122568",
            "problem": "In a large, well-mixed population playing a symmetric game with $3$ pure strategies, the population state is represented by a mixed strategy $ \\mathbf{x} = (x_{1}, x_{2}, x_{3}) $ on the $2$-simplex, where $x_{i} \\ge 0$ and $x_{1} + x_{2} + x_{3} = 1$. The population evolves under continuous-time replicator dynamics, which is a standard model in complex adaptive systems for the evolution of strategy frequencies. Let the game be represented by the $3 \\times 3$ payoff matrix\n$$\nA \\;=\\;\n\\begin{pmatrix}\n2  -1  0 \\\\\n1  1  -1 \\\\\n0  2  1\n\\end{pmatrix}.\n$$\nStarting from the definition of continuous-time replicator dynamics and the definition of a stationary state, derive the necessary condition that characterizes an interior stationary state (i.e., a state with $x_{i}  0$ for all $i$). Then, using only this derived condition together with the constraints $x_{1} + x_{2} + x_{3} = 1$ and $x_{i}  0$, compute the interior stationary state for the given matrix $A$ explicitly.\n\nProvide your final answer as the vector of exact rational numbers for $(x_{1}, x_{2}, x_{3})$. Do not approximate; no rounding is required. The final answer should contain no units.",
            "solution": "The continuous-time replicator dynamics for a population with strategy frequencies given by the vector $\\mathbf{x} = (x_1, x_2, \\ldots, x_n)$ and a payoff matrix $A$ is described by the system of differential equations:\n$$\n\\dot{x_i} = x_i \\left[ (A\\mathbf{x})_i - \\mathbf{x}^T A \\mathbf{x} \\right] \\quad \\text{for } i = 1, 2, \\ldots, n\n$$\nHere, $(A\\mathbf{x})_i$ represents the expected payoff (or fitness) of an individual playing pure strategy $i$ in a population with state $\\mathbf{x}$. The term $\\phi(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} = \\sum_{j=1}^n x_j(A\\mathbf{x})_j$ is the average payoff of the entire population.\n\nA stationary state, or fixed point, of the dynamics is a state $\\mathbf{x}^*$ at which the population composition does not change over time, i.e., $\\dot{x_i} = 0$ for all $i$. Thus, a stationary state must satisfy:\n$$\nx_i^* \\left[ (A\\mathbf{x}^*)_i - \\phi(\\mathbf{x}^*) \\right] = 0 \\quad \\text{for all } i\n$$\nThe problem asks for an interior stationary state, which is defined by the condition $x_i^* > 0$ for all $i$. For the equation above to hold when $x_i^* > 0$, the term in the brackets must be zero:\n$$\n(A\\mathbf{x}^*)_i - \\phi(\\mathbf{x}^*) = 0 \\quad \\implies \\quad (A\\mathbf{x}^*)_i = \\phi(\\mathbf{x}^*)\n$$\nThis must be true for all $i \\in \\{1, 2, 3\\}$. This implies that at an interior stationary state, the expected payoffs of all pure strategies must be equal to each other (and thus equal to the average payoff of the population). This is the necessary condition:\n$$\n(A\\mathbf{x}^*)_1 = (A\\mathbf{x}^*)_2 = (A\\mathbf{x}^*)_3\n$$\nNow, we apply this condition to the specific game defined by the payoff matrix:\n$$\nA \\;=\\;\n\\begin{pmatrix}\n2  -1  0 \\\\\n1  1  -1 \\\\\n0  2  1\n\\end{pmatrix}\n$$\nand the population state vector $\\mathbf{x} = (x_1, x_2, x_3)^T$.\n\nFirst, we compute the expected payoff for each pure strategy $i$, denoted by $(A\\mathbf{x})_i$:\n$$\n(A\\mathbf{x})_1 = a_{11}x_1 + a_{12}x_2 + a_{13}x_3 = 2x_1 - x_2\n$$\n$$\n(A\\mathbf{x})_2 = a_{21}x_1 + a_{22}x_2 + a_{23}x_3 = x_1 + x_2 - x_3\n$$\n$$\n(A\\mathbf{x})_3 = a_{31}x_1 + a_{32}x_2 + a_{33}x_3 = 2x_2 + x_3\n$$\nApplying the condition $(A\\mathbf{x})_1 = (A\\mathbf{x})_2 = (A\\mathbf{x})_3$, we obtain a system of two linear equations:\n$$\n2x_1 - x_2 = x_1 + x_2 - x_3 \\quad (1)\n$$\n$$\nx_1 + x_2 - x_3 = 2x_2 + x_3 \\quad (2)\n$$\nSimplifying these equations, we get:\nFrom (1): $x_1 - 2x_2 + x_3 = 0$\nFrom (2): $x_1 - x_2 - 2x_3 = 0$\n\nWe must solve this system together with the constraint that the frequencies sum to $1$:\n$$\nx_1 + x_2 + x_3 = 1 \\quad (3)\n$$\nWe have a system of three linear equations in three variables. We can solve this system. Let's subtract the second simplified equation from the first:\n$$\n(x_1 - 2x_2 + x_3) - (x_1 - x_2 - 2x_3) = 0 - 0\n$$\n$$\n-x_2 + 3x_3 = 0 \\implies x_2 = 3x_3\n$$\nNow, we express $x_1$ in terms of $x_3$ by substituting $x_2 = 3x_3$ into the second simplified equation:\n$$\nx_1 - (3x_3) - 2x_3 = 0\n$$\n$$\nx_1 - 5x_3 = 0 \\implies x_1 = 5x_3\n$$\nNow we have both $x_1$ and $x_2$ in terms of $x_3$. We substitute these expressions into the simplex constraint equation (3):\n$$\n(5x_3) + (3x_3) + x_3 = 1\n$$\n$$\n9x_3 = 1 \\implies x_3 = \\frac{1}{9}\n$$\nWith the value for $x_3$, we can find $x_1$ and $x_2$:\n$$\nx_1 = 5x_3 = 5 \\left(\\frac{1}{9}\\right) = \\frac{5}{9}\n$$\n$$\nx_2 = 3x_3 = 3 \\left(\\frac{1}{9}\\right) = \\frac{3}{9} = \\frac{1}{3}\n$$\nThe interior stationary state is therefore $\\mathbf{x}^* = (x_1, x_2, x_3) = (\\frac{5}{9}, \\frac{1}{3}, \\frac{1}{9})$.\nWe verify that $x_i > 0$ for all $i$: $\\frac{5}{9} > 0$, $\\frac{1}{3} > 0$, $\\frac{1}{9} > 0$.\nWe also verify that they sum to $1$: $\\frac{5}{9} + \\frac{1}{3} + \\frac{1}{9} = \\frac{5}{9} + \\frac{3}{9} + \\frac{1}{9} = \\frac{9}{9} = 1$.\nThe solution is consistent with all conditions.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{5}{9}  \\frac{1}{3}  \\frac{1}{9} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The replicator equation possesses a subtle geometric structure that is not immediately obvious from its form. This advanced computational practice challenges you to explore this structure by contrasting the replicator dynamics with standard Euclidean gradient ascent on the game's potential landscape . By implementing the vector fields and comparing their direction and effect near the simplex boundaries, you will gain a deeper, tangible intuition for why replicator dynamics is a special and powerful model of selection.",
            "id": "4275502",
            "problem": "Consider a finite population game in Evolutionary Game Theory (EGT) with $n$ pure strategies. The population state is a probability vector $x \\in \\Delta^n$, where the simplex $\\Delta^n = \\{ x \\in \\mathbb{R}^n \\mid \\sum_{i=1}^{n} x_i = 1, \\, x_i \\ge 0 \\, \\forall i \\}$. Let $A \\in \\mathbb{R}^{n \\times n}$ be a given payoff matrix. The expected payoff to strategy $i$ under state $x$ is $(A x)_i$, and the mean population payoff is $\\bar{\\pi}(x) = x^\\top A x$. The replicator vector field is the vector $R(x) \\in \\mathbb{R}^n$ defined by the fundamental law of replicator dynamics: $R_i(x) = x_i \\left( (A x)_i - \\bar{\\pi}(x) \\right)$, which is tangent to the simplex because $\\sum_{i=1}^{n} R_i(x) = 0$.\n\nTo compare the replicator flow with Euclidean gradient ascent, define the symmetric part of the payoff matrix by $S = \\tfrac{1}{2} (A + A^\\top)$ and the potential function by $\\Phi(x) = x^\\top S x$. The Euclidean gradient of $\\Phi$ is $\\nabla \\Phi(x) = 2 S x$. To remain on the simplex, one must respect the geometry induced by the affine constraint $\\sum_i x_i = 1$, which implies that feasible directions lie in the tangent space $T_x \\Delta^n = \\{ v \\in \\mathbb{R}^n \\mid \\sum_{i=1}^{n} v_i = 0 \\}$. A feasible Euclidean ascent direction is obtained by orthogonally projecting $\\nabla \\Phi(x)$ onto $T_x \\Delta^n$ with respect to the standard inner product, which removes the component along the vector of all ones. Denote this projected direction by $G(x)$.\n\nFor any direction $v \\in T_x \\Delta^n$, the instantaneous rate of change of the potential along $v$ is the directional derivative $D_v \\Phi(x) = \\nabla \\Phi(x) \\cdot v$, where $\\cdot$ denotes the standard Euclidean inner product. To highlight the role of the simplex’s boundary, define the largest feasible explicit Euler step size that maintains nonnegativity when stepping from $x$ along $v$ by\n$$\n\\delta_{\\max}(x,v) = \\min_{i: v_i  0} \\frac{x_i}{-v_i},\n$$\nwith the convention that if $v_i \\ge 0$ for all $i$ then $\\delta_{\\max}(x,v) = +\\infty$. Given a fixed cap $0  \\delta_{\\mathrm{cap}} \\in \\mathbb{R}$, define the feasible fraction $f(x,v) = \\min\\{ \\delta_{\\max}(x,v), \\delta_{\\mathrm{cap}} \\} / \\delta_{\\mathrm{cap}} \\in [0,1]$. This quantity measures how close one can step along $v$ without leaving the simplex when using an explicit Euler step with step size at most $\\delta_{\\mathrm{cap}}$.\n\nYour task is to implement a program that, for each test case, computes:\n- The potential value $\\Phi(x)$.\n- The cosine similarity $\\cos(R(x),G(x)) = \\frac{R(x) \\cdot G(x)}{\\|R(x)\\|_2 \\, \\|G(x)\\|_2}$, with the convention that if either norm is $0$, the cosine similarity is $0$.\n- The directional derivatives $D_{R} \\Phi(x) = \\nabla \\Phi(x) \\cdot R(x)$ and $D_{G} \\Phi(x) = \\nabla \\Phi(x) \\cdot G(x)$.\n- The ratio of feasible fractions $\\rho(x) = \\frac{f(x,R(x))}{f(x,G(x))}$, computed with the cap $\\delta_{\\mathrm{cap}} = 0.1$. If $f(x,G(x)) = 0$, set the ratio to $+\\infty$.\n\nStart from the fundamental definitions above. Derive any additional relations you need for $G(x)$ from first principles, using the orthogonal projection of a vector in $\\mathbb{R}^n$ onto the subspace $T_x \\Delta^n$, and implement the computations numerically.\n\nUse the following test suite with $n = 3$:\n- Symmetric coordination-like matrix:\n$$\nA_1 = \\begin{bmatrix}\n0.0  1.2  0.5 \\\\\n1.2  0.0  0.8 \\\\\n0.5  0.8  0.0\n\\end{bmatrix}.\n$$\n- Symmetric anti-coordination-like matrix:\n$$\nA_2 = \\begin{bmatrix}\n0.0  -1.0  -0.5 \\\\\n-1.0  0.0  -0.2 \\\\\n-0.5  -0.2  0.0\n\\end{bmatrix}.\n$$\n- Non-symmetric matrix:\n$$\nA_3 = \\begin{bmatrix}\n0.0  2.0  -1.0 \\\\\n0.5  0.0  0.0 \\\\\n0.0  -2.0  0.0\n\\end{bmatrix}.\n$$\nUse the two population states:\n$$\nx^{(1)} = \\begin{bmatrix} 0.4 \\\\ 0.4 \\\\ 0.2 \\end{bmatrix}, \\quad\nx^{(2)} = \\begin{bmatrix} 0.05 \\\\ 0.55 \\\\ 0.40 \\end{bmatrix}.\n$$\nEvaluate the five cases:\n$$(A_1, x^{(1)}), \\; (A_1, x^{(2)}), \\; (A_2, x^{(1)}), \\; (A_3, x^{(1)}), \\; (A_3, x^{(2)}).$$\n\nFinal output format: Your program should produce a single line of output containing a flat list of $25$ floating-point numbers in the following order for the five cases, each case contributing $5$ numbers as\n$$\n[\\Phi(x), \\; \\cos(R,G), \\; D_R \\Phi(x), \\; D_G \\Phi(x), \\; \\rho(x)]\n$$\nconcatenated across the five cases. The single printed line must be exactly of the form\n$$\n[\\text{r}_1,\\text{r}_2,\\ldots,\\text{r}_{25}]\n$$\nwith comma-separated decimal values and no additional text.",
            "solution": "The task is to compute a set of five quantities for five distinct cases, each defined by a payoff matrix $A$ and a population state vector $x$. The quantities to compute are the potential $\\Phi(x)$, the cosine similarity between the replicator vector field $R(x)$ and the projected gradient vector field $G(x)$, the directional derivatives of the potential along these two fields, $D_R \\Phi(x)$ and $D_G \\Phi(x)$, and a ratio of feasible step fractions $\\rho(x)$. The computations for each case $(A, x)$ follow a sequence of steps derived from the provided definitions.\n\nFirst, we establish the computational formulas for all required quantities. Let the number of strategies be $n$.\n\n1.  **Potential $\\Phi(x)$**: The potential function is defined using the symmetric part of the payoff matrix, $S = \\frac{1}{2} (A + A^\\top)$. The potential is $\\Phi(x) = x^\\top S x$. For any vector $x$, it is a known identity that $x^\\top A x = x^\\top S x$, since the contribution from the skew-symmetric part of $A$ is zero. This means the mean population payoff $\\bar{\\pi}(x)$ is identical to the potential $\\Phi(x)$. So, we can compute $\\Phi(x)$ as $x^\\top A x$.\n\n2.  **Replicator Vector Field $R(x)$**: The components of the replicator vector field are given by $R_i(x) = x_i \\left( (A x)_i - \\bar{\\pi}(x) \\right)$ for $i = 1, \\dots, n$. Computationally, this involves:\n    a. Calculating the vector of expected payoffs, $p = Ax$.\n    b. Calculating the mean population payoff, $\\bar{\\pi}(x) = x^\\top p$.\n    c. Calculating the components $R_i(x) = x_i (p_i - \\bar{\\pi}(x))$.\n\n3.  **Projected Gradient Vector Field $G(x)$**: This vector is the orthogonal projection of the gradient of the potential, $\\nabla \\Phi(x)$, onto the tangent space of the simplex, $T_x \\Delta^n = \\{ v \\in \\mathbb{R}^n \\mid \\sum_{i=1}^{n} v_i = 0 \\}$.\n    a. The gradient of the potential $\\Phi(x) = x^\\top S x$ is $\\nabla \\Phi(x) = 2Sx$.\n    b. The tangent space is a linear subspace whose orthogonal complement is spanned by the vector of all ones, $\\mathbf{1} = [1, \\dots, 1]^\\top$. The orthogonal projection of a vector $u$ onto this tangent space is $u - \\text{proj}_{\\mathbf{1}}(u) = u - \\frac{u \\cdot \\mathbf{1}}{\\mathbf{1} \\cdot \\mathbf{1}} \\mathbf{1}$.\n    c. Applying this to $u = \\nabla \\Phi(x)$, and noting that $\\mathbf{1} \\cdot \\mathbf{1} = n$, we get:\n       $$ G(x) = \\nabla \\Phi(x) - \\frac{1}{n} \\left( \\sum_{i=1}^{n} (\\nabla \\Phi(x))_i \\right) \\mathbf{1} $$\n       This is equivalent to subtracting the mean from each component of $\\nabla \\Phi(x)$.\n\n4.  **Cosine Similarity $\\cos(R(x), G(x))$**: This is calculated using the Euclidean inner product:\n    $$ \\cos(R(x),G(x)) = \\frac{R(x) \\cdot G(x)}{\\|R(x)\\|_2 \\, \\|G(x)\\|_2} $$\n    If either norm in the denominator is $0$, the cosine similarity is defined to be $0$.\n\n5.  **Directional Derivatives $D_R \\Phi(x)$ and $D_G \\Phi(x)$**: These are computed as the dot product of the gradient with the direction vector.\n    a. $D_R \\Phi(x) = \\nabla \\Phi(x) \\cdot R(x)$. This quantity indicates how rapidly the potential function $\\Phi(x)$ changes along the flow of replicator dynamics.\n    b. $D_G \\Phi(x) = \\nabla \\Phi(x) \\cdot G(x)$. Due to the properties of orthogonal projection, this simplifies to $D_G \\Phi(x) = \\|G(x)\\|_2^2$, which is always non-negative.\n\n6.  **Ratio of Feasible Fractions $\\rho(x)$**: This quantity depends on the largest step size one can take from $x$ along a direction $v$ without violating non-negativity.\n    a. The maximum feasible step size is $\\delta_{\\max}(x,v) = \\min_{i: v_i  0} \\{ \\frac{x_i}{-v_i} \\}$. If the set $\\{i \\mid v_i  0\\}$ is empty, $\\delta_{\\max}(x,v) = +\\infty$.\n    b. The feasible fraction, with a cap $\\delta_{\\mathrm{cap}} = 0.1$, is $f(x,v) = \\frac{\\min\\{ \\delta_{\\max}(x,v), \\delta_{\\mathrm{cap}} \\}}{\\delta_{\\mathrm{cap}}}$.\n    c. The final ratio is $\\rho(x) = \\frac{f(x,R(x))}{f(x,G(x))}$. If the denominator $f(x,G(x)) = 0$, the ratio is set to $+\\infty$.\n\nFor each of the five test cases $(A_k, x^{(j)})$, we will execute these computational steps and collect the five resulting floating-point numbers. The final output is a single flattened list of these $5 \\times 5 = 25$ numbers.",
            "answer": "```python\nimport numpy as np\n\ndef calculate_metrics(A, x, delta_cap=0.1):\n    \"\"\"\n    Computes the set of five specified metrics for a given payoff matrix A and population state x.\n    \"\"\"\n    n = A.shape[0]\n\n    # 1. Potential Phi(x)\n    S = 0.5 * (A + A.T)\n    # Note: x.T @ S @ x is always equal to x.T @ A @ x\n    phi = x.T @ S @ x\n\n    # 2. Replicator Vector Field R(x)\n    payoffs = A @ x\n    pi_bar = x.T @ payoffs\n    R = x * (payoffs - pi_bar)\n\n    # 3. Projected Gradient Vector Field G(x)\n    grad_phi = 2 * S @ x\n    G = grad_phi - np.mean(grad_phi) * np.ones(n)\n\n    # 4. Cosine Similarity cos(R(x), G(x))\n    norm_R = np.linalg.norm(R)\n    norm_G = np.linalg.norm(G)\n    if norm_R == 0.0 or norm_G == 0.0:\n        cos_sim = 0.0\n    else:\n        dot_RG = np.dot(R, G)\n        cos_sim = dot_RG / (norm_R * norm_G)\n\n    # 5. Directional Derivatives D_R Phi(x) and D_G Phi(x)\n    D_R_phi = np.dot(grad_phi, R)\n    D_G_phi = np.dot(grad_phi, G)\n\n    # 6. Ratio of Feasible Fractions rho(x)\n    def get_f(x_vec, v_vec, cap):\n        neg_v_indices = np.where(v_vec  0)[0]\n        if neg_v_indices.size == 0:\n            delta_max = np.inf\n        else:\n            ratios = x_vec[neg_v_indices] / -v_vec[neg_v_indices]\n            delta_max = np.min(ratios)\n        \n        return min(delta_max, cap) / cap\n\n    f_R = get_f(x, R, delta_cap)\n    f_G = get_f(x, G, delta_cap)\n\n    if f_G == 0.0:\n        rho = np.inf\n    else:\n        rho = f_R / f_G\n\n    return [phi, cos_sim, D_R_phi, D_G_phi, rho]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Define matrices\n    A1 = np.array([\n        [0.0, 1.2, 0.5],\n        [1.2, 0.0, 0.8],\n        [0.5, 0.8, 0.0]\n    ])\n    A2 = np.array([\n        [0.0, -1.0, -0.5],\n        [-1.0, 0.0, -0.2],\n        [-0.5, -0.2, 0.0]\n    ])\n    A3 = np.array([\n        [0.0, 2.0, -1.0],\n        [0.5, 0.0, 0.0],\n        [0.0, -2.0, 0.0]\n    ])\n\n    # Define population states\n    x1 = np.array([0.4, 0.4, 0.2])\n    x2 = np.array([0.05, 0.55, 0.40])\n\n    # Define the 5 test cases\n    test_cases = [\n        (A1, x1),\n        (A1, x2),\n        (A2, x1),\n        (A3, x1),\n        (A3, x2)\n    ]\n\n    all_results = []\n    for A, x in test_cases:\n        results_for_case = calculate_metrics(A, x)\n        all_results.extend(results_for_case)\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n\n```"
        }
    ]
}