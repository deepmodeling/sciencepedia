{
    "hands_on_practices": [
        {
            "introduction": "纳什均衡描述了一个稳定状态，其中任何参与者都无法通过单方面改变策略而获得更好的收益。第一个实践练习  旨在深入探讨这种自利行为的一个关键意涵：个体理性与集体福祉之间的潜在冲突。通过在一个简单的双人博弈中，运用解析方法求解纳什均衡与社会最优解，您将亲手量化“无政府代价”(price of anarchy)，从而直观地理解为何个体追求自身利益最大化并不总能导向集体最优的结果。",
            "id": "3154673",
            "problem": "考虑一个双人线性二次博弈，其中参与者 $i \\in \\{1,2\\}$ 选择一个标量决策变量 $x_i \\in \\mathbb{R}$。成本函数由下式给出\n$$\nf_i(x_1,x_2) \\;=\\; \\frac{1}{2} \\, q_i \\, x_i^{2} \\;+\\; b_i \\, x_i \\, x_{-i} \\;+\\; c_i \\, x_i,\n$$\n其中 $x_{-i}$ 表示另一个参与者的决策。令 $q_1 = 2$, $q_2 = 4$, $b_1 = 1$, $b_2 = 1$, $c_1 = -5$，且 $c_2 = 1$。假设对于每个参与者都有 $q_i  0$，因此每个参与者的优化问题关于其自身的决策变量是严格凸的。\n\n从纳什均衡（NE）的定义出发（即没有参与者可以通过单方面偏离来降低自己的成本），并利用可微凸函数的一阶最优性条件，推导出描述纳什均衡的分块线性系统，并求解均衡点 $(x_1^{\\ast}, x_2^{\\ast})$。然后，构建最小化社会成本的中心化优化问题\n$$\nF(x_1,x_2) \\;=\\; f_1(x_1,x_2) \\;+\\; f_2(x_1,x_2),\n$$\n推导其一阶最优性条件，并求解中心化最优解 $(x_1^{c}, x_2^{c})$。\n\n将两个解连接成一个单一的行向量 $\\big(x_1^{\\ast}, \\, x_2^{\\ast}, \\, x_1^{c}, \\, x_2^{c}\\big)$ 作为你的最终结果。无需四舍五入。",
            "solution": "该问题要求为一个双人线性二次博弈找到两个不同的解：纳什均衡（NE）和中心化（社会最优）解。\n\n首先，我们确定纳什均衡，记为 $(x_1^{\\ast}, x_2^{\\ast})$。纳什均衡是一种状态，在该状态下，假设其他参与者的决策保持不变，没有任何一个参与者能通过单方面改变自己的决策来改善其结果（即降低其成本）。对于参与者 $i \\in \\{1,2\\}$，其成本函数 $f_i(x_1, x_2)$ 关于其自身的决策变量 $x_i$ 是可微且凸的，该条件在数学上通过一阶最优性条件 $\\frac{\\partial f_i}{\\partial x_i} = 0$ 来表示。\n\n参与者 $i$ 的成本函数给出如下：\n$$\nf_i(x_1,x_2) = \\frac{1}{2} q_i x_i^{2} + b_i x_i x_{-i} + c_i x_i\n$$\n其中 $x_{-i}$ 是另一个参与者的决策。问题陈述 $q_i  0$，这确保了 $f_i$ 关于 $x_i$ 是严格凸的，从而保证一阶条件能够确定参与者 $i$ 优化问题的唯一最小值。\n\n让我们计算每个参与者的偏导数。\n对于参与者 1：\n$$\nf_1(x_1,x_2) = \\frac{1}{2} q_1 x_1^{2} + b_1 x_1 x_2 + c_1 x_1\n$$\n一阶条件是：\n$$\n\\frac{\\partial f_1}{\\partial x_1} = q_1 x_1 + b_1 x_2 + c_1 = 0\n$$\n\n对于参与者 2：\n$$\nf_2(x_1,x_2) = \\frac{1}{2} q_2 x_2^{2} + b_2 x_2 x_1 + c_2 x_2\n$$\n一阶条件是：\n$$\n\\frac{\\partial f_2}{\\partial x_2} = q_2 x_2 + b_2 x_1 + c_2 = 0\n$$\n\n这两个方程构成了求解纳什均衡 $(x_1^{\\ast}, x_2^{\\ast})$ 的一个线性系统：\n\\begin{align*}\nq_1 x_1^{\\ast} + b_1 x_2^{\\ast} = -c_1 \\\\\nb_2 x_1^{\\ast} + q_2 x_2^{\\ast} = -c_2\n\\end{align*}\n以矩阵形式表示，即为：\n$$\n\\begin{pmatrix} q_1  b_1 \\\\ b_2  q_2 \\end{pmatrix} \\begin{pmatrix} x_1^{\\ast} \\\\ x_2^{\\ast} \\end{pmatrix} = \\begin{pmatrix} -c_1 \\\\ -c_2 \\end{pmatrix}\n$$\n给定的参数值为：$q_1 = 2$，$q_2 = 4$，$b_1 = 1$，$b_2 = 1$，$c_1 = -5$，且 $c_2 = 1$。将这些值代入系统中，得到：\n\\begin{align*}\n2 x_1^{\\ast} + 1 x_2^{\\ast} = -(-5) = 5 \\\\\n1 x_1^{\\ast} + 4 x_2^{\\ast} = -1\n\\end{align*}\n从第一个方程中，我们可以用 $x_1^{\\ast}$ 来表示 $x_2^{\\ast}$：\n$$\nx_2^{\\ast} = 5 - 2 x_1^{\\ast}\n$$\n将此代入第二个方程中：\n$$\nx_1^{\\ast} + 4(5 - 2 x_1^{\\ast}) = -1\n$$\n$$\nx_1^{\\ast} + 20 - 8 x_1^{\\ast} = -1\n$$\n$$\n-7 x_1^{\\ast} = -21\n$$\n$$\nx_1^{\\ast} = 3\n$$\n现在，我们将 $x_1^{\\ast}$ 的值代回以求得 $x_2^{\\ast}$：\n$$\nx_2^{\\ast} = 5 - 2(3) = 5 - 6 = -1\n$$\n因此，纳什均衡为 $(x_1^{\\ast}, x_2^{\\ast}) = (3, -1)$。\n\n接下来，我们确定中心化最优解，记为 $(x_1^{c}, x_2^{c})$。这是一对能使总成本或社会成本 $F(x_1,x_2) = f_1(x_1,x_2) + f_2(x_1,x_2)$ 最小化的决策。\n让我们写出社会成本函数 $F(x_1,x_2)$：\n$$\nF(x_1,x_2) = \\left(\\frac{1}{2} q_1 x_1^{2} + b_1 x_1 x_2 + c_1 x_1\\right) + \\left(\\frac{1}{2} q_2 x_2^{2} + b_2 x_1 x_2 + c_2 x_2\\right)\n$$\n$$\nF(x_1,x_2) = \\frac{1}{2} q_1 x_1^{2} + \\frac{1}{2} q_2 x_2^{2} + (b_1 + b_2) x_1 x_2 + c_1 x_1 + c_2 x_2\n$$\n这是一个关于变量 $(x_1, x_2)$ 的联合优化问题。为求最小值，我们计算 $F$ 的梯度并令其为零。一阶条件是 $\\frac{\\partial F}{\\partial x_1} = 0$ 和 $\\frac{\\partial F}{\\partial x_2} = 0$。\n$$\n\\frac{\\partial F}{\\partial x_1} = q_1 x_1 + (b_1 + b_2) x_2 + c_1 = 0\n$$\n$$\n\\frac{\\partial F}{\\partial x_2} = q_2 x_2 + (b_1 + b_2) x_1 + c_2 = 0\n$$\n这为我们提供了求解中心化最优解 $(x_1^{c}, x_2^{c})$ 的一个线性方程组：\n\\begin{align*}\nq_1 x_1^{c} + (b_1 + b_2) x_2^{c} = -c_1 \\\\\n(b_1 + b_2) x_1^{c} + q_2 x_2^{c} = -c_2\n\\end{align*}\n为确保这是一个最小值，我们可以检查 $F$ 的海森矩阵，即 $H_F = \\begin{pmatrix} q_1  b_1+b_2 \\\\ b_1+b_2  q_2 \\end{pmatrix}$。使用给定值，$H_F = \\begin{pmatrix} 2  2 \\\\ 2  4 \\end{pmatrix}$。其顺序主子式为 $2  0$ 和 $\\det(H_F) = 2(4) - 2(2) = 4  0$。由于海森矩阵是正定的，因此 $F$ 是严格凸的，一阶条件的解是唯一的全局最小值。\n\n将参数值代入中心化解的系统中：\n\\begin{align*}\n2 x_1^{c} + (1+1) x_2^{c} = -(-5) \\implies 2 x_1^{c} + 2 x_2^{c} = 5 \\\\\n(1+1) x_1^{c} + 4 x_2^{c} = -1 \\implies 2 x_1^{c} + 4 x_2^{c} = -1\n\\end{align*}\n我们现在解这个方程组。用第二个方程减去第一个方程，得到：\n$$\n(2 x_1^{c} + 4 x_2^{c}) - (2 x_1^{c} + 2 x_2^{c}) = -1 - 5\n$$\n$$\n2 x_2^{c} = -6\n$$\n$$\nx_2^{c} = -3\n$$\n将 $x_2^{c} = -3$ 代入第一个方程：\n$$\n2 x_1^{c} + 2(-3) = 5\n$$\n$$\n2 x_1^{c} - 6 = 5\n$$\n$$\n2 x_1^{c} = 11\n$$\n$$\nx_1^{c} = \\frac{11}{2}\n$$\n因此，中心化最优解为 $(x_1^{c}, x_2^{c}) = (\\frac{11}{2}, -3)$。\n\n问题要求将最终结果表示为连接后的行向量 $\\big(x_1^{\\ast}, x_2^{\\ast}, x_1^{c}, x_2^{c}\\big)$。\n计算出的值为 $x_1^{\\ast} = 3$，$x_2^{\\ast} = -1$，$x_1^{c} = \\frac{11}{2}$ 和 $x_2^{c} = -3$。\n最终的向量是 $\\big(3, -1, \\frac{11}{2}, -3\\big)$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 3  -1  \\frac{11}{2}  -3 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "现实世界中的许多复杂系统，从交通网络到互联网路由，都涉及海量主体同时进行决策。本练习  将纳什均衡的概念拓展至大规模网络背景，引入适用于“非原子”拥塞博弈的沃德罗普均衡（Wardrop equilibrium）。您将通过编程实现一个基于复制动态（replicator dynamics）的学习模型，模拟群体行为如何通过学习过程自发涌现并趋向均衡，从而深刻体会个体微观决策规则与系统宏观稳态之间的内在联系。",
            "id": "4310494",
            "problem": "考虑一个非原子拥塞博弈，其网络由连接单一源-汇对的两条平行链路组成。总质量归一化为 $1$ 的连续体智能体在链路 $1$ 和链路 $2$ 之间进行选择。设 $p \\in [0,1]$ 表示使用链路 $1$ 的群体份额，因此链路流量为 $x_1 = p$ 和 $x_2 = 1 - p$。每条链路 $k \\in \\{1,2\\}$ 都有一个仿射成本函数 $c_k(x_k) = a_k + b_k x_k$，其中参数 $a_k \\in \\mathbb{R}$ 且 $b_k \\ge 0$。选择链路 $k$ 的智能体的收益为 $u_k = -c_k(x_k)$，因为它们旨在最小化成本。\n\n基本定义和基础：\n- 纳什均衡（在非原子路由博弈中称为 Wardrop 均衡）是一种群体分布，其中所有被使用的策略都具有最小成本；具体来说，当两条链路都被使用时，均衡条件是 $c_1(x_1) = c_2(x_2)$，而当只有一条链路被使用时，其成本不高于另一条链路。\n- 在势博弈（包括拥塞博弈）中，诸如模仿者复制动态之类的学习动态具有李雅普诺夫结构。考虑由以下更新规则定义的离散时间模仿者复制动态\n$$\np_{t+1} = p_t + \\eta \\, p_t \\, (1 - p_t) \\, \\big(u_1(p_t) - u_2(p_t)\\big),\n$$\n其中 $\\eta  0$ 是一个学习率参数，且对于 $x_1 = p$ 和 $x_2 = 1 - p$，有 $u_k(p) = -c_k(x_k)$。此动态的稳定点满足 $p \\in \\{0,1\\}$ 或 $u_1(p) = u_2(p)$，这等价于 $c_1(p) = c_2(1 - p)$，即 Wardrop 均衡条件。\n\n任务：\n- 通过令两条链路在都被使用时的成本相等，推导解析的 Wardrop 均衡份额 $p^\\star$。对于 $b_1 + b_2  0$，内部均衡可通过求解\n$$\na_1 + b_1 p^\\star = a_2 + b_2 (1 - p^\\star),\n$$\n得到\n$$\np^\\star = \\frac{a_2 + b_2 - a_1}{b_1 + b_2}.\n$$\n如果计算出的 $p^\\star$ 位于 $[0,1]$ 之外，则均衡点在边界 $p^\\star = 0$ 或 $p^\\star = 1$ 处，具体取决于在极端情况下哪条链路的成本更低。如果 $b_1 + b_2 = 0$ 且 $a_1 = a_2$，则对于所有 $p$，都有 $c_1(x_1) = c_2(x_2)$，均衡集是整个区间 $[0,1]$；在这种退化情况下，任何 $p$ 都是一个纳什均衡。\n- 实现具有上述更新规则的离散时间模仿者复制动态。使用 $u_1(p) = -\\big(a_1 + b_1 p\\big)$ 和 $u_2(p) = -\\big(a_2 + b_2 (1 - p)\\big)$，从初始条件 $p_0 \\in [0,1]$ 开始，并迭代指定的步数 $T \\in \\mathbb{N}$。算法应将迭代值裁剪以保持在区间 $[0,1]$ 内。\n\n对于下面列出的每个测试用例，您的程序必须：\n$1.$ 根据参数计算解析均衡 $p^\\star$。\n$2.$ 从 $p_0$ 开始，使用学习率 $\\eta$ 模拟复制动态 $T$ 步。\n$3.$ 计算最终绝对偏差 $|p_T - p^\\star|$。在 $b_1 + b_2 = 0$ 且 $a_1 = a_2$ 的退化情况下，将均衡集视为 $[0,1]$ 并报告偏差为 $0$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[r_1,r_2,\\dots]$），其中每个 $r_i$ 是相应测试用例的浮点偏差。\n\n测试套件：\n使用以下五个测试用例，每个用例由 $(a_1, b_1, a_2, b_2, \\eta, T, p_0)$ 指定：\n$1.$ $(0.2, 1.0, 0.8, 0.4, 0.05, 20000, 0.1)$\n$2.$ $(0.0, 1.0, 2.0, 1.0, 0.05, 20000, 0.5)$\n$3.$ $(1.5, 1.0, 0.0, 1.0, 0.05, 20000, 0.8)$\n$4.$ $(1.0, 0.0, 1.0, 0.0, 0.2, 1000, 0.3)$\n$5.$ $(0.0, 1.0, 0.1, 3.0, 0.03, 30000, 0.9)$\n\n最终输出格式要求：\n您的程序必须打印单行，其中包含一个由五个浮点数组成的列表 $[r_1,r_2,r_3,r_4,r_5]$，其中 $r_i$ 是测试用例 $i$ 的偏差。不应打印任何其他文本。",
            "solution": "我们从博弈论和网络科学的核心定义开始。在一个具有仿射成本函数 $c_k(x_k) = a_k + b_k x_k$ 的两条平行链路上的非原子路由博弈中，智能体最小化成本，此时 Wardrop 均衡与纳什均衡一致：被使用的策略（具有正流量的链路）必须具有相等且最小的成本。\n\n设 $p \\in [0,1]$ 表示选择链路 $1$ 的群体份额，因此 $x_1 = p$ 且 $x_2 = 1 - p$。成本为 $c_1(p) = a_1 + b_1 p$ 和 $c_2(1-p) = a_2 + b_2 (1-p)$。纳什均衡条件是：\n$1.$ 内部均衡：如果两条链路都被使用，则 $c_1(p^\\star) = c_2(1 - p^\\star)$。\n$2.$ 边界均衡：如果内部解位于 $[0,1]$ 之外，则均衡点必须在 $p^\\star = 0$ 或 $p^\\star = 1$ 处，具体取决于哪个边界为被使用的策略产生更低的成本。\n\n求解内部方程 $a_1 + b_1 p^\\star = a_2 + b_2 (1 - p^\\star)$ 可得\n$$\np^\\star = \\frac{a_2 + b_2 - a_1}{b_1 + b_2},\n$$\n前提是 $b_1 + b_2  0$。如果 $p^\\star \\notin [0,1]$，则均衡点在边界处：如果在 $p=0$ 时链路 $2$ 严格更便宜，则 $p^\\star = 0$；如果在 $p=1$ 时链路 $1$ 严格更便宜，则 $p^\\star = 1$。在退化情况 $b_1 + b_2 = 0$ 下，两个成本都是常数。如果 $a_1 = a_2$，则对于所有 $p$ 都有 $c_1 = c_2$，并且每个 $p \\in [0,1]$ 都是一个纳什均衡；否则，均衡点在边界上，所有质量都集中在成本更低的链路上。\n\n我们现在将学习和自适应动态与均衡联系起来。一个双策略群体博弈的离散时间模仿者复制动态是\n$$\np_{t+1} = p_t + \\eta \\, p_t \\, (1 - p_t) \\, \\big(u_1(p_t) - u_2(p_t)\\big),\n$$\n其中 $\\eta  0$ 是学习率，而 $u_k(p) = -c_k(x_k)$ 是等于负成本的收益。代入 $u_1(p) = -\\big(a_1 + b_1 p\\big)$ 和 $u_2(p) = -\\big(a_2 + b_2 (1 - p)\\big)$，我们得到\n$$\nu_1(p) - u_2(p) = -\\big(a_1 + b_1 p\\big) + \\big(-a_2 - b_2 + b_2 p\\big) = -\\big(a_1 - a_2 - b_2\\big) - (b_1 + b_2) p.\n$$\n等价地，$u_1(p) - u_2(p)$ 的符号反映了 $c_2(1 - p) - c_1(p)$ 的符号，并且更新会使 $p$ 朝着更高收益（更低成本）的方向移动。该动态的稳定点满足 $p \\in \\{0,1\\}$ 或 $u_1(p) = u_2(p)$，这恰好是 $c_1(p) = c_2(1 - p)$。在诸如拥塞博弈之类的势博弈中，模仿动态允许一个与势相关的李雅普诺夫函数，并且在合适的步长下，迭代会趋近于均衡集。\n\n算法设计：\n$1.$ 对于每个测试用例 $(a_1, b_1, a_2, b_2, \\eta, T, p_0)$，计算解析均衡 $p^\\star$：\n$1.1.$ 如果 $b_1 + b_2  0$，计算 $p^\\star = \\dfrac{a_2 + b_2 - a_1}{b_1 + b_2}$ 并将其投影到 $[0,1]$ 上；如果投影改变了该值，则表示这是一个边界均衡。\n$1.2.$ 如果 $b_1 + b_2 = 0$，检查是否 $a_1 = a_2$。如果是，则均衡集是整个区间 $[0,1]$；如果不是，则当 $a_1  a_2$ 时设 $p^\\star = 1$，当 $a_2  a_1$ 时设 $p^\\star = 0$。\n$2.$ 从 $p_0$ 开始，使用学习率 $\\eta$ 模拟离散时间复制动态 $T$ 次迭代：\n$$\np_{t+1} = \\mathrm{clip}\\Big(p_t + \\eta \\, p_t \\, (1 - p_t) \\, \\big(u_1(p_t) - u_2(p_t)\\big), \\, 0, \\, 1\\Big),\n$$\n其中 $\\mathrm{clip}$ 确保 $p_{t+1} \\in [0,1]$。这种裁剪与单纯形约束一致，并能抵消数值漂移。\n$3.$ 计算最终偏差 $|p_T - p^\\star|$。在成本恒定且相等的退化情况（$b_1 + b_2 = 0$ 且 $a_1 = a_2$）下，均衡集为 $[0,1]$；由于任何 $p_T \\in [0,1]$ 都是均衡点，因此报告偏差为 $0$。\n\n测试套件的覆盖理由：\n$1.$ 用例 $(0.2, 1.0, 0.8, 0.4, 0.05, 20000, 0.1)$ 代表一个典型的内部均衡。解析解为 $p^\\star = \\dfrac{0.8 + 0.4 - 0.2}{1.0 + 0.4} = \\dfrac{1.0}{1.4} \\approx 0.7142857$，复制动态应趋近于此内部解。\n$2.$ 用例 $(0.0, 1.0, 2.0, 1.0, 0.05, 20000, 0.5)$ 得出 $p^\\star = \\dfrac{2.0 + 1.0 - 0.0}{1.0 + 1.0} = \\dfrac{3.0}{2.0} = 1.5$，该值位于 $[0,1]$ 之外，因此为边界均衡 $p^\\star = 1$；动态应收敛到 $1$。\n$3.$ 用例 $(1.5, 1.0, 0.0, 1.0, 0.05, 20000, 0.8)$ 得出 $p^\\star = \\dfrac{0.0 + 1.0 - 1.5}{1.0 + 1.0} = \\dfrac{-0.5}{2.0} = -0.25$，因此为边界均衡 $p^\\star = 0$；动态应收敛到 $0$。\n$4.$ 用例 $(1.0, 0.0, 1.0, 0.0, 0.2, 1000, 0.3)$ 中有 $b_1 + b_2 = 0$ 和 $a_1 = a_2$，使得两条链路的成本恒定且相等；均衡集是整个区间 $[0,1]$，且动态具有 $u_1(p) - u_2(p) = 0$，因此 $p_t$ 是常数。报告的偏差为 $0$。\n$5.$ 用例 $(0.0, 1.0, 0.1, 3.0, 0.03, 30000, 0.9)$ 中有 $p^\\star = \\dfrac{0.1 + 3.0 - 0.0}{1.0 + 3.0} = \\dfrac{3.1}{4.0} = 0.775$，这是一个靠近边界的内部解，其中链路斜率不对称；动态应收敛到接近此值。\n\n最终程序确定性地执行这些计算，并将偏差以包含在方括号内的单个逗号分隔列表的形式输出，确保了可复现性和精确的数值答案。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_equilibrium(a1, b1, a2, b2):\n    \"\"\"\n    Compute the Wardrop (Nash) equilibrium share p* for a two-link affine congestion game.\n    Returns (p_star, continuum_flag).\n    continuum_flag is True only when b1 + b2 == 0 and a1 == a2 (continuum of equilibria).\n    \"\"\"\n    denom = b1 + b2\n    if denom == 0.0:\n        # Costs are constant. If equal constants, continuum of equilibria.\n        if np.isclose(a1, a2):\n            return None, True  # Any p in [0,1] is equilibrium\n        else:\n            # All mass on cheaper link\n            return (1.0 if a1  a2 else 0.0), False\n    else:\n        p_star = (a2 + b2 - a1) / denom\n        # Project onto [0,1] due to boundary equilibria\n        if p_star  0.0:\n            p_star = 0.0\n        elif p_star > 1.0:\n            p_star = 1.0\n        return p_star, False\n\ndef simulate_replicator(a1, b1, a2, b2, eta, T, p0):\n    \"\"\"\n    Simulate discrete-time imitative replicator dynamics for T steps:\n        p_{t+1} = p_t + eta * p_t * (1 - p_t) * (u1(p_t) - u2(p_t)),\n    with u1 = -(a1 + b1 * p), u2 = -(a2 + b2 * (1 - p)).\n    Returns p_T.\n    \"\"\"\n    p = float(p0)\n    for _ in range(T):\n        # Payoffs are negative costs\n        u1 = -(a1 + b1 * p)\n        u2 = -(a2 + b2 * (1.0 - p))\n        delta = eta * p * (1.0 - p) * (u1 - u2)\n        p = p + delta\n        # Clip to [0,1] to respect the simplex constraint\n        if p  0.0:\n            p = 0.0\n        elif p > 1.0:\n            p = 1.0\n    return p\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (a1, b1, a2, b2, eta, T, p0)\n    test_cases = [\n        (0.2, 1.0, 0.8, 0.4, 0.05, 20000, 0.1),\n        (0.0, 1.0, 2.0, 1.0, 0.05, 20000, 0.5),\n        (1.5, 1.0, 0.0, 1.0, 0.05, 20000, 0.8),\n        (1.0, 0.0, 1.0, 0.0, 0.2, 1000, 0.3),\n        (0.0, 1.0, 0.1, 3.0, 0.03, 30000, 0.9),\n    ]\n\n    results = []\n    for a1, b1, a2, b2, eta, T, p0 in test_cases:\n        p_star, continuum = compute_equilibrium(a1, b1, a2, b2)\n        p_T = simulate_replicator(a1, b1, a2, b2, eta, T, p0)\n        if continuum:\n            deviation = 0.0  # Any p in [0,1] is an equilibrium\n        else:\n            deviation = abs(p_T - p_star)\n        # Format with fixed precision for deterministic output\n        results.append(f\"{deviation:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在博弈中寻找纳什均衡的过程并非总能平稳地收敛，尤其是在纯粹的竞争性环境中。最后一个实践练习  将带您探索在“极小化极大”零和博弈（minimax zero-sum game）中可能出现的复杂动态，这类博弈是理解生成对抗网络（GANs）等现代对抗性系统的理论基石。您将通过实现一种先进的“乐观梯度下降-上升”（Optimistic Gradient Descent-Ascent, OGDA）算法，来亲身验证简单的梯度学习为何可能陷入持续的循环（cycling）而无法收敛，并理解更优化的算法如何帮助系统走向稳定，从而洞悉在对抗性环境中寻找均衡所面临的前沿挑战。",
            "id": "3154601",
            "problem": "考虑一个定义在一维连续策略上的双人零和极小化极大博弈，其中玩家 $1$ 选择 $x \\in \\mathbb{R}$ 来最小化一个损失，玩家 $2$ 选择 $y \\in \\mathbb{R}$ 来最大化同一个损失。该交互由可微损失函数\n$$\nL(x,y) = \\alpha\\, x y + \\frac{\\mu}{2} x^2 - \\frac{\\nu}{2} y^2,\n$$\n所控制，其中 $\\alpha \\in \\mathbb{R}$ 模拟玩家之间的耦合强度，$\\mu \\ge 0$ 和 $\\nu \\ge 0$ 分别模拟最小化者和最大化者的二次正则化项。\n\n基本基础：\n- 对于零和极小化极大博弈，纳什均衡是一对 $(x^\\star, y^\\star)$，使得对于所有 $x \\in \\mathbb{R}$ 和 $y \\in \\mathbb{R}$，\n$$\nL(x^\\star, y) \\le L(x^\\star, y^\\star) \\le L(x, y^\\star).\n$$\n对于凸凹函数 $L$（在 $x$ 上是凸的，在 $y$ 上是凹的），根据凸分析和变分不等式中经过充分检验的结果，这个鞍点条件等同于平稳性条件 $\\nabla_x L(x^\\star, y^\\star) = 0$ 和 $\\nabla_y L(x^\\star, y^\\star) = 0$ 的解。\n- 基于梯度的方法遵循由梯度 $\\nabla_x L$ 和 $\\nabla_y L$ 定义的向量场。在极小化极大动态中，朴素的梯度下降-上升法由于非对角耦合项的存在，常常在鞍点周围表现出旋转行为，这可能导致循环。乐观梯度下降-上升法 (OGDA) 通过引入前一步的梯度来修正更新，以抵消旋转效应。\n\n您的任务：\n1. 从第一性原理出发，使用鞍点和平稳性条件来确定上述定义的损失函数 $L(x,y)$ 的候选纳什均衡 $(x^\\star,y^\\star)$。\n2. 实现步长为 $\\eta  0$ 的乐观梯度下降-上升法 (OGDA)，该方法使用当前和之前的梯度来更新策略 $(x_t, y_t)$。令 $g_t^x = \\nabla_x L(x_t, y_t)$ 且 $g_t^y = \\nabla_y L(x_t, y_t)$。OGDA 更新规则为\n$$\nx_{t+1} = x_t - \\eta \\big( 2 g_t^x - g_{t-1}^x \\big), \\quad\ny_{t+1} = y_t + \\eta \\big( 2 g_t^y - g_{t-1}^y \\big).\n$$\n使用初始点 $(x_0,y_0)$ 处的梯度来一致地初始化 $g_{-1}^x$ 和 $g_{-1}^y$，使得第一次更新简化为单梯度步。\n3. 对指定的步数模拟 OGDA 迭代，并报告每个测试用例的以下量：\n   - 最终迭代与候选纳什均衡之间的欧几里得距离 $d_T = \\sqrt{(x_T - x^\\star)^2 + (y_T - y^\\star)^2}$，作为一个实数。\n   - 一个布尔值，指示序列是否根据准则 $d_T \\le 10^{-3}$ 收敛到纳什均衡。\n   - 一个布尔值，指示是否存在循环。循环定义为未发生收敛，轨迹在迭代的最后部分相对于其起点保持有界，并且径向距离序列 $r_t = \\sqrt{x_t^2 + y_t^2}$ 在轨迹的后半部分，其连续差分 $\\Delta r_t = r_{t+1} - r_t$ 的符号变化占有显著比例，从而表现出振荡。本问题不涉及物理单位；所有量均为无量纲实数。\n\n测试套件：\n在以下参数集上运行您的程序。每个测试用例由 ($\\alpha,\\mu,\\nu,\\eta,T,x_0,y_0$) 指定，其中 $T$ 是总迭代次数：\n- 情况 1：($\\alpha=1, \\mu=1/2, \\nu=1/2, \\eta=0.2, T=400, x_0=1, y_0=-1$)。\n- 情况 2：($\\alpha=1, \\mu=0, \\nu=0, \\eta=0.2, T=400, x_0=1, y_0=1$)。\n- 情况 3：($\\alpha=1, \\mu=0, \\nu=0, \\eta=1.0, T=400, x_0=1, y_0=1$)。\n- 情况 4：($\\alpha=3, \\mu=0.1, \\nu=0.1, \\eta=0.3, T=400, x_0=0.5, y_0=-0.5$)。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，并且本身是一个形如 $[d_T, \\text{converged}, \\text{cycled}]$ 的列表。例如，输出必须类似于\n$$\n[[d_1,\\text{True},\\text{False}],[d_2,\\text{False},\\text{True}],\\dots]\n$$\n其中 $d_i$ 为实际数值。",
            "solution": "我们从双人零和极小化极大博弈的纳什均衡的基本定义开始：一对满足\n$$\nL(x^\\star,y) \\le L(x^\\star,y^\\star) \\le L(x,y^\\star) \\quad \\text{对于所有 } x \\in \\mathbb{R}, y \\in \\mathbb{R}\n$$\n的 $(x^\\star,y^\\star)$。\n对于在 $x$ 上是凸的、在 $y$ 上是凹的，并且可微的 $L$，凸分析中一个经过充分检验的事实指出，这个鞍点条件等价于一阶平稳性条件的解：\n$$\n\\nabla_x L(x^\\star,y^\\star) = 0, \\quad \\nabla_y L(x^\\star,y^\\star) = 0.\n$$\n\n给定\n$$\nL(x,y) = \\alpha\\, x y + \\frac{\\mu}{2} x^2 - \\frac{\\nu}{2} y^2,\n$$\n其偏导数（梯度）为\n$$\n\\nabla_x L(x,y) = \\alpha\\, y + \\mu\\, x, \\quad \\nabla_y L(x,y) = \\alpha\\, x - \\nu\\, y.\n$$\n将它们设为零，得到线性系统\n$$\n\\alpha\\, y + \\mu\\, x = 0, \\quad \\alpha\\, x - \\nu\\, y = 0.\n$$\n当 $\\mu \\ge 0$ 且 $\\nu \\ge 0$ 时，该系统在实数域中的唯一解是 $x^\\star = 0$ 和 $y^\\star = 0$。具体来说，从 $\\alpha\\, y + \\mu\\, x = 0$ 我们得到 $y = -\\frac{\\mu}{\\alpha} x$（对于 $\\alpha \\neq 0$），代入 $\\alpha\\, x - \\nu\\, y = 0$ 得到\n$$\n\\alpha\\, x - \\nu \\left( -\\frac{\\mu}{\\alpha} x \\right) = \\left(\\alpha + \\frac{\\nu \\mu}{\\alpha}\\right) x = 0,\n$$\n所以 $x=0$，因此 $y=0$。当 $\\alpha=0$ 时，耦合消失，平稳性条件直接得出 $x=0$ 和 $y=0$。因此，候选纳什均衡是 $(x^\\star,y^\\star) = (0,0)$。\n\n极小化极大问题的优化动态通常使用梯度下降-上升法 (GDA)：\n$$\nx_{t+1} = x_t - \\eta \\nabla_x L(x_t,y_t), \\quad y_{t+1} = y_t + \\eta \\nabla_y L(x_t,y_t),\n$$\n但在具有非对角耦合（例如，双线性项）的博弈中，梯度场表现出可能导致围绕鞍点 $(x^\\star,y^\\star)$ 循环的旋转分量。为了缓解这种情况，乐观梯度下降-上升法 (OGDA) 引入了使用前一步梯度的外推：\n$$\nx_{t+1} = x_t - \\eta \\big( 2 g_t^x - g_{t-1}^x \\big), \\quad\ny_{t+1} = y_t + \\eta \\big( 2 g_t^y - g_{t-1}^y \\big),\n$$\n其中 $g_t^x = \\nabla_x L(x_t, y_t)$ 且 $g_t^y = \\nabla_y L(x_t, y_t)$。在合适的步长和平滑度条件下，这种修正抵消了梯度场的一部分旋转分量，从而产生朝向鞍点的更稳定的轨迹。\n\n算法实现：\n- 初始化 $(x_0,y_0)$ 并计算 $g_{-1}^x = \\nabla_x L(x_0,y_0)$ 和 $g_{-1}^y = \\nabla_y L(x_0,y_0)$。通过此选择，第一次更新简化为单梯度步，因为 $2 g_0 - g_{-1} = g_0$。\n- 迭代 $t = 0, 1, \\dots, T-1$：\n  1. 计算 $g_t^x = \\alpha\\, y_t + \\mu\\, x_t$, $g_t^y = \\alpha\\, x_t - \\nu\\, y_t$。\n  2. 更新\n     $$\n     x_{t+1} = x_t - \\eta \\big( 2 g_t^x - g_{t-1}^x \\big), \\quad\n     y_{t+1} = y_t + \\eta \\big( 2 g_t^y - g_{t-1}^y \\big).\n     $$\n  3. 为下一次迭代设置 $g_{t-1}^x \\leftarrow g_t^x$, $g_{t-1}^y \\leftarrow g_t^y$。\n- 在演化过程中记录径向距离 $r_t = \\sqrt{x_t^2 + y_t^2}$，并计算到纳什均衡的最终欧几里得距离：\n  $$\n  d_T = \\sqrt{(x_T - x^\\star)^2 + (y_T - y^\\star)^2} = \\sqrt{x_T^2 + y_T^2}.\n  $$\n\n收敛和循环诊断：\n- 收敛准则：如果 $d_T \\le 10^{-3}$，则声明收敛。\n- 循环检测：如果未发生收敛，当轨迹在迭代的后半段相对于起点是有界的，并且径向距离序列振荡时，声明为循环。具体来说：\n  - 有界性：设 $r_t$ 为半径；考虑后半部分的索引 $t \\in \\{ \\lfloor T/2 \\rfloor, \\dots, T \\}$。如果此窗口内的 $\\max r_t$ 小于初始半径 $r_0$ 的一个固定倍数（例如，20倍），则认为序列是有界的。这排除了发散的情况。\n  - 振荡：计算同一窗口内的连续差分 $\\Delta r_t = r_{t+1} - r_t$，并计算连续差分之间符号变化的比例。如果此比例超过一个阈值（例如，0.4），并且窗口内的振幅范围 $\\max r_t - \\min r_t$ 超过一个小的下限（例如，$10^{-3}$），则将该行为标记为循环。\n\n程序将这些规则应用于问题陈述中定义的每个测试用例，计算 $(x^\\star,y^\\star)$，模拟 OGDA，并为每个用例返回三元组 $[d_T, \\text{converged}, \\text{cycled}]$。最终输出将所有三元组聚合在单行的一个方括号列表中。这种设计将 OGDA 动态直接与极小化极大设置中的纳什均衡计算联系起来，并通过编程方式识别指示旋转动态的循环行为。",
            "answer": "```python\n# Python 3.12\n# Libraries: numpy 1.23.5, scipy 1.11.4 (not used)\nimport numpy as np\n\ndef grad_L(alpha, mu, nu, x, y):\n    # Gradients of L with respect to x and y\n    gx = alpha * y + mu * x\n    gy = alpha * x - nu * y\n    return gx, gy\n\ndef ogda(alpha, mu, nu, eta, T, x0, y0):\n    # Candidate Nash equilibrium for this quadratic-concave structure\n    x_star, y_star = 0.0, 0.0\n\n    # Initialize\n    x, y = float(x0), float(y0)\n    gx_prev, gy_prev = grad_L(alpha, mu, nu, x, y)  # use initial gradient as \"previous\" for OGDA start\n\n    radii = [np.hypot(x, y)]\n\n    for t in range(T):\n        gx, gy = grad_L(alpha, mu, nu, x, y)\n        # OGDA update: x_{t+1} = x_t - eta * (2 gx_t - gx_{t-1})\n        #              y_{t+1} = y_t + eta * (2 gy_t - gy_{t-1})\n        x_next = x - eta * (2.0 * gx - gx_prev)\n        y_next = y + eta * (2.0 * gy - gy_prev)\n        # Shift previous gradients\n        gx_prev, gy_prev = gx, gy\n        # Move to next\n        x, y = x_next, y_next\n        radii.append(np.hypot(x, y))\n\n    # Final distance to Nash equilibrium (which is at origin)\n    d_T = np.hypot(x - x_star, y - y_star)\n\n    # Convergence criterion\n    converged = d_T = 1e-3\n\n    # Cycling detection over last half of iterations\n    half_idx = len(radii) // 2\n    last_half = np.array(radii[half_idx:])\n    diffs = np.diff(last_half)\n\n    # Boundedness relative to start\n    r0 = radii[0]\n    bounded = (np.max(last_half)  20.0 * max(r0, 1e-12))\n\n    # Oscillation: fraction of sign changes in successive differences and amplitude range\n    if len(diffs) >= 2:\n        signs = np.sign(diffs)\n        # treat zeros as no sign change with neighbors; adjust by small epsilon\n        signs[signs == 0] = 0\n        sign_changes = 0\n        for i in range(len(signs) - 1):\n            if signs[i] * signs[i+1]  0:\n                sign_changes += 1\n        frac_changes = sign_changes / max(len(signs) - 1, 1)\n    else:\n        frac_changes = 0.0\n    amplitude = float(np.max(last_half) - np.min(last_half))\n    oscillatory = (frac_changes >= 0.4) and (amplitude > 1e-3)\n\n    cycled = (not converged) and bounded and oscillatory\n\n    return [d_T, converged, cycled]\n\ndef solve():\n    # Define the test cases from the problem statement:\n    # Each case is (alpha, mu, nu, eta, T, x0, y0)\n    test_cases = [\n        (1.0, 0.5, 0.5, 0.2, 400, 1.0, -1.0),   # Case 1\n        (1.0, 0.0, 0.0, 0.2, 400, 1.0, 1.0),    # Case 2\n        (1.0, 0.0, 0.0, 1.0, 400, 1.0, 1.0),    # Case 3\n        (3.0, 0.1, 0.1, 0.3, 400, 0.5, -0.5),   # Case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha, mu, nu, eta, T, x0, y0 = case\n        res = ogda(alpha, mu, nu, eta, T, x0, y0)\n        # Ensure float is not numpy type for clean printing\n        res = [float(res[0]), bool(res[1]), bool(res[2])]\n        results.append(res)\n\n    # Final print statement in the exact required format.\n    # Print as a single list of lists, with booleans and floats.\n    # Example: [[0.00123,True,False],[...],...]\n    def format_item(item):\n        # item is [float, bool, bool]\n        d = f\"{item[0]}\"\n        b1 = \"True\" if item[1] else \"False\"\n        b2 = \"True\" if item[2] else \"False\"\n        return f\"[{d},{b1},{b2}]\"\n\n    print(f\"[{','.join(format_item(r) for r in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}